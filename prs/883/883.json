{
  "repo": "duckdb/duckdb",
  "pull_number": 883,
  "instance_id": "duckdb__duckdb-883",
  "issue_numbers": [
    "782"
  ],
  "base_commit": "a3c2865880c1ec5c8d516b332f2394340de6c0d8",
  "patch": "diff --git a/benchmark/benchmark_runner.cpp b/benchmark/benchmark_runner.cpp\nindex 57c2b5498018..8714e5e20afb 100644\n--- a/benchmark/benchmark_runner.cpp\n+++ b/benchmark/benchmark_runner.cpp\n@@ -281,6 +281,9 @@ ConfigurationError run_benchmarks(const BenchmarkConfiguration &configuration) {\n \t\tif (benchmark_indices.empty()) {\n \t\t\treturn ConfigurationError::BenchmarkNotFound;\n \t\t}\n+\t\tstd::sort(benchmark_indices.begin(), benchmark_indices.end(), [&](const int a, const int b) -> bool {\n+\t\t\treturn benchmarks[a]->name < benchmarks[b]->name;\n+\t\t});\n \t\tif (configuration.meta == BenchmarkMetaType::INFO) {\n \t\t\t// print info of benchmarks\n \t\t\tfor (const auto &benchmark_index : benchmark_indices) {\ndiff --git a/benchmark/interpreted_benchmark.cpp b/benchmark/interpreted_benchmark.cpp\nindex b75fcf51578e..566851d0f0a4 100644\n--- a/benchmark/interpreted_benchmark.cpp\n+++ b/benchmark/interpreted_benchmark.cpp\n@@ -168,9 +168,9 @@ void InterpretedBenchmark::LoadBenchmark() {\n \t\t\t\t\t}\n \t\t\t\t\tauto result_splits = StringUtil::Split(line, \"\\t\");\n \t\t\t\t\tif ((int64_t)result_splits.size() != result_column_count) {\n-\t\t\t\t\t\tthrow std::runtime_error(reader.FormatException(\"expected \" + to_string(result_column_count) +\n+\t\t\t\t\t\tthrow std::runtime_error(reader.FormatException(\"expected \" + to_string(result_splits.size()) +\n \t\t\t\t\t\t                                                \" values but got \" +\n-\t\t\t\t\t\t                                                to_string(result_splits.size())));\n+\t\t\t\t\t\t                                                to_string(result_column_count)));\n \t\t\t\t\t}\n \t\t\t\t\tresult_values.push_back(move(result_splits));\n \t\t\t\t}\ndiff --git a/benchmark/micro/CMakeLists.txt b/benchmark/micro/CMakeLists.txt\nindex 1e9eedb1334b..53fff40b31a6 100644\n--- a/benchmark/micro/CMakeLists.txt\n+++ b/benchmark/micro/CMakeLists.txt\n@@ -9,7 +9,6 @@ add_library(\n   in.cpp\n   multiplications.cpp\n   orderby.cpp\n-  pointquery.cpp\n   indexcreation.cpp\n   rangejoin.cpp\n   rangequery.cpp\ndiff --git a/benchmark/micro/index/point_query_with_index.benchmark b/benchmark/micro/index/point_query_with_index.benchmark\nnew file mode 100644\nindex 000000000000..cee387c99a3f\n--- /dev/null\n+++ b/benchmark/micro/index/point_query_with_index.benchmark\n@@ -0,0 +1,13 @@\n+# name: benchmark/micro/index/point_query_with_index.benchmark\n+# description: Point query with an index on randomly ordered data\n+# group: [index]\n+\n+load\n+CREATE TABLE integers AS SELECT (i * 9876983769044 % 100000000) AS i, i + 2 AS j FROM range(0, 100000000) t(i);\n+CREATE INDEX i_index ON integers using art(i);\n+\n+run\n+SELECT i FROM integers WHERE i=50000 LIMIT 1\n+\n+result I\n+50000\ndiff --git a/benchmark/micro/index/point_query_without_index.benchmark b/benchmark/micro/index/point_query_without_index.benchmark\nnew file mode 100644\nindex 000000000000..6b334e0f8ce0\n--- /dev/null\n+++ b/benchmark/micro/index/point_query_without_index.benchmark\n@@ -0,0 +1,12 @@\n+# name: benchmark/micro/index/point_query_without_index.benchmark\n+# description: Point query without index on randomly ordered data\n+# group: [index]\n+\n+load\n+CREATE TABLE integers AS SELECT (i * 9876983769044 % 100000000) AS i, i + 2 AS j FROM range(0, 100000000) t(i);\n+\n+run\n+SELECT i FROM integers WHERE i=50000 LIMIT 1\n+\n+result I\n+50000\ndiff --git a/benchmark/micro/index/point_query_without_index_sequential.benchmark b/benchmark/micro/index/point_query_without_index_sequential.benchmark\nnew file mode 100644\nindex 000000000000..c5e59c68e8f5\n--- /dev/null\n+++ b/benchmark/micro/index/point_query_without_index_sequential.benchmark\n@@ -0,0 +1,12 @@\n+# name: benchmark/micro/index/point_query_without_index_sequential.benchmark\n+# description: Point query without on sequentially ordered data\n+# group: [index]\n+\n+load\n+CREATE TABLE integers AS SELECT i, i + 2 AS j FROM range(0, 100000000) t(i)\n+\n+run\n+SELECT j FROM integers WHERE i=50000\n+\n+result I\n+50002\ndiff --git a/benchmark/micro/index/range_query_with_index.benchmark b/benchmark/micro/index/range_query_with_index.benchmark\nnew file mode 100644\nindex 000000000000..aed437a5d185\n--- /dev/null\n+++ b/benchmark/micro/index/range_query_with_index.benchmark\n@@ -0,0 +1,13 @@\n+# name: benchmark/micro/index/range_query_with_index.benchmark\n+# description: Range query with index\n+# group: [index]\n+\n+load\n+CREATE TABLE integers AS SELECT i, i + 2 AS j FROM range(0, 100000000) t(i);\n+CREATE INDEX i_index ON integers using art(i);\n+\n+run\n+SELECT COUNT(j) FROM integers WHERE i >= 15000100 AND i < 15000200;\n+\n+result I\n+100\ndiff --git a/benchmark/micro/index/range_query_without_index.benchmark b/benchmark/micro/index/range_query_without_index.benchmark\nnew file mode 100644\nindex 000000000000..cd05647fa7f0\n--- /dev/null\n+++ b/benchmark/micro/index/range_query_without_index.benchmark\n@@ -0,0 +1,12 @@\n+# name: benchmark/micro/index/point_query_without_index.benchmark\n+# description: Range query without index\n+# group: [index]\n+\n+load\n+CREATE TABLE integers AS SELECT i, i + 2 AS j FROM range(0, 100000000) t(i);\n+\n+run\n+SELECT COUNT(j) FROM integers WHERE i >= 15000100 AND i < 15000200;\n+\n+result I\n+100\ndiff --git a/benchmark/micro/index/wide_range_query_with_index.benchmark b/benchmark/micro/index/wide_range_query_with_index.benchmark\nnew file mode 100644\nindex 000000000000..9a540320ab8a\n--- /dev/null\n+++ b/benchmark/micro/index/wide_range_query_with_index.benchmark\n@@ -0,0 +1,13 @@\n+# name: benchmark/micro/index/wide_range_query_with_index.benchmark\n+# description: Wide (non-selective) range query with index\n+# group: [index]\n+\n+load\n+CREATE TABLE integers AS SELECT i, i + 2 AS j FROM range(0, 100000000) t(i);\n+CREATE INDEX i_index ON integers using art(i);\n+\n+run\n+SELECT COUNT(j) FROM integers WHERE i >= 0 AND i < 15000200;\n+\n+result I\n+15000200\ndiff --git a/benchmark/micro/index/wide_range_query_without_index.benchmark b/benchmark/micro/index/wide_range_query_without_index.benchmark\nnew file mode 100644\nindex 000000000000..af9ba2bb9f6e\n--- /dev/null\n+++ b/benchmark/micro/index/wide_range_query_without_index.benchmark\n@@ -0,0 +1,12 @@\n+# name: benchmark/micro/index/wide_range_query_without_index.benchmark\n+# description: Wide (non-selective) range query without index\n+# group: [index]\n+\n+load\n+CREATE TABLE integers AS SELECT i, i + 2 AS j FROM range(0, 100000000) t(i);\n+\n+run\n+SELECT COUNT(j) FROM integers WHERE i >= 0 AND i < 15000200;\n+\n+result I\n+15000200\ndiff --git a/benchmark/micro/pointquery.cpp b/benchmark/micro/pointquery.cpp\ndeleted file mode 100644\nindex dc720d271d2e..000000000000\n--- a/benchmark/micro/pointquery.cpp\n+++ /dev/null\n@@ -1,89 +0,0 @@\n-#include \"benchmark_runner.hpp\"\n-#include \"duckdb_benchmark_macro.hpp\"\n-#include \"duckdb/main/appender.hpp\"\n-\n-#include <random>\n-\n-using namespace duckdb;\n-using namespace std;\n-\n-#define POINT_QUERY_ROW_COUNT 100000000\n-#define POINT_QUERY_ENTRY 50000\n-\n-DUCKDB_BENCHMARK(PointQueryWithoutIndex, \"[micro]\")\n-virtual void Load(DuckDBBenchmarkState *state) {\n-\tstate->conn.Query(\"CREATE TABLE integers(i INTEGER, j INTEGER);\");\n-\tAppender appender(state->conn, \"integers\"); // insert the elements into the database\n-\tfor (size_t i = 0; i < POINT_QUERY_ROW_COUNT; i++) {\n-\t\tappender.BeginRow();\n-\t\tappender.Append<int32_t>(i);\n-\t\tappender.Append<int32_t>(i + 2);\n-\t\tappender.EndRow();\n-\t}\n-}\n-\n-virtual string GetQuery() {\n-\treturn \"SELECT j FROM integers WHERE i=\" + to_string(POINT_QUERY_ENTRY);\n-}\n-\n-virtual string VerifyResult(QueryResult *result) {\n-\tif (!result->success) {\n-\t\treturn result->error;\n-\t}\n-\tauto &materialized = (MaterializedQueryResult &)*result;\n-\tif (materialized.collection.count != 1) {\n-\t\treturn \"Incorrect amount of rows in result\";\n-\t}\n-\tif (materialized.names.size() != 1) {\n-\t\treturn \"Incorrect amount of columns\";\n-\t}\n-\tif (materialized.GetValue<int32_t>(0, 0) != POINT_QUERY_ENTRY + 2) {\n-\t\treturn \"Incorrect result returned, expected \" + to_string(POINT_QUERY_ENTRY + 2);\n-\t}\n-\treturn string();\n-}\n-\n-virtual string BenchmarkInfo() {\n-\treturn StringUtil::Format(\"Runs the following query: \\\"\" + GetQuery() + \"\\\" without an index\");\n-}\n-FINISH_BENCHMARK(PointQueryWithoutIndex)\n-\n-DUCKDB_BENCHMARK(PointQueryWithIndexART, \"[micro]\")\n-virtual void Load(DuckDBBenchmarkState *state) {\n-\tstate->conn.Query(\"CREATE TABLE integers(i INTEGER, j INTEGER);\");\n-\tAppender appender(state->conn, \"integers\"); // insert the elements into the database\n-\tfor (size_t i = 0; i < POINT_QUERY_ROW_COUNT; i++) {\n-\t\tappender.BeginRow();\n-\t\tappender.Append<int32_t>(i);\n-\t\tappender.Append<int32_t>(i + 2);\n-\t\tappender.EndRow();\n-\t}\n-\tappender.Close();\n-\tstate->conn.Query(\"CREATE INDEX i_index ON integers using art(i)\");\n-}\n-\n-virtual string GetQuery() {\n-\treturn \"SELECT j FROM integers WHERE i=\" + to_string(POINT_QUERY_ENTRY);\n-}\n-\n-virtual string VerifyResult(QueryResult *result) {\n-\tif (!result->success) {\n-\t\treturn result->error;\n-\t}\n-\tauto &materialized = (MaterializedQueryResult &)*result;\n-\tif (materialized.collection.count != 1) {\n-\t\treturn \"Incorrect amount of rows in result\";\n-\t}\n-\tif (materialized.names.size() != 1) {\n-\t\treturn \"Incorrect amount of columns\";\n-\t}\n-\tif (materialized.GetValue<int32_t>(0, 0) != POINT_QUERY_ENTRY + 2) {\n-\t\treturn \"Incorrect result returned, expected \" + to_string(POINT_QUERY_ENTRY + 2);\n-\t}\n-\treturn string();\n-}\n-\n-virtual string BenchmarkInfo() {\n-\treturn StringUtil::Format(\"Runs the following query: \\\"\" + GetQuery() + \"\\\" with an ART index\");\n-}\n-FINISH_BENCHMARK(PointQueryWithIndexART)\ndiff --git a/extension/parquet/parquet-extension.cpp b/extension/parquet/parquet-extension.cpp\nindex f3024df2c7f4..9065df20e782 100644\n--- a/extension/parquet/parquet-extension.cpp\n+++ b/extension/parquet/parquet-extension.cpp\n@@ -845,8 +845,9 @@ void ParquetScanFunctionData::ReadChunk(DataChunk &output) {\n class ParquetScanFunction : public TableFunction {\n public:\n \tParquetScanFunction()\n-\t    : TableFunction(\"parquet_scan\", {LogicalType::VARCHAR}, parquet_scan_bind, parquet_scan_function, nullptr) {\n-\t\tsupports_projection = true;\n+\t    : TableFunction(\"parquet_scan\", {LogicalType::VARCHAR}, parquet_scan_function, parquet_scan_bind,\n+\t                    parquet_scan_init) {\n+\t\tprojection_pushdown = true;\n \t}\n \n \tstatic unique_ptr<FunctionData> ReadParquetHeader(string file_name, vector<LogicalType> &return_types,\n@@ -988,6 +989,14 @@ class ParquetScanFunction : public TableFunction {\n \t\treturn ReadParquetHeader(file_name, return_types, names);\n \t}\n \n+\tstatic unique_ptr<FunctionOperatorData>\n+\tparquet_scan_init(ClientContext &context, const FunctionData *bind_data, OperatorTaskInfo *task_info,\n+\t                  vector<column_t> &column_ids, unordered_map<idx_t, vector<TableFilter>> &table_filters) {\n+\t\tauto &data = (ParquetScanFunctionData &)*bind_data;\n+\t\tdata.column_ids = column_ids;\n+\t\treturn nullptr;\n+\t}\n+\n \tstatic unique_ptr<GlobalFunctionData> parquet_read_initialize(ClientContext &context, FunctionData &fdata) {\n \t\treturn make_unique<GlobalFunctionData>();\n \t}\n@@ -998,9 +1007,9 @@ class ParquetScanFunction : public TableFunction {\n \t\tdata.ReadChunk(output);\n \t}\n \n-\tstatic void parquet_scan_function(ClientContext &context, vector<Value> &input, DataChunk &output,\n-\t                                  FunctionData *dataptr) {\n-\t\tauto &data = *((ParquetScanFunctionData *)dataptr);\n+\tstatic void parquet_scan_function(ClientContext &context, const FunctionData *bind_data,\n+\t                                  FunctionOperatorData *operator_state, DataChunk &output) {\n+\t\tauto &data = (ParquetScanFunctionData &)*bind_data;\n \t\tdata.ReadChunk(output);\n \t}\n };\ndiff --git a/extension/tpch/tpch-extension.cpp b/extension/tpch/tpch-extension.cpp\nindex 6fee2e881d77..5dc3e0b6e5e6 100644\n--- a/extension/tpch/tpch-extension.cpp\n+++ b/extension/tpch/tpch-extension.cpp\n@@ -41,8 +41,9 @@ static unique_ptr<FunctionData> dbgen_bind(ClientContext &context, vector<Value>\n \treturn move(result);\n }\n \n-static void dbgen_function(ClientContext &context, vector<Value> &input, DataChunk &output, FunctionData *dataptr) {\n-\tauto &data = ((DBGenFunctionData &)*dataptr);\n+static void dbgen_function(ClientContext &context, const FunctionData *bind_data, FunctionOperatorData *operator_state,\n+                           DataChunk &output) {\n+\tauto &data = (DBGenFunctionData &)*bind_data;\n \tif (data.finished) {\n \t\treturn;\n \t}\n@@ -60,7 +61,7 @@ void TPCHExtension::Load(DuckDB &db) {\n \tConnection con(db);\n \tcon.BeginTransaction();\n \n-\tTableFunction dbgen_func(\"dbgen\", {}, dbgen_bind, dbgen_function);\n+\tTableFunction dbgen_func(\"dbgen\", {}, dbgen_function, dbgen_bind);\n \tdbgen_func.named_parameters[\"sf\"] = LogicalType::DOUBLE;\n \tdbgen_func.named_parameters[\"overwrite\"] = LogicalType::BOOLEAN;\n \tdbgen_func.named_parameters[\"schema\"] = LogicalType::VARCHAR;\ndiff --git a/src/common/enums/logical_operator_type.cpp b/src/common/enums/logical_operator_type.cpp\nindex df49a93ce3ea..0db2fe735c96 100644\n--- a/src/common/enums/logical_operator_type.cpp\n+++ b/src/common/enums/logical_operator_type.cpp\n@@ -65,8 +65,8 @@ string LogicalOperatorToString(LogicalOperatorType type) {\n \t\treturn \"UPDATE\";\n \tcase LogicalOperatorType::PREPARE:\n \t\treturn \"PREPARE\";\n-\tcase LogicalOperatorType::TABLE_FUNCTION:\n-\t\treturn \"TABLE_FUNCTION\";\n+\tcase LogicalOperatorType::DUMMY_SCAN:\n+\t\treturn \"DUMMY_SCAN\";\n \tcase LogicalOperatorType::CREATE_INDEX:\n \t\treturn \"CREATE_INDEX\";\n \tcase LogicalOperatorType::CREATE_TABLE:\n@@ -77,8 +77,6 @@ string LogicalOperatorToString(LogicalOperatorType type) {\n \t\treturn \"EXECUTE\";\n \tcase LogicalOperatorType::VACUUM:\n \t\treturn \"VACUUM\";\n-\tcase LogicalOperatorType::INDEX_SCAN:\n-\t\treturn \"INDEX_SCAN\";\n \tcase LogicalOperatorType::RECURSIVE_CTE:\n \t\treturn \"REC_CTE\";\n \tcase LogicalOperatorType::CTE_REF:\ndiff --git a/src/common/enums/physical_operator_type.cpp b/src/common/enums/physical_operator_type.cpp\nindex 835b47999ce5..2caf45511585 100644\n--- a/src/common/enums/physical_operator_type.cpp\n+++ b/src/common/enums/physical_operator_type.cpp\n@@ -8,12 +8,10 @@ string PhysicalOperatorToString(PhysicalOperatorType type) {\n \tswitch (type) {\n \tcase PhysicalOperatorType::LEAF:\n \t\treturn \"LEAF\";\n+\tcase PhysicalOperatorType::TABLE_SCAN:\n+\t\treturn \"TABLE_SCAN\";\n \tcase PhysicalOperatorType::DUMMY_SCAN:\n \t\treturn \"DUMMY_SCAN\";\n-\tcase PhysicalOperatorType::SEQ_SCAN:\n-\t\treturn \"SEQ_SCAN\";\n-\tcase PhysicalOperatorType::INDEX_SCAN:\n-\t\treturn \"INDEX_SCAN\";\n \tcase PhysicalOperatorType::CHUNK_SCAN:\n \t\treturn \"CHUNK_SCAN\";\n \tcase PhysicalOperatorType::DELIM_SCAN:\n@@ -76,8 +74,6 @@ string PhysicalOperatorToString(PhysicalOperatorType type) {\n \t\treturn \"EXPORT_EXTERNAL_FILE\";\n \tcase PhysicalOperatorType::EMPTY_RESULT:\n \t\treturn \"EMPTY_RESULT\";\n-\tcase PhysicalOperatorType::TABLE_FUNCTION:\n-\t\treturn \"TABLE_FUNCTION\";\n \tcase PhysicalOperatorType::CREATE:\n \t\treturn \"CREATE\";\n \tcase PhysicalOperatorType::CREATE_INDEX:\ndiff --git a/src/execution/index/art/art.cpp b/src/execution/index/art/art.cpp\nindex f9b6687620eb..7fb36ea39443 100644\n--- a/src/execution/index/art/art.cpp\n+++ b/src/execution/index/art/art.cpp\n@@ -49,18 +49,18 @@ bool ART::LeafMatches(Node *node, Key &key, unsigned depth) {\n \treturn true;\n }\n \n-unique_ptr<IndexScanState> ART::InitializeScanSinglePredicate(Transaction &transaction, vector<column_t> column_ids,\n-                                                              Value value, ExpressionType expression_type) {\n-\tauto result = make_unique<ARTIndexScanState>(column_ids);\n+unique_ptr<IndexScanState> ART::InitializeScanSinglePredicate(Transaction &transaction, Value value,\n+                                                              ExpressionType expression_type) {\n+\tauto result = make_unique<ARTIndexScanState>();\n \tresult->values[0] = value;\n \tresult->expressions[0] = expression_type;\n \treturn move(result);\n }\n \n-unique_ptr<IndexScanState> ART::InitializeScanTwoPredicates(Transaction &transaction, vector<column_t> column_ids,\n-                                                            Value low_value, ExpressionType low_expression_type,\n-                                                            Value high_value, ExpressionType high_expression_type) {\n-\tauto result = make_unique<ARTIndexScanState>(column_ids);\n+unique_ptr<IndexScanState> ART::InitializeScanTwoPredicates(Transaction &transaction, Value low_value,\n+                                                            ExpressionType low_expression_type, Value high_value,\n+                                                            ExpressionType high_expression_type) {\n+\tauto result = make_unique<ARTIndexScanState>();\n \tresult->values[0] = low_value;\n \tresult->expressions[0] = low_expression_type;\n \tresult->values[1] = high_value;\n@@ -423,16 +423,20 @@ static unique_ptr<Key> CreateKey(ART &art, PhysicalType type, Value &value) {\n \t}\n }\n \n-void ART::SearchEqual(vector<row_t> &result_ids, ARTIndexScanState *state) {\n-\tunique_ptr<Key> key = CreateKey(*this, types[0], state->values[0]);\n+bool ART::SearchEqual(ARTIndexScanState *state, idx_t max_count, vector<row_t> &result_ids) {\n+\tauto key = CreateKey(*this, types[0], state->values[0]);\n \tauto leaf = static_cast<Leaf *>(Lookup(tree, *key, 0));\n \tif (!leaf) {\n-\t\treturn;\n+\t\treturn true;\n+\t}\n+\tif (leaf->num_elements > max_count) {\n+\t\treturn false;\n \t}\n \tfor (idx_t i = 0; i < leaf->num_elements; i++) {\n \t\trow_t row_id = leaf->GetRowId(i);\n \t\tresult_ids.push_back(row_id);\n \t}\n+\treturn true;\n }\n \n Node *ART::Lookup(unique_ptr<Node> &node, Key &key, unsigned depth) {\n@@ -475,7 +479,7 @@ Node *ART::Lookup(unique_ptr<Node> &node, Key &key, unsigned depth) {\n // Iterator scans\n //===--------------------------------------------------------------------===//\n template <bool HAS_BOUND, bool INCLUSIVE>\n-void ART::IteratorScan(ARTIndexScanState *state, Iterator *it, vector<row_t> &result_ids, Key *bound) {\n+bool ART::IteratorScan(ARTIndexScanState *state, Iterator *it, Key *bound, idx_t max_count, vector<row_t> &result_ids) {\n \tbool has_next;\n \tdo {\n \t\tif (HAS_BOUND) {\n@@ -490,12 +494,17 @@ void ART::IteratorScan(ARTIndexScanState *state, Iterator *it, vector<row_t> &re\n \t\t\t\t}\n \t\t\t}\n \t\t}\n+\t\tif (result_ids.size() + it->node->num_elements > max_count) {\n+\t\t\t// adding these elements would exceed the max count\n+\t\t\treturn false;\n+\t\t}\n \t\tfor (idx_t i = 0; i < it->node->num_elements; i++) {\n \t\t\trow_t row_id = it->node->GetRowId(i);\n \t\t\tresult_ids.push_back(row_id);\n \t\t}\n \t\thas_next = ART::IteratorNext(*it);\n \t} while (has_next);\n+\treturn true;\n }\n \n bool ART::IteratorNext(Iterator &it) {\n@@ -618,7 +627,7 @@ bool ART::Bound(unique_ptr<Node> &n, Key &key, Iterator &it, bool inclusive) {\n \t}\n }\n \n-void ART::SearchGreater(vector<row_t> &result_ids, ARTIndexScanState *state, bool inclusive) {\n+bool ART::SearchGreater(ARTIndexScanState *state, bool inclusive, idx_t max_count, vector<row_t> &result_ids) {\n \tIterator *it = &state->iterator;\n \tauto key = CreateKey(*this, types[0], state->values[0]);\n \n@@ -627,13 +636,13 @@ void ART::SearchGreater(vector<row_t> &result_ids, ARTIndexScanState *state, boo\n \tif (!it->start) {\n \t\tbool found = ART::Bound(tree, *key, *it, inclusive);\n \t\tif (!found) {\n-\t\t\treturn;\n+\t\t\treturn true;\n \t\t}\n \t\tit->start = true;\n \t}\n \t// after that we continue the scan; we don't need to check the bounds as any value following this value is\n \t// automatically bigger and hence satisfies our predicate\n-\tIteratorScan<false, false>(state, it, result_ids, nullptr);\n+\treturn IteratorScan<false, false>(state, it, nullptr, max_count, result_ids);\n }\n \n //===--------------------------------------------------------------------===//\n@@ -675,9 +684,9 @@ static Leaf &FindMinimum(Iterator &it, Node &node) {\n \treturn FindMinimum(it, *next);\n }\n \n-void ART::SearchLess(vector<row_t> &result_ids, ARTIndexScanState *state, bool inclusive) {\n+bool ART::SearchLess(ARTIndexScanState *state, bool inclusive, idx_t max_count, vector<row_t> &result_ids) {\n \tif (!tree) {\n-\t\treturn;\n+\t\treturn true;\n \t}\n \n \tIterator *it = &state->iterator;\n@@ -688,23 +697,23 @@ void ART::SearchLess(vector<row_t> &result_ids, ARTIndexScanState *state, bool i\n \t\tauto &minimum = FindMinimum(state->iterator, *tree);\n \t\t// early out min value higher than upper bound query\n \t\tif (*minimum.value > *upper_bound) {\n-\t\t\treturn;\n+\t\t\treturn true;\n \t\t}\n \t\tit->start = true;\n \t}\n \t// now continue the scan until we reach the upper bound\n \tif (inclusive) {\n-\t\tIteratorScan<true, true>(state, it, result_ids, upper_bound.get());\n+\t\treturn IteratorScan<true, true>(state, it, upper_bound.get(), max_count, result_ids);\n \t} else {\n-\t\tIteratorScan<true, false>(state, it, result_ids, upper_bound.get());\n+\t\treturn IteratorScan<true, false>(state, it, upper_bound.get(), max_count, result_ids);\n \t}\n }\n \n //===--------------------------------------------------------------------===//\n // Closed Range Query\n //===--------------------------------------------------------------------===//\n-void ART::SearchCloseRange(vector<row_t> &result_ids, ARTIndexScanState *state, bool left_inclusive,\n-                           bool right_inclusive) {\n+bool ART::SearchCloseRange(ARTIndexScanState *state, bool left_inclusive, bool right_inclusive, idx_t max_count,\n+                           vector<row_t> &result_ids) {\n \tauto lower_bound = CreateKey(*this, types[0], state->values[0]);\n \tauto upper_bound = CreateKey(*this, types[0], state->values[1]);\n \tIterator *it = &state->iterator;\n@@ -712,88 +721,74 @@ void ART::SearchCloseRange(vector<row_t> &result_ids, ARTIndexScanState *state,\n \tif (!it->start) {\n \t\tbool found = ART::Bound(tree, *lower_bound, *it, left_inclusive);\n \t\tif (!found) {\n-\t\t\treturn;\n+\t\t\treturn true;\n \t\t}\n \t\tit->start = true;\n \t}\n \t// now continue the scan until we reach the upper bound\n \tif (right_inclusive) {\n-\t\tIteratorScan<true, true>(state, it, result_ids, upper_bound.get());\n+\t\treturn IteratorScan<true, true>(state, it, upper_bound.get(), max_count, result_ids);\n \t} else {\n-\t\tIteratorScan<true, false>(state, it, result_ids, upper_bound.get());\n+\t\treturn IteratorScan<true, false>(state, it, upper_bound.get(), max_count, result_ids);\n \t}\n }\n \n-void ART::Scan(Transaction &transaction, DataTable &table, TableIndexScanState &table_state, DataChunk &result) {\n-\tauto state = (ARTIndexScanState *)table_state.index_state.get();\n-\n-\t// scan the index\n-\tif (!state->checked) {\n-\t\tvector<row_t> result_ids;\n-\t\tassert(state->values[0].type().InternalType() == types[0]);\n-\n-\t\tif (state->values[1].is_null) {\n-\t\t\tlock_guard<mutex> l(lock);\n-\t\t\t// single predicate\n-\t\t\tswitch (state->expressions[0]) {\n-\t\t\tcase ExpressionType::COMPARE_EQUAL:\n-\t\t\t\tSearchEqual(result_ids, state);\n-\t\t\t\tbreak;\n-\t\t\tcase ExpressionType::COMPARE_GREATERTHANOREQUALTO:\n-\t\t\t\tSearchGreater(result_ids, state, true);\n-\t\t\t\tbreak;\n-\t\t\tcase ExpressionType::COMPARE_GREATERTHAN:\n-\t\t\t\tSearchGreater(result_ids, state, false);\n-\t\t\t\tbreak;\n-\t\t\tcase ExpressionType::COMPARE_LESSTHANOREQUALTO:\n-\t\t\t\tSearchLess(result_ids, state, true);\n-\t\t\t\tbreak;\n-\t\t\tcase ExpressionType::COMPARE_LESSTHAN:\n-\t\t\t\tSearchLess(result_ids, state, false);\n-\t\t\t\tbreak;\n-\t\t\tdefault:\n-\t\t\t\tthrow NotImplementedException(\"Operation not implemented\");\n-\t\t\t}\n-\t\t} else {\n-\t\t\tlock_guard<mutex> l(lock);\n-\t\t\t// two predicates\n-\t\t\tassert(state->values[1].type().InternalType() == types[0]);\n-\t\t\tbool left_inclusive = state->expressions[0] == ExpressionType ::COMPARE_GREATERTHANOREQUALTO;\n-\t\t\tbool right_inclusive = state->expressions[1] == ExpressionType ::COMPARE_LESSTHANOREQUALTO;\n-\t\t\tSearchCloseRange(result_ids, state, left_inclusive, right_inclusive);\n-\t\t}\n-\t\tstate->checked = true;\n+bool ART::Scan(Transaction &transaction, DataTable &table, IndexScanState &table_state, idx_t max_count,\n+               vector<row_t> &result_ids) {\n+\tauto state = (ARTIndexScanState *)&table_state;\n \n-\t\tif (result_ids.size() == 0) {\n-\t\t\treturn;\n-\t\t}\n-\n-\t\t// sort the row ids\n-\t\tsort(result_ids.begin(), result_ids.end());\n-\t\t// duplicate eliminate the row ids and append them to the row ids of the state\n-\t\tstate->result_ids.reserve(result_ids.size());\n+\tassert(state->values[0].type().InternalType() == types[0]);\n \n-\t\tstate->result_ids.push_back(result_ids[0]);\n-\t\tfor (idx_t i = 1; i < result_ids.size(); i++) {\n-\t\t\tif (result_ids[i] != result_ids[i - 1]) {\n-\t\t\t\tstate->result_ids.push_back(result_ids[i]);\n-\t\t\t}\n+\tvector<row_t> row_ids;\n+\tbool success = true;\n+\tif (state->values[1].is_null) {\n+\t\tlock_guard<mutex> l(lock);\n+\t\t// single predicate\n+\t\tswitch (state->expressions[0]) {\n+\t\tcase ExpressionType::COMPARE_EQUAL:\n+\t\t\tsuccess = SearchEqual(state, max_count, row_ids);\n+\t\t\tbreak;\n+\t\tcase ExpressionType::COMPARE_GREATERTHANOREQUALTO:\n+\t\t\tsuccess = SearchGreater(state, true, max_count, row_ids);\n+\t\t\tbreak;\n+\t\tcase ExpressionType::COMPARE_GREATERTHAN:\n+\t\t\tsuccess = SearchGreater(state, false, max_count, row_ids);\n+\t\t\tbreak;\n+\t\tcase ExpressionType::COMPARE_LESSTHANOREQUALTO:\n+\t\t\tsuccess = SearchLess(state, true, max_count, row_ids);\n+\t\t\tbreak;\n+\t\tcase ExpressionType::COMPARE_LESSTHAN:\n+\t\t\tsuccess = SearchLess(state, false, max_count, row_ids);\n+\t\t\tbreak;\n+\t\tdefault:\n+\t\t\tthrow NotImplementedException(\"Operation not implemented\");\n \t\t}\n+\t} else {\n+\t\tlock_guard<mutex> l(lock);\n+\t\t// two predicates\n+\t\tassert(state->values[1].type().InternalType() == types[0]);\n+\t\tbool left_inclusive = state->expressions[0] == ExpressionType ::COMPARE_GREATERTHANOREQUALTO;\n+\t\tbool right_inclusive = state->expressions[1] == ExpressionType ::COMPARE_LESSTHANOREQUALTO;\n+\t\tsuccess = SearchCloseRange(state, left_inclusive, right_inclusive, max_count, row_ids);\n+\t}\n+\tif (!success) {\n+\t\treturn false;\n \t}\n-\n-\tif (state->result_index >= state->result_ids.size()) {\n-\t\t// exhausted all row ids\n-\t\treturn;\n+\tif (row_ids.size() == 0) {\n+\t\treturn true;\n \t}\n+\t// sort the row ids\n+\tsort(row_ids.begin(), row_ids.end());\n+\t// duplicate eliminate the row ids and append them to the row ids of the state\n+\tresult_ids.reserve(row_ids.size());\n \n-\t// create a vector pointing to the current set of row ids\n-\tVector row_identifiers(LOGICAL_ROW_TYPE, (data_ptr_t)&state->result_ids[state->result_index]);\n-\tidx_t scan_count = MinValue<idx_t>(STANDARD_VECTOR_SIZE, state->result_ids.size() - state->result_index);\n-\n-\t// fetch the actual values from the base table\n-\ttable.Fetch(transaction, result, state->column_ids, row_identifiers, scan_count, table_state);\n-\n-\t// move to the next set of row ids\n-\tstate->result_index += scan_count;\n+\tresult_ids.push_back(row_ids[0]);\n+\tfor (idx_t i = 1; i < row_ids.size(); i++) {\n+\t\tif (row_ids[i] != row_ids[i - 1]) {\n+\t\t\tresult_ids.push_back(row_ids[i]);\n+\t\t}\n+\t}\n+\treturn true;\n }\n+\n } // namespace duckdb\ndiff --git a/src/execution/operator/scan/CMakeLists.txt b/src/execution/operator/scan/CMakeLists.txt\nindex c278bd6ab9c4..bac1efb41958 100644\n--- a/src/execution/operator/scan/CMakeLists.txt\n+++ b/src/execution/operator/scan/CMakeLists.txt\n@@ -1,12 +1,11 @@\n-add_library_unity(duckdb_operator_scan\n-                  OBJECT\n-                  physical_chunk_scan.cpp\n-                  physical_dummy_scan.cpp\n-                  physical_empty_result.cpp\n-                  physical_expression_scan.cpp\n-                  physical_index_scan.cpp\n-                  physical_table_function.cpp\n-                  physical_table_scan.cpp)\n+add_library_unity(\n+  duckdb_operator_scan\n+  OBJECT\n+  physical_chunk_scan.cpp\n+  physical_dummy_scan.cpp\n+  physical_empty_result.cpp\n+  physical_expression_scan.cpp\n+  physical_table_scan.cpp)\n set(ALL_OBJECT_FILES\n     ${ALL_OBJECT_FILES} $<TARGET_OBJECTS:duckdb_operator_scan>\n     PARENT_SCOPE)\ndiff --git a/src/execution/operator/scan/physical_index_scan.cpp b/src/execution/operator/scan/physical_index_scan.cpp\ndeleted file mode 100644\nindex 76dd8d6e6a11..000000000000\n--- a/src/execution/operator/scan/physical_index_scan.cpp\n+++ /dev/null\n@@ -1,66 +0,0 @@\n-#include \"duckdb/execution/operator/scan/physical_index_scan.hpp\"\n-\n-#include \"duckdb/catalog/catalog_entry/table_catalog_entry.hpp\"\n-#include \"duckdb/transaction/transaction.hpp\"\n-\n-using namespace std;\n-\n-namespace duckdb {\n-\n-class PhysicalIndexScanOperatorState : public PhysicalOperatorState {\n-public:\n-\tPhysicalIndexScanOperatorState() : PhysicalOperatorState(nullptr), initialized(false) {\n-\t}\n-\n-\tbool initialized;\n-\tTableIndexScanState scan_state;\n-};\n-\n-void PhysicalIndexScan::GetChunkInternal(ExecutionContext &context, DataChunk &chunk, PhysicalOperatorState *state_) {\n-\tauto state = reinterpret_cast<PhysicalIndexScanOperatorState *>(state_);\n-\tif (column_ids.size() == 0) {\n-\t\treturn;\n-\t}\n-\n-\tauto &transaction = Transaction::GetTransaction(context.client);\n-\tif (!state->initialized) {\n-\t\t// initialize the scan state of the index\n-\t\tif (low_index && high_index) {\n-\t\t\t// two predicates\n-\t\t\ttable.InitializeIndexScan(transaction, state->scan_state, index, low_value, low_expression_type, high_value,\n-\t\t\t                          high_expression_type, column_ids);\n-\t\t} else {\n-\t\t\t// single predicate\n-\t\t\tValue value;\n-\t\t\tExpressionType type;\n-\t\t\tif (low_index) {\n-\t\t\t\t// > or >=\n-\t\t\t\tvalue = low_value;\n-\t\t\t\ttype = low_expression_type;\n-\t\t\t} else if (high_index) {\n-\t\t\t\t// < or <=\n-\t\t\t\tvalue = high_value;\n-\t\t\t\ttype = high_expression_type;\n-\t\t\t} else {\n-\t\t\t\t// equality\n-\t\t\t\tassert(equal_index);\n-\t\t\t\tvalue = equal_value;\n-\t\t\t\ttype = ExpressionType::COMPARE_EQUAL;\n-\t\t\t}\n-\t\t\ttable.InitializeIndexScan(transaction, state->scan_state, index, value, type, column_ids);\n-\t\t}\n-\t\tstate->initialized = true;\n-\t}\n-\t// scan the index\n-\ttable.IndexScan(transaction, chunk, state->scan_state);\n-}\n-\n-string PhysicalIndexScan::ExtraRenderInformation() const {\n-\treturn tableref.name + \"[\" + low_value.ToString() + \"]\";\n-}\n-\n-unique_ptr<PhysicalOperatorState> PhysicalIndexScan::GetOperatorState() {\n-\treturn make_unique<PhysicalIndexScanOperatorState>();\n-}\n-\n-} // namespace duckdb\ndiff --git a/src/execution/operator/scan/physical_table_function.cpp b/src/execution/operator/scan/physical_table_function.cpp\ndeleted file mode 100644\nindex 5525dc9e2585..000000000000\n--- a/src/execution/operator/scan/physical_table_function.cpp\n+++ /dev/null\n@@ -1,28 +0,0 @@\n-#include \"duckdb/execution/operator/scan/physical_table_function.hpp\"\n-\n-#include \"duckdb/catalog/catalog_entry/schema_catalog_entry.hpp\"\n-#include \"duckdb/catalog/catalog_entry/table_function_catalog_entry.hpp\"\n-#include \"duckdb/execution/expression_executor.hpp\"\n-#include \"duckdb/planner/expression/bound_function_expression.hpp\"\n-\n-using namespace std;\n-\n-namespace duckdb {\n-\n-void PhysicalTableFunction::GetChunkInternal(ExecutionContext &context, DataChunk &chunk,\n-                                             PhysicalOperatorState *state) {\n-\t// run main code\n-\tfunction.function(context.client, parameters, chunk, bind_data.get());\n-\tif (chunk.size() == 0) {\n-\t\t// finished, call clean up\n-\t\tif (function.final) {\n-\t\t\tfunction.final(context.client, bind_data.get());\n-\t\t}\n-\t}\n-}\n-\n-string PhysicalTableFunction::ExtraRenderInformation() const {\n-\treturn function.name;\n-}\n-\n-} // namespace duckdb\ndiff --git a/src/execution/operator/scan/physical_table_scan.cpp b/src/execution/operator/scan/physical_table_scan.cpp\nindex c972f629a0ed..e659f072aba8 100644\n--- a/src/execution/operator/scan/physical_table_scan.cpp\n+++ b/src/execution/operator/scan/physical_table_scan.cpp\n@@ -14,87 +14,65 @@ namespace duckdb {\n \n class PhysicalTableScanOperatorState : public PhysicalOperatorState {\n public:\n-\tPhysicalTableScanOperatorState(Expression &expr)\n-\t    : PhysicalOperatorState(nullptr), initialized(false), executor(expr) {\n-\t}\n \tPhysicalTableScanOperatorState() : PhysicalOperatorState(nullptr), initialized(false) {\n \t}\n+\n+\tunique_ptr<FunctionOperatorData> operator_data;\n \t//! Whether or not the scan has been initialized\n \tbool initialized;\n-\t//! The current position in the scan\n-\tTableScanState scan_state;\n-\t//! Execute filters inside the table\n-\tExpressionExecutor executor;\n };\n \n-PhysicalTableScan::PhysicalTableScan(vector<LogicalType> types, TableCatalogEntry &tableref, DataTable &table,\n-                                     vector<column_t> column_ids, vector<unique_ptr<Expression>> filter,\n+PhysicalTableScan::PhysicalTableScan(vector<LogicalType> types, TableFunction function_,\n+                                     unique_ptr<FunctionData> bind_data_, vector<column_t> column_ids,\n                                      unordered_map<idx_t, vector<TableFilter>> table_filters)\n-    : PhysicalOperator(PhysicalOperatorType::SEQ_SCAN, move(types)), tableref(tableref), table(table),\n-      column_ids(move(column_ids)), table_filters(move(table_filters)) {\n-\tif (filter.size() > 1) {\n-\t\t//! create a big AND out of the expressions\n-\t\tauto conjunction = make_unique<BoundConjunctionExpression>(ExpressionType::CONJUNCTION_AND);\n-\t\tfor (auto &expr : filter) {\n-\t\t\tconjunction->children.push_back(move(expr));\n-\t\t}\n-\t\texpression = move(conjunction);\n-\t} else if (filter.size() == 1) {\n-\t\texpression = move(filter[0]);\n-\t}\n+    : PhysicalOperator(PhysicalOperatorType::TABLE_SCAN, move(types)), function(move(function_)),\n+      bind_data(move(bind_data_)), column_ids(move(column_ids)), table_filters(move(table_filters)) {\n }\n \n-class TableScanTaskInfo : public OperatorTaskInfo {\n-public:\n-\tTableScanState state;\n-};\n-\n void PhysicalTableScan::ParallelScanInfo(ClientContext &context,\n                                          std::function<void(unique_ptr<OperatorTaskInfo>)> callback) {\n \t// generate parallel scans\n-\ttable.InitializeParallelScan(context, column_ids, &table_filters, [&](TableScanState state) {\n-\t\tauto task = make_unique<TableScanTaskInfo>();\n-\t\ttask->state = move(state);\n-\t\tcallback(move(task));\n-\t});\n+\tif (function.parallel_tasks) {\n+\t\tfunction.parallel_tasks(context, bind_data.get(), column_ids, table_filters, callback);\n+\t}\n }\n \n void PhysicalTableScan::GetChunkInternal(ExecutionContext &context, DataChunk &chunk, PhysicalOperatorState *state_) {\n-\tauto state = reinterpret_cast<PhysicalTableScanOperatorState *>(state_);\n+\tauto &state = (PhysicalTableScanOperatorState &)*state_;\n \tif (column_ids.empty()) {\n \t\treturn;\n \t}\n-\tauto &transaction = Transaction::GetTransaction(context.client);\n-\tif (!state->initialized) {\n-\t\tauto &task = context.task;\n-\t\tauto task_info = task.task_info.find(this);\n-\t\tif (task_info != task.task_info.end()) {\n-\t\t\t// task specific limitations: scan the part indicated by the task\n-\t\t\tauto &info = (TableScanTaskInfo &)*task_info->second;\n-\t\t\tstate->scan_state = move(info.state);\n-\t\t} else {\n-\t\t\t// no task specific limitations for the scan: scan the entire table\n-\t\t\ttable.InitializeScan(transaction, state->scan_state, column_ids, &table_filters);\n+\tif (!state.initialized) {\n+\t\tif (function.init) {\n+\t\t\tauto &task = context.task;\n+\t\t\tauto task_info = task.task_info.find(this);\n+\t\t\tif (task_info != task.task_info.end()) {\n+\t\t\t\t// task specific limitations: pass the task information to the init function\n+\t\t\t\tstate.operator_data =\n+\t\t\t\t    function.init(context.client, bind_data.get(), task_info->second.get(), column_ids, table_filters);\n+\t\t\t} else {\n+\t\t\t\t// no task specific limitations\n+\t\t\t\tstate.operator_data =\n+\t\t\t\t    function.init(context.client, bind_data.get(), nullptr, column_ids, table_filters);\n+\t\t\t}\n \t\t}\n-\t\tstate->initialized = true;\n+\t\tstate.initialized = true;\n+\t}\n+\tfunction.function(context.client, bind_data.get(), state.operator_data.get(), chunk);\n+\tif (chunk.size() == 0 && function.cleanup) {\n+\t\tfunction.cleanup(context.client, bind_data.get(), state.operator_data.get());\n \t}\n-\ttable.Scan(transaction, chunk, state->scan_state, column_ids, table_filters);\n }\n \n-string PhysicalTableScan::ExtraRenderInformation() const {\n-\tif (expression) {\n-\t\treturn tableref.name + \" \" + expression->ToString();\n-\t} else {\n-\t\treturn tableref.name;\n+string PhysicalTableScan::ToString(idx_t depth) const {\n+\tif (function.to_string) {\n+\t\treturn string(depth * 4, ' ') + function.to_string(bind_data.get());\n \t}\n+\treturn PhysicalOperator::ToString(depth);\n }\n \n unique_ptr<PhysicalOperatorState> PhysicalTableScan::GetOperatorState() {\n-\tif (expression) {\n-\t\treturn make_unique<PhysicalTableScanOperatorState>(*expression);\n-\t} else {\n-\t\treturn make_unique<PhysicalTableScanOperatorState>();\n-\t}\n+\treturn make_unique<PhysicalTableScanOperatorState>();\n }\n \n } // namespace duckdb\ndiff --git a/src/execution/physical_plan/CMakeLists.txt b/src/execution/physical_plan/CMakeLists.txt\nindex 8b78a540aeba..41262888d9ec 100644\n--- a/src/execution/physical_plan/CMakeLists.txt\n+++ b/src/execution/physical_plan/CMakeLists.txt\n@@ -15,13 +15,13 @@ add_library_unity(\n   plan_delim_get.cpp\n   plan_delim_join.cpp\n   plan_distinct.cpp\n+  plan_dummy_scan.cpp\n   plan_empty_result.cpp\n   plan_execute.cpp\n   plan_explain.cpp\n   plan_export.cpp\n   plan_filter.cpp\n   plan_get.cpp\n-  plan_index_scan.cpp\n   plan_insert.cpp\n   plan_limit.cpp\n   plan_order.cpp\n@@ -30,7 +30,6 @@ add_library_unity(\n   plan_projection.cpp\n   plan_set_operation.cpp\n   plan_simple.cpp\n-  plan_table_function.cpp\n   plan_top_n.cpp\n   plan_update.cpp\n   plan_window.cpp\ndiff --git a/src/execution/physical_plan/plan_dummy_scan.cpp b/src/execution/physical_plan/plan_dummy_scan.cpp\nnew file mode 100644\nindex 000000000000..56fc4f209843\n--- /dev/null\n+++ b/src/execution/physical_plan/plan_dummy_scan.cpp\n@@ -0,0 +1,13 @@\n+#include \"duckdb/execution/operator/scan/physical_dummy_scan.hpp\"\n+#include \"duckdb/execution/physical_plan_generator.hpp\"\n+#include \"duckdb/planner/operator/logical_dummy_scan.hpp\"\n+\n+namespace duckdb {\n+using namespace std;\n+\n+unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalDummyScan &op) {\n+\tassert(op.children.size() == 0);\n+\treturn make_unique<PhysicalDummyScan>(op.types);\n+}\n+\n+} // namespace duckdb\ndiff --git a/src/execution/physical_plan/plan_get.cpp b/src/execution/physical_plan/plan_get.cpp\nindex c3eb801d831c..53b8bea9ecf3 100644\n--- a/src/execution/physical_plan/plan_get.cpp\n+++ b/src/execution/physical_plan/plan_get.cpp\n@@ -1,34 +1,82 @@\n-#include \"duckdb/execution/operator/scan/physical_dummy_scan.hpp\"\n+#include \"duckdb/execution/operator/projection/physical_projection.hpp\"\n #include \"duckdb/execution/operator/scan/physical_table_scan.hpp\"\n+#include \"duckdb/planner/expression/bound_constant_expression.hpp\"\n+#include \"duckdb/planner/expression/bound_reference_expression.hpp\"\n #include \"duckdb/execution/physical_plan_generator.hpp\"\n #include \"duckdb/planner/operator/logical_get.hpp\"\n+#include \"duckdb/function/table/table_scan.hpp\"\n \n namespace duckdb {\n using namespace std;\n \n unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalGet &op) {\n \tassert(op.children.empty());\n+\n+\t// create the table filter map\n \tunordered_map<idx_t, vector<TableFilter>> table_filter_umap;\n-\tif (!op.table) {\n-\t\treturn make_unique<PhysicalDummyScan>(op.types);\n-\t} else {\n-\t\tfor (auto &tableFilter : op.tableFilters) {\n+\tfor (auto &tableFilter : op.tableFilters) {\n+\t\t// find the relative column index from the absolute column index into the table\n+\t\tidx_t column_index = INVALID_INDEX;\n+\t\tfor (idx_t i = 0; i < op.column_ids.size(); i++) {\n+\t\t\tif (tableFilter.column_index == op.column_ids[i]) {\n+\t\t\t\tcolumn_index = i;\n+\t\t\t\tbreak;\n+\t\t\t}\n+\t\t}\n+\t\tif (column_index == INVALID_INDEX) {\n+\t\t\tthrow InternalException(\"Could not find column index for table filter\");\n+\t\t}\n+\t\ttableFilter.column_index = column_index;\n+\t\tauto filter = table_filter_umap.find(column_index);\n+\t\tif (filter != table_filter_umap.end()) {\n+\t\t\tfilter->second.push_back(tableFilter);\n+\t\t} else {\n+\t\t\ttable_filter_umap.insert(make_pair(column_index, vector<TableFilter>{tableFilter}));\n+\t\t}\n+\t}\n+\n+\tif (op.function.dependency) {\n+\t\top.function.dependency(dependencies, op.bind_data.get());\n+\t}\n+\t// create the table scan node\n+\tif (!op.function.projection_pushdown) {\n+\t\t// function does not support projection pushdown\n+\t\tauto node = make_unique<PhysicalTableScan>(op.returned_types, op.function, move(op.bind_data), op.column_ids,\n+\t\t                                           move(table_filter_umap));\n+\t\t// first check if an additional projection is necessary\n+\t\tif (op.column_ids.size() == op.returned_types.size()) {\n+\t\t\tbool projection_necessary = false;\n \t\t\tfor (idx_t i = 0; i < op.column_ids.size(); i++) {\n-\t\t\t\tif (tableFilter.column_index == op.column_ids[i]) {\n-\t\t\t\t\ttableFilter.column_index = i;\n-\t\t\t\t\tauto filter = table_filter_umap.find(i);\n-\t\t\t\t\tif (filter != table_filter_umap.end()) {\n-\t\t\t\t\t\tfilter->second.push_back(tableFilter);\n-\t\t\t\t\t} else {\n-\t\t\t\t\t\ttable_filter_umap.insert(make_pair(i, vector<TableFilter>{tableFilter}));\n-\t\t\t\t\t}\n+\t\t\t\tif (op.column_ids[i] != i) {\n+\t\t\t\t\tprojection_necessary = true;\n \t\t\t\t\tbreak;\n \t\t\t\t}\n \t\t\t}\n+\t\t\tif (!projection_necessary) {\n+\t\t\t\t// a projection is not necessary if all columns have been requested in-order\n+\t\t\t\t// in that case we just return the node\n+\t\t\t\treturn move(node);\n+\t\t\t}\n \t\t}\n-\t\tdependencies.insert(op.table);\n-\t\treturn make_unique<PhysicalTableScan>(op.types, *op.table, *op.table->storage, op.column_ids,\n-\t\t                                      move(op.expressions), move(table_filter_umap));\n+\t\t// push a projection on top that does the projection\n+\t\tvector<LogicalType> types;\n+\t\tvector<unique_ptr<Expression>> expressions;\n+\t\tfor (auto &column_id : op.column_ids) {\n+\t\t\tif (column_id == COLUMN_IDENTIFIER_ROW_ID) {\n+\t\t\t\ttypes.push_back(LogicalType::BIGINT);\n+\t\t\t\texpressions.push_back(make_unique<BoundConstantExpression>(Value::BIGINT(0)));\n+\t\t\t} else {\n+\t\t\t\tauto type = op.returned_types[column_id];\n+\t\t\t\ttypes.push_back(type);\n+\t\t\t\texpressions.push_back(make_unique<BoundReferenceExpression>(type, column_id));\n+\t\t\t}\n+\t\t}\n+\t\tauto projection = make_unique<PhysicalProjection>(move(types), move(expressions));\n+\t\tprojection->children.push_back(move(node));\n+\t\treturn move(projection);\n+\t} else {\n+\t\treturn make_unique<PhysicalTableScan>(op.types, op.function, move(op.bind_data), op.column_ids,\n+\t\t                                      move(table_filter_umap));\n \t}\n }\n \ndiff --git a/src/execution/physical_plan/plan_index_scan.cpp b/src/execution/physical_plan/plan_index_scan.cpp\ndeleted file mode 100644\nindex 4cdc95b80964..000000000000\n--- a/src/execution/physical_plan/plan_index_scan.cpp\n+++ /dev/null\n@@ -1,30 +0,0 @@\n-#include \"duckdb/execution/operator/scan/physical_index_scan.hpp\"\n-#include \"duckdb/execution/physical_plan_generator.hpp\"\n-\n-#include \"duckdb/planner/operator/logical_index_scan.hpp\"\n-\n-namespace duckdb {\n-using namespace std;\n-\n-unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalIndexScan &op) {\n-\tunique_ptr<PhysicalOperator> plan;\n-\tauto node = make_unique<PhysicalIndexScan>(op, op.tableref, op.table, op.index, op.column_ids);\n-\tif (op.equal_index) {\n-\t\tnode->equal_value = op.equal_value;\n-\t\tnode->equal_index = true;\n-\t}\n-\tif (op.low_index) {\n-\t\tnode->low_value = op.low_value;\n-\t\tnode->low_index = true;\n-\t\tnode->low_expression_type = op.low_expression_type;\n-\t}\n-\tif (op.high_index) {\n-\t\tnode->high_value = op.high_value;\n-\t\tnode->high_index = true;\n-\t\tnode->high_expression_type = op.high_expression_type;\n-\t}\n-\tplan = move(node);\n-\treturn plan;\n-}\n-\n-} // namespace duckdb\ndiff --git a/src/execution/physical_plan/plan_table_function.cpp b/src/execution/physical_plan/plan_table_function.cpp\ndeleted file mode 100644\nindex 11b01adc9fbb..000000000000\n--- a/src/execution/physical_plan/plan_table_function.cpp\n+++ /dev/null\n@@ -1,18 +0,0 @@\n-#include \"duckdb/execution/operator/scan/physical_table_function.hpp\"\n-#include \"duckdb/execution/physical_plan_generator.hpp\"\n-#include \"duckdb/planner/operator/logical_table_function.hpp\"\n-\n-namespace duckdb {\n-using namespace std;\n-\n-unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalTableFunction &op) {\n-\tassert(op.children.size() == 0);\n-\n-\tauto tfd = (TableFunctionData *)op.bind_data.get();\n-\tassert(tfd);\n-\t// pass on bound column ids into the bind data so the function scan can see them\n-\ttfd->column_ids = op.column_ids;\n-\treturn make_unique<PhysicalTableFunction>(op.types, op.function, move(op.bind_data), move(op.parameters));\n-}\n-\n-} // namespace duckdb\ndiff --git a/src/execution/physical_plan_generator.cpp b/src/execution/physical_plan_generator.cpp\nindex 5523366dfcc1..f396bc5ef161 100644\n--- a/src/execution/physical_plan_generator.cpp\n+++ b/src/execution/physical_plan_generator.cpp\n@@ -75,8 +75,8 @@ unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalOperator &\n \t\treturn CreatePlan((LogicalCopyFromFile &)op);\n \tcase LogicalOperatorType::COPY_TO_FILE:\n \t\treturn CreatePlan((LogicalCopyToFile &)op);\n-\tcase LogicalOperatorType::TABLE_FUNCTION:\n-\t\treturn CreatePlan((LogicalTableFunction &)op);\n+\tcase LogicalOperatorType::DUMMY_SCAN:\n+\t\treturn CreatePlan((LogicalDummyScan &)op);\n \tcase LogicalOperatorType::ANY_JOIN:\n \t\treturn CreatePlan((LogicalAnyJoin &)op);\n \tcase LogicalOperatorType::DELIM_JOIN:\n@@ -113,8 +113,6 @@ unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalOperator &\n \t\treturn CreatePlan((LogicalPrepare &)op);\n \tcase LogicalOperatorType::EXECUTE:\n \t\treturn CreatePlan((LogicalExecute &)op);\n-\tcase LogicalOperatorType::INDEX_SCAN:\n-\t\treturn CreatePlan((LogicalIndexScan &)op);\n \tcase LogicalOperatorType::CREATE_VIEW:\n \tcase LogicalOperatorType::CREATE_SEQUENCE:\n \tcase LogicalOperatorType::CREATE_SCHEMA:\ndiff --git a/src/function/table/CMakeLists.txt b/src/function/table/CMakeLists.txt\nindex d1ee5a1fca0f..f495772d86a6 100644\n--- a/src/function/table/CMakeLists.txt\n+++ b/src/function/table/CMakeLists.txt\n@@ -8,7 +8,8 @@ add_library_unity(\n   repeat.cpp\n   copy_csv.cpp\n   read_csv.cpp\n-  sqlite_functions.cpp)\n+  sqlite_functions.cpp\n+  table_scan.cpp)\n \n set(ALL_OBJECT_FILES\n     ${ALL_OBJECT_FILES} $<TARGET_OBJECTS:duckdb_func_table>\ndiff --git a/src/function/table/arrow.cpp b/src/function/table/arrow.cpp\nindex 2dc3bdcc25cb..8c60ccd0af6e 100644\n--- a/src/function/table/arrow.cpp\n+++ b/src/function/table/arrow.cpp\n@@ -20,6 +20,7 @@ struct ArrowScanFunctionData : public TableFunctionData {\n \tArrowArray current_chunk_root;\n \tidx_t chunk_idx = 0;\n \tidx_t chunk_offset = 0;\n+\tbool is_consumed = false;\n \n \tvoid ReleaseArray() {\n \t\tif (current_chunk_root.release) {\n@@ -118,11 +119,22 @@ static unique_ptr<FunctionData> arrow_scan_bind(ClientContext &context, vector<V\n \treturn move(res);\n }\n \n-static void arrow_scan_function(ClientContext &context, vector<Value> &input, DataChunk &output,\n-                                FunctionData *dataptr) {\n-\tauto &data = *((ArrowScanFunctionData *)dataptr);\n+static unique_ptr<FunctionOperatorData> arrow_scan_init(ClientContext &context, const FunctionData *bind_data,\n+                                                        OperatorTaskInfo *task_info, vector<column_t> &column_ids,\n+                                                        unordered_map<idx_t, vector<TableFilter>> &table_filters) {\n+\tauto &data = (ArrowScanFunctionData &)*bind_data;\n+\tif (data.is_consumed) {\n+\t\tthrow NotImplementedException(\"FIXME: Arrow streams can only be read once\");\n+\t}\n+\tdata.is_consumed = true;\n+\treturn nullptr;\n+}\n \n-\tif (!data.stream->release) { // no more chunks\n+static void arrow_scan_function(ClientContext &context, const FunctionData *bind_data,\n+                                FunctionOperatorData *operator_state, DataChunk &output) {\n+\tauto &data = (ArrowScanFunctionData &)*bind_data;\n+\tif (!data.stream->release) {\n+\t\t// no more chunks\n \t\treturn;\n \t}\n \n@@ -250,7 +262,7 @@ static void arrow_scan_function(ClientContext &context, vector<Value> &input, Da\n void ArrowTableFunction::RegisterFunction(BuiltinFunctions &set) {\n \tTableFunctionSet arrow(\"arrow_scan\");\n \n-\tarrow.AddFunction(TableFunction({LogicalType::POINTER}, arrow_scan_bind, arrow_scan_function));\n+\tarrow.AddFunction(TableFunction({LogicalType::POINTER}, arrow_scan_function, arrow_scan_bind, arrow_scan_init));\n \tset.AddFunction(arrow);\n }\n \ndiff --git a/src/function/table/range.cpp b/src/function/table/range.cpp\nindex 428bafe01cfe..89daf26d5532 100644\n--- a/src/function/table/range.cpp\n+++ b/src/function/table/range.cpp\n@@ -7,30 +7,30 @@ using namespace std;\n \n namespace duckdb {\n \n-struct RangeFunctionData : public TableFunctionData {\n-\tValue start;\n-\tValue end;\n-\tValue increment;\n-\tidx_t current_idx;\n+struct RangeFunctionBindData : public TableFunctionData {\n+\tint64_t start;\n+\tint64_t end;\n+\tint64_t increment;\n };\n \n+template <bool GENERATE_SERIES>\n static unique_ptr<FunctionData> range_function_bind(ClientContext &context, vector<Value> &inputs,\n                                                     unordered_map<string, Value> &named_parameters,\n                                                     vector<LogicalType> &return_types, vector<string> &names) {\n-\tauto result = make_unique<RangeFunctionData>();\n+\tauto result = make_unique<RangeFunctionBindData>();\n \tif (inputs.size() < 2) {\n \t\t// single argument: only the end is specified\n-\t\tresult->start = Value::BIGINT(0);\n-\t\tresult->end = inputs[0].CastAs(LogicalType::BIGINT);\n+\t\tresult->start = 0;\n+\t\tresult->end = inputs[0].GetValue<int64_t>();\n \t} else {\n \t\t// two arguments: first two arguments are start and end\n-\t\tresult->start = inputs[0].CastAs(LogicalType::BIGINT);\n-\t\tresult->end = inputs[1].CastAs(LogicalType::BIGINT);\n+\t\tresult->start = inputs[0].GetValue<int64_t>();\n+\t\tresult->end = inputs[1].GetValue<int64_t>();\n \t}\n \tif (inputs.size() < 3) {\n-\t\tresult->increment = Value::BIGINT(1);\n+\t\tresult->increment = 1;\n \t} else {\n-\t\tresult->increment = inputs[2].CastAs(LogicalType::BIGINT);\n+\t\tresult->increment = inputs[2].GetValue<int64_t>();\n \t}\n \tif (result->increment == 0) {\n \t\tthrow BinderException(\"interval cannot be 0!\");\n@@ -40,38 +40,81 @@ static unique_ptr<FunctionData> range_function_bind(ClientContext &context, vect\n \t} else if (result->start < result->end && result->increment < 0) {\n \t\tthrow BinderException(\"start is smaller than end, but increment is negative: cannot generate infinite series\");\n \t}\n-\tresult->current_idx = 0;\n \treturn_types.push_back(LogicalType::BIGINT);\n-\tnames.push_back(\"range\");\n+\tif (GENERATE_SERIES) {\n+\t\t// generate_series has inclusive bounds on the RHS\n+\t\tif (result->increment < 0) {\n+\t\t\tresult->end = result->end - 1;\n+\t\t} else {\n+\t\t\tresult->end = result->end + 1;\n+\t\t}\n+\t\tnames.push_back(\"generate_series\");\n+\t} else {\n+\t\tnames.push_back(\"range\");\n+\t}\n \treturn move(result);\n }\n \n-static void range_function(ClientContext &context, vector<Value> &input, DataChunk &output, FunctionData *dataptr) {\n-\tauto &data = ((RangeFunctionData &)*dataptr);\n-\tauto increment = data.increment.value_.bigint;\n-\tauto end = data.end.value_.bigint;\n-\tint64_t current_value = data.start.value_.bigint + (int64_t)increment * data.current_idx;\n+struct RangeFunctionState : public FunctionOperatorData {\n+\tRangeFunctionState() : current_idx(0) {\n+\t}\n+\n+\tint64_t current_idx;\n+};\n+\n+static unique_ptr<FunctionOperatorData> range_function_init(ClientContext &context, const FunctionData *bind_data,\n+                                                            OperatorTaskInfo *task_info, vector<column_t> &column_ids,\n+                                                            unordered_map<idx_t, vector<TableFilter>> &table_filters) {\n+\treturn make_unique<RangeFunctionState>();\n+}\n+\n+static void range_function(ClientContext &context, const FunctionData *bind_data_, FunctionOperatorData *state_,\n+                           DataChunk &output) {\n+\tauto &bind_data = (RangeFunctionBindData &)*bind_data_;\n+\tauto &state = (RangeFunctionState &)*state_;\n+\n+\tauto increment = bind_data.increment;\n+\tauto end = bind_data.end;\n+\tint64_t current_value = bind_data.start + (int64_t)increment * state.current_idx;\n \t// set the result vector as a sequence vector\n \toutput.data[0].Sequence(current_value, increment);\n-\tidx_t remaining = min<int64_t>((end - current_value) / increment, STANDARD_VECTOR_SIZE);\n+\tidx_t remaining = min<idx_t>((end - current_value) / increment, STANDARD_VECTOR_SIZE);\n \t// increment the index pointer by the remaining count\n-\tdata.current_idx += remaining;\n+\tstate.current_idx += remaining;\n \toutput.SetCardinality(remaining);\n }\n \n+idx_t range_cardinality(const FunctionData *bind_data_) {\n+\tauto &bind_data = (RangeFunctionBindData &)*bind_data_;\n+\treturn (bind_data.end - bind_data.start) / bind_data.increment;\n+}\n+\n void RangeTableFunction::RegisterFunction(BuiltinFunctions &set) {\n \tTableFunctionSet range(\"range\");\n \n \t// single argument range: (end) - implicit start = 0 and increment = 1\n-\trange.AddFunction(TableFunction({LogicalType::BIGINT}, range_function_bind, range_function));\n+\trange.AddFunction(TableFunction({LogicalType::BIGINT}, range_function, range_function_bind<false>,\n+\t                                range_function_init, nullptr, nullptr, nullptr, range_cardinality));\n \t// two arguments range: (start, end) - implicit increment = 1\n-\trange.AddFunction(TableFunction({LogicalType::BIGINT, LogicalType::BIGINT}, range_function_bind, range_function));\n+\trange.AddFunction(TableFunction({LogicalType::BIGINT, LogicalType::BIGINT}, range_function,\n+\t                                range_function_bind<false>, range_function_init, nullptr, nullptr, nullptr,\n+\t                                range_cardinality));\n \t// three arguments range: (start, end, increment)\n-\trange.AddFunction(TableFunction({LogicalType::BIGINT, LogicalType::BIGINT, LogicalType::BIGINT},\n-\t                                range_function_bind, range_function));\n-\tset.AddFunction(range);\n-\trange.name = \"generate_series\";\n+\trange.AddFunction(TableFunction({LogicalType::BIGINT, LogicalType::BIGINT, LogicalType::BIGINT}, range_function,\n+\t                                range_function_bind<false>, range_function_init, nullptr, nullptr, nullptr,\n+\t                                range_cardinality));\n \tset.AddFunction(range);\n+\t// generate_series: similar to range, but inclusive instead of exclusive bounds on the RHS\n+\tTableFunctionSet generate_series(\"generate_series\");\n+\tgenerate_series.AddFunction(TableFunction({LogicalType::BIGINT}, range_function, range_function_bind<true>,\n+\t                                          range_function_init, nullptr, nullptr, nullptr, range_cardinality));\n+\tgenerate_series.AddFunction(TableFunction({LogicalType::BIGINT, LogicalType::BIGINT}, range_function,\n+\t                                          range_function_bind<true>, range_function_init, nullptr, nullptr, nullptr,\n+\t                                          range_cardinality));\n+\tgenerate_series.AddFunction(TableFunction({LogicalType::BIGINT, LogicalType::BIGINT, LogicalType::BIGINT},\n+\t                                          range_function, range_function_bind<true>, range_function_init, nullptr,\n+\t                                          nullptr, nullptr, range_cardinality));\n+\tset.AddFunction(generate_series);\n }\n \n void BuiltinFunctions::RegisterTableFunctions() {\ndiff --git a/src/function/table/read_csv.cpp b/src/function/table/read_csv.cpp\nindex ff0e3b38f978..bf6dfc701e2a 100644\n--- a/src/function/table/read_csv.cpp\n+++ b/src/function/table/read_csv.cpp\n@@ -9,11 +9,13 @@ using namespace std;\n namespace duckdb {\n \n struct ReadCSVFunctionData : public TableFunctionData {\n-\tReadCSVFunctionData() {\n+\tReadCSVFunctionData() : is_consumed(false) {\n \t}\n \n \t//! The CSV reader\n \tunique_ptr<BufferedCSVReader> csv_reader;\n+\t//! Whether or not the CSV has already been read completely\n+\tbool is_consumed;\n };\n \n static unique_ptr<FunctionData> read_csv_bind(ClientContext &context, vector<Value> &inputs,\n@@ -102,6 +104,18 @@ static unique_ptr<FunctionData> read_csv_bind(ClientContext &context, vector<Val\n \treturn move(result);\n }\n \n+static unique_ptr<FunctionOperatorData> read_csv_init(ClientContext &context, const FunctionData *bind_data_,\n+                                                      OperatorTaskInfo *task_info, vector<column_t> &column_ids,\n+                                                      unordered_map<idx_t, vector<TableFilter>> &table_filters) {\n+\tauto &bind_data = (ReadCSVFunctionData &)*bind_data_;\n+\tif (bind_data.is_consumed) {\n+\t\tbind_data.csv_reader =\n+\t\t    make_unique<BufferedCSVReader>(context, bind_data.csv_reader->options, bind_data.csv_reader->sql_types);\n+\t}\n+\tbind_data.is_consumed = true;\n+\treturn nullptr;\n+}\n+\n static unique_ptr<FunctionData> read_csv_auto_bind(ClientContext &context, vector<Value> &inputs,\n                                                    unordered_map<string, Value> &named_parameters,\n                                                    vector<LogicalType> &return_types, vector<string> &names) {\n@@ -109,8 +123,9 @@ static unique_ptr<FunctionData> read_csv_auto_bind(ClientContext &context, vecto\n \treturn read_csv_bind(context, inputs, named_parameters, return_types, names);\n }\n \n-static void read_csv_info(ClientContext &context, vector<Value> &input, DataChunk &output, FunctionData *dataptr) {\n-\tauto &data = ((ReadCSVFunctionData &)*dataptr);\n+static void read_csv_function(ClientContext &context, const FunctionData *bind_data,\n+                              FunctionOperatorData *operator_state, DataChunk &output) {\n+\tauto &data = (ReadCSVFunctionData &)*bind_data;\n \tdata.csv_reader->ParseCSV(output);\n }\n \n@@ -130,15 +145,15 @@ static void add_named_parameters(TableFunction &table_function) {\n }\n \n void ReadCSVTableFunction::RegisterFunction(BuiltinFunctions &set) {\n-\tTableFunction read_csv_function =\n-\t    TableFunction(\"read_csv\", {LogicalType::VARCHAR}, read_csv_bind, read_csv_info, nullptr);\n-\tadd_named_parameters(read_csv_function);\n-\tset.AddFunction(read_csv_function);\n-\n-\tTableFunction read_csv_auto_function =\n-\t    TableFunction(\"read_csv_auto\", {LogicalType::VARCHAR}, read_csv_auto_bind, read_csv_info, nullptr);\n-\tadd_named_parameters(read_csv_auto_function);\n-\tset.AddFunction(read_csv_auto_function);\n+\n+\tTableFunction read_csv(\"read_csv\", {LogicalType::VARCHAR}, read_csv_function, read_csv_bind, read_csv_init);\n+\tadd_named_parameters(read_csv);\n+\tset.AddFunction(read_csv);\n+\n+\tTableFunction read_csv_auto(\"read_csv_auto\", {LogicalType::VARCHAR}, read_csv_function, read_csv_auto_bind,\n+\t                            read_csv_init);\n+\tadd_named_parameters(read_csv_auto);\n+\tset.AddFunction(read_csv_auto);\n }\n \n void BuiltinFunctions::RegisterReadFunctions() {\ndiff --git a/src/function/table/repeat.cpp b/src/function/table/repeat.cpp\nindex 75bfbb794436..63042d4cbce2 100644\n--- a/src/function/table/repeat.cpp\n+++ b/src/function/table/repeat.cpp\n@@ -6,32 +6,53 @@ using namespace std;\n namespace duckdb {\n \n struct RepeatFunctionData : public TableFunctionData {\n-\tRepeatFunctionData(idx_t target_count) : current_count(0), target_count(target_count) {\n+\tRepeatFunctionData(Value value, idx_t target_count) : value(move(value)), target_count(target_count) {\n \t}\n \n-\tidx_t current_count;\n+\tValue value;\n \tidx_t target_count;\n };\n \n+struct RepeatOperatorData : public FunctionOperatorData {\n+\tRepeatOperatorData() : current_count(0) {\n+\t}\n+\tidx_t current_count;\n+};\n+\n static unique_ptr<FunctionData> repeat_bind(ClientContext &context, vector<Value> &inputs,\n                                             unordered_map<string, Value> &named_parameters,\n                                             vector<LogicalType> &return_types, vector<string> &names) {\n \t// the repeat function returns the type of the first argument\n \treturn_types.push_back(inputs[0].type());\n \tnames.push_back(inputs[0].ToString());\n-\treturn make_unique<RepeatFunctionData>(inputs[1].GetValue<int64_t>());\n+\treturn make_unique<RepeatFunctionData>(inputs[0], inputs[1].GetValue<int64_t>());\n }\n \n-static void repeat_function(ClientContext &context, vector<Value> &input, DataChunk &output, FunctionData *dataptr) {\n-\tauto &repeat = (RepeatFunctionData &)*dataptr;\n-\tidx_t remaining = min<idx_t>(repeat.target_count - repeat.current_count, STANDARD_VECTOR_SIZE);\n-\toutput.data[0].Reference(input[0]);\n+static unique_ptr<FunctionOperatorData> repeat_init(ClientContext &context, const FunctionData *bind_data,\n+                                                    OperatorTaskInfo *task_info, vector<column_t> &column_ids,\n+                                                    unordered_map<idx_t, vector<TableFilter>> &table_filters) {\n+\treturn make_unique<RepeatOperatorData>();\n+}\n+\n+static void repeat_function(ClientContext &context, const FunctionData *bind_data_,\n+                            FunctionOperatorData *operator_state, DataChunk &output) {\n+\tauto &bind_data = (RepeatFunctionData &)*bind_data_;\n+\tauto &state = (RepeatOperatorData &)*operator_state;\n+\n+\tidx_t remaining = min<idx_t>(bind_data.target_count - state.current_count, STANDARD_VECTOR_SIZE);\n+\toutput.data[0].Reference(bind_data.value);\n \toutput.SetCardinality(remaining);\n-\trepeat.current_count += remaining;\n+\tstate.current_count += remaining;\n+}\n+\n+static idx_t repeat_cardinality(const FunctionData *bind_data_) {\n+\tauto &bind_data = (RepeatFunctionData &)*bind_data_;\n+\treturn bind_data.target_count;\n }\n \n void RepeatTableFunction::RegisterFunction(BuiltinFunctions &set) {\n-\tTableFunction repeat(\"repeat\", {LogicalType::ANY, LogicalType::BIGINT}, repeat_bind, repeat_function, nullptr);\n+\tTableFunction repeat(\"repeat\", {LogicalType::ANY, LogicalType::BIGINT}, repeat_function, repeat_bind, repeat_init,\n+\t                     nullptr, nullptr, nullptr, repeat_cardinality);\n \tset.AddFunction(repeat);\n }\n \ndiff --git a/src/function/table/sqlite/pragma_collations.cpp b/src/function/table/sqlite/pragma_collations.cpp\nindex 231165379f7d..5094cdb9b0a8 100644\n--- a/src/function/table/sqlite/pragma_collations.cpp\n+++ b/src/function/table/sqlite/pragma_collations.cpp\n@@ -10,12 +10,11 @@ using namespace std;\n \n namespace duckdb {\n \n-struct PragmaCollateData : public TableFunctionData {\n-\tPragmaCollateData() : initialized(false), offset(0) {\n+struct PragmaCollateData : public FunctionOperatorData {\n+\tPragmaCollateData() : offset(0) {\n \t}\n \n-\tbool initialized;\n-\tvector<CatalogEntry *> entries;\n+\tvector<string> entries;\n \tidx_t offset;\n };\n \n@@ -25,23 +24,26 @@ static unique_ptr<FunctionData> pragma_collate_bind(ClientContext &context, vect\n \tnames.push_back(\"collname\");\n \treturn_types.push_back(LogicalType::VARCHAR);\n \n-\treturn make_unique<PragmaCollateData>();\n+\treturn nullptr;\n }\n \n-static void pragma_collate_info(ClientContext &context, vector<Value> &input, DataChunk &output,\n-                                FunctionData *dataptr) {\n-\tauto &data = *((PragmaCollateData *)dataptr);\n-\tassert(input.size() == 0);\n-\tif (!data.initialized) {\n-\t\t// scan all the schemas\n-\t\tauto &transaction = Transaction::GetTransaction(context);\n-\t\tCatalog::GetCatalog(context).schemas->Scan(transaction, [&](CatalogEntry *entry) {\n-\t\t\tauto schema = (SchemaCatalogEntry *)entry;\n-\t\t\tschema->collations.Scan(transaction, [&](CatalogEntry *entry) { data.entries.push_back(entry); });\n-\t\t});\n-\t\tdata.initialized = true;\n-\t}\n+unique_ptr<FunctionOperatorData> pragma_collate_init(ClientContext &context, const FunctionData *bind_data,\n+                                                     OperatorTaskInfo *task_info, vector<column_t> &column_ids,\n+                                                     unordered_map<idx_t, vector<TableFilter>> &table_filters) {\n+\tauto result = make_unique<PragmaCollateData>();\n+\n+\tauto &transaction = Transaction::GetTransaction(context);\n+\tCatalog::GetCatalog(context).schemas->Scan(transaction, [&](CatalogEntry *entry) {\n+\t\tauto schema = (SchemaCatalogEntry *)entry;\n+\t\tschema->collations.Scan(transaction, [&](CatalogEntry *entry) { result->entries.push_back(entry->name); });\n+\t});\n \n+\treturn move(result);\n+}\n+\n+static void pragma_collate(ClientContext &context, const FunctionData *bind_data, FunctionOperatorData *operator_state,\n+                           DataChunk &output) {\n+\tauto &data = (PragmaCollateData &)*operator_state;\n \tif (data.offset >= data.entries.size()) {\n \t\t// finished returning values\n \t\treturn;\n@@ -50,16 +52,14 @@ static void pragma_collate_info(ClientContext &context, vector<Value> &input, Da\n \toutput.SetCardinality(next - data.offset);\n \tfor (idx_t i = data.offset; i < next; i++) {\n \t\tauto index = i - data.offset;\n-\t\tauto entry = (CollateCatalogEntry *)data.entries[i];\n-\n-\t\toutput.SetValue(0, index, Value(entry->name));\n+\t\toutput.SetValue(0, index, Value(data.entries[i]));\n \t}\n \n \tdata.offset = next;\n }\n \n void PragmaCollations::RegisterFunction(BuiltinFunctions &set) {\n-\tset.AddFunction(TableFunction(\"pragma_collations\", {}, pragma_collate_bind, pragma_collate_info, nullptr));\n+\tset.AddFunction(TableFunction(\"pragma_collations\", {}, pragma_collate, pragma_collate_bind, pragma_collate_init));\n }\n \n } // namespace duckdb\ndiff --git a/src/function/table/sqlite/pragma_database_list.cpp b/src/function/table/sqlite/pragma_database_list.cpp\nindex 8b960a0ec052..2b91da629bea 100644\n--- a/src/function/table/sqlite/pragma_database_list.cpp\n+++ b/src/function/table/sqlite/pragma_database_list.cpp\n@@ -6,7 +6,7 @@ using namespace std;\n \n namespace duckdb {\n \n-struct PragmaDatabaseListData : public TableFunctionData {\n+struct PragmaDatabaseListData : public FunctionOperatorData {\n \tPragmaDatabaseListData() : finished(false) {\n \t}\n \n@@ -25,12 +25,18 @@ static unique_ptr<FunctionData> pragma_database_list_bind(ClientContext &context\n \tnames.push_back(\"file\");\n \treturn_types.push_back(LogicalType::VARCHAR);\n \n-\t// initialize the function data structure\n+\treturn nullptr;\n+}\n+\n+unique_ptr<FunctionOperatorData> pragma_database_list_init(ClientContext &context, const FunctionData *bind_data,\n+                                                           OperatorTaskInfo *task_info, vector<column_t> &column_ids,\n+                                                           unordered_map<idx_t, vector<TableFilter>> &table_filters) {\n \treturn make_unique<PragmaDatabaseListData>();\n }\n \n-void pragma_database_list(ClientContext &context, vector<Value> &input, DataChunk &output, FunctionData *dataptr) {\n-\tauto &data = *((PragmaDatabaseListData *)dataptr);\n+void pragma_database_list(ClientContext &context, const FunctionData *bind_data, FunctionOperatorData *operator_state,\n+                          DataChunk &output) {\n+\tauto &data = (PragmaDatabaseListData &)*operator_state;\n \tif (data.finished) {\n \t\treturn;\n \t}\n@@ -44,8 +50,8 @@ void pragma_database_list(ClientContext &context, vector<Value> &input, DataChun\n }\n \n void PragmaDatabaseList::RegisterFunction(BuiltinFunctions &set) {\n-\tset.AddFunction(\n-\t    TableFunction(\"pragma_database_list\", {}, pragma_database_list_bind, pragma_database_list, nullptr));\n+\tset.AddFunction(TableFunction(\"pragma_database_list\", {}, pragma_database_list, pragma_database_list_bind,\n+\t                              pragma_database_list_init));\n }\n \n } // namespace duckdb\ndiff --git a/src/function/table/sqlite/pragma_table_info.cpp b/src/function/table/sqlite/pragma_table_info.cpp\nindex 349a3f7d3e3a..8534ab204137 100644\n--- a/src/function/table/sqlite/pragma_table_info.cpp\n+++ b/src/function/table/sqlite/pragma_table_info.cpp\n@@ -13,10 +13,15 @@ using namespace std;\n namespace duckdb {\n \n struct PragmaTableFunctionData : public TableFunctionData {\n-\tPragmaTableFunctionData() : entry(nullptr), offset(0) {\n+\tPragmaTableFunctionData(CatalogEntry *entry_) : entry(entry_) {\n \t}\n \n \tCatalogEntry *entry;\n+};\n+\n+struct PragmaTableOperatorData : public FunctionOperatorData {\n+\tPragmaTableOperatorData() : offset(0) {\n+\t}\n \tidx_t offset;\n };\n \n@@ -41,10 +46,23 @@ static unique_ptr<FunctionData> pragma_table_info_bind(ClientContext &context, v\n \tnames.push_back(\"pk\");\n \treturn_types.push_back(LogicalType::BOOLEAN);\n \n-\treturn make_unique<PragmaTableFunctionData>();\n+\tstring schema, table_name;\n+\tauto range_var = inputs[0].GetValue<string>();\n+\tCatalog::ParseRangeVar(range_var, schema, table_name);\n+\n+\t// look up the table name in the catalog\n+\tauto &catalog = Catalog::GetCatalog(context);\n+\tauto entry = catalog.GetEntry(context, CatalogType::TABLE_ENTRY, schema, table_name);\n+\treturn make_unique<PragmaTableFunctionData>(entry);\n }\n \n-static void pragma_table_info_table(PragmaTableFunctionData &data, TableCatalogEntry *table, DataChunk &output) {\n+unique_ptr<FunctionOperatorData> pragma_table_info_init(ClientContext &context, const FunctionData *bind_data,\n+                                                        OperatorTaskInfo *task_info, vector<column_t> &column_ids,\n+                                                        unordered_map<idx_t, vector<TableFilter>> &table_filters) {\n+\treturn make_unique<PragmaTableOperatorData>();\n+}\n+\n+static void pragma_table_info_table(PragmaTableOperatorData &data, TableCatalogEntry *table, DataChunk &output) {\n \tif (data.offset >= table->columns.size()) {\n \t\t// finished returning values\n \t\treturn;\n@@ -79,7 +97,7 @@ static void pragma_table_info_table(PragmaTableFunctionData &data, TableCatalogE\n \tdata.offset = next;\n }\n \n-static void pragma_table_info_view(PragmaTableFunctionData &data, ViewCatalogEntry *view, DataChunk &output) {\n+static void pragma_table_info_view(PragmaTableOperatorData &data, ViewCatalogEntry *view, DataChunk &output) {\n \tif (data.offset >= view->types.size()) {\n \t\t// finished returning values\n \t\treturn;\n@@ -111,26 +129,16 @@ static void pragma_table_info_view(PragmaTableFunctionData &data, ViewCatalogEnt\n \tdata.offset = next;\n }\n \n-static void pragma_table_info(ClientContext &context, vector<Value> &input, DataChunk &output, FunctionData *dataptr) {\n-\tauto &data = *((PragmaTableFunctionData *)dataptr);\n-\tif (!data.entry) {\n-\t\t// first call: load the entry from the catalog\n-\t\tassert(input.size() == 1);\n-\n-\t\tstring schema, table_name;\n-\t\tauto range_var = input[0].GetValue<string>();\n-\t\tCatalog::ParseRangeVar(range_var, schema, table_name);\n-\n-\t\t// look up the table name in the catalog\n-\t\tauto &catalog = Catalog::GetCatalog(context);\n-\t\tdata.entry = catalog.GetEntry(context, CatalogType::TABLE_ENTRY, schema, table_name);\n-\t}\n-\tswitch (data.entry->type) {\n+static void pragma_table_info(ClientContext &context, const FunctionData *bind_data_,\n+                              FunctionOperatorData *operator_state, DataChunk &output) {\n+\tauto &bind_data = (PragmaTableFunctionData &)*bind_data_;\n+\tauto &state = (PragmaTableOperatorData &)*operator_state;\n+\tswitch (bind_data.entry->type) {\n \tcase CatalogType::TABLE_ENTRY:\n-\t\tpragma_table_info_table(data, (TableCatalogEntry *)data.entry, output);\n+\t\tpragma_table_info_table(state, (TableCatalogEntry *)bind_data.entry, output);\n \t\tbreak;\n \tcase CatalogType::VIEW_ENTRY:\n-\t\tpragma_table_info_view(data, (ViewCatalogEntry *)data.entry, output);\n+\t\tpragma_table_info_view(state, (ViewCatalogEntry *)bind_data.entry, output);\n \t\tbreak;\n \tdefault:\n \t\tthrow NotImplementedException(\"Unimplemented catalog type for pragma_table_info\");\n@@ -138,8 +146,8 @@ static void pragma_table_info(ClientContext &context, vector<Value> &input, Data\n }\n \n void PragmaTableInfo::RegisterFunction(BuiltinFunctions &set) {\n-\tset.AddFunction(\n-\t    TableFunction(\"pragma_table_info\", {LogicalType::VARCHAR}, pragma_table_info_bind, pragma_table_info, nullptr));\n+\tset.AddFunction(TableFunction(\"pragma_table_info\", {LogicalType::VARCHAR}, pragma_table_info,\n+\t                              pragma_table_info_bind, pragma_table_info_init));\n }\n \n } // namespace duckdb\ndiff --git a/src/function/table/sqlite/sqlite_master.cpp b/src/function/table/sqlite/sqlite_master.cpp\nindex 84d932cee188..de8075ec2ecc 100644\n--- a/src/function/table/sqlite/sqlite_master.cpp\n+++ b/src/function/table/sqlite/sqlite_master.cpp\n@@ -12,11 +12,10 @@ using namespace std;\n \n namespace duckdb {\n \n-struct SQLiteMasterData : public TableFunctionData {\n-\tSQLiteMasterData() : initialized(false), offset(0) {\n+struct SQLiteMasterData : public FunctionOperatorData {\n+\tSQLiteMasterData() : offset(0) {\n \t}\n \n-\tbool initialized;\n \tvector<CatalogEntry *> entries;\n \tidx_t offset;\n };\n@@ -39,23 +38,27 @@ static unique_ptr<FunctionData> sqlite_master_bind(ClientContext &context, vecto\n \tnames.push_back(\"sql\");\n \treturn_types.push_back(LogicalType::VARCHAR);\n \n-\t// initialize the function data structure\n-\treturn make_unique<SQLiteMasterData>();\n+\treturn nullptr;\n }\n \n-void sqlite_master(ClientContext &context, vector<Value> &input, DataChunk &output, FunctionData *dataptr) {\n-\tauto &data = *((SQLiteMasterData *)dataptr);\n-\tassert(input.size() == 0);\n-\tif (!data.initialized) {\n-\t\t// scan all the schemas\n-\t\tauto &transaction = Transaction::GetTransaction(context);\n-\t\tCatalog::GetCatalog(context).schemas->Scan(transaction, [&](CatalogEntry *entry) {\n-\t\t\tauto schema = (SchemaCatalogEntry *)entry;\n-\t\t\tschema->tables.Scan(transaction, [&](CatalogEntry *entry) { data.entries.push_back(entry); });\n-\t\t});\n-\t\tdata.initialized = true;\n-\t}\n+unique_ptr<FunctionOperatorData> sqlite_master_init(ClientContext &context, const FunctionData *bind_data,\n+                                                    OperatorTaskInfo *task_info, vector<column_t> &column_ids,\n+                                                    unordered_map<idx_t, vector<TableFilter>> &table_filters) {\n+\tauto result = make_unique<SQLiteMasterData>();\n+\n+\t// scan all the schemas for tables and views and collect them\n+\tauto &transaction = Transaction::GetTransaction(context);\n+\tCatalog::GetCatalog(context).schemas->Scan(transaction, [&](CatalogEntry *entry) {\n+\t\tauto schema = (SchemaCatalogEntry *)entry;\n+\t\tschema->tables.Scan(transaction, [&](CatalogEntry *entry) { result->entries.push_back(entry); });\n+\t});\n+\n+\treturn move(result);\n+}\n \n+void sqlite_master(ClientContext &context, const FunctionData *bind_data, FunctionOperatorData *operator_state,\n+                   DataChunk &output) {\n+\tauto &data = (SQLiteMasterData &)*operator_state;\n \tif (data.offset >= data.entries.size()) {\n \t\t// finished returning values\n \t\treturn;\n@@ -102,7 +105,7 @@ void sqlite_master(ClientContext &context, vector<Value> &input, DataChunk &outp\n }\n \n void SQLiteMaster::RegisterFunction(BuiltinFunctions &set) {\n-\tset.AddFunction(TableFunction(\"sqlite_master\", {}, sqlite_master_bind, sqlite_master, nullptr));\n+\tset.AddFunction(TableFunction(\"sqlite_master\", {}, sqlite_master, sqlite_master_bind, sqlite_master_init));\n }\n \n } // namespace duckdb\ndiff --git a/src/function/table/sqlite_functions.cpp b/src/function/table/sqlite_functions.cpp\nindex 5a95c41663fa..9de75483aa25 100644\n--- a/src/function/table/sqlite_functions.cpp\n+++ b/src/function/table/sqlite_functions.cpp\n@@ -17,20 +17,20 @@ void BuiltinFunctions::RegisterSQLiteFunctions() {\n \tSQLiteMaster::RegisterFunction(*this);\n \tPragmaDatabaseList::RegisterFunction(*this);\n \n-\tCreateViewInfo info;\n-\tinfo.schema = DEFAULT_SCHEMA;\n-\tinfo.view_name = \"sqlite_master\";\n-\tinfo.on_conflict = OnCreateConflict::REPLACE;\n+\t// CreateViewInfo info;\n+\t// info.schema = DEFAULT_SCHEMA;\n+\t// info.view_name = \"sqlite_master\";\n+\t// info.on_conflict = OnCreateConflict::REPLACE;\n \n-\tauto select = make_unique<SelectNode>();\n-\tselect->select_list.push_back(make_unique<StarExpression>());\n-\tvector<unique_ptr<ParsedExpression>> children;\n+\t// auto select = make_unique<SelectNode>();\n+\t// select->select_list.push_back(make_unique<StarExpression>());\n+\t// vector<unique_ptr<ParsedExpression>> children;\n \n-\tauto function = make_unique<FunctionExpression>(DEFAULT_SCHEMA, \"sqlite_master\", children);\n-\tauto function_expr = make_unique<TableFunctionRef>();\n-\tfunction_expr->function = move(function);\n-\tselect->from_table = move(function_expr);\n-\tinfo.query = move(select);\n+\t// auto function = make_unique<FunctionExpression>(DEFAULT_SCHEMA, \"sqlite_master\", children);\n+\t// auto function_expr = make_unique<TableFunctionRef>();\n+\t// function_expr->function = move(function);\n+\t// select->from_table = move(function_expr);\n+\t// info.query = move(select);\n \t//\tcatalog.CreateView(transaction, &info);\n }\n \ndiff --git a/src/function/table/table_scan.cpp b/src/function/table/table_scan.cpp\nnew file mode 100644\nindex 000000000000..6c03ad98147d\n--- /dev/null\n+++ b/src/function/table/table_scan.cpp\n@@ -0,0 +1,288 @@\n+#include \"duckdb/function/table/table_scan.hpp\"\n+#include \"duckdb/catalog/catalog_entry/table_catalog_entry.hpp\"\n+\n+#include \"duckdb/parallel/task_context.hpp\"\n+#include \"duckdb/storage/data_table.hpp\"\n+#include \"duckdb/transaction/transaction.hpp\"\n+#include \"duckdb/transaction/local_storage.hpp\"\n+\n+#include \"duckdb/optimizer/matcher/expression_matcher.hpp\"\n+\n+#include \"duckdb/planner/expression/bound_between_expression.hpp\"\n+#include \"duckdb/planner/expression_iterator.hpp\"\n+#include \"duckdb/planner/operator/logical_get.hpp\"\n+\n+namespace duckdb {\n+\n+class TableScanTaskInfo : public OperatorTaskInfo {\n+public:\n+\tTableScanState state;\n+};\n+\n+struct TableScanOperatorData : public FunctionOperatorData {\n+\t//! The current position in the scan\n+\tTableScanState scan_state;\n+\tvector<column_t> column_ids;\n+\tunordered_map<idx_t, vector<TableFilter>> table_filters;\n+};\n+\n+struct IndexScanOperatorData : public FunctionOperatorData {\n+\tVector row_ids;\n+\tColumnFetchState fetch_state;\n+\tLocalScanState local_storage_state;\n+\tvector<column_t> column_ids;\n+\tbool finished;\n+};\n+\n+static unique_ptr<FunctionOperatorData> table_scan_init(ClientContext &context, const FunctionData *bind_data_,\n+                                                        OperatorTaskInfo *task_info, vector<column_t> &column_ids,\n+                                                        unordered_map<idx_t, vector<TableFilter>> &table_filters) {\n+\tauto result = make_unique<TableScanOperatorData>();\n+\tauto &transaction = Transaction::GetTransaction(context);\n+\tauto &bind_data = (const TableScanBindData &)*bind_data_;\n+\tresult->column_ids = column_ids;\n+\tresult->table_filters = table_filters;\n+\tif (task_info) {\n+\t\tauto &info = (TableScanTaskInfo &)*task_info;\n+\t\tresult->scan_state = move(info.state);\n+\t} else {\n+\t\tbind_data.table->storage->InitializeScan(transaction, result->scan_state, result->column_ids,\n+\t\t                                         &result->table_filters);\n+\t}\n+\treturn move(result);\n+}\n+\n+static void table_scan_function(ClientContext &context, const FunctionData *bind_data_,\n+                                FunctionOperatorData *operator_state, DataChunk &output) {\n+\tauto &bind_data = (const TableScanBindData &)*bind_data_;\n+\tauto &state = (TableScanOperatorData &)*operator_state;\n+\tauto &transaction = Transaction::GetTransaction(context);\n+\tbind_data.table->storage->Scan(transaction, output, state.scan_state, state.column_ids, state.table_filters);\n+}\n+\n+static unique_ptr<FunctionOperatorData> index_scan_init(ClientContext &context, const FunctionData *bind_data_,\n+                                                        OperatorTaskInfo *task_info, vector<column_t> &column_ids,\n+                                                        unordered_map<idx_t, vector<TableFilter>> &table_filters) {\n+\tauto result = make_unique<IndexScanOperatorData>();\n+\tauto &transaction = Transaction::GetTransaction(context);\n+\tauto &bind_data = (const TableScanBindData &)*bind_data_;\n+\tresult->column_ids = column_ids;\n+\tresult->row_ids.type = LOGICAL_ROW_TYPE;\n+\tFlatVector::SetData(result->row_ids, (data_ptr_t)&bind_data.result_ids[0]);\n+\ttransaction.storage.InitializeScan(bind_data.table->storage.get(), result->local_storage_state);\n+\n+\tresult->finished = false;\n+\treturn move(result);\n+}\n+\n+static void index_scan_function(ClientContext &context, const FunctionData *bind_data_,\n+                                FunctionOperatorData *operator_state, DataChunk &output) {\n+\tauto &bind_data = (const TableScanBindData &)*bind_data_;\n+\tauto &state = (IndexScanOperatorData &)*operator_state;\n+\tauto &transaction = Transaction::GetTransaction(context);\n+\tif (!state.finished) {\n+\t\tbind_data.table->storage->Fetch(transaction, output, state.column_ids, state.row_ids,\n+\t\t                                bind_data.result_ids.size(), state.fetch_state);\n+\t\tstate.finished = true;\n+\t}\n+\tif (output.size() == 0) {\n+\t\ttransaction.storage.Scan(state.local_storage_state, state.column_ids, output);\n+\t}\n+}\n+\n+void table_scan_parallel(ClientContext &context, const FunctionData *bind_data_, vector<column_t> &column_ids,\n+                         unordered_map<idx_t, vector<TableFilter>> &table_filters,\n+                         std::function<void(unique_ptr<OperatorTaskInfo>)> callback) {\n+\tauto &bind_data = (const TableScanBindData &)*bind_data_;\n+\tif (bind_data.is_index_scan) {\n+\t\t// don't need to parallelize index scans: we only fetch up to 1024 entries anyway...\n+\t\treturn;\n+\t}\n+\tbind_data.table->storage->InitializeParallelScan(context, column_ids, &table_filters, [&](TableScanState state) {\n+\t\tauto task = make_unique<TableScanTaskInfo>();\n+\t\ttask->state = move(state);\n+\t\tcallback(move(task));\n+\t});\n+}\n+\n+void table_scan_dependency(unordered_set<CatalogEntry *> &entries, const FunctionData *bind_data_) {\n+\tauto &bind_data = (const TableScanBindData &)*bind_data_;\n+\tentries.insert(bind_data.table);\n+}\n+\n+idx_t table_scan_cardinality(const FunctionData *bind_data_) {\n+\tauto &bind_data = (const TableScanBindData &)*bind_data_;\n+\treturn bind_data.table->storage->info->cardinality;\n+}\n+\n+static void RewriteIndexExpression(Index &index, LogicalGet &get, Expression &expr, bool &rewrite_possible) {\n+\tif (expr.type == ExpressionType::BOUND_COLUMN_REF) {\n+\t\tauto &bound_colref = (BoundColumnRefExpression &)expr;\n+\t\t// bound column ref: rewrite to fit in the current set of bound column ids\n+\t\tbound_colref.binding.table_index = get.table_index;\n+\t\tcolumn_t referenced_column = index.column_ids[bound_colref.binding.column_index];\n+\t\t// search for the referenced column in the set of column_ids\n+\t\tfor (idx_t i = 0; i < get.column_ids.size(); i++) {\n+\t\t\tif (get.column_ids[i] == referenced_column) {\n+\t\t\t\tbound_colref.binding.column_index = i;\n+\t\t\t\treturn;\n+\t\t\t}\n+\t\t}\n+\t\t// column id not found in bound columns in the LogicalGet: rewrite not possible\n+\t\trewrite_possible = false;\n+\t}\n+\tExpressionIterator::EnumerateChildren(\n+\t    expr, [&](Expression &child) { RewriteIndexExpression(index, get, child, rewrite_possible); });\n+}\n+\n+void table_scan_pushdown_complex_filter(ClientContext &context, LogicalGet &get, FunctionData *bind_data_,\n+                                        vector<unique_ptr<Expression>> &filters) {\n+\tauto &bind_data = (TableScanBindData &)*bind_data_;\n+\tauto table = bind_data.table;\n+\tauto &storage = *table->storage;\n+\n+\tif (bind_data.is_index_scan) {\n+\t\treturn;\n+\t}\n+\tif (filters.size() == 0 || storage.info->indexes.size() == 0) {\n+\t\t// no indexes or no filters: skip the pushdown\n+\t\treturn;\n+\t}\n+\t// check all the indexes\n+\tfor (size_t j = 0; j < storage.info->indexes.size(); j++) {\n+\t\tauto &index = storage.info->indexes[j];\n+\n+\t\t// first rewrite the index expression so the ColumnBindings align with the column bindings of the current table\n+\t\tif (index->unbound_expressions.size() > 1) {\n+\t\t\tcontinue;\n+\t\t}\n+\t\tauto index_expression = index->unbound_expressions[0]->Copy();\n+\t\tbool rewrite_possible = true;\n+\t\tRewriteIndexExpression(*index, get, *index_expression, rewrite_possible);\n+\t\tif (!rewrite_possible) {\n+\t\t\t// could not rewrite!\n+\t\t\tcontinue;\n+\t\t}\n+\n+\t\tValue low_value, high_value, equal_value;\n+\t\tExpressionType low_comparison_type, high_comparison_type;\n+\t\t// try to find a matching index for any of the filter expressions\n+\t\tfor (idx_t i = 0; i < filters.size(); i++) {\n+\t\t\tauto expr = filters[i].get();\n+\n+\t\t\t// create a matcher for a comparison with a constant\n+\t\t\tComparisonExpressionMatcher matcher;\n+\t\t\t// match on a comparison type\n+\t\t\tmatcher.expr_type = make_unique<ComparisonExpressionTypeMatcher>();\n+\t\t\t// match on a constant comparison with the indexed expression\n+\t\t\tmatcher.matchers.push_back(make_unique<ExpressionEqualityMatcher>(index_expression.get()));\n+\t\t\tmatcher.matchers.push_back(make_unique<ConstantExpressionMatcher>());\n+\n+\t\t\tmatcher.policy = SetMatcher::Policy::UNORDERED;\n+\n+\t\t\tvector<Expression *> bindings;\n+\t\t\tif (matcher.Match(expr, bindings)) {\n+\t\t\t\t// range or equality comparison with constant value\n+\t\t\t\t// we can use our index here\n+\t\t\t\t// bindings[0] = the expression\n+\t\t\t\t// bindings[1] = the index expression\n+\t\t\t\t// bindings[2] = the constant\n+\t\t\t\tauto comparison = (BoundComparisonExpression *)bindings[0];\n+\t\t\t\tassert(bindings[0]->GetExpressionClass() == ExpressionClass::BOUND_COMPARISON);\n+\t\t\t\tassert(bindings[2]->type == ExpressionType::VALUE_CONSTANT);\n+\n+\t\t\t\tauto constant_value = ((BoundConstantExpression *)bindings[2])->value;\n+\t\t\t\tauto comparison_type = comparison->type;\n+\t\t\t\tif (comparison->left->type == ExpressionType::VALUE_CONSTANT) {\n+\t\t\t\t\t// the expression is on the right side, we flip them around\n+\t\t\t\t\tcomparison_type = FlipComparisionExpression(comparison_type);\n+\t\t\t\t}\n+\t\t\t\tif (comparison_type == ExpressionType::COMPARE_EQUAL) {\n+\t\t\t\t\t// equality value\n+\t\t\t\t\t// equality overrides any other bounds so we just break here\n+\t\t\t\t\tequal_value = constant_value;\n+\t\t\t\t\tbreak;\n+\t\t\t\t} else if (comparison_type == ExpressionType::COMPARE_GREATERTHANOREQUALTO ||\n+\t\t\t\t           comparison_type == ExpressionType::COMPARE_GREATERTHAN) {\n+\t\t\t\t\t// greater than means this is a lower bound\n+\t\t\t\t\tlow_value = constant_value;\n+\t\t\t\t\tlow_comparison_type = comparison_type;\n+\t\t\t\t} else {\n+\t\t\t\t\t// smaller than means this is an upper bound\n+\t\t\t\t\thigh_value = constant_value;\n+\t\t\t\t\thigh_comparison_type = comparison_type;\n+\t\t\t\t}\n+\t\t\t} else if (expr->type == ExpressionType::COMPARE_BETWEEN) {\n+\t\t\t\t// BETWEEN expression\n+\t\t\t\tauto &between = (BoundBetweenExpression &)*expr;\n+\t\t\t\tif (!between.input->Equals(index_expression.get())) {\n+\t\t\t\t\t// expression doesn't match the current index expression\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tif (between.lower->type != ExpressionType::VALUE_CONSTANT ||\n+\t\t\t\t    between.upper->type != ExpressionType::VALUE_CONSTANT) {\n+\t\t\t\t\t// not a constant comparison\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tlow_value = ((BoundConstantExpression &)*between.lower).value;\n+\t\t\t\tlow_comparison_type = between.lower_inclusive ? ExpressionType::COMPARE_GREATERTHANOREQUALTO\n+\t\t\t\t                                              : ExpressionType::COMPARE_GREATERTHAN;\n+\t\t\t\thigh_value = ((BoundConstantExpression &)*between.upper).value;\n+\t\t\t\thigh_comparison_type = between.upper_inclusive ? ExpressionType::COMPARE_LESSTHANOREQUALTO\n+\t\t\t\t                                               : ExpressionType::COMPARE_LESSTHAN;\n+\t\t\t\tbreak;\n+\t\t\t}\n+\t\t}\n+\t\tif (!equal_value.is_null || !low_value.is_null || !high_value.is_null) {\n+\t\t\t// we can scan this index using this predicate: try a scan\n+\t\t\tauto &transaction = Transaction::GetTransaction(context);\n+\t\t\tunique_ptr<IndexScanState> index_state;\n+\t\t\tif (!equal_value.is_null) {\n+\t\t\t\t// equality predicate\n+\t\t\t\tindex_state =\n+\t\t\t\t    index->InitializeScanSinglePredicate(transaction, equal_value, ExpressionType::COMPARE_EQUAL);\n+\t\t\t} else if (!low_value.is_null && !high_value.is_null) {\n+\t\t\t\t// two-sided predicate\n+\t\t\t\tindex_state = index->InitializeScanTwoPredicates(transaction, low_value, low_comparison_type,\n+\t\t\t\t                                                 high_value, high_comparison_type);\n+\t\t\t} else if (!low_value.is_null) {\n+\t\t\t\t// less than predicate\n+\t\t\t\tindex_state = index->InitializeScanSinglePredicate(transaction, low_value, low_comparison_type);\n+\t\t\t} else {\n+\t\t\t\tassert(!high_value.is_null);\n+\t\t\t\tindex_state = index->InitializeScanSinglePredicate(transaction, high_value, high_comparison_type);\n+\t\t\t}\n+\t\t\tif (index->Scan(transaction, storage, *index_state, STANDARD_VECTOR_SIZE, bind_data.result_ids)) {\n+\t\t\t\t// use an index scan!\n+\t\t\t\tbind_data.is_index_scan = true;\n+\t\t\t\tget.function.init = index_scan_init;\n+\t\t\t\tget.function.function = index_scan_function;\n+\t\t\t\tget.function.filter_pushdown = false;\n+\t\t\t} else {\n+\t\t\t\tbind_data.result_ids.clear();\n+\t\t\t}\n+\t\t\treturn;\n+\t\t}\n+\t}\n+}\n+\n+string table_scan_to_string(const FunctionData *bind_data_) {\n+\tauto &bind_data = (const TableScanBindData &)*bind_data_;\n+\tstring result = \"SEQ_SCAN(\" + bind_data.table->name + \")\";\n+\treturn result;\n+}\n+\n+TableFunction TableScanFunction::GetFunction() {\n+\tTableFunction scan_function(\"seq_scan\", {}, table_scan_function);\n+\tscan_function.init = table_scan_init;\n+\tscan_function.parallel_tasks = table_scan_parallel;\n+\tscan_function.dependency = table_scan_dependency;\n+\tscan_function.cardinality = table_scan_cardinality;\n+\tscan_function.pushdown_complex_filter = table_scan_pushdown_complex_filter;\n+\tscan_function.to_string = table_scan_to_string;\n+\tscan_function.projection_pushdown = true;\n+\tscan_function.filter_pushdown = true;\n+\treturn scan_function;\n+}\n+\n+} // namespace duckdb\ndiff --git a/src/function/table/version/pragma_version.cpp b/src/function/table/version/pragma_version.cpp\nindex 225b7f020bc4..bf809cfb00a7 100644\n--- a/src/function/table/version/pragma_version.cpp\n+++ b/src/function/table/version/pragma_version.cpp\n@@ -3,10 +3,10 @@\n \n namespace duckdb {\n \n-struct PragmaVersionData : public TableFunctionData {\n-\tPragmaVersionData() : done(false) {\n+struct PragmaVersionData : public FunctionOperatorData {\n+\tPragmaVersionData() : finished(false) {\n \t}\n-\tbool done;\n+\tbool finished;\n };\n \n static unique_ptr<FunctionData> pragma_version_bind(ClientContext &context, vector<Value> &inputs,\n@@ -16,26 +16,30 @@ static unique_ptr<FunctionData> pragma_version_bind(ClientContext &context, vect\n \treturn_types.push_back(LogicalType::VARCHAR);\n \tnames.push_back(\"source_id\");\n \treturn_types.push_back(LogicalType::VARCHAR);\n+\treturn nullptr;\n+}\n \n+static unique_ptr<FunctionOperatorData> pragma_version_init(ClientContext &context, const FunctionData *bind_data,\n+                                                            OperatorTaskInfo *task_info, vector<column_t> &column_ids,\n+                                                            unordered_map<idx_t, vector<TableFilter>> &table_filters) {\n \treturn make_unique<PragmaVersionData>();\n }\n \n-static void pragma_version_info(ClientContext &context, vector<Value> &input, DataChunk &output,\n-                                FunctionData *dataptr) {\n-\tauto &data = *((PragmaVersionData *)dataptr);\n-\tassert(input.size() == 0);\n-\tif (data.done) {\n+static void pragma_version(ClientContext &context, const FunctionData *bind_data, FunctionOperatorData *operator_state,\n+                           DataChunk &output) {\n+\tauto &data = (PragmaVersionData &)*operator_state;\n+\tif (data.finished) {\n \t\t// finished returning values\n \t\treturn;\n \t}\n \toutput.SetCardinality(1);\n \toutput.SetValue(0, 0, DuckDB::LibraryVersion());\n \toutput.SetValue(1, 0, DuckDB::SourceID());\n-\tdata.done = true;\n+\tdata.finished = true;\n }\n \n void PragmaVersion::RegisterFunction(BuiltinFunctions &set) {\n-\tset.AddFunction(TableFunction(\"pragma_version\", {}, pragma_version_bind, pragma_version_info, nullptr));\n+\tset.AddFunction(TableFunction(\"pragma_version\", {}, pragma_version, pragma_version_bind, pragma_version_init));\n }\n \n const char *DuckDB::SourceID() {\ndiff --git a/src/include/duckdb/common/enums/logical_operator_type.hpp b/src/include/duckdb/common/enums/logical_operator_type.hpp\nindex 572d96c94487..b23559fa2ad0 100644\n--- a/src/include/duckdb/common/enums/logical_operator_type.hpp\n+++ b/src/include/duckdb/common/enums/logical_operator_type.hpp\n@@ -28,7 +28,7 @@ enum class LogicalOperatorType : uint8_t {\n \tCOPY_FROM_FILE = 9,\n \tCOPY_TO_FILE = 10,\n \tDISTINCT = 11,\n-\tINDEX_SCAN = 12,\n+\n \t// -----------------------------\n \t// Data sources\n \t// -----------------------------\n@@ -36,7 +36,7 @@ enum class LogicalOperatorType : uint8_t {\n \tCHUNK_GET = 26,\n \tDELIM_GET = 27,\n \tEXPRESSION_GET = 28,\n-\tTABLE_FUNCTION = 29,\n+\tDUMMY_SCAN = 29,\n \tEMPTY_RESULT = 30,\n \tCTE_REF = 31,\n \t// -----------------------------\ndiff --git a/src/include/duckdb/common/enums/physical_operator_type.hpp b/src/include/duckdb/common/enums/physical_operator_type.hpp\nindex 952bae1ffa1d..6c9a21ae7f82 100644\n--- a/src/include/duckdb/common/enums/physical_operator_type.hpp\n+++ b/src/include/duckdb/common/enums/physical_operator_type.hpp\n@@ -32,13 +32,11 @@ enum class PhysicalOperatorType : uint8_t {\n \tPROJECTION,\n \tCOPY_FROM_FILE,\n \tCOPY_TO_FILE,\n-\tTABLE_FUNCTION,\n \t// -----------------------------\n \t// Scans\n \t// -----------------------------\n+\tTABLE_SCAN,\n \tDUMMY_SCAN,\n-\tSEQ_SCAN,\n-\tINDEX_SCAN,\n \tCHUNK_SCAN,\n \tRECURSIVE_CTE_SCAN,\n \tDELIM_SCAN,\ndiff --git a/src/include/duckdb/execution/index/art/art.hpp b/src/include/duckdb/execution/index/art/art.hpp\nindex a867d0c75dd9..d37fbd53b1a3 100644\n--- a/src/include/duckdb/execution/index/art/art.hpp\n+++ b/src/include/duckdb/execution/index/art/art.hpp\n@@ -41,7 +41,7 @@ struct Iterator {\n };\n \n struct ARTIndexScanState : public IndexScanState {\n-\tARTIndexScanState(vector<column_t> column_ids) : IndexScanState(column_ids), checked(false), result_index(0) {\n+\tARTIndexScanState() : checked(false), result_index(0) {\n \t}\n \n \tValue values[2];\n@@ -67,18 +67,18 @@ class ART : public Index {\n public:\n \t//! Initialize a scan on the index with the given expression and column ids\n \t//! to fetch from the base table for a single predicate\n-\tunique_ptr<IndexScanState> InitializeScanSinglePredicate(Transaction &transaction, vector<column_t> column_ids,\n-\t                                                         Value value, ExpressionType expressionType) override;\n+\tunique_ptr<IndexScanState> InitializeScanSinglePredicate(Transaction &transaction, Value value,\n+\t                                                         ExpressionType expressionType) override;\n \n \t//! Initialize a scan on the index with the given expression and column ids\n \t//! to fetch from the base table for two predicates\n-\tunique_ptr<IndexScanState> InitializeScanTwoPredicates(Transaction &transaction, vector<column_t> column_ids,\n-\t                                                       Value low_value, ExpressionType low_expression_type,\n-\t                                                       Value high_value,\n+\tunique_ptr<IndexScanState> InitializeScanTwoPredicates(Transaction &transaction, Value low_value,\n+\t                                                       ExpressionType low_expression_type, Value high_value,\n \t                                                       ExpressionType high_expression_type) override;\n \n \t//! Perform a lookup on the index\n-\tvoid Scan(Transaction &transaction, DataTable &table, TableIndexScanState &state, DataChunk &result) override;\n+\tbool Scan(Transaction &transaction, DataTable &table, IndexScanState &state, idx_t max_count,\n+\t          vector<row_t> &result_ids) override;\n \t//! Append entries to the index\n \tbool Append(IndexLock &lock, DataChunk &entries, Vector &row_identifiers) override;\n \t//! Verify that data can be appended to the index\n@@ -113,15 +113,16 @@ class ART : public Index {\n \t//! Gets next node for range queries\n \tbool IteratorNext(Iterator &iter);\n \n-\tvoid SearchEqual(vector<row_t> &result_ids, ARTIndexScanState *state);\n-\tvoid SearchGreater(vector<row_t> &result_ids, ARTIndexScanState *state, bool inclusive);\n-\tvoid SearchLess(vector<row_t> &result_ids, ARTIndexScanState *state, bool inclusive);\n-\tvoid SearchCloseRange(vector<row_t> &result_ids, ARTIndexScanState *state, bool left_inclusive,\n-\t                      bool right_inclusive);\n+\tbool SearchEqual(ARTIndexScanState *state, idx_t max_count, vector<row_t> &result_ids);\n+\tbool SearchGreater(ARTIndexScanState *state, bool inclusive, idx_t max_count, vector<row_t> &result_ids);\n+\tbool SearchLess(ARTIndexScanState *state, bool inclusive, idx_t max_count, vector<row_t> &result_ids);\n+\tbool SearchCloseRange(ARTIndexScanState *state, bool left_inclusive, bool right_inclusive, idx_t max_count,\n+\t                      vector<row_t> &result_ids);\n \n private:\n \ttemplate <bool HAS_BOUND, bool INCLUSIVE>\n-\tvoid IteratorScan(ARTIndexScanState *state, Iterator *it, vector<row_t> &result_ids, Key *upper_bound);\n+\tbool IteratorScan(ARTIndexScanState *state, Iterator *it, Key *upper_bound, idx_t max_count,\n+\t                  vector<row_t> &result_ids);\n \n \tvoid GenerateKeys(DataChunk &input, vector<unique_ptr<Key>> &keys);\n };\ndiff --git a/src/include/duckdb/execution/operator/list.hpp b/src/include/duckdb/execution/operator/list.hpp\nindex 795ae844ecc6..2f9627616b15 100644\n--- a/src/include/duckdb/execution/operator/list.hpp\n+++ b/src/include/duckdb/execution/operator/list.hpp\n@@ -22,6 +22,7 @@\n #include \"duckdb/execution/operator/persistent/physical_copy_from_file.hpp\"\n #include \"duckdb/execution/operator/persistent/physical_copy_to_file.hpp\"\n #include \"duckdb/execution/operator/persistent/physical_delete.hpp\"\n+#include \"duckdb/execution/operator/persistent/physical_export.hpp\"\n #include \"duckdb/execution/operator/persistent/physical_insert.hpp\"\n #include \"duckdb/execution/operator/persistent/physical_update.hpp\"\n #include \"duckdb/execution/operator/projection/physical_projection.hpp\"\n@@ -30,8 +31,6 @@\n #include \"duckdb/execution/operator/scan/physical_dummy_scan.hpp\"\n #include \"duckdb/execution/operator/scan/physical_empty_result.hpp\"\n #include \"duckdb/execution/operator/scan/physical_expression_scan.hpp\"\n-#include \"duckdb/execution/operator/scan/physical_index_scan.hpp\"\n-#include \"duckdb/execution/operator/scan/physical_table_function.hpp\"\n #include \"duckdb/execution/operator/scan/physical_table_scan.hpp\"\n #include \"duckdb/execution/operator/schema/physical_alter.hpp\"\n #include \"duckdb/execution/operator/schema/physical_create_index.hpp\"\ndiff --git a/src/include/duckdb/execution/operator/scan/physical_index_scan.hpp b/src/include/duckdb/execution/operator/scan/physical_index_scan.hpp\ndeleted file mode 100644\nindex 7ebf6d8ebf9c..000000000000\n--- a/src/include/duckdb/execution/operator/scan/physical_index_scan.hpp\n+++ /dev/null\n@@ -1,55 +0,0 @@\n-//===----------------------------------------------------------------------===//\n-//                         DuckDB\n-//\n-// duckdb/execution/operator/scan/physical_index_scan.hpp\n-//\n-//\n-//===----------------------------------------------------------------------===//\n-\n-#pragma once\n-\n-#include \"duckdb/execution/physical_operator.hpp\"\n-#include \"duckdb/storage/data_table.hpp\"\n-#include \"duckdb/storage/index.hpp\"\n-\n-namespace duckdb {\n-\n-//! Represents a scan of an index\n-class PhysicalIndexScan : public PhysicalOperator {\n-public:\n-\tPhysicalIndexScan(LogicalOperator &op, TableCatalogEntry &tableref, DataTable &table, Index &index,\n-\t                  vector<column_t> column_ids)\n-\t    : PhysicalOperator(PhysicalOperatorType::INDEX_SCAN, op.types), tableref(tableref), table(table), index(index),\n-\t      column_ids(column_ids) {\n-\t}\n-\n-\t//! The table to scan\n-\tTableCatalogEntry &tableref;\n-\t//! The physical data table to scan\n-\tDataTable &table;\n-\t//! The index to use for the scan\n-\tIndex &index;\n-\t//! The column ids to project\n-\tvector<column_t> column_ids;\n-\n-\t//! The value for the query predicate\n-\tValue low_value;\n-\tValue high_value;\n-\tValue equal_value;\n-\n-\t//! If the predicate is low, high or equal\n-\tbool low_index = false;\n-\tbool high_index = false;\n-\tbool equal_index = false;\n-\n-\t//! The expression type (e.g., >, <, >=, <=)\n-\tExpressionType low_expression_type;\n-\tExpressionType high_expression_type;\n-\n-public:\n-\tvoid GetChunkInternal(ExecutionContext &context, DataChunk &chunk, PhysicalOperatorState *state) override;\n-\tstring ExtraRenderInformation() const override;\n-\tunique_ptr<PhysicalOperatorState> GetOperatorState() override;\n-};\n-\n-} // namespace duckdb\ndiff --git a/src/include/duckdb/execution/operator/scan/physical_table_function.hpp b/src/include/duckdb/execution/operator/scan/physical_table_function.hpp\ndeleted file mode 100644\nindex 2bb3316b515e..000000000000\n--- a/src/include/duckdb/execution/operator/scan/physical_table_function.hpp\n+++ /dev/null\n@@ -1,38 +0,0 @@\n-//===----------------------------------------------------------------------===//\n-//                         DuckDB\n-//\n-// duckdb/execution/operator/scan/physical_table_function.hpp\n-//\n-//\n-//===----------------------------------------------------------------------===//\n-\n-#pragma once\n-\n-#include \"duckdb/execution/physical_operator.hpp\"\n-#include \"duckdb/function/table_function.hpp\"\n-#include \"duckdb/storage/data_table.hpp\"\n-\n-namespace duckdb {\n-\n-//! Represents a scan of a base table\n-class PhysicalTableFunction : public PhysicalOperator {\n-public:\n-\tPhysicalTableFunction(vector<LogicalType> types, TableFunction function, unique_ptr<FunctionData> bind_data,\n-\t                      vector<Value> parameters)\n-\t    : PhysicalOperator(PhysicalOperatorType::TABLE_FUNCTION, move(types)), function(move(function)),\n-\t      bind_data(move(bind_data)), parameters(move(parameters)) {\n-\t}\n-\n-\t//! Function to call\n-\tTableFunction function;\n-\t//! The bind data\n-\tunique_ptr<FunctionData> bind_data;\n-\t//! Parameters\n-\tvector<Value> parameters;\n-\n-public:\n-\tvoid GetChunkInternal(ExecutionContext &context, DataChunk &chunk, PhysicalOperatorState *state) override;\n-\tstring ExtraRenderInformation() const override;\n-};\n-\n-} // namespace duckdb\ndiff --git a/src/include/duckdb/execution/operator/scan/physical_table_scan.hpp b/src/include/duckdb/execution/operator/scan/physical_table_scan.hpp\nindex 8cd857bbc2cd..a439daa72932 100644\n--- a/src/include/duckdb/execution/operator/scan/physical_table_scan.hpp\n+++ b/src/include/duckdb/execution/operator/scan/physical_table_scan.hpp\n@@ -10,31 +10,28 @@\n \n #include \"duckdb/execution/physical_operator.hpp\"\n #include \"duckdb/storage/data_table.hpp\"\n+#include \"duckdb/function/table_function.hpp\"\n \n namespace duckdb {\n \n //! Represents a scan of a base table\n class PhysicalTableScan : public PhysicalOperator {\n public:\n-\tPhysicalTableScan(vector<LogicalType> types, TableCatalogEntry &tableref, DataTable &table,\n-\t                  vector<column_t> column_ids, vector<unique_ptr<Expression>> filter,\n-\t                  unordered_map<idx_t, vector<TableFilter>> table_filters);\n-\n-\t//! The table to scan\n-\tTableCatalogEntry &tableref;\n-\t//! The physical data table to scan\n-\tDataTable &table;\n-\t//! The column ids to project\n+\tPhysicalTableScan(vector<LogicalType> types, TableFunction function, unique_ptr<FunctionData> bind_data,\n+\t                  vector<column_t> column_ids, unordered_map<idx_t, vector<TableFilter>> table_filters);\n+\n+\t//! The table function\n+\tTableFunction function;\n+\t//! Bind data of the function\n+\tunique_ptr<FunctionData> bind_data;\n+\t//! The projected-out column ids\n \tvector<column_t> column_ids;\n-\n-\t//! The filter expression\n-\tunique_ptr<Expression> expression;\n-\t//! Filters pushed down to table scan\n+\t//! The table filters\n \tunordered_map<idx_t, vector<TableFilter>> table_filters;\n \n public:\n \tvoid GetChunkInternal(ExecutionContext &context, DataChunk &chunk, PhysicalOperatorState *state) override;\n-\tstring ExtraRenderInformation() const override;\n+\tstring ToString(idx_t depth = 0) const override;\n \tunique_ptr<PhysicalOperatorState> GetOperatorState() override;\n \n \tvoid ParallelScanInfo(ClientContext &context, std::function<void(unique_ptr<OperatorTaskInfo>)> callback) override;\ndiff --git a/src/include/duckdb/execution/physical_operator.hpp b/src/include/duckdb/execution/physical_operator.hpp\nindex 3fe8755eb121..bfaca7be7298 100644\n--- a/src/include/duckdb/execution/physical_operator.hpp\n+++ b/src/include/duckdb/execution/physical_operator.hpp\n@@ -64,7 +64,7 @@ class PhysicalOperator {\n \tvector<LogicalType> types;\n \n public:\n-\tstring ToString(idx_t depth = 0) const;\n+\tvirtual string ToString(idx_t depth = 0) const;\n \tvoid Print();\n \n \t//! Return a vector of the types that will be returned by this operator\ndiff --git a/src/include/duckdb/execution/physical_plan_generator.hpp b/src/include/duckdb/execution/physical_plan_generator.hpp\nindex 9bbe8aae4495..2ed46e4ded4b 100644\n--- a/src/include/duckdb/execution/physical_plan_generator.hpp\n+++ b/src/include/duckdb/execution/physical_plan_generator.hpp\n@@ -51,13 +51,13 @@ class PhysicalPlanGenerator {\n \tunique_ptr<PhysicalOperator> CreatePlan(LogicalDelimGet &op);\n \tunique_ptr<PhysicalOperator> CreatePlan(LogicalDelimJoin &op);\n \tunique_ptr<PhysicalOperator> CreatePlan(LogicalDistinct &op);\n+\tunique_ptr<PhysicalOperator> CreatePlan(LogicalDummyScan &expr);\n \tunique_ptr<PhysicalOperator> CreatePlan(LogicalEmptyResult &op);\n \tunique_ptr<PhysicalOperator> CreatePlan(LogicalExpressionGet &op);\n \tunique_ptr<PhysicalOperator> CreatePlan(LogicalExport &op);\n \tunique_ptr<PhysicalOperator> CreatePlan(LogicalFilter &op);\n \tunique_ptr<PhysicalOperator> CreatePlan(LogicalGet &op);\n \tunique_ptr<PhysicalOperator> CreatePlan(LogicalLimit &op);\n-\tunique_ptr<PhysicalOperator> CreatePlan(LogicalIndexScan &op);\n \tunique_ptr<PhysicalOperator> CreatePlan(LogicalOrder &op);\n \tunique_ptr<PhysicalOperator> CreatePlan(LogicalTopN &op);\n \tunique_ptr<PhysicalOperator> CreatePlan(LogicalProjection &op);\n@@ -67,7 +67,6 @@ class PhysicalPlanGenerator {\n \tunique_ptr<PhysicalOperator> CreatePlan(LogicalExplain &op);\n \tunique_ptr<PhysicalOperator> CreatePlan(LogicalSetOperation &op);\n \tunique_ptr<PhysicalOperator> CreatePlan(LogicalUpdate &op);\n-\tunique_ptr<PhysicalOperator> CreatePlan(LogicalTableFunction &expr);\n \tunique_ptr<PhysicalOperator> CreatePlan(LogicalPrepare &expr);\n \tunique_ptr<PhysicalOperator> CreatePlan(LogicalWindow &expr);\n \tunique_ptr<PhysicalOperator> CreatePlan(LogicalExecute &op);\ndiff --git a/src/include/duckdb/function/table/table_scan.hpp b/src/include/duckdb/function/table/table_scan.hpp\nnew file mode 100644\nindex 000000000000..ea2e265a3d15\n--- /dev/null\n+++ b/src/include/duckdb/function/table/table_scan.hpp\n@@ -0,0 +1,41 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/function/table/table_scan.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#pragma once\n+\n+#include \"duckdb/function/table_function.hpp\"\n+\n+namespace duckdb {\n+class TableCatalogEntry;\n+\n+struct TableScanBindData : public FunctionData {\n+\tTableScanBindData(TableCatalogEntry *table) : table(table), is_index_scan(false) {\n+\t}\n+\n+\t//! The table to scan\n+\tTableCatalogEntry *table;\n+\n+\t//! Whether or not the table scan is an index scan\n+\tbool is_index_scan;\n+\t//! The row ids to fetch (in case of an index scan)\n+\tvector<row_t> result_ids;\n+\n+\tunique_ptr<FunctionData> Copy() override {\n+\t\tauto result = make_unique<TableScanBindData>(table);\n+\t\tresult->is_index_scan = is_index_scan;\n+\t\tresult->result_ids = result_ids;\n+\t\treturn move(result);\n+\t}\n+};\n+\n+//! The table scan function represents a sequential scan over one of DuckDB's base tables.\n+struct TableScanFunction {\n+\tstatic TableFunction GetFunction();\n+};\n+\n+} // namespace duckdb\ndiff --git a/src/include/duckdb/function/table_function.hpp b/src/include/duckdb/function/table_function.hpp\nindex 3ed0b93a1b21..adebc9c546e3 100644\n--- a/src/include/duckdb/function/table_function.hpp\n+++ b/src/include/duckdb/function/table_function.hpp\n@@ -11,40 +11,110 @@\n #include \"duckdb/function/function.hpp\"\n #include \"duckdb/common/unordered_map.hpp\"\n \n+#include <functional>\n+\n namespace duckdb {\n+class LogicalGet;\n+class OperatorTaskInfo;\n+class TableFilter;\n+\n+struct FunctionOperatorData {\n+\tvirtual ~FunctionOperatorData() {\n+\t}\n+};\n+\n+//! TableFilter represents a filter pushed down into the table scan.\n+class TableFilter {\n+public:\n+\tTableFilter(Value constant, ExpressionType comparison_type, idx_t column_index)\n+\t    : constant(constant), comparison_type(comparison_type), column_index(column_index){};\n+\tValue constant;\n+\tExpressionType comparison_type;\n+\tidx_t column_index;\n+};\n \n-//! Function used for determining the return type of a table producing function\n typedef unique_ptr<FunctionData> (*table_function_bind_t)(ClientContext &context, vector<Value> &inputs,\n                                                           unordered_map<string, Value> &named_parameters,\n                                                           vector<LogicalType> &return_types, vector<string> &names);\n-//! Type used for table-returning function\n-typedef void (*table_function_t)(ClientContext &context, vector<Value> &input, DataChunk &output,\n-                                 FunctionData *dataptr);\n-//! Type used for final (cleanup) function\n-typedef void (*table_function_final_t)(ClientContext &context, FunctionData *dataptr);\n+typedef unique_ptr<FunctionOperatorData> (*table_function_init_t)(\n+    ClientContext &context, const FunctionData *bind_data, OperatorTaskInfo *task_info, vector<column_t> &column_ids,\n+    unordered_map<idx_t, vector<TableFilter>> &table_filters);\n+typedef void (*table_function_t)(ClientContext &context, const FunctionData *bind_data,\n+                                 FunctionOperatorData *operator_state, DataChunk &output);\n+typedef void (*table_function_cleanup_t)(ClientContext &context, const FunctionData *bind_data,\n+                                         FunctionOperatorData *operator_state);\n+typedef void (*table_function_parallel_t)(ClientContext &context, const FunctionData *bind_data,\n+                                          vector<column_t> &column_ids,\n+                                          unordered_map<idx_t, vector<TableFilter>> &table_filters,\n+                                          std::function<void(unique_ptr<OperatorTaskInfo>)> callback);\n+typedef void (*table_function_dependency_t)(unordered_set<CatalogEntry *> &dependencies, const FunctionData *bind_data);\n+typedef idx_t (*table_function_cardinality_t)(const FunctionData *bind_data);\n+typedef void (*table_function_pushdown_complex_filter_t)(ClientContext &context, LogicalGet &get,\n+                                                         FunctionData *bind_data,\n+                                                         vector<unique_ptr<Expression>> &filters);\n+typedef string (*table_function_to_string_t)(const FunctionData *bind_data);\n \n class TableFunction : public SimpleFunction {\n public:\n-\tTableFunction(string name, vector<LogicalType> arguments, table_function_bind_t bind, table_function_t function,\n-\t              table_function_final_t final = nullptr, bool supports_projection = false)\n-\t    : SimpleFunction(name, move(arguments)), bind(bind), function(function), final(final),\n-\t      supports_projection(supports_projection) {\n+\tTableFunction(string name, vector<LogicalType> arguments, table_function_t function,\n+\t              table_function_bind_t bind = nullptr, table_function_init_t init = nullptr,\n+\t              table_function_cleanup_t cleanup = nullptr, table_function_parallel_t parallel_tasks = nullptr,\n+\t              table_function_dependency_t dependency = nullptr, table_function_cardinality_t cardinality = nullptr,\n+\t              table_function_pushdown_complex_filter_t pushdown_complex_filter = nullptr,\n+\t              table_function_to_string_t to_string = nullptr, bool projection_pushdown = false,\n+\t              bool filter_pushdown = false)\n+\t    : SimpleFunction(name, move(arguments)), bind(bind), init(init), function(function), cleanup(cleanup),\n+\t      parallel_tasks(parallel_tasks), dependency(dependency), cardinality(cardinality),\n+\t      pushdown_complex_filter(pushdown_complex_filter), to_string(to_string),\n+\t      projection_pushdown(projection_pushdown), filter_pushdown(filter_pushdown) {\n \t}\n-\tTableFunction(vector<LogicalType> arguments, table_function_bind_t bind, table_function_t function,\n-\t              table_function_final_t final = nullptr, bool supports_projection = false)\n-\t    : TableFunction(string(), move(arguments), bind, function, final, supports_projection) {\n+\tTableFunction(vector<LogicalType> arguments, table_function_t function, table_function_bind_t bind = nullptr,\n+\t              table_function_init_t init = nullptr, table_function_cleanup_t cleanup = nullptr,\n+\t              table_function_parallel_t parallel_tasks = nullptr, table_function_dependency_t dependency = nullptr,\n+\t              table_function_cardinality_t cardinality = nullptr,\n+\t              table_function_pushdown_complex_filter_t pushdown_complex_filter = nullptr,\n+\t              table_function_to_string_t to_string = nullptr, bool projection_pushdown = false,\n+\t              bool filter_pushdown = false)\n+\t    : TableFunction(string(), move(arguments), function, bind, init, cleanup, parallel_tasks, dependency,\n+\t                    cardinality, pushdown_complex_filter, to_string, projection_pushdown, filter_pushdown) {\n \t}\n \n-\t//! The bind function\n+\t//! (Optional) Bind function\n+\t//! This function is used for determining the return type of a table producing function and returning bind data\n+\t//! The returned FunctionData object should be constant and should not be changed during execution.\n \ttable_function_bind_t bind;\n-\t//! The function pointer\n+\t//! (Optional) init function\n+\t//! Initialize the operator state of the function. The operator state is used to keep track of the progress in the\n+\t//! table function.\n+\ttable_function_init_t init;\n+\t//! The main function\n \ttable_function_t function;\n-\t//! Final function pointer\n-\ttable_function_final_t final;\n+\t//! (Optional) cleanup function\n+\t//! The final cleanup function, called after all data is exhausted from the main function\n+\ttable_function_cleanup_t cleanup;\n+\t//! (Optional) parallel task split\n+\t//! The function used to split the table-producing function into parallel tasks\n+\ttable_function_parallel_t parallel_tasks;\n+\t//! (Optional) dependency function\n+\t//! Sets up which catalog entries this table function depend on\n+\ttable_function_dependency_t dependency;\n+\t//! (Optional) cardinality function\n+\t//! Returns the expected cardinality of this scan\n+\ttable_function_cardinality_t cardinality;\n+\t//! (Optional) pushdown a set of arbitrary filter expressions, rather than only simple comparisons with a constant\n+\t//! Any functions remaining in the expression list will be pushed as a regular filter after the scan\n+\ttable_function_pushdown_complex_filter_t pushdown_complex_filter;\n+\t//! (Optional) function for rendering the operator to a string in profiling output\n+\ttable_function_to_string_t to_string;\n+\n \t//! Supported named parameters by the function\n \tunordered_map<string, LogicalType> named_parameters;\n-\t//! Whether or not the table function supports projection\n-\tbool supports_projection;\n+\t//! Whether or not the table function supports projection pushdown. If not supported a projection will be added\n+\t//! that filters out unused columns.\n+\tbool projection_pushdown;\n+\t//! Whether or not the table function supports filter pushdown. If not supported a filter will be added\n+\t//! that applies the table filter directly.\n+\tbool filter_pushdown;\n \n \tstring ToString();\n };\ndiff --git a/src/include/duckdb/optimizer/filter_combiner.hpp b/src/include/duckdb/optimizer/filter_combiner.hpp\nindex 187ace5a2358..2c6e3c8272e8 100644\n--- a/src/include/duckdb/optimizer/filter_combiner.hpp\n+++ b/src/include/duckdb/optimizer/filter_combiner.hpp\n@@ -37,8 +37,7 @@ class FilterCombiner {\n \n \tvoid GenerateFilters(std::function<void(unique_ptr<Expression> filter)> callback);\n \tbool HasFilters();\n-\tvector<TableFilter> GenerateTableScanFilters(std::function<void(unique_ptr<Expression> filter)> callback,\n-\t                                             vector<idx_t> &column_ids);\n+\tvector<TableFilter> GenerateTableScanFilters(vector<idx_t> &column_ids);\n \n private:\n \tFilterResult AddFilter(Expression *expr);\ndiff --git a/src/include/duckdb/optimizer/index_scan.hpp b/src/include/duckdb/optimizer/index_scan.hpp\ndeleted file mode 100644\nindex 59d8cff96f2e..000000000000\n--- a/src/include/duckdb/optimizer/index_scan.hpp\n+++ /dev/null\n@@ -1,27 +0,0 @@\n-//===----------------------------------------------------------------------===//\n-//                         DuckDB\n-//\n-// duckdb/optimizer/index_scan.hpp\n-//\n-//\n-//===----------------------------------------------------------------------===//\n-\n-#pragma once\n-\n-#include \"duckdb/optimizer/filter_combiner.hpp\"\n-#include \"duckdb/optimizer/rule.hpp\"\n-\n-namespace duckdb {\n-class Optimizer;\n-\n-class IndexScan {\n-public:\n-\t//! Optimize Filters in Index Scans\n-\tunique_ptr<LogicalOperator> Optimize(unique_ptr<LogicalOperator> node);\n-\n-private:\n-\t//! Transform a Filter in an index scan\n-\tunique_ptr<LogicalOperator> TransformFilterToIndexScan(unique_ptr<LogicalOperator> op);\n-};\n-\n-} // namespace duckdb\ndiff --git a/src/include/duckdb/planner/bind_context.hpp b/src/include/duckdb/planner/bind_context.hpp\nindex ba3e6fb6d848..90df4b1527b0 100644\n--- a/src/include/duckdb/planner/bind_context.hpp\n+++ b/src/include/duckdb/planner/bind_context.hpp\n@@ -45,7 +45,11 @@ class BindContext {\n \tvoid GenerateAllColumnExpressions(vector<unique_ptr<ParsedExpression>> &new_select_list, string relation_name = \"\");\n \n \t//! Adds a base table with the given alias to the BindContext.\n-\tvoid AddBaseTable(idx_t index, const string &alias, TableCatalogEntry &table, LogicalGet &get);\n+\tvoid AddBaseTable(idx_t index, const string &alias, vector<string> names, vector<LogicalType> types,\n+\t                  unordered_map<string, column_t> name_map, LogicalGet &get);\n+\t//! Adds a call to a table function with the given alias to the BindContext.\n+\tvoid AddTableFunction(idx_t index, const string &alias, vector<string> names, vector<LogicalType> types,\n+\t                      LogicalGet &get);\n \t//! Adds a subquery with a given alias to the BindContext.\n \tvoid AddSubquery(idx_t index, const string &alias, SubqueryRef &ref, BoundQueryNode &subquery);\n \t//! Adds a base table with the given alias to the BindContext.\ndiff --git a/src/include/duckdb/planner/logical_tokens.hpp b/src/include/duckdb/planner/logical_tokens.hpp\nindex 5fd7488cffd5..01852dc9b385 100644\n--- a/src/include/duckdb/planner/logical_tokens.hpp\n+++ b/src/include/duckdb/planner/logical_tokens.hpp\n@@ -28,6 +28,7 @@ class LogicalDelete;\n class LogicalDelimGet;\n class LogicalDelimJoin;\n class LogicalDistinct;\n+class LogicalDummyScan;\n class LogicalEmptyResult;\n class LogicalExecute;\n class LogicalExplain;\n@@ -35,7 +36,6 @@ class LogicalExport;\n class LogicalExpressionGet;\n class LogicalFilter;\n class LogicalGet;\n-class LogicalIndexScan;\n class LogicalInsert;\n class LogicalJoin;\n class LogicalLimit;\n@@ -46,7 +46,6 @@ class LogicalProjection;\n class LogicalRecursiveCTE;\n class LogicalSetOperation;\n class LogicalSimple;\n-class LogicalTableFunction;\n class LogicalTopN;\n class LogicalUnnest;\n class LogicalUpdate;\ndiff --git a/src/include/duckdb/planner/operator/list.hpp b/src/include/duckdb/planner/operator/list.hpp\nindex 34ff14b10cec..bbd3c9b189e0 100644\n--- a/src/include/duckdb/planner/operator/list.hpp\n+++ b/src/include/duckdb/planner/operator/list.hpp\n@@ -13,6 +13,7 @@\n #include \"duckdb/planner/operator/logical_delim_get.hpp\"\n #include \"duckdb/planner/operator/logical_delim_join.hpp\"\n #include \"duckdb/planner/operator/logical_distinct.hpp\"\n+#include \"duckdb/planner/operator/logical_dummy_scan.hpp\"\n #include \"duckdb/planner/operator/logical_empty_result.hpp\"\n #include \"duckdb/planner/operator/logical_execute.hpp\"\n #include \"duckdb/planner/operator/logical_explain.hpp\"\n@@ -20,7 +21,6 @@\n #include \"duckdb/planner/operator/logical_expression_get.hpp\"\n #include \"duckdb/planner/operator/logical_filter.hpp\"\n #include \"duckdb/planner/operator/logical_get.hpp\"\n-#include \"duckdb/planner/operator/logical_index_scan.hpp\"\n #include \"duckdb/planner/operator/logical_insert.hpp\"\n #include \"duckdb/planner/operator/logical_join.hpp\"\n #include \"duckdb/planner/operator/logical_limit.hpp\"\n@@ -31,7 +31,6 @@\n #include \"duckdb/planner/operator/logical_recursive_cte.hpp\"\n #include \"duckdb/planner/operator/logical_set_operation.hpp\"\n #include \"duckdb/planner/operator/logical_simple.hpp\"\n-#include \"duckdb/planner/operator/logical_table_function.hpp\"\n #include \"duckdb/planner/operator/logical_top_n.hpp\"\n #include \"duckdb/planner/operator/logical_unnest.hpp\"\n #include \"duckdb/planner/operator/logical_update.hpp\"\ndiff --git a/src/include/duckdb/planner/operator/logical_dummy_scan.hpp b/src/include/duckdb/planner/operator/logical_dummy_scan.hpp\nnew file mode 100644\nindex 000000000000..612f8e081b56\n--- /dev/null\n+++ b/src/include/duckdb/planner/operator/logical_dummy_scan.hpp\n@@ -0,0 +1,39 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/planner/operator/logical_dummy_scan.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#pragma once\n+\n+#include \"duckdb/planner/logical_operator.hpp\"\n+\n+namespace duckdb {\n+\n+//! LogicalDummyScan represents a dummy scan returning a single row\n+class LogicalDummyScan : public LogicalOperator {\n+public:\n+\tLogicalDummyScan(idx_t table_index) : LogicalOperator(LogicalOperatorType::DUMMY_SCAN), table_index(table_index) {\n+\t}\n+\n+\tidx_t table_index;\n+\n+public:\n+\tvector<ColumnBinding> GetColumnBindings() override {\n+\t\treturn {ColumnBinding(table_index, 0)};\n+\t}\n+\n+\tidx_t EstimateCardinality() override {\n+\t\treturn 1;\n+\t}\n+\n+protected:\n+\tvoid ResolveTypes() override {\n+\t\tif (types.size() == 0) {\n+\t\t\ttypes.push_back(LogicalType::INTEGER);\n+\t\t}\n+\t}\n+};\n+} // namespace duckdb\ndiff --git a/src/include/duckdb/planner/operator/logical_get.hpp b/src/include/duckdb/planner/operator/logical_get.hpp\nindex 38b4c3b7581c..a5c65987fdd0 100644\n--- a/src/include/duckdb/planner/operator/logical_get.hpp\n+++ b/src/include/duckdb/planner/operator/logical_get.hpp\n@@ -8,35 +8,39 @@\n \n #pragma once\n \n-#include \"duckdb/catalog/catalog_entry/table_catalog_entry.hpp\"\n #include \"duckdb/planner/logical_operator.hpp\"\n-\n-#include \"duckdb/storage/data_table.hpp\"\n+#include \"duckdb/function/table_function.hpp\"\n \n namespace duckdb {\n \n //! LogicalGet represents a scan operation from a data source\n class LogicalGet : public LogicalOperator {\n public:\n-\tLogicalGet(idx_t table_index);\n-\tLogicalGet(TableCatalogEntry *table, idx_t table_index);\n-\tLogicalGet(TableCatalogEntry *table, idx_t table_index, vector<column_t> column_ids);\n-\n-\tidx_t EstimateCardinality() override;\n+\tLogicalGet(idx_t table_index, TableFunction function, unique_ptr<FunctionData> bind_data,\n+\t           vector<LogicalType> returned_types, vector<string> returned_names);\n \n-\t//! The base table to retrieve data from\n-\tTableCatalogEntry *table;\n \t//! The table index in the current bind context\n \tidx_t table_index;\n+\t//! The function that is called\n+\tTableFunction function;\n+\t//! The bind data of the function\n+\tunique_ptr<FunctionData> bind_data;\n+\t//! The types of ALL columns that can be returned by the table function\n+\tvector<LogicalType> returned_types;\n+\t//! The names of ALL columns that can be returned by the table function\n+\tvector<string> names;\n \t//! Bound column IDs\n \tvector<column_t> column_ids;\n \t//! Filters pushed down for table scan\n \tvector<TableFilter> tableFilters;\n+\n \tstring ParamsToString() const override;\n \n public:\n \tvector<ColumnBinding> GetColumnBindings() override;\n \n+\tidx_t EstimateCardinality() override;\n+\n protected:\n \tvoid ResolveTypes() override;\n };\ndiff --git a/src/include/duckdb/planner/operator/logical_index_scan.hpp b/src/include/duckdb/planner/operator/logical_index_scan.hpp\ndeleted file mode 100644\nindex 3116bb1db796..000000000000\n--- a/src/include/duckdb/planner/operator/logical_index_scan.hpp\n+++ /dev/null\n@@ -1,67 +0,0 @@\n-//===----------------------------------------------------------------------===//\n-//                         DuckDB\n-//\n-// duckdb/planner/operator/logical_index_scan.hpp\n-//\n-//\n-//===----------------------------------------------------------------------===//\n-\n-#pragma once\n-\n-#include \"duckdb/planner/logical_operator.hpp\"\n-#include \"duckdb/catalog/catalog_entry/table_catalog_entry.hpp\"\n-#include \"duckdb/storage/index.hpp\"\n-\n-namespace duckdb {\n-\n-//! LogicalIndex represents an Index Scan operation\n-class LogicalIndexScan : public LogicalOperator {\n-public:\n-\tLogicalIndexScan(TableCatalogEntry &tableref, DataTable &table, Index &index, vector<column_t> column_ids,\n-\t                 idx_t table_index)\n-\t    : LogicalOperator(LogicalOperatorType::INDEX_SCAN), tableref(tableref), table(table), index(index),\n-\t      column_ids(column_ids), table_index(table_index) {\n-\t}\n-\n-\t//! The table to scan\n-\tTableCatalogEntry &tableref;\n-\t//! The physical data table to scan\n-\tDataTable &table;\n-\t//! The index to use for the scan\n-\tIndex &index;\n-\t//! The column ids to project\n-\tvector<column_t> column_ids;\n-\n-\t//! The value for the query predicate\n-\tValue low_value;\n-\tValue high_value;\n-\tValue equal_value;\n-\n-\t//! If the predicate is low, high or equal\n-\tbool low_index = false;\n-\tbool high_index = false;\n-\tbool equal_index = false;\n-\n-\t//! The expression type (e.g., >, <, >=, <=)\n-\tExpressionType low_expression_type;\n-\tExpressionType high_expression_type;\n-\n-\t//! The table index in the current bind context\n-\tidx_t table_index;\n-\n-public:\n-\tvector<ColumnBinding> GetColumnBindings() override {\n-\t\treturn GenerateColumnBindings(table_index, column_ids.size());\n-\t}\n-\n-protected:\n-\tvoid ResolveTypes() override {\n-\t\tif (column_ids.size() == 0) {\n-\t\t\ttypes = {LogicalType::INTEGER};\n-\t\t} else {\n-\t\t\ttypes = tableref.GetTypes(column_ids);\n-\t\t}\n-\t}\n-};\n-\n-} // namespace duckdb\ndiff --git a/src/include/duckdb/planner/operator/logical_table_function.hpp b/src/include/duckdb/planner/operator/logical_table_function.hpp\ndeleted file mode 100644\nindex 73bcd4d56306..000000000000\n--- a/src/include/duckdb/planner/operator/logical_table_function.hpp\n+++ /dev/null\n@@ -1,49 +0,0 @@\n-//===----------------------------------------------------------------------===//\n-//                         DuckDB\n-//\n-// duckdb/planner/operator/logical_table_function.hpp\n-//\n-//\n-//===----------------------------------------------------------------------===//\n-\n-#pragma once\n-\n-#include \"duckdb/planner/logical_operator.hpp\"\n-#include \"duckdb/function/table_function.hpp\"\n-#include \"duckdb/common/types/value.hpp\"\n-\n-namespace duckdb {\n-\n-//! LogicalTableFunction represents a call to a table-producing function\n-class LogicalTableFunction : public LogicalOperator {\n-public:\n-\tLogicalTableFunction(TableFunction function, idx_t table_index, unique_ptr<FunctionData> bind_data,\n-\t                     vector<Value> parameters, vector<LogicalType> return_types, vector<string> names)\n-\t    : LogicalOperator(LogicalOperatorType::TABLE_FUNCTION), function(move(function)), table_index(table_index),\n-\t      bind_data(move(bind_data)), parameters(move(parameters)), return_types(move(return_types)),\n-\t      names(move(names)) {\n-\t}\n-\n-\t//! The function\n-\tTableFunction function;\n-\t//! The table index of the table-producing function\n-\tidx_t table_index;\n-\t//! The bind data of the function\n-\tunique_ptr<FunctionData> bind_data;\n-\t//! The input parameters\n-\tvector<Value> parameters;\n-\t//! The set of returned sql types\n-\tvector<LogicalType> return_types;\n-\t//! The set of returned column names\n-\tvector<string> names;\n-\t//! Bound column IDs\n-\tvector<column_t> column_ids;\n-\n-public:\n-\tvector<ColumnBinding> GetColumnBindings() override;\n-\tstring ParamsToString() const override;\n-\n-protected:\n-\tvoid ResolveTypes() override;\n-};\n-} // namespace duckdb\ndiff --git a/src/include/duckdb/planner/table_binding.hpp b/src/include/duckdb/planner/table_binding.hpp\nindex 285eadd51f08..c270c6bc4930 100644\n--- a/src/include/duckdb/planner/table_binding.hpp\n+++ b/src/include/duckdb/planner/table_binding.hpp\n@@ -24,53 +24,40 @@ class TableCatalogEntry;\n class TableFunctionCatalogEntry;\n class BoundTableFunction;\n \n-enum class BindingType : uint8_t { TABLE = 0, SUBQUERY = 1, TABLE_FUNCTION = 2, GENERIC = 3 };\n-\n-//! A Binding represents a binding to a table, table-producing function or subquery with a specified table index. Used\n-//! in the binder.\n+//! A Binding represents a binding to a table, table-producing function or subquery with a specified table index.\n struct Binding {\n-\tBinding(BindingType type, const string &alias, idx_t index) : type(type), alias(alias), index(index) {\n-\t}\n+\tBinding(const string &alias, vector<LogicalType> types, vector<string> names, idx_t index);\n+\tBinding(const string &alias, idx_t index);\n \tvirtual ~Binding() = default;\n \n-\tBindingType type;\n+\t//! The alias of the binding\n \tstring alias;\n+\t//! The table index of the binding\n \tidx_t index;\n+\tvector<LogicalType> types;\n+\t//! Column names of the subquery\n+\tvector<string> names;\n+\t//! Name -> index for the names\n+\tunordered_map<string, column_t> name_map;\n \n public:\n-\tvirtual bool HasMatchingBinding(const string &column_name) = 0;\n-\tvirtual BindResult Bind(ColumnRefExpression &colref, idx_t depth) = 0;\n-\tvirtual void GenerateAllColumnExpressions(BindContext &context,\n-\t                                          vector<unique_ptr<ParsedExpression>> &select_list) = 0;\n+\tbool HasMatchingBinding(const string &column_name);\n+\tvirtual BindResult Bind(ColumnRefExpression &colref, idx_t depth);\n+\tvoid GenerateAllColumnExpressions(BindContext &context, vector<unique_ptr<ParsedExpression>> &select_list);\n };\n \n-//! Represents a binding to a base table\n+//! TableBinding is exactly like the Binding, except it keeps track of which columns were bound in the linked LogicalGet\n+//! node for projection pushdown purposes.\n struct TableBinding : public Binding {\n-\tTableBinding(const string &alias, TableCatalogEntry &table, LogicalGet &get, idx_t index);\n+\tTableBinding(const string &alias, vector<LogicalType> types, vector<string> names, LogicalGet &get, idx_t index);\n+\tTableBinding(const string &alias, vector<LogicalType> types, vector<string> names,\n+\t             unordered_map<string, column_t> name_map, LogicalGet &get, idx_t index);\n \n-\tTableCatalogEntry &table;\n+\t//! the underlying LogicalGet\n \tLogicalGet &get;\n \n public:\n-\tbool HasMatchingBinding(const string &column_name) override;\n-\tBindResult Bind(ColumnRefExpression &colref, idx_t depth) override;\n-\tvoid GenerateAllColumnExpressions(BindContext &context, vector<unique_ptr<ParsedExpression>> &select_list) override;\n-};\n-\n-//! Represents a generic binding with types and names\n-struct GenericBinding : public Binding {\n-\tGenericBinding(const string &alias, vector<LogicalType> types, vector<string> names, idx_t index);\n-\n-\tvector<LogicalType> types;\n-\t//! Column names of the subquery\n-\tvector<string> names;\n-\t//! Name -> index for the names\n-\tunordered_map<string, column_t> name_map;\n-\n-public:\n-\tbool HasMatchingBinding(const string &column_name) override;\n \tBindResult Bind(ColumnRefExpression &colref, idx_t depth) override;\n-\tvoid GenerateAllColumnExpressions(BindContext &context, vector<unique_ptr<ParsedExpression>> &select_list) override;\n };\n \n } // namespace duckdb\ndiff --git a/src/include/duckdb/planner/tableref/bound_basetableref.hpp b/src/include/duckdb/planner/tableref/bound_basetableref.hpp\nindex 679d33651298..b3182c7f47b7 100644\n--- a/src/include/duckdb/planner/tableref/bound_basetableref.hpp\n+++ b/src/include/duckdb/planner/tableref/bound_basetableref.hpp\n@@ -17,9 +17,11 @@ class TableCatalogEntry;\n //! Represents a TableReference to a base table in the schema\n class BoundBaseTableRef : public BoundTableRef {\n public:\n-\tBoundBaseTableRef(unique_ptr<LogicalOperator> get) : BoundTableRef(TableReferenceType::BASE_TABLE), get(move(get)) {\n+\tBoundBaseTableRef(TableCatalogEntry *table, unique_ptr<LogicalOperator> get)\n+\t    : BoundTableRef(TableReferenceType::BASE_TABLE), table(table), get(move(get)) {\n \t}\n \n+\tTableCatalogEntry *table;\n \tunique_ptr<LogicalOperator> get;\n };\n } // namespace duckdb\ndiff --git a/src/include/duckdb/planner/tableref/bound_table_function.hpp b/src/include/duckdb/planner/tableref/bound_table_function.hpp\nindex b6b6361273fa..20e5575a8a61 100644\n--- a/src/include/duckdb/planner/tableref/bound_table_function.hpp\n+++ b/src/include/duckdb/planner/tableref/bound_table_function.hpp\n@@ -8,31 +8,19 @@\n \n #pragma once\n \n-#include \"duckdb/common/types/value.hpp\"\n-#include \"duckdb/planner/expression.hpp\"\n #include \"duckdb/planner/bound_tableref.hpp\"\n-#include \"duckdb/function/table_function.hpp\"\n+#include \"duckdb/planner/logical_operator.hpp\"\n \n namespace duckdb {\n \n //! Represents a reference to a table-producing function call\n class BoundTableFunction : public BoundTableRef {\n public:\n-\tBoundTableFunction(TableFunction function, idx_t bind_index)\n-\t    : BoundTableRef(TableReferenceType::TABLE_FUNCTION), function(function), bind_index(bind_index) {\n+\tBoundTableFunction(unique_ptr<LogicalOperator> get)\n+\t    : BoundTableRef(TableReferenceType::TABLE_FUNCTION), get(move(get)) {\n \t}\n \n-\t//! The function that is called\n-\tTableFunction function;\n-\t//! The bind data of the function\n-\tunique_ptr<FunctionData> bind_data;\n-\t//! The set of parameters to use as input to the table-producing function\n-\tvector<Value> parameters;\n-\t//! The set of returned sql types\n-\tvector<LogicalType> return_types;\n-\t//! The set of returned column names\n-\tvector<string> names;\n-\t//! The index in the bind context\n-\tidx_t bind_index;\n+\tunique_ptr<LogicalOperator> get;\n };\n+\n } // namespace duckdb\ndiff --git a/src/include/duckdb/storage/data_table.hpp b/src/include/duckdb/storage/data_table.hpp\nindex d54be8443e5c..39b5d6e9fda6 100644\n--- a/src/include/duckdb/storage/data_table.hpp\n+++ b/src/include/duckdb/storage/data_table.hpp\n@@ -32,16 +32,6 @@ class Transaction;\n \n typedef unique_ptr<vector<unique_ptr<PersistentSegment>>[]> persistent_data_t;\n \n-//! TableFilter represents a filter pushed down into the table scan.\n-class TableFilter {\n-public:\n-\tTableFilter(Value constant, ExpressionType comparison_type, idx_t column_index)\n-\t    : constant(constant), comparison_type(comparison_type), column_index(column_index){};\n-\tValue constant;\n-\tExpressionType comparison_type;\n-\tidx_t column_index;\n-};\n-\n struct DataTableInfo {\n \tDataTableInfo(string schema, string table) : cardinality(0), schema(move(schema)), table(move(table)) {\n \t}\n@@ -97,19 +87,9 @@ class DataTable {\n \tvoid Scan(Transaction &transaction, DataChunk &result, TableScanState &state, vector<column_t> &column_ids,\n \t          unordered_map<idx_t, vector<TableFilter>> &table_filters);\n \n-\t//! Initialize an index scan with a single predicate and a comparison type (= <= < > >=)\n-\tvoid InitializeIndexScan(Transaction &transaction, TableIndexScanState &state, Index &index, Value value,\n-\t                         ExpressionType expr_type, vector<column_t> column_ids);\n-\t//! Initialize an index scan with two predicates and two comparison types (> >= < <=)\n-\tvoid InitializeIndexScan(Transaction &transaction, TableIndexScanState &state, Index &index, Value low_value,\n-\t                         ExpressionType low_type, Value high_value, ExpressionType high_type,\n-\t                         vector<column_t> column_ids);\n-\t//! Scans up to STANDARD_VECTOR_SIZE elements from the table from the given index structure\n-\tvoid IndexScan(Transaction &transaction, DataChunk &result, TableIndexScanState &state);\n-\n \t//! Fetch data from the specific row identifiers from the base table\n \tvoid Fetch(Transaction &transaction, DataChunk &result, vector<column_t> &column_ids, Vector &row_ids,\n-\t           idx_t fetch_count, TableIndexScanState &state);\n+\t           idx_t fetch_count, ColumnFetchState &state);\n \n \t//! Append a DataChunk to the table. Throws an exception if the columns don't match the tables' columns.\n \tvoid Append(TableCatalogEntry &table, ClientContext &context, DataChunk &chunk);\n@@ -150,9 +130,6 @@ class DataTable {\n \t//! Verify constraints with a chunk from the Update containing only the specified column_ids\n \tvoid VerifyUpdateConstraints(TableCatalogEntry &table, DataChunk &chunk, vector<column_t> &column_ids);\n \n-\tvoid InitializeIndexScan(Transaction &transaction, TableIndexScanState &state, Index &index,\n-\t                         vector<column_t> column_ids);\n-\n \tvoid InitializeScanWithOffset(TableScanState &state, const vector<column_t> &column_ids,\n \t                              unordered_map<idx_t, vector<TableFilter>> *table_filters, idx_t offset);\n \tbool CheckZonemap(TableScanState &state, unordered_map<idx_t, vector<TableFilter>> &table_filters,\ndiff --git a/src/include/duckdb/storage/index.hpp b/src/include/duckdb/storage/index.hpp\nindex 23bc6f168f14..a74aba637f82 100644\n--- a/src/include/duckdb/storage/index.hpp\n+++ b/src/include/duckdb/storage/index.hpp\n@@ -47,17 +47,17 @@ class Index {\n public:\n \t//! Initialize a scan on the index with the given expression and column ids\n \t//! to fetch from the base table when we only have one query predicate\n-\tvirtual unique_ptr<IndexScanState> InitializeScanSinglePredicate(Transaction &transaction,\n-\t                                                                 vector<column_t> column_ids, Value value,\n+\tvirtual unique_ptr<IndexScanState> InitializeScanSinglePredicate(Transaction &transaction, Value value,\n \t                                                                 ExpressionType expressionType) = 0;\n \t//! Initialize a scan on the index with the given expression and column ids\n \t//! to fetch from the base table for two query predicates\n-\tvirtual unique_ptr<IndexScanState> InitializeScanTwoPredicates(Transaction &transaction,\n-\t                                                               vector<column_t> column_ids, Value low_value,\n+\tvirtual unique_ptr<IndexScanState> InitializeScanTwoPredicates(Transaction &transaction, Value low_value,\n \t                                                               ExpressionType low_expression_type, Value high_value,\n \t                                                               ExpressionType high_expression_type) = 0;\n-\t//! Perform a lookup on the index\n-\tvirtual void Scan(Transaction &transaction, DataTable &table, TableIndexScanState &state, DataChunk &result) = 0;\n+\t//! Perform a lookup on the index, fetching up to max_count result ids. Returns true if all row ids were fetched,\n+\t//! and false otherwise.\n+\tvirtual bool Scan(Transaction &transaction, DataTable &table, IndexScanState &state, idx_t max_count,\n+\t                  vector<row_t> &result_ids) = 0;\n \n \t//! Obtain a lock on the index\n \tvirtual void InitializeLock(IndexLock &state);\ndiff --git a/src/include/duckdb/storage/table/scan_state.hpp b/src/include/duckdb/storage/table/scan_state.hpp\nindex f9416f3982b6..2039af87eba1 100644\n--- a/src/include/duckdb/storage/table/scan_state.hpp\n+++ b/src/include/duckdb/storage/table/scan_state.hpp\n@@ -22,10 +22,6 @@ class PersistentSegment;\n class TransientSegment;\n \n struct IndexScanState {\n-\tvector<column_t> column_ids;\n-\n-\tIndexScanState(vector<column_t> column_ids) : column_ids(column_ids) {\n-\t}\n \tvirtual ~IndexScanState() {\n \t}\n };\n@@ -86,12 +82,4 @@ class CreateIndexScanState : public TableScanState {\n \tstd::unique_lock<std::mutex> append_lock;\n };\n \n-struct TableIndexScanState {\n-\tIndex *index;\n-\tunique_ptr<IndexScanState> index_state;\n-\tColumnFetchState fetch_state;\n-\tLocalScanState local_state;\n-\tvector<column_t> column_ids;\n-};\n-\n } // namespace duckdb\ndiff --git a/src/main/query_profiler.cpp b/src/main/query_profiler.cpp\nindex 1b59a6df7cfc..3f6ee5259070 100644\n--- a/src/main/query_profiler.cpp\n+++ b/src/main/query_profiler.cpp\n@@ -52,9 +52,7 @@ bool QueryProfiler::OperatorRequiresProfiling(PhysicalOperatorType op_type) {\n \tcase PhysicalOperatorType::PROJECTION:\n \tcase PhysicalOperatorType::COPY_FROM_FILE:\n \tcase PhysicalOperatorType::COPY_TO_FILE:\n-\tcase PhysicalOperatorType::TABLE_FUNCTION:\n-\tcase PhysicalOperatorType::SEQ_SCAN:\n-\tcase PhysicalOperatorType::INDEX_SCAN:\n+\tcase PhysicalOperatorType::TABLE_SCAN:\n \tcase PhysicalOperatorType::CHUNK_SCAN:\n \tcase PhysicalOperatorType::DELIM_SCAN:\n \tcase PhysicalOperatorType::EXTERNAL_FILE_SCAN:\ndiff --git a/src/optimizer/CMakeLists.txt b/src/optimizer/CMakeLists.txt\nindex 21aaa19ab4ed..e3458148303e 100644\n--- a/src/optimizer/CMakeLists.txt\n+++ b/src/optimizer/CMakeLists.txt\n@@ -3,21 +3,21 @@ add_subdirectory(join_order)\n add_subdirectory(pushdown)\n add_subdirectory(rule)\n \n-add_library_unity(duckdb_optimizer\n-                  OBJECT\n-                  cse_optimizer.cpp\n-                  column_lifetime_analyzer.cpp\n-                  expression_heuristics.cpp\n-                  filter_combiner.cpp\n-                  filter_pushdown.cpp\n-                  in_clause_rewriter.cpp\n-                  join_order_optimizer.cpp\n-                  optimizer.cpp\n-                  expression_rewriter.cpp\n-                  regex_range_filter.cpp\n-                  remove_unused_columns.cpp\n-                  index_scan.cpp\n-                  topn_optimizer.cpp)\n+add_library_unity(\n+  duckdb_optimizer\n+  OBJECT\n+  cse_optimizer.cpp\n+  column_lifetime_analyzer.cpp\n+  expression_heuristics.cpp\n+  filter_combiner.cpp\n+  filter_pushdown.cpp\n+  in_clause_rewriter.cpp\n+  join_order_optimizer.cpp\n+  optimizer.cpp\n+  expression_rewriter.cpp\n+  regex_range_filter.cpp\n+  remove_unused_columns.cpp\n+  topn_optimizer.cpp)\n set(ALL_OBJECT_FILES\n     ${ALL_OBJECT_FILES} $<TARGET_OBJECTS:duckdb_optimizer>\n     PARENT_SCOPE)\ndiff --git a/src/optimizer/filter_combiner.cpp b/src/optimizer/filter_combiner.cpp\nindex 70ab3a49855e..f51cc9f5d57c 100644\n--- a/src/optimizer/filter_combiner.cpp\n+++ b/src/optimizer/filter_combiner.cpp\n@@ -155,14 +155,11 @@ bool FilterCombiner::HasFilters() {\n \treturn has_filters;\n }\n \n-vector<TableFilter>\n-FilterCombiner::GenerateTableScanFilters(std::function<void(unique_ptr<Expression> filter)> callback,\n-                                         vector<idx_t> &column_ids) {\n+vector<TableFilter> FilterCombiner::GenerateTableScanFilters(vector<idx_t> &column_ids) {\n \tvector<TableFilter> tableFilters;\n \t//! First, we figure the filters that have constant expressions that we can push down to the table scan\n \tfor (auto &constant_value : constant_values) {\n \t\tif (constant_value.second.size() > 0) {\n-\t\t\t//\t\t\tfor (idx_t i = 0; i < constant_value.second.size(); ++i) {\n \t\t\tauto filter_exp = equivalence_map.end();\n \t\t\tif ((constant_value.second[0].comparison_type == ExpressionType::COMPARE_EQUAL ||\n \t\t\t     constant_value.second[0].comparison_type == ExpressionType::COMPARE_GREATERTHAN ||\n@@ -183,45 +180,11 @@ FilterCombiner::GenerateTableScanFilters(std::function<void(unique_ptr<Expressio\n \t\t\t\t\tauto &constant_list = constant_values.find(equivalence_set)->second;\n \t\t\t\t\t// for each entry generate an equality expression comparing to each other\n \t\t\t\t\tfor (idx_t i = 0; i < entries.size(); i++) {\n-\t\t\t\t\t\tfor (idx_t k = i + 1; k < entries.size(); k++) {\n-\t\t\t\t\t\t\tauto comparison = make_unique<BoundComparisonExpression>(\n-\t\t\t\t\t\t\t    ExpressionType::COMPARE_EQUAL, entries[i]->Copy(), entries[k]->Copy());\n-\t\t\t\t\t\t\tcallback(move(comparison));\n-\t\t\t\t\t\t}\n \t\t\t\t\t\t// for each entry also create a comparison with each constant\n-\t\t\t\t\t\tint lower_index = -1, upper_index = -1;\n \t\t\t\t\t\tfor (idx_t k = 0; k < constant_list.size(); k++) {\n \t\t\t\t\t\t\ttableFilters.push_back(TableFilter(constant_value.second[k].constant,\n \t\t\t\t\t\t\t                                   constant_value.second[k].comparison_type,\n \t\t\t\t\t\t\t                                   filter_col_exp->binding.column_index));\n-\t\t\t\t\t\t\tauto &info = constant_list[k];\n-\t\t\t\t\t\t\tif (info.comparison_type == ExpressionType::COMPARE_GREATERTHAN ||\n-\t\t\t\t\t\t\t    info.comparison_type == ExpressionType::COMPARE_GREATERTHANOREQUALTO) {\n-\t\t\t\t\t\t\t\tlower_index = k;\n-\n-\t\t\t\t\t\t\t} else if (info.comparison_type == ExpressionType::COMPARE_LESSTHAN ||\n-\t\t\t\t\t\t\t           info.comparison_type == ExpressionType::COMPARE_LESSTHANOREQUALTO) {\n-\t\t\t\t\t\t\t\tupper_index = k;\n-\t\t\t\t\t\t\t} else {\n-\t\t\t\t\t\t\t\tauto constant = make_unique<BoundConstantExpression>(info.constant);\n-\t\t\t\t\t\t\t\tauto comparison = make_unique<BoundComparisonExpression>(\n-\t\t\t\t\t\t\t\t    info.comparison_type, entries[i]->Copy(), move(constant));\n-\t\t\t\t\t\t\t\tcallback(move(comparison));\n-\t\t\t\t\t\t\t}\n-\t\t\t\t\t\t}\n-\t\t\t\t\t\tif (lower_index >= 0) {\n-\t\t\t\t\t\t\t// only lower index found, create simple comparison expression\n-\t\t\t\t\t\t\tauto constant = make_unique<BoundConstantExpression>(constant_list[lower_index].constant);\n-\t\t\t\t\t\t\tauto comparison = make_unique<BoundComparisonExpression>(\n-\t\t\t\t\t\t\t    constant_list[lower_index].comparison_type, entries[i]->Copy(), move(constant));\n-\t\t\t\t\t\t\tcallback(move(comparison));\n-\t\t\t\t\t\t}\n-\t\t\t\t\t\tif (upper_index >= 0) {\n-\t\t\t\t\t\t\t// only upper index found, create simple comparison expression\n-\t\t\t\t\t\t\tauto constant = make_unique<BoundConstantExpression>(constant_list[upper_index].constant);\n-\t\t\t\t\t\t\tauto comparison = make_unique<BoundComparisonExpression>(\n-\t\t\t\t\t\t\t    constant_list[upper_index].comparison_type, entries[i]->Copy(), move(constant));\n-\t\t\t\t\t\t\tcallback(move(comparison));\n \t\t\t\t\t\t}\n \t\t\t\t\t}\n \t\t\t\t\tequivalence_map.erase(filter_exp);\ndiff --git a/src/optimizer/index_scan.cpp b/src/optimizer/index_scan.cpp\ndeleted file mode 100644\nindex 5264fcd000cf..000000000000\n--- a/src/optimizer/index_scan.cpp\n+++ /dev/null\n@@ -1,155 +0,0 @@\n-#include \"duckdb/optimizer/index_scan.hpp\"\n-#include \"duckdb/optimizer/matcher/expression_matcher.hpp\"\n-\n-#include \"duckdb/parser/expression/comparison_expression.hpp\"\n-\n-#include \"duckdb/planner/expression/bound_columnref_expression.hpp\"\n-#include \"duckdb/planner/expression/bound_comparison_expression.hpp\"\n-#include \"duckdb/planner/expression/bound_constant_expression.hpp\"\n-#include \"duckdb/planner/expression_iterator.hpp\"\n-#include \"duckdb/planner/operator/logical_filter.hpp\"\n-#include \"duckdb/planner/operator/logical_get.hpp\"\n-#include \"duckdb/planner/operator/logical_index_scan.hpp\"\n-\n-#include \"duckdb/storage/data_table.hpp\"\n-namespace duckdb {\n-using namespace std;\n-\n-unique_ptr<LogicalOperator> IndexScan::Optimize(unique_ptr<LogicalOperator> op) {\n-\tif (op->type == LogicalOperatorType::FILTER && op->children[0]->type == LogicalOperatorType::GET) {\n-\t\treturn TransformFilterToIndexScan(move(op));\n-\t}\n-\tfor (auto &child : op->children) {\n-\t\tchild = Optimize(move(child));\n-\t}\n-\treturn op;\n-}\n-\n-static void RewriteIndexExpression(Index &index, LogicalGet &get, Expression &expr, bool &rewrite_possible) {\n-\tif (expr.type == ExpressionType::BOUND_COLUMN_REF) {\n-\t\tauto &bound_colref = (BoundColumnRefExpression &)expr;\n-\t\t// bound column ref: rewrite to fit in the current set of bound column ids\n-\t\tbound_colref.binding.table_index = get.table_index;\n-\t\tcolumn_t referenced_column = index.column_ids[bound_colref.binding.column_index];\n-\t\t// search for the referenced column in the set of column_ids\n-\t\tfor (idx_t i = 0; i < get.column_ids.size(); i++) {\n-\t\t\tif (get.column_ids[i] == referenced_column) {\n-\t\t\t\tbound_colref.binding.column_index = i;\n-\t\t\t\treturn;\n-\t\t\t}\n-\t\t}\n-\t\t// column id not found in bound columns in the LogicalGet: rewrite not possible\n-\t\trewrite_possible = false;\n-\t}\n-\tExpressionIterator::EnumerateChildren(\n-\t    expr, [&](Expression &child) { RewriteIndexExpression(index, get, child, rewrite_possible); });\n-}\n-\n-unique_ptr<LogicalOperator> IndexScan::TransformFilterToIndexScan(unique_ptr<LogicalOperator> op) {\n-\tassert(op->type == LogicalOperatorType::FILTER);\n-\tauto &filter = (LogicalFilter &)*op;\n-\tauto get = (LogicalGet *)op->children[0].get();\n-\n-\tif (!get->table) {\n-\t\treturn op;\n-\t}\n-\n-\tauto &storage = *get->table->storage;\n-\n-\tif (storage.info->indexes.size() == 0) {\n-\t\t// no indexes on the table, can't rewrite\n-\t\treturn op;\n-\t}\n-\n-\t// check all the indexes\n-\tfor (size_t j = 0; j < storage.info->indexes.size(); j++) {\n-\t\tauto &index = storage.info->indexes[j];\n-\n-\t\t//\t\tassert(index->unbound_expressions.size() == 1);\n-\t\t// first rewrite the index expression so the ColumnBindings align with the column bindings of the current table\n-\t\tif (index->unbound_expressions.size() > 1)\n-\t\t\tcontinue;\n-\t\tauto index_expression = index->unbound_expressions[0]->Copy();\n-\t\tbool rewrite_possible = true;\n-\t\tRewriteIndexExpression(*index, *get, *index_expression, rewrite_possible);\n-\t\tif (!rewrite_possible) {\n-\t\t\t// could not rewrite!\n-\t\t\tcontinue;\n-\t\t}\n-\n-\t\tValue low_value, high_value, equal_value;\n-\t\t// try to find a matching index for any of the filter expressions\n-\t\tauto expr = filter.expressions[0].get();\n-\t\tauto low_comparison_type = expr->type;\n-\t\tauto high_comparison_type = expr->type;\n-\t\tfor (idx_t i = 0; i < filter.expressions.size(); i++) {\n-\t\t\texpr = filter.expressions[i].get();\n-\t\t\t// create a matcher for a comparison with a constant\n-\t\t\tComparisonExpressionMatcher matcher;\n-\t\t\t// match on a comparison type\n-\t\t\tmatcher.expr_type = make_unique<ComparisonExpressionTypeMatcher>();\n-\t\t\t// match on a constant comparison with the indexed expression\n-\t\t\tmatcher.matchers.push_back(make_unique<ExpressionEqualityMatcher>(index_expression.get()));\n-\t\t\tmatcher.matchers.push_back(make_unique<ConstantExpressionMatcher>());\n-\n-\t\t\tmatcher.policy = SetMatcher::Policy::UNORDERED;\n-\n-\t\t\tvector<Expression *> bindings;\n-\t\t\tif (matcher.Match(expr, bindings)) {\n-\t\t\t\t// range or equality comparison with constant value\n-\t\t\t\t// we can use our index here\n-\t\t\t\t// bindings[0] = the expression\n-\t\t\t\t// bindings[1] = the index expression\n-\t\t\t\t// bindings[2] = the constant\n-\t\t\t\tauto comparison = (BoundComparisonExpression *)bindings[0];\n-\t\t\t\tassert(bindings[0]->GetExpressionClass() == ExpressionClass::BOUND_COMPARISON);\n-\t\t\t\tassert(bindings[2]->type == ExpressionType::VALUE_CONSTANT);\n-\n-\t\t\t\tauto constant_value = ((BoundConstantExpression *)bindings[2])->value;\n-\t\t\t\tauto comparison_type = comparison->type;\n-\t\t\t\tif (comparison->left->type == ExpressionType::VALUE_CONSTANT) {\n-\t\t\t\t\t// the expression is on the right side, we flip them around\n-\t\t\t\t\tcomparison_type = FlipComparisionExpression(comparison_type);\n-\t\t\t\t}\n-\t\t\t\tif (comparison_type == ExpressionType::COMPARE_EQUAL) {\n-\t\t\t\t\t// equality value\n-\t\t\t\t\t// equality overrides any other bounds so we just break here\n-\t\t\t\t\tequal_value = constant_value;\n-\t\t\t\t\tbreak;\n-\t\t\t\t} else if (comparison_type == ExpressionType::COMPARE_GREATERTHANOREQUALTO ||\n-\t\t\t\t           comparison_type == ExpressionType::COMPARE_GREATERTHAN) {\n-\t\t\t\t\t// greater than means this is a lower bound\n-\t\t\t\t\tlow_value = constant_value;\n-\t\t\t\t\tlow_comparison_type = comparison_type;\n-\t\t\t\t} else {\n-\t\t\t\t\t// smaller than means this is an upper bound\n-\t\t\t\t\thigh_value = constant_value;\n-\t\t\t\t\thigh_comparison_type = comparison_type;\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n-\t\tif (!equal_value.is_null || !low_value.is_null || !high_value.is_null) {\n-\t\t\tauto logical_index_scan = make_unique<LogicalIndexScan>(*get->table, *get->table->storage, *index,\n-\t\t\t                                                        get->column_ids, get->table_index);\n-\t\t\tif (!equal_value.is_null) {\n-\t\t\t\tlogical_index_scan->equal_value = equal_value;\n-\t\t\t\tlogical_index_scan->equal_index = true;\n-\t\t\t}\n-\t\t\tif (!low_value.is_null) {\n-\t\t\t\tlogical_index_scan->low_value = low_value;\n-\t\t\t\tlogical_index_scan->low_index = true;\n-\t\t\t\tlogical_index_scan->low_expression_type = low_comparison_type;\n-\t\t\t}\n-\t\t\tif (!high_value.is_null) {\n-\t\t\t\tlogical_index_scan->high_value = high_value;\n-\t\t\t\tlogical_index_scan->high_index = true;\n-\t\t\t\tlogical_index_scan->high_expression_type = high_comparison_type;\n-\t\t\t}\n-\t\t\top->children[0] = move(logical_index_scan);\n-\t\t\tbreak;\n-\t\t}\n-\t}\n-\treturn op;\n-}\n-\n-} // namespace duckdb\ndiff --git a/src/optimizer/join_order_optimizer.cpp b/src/optimizer/join_order_optimizer.cpp\nindex 2c59877580ac..d83b04aee817 100644\n--- a/src/optimizer/join_order_optimizer.cpp\n+++ b/src/optimizer/join_order_optimizer.cpp\n@@ -143,11 +143,11 @@ bool JoinOrderOptimizer::ExtractJoinRelations(LogicalOperator &input_op, vector<\n \t\trelation_mapping[get->table_index] = relations.size();\n \t\trelations.push_back(move(relation));\n \t\treturn true;\n-\t} else if (op->type == LogicalOperatorType::TABLE_FUNCTION) {\n+\t} else if (op->type == LogicalOperatorType::DUMMY_SCAN) {\n \t\t// table function call, add to set of relations\n-\t\tauto table_function = (LogicalTableFunction *)op;\n+\t\tauto dummy_scan = (LogicalDummyScan *)op;\n \t\tauto relation = make_unique<SingleJoinRelation>(&input_op, parent);\n-\t\trelation_mapping[table_function->table_index] = relations.size();\n+\t\trelation_mapping[dummy_scan->table_index] = relations.size();\n \t\trelations.push_back(move(relation));\n \t\treturn true;\n \t} else if (op->type == LogicalOperatorType::PROJECTION) {\ndiff --git a/src/optimizer/optimizer.cpp b/src/optimizer/optimizer.cpp\nindex cc46691698da..1ef7ee8f6fa5 100644\n--- a/src/optimizer/optimizer.cpp\n+++ b/src/optimizer/optimizer.cpp\n@@ -7,7 +7,6 @@\n #include \"duckdb/optimizer/expression_heuristics.hpp\"\n #include \"duckdb/optimizer/filter_pushdown.hpp\"\n #include \"duckdb/optimizer/in_clause_rewriter.hpp\"\n-#include \"duckdb/optimizer/index_scan.hpp\"\n #include \"duckdb/optimizer/join_order_optimizer.hpp\"\n #include \"duckdb/optimizer/regex_range_filter.hpp\"\n #include \"duckdb/optimizer/remove_unused_columns.hpp\"\n@@ -51,12 +50,6 @@ unique_ptr<LogicalOperator> Optimizer::Optimize(unique_ptr<LogicalOperator> plan\n \tplan = filter_pushdown.Rewrite(move(plan));\n \tcontext.profiler.EndPhase();\n \n-\t// check if filters match with existing indexes, if true transforms filters to index scans\n-\tcontext.profiler.StartPhase(\"index_scan\");\n-\tIndexScan index_scan;\n-\tplan = index_scan.Optimize(move(plan));\n-\tcontext.profiler.EndPhase();\n-\n \tcontext.profiler.StartPhase(\"regex_range\");\n \tRegexRangeFilter regex_opt;\n \tplan = regex_opt.Rewrite(move(plan));\ndiff --git a/src/optimizer/pushdown/pushdown_get.cpp b/src/optimizer/pushdown/pushdown_get.cpp\nindex aa1c4237ef52..9a4e054722a0 100644\n--- a/src/optimizer/pushdown/pushdown_get.cpp\n+++ b/src/optimizer/pushdown/pushdown_get.cpp\n@@ -1,70 +1,51 @@\n #include \"duckdb/optimizer/filter_pushdown.hpp\"\n #include \"duckdb/planner/operator/logical_filter.hpp\"\n #include \"duckdb/planner/operator/logical_get.hpp\"\n+#include \"duckdb/planner/expression/bound_columnref_expression.hpp\"\n #include \"duckdb/storage/data_table.hpp\"\n+#include \"duckdb/optimizer/optimizer.hpp\"\n+\n namespace duckdb {\n using namespace std;\n \n unique_ptr<LogicalOperator> FilterPushdown::PushdownGet(unique_ptr<LogicalOperator> op) {\n \tassert(op->type == LogicalOperatorType::GET);\n \tauto &get = (LogicalGet &)*op;\n-\tif (!get.tableFilters.empty()) {\n-\t\tif (!filters.empty()) {\n-\t\t\t//! We didn't managed to push down all filters to table scan\n-\t\t\tauto logicalFilter = make_unique<LogicalFilter>();\n-\t\t\tfor (auto &f : filters) {\n-\t\t\t\tlogicalFilter->expressions.push_back(move(f->filter));\n-\t\t\t}\n-\t\t\tlogicalFilter->children.push_back(move(op));\n-\t\t\treturn move(logicalFilter);\n-\t\t} else {\n-\t\t\treturn op;\n+\t// first push down arbitrary filters\n+\tif (get.function.pushdown_complex_filter) {\n+\t\t// for the remaining filters, check if we can push any of them into the scan as well\n+\t\tvector<unique_ptr<Expression>> expressions;\n+\t\tfor (idx_t i = 0; i < filters.size(); i++) {\n+\t\t\texpressions.push_back(move(filters[i]->filter));\n \t\t}\n-\t}\n-\t//! FIXME: We only need to skip if the index is in the column being filtered\n-\tif (!get.table || !get.table->storage->info->indexes.empty()) {\n-\t\t//! now push any existing filters\n-\t\tif (filters.empty()) {\n-\t\t\t//! no filters to push\n-\t\t\treturn op;\n+\t\tfilters.clear();\n+\n+\t\tget.function.pushdown_complex_filter(optimizer.context, get, get.bind_data.get(), expressions);\n+\n+\t\tif (expressions.size() == 0) {\n+\t\t\treturn move(op);\n \t\t}\n-\t\tauto filter = make_unique<LogicalFilter>();\n-\t\tfor (auto &f : filters) {\n-\t\t\tfilter->expressions.push_back(move(f->filter));\n+\t\t// re-generate the filters\n+\t\tfor (auto &expr : expressions) {\n+\t\t\tauto f = make_unique<Filter>();\n+\t\t\tf->filter = move(expr);\n+\t\t\tf->ExtractBindings();\n+\t\t\tfilters.push_back(move(f));\n \t\t}\n-\t\tfilter->children.push_back(move(op));\n-\t\treturn move(filter);\n+\t}\n+\tif (!get.tableFilters.empty() || !get.function.filter_pushdown) {\n+\t\t// the table function does not support filter pushdown: push a LogicalFilter on top\n+\t\treturn FinishPushdown(move(op));\n \t}\n \tPushFilters();\n \n-\tvector<unique_ptr<Filter>> filtersToPushDown;\n-\tget.tableFilters = combiner.GenerateTableScanFilters(\n-\t    [&](unique_ptr<Expression> filter) {\n-\t\t    auto f = make_unique<Filter>();\n-\t\t    f->filter = move(filter);\n-\t\t    f->ExtractBindings();\n-\t\t    filtersToPushDown.push_back(move(f));\n-\t    },\n-\t    get.column_ids);\n+\tget.tableFilters = combiner.GenerateTableScanFilters(get.column_ids);\n \tfor (auto &f : get.tableFilters) {\n \t\tf.column_index = get.column_ids[f.column_index];\n \t}\n \n \tGenerateFilters();\n-\tfor (auto &f : filtersToPushDown) {\n-\t\tget.expressions.push_back(move(f->filter));\n-\t}\n-\n-\tif (!filters.empty()) {\n-\t\t//! We didn't managed to push down all filters to table scan\n-\t\tauto logicalFilter = make_unique<LogicalFilter>();\n-\t\tfor (auto &f : filters) {\n-\t\t\tlogicalFilter->expressions.push_back(move(f->filter));\n-\t\t}\n-\t\tlogicalFilter->children.push_back(move(op));\n-\t\treturn move(logicalFilter);\n-\t}\n-\treturn op;\n+\treturn FinishPushdown(move(op));\n }\n \n } // namespace duckdb\ndiff --git a/src/optimizer/remove_unused_columns.cpp b/src/optimizer/remove_unused_columns.cpp\nindex 4b9c44fd7641..0de8ce22b8a9 100644\n--- a/src/optimizer/remove_unused_columns.cpp\n+++ b/src/optimizer/remove_unused_columns.cpp\n@@ -10,7 +10,6 @@\n #include \"duckdb/planner/operator/logical_comparison_join.hpp\"\n #include \"duckdb/planner/operator/logical_filter.hpp\"\n #include \"duckdb/planner/operator/logical_get.hpp\"\n-#include \"duckdb/planner/operator/logical_table_function.hpp\"\n #include \"duckdb/planner/operator/logical_projection.hpp\"\n #include \"duckdb/planner/column_binding_map.hpp\"\n \n@@ -140,6 +139,24 @@ void RemoveUnusedColumns::VisitOperator(LogicalOperator &op) {\n \t\tLogicalOperatorVisitor::VisitOperatorExpressions(op);\n \t\tif (!everything_referenced) {\n \t\t\tauto &get = (LogicalGet &)op;\n+\t\t\t// for every table filter, push a column binding into the column references map to prevent the column from\n+\t\t\t// being projected out\n+\t\t\tfor (auto &filter : get.tableFilters) {\n+\t\t\t\tidx_t index = INVALID_INDEX;\n+\t\t\t\tfor (idx_t i = 0; i < get.column_ids.size(); i++) {\n+\t\t\t\t\tif (get.column_ids[i] == filter.column_index) {\n+\t\t\t\t\t\tindex = i;\n+\t\t\t\t\t\tbreak;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t\tif (index == INVALID_INDEX) {\n+\t\t\t\t\tthrow InternalException(\"Could not find column index for table filter\");\n+\t\t\t\t}\n+\t\t\t\tColumnBinding filter_binding(get.table_index, index);\n+\t\t\t\tif (column_references.find(filter_binding) == column_references.end()) {\n+\t\t\t\t\tcolumn_references.insert(make_pair(filter_binding, vector<BoundColumnRefExpression *>()));\n+\t\t\t\t}\n+\t\t\t}\n \t\t\t// table scan: figure out which columns are referenced\n \t\t\tClearUnusedExpressions(get.column_ids, get.table_index);\n \n@@ -151,19 +168,6 @@ void RemoveUnusedColumns::VisitOperator(LogicalOperator &op) {\n \t\t\t}\n \t\t}\n \t\treturn;\n-\tcase LogicalOperatorType::TABLE_FUNCTION: {\n-\t\tLogicalOperatorVisitor::VisitOperatorExpressions(op);\n-\t\tauto &fun = (LogicalTableFunction &)op;\n-\t\tif (!everything_referenced && fun.function.supports_projection) {\n-\t\t\t// table producing function: figure out which columns are referenced\n-\t\t\tClearUnusedExpressions(fun.column_ids, fun.table_index);\n-\t\t\t// see above for this special case\n-\t\t\tif (fun.column_ids.size() == 0) {\n-\t\t\t\tfun.column_ids.push_back(COLUMN_IDENTIFIER_ROW_ID);\n-\t\t\t}\n-\t\t}\n-\t\treturn;\n-\t}\n \tcase LogicalOperatorType::DISTINCT: {\n \t\t// distinct, all projected columns are used for the DISTINCT computation\n \t\t// mark all columns as used and continue to the children\ndiff --git a/src/parallel/pipeline.cpp b/src/parallel/pipeline.cpp\nindex 9f69a66ef152..6191dbbd4b35 100644\n--- a/src/parallel/pipeline.cpp\n+++ b/src/parallel/pipeline.cpp\n@@ -31,7 +31,8 @@ class PipelineTask : public Task {\n };\n \n Pipeline::Pipeline(Executor &executor_)\n-    : executor(executor_), finished_dependencies(0), finished(false), finished_tasks(0), total_tasks(0), recursive_cte(nullptr) {\n+    : executor(executor_), finished_dependencies(0), finished(false), finished_tasks(0), total_tasks(0),\n+      recursive_cte(nullptr) {\n }\n \n void Pipeline::Execute(TaskContext &task) {\n@@ -72,7 +73,7 @@ void Pipeline::FinishTask() {\n \tif (current_finished == total_tasks) {\n \t\ttry {\n \t\t\tsink->Finalize(executor.context, move(sink_state));\n-\t\t} catch(std::exception &ex) {\n+\t\t} catch (std::exception &ex) {\n \t\t\texecutor.PushError(ex.what());\n \t\t} catch (...) {\n \t\t\texecutor.PushError(\"Unknown exception in Finalize!\");\n@@ -96,7 +97,7 @@ bool Pipeline::ScheduleOperator(PhysicalOperator *op) {\n \tcase PhysicalOperatorType::HASH_JOIN:\n \t\t// filter, projection or hash probe: continue in children\n \t\treturn ScheduleOperator(op->children[0].get());\n-\tcase PhysicalOperatorType::SEQ_SCAN: {\n+\tcase PhysicalOperatorType::TABLE_SCAN: {\n \t\t// we reached a scan: split it up into parts and schedule the parts\n \t\tauto &scheduler = TaskScheduler::GetScheduler(executor.context);\n \ndiff --git a/src/planner/bind_context.cpp b/src/planner/bind_context.cpp\nindex 4d0a69517f60..23b585938f13 100644\n--- a/src/planner/bind_context.cpp\n+++ b/src/planner/bind_context.cpp\n@@ -101,8 +101,14 @@ void BindContext::AddBinding(const string &alias, unique_ptr<Binding> binding) {\n \tbindings[alias] = move(binding);\n }\n \n-void BindContext::AddBaseTable(idx_t index, const string &alias, TableCatalogEntry &table, LogicalGet &get) {\n-\tAddBinding(alias, make_unique<TableBinding>(alias, table, get, index));\n+void BindContext::AddBaseTable(idx_t index, const string &alias, vector<string> names, vector<LogicalType> types,\n+                               unordered_map<string, column_t> name_map, LogicalGet &get) {\n+\tAddBinding(alias, make_unique<TableBinding>(alias, move(types), move(names), move(name_map), get, index));\n+}\n+\n+void BindContext::AddTableFunction(idx_t index, const string &alias, vector<string> names, vector<LogicalType> types,\n+                                   LogicalGet &get) {\n+\tAddBinding(alias, make_unique<TableBinding>(alias, move(types), move(names), get, index));\n }\n \n void BindContext::AddSubquery(idx_t index, const string &alias, SubqueryRef &ref, BoundQueryNode &subquery) {\n@@ -123,11 +129,11 @@ void BindContext::AddSubquery(idx_t index, const string &alias, SubqueryRef &ref\n }\n \n void BindContext::AddGenericBinding(idx_t index, const string &alias, vector<string> names, vector<LogicalType> types) {\n-\tAddBinding(alias, make_unique<GenericBinding>(alias, move(types), move(names), index));\n+\tAddBinding(alias, make_unique<Binding>(alias, move(types), move(names), index));\n }\n \n void BindContext::AddCTEBinding(idx_t index, const string &alias, vector<string> names, vector<LogicalType> types) {\n-\tauto binding = make_shared<GenericBinding>(alias, move(types), move(names), index);\n+\tauto binding = make_shared<Binding>(alias, move(types), move(names), index);\n \n \tif (cte_bindings.find(alias) != cte_bindings.end()) {\n \t\tthrow BinderException(\"Duplicate alias \\\"%s\\\" in query!\", alias);\ndiff --git a/src/planner/binder/statement/bind_call.cpp b/src/planner/binder/statement/bind_call.cpp\nindex 0a1ed1197887..96ee958423b1 100644\n--- a/src/planner/binder/statement/bind_call.cpp\n+++ b/src/planner/binder/statement/bind_call.cpp\n@@ -2,6 +2,7 @@\n #include \"duckdb/parser/statement/call_statement.hpp\"\n #include \"duckdb/parser/tableref/table_function_ref.hpp\"\n #include \"duckdb/planner/tableref/bound_table_function.hpp\"\n+#include \"duckdb/planner/operator/logical_get.hpp\"\n \n namespace duckdb {\n using namespace std;\n@@ -14,9 +15,14 @@ BoundStatement Binder::Bind(CallStatement &stmt) {\n \n \tauto bound_func = Bind(ref);\n \tauto &bound_table_func = (BoundTableFunction &)*bound_func;\n+\tauto &get = (LogicalGet &)*bound_table_func.get;\n+\tassert(get.returned_types.size() > 0);\n+\tfor (idx_t i = 0; i < get.returned_types.size(); i++) {\n+\t\tget.column_ids.push_back(i);\n+\t}\n \n-\tresult.types = bound_table_func.return_types;\n-\tresult.names = bound_table_func.names;\n+\tresult.types = get.returned_types;\n+\tresult.names = get.names;\n \tresult.plan = CreatePlan(*bound_func);\n \treturn result;\n }\ndiff --git a/src/planner/binder/statement/bind_create.cpp b/src/planner/binder/statement/bind_create.cpp\nindex ed1534fa9c72..2586d522fd6e 100644\n--- a/src/planner/binder/statement/bind_create.cpp\n+++ b/src/planner/binder/statement/bind_create.cpp\n@@ -87,6 +87,8 @@ BoundStatement Binder::Bind(CreateStatement &stmt) {\n \t\tif (bound_table->type != TableReferenceType::BASE_TABLE) {\n \t\t\tthrow BinderException(\"Can only delete from base table!\");\n \t\t}\n+\t\tauto &table_binding = (BoundBaseTableRef &)*bound_table;\n+\t\tauto table = table_binding.table;\n \t\t// bind the index expressions\n \t\tvector<unique_ptr<Expression>> expressions;\n \t\tIndexBinder binder(*this, context);\n@@ -107,7 +109,7 @@ BoundStatement Binder::Bind(CreateStatement &stmt) {\n \t\t// this gives us a logical table scan\n \t\t// we take the required columns from here\n \t\t// create the logical operator\n-\t\tresult.plan = make_unique<LogicalCreateIndex>(*get.table, get.column_ids, move(expressions),\n+\t\tresult.plan = make_unique<LogicalCreateIndex>(*table, get.column_ids, move(expressions),\n \t\t                                              unique_ptr_cast<CreateInfo, CreateIndexInfo>(move(stmt.info)));\n \t\tbreak;\n \t}\ndiff --git a/src/planner/binder/statement/bind_delete.cpp b/src/planner/binder/statement/bind_delete.cpp\nindex 115d98bf3a23..1da159203c6e 100644\n--- a/src/planner/binder/statement/bind_delete.cpp\n+++ b/src/planner/binder/statement/bind_delete.cpp\n@@ -5,6 +5,7 @@\n #include \"duckdb/planner/operator/logical_filter.hpp\"\n #include \"duckdb/planner/operator/logical_get.hpp\"\n #include \"duckdb/planner/bound_tableref.hpp\"\n+#include \"duckdb/planner/tableref/bound_basetableref.hpp\"\n \n namespace duckdb {\n using namespace std;\n@@ -17,11 +18,14 @@ BoundStatement Binder::Bind(DeleteStatement &stmt) {\n \tif (bound_table->type != TableReferenceType::BASE_TABLE) {\n \t\tthrow BinderException(\"Can only delete from base table!\");\n \t}\n+\tauto &table_binding = (BoundBaseTableRef &)*bound_table;\n+\tauto table = table_binding.table;\n+\n \tauto root = CreatePlan(*bound_table);\n \tauto &get = (LogicalGet &)*root;\n-\tassert(root->type == LogicalOperatorType::GET && get.table);\n+\tassert(root->type == LogicalOperatorType::GET);\n \n-\tif (!get.table->temporary) {\n+\tif (!table->temporary) {\n \t\t// delete from persistent table: not read only!\n \t\tthis->read_only = false;\n \t}\n@@ -37,7 +41,7 @@ BoundStatement Binder::Bind(DeleteStatement &stmt) {\n \t\troot = move(filter);\n \t}\n \t// create the delete node\n-\tauto del = make_unique<LogicalDelete>(get.table);\n+\tauto del = make_unique<LogicalDelete>(table);\n \tdel->AddChild(move(root));\n \n \t// set up the delete expression\ndiff --git a/src/planner/binder/statement/bind_update.cpp b/src/planner/binder/statement/bind_update.cpp\nindex 0689be8bacd2..4ef6a8de956a 100644\n--- a/src/planner/binder/statement/bind_update.cpp\n+++ b/src/planner/binder/statement/bind_update.cpp\n@@ -12,6 +12,7 @@\n #include \"duckdb/parser/expression/columnref_expression.hpp\"\n #include \"duckdb/storage/data_table.hpp\"\n #include \"duckdb/planner/bound_tableref.hpp\"\n+#include \"duckdb/planner/tableref/bound_basetableref.hpp\"\n \n #include <algorithm>\n \n@@ -94,11 +95,13 @@ BoundStatement Binder::Bind(UpdateStatement &stmt) {\n \tif (bound_table->type != TableReferenceType::BASE_TABLE) {\n \t\tthrow BinderException(\"Can only update base table!\");\n \t}\n+\tauto &table_binding = (BoundBaseTableRef &)*bound_table;\n+\tauto table = table_binding.table;\n+\n \tauto root = CreatePlan(*bound_table);\n \tauto &get = (LogicalGet &)*root;\n-\tassert(root->type == LogicalOperatorType::GET && get.table);\n+\tassert(root->type == LogicalOperatorType::GET);\n \n-\tauto &table = get.table;\n \tif (!table->temporary) {\n \t\t// update of persistent table: not read only!\n \t\tthis->read_only = false;\ndiff --git a/src/planner/binder/tableref/bind_basetableref.cpp b/src/planner/binder/tableref/bind_basetableref.cpp\nindex 5fd695527984..7f3cb2c8ed11 100644\n--- a/src/planner/binder/tableref/bind_basetableref.cpp\n+++ b/src/planner/binder/tableref/bind_basetableref.cpp\n@@ -7,6 +7,7 @@\n #include \"duckdb/planner/tableref/bound_cteref.hpp\"\n #include \"duckdb/planner/operator/logical_get.hpp\"\n #include \"duckdb/parser/statement/select_statement.hpp\"\n+#include \"duckdb/function/table/table_scan.hpp\"\n \n namespace duckdb {\n using namespace std;\n@@ -29,7 +30,7 @@ unique_ptr<BoundTableRef> Binder::Bind(BaseTableRef &ref) {\n \t\t\t// This can only be the case if there is a recursive CTE present.\n \t\t\tauto index = GenerateTableIndex();\n \t\t\tauto result = make_unique<BoundCTERef>(index, ctebinding->index);\n-\t\t\tauto b = (GenericBinding *)ctebinding;\n+\t\t\tauto b = ctebinding;\n \n \t\t\tbind_context.AddGenericBinding(index, ref.alias.empty() ? ref.table_name : ref.alias, b->names, b->types);\n \t\t\t// Update references to CTE\n@@ -51,10 +52,21 @@ unique_ptr<BoundTableRef> Binder::Bind(BaseTableRef &ref) {\n \t\tauto table_index = GenerateTableIndex();\n \t\tauto table = (TableCatalogEntry *)table_or_view;\n \n-\t\tauto logical_get = make_unique<LogicalGet>(table, table_index);\n+\t\tauto scan_function = TableScanFunction::GetFunction();\n+\t\tauto bind_data = make_unique<TableScanBindData>(table);\n+\t\tvector<LogicalType> table_types;\n+\t\tvector<string> table_names;\n+\t\tfor (auto &col : table->columns) {\n+\t\t\ttable_types.push_back(col.type);\n+\t\t\ttable_names.push_back(col.name);\n+\t\t}\n+\n+\t\tauto logical_get =\n+\t\t    make_unique<LogicalGet>(table_index, scan_function, move(bind_data), table_types, table_names);\n \t\tauto alias = ref.alias.empty() ? ref.table_name : ref.alias;\n-\t\tbind_context.AddBaseTable(table_index, alias, *table, *logical_get);\n-\t\treturn make_unique_base<BoundTableRef, BoundBaseTableRef>(move(logical_get));\n+\t\tbind_context.AddBaseTable(table_index, alias, move(table_names), move(table_types), table->name_map,\n+\t\t                          *logical_get);\n+\t\treturn make_unique_base<BoundTableRef, BoundBaseTableRef>(table, move(logical_get));\n \t}\n \tcase CatalogType::VIEW_ENTRY: {\n \t\t// the node is a view: get the query that the view represents\ndiff --git a/src/planner/binder/tableref/bind_table_function.cpp b/src/planner/binder/tableref/bind_table_function.cpp\nindex b6b572f10887..18cc90a3b902 100644\n--- a/src/planner/binder/tableref/bind_table_function.cpp\n+++ b/src/planner/binder/tableref/bind_table_function.cpp\n@@ -5,6 +5,7 @@\n #include \"duckdb/parser/expression/columnref_expression.hpp\"\n #include \"duckdb/parser/expression/comparison_expression.hpp\"\n #include \"duckdb/planner/expression_binder/constant_binder.hpp\"\n+#include \"duckdb/planner/operator/logical_get.hpp\"\n #include \"duckdb/planner/tableref/bound_table_function.hpp\"\n #include \"duckdb/execution/expression_executor.hpp\"\n #include \"duckdb/common/algorithm.hpp\"\n@@ -72,29 +73,31 @@ unique_ptr<BoundTableRef> Binder::Bind(TableFunctionRef &ref) {\n \t}\n \n \t// cast the parameters to the type of the function\n-\tauto result = make_unique<BoundTableFunction>(table_function, bind_index);\n \tfor (idx_t i = 0; i < arguments.size(); i++) {\n-\t\tif (table_function.arguments[i] == LogicalType::ANY) {\n-\t\t\tresult->parameters.push_back(move(parameters[i]));\n-\t\t} else {\n-\t\t\tresult->parameters.push_back(parameters[i].CastAs(table_function.arguments[i]));\n+\t\tif (table_function.arguments[i] != LogicalType::ANY) {\n+\t\t\tparameters[i] = parameters[i].CastAs(table_function.arguments[i]);\n \t\t}\n \t}\n \n \t// perform the binding\n-\tresult->bind_data =\n-\t    table_function.bind(context, result->parameters, named_parameters, result->return_types, result->names);\n-\tassert(result->return_types.size() == result->names.size());\n-\tassert(result->return_types.size() > 0);\n-\tvector<string> names = result->names;\n-\tfor (idx_t i = 0; i < ref.column_name_alias.size() && i < result->names.size(); i++) {\n-\t\tnames[i] = ref.column_name_alias[i];\n+\tunique_ptr<FunctionData> bind_data;\n+\tvector<LogicalType> return_types;\n+\tvector<string> return_names;\n+\tif (table_function.bind) {\n+\t\tbind_data = table_function.bind(context, parameters, named_parameters, return_types, return_names);\n+\t}\n+\tassert(return_types.size() == return_names.size());\n+\tassert(return_types.size() > 0);\n+\t// overwrite the names with any supplied aliases\n+\tfor (idx_t i = 0; i < ref.column_name_alias.size() && i < return_names.size(); i++) {\n+\t\treturn_names[i] = ref.column_name_alias[i];\n \t}\n+\tauto get = make_unique<LogicalGet>(bind_index, table_function, move(bind_data), return_types, return_names);\n \t// now add the table function to the bind context so its columns can be bound\n-\tbind_context.AddGenericBinding(bind_index, ref.alias.empty() ? fexpr->function_name : ref.alias, names,\n-\t                               result->return_types);\n+\tbind_context.AddTableFunction(bind_index, ref.alias.empty() ? fexpr->function_name : ref.alias, return_names,\n+\t                              return_types, *get);\n \n-\treturn move(result);\n+\treturn make_unique_base<BoundTableRef, BoundTableFunction>(move(get));\n }\n \n } // namespace duckdb\ndiff --git a/src/planner/binder/tableref/plan_dummytableref.cpp b/src/planner/binder/tableref/plan_dummytableref.cpp\nindex b85ae4bf9b44..e1705419f81a 100644\n--- a/src/planner/binder/tableref/plan_dummytableref.cpp\n+++ b/src/planner/binder/tableref/plan_dummytableref.cpp\n@@ -1,12 +1,12 @@\n #include \"duckdb/planner/binder.hpp\"\n-#include \"duckdb/planner/operator/logical_get.hpp\"\n+#include \"duckdb/planner/operator/logical_dummy_scan.hpp\"\n #include \"duckdb/planner/tableref/bound_dummytableref.hpp\"\n \n namespace duckdb {\n using namespace std;\n \n unique_ptr<LogicalOperator> Binder::CreatePlan(BoundEmptyTableRef &ref) {\n-\treturn make_unique<LogicalGet>(ref.bind_index);\n+\treturn make_unique<LogicalDummyScan>(ref.bind_index);\n }\n \n } // namespace duckdb\ndiff --git a/src/planner/binder/tableref/plan_expressionlistref.cpp b/src/planner/binder/tableref/plan_expressionlistref.cpp\nindex 3a77b2e0774b..cb8f0a7a573b 100644\n--- a/src/planner/binder/tableref/plan_expressionlistref.cpp\n+++ b/src/planner/binder/tableref/plan_expressionlistref.cpp\n@@ -1,13 +1,13 @@\n #include \"duckdb/planner/binder.hpp\"\n #include \"duckdb/planner/tableref/bound_expressionlistref.hpp\"\n #include \"duckdb/planner/operator/logical_expression_get.hpp\"\n-#include \"duckdb/planner/operator/logical_get.hpp\"\n+#include \"duckdb/planner/operator/logical_dummy_scan.hpp\"\n \n namespace duckdb {\n using namespace std;\n \n unique_ptr<LogicalOperator> Binder::CreatePlan(BoundExpressionListRef &ref) {\n-\tauto root = make_unique_base<LogicalOperator, LogicalGet>(0);\n+\tauto root = make_unique_base<LogicalOperator, LogicalDummyScan>(0);\n \t// values list, first plan any subqueries in the list\n \tfor (auto &expr_list : ref.values) {\n \t\tfor (auto &expr : expr_list) {\ndiff --git a/src/planner/binder/tableref/plan_table_function.cpp b/src/planner/binder/tableref/plan_table_function.cpp\nindex 44027c0b9c07..16906eda787b 100644\n--- a/src/planner/binder/tableref/plan_table_function.cpp\n+++ b/src/planner/binder/tableref/plan_table_function.cpp\n@@ -1,18 +1,11 @@\n #include \"duckdb/planner/binder.hpp\"\n-#include \"duckdb/planner/operator/logical_table_function.hpp\"\n #include \"duckdb/planner/tableref/bound_table_function.hpp\"\n \n namespace duckdb {\n using namespace std;\n \n unique_ptr<LogicalOperator> Binder::CreatePlan(BoundTableFunction &ref) {\n-\n-\tauto logical_fun = make_unique<LogicalTableFunction>(ref.function, ref.bind_index, move(ref.bind_data),\n-\t                                                     move(ref.parameters), ref.return_types, ref.names);\n-\tfor (idx_t i = 0; i < ref.return_types.size(); i++) {\n-\t\tlogical_fun->column_ids.push_back(i);\n-\t}\n-\treturn move(logical_fun);\n+\treturn move(ref.get);\n }\n \n } // namespace duckdb\ndiff --git a/src/planner/operator/CMakeLists.txt b/src/planner/operator/CMakeLists.txt\nindex 801abad051af..2e99f2126f83 100644\n--- a/src/planner/operator/CMakeLists.txt\n+++ b/src/planner/operator/CMakeLists.txt\n@@ -1,17 +1,18 @@\n-add_library_unity(duckdb_planner_operator\n-                  OBJECT\n-                  logical_aggregate.cpp\n-                  logical_empty_result.cpp\n-                  logical_any_join.cpp\n-                  logical_comparison_join.cpp\n-                  logical_cross_product.cpp\n-                  logical_filter.cpp\n-                  logical_get.cpp\n-                  logical_join.cpp\n-                  logical_projection.cpp\n-                  logical_table_function.cpp\n-                  logical_unnest.cpp\n-                  logical_window.cpp\n-                  logical_distinct.cpp)\n-set(ALL_OBJECT_FILES ${ALL_OBJECT_FILES}\n-                     $<TARGET_OBJECTS:duckdb_planner_operator> PARENT_SCOPE)\n+add_library_unity(\n+  duckdb_planner_operator\n+  OBJECT\n+  logical_aggregate.cpp\n+  logical_empty_result.cpp\n+  logical_any_join.cpp\n+  logical_comparison_join.cpp\n+  logical_cross_product.cpp\n+  logical_filter.cpp\n+  logical_get.cpp\n+  logical_join.cpp\n+  logical_projection.cpp\n+  logical_unnest.cpp\n+  logical_window.cpp\n+  logical_distinct.cpp)\n+set(ALL_OBJECT_FILES\n+    ${ALL_OBJECT_FILES} $<TARGET_OBJECTS:duckdb_planner_operator>\n+    PARENT_SCOPE)\ndiff --git a/src/planner/operator/logical_get.cpp b/src/planner/operator/logical_get.cpp\nindex e3218e6b33d8..8617e2844261 100644\n--- a/src/planner/operator/logical_get.cpp\n+++ b/src/planner/operator/logical_get.cpp\n@@ -2,31 +2,23 @@\n \n #include \"duckdb/catalog/catalog_entry/table_catalog_entry.hpp\"\n #include \"duckdb/storage/data_table.hpp\"\n+#include \"duckdb/planner/operator/logical_get.hpp\"\n \n namespace duckdb {\n using namespace std;\n \n-LogicalGet::LogicalGet(idx_t table_index)\n-    : LogicalOperator(LogicalOperatorType::GET), table(nullptr), table_index(table_index) {\n-}\n-LogicalGet::LogicalGet(TableCatalogEntry *table, idx_t table_index)\n-    : LogicalOperator(LogicalOperatorType::GET), table(table), table_index(table_index) {\n-}\n-LogicalGet::LogicalGet(TableCatalogEntry *table, idx_t table_index, vector<column_t> column_ids)\n-    : LogicalOperator(LogicalOperatorType::GET), table(table), table_index(table_index), column_ids(column_ids) {\n+LogicalGet::LogicalGet(idx_t table_index, TableFunction function, unique_ptr<FunctionData> bind_data,\n+                       vector<LogicalType> returned_types, vector<string> returned_names)\n+    : LogicalOperator(LogicalOperatorType::GET), table_index(table_index), function(move(function)),\n+      bind_data(move(bind_data)), returned_types(move(returned_types)), names(move(returned_names)) {\n }\n \n string LogicalGet::ParamsToString() const {\n-\tif (!table) {\n-\t\treturn \"\";\n-\t}\n-\treturn \"(\" + table->name + \")\";\n+\treturn string();\n+\t// return \"(\" + table->name + \")\";\n }\n \n vector<ColumnBinding> LogicalGet::GetColumnBindings() {\n-\tif (!table) {\n-\t\treturn {ColumnBinding(INVALID_INDEX, 0)};\n-\t}\n \tif (column_ids.size() == 0) {\n \t\treturn {ColumnBinding(table_index, 0)};\n \t}\n@@ -41,12 +33,18 @@ void LogicalGet::ResolveTypes() {\n \tif (column_ids.size() == 0) {\n \t\tcolumn_ids.push_back(COLUMN_IDENTIFIER_ROW_ID);\n \t}\n-\ttypes = table->GetTypes(column_ids);\n+\tfor (auto &index : column_ids) {\n+\t\tif (index == COLUMN_IDENTIFIER_ROW_ID) {\n+\t\t\ttypes.push_back(LOGICAL_ROW_TYPE);\n+\t\t} else {\n+\t\t\ttypes.push_back(returned_types[index]);\n+\t\t}\n+\t}\n }\n \n idx_t LogicalGet::EstimateCardinality() {\n-\tif (table) {\n-\t\treturn table->storage->info->cardinality;\n+\tif (function.cardinality) {\n+\t\treturn function.cardinality(bind_data.get());\n \t} else {\n \t\treturn 1;\n \t}\ndiff --git a/src/planner/operator/logical_table_function.cpp b/src/planner/operator/logical_table_function.cpp\ndeleted file mode 100644\nindex de5aa9075902..000000000000\n--- a/src/planner/operator/logical_table_function.cpp\n+++ /dev/null\n@@ -1,30 +0,0 @@\n-#include \"duckdb/planner/operator/logical_table_function.hpp\"\n-\n-#include \"duckdb/catalog/catalog_entry/table_function_catalog_entry.hpp\"\n-\n-namespace duckdb {\n-using namespace std;\n-\n-vector<ColumnBinding> LogicalTableFunction::GetColumnBindings() {\n-\tvector<ColumnBinding> result;\n-\tfor (idx_t i = 0; i < column_ids.size(); i++) {\n-\t\tresult.push_back(ColumnBinding(table_index, i));\n-\t}\n-\treturn result;\n-}\n-\n-void LogicalTableFunction::ResolveTypes() {\n-\tfor (auto col_idx : column_ids) {\n-\t\tif (col_idx == COLUMN_IDENTIFIER_ROW_ID) {\n-\t\t\ttypes.push_back(LOGICAL_ROW_TYPE);\n-\t\t\tcontinue;\n-\t\t}\n-\t\ttypes.push_back(return_types[col_idx]);\n-\t}\n-}\n-\n-string LogicalTableFunction::ParamsToString() const {\n-\treturn \"(\" + function.name + \")\";\n-}\n-\n-} // namespace duckdb\ndiff --git a/src/planner/table_binding.cpp b/src/planner/table_binding.cpp\nindex 9871c4400dd6..b52f61440d2b 100644\n--- a/src/planner/table_binding.cpp\n+++ b/src/planner/table_binding.cpp\n@@ -13,64 +13,11 @@\n namespace duckdb {\n using namespace std;\n \n-TableBinding::TableBinding(const string &alias, TableCatalogEntry &table, LogicalGet &get, idx_t index)\n-    : Binding(BindingType::TABLE, alias, index), table(table), get(get) {\n+Binding::Binding(const string &alias, idx_t index) : alias(alias), index(index) {\n }\n \n-bool TableBinding::HasMatchingBinding(const string &column_name) {\n-\treturn table.ColumnExists(column_name);\n-}\n-\n-BindResult TableBinding::Bind(ColumnRefExpression &colref, idx_t depth) {\n-\tauto entry = table.name_map.find(colref.column_name);\n-\tif (entry == table.name_map.end()) {\n-\t\treturn BindResult(StringUtil::Format(\"Table \\\"%s\\\" does not have a column named \\\"%s\\\"\", colref.table_name,\n-\t\t                                     colref.column_name));\n-\t}\n-\tauto col_index = entry->second;\n-\t// fetch the type of the column\n-\tLogicalType col_type;\n-\tif (entry->second == COLUMN_IDENTIFIER_ROW_ID) {\n-\t\t// row id: BIGINT type\n-\t\tcol_type = LogicalType::BIGINT;\n-\t} else {\n-\t\t// normal column: fetch type from base column\n-\t\tauto &col = table.columns[col_index];\n-\t\tcol_type = col.type;\n-\t}\n-\n-\tauto &column_ids = get.column_ids;\n-\t// check if the entry already exists in the column list for the table\n-\tColumnBinding binding;\n-\n-\tbinding.column_index = column_ids.size();\n-\tfor (idx_t i = 0; i < column_ids.size(); i++) {\n-\t\tif (column_ids[i] == col_index) {\n-\t\t\tbinding.column_index = i;\n-\t\t\tbreak;\n-\t\t}\n-\t}\n-\tif (binding.column_index == column_ids.size()) {\n-\t\t// column binding not found: add it to the list of bindings\n-\t\tcolumn_ids.push_back(col_index);\n-\t}\n-\tbinding.table_index = index;\n-\treturn BindResult(make_unique<BoundColumnRefExpression>(colref.GetName(), col_type, binding, depth));\n-}\n-\n-void TableBinding::GenerateAllColumnExpressions(BindContext &context,\n-                                                vector<unique_ptr<ParsedExpression>> &select_list) {\n-\tfor (auto &column : table.columns) {\n-\t\tif (context.BindingIsHidden(alias, column.name)) {\n-\t\t\tcontinue;\n-\t\t}\n-\t\tassert(!column.name.empty());\n-\t\tselect_list.push_back(make_unique<ColumnRefExpression>(column.name, alias));\n-\t}\n-}\n-\n-GenericBinding::GenericBinding(const string &alias, vector<LogicalType> coltypes, vector<string> colnames, idx_t index)\n-    : Binding(BindingType::GENERIC, alias, index), types(move(coltypes)), names(move(colnames)) {\n+Binding::Binding(const string &alias, vector<LogicalType> coltypes, vector<string> colnames, idx_t index)\n+    : alias(alias), index(index), types(move(coltypes)), names(move(colnames)) {\n \tassert(types.size() == names.size());\n \tfor (idx_t i = 0; i < names.size(); i++) {\n \t\tauto &name = names[i];\n@@ -83,12 +30,12 @@ GenericBinding::GenericBinding(const string &alias, vector<LogicalType> coltypes\n \tTableCatalogEntry::AddLowerCaseAliases(name_map);\n }\n \n-bool GenericBinding::HasMatchingBinding(const string &column_name) {\n+bool Binding::HasMatchingBinding(const string &column_name) {\n \tauto entry = name_map.find(column_name);\n \treturn entry != name_map.end();\n }\n \n-BindResult GenericBinding::Bind(ColumnRefExpression &colref, idx_t depth) {\n+BindResult Binding::Bind(ColumnRefExpression &colref, idx_t depth) {\n \tauto column_entry = name_map.find(colref.column_name);\n \tif (column_entry == name_map.end()) {\n \t\treturn BindResult(StringUtil::Format(\"Values list \\\"%s\\\" does not have a column named \\\"%s\\\"\", alias.c_str(),\n@@ -101,8 +48,7 @@ BindResult GenericBinding::Bind(ColumnRefExpression &colref, idx_t depth) {\n \treturn BindResult(make_unique<BoundColumnRefExpression>(colref.GetName(), sql_type, binding, depth));\n }\n \n-void GenericBinding::GenerateAllColumnExpressions(BindContext &context,\n-                                                  vector<unique_ptr<ParsedExpression>> &select_list) {\n+void Binding::GenerateAllColumnExpressions(BindContext &context, vector<unique_ptr<ParsedExpression>> &select_list) {\n \tfor (auto &column_name : names) {\n \t\tassert(!column_name.empty());\n \t\tif (context.BindingIsHidden(alias, column_name)) {\n@@ -112,4 +58,51 @@ void GenericBinding::GenerateAllColumnExpressions(BindContext &context,\n \t}\n }\n \n+TableBinding::TableBinding(const string &alias, vector<LogicalType> types_, vector<string> names_, LogicalGet &get,\n+                           idx_t index)\n+    : Binding(alias, move(types_), move(names_), index), get(get) {\n+}\n+\n+TableBinding::TableBinding(const string &alias, vector<LogicalType> types, vector<string> names,\n+                           unordered_map<string, column_t> name_map, LogicalGet &get, idx_t index)\n+    : TableBinding(alias, move(types), move(names), get, index) {\n+\tthis->name_map = move(name_map);\n+}\n+\n+BindResult TableBinding::Bind(ColumnRefExpression &colref, idx_t depth) {\n+\tauto entry = name_map.find(colref.column_name);\n+\tif (entry == name_map.end()) {\n+\t\treturn BindResult(StringUtil::Format(\"Table \\\"%s\\\" does not have a column named \\\"%s\\\"\", colref.table_name,\n+\t\t                                     colref.column_name));\n+\t}\n+\tauto col_index = entry->second;\n+\t// fetch the type of the column\n+\tLogicalType col_type;\n+\tif (entry->second == COLUMN_IDENTIFIER_ROW_ID) {\n+\t\t// row id: BIGINT type\n+\t\tcol_type = LogicalType::BIGINT;\n+\t} else {\n+\t\t// normal column: fetch type from base column\n+\t\tcol_type = types[col_index];\n+\t}\n+\n+\tauto &column_ids = get.column_ids;\n+\t// check if the entry already exists in the column list for the table\n+\tColumnBinding binding;\n+\n+\tbinding.column_index = column_ids.size();\n+\tfor (idx_t i = 0; i < column_ids.size(); i++) {\n+\t\tif (column_ids[i] == col_index) {\n+\t\t\tbinding.column_index = i;\n+\t\t\tbreak;\n+\t\t}\n+\t}\n+\tif (binding.column_index == column_ids.size()) {\n+\t\t// column binding not found: add it to the list of bindings\n+\t\tcolumn_ids.push_back(col_index);\n+\t}\n+\tbinding.table_index = index;\n+\treturn BindResult(make_unique<BoundColumnRefExpression>(colref.GetName(), col_type, binding, depth));\n+}\n+\n } // namespace duckdb\ndiff --git a/src/storage/data_table.cpp b/src/storage/data_table.cpp\nindex 93a3a8715347..1ca4d8a6af7f 100644\n--- a/src/storage/data_table.cpp\n+++ b/src/storage/data_table.cpp\n@@ -514,51 +514,14 @@ bool DataTable::ScanBaseTable(Transaction &transaction, DataChunk &result, Table\n \treturn true;\n }\n \n-//===--------------------------------------------------------------------===//\n-// Index Scan\n-//===--------------------------------------------------------------------===//\n-void DataTable::InitializeIndexScan(Transaction &transaction, TableIndexScanState &state, Index &index,\n-                                    vector<column_t> column_ids) {\n-\tstate.index = &index;\n-\tstate.column_ids = move(column_ids);\n-\ttransaction.storage.InitializeScan(this, state.local_state);\n-}\n-\n-void DataTable::InitializeIndexScan(Transaction &transaction, TableIndexScanState &state, Index &index, Value value,\n-                                    ExpressionType expr_type, vector<column_t> column_ids) {\n-\tInitializeIndexScan(transaction, state, index, move(column_ids));\n-\tstate.index_state = index.InitializeScanSinglePredicate(transaction, state.column_ids, value, expr_type);\n-}\n-\n-void DataTable::InitializeIndexScan(Transaction &transaction, TableIndexScanState &state, Index &index, Value low_value,\n-                                    ExpressionType low_type, Value high_value, ExpressionType high_type,\n-                                    vector<column_t> column_ids) {\n-\tInitializeIndexScan(transaction, state, index, move(column_ids));\n-\tstate.index_state =\n-\t    index.InitializeScanTwoPredicates(transaction, state.column_ids, low_value, low_type, high_value, high_type);\n-}\n-\n-void DataTable::IndexScan(Transaction &transaction, DataChunk &result, TableIndexScanState &state) {\n-\t// clear any previously pinned blocks\n-\tstate.fetch_state.handles.clear();\n-\t// scan the index\n-\tstate.index->Scan(transaction, *this, state, result);\n-\tif (result.size() > 0) {\n-\t\treturn;\n-\t}\n-\t// scan the local structure\n-\ttransaction.storage.Scan(state.local_state, state.column_ids, result);\n-}\n-\n //===--------------------------------------------------------------------===//\n // Fetch\n //===--------------------------------------------------------------------===//\n void DataTable::Fetch(Transaction &transaction, DataChunk &result, vector<column_t> &column_ids,\n-                      Vector &row_identifiers, idx_t fetch_count, TableIndexScanState &state) {\n+                      Vector &row_identifiers, idx_t fetch_count, ColumnFetchState &state) {\n \t// first figure out which row identifiers we should use for this transaction by looking at the VersionManagers\n \trow_t rows[STANDARD_VECTOR_SIZE];\n \tidx_t count = FetchRows(transaction, row_identifiers, fetch_count, rows);\n-\n \tif (count == 0) {\n \t\t// no rows to use\n \t\treturn;\n@@ -579,7 +542,7 @@ void DataTable::Fetch(Transaction &transaction, DataChunk &result, vector<column\n \t\t\t// regular column: fetch data from the base column\n \t\t\tfor (idx_t i = 0; i < count; i++) {\n \t\t\t\tauto row_id = rows[i];\n-\t\t\t\tcolumns[column]->FetchRow(state.fetch_state, transaction, row_id, result.data[col_idx], i);\n+\t\t\t\tcolumns[column]->FetchRow(state, transaction, row_id, result.data[col_idx], i);\n \t\t\t}\n \t\t}\n \t}\ndiff --git a/src/storage/uncompressed_segment.cpp b/src/storage/uncompressed_segment.cpp\nindex 3d285ee11318..4b68f12d595f 100644\n--- a/src/storage/uncompressed_segment.cpp\n+++ b/src/storage/uncompressed_segment.cpp\n@@ -144,6 +144,19 @@ void UncompressedSegment::Fetch(ColumnScanState &state, idx_t vector_index, Vect\n //===--------------------------------------------------------------------===//\n // Filter\n //===--------------------------------------------------------------------===//\n+template <class T, class OP, bool HAS_NULL>\n+static idx_t filter_selection_loop(T *vec, T *predicate, SelectionVector &sel, idx_t approved_tuple_count,\n+                                   nullmask_t &nullmask, SelectionVector &result_sel) {\n+\tidx_t result_count = 0;\n+\tfor (idx_t i = 0; i < approved_tuple_count; i++) {\n+\t\tauto idx = sel.get_index(i);\n+\t\tif ((!HAS_NULL || !nullmask[idx]) && OP::Operation(vec[idx], *predicate)) {\n+\t\t\tresult_sel.set_index(result_count++, idx);\n+\t\t}\n+\t}\n+\treturn result_count;\n+}\n+\n template <class T>\n static void filterSelectionType(T *vec, T *predicate, SelectionVector &sel, idx_t &approved_tuple_count,\n                                 ExpressionType comparison_type, nullmask_t &nullmask) {\n@@ -152,54 +165,51 @@ static void filterSelectionType(T *vec, T *predicate, SelectionVector &sel, idx_\n \tswitch (comparison_type) {\n \tcase ExpressionType::COMPARE_EQUAL: {\n \t\tif (!nullmask.any()) {\n-\t\t\tapproved_tuple_count = BinaryExecutor::SelectFlatLoop<T, T, Equals, false, true, true, true, false>(\n-\t\t\t    vec, predicate, &sel, approved_tuple_count, nullmask, &new_sel, &sel);\n+\t\t\tapproved_tuple_count =\n+\t\t\t    filter_selection_loop<T, Equals, false>(vec, predicate, sel, approved_tuple_count, nullmask, new_sel);\n \t\t} else {\n-\t\t\tapproved_tuple_count = BinaryExecutor::SelectFlatLoop<T, T, Equals, false, true, false, true, false>(\n-\t\t\t    vec, predicate, &sel, approved_tuple_count, nullmask, &new_sel, &sel);\n+\t\t\tapproved_tuple_count =\n+\t\t\t    filter_selection_loop<T, Equals, true>(vec, predicate, sel, approved_tuple_count, nullmask, new_sel);\n \t\t}\n \t\tbreak;\n \t}\n \tcase ExpressionType::COMPARE_LESSTHAN: {\n \t\tif (!nullmask.any()) {\n-\t\t\tapproved_tuple_count = BinaryExecutor::SelectFlatLoop<T, T, LessThan, false, true, true, true, false>(\n-\t\t\t    vec, predicate, &sel, approved_tuple_count, nullmask, &new_sel, &sel);\n+\t\t\tapproved_tuple_count =\n+\t\t\t    filter_selection_loop<T, LessThan, false>(vec, predicate, sel, approved_tuple_count, nullmask, new_sel);\n \t\t} else {\n-\t\t\tapproved_tuple_count = BinaryExecutor::SelectFlatLoop<T, T, LessThan, false, true, false, true, false>(\n-\t\t\t    vec, predicate, &sel, approved_tuple_count, nullmask, &new_sel, &sel);\n+\t\t\tapproved_tuple_count =\n+\t\t\t    filter_selection_loop<T, LessThan, true>(vec, predicate, sel, approved_tuple_count, nullmask, new_sel);\n \t\t}\n \t\tbreak;\n \t}\n \tcase ExpressionType::COMPARE_GREATERTHAN: {\n \t\tif (!nullmask.any()) {\n-\t\t\tapproved_tuple_count = BinaryExecutor::SelectFlatLoop<T, T, GreaterThan, false, true, true, true, false>(\n-\t\t\t    vec, predicate, &sel, approved_tuple_count, nullmask, &new_sel, &sel);\n+\t\t\tapproved_tuple_count = filter_selection_loop<T, GreaterThan, false>(\n+\t\t\t    vec, predicate, sel, approved_tuple_count, nullmask, new_sel);\n \t\t} else {\n-\t\t\tapproved_tuple_count = BinaryExecutor::SelectFlatLoop<T, T, GreaterThan, false, true, false, true, false>(\n-\t\t\t    vec, predicate, &sel, approved_tuple_count, nullmask, &new_sel, &sel);\n+\t\t\tapproved_tuple_count = filter_selection_loop<T, GreaterThan, true>(vec, predicate, sel,\n+\t\t\t                                                                   approved_tuple_count, nullmask, new_sel);\n \t\t}\n \t\tbreak;\n \t}\n \tcase ExpressionType::COMPARE_LESSTHANOREQUALTO: {\n \t\tif (!nullmask.any()) {\n-\t\t\tapproved_tuple_count = BinaryExecutor::SelectFlatLoop<T, T, LessThanEquals, false, true, true, true, false>(\n-\t\t\t    vec, predicate, &sel, approved_tuple_count, nullmask, &new_sel, &sel);\n+\t\t\tapproved_tuple_count = filter_selection_loop<T, LessThanEquals, false>(\n+\t\t\t    vec, predicate, sel, approved_tuple_count, nullmask, new_sel);\n \t\t} else {\n-\t\t\tapproved_tuple_count =\n-\t\t\t    BinaryExecutor::SelectFlatLoop<T, T, LessThanEquals, false, true, false, true, false>(\n-\t\t\t        vec, predicate, &sel, approved_tuple_count, nullmask, &new_sel, &sel);\n+\t\t\tapproved_tuple_count = filter_selection_loop<T, LessThanEquals, true>(\n+\t\t\t    vec, predicate, sel, approved_tuple_count, nullmask, new_sel);\n \t\t}\n \t\tbreak;\n \t}\n \tcase ExpressionType::COMPARE_GREATERTHANOREQUALTO: {\n \t\tif (!nullmask.any()) {\n-\t\t\tapproved_tuple_count =\n-\t\t\t    BinaryExecutor::SelectFlatLoop<T, T, GreaterThanEquals, false, true, true, true, false>(\n-\t\t\t        vec, predicate, &sel, approved_tuple_count, nullmask, &new_sel, &sel);\n+\t\t\tapproved_tuple_count = filter_selection_loop<T, GreaterThanEquals, false>(\n+\t\t\t    vec, predicate, sel, approved_tuple_count, nullmask, new_sel);\n \t\t} else {\n-\t\t\tapproved_tuple_count =\n-\t\t\t    BinaryExecutor::SelectFlatLoop<T, T, GreaterThanEquals, false, true, false, true, false>(\n-\t\t\t        vec, predicate, &sel, approved_tuple_count, nullmask, &new_sel, &sel);\n+\t\t\tapproved_tuple_count = filter_selection_loop<T, GreaterThanEquals, true>(\n+\t\t\t    vec, predicate, sel, approved_tuple_count, nullmask, new_sel);\n \t\t}\n \t\tbreak;\n \t}\ndiff --git a/third_party/catch/catch.hpp b/third_party/catch/catch.hpp\nindex 841e53d20fcf..d8ae61b9ca69 100644\n--- a/third_party/catch/catch.hpp\n+++ b/third_party/catch/catch.hpp\n@@ -1860,6 +1860,13 @@ namespace Catch {\n         INTERNAL_CATCH_REACT( catchAssertionHandler ) \\\n     } while( false )\n \n+#define INTERNAL_CATCH_MSG_LINENR( macroName, messageType, resultDisposition, fname, linenr, ... ) \\\n+    do { \\\n+        Catch::AssertionHandler catchAssertionHandler( macroName##_catch_sr, ::Catch::SourceLineInfo(fname.c_str(), linenr), Catch::StringRef(), resultDisposition ); \\\n+        catchAssertionHandler.handleMessage( messageType, ( Catch::MessageStream() << __VA_ARGS__ + ::Catch::StreamEndStop() ).m_stream.str() ); \\\n+        INTERNAL_CATCH_REACT( catchAssertionHandler ) \\\n+    } while( false )\n+\n ///////////////////////////////////////////////////////////////////////////////\n #define INTERNAL_CATCH_CAPTURE( varName, macroName, ... ) \\\n     auto varName = Catch::Capturer( macroName, CATCH_INTERNAL_LINEINFO, Catch::ResultWas::Info, #__VA_ARGS__ ); \\\n@@ -13778,6 +13785,7 @@ int main (int argc, char * const argv[]) {\n #define SECTION( ... ) INTERNAL_CATCH_SECTION( __VA_ARGS__ )\n #define DYNAMIC_SECTION( ... ) INTERNAL_CATCH_DYNAMIC_SECTION( __VA_ARGS__ )\n #define FAIL( ... ) INTERNAL_CATCH_MSG( \"FAIL\", Catch::ResultWas::ExplicitFailure, Catch::ResultDisposition::Normal, __VA_ARGS__ )\n+#define FAIL_LINE(fname, linenr, ...) INTERNAL_CATCH_MSG_LINENR( \"FAIL\", Catch::ResultWas::ExplicitFailure, Catch::ResultDisposition::Normal, fname, linenr, __VA_ARGS__ )\n #define FAIL_CHECK( ... ) INTERNAL_CATCH_MSG( \"FAIL_CHECK\", Catch::ResultWas::ExplicitFailure, Catch::ResultDisposition::ContinueOnFailure, __VA_ARGS__ )\n #define SUCCEED( ... ) INTERNAL_CATCH_MSG( \"SUCCEED\", Catch::ResultWas::Ok, Catch::ResultDisposition::ContinueOnFailure, __VA_ARGS__ )\n #define ANON_TEST_CASE() INTERNAL_CATCH_TESTCASE()\n@@ -13907,6 +13915,7 @@ using Catch::Detail::Approx;\n #define SECTION( ... )\n #define DYNAMIC_SECTION( ... )\n #define FAIL( ... ) (void)(0)\n+#define FAIL_LINE( ... ) (void)(0)\n #define FAIL_CHECK( ... ) (void)(0)\n #define SUCCEED( ... ) (void)(0)\n #define ANON_TEST_CASE() INTERNAL_CATCH_TESTCASE_NO_REGISTRATION(INTERNAL_CATCH_UNIQUE_NAME( ____C_A_T_C_H____T_E_S_T____ ))\ndiff --git a/tools/pythonpkg/duckdb_python.cpp b/tools/pythonpkg/duckdb_python.cpp\nindex 48d4be61a82e..9b87cfbe9302 100644\n--- a/tools/pythonpkg/duckdb_python.cpp\n+++ b/tools/pythonpkg/duckdb_python.cpp\n@@ -61,8 +61,7 @@ struct IntegralConvert {\n \t}\n };\n \n-template <>\n-double IntegralConvert::convert_value(hugeint_t val) {\n+template <> double IntegralConvert::convert_value(hugeint_t val) {\n \tdouble result;\n \tHugeint::TryCast(val, result);\n \treturn result;\n@@ -93,7 +92,7 @@ template <class T> static py::array fetch_column_regular(string numpy_type, Chun\n \treturn fetch_column<T, T, RegularConvert>(numpy_type, collection, column);\n }\n \n-template<class DUCKDB_T>\n+template <class DUCKDB_T>\n static void decimal_convert_internal(ChunkCollection &collection, idx_t column, double *out_ptr, double division) {\n \tidx_t out_offset = 0;\n \tfor (auto &data_chunk : collection.chunks) {\n@@ -110,13 +109,14 @@ static void decimal_convert_internal(ChunkCollection &collection, idx_t column,\n \t}\n }\n \n-static py::array fetch_column_decimal(string numpy_type, ChunkCollection &collection, idx_t column, LogicalType &decimal_type) {\n+static py::array fetch_column_decimal(string numpy_type, ChunkCollection &collection, idx_t column,\n+                                      LogicalType &decimal_type) {\n \tauto out = py::array(py::dtype(numpy_type), collection.count);\n \tauto out_ptr = (double *)out.mutable_data();\n \n \tauto dec_scale = decimal_type.scale();\n \tdouble division = pow(10, dec_scale);\n-\tswitch(decimal_type.InternalType()) {\n+\tswitch (decimal_type.InternalType()) {\n \tcase PhysicalType::INT16:\n \t\tdecimal_convert_internal<int16_t>(collection, column, out_ptr, division);\n \t\tbreak;\n@@ -155,17 +155,24 @@ std::string generate() {\n \n struct PandasScanFunctionData : public TableFunctionData {\n \tPandasScanFunctionData(py::handle df, idx_t row_count, vector<LogicalType> sql_types)\n-\t    : df(df), row_count(row_count), sql_types(sql_types), position(0) {\n+\t    : df(df), row_count(row_count), sql_types(sql_types) {\n \t}\n \tpy::handle df;\n \tidx_t row_count;\n \tvector<LogicalType> sql_types;\n+};\n+\n+struct PandasScanState : public FunctionOperatorData {\n+\tPandasScanState() : position(0) {\n+\t}\n+\n \tidx_t position;\n };\n \n struct PandasScanFunction : public TableFunction {\n \tPandasScanFunction()\n-\t    : TableFunction(\"pandas_scan\", {LogicalType::VARCHAR}, pandas_scan_bind, pandas_scan_function, nullptr){};\n+\t    : TableFunction(\"pandas_scan\", {LogicalType::VARCHAR}, pandas_scan_function, pandas_scan_bind, pandas_scan_init,\n+\t                    nullptr, nullptr, nullptr, pandas_scan_cardinality){};\n \n \tstatic unique_ptr<FunctionData> pandas_scan_bind(ClientContext &context, vector<Value> &inputs,\n \t                                                 unordered_map<string, Value> &named_parameters,\n@@ -220,6 +227,12 @@ struct PandasScanFunction : public TableFunction {\n \t\treturn make_unique<PandasScanFunctionData>(df, row_count, return_types);\n \t}\n \n+\tstatic unique_ptr<FunctionOperatorData> pandas_scan_init(ClientContext &context, const FunctionData *bind_data,\n+\t                                                         OperatorTaskInfo *task_info, vector<column_t> &column_ids,\n+\t                                                         unordered_map<idx_t, vector<TableFilter>> &table_filters) {\n+\t\treturn make_unique<PandasScanState>();\n+\t}\n+\n \ttemplate <class T> static void scan_pandas_column(py::array numpy_col, idx_t count, idx_t offset, Vector &out) {\n \t\tauto src_ptr = (T *)numpy_col.data();\n \t\tFlatVector::SetData(out, (data_ptr_t)(src_ptr + offset));\n@@ -240,14 +253,15 @@ struct PandasScanFunction : public TableFunction {\n \t\t}\n \t}\n \n-\tstatic void pandas_scan_function(ClientContext &context, vector<Value> &input, DataChunk &output,\n-\t                                 FunctionData *dataptr) {\n-\t\tauto &data = *((PandasScanFunctionData *)dataptr);\n+\tstatic void pandas_scan_function(ClientContext &context, const FunctionData *bind_data,\n+\t                                 FunctionOperatorData *operator_state, DataChunk &output) {\n+\t\tauto &data = (PandasScanFunctionData &)*bind_data;\n+\t\tauto &state = (PandasScanState &)*operator_state;\n \n-\t\tif (data.position >= data.row_count) {\n+\t\tif (state.position >= data.row_count) {\n \t\t\treturn;\n \t\t}\n-\t\tidx_t this_count = std::min((idx_t)STANDARD_VECTOR_SIZE, data.row_count - data.position);\n+\t\tidx_t this_count = std::min((idx_t)STANDARD_VECTOR_SIZE, data.row_count - state.position);\n \n \t\tauto df_names = py::list(data.df.attr(\"columns\"));\n \t\tauto get_fun = data.df.attr(\"__getitem__\");\n@@ -258,26 +272,26 @@ struct PandasScanFunction : public TableFunction {\n \n \t\t\tswitch (data.sql_types[col_idx].id()) {\n \t\t\tcase LogicalTypeId::BOOLEAN:\n-\t\t\t\tscan_pandas_column<bool>(numpy_col, this_count, data.position, output.data[col_idx]);\n+\t\t\t\tscan_pandas_column<bool>(numpy_col, this_count, state.position, output.data[col_idx]);\n \t\t\t\tbreak;\n \t\t\tcase LogicalTypeId::TINYINT:\n-\t\t\t\tscan_pandas_column<int8_t>(numpy_col, this_count, data.position, output.data[col_idx]);\n+\t\t\t\tscan_pandas_column<int8_t>(numpy_col, this_count, state.position, output.data[col_idx]);\n \t\t\t\tbreak;\n \t\t\tcase LogicalTypeId::SMALLINT:\n-\t\t\t\tscan_pandas_column<int16_t>(numpy_col, this_count, data.position, output.data[col_idx]);\n+\t\t\t\tscan_pandas_column<int16_t>(numpy_col, this_count, state.position, output.data[col_idx]);\n \t\t\t\tbreak;\n \t\t\tcase LogicalTypeId::INTEGER:\n-\t\t\t\tscan_pandas_column<int32_t>(numpy_col, this_count, data.position, output.data[col_idx]);\n+\t\t\t\tscan_pandas_column<int32_t>(numpy_col, this_count, state.position, output.data[col_idx]);\n \t\t\t\tbreak;\n \t\t\tcase LogicalTypeId::BIGINT:\n-\t\t\t\tscan_pandas_column<int64_t>(numpy_col, this_count, data.position, output.data[col_idx]);\n+\t\t\t\tscan_pandas_column<int64_t>(numpy_col, this_count, state.position, output.data[col_idx]);\n \t\t\t\tbreak;\n \t\t\tcase LogicalTypeId::FLOAT:\n-\t\t\t\tscan_pandas_fp_column<float>((float *)numpy_col.data(), this_count, data.position,\n+\t\t\t\tscan_pandas_fp_column<float>((float *)numpy_col.data(), this_count, state.position,\n \t\t\t\t                             output.data[col_idx]);\n \t\t\t\tbreak;\n \t\t\tcase LogicalTypeId::DOUBLE:\n-\t\t\t\tscan_pandas_fp_column<double>((double *)numpy_col.data(), this_count, data.position,\n+\t\t\t\tscan_pandas_fp_column<double>((double *)numpy_col.data(), this_count, state.position,\n \t\t\t\t                              output.data[col_idx]);\n \t\t\t\tbreak;\n \t\t\tcase LogicalTypeId::TIMESTAMP: {\n@@ -286,7 +300,7 @@ struct PandasScanFunction : public TableFunction {\n \t\t\t\tauto &nullmask = FlatVector::Nullmask(output.data[col_idx]);\n \n \t\t\t\tfor (idx_t row = 0; row < this_count; row++) {\n-\t\t\t\t\tauto source_idx = data.position + row;\n+\t\t\t\t\tauto source_idx = state.position + row;\n \t\t\t\t\tif (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {\n \t\t\t\t\t\t// pandas Not a Time (NaT)\n \t\t\t\t\t\tnullmask[row] = true;\n@@ -305,7 +319,7 @@ struct PandasScanFunction : public TableFunction {\n \t\t\t\tauto tgt_ptr = (string_t *)FlatVector::GetData(output.data[col_idx]);\n \n \t\t\t\tfor (idx_t row = 0; row < this_count; row++) {\n-\t\t\t\t\tauto source_idx = data.position + row;\n+\t\t\t\t\tauto source_idx = state.position + row;\n \t\t\t\t\tauto val = src_ptr[source_idx];\n \n #if PY_MAJOR_VERSION >= 3\n@@ -332,7 +346,12 @@ struct PandasScanFunction : public TableFunction {\n \t\t\t\tthrow runtime_error(\"Unsupported type \" + data.sql_types[col_idx].ToString());\n \t\t\t}\n \t\t}\n-\t\tdata.position += this_count;\n+\t\tstate.position += this_count;\n+\t}\n+\n+\tstatic idx_t pandas_scan_cardinality(const FunctionData *bind_data) {\n+\t\tauto &data = (PandasScanFunctionData &)*bind_data;\n+\t\treturn data.row_count;\n \t}\n };\n \n@@ -504,7 +523,8 @@ struct DuckDBPyResult {\n \t\t\t\tcol_res = duckdb_py_convert::fetch_column_regular<double>(\"float64\", mres->collection, col_idx);\n \t\t\t\tbreak;\n \t\t\tcase LogicalTypeId::DECIMAL:\n-\t\t\t\tcol_res = duckdb_py_convert::fetch_column_decimal(\"float64\", mres->collection, col_idx, mres->types[col_idx]);\n+\t\t\t\tcol_res =\n+\t\t\t\t    duckdb_py_convert::fetch_column_decimal(\"float64\", mres->collection, col_idx, mres->types[col_idx]);\n \t\t\t\tbreak;\n \t\t\tcase LogicalTypeId::TIMESTAMP:\n \t\t\t\tcol_res = duckdb_py_convert::fetch_column<timestamp_t, int64_t, duckdb_py_convert::TimestampConvert>(\ndiff --git a/tools/rpkg/src/duckdbr.cpp b/tools/rpkg/src/duckdbr.cpp\nindex 5dd7d9a77d72..e8df1e1f7a7e 100644\n--- a/tools/rpkg/src/duckdbr.cpp\n+++ b/tools/rpkg/src/duckdbr.cpp\n@@ -36,14 +36,12 @@ static void vector_to_r(Vector &src_vec, size_t count, void *dest, uint64_t dest\n }\n \n struct RIntegralType {\n-\ttemplate<class T>\n-\tstatic double DoubleCast(T val) {\n+\ttemplate <class T> static double DoubleCast(T val) {\n \t\treturn double(val);\n \t}\n };\n \n-template<class T>\n-static void RDecimalCastLoop(Vector &src_vec, size_t count, double *dest_ptr, uint8_t scale) {\n+template <class T> static void RDecimalCastLoop(Vector &src_vec, size_t count, double *dest_ptr, uint8_t scale) {\n \tauto src_ptr = FlatVector::GetData<T>(src_vec);\n \tauto &nullmask = FlatVector::Nullmask(src_vec);\n \tdouble division = pow(10, scale);\n@@ -557,7 +555,7 @@ SEXP duckdb_execute_R(SEXP stmtsexp) {\n \t\t\t\t\tauto &decimal_type = result->types[col_idx];\n \t\t\t\t\tdouble *dest_ptr = ((double *)NUMERIC_POINTER(dest)) + dest_offset;\n \t\t\t\t\tauto dec_scale = decimal_type.scale();\n-\t\t\t\t\tswitch(decimal_type.InternalType()) {\n+\t\t\t\t\tswitch (decimal_type.InternalType()) {\n \t\t\t\t\tcase PhysicalType::INT16:\n \t\t\t\t\t\tRDecimalCastLoop<int16_t>(src_vec, chunk->size(), dest_ptr, dec_scale);\n \t\t\t\t\t\tbreak;\n@@ -628,18 +626,24 @@ static SEXP duckdb_finalize_database_R(SEXP dbsexp) {\n \n struct DataFrameScanFunctionData : public TableFunctionData {\n \tDataFrameScanFunctionData(SEXP df, idx_t row_count, vector<RType> rtypes)\n-\t    : df(df), row_count(row_count), rtypes(rtypes), position(0) {\n+\t    : df(df), row_count(row_count), rtypes(rtypes) {\n \t}\n \tSEXP df;\n \tidx_t row_count;\n \tvector<RType> rtypes;\n+};\n+\n+struct DataFrameScanState : public FunctionOperatorData {\n+\tDataFrameScanState() : position(0) {\n+\t}\n+\n \tidx_t position;\n };\n \n struct DataFrameScanFunction : public TableFunction {\n \tDataFrameScanFunction()\n-\t    : TableFunction(\"dataframe_scan\", {LogicalType::VARCHAR}, dataframe_scan_bind, dataframe_scan_function,\n-\t                    nullptr){};\n+\t    : TableFunction(\"dataframe_scan\", {LogicalType::VARCHAR}, dataframe_scan_function, dataframe_scan_bind,\n+\t                    dataframe_scan_init, nullptr, nullptr, nullptr, dataframe_scan_cardinality){};\n \n \tstatic unique_ptr<FunctionData> dataframe_scan_bind(ClientContext &context, vector<Value> &inputs,\n \t                                                    unordered_map<string, Value> &named_parameters,\n@@ -685,14 +689,20 @@ struct DataFrameScanFunction : public TableFunction {\n \t\treturn make_unique<DataFrameScanFunctionData>(df, row_count, rtypes);\n \t}\n \n-\tstatic void dataframe_scan_function(ClientContext &context, vector<Value> &input, DataChunk &output,\n-\t                                    FunctionData *dataptr) {\n-\t\tauto &data = *((DataFrameScanFunctionData *)dataptr);\n+\tstatic unique_ptr<FunctionOperatorData>\n+\tdataframe_scan_init(ClientContext &context, const FunctionData *bind_data, OperatorTaskInfo *task_info,\n+\t                    vector<column_t> &column_ids, unordered_map<idx_t, vector<TableFilter>> &table_filters) {\n+\t\treturn make_unique<DataFrameScanState>();\n+\t}\n \n-\t\tif (data.position >= data.row_count) {\n+\tstatic void dataframe_scan_function(ClientContext &context, const FunctionData *bind_data,\n+\t                                    FunctionOperatorData *operator_state, DataChunk &output) {\n+\t\tauto &data = (DataFrameScanFunctionData &)*bind_data;\n+\t\tauto &state = (DataFrameScanState &)*operator_state;\n+\t\tif (state.position >= data.row_count) {\n \t\t\treturn;\n \t\t}\n-\t\tidx_t this_count = std::min((idx_t)STANDARD_VECTOR_SIZE, data.row_count - data.position);\n+\t\tidx_t this_count = std::min((idx_t)STANDARD_VECTOR_SIZE, data.row_count - state.position);\n \n \t\toutput.SetCardinality(this_count);\n \n@@ -703,33 +713,33 @@ struct DataFrameScanFunction : public TableFunction {\n \n \t\t\tswitch (data.rtypes[col_idx]) {\n \t\t\tcase RType::LOGICAL: {\n-\t\t\t\tauto data_ptr = INTEGER_POINTER(coldata) + data.position;\n+\t\t\t\tauto data_ptr = INTEGER_POINTER(coldata) + state.position;\n \t\t\t\tAppendColumnSegment<int, bool, RBooleanType>(data_ptr, v, this_count);\n \t\t\t\tbreak;\n \t\t\t}\n \t\t\tcase RType::INTEGER: {\n-\t\t\t\tauto data_ptr = INTEGER_POINTER(coldata) + data.position;\n+\t\t\t\tauto data_ptr = INTEGER_POINTER(coldata) + state.position;\n \t\t\t\tAppendColumnSegment<int, int, RIntegerType>(data_ptr, v, this_count);\n \t\t\t\tbreak;\n \t\t\t}\n \t\t\tcase RType::NUMERIC: {\n-\t\t\t\tauto data_ptr = NUMERIC_POINTER(coldata) + data.position;\n+\t\t\t\tauto data_ptr = NUMERIC_POINTER(coldata) + state.position;\n \t\t\t\tAppendColumnSegment<double, double, RDoubleType>(data_ptr, v, this_count);\n \t\t\t\tbreak;\n \t\t\t}\n \t\t\tcase RType::STRING:\n-\t\t\t\tAppendStringSegment(coldata, v, data.position, this_count);\n+\t\t\t\tAppendStringSegment(coldata, v, state.position, this_count);\n \t\t\t\tbreak;\n \t\t\tcase RType::FACTOR:\n-\t\t\t\tAppendFactor(coldata, v, data.position, this_count);\n+\t\t\t\tAppendFactor(coldata, v, state.position, this_count);\n \t\t\t\tbreak;\n \t\t\tcase RType::TIMESTAMP: {\n-\t\t\t\tauto data_ptr = NUMERIC_POINTER(coldata) + data.position;\n+\t\t\t\tauto data_ptr = NUMERIC_POINTER(coldata) + state.position;\n \t\t\t\tAppendColumnSegment<double, timestamp_t, RTimestampType>(data_ptr, v, this_count);\n \t\t\t\tbreak;\n \t\t\t}\n \t\t\tcase RType::DATE: {\n-\t\t\t\tauto data_ptr = NUMERIC_POINTER(coldata) + data.position;\n+\t\t\t\tauto data_ptr = NUMERIC_POINTER(coldata) + state.position;\n \t\t\t\tAppendColumnSegment<double, date_t, RDateType>(data_ptr, v, this_count);\n \t\t\t\tbreak;\n \t\t\t}\n@@ -738,7 +748,12 @@ struct DataFrameScanFunction : public TableFunction {\n \t\t\t}\n \t\t}\n \n-\t\tdata.position += this_count;\n+\t\tstate.position += this_count;\n+\t}\n+\n+\tstatic idx_t dataframe_scan_cardinality(const FunctionData *bind_data) {\n+\t\tauto &data = (DataFrameScanFunctionData &)*bind_data;\n+\t\treturn data.row_count;\n \t}\n };\n \n",
  "test_patch": "diff --git a/test/optimizer/index_scan.test b/test/optimizer/index_scan.test\ndeleted file mode 100644\nindex 3cc41b530bd3..000000000000\n--- a/test/optimizer/index_scan.test\n+++ /dev/null\n@@ -1,25 +0,0 @@\n-# name: test/optimizer/index_scan.test\n-# description: Test Index Scan Optimizer for Integers\n-# group: [optimizer]\n-\n-statement ok\n-CREATE TABLE test(i INTEGER);\n-\n-statement ok\n-PRAGMA explain_output='optimized';\n-\n-statement ok\n-CREATE INDEX i_index ON test(i)\n-\n-query II\n-EXPLAIN SELECT i FROM test where i > 10::INTEGER\n-----\n-logical_opt\t<REGEX>:.*INDEX_SCAN.*\n-\n-statement ok\n-DROP INDEX i_index\n-\n-query II\n-EXPLAIN SELECT i FROM test where i > 10::INTEGER\n-----\n-logical_opt\t<REGEX>:.*GET.*\ndiff --git a/test/sql/copy/csv/recursive_read_csv.test b/test/sql/copy/csv/recursive_read_csv.test\nnew file mode 100644\nindex 000000000000..459125fd748f\n--- /dev/null\n+++ b/test/sql/copy/csv/recursive_read_csv.test\n@@ -0,0 +1,69 @@\n+# name: test/sql/copy/csv/recursive_read_csv.test\n+# description: Test read CSV function in a recursive CTE\n+# group: [csv]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+# first create a table from read csv, and use that in a recursive te\n+statement ok\n+create table r AS SELECT * FROM read_csv('test/sql/copy/csv/data/test/date.csv', columns=STRUCT_PACK(d := 'DATE'), header=0, auto_detect=0);\n+\n+query II\n+WITH RECURSIVE t(i) AS\n+(\n+\tSELECT 1, NULL::DATE\n+\tUNION ALL\n+\t(\n+\t\tSELECT i+1, d\n+\t\tFROM t, r\n+\t\tWHERE i<5\n+\t)\n+)\n+SELECT * FROM t ORDER BY i;\n+----\n+1\tNULL\n+2\t2019-06-05\n+3\t2019-06-05\n+4\t2019-06-05\n+5\t2019-06-05\n+\n+# directly calling the function should be equivalent\n+query II\n+WITH RECURSIVE t(i) AS\n+(\n+\tSELECT 1, NULL::DATE\n+\tUNION ALL\n+\t(\n+\t\tSELECT i+1, d\n+\t\tFROM t, read_csv('test/sql/copy/csv/data/test/date.csv', columns=STRUCT_PACK(d := 'DATE'), header=0, auto_detect=0)\n+\t\tWHERE i<5\n+\t)\n+)\n+SELECT * FROM t ORDER BY i;\n+----\n+1\tNULL\n+2\t2019-06-05\n+3\t2019-06-05\n+4\t2019-06-05\n+5\t2019-06-05\n+\n+# should also work if we use auto detect\n+query II\n+WITH RECURSIVE t(i) AS\n+(\n+\tSELECT 1, NULL::DATE\n+\tUNION ALL\n+\t(\n+\t\tSELECT i+1, d\n+\t\tFROM t, read_csv('test/sql/copy/csv/data/test/date.csv', header=0, auto_detect=1) r(d)\n+\t\tWHERE i<5\n+\t)\n+)\n+SELECT * FROM t ORDER BY i;\n+----\n+1\tNULL\n+2\t2019-06-05\n+3\t2019-06-05\n+4\t2019-06-05\n+5\t2019-06-05\ndiff --git a/test/sql/cte/game_of_life.test_slow b/test/sql/cte/game_of_life.test_slow\nindex 98142e6014cb..bb561b2238fa 100644\n--- a/test/sql/cte/game_of_life.test_slow\n+++ b/test/sql/cte/game_of_life.test_slow\n@@ -1,9 +1,9 @@\n-# name: test/sql/cte/game_of_life.test\n+# name: test/sql/cte/game_of_life.test_slow\n # description: Run conways game of life as a CTE (https://gist.github.com/janickr/58fab629ee3ea7e5638a)\n # group: [cte]\n \n statement ok\n-create table series as select * from range(-1,1+1) x(n);\n+create table series as select * from generate_series(-1,1) x(n);\n \n # conway\n query III\n@@ -35,9 +35,6 @@ select * from game where n=4 order by n, x, y; --select generation 4\n 4\t3\t3\n 4\t3\t4\n \n-mode skip\n-\n-# FIXME: table functions keep state in function data -> this should be fixed, as it causes problems with recursive CTEs\n query III\n with recursive generation1(x,y) as (   --the initial board setup\n   select 2, 3\n@@ -54,7 +51,7 @@ game(n, x, y) as (\n     select n, x+offset_x new_x, y+offset_y new_y, max(self) over (partition by n+1, x+offset_x, y+offset_y) cell_was_already_alive\n     from game, (\n         select x.n offset_x, y.n offset_y, case when x.n = 0 and y.n = 0 then 1 else 0 end self\n-        from range(-1,2) x(n), range(-1,2) y(n) --join 2 row generators to get 9 pairs\n+        from generate_series(-1,1) x(n), generate_series(-1,1) y(n) --join 2 row generators to get 9 pairs\n       ) offsets_to_neighbours_and_self(offset_x, offset_y, self)\n     where n < 100\n   ) all_impacts\ndiff --git a/test/sql/cte/test_recursive_cte_union_all.test b/test/sql/cte/test_recursive_cte_union_all.test\nindex ed5cb9831c4a..fdd8e34d23b9 100644\n--- a/test/sql/cte/test_recursive_cte_union_all.test\n+++ b/test/sql/cte/test_recursive_cte_union_all.test\n@@ -87,6 +87,28 @@ NULL\n NULL\n NULL\n \n+# recursive CTE with table-producing function\n+query I\n+WITH RECURSIVE t AS (\n+\tSELECT 1 AS i\n+\tUNION ALL\n+\tSELECT j\n+\tFROM t, generate_series(0, 10, 1) series(j)\n+\tWHERE j=i+1\n+)\n+SELECT * FROM t;\n+----\n+1\n+2\n+3\n+4\n+5\n+6\n+7\n+8\n+9\n+10\n+\n # order by is not allowed in the recursive term of ctes\n statement error\n with recursive t as (select 1 as x union all select x+1 from t where x < 3 order by x) select * from t\ndiff --git a/test/sql/pragma/test_pragma_database_list.test b/test/sql/pragma/test_pragma_database_list.test\nindex 6785dff607b2..4e85bfcf0b51 100644\n--- a/test/sql/pragma/test_pragma_database_list.test\n+++ b/test/sql/pragma/test_pragma_database_list.test\n@@ -15,11 +15,10 @@ SELECT * FROM pragma_database_list()\n statement error\n PRAGMA database_list()\n \n-# FIXME: need to merge changes from hugeint branch\n-# # load a database file\n-# load __TEST_DIR__/test.db\n+# load a database file\n+load __TEST_DIR__/test.db\n \n-# query III\n-# SELECT * FROM pragma_database_list()\n-# ----\n-# 0\tmain\t(empty)\n+query II\n+SELECT seq, name FROM pragma_database_list() WHERE file LIKE '%test.db%'\n+----\n+0\tmain\ndiff --git a/test/sql/table_function/sqlite_master.test b/test/sql/table_function/sqlite_master.test\nnew file mode 100644\nindex 000000000000..2f8b881d948a\n--- /dev/null\n+++ b/test/sql/table_function/sqlite_master.test\n@@ -0,0 +1,32 @@\n+# name: test/sql/table_function/sqlite_master.test\n+# description: Test sqlite_master function\n+# group: [table_function]\n+\n+statement ok\n+CREATE TABLE integers(i INTEGER);\n+\n+query IIIII\n+SELECT * FROM sqlite_master();\n+----\n+table\tintegers\tintegers\t0\tCREATE TABLE integers(i INTEGER);\n+\n+query I\n+SELECT EXISTS(SELECT * FROM sqlite_master())\n+----\n+1\n+\n+query I\n+SELECT EXISTS(SELECT * FROM sqlite_master() OFFSET 1)\n+----\n+0\n+\n+\n+query I\n+SELECT COUNT(*) FROM sqlite_master() WHERE name='test'\n+----\n+0\n+\n+query I\n+SELECT COUNT(*) FROM sqlite_master() WHERE name='integers'\n+----\n+1\n\\ No newline at end of file\ndiff --git a/test/sql/table_function/test_range_function.test b/test/sql/table_function/test_range_function.test\nindex e41dbb60362d..4989576d4b5d 100644\n--- a/test/sql/table_function/test_range_function.test\n+++ b/test/sql/table_function/test_range_function.test\n@@ -16,7 +16,7 @@ SELECT * FROM range(0, 10, 1)\n 8\n 9\n \n-# generate_series is an alias for range for postgres compatibility\n+# generate_series is similar to range, but has inclusive bounds (for postgres compatibility)\n query I\n SELECT * FROM generate_series(0, 10, 1)\n ----\n@@ -30,6 +30,7 @@ SELECT * FROM generate_series(0, 10, 1)\n 7\n 8\n 9\n+10\n \n query I\n SELECT * FROM range(10, 0, -1) ORDER BY 1 ASC\n@@ -45,6 +46,21 @@ SELECT * FROM range(10, 0, -1) ORDER BY 1 ASC\n 9\n 10\n \n+query I\n+SELECT * FROM generate_series(10, 0, -1) ORDER BY 1 ASC\n+----\n+0\n+1\n+2\n+3\n+4\n+5\n+6\n+7\n+8\n+9\n+10\n+\n query I\n SELECT * FROM range(0, -5, -1)\n ----\n@@ -94,6 +110,21 @@ SELECT * FROM range(0, 10)\n 8\n 9\n \n+query I\n+SELECT EXISTS(SELECT * FROM range(10))\n+----\n+1\n+\n+query I\n+SELECT EXISTS(SELECT * FROM range(0))\n+----\n+0\n+\n+query I\n+SELECT * FROM range(10) t1(j) WHERE j=3\n+----\n+3\n+\n statement error\n SELECT * FROM range('hello')\n \ndiff --git a/test/sqlite/test_sqllogictest.cpp b/test/sqlite/test_sqllogictest.cpp\nindex eb2e574a93f7..a10d7fd515ab 100644\n--- a/test/sqlite/test_sqllogictest.cpp\n+++ b/test/sqlite/test_sqllogictest.cpp\n@@ -516,6 +516,12 @@ struct Command {\n \t\t}\n \t}\n \n+\tunique_ptr<MaterializedQueryResult> ExecuteQuery(Connection *connection, string file_name, int query_line,\n+\t                                                 string sql_query) {\n+\t\tquery_break(query_line);\n+\t\treturn connection->Query(sql_query);\n+\t}\n+\n \tvirtual void Execute() = 0;\n \tvoid ExecuteLoop() {\n \t\t// store the original query\n@@ -575,7 +581,7 @@ void Statement::Execute() {\n \t}\n \n \tquery_break(query_line);\n-\tauto result = connection->Query(sql_query);\n+\tauto result = ExecuteQuery(connection, file_name, query_line, sql_query);\n \tbool error = !result->success;\n \n \tif (runner.output_result_mode || runner.debug_mode) {\n@@ -597,7 +603,7 @@ void Statement::Execute() {\n \t\tif (result) {\n \t\t\tresult->Print();\n \t\t}\n-\t\tFAIL();\n+\t\tFAIL_LINE(file_name, query_line);\n \t}\n \tREQUIRE(!error);\n }\n@@ -610,7 +616,7 @@ void Query::ColumnCountMismatch(MaterializedQueryResult &result, int expected_co\n \tprint_sql(sql_query);\n \tprint_line_sep();\n \tprint_result_error(result, values, expected_column_count, row_wise);\n-\tFAIL();\n+\tFAIL_LINE(file_name, query_line);\n }\n \n vector<string> Query::LoadResultFromFile(string fname, vector<string> names) {\n@@ -632,7 +638,7 @@ vector<string> Query::LoadResultFromFile(string fname, vector<string> names) {\n \tif (!csv_result->success) {\n \t\tstring error = StringUtil::Format(\"Could not read CSV File \\\"%s\\\": %s\", fname, csv_result->error);\n \t\tprint_error_header(error.c_str(), file_name.c_str(), query_line);\n-\t\tFAIL();\n+\t\tFAIL_LINE(file_name, query_line);\n \t}\n \texpected_column_count = csv_result->column_count();\n \n@@ -661,8 +667,7 @@ void Query::Execute() {\n \t\tprint_line_sep();\n \t}\n \n-\tquery_break(query_line);\n-\tauto result = connection->Query(sql_query);\n+\tauto result = ExecuteQuery(connection, file_name, query_line, sql_query);\n \tif (!result->success) {\n \t\tprint_line_sep();\n \t\tfprintf(stderr, \"Query unexpectedly failed (%s:%d)\\n\", file_name.c_str(), query_line);\n@@ -671,7 +676,7 @@ void Query::Execute() {\n \t\tprint_line_sep();\n \t\tprint_header(\"Actual result:\");\n \t\tresult->Print();\n-\t\tFAIL();\n+\t\tFAIL_LINE(file_name, query_line);\n \t}\n \tvector<string> azResult;\n \tint nResult;\n@@ -817,7 +822,7 @@ void Query::Execute() {\n \t\t\tfprintf(stderr, \"Expected %d columns, but %d values were supplied\\n\", (int)expected_column_count,\n \t\t\t        (int)comparison_values.size());\n \t\t\tfprintf(stderr, \"This is not cleanly divisible (i.e. the last row does not have enough values)\\n\");\n-\t\t\tFAIL();\n+\t\t\tFAIL_LINE(file_name, query_line);\n \t\t}\n \t\tif (expected_rows != result->collection.count) {\n \t\t\tif (column_count_mismatch) {\n@@ -830,7 +835,7 @@ void Query::Execute() {\n \t\t\tprint_sql(sql_query);\n \t\t\tprint_line_sep();\n \t\t\tprint_result_error(*result, comparison_values, expected_column_count, row_wise);\n-\t\t\tFAIL();\n+\t\t\tFAIL_LINE(file_name, query_line);\n \t\t}\n \n \t\tif (row_wise) {\n@@ -853,14 +858,14 @@ void Query::Execute() {\n \t\t\t\t\tprint_line_sep();\n \t\t\t\t\tprint_sql(sql_query);\n \t\t\t\t\tprint_line_sep();\n-\t\t\t\t\tFAIL();\n+\t\t\t\t\tFAIL_LINE(file_name, query_line);\n \t\t\t\t}\n \t\t\t\tfor (idx_t c = 0; c < splits.size(); c++) {\n \t\t\t\t\tbool success = compare_values(*result, azResult[current_row * expected_column_count + c], splits[c],\n \t\t\t\t\t                              file_name, query_line, sql_query, current_row, c, comparison_values,\n \t\t\t\t\t                              expected_column_count, row_wise);\n \t\t\t\t\tif (!success) {\n-\t\t\t\t\t\tFAIL();\n+\t\t\t\t\t\tFAIL_LINE(file_name, query_line);\n \t\t\t\t\t}\n \t\t\t\t\t// we do this just to increment the assertion counter\n \t\t\t\t\tREQUIRE(success);\n@@ -874,7 +879,7 @@ void Query::Execute() {\n \t\t\t\t                              comparison_values[i], file_name, query_line, sql_query, current_row,\n \t\t\t\t                              current_column, comparison_values, expected_column_count, row_wise);\n \t\t\t\tif (!success) {\n-\t\t\t\t\tFAIL();\n+\t\t\t\t\tFAIL_LINE(file_name, query_line);\n \t\t\t\t}\n \t\t\t\t// we do this just to increment the assertion counter\n \t\t\t\tREQUIRE(success);\n@@ -901,7 +906,7 @@ void Query::Execute() {\n \t\t\t          << string(result->column_count(), 'I') << termcolor::reset << termcolor::bold << \"\\\"\"\n \t\t\t          << termcolor::reset << std::endl;\n \t\t\tprint_line_sep();\n-\t\t\tFAIL();\n+\t\t\tFAIL_LINE(file_name, query_line);\n \t\t}\n \t} else {\n \t\tbool hash_compare_error = false;\n@@ -919,7 +924,7 @@ void Query::Execute() {\n \t\t\tif (values.size() <= 0) {\n \t\t\t\tprint_error_header(\"Error in test: attempting to compare hash but no hash found!\", file_name,\n \t\t\t\t                   query_line);\n-\t\t\t\tFAIL();\n+\t\t\t\tFAIL_LINE(file_name, query_line);\n \t\t\t}\n \t\t\thash_compare_error = strcmp(values[0].c_str(), zHash) != 0;\n \t\t}\n@@ -934,7 +939,7 @@ void Query::Execute() {\n \t\t\tprint_header(\"Actual result:\");\n \t\t\tprint_line_sep();\n \t\t\tresult->Print();\n-\t\t\tFAIL();\n+\t\t\tFAIL_LINE(file_name, query_line);\n \t\t}\n \t\tREQUIRE(!hash_compare_error);\n \t}\n",
  "problem_statement": "Unify scan ops and allow filter and projection pushdown into table functions (e.g. CSV/Parquet reader)\nHi,\r\n\r\nis it already possible to read only specific columns from (gzipped) csv-files  into an existing table?\r\nIt would save us from preprocessing files or loading unneeded data.\r\n\r\n(unfortunately, read_csv_auto might crash, if data type is guessed incorrectly)\n",
  "hints_text": "This is not possible yet, but is on the agenda for extra features. Currently all the columns of the CSV file are always read.\nDo you have a preference on where this should be implemented? \r\nFiltering rows to import by field value would be cool, too.\r\n\nMy idea would be to implement it as part of the CSV scan, where any filters and projections are automatically pushed into the scan. E.g. if you do:\r\n\r\n```sql\r\n-- test.csv has 4 columns (col1, col2, col3, col4)\r\nSELECT col1 FROM read_csv('test.csv') WHERE col4=1;\r\n```\r\nOnly col1 and col4 will be read, and values of col1 will only be read for which col4 is equal to 1.\r\n\r\nThe table scans that we have that scan the base tables already do something similar, and we have plans to extend that support to any scans (including scans over external files, like parquet/csv files).\nGoing to reopen this with a new title, as we don't have an issue for it yet but it's something I want to do sooner rather than later :)\nParquet reader already does projection pushdown\nFair point ^^, but currently in an orthogonal way to the main scan, right? I think the unification will clean up the code a lot here.\ncorrect, it will",
  "created_at": "2020-09-07T16:25:13Z"
}