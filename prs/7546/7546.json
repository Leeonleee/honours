{
  "repo": "duckdb/duckdb",
  "pull_number": 7546,
  "instance_id": "duckdb__duckdb-7546",
  "issue_numbers": [
    "7543"
  ],
  "base_commit": "d3562b54ee03f4aaa000cf6700124f06d13a9d96",
  "patch": "diff --git a/src/core_functions/aggregate/holistic/mode.cpp b/src/core_functions/aggregate/holistic/mode.cpp\nindex 1e70905a4822..48cac7c6075c 100644\n--- a/src/core_functions/aggregate/holistic/mode.cpp\n+++ b/src/core_functions/aggregate/holistic/mode.cpp\n@@ -35,7 +35,13 @@ using FrameBounds = std::pair<idx_t, idx_t>;\n \n template <class KEY_TYPE>\n struct ModeState {\n-\tusing Counts = unordered_map<KEY_TYPE, size_t>;\n+\tstruct ModeAttr {\n+\t\tModeAttr() : count(0), first_row(std::numeric_limits<idx_t>::max()) {\n+\t\t}\n+\t\tsize_t count;\n+\t\tidx_t first_row;\n+\t};\n+\tusing Counts = unordered_map<KEY_TYPE, ModeAttr>;\n \n \tCounts *frequency_map;\n \tKEY_TYPE *mode;\n@@ -68,10 +74,14 @@ struct ModeState {\n \t\tvalid = false;\n \t}\n \n-\tvoid ModeAdd(const KEY_TYPE &key) {\n-\t\tauto new_count = ((*frequency_map)[key] += 1);\n+\tvoid ModeAdd(const KEY_TYPE &key, idx_t row) {\n+\t\tauto &attr = (*frequency_map)[key];\n+\t\tauto new_count = (attr.count += 1);\n \t\tif (new_count == 1) {\n \t\t\t++nonzero;\n+\t\t\tattr.first_row = row;\n+\t\t} else {\n+\t\t\tattr.first_row = MinValue(row, attr.first_row);\n \t\t}\n \t\tif (new_count > count) {\n \t\t\tvalid = true;\n@@ -84,12 +94,12 @@ struct ModeState {\n \t\t}\n \t}\n \n-\tvoid ModeRm(const KEY_TYPE &key) {\n-\t\tauto i = frequency_map->find(key);\n-\t\tauto old_count = i->second;\n+\tvoid ModeRm(const KEY_TYPE &key, idx_t frame) {\n+\t\tauto &attr = (*frequency_map)[key];\n+\t\tauto old_count = attr.count;\n \t\tnonzero -= int(old_count == 1);\n \n-\t\ti->second -= 1;\n+\t\tattr.count -= 1;\n \t\tif (count == old_count && key == *mode) {\n \t\t\tvalid = false;\n \t\t}\n@@ -99,9 +109,10 @@ struct ModeState {\n \t\t//! Initialize control variables to first variable of the frequency map\n \t\tauto highest_frequency = frequency_map->begin();\n \t\tfor (auto i = highest_frequency; i != frequency_map->end(); ++i) {\n-\t\t\t// Tie break with the lowest\n-\t\t\tif (i->second > highest_frequency->second ||\n-\t\t\t    (i->second == highest_frequency->second && i->first < highest_frequency->first)) {\n+\t\t\t// Tie break with the lowest insert position\n+\t\t\tif (i->second.count > highest_frequency->second.count ||\n+\t\t\t    (i->second.count == highest_frequency->second.count &&\n+\t\t\t     i->second.first_row < highest_frequency->second.first_row)) {\n \t\t\t\thighest_frequency = i;\n \t\t\t}\n \t\t}\n@@ -146,10 +157,13 @@ struct ModeFunction {\n \ttemplate <class INPUT_TYPE, class STATE, class OP>\n \tstatic void Operation(STATE *state, AggregateInputData &, INPUT_TYPE *input, ValidityMask &mask, idx_t idx) {\n \t\tif (!state->frequency_map) {\n-\t\t\tstate->frequency_map = new unordered_map<KEY_TYPE, size_t>();\n+\t\t\tstate->frequency_map = new typename STATE::Counts();\n \t\t}\n \t\tauto key = KEY_TYPE(input[idx]);\n-\t\t(*state->frequency_map)[key]++;\n+\t\tauto &i = (*state->frequency_map)[key];\n+\t\ti.count++;\n+\t\ti.first_row = MinValue<idx_t>(i.first_row, state->count);\n+\t\tstate->count++;\n \t}\n \n \ttemplate <class STATE, class OP>\n@@ -159,12 +173,15 @@ struct ModeFunction {\n \t\t}\n \t\tif (!target->frequency_map) {\n \t\t\t// Copy - don't destroy! Otherwise windowing will break.\n-\t\t\ttarget->frequency_map = new unordered_map<KEY_TYPE, size_t>(*source.frequency_map);\n+\t\t\ttarget->frequency_map = new typename STATE::Counts(*source.frequency_map);\n \t\t\treturn;\n \t\t}\n \t\tfor (auto &val : *source.frequency_map) {\n-\t\t\t(*target->frequency_map)[val.first] += val.second;\n+\t\t\tauto &i = (*target->frequency_map)[val.first];\n+\t\t\ti.count += val.second.count;\n+\t\t\ti.first_row = MinValue(i.first_row, val.second.first_row);\n \t\t}\n+\t\ttarget->count += source.count;\n \t}\n \n \ttemplate <class INPUT_TYPE, class STATE>\n@@ -185,10 +202,13 @@ struct ModeFunction {\n \tstatic void ConstantOperation(STATE *state, AggregateInputData &, INPUT_TYPE *input, ValidityMask &mask,\n \t                              idx_t count) {\n \t\tif (!state->frequency_map) {\n-\t\t\tstate->frequency_map = new unordered_map<KEY_TYPE, size_t>();\n+\t\t\tstate->frequency_map = new typename STATE::Counts();\n \t\t}\n \t\tauto key = KEY_TYPE(input[0]);\n-\t\t(*state->frequency_map)[key] += count;\n+\t\tauto &i = (*state->frequency_map)[key];\n+\t\ti.count += count;\n+\t\ti.first_row = MinValue<idx_t>(i.first_row, state->count);\n+\t\tstate->count += count;\n \t}\n \n \ttemplate <class STATE, class INPUT_TYPE, class RESULT_TYPE>\n@@ -201,7 +221,7 @@ struct ModeFunction {\n \t\tModeIncluded included(fmask, dmask, bias);\n \n \t\tif (!state->frequency_map) {\n-\t\t\tstate->frequency_map = new unordered_map<KEY_TYPE, size_t>();\n+\t\t\tstate->frequency_map = new typename STATE::Counts;\n \t\t}\n \t\tconst double tau = .25;\n \t\tif (state->nonzero <= tau * state->frequency_map->size()) {\n@@ -209,31 +229,31 @@ struct ModeFunction {\n \t\t\t// for f \u2208 F do\n \t\t\tfor (auto f = frame.first; f < frame.second; ++f) {\n \t\t\t\tif (included(f)) {\n-\t\t\t\t\tstate->ModeAdd(KEY_TYPE(data[f]));\n+\t\t\t\t\tstate->ModeAdd(KEY_TYPE(data[f]), f);\n \t\t\t\t}\n \t\t\t}\n \t\t} else {\n \t\t\t// for f \u2208 P \\ F do\n \t\t\tfor (auto p = prev.first; p < frame.first; ++p) {\n \t\t\t\tif (included(p)) {\n-\t\t\t\t\tstate->ModeRm(KEY_TYPE(data[p]));\n+\t\t\t\t\tstate->ModeRm(KEY_TYPE(data[p]), p);\n \t\t\t\t}\n \t\t\t}\n \t\t\tfor (auto p = frame.second; p < prev.second; ++p) {\n \t\t\t\tif (included(p)) {\n-\t\t\t\t\tstate->ModeRm(KEY_TYPE(data[p]));\n+\t\t\t\t\tstate->ModeRm(KEY_TYPE(data[p]), p);\n \t\t\t\t}\n \t\t\t}\n \n \t\t\t// for f \u2208 F \\ P do\n \t\t\tfor (auto f = frame.first; f < prev.first; ++f) {\n \t\t\t\tif (included(f)) {\n-\t\t\t\t\tstate->ModeAdd(KEY_TYPE(data[f]));\n+\t\t\t\t\tstate->ModeAdd(KEY_TYPE(data[f]), f);\n \t\t\t\t}\n \t\t\t}\n \t\t\tfor (auto f = prev.second; f < frame.second; ++f) {\n \t\t\t\tif (included(f)) {\n-\t\t\t\t\tstate->ModeAdd(KEY_TYPE(data[f]));\n+\t\t\t\t\tstate->ModeAdd(KEY_TYPE(data[f]), f);\n \t\t\t\t}\n \t\t\t}\n \t\t}\n@@ -243,7 +263,7 @@ struct ModeFunction {\n \t\t\tauto highest_frequency = state->Scan();\n \t\t\tif (highest_frequency != state->frequency_map->end()) {\n \t\t\t\t*(state->mode) = highest_frequency->first;\n-\t\t\t\tstate->count = highest_frequency->second;\n+\t\t\t\tstate->count = highest_frequency->second.count;\n \t\t\t\tstate->valid = (state->count > 0);\n \t\t\t}\n \t\t}\ndiff --git a/src/planner/binder/expression/bind_aggregate_expression.cpp b/src/planner/binder/expression/bind_aggregate_expression.cpp\nindex c634ddedf5cb..913ce5ec36e2 100644\n--- a/src/planner/binder/expression/bind_aggregate_expression.cpp\n+++ b/src/planner/binder/expression/bind_aggregate_expression.cpp\n@@ -99,7 +99,8 @@ BindResult BaseSelectBinder::BindAggregate(FunctionExpression &aggr, AggregateFu\n \tbool negate_fractions = false;\n \tif (aggr.order_bys && aggr.order_bys->orders.size() == 1) {\n \t\tconst auto &func_name = aggr.function_name;\n-\t\tordered_set_agg = (func_name == \"quantile_cont\" || func_name == \"quantile_disc\" || func_name == \"mode\");\n+\t\tordered_set_agg = (func_name == \"quantile_cont\" || func_name == \"quantile_disc\" ||\n+\t\t                   (func_name == \"mode\" && aggr.children.empty()));\n \n \t\tif (ordered_set_agg) {\n \t\t\tauto &config = DBConfig::GetConfig(context);\n@@ -182,13 +183,20 @@ BindResult BaseSelectBinder::BindAggregate(FunctionExpression &aggr, AggregateFu\n \tvector<unique_ptr<Expression>> children;\n \n \tif (ordered_set_agg) {\n+\t\tconst bool order_sensitive = (aggr.function_name == \"mode\");\n \t\tfor (auto &order : aggr.order_bys->orders) {\n \t\t\tauto &child = BoundExpression::GetExpression(*order.expression);\n \t\t\ttypes.push_back(child->return_type);\n \t\t\targuments.push_back(child->return_type);\n-\t\t\tchildren.push_back(std::move(child));\n+\t\t\tif (order_sensitive) {\n+\t\t\t\tchildren.push_back(child->Copy());\n+\t\t\t} else {\n+\t\t\t\tchildren.push_back(std::move(child));\n+\t\t\t}\n+\t\t}\n+\t\tif (!order_sensitive) {\n+\t\t\taggr.order_bys->orders.clear();\n \t\t}\n-\t\taggr.order_bys->orders.clear();\n \t}\n \n \tfor (idx_t i = 0; i < aggr.children.size(); i++) {\n",
  "test_patch": "diff --git a/test/sql/aggregate/aggregates/test_mode.test b/test/sql/aggregate/aggregates/test_mode.test\nindex 3b1b2762a8b9..c19abbae132a 100644\n--- a/test/sql/aggregate/aggregates/test_mode.test\n+++ b/test/sql/aggregate/aggregates/test_mode.test\n@@ -281,3 +281,20 @@ select k, v, mode(v) over (partition by k)\n 2\t2\t2\n 2\t5\t2\n 3\t1\t1\n+\n+# MODE is order-sensitive, so this should bind and return the larger value\n+query I\n+SELECT MODE(order_occurrences ORDER BY order_occurrences DESC) FROM (\n+VALUES\n+\t(500, 1),\n+\t(1000, 2),\n+\t(800, 3),\n+\t(1000, 4),\n+\t(500, 5),\n+\t(550, 6),\n+\t(400, 7),\n+\t(200, 8),\n+\t(10, 9)\n+)items_per_order(order_occurrences, item_count);\n+----\n+1000\ndiff --git a/test/sql/aggregate/aggregates/test_ordered_aggregates.test b/test/sql/aggregate/aggregates/test_ordered_aggregates.test\nindex 7d021e8327cb..be854b7080fe 100644\n--- a/test/sql/aggregate/aggregates/test_ordered_aggregates.test\n+++ b/test/sql/aggregate/aggregates/test_ordered_aggregates.test\n@@ -87,6 +87,23 @@ FROM VALUES (11000), (3100), (2900), (2800), (2600), (2500) AS tab(col);\n ----\n [3100, 2900, 2600]\n \n+# MODE is order-sensitive\n+query I\n+SELECT MODE() WITHIN GROUP (ORDER BY order_occurrences DESC) FROM (\n+VALUES\n+\t(500, 1),\n+\t(1000, 2),\n+\t(800, 3),\n+\t(1000, 4),\n+\t(500, 5),\n+\t(550, 6),\n+\t(400, 7),\n+\t(200, 8),\n+\t(10, 9)\n+) items_per_order(order_occurrences, item_count);\n+----\n+1000\n+\n #\n # Error checking\n #\ndiff --git a/test/sql/types/timestamp/test_infinite_time.test b/test/sql/types/timestamp/test_infinite_time.test\nindex 7a97f977f1b4..f3cff00d0182 100644\n--- a/test/sql/types/timestamp/test_infinite_time.test\n+++ b/test/sql/types/timestamp/test_infinite_time.test\n@@ -135,13 +135,7 @@ query III\n SELECT MODE(ts), MODE(tstz), MODE(dt)\n FROM specials;\n ----\n--infinity\t-infinity\t-infinity\n-\n-query III\n-SELECT MODE(ts), MODE(tstz), MODE(dt)\n-FROM specials;\n-----\n--infinity\t-infinity\t-infinity\n+infinity\tinfinity\tinfinity\n \n query III\n SELECT APPROX_COUNT_DISTINCT(ts), APPROX_COUNT_DISTINCT(tstz), APPROX_COUNT_DISTINCT(dt)\n",
  "problem_statement": "MODE() WITHIN GROUP Incorrect Output\n### What happens?\n\nMODE() WITHIN GROUP when provided with an ORDER BY value DESC doesn't produce the correct output.\n\n### To Reproduce\n\n```\r\nSELECT MODE() WITHIN GROUP (ORDER BY order_occurrences DESC) FROM (\r\nVALUES\r\n\t(500, 1),\r\n\t(1000, 2),\r\n\t(800, 3),\r\n\t(1000, 4),\r\n\t(500, 5),\r\n\t(550, 6),\r\n\t(400, 7),\r\n\t(200, 8),\r\n\t(10, 9)\r\n)items_per_order(order_occurrences, item_count);\r\n```\r\nShould output 1000, but gives 500. \r\n\r\nTested in the DuckDB shell with v.0.7.2-dev2931 as well as within a Workspace running 0.7.0. \n\n### OS:\n\nWeb\n\n### DuckDB Version:\n\nDuckDB Web Shell Database: v0.7.2-dev2931\n\n### DuckDB Client:\n\nWeb\n\n### Full Name:\n\nDwayne McMurchy\n\n### Affiliation:\n\nNone\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\n",
  "hints_text": "Thanks for the report! I can confirm the ties are indeed not correctly resolved according to the `ORDER BY` predicate for `MODE`.\r\n\r\nPerhaps related - ordered aggregates do not seem to work together with `MODE` correctly either:\r\n\r\n```sql\r\nSELECT MODE(order_occurrences ORDER BY order_occurrences DESC) FROM (\r\nVALUES\r\n\t(500, 1),\r\n\t(1000, 2),\r\n\t(800, 3),\r\n\t(1000, 4),\r\n\t(500, 5),\r\n\t(550, 6),\r\n\t(400, 7),\r\n\t(200, 8),\r\n\t(10, 9)\r\n)items_per_order(order_occurrences, item_count);\r\n-- Error: Binder Error: No function matches the given name and argument types 'mode(INTEGER, INTEGER)'. You might need to add explicit type casts.\r\n```\nAh, we are not tracking the actual ordering, which could be a problem for all of them. From the [PG docs](https://www.postgresql.org/docs/current/functions-aggregate.html#FUNCTIONS-ORDEREDSET-TABLE):\r\n\r\n> Each of the \u201chypothetical-set\u201d aggregates listed in [Table 9.61](https://www.postgresql.org/docs/current/functions-aggregate.html#FUNCTIONS-HYPOTHETICAL-TABLE) is associated with a window function of the same name defined in [Section 9.22](https://www.postgresql.org/docs/current/functions-window.html). In each case, the aggregate's result is the value that the associated window function would have returned for the \u201chypothetical\u201d row constructed from args, if such a row had been added to the sorted group of rows represented by the sorted_args.\r\n\r\nSo we should be producing the same result as\r\n\r\n```sql\r\nSELECT DISTINCT MODE(order_occurrences) OVER (ORDER BY order_occurrences DESC) FROM ...\r\n```\r\n\r\nThis may be tricky to retrofit.\nPossible fix:\r\n\r\n1. Mark `MODE` as an order-sensitive aggregate\r\n2. Tie-break based on hash table insert ordering\nThat did it. \r\n\r\nThis is sort of analogous to negating the arguments to percentiles when sorting.",
  "created_at": "2023-05-16T19:14:25Z"
}