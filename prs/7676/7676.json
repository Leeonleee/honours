{
  "repo": "duckdb/duckdb",
  "pull_number": 7676,
  "instance_id": "duckdb__duckdb-7676",
  "issue_numbers": [
    "7660",
    "7660"
  ],
  "base_commit": "aac029220ae28679b98bfbb68cdee5572ecfcccf",
  "patch": "diff --git a/src/catalog/catalog.cpp b/src/catalog/catalog.cpp\nindex 34ce7a8eb946..0ecbe424e5e5 100644\n--- a/src/catalog/catalog.cpp\n+++ b/src/catalog/catalog.cpp\n@@ -690,15 +690,16 @@ bool Catalog::TypeExists(ClientContext &context, const string &catalog_name, con\n vector<reference<SchemaCatalogEntry>> Catalog::GetSchemas(ClientContext &context, const string &catalog_name) {\n \tvector<reference<Catalog>> catalogs;\n \tif (IsInvalidCatalog(catalog_name)) {\n-\t\tunordered_set<string> name;\n+\t\treference_set_t<Catalog> inserted_catalogs;\n \n \t\tauto &search_path = *context.client_data->catalog_search_path;\n \t\tfor (auto &entry : search_path.Get()) {\n-\t\t\tif (name.find(entry.catalog) != name.end()) {\n+\t\t\tauto &catalog = Catalog::GetCatalog(context, entry.catalog);\n+\t\t\tif (inserted_catalogs.find(catalog) != inserted_catalogs.end()) {\n \t\t\t\tcontinue;\n \t\t\t}\n-\t\t\tname.insert(entry.catalog);\n-\t\t\tcatalogs.push_back(Catalog::GetCatalog(context, entry.catalog));\n+\t\t\tinserted_catalogs.insert(catalog);\n+\t\t\tcatalogs.push_back(catalog);\n \t\t}\n \t} else {\n \t\tcatalogs.push_back(Catalog::GetCatalog(context, catalog_name));\n",
  "test_patch": "diff --git a/test/sql/attach/attach_issue_7660.test b/test/sql/attach/attach_issue_7660.test\nnew file mode 100644\nindex 000000000000..303f367b8983\n--- /dev/null\n+++ b/test/sql/attach/attach_issue_7660.test\n@@ -0,0 +1,39 @@\n+# name: test/sql/attach/attach_issue_7660.test\n+# description: Issue #7660 - USE databases causes export database to produce duplicate data\n+# group: [attach]\n+\n+require noforcestorage\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+attach ':memory:' as test;\n+\n+statement ok\n+use test;\n+\n+statement ok\n+create table tbl1 as select 1 as a;\n+\n+query I\n+FROM test.tbl1\n+----\n+1\n+\n+statement ok\n+export database '__TEST_DIR__/test_issue_7660';\n+\n+statement ok\n+USE memory\n+\n+statement ok\n+DETACH test\n+\n+statement ok\n+import database '__TEST_DIR__/test_issue_7660'\n+\n+query I\n+FROM tbl1\n+----\n+1\n",
  "problem_statement": "`USE databases` causes `export database` to produce duplicate data\n### What happens?\n\nIf you attach a databases, issue a use command to make it a default, and export the data to a folder, the resulting `load.sql` will include duplicate instructions to import the tables.\r\n\r\nThe issue comes from [bind_export.cpp](https://github.com/duckdb/duckdb/blob/master/src/planner/binder/statement/bind_export.cpp#L119) which asks for a list of schemas:\r\n```\r\nauto schemas = Catalog::GetSchemas(context, catalog);\r\n```\r\n\r\nAt that point the search path has relevant two entries - one with the result of the use command and one for the default catalog: \r\n```\r\n[1] = {duckdb::CatalogSearchEntry} \r\n catalog = {std::string} \"test\"\r\n schema = {std::string} \"main\"\r\n[2] = {duckdb::CatalogSearchEntry} \r\n catalog = {std::string} \"\"\r\n schema = {std::string} \"main\"\r\n ```\r\n \r\nWhich then resolves [here](https://github.com/duckdb/duckdb/blob/master/src/catalog/catalog.cpp#L701) to a schema list which contains `test.main` twice. \r\n \r\nAs a result the tables in the schema are visited twice and the file export contains duplicate. \r\n\r\nI'm not sure if that's the export command that uses the search path wrong, or a more fundamental issue with the catalog API. It feels to me that GetSchemas should never have duplicates.\r\n\n\n### To Reproduce\n\n```\r\nv0.8.0 e8e4cea5ec\r\nEnter \".help\" for usage hints.\r\nConnected to a transient in-memory database.\r\nUse \".open FILENAME\" to reopen on a persistent database.\r\nD attach ':memory:' as test;\r\nD use test;\r\nD create table tbl1 as select 1 as a;\r\nD export database 'test_export';\r\n```\r\n\r\nWhich results in:\r\n```\r\n\u00bb cat test_export/load.sql \r\nCOPY tbl1 FROM 'test_export/tbl_.csv' (FORMAT 'csv', quote '\"', delimiter ',', header 0);\r\nCOPY tbl1 FROM 'test_export/tbl__1.csv' (FORMAT 'csv', quote '\"', delimiter ',', header 0);\r\n```\n\n### OS:\n\nMacOS\n\n### DuckDB Version:\n\n0.8.0\n\n### DuckDB Client:\n\ncli\n\n### Full Name:\n\nBoaz Leskes\n\n### Affiliation:\n\nMotherDuck\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\n`USE databases` causes `export database` to produce duplicate data\n### What happens?\n\nIf you attach a databases, issue a use command to make it a default, and export the data to a folder, the resulting `load.sql` will include duplicate instructions to import the tables.\r\n\r\nThe issue comes from [bind_export.cpp](https://github.com/duckdb/duckdb/blob/master/src/planner/binder/statement/bind_export.cpp#L119) which asks for a list of schemas:\r\n```\r\nauto schemas = Catalog::GetSchemas(context, catalog);\r\n```\r\n\r\nAt that point the search path has relevant two entries - one with the result of the use command and one for the default catalog: \r\n```\r\n[1] = {duckdb::CatalogSearchEntry} \r\n catalog = {std::string} \"test\"\r\n schema = {std::string} \"main\"\r\n[2] = {duckdb::CatalogSearchEntry} \r\n catalog = {std::string} \"\"\r\n schema = {std::string} \"main\"\r\n ```\r\n \r\nWhich then resolves [here](https://github.com/duckdb/duckdb/blob/master/src/catalog/catalog.cpp#L701) to a schema list which contains `test.main` twice. \r\n \r\nAs a result the tables in the schema are visited twice and the file export contains duplicate. \r\n\r\nI'm not sure if that's the export command that uses the search path wrong, or a more fundamental issue with the catalog API. It feels to me that GetSchemas should never have duplicates.\r\n\n\n### To Reproduce\n\n```\r\nv0.8.0 e8e4cea5ec\r\nEnter \".help\" for usage hints.\r\nConnected to a transient in-memory database.\r\nUse \".open FILENAME\" to reopen on a persistent database.\r\nD attach ':memory:' as test;\r\nD use test;\r\nD create table tbl1 as select 1 as a;\r\nD export database 'test_export';\r\n```\r\n\r\nWhich results in:\r\n```\r\n\u00bb cat test_export/load.sql \r\nCOPY tbl1 FROM 'test_export/tbl_.csv' (FORMAT 'csv', quote '\"', delimiter ',', header 0);\r\nCOPY tbl1 FROM 'test_export/tbl__1.csv' (FORMAT 'csv', quote '\"', delimiter ',', header 0);\r\n```\n\n### OS:\n\nMacOS\n\n### DuckDB Version:\n\n0.8.0\n\n### DuckDB Client:\n\ncli\n\n### Full Name:\n\nBoaz Leskes\n\n### Affiliation:\n\nMotherDuck\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\n",
  "hints_text": "\n",
  "created_at": "2023-05-25T10:51:01Z"
}