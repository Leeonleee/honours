You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
OFFSET -1  - Uncaught Exception
-1 offset causes duckdb to crash.
e.g 
~~~
CREATE  MACRO my_seq(srt, nlimit, noffset) as TABLE SELECT * FROM generate_series(srt) LIMIT nlimit OFFSET noffset;
SELECT  * FROM  my_seq(10,5,-1);
~~~



OFFSET -1  - Uncaught Exception
-1 offset causes duckdb to crash.
e.g 
~~~
CREATE  MACRO my_seq(srt, nlimit, noffset) as TABLE SELECT * FROM generate_series(srt) LIMIT nlimit OFFSET noffset;
SELECT  * FROM  my_seq(10,5,-1);
~~~




</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
3: </div>
4: <p>&nbsp;</p>
5: 
6: <p align="center">
7:   <a href="https://github.com/duckdb/duckdb/actions">
8:     <img src="https://github.com/cwida/duckdb/workflows/.github/workflows/main.yml/badge.svg?branch=master" alt=".github/workflows/main.yml">
9:   </a>
10:   <a href="https://www.codefactor.io/repository/github/cwida/duckdb">
11:     <img src="https://www.codefactor.io/repository/github/cwida/duckdb/badge" alt="CodeFactor"/>
12:   </a>
13:   <a href="https://app.codecov.io/gh/duckdb/duckdb">
14:     <img src="https://codecov.io/gh/duckdb/duckdb/branch/master/graph/badge.svg?token=FaxjcfFghN" alt="codecov"/>
15:   </a>
16:   <a href="https://discord.gg/tcvwpjfnZx">
17:     <img src="https://shields.io/discord/909674491309850675" alt="discord" />
18:   </a>
19: </p>
20: 
21: ## DuckDB
22: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on the goals of DuckDB, please refer to [the Why DuckDB page on our website](https://duckdb.org/why_duckdb).
23: 
24: ## Installation
25: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
26: 
27: ## Data Import
28: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
29: 
30: ```sql
31: SELECT * FROM 'myfile.csv';
32: SELECT * FROM 'myfile.parquet';
33: ```
34: 
35: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
36: 
37: ## SQL Reference
38: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
39: 
40: ## Development
41: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`.
42: 
43: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
44: 
45: 
[end of README.md]
[start of src/planner/binder/query_node/bind_select_node.cpp]
1: #include "duckdb/common/limits.hpp"
2: #include "duckdb/common/string_util.hpp"
3: #include "duckdb/execution/expression_executor.hpp"
4: #include "duckdb/main/config.hpp"
5: #include "duckdb/parser/expression/columnref_expression.hpp"
6: #include "duckdb/parser/expression/comparison_expression.hpp"
7: #include "duckdb/parser/expression/constant_expression.hpp"
8: #include "duckdb/parser/expression/subquery_expression.hpp"
9: #include "duckdb/parser/query_node/select_node.hpp"
10: #include "duckdb/parser/tableref/joinref.hpp"
11: #include "duckdb/planner/binder.hpp"
12: #include "duckdb/planner/expression_binder/column_alias_binder.hpp"
13: #include "duckdb/planner/expression_binder/constant_binder.hpp"
14: #include "duckdb/planner/expression_binder/group_binder.hpp"
15: #include "duckdb/planner/expression_binder/having_binder.hpp"
16: #include "duckdb/planner/expression_binder/qualify_binder.hpp"
17: #include "duckdb/planner/expression_binder/order_binder.hpp"
18: #include "duckdb/planner/expression_binder/select_binder.hpp"
19: #include "duckdb/planner/expression_binder/where_binder.hpp"
20: #include "duckdb/planner/query_node/bound_select_node.hpp"
21: #include "duckdb/planner/expression_binder/aggregate_binder.hpp"
22: 
23: namespace duckdb {
24: 
25: unique_ptr<Expression> Binder::BindOrderExpression(OrderBinder &order_binder, unique_ptr<ParsedExpression> expr) {
26: 	// we treat the Distinct list as a order by
27: 	auto bound_expr = order_binder.Bind(move(expr));
28: 	if (!bound_expr) {
29: 		// DISTINCT ON non-integer constant
30: 		// remove the expression from the DISTINCT ON list
31: 		return nullptr;
32: 	}
33: 	D_ASSERT(bound_expr->type == ExpressionType::BOUND_COLUMN_REF);
34: 	return bound_expr;
35: }
36: 
37: unique_ptr<Expression> Binder::BindDelimiter(ClientContext &context, unique_ptr<ParsedExpression> delimiter,
38:                                              const LogicalType &type, Value &delimiter_value) {
39: 	auto new_binder = Binder::CreateBinder(context, this, true);
40: 	ExpressionBinder expr_binder(*new_binder, context);
41: 	expr_binder.target_type = type;
42: 	auto expr = expr_binder.Bind(delimiter);
43: 	if (expr->IsFoldable()) {
44: 		//! this is a constant
45: 		delimiter_value = ExpressionExecutor::EvaluateScalar(*expr).CastAs(type);
46: 		return nullptr;
47: 	}
48: 	return expr;
49: }
50: 
51: unique_ptr<BoundResultModifier> Binder::BindLimit(LimitModifier &limit_mod) {
52: 	auto result = make_unique<BoundLimitModifier>();
53: 	if (limit_mod.limit) {
54: 		Value val;
55: 		result->limit = BindDelimiter(context, move(limit_mod.limit), LogicalType::BIGINT, val);
56: 		if (!result->limit) {
57: 			result->limit_val = val.GetValue<int64_t>();
58: 		}
59: 	}
60: 	if (limit_mod.offset) {
61: 		Value val;
62: 		result->offset = BindDelimiter(context, move(limit_mod.offset), LogicalType::BIGINT, val);
63: 		if (!result->offset) {
64: 			result->offset_val = val.GetValue<int64_t>();
65: 		}
66: 	}
67: 	return move(result);
68: }
69: 
70: unique_ptr<BoundResultModifier> Binder::BindLimitPercent(LimitPercentModifier &limit_mod) {
71: 	auto result = make_unique<BoundLimitPercentModifier>();
72: 	if (limit_mod.limit) {
73: 		Value val;
74: 		result->limit = BindDelimiter(context, move(limit_mod.limit), LogicalType::DOUBLE, val);
75: 		if (!result->limit) {
76: 			result->limit_percent = val.GetValue<double>();
77: 			if (result->limit_percent < 0.0) {
78: 				throw Exception("Limit percentage can't be negative value");
79: 			}
80: 		}
81: 	}
82: 	if (limit_mod.offset) {
83: 		Value val;
84: 		result->offset = BindDelimiter(context, move(limit_mod.offset), LogicalType::BIGINT, val);
85: 		if (!result->offset) {
86: 			result->offset_val = val.GetValue<int64_t>();
87: 		}
88: 	}
89: 	return move(result);
90: }
91: 
92: void Binder::BindModifiers(OrderBinder &order_binder, QueryNode &statement, BoundQueryNode &result) {
93: 	for (auto &mod : statement.modifiers) {
94: 		unique_ptr<BoundResultModifier> bound_modifier;
95: 		switch (mod->type) {
96: 		case ResultModifierType::DISTINCT_MODIFIER: {
97: 			auto &distinct = (DistinctModifier &)*mod;
98: 			auto bound_distinct = make_unique<BoundDistinctModifier>();
99: 			if (distinct.distinct_on_targets.empty()) {
100: 				for (idx_t i = 0; i < result.names.size(); i++) {
101: 					distinct.distinct_on_targets.push_back(make_unique<ConstantExpression>(Value::INTEGER(1 + i)));
102: 				}
103: 			}
104: 			for (auto &distinct_on_target : distinct.distinct_on_targets) {
105: 				auto expr = BindOrderExpression(order_binder, move(distinct_on_target));
106: 				if (!expr) {
107: 					continue;
108: 				}
109: 				bound_distinct->target_distincts.push_back(move(expr));
110: 			}
111: 			bound_modifier = move(bound_distinct);
112: 			break;
113: 		}
114: 		case ResultModifierType::ORDER_MODIFIER: {
115: 			auto &order = (OrderModifier &)*mod;
116: 			auto bound_order = make_unique<BoundOrderModifier>();
117: 			auto &config = DBConfig::GetConfig(context);
118: 			D_ASSERT(!order.orders.empty());
119: 			if (order.orders[0].expression->type == ExpressionType::STAR) {
120: 				// ORDER BY ALL
121: 				// replace the order list with the maximum order by count
122: 				D_ASSERT(order.orders.size() == 1);
123: 				auto order_type = order.orders[0].type;
124: 				auto null_order = order.orders[0].null_order;
125: 
126: 				vector<OrderByNode> new_orders;
127: 				for (idx_t i = 0; i < order_binder.MaxCount(); i++) {
128: 					new_orders.emplace_back(order_type, null_order,
129: 					                        make_unique<ConstantExpression>(Value::INTEGER(i + 1)));
130: 				}
131: 				order.orders = move(new_orders);
132: 			}
133: 			for (auto &order_node : order.orders) {
134: 				auto order_expression = BindOrderExpression(order_binder, move(order_node.expression));
135: 				if (!order_expression) {
136: 					continue;
137: 				}
138: 				auto type = order_node.type == OrderType::ORDER_DEFAULT ? config.default_order_type : order_node.type;
139: 				auto null_order = order_node.null_order == OrderByNullType::ORDER_DEFAULT ? config.default_null_order
140: 				                                                                          : order_node.null_order;
141: 				bound_order->orders.emplace_back(type, null_order, move(order_expression));
142: 			}
143: 			if (!bound_order->orders.empty()) {
144: 				bound_modifier = move(bound_order);
145: 			}
146: 			break;
147: 		}
148: 		case ResultModifierType::LIMIT_MODIFIER:
149: 			bound_modifier = BindLimit((LimitModifier &)*mod);
150: 			break;
151: 		case ResultModifierType::LIMIT_PERCENT_MODIFIER:
152: 			bound_modifier = BindLimitPercent((LimitPercentModifier &)*mod);
153: 			break;
154: 		default:
155: 			throw Exception("Unsupported result modifier");
156: 		}
157: 		if (bound_modifier) {
158: 			result.modifiers.push_back(move(bound_modifier));
159: 		}
160: 	}
161: }
162: 
163: void Binder::BindModifierTypes(BoundQueryNode &result, const vector<LogicalType> &sql_types, idx_t projection_index) {
164: 	for (auto &bound_mod : result.modifiers) {
165: 		switch (bound_mod->type) {
166: 		case ResultModifierType::DISTINCT_MODIFIER: {
167: 			auto &distinct = (BoundDistinctModifier &)*bound_mod;
168: 			if (distinct.target_distincts.empty()) {
169: 				// DISTINCT without a target: push references to the standard select list
170: 				for (idx_t i = 0; i < sql_types.size(); i++) {
171: 					distinct.target_distincts.push_back(
172: 					    make_unique<BoundColumnRefExpression>(sql_types[i], ColumnBinding(projection_index, i)));
173: 				}
174: 			} else {
175: 				// DISTINCT with target list: set types
176: 				for (auto &expr : distinct.target_distincts) {
177: 					D_ASSERT(expr->type == ExpressionType::BOUND_COLUMN_REF);
178: 					auto &bound_colref = (BoundColumnRefExpression &)*expr;
179: 					if (bound_colref.binding.column_index == DConstants::INVALID_INDEX) {
180: 						throw BinderException("Ambiguous name in DISTINCT ON!");
181: 					}
182: 					D_ASSERT(bound_colref.binding.column_index < sql_types.size());
183: 					bound_colref.return_type = sql_types[bound_colref.binding.column_index];
184: 				}
185: 			}
186: 			for (auto &target_distinct : distinct.target_distincts) {
187: 				auto &bound_colref = (BoundColumnRefExpression &)*target_distinct;
188: 				auto sql_type = sql_types[bound_colref.binding.column_index];
189: 				if (sql_type.id() == LogicalTypeId::VARCHAR) {
190: 					target_distinct = ExpressionBinder::PushCollation(context, move(target_distinct),
191: 					                                                  StringType::GetCollation(sql_type), true);
192: 				}
193: 			}
194: 			break;
195: 		}
196: 		case ResultModifierType::ORDER_MODIFIER: {
197: 			auto &order = (BoundOrderModifier &)*bound_mod;
198: 			for (auto &order_node : order.orders) {
199: 				auto &expr = order_node.expression;
200: 				D_ASSERT(expr->type == ExpressionType::BOUND_COLUMN_REF);
201: 				auto &bound_colref = (BoundColumnRefExpression &)*expr;
202: 				if (bound_colref.binding.column_index == DConstants::INVALID_INDEX) {
203: 					throw BinderException("Ambiguous name in ORDER BY!");
204: 				}
205: 				D_ASSERT(bound_colref.binding.column_index < sql_types.size());
206: 				auto sql_type = sql_types[bound_colref.binding.column_index];
207: 				bound_colref.return_type = sql_types[bound_colref.binding.column_index];
208: 				if (sql_type.id() == LogicalTypeId::VARCHAR) {
209: 					order_node.expression = ExpressionBinder::PushCollation(context, move(order_node.expression),
210: 					                                                        StringType::GetCollation(sql_type));
211: 				}
212: 			}
213: 			break;
214: 		}
215: 		default:
216: 			break;
217: 		}
218: 	}
219: }
220: 
221: unique_ptr<BoundQueryNode> Binder::BindNode(SelectNode &statement) {
222: 	auto result = make_unique<BoundSelectNode>();
223: 	result->projection_index = GenerateTableIndex();
224: 	result->group_index = GenerateTableIndex();
225: 	result->aggregate_index = GenerateTableIndex();
226: 	result->groupings_index = GenerateTableIndex();
227: 	result->window_index = GenerateTableIndex();
228: 	result->unnest_index = GenerateTableIndex();
229: 	result->prune_index = GenerateTableIndex();
230: 
231: 	// first bind the FROM table statement
232: 	result->from_table = Bind(*statement.from_table);
233: 
234: 	// bind the sample clause
235: 	if (statement.sample) {
236: 		result->sample_options = move(statement.sample);
237: 	}
238: 
239: 	// visit the select list and expand any "*" statements
240: 	vector<unique_ptr<ParsedExpression>> new_select_list;
241: 	for (auto &select_element : statement.select_list) {
242: 		if (select_element->GetExpressionType() == ExpressionType::STAR) {
243: 			// * statement, expand to all columns from the FROM clause
244: 			bind_context.GenerateAllColumnExpressions((StarExpression &)*select_element, new_select_list);
245: 		} else {
246: 			// regular statement, add it to the list
247: 			new_select_list.push_back(move(select_element));
248: 		}
249: 	}
250: 	if (new_select_list.empty()) {
251: 		throw BinderException("SELECT list is empty after resolving * expressions!");
252: 	}
253: 	statement.select_list = move(new_select_list);
254: 
255: 	// create a mapping of (alias -> index) and a mapping of (Expression -> index) for the SELECT list
256: 	case_insensitive_map_t<idx_t> alias_map;
257: 	expression_map_t<idx_t> projection_map;
258: 	for (idx_t i = 0; i < statement.select_list.size(); i++) {
259: 		auto &expr = statement.select_list[i];
260: 		result->names.push_back(expr->GetName());
261: 		ExpressionBinder::QualifyColumnNames(*this, expr);
262: 		if (!expr->alias.empty()) {
263: 			alias_map[expr->alias] = i;
264: 			result->names[i] = expr->alias;
265: 		}
266: 		projection_map[expr.get()] = i;
267: 		result->original_expressions.push_back(expr->Copy());
268: 	}
269: 	result->column_count = statement.select_list.size();
270: 
271: 	// first visit the WHERE clause
272: 	// the WHERE clause happens before the GROUP BY, PROJECTION or HAVING clauses
273: 	if (statement.where_clause) {
274: 		ColumnAliasBinder alias_binder(*result, alias_map);
275: 		WhereBinder where_binder(*this, context, &alias_binder);
276: 		unique_ptr<ParsedExpression> condition = move(statement.where_clause);
277: 		result->where_clause = where_binder.Bind(condition);
278: 	}
279: 
280: 	// now bind all the result modifiers; including DISTINCT and ORDER BY targets
281: 	OrderBinder order_binder({this}, result->projection_index, statement, alias_map, projection_map);
282: 	BindModifiers(order_binder, statement, *result);
283: 
284: 	vector<unique_ptr<ParsedExpression>> unbound_groups;
285: 	BoundGroupInformation info;
286: 	auto &group_expressions = statement.groups.group_expressions;
287: 	if (!group_expressions.empty()) {
288: 		// the statement has a GROUP BY clause, bind it
289: 		unbound_groups.resize(group_expressions.size());
290: 		GroupBinder group_binder(*this, context, statement, result->group_index, alias_map, info.alias_map);
291: 		for (idx_t i = 0; i < group_expressions.size(); i++) {
292: 
293: 			// we keep a copy of the unbound expression;
294: 			// we keep the unbound copy around to check for group references in the SELECT and HAVING clause
295: 			// the reason we want the unbound copy is because we want to figure out whether an expression
296: 			// is a group reference BEFORE binding in the SELECT/HAVING binder
297: 			group_binder.unbound_expression = group_expressions[i]->Copy();
298: 			group_binder.bind_index = i;
299: 
300: 			// bind the groups
301: 			LogicalType group_type;
302: 			auto bound_expr = group_binder.Bind(group_expressions[i], &group_type);
303: 			D_ASSERT(bound_expr->return_type.id() != LogicalTypeId::INVALID);
304: 
305: 			// push a potential collation, if necessary
306: 			bound_expr =
307: 			    ExpressionBinder::PushCollation(context, move(bound_expr), StringType::GetCollation(group_type), true);
308: 			result->groups.group_expressions.push_back(move(bound_expr));
309: 
310: 			// in the unbound expression we DO bind the table names of any ColumnRefs
311: 			// we do this to make sure that "table.a" and "a" are treated the same
312: 			// if we wouldn't do this then (SELECT test.a FROM test GROUP BY a) would not work because "test.a" <> "a"
313: 			// hence we convert "a" -> "test.a" in the unbound expression
314: 			unbound_groups[i] = move(group_binder.unbound_expression);
315: 			ExpressionBinder::QualifyColumnNames(*this, unbound_groups[i]);
316: 			info.map[unbound_groups[i].get()] = i;
317: 		}
318: 	}
319: 	result->groups.grouping_sets = move(statement.groups.grouping_sets);
320: 
321: 	// bind the HAVING clause, if any
322: 	if (statement.having) {
323: 		HavingBinder having_binder(*this, context, *result, info, alias_map);
324: 		ExpressionBinder::QualifyColumnNames(*this, statement.having);
325: 		result->having = having_binder.Bind(statement.having);
326: 	}
327: 
328: 	// bind the QUALIFY clause, if any
329: 	if (statement.qualify) {
330: 		QualifyBinder qualify_binder(*this, context, *result, info, alias_map);
331: 		ExpressionBinder::QualifyColumnNames(*this, statement.qualify);
332: 		result->qualify = qualify_binder.Bind(statement.qualify);
333: 	}
334: 
335: 	// after that, we bind to the SELECT list
336: 	SelectBinder select_binder(*this, context, *result, info);
337: 	vector<LogicalType> internal_sql_types;
338: 	for (idx_t i = 0; i < statement.select_list.size(); i++) {
339: 		LogicalType result_type;
340: 		auto expr = select_binder.Bind(statement.select_list[i], &result_type);
341: 		if (statement.aggregate_handling == AggregateHandling::FORCE_AGGREGATES && select_binder.HasBoundColumns()) {
342: 			if (select_binder.BoundAggregates()) {
343: 				throw BinderException("Cannot mix aggregates with non-aggregated columns!");
344: 			}
345: 			// we are forcing aggregates, and the node has columns bound
346: 			// this entry becomes a group
347: 			auto group_ref = make_unique<BoundColumnRefExpression>(
348: 			    expr->return_type, ColumnBinding(result->group_index, result->groups.group_expressions.size()));
349: 			result->groups.group_expressions.push_back(move(expr));
350: 			expr = move(group_ref);
351: 		}
352: 		result->select_list.push_back(move(expr));
353: 		if (i < result->column_count) {
354: 			result->types.push_back(result_type);
355: 		}
356: 		internal_sql_types.push_back(result_type);
357: 		if (statement.aggregate_handling == AggregateHandling::FORCE_AGGREGATES) {
358: 			select_binder.ResetBindings();
359: 		}
360: 	}
361: 	result->need_prune = result->select_list.size() > result->column_count;
362: 
363: 	// in the normal select binder, we bind columns as if there is no aggregation
364: 	// i.e. in the query [SELECT i, SUM(i) FROM integers;] the "i" will be bound as a normal column
365: 	// since we have an aggregation, we need to either (1) throw an error, or (2) wrap the column in a FIRST() aggregate
366: 	// we choose the former one [CONTROVERSIAL: this is the PostgreSQL behavior]
367: 	if (!result->groups.group_expressions.empty() || !result->aggregates.empty() || statement.having ||
368: 	    !result->groups.grouping_sets.empty()) {
369: 		if (statement.aggregate_handling == AggregateHandling::NO_AGGREGATES_ALLOWED) {
370: 			throw BinderException("Aggregates cannot be present in a Project relation!");
371: 		} else if (statement.aggregate_handling == AggregateHandling::STANDARD_HANDLING) {
372: 			if (select_binder.HasBoundColumns()) {
373: 				auto &bound_columns = select_binder.GetBoundColumns();
374: 				throw BinderException(
375: 				    FormatError(bound_columns[0].query_location,
376: 				                "column \"%s\" must appear in the GROUP BY clause or be used in an aggregate function",
377: 				                bound_columns[0].name));
378: 			}
379: 		}
380: 	}
381: 
382: 	// QUALIFY clause requires at least one window function to be specified in at least one of the SELECT column list or
383: 	// the filter predicate of the QUALIFY clause
384: 	if (statement.qualify && result->windows.empty()) {
385: 		throw BinderException("at least one window function must appear in the SELECT column or QUALIFY clause");
386: 	}
387: 
388: 	// now that the SELECT list is bound, we set the types of DISTINCT/ORDER BY expressions
389: 	BindModifierTypes(*result, internal_sql_types, result->projection_index);
390: 	return move(result);
391: }
392: 
393: } // namespace duckdb
[end of src/planner/binder/query_node/bind_select_node.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: