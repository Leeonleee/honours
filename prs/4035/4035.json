{
  "repo": "duckdb/duckdb",
  "pull_number": 4035,
  "instance_id": "duckdb__duckdb-4035",
  "issue_numbers": [
    "3969"
  ],
  "base_commit": "38f2861e2d6c2f449c4caa8fbb8f68e791adb22b",
  "patch": "diff --git a/.github/workflows/extensions.csv b/.github/workflows/extensions.csv\nindex 827656689d8d..c4c686c512a4 100644\n--- a/.github/workflows/extensions.csv\n+++ b/.github/workflows/extensions.csv\n@@ -1,2 +1,2 @@\n-sqlite_scanner,https://github.com/duckdblabs/sqlitescanner,f671de2cb6f0d1bba58f300262b81cfeb745197d\n-postgres_scanner,https://github.com/duckdblabs/postgresscanner,8bfe3bbdb089c62ab51792ebbb41d4e0b3f30619\n+sqlite_scanner,https://github.com/duckdblabs/sqlitescanner,a039bb0938ca25f198eb264b69561749652c6647\n+postgres_scanner,https://github.com/duckdblabs/postgresscanner,37231bf985fb825dccf79aad94ee0630dae2d7c6\ndiff --git a/extension/httpfs/include/s3fs.hpp b/extension/httpfs/include/s3fs.hpp\nindex 646769061c2c..5eefe480bcd1 100644\n--- a/extension/httpfs/include/s3fs.hpp\n+++ b/extension/httpfs/include/s3fs.hpp\n@@ -48,15 +48,15 @@ class S3FileSystem;\n // Holds the buffered data for 1 part of an S3 Multipart upload\n class S3WriteBuffer {\n public:\n-\texplicit S3WriteBuffer(idx_t buffer_start, size_t buffer_size, unique_ptr<BufferHandle> &buffer)\n-\t    : idx(0), buffer_start(buffer_start), buffer(std::move(buffer)) {\n+\texplicit S3WriteBuffer(idx_t buffer_start, size_t buffer_size, BufferHandle buffer_p)\n+\t    : idx(0), buffer_start(buffer_start), buffer(move(buffer_p)) {\n \t\tbuffer_end = buffer_start + buffer_size;\n \t\tpart_no = buffer_start / buffer_size;\n \t\tuploading = false;\n \t}\n \n \tvoid *Ptr() {\n-\t\treturn buffer->Ptr();\n+\t\treturn buffer.Ptr();\n \t}\n \n \t// The S3 multipart part number. Note that internally we start at 0 but AWS S3 starts at 1\n@@ -65,7 +65,7 @@ class S3WriteBuffer {\n \tidx_t idx;\n \tidx_t buffer_start;\n \tidx_t buffer_end;\n-\tunique_ptr<BufferHandle> buffer;\n+\tBufferHandle buffer;\n \tstd::atomic<bool> uploading;\n };\n \n@@ -87,6 +87,7 @@ class S3FileHandle : public HTTPFileHandle {\n \tconst S3AuthParams auth_params;\n \tconst S3ConfigParams config_params;\n \n+public:\n \tvoid Close() override;\n \tunique_ptr<ResponseWrapper> Initialize() override;\n \n@@ -113,6 +114,9 @@ class S3FileHandle : public HTTPFileHandle {\n \n class S3FileSystem : public HTTPFileSystem {\n public:\n+\texplicit S3FileSystem(BufferManager &buffer_manager) : buffer_manager(buffer_manager) {\n+\t}\n+\n \tconstexpr static int MULTIPART_UPLOAD_WAIT_BETWEEN_RETRIES_MS = 1000;\n \n \t// Global limits to write buffers\n@@ -121,11 +125,9 @@ class S3FileSystem : public HTTPFileSystem {\n \tstd::atomic<uint16_t> buffers_available;\n \tstd::atomic<uint16_t> threads_waiting_for_memory = {0};\n \n-\texplicit S3FileSystem(BufferManager &buffer_manager) : buffer_manager(buffer_manager) {\n-\t}\n-\n \tBufferManager &buffer_manager;\n \n+public:\n \t// HTTP Requests\n \tunique_ptr<ResponseWrapper> PostRequest(FileHandle &handle, string url, HeaderMap header_map,\n \t                                        unique_ptr<char[]> &buffer_out, idx_t &buffer_out_len, char *buffer_in,\ndiff --git a/extension/httpfs/s3fs.cpp b/extension/httpfs/s3fs.cpp\nindex 115fb5ab08ac..b4f7d2ea0561 100644\n--- a/extension/httpfs/s3fs.cpp\n+++ b/extension/httpfs/s3fs.cpp\n@@ -433,7 +433,7 @@ std::shared_ptr<S3WriteBuffer> S3FileSystem::GetBuffer(S3FileHandle &file_handle\n \t}\n \n \t// Try to allocate a buffer from the buffer manager\n-\tunique_ptr<BufferHandle> duckdb_buffer;\n+\tBufferHandle duckdb_buffer;\n \tbool set_waiting_for_memory = false;\n \n \twhile (true) {\n@@ -466,8 +466,8 @@ std::shared_ptr<S3WriteBuffer> S3FileSystem::GetBuffer(S3FileHandle &file_handle\n \t\t}\n \t}\n \n-\tauto new_write_buffer =\n-\t    make_shared<S3WriteBuffer>(write_buffer_idx * file_handle.part_size, file_handle.part_size, duckdb_buffer);\n+\tauto new_write_buffer = make_shared<S3WriteBuffer>(write_buffer_idx * file_handle.part_size, file_handle.part_size,\n+\t                                                   move(duckdb_buffer));\n \n \t{\n \t\tstd::unique_lock<std::mutex> lck(file_handle.write_buffers_lock);\ndiff --git a/extension/parquet/column_reader.cpp b/extension/parquet/column_reader.cpp\nindex c2f73df55652..8cf275b9eaf1 100644\n--- a/extension/parquet/column_reader.cpp\n+++ b/extension/parquet/column_reader.cpp\n@@ -687,7 +687,7 @@ ListColumnReader::ListColumnReader(ParquetReader &reader, LogicalType type_p, co\n                                    idx_t schema_idx_p, idx_t max_define_p, idx_t max_repeat_p,\n                                    unique_ptr<ColumnReader> child_column_reader_p)\n     : ColumnReader(reader, move(type_p), schema_p, schema_idx_p, max_define_p, max_repeat_p),\n-      child_column_reader(move(child_column_reader_p)), read_cache(ListType::GetChildType(Type())),\n+      child_column_reader(move(child_column_reader_p)), read_cache(reader.allocator, ListType::GetChildType(Type())),\n       read_vector(read_cache), overflow_child_count(0) {\n \n \tchild_defines.resize(reader.allocator, STANDARD_VECTOR_SIZE);\n@@ -717,7 +717,7 @@ CastColumnReader::CastColumnReader(unique_ptr<ColumnReader> child_reader_p, Logi\n                    child_reader_p->MaxDefine(), child_reader_p->MaxRepeat()),\n       child_reader(move(child_reader_p)) {\n \tvector<LogicalType> intermediate_types {child_reader->Type()};\n-\tintermediate_chunk.Initialize(intermediate_types);\n+\tintermediate_chunk.Initialize(reader.allocator, intermediate_types);\n }\n \n unique_ptr<BaseStatistics> CastColumnReader::Stats(const std::vector<ColumnChunk> &columns) {\ndiff --git a/extension/parquet/parquet-extension.cpp b/extension/parquet/parquet-extension.cpp\nindex 71e2f9491c22..33f93c0a3592 100644\n--- a/extension/parquet/parquet-extension.cpp\n+++ b/extension/parquet/parquet-extension.cpp\n@@ -249,7 +249,7 @@ class ParquetScanFunction {\n \t}\n \n \tstatic unique_ptr<LocalTableFunctionState>\n-\tParquetScanInitLocal(ClientContext &context, TableFunctionInitInput &input, GlobalTableFunctionState *gstate_p) {\n+\tParquetScanInitLocal(ExecutionContext &context, TableFunctionInitInput &input, GlobalTableFunctionState *gstate_p) {\n \t\tauto &bind_data = (ParquetReadBindData &)*input.bind_data;\n \t\tauto &gstate = (ParquetReadGlobalState &)*gstate_p;\n \n@@ -258,7 +258,7 @@ class ParquetScanFunction {\n \t\tresult->is_parallel = true;\n \t\tresult->batch_index = 0;\n \t\tresult->table_filters = input.filters;\n-\t\tif (!ParquetParallelStateNext(context, bind_data, *result, gstate)) {\n+\t\tif (!ParquetParallelStateNext(context.client, bind_data, *result, gstate)) {\n \t\t\treturn nullptr;\n \t\t}\n \t\treturn move(result);\n@@ -367,8 +367,8 @@ struct ParquetWriteGlobalState : public GlobalFunctionData {\n };\n \n struct ParquetWriteLocalState : public LocalFunctionData {\n-\tParquetWriteLocalState() {\n-\t\tbuffer = make_unique<ChunkCollection>();\n+\texplicit ParquetWriteLocalState(Allocator &allocator) {\n+\t\tbuffer = make_unique<ChunkCollection>(allocator);\n \t}\n \n \tunique_ptr<ChunkCollection> buffer;\n@@ -421,7 +421,7 @@ unique_ptr<GlobalFunctionData> ParquetWriteInitializeGlobal(ClientContext &conte\n \treturn move(global_state);\n }\n \n-void ParquetWriteSink(ClientContext &context, FunctionData &bind_data_p, GlobalFunctionData &gstate,\n+void ParquetWriteSink(ExecutionContext &context, FunctionData &bind_data_p, GlobalFunctionData &gstate,\n                       LocalFunctionData &lstate, DataChunk &input) {\n \tauto &bind_data = (ParquetWriteBindData &)bind_data_p;\n \tauto &global_state = (ParquetWriteGlobalState &)gstate;\n@@ -433,11 +433,11 @@ void ParquetWriteSink(ClientContext &context, FunctionData &bind_data_p, GlobalF\n \t\t// if the chunk collection exceeds a certain size we flush it to the parquet file\n \t\tglobal_state.writer->Flush(*local_state.buffer);\n \t\t// and reset the buffer\n-\t\tlocal_state.buffer = make_unique<ChunkCollection>();\n+\t\tlocal_state.buffer = make_unique<ChunkCollection>(Allocator::Get(context.client));\n \t}\n }\n \n-void ParquetWriteCombine(ClientContext &context, FunctionData &bind_data, GlobalFunctionData &gstate,\n+void ParquetWriteCombine(ExecutionContext &context, FunctionData &bind_data, GlobalFunctionData &gstate,\n                          LocalFunctionData &lstate) {\n \tauto &global_state = (ParquetWriteGlobalState &)gstate;\n \tauto &local_state = (ParquetWriteLocalState &)lstate;\n@@ -451,8 +451,8 @@ void ParquetWriteFinalize(ClientContext &context, FunctionData &bind_data, Globa\n \tglobal_state.writer->Finalize();\n }\n \n-unique_ptr<LocalFunctionData> ParquetWriteInitializeLocal(ClientContext &context, FunctionData &bind_data) {\n-\treturn make_unique<ParquetWriteLocalState>();\n+unique_ptr<LocalFunctionData> ParquetWriteInitializeLocal(ExecutionContext &context, FunctionData &bind_data) {\n+\treturn make_unique<ParquetWriteLocalState>(Allocator::Get(context.client));\n }\n \n unique_ptr<TableFunctionRef> ParquetScanReplacement(ClientContext &context, const string &table_name,\ndiff --git a/extension/parquet/parquet_metadata.cpp b/extension/parquet/parquet_metadata.cpp\nindex 63da12d659f4..918a9bcc9b1d 100644\n--- a/extension/parquet/parquet_metadata.cpp\n+++ b/extension/parquet/parquet_metadata.cpp\n@@ -22,6 +22,9 @@ struct ParquetMetaDataBindData : public TableFunctionData {\n };\n \n struct ParquetMetaDataOperatorData : public GlobalTableFunctionState {\n+\texplicit ParquetMetaDataOperatorData(Allocator &allocator) : collection(allocator) {\n+\t}\n+\n \tidx_t file_index;\n \tChunkCollection collection;\n \n@@ -132,7 +135,7 @@ void ParquetMetaDataOperatorData::LoadFileMetaData(ClientContext &context, const\n \tauto reader = make_unique<ParquetReader>(context, file_path, parquet_options);\n \tidx_t count = 0;\n \tDataChunk current_chunk;\n-\tcurrent_chunk.Initialize(return_types);\n+\tcurrent_chunk.Initialize(context, return_types);\n \tauto meta_data = reader->GetFileMetadata();\n \tvector<LogicalType> column_types;\n \tvector<idx_t> schema_indexes;\n@@ -338,7 +341,7 @@ void ParquetMetaDataOperatorData::LoadSchemaData(ClientContext &context, const v\n \tauto reader = make_unique<ParquetReader>(context, file_path, parquet_options);\n \tidx_t count = 0;\n \tDataChunk current_chunk;\n-\tcurrent_chunk.Initialize(return_types);\n+\tcurrent_chunk.Initialize(context, return_types);\n \tauto meta_data = reader->GetFileMetadata();\n \tfor (idx_t col_idx = 0; col_idx < meta_data->schema.size(); col_idx++) {\n \t\tauto &column = meta_data->schema[col_idx];\n@@ -419,7 +422,7 @@ unique_ptr<GlobalTableFunctionState> ParquetMetaDataInit(ClientContext &context,\n \tauto &bind_data = (ParquetMetaDataBindData &)*input.bind_data;\n \tD_ASSERT(!bind_data.files.empty());\n \n-\tauto result = make_unique<ParquetMetaDataOperatorData>();\n+\tauto result = make_unique<ParquetMetaDataOperatorData>(Allocator::Get(context));\n \tif (SCHEMA) {\n \t\tresult->LoadSchemaData(context, bind_data.return_types, bind_data.files[0]);\n \t} else {\ndiff --git a/extension/parquet/parquet_reader.cpp b/extension/parquet/parquet_reader.cpp\nindex 00dacdbcaa25..4869080ddd92 100644\n--- a/extension/parquet/parquet_reader.cpp\n+++ b/extension/parquet/parquet_reader.cpp\n@@ -451,7 +451,7 @@ ParquetReader::ParquetReader(Allocator &allocator_p, unique_ptr<FileHandle> file\n ParquetReader::ParquetReader(ClientContext &context_p, string file_name_p, const vector<string> &expected_names,\n                              const vector<LogicalType> &expected_types_p, const vector<column_t> &column_ids,\n                              ParquetOptions parquet_options_p, const string &initial_filename_p)\n-    : allocator(Allocator::Get(context_p)), file_opener(FileSystem::GetFileOpener(context_p)),\n+    : allocator(BufferAllocator::Get(context_p)), file_opener(FileSystem::GetFileOpener(context_p)),\n       parquet_options(parquet_options_p) {\n \tauto &fs = FileSystem::GetFileSystem(context_p);\n \tfile_name = move(file_name_p);\ndiff --git a/extension/parquet/parquetcli.cpp b/extension/parquet/parquetcli.cpp\nindex f928cd7bc76c..cae5bc24dd10 100644\n--- a/extension/parquet/parquetcli.cpp\n+++ b/extension/parquet/parquetcli.cpp\n@@ -87,7 +87,7 @@ int main(int argc, const char **argv) {\n \treader.InitializeScan(state, column_ids, groups, &filters);\n \tDataChunk output;\n \n-\toutput.Initialize(return_types);\n+\toutput.Initialize(allocator, return_types);\n \tdo {\n \t\toutput.Reset();\n \t\treader.Scan(state, output);\ndiff --git a/scripts/build_out_of_tree_extensions.py b/scripts/build_out_of_tree_extensions.py\nindex 12ca546ca30a..8767fc63226b 100644\n--- a/scripts/build_out_of_tree_extensions.py\n+++ b/scripts/build_out_of_tree_extensions.py\n@@ -49,10 +49,12 @@ def exec(cmd):\n for task in tasks:\n     print(task)\n     clonedir = task['name'] + \"_clone\"\n-    exec('git clone %s %s' % (task['url'], clonedir))\n+    if not os.path.isdir(clonedir):\n+        exec('git clone %s %s' % (task['url'], clonedir))\n     os.chdir(clonedir)\n     exec('git checkout %s' % (task['commit']))\n     os.chdir(basedir)\n     os.environ['BUILD_OUT_OF_TREE_EXTENSION'] = clonedir\n+    print(f\"Building extension \\\"{task['name']}\\\" from URL \\\"{task['url']}\\\" at commit \\\"{task['commit']}\\\" at clonedir \\\"{clonedir}\\\"\")\n     exec('make')\n print(\"done\")\n\\ No newline at end of file\ndiff --git a/src/common/CMakeLists.txt b/src/common/CMakeLists.txt\nindex 16394efc201a..8a19adc81734 100644\n--- a/src/common/CMakeLists.txt\n+++ b/src/common/CMakeLists.txt\n@@ -8,6 +8,11 @@ add_subdirectory(types)\n add_subdirectory(value_operations)\n add_subdirectory(vector_operations)\n \n+if(${EXIT_TIME_DESTRUCTORS_WARNING})\n+  set(CMAKE_CXX_FLAGS_DEBUG\n+      \"${CMAKE_CXX_FLAGS_DEBUG} -Wno-exit-time-destructors\")\n+endif()\n+\n add_library_unity(\n   duckdb_common\n   OBJECT\ndiff --git a/src/common/allocator.cpp b/src/common/allocator.cpp\nindex 75d5a18e7226..9ab2bbff3691 100644\n--- a/src/common/allocator.cpp\n+++ b/src/common/allocator.cpp\n@@ -1,4 +1,13 @@\n #include \"duckdb/common/allocator.hpp\"\n+#include \"duckdb/common/assert.hpp\"\n+#include \"duckdb/common/exception.hpp\"\n+#include \"duckdb/common/atomic.hpp\"\n+#ifdef DUCKDB_DEBUG_ALLOCATION\n+#include \"duckdb/common/mutex.hpp\"\n+#include \"duckdb/common/pair.hpp\"\n+#include \"duckdb/common/unordered_map.hpp\"\n+#include <execinfo.h>\n+#endif\n \n namespace duckdb {\n \n@@ -17,33 +26,168 @@ void AllocatedData::Reset() {\n \tpointer = nullptr;\n }\n \n+//===--------------------------------------------------------------------===//\n+// Debug Info\n+//===--------------------------------------------------------------------===//\n+struct AllocatorDebugInfo {\n+#ifdef DEBUG\n+\tAllocatorDebugInfo();\n+\t~AllocatorDebugInfo();\n+\n+\tstatic string GetStackTrace(int max_depth = 128);\n+\n+\tvoid AllocateData(data_ptr_t pointer, idx_t size);\n+\tvoid FreeData(data_ptr_t pointer, idx_t size);\n+\tvoid ReallocateData(data_ptr_t pointer, data_ptr_t new_pointer, idx_t old_size, idx_t new_size);\n+\n+private:\n+\t//! The number of bytes that are outstanding (i.e. that have been allocated - but not freed)\n+\t//! Used for debug purposes\n+\tatomic<idx_t> allocation_count;\n+#ifdef DUCKDB_DEBUG_ALLOCATION\n+\tmutex pointer_lock;\n+\t//! Set of active outstanding pointers together with stack traces\n+\tunordered_map<data_ptr_t, pair<idx_t, string>> pointers;\n+#endif\n+#endif\n+};\n+\n+PrivateAllocatorData::PrivateAllocatorData() {\n+}\n+\n+PrivateAllocatorData::~PrivateAllocatorData() {\n+}\n+\n+//===--------------------------------------------------------------------===//\n+// Allocator\n+//===--------------------------------------------------------------------===//\n Allocator::Allocator()\n-    : allocate_function(Allocator::DefaultAllocate), free_function(Allocator::DefaultFree),\n-      reallocate_function(Allocator::DefaultReallocate) {\n+    : Allocator(Allocator::DefaultAllocate, Allocator::DefaultFree, Allocator::DefaultReallocate, nullptr) {\n }\n \n Allocator::Allocator(allocate_function_ptr_t allocate_function_p, free_function_ptr_t free_function_p,\n-                     reallocate_function_ptr_t reallocate_function_p, unique_ptr<PrivateAllocatorData> private_data)\n+                     reallocate_function_ptr_t reallocate_function_p, unique_ptr<PrivateAllocatorData> private_data_p)\n     : allocate_function(allocate_function_p), free_function(free_function_p),\n-      reallocate_function(reallocate_function_p), private_data(move(private_data)) {\n+      reallocate_function(reallocate_function_p), private_data(move(private_data_p)) {\n+\tD_ASSERT(allocate_function);\n+\tD_ASSERT(free_function);\n+\tD_ASSERT(reallocate_function);\n+#ifdef DEBUG\n+\tif (!private_data) {\n+\t\tprivate_data = make_unique<PrivateAllocatorData>();\n+\t}\n+\tprivate_data->debug_info = make_unique<AllocatorDebugInfo>();\n+#endif\n+}\n+\n+Allocator::~Allocator() {\n }\n \n data_ptr_t Allocator::AllocateData(idx_t size) {\n-\treturn allocate_function(private_data.get(), size);\n+\tauto result = allocate_function(private_data.get(), size);\n+#ifdef DEBUG\n+\tD_ASSERT(private_data);\n+\tprivate_data->debug_info->AllocateData(result, size);\n+#endif\n+\treturn result;\n }\n \n void Allocator::FreeData(data_ptr_t pointer, idx_t size) {\n \tif (!pointer) {\n \t\treturn;\n \t}\n-\treturn free_function(private_data.get(), pointer, size);\n+#ifdef DEBUG\n+\tD_ASSERT(private_data);\n+\tprivate_data->debug_info->FreeData(pointer, size);\n+#endif\n+\tfree_function(private_data.get(), pointer, size);\n }\n \n-data_ptr_t Allocator::ReallocateData(data_ptr_t pointer, idx_t size) {\n+data_ptr_t Allocator::ReallocateData(data_ptr_t pointer, idx_t old_size, idx_t size) {\n \tif (!pointer) {\n-\t\treturn pointer;\n+\t\treturn nullptr;\n \t}\n-\treturn reallocate_function(private_data.get(), pointer, size);\n+\tauto new_pointer = reallocate_function(private_data.get(), pointer, old_size, size);\n+#ifdef DEBUG\n+\tD_ASSERT(private_data);\n+\tprivate_data->debug_info->ReallocateData(pointer, new_pointer, old_size, size);\n+#endif\n+\treturn new_pointer;\n }\n \n+Allocator &Allocator::DefaultAllocator() {\n+\tstatic Allocator DEFAULT_ALLOCATOR;\n+\treturn DEFAULT_ALLOCATOR;\n+}\n+\n+//===--------------------------------------------------------------------===//\n+// Debug Info (extended)\n+//===--------------------------------------------------------------------===//\n+#ifdef DEBUG\n+AllocatorDebugInfo::AllocatorDebugInfo() {\n+\tallocation_count = 0;\n+}\n+AllocatorDebugInfo::~AllocatorDebugInfo() {\n+#ifdef DUCKDB_DEBUG_ALLOCATION\n+\tif (allocation_count != 0) {\n+\t\tprintf(\"Outstanding allocations found for Allocator\\n\");\n+\t\tfor (auto &entry : pointers) {\n+\t\t\tprintf(\"Allocation of size %lld at address %p\\n\", entry.second.first, (void *)entry.first);\n+\t\t\tprintf(\"Stack trace:\\n%s\\n\", entry.second.second.c_str());\n+\t\t\tprintf(\"\\n\");\n+\t\t}\n+\t}\n+#endif\n+\t//! Verify that there is no outstanding memory still associated with the batched allocator\n+\t//! Only works for access to the batched allocator through the batched allocator interface\n+\t//! If this assertion triggers, enable DUCKDB_DEBUG_ALLOCATION for more information about the allocations\n+\tD_ASSERT(allocation_count == 0);\n+}\n+\n+string AllocatorDebugInfo::GetStackTrace(int max_depth) {\n+#ifdef DUCKDB_DEBUG_ALLOCATION\n+\tstring result;\n+\tauto callstack = unique_ptr<void *[]>(new void *[max_depth]);\n+\tint frames = backtrace(callstack.get(), max_depth);\n+\tchar **strs = backtrace_symbols(callstack.get(), frames);\n+\tfor (int i = 0; i < frames; i++) {\n+\t\tresult += strs[i];\n+\t\tresult += \"\\n\";\n+\t}\n+\tfree(strs);\n+\treturn result;\n+#else\n+\tthrow InternalException(\"GetStackTrace not supported without DUCKDB_DEBUG_ALLOCATION\");\n+#endif\n+}\n+\n+void AllocatorDebugInfo::AllocateData(data_ptr_t pointer, idx_t size) {\n+\tallocation_count += size;\n+#ifdef DUCKDB_DEBUG_ALLOCATION\n+\tlock_guard<mutex> l(pointer_lock);\n+\tpointers[pointer] = make_pair(size, GetStackTrace());\n+#endif\n+}\n+\n+void AllocatorDebugInfo::FreeData(data_ptr_t pointer, idx_t size) {\n+\tD_ASSERT(allocation_count >= size);\n+\tallocation_count -= size;\n+#ifdef DUCKDB_DEBUG_ALLOCATION\n+\tlock_guard<mutex> l(pointer_lock);\n+\t// verify that the pointer exists\n+\tD_ASSERT(pointers.find(pointer) != pointers.end());\n+\t// verify that the stored size matches the passed in size\n+\tD_ASSERT(pointers[pointer].first == size);\n+\t// erase the pointer\n+\tpointers.erase(pointer);\n+#endif\n+}\n+\n+void AllocatorDebugInfo::ReallocateData(data_ptr_t pointer, data_ptr_t new_pointer, idx_t old_size, idx_t new_size) {\n+\tFreeData(pointer, old_size);\n+\tAllocateData(new_pointer, new_size);\n+}\n+\n+#endif\n+\n } // namespace duckdb\ndiff --git a/src/common/arrow_wrapper.cpp b/src/common/arrow_wrapper.cpp\nindex 032ef1ae930b..04e9c3b56a69 100644\n--- a/src/common/arrow_wrapper.cpp\n+++ b/src/common/arrow_wrapper.cpp\n@@ -130,7 +130,7 @@ int ResultArrowArrayStreamWrapper::MyStreamGetNext(struct ArrowArrayStream *stre\n \t\treturn 0;\n \t}\n \tunique_ptr<DataChunk> agg_chunk_result = make_unique<DataChunk>();\n-\tagg_chunk_result->Initialize(chunk_result->GetTypes());\n+\tagg_chunk_result->Initialize(Allocator::DefaultAllocator(), chunk_result->GetTypes());\n \tagg_chunk_result->Append(*chunk_result, true);\n \n \twhile (agg_chunk_result->size() < my_stream->batch_size) {\ndiff --git a/src/common/file_buffer.cpp b/src/common/file_buffer.cpp\nindex 8060af101694..06a928e87be0 100644\n--- a/src/common/file_buffer.cpp\n+++ b/src/common/file_buffer.cpp\n@@ -35,6 +35,9 @@ FileBuffer::FileBuffer(FileBuffer &source, FileBufferType type_p) : allocator(so\n }\n \n FileBuffer::~FileBuffer() {\n+\tif (!malloced_buffer) {\n+\t\treturn;\n+\t}\n \tallocator.FreeData(malloced_buffer, malloced_size);\n }\n \n@@ -43,51 +46,24 @@ void FileBuffer::SetMallocedSize(uint64_t &bufsiz) {\n \tif (type == FileBufferType::MANAGED_BUFFER && bufsiz != Storage::FILE_HEADER_SIZE) {\n \t\tbufsiz += Storage::BLOCK_HEADER_SIZE;\n \t}\n-\tif (type == FileBufferType::BLOCK) {\n-\t\tconst int sector_size = Storage::SECTOR_SIZE;\n-\t\t// round up to the nearest sector_size\n-\t\tif (bufsiz % sector_size != 0) {\n-\t\t\tbufsiz += sector_size - (bufsiz % sector_size);\n-\t\t}\n-\t\tD_ASSERT(bufsiz % sector_size == 0);\n-\t\tD_ASSERT(bufsiz >= sector_size);\n-\t\t// we add (sector_size - 1) to ensure that we can align the buffer to sector_size\n-\t\tmalloced_size = bufsiz + (sector_size - 1);\n-\t} else {\n-\t\tmalloced_size = bufsiz;\n-\t}\n+\tmalloced_size = bufsiz;\n }\n \n void FileBuffer::Construct(uint64_t bufsiz) {\n \tif (!malloced_buffer) {\n \t\tthrow std::bad_alloc();\n \t}\n-\tif (type == FileBufferType::BLOCK) {\n-\t\tconst int sector_size = Storage::SECTOR_SIZE;\n-\t\t// round to multiple of sector_size\n-\t\tuint64_t num = (uint64_t)malloced_buffer;\n-\t\tuint64_t remainder = num % sector_size;\n-\t\tif (remainder != 0) {\n-\t\t\tnum = num + sector_size - remainder;\n-\t\t}\n-\t\tD_ASSERT(num % sector_size == 0);\n-\t\tD_ASSERT(num + bufsiz <= ((uint64_t)malloced_buffer + bufsiz + (sector_size - 1)));\n-\t\tD_ASSERT(num >= (uint64_t)malloced_buffer);\n-\t\t// construct the FileBuffer object\n-\t\tinternal_buffer = (data_ptr_t)num;\n-\t\tinternal_size = bufsiz;\n-\t} else {\n-\t\tinternal_buffer = malloced_buffer;\n-\t\tinternal_size = malloced_size;\n-\t}\n+\tinternal_buffer = malloced_buffer;\n+\tinternal_size = malloced_size;\n \tbuffer = internal_buffer + Storage::BLOCK_HEADER_SIZE;\n \tsize = internal_size - Storage::BLOCK_HEADER_SIZE;\n }\n \n void FileBuffer::Resize(uint64_t bufsiz) {\n \tD_ASSERT(type == FileBufferType::MANAGED_BUFFER);\n+\tauto old_size = malloced_size;\n \tSetMallocedSize(bufsiz);\n-\tmalloced_buffer = allocator.ReallocateData(malloced_buffer, malloced_size);\n+\tmalloced_buffer = allocator.ReallocateData(malloced_buffer, old_size, malloced_size);\n \tConstruct(bufsiz);\n }\n \ndiff --git a/src/common/file_system.cpp b/src/common/file_system.cpp\nindex 5a241f303e91..3e99ecd1f532 100644\n--- a/src/common/file_system.cpp\n+++ b/src/common/file_system.cpp\n@@ -88,7 +88,7 @@ void FileSystem::SetWorkingDirectory(const string &path) {\n idx_t FileSystem::GetAvailableMemory() {\n \tULONGLONG available_memory_kb;\n \tif (GetPhysicallyInstalledSystemMemory(&available_memory_kb)) {\n-\t\treturn MinValue<idx_t>(available_memory_kb * 1024, UINTPTR_MAX);\n+\t\treturn MinValue<idx_t>(available_memory_kb * 1000, UINTPTR_MAX);\n \t}\n \t// fallback: try GlobalMemoryStatusEx\n \tMEMORYSTATUSEX mem_state;\ndiff --git a/src/common/local_file_system.cpp b/src/common/local_file_system.cpp\nindex 878f4acad069..e62bbf18d81e 100644\n--- a/src/common/local_file_system.cpp\n+++ b/src/common/local_file_system.cpp\n@@ -496,7 +496,11 @@ struct WindowsFileHandle : public FileHandle {\n \n public:\n \tvoid Close() override {\n+\t\tif (!fd) {\n+\t\t\treturn;\n+\t\t}\n \t\tCloseHandle(fd);\n+\t\tfd = nullptr;\n \t};\n };\n \n@@ -701,7 +705,8 @@ static void DeleteDirectoryRecursive(FileSystem &fs, string directory) {\n \t});\n \tauto unicode_path = WindowsUtil::UTF8ToUnicode(directory.c_str());\n \tif (!RemoveDirectoryW(unicode_path.c_str())) {\n-\t\tthrow IOException(\"Failed to delete directory\");\n+\t\tauto error = LocalFileSystem::GetLastErrorAsString();\n+\t\tthrow IOException(\"Failed to delete directory \\\"%s\\\": %s\", directory, error);\n \t}\n }\n \n@@ -717,7 +722,10 @@ void LocalFileSystem::RemoveDirectory(const string &directory) {\n \n void LocalFileSystem::RemoveFile(const string &filename) {\n \tauto unicode_path = WindowsUtil::UTF8ToUnicode(filename.c_str());\n-\tDeleteFileW(unicode_path.c_str());\n+\tif (!DeleteFileW(unicode_path.c_str())) {\n+\t\tauto error = LocalFileSystem::GetLastErrorAsString();\n+\t\tthrow IOException(\"Failed to delete file \\\"%s\\\": %s\", filename, error);\n+\t}\n }\n \n bool LocalFileSystem::ListFiles(const string &directory, const std::function<void(const string &, bool)> &callback) {\ndiff --git a/src/common/row_operations/row_aggregate.cpp b/src/common/row_operations/row_aggregate.cpp\nindex 3bb32d2b792c..76aeb93557d5 100644\n--- a/src/common/row_operations/row_aggregate.cpp\n+++ b/src/common/row_operations/row_aggregate.cpp\n@@ -10,6 +10,7 @@\n #include \"duckdb/common/types/row_layout.hpp\"\n #include \"duckdb/catalog/catalog_entry/aggregate_function_catalog_entry.hpp\"\n #include \"duckdb/execution/expression_executor.hpp\"\n+#include \"duckdb/execution/operator/aggregate/aggregate_object.hpp\"\n \n namespace duckdb {\n \n@@ -53,20 +54,14 @@ void RowOperations::UpdateStates(AggregateObject &aggr, Vector &addresses, DataC\n \t                     addresses, count);\n }\n \n-void RowOperations::UpdateFilteredStates(AggregateObject &aggr, Vector &addresses, DataChunk &payload, idx_t arg_idx) {\n-\tExpressionExecutor filter_execution(aggr.filter);\n-\tSelectionVector true_sel(STANDARD_VECTOR_SIZE);\n-\tauto count = filter_execution.SelectExpression(payload, true_sel);\n+void RowOperations::UpdateFilteredStates(AggregateFilterData &filter_data, AggregateObject &aggr, Vector &addresses,\n+                                         DataChunk &payload, idx_t arg_idx) {\n+\tidx_t count = filter_data.ApplyFilter(payload);\n \n-\tDataChunk filtered_payload;\n-\tauto pay_types = payload.GetTypes();\n-\tfiltered_payload.Initialize(pay_types);\n-\tfiltered_payload.Slice(payload, true_sel, count);\n-\n-\tVector filtered_addresses(addresses, true_sel, count);\n+\tVector filtered_addresses(addresses, filter_data.true_sel, count);\n \tfiltered_addresses.Normalify(count);\n \n-\tUpdateStates(aggr, filtered_addresses, filtered_payload, arg_idx, filtered_payload.size());\n+\tUpdateStates(aggr, filtered_addresses, filter_data.filtered_payload, arg_idx, count);\n }\n \n void RowOperations::CombineStates(RowLayout &layout, Vector &sources, Vector &targets, idx_t count) {\ndiff --git a/src/common/row_operations/row_scatter.cpp b/src/common/row_operations/row_scatter.cpp\nindex 745b2fc32cb9..3bebd3736559 100644\n--- a/src/common/row_operations/row_scatter.cpp\n+++ b/src/common/row_operations/row_scatter.cpp\n@@ -125,7 +125,7 @@ void RowOperations::Scatter(DataChunk &columns, VectorData col_data[], const Row\n \tauto &types = layout.GetTypes();\n \n \t// Compute the entry size of the variable size columns\n-\tvector<unique_ptr<BufferHandle>> handles;\n+\tvector<BufferHandle> handles;\n \tdata_ptr_t data_locations[STANDARD_VECTOR_SIZE];\n \tif (!layout.AllConstant()) {\n \t\tidx_t entry_sizes[STANDARD_VECTOR_SIZE];\ndiff --git a/src/common/sort/merge_sorter.cpp b/src/common/sort/merge_sorter.cpp\nindex 00067e3055fa..5dcdff09651d 100644\n--- a/src/common/sort/merge_sorter.cpp\n+++ b/src/common/sort/merge_sorter.cpp\n@@ -147,8 +147,8 @@ int MergeSorter::CompareUsingGlobalIndex(SBScanState &l, SBScanState &r, const i\n \n \tl.PinRadix(l.block_idx);\n \tr.PinRadix(r.block_idx);\n-\tdata_ptr_t l_ptr = l.radix_handle->Ptr() + l.entry_idx * sort_layout.entry_size;\n-\tdata_ptr_t r_ptr = r.radix_handle->Ptr() + r.entry_idx * sort_layout.entry_size;\n+\tdata_ptr_t l_ptr = l.radix_handle.Ptr() + l.entry_idx * sort_layout.entry_size;\n+\tdata_ptr_t r_ptr = r.radix_handle.Ptr() + r.entry_idx * sort_layout.entry_size;\n \n \tint comp_res;\n \tif (sort_layout.all_constant) {\n@@ -342,7 +342,7 @@ void MergeSorter::MergeRadix(const idx_t &count, const bool left_smaller[]) {\n \n \tRowDataBlock *result_block = &result->radix_sorting_data.back();\n \tauto result_handle = buffer_manager.Pin(result_block->block);\n-\tdata_ptr_t result_ptr = result_handle->Ptr() + result_block->count * sort_layout.entry_size;\n+\tdata_ptr_t result_ptr = result_handle.Ptr() + result_block->count * sort_layout.entry_size;\n \n \tidx_t copied = 0;\n \twhile (copied < count) {\n@@ -418,15 +418,15 @@ void MergeSorter::MergeData(SortedData &result_data, SortedData &l_data, SortedD\n \t// Result rows to write to\n \tRowDataBlock *result_data_block = &result_data.data_blocks.back();\n \tauto result_data_handle = buffer_manager.Pin(result_data_block->block);\n-\tdata_ptr_t result_data_ptr = result_data_handle->Ptr() + result_data_block->count * row_width;\n+\tdata_ptr_t result_data_ptr = result_data_handle.Ptr() + result_data_block->count * row_width;\n \t// Result heap to write to (if needed)\n \tRowDataBlock *result_heap_block;\n-\tunique_ptr<BufferHandle> result_heap_handle;\n+\tBufferHandle result_heap_handle;\n \tdata_ptr_t result_heap_ptr;\n \tif (!layout.AllConstant() && state.external) {\n \t\tresult_heap_block = &result_data.heap_blocks.back();\n \t\tresult_heap_handle = buffer_manager.Pin(result_heap_block->block);\n-\t\tresult_heap_ptr = result_heap_handle->Ptr() + result_heap_block->byte_offset;\n+\t\tresult_heap_ptr = result_heap_handle.Ptr() + result_heap_block->byte_offset;\n \t}\n \n \tidx_t copied = 0;\n@@ -530,7 +530,7 @@ void MergeSorter::MergeData(SortedData &result_data, SortedData &l_data, SortedD\n \t\t\t\t\tidx_t new_capacity = result_heap_block->byte_offset + copy_bytes;\n \t\t\t\t\tbuffer_manager.ReAllocate(result_heap_block->block, new_capacity);\n \t\t\t\t\tresult_heap_block->capacity = new_capacity;\n-\t\t\t\t\tresult_heap_ptr = result_heap_handle->Ptr() + result_heap_block->byte_offset;\n+\t\t\t\t\tresult_heap_ptr = result_heap_handle.Ptr() + result_heap_block->byte_offset;\n \t\t\t\t}\n \t\t\t\tD_ASSERT(result_heap_block->byte_offset + copy_bytes <= result_heap_block->capacity);\n \t\t\t\t// Now copy the heap data\n@@ -554,11 +554,11 @@ void MergeSorter::MergeData(SortedData &result_data, SortedData &l_data, SortedD\n \t\t\t} else if (r_done) {\n \t\t\t\t// Right side is exhausted - flush left\n \t\t\t\tFlushBlobs(layout, l_count, l_ptr, l.entry_idx, l_heap_ptr, result_data_block, result_data_ptr,\n-\t\t\t\t           result_heap_block, *result_heap_handle, result_heap_ptr, copied, count);\n+\t\t\t\t           result_heap_block, result_heap_handle, result_heap_ptr, copied, count);\n \t\t\t} else {\n \t\t\t\t// Left side is exhausted - flush right\n \t\t\t\tFlushBlobs(layout, r_count, r_ptr, r.entry_idx, r_heap_ptr, result_data_block, result_data_ptr,\n-\t\t\t\t           result_heap_block, *result_heap_handle, result_heap_ptr, copied, count);\n+\t\t\t\t           result_heap_block, result_heap_handle, result_heap_ptr, copied, count);\n \t\t\t}\n \t\t\tD_ASSERT(result_data_block->count == result_heap_block->count);\n \t\t}\ndiff --git a/src/common/sort/radix_sort.cpp b/src/common/sort/radix_sort.cpp\nindex d6a4daa67317..410d0c4740b2 100644\n--- a/src/common/sort/radix_sort.cpp\n+++ b/src/common/sort/radix_sort.cpp\n@@ -39,12 +39,12 @@ static void SortTiedBlobs(BufferManager &buffer_manager, const data_ptr_t datapt\n \t// Re-order\n \tauto temp_block =\n \t    buffer_manager.Allocate(MaxValue((end - start) * sort_layout.entry_size, (idx_t)Storage::BLOCK_SIZE));\n-\tdata_ptr_t temp_ptr = temp_block->Ptr();\n+\tdata_ptr_t temp_ptr = temp_block.Ptr();\n \tfor (idx_t i = 0; i < end - start; i++) {\n \t\tFastMemcpy(temp_ptr, entry_ptrs[i], sort_layout.entry_size);\n \t\ttemp_ptr += sort_layout.entry_size;\n \t}\n-\tmemcpy(dataptr + start * sort_layout.entry_size, temp_block->Ptr(), (end - start) * sort_layout.entry_size);\n+\tmemcpy(dataptr + start * sort_layout.entry_size, temp_block.Ptr(), (end - start) * sort_layout.entry_size);\n \t// Determine if there are still ties (if this is not the last column)\n \tif (tie_col < sort_layout.column_count - 1) {\n \t\tdata_ptr_t idx_ptr = dataptr + start * sort_layout.entry_size + sort_layout.comparison_size;\n@@ -66,7 +66,7 @@ static void SortTiedBlobs(BufferManager &buffer_manager, SortedBlock &sb, bool *\n \tD_ASSERT(!ties[count - 1]);\n \tauto &blob_block = sb.blob_sorting_data->data_blocks.back();\n \tauto blob_handle = buffer_manager.Pin(blob_block.block);\n-\tconst data_ptr_t blob_ptr = blob_handle->Ptr();\n+\tconst data_ptr_t blob_ptr = blob_handle.Ptr();\n \n \tfor (idx_t i = 0; i < count; i++) {\n \t\tif (!ties[i]) {\n@@ -117,8 +117,8 @@ void RadixSortLSD(BufferManager &buffer_manager, const data_ptr_t &dataptr, cons\n \t\t// Init counts to 0\n \t\tmemset(counts, 0, sizeof(counts));\n \t\t// Const some values for convenience\n-\t\tconst data_ptr_t source_ptr = swap ? temp_block->Ptr() : dataptr;\n-\t\tconst data_ptr_t target_ptr = swap ? dataptr : temp_block->Ptr();\n+\t\tconst data_ptr_t source_ptr = swap ? temp_block.Ptr() : dataptr;\n+\t\tconst data_ptr_t target_ptr = swap ? dataptr : temp_block.Ptr();\n \t\tconst idx_t offset = col_offset + sorting_size - r;\n \t\t// Collect counts\n \t\tdata_ptr_t offset_ptr = source_ptr + offset;\n@@ -146,7 +146,7 @@ void RadixSortLSD(BufferManager &buffer_manager, const data_ptr_t &dataptr, cons\n \t}\n \t// Move data back to original buffer (if it was swapped)\n \tif (swap) {\n-\t\tmemcpy(dataptr, temp_block->Ptr(), count * row_width);\n+\t\tmemcpy(dataptr, temp_block.Ptr(), count * row_width);\n \t}\n }\n \n@@ -245,7 +245,7 @@ void RadixSort(BufferManager &buffer_manager, const data_ptr_t &dataptr, const i\n \t} else {\n \t\tauto temp_block = buffer_manager.Allocate(MaxValue(count * sort_layout.entry_size, (idx_t)Storage::BLOCK_SIZE));\n \t\tauto preallocated_array = unique_ptr<idx_t[]>(new idx_t[sorting_size * SortConstants::MSD_RADIX_LOCATIONS]);\n-\t\tRadixSortMSD(dataptr, temp_block->Ptr(), count, col_offset, sort_layout.entry_size, sorting_size, 0,\n+\t\tRadixSortMSD(dataptr, temp_block.Ptr(), count, col_offset, sort_layout.entry_size, sorting_size, 0,\n \t\t             preallocated_array.get(), false);\n \t}\n }\n@@ -276,7 +276,7 @@ void LocalSortState::SortInMemory() {\n \tauto &block = sb.radix_sorting_data.back();\n \tconst auto &count = block.count;\n \tauto handle = buffer_manager->Pin(block.block);\n-\tconst auto dataptr = handle->Ptr();\n+\tconst auto dataptr = handle.Ptr();\n \t// Assign an index to each row\n \tdata_ptr_t idx_dataptr = dataptr + sort_layout->comparison_size;\n \tfor (uint32_t i = 0; i < count; i++) {\ndiff --git a/src/common/sort/sort_state.cpp b/src/common/sort/sort_state.cpp\nindex 696d46bb7c11..9eb785b68498 100644\n--- a/src/common/sort/sort_state.cpp\n+++ b/src/common/sort/sort_state.cpp\n@@ -233,11 +233,11 @@ RowDataBlock LocalSortState::ConcatenateBlocks(RowDataCollection &row_data) {\n \tRowDataBlock new_block(*buffer_manager, capacity, entry_size);\n \tnew_block.count = row_data.count;\n \tauto new_block_handle = buffer_manager->Pin(new_block.block);\n-\tdata_ptr_t new_block_ptr = new_block_handle->Ptr();\n+\tdata_ptr_t new_block_ptr = new_block_handle.Ptr();\n \t// Copy the data of the blocks into a single block\n \tfor (auto &block : row_data.blocks) {\n \t\tauto block_handle = buffer_manager->Pin(block.block);\n-\t\tmemcpy(new_block_ptr, block_handle->Ptr(), block.count * entry_size);\n+\t\tmemcpy(new_block_ptr, block_handle.Ptr(), block.count * entry_size);\n \t\tnew_block_ptr += block.count * entry_size;\n \t}\n \trow_data.blocks.clear();\n@@ -251,12 +251,12 @@ void LocalSortState::ReOrder(SortedData &sd, data_ptr_t sorting_ptr, RowDataColl\n \tauto &unordered_data_block = sd.data_blocks.back();\n \tconst idx_t &count = unordered_data_block.count;\n \tauto unordered_data_handle = buffer_manager->Pin(unordered_data_block.block);\n-\tconst data_ptr_t unordered_data_ptr = unordered_data_handle->Ptr();\n+\tconst data_ptr_t unordered_data_ptr = unordered_data_handle.Ptr();\n \t// Create new block that will hold re-ordered row data\n \tRowDataBlock ordered_data_block(*buffer_manager, unordered_data_block.capacity, unordered_data_block.entry_size);\n \tordered_data_block.count = count;\n \tauto ordered_data_handle = buffer_manager->Pin(ordered_data_block.block);\n-\tdata_ptr_t ordered_data_ptr = ordered_data_handle->Ptr();\n+\tdata_ptr_t ordered_data_ptr = ordered_data_handle.Ptr();\n \t// Re-order fixed-size row layout\n \tconst idx_t row_width = sd.layout.GetRowWidth();\n \tconst idx_t sorting_entry_size = gstate.sort_layout.entry_size;\n@@ -272,7 +272,7 @@ void LocalSortState::ReOrder(SortedData &sd, data_ptr_t sorting_ptr, RowDataColl\n \t// Deal with the heap (if necessary)\n \tif (!sd.layout.AllConstant() && reorder_heap) {\n \t\t// Swizzle the column pointers to offsets\n-\t\tRowOperations::SwizzleColumns(sd.layout, ordered_data_handle->Ptr(), count);\n+\t\tRowOperations::SwizzleColumns(sd.layout, ordered_data_handle.Ptr(), count);\n \t\t// Create a single heap block to store the ordered heap\n \t\tidx_t total_byte_offset = std::accumulate(heap.blocks.begin(), heap.blocks.end(), 0,\n \t\t                                          [](idx_t a, const RowDataBlock &b) { return a + b.byte_offset; });\n@@ -281,9 +281,9 @@ void LocalSortState::ReOrder(SortedData &sd, data_ptr_t sorting_ptr, RowDataColl\n \t\tordered_heap_block.count = count;\n \t\tordered_heap_block.byte_offset = total_byte_offset;\n \t\tauto ordered_heap_handle = buffer_manager->Pin(ordered_heap_block.block);\n-\t\tdata_ptr_t ordered_heap_ptr = ordered_heap_handle->Ptr();\n+\t\tdata_ptr_t ordered_heap_ptr = ordered_heap_handle.Ptr();\n \t\t// Fill the heap in order\n-\t\tordered_data_ptr = ordered_data_handle->Ptr();\n+\t\tordered_data_ptr = ordered_data_handle.Ptr();\n \t\tconst idx_t heap_pointer_offset = sd.layout.GetHeapPointerOffset();\n \t\tfor (idx_t i = 0; i < count; i++) {\n \t\t\tauto heap_row_ptr = Load<data_ptr_t>(ordered_data_ptr + heap_pointer_offset);\n@@ -293,7 +293,7 @@ void LocalSortState::ReOrder(SortedData &sd, data_ptr_t sorting_ptr, RowDataColl\n \t\t\tordered_data_ptr += row_width;\n \t\t}\n \t\t// Swizzle the base pointer to the offset of each row in the heap\n-\t\tRowOperations::SwizzleHeapPointer(sd.layout, ordered_data_handle->Ptr(), ordered_heap_handle->Ptr(), count);\n+\t\tRowOperations::SwizzleHeapPointer(sd.layout, ordered_data_handle.Ptr(), ordered_heap_handle.Ptr(), count);\n \t\t// Move the re-ordered heap to the SortedData, and clear the local heap\n \t\tsd.heap_blocks.push_back(move(ordered_heap_block));\n \t\theap.pinned_blocks.clear();\n@@ -305,7 +305,7 @@ void LocalSortState::ReOrder(SortedData &sd, data_ptr_t sorting_ptr, RowDataColl\n void LocalSortState::ReOrder(GlobalSortState &gstate, bool reorder_heap) {\n \tauto &sb = *sorted_blocks.back();\n \tauto sorting_handle = buffer_manager->Pin(sb.radix_sorting_data.back().block);\n-\tconst data_ptr_t sorting_ptr = sorting_handle->Ptr() + gstate.sort_layout.comparison_size;\n+\tconst data_ptr_t sorting_ptr = sorting_handle.Ptr() + gstate.sort_layout.comparison_size;\n \t// Re-order variable size sorting columns\n \tif (!gstate.sort_layout.all_constant) {\n \t\tReOrder(*sb.blob_sorting_data, sorting_ptr, *blob_sorting_heap, gstate, reorder_heap);\n@@ -424,7 +424,7 @@ void GlobalSortState::CompleteMergeRound(bool keep_radix_data) {\n void GlobalSortState::Print() {\n \tPayloadScanner scanner(*this, false);\n \tDataChunk chunk;\n-\tchunk.Initialize(scanner.GetPayloadTypes());\n+\tchunk.Initialize(Allocator::DefaultAllocator(), scanner.GetPayloadTypes());\n \tfor (;;) {\n \t\tscanner.Scan(chunk);\n \t\tconst auto count = chunk.size();\ndiff --git a/src/common/sort/sorted_block.cpp b/src/common/sort/sorted_block.cpp\nindex 0667494e7a4f..f5d5b64711bb 100644\n--- a/src/common/sort/sorted_block.cpp\n+++ b/src/common/sort/sorted_block.cpp\n@@ -67,7 +67,7 @@ void SortedData::Unswizzle() {\n \t\tauto &heap_block = heap_blocks[i];\n \t\tauto data_handle_p = buffer_manager.Pin(data_block.block);\n \t\tauto heap_handle_p = buffer_manager.Pin(heap_block.block);\n-\t\tRowOperations::UnswizzlePointers(layout, data_handle_p->Ptr(), heap_handle_p->Ptr(), data_block.count);\n+\t\tRowOperations::UnswizzlePointers(layout, data_handle_p.Ptr(), heap_handle_p.Ptr(), data_block.count);\n \t\tstate.heap_blocks.push_back(move(heap_block));\n \t\tstate.pinned_blocks.push_back(move(heap_handle_p));\n \t}\n@@ -218,7 +218,7 @@ void SBScanState::PinRadix(idx_t block_idx_to) {\n \tauto &radix_sorting_data = sb->radix_sorting_data;\n \tD_ASSERT(block_idx_to < radix_sorting_data.size());\n \tauto &block = radix_sorting_data[block_idx_to];\n-\tif (!radix_handle || radix_handle->handle->BlockId() != block.block->BlockId()) {\n+\tif (!radix_handle.IsValid() || radix_handle.GetBlockId() != block.block->BlockId()) {\n \t\tradix_handle = buffer_manager.Pin(block.block);\n \t}\n }\n@@ -229,26 +229,26 @@ void SBScanState::PinData(SortedData &sd) {\n \tauto &heap_handle = sd.type == SortedDataType::BLOB ? blob_sorting_heap_handle : payload_heap_handle;\n \n \tauto &data_block = sd.data_blocks[block_idx];\n-\tif (!data_handle || data_handle->handle->BlockId() != data_block.block->BlockId()) {\n+\tif (!data_handle.IsValid() || data_handle.GetBlockId() != data_block.block->BlockId()) {\n \t\tdata_handle = buffer_manager.Pin(data_block.block);\n \t}\n \tif (sd.layout.AllConstant() || !state.external) {\n \t\treturn;\n \t}\n \tauto &heap_block = sd.heap_blocks[block_idx];\n-\tif (!heap_handle || heap_handle->handle->BlockId() != heap_block.block->BlockId()) {\n+\tif (!heap_handle.IsValid() || heap_handle.GetBlockId() != heap_block.block->BlockId()) {\n \t\theap_handle = buffer_manager.Pin(heap_block.block);\n \t}\n }\n \n data_ptr_t SBScanState::RadixPtr() const {\n-\treturn radix_handle->Ptr() + entry_idx * sort_layout.entry_size;\n+\treturn radix_handle.Ptr() + entry_idx * sort_layout.entry_size;\n }\n \n data_ptr_t SBScanState::DataPtr(SortedData &sd) const {\n-\tauto &data_handle = sd.type == SortedDataType::BLOB ? *blob_sorting_data_handle : *payload_data_handle;\n+\tauto &data_handle = sd.type == SortedDataType::BLOB ? blob_sorting_data_handle : payload_data_handle;\n \tD_ASSERT(sd.data_blocks[block_idx].block->Readers() != 0 &&\n-\t         data_handle.handle->BlockId() == sd.data_blocks[block_idx].block->BlockId());\n+\t         data_handle.GetBlockId() == sd.data_blocks[block_idx].block->BlockId());\n \treturn data_handle.Ptr() + entry_idx * sd.layout.GetRowWidth();\n }\n \n@@ -257,10 +257,10 @@ data_ptr_t SBScanState::HeapPtr(SortedData &sd) const {\n }\n \n data_ptr_t SBScanState::BaseHeapPtr(SortedData &sd) const {\n-\tauto &heap_handle = sd.type == SortedDataType::BLOB ? *blob_sorting_heap_handle : *payload_heap_handle;\n+\tauto &heap_handle = sd.type == SortedDataType::BLOB ? blob_sorting_heap_handle : payload_heap_handle;\n \tD_ASSERT(!sd.layout.AllConstant() && state.external);\n \tD_ASSERT(sd.heap_blocks[block_idx].block->Readers() != 0 &&\n-\t         heap_handle.handle->BlockId() == sd.heap_blocks[block_idx].block->BlockId());\n+\t         heap_handle.GetBlockId() == sd.heap_blocks[block_idx].block->BlockId());\n \treturn heap_handle.Ptr();\n }\n \n@@ -318,7 +318,7 @@ void PayloadScanner::Scan(DataChunk &chunk) {\n \t\tread_state.PinData(sorted_data);\n \t\tauto &data_block = sorted_data.data_blocks[read_state.block_idx];\n \t\tidx_t next = MinValue(data_block.count - read_state.entry_idx, count - scanned);\n-\t\tconst data_ptr_t data_ptr = read_state.payload_data_handle->Ptr() + read_state.entry_idx * row_width;\n+\t\tconst data_ptr_t data_ptr = read_state.payload_data_handle.Ptr() + read_state.entry_idx * row_width;\n \t\t// Set up the next pointers\n \t\tdata_ptr_t row_ptr = data_ptr;\n \t\tfor (idx_t i = 0; i < next; i++) {\n@@ -327,7 +327,7 @@ void PayloadScanner::Scan(DataChunk &chunk) {\n \t\t}\n \t\t// Unswizzle the offsets back to pointers (if needed)\n \t\tif (!sorted_data.layout.AllConstant() && global_sort_state.external) {\n-\t\t\tRowOperations::UnswizzlePointers(sorted_data.layout, data_ptr, read_state.payload_heap_handle->Ptr(), next);\n+\t\t\tRowOperations::UnswizzlePointers(sorted_data.layout, data_ptr, read_state.payload_heap_handle.Ptr(), next);\n \t\t}\n \t\t// Update state indices\n \t\tread_state.entry_idx += next;\ndiff --git a/src/common/types/batched_chunk_collection.cpp b/src/common/types/batched_chunk_collection.cpp\nindex 681d9c0df85e..8cd2a1eac22a 100644\n--- a/src/common/types/batched_chunk_collection.cpp\n+++ b/src/common/types/batched_chunk_collection.cpp\n@@ -3,7 +3,7 @@\n \n namespace duckdb {\n \n-BatchedChunkCollection::BatchedChunkCollection() {\n+BatchedChunkCollection::BatchedChunkCollection(Allocator &allocator) : allocator(allocator) {\n }\n \n void BatchedChunkCollection::Append(DataChunk &input, idx_t batch_index) {\n@@ -11,7 +11,7 @@ void BatchedChunkCollection::Append(DataChunk &input, idx_t batch_index) {\n \tauto entry = data.find(batch_index);\n \tChunkCollection *collection;\n \tif (entry == data.end()) {\n-\t\tauto new_collection = make_unique<ChunkCollection>();\n+\t\tauto new_collection = make_unique<ChunkCollection>(allocator);\n \t\tcollection = new_collection.get();\n \t\tdata.insert(make_pair(batch_index, move(new_collection)));\n \t} else {\ndiff --git a/src/common/types/chunk_collection.cpp b/src/common/types/chunk_collection.cpp\nindex 4b43c1803925..082363e28762 100644\n--- a/src/common/types/chunk_collection.cpp\n+++ b/src/common/types/chunk_collection.cpp\n@@ -13,6 +13,12 @@\n \n namespace duckdb {\n \n+ChunkCollection::ChunkCollection(Allocator &allocator) : allocator(allocator), count(0) {\n+}\n+\n+ChunkCollection::ChunkCollection(ClientContext &context) : ChunkCollection(Allocator::Get(context)) {\n+}\n+\n void ChunkCollection::Verify() {\n #ifdef DEBUG\n \tfor (auto &chunk : chunks) {\n@@ -114,7 +120,7 @@ void ChunkCollection::Append(DataChunk &new_chunk) {\n \tif (remaining_data > 0) {\n \t\t// create a new chunk and fill it with the remainder\n \t\tauto chunk = make_unique<DataChunk>();\n-\t\tchunk->Initialize(types);\n+\t\tchunk->Initialize(allocator, types);\n \t\tnew_chunk.Copy(*chunk, offset);\n \t\tchunks.push_back(move(chunk));\n \t}\ndiff --git a/src/common/types/data_chunk.cpp b/src/common/types/data_chunk.cpp\nindex b4472a684893..bd2c2315b9ae 100644\n--- a/src/common/types/data_chunk.cpp\n+++ b/src/common/types/data_chunk.cpp\n@@ -18,6 +18,7 @@\n #include \"duckdb/common/vector_operations/vector_operations.hpp\"\n #include \"duckdb/common/types/arrow_aux_data.hpp\"\n #include \"duckdb/common/types/uuid.hpp\"\n+#include \"duckdb/execution/execution_context.hpp\"\n \n namespace duckdb {\n \n@@ -36,17 +37,21 @@ void DataChunk::InitializeEmpty(const vector<LogicalType> &types) {\n \t}\n }\n \n-void DataChunk::Initialize(const vector<LogicalType> &types) {\n+void DataChunk::Initialize(Allocator &allocator, const vector<LogicalType> &types) {\n \tD_ASSERT(data.empty());   // can only be initialized once\n \tD_ASSERT(!types.empty()); // empty chunk not allowed\n \tcapacity = STANDARD_VECTOR_SIZE;\n \tfor (idx_t i = 0; i < types.size(); i++) {\n-\t\tVectorCache cache(types[i]);\n+\t\tVectorCache cache(allocator, types[i]);\n \t\tdata.emplace_back(cache);\n \t\tvector_caches.push_back(move(cache));\n \t}\n }\n \n+void DataChunk::Initialize(ClientContext &context, const vector<LogicalType> &types) {\n+\tInitialize(Allocator::Get(context), types);\n+}\n+\n void DataChunk::Reset() {\n \tif (data.empty()) {\n \t\treturn;\n@@ -218,7 +223,7 @@ void DataChunk::Deserialize(Deserializer &source) {\n \tfor (idx_t i = 0; i < column_count; i++) {\n \t\ttypes.push_back(LogicalType::Deserialize(source));\n \t}\n-\tInitialize(types);\n+\tInitialize(Allocator::DefaultAllocator(), types);\n \t// now load the column data\n \tSetCardinality(rows);\n \tfor (idx_t i = 0; i < column_count; i++) {\ndiff --git a/src/common/types/row_data_collection.cpp b/src/common/types/row_data_collection.cpp\nindex 3cf112a156da..8506265cecd2 100644\n--- a/src/common/types/row_data_collection.cpp\n+++ b/src/common/types/row_data_collection.cpp\n@@ -42,9 +42,9 @@ idx_t RowDataCollection::AppendToBlock(RowDataBlock &block, BufferHandle &handle\n \treturn append_count;\n }\n \n-vector<unique_ptr<BufferHandle>> RowDataCollection::Build(idx_t added_count, data_ptr_t key_locations[],\n-                                                          idx_t entry_sizes[], const SelectionVector *sel) {\n-\tvector<unique_ptr<BufferHandle>> handles;\n+vector<BufferHandle> RowDataCollection::Build(idx_t added_count, data_ptr_t key_locations[], idx_t entry_sizes[],\n+                                              const SelectionVector *sel) {\n+\tvector<BufferHandle> handles;\n \tvector<BlockAppendEntry> append_entries;\n \n \t// first allocate space of where to serialize the keys and payload columns\n@@ -60,7 +60,7 @@ vector<unique_ptr<BufferHandle>> RowDataCollection::Build(idx_t added_count, dat\n \t\t\t\t// last block has space: pin the buffer of this block\n \t\t\t\tauto handle = buffer_manager.Pin(last_block.block);\n \t\t\t\t// now append to the block\n-\t\t\t\tidx_t append_count = AppendToBlock(last_block, *handle, append_entries, remaining, entry_sizes);\n+\t\t\t\tidx_t append_count = AppendToBlock(last_block, handle, append_entries, remaining, entry_sizes);\n \t\t\t\tremaining -= append_count;\n \t\t\t\thandles.push_back(move(handle));\n \t\t\t}\n@@ -73,7 +73,7 @@ vector<unique_ptr<BufferHandle>> RowDataCollection::Build(idx_t added_count, dat\n \t\t\t// offset the entry sizes array if we have added entries already\n \t\t\tidx_t *offset_entry_sizes = entry_sizes ? entry_sizes + added_count - remaining : nullptr;\n \n-\t\t\tidx_t append_count = AppendToBlock(new_block, *handle, append_entries, remaining, offset_entry_sizes);\n+\t\t\tidx_t append_count = AppendToBlock(new_block, handle, append_entries, remaining, offset_entry_sizes);\n \t\t\tD_ASSERT(new_block.count > 0);\n \t\t\tremaining -= append_count;\n \ndiff --git a/src/common/types/row_layout.cpp b/src/common/types/row_layout.cpp\nindex 4fac9885ab9e..d3b138eca33d 100644\n--- a/src/common/types/row_layout.cpp\n+++ b/src/common/types/row_layout.cpp\n@@ -12,19 +12,6 @@\n \n namespace duckdb {\n \n-vector<AggregateObject> AggregateObject::CreateAggregateObjects(const vector<BoundAggregateExpression *> &bindings) {\n-\tvector<AggregateObject> aggregates;\n-\tfor (auto &binding : bindings) {\n-\t\tauto payload_size = binding->function.state_size();\n-#ifndef DUCKDB_ALLOW_UNDEFINED\n-\t\tpayload_size = AlignValue(payload_size);\n-#endif\n-\t\taggregates.emplace_back(binding->function, binding->bind_info.get(), binding->children.size(), payload_size,\n-\t\t                        binding->distinct, binding->return_type.InternalType(), binding->filter.get());\n-\t}\n-\treturn aggregates;\n-}\n-\n RowLayout::RowLayout()\n     : flag_width(0), data_width(0), aggr_width(0), row_width(0), all_constant(true), heap_pointer_offset(0) {\n }\ndiff --git a/src/common/types/string_heap.cpp b/src/common/types/string_heap.cpp\nindex 2c4fde0f9bdc..93131ade9884 100644\n--- a/src/common/types/string_heap.cpp\n+++ b/src/common/types/string_heap.cpp\n@@ -9,9 +9,15 @@\n \n namespace duckdb {\n \n-#define MINIMUM_HEAP_SIZE 4096\n+StringHeap::StringHeap() : allocator(Allocator::DefaultAllocator()) {\n+}\n+\n+void StringHeap::Destroy() {\n+\tallocator.Destroy();\n+}\n \n-StringHeap::StringHeap() : tail(nullptr) {\n+void StringHeap::Move(StringHeap &other) {\n+\tother.allocator.Move(allocator);\n }\n \n string_t StringHeap::AddString(const char *data, idx_t len) {\n@@ -39,19 +45,13 @@ string_t StringHeap::AddBlob(const char *data, idx_t len) {\n \treturn insert_string;\n }\n \n+string_t StringHeap::AddBlob(const string_t &data) {\n+\treturn AddBlob(data.GetDataUnsafe(), data.GetSize());\n+}\n+\n string_t StringHeap::EmptyString(idx_t len) {\n \tD_ASSERT(len >= string_t::INLINE_LENGTH);\n-\tif (!chunk || chunk->current_position + len >= chunk->maximum_size) {\n-\t\t// have to make a new entry\n-\t\tauto new_chunk = make_unique<StringChunk>(MaxValue<idx_t>(len, MINIMUM_HEAP_SIZE));\n-\t\tnew_chunk->prev = move(chunk);\n-\t\tchunk = move(new_chunk);\n-\t\tif (!tail) {\n-\t\t\ttail = chunk.get();\n-\t\t}\n-\t}\n-\tauto insert_pos = chunk->data.get() + chunk->current_position;\n-\tchunk->current_position += len;\n+\tauto insert_pos = (const char *)allocator.Allocate(len);\n \treturn string_t(insert_pos, len);\n }\n \ndiff --git a/src/common/types/vector.cpp b/src/common/types/vector.cpp\nindex 789ab9e21bd7..a434338801db 100644\n--- a/src/common/types/vector.cpp\n+++ b/src/common/types/vector.cpp\n@@ -1301,7 +1301,7 @@ string_t StringVector::EmptyString(Vector &vector, idx_t len) {\n \treturn string_buffer.EmptyString(len);\n }\n \n-void StringVector::AddHandle(Vector &vector, unique_ptr<BufferHandle> handle) {\n+void StringVector::AddHandle(Vector &vector, BufferHandle handle) {\n \tD_ASSERT(vector.GetType().InternalType() == PhysicalType::VARCHAR);\n \tif (!vector.auxiliary) {\n \t\tvector.auxiliary = make_buffer<VectorStringBuffer>();\ndiff --git a/src/common/types/vector_buffer.cpp b/src/common/types/vector_buffer.cpp\nindex 2398ed6871c4..b48e65298732 100644\n--- a/src/common/types/vector_buffer.cpp\n+++ b/src/common/types/vector_buffer.cpp\n@@ -93,7 +93,7 @@ void VectorListBuffer::PushBack(const Value &insert) {\n VectorListBuffer::~VectorListBuffer() {\n }\n \n-ManagedVectorBuffer::ManagedVectorBuffer(unique_ptr<BufferHandle> handle)\n+ManagedVectorBuffer::ManagedVectorBuffer(BufferHandle handle)\n     : VectorBuffer(VectorBufferType::MANAGED_BUFFER), handle(move(handle)) {\n }\n \ndiff --git a/src/common/types/vector_cache.cpp b/src/common/types/vector_cache.cpp\nindex fe2ee8ba0c1b..2cd372a89d85 100644\n--- a/src/common/types/vector_cache.cpp\n+++ b/src/common/types/vector_cache.cpp\n@@ -1,20 +1,21 @@\n #include \"duckdb/common/types/vector_cache.hpp\"\n #include \"duckdb/common/types/vector.hpp\"\n+#include \"duckdb/common/allocator.hpp\"\n \n namespace duckdb {\n \n class VectorCacheBuffer : public VectorBuffer {\n public:\n-\texplicit VectorCacheBuffer(const LogicalType &type_p)\n+\texplicit VectorCacheBuffer(Allocator &allocator, const LogicalType &type_p)\n \t    : VectorBuffer(VectorBufferType::OPAQUE_BUFFER), type(type_p) {\n \t\tauto internal_type = type.InternalType();\n \t\tswitch (internal_type) {\n \t\tcase PhysicalType::LIST: {\n \t\t\t// memory for the list offsets\n-\t\t\towned_data = unique_ptr<data_t[]>(new data_t[STANDARD_VECTOR_SIZE * GetTypeIdSize(internal_type)]);\n+\t\t\towned_data = allocator.Allocate(STANDARD_VECTOR_SIZE * GetTypeIdSize(internal_type));\n \t\t\t// child data of the list\n \t\t\tauto &child_type = ListType::GetChildType(type);\n-\t\t\tchild_caches.push_back(make_buffer<VectorCacheBuffer>(child_type));\n+\t\t\tchild_caches.push_back(make_buffer<VectorCacheBuffer>(allocator, child_type));\n \t\t\tauto child_vector = make_unique<Vector>(child_type, false, false);\n \t\t\tauxiliary = make_unique<VectorListBuffer>(move(child_vector));\n \t\t\tbreak;\n@@ -22,14 +23,14 @@ class VectorCacheBuffer : public VectorBuffer {\n \t\tcase PhysicalType::STRUCT: {\n \t\t\tauto &child_types = StructType::GetChildTypes(type);\n \t\t\tfor (auto &child_type : child_types) {\n-\t\t\t\tchild_caches.push_back(make_buffer<VectorCacheBuffer>(child_type.second));\n+\t\t\t\tchild_caches.push_back(make_buffer<VectorCacheBuffer>(allocator, child_type.second));\n \t\t\t}\n \t\t\tauto struct_buffer = make_unique<VectorStructBuffer>(type);\n \t\t\tauxiliary = move(struct_buffer);\n \t\t\tbreak;\n \t\t}\n \t\tdefault:\n-\t\t\towned_data = unique_ptr<data_t[]>(new data_t[STANDARD_VECTOR_SIZE * GetTypeIdSize(internal_type)]);\n+\t\t\towned_data = allocator.Allocate(STANDARD_VECTOR_SIZE * GetTypeIdSize(internal_type));\n \t\t\tbreak;\n \t\t}\n \t}\n@@ -42,7 +43,7 @@ class VectorCacheBuffer : public VectorBuffer {\n \t\tresult.validity.Reset();\n \t\tswitch (internal_type) {\n \t\tcase PhysicalType::LIST: {\n-\t\t\tresult.data = owned_data.get();\n+\t\t\tresult.data = owned_data->get();\n \t\t\t// reinitialize the VectorListBuffer\n \t\t\tAssignSharedPointer(result.auxiliary, auxiliary);\n \t\t\t// propagate through child\n@@ -70,7 +71,7 @@ class VectorCacheBuffer : public VectorBuffer {\n \t\t}\n \t\tdefault:\n \t\t\t// regular type: no aux data and reset data to cached data\n-\t\t\tresult.data = owned_data.get();\n+\t\t\tresult.data = owned_data->get();\n \t\t\tresult.auxiliary.reset();\n \t\t\tbreak;\n \t\t}\n@@ -84,15 +85,15 @@ class VectorCacheBuffer : public VectorBuffer {\n \t//! The type of the vector cache\n \tLogicalType type;\n \t//! Owned data\n-\tunique_ptr<data_t[]> owned_data;\n+\tunique_ptr<AllocatedData> owned_data;\n \t//! Child caches (if any). Used for nested types.\n \tvector<buffer_ptr<VectorBuffer>> child_caches;\n \t//! Aux data for the vector (if any)\n \tbuffer_ptr<VectorBuffer> auxiliary;\n };\n \n-VectorCache::VectorCache(const LogicalType &type_p) {\n-\tbuffer = make_unique<VectorCacheBuffer>(type_p);\n+VectorCache::VectorCache(Allocator &allocator, const LogicalType &type_p) {\n+\tbuffer = make_unique<VectorCacheBuffer>(allocator, type_p);\n }\n \n void VectorCache::ResetFromCache(Vector &result) const {\ndiff --git a/src/execution/aggregate_hashtable.cpp b/src/execution/aggregate_hashtable.cpp\nindex 52603c1dfca0..f6f47f4915bb 100644\n--- a/src/execution/aggregate_hashtable.cpp\n+++ b/src/execution/aggregate_hashtable.cpp\n@@ -18,26 +18,29 @@ namespace duckdb {\n \n using ValidityBytes = RowLayout::ValidityBytes;\n \n-GroupedAggregateHashTable::GroupedAggregateHashTable(BufferManager &buffer_manager, vector<LogicalType> group_types,\n-                                                     vector<LogicalType> payload_types,\n+GroupedAggregateHashTable::GroupedAggregateHashTable(Allocator &allocator, BufferManager &buffer_manager,\n+                                                     vector<LogicalType> group_types, vector<LogicalType> payload_types,\n                                                      const vector<BoundAggregateExpression *> &bindings,\n                                                      HtEntryType entry_type)\n-    : GroupedAggregateHashTable(buffer_manager, move(group_types), move(payload_types),\n+    : GroupedAggregateHashTable(allocator, buffer_manager, move(group_types), move(payload_types),\n                                 AggregateObject::CreateAggregateObjects(bindings), entry_type) {\n }\n \n-GroupedAggregateHashTable::GroupedAggregateHashTable(BufferManager &buffer_manager, vector<LogicalType> group_types)\n-    : GroupedAggregateHashTable(buffer_manager, move(group_types), {}, vector<AggregateObject>()) {\n+GroupedAggregateHashTable::GroupedAggregateHashTable(Allocator &allocator, BufferManager &buffer_manager,\n+                                                     vector<LogicalType> group_types)\n+    : GroupedAggregateHashTable(allocator, buffer_manager, move(group_types), {}, vector<AggregateObject>()) {\n }\n \n-GroupedAggregateHashTable::GroupedAggregateHashTable(BufferManager &buffer_manager, vector<LogicalType> group_types_p,\n+GroupedAggregateHashTable::GroupedAggregateHashTable(Allocator &allocator, BufferManager &buffer_manager,\n+                                                     vector<LogicalType> group_types_p,\n                                                      vector<LogicalType> payload_types_p,\n                                                      vector<AggregateObject> aggregate_objects_p,\n                                                      HtEntryType entry_type)\n-    : BaseAggregateHashTable(buffer_manager, move(payload_types_p)), entry_type(entry_type), capacity(0), entries(0),\n-      payload_page_offset(0), is_finalized(false), ht_offsets(LogicalTypeId::BIGINT),\n-      hash_salts(LogicalTypeId::SMALLINT), group_compare_vector(STANDARD_VECTOR_SIZE),\n-      no_match_vector(STANDARD_VECTOR_SIZE), empty_vector(STANDARD_VECTOR_SIZE) {\n+    : BaseAggregateHashTable(allocator, aggregate_objects_p, buffer_manager, move(payload_types_p)),\n+      entry_type(entry_type), capacity(0), entries(0), payload_page_offset(0), is_finalized(false),\n+      ht_offsets(LogicalTypeId::BIGINT), hash_salts(LogicalTypeId::SMALLINT),\n+      group_compare_vector(STANDARD_VECTOR_SIZE), no_match_vector(STANDARD_VECTOR_SIZE),\n+      empty_vector(STANDARD_VECTOR_SIZE) {\n \n \t// Append hash column to the end and initialise the row layout\n \tgroup_types_p.emplace_back(LogicalType::HASH);\n@@ -51,7 +54,7 @@ GroupedAggregateHashTable::GroupedAggregateHashTable(BufferManager &buffer_manag\n \tD_ASSERT(tuple_size <= Storage::BLOCK_SIZE);\n \ttuples_per_block = Storage::BLOCK_SIZE / tuple_size;\n \thashes_hdl = buffer_manager.Allocate(Storage::BLOCK_SIZE);\n-\thashes_hdl_ptr = hashes_hdl->Ptr();\n+\thashes_hdl_ptr = hashes_hdl.Ptr();\n \n \tswitch (entry_type) {\n \tcase HtEntryType::HT_WIDTH_64: {\n@@ -82,7 +85,8 @@ GroupedAggregateHashTable::GroupedAggregateHashTable(BufferManager &buffer_manag\n \t\t\tfor (idx_t child_idx = 0; child_idx < aggr.child_count; child_idx++) {\n \t\t\t\tdistinct_group_types.push_back(payload_types[payload_idx + child_idx]);\n \t\t\t}\n-\t\t\tdistinct_hashes[i] = make_unique<GroupedAggregateHashTable>(buffer_manager, distinct_group_types);\n+\t\t\tdistinct_hashes[i] =\n+\t\t\t    make_unique<GroupedAggregateHashTable>(allocator, buffer_manager, distinct_group_types);\n \t\t}\n \t\tpayload_idx += aggr.child_count;\n \t}\n@@ -119,7 +123,7 @@ void GroupedAggregateHashTable::PayloadApply(FUNC fun) {\n void GroupedAggregateHashTable::NewBlock() {\n \tauto pin = buffer_manager.Allocate(Storage::BLOCK_SIZE);\n \tpayload_hds.push_back(move(pin));\n-\tpayload_hds_ptrs.push_back(payload_hds.back()->Ptr());\n+\tpayload_hds_ptrs.push_back(payload_hds.back().Ptr());\n \tpayload_page_offset = 0;\n }\n \n@@ -219,7 +223,7 @@ void GroupedAggregateHashTable::Resize(idx_t size) {\n \tauto byte_size = size * sizeof(ENTRY);\n \tif (byte_size > (idx_t)Storage::BLOCK_SIZE) {\n \t\thashes_hdl = buffer_manager.Allocate(byte_size);\n-\t\thashes_hdl_ptr = hashes_hdl->Ptr();\n+\t\thashes_hdl_ptr = hashes_hdl.Ptr();\n \t}\n \tmemset(hashes_hdl_ptr, 0, byte_size);\n \thashes_end_ptr = hashes_hdl_ptr + byte_size;\n@@ -289,7 +293,7 @@ idx_t GroupedAggregateHashTable::AddChunk(DataChunk &groups, Vector &group_hashe\n \t\t\t\tprobe_types.push_back(payload_types[payload_idx + i]);\n \t\t\t}\n \t\t\tDataChunk probe_chunk;\n-\t\t\tprobe_chunk.Initialize(probe_types);\n+\t\t\tprobe_chunk.Initialize(Allocator::DefaultAllocator(), probe_types);\n \t\t\tfor (idx_t group_idx = 0; group_idx < groups.ColumnCount(); group_idx++) {\n \t\t\t\tprobe_chunk.data[group_idx].Reference(groups.data[group_idx]);\n \t\t\t}\n@@ -308,7 +312,7 @@ idx_t GroupedAggregateHashTable::AddChunk(DataChunk &groups, Vector &group_hashe\n \t\t\t\t// now fix up the payload and addresses accordingly by creating\n \t\t\t\t// a selection vector\n \t\t\t\tDataChunk distinct_payload;\n-\t\t\t\tdistinct_payload.Initialize(payload.GetTypes());\n+\t\t\t\tdistinct_payload.Initialize(Allocator::DefaultAllocator(), payload.GetTypes());\n \t\t\t\tdistinct_payload.Slice(payload, new_groups, new_group_count);\n \t\t\t\tdistinct_payload.Verify();\n \n@@ -317,14 +321,16 @@ idx_t GroupedAggregateHashTable::AddChunk(DataChunk &groups, Vector &group_hashe\n \n \t\t\t\tif (aggr.filter) {\n \t\t\t\t\tdistinct_addresses.Normalify(new_group_count);\n-\t\t\t\t\tRowOperations::UpdateFilteredStates(aggr, distinct_addresses, distinct_payload, payload_idx);\n+\t\t\t\t\tRowOperations::UpdateFilteredStates(filter_set.GetFilterData(aggr_idx), aggr, distinct_addresses,\n+\t\t\t\t\t                                    distinct_payload, payload_idx);\n \t\t\t\t} else {\n \t\t\t\t\tRowOperations::UpdateStates(aggr, distinct_addresses, distinct_payload, payload_idx,\n \t\t\t\t\t                            new_group_count);\n \t\t\t\t}\n \t\t\t}\n \t\t} else if (aggr.filter) {\n-\t\t\tRowOperations::UpdateFilteredStates(aggr, addresses, payload, payload_idx);\n+\t\t\tRowOperations::UpdateFilteredStates(filter_set.GetFilterData(aggr_idx), aggr, addresses, payload,\n+\t\t\t                                    payload_idx);\n \t\t} else {\n \t\t\tRowOperations::UpdateStates(aggr, addresses, payload, payload_idx, payload.size());\n \t\t}\n@@ -521,31 +527,40 @@ idx_t GroupedAggregateHashTable::FindOrCreateGroups(DataChunk &groups, Vector &a\n \treturn FindOrCreateGroups(groups, hashes, addresses_out, new_groups_out);\n }\n \n-void GroupedAggregateHashTable::FlushMove(Vector &source_addresses, Vector &source_hashes, idx_t count) {\n+struct FlushMoveState {\n+\tFlushMoveState(Allocator &allocator, RowLayout &layout)\n+\t    : new_groups(STANDARD_VECTOR_SIZE), group_addresses(LogicalType::POINTER),\n+\t      new_groups_sel(STANDARD_VECTOR_SIZE) {\n+\t\tvector<LogicalType> group_types(layout.GetTypes().begin(), layout.GetTypes().end() - 1);\n+\t\tgroups.Initialize(allocator, group_types);\n+\t}\n+\n+\tDataChunk groups;\n+\tSelectionVector new_groups;\n+\tVector group_addresses;\n+\tSelectionVector new_groups_sel;\n+};\n+\n+void GroupedAggregateHashTable::FlushMove(FlushMoveState &state, Vector &source_addresses, Vector &source_hashes,\n+                                          idx_t count) {\n \tD_ASSERT(source_addresses.GetType() == LogicalType::POINTER);\n \tD_ASSERT(source_hashes.GetType() == LogicalType::HASH);\n \n-\tDataChunk groups;\n-\tgroups.Initialize(vector<LogicalType>(layout.GetTypes().begin(), layout.GetTypes().end() - 1));\n-\tgroups.SetCardinality(count);\n-\tfor (idx_t i = 0; i < groups.ColumnCount(); i++) {\n-\t\tauto &column = groups.data[i];\n+\tstate.groups.Reset();\n+\tstate.groups.SetCardinality(count);\n+\tfor (idx_t i = 0; i < state.groups.ColumnCount(); i++) {\n+\t\tauto &column = state.groups.data[i];\n \t\tconst auto col_offset = layout.GetOffsets()[i];\n \t\tRowOperations::Gather(source_addresses, *FlatVector::IncrementalSelectionVector(), column,\n \t\t                      *FlatVector::IncrementalSelectionVector(), count, col_offset, i);\n \t}\n \n-\tSelectionVector new_groups(STANDARD_VECTOR_SIZE);\n-\tVector group_addresses(LogicalType::POINTER);\n-\tSelectionVector new_groups_sel(STANDARD_VECTOR_SIZE);\n+\tFindOrCreateGroups(state.groups, source_hashes, state.group_addresses, state.new_groups_sel);\n \n-\tFindOrCreateGroups(groups, source_hashes, group_addresses, new_groups_sel);\n-\n-\tRowOperations::CombineStates(layout, source_addresses, group_addresses, count);\n+\tRowOperations::CombineStates(layout, source_addresses, state.group_addresses, count);\n }\n \n void GroupedAggregateHashTable::Combine(GroupedAggregateHashTable &other) {\n-\n \tD_ASSERT(!is_finalized);\n \n \tD_ASSERT(other.layout.GetAggrWidth() == layout.GetAggrWidth());\n@@ -565,6 +580,7 @@ void GroupedAggregateHashTable::Combine(GroupedAggregateHashTable &other) {\n \n \tidx_t group_idx = 0;\n \n+\tFlushMoveState state(allocator, layout);\n \tother.PayloadApply([&](idx_t page_nr, idx_t page_offset, data_ptr_t ptr) {\n \t\tauto hash = Load<hash_t>(ptr + hash_offset);\n \n@@ -572,11 +588,11 @@ void GroupedAggregateHashTable::Combine(GroupedAggregateHashTable &other) {\n \t\taddresses_ptr[group_idx] = ptr;\n \t\tgroup_idx++;\n \t\tif (group_idx == STANDARD_VECTOR_SIZE) {\n-\t\t\tFlushMove(addresses, hashes, group_idx);\n+\t\t\tFlushMove(state, addresses, hashes, group_idx);\n \t\t\tgroup_idx = 0;\n \t\t}\n \t});\n-\tFlushMove(addresses, hashes, group_idx);\n+\tFlushMove(state, addresses, hashes, group_idx);\n \tstring_heap->Merge(*other.string_heap);\n \tVerify();\n }\n@@ -598,6 +614,7 @@ void GroupedAggregateHashTable::Partition(vector<GroupedAggregateHashTable *> &p\n \tD_ASSERT(partition_hts.size() > 1);\n \tvector<PartitionInfo> partition_info(partition_hts.size());\n \n+\tFlushMoveState state(allocator, layout);\n \tPayloadApply([&](idx_t page_nr, idx_t page_offset, data_ptr_t ptr) {\n \t\tauto hash = Load<hash_t>(ptr + hash_offset);\n \n@@ -611,7 +628,7 @@ void GroupedAggregateHashTable::Partition(vector<GroupedAggregateHashTable *> &p\n \t\tinfo.group_count++;\n \t\tif (info.group_count == STANDARD_VECTOR_SIZE) {\n \t\t\tD_ASSERT(partition_hts[partition]);\n-\t\t\tpartition_hts[partition]->FlushMove(info.addresses, info.hashes, info.group_count);\n+\t\t\tpartition_hts[partition]->FlushMove(state, info.addresses, info.hashes, info.group_count);\n \t\t\tinfo.group_count = 0;\n \t\t}\n \t});\n@@ -620,7 +637,7 @@ void GroupedAggregateHashTable::Partition(vector<GroupedAggregateHashTable *> &p\n \tidx_t total_count = 0;\n \tfor (auto &partition_entry : partition_hts) {\n \t\tauto &info = partition_info[info_idx++];\n-\t\tpartition_entry->FlushMove(info.addresses, info.hashes, info.group_count);\n+\t\tpartition_entry->FlushMove(state, info.addresses, info.hashes, info.group_count);\n \n \t\tpartition_entry->string_heap->Merge(*string_heap);\n \t\tpartition_entry->Verify();\n@@ -675,7 +692,7 @@ void GroupedAggregateHashTable::Finalize() {\n \t}\n \n \t// early release hashes, not needed for partition/scan\n-\thashes_hdl.reset();\n+\thashes_hdl.Destroy();\n \tis_finalized = true;\n }\n \ndiff --git a/src/execution/base_aggregate_hashtable.cpp b/src/execution/base_aggregate_hashtable.cpp\nindex c5e863f2c16a..5cd2f3ee7545 100644\n--- a/src/execution/base_aggregate_hashtable.cpp\n+++ b/src/execution/base_aggregate_hashtable.cpp\n@@ -3,8 +3,10 @@\n \n namespace duckdb {\n \n-BaseAggregateHashTable::BaseAggregateHashTable(BufferManager &buffer_manager, vector<LogicalType> payload_types_p)\n-    : buffer_manager(buffer_manager), payload_types(move(payload_types_p)) {\n+BaseAggregateHashTable::BaseAggregateHashTable(Allocator &allocator, const vector<AggregateObject> &aggregates,\n+                                               BufferManager &buffer_manager, vector<LogicalType> payload_types_p)\n+    : allocator(allocator), buffer_manager(buffer_manager), payload_types(move(payload_types_p)) {\n+\tfilter_set.Initialize(allocator, aggregates, payload_types);\n }\n \n } // namespace duckdb\ndiff --git a/src/execution/expression_executor.cpp b/src/execution/expression_executor.cpp\nindex 73f0477bbee8..82991756431a 100644\n--- a/src/execution/expression_executor.cpp\n+++ b/src/execution/expression_executor.cpp\n@@ -6,19 +6,22 @@\n \n namespace duckdb {\n \n-ExpressionExecutor::ExpressionExecutor() {\n+ExpressionExecutor::ExpressionExecutor(Allocator &allocator) : allocator(allocator) {\n }\n \n-ExpressionExecutor::ExpressionExecutor(const Expression *expression) : ExpressionExecutor() {\n+ExpressionExecutor::ExpressionExecutor(Allocator &allocator, const Expression *expression)\n+    : ExpressionExecutor(allocator) {\n \tD_ASSERT(expression);\n \tAddExpression(*expression);\n }\n \n-ExpressionExecutor::ExpressionExecutor(const Expression &expression) : ExpressionExecutor() {\n+ExpressionExecutor::ExpressionExecutor(Allocator &allocator, const Expression &expression)\n+    : ExpressionExecutor(allocator) {\n \tAddExpression(expression);\n }\n \n-ExpressionExecutor::ExpressionExecutor(const vector<unique_ptr<Expression>> &exprs) : ExpressionExecutor() {\n+ExpressionExecutor::ExpressionExecutor(Allocator &allocator, const vector<unique_ptr<Expression>> &exprs)\n+    : ExpressionExecutor(allocator) {\n \tD_ASSERT(exprs.size() > 0);\n \tfor (auto &expr : exprs) {\n \t\tAddExpression(*expr);\n@@ -33,8 +36,8 @@ void ExpressionExecutor::AddExpression(const Expression &expr) {\n }\n \n void ExpressionExecutor::Initialize(const Expression &expression, ExpressionExecutorState &state) {\n-\tstate.root_state = InitializeState(expression, state);\n \tstate.executor = this;\n+\tstate.root_state = InitializeState(expression, state);\n }\n \n void ExpressionExecutor::Execute(DataChunk *input, DataChunk &result) {\n@@ -80,7 +83,7 @@ Value ExpressionExecutor::EvaluateScalar(const Expression &expr) {\n \tD_ASSERT(expr.IsFoldable());\n \tD_ASSERT(expr.IsScalar());\n \t// use an ExpressionExecutor to execute the expression\n-\tExpressionExecutor executor(expr);\n+\tExpressionExecutor executor(Allocator::DefaultAllocator(), expr);\n \n \tVector result(expr.return_type);\n \texecutor.ExecuteExpression(result);\ndiff --git a/src/execution/expression_executor_state.cpp b/src/execution/expression_executor_state.cpp\nindex 9457a9312ffc..7bc5889a56ac 100644\n--- a/src/execution/expression_executor_state.cpp\n+++ b/src/execution/expression_executor_state.cpp\n@@ -11,7 +11,7 @@ void ExpressionState::AddChild(Expression *expr) {\n \n void ExpressionState::Finalize() {\n \tif (!types.empty()) {\n-\t\tintermediate_chunk.Initialize(types);\n+\t\tintermediate_chunk.Initialize(root.executor->allocator, types);\n \t}\n }\n ExpressionState::ExpressionState(const Expression &expr, ExpressionExecutorState &root)\ndiff --git a/src/execution/index/art/art.cpp b/src/execution/index/art/art.cpp\nindex f5ca8581b9a9..77da6e2b53af 100644\n--- a/src/execution/index/art/art.cpp\n+++ b/src/execution/index/art/art.cpp\n@@ -14,7 +14,6 @@ ART::ART(const vector<column_t> &column_ids, const vector<unique_ptr<Expression>\n          IndexConstraintType constraint_type)\n     : Index(IndexType::ART, column_ids, unbound_expressions, constraint_type) {\n \ttree = nullptr;\n-\texpression_result.Initialize(logical_types);\n \tis_little_endian = Radix::IsLittleEndian();\n \tfor (idx_t i = 0; i < types.size(); i++) {\n \t\tswitch (types[i]) {\n@@ -256,7 +255,7 @@ bool ART::Insert(IndexLock &lock, DataChunk &input, Vector &row_ids) {\n \n bool ART::Append(IndexLock &lock, DataChunk &appended_data, Vector &row_identifiers) {\n \tDataChunk expression_result;\n-\texpression_result.Initialize(logical_types);\n+\texpression_result.Initialize(Allocator::DefaultAllocator(), logical_types);\n \n \t// first resolve the expressions for the index\n \tExecuteExpressions(appended_data, expression_result);\n@@ -358,7 +357,7 @@ bool ART::Insert(unique_ptr<Node> &node, unique_ptr<Key> value, unsigned depth,\n //===--------------------------------------------------------------------===//\n void ART::Delete(IndexLock &state, DataChunk &input, Vector &row_ids) {\n \tDataChunk expression_result;\n-\texpression_result.Initialize(logical_types);\n+\texpression_result.Initialize(Allocator::DefaultAllocator(), logical_types);\n \n \t// first resolve the expressions\n \tExecuteExpressions(input, expression_result);\n@@ -859,7 +858,7 @@ void ART::VerifyExistence(DataChunk &chunk, VerifyExistenceType verify_type, str\n \t}\n \n \tDataChunk expression_result;\n-\texpression_result.Initialize(logical_types);\n+\texpression_result.Initialize(Allocator::DefaultAllocator(), logical_types);\n \n \t// unique index, check\n \tlock_guard<mutex> l(lock);\ndiff --git a/src/execution/join_hashtable.cpp b/src/execution/join_hashtable.cpp\nindex bb4d7899cc29..14582528d929 100644\n--- a/src/execution/join_hashtable.cpp\n+++ b/src/execution/join_hashtable.cpp\n@@ -82,7 +82,7 @@ void JoinHashTable::ApplyBitmask(Vector &hashes, const SelectionVector &sel, idx\n \n \tauto hash_data = (hash_t *)hdata.data;\n \tauto result_data = FlatVector::GetData<data_ptr_t *>(pointers);\n-\tauto main_ht = (data_ptr_t *)hash_map->node->buffer;\n+\tauto main_ht = (data_ptr_t *)hash_map.Ptr();\n \tfor (idx_t i = 0; i < count; i++) {\n \t\tauto rindex = sel.get_index(i);\n \t\tauto hindex = hdata.sel->get_index(rindex);\n@@ -242,7 +242,7 @@ void JoinHashTable::InsertHashes(Vector &hashes, idx_t count, data_ptr_t key_loc\n \thashes.Normalify(count);\n \n \tD_ASSERT(hashes.GetVectorType() == VectorType::FLAT_VECTOR);\n-\tauto pointers = (data_ptr_t *)hash_map->node->buffer;\n+\tauto pointers = (data_ptr_t *)hash_map.Ptr();\n \tauto indices = FlatVector::GetData<hash_t>(hashes);\n \tfor (idx_t i = 0; i < count; i++) {\n \t\tauto index = indices[i];\n@@ -265,7 +265,7 @@ void JoinHashTable::Finalize() {\n \n \t// allocate the HT and initialize it with all-zero entries\n \thash_map = buffer_manager.Allocate(capacity * sizeof(data_ptr_t));\n-\tmemset(hash_map->node->buffer, 0, capacity * sizeof(data_ptr_t));\n+\tmemset(hash_map.Ptr(), 0, capacity * sizeof(data_ptr_t));\n \n \tVector hashes(LogicalType::HASH);\n \tauto hash_data = FlatVector::GetData<hash_t>(hashes);\n@@ -276,7 +276,7 @@ void JoinHashTable::Finalize() {\n \t// FIXME: if we cannot keep everything pinned in memory, we could switch to an out-of-memory merge join or so\n \tfor (auto &block : block_collection->blocks) {\n \t\tauto handle = buffer_manager.Pin(block.block);\n-\t\tdata_ptr_t dataptr = handle->node->buffer;\n+\t\tdata_ptr_t dataptr = handle.Ptr();\n \t\tidx_t entry = 0;\n \t\twhile (entry < block.count) {\n \t\t\t// fetch the next vector of entries from the blocks\n@@ -735,7 +735,7 @@ void JoinHashTable::ScanFullOuter(DataChunk &result, JoinHTScanState &state) {\n \t\tfor (; state.block_position < block_collection->blocks.size(); state.block_position++, state.position = 0) {\n \t\t\tauto &block = block_collection->blocks[state.block_position];\n \t\t\tauto &handle = pinned_handles[state.block_position];\n-\t\t\tauto baseptr = handle->node->buffer;\n+\t\t\tauto baseptr = handle.Ptr();\n \t\t\tfor (; state.position < block.count; state.position++) {\n \t\t\t\tauto tuple_base = baseptr + state.position * entry_size;\n \t\t\t\tauto found_match = Load<bool>(tuple_base + tuple_size);\n@@ -780,7 +780,7 @@ idx_t JoinHashTable::FillWithHTOffsets(data_ptr_t *key_locations, JoinHTScanStat\n \twhile (state.block_position < block_collection->blocks.size()) {\n \t\tauto &block = block_collection->blocks[state.block_position];\n \t\tauto handle = buffer_manager.Pin(block.block);\n-\t\tauto base_ptr = handle->node->buffer;\n+\t\tauto base_ptr = handle.Ptr();\n \t\t// go through all the tuples within this block\n \t\twhile (state.position < block.count) {\n \t\t\tauto tuple_base = base_ptr + state.position * entry_size;\ndiff --git a/src/execution/operator/aggregate/CMakeLists.txt b/src/execution/operator/aggregate/CMakeLists.txt\nindex c60a149b5c50..1f897f1dd87e 100644\n--- a/src/execution/operator/aggregate/CMakeLists.txt\n+++ b/src/execution/operator/aggregate/CMakeLists.txt\n@@ -1,6 +1,7 @@\n add_library_unity(\n   duckdb_operator_aggregate\n   OBJECT\n+  aggregate_object.cpp\n   physical_hash_aggregate.cpp\n   physical_perfecthash_aggregate.cpp\n   physical_simple_aggregate.cpp\ndiff --git a/src/execution/operator/aggregate/aggregate_object.cpp b/src/execution/operator/aggregate/aggregate_object.cpp\nnew file mode 100644\nindex 000000000000..b0421bdb5f50\n--- /dev/null\n+++ b/src/execution/operator/aggregate/aggregate_object.cpp\n@@ -0,0 +1,74 @@\n+#include \"duckdb/execution/operator/aggregate/aggregate_object.hpp\"\n+#include \"duckdb/planner/expression/bound_aggregate_expression.hpp\"\n+\n+namespace duckdb {\n+\n+AggregateObject::AggregateObject(AggregateFunction function, FunctionData *bind_data, idx_t child_count,\n+                                 idx_t payload_size, bool distinct, PhysicalType return_type, Expression *filter)\n+    : function(move(function)), bind_data(bind_data), child_count(child_count), payload_size(payload_size),\n+      distinct(distinct), return_type(return_type), filter(filter) {\n+}\n+\n+AggregateObject::AggregateObject(BoundAggregateExpression *aggr)\n+    : AggregateObject(aggr->function, aggr->bind_info.get(), aggr->children.size(),\n+                      AlignValue(aggr->function.state_size()), aggr->distinct, aggr->return_type.InternalType(),\n+                      aggr->filter.get()) {\n+}\n+\n+vector<AggregateObject> AggregateObject::CreateAggregateObjects(const vector<BoundAggregateExpression *> &bindings) {\n+\tvector<AggregateObject> aggregates;\n+\taggregates.reserve(aggregates.size());\n+\tfor (auto &binding : bindings) {\n+\t\taggregates.emplace_back(binding);\n+\t}\n+\treturn aggregates;\n+}\n+\n+AggregateFilterData::AggregateFilterData(Allocator &allocator, Expression &filter_expr,\n+                                         const vector<LogicalType> &payload_types)\n+    : filter_executor(allocator, &filter_expr), true_sel(STANDARD_VECTOR_SIZE) {\n+\tif (payload_types.empty()) {\n+\t\treturn;\n+\t}\n+\tfiltered_payload.Initialize(allocator, payload_types);\n+}\n+\n+idx_t AggregateFilterData::ApplyFilter(DataChunk &payload) {\n+\tfiltered_payload.Reset();\n+\n+\tauto count = filter_executor.SelectExpression(payload, true_sel);\n+\tfiltered_payload.Slice(payload, true_sel, count);\n+\treturn count;\n+}\n+\n+AggregateFilterDataSet::AggregateFilterDataSet() {\n+}\n+\n+void AggregateFilterDataSet::Initialize(Allocator &allocator, const vector<AggregateObject> &aggregates,\n+                                        const vector<LogicalType> &payload_types) {\n+\tbool has_filters = false;\n+\tfor (auto &aggregate : aggregates) {\n+\t\tif (aggregate.filter) {\n+\t\t\thas_filters = true;\n+\t\t\tbreak;\n+\t\t}\n+\t}\n+\tif (!has_filters) {\n+\t\t// no filters: nothing to do\n+\t\treturn;\n+\t}\n+\tfilter_data.resize(aggregates.size());\n+\tfor (idx_t aggr_idx = 0; aggr_idx < aggregates.size(); aggr_idx++) {\n+\t\tauto &aggr = aggregates[aggr_idx];\n+\t\tif (aggr.filter) {\n+\t\t\tfilter_data[aggr_idx] = make_unique<AggregateFilterData>(allocator, *aggr.filter, payload_types);\n+\t\t}\n+\t}\n+}\n+\n+AggregateFilterData &AggregateFilterDataSet::GetFilterData(idx_t aggr_idx) {\n+\tD_ASSERT(aggr_idx < filter_data.size());\n+\tD_ASSERT(filter_data[aggr_idx]);\n+\treturn *filter_data[aggr_idx];\n+}\n+} // namespace duckdb\ndiff --git a/src/execution/operator/aggregate/physical_hash_aggregate.cpp b/src/execution/operator/aggregate/physical_hash_aggregate.cpp\nindex 2961c0ec60db..f7d80ec18700 100644\n--- a/src/execution/operator/aggregate/physical_hash_aggregate.cpp\n+++ b/src/execution/operator/aggregate/physical_hash_aggregate.cpp\n@@ -238,9 +238,9 @@ SinkFinalizeType PhysicalHashAggregate::Finalize(Pipeline &pipeline, Event &even\n //===--------------------------------------------------------------------===//\n class PhysicalHashAggregateState : public GlobalSourceState {\n public:\n-\texplicit PhysicalHashAggregateState(const PhysicalHashAggregate &op) : scan_index(0) {\n+\texplicit PhysicalHashAggregateState(ClientContext &context, const PhysicalHashAggregate &op) : scan_index(0) {\n \t\tfor (auto &rt : op.radix_tables) {\n-\t\t\tradix_states.push_back(rt.GetGlobalSourceState());\n+\t\t\tradix_states.push_back(rt.GetGlobalSourceState(context));\n \t\t}\n \t}\n \n@@ -250,7 +250,7 @@ class PhysicalHashAggregateState : public GlobalSourceState {\n };\n \n unique_ptr<GlobalSourceState> PhysicalHashAggregate::GetGlobalSourceState(ClientContext &context) const {\n-\treturn make_unique<PhysicalHashAggregateState>(*this);\n+\treturn make_unique<PhysicalHashAggregateState>(context, *this);\n }\n \n void PhysicalHashAggregate::GetData(ExecutionContext &context, DataChunk &chunk, GlobalSourceState &gstate_p,\ndiff --git a/src/execution/operator/aggregate/physical_perfecthash_aggregate.cpp b/src/execution/operator/aggregate/physical_perfecthash_aggregate.cpp\nindex 29fa4a228c7e..8b134b4754e8 100644\n--- a/src/execution/operator/aggregate/physical_perfecthash_aggregate.cpp\n+++ b/src/execution/operator/aggregate/physical_perfecthash_aggregate.cpp\n@@ -70,9 +70,10 @@ PhysicalPerfectHashAggregate::PhysicalPerfectHashAggregate(ClientContext &contex\n \t}\n }\n \n-unique_ptr<PerfectAggregateHashTable> PhysicalPerfectHashAggregate::CreateHT(ClientContext &context) const {\n-\treturn make_unique<PerfectAggregateHashTable>(BufferManager::GetBufferManager(context), group_types, payload_types,\n-\t                                              aggregate_objects, group_minima, required_bits);\n+unique_ptr<PerfectAggregateHashTable> PhysicalPerfectHashAggregate::CreateHT(Allocator &allocator,\n+                                                                             ClientContext &context) const {\n+\treturn make_unique<PerfectAggregateHashTable>(allocator, BufferManager::GetBufferManager(context), group_types,\n+\t                                              payload_types, aggregate_objects, group_minima, required_bits);\n }\n \n //===--------------------------------------------------------------------===//\n@@ -81,7 +82,7 @@ unique_ptr<PerfectAggregateHashTable> PhysicalPerfectHashAggregate::CreateHT(Cli\n class PerfectHashAggregateGlobalState : public GlobalSinkState {\n public:\n \tPerfectHashAggregateGlobalState(const PhysicalPerfectHashAggregate &op, ClientContext &context)\n-\t    : ht(op.CreateHT(context)) {\n+\t    : ht(op.CreateHT(Allocator::Get(context), context)) {\n \t}\n \n \t//! The lock for updating the global aggregate state\n@@ -92,8 +93,8 @@ class PerfectHashAggregateGlobalState : public GlobalSinkState {\n \n class PerfectHashAggregateLocalState : public LocalSinkState {\n public:\n-\tPerfectHashAggregateLocalState(const PhysicalPerfectHashAggregate &op, ClientContext &context)\n-\t    : ht(op.CreateHT(context)) {\n+\tPerfectHashAggregateLocalState(const PhysicalPerfectHashAggregate &op, ExecutionContext &context)\n+\t    : ht(op.CreateHT(Allocator::Get(context.client), context.client)) {\n \t\tgroup_chunk.InitializeEmpty(op.group_types);\n \t\tif (!op.payload_types.empty()) {\n \t\t\taggregate_input_chunk.InitializeEmpty(op.payload_types);\n@@ -111,7 +112,7 @@ unique_ptr<GlobalSinkState> PhysicalPerfectHashAggregate::GetGlobalSinkState(Cli\n }\n \n unique_ptr<LocalSinkState> PhysicalPerfectHashAggregate::GetLocalSinkState(ExecutionContext &context) const {\n-\treturn make_unique<PerfectHashAggregateLocalState>(*this, context.client);\n+\treturn make_unique<PerfectHashAggregateLocalState>(*this, context);\n }\n \n SinkResultType PhysicalPerfectHashAggregate::Sink(ExecutionContext &context, GlobalSinkState &state,\ndiff --git a/src/execution/operator/aggregate/physical_simple_aggregate.cpp b/src/execution/operator/aggregate/physical_simple_aggregate.cpp\nindex eb6466c30add..e4e5dcd7c210 100644\n--- a/src/execution/operator/aggregate/physical_simple_aggregate.cpp\n+++ b/src/execution/operator/aggregate/physical_simple_aggregate.cpp\n@@ -5,6 +5,7 @@\n #include \"duckdb/planner/expression/bound_aggregate_expression.hpp\"\n #include \"duckdb/catalog/catalog_entry/aggregate_function_catalog_entry.hpp\"\n #include \"duckdb/main/client_context.hpp\"\n+#include \"duckdb/execution/operator/aggregate/aggregate_object.hpp\"\n \n namespace duckdb {\n \n@@ -68,8 +69,11 @@ class SimpleAggregateGlobalState : public GlobalSinkState {\n \n class SimpleAggregateLocalState : public LocalSinkState {\n public:\n-\texplicit SimpleAggregateLocalState(const vector<unique_ptr<Expression>> &aggregates) : state(aggregates) {\n+\tSimpleAggregateLocalState(Allocator &allocator, const vector<unique_ptr<Expression>> &aggregates,\n+\t                          const vector<LogicalType> &child_types)\n+\t    : state(aggregates), child_executor(allocator) {\n \t\tvector<LogicalType> payload_types;\n+\t\tvector<AggregateObject> aggregate_objects;\n \t\tfor (auto &aggregate : aggregates) {\n \t\t\tD_ASSERT(aggregate->GetExpressionClass() == ExpressionClass::BOUND_AGGREGATE);\n \t\t\tauto &aggr = (BoundAggregateExpression &)*aggregate;\n@@ -80,10 +84,12 @@ class SimpleAggregateLocalState : public LocalSinkState {\n \t\t\t\t\tchild_executor.AddExpression(*child);\n \t\t\t\t}\n \t\t\t}\n+\t\t\taggregate_objects.emplace_back(&aggr);\n \t\t}\n \t\tif (!payload_types.empty()) { // for select count(*) from t; there is no payload at all\n-\t\t\tpayload_chunk.Initialize(payload_types);\n+\t\t\tpayload_chunk.Initialize(allocator, payload_types);\n \t\t}\n+\t\tfilter_set.Initialize(allocator, aggregate_objects, child_types);\n \t}\n \tvoid Reset() {\n \t\tpayload_chunk.Reset();\n@@ -95,6 +101,8 @@ class SimpleAggregateLocalState : public LocalSinkState {\n \tExpressionExecutor child_executor;\n \t//! The payload chunk\n \tDataChunk payload_chunk;\n+\t//! Aggregate filter data set\n+\tAggregateFilterDataSet filter_set;\n };\n \n unique_ptr<GlobalSinkState> PhysicalSimpleAggregate::GetGlobalSinkState(ClientContext &context) const {\n@@ -102,7 +110,7 @@ unique_ptr<GlobalSinkState> PhysicalSimpleAggregate::GetGlobalSinkState(ClientCo\n }\n \n unique_ptr<LocalSinkState> PhysicalSimpleAggregate::GetLocalSinkState(ExecutionContext &context) const {\n-\treturn make_unique<SimpleAggregateLocalState>(aggregates);\n+\treturn make_unique<SimpleAggregateLocalState>(Allocator::Get(context.client), aggregates, children[0]->GetTypes());\n }\n \n SinkResultType PhysicalSimpleAggregate::Sink(ExecutionContext &context, GlobalSinkState &state, LocalSinkState &lstate,\n@@ -114,18 +122,14 @@ SinkResultType PhysicalSimpleAggregate::Sink(ExecutionContext &context, GlobalSi\n \n \tDataChunk &payload_chunk = sink.payload_chunk;\n \tfor (idx_t aggr_idx = 0; aggr_idx < aggregates.size(); aggr_idx++) {\n-\t\tDataChunk filtered_input;\n \t\tauto &aggregate = (BoundAggregateExpression &)*aggregates[aggr_idx];\n \t\tidx_t payload_cnt = 0;\n \t\t// resolve the filter (if any)\n \t\tif (aggregate.filter) {\n-\t\t\tExpressionExecutor filter_execution(aggregate.filter.get());\n-\t\t\tSelectionVector true_sel(STANDARD_VECTOR_SIZE);\n-\t\t\tauto count = filter_execution.SelectExpression(input, true_sel);\n-\t\t\tauto input_types = input.GetTypes();\n-\t\t\tfiltered_input.Initialize(input_types);\n-\t\t\tfiltered_input.Slice(input, true_sel, count);\n-\t\t\tsink.child_executor.SetChunk(filtered_input);\n+\t\t\tauto &filtered_data = sink.filter_set.GetFilterData(aggr_idx);\n+\t\t\tauto count = filtered_data.ApplyFilter(input);\n+\n+\t\t\tsink.child_executor.SetChunk(filtered_data.filtered_payload);\n \t\t\tpayload_chunk.SetCardinality(count);\n \t\t} else {\n \t\t\tsink.child_executor.SetChunk(input);\ndiff --git a/src/execution/operator/aggregate/physical_streaming_window.cpp b/src/execution/operator/aggregate/physical_streaming_window.cpp\nindex 3511eda9bddd..ac5a5fd1cd17 100644\n--- a/src/execution/operator/aggregate/physical_streaming_window.cpp\n+++ b/src/execution/operator/aggregate/physical_streaming_window.cpp\n@@ -61,7 +61,7 @@ unique_ptr<GlobalOperatorState> PhysicalStreamingWindow::GetGlobalOperatorState(\n \treturn make_unique<StreamingWindowGlobalState>();\n }\n \n-unique_ptr<OperatorState> PhysicalStreamingWindow::GetOperatorState(ClientContext &context) const {\n+unique_ptr<OperatorState> PhysicalStreamingWindow::GetOperatorState(ExecutionContext &context) const {\n \treturn make_unique<StreamingWindowState>();\n }\n \ndiff --git a/src/execution/operator/aggregate/physical_window.cpp b/src/execution/operator/aggregate/physical_window.cpp\nindex 351889822b76..333e189aefcc 100644\n--- a/src/execution/operator/aggregate/physical_window.cpp\n+++ b/src/execution/operator/aggregate/physical_window.cpp\n@@ -24,9 +24,9 @@ using counts_t = std::vector<size_t>;\n //\tGlobal sink state\n class WindowGlobalState : public GlobalSinkState {\n public:\n-\tWindowGlobalState(const PhysicalWindow &op_p, ClientContext &context)\n-\t    : op(op_p), buffer_manager(BufferManager::GetBufferManager(context)),\n-\t      mode(DBConfig::GetConfig(context).window_mode) {\n+\tWindowGlobalState(Allocator &allocator, const PhysicalWindow &op_p, ClientContext &context)\n+\t    : op(op_p), buffer_manager(BufferManager::GetBufferManager(context)), chunks(allocator),\n+\t      over_collection(allocator), hash_collection(allocator), mode(DBConfig::GetConfig(context).window_mode) {\n \t}\n \tconst PhysicalWindow &op;\n \tBufferManager &buffer_manager;\n@@ -41,8 +41,9 @@ class WindowGlobalState : public GlobalSinkState {\n //\tPer-thread sink state\n class WindowLocalState : public LocalSinkState {\n public:\n-\texplicit WindowLocalState(const PhysicalWindow &op_p, const unsigned partition_bits = 10)\n-\t    : op(op_p), partition_count(size_t(1) << partition_bits) {\n+\texplicit WindowLocalState(Allocator &allocator, const PhysicalWindow &op_p, const unsigned partition_bits = 10)\n+\t    : op(op_p), chunks(allocator), over_collection(allocator), hash_collection(allocator),\n+\t      partition_count(size_t(1) << partition_bits) {\n \t}\n \n \tconst PhysicalWindow &op;\n@@ -56,8 +57,9 @@ class WindowLocalState : public LocalSinkState {\n // Per-thread read state\n class WindowOperatorState : public LocalSourceState {\n public:\n-\tWindowOperatorState(const PhysicalWindow &op, ExecutionContext &context)\n-\t    : buffer_manager(BufferManager::GetBufferManager(context.client)) {\n+\tWindowOperatorState(Allocator &allocator, const PhysicalWindow &op, ExecutionContext &context)\n+\t    : buffer_manager(BufferManager::GetBufferManager(context.client)), chunks(allocator),\n+\t      window_results(allocator) {\n \t\tauto &gstate = (WindowGlobalState &)*op.sink_state;\n \t\t// initialize thread-local operator state\n \t\tpartitions = gstate.counts.size();\n@@ -65,6 +67,7 @@ class WindowOperatorState : public LocalSourceState {\n \t\tposition = 0;\n \t}\n \n+\tBufferManager &buffer_manager;\n \t//! The number of partitions to process (0 if there is no partitioning)\n \tsize_t partitions;\n \t//! The output read position.\n@@ -76,7 +79,6 @@ class WindowOperatorState : public LocalSourceState {\n \t//! The read cursor\n \tidx_t position;\n \n-\tBufferManager &buffer_manager;\n \tunique_ptr<GlobalSortState> global_sort_state;\n };\n \n@@ -286,8 +288,9 @@ static void MaterializeExpressions(Expression **exprs, idx_t expr_count, ChunkCo\n \t\treturn;\n \t}\n \n+\tauto &allocator = input.GetAllocator();\n \tvector<LogicalType> types;\n-\tExpressionExecutor executor;\n+\tExpressionExecutor executor(allocator);\n \tfor (idx_t expr_idx = 0; expr_idx < expr_count; ++expr_idx) {\n \t\ttypes.push_back(exprs[expr_idx]->return_type);\n \t\texecutor.AddExpression(*exprs[expr_idx]);\n@@ -295,7 +298,7 @@ static void MaterializeExpressions(Expression **exprs, idx_t expr_count, ChunkCo\n \n \tfor (idx_t i = 0; i < input.ChunkCount(); i++) {\n \t\tDataChunk chunk;\n-\t\tchunk.Initialize(types);\n+\t\tchunk.Initialize(allocator, types);\n \n \t\texecutor.Execute(input.GetChunk(i), chunk);\n \n@@ -319,6 +322,7 @@ static void SortCollectionForPartition(WindowOperatorState &state, BoundWindowEx\n \tif (input.Count() == 0) {\n \t\treturn;\n \t}\n+\tauto &allocator = input.GetAllocator();\n \n \tvector<BoundOrderByNode> orders;\n \t// we sort by both 1) partition by expression list and 2) order by expressions\n@@ -349,8 +353,8 @@ static void SortCollectionForPartition(WindowOperatorState &state, BoundWindowEx\n \tDataChunk payload_partition;\n \tif (hashes) {\n \t\tsel.Initialize(STANDARD_VECTOR_SIZE);\n-\t\tover_partition.Initialize(over.Types());\n-\t\tpayload_partition.Initialize(payload_types);\n+\t\tover_partition.Initialize(allocator, over.Types());\n+\t\tpayload_partition.Initialize(allocator, payload_types);\n \t}\n \n \t// initialize row layout for sorting\n@@ -431,12 +435,13 @@ static void ScanSortedPartition(WindowOperatorState &state, ChunkCollection &inp\n \n \tauto payload_types = input_types;\n \tpayload_types.insert(payload_types.end(), over_types.begin(), over_types.end());\n+\tauto &allocator = input.GetAllocator();\n \n \t// scan the sorted row data\n \tPayloadScanner scanner(*global_sort_state.sorted_blocks[0]->payload_data, global_sort_state);\n \tfor (;;) {\n \t\tDataChunk payload_chunk;\n-\t\tpayload_chunk.Initialize(payload_types);\n+\t\tpayload_chunk.Initialize(allocator, payload_types);\n \t\tpayload_chunk.SetCardinality(0);\n \t\tscanner.Scan(payload_chunk);\n \t\tif (payload_chunk.size() == 0) {\n@@ -453,9 +458,10 @@ static void ScanSortedPartition(WindowOperatorState &state, ChunkCollection &inp\n \t}\n }\n \n-static void HashChunk(counts_t &counts, DataChunk &hash_chunk, DataChunk &sort_chunk, const idx_t partition_cols) {\n+static void HashChunk(Allocator &allocator, counts_t &counts, DataChunk &hash_chunk, DataChunk &sort_chunk,\n+                      const idx_t partition_cols) {\n \tconst vector<LogicalType> hash_types(1, LogicalType::HASH);\n-\thash_chunk.Initialize(hash_types);\n+\thash_chunk.Initialize(allocator, hash_types);\n \thash_chunk.SetCardinality(sort_chunk);\n \tauto &hash_vector = hash_chunk.data[0];\n \n@@ -478,9 +484,10 @@ static void HashChunk(counts_t &counts, DataChunk &hash_chunk, DataChunk &sort_c\n \t}\n }\n \n-static void MaterializeOverForWindow(BoundWindowExpression *wexpr, DataChunk &input_chunk, DataChunk &over_chunk) {\n+static void MaterializeOverForWindow(Allocator &allocator, BoundWindowExpression *wexpr, DataChunk &input_chunk,\n+                                     DataChunk &over_chunk) {\n \tvector<LogicalType> over_types;\n-\tExpressionExecutor executor;\n+\tExpressionExecutor executor(allocator);\n \n \t// we sort by both 1) partition by expression list and 2) order by expressions\n \tfor (idx_t prt_idx = 0; prt_idx < wexpr->partitions.size(); prt_idx++) {\n@@ -497,7 +504,7 @@ static void MaterializeOverForWindow(BoundWindowExpression *wexpr, DataChunk &in\n \n \tD_ASSERT(!over_types.empty());\n \n-\tover_chunk.Initialize(over_types);\n+\tover_chunk.Initialize(allocator, over_types);\n \texecutor.Execute(input_chunk, over_chunk);\n \n \tover_chunk.Verify();\n@@ -878,9 +885,9 @@ static void ComputeWindowExpression(BoundWindowExpression *wexpr, ChunkCollectio\n                                     const ValidityMask &order_mask, WindowAggregationMode mode) {\n \n \t// TODO we could evaluate those expressions in parallel\n-\n+\tauto &allocator = input.GetAllocator();\n \t// evaluate inner expressions of window functions, could be more complex\n-\tChunkCollection payload_collection;\n+\tChunkCollection payload_collection(allocator);\n \tvector<Expression *> exprs;\n \tfor (auto &child : wexpr->children) {\n \t\texprs.push_back(child.get());\n@@ -888,8 +895,8 @@ static void ComputeWindowExpression(BoundWindowExpression *wexpr, ChunkCollectio\n \t// TODO: child may be a scalar, don't need to materialize the whole collection then\n \tMaterializeExpressions(exprs.data(), exprs.size(), input, payload_collection);\n \n-\tChunkCollection leadlag_offset_collection;\n-\tChunkCollection leadlag_default_collection;\n+\tChunkCollection leadlag_offset_collection(allocator);\n+\tChunkCollection leadlag_default_collection(allocator);\n \tif (wexpr->type == ExpressionType::WINDOW_LEAD || wexpr->type == ExpressionType::WINDOW_LAG) {\n \t\tif (wexpr->offset_expr) {\n \t\t\tMaterializeExpression(wexpr->offset_expr.get(), input, leadlag_offset_collection,\n@@ -908,7 +915,7 @@ static void ComputeWindowExpression(BoundWindowExpression *wexpr, ChunkCollectio\n \t\t// \tStart with all invalid and set the ones that pass\n \t\tfilter_bits.resize(ValidityMask::ValidityMaskSize(input.Count()), 0);\n \t\tfilter_mask.Initialize(filter_bits.data());\n-\t\tExpressionExecutor filter_execution(*wexpr->filter_expr);\n+\t\tExpressionExecutor filter_execution(allocator, *wexpr->filter_expr);\n \t\tSelectionVector true_sel(STANDARD_VECTOR_SIZE);\n \t\tidx_t base_idx = 0;\n \t\tfor (auto &chunk : input.Chunks()) {\n@@ -921,12 +928,12 @@ static void ComputeWindowExpression(BoundWindowExpression *wexpr, ChunkCollectio\n \t}\n \n \t// evaluate boundaries if present. Parser has checked boundary types.\n-\tChunkCollection boundary_start_collection;\n+\tChunkCollection boundary_start_collection(allocator);\n \tif (wexpr->start_expr) {\n \t\tMaterializeExpression(wexpr->start_expr.get(), input, boundary_start_collection, wexpr->start_expr->IsScalar());\n \t}\n \n-\tChunkCollection boundary_end_collection;\n+\tChunkCollection boundary_end_collection(allocator);\n \tif (wexpr->end_expr) {\n \t\tMaterializeExpression(wexpr->end_expr.get(), input, boundary_end_collection, wexpr->end_expr->IsScalar());\n \t}\n@@ -982,7 +989,7 @@ static void ComputeWindowExpression(BoundWindowExpression *wexpr, ChunkCollectio\n \t// this is the main loop, go through all sorted rows and compute window function result\n \tconst vector<LogicalType> output_types(1, wexpr->return_type);\n \tDataChunk output_chunk;\n-\toutput_chunk.Initialize(output_types);\n+\toutput_chunk.Initialize(allocator, output_types);\n \tfor (idx_t row_idx = 0; row_idx < input.Count(); row_idx++) {\n \t\t// Grow the chunk if necessary.\n \t\tconst auto output_offset = row_idx % STANDARD_VECTOR_SIZE;\n@@ -1189,7 +1196,7 @@ static void ComputeWindowExpressions(WindowExpressions &window_exprs, ChunkColle\n \n \t//\tCompute the functions columnwise\n \tfor (idx_t expr_idx = 0; expr_idx < window_exprs.size(); ++expr_idx) {\n-\t\tChunkCollection output;\n+\t\tChunkCollection output(input.GetAllocator());\n \t\tComputeWindowExpression(window_exprs[expr_idx], input, output, over, partition_mask, order_mask, mode);\n \t\twindow_results.Fuse(output);\n \t}\n@@ -1198,7 +1205,8 @@ static void ComputeWindowExpressions(WindowExpressions &window_exprs, ChunkColle\n //===--------------------------------------------------------------------===//\n // Sink\n //===--------------------------------------------------------------------===//\n-static void GeneratePartition(WindowOperatorState &state, WindowGlobalState &gstate, const idx_t hash_bin) {\n+static void GeneratePartition(Allocator &allocator, WindowOperatorState &state, WindowGlobalState &gstate,\n+                              const idx_t hash_bin) {\n \tauto &op = (PhysicalWindow &)gstate.op;\n \tWindowExpressions window_exprs;\n \tfor (idx_t expr_idx = 0; expr_idx < op.select_list.size(); ++expr_idx) {\n@@ -1225,7 +1233,7 @@ static void GeneratePartition(WindowOperatorState &state, WindowGlobalState &gst\n \n \tif (gstate.counts.empty() && hash_bin == 0) {\n \t\tChunkCollection &input = gstate.chunks;\n-\t\tChunkCollection output;\n+\t\tChunkCollection output(allocator);\n \t\tChunkCollection &over = gstate.over_collection;\n \n \t\tconst auto has_sorting = over_expr->partitions.size() + over_expr->orders.size();\n@@ -1248,9 +1256,9 @@ static void GeneratePartition(WindowOperatorState &state, WindowGlobalState &gst\n \t\t                           hash_bin, hash_mask);\n \n \t\t// Scan the sorted data into new Collections\n-\t\tChunkCollection input;\n-\t\tChunkCollection output;\n-\t\tChunkCollection over;\n+\t\tChunkCollection input(allocator);\n+\t\tChunkCollection output(allocator);\n+\t\tChunkCollection over(allocator);\n \t\tScanSortedPartition(state, input, input_types, over, over_types);\n \n \t\tComputeWindowExpressions(window_exprs, input, output, over, gstate.mode);\n@@ -1294,10 +1302,11 @@ SinkResultType PhysicalWindow::Sink(ExecutionContext &context, GlobalSinkState &\n \tconst auto over_idx = 0;\n \tauto over_expr = reinterpret_cast<BoundWindowExpression *>(select_list[over_idx].get());\n \n+\tauto &allocator = Allocator::Get(context.client);\n \tconst auto sort_col_count = over_expr->partitions.size() + over_expr->orders.size();\n \tif (sort_col_count > 0) {\n \t\tDataChunk over_chunk;\n-\t\tMaterializeOverForWindow(over_expr, input, over_chunk);\n+\t\tMaterializeOverForWindow(allocator, over_expr, input, over_chunk);\n \n \t\tif (!over_expr->partitions.empty()) {\n \t\t\tif (lstate.counts.empty()) {\n@@ -1305,7 +1314,7 @@ SinkResultType PhysicalWindow::Sink(ExecutionContext &context, GlobalSinkState &\n \t\t\t}\n \n \t\t\tDataChunk hash_chunk;\n-\t\t\tHashChunk(lstate.counts, hash_chunk, over_chunk, over_expr->partitions.size());\n+\t\t\tHashChunk(allocator, lstate.counts, hash_chunk, over_chunk, over_expr->partitions.size());\n \t\t\tlstate.hash_collection.Append(hash_chunk);\n \t\t\tD_ASSERT(lstate.chunks.Count() == lstate.hash_collection.Count());\n \t\t}\n@@ -1337,11 +1346,11 @@ void PhysicalWindow::Combine(ExecutionContext &context, GlobalSinkState &gstate_\n }\n \n unique_ptr<LocalSinkState> PhysicalWindow::GetLocalSinkState(ExecutionContext &context) const {\n-\treturn make_unique<WindowLocalState>(*this);\n+\treturn make_unique<WindowLocalState>(Allocator::Get(context.client), *this);\n }\n \n unique_ptr<GlobalSinkState> PhysicalWindow::GetGlobalSinkState(ClientContext &context) const {\n-\treturn make_unique<WindowGlobalState>(*this, context);\n+\treturn make_unique<WindowGlobalState>(Allocator::Get(context), *this, context);\n }\n \n //===--------------------------------------------------------------------===//\n@@ -1378,7 +1387,7 @@ class WindowGlobalSourceState : public GlobalSourceState {\n \n unique_ptr<LocalSourceState> PhysicalWindow::GetLocalSourceState(ExecutionContext &context,\n                                                                  GlobalSourceState &gstate) const {\n-\treturn make_unique<WindowOperatorState>(*this, context);\n+\treturn make_unique<WindowOperatorState>(Allocator::Get(context.client), *this, context);\n }\n \n unique_ptr<GlobalSourceState> PhysicalWindow::GetGlobalSourceState(ClientContext &context) const {\n@@ -1399,7 +1408,7 @@ void PhysicalWindow::GetData(ExecutionContext &context, DataChunk &chunk, Global\n \t\t\t\t\tbreak;\n \t\t\t\t}\n \t\t\t}\n-\t\t\tGeneratePartition(state, gstate, hash_bin);\n+\t\t\tGeneratePartition(Allocator::Get(context.client), state, gstate, hash_bin);\n \t\t}\n \t\tScan(state, chunk);\n \t\tif (chunk.size() != 0) {\ndiff --git a/src/execution/operator/filter/physical_filter.cpp b/src/execution/operator/filter/physical_filter.cpp\nindex 62d39c2ec022..854745cc6095 100644\n--- a/src/execution/operator/filter/physical_filter.cpp\n+++ b/src/execution/operator/filter/physical_filter.cpp\n@@ -22,7 +22,8 @@ PhysicalFilter::PhysicalFilter(vector<LogicalType> types, vector<unique_ptr<Expr\n \n class FilterState : public OperatorState {\n public:\n-\texplicit FilterState(Expression &expr) : executor(expr), sel(STANDARD_VECTOR_SIZE) {\n+\texplicit FilterState(ExecutionContext &context, Expression &expr)\n+\t    : executor(Allocator::Get(context.client), expr), sel(STANDARD_VECTOR_SIZE) {\n \t}\n \n \tExpressionExecutor executor;\n@@ -34,8 +35,8 @@ class FilterState : public OperatorState {\n \t}\n };\n \n-unique_ptr<OperatorState> PhysicalFilter::GetOperatorState(ClientContext &context) const {\n-\treturn make_unique<FilterState>(*expression);\n+unique_ptr<OperatorState> PhysicalFilter::GetOperatorState(ExecutionContext &context) const {\n+\treturn make_unique<FilterState>(context, *expression);\n }\n \n OperatorResultType PhysicalFilter::Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\ndiff --git a/src/execution/operator/helper/physical_batch_collector.cpp b/src/execution/operator/helper/physical_batch_collector.cpp\nindex 9a8044207802..f0a9daa9c3e0 100644\n--- a/src/execution/operator/helper/physical_batch_collector.cpp\n+++ b/src/execution/operator/helper/physical_batch_collector.cpp\n@@ -13,6 +13,9 @@ PhysicalBatchCollector::PhysicalBatchCollector(PreparedStatementData &data) : Ph\n //===--------------------------------------------------------------------===//\n class BatchCollectorGlobalState : public GlobalSinkState {\n public:\n+\texplicit BatchCollectorGlobalState(Allocator &allocator) : data(allocator) {\n+\t}\n+\n \tmutex glock;\n \tBatchedChunkCollection data;\n \tunique_ptr<MaterializedQueryResult> result;\n@@ -20,6 +23,9 @@ class BatchCollectorGlobalState : public GlobalSinkState {\n \n class BatchCollectorLocalState : public LocalSinkState {\n public:\n+\texplicit BatchCollectorLocalState(Allocator &allocator) : data(allocator) {\n+\t}\n+\n \tBatchedChunkCollection data;\n };\n \n@@ -45,7 +51,7 @@ SinkFinalizeType PhysicalBatchCollector::Finalize(Pipeline &pipeline, Event &eve\n \tauto result =\n \t    make_unique<MaterializedQueryResult>(statement_type, properties, types, names, context.shared_from_this());\n \tDataChunk output;\n-\toutput.Initialize(types);\n+\toutput.Initialize(BufferAllocator::Get(context), types);\n \n \tBatchedChunkScanState state;\n \tgstate.data.InitializeScan(state);\n@@ -63,11 +69,11 @@ SinkFinalizeType PhysicalBatchCollector::Finalize(Pipeline &pipeline, Event &eve\n }\n \n unique_ptr<LocalSinkState> PhysicalBatchCollector::GetLocalSinkState(ExecutionContext &context) const {\n-\treturn make_unique<BatchCollectorLocalState>();\n+\treturn make_unique<BatchCollectorLocalState>(Allocator::DefaultAllocator());\n }\n \n unique_ptr<GlobalSinkState> PhysicalBatchCollector::GetGlobalSinkState(ClientContext &context) const {\n-\treturn make_unique<BatchCollectorGlobalState>();\n+\treturn make_unique<BatchCollectorGlobalState>(Allocator::DefaultAllocator());\n }\n \n unique_ptr<QueryResult> PhysicalBatchCollector::GetResult(GlobalSinkState &state) {\ndiff --git a/src/execution/operator/helper/physical_limit.cpp b/src/execution/operator/helper/physical_limit.cpp\nindex c82548cd36f5..22aed2ac757f 100644\n--- a/src/execution/operator/helper/physical_limit.cpp\n+++ b/src/execution/operator/helper/physical_limit.cpp\n@@ -21,7 +21,7 @@ PhysicalLimit::PhysicalLimit(vector<LogicalType> types, idx_t limit, idx_t offse\n //===--------------------------------------------------------------------===//\n class LimitGlobalState : public GlobalSinkState {\n public:\n-\texplicit LimitGlobalState(const PhysicalLimit &op) {\n+\texplicit LimitGlobalState(Allocator &allocator, const PhysicalLimit &op) : data(allocator) {\n \t\tlimit = 0;\n \t\toffset = 0;\n \t}\n@@ -34,7 +34,7 @@ class LimitGlobalState : public GlobalSinkState {\n \n class LimitLocalState : public LocalSinkState {\n public:\n-\texplicit LimitLocalState(const PhysicalLimit &op) : current_offset(0) {\n+\texplicit LimitLocalState(Allocator &allocator, const PhysicalLimit &op) : current_offset(0), data(allocator) {\n \t\tthis->limit = op.limit_expression ? DConstants::INVALID_INDEX : op.limit_value;\n \t\tthis->offset = op.offset_expression ? DConstants::INVALID_INDEX : op.offset_value;\n \t}\n@@ -46,15 +46,16 @@ class LimitLocalState : public LocalSinkState {\n };\n \n unique_ptr<GlobalSinkState> PhysicalLimit::GetGlobalSinkState(ClientContext &context) const {\n-\treturn make_unique<LimitGlobalState>(*this);\n+\treturn make_unique<LimitGlobalState>(Allocator::Get(context), *this);\n }\n \n unique_ptr<LocalSinkState> PhysicalLimit::GetLocalSinkState(ExecutionContext &context) const {\n-\treturn make_unique<LimitLocalState>(*this);\n+\treturn make_unique<LimitLocalState>(Allocator::Get(context.client), *this);\n }\n \n-bool PhysicalLimit::ComputeOffset(DataChunk &input, idx_t &limit, idx_t &offset, idx_t current_offset,\n-                                  idx_t &max_element, Expression *limit_expression, Expression *offset_expression) {\n+bool PhysicalLimit::ComputeOffset(ExecutionContext &context, DataChunk &input, idx_t &limit, idx_t &offset,\n+                                  idx_t current_offset, idx_t &max_element, Expression *limit_expression,\n+                                  Expression *offset_expression) {\n \tif (limit != DConstants::INVALID_INDEX && offset != DConstants::INVALID_INDEX) {\n \t\tmax_element = limit + offset;\n \t\tif ((limit == 0 || current_offset >= max_element) && !(limit_expression || offset_expression)) {\n@@ -65,7 +66,7 @@ bool PhysicalLimit::ComputeOffset(DataChunk &input, idx_t &limit, idx_t &offset,\n \t// get the next chunk from the child\n \tif (limit == DConstants::INVALID_INDEX) {\n \t\tlimit = 1ULL << 62ULL;\n-\t\tValue val = GetDelimiter(input, limit_expression);\n+\t\tValue val = GetDelimiter(context, input, limit_expression);\n \t\tif (!val.IsNull()) {\n \t\t\tlimit = val.GetValue<idx_t>();\n \t\t}\n@@ -75,7 +76,7 @@ bool PhysicalLimit::ComputeOffset(DataChunk &input, idx_t &limit, idx_t &offset,\n \t}\n \tif (offset == DConstants::INVALID_INDEX) {\n \t\toffset = 0;\n-\t\tValue val = GetDelimiter(input, offset_expression);\n+\t\tValue val = GetDelimiter(context, input, offset_expression);\n \t\tif (!val.IsNull()) {\n \t\t\toffset = val.GetValue<idx_t>();\n \t\t}\n@@ -99,7 +100,7 @@ SinkResultType PhysicalLimit::Sink(ExecutionContext &context, GlobalSinkState &g\n \tauto &offset = state.offset;\n \n \tidx_t max_element;\n-\tif (!ComputeOffset(input, limit, offset, state.current_offset, max_element, limit_expression.get(),\n+\tif (!ComputeOffset(context, input, limit, offset, state.current_offset, max_element, limit_expression.get(),\n \t                   offset_expression.get())) {\n \t\treturn SinkResultType::FINISHED;\n \t}\n@@ -198,11 +199,12 @@ bool PhysicalLimit::HandleOffset(DataChunk &input, idx_t &current_offset, idx_t\n \treturn true;\n }\n \n-Value PhysicalLimit::GetDelimiter(DataChunk &input, Expression *expr) {\n+Value PhysicalLimit::GetDelimiter(ExecutionContext &context, DataChunk &input, Expression *expr) {\n \tDataChunk limit_chunk;\n \tvector<LogicalType> types {expr->return_type};\n-\tlimit_chunk.Initialize(types);\n-\tExpressionExecutor limit_executor(expr);\n+\tauto &allocator = Allocator::Get(context.client);\n+\tlimit_chunk.Initialize(allocator, types);\n+\tExpressionExecutor limit_executor(allocator, expr);\n \tauto input_size = input.size();\n \tinput.SetCardinality(1);\n \tlimit_executor.Execute(input, limit_chunk);\ndiff --git a/src/execution/operator/helper/physical_limit_percent.cpp b/src/execution/operator/helper/physical_limit_percent.cpp\nindex 36e0229ce04f..783aa251ef2e 100644\n--- a/src/execution/operator/helper/physical_limit_percent.cpp\n+++ b/src/execution/operator/helper/physical_limit_percent.cpp\n@@ -13,7 +13,8 @@ namespace duckdb {\n //===--------------------------------------------------------------------===//\n class LimitPercentGlobalState : public GlobalSinkState {\n public:\n-\texplicit LimitPercentGlobalState(const PhysicalLimitPercent &op) : current_offset(0) {\n+\texplicit LimitPercentGlobalState(Allocator &allocator, const PhysicalLimitPercent &op)\n+\t    : current_offset(0), data(allocator) {\n \t\tif (!op.limit_expression) {\n \t\t\tthis->limit_percent = op.limit_percent;\n \t\t\tis_limit_percent_delimited = true;\n@@ -39,7 +40,7 @@ class LimitPercentGlobalState : public GlobalSinkState {\n };\n \n unique_ptr<GlobalSinkState> PhysicalLimitPercent::GetGlobalSinkState(ClientContext &context) const {\n-\treturn make_unique<LimitPercentGlobalState>(*this);\n+\treturn make_unique<LimitPercentGlobalState>(Allocator::Get(context), *this);\n }\n \n SinkResultType PhysicalLimitPercent::Sink(ExecutionContext &context, GlobalSinkState &gstate, LocalSinkState &lstate,\n@@ -51,7 +52,7 @@ SinkResultType PhysicalLimitPercent::Sink(ExecutionContext &context, GlobalSinkS\n \n \t// get the next chunk from the child\n \tif (!state.is_limit_percent_delimited) {\n-\t\tValue val = PhysicalLimit::GetDelimiter(input, limit_expression.get());\n+\t\tValue val = PhysicalLimit::GetDelimiter(context, input, limit_expression.get());\n \t\tif (!val.IsNull()) {\n \t\t\tlimit_percent = val.GetValue<double>();\n \t\t}\n@@ -61,7 +62,7 @@ SinkResultType PhysicalLimitPercent::Sink(ExecutionContext &context, GlobalSinkS\n \t\tstate.is_limit_percent_delimited = true;\n \t}\n \tif (!state.is_offset_delimited) {\n-\t\tValue val = PhysicalLimit::GetDelimiter(input, offset_expression.get());\n+\t\tValue val = PhysicalLimit::GetDelimiter(context, input, offset_expression.get());\n \t\tif (!val.IsNull()) {\n \t\t\toffset = val.GetValue<idx_t>();\n \t\t}\ndiff --git a/src/execution/operator/helper/physical_reservoir_sample.cpp b/src/execution/operator/helper/physical_reservoir_sample.cpp\nindex 11cf894b261d..fbe35a8e8cd6 100644\n--- a/src/execution/operator/helper/physical_reservoir_sample.cpp\n+++ b/src/execution/operator/helper/physical_reservoir_sample.cpp\n@@ -8,19 +8,19 @@ namespace duckdb {\n //===--------------------------------------------------------------------===//\n class SampleGlobalSinkState : public GlobalSinkState {\n public:\n-\texplicit SampleGlobalSinkState(SampleOptions &options) {\n+\texplicit SampleGlobalSinkState(Allocator &allocator, SampleOptions &options) {\n \t\tif (options.is_percentage) {\n \t\t\tauto percentage = options.sample_size.GetValue<double>();\n \t\t\tif (percentage == 0) {\n \t\t\t\treturn;\n \t\t\t}\n-\t\t\tsample = make_unique<ReservoirSamplePercentage>(percentage, options.seed);\n+\t\t\tsample = make_unique<ReservoirSamplePercentage>(allocator, percentage, options.seed);\n \t\t} else {\n \t\t\tauto size = options.sample_size.GetValue<int64_t>();\n \t\t\tif (size == 0) {\n \t\t\t\treturn;\n \t\t\t}\n-\t\t\tsample = make_unique<ReservoirSample>(size, options.seed);\n+\t\t\tsample = make_unique<ReservoirSample>(allocator, size, options.seed);\n \t\t}\n \t}\n \n@@ -31,7 +31,7 @@ class SampleGlobalSinkState : public GlobalSinkState {\n };\n \n unique_ptr<GlobalSinkState> PhysicalReservoirSample::GetGlobalSinkState(ClientContext &context) const {\n-\treturn make_unique<SampleGlobalSinkState>(*options);\n+\treturn make_unique<SampleGlobalSinkState>(Allocator::Get(context), *options);\n }\n \n SinkResultType PhysicalReservoirSample::Sink(ExecutionContext &context, GlobalSinkState &state, LocalSinkState &lstate,\ndiff --git a/src/execution/operator/helper/physical_streaming_limit.cpp b/src/execution/operator/helper/physical_streaming_limit.cpp\nindex 13c8931e6f18..88ca3bbba740 100644\n--- a/src/execution/operator/helper/physical_streaming_limit.cpp\n+++ b/src/execution/operator/helper/physical_streaming_limit.cpp\n@@ -34,7 +34,7 @@ class StreamingLimitGlobalState : public GlobalOperatorState {\n \tstd::atomic<idx_t> current_offset;\n };\n \n-unique_ptr<OperatorState> PhysicalStreamingLimit::GetOperatorState(ClientContext &context) const {\n+unique_ptr<OperatorState> PhysicalStreamingLimit::GetOperatorState(ExecutionContext &context) const {\n \treturn make_unique<StreamingLimitOperatorState>(*this);\n }\n \n@@ -50,8 +50,8 @@ OperatorResultType PhysicalStreamingLimit::Execute(ExecutionContext &context, Da\n \tauto &offset = state.offset;\n \tidx_t current_offset = gstate.current_offset.fetch_add(input.size());\n \tidx_t max_element;\n-\tif (!PhysicalLimit::ComputeOffset(input, limit, offset, current_offset, max_element, limit_expression.get(),\n-\t                                  offset_expression.get())) {\n+\tif (!PhysicalLimit::ComputeOffset(context, input, limit, offset, current_offset, max_element,\n+\t                                  limit_expression.get(), offset_expression.get())) {\n \t\treturn OperatorResultType::FINISHED;\n \t}\n \tif (PhysicalLimit::HandleOffset(input, current_offset, offset, limit)) {\ndiff --git a/src/execution/operator/helper/physical_streaming_sample.cpp b/src/execution/operator/helper/physical_streaming_sample.cpp\nindex d251d5be4070..a8dc7f21acd9 100644\n--- a/src/execution/operator/helper/physical_streaming_sample.cpp\n+++ b/src/execution/operator/helper/physical_streaming_sample.cpp\n@@ -48,7 +48,7 @@ void PhysicalStreamingSample::BernoulliSample(DataChunk &input, DataChunk &resul\n \t}\n }\n \n-unique_ptr<OperatorState> PhysicalStreamingSample::GetOperatorState(ClientContext &context) const {\n+unique_ptr<OperatorState> PhysicalStreamingSample::GetOperatorState(ExecutionContext &context) const {\n \treturn make_unique<StreamingSampleOperatorState>(seed);\n }\n \ndiff --git a/src/execution/operator/join/perfect_hash_join_executor.cpp b/src/execution/operator/join/perfect_hash_join_executor.cpp\nindex f1219e147b93..fa29a9900ba5 100644\n--- a/src/execution/operator/join/perfect_hash_join_executor.cpp\n+++ b/src/execution/operator/join/perfect_hash_join_executor.cpp\n@@ -127,6 +127,16 @@ bool PerfectHashJoinExecutor::TemplatedFillSelectionVectorBuild(Vector &source,\n //===--------------------------------------------------------------------===//\n class PerfectHashJoinState : public OperatorState {\n public:\n+\tPerfectHashJoinState(Allocator &allocator, const PhysicalHashJoin &join) : probe_executor(allocator) {\n+\t\tjoin_keys.Initialize(allocator, join.condition_types);\n+\t\tfor (auto &cond : join.conditions) {\n+\t\t\tprobe_executor.AddExpression(*cond.left);\n+\t\t}\n+\t\tbuild_sel_vec.Initialize(STANDARD_VECTOR_SIZE);\n+\t\tprobe_sel_vec.Initialize(STANDARD_VECTOR_SIZE);\n+\t\tseq_sel_vec.Initialize(STANDARD_VECTOR_SIZE);\n+\t}\n+\n \tDataChunk join_keys;\n \tExpressionExecutor probe_executor;\n \tSelectionVector build_sel_vec;\n@@ -134,15 +144,8 @@ class PerfectHashJoinState : public OperatorState {\n \tSelectionVector seq_sel_vec;\n };\n \n-unique_ptr<OperatorState> PerfectHashJoinExecutor::GetOperatorState(ClientContext &context) {\n-\tauto state = make_unique<PerfectHashJoinState>();\n-\tstate->join_keys.Initialize(join.condition_types);\n-\tfor (auto &cond : join.conditions) {\n-\t\tstate->probe_executor.AddExpression(*cond.left);\n-\t}\n-\tstate->build_sel_vec.Initialize(STANDARD_VECTOR_SIZE);\n-\tstate->probe_sel_vec.Initialize(STANDARD_VECTOR_SIZE);\n-\tstate->seq_sel_vec.Initialize(STANDARD_VECTOR_SIZE);\n+unique_ptr<OperatorState> PerfectHashJoinExecutor::GetOperatorState(ExecutionContext &context) {\n+\tauto state = make_unique<PerfectHashJoinState>(Allocator::Get(context.client), join);\n \treturn move(state);\n }\n \ndiff --git a/src/execution/operator/join/physical_blockwise_nl_join.cpp b/src/execution/operator/join/physical_blockwise_nl_join.cpp\nindex 998e553b1168..d0fa2ff22a80 100644\n--- a/src/execution/operator/join/physical_blockwise_nl_join.cpp\n+++ b/src/execution/operator/join/physical_blockwise_nl_join.cpp\n@@ -29,6 +29,9 @@ class BlockwiseNLJoinLocalState : public LocalSinkState {\n \n class BlockwiseNLJoinGlobalState : public GlobalSinkState {\n public:\n+\texplicit BlockwiseNLJoinGlobalState(Allocator &allocator) : right_chunks(allocator) {\n+\t}\n+\n \tmutex lock;\n \tChunkCollection right_chunks;\n \t//! Whether or not a tuple on the RHS has found a match, only used for FULL OUTER joins\n@@ -36,7 +39,7 @@ class BlockwiseNLJoinGlobalState : public GlobalSinkState {\n };\n \n unique_ptr<GlobalSinkState> PhysicalBlockwiseNLJoin::GetGlobalSinkState(ClientContext &context) const {\n-\treturn make_unique<BlockwiseNLJoinGlobalState>();\n+\treturn make_unique<BlockwiseNLJoinGlobalState>(Allocator::Get(context));\n }\n \n unique_ptr<LocalSinkState> PhysicalBlockwiseNLJoin::GetLocalSinkState(ExecutionContext &context) const {\n@@ -72,8 +75,8 @@ SinkFinalizeType PhysicalBlockwiseNLJoin::Finalize(Pipeline &pipeline, Event &ev\n //===--------------------------------------------------------------------===//\n class BlockwiseNLJoinState : public OperatorState {\n public:\n-\texplicit BlockwiseNLJoinState(const PhysicalBlockwiseNLJoin &op)\n-\t    : left_position(0), right_position(0), executor(*op.condition) {\n+\texplicit BlockwiseNLJoinState(ExecutionContext &context, const PhysicalBlockwiseNLJoin &op)\n+\t    : left_position(0), right_position(0), executor(Allocator::Get(context.client), *op.condition) {\n \t\tif (IsLeftOuterJoin(op.join_type)) {\n \t\t\tleft_found_match = unique_ptr<bool[]>(new bool[STANDARD_VECTOR_SIZE]);\n \t\t\tmemset(left_found_match.get(), 0, sizeof(bool) * STANDARD_VECTOR_SIZE);\n@@ -87,8 +90,8 @@ class BlockwiseNLJoinState : public OperatorState {\n \tExpressionExecutor executor;\n };\n \n-unique_ptr<OperatorState> PhysicalBlockwiseNLJoin::GetOperatorState(ClientContext &context) const {\n-\treturn make_unique<BlockwiseNLJoinState>(*this);\n+unique_ptr<OperatorState> PhysicalBlockwiseNLJoin::GetOperatorState(ExecutionContext &context) const {\n+\treturn make_unique<BlockwiseNLJoinState>(context, *this);\n }\n \n OperatorResultType PhysicalBlockwiseNLJoin::Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\ndiff --git a/src/execution/operator/join/physical_cross_product.cpp b/src/execution/operator/join/physical_cross_product.cpp\nindex 5442aac3cc06..fe33481202ec 100644\n--- a/src/execution/operator/join/physical_cross_product.cpp\n+++ b/src/execution/operator/join/physical_cross_product.cpp\n@@ -17,7 +17,7 @@ PhysicalCrossProduct::PhysicalCrossProduct(vector<LogicalType> types, unique_ptr\n //===--------------------------------------------------------------------===//\n class CrossProductGlobalState : public GlobalSinkState {\n public:\n-\tCrossProductGlobalState() {\n+\texplicit CrossProductGlobalState(ClientContext &context) : rhs_materialized(BufferAllocator::Get(context)) {\n \t}\n \n \tChunkCollection rhs_materialized;\n@@ -25,7 +25,7 @@ class CrossProductGlobalState : public GlobalSinkState {\n };\n \n unique_ptr<GlobalSinkState> PhysicalCrossProduct::GetGlobalSinkState(ClientContext &context) const {\n-\treturn make_unique<CrossProductGlobalState>();\n+\treturn make_unique<CrossProductGlobalState>(context);\n }\n \n SinkResultType PhysicalCrossProduct::Sink(ExecutionContext &context, GlobalSinkState &state, LocalSinkState &lstate_p,\n@@ -47,7 +47,7 @@ class CrossProductOperatorState : public OperatorState {\n \tidx_t right_position;\n };\n \n-unique_ptr<OperatorState> PhysicalCrossProduct::GetOperatorState(ClientContext &context) const {\n+unique_ptr<OperatorState> PhysicalCrossProduct::GetOperatorState(ExecutionContext &context) const {\n \treturn make_unique<CrossProductOperatorState>();\n }\n \ndiff --git a/src/execution/operator/join/physical_delim_join.cpp b/src/execution/operator/join/physical_delim_join.cpp\nindex 9e0616175f47..4617f7776f40 100644\n--- a/src/execution/operator/join/physical_delim_join.cpp\n+++ b/src/execution/operator/join/physical_delim_join.cpp\n@@ -40,7 +40,7 @@ vector<PhysicalOperator *> PhysicalDelimJoin::GetChildren() const {\n //===--------------------------------------------------------------------===//\n class DelimJoinGlobalState : public GlobalSinkState {\n public:\n-\texplicit DelimJoinGlobalState(const PhysicalDelimJoin *delim_join) {\n+\texplicit DelimJoinGlobalState(Allocator &allocator, const PhysicalDelimJoin *delim_join) : lhs_data(allocator) {\n \t\tD_ASSERT(delim_join->delim_scans.size() > 0);\n \t\t// set up the delim join chunk to scan in the original join\n \t\tauto &cached_chunk_scan = (PhysicalChunkScan &)*delim_join->join->children[0];\n@@ -58,6 +58,9 @@ class DelimJoinGlobalState : public GlobalSinkState {\n \n class DelimJoinLocalState : public LocalSinkState {\n public:\n+\texplicit DelimJoinLocalState(Allocator &allocator) : lhs_data(allocator) {\n+\t}\n+\n \tunique_ptr<LocalSinkState> distinct_state;\n \tChunkCollection lhs_data;\n \n@@ -67,7 +70,7 @@ class DelimJoinLocalState : public LocalSinkState {\n };\n \n unique_ptr<GlobalSinkState> PhysicalDelimJoin::GetGlobalSinkState(ClientContext &context) const {\n-\tauto state = make_unique<DelimJoinGlobalState>(this);\n+\tauto state = make_unique<DelimJoinGlobalState>(BufferAllocator::Get(context), this);\n \tdistinct->sink_state = distinct->GetGlobalSinkState(context);\n \tif (delim_scans.size() > 1) {\n \t\tPhysicalHashAggregate::SetMultiScan(*distinct->sink_state);\n@@ -76,7 +79,7 @@ unique_ptr<GlobalSinkState> PhysicalDelimJoin::GetGlobalSinkState(ClientContext\n }\n \n unique_ptr<LocalSinkState> PhysicalDelimJoin::GetLocalSinkState(ExecutionContext &context) const {\n-\tauto state = make_unique<DelimJoinLocalState>();\n+\tauto state = make_unique<DelimJoinLocalState>(Allocator::Get(context.client));\n \tstate->distinct_state = distinct->GetLocalSinkState(context);\n \treturn move(state);\n }\ndiff --git a/src/execution/operator/join/physical_hash_join.cpp b/src/execution/operator/join/physical_hash_join.cpp\nindex 599b797a261b..3eeda5893c2b 100644\n--- a/src/execution/operator/join/physical_hash_join.cpp\n+++ b/src/execution/operator/join/physical_hash_join.cpp\n@@ -45,6 +45,16 @@ PhysicalHashJoin::PhysicalHashJoin(LogicalOperator &op, unique_ptr<PhysicalOpera\n //===--------------------------------------------------------------------===//\n class HashJoinLocalState : public LocalSinkState {\n public:\n+\tHashJoinLocalState(Allocator &allocator, const PhysicalHashJoin &hj) : build_executor(allocator) {\n+\t\tif (!hj.right_projection_map.empty()) {\n+\t\t\tbuild_chunk.Initialize(allocator, hj.build_types);\n+\t\t}\n+\t\tfor (auto &cond : hj.conditions) {\n+\t\t\tbuild_executor.AddExpression(*cond.right);\n+\t\t}\n+\t\tjoin_keys.Initialize(allocator, hj.condition_types);\n+\t}\n+\n \tDataChunk build_chunk;\n \tDataChunk join_keys;\n \tExpressionExecutor build_executor;\n@@ -100,11 +110,12 @@ unique_ptr<GlobalSinkState> PhysicalHashJoin::GetGlobalSinkState(ClientContext &\n \t\t\tpayload_types.push_back(aggr->return_type);\n \t\t\tinfo.correlated_aggregates.push_back(move(aggr));\n \n+\t\t\tauto &allocator = Allocator::Get(context);\n \t\t\tinfo.correlated_counts = make_unique<GroupedAggregateHashTable>(\n-\t\t\t    BufferManager::GetBufferManager(context), delim_types, payload_types, correlated_aggregates);\n+\t\t\t    allocator, BufferManager::GetBufferManager(context), delim_types, payload_types, correlated_aggregates);\n \t\t\tinfo.correlated_types = delim_types;\n-\t\t\tinfo.group_chunk.Initialize(delim_types);\n-\t\t\tinfo.result_chunk.Initialize(payload_types);\n+\t\t\tinfo.group_chunk.Initialize(allocator, delim_types);\n+\t\t\tinfo.result_chunk.Initialize(allocator, payload_types);\n \t\t}\n \t}\n \t// for perfect hash join\n@@ -114,14 +125,8 @@ unique_ptr<GlobalSinkState> PhysicalHashJoin::GetGlobalSinkState(ClientContext &\n }\n \n unique_ptr<LocalSinkState> PhysicalHashJoin::GetLocalSinkState(ExecutionContext &context) const {\n-\tauto state = make_unique<HashJoinLocalState>();\n-\tif (!right_projection_map.empty()) {\n-\t\tstate->build_chunk.Initialize(build_types);\n-\t}\n-\tfor (auto &cond : conditions) {\n-\t\tstate->build_executor.AddExpression(*cond.right);\n-\t}\n-\tstate->join_keys.Initialize(condition_types);\n+\tauto &allocator = Allocator::Get(context.client);\n+\tauto state = make_unique<HashJoinLocalState>(allocator, *this);\n \treturn move(state);\n }\n \n@@ -190,6 +195,9 @@ SinkFinalizeType PhysicalHashJoin::Finalize(Pipeline &pipeline, Event &event, Cl\n //===--------------------------------------------------------------------===//\n class PhysicalHashJoinState : public OperatorState {\n public:\n+\texplicit PhysicalHashJoinState(Allocator &allocator) : probe_executor(allocator) {\n+\t}\n+\n \tDataChunk join_keys;\n \tExpressionExecutor probe_executor;\n \tunique_ptr<JoinHashTable::ScanStructure> scan_structure;\n@@ -201,13 +209,14 @@ class PhysicalHashJoinState : public OperatorState {\n \t}\n };\n \n-unique_ptr<OperatorState> PhysicalHashJoin::GetOperatorState(ClientContext &context) const {\n-\tauto state = make_unique<PhysicalHashJoinState>();\n+unique_ptr<OperatorState> PhysicalHashJoin::GetOperatorState(ExecutionContext &context) const {\n+\tauto &allocator = Allocator::Get(context.client);\n \tauto &sink = (HashJoinGlobalState &)*sink_state;\n+\tauto state = make_unique<PhysicalHashJoinState>(allocator);\n \tif (sink.perfect_join_executor) {\n \t\tstate->perfect_hash_join_state = sink.perfect_join_executor->GetOperatorState(context);\n \t} else {\n-\t\tstate->join_keys.Initialize(condition_types);\n+\t\tstate->join_keys.Initialize(allocator, condition_types);\n \t\tfor (auto &cond : conditions) {\n \t\t\tstate->probe_executor.AddExpression(*cond.left);\n \t\t}\ndiff --git a/src/execution/operator/join/physical_iejoin.cpp b/src/execution/operator/join/physical_iejoin.cpp\nindex 3e01dc26303d..bbaa8e0e9762 100644\n--- a/src/execution/operator/join/physical_iejoin.cpp\n+++ b/src/execution/operator/join/physical_iejoin.cpp\n@@ -69,7 +69,8 @@ class IEJoinLocalState : public LocalSinkState {\n public:\n \tusing LocalSortedTable = PhysicalRangeJoin::LocalSortedTable;\n \n-\tIEJoinLocalState(const PhysicalRangeJoin &op, const idx_t child) : table(op, child) {\n+\tIEJoinLocalState(Allocator &allocator, const PhysicalRangeJoin &op, const idx_t child)\n+\t    : table(allocator, op, child) {\n \t}\n \n \t//! The local sort state\n@@ -129,7 +130,7 @@ unique_ptr<LocalSinkState> PhysicalIEJoin::GetLocalSinkState(ExecutionContext &c\n \t\tconst auto &ie_sink = (IEJoinGlobalState &)*sink_state;\n \t\tsink_child = ie_sink.child;\n \t}\n-\treturn make_unique<IEJoinLocalState>(*this, sink_child);\n+\treturn make_unique<IEJoinLocalState>(Allocator::Get(context.client), *this, sink_child);\n }\n \n SinkResultType PhysicalIEJoin::Sink(ExecutionContext &context, GlobalSinkState &gstate_p, LocalSinkState &lstate_p,\n@@ -315,7 +316,7 @@ struct IEJoinUnion {\n \t\tPayloadScanner scanner(blocks, gstate, false);\n \n \t\tDataChunk payload;\n-\t\tpayload.Initialize(gstate.payload_layout.GetTypes());\n+\t\tpayload.Initialize(Allocator::DefaultAllocator(), gstate.payload_layout.GetTypes());\n \t\tfor (;;) {\n \t\t\tscanner.Scan(payload);\n \t\t\tconst auto count = payload.size();\n@@ -382,7 +383,7 @@ idx_t IEJoinUnion::AppendKey(SortedTable &table, ExpressionExecutor &executor, S\n \tauto table_idx = block_idx * gstate.block_capacity;\n \n \tDataChunk scanned;\n-\tscanned.Initialize(scanner.GetPayloadTypes());\n+\tscanned.Initialize(Allocator::DefaultAllocator(), scanner.GetPayloadTypes());\n \n \t// Writing\n \tauto types = local_sort_state.sort_layout->logical_types;\n@@ -394,7 +395,7 @@ idx_t IEJoinUnion::AppendKey(SortedTable &table, ExpressionExecutor &executor, S\n \n \tDataChunk keys;\n \tDataChunk payload;\n-\tkeys.Initialize(types);\n+\tkeys.Initialize(Allocator::DefaultAllocator(), types);\n \n \tidx_t inserted = 0;\n \tfor (auto rid = base; table_idx < valid;) {\n@@ -442,6 +443,7 @@ idx_t IEJoinUnion::AppendKey(SortedTable &table, ExpressionExecutor &executor, S\n IEJoinUnion::IEJoinUnion(ClientContext &context, const PhysicalIEJoin &op, SortedTable &t1, const idx_t b1,\n                          SortedTable &t2, const idx_t b2)\n     : n(0), i(0) {\n+\tauto &allocator = Allocator::Get(context);\n \t// input : query Q with 2 join predicates t1.X op1 t2.X' and t1.Y op2 t2.Y', tables T, T' of sizes m and n resp.\n \t// output: a list of tuple pairs (ti , tj)\n \t// Note that T/T' are already sorted on X/X' and contain the payload data\n@@ -487,13 +489,13 @@ IEJoinUnion::IEJoinUnion(ClientContext &context, const PhysicalIEJoin &op, Sorte\n \tl1 = make_unique<SortedTable>(context, orders, payload_layout);\n \n \t// LHS has positive rids\n-\tExpressionExecutor l_executor;\n+\tExpressionExecutor l_executor(allocator);\n \tl_executor.AddExpression(*order1.expression);\n \tl_executor.AddExpression(*order2.expression);\n \tAppendKey(t1, l_executor, *l1, 1, 1, b1);\n \n \t// RHS has negative rids\n-\tExpressionExecutor r_executor;\n+\tExpressionExecutor r_executor(allocator);\n \tr_executor.AddExpression(*op.rhs_orders[0][0].expression);\n \tr_executor.AddExpression(*op.rhs_orders[1][0].expression);\n \tAppendKey(t2, r_executor, *l1, -1, -1, b2);\n@@ -520,7 +522,7 @@ IEJoinUnion::IEJoinUnion(ClientContext &context, const PhysicalIEJoin &op, Sorte\n \tref = make_unique<BoundReferenceExpression>(order2.expression->return_type, 0);\n \torders.emplace_back(BoundOrderByNode(order2.type, order2.null_order, move(ref)));\n \n-\tExpressionExecutor executor;\n+\tExpressionExecutor executor(allocator);\n \texecutor.AddExpression(*orders[0].expression);\n \n \tl2 = make_unique<SortedTable>(context, orders, payload_layout);\n@@ -730,15 +732,16 @@ idx_t IEJoinUnion::JoinComplexBlocks(SelectionVector &lsel, SelectionVector &rse\n \n class IEJoinState : public OperatorState {\n public:\n-\texplicit IEJoinState(const PhysicalIEJoin &op) : local_left(op, 0) {};\n+\texplicit IEJoinState(Allocator &allocator, const PhysicalIEJoin &op) : local_left(allocator, op, 0) {};\n \n \tIEJoinLocalState local_left;\n };\n \n class IEJoinLocalSourceState : public LocalSourceState {\n public:\n-\texplicit IEJoinLocalSourceState(const PhysicalIEJoin &op)\n-\t    : op(op), true_sel(STANDARD_VECTOR_SIZE), left_matches(nullptr), right_matches(nullptr) {\n+\texplicit IEJoinLocalSourceState(Allocator &allocator, const PhysicalIEJoin &op)\n+\t    : op(op), true_sel(STANDARD_VECTOR_SIZE), left_executor(allocator), right_executor(allocator),\n+\t      left_matches(nullptr), right_matches(nullptr) {\n \n \t\tif (op.conditions.size() < 3) {\n \t\t\treturn;\n@@ -756,8 +759,8 @@ class IEJoinLocalSourceState : public LocalSourceState {\n \t\t\tright_executor.AddExpression(*cond.right);\n \t\t}\n \n-\t\tleft_keys.Initialize(left_types);\n-\t\tright_keys.Initialize(right_types);\n+\t\tleft_keys.Initialize(allocator, left_types);\n+\t\tright_keys.Initialize(allocator, right_types);\n \t}\n \n \tidx_t SelectOuterRows(bool *matches) {\n@@ -1027,7 +1030,7 @@ unique_ptr<GlobalSourceState> PhysicalIEJoin::GetGlobalSourceState(ClientContext\n \n unique_ptr<LocalSourceState> PhysicalIEJoin::GetLocalSourceState(ExecutionContext &context,\n                                                                  GlobalSourceState &gstate) const {\n-\treturn make_unique<IEJoinLocalSourceState>(*this);\n+\treturn make_unique<IEJoinLocalSourceState>(Allocator::Get(context.client), *this);\n }\n \n void PhysicalIEJoin::GetData(ExecutionContext &context, DataChunk &result, GlobalSourceState &gstate,\ndiff --git a/src/execution/operator/join/physical_index_join.cpp b/src/execution/operator/join/physical_index_join.cpp\nindex 5a7091477ec9..96a785775a02 100644\n--- a/src/execution/operator/join/physical_index_join.cpp\n+++ b/src/execution/operator/join/physical_index_join.cpp\n@@ -14,16 +14,16 @@ namespace duckdb {\n \n class IndexJoinOperatorState : public OperatorState {\n public:\n-\texplicit IndexJoinOperatorState(const PhysicalIndexJoin &op) {\n+\tIndexJoinOperatorState(Allocator &allocator, const PhysicalIndexJoin &op) : probe_executor(allocator) {\n \t\trhs_rows.resize(STANDARD_VECTOR_SIZE);\n \t\tresult_sizes.resize(STANDARD_VECTOR_SIZE);\n \n-\t\tjoin_keys.Initialize(op.condition_types);\n+\t\tjoin_keys.Initialize(allocator, op.condition_types);\n \t\tfor (auto &cond : op.conditions) {\n \t\t\tprobe_executor.AddExpression(*cond.left);\n \t\t}\n \t\tif (!op.fetch_types.empty()) {\n-\t\t\trhs_chunk.Initialize(op.fetch_types);\n+\t\t\trhs_chunk.Initialize(allocator, op.fetch_types);\n \t\t}\n \t\trhs_sel.Initialize(STANDARD_VECTOR_SIZE);\n \t}\n@@ -83,8 +83,8 @@ PhysicalIndexJoin::PhysicalIndexJoin(LogicalOperator &op, unique_ptr<PhysicalOpe\n \t}\n }\n \n-unique_ptr<OperatorState> PhysicalIndexJoin::GetOperatorState(ClientContext &context) const {\n-\treturn make_unique<IndexJoinOperatorState>(*this);\n+unique_ptr<OperatorState> PhysicalIndexJoin::GetOperatorState(ExecutionContext &context) const {\n+\treturn make_unique<IndexJoinOperatorState>(Allocator::Get(context.client), *this);\n }\n \n void PhysicalIndexJoin::Output(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\ndiff --git a/src/execution/operator/join/physical_nested_loop_join.cpp b/src/execution/operator/join/physical_nested_loop_join.cpp\nindex 0ed0b5f32ad6..b65a00579417 100644\n--- a/src/execution/operator/join/physical_nested_loop_join.cpp\n+++ b/src/execution/operator/join/physical_nested_loop_join.cpp\n@@ -110,13 +110,14 @@ void PhysicalJoin::ConstructMarkJoinResult(DataChunk &join_keys, DataChunk &left\n //===--------------------------------------------------------------------===//\n class NestedLoopJoinLocalState : public LocalSinkState {\n public:\n-\texplicit NestedLoopJoinLocalState(const vector<JoinCondition> &conditions) {\n+\texplicit NestedLoopJoinLocalState(Allocator &allocator, const vector<JoinCondition> &conditions)\n+\t    : rhs_executor(allocator) {\n \t\tvector<LogicalType> condition_types;\n \t\tfor (auto &cond : conditions) {\n \t\t\trhs_executor.AddExpression(*cond.right);\n \t\t\tcondition_types.push_back(cond.right->return_type);\n \t\t}\n-\t\tright_condition.Initialize(condition_types);\n+\t\tright_condition.Initialize(allocator, condition_types);\n \t}\n \n \t//! The chunk holding the right condition\n@@ -127,7 +128,8 @@ class NestedLoopJoinLocalState : public LocalSinkState {\n \n class NestedLoopJoinGlobalState : public GlobalSinkState {\n public:\n-\tNestedLoopJoinGlobalState() : has_null(false) {\n+\texplicit NestedLoopJoinGlobalState(Allocator &allocator)\n+\t    : right_data(allocator), right_chunks(allocator), has_null(false) {\n \t}\n \n \tmutex nj_lock;\n@@ -188,11 +190,11 @@ SinkFinalizeType PhysicalNestedLoopJoin::Finalize(Pipeline &pipeline, Event &eve\n }\n \n unique_ptr<GlobalSinkState> PhysicalNestedLoopJoin::GetGlobalSinkState(ClientContext &context) const {\n-\treturn make_unique<NestedLoopJoinGlobalState>();\n+\treturn make_unique<NestedLoopJoinGlobalState>(Allocator::Get(context));\n }\n \n unique_ptr<LocalSinkState> PhysicalNestedLoopJoin::GetLocalSinkState(ExecutionContext &context) const {\n-\treturn make_unique<NestedLoopJoinLocalState>(conditions);\n+\treturn make_unique<NestedLoopJoinLocalState>(Allocator::Get(context.client), conditions);\n }\n \n //===--------------------------------------------------------------------===//\n@@ -200,14 +202,16 @@ unique_ptr<LocalSinkState> PhysicalNestedLoopJoin::GetLocalSinkState(ExecutionCo\n //===--------------------------------------------------------------------===//\n class PhysicalNestedLoopJoinState : public OperatorState {\n public:\n-\tPhysicalNestedLoopJoinState(const PhysicalNestedLoopJoin &op, const vector<JoinCondition> &conditions)\n-\t    : fetch_next_left(true), fetch_next_right(false), right_chunk(0), left_tuple(0), right_tuple(0) {\n+\tPhysicalNestedLoopJoinState(Allocator &allocator, const PhysicalNestedLoopJoin &op,\n+\t                            const vector<JoinCondition> &conditions)\n+\t    : fetch_next_left(true), fetch_next_right(false), right_chunk(0), lhs_executor(allocator), left_tuple(0),\n+\t      right_tuple(0) {\n \t\tvector<LogicalType> condition_types;\n \t\tfor (auto &cond : conditions) {\n \t\t\tlhs_executor.AddExpression(*cond.left);\n \t\t\tcondition_types.push_back(cond.left->return_type);\n \t\t}\n-\t\tleft_condition.Initialize(condition_types);\n+\t\tleft_condition.Initialize(allocator, condition_types);\n \t\tif (IsLeftOuterJoin(op.join_type)) {\n \t\t\tleft_found_match = unique_ptr<bool[]>(new bool[STANDARD_VECTOR_SIZE]);\n \t\t\tmemset(left_found_match.get(), 0, sizeof(bool) * STANDARD_VECTOR_SIZE);\n@@ -232,8 +236,8 @@ class PhysicalNestedLoopJoinState : public OperatorState {\n \t}\n };\n \n-unique_ptr<OperatorState> PhysicalNestedLoopJoin::GetOperatorState(ClientContext &context) const {\n-\treturn make_unique<PhysicalNestedLoopJoinState>(*this, conditions);\n+unique_ptr<OperatorState> PhysicalNestedLoopJoin::GetOperatorState(ExecutionContext &context) const {\n+\treturn make_unique<PhysicalNestedLoopJoinState>(Allocator::Get(context.client), *this, conditions);\n }\n \n OperatorResultType PhysicalNestedLoopJoin::Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\ndiff --git a/src/execution/operator/join/physical_piecewise_merge_join.cpp b/src/execution/operator/join/physical_piecewise_merge_join.cpp\nindex 3baa2b1a9429..0ce82af03b81 100644\n--- a/src/execution/operator/join/physical_piecewise_merge_join.cpp\n+++ b/src/execution/operator/join/physical_piecewise_merge_join.cpp\n@@ -57,7 +57,8 @@ PhysicalPiecewiseMergeJoin::PhysicalPiecewiseMergeJoin(LogicalOperator &op, uniq\n //===--------------------------------------------------------------------===//\n class MergeJoinLocalState : public LocalSinkState {\n public:\n-\texplicit MergeJoinLocalState(const PhysicalRangeJoin &op, const idx_t child) : table(op, child) {\n+\texplicit MergeJoinLocalState(Allocator &allocator, const PhysicalRangeJoin &op, const idx_t child)\n+\t    : table(allocator, op, child) {\n \t}\n \n \t//! The local sort state\n@@ -103,7 +104,7 @@ unique_ptr<GlobalSinkState> PhysicalPiecewiseMergeJoin::GetGlobalSinkState(Clien\n \n unique_ptr<LocalSinkState> PhysicalPiecewiseMergeJoin::GetLocalSinkState(ExecutionContext &context) const {\n \t// We only sink the RHS\n-\treturn make_unique<MergeJoinLocalState>(*this, 1);\n+\treturn make_unique<MergeJoinLocalState>(Allocator::Get(context.client), *this, 1);\n }\n \n SinkResultType PhysicalPiecewiseMergeJoin::Sink(ExecutionContext &context, GlobalSinkState &gstate_p,\n@@ -157,10 +158,11 @@ class PiecewiseMergeJoinState : public OperatorState {\n public:\n \tusing LocalSortedTable = PhysicalRangeJoin::LocalSortedTable;\n \n-\texplicit PiecewiseMergeJoinState(const PhysicalPiecewiseMergeJoin &op, BufferManager &buffer_manager,\n-\t                                 bool force_external)\n-\t    : op(op), buffer_manager(buffer_manager), force_external(force_external), left_position(0), first_fetch(true),\n-\t      finished(true), right_position(0), right_chunk_index(0) {\n+\texplicit PiecewiseMergeJoinState(Allocator &allocator, const PhysicalPiecewiseMergeJoin &op,\n+\t                                 BufferManager &buffer_manager, bool force_external)\n+\t    : allocator(allocator), op(op), buffer_manager(buffer_manager), force_external(force_external),\n+\t      left_position(0), first_fetch(true), finished(true), right_position(0), right_chunk_index(0),\n+\t      rhs_executor(allocator) {\n \t\tvector<LogicalType> condition_types;\n \t\tfor (auto &order : op.lhs_orders) {\n \t\t\tcondition_types.push_back(order.expression->return_type);\n@@ -170,7 +172,7 @@ class PiecewiseMergeJoinState : public OperatorState {\n \t\t\tmemset(lhs_found_match.get(), 0, sizeof(bool) * STANDARD_VECTOR_SIZE);\n \t\t}\n \t\tlhs_layout.Initialize(op.children[0]->types);\n-\t\tlhs_payload.Initialize(op.children[0]->types);\n+\t\tlhs_payload.Initialize(allocator, op.children[0]->types);\n \n \t\tlhs_order.emplace_back(op.lhs_orders[0].Copy());\n \n@@ -181,9 +183,10 @@ class PiecewiseMergeJoinState : public OperatorState {\n \t\t\trhs_executor.AddExpression(*order.expression);\n \t\t\tcondition_types.push_back(order.expression->return_type);\n \t\t}\n-\t\trhs_keys.Initialize(condition_types);\n+\t\trhs_keys.Initialize(allocator, condition_types);\n \t}\n \n+\tAllocator &allocator;\n \tconst PhysicalPiecewiseMergeJoin &op;\n \tBufferManager &buffer_manager;\n \tbool force_external;\n@@ -216,7 +219,7 @@ class PiecewiseMergeJoinState : public OperatorState {\n \tvoid ResolveJoinKeys(DataChunk &input) {\n \t\t// sort by join key\n \t\tlhs_global_state = make_unique<GlobalSortState>(buffer_manager, lhs_order, lhs_layout);\n-\t\tlhs_local_table = make_unique<LocalSortedTable>(op, 0);\n+\t\tlhs_local_table = make_unique<LocalSortedTable>(allocator, op, 0);\n \t\tlhs_local_table->Sink(input, *lhs_global_state);\n \n \t\t// Set external (can be forced with the PRAGMA)\n@@ -248,10 +251,11 @@ class PiecewiseMergeJoinState : public OperatorState {\n \t}\n };\n \n-unique_ptr<OperatorState> PhysicalPiecewiseMergeJoin::GetOperatorState(ClientContext &context) const {\n-\tauto &buffer_manager = BufferManager::GetBufferManager(context);\n-\tauto &config = ClientConfig::GetConfig(context);\n-\treturn make_unique<PiecewiseMergeJoinState>(*this, buffer_manager, config.force_external);\n+unique_ptr<OperatorState> PhysicalPiecewiseMergeJoin::GetOperatorState(ExecutionContext &context) const {\n+\tauto &buffer_manager = BufferManager::GetBufferManager(context.client);\n+\tauto &config = ClientConfig::GetConfig(context.client);\n+\treturn make_unique<PiecewiseMergeJoinState>(Allocator::Get(context.client), *this, buffer_manager,\n+\t                                            config.force_external);\n }\n \n static inline idx_t SortedBlockNotNull(const idx_t base, const idx_t count, const idx_t not_null) {\n@@ -695,7 +699,7 @@ void PhysicalPiecewiseMergeJoin::GetData(ExecutionContext &context, DataChunk &r\n \t// ConstructFullOuterJoinResult(sink.table->found_match.get(), sink.right_chunks, chunk,\n \t// state.right_outer_position);\n \tDataChunk rhs_chunk;\n-\trhs_chunk.Initialize(sink.table->global_sort_state.payload_layout.GetTypes());\n+\trhs_chunk.Initialize(Allocator::Get(context.client), sink.table->global_sort_state.payload_layout.GetTypes());\n \tSelectionVector rsel(STANDARD_VECTOR_SIZE);\n \tfor (;;) {\n \t\t// Read the next sorted chunk\ndiff --git a/src/execution/operator/join/physical_range_join.cpp b/src/execution/operator/join/physical_range_join.cpp\nindex 0a75368159f4..ee4d2cfcdc6e 100644\n--- a/src/execution/operator/join/physical_range_join.cpp\n+++ b/src/execution/operator/join/physical_range_join.cpp\n@@ -15,8 +15,9 @@\n \n namespace duckdb {\n \n-PhysicalRangeJoin::LocalSortedTable::LocalSortedTable(const PhysicalRangeJoin &op, const idx_t child)\n-    : op(op), has_null(0), count(0) {\n+PhysicalRangeJoin::LocalSortedTable::LocalSortedTable(Allocator &allocator, const PhysicalRangeJoin &op,\n+                                                      const idx_t child)\n+    : op(op), executor(allocator), has_null(0), count(0) {\n \t// Initialize order clause expression executor and key DataChunk\n \tvector<LogicalType> types;\n \tfor (const auto &cond : op.conditions) {\n@@ -25,7 +26,7 @@ PhysicalRangeJoin::LocalSortedTable::LocalSortedTable(const PhysicalRangeJoin &o\n \n \t\ttypes.push_back(expr->return_type);\n \t}\n-\tkeys.Initialize(types);\n+\tkeys.Initialize(allocator, types);\n }\n \n void PhysicalRangeJoin::LocalSortedTable::Sink(DataChunk &input, GlobalSortState &global_sort_state) {\n@@ -306,7 +307,7 @@ void PhysicalRangeJoin::SliceSortedPayload(DataChunk &payload, GlobalSortState &\n \n \t// Unswizzle the offsets back to pointers (if needed)\n \tif (!sorted_data.layout.AllConstant() && state.external) {\n-\t\tRowOperations::UnswizzlePointers(sorted_data.layout, data_ptr, read_state.payload_heap_handle->Ptr(),\n+\t\tRowOperations::UnswizzlePointers(sorted_data.layout, data_ptr, read_state.payload_heap_handle.Ptr(),\n \t\t                                 addr_count);\n \t}\n \ndiff --git a/src/execution/operator/order/physical_order.cpp b/src/execution/operator/order/physical_order.cpp\nindex 0d763f03c8c7..5eba6ec5dac9 100644\n--- a/src/execution/operator/order/physical_order.cpp\n+++ b/src/execution/operator/order/physical_order.cpp\n@@ -30,7 +30,15 @@ class OrderGlobalState : public GlobalSinkState {\n \n class OrderLocalState : public LocalSinkState {\n public:\n-\tOrderLocalState() {\n+\tOrderLocalState(ExecutionContext &context, const vector<BoundOrderByNode> &orders)\n+\t    : executor(Allocator::Get(context.client)) {\n+\t\t// Initialize order clause expression executor and DataChunk\n+\t\tvector<LogicalType> types;\n+\t\tfor (auto &order : orders) {\n+\t\t\ttypes.push_back(order.expression->return_type);\n+\t\t\texecutor.AddExpression(*order.expression);\n+\t\t}\n+\t\tsort.Initialize(Allocator::Get(context.client), types);\n \t}\n \n public:\n@@ -58,14 +66,7 @@ unique_ptr<GlobalSinkState> PhysicalOrder::GetGlobalSinkState(ClientContext &con\n }\n \n unique_ptr<LocalSinkState> PhysicalOrder::GetLocalSinkState(ExecutionContext &context) const {\n-\tauto result = make_unique<OrderLocalState>();\n-\t// Initialize order clause expression executor and DataChunk\n-\tvector<LogicalType> types;\n-\tfor (auto &order : orders) {\n-\t\ttypes.push_back(order.expression->return_type);\n-\t\tresult->executor.AddExpression(*order.expression);\n-\t}\n-\tresult->sort.Initialize(types);\n+\tauto result = make_unique<OrderLocalState>(context, orders);\n \treturn move(result);\n }\n \ndiff --git a/src/execution/operator/order/physical_top_n.cpp b/src/execution/operator/order/physical_top_n.cpp\nindex 4be60a3dc692..88243f074137 100644\n--- a/src/execution/operator/order/physical_top_n.cpp\n+++ b/src/execution/operator/order/physical_top_n.cpp\n@@ -54,8 +54,13 @@ class TopNHeap {\n public:\n \tTopNHeap(ClientContext &context, const vector<LogicalType> &payload_types, const vector<BoundOrderByNode> &orders,\n \t         idx_t limit, idx_t offset);\n+\tTopNHeap(ExecutionContext &context, const vector<LogicalType> &payload_types,\n+\t         const vector<BoundOrderByNode> &orders, idx_t limit, idx_t offset);\n+\tTopNHeap(BufferManager &buffer_manager, Allocator &allocator, const vector<LogicalType> &payload_types,\n+\t         const vector<BoundOrderByNode> &orders, idx_t limit, idx_t offset);\n \n-\tClientContext &context;\n+\tAllocator &allocator;\n+\tBufferManager &buffer_manager;\n \tconst vector<LogicalType> &payload_types;\n \tconst vector<BoundOrderByNode> &orders;\n \tidx_t limit;\n@@ -99,7 +104,7 @@ TopNSortState::TopNSortState(TopNHeap &heap) : heap(heap), count(0), is_sorted(f\n void TopNSortState::Initialize() {\n \tRowLayout layout;\n \tlayout.Initialize(heap.payload_types);\n-\tauto &buffer_manager = BufferManager::GetBufferManager(heap.context);\n+\tauto &buffer_manager = heap.buffer_manager;\n \tglobal_state = make_unique<GlobalSortState>(buffer_manager, heap.orders, layout);\n \tlocal_state = make_unique<LocalSortState>();\n \tlocal_state->Initialize(*global_state, buffer_manager);\n@@ -139,7 +144,7 @@ void TopNSortState::Finalize() {\n \n \tglobal_state->PrepareMergePhase();\n \twhile (global_state->sorted_blocks.size() > 1) {\n-\t\tMergeSorter merge_sorter(*global_state, BufferManager::GetBufferManager(heap.context));\n+\t\tMergeSorter merge_sorter(*global_state, heap.buffer_manager);\n \t\tmerge_sorter.PerformInMergeRound();\n \t\tglobal_state->CompleteMergeRound();\n \t}\n@@ -216,11 +221,12 @@ void TopNSortState::Scan(TopNScanState &state, DataChunk &chunk) {\n //===--------------------------------------------------------------------===//\n // TopNHeap\n //===--------------------------------------------------------------------===//\n-TopNHeap::TopNHeap(ClientContext &context_p, const vector<LogicalType> &payload_types_p,\n+TopNHeap::TopNHeap(BufferManager &buffer_manager, Allocator &allocator, const vector<LogicalType> &payload_types_p,\n                    const vector<BoundOrderByNode> &orders_p, idx_t limit, idx_t offset)\n-    : context(context_p), payload_types(payload_types_p), orders(orders_p), limit(limit), offset(offset),\n-      sort_state(*this), has_boundary_values(false), final_sel(STANDARD_VECTOR_SIZE), true_sel(STANDARD_VECTOR_SIZE),\n-      false_sel(STANDARD_VECTOR_SIZE), new_remaining_sel(STANDARD_VECTOR_SIZE) {\n+    : allocator(allocator), buffer_manager(buffer_manager), payload_types(payload_types_p), orders(orders_p),\n+      limit(limit), offset(offset), sort_state(*this), executor(allocator), has_boundary_values(false),\n+      final_sel(STANDARD_VECTOR_SIZE), true_sel(STANDARD_VECTOR_SIZE), false_sel(STANDARD_VECTOR_SIZE),\n+      new_remaining_sel(STANDARD_VECTOR_SIZE) {\n \t// initialize the executor and the sort_chunk\n \tvector<LogicalType> sort_types;\n \tfor (auto &order : orders) {\n@@ -228,13 +234,25 @@ TopNHeap::TopNHeap(ClientContext &context_p, const vector<LogicalType> &payload_\n \t\tsort_types.push_back(expr->return_type);\n \t\texecutor.AddExpression(*expr);\n \t}\n-\tpayload_chunk.Initialize(payload_types);\n-\tsort_chunk.Initialize(sort_types);\n-\tcompare_chunk.Initialize(sort_types);\n-\tboundary_values.Initialize(sort_types);\n+\tpayload_chunk.Initialize(allocator, payload_types);\n+\tsort_chunk.Initialize(allocator, sort_types);\n+\tcompare_chunk.Initialize(allocator, sort_types);\n+\tboundary_values.Initialize(allocator, sort_types);\n \tsort_state.Initialize();\n }\n \n+TopNHeap::TopNHeap(ClientContext &context, const vector<LogicalType> &payload_types,\n+                   const vector<BoundOrderByNode> &orders, idx_t limit, idx_t offset)\n+    : TopNHeap(BufferManager::GetBufferManager(context), BufferAllocator::Get(context), payload_types, orders, limit,\n+               offset) {\n+}\n+\n+TopNHeap::TopNHeap(ExecutionContext &context, const vector<LogicalType> &payload_types,\n+                   const vector<BoundOrderByNode> &orders, idx_t limit, idx_t offset)\n+    : TopNHeap(BufferManager::GetBufferManager(context.client), Allocator::Get(context.client), payload_types, orders,\n+               limit, offset) {\n+}\n+\n void TopNHeap::Sink(DataChunk &input) {\n \tsort_state.Sink(input);\n }\n@@ -273,7 +291,7 @@ void TopNHeap::Reduce() {\n \tsort_state.InitializeScan(state, false);\n \n \tDataChunk new_chunk;\n-\tnew_chunk.Initialize(payload_types);\n+\tnew_chunk.Initialize(allocator, payload_types);\n \n \tDataChunk *current_chunk = &new_chunk;\n \tDataChunk *prev_chunk = &payload_chunk;\n@@ -400,7 +418,7 @@ class TopNGlobalState : public GlobalSinkState {\n \n class TopNLocalState : public LocalSinkState {\n public:\n-\tTopNLocalState(ClientContext &context, const vector<LogicalType> &payload_types,\n+\tTopNLocalState(ExecutionContext &context, const vector<LogicalType> &payload_types,\n \t               const vector<BoundOrderByNode> &orders, idx_t limit, idx_t offset)\n \t    : heap(context, payload_types, orders, limit, offset) {\n \t}\n@@ -409,7 +427,7 @@ class TopNLocalState : public LocalSinkState {\n };\n \n unique_ptr<LocalSinkState> PhysicalTopN::GetLocalSinkState(ExecutionContext &context) const {\n-\treturn make_unique<TopNLocalState>(context.client, types, orders, limit, offset);\n+\treturn make_unique<TopNLocalState>(context, types, orders, limit, offset);\n }\n \n unique_ptr<GlobalSinkState> PhysicalTopN::GetGlobalSinkState(ClientContext &context) const {\ndiff --git a/src/execution/operator/persistent/buffered_csv_reader.cpp b/src/execution/operator/persistent/buffered_csv_reader.cpp\nindex 6580ef5bccb9..31cfef48bc90 100644\n--- a/src/execution/operator/persistent/buffered_csv_reader.cpp\n+++ b/src/execution/operator/persistent/buffered_csv_reader.cpp\n@@ -492,17 +492,18 @@ TextSearchShiftArray::TextSearchShiftArray(string search_term) : length(search_t\n \t}\n }\n \n-BufferedCSVReader::BufferedCSVReader(FileSystem &fs_p, FileOpener *opener_p, BufferedCSVReaderOptions options_p,\n-                                     const vector<LogicalType> &requested_types)\n-    : fs(fs_p), opener(opener_p), options(move(options_p)), buffer_size(0), position(0), start(0) {\n+BufferedCSVReader::BufferedCSVReader(FileSystem &fs_p, Allocator &allocator, FileOpener *opener_p,\n+                                     BufferedCSVReaderOptions options_p, const vector<LogicalType> &requested_types)\n+    : fs(fs_p), allocator(allocator), opener(opener_p), options(move(options_p)), buffer_size(0), position(0),\n+      start(0) {\n \tfile_handle = OpenCSV(options);\n \tInitialize(requested_types);\n }\n \n BufferedCSVReader::BufferedCSVReader(ClientContext &context, BufferedCSVReaderOptions options_p,\n                                      const vector<LogicalType> &requested_types)\n-    : BufferedCSVReader(FileSystem::GetFileSystem(context), FileSystem::GetFileOpener(context), move(options_p),\n-                        requested_types) {\n+    : BufferedCSVReader(FileSystem::GetFileSystem(context), Allocator::Get(context), FileSystem::GetFileOpener(context),\n+                        move(options_p), requested_types) {\n }\n \n BufferedCSVReader::~BufferedCSVReader() {\n@@ -669,7 +670,7 @@ void BufferedCSVReader::InitParseChunk(idx_t num_cols) {\n \n \t\t// initialize the parse_chunk with a set of VARCHAR types\n \t\tvector<LogicalType> varchar_types(num_cols, LogicalType::VARCHAR);\n-\t\tparse_chunk.Initialize(varchar_types);\n+\t\tparse_chunk.Initialize(allocator, varchar_types);\n \t}\n }\n \n@@ -996,7 +997,7 @@ void BufferedCSVReader::DetectCandidateTypes(const vector<LogicalType> &type_can\n \t\t// jump to beginning and skip potential header\n \t\tJumpToBeginning(options.skip_rows, true);\n \t\tDataChunk header_row;\n-\t\theader_row.Initialize(sql_types);\n+\t\theader_row.Initialize(allocator, sql_types);\n \t\tparse_chunk.Copy(header_row);\n \n \t\tif (header_row.size() == 0) {\n@@ -1116,7 +1117,7 @@ void BufferedCSVReader::DetectCandidateTypes(const vector<LogicalType> &type_can\n \t\t\tbest_format_candidates = format_candidates;\n \t\t\tbest_header_row.Destroy();\n \t\t\tauto header_row_types = header_row.GetTypes();\n-\t\t\tbest_header_row.Initialize(header_row_types);\n+\t\t\tbest_header_row.Initialize(allocator, header_row_types);\n \t\t\theader_row.Copy(best_header_row);\n \t\t}\n \t}\ndiff --git a/src/execution/operator/persistent/physical_copy_to_file.cpp b/src/execution/operator/persistent/physical_copy_to_file.cpp\nindex b3e155c82348..022472c0863c 100644\n--- a/src/execution/operator/persistent/physical_copy_to_file.cpp\n+++ b/src/execution/operator/persistent/physical_copy_to_file.cpp\n@@ -47,7 +47,7 @@ SinkResultType PhysicalCopyToFile::Sink(ExecutionContext &context, GlobalSinkSta\n \tauto &l = (CopyToFunctionLocalState &)lstate;\n \n \tg.rows_copied += input.size();\n-\tfunction.copy_to_sink(context.client, *bind_data, *g.global_state, *l.local_state, input);\n+\tfunction.copy_to_sink(context, *bind_data, *g.global_state, *l.local_state, input);\n \treturn SinkResultType::NEED_MORE_INPUT;\n }\n \n@@ -56,7 +56,7 @@ void PhysicalCopyToFile::Combine(ExecutionContext &context, GlobalSinkState &gst\n \tauto &l = (CopyToFunctionLocalState &)lstate;\n \n \tif (function.copy_to_combine) {\n-\t\tfunction.copy_to_combine(context.client, *bind_data, *g.global_state, *l.local_state);\n+\t\tfunction.copy_to_combine(context, *bind_data, *g.global_state, *l.local_state);\n \t}\n }\n \n@@ -74,7 +74,7 @@ SinkFinalizeType PhysicalCopyToFile::Finalize(Pipeline &pipeline, Event &event,\n }\n \n unique_ptr<LocalSinkState> PhysicalCopyToFile::GetLocalSinkState(ExecutionContext &context) const {\n-\treturn make_unique<CopyToFunctionLocalState>(function.copy_to_initialize_local(context.client, *bind_data));\n+\treturn make_unique<CopyToFunctionLocalState>(function.copy_to_initialize_local(context, *bind_data));\n }\n unique_ptr<GlobalSinkState> PhysicalCopyToFile::GetGlobalSinkState(ClientContext &context) const {\n \treturn make_unique<CopyToFunctionGlobalState>(function.copy_to_initialize_global(context, *bind_data, file_path));\ndiff --git a/src/execution/operator/persistent/physical_delete.cpp b/src/execution/operator/persistent/physical_delete.cpp\nindex 1cb559839085..88f711999372 100644\n--- a/src/execution/operator/persistent/physical_delete.cpp\n+++ b/src/execution/operator/persistent/physical_delete.cpp\n@@ -13,7 +13,8 @@ namespace duckdb {\n //===--------------------------------------------------------------------===//\n class DeleteGlobalState : public GlobalSinkState {\n public:\n-\tDeleteGlobalState() : deleted_count(0), returned_chunk_count(0) {\n+\texplicit DeleteGlobalState(Allocator &allocator)\n+\t    : deleted_count(0), return_chunk_collection(allocator), returned_chunk_count(0) {\n \t}\n \n \tmutex delete_lock;\n@@ -24,8 +25,8 @@ class DeleteGlobalState : public GlobalSinkState {\n \n class DeleteLocalState : public LocalSinkState {\n public:\n-\texplicit DeleteLocalState(const vector<LogicalType> &table_types) {\n-\t\tdelete_chunk.Initialize(table_types);\n+\tDeleteLocalState(Allocator &allocator, const vector<LogicalType> &table_types) {\n+\t\tdelete_chunk.Initialize(allocator, table_types);\n \t}\n \tDataChunk delete_chunk;\n };\n@@ -57,11 +58,11 @@ SinkResultType PhysicalDelete::Sink(ExecutionContext &context, GlobalSinkState &\n }\n \n unique_ptr<GlobalSinkState> PhysicalDelete::GetGlobalSinkState(ClientContext &context) const {\n-\treturn make_unique<DeleteGlobalState>();\n+\treturn make_unique<DeleteGlobalState>(Allocator::Get(context));\n }\n \n unique_ptr<LocalSinkState> PhysicalDelete::GetLocalSinkState(ExecutionContext &context) const {\n-\treturn make_unique<DeleteLocalState>(table.GetTypes());\n+\treturn make_unique<DeleteLocalState>(Allocator::Get(context.client), table.GetTypes());\n }\n \n //===--------------------------------------------------------------------===//\ndiff --git a/src/execution/operator/persistent/physical_insert.cpp b/src/execution/operator/persistent/physical_insert.cpp\nindex 9557580756a9..cf4ad37ac5b5 100644\n--- a/src/execution/operator/persistent/physical_insert.cpp\n+++ b/src/execution/operator/persistent/physical_insert.cpp\n@@ -14,7 +14,8 @@ namespace duckdb {\n //===--------------------------------------------------------------------===//\n class InsertGlobalState : public GlobalSinkState {\n public:\n-\tInsertGlobalState() : insert_count(0), returned_chunk_count(0) {\n+\texplicit InsertGlobalState(Allocator &allocator)\n+\t    : insert_count(0), return_chunk_collection(allocator), returned_chunk_count(0) {\n \t}\n \n \tmutex lock;\n@@ -25,9 +26,10 @@ class InsertGlobalState : public GlobalSinkState {\n \n class InsertLocalState : public LocalSinkState {\n public:\n-\tInsertLocalState(const vector<LogicalType> &types, const vector<unique_ptr<Expression>> &bound_defaults)\n-\t    : default_executor(bound_defaults) {\n-\t\tinsert_chunk.Initialize(types);\n+\tInsertLocalState(Allocator &allocator, const vector<LogicalType> &types,\n+\t                 const vector<unique_ptr<Expression>> &bound_defaults)\n+\t    : default_executor(allocator, bound_defaults) {\n+\t\tinsert_chunk.Initialize(allocator, types);\n \t}\n \n \tDataChunk insert_chunk;\n@@ -91,11 +93,11 @@ SinkResultType PhysicalInsert::Sink(ExecutionContext &context, GlobalSinkState &\n }\n \n unique_ptr<GlobalSinkState> PhysicalInsert::GetGlobalSinkState(ClientContext &context) const {\n-\treturn make_unique<InsertGlobalState>();\n+\treturn make_unique<InsertGlobalState>(Allocator::Get(context));\n }\n \n unique_ptr<LocalSinkState> PhysicalInsert::GetLocalSinkState(ExecutionContext &context) const {\n-\treturn make_unique<InsertLocalState>(table->GetTypes(), bound_defaults);\n+\treturn make_unique<InsertLocalState>(Allocator::Get(context.client), table->GetTypes(), bound_defaults);\n }\n \n void PhysicalInsert::Combine(ExecutionContext &context, GlobalSinkState &gstate, LocalSinkState &lstate) const {\ndiff --git a/src/execution/operator/persistent/physical_update.cpp b/src/execution/operator/persistent/physical_update.cpp\nindex 267afba9685e..11733bf4e874 100644\n--- a/src/execution/operator/persistent/physical_update.cpp\n+++ b/src/execution/operator/persistent/physical_update.cpp\n@@ -15,7 +15,8 @@ namespace duckdb {\n //===--------------------------------------------------------------------===//\n class UpdateGlobalState : public GlobalSinkState {\n public:\n-\tUpdateGlobalState() : updated_count(0), returned_chunk_count(0) {\n+\texplicit UpdateGlobalState(Allocator &allocator)\n+\t    : updated_count(0), return_chunk_collection(allocator), returned_chunk_count(0) {\n \t}\n \n \tmutex lock;\n@@ -27,18 +28,18 @@ class UpdateGlobalState : public GlobalSinkState {\n \n class UpdateLocalState : public LocalSinkState {\n public:\n-\tUpdateLocalState(const vector<unique_ptr<Expression>> &expressions, const vector<LogicalType> &table_types,\n-\t                 const vector<unique_ptr<Expression>> &bound_defaults)\n-\t    : default_executor(bound_defaults) {\n+\tUpdateLocalState(Allocator &allocator, const vector<unique_ptr<Expression>> &expressions,\n+\t                 const vector<LogicalType> &table_types, const vector<unique_ptr<Expression>> &bound_defaults)\n+\t    : default_executor(allocator, bound_defaults) {\n \t\t// initialize the update chunk\n \t\tvector<LogicalType> update_types;\n \t\tupdate_types.reserve(expressions.size());\n \t\tfor (auto &expr : expressions) {\n \t\t\tupdate_types.push_back(expr->return_type);\n \t\t}\n-\t\tupdate_chunk.Initialize(update_types);\n+\t\tupdate_chunk.Initialize(allocator, update_types);\n \t\t// initialize the mock chunk\n-\t\tmock_chunk.Initialize(table_types);\n+\t\tmock_chunk.Initialize(allocator, table_types);\n \t}\n \n \tDataChunk update_chunk;\n@@ -121,11 +122,11 @@ SinkResultType PhysicalUpdate::Sink(ExecutionContext &context, GlobalSinkState &\n }\n \n unique_ptr<GlobalSinkState> PhysicalUpdate::GetGlobalSinkState(ClientContext &context) const {\n-\treturn make_unique<UpdateGlobalState>();\n+\treturn make_unique<UpdateGlobalState>(Allocator::Get(context));\n }\n \n unique_ptr<LocalSinkState> PhysicalUpdate::GetLocalSinkState(ExecutionContext &context) const {\n-\treturn make_unique<UpdateLocalState>(expressions, table.GetTypes(), bound_defaults);\n+\treturn make_unique<UpdateLocalState>(Allocator::Get(context.client), expressions, table.GetTypes(), bound_defaults);\n }\n \n void PhysicalUpdate::Combine(ExecutionContext &context, GlobalSinkState &gstate, LocalSinkState &lstate) const {\ndiff --git a/src/execution/operator/projection/physical_projection.cpp b/src/execution/operator/projection/physical_projection.cpp\nindex b4e557564716..0c28a53cb8a6 100644\n--- a/src/execution/operator/projection/physical_projection.cpp\n+++ b/src/execution/operator/projection/physical_projection.cpp\n@@ -6,7 +6,8 @@ namespace duckdb {\n \n class ProjectionState : public OperatorState {\n public:\n-\texplicit ProjectionState(const vector<unique_ptr<Expression>> &expressions) : executor(expressions) {\n+\texplicit ProjectionState(ExecutionContext &context, const vector<unique_ptr<Expression>> &expressions)\n+\t    : executor(Allocator::Get(context.client), expressions) {\n \t}\n \n \tExpressionExecutor executor;\n@@ -30,8 +31,8 @@ OperatorResultType PhysicalProjection::Execute(ExecutionContext &context, DataCh\n \treturn OperatorResultType::NEED_MORE_INPUT;\n }\n \n-unique_ptr<OperatorState> PhysicalProjection::GetOperatorState(ClientContext &context) const {\n-\treturn make_unique<ProjectionState>(select_list);\n+unique_ptr<OperatorState> PhysicalProjection::GetOperatorState(ExecutionContext &context) const {\n+\treturn make_unique<ProjectionState>(context, select_list);\n }\n \n string PhysicalProjection::ParamsToString() const {\ndiff --git a/src/execution/operator/projection/physical_tableinout_function.cpp b/src/execution/operator/projection/physical_tableinout_function.cpp\nindex 123d67a4b2b8..72f74e6486dd 100644\n--- a/src/execution/operator/projection/physical_tableinout_function.cpp\n+++ b/src/execution/operator/projection/physical_tableinout_function.cpp\n@@ -25,11 +25,12 @@ PhysicalTableInOutFunction::PhysicalTableInOutFunction(vector<LogicalType> types\n       function(move(function_p)), bind_data(move(bind_data_p)), column_ids(move(column_ids_p)) {\n }\n \n-unique_ptr<OperatorState> PhysicalTableInOutFunction::GetOperatorState(ClientContext &context) const {\n+unique_ptr<OperatorState> PhysicalTableInOutFunction::GetOperatorState(ExecutionContext &context) const {\n+\tauto &gstate = (TableInOutGlobalState &)*op_state;\n \tauto result = make_unique<TableInOutLocalState>();\n \tif (function.init_local) {\n \t\tTableFunctionInitInput input(bind_data.get(), column_ids, nullptr);\n-\t\tresult->local_state = function.init_local(context, input, nullptr);\n+\t\tresult->local_state = function.init_local(context, input, gstate.global_state.get());\n \t}\n \treturn move(result);\n }\n@@ -48,7 +49,7 @@ OperatorResultType PhysicalTableInOutFunction::Execute(ExecutionContext &context\n \tauto &gstate = (TableInOutGlobalState &)gstate_p;\n \tauto &state = (TableInOutLocalState &)state_p;\n \tTableFunctionInput data(bind_data.get(), state.local_state.get(), gstate.global_state.get());\n-\treturn function.in_out_function(context.client, data, input, chunk);\n+\treturn function.in_out_function(context, data, input, chunk);\n }\n \n } // namespace duckdb\ndiff --git a/src/execution/operator/projection/physical_unnest.cpp b/src/execution/operator/projection/physical_unnest.cpp\nindex 5cbd5449f5b3..3bd35e6a9eed 100644\n--- a/src/execution/operator/projection/physical_unnest.cpp\n+++ b/src/execution/operator/projection/physical_unnest.cpp\n@@ -10,7 +10,19 @@ namespace duckdb {\n \n class UnnestOperatorState : public OperatorState {\n public:\n-\tUnnestOperatorState() : parent_position(0), list_position(0), list_length(-1), first_fetch(true) {\n+\tUnnestOperatorState(Allocator &allocator, const vector<unique_ptr<Expression>> &select_list)\n+\t    : parent_position(0), list_position(0), list_length(-1), first_fetch(true), executor(allocator) {\n+\t\tvector<LogicalType> list_data_types;\n+\t\tfor (auto &exp : select_list) {\n+\t\t\tD_ASSERT(exp->type == ExpressionType::BOUND_UNNEST);\n+\t\t\tauto bue = (BoundUnnestExpression *)exp.get();\n+\t\t\tlist_data_types.push_back(bue->child->return_type);\n+\t\t\texecutor.AddExpression(*bue->child.get());\n+\t\t}\n+\t\tlist_data.Initialize(allocator, list_data_types);\n+\n+\t\tlist_vector_data.resize(list_data.ColumnCount());\n+\t\tlist_child_data.resize(list_data.ColumnCount());\n \t}\n \n \tidx_t parent_position;\n@@ -18,6 +30,7 @@ class UnnestOperatorState : public OperatorState {\n \tint64_t list_length;\n \tbool first_fetch;\n \n+\tExpressionExecutor executor;\n \tDataChunk list_data;\n \tvector<VectorData> list_vector_data;\n \tvector<VectorData> list_child_data;\n@@ -144,15 +157,16 @@ static void UnnestVector(VectorData &vdata, Vector &source, idx_t list_size, idx\n \t}\n }\n \n-unique_ptr<OperatorState> PhysicalUnnest::GetOperatorState(ClientContext &context) const {\n-\treturn PhysicalUnnest::GetState(context);\n+unique_ptr<OperatorState> PhysicalUnnest::GetOperatorState(ExecutionContext &context) const {\n+\treturn PhysicalUnnest::GetState(context, select_list);\n }\n \n-unique_ptr<OperatorState> PhysicalUnnest::GetState(ClientContext &context) {\n-\treturn make_unique<UnnestOperatorState>();\n+unique_ptr<OperatorState> PhysicalUnnest::GetState(ExecutionContext &context,\n+                                                   const vector<unique_ptr<Expression>> &select_list) {\n+\treturn make_unique<UnnestOperatorState>(Allocator::Get(context.client), select_list);\n }\n \n-OperatorResultType PhysicalUnnest::ExecuteInternal(ClientContext &context, DataChunk &input, DataChunk &chunk,\n+OperatorResultType PhysicalUnnest::ExecuteInternal(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n                                                    OperatorState &state_p,\n                                                    const vector<unique_ptr<Expression>> &select_list,\n                                                    bool include_input) {\n@@ -160,26 +174,17 @@ OperatorResultType PhysicalUnnest::ExecuteInternal(ClientContext &context, DataC\n \tdo {\n \t\tif (state.first_fetch) {\n \t\t\t// get the list data to unnest\n-\t\t\tExpressionExecutor executor;\n-\t\t\tvector<LogicalType> list_data_types;\n-\t\t\tfor (auto &exp : select_list) {\n-\t\t\t\tD_ASSERT(exp->type == ExpressionType::BOUND_UNNEST);\n-\t\t\t\tauto bue = (BoundUnnestExpression *)exp.get();\n-\t\t\t\tlist_data_types.push_back(bue->child->return_type);\n-\t\t\t\texecutor.AddExpression(*bue->child.get());\n-\t\t\t}\n-\t\t\tstate.list_data.Destroy();\n-\t\t\tstate.list_data.Initialize(list_data_types);\n-\t\t\texecutor.Execute(input, state.list_data);\n+\t\t\tstate.list_data.Reset();\n+\t\t\tstate.executor.Execute(input, state.list_data);\n \n \t\t\t// paranoia aplenty\n \t\t\tstate.list_data.Verify();\n \t\t\tD_ASSERT(input.size() == state.list_data.size());\n \t\t\tD_ASSERT(state.list_data.ColumnCount() == select_list.size());\n+\t\t\tD_ASSERT(state.list_vector_data.size() == state.list_data.ColumnCount());\n+\t\t\tD_ASSERT(state.list_child_data.size() == state.list_data.ColumnCount());\n \n \t\t\t// initialize VectorData object so the nullmask can accessed\n-\t\t\tstate.list_vector_data.resize(state.list_data.ColumnCount());\n-\t\t\tstate.list_child_data.resize(state.list_data.ColumnCount());\n \t\t\tfor (idx_t col_idx = 0; col_idx < state.list_data.ColumnCount(); col_idx++) {\n \t\t\t\tauto &list_vector = state.list_data.data[col_idx];\n \t\t\t\tlist_vector.Orrify(state.list_data.size(), state.list_vector_data[col_idx]);\n@@ -296,7 +301,7 @@ OperatorResultType PhysicalUnnest::ExecuteInternal(ClientContext &context, DataC\n \n OperatorResultType PhysicalUnnest::Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n                                            GlobalOperatorState &gstate, OperatorState &state) const {\n-\treturn ExecuteInternal(context.client, input, chunk, state, select_list);\n+\treturn ExecuteInternal(context, input, chunk, state, select_list);\n }\n \n } // namespace duckdb\ndiff --git a/src/execution/operator/scan/physical_expression_scan.cpp b/src/execution/operator/scan/physical_expression_scan.cpp\nindex e635b0e0da25..f7aef86d72e9 100644\n--- a/src/execution/operator/scan/physical_expression_scan.cpp\n+++ b/src/execution/operator/scan/physical_expression_scan.cpp\n@@ -6,8 +6,8 @@ namespace duckdb {\n \n class ExpressionScanState : public OperatorState {\n public:\n-\texplicit ExpressionScanState(const PhysicalExpressionScan &op) : expression_index(0) {\n-\t\ttemp_chunk.Initialize(op.GetTypes());\n+\texplicit ExpressionScanState(Allocator &allocator, const PhysicalExpressionScan &op) : expression_index(0) {\n+\t\ttemp_chunk.Initialize(allocator, op.GetTypes());\n \t}\n \n \t//! The current position in the scan\n@@ -16,8 +16,8 @@ class ExpressionScanState : public OperatorState {\n \tDataChunk temp_chunk;\n };\n \n-unique_ptr<OperatorState> PhysicalExpressionScan::GetOperatorState(ClientContext &context) const {\n-\treturn make_unique<ExpressionScanState>(*this);\n+unique_ptr<OperatorState> PhysicalExpressionScan::GetOperatorState(ExecutionContext &context) const {\n+\treturn make_unique<ExpressionScanState>(Allocator::Get(context.client), *this);\n }\n \n OperatorResultType PhysicalExpressionScan::Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n@@ -27,7 +27,7 @@ OperatorResultType PhysicalExpressionScan::Execute(ExecutionContext &context, Da\n \tfor (; chunk.size() + input.size() <= STANDARD_VECTOR_SIZE && state.expression_index < expressions.size();\n \t     state.expression_index++) {\n \t\tstate.temp_chunk.Reset();\n-\t\tEvaluateExpression(state.expression_index, &input, state.temp_chunk);\n+\t\tEvaluateExpression(Allocator::Get(context.client), state.expression_index, &input, state.temp_chunk);\n \t\tchunk.Append(state.temp_chunk);\n \t}\n \tif (state.expression_index < expressions.size()) {\n@@ -38,8 +38,9 @@ OperatorResultType PhysicalExpressionScan::Execute(ExecutionContext &context, Da\n \t}\n }\n \n-void PhysicalExpressionScan::EvaluateExpression(idx_t expression_idx, DataChunk *child_chunk, DataChunk &result) const {\n-\tExpressionExecutor executor(expressions[expression_idx]);\n+void PhysicalExpressionScan::EvaluateExpression(Allocator &allocator, idx_t expression_idx, DataChunk *child_chunk,\n+                                                DataChunk &result) const {\n+\tExpressionExecutor executor(allocator, expressions[expression_idx]);\n \tif (child_chunk) {\n \t\tchild_chunk->Verify();\n \t\texecutor.Execute(*child_chunk, result);\ndiff --git a/src/execution/operator/scan/physical_table_scan.cpp b/src/execution/operator/scan/physical_table_scan.cpp\nindex e0f406aea574..6532ddb7335b 100644\n--- a/src/execution/operator/scan/physical_table_scan.cpp\n+++ b/src/execution/operator/scan/physical_table_scan.cpp\n@@ -46,7 +46,7 @@ class TableScanLocalSourceState : public LocalSourceState {\n \t                          const PhysicalTableScan &op) {\n \t\tif (op.function.init_local) {\n \t\t\tTableFunctionInitInput input(op.bind_data.get(), op.column_ids, op.table_filters.get());\n-\t\t\tlocal_state = op.function.init_local(context.client, input, gstate.global_state.get());\n+\t\t\tlocal_state = op.function.init_local(context, input, gstate.global_state.get());\n \t\t}\n \t}\n \ndiff --git a/src/execution/operator/set/physical_recursive_cte.cpp b/src/execution/operator/set/physical_recursive_cte.cpp\nindex cca5081b78d5..3f5270a3652e 100644\n--- a/src/execution/operator/set/physical_recursive_cte.cpp\n+++ b/src/execution/operator/set/physical_recursive_cte.cpp\n@@ -29,9 +29,10 @@ PhysicalRecursiveCTE::~PhysicalRecursiveCTE() {\n class RecursiveCTEState : public GlobalSinkState {\n public:\n \texplicit RecursiveCTEState(ClientContext &context, const PhysicalRecursiveCTE &op)\n-\t    : new_groups(STANDARD_VECTOR_SIZE) {\n-\t\tht = make_unique<GroupedAggregateHashTable>(BufferManager::GetBufferManager(context), op.types,\n-\t\t                                            vector<LogicalType>(), vector<BoundAggregateExpression *>());\n+\t    : intermediate_table(Allocator::Get(context)), new_groups(STANDARD_VECTOR_SIZE) {\n+\t\tht = make_unique<GroupedAggregateHashTable>(Allocator::Get(context), BufferManager::GetBufferManager(context),\n+\t\t                                            op.types, vector<LogicalType>(),\n+\t\t                                            vector<BoundAggregateExpression *>());\n \t}\n \n \tunique_ptr<GroupedAggregateHashTable> ht;\ndiff --git a/src/execution/partitionable_hashtable.cpp b/src/execution/partitionable_hashtable.cpp\nindex 07c19d007e56..732057995a28 100644\n--- a/src/execution/partitionable_hashtable.cpp\n+++ b/src/execution/partitionable_hashtable.cpp\n@@ -44,18 +44,19 @@ RadixPartitionInfo::RadixPartitionInfo(const idx_t n_partitions_upper_bound)\n \tD_ASSERT(radix_bits <= 8);\n }\n \n-PartitionableHashTable::PartitionableHashTable(BufferManager &buffer_manager_p, RadixPartitionInfo &partition_info_p,\n-                                               vector<LogicalType> group_types_p, vector<LogicalType> payload_types_p,\n+PartitionableHashTable::PartitionableHashTable(Allocator &allocator, BufferManager &buffer_manager_p,\n+                                               RadixPartitionInfo &partition_info_p, vector<LogicalType> group_types_p,\n+                                               vector<LogicalType> payload_types_p,\n                                                vector<BoundAggregateExpression *> bindings_p)\n-    : buffer_manager(buffer_manager_p), group_types(move(group_types_p)), payload_types(move(payload_types_p)),\n-      bindings(move(bindings_p)), is_partitioned(false), partition_info(partition_info_p), hashes(LogicalType::HASH),\n-      hashes_subset(LogicalType::HASH) {\n+    : allocator(allocator), buffer_manager(buffer_manager_p), group_types(move(group_types_p)),\n+      payload_types(move(payload_types_p)), bindings(move(bindings_p)), is_partitioned(false),\n+      partition_info(partition_info_p), hashes(LogicalType::HASH), hashes_subset(LogicalType::HASH) {\n \n \tsel_vectors.resize(partition_info.n_partitions);\n \tsel_vector_sizes.resize(partition_info.n_partitions);\n-\tgroup_subset.Initialize(group_types);\n+\tgroup_subset.Initialize(allocator, group_types);\n \tif (!payload_types.empty()) {\n-\t\tpayload_subset.Initialize(payload_types);\n+\t\tpayload_subset.Initialize(allocator, payload_types);\n \t}\n \n \tfor (hash_t r = 0; r < partition_info.n_partitions; r++) {\n@@ -70,8 +71,8 @@ idx_t PartitionableHashTable::ListAddChunk(HashTableList &list, DataChunk &group\n \t\t\t// early release first part of ht and prevent adding of more data\n \t\t\tlist.back()->Finalize();\n \t\t}\n-\t\tlist.push_back(make_unique<GroupedAggregateHashTable>(buffer_manager, group_types, payload_types, bindings,\n-\t\t                                                      HtEntryType::HT_WIDTH_32));\n+\t\tlist.push_back(make_unique<GroupedAggregateHashTable>(allocator, buffer_manager, group_types, payload_types,\n+\t\t                                                      bindings, HtEntryType::HT_WIDTH_32));\n \t}\n \treturn list.back()->AddChunk(groups, group_hashes, payload);\n }\n@@ -132,7 +133,7 @@ void PartitionableHashTable::Partition() {\n \tfor (auto &unpartitioned_ht : unpartitioned_hts) {\n \t\tfor (idx_t r = 0; r < partition_info.n_partitions; r++) {\n \t\t\tradix_partitioned_hts[r].push_back(make_unique<GroupedAggregateHashTable>(\n-\t\t\t    buffer_manager, group_types, payload_types, bindings, HtEntryType::HT_WIDTH_32));\n+\t\t\t    allocator, buffer_manager, group_types, payload_types, bindings, HtEntryType::HT_WIDTH_32));\n \t\t\tpartition_hts[r] = radix_partitioned_hts[r].back().get();\n \t\t}\n \t\tunpartitioned_ht->Partition(partition_hts, partition_info.radix_mask, partition_info.RADIX_SHIFT);\ndiff --git a/src/execution/perfect_aggregate_hashtable.cpp b/src/execution/perfect_aggregate_hashtable.cpp\nindex 050db3788b8b..f4894b87dc79 100644\n--- a/src/execution/perfect_aggregate_hashtable.cpp\n+++ b/src/execution/perfect_aggregate_hashtable.cpp\n@@ -4,14 +4,14 @@\n \n namespace duckdb {\n \n-PerfectAggregateHashTable::PerfectAggregateHashTable(BufferManager &buffer_manager,\n+PerfectAggregateHashTable::PerfectAggregateHashTable(Allocator &allocator, BufferManager &buffer_manager,\n                                                      const vector<LogicalType> &group_types_p,\n                                                      vector<LogicalType> payload_types_p,\n                                                      vector<AggregateObject> aggregate_objects_p,\n                                                      vector<Value> group_minima_p, vector<idx_t> required_bits_p)\n-    : BaseAggregateHashTable(buffer_manager, move(payload_types_p)), addresses(LogicalType::POINTER),\n-      required_bits(move(required_bits_p)), total_required_bits(0), group_minima(move(group_minima_p)),\n-      sel(STANDARD_VECTOR_SIZE) {\n+    : BaseAggregateHashTable(allocator, aggregate_objects_p, buffer_manager, move(payload_types_p)),\n+      addresses(LogicalType::POINTER), required_bits(move(required_bits_p)), total_required_bits(0),\n+      group_minima(move(group_minima_p)), sel(STANDARD_VECTOR_SIZE) {\n \tfor (auto &group_bits : required_bits) {\n \t\ttotal_required_bits += group_bits;\n \t}\n@@ -119,10 +119,12 @@ void PerfectAggregateHashTable::AddChunk(DataChunk &groups, DataChunk &payload)\n \t// after finding the group location we update the aggregates\n \tidx_t payload_idx = 0;\n \tauto &aggregates = layout.GetAggregates();\n-\tfor (auto &aggregate : aggregates) {\n+\tfor (idx_t aggr_idx = 0; aggr_idx < aggregates.size(); aggr_idx++) {\n+\t\tauto &aggregate = aggregates[aggr_idx];\n \t\tauto input_count = (idx_t)aggregate.child_count;\n \t\tif (aggregate.filter) {\n-\t\t\tRowOperations::UpdateFilteredStates(aggregate, addresses, payload, payload_idx);\n+\t\t\tRowOperations::UpdateFilteredStates(filter_set.GetFilterData(aggr_idx), aggregate, addresses, payload,\n+\t\t\t                                    payload_idx);\n \t\t} else {\n \t\t\tRowOperations::UpdateStates(aggregate, addresses, payload, payload_idx, payload.size());\n \t\t}\ndiff --git a/src/execution/physical_operator.cpp b/src/execution/physical_operator.cpp\nindex c855c24384a0..6d32c299cbab 100644\n--- a/src/execution/physical_operator.cpp\n+++ b/src/execution/physical_operator.cpp\n@@ -38,7 +38,7 @@ vector<PhysicalOperator *> PhysicalOperator::GetChildren() const {\n // Operator\n //===--------------------------------------------------------------------===//\n // LCOV_EXCL_START\n-unique_ptr<OperatorState> PhysicalOperator::GetOperatorState(ClientContext &context) const {\n+unique_ptr<OperatorState> PhysicalOperator::GetOperatorState(ExecutionContext &context) const {\n \treturn make_unique<OperatorState>();\n }\n \ndiff --git a/src/execution/physical_plan/plan_explain.cpp b/src/execution/physical_plan/plan_explain.cpp\nindex d9de0175958f..618638a1ab17 100644\n--- a/src/execution/physical_plan/plan_explain.cpp\n+++ b/src/execution/physical_plan/plan_explain.cpp\n@@ -36,10 +36,11 @@ unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalExplain &o\n \t}\n \n \t// create a ChunkCollection from the output\n-\tauto collection = make_unique<ChunkCollection>();\n+\tauto &allocator = Allocator::Get(context);\n+\tauto collection = make_unique<ChunkCollection>(allocator);\n \n \tDataChunk chunk;\n-\tchunk.Initialize(op.types);\n+\tchunk.Initialize(allocator, op.types);\n \tfor (idx_t i = 0; i < keys.size(); i++) {\n \t\tchunk.SetValue(0, chunk.size(), Value(keys[i]));\n \t\tchunk.SetValue(1, chunk.size(), Value(values[i]));\ndiff --git a/src/execution/physical_plan/plan_expression_get.cpp b/src/execution/physical_plan/plan_expression_get.cpp\nindex 929bb9b2bfb8..dd212ef3b7dc 100644\n--- a/src/execution/physical_plan/plan_expression_get.cpp\n+++ b/src/execution/physical_plan/plan_expression_get.cpp\n@@ -14,18 +14,19 @@ unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalExpression\n \tif (!expr_scan->IsFoldable()) {\n \t\treturn move(expr_scan);\n \t}\n+\tauto &allocator = Allocator::Get(context);\n \t// simple expression scan (i.e. no subqueries to evaluate and no prepared statement parameters)\n \t// we can evaluate all the expressions right now and turn this into a chunk collection scan\n \tauto chunk_scan =\n \t    make_unique<PhysicalChunkScan>(op.types, PhysicalOperatorType::CHUNK_SCAN, expr_scan->expressions.size());\n-\tchunk_scan->owned_collection = make_unique<ChunkCollection>();\n+\tchunk_scan->owned_collection = make_unique<ChunkCollection>(allocator);\n \tchunk_scan->collection = chunk_scan->owned_collection.get();\n \n \tDataChunk chunk;\n-\tchunk.Initialize(op.types);\n+\tchunk.Initialize(allocator, op.types);\n \tfor (idx_t expression_idx = 0; expression_idx < expr_scan->expressions.size(); expression_idx++) {\n \t\tchunk.Reset();\n-\t\texpr_scan->EvaluateExpression(expression_idx, nullptr, chunk);\n+\t\texpr_scan->EvaluateExpression(allocator, expression_idx, nullptr, chunk);\n \t\tchunk_scan->owned_collection->Append(chunk);\n \t}\n \treturn move(chunk_scan);\ndiff --git a/src/execution/physical_plan/plan_recursive_cte.cpp b/src/execution/physical_plan/plan_recursive_cte.cpp\nindex 5437d46c8ca5..3245a5140624 100644\n--- a/src/execution/physical_plan/plan_recursive_cte.cpp\n+++ b/src/execution/physical_plan/plan_recursive_cte.cpp\n@@ -11,7 +11,7 @@ unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalRecursiveC\n \tD_ASSERT(op.children.size() == 2);\n \n \t// Create the working_table that the PhysicalRecursiveCTE will use for evaluation.\n-\tauto working_table = std::make_shared<ChunkCollection>();\n+\tauto working_table = std::make_shared<ChunkCollection>(context);\n \n \t// Add the ChunkCollection to the context of this PhysicalPlanGenerator\n \trec_ctes[op.table_index] = working_table;\ndiff --git a/src/execution/physical_plan/plan_show_select.cpp b/src/execution/physical_plan/plan_show_select.cpp\nindex 5cbfd4236a79..0a446f9b39df 100644\n--- a/src/execution/physical_plan/plan_show_select.cpp\n+++ b/src/execution/physical_plan/plan_show_select.cpp\n@@ -7,9 +7,9 @@ namespace duckdb {\n \n unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalShow &op) {\n \tDataChunk output;\n-\toutput.Initialize(op.types);\n+\toutput.Initialize(Allocator::Get(context), op.types);\n \n-\tauto collection = make_unique<ChunkCollection>();\n+\tauto collection = make_unique<ChunkCollection>(Allocator::Get(context));\n \tfor (idx_t column_idx = 0; column_idx < op.types_select.size(); column_idx++) {\n \t\tauto type = op.types_select[column_idx];\n \t\tauto &name = op.aliases[column_idx];\ndiff --git a/src/execution/radix_partitioned_hashtable.cpp b/src/execution/radix_partitioned_hashtable.cpp\nindex 6bdf38211e25..a2acf5292d7f 100644\n--- a/src/execution/radix_partitioned_hashtable.cpp\n+++ b/src/execution/radix_partitioned_hashtable.cpp\n@@ -123,9 +123,9 @@ void RadixPartitionedHashTable::Sink(ExecutionContext &context, GlobalSinkState\n \t\tlock_guard<mutex> glock(gstate.lock);\n \t\tgstate.is_empty = gstate.is_empty && group_chunk.size() == 0;\n \t\tif (gstate.finalized_hts.empty()) {\n-\t\t\tgstate.finalized_hts.push_back(\n-\t\t\t    make_unique<GroupedAggregateHashTable>(BufferManager::GetBufferManager(context.client), group_types,\n-\t\t\t                                           op.payload_types, op.bindings, HtEntryType::HT_WIDTH_64));\n+\t\t\tgstate.finalized_hts.push_back(make_unique<GroupedAggregateHashTable>(\n+\t\t\t    Allocator::Get(context.client), BufferManager::GetBufferManager(context.client), group_types,\n+\t\t\t    op.payload_types, op.bindings, HtEntryType::HT_WIDTH_64));\n \t\t}\n \t\tD_ASSERT(gstate.finalized_hts.size() == 1);\n \t\tD_ASSERT(gstate.finalized_hts[0]);\n@@ -140,9 +140,9 @@ void RadixPartitionedHashTable::Sink(ExecutionContext &context, GlobalSinkState\n \t}\n \n \tif (!llstate.ht) {\n-\t\tllstate.ht =\n-\t\t    make_unique<PartitionableHashTable>(BufferManager::GetBufferManager(context.client), gstate.partition_info,\n-\t\t                                        group_types, op.payload_types, op.bindings);\n+\t\tllstate.ht = make_unique<PartitionableHashTable>(\n+\t\t    Allocator::Get(context.client), BufferManager::GetBufferManager(context.client), gstate.partition_info,\n+\t\t    group_types, op.payload_types, op.bindings);\n \t}\n \n \tgstate.total_groups +=\n@@ -210,6 +210,8 @@ bool RadixPartitionedHashTable::Finalize(ClientContext &context, GlobalSinkState\n \t\t}\n \t}\n \n+\tauto &allocator = Allocator::Get(context);\n+\tauto &buffer_manager = BufferManager::GetBufferManager(context);\n \tif (any_partitioned) {\n \t\t// if one is partitioned, all have to be\n \t\t// this should mostly have already happened in Combine, but if not we do it here\n@@ -221,9 +223,8 @@ bool RadixPartitionedHashTable::Finalize(ClientContext &context, GlobalSinkState\n \t\t// schedule additional tasks to combine the partial HTs\n \t\tgstate.finalized_hts.resize(gstate.partition_info.n_partitions);\n \t\tfor (idx_t r = 0; r < gstate.partition_info.n_partitions; r++) {\n-\t\t\tgstate.finalized_hts[r] =\n-\t\t\t    make_unique<GroupedAggregateHashTable>(BufferManager::GetBufferManager(context), group_types,\n-\t\t\t                                           op.payload_types, op.bindings, HtEntryType::HT_WIDTH_64);\n+\t\t\tgstate.finalized_hts[r] = make_unique<GroupedAggregateHashTable>(\n+\t\t\t    allocator, buffer_manager, group_types, op.payload_types, op.bindings, HtEntryType::HT_WIDTH_64);\n \t\t}\n \t\tgstate.is_partitioned = true;\n \t\treturn true;\n@@ -231,9 +232,8 @@ bool RadixPartitionedHashTable::Finalize(ClientContext &context, GlobalSinkState\n \t\t     // TODO possible optimization, if total count < limit for 32 bit ht, use that one\n \t\t     // create this ht here so finalize needs no lock on gstate\n \n-\t\tgstate.finalized_hts.push_back(make_unique<GroupedAggregateHashTable>(BufferManager::GetBufferManager(context),\n-\t\t                                                                      group_types, op.payload_types,\n-\t\t                                                                      op.bindings, HtEntryType::HT_WIDTH_64));\n+\t\tgstate.finalized_hts.push_back(make_unique<GroupedAggregateHashTable>(\n+\t\t    allocator, buffer_manager, group_types, op.payload_types, op.bindings, HtEntryType::HT_WIDTH_64));\n \t\tfor (auto &pht : gstate.intermediate_hts) {\n \t\t\tauto unpartitioned = pht->GetUnpartitioned();\n \t\t\tfor (auto &unpartitioned_ht : unpartitioned) {\n@@ -305,13 +305,13 @@ bool RadixPartitionedHashTable::ForceSingleHT(GlobalSinkState &state) const {\n //===--------------------------------------------------------------------===//\n class RadixHTGlobalSourceState : public GlobalSourceState {\n public:\n-\texplicit RadixHTGlobalSourceState(const RadixPartitionedHashTable &ht)\n+\texplicit RadixHTGlobalSourceState(Allocator &allocator, const RadixPartitionedHashTable &ht)\n \t    : ht_index(0), ht_scan_position(0), finished(false) {\n \t\tauto scan_chunk_types = ht.group_types;\n \t\tfor (auto &aggr_type : ht.op.aggregate_return_types) {\n \t\t\tscan_chunk_types.push_back(aggr_type);\n \t\t}\n-\t\tscan_chunk.Initialize(scan_chunk_types);\n+\t\tscan_chunk.Initialize(allocator, scan_chunk_types);\n \t}\n \n \t//! Materialized GROUP BY expressions & aggregates\n@@ -322,8 +322,8 @@ class RadixHTGlobalSourceState : public GlobalSourceState {\n \tbool finished;\n };\n \n-unique_ptr<GlobalSourceState> RadixPartitionedHashTable::GetGlobalSourceState() const {\n-\treturn make_unique<RadixHTGlobalSourceState>(*this);\n+unique_ptr<GlobalSourceState> RadixPartitionedHashTable::GetGlobalSourceState(ClientContext &context) const {\n+\treturn make_unique<RadixHTGlobalSourceState>(Allocator::Get(context), *this);\n }\n \n void RadixPartitionedHashTable::GetData(ExecutionContext &context, DataChunk &chunk, GlobalSinkState &sink_state,\ndiff --git a/src/execution/reservoir_sample.cpp b/src/execution/reservoir_sample.cpp\nindex 8303fd5d0a2e..08dbaf0e7287 100644\n--- a/src/execution/reservoir_sample.cpp\n+++ b/src/execution/reservoir_sample.cpp\n@@ -3,6 +3,10 @@\n \n namespace duckdb {\n \n+ReservoirSample::ReservoirSample(Allocator &allocator, idx_t sample_count, int64_t seed)\n+    : BlockingSample(seed), sample_count(sample_count), reservoir(allocator) {\n+}\n+\n void ReservoirSample::AddToReservoir(DataChunk &input) {\n \tif (sample_count == 0) {\n \t\treturn;\n@@ -85,10 +89,11 @@ idx_t ReservoirSample::FillReservoir(DataChunk &input) {\n \treturn input.size();\n }\n \n-ReservoirSamplePercentage::ReservoirSamplePercentage(double percentage, int64_t seed)\n-    : BlockingSample(seed), sample_percentage(percentage / 100.0), current_count(0), is_finalized(false) {\n+ReservoirSamplePercentage::ReservoirSamplePercentage(Allocator &allocator, double percentage, int64_t seed)\n+    : BlockingSample(seed), allocator(allocator), sample_percentage(percentage / 100.0), current_count(0),\n+      is_finalized(false) {\n \treservoir_sample_size = idx_t(sample_percentage * RESERVOIR_THRESHOLD);\n-\tcurrent_sample = make_unique<ReservoirSample>(reservoir_sample_size, random.NextRandomInteger());\n+\tcurrent_sample = make_unique<ReservoirSample>(allocator, reservoir_sample_size, random.NextRandomInteger());\n }\n \n void ReservoirSamplePercentage::AddToReservoir(DataChunk &input) {\n@@ -116,7 +121,7 @@ void ReservoirSamplePercentage::AddToReservoir(DataChunk &input) {\n \t\tfinished_samples.push_back(move(current_sample));\n \n \t\t// allocate a new sample, and potentially add the remainder of the current input to that sample\n-\t\tcurrent_sample = make_unique<ReservoirSample>(reservoir_sample_size, random.NextRandomInteger());\n+\t\tcurrent_sample = make_unique<ReservoirSample>(allocator, reservoir_sample_size, random.NextRandomInteger());\n \t\tif (append_to_next_sample > 0) {\n \t\t\tcurrent_sample->AddToReservoir(input);\n \t\t}\n@@ -149,7 +154,7 @@ void ReservoirSamplePercentage::Finalize() {\n \tif (current_count > 0) {\n \t\t// create a new sample\n \t\tauto new_sample_size = idx_t(round(sample_percentage * current_count));\n-\t\tauto new_sample = make_unique<ReservoirSample>(new_sample_size, random.NextRandomInteger());\n+\t\tauto new_sample = make_unique<ReservoirSample>(allocator, new_sample_size, random.NextRandomInteger());\n \t\twhile (true) {\n \t\t\tauto chunk = current_sample->GetChunk();\n \t\t\tif (!chunk || chunk->size() == 0) {\ndiff --git a/src/execution/window_segment_tree.cpp b/src/execution/window_segment_tree.cpp\nindex bf21f24a45cf..e1efcbb29479 100644\n--- a/src/execution/window_segment_tree.cpp\n+++ b/src/execution/window_segment_tree.cpp\n@@ -21,7 +21,7 @@ WindowSegmentTree::WindowSegmentTree(AggregateFunction &aggregate, FunctionData\n \n \tif (input_ref && input_ref->ColumnCount() > 0) {\n \t\tfilter_sel.Initialize(STANDARD_VECTOR_SIZE);\n-\t\tinputs.Initialize(input_ref->Types());\n+\t\tinputs.Initialize(Allocator::DefaultAllocator(), input_ref->Types());\n \t\t// if we have a frame-by-frame method, share the single state\n \t\tif (aggregate.window && UseWindowAPI()) {\n \t\t\tAggregateInit();\ndiff --git a/src/function/aggregate/sorted_aggregate_function.cpp b/src/function/aggregate/sorted_aggregate_function.cpp\nindex 4a9eb3a1e634..14603e2d56fc 100644\n--- a/src/function/aggregate/sorted_aggregate_function.cpp\n+++ b/src/function/aggregate/sorted_aggregate_function.cpp\n@@ -71,7 +71,8 @@ struct SortedAggregateBindData : public FunctionData {\n };\n \n struct SortedAggregateState {\n-\tSortedAggregateState() : nsel(0) {\n+\tSortedAggregateState()\n+\t    : arguments(Allocator::DefaultAllocator()), ordering(Allocator::DefaultAllocator()), nsel(0) {\n \t}\n \n \tChunkCollection arguments;\ndiff --git a/src/function/scalar/list/list_sort.cpp b/src/function/scalar/list/list_sort.cpp\nindex 14ff74907e4d..c06c4892ff99 100644\n--- a/src/function/scalar/list/list_sort.cpp\n+++ b/src/function/scalar/list/list_sort.cpp\n@@ -96,7 +96,6 @@ void SinkDataChunk(Vector *child_vector, SelectionVector &sel, idx_t offset_list\n }\n \n static void ListSortFunction(DataChunk &args, ExpressionState &state, Vector &result) {\n-\n \tD_ASSERT(args.ColumnCount() >= 1 && args.ColumnCount() <= 3);\n \tauto count = args.size();\n \tVector &lists = args.data[0];\n@@ -203,7 +202,7 @@ static void ListSortFunction(DataChunk &args, ExpressionState &state, Vector &re\n \t\tPayloadScanner scanner(*global_sort_state.sorted_blocks[0]->payload_data, global_sort_state);\n \t\tfor (;;) {\n \t\t\tDataChunk result_chunk;\n-\t\t\tresult_chunk.Initialize(info.payload_types);\n+\t\t\tresult_chunk.Initialize(Allocator::DefaultAllocator(), info.payload_types);\n \t\t\tresult_chunk.SetCardinality(0);\n \t\t\tscanner.Scan(result_chunk);\n \t\t\tif (result_chunk.size() == 0) {\ndiff --git a/src/function/table/arrow.cpp b/src/function/table/arrow.cpp\nindex 0024ebe2cd51..224681b1bd4f 100644\n--- a/src/function/table/arrow.cpp\n+++ b/src/function/table/arrow.cpp\n@@ -277,7 +277,7 @@ unique_ptr<GlobalTableFunctionState> ArrowTableFunction::ArrowScanInitGlobal(Cli\n \treturn move(result);\n }\n \n-unique_ptr<LocalTableFunctionState> ArrowTableFunction::ArrowScanInitLocal(ClientContext &context,\n+unique_ptr<LocalTableFunctionState> ArrowTableFunction::ArrowScanInitLocal(ExecutionContext &context,\n                                                                            TableFunctionInitInput &input,\n                                                                            GlobalTableFunctionState *global_state_p) {\n \tauto &global_state = (ArrowScanGlobalState &)*global_state_p;\n@@ -285,7 +285,7 @@ unique_ptr<LocalTableFunctionState> ArrowTableFunction::ArrowScanInitLocal(Clien\n \tauto result = make_unique<ArrowScanLocalState>(move(current_chunk));\n \tresult->column_ids = input.column_ids;\n \tresult->filters = input.filters;\n-\tif (!ArrowScanParallelStateNext(context, input.bind_data, *result, global_state)) {\n+\tif (!ArrowScanParallelStateNext(context.client, input.bind_data, *result, global_state)) {\n \t\treturn nullptr;\n \t}\n \treturn move(result);\ndiff --git a/src/function/table/copy_csv.cpp b/src/function/table/copy_csv.cpp\nindex 7c4b12541789..df26e72b4384 100644\n--- a/src/function/table/copy_csv.cpp\n+++ b/src/function/table/copy_csv.cpp\n@@ -262,7 +262,7 @@ struct GlobalWriteCSVData : public GlobalFunctionData {\n \tunique_ptr<FileHandle> handle;\n };\n \n-static unique_ptr<LocalFunctionData> WriteCSVInitializeLocal(ClientContext &context, FunctionData &bind_data) {\n+static unique_ptr<LocalFunctionData> WriteCSVInitializeLocal(ExecutionContext &context, FunctionData &bind_data) {\n \tauto &csv_data = (WriteCSVData &)bind_data;\n \tauto local_data = make_unique<LocalReadCSVData>();\n \n@@ -270,7 +270,7 @@ static unique_ptr<LocalFunctionData> WriteCSVInitializeLocal(ClientContext &cont\n \tvector<LogicalType> types;\n \ttypes.resize(csv_data.options.names.size(), LogicalType::VARCHAR);\n \n-\tlocal_data->cast_chunk.Initialize(types);\n+\tlocal_data->cast_chunk.Initialize(Allocator::Get(context.client), types);\n \treturn move(local_data);\n }\n \n@@ -298,7 +298,7 @@ static unique_ptr<GlobalFunctionData> WriteCSVInitializeGlobal(ClientContext &co\n \treturn move(global_data);\n }\n \n-static void WriteCSVSink(ClientContext &context, FunctionData &bind_data, GlobalFunctionData &gstate,\n+static void WriteCSVSink(ExecutionContext &context, FunctionData &bind_data, GlobalFunctionData &gstate,\n                          LocalFunctionData &lstate, DataChunk &input) {\n \tauto &csv_data = (WriteCSVData &)bind_data;\n \tauto &options = csv_data.options;\n@@ -365,7 +365,7 @@ static void WriteCSVSink(ClientContext &context, FunctionData &bind_data, Global\n //===--------------------------------------------------------------------===//\n // Combine\n //===--------------------------------------------------------------------===//\n-static void WriteCSVCombine(ClientContext &context, FunctionData &bind_data, GlobalFunctionData &gstate,\n+static void WriteCSVCombine(ExecutionContext &context, FunctionData &bind_data, GlobalFunctionData &gstate,\n                             LocalFunctionData &lstate) {\n \tauto &local_data = (LocalReadCSVData &)lstate;\n \tauto &global_state = (GlobalWriteCSVData &)gstate;\ndiff --git a/src/function/table/pragma_detailed_profiling_output.cpp b/src/function/table/pragma_detailed_profiling_output.cpp\nindex 58079a97bcb7..5143ee33f017 100644\n--- a/src/function/table/pragma_detailed_profiling_output.cpp\n+++ b/src/function/table/pragma_detailed_profiling_output.cpp\n@@ -111,11 +111,11 @@ static void PragmaDetailedProfilingOutputFunction(ClientContext &context, TableF\n \n \tif (!state.initialized) {\n \t\t// create a ChunkCollection\n-\t\tauto collection = make_unique<ChunkCollection>();\n+\t\tauto collection = make_unique<ChunkCollection>(context);\n \n \t\t// create a chunk\n \t\tDataChunk chunk;\n-\t\tchunk.Initialize(data.types);\n+\t\tchunk.Initialize(context, data.types);\n \n \t\t// Initialize ids\n \t\tint operator_counter = 1;\ndiff --git a/src/function/table/pragma_last_profiling_output.cpp b/src/function/table/pragma_last_profiling_output.cpp\nindex 02cab74bb1c4..7ed64671f679 100644\n--- a/src/function/table/pragma_last_profiling_output.cpp\n+++ b/src/function/table/pragma_last_profiling_output.cpp\n@@ -63,10 +63,10 @@ static void PragmaLastProfilingOutputFunction(ClientContext &context, TableFunct\n \tauto &data = (PragmaLastProfilingOutputData &)*data_p.bind_data;\n \tif (!state.initialized) {\n \t\t// create a ChunkCollection\n-\t\tauto collection = make_unique<ChunkCollection>();\n+\t\tauto collection = make_unique<ChunkCollection>(context);\n \n \t\tDataChunk chunk;\n-\t\tchunk.Initialize(data.types);\n+\t\tchunk.Initialize(context, data.types);\n \t\tint operator_counter = 1;\n \t\tif (!ClientData::Get(context).query_profiler_history->GetPrevProfilers().empty()) {\n \t\t\tfor (auto op :\ndiff --git a/src/function/table/summary.cpp b/src/function/table/summary.cpp\nindex cb1db1380526..b30a193c4a67 100644\n--- a/src/function/table/summary.cpp\n+++ b/src/function/table/summary.cpp\n@@ -21,7 +21,7 @@ static unique_ptr<FunctionData> SummaryFunctionBind(ClientContext &context, Tabl\n \treturn make_unique<TableFunctionData>();\n }\n \n-static OperatorResultType SummaryFunction(ClientContext &context, TableFunctionInput &data_p, DataChunk &input,\n+static OperatorResultType SummaryFunction(ExecutionContext &context, TableFunctionInput &data_p, DataChunk &input,\n                                           DataChunk &output) {\n \toutput.SetCardinality(input.size());\n \ndiff --git a/src/function/table/table_scan.cpp b/src/function/table/table_scan.cpp\nindex 745c89acbdf3..f904c11ccf95 100644\n--- a/src/function/table/table_scan.cpp\n+++ b/src/function/table/table_scan.cpp\n@@ -51,7 +51,7 @@ struct TableScanGlobalState : public GlobalTableFunctionState {\n \t}\n };\n \n-static unique_ptr<LocalTableFunctionState> TableScanInitLocal(ClientContext &context, TableFunctionInitInput &input,\n+static unique_ptr<LocalTableFunctionState> TableScanInitLocal(ExecutionContext &context, TableFunctionInitInput &input,\n                                                               GlobalTableFunctionState *gstate) {\n \tauto result = make_unique<TableScanLocalState>();\n \tauto &bind_data = (TableScanBindData &)*input.bind_data;\n@@ -61,7 +61,7 @@ static unique_ptr<LocalTableFunctionState> TableScanInitLocal(ClientContext &con\n \t\tcol = storage_idx;\n \t}\n \tresult->scan_state.table_filters = input.filters;\n-\tTableScanParallelStateNext(context, input.bind_data, result.get(), gstate);\n+\tTableScanParallelStateNext(context.client, input.bind_data, result.get(), gstate);\n \treturn move(result);\n }\n \ndiff --git a/src/function/table/unnest.cpp b/src/function/table/unnest.cpp\nindex 9f04b9dd2151..be8843dbd088 100644\n--- a/src/function/table/unnest.cpp\n+++ b/src/function/table/unnest.cpp\n@@ -23,11 +23,10 @@ struct UnnestBindData : public FunctionData {\n \t}\n };\n \n-struct UnnestOperatorData : public GlobalTableFunctionState {\n-\tUnnestOperatorData() {\n+struct UnnestGlobalState : public GlobalTableFunctionState {\n+\tUnnestGlobalState() {\n \t}\n \n-\tunique_ptr<OperatorState> operator_state;\n \tvector<unique_ptr<Expression>> select_list;\n \n \tidx_t MaxThreads() const override {\n@@ -35,6 +34,13 @@ struct UnnestOperatorData : public GlobalTableFunctionState {\n \t}\n };\n \n+struct UnnestLocalState : public LocalTableFunctionState {\n+\tUnnestLocalState() {\n+\t}\n+\n+\tunique_ptr<OperatorState> operator_state;\n+};\n+\n static unique_ptr<FunctionData> UnnestBind(ClientContext &context, TableFunctionBindInput &input,\n                                            vector<LogicalType> &return_types, vector<string> &names) {\n \tif (input.input_table_types.size() != 1 || input.input_table_types[0].id() != LogicalTypeId::LIST) {\n@@ -45,10 +51,18 @@ static unique_ptr<FunctionData> UnnestBind(ClientContext &context, TableFunction\n \treturn make_unique<UnnestBindData>(input.input_table_types[0]);\n }\n \n+static unique_ptr<LocalTableFunctionState> UnnestLocalInit(ExecutionContext &context, TableFunctionInitInput &input,\n+                                                           GlobalTableFunctionState *global_state) {\n+\tauto &gstate = (UnnestGlobalState &)*global_state;\n+\n+\tauto result = make_unique<UnnestLocalState>();\n+\tresult->operator_state = PhysicalUnnest::GetState(context, gstate.select_list);\n+\treturn move(result);\n+}\n+\n static unique_ptr<GlobalTableFunctionState> UnnestInit(ClientContext &context, TableFunctionInitInput &input) {\n \tauto &bind_data = (UnnestBindData &)*input.bind_data;\n-\tauto result = make_unique<UnnestOperatorData>();\n-\tresult->operator_state = PhysicalUnnest::GetState(context);\n+\tauto result = make_unique<UnnestGlobalState>();\n \tauto ref = make_unique<BoundReferenceExpression>(bind_data.input_type, 0);\n \tauto bound_unnest = make_unique<BoundUnnestExpression>(ListType::GetChildType(bind_data.input_type));\n \tbound_unnest->child = move(ref);\n@@ -56,14 +70,15 @@ static unique_ptr<GlobalTableFunctionState> UnnestInit(ClientContext &context, T\n \treturn move(result);\n }\n \n-static OperatorResultType UnnestFunction(ClientContext &context, TableFunctionInput &data_p, DataChunk &input,\n+static OperatorResultType UnnestFunction(ExecutionContext &context, TableFunctionInput &data_p, DataChunk &input,\n                                          DataChunk &output) {\n-\tauto &state = (UnnestOperatorData &)*data_p.global_state;\n-\treturn PhysicalUnnest::ExecuteInternal(context, input, output, *state.operator_state, state.select_list, false);\n+\tauto &state = (UnnestGlobalState &)*data_p.global_state;\n+\tauto &lstate = (UnnestLocalState &)*data_p.local_state;\n+\treturn PhysicalUnnest::ExecuteInternal(context, input, output, *lstate.operator_state, state.select_list, false);\n }\n \n void UnnestTableFunction::RegisterFunction(BuiltinFunctions &set) {\n-\tTableFunction unnest_function(\"unnest\", {LogicalTypeId::TABLE}, nullptr, UnnestBind, UnnestInit);\n+\tTableFunction unnest_function(\"unnest\", {LogicalTypeId::TABLE}, nullptr, UnnestBind, UnnestInit, UnnestLocalInit);\n \tunnest_function.in_out_function = UnnestFunction;\n \tset.AddFunction(unnest_function);\n }\ndiff --git a/src/include/duckdb/common/allocator.hpp b/src/include/duckdb/common/allocator.hpp\nindex a9a40b4dddd4..c0cbcea7503a 100644\n--- a/src/include/duckdb/common/allocator.hpp\n+++ b/src/include/duckdb/common/allocator.hpp\n@@ -14,15 +14,22 @@ namespace duckdb {\n class Allocator;\n class ClientContext;\n class DatabaseInstance;\n+class ExecutionContext;\n+class ThreadContext;\n+\n+struct AllocatorDebugInfo;\n \n struct PrivateAllocatorData {\n-\tvirtual ~PrivateAllocatorData() {\n-\t}\n+\tPrivateAllocatorData();\n+\tvirtual ~PrivateAllocatorData();\n+\n+\tunique_ptr<AllocatorDebugInfo> debug_info;\n };\n \n typedef data_ptr_t (*allocate_function_ptr_t)(PrivateAllocatorData *private_data, idx_t size);\n typedef void (*free_function_ptr_t)(PrivateAllocatorData *private_data, data_ptr_t pointer, idx_t size);\n-typedef data_ptr_t (*reallocate_function_ptr_t)(PrivateAllocatorData *private_data, data_ptr_t pointer, idx_t size);\n+typedef data_ptr_t (*reallocate_function_ptr_t)(PrivateAllocatorData *private_data, data_ptr_t pointer, idx_t old_size,\n+                                                idx_t size);\n \n class AllocatedData {\n public:\n@@ -52,12 +59,12 @@ class Allocator {\n \tDUCKDB_API Allocator(allocate_function_ptr_t allocate_function_p, free_function_ptr_t free_function_p,\n \t                     reallocate_function_ptr_t reallocate_function_p,\n \t                     unique_ptr<PrivateAllocatorData> private_data);\n-\n-\tDUCKDB_API Allocator &operator=(Allocator &&allocator) noexcept = default;\n+\tDUCKDB_API Allocator &operator=(Allocator &&allocator) noexcept = delete;\n+\tDUCKDB_API ~Allocator();\n \n \tdata_ptr_t AllocateData(idx_t size);\n \tvoid FreeData(data_ptr_t pointer, idx_t size);\n-\tdata_ptr_t ReallocateData(data_ptr_t pointer, idx_t size);\n+\tdata_ptr_t ReallocateData(data_ptr_t pointer, idx_t old_size, idx_t new_size);\n \n \tunique_ptr<AllocatedData> Allocate(idx_t size) {\n \t\treturn make_unique<AllocatedData>(*this, AllocateData(size), size);\n@@ -69,7 +76,8 @@ class Allocator {\n \tstatic void DefaultFree(PrivateAllocatorData *private_data, data_ptr_t pointer, idx_t size) {\n \t\tfree(pointer);\n \t}\n-\tstatic data_ptr_t DefaultReallocate(PrivateAllocatorData *private_data, data_ptr_t pointer, idx_t size) {\n+\tstatic data_ptr_t DefaultReallocate(PrivateAllocatorData *private_data, data_ptr_t pointer, idx_t old_size,\n+\t                                    idx_t size) {\n \t\treturn (data_ptr_t)realloc(pointer, size);\n \t}\n \tstatic Allocator &Get(ClientContext &context);\n@@ -79,6 +87,8 @@ class Allocator {\n \t\treturn private_data.get();\n \t}\n \n+\tstatic Allocator &DefaultAllocator();\n+\n private:\n \tallocate_function_ptr_t allocate_function;\n \tfree_function_ptr_t free_function;\n@@ -87,4 +97,13 @@ class Allocator {\n \tunique_ptr<PrivateAllocatorData> private_data;\n };\n \n+//! The BufferAllocator is a wrapper around the global allocator class that sends any allocations made through the\n+//! buffer manager. This makes the buffer manager aware of the memory usage, allowing it to potentially free\n+//! other blocks to make space in memory.\n+//! Note that there is a cost to doing so (several atomic operations will be performed on allocation/free).\n+//! As such this class should be used primarily for larger allocations.\n+struct BufferAllocator {\n+\tstatic Allocator &Get(ClientContext &context);\n+};\n+\n } // namespace duckdb\ndiff --git a/src/include/duckdb/common/enums/undo_flags.hpp b/src/include/duckdb/common/enums/undo_flags.hpp\nindex 5afdbf2649a2..928161144979 100644\n--- a/src/include/duckdb/common/enums/undo_flags.hpp\n+++ b/src/include/duckdb/common/enums/undo_flags.hpp\n@@ -12,7 +12,7 @@\n \n namespace duckdb {\n \n-enum class UndoFlags : uint32_t { // far to big but aligned (TM)\n+enum class UndoFlags : uint32_t { // far too big but aligned (TM)\n \tEMPTY_ENTRY = 0,\n \tCATALOG_ENTRY = 1,\n \tINSERT_TUPLE = 2,\ndiff --git a/src/include/duckdb/common/row_operations/row_operations.hpp b/src/include/duckdb/common/row_operations/row_operations.hpp\nindex 780331aeaa17..1581801b00b9 100644\n--- a/src/include/duckdb/common/row_operations/row_operations.hpp\n+++ b/src/include/duckdb/common/row_operations/row_operations.hpp\n@@ -14,6 +14,7 @@\n namespace duckdb {\n \n struct AggregateObject;\n+struct AggregateFilterData;\n class DataChunk;\n class RowLayout;\n class RowDataCollection;\n@@ -34,7 +35,8 @@ struct RowOperations {\n \t//! update - aligned addresses\n \tstatic void UpdateStates(AggregateObject &aggr, Vector &addresses, DataChunk &payload, idx_t arg_idx, idx_t count);\n \t//! filtered update - aligned addresses\n-\tstatic void UpdateFilteredStates(AggregateObject &aggr, Vector &addresses, DataChunk &payload, idx_t arg_idx);\n+\tstatic void UpdateFilteredStates(AggregateFilterData &filter_data, AggregateObject &aggr, Vector &addresses,\n+\t                                 DataChunk &payload, idx_t arg_idx);\n \t//! combine - unaligned addresses, updated\n \tstatic void CombineStates(RowLayout &layout, Vector &sources, Vector &targets, idx_t count);\n \t//! finalize - unaligned addresses, updated\ndiff --git a/src/include/duckdb/common/sort/sort.hpp b/src/include/duckdb/common/sort/sort.hpp\nindex a07dabe99226..50d59a947b95 100644\n--- a/src/include/duckdb/common/sort/sort.hpp\n+++ b/src/include/duckdb/common/sort/sort.hpp\n@@ -81,7 +81,7 @@ struct GlobalSortState {\n \n \t//! Pinned heap data (if sorting in memory)\n \tvector<RowDataBlock> heap_blocks;\n-\tvector<unique_ptr<BufferHandle>> pinned_blocks;\n+\tvector<BufferHandle> pinned_blocks;\n \n \t//! Capacity (number of rows) used to initialize blocks\n \tidx_t block_capacity;\ndiff --git a/src/include/duckdb/common/sort/sorted_block.hpp b/src/include/duckdb/common/sort/sorted_block.hpp\nindex cb5839675091..3b45a0f98b14 100644\n--- a/src/include/duckdb/common/sort/sorted_block.hpp\n+++ b/src/include/duckdb/common/sort/sorted_block.hpp\n@@ -8,6 +8,7 @@\n #pragma once\n \n #include \"duckdb/common/types/row_layout.hpp\"\n+#include \"duckdb/storage/buffer/buffer_handle.hpp\"\n \n namespace duckdb {\n \n@@ -114,13 +115,13 @@ struct SBScanState {\n \tidx_t block_idx;\n \tidx_t entry_idx;\n \n-\tunique_ptr<BufferHandle> radix_handle = nullptr;\n+\tBufferHandle radix_handle;\n \n-\tunique_ptr<BufferHandle> blob_sorting_data_handle = nullptr;\n-\tunique_ptr<BufferHandle> blob_sorting_heap_handle = nullptr;\n+\tBufferHandle blob_sorting_data_handle;\n+\tBufferHandle blob_sorting_heap_handle;\n \n-\tunique_ptr<BufferHandle> payload_data_handle = nullptr;\n-\tunique_ptr<BufferHandle> payload_heap_handle = nullptr;\n+\tBufferHandle payload_data_handle;\n+\tBufferHandle payload_heap_handle;\n };\n \n //! Used to scan the data into DataChunks after sorting\ndiff --git a/src/include/duckdb/common/types/batched_chunk_collection.hpp b/src/include/duckdb/common/types/batched_chunk_collection.hpp\nindex 3e6aff2099de..38be9f9a8cd6 100644\n--- a/src/include/duckdb/common/types/batched_chunk_collection.hpp\n+++ b/src/include/duckdb/common/types/batched_chunk_collection.hpp\n@@ -22,7 +22,7 @@ struct BatchedChunkScanState {\n //! Scans over a BatchedChunkCollection are ordered by batch index\n class BatchedChunkCollection {\n public:\n-\tDUCKDB_API BatchedChunkCollection();\n+\tDUCKDB_API BatchedChunkCollection(Allocator &allocator);\n \n \t//! Appends a datachunk with the given batch index to the batched collection\n \tDUCKDB_API void Append(DataChunk &input, idx_t batch_index);\n@@ -40,6 +40,7 @@ class BatchedChunkCollection {\n \tDUCKDB_API void Print() const;\n \n private:\n+\tAllocator &allocator;\n \t//! The data of the batched chunk collection - a set of batch_index -> ChunkCollection pointers\n \tmap<idx_t, unique_ptr<ChunkCollection>> data;\n };\ndiff --git a/src/include/duckdb/common/types/chunk_collection.hpp b/src/include/duckdb/common/types/chunk_collection.hpp\nindex ee8e4d7c4e81..b34ee2e0bf3c 100644\n--- a/src/include/duckdb/common/types/chunk_collection.hpp\n+++ b/src/include/duckdb/common/types/chunk_collection.hpp\n@@ -13,6 +13,8 @@\n #include \"duckdb/common/winapi.hpp\"\n \n namespace duckdb {\n+class Allocator;\n+class ClientContext;\n \n //!  A ChunkCollection represents a set of DataChunks that all have the same\n //!  types\n@@ -24,8 +26,8 @@ namespace duckdb {\n */\n class ChunkCollection {\n public:\n-\tChunkCollection() : count(0) {\n-\t}\n+\tChunkCollection(Allocator &allocator);\n+\tChunkCollection(ClientContext &context);\n \n \t//! The amount of columns in the ChunkCollection\n \tDUCKDB_API vector<LogicalType> &Types() {\n@@ -126,7 +128,12 @@ class ChunkCollection {\n \t\treturn result;\n \t}\n \n+\tAllocator &GetAllocator() {\n+\t\treturn allocator;\n+\t}\n+\n private:\n+\tAllocator &allocator;\n \t//! The total amount of elements in the collection\n \tidx_t count;\n \t//! The set of data chunks in the collection\ndiff --git a/src/include/duckdb/common/types/data_chunk.hpp b/src/include/duckdb/common/types/data_chunk.hpp\nindex 68344477a105..dda25140257c 100644\n--- a/src/include/duckdb/common/types/data_chunk.hpp\n+++ b/src/include/duckdb/common/types/data_chunk.hpp\n@@ -11,12 +11,15 @@\n #include \"duckdb/common/common.hpp\"\n #include \"duckdb/common/types/vector.hpp\"\n #include \"duckdb/common/winapi.hpp\"\n-\n+#include \"duckdb/common/allocator.hpp\"\n #include \"duckdb/common/arrow_wrapper.hpp\"\n \n struct ArrowArray;\n \n namespace duckdb {\n+class Allocator;\n+class ClientContext;\n+class ExecutionContext;\n class VectorCache;\n \n //!  A Data Chunk represents a set of vectors.\n@@ -76,7 +79,8 @@ class DataChunk {\n \t//! This will create one vector of the specified type for each LogicalType in the\n \t//! types list. The vector will be referencing vector to the data owned by\n \t//! the DataChunk.\n-\tDUCKDB_API void Initialize(const vector<LogicalType> &types);\n+\tDUCKDB_API void Initialize(Allocator &allocator, const vector<LogicalType> &types);\n+\tDUCKDB_API void Initialize(ClientContext &context, const vector<LogicalType> &types);\n \t//! Initializes an empty DataChunk with the given types. The vectors will *not* have any data allocated for them.\n \tDUCKDB_API void InitializeEmpty(const vector<LogicalType> &types);\n \t//! Append the other DataChunk to this one. The column count and types of\ndiff --git a/src/include/duckdb/common/types/row_data_collection.hpp b/src/include/duckdb/common/types/row_data_collection.hpp\nindex e7a02e39e605..0860dddb3bd0 100644\n--- a/src/include/duckdb/common/types/row_data_collection.hpp\n+++ b/src/include/duckdb/common/types/row_data_collection.hpp\n@@ -52,13 +52,13 @@ class RowDataCollection {\n \t//! The blocks holding the main data\n \tvector<RowDataBlock> blocks;\n \t//! The blocks that this collection currently has pinned\n-\tvector<unique_ptr<BufferHandle>> pinned_blocks;\n+\tvector<BufferHandle> pinned_blocks;\n \n public:\n \tidx_t AppendToBlock(RowDataBlock &block, BufferHandle &handle, vector<BlockAppendEntry> &append_entries,\n \t                    idx_t remaining, idx_t entry_sizes[]);\n-\tvector<unique_ptr<BufferHandle>> Build(idx_t added_count, data_ptr_t key_locations[], idx_t entry_sizes[],\n-\t                                       const SelectionVector *sel = FlatVector::IncrementalSelectionVector());\n+\tvector<BufferHandle> Build(idx_t added_count, data_ptr_t key_locations[], idx_t entry_sizes[],\n+\t                           const SelectionVector *sel = FlatVector::IncrementalSelectionVector());\n \n \tvoid Merge(RowDataCollection &other);\n \ndiff --git a/src/include/duckdb/common/types/row_layout.hpp b/src/include/duckdb/common/types/row_layout.hpp\nindex fdccbdb9500e..321aed310a7b 100644\n--- a/src/include/duckdb/common/types/row_layout.hpp\n+++ b/src/include/duckdb/common/types/row_layout.hpp\n@@ -10,29 +10,10 @@\n \n #include \"duckdb/common/common.hpp\"\n #include \"duckdb/common/types/validity_mask.hpp\"\n-#include \"duckdb/function/aggregate_function.hpp\"\n #include \"duckdb/planner/expression.hpp\"\n+#include \"duckdb/execution/operator/aggregate/aggregate_object.hpp\"\n \n namespace duckdb {\n-class BoundAggregateExpression;\n-\n-struct AggregateObject {\n-\tAggregateObject(AggregateFunction function, FunctionData *bind_data, idx_t child_count, idx_t payload_size,\n-\t                bool distinct, PhysicalType return_type, Expression *filter = nullptr)\n-\t    : function(move(function)), bind_data(bind_data), child_count(child_count), payload_size(payload_size),\n-\t      distinct(distinct), return_type(return_type), filter(filter) {\n-\t}\n-\n-\tAggregateFunction function;\n-\tFunctionData *bind_data;\n-\tidx_t child_count;\n-\tidx_t payload_size;\n-\tbool distinct;\n-\tPhysicalType return_type;\n-\tExpression *filter = nullptr;\n-\n-\tstatic vector<AggregateObject> CreateAggregateObjects(const vector<BoundAggregateExpression *> &bindings);\n-};\n \n class RowLayout {\n public:\ndiff --git a/src/include/duckdb/common/types/string_heap.hpp b/src/include/duckdb/common/types/string_heap.hpp\nindex 388c3fbb98fe..762c49f2b96f 100644\n--- a/src/include/duckdb/common/types/string_heap.hpp\n+++ b/src/include/duckdb/common/types/string_heap.hpp\n@@ -10,6 +10,7 @@\n \n #include \"duckdb/common/common.hpp\"\n #include \"duckdb/common/types/value.hpp\"\n+#include \"duckdb/storage/arena_allocator.hpp\"\n \n namespace duckdb {\n //! A string heap is the owner of a set of strings, strings can be inserted into\n@@ -19,17 +20,8 @@ class StringHeap {\n public:\n \tStringHeap();\n \n-\tvoid Destroy() {\n-\t\ttail = nullptr;\n-\t\tchunk = nullptr;\n-\t}\n-\n-\tvoid Move(StringHeap &other) {\n-\t\tD_ASSERT(!other.chunk);\n-\t\tother.tail = tail;\n-\t\tother.chunk = move(chunk);\n-\t\ttail = nullptr;\n-\t}\n+\tvoid Destroy();\n+\tvoid Move(StringHeap &other);\n \n \t//! Add a string to the string heap, returns a pointer to the string\n \tstring_t AddString(const char *data, idx_t len);\n@@ -40,31 +32,14 @@ class StringHeap {\n \t//! Add a string to the string heap, returns a pointer to the string\n \tstring_t AddString(const string_t &data);\n \t//! Add a blob to the string heap; blobs can be non-valid UTF8\n+\tstring_t AddBlob(const string_t &data);\n+\t//! Add a blob to the string heap; blobs can be non-valid UTF8\n \tstring_t AddBlob(const char *data, idx_t len);\n \t//! Allocates space for an empty string of size \"len\" on the heap\n \tstring_t EmptyString(idx_t len);\n \n private:\n-\tstruct StringChunk {\n-\t\texplicit StringChunk(idx_t size) : current_position(0), maximum_size(size) {\n-\t\t\tdata = unique_ptr<char[]>(new char[maximum_size]);\n-\t\t}\n-\t\t~StringChunk() {\n-\t\t\tif (prev) {\n-\t\t\t\tauto current_prev = move(prev);\n-\t\t\t\twhile (current_prev) {\n-\t\t\t\t\tcurrent_prev = move(current_prev->prev);\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n-\n-\t\tunique_ptr<char[]> data;\n-\t\tidx_t current_position;\n-\t\tidx_t maximum_size;\n-\t\tunique_ptr<StringChunk> prev;\n-\t};\n-\tStringChunk *tail;\n-\tunique_ptr<StringChunk> chunk;\n+\tArenaAllocator allocator;\n };\n \n } // namespace duckdb\ndiff --git a/src/include/duckdb/common/types/vector.hpp b/src/include/duckdb/common/types/vector.hpp\nindex 55dbec0236e7..9224df331957 100644\n--- a/src/include/duckdb/common/types/vector.hpp\n+++ b/src/include/duckdb/common/types/vector.hpp\n@@ -342,7 +342,7 @@ struct StringVector {\n \t//! result of an operation\n \tDUCKDB_API static string_t EmptyString(Vector &vector, idx_t len);\n \t//! Adds a reference to a handle that stores strings of this vector\n-\tDUCKDB_API static void AddHandle(Vector &vector, unique_ptr<BufferHandle> handle);\n+\tDUCKDB_API static void AddHandle(Vector &vector, BufferHandle handle);\n \t//! Adds a reference to an unspecified vector buffer that stores strings of this vector\n \tDUCKDB_API static void AddBuffer(Vector &vector, buffer_ptr<VectorBuffer> buffer);\n \t//! Add a reference from this vector to the string heap of the provided vector\ndiff --git a/src/include/duckdb/common/types/vector_buffer.hpp b/src/include/duckdb/common/types/vector_buffer.hpp\nindex e61aa041c635..d1e091d0ecf1 100644\n--- a/src/include/duckdb/common/types/vector_buffer.hpp\n+++ b/src/include/duckdb/common/types/vector_buffer.hpp\n@@ -12,6 +12,7 @@\n #include \"duckdb/common/types/selection_vector.hpp\"\n #include \"duckdb/common/types/string_heap.hpp\"\n #include \"duckdb/common/types/string_type.hpp\"\n+#include \"duckdb/storage/buffer/buffer_handle.hpp\"\n \n namespace duckdb {\n \n@@ -206,11 +207,11 @@ class VectorListBuffer : public VectorBuffer {\n //! The ManagedVectorBuffer holds a buffer handle\n class ManagedVectorBuffer : public VectorBuffer {\n public:\n-\texplicit ManagedVectorBuffer(unique_ptr<BufferHandle> handle);\n+\texplicit ManagedVectorBuffer(BufferHandle handle);\n \t~ManagedVectorBuffer() override;\n \n private:\n-\tunique_ptr<BufferHandle> handle;\n+\tBufferHandle handle;\n };\n \n } // namespace duckdb\ndiff --git a/src/include/duckdb/common/types/vector_cache.hpp b/src/include/duckdb/common/types/vector_cache.hpp\nindex 2f6a5ba94a35..ebb1b9ea3b57 100644\n--- a/src/include/duckdb/common/types/vector_cache.hpp\n+++ b/src/include/duckdb/common/types/vector_cache.hpp\n@@ -13,13 +13,14 @@\n #include \"duckdb/common/types/vector_buffer.hpp\"\n \n namespace duckdb {\n+class Allocator;\n class Vector;\n \n //! The VectorCache holds cached data that allows for re-use of the same memory by vectors\n class VectorCache {\n public:\n \t//! Instantiate a vector cache with the given type\n-\texplicit VectorCache(const LogicalType &type);\n+\texplicit VectorCache(Allocator &allocator, const LogicalType &type);\n \n \tbuffer_ptr<VectorBuffer> buffer;\n \ndiff --git a/src/include/duckdb/execution/aggregate_hashtable.hpp b/src/include/duckdb/execution/aggregate_hashtable.hpp\nindex 4299d065e3b5..72f9681a47af 100644\n--- a/src/include/duckdb/execution/aggregate_hashtable.hpp\n+++ b/src/include/duckdb/execution/aggregate_hashtable.hpp\n@@ -9,12 +9,15 @@\n #pragma once\n \n #include \"duckdb/execution/base_aggregate_hashtable.hpp\"\n+#include \"duckdb/storage/buffer/buffer_handle.hpp\"\n \n namespace duckdb {\n class BlockHandle;\n class BufferHandle;\n class RowDataCollection;\n \n+struct FlushMoveState;\n+\n //! GroupedAggregateHashTable is a linear probing HT that is used for computing\n //! aggregates\n /*!\n@@ -56,15 +59,24 @@ enum HtEntryType { HT_WIDTH_32, HT_WIDTH_64 };\n \n class GroupedAggregateHashTable : public BaseAggregateHashTable {\n public:\n-\tGroupedAggregateHashTable(BufferManager &buffer_manager, vector<LogicalType> group_types,\n+\t//! The hash table load factor, when a resize is triggered\n+\tconstexpr static float LOAD_FACTOR = 1.5;\n+\tconstexpr static uint8_t HASH_WIDTH = sizeof(hash_t);\n+\n+public:\n+\tGroupedAggregateHashTable(Allocator &allocator, BufferManager &buffer_manager, vector<LogicalType> group_types,\n \t                          vector<LogicalType> payload_types, const vector<BoundAggregateExpression *> &aggregates,\n \t                          HtEntryType entry_type = HtEntryType::HT_WIDTH_64);\n-\tGroupedAggregateHashTable(BufferManager &buffer_manager, vector<LogicalType> group_types,\n+\tGroupedAggregateHashTable(Allocator &allocator, BufferManager &buffer_manager, vector<LogicalType> group_types,\n \t                          vector<LogicalType> payload_types, vector<AggregateObject> aggregates,\n \t                          HtEntryType entry_type = HtEntryType::HT_WIDTH_64);\n-\tGroupedAggregateHashTable(BufferManager &buffer_manager, vector<LogicalType> group_types);\n+\tGroupedAggregateHashTable(Allocator &allocator, BufferManager &buffer_manager, vector<LogicalType> group_types);\n \t~GroupedAggregateHashTable() override;\n \n+\t//! The stringheap of the AggregateHashTable\n+\tunique_ptr<RowDataCollection> string_heap;\n+\n+public:\n \t//! Add the given data to the HT, computing the aggregates grouped by the\n \t//! data in the group chunk. When resize = true, aggregates will not be\n \t//! computed but instead just assigned.\n@@ -100,13 +112,6 @@ class GroupedAggregateHashTable : public BaseAggregateHashTable {\n \n \tvoid Finalize();\n \n-\t//! The stringheap of the AggregateHashTable\n-\tunique_ptr<RowDataCollection> string_heap;\n-\n-\t//! The hash table load factor, when a resize is triggered\n-\tconstexpr static float LOAD_FACTOR = 1.5;\n-\tconstexpr static uint8_t HASH_WIDTH = sizeof(hash_t);\n-\n private:\n \tHtEntryType entry_type;\n \n@@ -120,11 +125,11 @@ class GroupedAggregateHashTable : public BaseAggregateHashTable {\n \t//! The amount of entries stored in the HT currently\n \tidx_t entries;\n \t//! The data of the HT\n-\tvector<unique_ptr<BufferHandle>> payload_hds;\n+\tvector<BufferHandle> payload_hds;\n \tvector<data_ptr_t> payload_hds_ptrs;\n \n \t//! The hashes of the HT\n-\tunique_ptr<BufferHandle> hashes_hdl;\n+\tBufferHandle hashes_hdl;\n \tdata_ptr_t hashes_hdl_ptr;\n \tdata_ptr_t hashes_end_ptr; // of hashes\n \tidx_t hash_offset;         // Offset into the layout of the hash column\n@@ -156,7 +161,7 @@ class GroupedAggregateHashTable : public BaseAggregateHashTable {\n \n \tvoid Verify();\n \n-\tvoid FlushMove(Vector &source_addresses, Vector &source_hashes, idx_t count);\n+\tvoid FlushMove(FlushMoveState &state, Vector &source_addresses, Vector &source_hashes, idx_t count);\n \tvoid NewBlock();\n \n \ttemplate <class ENTRY>\ndiff --git a/src/include/duckdb/execution/base_aggregate_hashtable.hpp b/src/include/duckdb/execution/base_aggregate_hashtable.hpp\nindex 487a812c508d..57dce04bdf7b 100644\n--- a/src/include/duckdb/execution/base_aggregate_hashtable.hpp\n+++ b/src/include/duckdb/execution/base_aggregate_hashtable.hpp\n@@ -11,22 +11,27 @@\n #include \"duckdb/common/common.hpp\"\n #include \"duckdb/common/types/row_layout.hpp\"\n #include \"duckdb/common/types/vector.hpp\"\n+#include \"duckdb/execution/operator/aggregate/aggregate_object.hpp\"\n \n namespace duckdb {\n class BufferManager;\n \n class BaseAggregateHashTable {\n public:\n-\tBaseAggregateHashTable(BufferManager &buffer_manager, vector<LogicalType> payload_types);\n+\tBaseAggregateHashTable(Allocator &allocator, const vector<AggregateObject> &aggregates,\n+\t                       BufferManager &buffer_manager, vector<LogicalType> payload_types);\n \tvirtual ~BaseAggregateHashTable() {\n \t}\n \n protected:\n+\tAllocator &allocator;\n \tBufferManager &buffer_manager;\n \t//! A helper for managing offsets into the data buffers\n \tRowLayout layout;\n \t//! The types of the payload columns stored in the hashtable\n \tvector<LogicalType> payload_types;\n+\t//! Intermediate structures and data for aggregate filters\n+\tAggregateFilterDataSet filter_set;\n };\n \n } // namespace duckdb\ndiff --git a/src/include/duckdb/execution/expression_executor.hpp b/src/include/duckdb/execution/expression_executor.hpp\nindex aec06bc80c20..42c4ac3ee2cc 100644\n--- a/src/include/duckdb/execution/expression_executor.hpp\n+++ b/src/include/duckdb/execution/expression_executor.hpp\n@@ -14,15 +14,25 @@\n #include \"duckdb/planner/expression.hpp\"\n \n namespace duckdb {\n+class Allocator;\n class ExecutionContext;\n+\n //! ExpressionExecutor is responsible for executing a set of expressions and storing the result in a data chunk\n class ExpressionExecutor {\n public:\n-\tDUCKDB_API ExpressionExecutor();\n-\tDUCKDB_API explicit ExpressionExecutor(const Expression *expression);\n-\tDUCKDB_API explicit ExpressionExecutor(const Expression &expression);\n-\tDUCKDB_API explicit ExpressionExecutor(const vector<unique_ptr<Expression>> &expressions);\n+\tDUCKDB_API ExpressionExecutor(Allocator &allocator);\n+\tDUCKDB_API explicit ExpressionExecutor(Allocator &allocator, const Expression *expression);\n+\tDUCKDB_API explicit ExpressionExecutor(Allocator &allocator, const Expression &expression);\n+\tDUCKDB_API explicit ExpressionExecutor(Allocator &allocator, const vector<unique_ptr<Expression>> &expressions);\n+\n+\tAllocator &allocator;\n+\t//! The expressions of the executor\n+\tvector<const Expression *> expressions;\n+\t//! The data chunk of the current physical operator, used to resolve\n+\t//! column references and determines the output cardinality\n+\tDataChunk *chunk = nullptr;\n \n+public:\n \t//! Add an expression to the set of to-be-executed expressions of the executor\n \tDUCKDB_API void AddExpression(const Expression &expr);\n \n@@ -64,12 +74,6 @@ class ExpressionExecutor {\n \n \tDUCKDB_API vector<unique_ptr<ExpressionExecutorState>> &GetStates();\n \n-\t//! The expressions of the executor\n-\tvector<const Expression *> expressions;\n-\t//! The data chunk of the current physical operator, used to resolve\n-\t//! column references and determines the output cardinality\n-\tDataChunk *chunk = nullptr;\n-\n protected:\n \tvoid Initialize(const Expression &expr, ExpressionExecutorState &state);\n \ndiff --git a/src/include/duckdb/execution/index/art/art.hpp b/src/include/duckdb/execution/index/art/art.hpp\nindex 60faa9e28960..e995e9aae7bb 100644\n--- a/src/include/duckdb/execution/index/art/art.hpp\n+++ b/src/include/duckdb/execution/index/art/art.hpp\n@@ -111,9 +111,6 @@ class ART : public Index {\n \t//! Search Equal used for Joins that do not need to fetch data\n \tvoid SearchEqualJoinNoFetch(Value &equal_value, idx_t &result_size);\n \n-private:\n-\tDataChunk expression_result;\n-\n private:\n \t//! Insert a row id into a leaf node\n \tbool InsertToLeaf(Leaf &leaf, row_t row_id);\ndiff --git a/src/include/duckdb/execution/join_hashtable.hpp b/src/include/duckdb/execution/join_hashtable.hpp\nindex df75d3c612c2..aabbf7d5a5d7 100644\n--- a/src/include/duckdb/execution/join_hashtable.hpp\n+++ b/src/include/duckdb/execution/join_hashtable.hpp\n@@ -191,9 +191,9 @@ class JoinHashTable {\n \t//! The stringheap of the JoinHashTable\n \tunique_ptr<RowDataCollection> string_heap;\n \t//! Pinned handles, these are pinned during finalization only\n-\tvector<unique_ptr<BufferHandle>> pinned_handles;\n+\tvector<BufferHandle> pinned_handles;\n \t//! The hash map of the HT, created after finalization\n-\tunique_ptr<BufferHandle> hash_map;\n+\tBufferHandle hash_map;\n \t//! Whether or not NULL values are considered equal in each of the comparisons\n \tvector<bool> null_values_are_equal;\n \ndiff --git a/src/include/duckdb/execution/operator/aggregate/aggregate_object.hpp b/src/include/duckdb/execution/operator/aggregate/aggregate_object.hpp\nnew file mode 100644\nindex 000000000000..61862ef07e47\n--- /dev/null\n+++ b/src/include/duckdb/execution/operator/aggregate/aggregate_object.hpp\n@@ -0,0 +1,56 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/execution/operator/aggregate/aggregate_object.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#pragma once\n+\n+#include \"duckdb/execution/expression_executor.hpp\"\n+#include \"duckdb/function/aggregate_function.hpp\"\n+\n+namespace duckdb {\n+\n+class BoundAggregateExpression;\n+\n+struct AggregateObject {\n+\tAggregateObject(AggregateFunction function, FunctionData *bind_data, idx_t child_count, idx_t payload_size,\n+\t                bool distinct, PhysicalType return_type, Expression *filter = nullptr);\n+\tAggregateObject(BoundAggregateExpression *aggr);\n+\n+\tAggregateFunction function;\n+\tFunctionData *bind_data;\n+\tidx_t child_count;\n+\tidx_t payload_size;\n+\tbool distinct;\n+\tPhysicalType return_type;\n+\tExpression *filter = nullptr;\n+\n+\tstatic vector<AggregateObject> CreateAggregateObjects(const vector<BoundAggregateExpression *> &bindings);\n+};\n+\n+struct AggregateFilterData {\n+\tAggregateFilterData(Allocator &allocator, Expression &filter_expr, const vector<LogicalType> &payload_types);\n+\n+\tidx_t ApplyFilter(DataChunk &payload);\n+\n+\tExpressionExecutor filter_executor;\n+\tDataChunk filtered_payload;\n+\tSelectionVector true_sel;\n+};\n+\n+struct AggregateFilterDataSet {\n+\tAggregateFilterDataSet();\n+\n+\tvector<unique_ptr<AggregateFilterData>> filter_data;\n+\n+public:\n+\tvoid Initialize(Allocator &allocator, const vector<AggregateObject> &aggregates,\n+\t                const vector<LogicalType> &payload_types);\n+\n+\tAggregateFilterData &GetFilterData(idx_t aggr_idx);\n+};\n+\n+} // namespace duckdb\ndiff --git a/src/include/duckdb/execution/operator/aggregate/physical_perfecthash_aggregate.hpp b/src/include/duckdb/execution/operator/aggregate/physical_perfecthash_aggregate.hpp\nindex 4b9cb8572061..70309df0f27a 100644\n--- a/src/include/duckdb/execution/operator/aggregate/physical_perfecthash_aggregate.hpp\n+++ b/src/include/duckdb/execution/operator/aggregate/physical_perfecthash_aggregate.hpp\n@@ -46,7 +46,7 @@ class PhysicalPerfectHashAggregate : public PhysicalOperator {\n \tstring ParamsToString() const override;\n \n \t//! Create a perfect aggregate hash table for this node\n-\tunique_ptr<PerfectAggregateHashTable> CreateHT(ClientContext &context) const;\n+\tunique_ptr<PerfectAggregateHashTable> CreateHT(Allocator &allocator, ClientContext &context) const;\n \n \tbool IsSink() const override {\n \t\treturn true;\ndiff --git a/src/include/duckdb/execution/operator/aggregate/physical_streaming_window.hpp b/src/include/duckdb/execution/operator/aggregate/physical_streaming_window.hpp\nindex ddf5cbaa1204..abef7ddbca04 100644\n--- a/src/include/duckdb/execution/operator/aggregate/physical_streaming_window.hpp\n+++ b/src/include/duckdb/execution/operator/aggregate/physical_streaming_window.hpp\n@@ -25,7 +25,7 @@ class PhysicalStreamingWindow : public PhysicalOperator {\n \n public:\n \tunique_ptr<GlobalOperatorState> GetGlobalOperatorState(ClientContext &context) const override;\n-\tunique_ptr<OperatorState> GetOperatorState(ClientContext &context) const override;\n+\tunique_ptr<OperatorState> GetOperatorState(ExecutionContext &context) const override;\n \n \tOperatorResultType Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n \t                           GlobalOperatorState &gstate, OperatorState &state) const override;\ndiff --git a/src/include/duckdb/execution/operator/filter/physical_filter.hpp b/src/include/duckdb/execution/operator/filter/physical_filter.hpp\nindex 9848704da7b8..ef0aece1d291 100644\n--- a/src/include/duckdb/execution/operator/filter/physical_filter.hpp\n+++ b/src/include/duckdb/execution/operator/filter/physical_filter.hpp\n@@ -24,7 +24,7 @@ class PhysicalFilter : public PhysicalOperator {\n \tunique_ptr<Expression> expression;\n \n public:\n-\tunique_ptr<OperatorState> GetOperatorState(ClientContext &context) const override;\n+\tunique_ptr<OperatorState> GetOperatorState(ExecutionContext &context) const override;\n \n \tOperatorResultType Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n \t                           GlobalOperatorState &gstate, OperatorState &state) const override;\ndiff --git a/src/include/duckdb/execution/operator/helper/physical_limit.hpp b/src/include/duckdb/execution/operator/helper/physical_limit.hpp\nindex 60370af9532d..dedec1d115dd 100644\n--- a/src/include/duckdb/execution/operator/helper/physical_limit.hpp\n+++ b/src/include/duckdb/execution/operator/helper/physical_limit.hpp\n@@ -56,10 +56,11 @@ class PhysicalLimit : public PhysicalOperator {\n \t}\n \n public:\n-\tstatic bool ComputeOffset(DataChunk &input, idx_t &limit, idx_t &offset, idx_t current_offset, idx_t &max_element,\n-\t                          Expression *limit_expression, Expression *offset_expression);\n+\tstatic bool ComputeOffset(ExecutionContext &context, DataChunk &input, idx_t &limit, idx_t &offset,\n+\t                          idx_t current_offset, idx_t &max_element, Expression *limit_expression,\n+\t                          Expression *offset_expression);\n \tstatic bool HandleOffset(DataChunk &input, idx_t &current_offset, idx_t offset, idx_t limit);\n-\tstatic Value GetDelimiter(DataChunk &input, Expression *expr);\n+\tstatic Value GetDelimiter(ExecutionContext &context, DataChunk &input, Expression *expr);\n };\n \n } // namespace duckdb\ndiff --git a/src/include/duckdb/execution/operator/helper/physical_streaming_limit.hpp b/src/include/duckdb/execution/operator/helper/physical_streaming_limit.hpp\nindex 2def2d4c0af0..7c337e1096a9 100644\n--- a/src/include/duckdb/execution/operator/helper/physical_streaming_limit.hpp\n+++ b/src/include/duckdb/execution/operator/helper/physical_streaming_limit.hpp\n@@ -27,7 +27,7 @@ class PhysicalStreamingLimit : public PhysicalOperator {\n \n public:\n \t// Operator interface\n-\tunique_ptr<OperatorState> GetOperatorState(ClientContext &context) const override;\n+\tunique_ptr<OperatorState> GetOperatorState(ExecutionContext &context) const override;\n \tunique_ptr<GlobalOperatorState> GetGlobalOperatorState(ClientContext &context) const override;\n \tOperatorResultType Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n \t                           GlobalOperatorState &gstate, OperatorState &state) const override;\ndiff --git a/src/include/duckdb/execution/operator/helper/physical_streaming_sample.hpp b/src/include/duckdb/execution/operator/helper/physical_streaming_sample.hpp\nindex 6ab9589dcbb3..146d50c283da 100644\n--- a/src/include/duckdb/execution/operator/helper/physical_streaming_sample.hpp\n+++ b/src/include/duckdb/execution/operator/helper/physical_streaming_sample.hpp\n@@ -25,7 +25,7 @@ class PhysicalStreamingSample : public PhysicalOperator {\n \n public:\n \t// Operator interface\n-\tunique_ptr<OperatorState> GetOperatorState(ClientContext &context) const override;\n+\tunique_ptr<OperatorState> GetOperatorState(ExecutionContext &context) const override;\n \tOperatorResultType Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n \t                           GlobalOperatorState &gstate, OperatorState &state) const override;\n \ndiff --git a/src/include/duckdb/execution/operator/join/perfect_hash_join_executor.hpp b/src/include/duckdb/execution/operator/join/perfect_hash_join_executor.hpp\nindex e75c1328660b..d9fa533d3333 100644\n--- a/src/include/duckdb/execution/operator/join/perfect_hash_join_executor.hpp\n+++ b/src/include/duckdb/execution/operator/join/perfect_hash_join_executor.hpp\n@@ -41,7 +41,7 @@ class PerfectHashJoinExecutor {\n public:\n \tbool CanDoPerfectHashJoin();\n \n-\tunique_ptr<OperatorState> GetOperatorState(ClientContext &context);\n+\tunique_ptr<OperatorState> GetOperatorState(ExecutionContext &context);\n \tOperatorResultType ProbePerfectHashTable(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n \t                                         OperatorState &state);\n \tbool BuildPerfectHashTable(LogicalType &type);\ndiff --git a/src/include/duckdb/execution/operator/join/physical_blockwise_nl_join.hpp b/src/include/duckdb/execution/operator/join/physical_blockwise_nl_join.hpp\nindex dd2333d48239..b6b5c4de892f 100644\n--- a/src/include/duckdb/execution/operator/join/physical_blockwise_nl_join.hpp\n+++ b/src/include/duckdb/execution/operator/join/physical_blockwise_nl_join.hpp\n@@ -25,7 +25,7 @@ class PhysicalBlockwiseNLJoin : public PhysicalJoin {\n \n public:\n \t// Operator Interface\n-\tunique_ptr<OperatorState> GetOperatorState(ClientContext &context) const override;\n+\tunique_ptr<OperatorState> GetOperatorState(ExecutionContext &context) const override;\n \tOperatorResultType Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n \t                           GlobalOperatorState &gstate, OperatorState &state) const override;\n \ndiff --git a/src/include/duckdb/execution/operator/join/physical_cross_product.hpp b/src/include/duckdb/execution/operator/join/physical_cross_product.hpp\nindex 6ce9dd78d11b..a290dd1f4004 100644\n--- a/src/include/duckdb/execution/operator/join/physical_cross_product.hpp\n+++ b/src/include/duckdb/execution/operator/join/physical_cross_product.hpp\n@@ -20,7 +20,7 @@ class PhysicalCrossProduct : public PhysicalOperator {\n \n public:\n \t// Operator Interface\n-\tunique_ptr<OperatorState> GetOperatorState(ClientContext &context) const override;\n+\tunique_ptr<OperatorState> GetOperatorState(ExecutionContext &context) const override;\n \tOperatorResultType Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n \t                           GlobalOperatorState &gstate, OperatorState &state) const override;\n \ndiff --git a/src/include/duckdb/execution/operator/join/physical_hash_join.hpp b/src/include/duckdb/execution/operator/join/physical_hash_join.hpp\nindex 336f577ea5e0..47b44cf4402a 100644\n--- a/src/include/duckdb/execution/operator/join/physical_hash_join.hpp\n+++ b/src/include/duckdb/execution/operator/join/physical_hash_join.hpp\n@@ -41,7 +41,7 @@ class PhysicalHashJoin : public PhysicalComparisonJoin {\n \n public:\n \t// Operator Interface\n-\tunique_ptr<OperatorState> GetOperatorState(ClientContext &context) const override;\n+\tunique_ptr<OperatorState> GetOperatorState(ExecutionContext &context) const override;\n \tOperatorResultType Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n \t                           GlobalOperatorState &gstate, OperatorState &state) const override;\n \ndiff --git a/src/include/duckdb/execution/operator/join/physical_index_join.hpp b/src/include/duckdb/execution/operator/join/physical_index_join.hpp\nindex 402d7104ce3e..8a2fd926d0df 100644\n--- a/src/include/duckdb/execution/operator/join/physical_index_join.hpp\n+++ b/src/include/duckdb/execution/operator/join/physical_index_join.hpp\n@@ -50,7 +50,7 @@ class PhysicalIndexJoin : public PhysicalOperator {\n \tbool lhs_first = true;\n \n public:\n-\tunique_ptr<OperatorState> GetOperatorState(ClientContext &context) const override;\n+\tunique_ptr<OperatorState> GetOperatorState(ExecutionContext &context) const override;\n \tOperatorResultType Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n \t                           GlobalOperatorState &gstate, OperatorState &state) const override;\n \ndiff --git a/src/include/duckdb/execution/operator/join/physical_nested_loop_join.hpp b/src/include/duckdb/execution/operator/join/physical_nested_loop_join.hpp\nindex 3dddc751004a..e44d4658fe25 100644\n--- a/src/include/duckdb/execution/operator/join/physical_nested_loop_join.hpp\n+++ b/src/include/duckdb/execution/operator/join/physical_nested_loop_join.hpp\n@@ -25,7 +25,7 @@ class PhysicalNestedLoopJoin : public PhysicalComparisonJoin {\n \n public:\n \t// Operator Interface\n-\tunique_ptr<OperatorState> GetOperatorState(ClientContext &context) const override;\n+\tunique_ptr<OperatorState> GetOperatorState(ExecutionContext &context) const override;\n \tOperatorResultType Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n \t                           GlobalOperatorState &gstate, OperatorState &state) const override;\n \ndiff --git a/src/include/duckdb/execution/operator/join/physical_piecewise_merge_join.hpp b/src/include/duckdb/execution/operator/join/physical_piecewise_merge_join.hpp\nindex 0493f30cf365..2f7ae80319af 100644\n--- a/src/include/duckdb/execution/operator/join/physical_piecewise_merge_join.hpp\n+++ b/src/include/duckdb/execution/operator/join/physical_piecewise_merge_join.hpp\n@@ -29,7 +29,7 @@ class PhysicalPiecewiseMergeJoin : public PhysicalRangeJoin {\n \n public:\n \t// Operator Interface\n-\tunique_ptr<OperatorState> GetOperatorState(ClientContext &context) const override;\n+\tunique_ptr<OperatorState> GetOperatorState(ExecutionContext &context) const override;\n \tOperatorResultType Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n \t                           GlobalOperatorState &gstate, OperatorState &state) const override;\n \ndiff --git a/src/include/duckdb/execution/operator/join/physical_range_join.hpp b/src/include/duckdb/execution/operator/join/physical_range_join.hpp\nindex 16f3ac6c6b10..aeff4c8c41db 100644\n--- a/src/include/duckdb/execution/operator/join/physical_range_join.hpp\n+++ b/src/include/duckdb/execution/operator/join/physical_range_join.hpp\n@@ -22,7 +22,7 @@ class PhysicalRangeJoin : public PhysicalComparisonJoin {\n public:\n \tclass LocalSortedTable {\n \tpublic:\n-\t\tLocalSortedTable(const PhysicalRangeJoin &op, const idx_t child);\n+\t\tLocalSortedTable(Allocator &allocator, const PhysicalRangeJoin &op, const idx_t child);\n \n \t\tvoid Sink(DataChunk &input, GlobalSortState &global_sort_state);\n \ndiff --git a/src/include/duckdb/execution/operator/persistent/buffered_csv_reader.hpp b/src/include/duckdb/execution/operator/persistent/buffered_csv_reader.hpp\nindex b518a1a7a8cf..7cda5b6374ad 100644\n--- a/src/include/duckdb/execution/operator/persistent/buffered_csv_reader.hpp\n+++ b/src/include/duckdb/execution/operator/persistent/buffered_csv_reader.hpp\n@@ -159,11 +159,12 @@ class BufferedCSVReader {\n \tBufferedCSVReader(ClientContext &context, BufferedCSVReaderOptions options,\n \t                  const vector<LogicalType> &requested_types = vector<LogicalType>());\n \n-\tBufferedCSVReader(FileSystem &fs, FileOpener *opener, BufferedCSVReaderOptions options,\n+\tBufferedCSVReader(FileSystem &fs, Allocator &allocator, FileOpener *opener, BufferedCSVReaderOptions options,\n \t                  const vector<LogicalType> &requested_types = vector<LogicalType>());\n \t~BufferedCSVReader();\n \n \tFileSystem &fs;\n+\tAllocator &allocator;\n \tFileOpener *opener;\n \tBufferedCSVReaderOptions options;\n \tvector<LogicalType> sql_types;\ndiff --git a/src/include/duckdb/execution/operator/projection/physical_projection.hpp b/src/include/duckdb/execution/operator/projection/physical_projection.hpp\nindex 8dea64ed758f..072c6f394274 100644\n--- a/src/include/duckdb/execution/operator/projection/physical_projection.hpp\n+++ b/src/include/duckdb/execution/operator/projection/physical_projection.hpp\n@@ -21,7 +21,7 @@ class PhysicalProjection : public PhysicalOperator {\n \tvector<unique_ptr<Expression>> select_list;\n \n public:\n-\tunique_ptr<OperatorState> GetOperatorState(ClientContext &context) const override;\n+\tunique_ptr<OperatorState> GetOperatorState(ExecutionContext &context) const override;\n \tOperatorResultType Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n \t                           GlobalOperatorState &gstate, OperatorState &state) const override;\n \ndiff --git a/src/include/duckdb/execution/operator/projection/physical_tableinout_function.hpp b/src/include/duckdb/execution/operator/projection/physical_tableinout_function.hpp\nindex 6a146be740df..2a4500a6fd81 100644\n--- a/src/include/duckdb/execution/operator/projection/physical_tableinout_function.hpp\n+++ b/src/include/duckdb/execution/operator/projection/physical_tableinout_function.hpp\n@@ -22,7 +22,7 @@ class PhysicalTableInOutFunction : public PhysicalOperator {\n \t                           idx_t estimated_cardinality);\n \n public:\n-\tunique_ptr<OperatorState> GetOperatorState(ClientContext &context) const override;\n+\tunique_ptr<OperatorState> GetOperatorState(ExecutionContext &context) const override;\n \tunique_ptr<GlobalOperatorState> GetGlobalOperatorState(ClientContext &context) const override;\n \tOperatorResultType Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n \t                           GlobalOperatorState &gstate, OperatorState &state) const override;\ndiff --git a/src/include/duckdb/execution/operator/projection/physical_unnest.hpp b/src/include/duckdb/execution/operator/projection/physical_unnest.hpp\nindex 665cb9773dc9..f7ae86e0755f 100644\n--- a/src/include/duckdb/execution/operator/projection/physical_unnest.hpp\n+++ b/src/include/duckdb/execution/operator/projection/physical_unnest.hpp\n@@ -24,7 +24,7 @@ class PhysicalUnnest : public PhysicalOperator {\n \tvector<unique_ptr<Expression>> select_list;\n \n public:\n-\tunique_ptr<OperatorState> GetOperatorState(ClientContext &context) const override;\n+\tunique_ptr<OperatorState> GetOperatorState(ExecutionContext &context) const override;\n \tOperatorResultType Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n \t                           GlobalOperatorState &gstate, OperatorState &state) const override;\n \n@@ -33,8 +33,9 @@ class PhysicalUnnest : public PhysicalOperator {\n \t}\n \n public:\n-\tstatic unique_ptr<OperatorState> GetState(ClientContext &context);\n-\tstatic OperatorResultType ExecuteInternal(ClientContext &context, DataChunk &input, DataChunk &chunk,\n+\tstatic unique_ptr<OperatorState> GetState(ExecutionContext &context,\n+\t                                          const vector<unique_ptr<Expression>> &select_list);\n+\tstatic OperatorResultType ExecuteInternal(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n \t                                          OperatorState &state, const vector<unique_ptr<Expression>> &select_list,\n \t                                          bool include_input = true);\n };\ndiff --git a/src/include/duckdb/execution/operator/scan/physical_expression_scan.hpp b/src/include/duckdb/execution/operator/scan/physical_expression_scan.hpp\nindex aa790b1cc859..560507af99c7 100644\n--- a/src/include/duckdb/execution/operator/scan/physical_expression_scan.hpp\n+++ b/src/include/duckdb/execution/operator/scan/physical_expression_scan.hpp\n@@ -27,7 +27,7 @@ class PhysicalExpressionScan : public PhysicalOperator {\n \tvector<vector<unique_ptr<Expression>>> expressions;\n \n public:\n-\tunique_ptr<OperatorState> GetOperatorState(ClientContext &context) const override;\n+\tunique_ptr<OperatorState> GetOperatorState(ExecutionContext &context) const override;\n \tOperatorResultType Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n \t                           GlobalOperatorState &gstate, OperatorState &state) const override;\n \n@@ -37,7 +37,8 @@ class PhysicalExpressionScan : public PhysicalOperator {\n \n public:\n \tbool IsFoldable() const;\n-\tvoid EvaluateExpression(idx_t expression_idx, DataChunk *child_chunk, DataChunk &result) const;\n+\tvoid EvaluateExpression(Allocator &allocator, idx_t expression_idx, DataChunk *child_chunk,\n+\t                        DataChunk &result) const;\n };\n \n } // namespace duckdb\ndiff --git a/src/include/duckdb/execution/partitionable_hashtable.hpp b/src/include/duckdb/execution/partitionable_hashtable.hpp\nindex 38ea074cd4a8..645753e78a91 100644\n--- a/src/include/duckdb/execution/partitionable_hashtable.hpp\n+++ b/src/include/duckdb/execution/partitionable_hashtable.hpp\n@@ -24,7 +24,7 @@ typedef vector<unique_ptr<GroupedAggregateHashTable>> HashTableList;\n \n class PartitionableHashTable {\n public:\n-\tPartitionableHashTable(BufferManager &buffer_manager_p, RadixPartitionInfo &partition_info_p,\n+\tPartitionableHashTable(Allocator &allocator, BufferManager &buffer_manager_p, RadixPartitionInfo &partition_info_p,\n \t                       vector<LogicalType> group_types_p, vector<LogicalType> payload_types_p,\n \t                       vector<BoundAggregateExpression *> bindings_p);\n \n@@ -38,6 +38,7 @@ class PartitionableHashTable {\n \tvoid Finalize();\n \n private:\n+\tAllocator &allocator;\n \tBufferManager &buffer_manager;\n \tvector<LogicalType> group_types;\n \tvector<LogicalType> payload_types;\ndiff --git a/src/include/duckdb/execution/perfect_aggregate_hashtable.hpp b/src/include/duckdb/execution/perfect_aggregate_hashtable.hpp\nindex 707be1b2b451..4ef4fb9c8b4b 100644\n--- a/src/include/duckdb/execution/perfect_aggregate_hashtable.hpp\n+++ b/src/include/duckdb/execution/perfect_aggregate_hashtable.hpp\n@@ -14,9 +14,10 @@ namespace duckdb {\n \n class PerfectAggregateHashTable : public BaseAggregateHashTable {\n public:\n-\tPerfectAggregateHashTable(BufferManager &buffer_manager, const vector<LogicalType> &group_types,\n-\t                          vector<LogicalType> payload_types_p, vector<AggregateObject> aggregate_objects,\n-\t                          vector<Value> group_minima, vector<idx_t> required_bits);\n+\tPerfectAggregateHashTable(Allocator &allocator, BufferManager &buffer_manager,\n+\t                          const vector<LogicalType> &group_types, vector<LogicalType> payload_types_p,\n+\t                          vector<AggregateObject> aggregate_objects, vector<Value> group_minima,\n+\t                          vector<idx_t> required_bits);\n \t~PerfectAggregateHashTable() override;\n \n public:\ndiff --git a/src/include/duckdb/execution/physical_operator.hpp b/src/include/duckdb/execution/physical_operator.hpp\nindex 12eed0698775..c3cd5407ba62 100644\n--- a/src/include/duckdb/execution/physical_operator.hpp\n+++ b/src/include/duckdb/execution/physical_operator.hpp\n@@ -130,7 +130,7 @@ class PhysicalOperator {\n \n public:\n \t// Operator interface\n-\tvirtual unique_ptr<OperatorState> GetOperatorState(ClientContext &context) const;\n+\tvirtual unique_ptr<OperatorState> GetOperatorState(ExecutionContext &context) const;\n \tvirtual unique_ptr<GlobalOperatorState> GetGlobalOperatorState(ClientContext &context) const;\n \tvirtual OperatorResultType Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n \t                                   GlobalOperatorState &gstate, OperatorState &state) const;\ndiff --git a/src/include/duckdb/execution/radix_partitioned_hashtable.hpp b/src/include/duckdb/execution/radix_partitioned_hashtable.hpp\nindex efba97e136fb..dd284ad74f8a 100644\n--- a/src/include/duckdb/execution/radix_partitioned_hashtable.hpp\n+++ b/src/include/duckdb/execution/radix_partitioned_hashtable.hpp\n@@ -48,7 +48,7 @@ class RadixPartitionedHashTable {\n \t                   vector<unique_ptr<Task>> &tasks) const;\n \n \t//! Source interface\n-\tunique_ptr<GlobalSourceState> GetGlobalSourceState() const;\n+\tunique_ptr<GlobalSourceState> GetGlobalSourceState(ClientContext &context) const;\n \tvoid GetData(ExecutionContext &context, DataChunk &chunk, GlobalSinkState &sink_state,\n \t             GlobalSourceState &gstate_p) const;\n \ndiff --git a/src/include/duckdb/execution/reservoir_sample.hpp b/src/include/duckdb/execution/reservoir_sample.hpp\nindex 81eaf7eda255..7af05d5ca087 100644\n--- a/src/include/duckdb/execution/reservoir_sample.hpp\n+++ b/src/include/duckdb/execution/reservoir_sample.hpp\n@@ -63,8 +63,7 @@ class BlockingSample {\n //! The reservoir sample class maintains a streaming sample of fixed size \"sample_count\"\n class ReservoirSample : public BlockingSample {\n public:\n-\tReservoirSample(idx_t sample_count, int64_t seed) : BlockingSample(seed), sample_count(sample_count) {\n-\t}\n+\tReservoirSample(Allocator &allocator, idx_t sample_count, int64_t seed);\n \n \t//! Add a chunk of data to the sample\n \tvoid AddToReservoir(DataChunk &input) override;\n@@ -92,7 +91,7 @@ class ReservoirSamplePercentage : public BlockingSample {\n \tconstexpr static idx_t RESERVOIR_THRESHOLD = 100000;\n \n public:\n-\tReservoirSamplePercentage(double percentage, int64_t seed);\n+\tReservoirSamplePercentage(Allocator &allocator, double percentage, int64_t seed);\n \n \t//! Add a chunk of data to the sample\n \tvoid AddToReservoir(DataChunk &input) override;\n@@ -105,6 +104,7 @@ class ReservoirSamplePercentage : public BlockingSample {\n \tvoid Finalize();\n \n private:\n+\tAllocator &allocator;\n \t//! The sample_size to sample\n \tdouble sample_percentage;\n \t//! The fixed sample size of the sub-reservoirs\ndiff --git a/src/include/duckdb/function/copy_function.hpp b/src/include/duckdb/function/copy_function.hpp\nindex 107c04db6042..c6877b178a91 100644\n--- a/src/include/duckdb/function/copy_function.hpp\n+++ b/src/include/duckdb/function/copy_function.hpp\n@@ -27,12 +27,12 @@ struct GlobalFunctionData {\n \n typedef unique_ptr<FunctionData> (*copy_to_bind_t)(ClientContext &context, CopyInfo &info, vector<string> &names,\n                                                    vector<LogicalType> &sql_types);\n-typedef unique_ptr<LocalFunctionData> (*copy_to_initialize_local_t)(ClientContext &context, FunctionData &bind_data);\n+typedef unique_ptr<LocalFunctionData> (*copy_to_initialize_local_t)(ExecutionContext &context, FunctionData &bind_data);\n typedef unique_ptr<GlobalFunctionData> (*copy_to_initialize_global_t)(ClientContext &context, FunctionData &bind_data,\n                                                                       const string &file_path);\n-typedef void (*copy_to_sink_t)(ClientContext &context, FunctionData &bind_data, GlobalFunctionData &gstate,\n+typedef void (*copy_to_sink_t)(ExecutionContext &context, FunctionData &bind_data, GlobalFunctionData &gstate,\n                                LocalFunctionData &lstate, DataChunk &input);\n-typedef void (*copy_to_combine_t)(ClientContext &context, FunctionData &bind_data, GlobalFunctionData &gstate,\n+typedef void (*copy_to_combine_t)(ExecutionContext &context, FunctionData &bind_data, GlobalFunctionData &gstate,\n                                   LocalFunctionData &lstate);\n typedef void (*copy_to_finalize_t)(ClientContext &context, FunctionData &bind_data, GlobalFunctionData &gstate);\n \ndiff --git a/src/include/duckdb/function/table/arrow.hpp b/src/include/duckdb/function/table/arrow.hpp\nindex 8fc7f6102bb1..10d65b877327 100644\n--- a/src/include/duckdb/function/table/arrow.hpp\n+++ b/src/include/duckdb/function/table/arrow.hpp\n@@ -111,7 +111,8 @@ struct ArrowTableFunction {\n \t                                                                TableFunctionInitInput &input);\n \n \t//! Initialize Local State\n-\tstatic unique_ptr<LocalTableFunctionState> ArrowScanInitLocal(ClientContext &context, TableFunctionInitInput &input,\n+\tstatic unique_ptr<LocalTableFunctionState> ArrowScanInitLocal(ExecutionContext &context,\n+\t                                                              TableFunctionInitInput &input,\n \t                                                              GlobalTableFunctionState *global_state);\n \n \t//! Scan Function\ndiff --git a/src/include/duckdb/function/table_function.hpp b/src/include/duckdb/function/table_function.hpp\nindex 51e467be492e..6b5c3dcb758b 100644\n--- a/src/include/duckdb/function/table_function.hpp\n+++ b/src/include/duckdb/function/table_function.hpp\n@@ -11,6 +11,7 @@\n #include \"duckdb/function/function.hpp\"\n #include \"duckdb/storage/statistics/node_statistics.hpp\"\n #include \"duckdb/common/enums/operator_result_type.hpp\"\n+#include \"duckdb/execution/execution_context.hpp\"\n \n #include <functional>\n \n@@ -82,14 +83,14 @@ typedef unique_ptr<FunctionData> (*table_function_bind_t)(ClientContext &context\n                                                           vector<LogicalType> &return_types, vector<string> &names);\n typedef unique_ptr<GlobalTableFunctionState> (*table_function_init_global_t)(ClientContext &context,\n                                                                              TableFunctionInitInput &input);\n-typedef unique_ptr<LocalTableFunctionState> (*table_function_init_local_t)(ClientContext &context,\n+typedef unique_ptr<LocalTableFunctionState> (*table_function_init_local_t)(ExecutionContext &context,\n                                                                            TableFunctionInitInput &input,\n                                                                            GlobalTableFunctionState *global_state);\n typedef unique_ptr<BaseStatistics> (*table_statistics_t)(ClientContext &context, const FunctionData *bind_data,\n                                                          column_t column_index);\n typedef void (*table_function_t)(ClientContext &context, TableFunctionInput &data, DataChunk &output);\n \n-typedef OperatorResultType (*table_in_out_function_t)(ClientContext &context, TableFunctionInput &data,\n+typedef OperatorResultType (*table_in_out_function_t)(ExecutionContext &context, TableFunctionInput &data,\n                                                       DataChunk &input, DataChunk &output);\n typedef idx_t (*table_function_get_batch_index_t)(ClientContext &context, const FunctionData *bind_data,\n                                                   LocalTableFunctionState *local_state,\ndiff --git a/src/include/duckdb/main/appender.hpp b/src/include/duckdb/main/appender.hpp\nindex 550bb7b25d0b..6f8724b5bd22 100644\n--- a/src/include/duckdb/main/appender.hpp\n+++ b/src/include/duckdb/main/appender.hpp\n@@ -26,6 +26,7 @@ class BaseAppender {\n \t//! The amount of chunks that will be gathered in the chunk collection before flushing\n \tstatic constexpr const idx_t FLUSH_COUNT = 100;\n \n+\tAllocator &allocator;\n \t//! The append types\n \tvector<LogicalType> types;\n \t//! The buffered data for the append\n@@ -36,8 +37,8 @@ class BaseAppender {\n \tidx_t column = 0;\n \n public:\n-\tDUCKDB_API BaseAppender();\n-\tDUCKDB_API BaseAppender(vector<LogicalType> types);\n+\tDUCKDB_API BaseAppender(Allocator &allocator);\n+\tDUCKDB_API BaseAppender(Allocator &allocator, vector<LogicalType> types);\n \tDUCKDB_API virtual ~BaseAppender();\n \n \t//! Begins a new row append, after calling this the other AppendX() functions\ndiff --git a/src/include/duckdb/main/config.hpp b/src/include/duckdb/main/config.hpp\nindex ee7ffd95dd0e..99a03f7fc889 100644\n--- a/src/include/duckdb/main/config.hpp\n+++ b/src/include/duckdb/main/config.hpp\n@@ -77,7 +77,7 @@ struct DBConfig {\n \t//! Access mode of the database (AUTOMATIC, READ_ONLY or READ_WRITE)\n \tAccessMode access_mode = AccessMode::AUTOMATIC;\n \t//! The allocator used by the system\n-\tAllocator allocator;\n+\tunique_ptr<Allocator> allocator;\n \t// Checkpoint when WAL reaches this size (default: 16MB)\n \tidx_t checkpoint_wal_size = 1 << 24;\n \t//! Whether or not to use Direct IO, bypassing operating system buffers\ndiff --git a/src/include/duckdb/optimizer/in_clause_rewriter.hpp b/src/include/duckdb/optimizer/in_clause_rewriter.hpp\nindex fac612f9d3ca..91e4e1f86d4c 100644\n--- a/src/include/duckdb/optimizer/in_clause_rewriter.hpp\n+++ b/src/include/duckdb/optimizer/in_clause_rewriter.hpp\n@@ -11,13 +11,15 @@\n #include \"duckdb/planner/logical_operator_visitor.hpp\"\n \n namespace duckdb {\n+class ClientContext;\n class Optimizer;\n \n class InClauseRewriter : public LogicalOperatorVisitor {\n public:\n-\texplicit InClauseRewriter(Optimizer &optimizer) : optimizer(optimizer) {\n+\texplicit InClauseRewriter(ClientContext &context, Optimizer &optimizer) : context(context), optimizer(optimizer) {\n \t}\n \n+\tClientContext &context;\n \tOptimizer &optimizer;\n \tunique_ptr<LogicalOperator> root;\n \ndiff --git a/src/include/duckdb/storage/arena_allocator.hpp b/src/include/duckdb/storage/arena_allocator.hpp\nnew file mode 100644\nindex 000000000000..6a398770d412\n--- /dev/null\n+++ b/src/include/duckdb/storage/arena_allocator.hpp\n@@ -0,0 +1,51 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/storage/arena_allocator.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#pragma once\n+\n+#include \"duckdb/common/common.hpp\"\n+#include \"duckdb/common/allocator.hpp\"\n+\n+namespace duckdb {\n+\n+struct ArenaChunk {\n+\tArenaChunk(Allocator &allocator, idx_t size);\n+\t~ArenaChunk();\n+\n+\tunique_ptr<AllocatedData> data;\n+\tidx_t current_position;\n+\tidx_t maximum_size;\n+\tunique_ptr<ArenaChunk> next;\n+\tArenaChunk *prev;\n+};\n+\n+class ArenaAllocator {\n+\tstatic constexpr const idx_t ARENA_ALLOCATOR_INITIAL_CAPACITY = 2048;\n+\n+public:\n+\tArenaAllocator(Allocator &allocator, idx_t initial_capacity = ARENA_ALLOCATOR_INITIAL_CAPACITY);\n+\t~ArenaAllocator();\n+\n+\tdata_ptr_t Allocate(idx_t size);\n+\tvoid Destroy();\n+\tvoid Move(ArenaAllocator &allocator);\n+\n+\tArenaChunk *GetHead();\n+\tArenaChunk *GetTail();\n+\n+\tbool IsEmpty();\n+\n+private:\n+\t//! Internal allocator that is used by the arena allocator\n+\tAllocator &allocator;\n+\tidx_t current_capacity;\n+\tunique_ptr<ArenaChunk> head;\n+\tArenaChunk *tail;\n+};\n+\n+} // namespace duckdb\ndiff --git a/src/include/duckdb/storage/buffer/block_handle.hpp b/src/include/duckdb/storage/buffer/block_handle.hpp\nindex e2fccb479994..a1f386f73f6a 100644\n--- a/src/include/duckdb/storage/buffer/block_handle.hpp\n+++ b/src/include/duckdb/storage/buffer/block_handle.hpp\n@@ -44,7 +44,8 @@ class BlockHandle {\n \t}\n \n private:\n-\tstatic unique_ptr<BufferHandle> Load(shared_ptr<BlockHandle> &handle);\n+\tstatic BufferHandle Load(shared_ptr<BlockHandle> &handle, unique_ptr<FileBuffer> buffer = nullptr);\n+\tunique_ptr<FileBuffer> UnloadAndTakeBlock();\n \tvoid Unload();\n \tbool CanUnload();\n \ndiff --git a/src/include/duckdb/storage/buffer/buffer_handle.hpp b/src/include/duckdb/storage/buffer/buffer_handle.hpp\nindex 77c5689a42df..7cde6316e896 100644\n--- a/src/include/duckdb/storage/buffer/buffer_handle.hpp\n+++ b/src/include/duckdb/storage/buffer/buffer_handle.hpp\n@@ -16,14 +16,35 @@ class FileBuffer;\n \n class BufferHandle {\n public:\n-\tBufferHandle(shared_ptr<BlockHandle> handle, FileBuffer *node);\n+\tDUCKDB_API BufferHandle();\n+\tDUCKDB_API BufferHandle(shared_ptr<BlockHandle> handle, FileBuffer *node);\n \tDUCKDB_API ~BufferHandle();\n+\t// disable copy constructors\n+\tDUCKDB_API BufferHandle(const BufferHandle &other) = delete;\n+\tDUCKDB_API BufferHandle &operator=(const BufferHandle &) = delete;\n+\t//! enable move constructors\n+\tDUCKDB_API BufferHandle(BufferHandle &&other) noexcept;\n+\tDUCKDB_API BufferHandle &operator=(BufferHandle &&) noexcept;\n \n+public:\n+\t//! Returns whether or not the BufferHandle is valid.\n+\tDUCKDB_API bool IsValid() const;\n+\t//! Returns a pointer to the buffer data. Handle must be valid.\n+\tDUCKDB_API data_ptr_t Ptr() const;\n+\t//! Returns a pointer to the buffer data. Handle must be valid.\n+\tDUCKDB_API data_ptr_t Ptr();\n+\t//! Gets the block id of the underlying block. Handle must be valid.\n+\tDUCKDB_API block_id_t GetBlockId() const;\n+\t//! Gets the underlying file buffer. Handle must be valid.\n+\tDUCKDB_API FileBuffer &GetFileBuffer();\n+\t//! Destroys the buffer handle\n+\tDUCKDB_API void Destroy();\n+\n+private:\n \t//! The block handle\n \tshared_ptr<BlockHandle> handle;\n \t//! The managed buffer node\n \tFileBuffer *node;\n-\tDUCKDB_API data_ptr_t Ptr();\n };\n \n } // namespace duckdb\ndiff --git a/src/include/duckdb/storage/buffer/managed_buffer.hpp b/src/include/duckdb/storage/buffer/managed_buffer.hpp\nindex 9130664a01b6..4897421f2529 100644\n--- a/src/include/duckdb/storage/buffer/managed_buffer.hpp\n+++ b/src/include/duckdb/storage/buffer/managed_buffer.hpp\n@@ -19,6 +19,7 @@ class DatabaseInstance;\n class ManagedBuffer : public FileBuffer {\n public:\n \tManagedBuffer(DatabaseInstance &db, idx_t size, bool can_destroy, block_id_t id);\n+\tManagedBuffer(DatabaseInstance &db, FileBuffer &source, bool can_destroy, block_id_t id);\n \n \tDatabaseInstance &db;\n \t//! Whether or not the managed buffer can be freely destroyed when unpinned.\ndiff --git a/src/include/duckdb/storage/buffer_manager.hpp b/src/include/duckdb/storage/buffer_manager.hpp\nindex b4beff62d60d..2e59c5579b10 100644\n--- a/src/include/duckdb/storage/buffer_manager.hpp\n+++ b/src/include/duckdb/storage/buffer_manager.hpp\n@@ -16,6 +16,7 @@\n #include \"duckdb/storage/buffer/block_handle.hpp\"\n #include \"duckdb/storage/buffer/buffer_handle.hpp\"\n #include \"duckdb/storage/buffer/managed_buffer.hpp\"\n+#include \"duckdb/common/allocator.hpp\"\n \n namespace duckdb {\n class DatabaseInstance;\n@@ -46,12 +47,12 @@ class BufferManager {\n \n \t//! Allocate an in-memory buffer with a single pin.\n \t//! The allocated memory is released when the buffer handle is destroyed.\n-\tDUCKDB_API unique_ptr<BufferHandle> Allocate(idx_t block_size);\n+\tDUCKDB_API BufferHandle Allocate(idx_t block_size);\n \n \t//! Reallocate an in-memory buffer that is pinned.\n \tvoid ReAllocate(shared_ptr<BlockHandle> &handle, idx_t block_size);\n \n-\tunique_ptr<BufferHandle> Pin(shared_ptr<BlockHandle> &handle);\n+\tBufferHandle Pin(shared_ptr<BlockHandle> &handle);\n \tvoid Unpin(shared_ptr<BlockHandle> &handle);\n \n \tvoid UnregisterBlock(block_id_t block_id, bool can_destroy);\n@@ -76,10 +77,14 @@ class BufferManager {\n \n \tvoid SetTemporaryDirectory(string new_dir);\n \n+\tDUCKDB_API Allocator &GetBufferAllocator();\n+\n private:\n \t//! Evict blocks until the currently used memory + extra_memory fit, returns false if this was not possible\n \t//! (i.e. not enough blocks could be evicted)\n-\tbool EvictBlocks(idx_t extra_memory, idx_t memory_limit);\n+\t//! If the \"buffer\" argument is specified AND the system can find a buffer to re-use for the given allocation size\n+\t//! \"buffer\" will be made to point to the re-usable memory. Note that this is not guaranteed.\n+\tbool EvictBlocks(idx_t extra_memory, idx_t memory_limit, unique_ptr<FileBuffer> *buffer = nullptr);\n \n \t//! Garbage collect eviction queue\n \tvoid PurgeQueue();\n@@ -87,7 +92,7 @@ class BufferManager {\n \t//! Write a temporary buffer to disk\n \tvoid WriteTemporaryBuffer(ManagedBuffer &buffer);\n \t//! Read a temporary buffer from disk\n-\tunique_ptr<FileBuffer> ReadTemporaryBuffer(block_id_t id);\n+\tunique_ptr<FileBuffer> ReadTemporaryBuffer(block_id_t id, unique_ptr<FileBuffer> buffer = nullptr);\n \t//! Get the path of the temporary buffer\n \tstring GetTemporaryPath(block_id_t id);\n \n@@ -99,6 +104,11 @@ class BufferManager {\n \n \tstring InMemoryWarning();\n \n+\tstatic data_ptr_t BufferAllocatorAllocate(PrivateAllocatorData *private_data, idx_t size);\n+\tstatic void BufferAllocatorFree(PrivateAllocatorData *private_data, data_ptr_t pointer, idx_t size);\n+\tstatic data_ptr_t BufferAllocatorRealloc(PrivateAllocatorData *private_data, data_ptr_t pointer, idx_t old_size,\n+\t                                         idx_t size);\n+\n private:\n \t//! The database instance\n \tDatabaseInstance &db;\n@@ -122,5 +132,7 @@ class BufferManager {\n \tunique_ptr<EvictionQueue> queue;\n \t//! The temporary id used for managed buffers\n \tatomic<block_id_t> temporary_id;\n+\t//! Allocator associated with the buffer manager, that passes all allocations through this buffer manager\n+\tAllocator buffer_allocator;\n };\n } // namespace duckdb\ndiff --git a/src/include/duckdb/storage/checkpoint/write_overflow_strings_to_disk.hpp b/src/include/duckdb/storage/checkpoint/write_overflow_strings_to_disk.hpp\nindex bed2259d2671..6ede20106b14 100644\n--- a/src/include/duckdb/storage/checkpoint/write_overflow_strings_to_disk.hpp\n+++ b/src/include/duckdb/storage/checkpoint/write_overflow_strings_to_disk.hpp\n@@ -21,7 +21,7 @@ class WriteOverflowStringsToDisk : public OverflowStringWriter {\n \tDatabaseInstance &db;\n \n \t//! Temporary buffer\n-\tunique_ptr<BufferHandle> handle;\n+\tBufferHandle handle;\n \t//! The block on-disk to which we are writing\n \tblock_id_t block_id;\n \t//! The offset within the current block\ndiff --git a/src/include/duckdb/storage/meta_block_reader.hpp b/src/include/duckdb/storage/meta_block_reader.hpp\nindex f0a5e9ae5b71..c14ce9fe12cc 100644\n--- a/src/include/duckdb/storage/meta_block_reader.hpp\n+++ b/src/include/duckdb/storage/meta_block_reader.hpp\n@@ -11,6 +11,7 @@\n #include \"duckdb/common/common.hpp\"\n #include \"duckdb/common/serializer.hpp\"\n #include \"duckdb/storage/block.hpp\"\n+#include \"duckdb/storage/buffer/buffer_handle.hpp\"\n \n namespace duckdb {\n class BlockHandle;\n@@ -25,7 +26,7 @@ class MetaBlockReader : public Deserializer {\n \n \tDatabaseInstance &db;\n \tshared_ptr<BlockHandle> block;\n-\tunique_ptr<BufferHandle> handle;\n+\tBufferHandle handle;\n \tidx_t offset;\n \tblock_id_t next_block;\n \ndiff --git a/src/include/duckdb/storage/string_uncompressed.hpp b/src/include/duckdb/storage/string_uncompressed.hpp\nindex ae401f5022cc..a9e639a5c44c 100644\n--- a/src/include/duckdb/storage/string_uncompressed.hpp\n+++ b/src/include/duckdb/storage/string_uncompressed.hpp\n@@ -29,7 +29,7 @@ struct StringDictionaryContainer {\n };\n \n struct StringScanState : public SegmentScanState {\n-\tunique_ptr<BufferHandle> handle;\n+\tBufferHandle handle;\n };\n \n struct UncompressedStringStorage {\n@@ -70,17 +70,17 @@ struct UncompressedStringStorage {\n \n \t\tD_ASSERT(segment.GetBlockOffset() == 0);\n \t\tauto source_data = (string_t *)data.data;\n-\t\tauto result_data = (int32_t *)(handle->node->buffer + DICTIONARY_HEADER_SIZE);\n+\t\tauto result_data = (int32_t *)(handle.Ptr() + DICTIONARY_HEADER_SIZE);\n \t\tfor (idx_t i = 0; i < count; i++) {\n \t\t\tauto source_idx = data.sel->get_index(offset + i);\n \t\t\tauto target_idx = segment.count.load();\n-\t\t\tidx_t remaining_space = RemainingSpace(segment, *handle);\n+\t\t\tidx_t remaining_space = RemainingSpace(segment, handle);\n \t\t\tif (remaining_space < sizeof(int32_t)) {\n \t\t\t\t// string index does not fit in the block at all\n \t\t\t\treturn i;\n \t\t\t}\n \t\t\tremaining_space -= sizeof(int32_t);\n-\t\t\tauto dictionary = GetDictionary(segment, *handle);\n+\t\t\tauto dictionary = GetDictionary(segment, handle);\n \t\t\tif (!data.validity.RowIsValid(source_idx)) {\n \t\t\t\t// null value is stored as a copy of the last value, this is done to be able to efficiently do the\n \t\t\t\t// string_length calculation\n@@ -90,7 +90,7 @@ struct UncompressedStringStorage {\n \t\t\t\t\tresult_data[target_idx] = 0;\n \t\t\t\t}\n \t\t\t} else {\n-\t\t\t\tauto end = handle->node->buffer + dictionary.end;\n+\t\t\t\tauto end = handle.Ptr() + dictionary.end;\n \n \t\t\t\tdictionary.Verify();\n \n@@ -150,7 +150,7 @@ struct UncompressedStringStorage {\n \t\t\t\t\t\t// now write the actual string data into the dictionary\n \t\t\t\t\t\tmemcpy(dict_pos, source_data[source_idx].GetDataUnsafe(), string_length);\n \t\t\t\t\t}\n-\t\t\t\t\tD_ASSERT(RemainingSpace(segment, *handle) <= Storage::BLOCK_SIZE);\n+\t\t\t\t\tD_ASSERT(RemainingSpace(segment, handle) <= Storage::BLOCK_SIZE);\n \t\t\t\t\t// place the dictionary offset into the set of vectors\n \t\t\t\t\tdictionary.Verify();\n \n@@ -160,7 +160,7 @@ struct UncompressedStringStorage {\n \t\t\t\t\tif (DUPLICATE_ELIMINATE) {\n \t\t\t\t\t\tseen_strings->insert({source_data[source_idx].GetString(), dictionary.size});\n \t\t\t\t\t}\n-\t\t\t\t\tSetDictionary(segment, *handle, dictionary);\n+\t\t\t\t\tSetDictionary(segment, handle, dictionary);\n \t\t\t\t}\n \t\t\t}\n \t\t\tsegment.count++;\ndiff --git a/src/include/duckdb/storage/table/column_checkpoint_state.hpp b/src/include/duckdb/storage/table/column_checkpoint_state.hpp\nindex d25b5e91a58a..bba2ce0d996e 100644\n--- a/src/include/duckdb/storage/table/column_checkpoint_state.hpp\n+++ b/src/include/duckdb/storage/table/column_checkpoint_state.hpp\n@@ -32,9 +32,7 @@ struct ColumnCheckpointState {\n \tunique_ptr<BaseStatistics> global_stats;\n \n public:\n-\tvirtual unique_ptr<BaseStatistics> GetStatistics() {\n-\t\treturn global_stats->Copy();\n-\t}\n+\tvirtual unique_ptr<BaseStatistics> GetStatistics();\n \n \tvirtual void FlushSegment(unique_ptr<ColumnSegment> segment, idx_t segment_size);\n \tvirtual void FlushToDisk();\ndiff --git a/src/include/duckdb/storage/table/row_group.hpp b/src/include/duckdb/storage/table/row_group.hpp\nindex c4838ea9b855..7d6c1f5edade 100644\n--- a/src/include/duckdb/storage/table/row_group.hpp\n+++ b/src/include/duckdb/storage/table/row_group.hpp\n@@ -129,7 +129,8 @@ class RowGroup : public SegmentBase {\n \tvoid UpdateColumn(Transaction &transaction, DataChunk &updates, Vector &row_ids,\n \t                  const vector<column_t> &column_path);\n \n-\tvoid MergeStatistics(idx_t column_idx, BaseStatistics &other);\n+\tvoid MergeStatistics(idx_t column_idx, const BaseStatistics &other);\n+\tvoid MergeIntoStatistics(idx_t column_idx, BaseStatistics &other);\n \tunique_ptr<BaseStatistics> GetStatistics(idx_t column_idx);\n \n \tvoid GetStorageInfo(idx_t row_group_index, vector<vector<Value>> &result);\ndiff --git a/src/include/duckdb/storage/table/scan_state.hpp b/src/include/duckdb/storage/table/scan_state.hpp\nindex 743c6171987f..6f0b756d9886 100644\n--- a/src/include/duckdb/storage/table/scan_state.hpp\n+++ b/src/include/duckdb/storage/table/scan_state.hpp\n@@ -35,7 +35,7 @@ struct IndexScanState {\n \t}\n };\n \n-typedef unordered_map<block_id_t, unique_ptr<BufferHandle>> buffer_handle_set_t;\n+typedef unordered_map<block_id_t, BufferHandle> buffer_handle_set_t;\n \n struct ColumnScanState {\n \t//! The column segment that is currently being scanned\n@@ -67,6 +67,8 @@ struct ColumnFetchState {\n \tbuffer_handle_set_t handles;\n \t//! Any child states of the fetch\n \tvector<unique_ptr<ColumnFetchState>> child_states;\n+\n+\tBufferHandle &GetOrInsertHandle(ColumnSegment &segment);\n };\n \n struct LocalScanState {\ndiff --git a/src/include/duckdb/transaction/local_storage.hpp b/src/include/duckdb/transaction/local_storage.hpp\nindex caecb83660cc..36244b688d72 100644\n--- a/src/include/duckdb/transaction/local_storage.hpp\n+++ b/src/include/duckdb/transaction/local_storage.hpp\n@@ -22,6 +22,8 @@ class LocalTableStorage : public std::enable_shared_from_this<LocalTableStorage>\n \t~LocalTableStorage();\n \n \tDataTable &table;\n+\n+\tAllocator &allocator;\n \t//! The main chunk collection holding the data\n \tChunkCollection collection;\n \t//! The set of unique indexes\ndiff --git a/src/include/duckdb/transaction/transaction.hpp b/src/include/duckdb/transaction/transaction.hpp\nindex a28526389884..4687a4a1319e 100644\n--- a/src/include/duckdb/transaction/transaction.hpp\n+++ b/src/include/duckdb/transaction/transaction.hpp\n@@ -36,11 +36,7 @@ struct UpdateInfo;\n class Transaction {\n public:\n \tTransaction(weak_ptr<ClientContext> context, transaction_t start_time, transaction_t transaction_id,\n-\t            timestamp_t start_timestamp, idx_t catalog_version)\n-\t    : context(move(context)), start_time(start_time), transaction_id(transaction_id), commit_id(0),\n-\t      highest_active_query(0), active_query(MAXIMUM_QUERY_ID), start_timestamp(start_timestamp),\n-\t      catalog_version(catalog_version), storage(*this), is_invalidated(false) {\n-\t}\n+\t            timestamp_t start_timestamp, idx_t catalog_version);\n \n \tweak_ptr<ClientContext> context;\n \t//! The start timestamp of this transaction\ndiff --git a/src/include/duckdb/transaction/undo_buffer.hpp b/src/include/duckdb/transaction/undo_buffer.hpp\nindex d87d77ebab83..80e5e25d9a0d 100644\n--- a/src/include/duckdb/transaction/undo_buffer.hpp\n+++ b/src/include/duckdb/transaction/undo_buffer.hpp\n@@ -10,37 +10,25 @@\n \n #include \"duckdb/common/common.hpp\"\n #include \"duckdb/common/enums/undo_flags.hpp\"\n+#include \"duckdb/storage/arena_allocator.hpp\"\n \n namespace duckdb {\n \n class WriteAheadLog;\n \n-struct UndoChunk {\n-\texplicit UndoChunk(idx_t size);\n-\t~UndoChunk();\n-\n-\tdata_ptr_t WriteEntry(UndoFlags type, uint32_t len);\n-\n-\tunique_ptr<data_t[]> data;\n-\tidx_t current_position;\n-\tidx_t maximum_size;\n-\tunique_ptr<UndoChunk> next;\n-\tUndoChunk *prev;\n-};\n-\n //! The undo buffer of a transaction is used to hold previous versions of tuples\n //! that might be required in the future (because of rollbacks or previous\n //! transactions accessing them)\n class UndoBuffer {\n public:\n \tstruct IteratorState {\n-\t\tUndoChunk *current;\n+\t\tArenaChunk *current;\n \t\tdata_ptr_t start;\n \t\tdata_ptr_t end;\n \t};\n \n public:\n-\tUndoBuffer();\n+\tUndoBuffer(const shared_ptr<ClientContext> &context);\n \n \t//! Reserve space for an entry of the specified type and length in the undo\n \t//! buffer\n@@ -60,8 +48,7 @@ class UndoBuffer {\n \tvoid Rollback() noexcept;\n \n private:\n-\tunique_ptr<UndoChunk> head;\n-\tUndoChunk *tail;\n+\tArenaAllocator allocator;\n \n private:\n \ttemplate <class T>\ndiff --git a/src/main/appender.cpp b/src/main/appender.cpp\nindex 39abc5e244ad..8c1a236204e0 100644\n--- a/src/main/appender.cpp\n+++ b/src/main/appender.cpp\n@@ -12,10 +12,11 @@\n \n namespace duckdb {\n \n-BaseAppender::BaseAppender() : column(0) {\n+BaseAppender::BaseAppender(Allocator &allocator) : allocator(allocator), collection(allocator), column(0) {\n }\n \n-BaseAppender::BaseAppender(vector<LogicalType> types_p) : types(move(types_p)), column(0) {\n+BaseAppender::BaseAppender(Allocator &allocator, vector<LogicalType> types_p)\n+    : allocator(allocator), types(move(types_p)), collection(allocator), column(0) {\n \tInitializeChunk();\n }\n \n@@ -35,7 +36,7 @@ void BaseAppender::Destructor() {\n }\n \n InternalAppender::InternalAppender(ClientContext &context_p, TableCatalogEntry &table_p)\n-    : BaseAppender(table_p.GetTypes()), context(context_p), table(table_p) {\n+    : BaseAppender(Allocator::DefaultAllocator(), table_p.GetTypes()), context(context_p), table(table_p) {\n }\n \n InternalAppender::~InternalAppender() {\n@@ -43,7 +44,7 @@ InternalAppender::~InternalAppender() {\n }\n \n Appender::Appender(Connection &con, const string &schema_name, const string &table_name)\n-    : BaseAppender(), context(con.context) {\n+    : BaseAppender(Allocator::DefaultAllocator()), context(con.context) {\n \tdescription = con.TableInfo(schema_name, table_name);\n \tif (!description) {\n \t\t// table could not be found\n@@ -64,7 +65,7 @@ Appender::~Appender() {\n \n void BaseAppender::InitializeChunk() {\n \tchunk = make_unique<DataChunk>();\n-\tchunk->Initialize(types);\n+\tchunk->Initialize(allocator, types);\n }\n \n void BaseAppender::BeginRow() {\ndiff --git a/src/main/capi/data_chunk-c.cpp b/src/main/capi/data_chunk-c.cpp\nindex cfae42324825..d6232e92de43 100644\n--- a/src/main/capi/data_chunk-c.cpp\n+++ b/src/main/capi/data_chunk-c.cpp\n@@ -14,7 +14,7 @@ duckdb_data_chunk duckdb_create_data_chunk(duckdb_logical_type *ctypes, idx_t co\n \t}\n \n \tauto result = new duckdb::DataChunk();\n-\tresult->Initialize(types);\n+\tresult->Initialize(duckdb::Allocator::DefaultAllocator(), types);\n \treturn result;\n }\n \ndiff --git a/src/main/capi/table_function-c.cpp b/src/main/capi/table_function-c.cpp\nindex bb27a22e05fa..ab0bd64bdf5e 100644\n--- a/src/main/capi/table_function-c.cpp\n+++ b/src/main/capi/table_function-c.cpp\n@@ -133,7 +133,7 @@ unique_ptr<GlobalTableFunctionState> CTableFunctionInit(ClientContext &context,\n \treturn move(result);\n }\n \n-unique_ptr<LocalTableFunctionState> CTableFunctionLocalInit(ClientContext &context, TableFunctionInitInput &data_p,\n+unique_ptr<LocalTableFunctionState> CTableFunctionLocalInit(ExecutionContext &context, TableFunctionInitInput &data_p,\n                                                             GlobalTableFunctionState *gstate) {\n \tauto &bind_data = (CTableBindData &)*data_p.bind_data;\n \tauto result = make_unique<CTableLocalInitData>();\ndiff --git a/src/main/connection.cpp b/src/main/connection.cpp\nindex 23819f9c404b..f2194c2f4582 100644\n--- a/src/main/connection.cpp\n+++ b/src/main/connection.cpp\n@@ -120,7 +120,7 @@ unique_ptr<LogicalOperator> Connection::ExtractPlan(const string &query) {\n }\n \n void Connection::Append(TableDescription &description, DataChunk &chunk) {\n-\tChunkCollection collection;\n+\tChunkCollection collection(*context);\n \tcollection.Append(chunk);\n \tAppend(description, collection);\n }\ndiff --git a/src/main/database.cpp b/src/main/database.cpp\nindex 9ffaf00b3269..1c3044e599ae 100644\n--- a/src/main/database.cpp\n+++ b/src/main/database.cpp\n@@ -190,7 +190,7 @@ Allocator &Allocator::Get(ClientContext &context) {\n }\n \n Allocator &Allocator::Get(DatabaseInstance &db) {\n-\treturn db.config.allocator;\n+\treturn *db.config.allocator;\n }\n \n void DatabaseInstance::Configure(DBConfig &new_config) {\n@@ -223,6 +223,9 @@ void DatabaseInstance::Configure(DBConfig &new_config) {\n \tconfig.load_extensions = new_config.load_extensions;\n \tconfig.force_compression = new_config.force_compression;\n \tconfig.allocator = move(new_config.allocator);\n+\tif (!config.allocator) {\n+\t\tconfig.allocator = make_unique<Allocator>();\n+\t}\n \tconfig.checkpoint_wal_size = new_config.checkpoint_wal_size;\n \tconfig.use_direct_io = new_config.use_direct_io;\n \tconfig.temporary_directory = new_config.temporary_directory;\ndiff --git a/src/main/materialized_query_result.cpp b/src/main/materialized_query_result.cpp\nindex 54a85bfa7f21..57cf8fbba135 100644\n--- a/src/main/materialized_query_result.cpp\n+++ b/src/main/materialized_query_result.cpp\n@@ -5,13 +5,13 @@ namespace duckdb {\n \n MaterializedQueryResult::MaterializedQueryResult(StatementType statement_type, StatementProperties properties,\n                                                  vector<LogicalType> types, vector<string> names,\n-                                                 const shared_ptr<ClientContext> &context)\n+                                                 const shared_ptr<ClientContext> &context_p)\n     : QueryResult(QueryResultType::MATERIALIZED_RESULT, statement_type, properties, move(types), move(names)),\n-      context(context) {\n+      collection(Allocator::DefaultAllocator()), context(context_p) {\n }\n \n MaterializedQueryResult::MaterializedQueryResult(string error)\n-    : QueryResult(QueryResultType::MATERIALIZED_RESULT, move(error)) {\n+    : QueryResult(QueryResultType::MATERIALIZED_RESULT, move(error)), collection(Allocator::DefaultAllocator()) {\n }\n \n Value MaterializedQueryResult::GetValue(idx_t column, idx_t index) {\ndiff --git a/src/main/relation/setop_relation.cpp b/src/main/relation/setop_relation.cpp\nindex 1cc228fc2820..f9251507e0ce 100644\n--- a/src/main/relation/setop_relation.cpp\n+++ b/src/main/relation/setop_relation.cpp\n@@ -1,6 +1,7 @@\n #include \"duckdb/main/relation/setop_relation.hpp\"\n #include \"duckdb/main/client_context.hpp\"\n #include \"duckdb/parser/query_node/set_operation_node.hpp\"\n+#include \"duckdb/parser/result_modifier.hpp\"\n \n namespace duckdb {\n \n@@ -16,6 +17,9 @@ SetOpRelation::SetOpRelation(shared_ptr<Relation> left_p, shared_ptr<Relation> r\n \n unique_ptr<QueryNode> SetOpRelation::GetQueryNode() {\n \tauto result = make_unique<SetOperationNode>();\n+\tif (setop_type == SetOperationType::EXCEPT || setop_type == SetOperationType::INTERSECT) {\n+\t\tresult->modifiers.push_back(make_unique<DistinctModifier>());\n+\t}\n \tresult->left = left->GetQueryNode();\n \tresult->right = right->GetQueryNode();\n \tresult->setop_type = setop_type;\ndiff --git a/src/optimizer/in_clause_rewriter.cpp b/src/optimizer/in_clause_rewriter.cpp\nindex 2887e2fb1136..f1a3e0114087 100644\n--- a/src/optimizer/in_clause_rewriter.cpp\n+++ b/src/optimizer/in_clause_rewriter.cpp\n@@ -65,9 +65,9 @@ unique_ptr<Expression> InClauseRewriter::VisitReplace(BoundOperatorExpression &e\n \t// generate a mark join that replaces this IN expression\n \t// first generate a ChunkCollection from the set of expressions\n \tvector<LogicalType> types = {in_type};\n-\tauto collection = make_unique<ChunkCollection>();\n+\tauto collection = make_unique<ChunkCollection>(context);\n \tDataChunk chunk;\n-\tchunk.Initialize(types);\n+\tchunk.Initialize(context, types);\n \tfor (idx_t i = 1; i < expr.children.size(); i++) {\n \t\t// resolve this expression to a constant\n \t\tauto value = ExpressionExecutor::EvaluateScalar(*expr.children[i]);\ndiff --git a/src/optimizer/optimizer.cpp b/src/optimizer/optimizer.cpp\nindex 1b302f1b9f67..f56c28cb3458 100644\n--- a/src/optimizer/optimizer.cpp\n+++ b/src/optimizer/optimizer.cpp\n@@ -83,7 +83,7 @@ unique_ptr<LogicalOperator> Optimizer::Optimize(unique_ptr<LogicalOperator> plan\n \t});\n \n \tRunOptimizer(OptimizerType::IN_CLAUSE, [&]() {\n-\t\tInClauseRewriter rewriter(*this);\n+\t\tInClauseRewriter rewriter(context, *this);\n \t\tplan = rewriter.Rewrite(move(plan));\n \t});\n \ndiff --git a/src/parallel/pipeline_executor.cpp b/src/parallel/pipeline_executor.cpp\nindex e62fc64e12d7..4a0b527a6510 100644\n--- a/src/parallel/pipeline_executor.cpp\n+++ b/src/parallel/pipeline_executor.cpp\n@@ -20,9 +20,9 @@ PipelineExecutor::PipelineExecutor(ClientContext &context_p, Pipeline &pipeline_\n \t\tauto prev_operator = i == 0 ? pipeline.source : pipeline.operators[i - 1];\n \t\tauto current_operator = pipeline.operators[i];\n \t\tauto chunk = make_unique<DataChunk>();\n-\t\tchunk->Initialize(prev_operator->GetTypes());\n+\t\tchunk->Initialize(Allocator::Get(context.client), prev_operator->GetTypes());\n \t\tintermediate_chunks.push_back(move(chunk));\n-\t\tintermediate_states.push_back(current_operator->GetOperatorState(context.client));\n+\t\tintermediate_states.push_back(current_operator->GetOperatorState(context));\n \t\tif (can_cache_in_pipeline && current_operator->RequiresCache()) {\n \t\t\tauto &cache_types = current_operator->GetTypes();\n \t\t\tbool can_cache = true;\n@@ -36,7 +36,7 @@ PipelineExecutor::PipelineExecutor(ClientContext &context_p, Pipeline &pipeline_\n \t\t\t\tcontinue;\n \t\t\t}\n \t\t\tcached_chunks[i] = make_unique<DataChunk>();\n-\t\t\tcached_chunks[i]->Initialize(current_operator->GetTypes());\n+\t\t\tcached_chunks[i]->Initialize(Allocator::Get(context.client), current_operator->GetTypes());\n \t\t}\n \t\tif (current_operator->IsSink() && current_operator->sink_state->state == SinkFinalizeType::NO_OUTPUT_POSSIBLE) {\n \t\t\t// one of the operators has already figured out no output is possible\n@@ -184,7 +184,7 @@ void PipelineExecutor::CacheChunk(DataChunk &current_chunk, idx_t operator_idx)\n \t\t\tif (chunk_cache.size() >= (STANDARD_VECTOR_SIZE - CACHE_THRESHOLD)) {\n \t\t\t\t// chunk cache full: return it\n \t\t\t\tcurrent_chunk.Move(chunk_cache);\n-\t\t\t\tchunk_cache.Initialize(pipeline.operators[operator_idx]->GetTypes());\n+\t\t\t\tchunk_cache.Initialize(Allocator::Get(context.client), pipeline.operators[operator_idx]->GetTypes());\n \t\t\t} else {\n \t\t\t\t// chunk cache not full: probe again\n \t\t\t\tcurrent_chunk.Reset();\n@@ -345,7 +345,7 @@ void PipelineExecutor::FetchFromSource(DataChunk &result) {\n \n void PipelineExecutor::InitializeChunk(DataChunk &chunk) {\n \tPhysicalOperator *last_op = pipeline.operators.empty() ? pipeline.source : pipeline.operators.back();\n-\tchunk.Initialize(last_op->GetTypes());\n+\tchunk.Initialize(Allocator::DefaultAllocator(), last_op->GetTypes());\n }\n \n void PipelineExecutor::StartOperator(PhysicalOperator *op) {\ndiff --git a/src/parallel/thread_context.cpp b/src/parallel/thread_context.cpp\nindex 5927ea180e99..049a8fcf9bbe 100644\n--- a/src/parallel/thread_context.cpp\n+++ b/src/parallel/thread_context.cpp\n@@ -1,5 +1,5 @@\n #include \"duckdb/parallel/thread_context.hpp\"\n-\n+#include \"duckdb/execution/execution_context.hpp\"\n #include \"duckdb/main/client_context.hpp\"\n \n namespace duckdb {\ndiff --git a/src/storage/CMakeLists.txt b/src/storage/CMakeLists.txt\nindex a947ec6958b2..a8e02b4ca637 100644\n--- a/src/storage/CMakeLists.txt\n+++ b/src/storage/CMakeLists.txt\n@@ -7,6 +7,7 @@ add_subdirectory(table)\n add_library_unity(\n   duckdb_storage\n   OBJECT\n+  arena_allocator.cpp\n   buffer_manager.cpp\n   checkpoint_manager.cpp\n   block.cpp\ndiff --git a/src/storage/arena_allocator.cpp b/src/storage/arena_allocator.cpp\nnew file mode 100644\nindex 000000000000..a15a99b4841a\n--- /dev/null\n+++ b/src/storage/arena_allocator.cpp\n@@ -0,0 +1,75 @@\n+#include \"duckdb/storage/arena_allocator.hpp\"\n+#include \"duckdb/common/assert.hpp\"\n+\n+namespace duckdb {\n+\n+ArenaChunk::ArenaChunk(Allocator &allocator, idx_t size) : current_position(0), maximum_size(size), prev(nullptr) {\n+\tD_ASSERT(size > 0);\n+\tdata = allocator.Allocate(size);\n+}\n+ArenaChunk::~ArenaChunk() {\n+\tif (next) {\n+\t\tauto current_next = move(next);\n+\t\twhile (current_next) {\n+\t\t\tcurrent_next = move(current_next->next);\n+\t\t}\n+\t}\n+}\n+\n+ArenaAllocator::ArenaAllocator(Allocator &allocator, idx_t initial_capacity) : allocator(allocator) {\n+\thead = nullptr;\n+\ttail = nullptr;\n+\tcurrent_capacity = initial_capacity;\n+}\n+\n+ArenaAllocator::~ArenaAllocator() {\n+}\n+\n+data_ptr_t ArenaAllocator::Allocate(idx_t len) {\n+\tD_ASSERT(!head || head->current_position <= head->maximum_size);\n+\tif (!head || head->current_position + len > head->maximum_size) {\n+\t\tdo {\n+\t\t\tcurrent_capacity *= 2;\n+\t\t} while (current_capacity < len);\n+\t\tauto new_chunk = make_unique<ArenaChunk>(allocator, current_capacity);\n+\t\tif (head) {\n+\t\t\thead->prev = new_chunk.get();\n+\t\t\tnew_chunk->next = move(head);\n+\t\t} else {\n+\t\t\ttail = new_chunk.get();\n+\t\t}\n+\t\thead = move(new_chunk);\n+\t}\n+\tD_ASSERT(head->current_position + len <= head->maximum_size);\n+\tauto result = head->data->get() + head->current_position;\n+\thead->current_position += len;\n+\treturn result;\n+}\n+\n+void ArenaAllocator::Destroy() {\n+\thead = nullptr;\n+\ttail = nullptr;\n+\tcurrent_capacity = ARENA_ALLOCATOR_INITIAL_CAPACITY;\n+}\n+\n+void ArenaAllocator::Move(ArenaAllocator &other) {\n+\tD_ASSERT(!other.head);\n+\tother.tail = tail;\n+\tother.head = move(head);\n+\tother.current_capacity = current_capacity;\n+\tDestroy();\n+}\n+\n+ArenaChunk *ArenaAllocator::GetHead() {\n+\treturn head.get();\n+}\n+\n+ArenaChunk *ArenaAllocator::GetTail() {\n+\treturn tail;\n+}\n+\n+bool ArenaAllocator::IsEmpty() {\n+\treturn head == nullptr;\n+}\n+\n+} // namespace duckdb\ndiff --git a/src/storage/buffer/buffer_handle.cpp b/src/storage/buffer/buffer_handle.cpp\nindex f4a138b89c81..08fa1e9fc39e 100644\n--- a/src/storage/buffer/buffer_handle.cpp\n+++ b/src/storage/buffer/buffer_handle.cpp\n@@ -3,16 +3,59 @@\n \n namespace duckdb {\n \n+BufferHandle::BufferHandle() : handle(nullptr), node(nullptr) {\n+}\n+\n BufferHandle::BufferHandle(shared_ptr<BlockHandle> handle, FileBuffer *node) : handle(move(handle)), node(node) {\n }\n \n+BufferHandle::BufferHandle(BufferHandle &&other) noexcept {\n+\tstd::swap(node, other.node);\n+\tstd::swap(handle, other.handle);\n+}\n+\n+BufferHandle &BufferHandle::operator=(BufferHandle &&other) noexcept {\n+\tstd::swap(node, other.node);\n+\tstd::swap(handle, other.handle);\n+\treturn *this;\n+}\n+\n BufferHandle::~BufferHandle() {\n-\tauto &buffer_manager = BufferManager::GetBufferManager(handle->db);\n-\tbuffer_manager.Unpin(handle);\n+\tDestroy();\n+}\n+\n+bool BufferHandle::IsValid() const {\n+\treturn node != nullptr;\n+}\n+\n+data_ptr_t BufferHandle::Ptr() const {\n+\tD_ASSERT(IsValid());\n+\treturn node->buffer;\n }\n \n data_ptr_t BufferHandle::Ptr() {\n+\tD_ASSERT(IsValid());\n \treturn node->buffer;\n }\n \n+block_id_t BufferHandle::GetBlockId() const {\n+\tD_ASSERT(handle);\n+\treturn handle->BlockId();\n+}\n+\n+void BufferHandle::Destroy() {\n+\tif (!handle) {\n+\t\treturn;\n+\t}\n+\tauto &buffer_manager = BufferManager::GetBufferManager(handle->db);\n+\tbuffer_manager.Unpin(handle);\n+\thandle.reset();\n+\tnode = nullptr;\n+}\n+\n+FileBuffer &BufferHandle::GetFileBuffer() {\n+\tD_ASSERT(node);\n+\treturn *node;\n+}\n+\n } // namespace duckdb\ndiff --git a/src/storage/buffer/managed_buffer.cpp b/src/storage/buffer/managed_buffer.cpp\nindex 7659b4012f10..dc3d98ec2141 100644\n--- a/src/storage/buffer/managed_buffer.cpp\n+++ b/src/storage/buffer/managed_buffer.cpp\n@@ -12,4 +12,10 @@ ManagedBuffer::ManagedBuffer(DatabaseInstance &db, idx_t size, bool can_destroy,\n \tD_ASSERT(size >= Storage::BLOCK_SIZE);\n }\n \n+ManagedBuffer::ManagedBuffer(DatabaseInstance &db, FileBuffer &source, bool can_destroy, block_id_t id)\n+    : FileBuffer(source, FileBufferType::MANAGED_BUFFER), db(db), can_destroy(can_destroy), id(id) {\n+\tD_ASSERT(id >= MAXIMUM_BLOCK);\n+\tD_ASSERT(size >= Storage::BLOCK_SIZE);\n+}\n+\n } // namespace duckdb\ndiff --git a/src/storage/buffer_manager.cpp b/src/storage/buffer_manager.cpp\nindex c95fdec3769d..106e2b0f4b2b 100644\n--- a/src/storage/buffer_manager.cpp\n+++ b/src/storage/buffer_manager.cpp\n@@ -2,11 +2,19 @@\n \n #include \"duckdb/common/allocator.hpp\"\n #include \"duckdb/common/exception.hpp\"\n+#include \"duckdb/common/set.hpp\"\n #include \"duckdb/parallel/concurrentqueue.hpp\"\n #include \"duckdb/storage/storage_manager.hpp\"\n \n namespace duckdb {\n \n+struct BufferAllocatorData : PrivateAllocatorData {\n+\texplicit BufferAllocatorData(BufferManager &manager) : manager(manager) {\n+\t}\n+\n+\tBufferManager &manager;\n+};\n+\n BlockHandle::BlockHandle(DatabaseInstance &db, block_id_t block_id_p)\n     : db(db), readers(0), block_id(block_id_p), buffer(nullptr), eviction_timestamp(0), can_destroy(false) {\n \teviction_timestamp = 0;\n@@ -34,35 +42,73 @@ BlockHandle::~BlockHandle() {\n \tbuffer_manager.UnregisterBlock(block_id, can_destroy);\n }\n \n-unique_ptr<BufferHandle> BlockHandle::Load(shared_ptr<BlockHandle> &handle) {\n+unique_ptr<Block> AllocateBlock(Allocator &allocator, unique_ptr<FileBuffer> reusable_buffer, block_id_t block_id) {\n+\tif (reusable_buffer) {\n+\t\t// re-usable buffer: re-use it\n+\t\tif (reusable_buffer->type == FileBufferType::BLOCK) {\n+\t\t\t// we can reuse the buffer entirely\n+\t\t\tauto &block = (Block &)*reusable_buffer;\n+\t\t\tblock.id = block_id;\n+\t\t\treturn unique_ptr_cast<FileBuffer, Block>(move(reusable_buffer));\n+\t\t}\n+\t\tauto block = make_unique<Block>(*reusable_buffer, block_id);\n+\t\treusable_buffer.reset();\n+\t\treturn block;\n+\t} else {\n+\t\t// no re-usable buffer: allocate a new block\n+\t\treturn make_unique<Block>(allocator, block_id);\n+\t}\n+}\n+\n+unique_ptr<ManagedBuffer> AllocateManagedBuffer(DatabaseInstance &db, unique_ptr<FileBuffer> reusable_buffer,\n+                                                idx_t size, bool can_destroy, block_id_t id) {\n+\tif (reusable_buffer) {\n+\t\t// re-usable buffer: re-use it\n+\t\tif (reusable_buffer->type == FileBufferType::MANAGED_BUFFER) {\n+\t\t\t// we can reuse the buffer entirely\n+\t\t\tauto &managed = (ManagedBuffer &)*reusable_buffer;\n+\t\t\tmanaged.id = id;\n+\t\t\tmanaged.can_destroy = can_destroy;\n+\t\t\treturn unique_ptr_cast<FileBuffer, ManagedBuffer>(move(reusable_buffer));\n+\t\t}\n+\t\tauto buffer = make_unique<ManagedBuffer>(db, *reusable_buffer, can_destroy, id);\n+\t\treusable_buffer.reset();\n+\t\treturn buffer;\n+\t} else {\n+\t\t// no re-usable buffer: allocate a new buffer\n+\t\treturn make_unique<ManagedBuffer>(db, size, can_destroy, id);\n+\t}\n+}\n+\n+BufferHandle BlockHandle::Load(shared_ptr<BlockHandle> &handle, unique_ptr<FileBuffer> reusable_buffer) {\n \tif (handle->state == BlockState::BLOCK_LOADED) {\n \t\t// already loaded\n \t\tD_ASSERT(handle->buffer);\n-\t\treturn make_unique<BufferHandle>(handle, handle->buffer.get());\n+\t\treturn BufferHandle(handle, handle->buffer.get());\n \t}\n \n \tauto &buffer_manager = BufferManager::GetBufferManager(handle->db);\n \tauto &block_manager = BlockManager::GetBlockManager(handle->db);\n \tif (handle->block_id < MAXIMUM_BLOCK) {\n-\t\tauto block = make_unique<Block>(Allocator::Get(handle->db), handle->block_id);\n+\t\tauto block = AllocateBlock(Allocator::Get(handle->db), move(reusable_buffer), handle->block_id);\n \t\tblock_manager.Read(*block);\n \t\thandle->buffer = move(block);\n \t} else {\n \t\tif (handle->can_destroy) {\n-\t\t\treturn nullptr;\n+\t\t\treturn BufferHandle();\n \t\t} else {\n-\t\t\thandle->buffer = buffer_manager.ReadTemporaryBuffer(handle->block_id);\n+\t\t\thandle->buffer = buffer_manager.ReadTemporaryBuffer(handle->block_id, move(reusable_buffer));\n \t\t}\n \t}\n \thandle->state = BlockState::BLOCK_LOADED;\n-\treturn make_unique<BufferHandle>(handle, handle->buffer.get());\n+\treturn BufferHandle(handle, handle->buffer.get());\n }\n \n-void BlockHandle::Unload() {\n+unique_ptr<FileBuffer> BlockHandle::UnloadAndTakeBlock() {\n \tauto &buffer_manager = BufferManager::GetBufferManager(db);\n \tif (state == BlockState::BLOCK_UNLOADED) {\n \t\t// already unloaded: nothing to do\n-\t\treturn;\n+\t\treturn nullptr;\n \t}\n \tD_ASSERT(CanUnload());\n \tD_ASSERT(memory_usage >= Storage::BLOCK_ALLOC_SIZE);\n@@ -71,9 +117,14 @@ void BlockHandle::Unload() {\n \t\t// temporary block that cannot be destroyed: write to temporary file\n \t\tbuffer_manager.WriteTemporaryBuffer((ManagedBuffer &)*buffer);\n \t}\n-\tbuffer.reset();\n \tbuffer_manager.current_memory -= memory_usage;\n \tstate = BlockState::BLOCK_UNLOADED;\n+\treturn move(buffer);\n+}\n+\n+void BlockHandle::Unload() {\n+\tauto block = UnloadAndTakeBlock();\n+\tblock.reset();\n }\n \n bool BlockHandle::CanUnload() {\n@@ -96,6 +147,8 @@ bool BlockHandle::CanUnload() {\n }\n \n struct BufferEvictionNode {\n+\tBufferEvictionNode() {\n+\t}\n \tBufferEvictionNode(weak_ptr<BlockHandle> handle_p, idx_t timestamp_p)\n \t    : handle(move(handle_p)), timestamp(timestamp_p) {\n \t\tD_ASSERT(!handle.expired());\n@@ -127,30 +180,25 @@ struct BufferEvictionNode {\n \t}\n };\n \n-typedef duckdb_moodycamel::ConcurrentQueue<unique_ptr<BufferEvictionNode>> eviction_queue_t;\n+typedef duckdb_moodycamel::ConcurrentQueue<BufferEvictionNode> eviction_queue_t;\n \n struct EvictionQueue {\n \teviction_queue_t q;\n };\n \n+class TemporaryFileManager;\n+\n class TemporaryDirectoryHandle {\n public:\n-\tTemporaryDirectoryHandle(DatabaseInstance &db, string path_p) : db(db), temp_directory(move(path_p)) {\n-\t\tauto &fs = FileSystem::GetFileSystem(db);\n-\t\tif (!temp_directory.empty()) {\n-\t\t\tfs.CreateDirectory(temp_directory);\n-\t\t}\n-\t}\n-\t~TemporaryDirectoryHandle() {\n-\t\tauto &fs = FileSystem::GetFileSystem(db);\n-\t\tif (!temp_directory.empty()) {\n-\t\t\tfs.RemoveDirectory(temp_directory);\n-\t\t}\n-\t}\n+\tTemporaryDirectoryHandle(DatabaseInstance &db, string path_p);\n+\t~TemporaryDirectoryHandle();\n+\n+\tTemporaryFileManager &GetTempFile();\n \n private:\n \tDatabaseInstance &db;\n \tstring temp_directory;\n+\tunique_ptr<TemporaryFileManager> temp_file;\n };\n \n void BufferManager::SetTemporaryDirectory(string new_dir) {\n@@ -162,7 +210,9 @@ void BufferManager::SetTemporaryDirectory(string new_dir) {\n \n BufferManager::BufferManager(DatabaseInstance &db, string tmp, idx_t maximum_memory)\n     : db(db), current_memory(0), maximum_memory(maximum_memory), temp_directory(move(tmp)),\n-      queue(make_unique<EvictionQueue>()), temporary_id(MAXIMUM_BLOCK) {\n+      queue(make_unique<EvictionQueue>()), temporary_id(MAXIMUM_BLOCK),\n+      buffer_allocator(BufferAllocatorAllocate, BufferAllocatorFree, BufferAllocatorRealloc,\n+                       make_unique<BufferAllocatorData>(*this)) {\n }\n \n BufferManager::~BufferManager() {\n@@ -200,19 +250,15 @@ shared_ptr<BlockHandle> BufferManager::ConvertToPersistent(BlockManager &block_m\n \tD_ASSERT(new_block->state == BlockState::BLOCK_UNLOADED);\n \tD_ASSERT(new_block->readers == 0);\n \n-#ifdef DEBUG\n-\tlock_guard<mutex> b_lock(blocks_lock);\n-#endif\n-\n \t// move the data from the old block into data for the new block\n \tnew_block->state = BlockState::BLOCK_LOADED;\n \tnew_block->buffer = make_unique<Block>(*old_block->buffer, block_id);\n \n \t// clear the old buffer and unload it\n-\told_handle.reset();\n \told_block->buffer.reset();\n \told_block->state = BlockState::BLOCK_UNLOADED;\n \told_block->memory_usage = 0;\n+\told_handle.Destroy();\n \told_block.reset();\n \n \t// persist the new block to disk\n@@ -226,19 +272,19 @@ shared_ptr<BlockHandle> BufferManager::ConvertToPersistent(BlockManager &block_m\n shared_ptr<BlockHandle> BufferManager::RegisterMemory(idx_t block_size, bool can_destroy) {\n \tauto alloc_size = block_size + Storage::BLOCK_HEADER_SIZE;\n \t// first evict blocks until we have enough memory to store this buffer\n-\tif (!EvictBlocks(alloc_size, maximum_memory)) {\n+\tunique_ptr<FileBuffer> reusable_buffer;\n+\tif (!EvictBlocks(alloc_size, maximum_memory, &reusable_buffer)) {\n \t\tthrow OutOfMemoryException(\"could not allocate block of %lld bytes%s\", alloc_size, InMemoryWarning());\n \t}\n \n-\t// allocate the buffer\n \tauto temp_id = ++temporary_id;\n-\tauto buffer = make_unique<ManagedBuffer>(db, block_size, can_destroy, temp_id);\n+\tauto buffer = AllocateManagedBuffer(db, move(reusable_buffer), block_size, can_destroy, temp_id);\n \n \t// create a new block pointer for this block\n \treturn make_shared<BlockHandle>(db, temp_id, move(buffer), can_destroy, block_size);\n }\n \n-unique_ptr<BufferHandle> BufferManager::Allocate(idx_t block_size) {\n+BufferHandle BufferManager::Allocate(idx_t block_size) {\n \tauto block = RegisterMemory(block_size, true);\n \treturn Pin(block);\n }\n@@ -267,7 +313,7 @@ void BufferManager::ReAllocate(shared_ptr<BlockHandle> &handle, idx_t block_size\n \thandle->memory_usage = alloc_size;\n }\n \n-unique_ptr<BufferHandle> BufferManager::Pin(shared_ptr<BlockHandle> &handle) {\n+BufferHandle BufferManager::Pin(shared_ptr<BlockHandle> &handle) {\n \tidx_t required_memory;\n \t{\n \t\t// lock the block\n@@ -281,7 +327,8 @@ unique_ptr<BufferHandle> BufferManager::Pin(shared_ptr<BlockHandle> &handle) {\n \t\trequired_memory = handle->memory_usage;\n \t}\n \t// evict blocks until we have space for the current block\n-\tif (!EvictBlocks(required_memory, maximum_memory)) {\n+\tunique_ptr<FileBuffer> reusable_buffer;\n+\tif (!EvictBlocks(required_memory, maximum_memory, &reusable_buffer)) {\n \t\tthrow OutOfMemoryException(\"failed to pin block of size %lld%s\", required_memory, InMemoryWarning());\n \t}\n \t// lock the handle again and repeat the check (in case anybody loaded in the mean time)\n@@ -296,14 +343,14 @@ unique_ptr<BufferHandle> BufferManager::Pin(shared_ptr<BlockHandle> &handle) {\n \t// now we can actually load the current block\n \tD_ASSERT(handle->readers == 0);\n \thandle->readers = 1;\n-\treturn handle->Load(handle);\n+\treturn handle->Load(handle, move(reusable_buffer));\n }\n \n void BufferManager::AddToEvictionQueue(shared_ptr<BlockHandle> &handle) {\n \tD_ASSERT(handle->readers == 0);\n \thandle->eviction_timestamp++;\n \tPurgeQueue();\n-\tqueue->q.enqueue(make_unique<BufferEvictionNode>(weak_ptr<BlockHandle>(handle), handle->eviction_timestamp));\n+\tqueue->q.enqueue(BufferEvictionNode(weak_ptr<BlockHandle>(handle), handle->eviction_timestamp));\n }\n \n void BufferManager::Unpin(shared_ptr<BlockHandle> &handle) {\n@@ -315,10 +362,10 @@ void BufferManager::Unpin(shared_ptr<BlockHandle> &handle) {\n \t}\n }\n \n-bool BufferManager::EvictBlocks(idx_t extra_memory, idx_t memory_limit) {\n+bool BufferManager::EvictBlocks(idx_t extra_memory, idx_t memory_limit, unique_ptr<FileBuffer> *buffer) {\n \tPurgeQueue();\n \n-\tunique_ptr<BufferEvictionNode> node;\n+\tBufferEvictionNode node;\n \tcurrent_memory += extra_memory;\n \twhile (current_memory > memory_limit) {\n \t\t// get a block to unpin from the queue\n@@ -327,30 +374,36 @@ bool BufferManager::EvictBlocks(idx_t extra_memory, idx_t memory_limit) {\n \t\t\treturn false;\n \t\t}\n \t\t// get a reference to the underlying block pointer\n-\t\tauto handle = node->TryGetBlockHandle();\n+\t\tauto handle = node.TryGetBlockHandle();\n \t\tif (!handle) {\n \t\t\tcontinue;\n \t\t}\n \t\t// we might be able to free this block: grab the mutex and check if we can free it\n \t\tlock_guard<mutex> lock(handle->lock);\n-\t\tif (!node->CanUnload(*handle)) {\n+\t\tif (!node.CanUnload(*handle)) {\n \t\t\t// something changed in the mean-time, bail out\n \t\t\tcontinue;\n \t\t}\n \t\t// hooray, we can unload the block\n-\t\t// release the memory and mark the block as unloaded\n-\t\thandle->Unload();\n+\t\tif (buffer && handle->buffer->AllocSize() == extra_memory) {\n+\t\t\t// we can actually re-use the memory directly!\n+\t\t\t*buffer = handle->UnloadAndTakeBlock();\n+\t\t\treturn true;\n+\t\t} else {\n+\t\t\t// release the memory and mark the block as unloaded\n+\t\t\thandle->Unload();\n+\t\t}\n \t}\n \treturn true;\n }\n \n void BufferManager::PurgeQueue() {\n-\tunique_ptr<BufferEvictionNode> node;\n+\tBufferEvictionNode node;\n \twhile (true) {\n \t\tif (!queue->q.try_dequeue(node)) {\n \t\t\tbreak;\n \t\t}\n-\t\tauto handle = node->TryGetBlockHandle();\n+\t\tauto handle = node.TryGetBlockHandle();\n \t\tif (!handle) {\n \t\t\tcontinue;\n \t\t} else {\n@@ -394,6 +447,323 @@ void BufferManager::SetLimit(idx_t limit) {\n \t}\n }\n \n+//===--------------------------------------------------------------------===//\n+// Temporary File Management\n+//===--------------------------------------------------------------------===//\n+unique_ptr<ManagedBuffer> ReadTemporaryBufferInternal(DatabaseInstance &db, FileHandle &handle, idx_t position,\n+                                                      idx_t size, block_id_t id,\n+                                                      unique_ptr<FileBuffer> reusable_buffer) {\n+\tauto buffer = AllocateManagedBuffer(db, move(reusable_buffer), size, false, id);\n+\tbuffer->Read(handle, position);\n+\treturn buffer;\n+}\n+\n+struct TemporaryFileIndex {\n+\texplicit TemporaryFileIndex(idx_t file_index = DConstants::INVALID_INDEX,\n+\t                            idx_t block_index = DConstants::INVALID_INDEX)\n+\t    : file_index(file_index), block_index(block_index) {\n+\t}\n+\n+\tidx_t file_index;\n+\tidx_t block_index;\n+\n+public:\n+\tbool IsValid() {\n+\t\treturn block_index != DConstants::INVALID_INDEX;\n+\t}\n+};\n+\n+struct BlockIndexManager {\n+\tBlockIndexManager() : max_index(0) {\n+\t}\n+\n+public:\n+\t//! Obtains a new block index from the index manager\n+\tidx_t GetNewBlockIndex() {\n+\t\tauto index = GetNewBlockIndexInternal();\n+\t\tindexes_in_use.insert(index);\n+\t\treturn index;\n+\t}\n+\n+\t//! Removes an index from the block manager\n+\t//! Returns true if the max_index has been altered\n+\tbool RemoveIndex(idx_t index) {\n+\t\t// remove this block from the set of blocks\n+\t\tindexes_in_use.erase(index);\n+\t\tfree_indexes.insert(index);\n+\t\t// check if we can truncate the file\n+\n+\t\t// get the max_index in use right now\n+\t\tauto max_index_in_use = indexes_in_use.empty() ? 0 : *indexes_in_use.rbegin();\n+\t\tif (max_index_in_use < max_index) {\n+\t\t\t// max index in use is lower than the max_index\n+\t\t\t// reduce the max_index\n+\t\t\tmax_index = max_index_in_use + 1;\n+\t\t\t// we can remove any free_indexes that are larger than the current max_index\n+\t\t\twhile (!free_indexes.empty()) {\n+\t\t\t\tauto max_entry = *free_indexes.rbegin();\n+\t\t\t\tif (max_entry < max_index) {\n+\t\t\t\t\tbreak;\n+\t\t\t\t}\n+\t\t\t\tfree_indexes.erase(max_entry);\n+\t\t\t}\n+\t\t\treturn true;\n+\t\t}\n+\t\treturn false;\n+\t}\n+\n+\tidx_t GetMaxIndex() {\n+\t\treturn max_index;\n+\t}\n+\n+\tbool HasFreeBlocks() {\n+\t\treturn !free_indexes.empty();\n+\t}\n+\n+private:\n+\tidx_t GetNewBlockIndexInternal() {\n+\t\tif (free_indexes.empty()) {\n+\t\t\treturn max_index++;\n+\t\t}\n+\t\tauto entry = free_indexes.begin();\n+\t\tauto index = *entry;\n+\t\tfree_indexes.erase(entry);\n+\t\treturn index;\n+\t}\n+\n+\tidx_t max_index;\n+\tset<idx_t> free_indexes;\n+\tset<idx_t> indexes_in_use;\n+};\n+\n+class TemporaryFileHandle {\n+\tconstexpr static idx_t MAX_ALLOWED_INDEX = 4000;\n+\n+public:\n+\tTemporaryFileHandle(DatabaseInstance &db, const string &temp_directory, idx_t index)\n+\t    : db(db), file_index(index), path(FileSystem::GetFileSystem(db).JoinPath(\n+\t                                     temp_directory, \"duckdb_temp_storage-\" + to_string(index) + \".tmp\")) {\n+\t}\n+\n+public:\n+\tstruct TemporaryFileLock {\n+\t\texplicit TemporaryFileLock(mutex &mutex) : lock(mutex) {\n+\t\t}\n+\n+\t\tlock_guard<mutex> lock;\n+\t};\n+\n+public:\n+\tTemporaryFileIndex TryGetBlockIndex() {\n+\t\tTemporaryFileLock lock(file_lock);\n+\t\tif (index_manager.GetMaxIndex() >= MAX_ALLOWED_INDEX && index_manager.HasFreeBlocks()) {\n+\t\t\t// file is at capacity\n+\t\t\treturn TemporaryFileIndex();\n+\t\t}\n+\t\t// open the file handle if it does not yet exist\n+\t\tCreateFileIfNotExists(lock);\n+\t\t// fetch a new block index to write to\n+\t\tauto block_index = index_manager.GetNewBlockIndex();\n+\t\treturn TemporaryFileIndex(file_index, block_index);\n+\t}\n+\n+\tvoid WriteTemporaryFile(ManagedBuffer &buffer, TemporaryFileIndex index) {\n+\t\tD_ASSERT(buffer.size == Storage::BLOCK_SIZE);\n+\t\tbuffer.Write(*handle, GetPositionInFile(index.block_index));\n+\t}\n+\n+\tunique_ptr<FileBuffer> ReadTemporaryBuffer(block_id_t id, idx_t block_index,\n+\t                                           unique_ptr<FileBuffer> reusable_buffer) {\n+\t\tauto buffer = ReadTemporaryBufferInternal(db, *handle, GetPositionInFile(block_index), Storage::BLOCK_SIZE, id,\n+\t\t                                          move(reusable_buffer));\n+\t\t{\n+\t\t\t// remove the block (and potentially truncate the temp file)\n+\t\t\tTemporaryFileLock lock(file_lock);\n+\t\t\tD_ASSERT(handle);\n+\t\t\tRemoveTempBlockIndex(lock, block_index);\n+\t\t}\n+\t\treturn move(buffer);\n+\t}\n+\n+\tbool DeleteIfEmpty() {\n+\t\tTemporaryFileLock lock(file_lock);\n+\t\tif (index_manager.GetMaxIndex() > 0) {\n+\t\t\t// there are still blocks in this file\n+\t\t\treturn false;\n+\t\t}\n+\t\t// the file is empty: delete it\n+\t\thandle.reset();\n+\t\tauto &fs = FileSystem::GetFileSystem(db);\n+\t\tfs.RemoveFile(path);\n+\t\treturn true;\n+\t}\n+\n+private:\n+\tvoid CreateFileIfNotExists(TemporaryFileLock &) {\n+\t\tif (handle) {\n+\t\t\treturn;\n+\t\t}\n+\t\tauto &fs = FileSystem::GetFileSystem(db);\n+\t\thandle = fs.OpenFile(path, FileFlags::FILE_FLAGS_READ | FileFlags::FILE_FLAGS_WRITE |\n+\t\t                               FileFlags::FILE_FLAGS_FILE_CREATE);\n+\t}\n+\n+\tvoid RemoveTempBlockIndex(TemporaryFileLock &, idx_t index) {\n+\t\t// remove the block index from the index manager\n+\t\tif (index_manager.RemoveIndex(index)) {\n+\t\t\t// the max_index that is currently in use has decreased\n+\t\t\t// as a result we can truncate the file\n+\t\t\tauto max_index = index_manager.GetMaxIndex();\n+\t\t\tauto &fs = FileSystem::GetFileSystem(db);\n+\t\t\tfs.Truncate(*handle, GetPositionInFile(max_index + 1));\n+\t\t}\n+\t}\n+\n+\tidx_t GetPositionInFile(idx_t index) {\n+\t\treturn index * Storage::BLOCK_ALLOC_SIZE;\n+\t}\n+\n+private:\n+\tDatabaseInstance &db;\n+\tunique_ptr<FileHandle> handle;\n+\tidx_t file_index;\n+\tstring path;\n+\tmutex file_lock;\n+\tBlockIndexManager index_manager;\n+};\n+\n+class TemporaryFileManager {\n+public:\n+\tTemporaryFileManager(DatabaseInstance &db, const string &temp_directory_p)\n+\t    : db(db), temp_directory(temp_directory_p) {\n+\t}\n+\n+public:\n+\tstruct TemporaryManagerLock {\n+\t\texplicit TemporaryManagerLock(mutex &mutex) : lock(mutex) {\n+\t\t}\n+\n+\t\tlock_guard<mutex> lock;\n+\t};\n+\n+\tvoid WriteTemporaryBuffer(ManagedBuffer &buffer) {\n+\t\tD_ASSERT(buffer.size == Storage::BLOCK_SIZE);\n+\t\tTemporaryFileIndex index;\n+\t\tTemporaryFileHandle *handle = nullptr;\n+\n+\t\t{\n+\t\t\tTemporaryManagerLock lock(manager_lock);\n+\t\t\t// first check if we can write to an open existing file\n+\t\t\tfor (auto &entry : files) {\n+\t\t\t\tauto &temp_file = entry.second;\n+\t\t\t\tindex = temp_file->TryGetBlockIndex();\n+\t\t\t\tif (index.IsValid()) {\n+\t\t\t\t\thandle = entry.second.get();\n+\t\t\t\t\tbreak;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\tif (!handle) {\n+\t\t\t\t// no existing handle to write to; we need to create & open a new file\n+\t\t\t\tauto new_file_index = index_manager.GetNewBlockIndex();\n+\t\t\t\tauto new_file = make_unique<TemporaryFileHandle>(db, temp_directory, new_file_index);\n+\t\t\t\thandle = new_file.get();\n+\t\t\t\tfiles[new_file_index] = move(new_file);\n+\n+\t\t\t\tindex = handle->TryGetBlockIndex();\n+\t\t\t}\n+\t\t\tD_ASSERT(used_blocks.find(buffer.id) == used_blocks.end());\n+\t\t\tused_blocks[buffer.id] = index;\n+\t\t}\n+\t\tD_ASSERT(handle);\n+\t\tD_ASSERT(index.IsValid());\n+\t\thandle->WriteTemporaryFile(buffer, index);\n+\t}\n+\n+\tbool HasTemporaryBuffer(block_id_t block_id) {\n+\t\tlock_guard<mutex> lock(manager_lock);\n+\t\treturn used_blocks.find(block_id) != used_blocks.end();\n+\t}\n+\n+\tunique_ptr<FileBuffer> ReadTemporaryBuffer(block_id_t id, unique_ptr<FileBuffer> reusable_buffer) {\n+\t\tTemporaryFileIndex index;\n+\t\tTemporaryFileHandle *handle;\n+\t\t{\n+\t\t\tTemporaryManagerLock lock(manager_lock);\n+\t\t\tindex = GetTempBlockIndex(lock, id);\n+\t\t\thandle = GetFileHandle(lock, index.file_index);\n+\t\t}\n+\t\tauto buffer = handle->ReadTemporaryBuffer(id, index.block_index, move(reusable_buffer));\n+\t\t{\n+\t\t\t// remove the block (and potentially erase the temp file)\n+\t\t\tTemporaryManagerLock lock(manager_lock);\n+\t\t\tEraseUsedBlock(lock, id, handle, index.file_index);\n+\t\t}\n+\t\treturn buffer;\n+\t}\n+\n+\tvoid DeleteTemporaryBuffer(block_id_t id) {\n+\t\tTemporaryManagerLock lock(manager_lock);\n+\t\tauto index = GetTempBlockIndex(lock, id);\n+\t\tauto handle = GetFileHandle(lock, index.file_index);\n+\t\tEraseUsedBlock(lock, id, handle, index.file_index);\n+\t}\n+\n+private:\n+\tvoid EraseUsedBlock(TemporaryManagerLock &lock, block_id_t id, TemporaryFileHandle *handle, idx_t file_index) {\n+\t\tused_blocks.erase(id);\n+\t\tif (handle->DeleteIfEmpty()) {\n+\t\t\tEraseFileHandle(lock, file_index);\n+\t\t}\n+\t}\n+\n+\tTemporaryFileHandle *GetFileHandle(TemporaryManagerLock &, idx_t index) {\n+\t\treturn files[index].get();\n+\t}\n+\n+\tTemporaryFileIndex GetTempBlockIndex(TemporaryManagerLock &, block_id_t id) {\n+\t\tD_ASSERT(used_blocks.find(id) != used_blocks.end());\n+\t\treturn used_blocks[id];\n+\t}\n+\n+\tvoid EraseFileHandle(TemporaryManagerLock &, idx_t file_index) {\n+\t\tfiles.erase(file_index);\n+\t\tindex_manager.RemoveIndex(file_index);\n+\t}\n+\n+private:\n+\tDatabaseInstance &db;\n+\tmutex manager_lock;\n+\t//! The temporary directory\n+\tstring temp_directory;\n+\t//! The set of active temporary file handles\n+\tunordered_map<idx_t, unique_ptr<TemporaryFileHandle>> files;\n+\t//! map of block_id -> temporary file position\n+\tunordered_map<block_id_t, TemporaryFileIndex> used_blocks;\n+\t//! Manager of in-use temporary file indexes\n+\tBlockIndexManager index_manager;\n+};\n+\n+TemporaryDirectoryHandle::TemporaryDirectoryHandle(DatabaseInstance &db, string path_p)\n+    : db(db), temp_directory(move(path_p)), temp_file(make_unique<TemporaryFileManager>(db, temp_directory)) {\n+\tauto &fs = FileSystem::GetFileSystem(db);\n+\tif (!temp_directory.empty()) {\n+\t\tfs.CreateDirectory(temp_directory);\n+\t}\n+}\n+TemporaryDirectoryHandle::~TemporaryDirectoryHandle() {\n+\t// first release any temporary files\n+\ttemp_file.reset();\n+\t// then delete the temporary file directory\n+\tauto &fs = FileSystem::GetFileSystem(db);\n+\tif (!temp_directory.empty()) {\n+\t\tfs.RemoveDirectory(temp_directory);\n+\t}\n+}\n+\n+TemporaryFileManager &TemporaryDirectoryHandle::GetTempFile() {\n+\treturn *temp_file;\n+}\n+\n string BufferManager::GetTemporaryPath(block_id_t id) {\n \tauto &fs = FileSystem::GetFileSystem(db);\n \treturn fs.JoinPath(temp_directory, to_string(id) + \".block\");\n@@ -414,8 +784,12 @@ void BufferManager::RequireTemporaryDirectory() {\n \n void BufferManager::WriteTemporaryBuffer(ManagedBuffer &buffer) {\n \tRequireTemporaryDirectory();\n+\tif (buffer.size == Storage::BLOCK_SIZE) {\n+\t\ttemp_directory_handle->GetTempFile().WriteTemporaryBuffer(buffer);\n+\t\treturn;\n+\t}\n \n-\tD_ASSERT(buffer.size >= Storage::BLOCK_SIZE);\n+\tD_ASSERT(buffer.size > Storage::BLOCK_SIZE);\n \t// get the path to write to\n \tauto path = GetTemporaryPath(buffer.id);\n \t// create the file and write the size followed by the buffer contents\n@@ -425,9 +799,12 @@ void BufferManager::WriteTemporaryBuffer(ManagedBuffer &buffer) {\n \tbuffer.Write(*handle, sizeof(idx_t));\n }\n \n-unique_ptr<FileBuffer> BufferManager::ReadTemporaryBuffer(block_id_t id) {\n+unique_ptr<FileBuffer> BufferManager::ReadTemporaryBuffer(block_id_t id, unique_ptr<FileBuffer> reusable_buffer) {\n \tD_ASSERT(!temp_directory.empty());\n \tD_ASSERT(temp_directory_handle.get());\n+\tif (temp_directory_handle->GetTempFile().HasTemporaryBuffer(id)) {\n+\t\treturn temp_directory_handle->GetTempFile().ReadTemporaryBuffer(id, move(reusable_buffer));\n+\t}\n \tidx_t block_size;\n \t// open the temporary file and read the size\n \tauto path = GetTemporaryPath(id);\n@@ -436,8 +813,7 @@ unique_ptr<FileBuffer> BufferManager::ReadTemporaryBuffer(block_id_t id) {\n \thandle->Read(&block_size, sizeof(idx_t), 0);\n \n \t// now allocate a buffer of this size and read the data into that buffer\n-\tauto buffer = make_unique<ManagedBuffer>(db, block_size, false, id);\n-\tbuffer->Read(*handle, sizeof(idx_t));\n+\tauto buffer = ReadTemporaryBufferInternal(db, *handle, sizeof(idx_t), block_size, id, move(reusable_buffer));\n \n \thandle.reset();\n \tDeleteTemporaryFile(id);\n@@ -445,7 +821,20 @@ unique_ptr<FileBuffer> BufferManager::ReadTemporaryBuffer(block_id_t id) {\n }\n \n void BufferManager::DeleteTemporaryFile(block_id_t id) {\n-\tif (temp_directory.empty() || !temp_directory_handle) {\n+\tif (temp_directory.empty()) {\n+\t\t// no temporary directory specified: nothing to delete\n+\t\treturn;\n+\t}\n+\t{\n+\t\tlock_guard<mutex> temp_handle_guard(temp_handle_lock);\n+\t\tif (!temp_directory_handle) {\n+\t\t\t// temporary directory was not initialized yet: nothing to delete\n+\t\t\treturn;\n+\t\t}\n+\t}\n+\t// check if we should delete the file from the shared pool of files, or from the general file system\n+\tif (temp_directory_handle->GetTempFile().HasTemporaryBuffer(id)) {\n+\t\ttemp_directory_handle->GetTempFile().DeleteTemporaryBuffer(id);\n \t\treturn;\n \t}\n \tauto &fs = FileSystem::GetFileSystem(db);\n@@ -465,4 +854,38 @@ string BufferManager::InMemoryWarning() {\n \t       \"\\nOr set PRAGMA temp_directory='/path/to/tmp.tmp'\";\n }\n \n+//===--------------------------------------------------------------------===//\n+// Buffer Allocator\n+//===--------------------------------------------------------------------===//\n+data_ptr_t BufferManager::BufferAllocatorAllocate(PrivateAllocatorData *private_data, idx_t size) {\n+\tauto &data = (BufferAllocatorData &)*private_data;\n+\tif (!data.manager.EvictBlocks(size, data.manager.maximum_memory)) {\n+\t\tthrow OutOfMemoryException(\"failed to allocate data of size %lld%s\", size, data.manager.InMemoryWarning());\n+\t}\n+\treturn Allocator::Get(data.manager.db).AllocateData(size);\n+}\n+\n+void BufferManager::BufferAllocatorFree(PrivateAllocatorData *private_data, data_ptr_t pointer, idx_t size) {\n+\tauto &data = (BufferAllocatorData &)*private_data;\n+\tdata.manager.current_memory -= size;\n+\treturn Allocator::Get(data.manager.db).FreeData(pointer, size);\n+}\n+\n+data_ptr_t BufferManager::BufferAllocatorRealloc(PrivateAllocatorData *private_data, data_ptr_t pointer, idx_t old_size,\n+                                                 idx_t size) {\n+\tauto &data = (BufferAllocatorData &)*private_data;\n+\tdata.manager.current_memory -= old_size;\n+\tdata.manager.current_memory += size;\n+\treturn Allocator::Get(data.manager.db).ReallocateData(pointer, old_size, size);\n+}\n+\n+Allocator &BufferAllocator::Get(ClientContext &context) {\n+\tauto &manager = BufferManager::GetBufferManager(context);\n+\treturn manager.GetBufferAllocator();\n+}\n+\n+Allocator &BufferManager::GetBufferAllocator() {\n+\treturn buffer_allocator;\n+}\n+\n } // namespace duckdb\ndiff --git a/src/storage/checkpoint/write_overflow_strings_to_disk.cpp b/src/storage/checkpoint/write_overflow_strings_to_disk.cpp\nindex 1fedb520f343..e8e64b40295c 100644\n--- a/src/storage/checkpoint/write_overflow_strings_to_disk.cpp\n+++ b/src/storage/checkpoint/write_overflow_strings_to_disk.cpp\n@@ -12,14 +12,14 @@ WriteOverflowStringsToDisk::WriteOverflowStringsToDisk(DatabaseInstance &db)\n WriteOverflowStringsToDisk::~WriteOverflowStringsToDisk() {\n \tauto &block_manager = BlockManager::GetBlockManager(db);\n \tif (offset > 0) {\n-\t\tblock_manager.Write(*handle->node, block_id);\n+\t\tblock_manager.Write(handle.GetFileBuffer(), block_id);\n \t}\n }\n \n void WriteOverflowStringsToDisk::WriteString(string_t string, block_id_t &result_block, int32_t &result_offset) {\n \tauto &buffer_manager = BufferManager::GetBufferManager(db);\n \tauto &block_manager = BlockManager::GetBlockManager(db);\n-\tif (!handle) {\n+\tif (!handle.IsValid()) {\n \t\thandle = buffer_manager.Allocate(Storage::BLOCK_SIZE);\n \t}\n \t// first write the length of the string\n@@ -39,8 +39,9 @@ void WriteOverflowStringsToDisk::WriteString(string_t string, block_id_t &result\n \tstring_t compressed_string((const char *)compressed_buf.get(), compressed_size);\n \n \t// store sizes\n-\tStore<uint32_t>(compressed_size, handle->node->buffer + offset);\n-\tStore<uint32_t>(uncompressed_size, handle->node->buffer + offset + sizeof(uint32_t));\n+\tauto data_ptr = handle.Ptr();\n+\tStore<uint32_t>(compressed_size, data_ptr + offset);\n+\tStore<uint32_t>(uncompressed_size, data_ptr + offset + sizeof(uint32_t));\n \n \t// now write the remainder of the string\n \toffset += 2 * sizeof(uint32_t);\n@@ -49,7 +50,7 @@ void WriteOverflowStringsToDisk::WriteString(string_t string, block_id_t &result\n \twhile (remaining > 0) {\n \t\tuint32_t to_write = MinValue<uint32_t>(remaining, STRING_SPACE - offset);\n \t\tif (to_write > 0) {\n-\t\t\tmemcpy(handle->node->buffer + offset, strptr, to_write);\n+\t\t\tmemcpy(data_ptr + offset, strptr, to_write);\n \n \t\t\tremaining -= to_write;\n \t\t\toffset += to_write;\n@@ -59,7 +60,7 @@ void WriteOverflowStringsToDisk::WriteString(string_t string, block_id_t &result\n \t\t\t// there is still remaining stuff to write\n \t\t\t// first get the new block id and write it to the end of the previous block\n \t\t\tauto new_block_id = block_manager.GetFreeBlockId();\n-\t\t\tStore<block_id_t>(new_block_id, handle->node->buffer + offset);\n+\t\t\tStore<block_id_t>(new_block_id, data_ptr + offset);\n \t\t\t// now write the current block to disk and allocate a new block\n \t\t\tAllocateNewBlock(new_block_id);\n \t\t}\n@@ -70,7 +71,7 @@ void WriteOverflowStringsToDisk::AllocateNewBlock(block_id_t new_block_id) {\n \tauto &block_manager = BlockManager::GetBlockManager(db);\n \tif (block_id != INVALID_BLOCK) {\n \t\t// there is an old block, write it first\n-\t\tblock_manager.Write(*handle->node, block_id);\n+\t\tblock_manager.Write(handle.GetFileBuffer(), block_id);\n \t}\n \toffset = 0;\n \tblock_id = new_block_id;\ndiff --git a/src/storage/compression/bitpacking.cpp b/src/storage/compression/bitpacking.cpp\nindex b4576a2ddb53..5f2fa7a1e1cc 100644\n--- a/src/storage/compression/bitpacking.cpp\n+++ b/src/storage/compression/bitpacking.cpp\n@@ -118,7 +118,7 @@ struct BitpackingCompressState : public CompressionState {\n \tColumnDataCheckpointer &checkpointer;\n \tCompressionFunction *function;\n \tunique_ptr<ColumnSegment> current_segment;\n-\tunique_ptr<BufferHandle> handle;\n+\tBufferHandle handle;\n \n \t// Ptr to next free spot in segment;\n \tdata_ptr_t data_ptr;\n@@ -165,9 +165,8 @@ struct BitpackingCompressState : public CompressionState {\n \t\tauto &buffer_manager = BufferManager::GetBufferManager(db);\n \t\thandle = buffer_manager.Pin(current_segment->block);\n \n-\t\tdata_ptr = handle->Ptr() + current_segment->GetBlockOffset() + BitpackingPrimitives::BITPACKING_HEADER_SIZE;\n-\t\twidth_ptr =\n-\t\t    handle->Ptr() + current_segment->GetBlockOffset() + Storage::BLOCK_SIZE - sizeof(bitpacking_width_t);\n+\t\tdata_ptr = handle.Ptr() + current_segment->GetBlockOffset() + BitpackingPrimitives::BITPACKING_HEADER_SIZE;\n+\t\twidth_ptr = handle.Ptr() + current_segment->GetBlockOffset() + Storage::BLOCK_SIZE - sizeof(bitpacking_width_t);\n \t}\n \n \tvoid Append(VectorData &vdata, idx_t count) {\n@@ -193,16 +192,17 @@ struct BitpackingCompressState : public CompressionState {\n \n \tvoid FlushSegment() {\n \t\tauto &state = checkpointer.GetCheckpointState();\n+\t\tauto dataptr = handle.Ptr();\n \n \t\t// Compact the segment by moving the widths next to the data.\n-\t\tidx_t minimal_widths_offset = AlignValue(data_ptr - handle->node->buffer);\n-\t\tidx_t widths_size = handle->node->buffer + Storage::BLOCK_SIZE - width_ptr - 1;\n+\t\tidx_t minimal_widths_offset = AlignValue(data_ptr - dataptr);\n+\t\tidx_t widths_size = dataptr + Storage::BLOCK_SIZE - width_ptr - 1;\n \t\tidx_t total_segment_size = minimal_widths_offset + widths_size;\n-\t\tmemmove(handle->node->buffer + minimal_widths_offset, width_ptr + 1, widths_size);\n+\t\tmemmove(dataptr + minimal_widths_offset, width_ptr + 1, widths_size);\n \n \t\t// Store the offset of the first width (which is at the highest address).\n-\t\tStore<idx_t>(minimal_widths_offset + widths_size - 1, handle->node->buffer);\n-\t\thandle.reset();\n+\t\tStore<idx_t>(minimal_widths_offset + widths_size - 1, dataptr);\n+\t\thandle.Destroy();\n \n \t\tstate.FlushSegment(move(current_segment), total_segment_size);\n \t}\n@@ -243,19 +243,18 @@ struct BitpackingScanState : public SegmentScanState {\n \texplicit BitpackingScanState(ColumnSegment &segment) {\n \t\tauto &buffer_manager = BufferManager::GetBufferManager(segment.db);\n \t\thandle = buffer_manager.Pin(segment.block);\n-\n-\t\tcurrent_width_group_ptr =\n-\t\t    handle->node->buffer + segment.GetBlockOffset() + BitpackingPrimitives::BITPACKING_HEADER_SIZE;\n+\t\tauto dataptr = handle.Ptr();\n+\t\tcurrent_width_group_ptr = dataptr + segment.GetBlockOffset() + BitpackingPrimitives::BITPACKING_HEADER_SIZE;\n \n \t\t// load offset to bitpacking widths pointer\n-\t\tauto bitpacking_widths_offset = Load<idx_t>(handle->node->buffer + segment.GetBlockOffset());\n-\t\tbitpacking_width_ptr = handle->node->buffer + segment.GetBlockOffset() + bitpacking_widths_offset;\n+\t\tauto bitpacking_widths_offset = Load<idx_t>(dataptr + segment.GetBlockOffset());\n+\t\tbitpacking_width_ptr = dataptr + segment.GetBlockOffset() + bitpacking_widths_offset;\n \n \t\t// load the bitwidth of the first vector\n \t\tLoadCurrentBitWidth();\n \t}\n \n-\tunique_ptr<BufferHandle> handle;\n+\tBufferHandle handle;\n \n \tvoid (*decompress_function)(data_ptr_t, data_ptr_t, bitpacking_width_t, bool skip_sign_extension);\n \tT decompression_buffer[BitpackingPrimitives::BITPACKING_ALGORITHM_GROUP_SIZE];\n@@ -267,8 +266,7 @@ struct BitpackingScanState : public SegmentScanState {\n \n public:\n \tvoid LoadCurrentBitWidth() {\n-\t\tD_ASSERT(bitpacking_width_ptr > handle->node->buffer &&\n-\t\t         bitpacking_width_ptr < handle->node->buffer + Storage::BLOCK_SIZE);\n+\t\tD_ASSERT(bitpacking_width_ptr > handle.Ptr() && bitpacking_width_ptr < handle.Ptr() + Storage::BLOCK_SIZE);\n \t\tcurrent_width = Load<bitpacking_width_t>(bitpacking_width_ptr);\n \t\tLoadDecompressFunction();\n \t}\ndiff --git a/src/storage/compression/dictionary_compression.cpp b/src/storage/compression/dictionary_compression.cpp\nindex a23c06f7323b..507be6a7f601 100644\n--- a/src/storage/compression/dictionary_compression.cpp\n+++ b/src/storage/compression/dictionary_compression.cpp\n@@ -7,15 +7,27 @@\n #include \"duckdb/storage/string_uncompressed.hpp\"\n #include \"duckdb/storage/table/append_state.hpp\"\n #include \"duckdb/storage/table/column_data_checkpointer.hpp\"\n+#include \"duckdb/common/operator/comparison_operators.hpp\"\n \n namespace duckdb {\n \n struct StringHash {\n-\tstd::size_t operator()(const string &k) const {\n-\t\treturn Hash(k.c_str(), k.size());\n+\tstd::size_t operator()(const string_t &k) const {\n+\t\treturn Hash(k);\n \t}\n };\n \n+struct StringEquality {\n+\tbool operator()(const string_t &a, const string_t &b) const {\n+\t\treturn Equals::Operation(a, b);\n+\t}\n+};\n+\n+template <typename T>\n+using string_map_t = unordered_map<string_t, T, StringHash, StringEquality>;\n+\n+using string_set_t = unordered_set<string_t, StringHash, StringEquality>;\n+\n // Abstract class for keeping compression state either for compression or size analysis\n class DictionaryCompressionState : public CompressionState {\n public:\n@@ -137,6 +149,28 @@ struct DictionaryCompressionCompressState : public DictionaryCompressionState {\n \t\tCreateEmptySegment(checkpointer.GetRowGroup().start);\n \t}\n \n+\tColumnDataCheckpointer &checkpointer;\n+\tCompressionFunction *function;\n+\n+\t// State regarding current segment\n+\tunique_ptr<ColumnSegment> current_segment;\n+\tBufferHandle current_handle;\n+\tStringDictionaryContainer current_dictionary;\n+\tdata_ptr_t current_end_ptr;\n+\n+\t// Buffers and map for current segment\n+\tStringHeap heap;\n+\tstring_map_t<uint32_t> current_string_map;\n+\tstd::vector<uint32_t> index_buffer;\n+\tstd::vector<uint32_t> selection_buffer;\n+\n+\tbitpacking_width_t current_width = 0;\n+\tbitpacking_width_t next_width = 0;\n+\n+\t// Result of latest LookupString call\n+\tuint32_t latest_lookup_result;\n+\n+public:\n \tvoid CreateEmptySegment(idx_t row_start) {\n \t\tauto &db = checkpointer.GetDatabase();\n \t\tauto &type = checkpointer.GetType();\n@@ -157,30 +191,10 @@ struct DictionaryCompressionCompressState : public DictionaryCompressionState {\n \t\t// Reset the pointers into the current segment\n \t\tauto &buffer_manager = BufferManager::GetBufferManager(current_segment->db);\n \t\tcurrent_handle = buffer_manager.Pin(current_segment->block);\n-\t\tcurrent_dictionary = DictionaryCompressionStorage::GetDictionary(*current_segment, *current_handle);\n-\t\tcurrent_end_ptr = current_handle->node->buffer + current_dictionary.end;\n+\t\tcurrent_dictionary = DictionaryCompressionStorage::GetDictionary(*current_segment, current_handle);\n+\t\tcurrent_end_ptr = current_handle.Ptr() + current_dictionary.end;\n \t}\n \n-\tColumnDataCheckpointer &checkpointer;\n-\tCompressionFunction *function;\n-\n-\t// State regarding current segment\n-\tunique_ptr<ColumnSegment> current_segment;\n-\tunique_ptr<BufferHandle> current_handle;\n-\tStringDictionaryContainer current_dictionary;\n-\tdata_ptr_t current_end_ptr;\n-\n-\t// Buffers and map for current segment\n-\tstd::unordered_map<string, uint32_t, StringHash> current_string_map;\n-\tstd::vector<uint32_t> index_buffer;\n-\tstd::vector<uint32_t> selection_buffer;\n-\n-\tbitpacking_width_t current_width = 0;\n-\tbitpacking_width_t next_width = 0;\n-\n-\t// Result of latest LookupString call\n-\tuint32_t latest_lookup_result;\n-\n \tvoid Verify() override {\n \t\tcurrent_dictionary.Verify();\n \t\tD_ASSERT(current_segment->count == selection_buffer.size());\n@@ -191,7 +205,7 @@ struct DictionaryCompressionCompressState : public DictionaryCompressionState {\n \t}\n \n \tbool LookupString(string_t str) override {\n-\t\tauto search = current_string_map.find(str.GetString());\n+\t\tauto search = current_string_map.find(str);\n \t\tauto has_result = search != current_string_map.end();\n \n \t\tif (has_result) {\n@@ -213,8 +227,12 @@ struct DictionaryCompressionCompressState : public DictionaryCompressionState {\n \t\t// Update buffers and map\n \t\tindex_buffer.push_back(current_dictionary.size);\n \t\tselection_buffer.push_back(index_buffer.size() - 1);\n-\t\tcurrent_string_map.insert({str.GetString(), index_buffer.size() - 1});\n-\t\tDictionaryCompressionStorage::SetDictionary(*current_segment, *current_handle, current_dictionary);\n+\t\tif (str.IsInlined()) {\n+\t\t\tcurrent_string_map.insert({str, index_buffer.size() - 1});\n+\t\t} else {\n+\t\t\tcurrent_string_map.insert({heap.AddBlob(str), index_buffer.size() - 1});\n+\t\t}\n+\t\tDictionaryCompressionStorage::SetDictionary(*current_segment, current_handle, current_dictionary);\n \n \t\tcurrent_width = next_width;\n \t\tcurrent_segment->count++;\n@@ -267,7 +285,7 @@ struct DictionaryCompressionCompressState : public DictionaryCompressionState {\n \t\t                  index_buffer_size + current_dictionary.size;\n \n \t\t// calculate ptr and offsets\n-\t\tauto base_ptr = handle->node->buffer;\n+\t\tauto base_ptr = handle.Ptr();\n \t\tauto header_ptr = (dictionary_compression_header_t *)base_ptr;\n \t\tauto compressed_selection_buffer_offset = DictionaryCompressionStorage::DICTIONARY_HEADER_SIZE;\n \t\tauto index_buffer_offset = compressed_selection_buffer_offset + compressed_selection_buffer_size;\n@@ -304,7 +322,7 @@ struct DictionaryCompressionCompressState : public DictionaryCompressionState {\n \t\tcurrent_dictionary.end -= move_amount;\n \t\tD_ASSERT(current_dictionary.end == total_size);\n \t\t// write the new dictionary (with the updated \"end\")\n-\t\tDictionaryCompressionStorage::SetDictionary(*current_segment, *handle, current_dictionary);\n+\t\tDictionaryCompressionStorage::SetDictionary(*current_segment, handle, current_dictionary);\n \t\treturn total_size;\n \t}\n };\n@@ -312,8 +330,8 @@ struct DictionaryCompressionCompressState : public DictionaryCompressionState {\n //===--------------------------------------------------------------------===//\n // Analyze\n //===--------------------------------------------------------------------===//\n-struct DictionaryCompressionAnalyzeState : public AnalyzeState, DictionaryCompressionState {\n-\tDictionaryCompressionAnalyzeState()\n+struct DictionaryAnalyzeState : public DictionaryCompressionState {\n+\tDictionaryAnalyzeState()\n \t    : segment_count(0), current_tuple_count(0), current_unique_count(0), current_dict_size(0), current_width(0),\n \t      next_width(0) {\n \t}\n@@ -322,19 +340,24 @@ struct DictionaryCompressionAnalyzeState : public AnalyzeState, DictionaryCompre\n \tidx_t current_tuple_count;\n \tidx_t current_unique_count;\n \tsize_t current_dict_size;\n-\tstd::unordered_set<string, StringHash> current_set;\n+\tStringHeap heap;\n+\tstring_set_t current_set;\n \tbitpacking_width_t current_width;\n \tbitpacking_width_t next_width;\n \n \tbool LookupString(string_t str) override {\n-\t\treturn current_set.count(str.GetString());\n+\t\treturn current_set.count(str);\n \t}\n \n \tvoid AddNewString(string_t str) override {\n \t\tcurrent_tuple_count++;\n \t\tcurrent_unique_count++;\n \t\tcurrent_dict_size += str.GetSize();\n-\t\tcurrent_set.insert(str.GetString());\n+\t\tif (str.IsInlined()) {\n+\t\t\tcurrent_set.insert(str);\n+\t\t} else {\n+\t\t\tcurrent_set.insert(heap.AddBlob(str));\n+\t\t}\n \t\tcurrent_width = next_width;\n \t}\n \n@@ -368,17 +391,25 @@ struct DictionaryCompressionAnalyzeState : public AnalyzeState, DictionaryCompre\n \tvoid Verify() override {};\n };\n \n+struct DictionaryCompressionAnalyzeState : public AnalyzeState {\n+\tDictionaryCompressionAnalyzeState() : analyze_state(make_unique<DictionaryAnalyzeState>()) {\n+\t}\n+\n+\tunique_ptr<DictionaryAnalyzeState> analyze_state;\n+};\n+\n unique_ptr<AnalyzeState> DictionaryCompressionStorage::StringInitAnalyze(ColumnData &col_data, PhysicalType type) {\n \treturn make_unique<DictionaryCompressionAnalyzeState>();\n }\n \n bool DictionaryCompressionStorage::StringAnalyze(AnalyzeState &state_p, Vector &input, idx_t count) {\n \tauto &state = (DictionaryCompressionAnalyzeState &)state_p;\n-\treturn state.UpdateState(input, count);\n+\treturn state.analyze_state->UpdateState(input, count);\n }\n \n idx_t DictionaryCompressionStorage::StringFinalAnalyze(AnalyzeState &state_p) {\n-\tauto &state = (DictionaryCompressionAnalyzeState &)state_p;\n+\tauto &analyze_state = (DictionaryCompressionAnalyzeState &)state_p;\n+\tauto &state = *analyze_state.analyze_state;\n \n \tauto width = BitpackingPrimitives::MinimumBitWidth(state.current_unique_count + 1);\n \tauto req_space =\n@@ -409,7 +440,7 @@ void DictionaryCompressionStorage::FinalizeCompress(CompressionState &state_p) {\n // Scan\n //===--------------------------------------------------------------------===//\n struct CompressedStringScanState : public StringScanState {\n-\tunique_ptr<BufferHandle> handle;\n+\tBufferHandle handle;\n \tbuffer_ptr<Vector> dictionary;\n \tbitpacking_width_t current_width;\n \tbuffer_ptr<SelectionVector> sel_vec;\n@@ -421,10 +452,10 @@ unique_ptr<SegmentScanState> DictionaryCompressionStorage::StringInitScan(Column\n \tauto &buffer_manager = BufferManager::GetBufferManager(segment.db);\n \tstate->handle = buffer_manager.Pin(segment.block);\n \n-\tauto baseptr = state->handle->node->buffer + segment.GetBlockOffset();\n+\tauto baseptr = state->handle.Ptr() + segment.GetBlockOffset();\n \n \t// Load header values\n-\tauto dict = DictionaryCompressionStorage::GetDictionary(segment, *(state->handle));\n+\tauto dict = DictionaryCompressionStorage::GetDictionary(segment, state->handle);\n \tauto header_ptr = (dictionary_compression_header_t *)baseptr;\n \tauto index_buffer_offset = Load<uint32_t>((data_ptr_t)&header_ptr->index_buffer_offset);\n \tauto index_buffer_count = Load<uint32_t>((data_ptr_t)&header_ptr->index_buffer_count);\n@@ -454,8 +485,8 @@ void DictionaryCompressionStorage::StringScanPartial(ColumnSegment &segment, Col\n \tauto &scan_state = (CompressedStringScanState &)*state.scan_state;\n \tauto start = segment.GetRelativeIndex(state.row_index);\n \n-\tauto baseptr = scan_state.handle->node->buffer + segment.GetBlockOffset();\n-\tauto dict = DictionaryCompressionStorage::GetDictionary(segment, *scan_state.handle);\n+\tauto baseptr = scan_state.handle.Ptr() + segment.GetBlockOffset();\n+\tauto dict = DictionaryCompressionStorage::GetDictionary(segment, scan_state.handle);\n \n \tauto header_ptr = (dictionary_compression_header_t *)baseptr;\n \tauto index_buffer_offset = Load<uint32_t>((data_ptr_t)&header_ptr->index_buffer_offset);\n@@ -529,24 +560,11 @@ void DictionaryCompressionStorage::StringFetchRow(ColumnSegment &segment, Column\n                                                   Vector &result, idx_t result_idx) {\n \t// fetch a single row from the string segment\n \t// first pin the main buffer if it is not already pinned\n-\tauto primary_id = segment.block->BlockId();\n-\n-\tBufferHandle *handle_ptr;\n-\tauto entry = state.handles.find(primary_id);\n-\tif (entry == state.handles.end()) {\n-\t\t// not pinned yet: pin it\n-\t\tauto &buffer_manager = BufferManager::GetBufferManager(segment.db);\n-\t\tauto handle = buffer_manager.Pin(segment.block);\n-\t\thandle_ptr = handle.get();\n-\t\tstate.handles[primary_id] = move(handle);\n-\t} else {\n-\t\t// already pinned: use the pinned handle\n-\t\thandle_ptr = entry->second.get();\n-\t}\n+\tauto &handle = state.GetOrInsertHandle(segment);\n \n-\tauto baseptr = handle_ptr->node->buffer + segment.GetBlockOffset();\n+\tauto baseptr = handle.Ptr() + segment.GetBlockOffset();\n \tauto header_ptr = (dictionary_compression_header_t *)baseptr;\n-\tauto dict = DictionaryCompressionStorage::GetDictionary(segment, *handle_ptr);\n+\tauto dict = DictionaryCompressionStorage::GetDictionary(segment, handle);\n \tauto index_buffer_offset = Load<uint32_t>((data_ptr_t)&header_ptr->index_buffer_offset);\n \tauto width = (bitpacking_width_t)(Load<uint32_t>((data_ptr_t)&header_ptr->bitpacking_width));\n \tauto index_buffer_ptr = (uint32_t *)(baseptr + index_buffer_offset);\n@@ -589,7 +607,7 @@ idx_t DictionaryCompressionStorage::RequiredSpace(idx_t current_count, idx_t ind\n }\n \n StringDictionaryContainer DictionaryCompressionStorage::GetDictionary(ColumnSegment &segment, BufferHandle &handle) {\n-\tauto header_ptr = (dictionary_compression_header_t *)(handle.node->buffer + segment.GetBlockOffset());\n+\tauto header_ptr = (dictionary_compression_header_t *)(handle.Ptr() + segment.GetBlockOffset());\n \tStringDictionaryContainer container;\n \tcontainer.size = Load<uint32_t>((data_ptr_t)&header_ptr->dict_size);\n \tcontainer.end = Load<uint32_t>((data_ptr_t)&header_ptr->dict_end);\n@@ -598,7 +616,7 @@ StringDictionaryContainer DictionaryCompressionStorage::GetDictionary(ColumnSegm\n \n void DictionaryCompressionStorage::SetDictionary(ColumnSegment &segment, BufferHandle &handle,\n                                                  StringDictionaryContainer container) {\n-\tauto header_ptr = (dictionary_compression_header_t *)(handle.node->buffer + segment.GetBlockOffset());\n+\tauto header_ptr = (dictionary_compression_header_t *)(handle.Ptr() + segment.GetBlockOffset());\n \tStore<uint32_t>(container.size, (data_ptr_t)&header_ptr->dict_size);\n \tStore<uint32_t>(container.end, (data_ptr_t)&header_ptr->dict_end);\n }\ndiff --git a/src/storage/compression/fixed_size_uncompressed.cpp b/src/storage/compression/fixed_size_uncompressed.cpp\nindex cc0648248e3d..98cb6be92921 100644\n--- a/src/storage/compression/fixed_size_uncompressed.cpp\n+++ b/src/storage/compression/fixed_size_uncompressed.cpp\n@@ -105,7 +105,7 @@ void UncompressedFunctions::FinalizeCompress(CompressionState &state_p) {\n // Scan\n //===--------------------------------------------------------------------===//\n struct FixedSizeScanState : public SegmentScanState {\n-\tunique_ptr<BufferHandle> handle;\n+\tBufferHandle handle;\n };\n \n unique_ptr<SegmentScanState> FixedSizeInitScan(ColumnSegment &segment) {\n@@ -124,7 +124,7 @@ void FixedSizeScanPartial(ColumnSegment &segment, ColumnScanState &state, idx_t\n \tauto &scan_state = (FixedSizeScanState &)*state.scan_state;\n \tauto start = segment.GetRelativeIndex(state.row_index);\n \n-\tauto data = scan_state.handle->node->buffer + segment.GetBlockOffset();\n+\tauto data = scan_state.handle.Ptr() + segment.GetBlockOffset();\n \tauto source_data = data + start * sizeof(T);\n \n \t// copy the data from the base table\n@@ -137,7 +137,7 @@ void FixedSizeScan(ColumnSegment &segment, ColumnScanState &state, idx_t scan_co\n \tauto &scan_state = (FixedSizeScanState &)*state.scan_state;\n \tauto start = segment.GetRelativeIndex(state.row_index);\n \n-\tauto data = scan_state.handle->node->buffer + segment.GetBlockOffset();\n+\tauto data = scan_state.handle.Ptr() + segment.GetBlockOffset();\n \tauto source_data = data + start * sizeof(T);\n \n \tresult.SetVectorType(VectorType::FLAT_VECTOR);\n@@ -160,7 +160,7 @@ void FixedSizeFetchRow(ColumnSegment &segment, ColumnFetchState &state, row_t ro\n \tauto handle = buffer_manager.Pin(segment.block);\n \n \t// first fetch the data from the base table\n-\tauto data_ptr = handle->node->buffer + segment.GetBlockOffset() + row_id * sizeof(T);\n+\tauto data_ptr = handle.Ptr() + segment.GetBlockOffset() + row_id * sizeof(T);\n \n \tmemcpy(FlatVector::GetData(result) + result_idx * sizeof(T), data_ptr, sizeof(T));\n }\n@@ -215,7 +215,7 @@ idx_t FixedSizeAppend(ColumnSegment &segment, SegmentStatistics &stats, VectorDa\n \tauto handle = buffer_manager.Pin(segment.block);\n \tD_ASSERT(segment.GetBlockOffset() == 0);\n \n-\tauto target_ptr = handle->node->buffer;\n+\tauto target_ptr = handle.Ptr();\n \tidx_t max_tuple_count = Storage::BLOCK_SIZE / sizeof(T);\n \tidx_t copy_count = MinValue<idx_t>(count, max_tuple_count - segment.count);\n \ndiff --git a/src/storage/compression/rle.cpp b/src/storage/compression/rle.cpp\nindex c1dcfa342519..c47e7fb79ba9 100644\n--- a/src/storage/compression/rle.cpp\n+++ b/src/storage/compression/rle.cpp\n@@ -166,7 +166,7 @@ struct RLECompressState : public CompressionState {\n \n \tvoid WriteValue(T value, rle_count_t count, bool is_null) {\n \t\t// write the RLE entry\n-\t\tauto handle_ptr = handle->Ptr() + RLEConstants::RLE_HEADER_SIZE;\n+\t\tauto handle_ptr = handle.Ptr() + RLEConstants::RLE_HEADER_SIZE;\n \t\tauto data_pointer = (T *)handle_ptr;\n \t\tauto index_pointer = (rle_count_t *)(handle_ptr + max_rle_count * sizeof(T));\n \t\tdata_pointer[entry_count] = value;\n@@ -195,10 +195,11 @@ struct RLECompressState : public CompressionState {\n \t\tidx_t original_rle_offset = RLEConstants::RLE_HEADER_SIZE + max_rle_count * sizeof(T);\n \t\tidx_t minimal_rle_offset = AlignValue(RLEConstants::RLE_HEADER_SIZE + sizeof(T) * entry_count);\n \t\tidx_t total_segment_size = minimal_rle_offset + counts_size;\n-\t\tmemmove(handle->node->buffer + minimal_rle_offset, handle->node->buffer + original_rle_offset, counts_size);\n+\t\tauto data_ptr = handle.Ptr();\n+\t\tmemmove(data_ptr + minimal_rle_offset, data_ptr + original_rle_offset, counts_size);\n \t\t// store the final RLE offset within the segment\n-\t\tStore<uint64_t>(minimal_rle_offset, handle->node->buffer);\n-\t\thandle.reset();\n+\t\tStore<uint64_t>(minimal_rle_offset, data_ptr);\n+\t\thandle.Destroy();\n \n \t\tauto &state = checkpointer.GetCheckpointState();\n \t\tstate.FlushSegment(move(current_segment), total_segment_size);\n@@ -214,7 +215,7 @@ struct RLECompressState : public CompressionState {\n \tColumnDataCheckpointer &checkpointer;\n \tCompressionFunction *function;\n \tunique_ptr<ColumnSegment> current_segment;\n-\tunique_ptr<BufferHandle> handle;\n+\tBufferHandle handle;\n \n \tRLEState<T> state;\n \tidx_t entry_count = 0;\n@@ -251,12 +252,12 @@ struct RLEScanState : public SegmentScanState {\n \t\thandle = buffer_manager.Pin(segment.block);\n \t\tentry_pos = 0;\n \t\tposition_in_entry = 0;\n-\t\trle_count_offset = Load<uint64_t>(handle->node->buffer + segment.GetBlockOffset());\n+\t\trle_count_offset = Load<uint64_t>(handle.Ptr() + segment.GetBlockOffset());\n \t\tD_ASSERT(rle_count_offset <= Storage::BLOCK_SIZE);\n \t}\n \n \tvoid Skip(ColumnSegment &segment, idx_t skip_count) {\n-\t\tauto data = handle->node->buffer + segment.GetBlockOffset();\n+\t\tauto data = handle.Ptr() + segment.GetBlockOffset();\n \t\tauto index_pointer = (rle_count_t *)(data + rle_count_offset);\n \n \t\tfor (idx_t i = 0; i < skip_count; i++) {\n@@ -271,7 +272,7 @@ struct RLEScanState : public SegmentScanState {\n \t\t}\n \t}\n \n-\tunique_ptr<BufferHandle> handle;\n+\tBufferHandle handle;\n \tuint32_t rle_offset;\n \tidx_t entry_pos;\n \tidx_t position_in_entry;\n@@ -298,7 +299,7 @@ void RLEScanPartial(ColumnSegment &segment, ColumnScanState &state, idx_t scan_c\n                     idx_t result_offset) {\n \tauto &scan_state = (RLEScanState<T> &)*state.scan_state;\n \n-\tauto data = scan_state.handle->node->buffer + segment.GetBlockOffset();\n+\tauto data = scan_state.handle.Ptr() + segment.GetBlockOffset();\n \tauto data_pointer = (T *)(data + RLEConstants::RLE_HEADER_SIZE);\n \tauto index_pointer = (rle_count_t *)(data + scan_state.rle_count_offset);\n \n@@ -331,7 +332,7 @@ void RLEFetchRow(ColumnSegment &segment, ColumnFetchState &state, row_t row_id,\n \tRLEScanState<T> scan_state(segment);\n \tscan_state.Skip(segment, row_id);\n \n-\tauto data = scan_state.handle->node->buffer + segment.GetBlockOffset();\n+\tauto data = scan_state.handle.Ptr() + segment.GetBlockOffset();\n \tauto data_pointer = (T *)(data + RLEConstants::RLE_HEADER_SIZE);\n \tauto result_data = FlatVector::GetData<T>(result);\n \tresult_data[result_idx] = data_pointer[scan_state.entry_pos];\ndiff --git a/src/storage/compression/string_uncompressed.cpp b/src/storage/compression/string_uncompressed.cpp\nindex 732d72feae29..d86f0132be7f 100644\n--- a/src/storage/compression/string_uncompressed.cpp\n+++ b/src/storage/compression/string_uncompressed.cpp\n@@ -1,5 +1,6 @@\n #include \"duckdb/storage/string_uncompressed.hpp\"\n #include \"duckdb/storage/checkpoint/write_overflow_strings_to_disk.hpp\"\n+#include \"duckdb/common/pair.hpp\"\n #include \"miniz_wrapper.hpp\"\n \n namespace duckdb {\n@@ -74,8 +75,8 @@ void UncompressedStringStorage::StringScanPartial(ColumnSegment &segment, Column\n \tauto &scan_state = (StringScanState &)*state.scan_state;\n \tauto start = segment.GetRelativeIndex(state.row_index);\n \n-\tauto baseptr = scan_state.handle->node->buffer + segment.GetBlockOffset();\n-\tauto dict = GetDictionary(segment, *scan_state.handle);\n+\tauto baseptr = scan_state.handle.Ptr() + segment.GetBlockOffset();\n+\tauto dict = GetDictionary(segment, scan_state.handle);\n \tauto base_data = (int32_t *)(baseptr + DICTIONARY_HEADER_SIZE);\n \tauto result_data = FlatVector::GetData<string_t>(result);\n \n@@ -98,26 +99,30 @@ void UncompressedStringStorage::StringScan(ColumnSegment &segment, ColumnScanSta\n //===--------------------------------------------------------------------===//\n // Fetch\n //===--------------------------------------------------------------------===//\n-void UncompressedStringStorage::StringFetchRow(ColumnSegment &segment, ColumnFetchState &state, row_t row_id,\n-                                               Vector &result, idx_t result_idx) {\n-\t// fetch a single row from the string segment\n-\t// first pin the main buffer if it is not already pinned\n+BufferHandle &ColumnFetchState::GetOrInsertHandle(ColumnSegment &segment) {\n \tauto primary_id = segment.block->BlockId();\n \n-\tBufferHandle *handle_ptr;\n-\tauto entry = state.handles.find(primary_id);\n-\tif (entry == state.handles.end()) {\n+\tauto entry = handles.find(primary_id);\n+\tif (entry == handles.end()) {\n \t\t// not pinned yet: pin it\n \t\tauto &buffer_manager = BufferManager::GetBufferManager(segment.db);\n \t\tauto handle = buffer_manager.Pin(segment.block);\n-\t\thandle_ptr = handle.get();\n-\t\tstate.handles[primary_id] = move(handle);\n+\t\tauto entry = handles.insert(make_pair(primary_id, move(handle)));\n+\t\treturn entry.first->second;\n \t} else {\n \t\t// already pinned: use the pinned handle\n-\t\thandle_ptr = entry->second.get();\n+\t\treturn entry->second;\n \t}\n-\tauto baseptr = handle_ptr->node->buffer + segment.GetBlockOffset();\n-\tauto dict = GetDictionary(segment, *handle_ptr);\n+}\n+\n+void UncompressedStringStorage::StringFetchRow(ColumnSegment &segment, ColumnFetchState &state, row_t row_id,\n+                                               Vector &result, idx_t result_idx) {\n+\t// fetch a single row from the string segment\n+\t// first pin the main buffer if it is not already pinned\n+\tauto &handle = state.GetOrInsertHandle(segment);\n+\n+\tauto baseptr = handle.Ptr() + segment.GetBlockOffset();\n+\tauto dict = GetDictionary(segment, handle);\n \tauto base_data = (int32_t *)(baseptr + DICTIONARY_HEADER_SIZE);\n \tauto result_data = FlatVector::GetData<string_t>(result);\n \n@@ -143,7 +148,7 @@ unique_ptr<CompressedSegmentState> UncompressedStringStorage::StringInitSegment(\n \t\tStringDictionaryContainer dictionary;\n \t\tdictionary.size = 0;\n \t\tdictionary.end = Storage::BLOCK_SIZE;\n-\t\tSetDictionary(segment, *handle, dictionary);\n+\t\tSetDictionary(segment, handle, dictionary);\n \t}\n \treturn make_unique<UncompressedStringSegmentState>();\n }\n@@ -151,7 +156,7 @@ unique_ptr<CompressedSegmentState> UncompressedStringStorage::StringInitSegment(\n idx_t UncompressedStringStorage::FinalizeAppend(ColumnSegment &segment, SegmentStatistics &stats) {\n \tauto &buffer_manager = BufferManager::GetBufferManager(segment.db);\n \tauto handle = buffer_manager.Pin(segment.block);\n-\tauto dict = GetDictionary(segment, *handle);\n+\tauto dict = GetDictionary(segment, handle);\n \tD_ASSERT(dict.end == Storage::BLOCK_SIZE);\n \t// compute the total size required to store this segment\n \tauto offset_size = DICTIONARY_HEADER_SIZE + segment.count * sizeof(int32_t);\n@@ -163,11 +168,12 @@ idx_t UncompressedStringStorage::FinalizeAppend(ColumnSegment &segment, SegmentS\n \t// the block has space left: figure out how much space we can save\n \tauto move_amount = Storage::BLOCK_SIZE - total_size;\n \t// move the dictionary so it lines up exactly with the offsets\n-\tmemmove(handle->node->buffer + offset_size, handle->node->buffer + dict.end - dict.size, dict.size);\n+\tauto dataptr = handle.Ptr();\n+\tmemmove(dataptr + offset_size, dataptr + dict.end - dict.size, dict.size);\n \tdict.end -= move_amount;\n \tD_ASSERT(dict.end == total_size);\n \t// write the new dictionary (with the updated \"end\")\n-\tSetDictionary(segment, *handle, dict);\n+\tSetDictionary(segment, handle, dict);\n \treturn total_size;\n }\n \n@@ -191,13 +197,13 @@ CompressionFunction StringUncompressed::GetFunction(PhysicalType data_type) {\n //===--------------------------------------------------------------------===//\n void UncompressedStringStorage::SetDictionary(ColumnSegment &segment, BufferHandle &handle,\n                                               StringDictionaryContainer container) {\n-\tauto startptr = handle.node->buffer + segment.GetBlockOffset();\n+\tauto startptr = handle.Ptr() + segment.GetBlockOffset();\n \tStore<uint32_t>(container.size, startptr);\n \tStore<uint32_t>(container.end, startptr + sizeof(uint32_t));\n }\n \n StringDictionaryContainer UncompressedStringStorage::GetDictionary(ColumnSegment &segment, BufferHandle &handle) {\n-\tauto startptr = handle.node->buffer + segment.GetBlockOffset();\n+\tauto startptr = handle.Ptr() + segment.GetBlockOffset();\n \tStringDictionaryContainer container;\n \tcontainer.size = Load<uint32_t>(startptr);\n \tcontainer.end = Load<uint32_t>(startptr + sizeof(uint32_t));\n@@ -228,7 +234,7 @@ void UncompressedStringStorage::WriteStringMemory(ColumnSegment &segment, string\n                                                   int32_t &result_offset) {\n \tuint32_t total_length = string.GetSize() + sizeof(uint32_t);\n \tshared_ptr<BlockHandle> block;\n-\tunique_ptr<BufferHandle> handle;\n+\tBufferHandle handle;\n \n \tauto &buffer_manager = BufferManager::GetBufferManager(segment.db);\n \tauto &state = (UncompressedStringSegmentState &)*segment.GetSegmentState();\n@@ -256,7 +262,7 @@ void UncompressedStringStorage::WriteStringMemory(ColumnSegment &segment, string\n \tresult_offset = state.head->offset;\n \n \t// copy the string and the length there\n-\tauto ptr = handle->node->buffer + state.head->offset;\n+\tauto ptr = handle.Ptr() + state.head->offset;\n \tStore<uint32_t>(string.GetSize(), ptr);\n \tptr += sizeof(uint32_t);\n \tmemcpy(ptr, string.GetDataUnsafe(), string.GetSize());\n@@ -277,8 +283,8 @@ string_t UncompressedStringStorage::ReadOverflowString(ColumnSegment &segment, V\n \t\tauto handle = buffer_manager.Pin(block_handle);\n \n \t\t// read header\n-\t\tuint32_t compressed_size = Load<uint32_t>(handle->node->buffer + offset);\n-\t\tuint32_t uncompressed_size = Load<uint32_t>(handle->node->buffer + offset + sizeof(uint32_t));\n+\t\tuint32_t compressed_size = Load<uint32_t>(handle.Ptr() + offset);\n+\t\tuint32_t uncompressed_size = Load<uint32_t>(handle.Ptr() + offset + sizeof(uint32_t));\n \t\tuint32_t remaining = compressed_size;\n \t\toffset += 2 * sizeof(uint32_t);\n \n@@ -287,7 +293,7 @@ string_t UncompressedStringStorage::ReadOverflowString(ColumnSegment &segment, V\n \n \t\t// If string is in single block we decompress straight from it, else we copy first\n \t\tif (remaining <= Storage::BLOCK_SIZE - sizeof(block_id_t) - offset) {\n-\t\t\tdecompression_ptr = handle->node->buffer + offset;\n+\t\t\tdecompression_ptr = handle.Ptr() + offset;\n \t\t} else {\n \t\t\tdecompression_buffer = std::unique_ptr<data_t[]>(new data_t[compressed_size]);\n \t\t\tauto target_ptr = decompression_buffer.get();\n@@ -295,14 +301,14 @@ string_t UncompressedStringStorage::ReadOverflowString(ColumnSegment &segment, V\n \t\t\t// now append the string to the single buffer\n \t\t\twhile (remaining > 0) {\n \t\t\t\tidx_t to_write = MinValue<idx_t>(remaining, Storage::BLOCK_SIZE - sizeof(block_id_t) - offset);\n-\t\t\t\tmemcpy(target_ptr, handle->node->buffer + offset, to_write);\n+\t\t\t\tmemcpy(target_ptr, handle.Ptr() + offset, to_write);\n \n \t\t\t\tremaining -= to_write;\n \t\t\t\toffset += to_write;\n \t\t\t\ttarget_ptr += to_write;\n \t\t\t\tif (remaining > 0) {\n \t\t\t\t\t// read the next block\n-\t\t\t\t\tblock_id_t next_block = Load<block_id_t>(handle->node->buffer + offset);\n+\t\t\t\t\tblock_id_t next_block = Load<block_id_t>(handle.Ptr() + offset);\n \t\t\t\t\tblock_handle = buffer_manager.RegisterBlock(next_block);\n \t\t\t\t\thandle = buffer_manager.Pin(block_handle);\n \t\t\t\t\toffset = 0;\n@@ -314,12 +320,12 @@ string_t UncompressedStringStorage::ReadOverflowString(ColumnSegment &segment, V\n \t\t// overflow strings on disk are gzipped, decompress here\n \t\tauto decompressed_target_handle =\n \t\t    buffer_manager.Allocate(MaxValue<idx_t>(Storage::BLOCK_SIZE, uncompressed_size));\n-\t\tauto decompressed_target_ptr = decompressed_target_handle->node->buffer;\n+\t\tauto decompressed_target_ptr = decompressed_target_handle.Ptr();\n \t\tMiniZStream s;\n \t\ts.Decompress((const char *)decompression_ptr, compressed_size, (char *)decompressed_target_ptr,\n \t\t             uncompressed_size);\n \n-\t\tauto final_buffer = decompressed_target_handle->node->buffer;\n+\t\tauto final_buffer = decompressed_target_handle.Ptr();\n \t\tStringVector::AddHandle(result, move(decompressed_target_handle));\n \t\treturn ReadString(final_buffer, 0, uncompressed_size);\n \t} else {\n@@ -328,7 +334,7 @@ string_t UncompressedStringStorage::ReadOverflowString(ColumnSegment &segment, V\n \t\tauto entry = state.overflow_blocks.find(block);\n \t\tD_ASSERT(entry != state.overflow_blocks.end());\n \t\tauto handle = buffer_manager.Pin(entry->second->block);\n-\t\tauto final_buffer = handle->node->buffer;\n+\t\tauto final_buffer = handle.Ptr();\n \t\tStringVector::AddHandle(result, move(handle));\n \t\treturn ReadStringWithLength(final_buffer, offset);\n \t}\ndiff --git a/src/storage/compression/validity_uncompressed.cpp b/src/storage/compression/validity_uncompressed.cpp\nindex 386935e43ad5..065e395616b9 100644\n--- a/src/storage/compression/validity_uncompressed.cpp\n+++ b/src/storage/compression/validity_uncompressed.cpp\n@@ -202,7 +202,7 @@ idx_t ValidityFinalAnalyze(AnalyzeState &state_p) {\n // Scan\n //===--------------------------------------------------------------------===//\n struct ValidityScanState : public SegmentScanState {\n-\tunique_ptr<BufferHandle> handle;\n+\tBufferHandle handle;\n };\n \n unique_ptr<SegmentScanState> ValidityInitScan(ColumnSegment &segment) {\n@@ -223,7 +223,7 @@ void ValidityScanPartial(ColumnSegment &segment, ColumnScanState &state, idx_t s\n \tauto &scan_state = (ValidityScanState &)*state.scan_state;\n \n \tauto &result_mask = FlatVector::Validity(result);\n-\tauto buffer_ptr = scan_state.handle->node->buffer + segment.GetBlockOffset();\n+\tauto buffer_ptr = scan_state.handle.Ptr() + segment.GetBlockOffset();\n \tauto input_data = (validity_t *)buffer_ptr;\n \n #ifdef DEBUG\n@@ -348,7 +348,7 @@ void ValidityScan(ColumnSegment &segment, ColumnScanState &state, idx_t scan_cou\n \t\t// note: this is only an optimization which avoids having to do messy bitshifting in the common case\n \t\t// it is not required for correctness\n \t\tauto &result_mask = FlatVector::Validity(result);\n-\t\tauto buffer_ptr = scan_state.handle->node->buffer + segment.GetBlockOffset();\n+\t\tauto buffer_ptr = scan_state.handle.Ptr() + segment.GetBlockOffset();\n \t\tauto input_data = (validity_t *)buffer_ptr;\n \t\tauto result_data = (validity_t *)result_mask.GetData();\n \t\tidx_t start_offset = start / ValidityMask::BITS_PER_VALUE;\n@@ -377,7 +377,7 @@ void ValidityFetchRow(ColumnSegment &segment, ColumnFetchState &state, row_t row\n \tD_ASSERT(row_id >= 0 && row_id < row_t(segment.count));\n \tauto &buffer_manager = BufferManager::GetBufferManager(segment.db);\n \tauto handle = buffer_manager.Pin(segment.block);\n-\tauto dataptr = handle->node->buffer + segment.GetBlockOffset();\n+\tauto dataptr = handle.Ptr() + segment.GetBlockOffset();\n \tValidityMask mask((validity_t *)dataptr);\n \tauto &result_mask = FlatVector::Validity(result);\n \tif (!mask.RowIsValidUnsafe(row_id)) {\n@@ -392,7 +392,7 @@ unique_ptr<CompressedSegmentState> ValidityInitSegment(ColumnSegment &segment, b\n \tauto &buffer_manager = BufferManager::GetBufferManager(segment.db);\n \tif (block_id == INVALID_BLOCK) {\n \t\tauto handle = buffer_manager.Pin(segment.block);\n-\t\tmemset(handle->node->buffer, 0xFF, Storage::BLOCK_SIZE);\n+\t\tmemset(handle.Ptr(), 0xFF, Storage::BLOCK_SIZE);\n \t}\n \treturn nullptr;\n }\n@@ -412,7 +412,7 @@ idx_t ValidityAppend(ColumnSegment &segment, SegmentStatistics &stats, VectorDat\n \tauto &buffer_manager = BufferManager::GetBufferManager(segment.db);\n \tauto handle = buffer_manager.Pin(segment.block);\n \n-\tValidityMask mask((validity_t *)handle->node->buffer);\n+\tValidityMask mask((validity_t *)handle.Ptr());\n \tfor (idx_t i = 0; i < append_count; i++) {\n \t\tauto idx = data.sel->get_index(offset + i);\n \t\tif (!data.validity.RowIsValidUnsafe(idx)) {\n@@ -441,7 +441,7 @@ void ValidityRevertAppend(ColumnSegment &segment, idx_t start_row) {\n \t\tidx_t byte_pos = start_bit / 8;\n \t\tidx_t bit_start = byte_pos * 8;\n \t\tidx_t bit_end = (byte_pos + 1) * 8;\n-\t\tValidityMask mask((validity_t *)handle->node->buffer + byte_pos);\n+\t\tValidityMask mask((validity_t *)handle.Ptr() + byte_pos);\n \t\tfor (idx_t i = start_bit; i < bit_end; i++) {\n \t\t\tmask.SetValid(i - bit_start);\n \t\t}\n@@ -450,7 +450,7 @@ void ValidityRevertAppend(ColumnSegment &segment, idx_t start_row) {\n \t\trevert_start = start_bit / 8;\n \t}\n \t// for the rest, we just memset\n-\tmemset(handle->node->buffer + revert_start, 0xFF, Storage::BLOCK_SIZE - revert_start);\n+\tmemset(handle.Ptr() + revert_start, 0xFF, Storage::BLOCK_SIZE - revert_start);\n }\n \n //===--------------------------------------------------------------------===//\ndiff --git a/src/storage/data_table.cpp b/src/storage/data_table.cpp\nindex f0da3a1d98b5..4846b7787b5e 100644\n--- a/src/storage/data_table.cpp\n+++ b/src/storage/data_table.cpp\n@@ -87,7 +87,7 @@ DataTable::DataTable(ClientContext &context, DataTable &parent, ColumnDefinition\n \n \tauto &transaction = Transaction::GetTransaction(context);\n \n-\tExpressionExecutor executor;\n+\tExpressionExecutor executor(Allocator::Get(context));\n \tDataChunk dummy_chunk;\n \tVector result(new_column_type);\n \tif (!default_value) {\n@@ -212,10 +212,11 @@ DataTable::DataTable(ClientContext &context, DataTable &parent, idx_t changed_id\n \t\t\tscan_types.push_back(parent.column_definitions[bound_columns[i]].Type());\n \t\t}\n \t}\n+\tauto &allocator = Allocator::Get(context);\n \tDataChunk scan_chunk;\n-\tscan_chunk.Initialize(scan_types);\n+\tscan_chunk.Initialize(allocator, scan_types);\n \n-\tExpressionExecutor executor;\n+\tExpressionExecutor executor(allocator);\n \texecutor.AddExpression(cast_expr);\n \n \tTableScanState scan_state;\n@@ -441,7 +442,7 @@ static void VerifyGeneratedExpressionSuccess(TableCatalogEntry &table, DataChunk\n                                              column_t index) {\n \tauto &col = table.columns[index];\n \tD_ASSERT(col.Generated());\n-\tExpressionExecutor executor(expr);\n+\tExpressionExecutor executor(Allocator::DefaultAllocator(), expr);\n \tVector result(col.Type());\n \ttry {\n \t\texecutor.ExecuteExpression(chunk, result);\n@@ -451,7 +452,7 @@ static void VerifyGeneratedExpressionSuccess(TableCatalogEntry &table, DataChunk\n }\n \n static void VerifyCheckConstraint(TableCatalogEntry &table, Expression &expr, DataChunk &chunk) {\n-\tExpressionExecutor executor(expr);\n+\tExpressionExecutor executor(Allocator::DefaultAllocator(), expr);\n \tVector result(LogicalType::INTEGER);\n \ttry {\n \t\texecutor.ExecuteExpression(chunk, result);\n@@ -721,7 +722,7 @@ void DataTable::Append(Transaction &transaction, DataChunk &chunk, TableAppendSt\n \t\t\t// merge the stats\n \t\t\tlock_guard<mutex> stats_guard(stats_lock);\n \t\t\tfor (idx_t i = 0; i < column_definitions.size(); i++) {\n-\t\t\t\tcolumn_stats[i]->stats->Merge(*current_row_group->GetStatistics(i));\n+\t\t\t\tcurrent_row_group->MergeIntoStatistics(i, *column_stats[i]->stats);\n \t\t\t}\n \t\t}\n \t\tstate.remaining_append_count -= append_count;\n@@ -770,7 +771,7 @@ void DataTable::ScanTableSegment(idx_t row_start, idx_t count, const std::functi\n \t\ttypes.push_back(col.Type());\n \t}\n \tDataChunk chunk;\n-\tchunk.Initialize(types);\n+\tchunk.Initialize(Allocator::Get(db), types);\n \n \tCreateIndexScanState state;\n \n@@ -803,6 +804,9 @@ void DataTable::ScanTableSegment(idx_t row_start, idx_t count, const std::functi\n }\n \n void DataTable::WriteToLog(WriteAheadLog &log, idx_t row_start, idx_t count) {\n+\tif (log.skip_writing) {\n+\t\treturn;\n+\t}\n \tlog.WriteSetTable(info->schema, info->table);\n \tScanTableSegment(row_start, count, [&](DataChunk &chunk) { log.WriteInsert(chunk); });\n }\n@@ -966,7 +970,7 @@ void DataTable::RemoveFromIndexes(Vector &row_identifiers, idx_t count) {\n \t\tstate.column_ids.push_back(i);\n \t}\n \tDataChunk result;\n-\tresult.Initialize(types);\n+\tresult.Initialize(Allocator::Get(db), types);\n \n \trow_group->InitializeScanWithOffset(state.row_group_scan_state, row_group_vector_idx);\n \trow_group->ScanCommitted(state.row_group_scan_state, result,\n@@ -1027,7 +1031,7 @@ idx_t DataTable::Delete(TableCatalogEntry &table, ClientContext &context, Vector\n \t\t\tcol_ids.push_back(column_definitions[i].StorageOid());\n \t\t\ttypes.emplace_back(column_definitions[i].Type());\n \t\t}\n-\t\tverify_chunk.Initialize(types);\n+\t\tverify_chunk.Initialize(Allocator::Get(context), types);\n \t\tFetch(transaction, verify_chunk, col_ids, row_identifiers, count, fetch_state);\n \t}\n \tVerifyDeleteConstraints(table, context, verify_chunk);\n@@ -1264,8 +1268,10 @@ bool DataTable::ScanCreateIndex(CreateIndexScanState &state, DataChunk &result,\n }\n \n void DataTable::AddIndex(unique_ptr<Index> index, const vector<unique_ptr<Expression>> &expressions) {\n+\tauto &allocator = Allocator::Get(db);\n+\n \tDataChunk result;\n-\tresult.Initialize(index->logical_types);\n+\tresult.Initialize(allocator, index->logical_types);\n \n \tDataChunk intermediate;\n \tvector<LogicalType> intermediate_types;\n@@ -1276,7 +1282,7 @@ void DataTable::AddIndex(unique_ptr<Index> index, const vector<unique_ptr<Expres\n \t\tintermediate_types.push_back(col.Type());\n \t}\n \tintermediate_types.emplace_back(LogicalType::ROW_TYPE);\n-\tintermediate.Initialize(intermediate_types);\n+\tintermediate.Initialize(allocator, intermediate_types);\n \n \t// initialize an index scan\n \tCreateIndexScanState state;\n@@ -1290,7 +1296,7 @@ void DataTable::AddIndex(unique_ptr<Index> index, const vector<unique_ptr<Expres\n \t{\n \t\tIndexLock lock;\n \t\tindex->InitializeLock(lock);\n-\t\tExpressionExecutor executor(expressions);\n+\t\tExpressionExecutor executor(allocator, expressions);\n \t\twhile (true) {\n \t\t\tintermediate.Reset();\n \t\t\t// scan a new chunk from the table to index\ndiff --git a/src/storage/index.cpp b/src/storage/index.cpp\nindex bd5610357520..686cac412426 100644\n--- a/src/storage/index.cpp\n+++ b/src/storage/index.cpp\n@@ -9,7 +9,8 @@ namespace duckdb {\n \n Index::Index(IndexType type, const vector<column_t> &column_ids_p,\n              const vector<unique_ptr<Expression>> &unbound_expressions, IndexConstraintType constraint_type_p)\n-    : type(type), column_ids(column_ids_p), constraint_type(constraint_type_p) {\n+    : type(type), column_ids(column_ids_p), constraint_type(constraint_type_p),\n+      executor(Allocator::DefaultAllocator()) {\n \tfor (auto &expr : unbound_expressions) {\n \t\ttypes.push_back(expr->return_type.InternalType());\n \t\tlogical_types.push_back(expr->return_type);\ndiff --git a/src/storage/local_storage.cpp b/src/storage/local_storage.cpp\nindex 8eafff7fe25e..ea4e2ce6eb52 100644\n--- a/src/storage/local_storage.cpp\n+++ b/src/storage/local_storage.cpp\n@@ -11,7 +11,8 @@\n \n namespace duckdb {\n \n-LocalTableStorage::LocalTableStorage(DataTable &table) : table(table), active_scans(0) {\n+LocalTableStorage::LocalTableStorage(DataTable &table)\n+    : table(table), allocator(Allocator::Get(table.db)), collection(allocator), active_scans(0) {\n \tClear();\n }\n \n@@ -364,7 +365,7 @@ bool LocalStorage::ScanTableStorage(DataTable &table, LocalTableStorage &storage\n \t}\n \n \tDataChunk chunk;\n-\tchunk.Initialize(table.GetTypes());\n+\tchunk.Initialize(storage.allocator, table.GetTypes());\n \n \t// initialize the scan\n \tLocalScanState state;\n@@ -447,7 +448,8 @@ void LocalStorage::AddColumn(DataTable *old_dt, DataTable *new_dt, ColumnDefinit\n \n \t// now add the new column filled with the default value to all chunks\n \tconst auto &new_column_type = new_column.Type();\n-\tExpressionExecutor executor;\n+\tauto &allocator = Allocator::DefaultAllocator();\n+\tExpressionExecutor executor(allocator);\n \tDataChunk dummy_chunk;\n \tif (default_value) {\n \t\texecutor.AddExpression(*default_value);\ndiff --git a/src/storage/meta_block_reader.cpp b/src/storage/meta_block_reader.cpp\nindex f5448307793d..006ccb77bbe3 100644\n--- a/src/storage/meta_block_reader.cpp\n+++ b/src/storage/meta_block_reader.cpp\n@@ -5,8 +5,7 @@\n \n namespace duckdb {\n \n-MetaBlockReader::MetaBlockReader(DatabaseInstance &db, block_id_t block_id)\n-    : db(db), handle(nullptr), offset(0), next_block(-1) {\n+MetaBlockReader::MetaBlockReader(DatabaseInstance &db, block_id_t block_id) : db(db), offset(0), next_block(-1) {\n \tReadNewBlock(block_id);\n }\n \n@@ -14,12 +13,12 @@ MetaBlockReader::~MetaBlockReader() {\n }\n \n void MetaBlockReader::ReadData(data_ptr_t buffer, idx_t read_size) {\n-\twhile (offset + read_size > handle->node->size) {\n+\twhile (offset + read_size > handle.GetFileBuffer().size) {\n \t\t// cannot read entire entry from block\n \t\t// first read what we can from this block\n-\t\tidx_t to_read = handle->node->size - offset;\n+\t\tidx_t to_read = handle.GetFileBuffer().size - offset;\n \t\tif (to_read > 0) {\n-\t\t\tmemcpy(buffer, handle->node->buffer + offset, to_read);\n+\t\t\tmemcpy(buffer, handle.Ptr() + offset, to_read);\n \t\t\tread_size -= to_read;\n \t\t\tbuffer += to_read;\n \t\t}\n@@ -27,7 +26,7 @@ void MetaBlockReader::ReadData(data_ptr_t buffer, idx_t read_size) {\n \t\tReadNewBlock(next_block);\n \t}\n \t// we have enough left in this block to read from the buffer\n-\tmemcpy(buffer, handle->node->buffer + offset, read_size);\n+\tmemcpy(buffer, handle.Ptr() + offset, read_size);\n \toffset += read_size;\n }\n \n@@ -39,7 +38,7 @@ void MetaBlockReader::ReadNewBlock(block_id_t id) {\n \tblock = buffer_manager.RegisterBlock(id);\n \thandle = buffer_manager.Pin(block);\n \n-\tnext_block = Load<block_id_t>(handle->node->buffer);\n+\tnext_block = Load<block_id_t>(handle.Ptr());\n \tD_ASSERT(next_block >= -1);\n \toffset = sizeof(block_id_t);\n }\ndiff --git a/src/storage/storage_manager.cpp b/src/storage/storage_manager.cpp\nindex 5c6f164b344f..e79218d2ce7b 100644\n--- a/src/storage/storage_manager.cpp\n+++ b/src/storage/storage_manager.cpp\n@@ -49,15 +49,15 @@ void StorageManager::Initialize() {\n \tif (in_memory && read_only) {\n \t\tthrow CatalogException(\"Cannot launch in-memory database in read-only mode!\");\n \t}\n+\tauto &config = DBConfig::GetConfig(db);\n+\tauto &catalog = Catalog::GetCatalog(db);\n+\tbuffer_manager = make_unique<BufferManager>(db, config.temporary_directory, config.maximum_memory);\n \n \t// first initialize the base system catalogs\n \t// these are never written to the WAL\n \tConnection con(db);\n \tcon.BeginTransaction();\n \n-\tauto &config = DBConfig::GetConfig(db);\n-\tauto &catalog = Catalog::GetCatalog(*con.context);\n-\n \t// create the default schema\n \tCreateSchemaInfo info;\n \tinfo.schema = DEFAULT_SCHEMA;\n@@ -78,7 +78,6 @@ void StorageManager::Initialize() {\n \t\tLoadDatabase();\n \t} else {\n \t\tblock_manager = make_unique<InMemoryBlockManager>();\n-\t\tbuffer_manager = make_unique<BufferManager>(db, config.temporary_directory, config.maximum_memory);\n \t}\n }\n \n@@ -100,13 +99,11 @@ void StorageManager::LoadDatabase() {\n \t\t}\n \t\t// initialize the block manager while creating a new db file\n \t\tblock_manager = make_unique<SingleFileBlockManager>(db, path, read_only, true, config.use_direct_io);\n-\t\tbuffer_manager = make_unique<BufferManager>(db, config.temporary_directory, config.maximum_memory);\n \t} else {\n \t\t// initialize the block manager while loading the current db file\n \t\tauto sf_bm = make_unique<SingleFileBlockManager>(db, path, read_only, false, config.use_direct_io);\n \t\tauto sf = sf_bm.get();\n \t\tblock_manager = move(sf_bm);\n-\t\tbuffer_manager = make_unique<BufferManager>(db, config.temporary_directory, config.maximum_memory);\n \t\tsf->LoadFreeList();\n \n \t\t//! Load from storage\ndiff --git a/src/storage/table/column_checkpoint_state.cpp b/src/storage/table/column_checkpoint_state.cpp\nindex 90f0811e1619..7e9d5f257fa7 100644\n--- a/src/storage/table/column_checkpoint_state.cpp\n+++ b/src/storage/table/column_checkpoint_state.cpp\n@@ -21,6 +21,11 @@ ColumnCheckpointState::ColumnCheckpointState(RowGroup &row_group, ColumnData &co\n ColumnCheckpointState::~ColumnCheckpointState() {\n }\n \n+unique_ptr<BaseStatistics> ColumnCheckpointState::GetStatistics() {\n+\tD_ASSERT(global_stats);\n+\treturn move(global_stats);\n+}\n+\n void ColumnCheckpointState::FlushSegment(unique_ptr<ColumnSegment> segment, idx_t segment_size) {\n \tD_ASSERT(segment_size <= Storage::BLOCK_SIZE);\n \tauto tuple_count = segment->count.load();\n@@ -96,7 +101,7 @@ void ColumnCheckpointState::FlushSegment(unique_ptr<ColumnSegment> segment, idx_\n \t\t\t// pin the new block\n \t\t\tauto new_handle = buffer_manager.Pin(partial_block->block);\n \t\t\t// memcpy the contents of the old block to the new block\n-\t\t\tmemcpy(new_handle->Ptr() + offset_in_block, old_handle->Ptr(), segment_size);\n+\t\t\tmemcpy(new_handle.Ptr() + offset_in_block, old_handle.Ptr(), segment_size);\n \t\t} else {\n \t\t\t// convert the segment into a persistent segment that points to this block\n \t\t\tsegment->ConvertToPersistent(block_id);\ndiff --git a/src/storage/table/column_data_checkpointer.cpp b/src/storage/table/column_data_checkpointer.cpp\nindex 44c132951b8a..2c6bc542bbfa 100644\n--- a/src/storage/table/column_data_checkpointer.cpp\n+++ b/src/storage/table/column_data_checkpointer.cpp\n@@ -168,7 +168,6 @@ void ColumnDataCheckpointer::WriteToDisk() {\n \t    [&](Vector &scan_vector, idx_t count) { best_function->compress(*compress_state, scan_vector, count); });\n \tbest_function->compress_finalize(*compress_state);\n \n-\t// now we actually write the data to disk\n \towned_segment.reset();\n }\n \ndiff --git a/src/storage/table/row_group.cpp b/src/storage/table/row_group.cpp\nindex ffbdc08083eb..9742dddb73d9 100644\n--- a/src/storage/table/row_group.cpp\n+++ b/src/storage/table/row_group.cpp\n@@ -641,14 +641,22 @@ unique_ptr<BaseStatistics> RowGroup::GetStatistics(idx_t column_idx) {\n \treturn stats[column_idx]->statistics->Copy();\n }\n \n-void RowGroup::MergeStatistics(idx_t column_idx, BaseStatistics &other) {\n+void RowGroup::MergeStatistics(idx_t column_idx, const BaseStatistics &other) {\n \tD_ASSERT(column_idx < stats.size());\n \n \tlock_guard<mutex> slock(stats_lock);\n \tstats[column_idx]->statistics->Merge(other);\n }\n \n+void RowGroup::MergeIntoStatistics(idx_t column_idx, BaseStatistics &other) {\n+\tD_ASSERT(column_idx < stats.size());\n+\n+\tlock_guard<mutex> slock(stats_lock);\n+\tother.Merge(*stats[column_idx]->statistics);\n+}\n+\n RowGroupPointer RowGroup::Checkpoint(TableDataWriter &writer, vector<unique_ptr<BaseStatistics>> &global_stats) {\n+\tRowGroupPointer row_group_pointer;\n \tvector<unique_ptr<ColumnCheckpointState>> states;\n \tstates.reserve(columns.size());\n \n@@ -663,12 +671,12 @@ RowGroupPointer RowGroup::Checkpoint(TableDataWriter &writer, vector<unique_ptr<\n \t\tD_ASSERT(stats);\n \n \t\tglobal_stats[column_idx]->Merge(*stats);\n+\t\trow_group_pointer.statistics.push_back(move(stats));\n \t\tstates.push_back(move(checkpoint_state));\n \t}\n \n \t// construct the row group pointer and write the column meta data to disk\n \tD_ASSERT(states.size() == columns.size());\n-\tRowGroupPointer row_group_pointer;\n \trow_group_pointer.row_start = start;\n \trow_group_pointer.tuple_count = count;\n \tfor (auto &state : states) {\n@@ -678,7 +686,6 @@ RowGroupPointer RowGroup::Checkpoint(TableDataWriter &writer, vector<unique_ptr<\n \n \t\t// store the stats and the data pointers in the row group pointers\n \t\trow_group_pointer.data_pointers.push_back(pointer);\n-\t\trow_group_pointer.statistics.push_back(state->GetStatistics());\n \n \t\t// now flush the actual column data to disk\n \t\tstate->FlushToDisk();\ndiff --git a/src/storage/table/standard_column_data.cpp b/src/storage/table/standard_column_data.cpp\nindex 0b53e5323135..c17985606341 100644\n--- a/src/storage/table/standard_column_data.cpp\n+++ b/src/storage/table/standard_column_data.cpp\n@@ -159,9 +159,9 @@ struct StandardColumnCheckpointState : public ColumnCheckpointState {\n \n public:\n \tunique_ptr<BaseStatistics> GetStatistics() override {\n-\t\tauto stats = global_stats->Copy();\n-\t\tstats->validity_stats = validity_state->GetStatistics();\n-\t\treturn stats;\n+\t\tD_ASSERT(global_stats);\n+\t\tglobal_stats->validity_stats = validity_state->GetStatistics();\n+\t\treturn move(global_stats);\n \t}\n \n \tvoid FlushToDisk() override {\ndiff --git a/src/transaction/commit_state.cpp b/src/transaction/commit_state.cpp\nindex 1ec8d37a1025..fce86498931a 100644\n--- a/src/transaction/commit_state.cpp\n+++ b/src/transaction/commit_state.cpp\n@@ -146,7 +146,7 @@ void CommitState::WriteDelete(DeleteInfo *info) {\n \tif (!delete_chunk) {\n \t\tdelete_chunk = make_unique<DataChunk>();\n \t\tvector<LogicalType> delete_types = {LogicalType::ROW_TYPE};\n-\t\tdelete_chunk->Initialize(delete_types);\n+\t\tdelete_chunk->Initialize(Allocator::DefaultAllocator(), delete_types);\n \t}\n \tauto rows = FlatVector::GetData<row_t>(delete_chunk->data[0]);\n \tfor (idx_t i = 0; i < info->count; i++) {\n@@ -174,7 +174,7 @@ void CommitState::WriteUpdate(UpdateInfo *info) {\n \tupdate_types.emplace_back(LogicalType::ROW_TYPE);\n \n \tupdate_chunk = make_unique<DataChunk>();\n-\tupdate_chunk->Initialize(update_types);\n+\tupdate_chunk->Initialize(Allocator::DefaultAllocator(), update_types);\n \n \t// fetch the updated values from the base segment\n \tinfo->segment->FetchCommitted(info->vector_index, update_chunk->data[0]);\ndiff --git a/src/transaction/transaction.cpp b/src/transaction/transaction.cpp\nindex 41fccf743672..e0f89d3b6292 100644\n--- a/src/transaction/transaction.cpp\n+++ b/src/transaction/transaction.cpp\n@@ -19,6 +19,13 @@\n \n namespace duckdb {\n \n+Transaction::Transaction(weak_ptr<ClientContext> context_p, transaction_t start_time, transaction_t transaction_id,\n+                         timestamp_t start_timestamp, idx_t catalog_version)\n+    : context(move(context_p)), start_time(start_time), transaction_id(transaction_id), commit_id(0),\n+      highest_active_query(0), active_query(MAXIMUM_QUERY_ID), start_timestamp(start_timestamp),\n+      catalog_version(catalog_version), storage(*this), is_invalidated(false), undo_buffer(context.lock()) {\n+}\n+\n Transaction &Transaction::GetTransaction(ClientContext &context) {\n \treturn context.ActiveTransaction();\n }\ndiff --git a/src/transaction/undo_buffer.cpp b/src/transaction/undo_buffer.cpp\nindex 794293bbbf3e..c6d3174dea17 100644\n--- a/src/transaction/undo_buffer.cpp\n+++ b/src/transaction/undo_buffer.cpp\n@@ -14,64 +14,30 @@\n #include <unordered_map>\n \n namespace duckdb {\n-constexpr uint32_t DEFAULT_UNDO_CHUNK_SIZE = 4096 * 3;\n constexpr uint32_t UNDO_ENTRY_HEADER_SIZE = sizeof(UndoFlags) + sizeof(uint32_t);\n \n-static idx_t AlignLength(idx_t len) {\n-\treturn (len + 7) / 8 * 8;\n-}\n-\n-UndoBuffer::UndoBuffer() {\n-\thead = make_unique<UndoChunk>(0);\n-\ttail = head.get();\n-}\n-\n-UndoChunk::UndoChunk(idx_t size) : current_position(0), maximum_size(size), prev(nullptr) {\n-\tif (size > 0) {\n-\t\tdata = unique_ptr<data_t[]>(new data_t[maximum_size]);\n-\t}\n-}\n-UndoChunk::~UndoChunk() {\n-\tif (next) {\n-\t\tauto current_next = move(next);\n-\t\twhile (current_next) {\n-\t\t\tcurrent_next = move(current_next->next);\n-\t\t}\n-\t}\n-}\n-\n-data_ptr_t UndoChunk::WriteEntry(UndoFlags type, uint32_t len) {\n-\tlen = AlignLength(len);\n-\tD_ASSERT(sizeof(UndoFlags) + sizeof(len) == 8);\n-\tStore<UndoFlags>(type, data.get() + current_position);\n-\tcurrent_position += sizeof(UndoFlags);\n-\tStore<uint32_t>(len, data.get() + current_position);\n-\tcurrent_position += sizeof(uint32_t);\n-\n-\tdata_ptr_t result = data.get() + current_position;\n-\tcurrent_position += len;\n-\treturn result;\n+UndoBuffer::UndoBuffer(const shared_ptr<ClientContext> &context) : allocator(BufferAllocator::Get(*context)) {\n+\tD_ASSERT(context);\n }\n \n data_ptr_t UndoBuffer::CreateEntry(UndoFlags type, idx_t len) {\n \tD_ASSERT(len <= NumericLimits<uint32_t>::Maximum());\n-\tidx_t needed_space = AlignLength(len + UNDO_ENTRY_HEADER_SIZE);\n-\tif (head->current_position + needed_space >= head->maximum_size) {\n-\t\tauto new_chunk =\n-\t\t    make_unique<UndoChunk>(needed_space > DEFAULT_UNDO_CHUNK_SIZE ? needed_space : DEFAULT_UNDO_CHUNK_SIZE);\n-\t\thead->prev = new_chunk.get();\n-\t\tnew_chunk->next = move(head);\n-\t\thead = move(new_chunk);\n-\t}\n-\treturn head->WriteEntry(type, len);\n+\tlen = AlignValue(len);\n+\tidx_t needed_space = len + UNDO_ENTRY_HEADER_SIZE;\n+\tauto data = allocator.Allocate(needed_space);\n+\tStore<UndoFlags>(type, data);\n+\tdata += sizeof(UndoFlags);\n+\tStore<uint32_t>(len, data);\n+\tdata += sizeof(uint32_t);\n+\treturn data;\n }\n \n template <class T>\n void UndoBuffer::IterateEntries(UndoBuffer::IteratorState &state, T &&callback) {\n \t// iterate in insertion order: start with the tail\n-\tstate.current = tail;\n+\tstate.current = allocator.GetTail();\n \twhile (state.current) {\n-\t\tstate.start = state.current->data.get();\n+\t\tstate.start = state.current->data->get();\n \t\tstate.end = state.start + state.current->current_position;\n \t\twhile (state.start < state.end) {\n \t\t\tUndoFlags type = Load<UndoFlags>(state.start);\n@@ -89,9 +55,9 @@ void UndoBuffer::IterateEntries(UndoBuffer::IteratorState &state, T &&callback)\n template <class T>\n void UndoBuffer::IterateEntries(UndoBuffer::IteratorState &state, UndoBuffer::IteratorState &end_state, T &&callback) {\n \t// iterate in insertion order: start with the tail\n-\tstate.current = tail;\n+\tstate.current = allocator.GetTail();\n \twhile (state.current) {\n-\t\tstate.start = state.current->data.get();\n+\t\tstate.start = state.current->data->get();\n \t\tstate.end =\n \t\t    state.current == end_state.current ? end_state.start : state.start + state.current->current_position;\n \t\twhile (state.start < state.end) {\n@@ -113,9 +79,9 @@ void UndoBuffer::IterateEntries(UndoBuffer::IteratorState &state, UndoBuffer::It\n template <class T>\n void UndoBuffer::ReverseIterateEntries(T &&callback) {\n \t// iterate in reverse insertion order: start with the head\n-\tauto current = head.get();\n+\tauto current = allocator.GetHead();\n \twhile (current) {\n-\t\tdata_ptr_t start = current->data.get();\n+\t\tdata_ptr_t start = current->data->get();\n \t\tdata_ptr_t end = start + current->current_position;\n \t\t// create a vector with all nodes in this chunk\n \t\tvector<pair<UndoFlags, data_ptr_t>> nodes;\n@@ -136,12 +102,12 @@ void UndoBuffer::ReverseIterateEntries(T &&callback) {\n }\n \n bool UndoBuffer::ChangesMade() {\n-\treturn head->maximum_size > 0;\n+\treturn !allocator.IsEmpty();\n }\n \n idx_t UndoBuffer::EstimatedSize() {\n \tidx_t estimated_size = 0;\n-\tauto node = head.get();\n+\tauto node = allocator.GetHead();\n \twhile (node) {\n \t\testimated_size += node->current_position;\n \t\tnode = node->next.get();\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/map.hpp b/tools/pythonpkg/src/include/duckdb_python/map.hpp\nindex 014de69982c9..fbdc42e53527 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/map.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/map.hpp\n@@ -11,6 +11,7 @@\n #include \"duckdb.hpp\"\n #include \"duckdb_python/pybind_wrapper.hpp\"\n #include \"duckdb/parser/parsed_data/create_table_function_info.hpp\"\n+#include \"duckdb/execution/execution_context.hpp\"\n \n namespace duckdb {\n \n@@ -22,7 +23,7 @@ struct MapFunction : public TableFunction {\n \tstatic unique_ptr<FunctionData> MapFunctionBind(ClientContext &context, TableFunctionBindInput &input,\n \t                                                vector<LogicalType> &return_types, vector<string> &names);\n \n-\tstatic OperatorResultType MapFunctionExec(ClientContext &context, TableFunctionInput &data, DataChunk &input,\n+\tstatic OperatorResultType MapFunctionExec(ExecutionContext &context, TableFunctionInput &data, DataChunk &input,\n \t                                          DataChunk &output);\n };\n \ndiff --git a/tools/pythonpkg/src/include/duckdb_python/pandas_scan.hpp b/tools/pythonpkg/src/include/duckdb_python/pandas_scan.hpp\nindex e120d3ccab1a..03a73550ad93 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/pandas_scan.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/pandas_scan.hpp\n@@ -28,7 +28,7 @@ struct PandasScanFunction : public TableFunction {\n \tstatic unique_ptr<GlobalTableFunctionState> PandasScanInitGlobal(ClientContext &context,\n \t                                                                 TableFunctionInitInput &input);\n \tstatic unique_ptr<LocalTableFunctionState>\n-\tPandasScanInitLocal(ClientContext &context, TableFunctionInitInput &input, GlobalTableFunctionState *gstate);\n+\tPandasScanInitLocal(ExecutionContext &context, TableFunctionInitInput &input, GlobalTableFunctionState *gstate);\n \n \tstatic idx_t PandasScanMaxThreads(ClientContext &context, const FunctionData *bind_data_p);\n \ndiff --git a/tools/pythonpkg/src/map.cpp b/tools/pythonpkg/src/map.cpp\nindex 54fa08f29382..c5a4ef47733a 100644\n--- a/tools/pythonpkg/src/map.cpp\n+++ b/tools/pythonpkg/src/map.cpp\n@@ -67,7 +67,7 @@ static string TypeVectorToString(vector<LogicalType> &types) {\n \treturn StringUtil::Join(types, types.size(), \", \", [](const LogicalType &argument) { return argument.ToString(); });\n }\n \n-OperatorResultType MapFunction::MapFunctionExec(ClientContext &context, TableFunctionInput &data_p, DataChunk &input,\n+OperatorResultType MapFunction::MapFunctionExec(ExecutionContext &context, TableFunctionInput &data_p, DataChunk &input,\n                                                 DataChunk &output) {\n \tpy::gil_scoped_acquire acquire;\n \ndiff --git a/tools/pythonpkg/src/pandas_scan.cpp b/tools/pythonpkg/src/pandas_scan.cpp\nindex 51b0f57853b3..560bbaed278e 100644\n--- a/tools/pythonpkg/src/pandas_scan.cpp\n+++ b/tools/pythonpkg/src/pandas_scan.cpp\n@@ -87,12 +87,12 @@ unique_ptr<GlobalTableFunctionState> PandasScanFunction::PandasScanInitGlobal(Cl\n \treturn make_unique<PandasScanGlobalState>(PandasScanMaxThreads(context, input.bind_data));\n }\n \n-unique_ptr<LocalTableFunctionState> PandasScanFunction::PandasScanInitLocal(ClientContext &context,\n+unique_ptr<LocalTableFunctionState> PandasScanFunction::PandasScanInitLocal(ExecutionContext &context,\n                                                                             TableFunctionInitInput &input,\n                                                                             GlobalTableFunctionState *gstate) {\n \tauto result = make_unique<PandasScanLocalState>(0, 0);\n \tresult->column_ids = input.column_ids;\n-\tPandasScanParallelStateNext(context, input.bind_data, result.get(), gstate);\n+\tPandasScanParallelStateNext(context.client, input.bind_data, result.get(), gstate);\n \treturn move(result);\n }\n \ndiff --git a/tools/rpkg/src/scan.cpp b/tools/rpkg/src/scan.cpp\nindex cead85c4d479..4024eed528f1 100644\n--- a/tools/rpkg/src/scan.cpp\n+++ b/tools/rpkg/src/scan.cpp\n@@ -200,13 +200,14 @@ static bool DataFrameScanParallelStateNext(ClientContext &context, const Functio\n \treturn true;\n }\n \n-static unique_ptr<LocalTableFunctionState> DataFrameScanInitLocal(ClientContext &context, TableFunctionInitInput &input,\n+static unique_ptr<LocalTableFunctionState> DataFrameScanInitLocal(ExecutionContext &context,\n+                                                                  TableFunctionInitInput &input,\n                                                                   GlobalTableFunctionState *global_state) {\n \tauto &gstate = (DataFrameGlobalState &)*global_state;\n \tauto result = make_unique<DataFrameLocalState>();\n \n \tresult->column_ids = input.column_ids;\n-\tDataFrameScanParallelStateNext(context, input.bind_data, *result, gstate);\n+\tDataFrameScanParallelStateNext(context.client, input.bind_data, *result, gstate);\n \treturn move(result);\n }\n \ndiff --git a/tools/sqlite3_api_wrapper/sqlite3_udf_api/cast_sqlite.cpp b/tools/sqlite3_api_wrapper/sqlite3_udf_api/cast_sqlite.cpp\nindex 0fee1caf1bc4..6f8d87160520 100644\n--- a/tools/sqlite3_api_wrapper/sqlite3_udf_api/cast_sqlite.cpp\n+++ b/tools/sqlite3_api_wrapper/sqlite3_udf_api/cast_sqlite.cpp\n@@ -35,7 +35,7 @@ void CastSQLite::InputVectorsToVarchar(DataChunk &data_chunk, DataChunk &new_chu\n \t\t\ttype = LogicalType::VARCHAR;\n \t\t}\n \t}\n-\tnew_chunk.Initialize(new_types);\n+\tnew_chunk.Initialize(Allocator::DefaultAllocator(), new_types);\n \n \tfor (idx_t i = 0; i < data_chunk.ColumnCount(); ++i) {\n \t\tif (CastSQLite::RequiresCastToVarchar(data_chunk.data[i].GetType())) {\n",
  "test_patch": "diff --git a/src/function/table/system/test_vector_types.cpp b/src/function/table/system/test_vector_types.cpp\nindex 4cc7f75bf72a..7a7de9664b61 100644\n--- a/src/function/table/system/test_vector_types.cpp\n+++ b/src/function/table/system/test_vector_types.cpp\n@@ -79,7 +79,7 @@ struct TestVectorFlat {\n \t\tvector<Value> result_values = GenerateValues(info, info.type);\n \t\tfor (idx_t cur_row = 0; cur_row < result_values.size(); cur_row += STANDARD_VECTOR_SIZE) {\n \t\t\tauto result = make_unique<DataChunk>();\n-\t\t\tresult->Initialize({info.type});\n+\t\t\tresult->Initialize(Allocator::DefaultAllocator(), {info.type});\n \t\t\tauto cardinality = MinValue<idx_t>(STANDARD_VECTOR_SIZE, result_values.size() - cur_row);\n \t\t\tfor (idx_t i = 0; i < cardinality; i++) {\n \t\t\t\tresult->data[0].SetValue(i, result_values[cur_row + i]);\n@@ -95,7 +95,7 @@ struct TestVectorConstant {\n \t\tauto values = TestVectorFlat::GenerateValues(info, info.type);\n \t\tfor (idx_t cur_row = 0; cur_row < TestVectorFlat::TEST_VECTOR_CARDINALITY; cur_row += STANDARD_VECTOR_SIZE) {\n \t\t\tauto result = make_unique<DataChunk>();\n-\t\t\tresult->Initialize({info.type});\n+\t\t\tresult->Initialize(Allocator::DefaultAllocator(), {info.type});\n \t\t\tauto cardinality = MinValue<idx_t>(STANDARD_VECTOR_SIZE, TestVectorFlat::TEST_VECTOR_CARDINALITY - cur_row);\n \t\t\tresult->data[0].SetValue(0, values[0]);\n \t\t\tresult->data[0].SetVectorType(VectorType::CONSTANT_VECTOR);\n@@ -160,7 +160,7 @@ struct TestVectorSequence {\n \tstatic void Generate(TestVectorInfo &info) {\n #if STANDARD_VECTOR_SIZE > 2\n \t\tauto result = make_unique<DataChunk>();\n-\t\tresult->Initialize({info.type});\n+\t\tresult->Initialize(Allocator::DefaultAllocator(), {info.type});\n \n \t\tGenerateVector(info, info.type, result->data[0]);\n \t\tresult->SetCardinality(3);\ndiff --git a/test/api/test_custom_allocator.cpp b/test/api/test_custom_allocator.cpp\nindex 80d765a0ff8b..c1d02b2fcc52 100644\n--- a/test/api/test_custom_allocator.cpp\n+++ b/test/api/test_custom_allocator.cpp\n@@ -25,9 +25,10 @@ void my_free_function(PrivateAllocatorData *private_data, data_ptr_t pointer, id\n \tfree(pointer);\n }\n \n-data_ptr_t my_reallocate_function(PrivateAllocatorData *private_data, data_ptr_t pointer, idx_t size) {\n+data_ptr_t my_reallocate_function(PrivateAllocatorData *private_data, data_ptr_t pointer, idx_t old_size, idx_t size) {\n \tauto my_allocate_data = (MyAllocateData *)private_data;\n-\t*my_allocate_data->memory_counter -= size;\n+\t*my_allocate_data->memory_counter -= old_size;\n+\t*my_allocate_data->memory_counter += size;\n \treturn (data_ptr_t)realloc(pointer, size);\n }\n \n@@ -35,13 +36,11 @@ TEST_CASE(\"Test using a custom allocator\", \"[api]\") {\n \tatomic<idx_t> memory_counter;\n \tmemory_counter = 0;\n \n-\tAllocator my_allocator(my_allocate_function, my_free_function, my_reallocate_function,\n-\t                       make_unique<MyAllocateData>(&memory_counter));\n-\n \tREQUIRE(memory_counter.load() == 0);\n \n \tDBConfig config;\n-\tconfig.allocator = move(my_allocator);\n+\tconfig.allocator = make_unique<Allocator>(my_allocate_function, my_free_function, my_reallocate_function,\n+\t                                          make_unique<MyAllocateData>(&memory_counter));\n \tDuckDB db(nullptr, &config);\n \tConnection con(db);\n \tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE tbl AS SELECT * FROM range(1000000)\"));\ndiff --git a/test/api/test_dbdir.cpp b/test/api/test_dbdir.cpp\nindex 985542e3e5fb..20eefd92ed37 100644\n--- a/test/api/test_dbdir.cpp\n+++ b/test/api/test_dbdir.cpp\n@@ -31,6 +31,7 @@ static void test_in_memory_initialization(string dbdir) {\n \tREQUIRE(!fs->DirectoryExists(dbdir));\n \n \t// clean up\n+\tcon.reset();\n \tdb.reset();\n \n \t// make sure to clean up the database & temporary folder\ndiff --git a/test/api/test_relation_api.cpp b/test/api/test_relation_api.cpp\nindex 0c2f533313fd..c4cd9984d0c7 100644\n--- a/test/api/test_relation_api.cpp\n+++ b/test/api/test_relation_api.cpp\n@@ -245,8 +245,8 @@ TEST_CASE(\"Test combinations of set operations\", \"[relation_api]\") {\n \tREQUIRE(CHECK_COLUMN(result, 0, {1, 2, 3}));\n \tREQUIRE(CHECK_COLUMN(result, 1, {10, 5, 4}));\n \tREQUIRE_NOTHROW(result = vunion->Intersect(vunion)->Order(\"1\")->Execute());\n-\tREQUIRE(CHECK_COLUMN(result, 0, {1, 1, 2, 2, 3, 3}));\n-\tREQUIRE(CHECK_COLUMN(result, 1, {10, 10, 5, 5, 4, 4}));\n+\tREQUIRE(CHECK_COLUMN(result, 0, {1, 2, 3}));\n+\tREQUIRE(CHECK_COLUMN(result, 1, {10, 5, 4}));\n \tREQUIRE_NOTHROW(result = vunion->Except(vunion)->Execute());\n \tREQUIRE(CHECK_COLUMN(result, 0, {}));\n \tREQUIRE(CHECK_COLUMN(result, 1, {}));\ndiff --git a/test/common/test_file_system.cpp b/test/common/test_file_system.cpp\nindex d8a30431388c..105b198d940c 100644\n--- a/test/common/test_file_system.cpp\n+++ b/test/common/test_file_system.cpp\n@@ -96,37 +96,3 @@ TEST_CASE(\"Test file operations\", \"[file_system]\") {\n \thandle.reset();\n \tfs->RemoveFile(fname);\n }\n-\n-TEST_CASE(\"Test file buffers for reading/writing to file\", \"[file_system]\") {\n-\tunique_ptr<FileSystem> fs = FileSystem::CreateLocal();\n-\tunique_ptr<FileHandle> handle;\n-\tAllocator allocator;\n-\n-\tauto fname = TestCreatePath(\"test_file\");\n-\n-\t// create the buffer and fill it with data\n-\tauto buf = make_unique<FileBuffer>(allocator, FileBufferType::BLOCK, 4096);\n-\tint64_t *ptr = (int64_t *)buf->buffer;\n-\tfor (int64_t i = 0; i < 10; i++) {\n-\t\tptr[i] = i;\n-\t}\n-\n-\t// open file for writing\n-\tREQUIRE_NOTHROW(handle = fs->OpenFile(fname,\n-\t                                      FileFlags::FILE_FLAGS_WRITE | FileFlags::FILE_FLAGS_READ |\n-\t                                          FileFlags::FILE_FLAGS_FILE_CREATE | FileFlags::FILE_FLAGS_DIRECT_IO,\n-\t                                      FileLockType::WRITE_LOCK));\n-\t// write the buffer\n-\tREQUIRE_NOTHROW(buf->Write(*handle, 0));\n-\t// clear the buffer\n-\tbuf->Clear();\n-\t// now read data back into the buffer\n-\tREQUIRE_NOTHROW(buf->Read(*handle, 0));\n-\tfor (int64_t i = 0; i < 10; i++) {\n-\t\tREQUIRE(ptr[i] == i);\n-\t}\n-\t// close the file\n-\thandle.reset();\n-\n-\tfs->RemoveFile(fname);\n-}\ndiff --git a/test/helpers/test_helpers.cpp b/test/helpers/test_helpers.cpp\nindex 014c86ad9ced..f35e5eaf1038 100644\n--- a/test/helpers/test_helpers.cpp\n+++ b/test/helpers/test_helpers.cpp\n@@ -290,7 +290,7 @@ bool compare_result(string csv, ChunkCollection &collection, vector<LogicalType>\n \n \t// set up the intermediate result chunk\n \tDataChunk parsed_result;\n-\tparsed_result.Initialize(sql_types);\n+\tparsed_result.Initialize(Allocator::DefaultAllocator(), sql_types);\n \n \tDuckDB db;\n \tConnection con(db);\ndiff --git a/test/sql/storage/test_buffer_manager.cpp b/test/sql/storage/test_buffer_manager.cpp\nindex f62105ef9a63..6315b13174be 100644\n--- a/test/sql/storage/test_buffer_manager.cpp\n+++ b/test/sql/storage/test_buffer_manager.cpp\n@@ -257,7 +257,7 @@ TEST_CASE(\"Test buffer reallocation\", \"[storage][.]\") {\n \t\tbuffer_manager.ReAllocate(block, requested_size);\n \t\tD_ASSERT(buffer_manager.GetUsedMemory() == requested_size + Storage::BLOCK_HEADER_SIZE);\n \t\t// unpin and make sure it's evicted\n-\t\thandle.reset();\n+\t\thandle.Destroy();\n \t\tREQUIRE_NO_FAIL(con.Query(StringUtil::Format(\"PRAGMA memory_limit='%lldB'\", requested_size)));\n \t\tD_ASSERT(buffer_manager.GetUsedMemory() == 0);\n \t\t// re-pin\n@@ -271,7 +271,7 @@ TEST_CASE(\"Test buffer reallocation\", \"[storage][.]\") {\n \t\tbuffer_manager.ReAllocate(block, requested_size);\n \t\tD_ASSERT(buffer_manager.GetUsedMemory() == requested_size + Storage::BLOCK_HEADER_SIZE);\n \t\t// unpin and make sure it's evicted\n-\t\thandle.reset();\n+\t\thandle.Destroy();\n \t\tREQUIRE_NO_FAIL(con.Query(StringUtil::Format(\"PRAGMA memory_limit='%lldB'\", requested_size)));\n \t\tD_ASSERT(buffer_manager.GetUsedMemory() == 0);\n \t\t// re-pin\ndiff --git a/test/sqlite/sqllogic_test_runner.cpp b/test/sqlite/sqllogic_test_runner.cpp\nindex 5d850bdec356..1da3aad2b87f 100644\n--- a/test/sqlite/sqllogic_test_runner.cpp\n+++ b/test/sqlite/sqllogic_test_runner.cpp\n@@ -16,6 +16,9 @@ SQLLogicTestRunner::SQLLogicTestRunner(string dbpath) : dbpath(move(dbpath)) {\n }\n \n SQLLogicTestRunner::~SQLLogicTestRunner() {\n+\tconfig.reset();\n+\tcon.reset();\n+\tdb.reset();\n \tfor (auto &loaded_path : loaded_databases) {\n \t\tif (loaded_path.empty()) {\n \t\t\tcontinue;\n",
  "problem_statement": "OOM when reading Parquet file\n#### What happens?\r\nIt is using all available memory and is terminated by OOM.\r\n\r\n#### To Reproduce\r\n\r\nAllocate a machine with 32 GB RAM, like c6a.4xlarge on AWS, with Ubuntu 22.04.\r\nssh into that machine.\r\nRun the following commands:\r\n\r\n```\r\nsudo apt-get update\r\nsudo apt-get install python3-pip\r\npip install duckdb\r\nwget 'https://datasets.clickhouse.com/hits_compatible/hits.parquet'\r\n```\r\n\r\nCreate the following run.py file:\r\n```\r\n#!/usr/bin/env python3\r\n\r\nimport duckdb\r\nimport timeit\r\n\r\ncon = duckdb.connect(database='my-db.duckdb', read_only=False)\r\n\r\nprint(\"Will load the data\")\r\n\r\nstart = timeit.timeit()\r\ncon.execute(\"CREATE TABLE hits AS SELECT * FROM parquet_scan('hits.parquet')\")\r\nend = timeit.timeit()\r\nprint(end - start)\r\n```\r\n\r\nMake it executable:\r\n```\r\nchmod +x run.py\r\n```\r\n\r\nRun it:\r\n```\r\n./run.py\r\n```\r\n\r\nWait around 10 minutes... \r\n\r\n```\r\nWill load the data\r\nKilled\r\n```\r\n\r\n#### Environment (please complete the following information):\r\n - OS: Ubuntu 22.04\r\n - DuckDB Version: 0.4.0\r\n - DuckDB Client: Python\r\n\r\n#### Identity Disclosure:\r\n - Full Name: Alexey Milovidov\r\n - Affiliation: ClickHouse, Inc\r\n\r\nWith OOM it cannot qualify in the ClickHouse benchmark.\r\n\r\n#### Before Submitting\r\n\r\n- [x] **Have you tried this on the latest `master` branch?** No.\r\n* **Python**: `pip install duckdb --upgrade --pre` It installs the same version 0.4.0.\r\n* **R**: I don't use R.\r\n* **Other Platforms**: I don't use other platforms.\r\n\r\n- [x] **Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?** Yes.\r\n\n",
  "hints_text": "The table contains 99 997 497 rows.\nI tried to add the following lines to the Python script:\r\n\r\n```\r\ncon.execute(\"PRAGMA memory_limit='{}b'\".format(psutil.virtual_memory().total / 2))\r\ncon.execute(\"PRAGMA threads={}\".format(psutil.cpu_count(logical=False)))\r\n```\r\n\r\nBut it did not help.\nI tried to load from the CLI but it also fails with OOM:\r\n\r\n```\r\n#!/usr/bin/expect -f\r\n\r\nmatch_max 100000\r\nset timeout 10000\r\n\r\nspawn ./duckdb\r\nexpect \"D \"\r\n\r\nsend -- \"PRAGMA threads = 8;\\r\"\r\nexpect \"D \"\r\n\r\nsend -- \"PRAGMA temp_directory='duckdb.tmp';\\r\"\r\nexpect \"D \"\r\n\r\nsend -- \".timer on\\r\"\r\nexpect \"D \"\r\n\r\nsend -- \"CREATE TABLE hits AS SELECT * FROM parquet_scan('hits.parquet');\\r\"\r\nexpect \"D \"\r\n```\nChanging `parquet_scan` to `read_parquet` does not help, although the difference is unclear.\nHello!\r\n\r\nJust a random idea, but would it help to create the table first and then insert into it? Create table as select * from ... where 1=0, etc.\nI tried, but it did not help.\r\nAlso tried to switch to .csv.\nThanks for the report! I will investigate more after the weekend.\r\n\r\nAs a work-around for now, perhaps try either (1) setting an even lower memory limit explicitly (e.g. `SET memory_limit='8GB'`, instead of the 16GB/24GB you tried before) or (2) splitting up the file load into multiple calls using e.g. `INSERT INTO tbl SELECT * FROM hits.parquet LIMIT ... OFFSET ...`. Neither will be particularly fast but at least it should work.\r\n\nOn the topic of the clickhouse benchmarks, please make sure to use the `approx_count_distinct` function instead of `COUNT(DISTINCT)` for better performance on approx distinct counts :)\r\n\r\nIs the code that you are using to benchmark DuckDB available somewhere publicly, or could we perhaps have a look at it otherwise? \n(Hi, Alexey), I tried this, it went up to 117 GB on a machine with 126 GB RAM when not setting a memory limit, but it completed. When setting the memory limit to 10 GB, it went up to 24 GB but also completed successfully (albeit much slower). \r\n\r\nSo indeed I would recommend setting a very conservative memory limit for the load (e.g. 10 GB on the machine you're on). Going forward, we need to have a look for the source of those additional allocations. \r\n\r\nUpdate: Here is the Parquet file metadata \r\n[hits.metadata.tsv.gz](https://github.com/duckdb/duckdb/files/8986510/hits.metadata.tsv.gz)\r\n\r\n\nOk, I will set the memory limit to 8GB.\r\n\r\nI'm currently preparing the benchmark, it is in work in progress: https://github.com/ClickHouse/ClickHouse/pull/38437\r\nThe idea is to make it easy reproducible (like running a single small script) and also compatible with most SQL DBMS.\r\nSo, I've removed all custom aggregate functions and data types.\r\n\nSounds great! Let me know if the fix works and if you run into anything else.\nStrange, but it does not work. I've set memory limit to the `psutil.virtual_memory().total / 4`.\r\n\r\nIf I load Parquet it does not succeed due to unsupported cast:\r\n```\r\nUnimplemented type for cast (BIGINT -> TIMESTAMP)\r\n```\r\n\r\nIf I load CSV it still failed with OOM.\r\n\r\nI will try to use 4GB.\nI will try to split the file into parts.\r\nUpdate: lowering to 4GB helped.\nNow I have different error:\r\n\r\n```\r\nubuntu@ip-172-31-4-239:~$ ./run.py \r\nWill load the data\r\n4216.5390389899985\r\nSELECT COUNT(*) FROM hits;\r\n\r\n0.05523904401343316\r\n0.003909286999260075\r\n0.0038267960044322535\r\nSELECT COUNT(*) FROM hits WHERE AdvEngineID != 0;\r\n\r\n0.1603328409983078\r\n0.06337512300524395\r\n0.05665142499492504\r\nSELECT SUM(AdvEngineID), COUNT(*), AVG(ResolutionWidth) FROM hits;\r\n\r\n0.238524653002969\r\n0.08392444600758608\r\n0.07758511300198734\r\nSELECT AVG(UserID) FROM hits;\r\n\r\n1.1524075900088064\r\n0.10763906499778386\r\n0.09490979700058233\r\nSELECT COUNT(DISTINCT UserID) FROM hits;\r\n\r\n9.184395752003184\r\n8.429843456004164\r\n9.689035353003419\r\nSELECT COUNT(DISTINCT SearchPhrase) FROM hits;\r\n\r\nSegmentation fault (core dumped)\r\n```\nIf I restart Python script after every query (and reopen the database), it succeeded.\r\nMost likely previous queries have corrupted the memory.\nThat's also something for us to look into. But to come back on a point Mark made above, I see you are running COUNT DISTINCT there, which are approximate in ClickHouse AFAIK but are not approximate (ie exact) in DuckDB. Could you please make sure DuckDB's approx_count_distinct for the comparison? Thanks!\nNo, COUNT(DISTINCT ...) is exact in ClickHouse.\r\nClickHouse also has an approximate count distinct, but under different names.\nThanks for the clarification, great to hear the default is the exact one.",
  "created_at": "2022-07-05T14:46:41Z"
}