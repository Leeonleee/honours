You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
A comparison column=column unexpectedly evaluates to TRUE for column=NULL
Consider the following statements:

```sql
CREATE TABLE t0(c0 INT);
INSERT INTO t0(c0) VALUES (NULL);
SELECT * FROM t0 WHERE c0 = c0; -- expected: {}, actual: {NULL}
```
Unexpectedly, the `SELECT` fetches a row. This is unexpected, since the value of `c0` is `NULL` and `NULL = NULL` should evaluate to `NULL`, and thus fetch no rows.

I found this bug based on commit bc9f086b9fcffb058763a6d1723da01127cd9100.
SELECT causes JDBC driver to crash
Consider the following statements (note that the newline is significiant):

```sql
CREATE TABLE t0(c0 VARCHAR, c1 DOUBLE);
CREATE TABLE t1(c0 DOUBLE, PRIMARY KEY(c0));
INSERT INTO t0(c0) VALUES (0), (0), (0), (0);
INSERT INTO t0(c0) VALUES (NULL), (NULL);
INSERT INTO t1(c0) VALUES (0), (1);

SELECT t0.c0 FROM t0, t1; -- A fatal error has been detected by the Java Runtime Environment
```

When executing the statements using the Java code below, the JVM crashes:

```java
Connection con = DriverManager.getConnection("jdbc:duckdb:");
for (String s : fileContent.split("\n")) {
    try (Statement st = con.createStatement()) {
        try {
            st.execute(s);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
con.close();
```

Note that for the newline, the following exception is thrown:
```
java.sql.SQLException: No statement to prepare!
	at nl.cwi.da.duckdb.DuckDBNative.duckdb_jdbc_prepare(Native Method)
	at nl.cwi.da.duckdb.DuckDBStatement.execute(DuckDBStatement.java:22)
	at reproduce.ExecuteDuckDB$2.run(ExecuteDuckDB.java:51)
	at java.base/java.lang.Thread.run(Thread.java:834)
```
The original test case that crashed the JVM did not have a newline in it.

The logs suggest that the following was executed during the crash:
```
j  nl.cwi.da.duckdb.DuckDBNative.duckdb_jdbc_fetch(Ljava/nio/ByteBuffer;)[Lnl/cwi/da/duckdb/DuckDBVector;+0
j  nl.cwi.da.duckdb.DuckDBResultSet.<init>(Lnl/cwi/da/duckdb/DuckDBStatement;Ljava/nio/ByteBuffer;)V+34
j  nl.cwi.da.duckdb.DuckDBStatement.execute(Ljava/lang/String;)Z+36
```
I found this bug based on commit c2ce42268b23967de165a0c54460b6c974c5e3e1.
SELECT causes JDBC driver to crash
Consider the following statements (note that the newline is significiant):

```sql
CREATE TABLE t0(c0 VARCHAR, c1 DOUBLE);
CREATE TABLE t1(c0 DOUBLE, PRIMARY KEY(c0));
INSERT INTO t0(c0) VALUES (0), (0), (0), (0);
INSERT INTO t0(c0) VALUES (NULL), (NULL);
INSERT INTO t1(c0) VALUES (0), (1);

SELECT t0.c0 FROM t0, t1; -- A fatal error has been detected by the Java Runtime Environment
```

When executing the statements using the Java code below, the JVM crashes:

```java
Connection con = DriverManager.getConnection("jdbc:duckdb:");
for (String s : fileContent.split("\n")) {
    try (Statement st = con.createStatement()) {
        try {
            st.execute(s);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
con.close();
```

Note that for the newline, the following exception is thrown:
```
java.sql.SQLException: No statement to prepare!
	at nl.cwi.da.duckdb.DuckDBNative.duckdb_jdbc_prepare(Native Method)
	at nl.cwi.da.duckdb.DuckDBStatement.execute(DuckDBStatement.java:22)
	at reproduce.ExecuteDuckDB$2.run(ExecuteDuckDB.java:51)
	at java.base/java.lang.Thread.run(Thread.java:834)
```
The original test case that crashed the JVM did not have a newline in it.

The logs suggest that the following was executed during the crash:
```
j  nl.cwi.da.duckdb.DuckDBNative.duckdb_jdbc_fetch(Ljava/nio/ByteBuffer;)[Lnl/cwi/da/duckdb/DuckDBVector;+0
j  nl.cwi.da.duckdb.DuckDBResultSet.<init>(Lnl/cwi/da/duckdb/DuckDBStatement;Ljava/nio/ByteBuffer;)V+34
j  nl.cwi.da.duckdb.DuckDBStatement.execute(Ljava/lang/String;)Z+36
```
I found this bug based on commit c2ce42268b23967de165a0c54460b6c974c5e3e1.

</issue>
<code>
[start of README.md]
1: <img align="left" src="logo/duckdb-logo.png" height="120">
2: 
3: # DuckDB, the SQLite for Analytics
4: [![Travis](https://api.travis-ci.org/cwida/duckdb.svg?branch=master)](https://travis-ci.org/cwida/duckdb)
5: [![CodeFactor](https://www.codefactor.io/repository/github/cwida/duckdb/badge)](https://www.codefactor.io/repository/github/cwida/duckdb)
6: [![Coverage Status](https://coveralls.io/repos/github/cwida/duckdb/badge.svg?branch=master)](https://coveralls.io/github/cwida/duckdb?branch=master)
7: 
8: <br>
9: 
10: 
11: # Requirements
12: DuckDB requires [CMake](https://cmake.org) to be installed and a `C++11` compliant compiler. GCC 4.9 and newer, Clang 3.9 and newer and VisualStudio 2017 are tested on each revision.
13: 
14: ## Compiling
15: Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You may run `make unit` and `make allunit` to verify that your version works properly after making changes.
16: 
17: # Usage
18: A command line utility based on `sqlite3` can be found in either `build/release/duckdb_cli` (release, the default) or `build/debug/duckdb_cli` (debug).
19: 
20: # Embedding
21: As DuckDB is an embedded database, there is no database server to launch or client to connect to a running server. However, the database server can be embedded directly into an application using the C or C++ bindings. The main build process creates the shared library `build/release/src/libduckdb.[so|dylib|dll]` that can be linked against. A static library is built as well.
22: 
23: For examples on how to embed DuckDB into your application, see the [examples](https://github.com/cwida/duckdb/tree/master/examples) folder.
24: 
25: ## Benchmarks
26: After compiling, benchmarks can be executed from the root directory by executing `./build/release/benchmark/benchmark_runner`.
27: 
28: ## Standing on the Shoulders of Giants
29: DuckDB is implemented in C++ 11, should compile with GCC and clang, uses CMake to build and [Catch2](https://github.com/catchorg/Catch2) for testing. DuckDB uses some components from various Open-Source databases and draws inspiration from scientific publications. Here is an overview:
30: 
31: * Parser: We use the PostgreSQL parser that was [repackaged as a stand-alone library](https://github.com/lfittl/libpg_query). The translation to our own parse tree is inspired by [Peloton](https://pelotondb.io).
32: * Shell: We have adapted the [SQLite shell](https://sqlite.org/cli.html) to work with DuckDB.
33: * Tests: We use the [SQL Logic Tests from SQLite](https://www.sqlite.org/sqllogictest/doc/trunk/about.wiki) to test DuckDB.
34: * Query fuzzing: We use [SQLsmith](https://github.com/anse1/sqlsmith) to generate random queries for additional testing.
35: * Date Math: We use the date math component from [MonetDB](https://www.monetdb.org).
36: * SQL Window Functions: DuckDB's window functions implementation uses Segment Tree Aggregation as described in the paper "Efficient Processing of Window Functions in Analytical SQL Queries" by Viktor Leis, Kan Kundhikanjana, Alfons Kemper and Thomas Neumann.
37: * Execution engine: The vectorized execution engine is inspired by the paper "MonetDB/X100: Hyper-Pipelining Query Execution" by Peter Boncz, Marcin Zukowski and Niels Nes.
38: * Optimizer: DuckDB's optimizer draws inspiration from the papers "Dynamic programming strikes back" by Guido Moerkotte and Thomas Neumman as well as "Unnesting Arbitrary Queries" by Thomas Neumann and Alfons Kemper.
39: * Concurrency control: Our MVCC implementation is inspired by the paper "Fast Serializable Multi-Version Concurrency Control for Main-Memory Database Systems" by Thomas Neumann, Tobias Mühlbauer and Alfons Kemper.
40: * Regular Expression: DuckDB uses Google's [RE2](https://github.com/google/re2) regular expression engine.
41: 
42: ## Other pages
43: * [Continuous Benchmarking (CB™)](https://www.duckdb.org/benchmarks/index.html), runs TPC-H, TPC-DS and some microbenchmarks on every commit
[end of README.md]
[start of src/CMakeLists.txt]
1: add_definitions(-DDUCKDB)
2: 
3: if(NOT MSVC)
4:   set(
5:     CMAKE_CXX_FLAGS_DEBUG
6:     "${CMAKE_CXX_FLAGS_DEBUG} -Wextra -Wno-unused-parameter -Wno-redundant-move -Wnarrowing"
7:     )
8: endif()
9: 
10: if(AMALGAMATION_BUILD)
11: 
12:   if(WIN32)
13:     add_definitions(/bigobj)
14:   endif()
15: 
16:   add_library(duckdb SHARED "${CMAKE_SOURCE_DIR}/src/amalgamation/duckdb.cpp")
17:   add_library(duckdb_static STATIC
18:               "${CMAKE_SOURCE_DIR}/src/amalgamation/duckdb.cpp")
19: 
20:   install(FILES "${CMAKE_SOURCE_DIR}/src/amalgamation/duckdb.hpp"
21:           DESTINATION "${INSTALL_INCLUDE_DIR}")
22: 
23: else()
24: 
25:   add_subdirectory(optimizer)
26:   add_subdirectory(planner)
27:   add_subdirectory(parser)
28:   add_subdirectory(function)
29:   add_subdirectory(catalog)
30:   add_subdirectory(common)
31:   add_subdirectory(execution)
32:   add_subdirectory(main)
33:   add_subdirectory(storage)
34:   add_subdirectory(transaction)
35: 
36:   set(DUCKDB_LINK_LIBS
37:       fmt
38:       pg_query
39:       hyperloglog
40:       re2
41:       miniz
42:       utf8proc)
43: 
44:   add_library(duckdb SHARED ${ALL_OBJECT_FILES})
45:   target_link_libraries(duckdb ${DUCKDB_LINK_LIBS})
46: 
47:   add_library(duckdb_static STATIC ${ALL_OBJECT_FILES})
48:   target_link_libraries(duckdb_static ${DUCKDB_LINK_LIBS})
49: 
50:   target_include_directories(
51:     duckdb
52:     PUBLIC $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/include>
53:            $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>)
54: 
55:   target_include_directories(
56:     duckdb_static
57:     PUBLIC $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/include>
58:            $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>)
59: 
60:   install(DIRECTORY "${CMAKE_SOURCE_DIR}/src/include/duckdb"
61:           DESTINATION "${INSTALL_INCLUDE_DIR}"
62:           FILES_MATCHING
63:           PATTERN "*.hpp")
64:   install(FILES "${CMAKE_SOURCE_DIR}/src/include/duckdb.hpp"
65:                 "${CMAKE_SOURCE_DIR}/src/include/duckdb.h"
66:           DESTINATION "${INSTALL_INCLUDE_DIR}")
67: 
68: endif()
69: 
70: install(TARGETS duckdb duckdb_static
71:         EXPORT "${DUCKDB_EXPORT_SET}"
72:         LIBRARY DESTINATION "${INSTALL_LIB_DIR}"
73:         ARCHIVE DESTINATION "${INSTALL_LIB_DIR}")
[end of src/CMakeLists.txt]
[start of src/common/types/vector.cpp]
1: #include <cstring> // strlen() on Solaris
2: 
3: #include "duckdb/common/types/vector.hpp"
4: 
5: #include "duckdb/common/assert.hpp"
6: #include "duckdb/common/exception.hpp"
7: #include "duckdb/common/printer.hpp"
8: #include "duckdb/common/vector_operations/vector_operations.hpp"
9: #include "duckdb/common/types/chunk_collection.hpp"
10: #include "duckdb/common/serializer.hpp"
11: #include "duckdb/common/types/null_value.hpp"
12: 
13: using namespace std;
14: 
15: namespace duckdb {
16: 
17: Vector::Vector(TypeId type, bool create_data, bool zero_data)
18:     : vector_type(VectorType::FLAT_VECTOR), type(type), data(nullptr) {
19: 	if (create_data) {
20: 		Initialize(type, zero_data);
21: 	}
22: }
23: 
24: Vector::Vector(TypeId type) : Vector(type, true, false) {
25: }
26: 
27: Vector::Vector(TypeId type, data_ptr_t dataptr) : vector_type(VectorType::FLAT_VECTOR), type(type), data(dataptr) {
28: 	if (dataptr && type == TypeId::INVALID) {
29: 		throw InvalidTypeException(type, "Cannot create a vector of type INVALID!");
30: 	}
31: }
32: 
33: Vector::Vector(Value value) : vector_type(VectorType::CONSTANT_VECTOR) {
34: 	Reference(value);
35: }
36: 
37: Vector::Vector() : vector_type(VectorType::FLAT_VECTOR), type(TypeId::INVALID), data(nullptr) {
38: }
39: 
40: Vector::Vector(Vector &&other) noexcept
41:     : vector_type(other.vector_type), type(other.type), data(other.data), nullmask(other.nullmask),
42:       buffer(move(other.buffer)), auxiliary(move(other.auxiliary)) {
43: }
44: 
45: void Vector::Reference(Value &value) {
46: 	vector_type = VectorType::CONSTANT_VECTOR;
47: 	type = value.type;
48: 	buffer = VectorBuffer::CreateConstantVector(type);
49: 	auxiliary.reset();
50: 	data = buffer->GetData();
51: 	SetValue(0, value);
52: }
53: 
54: void Vector::Reference(Vector &other) {
55: 	vector_type = other.vector_type;
56: 	buffer = other.buffer;
57: 	auxiliary = other.auxiliary;
58: 	data = other.data;
59: 	type = other.type;
60: 	nullmask = other.nullmask;
61: }
62: 
63: void Vector::Slice(Vector &other, idx_t offset) {
64: 	if (other.vector_type == VectorType::CONSTANT_VECTOR) {
65: 		Reference(other);
66: 		return;
67: 	}
68: 	assert(other.vector_type == VectorType::FLAT_VECTOR);
69: 
70: 	// create a reference to the other vector
71: 	Reference(other);
72: 	if (offset > 0) {
73: 		data = data + GetTypeIdSize(type) * offset;
74: 		nullmask <<= offset;
75: 	}
76: }
77: 
78: void Vector::Slice(Vector &other, const SelectionVector &sel, idx_t count) {
79: 	Reference(other);
80: 	Slice(sel, count);
81: }
82: 
83: void Vector::Slice(const SelectionVector &sel, idx_t count) {
84: 	if (vector_type == VectorType::CONSTANT_VECTOR) {
85: 		// dictionary on a constant is just a constant
86: 		return;
87: 	}
88: 	if (vector_type == VectorType::DICTIONARY_VECTOR) {
89: 		// already a dictionary, slice the current dictionary
90: 		auto &current_sel = DictionaryVector::SelVector(*this);
91: 		auto sliced_dictionary = current_sel.Slice(sel, count);
92: 		buffer = make_unique<DictionaryBuffer>(move(sliced_dictionary));
93: 		return;
94: 	}
95: 	auto child_ref = make_buffer<VectorChildBuffer>();
96: 	child_ref->data.Reference(*this);
97: 
98: 	auto dict_buffer = make_unique<DictionaryBuffer>(sel);
99: 	buffer = move(dict_buffer);
100: 	auxiliary = move(child_ref);
101: 	vector_type = VectorType::DICTIONARY_VECTOR;
102: }
103: 
104: void Vector::Slice(const SelectionVector &sel, idx_t count, sel_cache_t &cache) {
105: 	if (vector_type == VectorType::DICTIONARY_VECTOR) {
106: 		// dictionary vector: need to merge dictionaries
107: 		// check if we have a cached entry
108: 		auto &current_sel = DictionaryVector::SelVector(*this);
109: 		auto target_data = current_sel.data();
110: 		auto entry = cache.find(target_data);
111: 		if (entry != cache.end()) {
112: 			// cached entry exists: use that
113: 			this->buffer = entry->second;
114: 		} else {
115: 			Slice(sel, count);
116: 			cache[target_data] = this->buffer;
117: 		}
118: 	} else {
119: 		Slice(sel, count);
120: 	}
121: }
122: 
123: void Vector::Initialize(TypeId new_type, bool zero_data) {
124: 	if (new_type != TypeId::INVALID) {
125: 		type = new_type;
126: 	}
127: 	vector_type = VectorType::FLAT_VECTOR;
128: 	buffer.reset();
129: 	auxiliary.reset();
130: 	nullmask.reset();
131: 	if (GetTypeIdSize(type) > 0) {
132: 		buffer = VectorBuffer::CreateStandardVector(type);
133: 		data = buffer->GetData();
134: 		if (zero_data) {
135: 			memset(data, 0, STANDARD_VECTOR_SIZE * GetTypeIdSize(type));
136: 		}
137: 	}
138: }
139: 
140: void Vector::SetValue(idx_t index, Value val) {
141: 	if (vector_type == VectorType::DICTIONARY_VECTOR) {
142: 		// dictionary: apply dictionary and forward to child
143: 		auto &sel_vector = DictionaryVector::SelVector(*this);
144: 		auto &child = DictionaryVector::Child(*this);
145: 		return child.SetValue(sel_vector.get_index(index), move(val));
146: 	}
147: 	Value newVal = val.CastAs(type);
148: 
149: 	nullmask[index] = newVal.is_null;
150: 	if (newVal.is_null) {
151: 		return;
152: 	}
153: 	switch (type) {
154: 	case TypeId::BOOL:
155: 		((int8_t *)data)[index] = newVal.value_.boolean;
156: 		break;
157: 	case TypeId::INT8:
158: 		((int8_t *)data)[index] = newVal.value_.tinyint;
159: 		break;
160: 	case TypeId::INT16:
161: 		((int16_t *)data)[index] = newVal.value_.smallint;
162: 		break;
163: 	case TypeId::INT32:
164: 		((int32_t *)data)[index] = newVal.value_.integer;
165: 		break;
166: 	case TypeId::INT64:
167: 		((int64_t *)data)[index] = newVal.value_.bigint;
168: 		break;
169: 	case TypeId::FLOAT:
170: 		((float *)data)[index] = newVal.value_.float_;
171: 		break;
172: 	case TypeId::DOUBLE:
173: 		((double *)data)[index] = newVal.value_.double_;
174: 		break;
175: 	case TypeId::POINTER:
176: 		((uintptr_t *)data)[index] = newVal.value_.pointer;
177: 		break;
178: 	case TypeId::VARCHAR: {
179: 		((string_t *)data)[index] = StringVector::AddString(*this, newVal.str_value);
180: 		break;
181: 	}
182: 	case TypeId::STRUCT: {
183: 		if (!auxiliary || StructVector::GetEntries(*this).size() == 0) {
184: 			for (size_t i = 0; i < val.struct_value.size(); i++) {
185: 				auto &struct_child = val.struct_value[i];
186: 				auto cv = make_unique<Vector>(struct_child.second.type);
187: 				cv->vector_type = vector_type;
188: 				StructVector::AddEntry(*this, struct_child.first, move(cv));
189: 			}
190: 		}
191: 
192: 		auto &children = StructVector::GetEntries(*this);
193: 		assert(children.size() == val.struct_value.size());
194: 
195: 		for (size_t i = 0; i < val.struct_value.size(); i++) {
196: 			auto &struct_child = val.struct_value[i];
197: 			assert(vector_type == VectorType::CONSTANT_VECTOR || vector_type == VectorType::FLAT_VECTOR);
198: 			auto &vec_child = children[i];
199: 			assert(vec_child.first == struct_child.first);
200: 			vec_child.second->SetValue(index, struct_child.second);
201: 		}
202: 	} break;
203: 
204: 	case TypeId::LIST: {
205: 		if (!auxiliary) {
206: 			auto cc = make_unique<ChunkCollection>();
207: 			ListVector::SetEntry(*this, move(cc));
208: 		}
209: 		auto &child_cc = ListVector::GetEntry(*this);
210: 		// TODO optimization: in-place update if fits
211: 		auto offset = child_cc.count;
212: 		if (val.list_value.size() > 0) {
213: 			idx_t append_idx = 0;
214: 			while (append_idx < val.list_value.size()) {
215: 				idx_t this_append_len = min((idx_t)STANDARD_VECTOR_SIZE, val.list_value.size() - append_idx);
216: 
217: 				DataChunk child_append_chunk;
218: 				child_append_chunk.SetCardinality(this_append_len);
219: 				vector<TypeId> types;
220: 				types.push_back(val.list_value[0].type);
221: 				child_append_chunk.Initialize(types);
222: 				for (idx_t i = 0; i < this_append_len; i++) {
223: 					child_append_chunk.data[0].SetValue(i, val.list_value[i + append_idx]);
224: 				}
225: 				child_cc.Append(child_append_chunk);
226: 				append_idx += this_append_len;
227: 			}
228: 		}
229: 		// now set the pointer
230: 		auto &entry = ((list_entry_t *)data)[index];
231: 		entry.length = val.list_value.size();
232: 		entry.offset = offset;
233: 	} break;
234: 	default:
235: 		throw NotImplementedException("Unimplemented type for Vector::SetValue");
236: 	}
237: }
238: 
239: Value Vector::GetValue(idx_t index) const {
240: 	if (vector_type == VectorType::CONSTANT_VECTOR) {
241: 		index = 0;
242: 	} else if (vector_type == VectorType::DICTIONARY_VECTOR) {
243: 		// dictionary: apply dictionary and forward to child
244: 		auto &sel_vector = DictionaryVector::SelVector(*this);
245: 		auto &child = DictionaryVector::Child(*this);
246: 		return child.GetValue(sel_vector.get_index(index));
247: 	} else {
248: 		assert(vector_type == VectorType::FLAT_VECTOR);
249: 	}
250: 
251: 	if (nullmask[index]) {
252: 		return Value(type);
253: 	}
254: 	switch (type) {
255: 	case TypeId::BOOL:
256: 		return Value::BOOLEAN(((int8_t *)data)[index]);
257: 	case TypeId::INT8:
258: 		return Value::TINYINT(((int8_t *)data)[index]);
259: 	case TypeId::INT16:
260: 		return Value::SMALLINT(((int16_t *)data)[index]);
261: 	case TypeId::INT32:
262: 		return Value::INTEGER(((int32_t *)data)[index]);
263: 	case TypeId::INT64:
264: 		return Value::BIGINT(((int64_t *)data)[index]);
265: 	case TypeId::HASH:
266: 		return Value::HASH(((hash_t *)data)[index]);
267: 	case TypeId::POINTER:
268: 		return Value::POINTER(((uintptr_t *)data)[index]);
269: 	case TypeId::FLOAT:
270: 		return Value::FLOAT(((float *)data)[index]);
271: 	case TypeId::DOUBLE:
272: 		return Value::DOUBLE(((double *)data)[index]);
273: 	case TypeId::VARCHAR: {
274: 		auto str = ((string_t *)data)[index];
275: 		return Value(str.GetString());
276: 	}
277: 	case TypeId::STRUCT: {
278: 		Value ret(TypeId::STRUCT);
279: 		ret.is_null = false;
280: 		// we can derive the value schema from the vector schema
281: 		for (auto &struct_child : StructVector::GetEntries(*this)) {
282: 			ret.struct_value.push_back(pair<string, Value>(struct_child.first, struct_child.second->GetValue(index)));
283: 		}
284: 		return ret;
285: 	}
286: 	case TypeId::LIST: {
287: 		Value ret(TypeId::LIST);
288: 		ret.is_null = false;
289: 		auto offlen = ((list_entry_t *)data)[index];
290: 		auto &child_cc = ListVector::GetEntry(*this);
291: 		for (idx_t i = offlen.offset; i < offlen.offset + offlen.length; i++) {
292: 			ret.list_value.push_back(child_cc.GetValue(0, i));
293: 		}
294: 		return ret;
295: 	}
296: 	default:
297: 		throw NotImplementedException("Unimplemented type for value access");
298: 	}
299: }
300: 
301: string VectorTypeToString(VectorType type) {
302: 	switch (type) {
303: 	case VectorType::FLAT_VECTOR:
304: 		return "FLAT";
305: 	case VectorType::SEQUENCE_VECTOR:
306: 		return "SEQUENCE";
307: 	case VectorType::DICTIONARY_VECTOR:
308: 		return "DICTIONARY";
309: 	case VectorType::CONSTANT_VECTOR:
310: 		return "CONSTANT";
311: 	default:
312: 		return "UNKNOWN";
313: 	}
314: }
315: 
316: string Vector::ToString(idx_t count) const {
317: 	string retval = VectorTypeToString(vector_type) + " " + TypeIdToString(type) + ": " + to_string(count) + " = [ ";
318: 	switch (vector_type) {
319: 	case VectorType::FLAT_VECTOR:
320: 	case VectorType::DICTIONARY_VECTOR:
321: 		for (idx_t i = 0; i < count; i++) {
322: 			retval += GetValue(i).ToString() + (i == count - 1 ? "" : ", ");
323: 		}
324: 		break;
325: 	case VectorType::CONSTANT_VECTOR:
326: 		retval += GetValue(0).ToString();
327: 		break;
328: 	case VectorType::SEQUENCE_VECTOR: {
329: 		int64_t start, increment;
330: 		SequenceVector::GetSequence(*this, start, increment);
331: 		for (idx_t i = 0; i < count; i++) {
332: 			retval += to_string(start + increment * i) + (i == count - 1 ? "" : ", ");
333: 		}
334: 		break;
335: 	}
336: 	default:
337: 		retval += "UNKNOWN VECTOR TYPE";
338: 		break;
339: 	}
340: 	retval += "]";
341: 	return retval;
342: }
343: 
344: void Vector::Print(idx_t count) {
345: 	Printer::Print(ToString(count));
346: }
347: 
348: string Vector::ToString() const {
349: 	string retval = VectorTypeToString(vector_type) + " " + TypeIdToString(type) + ": (UNKNOWN COUNT) [ ";
350: 	switch (vector_type) {
351: 	case VectorType::FLAT_VECTOR:
352: 	case VectorType::DICTIONARY_VECTOR:
353: 		break;
354: 	case VectorType::CONSTANT_VECTOR:
355: 		retval += GetValue(0).ToString();
356: 		break;
357: 	case VectorType::SEQUENCE_VECTOR: {
358: 		break;
359: 	}
360: 	default:
361: 		retval += "UNKNOWN VECTOR TYPE";
362: 		break;
363: 	}
364: 	retval += "]";
365: 	return retval;
366: }
367: 
368: void Vector::Print() {
369: 	Printer::Print(ToString());
370: }
371: 
372: template <class T> static void flatten_constant_vector_loop(data_ptr_t data, data_ptr_t old_data, idx_t count) {
373: 	auto constant = *((T *)old_data);
374: 	auto output = (T *)data;
375: 	for (idx_t i = 0; i < count; i++) {
376: 		output[i] = constant;
377: 	}
378: }
379: 
380: void Vector::Normalify(idx_t count) {
381: 	switch (vector_type) {
382: 	case VectorType::FLAT_VECTOR:
383: 		// already a flat vector
384: 		break;
385: 	case VectorType::DICTIONARY_VECTOR: {
386: 		// create a new flat vector of this type
387: 		Vector other(type);
388: 		// now copy the data of this vector to the other vector, removing the selection vector in the process
389: 		VectorOperations::Copy(*this, other, count, 0, 0);
390: 		// create a reference to the data in the other vector
391: 		this->Reference(other);
392: 		break;
393: 	}
394: 	case VectorType::CONSTANT_VECTOR: {
395: 		vector_type = VectorType::FLAT_VECTOR;
396: 		// allocate a new buffer for the vector
397: 		auto old_buffer = move(buffer);
398: 		auto old_data = data;
399: 		buffer = VectorBuffer::CreateStandardVector(type);
400: 		data = buffer->GetData();
401: 		if (nullmask[0]) {
402: 			// constant NULL, set nullmask
403: 			nullmask.set();
404: 			return;
405: 		}
406: 		// non-null constant: have to repeat the constant
407: 		switch (type) {
408: 		case TypeId::BOOL:
409: 		case TypeId::INT8:
410: 			flatten_constant_vector_loop<int8_t>(data, old_data, count);
411: 			break;
412: 		case TypeId::INT16:
413: 			flatten_constant_vector_loop<int16_t>(data, old_data, count);
414: 			break;
415: 		case TypeId::INT32:
416: 			flatten_constant_vector_loop<int32_t>(data, old_data, count);
417: 			break;
418: 		case TypeId::INT64:
419: 			flatten_constant_vector_loop<int64_t>(data, old_data, count);
420: 			break;
421: 		case TypeId::FLOAT:
422: 			flatten_constant_vector_loop<float>(data, old_data, count);
423: 			break;
424: 		case TypeId::DOUBLE:
425: 			flatten_constant_vector_loop<double>(data, old_data, count);
426: 			break;
427: 		case TypeId::HASH:
428: 			flatten_constant_vector_loop<hash_t>(data, old_data, count);
429: 			break;
430: 		case TypeId::POINTER:
431: 			flatten_constant_vector_loop<uintptr_t>(data, old_data, count);
432: 			break;
433: 		case TypeId::VARCHAR:
434: 			flatten_constant_vector_loop<string_t>(data, old_data, count);
435: 			break;
436: 		case TypeId::LIST: {
437: 			flatten_constant_vector_loop<list_entry_t>(data, old_data, count);
438: 			break;
439: 		}
440: 		case TypeId::STRUCT: {
441: 			for (auto &child : StructVector::GetEntries(*this)) {
442: 				assert(child.second->vector_type == VectorType::CONSTANT_VECTOR);
443: 				child.second->Normalify(count);
444: 			}
445: 		} break;
446: 		default:
447: 			throw NotImplementedException("Unimplemented type for VectorOperations::Normalify");
448: 		}
449: 		break;
450: 	}
451: 	case VectorType::SEQUENCE_VECTOR: {
452: 		int64_t start, increment;
453: 		SequenceVector::GetSequence(*this, start, increment);
454: 
455: 		vector_type = VectorType::FLAT_VECTOR;
456: 		buffer = VectorBuffer::CreateStandardVector(type);
457: 		data = buffer->GetData();
458: 		VectorOperations::GenerateSequence(*this, count, start, increment);
459: 		break;
460: 	}
461: 	default:
462: 		throw NotImplementedException("FIXME: unimplemented type for normalify");
463: 	}
464: }
465: 
466: void Vector::Normalify(const SelectionVector &sel, idx_t count) {
467: 	switch (vector_type) {
468: 	case VectorType::FLAT_VECTOR:
469: 		// already a flat vector
470: 		break;
471: 	case VectorType::SEQUENCE_VECTOR: {
472: 		int64_t start, increment;
473: 		SequenceVector::GetSequence(*this, start, increment);
474: 
475: 		vector_type = VectorType::FLAT_VECTOR;
476: 		buffer = VectorBuffer::CreateStandardVector(type);
477: 		data = buffer->GetData();
478: 		VectorOperations::GenerateSequence(*this, count, sel, start, increment);
479: 		break;
480: 	}
481: 	default:
482: 		throw NotImplementedException("Unimplemented type for normalify with selection vector");
483: 	}
484: }
485: 
486: void Vector::Orrify(idx_t count, VectorData &data) {
487: 	switch (vector_type) {
488: 	case VectorType::DICTIONARY_VECTOR: {
489: 		auto &sel = DictionaryVector::SelVector(*this);
490: 		auto &child = DictionaryVector::Child(*this);
491: 		child.Normalify(sel, count);
492: 
493: 		data.sel = &sel;
494: 		data.data = FlatVector::GetData(child);
495: 		data.nullmask = &FlatVector::Nullmask(child);
496: 		break;
497: 	}
498: 	case VectorType::CONSTANT_VECTOR:
499: 		data.sel = &ConstantVector::ZeroSelectionVector;
500: 		data.data = ConstantVector::GetData(*this);
501: 		data.nullmask = &nullmask;
502: 		break;
503: 	default:
504: 		Normalify(count);
505: 		data.sel = &FlatVector::IncrementalSelectionVector;
506: 		data.data = FlatVector::GetData(*this);
507: 		data.nullmask = &nullmask;
508: 		break;
509: 	}
510: }
511: 
512: void Vector::Sequence(int64_t start, int64_t increment) {
513: 	vector_type = VectorType::SEQUENCE_VECTOR;
514: 	this->buffer = make_buffer<VectorBuffer>(sizeof(int64_t) * 2);
515: 	auto data = (int64_t *)buffer->GetData();
516: 	data[0] = start;
517: 	data[1] = increment;
518: 	nullmask.reset();
519: 	auxiliary.reset();
520: }
521: 
522: void Vector::Serialize(idx_t count, Serializer &serializer) {
523: 	if (TypeIsConstantSize(type)) {
524: 		// constant size type: simple copy
525: 		idx_t write_size = GetTypeIdSize(type) * count;
526: 		auto ptr = unique_ptr<data_t[]>(new data_t[write_size]);
527: 		VectorOperations::WriteToStorage(*this, count, ptr.get());
528: 		serializer.WriteData(ptr.get(), write_size);
529: 	} else {
530: 		VectorData vdata;
531: 		Orrify(count, vdata);
532: 
533: 		switch (type) {
534: 		case TypeId::VARCHAR: {
535: 			auto strings = (string_t *)vdata.data;
536: 			for (idx_t i = 0; i < count; i++) {
537: 				auto idx = vdata.sel->get_index(i);
538: 				auto source = (*vdata.nullmask)[idx] ? NullValue<const char *>() : strings[idx].GetData();
539: 				serializer.WriteString(source);
540: 			}
541: 			break;
542: 		}
543: 		default:
544: 			throw NotImplementedException("Unimplemented type for Vector::Serialize!");
545: 		}
546: 	}
547: }
548: 
549: void Vector::Deserialize(idx_t count, Deserializer &source) {
550: 	if (TypeIsConstantSize(type)) {
551: 		// constant size type: read fixed amount of data from
552: 		auto column_size = GetTypeIdSize(type) * count;
553: 		auto ptr = unique_ptr<data_t[]>(new data_t[column_size]);
554: 		source.ReadData(ptr.get(), column_size);
555: 
556: 		VectorOperations::ReadFromStorage(ptr.get(), count, *this);
557: 	} else {
558: 		auto strings = FlatVector::GetData<string_t>(*this);
559: 		auto &nullmask = FlatVector::Nullmask(*this);
560: 		for (idx_t i = 0; i < count; i++) {
561: 			// read the strings
562: 			auto str = source.Read<string>();
563: 			// now add the string to the StringHeap of the vector
564: 			// and write the pointer into the vector
565: 			if (IsNullValue<const char *>((const char *)str.c_str())) {
566: 				nullmask[i] = true;
567: 			} else {
568: 				strings[i] = StringVector::AddString(*this, str);
569: 			}
570: 		}
571: 	}
572: }
573: 
574: void Vector::Verify(const SelectionVector &sel, idx_t count) {
575: #ifdef DEBUG
576: 	if (count == 0) {
577: 		return;
578: 	}
579: 	if (vector_type == VectorType::DICTIONARY_VECTOR) {
580: 		auto &child = DictionaryVector::Child(*this);
581: 		auto &dict_sel = DictionaryVector::SelVector(*this);
582: 		for (idx_t i = 0; i < count; i++) {
583: 			auto oidx = sel.get_index(i);
584: 			auto idx = dict_sel.get_index(oidx);
585: 			assert(idx < STANDARD_VECTOR_SIZE);
586: 		}
587: 		// merge the selection vectors and verify the child
588: 		auto new_buffer = dict_sel.Slice(sel, count);
589: 		SelectionVector new_sel(new_buffer);
590: 		child.Verify(new_sel, count);
591: 		return;
592: 	}
593: 	if (type == TypeId::VARCHAR) {
594: 		// we just touch all the strings and let the sanitizer figure out if any
595: 		// of them are deallocated/corrupt
596: 		switch (vector_type) {
597: 		case VectorType::CONSTANT_VECTOR: {
598: 			auto string = ConstantVector::GetData<string_t>(*this);
599: 			if (!ConstantVector::IsNull(*this)) {
600: 				string->Verify();
601: 			}
602: 			break;
603: 		}
604: 		case VectorType::FLAT_VECTOR: {
605: 			auto strings = FlatVector::GetData<string_t>(*this);
606: 			for (idx_t i = 0; i < count; i++) {
607: 				auto oidx = sel.get_index(i);
608: 				if (!nullmask[oidx]) {
609: 					strings[oidx].Verify();
610: 				}
611: 			}
612: 			break;
613: 		}
614: 		default:
615: 			break;
616: 		}
617: 	}
618: 
619: 	if (type == TypeId::STRUCT) {
620: 		if (vector_type == VectorType::FLAT_VECTOR || vector_type == VectorType::CONSTANT_VECTOR) {
621: 			auto &children = StructVector::GetEntries(*this);
622: 			assert(children.size() > 0);
623: 			for (auto &child : children) {
624: 				child.second->Verify(sel, count);
625: 			}
626: 		}
627: 	}
628: 
629: 	if (type == TypeId::LIST) {
630: 		if (vector_type == VectorType::CONSTANT_VECTOR) {
631: 			if (!ConstantVector::IsNull(*this)) {
632: 				ListVector::GetEntry(*this).Verify();
633: 				auto le = ConstantVector::GetData<list_entry_t>(*this);
634: 				assert(le->offset + le->length <= ListVector::GetEntry(*this).count);
635: 			}
636: 		} else if (vector_type == VectorType::FLAT_VECTOR) {
637: 			if (ListVector::HasEntry(*this)) {
638: 				ListVector::GetEntry(*this).Verify();
639: 			}
640: 			auto list_data = FlatVector::GetData<list_entry_t>(*this);
641: 			for (idx_t i = 0; i < count; i++) {
642: 				auto idx = sel.get_index(i);
643: 				auto &le = list_data[idx];
644: 				if (!nullmask[idx]) {
645: 					assert(le.offset + le.length <= ListVector::GetEntry(*this).count);
646: 				}
647: 			}
648: 		}
649: 	}
650: // TODO verify list and struct
651: #endif
652: }
653: 
654: void Vector::Verify(idx_t count) {
655: 	Verify(FlatVector::IncrementalSelectionVector, count);
656: }
657: 
658: string_t StringVector::AddString(Vector &vector, const char *data, idx_t len) {
659: 	return StringVector::AddString(vector, string_t(data, len));
660: }
661: 
662: string_t StringVector::AddString(Vector &vector, const char *data) {
663: 	return StringVector::AddString(vector, string_t(data, strlen(data)));
664: }
665: 
666: string_t StringVector::AddString(Vector &vector, const string &data) {
667: 	return StringVector::AddString(vector, string_t(data.c_str(), data.size()));
668: }
669: 
670: string_t StringVector::AddString(Vector &vector, string_t data) {
671: 	assert(vector.type == TypeId::VARCHAR);
672: 	if (data.IsInlined()) {
673: 		// string will be inlined: no need to store in string heap
674: 		return data;
675: 	}
676: 	if (!vector.auxiliary) {
677: 		vector.auxiliary = make_buffer<VectorStringBuffer>();
678: 	}
679: 	assert(vector.auxiliary->type == VectorBufferType::STRING_BUFFER);
680: 	auto &string_buffer = (VectorStringBuffer &)*vector.auxiliary;
681: 	return string_buffer.AddString(data);
682: }
683: 
684: string_t StringVector::EmptyString(Vector &vector, idx_t len) {
685: 	assert(vector.type == TypeId::VARCHAR);
686: 	if (len < string_t::INLINE_LENGTH) {
687: 		return string_t(len);
688: 	}
689: 	if (!vector.auxiliary) {
690: 		vector.auxiliary = make_buffer<VectorStringBuffer>();
691: 	}
692: 	assert(vector.auxiliary->type == VectorBufferType::STRING_BUFFER);
693: 	auto &string_buffer = (VectorStringBuffer &)*vector.auxiliary;
694: 	return string_buffer.EmptyString(len);
695: }
696: 
697: void StringVector::AddHeapReference(Vector &vector, Vector &other) {
698: 	assert(vector.type == TypeId::VARCHAR);
699: 	assert(other.type == TypeId::VARCHAR);
700: 
701: 	if (!other.auxiliary) {
702: 		return;
703: 	}
704: 	if (!vector.auxiliary) {
705: 		vector.auxiliary = make_buffer<VectorStringBuffer>();
706: 	}
707: 	assert(vector.auxiliary->type == VectorBufferType::STRING_BUFFER);
708: 	assert(other.auxiliary->type == VectorBufferType::STRING_BUFFER);
709: 	auto &string_buffer = (VectorStringBuffer &)*vector.auxiliary;
710: 	string_buffer.AddHeapReference(other.auxiliary);
711: }
712: 
713: bool StructVector::HasEntries(const Vector &vector) {
714: 	assert(vector.type == TypeId::STRUCT);
715: 	assert(vector.vector_type == VectorType::FLAT_VECTOR || vector.vector_type == VectorType::CONSTANT_VECTOR);
716: 	assert(vector.auxiliary == nullptr || vector.auxiliary->type == VectorBufferType::STRUCT_BUFFER);
717: 	return vector.auxiliary != nullptr;
718: }
719: 
720: child_list_t<unique_ptr<Vector>> &StructVector::GetEntries(const Vector &vector) {
721: 	assert(vector.type == TypeId::STRUCT);
722: 	assert(vector.vector_type == VectorType::FLAT_VECTOR || vector.vector_type == VectorType::CONSTANT_VECTOR);
723: 	assert(vector.auxiliary);
724: 	assert(vector.auxiliary->type == VectorBufferType::STRUCT_BUFFER);
725: 	return ((VectorStructBuffer *)vector.auxiliary.get())->GetChildren();
726: }
727: 
728: void StructVector::AddEntry(Vector &vector, string name, unique_ptr<Vector> entry) {
729: 	// TODO asser that an entry with this name does not already exist
730: 	assert(vector.type == TypeId::STRUCT);
731: 	assert(vector.vector_type == VectorType::FLAT_VECTOR || vector.vector_type == VectorType::CONSTANT_VECTOR);
732: 	if (!vector.auxiliary) {
733: 		vector.auxiliary = make_buffer<VectorStructBuffer>();
734: 	}
735: 	assert(vector.auxiliary);
736: 	assert(vector.auxiliary->type == VectorBufferType::STRUCT_BUFFER);
737: 	((VectorStructBuffer *)vector.auxiliary.get())->AddChild(name, move(entry));
738: }
739: 
740: bool ListVector::HasEntry(const Vector &vector) {
741: 	assert(vector.type == TypeId::LIST);
742: 	if (vector.vector_type == VectorType::DICTIONARY_VECTOR) {
743: 		auto &child = DictionaryVector::Child(vector);
744: 		return ListVector::HasEntry(child);
745: 	}
746: 	assert(vector.vector_type == VectorType::FLAT_VECTOR || vector.vector_type == VectorType::CONSTANT_VECTOR);
747: 	return vector.auxiliary != nullptr;
748: }
749: 
750: ChunkCollection &ListVector::GetEntry(const Vector &vector) {
751: 	assert(vector.type == TypeId::LIST);
752: 	if (vector.vector_type == VectorType::DICTIONARY_VECTOR) {
753: 		auto &child = DictionaryVector::Child(vector);
754: 		return ListVector::GetEntry(child);
755: 	}
756: 	assert(vector.vector_type == VectorType::FLAT_VECTOR || vector.vector_type == VectorType::CONSTANT_VECTOR);
757: 	assert(vector.auxiliary);
758: 	assert(vector.auxiliary->type == VectorBufferType::LIST_BUFFER);
759: 	return ((VectorListBuffer *)vector.auxiliary.get())->GetChild();
760: }
761: 
762: void ListVector::SetEntry(Vector &vector, unique_ptr<ChunkCollection> cc) {
763: 	assert(vector.type == TypeId::LIST);
764: 	assert(vector.vector_type == VectorType::FLAT_VECTOR || vector.vector_type == VectorType::CONSTANT_VECTOR);
765: 	if (!vector.auxiliary) {
766: 		vector.auxiliary = make_buffer<VectorListBuffer>();
767: 	}
768: 	assert(vector.auxiliary);
769: 	assert(vector.auxiliary->type == VectorBufferType::LIST_BUFFER);
770: 	((VectorListBuffer *)vector.auxiliary.get())->SetChild(move(cc));
771: }
772: 
773: } // namespace duckdb
[end of src/common/types/vector.cpp]
[start of src/common/vector_operations/boolean_operators.cpp]
1: //===--------------------------------------------------------------------===//
2: // boolean_operators.cpp
3: // Description: This file contains the implementation of the boolean
4: // operations AND OR !
5: //===--------------------------------------------------------------------===//
6: 
7: #include "duckdb/common/operator/boolean_operators.hpp"
8: 
9: #include "duckdb/common/vector_operations/binary_executor.hpp"
10: #include "duckdb/common/vector_operations/unary_executor.hpp"
11: #include "duckdb/common/vector_operations/vector_operations.hpp"
12: 
13: using namespace duckdb;
14: using namespace std;
15: 
16: //===--------------------------------------------------------------------===//
17: // AND/OR
18: //===--------------------------------------------------------------------===//
19: template <class OP, class NULLOP>
20: static void templated_boolean_nullmask(Vector &left, Vector &right, Vector &result, idx_t count) {
21: 	assert(left.type == TypeId::BOOL && right.type == TypeId::BOOL && result.type == TypeId::BOOL);
22: 
23: 	if (left.vector_type == VectorType::CONSTANT_VECTOR && right.vector_type == VectorType::CONSTANT_VECTOR) {
24: 		// operation on two constants, result is constant vector
25: 		result.vector_type = VectorType::CONSTANT_VECTOR;
26: 		auto ldata = ConstantVector::GetData<bool>(left);
27: 		auto rdata = ConstantVector::GetData<bool>(right);
28: 		auto result_data = ConstantVector::GetData<bool>(result);
29: 		*result_data = OP::Operation(*ldata, *rdata);
30: 		ConstantVector::SetNull(
31: 		    result, NULLOP::Operation(*ldata, *rdata, ConstantVector::IsNull(left), ConstantVector::IsNull(right)));
32: 	} else {
33: 		// perform generic loop
34: 		VectorData ldata, rdata;
35: 		left.Orrify(count, ldata);
36: 		right.Orrify(count, rdata);
37: 
38: 		result.vector_type = VectorType::FLAT_VECTOR;
39: 		auto left_data = (bool *)ldata.data;
40: 		auto right_data = (bool *)rdata.data;
41: 		auto result_data = FlatVector::GetData<bool>(result);
42: 		auto &result_mask = FlatVector::Nullmask(result);
43: 		if (ldata.nullmask->any() || rdata.nullmask->any()) {
44: 			for (idx_t i = 0; i < count; i++) {
45: 				auto lidx = ldata.sel->get_index(i);
46: 				auto ridx = rdata.sel->get_index(i);
47: 				result_data[i] = OP::Operation(left_data[lidx], right_data[ridx]);
48: 				result_mask[i] = NULLOP::Operation(left_data[lidx], right_data[ridx], (*ldata.nullmask)[lidx],
49: 				                                   (*rdata.nullmask)[ridx]);
50: 			}
51: 		} else {
52: 			for (idx_t i = 0; i < count; i++) {
53: 				auto lidx = ldata.sel->get_index(i);
54: 				auto ridx = rdata.sel->get_index(i);
55: 				result_data[i] = OP::Operation(left_data[lidx], right_data[ridx]);
56: 			}
57: 		}
58: 	}
59: }
60: 
61: void VectorOperations::And(Vector &left, Vector &right, Vector &result, idx_t count) {
62: 	templated_boolean_nullmask<duckdb::And, duckdb::AndMask>(left, right, result, count);
63: }
64: 
65: void VectorOperations::Or(Vector &left, Vector &right, Vector &result, idx_t count) {
66: 	templated_boolean_nullmask<duckdb::Or, duckdb::OrMask>(left, right, result, count);
67: }
68: 
69: struct NotOperator {
70: 	template <class TA, class TR> static inline TR Operation(TA left) {
71: 		return !left;
72: 	}
73: };
74: 
75: void VectorOperations::Not(Vector &input, Vector &result, idx_t count) {
76: 	assert(input.type == TypeId::BOOL && result.type == TypeId::BOOL);
77: 	UnaryExecutor::Execute<bool, bool, NotOperator>(input, result, count);
78: }
[end of src/common/vector_operations/boolean_operators.cpp]
[start of src/execution/merge_join/merge_join.cpp]
1: #include "duckdb/execution/merge_join.hpp"
2: 
3: #include "duckdb/parser/expression/comparison_expression.hpp"
4: 
5: using namespace duckdb;
6: using namespace std;
7: 
8: template <class MJ, class L_ARG, class R_ARG> static idx_t merge_join(L_ARG &l, R_ARG &r) {
9: 	switch (l.type) {
10: 	case TypeId::INT8:
11: 		return MJ::template Operation<int8_t>(l, r);
12: 	case TypeId::INT16:
13: 		return MJ::template Operation<int16_t>(l, r);
14: 	case TypeId::INT32:
15: 		return MJ::template Operation<int32_t>(l, r);
16: 	case TypeId::INT64:
17: 		return MJ::template Operation<int64_t>(l, r);
18: 	case TypeId::FLOAT:
19: 		return MJ::template Operation<float>(l, r);
20: 	case TypeId::DOUBLE:
21: 		return MJ::template Operation<double>(l, r);
22: 	case TypeId::VARCHAR:
23: 		return MJ::template Operation<string_t>(l, r);
24: 	default:
25: 		throw NotImplementedException("Type not implemented for merge join!");
26: 	}
27: }
28: 
29: template <class T, class L_ARG, class R_ARG>
30: static idx_t perform_merge_join(L_ARG &l, R_ARG &r, ExpressionType comparison_type) {
31: 	switch (comparison_type) {
32: 	case ExpressionType::COMPARE_EQUAL:
33: 		return merge_join<typename T::Equality, L_ARG, R_ARG>(l, r);
34: 	case ExpressionType::COMPARE_LESSTHAN:
35: 		return merge_join<typename T::LessThan, L_ARG, R_ARG>(l, r);
36: 	case ExpressionType::COMPARE_LESSTHANOREQUALTO:
37: 		return merge_join<typename T::LessThanEquals, L_ARG, R_ARG>(l, r);
38: 	case ExpressionType::COMPARE_GREATERTHAN:
39: 		return merge_join<typename T::GreaterThan, L_ARG, R_ARG>(l, r);
40: 	default:
41: 		// "Unimplemented comparison type for merge join!"
42: 		assert(comparison_type == ExpressionType::COMPARE_GREATERTHANOREQUALTO);
43: 		return merge_join<typename T::GreaterThanEquals, L_ARG, R_ARG>(l, r);
44: 	}
45: }
46: 
47: idx_t MergeJoinInner::Perform(MergeInfo &l, MergeInfo &r, ExpressionType comparison_type) {
48: 	assert(l.info_type == MergeInfoType::SCALAR_MERGE_INFO && r.info_type == MergeInfoType::SCALAR_MERGE_INFO);
49: 	auto &left = (ScalarMergeInfo &)l;
50: 	auto &right = (ScalarMergeInfo &)r;
51: 	assert(left.type == right.type);
52: 	if (left.order.count == 0 || right.order.count == 0) {
53: 		return 0;
54: 	}
55: 	return perform_merge_join<MergeJoinInner, ScalarMergeInfo, ScalarMergeInfo>(left, right, comparison_type);
56: }
57: 
58: idx_t MergeJoinMark::Perform(MergeInfo &l, MergeInfo &r, ExpressionType comparison_type) {
59: 	assert(l.info_type == MergeInfoType::SCALAR_MERGE_INFO && r.info_type == MergeInfoType::CHUNK_MERGE_INFO);
60: 	auto &left = (ScalarMergeInfo &)l;
61: 	auto &right = (ChunkMergeInfo &)r;
62: 	assert(left.type == right.type);
63: 	if (left.order.count == 0 || right.data_chunks.count == 0) {
64: 		return 0;
65: 	}
66: 	return perform_merge_join<MergeJoinMark, ScalarMergeInfo, ChunkMergeInfo>(left, right, comparison_type);
67: }
[end of src/execution/merge_join/merge_join.cpp]
[start of src/execution/operator/join/physical_piecewise_merge_join.cpp]
1: #include "duckdb/execution/operator/join/physical_piecewise_merge_join.hpp"
2: 
3: #include "duckdb/common/vector_operations/vector_operations.hpp"
4: #include "duckdb/execution/expression_executor.hpp"
5: #include "duckdb/execution/merge_join.hpp"
6: #include "duckdb/common/operator/comparison_operators.hpp"
7: 
8: using namespace duckdb;
9: using namespace std;
10: 
11: static void OrderVector(Vector &vector, idx_t count, MergeOrder &order);
12: 
13: class PhysicalPiecewiseMergeJoinState : public PhysicalComparisonJoinState {
14: public:
15: 	PhysicalPiecewiseMergeJoinState(PhysicalOperator *left, PhysicalOperator *right, vector<JoinCondition> &conditions)
16: 	    : PhysicalComparisonJoinState(left, right, conditions), initialized(false), left_position(0), right_position(0),
17: 	      right_chunk_index(0), has_null(false) {
18: 	}
19: 
20: 	bool initialized;
21: 	idx_t left_position;
22: 	idx_t right_position;
23: 	idx_t right_chunk_index;
24: 	DataChunk left_chunk;
25: 	DataChunk join_keys;
26: 	MergeOrder left_orders;
27: 	ChunkCollection right_chunks;
28: 	ChunkCollection right_conditions;
29: 	vector<MergeOrder> right_orders;
30: 	bool has_null;
31: };
32: 
33: PhysicalPiecewiseMergeJoin::PhysicalPiecewiseMergeJoin(LogicalOperator &op, unique_ptr<PhysicalOperator> left,
34:                                                        unique_ptr<PhysicalOperator> right, vector<JoinCondition> cond,
35:                                                        JoinType join_type)
36:     : PhysicalComparisonJoin(op, PhysicalOperatorType::PIECEWISE_MERGE_JOIN, move(cond), join_type) {
37: 	// for now we only support one condition!
38: 	assert(conditions.size() == 1);
39: 	for (auto &cond : conditions) {
40: 		// COMPARE NOT EQUAL not supported yet with merge join
41: 		assert(cond.comparison != ExpressionType::COMPARE_NOTEQUAL);
42: 		assert(cond.left->return_type == cond.right->return_type);
43: 		join_key_types.push_back(cond.left->return_type);
44: 	}
45: 	children.push_back(move(left));
46: 	children.push_back(move(right));
47: }
48: 
49: void PhysicalPiecewiseMergeJoin::GetChunkInternal(ClientContext &context, DataChunk &chunk,
50:                                                   PhysicalOperatorState *state_) {
51: 	auto state = reinterpret_cast<PhysicalPiecewiseMergeJoinState *>(state_);
52: 	assert(conditions.size() == 1);
53: 	if (!state->initialized) {
54: 		// create the sorted pieces
55: 		auto right_state = children[1]->GetOperatorState();
56: 		auto types = children[1]->GetTypes();
57: 
58: 		DataChunk right_chunk;
59: 		right_chunk.Initialize(types);
60: 		state->join_keys.Initialize(join_key_types);
61: 		// first fetch the entire right side
62: 		while (true) {
63: 			children[1]->GetChunk(context, right_chunk, right_state.get());
64: 			if (right_chunk.size() == 0) {
65: 				break;
66: 			}
67: 			// resolve the join keys for this chunk
68: 			state->rhs_executor.SetChunk(right_chunk);
69: 
70: 			state->join_keys.Reset();
71: 			state->join_keys.SetCardinality(right_chunk);
72: 			for (idx_t k = 0; k < conditions.size(); k++) {
73: 				// resolve the join key
74: 				state->rhs_executor.ExecuteExpression(k, state->join_keys.data[k]);
75: 			}
76: 			// append the join keys and the chunk to the chunk collection
77: 			state->right_chunks.Append(right_chunk);
78: 			state->right_conditions.Append(state->join_keys);
79: 		}
80: 		if (state->right_chunks.count == 0 && (type == JoinType::INNER || type == JoinType::SEMI)) {
81: 			// empty RHS with INNER or SEMI join means empty result set
82: 			return;
83: 		}
84: 		// now order all the chunks
85: 		state->right_orders.resize(state->right_conditions.chunks.size());
86: 		for (idx_t i = 0; i < state->right_conditions.chunks.size(); i++) {
87: 			auto &chunk_to_order = *state->right_conditions.chunks[i];
88: 			assert(chunk_to_order.column_count() == 1);
89: 			for (idx_t col_idx = 0; col_idx < chunk_to_order.column_count(); col_idx++) {
90: 				OrderVector(chunk_to_order.data[col_idx], chunk_to_order.size(), state->right_orders[i]);
91: 				if (state->right_orders[i].count < chunk_to_order.size()) {
92: 					// the amount of entries in the order vector is smaller than the amount of entries in the vector
93: 					// this only happens if there are NULL values in the right-hand side
94: 					// hence we set the has_null to true (this is required for the MARK join)
95: 					state->has_null = true;
96: 				}
97: 			}
98: 		}
99: 		state->right_chunk_index = state->right_orders.size();
100: 		state->initialized = true;
101: 	}
102: 
103: 	do {
104: 		// check if we have to fetch a child from the left side
105: 		if (state->right_chunk_index == state->right_orders.size()) {
106: 			// fetch the chunk from the left side
107: 			children[0]->GetChunk(context, state->child_chunk, state->child_state.get());
108: 			if (state->child_chunk.size() == 0) {
109: 				return;
110: 			}
111: 
112: 			// resolve the join keys for the left chunk
113: 			state->join_keys.Reset();
114: 			state->lhs_executor.SetChunk(state->child_chunk);
115: 			state->join_keys.SetCardinality(state->child_chunk);
116: 			for (idx_t k = 0; k < conditions.size(); k++) {
117: 				state->lhs_executor.ExecuteExpression(k, state->join_keys.data[k]);
118: 				// sort by join key
119: 				OrderVector(state->join_keys.data[k], state->join_keys.size(), state->left_orders);
120: 			}
121: 			state->right_chunk_index = 0;
122: 			state->left_position = 0;
123: 			state->right_position = 0;
124: 		}
125: 
126: 		ScalarMergeInfo left_info(state->left_orders, state->join_keys.data[0].type, state->left_position);
127: 
128: 		// first check if the join type is MARK, SEMI or ANTI
129: 		// in this case we loop over the entire right collection immediately
130: 		// because we can never return more than STANDARD_VECTOR_SIZE rows from a join
131: 		switch (type) {
132: 		case JoinType::MARK: {
133: 			// MARK join
134: 			if (state->right_chunks.count > 0) {
135: 				ChunkMergeInfo right_info(state->right_conditions, state->right_orders);
136: 				// first perform the MARK join
137: 				// this method uses the LHS to loop over the entire RHS looking for matches
138: 				MergeJoinMark::Perform(left_info, right_info, conditions[0].comparison);
139: 				// now construct the mark join result from the found matches
140: 				PhysicalJoin::ConstructMarkJoinResult(state->join_keys, state->child_chunk, chunk,
141: 				                                      right_info.found_match, state->has_null);
142: 			} else {
143: 				// RHS empty: result is false for everything
144: 				chunk.Reference(state->child_chunk);
145: 				auto &mark_vector = chunk.data.back();
146: 				mark_vector.vector_type = VectorType::CONSTANT_VECTOR;
147: 				mark_vector.SetValue(0, Value::BOOLEAN(false));
148: 			}
149: 			state->right_chunk_index = state->right_orders.size();
150: 			return;
151: 		}
152: 		default:
153: 			// INNER, LEFT OUTER, etc... join that can return >STANDARD_VECTOR_SIZE entries
154: 			break;
155: 		}
156: 
157: 		// perform the actual merge join
158: 		auto &right_chunk = *state->right_chunks.chunks[state->right_chunk_index];
159: 		auto &right_condition_chunk = *state->right_conditions.chunks[state->right_chunk_index];
160: 		auto &right_orders = state->right_orders[state->right_chunk_index];
161: 
162: 		ScalarMergeInfo right(right_orders, right_condition_chunk.data[0].type, state->right_position);
163: 		// perform the merge join
164: 		switch (type) {
165: 		case JoinType::INNER: {
166: 			idx_t result_count = MergeJoinInner::Perform(left_info, right, conditions[0].comparison);
167: 			if (result_count == 0) {
168: 				// exhausted this chunk on the right side
169: 				// move to the next
170: 				state->right_chunk_index++;
171: 				state->left_position = 0;
172: 				state->right_position = 0;
173: 			} else {
174: 				chunk.Slice(state->child_chunk, left_info.result, result_count);
175: 				chunk.Slice(right_chunk, right.result, result_count, state->child_chunk.column_count());
176: 			}
177: 			break;
178: 		}
179: 		default:
180: 			throw NotImplementedException("Unimplemented join type for merge join");
181: 		}
182: 	} while (chunk.size() == 0);
183: }
184: 
185: unique_ptr<PhysicalOperatorState> PhysicalPiecewiseMergeJoin::GetOperatorState() {
186: 	return make_unique<PhysicalPiecewiseMergeJoinState>(children[0].get(), children[1].get(), conditions);
187: }
188: 
189: template <class T, class OP>
190: static sel_t templated_quicksort_initial(T *data, const SelectionVector &sel, const SelectionVector &not_null_sel,
191:                                          idx_t count, SelectionVector &result) {
192: 	// select pivot
193: 	auto pivot_idx = not_null_sel.get_index(0);
194: 	auto dpivot_idx = sel.get_index(pivot_idx);
195: 	sel_t low = 0, high = count - 1;
196: 	// now insert elements
197: 	for (idx_t i = 1; i < count; i++) {
198: 		auto idx = not_null_sel.get_index(i);
199: 		auto didx = sel.get_index(idx);
200: 		if (OP::Operation(data[didx], data[dpivot_idx])) {
201: 			result.set_index(low++, idx);
202: 		} else {
203: 			result.set_index(high--, idx);
204: 		}
205: 	}
206: 	assert(low == high);
207: 	result.set_index(low, pivot_idx);
208: 	return low;
209: }
210: 
211: template <class T, class OP>
212: static void templated_quicksort_inplace(T *data, const SelectionVector &sel, idx_t count, SelectionVector &result,
213:                                         sel_t left, sel_t right) {
214: 	if (left >= right) {
215: 		return;
216: 	}
217: 
218: 	sel_t middle = left + (right - left) / 2;
219: 	sel_t dpivot_idx = sel.get_index(result.get_index(middle));
220: 
221: 	// move the mid point value to the front.
222: 	sel_t i = left + 1;
223: 	sel_t j = right;
224: 
225: 	result.swap(middle, left);
226: 	while (i <= j) {
227: 		while (i <= j && (OP::Operation(data[sel.get_index(result.get_index(i))], data[dpivot_idx]))) {
228: 			i++;
229: 		}
230: 
231: 		while (i <= j && OP::Operation(data[dpivot_idx], data[sel.get_index(result.get_index(j))])) {
232: 			j--;
233: 		}
234: 
235: 		if (i < j) {
236: 			result.swap(i, j);
237: 		}
238: 	}
239: 	result.swap(i - 1, left);
240: 	sel_t part = i - 1;
241: 
242: 	if (part > 0) {
243: 		templated_quicksort_inplace<T, OP>(data, sel, count, result, left, part - 1);
244: 	}
245: 	templated_quicksort_inplace<T, OP>(data, sel, count, result, part + 1, right);
246: }
247: 
248: template <class T, class OP>
249: void templated_quicksort(T *__restrict data, const SelectionVector &sel, const SelectionVector &not_null_sel,
250:                          idx_t count, SelectionVector &result) {
251: 	auto part = templated_quicksort_initial<T, OP>(data, sel, not_null_sel, count, result);
252: 	if (part > count) {
253: 		return;
254: 	}
255: 	templated_quicksort_inplace<T, OP>(data, sel, count, result, 0, part);
256: 	templated_quicksort_inplace<T, OP>(data, sel, count, result, part + 1, count - 1);
257: }
258: 
259: template <class T>
260: static void templated_quicksort(VectorData &vdata, const SelectionVector &not_null_sel, idx_t not_null_count,
261:                                 SelectionVector &result) {
262: 	if (not_null_count == 0) {
263: 		return;
264: 	}
265: 	templated_quicksort<T, duckdb::LessThanEquals>((T *)vdata.data, *vdata.sel, not_null_sel, not_null_count, result);
266: }
267: 
268: void OrderVector(Vector &vector, idx_t count, MergeOrder &order) {
269: 	if (count == 0) {
270: 		order.count = 0;
271: 		return;
272: 	}
273: 	vector.Orrify(count, order.vdata);
274: 	auto &vdata = order.vdata;
275: 
276: 	// first filter out all the non-null values
277: 	idx_t not_null_count = 0;
278: 	SelectionVector not_null(STANDARD_VECTOR_SIZE);
279: 	for (idx_t i = 0; i < count; i++) {
280: 		auto idx = vdata.sel->get_index(i);
281: 		if (!(*vdata.nullmask)[idx]) {
282: 			not_null.set_index(not_null_count++, i);
283: 		}
284: 	}
285: 	order.count = not_null_count;
286: 	order.order.Initialize(STANDARD_VECTOR_SIZE);
287: 	switch (vector.type) {
288: 	case TypeId::INT8:
289: 		templated_quicksort<int8_t>(vdata, not_null, not_null_count, order.order);
290: 		break;
291: 	case TypeId::INT16:
292: 		templated_quicksort<int16_t>(vdata, not_null, not_null_count, order.order);
293: 		break;
294: 	case TypeId::INT32:
295: 		templated_quicksort<int32_t>(vdata, not_null, not_null_count, order.order);
296: 		break;
297: 	case TypeId::INT64:
298: 		templated_quicksort<int64_t>(vdata, not_null, not_null_count, order.order);
299: 		break;
300: 	case TypeId::FLOAT:
301: 		templated_quicksort<float>(vdata, not_null, not_null_count, order.order);
302: 		break;
303: 	case TypeId::DOUBLE:
304: 		templated_quicksort<double>(vdata, not_null, not_null_count, order.order);
305: 		break;
306: 	case TypeId::VARCHAR:
307: 		templated_quicksort<string_t>(vdata, not_null, not_null_count, order.order);
308: 		break;
309: 	default:
310: 		throw NotImplementedException("Unimplemented type for sort");
311: 	}
312: }
[end of src/execution/operator/join/physical_piecewise_merge_join.cpp]
[start of src/function/table/sqlite/pragma_table_info.cpp]
1: #include "duckdb/function/table/sqlite_functions.hpp"
2: 
3: #include "duckdb/catalog/catalog.hpp"
4: #include "duckdb/catalog/catalog_entry/table_catalog_entry.hpp"
5: #include "duckdb/catalog/catalog_entry/view_catalog_entry.hpp"
6: #include "duckdb/common/exception.hpp"
7: #include "duckdb/catalog/catalog.hpp"
8: 
9: #include <algorithm>
10: 
11: using namespace std;
12: 
13: namespace duckdb {
14: 
15: struct PragmaTableFunctionData : public TableFunctionData {
16: 	PragmaTableFunctionData() : entry(nullptr), offset(0) {
17: 	}
18: 
19: 	CatalogEntry *entry;
20: 	idx_t offset;
21: };
22: 
23: static unique_ptr<FunctionData> pragma_table_info_bind(ClientContext &context, vector<Value> inputs,
24:                                                        vector<SQLType> &return_types, vector<string> &names) {
25: 	names.push_back("cid");
26: 	return_types.push_back(SQLType::INTEGER);
27: 
28: 	names.push_back("name");
29: 	return_types.push_back(SQLType::VARCHAR);
30: 
31: 	names.push_back("type");
32: 	return_types.push_back(SQLType::VARCHAR);
33: 
34: 	names.push_back("notnull");
35: 	return_types.push_back(SQLType::BOOLEAN);
36: 
37: 	names.push_back("dflt_value");
38: 	return_types.push_back(SQLType::VARCHAR);
39: 
40: 	names.push_back("pk");
41: 	return_types.push_back(SQLType::BOOLEAN);
42: 
43: 	return make_unique<PragmaTableFunctionData>();
44: }
45: 
46: static void pragma_table_info_table(PragmaTableFunctionData &data, TableCatalogEntry *table, DataChunk &output) {
47: 	if (data.offset >= table->columns.size()) {
48: 		// finished returning values
49: 		return;
50: 	}
51: 	// start returning values
52: 	// either fill up the chunk or return all the remaining columns
53: 	idx_t next = min(data.offset + STANDARD_VECTOR_SIZE, (idx_t)table->columns.size());
54: 	output.SetCardinality(next - data.offset);
55: 
56: 	for (idx_t i = data.offset; i < next; i++) {
57: 		auto index = i - data.offset;
58: 		auto &column = table->columns[i];
59: 		// return values:
60: 		// "cid", TypeId::INT32
61: 		assert(column.oid < (idx_t)std::numeric_limits<int32_t>::max());
62: 
63: 		output.SetValue(0, index, Value::INTEGER((int32_t)column.oid));
64: 		// "name", TypeId::VARCHAR
65: 		output.SetValue(1, index, Value(column.name));
66: 		// "type", TypeId::VARCHAR
67: 		output.SetValue(2, index, Value(SQLTypeToString(column.type)));
68: 		// "notnull", TypeId::BOOL
69: 		// FIXME: look at constraints
70: 		output.SetValue(3, index, Value::BOOLEAN(false));
71: 		// "dflt_value", TypeId::VARCHAR
72: 		string def_value = column.default_value ? column.default_value->ToString() : "NULL";
73: 		output.SetValue(4, index, Value(def_value));
74: 		// "pk", TypeId::BOOL
75: 		// FIXME: look at constraints
76: 		output.SetValue(5, index, Value::BOOLEAN(false));
77: 	}
78: 	data.offset = next;
79: }
80: 
81: static void pragma_table_info_view(PragmaTableFunctionData &data, ViewCatalogEntry *view, DataChunk &output) {
82: 	if (data.offset >= view->types.size()) {
83: 		// finished returning values
84: 		return;
85: 	}
86: 	// start returning values
87: 	// either fill up the chunk or return all the remaining columns
88: 	idx_t next = min(data.offset + STANDARD_VECTOR_SIZE, (idx_t)view->types.size());
89: 	output.SetCardinality(next - data.offset);
90: 
91: 	for (idx_t i = data.offset; i < next; i++) {
92: 		auto index = i - data.offset;
93: 		auto type = view->types[index];
94: 		auto &name = view->aliases[index];
95: 		// return values:
96: 		// "cid", TypeId::INT32
97: 
98: 		output.SetValue(0, index, Value::INTEGER((int32_t) index));
99: 		// "name", TypeId::VARCHAR
100: 		output.SetValue(1, index, Value(name));
101: 		// "type", TypeId::VARCHAR
102: 		output.SetValue(2, index, Value(SQLTypeToString(type)));
103: 		// "notnull", TypeId::BOOL
104: 		output.SetValue(3, index, Value::BOOLEAN(false));
105: 		// "dflt_value", TypeId::VARCHAR
106: 		output.SetValue(4, index, Value());
107: 		// "pk", TypeId::BOOL
108: 		output.SetValue(5, index, Value::BOOLEAN(false));
109: 	}
110: 	data.offset = next;
111: }
112: 
113: static void pragma_table_info(ClientContext &context, vector<Value> &input, DataChunk &output, FunctionData *dataptr) {
114: 	auto &data = *((PragmaTableFunctionData *)dataptr);
115: 	if (!data.entry) {
116: 		// first call: load the entry from the catalog
117: 		assert(input.size() == 1);
118: 
119: 		string schema, table_name;
120: 		auto range_var = input[0].GetValue<string>();
121: 		Catalog::ParseRangeVar(range_var, schema, table_name);
122: 
123: 		// look up the table name in the catalog
124: 		auto &catalog = Catalog::GetCatalog(context);
125: 		data.entry = catalog.GetEntry(context, CatalogType::TABLE, schema, table_name);
126: 	}
127: 	switch(data.entry->type) {
128: 	case CatalogType::TABLE:
129: 		pragma_table_info_table(data, (TableCatalogEntry*) data.entry, output);
130: 		break;
131: 	case CatalogType::VIEW:
132: 		pragma_table_info_view(data, (ViewCatalogEntry*) data.entry, output);
133: 		break;
134: 	default:
135: 		throw NotImplementedException("Unimplemented catalog type for pragma_table_info");
136: 	}
137: }
138: 
139: void PragmaTableInfo::RegisterFunction(BuiltinFunctions &set) {
140: 	set.AddFunction(
141: 	    TableFunction("pragma_table_info", {SQLType::VARCHAR}, pragma_table_info_bind, pragma_table_info, nullptr));
142: }
143: 
144: } // namespace duckdb
[end of src/function/table/sqlite/pragma_table_info.cpp]
[start of src/include/duckdb/common/operator/boolean_operators.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/common/operator/boolean_operators.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: namespace duckdb {
12: 
13: /*
14: SQL AND Rules:
15: 
16: TRUE  AND TRUE   = TRUE
17: TRUE  AND FALSE  = FALSE
18: TRUE  AND NULL   = NULL
19: FALSE AND TRUE   = FALSE
20: FALSE AND FALSE  = FALSE
21: FALSE AND NULL   = FALSE
22: NULL  AND TRUE   = NULL
23: NULL  AND FALSE  = FALSE
24: NULL  AND NULL   = NULL
25: 
26: Basically:
27: - Only true if both are true
28: - False if either is false (regardless of NULLs)
29: - NULL otherwise
30: */
31: struct And {
32: 	static inline bool Operation(bool left, bool right) {
33: 		return left && right;
34: 	}
35: };
36: 
37: struct AndMask {
38: 	static inline bool Operation(bool left, bool right, bool left_null, bool right_null) {
39: 		return (left_null && (right_null || right)) || (right_null && left);
40: 	}
41: };
42: 
43: /*
44: SQL OR Rules:
45: 
46: OR
47: TRUE  OR TRUE  = TRUE
48: TRUE  OR FALSE = TRUE
49: TRUE  OR NULL  = TRUE
50: FALSE OR TRUE  = TRUE
51: FALSE OR FALSE = FALSE
52: FALSE OR NULL  = NULL
53: NULL  OR TRUE  = TRUE
54: NULL  OR FALSE = NULL
55: NULL  OR NULL  = NULL
56: 
57: Basically:
58: - Only false if both are false
59: - True if either is true (regardless of NULLs)
60: - NULL otherwise
61: */
62: struct Or {
63: 	static inline bool Operation(bool left, bool right) {
64: 		return left || right;
65: 	}
66: };
67: 
68: struct OrMask {
69: 	static inline bool Operation(bool left, bool right, bool left_null, bool right_null) {
70: 		return (left_null && (right_null || !right)) || (right_null && !left);
71: 	}
72: };
73: } // namespace duckdb
[end of src/include/duckdb/common/operator/boolean_operators.hpp]
[start of src/optimizer/filter_combiner.cpp]
1: #include "duckdb/optimizer/filter_combiner.hpp"
2: 
3: #include "duckdb/execution/expression_executor.hpp"
4: #include "duckdb/planner/expression/bound_between_expression.hpp"
5: #include "duckdb/planner/expression/bound_comparison_expression.hpp"
6: #include "duckdb/planner/expression/bound_constant_expression.hpp"
7: #include "duckdb/planner/operator/logical_empty_result.hpp"
8: #include "duckdb/planner/operator/logical_filter.hpp"
9: #include "duckdb/planner/expression/bound_columnref_expression.hpp"
10: #include "duckdb/planner/expression.hpp"
11: using namespace duckdb;
12: using namespace std;
13: 
14: using ExpressionValueInformation = FilterCombiner::ExpressionValueInformation;
15: 
16: ValueComparisonResult CompareValueInformation(ExpressionValueInformation &left, ExpressionValueInformation &right);
17: 
18: Expression *FilterCombiner::GetNode(Expression *expr) {
19: 	auto entry = stored_expressions.find(expr);
20: 	if (entry != stored_expressions.end()) {
21: 		// expression already exists: return a reference to the stored expression
22: 		return entry->second.get();
23: 	}
24: 	// expression does not exist yet: create a copy and store it
25: 	auto copy = expr->Copy();
26: 	auto pointer_copy = copy.get();
27: 	stored_expressions.insert(make_pair(pointer_copy, move(copy)));
28: 	return pointer_copy;
29: }
30: 
31: idx_t FilterCombiner::GetEquivalenceSet(Expression *expr) {
32: 	assert(stored_expressions.find(expr) != stored_expressions.end());
33: 	assert(stored_expressions.find(expr)->second.get() == expr);
34: 
35: 	auto entry = equivalence_set_map.find(expr);
36: 	if (entry == equivalence_set_map.end()) {
37: 		idx_t index = set_index++;
38: 		equivalence_set_map[expr] = index;
39: 		equivalence_map[index].push_back(expr);
40: 		constant_values.insert(make_pair(index, vector<ExpressionValueInformation>()));
41: 		return index;
42: 	} else {
43: 		return entry->second;
44: 	}
45: }
46: 
47: FilterResult FilterCombiner::AddConstantComparison(vector<ExpressionValueInformation> &info_list,
48:                                                    ExpressionValueInformation info) {
49: 	for (idx_t i = 0; i < info_list.size(); i++) {
50: 		auto comparison = CompareValueInformation(info_list[i], info);
51: 		switch (comparison) {
52: 		case ValueComparisonResult::PRUNE_LEFT:
53: 			// prune the entry from the info list
54: 			info_list.erase(info_list.begin() + i);
55: 			i--;
56: 			break;
57: 		case ValueComparisonResult::PRUNE_RIGHT:
58: 			// prune the current info
59: 			return FilterResult::SUCCESS;
60: 		case ValueComparisonResult::UNSATISFIABLE_CONDITION:
61: 			// combination of filters is unsatisfiable: prune the entire branch
62: 			return FilterResult::UNSATISFIABLE;
63: 		default:
64: 			// prune nothing, move to the next condition
65: 			break;
66: 		}
67: 	}
68: 	// finally add the entry to the list
69: 	info_list.push_back(info);
70: 	return FilterResult::SUCCESS;
71: }
72: 
73: FilterResult FilterCombiner::AddFilter(unique_ptr<Expression> expr) {
74: 	// try to push the filter into the combiner
75: 	auto result = AddFilter(expr.get());
76: 	if (result == FilterResult::UNSUPPORTED) {
77: 		// unsupported filter, push into remaining filters
78: 		remaining_filters.push_back(move(expr));
79: 		return FilterResult::SUCCESS;
80: 	}
81: 	return result;
82: }
83: 
84: void FilterCombiner::GenerateFilters(std::function<void(unique_ptr<Expression> filter)> callback) {
85: 	// first loop over the remaining filters
86: 	for (auto &filter : remaining_filters) {
87: 		callback(move(filter));
88: 	}
89: 	remaining_filters.clear();
90: 	// now loop over the equivalence sets
91: 	for (auto &entry : equivalence_map) {
92: 		auto equivalence_set = entry.first;
93: 		auto &entries = entry.second;
94: 		auto &constant_list = constant_values.find(equivalence_set)->second;
95: 		// for each entry generate an equality expression comparing to each other
96: 		for (idx_t i = 0; i < entries.size(); i++) {
97: 			for (idx_t k = i + 1; k < entries.size(); k++) {
98: 				auto comparison = make_unique<BoundComparisonExpression>(ExpressionType::COMPARE_EQUAL,
99: 				                                                         entries[i]->Copy(), entries[k]->Copy());
100: 				callback(move(comparison));
101: 			}
102: 			// for each entry also create a comparison with each constant
103: 			int lower_index = -1, upper_index = -1;
104: 			bool lower_inclusive, upper_inclusive;
105: 			for (idx_t k = 0; k < constant_list.size(); k++) {
106: 				auto &info = constant_list[k];
107: 				if (info.comparison_type == ExpressionType::COMPARE_GREATERTHAN ||
108: 				    info.comparison_type == ExpressionType::COMPARE_GREATERTHANOREQUALTO) {
109: 					lower_index = k;
110: 					lower_inclusive = info.comparison_type == ExpressionType::COMPARE_GREATERTHANOREQUALTO;
111: 				} else if (info.comparison_type == ExpressionType::COMPARE_LESSTHAN ||
112: 				           info.comparison_type == ExpressionType::COMPARE_LESSTHANOREQUALTO) {
113: 					upper_index = k;
114: 					upper_inclusive = info.comparison_type == ExpressionType::COMPARE_LESSTHANOREQUALTO;
115: 				} else {
116: 					auto constant = make_unique<BoundConstantExpression>(info.constant);
117: 					auto comparison = make_unique<BoundComparisonExpression>(info.comparison_type, entries[i]->Copy(),
118: 					                                                         move(constant));
119: 					callback(move(comparison));
120: 				}
121: 			}
122: 			if (lower_index >= 0 && upper_index >= 0) {
123: 				// found both lower and upper index, create a BETWEEN expression
124: 				auto lower_constant = make_unique<BoundConstantExpression>(constant_list[lower_index].constant);
125: 				auto upper_constant = make_unique<BoundConstantExpression>(constant_list[upper_index].constant);
126: 				auto between = make_unique<BoundBetweenExpression>(
127: 				    entries[i]->Copy(), move(lower_constant), move(upper_constant), lower_inclusive, upper_inclusive);
128: 				callback(move(between));
129: 			} else if (lower_index >= 0) {
130: 				// only lower index found, create simple comparison expression
131: 				auto constant = make_unique<BoundConstantExpression>(constant_list[lower_index].constant);
132: 				auto comparison = make_unique<BoundComparisonExpression>(constant_list[lower_index].comparison_type,
133: 				                                                         entries[i]->Copy(), move(constant));
134: 				callback(move(comparison));
135: 			} else if (upper_index >= 0) {
136: 				// only upper index found, create simple comparison expression
137: 				auto constant = make_unique<BoundConstantExpression>(constant_list[upper_index].constant);
138: 				auto comparison = make_unique<BoundComparisonExpression>(constant_list[upper_index].comparison_type,
139: 				                                                         entries[i]->Copy(), move(constant));
140: 				callback(move(comparison));
141: 			}
142: 		}
143: 	}
144: 	stored_expressions.clear();
145: 	equivalence_set_map.clear();
146: 	constant_values.clear();
147: 	equivalence_map.clear();
148: }
149: 
150: bool FilterCombiner::HasFilters() {
151: 	bool has_filters = false;
152: 	GenerateFilters([&](unique_ptr<Expression> child) { has_filters = true; });
153: 	return has_filters;
154: }
155: 
156: vector<TableFilter>
157: FilterCombiner::GenerateTableScanFilters(std::function<void(unique_ptr<Expression> filter)> callback,
158:                                          vector<idx_t> &column_ids) {
159: 	vector<TableFilter> tableFilters;
160: 	//! First, we figure the filters that have constant expressions that we can push down to the table scan
161: 	for (auto &constant_value : constant_values) {
162: 		if (constant_value.second.size() > 0) {
163: 			for (idx_t i = 0; i < constant_value.second.size(); ++i) {
164: 				if ((constant_value.second[i].comparison_type == ExpressionType::COMPARE_EQUAL ||
165: 				     constant_value.second[i].comparison_type == ExpressionType::COMPARE_GREATERTHAN ||
166: 				     constant_value.second[i].comparison_type == ExpressionType::COMPARE_GREATERTHANOREQUALTO ||
167: 				     constant_value.second[i].comparison_type == ExpressionType::COMPARE_LESSTHAN ||
168: 				     constant_value.second[i].comparison_type == ExpressionType::COMPARE_LESSTHANOREQUALTO) &&
169: 				    TypeIsNumeric(constant_value.second[i].constant.type)) {
170: 					//! Here we check if these filters are column references
171: 					auto filter_exp = equivalence_map.find(constant_value.first);
172: 					if (filter_exp->second.size() == 1 &&
173: 					    filter_exp->second[0]->type == ExpressionType::BOUND_COLUMN_REF) {
174: 						auto filter_col_exp = static_cast<BoundColumnRefExpression *>(filter_exp->second[0]);
175: 						if (column_ids[filter_col_exp->binding.column_index] == COLUMN_IDENTIFIER_ROW_ID) {
176: 							break;
177: 						}
178: 						tableFilters.push_back(TableFilter(constant_value.second[i].constant,
179: 						                                   constant_value.second[i].comparison_type,
180: 						                                   filter_col_exp->binding.column_index));
181: 						auto equivalence_set = filter_exp->first;
182: 						auto &entries = filter_exp->second;
183: 						auto &constant_list = constant_values.find(equivalence_set)->second;
184: 						// for each entry generate an equality expression comparing to each other
185: 						for (idx_t i = 0; i < entries.size(); i++) {
186: 							for (idx_t k = i + 1; k < entries.size(); k++) {
187: 								auto comparison = make_unique<BoundComparisonExpression>(
188: 								    ExpressionType::COMPARE_EQUAL, entries[i]->Copy(), entries[k]->Copy());
189: 								callback(move(comparison));
190: 							}
191: 							// for each entry also create a comparison with each constant
192: 							int lower_index = -1, upper_index = -1;
193: 							bool lower_inclusive, upper_inclusive;
194: 							for (idx_t k = 0; k < constant_list.size(); k++) {
195: 								auto &info = constant_list[k];
196: 								if (info.comparison_type == ExpressionType::COMPARE_GREATERTHAN ||
197: 								    info.comparison_type == ExpressionType::COMPARE_GREATERTHANOREQUALTO) {
198: 									lower_index = k;
199: 									lower_inclusive =
200: 									    info.comparison_type == ExpressionType::COMPARE_GREATERTHANOREQUALTO;
201: 								} else if (info.comparison_type == ExpressionType::COMPARE_LESSTHAN ||
202: 								           info.comparison_type == ExpressionType::COMPARE_LESSTHANOREQUALTO) {
203: 									upper_index = k;
204: 									upper_inclusive = info.comparison_type == ExpressionType::COMPARE_LESSTHANOREQUALTO;
205: 								} else {
206: 									auto constant = make_unique<BoundConstantExpression>(info.constant);
207: 									auto comparison = make_unique<BoundComparisonExpression>(
208: 									    info.comparison_type, entries[i]->Copy(), move(constant));
209: 									callback(move(comparison));
210: 								}
211: 							}
212: 							if (lower_index >= 0 && upper_index >= 0) {
213: 								// found both lower and upper index, create a BETWEEN expression
214: 								auto lower_constant =
215: 								    make_unique<BoundConstantExpression>(constant_list[lower_index].constant);
216: 								auto upper_constant =
217: 								    make_unique<BoundConstantExpression>(constant_list[upper_index].constant);
218: 								auto between = make_unique<BoundBetweenExpression>(
219: 								    entries[i]->Copy(), move(lower_constant), move(upper_constant), lower_inclusive,
220: 								    upper_inclusive);
221: 								callback(move(between));
222: 							} else if (lower_index >= 0) {
223: 								// only lower index found, create simple comparison expression
224: 								auto constant =
225: 								    make_unique<BoundConstantExpression>(constant_list[lower_index].constant);
226: 								auto comparison = make_unique<BoundComparisonExpression>(
227: 								    constant_list[lower_index].comparison_type, entries[i]->Copy(), move(constant));
228: 								callback(move(comparison));
229: 							} else if (upper_index >= 0) {
230: 								// only upper index found, create simple comparison expression
231: 								auto constant =
232: 								    make_unique<BoundConstantExpression>(constant_list[upper_index].constant);
233: 								auto comparison = make_unique<BoundComparisonExpression>(
234: 								    constant_list[upper_index].comparison_type, entries[i]->Copy(), move(constant));
235: 								callback(move(comparison));
236: 							}
237: 						}
238: 						equivalence_map.erase(filter_exp);
239: 					}
240: 				}
241: 			}
242: 		}
243: 	}
244: 	return tableFilters;
245: }
246: 
247: FilterResult FilterCombiner::AddFilter(Expression *expr) {
248: 	if (expr->HasParameter()) {
249: 		return FilterResult::UNSUPPORTED;
250: 	}
251: 	if (expr->IsFoldable()) {
252: 		// scalar condition, evaluate it
253: 		auto result = ExpressionExecutor::EvaluateScalar(*expr).CastAs(TypeId::BOOL);
254: 		// check if the filter passes
255: 		if (result.is_null || !result.value_.boolean) {
256: 			// the filter does not pass the scalar test, create an empty result
257: 			return FilterResult::UNSATISFIABLE;
258: 		} else {
259: 			// the filter passes the scalar test, just remove the condition
260: 			return FilterResult::SUCCESS;
261: 		}
262: 	}
263: 	assert(!expr->IsFoldable());
264: 	if (expr->GetExpressionClass() != ExpressionClass::BOUND_COMPARISON) {
265: 		// only comparisons supported for now
266: 		return FilterResult::UNSUPPORTED;
267: 	}
268: 	auto &comparison = (BoundComparisonExpression &)*expr;
269: 	if (comparison.type != ExpressionType::COMPARE_LESSTHAN &&
270: 	    comparison.type != ExpressionType::COMPARE_LESSTHANOREQUALTO &&
271: 	    comparison.type != ExpressionType::COMPARE_GREATERTHAN &&
272: 	    comparison.type != ExpressionType::COMPARE_GREATERTHANOREQUALTO &&
273: 	    comparison.type != ExpressionType::COMPARE_EQUAL && comparison.type != ExpressionType::COMPARE_NOTEQUAL) {
274: 		// only support [>, >=, <, <=, ==] expressions
275: 		return FilterResult::UNSUPPORTED;
276: 	}
277: 	// check if one of the sides is a scalar value
278: 	bool left_is_scalar = comparison.left->IsFoldable();
279: 	bool right_is_scalar = comparison.right->IsFoldable();
280: 	if (left_is_scalar || right_is_scalar) {
281: 		// comparison with scalar
282: 		auto node = GetNode(left_is_scalar ? comparison.right.get() : comparison.left.get());
283: 		idx_t equivalence_set = GetEquivalenceSet(node);
284: 		auto scalar = left_is_scalar ? comparison.left.get() : comparison.right.get();
285: 		auto constant_value = ExpressionExecutor::EvaluateScalar(*scalar);
286: 
287: 		// create the ExpressionValueInformation
288: 		ExpressionValueInformation info;
289: 		info.comparison_type = left_is_scalar ? FlipComparisionExpression(comparison.type) : comparison.type;
290: 		info.constant = constant_value;
291: 
292: 		// get the current bucket of constant values
293: 		assert(constant_values.find(equivalence_set) != constant_values.end());
294: 		auto &info_list = constant_values.find(equivalence_set)->second;
295: 		// check the existing constant comparisons to see if we can do any pruning
296: 		return AddConstantComparison(info_list, info);
297: 	} else {
298: 		// comparison between two non-scalars
299: 		// only handle comparisons for now
300: 		if (expr->type != ExpressionType::COMPARE_EQUAL) {
301: 			return FilterResult::UNSUPPORTED;
302: 		}
303: 		// get the LHS and RHS nodes
304: 		auto left_node = GetNode(comparison.left.get());
305: 		auto right_node = GetNode(comparison.right.get());
306: 		// get the equivalence sets of the LHS and RHS
307: 		auto left_equivalence_set = GetEquivalenceSet(left_node);
308: 		auto right_equivalence_set = GetEquivalenceSet(right_node);
309: 		if (left_equivalence_set == right_equivalence_set) {
310: 			// this equality filter already exists, prune it
311: 			return FilterResult::SUCCESS;
312: 		}
313: 		// add the right bucket into the left bucket
314: 		assert(equivalence_map.find(left_equivalence_set) != equivalence_map.end());
315: 		assert(equivalence_map.find(right_equivalence_set) != equivalence_map.end());
316: 
317: 		auto &left_bucket = equivalence_map.find(left_equivalence_set)->second;
318: 		auto &right_bucket = equivalence_map.find(right_equivalence_set)->second;
319: 		for (idx_t i = 0; i < right_bucket.size(); i++) {
320: 			// rewrite the equivalence set mapping for this node
321: 			equivalence_set_map[right_bucket[i]] = left_equivalence_set;
322: 			// add the node to the left bucket
323: 			left_bucket.push_back(right_bucket[i]);
324: 		}
325: 		// now add all constant values from the right bucket to the left bucket
326: 		assert(constant_values.find(left_equivalence_set) != constant_values.end());
327: 		assert(constant_values.find(right_equivalence_set) != constant_values.end());
328: 		auto &left_constant_bucket = constant_values.find(left_equivalence_set)->second;
329: 		auto &right_constant_bucket = constant_values.find(right_equivalence_set)->second;
330: 		for (idx_t i = 0; i < right_constant_bucket.size(); i++) {
331: 			if (AddConstantComparison(left_constant_bucket, right_constant_bucket[i]) == FilterResult::UNSATISFIABLE) {
332: 				return FilterResult::UNSATISFIABLE;
333: 			}
334: 		}
335: 	}
336: 	return FilterResult::SUCCESS;
337: }
338: 
339: static bool IsGreaterThan(ExpressionType type) {
340: 	return type == ExpressionType::COMPARE_GREATERTHAN || type == ExpressionType::COMPARE_GREATERTHANOREQUALTO;
341: }
342: 
343: static bool IsLessThan(ExpressionType type) {
344: 	return type == ExpressionType::COMPARE_LESSTHAN || type == ExpressionType::COMPARE_LESSTHANOREQUALTO;
345: }
346: 
347: ValueComparisonResult InvertValueComparisonResult(ValueComparisonResult result) {
348: 	if (result == ValueComparisonResult::PRUNE_RIGHT) {
349: 		return ValueComparisonResult::PRUNE_LEFT;
350: 	}
351: 	if (result == ValueComparisonResult::PRUNE_LEFT) {
352: 		return ValueComparisonResult::PRUNE_RIGHT;
353: 	}
354: 	return result;
355: }
356: 
357: ValueComparisonResult CompareValueInformation(ExpressionValueInformation &left, ExpressionValueInformation &right) {
358: 	if (left.comparison_type == ExpressionType::COMPARE_EQUAL) {
359: 		// left is COMPARE_EQUAL, we can either
360: 		// (1) prune the right side or
361: 		// (2) return UNSATISFIABLE
362: 		bool prune_right_side = false;
363: 		switch (right.comparison_type) {
364: 		case ExpressionType::COMPARE_LESSTHAN:
365: 			prune_right_side = left.constant < right.constant;
366: 			break;
367: 		case ExpressionType::COMPARE_LESSTHANOREQUALTO:
368: 			prune_right_side = left.constant <= right.constant;
369: 			break;
370: 		case ExpressionType::COMPARE_GREATERTHAN:
371: 			prune_right_side = left.constant > right.constant;
372: 			break;
373: 		case ExpressionType::COMPARE_GREATERTHANOREQUALTO:
374: 			prune_right_side = left.constant >= right.constant;
375: 			break;
376: 		case ExpressionType::COMPARE_NOTEQUAL:
377: 			prune_right_side = left.constant != right.constant;
378: 			break;
379: 		default:
380: 			assert(right.comparison_type == ExpressionType::COMPARE_EQUAL);
381: 			prune_right_side = left.constant == right.constant;
382: 			break;
383: 		}
384: 		if (prune_right_side) {
385: 			return ValueComparisonResult::PRUNE_RIGHT;
386: 		} else {
387: 			return ValueComparisonResult::UNSATISFIABLE_CONDITION;
388: 		}
389: 	} else if (right.comparison_type == ExpressionType::COMPARE_EQUAL) {
390: 		// right is COMPARE_EQUAL
391: 		return InvertValueComparisonResult(CompareValueInformation(right, left));
392: 	} else if (left.comparison_type == ExpressionType::COMPARE_NOTEQUAL) {
393: 		// left is COMPARE_NOTEQUAL, we can either
394: 		// (1) prune the left side or
395: 		// (2) not prune anything
396: 		bool prune_left_side = false;
397: 		switch (right.comparison_type) {
398: 		case ExpressionType::COMPARE_LESSTHAN:
399: 			prune_left_side = left.constant >= right.constant;
400: 			break;
401: 		case ExpressionType::COMPARE_LESSTHANOREQUALTO:
402: 			prune_left_side = left.constant > right.constant;
403: 			break;
404: 		case ExpressionType::COMPARE_GREATERTHAN:
405: 			prune_left_side = left.constant <= right.constant;
406: 			break;
407: 		case ExpressionType::COMPARE_GREATERTHANOREQUALTO:
408: 			prune_left_side = left.constant < right.constant;
409: 			break;
410: 		default:
411: 			assert(right.comparison_type == ExpressionType::COMPARE_NOTEQUAL);
412: 			prune_left_side = left.constant == right.constant;
413: 			break;
414: 		}
415: 		if (prune_left_side) {
416: 			return ValueComparisonResult::PRUNE_LEFT;
417: 		} else {
418: 			return ValueComparisonResult::PRUNE_NOTHING;
419: 		}
420: 	} else if (right.comparison_type == ExpressionType::COMPARE_NOTEQUAL) {
421: 		return InvertValueComparisonResult(CompareValueInformation(right, left));
422: 	} else if (IsGreaterThan(left.comparison_type) && IsGreaterThan(right.comparison_type)) {
423: 		// both comparisons are [>], we can either
424: 		// (1) prune the left side or
425: 		// (2) prune the right side
426: 		if (left.constant > right.constant) {
427: 			// left constant is more selective, prune right
428: 			return ValueComparisonResult::PRUNE_RIGHT;
429: 		} else if (left.constant < right.constant) {
430: 			// right constant is more selective, prune left
431: 			return ValueComparisonResult::PRUNE_LEFT;
432: 		} else {
433: 			// constants are equivalent
434: 			// however we can still have the scenario where one is [>=] and the other is [>]
435: 			// we want to prune the [>=] because [>] is more selective
436: 			// if left is [>=] we prune the left, else we prune the right
437: 			if (left.comparison_type == ExpressionType::COMPARE_GREATERTHANOREQUALTO) {
438: 				return ValueComparisonResult::PRUNE_LEFT;
439: 			} else {
440: 				return ValueComparisonResult::PRUNE_RIGHT;
441: 			}
442: 		}
443: 	} else if (IsLessThan(left.comparison_type) && IsLessThan(right.comparison_type)) {
444: 		// both comparisons are [<], we can either
445: 		// (1) prune the left side or
446: 		// (2) prune the right side
447: 		if (left.constant < right.constant) {
448: 			// left constant is more selective, prune right
449: 			return ValueComparisonResult::PRUNE_RIGHT;
450: 		} else if (left.constant > right.constant) {
451: 			// right constant is more selective, prune left
452: 			return ValueComparisonResult::PRUNE_LEFT;
453: 		} else {
454: 			// constants are equivalent
455: 			// however we can still have the scenario where one is [<=] and the other is [<]
456: 			// we want to prune the [<=] because [<] is more selective
457: 			// if left is [<=] we prune the left, else we prune the right
458: 			if (left.comparison_type == ExpressionType::COMPARE_LESSTHANOREQUALTO) {
459: 				return ValueComparisonResult::PRUNE_LEFT;
460: 			} else {
461: 				return ValueComparisonResult::PRUNE_RIGHT;
462: 			}
463: 		}
464: 	} else if (IsLessThan(left.comparison_type)) {
465: 		assert(IsGreaterThan(right.comparison_type));
466: 		// left is [<] and right is [>], in this case we can either
467: 		// (1) prune nothing or
468: 		// (2) return UNSATISFIABLE
469: 		// the SMALLER THAN constant has to be greater than the BIGGER THAN constant
470: 		if (left.constant >= right.constant) {
471: 			return ValueComparisonResult::PRUNE_NOTHING;
472: 		} else {
473: 			return ValueComparisonResult::UNSATISFIABLE_CONDITION;
474: 		}
475: 	} else {
476: 		// left is [>] and right is [<] or [!=]
477: 		assert(IsLessThan(right.comparison_type) && IsGreaterThan(left.comparison_type));
478: 		return InvertValueComparisonResult(CompareValueInformation(right, left));
479: 	}
480: }
[end of src/optimizer/filter_combiner.cpp]
[start of tools/jdbc/src/jni/duckdb_java.cpp]
1: #include "nl_cwi_da_duckdb_DuckDBNative.h"
2: #include "duckdb.hpp"
3: #include "duckdb/main/client_context.hpp"
4: 
5: using namespace duckdb;
6: using namespace std;
7: 
8: JNIEXPORT jobject JNICALL Java_nl_cwi_da_duckdb_DuckDBNative_duckdb_1jdbc_1startup(JNIEnv *env, jclass,
9:                                                                                    jstring database_j,
10:                                                                                    jboolean read_only) {
11: 
12: 	auto *database_c = env->GetStringUTFChars(database_j, 0);
13: 	auto database = string(database_c);
14: 	env->ReleaseStringUTFChars(database_j, database_c);
15: 
16: 	auto db = new DuckDB(database);
17: 	return env->NewDirectByteBuffer(db, 0);
18: }
19: 
20: JNIEXPORT void JNICALL Java_nl_cwi_da_duckdb_DuckDBNative_duckdb_1jdbc_1shutdown(JNIEnv *env, jclass,
21:                                                                                  jobject db_ref_buf) {
22: 	auto db_ref = (DuckDB *)env->GetDirectBufferAddress(db_ref_buf);
23: 	if (db_ref) {
24: 		delete db_ref;
25: 	}
26: }
27: 
28: JNIEXPORT jobject JNICALL Java_nl_cwi_da_duckdb_DuckDBNative_duckdb_1jdbc_1connect(JNIEnv *env, jclass,
29:                                                                                    jobject db_ref_buf) {
30: 	auto db_ref = (DuckDB *)env->GetDirectBufferAddress(db_ref_buf);
31: 	auto conn = new Connection(*db_ref);
32: 	return env->NewDirectByteBuffer(conn, 0);
33: }
34: 
35: JNIEXPORT void JNICALL Java_nl_cwi_da_duckdb_DuckDBNative_duckdb_1jdbc_1set_1auto_1commit(JNIEnv *env, jclass,
36:                                                                                           jobject conn_ref_buf,
37:                                                                                           jboolean auto_commit) {
38: 	auto conn_ref = (Connection *)env->GetDirectBufferAddress(conn_ref_buf);
39: 	if (!conn_ref) {
40: 		jclass Exception = env->FindClass("java/sql/SQLException");
41: 		env->ThrowNew(Exception, "Invalid connection");
42: 	}
43: 	conn_ref->context->transaction.SetAutoCommit(auto_commit);
44: }
45: 
46: JNIEXPORT jboolean JNICALL Java_nl_cwi_da_duckdb_DuckDBNative_duckdb_1jdbc_1get_1auto_1commit(JNIEnv *env, jclass,
47:                                                                                               jobject conn_ref_buf) {
48: 	auto conn_ref = (Connection *)env->GetDirectBufferAddress(conn_ref_buf);
49: 	if (!conn_ref) {
50: 		jclass Exception = env->FindClass("java/sql/SQLException");
51: 		env->ThrowNew(Exception, "Invalid connection");
52: 	}
53: 	return conn_ref->context->transaction.IsAutoCommit();
54: }
55: 
56: JNIEXPORT void JNICALL Java_nl_cwi_da_duckdb_DuckDBNative_duckdb_1jdbc_1disconnect(JNIEnv *env, jclass,
57:                                                                                    jobject conn_ref_buf) {
58: 	auto conn_ref = (Connection *)env->GetDirectBufferAddress(conn_ref_buf);
59: 	if (conn_ref) {
60: 		delete conn_ref;
61: 	}
62: }
63: 
64: struct StatementHolder {
65: 	unique_ptr<PreparedStatement> stmt;
66: };
67: 
68: JNIEXPORT jobject JNICALL Java_nl_cwi_da_duckdb_DuckDBNative_duckdb_1jdbc_1prepare(JNIEnv *env, jclass,
69:                                                                                    jobject conn_ref_buf,
70:                                                                                    jstring query_j) {
71: 	auto conn_ref = (Connection *)env->GetDirectBufferAddress(conn_ref_buf);
72: 	if (!conn_ref) {
73: 		jclass Exception = env->FindClass("java/sql/SQLException");
74: 		env->ThrowNew(Exception, "Invalid connection");
75: 	}
76: 
77: 	auto *query_c = env->GetStringUTFChars(query_j, 0);
78: 	auto query = string(query_c);
79: 	env->ReleaseStringUTFChars(query_j, query_c);
80: 
81: 	auto stmt_ref = new StatementHolder();
82: 	stmt_ref->stmt = conn_ref->Prepare(query);
83: 	if (!stmt_ref->stmt->success) {
84: 		jclass Exception = env->FindClass("java/sql/SQLException");
85: 		string error_msg = string(stmt_ref->stmt->error);
86: 		stmt_ref->stmt = nullptr;
87: 		env->ThrowNew(Exception, error_msg.c_str());
88: 	}
89: 	return env->NewDirectByteBuffer(stmt_ref, 0);
90: }
91: 
92: struct ResultHolder {
93: 	unique_ptr<QueryResult> res;
94: 	unique_ptr<DataChunk> chunk;
95: };
96: 
97: JNIEXPORT jobject JNICALL Java_nl_cwi_da_duckdb_DuckDBNative_duckdb_1jdbc_1execute(JNIEnv *env, jclass,
98:                                                                                    jobject stmt_ref_buf,
99:                                                                                    jobjectArray params) {
100: 	auto stmt_ref = (StatementHolder *)env->GetDirectBufferAddress(stmt_ref_buf);
101: 	if (!stmt_ref) {
102: 		jclass Exception = env->FindClass("java/sql/SQLException");
103: 		env->ThrowNew(Exception, "Invalid statement");
104: 	}
105: 	auto res_ref = new ResultHolder();
106: 	res_ref->res = stmt_ref->stmt->Execute();
107: 	if (!res_ref->res->success) {
108: 		jclass Exception = env->FindClass("java/sql/SQLException");
109: 		string error_msg = string(res_ref->res->error);
110: 		res_ref->res = nullptr;
111: 		env->ThrowNew(Exception, error_msg.c_str());
112: 	}
113: 	return env->NewDirectByteBuffer(res_ref, 0);
114: }
115: 
116: JNIEXPORT void JNICALL Java_nl_cwi_da_duckdb_DuckDBNative_duckdb_1jdbc_1release(JNIEnv *env, jclass,
117:                                                                                 jobject stmt_ref_buf) {
118: 	auto stmt_ref = (StatementHolder *)env->GetDirectBufferAddress(stmt_ref_buf);
119: 	if (stmt_ref) {
120: 		delete stmt_ref;
121: 	}
122: }
123: 
124: JNIEXPORT void JNICALL Java_nl_cwi_da_duckdb_DuckDBNative_duckdb_1jdbc_1free_1result(JNIEnv *env, jclass,
125:                                                                                      jobject res_ref_buf) {
126: 	auto res_ref = (ResultHolder *)env->GetDirectBufferAddress(res_ref_buf);
127: 	if (res_ref) {
128: 		delete res_ref;
129: 	}
130: }
131: 
132: JNIEXPORT jobject JNICALL Java_nl_cwi_da_duckdb_DuckDBNative_duckdb_1jdbc_1meta(JNIEnv *env, jclass,
133:                                                                                 jobject res_ref_buf) {
134: 	auto res_ref = (ResultHolder *)env->GetDirectBufferAddress(res_ref_buf);
135: 	if (!res_ref || !res_ref->res) {
136: 		jclass Exception = env->FindClass("java/sql/SQLException");
137: 		env->ThrowNew(Exception, "Invalid result set");
138: 	}
139: 
140: 	jclass meta = env->FindClass("nl/cwi/da/duckdb/DuckDBResultSetMetaData");
141: 	jmethodID meta_construct = env->GetMethodID(meta, "<init>", "(I[Ljava/lang/String;[Ljava/lang/String;)V");
142: 
143: 	auto column_count = res_ref->res->names.size();
144: 
145: 	auto name_array = env->NewObjectArray(column_count, env->FindClass("java/lang/String"), nullptr);
146: 	auto type_array = env->NewObjectArray(column_count, env->FindClass("java/lang/String"), nullptr);
147: 
148: 	for (idx_t col_idx = 0; col_idx < column_count; col_idx++) {
149: 		env->SetObjectArrayElement(name_array, col_idx, env->NewStringUTF(res_ref->res->names[col_idx].c_str()));
150: 		env->SetObjectArrayElement(type_array, col_idx,
151: 		                           env->NewStringUTF(SQLTypeToString(res_ref->res->sql_types[col_idx]).c_str()));
152: 	}
153: 
154: 	return env->NewObject(meta, meta_construct, column_count, name_array, type_array);
155: }
156: 
157: JNIEXPORT jobjectArray JNICALL Java_nl_cwi_da_duckdb_DuckDBNative_duckdb_1jdbc_1fetch(JNIEnv *env, jclass,
158:                                                                                       jobject res_ref_buf) {
159: 	auto res_ref = (ResultHolder *)env->GetDirectBufferAddress(res_ref_buf);
160: 	if (!res_ref) {
161: 		jclass Exception = env->FindClass("java/sql/SQLException");
162: 		env->ThrowNew(Exception, "Invalid result set");
163: 	}
164: 
165: 	res_ref->chunk = res_ref->res->Fetch();
166: 	auto row_count = res_ref->chunk->size();
167: 
168: 	auto vec_array = (jobjectArray)env->NewObjectArray(res_ref->chunk->column_count(),
169: 	                                                   env->FindClass("nl/cwi/da/duckdb/DuckDBVector"), nullptr);
170: 	for (idx_t col_idx = 0; col_idx < res_ref->chunk->column_count(); col_idx++) {
171: 		auto &vec = res_ref->chunk->data[col_idx];
172: 		auto type_str = env->NewStringUTF(TypeIdToString(vec.type).c_str());
173: 		// construct nullmask
174: 		auto null_array = env->NewBooleanArray(row_count);
175: 		jboolean *null_array_ptr = env->GetBooleanArrayElements(null_array, nullptr);
176: 		for (idx_t row_idx = 0; row_idx < row_count; row_idx++) {
177: 			null_array_ptr[row_idx] = FlatVector::Nullmask(vec)[row_idx];
178: 		}
179: 		env->ReleaseBooleanArrayElements(null_array, null_array_ptr, 0);
180: 
181: 		jclass vec_class = env->FindClass("nl/cwi/da/duckdb/DuckDBVector");
182: 		jmethodID vec_construct = env->GetMethodID(vec_class, "<init>", "(Ljava/lang/String;I[Z)V");
183: 		auto jvec = env->NewObject(vec_class, vec_construct, type_str, (int)row_count, null_array);
184: 
185: 		jobject constlen_data = nullptr;
186: 		jobjectArray varlen_data = nullptr;
187: 
188: 		switch (vec.type) {
189: 		case TypeId::BOOL:
190: 			constlen_data = env->NewDirectByteBuffer(FlatVector::GetData(vec), row_count * sizeof(bool));
191: 			break;
192: 		case TypeId::INT8:
193: 			constlen_data = env->NewDirectByteBuffer(FlatVector::GetData(vec), row_count * sizeof(int8_t));
194: 			break;
195: 		case TypeId::INT16:
196: 			constlen_data = env->NewDirectByteBuffer(FlatVector::GetData(vec), row_count * sizeof(int16_t));
197: 			break;
198: 		case TypeId::INT32:
199: 			constlen_data = env->NewDirectByteBuffer(FlatVector::GetData(vec), row_count * sizeof(int32_t));
200: 			break;
201: 		case TypeId::INT64:
202: 			constlen_data = env->NewDirectByteBuffer(FlatVector::GetData(vec), row_count * sizeof(int64_t));
203: 			break;
204: 		case TypeId::FLOAT:
205: 			constlen_data = env->NewDirectByteBuffer(FlatVector::GetData(vec), row_count * sizeof(float));
206: 			break;
207: 		case TypeId::DOUBLE:
208: 			constlen_data = env->NewDirectByteBuffer(FlatVector::GetData(vec), row_count * sizeof(double));
209: 			break;
210: 		case TypeId::VARCHAR:
211: 			varlen_data = env->NewObjectArray(row_count, env->FindClass("java/lang/String"), nullptr);
212: 			for (idx_t row_idx = 0; row_idx < row_count; row_idx++) {
213: 				env->SetObjectArrayElement(
214: 				    varlen_data, row_idx, env->NewStringUTF(((string_t *)FlatVector::GetData(vec))[row_idx].GetData()));
215: 			}
216: 			break;
217: 		default:
218: 			jclass Exception = env->FindClass("java/sql/SQLException");
219: 			env->ThrowNew(Exception, ("Unsupported result column type " + TypeIdToString(vec.type)).c_str());
220: 		}
221: 
222: 		jfieldID constlen_data_field = env->GetFieldID(vec_class, "constlen_data", "Ljava/nio/ByteBuffer;");
223: 		jfieldID varlen_data_field = env->GetFieldID(vec_class, "varlen_data", "[Ljava/lang/Object;");
224: 
225: 		env->SetObjectField(jvec, constlen_data_field, constlen_data);
226: 		env->SetObjectField(jvec, varlen_data_field, varlen_data);
227: 
228: 		env->SetObjectArrayElement(vec_array, col_idx, jvec);
229: 	}
230: 
231: 	return vec_array;
232: }
[end of tools/jdbc/src/jni/duckdb_java.cpp]
[start of tools/jdbc/src/main/java/nl/cwi/da/duckdb/DuckDBConnection.java]
1: package nl.cwi.da.duckdb;
2: 
3: import java.nio.ByteBuffer;
4: import java.sql.Array;
5: import java.sql.Blob;
6: import java.sql.CallableStatement;
7: import java.sql.Clob;
8: import java.sql.DatabaseMetaData;
9: import java.sql.NClob;
10: import java.sql.PreparedStatement;
11: import java.sql.ResultSet;
12: import java.sql.SQLClientInfoException;
13: import java.sql.SQLException;
14: import java.sql.SQLFeatureNotSupportedException;
15: import java.sql.SQLWarning;
16: import java.sql.SQLXML;
17: import java.sql.Savepoint;
18: import java.sql.Statement;
19: import java.sql.Struct;
20: import java.util.Map;
21: import java.util.Properties;
22: import java.util.concurrent.Executor;
23: 
24: public class DuckDBConnection implements java.sql.Connection {
25: 	protected ByteBuffer conn_ref = null;
26: 	protected DuckDBDatabase db;
27: 
28: 	public DuckDBConnection(DuckDBDatabase db) {
29: 		conn_ref = DuckDBNative.duckdb_jdbc_connect(db.db_ref);
30: 		this.db = db;
31: 	}
32: 
33: 	public Statement createStatement() throws SQLException {
34: 		if (isClosed()) {
35: 			throw new SQLException("Connection was closed");
36: 		}
37: 		return new DuckDBStatement(this);
38: 	}
39: 
40: 	public void commit() throws SQLException {
41: 		Statement s = createStatement();
42: 		s.execute("COMMIT");
43: 		s.close();
44: 	}
45: 
46: 	public void rollback() throws SQLException {
47: 		Statement s = createStatement();
48: 		s.execute("ROLLBACK");
49: 		s.close();
50: 	}
51: 
52: 	public void close() throws SQLException {
53: 		if (conn_ref != null) {
54: 			DuckDBNative.duckdb_jdbc_disconnect(conn_ref);
55: 			conn_ref = null;
56: 		}
57: 		db = null;
58: 	}
59: 
60: 	public boolean isClosed() throws SQLException {
61: 		return conn_ref == null;
62: 	}
63: 
64: 	public boolean isValid(int timeout) throws SQLException {
65: 		if (isClosed()) {
66: 			return false;
67: 		}
68: 		// run a query just to be sure
69: 		Statement s = createStatement();
70: 		ResultSet rs = s.executeQuery("SELECT 42");
71: 		if (!rs.next() || rs.getInt(1) != 42) {
72: 			rs.close();
73: 			s.close();
74: 			return false;
75: 		}
76: 		rs.close();
77: 		s.close();
78: 
79: 		return true;
80: 	}
81: 
82: 	public SQLWarning getWarnings() throws SQLException {
83: 		return null;
84: 	}
85: 
86: 	public void clearWarnings() throws SQLException {
87: 	}
88: 
89: 	public void setTransactionIsolation(int level) throws SQLException {
90: 		if (level > TRANSACTION_REPEATABLE_READ) {
91: 			throw new SQLFeatureNotSupportedException();
92: 		}
93: 	}
94: 
95: 	public int getTransactionIsolation() throws SQLException {
96: 		return TRANSACTION_REPEATABLE_READ;
97: 	}
98: 
99: 	public void setReadOnly(boolean readOnly) throws SQLException {
100: 		if (readOnly) {
101: 			throw new SQLFeatureNotSupportedException("Invidual connections can't be read-only");
102: 		}
103: 	}
104: 
105: 	public boolean isReadOnly() throws SQLException {
106: 		return false;
107: 	}
108: 
109: 	// at some point we will implement this
110: 
111: 	public void setAutoCommit(boolean autoCommit) throws SQLException {
112: 		if (isClosed()) {
113: 			throw new SQLException("Connection was closed");
114: 		}
115: 		DuckDBNative.duckdb_jdbc_set_auto_commit(conn_ref, autoCommit);
116: 	}
117: 
118: 	public boolean getAutoCommit() throws SQLException {
119: 		if (isClosed()) {
120: 			throw new SQLException("Connection was closed");
121: 		}
122: 		return DuckDBNative.duckdb_jdbc_get_auto_commit(conn_ref);
123: 	}
124: 
125: 	public PreparedStatement prepareStatement(String sql) throws SQLException {
126: 		throw new SQLFeatureNotSupportedException();
127: 	}
128: 
129: 	public DatabaseMetaData getMetaData() throws SQLException {
130: 		return new DuckDBDatabaseMetaData(this);
131: 	}
132: 
133: 	public void setCatalog(String catalog) throws SQLException {
134: 		throw new SQLFeatureNotSupportedException();
135: 	}
136: 
137: 	public String getCatalog() throws SQLException {
138: 		throw new SQLFeatureNotSupportedException();
139: 	}
140: 
141: 	public void setSchema(String schema) throws SQLException {
142: 		throw new SQLFeatureNotSupportedException();
143: 	}
144: 
145: 	public String getSchema() throws SQLException {
146: 		throw new SQLFeatureNotSupportedException();
147: 	}
148: 
149: 	public void abort(Executor executor) throws SQLException {
150: 		throw new SQLFeatureNotSupportedException();
151: 	}
152: 
153: 	public Clob createClob() throws SQLException {
154: 		throw new SQLFeatureNotSupportedException();
155: 	}
156: 
157: 	public Blob createBlob() throws SQLException {
158: 		throw new SQLFeatureNotSupportedException();
159: 	}
160: 
161: 	// less likely to implement this stuff
162: 
163: 	public <T> T unwrap(Class<T> iface) throws SQLException {
164: 		throw new SQLFeatureNotSupportedException();
165: 	}
166: 
167: 	public boolean isWrapperFor(Class<?> iface) throws SQLException {
168: 		throw new SQLFeatureNotSupportedException();
169: 	}
170: 
171: 	public CallableStatement prepareCall(String sql) throws SQLException {
172: 		throw new SQLFeatureNotSupportedException();
173: 	}
174: 
175: 	public String nativeSQL(String sql) throws SQLException {
176: 		throw new SQLFeatureNotSupportedException();
177: 	}
178: 
179: 	public Statement createStatement(int resultSetType, int resultSetConcurrency) throws SQLException {
180: 		throw new SQLFeatureNotSupportedException();
181: 	}
182: 
183: 	public PreparedStatement prepareStatement(String sql, int resultSetType, int resultSetConcurrency)
184: 			throws SQLException {
185: 		throw new SQLFeatureNotSupportedException();
186: 	}
187: 
188: 	public CallableStatement prepareCall(String sql, int resultSetType, int resultSetConcurrency) throws SQLException {
189: 		throw new SQLFeatureNotSupportedException();
190: 	}
191: 
192: 	public Map<String, Class<?>> getTypeMap() throws SQLException {
193: 		throw new SQLFeatureNotSupportedException();
194: 	}
195: 
196: 	public void setTypeMap(Map<String, Class<?>> map) throws SQLException {
197: 		throw new SQLFeatureNotSupportedException();
198: 	}
199: 
200: 	public void setHoldability(int holdability) throws SQLException {
201: 		throw new SQLFeatureNotSupportedException();
202: 	}
203: 
204: 	public int getHoldability() throws SQLException {
205: 		throw new SQLFeatureNotSupportedException();
206: 	}
207: 
208: 	public Savepoint setSavepoint() throws SQLException {
209: 		throw new SQLFeatureNotSupportedException();
210: 	}
211: 
212: 	public Savepoint setSavepoint(String name) throws SQLException {
213: 		throw new SQLFeatureNotSupportedException();
214: 	}
215: 
216: 	public void rollback(Savepoint savepoint) throws SQLException {
217: 		throw new SQLFeatureNotSupportedException();
218: 	}
219: 
220: 	public void releaseSavepoint(Savepoint savepoint) throws SQLException {
221: 		throw new SQLFeatureNotSupportedException();
222: 	}
223: 
224: 	public Statement createStatement(int resultSetType, int resultSetConcurrency, int resultSetHoldability)
225: 			throws SQLException {
226: 		throw new SQLFeatureNotSupportedException();
227: 	}
228: 
229: 	public PreparedStatement prepareStatement(String sql, int resultSetType, int resultSetConcurrency,
230: 			int resultSetHoldability) throws SQLException {
231: 		throw new SQLFeatureNotSupportedException();
232: 	}
233: 
234: 	public CallableStatement prepareCall(String sql, int resultSetType, int resultSetConcurrency,
235: 			int resultSetHoldability) throws SQLException {
236: 		throw new SQLFeatureNotSupportedException();
237: 	}
238: 
239: 	public PreparedStatement prepareStatement(String sql, int autoGeneratedKeys) throws SQLException {
240: 		throw new SQLFeatureNotSupportedException();
241: 	}
242: 
243: 	public PreparedStatement prepareStatement(String sql, int[] columnIndexes) throws SQLException {
244: 		throw new SQLFeatureNotSupportedException();
245: 	}
246: 
247: 	public PreparedStatement prepareStatement(String sql, String[] columnNames) throws SQLException {
248: 		throw new SQLFeatureNotSupportedException();
249: 	}
250: 
251: 	public NClob createNClob() throws SQLException {
252: 		throw new SQLFeatureNotSupportedException();
253: 	}
254: 
255: 	public SQLXML createSQLXML() throws SQLException {
256: 		throw new SQLFeatureNotSupportedException(); // hell no
257: 	}
258: 
259: 	public void setClientInfo(String name, String value) throws SQLClientInfoException {
260: 		throw new SQLClientInfoException();
261: 	}
262: 
263: 	public void setClientInfo(Properties properties) throws SQLClientInfoException {
264: 		throw new SQLClientInfoException();
265: 	}
266: 
267: 	public String getClientInfo(String name) throws SQLException {
268: 		throw new SQLFeatureNotSupportedException();
269: 	}
270: 
271: 	public Properties getClientInfo() throws SQLException {
272: 		throw new SQLFeatureNotSupportedException();
273: 	}
274: 
275: 	public Array createArrayOf(String typeName, Object[] elements) throws SQLException {
276: 		throw new SQLFeatureNotSupportedException();
277: 	}
278: 
279: 	public Struct createStruct(String typeName, Object[] attributes) throws SQLException {
280: 		throw new SQLFeatureNotSupportedException();
281: 	}
282: 
283: 	public void setNetworkTimeout(Executor executor, int milliseconds) throws SQLException {
284: 		throw new SQLFeatureNotSupportedException();
285: 	}
286: 
287: 	public int getNetworkTimeout() throws SQLException {
288: 		throw new SQLFeatureNotSupportedException();
289: 	}
290: 
291: }
[end of tools/jdbc/src/main/java/nl/cwi/da/duckdb/DuckDBConnection.java]
[start of tools/jdbc/src/main/java/nl/cwi/da/duckdb/DuckDBDatabase.java]
1: package nl.cwi.da.duckdb;
2: 
3: import java.nio.ByteBuffer;
4: import java.sql.SQLException;
5: 
6: public class DuckDBDatabase {
7: 
8: 	public DuckDBDatabase(String url) throws SQLException {
9: 		if (!url.startsWith("jdbc:duckdb")) {
10: 			throw new SQLException("DuckDB JDBC URL needs to start with 'jdbc:duckdb:'");
11: 		}
12: 		String db_dir = url.replaceFirst("^jdbc:duckdb:", "").trim();
13: 		if (db_dir.length() == 0) {
14: 			db_dir = ":memory:";
15: 		}
16: 		db_ref = DuckDBNative.duckdb_jdbc_startup(db_dir, false);
17: 	}
18: 
19: 	protected void finalize() throws Throwable {
20: 		if (db_ref != null) {
21: 			DuckDBNative.duckdb_jdbc_shutdown(db_ref);
22: 			db_ref = null;
23: 		}
24: 	}
25: 
26: 	protected ByteBuffer db_ref;
27: 
28: }
[end of tools/jdbc/src/main/java/nl/cwi/da/duckdb/DuckDBDatabase.java]
[start of tools/jdbc/src/main/java/nl/cwi/da/duckdb/DuckDBResultSet.java]
1: package nl.cwi.da.duckdb;
2: 
3: import java.io.InputStream;
4: import java.io.Reader;
5: import java.math.BigDecimal;
6: import java.net.URL;
7: import java.nio.ByteBuffer;
8: import java.nio.ByteOrder;
9: import java.sql.Array;
10: import java.sql.Blob;
11: import java.sql.Clob;
12: import java.sql.Date;
13: import java.sql.NClob;
14: import java.sql.Ref;
15: import java.sql.ResultSet;
16: import java.sql.ResultSetMetaData;
17: import java.sql.RowId;
18: import java.sql.SQLException;
19: import java.sql.SQLFeatureNotSupportedException;
20: import java.sql.SQLWarning;
21: import java.sql.SQLXML;
22: import java.sql.Statement;
23: import java.sql.Time;
24: import java.sql.Timestamp;
25: import java.util.Calendar;
26: import java.util.Map;
27: 
28: public class DuckDBResultSet implements ResultSet {
29: 
30: 	private DuckDBStatement stmt;
31: 	private DuckDBResultSetMetaData meta;
32: 
33: 	private ByteBuffer result_ref;
34: 	private DuckDBVector[] current_chunk;
35: 	private int chunk_idx = 0;
36: 	private boolean finished = false;
37: 	private boolean was_null;
38: 
39: 	public DuckDBResultSet(DuckDBStatement stmt, ByteBuffer result_ref) {
40: 		this.stmt = stmt;
41: 		this.result_ref = result_ref;
42: 		meta = DuckDBNative.duckdb_jdbc_meta(result_ref);
43: 		current_chunk = DuckDBNative.duckdb_jdbc_fetch(result_ref);
44: 		if (current_chunk.length == 0) {
45: 			finished = true;
46: 		}
47: 	}
48: 
49: 	public Statement getStatement() throws SQLException {
50: 		if (isClosed()) {
51: 			throw new SQLException("ResultSet was closed");
52: 		}
53: 		return stmt;
54: 	}
55: 
56: 	public ResultSetMetaData getMetaData() throws SQLException {
57: 		if (isClosed()) {
58: 			throw new SQLException("ResultSet was closed");
59: 		}
60: 		return meta;
61: 	}
62: 
63: 	public boolean next() throws SQLException {
64: 		if (isClosed()) {
65: 			throw new SQLException("ResultSet was closed");
66: 		}
67: 		if (finished) {
68: 			return false;
69: 		}
70: 		chunk_idx++;
71: 		if (chunk_idx > current_chunk[0].length) {
72: 			current_chunk = DuckDBNative.duckdb_jdbc_fetch(result_ref);
73: 			chunk_idx = 1;
74: 		}
75: 		if (current_chunk.length == 0) {
76: 			finished = true;
77: 			return false;
78: 		}
79: 		return true;
80: 	}
81: 
82: 	public void close() throws SQLException {
83: 		if (result_ref != null) {
84: 			DuckDBNative.duckdb_jdbc_free_result(result_ref);
85: 			result_ref = null;
86: 		}
87: 		stmt = null;
88: 		meta = null;
89: 		current_chunk = null;
90: 	}
91: 
92: 	public boolean isClosed() throws SQLException {
93: 		return result_ref == null;
94: 	}
95: 
96: 	private void check(int columnIndex) throws SQLException {
97: 		if (isClosed()) {
98: 			throw new SQLException("ResultSet was closed");
99: 		}
100: 		if (columnIndex < 1 || columnIndex > meta.column_count) {
101: 			throw new SQLException("Column index out of bounds");
102: 		}
103: 
104: 	}
105: 
106: 	public Object getObject(int columnIndex) throws SQLException {
107: 		switch (meta.column_types[columnIndex - 1]) {
108: 		case "BOOLEAN":
109: 			return getBoolean(columnIndex);
110: 		case "TINYINT":
111: 			return getByte(columnIndex);
112: 		case "SMALLINT":
113: 			return getShort(columnIndex);
114: 		case "INTEGER":
115: 			return getInt(columnIndex);
116: 		case "BIGINT":
117: 			return getLong(columnIndex);
118: 		case "FLOAT":
119: 			return getFloat(columnIndex);
120: 		case "DOUBLE":
121: 			return getDouble(columnIndex);
122: 		case "VARCHAR":
123: 			return getString(columnIndex);
124: 		default:
125: 			throw new SQLException("Not implemented type: " + meta.column_types[columnIndex - 1]);
126: 		}
127: 	}
128: 
129: 	public boolean wasNull() throws SQLException {
130: 		if (isClosed()) {
131: 			throw new SQLException("ResultSet was closed");
132: 		}
133: 		return was_null;
134: 	}
135: 
136: 	private boolean check_and_null(int columnIndex) throws SQLException {
137: 		check(columnIndex);
138: 		was_null = current_chunk[columnIndex - 1].nullmask[chunk_idx - 1];
139: 		return was_null;
140: 	}
141: 
142: 	public String getString(int columnIndex) throws SQLException {
143: 		if (check_and_null(columnIndex)) {
144: 			return "NULL";
145: 		}
146: 		if ("VARCHAR".equals(meta.column_types[columnIndex - 1])) {
147: 			return (String) current_chunk[columnIndex - 1].varlen_data[chunk_idx - 1];
148: 		}
149: 		return getObject(columnIndex).toString();
150: 	}
151: 
152: 	private ByteBuffer getbuf(int columnIndex, int typeWidth) throws SQLException {
153: 		ByteBuffer buf = current_chunk[columnIndex - 1].constlen_data;
154: 		buf.order(ByteOrder.LITTLE_ENDIAN);
155: 		buf.position((chunk_idx - 1) * typeWidth);
156: 		return buf;
157: 	}
158: 
159: 	public boolean getBoolean(int columnIndex) throws SQLException {
160: 		if (check_and_null(columnIndex)) {
161: 			return false;
162: 		}
163: 		if ("BOOLEAN".equals(meta.column_types[columnIndex - 1])) {
164: 			return getbuf(columnIndex, 1).get() == 1;
165: 		}
166: 		Object o = getObject(columnIndex);
167: 		if (o instanceof Number) {
168: 			return ((Number) o).byteValue() == 1;
169: 		}
170: 
171: 		return Boolean.parseBoolean(getObject(columnIndex).toString());
172: 	}
173: 
174: 	public byte getByte(int columnIndex) throws SQLException {
175: 		if (check_and_null(columnIndex)) {
176: 			return 0;
177: 		}
178: 		if ("TINYINT".equals(meta.column_types[columnIndex - 1])) {
179: 			return getbuf(columnIndex, 1).get();
180: 		}
181: 		Object o = getObject(columnIndex);
182: 		if (o instanceof Number) {
183: 			return ((Number) o).byteValue();
184: 		}
185: 		return Byte.parseByte(o.toString());
186: 	}
187: 
188: 	public short getShort(int columnIndex) throws SQLException {
189: 		if (check_and_null(columnIndex)) {
190: 			return 0;
191: 		}
192: 		if ("SMALLINT".equals(meta.column_types[columnIndex - 1])) {
193: 			return getbuf(columnIndex, 2).getShort();
194: 		}
195: 		Object o = getObject(columnIndex);
196: 		if (o instanceof Number) {
197: 			return ((Number) o).shortValue();
198: 		}
199: 		return Short.parseShort(o.toString());
200: 	}
201: 
202: 	public int getInt(int columnIndex) throws SQLException {
203: 		if (check_and_null(columnIndex)) {
204: 			return 0;
205: 		}
206: 		if ("INTEGER".equals(meta.column_types[columnIndex - 1])) {
207: 			return getbuf(columnIndex, 4).getInt();
208: 		}
209: 		Object o = getObject(columnIndex);
210: 		if (o instanceof Number) {
211: 			return ((Number) o).intValue();
212: 		}
213: 		return Integer.parseInt(o.toString());
214: 	}
215: 
216: 	public long getLong(int columnIndex) throws SQLException {
217: 		if (check_and_null(columnIndex)) {
218: 			return 0;
219: 		}
220: 		if ("BIGINT".equals(meta.column_types[columnIndex - 1])) {
221: 			return getbuf(columnIndex, 8).getLong();
222: 		}
223: 		Object o = getObject(columnIndex);
224: 		if (o instanceof Number) {
225: 			return ((Number) o).longValue();
226: 		}
227: 		return Long.parseLong(o.toString());
228: 	}
229: 
230: 	public float getFloat(int columnIndex) throws SQLException {
231: 		if (check_and_null(columnIndex)) {
232: 			return Float.NaN;
233: 		}
234: 		if ("FLOAT".equals(meta.column_types[columnIndex - 1])) {
235: 			return getbuf(columnIndex, 4).getFloat();
236: 		}
237: 		Object o = getObject(columnIndex);
238: 		if (o instanceof Number) {
239: 			return ((Number) o).floatValue();
240: 		}
241: 		return Float.parseFloat(o.toString());
242: 	}
243: 
244: 	public double getDouble(int columnIndex) throws SQLException {
245: 		if (check_and_null(columnIndex)) {
246: 			return Double.NaN;
247: 		}
248: 		if ("DOUBLE".equals(meta.column_types[columnIndex - 1])) {
249: 			return getbuf(columnIndex, 8).getDouble();
250: 		}
251: 		Object o = getObject(columnIndex);
252: 		if (o instanceof Number) {
253: 			return ((Number) o).doubleValue();
254: 		}
255: 		return Double.parseDouble(o.toString());
256: 	}
257: 
258: 	public int findColumn(String columnLabel) throws SQLException {
259: 		if (isClosed()) {
260: 			throw new SQLException("ResultSet was closed");
261: 		}
262: 		for (int col_idx = 0; col_idx < meta.column_count; col_idx++) {
263: 			if (meta.column_names[col_idx].contentEquals(columnLabel)) {
264: 				return col_idx + 1;
265: 			}
266: 		}
267: 		throw new SQLException("Could not find column with label " + columnLabel);
268: 	}
269: 
270: 	public String getString(String columnLabel) throws SQLException {
271: 		return getString(findColumn(columnLabel));
272: 	}
273: 
274: 	public boolean getBoolean(String columnLabel) throws SQLException {
275: 		return getBoolean(findColumn(columnLabel));
276: 	}
277: 
278: 	public byte getByte(String columnLabel) throws SQLException {
279: 		return getByte(findColumn(columnLabel));
280: 	}
281: 
282: 	public short getShort(String columnLabel) throws SQLException {
283: 		return getShort(findColumn(columnLabel));
284: 	}
285: 
286: 	public int getInt(String columnLabel) throws SQLException {
287: 		return getInt(findColumn(columnLabel));
288: 	}
289: 
290: 	public long getLong(String columnLabel) throws SQLException {
291: 		return getLong(findColumn(columnLabel));
292: 	}
293: 
294: 	public float getFloat(String columnLabel) throws SQLException {
295: 		return getFloat(findColumn(columnLabel));
296: 	}
297: 
298: 	public double getDouble(String columnLabel) throws SQLException {
299: 		return getDouble(findColumn(columnLabel));
300: 	}
301: 
302: 	public Object getObject(String columnLabel) throws SQLException {
303: 		return getObject(findColumn(columnLabel));
304: 	}
305: 
306: 	public BigDecimal getBigDecimal(int columnIndex, int scale) throws SQLException {
307: 		throw new SQLFeatureNotSupportedException();
308: 	}
309: 
310: 	public byte[] getBytes(int columnIndex) throws SQLException {
311: 		throw new SQLFeatureNotSupportedException();
312: 	}
313: 
314: 	public Date getDate(int columnIndex) throws SQLException {
315: 		throw new SQLFeatureNotSupportedException();
316: 	}
317: 
318: 	public Time getTime(int columnIndex) throws SQLException {
319: 		throw new SQLFeatureNotSupportedException();
320: 	}
321: 
322: 	public Timestamp getTimestamp(int columnIndex) throws SQLException {
323: 		throw new SQLFeatureNotSupportedException();
324: 	}
325: 
326: 	public InputStream getAsciiStream(int columnIndex) throws SQLException {
327: 		throw new SQLFeatureNotSupportedException();
328: 	}
329: 
330: 	public InputStream getUnicodeStream(int columnIndex) throws SQLException {
331: 		throw new SQLFeatureNotSupportedException();
332: 	}
333: 
334: 	public InputStream getBinaryStream(int columnIndex) throws SQLException {
335: 		throw new SQLFeatureNotSupportedException();
336: 	}
337: 
338: 	public BigDecimal getBigDecimal(String columnLabel, int scale) throws SQLException {
339: 		throw new SQLFeatureNotSupportedException();
340: 	}
341: 
342: 	public byte[] getBytes(String columnLabel) throws SQLException {
343: 		throw new SQLFeatureNotSupportedException();
344: 	}
345: 
346: 	public Date getDate(String columnLabel) throws SQLException {
347: 		throw new SQLFeatureNotSupportedException();
348: 	}
349: 
350: 	public Time getTime(String columnLabel) throws SQLException {
351: 		throw new SQLFeatureNotSupportedException();
352: 	}
353: 
354: 	public Timestamp getTimestamp(String columnLabel) throws SQLException {
355: 		throw new SQLFeatureNotSupportedException();
356: 	}
357: 
358: 	public InputStream getAsciiStream(String columnLabel) throws SQLException {
359: 		throw new SQLFeatureNotSupportedException();
360: 	}
361: 
362: 	public InputStream getUnicodeStream(String columnLabel) throws SQLException {
363: 		throw new SQLFeatureNotSupportedException();
364: 	}
365: 
366: 	public InputStream getBinaryStream(String columnLabel) throws SQLException {
367: 		throw new SQLFeatureNotSupportedException();
368: 	}
369: 
370: 	public SQLWarning getWarnings() throws SQLException {
371: 		throw new SQLFeatureNotSupportedException();
372: 	}
373: 
374: 	public void clearWarnings() throws SQLException {
375: 		throw new SQLFeatureNotSupportedException();
376: 	}
377: 
378: 	public String getCursorName() throws SQLException {
379: 		throw new SQLFeatureNotSupportedException();
380: 	}
381: 
382: 	public Reader getCharacterStream(int columnIndex) throws SQLException {
383: 		throw new SQLFeatureNotSupportedException();
384: 	}
385: 
386: 	public Reader getCharacterStream(String columnLabel) throws SQLException {
387: 		throw new SQLFeatureNotSupportedException();
388: 	}
389: 
390: 	public BigDecimal getBigDecimal(int columnIndex) throws SQLException {
391: 		throw new SQLFeatureNotSupportedException();
392: 	}
393: 
394: 	public BigDecimal getBigDecimal(String columnLabel) throws SQLException {
395: 		throw new SQLFeatureNotSupportedException();
396: 	}
397: 
398: 	public boolean isBeforeFirst() throws SQLException {
399: 		throw new SQLFeatureNotSupportedException();
400: 	}
401: 
402: 	public boolean isAfterLast() throws SQLException {
403: 		throw new SQLFeatureNotSupportedException();
404: 	}
405: 
406: 	public boolean isFirst() throws SQLException {
407: 		throw new SQLFeatureNotSupportedException();
408: 	}
409: 
410: 	public boolean isLast() throws SQLException {
411: 		throw new SQLFeatureNotSupportedException();
412: 	}
413: 
414: 	public void beforeFirst() throws SQLException {
415: 		throw new SQLFeatureNotSupportedException();
416: 	}
417: 
418: 	public void afterLast() throws SQLException {
419: 		throw new SQLFeatureNotSupportedException();
420: 	}
421: 
422: 	public boolean first() throws SQLException {
423: 		throw new SQLFeatureNotSupportedException();
424: 	}
425: 
426: 	public boolean last() throws SQLException {
427: 		throw new SQLFeatureNotSupportedException();
428: 	}
429: 
430: 	public int getRow() throws SQLException {
431: 		// TODO Auto-generated method stub
432: 		return 0;
433: 	}
434: 
435: 	public boolean absolute(int row) throws SQLException {
436: 		throw new SQLFeatureNotSupportedException();
437: 	}
438: 
439: 	public boolean relative(int rows) throws SQLException {
440: 		throw new SQLFeatureNotSupportedException();
441: 	}
442: 
443: 	public boolean previous() throws SQLException {
444: 		throw new SQLFeatureNotSupportedException();
445: 	}
446: 
447: 	public void setFetchDirection(int direction) throws SQLException {
448: 		throw new SQLFeatureNotSupportedException();
449: 	}
450: 
451: 	public int getFetchDirection() throws SQLException {
452: 		throw new SQLFeatureNotSupportedException();
453: 	}
454: 
455: 	public void setFetchSize(int rows) throws SQLException {
456: 		throw new SQLFeatureNotSupportedException();
457: 	}
458: 
459: 	public int getFetchSize() throws SQLException {
460: 		throw new SQLFeatureNotSupportedException();
461: 	}
462: 
463: 	public int getType() throws SQLException {
464: 		return ResultSet.TYPE_FORWARD_ONLY;
465: 	}
466: 
467: 	public int getConcurrency() throws SQLException {
468: 		throw new SQLFeatureNotSupportedException();
469: 	}
470: 
471: 	public boolean rowUpdated() throws SQLException {
472: 		throw new SQLFeatureNotSupportedException();
473: 	}
474: 
475: 	public boolean rowInserted() throws SQLException {
476: 		throw new SQLFeatureNotSupportedException();
477: 	}
478: 
479: 	public boolean rowDeleted() throws SQLException {
480: 		throw new SQLFeatureNotSupportedException();
481: 	}
482: 
483: 	public void updateNull(int columnIndex) throws SQLException {
484: 		throw new SQLFeatureNotSupportedException();
485: 	}
486: 
487: 	public void updateBoolean(int columnIndex, boolean x) throws SQLException {
488: 		throw new SQLFeatureNotSupportedException();
489: 	}
490: 
491: 	public void updateByte(int columnIndex, byte x) throws SQLException {
492: 		throw new SQLFeatureNotSupportedException();
493: 	}
494: 
495: 	public void updateShort(int columnIndex, short x) throws SQLException {
496: 		throw new SQLFeatureNotSupportedException();
497: 	}
498: 
499: 	public void updateInt(int columnIndex, int x) throws SQLException {
500: 		throw new SQLFeatureNotSupportedException();
501: 	}
502: 
503: 	public void updateLong(int columnIndex, long x) throws SQLException {
504: 		throw new SQLFeatureNotSupportedException();
505: 	}
506: 
507: 	public void updateFloat(int columnIndex, float x) throws SQLException {
508: 		throw new SQLFeatureNotSupportedException();
509: 	}
510: 
511: 	public void updateDouble(int columnIndex, double x) throws SQLException {
512: 		throw new SQLFeatureNotSupportedException();
513: 	}
514: 
515: 	public void updateBigDecimal(int columnIndex, BigDecimal x) throws SQLException {
516: 		throw new SQLFeatureNotSupportedException();
517: 	}
518: 
519: 	public void updateString(int columnIndex, String x) throws SQLException {
520: 		throw new SQLFeatureNotSupportedException();
521: 	}
522: 
523: 	public void updateBytes(int columnIndex, byte[] x) throws SQLException {
524: 		throw new SQLFeatureNotSupportedException();
525: 	}
526: 
527: 	public void updateDate(int columnIndex, Date x) throws SQLException {
528: 		throw new SQLFeatureNotSupportedException();
529: 	}
530: 
531: 	public void updateTime(int columnIndex, Time x) throws SQLException {
532: 		throw new SQLFeatureNotSupportedException();
533: 	}
534: 
535: 	public void updateTimestamp(int columnIndex, Timestamp x) throws SQLException {
536: 		throw new SQLFeatureNotSupportedException();
537: 	}
538: 
539: 	public void updateAsciiStream(int columnIndex, InputStream x, int length) throws SQLException {
540: 		throw new SQLFeatureNotSupportedException();
541: 	}
542: 
543: 	public void updateBinaryStream(int columnIndex, InputStream x, int length) throws SQLException {
544: 		throw new SQLFeatureNotSupportedException();
545: 	}
546: 
547: 	public void updateCharacterStream(int columnIndex, Reader x, int length) throws SQLException {
548: 		throw new SQLFeatureNotSupportedException();
549: 	}
550: 
551: 	public void updateObject(int columnIndex, Object x, int scaleOrLength) throws SQLException {
552: 		throw new SQLFeatureNotSupportedException();
553: 	}
554: 
555: 	public void updateObject(int columnIndex, Object x) throws SQLException {
556: 		throw new SQLFeatureNotSupportedException();
557: 	}
558: 
559: 	public void updateNull(String columnLabel) throws SQLException {
560: 		throw new SQLFeatureNotSupportedException();
561: 	}
562: 
563: 	public void updateBoolean(String columnLabel, boolean x) throws SQLException {
564: 		throw new SQLFeatureNotSupportedException();
565: 	}
566: 
567: 	public void updateByte(String columnLabel, byte x) throws SQLException {
568: 		throw new SQLFeatureNotSupportedException();
569: 	}
570: 
571: 	public void updateShort(String columnLabel, short x) throws SQLException {
572: 		throw new SQLFeatureNotSupportedException();
573: 	}
574: 
575: 	public void updateInt(String columnLabel, int x) throws SQLException {
576: 		throw new SQLFeatureNotSupportedException();
577: 	}
578: 
579: 	public void updateLong(String columnLabel, long x) throws SQLException {
580: 		throw new SQLFeatureNotSupportedException();
581: 	}
582: 
583: 	public void updateFloat(String columnLabel, float x) throws SQLException {
584: 		throw new SQLFeatureNotSupportedException();
585: 	}
586: 
587: 	public void updateDouble(String columnLabel, double x) throws SQLException {
588: 		throw new SQLFeatureNotSupportedException();
589: 	}
590: 
591: 	public void updateBigDecimal(String columnLabel, BigDecimal x) throws SQLException {
592: 		throw new SQLFeatureNotSupportedException();
593: 	}
594: 
595: 	public void updateString(String columnLabel, String x) throws SQLException {
596: 		throw new SQLFeatureNotSupportedException();
597: 	}
598: 
599: 	public void updateBytes(String columnLabel, byte[] x) throws SQLException {
600: 		throw new SQLFeatureNotSupportedException();
601: 	}
602: 
603: 	public void updateDate(String columnLabel, Date x) throws SQLException {
604: 		throw new SQLFeatureNotSupportedException();
605: 	}
606: 
607: 	public void updateTime(String columnLabel, Time x) throws SQLException {
608: 		throw new SQLFeatureNotSupportedException();
609: 	}
610: 
611: 	public void updateTimestamp(String columnLabel, Timestamp x) throws SQLException {
612: 		throw new SQLFeatureNotSupportedException();
613: 	}
614: 
615: 	public void updateAsciiStream(String columnLabel, InputStream x, int length) throws SQLException {
616: 		throw new SQLFeatureNotSupportedException();
617: 	}
618: 
619: 	public void updateBinaryStream(String columnLabel, InputStream x, int length) throws SQLException {
620: 		throw new SQLFeatureNotSupportedException();
621: 	}
622: 
623: 	public void updateCharacterStream(String columnLabel, Reader reader, int length) throws SQLException {
624: 		throw new SQLFeatureNotSupportedException();
625: 	}
626: 
627: 	public void updateObject(String columnLabel, Object x, int scaleOrLength) throws SQLException {
628: 		throw new SQLFeatureNotSupportedException();
629: 	}
630: 
631: 	public void updateObject(String columnLabel, Object x) throws SQLException {
632: 		throw new SQLFeatureNotSupportedException();
633: 	}
634: 
635: 	public void insertRow() throws SQLException {
636: 		throw new SQLFeatureNotSupportedException();
637: 	}
638: 
639: 	public void updateRow() throws SQLException {
640: 		throw new SQLFeatureNotSupportedException();
641: 	}
642: 
643: 	public void deleteRow() throws SQLException {
644: 		throw new SQLFeatureNotSupportedException();
645: 	}
646: 
647: 	public void refreshRow() throws SQLException {
648: 		throw new SQLFeatureNotSupportedException();
649: 	}
650: 
651: 	public void cancelRowUpdates() throws SQLException {
652: 		throw new SQLFeatureNotSupportedException();
653: 	}
654: 
655: 	public void moveToInsertRow() throws SQLException {
656: 		throw new SQLFeatureNotSupportedException();
657: 	}
658: 
659: 	public void moveToCurrentRow() throws SQLException {
660: 		throw new SQLFeatureNotSupportedException();
661: 	}
662: 
663: 	public Object getObject(int columnIndex, Map<String, Class<?>> map) throws SQLException {
664: 		throw new SQLFeatureNotSupportedException();
665: 	}
666: 
667: 	public Ref getRef(int columnIndex) throws SQLException {
668: 		throw new SQLFeatureNotSupportedException();
669: 	}
670: 
671: 	public Blob getBlob(int columnIndex) throws SQLException {
672: 		throw new SQLFeatureNotSupportedException();
673: 	}
674: 
675: 	public Clob getClob(int columnIndex) throws SQLException {
676: 		throw new SQLFeatureNotSupportedException();
677: 	}
678: 
679: 	public Array getArray(int columnIndex) throws SQLException {
680: 		throw new SQLFeatureNotSupportedException();
681: 	}
682: 
683: 	public Object getObject(String columnLabel, Map<String, Class<?>> map) throws SQLException {
684: 		throw new SQLFeatureNotSupportedException();
685: 	}
686: 
687: 	public Ref getRef(String columnLabel) throws SQLException {
688: 		throw new SQLFeatureNotSupportedException();
689: 	}
690: 
691: 	public Blob getBlob(String columnLabel) throws SQLException {
692: 		throw new SQLFeatureNotSupportedException();
693: 	}
694: 
695: 	public Clob getClob(String columnLabel) throws SQLException {
696: 		throw new SQLFeatureNotSupportedException();
697: 	}
698: 
699: 	public Array getArray(String columnLabel) throws SQLException {
700: 		throw new SQLFeatureNotSupportedException();
701: 	}
702: 
703: 	public Date getDate(int columnIndex, Calendar cal) throws SQLException {
704: 		throw new SQLFeatureNotSupportedException();
705: 	}
706: 
707: 	public Date getDate(String columnLabel, Calendar cal) throws SQLException {
708: 		throw new SQLFeatureNotSupportedException();
709: 	}
710: 
711: 	public Time getTime(int columnIndex, Calendar cal) throws SQLException {
712: 		throw new SQLFeatureNotSupportedException();
713: 	}
714: 
715: 	public Time getTime(String columnLabel, Calendar cal) throws SQLException {
716: 		throw new SQLFeatureNotSupportedException();
717: 	}
718: 
719: 	public Timestamp getTimestamp(int columnIndex, Calendar cal) throws SQLException {
720: 		throw new SQLFeatureNotSupportedException();
721: 	}
722: 
723: 	public Timestamp getTimestamp(String columnLabel, Calendar cal) throws SQLException {
724: 		throw new SQLFeatureNotSupportedException();
725: 	}
726: 
727: 	public URL getURL(int columnIndex) throws SQLException {
728: 		throw new SQLFeatureNotSupportedException();
729: 	}
730: 
731: 	public URL getURL(String columnLabel) throws SQLException {
732: 		throw new SQLFeatureNotSupportedException();
733: 	}
734: 
735: 	public void updateRef(int columnIndex, Ref x) throws SQLException {
736: 		throw new SQLFeatureNotSupportedException();
737: 	}
738: 
739: 	public void updateRef(String columnLabel, Ref x) throws SQLException {
740: 		throw new SQLFeatureNotSupportedException();
741: 	}
742: 
743: 	public void updateBlob(int columnIndex, Blob x) throws SQLException {
744: 		throw new SQLFeatureNotSupportedException();
745: 	}
746: 
747: 	public void updateBlob(String columnLabel, Blob x) throws SQLException {
748: 		throw new SQLFeatureNotSupportedException();
749: 	}
750: 
751: 	public void updateClob(int columnIndex, Clob x) throws SQLException {
752: 		throw new SQLFeatureNotSupportedException();
753: 	}
754: 
755: 	public void updateClob(String columnLabel, Clob x) throws SQLException {
756: 		throw new SQLFeatureNotSupportedException();
757: 	}
758: 
759: 	public void updateArray(int columnIndex, Array x) throws SQLException {
760: 		throw new SQLFeatureNotSupportedException();
761: 	}
762: 
763: 	public void updateArray(String columnLabel, Array x) throws SQLException {
764: 		throw new SQLFeatureNotSupportedException();
765: 	}
766: 
767: 	public RowId getRowId(int columnIndex) throws SQLException {
768: 		throw new SQLFeatureNotSupportedException();
769: 	}
770: 
771: 	public RowId getRowId(String columnLabel) throws SQLException {
772: 		throw new SQLFeatureNotSupportedException();
773: 	}
774: 
775: 	public void updateRowId(int columnIndex, RowId x) throws SQLException {
776: 		throw new SQLFeatureNotSupportedException();
777: 	}
778: 
779: 	public void updateRowId(String columnLabel, RowId x) throws SQLException {
780: 		throw new SQLFeatureNotSupportedException();
781: 	}
782: 
783: 	public int getHoldability() throws SQLException {
784: 		throw new SQLFeatureNotSupportedException();
785: 	}
786: 
787: 	public void updateNString(int columnIndex, String nString) throws SQLException {
788: 		throw new SQLFeatureNotSupportedException();
789: 	}
790: 
791: 	public void updateNString(String columnLabel, String nString) throws SQLException {
792: 		throw new SQLFeatureNotSupportedException();
793: 	}
794: 
795: 	public void updateNClob(int columnIndex, NClob nClob) throws SQLException {
796: 		throw new SQLFeatureNotSupportedException();
797: 	}
798: 
799: 	public void updateNClob(String columnLabel, NClob nClob) throws SQLException {
800: 		throw new SQLFeatureNotSupportedException();
801: 	}
802: 
803: 	public NClob getNClob(int columnIndex) throws SQLException {
804: 		throw new SQLFeatureNotSupportedException();
805: 	}
806: 
807: 	public NClob getNClob(String columnLabel) throws SQLException {
808: 		throw new SQLFeatureNotSupportedException();
809: 	}
810: 
811: 	public SQLXML getSQLXML(int columnIndex) throws SQLException {
812: 		throw new SQLFeatureNotSupportedException();
813: 	}
814: 
815: 	public SQLXML getSQLXML(String columnLabel) throws SQLException {
816: 		throw new SQLFeatureNotSupportedException();
817: 	}
818: 
819: 	public void updateSQLXML(int columnIndex, SQLXML xmlObject) throws SQLException {
820: 		throw new SQLFeatureNotSupportedException();
821: 	}
822: 
823: 	public void updateSQLXML(String columnLabel, SQLXML xmlObject) throws SQLException {
824: 		throw new SQLFeatureNotSupportedException();
825: 	}
826: 
827: 	public String getNString(int columnIndex) throws SQLException {
828: 		throw new SQLFeatureNotSupportedException();
829: 	}
830: 
831: 	public String getNString(String columnLabel) throws SQLException {
832: 		throw new SQLFeatureNotSupportedException();
833: 	}
834: 
835: 	public Reader getNCharacterStream(int columnIndex) throws SQLException {
836: 		throw new SQLFeatureNotSupportedException();
837: 	}
838: 
839: 	public Reader getNCharacterStream(String columnLabel) throws SQLException {
840: 		throw new SQLFeatureNotSupportedException();
841: 	}
842: 
843: 	public void updateNCharacterStream(int columnIndex, Reader x, long length) throws SQLException {
844: 		throw new SQLFeatureNotSupportedException();
845: 	}
846: 
847: 	public void updateNCharacterStream(String columnLabel, Reader reader, long length) throws SQLException {
848: 		throw new SQLFeatureNotSupportedException();
849: 	}
850: 
851: 	public void updateAsciiStream(int columnIndex, InputStream x, long length) throws SQLException {
852: 		throw new SQLFeatureNotSupportedException();
853: 	}
854: 
855: 	public void updateBinaryStream(int columnIndex, InputStream x, long length) throws SQLException {
856: 		throw new SQLFeatureNotSupportedException();
857: 	}
858: 
859: 	public void updateCharacterStream(int columnIndex, Reader x, long length) throws SQLException {
860: 		throw new SQLFeatureNotSupportedException();
861: 	}
862: 
863: 	public void updateAsciiStream(String columnLabel, InputStream x, long length) throws SQLException {
864: 		throw new SQLFeatureNotSupportedException();
865: 	}
866: 
867: 	public void updateBinaryStream(String columnLabel, InputStream x, long length) throws SQLException {
868: 		throw new SQLFeatureNotSupportedException();
869: 	}
870: 
871: 	public void updateCharacterStream(String columnLabel, Reader reader, long length) throws SQLException {
872: 		throw new SQLFeatureNotSupportedException();
873: 	}
874: 
875: 	public void updateBlob(int columnIndex, InputStream inputStream, long length) throws SQLException {
876: 		throw new SQLFeatureNotSupportedException();
877: 	}
878: 
879: 	public void updateBlob(String columnLabel, InputStream inputStream, long length) throws SQLException {
880: 		throw new SQLFeatureNotSupportedException();
881: 	}
882: 
883: 	public void updateClob(int columnIndex, Reader reader, long length) throws SQLException {
884: 		throw new SQLFeatureNotSupportedException();
885: 	}
886: 
887: 	public void updateClob(String columnLabel, Reader reader, long length) throws SQLException {
888: 		throw new SQLFeatureNotSupportedException();
889: 	}
890: 
891: 	public void updateNClob(int columnIndex, Reader reader, long length) throws SQLException {
892: 		throw new SQLFeatureNotSupportedException();
893: 	}
894: 
895: 	public void updateNClob(String columnLabel, Reader reader, long length) throws SQLException {
896: 		throw new SQLFeatureNotSupportedException();
897: 	}
898: 
899: 	public void updateNCharacterStream(int columnIndex, Reader x) throws SQLException {
900: 		throw new SQLFeatureNotSupportedException();
901: 	}
902: 
903: 	public void updateNCharacterStream(String columnLabel, Reader reader) throws SQLException {
904: 		throw new SQLFeatureNotSupportedException();
905: 	}
906: 
907: 	public void updateAsciiStream(int columnIndex, InputStream x) throws SQLException {
908: 		throw new SQLFeatureNotSupportedException();
909: 	}
910: 
911: 	public void updateBinaryStream(int columnIndex, InputStream x) throws SQLException {
912: 		throw new SQLFeatureNotSupportedException();
913: 	}
914: 
915: 	public void updateCharacterStream(int columnIndex, Reader x) throws SQLException {
916: 		throw new SQLFeatureNotSupportedException();
917: 	}
918: 
919: 	public void updateAsciiStream(String columnLabel, InputStream x) throws SQLException {
920: 		throw new SQLFeatureNotSupportedException();
921: 	}
922: 
923: 	public void updateBinaryStream(String columnLabel, InputStream x) throws SQLException {
924: 		throw new SQLFeatureNotSupportedException();
925: 	}
926: 
927: 	public void updateCharacterStream(String columnLabel, Reader reader) throws SQLException {
928: 		throw new SQLFeatureNotSupportedException();
929: 	}
930: 
931: 	public void updateBlob(int columnIndex, InputStream inputStream) throws SQLException {
932: 		throw new SQLFeatureNotSupportedException();
933: 	}
934: 
935: 	public void updateBlob(String columnLabel, InputStream inputStream) throws SQLException {
936: 		throw new SQLFeatureNotSupportedException();
937: 	}
938: 
939: 	public void updateClob(int columnIndex, Reader reader) throws SQLException {
940: 		throw new SQLFeatureNotSupportedException();
941: 	}
942: 
943: 	public void updateClob(String columnLabel, Reader reader) throws SQLException {
944: 		throw new SQLFeatureNotSupportedException();
945: 	}
946: 
947: 	public void updateNClob(int columnIndex, Reader reader) throws SQLException {
948: 		throw new SQLFeatureNotSupportedException();
949: 	}
950: 
951: 	public void updateNClob(String columnLabel, Reader reader) throws SQLException {
952: 		throw new SQLFeatureNotSupportedException();
953: 	}
954: 
955: 	public <T> T getObject(int columnIndex, Class<T> type) throws SQLException {
956: 		throw new SQLFeatureNotSupportedException();
957: 	}
958: 
959: 	public <T> T getObject(String columnLabel, Class<T> type) throws SQLException {
960: 		throw new SQLFeatureNotSupportedException();
961: 	}
962: 
963: 	public <T> T unwrap(Class<T> iface) throws SQLException {
964: 		throw new SQLFeatureNotSupportedException();
965: 	}
966: 
967: 	public boolean isWrapperFor(Class<?> iface) throws SQLException {
968: 		throw new SQLFeatureNotSupportedException();
969: 	}
970: 
971: }
[end of tools/jdbc/src/main/java/nl/cwi/da/duckdb/DuckDBResultSet.java]
[start of tools/jdbc/src/main/java/nl/cwi/da/duckdb/DuckDBStatement.java]
1: package nl.cwi.da.duckdb;
2: 
3: import java.nio.ByteBuffer;
4: import java.sql.Connection;
5: import java.sql.ResultSet;
6: import java.sql.SQLException;
7: import java.sql.SQLFeatureNotSupportedException;
8: import java.sql.SQLWarning;
9: import java.sql.Statement;
10: 
11: public class DuckDBStatement implements Statement {
12: 
13: 	private DuckDBConnection conn;
14: 	private DuckDBResultSet result = null;
15: 	private ByteBuffer stmt_ref = null;
16: 
17: 	public DuckDBStatement(DuckDBConnection conn) {
18: 		this.conn = conn;
19: 	}
20: 
21: 	public boolean execute(String sql) throws SQLException {
22: 		stmt_ref = DuckDBNative.duckdb_jdbc_prepare(conn.conn_ref, sql);
23: 		Object[] params = {};
24: 		ByteBuffer result_ref = DuckDBNative.duckdb_jdbc_execute(stmt_ref, params);
25: 		result = new DuckDBResultSet(this, result_ref);
26: 		return true;
27: 	}
28: 
29: 	public ResultSet getResultSet() throws SQLException {
30: 		if (result == null) {
31: 			throw new SQLException("No result set. execute() a query first");
32: 		}
33: 		if (isClosed()) {
34: 			throw new SQLException("Statement was closed");
35: 		}
36: 		return result;
37: 	}
38: 
39: 	public ResultSet executeQuery(String sql) throws SQLException {
40: 		execute(sql);
41: 		return getResultSet();
42: 	}
43: 
44: 	public int executeUpdate(String sql) throws SQLException {
45: 		execute(sql);
46: 		int affected = result.getInt(0);
47: 		result.close();
48: 		return affected;
49: 	}
50: 
51: 	public void close() throws SQLException {
52: 		if (stmt_ref != null) {
53: 			DuckDBNative.duckdb_jdbc_release(stmt_ref);
54: 			stmt_ref = null;
55: 		}
56: 		conn = null;
57: 	}
58: 
59: 	public boolean isClosed() throws SQLException {
60: 		return stmt_ref == null;
61: 	}
62: 
63: 	public Connection getConnection() throws SQLException {
64: 		if (isClosed()) {
65: 			throw new SQLException("Statement was closed");
66: 		}
67: 		return conn;
68: 	}
69: 
70: 	public SQLWarning getWarnings() throws SQLException {
71: 		return null;
72: 	}
73: 
74: 	public void clearWarnings() throws SQLException {
75: 	}
76: 
77: 	public <T> T unwrap(Class<T> iface) throws SQLException {
78: 		throw new SQLFeatureNotSupportedException();
79: 	}
80: 
81: 	public boolean isWrapperFor(Class<?> iface) throws SQLException {
82: 		throw new SQLFeatureNotSupportedException();
83: 	}
84: 
85: 	public int getMaxFieldSize() throws SQLException {
86: 		throw new SQLFeatureNotSupportedException();
87: 	}
88: 
89: 	public void setMaxFieldSize(int max) throws SQLException {
90: 		throw new SQLFeatureNotSupportedException();
91: 	}
92: 
93: 	public int getMaxRows() throws SQLException {
94: 		throw new SQLFeatureNotSupportedException();
95: 	}
96: 
97: 	public void setMaxRows(int max) throws SQLException {
98: 		throw new SQLFeatureNotSupportedException();
99: 	}
100: 
101: 	public void setEscapeProcessing(boolean enable) throws SQLException {
102: 		throw new SQLFeatureNotSupportedException();
103: 	}
104: 
105: 	public int getQueryTimeout() throws SQLException {
106: 		throw new SQLFeatureNotSupportedException();
107: 	}
108: 
109: 	public void setQueryTimeout(int seconds) throws SQLException {
110: 		throw new SQLFeatureNotSupportedException();
111: 	}
112: 
113: 	public void cancel() throws SQLException {
114: 		throw new SQLFeatureNotSupportedException();
115: 	}
116: 
117: 	public void setCursorName(String name) throws SQLException {
118: 		throw new SQLFeatureNotSupportedException();
119: 	}
120: 
121: 	public int getUpdateCount() throws SQLException {
122: 		throw new SQLFeatureNotSupportedException();
123: 	}
124: 
125: 	public boolean getMoreResults() throws SQLException {
126: 		return false;
127: 	}
128: 
129: 	public void setFetchDirection(int direction) throws SQLException {
130: 		throw new SQLFeatureNotSupportedException();
131: 	}
132: 
133: 	public int getFetchDirection() throws SQLException {
134: 		throw new SQLFeatureNotSupportedException();
135: 	}
136: 
137: 	public void setFetchSize(int rows) throws SQLException {
138: 		throw new SQLFeatureNotSupportedException();
139: 	}
140: 
141: 	public int getFetchSize() throws SQLException {
142: 		throw new SQLFeatureNotSupportedException();
143: 	}
144: 
145: 	public int getResultSetConcurrency() throws SQLException {
146: 		throw new SQLFeatureNotSupportedException();
147: 	}
148: 
149: 	public int getResultSetType() throws SQLException {
150: 		throw new SQLFeatureNotSupportedException();
151: 	}
152: 
153: 	public void addBatch(String sql) throws SQLException {
154: 		throw new SQLFeatureNotSupportedException();
155: 	}
156: 
157: 	public void clearBatch() throws SQLException {
158: 		throw new SQLFeatureNotSupportedException();
159: 	}
160: 
161: 	public int[] executeBatch() throws SQLException {
162: 		throw new SQLFeatureNotSupportedException();
163: 	}
164: 
165: 	public boolean getMoreResults(int current) throws SQLException {
166: 		return false;
167: 	}
168: 
169: 	public ResultSet getGeneratedKeys() throws SQLException {
170: 		throw new SQLFeatureNotSupportedException();
171: 	}
172: 
173: 	public int executeUpdate(String sql, int autoGeneratedKeys) throws SQLException {
174: 		throw new SQLFeatureNotSupportedException();
175: 	}
176: 
177: 	public int executeUpdate(String sql, int[] columnIndexes) throws SQLException {
178: 		throw new SQLFeatureNotSupportedException();
179: 	}
180: 
181: 	public int executeUpdate(String sql, String[] columnNames) throws SQLException {
182: 		throw new SQLFeatureNotSupportedException();
183: 	}
184: 
185: 	public boolean execute(String sql, int autoGeneratedKeys) throws SQLException {
186: 		throw new SQLFeatureNotSupportedException();
187: 	}
188: 
189: 	public boolean execute(String sql, int[] columnIndexes) throws SQLException {
190: 		throw new SQLFeatureNotSupportedException();
191: 	}
192: 
193: 	public boolean execute(String sql, String[] columnNames) throws SQLException {
194: 		throw new SQLFeatureNotSupportedException();
195: 	}
196: 
197: 	public int getResultSetHoldability() throws SQLException {
198: 		throw new SQLFeatureNotSupportedException();
199: 	}
200: 
201: 	public void setPoolable(boolean poolable) throws SQLException {
202: 		throw new SQLFeatureNotSupportedException();
203: 	}
204: 
205: 	public boolean isPoolable() throws SQLException {
206: 		throw new SQLFeatureNotSupportedException();
207: 	}
208: 
209: 	public void closeOnCompletion() throws SQLException {
210: 		throw new SQLFeatureNotSupportedException();
211: 	}
212: 
213: 	public boolean isCloseOnCompletion() throws SQLException {
214: 		throw new SQLFeatureNotSupportedException();
215: 	}
216: 
217: }
[end of tools/jdbc/src/main/java/nl/cwi/da/duckdb/DuckDBStatement.java]
[start of tools/sqlite3_api_wrapper/sqlite3_api_wrapper.cpp]
1: #include "sqlite3.h"
2: 
3: #include <ctype.h>
4: #include <duckdb.hpp>
5: #include <stdio.h>
6: #include <stdlib.h>
7: #include <string.h>
8: #include <time.h>
9: #include <string>
10: #include <chrono>
11: 
12: using namespace duckdb;
13: using namespace std;
14: 
15: #define SOURCE_ID DUCKDB_SOURCE_ID
16: #define LIB_VERSION "DuckDB"
17: 
18: static char *sqlite3_strdup(const char *str);
19: 
20: struct sqlite3_string_buffer {
21: 	//! String data
22: 	unique_ptr<char[]> data;
23: };
24: 
25: struct sqlite3_stmt {
26: 	//! The DB object that this statement belongs to
27: 	sqlite3 *db;
28: 	//! The query string
29: 	string query_string;
30: 	//! The prepared statement object, if successfully prepared
31: 	unique_ptr<PreparedStatement> prepared;
32: 	//! The result object, if successfully executed
33: 	unique_ptr<QueryResult> result;
34: 	//! The current chunk that we are iterating over
35: 	unique_ptr<DataChunk> current_chunk;
36: 	//! The current row into the current chunk that we are iterating over
37: 	int64_t current_row;
38: 	//! Bound values, used for binding to the prepared statement
39: 	vector<Value> bound_values;
40: 	//! Names of the prepared parameters
41: 	vector<string> bound_names;
42: 	//! The current column values converted to string, used and filled by sqlite3_column_text
43: 	unique_ptr<sqlite3_string_buffer[]> current_text;
44: };
45: 
46: struct sqlite3 {
47: 	unique_ptr<DuckDB> db;
48: 	unique_ptr<Connection> con;
49: 	string last_error;
50: };
51: 
52: void sqlite3_randomness(int N, void *pBuf) {
53: 	static bool init = false;
54: 	if (!init) {
55: 		srand(time(NULL));
56: 		init = true;
57: 	}
58: 	unsigned char *zBuf = (unsigned char *)pBuf;
59: 	while (N--) {
60: 		unsigned char nextByte = rand() % 255;
61: 		zBuf[N] = nextByte;
62: 	}
63: }
64: 
65: int sqlite3_open(const char *filename, /* Database filename (UTF-8) */
66:                  sqlite3 **ppDb        /* OUT: SQLite db handle */
67: ) {
68: 	if (filename && strcmp(filename, ":memory:") == 0) {
69: 		filename = NULL;
70: 	}
71: 	*ppDb = nullptr;
72: 
73: 	sqlite3 *pDb = nullptr;
74: 	try {
75: 		pDb = new sqlite3();
76: 		pDb->db = make_unique<DuckDB>(filename);
77: 		pDb->con = make_unique<Connection>(*pDb->db);
78: 	} catch (std::exception &ex) {
79: 		if (pDb) {
80: 			pDb->last_error = ex.what();
81: 		}
82: 		return SQLITE_ERROR;
83: 	}
84: 	*ppDb = pDb;
85: 	return SQLITE_OK;
86: }
87: 
88: int sqlite3_open_v2(const char *filename, /* Database filename (UTF-8) */
89:                     sqlite3 **ppDb,       /* OUT: SQLite db handle */
90:                     int flags,            /* Flags */
91:                     const char *zVfs      /* Name of VFS module to use */
92: ) {
93: 	return sqlite3_open(filename, ppDb);
94: }
95: 
96: int sqlite3_close(sqlite3 *db) {
97: 	if (db) {
98: 		delete db;
99: 	}
100: 	return SQLITE_OK;
101: }
102: 
103: int sqlite3_shutdown(void) {
104: 	return SQLITE_OK;
105: }
106: 
107: /* In SQLite this function compiles the query into VDBE bytecode,
108:  * in the implementation it currently executes the query */
109: // TODO: prepare the statement instead of executing right away
110: int sqlite3_prepare_v2(sqlite3 *db,           /* Database handle */
111:                        const char *zSql,      /* SQL statement, UTF-8 encoded */
112:                        int nByte,             /* Maximum length of zSql in bytes. */
113:                        sqlite3_stmt **ppStmt, /* OUT: Statement handle */
114:                        const char **pzTail    /* OUT: Pointer to unused portion of zSql */
115: ) {
116: 	if (!db || !ppStmt || !zSql) {
117: 		return SQLITE_MISUSE;
118: 	}
119: 	*ppStmt = nullptr;
120: 	string query = nByte < 0 ? zSql : string(zSql, nByte);
121: 	if (pzTail) {
122: 		*pzTail = zSql + query.size();
123: 	}
124: 
125: 	try {
126: 		// extract the statements from the SQL query
127: 		auto statements = db->con->ExtractStatements(query);
128: 		if (statements.size() == 0) {
129: 			// no statements to prepare!
130: 			return SQLITE_OK;
131: 		}
132: 
133: 		// extract the first statement
134: 		auto statement = statements[0].get();
135: 		// extract the remainder
136: 		bool set_remainder = statement->stmt_location + statement->stmt_length < query.size();
137: 		query = query.substr(statement->stmt_location, statement->stmt_length);
138: 
139: 		// now prepare the query
140: 		auto prepared = db->con->Prepare(query);
141: 		if (!prepared->success) {
142: 			// failed to prepare: set the error message
143: 			db->last_error = prepared->error;
144: 			return SQLITE_ERROR;
145: 		}
146: 
147: 		// create the statement entry
148: 		unique_ptr<sqlite3_stmt> stmt = make_unique<sqlite3_stmt>();
149: 		stmt->db = db;
150: 		stmt->query_string = query;
151: 		stmt->prepared = move(prepared);
152: 		stmt->current_row = -1;
153: 		for (idx_t i = 0; i < stmt->prepared->n_param; i++) {
154: 			stmt->bound_names.push_back("$" + to_string(i + 1));
155: 			stmt->bound_values.push_back(Value());
156: 		}
157: 
158: 		// extract the remainder of the query and assign it to the pzTail
159: 		if (pzTail && set_remainder) {
160: 			*pzTail = zSql + query.size() + 1;
161: 		}
162: 
163: 		*ppStmt = stmt.release();
164: 		return SQLITE_OK;
165: 	} catch (std::exception &ex) {
166: 		db->last_error = ex.what();
167: 		return SQLITE_ERROR;
168: 	}
169: }
170: 
171: bool sqlite3_display_result(StatementType type) {
172: 	switch (type) {
173: 	case StatementType::EXECUTE:
174: 	case StatementType::EXPLAIN:
175: 	case StatementType::SELECT:
176: 		return true;
177: 	default:
178: 		return false;
179: 	}
180: }
181: 
182: /* Prepare the next result to be retrieved */
183: int sqlite3_step(sqlite3_stmt *pStmt) {
184: 	if (!pStmt) {
185: 		return SQLITE_MISUSE;
186: 	}
187: 	if (!pStmt->prepared) {
188: 		pStmt->db->last_error = "Attempting sqlite3_step() on a non-successfully prepared statement";
189: 		return SQLITE_ERROR;
190: 	}
191: 	pStmt->current_text = nullptr;
192: 	if (!pStmt->result) {
193: 		// no result yet! call Execute()
194: 		pStmt->result = pStmt->prepared->Execute(pStmt->bound_values);
195: 		if (!pStmt->result->success) {
196: 			// error in execute: clear prepared statement
197: 			pStmt->db->last_error = pStmt->result->error;
198: 			pStmt->prepared = nullptr;
199: 			return SQLITE_ERROR;
200: 		}
201: 		// fetch a chunk
202: 		pStmt->current_chunk = pStmt->result->Fetch();
203: 		pStmt->current_row = -1;
204: 		if (!sqlite3_display_result(pStmt->prepared->type)) {
205: 			// only SELECT statements return results
206: 			sqlite3_reset(pStmt);
207: 		}
208: 	}
209: 	if (!pStmt->current_chunk) {
210: 		return SQLITE_DONE;
211: 	}
212: 	pStmt->current_row++;
213: 	if (pStmt->current_row >= (int32_t)pStmt->current_chunk->size()) {
214: 		// have to fetch again!
215: 		pStmt->current_row = 0;
216: 		pStmt->current_chunk = pStmt->result->Fetch();
217: 		if (!pStmt->current_chunk || pStmt->current_chunk->size() == 0) {
218: 			sqlite3_reset(pStmt);
219: 			return SQLITE_DONE;
220: 		}
221: 	}
222: 	return SQLITE_ROW;
223: }
224: 
225: /* Execute multiple semicolon separated SQL statements
226:  * and execute the passed callback for each produced result,
227:  * largely copied from the original sqlite3 source */
228: int sqlite3_exec(sqlite3 *db,                /* The database on which the SQL executes */
229:                  const char *zSql,           /* The SQL to be executed */
230:                  sqlite3_callback xCallback, /* Invoke this callback routine */
231:                  void *pArg,                 /* First argument to xCallback() */
232:                  char **pzErrMsg             /* Write error messages here */
233: ) {
234: 	int rc = SQLITE_OK;            /* Return code */
235: 	const char *zLeftover;         /* Tail of unprocessed SQL */
236: 	sqlite3_stmt *pStmt = nullptr; /* The current SQL statement */
237: 	char **azCols = nullptr;       /* Names of result columns */
238: 	char **azVals = nullptr;       /* Result values */
239: 
240: 	if (zSql == nullptr) {
241: 		zSql = "";
242: 	}
243: 
244: 	while (rc == SQLITE_OK && zSql[0]) {
245: 		int nCol;
246: 
247: 		pStmt = nullptr;
248: 		rc = sqlite3_prepare_v2(db, zSql, -1, &pStmt, &zLeftover);
249: 		if (rc != SQLITE_OK) {
250: 			if (pzErrMsg) {
251: 				auto errmsg = sqlite3_errmsg(db);
252: 				*pzErrMsg = errmsg ? sqlite3_strdup(errmsg) : nullptr;
253: 			}
254: 			continue;
255: 		}
256: 		if (!pStmt) {
257: 			/* this happens for a comment or white-space */
258: 			zSql = zLeftover;
259: 			continue;
260: 		}
261: 
262: 		nCol = sqlite3_column_count(pStmt);
263: 		azCols = (char **)malloc(nCol * sizeof(const char *));
264: 		azVals = (char **)malloc(nCol * sizeof(const char *));
265: 		if (!azCols || !azVals) {
266: 			goto exec_out;
267: 		}
268: 		for (int i = 0; i < nCol; i++) {
269: 			azCols[i] = (char *)sqlite3_column_name(pStmt, i);
270: 		}
271: 
272: 		while (true) {
273: 			rc = sqlite3_step(pStmt);
274: 
275: 			/* Invoke the callback function if required */
276: 			if (xCallback && rc == SQLITE_ROW) {
277: 				for (int i = 0; i < nCol; i++) {
278: 					azVals[i] = (char *)sqlite3_column_text(pStmt, i);
279: 					if (!azVals[i] && sqlite3_column_type(pStmt, i) != SQLITE_NULL) {
280: 						fprintf(stderr, "sqlite3_exec: out of memory.\n");
281: 						goto exec_out;
282: 					}
283: 				}
284: 				if (xCallback(pArg, nCol, azVals, azCols)) {
285: 					/* EVIDENCE-OF: R-38229-40159 If the callback function to
286: 					** sqlite3_exec() returns non-zero, then sqlite3_exec() will
287: 					** return SQLITE_ABORT. */
288: 					rc = SQLITE_ABORT;
289: 					sqlite3_finalize(pStmt);
290: 					pStmt = 0;
291: 					fprintf(stderr, "sqlite3_exec: callback returned non-zero. "
292: 					                "Aborting.\n");
293: 					goto exec_out;
294: 				}
295: 			}
296: 			if (rc == SQLITE_DONE) {
297: 				rc = sqlite3_finalize(pStmt);
298: 				pStmt = nullptr;
299: 				zSql = zLeftover;
300: 				while (isspace(zSql[0]))
301: 					zSql++;
302: 				break;
303: 			} else if (rc != SQLITE_ROW) {
304: 				// error
305: 				if (pzErrMsg) {
306: 					auto errmsg = sqlite3_errmsg(db);
307: 					*pzErrMsg = errmsg ? sqlite3_strdup(errmsg) : nullptr;
308: 				}
309: 				goto exec_out;
310: 			}
311: 		}
312: 
313: 		sqlite3_free(azCols);
314: 		sqlite3_free(azVals);
315: 		azCols = nullptr;
316: 		azVals = nullptr;
317: 	}
318: 
319: exec_out:
320: 	if (pStmt) {
321: 		sqlite3_finalize(pStmt);
322: 	}
323: 	sqlite3_free(azCols);
324: 	sqlite3_free(azVals);
325: 	if (rc != SQLITE_OK && pzErrMsg && !*pzErrMsg) {
326: 		// error but no error message set
327: 		*pzErrMsg = sqlite3_strdup("Unknown error in DuckDB!");
328: 	}
329: 	return rc;
330: }
331: 
332: /* Return the text of the SQL that was used to prepare the statement */
333: const char *sqlite3_sql(sqlite3_stmt *pStmt) {
334: 	return pStmt->query_string.c_str();
335: }
336: 
337: int sqlite3_column_count(sqlite3_stmt *pStmt) {
338: 	if (!pStmt) {
339: 		return 0;
340: 	}
341: 	return (int)pStmt->prepared->types.size();
342: }
343: 
344: ////////////////////////////
345: //     sqlite3_column     //
346: ////////////////////////////
347: int sqlite3_column_type(sqlite3_stmt *pStmt, int iCol) {
348: 	if (!pStmt || !pStmt->result || !pStmt->current_chunk) {
349: 		return 0;
350: 	}
351: 	if (FlatVector::IsNull(pStmt->current_chunk->data[iCol], pStmt->current_row)) {
352: 		return SQLITE_NULL;
353: 	}
354: 	auto column_type = pStmt->result->sql_types[iCol];
355: 	switch (column_type.id) {
356: 	case SQLTypeId::BOOLEAN:
357: 	case SQLTypeId::TINYINT:
358: 	case SQLTypeId::SMALLINT:
359: 	case SQLTypeId::INTEGER:
360: 	case SQLTypeId::BIGINT: /* TODO: Maybe blob? */
361: 		return SQLITE_INTEGER;
362: 	case SQLTypeId::FLOAT:
363: 	case SQLTypeId::DOUBLE:
364: 	case SQLTypeId::DECIMAL:
365: 		return SQLITE_FLOAT;
366: 	case SQLTypeId::DATE:
367: 	case SQLTypeId::TIME:
368: 	case SQLTypeId::TIMESTAMP:
369: 	case SQLTypeId::VARCHAR:
370: 	case SQLTypeId::LIST:
371: 	case SQLTypeId::STRUCT:
372: 		return SQLITE_BLOB;
373: 	default:
374: 		return 0;
375: 	}
376: 	return 0;
377: }
378: 
379: const char *sqlite3_column_name(sqlite3_stmt *pStmt, int N) {
380: 	if (!pStmt) {
381: 		return nullptr;
382: 	}
383: 	return pStmt->prepared->names[N].c_str();
384: }
385: 
386: static bool sqlite3_column_has_value(sqlite3_stmt *pStmt, int iCol, SQLType target_type, Value &val) {
387: 	if (!pStmt || !pStmt->result || !pStmt->current_chunk) {
388: 		return false;
389: 	}
390: 	if (iCol < 0 || iCol >= (int)pStmt->result->sql_types.size()) {
391: 		return false;
392: 	}
393: 	if (FlatVector::IsNull(pStmt->current_chunk->data[iCol], pStmt->current_row)) {
394: 		return false;
395: 	}
396: 	try {
397: 		val = pStmt->current_chunk->data[iCol]
398: 		          .GetValue(pStmt->current_row)
399: 		          .CastAs(pStmt->result->sql_types[iCol], target_type);
400: 	} catch (...) {
401: 		return false;
402: 	}
403: 	return true;
404: }
405: 
406: double sqlite3_column_double(sqlite3_stmt *stmt, int iCol) {
407: 	Value val;
408: 	if (!sqlite3_column_has_value(stmt, iCol, SQLTypeId::DOUBLE, val)) {
409: 		return 0;
410: 	}
411: 	return val.value_.double_;
412: }
413: 
414: int sqlite3_column_int(sqlite3_stmt *stmt, int iCol) {
415: 	Value val;
416: 	if (!sqlite3_column_has_value(stmt, iCol, SQLTypeId::INTEGER, val)) {
417: 		return 0;
418: 	}
419: 	return val.value_.integer;
420: }
421: 
422: sqlite3_int64 sqlite3_column_int64(sqlite3_stmt *stmt, int iCol) {
423: 	Value val;
424: 	if (!sqlite3_column_has_value(stmt, iCol, SQLTypeId::BIGINT, val)) {
425: 		return 0;
426: 	}
427: 	return val.value_.bigint;
428: }
429: 
430: const unsigned char *sqlite3_column_text(sqlite3_stmt *pStmt, int iCol) {
431: 	Value val;
432: 	if (!sqlite3_column_has_value(pStmt, iCol, SQLTypeId::VARCHAR, val)) {
433: 		return nullptr;
434: 	}
435: 	try {
436: 		if (!pStmt->current_text) {
437: 			pStmt->current_text =
438: 			    unique_ptr<sqlite3_string_buffer[]>(new sqlite3_string_buffer[pStmt->result->sql_types.size()]);
439: 		}
440: 		auto &entry = pStmt->current_text[iCol];
441: 		if (!entry.data) {
442: 			// not initialized yet, convert the value and initialize it
443: 			entry.data = unique_ptr<char[]>(new char[val.str_value.size() + 1]);
444: 			memcpy(entry.data.get(), val.str_value.c_str(), val.str_value.size() + 1);
445: 		}
446: 		return (const unsigned char *)entry.data.get();
447: 	} catch (...) {
448: 		// memory error!
449: 		return nullptr;
450: 	}
451: }
452: 
453: ////////////////////////////
454: //      sqlite3_bind      //
455: ////////////////////////////
456: int sqlite3_bind_parameter_count(sqlite3_stmt *stmt) {
457: 	if (!stmt) {
458: 		return 0;
459: 	}
460: 	return stmt->prepared->n_param;
461: }
462: 
463: const char *sqlite3_bind_parameter_name(sqlite3_stmt *stmt, int idx) {
464: 	if (!stmt) {
465: 		return nullptr;
466: 	}
467: 	if (idx < 1 || idx > (int)stmt->prepared->n_param) {
468: 		return nullptr;
469: 	}
470: 	return stmt->bound_names[idx - 1].c_str();
471: }
472: 
473: int sqlite3_bind_parameter_index(sqlite3_stmt *stmt, const char *zName) {
474: 	if (!stmt || !zName) {
475: 		return 0;
476: 	}
477: 	for (idx_t i = 0; i < stmt->bound_names.size(); i++) {
478: 		if (stmt->bound_names[i] == string(zName)) {
479: 			return i + 1;
480: 		}
481: 	}
482: 	return 0;
483: }
484: 
485: int sqlite3_internal_bind_value(sqlite3_stmt *stmt, int idx, Value value) {
486: 	if (!stmt || !stmt->prepared || stmt->result) {
487: 		return SQLITE_MISUSE;
488: 	}
489: 	if (idx < 1 || idx > (int)stmt->prepared->n_param) {
490: 		return SQLITE_RANGE;
491: 	}
492: 	stmt->bound_values[idx - 1] = value;
493: 	return SQLITE_OK;
494: }
495: 
496: int sqlite3_bind_int(sqlite3_stmt *stmt, int idx, int val) {
497: 	return sqlite3_internal_bind_value(stmt, idx, Value::INTEGER(val));
498: }
499: 
500: int sqlite3_bind_int64(sqlite3_stmt *stmt, int idx, sqlite3_int64 val) {
501: 	return sqlite3_internal_bind_value(stmt, idx, Value::BIGINT(val));
502: }
503: 
504: int sqlite3_bind_double(sqlite3_stmt *stmt, int idx, double val) {
505: 	return sqlite3_internal_bind_value(stmt, idx, Value::DOUBLE(val));
506: }
507: 
508: int sqlite3_bind_null(sqlite3_stmt *stmt, int idx) {
509: 	return sqlite3_internal_bind_value(stmt, idx, Value());
510: }
511: 
512: int sqlite3_bind_text(sqlite3_stmt *stmt, int idx, const char *val, int length, void (*free_func)(void *)) {
513: 	if (!val) {
514: 		return SQLITE_MISUSE;
515: 	}
516: 	string value;
517: 	if (length < 0) {
518: 		value = string(val);
519: 	} else {
520: 		value = string(val, val + length);
521: 	}
522: 	if (free_func && ((ptrdiff_t)free_func) != -1) {
523: 		free_func((void *)val);
524: 	}
525: 	return sqlite3_internal_bind_value(stmt, idx, Value(value));
526: }
527: 
528: int sqlite3_clear_bindings(sqlite3_stmt *stmt) {
529: 	if (!stmt) {
530: 		return SQLITE_MISUSE;
531: 	}
532: 	return SQLITE_OK;
533: }
534: 
535: int sqlite3_initialize(void) {
536: 	return SQLITE_OK;
537: }
538: 
539: int sqlite3_finalize(sqlite3_stmt *pStmt) {
540: 	if (pStmt) {
541: 		if (pStmt->result && !pStmt->result->success) {
542: 			pStmt->db->last_error = string(pStmt->result->error);
543: 			delete pStmt;
544: 			return SQLITE_ERROR;
545: 		}
546: 
547: 		delete pStmt;
548: 	}
549: 	return SQLITE_OK;
550: }
551: 
552: /*
553: ** Some systems have stricmp().  Others have strcasecmp().  Because
554: ** there is no consistency, we will define our own.
555: **
556: ** IMPLEMENTATION-OF: R-30243-02494 The sqlite3_stricmp() and
557: ** sqlite3_strnicmp() APIs allow applications and extensions to compare
558: ** the contents of two buffers containing UTF-8 strings in a
559: ** case-independent fashion, using the same definition of "case
560: ** independence" that SQLite uses internally when comparing identifiers.
561: */
562: 
563: const unsigned char sqlite3UpperToLower[] = {
564:     0,   1,   2,   3,   4,   5,   6,   7,   8,   9,   10,  11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,
565:     22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,
566:     44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  97,
567:     98,  99,  100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,
568:     120, 121, 122, 91,  92,  93,  94,  95,  96,  97,  98,  99,  100, 101, 102, 103, 104, 105, 106, 107, 108, 109,
569:     110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,
570:     132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
571:     154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,
572:     176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,
573:     198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,
574:     220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,
575:     242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255};
576: 
577: int sqlite3StrICmp(const char *zLeft, const char *zRight) {
578: 	unsigned char *a, *b;
579: 	int c;
580: 	a = (unsigned char *)zLeft;
581: 	b = (unsigned char *)zRight;
582: 	for (;;) {
583: 		c = (int)sqlite3UpperToLower[*a] - (int)sqlite3UpperToLower[*b];
584: 		if (c || *a == 0)
585: 			break;
586: 		a++;
587: 		b++;
588: 	}
589: 	return c;
590: }
591: 
592: SQLITE_API int sqlite3_stricmp(const char *zLeft, const char *zRight) {
593: 	if (zLeft == 0) {
594: 		return zRight ? -1 : 0;
595: 	} else if (zRight == 0) {
596: 		return 1;
597: 	}
598: 	return sqlite3StrICmp(zLeft, zRight);
599: }
600: 
601: SQLITE_API int sqlite3_strnicmp(const char *zLeft, const char *zRight, int N) {
602: 	unsigned char *a, *b;
603: 	if (zLeft == 0) {
604: 		return zRight ? -1 : 0;
605: 	} else if (zRight == 0) {
606: 		return 1;
607: 	}
608: 	a = (unsigned char *)zLeft;
609: 	b = (unsigned char *)zRight;
610: 	while (N-- > 0 && *a != 0 && sqlite3UpperToLower[*a] == sqlite3UpperToLower[*b]) {
611: 		a++;
612: 		b++;
613: 	}
614: 	return N < 0 ? 0 : sqlite3UpperToLower[*a] - sqlite3UpperToLower[*b];
615: }
616: 
617: char *sqlite3_strdup(const char *str) {
618: 	char *result = (char *)sqlite3_malloc64(strlen(str) + 1);
619: 	strcpy(result, str);
620: 	return result;
621: }
622: 
623: void *sqlite3_malloc64(sqlite3_uint64 n) {
624: 	return malloc(n);
625: }
626: void sqlite3_free(void *pVoid) {
627: 	free(pVoid);
628: }
629: 
630: void *sqlite3_malloc(int n) {
631: 	return sqlite3_malloc64(n);
632: }
633: 
634: void *sqlite3_realloc(void *ptr, int n) {
635: 	return sqlite3_realloc64(ptr, n);
636: }
637: 
638: void *sqlite3_realloc64(void *ptr, sqlite3_uint64 n) {
639: 	return realloc(ptr, n);
640: }
641: 
642: // TODO: stub
643: int sqlite3_config(int i, ...) {
644: 	return SQLITE_OK;
645: }
646: 
647: int sqlite3_errcode(sqlite3 *db) {
648: 	if (!db) {
649: 		return SQLITE_MISUSE;
650: 	}
651: 	return db->last_error.empty() ? SQLITE_OK : SQLITE_ERROR;
652: }
653: 
654: int sqlite3_extended_errcode(sqlite3 *db) {
655: 	return sqlite3_errcode(db);
656: }
657: 
658: const char *sqlite3_errmsg(sqlite3 *db) {
659: 	if (!db) {
660: 		return "";
661: 	}
662: 	return db->last_error.c_str();
663: }
664: 
665: void sqlite3_interrupt(sqlite3 *db) {
666: 	if (db) {
667: 		db->con->Interrupt();
668: 	}
669: }
670: 
671: const char *sqlite3_libversion(void) {
672: 	return LIB_VERSION;
673: }
674: const char *sqlite3_sourceid(void) {
675: 	return SOURCE_ID;
676: }
677: 
678: int sqlite3_reset(sqlite3_stmt *stmt) {
679: 	if (stmt) {
680: 		stmt->result = nullptr;
681: 		stmt->current_chunk = nullptr;
682: 	}
683: 	return SQLITE_OK;
684: }
685: 
686: // support functions for shell.c
687: // most are dummies, we don't need them really
688: 
689: // TODO use re2 here?
690: int sqlite3_strglob(const char *zGlobPattern, const char *zString) {
691: 	fprintf(stderr, "sqlite3_strglob: unsupported.\n");
692: 
693: 	return -1;
694: }
695: 
696: int sqlite3_strlike(const char *zPattern, const char *zStr, unsigned int esc) {
697: 	fprintf(stderr, "sqlite3_strlike: unsupported.\n");
698: 
699: 	return -1;
700: }
701: 
702: int sqlite3_db_status(sqlite3 *, int op, int *pCur, int *pHiwtr, int resetFlg) {
703: 	fprintf(stderr, "sqlite3_db_status: unsupported.\n");
704: 	return -1;
705: }
706: 
707: // TODO these should eventually be implemented
708: 
709: int sqlite3_changes(sqlite3 *db) {
710: 	fprintf(stderr, "sqlite3_changes: unsupported.\n");
711: 	return 0;
712: }
713: 
714: int sqlite3_total_changes(sqlite3 *) {
715: 	fprintf(stderr, "sqlite3_total_changes: unsupported.\n");
716: 	return 0;
717: }
718: 
719: // checks if input ends with ;
720: int sqlite3_complete(const char *sql) {
721: 	// FIXME fprintf(stderr, "sqlite3_complete: unsupported.\n");
722: 	return -1;
723: }
724: 
725: int sqlite3_bind_blob(sqlite3_stmt *, int, const void *, int n, void (*)(void *)) {
726: 	fprintf(stderr, "sqlite3_bind_blob: unsupported.\n");
727: 	return -1;
728: }
729: 
730: const void *sqlite3_column_blob(sqlite3_stmt *, int iCol) {
731: 	fprintf(stderr, "sqlite3_column_blob: unsupported.\n");
732: 	return nullptr;
733: }
734: 
735: // length of varchar or blob value
736: int sqlite3_column_bytes(sqlite3_stmt *, int iCol) {
737: 	fprintf(stderr, "sqlite3_column_bytes: unsupported.\n");
738: 	return -1;
739: }
740: 
741: sqlite3_value *sqlite3_column_value(sqlite3_stmt *, int iCol) {
742: 	fprintf(stderr, "sqlite3_column_value: unsupported.\n");
743: 	return nullptr;
744: }
745: 
746: int sqlite3_db_config(sqlite3 *, int op, ...) {
747: 	fprintf(stderr, "sqlite3_db_config: unsupported.\n");
748: 	return -1;
749: }
750: 
751: int sqlite3_get_autocommit(sqlite3 *db) {
752: 	return 1;
753: 	// TODO fix this
754: 	// return db->con->context->transaction.IsAutoCommit();
755: 	fprintf(stderr, "sqlite3_get_autocommit: unsupported.\n");
756: }
757: 
758: int sqlite3_limit(sqlite3 *, int id, int newVal) {
759: 	fprintf(stderr, "sqlite3_limit: unsupported.\n");
760: 	return -1;
761: }
762: 
763: int sqlite3_stmt_readonly(sqlite3_stmt *pStmt) {
764: 	fprintf(stderr, "sqlite3_stmt_readonly: unsupported.\n");
765: 	return -1;
766: }
767: 
768: // TODO pretty easy schema lookup
769: int sqlite3_table_column_metadata(sqlite3 *db,             /* Connection handle */
770:                                   const char *zDbName,     /* Database name or NULL */
771:                                   const char *zTableName,  /* Table name */
772:                                   const char *zColumnName, /* Column name */
773:                                   char const **pzDataType, /* OUTPUT: Declared data type */
774:                                   char const **pzCollSeq,  /* OUTPUT: Collation sequence name */
775:                                   int *pNotNull,           /* OUTPUT: True if NOT NULL constraint exists */
776:                                   int *pPrimaryKey,        /* OUTPUT: True if column part of PK */
777:                                   int *pAutoinc            /* OUTPUT: True if column is auto-increment */
778: ) {
779: 	fprintf(stderr, "sqlite3_table_column_metadata: unsupported.\n");
780: 	return -1;
781: }
782: 
783: const char *sqlite3_column_decltype(sqlite3_stmt *stmt, int col) {
784: 	fprintf(stderr, "sqlite3_column_decltype: unsupported.\n");
785: 	return nullptr;
786: }
787: 
788: int sqlite3_status64(int op, sqlite3_int64 *pCurrent, sqlite3_int64 *pHighwater, int resetFlag) {
789: 	fprintf(stderr, "sqlite3_status64: unsupported.\n");
790: 	return -1;
791: }
792: 
793: int sqlite3_status64(sqlite3 *, int op, int *pCur, int *pHiwtr, int resetFlg) {
794: 	fprintf(stderr, "sqlite3_status64: unsupported.\n");
795: 	return -1;
796: }
797: 
798: int sqlite3_stmt_status(sqlite3_stmt *, int op, int resetFlg) {
799: 	fprintf(stderr, "sqlite3_stmt_status: unsupported.\n");
800: 	return -1;
801: }
802: 
803: int sqlite3_file_control(sqlite3 *, const char *zDbName, int op, void *) {
804: 	fprintf(stderr, "sqlite3_file_control: unsupported.\n");
805: 	return -1;
806: }
807: 
808: int sqlite3_declare_vtab(sqlite3 *, const char *zSQL) {
809: 	fprintf(stderr, "sqlite3_declare_vtab: unsupported.\n");
810: 	return -1;
811: }
812: 
813: const char *sqlite3_vtab_collation(sqlite3_index_info *, int) {
814: 	fprintf(stderr, "sqlite3_vtab_collation: unsupported.\n");
815: 	return nullptr;
816: }
817: 
818: int sqlite3_sleep(int) {
819: 	fprintf(stderr, "sqlite3_sleep: unsupported.\n");
820: 	return -1;
821: }
822: 
823: int sqlite3_busy_timeout(sqlite3 *, int ms) {
824: 	fprintf(stderr, "sqlite3_busy_timeout: unsupported.\n");
825: 	return -1;
826: }
827: 
828: // unlikely to be supported
829: 
830: int sqlite3_trace_v2(sqlite3 *, unsigned uMask, int (*xCallback)(unsigned, void *, void *, void *), void *pCtx) {
831: 	fprintf(stderr, "sqlite3_trace_v2: unsupported.\n");
832: 	return -1;
833: }
834: 
835: int sqlite3_test_control(int op, ...) {
836: 	fprintf(stderr, "sqlite3_test_control: unsupported.\n");
837: 	return -1;
838: }
839: 
840: int sqlite3_enable_load_extension(sqlite3 *db, int onoff) {
841: 	// fprintf(stderr, "sqlite3_enable_load_extension: unsupported.\n");
842: 	return -1;
843: }
844: 
845: int sqlite3_load_extension(sqlite3 *db,       /* Load the extension into this database connection */
846:                            const char *zFile, /* Name of the shared library containing extension */
847:                            const char *zProc, /* Entry point.  Derived from zFile if 0 */
848:                            char **pzErrMsg    /* Put error message here if not 0 */
849: ) {
850: 	// fprintf(stderr, "sqlite3_load_extension: unsupported.\n");
851: 	return -1;
852: }
853: 
854: int sqlite3_create_module(sqlite3 *db,             /* SQLite connection to register module with */
855:                           const char *zName,       /* Name of the module */
856:                           const sqlite3_module *p, /* Methods for the module */
857:                           void *pClientData        /* Client data for xCreate/xConnect */
858: ) {
859: 	// fprintf(stderr, "sqlite3_create_module: unsupported.\n");
860: 	return -1;
861: }
862: 
863: int sqlite3_create_function(sqlite3 *db, const char *zFunctionName, int nArg, int eTextRep, void *pApp,
864:                             void (*xFunc)(sqlite3_context *, int, sqlite3_value **),
865:                             void (*xStep)(sqlite3_context *, int, sqlite3_value **),
866:                             void (*xFinal)(sqlite3_context *)) {
867: 	// fprintf(stderr, "sqlite3_create_function: unsupported.\n");
868: 	return -1;
869: }
870: 
871: int sqlite3_set_authorizer(sqlite3 *, int (*xAuth)(void *, int, const char *, const char *, const char *, const char *),
872:                            void *pUserData) {
873: 	fprintf(stderr, "sqlite3_set_authorizer: unsupported.\n");
874: 	return -1;
875: }
876: 
877: // needed in shell timer
878: static int unixCurrentTimeInt64(sqlite3_vfs *NotUsed, sqlite3_int64 *piNow) {
879: 	using namespace std::chrono;
880: 	*piNow = (sqlite3_int64)duration_cast<milliseconds>(system_clock::now().time_since_epoch()).count();
881: 	return SQLITE_OK;
882: }
883: 
884: // virtual file system, providing some dummies to avoid crashes
885: sqlite3_vfs *sqlite3_vfs_find(const char *zVfsName) {
886: 	// return a dummy because the shell does not check the return code.
887: 	// fprintf(stderr, "sqlite3_vfs_find: unsupported.\n");
888: 	sqlite3_vfs *res = (sqlite3_vfs *)sqlite3_malloc(sizeof(sqlite3_vfs));
889: 	res->xCurrentTimeInt64 = unixCurrentTimeInt64;
890: 	res->iVersion = 2;
891: 	res->zName = "dummy";
892: 	res->pNext = nullptr;
893: 	assert(res);
894: 	return res;
895: }
896: int sqlite3_vfs_register(sqlite3_vfs *, int makeDflt) {
897: 	// fprintf(stderr, "sqlite3_vfs_register: unsupported.\n");
898: 	return -1;
899: }
900: 
901: // backups, unused
902: 
903: int sqlite3_backup_step(sqlite3_backup *p, int nPage) {
904: 	fprintf(stderr, "sqlite3_backup_step: unsupported.\n");
905: 	return -1;
906: }
907: int sqlite3_backup_finish(sqlite3_backup *p) {
908: 	fprintf(stderr, "sqlite3_backup_finish: unsupported.\n");
909: 	return -1;
910: }
911: 
912: sqlite3_backup *sqlite3_backup_init(sqlite3 *pDest,         /* Destination database handle */
913:                                     const char *zDestName,  /* Destination database name */
914:                                     sqlite3 *pSource,       /* Source database handle */
915:                                     const char *zSourceName /* Source database name */
916: ) {
917: 	fprintf(stderr, "sqlite3_backup_init: unsupported.\n");
918: 	return nullptr;
919: }
920: 
921: // UDF support stuff, unused for now. These cannot be called as create_function above is disabled
922: 
923: SQLITE_API sqlite3 *sqlite3_context_db_handle(sqlite3_context *) {
924: 	return nullptr;
925: }
926: 
927: void *sqlite3_user_data(sqlite3_context *) {
928: 	return nullptr;
929: }
930: 
931: #ifdef _WIN32
932: #include <windows.h>
933: 
934: static void *sqlite3MallocZero(size_t n) {
935: 	auto res = sqlite3_malloc(n);
936: 	assert(res);
937: 	memset(res, 0, n);
938: 	return res;
939: }
940: 
941: static LPWSTR winUtf8ToUnicode(const char *zText) {
942: 	int nChar;
943: 	LPWSTR zWideText;
944: 
945: 	nChar = MultiByteToWideChar(CP_UTF8, 0, zText, -1, NULL, 0);
946: 	if (nChar == 0) {
947: 		return 0;
948: 	}
949: 	zWideText = (LPWSTR)sqlite3MallocZero(nChar * sizeof(WCHAR));
950: 	if (zWideText == 0) {
951: 		return 0;
952: 	}
953: 	nChar = MultiByteToWideChar(CP_UTF8, 0, zText, -1, zWideText, nChar);
954: 	if (nChar == 0) {
955: 		sqlite3_free(zWideText);
956: 		zWideText = 0;
957: 	}
958: 	return zWideText;
959: }
960: 
961: static char *winUnicodeToMbcs(LPCWSTR zWideText, int useAnsi) {
962: 	int nByte;
963: 	char *zText;
964: 	int codepage = useAnsi ? CP_ACP : CP_OEMCP;
965: 
966: 	nByte = WideCharToMultiByte(codepage, 0, zWideText, -1, 0, 0, 0, 0);
967: 	if (nByte == 0) {
968: 		return 0;
969: 	}
970: 	zText = (char *)sqlite3MallocZero(nByte);
971: 	if (zText == 0) {
972: 		return 0;
973: 	}
974: 	nByte = WideCharToMultiByte(codepage, 0, zWideText, -1, zText, nByte, 0, 0);
975: 	if (nByte == 0) {
976: 		sqlite3_free(zText);
977: 		zText = 0;
978: 	}
979: 	return zText;
980: }
981: 
982: static char *winUtf8ToMbcs(const char *zText, int useAnsi) {
983: 	char *zTextMbcs;
984: 	LPWSTR zTmpWide;
985: 
986: 	zTmpWide = winUtf8ToUnicode(zText);
987: 	if (zTmpWide == 0) {
988: 		return 0;
989: 	}
990: 	zTextMbcs = winUnicodeToMbcs(zTmpWide, useAnsi);
991: 	sqlite3_free(zTmpWide);
992: 	return zTextMbcs;
993: }
994: 
995: SQLITE_API char *sqlite3_win32_utf8_to_mbcs_v2(const char *zText, int useAnsi) {
996: 	return winUtf8ToMbcs(zText, useAnsi);
997: }
998: 
999: LPWSTR sqlite3_win32_utf8_to_unicode(const char *zText) {
1000: 	return winUtf8ToUnicode(zText);
1001: }
1002: 
1003: static LPWSTR winMbcsToUnicode(const char *zText, int useAnsi) {
1004: 	int nByte;
1005: 	LPWSTR zMbcsText;
1006: 	int codepage = useAnsi ? CP_ACP : CP_OEMCP;
1007: 
1008: 	nByte = MultiByteToWideChar(codepage, 0, zText, -1, NULL, 0) * sizeof(WCHAR);
1009: 	if (nByte == 0) {
1010: 		return 0;
1011: 	}
1012: 	zMbcsText = (LPWSTR)sqlite3MallocZero(nByte * sizeof(WCHAR));
1013: 	if (zMbcsText == 0) {
1014: 		return 0;
1015: 	}
1016: 	nByte = MultiByteToWideChar(codepage, 0, zText, -1, zMbcsText, nByte);
1017: 	if (nByte == 0) {
1018: 		sqlite3_free(zMbcsText);
1019: 		zMbcsText = 0;
1020: 	}
1021: 	return zMbcsText;
1022: }
1023: 
1024: static char *winUnicodeToUtf8(LPCWSTR zWideText) {
1025: 	int nByte;
1026: 	char *zText;
1027: 
1028: 	nByte = WideCharToMultiByte(CP_UTF8, 0, zWideText, -1, 0, 0, 0, 0);
1029: 	if (nByte == 0) {
1030: 		return 0;
1031: 	}
1032: 	zText = (char *)sqlite3MallocZero(nByte);
1033: 	if (zText == 0) {
1034: 		return 0;
1035: 	}
1036: 	nByte = WideCharToMultiByte(CP_UTF8, 0, zWideText, -1, zText, nByte, 0, 0);
1037: 	if (nByte == 0) {
1038: 		sqlite3_free(zText);
1039: 		zText = 0;
1040: 	}
1041: 	return zText;
1042: }
1043: 
1044: static char *winMbcsToUtf8(const char *zText, int useAnsi) {
1045: 	char *zTextUtf8;
1046: 	LPWSTR zTmpWide;
1047: 
1048: 	zTmpWide = winMbcsToUnicode(zText, useAnsi);
1049: 	if (zTmpWide == 0) {
1050: 		return 0;
1051: 	}
1052: 	zTextUtf8 = winUnicodeToUtf8(zTmpWide);
1053: 	sqlite3_free(zTmpWide);
1054: 	return zTextUtf8;
1055: }
1056: 
1057: SQLITE_API char *sqlite3_win32_mbcs_to_utf8_v2(const char *zText, int useAnsi) {
1058: 	return winMbcsToUtf8(zText, useAnsi);
1059: }
1060: 
1061: SQLITE_API char *sqlite3_win32_unicode_to_utf8(LPCWSTR zWideText) {
1062: 	return winUnicodeToUtf8(zWideText);
1063: }
1064: 
1065: #endif
1066: 
1067: // TODO complain
1068: SQLITE_API void sqlite3_result_blob(sqlite3_context *, const void *, int, void (*)(void *)) {
1069: }
1070: SQLITE_API void sqlite3_result_blob64(sqlite3_context *, const void *, sqlite3_uint64, void (*)(void *)) {
1071: }
1072: SQLITE_API void sqlite3_result_double(sqlite3_context *, double) {
1073: }
1074: SQLITE_API void sqlite3_result_error(sqlite3_context *, const char *, int) {
1075: }
1076: SQLITE_API void sqlite3_result_error16(sqlite3_context *, const void *, int) {
1077: }
1078: SQLITE_API void sqlite3_result_error_toobig(sqlite3_context *) {
1079: }
1080: SQLITE_API void sqlite3_result_error_nomem(sqlite3_context *) {
1081: }
1082: SQLITE_API void sqlite3_result_error_code(sqlite3_context *, int) {
1083: }
1084: SQLITE_API void sqlite3_result_int(sqlite3_context *, int) {
1085: }
1086: SQLITE_API void sqlite3_result_int64(sqlite3_context *, sqlite3_int64) {
1087: }
1088: SQLITE_API void sqlite3_result_null(sqlite3_context *) {
1089: }
1090: SQLITE_API void sqlite3_result_text(sqlite3_context *, const char *, int, void (*)(void *)) {
1091: }
1092: SQLITE_API void sqlite3_result_text64(sqlite3_context *, const char *, sqlite3_uint64, void (*)(void *),
1093:                                       unsigned char encoding) {
1094: }
1095: SQLITE_API void sqlite3_result_text16(sqlite3_context *, const void *, int, void (*)(void *)) {
1096: }
1097: SQLITE_API void sqlite3_result_text16le(sqlite3_context *, const void *, int, void (*)(void *)) {
1098: }
1099: SQLITE_API void sqlite3_result_text16be(sqlite3_context *, const void *, int, void (*)(void *)) {
1100: }
1101: SQLITE_API void sqlite3_result_value(sqlite3_context *, sqlite3_value *) {
1102: }
1103: SQLITE_API void sqlite3_result_pointer(sqlite3_context *, void *, const char *, void (*)(void *)) {
1104: }
1105: SQLITE_API void sqlite3_result_zeroblob(sqlite3_context *, int n) {
1106: }
1107: SQLITE_API int sqlite3_result_zeroblob64(sqlite3_context *, sqlite3_uint64 n) {
1108: 	return -1;
1109: }
1110: 
1111: // TODO complain
1112: const void *sqlite3_value_blob(sqlite3_value *) {
1113: 	return nullptr;
1114: }
1115: double sqlite3_value_double(sqlite3_value *) {
1116: 	return 0;
1117: }
1118: int sqlite3_value_int(sqlite3_value *) {
1119: 	return 0;
1120: }
1121: sqlite3_int64 sqlite3_value_int64(sqlite3_value *) {
1122: 	return 0;
1123: }
1124: void *sqlite3_value_pointer(sqlite3_value *, const char *) {
1125: 	return nullptr;
1126: }
1127: const unsigned char *sqlite3_value_text(sqlite3_value *) {
1128: 	return nullptr;
1129: }
1130: SQLITE_API const void *sqlite3_value_text16(sqlite3_value *) {
1131: 	return nullptr;
1132: }
1133: SQLITE_API const void *sqlite3_value_text16le(sqlite3_value *) {
1134: 	return nullptr;
1135: }
1136: SQLITE_API const void *sqlite3_value_text16be(sqlite3_value *) {
1137: 	return nullptr;
1138: }
1139: SQLITE_API int sqlite3_value_bytes(sqlite3_value *) {
1140: 	return 0;
1141: }
1142: SQLITE_API int sqlite3_value_bytes16(sqlite3_value *) {
1143: 	return 0;
1144: }
1145: SQLITE_API int sqlite3_value_type(sqlite3_value *) {
1146: 	return 0;
1147: }
1148: SQLITE_API int sqlite3_value_numeric_type(sqlite3_value *) {
1149: 	return 0;
1150: }
1151: SQLITE_API int sqlite3_value_nochange(sqlite3_value *) {
1152: 	return 0;
1153: }
[end of tools/sqlite3_api_wrapper/sqlite3_api_wrapper.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: