{
  "repo": "duckdb/duckdb",
  "pull_number": 1437,
  "instance_id": "duckdb__duckdb-1437",
  "issue_numbers": [
    "1391"
  ],
  "base_commit": "6e220ef7a38df46ea349ba81847b9aa2047c6830",
  "patch": "diff --git a/extension/parquet/include/parquet_reader.hpp b/extension/parquet/include/parquet_reader.hpp\nindex 72769b9fdb5f..aa177bd31435 100644\n--- a/extension/parquet/include/parquet_reader.hpp\n+++ b/extension/parquet/include/parquet_reader.hpp\n@@ -79,7 +79,7 @@ class ParquetReader {\n \tbool ScanInternal(ParquetReaderScanState &state, DataChunk &output);\n \n \tconst parquet::format::RowGroup &GetGroup(ParquetReaderScanState &state);\n-\tvoid PrepareRowGroupBuffer(ParquetReaderScanState &state, idx_t col_idx);\n+\tvoid PrepareRowGroupBuffer(ParquetReaderScanState &state, idx_t out_col_idx);\n \n \ttemplate <typename... Args>\n \tstd::runtime_error FormatException(const string fmt_str, Args... params) {\ndiff --git a/extension/parquet/parquet_reader.cpp b/extension/parquet/parquet_reader.cpp\nindex ce4d1c79f760..c9c84663d64f 100644\n--- a/extension/parquet/parquet_reader.cpp\n+++ b/extension/parquet/parquet_reader.cpp\n@@ -307,15 +307,16 @@ const RowGroup &ParquetReader::GetGroup(ParquetReaderScanState &state) {\n \treturn file_meta_data->row_groups[state.group_idx_list[state.current_group]];\n }\n \n-void ParquetReader::PrepareRowGroupBuffer(ParquetReaderScanState &state, idx_t file_col_idx) {\n+void ParquetReader::PrepareRowGroupBuffer(ParquetReaderScanState &state, idx_t out_col_idx) {\n \tauto &group = GetGroup(state);\n \n-\tauto column_reader = ((StructColumnReader *)state.root_reader.get())->GetChildReader(file_col_idx);\n+\tauto column_reader = ((StructColumnReader *)state.root_reader.get())->GetChildReader(state.column_ids[out_col_idx]);\n \n \t// TODO move this to columnreader too\n \tif (state.filters) {\n \t\tauto stats = column_reader->Stats(group.columns);\n-\t\tauto filter_entry = state.filters->filters.find(file_col_idx);\n+\t\t// filters contain output chunk index, not file col idx!\n+\t\tauto filter_entry = state.filters->filters.find(out_col_idx);\n \t\tif (stats && filter_entry != state.filters->filters.end()) {\n \t\t\tbool skip_chunk = false;\n \t\t\tswitch (column_reader->Type().id()) {\n@@ -488,14 +489,12 @@ bool ParquetReader::ScanInternal(ParquetReaderScanState &state, DataChunk &resul\n \t\t}\n \n \t\tfor (idx_t out_col_idx = 0; out_col_idx < result.ColumnCount(); out_col_idx++) {\n-\t\t\tauto file_col_idx = state.column_ids[out_col_idx];\n-\n \t\t\t// this is a special case where we are not interested in the actual contents of the file\n-\t\t\tif (file_col_idx == COLUMN_IDENTIFIER_ROW_ID) {\n+\t\t\tif (state.column_ids[out_col_idx] == COLUMN_IDENTIFIER_ROW_ID) {\n \t\t\t\tcontinue;\n \t\t\t}\n \n-\t\t\tPrepareRowGroupBuffer(state, file_col_idx);\n+\t\t\tPrepareRowGroupBuffer(state, out_col_idx);\n \t\t}\n \t\treturn true;\n \t}\ndiff --git a/extension/parquet/parquet_statistics.cpp b/extension/parquet/parquet_statistics.cpp\nindex 9d8b0403d0bd..538e70024f28 100644\n--- a/extension/parquet/parquet_statistics.cpp\n+++ b/extension/parquet/parquet_statistics.cpp\n@@ -138,20 +138,16 @@ unique_ptr<BaseStatistics> ParquetTransformColumnStatistics(const SchemaElement\n \tcase LogicalTypeId::VARCHAR: {\n \t\tauto string_stats = make_unique<StringStatistics>(type);\n \t\tif (parquet_stats.__isset.min) {\n-\t\t\tmemcpy(string_stats->min, (data_ptr_t)parquet_stats.min.data(),\n-\t\t\t       MinValue<idx_t>(parquet_stats.min.size(), StringStatistics::MAX_STRING_MINMAX_SIZE));\n+\t\t\tstring_stats->Update(parquet_stats.min);\n \t\t} else if (parquet_stats.__isset.min_value) {\n-\t\t\tmemcpy(string_stats->min, (data_ptr_t)parquet_stats.min_value.data(),\n-\t\t\t       MinValue<idx_t>(parquet_stats.min_value.size(), StringStatistics::MAX_STRING_MINMAX_SIZE));\n+\t\t\tstring_stats->Update(parquet_stats.min_value);\n \t\t} else {\n \t\t\treturn nullptr;\n \t\t}\n \t\tif (parquet_stats.__isset.max) {\n-\t\t\tmemcpy(string_stats->max, (data_ptr_t)parquet_stats.max.data(),\n-\t\t\t       MinValue<idx_t>(parquet_stats.max.size(), StringStatistics::MAX_STRING_MINMAX_SIZE));\n+\t\t\tstring_stats->Update(parquet_stats.max);\n \t\t} else if (parquet_stats.__isset.max_value) {\n-\t\t\tmemcpy(string_stats->max, (data_ptr_t)parquet_stats.max_value.data(),\n-\t\t\t       MinValue<idx_t>(parquet_stats.max_value.size(), StringStatistics::MAX_STRING_MINMAX_SIZE));\n+\t\t\tstring_stats->Update(parquet_stats.max_value);\n \t\t} else {\n \t\t\treturn nullptr;\n \t\t}\n",
  "test_patch": "diff --git a/test/sql/copy/parquet/data/filter_bug1391.parquet b/test/sql/copy/parquet/data/filter_bug1391.parquet\nnew file mode 100644\nindex 000000000000..d4e951a857ee\nBinary files /dev/null and b/test/sql/copy/parquet/data/filter_bug1391.parquet differ\ndiff --git a/test/sql/copy/parquet/parquet_filter_bug1391.test b/test/sql/copy/parquet/parquet_filter_bug1391.test\nnew file mode 100644\nindex 000000000000..2536061a9f77\n--- /dev/null\n+++ b/test/sql/copy/parquet/parquet_filter_bug1391.test\n@@ -0,0 +1,43 @@\n+# name: test/sql/copy/parquet/parquet_filter_bug1391.test\n+# description: Test basic parquet reading\n+# group: [parquet]\n+\n+require parquet\n+require vector_size 512\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+CREATE VIEW tbl AS SELECT * FROM PARQUET_SCAN('test/sql/copy/parquet/data/filter_bug1391.parquet');\n+#\n+#query I\n+#SELECT ORGUNITID FROM tbl LIMIT 10\n+#----\n+#98\n+#13\n+#175\n+#200\n+#262\n+#206\n+#204\n+#131\n+#181\n+#269\n+#\n+#query I\n+#SELECT COUNT(*) FROM tbl;\n+#----\n+#9789\n+\n+query I\n+SELECT COUNT(*) FROM tbl\n+WHERE Namevalidfrom <= '2017-03-01'\n+AND Namevalidto >= '2017-03-01'\n+AND Parentnamevalidfrom <= '2017-03-01'\n+AND Parentnamevalidto >= '2017-03-01'\n+AND CustomerCode = 'CODE';\n+----\n+8722\n+\n+\ndiff --git a/test/sql/copy/parquet/test_parquet_filter_pushdown.test b/test/sql/copy/parquet/test_parquet_filter_pushdown.test\nindex 1ab5c547df97..7b4f6873a091 100644\n--- a/test/sql/copy/parquet/test_parquet_filter_pushdown.test\n+++ b/test/sql/copy/parquet/test_parquet_filter_pushdown.test\n@@ -4,51 +4,51 @@\n \n require parquet\n require vector_size 512\n-\n-statement ok\n-pragma enable_verification\n-\n-# userdata1.parquet\n-query I\n-SELECT COUNT(*) FROM parquet_scan('test/sql/copy/parquet/data/userdata1.parquet') where id > 500\n-----\n-500\n-\n-query I\n-SELECT COUNT(*) FROM parquet_scan('test/sql/copy/parquet/data/userdata1.parquet') where id < 500\n-----\n-499\n-\n-query I\n-SELECT COUNT(*) FROM parquet_scan('test/sql/copy/parquet/data/userdata1.parquet') where id > 100 and id < 900\n-----\n-799\n-\n-query I\n-SELECT COUNT(*) FROM parquet_scan('test/sql/copy/parquet/data/userdata1.parquet') where id between 100 and 900\n-----\n-801\n-\n-query IIIII\n-SELECT registration_dttm, id, first_name, birthdate, salary FROM parquet_scan('test/sql/copy/parquet/data/userdata1.parquet') where id = 42\n-----\n-2016-02-03 04:33:04\t42\tTodd\t12/19/1999\t284728.990000\n-\n-\n-query I\n-SELECT COUNT(*) FROM parquet_scan('test/sql/copy/parquet/data/userdata1.parquet') where id = 42\n-----\n-1\n-\n-query I\n-SELECT COUNT(*) FROM parquet_scan('test/sql/copy/parquet/data/userdata1.parquet') where salary < 1000\n-----\n-0\n-\n-query I\n-SELECT COUNT(*) FROM parquet_scan('test/sql/copy/parquet/data/userdata1.parquet') where salary < 1000\n-----\n-0\n+#\n+#statement ok\n+#pragma enable_verification\n+#\n+## userdata1.parquet\n+#query I\n+#SELECT COUNT(*) FROM parquet_scan('test/sql/copy/parquet/data/userdata1.parquet') where id > 500\n+#----\n+#500\n+#\n+#query I\n+#SELECT COUNT(*) FROM parquet_scan('test/sql/copy/parquet/data/userdata1.parquet') where id < 500\n+#----\n+#499\n+#\n+#query I\n+#SELECT COUNT(*) FROM parquet_scan('test/sql/copy/parquet/data/userdata1.parquet') where id > 100 and id < 900\n+#----\n+#799\n+#\n+#query I\n+#SELECT COUNT(*) FROM parquet_scan('test/sql/copy/parquet/data/userdata1.parquet') where id between 100 and 900\n+#----\n+#801\n+#\n+#query IIIII\n+#SELECT registration_dttm, id, first_name, birthdate, salary FROM parquet_scan('test/sql/copy/parquet/data/userdata1.parquet') where id = 42\n+#----\n+#2016-02-03 04:33:04\t42\tTodd\t12/19/1999\t284728.990000\n+#\n+#\n+#query I\n+#SELECT COUNT(*) FROM parquet_scan('test/sql/copy/parquet/data/userdata1.parquet') where id = 42\n+#----\n+#1\n+#\n+#query I\n+#SELECT COUNT(*) FROM parquet_scan('test/sql/copy/parquet/data/userdata1.parquet') where salary < 1000\n+#----\n+#0\n+#\n+#query I\n+#SELECT COUNT(*) FROM parquet_scan('test/sql/copy/parquet/data/userdata1.parquet') where salary < 1000\n+#----\n+#0\n \n query II\n SELECT first_name, gender FROM parquet_scan('test/sql/copy/parquet/data/userdata1.parquet') where first_name = 'Mark' and gender <> ''\n@@ -64,6 +64,20 @@ Mark\tMale\n Mark\tMale\n Mark\tMale\n \n+query II\n+SELECT gender, first_name FROM parquet_scan('test/sql/copy/parquet/data/userdata1.parquet') where first_name = 'Mark' and gender <> ''\n+----\n+Male\tMark\n+Male\tMark\n+Male\tMark\n+Male\tMark\n+Male\tMark\n+Male\tMark\n+Male\tMark\n+Male\tMark\n+Male\tMark\n+Male\tMark\n+\n query I\n SELECT COUNT(*) FROM parquet_scan('test/sql/copy/parquet/data/userdata1.parquet') where gender = 'Male' and first_name = 'Mark'\n ----\n",
  "problem_statement": "Wrong behavior when including a filter field in the select over a parquet file view\nI have a parquet file with the following layout:\r\n\r\nORGUNITID: int64\r\nVALIDFROM: string\r\nVALIDTO: string\r\nORGUNITNAME: string\r\n**NAMEVALIDFROM: string\r\nNAMEVALIDTO: string**\r\nPARENTID: int64\r\nPARENTNAME: string\r\nPARENTNAMEVALIDFROM: string\r\nPARENTNAMEVALIDTO: string\r\nLEVELID: int64\r\nLEVELNAME: string\r\nPARENTLEVELID: int64\r\nPARENTLEVELNAME: string\r\nORGSTRUCTVALIDFROM: string\r\nORGSTRUCTVALIDTO: string\r\nPARENTORGSTRUCTVALIDFROM: string\r\nPARENTORGSTRUCTVALIDTO: string\r\nCUSTOMERCODE: string\r\n\r\nThe fields VALIDFROM and VALIDTO range from '1900-01-01' to '9999-31-12'. \r\n\r\nIn python I create a view of the parquet file:\r\n\r\nc = duckdb.connect()\r\nc.execute(f\"CREATE VIEW tbl AS SELECT * FROM parquet_scan('table.parquet');\")\r\n\r\nIf I select all fields everything works fine, \r\n\r\nsql = '''\r\n    SELECT * from tbl\r\n    where Namevalidfrom <=  '2017-03-01'\r\n    AND Namevalidto >=  '2017-03-01'\r\n    AND Parentnamevalidfrom <=  '2017-03-01'\r\n    AND Parentnamevalidto >=  '2017-03-01'\r\n    AND Orgunitid IN  (.... numbers ...)\r\n    AND Parentid in (... numbers ...)\r\n    AND CustomerCode = 'code'        \r\n'''\r\nthis returns an array of tuples which satisfy criteria\r\n\r\nIf I select any of these 2 fields alone or in combination with other fields, the response is empty array\r\nNAMEVALIDFROM: string\r\nNAMEVALIDTO: string\r\n\r\nsql = '''\r\n    SELECT **Namevalidfrom** from tbl\r\n    where Namevalidfrom <=  '2017-03-01'\r\n    AND Namevalidto >=  '2017-03-01'\r\n    AND Parentnamevalidfrom <=  '2017-03-01'\r\n    AND Parentnamevalidto >=  '2017-03-01'\r\n    AND Orgunitid IN  (.... numbers ...)\r\n    AND Parentid in (... numbers ...)\r\n    AND CustomerCode = 'code'   \r\n'''\r\n\r\n^^^ this returns an empty array\r\n\r\nOr even if select through a subquery:\r\nsql = '''\r\n    SELECT **Namevalidfrom**  from (\r\n        select * from OrgUnitBridge \r\n    where Namevalidfrom <=  '2017-03-01'\r\n    AND Namevalidto >=  '2017-03-01'\r\n    AND Parentnamevalidfrom <=  '2017-03-01'\r\n    AND Parentnamevalidto >=  '2017-03-01'\r\n    AND Orgunitid IN  (.... numbers ...)\r\n    AND Parentid in (... numbers ...)\r\n    AND CustomerCode = 'code' ) t\r\n'''\r\n^^^ this returns an empty array\r\n\r\nI have changed the data type in the parquet file for these 2 fields to both STRING and TIMESTAMP and I get the same behavior.\r\n\r\nUsing v.0.2.4 through Python in Ubuntu 20.\r\n \r\nHere's a sample of the data:\r\n[(10318, '1900-01-01 00:00:00.000', '9999-12-31 00:00:00.000', 'XYZ Admin', '1900-01-01 00:00:00.000', '9999-12-31 00:00:00.000', 10144, 'XYZ', '1900-01-01 00:00:00.000', '9999-12-31 00:00:00.000', 10005, 'unit', 10004, 'department', '2020-04-27 00:00:00.000', '9999-12-31 00:00:00.000', '1900-01-01 00:00:00.000', '2020-04-23 00:00:00.000', 'code')]\r\n\r\nI have enabled logs PRAGMA but the file is empty.\r\n\n",
  "hints_text": "Could you share a parquet file where you demonstrate the issue? It looks like a problem with selection pushdown. \nThe filtering is also involved somehow, take this query for example and comment out filter predicates.\r\n\r\n    select Namevalidfrom from tbl \r\n    where Namevalidfrom <=  '2017-03-01' \r\n    AND Namevalidto >=  '2017-03-01'\r\n    AND Parentnamevalidfrom <=  '2017-03-01'\r\n    AND Parentnamevalidto >=  '2017-03-01'    \r\n    AND CustomerCode = 'CODE' \r\n\r\nThe sample attached.\r\n\r\n[sample.zip](https://github.com/cwida/duckdb/files/5971585/sample.zip)\r\n\nThanks for sharing the file and query, looks like there is indeed a bug here (or wrong statistics).",
  "created_at": "2021-02-23T12:36:44Z"
}