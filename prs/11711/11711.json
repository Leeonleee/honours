{
  "repo": "duckdb/duckdb",
  "pull_number": 11711,
  "instance_id": "duckdb__duckdb-11711",
  "issue_numbers": [
    "11660"
  ],
  "base_commit": "f6e169b71fbdfbc95d23542ee227632720af5f96",
  "patch": "diff --git a/src/execution/operator/csv_scanner/util/csv_reader_options.cpp b/src/execution/operator/csv_scanner/util/csv_reader_options.cpp\nindex 0bde700c0b4b..dd7853ee860c 100644\n--- a/src/execution/operator/csv_scanner/util/csv_reader_options.cpp\n+++ b/src/execution/operator/csv_scanner/util/csv_reader_options.cpp\n@@ -148,7 +148,7 @@ void CSVReaderOptions::SetDateFormat(LogicalTypeId type, const string &format, b\n \t\terror = StrTimeFormat::ParseFormatSpecifier(format, strpformat);\n \t\tdialect_options.date_format[type].Set(strpformat);\n \t} else {\n-\t\terror = StrTimeFormat::ParseFormatSpecifier(format, write_date_format[type]);\n+\t\twrite_date_format[type] = Value(format);\n \t}\n \tif (!error.empty()) {\n \t\tthrow InvalidInputException(\"Could not parse DATEFORMAT: %s\", error.c_str());\ndiff --git a/src/function/table/copy_csv.cpp b/src/function/table/copy_csv.cpp\nindex b3ba6eabf4b5..6216e3441b01 100644\n--- a/src/function/table/copy_csv.cpp\n+++ b/src/function/table/copy_csv.cpp\n@@ -12,6 +12,14 @@\n #include \"duckdb/function/scalar/string_functions.hpp\"\n #include \"duckdb/function/table/read_csv.hpp\"\n #include \"duckdb/parser/parsed_data/copy_info.hpp\"\n+#include \"duckdb/parser/expression/cast_expression.hpp\"\n+#include \"duckdb/parser/expression/function_expression.hpp\"\n+#include \"duckdb/parser/expression/columnref_expression.hpp\"\n+#include \"duckdb/parser/expression/constant_expression.hpp\"\n+#include \"duckdb/parser/expression/bound_expression.hpp\"\n+#include \"duckdb/planner/expression/bound_reference_expression.hpp\"\n+#include \"duckdb/execution/column_binding_resolver.hpp\"\n+#include \"duckdb/planner/operator/logical_dummy_scan.hpp\"\n #include <limits>\n \n namespace duckdb {\n@@ -93,6 +101,62 @@ string TransformNewLine(string new_line) {\n \t;\n }\n \n+static vector<unique_ptr<Expression>> CreateCastExpressions(WriteCSVData &bind_data, ClientContext &context,\n+                                                            const vector<string> &names,\n+                                                            const vector<LogicalType> &sql_types) {\n+\tauto &options = bind_data.options;\n+\tauto &formats = options.write_date_format;\n+\n+\tbool has_dateformat = !formats[LogicalTypeId::DATE].IsNull();\n+\tbool has_timestampformat = !formats[LogicalTypeId::TIMESTAMP].IsNull();\n+\n+\t// Create a binder\n+\tauto binder = Binder::CreateBinder(context);\n+\n+\tauto &bind_context = binder->bind_context;\n+\tauto table_index = binder->GenerateTableIndex();\n+\tbind_context.AddGenericBinding(table_index, \"copy_csv\", names, sql_types);\n+\n+\t// Create the ParsedExpressions (cast, strftime, etc..)\n+\tvector<unique_ptr<ParsedExpression>> unbound_expressions;\n+\tfor (idx_t i = 0; i < sql_types.size(); i++) {\n+\t\tauto &type = sql_types[i];\n+\t\tauto &name = names[i];\n+\n+\t\tbool is_timestamp = type.id() == LogicalTypeId::TIMESTAMP || type.id() == LogicalTypeId::TIMESTAMP_TZ;\n+\t\tif (has_dateformat && type.id() == LogicalTypeId::DATE) {\n+\t\t\t// strftime(<name>, 'format')\n+\t\t\tvector<unique_ptr<ParsedExpression>> children;\n+\t\t\tchildren.push_back(make_uniq<BoundExpression>(make_uniq<BoundReferenceExpression>(name, type, i)));\n+\t\t\tchildren.push_back(make_uniq<ConstantExpression>(formats[LogicalTypeId::DATE]));\n+\t\t\tauto func = make_uniq_base<ParsedExpression, FunctionExpression>(\"strftime\", std::move(children));\n+\t\t\tunbound_expressions.push_back(std::move(func));\n+\t\t} else if (has_timestampformat && is_timestamp) {\n+\t\t\t// strftime(<name>, 'format')\n+\t\t\tvector<unique_ptr<ParsedExpression>> children;\n+\t\t\tchildren.push_back(make_uniq<BoundExpression>(make_uniq<BoundReferenceExpression>(name, type, i)));\n+\t\t\tchildren.push_back(make_uniq<ConstantExpression>(formats[LogicalTypeId::TIMESTAMP]));\n+\t\t\tauto func = make_uniq_base<ParsedExpression, FunctionExpression>(\"strftime\", std::move(children));\n+\t\t\tunbound_expressions.push_back(std::move(func));\n+\t\t} else {\n+\t\t\t// CAST <name> AS VARCHAR\n+\t\t\tauto column = make_uniq<BoundExpression>(make_uniq<BoundReferenceExpression>(name, type, i));\n+\t\t\tauto expr = make_uniq_base<ParsedExpression, CastExpression>(LogicalType::VARCHAR, std::move(column));\n+\t\t\tunbound_expressions.push_back(std::move(expr));\n+\t\t}\n+\t}\n+\n+\t// Create an ExpressionBinder, bind the Expressions\n+\tvector<unique_ptr<Expression>> expressions;\n+\tExpressionBinder expression_binder(*binder, context);\n+\texpression_binder.target_type = LogicalType::VARCHAR;\n+\tfor (auto &expr : unbound_expressions) {\n+\t\texpressions.push_back(expression_binder.Bind(expr));\n+\t}\n+\n+\treturn expressions;\n+}\n+\n static unique_ptr<FunctionData> WriteCSVBind(ClientContext &context, CopyFunctionBindInput &input,\n                                              const vector<string> &names, const vector<LogicalType> &sql_types) {\n \tauto bind_data = make_uniq<WriteCSVData>(input.info.file_path, sql_types, names);\n@@ -110,6 +174,9 @@ static unique_ptr<FunctionData> WriteCSVBind(ClientContext &context, CopyFunctio\n \t}\n \tbind_data->Finalize();\n \n+\tauto expressions = CreateCastExpressions(*bind_data, context, names, sql_types);\n+\tbind_data->cast_expressions = std::move(expressions);\n+\n \tbind_data->requires_quotes = make_unsafe_uniq_array<bool>(256);\n \tmemset(bind_data->requires_quotes.get(), 0, sizeof(bool) * 256);\n \tbind_data->requires_quotes['\\n'] = true;\n@@ -264,6 +331,14 @@ static void WriteQuotedString(WriteStream &writer, WriteCSVData &csv_data, const\n // Sink\n //===--------------------------------------------------------------------===//\n struct LocalWriteCSVData : public LocalFunctionData {\n+public:\n+\tLocalWriteCSVData(ClientContext &context, vector<unique_ptr<Expression>> &expressions)\n+\t    : executor(context, expressions) {\n+\t}\n+\n+public:\n+\t//! Used to execute the expressions that transform input -> string\n+\tExpressionExecutor executor;\n \t//! The thread-local buffer to write data into\n \tMemoryStream stream;\n \t//! A chunk with VARCHAR columns to cast intermediates into\n@@ -316,7 +391,7 @@ struct GlobalWriteCSVData : public GlobalFunctionData {\n \n static unique_ptr<LocalFunctionData> WriteCSVInitializeLocal(ExecutionContext &context, FunctionData &bind_data) {\n \tauto &csv_data = bind_data.Cast<WriteCSVData>();\n-\tauto local_data = make_uniq<LocalWriteCSVData>();\n+\tauto local_data = make_uniq<LocalWriteCSVData>(context.client, csv_data.cast_expressions);\n \n \t// create the chunk with VARCHAR types\n \tvector<LogicalType> types;\n@@ -361,33 +436,16 @@ idx_t WriteCSVFileSize(GlobalFunctionData &gstate) {\n }\n \n static void WriteCSVChunkInternal(ClientContext &context, FunctionData &bind_data, DataChunk &cast_chunk,\n-                                  MemoryStream &writer, DataChunk &input, bool &written_anything) {\n+                                  MemoryStream &writer, DataChunk &input, bool &written_anything,\n+                                  ExpressionExecutor &executor) {\n \tauto &csv_data = bind_data.Cast<WriteCSVData>();\n \tauto &options = csv_data.options;\n \n \t// first cast the columns of the chunk to varchar\n \tcast_chunk.Reset();\n \tcast_chunk.SetCardinality(input);\n-\tfor (idx_t col_idx = 0; col_idx < input.ColumnCount(); col_idx++) {\n-\t\tif (csv_data.sql_types[col_idx].id() == LogicalTypeId::VARCHAR) {\n-\t\t\t// VARCHAR, just reinterpret (cannot reference, because LogicalTypeId::VARCHAR is used by the JSON type too)\n-\t\t\tcast_chunk.data[col_idx].Reinterpret(input.data[col_idx]);\n-\t\t} else if (!csv_data.options.write_date_format[LogicalTypeId::DATE].Empty() &&\n-\t\t           csv_data.sql_types[col_idx].id() == LogicalTypeId::DATE) {\n-\t\t\t// use the date format to cast the chunk\n-\t\t\tcsv_data.options.write_date_format[LogicalTypeId::DATE].ConvertDateVector(\n-\t\t\t    input.data[col_idx], cast_chunk.data[col_idx], input.size());\n-\t\t} else if (!csv_data.options.write_date_format[LogicalTypeId::TIMESTAMP].Empty() &&\n-\t\t           (csv_data.sql_types[col_idx].id() == LogicalTypeId::TIMESTAMP ||\n-\t\t            csv_data.sql_types[col_idx].id() == LogicalTypeId::TIMESTAMP_TZ)) {\n-\t\t\t// use the timestamp format to cast the chunk\n-\t\t\tcsv_data.options.write_date_format[LogicalTypeId::TIMESTAMP].ConvertTimestampVector(\n-\t\t\t    input.data[col_idx], cast_chunk.data[col_idx], input.size());\n-\t\t} else {\n-\t\t\t// non varchar column, perform the cast\n-\t\t\tVectorOperations::Cast(context, input.data[col_idx], cast_chunk.data[col_idx], input.size());\n-\t\t}\n-\t}\n+\n+\texecutor.Execute(input, cast_chunk);\n \n \tcast_chunk.Flatten();\n \t// now loop over the vectors and output the values\n@@ -428,7 +486,7 @@ static void WriteCSVSink(ExecutionContext &context, FunctionData &bind_data, Glo\n \n \t// write data into the local buffer\n \tWriteCSVChunkInternal(context.client, bind_data, local_data.cast_chunk, local_data.stream, input,\n-\t                      local_data.written_anything);\n+\t                      local_data.written_anything, local_data.executor);\n \n \t// check if we should flush what we have currently written\n \tauto &writer = local_data.stream;\n@@ -506,11 +564,15 @@ unique_ptr<PreparedBatchData> WriteCSVPrepareBatch(ClientContext &context, Funct\n \tDataChunk cast_chunk;\n \tcast_chunk.Initialize(Allocator::Get(context), types);\n \n+\tauto &original_types = collection->Types();\n+\tauto expressions = CreateCastExpressions(csv_data, context, csv_data.options.name_list, original_types);\n+\tExpressionExecutor executor(context, expressions);\n+\n \t// write CSV chunks to the batch data\n \tbool written_anything = false;\n \tauto batch = make_uniq<WriteCSVBatchData>();\n \tfor (auto &chunk : collection->Chunks()) {\n-\t\tWriteCSVChunkInternal(context, bind_data, cast_chunk, batch->stream, chunk, written_anything);\n+\t\tWriteCSVChunkInternal(context, bind_data, cast_chunk, batch->stream, chunk, written_anything, executor);\n \t}\n \treturn std::move(batch);\n }\ndiff --git a/src/include/duckdb/execution/operator/csv_scanner/csv_reader_options.hpp b/src/include/duckdb/execution/operator/csv_scanner/csv_reader_options.hpp\nindex d929fb721aaf..65ae58f0e0e5 100644\n--- a/src/include/duckdb/execution/operator/csv_scanner/csv_reader_options.hpp\n+++ b/src/include/duckdb/execution/operator/csv_scanner/csv_reader_options.hpp\n@@ -123,7 +123,7 @@ struct CSVReaderOptions {\n \t//! The date format to use (if any is specified)\n \tmap<LogicalTypeId, StrpTimeFormat> date_format = {{LogicalTypeId::DATE, {}}, {LogicalTypeId::TIMESTAMP, {}}};\n \t//! The date format to use for writing (if any is specified)\n-\tmap<LogicalTypeId, StrfTimeFormat> write_date_format = {{LogicalTypeId::DATE, {}}, {LogicalTypeId::TIMESTAMP, {}}};\n+\tmap<LogicalTypeId, Value> write_date_format = {{LogicalTypeId::DATE, Value()}, {LogicalTypeId::TIMESTAMP, Value()}};\n \t//! Whether or not a type format is specified\n \tmap<LogicalTypeId, bool> has_format = {{LogicalTypeId::DATE, false}, {LogicalTypeId::TIMESTAMP, false}};\n \ndiff --git a/src/include/duckdb/function/table/read_csv.hpp b/src/include/duckdb/function/table/read_csv.hpp\nindex aeb5050214fe..272fbbf68550 100644\n--- a/src/include/duckdb/function/table/read_csv.hpp\n+++ b/src/include/duckdb/function/table/read_csv.hpp\n@@ -56,6 +56,8 @@ struct WriteCSVData : public BaseCSVData {\n \tidx_t flush_size = 4096ULL * 8ULL;\n \t//! For each byte whether or not the CSV file requires quotes when containing the byte\n \tunsafe_unique_array<bool> requires_quotes;\n+\t//! Expressions used to convert the input into strings\n+\tvector<unique_ptr<Expression>> cast_expressions;\n };\n \n struct ColumnInfo {\n",
  "test_patch": "diff --git a/test/sql/copy/csv/test_csv_timestamp_tz.test b/test/sql/copy/csv/test_csv_timestamp_tz.test\nindex 6bc16ad0df7e..36728603706c 100644\n--- a/test/sql/copy/csv/test_csv_timestamp_tz.test\n+++ b/test/sql/copy/csv/test_csv_timestamp_tz.test\n@@ -5,14 +5,9 @@\n statement ok\n pragma enable_verification\n \n-statement ok\n+statement error\n copy (\n select '2021-05-25 04:55:03.382494 UTC'::timestamp as ts, '2021-05-25 04:55:03.382494 UTC'::timestamptz as tstz\n ) to '__TEST_DIR__/timestamps.csv' ( timestampformat '%A');\n-\n-\n-query II\n-select * from read_csv_auto('__TEST_DIR__/timestamps.csv');\n ----\n-Tuesday\tTuesday\n-\n+No function matches the given name and argument types\ndiff --git a/test/sql/copy/csv/test_csv_timestamp_tz_icu.test b/test/sql/copy/csv/test_csv_timestamp_tz_icu.test\nnew file mode 100644\nindex 000000000000..f24d9f799147\n--- /dev/null\n+++ b/test/sql/copy/csv/test_csv_timestamp_tz_icu.test\n@@ -0,0 +1,24 @@\n+# name: test/sql/copy/csv/test_csv_timestamp_tz_icu.test\n+# description: Test CSV with timestamp_tz and timestampformat\n+# group: [csv]\n+\n+statement ok\n+pragma enable_verification\n+\n+require icu\n+\n+statement ok\n+SET Calendar = 'gregorian';\n+\n+statement ok\n+SET TimeZone = 'America/Los_Angeles';\n+\n+statement ok\n+COPY (\n+    SELECT make_timestamptz(1713193669561000) AS t\n+) TO '__TEST_DIR__/timestamp-format.csv' (FORMAT CSV, timestampformat '%x %X.%g%z');\n+\n+query I\n+select * from read_csv('__TEST_DIR__/timestamp-format.csv', all_varchar=true)\n+----\n+2024-04-15 08:07:49.561-07\n",
  "problem_statement": "timestampformat option for csv copy ignores configured timezone with timestamptz\n### What happens?\r\n\r\nThe `timestampformat` argument described [here](https://duckdb.org/docs/sql/statements/copy#csv-options) allows you to customize the formatting of timestamps when converting to CSV but it ignores the configured TimeZone. When converting to CSV without specifying the `timestampformat`, the generated string uses the configured TimeZone.  When converting to CSV and specifying the `timestampformat`, however, the generated string ignores the configured TimeZone and writes the timestamp in UTC.\r\n\r\n### To Reproduce\r\n\r\nWith the TimeZone set to `America/Phoenix`:\r\n\r\n```sql\r\nCOPY (\r\n    SELECT make_timestamptz(1713193669561000) AS t\r\n) TO 'timestamp-noformat.csv' (FORMAT CSV);\r\n```\r\ngenerates `2024-04-15 08:07:49.561-07`. Note the `-07` timezone offset.\r\n```sql\r\nCOPY (\r\n    SELECT make_timestamptz(1713193669561000) AS t\r\n) TO 'timestamp-format.csv' (FORMAT CSV, timestampformat '%x %X.%g%z');\r\n```\r\ngenerates `2024-04-15 15:07:49.561+00`.  Note that the timezone offset is now `+00` even though the TimeZone is set to `America/Phoenix`.\r\n\r\n\r\n\r\n### OS:\r\n\r\nWindows, Linux\r\n\r\n### DuckDB Version:\r\n\r\n0.10.1\r\n\r\n### DuckDB Client:\r\n\r\nJDBC\r\n\r\n### Full Name:\r\n\r\nTJ Brown\r\n\r\n### Affiliation:\r\n\r\nIntel\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\n",
  "hints_text": "`With the TimeZone set to America/Phoenix`\r\nThis can be done in multiple ways, please provide the code indicating the way you did it\r\n\r\nI have a hunch this might be related to <https://github.com/duckdb/duckdb/pull/11546>\nI hadn't explicitly set the TimeZone myself, but the following query\r\n```sql\r\nSELECT value\r\nFROM duckdb_settings()\r\nWHERE name = 'TimeZone';\r\n```\r\nreturns `America/Phoenix`.\r\n\nI think the cause is this:\r\n```c++\r\n   658                              Timestamp::Convert(input, date, time);\r\n   659                              idx_t len = GetLength(date, time, 0, nullptr);\r\n   660                              string_t target = StringVector::EmptyString(result, len);\r\n-> 661                              FormatString(date, time, target.GetDataWriteable());\r\n   662                              target.Finalize();\r\n   663                              return target;\r\n   664                      } else {\r\n```\r\n\r\nThis has a version which takes a timezone, but that is never used here\nIt can't use the TZ because it doesn't know how to do the conversion from the instant in the column to the offset value. ICU overrides `strftime` for TSTZ in `ICUStrftime::Operation` and does exactly this. So I would say the problem is here:\r\n\r\n```cpp\r\n\t\t} else if (!csv_data.options.write_date_format[LogicalTypeId::TIMESTAMP].Empty() &&\r\n\t\t           (csv_data.sql_types[col_idx].id() == LogicalTypeId::TIMESTAMP ||\r\n\t\t            csv_data.sql_types[col_idx].id() == LogicalTypeId::TIMESTAMP_TZ)) {\r\n\t\t\t// use the timestamp format to cast the chunk\r\n=>\t\t\tcsv_data.options.write_date_format[LogicalTypeId::TIMESTAMP].ConvertTimestampVector(\r\n\t\t\t    input.data[col_idx], cast_chunk.data[col_idx], input.size());\r\n\t\t} else {\r\n```\r\n\r\nas this function is not extension-aware.\n> It can't use the TZ because it doesn't know how to do the conversion from the instant in the column to the offset value. ICU overrides `strftime` for TSTZ in `ICUStrftime::Operation` and does exactly this. So I would say the problem is here:\r\n> \r\n> ```c++\r\n> \t\t} else if (!csv_data.options.write_date_format[LogicalTypeId::TIMESTAMP].Empty() &&\r\n> \t\t           (csv_data.sql_types[col_idx].id() == LogicalTypeId::TIMESTAMP ||\r\n> \t\t            csv_data.sql_types[col_idx].id() == LogicalTypeId::TIMESTAMP_TZ)) {\r\n> \t\t\t// use the timestamp format to cast the chunk\r\n> =>\t\t\tcsv_data.options.write_date_format[LogicalTypeId::TIMESTAMP].ConvertTimestampVector(\r\n> \t\t\t    input.data[col_idx], cast_chunk.data[col_idx], input.size());\r\n> \t\t} else {\r\n> ```\r\n> \r\n> as this function is not extension-aware.\r\n\r\nIf we want to support this:\r\n\r\nI wonder if we need to make the `CopyFunctionCatalogEntry` more modular\r\nSo CSV/JSON etc would create a `CopyFunctionCatalogEntry`, this contains a CatalogSet and inside that you can register `CopyFunctionFormatCatalogEntry` entries, then we could autoload the CopyFunctionFormatCatalogEntry for TZ when required.\r\n\r\nThough this is part of a bigger problem of interleaving extensions (even though CSV isn't an extension, it still makes use of the Catalog to be discovered)\n> ...\r\n> \r\n> as this function is not extension-aware.\r\n\r\nThough, thinking more about this, we have Cast functions registered by ICU right?\r\nI imagine that's how the CSV COPY would solve this, by looking up the Cast function and using that?\n> > ...\r\n> > as this function is not extension-aware.\r\n> \r\n> Though, thinking more about this, we have Cast functions registered by ICU right? I imagine that's how the CSV COPY would solve this, by looking up the Cast function and using that?\r\n\r\nCasting doesn't take a format, but ICU also overrides `strptime` so maybe we could hook into that? Looking at the builtin `strptime`, it is just a wrapper for `ConvertTimestampVector`, so it wouldn't be a big change.",
  "created_at": "2024-04-18T10:08:08Z"
}