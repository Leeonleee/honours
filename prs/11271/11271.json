{
  "repo": "duckdb/duckdb",
  "pull_number": 11271,
  "instance_id": "duckdb__duckdb-11271",
  "issue_numbers": [
    "10751"
  ],
  "base_commit": "5f74399a0e7a93609546ecc86b2ae9285dffcb7d",
  "patch": "diff --git a/data/json/10751.json b/data/json/10751.json\nnew file mode 100644\nindex 000000000000..e07f69051995\n--- /dev/null\n+++ b/data/json/10751.json\n@@ -0,0 +1,3 @@\n+{\"event\":\"Event Started\",\"properties\":{\"time\":1707878164,\"distinct_id\":\"20110941\",\"$app_version_string\":\"9.10.1\",\"$city\":\"Cookstown\",\"$insert_id\":\"244b811e-378a-5444-b373-d1a5d6e9bba0\",\"$os\":\"Android\",\"Platform\":\"google\",\"audio\":97257,\"collection\":1438,\"guide\":389,\"id\":\"20110474\",\"ipCountry\":\"GB\",\"length\":\"12 min\",\"platform\":\"google\",\"event_id\":1037203}}\n+{\"event\":\"Event Started\",\"properties\":{\"time\":1707868801,\"distinct_id\":\"11456737\",\"$app_version_string\":\"9.10.1\",\"$city\":\"El Paso\",\"$insert_id\":\"7a36c4d4-267a-5090-a06b-8b90824bc8d8\",\"$os\":\"Android\",\"Platform\":\"google\",\"audio\":38043,\"collection\":371,\"guide\":73,\"id\":\"11456737\",\"ipCountry\":\"US\",\"length\":\"1 min\",\"platform\":\"google\",\"event_id\":1004067}}\n+{\"event\":\"Event Started\",\"properties\":{\"time\":1707868829,\"distinct_id\":\"11456737\",\"$app_version_string\":\"9.10.1\",\"$city\":\"El Paso\",\"$insert_id\":\"e25220b3-068c-520f-84a8-dbd7320068c7\",\"$os\":\"Android\",\"Platform\":\"google\",\"audio\":38042,\"collection\":371,\"guide\":73,\"id\":\"11456737\",\"ipCountry\":\"US\",\"length\":\"1 min\",\"platform\":\"google\",\"event_id\":1004068}}\n\\ No newline at end of file\ndiff --git a/data/json/11152.json b/data/json/11152.json\nnew file mode 100644\nindex 000000000000..24fcca6b8f17\n--- /dev/null\n+++ b/data/json/11152.json\n@@ -0,0 +1,5 @@\n+{\"fileSize\": 9798,\"totalStreamRespTimeMs\": 27,\"lastSyncDiffMs\": 1040, \"fileSize\": 3266,\"totalStreamRespTimeMs\": 0,\"lastSyncDiffMs\": 307, \"fileSize\": 3266,\"totalStreamRespTimeMs\": 0,\"lastSyncDiffMs\": 307, \"fileSize\": 3266,\"totalStreamRespTimeMs\": 0,\"lastSyncDiffMs\": 307}\n+{\"fileSize\": 13064,\"totalStreamRespTimeMs\": 1,\"lastSyncDiffMs\": 1409}\n+{\"crap\": 13064,\"tmeMs\": 1,\"lastSy\": 1409, \"blaa\": \"bar\"}\n+{\"errorsToo\",\"notparsing\",\"badJSON\"}\n+\ndiff --git a/extension/json/include/json_structure.hpp b/extension/json/include/json_structure.hpp\nindex 7fcd43b35fe2..1f0087778d74 100644\n--- a/extension/json/include/json_structure.hpp\n+++ b/extension/json/include/json_structure.hpp\n@@ -19,7 +19,7 @@ struct StrpTimeFormat;\n struct JSONStructureNode {\n public:\n \tJSONStructureNode();\n-\tJSONStructureNode(yyjson_val *key_p, yyjson_val *val_p);\n+\tJSONStructureNode(yyjson_val *key_p, yyjson_val *val_p, const bool ignore_errors);\n \n \t//! Disable copy constructors\n \tJSONStructureNode(const JSONStructureNode &other) = delete;\n@@ -64,7 +64,7 @@ struct JSONStructureDescription {\n \tJSONStructureDescription &operator=(JSONStructureDescription &&) noexcept;\n \n \tJSONStructureNode &GetOrCreateChild();\n-\tJSONStructureNode &GetOrCreateChild(yyjson_val *key, yyjson_val *val);\n+\tJSONStructureNode &GetOrCreateChild(yyjson_val *key, yyjson_val *val, const bool ignore_errors);\n \n public:\n \t//! Type of this description\n@@ -80,7 +80,7 @@ struct JSONStructureDescription {\n \n struct JSONStructure {\n public:\n-\tstatic void ExtractStructure(yyjson_val *val, JSONStructureNode &node);\n+\tstatic void ExtractStructure(yyjson_val *val, JSONStructureNode &node, const bool ignore_errors);\n \tstatic LogicalType StructureToType(ClientContext &context, const JSONStructureNode &node, const idx_t max_depth,\n \t                                   const double field_appearance_threshold, idx_t depth = 0,\n \t                                   idx_t sample_count = DConstants::INVALID_INDEX);\ndiff --git a/extension/json/json_functions/json_structure.cpp b/extension/json/json_functions/json_structure.cpp\nindex ad319c6a9469..0fd574f898e0 100644\n--- a/extension/json/json_functions/json_structure.cpp\n+++ b/extension/json/json_functions/json_structure.cpp\n@@ -22,10 +22,10 @@ static inline LogicalTypeId MaxNumericType(LogicalTypeId &a, LogicalTypeId &b) {\n JSONStructureNode::JSONStructureNode() : initialized(false), count(0) {\n }\n \n-JSONStructureNode::JSONStructureNode(yyjson_val *key_p, yyjson_val *val_p)\n+JSONStructureNode::JSONStructureNode(yyjson_val *key_p, yyjson_val *val_p, const bool ignore_errors)\n     : key(make_uniq<string>(unsafe_yyjson_get_str(key_p), unsafe_yyjson_get_len(key_p))), initialized(false), count(0) {\n \tD_ASSERT(yyjson_is_str(key_p));\n-\tJSONStructure::ExtractStructure(val_p, *this);\n+\tJSONStructure::ExtractStructure(val_p, *this, ignore_errors);\n }\n \n JSONStructureNode::JSONStructureNode(JSONStructureNode &&other) noexcept {\n@@ -351,7 +351,8 @@ JSONStructureNode &JSONStructureDescription::GetOrCreateChild() {\n \treturn children.back();\n }\n \n-JSONStructureNode &JSONStructureDescription::GetOrCreateChild(yyjson_val *key, yyjson_val *val) {\n+JSONStructureNode &JSONStructureDescription::GetOrCreateChild(yyjson_val *key, yyjson_val *val,\n+                                                              const bool ignore_errors) {\n \tD_ASSERT(yyjson_is_str(key));\n \t// Check if there is already a child with the same key\n \tidx_t child_idx;\n@@ -359,18 +360,18 @@ JSONStructureNode &JSONStructureDescription::GetOrCreateChild(yyjson_val *key, y\n \tauto it = key_map.find(temp_key);\n \tif (it == key_map.end()) { // Didn't find, create a new child\n \t\tchild_idx = children.size();\n-\t\tchildren.emplace_back(key, val);\n+\t\tchildren.emplace_back(key, val, ignore_errors);\n \t\tconst auto &persistent_key_string = children.back().key;\n \t\tJSONKey new_key {persistent_key_string->c_str(), persistent_key_string->length()};\n \t\tkey_map.emplace(new_key, child_idx);\n \t} else { // Found it\n \t\tchild_idx = it->second;\n-\t\tJSONStructure::ExtractStructure(val, children[child_idx]);\n+\t\tJSONStructure::ExtractStructure(val, children[child_idx], ignore_errors);\n \t}\n \treturn children[child_idx];\n }\n \n-static inline void ExtractStructureArray(yyjson_val *arr, JSONStructureNode &node) {\n+static inline void ExtractStructureArray(yyjson_val *arr, JSONStructureNode &node, const bool ignore_errors) {\n \tD_ASSERT(yyjson_is_arr(arr));\n \tauto &description = node.GetOrCreateDescription(LogicalTypeId::LIST);\n \tauto &child = description.GetOrCreateChild();\n@@ -378,50 +379,50 @@ static inline void ExtractStructureArray(yyjson_val *arr, JSONStructureNode &nod\n \tsize_t idx, max;\n \tyyjson_val *val;\n \tyyjson_arr_foreach(arr, idx, max, val) {\n-\t\tJSONStructure::ExtractStructure(val, child);\n+\t\tJSONStructure::ExtractStructure(val, child, ignore_errors);\n \t}\n }\n \n-static inline void ExtractStructureObject(yyjson_val *obj, JSONStructureNode &node) {\n+static inline void ExtractStructureObject(yyjson_val *obj, JSONStructureNode &node, const bool ignore_errors) {\n \tD_ASSERT(yyjson_is_obj(obj));\n \tauto &description = node.GetOrCreateDescription(LogicalTypeId::STRUCT);\n \n \t// Keep track of keys so we can detect duplicates\n-\tjson_key_set_t obj_keys;\n+\tcase_insensitive_set_t obj_keys;\n \n \tsize_t idx, max;\n \tyyjson_val *key, *val;\n \tyyjson_obj_foreach(obj, idx, max, key, val) {\n \t\tauto key_ptr = unsafe_yyjson_get_str(key);\n \t\tauto key_len = unsafe_yyjson_get_len(key);\n-\t\tauto insert_result = obj_keys.insert({key_ptr, key_len});\n-\t\tif (!insert_result.second) {\n+\t\tauto insert_result = obj_keys.insert(string(key_ptr, key_len));\n+\t\tif (!ignore_errors && !insert_result.second) {\n \t\t\tJSONCommon::ThrowValFormatError(\"Duplicate key \\\"\" + string(key_ptr, key_len) + \"\\\" in object %s\", obj);\n \t\t}\n-\t\tdescription.GetOrCreateChild(key, val);\n+\t\tdescription.GetOrCreateChild(key, val, ignore_errors);\n \t}\n }\n \n-static inline void ExtractStructureVal(yyjson_val *val, JSONStructureNode &node) {\n+static inline void ExtractStructureVal(yyjson_val *val, JSONStructureNode &node, const bool ignore_errors) {\n \tD_ASSERT(!yyjson_is_arr(val) && !yyjson_is_obj(val));\n \tnode.GetOrCreateDescription(JSONCommon::ValTypeToLogicalTypeId(val));\n }\n \n-void JSONStructure::ExtractStructure(yyjson_val *val, JSONStructureNode &node) {\n+void JSONStructure::ExtractStructure(yyjson_val *val, JSONStructureNode &node, const bool ignore_errors) {\n \tnode.count++;\n \tswitch (yyjson_get_tag(val)) {\n \tcase YYJSON_TYPE_ARR | YYJSON_SUBTYPE_NONE:\n-\t\treturn ExtractStructureArray(val, node);\n+\t\treturn ExtractStructureArray(val, node, ignore_errors);\n \tcase YYJSON_TYPE_OBJ | YYJSON_SUBTYPE_NONE:\n-\t\treturn ExtractStructureObject(val, node);\n+\t\treturn ExtractStructureObject(val, node, ignore_errors);\n \tdefault:\n-\t\treturn ExtractStructureVal(val, node);\n+\t\treturn ExtractStructureVal(val, node, ignore_errors);\n \t}\n }\n \n-JSONStructureNode ExtractStructureInternal(yyjson_val *val) {\n+JSONStructureNode ExtractStructureInternal(yyjson_val *val, const bool ignore_errors) {\n \tJSONStructureNode node;\n-\tJSONStructure::ExtractStructure(val, node);\n+\tJSONStructure::ExtractStructure(val, node, ignore_errors);\n \treturn node;\n }\n \n@@ -476,7 +477,7 @@ static inline yyjson_mut_val *ConvertStructure(const JSONStructureNode &node, yy\n \n static inline string_t JSONStructureFunction(yyjson_val *val, yyjson_alc *alc, Vector &result) {\n \treturn JSONCommon::WriteVal<yyjson_mut_val>(\n-\t    ConvertStructure(ExtractStructureInternal(val), yyjson_mut_doc_new(alc)), alc);\n+\t    ConvertStructure(ExtractStructureInternal(val, false), yyjson_mut_doc_new(alc)), alc);\n }\n \n static void StructureFunction(DataChunk &args, ExpressionState &state, Vector &result) {\ndiff --git a/extension/json/json_functions/read_json.cpp b/extension/json/json_functions/read_json.cpp\nindex 8b331c8a7c26..4e8a2d746f6d 100644\n--- a/extension/json/json_functions/read_json.cpp\n+++ b/extension/json/json_functions/read_json.cpp\n@@ -6,6 +6,35 @@\n \n namespace duckdb {\n \n+static inline LogicalType RemoveDuplicateStructKeys(const LogicalType &type, const bool ignore_errors) {\n+\tswitch (type.id()) {\n+\tcase LogicalTypeId::STRUCT: {\n+\t\tcase_insensitive_set_t child_names;\n+\t\tchild_list_t<LogicalType> child_types;\n+\t\tfor (auto &child_type : StructType::GetChildTypes(type)) {\n+\t\t\tauto insert_success = child_names.insert(child_type.first).second;\n+\t\t\tif (!insert_success) {\n+\t\t\t\tif (ignore_errors) {\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tthrow NotImplementedException(\n+\t\t\t\t    \"Duplicate name \\\"%s\\\" in struct auto-detected in JSON, try ignore_errors=true\", child_type.first);\n+\t\t\t} else {\n+\t\t\t\tchild_types.emplace_back(child_type.first, RemoveDuplicateStructKeys(child_type.second, ignore_errors));\n+\t\t\t}\n+\t\t}\n+\t\treturn LogicalType::STRUCT(child_types);\n+\t}\n+\tcase LogicalTypeId::MAP:\n+\t\treturn LogicalType::MAP(RemoveDuplicateStructKeys(MapType::KeyType(type), ignore_errors),\n+\t\t                        RemoveDuplicateStructKeys(MapType::ValueType(type), ignore_errors));\n+\tcase LogicalTypeId::LIST:\n+\t\treturn LogicalType::LIST(RemoveDuplicateStructKeys(ListType::GetChildType(type), ignore_errors));\n+\tdefault:\n+\t\treturn type;\n+\t}\n+}\n+\n void JSONScan::AutoDetect(ClientContext &context, JSONScanData &bind_data, vector<LogicalType> &return_types,\n                           vector<string> &names) {\n \t// Change scan type during detection\n@@ -40,7 +69,7 @@ void JSONScan::AutoDetect(ClientContext &context, JSONScanData &bind_data, vecto\n \t\t\tfor (idx_t i = 0; i < next; i++) {\n \t\t\t\tconst auto &val = lstate.values[i];\n \t\t\t\tif (val) {\n-\t\t\t\t\tJSONStructure::ExtractStructure(val, node);\n+\t\t\t\t\tJSONStructure::ExtractStructure(val, node, true);\n \t\t\t\t}\n \t\t\t}\n \t\t\tif (!node.ContainsVarchar()) { // Can't refine non-VARCHAR types\n@@ -94,7 +123,7 @@ void JSONScan::AutoDetect(ClientContext &context, JSONScanData &bind_data, vecto\n \t\t\treturn_types.reserve(child_types.size());\n \t\t\tnames.reserve(child_types.size());\n \t\t\tfor (auto &child_type : child_types) {\n-\t\t\t\treturn_types.emplace_back(child_type.second);\n+\t\t\t\treturn_types.emplace_back(RemoveDuplicateStructKeys(child_type.second, bind_data.ignore_errors));\n \t\t\t\tnames.emplace_back(child_type.first);\n \t\t\t}\n \t\t} else {\n@@ -103,7 +132,7 @@ void JSONScan::AutoDetect(ClientContext &context, JSONScanData &bind_data, vecto\n \t\t}\n \t} else {\n \t\tD_ASSERT(bind_data.options.record_type == JSONRecordType::VALUES);\n-\t\treturn_types.emplace_back(type);\n+\t\treturn_types.emplace_back(RemoveDuplicateStructKeys(type, bind_data.ignore_errors));\n \t\tnames.emplace_back(\"json\");\n \t}\n }\n",
  "test_patch": "diff --git a/test/sql/json/issues/issue10751and11152.test b/test/sql/json/issues/issue10751and11152.test\nnew file mode 100644\nindex 000000000000..1273e39962b7\n--- /dev/null\n+++ b/test/sql/json/issues/issue10751and11152.test\n@@ -0,0 +1,26 @@\n+# name: test/sql/json/issues/issue10751and11152.test\n+# description: Test issue 10751 and 11152 - Duplicate keys in JSON object ignore_errors\n+# group: [issues]\n+\n+require json\n+\n+# issue 10751\n+statement error\n+create or replace table json_test as select * from read_json_auto('data/json/10751.json', format = 'newline_delimited');\n+----\n+Not implemented Error: Duplicate name\n+\n+statement ok\n+create table json_test as select * from read_json_auto('data/json/10751.json', format = 'newline_delimited', ignore_errors=true);\n+\n+statement ok\n+select * from json_test;\n+\n+# issue 11152\n+statement error\n+FROM read_json_auto('data/json/11152.json');\n+----\n+Invalid Input Error: Malformed JSON\n+\n+statement ok\n+FROM read_json_auto('data/json/11152.json', ignore_errors=true);\n",
  "problem_statement": "`NotImplementedException` - Querying JSON file with duplicate column names crashes CLI \n### What happens?\r\n\r\nWhen querying a newline-delimited JSON file with `read_json_auto` DuckDB crashes with a `NotImplementedException`:\r\n\r\n```\r\nlibc++abi: terminating due to uncaught exception of type duckdb::NotImplementedException: {\"exception_type\":\"Not implemented\",\"exception_message\":\"Error while casting - duplicate name \\\"platform\\\" in struct\"}\r\n```\r\n\r\nThe column name `platform` is just the first of a number of the same kind of duplicates. They're duplicates in the sense that their lower cased representation matches - \"Platform\" == \"platform\". This jives with DuckDB elsewhere; i.e.,\r\n\r\n```\r\ncreate or replace table test as select 1 as id, struct_pack(platform := 2, \"Platform\" := 3);\r\nError: Binder Error: Duplicate struct entry name \"Platform\"\r\n```\r\n\r\nSo rejecting these is consistent. The bug is the lack of error handling or validation.\r\n\r\nIf the file is altered so that the field names are truly identical - `platform` == `platform` instead of `Platform` and `platform`, we get the expected behavior and no crash:\r\n\r\n```\r\nselect * from read_json_auto('bug_report.json', format = 'newline_delimited');\r\nError: Invalid Input Error: Duplicate key \"platform\" in object {\"time\":1707878164,\"distinct_id\":\"20110941\",\"$app_version_string\":\"9.10.1\",\"$city\":\"Cookstown\",\"$insert_id\":\"244b811e-378a-5444-b373-d1a5d6e9bba0\",\"$os\":\"Android\",\"platform\":\"google\",\"platform\":\"google\",\"event_id\":1037203}\r\n```\r\n\r\n### To Reproduce\r\n\r\nCreate a table with the [attached file](https://github.com/duckdb/duckdb/files/14334220/bug_report.json):\r\n\r\n```\r\ncreate table json_test as select * from read_json_auto('bug_report.json', format = 'newline_delimited');\r\n```\r\n\r\nQuery the newly created table:\r\n\r\n```\r\nselect * from json_test;\r\n```\r\n\r\n### OS:\r\n\r\nmacOS\r\n\r\n### DuckDB Version:\r\n\r\n0.10.0\r\n\r\n### DuckDB Client:\r\n\r\nCLI\r\n\r\n### Full Name:\r\n\r\nBrandon Freeman\r\n\r\n### Affiliation:\r\n\r\nHallow\r\n\r\n### Have you tried this on the latest [nightly build](https://duckdb.org/docs/installation/?version=main)?\r\n\r\nI have not tested with any build\r\n\r\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\r\n\r\n- [X] Yes, I have\n",
  "hints_text": "Thanks! Reproduced, we'll take a look.\nI have pushed a partial fix for this in https://github.com/duckdb/duckdb/pull/10881 that correctly renders an exception instead in this case instead of aborting. The JSON issue separately needs to be fixed, however.\nMight be related: https://github.com/duckdb/duckdb/issues/11152",
  "created_at": "2024-03-20T14:31:51Z"
}