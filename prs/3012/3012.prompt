You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
Correlated group on ANY subquery
#### What happens?
While this subquery crashes on MonetDB, it gives error on DuckDB :) The dependent join unnesting is not available for the ANY operator. If you consider this as a feature, please close the issue.

#### To Reproduce
CREATE TABLE t0 (c0 INT);
CREATE TABLE t1 (c0 INT);
INSERT INTO t0 VALUES (1);
INSERT INTO t1 VALUES (1);

SELECT 1 = ANY(SELECT 1 FROM t1 JOIN (SELECT count(*) GROUP BY t0.c0) AS x(x) ON TRUE) FROM t0;
Error: INTERNAL Error: Logical operator type "ANY_JOIN" for dependent join

#### Environment (please complete the following information):
 - OS: Linux
 - DuckDB Version: downloaded and compiled from the tip of master branch
 - DuckDB Client: Shell

#### Before Submitting

- [x] **Have you tried this on the latest `master` branch?**
* **Python**: `pip install duckdb --upgrade --pre`
* **R**: `install.packages("https://github.com/duckdb/duckdb/releases/download/master-builds/duckdb_r_src.tar.gz", repos = NULL)`
* **Other Platforms**: You can find binaries [here](https://github.com/duckdb/duckdb/releases/tag/master-builds) or compile from source.

- [x] **Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?**

Correlated group on ANY subquery
#### What happens?
While this subquery crashes on MonetDB, it gives error on DuckDB :) The dependent join unnesting is not available for the ANY operator. If you consider this as a feature, please close the issue.

#### To Reproduce
CREATE TABLE t0 (c0 INT);
CREATE TABLE t1 (c0 INT);
INSERT INTO t0 VALUES (1);
INSERT INTO t1 VALUES (1);

SELECT 1 = ANY(SELECT 1 FROM t1 JOIN (SELECT count(*) GROUP BY t0.c0) AS x(x) ON TRUE) FROM t0;
Error: INTERNAL Error: Logical operator type "ANY_JOIN" for dependent join

#### Environment (please complete the following information):
 - OS: Linux
 - DuckDB Version: downloaded and compiled from the tip of master branch
 - DuckDB Client: Shell

#### Before Submitting

- [x] **Have you tried this on the latest `master` branch?**
* **Python**: `pip install duckdb --upgrade --pre`
* **R**: `install.packages("https://github.com/duckdb/duckdb/releases/download/master-builds/duckdb_r_src.tar.gz", repos = NULL)`
* **Other Platforms**: You can find binaries [here](https://github.com/duckdb/duckdb/releases/tag/master-builds) or compile from source.

- [x] **Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?**


</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
3: </div>
4: <p>&nbsp;</p>
5: 
6: <p align="center">
7:   <a href="https://github.com/duckdb/duckdb/actions">
8:     <img src="https://github.com/cwida/duckdb/workflows/.github/workflows/main.yml/badge.svg?branch=master" alt=".github/workflows/main.yml">
9:   </a>
10:   <a href="https://www.codefactor.io/repository/github/cwida/duckdb">
11:     <img src="https://www.codefactor.io/repository/github/cwida/duckdb/badge" alt="CodeFactor"/>
12:   </a>
13:   <a href="https://app.codecov.io/gh/duckdb/duckdb">
14:     <img src="https://codecov.io/gh/duckdb/duckdb/branch/master/graph/badge.svg?token=FaxjcfFghN" alt="codecov"/>
15:   </a>
16:   <a href="https://discord.gg/tcvwpjfnZx">
17:     <img src="https://shields.io/discord/909674491309850675" alt="discord" />
18:   </a>
19: </p>
20: 
21: ## DuckDB
22: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on the goals of DuckDB, please refer to [the Why DuckDB page on our website](https://duckdb.org/why_duckdb).
23: 
24: ## Installation
25: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
26: 
27: ## Data Import
28: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
29: 
30: ```sql
31: SELECT * FROM 'myfile.csv';
32: SELECT * FROM 'myfile.parquet';
33: ```
34: 
35: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
36: 
37: ## SQL Reference
38: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
39: 
40: ## Development
41: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`.
42: 
43: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
44: 
45: 
[end of README.md]
[start of src/optimizer/statistics/operator/propagate_filter.cpp]
1: #include "duckdb/function/scalar/generic_functions.hpp"
2: #include "duckdb/optimizer/statistics_propagator.hpp"
3: #include "duckdb/planner/expression/bound_between_expression.hpp"
4: #include "duckdb/planner/expression/bound_columnref_expression.hpp"
5: #include "duckdb/planner/expression/bound_comparison_expression.hpp"
6: #include "duckdb/planner/expression/bound_constant_expression.hpp"
7: #include "duckdb/planner/operator/logical_filter.hpp"
8: #include "duckdb/storage/statistics/numeric_statistics.hpp"
9: 
10: namespace duckdb {
11: 
12: bool StatisticsPropagator::ExpressionIsConstant(Expression &expr, const Value &val) {
13: 	if (expr.GetExpressionClass() != ExpressionClass::BOUND_CONSTANT) {
14: 		return false;
15: 	}
16: 	auto &bound_constant = (BoundConstantExpression &)expr;
17: 	D_ASSERT(bound_constant.value.type() == val.type());
18: 	return bound_constant.value == val;
19: }
20: 
21: bool StatisticsPropagator::ExpressionIsConstantOrNull(Expression &expr, const Value &val) {
22: 	if (expr.GetExpressionClass() != ExpressionClass::BOUND_FUNCTION) {
23: 		return false;
24: 	}
25: 	auto &bound_function = (BoundFunctionExpression &)expr;
26: 	return ConstantOrNull::IsConstantOrNull(bound_function, val);
27: }
28: 
29: void StatisticsPropagator::SetStatisticsNotNull(ColumnBinding binding) {
30: 	auto entry = statistics_map.find(binding);
31: 	if (entry == statistics_map.end()) {
32: 		return;
33: 	}
34: 	entry->second->validity_stats = make_unique<ValidityStatistics>(false);
35: }
36: 
37: void StatisticsPropagator::UpdateFilterStatistics(BaseStatistics &stats, ExpressionType comparison_type,
38:                                                   const Value &constant) {
39: 	// any comparison filter removes all null values
40: 	stats.validity_stats = make_unique<ValidityStatistics>(false);
41: 	if (!stats.type.IsNumeric()) {
42: 		// don't handle non-numeric columns here (yet)
43: 		return;
44: 	}
45: 	auto &numeric_stats = (NumericStatistics &)stats;
46: 	if (numeric_stats.min.IsNull() || numeric_stats.max.IsNull()) {
47: 		// no stats available: skip this
48: 		return;
49: 	}
50: 	switch (comparison_type) {
51: 	case ExpressionType::COMPARE_LESSTHAN:
52: 	case ExpressionType::COMPARE_LESSTHANOREQUALTO:
53: 		// X < constant OR X <= constant
54: 		// max becomes the constant
55: 		numeric_stats.max = constant;
56: 		break;
57: 	case ExpressionType::COMPARE_GREATERTHAN:
58: 	case ExpressionType::COMPARE_GREATERTHANOREQUALTO:
59: 		// X > constant OR X >= constant
60: 		// min becomes the constant
61: 		numeric_stats.min = constant;
62: 		break;
63: 	case ExpressionType::COMPARE_EQUAL:
64: 		// X = constant
65: 		// both min and max become the constant
66: 		numeric_stats.min = constant;
67: 		numeric_stats.max = constant;
68: 		break;
69: 	default:
70: 		break;
71: 	}
72: }
73: 
74: void StatisticsPropagator::UpdateFilterStatistics(BaseStatistics &lstats, BaseStatistics &rstats,
75:                                                   ExpressionType comparison_type) {
76: 	// any comparison filter removes all null values
77: 	lstats.validity_stats = make_unique<ValidityStatistics>(false);
78: 	rstats.validity_stats = make_unique<ValidityStatistics>(false);
79: 	D_ASSERT(lstats.type == rstats.type);
80: 	if (!lstats.type.IsNumeric()) {
81: 		// don't handle non-numeric columns here (yet)
82: 		return;
83: 	}
84: 	auto &left_stats = (NumericStatistics &)lstats;
85: 	auto &right_stats = (NumericStatistics &)rstats;
86: 	if (left_stats.min.IsNull() || left_stats.max.IsNull() || right_stats.min.IsNull() || right_stats.max.IsNull()) {
87: 		// no stats available: skip this
88: 		return;
89: 	}
90: 	switch (comparison_type) {
91: 	case ExpressionType::COMPARE_LESSTHAN:
92: 	case ExpressionType::COMPARE_LESSTHANOREQUALTO:
93: 		// LEFT < RIGHT OR LEFT <= RIGHT
94: 		// we know that every value of left is smaller (or equal to) every value in right
95: 		// i.e. if we have left = [-50, 250] and right = [-100, 100]
96: 
97: 		// we know that left.max is AT MOST equal to right.max
98: 		// because any value in left that is BIGGER than right.max will not pass the filter
99: 		if (left_stats.max > right_stats.max) {
100: 			left_stats.max = right_stats.max;
101: 		}
102: 
103: 		// we also know that right.min is AT MOST equal to left.min
104: 		// because any value in right that is SMALLER than left.min will not pass the filter
105: 		if (right_stats.min < left_stats.min) {
106: 			right_stats.min = left_stats.min;
107: 		}
108: 		// so in our example, the bounds get updated as follows:
109: 		// left: [-50, 100], right: [-50, 100]
110: 		break;
111: 	case ExpressionType::COMPARE_GREATERTHAN:
112: 	case ExpressionType::COMPARE_GREATERTHANOREQUALTO:
113: 		// LEFT > RIGHT OR LEFT >= RIGHT
114: 		// we know that every value of left is bigger (or equal to) every value in right
115: 		// this is essentially the inverse of the less than (or equal to) scenario
116: 		if (right_stats.max > left_stats.max) {
117: 			right_stats.max = left_stats.max;
118: 		}
119: 		if (left_stats.min < right_stats.min) {
120: 			left_stats.min = right_stats.min;
121: 		}
122: 		break;
123: 	case ExpressionType::COMPARE_EQUAL:
124: 		// LEFT = RIGHT
125: 		// only the tightest bounds pass
126: 		// so if we have e.g. left = [-50, 250] and right = [-100, 100]
127: 		// the tighest bounds are [-50, 100]
128: 		// select the highest min
129: 		if (left_stats.min > right_stats.min) {
130: 			right_stats.min = left_stats.min;
131: 		} else {
132: 			left_stats.min = right_stats.min;
133: 		}
134: 		// select the lowest max
135: 		if (left_stats.max < right_stats.max) {
136: 			right_stats.max = left_stats.max;
137: 		} else {
138: 			left_stats.max = right_stats.max;
139: 		}
140: 		break;
141: 	default:
142: 		break;
143: 	}
144: }
145: 
146: void StatisticsPropagator::UpdateFilterStatistics(Expression &left, Expression &right, ExpressionType comparison_type) {
147: 	// first check if either side is a bound column ref
148: 	// any column ref involved in a comparison will not be null after the comparison
149: 	if (left.type == ExpressionType::BOUND_COLUMN_REF) {
150: 		SetStatisticsNotNull(((BoundColumnRefExpression &)left).binding);
151: 	}
152: 	if (right.type == ExpressionType::BOUND_COLUMN_REF) {
153: 		SetStatisticsNotNull(((BoundColumnRefExpression &)right).binding);
154: 	}
155: 	// check if this is a comparison between a constant and a column ref
156: 	BoundConstantExpression *constant = nullptr;
157: 	BoundColumnRefExpression *columnref = nullptr;
158: 	if (left.type == ExpressionType::VALUE_CONSTANT && right.type == ExpressionType::BOUND_COLUMN_REF) {
159: 		constant = (BoundConstantExpression *)&left;
160: 		columnref = (BoundColumnRefExpression *)&right;
161: 		comparison_type = FlipComparisionExpression(comparison_type);
162: 	} else if (left.type == ExpressionType::BOUND_COLUMN_REF && right.type == ExpressionType::VALUE_CONSTANT) {
163: 		columnref = (BoundColumnRefExpression *)&left;
164: 		constant = (BoundConstantExpression *)&right;
165: 	} else if (left.type == ExpressionType::BOUND_COLUMN_REF && right.type == ExpressionType::BOUND_COLUMN_REF) {
166: 		// comparison between two column refs
167: 		auto &left_column_ref = (BoundColumnRefExpression &)left;
168: 		auto &right_column_ref = (BoundColumnRefExpression &)right;
169: 		auto lentry = statistics_map.find(left_column_ref.binding);
170: 		auto rentry = statistics_map.find(right_column_ref.binding);
171: 		if (lentry == statistics_map.end() || rentry == statistics_map.end()) {
172: 			return;
173: 		}
174: 		UpdateFilterStatistics(*lentry->second, *rentry->second, comparison_type);
175: 	} else {
176: 		// unsupported filter
177: 		return;
178: 	}
179: 	if (constant && columnref) {
180: 		// comparison between columnref
181: 		auto entry = statistics_map.find(columnref->binding);
182: 		if (entry == statistics_map.end()) {
183: 			return;
184: 		}
185: 		UpdateFilterStatistics(*entry->second, comparison_type, constant->value);
186: 	}
187: }
188: 
189: void StatisticsPropagator::UpdateFilterStatistics(Expression &condition) {
190: 	// in filters, we check for constant comparisons with bound columns
191: 	// if we find a comparison in the form of e.g. "i=3", we can update our statistics for that column
192: 	switch (condition.GetExpressionClass()) {
193: 	case ExpressionClass::BOUND_BETWEEN: {
194: 		auto &between = (BoundBetweenExpression &)condition;
195: 		UpdateFilterStatistics(*between.input, *between.lower, between.LowerComparisonType());
196: 		UpdateFilterStatistics(*between.input, *between.upper, between.UpperComparisonType());
197: 		break;
198: 	}
199: 	case ExpressionClass::BOUND_COMPARISON: {
200: 		auto &comparison = (BoundComparisonExpression &)condition;
201: 		UpdateFilterStatistics(*comparison.left, *comparison.right, comparison.type);
202: 		break;
203: 	}
204: 	default:
205: 		break;
206: 	}
207: }
208: 
209: unique_ptr<NodeStatistics> StatisticsPropagator::PropagateStatistics(LogicalFilter &filter,
210:                                                                      unique_ptr<LogicalOperator> *node_ptr) {
211: 	// first propagate to the child
212: 	node_stats = PropagateStatistics(filter.children[0]);
213: 	if (filter.children[0]->type == LogicalOperatorType::LOGICAL_EMPTY_RESULT) {
214: 		ReplaceWithEmptyResult(*node_ptr);
215: 		return make_unique<NodeStatistics>(0, 0);
216: 	}
217: 
218: 	// then propagate to each of the expressions
219: 	for (idx_t i = 0; i < filter.expressions.size(); i++) {
220: 		auto &condition = filter.expressions[i];
221: 		PropagateExpression(condition);
222: 
223: 		if (ExpressionIsConstant(*condition, Value::BOOLEAN(true))) {
224: 			// filter is always true; it is useless to execute it
225: 			// erase this condition
226: 			filter.expressions.erase(filter.expressions.begin() + i);
227: 			i--;
228: 			if (filter.expressions.empty()) {
229: 				// all conditions have been erased: remove the entire filter
230: 				*node_ptr = move(filter.children[0]);
231: 				break;
232: 			}
233: 		} else if (ExpressionIsConstant(*condition, Value::BOOLEAN(false)) ||
234: 		           ExpressionIsConstantOrNull(*condition, Value::BOOLEAN(false))) {
235: 			// filter is always false or null; this entire filter should be replaced by an empty result block
236: 			ReplaceWithEmptyResult(*node_ptr);
237: 			return make_unique<NodeStatistics>(0, 0);
238: 		} else {
239: 			// cannot prune this filter: propagate statistics from the filter
240: 			UpdateFilterStatistics(*condition);
241: 		}
242: 	}
243: 	// the max cardinality of a filter is the cardinality of the input (i.e. no tuples get filtered)
244: 	return move(node_stats);
245: }
246: 
247: } // namespace duckdb
[end of src/optimizer/statistics/operator/propagate_filter.cpp]
[start of src/planner/subquery/flatten_dependent_join.cpp]
1: #include "duckdb/planner/subquery/flatten_dependent_join.hpp"
2: 
3: #include "duckdb/planner/binder.hpp"
4: #include "duckdb/planner/expression/list.hpp"
5: #include "duckdb/planner/logical_operator_visitor.hpp"
6: #include "duckdb/planner/binder.hpp"
7: #include "duckdb/planner/operator/list.hpp"
8: #include "duckdb/planner/subquery/has_correlated_expressions.hpp"
9: #include "duckdb/planner/subquery/rewrite_correlated_expressions.hpp"
10: #include "duckdb/planner/expression/bound_aggregate_expression.hpp"
11: #include "duckdb/catalog/catalog_entry/aggregate_function_catalog_entry.hpp"
12: #include "duckdb/function/aggregate/distributive_functions.hpp"
13: 
14: namespace duckdb {
15: 
16: FlattenDependentJoins::FlattenDependentJoins(Binder &binder, const vector<CorrelatedColumnInfo> &correlated)
17:     : binder(binder), correlated_columns(correlated) {
18: 	for (idx_t i = 0; i < correlated_columns.size(); i++) {
19: 		auto &col = correlated_columns[i];
20: 		correlated_map[col.binding] = i;
21: 		delim_types.push_back(col.type);
22: 	}
23: }
24: 
25: bool FlattenDependentJoins::DetectCorrelatedExpressions(LogicalOperator *op) {
26: 	D_ASSERT(op);
27: 	// check if this entry has correlated expressions
28: 	HasCorrelatedExpressions visitor(correlated_columns);
29: 	visitor.VisitOperator(*op);
30: 	bool has_correlation = visitor.has_correlated_expressions;
31: 	// now visit the children of this entry and check if they have correlated expressions
32: 	for (auto &child : op->children) {
33: 		// we OR the property with its children such that has_correlation is true if either
34: 		// (1) this node has a correlated expression or
35: 		// (2) one of its children has a correlated expression
36: 		if (DetectCorrelatedExpressions(child.get())) {
37: 			has_correlation = true;
38: 		}
39: 	}
40: 	// set the entry in the map
41: 	has_correlated_expressions[op] = has_correlation;
42: 	return has_correlation;
43: }
44: 
45: unique_ptr<LogicalOperator> FlattenDependentJoins::PushDownDependentJoin(unique_ptr<LogicalOperator> plan) {
46: 	auto result = PushDownDependentJoinInternal(move(plan));
47: 	if (!replacement_map.empty()) {
48: 		// check if we have to replace any COUNT aggregates into "CASE WHEN X IS NULL THEN 0 ELSE COUNT END"
49: 		RewriteCountAggregates aggr(replacement_map);
50: 		aggr.VisitOperator(*result);
51: 	}
52: 	return result;
53: }
54: 
55: unique_ptr<LogicalOperator> FlattenDependentJoins::PushDownDependentJoinInternal(unique_ptr<LogicalOperator> plan) {
56: 	// first check if the logical operator has correlated expressions
57: 	auto entry = has_correlated_expressions.find(plan.get());
58: 	D_ASSERT(entry != has_correlated_expressions.end());
59: 	if (!entry->second) {
60: 		// we reached a node without correlated expressions
61: 		// we can eliminate the dependent join now and create a simple cross product
62: 		auto cross_product = make_unique<LogicalCrossProduct>();
63: 		// now create the duplicate eliminated scan for this node
64: 		auto delim_index = binder.GenerateTableIndex();
65: 		this->base_binding = ColumnBinding(delim_index, 0);
66: 		auto delim_scan = make_unique<LogicalDelimGet>(delim_index, delim_types);
67: 		cross_product->children.push_back(move(delim_scan));
68: 		cross_product->children.push_back(move(plan));
69: 		return move(cross_product);
70: 	}
71: 	switch (plan->type) {
72: 	case LogicalOperatorType::LOGICAL_UNNEST:
73: 	case LogicalOperatorType::LOGICAL_FILTER: {
74: 		// filter
75: 		// first we flatten the dependent join in the child of the filter
76: 		plan->children[0] = PushDownDependentJoinInternal(move(plan->children[0]));
77: 		// then we replace any correlated expressions with the corresponding entry in the correlated_map
78: 		RewriteCorrelatedExpressions rewriter(base_binding, correlated_map);
79: 		rewriter.VisitOperator(*plan);
80: 		return plan;
81: 	}
82: 	case LogicalOperatorType::LOGICAL_PROJECTION: {
83: 		// projection
84: 		// first we flatten the dependent join in the child of the projection
85: 		plan->children[0] = PushDownDependentJoinInternal(move(plan->children[0]));
86: 		// then we replace any correlated expressions with the corresponding entry in the correlated_map
87: 		RewriteCorrelatedExpressions rewriter(base_binding, correlated_map);
88: 		rewriter.VisitOperator(*plan);
89: 		// now we add all the columns of the delim_scan to the projection list
90: 		auto proj = (LogicalProjection *)plan.get();
91: 		for (idx_t i = 0; i < correlated_columns.size(); i++) {
92: 			auto colref = make_unique<BoundColumnRefExpression>(
93: 			    correlated_columns[i].type, ColumnBinding(base_binding.table_index, base_binding.column_index + i));
94: 			plan->expressions.push_back(move(colref));
95: 		}
96: 
97: 		base_binding.table_index = proj->table_index;
98: 		this->delim_offset = base_binding.column_index = plan->expressions.size() - correlated_columns.size();
99: 		this->data_offset = 0;
100: 		return plan;
101: 	}
102: 	case LogicalOperatorType::LOGICAL_AGGREGATE_AND_GROUP_BY: {
103: 		auto &aggr = (LogicalAggregate &)*plan;
104: 		// aggregate and group by
105: 		// first we flatten the dependent join in the child of the projection
106: 		plan->children[0] = PushDownDependentJoinInternal(move(plan->children[0]));
107: 		// then we replace any correlated expressions with the corresponding entry in the correlated_map
108: 		RewriteCorrelatedExpressions rewriter(base_binding, correlated_map);
109: 		rewriter.VisitOperator(*plan);
110: 		// now we add all the columns of the delim_scan to the grouping operators AND the projection list
111: 		for (idx_t i = 0; i < correlated_columns.size(); i++) {
112: 			auto colref = make_unique<BoundColumnRefExpression>(
113: 			    correlated_columns[i].type, ColumnBinding(base_binding.table_index, base_binding.column_index + i));
114: 			for (auto &set : aggr.grouping_sets) {
115: 				set.insert(aggr.groups.size());
116: 			}
117: 			aggr.groups.push_back(move(colref));
118: 		}
119: 		if (aggr.groups.size() == correlated_columns.size()) {
120: 			// we have to perform a LEFT OUTER JOIN between the result of this aggregate and the delim scan
121: 			// FIXME: this does not always have to be a LEFT OUTER JOIN, depending on whether aggr.expressions return
122: 			// NULL or a value
123: 			auto left_outer_join = make_unique<LogicalComparisonJoin>(JoinType::LEFT);
124: 			auto left_index = binder.GenerateTableIndex();
125: 			auto delim_scan = make_unique<LogicalDelimGet>(left_index, delim_types);
126: 			left_outer_join->children.push_back(move(delim_scan));
127: 			left_outer_join->children.push_back(move(plan));
128: 			for (idx_t i = 0; i < correlated_columns.size(); i++) {
129: 				JoinCondition cond;
130: 				cond.left =
131: 				    make_unique<BoundColumnRefExpression>(correlated_columns[i].type, ColumnBinding(left_index, i));
132: 				cond.right = make_unique<BoundColumnRefExpression>(
133: 				    correlated_columns[i].type,
134: 				    ColumnBinding(aggr.group_index, (aggr.groups.size() - correlated_columns.size()) + i));
135: 				cond.comparison = ExpressionType::COMPARE_EQUAL;
136: 				cond.null_values_are_equal = true;
137: 				left_outer_join->conditions.push_back(move(cond));
138: 			}
139: 			// for any COUNT aggregate we replace references to the column with: CASE WHEN COUNT(*) IS NULL THEN 0
140: 			// ELSE COUNT(*) END
141: 			for (idx_t i = 0; i < aggr.expressions.size(); i++) {
142: 				D_ASSERT(aggr.expressions[i]->GetExpressionClass() == ExpressionClass::BOUND_AGGREGATE);
143: 				auto bound = (BoundAggregateExpression *)&*aggr.expressions[i];
144: 				vector<LogicalType> arguments;
145: 				if (bound->function == CountFun::GetFunction() || bound->function == CountStarFun::GetFunction()) {
146: 					// have to replace this ColumnBinding with the CASE expression
147: 					replacement_map[ColumnBinding(aggr.aggregate_index, i)] = i;
148: 				}
149: 			}
150: 			// now we update the delim_index
151: 
152: 			base_binding.table_index = left_index;
153: 			this->delim_offset = base_binding.column_index = 0;
154: 			this->data_offset = 0;
155: 			return move(left_outer_join);
156: 		} else {
157: 			// update the delim_index
158: 			base_binding.table_index = aggr.group_index;
159: 			this->delim_offset = base_binding.column_index = aggr.groups.size() - correlated_columns.size();
160: 			this->data_offset = aggr.groups.size();
161: 			return plan;
162: 		}
163: 	}
164: 	case LogicalOperatorType::LOGICAL_CROSS_PRODUCT: {
165: 		// cross product
166: 		// push into both sides of the plan
167: 		bool left_has_correlation = has_correlated_expressions.find(plan->children[0].get())->second;
168: 		bool right_has_correlation = has_correlated_expressions.find(plan->children[1].get())->second;
169: 		if (!right_has_correlation) {
170: 			// only left has correlation: push into left
171: 			plan->children[0] = PushDownDependentJoinInternal(move(plan->children[0]));
172: 			return plan;
173: 		}
174: 		if (!left_has_correlation) {
175: 			// only right has correlation: push into right
176: 			plan->children[1] = PushDownDependentJoinInternal(move(plan->children[1]));
177: 			return plan;
178: 		}
179: 		// both sides have correlation
180: 		// turn into an inner join
181: 		auto join = make_unique<LogicalComparisonJoin>(JoinType::INNER);
182: 		plan->children[0] = PushDownDependentJoinInternal(move(plan->children[0]));
183: 		auto left_binding = this->base_binding;
184: 		plan->children[1] = PushDownDependentJoinInternal(move(plan->children[1]));
185: 		// add the correlated columns to the join conditions
186: 		for (idx_t i = 0; i < correlated_columns.size(); i++) {
187: 			JoinCondition cond;
188: 			cond.left = make_unique<BoundColumnRefExpression>(
189: 			    correlated_columns[i].type, ColumnBinding(left_binding.table_index, left_binding.column_index + i));
190: 			cond.right = make_unique<BoundColumnRefExpression>(
191: 			    correlated_columns[i].type, ColumnBinding(base_binding.table_index, base_binding.column_index + i));
192: 			cond.comparison = ExpressionType::COMPARE_EQUAL;
193: 			cond.null_values_are_equal = true;
194: 			join->conditions.push_back(move(cond));
195: 		}
196: 		join->children.push_back(move(plan->children[0]));
197: 		join->children.push_back(move(plan->children[1]));
198: 		return move(join);
199: 	}
200: 	case LogicalOperatorType::LOGICAL_COMPARISON_JOIN: {
201: 		auto &join = (LogicalComparisonJoin &)*plan;
202: 		D_ASSERT(plan->children.size() == 2);
203: 		// check the correlated expressions in the children of the join
204: 		bool left_has_correlation = has_correlated_expressions.find(plan->children[0].get())->second;
205: 		bool right_has_correlation = has_correlated_expressions.find(plan->children[1].get())->second;
206: 
207: 		if (join.join_type == JoinType::INNER) {
208: 			// inner join
209: 			if (!right_has_correlation) {
210: 				// only left has correlation: push into left
211: 				plan->children[0] = PushDownDependentJoinInternal(move(plan->children[0]));
212: 				return plan;
213: 			}
214: 			if (!left_has_correlation) {
215: 				// only right has correlation: push into right
216: 				plan->children[1] = PushDownDependentJoinInternal(move(plan->children[1]));
217: 				return plan;
218: 			}
219: 		} else if (join.join_type == JoinType::LEFT) {
220: 			// left outer join
221: 			if (!right_has_correlation) {
222: 				// only left has correlation: push into left
223: 				plan->children[0] = PushDownDependentJoinInternal(move(plan->children[0]));
224: 				return plan;
225: 			}
226: 		} else if (join.join_type == JoinType::MARK) {
227: 			if (right_has_correlation) {
228: 				throw Exception("MARK join with correlation in RHS not supported");
229: 			}
230: 			// push the child into the LHS
231: 			plan->children[0] = PushDownDependentJoinInternal(move(plan->children[0]));
232: 			// rewrite expressions in the join conditions
233: 			RewriteCorrelatedExpressions rewriter(base_binding, correlated_map);
234: 			rewriter.VisitOperator(*plan);
235: 			return plan;
236: 		} else {
237: 			throw Exception("Unsupported join type for flattening correlated subquery");
238: 		}
239: 		// both sides have correlation
240: 		// push into both sides
241: 		// NOTE: for OUTER JOINS it matters what the BASE BINDING is after the join
242: 		// for the LEFT OUTER JOIN, we want the LEFT side to be the base binding after we push
243: 		// because the RIGHT binding might contain NULL values
244: 		plan->children[0] = PushDownDependentJoinInternal(move(plan->children[0]));
245: 		auto left_binding = this->base_binding;
246: 		plan->children[1] = PushDownDependentJoinInternal(move(plan->children[1]));
247: 		auto right_binding = this->base_binding;
248: 		if (join.join_type == JoinType::LEFT) {
249: 			this->base_binding = left_binding;
250: 		}
251: 		// add the correlated columns to the join conditions
252: 		for (idx_t i = 0; i < correlated_columns.size(); i++) {
253: 			JoinCondition cond;
254: 
255: 			cond.left = make_unique<BoundColumnRefExpression>(
256: 			    correlated_columns[i].type, ColumnBinding(left_binding.table_index, left_binding.column_index + i));
257: 			cond.right = make_unique<BoundColumnRefExpression>(
258: 			    correlated_columns[i].type, ColumnBinding(right_binding.table_index, right_binding.column_index + i));
259: 			cond.comparison = ExpressionType::COMPARE_EQUAL;
260: 			cond.null_values_are_equal = true;
261: 			join.conditions.push_back(move(cond));
262: 		}
263: 		// then we replace any correlated expressions with the corresponding entry in the correlated_map
264: 		RewriteCorrelatedExpressions rewriter(right_binding, correlated_map);
265: 		rewriter.VisitOperator(*plan);
266: 		return plan;
267: 	}
268: 	case LogicalOperatorType::LOGICAL_LIMIT: {
269: 		auto &limit = (LogicalLimit &)*plan;
270: 		if (limit.offset_val > 0) {
271: 			throw ParserException("OFFSET not supported in correlated subquery");
272: 		}
273: 		if (limit.limit) {
274: 			throw ParserException("Non-constant limit not supported in correlated subquery");
275: 		}
276: 		plan->children[0] = PushDownDependentJoinInternal(move(plan->children[0]));
277: 		if (limit.limit_val == 0) {
278: 			// limit = 0 means we return zero columns here
279: 			return plan;
280: 		} else {
281: 			// limit > 0 does nothing
282: 			return move(plan->children[0]);
283: 		}
284: 	}
285: 	case LogicalOperatorType::LOGICAL_LIMIT_PERCENT: {
286: 		throw ParserException("Limit percent operator not supported in correlated subquery");
287: 	}
288: 	case LogicalOperatorType::LOGICAL_WINDOW: {
289: 		auto &window = (LogicalWindow &)*plan;
290: 		// push into children
291: 		plan->children[0] = PushDownDependentJoinInternal(move(plan->children[0]));
292: 		// add the correlated columns to the PARTITION BY clauses in the Window
293: 		for (auto &expr : window.expressions) {
294: 			D_ASSERT(expr->GetExpressionClass() == ExpressionClass::BOUND_WINDOW);
295: 			auto &w = (BoundWindowExpression &)*expr;
296: 			for (idx_t i = 0; i < correlated_columns.size(); i++) {
297: 				w.partitions.push_back(make_unique<BoundColumnRefExpression>(
298: 				    correlated_columns[i].type,
299: 				    ColumnBinding(base_binding.table_index, base_binding.column_index + i)));
300: 			}
301: 		}
302: 		return plan;
303: 	}
304: 	case LogicalOperatorType::LOGICAL_EXCEPT:
305: 	case LogicalOperatorType::LOGICAL_INTERSECT:
306: 	case LogicalOperatorType::LOGICAL_UNION: {
307: 		auto &setop = (LogicalSetOperation &)*plan;
308: 		// set operator, push into both children
309: 		plan->children[0] = PushDownDependentJoin(move(plan->children[0]));
310: 		plan->children[1] = PushDownDependentJoin(move(plan->children[1]));
311: 		// we have to refer to the setop index now
312: 		base_binding.table_index = setop.table_index;
313: 		base_binding.column_index = setop.column_count;
314: 		setop.column_count += correlated_columns.size();
315: 		return plan;
316: 	}
317: 	case LogicalOperatorType::LOGICAL_DISTINCT:
318: 		plan->children[0] = PushDownDependentJoin(move(plan->children[0]));
319: 		return plan;
320: 	case LogicalOperatorType::LOGICAL_EXPRESSION_GET: {
321: 		// expression get
322: 		// first we flatten the dependent join in the child
323: 		plan->children[0] = PushDownDependentJoinInternal(move(plan->children[0]));
324: 		// then we replace any correlated expressions with the corresponding entry in the correlated_map
325: 		RewriteCorrelatedExpressions rewriter(base_binding, correlated_map);
326: 		rewriter.VisitOperator(*plan);
327: 		// now we add all the correlated columns to each of the expressions of the expression scan
328: 		auto expr_get = (LogicalExpressionGet *)plan.get();
329: 		for (idx_t i = 0; i < correlated_columns.size(); i++) {
330: 			for (auto &expr_list : expr_get->expressions) {
331: 				auto colref = make_unique<BoundColumnRefExpression>(
332: 				    correlated_columns[i].type, ColumnBinding(base_binding.table_index, base_binding.column_index + i));
333: 				expr_list.push_back(move(colref));
334: 			}
335: 			expr_get->expr_types.push_back(correlated_columns[i].type);
336: 		}
337: 
338: 		base_binding.table_index = expr_get->table_index;
339: 		this->delim_offset = base_binding.column_index = expr_get->expr_types.size() - correlated_columns.size();
340: 		this->data_offset = 0;
341: 		return plan;
342: 	}
343: 	case LogicalOperatorType::LOGICAL_ORDER_BY:
344: 		throw ParserException("ORDER BY not supported in correlated subquery");
345: 	default:
346: 		throw InternalException("Logical operator type \"%s\" for dependent join", LogicalOperatorToString(plan->type));
347: 	}
348: }
349: 
350: } // namespace duckdb
[end of src/planner/subquery/flatten_dependent_join.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: