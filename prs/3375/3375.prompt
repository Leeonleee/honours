You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
R: Defer fixing parameter type
**What does happen?**

A certain type of parameterized query isn't yet supported, this causes a small subset of DBItest tests to fail.

**What should happen?**

Find a way to test the behavior, by implementing in DuckDB or by adapting DBItest.

**To Reproduce**

``` r
library(DBI)

drv1 <- duckdb::duckdb()
conn1 <- dbConnect(drv1, debug = FALSE)
dbGetQuery(conn1, "SELECT CASE WHEN (? = 1) AND (? = 2) AND (? = 3) AND ((? IS NULL)) THEN 1.5 ELSE 2.5 END AS a", params = list(1L, 2L, 3L, NA_integer_))
#> Error in .local(conn, statement, ...): duckdb_prepare_R: Failed to prepare query SELECT CASE WHEN (? = 1) AND (? = 2) AND (? = 3) AND ((? IS NULL)) THEN 1.5 ELSE 2.5 END AS a
#> Error: Binder Error: Could not determine type of parameters: try adding explicit type casts
dbDisconnect(conn1)
```

<sup>Created on 2021-08-11 by the [reprex package](https://reprex.tidyverse.org) (v2.0.1)</sup>

**Environment (please complete the following information):**
 - OS: macOS
 - DuckDB Version: 0.2.9

**Before submitting**
- [x] Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?
- [x] Have you tried this on the latest `master` branch? In case you cannot compile, you may find some binaries here: https://github.com/duckdb/duckdb/releases/tag/master-builds

heap-use-after-free in duckdb::LogicalType::operator==(duckdb::LogicalType const&)
#### What happens?
```
heap-use-after-free in duckdb::LogicalType::operator==(duckdb::LogicalType const&) const /root/duckdb/src/common/types.cpp:1388:6
```

#### To Reproduce
```
PREPARE s1 AS SELECT CAST(? AS INTEGER), CAST(? AS STRING);
SELECT MIN ( DISTINCT + CAST ( NULL AS INTEGER ) ) * COUNT ( * ) * - + 16 * CASE + + AVG ( ALL 97 ) WHEN ( + NULLIF ( SUM ( CAST ( NULL AS REAL ) ), 6 ) ) THEN 51 * 31 + - 6 WHEN + 48 * - 34 THEN NULL WHEN 91 * + ( SUM ( CAST ( NULL AS INTEGER ) ) ) THEN NULL END * - 4 + - 67;
EXECUTE s1(42, 'dpfkg');
```

#### Environment (please complete the following information):
 - OS: linux
 - DuckDB Version: v0.3.3-dev1399 7c5ba6c0e
 - DuckDB Client: /usr/local/bin/duckdb

#### Before Submitting

- [x] **Have you tried this on the latest `master` branch?**
* **Python**: `pip install duckdb --upgrade --pre`
* **R**: `install.packages("https://github.com/duckdb/duckdb/releases/download/master-builds/duckdb_r_src.tar.gz", repos = NULL)`
* **Other Platforms**: You can find binaries [here](https://github.com/duckdb/duckdb/releases/tag/master-builds) or compile from source.

- [x] **Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?**

#### ASAN detail
```
==61101==ERROR: AddressSanitizer: heap-use-after-free on address 0x60c0000193c0 at pc 0x0000036e5e2c bp 0x7fffa2af7e10 sp 0x7fffa2af7e08
READ of size 1 at 0x60c0000193c0 thread T0
    #0 0x36e5e2b in duckdb::LogicalType::operator==(duckdb::LogicalType const&) const /root/duckdb/src/common/types.cpp:1388:6
    #1 0x3a8046c in duckdb::ExpressionExecutor::Execute(duckdb::BoundParameterExpression const&, duckdb::ExpressionState*, duckdb::SelectionVector const*, unsigned long, duckdb::Vector&) /root/duckdb/src/execution/expression_executor/execute_parameter.cpp:17:2
    #2 0x44b2184 in duckdb::ExpressionExecutor::Execute(duckdb::Expression const&, duckdb::ExpressionState*, duckdb::SelectionVector const*, unsigned long, duckdb::Vector&) /root/duckdb/src/execution/expression_executor.cpp:179:3
    #3 0x44ad550 in duckdb::ExpressionExecutor::ExecuteExpression(unsigned long, duckdb::Vector&) /root/duckdb/src/execution/expression_executor.cpp:75:2
    #4 0x44ac004 in duckdb::ExpressionExecutor::Execute(duckdb::DataChunk*, duckdb::DataChunk&) /root/duckdb/src/execution/expression_executor.cpp:46:3
    #5 0x413d93c in duckdb::ExpressionExecutor::Execute(duckdb::DataChunk&, duckdb::DataChunk&) /root/duckdb/src/include/duckdb/execution/expression_executor.hpp:32:3
    #6 0xa0d0f56 in duckdb::PhysicalProjection::Execute(duckdb::ExecutionContext&, duckdb::DataChunk&, duckdb::DataChunk&, duckdb::GlobalOperatorState&, duckdb::OperatorState&) const /root/duckdb/src/execution/operator/projection/physical_projection.cpp:29:17
    #7 0x4a523ef in duckdb::PipelineExecutor::Execute(duckdb::DataChunk&, duckdb::DataChunk&, unsigned long) /root/duckdb/src/parallel/pipeline_executor.cpp:275:36
    #8 0x4a2ff57 in duckdb::PipelineExecutor::ExecutePull(duckdb::DataChunk&) /root/duckdb/src/parallel/pipeline_executor.cpp:200:5
    #9 0x4a2e480 in duckdb::Executor::FetchChunk() /root/duckdb/src/parallel/executor.cpp:729:18
    #10 0x46eab4d in duckdb::ClientContext::FetchInternal(duckdb::ClientContextLock&, duckdb::Executor&, duckdb::BaseQueryResult&) /root/duckdb/src/main/client_context.cpp:96:25
    #11 0x46ea4e2 in duckdb::ClientContext::Fetch(duckdb::ClientContextLock&, duckdb::StreamQueryResult&) /root/duckdb/src/main/client_context.cpp:88:9
    #12 0x4798d50 in duckdb::StreamQueryResult::FetchRaw() /root/duckdb/src/main/stream_query_result.cpp:47:20
    #13 0x47867b7 in duckdb::QueryResult::Fetch() /root/duckdb/src/main/query_result.cpp:50:15
    #14 0x1cdb59e in duckdb::QueryResult::TryFetch(std::unique_ptr<duckdb::DataChunk, std::default_delete<duckdb::DataChunk> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) /root/duckdb/src/include/duckdb/main/query_result.hpp:85:13
    #15 0x1cd819c in sqlite3_step /root/duckdb/tools/sqlite3_api_wrapper/sqlite3_api_wrapper.cpp:229:23
    #16 0x1c900ea in exec_prepared_stmt_columnar /root/duckdb/tools/shell/shell.c:12710:8
    #17 0x1c8bd27 in exec_prepared_stmt /root/duckdb/tools/shell/shell.c:12886:5
    #18 0x1b7f8b3 in shell_exec /root/duckdb/tools/shell/shell.c:13204:7
    #19 0x1ca01d5 in runOneSqlLine /root/duckdb/tools/shell/shell.c:19991:8
    #20 0x1b85691 in process_input /root/duckdb/tools/shell/shell.c:20106:17
    #21 0x1b1d1db in main /root/duckdb/tools/shell/shell.c:20908:12
    #22 0x7fb79fd590b2 in __libc_start_main /build/glibc-sMfBJT/glibc-2.31/csu/../csu/libc-start.c:308:16
    #23 0x1a379fd in _start (/root/bld_asan_debug/duckdb+0x1a379fd)

0x60c0000193c0 is located 0 bytes inside of 128-byte region [0x60c0000193c0,0x60c000019440)
freed by thread T0 here:
    #0 0x1ae457d in operator delete(void*) (/root/bld_asan_debug/duckdb+0x1ae457d)
    #1 0x47a474a in std::default_delete<duckdb::Value>::operator()(duckdb::Value*) const /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/unique_ptr.h:81:2
    #2 0x47a416a in std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >::~unique_ptr() /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/unique_ptr.h:292:4
    #3 0x47a3da0 in void std::_Destroy<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> > >(std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >*) /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/stl_construct.h:98:19
    #4 0x47a3bca in void std::_Destroy_aux<false>::__destroy<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >*>(std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >*, std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >*) /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/stl_construct.h:108:6
    #5 0x47a3af4 in void std::_Destroy<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >*>(std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >*, std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >*) /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/stl_construct.h:136:7
    #6 0x47a33dc in void std::_Destroy<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >*, std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> > >(std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >*, std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >*, std::allocator<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> > >&) /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/stl_construct.h:206:7
    #7 0x47a32db in std::vector<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >, std::allocator<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> > > >::~vector() /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/stl_vector.h:677:2
    #8 0x47a2e3c in std::pair<unsigned long const, std::vector<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >, std::allocator<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> > > > >::~pair() /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/stl_pair.h:208:12
    #9 0x47a2d4e in void __gnu_cxx::new_allocator<std::__detail::_Hash_node<std::pair<unsigned long const, std::vector<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >, std::allocator<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> > > > >, false> >::destroy<std::pair<unsigned long const, std::vector<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >, std::allocator<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> > > > > >(std::pair<unsigned long const, std::vector<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >, std::allocator<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> > > > >*) /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/ext/new_allocator.h:152:10
    #10 0x47a2916 in void std::allocator_traits<std::allocator<std::__detail::_Hash_node<std::pair<unsigned long const, std::vector<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >, std::allocator<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> > > > >, false> > >::destroy<std::pair<unsigned long const, std::vector<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >, std::allocator<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> > > > > >(std::allocator<std::__detail::_Hash_node<std::pair<unsigned long const, std::vector<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >, std::allocator<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> > > > >, false> >&, std::pair<unsigned long const, std::vector<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >, std::allocator<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> > > > >*) /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/alloc_traits.h:496:8
    #11 0x47a2827 in std::__detail::_Hashtable_alloc<std::allocator<std::__detail::_Hash_node<std::pair<unsigned long const, std::vector<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >, std::allocator<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> > > > >, false> > >::_M_deallocate_node(std::__detail::_Hash_node<std::pair<unsigned long const, std::vector<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >, std::allocator<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> > > > >, false>*) /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/hashtable_policy.h:2102:7
    #12 0x47a18e7 in std::__detail::_Hashtable_alloc<std::allocator<std::__detail::_Hash_node<std::pair<unsigned long const, std::vector<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >, std::allocator<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> > > > >, false> > >::_M_deallocate_nodes(std::__detail::_Hash_node<std::pair<unsigned long const, std::vector<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >, std::allocator<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> > > > >, false>*) /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/hashtable_policy.h:2124:4
    #13 0x47f8576 in std::_Hashtable<unsigned long, std::pair<unsigned long const, std::vector<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >, std::allocator<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> > > > >, std::allocator<std::pair<unsigned long const, std::vector<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >, std::allocator<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> > > > > >, std::__detail::_Select1st, std::equal_to<unsigned long>, std::hash<unsigned long>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true> >::clear() /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/hashtable.h:2063:13
    #14 0x47f83b8 in std::_Hashtable<unsigned long, std::pair<unsigned long const, std::vector<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >, std::allocator<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> > > > >, std::allocator<std::pair<unsigned long const, std::vector<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >, std::allocator<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> > > > > >, std::__detail::_Select1st, std::equal_to<unsigned long>, std::hash<unsigned long>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true> >::~_Hashtable() /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/hashtable.h:1387:7
    #15 0x474e2b8 in std::unordered_map<unsigned long, std::vector<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >, std::allocator<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> > > >, std::hash<unsigned long>, std::equal_to<unsigned long>, std::allocator<std::pair<unsigned long const, std::vector<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> >, std::allocator<std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> > > > > > >::~unordered_map() /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/unordered_map.h:102:11
    #16 0x474e1b6 in duckdb::PreparedStatementData::~PreparedStatementData() /root/duckdb/src/main/prepared_statement_data.cpp:12:1
    #17 0x487c9ee in void __gnu_cxx::new_allocator<duckdb::PreparedStatementData>::destroy<duckdb::PreparedStatementData>(duckdb::PreparedStatementData*) /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/ext/new_allocator.h:152:10
    #18 0x487c686 in void std::allocator_traits<std::allocator<duckdb::PreparedStatementData> >::destroy<duckdb::PreparedStatementData>(std::allocator<duckdb::PreparedStatementData>&, duckdb::PreparedStatementData*) /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/alloc_traits.h:496:8
    #19 0x487b735 in std::_Sp_counted_ptr_inplace<duckdb::PreparedStatementData, std::allocator<duckdb::PreparedStatementData>, (__gnu_cxx::_Lock_policy)2>::_M_dispose() /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/shared_ptr_base.h:557:2
    #20 0x1d0b943 in std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release() /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/shared_ptr_base.h:155:6
    #21 0x1d0b5fc in std::__shared_count<(__gnu_cxx::_Lock_policy)2>::~__shared_count() /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/shared_ptr_base.h:730:11
    #22 0x380edbc in std::__shared_ptr<duckdb::PreparedStatementData, (__gnu_cxx::_Lock_policy)2>::~__shared_ptr() /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/shared_ptr_base.h:1169:31
    #23 0x46fa8c8 in std::shared_ptr<duckdb::PreparedStatementData>::~shared_ptr() /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/shared_ptr.h:103:11
    #24 0x5da2406 in duckdb::Planner::PlanExecute(std::unique_ptr<duckdb::SQLStatement, std::default_delete<duckdb::SQLStatement> >) /root/duckdb/src/planner/planner.cpp:126:1
    #25 0x5d9e1a5 in duckdb::Planner::CreatePlan(std::unique_ptr<duckdb::SQLStatement, std::default_delete<duckdb::SQLStatement> >) /root/duckdb/src/planner/planner.cpp:168:3
    #26 0x4612bee in duckdb::ClientContext::CreatePreparedStatement(duckdb::ClientContextLock&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unique_ptr<duckdb::SQLStatement, std::default_delete<duckdb::SQLStatement> >) /root/duckdb/src/main/client_context.cpp:251:10
    #27 0x4881efc in duckdb::ClientContext::PrepareInternal(duckdb::ClientContextLock&, std::unique_ptr<duckdb::SQLStatement, std::default_delete<duckdb::SQLStatement> >)::$_1::operator()() const /root/duckdb/src/main/client_context.cpp:416:36
    #28 0x488103c in std::_Function_handler<void (), duckdb::ClientContext::PrepareInternal(duckdb::ClientContextLock&, std::unique_ptr<duckdb::SQLStatement, std::default_delete<duckdb::SQLStatement> >)::$_1>::_M_invoke(std::_Any_data const&) /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/std_function.h:300:2
    #29 0x4714e43 in std::function<void ()>::operator()() const /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/std_function.h:688:14

previously allocated by thread T0 here:
    #0 0x1ae3d1d in operator new(unsigned long) (/root/bld_asan_debug/duckdb+0x1ae3d1d)
    #1 0x5d9a03a in std::unique_ptr<duckdb::Value, std::default_delete<duckdb::Value> > duckdb::make_unique<duckdb::Value, duckdb::LogicalType&>(duckdb::LogicalType&) /root/duckdb/src/include/duckdb/common/helper.hpp:41:23
    #2 0x5d97c06 in duckdb::Planner::CreatePlan(duckdb::SQLStatement&) /root/duckdb/src/planner/planner.cpp:47:16
    #3 0x5d9e0a8 in duckdb::Planner::CreatePlan(std::unique_ptr<duckdb::SQLStatement, std::default_delete<duckdb::SQLStatement> >) /root/duckdb/src/planner/planner.cpp:165:3
    #4 0x5d9bcb8 in duckdb::Planner::PrepareSQLStatement(std::unique_ptr<duckdb::SQLStatement, std::default_delete<duckdb::SQLStatement> >) /root/duckdb/src/planner/planner.cpp:64:2
    #5 0x5da011f in duckdb::Planner::PlanExecute(std::unique_ptr<duckdb::SQLStatement, std::default_delete<duckdb::SQLStatement> >) /root/duckdb/src/planner/planner.cpp:94:14
    #6 0x5d9e1a5 in duckdb::Planner::CreatePlan(std::unique_ptr<duckdb::SQLStatement, std::default_delete<duckdb::SQLStatement> >) /root/duckdb/src/planner/planner.cpp:168:3
    #7 0x4612bee in duckdb::ClientContext::CreatePreparedStatement(duckdb::ClientContextLock&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unique_ptr<duckdb::SQLStatement, std::default_delete<duckdb::SQLStatement> >) /root/duckdb/src/main/client_context.cpp:251:10
    #8 0x4881efc in duckdb::ClientContext::PrepareInternal(duckdb::ClientContextLock&, std::unique_ptr<duckdb::SQLStatement, std::default_delete<duckdb::SQLStatement> >)::$_1::operator()() const /root/duckdb/src/main/client_context.cpp:416:36
    #9 0x488103c in std::_Function_handler<void (), duckdb::ClientContext::PrepareInternal(duckdb::ClientContextLock&, std::unique_ptr<duckdb::SQLStatement, std::default_delete<duckdb::SQLStatement> >)::$_1>::_M_invoke(std::_Any_data const&) /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/std_function.h:300:2
    #10 0x4714e43 in std::function<void ()>::operator()() const /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/std_function.h:688:14
    #11 0x47054ce in duckdb::ClientContext::RunFunctionInTransactionInternal(duckdb::ClientContextLock&, std::function<void ()> const&, bool) /root/duckdb/src/main/client_context.cpp:939:3
    #12 0x4706b37 in duckdb::ClientContext::PrepareInternal(duckdb::ClientContextLock&, std::unique_ptr<duckdb::SQLStatement, std::default_delete<duckdb::SQLStatement> >) /root/duckdb/src/main/client_context.cpp:415:2
    #13 0x47083fa in duckdb::ClientContext::Prepare(std::unique_ptr<duckdb::SQLStatement, std::default_delete<duckdb::SQLStatement> >) /root/duckdb/src/main/client_context.cpp:426:10
    #14 0x4728d33 in duckdb::Connection::Prepare(std::unique_ptr<duckdb::SQLStatement, std::default_delete<duckdb::SQLStatement> >) /root/duckdb/src/main/connection.cpp:95:18
    #15 0x1cd10c9 in sqlite3_prepare_v2 /root/duckdb/tools/sqlite3_api_wrapper/sqlite3_api_wrapper.cpp:164:28
    #16 0x1b7cd09 in shell_exec /root/duckdb/tools/shell/shell.c:13110:10
    #17 0x1ca01d5 in runOneSqlLine /root/duckdb/tools/shell/shell.c:19991:8
    #18 0x1b85691 in process_input /root/duckdb/tools/shell/shell.c:20106:17
    #19 0x1b1d1db in main /root/duckdb/tools/shell/shell.c:20908:12
    #20 0x7fb79fd590b2 in __libc_start_main /build/glibc-sMfBJT/glibc-2.31/csu/../csu/libc-start.c:308:16

SUMMARY: AddressSanitizer: heap-use-after-free /root/duckdb/src/common/types.cpp:1388:6 in duckdb::LogicalType::operator==(duckdb::LogicalType const&) const
Shadow bytes around the buggy address:
  0x0c187fffb220: fd fd fd fd fd fd fd fd fa fa fa fa fa fa fa fa
  0x0c187fffb230: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c187fffb240: fa fa fa fa fa fa fa fa fd fd fd fd fd fd fd fd
  0x0c187fffb250: fd fd fd fd fd fd fd fd fa fa fa fa fa fa fa fa
  0x0c187fffb260: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
=>0x0c187fffb270: fa fa fa fa fa fa fa fa[fd]fd fd fd fd fd fd fd
  0x0c187fffb280: fd fd fd fd fd fd fd fd fa fa fa fa fa fa fa fa
  0x0c187fffb290: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
  0x0c187fffb2a0: fa fa fa fa fa fa fa fa fd fd fd fd fd fd fd fd
  0x0c187fffb2b0: fd fd fd fd fd fd fd fd fa fa fa fa fa fa fa fa
  0x0c187fffb2c0: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd
Shadow byte legend (one shadow byte represents 8 application bytes):
  Addressable:           00
  Partially addressable: 01 02 03 04 05 06 07 
  Heap left redzone:       fa
  Freed heap region:       fd
  Stack left redzone:      f1
  Stack mid redzone:       f2
  Stack right redzone:     f3
  Stack after return:      f5
  Stack use after scope:   f8
  Global redzone:          f9
  Global init order:       f6
  Poisoned by user:        f7
  Container overflow:      fc
  Array cookie:            ac
  Intra object redzone:    bb
  ASan internal:           fe
  Left alloca redzone:     ca
  Right alloca redzone:    cb
  Shadow gap:              cc
==61101==ABORTING
```


</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
3: </div>
4: <p>&nbsp;</p>
5: 
6: <p align="center">
7:   <a href="https://github.com/duckdb/duckdb/actions">
8:     <img src="https://github.com/cwida/duckdb/workflows/.github/workflows/main.yml/badge.svg?branch=master" alt=".github/workflows/main.yml">
9:   </a>
10:   <a href="https://www.codefactor.io/repository/github/cwida/duckdb">
11:     <img src="https://www.codefactor.io/repository/github/cwida/duckdb/badge" alt="CodeFactor"/>
12:   </a>
13:   <a href="https://app.codecov.io/gh/duckdb/duckdb">
14:     <img src="https://codecov.io/gh/duckdb/duckdb/branch/master/graph/badge.svg?token=FaxjcfFghN" alt="codecov"/>
15:   </a>
16:   <a href="https://discord.gg/tcvwpjfnZx">
17:     <img src="https://shields.io/discord/909674491309850675" alt="discord" />
18:   </a>
19: </p>
20: 
21: ## DuckDB
22: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on the goals of DuckDB, please refer to [the Why DuckDB page on our website](https://duckdb.org/why_duckdb).
23: 
24: ## Installation
25: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
26: 
27: ## Data Import
28: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
29: 
30: ```sql
31: SELECT * FROM 'myfile.csv';
32: SELECT * FROM 'myfile.parquet';
33: ```
34: 
35: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
36: 
37: ## SQL Reference
38: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
39: 
40: ## Development
41: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`.
42: 
43: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
44: 
45: 
[end of README.md]
[start of extension/icu/icu-dateadd.cpp]
1: #include "include/icu-dateadd.hpp"
2: #include "include/icu-datefunc.hpp"
3: 
4: #include "duckdb/parser/parsed_data/create_scalar_function_info.hpp"
5: #include "duckdb/planner/expression/bound_function_expression.hpp"
6: #include "duckdb/common/operator/add.hpp"
7: #include "duckdb/common/operator/multiply.hpp"
8: #include "duckdb/common/types/time.hpp"
9: #include "duckdb/common/types/timestamp.hpp"
10: 
11: namespace duckdb {
12: 
13: struct ICUCalendarAdd {
14: 	template <class TA, class TB, class TR>
15: 	static inline TR Operation(TA left, TB right, icu::Calendar *calendar) {
16: 		throw InternalException("Unimplemented type for ICUCalendarAdd");
17: 	}
18: };
19: 
20: struct ICUCalendarSub : public ICUDateFunc {
21: 	template <class TA, class TB, class TR>
22: 	static inline TR Operation(TA left, TB right, icu::Calendar *calendar) {
23: 		throw InternalException("Unimplemented type for ICUCalendarSub");
24: 	}
25: };
26: 
27: struct ICUCalendarAge : public ICUDateFunc {
28: 	template <class TA, class TB, class TR>
29: 	static inline TR Operation(TA left, TB right, icu::Calendar *calendar) {
30: 		throw InternalException("Unimplemented type for ICUCalendarAge");
31: 	}
32: };
33: 
34: template <>
35: timestamp_t ICUCalendarAdd::Operation(timestamp_t timestamp, interval_t interval, icu::Calendar *calendar) {
36: 	int64_t millis = timestamp.value / Interval::MICROS_PER_MSEC;
37: 	int64_t micros = timestamp.value % Interval::MICROS_PER_MSEC;
38: 
39: 	// Manually move the µs
40: 	micros += interval.micros % Interval::MICROS_PER_MSEC;
41: 	if (micros >= Interval::MICROS_PER_MSEC) {
42: 		micros -= Interval::MICROS_PER_MSEC;
43: 		++millis;
44: 	} else if (micros < 0) {
45: 		micros += Interval::MICROS_PER_MSEC;
46: 		--millis;
47: 	}
48: 
49: 	// Make sure the value is still in range
50: 	date_t d;
51: 	dtime_t t;
52: 	auto us = MultiplyOperatorOverflowCheck::Operation<int64_t, int64_t, int64_t>(millis, Interval::MICROS_PER_MSEC);
53: 	Timestamp::Convert(timestamp_t(us), d, t);
54: 
55: 	// Now use the calendar to add the other parts
56: 	UErrorCode status = U_ZERO_ERROR;
57: 	const auto udate = UDate(millis);
58: 	calendar->setTime(udate, status);
59: 
60: 	// Add interval fields from lowest to highest
61: 	calendar->add(UCAL_MILLISECOND, interval.micros / Interval::MICROS_PER_MSEC, status);
62: 	calendar->add(UCAL_DATE, interval.days, status);
63: 	calendar->add(UCAL_MONTH, interval.months, status);
64: 
65: 	return ICUDateFunc::GetTime(calendar, micros);
66: }
67: 
68: template <>
69: timestamp_t ICUCalendarAdd::Operation(interval_t interval, timestamp_t timestamp, icu::Calendar *calendar) {
70: 	return Operation<timestamp_t, interval_t, timestamp_t>(timestamp, interval, calendar);
71: }
72: 
73: template <>
74: timestamp_t ICUCalendarSub::Operation(timestamp_t timestamp, interval_t interval, icu::Calendar *calendar) {
75: 	const interval_t negated {-interval.months, -interval.days, -interval.micros};
76: 	return ICUCalendarAdd::template Operation<timestamp_t, interval_t, timestamp_t>(timestamp, negated, calendar);
77: }
78: 
79: template <>
80: interval_t ICUCalendarSub::Operation(timestamp_t end_date, timestamp_t start_date, icu::Calendar *calendar) {
81: 	if (start_date > end_date) {
82: 		auto negated = Operation<timestamp_t, timestamp_t, interval_t>(start_date, end_date, calendar);
83: 		return {-negated.months, -negated.days, -negated.micros};
84: 	}
85: 
86: 	auto start_micros = ICUDateFunc::SetTime(calendar, start_date);
87: 	auto end_micros = (uint64_t)(end_date.value % Interval::MICROS_PER_MSEC);
88: 
89: 	// Borrow 1ms from end_date if we wrap. This works because start_date <= end_date
90: 	// and if the µs are out of order, then there must be an extra ms.
91: 	if (start_micros > (idx_t) end_micros) {
92: 		end_date.value -= Interval::MICROS_PER_MSEC;
93: 		end_micros += Interval::MICROS_PER_MSEC;
94: 	}
95: 
96: 	//	Timestamp differences do not use months, so start with days
97: 	interval_t result;
98: 	result.months = 0;
99: 	result.days = SubtractField(calendar, UCAL_DATE, end_date);
100: 
101: 	auto hour_diff = SubtractField(calendar, UCAL_HOUR_OF_DAY, end_date);
102: 	auto min_diff = SubtractField(calendar, UCAL_MINUTE, end_date);
103: 	auto sec_diff = SubtractField(calendar, UCAL_SECOND, end_date);
104: 	auto ms_diff = SubtractField(calendar, UCAL_MILLISECOND, end_date);
105: 	auto micros_diff = ms_diff * Interval::MICROS_PER_MSEC + (end_micros - start_micros);
106: 	result.micros = Time::FromTime(hour_diff, min_diff, sec_diff, micros_diff).micros;
107: 
108: 	return result;
109: }
110: 
111: template <>
112: interval_t ICUCalendarAge::Operation(timestamp_t end_date, timestamp_t start_date, icu::Calendar *calendar) {
113: 	if (start_date > end_date) {
114: 		auto negated = Operation<timestamp_t, timestamp_t, interval_t>(start_date, end_date, calendar);
115: 		return {-negated.months, -negated.days, -negated.micros};
116: 	}
117: 
118: 	auto start_micros = ICUDateFunc::SetTime(calendar, start_date);
119: 	auto end_micros = (uint64_t)(end_date.value % Interval::MICROS_PER_MSEC);
120: 
121: 	// Borrow 1ms from end_date if we wrap. This works because start_date <= end_date
122: 	// and if the µs are out of order, then there must be an extra ms.
123: 	if (start_micros > (idx_t) end_micros) {
124: 		end_date.value -= Interval::MICROS_PER_MSEC;
125: 		end_micros += Interval::MICROS_PER_MSEC;
126: 	}
127: 
128: 	//	Lunar calendars have uneven numbers of months, so we just diff months, not years
129: 	interval_t result;
130: 	result.months = SubtractField(calendar, UCAL_MONTH, end_date);
131: 	result.days = SubtractField(calendar, UCAL_DATE, end_date);
132: 
133: 	auto hour_diff = SubtractField(calendar, UCAL_HOUR_OF_DAY, end_date);
134: 	auto min_diff = SubtractField(calendar, UCAL_MINUTE, end_date);
135: 	auto sec_diff = SubtractField(calendar, UCAL_SECOND, end_date);
136: 	auto ms_diff = SubtractField(calendar, UCAL_MILLISECOND, end_date);
137: 	auto micros_diff = ms_diff * Interval::MICROS_PER_MSEC + (end_micros - start_micros);
138: 	result.micros = Time::FromTime(hour_diff, min_diff, sec_diff, micros_diff).micros;
139: 
140: 	return result;
141: }
142: 
143: struct ICUDateAdd : public ICUDateFunc {
144: 
145: 	template <typename TA, typename TR, typename OP>
146: 	static void ExecuteUnary(DataChunk &args, ExpressionState &state, Vector &result) {
147: 		D_ASSERT(args.ColumnCount() == 1);
148: 
149: 		auto &func_expr = (BoundFunctionExpression &)state.expr;
150: 		auto &info = (BindData &)*func_expr.bind_info;
151: 		CalendarPtr calendar(info.calendar->clone());
152: 
153: 		auto end_date = Timestamp::GetCurrentTimestamp();
154: 		UnaryExecutor::Execute<TA, TR>(args.data[0], result, args.size(), [&](TA start_date) {
155: 			return OP::template Operation<timestamp_t, TA, TR>(end_date, start_date, calendar.get());
156: 		});
157: 	}
158: 
159: 	template <typename TA, typename TR, typename OP>
160: 	inline static ScalarFunction GetUnaryDateFunction(const LogicalTypeId &left_type,
161: 	                                                  const LogicalTypeId &result_type) {
162: 		return ScalarFunction({left_type}, result_type, ExecuteUnary<TA, TR, OP>, false, false, Bind);
163: 	}
164: 
165: 	template <typename TA, typename TB, typename TR, typename OP>
166: 	static void ExecuteBinary(DataChunk &args, ExpressionState &state, Vector &result) {
167: 		D_ASSERT(args.ColumnCount() == 2);
168: 
169: 		auto &func_expr = (BoundFunctionExpression &)state.expr;
170: 		auto &info = (BindData &)*func_expr.bind_info;
171: 		CalendarPtr calendar(info.calendar->clone());
172: 
173: 		BinaryExecutor::Execute<TA, TB, TR>(args.data[0], args.data[1], result, args.size(), [&](TA left, TB right) {
174: 			return OP::template Operation<TA, TB, TR>(left, right, calendar.get());
175: 		});
176: 	}
177: 
178: 	template <typename TA, typename TB, typename TR, typename OP>
179: 	inline static ScalarFunction GetBinaryDateFunction(const LogicalTypeId &left_type, const LogicalTypeId &right_type,
180: 	                                                   const LogicalTypeId &result_type) {
181: 		return ScalarFunction({left_type, right_type}, result_type, ExecuteBinary<TA, TB, TR, OP>,false, false, Bind);
182: 	}
183: 
184: 	template <typename TA, typename TB, typename OP>
185: 	static ScalarFunction GetDateAddFunction(const LogicalTypeId &left_type, const LogicalTypeId &right_type) {
186: 		return GetBinaryDateFunction<TA, TB, timestamp_t, OP>(left_type, right_type, LogicalType::TIMESTAMP_TZ);
187: 	}
188: 
189: 	static void AddDateAddOperators(const string &name, ClientContext &context) {
190: 		//	temporal + interval
191: 		ScalarFunctionSet set(name);
192: 		set.AddFunction(GetDateAddFunction<timestamp_t, interval_t, ICUCalendarAdd>(LogicalType::TIMESTAMP_TZ,
193: 		                                                                            LogicalType::INTERVAL));
194: 		set.AddFunction(GetDateAddFunction<interval_t, timestamp_t, ICUCalendarAdd>(LogicalType::INTERVAL,
195: 		                                                                            LogicalType::TIMESTAMP_TZ));
196: 
197: 		CreateScalarFunctionInfo func_info(set);
198: 		auto &catalog = Catalog::GetCatalog(context);
199: 		catalog.AddFunction(context, &func_info);
200: 	}
201: 
202: 	template <typename TA, typename OP>
203: 	static ScalarFunction GetUnaryAgeFunction(const LogicalTypeId &left_type) {
204: 		return GetUnaryDateFunction<TA, interval_t, OP>(left_type, LogicalType::INTERVAL);
205: 	}
206: 
207: 	template <typename TA, typename TB, typename OP>
208: 	static ScalarFunction GetBinaryAgeFunction(const LogicalTypeId &left_type, const LogicalTypeId &right_type) {
209: 		return GetBinaryDateFunction<TA, TB, interval_t, OP>(left_type, right_type, LogicalType::INTERVAL);
210: 	}
211: 
212: 	static void AddDateSubOperators(const string &name, ClientContext &context) {
213: 		//	temporal - interval
214: 		ScalarFunctionSet set(name);
215: 		set.AddFunction(GetDateAddFunction<timestamp_t, interval_t, ICUCalendarSub>(LogicalType::TIMESTAMP_TZ,
216: 		                                                                            LogicalType::INTERVAL));
217: 
218: 		//	temporal - temporal
219: 		set.AddFunction(GetBinaryAgeFunction<timestamp_t, timestamp_t, ICUCalendarSub>(LogicalType::TIMESTAMP_TZ,
220: 		                                                                               LogicalType::TIMESTAMP_TZ));
221: 
222: 		CreateScalarFunctionInfo func_info(set);
223: 		auto &catalog = Catalog::GetCatalog(context);
224: 		catalog.AddFunction(context, &func_info);
225: 	}
226: 
227: 	static void AddDateAgeFunctions(const string &name, ClientContext &context) {
228: 		//	age(temporal, temporal)
229: 		ScalarFunctionSet set(name);
230: 		set.AddFunction(GetBinaryAgeFunction<timestamp_t, timestamp_t, ICUCalendarAge>(LogicalType::TIMESTAMP_TZ,
231: 		                                                                               LogicalType::TIMESTAMP_TZ));
232: 		set.AddFunction(GetUnaryAgeFunction<timestamp_t, ICUCalendarAge>(LogicalType::TIMESTAMP_TZ));
233: 
234: 		CreateScalarFunctionInfo func_info(set);
235: 		auto &catalog = Catalog::GetCatalog(context);
236: 		catalog.AddFunction(context, &func_info);
237: 	}
238: };
239: 
240: void RegisterICUDateAddFunctions(ClientContext &context) {
241: 	ICUDateAdd::AddDateAddOperators("+", context);
242: 	ICUDateAdd::AddDateSubOperators("-", context);
243: 	ICUDateAdd::AddDateAgeFunctions("age", context);
244: }
245: 
246: } // namespace duckdb
[end of extension/icu/icu-dateadd.cpp]
[start of extension/icu/icu-strptime.cpp]
1: #include "include/icu-strptime.hpp"
2: #include "include/icu-datefunc.hpp"
3: 
4: #include "duckdb/catalog/catalog_entry/scalar_function_catalog_entry.hpp"
5: #include "duckdb/common/types/date.hpp"
6: #include "duckdb/common/types/time.hpp"
7: #include "duckdb/common/types/timestamp.hpp"
8: #include "duckdb/common/vector_operations/binary_executor.hpp"
9: #include "duckdb/execution/expression_executor.hpp"
10: #include "duckdb/function/scalar/strftime.hpp"
11: #include "duckdb/main/client_context.hpp"
12: #include "duckdb/parser/parsed_data/create_scalar_function_info.hpp"
13: #include "duckdb/planner/expression/bound_function_expression.hpp"
14: 
15: namespace duckdb {
16: 
17: struct ICUStrptime : public ICUDateFunc {
18: 	struct ICUStrptimeBindData : public BindData {
19: 		ICUStrptimeBindData(ClientContext &context, const StrpTimeFormat &format) : BindData(context), format(format) {
20: 		}
21: 		ICUStrptimeBindData(const ICUStrptimeBindData &other) : BindData(other), format(other.format) {
22: 		}
23: 
24: 		StrpTimeFormat format;
25: 
26: 		bool Equals(const FunctionData &other_p) const override {
27: 			auto &other = (ICUStrptimeBindData &)other_p;
28: 			return format.format_specifier == other.format.format_specifier;
29: 		}
30: 		unique_ptr<FunctionData> Copy() const override {
31: 			return make_unique<ICUStrptimeBindData>(*this);
32: 		}
33: 	};
34: 
35: 	static void ParseFormatSpecifier(string_t &format_specifier, StrpTimeFormat &format) {
36: 		format.format_specifier = format_specifier.GetString();
37: 		const auto error = StrTimeFormat::ParseFormatSpecifier(format.format_specifier, format);
38: 		if (!error.empty()) {
39: 			throw InvalidInputException("Failed to parse format specifier %s: %s", format.format_specifier, error);
40: 		}
41: 	}
42: 
43: 	static timestamp_t Operation(icu::Calendar *calendar, string_t input, StrpTimeFormat &format) {
44: 		StrpTimeFormat::ParseResult parsed;
45: 		format.Parse(input, parsed);
46: 		if (!parsed.error_message.empty()) {
47: 			throw InvalidInputException(parsed.FormatError(input, format.format_specifier));
48: 		}
49: 
50: 		// Set TZ first, if any.
51: 		// Note that empty TZ names are not allowed,
52: 		// but unknown names will map to GMT.
53: 		if (!parsed.tz.empty()) {
54: 			SetTimeZone(calendar, parsed.tz);
55: 		}
56: 
57: 		// Now get the parts in the given time zone
58: 		uint64_t micros = 0;
59: 		calendar->set(UCAL_EXTENDED_YEAR, parsed.data[0]); // strptime doesn't understand eras
60: 		calendar->set(UCAL_MONTH, parsed.data[1] - 1);
61: 		calendar->set(UCAL_DATE, parsed.data[2]);
62: 		calendar->set(UCAL_HOUR_OF_DAY, parsed.data[3]);
63: 		calendar->set(UCAL_MINUTE, parsed.data[4]);
64: 		calendar->set(UCAL_SECOND, parsed.data[5]);
65: 		calendar->set(UCAL_MILLISECOND, parsed.data[6] / Interval::MICROS_PER_MSEC);
66: 
67: 		// This overrides the TZ setting, so only use it if an offset was parsed.
68: 		// Note that we don't bother/worry about the DST setting because the two just combine.
69: 		if (format.HasFormatSpecifier(StrTimeSpecifier::UTC_OFFSET)) {
70: 			calendar->set(UCAL_ZONE_OFFSET, parsed.data[7] * Interval::MSECS_PER_SEC * Interval::SECS_PER_MINUTE);
71: 		}
72: 
73: 		return GetTime(calendar, micros);
74: 	}
75: 
76: 	static void ICUStrptimeFunction(DataChunk &args, ExpressionState &state, Vector &result) {
77: 		D_ASSERT(args.ColumnCount() == 2);
78: 		auto &str_arg = args.data[0];
79: 		auto &fmt_arg = args.data[1];
80: 
81: 		auto &func_expr = (BoundFunctionExpression &)state.expr;
82: 		auto &info = (ICUStrptimeBindData &)*func_expr.bind_info;
83: 		CalendarPtr calendar(info.calendar->clone());
84: 		auto &format = info.format;
85: 
86: 		D_ASSERT(fmt_arg.GetVectorType() == VectorType::CONSTANT_VECTOR);
87: 
88: 		if (ConstantVector::IsNull(fmt_arg)) {
89: 			result.SetVectorType(VectorType::CONSTANT_VECTOR);
90: 			ConstantVector::SetNull(result, true);
91: 		} else {
92: 			UnaryExecutor::Execute<string_t, timestamp_t>(
93: 			    str_arg, result, args.size(), [&](string_t input) { return Operation(calendar.get(), input, format); });
94: 		}
95: 	}
96: 
97: 	static bind_scalar_function_t bind;
98: 
99: 	static unique_ptr<FunctionData> StrpTimeBindFunction(ClientContext &context, ScalarFunction &bound_function,
100: 	                                                     vector<unique_ptr<Expression>> &arguments) {
101: 		if (!arguments[1]->IsFoldable()) {
102: 			throw InvalidInputException("strptime format must be a constant");
103: 		}
104: 		Value options_str = ExpressionExecutor::EvaluateScalar(*arguments[1]);
105: 		StrpTimeFormat format;
106: 		if (!options_str.IsNull()) {
107: 			auto format_string = options_str.ToString();
108: 			format.format_specifier = format_string;
109: 			string error = StrTimeFormat::ParseFormatSpecifier(format_string, format);
110: 			if (!error.empty()) {
111: 				throw InvalidInputException("Failed to parse format specifier %s: %s", format_string, error);
112: 			}
113: 
114: 			// If we have a time zone, we should use ICU for parsing and return a TSTZ instead.
115: 			if (format.HasFormatSpecifier(StrTimeSpecifier::TZ_NAME)) {
116: 				bound_function.function = ICUStrptimeFunction;
117: 				bound_function.return_type = LogicalType::TIMESTAMP_TZ;
118: 				return make_unique<ICUStrptimeBindData>(context, format);
119: 			}
120: 		}
121: 
122: 		// Fall back to faster, non-TZ parsing
123: 		bound_function.bind = bind;
124: 		return bind(context, bound_function, arguments);
125: 	}
126: 
127: 	static void AddBinaryTimestampFunction(const string &name, ClientContext &context) {
128: 		// Find the old function
129: 		auto &catalog = Catalog::GetCatalog(context);
130: 		auto entry = catalog.GetEntry(context, CatalogType::SCALAR_FUNCTION_ENTRY, DEFAULT_SCHEMA, name);
131: 		D_ASSERT(entry && entry->type == CatalogType::SCALAR_FUNCTION_ENTRY);
132: 		auto &func = (ScalarFunctionCatalogEntry &)*entry;
133: 		vector<LogicalType> types {LogicalType::VARCHAR, LogicalType::VARCHAR};
134: 		string error;
135: 		const idx_t best_function = Function::BindFunction(func.name, func.functions, types, error);
136: 		if (best_function == DConstants::INVALID_INDEX) {
137: 			return;
138: 		}
139: 
140: 		// Tail patch the old binder
141: 		auto &bound_function = func.functions[best_function];
142: 		bind = bound_function.bind;
143: 		bound_function.bind = StrpTimeBindFunction;
144: 	}
145: };
146: 
147: bind_scalar_function_t ICUStrptime::bind = nullptr;
148: 
149: struct ICUStrftime : public ICUDateFunc {
150: 	static void ParseFormatSpecifier(string_t &format_str, StrfTimeFormat &format) {
151: 		const auto format_specifier = format_str.GetString();
152: 		const auto error = StrTimeFormat::ParseFormatSpecifier(format_specifier, format);
153: 		if (!error.empty()) {
154: 			throw InvalidInputException("Failed to parse format specifier %s: %s", format_specifier, error);
155: 		}
156: 	}
157: 
158: 	static string_t Operation(icu::Calendar *calendar, timestamp_t input, const char *tz_name, StrfTimeFormat &format,
159: 	                          Vector &result) {
160: 		// Now get the parts in the given time zone
161: 		uint64_t micros = SetTime(calendar, input);
162: 
163: 		int32_t data[8];
164: 		data[0] = ExtractField(calendar, UCAL_EXTENDED_YEAR); // strftime doesn't understand eras.
165: 		data[1] = ExtractField(calendar, UCAL_MONTH) + 1;
166: 		data[2] = ExtractField(calendar, UCAL_DATE);
167: 		data[3] = ExtractField(calendar, UCAL_HOUR_OF_DAY);
168: 		data[4] = ExtractField(calendar, UCAL_MINUTE);
169: 		data[5] = ExtractField(calendar, UCAL_SECOND);
170: 		data[6] = ExtractField(calendar, UCAL_MILLISECOND) * Interval::MICROS_PER_MSEC + micros;
171: 
172: 		data[7] = ExtractField(calendar, UCAL_ZONE_OFFSET) + ExtractField(calendar, UCAL_DST_OFFSET);
173: 		data[7] /= Interval::MSECS_PER_SEC;
174: 		data[7] /= Interval::SECS_PER_MINUTE;
175: 
176: 		const auto date = Date::FromDate(data[0], data[1], data[2]);
177: 		const auto time = Time::FromTime(data[3], data[4], data[5], data[6]);
178: 
179: 		const auto len = format.GetLength(date, time, data[7], tz_name);
180: 		string_t target = StringVector::EmptyString(result, len);
181: 		format.FormatString(date, data, tz_name, target.GetDataWriteable());
182: 		target.Finalize();
183: 
184: 		return target;
185: 	}
186: 
187: 	static void ICUStrftimeFunction(DataChunk &args, ExpressionState &state, Vector &result) {
188: 		D_ASSERT(args.ColumnCount() == 2);
189: 		auto &src_arg = args.data[0];
190: 		auto &fmt_arg = args.data[1];
191: 
192: 		auto &func_expr = (BoundFunctionExpression &)state.expr;
193: 		auto &info = (BindData &)*func_expr.bind_info;
194: 		CalendarPtr calendar(info.calendar->clone());
195: 		const auto tz_name = info.tz_setting.c_str();
196: 
197: 		if (fmt_arg.GetVectorType() == VectorType::CONSTANT_VECTOR) {
198: 			// Common case of constant part.
199: 			if (ConstantVector::IsNull(fmt_arg)) {
200: 				result.SetVectorType(VectorType::CONSTANT_VECTOR);
201: 				ConstantVector::SetNull(result, true);
202: 			} else {
203: 				StrfTimeFormat format;
204: 				ParseFormatSpecifier(*ConstantVector::GetData<string_t>(fmt_arg), format);
205: 
206: 				UnaryExecutor::Execute<timestamp_t, string_t>(src_arg, result, args.size(), [&](timestamp_t input) {
207: 					return Operation(calendar.get(), input, tz_name, format, result);
208: 				});
209: 			}
210: 		} else {
211: 			BinaryExecutor::Execute<timestamp_t, string_t, string_t>(
212: 			    src_arg, fmt_arg, result, args.size(), [&](timestamp_t input, string_t format_specifier) {
213: 				    StrfTimeFormat format;
214: 				    ParseFormatSpecifier(format_specifier, format);
215: 
216: 				    return Operation(calendar.get(), input, tz_name, format, result);
217: 			    });
218: 		}
219: 	}
220: 
221: 	static void AddBinaryTimestampFunction(const string &name, ClientContext &context) {
222: 		ScalarFunctionSet set(name);
223: 		set.AddFunction(ScalarFunction({LogicalType::TIMESTAMP_TZ, LogicalType::VARCHAR}, LogicalType::VARCHAR,
224: 		                               ICUStrftimeFunction, false, false, Bind));
225: 
226: 		CreateScalarFunctionInfo func_info(set);
227: 		auto &catalog = Catalog::GetCatalog(context);
228: 		catalog.AddFunction(context, &func_info);
229: 	}
230: };
231: 
232: void RegisterICUStrptimeFunctions(ClientContext &context) {
233: 	ICUStrptime::AddBinaryTimestampFunction("strptime", context);
234: 	ICUStrftime::AddBinaryTimestampFunction("strftime", context);
235: }
236: 
237: } // namespace duckdb
[end of extension/icu/icu-strptime.cpp]
[start of src/common/symbols.cpp]
1: // this file is used to instantiate symbols for LLDB so e.g.
2: // std::vector and std::unique_ptr can be accessed from the debugger
3: 
4: #ifdef DEBUG
5: 
6: #include "duckdb/catalog/catalog.hpp"
7: #include "duckdb/catalog/catalog_entry/list.hpp"
8: #include "duckdb/common/types/chunk_collection.hpp"
9: #include "duckdb/execution/aggregate_hashtable.hpp"
10: #include "duckdb/execution/column_binding_resolver.hpp"
11: #include "duckdb/execution/join_hashtable.hpp"
12: #include "duckdb/execution/physical_operator.hpp"
13: #include "duckdb/main/materialized_query_result.hpp"
14: #include "duckdb/main/query_profiler.hpp"
15: #include "duckdb/main/query_result.hpp"
16: #include "duckdb/main/relation.hpp"
17: #include "duckdb/main/stream_query_result.hpp"
18: #include "duckdb/optimizer/join_order_optimizer.hpp"
19: #include "duckdb/optimizer/rule.hpp"
20: #include "duckdb/parallel/pipeline.hpp"
21: #include "duckdb/parser/constraint.hpp"
22: #include "duckdb/parser/constraints/list.hpp"
23: #include "duckdb/parser/expression/list.hpp"
24: #include "duckdb/parser/query_node.hpp"
25: #include "duckdb/parser/query_node/select_node.hpp"
26: #include "duckdb/parser/query_node/set_operation_node.hpp"
27: #include "duckdb/parser/statement/list.hpp"
28: #include "duckdb/parser/tableref/list.hpp"
29: #include "duckdb/planner/expression/list.hpp"
30: #include "duckdb/planner/logical_operator.hpp"
31: #include "duckdb/planner/operator/list.hpp"
32: #include "duckdb/planner/operator/logical_join.hpp"
33: #include "duckdb/planner/query_node/bound_select_node.hpp"
34: #include "duckdb/planner/query_node/bound_set_operation_node.hpp"
35: #include "duckdb/storage/data_table.hpp"
36: #include "duckdb/storage/write_ahead_log.hpp"
37: #include "duckdb/transaction/transaction.hpp"
38: 
39: using namespace duckdb;
40: 
41: template class std::unique_ptr<SQLStatement>;
42: template class std::unique_ptr<AlterStatement>;
43: template class std::unique_ptr<CopyStatement>;
44: template class std::unique_ptr<CreateStatement>;
45: template class std::unique_ptr<DeleteStatement>;
46: template class std::unique_ptr<DropStatement>;
47: template class std::unique_ptr<InsertStatement>;
48: template class std::unique_ptr<SelectStatement>;
49: template class std::unique_ptr<TransactionStatement>;
50: template class std::unique_ptr<UpdateStatement>;
51: template class std::unique_ptr<PrepareStatement>;
52: template class std::unique_ptr<ExecuteStatement>;
53: template class std::unique_ptr<QueryNode>;
54: template class std::unique_ptr<SelectNode>;
55: template class std::unique_ptr<SetOperationNode>;
56: template class std::unique_ptr<ParsedExpression>;
57: template class std::unique_ptr<CaseExpression>;
58: template class std::unique_ptr<CastExpression>;
59: template class std::unique_ptr<ColumnRefExpression>;
60: template class std::unique_ptr<ComparisonExpression>;
61: template class std::unique_ptr<ConjunctionExpression>;
62: template class std::unique_ptr<ConstantExpression>;
63: template class std::unique_ptr<DefaultExpression>;
64: template class std::unique_ptr<FunctionExpression>;
65: template class std::unique_ptr<OperatorExpression>;
66: template class std::unique_ptr<ParameterExpression>;
67: template class std::unique_ptr<StarExpression>;
68: template class std::unique_ptr<SubqueryExpression>;
69: template class std::unique_ptr<WindowExpression>;
70: template class std::unique_ptr<Constraint>;
71: template class std::unique_ptr<NotNullConstraint>;
72: template class std::unique_ptr<CheckConstraint>;
73: template class std::unique_ptr<UniqueConstraint>;
74: template class std::unique_ptr<ForeignKeyConstraint>;
75: // template class std::unique_ptr<TableRef>;
76: template class std::unique_ptr<BaseTableRef>;
77: template class std::unique_ptr<CrossProductRef>;
78: template class std::unique_ptr<JoinRef>;
79: template class std::unique_ptr<SubqueryRef>;
80: template class std::unique_ptr<TableFunctionRef>;
81: template class std::unique_ptr<Pipeline>;
82: template class std::shared_ptr<Pipeline>;
83: template class std::weak_ptr<Pipeline>;
84: template class std::shared_ptr<PreparedStatementData>;
85: 
86: template class std::unique_ptr<Expression>;
87: template class std::unique_ptr<BoundQueryNode>;
88: template class std::unique_ptr<BoundSelectNode>;
89: template class std::unique_ptr<BoundSetOperationNode>;
90: template class std::unique_ptr<BoundAggregateExpression>;
91: template class std::unique_ptr<BoundCaseExpression>;
92: template class std::unique_ptr<BoundCastExpression>;
93: template class std::unique_ptr<BoundColumnRefExpression>;
94: template class std::unique_ptr<BoundComparisonExpression>;
95: template class std::unique_ptr<BoundConjunctionExpression>;
96: template class std::unique_ptr<BoundConstantExpression>;
97: template class std::unique_ptr<BoundDefaultExpression>;
98: template class std::unique_ptr<BoundFunctionExpression>;
99: template class std::unique_ptr<BoundOperatorExpression>;
100: template class std::unique_ptr<BoundParameterExpression>;
101: template class std::unique_ptr<BoundReferenceExpression>;
102: template class std::unique_ptr<BoundSubqueryExpression>;
103: template class std::unique_ptr<BoundWindowExpression>;
104: 
105: template class std::unique_ptr<CatalogEntry>;
106: template class std::unique_ptr<BindContext>;
107: template class std::unique_ptr<char[]>;
108: template class std::unique_ptr<QueryResult>;
109: template class std::unique_ptr<MaterializedQueryResult>;
110: template class std::unique_ptr<StreamQueryResult>;
111: template class std::unique_ptr<LogicalOperator>;
112: template class std::unique_ptr<PhysicalOperator>;
113: template class std::unique_ptr<OperatorState>;
114: template class std::unique_ptr<sel_t[]>;
115: template class std::unique_ptr<StringHeap>;
116: template class std::unique_ptr<GroupedAggregateHashTable>;
117: template class std::unique_ptr<TableRef>;
118: template class std::unique_ptr<Transaction>;
119: template class std::unique_ptr<uint64_t[]>;
120: template class std::unique_ptr<data_t[]>;
121: template class std::unique_ptr<Vector[]>;
122: template class std::unique_ptr<DataChunk>;
123: template class std::unique_ptr<JoinHashTable>;
124: template class std::unique_ptr<JoinHashTable::ScanStructure>;
125: template class std::unique_ptr<data_ptr_t[]>;
126: template class std::unique_ptr<Rule>;
127: template class std::unique_ptr<LogicalFilter>;
128: template class std::unique_ptr<LogicalJoin>;
129: template class std::unique_ptr<LogicalComparisonJoin>;
130: template class std::unique_ptr<FilterInfo>;
131: template class std::unique_ptr<JoinOrderOptimizer::JoinNode>;
132: template class std::unique_ptr<SingleJoinRelation>;
133: template class std::shared_ptr<Relation>;
134: template class std::unique_ptr<CatalogSet>;
135: template class std::unique_ptr<Binder>;
136: 
137: #define INSTANTIATE_VECTOR(VECTOR_DEFINITION)                                                                          \
138: 	template VECTOR_DEFINITION::size_type VECTOR_DEFINITION::size() const;                                             \
139: 	template VECTOR_DEFINITION::const_reference VECTOR_DEFINITION::operator[](VECTOR_DEFINITION::size_type n) const;   \
140: 	template VECTOR_DEFINITION::reference VECTOR_DEFINITION::operator[](VECTOR_DEFINITION::size_type n);               \
141: 	template VECTOR_DEFINITION::const_reference VECTOR_DEFINITION::back() const;                                       \
142: 	template VECTOR_DEFINITION::reference VECTOR_DEFINITION::back();                                                   \
143: 	template VECTOR_DEFINITION::const_reference VECTOR_DEFINITION::front() const;                                      \
144: 	template VECTOR_DEFINITION::reference VECTOR_DEFINITION::front();
145: 
146: INSTANTIATE_VECTOR(std::vector<ColumnDefinition>)
147: template class std::vector<ExpressionType>;
148: INSTANTIATE_VECTOR(std::vector<JoinCondition>)
149: INSTANTIATE_VECTOR(std::vector<OrderByNode>)
150: template class std::vector<uint64_t>;
151: template class std::vector<string>;
152: INSTANTIATE_VECTOR(std::vector<Expression *>)
153: INSTANTIATE_VECTOR(std::vector<std::unique_ptr<Expression>>)
154: INSTANTIATE_VECTOR(std::vector<std::unique_ptr<DataChunk>>)
155: INSTANTIATE_VECTOR(std::vector<std::unique_ptr<SQLStatement>>)
156: INSTANTIATE_VECTOR(std::vector<std::unique_ptr<PhysicalOperator>>)
157: INSTANTIATE_VECTOR(std::vector<std::unique_ptr<LogicalOperator>>)
158: INSTANTIATE_VECTOR(std::vector<std::unique_ptr<Transaction>>)
159: INSTANTIATE_VECTOR(std::vector<std::unique_ptr<JoinOrderOptimizer::JoinNode>>)
160: template class std::vector<PhysicalType>;
161: template class std::vector<Value>;
162: template class std::vector<int>;
163: INSTANTIATE_VECTOR(std::vector<std::unique_ptr<Rule>>)
164: INSTANTIATE_VECTOR(std::vector<std::unique_ptr<Pipeline>>)
165: INSTANTIATE_VECTOR(std::vector<std::shared_ptr<Pipeline>>)
166: template class std::vector<std::vector<Expression *>>;
167: template class std::vector<LogicalType>;
168: 
169: #if !defined(__clang__)
170: template struct std::atomic<uint64_t>;
171: #endif
172: 
173: template class std::bitset<STANDARD_VECTOR_SIZE>;
174: template class std::unordered_map<PhysicalOperator *, QueryProfiler::TreeNode *>;
175: template class std::stack<PhysicalOperator *>;
176: 
177: /* -pedantic does not like this
178: #define INSTANTIATE_UNORDERED_MAP(MAP_DEFINITION)                                                                      \
179:     template MAP_DEFINITION::mapped_type &MAP_DEFINITION::operator[](MAP_DEFINITION::key_type &&k);                    \
180:     template MAP_DEFINITION::mapped_type &MAP_DEFINITION::operator[](const MAP_DEFINITION::key_type &k);
181: 
182: using catalog_map = std::unordered_map<string, unique_ptr<CatalogEntry>>;
183: INSTANTIATE_UNORDERED_MAP(catalog_map)
184: */
185: 
186: template class std::unordered_map<string, uint64_t>;
187: template class std::unordered_map<string, std::vector<string>>;
188: template class std::unordered_map<string, std::pair<uint64_t, Expression *>>;
189: // template class std::unordered_map<string, TableBinding>;
190: template class std::unordered_map<string, SelectStatement *>;
191: template class std::unordered_map<uint64_t, uint64_t>;
192: 
193: #endif
[end of src/common/symbols.cpp]
[start of src/execution/physical_plan/plan_execute.cpp]
1: #include "duckdb/execution/operator/helper/physical_execute.hpp"
2: #include "duckdb/execution/physical_plan_generator.hpp"
3: #include "duckdb/planner/operator/logical_execute.hpp"
4: 
5: namespace duckdb {
6: 
7: unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalExecute &op) {
8: 	D_ASSERT(op.children.size() == 0);
9: 	return make_unique<PhysicalExecute>(op.prepared->plan.get());
10: }
11: 
12: } // namespace duckdb
[end of src/execution/physical_plan/plan_execute.cpp]
[start of src/function/cast_rules.cpp]
1: #include "duckdb/function/cast_rules.hpp"
2: 
3: namespace duckdb {
4: 
5: //! The target type determines the preferred implicit casts
6: static int64_t TargetTypeCost(const LogicalType &type) {
7: 	switch (type.id()) {
8: 	case LogicalTypeId::INTEGER:
9: 		return 103;
10: 	case LogicalTypeId::BIGINT:
11: 		return 101;
12: 	case LogicalTypeId::DOUBLE:
13: 		return 102;
14: 	case LogicalTypeId::HUGEINT:
15: 		return 120;
16: 	case LogicalTypeId::TIMESTAMP:
17: 		return 120;
18: 	case LogicalTypeId::VARCHAR:
19: 		return 149;
20: 	case LogicalTypeId::DECIMAL:
21: 		return 104;
22: 	case LogicalTypeId::STRUCT:
23: 	case LogicalTypeId::MAP:
24: 	case LogicalTypeId::LIST:
25: 		return 160;
26: 	default:
27: 		return 110;
28: 	}
29: }
30: 
31: static int64_t ImplicitCastTinyint(const LogicalType &to) {
32: 	switch (to.id()) {
33: 	case LogicalTypeId::SMALLINT:
34: 	case LogicalTypeId::INTEGER:
35: 	case LogicalTypeId::BIGINT:
36: 	case LogicalTypeId::HUGEINT:
37: 	case LogicalTypeId::FLOAT:
38: 	case LogicalTypeId::DOUBLE:
39: 	case LogicalTypeId::DECIMAL:
40: 		return TargetTypeCost(to);
41: 	default:
42: 		return -1;
43: 	}
44: }
45: 
46: static int64_t ImplicitCastSmallint(const LogicalType &to) {
47: 	switch (to.id()) {
48: 	case LogicalTypeId::INTEGER:
49: 	case LogicalTypeId::BIGINT:
50: 	case LogicalTypeId::HUGEINT:
51: 	case LogicalTypeId::FLOAT:
52: 	case LogicalTypeId::DOUBLE:
53: 	case LogicalTypeId::DECIMAL:
54: 		return TargetTypeCost(to);
55: 	default:
56: 		return -1;
57: 	}
58: }
59: 
60: static int64_t ImplicitCastInteger(const LogicalType &to) {
61: 	switch (to.id()) {
62: 	case LogicalTypeId::BIGINT:
63: 	case LogicalTypeId::HUGEINT:
64: 	case LogicalTypeId::FLOAT:
65: 	case LogicalTypeId::DOUBLE:
66: 	case LogicalTypeId::DECIMAL:
67: 		return TargetTypeCost(to);
68: 	default:
69: 		return -1;
70: 	}
71: }
72: 
73: static int64_t ImplicitCastBigint(const LogicalType &to) {
74: 	switch (to.id()) {
75: 	case LogicalTypeId::FLOAT:
76: 	case LogicalTypeId::DOUBLE:
77: 	case LogicalTypeId::HUGEINT:
78: 	case LogicalTypeId::DECIMAL:
79: 		return TargetTypeCost(to);
80: 	default:
81: 		return -1;
82: 	}
83: }
84: 
85: static int64_t ImplicitCastUTinyint(const LogicalType &to) {
86: 	switch (to.id()) {
87: 	case LogicalTypeId::USMALLINT:
88: 	case LogicalTypeId::UINTEGER:
89: 	case LogicalTypeId::UBIGINT:
90: 	case LogicalTypeId::SMALLINT:
91: 	case LogicalTypeId::INTEGER:
92: 	case LogicalTypeId::BIGINT:
93: 	case LogicalTypeId::HUGEINT:
94: 	case LogicalTypeId::FLOAT:
95: 	case LogicalTypeId::DOUBLE:
96: 	case LogicalTypeId::DECIMAL:
97: 		return TargetTypeCost(to);
98: 	default:
99: 		return -1;
100: 	}
101: }
102: 
103: static int64_t ImplicitCastUSmallint(const LogicalType &to) {
104: 	switch (to.id()) {
105: 	case LogicalTypeId::UINTEGER:
106: 	case LogicalTypeId::UBIGINT:
107: 	case LogicalTypeId::INTEGER:
108: 	case LogicalTypeId::BIGINT:
109: 	case LogicalTypeId::HUGEINT:
110: 	case LogicalTypeId::FLOAT:
111: 	case LogicalTypeId::DOUBLE:
112: 	case LogicalTypeId::DECIMAL:
113: 		return TargetTypeCost(to);
114: 	default:
115: 		return -1;
116: 	}
117: }
118: 
119: static int64_t ImplicitCastUInteger(const LogicalType &to) {
120: 	switch (to.id()) {
121: 
122: 	case LogicalTypeId::UBIGINT:
123: 	case LogicalTypeId::BIGINT:
124: 	case LogicalTypeId::HUGEINT:
125: 	case LogicalTypeId::FLOAT:
126: 	case LogicalTypeId::DOUBLE:
127: 	case LogicalTypeId::DECIMAL:
128: 		return TargetTypeCost(to);
129: 	default:
130: 		return -1;
131: 	}
132: }
133: 
134: static int64_t ImplicitCastUBigint(const LogicalType &to) {
135: 	switch (to.id()) {
136: 	case LogicalTypeId::FLOAT:
137: 	case LogicalTypeId::DOUBLE:
138: 	case LogicalTypeId::HUGEINT:
139: 	case LogicalTypeId::DECIMAL:
140: 		return TargetTypeCost(to);
141: 	default:
142: 		return -1;
143: 	}
144: }
145: 
146: static int64_t ImplicitCastFloat(const LogicalType &to) {
147: 	switch (to.id()) {
148: 	case LogicalTypeId::DOUBLE:
149: 		return TargetTypeCost(to);
150: 	default:
151: 		return -1;
152: 	}
153: }
154: 
155: static int64_t ImplicitCastDouble(const LogicalType &to) {
156: 	switch (to.id()) {
157: 	default:
158: 		return -1;
159: 	}
160: }
161: 
162: static int64_t ImplicitCastDecimal(const LogicalType &to) {
163: 	switch (to.id()) {
164: 	case LogicalTypeId::FLOAT:
165: 	case LogicalTypeId::DOUBLE:
166: 		return TargetTypeCost(to);
167: 	default:
168: 		return -1;
169: 	}
170: }
171: 
172: static int64_t ImplicitCastHugeint(const LogicalType &to) {
173: 	switch (to.id()) {
174: 	case LogicalTypeId::FLOAT:
175: 	case LogicalTypeId::DOUBLE:
176: 	case LogicalTypeId::DECIMAL:
177: 		return TargetTypeCost(to);
178: 	default:
179: 		return -1;
180: 	}
181: }
182: 
183: static int64_t ImplicitCastDate(const LogicalType &to) {
184: 	switch (to.id()) {
185: 	case LogicalTypeId::TIMESTAMP:
186: 		return TargetTypeCost(to);
187: 	default:
188: 		return -1;
189: 	}
190: }
191: 
192: int64_t CastRules::ImplicitCast(const LogicalType &from, const LogicalType &to) {
193: 	if (to.id() == LogicalTypeId::ANY) {
194: 		// anything can be cast to ANY type for no cost
195: 		return 0;
196: 	}
197: 	if (from.id() == LogicalTypeId::SQLNULL || from.id() == LogicalTypeId::UNKNOWN) {
198: 		// NULL expression or parameter expression can be cast to anything
199: 		return TargetTypeCost(to);
200: 	}
201: 	if (from.id() == LogicalTypeId::BLOB && to.id() == LogicalTypeId::VARCHAR) {
202: 		// Implicit cast not allowed from BLOB to VARCHAR
203: 		return -1;
204: 	}
205: 	if ((from.id() == LogicalTypeId::VARCHAR && to.id() == LogicalTypeId::JSON) ||
206: 	    (from.id() == LogicalTypeId::JSON && to.id() == LogicalTypeId::VARCHAR)) {
207: 		// Virtually no cost, just a different tag
208: 		return 1;
209: 	}
210: 	if (to.id() == LogicalTypeId::VARCHAR || to.id() == LogicalTypeId::JSON) {
211: 		// everything can be cast to VARCHAR/JSON, but this cast has a high cost
212: 		return TargetTypeCost(to);
213: 	}
214: 	if (from.id() == LogicalTypeId::LIST && to.id() == LogicalTypeId::LIST) {
215: 		// Lists can be cast if their child types can be cast
216: 		return ImplicitCast(ListType::GetChildType(from), ListType::GetChildType(to));
217: 	}
218: 	if ((from.id() == LogicalTypeId::TIMESTAMP_SEC || from.id() == LogicalTypeId::TIMESTAMP_MS ||
219: 	     from.id() == LogicalTypeId::TIMESTAMP_NS) &&
220: 	    to.id() == LogicalTypeId::TIMESTAMP) {
221: 		//! Any timestamp type can be converted to the default (us) type at low cost
222: 		return 101;
223: 	}
224: 	if ((to.id() == LogicalTypeId::TIMESTAMP_SEC || to.id() == LogicalTypeId::TIMESTAMP_MS ||
225: 	     to.id() == LogicalTypeId::TIMESTAMP_NS) &&
226: 	    from.id() == LogicalTypeId::TIMESTAMP) {
227: 		//! Any timestamp type can be converted to the default (us) type at low cost
228: 		return 100;
229: 	}
230: 	switch (from.id()) {
231: 	case LogicalTypeId::TINYINT:
232: 		return ImplicitCastTinyint(to);
233: 	case LogicalTypeId::SMALLINT:
234: 		return ImplicitCastSmallint(to);
235: 	case LogicalTypeId::INTEGER:
236: 		return ImplicitCastInteger(to);
237: 	case LogicalTypeId::BIGINT:
238: 		return ImplicitCastBigint(to);
239: 	case LogicalTypeId::UTINYINT:
240: 		return ImplicitCastUTinyint(to);
241: 	case LogicalTypeId::USMALLINT:
242: 		return ImplicitCastUSmallint(to);
243: 	case LogicalTypeId::UINTEGER:
244: 		return ImplicitCastUInteger(to);
245: 	case LogicalTypeId::UBIGINT:
246: 		return ImplicitCastUBigint(to);
247: 	case LogicalTypeId::HUGEINT:
248: 		return ImplicitCastHugeint(to);
249: 	case LogicalTypeId::FLOAT:
250: 		return ImplicitCastFloat(to);
251: 	case LogicalTypeId::DOUBLE:
252: 		return ImplicitCastDouble(to);
253: 	case LogicalTypeId::DATE:
254: 		return ImplicitCastDate(to);
255: 	case LogicalTypeId::DECIMAL:
256: 		return ImplicitCastDecimal(to);
257: 	default:
258: 		return -1;
259: 	}
260: }
261: 
262: } // namespace duckdb
[end of src/function/cast_rules.cpp]
[start of src/function/function.cpp]
1: #include "duckdb/function/function.hpp"
2: 
3: #include "duckdb/catalog/catalog.hpp"
4: #include "duckdb/catalog/catalog_entry/scalar_function_catalog_entry.hpp"
5: #include "duckdb/common/types/hash.hpp"
6: #include "duckdb/common/limits.hpp"
7: #include "duckdb/common/string_util.hpp"
8: #include "duckdb/function/aggregate_function.hpp"
9: #include "duckdb/function/cast_rules.hpp"
10: #include "duckdb/function/scalar/string_functions.hpp"
11: #include "duckdb/function/scalar_function.hpp"
12: #include "duckdb/parser/parsed_data/create_aggregate_function_info.hpp"
13: #include "duckdb/parser/parsed_data/create_collation_info.hpp"
14: #include "duckdb/parser/parsed_data/create_copy_function_info.hpp"
15: #include "duckdb/parser/parsed_data/create_pragma_function_info.hpp"
16: #include "duckdb/parser/parsed_data/create_scalar_function_info.hpp"
17: #include "duckdb/parser/parsed_data/create_table_function_info.hpp"
18: #include "duckdb/parser/parsed_data/pragma_info.hpp"
19: #include "duckdb/planner/expression/bound_aggregate_expression.hpp"
20: #include "duckdb/planner/expression/bound_cast_expression.hpp"
21: #include "duckdb/planner/expression/bound_function_expression.hpp"
22: #include "duckdb/planner/expression_binder.hpp"
23: 
24: namespace duckdb {
25: 
26: FunctionData::~FunctionData() {
27: }
28: 
29: bool FunctionData::Equals(const FunctionData *left, const FunctionData *right) {
30: 	if (left == right) {
31: 		return true;
32: 	}
33: 	if (!left || !right) {
34: 		return false;
35: 	}
36: 	return left->Equals(*right);
37: }
38: 
39: TableFunctionData::~TableFunctionData() {
40: }
41: 
42: unique_ptr<FunctionData> TableFunctionData::Copy() const {
43: 	throw InternalException("Copy not supported for TableFunctionData");
44: }
45: 
46: bool TableFunctionData::Equals(const FunctionData &other) const {
47: 	return false;
48: }
49: 
50: Function::Function(string name_p) : name(move(name_p)) {
51: }
52: Function::~Function() {
53: }
54: 
55: SimpleFunction::SimpleFunction(string name_p, vector<LogicalType> arguments_p, LogicalType varargs_p)
56:     : Function(move(name_p)), arguments(move(arguments_p)), varargs(move(varargs_p)) {
57: }
58: 
59: SimpleFunction::~SimpleFunction() {
60: }
61: 
62: string SimpleFunction::ToString() {
63: 	return Function::CallToString(name, arguments);
64: }
65: 
66: bool SimpleFunction::HasVarArgs() const {
67: 	return varargs.id() != LogicalTypeId::INVALID;
68: }
69: 
70: SimpleNamedParameterFunction::SimpleNamedParameterFunction(string name_p, vector<LogicalType> arguments_p,
71:                                                            LogicalType varargs_p)
72:     : SimpleFunction(move(name_p), move(arguments_p), move(varargs_p)) {
73: }
74: 
75: SimpleNamedParameterFunction::~SimpleNamedParameterFunction() {
76: }
77: 
78: string SimpleNamedParameterFunction::ToString() {
79: 	return Function::CallToString(name, arguments, named_parameters);
80: }
81: 
82: bool SimpleNamedParameterFunction::HasNamedParameters() {
83: 	return !named_parameters.empty();
84: }
85: 
86: BaseScalarFunction::BaseScalarFunction(string name_p, vector<LogicalType> arguments_p, LogicalType return_type_p,
87:                                        bool has_side_effects, LogicalType varargs_p, bool propagates_null_values_p)
88:     : SimpleFunction(move(name_p), move(arguments_p), move(varargs_p)), return_type(move(return_type_p)),
89:       has_side_effects(has_side_effects), propagates_null_values(propagates_null_values_p) {
90: }
91: 
92: BaseScalarFunction::~BaseScalarFunction() {
93: }
94: 
95: string BaseScalarFunction::ToString() {
96: 	return Function::CallToString(name, arguments, return_type);
97: }
98: 
99: // add your initializer for new functions here
100: void BuiltinFunctions::Initialize() {
101: 	RegisterSQLiteFunctions();
102: 	RegisterReadFunctions();
103: 	RegisterTableFunctions();
104: 	RegisterArrowFunctions();
105: 
106: 	RegisterAlgebraicAggregates();
107: 	RegisterDistributiveAggregates();
108: 	RegisterNestedAggregates();
109: 	RegisterHolisticAggregates();
110: 	RegisterRegressiveAggregates();
111: 
112: 	RegisterDateFunctions();
113: 	RegisterEnumFunctions();
114: 	RegisterGenericFunctions();
115: 	RegisterMathFunctions();
116: 	RegisterOperators();
117: 	RegisterSequenceFunctions();
118: 	RegisterStringFunctions();
119: 	RegisterNestedFunctions();
120: 	RegisterTrigonometricsFunctions();
121: 
122: 	RegisterPragmaFunctions();
123: 
124: 	// initialize collations
125: 	AddCollation("nocase", LowerFun::GetFunction(), true);
126: 	AddCollation("noaccent", StripAccentsFun::GetFunction());
127: 	AddCollation("nfc", NFCNormalizeFun::GetFunction());
128: }
129: 
130: BuiltinFunctions::BuiltinFunctions(ClientContext &context, Catalog &catalog) : context(context), catalog(catalog) {
131: }
132: 
133: void BuiltinFunctions::AddCollation(string name, ScalarFunction function, bool combinable,
134:                                     bool not_required_for_equality) {
135: 	CreateCollationInfo info(move(name), move(function), combinable, not_required_for_equality);
136: 	catalog.CreateCollation(context, &info);
137: }
138: 
139: void BuiltinFunctions::AddFunction(AggregateFunctionSet set) {
140: 	CreateAggregateFunctionInfo info(move(set));
141: 	catalog.CreateFunction(context, &info);
142: }
143: 
144: void BuiltinFunctions::AddFunction(AggregateFunction function) {
145: 	CreateAggregateFunctionInfo info(move(function));
146: 	catalog.CreateFunction(context, &info);
147: }
148: 
149: void BuiltinFunctions::AddFunction(PragmaFunction function) {
150: 	CreatePragmaFunctionInfo info(move(function));
151: 	catalog.CreatePragmaFunction(context, &info);
152: }
153: 
154: void BuiltinFunctions::AddFunction(const string &name, vector<PragmaFunction> functions) {
155: 	CreatePragmaFunctionInfo info(name, move(functions));
156: 	catalog.CreatePragmaFunction(context, &info);
157: }
158: 
159: void BuiltinFunctions::AddFunction(ScalarFunction function) {
160: 	CreateScalarFunctionInfo info(move(function));
161: 	catalog.CreateFunction(context, &info);
162: }
163: 
164: void BuiltinFunctions::AddFunction(const vector<string> &names, ScalarFunction function) { // NOLINT: false positive
165: 	for (auto &name : names) {
166: 		function.name = name;
167: 		AddFunction(function);
168: 	}
169: }
170: 
171: void BuiltinFunctions::AddFunction(ScalarFunctionSet set) {
172: 	CreateScalarFunctionInfo info(move(set));
173: 	catalog.CreateFunction(context, &info);
174: }
175: 
176: void BuiltinFunctions::AddFunction(TableFunction function) {
177: 	CreateTableFunctionInfo info(move(function));
178: 	catalog.CreateTableFunction(context, &info);
179: }
180: 
181: void BuiltinFunctions::AddFunction(TableFunctionSet set) {
182: 	CreateTableFunctionInfo info(move(set));
183: 	catalog.CreateTableFunction(context, &info);
184: }
185: 
186: void BuiltinFunctions::AddFunction(CopyFunction function) {
187: 	CreateCopyFunctionInfo info(move(function));
188: 	catalog.CreateCopyFunction(context, &info);
189: }
190: 
191: hash_t BaseScalarFunction::Hash() const {
192: 	hash_t hash = return_type.Hash();
193: 	for (auto &arg : arguments) {
194: 		duckdb::CombineHash(hash, arg.Hash());
195: 	}
196: 	return hash;
197: }
198: 
199: string Function::CallToString(const string &name, const vector<LogicalType> &arguments) {
200: 	string result = name + "(";
201: 	result += StringUtil::Join(arguments, arguments.size(), ", ",
202: 	                           [](const LogicalType &argument) { return argument.ToString(); });
203: 	return result + ")";
204: }
205: 
206: string Function::CallToString(const string &name, const vector<LogicalType> &arguments,
207:                               const LogicalType &return_type) {
208: 	string result = CallToString(name, arguments);
209: 	result += " -> " + return_type.ToString();
210: 	return result;
211: }
212: 
213: string Function::CallToString(const string &name, const vector<LogicalType> &arguments,
214:                               const named_parameter_type_map_t &named_parameters) {
215: 	vector<string> input_arguments;
216: 	input_arguments.reserve(arguments.size() + named_parameters.size());
217: 	for (auto &arg : arguments) {
218: 		input_arguments.push_back(arg.ToString());
219: 	}
220: 	for (auto &kv : named_parameters) {
221: 		input_arguments.push_back(StringUtil::Format("%s : %s", kv.first, kv.second.ToString()));
222: 	}
223: 	return StringUtil::Format("%s(%s)", name, StringUtil::Join(input_arguments, ", "));
224: }
225: 
226: static int64_t BindVarArgsFunctionCost(SimpleFunction &func, vector<LogicalType> &arguments) {
227: 	if (arguments.size() < func.arguments.size()) {
228: 		// not enough arguments to fulfill the non-vararg part of the function
229: 		return -1;
230: 	}
231: 	int64_t cost = 0;
232: 	for (idx_t i = 0; i < arguments.size(); i++) {
233: 		LogicalType arg_type = i < func.arguments.size() ? func.arguments[i] : func.varargs;
234: 		if (arguments[i] == arg_type) {
235: 			// arguments match: do nothing
236: 			continue;
237: 		}
238: 		int64_t cast_cost = CastRules::ImplicitCast(arguments[i], arg_type);
239: 		if (cast_cost >= 0) {
240: 			// we can implicitly cast, add the cost to the total cost
241: 			cost += cast_cost;
242: 		} else {
243: 			// we can't implicitly cast: throw an error
244: 			return -1;
245: 		}
246: 	}
247: 	return cost;
248: }
249: 
250: static int64_t BindFunctionCost(SimpleFunction &func, vector<LogicalType> &arguments) {
251: 	if (func.HasVarArgs()) {
252: 		// special case varargs function
253: 		return BindVarArgsFunctionCost(func, arguments);
254: 	}
255: 	if (func.arguments.size() != arguments.size()) {
256: 		// invalid argument count: check the next function
257: 		return -1;
258: 	}
259: 	int64_t cost = 0;
260: 	for (idx_t i = 0; i < arguments.size(); i++) {
261: 		if (arguments[i].id() == func.arguments[i].id()) {
262: 			// arguments match: do nothing
263: 			continue;
264: 		}
265: 		int64_t cast_cost = CastRules::ImplicitCast(arguments[i], func.arguments[i]);
266: 		if (cast_cost >= 0) {
267: 			// we can implicitly cast, add the cost to the total cost
268: 			cost += cast_cost;
269: 		} else {
270: 			// we can't implicitly cast: throw an error
271: 			return -1;
272: 		}
273: 	}
274: 	return cost;
275: }
276: 
277: template <class T>
278: static idx_t BindFunctionFromArguments(const string &name, vector<T> &functions, vector<LogicalType> &arguments,
279:                                        string &error) {
280: 	idx_t best_function = DConstants::INVALID_INDEX;
281: 	int64_t lowest_cost = NumericLimits<int64_t>::Maximum();
282: 	vector<idx_t> conflicting_functions;
283: 	for (idx_t f_idx = 0; f_idx < functions.size(); f_idx++) {
284: 		auto &func = functions[f_idx];
285: 		// check the arguments of the function
286: 		int64_t cost = BindFunctionCost(func, arguments);
287: 		if (cost < 0) {
288: 			// auto casting was not possible
289: 			continue;
290: 		}
291: 		if (cost == lowest_cost) {
292: 			conflicting_functions.push_back(f_idx);
293: 			continue;
294: 		}
295: 		if (cost > lowest_cost) {
296: 			continue;
297: 		}
298: 		conflicting_functions.clear();
299: 		lowest_cost = cost;
300: 		best_function = f_idx;
301: 	}
302: 	if (!conflicting_functions.empty()) {
303: 		// there are multiple possible function definitions
304: 		// throw an exception explaining which overloads are there
305: 		conflicting_functions.push_back(best_function);
306: 		string call_str = Function::CallToString(name, arguments);
307: 		string candidate_str = "";
308: 		for (auto &conf : conflicting_functions) {
309: 			auto &f = functions[conf];
310: 			candidate_str += "\t" + f.ToString() + "\n";
311: 		}
312: 		error =
313: 		    StringUtil::Format("Could not choose a best candidate function for the function call \"%s\". In order to "
314: 		                       "select one, please add explicit type casts.\n\tCandidate functions:\n%s",
315: 		                       call_str, candidate_str);
316: 		return DConstants::INVALID_INDEX;
317: 	}
318: 	if (best_function == DConstants::INVALID_INDEX) {
319: 		// no matching function was found, throw an error
320: 		string call_str = Function::CallToString(name, arguments);
321: 		string candidate_str = "";
322: 		for (auto &f : functions) {
323: 			candidate_str += "\t" + f.ToString() + "\n";
324: 		}
325: 		error = StringUtil::Format("No function matches the given name and argument types '%s'. You might need to add "
326: 		                           "explicit type casts.\n\tCandidate functions:\n%s",
327: 		                           call_str, candidate_str);
328: 		return DConstants::INVALID_INDEX;
329: 	}
330: 	return best_function;
331: }
332: 
333: idx_t Function::BindFunction(const string &name, vector<ScalarFunction> &functions, vector<LogicalType> &arguments,
334:                              string &error) {
335: 	return BindFunctionFromArguments(name, functions, arguments, error);
336: }
337: 
338: idx_t Function::BindFunction(const string &name, vector<AggregateFunction> &functions, vector<LogicalType> &arguments,
339:                              string &error) {
340: 	return BindFunctionFromArguments(name, functions, arguments, error);
341: }
342: 
343: idx_t Function::BindFunction(const string &name, vector<TableFunction> &functions, vector<LogicalType> &arguments,
344:                              string &error) {
345: 	return BindFunctionFromArguments(name, functions, arguments, error);
346: }
347: 
348: idx_t Function::BindFunction(const string &name, vector<PragmaFunction> &functions, PragmaInfo &info, string &error) {
349: 	vector<LogicalType> types;
350: 	for (auto &value : info.parameters) {
351: 		types.push_back(value.type());
352: 	}
353: 	idx_t entry = BindFunctionFromArguments(name, functions, types, error);
354: 	if (entry == DConstants::INVALID_INDEX) {
355: 		throw BinderException(error);
356: 	}
357: 	auto &candidate_function = functions[entry];
358: 	// cast the input parameters
359: 	for (idx_t i = 0; i < info.parameters.size(); i++) {
360: 		auto target_type =
361: 		    i < candidate_function.arguments.size() ? candidate_function.arguments[i] : candidate_function.varargs;
362: 		info.parameters[i] = info.parameters[i].CastAs(target_type);
363: 	}
364: 	return entry;
365: }
366: 
367: vector<LogicalType> GetLogicalTypesFromExpressions(vector<unique_ptr<Expression>> &arguments) {
368: 	vector<LogicalType> types;
369: 	types.reserve(arguments.size());
370: 	for (auto &argument : arguments) {
371: 		types.push_back(argument->return_type);
372: 	}
373: 	return types;
374: }
375: 
376: idx_t Function::BindFunction(const string &name, vector<ScalarFunction> &functions,
377:                              vector<unique_ptr<Expression>> &arguments, string &error) {
378: 	auto types = GetLogicalTypesFromExpressions(arguments);
379: 	return Function::BindFunction(name, functions, types, error);
380: }
381: 
382: idx_t Function::BindFunction(const string &name, vector<AggregateFunction> &functions,
383:                              vector<unique_ptr<Expression>> &arguments, string &error) {
384: 	auto types = GetLogicalTypesFromExpressions(arguments);
385: 	return Function::BindFunction(name, functions, types, error);
386: }
387: 
388: idx_t Function::BindFunction(const string &name, vector<TableFunction> &functions,
389:                              vector<unique_ptr<Expression>> &arguments, string &error) {
390: 	auto types = GetLogicalTypesFromExpressions(arguments);
391: 	return Function::BindFunction(name, functions, types, error);
392: }
393: 
394: enum class LogicalTypeComparisonResult { IDENTICAL_TYPE, TARGET_IS_ANY, DIFFERENT_TYPES };
395: 
396: LogicalTypeComparisonResult RequiresCast(const LogicalType &source_type, const LogicalType &target_type) {
397: 	if (target_type.id() == LogicalTypeId::ANY) {
398: 		return LogicalTypeComparisonResult::TARGET_IS_ANY;
399: 	}
400: 	if (source_type == target_type) {
401: 		return LogicalTypeComparisonResult::IDENTICAL_TYPE;
402: 	}
403: 	if (source_type.id() == LogicalTypeId::LIST && target_type.id() == LogicalTypeId::LIST) {
404: 		return RequiresCast(ListType::GetChildType(source_type), ListType::GetChildType(target_type));
405: 	}
406: 	return LogicalTypeComparisonResult::DIFFERENT_TYPES;
407: }
408: 
409: void BaseScalarFunction::CastToFunctionArguments(vector<unique_ptr<Expression>> &children) {
410: 	for (idx_t i = 0; i < children.size(); i++) {
411: 		auto target_type = i < this->arguments.size() ? this->arguments[i] : this->varargs;
412: 		target_type.Verify();
413: 		// check if the type of child matches the type of function argument
414: 		// if not we need to add a cast
415: 		auto cast_result = RequiresCast(children[i]->return_type, target_type);
416: 		// except for one special case: if the function accepts ANY argument
417: 		// in that case we don't add a cast
418: 		if (cast_result == LogicalTypeComparisonResult::TARGET_IS_ANY) {
419: 			if (children[i]->return_type.id() == LogicalTypeId::UNKNOWN) {
420: 				// UNLESS the child is a prepared statement parameter
421: 				// in that case we default the prepared statement parameter to VARCHAR
422: 				children[i]->return_type =
423: 				    ExpressionBinder::ExchangeType(target_type, LogicalTypeId::ANY, LogicalType::VARCHAR);
424: 			}
425: 		} else if (cast_result == LogicalTypeComparisonResult::DIFFERENT_TYPES) {
426: 			children[i] = BoundCastExpression::AddCastToType(move(children[i]), target_type);
427: 		}
428: 	}
429: }
430: 
431: unique_ptr<BoundFunctionExpression> ScalarFunction::BindScalarFunction(ClientContext &context, const string &schema,
432:                                                                        const string &name,
433:                                                                        vector<unique_ptr<Expression>> children,
434:                                                                        string &error, bool is_operator) {
435: 	// bind the function
436: 	auto function = Catalog::GetCatalog(context).GetEntry(context, CatalogType::SCALAR_FUNCTION_ENTRY, schema, name);
437: 	D_ASSERT(function && function->type == CatalogType::SCALAR_FUNCTION_ENTRY);
438: 	return ScalarFunction::BindScalarFunction(context, (ScalarFunctionCatalogEntry &)*function, move(children), error,
439: 	                                          is_operator);
440: }
441: 
442: unique_ptr<BoundFunctionExpression> ScalarFunction::BindScalarFunction(ClientContext &context,
443:                                                                        ScalarFunctionCatalogEntry &func,
444:                                                                        vector<unique_ptr<Expression>> children,
445:                                                                        string &error, bool is_operator) {
446: 	// bind the function
447: 	idx_t best_function = Function::BindFunction(func.name, func.functions, children, error);
448: 	if (best_function == DConstants::INVALID_INDEX) {
449: 		return nullptr;
450: 	}
451: 	// found a matching function!
452: 	auto &bound_function = func.functions[best_function];
453: 	return ScalarFunction::BindScalarFunction(context, bound_function, move(children), is_operator);
454: }
455: 
456: unique_ptr<BoundFunctionExpression> ScalarFunction::BindScalarFunction(ClientContext &context,
457:                                                                        ScalarFunction bound_function,
458:                                                                        vector<unique_ptr<Expression>> children,
459:                                                                        bool is_operator) {
460: 	unique_ptr<FunctionData> bind_info;
461: 	if (bound_function.bind) {
462: 		bind_info = bound_function.bind(context, bound_function, children);
463: 	}
464: 	// check if we need to add casts to the children
465: 	bound_function.CastToFunctionArguments(children);
466: 
467: 	// now create the function
468: 	auto return_type = bound_function.return_type;
469: 	return make_unique<BoundFunctionExpression>(move(return_type), move(bound_function), move(children),
470: 	                                            move(bind_info), is_operator);
471: }
472: 
473: unique_ptr<BoundAggregateExpression>
474: AggregateFunction::BindAggregateFunction(ClientContext &context, AggregateFunction bound_function,
475:                                          vector<unique_ptr<Expression>> children, unique_ptr<Expression> filter,
476:                                          bool is_distinct, unique_ptr<BoundOrderModifier> order_bys) {
477: 	unique_ptr<FunctionData> bind_info;
478: 	if (bound_function.bind) {
479: 		bind_info = bound_function.bind(context, bound_function, children);
480: 		// we may have lost some arguments in the bind
481: 		children.resize(MinValue(bound_function.arguments.size(), children.size()));
482: 	}
483: 
484: 	// check if we need to add casts to the children
485: 	bound_function.CastToFunctionArguments(children);
486: 
487: 	// Special case: for ORDER BY aggregates, we wrap the aggregate function in a SortedAggregateFunction
488: 	// The children are the sort clauses and the binding contains the ordering data.
489: 	if (order_bys && !order_bys->orders.empty()) {
490: 		bind_info = BindSortedAggregate(bound_function, children, move(bind_info), move(order_bys));
491: 	}
492: 
493: 	return make_unique<BoundAggregateExpression>(move(bound_function), move(children), move(filter), move(bind_info),
494: 	                                             is_distinct);
495: }
496: 
497: } // namespace duckdb
[end of src/function/function.cpp]
[start of src/function/scalar/list/array_slice.cpp]
1: #include "duckdb/planner/expression/bound_function_expression.hpp"
2: #include "duckdb/common/string_util.hpp"
3: #include "duckdb/parser/expression/bound_expression.hpp"
4: #include "duckdb/function/scalar/nested_functions.hpp"
5: #include "duckdb/common/types/chunk_collection.hpp"
6: #include "duckdb/common/types/data_chunk.hpp"
7: #include "duckdb/common/pair.hpp"
8: #include "duckdb/function/scalar/string_functions.hpp"
9: 
10: namespace duckdb {
11: 
12: template <typename INPUT_TYPE, typename INDEX_TYPE>
13: INDEX_TYPE ValueOffset(const INPUT_TYPE &value) {
14: 	return 0;
15: }
16: 
17: template <>
18: int64_t ValueOffset(const list_entry_t &value) {
19: 	return value.offset;
20: }
21: 
22: template <typename INPUT_TYPE, typename INDEX_TYPE>
23: INDEX_TYPE ValueLength(const INPUT_TYPE &value) {
24: 	return 0;
25: }
26: 
27: template <>
28: int64_t ValueLength(const list_entry_t &value) {
29: 	return value.length;
30: }
31: 
32: template <>
33: int32_t ValueLength(const string_t &value) {
34: 	return LengthFun::Length<string_t, int32_t>(value);
35: }
36: 
37: template <typename INPUT_TYPE, typename INDEX_TYPE>
38: bool ClampIndex(INDEX_TYPE &index, const INPUT_TYPE &value) {
39: 	const auto length = ValueLength<INPUT_TYPE, INDEX_TYPE>(value);
40: 	if (index < 0) {
41: 		if (-index > length) {
42: 			return false;
43: 		}
44: 		index = length + index;
45: 	} else if (index > length) {
46: 		index = length;
47: 	}
48: 	return true;
49: }
50: 
51: template <typename INPUT_TYPE, typename INDEX_TYPE>
52: static bool ClampSlice(const INPUT_TYPE &value, INDEX_TYPE &begin, INDEX_TYPE &end, bool begin_valid, bool end_valid) {
53: 	// Clamp offsets
54: 	begin = begin_valid ? begin : 0;
55: 	end = end_valid ? end : ValueLength<INPUT_TYPE, INDEX_TYPE>(value);
56: 	if (!ClampIndex(begin, value) || !ClampIndex(end, value)) {
57: 		return false;
58: 	}
59: 	end = MaxValue<INDEX_TYPE>(begin, end);
60: 
61: 	return true;
62: }
63: 
64: template <typename INPUT_TYPE, typename INDEX_TYPE>
65: INPUT_TYPE SliceValue(Vector &result, INPUT_TYPE input, INDEX_TYPE begin, INDEX_TYPE end) {
66: 	return input;
67: }
68: 
69: template <>
70: list_entry_t SliceValue(Vector &result, list_entry_t input, int64_t begin, int64_t end) {
71: 	input.offset += begin;
72: 	input.length = end - begin;
73: 	return input;
74: }
75: 
76: template <>
77: string_t SliceValue(Vector &result, string_t input, int32_t begin, int32_t end) {
78: 	// one-based - zero has strange semantics
79: 	return SubstringFun::SubstringScalarFunction(result, input, begin + 1, end - begin);
80: }
81: 
82: template <typename INPUT_TYPE, typename INDEX_TYPE>
83: static void ExecuteSlice(Vector &result, Vector &s, Vector &b, Vector &e, const idx_t count) {
84: 	if (result.GetVectorType() == VectorType::CONSTANT_VECTOR) {
85: 		auto rdata = ConstantVector::GetData<INPUT_TYPE>(result);
86: 		auto sdata = ConstantVector::GetData<INPUT_TYPE>(s);
87: 		auto bdata = ConstantVector::GetData<INDEX_TYPE>(b);
88: 		auto edata = ConstantVector::GetData<INDEX_TYPE>(e);
89: 
90: 		auto sliced = sdata[0];
91: 		auto begin = (bdata[0] > 0) ? bdata[0] - 1 : bdata[0];
92: 		auto end = edata[0];
93: 
94: 		auto svalid = !ConstantVector::IsNull(s);
95: 		auto bvalid = !ConstantVector::IsNull(b);
96: 		auto evalid = !ConstantVector::IsNull(e);
97: 
98: 		// Try to slice
99: 		if (!svalid || !ClampSlice(sliced, begin, end, bvalid, evalid)) {
100: 			ConstantVector::SetNull(result, true);
101: 		} else {
102: 			rdata[0] = SliceValue<INPUT_TYPE, INDEX_TYPE>(result, sliced, begin, end);
103: 		}
104: 	} else {
105: 		VectorData sdata, bdata, edata;
106: 
107: 		s.Orrify(count, sdata);
108: 		b.Orrify(count, bdata);
109: 		e.Orrify(count, edata);
110: 
111: 		auto rdata = FlatVector::GetData<INPUT_TYPE>(result);
112: 		auto &rmask = FlatVector::Validity(result);
113: 
114: 		for (idx_t i = 0; i < count; ++i) {
115: 			auto sidx = sdata.sel->get_index(i);
116: 			auto bidx = bdata.sel->get_index(i);
117: 			auto eidx = edata.sel->get_index(i);
118: 
119: 			auto sliced = ((INPUT_TYPE *)sdata.data)[sidx];
120: 			auto begin = ((INDEX_TYPE *)bdata.data)[bidx];
121: 			auto end = ((INDEX_TYPE *)edata.data)[eidx];
122: 
123: 			begin = (begin > 0) ? begin - 1 : begin;
124: 
125: 			auto svalid = sdata.validity.RowIsValid(sidx);
126: 			auto bvalid = bdata.validity.RowIsValid(bidx);
127: 			auto evalid = edata.validity.RowIsValid(eidx);
128: 
129: 			// Try to slice
130: 			if (!svalid || !ClampSlice(sliced, begin, end, bvalid, evalid)) {
131: 				rmask.SetInvalid(i);
132: 			} else {
133: 				rdata[i] = SliceValue<INPUT_TYPE, INDEX_TYPE>(result, sliced, begin, end);
134: 			}
135: 		}
136: 	}
137: 
138: 	result.Verify(count);
139: }
140: 
141: static void ArraySliceFunction(DataChunk &args, ExpressionState &state, Vector &result) {
142: 	D_ASSERT(args.ColumnCount() == 3);
143: 	D_ASSERT(args.data.size() == 3);
144: 	auto count = args.size();
145: 
146: 	Vector &s = args.data[0];
147: 	Vector &b = args.data[1];
148: 	Vector &e = args.data[2];
149: 
150: 	s.Normalify(count);
151: 	switch (result.GetType().id()) {
152: 	case LogicalTypeId::LIST:
153: 		// Share the value dictionary as we are just going to slice it
154: 		ListVector::ReferenceEntry(result, s);
155: 		ExecuteSlice<list_entry_t, int64_t>(result, s, b, e, count);
156: 		break;
157: 	case LogicalTypeId::VARCHAR:
158: 		ExecuteSlice<string_t, int32_t>(result, s, b, e, count);
159: 		break;
160: 	default:
161: 		throw NotImplementedException("Specifier type not implemented");
162: 	}
163: 
164: 	result.SetVectorType(VectorType::CONSTANT_VECTOR);
165: 	for (idx_t i = 0; i < args.ColumnCount(); i++) {
166: 		if (args.data[i].GetVectorType() != VectorType::CONSTANT_VECTOR) {
167: 			result.SetVectorType(VectorType::FLAT_VECTOR);
168: 			break;
169: 		}
170: 	}
171: }
172: 
173: static unique_ptr<FunctionData> ArraySliceBind(ClientContext &context, ScalarFunction &bound_function,
174:                                                vector<unique_ptr<Expression>> &arguments) {
175: 	D_ASSERT(bound_function.arguments.size() == 3);
176: 	switch (arguments[0]->return_type.id()) {
177: 	case LogicalTypeId::LIST:
178: 		// The result is the same type
179: 		bound_function.return_type = arguments[0]->return_type;
180: 		break;
181: 	case LogicalTypeId::VARCHAR:
182: 		// string slice returns a string, but can only accept 32 bit integers
183: 		bound_function.return_type = arguments[0]->return_type;
184: 		bound_function.arguments[1] = LogicalType::INTEGER;
185: 		bound_function.arguments[2] = LogicalType::INTEGER;
186: 		break;
187: 	default:
188: 		throw BinderException("ARRAY_SLICE can only operate on LISTs and VARCHARs");
189: 	}
190: 
191: 	return make_unique<VariableReturnBindData>(bound_function.return_type);
192: }
193: 
194: void ArraySliceFun::RegisterFunction(BuiltinFunctions &set) {
195: 	// the arguments and return types are actually set in the binder function
196: 	ScalarFunction fun({LogicalType::ANY, LogicalType::BIGINT, LogicalType::BIGINT}, LogicalType::ANY,
197: 	                   ArraySliceFunction, false, false, ArraySliceBind);
198: 	fun.varargs = LogicalType::ANY;
199: 	set.AddFunction({"array_slice", "list_slice"}, fun);
200: }
201: 
202: } // namespace duckdb
[end of src/function/scalar/list/array_slice.cpp]
[start of src/function/scalar/list/contains_or_position.cpp]
1: #include "duckdb/planner/expression/bound_function_expression.hpp"
2: #include "duckdb/function/scalar/nested_functions.hpp"
3: #include "duckdb/planner/expression_binder.hpp"
4: 
5: namespace duckdb {
6: 
7: template <class T>
8: static inline bool ValueEqualsOrNot(const T &left, const T &right) {
9: 	return left == right;
10: }
11: 
12: template <>
13: inline bool ValueEqualsOrNot(const string_t &left, const string_t &right) {
14: 	return StringComparisonOperators::EqualsOrNot<false>(left, right);
15: }
16: 
17: struct ContainsFunctor {
18: 	static inline bool Initialize() {
19: 		return false;
20: 	}
21: 	static inline bool UpdateResultEntries(idx_t child_idx) {
22: 		return true;
23: 	}
24: };
25: 
26: struct PositionFunctor {
27: 	static inline int32_t Initialize() {
28: 		return 0;
29: 	}
30: 	static inline int32_t UpdateResultEntries(idx_t child_idx) {
31: 		return child_idx + 1;
32: 	}
33: };
34: 
35: template <class CHILD_TYPE, class RETURN_TYPE, class OP>
36: static void TemplatedContainsOrPosition(DataChunk &args, ExpressionState &state, Vector &result,
37:                                         bool is_nested = false) {
38: 	D_ASSERT(args.ColumnCount() == 2);
39: 	auto count = args.size();
40: 	Vector &list = args.data[0];
41: 	Vector &value_vector = args.data[1];
42: 
43: 	// Create a result vector of type RETURN_TYPE
44: 	result.SetVectorType(VectorType::FLAT_VECTOR);
45: 	auto result_entries = FlatVector::GetData<RETURN_TYPE>(result);
46: 	auto &result_validity = FlatVector::Validity(result);
47: 
48: 	if (list.GetType().id() == LogicalTypeId::SQLNULL) {
49: 		result_validity.SetInvalid(0);
50: 		return;
51: 	}
52: 
53: 	auto list_size = ListVector::GetListSize(list);
54: 	auto &child_vector = ListVector::GetEntry(list);
55: 
56: 	VectorData child_data;
57: 	child_vector.Orrify(list_size, child_data);
58: 
59: 	VectorData list_data;
60: 	list.Orrify(count, list_data);
61: 	auto list_entries = (list_entry_t *)list_data.data;
62: 
63: 	VectorData value_data;
64: 	value_vector.Orrify(count, value_data);
65: 
66: 	// not required for a comparison of nested types
67: 	auto child_value = FlatVector::GetData<CHILD_TYPE>(child_vector);
68: 	auto values = FlatVector::GetData<CHILD_TYPE>(value_vector);
69: 
70: 	for (idx_t i = 0; i < count; i++) {
71: 		auto list_index = list_data.sel->get_index(i);
72: 		auto value_index = value_data.sel->get_index(i);
73: 
74: 		if (!list_data.validity.RowIsValid(list_index) || !value_data.validity.RowIsValid(value_index)) {
75: 			result_validity.SetInvalid(i);
76: 			continue;
77: 		}
78: 
79: 		const auto &list_entry = list_entries[list_index];
80: 
81: 		result_entries[i] = OP::Initialize();
82: 		for (idx_t child_idx = 0; child_idx < list_entry.length; child_idx++) {
83: 
84: 			auto child_value_idx = child_data.sel->get_index(list_entry.offset + child_idx);
85: 			if (!child_data.validity.RowIsValid(child_value_idx)) {
86: 				continue;
87: 			}
88: 
89: 			if (!is_nested) {
90: 				if (ValueEqualsOrNot<CHILD_TYPE>(child_value[child_value_idx], values[value_index])) {
91: 					result_entries[i] = OP::UpdateResultEntries(child_idx);
92: 					break; // Found value in list, no need to look further
93: 				}
94: 			} else {
95: 				// FIXME: using Value is less efficient than modifying the vector comparison code
96: 				// to more efficiently compare nested types
97: 				if (ValueEqualsOrNot<Value>(child_vector.GetValue(child_value_idx),
98: 				                            value_vector.GetValue(value_index))) {
99: 					result_entries[i] = OP::UpdateResultEntries(child_idx);
100: 					break; // Found value in list, no need to look further
101: 				}
102: 			}
103: 		}
104: 	}
105: }
106: 
107: template <class T, class OP>
108: static void ListContainsOrPosition(DataChunk &args, ExpressionState &state, Vector &result) {
109: 	switch (args.data[1].GetType().InternalType()) {
110: 	case PhysicalType::BOOL:
111: 	case PhysicalType::INT8:
112: 		TemplatedContainsOrPosition<int8_t, T, OP>(args, state, result);
113: 		break;
114: 	case PhysicalType::INT16:
115: 		TemplatedContainsOrPosition<int16_t, T, OP>(args, state, result);
116: 		break;
117: 	case PhysicalType::INT32:
118: 		TemplatedContainsOrPosition<int32_t, T, OP>(args, state, result);
119: 		break;
120: 	case PhysicalType::INT64:
121: 		TemplatedContainsOrPosition<int64_t, T, OP>(args, state, result);
122: 		break;
123: 	case PhysicalType::INT128:
124: 		TemplatedContainsOrPosition<hugeint_t, T, OP>(args, state, result);
125: 		break;
126: 	case PhysicalType::UINT8:
127: 		TemplatedContainsOrPosition<uint8_t, T, OP>(args, state, result);
128: 		break;
129: 	case PhysicalType::UINT16:
130: 		TemplatedContainsOrPosition<uint16_t, T, OP>(args, state, result);
131: 		break;
132: 	case PhysicalType::UINT32:
133: 		TemplatedContainsOrPosition<uint32_t, T, OP>(args, state, result);
134: 		break;
135: 	case PhysicalType::UINT64:
136: 		TemplatedContainsOrPosition<uint64_t, T, OP>(args, state, result);
137: 		break;
138: 	case PhysicalType::FLOAT:
139: 		TemplatedContainsOrPosition<float, T, OP>(args, state, result);
140: 		break;
141: 	case PhysicalType::DOUBLE:
142: 		TemplatedContainsOrPosition<double, T, OP>(args, state, result);
143: 		break;
144: 	case PhysicalType::VARCHAR:
145: 		TemplatedContainsOrPosition<string_t, T, OP>(args, state, result);
146: 		break;
147: 	case PhysicalType::MAP:
148: 	case PhysicalType::STRUCT:
149: 	case PhysicalType::LIST:
150: 		TemplatedContainsOrPosition<int8_t, T, OP>(args, state, result, true);
151: 		break;
152: 	default:
153: 		throw NotImplementedException("This function has not been implemented for this type");
154: 	}
155: }
156: 
157: static void ListContainsFunction(DataChunk &args, ExpressionState &state, Vector &result) {
158: 	return ListContainsOrPosition<bool, ContainsFunctor>(args, state, result);
159: }
160: 
161: static void ListPositionFunction(DataChunk &args, ExpressionState &state, Vector &result) {
162: 	return ListContainsOrPosition<int32_t, PositionFunctor>(args, state, result);
163: }
164: 
165: template <LogicalTypeId RETURN_TYPE>
166: static unique_ptr<FunctionData> ListContainsOrPositionBind(ClientContext &context, ScalarFunction &bound_function,
167:                                                            vector<unique_ptr<Expression>> &arguments) {
168: 	D_ASSERT(bound_function.arguments.size() == 2);
169: 
170: 	const auto &list = arguments[0]->return_type; // change to list
171: 	const auto &value = arguments[1]->return_type;
172: 	if (list.id() == LogicalTypeId::SQLNULL && value.id() == LogicalTypeId::SQLNULL) {
173: 		bound_function.arguments[0] = LogicalType::SQLNULL;
174: 		bound_function.arguments[1] = LogicalType::SQLNULL;
175: 		bound_function.return_type = LogicalType::SQLNULL;
176: 	} else if (list.id() == LogicalTypeId::SQLNULL || value.id() == LogicalTypeId::SQLNULL) {
177: 		// In case either the list or the value is NULL, return NULL
178: 		// Similar to behaviour of prestoDB
179: 		bound_function.arguments[0] = list;
180: 		bound_function.arguments[1] = value;
181: 		bound_function.return_type = LogicalTypeId::SQLNULL;
182: 	} else {
183: 		auto const &child_type = ListType::GetChildType(arguments[0]->return_type);
184: 		auto max_child_type = LogicalType::MaxLogicalType(child_type, value);
185: 		ExpressionBinder::ResolveParameterType(max_child_type);
186: 		auto list_type = LogicalType::LIST(max_child_type);
187: 
188: 		bound_function.arguments[0] = list_type;
189: 		bound_function.arguments[1] = value == max_child_type ? value : max_child_type;
190: 
191: 		// list_contains and list_position only differ in their return type
192: 		bound_function.return_type = RETURN_TYPE;
193: 	}
194: 	return make_unique<VariableReturnBindData>(bound_function.return_type);
195: }
196: 
197: static unique_ptr<FunctionData> ListContainsBind(ClientContext &context, ScalarFunction &bound_function,
198:                                                  vector<unique_ptr<Expression>> &arguments) {
199: 	return ListContainsOrPositionBind<LogicalType::BOOLEAN>(context, bound_function, arguments);
200: }
201: 
202: static unique_ptr<FunctionData> ListPositionBind(ClientContext &context, ScalarFunction &bound_function,
203:                                                  vector<unique_ptr<Expression>> &arguments) {
204: 	return ListContainsOrPositionBind<LogicalType::INTEGER>(context, bound_function, arguments);
205: }
206: 
207: ScalarFunction ListContainsFun::GetFunction() {
208: 	return ScalarFunction({LogicalType::LIST(LogicalType::ANY), LogicalType::ANY}, // argument list
209: 	                      LogicalType::BOOLEAN,                                    // return type
210: 	                      ListContainsFunction, false, false, ListContainsBind, nullptr);
211: }
212: 
213: ScalarFunction ListPositionFun::GetFunction() {
214: 	return ScalarFunction({LogicalType::LIST(LogicalType::ANY), LogicalType::ANY}, // argument list
215: 	                      LogicalType::INTEGER,                                    // return type
216: 	                      ListPositionFunction, false, false, ListPositionBind, nullptr);
217: }
218: 
219: void ListContainsFun::RegisterFunction(BuiltinFunctions &set) {
220: 	set.AddFunction({"list_contains", "array_contains", "list_has", "array_has"}, GetFunction());
221: }
222: 
223: void ListPositionFun::RegisterFunction(BuiltinFunctions &set) {
224: 	set.AddFunction({"list_position", "list_indexof", "array_position", "array_indexof"}, GetFunction());
225: }
226: } // namespace duckdb
[end of src/function/scalar/list/contains_or_position.cpp]
[start of src/function/scalar/list/flatten.cpp]
1: #include "duckdb/common/types/data_chunk.hpp"
2: #include "duckdb/function/scalar/nested_functions.hpp"
3: #include "duckdb/planner/expression/bound_function_expression.hpp"
4: #include "duckdb/storage/statistics/list_statistics.hpp"
5: 
6: namespace duckdb {
7: 
8: void ListFlattenFunction(DataChunk &args, ExpressionState &state, Vector &result) {
9: 	D_ASSERT(args.ColumnCount() == 1);
10: 
11: 	Vector &input = args.data[0];
12: 	if (input.GetType().id() == LogicalTypeId::SQLNULL) {
13: 		result.Reference(input);
14: 		return;
15: 	}
16: 
17: 	idx_t count = args.size();
18: 
19: 	VectorData list_data;
20: 	input.Orrify(count, list_data);
21: 	auto list_entries = (list_entry_t *)list_data.data;
22: 
23: 	auto &child_vector = ListVector::GetEntry(input);
24: 
25: 	result.SetVectorType(VectorType::FLAT_VECTOR);
26: 	auto result_entries = FlatVector::GetData<list_entry_t>(result);
27: 	auto &result_validity = FlatVector::Validity(result);
28: 
29: 	if (child_vector.GetType().id() == LogicalTypeId::SQLNULL) {
30: 		auto result_entries = FlatVector::GetData<list_entry_t>(result);
31: 		for (idx_t i = 0; i < count; i++) {
32: 			auto list_index = list_data.sel->get_index(i);
33: 			if (!list_data.validity.RowIsValid(list_index)) {
34: 				result_validity.SetInvalid(i);
35: 				continue;
36: 			}
37: 			result_entries[i].offset = 0;
38: 			result_entries[i].length = 0;
39: 		}
40: 		return;
41: 	}
42: 
43: 	auto child_size = ListVector::GetListSize(input);
44: 	VectorData child_data;
45: 	child_vector.Orrify(child_size, child_data);
46: 	auto child_entries = (list_entry_t *)child_data.data;
47: 	auto &data_vector = ListVector::GetEntry(child_vector);
48: 
49: 	idx_t offset = 0;
50: 	for (idx_t i = 0; i < count; i++) {
51: 		auto list_index = list_data.sel->get_index(i);
52: 		if (!list_data.validity.RowIsValid(list_index)) {
53: 			result_validity.SetInvalid(i);
54: 			continue;
55: 		}
56: 		auto list_entry = list_entries[list_index];
57: 
58: 		idx_t source_offset = 0;
59: 		// Find first valid child list entry to get offset
60: 		for (idx_t j = 0; j < list_entry.length; j++) {
61: 			auto child_list_index = child_data.sel->get_index(list_entry.offset + j);
62: 			if (child_data.validity.RowIsValid(child_list_index)) {
63: 				source_offset = child_entries[child_list_index].offset;
64: 				break;
65: 			}
66: 		}
67: 
68: 		idx_t length = 0;
69: 		// Find last valid child list entry to get length
70: 		for (idx_t j = list_entry.length - 1; j != (idx_t)-1; j--) {
71: 			auto child_list_index = child_data.sel->get_index(list_entry.offset + j);
72: 			if (child_data.validity.RowIsValid(child_list_index)) {
73: 				auto child_entry = child_entries[child_list_index];
74: 				length = child_entry.offset + child_entry.length - source_offset;
75: 				break;
76: 			}
77: 		}
78: 		ListVector::Append(result, data_vector, source_offset + length, source_offset);
79: 
80: 		result_entries[i].offset = offset;
81: 		result_entries[i].length = length;
82: 		offset += length;
83: 	}
84: 
85: 	if (input.GetVectorType() == VectorType::CONSTANT_VECTOR) {
86: 		result.SetVectorType(VectorType::CONSTANT_VECTOR);
87: 	}
88: }
89: 
90: static unique_ptr<FunctionData> ListFlattenBind(ClientContext &context, ScalarFunction &bound_function,
91:                                                 vector<unique_ptr<Expression>> &arguments) {
92: 	D_ASSERT(bound_function.arguments.size() == 1);
93: 
94: 	auto &input_type = arguments[0]->return_type;
95: 	bound_function.arguments[0] = input_type;
96: 	if (input_type.id() == LogicalTypeId::SQLNULL) {
97: 		bound_function.return_type = LogicalType(LogicalTypeId::SQLNULL);
98: 		return make_unique<VariableReturnBindData>(bound_function.return_type);
99: 	}
100: 	D_ASSERT(input_type.id() == LogicalTypeId::LIST);
101: 
102: 	auto child_type = ListType::GetChildType(input_type);
103: 	if (child_type.id() == LogicalType::SQLNULL) {
104: 		bound_function.return_type = input_type;
105: 		return make_unique<VariableReturnBindData>(bound_function.return_type);
106: 	}
107: 	D_ASSERT(child_type.id() == LogicalTypeId::LIST);
108: 
109: 	bound_function.return_type = child_type;
110: 	return make_unique<VariableReturnBindData>(bound_function.return_type);
111: }
112: 
113: static unique_ptr<BaseStatistics> ListFlattenStats(ClientContext &context, BoundFunctionExpression &expr,
114:                                                    FunctionData *bind_data,
115:                                                    vector<unique_ptr<BaseStatistics>> &child_stats) {
116: 	if (!child_stats[0]) {
117: 		return nullptr;
118: 	}
119: 	auto &list_stats = (ListStatistics &)*child_stats[0];
120: 	if (!list_stats.child_stats || list_stats.child_stats->type == LogicalTypeId::SQLNULL) {
121: 		return nullptr;
122: 	}
123: 
124: 	auto child_copy = list_stats.child_stats->Copy();
125: 	child_copy->validity_stats = make_unique<ValidityStatistics>(true);
126: 	return child_copy;
127: }
128: 
129: void ListFlattenFun::RegisterFunction(BuiltinFunctions &set) {
130: 	ScalarFunction fun({LogicalType::LIST(LogicalType::LIST(LogicalType::ANY))}, LogicalType::LIST(LogicalType::ANY),
131: 	                   ListFlattenFunction, false, false, ListFlattenBind, nullptr, ListFlattenStats);
132: 	set.AddFunction({"flatten"}, fun);
133: }
134: 
135: } // namespace duckdb
[end of src/function/scalar/list/flatten.cpp]
[start of src/function/scalar/list/list_aggregates.cpp]
1: #include "duckdb/planner/expression/bound_aggregate_expression.hpp"
2: #include "duckdb/planner/expression/bound_function_expression.hpp"
3: #include "duckdb/function/scalar/nested_functions.hpp"
4: #include "duckdb/planner/expression_binder.hpp"
5: #include "duckdb/catalog/catalog.hpp"
6: #include "duckdb/catalog/catalog_entry/aggregate_function_catalog_entry.hpp"
7: #include "duckdb/execution/expression_executor.hpp"
8: 
9: namespace duckdb {
10: 
11: // FIXME: use a local state for each thread to increase performance?
12: // FIXME: benchmark the use of simple_update against using update (if applicable)
13: 
14: struct ListAggregatesBindData : public FunctionData {
15: 	ListAggregatesBindData(const LogicalType &stype_p, unique_ptr<Expression> aggr_expr_p);
16: 	~ListAggregatesBindData() override;
17: 
18: 	LogicalType stype;
19: 	unique_ptr<Expression> aggr_expr;
20: 
21: 	unique_ptr<FunctionData> Copy() const override {
22: 		return make_unique<ListAggregatesBindData>(stype, aggr_expr->Copy());
23: 	}
24: 
25: 	bool Equals(const FunctionData &other_p) const override {
26: 		auto &other = (const ListAggregatesBindData &)other_p;
27: 		return stype == other.stype && aggr_expr->Equals(other.aggr_expr.get());
28: 	}
29: };
30: 
31: ListAggregatesBindData::ListAggregatesBindData(const LogicalType &stype_p, unique_ptr<Expression> aggr_expr_p)
32:     : stype(stype_p), aggr_expr(move(aggr_expr_p)) {
33: }
34: 
35: ListAggregatesBindData::~ListAggregatesBindData() {
36: }
37: 
38: struct StateVector {
39: 	StateVector(idx_t count_p, unique_ptr<Expression> aggr_expr_p)
40: 	    : count(count_p), aggr_expr(move(aggr_expr_p)), state_vector(Vector(LogicalType::POINTER, count_p)) {
41: 	}
42: 
43: 	~StateVector() {
44: 		// destroy objects within the aggregate states
45: 		auto &aggr = (BoundAggregateExpression &)*aggr_expr;
46: 		if (aggr.function.destructor) {
47: 			aggr.function.destructor(state_vector, count);
48: 		}
49: 	}
50: 
51: 	idx_t count;
52: 	unique_ptr<Expression> aggr_expr;
53: 	Vector state_vector;
54: };
55: 
56: static void ListAggregateFunction(DataChunk &args, ExpressionState &state, Vector &result) {
57: 
58: 	D_ASSERT(args.ColumnCount() == 2);
59: 	auto count = args.size();
60: 	Vector &lists = args.data[0];
61: 
62: 	// set the result vector
63: 	result.SetVectorType(VectorType::FLAT_VECTOR);
64: 	auto &result_validity = FlatVector::Validity(result);
65: 
66: 	if (lists.GetType().id() == LogicalTypeId::SQLNULL) {
67: 		result_validity.SetInvalid(0);
68: 		return;
69: 	}
70: 
71: 	// get the aggregate function
72: 	auto &func_expr = (BoundFunctionExpression &)state.expr;
73: 	auto &info = (ListAggregatesBindData &)*func_expr.bind_info;
74: 	auto &aggr = (BoundAggregateExpression &)*info.aggr_expr;
75: 
76: 	D_ASSERT(aggr.function.update);
77: 
78: 	auto lists_size = ListVector::GetListSize(lists);
79: 	auto &child_vector = ListVector::GetEntry(lists);
80: 
81: 	VectorData child_data;
82: 	child_vector.Orrify(lists_size, child_data);
83: 
84: 	VectorData lists_data;
85: 	lists.Orrify(count, lists_data);
86: 	auto list_entries = (list_entry_t *)lists_data.data;
87: 
88: 	// state_buffer holds the state for each list of this chunk
89: 	idx_t size = aggr.function.state_size();
90: 	auto state_buffer = unique_ptr<data_t[]>(new data_t[size * count]);
91: 
92: 	// state vector for initialize and finalize
93: 	StateVector state_vector(count, info.aggr_expr->Copy());
94: 	auto states = FlatVector::GetData<data_ptr_t>(state_vector.state_vector);
95: 
96: 	// state vector of STANDARD_VECTOR_SIZE holds the pointers to the states
97: 	Vector state_vector_update = Vector(LogicalType::POINTER);
98: 	auto states_update = FlatVector::GetData<data_ptr_t>(state_vector_update);
99: 
100: 	// selection vector pointing to the data
101: 	SelectionVector sel_vector(STANDARD_VECTOR_SIZE);
102: 	idx_t states_idx = 0;
103: 
104: 	for (idx_t i = 0; i < count; i++) {
105: 
106: 		// initialize the state for this list
107: 		auto state_ptr = state_buffer.get() + size * i;
108: 		states[i] = state_ptr;
109: 		aggr.function.initialize(states[i]);
110: 
111: 		auto lists_index = lists_data.sel->get_index(i);
112: 		const auto &list_entry = list_entries[lists_index];
113: 
114: 		// nothing to do for this list
115: 		if (!lists_data.validity.RowIsValid(lists_index)) {
116: 			result_validity.SetInvalid(i);
117: 			continue;
118: 		}
119: 
120: 		// skip empty list
121: 		if (list_entry.length == 0) {
122: 			continue;
123: 		}
124: 
125: 		for (idx_t child_idx = 0; child_idx < list_entry.length; child_idx++) {
126: 
127: 			// states vector is full, update
128: 			if (states_idx == STANDARD_VECTOR_SIZE) {
129: 
130: 				// update the aggregate state(s)
131: 				Vector slice = Vector(child_vector, sel_vector, states_idx);
132: 				aggr.function.update(&slice, aggr.bind_info.get(), 1, state_vector_update, states_idx);
133: 
134: 				// reset values
135: 				states_idx = 0;
136: 			}
137: 
138: 			auto source_idx = child_data.sel->get_index(list_entry.offset + child_idx);
139: 			sel_vector.set_index(states_idx, source_idx);
140: 			states_update[states_idx] = state_ptr;
141: 			states_idx++;
142: 		}
143: 	}
144: 
145: 	// update the remaining elements of the last list(s)
146: 	if (states_idx != 0) {
147: 		Vector slice = Vector(child_vector, sel_vector, states_idx);
148: 		aggr.function.update(&slice, aggr.bind_info.get(), 1, state_vector_update, states_idx);
149: 	}
150: 
151: 	// finalize all the aggregate states
152: 	aggr.function.finalize(state_vector.state_vector, aggr.bind_info.get(), result, count, 0);
153: }
154: 
155: static unique_ptr<FunctionData> ListAggregateBind(ClientContext &context, ScalarFunction &bound_function,
156:                                                   vector<unique_ptr<Expression>> &arguments) {
157: 
158: 	// the list column and the name of the aggregate function
159: 	D_ASSERT(bound_function.arguments.size() == 2);
160: 	D_ASSERT(arguments.size() == 2);
161: 
162: 	if (arguments[0]->return_type.id() == LogicalTypeId::SQLNULL) {
163: 		bound_function.arguments[0] = LogicalType::SQLNULL;
164: 		bound_function.return_type = LogicalType::SQLNULL;
165: 		return make_unique<VariableReturnBindData>(bound_function.return_type);
166: 	}
167: 
168: 	D_ASSERT(LogicalTypeId::LIST == arguments[0]->return_type.id());
169: 	auto list_child_type = ListType::GetChildType(arguments[0]->return_type);
170: 	bound_function.return_type = list_child_type;
171: 
172: 	if (!arguments[1]->IsFoldable()) {
173: 		throw InvalidInputException("Aggregate function name must be a constant");
174: 	}
175: 
176: 	// get the function name
177: 	Value function_value = ExpressionExecutor::EvaluateScalar(*arguments[1]);
178: 	auto function_name = function_value.ToString();
179: 
180: 	vector<LogicalType> types;
181: 	types.push_back(list_child_type);
182: 
183: 	// create the child expression and its type
184: 	vector<unique_ptr<Expression>> children;
185: 	auto expr = make_unique<BoundConstantExpression>(Value(LogicalType::SQLNULL));
186: 	expr->return_type = list_child_type;
187: 	children.push_back(move(expr));
188: 
189: 	// look up the aggregate function in the catalog
190: 	QueryErrorContext error_context(nullptr, 0);
191: 	auto func = (AggregateFunctionCatalogEntry *)Catalog::GetCatalog(context).GetEntry<AggregateFunctionCatalogEntry>(
192: 	    context, DEFAULT_SCHEMA, function_name, false, error_context);
193: 	D_ASSERT(func->type == CatalogType::AGGREGATE_FUNCTION_ENTRY);
194: 
195: 	// find a matching aggregate function
196: 	string error;
197: 	auto best_function_idx = Function::BindFunction(func->name, func->functions, types, error);
198: 	if (best_function_idx == DConstants::INVALID_INDEX) {
199: 		throw BinderException("No matching aggregate function");
200: 	}
201: 
202: 	// found a matching function, bind it as an aggregate
203: 	auto &best_function = func->functions[best_function_idx];
204: 	auto bound_aggr_function = AggregateFunction::BindAggregateFunction(context, best_function, move(children));
205: 
206: 	bound_function.arguments[0] =
207: 	    LogicalType::LIST(bound_aggr_function->function.arguments[0]); // for proper casting of the vectors
208: 	bound_function.return_type = bound_aggr_function->function.return_type;
209: 	return make_unique<ListAggregatesBindData>(bound_function.return_type, move(bound_aggr_function));
210: }
211: 
212: ScalarFunction ListAggregateFun::GetFunction() {
213: 	return ScalarFunction({LogicalType::LIST(LogicalType::ANY), LogicalType::VARCHAR}, LogicalType::ANY,
214: 	                      ListAggregateFunction, false, false, ListAggregateBind, nullptr, nullptr, nullptr);
215: }
216: 
217: void ListAggregateFun::RegisterFunction(BuiltinFunctions &set) {
218: 	set.AddFunction({"list_aggregate", "array_aggregate", "list_aggr", "array_aggr"}, GetFunction());
219: }
220: 
221: } // namespace duckdb
[end of src/function/scalar/list/list_aggregates.cpp]
[start of src/function/scalar/list/list_concat.cpp]
1: #include "duckdb/common/types/data_chunk.hpp"
2: #include "duckdb/function/scalar/nested_functions.hpp"
3: #include "duckdb/planner/expression/bound_function_expression.hpp"
4: #include "duckdb/planner/expression_binder.hpp"
5: #include "duckdb/storage/statistics/list_statistics.hpp"
6: #include "duckdb/storage/statistics/validity_statistics.hpp"
7: 
8: namespace duckdb {
9: 
10: static void ListConcatFunction(DataChunk &args, ExpressionState &state, Vector &result) {
11: 	D_ASSERT(args.ColumnCount() == 2);
12: 	auto count = args.size();
13: 
14: 	Vector &lhs = args.data[0];
15: 	Vector &rhs = args.data[1];
16: 	if (lhs.GetType().id() == LogicalTypeId::SQLNULL) {
17: 		result.Reference(rhs);
18: 		return;
19: 	}
20: 	if (rhs.GetType().id() == LogicalTypeId::SQLNULL) {
21: 		result.Reference(lhs);
22: 		return;
23: 	}
24: 
25: 	VectorData lhs_data;
26: 	VectorData rhs_data;
27: 	lhs.Orrify(count, lhs_data);
28: 	rhs.Orrify(count, rhs_data);
29: 	auto lhs_entries = (list_entry_t *)lhs_data.data;
30: 	auto rhs_entries = (list_entry_t *)rhs_data.data;
31: 
32: 	auto lhs_list_size = ListVector::GetListSize(lhs);
33: 	auto rhs_list_size = ListVector::GetListSize(rhs);
34: 	auto &lhs_child = ListVector::GetEntry(lhs);
35: 	auto &rhs_child = ListVector::GetEntry(rhs);
36: 	VectorData lhs_child_data;
37: 	VectorData rhs_child_data;
38: 	lhs_child.Orrify(lhs_list_size, lhs_child_data);
39: 	rhs_child.Orrify(rhs_list_size, rhs_child_data);
40: 
41: 	result.SetVectorType(VectorType::FLAT_VECTOR);
42: 	auto result_entries = FlatVector::GetData<list_entry_t>(result);
43: 	auto &result_validity = FlatVector::Validity(result);
44: 
45: 	idx_t offset = 0;
46: 	for (idx_t i = 0; i < count; i++) {
47: 		auto lhs_list_index = lhs_data.sel->get_index(i);
48: 		auto rhs_list_index = rhs_data.sel->get_index(i);
49: 		if (!lhs_data.validity.RowIsValid(lhs_list_index) && !rhs_data.validity.RowIsValid(rhs_list_index)) {
50: 			result_validity.SetInvalid(i);
51: 			continue;
52: 		}
53: 		result_entries[i].offset = offset;
54: 		result_entries[i].length = 0;
55: 		if (lhs_data.validity.RowIsValid(lhs_list_index)) {
56: 			const auto &lhs_entry = lhs_entries[lhs_list_index];
57: 			result_entries[i].length += lhs_entry.length;
58: 			ListVector::Append(result, lhs_child, *lhs_child_data.sel, lhs_entry.offset + lhs_entry.length,
59: 			                   lhs_entry.offset);
60: 		}
61: 		if (rhs_data.validity.RowIsValid(rhs_list_index)) {
62: 			const auto &rhs_entry = rhs_entries[rhs_list_index];
63: 			result_entries[i].length += rhs_entry.length;
64: 			ListVector::Append(result, rhs_child, *rhs_child_data.sel, rhs_entry.offset + rhs_entry.length,
65: 			                   rhs_entry.offset);
66: 		}
67: 		offset += result_entries[i].length;
68: 	}
69: 	D_ASSERT(ListVector::GetListSize(result) == offset);
70: 
71: 	if (lhs.GetVectorType() == VectorType::CONSTANT_VECTOR && rhs.GetVectorType() == VectorType::CONSTANT_VECTOR) {
72: 		result.SetVectorType(VectorType::CONSTANT_VECTOR);
73: 	}
74: }
75: 
76: static unique_ptr<FunctionData> ListConcatBind(ClientContext &context, ScalarFunction &bound_function,
77:                                                vector<unique_ptr<Expression>> &arguments) {
78: 	D_ASSERT(bound_function.arguments.size() == 2);
79: 
80: 	auto &lhs = arguments[0]->return_type;
81: 	auto &rhs = arguments[1]->return_type;
82: 	if (lhs.id() == LogicalTypeId::SQLNULL && rhs.id() == LogicalTypeId::SQLNULL) {
83: 		bound_function.return_type = LogicalType::SQLNULL;
84: 	} else if (lhs.id() == LogicalTypeId::SQLNULL || rhs.id() == LogicalTypeId::SQLNULL) {
85: 		// we mimic postgres behaviour: list_concat(NULL, my_list) = my_list
86: 		bound_function.arguments[0] = lhs;
87: 		bound_function.arguments[1] = rhs;
88: 		bound_function.return_type = rhs.id() == LogicalTypeId::SQLNULL ? lhs : rhs;
89: 	} else {
90: 		D_ASSERT(lhs.id() == LogicalTypeId::LIST);
91: 		D_ASSERT(rhs.id() == LogicalTypeId::LIST);
92: 
93: 		// Resolve list type
94: 		LogicalType child_type = LogicalType::SQLNULL;
95: 		for (const auto &argument : arguments) {
96: 			child_type = LogicalType::MaxLogicalType(child_type, ListType::GetChildType(argument->return_type));
97: 		}
98: 		ExpressionBinder::ResolveParameterType(child_type);
99: 		auto list_type = LogicalType::LIST(move(child_type));
100: 
101: 		bound_function.arguments[0] = list_type;
102: 		bound_function.arguments[1] = list_type;
103: 		bound_function.return_type = list_type;
104: 	}
105: 	return make_unique<VariableReturnBindData>(bound_function.return_type);
106: }
107: 
108: static unique_ptr<BaseStatistics> ListConcatStats(ClientContext &context, BoundFunctionExpression &expr,
109:                                                   FunctionData *bind_data,
110:                                                   vector<unique_ptr<BaseStatistics>> &child_stats) {
111: 	D_ASSERT(child_stats.size() == 2);
112: 	if (!child_stats[0] || !child_stats[1]) {
113: 		return nullptr;
114: 	}
115: 
116: 	auto &left_stats = (ListStatistics &)*child_stats[0];
117: 	auto &right_stats = (ListStatistics &)*child_stats[1];
118: 
119: 	auto stats = left_stats.Copy();
120: 	stats->Merge(right_stats);
121: 
122: 	return stats;
123: }
124: 
125: ScalarFunction ListConcatFun::GetFunction() {
126: 	// the arguments and return types are actually set in the binder function
127: 	return ScalarFunction({LogicalType::LIST(LogicalType::ANY), LogicalType::LIST(LogicalType::ANY)},
128: 	                      LogicalType::LIST(LogicalType::ANY), ListConcatFunction, false, false, ListConcatBind,
129: 	                      nullptr, ListConcatStats);
130: }
131: 
132: void ListConcatFun::RegisterFunction(BuiltinFunctions &set) {
133: 	set.AddFunction({"list_concat", "list_cat", "array_concat", "array_cat"}, GetFunction());
134: }
135: 
136: } // namespace duckdb
[end of src/function/scalar/list/list_concat.cpp]
[start of src/function/scalar/list/list_extract.cpp]
1: #include "duckdb/planner/expression/bound_function_expression.hpp"
2: #include "duckdb/common/string_util.hpp"
3: #include "duckdb/common/vector_operations/binary_executor.hpp"
4: #include "duckdb/parser/expression/bound_expression.hpp"
5: #include "duckdb/function/scalar/nested_functions.hpp"
6: #include "duckdb/function/scalar/string_functions.hpp"
7: #include "duckdb/common/types/chunk_collection.hpp"
8: #include "duckdb/common/types/data_chunk.hpp"
9: #include "duckdb/common/pair.hpp"
10: #include "duckdb/storage/statistics/list_statistics.hpp"
11: #include "duckdb/storage/statistics/validity_statistics.hpp"
12: 
13: namespace duckdb {
14: 
15: template <class T, bool HEAP_REF = false, bool VALIDITY_ONLY = false>
16: void ListExtractTemplate(idx_t count, VectorData &list_data, VectorData &offsets_data, Vector &child_vector,
17:                          idx_t list_size, Vector &result) {
18: 	VectorData child_data;
19: 	child_vector.Orrify(list_size, child_data);
20: 
21: 	T *result_data;
22: 
23: 	result.SetVectorType(VectorType::FLAT_VECTOR);
24: 	if (!VALIDITY_ONLY) {
25: 		result_data = FlatVector::GetData<T>(result);
26: 	}
27: 	auto &result_mask = FlatVector::Validity(result);
28: 
29: 	// heap-ref once
30: 	if (HEAP_REF) {
31: 		StringVector::AddHeapReference(result, child_vector);
32: 	}
33: 
34: 	// this is lifted from ExecuteGenericLoop because we can't push the list child data into this otherwise
35: 	// should have gone with GetValue perhaps
36: 	for (idx_t i = 0; i < count; i++) {
37: 		auto list_index = list_data.sel->get_index(i);
38: 		auto offsets_index = offsets_data.sel->get_index(i);
39: 		if (list_data.validity.RowIsValid(list_index) && offsets_data.validity.RowIsValid(offsets_index)) {
40: 			auto list_entry = ((list_entry_t *)list_data.data)[list_index];
41: 			auto offsets_entry = ((int64_t *)offsets_data.data)[offsets_index];
42: 
43: 			// 1-based indexing
44: 			if (offsets_entry == 0) {
45: 				result_mask.SetInvalid(i);
46: 				continue;
47: 			}
48: 			offsets_entry = (offsets_entry > 0) ? offsets_entry - 1 : offsets_entry;
49: 
50: 			idx_t child_offset;
51: 			if (offsets_entry < 0) {
52: 				if ((idx_t)-offsets_entry > list_entry.length) {
53: 					result_mask.SetInvalid(i);
54: 					continue;
55: 				}
56: 				child_offset = list_entry.offset + list_entry.length + offsets_entry;
57: 			} else {
58: 				if ((idx_t)offsets_entry >= list_entry.length) {
59: 					result_mask.SetInvalid(i);
60: 					continue;
61: 				}
62: 				child_offset = list_entry.offset + offsets_entry;
63: 			}
64: 			if (child_data.validity.RowIsValid(child_offset)) {
65: 				if (!VALIDITY_ONLY) {
66: 					result_data[i] = ((T *)child_data.data)[child_offset];
67: 				}
68: 			} else {
69: 				result_mask.SetInvalid(i);
70: 			}
71: 		} else {
72: 			result_mask.SetInvalid(i);
73: 		}
74: 	}
75: 	if (count == 1) {
76: 		result.SetVectorType(VectorType::CONSTANT_VECTOR);
77: 	}
78: }
79: static void ExecuteListExtractInternal(const idx_t count, VectorData &list, VectorData &offsets, Vector &child_vector,
80:                                        idx_t list_size, Vector &result) {
81: 	D_ASSERT(child_vector.GetType() == result.GetType());
82: 	switch (result.GetType().InternalType()) {
83: 	case PhysicalType::BOOL:
84: 	case PhysicalType::INT8:
85: 		ListExtractTemplate<int8_t>(count, list, offsets, child_vector, list_size, result);
86: 		break;
87: 	case PhysicalType::INT16:
88: 		ListExtractTemplate<int16_t>(count, list, offsets, child_vector, list_size, result);
89: 		break;
90: 	case PhysicalType::INT32:
91: 		ListExtractTemplate<int32_t>(count, list, offsets, child_vector, list_size, result);
92: 		break;
93: 	case PhysicalType::INT64:
94: 		ListExtractTemplate<int64_t>(count, list, offsets, child_vector, list_size, result);
95: 		break;
96: 	case PhysicalType::INT128:
97: 		ListExtractTemplate<hugeint_t>(count, list, offsets, child_vector, list_size, result);
98: 		break;
99: 	case PhysicalType::UINT8:
100: 		ListExtractTemplate<uint8_t>(count, list, offsets, child_vector, list_size, result);
101: 		break;
102: 	case PhysicalType::UINT16:
103: 		ListExtractTemplate<uint16_t>(count, list, offsets, child_vector, list_size, result);
104: 		break;
105: 	case PhysicalType::UINT32:
106: 		ListExtractTemplate<uint32_t>(count, list, offsets, child_vector, list_size, result);
107: 		break;
108: 	case PhysicalType::UINT64:
109: 		ListExtractTemplate<uint64_t>(count, list, offsets, child_vector, list_size, result);
110: 		break;
111: 	case PhysicalType::FLOAT:
112: 		ListExtractTemplate<float>(count, list, offsets, child_vector, list_size, result);
113: 		break;
114: 	case PhysicalType::DOUBLE:
115: 		ListExtractTemplate<double>(count, list, offsets, child_vector, list_size, result);
116: 		break;
117: 	case PhysicalType::VARCHAR:
118: 		ListExtractTemplate<string_t, true>(count, list, offsets, child_vector, list_size, result);
119: 		break;
120: 	case PhysicalType::INTERVAL:
121: 		ListExtractTemplate<interval_t>(count, list, offsets, child_vector, list_size, result);
122: 		break;
123: 	case PhysicalType::STRUCT: {
124: 		auto &entries = StructVector::GetEntries(child_vector);
125: 		auto &result_entries = StructVector::GetEntries(result);
126: 		D_ASSERT(entries.size() == result_entries.size());
127: 		// extract the child entries of the struct
128: 		for (idx_t i = 0; i < entries.size(); i++) {
129: 			ExecuteListExtractInternal(count, list, offsets, *entries[i], list_size, *result_entries[i]);
130: 		}
131: 		// extract the validity mask
132: 		ListExtractTemplate<bool, false, true>(count, list, offsets, child_vector, list_size, result);
133: 		break;
134: 	}
135: 	case PhysicalType::LIST: {
136: 		// nested list: we have to reference the child
137: 		auto &child_child_list = ListVector::GetEntry(child_vector);
138: 
139: 		ListVector::GetEntry(result).Reference(child_child_list);
140: 		ListVector::SetListSize(result, ListVector::GetListSize(child_vector));
141: 		ListExtractTemplate<list_entry_t>(count, list, offsets, child_vector, list_size, result);
142: 		break;
143: 	}
144: 	default:
145: 		throw NotImplementedException("Unimplemented type for LIST_EXTRACT");
146: 	}
147: }
148: 
149: static void ExecuteListExtract(Vector &result, Vector &list, Vector &offsets, const idx_t count) {
150: 	D_ASSERT(list.GetType().id() == LogicalTypeId::LIST);
151: 	VectorData list_data;
152: 	VectorData offsets_data;
153: 
154: 	list.Orrify(count, list_data);
155: 	offsets.Orrify(count, offsets_data);
156: 	ExecuteListExtractInternal(count, list_data, offsets_data, ListVector::GetEntry(list),
157: 	                           ListVector::GetListSize(list), result);
158: 	result.Verify(count);
159: }
160: 
161: static void ExecuteStringExtract(Vector &result, Vector &input_vector, Vector &subscript_vector, const idx_t count) {
162: 	BinaryExecutor::Execute<string_t, int32_t, string_t>(
163: 	    input_vector, subscript_vector, result, count, [&](string_t input_string, int32_t subscript) {
164: 		    return SubstringFun::SubstringScalarFunction(result, input_string, subscript, 1);
165: 	    });
166: }
167: 
168: static void ListExtractFunction(DataChunk &args, ExpressionState &state, Vector &result) {
169: 	D_ASSERT(args.ColumnCount() == 2);
170: 	auto count = args.size();
171: 
172: 	result.SetVectorType(VectorType::CONSTANT_VECTOR);
173: 	for (idx_t i = 0; i < args.ColumnCount(); i++) {
174: 		if (args.data[i].GetVectorType() != VectorType::CONSTANT_VECTOR) {
175: 			result.SetVectorType(VectorType::FLAT_VECTOR);
176: 		}
177: 	}
178: 
179: 	Vector &base = args.data[0];
180: 	Vector &subscript = args.data[1];
181: 
182: 	switch (base.GetType().id()) {
183: 	case LogicalTypeId::LIST:
184: 		ExecuteListExtract(result, base, subscript, count);
185: 		break;
186: 	case LogicalTypeId::VARCHAR:
187: 		ExecuteStringExtract(result, base, subscript, count);
188: 		break;
189: 	case LogicalTypeId::SQLNULL:
190: 		result.SetVectorType(VectorType::CONSTANT_VECTOR);
191: 		ConstantVector::SetNull(result, true);
192: 		break;
193: 	default:
194: 		throw NotImplementedException("Specifier type not implemented");
195: 	}
196: }
197: 
198: static unique_ptr<FunctionData> ListExtractBind(ClientContext &context, ScalarFunction &bound_function,
199:                                                 vector<unique_ptr<Expression>> &arguments) {
200: 	D_ASSERT(bound_function.arguments.size() == 2);
201: 	if (arguments[0]->return_type.id() == LogicalTypeId::SQLNULL) {
202: 		bound_function.arguments[0] = LogicalType::SQLNULL;
203: 		bound_function.return_type = LogicalType::SQLNULL;
204: 	} else {
205: 		D_ASSERT(LogicalTypeId::LIST == arguments[0]->return_type.id());
206: 		// list extract returns the child type of the list as return type
207: 		bound_function.return_type = ListType::GetChildType(arguments[0]->return_type);
208: 	}
209: 	return make_unique<VariableReturnBindData>(bound_function.return_type);
210: }
211: 
212: static unique_ptr<BaseStatistics> ListExtractStats(ClientContext &context, BoundFunctionExpression &expr,
213:                                                    FunctionData *bind_data,
214:                                                    vector<unique_ptr<BaseStatistics>> &child_stats) {
215: 	if (!child_stats[0]) {
216: 		return nullptr;
217: 	}
218: 	auto &list_stats = (ListStatistics &)*child_stats[0];
219: 	if (!list_stats.child_stats) {
220: 		return nullptr;
221: 	}
222: 	auto child_copy = list_stats.child_stats->Copy();
223: 	// list_extract always pushes a NULL, since if the offset is out of range for a list it inserts a null
224: 	child_copy->validity_stats = make_unique<ValidityStatistics>(true);
225: 	return child_copy;
226: }
227: 
228: void ListExtractFun::RegisterFunction(BuiltinFunctions &set) {
229: 	// the arguments and return types are actually set in the binder function
230: 	ScalarFunction lfun({LogicalType::LIST(LogicalType::ANY), LogicalType::BIGINT}, LogicalType::ANY,
231: 	                    ListExtractFunction, false, false, ListExtractBind, nullptr, ListExtractStats);
232: 
233: 	ScalarFunction sfun({LogicalType::VARCHAR, LogicalType::INTEGER}, LogicalType::VARCHAR, ListExtractFunction, false,
234: 	                    false, nullptr);
235: 
236: 	ScalarFunctionSet list_extract("list_extract");
237: 	list_extract.AddFunction(lfun);
238: 	list_extract.AddFunction(sfun);
239: 	set.AddFunction(list_extract);
240: 
241: 	ScalarFunctionSet list_element("list_element");
242: 	list_element.AddFunction(lfun);
243: 	list_element.AddFunction(sfun);
244: 	set.AddFunction(list_element);
245: 
246: 	ScalarFunctionSet array_extract("array_extract");
247: 	array_extract.AddFunction(lfun);
248: 	array_extract.AddFunction(sfun);
249: 	array_extract.AddFunction(StructExtractFun::GetFunction());
250: 	set.AddFunction(array_extract);
251: }
252: 
253: } // namespace duckdb
[end of src/function/scalar/list/list_extract.cpp]
[start of src/function/scalar/list/list_value.cpp]
1: #include "duckdb/planner/expression/bound_function_expression.hpp"
2: #include "duckdb/common/string_util.hpp"
3: #include "duckdb/parser/expression/bound_expression.hpp"
4: #include "duckdb/function/scalar/nested_functions.hpp"
5: #include "duckdb/common/types/data_chunk.hpp"
6: #include "duckdb/common/pair.hpp"
7: #include "duckdb/storage/statistics/list_statistics.hpp"
8: #include "duckdb/planner/expression_binder.hpp"
9: 
10: namespace duckdb {
11: 
12: static void ListValueFunction(DataChunk &args, ExpressionState &state, Vector &result) {
13: 	D_ASSERT(result.GetType().id() == LogicalTypeId::LIST);
14: 	auto &child_type = ListType::GetChildType(result.GetType());
15: 
16: 	result.SetVectorType(VectorType::CONSTANT_VECTOR);
17: 	for (idx_t i = 0; i < args.ColumnCount(); i++) {
18: 		if (args.data[i].GetVectorType() != VectorType::CONSTANT_VECTOR) {
19: 			result.SetVectorType(VectorType::FLAT_VECTOR);
20: 		}
21: 	}
22: 
23: 	auto result_data = FlatVector::GetData<list_entry_t>(result);
24: 	for (idx_t i = 0; i < args.size(); i++) {
25: 		result_data[i].offset = ListVector::GetListSize(result);
26: 		for (idx_t col_idx = 0; col_idx < args.ColumnCount(); col_idx++) {
27: 			auto val = args.GetValue(col_idx, i).CastAs(child_type);
28: 			ListVector::PushBack(result, val);
29: 		}
30: 		result_data[i].length = args.ColumnCount();
31: 	}
32: 	result.Verify(args.size());
33: }
34: 
35: static unique_ptr<FunctionData> ListValueBind(ClientContext &context, ScalarFunction &bound_function,
36:                                               vector<unique_ptr<Expression>> &arguments) {
37: 	// collect names and deconflict, construct return type
38: 	LogicalType child_type = LogicalType::SQLNULL;
39: 	for (idx_t i = 0; i < arguments.size(); i++) {
40: 		child_type = LogicalType::MaxLogicalType(child_type, arguments[i]->return_type);
41: 	}
42: 	ExpressionBinder::ResolveParameterType(child_type);
43: 
44: 	// this is more for completeness reasons
45: 	bound_function.varargs = child_type;
46: 	bound_function.return_type = LogicalType::LIST(move(child_type));
47: 	return make_unique<VariableReturnBindData>(bound_function.return_type);
48: }
49: 
50: unique_ptr<BaseStatistics> ListValueStats(ClientContext &context, BoundFunctionExpression &expr,
51:                                           FunctionData *bind_data, vector<unique_ptr<BaseStatistics>> &child_stats) {
52: 	auto list_stats = make_unique<ListStatistics>(expr.return_type);
53: 	for (idx_t i = 0; i < child_stats.size(); i++) {
54: 		if (child_stats[i]) {
55: 			list_stats->child_stats->Merge(*child_stats[i]);
56: 		} else {
57: 			list_stats->child_stats.reset();
58: 			return move(list_stats);
59: 		}
60: 	}
61: 	return move(list_stats);
62: }
63: 
64: void ListValueFun::RegisterFunction(BuiltinFunctions &set) {
65: 	// the arguments and return types are actually set in the binder function
66: 	ScalarFunction fun("list_value", {}, LogicalTypeId::LIST, ListValueFunction, false, ListValueBind, nullptr,
67: 	                   ListValueStats);
68: 	fun.varargs = LogicalType::ANY;
69: 	set.AddFunction(fun);
70: 	fun.name = "list_pack";
71: 	set.AddFunction(fun);
72: }
73: 
74: } // namespace duckdb
[end of src/function/scalar/list/list_value.cpp]
[start of src/function/scalar/string/printf.cpp]
1: #include "duckdb/function/scalar/string_functions.hpp"
2: #include "duckdb/planner/expression/bound_function_expression.hpp"
3: #include "duckdb/common/limits.hpp"
4: #include "fmt/format.h"
5: #include "fmt/printf.h"
6: 
7: namespace duckdb {
8: 
9: struct FMTPrintf {
10: 	template <class CTX>
11: 	static string OP(const char *format_str, std::vector<duckdb_fmt::basic_format_arg<CTX>> &format_args) {
12: 		return duckdb_fmt::vsprintf(
13: 		    format_str, duckdb_fmt::basic_format_args<CTX>(format_args.data(), static_cast<int>(format_args.size())));
14: 	}
15: };
16: 
17: struct FMTFormat {
18: 	template <class CTX>
19: 	static string OP(const char *format_str, std::vector<duckdb_fmt::basic_format_arg<CTX>> &format_args) {
20: 		return duckdb_fmt::vformat(
21: 		    format_str, duckdb_fmt::basic_format_args<CTX>(format_args.data(), static_cast<int>(format_args.size())));
22: 	}
23: };
24: 
25: unique_ptr<FunctionData> BindPrintfFunction(ClientContext &context, ScalarFunction &bound_function,
26:                                             vector<unique_ptr<Expression>> &arguments) {
27: 	for (idx_t i = 1; i < arguments.size(); i++) {
28: 		switch (arguments[i]->return_type.id()) {
29: 		case LogicalTypeId::BOOLEAN:
30: 		case LogicalTypeId::TINYINT:
31: 		case LogicalTypeId::SMALLINT:
32: 		case LogicalTypeId::INTEGER:
33: 		case LogicalTypeId::BIGINT:
34: 		case LogicalTypeId::FLOAT:
35: 		case LogicalTypeId::DOUBLE:
36: 		case LogicalTypeId::VARCHAR:
37: 			// these types are natively supported
38: 			bound_function.arguments.push_back(arguments[i]->return_type);
39: 			break;
40: 		case LogicalTypeId::DECIMAL:
41: 			// decimal type: add cast to double
42: 			bound_function.arguments.emplace_back(LogicalType::DOUBLE);
43: 			break;
44: 		default:
45: 			// all other types: add cast to string
46: 			bound_function.arguments.emplace_back(LogicalType::VARCHAR);
47: 			break;
48: 		}
49: 	}
50: 	return nullptr;
51: }
52: 
53: template <class FORMAT_FUN, class CTX>
54: static void PrintfFunction(DataChunk &args, ExpressionState &state, Vector &result) {
55: 	auto &format_string = args.data[0];
56: 	auto &result_validity = FlatVector::Validity(result);
57: 	result.SetVectorType(VectorType::CONSTANT_VECTOR);
58: 	result_validity.Initialize(args.size());
59: 	for (idx_t i = 0; i < args.ColumnCount(); i++) {
60: 		switch (args.data[i].GetVectorType()) {
61: 		case VectorType::CONSTANT_VECTOR:
62: 			if (ConstantVector::IsNull(args.data[i])) {
63: 				// constant null! result is always NULL regardless of other input
64: 				result.SetVectorType(VectorType::CONSTANT_VECTOR);
65: 				ConstantVector::SetNull(result, true);
66: 				return;
67: 			}
68: 			break;
69: 		default:
70: 			// FLAT VECTOR, we can directly OR the nullmask
71: 			args.data[i].Normalify(args.size());
72: 			result.SetVectorType(VectorType::FLAT_VECTOR);
73: 			result_validity.Combine(FlatVector::Validity(args.data[i]), args.size());
74: 			break;
75: 		}
76: 	}
77: 	idx_t count = result.GetVectorType() == VectorType::CONSTANT_VECTOR ? 1 : args.size();
78: 
79: 	auto format_data = FlatVector::GetData<string_t>(format_string);
80: 	auto result_data = FlatVector::GetData<string_t>(result);
81: 	for (idx_t idx = 0; idx < count; idx++) {
82: 		if (result.GetVectorType() == VectorType::FLAT_VECTOR && FlatVector::IsNull(result, idx)) {
83: 			// this entry is NULL: skip it
84: 			continue;
85: 		}
86: 
87: 		// first fetch the format string
88: 		auto fmt_idx = format_string.GetVectorType() == VectorType::CONSTANT_VECTOR ? 0 : idx;
89: 		auto format_string = format_data[fmt_idx].GetString();
90: 
91: 		// now gather all the format arguments
92: 		std::vector<duckdb_fmt::basic_format_arg<CTX>> format_args;
93: 		std::vector<unique_ptr<data_t[]>> string_args;
94: 
95: 		for (idx_t col_idx = 1; col_idx < args.ColumnCount(); col_idx++) {
96: 			auto &col = args.data[col_idx];
97: 			idx_t arg_idx = col.GetVectorType() == VectorType::CONSTANT_VECTOR ? 0 : idx;
98: 			switch (col.GetType().id()) {
99: 			case LogicalTypeId::BOOLEAN: {
100: 				auto arg_data = FlatVector::GetData<bool>(col);
101: 				format_args.emplace_back(duckdb_fmt::internal::make_arg<CTX>(arg_data[arg_idx]));
102: 				break;
103: 			}
104: 			case LogicalTypeId::TINYINT: {
105: 				auto arg_data = FlatVector::GetData<int8_t>(col);
106: 				format_args.emplace_back(duckdb_fmt::internal::make_arg<CTX>(arg_data[arg_idx]));
107: 				break;
108: 			}
109: 			case LogicalTypeId::SMALLINT: {
110: 				auto arg_data = FlatVector::GetData<int8_t>(col);
111: 				format_args.emplace_back(duckdb_fmt::internal::make_arg<CTX>(arg_data[arg_idx]));
112: 				break;
113: 			}
114: 			case LogicalTypeId::INTEGER: {
115: 				auto arg_data = FlatVector::GetData<int32_t>(col);
116: 				format_args.emplace_back(duckdb_fmt::internal::make_arg<CTX>(arg_data[arg_idx]));
117: 				break;
118: 			}
119: 			case LogicalTypeId::BIGINT: {
120: 				auto arg_data = FlatVector::GetData<int64_t>(col);
121: 				format_args.emplace_back(duckdb_fmt::internal::make_arg<CTX>(arg_data[arg_idx]));
122: 				break;
123: 			}
124: 			case LogicalTypeId::FLOAT: {
125: 				auto arg_data = FlatVector::GetData<float>(col);
126: 				format_args.emplace_back(duckdb_fmt::internal::make_arg<CTX>(arg_data[arg_idx]));
127: 				break;
128: 			}
129: 			case LogicalTypeId::DOUBLE: {
130: 				auto arg_data = FlatVector::GetData<double>(col);
131: 				format_args.emplace_back(duckdb_fmt::internal::make_arg<CTX>(arg_data[arg_idx]));
132: 				break;
133: 			}
134: 			case LogicalTypeId::VARCHAR: {
135: 				auto arg_data = FlatVector::GetData<string_t>(col);
136: 				auto string_view =
137: 				    duckdb_fmt::basic_string_view<char>(arg_data[arg_idx].GetDataUnsafe(), arg_data[arg_idx].GetSize());
138: 				format_args.emplace_back(duckdb_fmt::internal::make_arg<CTX>(string_view));
139: 				break;
140: 			}
141: 			default:
142: 				throw InternalException("Unexpected type for printf format");
143: 			}
144: 		}
145: 		// finally actually perform the format
146: 		string dynamic_result = FORMAT_FUN::template OP<CTX>(format_string.c_str(), format_args);
147: 		result_data[idx] = StringVector::AddString(result, dynamic_result);
148: 	}
149: }
150: 
151: void PrintfFun::RegisterFunction(BuiltinFunctions &set) {
152: 	// duckdb_fmt::printf_context, duckdb_fmt::vsprintf
153: 	ScalarFunction printf_fun =
154: 	    ScalarFunction("printf", {LogicalType::VARCHAR}, LogicalType::VARCHAR,
155: 	                   PrintfFunction<FMTPrintf, duckdb_fmt::printf_context>, false, BindPrintfFunction);
156: 	printf_fun.varargs = LogicalType::ANY;
157: 	set.AddFunction(printf_fun);
158: 
159: 	// duckdb_fmt::format_context, duckdb_fmt::vformat
160: 	ScalarFunction format_fun =
161: 	    ScalarFunction("format", {LogicalType::VARCHAR}, LogicalType::VARCHAR,
162: 	                   PrintfFunction<FMTFormat, duckdb_fmt::format_context>, false, BindPrintfFunction);
163: 	format_fun.varargs = LogicalType::ANY;
164: 	set.AddFunction(format_fun);
165: }
166: 
167: } // namespace duckdb
[end of src/function/scalar/string/printf.cpp]
[start of src/function/scalar/struct/struct_pack.cpp]
1: #include "duckdb/planner/expression/bound_function_expression.hpp"
2: #include "duckdb/common/string_util.hpp"
3: #include "duckdb/parser/expression/bound_expression.hpp"
4: #include "duckdb/function/scalar/nested_functions.hpp"
5: #include "duckdb/common/case_insensitive_map.hpp"
6: #include "duckdb/storage/statistics/struct_statistics.hpp"
7: #include "duckdb/planner/expression_binder.hpp"
8: 
9: namespace duckdb {
10: 
11: static void StructPackFunction(DataChunk &args, ExpressionState &state, Vector &result) {
12: #ifdef DEBUG
13: 	auto &func_expr = (BoundFunctionExpression &)state.expr;
14: 	auto &info = (VariableReturnBindData &)*func_expr.bind_info;
15: 	// this should never happen if the binder below is sane
16: 	D_ASSERT(args.ColumnCount() == StructType::GetChildTypes(info.stype).size());
17: #endif
18: 	bool all_const = true;
19: 	auto &child_entries = StructVector::GetEntries(result);
20: 	for (size_t i = 0; i < args.ColumnCount(); i++) {
21: 		if (args.data[i].GetVectorType() != VectorType::CONSTANT_VECTOR) {
22: 			all_const = false;
23: 		}
24: 		// same holds for this
25: 		child_entries[i]->Reference(args.data[i]);
26: 	}
27: 	result.SetVectorType(all_const ? VectorType::CONSTANT_VECTOR : VectorType::FLAT_VECTOR);
28: 
29: 	result.Verify(args.size());
30: }
31: 
32: static unique_ptr<FunctionData> StructPackBind(ClientContext &context, ScalarFunction &bound_function,
33:                                                vector<unique_ptr<Expression>> &arguments) {
34: 	case_insensitive_set_t name_collision_set;
35: 
36: 	// collect names and deconflict, construct return type
37: 	if (arguments.empty()) {
38: 		throw Exception("Can't pack nothing into a struct");
39: 	}
40: 	child_list_t<LogicalType> struct_children;
41: 	for (idx_t i = 0; i < arguments.size(); i++) {
42: 		auto &child = arguments[i];
43: 		if (child->alias.empty() && bound_function.name == "struct_pack") {
44: 			throw BinderException("Need named argument for struct pack, e.g. STRUCT_PACK(a := b)");
45: 		}
46: 		if (child->alias.empty() && bound_function.name == "row") {
47: 			child->alias = "v" + std::to_string(i + 1);
48: 		}
49: 		if (name_collision_set.find(child->alias) != name_collision_set.end()) {
50: 			throw BinderException("Duplicate struct entry name \"%s\"", child->alias);
51: 		}
52: 		ExpressionBinder::ResolveParameterType(arguments[i]);
53: 		name_collision_set.insert(child->alias);
54: 		struct_children.push_back(make_pair(child->alias, arguments[i]->return_type));
55: 	}
56: 
57: 	// this is more for completeness reasons
58: 	bound_function.return_type = LogicalType::STRUCT(move(struct_children));
59: 	return make_unique<VariableReturnBindData>(bound_function.return_type);
60: }
61: 
62: unique_ptr<BaseStatistics> StructPackStats(ClientContext &context, BoundFunctionExpression &expr,
63:                                            FunctionData *bind_data, vector<unique_ptr<BaseStatistics>> &child_stats) {
64: 	auto struct_stats = make_unique<StructStatistics>(expr.return_type);
65: 	D_ASSERT(child_stats.size() == struct_stats->child_stats.size());
66: 	for (idx_t i = 0; i < struct_stats->child_stats.size(); i++) {
67: 		struct_stats->child_stats[i] = child_stats[i] ? child_stats[i]->Copy() : nullptr;
68: 	}
69: 	return move(struct_stats);
70: }
71: 
72: void StructPackFun::RegisterFunction(BuiltinFunctions &set) {
73: 	// the arguments and return types are actually set in the binder function
74: 	ScalarFunction fun("struct_pack", {}, LogicalTypeId::STRUCT, StructPackFunction, false, StructPackBind, nullptr,
75: 	                   StructPackStats);
76: 	fun.varargs = LogicalType::ANY;
77: 	set.AddFunction(fun);
78: 	fun.name = "row";
79: 	set.AddFunction(fun);
80: }
81: 
82: } // namespace duckdb
[end of src/function/scalar/struct/struct_pack.cpp]
[start of src/include/duckdb/execution/operator/helper/physical_execute.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/execution/operator/helper/physical_execute.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/execution/physical_operator.hpp"
12: 
13: namespace duckdb {
14: 
15: class PhysicalExecute : public PhysicalOperator {
16: public:
17: 	explicit PhysicalExecute(PhysicalOperator *plan);
18: 
19: 	PhysicalOperator *plan;
20: };
21: 
22: } // namespace duckdb
[end of src/include/duckdb/execution/operator/helper/physical_execute.hpp]
[start of src/include/duckdb/function/aggregate_function.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/function/aggregate_function.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/vector_operations/aggregate_executor.hpp"
12: #include "duckdb/function/function.hpp"
13: #include "duckdb/storage/statistics/base_statistics.hpp"
14: #include "duckdb/storage/statistics/node_statistics.hpp"
15: #include "duckdb/planner/bound_result_modifier.hpp"
16: #include "duckdb/planner/expression.hpp"
17: 
18: namespace duckdb {
19: 
20: class BoundAggregateExpression;
21: 
22: //! The type used for sizing hashed aggregate function states
23: typedef idx_t (*aggregate_size_t)();
24: //! The type used for initializing hashed aggregate function states
25: typedef void (*aggregate_initialize_t)(data_ptr_t state);
26: //! The type used for updating hashed aggregate functions
27: typedef void (*aggregate_update_t)(Vector inputs[], FunctionData *bind_data, idx_t input_count, Vector &state,
28:                                    idx_t count);
29: //! The type used for combining hashed aggregate states
30: typedef void (*aggregate_combine_t)(Vector &state, Vector &combined, FunctionData *bind_data, idx_t count);
31: //! The type used for finalizing hashed aggregate function payloads
32: typedef void (*aggregate_finalize_t)(Vector &state, FunctionData *bind_data, Vector &result, idx_t count, idx_t offset);
33: //! The type used for propagating statistics in aggregate functions (optional)
34: typedef unique_ptr<BaseStatistics> (*aggregate_statistics_t)(ClientContext &context, BoundAggregateExpression &expr,
35:                                                              FunctionData *bind_data,
36:                                                              vector<unique_ptr<BaseStatistics>> &child_stats,
37:                                                              NodeStatistics *node_stats);
38: //! Binds the scalar function and creates the function data
39: typedef unique_ptr<FunctionData> (*bind_aggregate_function_t)(ClientContext &context, AggregateFunction &function,
40:                                                               vector<unique_ptr<Expression>> &arguments);
41: //! The type used for the aggregate destructor method. NOTE: this method is used in destructors and MAY NOT throw.
42: typedef void (*aggregate_destructor_t)(Vector &state, idx_t count);
43: 
44: //! The type used for updating simple (non-grouped) aggregate functions
45: typedef void (*aggregate_simple_update_t)(Vector inputs[], FunctionData *bind_data, idx_t input_count, data_ptr_t state,
46:                                           idx_t count);
47: 
48: //! The type used for updating complex windowed aggregate functions (optional)
49: typedef std::pair<idx_t, idx_t> FrameBounds;
50: typedef void (*aggregate_window_t)(Vector inputs[], FunctionData *bind_data, idx_t input_count, data_ptr_t state,
51:                                    const FrameBounds &frame, const FrameBounds &prev, Vector &result, idx_t rid,
52:                                    idx_t bias);
53: 
54: class AggregateFunction : public BaseScalarFunction {
55: public:
56: 	DUCKDB_API AggregateFunction(const string &name, const vector<LogicalType> &arguments,
57: 	                             const LogicalType &return_type, aggregate_size_t state_size,
58: 	                             aggregate_initialize_t initialize, aggregate_update_t update,
59: 	                             aggregate_combine_t combine, aggregate_finalize_t finalize,
60: 	                             bool propagates_null_values = false, aggregate_simple_update_t simple_update = nullptr,
61: 	                             bind_aggregate_function_t bind = nullptr, aggregate_destructor_t destructor = nullptr,
62: 	                             aggregate_statistics_t statistics = nullptr, aggregate_window_t window = nullptr)
63: 	    : BaseScalarFunction(name, arguments, return_type, false, LogicalType(LogicalTypeId::INVALID),
64: 	                         propagates_null_values),
65: 	      state_size(state_size), initialize(initialize), update(update), combine(combine), finalize(finalize),
66: 	      simple_update(simple_update), window(window), bind(bind), destructor(destructor), statistics(statistics) {
67: 	}
68: 
69: 	DUCKDB_API AggregateFunction(const string &name, const vector<LogicalType> &arguments,
70: 	                             const LogicalType &return_type, aggregate_size_t state_size,
71: 	                             aggregate_initialize_t initialize, aggregate_update_t update,
72: 	                             aggregate_combine_t combine, aggregate_finalize_t finalize,
73: 	                             aggregate_simple_update_t simple_update = nullptr,
74: 	                             bind_aggregate_function_t bind = nullptr, aggregate_destructor_t destructor = nullptr,
75: 	                             aggregate_statistics_t statistics = nullptr, aggregate_window_t window = nullptr)
76: 	    : BaseScalarFunction(name, arguments, return_type, false, LogicalType(LogicalTypeId::INVALID), false),
77: 	      state_size(state_size), initialize(initialize), update(update), combine(combine), finalize(finalize),
78: 	      simple_update(simple_update), window(window), bind(bind), destructor(destructor), statistics(statistics) {
79: 	}
80: 
81: 	DUCKDB_API AggregateFunction(const vector<LogicalType> &arguments, const LogicalType &return_type,
82: 	                             aggregate_size_t state_size, aggregate_initialize_t initialize,
83: 	                             aggregate_update_t update, aggregate_combine_t combine, aggregate_finalize_t finalize,
84: 	                             bool propagates_null_values = false, aggregate_simple_update_t simple_update = nullptr,
85: 	                             bind_aggregate_function_t bind = nullptr, aggregate_destructor_t destructor = nullptr,
86: 	                             aggregate_statistics_t statistics = nullptr, aggregate_window_t window = nullptr)
87: 	    : AggregateFunction(string(), arguments, return_type, state_size, initialize, update, combine, finalize,
88: 	                        propagates_null_values, simple_update, bind, destructor, statistics, window) {
89: 	}
90: 
91: 	DUCKDB_API AggregateFunction(const vector<LogicalType> &arguments, const LogicalType &return_type,
92: 	                             aggregate_size_t state_size, aggregate_initialize_t initialize,
93: 	                             aggregate_update_t update, aggregate_combine_t combine, aggregate_finalize_t finalize,
94: 	                             aggregate_simple_update_t simple_update = nullptr,
95: 	                             bind_aggregate_function_t bind = nullptr, aggregate_destructor_t destructor = nullptr,
96: 	                             aggregate_statistics_t statistics = nullptr, aggregate_window_t window = nullptr)
97: 	    : AggregateFunction(string(), arguments, return_type, state_size, initialize, update, combine, finalize, false,
98: 	                        simple_update, bind, destructor, statistics, window) {
99: 	}
100: 	//! The hashed aggregate state sizing function
101: 	aggregate_size_t state_size;
102: 	//! The hashed aggregate state initialization function
103: 	aggregate_initialize_t initialize;
104: 	//! The hashed aggregate update state function
105: 	aggregate_update_t update;
106: 	//! The hashed aggregate combine states function
107: 	aggregate_combine_t combine;
108: 	//! The hashed aggregate finalization function
109: 	aggregate_finalize_t finalize;
110: 	//! The simple aggregate update function (may be null)
111: 	aggregate_simple_update_t simple_update;
112: 	//! The windowed aggregate frame update function (may be null)
113: 	aggregate_window_t window;
114: 
115: 	//! The bind function (may be null)
116: 	bind_aggregate_function_t bind;
117: 	//! The destructor method (may be null)
118: 	aggregate_destructor_t destructor;
119: 
120: 	//! The statistics propagation function (may be null)
121: 	aggregate_statistics_t statistics;
122: 
123: 	DUCKDB_API bool operator==(const AggregateFunction &rhs) const {
124: 		return state_size == rhs.state_size && initialize == rhs.initialize && update == rhs.update &&
125: 		       combine == rhs.combine && finalize == rhs.finalize && window == rhs.window;
126: 	}
127: 	DUCKDB_API bool operator!=(const AggregateFunction &rhs) const {
128: 		return !(*this == rhs);
129: 	}
130: 
131: 	DUCKDB_API static unique_ptr<BoundAggregateExpression>
132: 	BindAggregateFunction(ClientContext &context, AggregateFunction bound_function,
133: 	                      vector<unique_ptr<Expression>> children, unique_ptr<Expression> filter = nullptr,
134: 	                      bool is_distinct = false, unique_ptr<BoundOrderModifier> order_bys = nullptr);
135: 
136: 	DUCKDB_API static unique_ptr<FunctionData> BindSortedAggregate(AggregateFunction &bound_function,
137: 	                                                               vector<unique_ptr<Expression>> &children,
138: 	                                                               unique_ptr<FunctionData> bind_info,
139: 	                                                               unique_ptr<BoundOrderModifier> order_bys);
140: 
141: public:
142: 	template <class STATE, class RESULT_TYPE, class OP>
143: 	static AggregateFunction NullaryAggregate(LogicalType return_type) {
144: 		return AggregateFunction(
145: 		    {}, return_type, AggregateFunction::StateSize<STATE>, AggregateFunction::StateInitialize<STATE, OP>,
146: 		    AggregateFunction::NullaryScatterUpdate<STATE, OP>, AggregateFunction::StateCombine<STATE, OP>,
147: 		    AggregateFunction::StateFinalize<STATE, RESULT_TYPE, OP>, AggregateFunction::NullaryUpdate<STATE, OP>);
148: 	}
149: 
150: 	template <class STATE, class INPUT_TYPE, class RESULT_TYPE, class OP>
151: 	static AggregateFunction UnaryAggregate(const LogicalType &input_type, LogicalType return_type,
152: 	                                        bool propagates_null_values = false) {
153: 		return AggregateFunction(
154: 		    {input_type}, return_type, AggregateFunction::StateSize<STATE>,
155: 		    AggregateFunction::StateInitialize<STATE, OP>, AggregateFunction::UnaryScatterUpdate<STATE, INPUT_TYPE, OP>,
156: 		    AggregateFunction::StateCombine<STATE, OP>, AggregateFunction::StateFinalize<STATE, RESULT_TYPE, OP>,
157: 		    propagates_null_values, AggregateFunction::UnaryUpdate<STATE, INPUT_TYPE, OP>);
158: 	}
159: 
160: 	template <class STATE, class INPUT_TYPE, class RESULT_TYPE, class OP>
161: 	static AggregateFunction UnaryAggregateDestructor(LogicalType input_type, LogicalType return_type) {
162: 		auto aggregate = UnaryAggregate<STATE, INPUT_TYPE, RESULT_TYPE, OP>(input_type, return_type);
163: 		aggregate.destructor = AggregateFunction::StateDestroy<STATE, OP>;
164: 		return aggregate;
165: 	}
166: 
167: 	template <class STATE, class A_TYPE, class B_TYPE, class RESULT_TYPE, class OP>
168: 	static AggregateFunction BinaryAggregate(const LogicalType &a_type, const LogicalType &b_type,
169: 	                                         LogicalType return_type) {
170: 		return AggregateFunction({a_type, b_type}, return_type, AggregateFunction::StateSize<STATE>,
171: 		                         AggregateFunction::StateInitialize<STATE, OP>,
172: 		                         AggregateFunction::BinaryScatterUpdate<STATE, A_TYPE, B_TYPE, OP>,
173: 		                         AggregateFunction::StateCombine<STATE, OP>,
174: 		                         AggregateFunction::StateFinalize<STATE, RESULT_TYPE, OP>,
175: 		                         AggregateFunction::BinaryUpdate<STATE, A_TYPE, B_TYPE, OP>);
176: 	}
177: 
178: public:
179: 	template <class STATE>
180: 	static idx_t StateSize() {
181: 		return sizeof(STATE);
182: 	}
183: 
184: 	template <class STATE, class OP>
185: 	static void StateInitialize(data_ptr_t state) {
186: 		OP::Initialize((STATE *)state);
187: 	}
188: 
189: 	template <class STATE, class OP>
190: 	static void NullaryScatterUpdate(Vector inputs[], FunctionData *bind_data, idx_t input_count, Vector &states,
191: 	                                 idx_t count) {
192: 		D_ASSERT(input_count == 0);
193: 		AggregateExecutor::NullaryScatter<STATE, OP>(states, bind_data, count);
194: 	}
195: 
196: 	template <class STATE, class OP>
197: 	static void NullaryUpdate(Vector inputs[], FunctionData *bind_data, idx_t input_count, data_ptr_t state,
198: 	                          idx_t count) {
199: 		D_ASSERT(input_count == 0);
200: 		AggregateExecutor::NullaryUpdate<STATE, OP>(state, bind_data, count);
201: 	}
202: 
203: 	template <class STATE, class T, class OP>
204: 	static void UnaryScatterUpdate(Vector inputs[], FunctionData *bind_data, idx_t input_count, Vector &states,
205: 	                               idx_t count) {
206: 		D_ASSERT(input_count == 1);
207: 		AggregateExecutor::UnaryScatter<STATE, T, OP>(inputs[0], states, bind_data, count);
208: 	}
209: 
210: 	template <class STATE, class INPUT_TYPE, class OP>
211: 	static void UnaryUpdate(Vector inputs[], FunctionData *bind_data, idx_t input_count, data_ptr_t state,
212: 	                        idx_t count) {
213: 		D_ASSERT(input_count == 1);
214: 		AggregateExecutor::UnaryUpdate<STATE, INPUT_TYPE, OP>(inputs[0], bind_data, state, count);
215: 	}
216: 
217: 	template <class STATE, class INPUT_TYPE, class RESULT_TYPE, class OP>
218: 	static void UnaryWindow(Vector inputs[], FunctionData *bind_data, idx_t input_count, data_ptr_t state,
219: 	                        const FrameBounds &frame, const FrameBounds &prev, Vector &result, idx_t rid, idx_t bias) {
220: 		D_ASSERT(input_count == 1);
221: 		AggregateExecutor::UnaryWindow<STATE, INPUT_TYPE, RESULT_TYPE, OP>(inputs[0], bind_data, state, frame, prev,
222: 		                                                                   result, rid, bias);
223: 	}
224: 
225: 	template <class STATE, class A_TYPE, class B_TYPE, class OP>
226: 	static void BinaryScatterUpdate(Vector inputs[], FunctionData *bind_data, idx_t input_count, Vector &states,
227: 	                                idx_t count) {
228: 		D_ASSERT(input_count == 2);
229: 		AggregateExecutor::BinaryScatter<STATE, A_TYPE, B_TYPE, OP>(bind_data, inputs[0], inputs[1], states, count);
230: 	}
231: 
232: 	template <class STATE, class A_TYPE, class B_TYPE, class OP>
233: 	static void BinaryUpdate(Vector inputs[], FunctionData *bind_data, idx_t input_count, data_ptr_t state,
234: 	                         idx_t count) {
235: 		D_ASSERT(input_count == 2);
236: 		AggregateExecutor::BinaryUpdate<STATE, A_TYPE, B_TYPE, OP>(bind_data, inputs[0], inputs[1], state, count);
237: 	}
238: 
239: 	template <class STATE, class OP>
240: 	static void StateCombine(Vector &source, Vector &target, FunctionData *bind_data, idx_t count) {
241: 		AggregateExecutor::Combine<STATE, OP>(source, target, bind_data, count);
242: 	}
243: 
244: 	template <class STATE, class RESULT_TYPE, class OP>
245: 	static void StateFinalize(Vector &states, FunctionData *bind_data, Vector &result, idx_t count, idx_t offset) {
246: 		AggregateExecutor::Finalize<STATE, RESULT_TYPE, OP>(states, bind_data, result, count, offset);
247: 	}
248: 
249: 	template <class STATE, class OP>
250: 	static void StateDestroy(Vector &states, idx_t count) {
251: 		AggregateExecutor::Destroy<STATE, OP>(states, count);
252: 	}
253: };
254: 
255: } // namespace duckdb
[end of src/include/duckdb/function/aggregate_function.hpp]
[start of src/include/duckdb/function/function.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/function/function.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/types/data_chunk.hpp"
12: #include "duckdb/common/named_parameter_map.hpp"
13: #include "duckdb/common/unordered_set.hpp"
14: #include "duckdb/parser/column_definition.hpp"
15: 
16: namespace duckdb {
17: class CatalogEntry;
18: class Catalog;
19: class ClientContext;
20: class Expression;
21: class ExpressionExecutor;
22: class Transaction;
23: 
24: class AggregateFunction;
25: class AggregateFunctionSet;
26: class CopyFunction;
27: class PragmaFunction;
28: class ScalarFunctionSet;
29: class ScalarFunction;
30: class TableFunctionSet;
31: class TableFunction;
32: 
33: struct PragmaInfo;
34: 
35: struct FunctionData {
36: 	DUCKDB_API virtual ~FunctionData();
37: 
38: 	DUCKDB_API virtual unique_ptr<FunctionData> Copy() const = 0;
39: 	DUCKDB_API virtual bool Equals(const FunctionData &other) const = 0;
40: 	DUCKDB_API static bool Equals(const FunctionData *left, const FunctionData *right);
41: };
42: 
43: struct TableFunctionData : public FunctionData {
44: 	// used to pass on projections to table functions that support them. NB, can contain COLUMN_IDENTIFIER_ROW_ID
45: 	vector<idx_t> column_ids;
46: 
47: 	DUCKDB_API virtual ~TableFunctionData();
48: 
49: 	DUCKDB_API unique_ptr<FunctionData> Copy() const override;
50: 	DUCKDB_API bool Equals(const FunctionData &other) const override;
51: };
52: 
53: struct FunctionParameters {
54: 	vector<Value> values;
55: 	named_parameter_map_t named_parameters;
56: };
57: 
58: //! Function is the base class used for any type of function (scalar, aggregate or simple function)
59: class Function {
60: public:
61: 	DUCKDB_API explicit Function(string name);
62: 	DUCKDB_API virtual ~Function();
63: 
64: 	//! The name of the function
65: 	string name;
66: 
67: public:
68: 	//! Returns the formatted string name(arg1, arg2, ...)
69: 	DUCKDB_API static string CallToString(const string &name, const vector<LogicalType> &arguments);
70: 	//! Returns the formatted string name(arg1, arg2..) -> return_type
71: 	DUCKDB_API static string CallToString(const string &name, const vector<LogicalType> &arguments,
72: 	                                      const LogicalType &return_type);
73: 	//! Returns the formatted string name(arg1, arg2.., np1=a, np2=b, ...)
74: 	DUCKDB_API static string CallToString(const string &name, const vector<LogicalType> &arguments,
75: 	                                      const named_parameter_type_map_t &named_parameters);
76: 
77: 	//! Bind a scalar function from the set of functions and input arguments. Returns the index of the chosen function,
78: 	//! returns DConstants::INVALID_INDEX and sets error if none could be found
79: 	DUCKDB_API static idx_t BindFunction(const string &name, vector<ScalarFunction> &functions,
80: 	                                     vector<LogicalType> &arguments, string &error);
81: 	DUCKDB_API static idx_t BindFunction(const string &name, vector<ScalarFunction> &functions,
82: 	                                     vector<unique_ptr<Expression>> &arguments, string &error);
83: 	//! Bind an aggregate function from the set of functions and input arguments. Returns the index of the chosen
84: 	//! function, returns DConstants::INVALID_INDEX and sets error if none could be found
85: 	DUCKDB_API static idx_t BindFunction(const string &name, vector<AggregateFunction> &functions,
86: 	                                     vector<LogicalType> &arguments, string &error);
87: 	DUCKDB_API static idx_t BindFunction(const string &name, vector<AggregateFunction> &functions,
88: 	                                     vector<unique_ptr<Expression>> &arguments, string &error);
89: 	//! Bind a table function from the set of functions and input arguments. Returns the index of the chosen
90: 	//! function, returns DConstants::INVALID_INDEX and sets error if none could be found
91: 	DUCKDB_API static idx_t BindFunction(const string &name, vector<TableFunction> &functions,
92: 	                                     vector<LogicalType> &arguments, string &error);
93: 	DUCKDB_API static idx_t BindFunction(const string &name, vector<TableFunction> &functions,
94: 	                                     vector<unique_ptr<Expression>> &arguments, string &error);
95: 	//! Bind a pragma function from the set of functions and input arguments
96: 	DUCKDB_API static idx_t BindFunction(const string &name, vector<PragmaFunction> &functions, PragmaInfo &info,
97: 	                                     string &error);
98: };
99: 
100: class SimpleFunction : public Function {
101: public:
102: 	DUCKDB_API SimpleFunction(string name, vector<LogicalType> arguments,
103: 	                          LogicalType varargs = LogicalType(LogicalTypeId::INVALID));
104: 	DUCKDB_API ~SimpleFunction() override;
105: 
106: 	//! The set of arguments of the function
107: 	vector<LogicalType> arguments;
108: 	//! The type of varargs to support, or LogicalTypeId::INVALID if the function does not accept variable length
109: 	//! arguments
110: 	LogicalType varargs;
111: 
112: public:
113: 	DUCKDB_API virtual string ToString();
114: 
115: 	DUCKDB_API bool HasVarArgs() const;
116: };
117: 
118: class SimpleNamedParameterFunction : public SimpleFunction {
119: public:
120: 	DUCKDB_API SimpleNamedParameterFunction(string name, vector<LogicalType> arguments,
121: 	                                        LogicalType varargs = LogicalType(LogicalTypeId::INVALID));
122: 	DUCKDB_API ~SimpleNamedParameterFunction() override;
123: 
124: 	//! The named parameters of the function
125: 	named_parameter_type_map_t named_parameters;
126: 
127: public:
128: 	DUCKDB_API string ToString() override;
129: 	DUCKDB_API bool HasNamedParameters();
130: };
131: 
132: class BaseScalarFunction : public SimpleFunction {
133: public:
134: 	DUCKDB_API BaseScalarFunction(string name, vector<LogicalType> arguments, LogicalType return_type,
135: 	                              bool has_side_effects, LogicalType varargs = LogicalType(LogicalTypeId::INVALID),
136: 	                              bool propagates_null_values = false);
137: 	DUCKDB_API ~BaseScalarFunction() override;
138: 
139: 	//! Return type of the function
140: 	LogicalType return_type;
141: 	//! Whether or not the function has side effects (e.g. sequence increments, random() functions, NOW()). Functions
142: 	//! with side-effects cannot be constant-folded.
143: 	bool has_side_effects;
144: 	//! Whether or not the function propagates null values
145: 	bool propagates_null_values;
146: 
147: public:
148: 	DUCKDB_API hash_t Hash() const;
149: 
150: 	//! Cast a set of expressions to the arguments of this function
151: 	DUCKDB_API void CastToFunctionArguments(vector<unique_ptr<Expression>> &children);
152: 
153: 	DUCKDB_API string ToString() override;
154: };
155: 
156: class BuiltinFunctions {
157: public:
158: 	BuiltinFunctions(ClientContext &transaction, Catalog &catalog);
159: 
160: 	//! Initialize a catalog with all built-in functions
161: 	void Initialize();
162: 
163: public:
164: 	void AddFunction(AggregateFunctionSet set);
165: 	void AddFunction(AggregateFunction function);
166: 	void AddFunction(ScalarFunctionSet set);
167: 	void AddFunction(PragmaFunction function);
168: 	void AddFunction(const string &name, vector<PragmaFunction> functions);
169: 	void AddFunction(ScalarFunction function);
170: 	void AddFunction(const vector<string> &names, ScalarFunction function);
171: 	void AddFunction(TableFunctionSet set);
172: 	void AddFunction(TableFunction function);
173: 	void AddFunction(CopyFunction function);
174: 
175: 	void AddCollation(string name, ScalarFunction function, bool combinable = false,
176: 	                  bool not_required_for_equality = false);
177: 
178: private:
179: 	ClientContext &context;
180: 	Catalog &catalog;
181: 
182: private:
183: 	template <class T>
184: 	void Register() {
185: 		T::RegisterFunction(*this);
186: 	}
187: 
188: 	// table-producing functions
189: 	void RegisterSQLiteFunctions();
190: 	void RegisterReadFunctions();
191: 	void RegisterTableFunctions();
192: 	void RegisterArrowFunctions();
193: 
194: 	// aggregates
195: 	void RegisterAlgebraicAggregates();
196: 	void RegisterDistributiveAggregates();
197: 	void RegisterNestedAggregates();
198: 	void RegisterHolisticAggregates();
199: 	void RegisterRegressiveAggregates();
200: 
201: 	// scalar functions
202: 	void RegisterDateFunctions();
203: 	void RegisterEnumFunctions();
204: 	void RegisterGenericFunctions();
205: 	void RegisterMathFunctions();
206: 	void RegisterOperators();
207: 	void RegisterStringFunctions();
208: 	void RegisterNestedFunctions();
209: 	void RegisterSequenceFunctions();
210: 	void RegisterTrigonometricsFunctions();
211: 
212: 	// pragmas
213: 	void RegisterPragmaFunctions();
214: };
215: 
216: } // namespace duckdb
[end of src/include/duckdb/function/function.hpp]
[start of src/include/duckdb/function/scalar_function.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/function/scalar_function.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/vector_operations/binary_executor.hpp"
12: #include "duckdb/common/vector_operations/ternary_executor.hpp"
13: #include "duckdb/common/vector_operations/unary_executor.hpp"
14: #include "duckdb/common/vector_operations/vector_operations.hpp"
15: #include "duckdb/execution/expression_executor_state.hpp"
16: #include "duckdb/function/function.hpp"
17: #include "duckdb/storage/statistics/base_statistics.hpp"
18: 
19: namespace duckdb {
20: 
21: struct FunctionLocalState {
22: 	DUCKDB_API virtual ~FunctionLocalState();
23: };
24: 
25: class BoundFunctionExpression;
26: class ScalarFunctionCatalogEntry;
27: 
28: //! The type used for scalar functions
29: typedef std::function<void(DataChunk &, ExpressionState &, Vector &)> scalar_function_t;
30: //! Binds the scalar function and creates the function data
31: typedef unique_ptr<FunctionData> (*bind_scalar_function_t)(ClientContext &context, ScalarFunction &bound_function,
32:                                                            vector<unique_ptr<Expression>> &arguments);
33: typedef unique_ptr<FunctionLocalState> (*init_local_state_t)(const BoundFunctionExpression &expr,
34:                                                              FunctionData *bind_data);
35: typedef unique_ptr<BaseStatistics> (*function_statistics_t)(ClientContext &context, BoundFunctionExpression &expr,
36:                                                             FunctionData *bind_data,
37:                                                             vector<unique_ptr<BaseStatistics>> &child_stats);
38: //! Adds the dependencies of this BoundFunctionExpression to the set of dependencies
39: typedef void (*dependency_function_t)(BoundFunctionExpression &expr, unordered_set<CatalogEntry *> &dependencies);
40: 
41: class ScalarFunction : public BaseScalarFunction {
42: public:
43: 	DUCKDB_API ScalarFunction(string name, vector<LogicalType> arguments, LogicalType return_type,
44: 	                          scalar_function_t function, bool has_side_effects = false,
45: 	                          bind_scalar_function_t bind = nullptr, dependency_function_t dependency = nullptr,
46: 	                          function_statistics_t statistics = nullptr, init_local_state_t init_local_state = nullptr,
47: 	                          LogicalType varargs = LogicalType(LogicalTypeId::INVALID),
48: 	                          bool propagate_null_values = false);
49: 
50: 	DUCKDB_API ScalarFunction(vector<LogicalType> arguments, LogicalType return_type, scalar_function_t function,
51: 	                          bool propagate_null_values = false, bool has_side_effects = false,
52: 	                          bind_scalar_function_t bind = nullptr, dependency_function_t dependency = nullptr,
53: 	                          function_statistics_t statistics = nullptr, init_local_state_t init_local_state = nullptr,
54: 	                          LogicalType varargs = LogicalType(LogicalTypeId::INVALID));
55: 
56: 	//! The main scalar function to execute
57: 	scalar_function_t function;
58: 	//! The bind function (if any)
59: 	bind_scalar_function_t bind;
60: 	//! Init thread local state for the function (if any)
61: 	init_local_state_t init_local_state;
62: 	//! The dependency function (if any)
63: 	dependency_function_t dependency;
64: 	//! The statistics propagation function (if any)
65: 	function_statistics_t statistics;
66: 
67: 	DUCKDB_API static unique_ptr<BoundFunctionExpression> BindScalarFunction(ClientContext &context,
68: 	                                                                         const string &schema, const string &name,
69: 	                                                                         vector<unique_ptr<Expression>> children,
70: 	                                                                         string &error, bool is_operator = false);
71: 	DUCKDB_API static unique_ptr<BoundFunctionExpression> BindScalarFunction(ClientContext &context,
72: 	                                                                         ScalarFunctionCatalogEntry &function,
73: 	                                                                         vector<unique_ptr<Expression>> children,
74: 	                                                                         string &error, bool is_operator = false);
75: 
76: 	DUCKDB_API static unique_ptr<BoundFunctionExpression> BindScalarFunction(ClientContext &context,
77: 	                                                                         ScalarFunction bound_function,
78: 	                                                                         vector<unique_ptr<Expression>> children,
79: 	                                                                         bool is_operator = false);
80: 
81: 	DUCKDB_API bool operator==(const ScalarFunction &rhs) const;
82: 	DUCKDB_API bool operator!=(const ScalarFunction &rhs) const;
83: 
84: 	DUCKDB_API bool Equal(const ScalarFunction &rhs) const;
85: 
86: private:
87: 	bool CompareScalarFunctionT(const scalar_function_t &other) const;
88: 
89: public:
90: 	DUCKDB_API static void NopFunction(DataChunk &input, ExpressionState &state, Vector &result);
91: 
92: 	template <class TA, class TR, class OP>
93: 	static void UnaryFunction(DataChunk &input, ExpressionState &state, Vector &result) {
94: 		D_ASSERT(input.ColumnCount() >= 1);
95: 		UnaryExecutor::Execute<TA, TR, OP>(input.data[0], result, input.size());
96: 	}
97: 
98: 	template <class TA, class TB, class TR, class OP>
99: 	static void BinaryFunction(DataChunk &input, ExpressionState &state, Vector &result) {
100: 		D_ASSERT(input.ColumnCount() == 2);
101: 		BinaryExecutor::ExecuteStandard<TA, TB, TR, OP>(input.data[0], input.data[1], result, input.size());
102: 	}
103: 
104: public:
105: 	template <class OP>
106: 	static scalar_function_t GetScalarUnaryFunction(LogicalType type) {
107: 		scalar_function_t function;
108: 		switch (type.id()) {
109: 		case LogicalTypeId::TINYINT:
110: 			function = &ScalarFunction::UnaryFunction<int8_t, int8_t, OP>;
111: 			break;
112: 		case LogicalTypeId::SMALLINT:
113: 			function = &ScalarFunction::UnaryFunction<int16_t, int16_t, OP>;
114: 			break;
115: 		case LogicalTypeId::INTEGER:
116: 			function = &ScalarFunction::UnaryFunction<int32_t, int32_t, OP>;
117: 			break;
118: 		case LogicalTypeId::BIGINT:
119: 			function = &ScalarFunction::UnaryFunction<int64_t, int64_t, OP>;
120: 			break;
121: 		case LogicalTypeId::UTINYINT:
122: 			function = &ScalarFunction::UnaryFunction<uint8_t, uint8_t, OP>;
123: 			break;
124: 		case LogicalTypeId::USMALLINT:
125: 			function = &ScalarFunction::UnaryFunction<uint16_t, uint16_t, OP>;
126: 			break;
127: 		case LogicalTypeId::UINTEGER:
128: 			function = &ScalarFunction::UnaryFunction<uint32_t, uint32_t, OP>;
129: 			break;
130: 		case LogicalTypeId::UBIGINT:
131: 			function = &ScalarFunction::UnaryFunction<uint64_t, uint64_t, OP>;
132: 			break;
133: 		case LogicalTypeId::HUGEINT:
134: 			function = &ScalarFunction::UnaryFunction<hugeint_t, hugeint_t, OP>;
135: 			break;
136: 		case LogicalTypeId::FLOAT:
137: 			function = &ScalarFunction::UnaryFunction<float, float, OP>;
138: 			break;
139: 		case LogicalTypeId::DOUBLE:
140: 			function = &ScalarFunction::UnaryFunction<double, double, OP>;
141: 			break;
142: 		default:
143: 			throw InternalException("Unimplemented type for GetScalarUnaryFunction");
144: 		}
145: 		return function;
146: 	}
147: 
148: 	template <class TR, class OP>
149: 	static scalar_function_t GetScalarUnaryFunctionFixedReturn(LogicalType type) {
150: 		scalar_function_t function;
151: 		switch (type.id()) {
152: 		case LogicalTypeId::TINYINT:
153: 			function = &ScalarFunction::UnaryFunction<int8_t, TR, OP>;
154: 			break;
155: 		case LogicalTypeId::SMALLINT:
156: 			function = &ScalarFunction::UnaryFunction<int16_t, TR, OP>;
157: 			break;
158: 		case LogicalTypeId::INTEGER:
159: 			function = &ScalarFunction::UnaryFunction<int32_t, TR, OP>;
160: 			break;
161: 		case LogicalTypeId::BIGINT:
162: 			function = &ScalarFunction::UnaryFunction<int64_t, TR, OP>;
163: 			break;
164: 		case LogicalTypeId::UTINYINT:
165: 			function = &ScalarFunction::UnaryFunction<uint8_t, TR, OP>;
166: 			break;
167: 		case LogicalTypeId::USMALLINT:
168: 			function = &ScalarFunction::UnaryFunction<uint16_t, TR, OP>;
169: 			break;
170: 		case LogicalTypeId::UINTEGER:
171: 			function = &ScalarFunction::UnaryFunction<uint32_t, TR, OP>;
172: 			break;
173: 		case LogicalTypeId::UBIGINT:
174: 			function = &ScalarFunction::UnaryFunction<uint64_t, TR, OP>;
175: 			break;
176: 		case LogicalTypeId::HUGEINT:
177: 			function = &ScalarFunction::UnaryFunction<hugeint_t, TR, OP>;
178: 			break;
179: 		case LogicalTypeId::FLOAT:
180: 			function = &ScalarFunction::UnaryFunction<float, TR, OP>;
181: 			break;
182: 		case LogicalTypeId::DOUBLE:
183: 			function = &ScalarFunction::UnaryFunction<double, TR, OP>;
184: 			break;
185: 		default:
186: 			throw InternalException("Unimplemented type for GetScalarUnaryFunctionFixedReturn");
187: 		}
188: 		return function;
189: 	}
190: };
191: 
192: } // namespace duckdb
[end of src/include/duckdb/function/scalar_function.hpp]
[start of src/include/duckdb/main/client_context.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/main/client_context.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/catalog/catalog_entry/schema_catalog_entry.hpp"
12: #include "duckdb/catalog/catalog_set.hpp"
13: #include "duckdb/common/enums/pending_execution_result.hpp"
14: #include "duckdb/common/deque.hpp"
15: #include "duckdb/common/pair.hpp"
16: #include "duckdb/common/progress_bar.hpp"
17: #include "duckdb/common/unordered_set.hpp"
18: #include "duckdb/common/winapi.hpp"
19: #include "duckdb/main/prepared_statement.hpp"
20: #include "duckdb/main/stream_query_result.hpp"
21: #include "duckdb/main/table_description.hpp"
22: #include "duckdb/transaction/transaction_context.hpp"
23: #include "duckdb/main/pending_query_result.hpp"
24: #include <random>
25: #include "duckdb/common/atomic.hpp"
26: #include "duckdb/main/client_config.hpp"
27: #include "duckdb/main/external_dependencies.hpp"
28: 
29: namespace duckdb {
30: class Appender;
31: class Catalog;
32: class CatalogSearchPath;
33: class ChunkCollection;
34: class DatabaseInstance;
35: class FileOpener;
36: class LogicalOperator;
37: class PreparedStatementData;
38: class Relation;
39: class BufferedFileWriter;
40: class QueryProfiler;
41: class QueryProfilerHistory;
42: class ClientContextLock;
43: struct CreateScalarFunctionInfo;
44: class ScalarFunctionCatalogEntry;
45: struct ActiveQueryContext;
46: struct ParserOptions;
47: 
48: //! The ClientContext holds information relevant to the current client session
49: //! during execution
50: class ClientContext : public std::enable_shared_from_this<ClientContext> {
51: 	friend class PendingQueryResult;
52: 	friend class StreamQueryResult;
53: 	friend class TransactionManager;
54: 
55: public:
56: 	DUCKDB_API explicit ClientContext(shared_ptr<DatabaseInstance> db);
57: 	DUCKDB_API ~ClientContext();
58: 
59: 	//! Query profiler
60: 	shared_ptr<QueryProfiler> profiler;
61: 	//! QueryProfiler History
62: 	unique_ptr<QueryProfilerHistory> query_profiler_history;
63: 	//! The database that this client is connected to
64: 	shared_ptr<DatabaseInstance> db;
65: 	//! Data for the currently running transaction
66: 	TransactionContext transaction;
67: 	//! Whether or not the query is interrupted
68: 	atomic<bool> interrupted;
69: 	//! External Objects (e.g., Python objects) that views depend of
70: 	unordered_map<string, vector<shared_ptr<ExternalDependency>>> external_dependencies;
71: 
72: 	unique_ptr<SchemaCatalogEntry> temporary_objects;
73: 	unordered_map<string, shared_ptr<PreparedStatementData>> prepared_statements;
74: 
75: 	//! The writer used to log queries (if logging is enabled)
76: 	unique_ptr<BufferedFileWriter> log_query_writer;
77: 	//! The random generator used by random(). Its seed value can be set by setseed().
78: 	std::mt19937 random_engine;
79: 
80: 	const unique_ptr<CatalogSearchPath> catalog_search_path;
81: 
82: 	unique_ptr<FileOpener> file_opener;
83: 
84: 	//! The client configuration
85: 	ClientConfig config;
86: 
87: public:
88: 	DUCKDB_API Transaction &ActiveTransaction() {
89: 		return transaction.ActiveTransaction();
90: 	}
91: 
92: 	//! Interrupt execution of a query
93: 	DUCKDB_API void Interrupt();
94: 	//! Enable query profiling
95: 	DUCKDB_API void EnableProfiling();
96: 	//! Disable query profiling
97: 	DUCKDB_API void DisableProfiling();
98: 
99: 	//! Issue a query, returning a QueryResult. The QueryResult can be either a StreamQueryResult or a
100: 	//! MaterializedQueryResult. The StreamQueryResult will only be returned in the case of a successful SELECT
101: 	//! statement.
102: 	DUCKDB_API unique_ptr<QueryResult> Query(const string &query, bool allow_stream_result);
103: 	DUCKDB_API unique_ptr<QueryResult> Query(unique_ptr<SQLStatement> statement, bool allow_stream_result);
104: 
105: 	//! Issues a query to the database and returns a Pending Query Result. Note that "query" may only contain
106: 	//! a single statement.
107: 	DUCKDB_API unique_ptr<PendingQueryResult> PendingQuery(const string &query);
108: 	//! Issues a query to the database and returns a Pending Query Result
109: 	DUCKDB_API unique_ptr<PendingQueryResult> PendingQuery(unique_ptr<SQLStatement> statement);
110: 
111: 	//! Destroy the client context
112: 	DUCKDB_API void Destroy();
113: 
114: 	//! Get the table info of a specific table, or nullptr if it cannot be found
115: 	DUCKDB_API unique_ptr<TableDescription> TableInfo(const string &schema_name, const string &table_name);
116: 	//! Appends a DataChunk to the specified table. Returns whether or not the append was successful.
117: 	DUCKDB_API void Append(TableDescription &description, ChunkCollection &collection);
118: 	//! Try to bind a relation in the current client context; either throws an exception or fills the result_columns
119: 	//! list with the set of returned columns
120: 	DUCKDB_API void TryBindRelation(Relation &relation, vector<ColumnDefinition> &result_columns);
121: 
122: 	//! Execute a relation
123: 	DUCKDB_API unique_ptr<QueryResult> Execute(const shared_ptr<Relation> &relation);
124: 
125: 	//! Prepare a query
126: 	DUCKDB_API unique_ptr<PreparedStatement> Prepare(const string &query);
127: 	//! Directly prepare a SQL statement
128: 	DUCKDB_API unique_ptr<PreparedStatement> Prepare(unique_ptr<SQLStatement> statement);
129: 
130: 	//! Create a pending query result from a prepared statement with the given name and set of parameters
131: 	//! It is possible that the prepared statement will be re-bound. This will generally happen if the catalog is
132: 	//! modified in between the prepared statement being bound and the prepared statement being run.
133: 	DUCKDB_API unique_ptr<PendingQueryResult>
134: 	PendingQuery(const string &query, shared_ptr<PreparedStatementData> &prepared, vector<Value> &values);
135: 
136: 	//! Execute a prepared statement with the given name and set of parameters
137: 	//! It is possible that the prepared statement will be re-bound. This will generally happen if the catalog is
138: 	//! modified in between the prepared statement being bound and the prepared statement being run.
139: 	DUCKDB_API unique_ptr<QueryResult> Execute(const string &query, shared_ptr<PreparedStatementData> &prepared,
140: 	                                           vector<Value> &values, bool allow_stream_result = true);
141: 
142: 	//! Gets current percentage of the query's progress, returns 0 in case the progress bar is disabled.
143: 	DUCKDB_API double GetProgress();
144: 
145: 	//! Register function in the temporary schema
146: 	DUCKDB_API void RegisterFunction(CreateFunctionInfo *info);
147: 
148: 	//! Parse statements from a query
149: 	DUCKDB_API vector<unique_ptr<SQLStatement>> ParseStatements(const string &query);
150: 
151: 	//! Extract the logical plan of a query
152: 	DUCKDB_API unique_ptr<LogicalOperator> ExtractPlan(const string &query);
153: 	DUCKDB_API void HandlePragmaStatements(vector<unique_ptr<SQLStatement>> &statements);
154: 
155: 	//! Runs a function with a valid transaction context, potentially starting a transaction if the context is in auto
156: 	//! commit mode.
157: 	DUCKDB_API void RunFunctionInTransaction(const std::function<void(void)> &fun,
158: 	                                         bool requires_valid_transaction = true);
159: 	//! Same as RunFunctionInTransaction, but does not obtain a lock on the client context or check for validation
160: 	DUCKDB_API void RunFunctionInTransactionInternal(ClientContextLock &lock, const std::function<void(void)> &fun,
161: 	                                                 bool requires_valid_transaction = true);
162: 
163: 	//! Equivalent to CURRENT_SETTING(key) SQL function.
164: 	DUCKDB_API bool TryGetCurrentSetting(const std::string &key, Value &result);
165: 
166: 	//! Returns the parser options for this client context
167: 	DUCKDB_API ParserOptions GetParserOptions();
168: 
169: 	DUCKDB_API unique_ptr<DataChunk> Fetch(ClientContextLock &lock, StreamQueryResult &result);
170: 
171: 	//! Whether or not the given result object (streaming query result or pending query result) is active
172: 	DUCKDB_API bool IsActiveResult(ClientContextLock &lock, BaseQueryResult *result);
173: 
174: 	//! Returns the current executor
175: 	Executor &GetExecutor();
176: 
177: 	//! Returns the current query string (if any)
178: 	const string &GetCurrentQuery();
179: 
180: 	//! Fetch a list of table names that are required for a given query
181: 	DUCKDB_API unordered_set<string> GetTableNames(const string &query);
182: 
183: private:
184: 	//! Parse statements and resolve pragmas from a query
185: 	bool ParseStatements(ClientContextLock &lock, const string &query, vector<unique_ptr<SQLStatement>> &result,
186: 	                     string &error);
187: 	//! Issues a query to the database and returns a Pending Query Result
188: 	unique_ptr<PendingQueryResult> PendingQueryInternal(ClientContextLock &lock, unique_ptr<SQLStatement> statement,
189: 	                                                    bool verify = true);
190: 	unique_ptr<QueryResult> ExecutePendingQueryInternal(ClientContextLock &lock, PendingQueryResult &query,
191: 	                                                    bool allow_stream_result);
192: 
193: 	//! Parse statements from a query
194: 	vector<unique_ptr<SQLStatement>> ParseStatementsInternal(ClientContextLock &lock, const string &query);
195: 	//! Perform aggressive query verification of a SELECT statement. Only called when query_verification_enabled is
196: 	//! true.
197: 	string VerifyQuery(ClientContextLock &lock, const string &query, unique_ptr<SQLStatement> statement);
198: 
199: 	void InitialCleanup(ClientContextLock &lock);
200: 	//! Internal clean up, does not lock. Caller must hold the context_lock.
201: 	void CleanupInternal(ClientContextLock &lock, BaseQueryResult *result = nullptr,
202: 	                     bool invalidate_transaction = false);
203: 	string FinalizeQuery(ClientContextLock &lock, bool success);
204: 	unique_ptr<PendingQueryResult> PendingStatementOrPreparedStatement(ClientContextLock &lock, const string &query,
205: 	                                                                   unique_ptr<SQLStatement> statement,
206: 	                                                                   shared_ptr<PreparedStatementData> &prepared,
207: 	                                                                   vector<Value> *values);
208: 	unique_ptr<PendingQueryResult> PendingPreparedStatement(ClientContextLock &lock,
209: 	                                                        shared_ptr<PreparedStatementData> statement_p,
210: 	                                                        vector<Value> bound_values);
211: 
212: 	//! Internally prepare a SQL statement. Caller must hold the context_lock.
213: 	shared_ptr<PreparedStatementData> CreatePreparedStatement(ClientContextLock &lock, const string &query,
214: 	                                                          unique_ptr<SQLStatement> statement);
215: 	unique_ptr<PendingQueryResult> PendingStatementInternal(ClientContextLock &lock, const string &query,
216: 	                                                        unique_ptr<SQLStatement> statement);
217: 	unique_ptr<QueryResult> RunStatementInternal(ClientContextLock &lock, const string &query,
218: 	                                             unique_ptr<SQLStatement> statement, bool allow_stream_result,
219: 	                                             bool verify = true);
220: 	unique_ptr<PreparedStatement> PrepareInternal(ClientContextLock &lock, unique_ptr<SQLStatement> statement);
221: 	void LogQueryInternal(ClientContextLock &lock, const string &query);
222: 
223: 	unique_ptr<QueryResult> FetchResultInternal(ClientContextLock &lock, PendingQueryResult &pending,
224: 	                                            bool allow_stream_result);
225: 	unique_ptr<DataChunk> FetchInternal(ClientContextLock &lock, Executor &executor, BaseQueryResult &result);
226: 
227: 	unique_ptr<ClientContextLock> LockContext();
228: 
229: 	bool UpdateFunctionInfoFromEntry(ScalarFunctionCatalogEntry *existing_function, CreateScalarFunctionInfo *new_info);
230: 
231: 	void BeginTransactionInternal(ClientContextLock &lock, bool requires_valid_transaction);
232: 	void BeginQueryInternal(ClientContextLock &lock, const string &query);
233: 	string EndQueryInternal(ClientContextLock &lock, bool success, bool invalidate_transaction);
234: 
235: 	PendingExecutionResult ExecuteTaskInternal(ClientContextLock &lock, PendingQueryResult &result);
236: 
237: 	unique_ptr<PendingQueryResult>
238: 	PendingStatementOrPreparedStatementInternal(ClientContextLock &lock, const string &query,
239: 	                                            unique_ptr<SQLStatement> statement,
240: 	                                            shared_ptr<PreparedStatementData> &prepared, vector<Value> *values);
241: 
242: 	unique_ptr<PendingQueryResult> PendingQueryPreparedInternal(ClientContextLock &lock, const string &query,
243: 	                                                            shared_ptr<PreparedStatementData> &prepared,
244: 	                                                            vector<Value> &values);
245: 
246: private:
247: 	//! Lock on using the ClientContext in parallel
248: 	mutex context_lock;
249: 	//! The currently active query context
250: 	unique_ptr<ActiveQueryContext> active_query;
251: 	//! The current query progress
252: 	atomic<double> query_progress;
253: };
254: 
255: class ClientContextLock {
256: public:
257: 	explicit ClientContextLock(mutex &context_lock) : client_guard(context_lock) {
258: 	}
259: 
260: 	~ClientContextLock() {
261: 	}
262: 
263: private:
264: 	lock_guard<mutex> client_guard;
265: };
266: 
267: class ClientContextWrapper {
268: public:
269: 	DUCKDB_API explicit ClientContextWrapper(const shared_ptr<ClientContext> &context)
270: 	    : client_context(context) {
271: 
272: 	      };
273: 	shared_ptr<ClientContext> GetContext() {
274: 		auto actual_context = client_context.lock();
275: 		if (!actual_context) {
276: 			throw std::runtime_error("This connection is closed");
277: 		}
278: 		return actual_context;
279: 	}
280: 
281: private:
282: 	std::weak_ptr<ClientContext> client_context;
283: };
284: 
285: } // namespace duckdb
[end of src/include/duckdb/main/client_context.hpp]
[start of src/include/duckdb/main/prepared_statement_data.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/main/prepared_statement_data.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/enums/statement_type.hpp"
12: #include "duckdb/common/types/value.hpp"
13: #include "duckdb/common/unordered_map.hpp"
14: #include "duckdb/common/unordered_set.hpp"
15: #include "duckdb/common/winapi.hpp"
16: 
17: namespace duckdb {
18: class CatalogEntry;
19: class PhysicalOperator;
20: class SQLStatement;
21: 
22: class PreparedStatementData {
23: public:
24: 	DUCKDB_API explicit PreparedStatementData(StatementType type);
25: 	DUCKDB_API ~PreparedStatementData();
26: 
27: 	StatementType statement_type;
28: 	//! The unbound SQL statement that was prepared
29: 	unique_ptr<SQLStatement> unbound_statement;
30: 	//! The fully prepared physical plan of the prepared statement
31: 	unique_ptr<PhysicalOperator> plan;
32: 	//! The map of parameter index to the actual value entry
33: 	unordered_map<idx_t, vector<unique_ptr<Value>>> value_map;
34: 
35: 	//! The result names of the transaction
36: 	vector<string> names;
37: 	//! The result types of the transaction
38: 	vector<LogicalType> types;
39: 
40: 	//! Whether or not the statement is a read-only statement, or whether it can result in changes to the database
41: 	bool read_only;
42: 	//! Whether or not the statement requires a valid transaction. Almost all statements require this, with the
43: 	//! exception of
44: 	bool requires_valid_transaction;
45: 	//! Whether or not the result can be streamed to the client
46: 	bool allow_stream_result;
47: 
48: 	//! The catalog version of when the prepared statement was bound
49: 	//! If this version is lower than the current catalog version, we have to rebind the prepared statement
50: 	idx_t catalog_version;
51: 
52: public:
53: 	//! Bind a set of values to the prepared statement data
54: 	DUCKDB_API void Bind(vector<Value> values);
55: 	//! Get the expected SQL Type of the bound parameter
56: 	DUCKDB_API LogicalType GetType(idx_t param_index);
57: };
58: 
59: } // namespace duckdb
[end of src/include/duckdb/main/prepared_statement_data.hpp]
[start of src/include/duckdb/planner/binder.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/planner/binder.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/unordered_map.hpp"
12: #include "duckdb/parser/column_definition.hpp"
13: #include "duckdb/parser/tokens.hpp"
14: #include "duckdb/planner/bind_context.hpp"
15: #include "duckdb/planner/bound_tokens.hpp"
16: #include "duckdb/planner/expression/bound_columnref_expression.hpp"
17: #include "duckdb/planner/logical_operator.hpp"
18: #include "duckdb/planner/bound_statement.hpp"
19: #include "duckdb/common/case_insensitive_map.hpp"
20: #include "duckdb/parser/result_modifier.hpp"
21: 
22: //#include "duckdb/catalog/catalog_entry/table_macro_catalog_entry.hpp"
23: 
24: namespace duckdb {
25: class BoundResultModifier;
26: class BoundSelectNode;
27: class ClientContext;
28: class ExpressionBinder;
29: class LimitModifier;
30: class OrderBinder;
31: class TableCatalogEntry;
32: class ViewCatalogEntry;
33: class TableMacroCatalogEntry;
34: 
35: struct CreateInfo;
36: struct BoundCreateTableInfo;
37: struct BoundCreateFunctionInfo;
38: struct CommonTableExpressionInfo;
39: 
40: enum class BindingMode : uint8_t { STANDARD_BINDING, EXTRACT_NAMES };
41: 
42: struct CorrelatedColumnInfo {
43: 	ColumnBinding binding;
44: 	LogicalType type;
45: 	string name;
46: 	idx_t depth;
47: 
48: 	explicit CorrelatedColumnInfo(BoundColumnRefExpression &expr)
49: 	    : binding(expr.binding), type(expr.return_type), name(expr.GetName()), depth(expr.depth) {
50: 	}
51: 
52: 	bool operator==(const CorrelatedColumnInfo &rhs) const {
53: 		return binding == rhs.binding;
54: 	}
55: };
56: 
57: //! Bind the parsed query tree to the actual columns present in the catalog.
58: /*!
59:   The binder is responsible for binding tables and columns to actual physical
60:   tables and columns in the catalog. In the process, it also resolves types of
61:   all expressions.
62: */
63: class Binder : public std::enable_shared_from_this<Binder> {
64: 	friend class ExpressionBinder;
65: 	friend class SelectBinder;
66: 	friend class RecursiveSubqueryPlanner;
67: 
68: public:
69: 	static shared_ptr<Binder> CreateBinder(ClientContext &context, Binder *parent = nullptr, bool inherit_ctes = true);
70: 
71: 	//! The client context
72: 	ClientContext &context;
73: 	//! A mapping of names to common table expressions
74: 	case_insensitive_map_t<CommonTableExpressionInfo *> CTE_bindings;
75: 	//! The CTEs that have already been bound
76: 	unordered_set<CommonTableExpressionInfo *> bound_ctes;
77: 	//! The bind context
78: 	BindContext bind_context;
79: 	//! The set of correlated columns bound by this binder (FIXME: this should probably be an unordered_set and not a
80: 	//! vector)
81: 	vector<CorrelatedColumnInfo> correlated_columns;
82: 	//! The set of parameter expressions bound by this binder
83: 	vector<BoundParameterExpression *> *parameters;
84: 	//! Whether or not the bound statement is read-only
85: 	bool read_only;
86: 	//! Whether or not the statement requires a valid transaction to run
87: 	bool requires_valid_transaction;
88: 	//! Whether or not the statement can be streamed to the client
89: 	bool allow_stream_result;
90: 	//! The alias for the currently processing subquery, if it exists
91: 	string alias;
92: 	//! Macro parameter bindings (if any)
93: 	MacroBinding *macro_binding = nullptr;
94: 
95: public:
96: 	BoundStatement Bind(SQLStatement &statement);
97: 	BoundStatement Bind(QueryNode &node);
98: 
99: 	unique_ptr<BoundCreateTableInfo> BindCreateTableInfo(unique_ptr<CreateInfo> info);
100: 	void BindCreateViewInfo(CreateViewInfo &base);
101: 	SchemaCatalogEntry *BindSchema(CreateInfo &info);
102: 	SchemaCatalogEntry *BindCreateFunctionInfo(CreateInfo &info);
103: 
104: 	//! Check usage, and cast named parameters to their types
105: 	static void BindNamedParameters(named_parameter_type_map_t &types, named_parameter_map_t &values,
106: 	                                QueryErrorContext &error_context, string &func_name);
107: 
108: 	unique_ptr<BoundTableRef> Bind(TableRef &ref);
109: 	unique_ptr<LogicalOperator> CreatePlan(BoundTableRef &ref);
110: 
111: 	//! Generates an unused index for a table
112: 	idx_t GenerateTableIndex();
113: 
114: 	//! Add a common table expression to the binder
115: 	void AddCTE(const string &name, CommonTableExpressionInfo *cte);
116: 	//! Find a common table expression by name; returns nullptr if none exists
117: 	CommonTableExpressionInfo *FindCTE(const string &name, bool skip = false);
118: 
119: 	bool CTEIsAlreadyBound(CommonTableExpressionInfo *cte);
120: 
121: 	//! Add the view to the set of currently bound views - used for detecting recursive view definitions
122: 	void AddBoundView(ViewCatalogEntry *view);
123: 
124: 	void PushExpressionBinder(ExpressionBinder *binder);
125: 	void PopExpressionBinder();
126: 	void SetActiveBinder(ExpressionBinder *binder);
127: 	ExpressionBinder *GetActiveBinder();
128: 	bool HasActiveBinder();
129: 
130: 	vector<ExpressionBinder *> &GetActiveBinders();
131: 
132: 	void MergeCorrelatedColumns(vector<CorrelatedColumnInfo> &other);
133: 	//! Add a correlated column to this binder (if it does not exist)
134: 	void AddCorrelatedColumn(const CorrelatedColumnInfo &info);
135: 
136: 	string FormatError(ParsedExpression &expr_context, const string &message);
137: 	string FormatError(TableRef &ref_context, const string &message);
138: 
139: 	string FormatErrorRecursive(idx_t query_location, const string &message, vector<ExceptionFormatValue> &values);
140: 	template <class T, typename... Args>
141: 	string FormatErrorRecursive(idx_t query_location, const string &msg, vector<ExceptionFormatValue> &values, T param,
142: 	                            Args... params) {
143: 		values.push_back(ExceptionFormatValue::CreateFormatValue<T>(param));
144: 		return FormatErrorRecursive(query_location, msg, values, params...);
145: 	}
146: 
147: 	template <typename... Args>
148: 	string FormatError(idx_t query_location, const string &msg, Args... params) {
149: 		vector<ExceptionFormatValue> values;
150: 		return FormatErrorRecursive(query_location, msg, values, params...);
151: 	}
152: 
153: 	static void BindLogicalType(ClientContext &context, LogicalType &type, const string &schema = "");
154: 
155: 	bool HasMatchingBinding(const string &table_name, const string &column_name, string &error_message);
156: 	bool HasMatchingBinding(const string &schema_name, const string &table_name, const string &column_name,
157: 	                        string &error_message);
158: 
159: 	void SetBindingMode(BindingMode mode);
160: 	BindingMode GetBindingMode();
161: 	void AddTableName(string table_name);
162: 	const unordered_set<string> &GetTableNames();
163: 
164: private:
165: 	//! The parent binder (if any)
166: 	shared_ptr<Binder> parent;
167: 	//! The vector of active binders
168: 	vector<ExpressionBinder *> active_binders;
169: 	//! The count of bound_tables
170: 	idx_t bound_tables;
171: 	//! Whether or not the binder has any unplanned subqueries that still need to be planned
172: 	bool has_unplanned_subqueries = false;
173: 	//! Whether or not subqueries should be planned already
174: 	bool plan_subquery = true;
175: 	//! Whether CTEs should reference the parent binder (if it exists)
176: 	bool inherit_ctes = true;
177: 	//! Whether or not the binder can contain NULLs as the root of expressions
178: 	bool can_contain_nulls = false;
179: 	//! The root statement of the query that is currently being parsed
180: 	SQLStatement *root_statement = nullptr;
181: 	//! Binding mode
182: 	BindingMode mode = BindingMode::STANDARD_BINDING;
183: 	//! Table names extracted for BindingMode::EXTRACT_NAMES
184: 	unordered_set<string> table_names;
185: 	//! The set of bound views
186: 	unordered_set<ViewCatalogEntry *> bound_views;
187: 
188: private:
189: 	//! Bind the default values of the columns of a table
190: 	void BindDefaultValues(vector<ColumnDefinition> &columns, vector<unique_ptr<Expression>> &bound_defaults);
191: 	//! Bind a limit value (LIMIT or OFFSET)
192: 	unique_ptr<Expression> BindDelimiter(ClientContext &context, OrderBinder &order_binder,
193: 	                                     unique_ptr<ParsedExpression> delimiter, const LogicalType &type,
194: 	                                     Value &delimiter_value);
195: 
196: 	//! Move correlated expressions from the child binder to this binder
197: 	void MoveCorrelatedExpressions(Binder &other);
198: 
199: 	BoundStatement Bind(SelectStatement &stmt);
200: 	BoundStatement Bind(InsertStatement &stmt);
201: 	BoundStatement Bind(CopyStatement &stmt);
202: 	BoundStatement Bind(DeleteStatement &stmt);
203: 	BoundStatement Bind(UpdateStatement &stmt);
204: 	BoundStatement Bind(CreateStatement &stmt);
205: 	BoundStatement Bind(DropStatement &stmt);
206: 	BoundStatement Bind(AlterStatement &stmt);
207: 	BoundStatement Bind(TransactionStatement &stmt);
208: 	BoundStatement Bind(PragmaStatement &stmt);
209: 	BoundStatement Bind(ExplainStatement &stmt);
210: 	BoundStatement Bind(VacuumStatement &stmt);
211: 	BoundStatement Bind(RelationStatement &stmt);
212: 	BoundStatement Bind(ShowStatement &stmt);
213: 	BoundStatement Bind(CallStatement &stmt);
214: 	BoundStatement Bind(ExportStatement &stmt);
215: 	BoundStatement Bind(SetStatement &stmt);
216: 	BoundStatement Bind(LoadStatement &stmt);
217: 	BoundStatement BindReturning(vector<unique_ptr<ParsedExpression>> returning_list, TableCatalogEntry *table,
218: 	                             idx_t update_table_index, unique_ptr<LogicalOperator> child_operator,
219: 	                             BoundStatement result);
220: 
221: 	unique_ptr<QueryNode> BindTableMacro(FunctionExpression &function, TableMacroCatalogEntry *macro_func, idx_t depth);
222: 
223: 	unique_ptr<BoundQueryNode> BindNode(SelectNode &node);
224: 	unique_ptr<BoundQueryNode> BindNode(SetOperationNode &node);
225: 	unique_ptr<BoundQueryNode> BindNode(RecursiveCTENode &node);
226: 	unique_ptr<BoundQueryNode> BindNode(QueryNode &node);
227: 
228: 	unique_ptr<LogicalOperator> VisitQueryNode(BoundQueryNode &node, unique_ptr<LogicalOperator> root);
229: 	unique_ptr<LogicalOperator> CreatePlan(BoundRecursiveCTENode &node);
230: 	unique_ptr<LogicalOperator> CreatePlan(BoundSelectNode &statement);
231: 	unique_ptr<LogicalOperator> CreatePlan(BoundSetOperationNode &node);
232: 	unique_ptr<LogicalOperator> CreatePlan(BoundQueryNode &node);
233: 
234: 	unique_ptr<BoundTableRef> Bind(BaseTableRef &ref);
235: 	unique_ptr<BoundTableRef> Bind(CrossProductRef &ref);
236: 	unique_ptr<BoundTableRef> Bind(JoinRef &ref);
237: 	unique_ptr<BoundTableRef> Bind(SubqueryRef &ref, CommonTableExpressionInfo *cte = nullptr);
238: 	unique_ptr<BoundTableRef> Bind(TableFunctionRef &ref);
239: 	unique_ptr<BoundTableRef> Bind(EmptyTableRef &ref);
240: 	unique_ptr<BoundTableRef> Bind(ExpressionListRef &ref);
241: 
242: 	bool BindFunctionParameters(vector<unique_ptr<ParsedExpression>> &expressions, vector<LogicalType> &arguments,
243: 	                            vector<Value> &parameters, named_parameter_map_t &named_parameters,
244: 	                            unique_ptr<BoundSubqueryRef> &subquery, string &error);
245: 
246: 	unique_ptr<LogicalOperator> CreatePlan(BoundBaseTableRef &ref);
247: 	unique_ptr<LogicalOperator> CreatePlan(BoundCrossProductRef &ref);
248: 	unique_ptr<LogicalOperator> CreatePlan(BoundJoinRef &ref);
249: 	unique_ptr<LogicalOperator> CreatePlan(BoundSubqueryRef &ref);
250: 	unique_ptr<LogicalOperator> CreatePlan(BoundTableFunction &ref);
251: 	unique_ptr<LogicalOperator> CreatePlan(BoundEmptyTableRef &ref);
252: 	unique_ptr<LogicalOperator> CreatePlan(BoundExpressionListRef &ref);
253: 	unique_ptr<LogicalOperator> CreatePlan(BoundCTERef &ref);
254: 
255: 	BoundStatement BindCopyTo(CopyStatement &stmt);
256: 	BoundStatement BindCopyFrom(CopyStatement &stmt);
257: 
258: 	void BindModifiers(OrderBinder &order_binder, QueryNode &statement, BoundQueryNode &result);
259: 	void BindModifierTypes(BoundQueryNode &result, const vector<LogicalType> &sql_types, idx_t projection_index);
260: 
261: 	BoundStatement BindSummarize(ShowStatement &stmt);
262: 	unique_ptr<BoundResultModifier> BindLimit(OrderBinder &order_binder, LimitModifier &limit_mod);
263: 	unique_ptr<BoundResultModifier> BindLimitPercent(OrderBinder &order_binder, LimitPercentModifier &limit_mod);
264: 	unique_ptr<Expression> BindOrderExpression(OrderBinder &order_binder, unique_ptr<ParsedExpression> expr);
265: 
266: 	unique_ptr<LogicalOperator> PlanFilter(unique_ptr<Expression> condition, unique_ptr<LogicalOperator> root);
267: 
268: 	void PlanSubqueries(unique_ptr<Expression> *expr, unique_ptr<LogicalOperator> *root);
269: 	unique_ptr<Expression> PlanSubquery(BoundSubqueryExpression &expr, unique_ptr<LogicalOperator> &root);
270: 
271: 	unique_ptr<LogicalOperator> CastLogicalOperatorToTypes(vector<LogicalType> &source_types,
272: 	                                                       vector<LogicalType> &target_types,
273: 	                                                       unique_ptr<LogicalOperator> op);
274: 
275: 	string FindBinding(const string &using_column, const string &join_side);
276: 	bool TryFindBinding(const string &using_column, const string &join_side, string &result);
277: 
278: 	void AddUsingBindingSet(unique_ptr<UsingColumnSet> set);
279: 	string RetrieveUsingBinding(Binder &current_binder, UsingColumnSet *current_set, const string &column_name,
280: 	                            const string &join_side, UsingColumnSet *new_set);
281: 
282: public:
283: 	// This should really be a private constructor, but make_shared does not allow it...
284: 	// If you are thinking about calling this, you should probably call Binder::CreateBinder
285: 	Binder(bool I_know_what_I_am_doing, ClientContext &context, shared_ptr<Binder> parent, bool inherit_ctes);
286: };
287: 
288: } // namespace duckdb
[end of src/include/duckdb/planner/binder.hpp]
[start of src/include/duckdb/planner/expression_binder.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/planner/expression_binder.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/exception.hpp"
12: #include "duckdb/parser/expression/bound_expression.hpp"
13: #include "duckdb/parser/parsed_expression.hpp"
14: #include "duckdb/parser/tokens.hpp"
15: #include "duckdb/planner/expression.hpp"
16: #include "duckdb/common/unordered_map.hpp"
17: 
18: namespace duckdb {
19: 
20: class Binder;
21: class ClientContext;
22: class QueryNode;
23: 
24: class ScalarFunctionCatalogEntry;
25: class AggregateFunctionCatalogEntry;
26: class ScalarMacroCatalogEntry;
27: class CatalogEntry;
28: class SimpleFunction;
29: 
30: struct MacroBinding;
31: 
32: struct BoundColumnReferenceInfo {
33: 	string name;
34: 	idx_t query_location;
35: };
36: 
37: struct BindResult {
38: 	BindResult() {
39: 	}
40: 	explicit BindResult(string error) : error(error) {
41: 	}
42: 	explicit BindResult(unique_ptr<Expression> expr) : expression(move(expr)) {
43: 	}
44: 
45: 	bool HasError() {
46: 		return !error.empty();
47: 	}
48: 
49: 	unique_ptr<Expression> expression;
50: 	string error;
51: };
52: 
53: class ExpressionBinder {
54: public:
55: 	ExpressionBinder(Binder &binder, ClientContext &context, bool replace_binder = false);
56: 	virtual ~ExpressionBinder();
57: 
58: 	//! The target type that should result from the binder. If the result is not of this type, a cast to this type will
59: 	//! be added. Defaults to INVALID.
60: 	LogicalType target_type;
61: 
62: 	MacroBinding *macro_binding;
63: 
64: public:
65: 	unique_ptr<Expression> Bind(unique_ptr<ParsedExpression> &expr, LogicalType *result_type = nullptr,
66: 	                            bool root_expression = true);
67: 
68: 	//! Returns whether or not any columns have been bound by the expression binder
69: 	bool HasBoundColumns() {
70: 		return !bound_columns.empty();
71: 	}
72: 	const vector<BoundColumnReferenceInfo> &GetBoundColumns() {
73: 		return bound_columns;
74: 	}
75: 
76: 	string Bind(unique_ptr<ParsedExpression> *expr, idx_t depth, bool root_expression = false);
77: 
78: 	unique_ptr<ParsedExpression> CreateStructExtract(unique_ptr<ParsedExpression> base, string field_name);
79: 	BindResult BindQualifiedColumnName(ColumnRefExpression &colref, const string &table_name);
80: 
81: 	unique_ptr<ParsedExpression> QualifyColumnName(const string &column_name, string &error_message);
82: 	unique_ptr<ParsedExpression> QualifyColumnName(ColumnRefExpression &colref, string &error_message);
83: 
84: 	// Bind table names to ColumnRefExpressions
85: 	void QualifyColumnNames(unique_ptr<ParsedExpression> &expr);
86: 	static void QualifyColumnNames(Binder &binder, unique_ptr<ParsedExpression> &expr);
87: 
88: 	static unique_ptr<Expression> PushCollation(ClientContext &context, unique_ptr<Expression> source,
89: 	                                            const string &collation, bool equality_only = false);
90: 	static void TestCollation(ClientContext &context, const string &collation);
91: 
92: 	bool BindCorrelatedColumns(unique_ptr<ParsedExpression> &expr);
93: 
94: 	void BindChild(unique_ptr<ParsedExpression> &expr, idx_t depth, string &error);
95: 	static void ExtractCorrelatedExpressions(Binder &binder, Expression &expr);
96: 
97: 	static bool ContainsNullType(const LogicalType &type);
98: 	static LogicalType ExchangeNullType(const LogicalType &type);
99: 	static bool ContainsType(const LogicalType &type, LogicalTypeId target);
100: 	static LogicalType ExchangeType(const LogicalType &type, LogicalTypeId target, LogicalType new_type);
101: 
102: 	static void ResolveParameterType(LogicalType &type);
103: 	static void ResolveParameterType(unique_ptr<Expression> &expr);
104: 
105: 	//! Bind the given expresion. Unlike Bind(), this does *not* mute the given ParsedExpression.
106: 	//! Exposed to be used from sub-binders that aren't subclasses of ExpressionBinder.
107: 	virtual BindResult BindExpression(unique_ptr<ParsedExpression> *expr_ptr, idx_t depth,
108: 	                                  bool root_expression = false);
109: 
110: 	void ReplaceMacroParametersRecursive(unique_ptr<ParsedExpression> &expr);
111: 
112: protected:
113: 	BindResult BindExpression(BetweenExpression &expr, idx_t depth);
114: 	BindResult BindExpression(CaseExpression &expr, idx_t depth);
115: 	BindResult BindExpression(CollateExpression &expr, idx_t depth);
116: 	BindResult BindExpression(CastExpression &expr, idx_t depth);
117: 	BindResult BindExpression(ColumnRefExpression &expr, idx_t depth);
118: 	BindResult BindExpression(ComparisonExpression &expr, idx_t depth);
119: 	BindResult BindExpression(ConjunctionExpression &expr, idx_t depth);
120: 	BindResult BindExpression(ConstantExpression &expr, idx_t depth);
121: 	BindResult BindExpression(FunctionExpression &expr, idx_t depth, unique_ptr<ParsedExpression> *expr_ptr);
122: 	BindResult BindExpression(LambdaExpression &expr, idx_t depth);
123: 	BindResult BindExpression(OperatorExpression &expr, idx_t depth);
124: 	BindResult BindExpression(ParameterExpression &expr, idx_t depth);
125: 	BindResult BindExpression(PositionalReferenceExpression &ref, idx_t depth);
126: 	BindResult BindExpression(StarExpression &expr, idx_t depth);
127: 	BindResult BindExpression(SubqueryExpression &expr, idx_t depth);
128: 
129: protected:
130: 	virtual BindResult BindGroupingFunction(OperatorExpression &op, idx_t depth);
131: 	virtual BindResult BindFunction(FunctionExpression &expr, ScalarFunctionCatalogEntry *function, idx_t depth);
132: 	virtual BindResult BindAggregate(FunctionExpression &expr, AggregateFunctionCatalogEntry *function, idx_t depth);
133: 	virtual BindResult BindUnnest(FunctionExpression &expr, idx_t depth);
134: 	virtual BindResult BindMacro(FunctionExpression &expr, ScalarMacroCatalogEntry *macro, idx_t depth,
135: 	                             unique_ptr<ParsedExpression> *expr_ptr);
136: 
137: 	virtual string UnsupportedAggregateMessage();
138: 	virtual string UnsupportedUnnestMessage();
139: 
140: 	Binder &binder;
141: 	ClientContext &context;
142: 	ExpressionBinder *stored_binder;
143: 	vector<BoundColumnReferenceInfo> bound_columns;
144: };
145: 
146: } // namespace duckdb
[end of src/include/duckdb/planner/expression_binder.hpp]
[start of src/include/duckdb/planner/planner.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/planner/planner.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/parser/sql_statement.hpp"
12: #include "duckdb/planner/binder.hpp"
13: #include "duckdb/planner/logical_operator.hpp"
14: 
15: namespace duckdb {
16: class ClientContext;
17: class PreparedStatementData;
18: 
19: //! The planner creates a logical query plan from the parsed SQL statements
20: //! using the Binder and LogicalPlanGenerator.
21: class Planner {
22: public:
23: 	explicit Planner(ClientContext &context);
24: 
25: 	void CreatePlan(unique_ptr<SQLStatement> statement);
26: 
27: 	unique_ptr<LogicalOperator> plan;
28: 	vector<string> names;
29: 	vector<LogicalType> types;
30: 	unordered_map<idx_t, vector<unique_ptr<Value>>> value_map;
31: 
32: 	shared_ptr<Binder> binder;
33: 	ClientContext &context;
34: 
35: 	bool read_only;
36: 	bool requires_valid_transaction;
37: 	bool allow_stream_result;
38: 
39: private:
40: 	void CreatePlan(SQLStatement &statement);
41: 	shared_ptr<PreparedStatementData> PrepareSQLStatement(unique_ptr<SQLStatement> statement);
42: 	void PlanPrepare(unique_ptr<SQLStatement> statement);
43: 	void PlanExecute(unique_ptr<SQLStatement> statement);
44: 
45: 	// void VerifyQuery(BoundSQLStatement &statement);
46: 	// void VerifyNode(BoundQueryNode &statement);
47: 	// void VerifyExpression(Expression &expr, vector<unique_ptr<Expression>> &copies);
48: 
49: 	// bool StatementRequiresValidTransaction(BoundSQLStatement &statement);
50: };
51: } // namespace duckdb
[end of src/include/duckdb/planner/planner.hpp]
[start of src/main/client_context.cpp]
1: #include "duckdb/main/client_context.hpp"
2: 
3: #include "duckdb/main/client_context_file_opener.hpp"
4: #include "duckdb/main/query_profiler.hpp"
5: #include "duckdb/catalog/catalog_entry/table_catalog_entry.hpp"
6: #include "duckdb/catalog/catalog_entry/scalar_function_catalog_entry.hpp"
7: #include "duckdb/catalog/catalog_search_path.hpp"
8: #include "duckdb/common/serializer/buffered_deserializer.hpp"
9: #include "duckdb/common/serializer/buffered_serializer.hpp"
10: #include "duckdb/execution/physical_plan_generator.hpp"
11: #include "duckdb/main/database.hpp"
12: #include "duckdb/main/materialized_query_result.hpp"
13: #include "duckdb/main/query_result.hpp"
14: #include "duckdb/main/stream_query_result.hpp"
15: #include "duckdb/optimizer/optimizer.hpp"
16: #include "duckdb/parser/parser.hpp"
17: #include "duckdb/parser/expression/constant_expression.hpp"
18: #include "duckdb/parser/parsed_data/create_function_info.hpp"
19: #include "duckdb/parser/statement/drop_statement.hpp"
20: #include "duckdb/parser/statement/explain_statement.hpp"
21: #include "duckdb/parser/statement/select_statement.hpp"
22: #include "duckdb/planner/operator/logical_execute.hpp"
23: #include "duckdb/planner/planner.hpp"
24: #include "duckdb/transaction/transaction_manager.hpp"
25: #include "duckdb/transaction/transaction.hpp"
26: #include "duckdb/storage/data_table.hpp"
27: #include "duckdb/main/appender.hpp"
28: #include "duckdb/main/relation.hpp"
29: #include "duckdb/parser/statement/relation_statement.hpp"
30: #include "duckdb/parallel/task_scheduler.hpp"
31: #include "duckdb/common/serializer/buffered_file_writer.hpp"
32: #include "duckdb/planner/pragma_handler.hpp"
33: #include "duckdb/common/file_system.hpp"
34: #include "duckdb/execution/column_binding_resolver.hpp"
35: 
36: namespace duckdb {
37: 
38: struct ActiveQueryContext {
39: 	//! The query that is currently being executed
40: 	string query;
41: 	//! The currently open result
42: 	BaseQueryResult *open_result = nullptr;
43: 	//! Prepared statement data
44: 	shared_ptr<PreparedStatementData> prepared;
45: 	//! The query executor
46: 	unique_ptr<Executor> executor;
47: 	//! The progress bar
48: 	unique_ptr<ProgressBar> progress_bar;
49: };
50: 
51: ClientContext::ClientContext(shared_ptr<DatabaseInstance> database)
52:     : profiler(make_shared<QueryProfiler>(*this)), query_profiler_history(make_unique<QueryProfilerHistory>()),
53:       db(move(database)), transaction(db->GetTransactionManager(), *this), interrupted(false),
54:       temporary_objects(make_unique<SchemaCatalogEntry>(&db->GetCatalog(), TEMP_SCHEMA, true)),
55:       catalog_search_path(make_unique<CatalogSearchPath>(*this)),
56:       file_opener(make_unique<ClientContextFileOpener>(*this)) {
57: 	std::random_device rd;
58: 	random_engine.seed(rd());
59: }
60: 
61: ClientContext::~ClientContext() {
62: 	if (Exception::UncaughtException()) {
63: 		return;
64: 	}
65: 	// destroy the client context and rollback if there is an active transaction
66: 	// but only if we are not destroying this client context as part of an exception stack unwind
67: 	Destroy();
68: }
69: 
70: unique_ptr<ClientContextLock> ClientContext::LockContext() {
71: 	return make_unique<ClientContextLock>(context_lock);
72: }
73: 
74: void ClientContext::Destroy() {
75: 	auto lock = LockContext();
76: 	if (transaction.HasActiveTransaction()) {
77: 		ActiveTransaction().active_query = MAXIMUM_QUERY_ID;
78: 		if (!transaction.IsAutoCommit()) {
79: 			transaction.Rollback();
80: 		}
81: 	}
82: 	CleanupInternal(*lock);
83: }
84: 
85: unique_ptr<DataChunk> ClientContext::Fetch(ClientContextLock &lock, StreamQueryResult &result) {
86: 	D_ASSERT(IsActiveResult(lock, &result));
87: 	D_ASSERT(active_query->executor);
88: 	return FetchInternal(lock, *active_query->executor, result);
89: }
90: 
91: unique_ptr<DataChunk> ClientContext::FetchInternal(ClientContextLock &lock, Executor &executor,
92:                                                    BaseQueryResult &result) {
93: 	bool invalidate_query = true;
94: 	try {
95: 		// fetch the chunk and return it
96: 		auto chunk = executor.FetchChunk();
97: 		if (!chunk || chunk->size() == 0) {
98: 			CleanupInternal(lock, &result);
99: 		}
100: 		return chunk;
101: 	} catch (StandardException &ex) {
102: 		// standard exceptions do not invalidate the current transaction
103: 		result.error = ex.what();
104: 		invalidate_query = false;
105: 	} catch (std::exception &ex) {
106: 		result.error = ex.what();
107: 	} catch (...) { // LCOV_EXCL_START
108: 		result.error = "Unhandled exception in FetchInternal";
109: 	} // LCOV_EXCL_STOP
110: 	result.success = false;
111: 	CleanupInternal(lock, &result, invalidate_query);
112: 	return nullptr;
113: }
114: 
115: void ClientContext::BeginTransactionInternal(ClientContextLock &lock, bool requires_valid_transaction) {
116: 	// check if we are on AutoCommit. In this case we should start a transaction
117: 	D_ASSERT(!active_query);
118: 	if (requires_valid_transaction && transaction.HasActiveTransaction() &&
119: 	    transaction.ActiveTransaction().IsInvalidated()) {
120: 		throw Exception("Failed: transaction has been invalidated!");
121: 	}
122: 	active_query = make_unique<ActiveQueryContext>();
123: 	if (transaction.IsAutoCommit()) {
124: 		transaction.BeginTransaction();
125: 	}
126: }
127: 
128: void ClientContext::BeginQueryInternal(ClientContextLock &lock, const string &query) {
129: 	BeginTransactionInternal(lock, false);
130: 	LogQueryInternal(lock, query);
131: 	active_query->query = query;
132: 	query_progress = -1;
133: 	ActiveTransaction().active_query = db->GetTransactionManager().GetQueryNumber();
134: }
135: 
136: string ClientContext::EndQueryInternal(ClientContextLock &lock, bool success, bool invalidate_transaction) {
137: 	profiler->EndQuery();
138: 
139: 	D_ASSERT(active_query.get());
140: 	string error;
141: 	try {
142: 		if (transaction.HasActiveTransaction()) {
143: 			// Move the query profiler into the history
144: 			auto &prev_profilers = query_profiler_history->GetPrevProfilers();
145: 			prev_profilers.emplace_back(transaction.ActiveTransaction().active_query, move(profiler));
146: 			// Reinitialize the query profiler
147: 			profiler = make_shared<QueryProfiler>(*this);
148: 			// Propagate settings of the saved query into the new profiler.
149: 			profiler->Propagate(*prev_profilers.back().second);
150: 			if (prev_profilers.size() >= query_profiler_history->GetPrevProfilersSize()) {
151: 				prev_profilers.pop_front();
152: 			}
153: 
154: 			ActiveTransaction().active_query = MAXIMUM_QUERY_ID;
155: 			if (transaction.IsAutoCommit()) {
156: 				if (success) {
157: 					transaction.Commit();
158: 				} else {
159: 					transaction.Rollback();
160: 				}
161: 			} else if (invalidate_transaction) {
162: 				D_ASSERT(!success);
163: 				ActiveTransaction().Invalidate();
164: 			}
165: 		}
166: 	} catch (std::exception &ex) {
167: 		error = ex.what();
168: 	} catch (...) { // LCOV_EXCL_START
169: 		error = "Unhandled exception!";
170: 	} // LCOV_EXCL_STOP
171: 	active_query.reset();
172: 	query_progress = -1;
173: 	return error;
174: }
175: 
176: void ClientContext::CleanupInternal(ClientContextLock &lock, BaseQueryResult *result, bool invalidate_transaction) {
177: 	if (!active_query) {
178: 		// no query currently active
179: 		return;
180: 	}
181: 	if (active_query->executor) {
182: 		active_query->executor->CancelTasks();
183: 	}
184: 	active_query->progress_bar.reset();
185: 
186: 	auto error = EndQueryInternal(lock, result ? result->success : false, invalidate_transaction);
187: 	if (result && result->success) {
188: 		// if an error occurred while committing report it in the result
189: 		result->error = error;
190: 		result->success = error.empty();
191: 	}
192: 	D_ASSERT(!active_query);
193: }
194: 
195: Executor &ClientContext::GetExecutor() {
196: 	D_ASSERT(active_query);
197: 	D_ASSERT(active_query->executor);
198: 	return *active_query->executor;
199: }
200: 
201: const string &ClientContext::GetCurrentQuery() {
202: 	D_ASSERT(active_query);
203: 	return active_query->query;
204: }
205: 
206: unique_ptr<QueryResult> ClientContext::FetchResultInternal(ClientContextLock &lock, PendingQueryResult &pending,
207:                                                            bool allow_stream_result) {
208: 	D_ASSERT(active_query);
209: 	D_ASSERT(active_query->open_result == &pending);
210: 	D_ASSERT(active_query->prepared);
211: 	auto &prepared = *active_query->prepared;
212: 	bool create_stream_result = prepared.allow_stream_result && allow_stream_result;
213: 	if (create_stream_result) {
214: 		active_query->progress_bar.reset();
215: 		query_progress = -1;
216: 
217: 		// successfully compiled SELECT clause and it is the last statement
218: 		// return a StreamQueryResult so the client can call Fetch() on it and stream the result
219: 		auto stream_result =
220: 		    make_unique<StreamQueryResult>(pending.statement_type, shared_from_this(), pending.types, pending.names);
221: 		active_query->open_result = stream_result.get();
222: 		return move(stream_result);
223: 	}
224: 	// create a materialized result by continuously fetching
225: 	auto result = make_unique<MaterializedQueryResult>(pending.statement_type, pending.types, pending.names);
226: 	while (true) {
227: 		auto chunk = FetchInternal(lock, GetExecutor(), *result);
228: 		if (!chunk || chunk->size() == 0) {
229: 			break;
230: 		}
231: #ifdef DEBUG
232: 		for (idx_t i = 0; i < chunk->ColumnCount(); i++) {
233: 			if (pending.types[i].id() == LogicalTypeId::VARCHAR) {
234: 				chunk->data[i].UTFVerify(chunk->size());
235: 			}
236: 		}
237: #endif
238: 		result->collection.Append(*chunk);
239: 	}
240: 	return move(result);
241: }
242: 
243: shared_ptr<PreparedStatementData> ClientContext::CreatePreparedStatement(ClientContextLock &lock, const string &query,
244:                                                                          unique_ptr<SQLStatement> statement) {
245: 	StatementType statement_type = statement->type;
246: 	auto result = make_shared<PreparedStatementData>(statement_type);
247: 
248: 	auto &profiler = QueryProfiler::Get(*this);
249: 	profiler.StartPhase("planner");
250: 	Planner planner(*this);
251: 	planner.CreatePlan(move(statement));
252: 	D_ASSERT(planner.plan);
253: 	profiler.EndPhase();
254: 
255: 	auto plan = move(planner.plan);
256: #ifdef DEBUG
257: 	plan->Verify();
258: #endif
259: 	// extract the result column names from the plan
260: 	result->read_only = planner.read_only;
261: 	result->requires_valid_transaction = planner.requires_valid_transaction;
262: 	result->allow_stream_result = planner.allow_stream_result;
263: 	result->names = planner.names;
264: 	result->types = planner.types;
265: 	result->value_map = move(planner.value_map);
266: 	result->catalog_version = Transaction::GetTransaction(*this).catalog_version;
267: 
268: 	if (config.enable_optimizer) {
269: 		profiler.StartPhase("optimizer");
270: 		Optimizer optimizer(*planner.binder, *this);
271: 		plan = optimizer.Optimize(move(plan));
272: 		D_ASSERT(plan);
273: 		profiler.EndPhase();
274: 
275: #ifdef DEBUG
276: 		plan->Verify();
277: #endif
278: 	}
279: 
280: 	profiler.StartPhase("physical_planner");
281: 	// now convert logical query plan into a physical query plan
282: 	PhysicalPlanGenerator physical_planner(*this);
283: 	auto physical_plan = physical_planner.CreatePlan(move(plan));
284: 	profiler.EndPhase();
285: 
286: #ifdef DEBUG
287: 	D_ASSERT(!physical_plan->ToString().empty());
288: #endif
289: 	result->plan = move(physical_plan);
290: 	return result;
291: }
292: 
293: double ClientContext::GetProgress() {
294: 	return query_progress.load();
295: }
296: 
297: unique_ptr<PendingQueryResult> ClientContext::PendingPreparedStatement(ClientContextLock &lock,
298:                                                                        shared_ptr<PreparedStatementData> statement_p,
299:                                                                        vector<Value> bound_values) {
300: 	D_ASSERT(active_query);
301: 	auto &statement = *statement_p;
302: 	if (ActiveTransaction().IsInvalidated() && statement.requires_valid_transaction) {
303: 		throw Exception("Current transaction is aborted (please ROLLBACK)");
304: 	}
305: 	auto &db_config = DBConfig::GetConfig(*this);
306: 	if (db_config.access_mode == AccessMode::READ_ONLY && !statement.read_only) {
307: 		throw Exception(StringUtil::Format("Cannot execute statement of type \"%s\" in read-only mode!",
308: 		                                   StatementTypeToString(statement.statement_type)));
309: 	}
310: 
311: 	// bind the bound values before execution
312: 	statement.Bind(move(bound_values));
313: 
314: 	active_query->executor = make_unique<Executor>(*this);
315: 	auto &executor = *active_query->executor;
316: 	if (config.enable_progress_bar) {
317: 		active_query->progress_bar = make_unique<ProgressBar>(executor, config.wait_time);
318: 		active_query->progress_bar->Start();
319: 		query_progress = 0;
320: 	}
321: 	executor.Initialize(statement.plan.get());
322: 	auto types = executor.GetTypes();
323: 	D_ASSERT(types == statement.types);
324: 	D_ASSERT(!active_query->open_result);
325: 
326: 	auto pending_result = make_unique<PendingQueryResult>(shared_from_this(), *statement_p, move(types));
327: 	active_query->prepared = move(statement_p);
328: 	active_query->open_result = pending_result.get();
329: 	return pending_result;
330: }
331: 
332: PendingExecutionResult ClientContext::ExecuteTaskInternal(ClientContextLock &lock, PendingQueryResult &result) {
333: 	D_ASSERT(active_query);
334: 	D_ASSERT(active_query->open_result == &result);
335: 	try {
336: 		auto result = active_query->executor->ExecuteTask();
337: 		if (active_query->progress_bar) {
338: 			active_query->progress_bar->Update(result == PendingExecutionResult::RESULT_READY);
339: 			query_progress = active_query->progress_bar->GetCurrentPercentage();
340: 		}
341: 		return result;
342: 	} catch (std::exception &ex) {
343: 		result.error = ex.what();
344: 	} catch (...) { // LCOV_EXCL_START
345: 		result.error = "Unhandled exception in ExecuteTaskInternal";
346: 	} // LCOV_EXCL_STOP
347: 	EndQueryInternal(lock, false, true);
348: 	result.success = false;
349: 	return PendingExecutionResult::EXECUTION_ERROR;
350: }
351: 
352: void ClientContext::InitialCleanup(ClientContextLock &lock) {
353: 	//! Cleanup any open results and reset the interrupted flag
354: 	CleanupInternal(lock);
355: 	interrupted = false;
356: }
357: 
358: vector<unique_ptr<SQLStatement>> ClientContext::ParseStatements(const string &query) {
359: 	auto lock = LockContext();
360: 	return ParseStatementsInternal(*lock, query);
361: }
362: 
363: vector<unique_ptr<SQLStatement>> ClientContext::ParseStatementsInternal(ClientContextLock &lock, const string &query) {
364: 	Parser parser(GetParserOptions());
365: 	parser.ParseQuery(query);
366: 
367: 	PragmaHandler handler(*this);
368: 	handler.HandlePragmaStatements(lock, parser.statements);
369: 
370: 	return move(parser.statements);
371: }
372: 
373: void ClientContext::HandlePragmaStatements(vector<unique_ptr<SQLStatement>> &statements) {
374: 	auto lock = LockContext();
375: 
376: 	PragmaHandler handler(*this);
377: 	handler.HandlePragmaStatements(*lock, statements);
378: }
379: 
380: unique_ptr<LogicalOperator> ClientContext::ExtractPlan(const string &query) {
381: 	auto lock = LockContext();
382: 
383: 	auto statements = ParseStatementsInternal(*lock, query);
384: 	if (statements.size() != 1) {
385: 		throw Exception("ExtractPlan can only prepare a single statement");
386: 	}
387: 
388: 	unique_ptr<LogicalOperator> plan;
389: 	RunFunctionInTransactionInternal(*lock, [&]() {
390: 		Planner planner(*this);
391: 		planner.CreatePlan(move(statements[0]));
392: 		D_ASSERT(planner.plan);
393: 
394: 		plan = move(planner.plan);
395: 
396: 		if (config.enable_optimizer) {
397: 			Optimizer optimizer(*planner.binder, *this);
398: 			plan = optimizer.Optimize(move(plan));
399: 		}
400: 
401: 		ColumnBindingResolver resolver;
402: 		resolver.VisitOperator(*plan);
403: 
404: 		plan->ResolveOperatorTypes();
405: 	});
406: 	return plan;
407: }
408: 
409: unique_ptr<PreparedStatement> ClientContext::PrepareInternal(ClientContextLock &lock,
410:                                                              unique_ptr<SQLStatement> statement) {
411: 	auto n_param = statement->n_param;
412: 	auto statement_query = statement->query;
413: 	shared_ptr<PreparedStatementData> prepared_data;
414: 	auto unbound_statement = statement->Copy();
415: 	RunFunctionInTransactionInternal(
416: 	    lock, [&]() { prepared_data = CreatePreparedStatement(lock, statement_query, move(statement)); }, false);
417: 	prepared_data->unbound_statement = move(unbound_statement);
418: 	return make_unique<PreparedStatement>(shared_from_this(), move(prepared_data), move(statement_query), n_param);
419: }
420: 
421: unique_ptr<PreparedStatement> ClientContext::Prepare(unique_ptr<SQLStatement> statement) {
422: 	auto lock = LockContext();
423: 	// prepare the query
424: 	try {
425: 		InitialCleanup(*lock);
426: 		return PrepareInternal(*lock, move(statement));
427: 	} catch (std::exception &ex) {
428: 		return make_unique<PreparedStatement>(ex.what());
429: 	}
430: }
431: 
432: unique_ptr<PreparedStatement> ClientContext::Prepare(const string &query) {
433: 	auto lock = LockContext();
434: 	// prepare the query
435: 	try {
436: 		InitialCleanup(*lock);
437: 
438: 		// first parse the query
439: 		auto statements = ParseStatementsInternal(*lock, query);
440: 		if (statements.empty()) {
441: 			throw Exception("No statement to prepare!");
442: 		}
443: 		if (statements.size() > 1) {
444: 			throw Exception("Cannot prepare multiple statements at once!");
445: 		}
446: 		return PrepareInternal(*lock, move(statements[0]));
447: 	} catch (std::exception &ex) {
448: 		return make_unique<PreparedStatement>(ex.what());
449: 	}
450: }
451: 
452: unique_ptr<PendingQueryResult> ClientContext::PendingQueryPreparedInternal(ClientContextLock &lock, const string &query,
453:                                                                            shared_ptr<PreparedStatementData> &prepared,
454:                                                                            vector<Value> &values) {
455: 	try {
456: 		InitialCleanup(lock);
457: 	} catch (std::exception &ex) {
458: 		return make_unique<PendingQueryResult>(ex.what());
459: 	}
460: 	return PendingStatementOrPreparedStatementInternal(lock, query, nullptr, prepared, &values);
461: }
462: 
463: unique_ptr<PendingQueryResult>
464: ClientContext::PendingQuery(const string &query, shared_ptr<PreparedStatementData> &prepared, vector<Value> &values) {
465: 	auto lock = LockContext();
466: 	return PendingQueryPreparedInternal(*lock, query, prepared, values);
467: }
468: 
469: unique_ptr<QueryResult> ClientContext::Execute(const string &query, shared_ptr<PreparedStatementData> &prepared,
470:                                                vector<Value> &values, bool allow_stream_result) {
471: 	auto lock = LockContext();
472: 	auto pending = PendingQueryPreparedInternal(*lock, query, prepared, values);
473: 	if (!pending->success) {
474: 		return make_unique<MaterializedQueryResult>(pending->error);
475: 	}
476: 	return pending->ExecuteInternal(*lock, allow_stream_result);
477: }
478: 
479: unique_ptr<PendingQueryResult> ClientContext::PendingStatementInternal(ClientContextLock &lock, const string &query,
480:                                                                        unique_ptr<SQLStatement> statement) {
481: 	// prepare the query for execution
482: 	auto prepared = CreatePreparedStatement(lock, query, move(statement));
483: 	// by default, no values are bound
484: 	vector<Value> bound_values;
485: 	// execute the prepared statement
486: 	return PendingPreparedStatement(lock, move(prepared), move(bound_values));
487: }
488: 
489: unique_ptr<QueryResult> ClientContext::RunStatementInternal(ClientContextLock &lock, const string &query,
490:                                                             unique_ptr<SQLStatement> statement,
491:                                                             bool allow_stream_result, bool verify) {
492: 	auto pending = PendingQueryInternal(lock, move(statement), verify);
493: 	if (!pending->success) {
494: 		return make_unique<MaterializedQueryResult>(move(pending->error));
495: 	}
496: 	return ExecutePendingQueryInternal(lock, *pending, allow_stream_result);
497: }
498: 
499: bool ClientContext::IsActiveResult(ClientContextLock &lock, BaseQueryResult *result) {
500: 	if (!active_query) {
501: 		return false;
502: 	}
503: 	return active_query->open_result == result;
504: }
505: 
506: static bool IsExplainAnalyze(SQLStatement *statement) {
507: 	if (!statement) {
508: 		return false;
509: 	}
510: 	if (statement->type != StatementType::EXPLAIN_STATEMENT) {
511: 		return false;
512: 	}
513: 	auto &explain = (ExplainStatement &)*statement;
514: 	return explain.explain_type == ExplainType::EXPLAIN_ANALYZE;
515: }
516: 
517: unique_ptr<PendingQueryResult> ClientContext::PendingStatementOrPreparedStatementInternal(
518:     ClientContextLock &lock, const string &query, unique_ptr<SQLStatement> statement,
519:     shared_ptr<PreparedStatementData> &prepared, vector<Value> *values) {
520: 	// check if we are on AutoCommit. In this case we should start a transaction.
521: 	if (statement && config.query_verification_enabled) {
522: 		// query verification is enabled
523: 		// create a copy of the statement, and use the copy
524: 		// this way we verify that the copy correctly copies all properties
525: 		auto copied_statement = statement->Copy();
526: 		switch (statement->type) {
527: 		case StatementType::SELECT_STATEMENT: {
528: 			// in case this is a select query, we verify the original statement
529: 			string error;
530: 			try {
531: 				error = VerifyQuery(lock, query, move(statement));
532: 			} catch (std::exception &ex) {
533: 				error = ex.what();
534: 			}
535: 			if (!error.empty()) {
536: 				// error in verifying query
537: 				return make_unique<PendingQueryResult>(error);
538: 			}
539: 			statement = move(copied_statement);
540: 			break;
541: 		}
542: 		case StatementType::INSERT_STATEMENT:
543: 		case StatementType::DELETE_STATEMENT:
544: 		case StatementType::UPDATE_STATEMENT: {
545: 			auto sql = statement->ToString();
546: 			Parser parser;
547: 			parser.ParseQuery(sql);
548: 			statement = move(parser.statements[0]);
549: 			break;
550: 		}
551: 		default:
552: 			statement = move(copied_statement);
553: 			break;
554: 		}
555: 	}
556: 	return PendingStatementOrPreparedStatement(lock, query, move(statement), prepared, values);
557: }
558: 
559: unique_ptr<PendingQueryResult>
560: ClientContext::PendingStatementOrPreparedStatement(ClientContextLock &lock, const string &query,
561:                                                    unique_ptr<SQLStatement> statement,
562:                                                    shared_ptr<PreparedStatementData> &prepared, vector<Value> *values) {
563: 	unique_ptr<PendingQueryResult> result;
564: 
565: 	BeginQueryInternal(lock, query);
566: 	// start the profiler
567: 	auto &profiler = QueryProfiler::Get(*this);
568: 	profiler.StartQuery(query, IsExplainAnalyze(statement ? statement.get() : prepared->unbound_statement.get()));
569: 	bool invalidate_query = true;
570: 	try {
571: 		if (statement) {
572: 			result = PendingStatementInternal(lock, query, move(statement));
573: 		} else {
574: 			auto &catalog = Catalog::GetCatalog(*this);
575: 			if (prepared->unbound_statement && catalog.GetCatalogVersion() != prepared->catalog_version) {
576: 				D_ASSERT(prepared->unbound_statement.get());
577: 				// catalog was modified: rebind the statement before execution
578: 				auto new_prepared = CreatePreparedStatement(lock, query, prepared->unbound_statement->Copy());
579: 				if (prepared->types != new_prepared->types) {
580: 					throw BinderException("Rebinding statement after catalog change resulted in change of types");
581: 				}
582: 				new_prepared->unbound_statement = move(prepared->unbound_statement);
583: 				prepared = move(new_prepared);
584: 			}
585: 			result = PendingPreparedStatement(lock, prepared, *values);
586: 		}
587: 	} catch (StandardException &ex) {
588: 		// standard exceptions do not invalidate the current transaction
589: 		result = make_unique<PendingQueryResult>(ex.what());
590: 		invalidate_query = false;
591: 	} catch (std::exception &ex) {
592: 		// other types of exceptions do invalidate the current transaction
593: 		result = make_unique<PendingQueryResult>(ex.what());
594: 	}
595: 	if (!result->success) {
596: 		// query failed: abort now
597: 		EndQueryInternal(lock, false, invalidate_query);
598: 		return result;
599: 	}
600: 	D_ASSERT(active_query->open_result == result.get());
601: 	return result;
602: }
603: 
604: void ClientContext::LogQueryInternal(ClientContextLock &, const string &query) {
605: 	if (!log_query_writer) {
606: #ifdef DUCKDB_FORCE_QUERY_LOG
607: 		try {
608: 			string log_path(DUCKDB_FORCE_QUERY_LOG);
609: 			log_query_writer = make_unique<BufferedFileWriter>(
610: 			    FileSystem::GetFileSystem(*this), log_path, BufferedFileWriter::DEFAULT_OPEN_FLAGS, file_opener.get());
611: 		} catch (...) {
612: 			return;
613: 		}
614: #else
615: 		return;
616: #endif
617: 	}
618: 	// log query path is set: log the query
619: 	log_query_writer->WriteData((const_data_ptr_t)query.c_str(), query.size());
620: 	log_query_writer->WriteData((const_data_ptr_t) "\n", 1);
621: 	log_query_writer->Flush();
622: 	log_query_writer->Sync();
623: }
624: 
625: unique_ptr<QueryResult> ClientContext::Query(unique_ptr<SQLStatement> statement, bool allow_stream_result) {
626: 	auto pending_query = PendingQuery(move(statement));
627: 	return pending_query->Execute(allow_stream_result);
628: }
629: 
630: unique_ptr<QueryResult> ClientContext::Query(const string &query, bool allow_stream_result) {
631: 	auto lock = LockContext();
632: 
633: 	string error;
634: 	vector<unique_ptr<SQLStatement>> statements;
635: 	if (!ParseStatements(*lock, query, statements, error)) {
636: 		return make_unique<MaterializedQueryResult>(move(error));
637: 	}
638: 	if (statements.empty()) {
639: 		// no statements, return empty successful result
640: 		return make_unique<MaterializedQueryResult>(StatementType::INVALID_STATEMENT);
641: 	}
642: 
643: 	unique_ptr<QueryResult> result;
644: 	QueryResult *last_result = nullptr;
645: 	for (idx_t i = 0; i < statements.size(); i++) {
646: 		auto &statement = statements[i];
647: 		bool is_last_statement = i + 1 == statements.size();
648: 		bool stream_result = allow_stream_result && is_last_statement;
649: 		auto pending_query = PendingQueryInternal(*lock, move(statement));
650: 		unique_ptr<QueryResult> current_result;
651: 		if (!pending_query->success) {
652: 			current_result = make_unique<MaterializedQueryResult>(pending_query->error);
653: 		} else {
654: 			current_result = ExecutePendingQueryInternal(*lock, *pending_query, stream_result);
655: 		}
656: 		// now append the result to the list of results
657: 		if (!last_result) {
658: 			// first result of the query
659: 			result = move(current_result);
660: 			last_result = result.get();
661: 		} else {
662: 			// later results; attach to the result chain
663: 			last_result->next = move(current_result);
664: 			last_result = last_result->next.get();
665: 		}
666: 	}
667: 	return result;
668: }
669: 
670: bool ClientContext::ParseStatements(ClientContextLock &lock, const string &query,
671:                                     vector<unique_ptr<SQLStatement>> &result, string &error) {
672: 	try {
673: 		InitialCleanup(lock);
674: 		// parse the query and transform it into a set of statements
675: 		result = ParseStatementsInternal(lock, query);
676: 		return true;
677: 	} catch (std::exception &ex) {
678: 		error = ex.what();
679: 		return false;
680: 	}
681: }
682: 
683: unique_ptr<PendingQueryResult> ClientContext::PendingQuery(const string &query) {
684: 	auto lock = LockContext();
685: 
686: 	string error;
687: 	vector<unique_ptr<SQLStatement>> statements;
688: 	if (!ParseStatements(*lock, query, statements, error)) {
689: 		return make_unique<PendingQueryResult>(move(error));
690: 	}
691: 	if (statements.size() != 1) {
692: 		return make_unique<PendingQueryResult>("PendingQuery can only take a single statement");
693: 	}
694: 	return PendingQueryInternal(*lock, move(statements[0]));
695: }
696: 
697: unique_ptr<PendingQueryResult> ClientContext::PendingQuery(unique_ptr<SQLStatement> statement) {
698: 	auto lock = LockContext();
699: 	return PendingQueryInternal(*lock, move(statement));
700: }
701: 
702: unique_ptr<PendingQueryResult> ClientContext::PendingQueryInternal(ClientContextLock &lock,
703:                                                                    unique_ptr<SQLStatement> statement, bool verify) {
704: 	auto query = statement->query;
705: 	shared_ptr<PreparedStatementData> prepared;
706: 	if (verify) {
707: 		return PendingStatementOrPreparedStatementInternal(lock, query, move(statement), prepared, nullptr);
708: 	} else {
709: 		return PendingStatementOrPreparedStatement(lock, query, move(statement), prepared, nullptr);
710: 	}
711: }
712: 
713: unique_ptr<QueryResult> ClientContext::ExecutePendingQueryInternal(ClientContextLock &lock, PendingQueryResult &query,
714:                                                                    bool allow_stream_result) {
715: 	return query.ExecuteInternal(lock, allow_stream_result);
716: }
717: 
718: void ClientContext::Interrupt() {
719: 	interrupted = true;
720: }
721: 
722: void ClientContext::EnableProfiling() {
723: 	auto lock = LockContext();
724: 	auto &config = ClientConfig::GetConfig(*this);
725: 	config.enable_profiler = true;
726: }
727: 
728: void ClientContext::DisableProfiling() {
729: 	auto lock = LockContext();
730: 	auto &config = ClientConfig::GetConfig(*this);
731: 	config.enable_profiler = false;
732: }
733: 
734: struct VerifyStatement {
735: 	VerifyStatement(unique_ptr<SelectStatement> statement_p, string statement_name_p, bool require_equality = true)
736: 	    : statement(move(statement_p)), statement_name(move(statement_name_p)), require_equality(require_equality),
737: 	      select_list(statement->node->GetSelectList()) {
738: 	}
739: 
740: 	unique_ptr<SelectStatement> statement;
741: 	string statement_name;
742: 	bool require_equality;
743: 	const vector<unique_ptr<ParsedExpression>> &select_list;
744: };
745: 
746: string ClientContext::VerifyQuery(ClientContextLock &lock, const string &query, unique_ptr<SQLStatement> statement) {
747: 	D_ASSERT(statement->type == StatementType::SELECT_STATEMENT);
748: 	// aggressive query verification
749: 
750: 	// the purpose of this function is to test correctness of otherwise hard to test features:
751: 	// Copy() of statements and expressions
752: 	// Serialize()/Deserialize() of expressions
753: 	// Hash() of expressions
754: 	// Equality() of statements and expressions
755: 	// ToString() of statements and expressions
756: 	// Correctness of plans both with and without optimizers
757: 
758: 	vector<VerifyStatement> verify_statements;
759: 
760: 	// copy the statement
761: 	auto select_stmt = (SelectStatement *)statement.get();
762: 	auto copied_stmt = unique_ptr_cast<SQLStatement, SelectStatement>(select_stmt->Copy());
763: 	auto unoptimized_stmt = unique_ptr_cast<SQLStatement, SelectStatement>(select_stmt->Copy());
764: 
765: 	BufferedSerializer serializer;
766: 	select_stmt->Serialize(serializer);
767: 	BufferedDeserializer source(serializer);
768: 	auto deserialized_stmt = SelectStatement::Deserialize(source);
769: 
770: 	Parser parser;
771: 	parser.ParseQuery(select_stmt->ToString());
772: 	D_ASSERT(parser.statements.size() == 1);
773: 	D_ASSERT(parser.statements[0]->type == StatementType::SELECT_STATEMENT);
774: 	auto parsed_statement = move(parser.statements[0]);
775: 
776: 	verify_statements.emplace_back(unique_ptr_cast<SQLStatement, SelectStatement>(move(statement)),
777: 	                               "Original statement");
778: 	verify_statements.emplace_back(move(copied_stmt), "Copied statement");
779: 	verify_statements.emplace_back(move(deserialized_stmt), "Deserialized statement");
780: 	verify_statements.emplace_back(unique_ptr_cast<SQLStatement, SelectStatement>(move(parsed_statement)),
781: 	                               "Parsed statement", false);
782: 
783: 	// all the statements should be equal
784: 	for (idx_t i = 1; i < verify_statements.size(); i++) {
785: 		if (!verify_statements[i].require_equality) {
786: 			continue;
787: 		}
788: 		D_ASSERT(verify_statements[i].statement->Equals(verify_statements[0].statement.get()));
789: 	}
790: 
791: 	// now perform checking on the expressions
792: #ifdef DEBUG
793: 	for (idx_t i = 1; i < verify_statements.size(); i++) {
794: 		D_ASSERT(verify_statements[i].select_list.size() == verify_statements[0].select_list.size());
795: 	}
796: 	auto expr_count = verify_statements[0].select_list.size();
797: 	auto &orig_expr_list = verify_statements[0].select_list;
798: 	for (idx_t i = 0; i < expr_count; i++) {
799: 		// run the ToString, to verify that it doesn't crash
800: 		auto str = orig_expr_list[i]->ToString();
801: 		for (idx_t v_idx = 0; v_idx < verify_statements.size(); v_idx++) {
802: 			if (!verify_statements[v_idx].require_equality && orig_expr_list[i]->HasSubquery()) {
803: 				continue;
804: 			}
805: 			// check that the expressions are equivalent
806: 			D_ASSERT(orig_expr_list[i]->Equals(verify_statements[v_idx].select_list[i].get()));
807: 			// check that the hashes are equivalent too
808: 			D_ASSERT(orig_expr_list[i]->Hash() == verify_statements[v_idx].select_list[i]->Hash());
809: 
810: 			verify_statements[v_idx].select_list[i]->Verify();
811: 		}
812: 		D_ASSERT(!orig_expr_list[i]->Equals(nullptr));
813: 
814: 		if (orig_expr_list[i]->HasSubquery()) {
815: 			continue;
816: 		}
817: 		// ToString round trip
818: 		auto parsed_list = Parser::ParseExpressionList(str);
819: 		D_ASSERT(parsed_list.size() == 1);
820: 		D_ASSERT(parsed_list[0]->Equals(orig_expr_list[i].get()));
821: 	}
822: 	// perform additional checking within the expressions
823: 	for (idx_t outer_idx = 0; outer_idx < orig_expr_list.size(); outer_idx++) {
824: 		auto hash = orig_expr_list[outer_idx]->Hash();
825: 		for (idx_t inner_idx = 0; inner_idx < orig_expr_list.size(); inner_idx++) {
826: 			auto hash2 = orig_expr_list[inner_idx]->Hash();
827: 			if (hash != hash2) {
828: 				// if the hashes are not equivalent, the expressions should not be equivalent
829: 				D_ASSERT(!orig_expr_list[outer_idx]->Equals(orig_expr_list[inner_idx].get()));
830: 			}
831: 		}
832: 	}
833: #endif
834: 
835: 	// disable profiling if it is enabled
836: 	auto &config = ClientConfig::GetConfig(*this);
837: 	bool profiling_is_enabled = config.enable_profiler;
838: 	if (profiling_is_enabled) {
839: 		config.enable_profiler = false;
840: 	}
841: 
842: 	// see below
843: 	auto statement_copy_for_explain = select_stmt->Copy();
844: 
845: 	// execute the original statement
846: 	vector<unique_ptr<MaterializedQueryResult>> results;
847: 	for (idx_t i = 0; i < verify_statements.size(); i++) {
848: 		interrupted = false;
849: 		try {
850: 			auto result = RunStatementInternal(lock, query, move(verify_statements[i].statement), false, false);
851: 			results.push_back(unique_ptr_cast<QueryResult, MaterializedQueryResult>(move(result)));
852: 		} catch (std::exception &ex) {
853: 			results.push_back(make_unique<MaterializedQueryResult>(ex.what()));
854: 		}
855: 	}
856: 
857: 	// check explain, only if q does not already contain EXPLAIN
858: 	if (results[0]->success) {
859: 		auto explain_q = "EXPLAIN " + query;
860: 		auto explain_stmt = make_unique<ExplainStatement>(move(statement_copy_for_explain));
861: 		try {
862: 			RunStatementInternal(lock, explain_q, move(explain_stmt), false, false);
863: 		} catch (std::exception &ex) { // LCOV_EXCL_START
864: 			return "EXPLAIN failed but query did not (" + string(ex.what()) + ")";
865: 		} // LCOV_EXCL_STOP
866: 	}
867: 
868: 	config.enable_optimizer = true;
869: 
870: 	if (profiling_is_enabled) {
871: 		config.enable_profiler = true;
872: 	}
873: 
874: 	// now compare the results
875: 	// the results of all runs should be identical
876: 	for (idx_t i = 1; i < results.size(); i++) {
877: 		auto name = verify_statements[i].statement_name;
878: 		if (results[0]->success != results[i]->success) { // LCOV_EXCL_START
879: 			string result = name + " differs from original result!\n";
880: 			result += "Original Result:\n" + results[0]->ToString();
881: 			result += name + ":\n" + results[i]->ToString();
882: 			return result;
883: 		}                                                             // LCOV_EXCL_STOP
884: 		if (!results[0]->collection.Equals(results[i]->collection)) { // LCOV_EXCL_START
885: 			string result = name + " differs from original result!\n";
886: 			result += "Original Result:\n" + results[0]->ToString();
887: 			result += name + ":\n" + results[i]->ToString();
888: 			return result;
889: 		} // LCOV_EXCL_STOP
890: 	}
891: 
892: 	return "";
893: }
894: 
895: bool ClientContext::UpdateFunctionInfoFromEntry(ScalarFunctionCatalogEntry *existing_function,
896:                                                 CreateScalarFunctionInfo *new_info) {
897: 	if (new_info->functions.empty()) {
898: 		throw InternalException("Registering function without scalar function definitions!");
899: 	}
900: 	bool need_rewrite_entry = false;
901: 	idx_t size_new_func = new_info->functions.size();
902: 	for (idx_t exist_idx = 0; exist_idx < existing_function->functions.size(); ++exist_idx) {
903: 		bool can_add = true;
904: 		for (idx_t new_idx = 0; new_idx < size_new_func; ++new_idx) {
905: 			if (new_info->functions[new_idx].Equal(existing_function->functions[exist_idx])) {
906: 				can_add = false;
907: 				break;
908: 			}
909: 		}
910: 		if (can_add) {
911: 			new_info->functions.push_back(existing_function->functions[exist_idx]);
912: 			need_rewrite_entry = true;
913: 		}
914: 	}
915: 	return need_rewrite_entry;
916: }
917: 
918: void ClientContext::RegisterFunction(CreateFunctionInfo *info) {
919: 	RunFunctionInTransaction([&]() {
920: 		auto &catalog = Catalog::GetCatalog(*this);
921: 		auto existing_function = (ScalarFunctionCatalogEntry *)catalog.GetEntry(
922: 		    *this, CatalogType::SCALAR_FUNCTION_ENTRY, info->schema, info->name, true);
923: 		if (existing_function) {
924: 			if (UpdateFunctionInfoFromEntry(existing_function, (CreateScalarFunctionInfo *)info)) {
925: 				// function info was updated from catalog entry, rewrite is needed
926: 				info->on_conflict = OnCreateConflict::REPLACE_ON_CONFLICT;
927: 			}
928: 		}
929: 		// create function
930: 		catalog.CreateFunction(*this, info);
931: 	});
932: }
933: 
934: void ClientContext::RunFunctionInTransactionInternal(ClientContextLock &lock, const std::function<void(void)> &fun,
935:                                                      bool requires_valid_transaction) {
936: 	if (requires_valid_transaction && transaction.HasActiveTransaction() &&
937: 	    transaction.ActiveTransaction().IsInvalidated()) {
938: 		throw Exception("Failed: transaction has been invalidated!");
939: 	}
940: 	// check if we are on AutoCommit. In this case we should start a transaction
941: 	bool require_new_transaction = transaction.IsAutoCommit() && !transaction.HasActiveTransaction();
942: 	if (require_new_transaction) {
943: 		D_ASSERT(!active_query);
944: 		transaction.BeginTransaction();
945: 	}
946: 	try {
947: 		fun();
948: 	} catch (StandardException &ex) {
949: 		if (require_new_transaction) {
950: 			transaction.Rollback();
951: 		}
952: 		throw;
953: 	} catch (std::exception &ex) {
954: 		if (require_new_transaction) {
955: 			transaction.Rollback();
956: 		} else {
957: 			ActiveTransaction().Invalidate();
958: 		}
959: 		throw;
960: 	}
961: 	if (require_new_transaction) {
962: 		transaction.Commit();
963: 	}
964: }
965: 
966: void ClientContext::RunFunctionInTransaction(const std::function<void(void)> &fun, bool requires_valid_transaction) {
967: 	auto lock = LockContext();
968: 	RunFunctionInTransactionInternal(*lock, fun, requires_valid_transaction);
969: }
970: 
971: unique_ptr<TableDescription> ClientContext::TableInfo(const string &schema_name, const string &table_name) {
972: 	unique_ptr<TableDescription> result;
973: 	RunFunctionInTransaction([&]() {
974: 		// obtain the table info
975: 		auto &catalog = Catalog::GetCatalog(*this);
976: 		auto table = catalog.GetEntry<TableCatalogEntry>(*this, schema_name, table_name, true);
977: 		if (!table) {
978: 			return;
979: 		}
980: 		// write the table info to the result
981: 		result = make_unique<TableDescription>();
982: 		result->schema = schema_name;
983: 		result->table = table_name;
984: 		for (auto &column : table->columns) {
985: 			result->columns.emplace_back(column.name, column.type);
986: 		}
987: 	});
988: 	return result;
989: }
990: 
991: void ClientContext::Append(TableDescription &description, ChunkCollection &collection) {
992: 	RunFunctionInTransaction([&]() {
993: 		auto &catalog = Catalog::GetCatalog(*this);
994: 		auto table_entry = catalog.GetEntry<TableCatalogEntry>(*this, description.schema, description.table);
995: 		// verify that the table columns and types match up
996: 		if (description.columns.size() != table_entry->columns.size()) {
997: 			throw Exception("Failed to append: table entry has different number of columns!");
998: 		}
999: 		for (idx_t i = 0; i < description.columns.size(); i++) {
1000: 			if (description.columns[i].type != table_entry->columns[i].type) {
1001: 				throw Exception("Failed to append: table entry has different number of columns!");
1002: 			}
1003: 		}
1004: 		for (auto &chunk : collection.Chunks()) {
1005: 			table_entry->storage->Append(*table_entry, *this, *chunk);
1006: 		}
1007: 	});
1008: }
1009: 
1010: void ClientContext::TryBindRelation(Relation &relation, vector<ColumnDefinition> &result_columns) {
1011: #ifdef DEBUG
1012: 	D_ASSERT(!relation.GetAlias().empty());
1013: 	D_ASSERT(!relation.ToString().empty());
1014: #endif
1015: 	RunFunctionInTransaction([&]() {
1016: 		// bind the expressions
1017: 		auto binder = Binder::CreateBinder(*this);
1018: 		auto result = relation.Bind(*binder);
1019: 		D_ASSERT(result.names.size() == result.types.size());
1020: 		for (idx_t i = 0; i < result.names.size(); i++) {
1021: 			result_columns.emplace_back(result.names[i], result.types[i]);
1022: 		}
1023: 	});
1024: }
1025: 
1026: unordered_set<string> ClientContext::GetTableNames(const string &query) {
1027: 	auto lock = LockContext();
1028: 
1029: 	auto statements = ParseStatementsInternal(*lock, query);
1030: 	if (statements.size() != 1) {
1031: 		throw InvalidInputException("Expected a single statement");
1032: 	}
1033: 
1034: 	unordered_set<string> result;
1035: 	RunFunctionInTransactionInternal(*lock, [&]() {
1036: 		// bind the expressions
1037: 		auto binder = Binder::CreateBinder(*this);
1038: 		binder->SetBindingMode(BindingMode::EXTRACT_NAMES);
1039: 		binder->Bind(*statements[0]);
1040: 		result = binder->GetTableNames();
1041: 	});
1042: 	return result;
1043: }
1044: 
1045: unique_ptr<QueryResult> ClientContext::Execute(const shared_ptr<Relation> &relation) {
1046: 	auto lock = LockContext();
1047: 	InitialCleanup(*lock);
1048: 
1049: 	string query;
1050: 	if (config.query_verification_enabled) {
1051: 		// run the ToString method of any relation we run, mostly to ensure it doesn't crash
1052: 		relation->ToString();
1053: 		relation->GetAlias();
1054: 		if (relation->IsReadOnly()) {
1055: 			// verify read only statements by running a select statement
1056: 			auto select = make_unique<SelectStatement>();
1057: 			select->node = relation->GetQueryNode();
1058: 			RunStatementInternal(*lock, query, move(select), false);
1059: 		}
1060: 	}
1061: 	auto &expected_columns = relation->Columns();
1062: 	auto relation_stmt = make_unique<RelationStatement>(relation);
1063: 
1064: 	unique_ptr<QueryResult> result;
1065: 	result = RunStatementInternal(*lock, query, move(relation_stmt), false);
1066: 	if (!result->success) {
1067: 		return result;
1068: 	}
1069: 	// verify that the result types and result names of the query match the expected result types/names
1070: 	if (result->types.size() == expected_columns.size()) {
1071: 		bool mismatch = false;
1072: 		for (idx_t i = 0; i < result->types.size(); i++) {
1073: 			if (result->types[i] != expected_columns[i].type || result->names[i] != expected_columns[i].name) {
1074: 				mismatch = true;
1075: 				break;
1076: 			}
1077: 		}
1078: 		if (!mismatch) {
1079: 			// all is as expected: return the result
1080: 			return result;
1081: 		}
1082: 	}
1083: 	// result mismatch
1084: 	string err_str = "Result mismatch in query!\nExpected the following columns: [";
1085: 	for (idx_t i = 0; i < expected_columns.size(); i++) {
1086: 		if (i > 0) {
1087: 			err_str += ", ";
1088: 		}
1089: 		err_str += expected_columns[i].name + " " + expected_columns[i].type.ToString();
1090: 	}
1091: 	err_str += "]\nBut result contained the following: ";
1092: 	for (idx_t i = 0; i < result->types.size(); i++) {
1093: 		err_str += i == 0 ? "[" : ", ";
1094: 		err_str += result->names[i] + " " + result->types[i].ToString();
1095: 	}
1096: 	err_str += "]";
1097: 	return make_unique<MaterializedQueryResult>(err_str);
1098: }
1099: 
1100: bool ClientContext::TryGetCurrentSetting(const std::string &key, Value &result) {
1101: 	// first check the built-in settings
1102: 	auto &db_config = DBConfig::GetConfig(*this);
1103: 	auto option = db_config.GetOptionByName(key);
1104: 	if (option) {
1105: 		result = option->get_setting(*this);
1106: 		return true;
1107: 	}
1108: 
1109: 	// then check the session values
1110: 	const auto &session_config_map = config.set_variables;
1111: 	const auto &global_config_map = db_config.set_variables;
1112: 
1113: 	auto session_value = session_config_map.find(key);
1114: 	bool found_session_value = session_value != session_config_map.end();
1115: 	auto global_value = global_config_map.find(key);
1116: 	bool found_global_value = global_value != global_config_map.end();
1117: 	if (!found_session_value && !found_global_value) {
1118: 		return false;
1119: 	}
1120: 
1121: 	result = found_session_value ? session_value->second : global_value->second;
1122: 	return true;
1123: }
1124: 
1125: ParserOptions ClientContext::GetParserOptions() {
1126: 	ParserOptions options;
1127: 	options.preserve_identifier_case = ClientConfig::GetConfig(*this).preserve_identifier_case;
1128: 	return options;
1129: }
1130: 
1131: } // namespace duckdb
[end of src/main/client_context.cpp]
[start of src/main/prepared_statement_data.cpp]
1: #include "duckdb/main/prepared_statement_data.hpp"
2: #include "duckdb/execution/physical_operator.hpp"
3: #include "duckdb/parser/sql_statement.hpp"
4: 
5: namespace duckdb {
6: 
7: PreparedStatementData::PreparedStatementData(StatementType type)
8:     : statement_type(type), read_only(true), requires_valid_transaction(true), allow_stream_result(false) {
9: }
10: 
11: PreparedStatementData::~PreparedStatementData() {
12: }
13: 
14: void PreparedStatementData::Bind(vector<Value> values) {
15: 	// set parameters
16: 	const auto required = unbound_statement ? unbound_statement->n_param : 0;
17: 	if (values.size() != required) {
18: 		throw BinderException("Parameter/argument count mismatch for prepared statement. Expected %llu, got %llu",
19: 		                      required, values.size());
20: 	}
21: 
22: 	// bind the required values
23: 	for (auto &it : value_map) {
24: 		const idx_t i = it.first - 1;
25: 		if (i >= values.size()) {
26: 			throw BinderException("Could not find parameter with index %llu", i + 1);
27: 		}
28: 		D_ASSERT(!it.second.empty());
29: 		if (!values[i].TryCastAs(it.second[0]->type())) {
30: 			throw BinderException(
31: 			    "Type mismatch for binding parameter with index %llu, expected type %s but got type %s", i + 1,
32: 			    it.second[0]->type().ToString().c_str(), values[i].type().ToString().c_str());
33: 		}
34: 		for (auto &target : it.second) {
35: 			*target = values[i];
36: 		}
37: 	}
38: }
39: 
40: LogicalType PreparedStatementData::GetType(idx_t param_idx) {
41: 	auto it = value_map.find(param_idx);
42: 	if (it == value_map.end()) {
43: 		throw BinderException("Could not find parameter with index %llu", param_idx);
44: 	}
45: 	D_ASSERT(!it->second.empty());
46: 	return it->second[0]->type();
47: }
48: 
49: } // namespace duckdb
[end of src/main/prepared_statement_data.cpp]
[start of src/planner/binder.cpp]
1: #include "duckdb/planner/binder.hpp"
2: 
3: #include "duckdb/parser/statement/list.hpp"
4: #include "duckdb/parser/query_node/select_node.hpp"
5: #include "duckdb/planner/bound_query_node.hpp"
6: #include "duckdb/planner/bound_tableref.hpp"
7: #include "duckdb/planner/expression.hpp"
8: #include "duckdb/planner/operator/logical_sample.hpp"
9: #include "duckdb/planner/operator/logical_projection.hpp"
10: #include "duckdb/catalog/catalog_entry/table_catalog_entry.hpp"
11: #include "duckdb/catalog/catalog_entry/view_catalog_entry.hpp"
12: #include "duckdb/planner/expression_binder/returning_binder.hpp"
13: 
14: #include <algorithm>
15: 
16: #include "duckdb/parser/tableref/table_function_ref.hpp"
17: 
18: namespace duckdb {
19: 
20: shared_ptr<Binder> Binder::CreateBinder(ClientContext &context, Binder *parent, bool inherit_ctes) {
21: 	return make_shared<Binder>(true, context, parent ? parent->shared_from_this() : nullptr, inherit_ctes);
22: }
23: 
24: Binder::Binder(bool, ClientContext &context, shared_ptr<Binder> parent_p, bool inherit_ctes_p)
25:     : context(context), read_only(true), requires_valid_transaction(true), allow_stream_result(false),
26:       parent(move(parent_p)), bound_tables(0), inherit_ctes(inherit_ctes_p) {
27: 	parameters = nullptr;
28: 	if (parent) {
29: 		// We have to inherit macro parameter bindings from the parent binder, if there is a parent.
30: 		macro_binding = parent->macro_binding;
31: 		if (inherit_ctes) {
32: 			// We have to inherit CTE bindings from the parent bind_context, if there is a parent.
33: 			bind_context.SetCTEBindings(parent->bind_context.GetCTEBindings());
34: 			bind_context.cte_references = parent->bind_context.cte_references;
35: 			parameters = parent->parameters;
36: 		}
37: 	}
38: }
39: 
40: BoundStatement Binder::Bind(SQLStatement &statement) {
41: 	root_statement = &statement;
42: 	switch (statement.type) {
43: 	case StatementType::SELECT_STATEMENT:
44: 		return Bind((SelectStatement &)statement);
45: 	case StatementType::INSERT_STATEMENT:
46: 		return Bind((InsertStatement &)statement);
47: 	case StatementType::COPY_STATEMENT:
48: 		return Bind((CopyStatement &)statement);
49: 	case StatementType::DELETE_STATEMENT:
50: 		return Bind((DeleteStatement &)statement);
51: 	case StatementType::UPDATE_STATEMENT:
52: 		return Bind((UpdateStatement &)statement);
53: 	case StatementType::RELATION_STATEMENT:
54: 		return Bind((RelationStatement &)statement);
55: 	case StatementType::CREATE_STATEMENT:
56: 		return Bind((CreateStatement &)statement);
57: 	case StatementType::DROP_STATEMENT:
58: 		return Bind((DropStatement &)statement);
59: 	case StatementType::ALTER_STATEMENT:
60: 		return Bind((AlterStatement &)statement);
61: 	case StatementType::TRANSACTION_STATEMENT:
62: 		return Bind((TransactionStatement &)statement);
63: 	case StatementType::PRAGMA_STATEMENT:
64: 		return Bind((PragmaStatement &)statement);
65: 	case StatementType::EXPLAIN_STATEMENT:
66: 		return Bind((ExplainStatement &)statement);
67: 	case StatementType::VACUUM_STATEMENT:
68: 		return Bind((VacuumStatement &)statement);
69: 	case StatementType::SHOW_STATEMENT:
70: 		return Bind((ShowStatement &)statement);
71: 	case StatementType::CALL_STATEMENT:
72: 		return Bind((CallStatement &)statement);
73: 	case StatementType::EXPORT_STATEMENT:
74: 		return Bind((ExportStatement &)statement);
75: 	case StatementType::SET_STATEMENT:
76: 		return Bind((SetStatement &)statement);
77: 	case StatementType::LOAD_STATEMENT:
78: 		return Bind((LoadStatement &)statement);
79: 	default: // LCOV_EXCL_START
80: 		throw NotImplementedException("Unimplemented statement type \"%s\" for Bind",
81: 		                              StatementTypeToString(statement.type));
82: 	} // LCOV_EXCL_STOP
83: }
84: 
85: unique_ptr<BoundQueryNode> Binder::BindNode(QueryNode &node) {
86: 	// first we visit the set of CTEs and add them to the bind context
87: 	for (auto &cte_it : node.cte_map) {
88: 		AddCTE(cte_it.first, cte_it.second.get());
89: 	}
90: 	// now we bind the node
91: 	unique_ptr<BoundQueryNode> result;
92: 	switch (node.type) {
93: 	case QueryNodeType::SELECT_NODE:
94: 		result = BindNode((SelectNode &)node);
95: 		break;
96: 	case QueryNodeType::RECURSIVE_CTE_NODE:
97: 		result = BindNode((RecursiveCTENode &)node);
98: 		break;
99: 	default:
100: 		D_ASSERT(node.type == QueryNodeType::SET_OPERATION_NODE);
101: 		result = BindNode((SetOperationNode &)node);
102: 		break;
103: 	}
104: 	return result;
105: }
106: 
107: BoundStatement Binder::Bind(QueryNode &node) {
108: 	auto bound_node = BindNode(node);
109: 
110: 	BoundStatement result;
111: 	result.names = bound_node->names;
112: 	result.types = bound_node->types;
113: 
114: 	// and plan it
115: 	result.plan = CreatePlan(*bound_node);
116: 	return result;
117: }
118: 
119: unique_ptr<LogicalOperator> Binder::CreatePlan(BoundQueryNode &node) {
120: 	switch (node.type) {
121: 	case QueryNodeType::SELECT_NODE:
122: 		return CreatePlan((BoundSelectNode &)node);
123: 	case QueryNodeType::SET_OPERATION_NODE:
124: 		return CreatePlan((BoundSetOperationNode &)node);
125: 	case QueryNodeType::RECURSIVE_CTE_NODE:
126: 		return CreatePlan((BoundRecursiveCTENode &)node);
127: 	default:
128: 		throw InternalException("Unsupported bound query node type");
129: 	}
130: }
131: 
132: unique_ptr<BoundTableRef> Binder::Bind(TableRef &ref) {
133: 	unique_ptr<BoundTableRef> result;
134: 	switch (ref.type) {
135: 	case TableReferenceType::BASE_TABLE:
136: 		result = Bind((BaseTableRef &)ref);
137: 		break;
138: 	case TableReferenceType::CROSS_PRODUCT:
139: 		result = Bind((CrossProductRef &)ref);
140: 		break;
141: 	case TableReferenceType::JOIN:
142: 		result = Bind((JoinRef &)ref);
143: 		break;
144: 	case TableReferenceType::SUBQUERY:
145: 		result = Bind((SubqueryRef &)ref);
146: 		break;
147: 	case TableReferenceType::EMPTY:
148: 		result = Bind((EmptyTableRef &)ref);
149: 		break;
150: 	case TableReferenceType::TABLE_FUNCTION:
151: 		result = Bind((TableFunctionRef &)ref);
152: 		break;
153: 	case TableReferenceType::EXPRESSION_LIST:
154: 		result = Bind((ExpressionListRef &)ref);
155: 		break;
156: 	default:
157: 		throw InternalException("Unknown table ref type");
158: 	}
159: 	result->sample = move(ref.sample);
160: 	return result;
161: }
162: 
163: unique_ptr<LogicalOperator> Binder::CreatePlan(BoundTableRef &ref) {
164: 	unique_ptr<LogicalOperator> root;
165: 	switch (ref.type) {
166: 	case TableReferenceType::BASE_TABLE:
167: 		root = CreatePlan((BoundBaseTableRef &)ref);
168: 		break;
169: 	case TableReferenceType::SUBQUERY:
170: 		root = CreatePlan((BoundSubqueryRef &)ref);
171: 		break;
172: 	case TableReferenceType::JOIN:
173: 		root = CreatePlan((BoundJoinRef &)ref);
174: 		break;
175: 	case TableReferenceType::CROSS_PRODUCT:
176: 		root = CreatePlan((BoundCrossProductRef &)ref);
177: 		break;
178: 	case TableReferenceType::TABLE_FUNCTION:
179: 		root = CreatePlan((BoundTableFunction &)ref);
180: 		break;
181: 	case TableReferenceType::EMPTY:
182: 		root = CreatePlan((BoundEmptyTableRef &)ref);
183: 		break;
184: 	case TableReferenceType::EXPRESSION_LIST:
185: 		root = CreatePlan((BoundExpressionListRef &)ref);
186: 		break;
187: 	case TableReferenceType::CTE:
188: 		root = CreatePlan((BoundCTERef &)ref);
189: 		break;
190: 	default:
191: 		throw InternalException("Unsupported bound table ref type type");
192: 	}
193: 	// plan the sample clause
194: 	if (ref.sample) {
195: 		root = make_unique<LogicalSample>(move(ref.sample), move(root));
196: 	}
197: 	return root;
198: }
199: 
200: void Binder::AddCTE(const string &name, CommonTableExpressionInfo *info) {
201: 	D_ASSERT(info);
202: 	D_ASSERT(!name.empty());
203: 	auto entry = CTE_bindings.find(name);
204: 	if (entry != CTE_bindings.end()) {
205: 		throw InternalException("Duplicate CTE \"%s\" in query!", name);
206: 	}
207: 	CTE_bindings[name] = info;
208: }
209: 
210: CommonTableExpressionInfo *Binder::FindCTE(const string &name, bool skip) {
211: 	auto entry = CTE_bindings.find(name);
212: 	if (entry != CTE_bindings.end()) {
213: 		if (!skip || entry->second->query->node->type == QueryNodeType::RECURSIVE_CTE_NODE) {
214: 			return entry->second;
215: 		}
216: 	}
217: 	if (parent && inherit_ctes) {
218: 		return parent->FindCTE(name, name == alias);
219: 	}
220: 	return nullptr;
221: }
222: 
223: bool Binder::CTEIsAlreadyBound(CommonTableExpressionInfo *cte) {
224: 	if (bound_ctes.find(cte) != bound_ctes.end()) {
225: 		return true;
226: 	}
227: 	if (parent && inherit_ctes) {
228: 		return parent->CTEIsAlreadyBound(cte);
229: 	}
230: 	return false;
231: }
232: 
233: void Binder::AddBoundView(ViewCatalogEntry *view) {
234: 	// check if the view is already bound
235: 	auto current = this;
236: 	while (current) {
237: 		if (current->bound_views.find(view) != current->bound_views.end()) {
238: 			throw BinderException("infinite recursion detected: attempting to recursively bind view \"%s\"",
239: 			                      view->name);
240: 		}
241: 		current = current->parent.get();
242: 	}
243: 	bound_views.insert(view);
244: }
245: 
246: idx_t Binder::GenerateTableIndex() {
247: 	if (parent) {
248: 		return parent->GenerateTableIndex();
249: 	}
250: 	return bound_tables++;
251: }
252: 
253: void Binder::PushExpressionBinder(ExpressionBinder *binder) {
254: 	GetActiveBinders().push_back(binder);
255: }
256: 
257: void Binder::PopExpressionBinder() {
258: 	D_ASSERT(HasActiveBinder());
259: 	GetActiveBinders().pop_back();
260: }
261: 
262: void Binder::SetActiveBinder(ExpressionBinder *binder) {
263: 	D_ASSERT(HasActiveBinder());
264: 	GetActiveBinders().back() = binder;
265: }
266: 
267: ExpressionBinder *Binder::GetActiveBinder() {
268: 	return GetActiveBinders().back();
269: }
270: 
271: bool Binder::HasActiveBinder() {
272: 	return !GetActiveBinders().empty();
273: }
274: 
275: vector<ExpressionBinder *> &Binder::GetActiveBinders() {
276: 	if (parent) {
277: 		return parent->GetActiveBinders();
278: 	}
279: 	return active_binders;
280: }
281: 
282: void Binder::AddUsingBindingSet(unique_ptr<UsingColumnSet> set) {
283: 	if (parent) {
284: 		parent->AddUsingBindingSet(move(set));
285: 		return;
286: 	}
287: 	bind_context.AddUsingBindingSet(move(set));
288: }
289: 
290: void Binder::MoveCorrelatedExpressions(Binder &other) {
291: 	MergeCorrelatedColumns(other.correlated_columns);
292: 	other.correlated_columns.clear();
293: }
294: 
295: void Binder::MergeCorrelatedColumns(vector<CorrelatedColumnInfo> &other) {
296: 	for (idx_t i = 0; i < other.size(); i++) {
297: 		AddCorrelatedColumn(other[i]);
298: 	}
299: }
300: 
301: void Binder::AddCorrelatedColumn(const CorrelatedColumnInfo &info) {
302: 	// we only add correlated columns to the list if they are not already there
303: 	if (std::find(correlated_columns.begin(), correlated_columns.end(), info) == correlated_columns.end()) {
304: 		correlated_columns.push_back(info);
305: 	}
306: }
307: 
308: bool Binder::HasMatchingBinding(const string &table_name, const string &column_name, string &error_message) {
309: 	string empty_schema;
310: 	return HasMatchingBinding(empty_schema, table_name, column_name, error_message);
311: }
312: 
313: bool Binder::HasMatchingBinding(const string &schema_name, const string &table_name, const string &column_name,
314:                                 string &error_message) {
315: 	Binding *binding;
316: 	if (macro_binding && table_name == macro_binding->alias) {
317: 		binding = macro_binding;
318: 	} else {
319: 		binding = bind_context.GetBinding(table_name, error_message);
320: 	}
321: 	if (!binding) {
322: 		return false;
323: 	}
324: 	if (!schema_name.empty()) {
325: 		auto table_entry = binding->GetTableEntry();
326: 		if (!table_entry) {
327: 			return false;
328: 		}
329: 		if (table_entry->schema->name != schema_name || table_entry->name != table_name) {
330: 			return false;
331: 		}
332: 	}
333: 	if (!binding->HasMatchingBinding(column_name)) {
334: 		error_message = binding->ColumnNotFoundError(column_name);
335: 		return false;
336: 	}
337: 	return true;
338: }
339: 
340: void Binder::SetBindingMode(BindingMode mode) {
341: 	if (parent) {
342: 		parent->SetBindingMode(mode);
343: 	}
344: 	this->mode = mode;
345: }
346: 
347: BindingMode Binder::GetBindingMode() {
348: 	if (parent) {
349: 		return parent->GetBindingMode();
350: 	}
351: 	return mode;
352: }
353: 
354: void Binder::AddTableName(string table_name) {
355: 	if (parent) {
356: 		parent->AddTableName(move(table_name));
357: 		return;
358: 	}
359: 	table_names.insert(move(table_name));
360: }
361: 
362: const unordered_set<string> &Binder::GetTableNames() {
363: 	if (parent) {
364: 		return parent->GetTableNames();
365: 	}
366: 	return table_names;
367: }
368: 
369: string Binder::FormatError(ParsedExpression &expr_context, const string &message) {
370: 	return FormatError(expr_context.query_location, message);
371: }
372: 
373: string Binder::FormatError(TableRef &ref_context, const string &message) {
374: 	return FormatError(ref_context.query_location, message);
375: }
376: 
377: string Binder::FormatErrorRecursive(idx_t query_location, const string &message, vector<ExceptionFormatValue> &values) {
378: 	QueryErrorContext context(root_statement, query_location);
379: 	return context.FormatErrorRecursive(message, values);
380: }
381: 
382: BoundStatement Binder::BindReturning(vector<unique_ptr<ParsedExpression>> returning_list, TableCatalogEntry *table,
383:                                      idx_t update_table_index, unique_ptr<LogicalOperator> child_operator,
384:                                      BoundStatement result) {
385: 
386: 	vector<LogicalType> types;
387: 	vector<std::string> names;
388: 
389: 	auto binder = Binder::CreateBinder(context);
390: 
391: 	for (auto &col : table->columns) {
392: 		names.push_back(col.name);
393: 		types.push_back(col.type);
394: 	}
395: 
396: 	binder->bind_context.AddGenericBinding(update_table_index, table->name, names, types);
397: 	ReturningBinder returning_binder(*binder, context);
398: 
399: 	vector<unique_ptr<Expression>> projection_expressions;
400: 	LogicalType result_type;
401: 	for (auto &returning_expr : returning_list) {
402: 		auto expr_type = returning_expr->GetExpressionType();
403: 		if (expr_type == ExpressionType::STAR) {
404: 			auto generated_star_list = vector<unique_ptr<ParsedExpression>>();
405: 			binder->bind_context.GenerateAllColumnExpressions((StarExpression &)*returning_expr, generated_star_list);
406: 
407: 			for (auto &star_column : generated_star_list) {
408: 				auto star_expr = returning_binder.Bind(star_column, &result_type);
409: 				result.types.push_back(result_type);
410: 				result.names.push_back(star_expr->GetName());
411: 				projection_expressions.push_back(move(star_expr));
412: 			}
413: 		} else {
414: 			auto expr = returning_binder.Bind(returning_expr, &result_type);
415: 			result.names.push_back(expr->GetName());
416: 			result.types.push_back(result_type);
417: 			projection_expressions.push_back(move(expr));
418: 		}
419: 	}
420: 
421: 	auto projection = make_unique<LogicalProjection>(GenerateTableIndex(), move(projection_expressions));
422: 	projection->AddChild(move(child_operator));
423: 	D_ASSERT(result.types.size() == result.names.size());
424: 	result.plan = move(projection);
425: 	this->allow_stream_result = true;
426: 	return result;
427: }
428: 
429: } // namespace duckdb
[end of src/planner/binder.cpp]
[start of src/planner/binder/expression/bind_aggregate_expression.cpp]
1: #include "duckdb/catalog/catalog_entry/aggregate_function_catalog_entry.hpp"
2: #include "duckdb/common/pair.hpp"
3: #include "duckdb/parser/expression/function_expression.hpp"
4: #include "duckdb/planner/expression/bound_aggregate_expression.hpp"
5: #include "duckdb/planner/expression/bound_columnref_expression.hpp"
6: #include "duckdb/planner/expression/bound_constant_expression.hpp"
7: #include "duckdb/planner/expression_binder/aggregate_binder.hpp"
8: #include "duckdb/planner/expression_binder/select_binder.hpp"
9: #include "duckdb/planner/query_node/bound_select_node.hpp"
10: #include "duckdb/execution/expression_executor.hpp"
11: #include "duckdb/function/scalar/generic_functions.hpp"
12: #include "duckdb/main/config.hpp"
13: 
14: namespace duckdb {
15: 
16: static void InvertPercentileFractions(unique_ptr<ParsedExpression> &fractions) {
17: 	D_ASSERT(fractions.get());
18: 	D_ASSERT(fractions->expression_class == ExpressionClass::BOUND_EXPRESSION);
19: 	auto &bound = (BoundExpression &)*fractions;
20: 
21: 	if (!bound.expr->IsFoldable()) {
22: 		return;
23: 	}
24: 
25: 	Value value = ExpressionExecutor::EvaluateScalar(*bound.expr);
26: 	if (value.type().id() == LogicalTypeId::LIST) {
27: 		vector<Value> values;
28: 		for (const auto &element_val : ListValue::GetChildren(value)) {
29: 			values.push_back(Value::DOUBLE(1 - element_val.GetValue<double>()));
30: 		}
31: 		bound.expr = make_unique<BoundConstantExpression>(Value::LIST(values));
32: 	} else {
33: 		bound.expr = make_unique<BoundConstantExpression>(Value::DOUBLE(1 - value.GetValue<double>()));
34: 	}
35: }
36: 
37: BindResult SelectBinder::BindAggregate(FunctionExpression &aggr, AggregateFunctionCatalogEntry *func, idx_t depth) {
38: 	// first bind the child of the aggregate expression (if any)
39: 	this->bound_aggregate = true;
40: 	unique_ptr<Expression> bound_filter;
41: 	AggregateBinder aggregate_binder(binder, context);
42: 	string error, filter_error;
43: 
44: 	// Now we bind the filter (if any)
45: 	if (aggr.filter) {
46: 		aggregate_binder.BindChild(aggr.filter, 0, error);
47: 	}
48: 
49: 	// Handle ordered-set aggregates by moving the single ORDER BY expression to the front of the children.
50: 	//	https://www.postgresql.org/docs/current/functions-aggregate.html#FUNCTIONS-ORDEREDSET-TABLE
51: 	bool ordered_set_agg = false;
52: 	bool invert_fractions = false;
53: 	if (aggr.order_bys && aggr.order_bys->orders.size() == 1) {
54: 		const auto &func_name = aggr.function_name;
55: 		ordered_set_agg = (func_name == "quantile_cont" || func_name == "quantile_disc" || func_name == "mode");
56: 
57: 		if (ordered_set_agg) {
58: 			auto &config = DBConfig::GetConfig(context);
59: 			const auto &order = aggr.order_bys->orders[0];
60: 			const auto sense = (order.type == OrderType::ORDER_DEFAULT) ? config.default_order_type : order.type;
61: 			invert_fractions = (sense == OrderType::DESCENDING);
62: 		}
63: 	}
64: 
65: 	for (auto &child : aggr.children) {
66: 		aggregate_binder.BindChild(child, 0, error);
67: 		// We have to invert the fractions for PERCENTILE_XXXX DESC
68: 		if (invert_fractions) {
69: 			InvertPercentileFractions(child);
70: 		}
71: 	}
72: 
73: 	// Bind the ORDER BYs, if any
74: 	if (aggr.order_bys && !aggr.order_bys->orders.empty()) {
75: 		for (auto &order : aggr.order_bys->orders) {
76: 			aggregate_binder.BindChild(order.expression, 0, error);
77: 		}
78: 	}
79: 
80: 	if (!error.empty()) {
81: 		// failed to bind child
82: 		if (aggregate_binder.HasBoundColumns()) {
83: 			for (idx_t i = 0; i < aggr.children.size(); i++) {
84: 				// however, we bound columns!
85: 				// that means this aggregation belongs to this node
86: 				// check if we have to resolve any errors by binding with parent binders
87: 				bool success = aggregate_binder.BindCorrelatedColumns(aggr.children[i]);
88: 				// if there is still an error after this, we could not successfully bind the aggregate
89: 				if (!success) {
90: 					throw BinderException(error);
91: 				}
92: 				auto &bound_expr = (BoundExpression &)*aggr.children[i];
93: 				ExtractCorrelatedExpressions(binder, *bound_expr.expr);
94: 			}
95: 			if (aggr.filter) {
96: 				bool success = aggregate_binder.BindCorrelatedColumns(aggr.filter);
97: 				// if there is still an error after this, we could not successfully bind the aggregate
98: 				if (!success) {
99: 					throw BinderException(error);
100: 				}
101: 				auto &bound_expr = (BoundExpression &)*aggr.filter;
102: 				ExtractCorrelatedExpressions(binder, *bound_expr.expr);
103: 			}
104: 			if (aggr.order_bys && !aggr.order_bys->orders.empty()) {
105: 				for (auto &order : aggr.order_bys->orders) {
106: 					bool success = aggregate_binder.BindCorrelatedColumns(order.expression);
107: 					if (!success) {
108: 						throw BinderException(error);
109: 					}
110: 					auto &bound_expr = (BoundExpression &)*order.expression;
111: 					ExtractCorrelatedExpressions(binder, *bound_expr.expr);
112: 				}
113: 			}
114: 		} else {
115: 			// we didn't bind columns, try again in children
116: 			return BindResult(error);
117: 		}
118: 	}
119: 	if (!filter_error.empty()) {
120: 		return BindResult(filter_error);
121: 	}
122: 
123: 	if (aggr.filter) {
124: 		auto &child = (BoundExpression &)*aggr.filter;
125: 		bound_filter = move(child.expr);
126: 	}
127: 	// all children bound successfully
128: 	// extract the children and types
129: 	vector<LogicalType> types;
130: 	vector<LogicalType> arguments;
131: 	vector<unique_ptr<Expression>> children;
132: 
133: 	if (ordered_set_agg) {
134: 		for (auto &order : aggr.order_bys->orders) {
135: 			auto &child = (BoundExpression &)*order.expression;
136: 			types.push_back(child.expr->return_type);
137: 			arguments.push_back(child.expr->return_type);
138: 			children.push_back(move(child.expr));
139: 		}
140: 		aggr.order_bys->orders.clear();
141: 	}
142: 
143: 	for (idx_t i = 0; i < aggr.children.size(); i++) {
144: 		auto &child = (BoundExpression &)*aggr.children[i];
145: 		types.push_back(child.expr->return_type);
146: 		arguments.push_back(child.expr->return_type);
147: 		children.push_back(move(child.expr));
148: 	}
149: 
150: 	// bind the aggregate
151: 	idx_t best_function = Function::BindFunction(func->name, func->functions, types, error);
152: 	if (best_function == DConstants::INVALID_INDEX) {
153: 		throw BinderException(binder.FormatError(aggr, error));
154: 	}
155: 	// found a matching function!
156: 	auto &bound_function = func->functions[best_function];
157: 
158: 	// Bind any sort columns, unless the aggregate is order-insensitive
159: 	auto order_bys = make_unique<BoundOrderModifier>();
160: 	if (!aggr.order_bys->orders.empty()) {
161: 		auto &config = DBConfig::GetConfig(context);
162: 		for (auto &order : aggr.order_bys->orders) {
163: 			auto &order_expr = (BoundExpression &)*order.expression;
164: 			const auto sense = (order.type == OrderType::ORDER_DEFAULT) ? config.default_order_type : order.type;
165: 			const auto null_order =
166: 			    (order.null_order == OrderByNullType::ORDER_DEFAULT) ? config.default_null_order : order.null_order;
167: 			order_bys->orders.emplace_back(BoundOrderByNode(sense, null_order, move(order_expr.expr)));
168: 		}
169: 	}
170: 
171: 	auto aggregate = AggregateFunction::BindAggregateFunction(context, bound_function, move(children),
172: 	                                                          move(bound_filter), aggr.distinct, move(order_bys));
173: 	if (aggr.export_state) {
174: 		aggregate = ExportAggregateFunction::Bind(move(aggregate));
175: 	}
176: 
177: 	// check for all the aggregates if this aggregate already exists
178: 	idx_t aggr_index;
179: 	auto entry = node.aggregate_map.find(aggregate.get());
180: 	if (entry == node.aggregate_map.end()) {
181: 		// new aggregate: insert into aggregate list
182: 		aggr_index = node.aggregates.size();
183: 		node.aggregate_map.insert(make_pair(aggregate.get(), aggr_index));
184: 		node.aggregates.push_back(move(aggregate));
185: 	} else {
186: 		// duplicate aggregate: simplify refer to this aggregate
187: 		aggr_index = entry->second;
188: 	}
189: 
190: 	// now create a column reference referring to the aggregate
191: 	auto colref = make_unique<BoundColumnRefExpression>(
192: 	    aggr.alias.empty() ? node.aggregates[aggr_index]->ToString() : aggr.alias,
193: 	    node.aggregates[aggr_index]->return_type, ColumnBinding(node.aggregate_index, aggr_index), depth);
194: 	// move the aggregate expression into the set of bound aggregates
195: 	return BindResult(move(colref));
196: }
197: } // namespace duckdb
[end of src/planner/binder/expression/bind_aggregate_expression.cpp]
[start of src/planner/binder/expression/bind_case_expression.cpp]
1: #include "duckdb/parser/expression/case_expression.hpp"
2: #include "duckdb/planner/expression/bound_case_expression.hpp"
3: #include "duckdb/planner/expression/bound_cast_expression.hpp"
4: #include "duckdb/planner/expression_binder.hpp"
5: 
6: namespace duckdb {
7: 
8: BindResult ExpressionBinder::BindExpression(CaseExpression &expr, idx_t depth) {
9: 	// first try to bind the children of the case expression
10: 	string error;
11: 	for (auto &check : expr.case_checks) {
12: 		BindChild(check.when_expr, depth, error);
13: 		BindChild(check.then_expr, depth, error);
14: 	}
15: 	BindChild(expr.else_expr, depth, error);
16: 	if (!error.empty()) {
17: 		return BindResult(error);
18: 	}
19: 	// the children have been successfully resolved
20: 	// figure out the result type of the CASE expression
21: 	auto return_type = ((BoundExpression &)*expr.else_expr).expr->return_type;
22: 	for (auto &check : expr.case_checks) {
23: 		auto &then_expr = (BoundExpression &)*check.then_expr;
24: 		return_type = LogicalType::MaxLogicalType(return_type, then_expr.expr->return_type);
25: 	}
26: 	ExpressionBinder::ResolveParameterType(return_type);
27: 
28: 	// bind all the individual components of the CASE statement
29: 	auto result = make_unique<BoundCaseExpression>(return_type);
30: 	for (idx_t i = 0; i < expr.case_checks.size(); i++) {
31: 		auto &check = expr.case_checks[i];
32: 		auto &when_expr = (BoundExpression &)*check.when_expr;
33: 		auto &then_expr = (BoundExpression &)*check.then_expr;
34: 		BoundCaseCheck result_check;
35: 		result_check.when_expr = BoundCastExpression::AddCastToType(move(when_expr.expr), LogicalType::BOOLEAN);
36: 		result_check.then_expr = BoundCastExpression::AddCastToType(move(then_expr.expr), return_type);
37: 		result->case_checks.push_back(move(result_check));
38: 	}
39: 	auto &else_expr = (BoundExpression &)*expr.else_expr;
40: 	result->else_expr = BoundCastExpression::AddCastToType(move(else_expr.expr), return_type);
41: 	return BindResult(move(result));
42: }
43: } // namespace duckdb
[end of src/planner/binder/expression/bind_case_expression.cpp]
[start of src/planner/binder/expression/bind_comparison_expression.cpp]
1: #include "duckdb/parser/expression/comparison_expression.hpp"
2: #include "duckdb/planner/expression/bound_cast_expression.hpp"
3: #include "duckdb/planner/expression/bound_constant_expression.hpp"
4: #include "duckdb/planner/expression/bound_comparison_expression.hpp"
5: #include "duckdb/planner/expression/bound_function_expression.hpp"
6: #include "duckdb/planner/expression_binder.hpp"
7: #include "duckdb/catalog/catalog_entry/collate_catalog_entry.hpp"
8: #include "duckdb/common/string_util.hpp"
9: 
10: #include "duckdb/function/scalar/string_functions.hpp"
11: 
12: #include "duckdb/common/types/decimal.hpp"
13: 
14: #include "duckdb/main/config.hpp"
15: #include "duckdb/catalog/catalog.hpp"
16: 
17: namespace duckdb {
18: 
19: unique_ptr<Expression> ExpressionBinder::PushCollation(ClientContext &context, unique_ptr<Expression> source,
20:                                                        const string &collation_p, bool equality_only) {
21: 	// replace default collation with system collation
22: 	string collation;
23: 	if (collation_p.empty()) {
24: 		collation = DBConfig::GetConfig(context).collation;
25: 	} else {
26: 		collation = collation_p;
27: 	}
28: 	collation = StringUtil::Lower(collation);
29: 	// bind the collation
30: 	if (collation.empty() || collation == "binary" || collation == "c" || collation == "posix") {
31: 		// binary collation: just skip
32: 		return source;
33: 	}
34: 	auto &catalog = Catalog::GetCatalog(context);
35: 	auto splits = StringUtil::Split(StringUtil::Lower(collation), ".");
36: 	vector<CollateCatalogEntry *> entries;
37: 	for (auto &collation_argument : splits) {
38: 		auto collation_entry = catalog.GetEntry<CollateCatalogEntry>(context, DEFAULT_SCHEMA, collation_argument);
39: 		if (collation_entry->combinable) {
40: 			entries.insert(entries.begin(), collation_entry);
41: 		} else {
42: 			if (!entries.empty() && !entries.back()->combinable) {
43: 				throw BinderException("Cannot combine collation types \"%s\" and \"%s\"", entries.back()->name,
44: 				                      collation_entry->name);
45: 			}
46: 			entries.push_back(collation_entry);
47: 		}
48: 	}
49: 	for (auto &collation_entry : entries) {
50: 		if (equality_only && collation_entry->not_required_for_equality) {
51: 			continue;
52: 		}
53: 		vector<unique_ptr<Expression>> children;
54: 		children.push_back(move(source));
55: 		auto function = ScalarFunction::BindScalarFunction(context, collation_entry->function, move(children));
56: 		source = move(function);
57: 	}
58: 	return source;
59: }
60: 
61: void ExpressionBinder::TestCollation(ClientContext &context, const string &collation) {
62: 	PushCollation(context, make_unique<BoundConstantExpression>(Value("")), collation);
63: }
64: 
65: LogicalType BoundComparisonExpression::BindComparison(LogicalType left_type, LogicalType right_type) {
66: 	auto result_type = LogicalType::MaxLogicalType(left_type, right_type);
67: 	switch (result_type.id()) {
68: 	case LogicalTypeId::DECIMAL: {
69: 		// result is a decimal: we need the maximum width and the maximum scale over width
70: 		vector<LogicalType> argument_types = {left_type, right_type};
71: 		uint8_t max_width = 0, max_scale = 0, max_width_over_scale = 0;
72: 		for (idx_t i = 0; i < argument_types.size(); i++) {
73: 			uint8_t width, scale;
74: 			auto can_convert = argument_types[i].GetDecimalProperties(width, scale);
75: 			if (!can_convert) {
76: 				return result_type;
77: 			}
78: 			max_width = MaxValue<uint8_t>(width, max_width);
79: 			max_scale = MaxValue<uint8_t>(scale, max_scale);
80: 			max_width_over_scale = MaxValue<uint8_t>(width - scale, max_width_over_scale);
81: 		}
82: 		max_width = MaxValue<uint8_t>(max_scale + max_width_over_scale, max_width);
83: 		if (max_width > Decimal::MAX_WIDTH_DECIMAL) {
84: 			// target width does not fit in decimal: truncate the scale (if possible) to try and make it fit
85: 			max_width = Decimal::MAX_WIDTH_DECIMAL;
86: 		}
87: 		return LogicalType::DECIMAL(max_width, max_scale);
88: 	}
89: 	case LogicalTypeId::VARCHAR:
90: 		// for comparison with strings, we prefer to bind to the numeric types
91: 		if (left_type.IsNumeric() || left_type.id() == LogicalTypeId::BOOLEAN) {
92: 			return left_type;
93: 		} else if (right_type.IsNumeric() || right_type.id() == LogicalTypeId::BOOLEAN) {
94: 			return right_type;
95: 		} else {
96: 			// else: check if collations are compatible
97: 			auto left_collation = StringType::GetCollation(left_type);
98: 			auto right_collation = StringType::GetCollation(right_type);
99: 			if (!left_collation.empty() && !right_collation.empty() && left_collation != right_collation) {
100: 				throw BinderException("Cannot combine types with different collation!");
101: 			}
102: 		}
103: 		return result_type;
104: 	case LogicalTypeId::UNKNOWN:
105: 		// comparing two prepared statement parameters (e.g. SELECT ?=?)
106: 		// default to VARCHAR
107: 		return LogicalType::VARCHAR;
108: 	default:
109: 		return result_type;
110: 	}
111: }
112: 
113: BindResult ExpressionBinder::BindExpression(ComparisonExpression &expr, idx_t depth) {
114: 	// first try to bind the children of the case expression
115: 	string error;
116: 	BindChild(expr.left, depth, error);
117: 	BindChild(expr.right, depth, error);
118: 	if (!error.empty()) {
119: 		return BindResult(error);
120: 	}
121: 	// the children have been successfully resolved
122: 	auto &left = (BoundExpression &)*expr.left;
123: 	auto &right = (BoundExpression &)*expr.right;
124: 	auto left_sql_type = left.expr->return_type;
125: 	auto right_sql_type = right.expr->return_type;
126: 	// cast the input types to the same type
127: 	// now obtain the result type of the input types
128: 	auto input_type = BoundComparisonExpression::BindComparison(left_sql_type, right_sql_type);
129: 	// add casts (if necessary)
130: 	left.expr = BoundCastExpression::AddCastToType(move(left.expr), input_type);
131: 	right.expr = BoundCastExpression::AddCastToType(move(right.expr), input_type);
132: 	if (input_type.id() == LogicalTypeId::VARCHAR) {
133: 		// handle collation
134: 		auto collation = StringType::GetCollation(input_type);
135: 		left.expr = PushCollation(context, move(left.expr), collation, expr.type == ExpressionType::COMPARE_EQUAL);
136: 		right.expr = PushCollation(context, move(right.expr), collation, expr.type == ExpressionType::COMPARE_EQUAL);
137: 	}
138: 	// now create the bound comparison expression
139: 	return BindResult(make_unique<BoundComparisonExpression>(expr.type, move(left.expr), move(right.expr)));
140: }
141: 
142: } // namespace duckdb
[end of src/planner/binder/expression/bind_comparison_expression.cpp]
[start of src/planner/binder/expression/bind_operator_expression.cpp]
1: #include "duckdb/parser/expression/operator_expression.hpp"
2: #include "duckdb/planner/expression/bound_cast_expression.hpp"
3: #include "duckdb/planner/expression/bound_operator_expression.hpp"
4: #include "duckdb/planner/expression/bound_case_expression.hpp"
5: #include "duckdb/parser/expression/function_expression.hpp"
6: #include "duckdb/planner/expression_binder.hpp"
7: 
8: namespace duckdb {
9: 
10: static LogicalType ResolveNotType(OperatorExpression &op, vector<BoundExpression *> &children) {
11: 	// NOT expression, cast child to BOOLEAN
12: 	D_ASSERT(children.size() == 1);
13: 	children[0]->expr = BoundCastExpression::AddCastToType(move(children[0]->expr), LogicalType::BOOLEAN);
14: 	return LogicalType(LogicalTypeId::BOOLEAN);
15: }
16: 
17: static LogicalType ResolveInType(OperatorExpression &op, vector<BoundExpression *> &children) {
18: 	if (children.empty()) {
19: 		throw InternalException("IN requires at least a single child node");
20: 	}
21: 	// get the maximum type from the children
22: 	LogicalType max_type = children[0]->expr->return_type;
23: 	for (idx_t i = 1; i < children.size(); i++) {
24: 		max_type = LogicalType::MaxLogicalType(max_type, children[i]->expr->return_type);
25: 	}
26: 	ExpressionBinder::ResolveParameterType(max_type);
27: 
28: 	// cast all children to the same type
29: 	for (idx_t i = 0; i < children.size(); i++) {
30: 		children[i]->expr = BoundCastExpression::AddCastToType(move(children[i]->expr), max_type);
31: 	}
32: 	// (NOT) IN always returns a boolean
33: 	return LogicalType::BOOLEAN;
34: }
35: 
36: static LogicalType ResolveOperatorType(OperatorExpression &op, vector<BoundExpression *> &children) {
37: 	switch (op.type) {
38: 	case ExpressionType::OPERATOR_IS_NULL:
39: 	case ExpressionType::OPERATOR_IS_NOT_NULL:
40: 		// IS (NOT) NULL always returns a boolean, and does not cast its children
41: 		ExpressionBinder::ResolveParameterType(children[0]->expr);
42: 		return LogicalType::BOOLEAN;
43: 	case ExpressionType::COMPARE_IN:
44: 	case ExpressionType::COMPARE_NOT_IN:
45: 		return ResolveInType(op, children);
46: 	case ExpressionType::OPERATOR_COALESCE: {
47: 		ResolveInType(op, children);
48: 		return children[0]->expr->return_type;
49: 	}
50: 	case ExpressionType::OPERATOR_NOT:
51: 		return ResolveNotType(op, children);
52: 	default:
53: 		throw InternalException("Unrecognized expression type for ResolveOperatorType");
54: 	}
55: }
56: 
57: BindResult ExpressionBinder::BindGroupingFunction(OperatorExpression &op, idx_t depth) {
58: 	return BindResult("GROUPING function is not supported here");
59: }
60: 
61: BindResult ExpressionBinder::BindExpression(OperatorExpression &op, idx_t depth) {
62: 	if (op.type == ExpressionType::GROUPING_FUNCTION) {
63: 		return BindGroupingFunction(op, depth);
64: 	}
65: 	// bind the children of the operator expression
66: 	string error;
67: 	for (idx_t i = 0; i < op.children.size(); i++) {
68: 		BindChild(op.children[i], depth, error);
69: 	}
70: 	if (!error.empty()) {
71: 		return BindResult(error);
72: 	}
73: 	// all children bound successfully
74: 	string function_name;
75: 	switch (op.type) {
76: 	case ExpressionType::ARRAY_EXTRACT: {
77: 		D_ASSERT(op.children[0]->expression_class == ExpressionClass::BOUND_EXPRESSION);
78: 		auto &b_exp = (BoundExpression &)*op.children[0];
79: 		if (b_exp.expr->return_type.id() == LogicalTypeId::MAP) {
80: 			function_name = "map_extract";
81: 		} else {
82: 			function_name = "array_extract";
83: 		}
84: 		break;
85: 	}
86: 	case ExpressionType::ARRAY_SLICE:
87: 		function_name = "array_slice";
88: 		break;
89: 	case ExpressionType::STRUCT_EXTRACT: {
90: 		D_ASSERT(op.children.size() == 2);
91: 		D_ASSERT(op.children[0]->expression_class == ExpressionClass::BOUND_EXPRESSION);
92: 		D_ASSERT(op.children[1]->expression_class == ExpressionClass::BOUND_EXPRESSION);
93: 		auto &extract_exp = (BoundExpression &)*op.children[0];
94: 		auto &name_exp = (BoundExpression &)*op.children[1];
95: 		if (extract_exp.expr->return_type.id() != LogicalTypeId::STRUCT &&
96: 		    extract_exp.expr->return_type.id() != LogicalTypeId::SQLNULL) {
97: 			return BindResult(
98: 			    StringUtil::Format("Cannot extract field %s from expression \"%s\" because it is not a struct",
99: 			                       name_exp.ToString(), extract_exp.ToString()));
100: 		}
101: 		function_name = "struct_extract";
102: 		break;
103: 	}
104: 	case ExpressionType::ARRAY_CONSTRUCTOR:
105: 		function_name = "list_value";
106: 		break;
107: 	case ExpressionType::ARROW:
108: 		function_name = "json_extract";
109: 		break;
110: 	default:
111: 		break;
112: 	}
113: 	if (!function_name.empty()) {
114: 		auto function = make_unique<FunctionExpression>(function_name, move(op.children));
115: 		return BindExpression(*function, depth, nullptr);
116: 	}
117: 
118: 	vector<BoundExpression *> children;
119: 	for (idx_t i = 0; i < op.children.size(); i++) {
120: 		D_ASSERT(op.children[i]->expression_class == ExpressionClass::BOUND_EXPRESSION);
121: 		children.push_back((BoundExpression *)op.children[i].get());
122: 	}
123: 	// now resolve the types
124: 	LogicalType result_type = ResolveOperatorType(op, children);
125: 	if (op.type == ExpressionType::OPERATOR_COALESCE) {
126: 		if (children.empty()) {
127: 			throw BinderException("COALESCE needs at least one child");
128: 		}
129: 		if (children.size() == 1) {
130: 			return BindResult(move(children[0]->expr));
131: 		}
132: 	}
133: 
134: 	auto result = make_unique<BoundOperatorExpression>(op.type, result_type);
135: 	for (auto &child : children) {
136: 		result->children.push_back(move(child->expr));
137: 	}
138: 	return BindResult(move(result));
139: }
140: 
141: } // namespace duckdb
[end of src/planner/binder/expression/bind_operator_expression.cpp]
[start of src/planner/binder/expression/bind_parameter_expression.cpp]
1: #include "duckdb/parser/expression/parameter_expression.hpp"
2: #include "duckdb/planner/binder.hpp"
3: #include "duckdb/planner/expression/bound_parameter_expression.hpp"
4: #include "duckdb/planner/expression_binder.hpp"
5: 
6: namespace duckdb {
7: 
8: BindResult ExpressionBinder::BindExpression(ParameterExpression &expr, idx_t depth) {
9: 	auto bound_parameter = make_unique<BoundParameterExpression>(expr.parameter_nr);
10: 	if (!binder.parameters) {
11: 		throw std::runtime_error("Unexpected prepared parameter. This type of statement can't be prepared!");
12: 	}
13: 	binder.parameters->push_back(bound_parameter.get());
14: 	return BindResult(move(bound_parameter));
15: }
16: 
17: } // namespace duckdb
[end of src/planner/binder/expression/bind_parameter_expression.cpp]
[start of src/planner/binder/expression/bind_subquery_expression.cpp]
1: #include "duckdb/parser/expression/subquery_expression.hpp"
2: #include "duckdb/planner/binder.hpp"
3: #include "duckdb/planner/expression/bound_cast_expression.hpp"
4: #include "duckdb/planner/expression/bound_subquery_expression.hpp"
5: #include "duckdb/planner/expression_binder.hpp"
6: #include "duckdb/common/string_util.hpp"
7: 
8: namespace duckdb {
9: 
10: class BoundSubqueryNode : public QueryNode {
11: public:
12: 	BoundSubqueryNode(shared_ptr<Binder> subquery_binder, unique_ptr<BoundQueryNode> bound_node,
13: 	                  unique_ptr<SelectStatement> subquery)
14: 	    : QueryNode(QueryNodeType::BOUND_SUBQUERY_NODE), subquery_binder(move(subquery_binder)),
15: 	      bound_node(move(bound_node)), subquery(move(subquery)) {
16: 	}
17: 
18: 	shared_ptr<Binder> subquery_binder;
19: 	unique_ptr<BoundQueryNode> bound_node;
20: 	unique_ptr<SelectStatement> subquery;
21: 
22: 	const vector<unique_ptr<ParsedExpression>> &GetSelectList() const override {
23: 		throw InternalException("Cannot get select list of bound subquery node");
24: 	}
25: 
26: 	string ToString() const override {
27: 		throw InternalException("Cannot ToString bound subquery node");
28: 	}
29: 	unique_ptr<QueryNode> Copy() const override {
30: 		throw InternalException("Cannot copy bound subquery node");
31: 	}
32: 	void Serialize(FieldWriter &writer) const override {
33: 		throw InternalException("Cannot serialize bound subquery node");
34: 	}
35: };
36: 
37: BindResult ExpressionBinder::BindExpression(SubqueryExpression &expr, idx_t depth) {
38: 	if (expr.subquery->node->type != QueryNodeType::BOUND_SUBQUERY_NODE) {
39: 		D_ASSERT(depth == 0);
40: 		// first bind the actual subquery in a new binder
41: 		auto subquery_binder = Binder::CreateBinder(context, &binder);
42: 		subquery_binder->can_contain_nulls = true;
43: 		auto bound_node = subquery_binder->BindNode(*expr.subquery->node);
44: 		// check the correlated columns of the subquery for correlated columns with depth > 1
45: 		for (idx_t i = 0; i < subquery_binder->correlated_columns.size(); i++) {
46: 			CorrelatedColumnInfo corr = subquery_binder->correlated_columns[i];
47: 			if (corr.depth > 1) {
48: 				// depth > 1, the column references the query ABOVE the current one
49: 				// add to the set of correlated columns for THIS query
50: 				corr.depth -= 1;
51: 				binder.AddCorrelatedColumn(corr);
52: 			}
53: 		}
54: 		if (expr.subquery_type != SubqueryType::EXISTS && bound_node->types.size() > 1) {
55: 			throw BinderException(binder.FormatError(
56: 			    expr, StringUtil::Format("Subquery returns %zu columns - expected 1", bound_node->types.size())));
57: 		}
58: 		auto prior_subquery = move(expr.subquery);
59: 		expr.subquery = make_unique<SelectStatement>();
60: 		expr.subquery->node =
61: 		    make_unique<BoundSubqueryNode>(move(subquery_binder), move(bound_node), move(prior_subquery));
62: 	}
63: 	// now bind the child node of the subquery
64: 	if (expr.child) {
65: 		// first bind the children of the subquery, if any
66: 		string error = Bind(&expr.child, depth);
67: 		if (!error.empty()) {
68: 			return BindResult(error);
69: 		}
70: 	}
71: 	// both binding the child and binding the subquery was successful
72: 	D_ASSERT(expr.subquery->node->type == QueryNodeType::BOUND_SUBQUERY_NODE);
73: 	auto bound_subquery = (BoundSubqueryNode *)expr.subquery->node.get();
74: 	auto child = (BoundExpression *)expr.child.get();
75: 	auto subquery_binder = move(bound_subquery->subquery_binder);
76: 	auto bound_node = move(bound_subquery->bound_node);
77: 	LogicalType return_type =
78: 	    expr.subquery_type == SubqueryType::SCALAR ? bound_node->types[0] : LogicalType(LogicalTypeId::BOOLEAN);
79: 	D_ASSERT(return_type.id() != LogicalTypeId::UNKNOWN);
80: 
81: 	auto result = make_unique<BoundSubqueryExpression>(return_type);
82: 	if (expr.subquery_type == SubqueryType::ANY) {
83: 		// ANY comparison
84: 		// cast child and subquery child to equivalent types
85: 		D_ASSERT(bound_node->types.size() == 1);
86: 		auto compare_type = LogicalType::MaxLogicalType(child->expr->return_type, bound_node->types[0]);
87: 		child->expr = BoundCastExpression::AddCastToType(move(child->expr), compare_type);
88: 		result->child_type = bound_node->types[0];
89: 		result->child_target = compare_type;
90: 	}
91: 	result->binder = move(subquery_binder);
92: 	result->subquery = move(bound_node);
93: 	result->subquery_type = expr.subquery_type;
94: 	result->child = child ? move(child->expr) : nullptr;
95: 	result->comparison_type = expr.comparison_type;
96: 
97: 	return BindResult(move(result));
98: }
99: 
100: } // namespace duckdb
[end of src/planner/binder/expression/bind_subquery_expression.cpp]
[start of src/planner/expression_binder.cpp]
1: #include "duckdb/planner/expression_binder.hpp"
2: 
3: #include "duckdb/parser/expression/columnref_expression.hpp"
4: #include "duckdb/parser/expression/positional_reference_expression.hpp"
5: #include "duckdb/parser/expression/subquery_expression.hpp"
6: #include "duckdb/parser/parsed_expression_iterator.hpp"
7: #include "duckdb/planner/binder.hpp"
8: #include "duckdb/planner/expression/bound_cast_expression.hpp"
9: #include "duckdb/planner/expression/bound_default_expression.hpp"
10: #include "duckdb/planner/expression/bound_parameter_expression.hpp"
11: #include "duckdb/planner/expression/bound_subquery_expression.hpp"
12: #include "duckdb/planner/expression_iterator.hpp"
13: 
14: namespace duckdb {
15: 
16: ExpressionBinder::ExpressionBinder(Binder &binder, ClientContext &context, bool replace_binder)
17:     : binder(binder), context(context), stored_binder(nullptr) {
18: 	if (replace_binder) {
19: 		stored_binder = binder.GetActiveBinder();
20: 		binder.SetActiveBinder(this);
21: 	} else {
22: 		binder.PushExpressionBinder(this);
23: 	}
24: }
25: 
26: ExpressionBinder::~ExpressionBinder() {
27: 	if (binder.HasActiveBinder()) {
28: 		if (stored_binder) {
29: 			binder.SetActiveBinder(stored_binder);
30: 		} else {
31: 			binder.PopExpressionBinder();
32: 		}
33: 	}
34: }
35: 
36: BindResult ExpressionBinder::BindExpression(unique_ptr<ParsedExpression> *expr, idx_t depth, bool root_expression) {
37: 	auto &expr_ref = **expr;
38: 	switch (expr_ref.expression_class) {
39: 	case ExpressionClass::BETWEEN:
40: 		return BindExpression((BetweenExpression &)expr_ref, depth);
41: 	case ExpressionClass::CASE:
42: 		return BindExpression((CaseExpression &)expr_ref, depth);
43: 	case ExpressionClass::CAST:
44: 		return BindExpression((CastExpression &)expr_ref, depth);
45: 	case ExpressionClass::COLLATE:
46: 		return BindExpression((CollateExpression &)expr_ref, depth);
47: 	case ExpressionClass::COLUMN_REF:
48: 		return BindExpression((ColumnRefExpression &)expr_ref, depth);
49: 	case ExpressionClass::COMPARISON:
50: 		return BindExpression((ComparisonExpression &)expr_ref, depth);
51: 	case ExpressionClass::CONJUNCTION:
52: 		return BindExpression((ConjunctionExpression &)expr_ref, depth);
53: 	case ExpressionClass::CONSTANT:
54: 		return BindExpression((ConstantExpression &)expr_ref, depth);
55: 	case ExpressionClass::FUNCTION:
56: 		// binding function expression has extra parameter needed for macro's
57: 		return BindExpression((FunctionExpression &)expr_ref, depth, expr);
58: 	case ExpressionClass::LAMBDA:
59: 		return BindExpression((LambdaExpression &)expr_ref, depth);
60: 	case ExpressionClass::OPERATOR:
61: 		return BindExpression((OperatorExpression &)expr_ref, depth);
62: 	case ExpressionClass::SUBQUERY:
63: 		return BindExpression((SubqueryExpression &)expr_ref, depth);
64: 	case ExpressionClass::PARAMETER:
65: 		return BindExpression((ParameterExpression &)expr_ref, depth);
66: 	case ExpressionClass::POSITIONAL_REFERENCE:
67: 		return BindExpression((PositionalReferenceExpression &)expr_ref, depth);
68: 	default:
69: 		throw NotImplementedException("Unimplemented expression class");
70: 	}
71: }
72: 
73: bool ExpressionBinder::BindCorrelatedColumns(unique_ptr<ParsedExpression> &expr) {
74: 	// try to bind in one of the outer queries, if the binding error occurred in a subquery
75: 	auto &active_binders = binder.GetActiveBinders();
76: 	// make a copy of the set of binders, so we can restore it later
77: 	auto binders = active_binders;
78: 	active_binders.pop_back();
79: 	idx_t depth = 1;
80: 	bool success = false;
81: 	while (!active_binders.empty()) {
82: 		auto &next_binder = active_binders.back();
83: 		ExpressionBinder::QualifyColumnNames(next_binder->binder, expr);
84: 		auto bind_result = next_binder->Bind(&expr, depth);
85: 		if (bind_result.empty()) {
86: 			success = true;
87: 			break;
88: 		}
89: 		depth++;
90: 		active_binders.pop_back();
91: 	}
92: 	active_binders = binders;
93: 	return success;
94: }
95: 
96: void ExpressionBinder::BindChild(unique_ptr<ParsedExpression> &expr, idx_t depth, string &error) {
97: 	if (expr) {
98: 		string bind_error = Bind(&expr, depth);
99: 		if (error.empty()) {
100: 			error = bind_error;
101: 		}
102: 	}
103: }
104: 
105: void ExpressionBinder::ExtractCorrelatedExpressions(Binder &binder, Expression &expr) {
106: 	if (expr.type == ExpressionType::BOUND_COLUMN_REF) {
107: 		auto &bound_colref = (BoundColumnRefExpression &)expr;
108: 		if (bound_colref.depth > 0) {
109: 			binder.AddCorrelatedColumn(CorrelatedColumnInfo(bound_colref));
110: 		}
111: 	}
112: 	ExpressionIterator::EnumerateChildren(expr,
113: 	                                      [&](Expression &child) { ExtractCorrelatedExpressions(binder, child); });
114: }
115: 
116: bool ExpressionBinder::ContainsType(const LogicalType &type, LogicalTypeId target) {
117: 	if (type.id() == target) {
118: 		return true;
119: 	}
120: 	switch (type.id()) {
121: 	case LogicalTypeId::STRUCT:
122: 	case LogicalTypeId::MAP: {
123: 		auto child_count = StructType::GetChildCount(type);
124: 		for (idx_t i = 0; i < child_count; i++) {
125: 			if (ContainsType(StructType::GetChildType(type, i), target)) {
126: 				return true;
127: 			}
128: 		}
129: 		return false;
130: 	}
131: 	case LogicalTypeId::LIST:
132: 		return ContainsType(ListType::GetChildType(type), target);
133: 	default:
134: 		return false;
135: 	}
136: }
137: 
138: LogicalType ExpressionBinder::ExchangeType(const LogicalType &type, LogicalTypeId target, LogicalType new_type) {
139: 	if (type.id() == target) {
140: 		return new_type;
141: 	}
142: 	switch (type.id()) {
143: 	case LogicalTypeId::STRUCT:
144: 	case LogicalTypeId::MAP: {
145: 		// we make a copy of the child types of the struct here
146: 		auto child_types = StructType::GetChildTypes(type);
147: 		for (auto &child_type : child_types) {
148: 			child_type.second = ExchangeType(child_type.second, target, new_type);
149: 		}
150: 		return type.id() == LogicalTypeId::MAP ? LogicalType::MAP(move(child_types))
151: 		                                       : LogicalType::STRUCT(move(child_types));
152: 	}
153: 	case LogicalTypeId::LIST:
154: 		return LogicalType::LIST(ExchangeType(ListType::GetChildType(type), target, new_type));
155: 	default:
156: 		return type;
157: 	}
158: }
159: 
160: bool ExpressionBinder::ContainsNullType(const LogicalType &type) {
161: 	return ContainsType(type, LogicalTypeId::SQLNULL);
162: }
163: 
164: LogicalType ExpressionBinder::ExchangeNullType(const LogicalType &type) {
165: 	return ExchangeType(type, LogicalTypeId::SQLNULL, LogicalType::INTEGER);
166: }
167: 
168: void ExpressionBinder::ResolveParameterType(LogicalType &type) {
169: 	if (type.id() == LogicalTypeId::UNKNOWN) {
170: 		type = LogicalType::VARCHAR;
171: 	}
172: }
173: 
174: void ExpressionBinder::ResolveParameterType(unique_ptr<Expression> &expr) {
175: 	if (ContainsType(expr->return_type, LogicalTypeId::UNKNOWN)) {
176: 		auto result_type = ExchangeType(expr->return_type, LogicalTypeId::UNKNOWN, LogicalType::VARCHAR);
177: 		expr = BoundCastExpression::AddCastToType(move(expr), result_type);
178: 	}
179: }
180: 
181: unique_ptr<Expression> ExpressionBinder::Bind(unique_ptr<ParsedExpression> &expr, LogicalType *result_type,
182:                                               bool root_expression) {
183: 	// bind the main expression
184: 	auto error_msg = Bind(&expr, 0, root_expression);
185: 	if (!error_msg.empty()) {
186: 		// failed to bind: try to bind correlated columns in the expression (if any)
187: 		bool success = BindCorrelatedColumns(expr);
188: 		if (!success) {
189: 			throw BinderException(error_msg);
190: 		}
191: 		auto bound_expr = (BoundExpression *)expr.get();
192: 		ExtractCorrelatedExpressions(binder, *bound_expr->expr);
193: 	}
194: 	D_ASSERT(expr->expression_class == ExpressionClass::BOUND_EXPRESSION);
195: 	auto bound_expr = (BoundExpression *)expr.get();
196: 	unique_ptr<Expression> result = move(bound_expr->expr);
197: 	if (target_type.id() != LogicalTypeId::INVALID) {
198: 		// the binder has a specific target type: add a cast to that type
199: 		result = BoundCastExpression::AddCastToType(move(result), target_type);
200: 	} else {
201: 		if (!binder.can_contain_nulls) {
202: 			// SQL NULL type is only used internally in the binder
203: 			// cast to INTEGER if we encounter it outside of the binder
204: 			if (ContainsNullType(result->return_type)) {
205: 				auto result_type = ExchangeNullType(result->return_type);
206: 				result = BoundCastExpression::AddCastToType(move(result), result_type);
207: 			}
208: 		}
209: 		// check if we failed to convert any parameters
210: 		// if we did, we push a cast
211: 		ExpressionBinder::ResolveParameterType(result);
212: 	}
213: 	if (result_type) {
214: 		*result_type = result->return_type;
215: 	}
216: 	return result;
217: }
218: 
219: string ExpressionBinder::Bind(unique_ptr<ParsedExpression> *expr, idx_t depth, bool root_expression) {
220: 	// bind the node, but only if it has not been bound yet
221: 	auto &expression = **expr;
222: 	auto alias = expression.alias;
223: 	if (expression.GetExpressionClass() == ExpressionClass::BOUND_EXPRESSION) {
224: 		// already bound, don't bind it again
225: 		return string();
226: 	}
227: 	// bind the expression
228: 	BindResult result = BindExpression(expr, depth, root_expression);
229: 	if (result.HasError()) {
230: 		return result.error;
231: 	} else {
232: 		// successfully bound: replace the node with a BoundExpression
233: 		*expr = make_unique<BoundExpression>(move(result.expression));
234: 		auto be = (BoundExpression *)expr->get();
235: 		D_ASSERT(be);
236: 		be->alias = alias;
237: 		if (!alias.empty()) {
238: 			be->expr->alias = alias;
239: 		}
240: 		return string();
241: 	}
242: }
243: 
244: } // namespace duckdb
[end of src/planner/expression_binder.cpp]
[start of src/planner/planner.cpp]
1: #include "duckdb/planner/planner.hpp"
2: #include "duckdb/main/query_profiler.hpp"
3: #include "duckdb/common/serializer.hpp"
4: #include "duckdb/main/client_context.hpp"
5: #include "duckdb/main/database.hpp"
6: #include "duckdb/parser/statement/pragma_statement.hpp"
7: #include "duckdb/parser/statement/prepare_statement.hpp"
8: #include "duckdb/main/prepared_statement_data.hpp"
9: #include "duckdb/planner/binder.hpp"
10: #include "duckdb/planner/expression/bound_parameter_expression.hpp"
11: #include "duckdb/planner/operator/logical_execute.hpp"
12: #include "duckdb/planner/operator/logical_prepare.hpp"
13: #include "duckdb/planner/expression_binder/constant_binder.hpp"
14: #include "duckdb/parser/statement/execute_statement.hpp"
15: #include "duckdb/execution/expression_executor.hpp"
16: #include "duckdb/transaction/transaction.hpp"
17: 
18: namespace duckdb {
19: 
20: Planner::Planner(ClientContext &context) : binder(Binder::CreateBinder(context)), context(context) {
21: }
22: 
23: void Planner::CreatePlan(SQLStatement &statement) {
24: 	auto &profiler = QueryProfiler::Get(context);
25: 
26: 	vector<BoundParameterExpression *> bound_parameters;
27: 
28: 	// first bind the tables and columns to the catalog
29: 	profiler.StartPhase("binder");
30: 	binder->parameters = &bound_parameters;
31: 	auto bound_statement = binder->Bind(statement);
32: 	profiler.EndPhase();
33: 
34: 	this->read_only = binder->read_only;
35: 	this->requires_valid_transaction = binder->requires_valid_transaction;
36: 	this->allow_stream_result = binder->allow_stream_result;
37: 	this->names = bound_statement.names;
38: 	this->types = bound_statement.types;
39: 	this->plan = move(bound_statement.plan);
40: 
41: 	// set up a map of parameter number -> value entries
42: 	for (auto &expr : bound_parameters) {
43: 		// check if the type of the parameter could be resolved
44: 		if (expr->return_type.id() == LogicalTypeId::INVALID || expr->return_type.id() == LogicalTypeId::UNKNOWN) {
45: 			throw BinderException("Could not determine type of parameters");
46: 		}
47: 		auto value = make_unique<Value>(expr->return_type);
48: 		expr->value = value.get();
49: 		// check if the parameter number has been used before
50: 		if (value_map.find(expr->parameter_nr) == value_map.end()) {
51: 			// not used before, create vector
52: 			value_map[expr->parameter_nr] = vector<unique_ptr<Value>>();
53: 		} else if (value_map[expr->parameter_nr].back()->type() != value->type()) {
54: 			// used before, but types are inconsistent
55: 			throw BinderException("Inconsistent types found for parameter with index %llu", expr->parameter_nr);
56: 		}
57: 		value_map[expr->parameter_nr].push_back(move(value));
58: 	}
59: }
60: 
61: shared_ptr<PreparedStatementData> Planner::PrepareSQLStatement(unique_ptr<SQLStatement> statement) {
62: 	auto copied_statement = statement->Copy();
63: 	// create a plan of the underlying statement
64: 	CreatePlan(move(statement));
65: 	// now create the logical prepare
66: 	auto prepared_data = make_shared<PreparedStatementData>(copied_statement->type);
67: 	prepared_data->unbound_statement = move(copied_statement);
68: 	prepared_data->names = names;
69: 	prepared_data->types = types;
70: 	prepared_data->value_map = move(value_map);
71: 	prepared_data->read_only = this->read_only;
72: 	prepared_data->requires_valid_transaction = this->requires_valid_transaction;
73: 	prepared_data->allow_stream_result = this->allow_stream_result;
74: 	prepared_data->catalog_version = Transaction::GetTransaction(context).catalog_version;
75: 	return prepared_data;
76: }
77: 
78: void Planner::PlanExecute(unique_ptr<SQLStatement> statement) {
79: 	auto &stmt = (ExecuteStatement &)*statement;
80: 
81: 	// bind the prepared statement
82: 	auto entry = context.prepared_statements.find(stmt.name);
83: 	if (entry == context.prepared_statements.end()) {
84: 		throw BinderException("Prepared statement \"%s\" does not exist", stmt.name);
85: 	}
86: 
87: 	// check if we need to rebind the prepared statement
88: 	// this happens if the catalog changes, since in this case e.g. tables we relied on may have been deleted
89: 	auto prepared = entry->second;
90: 	auto &catalog = Catalog::GetCatalog(context);
91: 	bool rebound = false;
92: 	if (catalog.GetCatalogVersion() != entry->second->catalog_version) {
93: 		// catalog was modified: rebind the statement before running the execute
94: 		prepared = PrepareSQLStatement(entry->second->unbound_statement->Copy());
95: 		if (prepared->types != entry->second->types) {
96: 			throw BinderException("Rebinding statement \"%s\" after catalog change resulted in change of types",
97: 			                      stmt.name);
98: 		}
99: 		rebound = true;
100: 	}
101: 
102: 	// the bound prepared statement is ready: bind any supplied parameters
103: 	vector<Value> bind_values;
104: 	for (idx_t i = 0; i < stmt.values.size(); i++) {
105: 		ConstantBinder cbinder(*binder, context, "EXECUTE statement");
106: 		if (prepared->value_map.count(i + 1)) {
107: 			cbinder.target_type = prepared->GetType(i + 1);
108: 		}
109: 		auto bound_expr = cbinder.Bind(stmt.values[i]);
110: 
111: 		Value value = ExpressionExecutor::EvaluateScalar(*bound_expr);
112: 		bind_values.push_back(move(value));
113: 	}
114: 	prepared->Bind(move(bind_values));
115: 	if (rebound) {
116: 		return;
117: 	}
118: 
119: 	// copy the properties of the prepared statement into the planner
120: 	this->read_only = prepared->read_only;
121: 	this->requires_valid_transaction = prepared->requires_valid_transaction;
122: 	this->allow_stream_result = prepared->allow_stream_result;
123: 	this->names = prepared->names;
124: 	this->types = prepared->types;
125: 	this->plan = make_unique<LogicalExecute>(move(prepared));
126: }
127: 
128: void Planner::PlanPrepare(unique_ptr<SQLStatement> statement) {
129: 	auto &stmt = (PrepareStatement &)*statement;
130: 	auto prepared_data = PrepareSQLStatement(move(stmt.statement));
131: 
132: 	auto prepare = make_unique<LogicalPrepare>(stmt.name, move(prepared_data), move(plan));
133: 	// we can prepare in read-only mode: prepared statements are not written to the catalog
134: 	this->read_only = true;
135: 	// we can always prepare, even if the transaction has been invalidated
136: 	// this is required because most clients ALWAYS invoke prepared statements
137: 	this->requires_valid_transaction = false;
138: 	this->allow_stream_result = false;
139: 	this->names = {"Success"};
140: 	this->types = {LogicalType::BOOLEAN};
141: 	this->plan = move(prepare);
142: }
143: 
144: void Planner::CreatePlan(unique_ptr<SQLStatement> statement) {
145: 	D_ASSERT(statement);
146: 	switch (statement->type) {
147: 	case StatementType::SELECT_STATEMENT:
148: 	case StatementType::INSERT_STATEMENT:
149: 	case StatementType::COPY_STATEMENT:
150: 	case StatementType::DELETE_STATEMENT:
151: 	case StatementType::UPDATE_STATEMENT:
152: 	case StatementType::CREATE_STATEMENT:
153: 	case StatementType::DROP_STATEMENT:
154: 	case StatementType::ALTER_STATEMENT:
155: 	case StatementType::TRANSACTION_STATEMENT:
156: 	case StatementType::EXPLAIN_STATEMENT:
157: 	case StatementType::VACUUM_STATEMENT:
158: 	case StatementType::RELATION_STATEMENT:
159: 	case StatementType::CALL_STATEMENT:
160: 	case StatementType::EXPORT_STATEMENT:
161: 	case StatementType::PRAGMA_STATEMENT:
162: 	case StatementType::SHOW_STATEMENT:
163: 	case StatementType::SET_STATEMENT:
164: 	case StatementType::LOAD_STATEMENT:
165: 		CreatePlan(*statement);
166: 		break;
167: 	case StatementType::EXECUTE_STATEMENT:
168: 		PlanExecute(move(statement));
169: 		break;
170: 	case StatementType::PREPARE_STATEMENT:
171: 		PlanPrepare(move(statement));
172: 		break;
173: 	default:
174: 		throw NotImplementedException("Cannot plan statement of type %s!", StatementTypeToString(statement->type));
175: 	}
176: }
177: 
178: } // namespace duckdb
[end of src/planner/planner.cpp]
[start of tools/rpkg/src/statement.cpp]
1: #include "rapi.hpp"
2: #include "typesr.hpp"
3: #include "altrepstring.hpp"
4: 
5: #include "duckdb/common/arrow.hpp"
6: #include "duckdb/common/types/timestamp.hpp"
7: #include "duckdb/common/arrow_wrapper.hpp"
8: #include "duckdb/common/result_arrow_wrapper.hpp"
9: #include "duckdb/main/stream_query_result.hpp"
10: 
11: using namespace duckdb;
12: using namespace cpp11::literals;
13: 
14: // converter for primitive types
15: template <class SRC, class DEST>
16: static void VectorToR(Vector &src_vec, size_t count, void *dest, uint64_t dest_offset, DEST na_val) {
17: 	auto src_ptr = FlatVector::GetData<SRC>(src_vec);
18: 	auto &mask = FlatVector::Validity(src_vec);
19: 	auto dest_ptr = ((DEST *)dest) + dest_offset;
20: 	for (size_t row_idx = 0; row_idx < count; row_idx++) {
21: 		dest_ptr[row_idx] = !mask.RowIsValid(row_idx) ? na_val : src_ptr[row_idx];
22: 	}
23: }
24: 
25: [[cpp11::register]] void rapi_release(duckdb::stmt_eptr_t stmt) {
26: 	auto stmt_ptr = stmt.release();
27: 	if (stmt_ptr) {
28: 		delete stmt_ptr;
29: 	}
30: }
31: 
32: [[cpp11::register]] cpp11::list rapi_prepare(duckdb::conn_eptr_t conn, std::string query) {
33: 	if (!conn || !conn->conn) {
34: 		cpp11::stop("rapi_prepare: Invalid connection");
35: 	}
36: 
37: 	auto statements = conn->conn->ExtractStatements(query.c_str());
38: 	if (statements.empty()) {
39: 		// no statements to execute
40: 		cpp11::stop("rapi_prepare: No statements to execute");
41: 	}
42: 	// if there are multiple statements, we directly execute the statements besides the last one
43: 	// we only return the result of the last statement to the user, unless one of the previous statements fails
44: 	for (idx_t i = 0; i + 1 < statements.size(); i++) {
45: 		auto res = conn->conn->Query(move(statements[i]));
46: 		if (!res->success) {
47: 			cpp11::stop("rapi_prepare: Failed to execute statement %s\nError: %s", query.c_str(), res->error.c_str());
48: 		}
49: 	}
50: 	auto stmt = conn->conn->Prepare(move(statements.back()));
51: 	if (!stmt->success) {
52: 		cpp11::stop("rapi_prepare: Failed to prepare query %s\nError: %s", query.c_str(), stmt->error.c_str());
53: 	}
54: 
55: 	cpp11::writable::list retlist;
56: 	retlist.reserve(6);
57: 	retlist.push_back({"str"_nm = query});
58: 
59: 	auto stmtholder = new RStatement();
60: 	stmtholder->stmt = move(stmt);
61: 
62: 	retlist.push_back({"ref"_nm = stmt_eptr_t(stmtholder)});
63: 	retlist.push_back({"type"_nm = StatementTypeToString(stmtholder->stmt->GetStatementType())});
64: 	retlist.push_back({"names"_nm = cpp11::as_sexp(stmtholder->stmt->GetNames())});
65: 
66: 	cpp11::writable::strings rtypes;
67: 
68: 	for (auto &stype : stmtholder->stmt->GetTypes()) {
69: 		string rtype = "";
70: 		switch (stype.id()) {
71: 		case LogicalTypeId::BOOLEAN:
72: 			rtype = "logical";
73: 			break;
74: 		case LogicalTypeId::UTINYINT:
75: 		case LogicalTypeId::TINYINT:
76: 		case LogicalTypeId::USMALLINT:
77: 		case LogicalTypeId::SMALLINT:
78: 		case LogicalTypeId::INTEGER:
79: 			rtype = "integer";
80: 			break;
81: 		case LogicalTypeId::TIMESTAMP_SEC:
82: 		case LogicalTypeId::TIMESTAMP_MS:
83: 		case LogicalTypeId::TIMESTAMP:
84: 		case LogicalTypeId::TIMESTAMP_TZ:
85: 		case LogicalTypeId::TIMESTAMP_NS:
86: 			rtype = "POSIXct";
87: 			break;
88: 		case LogicalTypeId::DATE:
89: 			rtype = "Date";
90: 			break;
91: 		case LogicalTypeId::TIME:
92: 			rtype = "difftime";
93: 			break;
94: 		case LogicalTypeId::UINTEGER:
95: 		case LogicalTypeId::UBIGINT:
96: 		case LogicalTypeId::BIGINT:
97: 		case LogicalTypeId::HUGEINT:
98: 		case LogicalTypeId::FLOAT:
99: 		case LogicalTypeId::DOUBLE:
100: 		case LogicalTypeId::DECIMAL:
101: 			rtype = "numeric";
102: 			break;
103: 		case LogicalTypeId::VARCHAR:
104: 			rtype = "character";
105: 			break;
106: 		case LogicalTypeId::BLOB:
107: 			rtype = "raw";
108: 			break;
109: 		case LogicalTypeId::LIST:
110: 			rtype = "list";
111: 			break;
112: 		case LogicalTypeId::ENUM:
113: 			rtype = "factor";
114: 			break;
115: 		default:
116: 			cpp11::stop("rapi_prepare: Unknown column type for prepare: %s", stype.ToString().c_str());
117: 			break;
118: 		}
119: 		rtypes.push_back(rtype);
120: 	}
121: 
122: 	retlist.push_back({"rtypes"_nm = rtypes});
123: 	retlist.push_back({"n_param"_nm = stmtholder->stmt->n_param});
124: 
125: 	return retlist;
126: }
127: 
128: [[cpp11::register]] cpp11::list rapi_bind(duckdb::stmt_eptr_t stmt, cpp11::list params, bool arrow) {
129: 	if (!stmt || !stmt->stmt) {
130: 		cpp11::stop("rapi_bind: Invalid statement");
131: 	}
132: 
133: 	stmt->parameters.clear();
134: 	stmt->parameters.resize(stmt->stmt->n_param);
135: 
136: 	if (stmt->stmt->n_param == 0) {
137: 		cpp11::stop("rapi_bind: dbBind called but query takes no parameters");
138: 	}
139: 
140: 	if (params.size() != stmt->stmt->n_param) {
141: 		cpp11::stop("rapi_bind: Bind parameters need to be a list of length %i", stmt->stmt->n_param);
142: 	}
143: 
144: 	R_len_t n_rows = Rf_length(params[0]);
145: 
146: 	for (auto param = std::next(params.begin()); param != params.end(); ++param) {
147: 		if (Rf_length(*param) != n_rows) {
148: 			cpp11::stop("rapi_bind: Bind parameter values need to have the same length");
149: 		}
150: 	}
151: 
152: 	if (n_rows != 1 && arrow) {
153: 		cpp11::stop("rapi_bind: Bind parameter values need to have length one for arrow queries");
154: 	}
155: 
156: 	cpp11::writable::list out;
157: 	out.reserve(n_rows);
158: 
159: 	for (idx_t row_idx = 0; row_idx < (size_t)n_rows; ++row_idx) {
160: 		for (idx_t param_idx = 0; param_idx < (idx_t)params.size(); param_idx++) {
161: 			SEXP valsexp = params[(size_t)param_idx];
162: 			auto val = RApiTypes::SexpToValue(valsexp, row_idx);
163: 			stmt->parameters[param_idx] = val;
164: 		}
165: 
166: 		// No protection, assigned immediately
167: 		out.push_back(rapi_execute(stmt, arrow));
168: 	}
169: 
170: 	return out;
171: }
172: 
173: static SEXP allocate(const LogicalType &type, RProtector &r_varvalue, idx_t nrows) {
174: 	SEXP varvalue = NULL;
175: 	switch (type.id()) {
176: 	case LogicalTypeId::BOOLEAN:
177: 		varvalue = r_varvalue.Protect(NEW_LOGICAL(nrows));
178: 		break;
179: 	case LogicalTypeId::UTINYINT:
180: 	case LogicalTypeId::TINYINT:
181: 	case LogicalTypeId::SMALLINT:
182: 	case LogicalTypeId::USMALLINT:
183: 	case LogicalTypeId::INTEGER:
184: 		varvalue = r_varvalue.Protect(NEW_INTEGER(nrows));
185: 		break;
186: 	case LogicalTypeId::UINTEGER:
187: 	case LogicalTypeId::UBIGINT:
188: 	case LogicalTypeId::BIGINT:
189: 	case LogicalTypeId::HUGEINT:
190: 	case LogicalTypeId::FLOAT:
191: 	case LogicalTypeId::DOUBLE:
192: 	case LogicalTypeId::DECIMAL:
193: 	case LogicalTypeId::TIMESTAMP_SEC:
194: 	case LogicalTypeId::TIMESTAMP_MS:
195: 	case LogicalTypeId::TIMESTAMP:
196: 	case LogicalTypeId::TIMESTAMP_TZ:
197: 	case LogicalTypeId::TIMESTAMP_NS:
198: 	case LogicalTypeId::DATE:
199: 	case LogicalTypeId::TIME:
200: 		varvalue = r_varvalue.Protect(NEW_NUMERIC(nrows));
201: 		break;
202: 	case LogicalTypeId::LIST:
203: 		varvalue = r_varvalue.Protect(NEW_LIST(nrows));
204: 		break;
205: 	case LogicalTypeId::VARCHAR: {
206: 		auto wrapper = new DuckDBAltrepStringWrapper();
207: 		wrapper->length = nrows;
208: 
209: 		cpp11::external_pointer<DuckDBAltrepStringWrapper> ptr(wrapper);
210: 		varvalue = r_varvalue.Protect(R_new_altrep(AltrepString::rclass, ptr, R_NilValue));
211: 		break;
212: 	}
213: 
214: 	case LogicalTypeId::BLOB:
215: 		varvalue = r_varvalue.Protect(NEW_LIST(nrows));
216: 		break;
217: 	case LogicalTypeId::ENUM:
218: 		varvalue = r_varvalue.Protect(NEW_INTEGER(nrows));
219: 		break;
220: 	default:
221: 		cpp11::stop("rapi_execute: Unknown column type for execute: %s", type.ToString().c_str());
222: 	}
223: 	if (!varvalue) {
224: 		throw std::bad_alloc();
225: 	}
226: 	return varvalue;
227: }
228: 
229: // Convert DuckDB's timestamp to R's timestamp (POSIXct). This is a represented as the number of seconds since the
230: // epoch, stored as a double.
231: template <LogicalTypeId>
232: double ConvertTimestampValue(int64_t timestamp);
233: 
234: template <>
235: double ConvertTimestampValue<LogicalTypeId::TIMESTAMP_SEC>(int64_t timestamp) {
236: 	return static_cast<double>(timestamp);
237: }
238: 
239: template <>
240: double ConvertTimestampValue<LogicalTypeId::TIMESTAMP_MS>(int64_t timestamp) {
241: 	return static_cast<double>(timestamp) / Interval::MSECS_PER_SEC;
242: }
243: 
244: template <>
245: double ConvertTimestampValue<LogicalTypeId::TIMESTAMP>(int64_t timestamp) {
246: 	return static_cast<double>(timestamp) / Interval::MICROS_PER_SEC;
247: }
248: 
249: template <>
250: double ConvertTimestampValue<LogicalTypeId::TIMESTAMP_TZ>(int64_t timestamp) {
251: 	return ConvertTimestampValue<LogicalTypeId::TIMESTAMP>(timestamp);
252: }
253: 
254: template <>
255: double ConvertTimestampValue<LogicalTypeId::TIMESTAMP_NS>(int64_t timestamp) {
256: 	return static_cast<double>(timestamp) / Interval::NANOS_PER_SEC;
257: }
258: 
259: template <LogicalTypeId LT>
260: void ConvertTimestampVector(Vector &src_vec, size_t count, SEXP &dest, uint64_t dest_offset) {
261: 	auto src_data = FlatVector::GetData<int64_t>(src_vec);
262: 	auto &mask = FlatVector::Validity(src_vec);
263: 	double *dest_ptr = ((double *)NUMERIC_POINTER(dest)) + dest_offset;
264: 	for (size_t row_idx = 0; row_idx < count; row_idx++) {
265: 		dest_ptr[row_idx] = !mask.RowIsValid(row_idx) ? NA_REAL : ConvertTimestampValue<LT>(src_data[row_idx]);
266: 	}
267: 
268: 	// some dresssup for R
269: 	SET_CLASS(dest, RStrings::get().POSIXct_POSIXt_str);
270: 	Rf_setAttrib(dest, RStrings::get().tzone_sym, RStrings::get().UTC_str);
271: }
272: 
273: std::once_flag nanosecond_coercion_warning;
274: 
275: static void transform(Vector &src_vec, SEXP &dest, idx_t dest_offset, idx_t n) {
276: 	switch (src_vec.GetType().id()) {
277: 	case LogicalTypeId::BOOLEAN:
278: 		VectorToR<int8_t, uint32_t>(src_vec, n, LOGICAL_POINTER(dest), dest_offset, NA_LOGICAL);
279: 		break;
280: 	case LogicalTypeId::UTINYINT:
281: 		VectorToR<uint8_t, uint32_t>(src_vec, n, INTEGER_POINTER(dest), dest_offset, NA_INTEGER);
282: 		break;
283: 	case LogicalTypeId::TINYINT:
284: 		VectorToR<int8_t, uint32_t>(src_vec, n, INTEGER_POINTER(dest), dest_offset, NA_INTEGER);
285: 		break;
286: 	case LogicalTypeId::USMALLINT:
287: 		VectorToR<uint16_t, uint32_t>(src_vec, n, INTEGER_POINTER(dest), dest_offset, NA_INTEGER);
288: 		break;
289: 	case LogicalTypeId::SMALLINT:
290: 		VectorToR<int16_t, uint32_t>(src_vec, n, INTEGER_POINTER(dest), dest_offset, NA_INTEGER);
291: 		break;
292: 	case LogicalTypeId::INTEGER:
293: 		VectorToR<int32_t, uint32_t>(src_vec, n, INTEGER_POINTER(dest), dest_offset, NA_INTEGER);
294: 		break;
295: 	case LogicalTypeId::TIMESTAMP_SEC:
296: 		ConvertTimestampVector<LogicalTypeId::TIMESTAMP_SEC>(src_vec, n, dest, dest_offset);
297: 		break;
298: 	case LogicalTypeId::TIMESTAMP_MS:
299: 		ConvertTimestampVector<LogicalTypeId::TIMESTAMP_MS>(src_vec, n, dest, dest_offset);
300: 		break;
301: 	case LogicalTypeId::TIMESTAMP:
302: 		ConvertTimestampVector<LogicalTypeId::TIMESTAMP>(src_vec, n, dest, dest_offset);
303: 		break;
304: 	case LogicalTypeId::TIMESTAMP_TZ:
305: 		ConvertTimestampVector<LogicalTypeId::TIMESTAMP_TZ>(src_vec, n, dest, dest_offset);
306: 		break;
307: 	case LogicalTypeId::TIMESTAMP_NS:
308: 		ConvertTimestampVector<LogicalTypeId::TIMESTAMP_NS>(src_vec, n, dest, dest_offset);
309: 		std::call_once(nanosecond_coercion_warning, Rf_warning,
310: 		               "Coercing nanoseconds to a lower resolution may result in a loss of data.");
311: 		break;
312: 	case LogicalTypeId::DATE: {
313: 		auto src_data = FlatVector::GetData<date_t>(src_vec);
314: 		auto &mask = FlatVector::Validity(src_vec);
315: 		double *dest_ptr = ((double *)NUMERIC_POINTER(dest)) + dest_offset;
316: 		for (size_t row_idx = 0; row_idx < n; row_idx++) {
317: 			dest_ptr[row_idx] = !mask.RowIsValid(row_idx) ? NA_REAL : (double)int32_t(src_data[row_idx]);
318: 		}
319: 
320: 		// some dresssup for R
321: 		SET_CLASS(dest, RStrings::get().Date_str);
322: 		break;
323: 	}
324: 	case LogicalTypeId::TIME: {
325: 		auto src_data = FlatVector::GetData<dtime_t>(src_vec);
326: 		auto &mask = FlatVector::Validity(src_vec);
327: 		double *dest_ptr = ((double *)NUMERIC_POINTER(dest)) + dest_offset;
328: 		for (size_t row_idx = 0; row_idx < n; row_idx++) {
329: 			if (!mask.RowIsValid(row_idx)) {
330: 				dest_ptr[row_idx] = NA_REAL;
331: 			} else {
332: 				dtime_t n = src_data[row_idx];
333: 				dest_ptr[row_idx] = n.micros / Interval::MICROS_PER_SEC;
334: 			}
335: 		}
336: 
337: 		// some dress-up for R
338: 		SET_CLASS(dest, RStrings::get().difftime_str);
339: 		Rf_setAttrib(dest, RStrings::get().units_sym, RStrings::get().secs_str);
340: 		break;
341: 	}
342: 	case LogicalTypeId::UINTEGER:
343: 		VectorToR<uint32_t, double>(src_vec, n, NUMERIC_POINTER(dest), dest_offset, NA_REAL);
344: 		break;
345: 	case LogicalTypeId::UBIGINT:
346: 		VectorToR<uint64_t, double>(src_vec, n, NUMERIC_POINTER(dest), dest_offset, NA_REAL);
347: 		break;
348: 	case LogicalTypeId::BIGINT:
349: 		VectorToR<int64_t, double>(src_vec, n, NUMERIC_POINTER(dest), dest_offset, NA_REAL);
350: 		break;
351: 	case LogicalTypeId::HUGEINT: {
352: 		auto src_data = FlatVector::GetData<hugeint_t>(src_vec);
353: 		auto &mask = FlatVector::Validity(src_vec);
354: 		double *dest_ptr = ((double *)NUMERIC_POINTER(dest)) + dest_offset;
355: 		for (size_t row_idx = 0; row_idx < n; row_idx++) {
356: 			if (!mask.RowIsValid(row_idx)) {
357: 				dest_ptr[row_idx] = NA_REAL;
358: 			} else {
359: 				Hugeint::TryCast(src_data[row_idx], dest_ptr[row_idx]);
360: 			}
361: 		}
362: 		break;
363: 	}
364: 	case LogicalTypeId::DECIMAL: {
365: 		auto &decimal_type = src_vec.GetType();
366: 		double *dest_ptr = ((double *)NUMERIC_POINTER(dest)) + dest_offset;
367: 		auto dec_scale = DecimalType::GetScale(decimal_type);
368: 		switch (decimal_type.InternalType()) {
369: 		case PhysicalType::INT16:
370: 			RDecimalCastLoop<int16_t>(src_vec, n, dest_ptr, dec_scale);
371: 			break;
372: 		case PhysicalType::INT32:
373: 			RDecimalCastLoop<int32_t>(src_vec, n, dest_ptr, dec_scale);
374: 			break;
375: 		case PhysicalType::INT64:
376: 			RDecimalCastLoop<int64_t>(src_vec, n, dest_ptr, dec_scale);
377: 			break;
378: 		case PhysicalType::INT128:
379: 			RDecimalCastLoop<hugeint_t>(src_vec, n, dest_ptr, dec_scale);
380: 			break;
381: 		default:
382: 			throw NotImplementedException("Unimplemented internal type for DECIMAL");
383: 		}
384: 		break;
385: 	}
386: 	case LogicalTypeId::FLOAT:
387: 		VectorToR<float, double>(src_vec, n, NUMERIC_POINTER(dest), dest_offset, NA_REAL);
388: 		break;
389: 
390: 	case LogicalTypeId::DOUBLE:
391: 		VectorToR<double, double>(src_vec, n, NUMERIC_POINTER(dest), dest_offset, NA_REAL);
392: 		break;
393: 	case LogicalTypeId::VARCHAR: {
394: 		auto wrapper = (DuckDBAltrepStringWrapper *)R_ExternalPtrAddr(R_altrep_data1(dest));
395: 		wrapper->vectors.emplace_back(LogicalType::VARCHAR, nullptr);
396: 		wrapper->vectors.back().Reference(src_vec);
397: 		break;
398: 	}
399: 	case LogicalTypeId::LIST: {
400: 		// figure out the total and max element length of the list vector child
401: 		auto src_data = ListVector::GetData(src_vec);
402: 		auto &child_type = ListType::GetChildType(src_vec.GetType());
403: 		Vector child_vector(child_type, nullptr);
404: 
405: 		// actual loop over rows
406: 		for (size_t row_idx = 0; row_idx < n; row_idx++) {
407: 			if (!FlatVector::Validity(src_vec).RowIsValid(row_idx)) {
408: 				SET_ELEMENT(dest, dest_offset + row_idx, Rf_ScalarLogical(NA_LOGICAL));
409: 			} else {
410: 				child_vector.Slice(ListVector::GetEntry(src_vec), src_data[row_idx].offset);
411: 
412: 				RProtector ele_prot;
413: 				// transform the list child vector to a single R SEXP
414: 				auto list_element =
415: 				    allocate(ListType::GetChildType(src_vec.GetType()), ele_prot, src_data[row_idx].length);
416: 				transform(child_vector, list_element, 0, src_data[row_idx].length);
417: 
418: 				// call R's own extract subset method
419: 				SET_ELEMENT(dest, dest_offset + row_idx, list_element);
420: 			}
421: 		}
422: 		break;
423: 	}
424: 	case LogicalTypeId::BLOB: {
425: 		auto src_ptr = FlatVector::GetData<string_t>(src_vec);
426: 		auto &mask = FlatVector::Validity(src_vec);
427: 		for (size_t row_idx = 0; row_idx < n; row_idx++) {
428: 			if (!mask.RowIsValid(row_idx)) {
429: 				SET_VECTOR_ELT(dest, dest_offset + row_idx, Rf_ScalarLogical(NA_LOGICAL));
430: 			} else {
431: 				SEXP rawval = NEW_RAW(src_ptr[row_idx].GetSize());
432: 				if (!rawval) {
433: 					throw std::bad_alloc();
434: 				}
435: 				memcpy(RAW_POINTER(rawval), src_ptr[row_idx].GetDataUnsafe(), src_ptr[row_idx].GetSize());
436: 				SET_VECTOR_ELT(dest, dest_offset + row_idx, rawval);
437: 			}
438: 		}
439: 		break;
440: 	}
441: 	case LogicalTypeId::ENUM: {
442: 		auto physical_type = src_vec.GetType().InternalType();
443: 
444: 		switch (physical_type) {
445: 		case PhysicalType::UINT8:
446: 			VectorToR<uint8_t, uint32_t>(src_vec, n, INTEGER_POINTER(dest), dest_offset, NA_INTEGER);
447: 			break;
448: 
449: 		case PhysicalType::UINT16:
450: 			VectorToR<uint16_t, uint32_t>(src_vec, n, INTEGER_POINTER(dest), dest_offset, NA_INTEGER);
451: 			break;
452: 
453: 		case PhysicalType::UINT32:
454: 			VectorToR<uint8_t, uint32_t>(src_vec, n, INTEGER_POINTER(dest), dest_offset, NA_INTEGER);
455: 			break;
456: 
457: 		default:
458: 			cpp11::stop("rapi_execute: Unknown enum type for convert: %s", TypeIdToString(physical_type).c_str());
459: 		}
460: 		// increment by one cause R factor offsets start at 1
461: 		auto dest_ptr = ((int32_t *)INTEGER_POINTER(dest)) + dest_offset;
462: 		for (idx_t i = 0; i < n; i++) {
463: 			if (dest_ptr[i] == NA_INTEGER) {
464: 				continue;
465: 			}
466: 			dest_ptr[i]++;
467: 		}
468: 
469: 		auto &str_vec = EnumType::GetValuesInsertOrder(src_vec.GetType());
470: 		auto size = EnumType::GetSize(src_vec.GetType());
471: 		vector<string> str_c_vec(size);
472: 		for (idx_t i = 0; i < size; i++) {
473: 			str_c_vec[i] = str_vec.GetValue(i).ToString();
474: 		}
475: 
476: 		SET_LEVELS(dest, StringsToSexp(str_c_vec));
477: 		SET_CLASS(dest, RStrings::get().factor_str);
478: 		break;
479: 	}
480: 	default:
481: 		cpp11::stop("rapi_execute: Unknown column type for convert: %s", src_vec.GetType().ToString().c_str());
482: 		break;
483: 	}
484: }
485: 
486: static SEXP duckdb_execute_R_impl(MaterializedQueryResult *result) {
487: 	// step 2: create result data frame and allocate columns
488: 	uint32_t ncols = result->types.size();
489: 	if (ncols == 0) {
490: 		return Rf_ScalarReal(0); // no need for protection because no allocation can happen afterwards
491: 	}
492: 
493: 	uint64_t nrows = result->collection.Count();
494: 	cpp11::list retlist(NEW_LIST(ncols));
495: 	SET_NAMES(retlist, StringsToSexp(result->names));
496: 
497: 	for (size_t col_idx = 0; col_idx < ncols; col_idx++) {
498: 		// TODO move the protector to allocate?
499: 		RProtector r_varvalue;
500: 		auto varvalue = allocate(result->types[col_idx], r_varvalue, nrows);
501: 		SET_VECTOR_ELT(retlist, col_idx, varvalue);
502: 	}
503: 
504: 	// at this point retlist is fully allocated and the only protected SEXP
505: 
506: 	// step 3: set values from chunks
507: 	uint64_t dest_offset = 0;
508: 	idx_t chunk_idx = 0;
509: 	while (true) {
510: 		auto chunk = result->Fetch();
511: 		if (!chunk || chunk->size() == 0) {
512: 			break;
513: 		}
514: 
515: 		D_ASSERT(chunk->ColumnCount() == ncols);
516: 		D_ASSERT(chunk->ColumnCount() == (idx_t)Rf_length(retlist));
517: 		for (size_t col_idx = 0; col_idx < chunk->ColumnCount(); col_idx++) {
518: 			SEXP dest = VECTOR_ELT(retlist, col_idx);
519: 			transform(chunk->data[col_idx], dest, dest_offset, chunk->size());
520: 		}
521: 		dest_offset += chunk->size();
522: 		chunk_idx++;
523: 	}
524: 
525: 	D_ASSERT(dest_offset == nrows);
526: 	return retlist;
527: }
528: 
529: struct AppendableRList {
530: 	AppendableRList() {
531: 		the_list = r.Protect(NEW_LIST(capacity));
532: 	}
533: 	void PrepAppend() {
534: 		if (size >= capacity) {
535: 			capacity = capacity * 2;
536: 			SEXP new_list = r.Protect(NEW_LIST(capacity));
537: 			D_ASSERT(new_list);
538: 			for (idx_t i = 0; i < size; i++) {
539: 				SET_VECTOR_ELT(new_list, i, VECTOR_ELT(the_list, i));
540: 			}
541: 			the_list = new_list;
542: 		}
543: 	}
544: 
545: 	void Append(SEXP val) {
546: 		D_ASSERT(size < capacity);
547: 		D_ASSERT(the_list != R_NilValue);
548: 		SET_VECTOR_ELT(the_list, size++, val);
549: 	}
550: 	SEXP the_list;
551: 	idx_t capacity = 1000;
552: 	idx_t size = 0;
553: 	RProtector r;
554: };
555: 
556: bool FetchArrowChunk(QueryResult *result, AppendableRList &batches_list, ArrowArray &arrow_data,
557:                      ArrowSchema &arrow_schema, SEXP batch_import_from_c, SEXP arrow_namespace, idx_t chunk_size) {
558: 
559: 	auto data_chunk = ArrowUtil::FetchChunk(result, chunk_size);
560: 	if (!data_chunk || data_chunk->size() == 0) {
561: 		return false;
562: 	}
563: 	QueryResult::ToArrowSchema(&arrow_schema, result->types, result->names);
564: 	data_chunk->ToArrowArray(&arrow_data);
565: 	batches_list.PrepAppend();
566: 	batches_list.Append(cpp11::safe[Rf_eval](batch_import_from_c, arrow_namespace));
567: 	return true;
568: }
569: 
570: // Turn a DuckDB result set into an Arrow Table
571: [[cpp11::register]] SEXP rapi_execute_arrow(duckdb::rqry_eptr_t qry_res, int chunk_size) {
572: 	if (qry_res->result->type == QueryResultType::STREAM_RESULT) {
573: 		qry_res->result = ((StreamQueryResult *)qry_res->result.get())->Materialize();
574: 	}
575: 	auto result = qry_res->result.get();
576: 	// somewhat dark magic below
577: 	cpp11::function getNamespace = RStrings::get().getNamespace_sym;
578: 	cpp11::sexp arrow_namespace(getNamespace(RStrings::get().arrow_str));
579: 
580: 	// export schema setup
581: 	ArrowSchema arrow_schema;
582: 	cpp11::doubles schema_ptr_sexp(Rf_ScalarReal(static_cast<double>(reinterpret_cast<uintptr_t>(&arrow_schema))));
583: 	cpp11::sexp schema_import_from_c(Rf_lang2(RStrings::get().ImportSchema_sym, schema_ptr_sexp));
584: 
585: 	// export data setup
586: 	ArrowArray arrow_data;
587: 	cpp11::doubles data_ptr_sexp(Rf_ScalarReal(static_cast<double>(reinterpret_cast<uintptr_t>(&arrow_data))));
588: 	cpp11::sexp batch_import_from_c(Rf_lang3(RStrings::get().ImportRecordBatch_sym, data_ptr_sexp, schema_ptr_sexp));
589: 	// create data batches
590: 	AppendableRList batches_list;
591: 
592: 	while (FetchArrowChunk(result, batches_list, arrow_data, arrow_schema, batch_import_from_c, arrow_namespace,
593: 	                       chunk_size)) {
594: 	}
595: 
596: 	SET_LENGTH(batches_list.the_list, batches_list.size);
597: 
598: 	QueryResult::ToArrowSchema(&arrow_schema, result->types, result->names);
599: 	cpp11::sexp schema_arrow_obj(cpp11::safe[Rf_eval](schema_import_from_c, arrow_namespace));
600: 
601: 	// create arrow::Table
602: 	cpp11::sexp from_record_batches(
603: 	    Rf_lang3(RStrings::get().Table__from_record_batches_sym, batches_list.the_list, schema_arrow_obj));
604: 	return cpp11::safe[Rf_eval](from_record_batches, arrow_namespace);
605: }
606: 
607: // Turn a DuckDB result set into an RecordBatchReader
608: [[cpp11::register]] SEXP rapi_record_batch(duckdb::rqry_eptr_t qry_res, int chunk_size) {
609: 	// somewhat dark magic below
610: 	cpp11::function getNamespace = RStrings::get().getNamespace_sym;
611: 	cpp11::sexp arrow_namespace(getNamespace(RStrings::get().arrow_str));
612: 
613: 	ResultArrowArrayStreamWrapper *result_stream = new ResultArrowArrayStreamWrapper(move(qry_res->result), chunk_size);
614: 	cpp11::sexp stream_ptr_sexp(
615: 	    Rf_ScalarReal(static_cast<double>(reinterpret_cast<uintptr_t>(&result_stream->stream))));
616: 	cpp11::sexp record_batch_reader(Rf_lang2(RStrings::get().ImportRecordBatchReader_sym, stream_ptr_sexp));
617: 	return cpp11::safe[Rf_eval](record_batch_reader, arrow_namespace);
618: }
619: 
620: [[cpp11::register]] SEXP rapi_execute(duckdb::stmt_eptr_t stmt, bool arrow) {
621: 	if (!stmt || !stmt->stmt) {
622: 		cpp11::stop("rapi_execute: Invalid statement");
623: 	}
624: 
625: 	auto generic_result = stmt->stmt->Execute(stmt->parameters, arrow);
626: 	if (!generic_result->success) {
627: 		cpp11::stop("rapi_execute: Failed to run query\nError: %s", generic_result->error.c_str());
628: 	}
629: 
630: 	if (arrow) {
631: 		auto query_result = new RQueryResult();
632: 		query_result->result = move(generic_result);
633: 		rqry_eptr_t query_resultsexp(query_result);
634: 		return query_resultsexp;
635: 	} else {
636: 		D_ASSERT(generic_result->type == QueryResultType::MATERIALIZED_RESULT);
637: 		MaterializedQueryResult *result = (MaterializedQueryResult *)generic_result.get();
638: 		return duckdb_execute_R_impl(result);
639: 	}
640: }
[end of tools/rpkg/src/statement.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: