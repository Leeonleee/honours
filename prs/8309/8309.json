{
  "repo": "duckdb/duckdb",
  "pull_number": 8309,
  "instance_id": "duckdb__duckdb-8309",
  "issue_numbers": [
    "3788"
  ],
  "base_commit": "02412e10151c893be139082cf3f1362f455308b0",
  "patch": "diff --git a/.github/config/uncovered_files.csv b/.github/config/uncovered_files.csv\nindex 8f64ad822a23..5c058b055c54 100644\n--- a/.github/config/uncovered_files.csv\n+++ b/.github/config/uncovered_files.csv\n@@ -114,7 +114,6 @@ core_functions/aggregate/holistic/approximate_quantile.cpp\t29\n core_functions/aggregate/holistic/mode.cpp\t11\n core_functions/aggregate/holistic/quantile.cpp\t14\n core_functions/aggregate/holistic/reservoir_quantile.cpp\t39\n-core_functions/aggregate/nested/list.cpp\t2\n core_functions/scalar/bit/bitstring.cpp\t3\n core_functions/scalar/date/date_diff.cpp\t124\n core_functions/scalar/date/date_part.cpp\t17\ndiff --git a/benchmark/micro/window/window_list_aggr.benchmark b/benchmark/micro/window/window_list_aggr.benchmark\nnew file mode 100644\nindex 000000000000..05067586c402\n--- /dev/null\n+++ b/benchmark/micro/window/window_list_aggr.benchmark\n@@ -0,0 +1,12 @@\n+# name: benchmark/micro/window/window_list_aggr.benchmark\n+# description: List aggregate window performance\n+# group: [window]\n+\n+name List aggregate window\n+group window\n+\n+load\n+CREATE TABLE tbl AS SELECT range AS i FROM range(10000000)\n+\n+run\n+SELECT i, list(i) OVER (PARTITION BY i % 2 ORDER BY i ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING) FROM tbl;\n\\ No newline at end of file\ndiff --git a/src/common/types/list_segment.cpp b/src/common/types/list_segment.cpp\nindex 6d86941768fb..de350b605cb1 100644\n--- a/src/common/types/list_segment.cpp\n+++ b/src/common/types/list_segment.cpp\n@@ -96,7 +96,7 @@ static uint16_t GetCapacityForNewSegment(uint16_t capacity) {\n }\n \n //===--------------------------------------------------------------------===//\n-// Create & Destroy\n+// Create\n //===--------------------------------------------------------------------===//\n template <class T>\n static ListSegment *CreatePrimitiveSegment(const ListSegmentFunctions &, ArenaAllocator &allocator, uint16_t capacity) {\n@@ -174,56 +174,55 @@ static ListSegment *GetSegment(const ListSegmentFunctions &functions, ArenaAlloc\n // Append\n //===--------------------------------------------------------------------===//\n template <class T>\n-static void WriteDataToPrimitiveSegment(const ListSegmentFunctions &functions, ArenaAllocator &allocator,\n-                                        ListSegment *segment, Vector &input, idx_t &entry_idx, idx_t &count) {\n+static void WriteDataToPrimitiveSegment(const ListSegmentFunctions &, ArenaAllocator &, ListSegment *segment,\n+                                        RecursiveUnifiedVectorFormat &input_data, idx_t &entry_idx) {\n \n-\t// get the vector data and the source index of the entry that we want to write\n-\tauto input_data = FlatVector::GetData(input);\n+\tauto sel_entry_idx = input_data.unified.sel->get_index(entry_idx);\n \n \t// write null validity\n \tauto null_mask = GetNullMask(segment);\n-\tauto is_null = FlatVector::IsNull(input, entry_idx);\n-\tnull_mask[segment->count] = is_null;\n+\tauto valid = input_data.unified.validity.RowIsValid(sel_entry_idx);\n+\tnull_mask[segment->count] = !valid;\n \n \t// write value\n-\tif (!is_null) {\n-\t\tauto data = GetPrimitiveData<T>(segment);\n-\t\tStore<T>(((T *)input_data)[entry_idx], data_ptr_cast(data + segment->count));\n+\tif (valid) {\n+\t\tauto segment_data = GetPrimitiveData<T>(segment);\n+\t\tauto input_data_ptr = UnifiedVectorFormat::GetData<T>(input_data.unified);\n+\t\tStore<T>(input_data_ptr[sel_entry_idx], data_ptr_cast(segment_data + segment->count));\n \t}\n }\n \n static void WriteDataToVarcharSegment(const ListSegmentFunctions &functions, ArenaAllocator &allocator,\n-                                      ListSegment *segment, Vector &input, idx_t &entry_idx, idx_t &count) {\n+                                      ListSegment *segment, RecursiveUnifiedVectorFormat &input_data,\n+                                      idx_t &entry_idx) {\n \n-\t// get the vector data and the source index of the entry that we want to write\n-\tauto input_data = FlatVector::GetData<string_t>(input);\n+\tauto sel_entry_idx = input_data.unified.sel->get_index(entry_idx);\n \n \t// write null validity\n \tauto null_mask = GetNullMask(segment);\n-\tauto is_null = FlatVector::IsNull(input, entry_idx);\n-\tnull_mask[segment->count] = is_null;\n+\tauto valid = input_data.unified.validity.RowIsValid(sel_entry_idx);\n+\tnull_mask[segment->count] = !valid;\n \n \t// set the length of this string\n \tauto str_length_data = GetListLengthData(segment);\n \tuint64_t str_length = 0;\n \n \t// get the string\n-\tstring_t str_t;\n-\tif (!is_null) {\n-\t\tstr_t = input_data[entry_idx];\n-\t\tstr_length = str_t.GetSize();\n+\tstring_t str_entry;\n+\tif (valid) {\n+\t\tstr_entry = UnifiedVectorFormat::GetData<string_t>(input_data.unified)[sel_entry_idx];\n+\t\tstr_length = str_entry.GetSize();\n \t}\n \n \t// we can reconstruct the offset from the length\n \tStore<uint64_t>(str_length, data_ptr_cast(str_length_data + segment->count));\n-\n-\tif (is_null) {\n+\tif (!valid) {\n \t\treturn;\n \t}\n \n \t// write the characters to the linked list of child segments\n \tauto child_segments = Load<LinkedList>(data_ptr_cast(GetListChildData(segment)));\n-\tfor (char &c : str_t.GetString()) {\n+\tfor (char &c : str_entry.GetString()) {\n \t\tauto child_segment = GetSegment(functions.child_functions.back(), allocator, child_segments);\n \t\tauto data = GetPrimitiveData<char>(child_segment);\n \t\tdata[child_segment->count] = c;\n@@ -236,37 +235,31 @@ static void WriteDataToVarcharSegment(const ListSegmentFunctions &functions, Are\n }\n \n static void WriteDataToListSegment(const ListSegmentFunctions &functions, ArenaAllocator &allocator,\n-                                   ListSegment *segment, Vector &input, idx_t &entry_idx, idx_t &count) {\n+                                   ListSegment *segment, RecursiveUnifiedVectorFormat &input_data, idx_t &entry_idx) {\n \n-\t// get the vector data and the source index of the entry that we want to write\n-\tauto input_data = FlatVector::GetData<list_entry_t>(input);\n+\tauto sel_entry_idx = input_data.unified.sel->get_index(entry_idx);\n \n \t// write null validity\n \tauto null_mask = GetNullMask(segment);\n-\tauto is_null = FlatVector::IsNull(input, entry_idx);\n-\tnull_mask[segment->count] = is_null;\n+\tauto valid = input_data.unified.validity.RowIsValid(sel_entry_idx);\n+\tnull_mask[segment->count] = !valid;\n \n \t// set the length of this list\n \tauto list_length_data = GetListLengthData(segment);\n \tuint64_t list_length = 0;\n \n-\tif (!is_null) {\n+\tif (valid) {\n \t\t// get list entry information\n-\t\tauto list_entries = input_data;\n-\t\tconst auto &list_entry = list_entries[entry_idx];\n+\t\tconst auto &list_entry = UnifiedVectorFormat::GetData<list_entry_t>(input_data.unified)[sel_entry_idx];\n \t\tlist_length = list_entry.length;\n \n-\t\t// get the child vector and its data\n-\t\tauto lists_size = ListVector::GetListSize(input);\n-\t\tauto &child_vector = ListVector::GetEntry(input);\n-\n \t\t// loop over the child vector entries and recurse on them\n \t\tauto child_segments = Load<LinkedList>(data_ptr_cast(GetListChildData(segment)));\n \t\tD_ASSERT(functions.child_functions.size() == 1);\n \t\tfor (idx_t child_idx = 0; child_idx < list_entry.length; child_idx++) {\n \t\t\tauto source_idx_child = list_entry.offset + child_idx;\n-\t\t\tfunctions.child_functions[0].AppendRow(allocator, child_segments, child_vector, source_idx_child,\n-\t\t\t                                       lists_size);\n+\t\t\tfunctions.child_functions[0].AppendRow(allocator, child_segments, input_data.children.back(),\n+\t\t\t                                       source_idx_child);\n \t\t}\n \t\t// store the updated linked list\n \t\tStore<LinkedList>(child_segments, data_ptr_cast(GetListChildData(segment)));\n@@ -276,35 +269,34 @@ static void WriteDataToListSegment(const ListSegmentFunctions &functions, ArenaA\n }\n \n static void WriteDataToStructSegment(const ListSegmentFunctions &functions, ArenaAllocator &allocator,\n-                                     ListSegment *segment, Vector &input, idx_t &entry_idx, idx_t &count) {\n+                                     ListSegment *segment, RecursiveUnifiedVectorFormat &input_data, idx_t &entry_idx) {\n+\n+\tauto sel_entry_idx = input_data.unified.sel->get_index(entry_idx);\n \n \t// write null validity\n \tauto null_mask = GetNullMask(segment);\n-\tauto is_null = FlatVector::IsNull(input, entry_idx);\n-\tnull_mask[segment->count] = is_null;\n+\tauto valid = input_data.unified.validity.RowIsValid(sel_entry_idx);\n+\tnull_mask[segment->count] = !valid;\n \n \t// write value\n-\tauto &children = StructVector::GetEntries(input);\n-\tD_ASSERT(children.size() == functions.child_functions.size());\n+\tD_ASSERT(input_data.children.size() == functions.child_functions.size());\n \tauto child_list = GetStructData(segment);\n \n \t// write the data of each of the children of the struct\n-\tfor (idx_t child_count = 0; child_count < children.size(); child_count++) {\n-\t\tauto child_list_segment = Load<ListSegment *>(data_ptr_cast(child_list + child_count));\n-\t\tauto &child_function = functions.child_functions[child_count];\n-\t\tchild_function.write_data(child_function, allocator, child_list_segment, *children[child_count], entry_idx,\n-\t\t                          count);\n+\tfor (idx_t i = 0; i < input_data.children.size(); i++) {\n+\t\tauto child_list_segment = Load<ListSegment *>(data_ptr_cast(child_list + i));\n+\t\tauto &child_function = functions.child_functions[i];\n+\t\tchild_function.write_data(child_function, allocator, child_list_segment, input_data.children[i], entry_idx);\n \t\tchild_list_segment->count++;\n \t}\n }\n \n-void ListSegmentFunctions::AppendRow(ArenaAllocator &allocator, LinkedList &linked_list, Vector &input,\n-                                     idx_t &entry_idx, idx_t &count) const {\n+void ListSegmentFunctions::AppendRow(ArenaAllocator &allocator, LinkedList &linked_list,\n+                                     RecursiveUnifiedVectorFormat &input_data, idx_t &entry_idx) const {\n \n-\tD_ASSERT(input.GetVectorType() == VectorType::FLAT_VECTOR);\n \tauto &write_data_to_segment = *this;\n \tauto segment = GetSegment(write_data_to_segment, allocator, linked_list);\n-\twrite_data_to_segment.write_data(write_data_to_segment, allocator, segment, input, entry_idx, count);\n+\twrite_data_to_segment.write_data(write_data_to_segment, allocator, segment, input_data, entry_idx);\n \n \tlinked_list.total_capacity++;\n \tsegment->count++;\n@@ -458,86 +450,6 @@ void ListSegmentFunctions::BuildListVector(const LinkedList &linked_list, Vector\n \t}\n }\n \n-//===--------------------------------------------------------------------===//\n-// Copy\n-//===--------------------------------------------------------------------===//\n-template <class T>\n-static ListSegment *CopyDataFromPrimitiveSegment(const ListSegmentFunctions &, const ListSegment *source,\n-                                                 ArenaAllocator &allocator) {\n-\n-\tauto target = (ListSegment *)AllocatePrimitiveData<T>(allocator, source->capacity);\n-\tmemcpy(target, source, sizeof(ListSegment) + source->capacity * (sizeof(bool) + sizeof(T)));\n-\ttarget->next = nullptr;\n-\treturn target;\n-}\n-\n-static ListSegment *CopyDataFromListSegment(const ListSegmentFunctions &functions, const ListSegment *source,\n-                                            ArenaAllocator &allocator) {\n-\n-\t// create an empty linked list for the child vector of target\n-\tauto source_linked_child_list = Load<LinkedList>(const_data_ptr_cast(GetListChildData(source)));\n-\n-\t// create the segment\n-\tauto target = reinterpret_cast<ListSegment *>(AllocateListData(allocator, source->capacity));\n-\tmemcpy(target, source,\n-\t       sizeof(ListSegment) + source->capacity * (sizeof(bool) + sizeof(uint64_t)) + sizeof(LinkedList));\n-\ttarget->next = nullptr;\n-\n-\tauto target_linked_list = GetListChildData(target);\n-\tLinkedList linked_list(source_linked_child_list.total_capacity, nullptr, nullptr);\n-\tStore<LinkedList>(linked_list, data_ptr_cast(target_linked_list));\n-\n-\t// recurse to copy the linked child list\n-\tauto target_linked_child_list = Load<LinkedList>(data_ptr_cast(GetListChildData(target)));\n-\tD_ASSERT(functions.child_functions.size() == 1);\n-\tfunctions.child_functions[0].CopyLinkedList(source_linked_child_list, target_linked_child_list, allocator);\n-\n-\t// store the updated linked list\n-\tStore<LinkedList>(target_linked_child_list, data_ptr_cast(GetListChildData(target)));\n-\treturn target;\n-}\n-\n-static ListSegment *CopyDataFromStructSegment(const ListSegmentFunctions &functions, const ListSegment *source,\n-                                              ArenaAllocator &allocator) {\n-\n-\tauto source_child_count = functions.child_functions.size();\n-\tauto target = reinterpret_cast<ListSegment *>(AllocateStructData(allocator, source->capacity, source_child_count));\n-\tmemcpy(target, source,\n-\t       sizeof(ListSegment) + source->capacity * sizeof(bool) + source_child_count * sizeof(ListSegment *));\n-\ttarget->next = nullptr;\n-\n-\t// recurse and copy the children\n-\tauto source_child_segments = GetStructData(source);\n-\tauto target_child_segments = GetStructData(target);\n-\n-\tfor (idx_t i = 0; i < functions.child_functions.size(); i++) {\n-\t\tauto child_function = functions.child_functions[i];\n-\t\tauto source_child_segment = Load<ListSegment *>(const_data_ptr_cast(source_child_segments + i));\n-\t\tauto target_child_segment = child_function.copy_data(child_function, source_child_segment, allocator);\n-\t\tStore<ListSegment *>(target_child_segment, data_ptr_cast(target_child_segments + i));\n-\t}\n-\treturn target;\n-}\n-\n-void ListSegmentFunctions::CopyLinkedList(const LinkedList &source_list, LinkedList &target_list,\n-                                          ArenaAllocator &allocator) const {\n-\tauto &copy_data_from_segment = *this;\n-\tauto source_segment = source_list.first_segment;\n-\n-\twhile (source_segment) {\n-\t\tauto target_segment = copy_data_from_segment.copy_data(copy_data_from_segment, source_segment, allocator);\n-\t\tsource_segment = source_segment->next;\n-\n-\t\tif (!target_list.first_segment) {\n-\t\t\ttarget_list.first_segment = target_segment;\n-\t\t}\n-\t\tif (target_list.last_segment) {\n-\t\t\ttarget_list.last_segment->next = target_segment;\n-\t\t}\n-\t\ttarget_list.last_segment = target_segment;\n-\t}\n-}\n-\n //===--------------------------------------------------------------------===//\n // Functions\n //===--------------------------------------------------------------------===//\n@@ -546,7 +458,6 @@ void SegmentPrimitiveFunction(ListSegmentFunctions &functions) {\n \tfunctions.create_segment = CreatePrimitiveSegment<T>;\n \tfunctions.write_data = WriteDataToPrimitiveSegment<T>;\n \tfunctions.read_data = ReadDataFromPrimitiveSegment<T>;\n-\tfunctions.copy_data = CopyDataFromPrimitiveSegment<T>;\n }\n \n void GetSegmentDataFunctions(ListSegmentFunctions &functions, const LogicalType &type) {\n@@ -597,7 +508,6 @@ void GetSegmentDataFunctions(ListSegmentFunctions &functions, const LogicalType\n \t\tfunctions.create_segment = CreateListSegment;\n \t\tfunctions.write_data = WriteDataToVarcharSegment;\n \t\tfunctions.read_data = ReadDataFromVarcharSegment;\n-\t\tfunctions.copy_data = CopyDataFromListSegment;\n \n \t\tfunctions.child_functions.emplace_back();\n \t\tSegmentPrimitiveFunction<char>(functions.child_functions.back());\n@@ -607,7 +517,6 @@ void GetSegmentDataFunctions(ListSegmentFunctions &functions, const LogicalType\n \t\tfunctions.create_segment = CreateListSegment;\n \t\tfunctions.write_data = WriteDataToListSegment;\n \t\tfunctions.read_data = ReadDataFromListSegment;\n-\t\tfunctions.copy_data = CopyDataFromListSegment;\n \n \t\t// recurse\n \t\tfunctions.child_functions.emplace_back();\n@@ -618,7 +527,6 @@ void GetSegmentDataFunctions(ListSegmentFunctions &functions, const LogicalType\n \t\tfunctions.create_segment = CreateStructSegment;\n \t\tfunctions.write_data = WriteDataToStructSegment;\n \t\tfunctions.read_data = ReadDataFromStructSegment;\n-\t\tfunctions.copy_data = CopyDataFromStructSegment;\n \n \t\t// recurse\n \t\tauto child_types = StructType::GetChildTypes(type);\ndiff --git a/src/common/types/vector.cpp b/src/common/types/vector.cpp\nindex 8ba05d94df39..88669e151f17 100644\n--- a/src/common/types/vector.cpp\n+++ b/src/common/types/vector.cpp\n@@ -892,6 +892,27 @@ void Vector::ToUnifiedFormat(idx_t count, UnifiedVectorFormat &format) {\n \t}\n }\n \n+void Vector::RecursiveToUnifiedFormat(Vector &input, idx_t count, RecursiveUnifiedVectorFormat &data) {\n+\n+\tinput.ToUnifiedFormat(count, data.unified);\n+\n+\tif (input.GetType().InternalType() == PhysicalType::LIST) {\n+\t\tauto &child = ListVector::GetEntry(input);\n+\t\tauto child_count = ListVector::GetListSize(input);\n+\t\tdata.children.emplace_back();\n+\t\tVector::RecursiveToUnifiedFormat(child, child_count, data.children.back());\n+\n+\t} else if (input.GetType().InternalType() == PhysicalType::STRUCT) {\n+\t\tauto &children = StructVector::GetEntries(input);\n+\t\tfor (idx_t i = 0; i < children.size(); i++) {\n+\t\t\tdata.children.emplace_back();\n+\t\t}\n+\t\tfor (idx_t i = 0; i < children.size(); i++) {\n+\t\t\tVector::RecursiveToUnifiedFormat(*children[i], count, data.children[i]);\n+\t\t}\n+\t}\n+}\n+\n void Vector::Sequence(int64_t start, int64_t increment, idx_t count) {\n \tthis->vector_type = VectorType::SEQUENCE_VECTOR;\n \tthis->buffer = make_buffer<VectorBuffer>(sizeof(int64_t) * 3);\ndiff --git a/src/core_functions/aggregate/holistic/mode.cpp b/src/core_functions/aggregate/holistic/mode.cpp\nindex 967ef24b9cff..ea5be91131bb 100644\n--- a/src/core_functions/aggregate/holistic/mode.cpp\n+++ b/src/core_functions/aggregate/holistic/mode.cpp\n@@ -31,8 +31,6 @@ struct hash<duckdb::hugeint_t> {\n \n namespace duckdb {\n \n-using FrameBounds = std::pair<idx_t, idx_t>;\n-\n template <class KEY_TYPE>\n struct ModeState {\n \tstruct ModeAttr {\n@@ -225,31 +223,31 @@ struct ModeFunction {\n \t\tif (state.nonzero <= tau * state.frequency_map->size()) {\n \t\t\tstate.Reset();\n \t\t\t// for f \u2208 F do\n-\t\t\tfor (auto f = frame.first; f < frame.second; ++f) {\n+\t\t\tfor (auto f = frame.start; f < frame.end; ++f) {\n \t\t\t\tif (included(f)) {\n \t\t\t\t\tstate.ModeAdd(KEY_TYPE(data[f]), f);\n \t\t\t\t}\n \t\t\t}\n \t\t} else {\n \t\t\t// for f \u2208 P \\ F do\n-\t\t\tfor (auto p = prev.first; p < frame.first; ++p) {\n+\t\t\tfor (auto p = prev.start; p < frame.start; ++p) {\n \t\t\t\tif (included(p)) {\n \t\t\t\t\tstate.ModeRm(KEY_TYPE(data[p]), p);\n \t\t\t\t}\n \t\t\t}\n-\t\t\tfor (auto p = frame.second; p < prev.second; ++p) {\n+\t\t\tfor (auto p = frame.end; p < prev.end; ++p) {\n \t\t\t\tif (included(p)) {\n \t\t\t\t\tstate.ModeRm(KEY_TYPE(data[p]), p);\n \t\t\t\t}\n \t\t\t}\n \n \t\t\t// for f \u2208 F \\ P do\n-\t\t\tfor (auto f = frame.first; f < prev.first; ++f) {\n+\t\t\tfor (auto f = frame.start; f < prev.start; ++f) {\n \t\t\t\tif (included(f)) {\n \t\t\t\t\tstate.ModeAdd(KEY_TYPE(data[f]), f);\n \t\t\t\t}\n \t\t\t}\n-\t\t\tfor (auto f = prev.second; f < frame.second; ++f) {\n+\t\t\tfor (auto f = prev.end; f < frame.end; ++f) {\n \t\t\t\tif (included(f)) {\n \t\t\t\t\tstate.ModeAdd(KEY_TYPE(data[f]), f);\n \t\t\t\t}\ndiff --git a/src/core_functions/aggregate/holistic/quantile.cpp b/src/core_functions/aggregate/holistic/quantile.cpp\nindex 88f58cfe8daa..e1120f7b28cf 100644\n--- a/src/core_functions/aggregate/holistic/quantile.cpp\n+++ b/src/core_functions/aggregate/holistic/quantile.cpp\n@@ -37,8 +37,6 @@ inline interval_t operator-(const interval_t &lhs, const interval_t &rhs) {\n \treturn Interval::FromMicro(Interval::GetMicro(lhs) - Interval::GetMicro(rhs));\n }\n \n-using FrameBounds = std::pair<idx_t, idx_t>;\n-\n template <typename SAVE_TYPE>\n struct QuantileState {\n \tusing SaveType = SAVE_TYPE;\n@@ -89,7 +87,7 @@ void ReuseIndexes(idx_t *index, const FrameBounds &frame, const FrameBounds &pre\n \tidx_t j = 0;\n \n \t//  Copy overlapping indices\n-\tfor (idx_t p = 0; p < (prev.second - prev.first); ++p) {\n+\tfor (idx_t p = 0; p < (prev.end - prev.start); ++p) {\n \t\tauto idx = index[p];\n \n \t\t//  Shift down into any hole\n@@ -98,7 +96,7 @@ void ReuseIndexes(idx_t *index, const FrameBounds &frame, const FrameBounds &pre\n \t\t}\n \n \t\t//  Skip overlapping values\n-\t\tif (frame.first <= idx && idx < frame.second) {\n+\t\tif (frame.start <= idx && idx < frame.end) {\n \t\t\t++j;\n \t\t}\n \t}\n@@ -106,15 +104,15 @@ void ReuseIndexes(idx_t *index, const FrameBounds &frame, const FrameBounds &pre\n \t//  Insert new indices\n \tif (j > 0) {\n \t\t// Overlap: append the new ends\n-\t\tfor (auto f = frame.first; f < prev.first; ++f, ++j) {\n+\t\tfor (auto f = frame.start; f < prev.start; ++f, ++j) {\n \t\t\tindex[j] = f;\n \t\t}\n-\t\tfor (auto f = prev.second; f < frame.second; ++f, ++j) {\n+\t\tfor (auto f = prev.end; f < frame.end; ++f, ++j) {\n \t\t\tindex[j] = f;\n \t\t}\n \t} else {\n \t\t//  No overlap: overwrite with new values\n-\t\tfor (auto f = frame.first; f < frame.second; ++f, ++j) {\n+\t\tfor (auto f = frame.start; f < frame.end; ++f, ++j) {\n \t\t\tindex[j] = f;\n \t\t}\n \t}\n@@ -124,17 +122,17 @@ static idx_t ReplaceIndex(idx_t *index, const FrameBounds &frame, const FrameBou\n \tD_ASSERT(index);\n \n \tidx_t j = 0;\n-\tfor (idx_t p = 0; p < (prev.second - prev.first); ++p) {\n+\tfor (idx_t p = 0; p < (prev.end - prev.start); ++p) {\n \t\tauto idx = index[p];\n \t\tif (j != p) {\n \t\t\tbreak;\n \t\t}\n \n-\t\tif (frame.first <= idx && idx < frame.second) {\n+\t\tif (frame.start <= idx && idx < frame.end) {\n \t\t\t++j;\n \t\t}\n \t}\n-\tindex[j] = frame.second - 1;\n+\tindex[j] = frame.end - 1;\n \n \treturn j;\n }\n@@ -560,7 +558,7 @@ struct QuantileScalarOperation : public QuantileOperation {\n \n \t\t//  Lazily initialise frame state\n \t\tauto prev_pos = state.pos;\n-\t\tstate.SetPos(frame.second - frame.first);\n+\t\tstate.SetPos(frame.end - frame.start);\n \n \t\tauto index = state.w.data();\n \t\tD_ASSERT(index);\n@@ -572,11 +570,11 @@ struct QuantileScalarOperation : public QuantileOperation {\n \t\tconst auto q = bind_data.quantiles[0];\n \n \t\tbool replace = false;\n-\t\tif (frame.first == prev.first + 1 && frame.second == prev.second + 1) {\n+\t\tif (frame.start == prev.start + 1 && frame.end == prev.end + 1) {\n \t\t\t//  Fixed frame size\n \t\t\tconst auto j = ReplaceIndex(index, frame, prev);\n \t\t\t//\tWe can only replace if the number of NULLs has not changed\n-\t\t\tif (included.AllValid() || included(prev.first) == included(prev.second)) {\n+\t\t\tif (included.AllValid() || included(prev.start) == included(prev.end)) {\n \t\t\t\tInterpolator<DISCRETE> interp(q, prev_pos, false);\n \t\t\t\treplace = CanReplace(index, data, j, interp.FRN, interp.CRN, included);\n \t\t\t\tif (replace) {\n@@ -720,7 +718,7 @@ struct QuantileListOperation : public QuantileOperation {\n \n \t\t//  Lazily initialise frame state\n \t\tauto prev_pos = state.pos;\n-\t\tstate.SetPos(frame.second - frame.first);\n+\t\tstate.SetPos(frame.end - frame.start);\n \n \t\tauto index = state.w.data();\n \n@@ -731,11 +729,11 @@ struct QuantileListOperation : public QuantileOperation {\n \t\t// then Q25 must be recomputed, but Q50 and Q75 are unaffected.\n \t\t// For a single element list, this reduces to the scalar case.\n \t\tstd::pair<idx_t, idx_t> replaceable {state.pos, 0};\n-\t\tif (frame.first == prev.first + 1 && frame.second == prev.second + 1) {\n+\t\tif (frame.start == prev.start + 1 && frame.end == prev.end + 1) {\n \t\t\t//  Fixed frame size\n \t\t\tconst auto j = ReplaceIndex(index, frame, prev);\n \t\t\t//\tWe can only replace if the number of NULLs has not changed\n-\t\t\tif (included.AllValid() || included(prev.first) == included(prev.second)) {\n+\t\t\tif (included.AllValid() || included(prev.start) == included(prev.end)) {\n \t\t\t\tfor (const auto &q : bind_data.order) {\n \t\t\t\t\tconst auto &quantile = bind_data.quantiles[q];\n \t\t\t\t\tInterpolator<DISCRETE> interp(quantile, prev_pos, false);\n@@ -1062,7 +1060,7 @@ struct MedianAbsoluteDeviationOperation : public QuantileOperation {\n \n \t\t//  Lazily initialise frame state\n \t\tauto prev_pos = state.pos;\n-\t\tstate.SetPos(frame.second - frame.first);\n+\t\tstate.SetPos(frame.end - frame.start);\n \n \t\tauto index = state.w.data();\n \t\tD_ASSERT(index);\n@@ -1085,11 +1083,11 @@ struct MedianAbsoluteDeviationOperation : public QuantileOperation {\n \t\tconst float q = 0.5;\n \n \t\tbool replace = false;\n-\t\tif (frame.first == prev.first + 1 && frame.second == prev.second + 1) {\n+\t\tif (frame.start == prev.start + 1 && frame.end == prev.end + 1) {\n \t\t\t//  Fixed frame size\n \t\t\tconst auto j = ReplaceIndex(index, frame, prev);\n \t\t\t//\tWe can only replace if the number of NULLs has not changed\n-\t\t\tif (included.AllValid() || included(prev.first) == included(prev.second)) {\n+\t\t\tif (included.AllValid() || included(prev.start) == included(prev.end)) {\n \t\t\t\tInterpolator<false> interp(q, prev_pos, false);\n \t\t\t\treplace = CanReplace(index, data, j, interp.FRN, interp.CRN, included);\n \t\t\t\tif (replace) {\ndiff --git a/src/core_functions/aggregate/nested/list.cpp b/src/core_functions/aggregate/nested/list.cpp\nindex a720e769dfdb..34713638088b 100644\n--- a/src/core_functions/aggregate/nested/list.cpp\n+++ b/src/core_functions/aggregate/nested/list.cpp\n@@ -5,24 +5,6 @@\n \n namespace duckdb {\n \n-static void RecursiveFlatten(Vector &vector, idx_t &count) {\n-\tif (vector.GetVectorType() != VectorType::FLAT_VECTOR) {\n-\t\tvector.Flatten(count);\n-\t}\n-\n-\tauto internal_type = vector.GetType().InternalType();\n-\tif (internal_type == PhysicalType::LIST) {\n-\t\tauto &child_vector = ListVector::GetEntry(vector);\n-\t\tauto child_vector_count = ListVector::GetListSize(vector);\n-\t\tRecursiveFlatten(child_vector, child_vector_count);\n-\t} else if (internal_type == PhysicalType::STRUCT) {\n-\t\tauto &children = StructVector::GetEntries(vector);\n-\t\tfor (auto &child : children) {\n-\t\t\tRecursiveFlatten(*child, count);\n-\t\t}\n-\t}\n-}\n-\n struct ListBindData : public FunctionData {\n \texplicit ListBindData(const LogicalType &stype_p);\n \t~ListBindData() override;\n@@ -60,12 +42,6 @@ struct ListFunction {\n \t\tstate.linked_list.first_segment = nullptr;\n \t\tstate.linked_list.last_segment = nullptr;\n \t}\n-\n-\ttemplate <class STATE>\n-\tstatic void Destroy(STATE &state, AggregateInputData &aggr_input_data) {\n-\t\t// nop\n-\t}\n-\n \tstatic bool IgnoreNull() {\n \t\treturn false;\n \t}\n@@ -73,58 +49,54 @@ struct ListFunction {\n \n static void ListUpdateFunction(Vector inputs[], AggregateInputData &aggr_input_data, idx_t input_count,\n                                Vector &state_vector, idx_t count) {\n-\tD_ASSERT(input_count == 1);\n \n+\tD_ASSERT(input_count == 1);\n \tauto &input = inputs[0];\n-\tUnifiedVectorFormat sdata;\n-\tstate_vector.ToUnifiedFormat(count, sdata);\n+\tRecursiveUnifiedVectorFormat input_data;\n+\tVector::RecursiveToUnifiedFormat(input, count, input_data);\n \n-\tauto states = UnifiedVectorFormat::GetData<ListAggState *>(sdata);\n-\tRecursiveFlatten(input, count);\n+\tUnifiedVectorFormat states_data;\n+\tstate_vector.ToUnifiedFormat(count, states_data);\n+\tauto states = UnifiedVectorFormat::GetData<ListAggState *>(states_data);\n \n \tauto &list_bind_data = aggr_input_data.bind_data->Cast<ListBindData>();\n \n \tfor (idx_t i = 0; i < count; i++) {\n-\t\tauto &state = *states[sdata.sel->get_index(i)];\n-\t\tlist_bind_data.functions.AppendRow(aggr_input_data.allocator, state.linked_list, input, i, count);\n+\t\tauto &state = *states[states_data.sel->get_index(i)];\n+\t\tlist_bind_data.functions.AppendRow(aggr_input_data.allocator, state.linked_list, input_data, i);\n \t}\n }\n \n-static void ListCombineFunction(Vector &state, Vector &combined, AggregateInputData &aggr_input_data, idx_t count) {\n-\tUnifiedVectorFormat sdata;\n-\tstate.ToUnifiedFormat(count, sdata);\n-\tauto states_ptr = UnifiedVectorFormat::GetData<ListAggState *>(sdata);\n+static void ListCombineFunction(Vector &states_vector, Vector &combined, AggregateInputData &, idx_t count) {\n \n-\tauto &list_bind_data = aggr_input_data.bind_data->Cast<ListBindData>();\n+\tUnifiedVectorFormat states_data;\n+\tstates_vector.ToUnifiedFormat(count, states_data);\n+\tauto states_ptr = UnifiedVectorFormat::GetData<ListAggState *>(states_data);\n \n \tauto combined_ptr = FlatVector::GetData<ListAggState *>(combined);\n \tfor (idx_t i = 0; i < count; i++) {\n-\t\tauto &state = *states_ptr[sdata.sel->get_index(i)];\n-\t\tif (state.linked_list.total_capacity == 0) {\n-\t\t\t// NULL, no need to append.\n-\t\t\tcontinue;\n-\t\t}\n \n-\t\t// copy the linked list of the state\n-\t\tauto copied_linked_list = LinkedList(state.linked_list.total_capacity, nullptr, nullptr);\n-\t\tlist_bind_data.functions.CopyLinkedList(state.linked_list, copied_linked_list, aggr_input_data.allocator);\n+\t\tauto &state = *states_ptr[states_data.sel->get_index(i)];\n+\t\tD_ASSERT(state.linked_list.total_capacity != 0);\n \n-\t\t// append the copied linked list to the combined state\n-\t\tif (combined_ptr[i]->linked_list.last_segment) {\n-\t\t\tcombined_ptr[i]->linked_list.last_segment->next = copied_linked_list.first_segment;\n-\t\t} else {\n-\t\t\tcombined_ptr[i]->linked_list.first_segment = copied_linked_list.first_segment;\n+\t\tif (combined_ptr[i]->linked_list.total_capacity == 0) {\n+\t\t\tcombined_ptr[i]->linked_list = state.linked_list;\n+\t\t\tcontinue;\n \t\t}\n-\t\tcombined_ptr[i]->linked_list.last_segment = copied_linked_list.last_segment;\n-\t\tcombined_ptr[i]->linked_list.total_capacity += copied_linked_list.total_capacity;\n+\n+\t\t// append the linked list\n+\t\tcombined_ptr[i]->linked_list.last_segment->next = state.linked_list.first_segment;\n+\t\tcombined_ptr[i]->linked_list.last_segment = state.linked_list.last_segment;\n+\t\tcombined_ptr[i]->linked_list.total_capacity += state.linked_list.total_capacity;\n \t}\n }\n \n-static void ListFinalize(Vector &state_vector, AggregateInputData &aggr_input_data, Vector &result, idx_t count,\n+static void ListFinalize(Vector &states_vector, AggregateInputData &aggr_input_data, Vector &result, idx_t count,\n                          idx_t offset) {\n-\tUnifiedVectorFormat sdata;\n-\tstate_vector.ToUnifiedFormat(count, sdata);\n-\tauto states = UnifiedVectorFormat::GetData<ListAggState *>(sdata);\n+\n+\tUnifiedVectorFormat states_data;\n+\tstates_vector.ToUnifiedFormat(count, states_data);\n+\tauto states = UnifiedVectorFormat::GetData<ListAggState *>(states_data);\n \n \tD_ASSERT(result.GetType().id() == LogicalTypeId::LIST);\n \n@@ -133,9 +105,11 @@ static void ListFinalize(Vector &state_vector, AggregateInputData &aggr_input_da\n \tsize_t total_len = ListVector::GetListSize(result);\n \n \tauto &list_bind_data = aggr_input_data.bind_data->Cast<ListBindData>();\n-\t// first iterate over all of the entries and set up the list entries, plus get the newly required total length\n+\n+\t// first iterate over all entries and set up the list entries, and get the newly required total length\n \tfor (idx_t i = 0; i < count; i++) {\n-\t\tauto &state = *states[sdata.sel->get_index(i)];\n+\n+\t\tauto &state = *states[states_data.sel->get_index(i)];\n \t\tconst auto rid = i + offset;\n \t\tresult_data[rid].offset = total_len;\n \t\tif (state.linked_list.total_capacity == 0) {\n@@ -143,16 +117,19 @@ static void ListFinalize(Vector &state_vector, AggregateInputData &aggr_input_da\n \t\t\tresult_data[rid].length = 0;\n \t\t\tcontinue;\n \t\t}\n+\n \t\t// set the length and offset of this list in the result vector\n \t\tauto total_capacity = state.linked_list.total_capacity;\n \t\tresult_data[rid].length = total_capacity;\n \t\ttotal_len += total_capacity;\n \t}\n-\t// reserve capacity, then iterate over all of the entries again and copy over the data tot he child vector\n+\n+\t// reserve capacity, then iterate over all entries again and copy over the data to the child vector\n \tListVector::Reserve(result, total_len);\n \tauto &result_child = ListVector::GetEntry(result);\n \tfor (idx_t i = 0; i < count; i++) {\n-\t\tauto &state = *states[sdata.sel->get_index(i)];\n+\n+\t\tauto &state = *states[states_data.sel->get_index(i)];\n \t\tconst auto rid = i + offset;\n \t\tif (state.linked_list.total_capacity == 0) {\n \t\t\tcontinue;\n@@ -161,6 +138,48 @@ static void ListFinalize(Vector &state_vector, AggregateInputData &aggr_input_da\n \t\tidx_t current_offset = result_data[rid].offset;\n \t\tlist_bind_data.functions.BuildListVector(state.linked_list, result_child, current_offset);\n \t}\n+\n+\tListVector::SetListSize(result, total_len);\n+}\n+\n+static void ListWindow(Vector inputs[], const ValidityMask &filter_mask, AggregateInputData &aggr_input_data,\n+                       idx_t input_count, data_ptr_t state, const FrameBounds &frame, const FrameBounds &prev,\n+                       Vector &result, idx_t rid, idx_t bias) {\n+\n+\tauto &list_bind_data = aggr_input_data.bind_data->Cast<ListBindData>();\n+\tLinkedList linked_list;\n+\n+\t// UPDATE step\n+\n+\tD_ASSERT(input_count == 1);\n+\tauto &input = inputs[0];\n+\n+\t// FIXME: we unify more values than necessary (count is frame.end)\n+\tRecursiveUnifiedVectorFormat input_data;\n+\tVector::RecursiveToUnifiedFormat(input, frame.end, input_data);\n+\n+\tfor (idx_t i = frame.start; i < frame.end; i++) {\n+\t\tlist_bind_data.functions.AppendRow(aggr_input_data.allocator, linked_list, input_data, i);\n+\t}\n+\n+\t// FINALIZE step\n+\n+\tD_ASSERT(result.GetType().id() == LogicalTypeId::LIST);\n+\tauto result_data = FlatVector::GetData<list_entry_t>(result);\n+\tsize_t total_len = ListVector::GetListSize(result);\n+\n+\t// set the length and offset of this list in the result vector\n+\tresult_data[rid].offset = total_len;\n+\tresult_data[rid].length = linked_list.total_capacity;\n+\tD_ASSERT(linked_list.total_capacity != 0);\n+\ttotal_len += linked_list.total_capacity;\n+\n+\t// reserve capacity, then copy over the data to the child vector\n+\tListVector::Reserve(result, total_len);\n+\tauto &result_child = ListVector::GetEntry(result);\n+\tidx_t offset = result_data[rid].offset;\n+\tlist_bind_data.functions.BuildListVector(linked_list, result_child, offset);\n+\n \tListVector::SetListSize(result, total_len);\n }\n \n@@ -182,8 +201,8 @@ unique_ptr<FunctionData> ListBindFunction(ClientContext &context, AggregateFunct\n AggregateFunction ListFun::GetFunction() {\n \treturn AggregateFunction({LogicalType::ANY}, LogicalTypeId::LIST, AggregateFunction::StateSize<ListAggState>,\n \t                         AggregateFunction::StateInitialize<ListAggState, ListFunction>, ListUpdateFunction,\n-\t                         ListCombineFunction, ListFinalize, nullptr, ListBindFunction,\n-\t                         AggregateFunction::StateDestroy<ListAggState, ListFunction>, nullptr, nullptr);\n+\t                         ListCombineFunction, ListFinalize, nullptr, ListBindFunction, nullptr, nullptr,\n+\t                         ListWindow);\n }\n \n } // namespace duckdb\ndiff --git a/src/execution/aggregate_hashtable.cpp b/src/execution/aggregate_hashtable.cpp\nindex 72ec38823486..9c23cca4a4bc 100644\n--- a/src/execution/aggregate_hashtable.cpp\n+++ b/src/execution/aggregate_hashtable.cpp\n@@ -584,6 +584,12 @@ void GroupedAggregateHashTable::Combine(GroupedAggregateHashTable &other) {\n \t}\n \n \tVerify();\n+\n+\t// if we combine states, then we also need to combine the arena allocators\n+\tfor (auto &stored_allocator : other.stored_allocators) {\n+\t\tstored_allocators.push_back(stored_allocator);\n+\t}\n+\tstored_allocators.push_back(other.aggregate_allocator);\n }\n \n void GroupedAggregateHashTable::Append(GroupedAggregateHashTable &other) {\ndiff --git a/src/execution/perfect_aggregate_hashtable.cpp b/src/execution/perfect_aggregate_hashtable.cpp\nindex 98baf412b895..826b1d55ad0f 100644\n--- a/src/execution/perfect_aggregate_hashtable.cpp\n+++ b/src/execution/perfect_aggregate_hashtable.cpp\n@@ -12,7 +12,8 @@ PerfectAggregateHashTable::PerfectAggregateHashTable(ClientContext &context, All\n                                                      vector<Value> group_minima_p, vector<idx_t> required_bits_p)\n     : BaseAggregateHashTable(context, allocator, aggregate_objects_p, std::move(payload_types_p)),\n       addresses(LogicalType::POINTER), required_bits(std::move(required_bits_p)), total_required_bits(0),\n-      group_minima(std::move(group_minima_p)), sel(STANDARD_VECTOR_SIZE), aggregate_allocator(allocator) {\n+      group_minima(std::move(group_minima_p)), sel(STANDARD_VECTOR_SIZE),\n+      aggregate_allocator(make_uniq<ArenaAllocator>(allocator)) {\n \tfor (auto &group_bits : required_bits) {\n \t\ttotal_required_bits += group_bits;\n \t}\n@@ -136,7 +137,7 @@ void PerfectAggregateHashTable::AddChunk(DataChunk &groups, DataChunk &payload)\n \t// after finding the group location we update the aggregates\n \tidx_t payload_idx = 0;\n \tauto &aggregates = layout.GetAggregates();\n-\tRowOperationsState row_state(aggregate_allocator);\n+\tRowOperationsState row_state(*aggregate_allocator);\n \tfor (idx_t aggr_idx = 0; aggr_idx < aggregates.size(); aggr_idx++) {\n \t\tauto &aggregate = aggregates[aggr_idx];\n \t\tauto input_count = (idx_t)aggregate.child_count;\n@@ -165,7 +166,7 @@ void PerfectAggregateHashTable::Combine(PerfectAggregateHashTable &other) {\n \tdata_ptr_t source_ptr = other.data;\n \tdata_ptr_t target_ptr = data;\n \tidx_t combine_count = 0;\n-\tRowOperationsState row_state(aggregate_allocator);\n+\tRowOperationsState row_state(*aggregate_allocator);\n \tfor (idx_t i = 0; i < total_groups; i++) {\n \t\tauto has_entry_source = other.group_is_set[i];\n \t\t// we only have any work to do if the source has an entry for this group\n@@ -183,6 +184,11 @@ void PerfectAggregateHashTable::Combine(PerfectAggregateHashTable &other) {\n \t\ttarget_ptr += tuple_size;\n \t}\n \tRowOperations::CombineStates(row_state, layout, source_addresses, target_addresses, combine_count);\n+\n+\t// FIXME: after moving the arena allocator, we currently have to ensure that the pointer is not nullptr, because the\n+\t// FIXME: Destroy()-function of the hash table expects an allocator in some cases (e.g., for sorted aggregates)\n+\tstored_allocators.push_back(std::move(other.aggregate_allocator));\n+\tother.aggregate_allocator = make_uniq<ArenaAllocator>(allocator);\n }\n \n template <class T>\n@@ -268,7 +274,7 @@ void PerfectAggregateHashTable::Scan(idx_t &scan_position, DataChunk &result) {\n \t}\n \t// then construct the payloads\n \tresult.SetCardinality(entry_count);\n-\tRowOperationsState row_state(aggregate_allocator);\n+\tRowOperationsState row_state(*aggregate_allocator);\n \tRowOperations::FinalizeStates(row_state, layout, addresses, result, grouping_columns);\n }\n \n@@ -289,7 +295,7 @@ void PerfectAggregateHashTable::Destroy() {\n \tidx_t count = 0;\n \n \t// iterate over all initialised slots of the hash table\n-\tRowOperationsState row_state(aggregate_allocator);\n+\tRowOperationsState row_state(*aggregate_allocator);\n \tdata_ptr_t payload_ptr = data;\n \tfor (idx_t i = 0; i < total_groups; i++) {\n \t\tif (group_is_set[i]) {\ndiff --git a/src/execution/window_executor.cpp b/src/execution/window_executor.cpp\nindex 168711999dab..a3cc0585449a 100644\n--- a/src/execution/window_executor.cpp\n+++ b/src/execution/window_executor.cpp\n@@ -204,19 +204,19 @@ static idx_t FindTypedRangeBound(const WindowInputColumn &over, const idx_t orde\n \tWindowColumnIterator<T> begin(over, order_begin);\n \tWindowColumnIterator<T> end(over, order_end);\n \n-\tif (order_begin < prev.first && prev.first < order_end) {\n-\t\tconst auto first = over.GetCell<T>(prev.first);\n+\tif (order_begin < prev.start && prev.start < order_end) {\n+\t\tconst auto first = over.GetCell<T>(prev.start);\n \t\tif (!comp(val, first)) {\n \t\t\t//\tprev.first <= val, so we can start further forward\n-\t\t\tbegin += (prev.first - order_begin);\n+\t\t\tbegin += (prev.start - order_begin);\n \t\t}\n \t}\n-\tif (order_begin <= prev.second && prev.second < order_end) {\n-\t\tconst auto second = over.GetCell<T>(prev.second);\n+\tif (order_begin <= prev.end && prev.end < order_end) {\n+\t\tconst auto second = over.GetCell<T>(prev.end);\n \t\tif (!comp(second, val)) {\n \t\t\t//\tval <= prev.second, so we can end further back\n \t\t\t// (prev.second is the largest peer)\n-\t\t\tend -= (order_end - prev.second - 1);\n+\t\t\tend -= (order_end - prev.end - 1);\n \t\t}\n \t}\n \n@@ -278,8 +278,6 @@ static idx_t FindOrderedRangeBound(const WindowInputColumn &over, const OrderTyp\n }\n \n struct WindowBoundariesState {\n-\tusing FrameBounds = std::pair<idx_t, idx_t>;\n-\n \tstatic inline bool IsScalar(const unique_ptr<Expression> &expr) {\n \t\treturn expr ? expr->IsScalar() : true;\n \t}\n@@ -375,8 +373,8 @@ void WindowBoundariesState::Update(const idx_t row_idx, const WindowInputColumn\n \t\t\t\t}\n \n \t\t\t\t//\tReset range hints\n-\t\t\t\tprev.first = valid_start;\n-\t\t\t\tprev.second = valid_end;\n+\t\t\t\tprev.start = valid_start;\n+\t\t\t\tprev.end = valid_end;\n \t\t\t}\n \t\t} else if (!is_peer) {\n \t\t\tpeer_start = row_idx;\n@@ -427,9 +425,9 @@ void WindowBoundariesState::Update(const idx_t row_idx, const WindowInputColumn\n \t\tif (boundary_start.CellIsNull(chunk_idx)) {\n \t\t\twindow_start = peer_start;\n \t\t} else {\n-\t\t\tprev.first = FindOrderedRangeBound<true>(range_collection, range_sense, valid_start, row_idx,\n+\t\t\tprev.start = FindOrderedRangeBound<true>(range_collection, range_sense, valid_start, row_idx,\n \t\t\t                                         boundary_start, chunk_idx, prev);\n-\t\t\twindow_start = prev.first;\n+\t\t\twindow_start = prev.start;\n \t\t}\n \t\tbreak;\n \t}\n@@ -437,9 +435,9 @@ void WindowBoundariesState::Update(const idx_t row_idx, const WindowInputColumn\n \t\tif (boundary_start.CellIsNull(chunk_idx)) {\n \t\t\twindow_start = peer_start;\n \t\t} else {\n-\t\t\tprev.first = FindOrderedRangeBound<true>(range_collection, range_sense, row_idx, valid_end, boundary_start,\n+\t\t\tprev.start = FindOrderedRangeBound<true>(range_collection, range_sense, row_idx, valid_end, boundary_start,\n \t\t\t                                         chunk_idx, prev);\n-\t\t\twindow_start = prev.first;\n+\t\t\twindow_start = prev.start;\n \t\t}\n \t\tbreak;\n \t}\n@@ -472,9 +470,9 @@ void WindowBoundariesState::Update(const idx_t row_idx, const WindowInputColumn\n \t\tif (boundary_end.CellIsNull(chunk_idx)) {\n \t\t\twindow_end = peer_end;\n \t\t} else {\n-\t\t\tprev.second = FindOrderedRangeBound<false>(range_collection, range_sense, valid_start, row_idx,\n-\t\t\t                                           boundary_end, chunk_idx, prev);\n-\t\t\twindow_end = prev.second;\n+\t\t\tprev.end = FindOrderedRangeBound<false>(range_collection, range_sense, valid_start, row_idx, boundary_end,\n+\t\t\t                                        chunk_idx, prev);\n+\t\t\twindow_end = prev.end;\n \t\t}\n \t\tbreak;\n \t}\n@@ -482,9 +480,9 @@ void WindowBoundariesState::Update(const idx_t row_idx, const WindowInputColumn\n \t\tif (boundary_end.CellIsNull(chunk_idx)) {\n \t\t\twindow_end = peer_end;\n \t\t} else {\n-\t\t\tprev.second = FindOrderedRangeBound<false>(range_collection, range_sense, row_idx, valid_end, boundary_end,\n-\t\t\t                                           chunk_idx, prev);\n-\t\t\twindow_end = prev.second;\n+\t\t\tprev.end = FindOrderedRangeBound<false>(range_collection, range_sense, row_idx, valid_end, boundary_end,\n+\t\t\t                                        chunk_idx, prev);\n+\t\t\twindow_end = prev.end;\n \t\t}\n \t\tbreak;\n \t}\ndiff --git a/src/function/aggregate/distributive/count.cpp b/src/function/aggregate/distributive/count.cpp\nindex 1f1c482835e8..ec9d705bb898 100644\n--- a/src/function/aggregate/distributive/count.cpp\n+++ b/src/function/aggregate/distributive/count.cpp\n@@ -39,8 +39,8 @@ struct CountStarFunction : public BaseCountFunction {\n \t                   Vector &result, idx_t rid, idx_t bias) {\n \t\tD_ASSERT(input_count == 0);\n \t\tauto data = FlatVector::GetData<RESULT_TYPE>(result);\n-\t\tconst auto begin = frame.first;\n-\t\tconst auto end = frame.second;\n+\t\tconst auto begin = frame.start;\n+\t\tconst auto end = frame.end;\n \t\t// Slice to any filtered rows\n \t\tif (!filter_mask.AllValid()) {\n \t\t\tRESULT_TYPE filtered = 0;\ndiff --git a/src/include/duckdb/common/types/list_segment.hpp b/src/include/duckdb/common/types/list_segment.hpp\nindex 0996c9f53604..ea4c2ad89f00 100644\n--- a/src/include/duckdb/common/types/list_segment.hpp\n+++ b/src/include/duckdb/common/types/list_segment.hpp\n@@ -22,14 +22,14 @@ struct ListSegment {\n \tListSegment *next;\n };\n struct LinkedList {\n-\tLinkedList() {};\n+\tLinkedList() : total_capacity(0), first_segment(nullptr), last_segment(nullptr) {};\n \tLinkedList(idx_t total_capacity_p, ListSegment *first_segment_p, ListSegment *last_segment_p)\n \t    : total_capacity(total_capacity_p), first_segment(first_segment_p), last_segment(last_segment_p) {\n \t}\n \n-\tidx_t total_capacity = 0;\n-\tListSegment *first_segment = nullptr;\n-\tListSegment *last_segment = nullptr;\n+\tidx_t total_capacity;\n+\tListSegment *first_segment;\n+\tListSegment *last_segment;\n };\n \n // forward declarations\n@@ -37,23 +37,21 @@ struct ListSegmentFunctions;\n typedef ListSegment *(*create_segment_t)(const ListSegmentFunctions &functions, ArenaAllocator &allocator,\n                                          uint16_t capacity);\n typedef void (*write_data_to_segment_t)(const ListSegmentFunctions &functions, ArenaAllocator &allocator,\n-                                        ListSegment *segment, Vector &input, idx_t &entry_idx, idx_t &count);\n+                                        ListSegment *segment, RecursiveUnifiedVectorFormat &input_data,\n+                                        idx_t &entry_idx);\n typedef void (*read_data_from_segment_t)(const ListSegmentFunctions &functions, const ListSegment *segment,\n                                          Vector &result, idx_t &total_count);\n-typedef ListSegment *(*copy_data_from_segment_t)(const ListSegmentFunctions &functions, const ListSegment *source,\n-                                                 ArenaAllocator &allocator);\n \n struct ListSegmentFunctions {\n \tcreate_segment_t create_segment;\n \twrite_data_to_segment_t write_data;\n \tread_data_from_segment_t read_data;\n-\tcopy_data_from_segment_t copy_data;\n+\n \tvector<ListSegmentFunctions> child_functions;\n \n-\tvoid AppendRow(ArenaAllocator &allocator, LinkedList &linked_list, Vector &input, idx_t &entry_idx,\n-\t               idx_t &count) const;\n+\tvoid AppendRow(ArenaAllocator &allocator, LinkedList &linked_list, RecursiveUnifiedVectorFormat &input_data,\n+\t               idx_t &entry_idx) const;\n \tvoid BuildListVector(const LinkedList &linked_list, Vector &result, idx_t &initial_total_count) const;\n-\tvoid CopyLinkedList(const LinkedList &source_list, LinkedList &target_list, ArenaAllocator &allocator) const;\n };\n \n void GetSegmentDataFunctions(ListSegmentFunctions &functions, const LogicalType &type);\ndiff --git a/src/include/duckdb/common/types/vector.hpp b/src/include/duckdb/common/types/vector.hpp\nindex 68d03d07b7f5..b3091cdc42d9 100644\n--- a/src/include/duckdb/common/types/vector.hpp\n+++ b/src/include/duckdb/common/types/vector.hpp\n@@ -35,6 +35,11 @@ struct UnifiedVectorFormat {\n \t}\n };\n \n+struct RecursiveUnifiedVectorFormat {\n+\tUnifiedVectorFormat unified;\n+\tvector<RecursiveUnifiedVectorFormat> children;\n+};\n+\n class VectorCache;\n class VectorStructBuffer;\n class VectorListBuffer;\n@@ -140,6 +145,8 @@ class Vector {\n \t//! The most common vector types (flat, constant & dictionary) can be converted to the canonical format \"for free\"\n \t//! ToUnifiedFormat was originally called Orrify, as a tribute to Orri Erling who came up with it\n \tDUCKDB_API void ToUnifiedFormat(idx_t count, UnifiedVectorFormat &data);\n+\t//! Recursively calls UnifiedVectorFormat on a vector and its child vectors (for nested types)\n+\tstatic void RecursiveToUnifiedFormat(Vector &input, idx_t count, RecursiveUnifiedVectorFormat &data);\n \n \t//! Turn the vector into a sequence vector\n \tDUCKDB_API void Sequence(int64_t start, int64_t increment, idx_t count);\ndiff --git a/src/include/duckdb/common/vector_operations/aggregate_executor.hpp b/src/include/duckdb/common/vector_operations/aggregate_executor.hpp\nindex d25f3180a53a..4a80ac81942c 100644\n--- a/src/include/duckdb/common/vector_operations/aggregate_executor.hpp\n+++ b/src/include/duckdb/common/vector_operations/aggregate_executor.hpp\n@@ -15,9 +15,14 @@\n \n namespace duckdb {\n \n+// structs\n struct AggregateInputData;\n-\n-typedef std::pair<idx_t, idx_t> FrameBounds;\n+struct FrameBounds {\n+\tFrameBounds() : start(0), end(0) {};\n+\tFrameBounds(idx_t start, idx_t end) : start(start), end(end) {};\n+\tidx_t start = 0;\n+\tidx_t end = 0;\n+};\n \n class AggregateExecutor {\n private:\ndiff --git a/src/include/duckdb/execution/perfect_aggregate_hashtable.hpp b/src/include/duckdb/execution/perfect_aggregate_hashtable.hpp\nindex 9d804850b0d0..211c27b36b22 100644\n--- a/src/include/duckdb/execution/perfect_aggregate_hashtable.hpp\n+++ b/src/include/duckdb/execution/perfect_aggregate_hashtable.hpp\n@@ -56,8 +56,10 @@ class PerfectAggregateHashTable : public BaseAggregateHashTable {\n \t//! Reused selection vector\n \tSelectionVector sel;\n \n-\t//! The arena allocator used by the aggregates for their internal state\n-\tArenaAllocator aggregate_allocator;\n+\t//! The active arena allocator used by the aggregates for their internal state\n+\tunique_ptr<ArenaAllocator> aggregate_allocator;\n+\t//! Owning arena allocators that this HT has data from\n+\tvector<unique_ptr<ArenaAllocator>> stored_allocators;\n \n private:\n \t//! Destroy the perfect aggregate HT (called automatically by the destructor)\ndiff --git a/src/include/duckdb/execution/window_segment_tree.hpp b/src/include/duckdb/execution/window_segment_tree.hpp\nindex de194c418f28..12786a19c41c 100644\n--- a/src/include/duckdb/execution/window_segment_tree.hpp\n+++ b/src/include/duckdb/execution/window_segment_tree.hpp\n@@ -117,8 +117,6 @@ class WindowCustomAggregator : public WindowAggregator {\n \n class WindowSegmentTree : public WindowAggregator {\n public:\n-\tusing FrameBounds = std::pair<idx_t, idx_t>;\n-\n \tWindowSegmentTree(AggregateObject aggr, const LogicalType &result_type, idx_t count, WindowAggregationMode mode_p);\n \t~WindowSegmentTree() override;\n \ndiff --git a/src/include/duckdb/function/aggregate_function.hpp b/src/include/duckdb/function/aggregate_function.hpp\nindex 31b2b8969d73..cee446c07236 100644\n--- a/src/include/duckdb/function/aggregate_function.hpp\n+++ b/src/include/duckdb/function/aggregate_function.hpp\n@@ -41,7 +41,6 @@ typedef void (*aggregate_simple_update_t)(Vector inputs[], AggregateInputData &a\n                                           data_ptr_t state, idx_t count);\n \n //! The type used for updating complex windowed aggregate functions (optional)\n-typedef std::pair<idx_t, idx_t> FrameBounds;\n typedef void (*aggregate_window_t)(Vector inputs[], const ValidityMask &filter_mask,\n                                    AggregateInputData &aggr_input_data, idx_t input_count, data_ptr_t state,\n                                    const FrameBounds &frame, const FrameBounds &prev, Vector &result, idx_t rid,\n",
  "test_patch": "diff --git a/test/sql/aggregate/aggregates/test_list_aggregate_function.test b/test/sql/aggregate/aggregates/test_list_aggregate_function.test\nindex 250b54387aa4..67503fbe62c0 100644\n--- a/test/sql/aggregate/aggregates/test_list_aggregate_function.test\n+++ b/test/sql/aggregate/aggregates/test_list_aggregate_function.test\n@@ -71,7 +71,6 @@ SELECT LIST(str) FROM varch GROUP BY g ORDER BY g\n # LIST\n # one level nested LIST\n \n-\n statement ok\n CREATE TABLE nested_lists (g INTEGER, i INTEGER[])\n \ndiff --git a/test/sql/types/nested/list/test_nested_list.test b/test/sql/types/nested/list/test_nested_list.test\nindex 71eecdb7bb6e..ec435478a09a 100644\n--- a/test/sql/types/nested/list/test_nested_list.test\n+++ b/test/sql/types/nested/list/test_nested_list.test\n@@ -215,7 +215,7 @@ SELECT g, LIST(STRUCT_PACK(a := e, b := e+1)) ls from list_data GROUP BY g ORDER\n \n # TODO check second col\n query IT\n-SELECT g, LIST(STRUCT_PACK(a := e, b := e+1)) ls from list_data WHERE g > 2GROUP BY g ORDER BY g\n+SELECT g, LIST(STRUCT_PACK(a := e, b := e+1)) ls from list_data WHERE g > 2 GROUP BY g ORDER BY g\n ----\n 3\t[{'a': 6, 'b': 7}]\n 5\t[{'a': NULL, 'b': NULL}]\ndiff --git a/test/sql/window/test_window_wide_frame.test_slow b/test/sql/window/test_window_wide_frame.test_slow\nindex 163799cfa67a..60ff21f30d17 100644\n--- a/test/sql/window/test_window_wide_frame.test_slow\n+++ b/test/sql/window/test_window_wide_frame.test_slow\n@@ -4,7 +4,6 @@\n \n require skip_reload\n \n-\n statement ok\n PRAGMA enable_verification\n \n@@ -15,8 +14,7 @@ statement ok\n CREATE TABLE flog AS\n \tSELECT (random() * 100)::INTEGER AS laufzeit\n \t, TIMESTAMP '2020-10-15 16:45:00' + INTERVAL (random() * 15 * 60) SECOND AS \"timestamp\"\n-\tFROM range(26000)\n-;\n+\tFROM range(26000);\n \n query III\n select timestamp\n",
  "problem_statement": "Specialize LIST aggregate function implementation\nCurrently the `LIST` aggregate function only has a generic implementation that uses a `Vector` to aggregate data. While this works in all cases, there is an opportunity to optimize this for lists of primitive types (e.g. numerics or strings). As the Vector itself holds a lot of extra data (`VectorType`, `LogicalType`, several buffers, a pointer to the data) which could be replaced with a simpler/more minimal structure. This is particularly relevant in the case of many very small lists.\r\n\r\nWe could even envision inlining simpler primitives into the actual hash table, instead of requiring a separate allocated storage area, e.g. for int32 you could envision a structure like this which would allow inlining up to 2 entries in the hash table:\r\n\r\n```cpp\r\nstruct list_data_t {\r\n  uint32_t length;\r\n  union {\r\n    struct {\r\n      uint32_t capacity;\r\n      data_ptr_t pointer;\r\n    } pointer;\r\n    struct {\r\n      bool is_null[2];\r\n      int32_t entries[2];\r\n    } inlined;\r\n  } value;\r\n}\r\n```\r\n\r\n\n",
  "hints_text": "While working on the `ColumnDataCollection` I have been thinking about how to apply it to the `LIST` aggregate. After consideration, I feel that we cannot re-use the ColumnDataCollection as-is here, since it is again not optimized for holding extremely small chunks of data. But we can use several of the implementation ideas I used there for this aggregate as well.\r\n\r\nHere is my idea for how this aggregate could be structured.\r\n\r\n## Data Structures\r\n\r\nThe data that is in the hash table looks like this (16 bytes):\r\n\r\n```cpp\r\nstruct linked_list_t {\r\n  list_vector_data_t *first_segment;\r\n  list_vector_data_t *last_segment;\r\n};\r\n\r\nstruct list_ht_data_t {\r\n  linked_list_t data;\r\n};\r\n```\r\n\r\nThe segments point to structs of the following shape:\r\n\r\n```cpp\r\nstruct list_vector_data_t {\r\n  uint16_t count;\r\n  uint16_t capacity;\r\n  list_vector_data_t *next;\r\n  bool is_null[capacity];\r\n  union {\r\n    struct {\r\n      T values[capacity];\r\n    } primitive_data;\r\n    struct {\r\n      linked_list_t child;\r\n      T list_offsets[capacity];\r\n    } list_data;\r\n    struct {\r\n      list_vector_data_t *children[child_count];\r\n    } struct_data;\r\n  }\r\n};\r\n```\r\n\r\nThe `list_vector_data_t` functions as a linked list of structures. On the top-level we have both a pointer to the first and last segments of the linked list. The last segment is used for appending (construction). The first segment is used for traversing the list in the final scan.\r\n\r\nThe `list_vector_data_t` has a child-element that is itself a linked list (in case of a LIST type), and child elements that are `list_vector_data_t` (in case of a STRUCT type). This allows for the recursive behavior that is required to model arbitrarily complex nested types in an efficient manner (1) without over-allocating in the case of many small lists, (2) without requiring a full copy when appended past the capacity, and (3) while allowing a Combine method that does not require a copy of the internals of the lists. This should make the structure efficient for both small and large lists. \r\n\r\n\r\n## Appending\r\n\r\nWhile appending, `list_vector_data_t` entries are allocated in contiguous regions of an extra heap in the hash table. I would start off by allocating this using e.g. the StringHeap class, but we can move to using buffer managed blocks and off-loading the blocks by turning the pointers into block_id + offset combinations later on.\r\n\r\nThe overhead of the structure itself is 12 bytes (2x uint16 + next pointer) per vector. At the root-level, we can start off by allocating a `list_vector_data_t` structure of capacity 4, then 8, then 16, etc.\r\n\r\nAppending works row-by-row, but should be templated on a **per-type** basis. What that means is if we have a complex structure (e.g. `STRUCT(VARCHAR, INT[])`) we should first insert the `STRUCT`, then the `VARCHAR`, then the `LIST`, then the `INT`. This way we can avoid per-value function-call overhead.\r\n\r\n## Example\r\nLet's say we have the following structure and values:\r\n\r\n```sql\r\nSTRUCT(INT[], VARCHAR, STRUCT(DOUBLE, DOUBLE))\r\n\r\n{'a': [1, 2, 3], 'b': 'hello'}\r\n{'a': [4, 5], 'b': NULL}\r\nNULL\r\n{'a': [6, NULL, 8, 9], 'b': 'world'}\r\n```\r\n\r\nThe root-level entry will be a struct:\r\n\r\n```cpp\r\n// root: struct\r\n#0 -> {\r\n  uint16_t count = 4;\r\n  uint16_t capacity = 4;\r\n  list_vector_data_t *next = NULL;\r\n  bool is_null[4] = { false, false, true, false };\r\n  list_vector_data_t *children[2] = { #1, #2 };\r\n};\r\n\r\n// child 1: list\r\n#1 -> {\r\n  uint16_t count = 4;\r\n  uint16_t capacity = 4;\r\n  list_vector_data_t *next = NULL;\r\n  bool is_null[4] = { false, false, true, false };\r\n  linked_list_t child { first = #3, last = #4 };\r\n  list_entry_t list_offsets[4] = { {0, 3}, {3, 2}, _, {5, 4} };  \r\n}\r\n\r\n// child 2: varchar\r\n#2 -> {\r\n  uint16_t count = 4;\r\n  uint16_t capacity = 4;\r\n  list_vector_data_t *next = NULL;\r\n  bool is_null[4] = { false, true, true, false };\r\n  string_t values[4] = { \"hello\", _, _, \"world\" };  \r\n}\r\n\r\n// child of list: int (1/2)\r\n#3 -> {\r\n  uint16_t count = 4;\r\n  uint16_t capacity = 4;\r\n  list_vector_data_t *next = #4;\r\n  bool is_null[4] = { false, false, false, false };\r\n  int32_t values[4] = { 1, 2, 3, 4 }\r\n}\r\n\r\n// child of list: int (2/2)\r\n#4 -> {\r\n  uint16_t count = 4;\r\n  uint16_t capacity = 8;\r\n  list_vector_data_t *next = NULL;\r\n  bool is_null[8] = { false, false, true, false, false, _, _, _ };\r\n  int32_t values[8] = { 5, 6, _, 8, 9, _, _, _ }\r\n}\r\n\r\n```\r\n\r\n  ",
  "created_at": "2023-07-19T14:41:13Z"
}