{
  "repo": "duckdb/duckdb",
  "pull_number": 5965,
  "instance_id": "duckdb__duckdb-5965",
  "issue_numbers": [
    "5868"
  ],
  "base_commit": "8919619b8989c4b8c58eac0ba304a7fd4c0c3402",
  "patch": "diff --git a/src/common/file_system.cpp b/src/common/file_system.cpp\nindex f32ff51494d5..ce15da27069c 100644\n--- a/src/common/file_system.cpp\n+++ b/src/common/file_system.cpp\n@@ -172,7 +172,7 @@ string FileSystem::ConvertSeparators(const string &path) {\n \treturn result;\n }\n \n-string FileSystem::ExtractBaseName(const string &path) {\n+string FileSystem::ExtractName(const string &path) {\n \tif (path.empty()) {\n \t\treturn string();\n \t}\n@@ -180,7 +180,14 @@ string FileSystem::ExtractBaseName(const string &path) {\n \tauto sep = PathSeparator();\n \tauto splits = StringUtil::Split(normalized_path, sep);\n \tD_ASSERT(!splits.empty());\n-\tauto vec = StringUtil::Split(splits.back(), \".\");\n+\treturn splits.back();\n+}\n+\n+string FileSystem::ExtractBaseName(const string &path) {\n+\tif (path.empty()) {\n+\t\treturn string();\n+\t}\n+\tauto vec = StringUtil::Split(ExtractName(path), \".\");\n \tD_ASSERT(!vec.empty());\n \treturn vec[0];\n }\n@@ -239,6 +246,14 @@ int64_t FileSystem::Write(FileHandle &handle, void *buffer, int64_t nr_bytes) {\n \tthrow NotImplementedException(\"%s: Write is not implemented!\", GetName());\n }\n \n+string FileSystem::GetFileExtension(FileHandle &handle) {\n+\tauto dot_location = handle.path.rfind('.');\n+\tif (dot_location != std::string::npos) {\n+\t\treturn handle.path.substr(dot_location + 1, std::string::npos);\n+\t}\n+\treturn string();\n+}\n+\n int64_t FileSystem::GetFileSize(FileHandle &handle) {\n \tthrow NotImplementedException(\"%s: GetFileSize is not implemented!\", GetName());\n }\ndiff --git a/src/function/pragma/pragma_queries.cpp b/src/function/pragma/pragma_queries.cpp\nindex 365de8d62c90..f848d12ff5f1 100644\n--- a/src/function/pragma/pragma_queries.cpp\n+++ b/src/function/pragma/pragma_queries.cpp\n@@ -1,6 +1,9 @@\n #include \"duckdb/function/pragma/pragma_functions.hpp\"\n #include \"duckdb/common/string_util.hpp\"\n #include \"duckdb/common/file_system.hpp\"\n+#include \"duckdb/parser/statement/export_statement.hpp\"\n+#include \"duckdb/parser/statement/copy_statement.hpp\"\n+#include \"duckdb/parser/parser.hpp\"\n #include \"duckdb/main/config.hpp\"\n \n namespace duckdb {\n@@ -73,7 +76,7 @@ string PragmaImportDatabase(ClientContext &context, const FunctionParameters &pa\n \tauto &fs = FileSystem::GetFileSystem(context);\n \tauto *opener = FileSystem::GetFileOpener(context);\n \n-\tstring query;\n+\tstring final_query;\n \t// read the \"shema.sql\" and \"load.sql\" files\n \tvector<string> files = {\"schema.sql\", \"load.sql\"};\n \tfor (auto &file : files) {\n@@ -83,10 +86,25 @@ string PragmaImportDatabase(ClientContext &context, const FunctionParameters &pa\n \t\tauto fsize = fs.GetFileSize(*handle);\n \t\tauto buffer = unique_ptr<char[]>(new char[fsize]);\n \t\tfs.Read(*handle, buffer.get(), fsize);\n-\n-\t\tquery += string(buffer.get(), fsize);\n+\t\tauto query = string(buffer.get(), fsize);\n+\t\t// Replace the placeholder with the path provided to IMPORT\n+\t\tif (file == \"load.sql\") {\n+\t\t\tParser parser;\n+\t\t\tparser.ParseQuery(query);\n+\t\t\tauto copy_statements = move(parser.statements);\n+\t\t\tquery.clear();\n+\t\t\tfor (auto &statement_p : copy_statements) {\n+\t\t\t\tD_ASSERT(statement_p->type == StatementType::COPY_STATEMENT);\n+\t\t\t\tauto &statement = (CopyStatement &)*statement_p;\n+\t\t\t\tauto &info = *statement.info;\n+\t\t\t\tauto file_name = fs.ExtractName(info.file_path);\n+\t\t\t\tinfo.file_path = fs.JoinPath(parameters.values[0].ToString(), file_name);\n+\t\t\t\tquery += statement.ToString() + \";\";\n+\t\t\t}\n+\t\t}\n+\t\tfinal_query += query;\n \t}\n-\treturn query;\n+\treturn final_query;\n }\n \n string PragmaDatabaseSize(ClientContext &context, const FunctionParameters &parameters) {\ndiff --git a/src/include/duckdb/common/file_system.hpp b/src/include/duckdb/common/file_system.hpp\nindex 4106ac360e7e..9abb0dd4d103 100644\n--- a/src/include/duckdb/common/file_system.hpp\n+++ b/src/include/duckdb/common/file_system.hpp\n@@ -128,6 +128,8 @@ class FileSystem {\n \t//! Write nr_bytes from the buffer into the file, moving the file pointer forward by nr_bytes.\n \tDUCKDB_API virtual int64_t Write(FileHandle &handle, void *buffer, int64_t nr_bytes);\n \n+\t//! Returns the extension of the file, or empty string if no extension was found.\n+\tDUCKDB_API string GetFileExtension(FileHandle &handle);\n \t//! Returns the file size of a file handle, returns -1 on error\n \tDUCKDB_API virtual int64_t GetFileSize(FileHandle &handle);\n \t//! Returns the file last modified time of a file handle, returns timespec with zero on all attributes on error\n@@ -176,8 +178,10 @@ class FileSystem {\n \tDUCKDB_API static string JoinPath(const string &a, const string &path);\n \t//! Convert separators in a path to the local separators (e.g. convert \"/\" into \\\\ on windows)\n \tDUCKDB_API static string ConvertSeparators(const string &path);\n-\t//! Extract the base name of a file (e.g. if the input is lib/example.dll the base name is example)\n+\t//! Extract the base name of a file (e.g. if the input is lib/example.dll the base name is 'example')\n \tDUCKDB_API static string ExtractBaseName(const string &path);\n+\t//! Extract the name of a file (e.g if the input is lib/example.dll the name is 'example.dll')\n+\tDUCKDB_API static string ExtractName(const string &path);\n \n \t//! Runs a glob on the file system, returning a list of matching files\n \tDUCKDB_API virtual vector<string> Glob(const string &path, FileOpener *opener = nullptr);\ndiff --git a/src/include/duckdb/parser/parsed_data/copy_info.hpp b/src/include/duckdb/parser/parsed_data/copy_info.hpp\nindex 7d780a2020a2..ddace9755fbd 100644\n--- a/src/include/duckdb/parser/parsed_data/copy_info.hpp\n+++ b/src/include/duckdb/parser/parsed_data/copy_info.hpp\n@@ -27,12 +27,12 @@ struct CopyInfo : public ParseInfo {\n \tstring table;\n \t//! List of columns to copy to/from\n \tvector<string> select_list;\n-\t//! The file path to copy to/from\n-\tstring file_path;\n \t//! Whether or not this is a copy to file (false) or copy from a file (true)\n \tbool is_from;\n \t//! The file format of the external file\n \tstring format;\n+\t//! The file path to copy to/from\n+\tstring file_path;\n \t//! Set of (key, value) options\n \tunordered_map<string, vector<Value>> options;\n \ndiff --git a/src/include/duckdb/parser/statement/copy_statement.hpp b/src/include/duckdb/parser/statement/copy_statement.hpp\nindex b7c5eb32d5f6..2cdb61df937d 100644\n--- a/src/include/duckdb/parser/statement/copy_statement.hpp\n+++ b/src/include/duckdb/parser/statement/copy_statement.hpp\n@@ -21,11 +21,15 @@ class CopyStatement : public SQLStatement {\n \tunique_ptr<CopyInfo> info;\n \t// The SQL statement used instead of a table when copying data out to a file\n \tunique_ptr<QueryNode> select_statement;\n+\tstring ToString() const override;\n+\tstring CopyOptionsToString(const string &format, const unordered_map<string, vector<Value>> &options) const;\n \n protected:\n \tCopyStatement(const CopyStatement &other);\n \n public:\n \tunique_ptr<SQLStatement> Copy() const override;\n+\n+private:\n };\n } // namespace duckdb\ndiff --git a/src/main/client_context.cpp b/src/main/client_context.cpp\nindex 32a725b4e10e..32fc2aa410bb 100644\n--- a/src/main/client_context.cpp\n+++ b/src/main/client_context.cpp\n@@ -665,6 +665,7 @@ unique_ptr<PendingQueryResult> ClientContext::PendingStatementOrPreparedStatemen\n \t\t\tstatement = std::move(copied_statement);\n \t\t\tbreak;\n \t\t}\n+\t\tcase StatementType::COPY_STATEMENT:\n \t\tcase StatementType::INSERT_STATEMENT:\n \t\tcase StatementType::DELETE_STATEMENT:\n \t\tcase StatementType::UPDATE_STATEMENT: {\ndiff --git a/src/parser/statement/copy_statement.cpp b/src/parser/statement/copy_statement.cpp\nindex 8927fc1ddd61..b53023b49da4 100644\n--- a/src/parser/statement/copy_statement.cpp\n+++ b/src/parser/statement/copy_statement.cpp\n@@ -11,6 +11,108 @@ CopyStatement::CopyStatement(const CopyStatement &other) : SQLStatement(other),\n \t}\n }\n \n+string ConvertOptionValueToString(const Value &val) {\n+\tauto type = val.type().id();\n+\tswitch (type) {\n+\tcase LogicalTypeId::VARCHAR:\n+\t\treturn KeywordHelper::WriteOptionallyQuoted(val.ToString());\n+\tdefault:\n+\t\treturn val.ToString();\n+\t}\n+}\n+\n+string CopyStatement::CopyOptionsToString(const string &format,\n+                                          const unordered_map<string, vector<Value>> &options) const {\n+\tif (format.empty() && options.empty()) {\n+\t\treturn string();\n+\t}\n+\tstring result;\n+\n+\tresult += \" (\";\n+\tif (!format.empty()) {\n+\t\tresult += \" FORMAT \";\n+\t\tresult += format;\n+\t}\n+\tfor (auto it = options.begin(); it != options.end(); it++) {\n+\t\tif (!format.empty() || it != options.begin()) {\n+\t\t\tresult += \", \";\n+\t\t}\n+\t\tauto &name = it->first;\n+\t\tauto &values = it->second;\n+\n+\t\tresult += name + \" \";\n+\t\tif (values.empty()) {\n+\t\t\t// Options like HEADER don't need an explicit value\n+\t\t\t// just providing the name already sets it to true\n+\t\t} else if (values.size() == 1) {\n+\t\t\tresult += ConvertOptionValueToString(values[0]);\n+\t\t} else {\n+\t\t\tresult += \"( \";\n+\t\t\tfor (idx_t i = 0; i < values.size(); i++) {\n+\t\t\t\tauto &value = values[i];\n+\t\t\t\tif (i) {\n+\t\t\t\t\tresult += \", \";\n+\t\t\t\t}\n+\t\t\t\tresult += KeywordHelper::WriteOptionallyQuoted(value.ToString());\n+\t\t\t}\n+\t\t\tresult += \" )\";\n+\t\t}\n+\t}\n+\tresult += \" )\";\n+\treturn result;\n+}\n+\n+// COPY table-name (c1, c2, ..)\n+string TablePart(const CopyInfo &info) {\n+\tstring result;\n+\n+\tif (!info.catalog.empty()) {\n+\t\tresult += KeywordHelper::WriteOptionallyQuoted(info.catalog) + \".\";\n+\t}\n+\tif (!info.schema.empty()) {\n+\t\tresult += KeywordHelper::WriteOptionallyQuoted(info.schema) + \".\";\n+\t}\n+\tD_ASSERT(!info.table.empty());\n+\tresult += KeywordHelper::WriteOptionallyQuoted(info.table);\n+\n+\t// (c1, c2, ..)\n+\tif (!info.select_list.empty()) {\n+\t\tresult += \" (\";\n+\t\tfor (idx_t i = 0; i < info.select_list.size(); i++) {\n+\t\t\tif (i > 0) {\n+\t\t\t\tresult += \", \";\n+\t\t\t}\n+\t\t\tresult += KeywordHelper::WriteOptionallyQuoted(info.select_list[i]);\n+\t\t}\n+\t\tresult += \" )\";\n+\t}\n+\treturn result;\n+}\n+\n+string CopyStatement::ToString() const {\n+\tstring result;\n+\n+\tresult += \"COPY \";\n+\tif (info->is_from) {\n+\t\tD_ASSERT(!select_statement);\n+\t\tresult += TablePart(*info);\n+\t\tresult += \" FROM\";\n+\t\tresult += StringUtil::Format(\" '%s'\", info->file_path);\n+\t\tresult += CopyOptionsToString(info->format, info->options);\n+\t} else {\n+\t\tif (select_statement) {\n+\t\t\t// COPY (select-node) TO ...\n+\t\t\tresult += \"(\" + select_statement->ToString() + \")\";\n+\t\t} else {\n+\t\t\tresult += TablePart(*info);\n+\t\t}\n+\t\tresult += \" TO\";\n+\t\tresult += StringUtil::Format(\"'%s'\", info->file_path);\n+\t\tresult += CopyOptionsToString(info->format, info->options);\n+\t}\n+\treturn result;\n+}\n+\n unique_ptr<SQLStatement> CopyStatement::Copy() const {\n \treturn unique_ptr<CopyStatement>(new CopyStatement(*this));\n }\ndiff --git a/src/planner/binder/statement/bind_export.cpp b/src/planner/binder/statement/bind_export.cpp\nindex a3f0d200af6f..fb769ab21336 100644\n--- a/src/planner/binder/statement/bind_export.cpp\n+++ b/src/planner/binder/statement/bind_export.cpp\n@@ -85,6 +85,15 @@ void ReorderTableEntries(vector<TableCatalogEntry *> &tables) {\n \ttables = ordered;\n }\n \n+string CreateFileName(const string &id_suffix, TableCatalogEntry *table, const string &extension) {\n+\tauto name = SanitizeExportIdentifier(table->name);\n+\tif (table->schema->name == DEFAULT_SCHEMA) {\n+\t\treturn StringUtil::Format(\"%s%s.%s\", name, id_suffix, extension);\n+\t}\n+\tauto schema = SanitizeExportIdentifier(table->schema->name);\n+\treturn StringUtil::Format(\"%s_%s%s.%s\", schema, name, id_suffix, extension);\n+}\n+\n BoundStatement Binder::Bind(ExportStatement &stmt) {\n \t// COPY TO a file\n \tauto &config = DBConfig::GetConfig(context);\n@@ -135,20 +144,13 @@ BoundStatement Binder::Bind(ExportStatement &stmt) {\n \t\tidx_t id = 0;\n \t\twhile (true) {\n \t\t\tstring id_suffix = id == 0 ? string() : \"_\" + to_string(id);\n-\t\t\tif (table->schema->name == DEFAULT_SCHEMA) {\n-\t\t\t\tinfo->file_path = fs.JoinPath(stmt.info->file_path,\n-\t\t\t\t                              StringUtil::Format(\"%s%s.%s\", SanitizeExportIdentifier(table->name),\n-\t\t\t\t                                                 id_suffix, copy_function->function.extension));\n-\t\t\t} else {\n-\t\t\t\tinfo->file_path =\n-\t\t\t\t    fs.JoinPath(stmt.info->file_path,\n-\t\t\t\t                StringUtil::Format(\"%s_%s%s.%s\", SanitizeExportIdentifier(table->schema->name),\n-\t\t\t\t                                   SanitizeExportIdentifier(table->name), id_suffix,\n-\t\t\t\t                                   copy_function->function.extension));\n-\t\t\t}\n-\t\t\tif (table_name_index.find(info->file_path) == table_name_index.end()) {\n+\t\t\tauto name = CreateFileName(id_suffix, table, copy_function->function.extension);\n+\t\t\tauto directory = stmt.info->file_path;\n+\t\t\tauto full_path = fs.JoinPath(directory, name);\n+\t\t\tinfo->file_path = full_path;\n+\t\t\tauto insert_result = table_name_index.insert(info->file_path);\n+\t\t\tif (insert_result.second == true) {\n \t\t\t\t// this name was not yet taken: take it\n-\t\t\t\ttable_name_index.insert(info->file_path);\n \t\t\t\tbreak;\n \t\t\t}\n \t\t\tid++;\n@@ -166,6 +168,7 @@ BoundStatement Binder::Bind(ExportStatement &stmt) {\n \t\texported_data.database_name = catalog;\n \t\texported_data.table_name = info->table;\n \t\texported_data.schema_name = info->schema;\n+\n \t\texported_data.file_path = info->file_path;\n \n \t\tExportedTableInfo table_info;\n",
  "test_patch": "diff --git a/tools/pythonpkg/tests/fast/test_import_export.py b/tools/pythonpkg/tests/fast/test_import_export.py\nnew file mode 100644\nindex 000000000000..2aed89d999e5\n--- /dev/null\n+++ b/tools/pythonpkg/tests/fast/test_import_export.py\n@@ -0,0 +1,52 @@\n+import duckdb\n+import pytest\n+from os import path\n+import shutil\n+import os\n+\n+@pytest.fixture(scope=\"session\")\n+def export_path(tmp_path_factory):\n+    database = tmp_path_factory.mktemp(\"export_dbs\", numbered=True)\n+    return str(database)\n+\n+@pytest.fixture(scope=\"session\")\n+def import_path(tmp_path_factory):\n+    database = tmp_path_factory.mktemp(\"import_dbs\", numbered=True)\n+    return str(database)\n+\n+def export_database(export_location):\n+    # Create the db\n+    duckdb.execute(\"create table tbl (a integer, b integer);\");\n+    duckdb.execute(\"insert into tbl values (5,1);\");\n+\n+    # Export the db\n+    duckdb.execute(f\"export database '{export_location}';\");\n+    print(f\"Exported database to {export_location}\")\n+\n+    # Destroy the db\n+    duckdb.execute(\"drop table tbl\");\n+\n+def import_database(import_location):\n+    duckdb.execute(f\"import database '{import_location}'\")\n+    print(f\"Imported database from {import_location}\");\n+\n+    res = duckdb.query(\"select * from tbl\").fetchall()\n+    assert res == [(5,1),]\n+    print(\"Successfully queried an imported database that was moved from its original export location!\")\n+\n+    # Destroy the db\n+    duckdb.execute(\"drop table tbl\");\n+\n+def move_database(export_location, import_location):\n+    assert path.exists(export_location)\n+    assert path.exists(import_location)\n+\n+    for file in ['schema.sql', 'load.sql', 'tbl.csv']:\n+        shutil.move(path.join(export_location, file), import_location)\n+\n+class TestDuckDBImportExport():\n+\t\n+    def test_import_and_export(self, export_path, import_path):\n+        export_database(export_path)\n+        move_database(export_path, import_path)\n+        import_database(import_path)\n",
  "problem_statement": "Absolute paths in EXPORT DATABASE load.sql\n### What happens?\r\n\r\nIf you `EXPORT DATABASE 'mypath' (FORMAT PARQUET);` the **absolute paths** to `mypath` are written in to `load.sql`.\r\n\r\nThis means you can't copy the exported files to another location and  `IMPORT DATABASE 'mypath'` because you'll get:\r\n```\r\nduckdb.InvalidInputException: Invalid Input Error: Attempting to execute an unsuccessful or closed pending query result\r\nError: IO Error: No files found that match the pattern \"/original/path/table.parquet\"\r\n```\r\n\r\n### To Reproduce\r\n\r\n1. `EXPORT DATABASE 'test' (FORMAT PARQUET);`\r\n\r\n1. Open `test/load.sql`\r\n\r\n1. Observe full paths in `test` directory, e.g.: `/home/dave/backup/test/table.parquet`\r\n\r\n1. Copy `test` to another location e.g. `test2`\r\n\r\n1. `IMPORT DATABASE 'test2'`\r\n\r\n1. Observe `IO Error`\r\n\r\n### OS:\r\n\r\nUbuntu 20.04.5 LTS\r\n\r\n### DuckDB Version:\r\n\r\nv0.6.1-dev83 dfae126\r\n\r\n### DuckDB Client:\r\n\r\nPython\r\n\r\n### Full Name:\r\n\r\nDave Tapley\r\n\r\n### Affiliation:\r\n\r\nJE Fuller\r\n\r\n### Have you tried this on the latest `master` branch?\r\n\r\n- [X] I agree\r\n\r\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\r\n\r\n- [X] I agree\n",
  "hints_text": "Here's my workaround in Python:\r\n\r\nTo export:\r\n```py\r\ncon.execute(f\"EXPORT DATABASE '{path}' (FORMAT PARQUET);\")\r\n\r\nloadSqlPath = path / 'load.sql'\r\nfor line in fileinput.input(loadSqlPath, inplace=True):\r\n    print(line.replace(str(path), 'ROOT'))\r\n```\r\n\r\nTo import:\r\n```py\r\nloadSqlPath = path / 'load.sql'\r\nfor line in fileinput.input(loadSqlPath, inplace=True):\r\n    print(line.replace('ROOT', str(path)))\r\n\r\ncon.execute(f\"IMPORT DATABASE '{str(path)}';\")\r\n```\nThanks for the report!\r\n\r\nThe problem with writing relative paths is that the `IMPORT` then only works from the same relative directory, e.g. this would fail:\r\n\r\n```sql\r\nEXPORT DATABASE 'mydir' (FORMAT PARQUET);\r\ncd ..\r\nIMPORT DATABASE 'root/mydir';\r\n```\r\n\r\nWe could make this a configuration option - or perhaps more cleanly would be to have the `IMPORT` modify the path automatically if it is different.\nYea I think so too, all the files that get written when we do an export database will be local to that created folder\r\nIt's probably nicest to just have IMPORT figure out what path the relevant files are at, it should have enough context",
  "created_at": "2023-01-23T11:55:40Z"
}