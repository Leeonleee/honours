You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
Fetching from table and view results in a crash
Consider the following statements:

```sql
CREATE TABLE t0(c0 INT);
CREATE VIEW v0 AS SELECT 0, 1 FROM t0 ORDER BY t0.c0;
SELECT t0.c0 FROM t0, v0; -- Conversion: Invalid TypeId <int>
```
Unexpectedly, the type ID changes nondeterministically:
```
sqlite> SELECT t0.c0 FROM t0, v0;
Error: Conversion: Invalid TypeId 10
sqlite> SELECT t0.c0 FROM t0, v0;
Error: Conversion: Invalid TypeId 54
sqlite> SELECT t0.c0 FROM t0, v0;
Error: Conversion: Invalid TypeId 26
sqlite> SELECT t0.c0 FROM t0, v0;
Error: Conversion: Invalid TypeId 33
sqlite> SELECT t0.c0 FROM t0, v0;
Error: Conversion: Invalid TypeId 255
sqlite> SELECT t0.c0 FROM t0, v0;
Error: Conversion: Invalid TypeId 10
```
The original test case crashed SQLancer. I reduced the crash based on the debug build, where the current test case causes an ASan error:
```
==15622==ERROR: AddressSanitizer: heap-buffer-overflow on address 0x602000007220 at pc 0x55944781b239 bp 0x7fff3cf78c60 sp 0x7fff3cf78c50
READ of size 16 at 0x602000007220 thread T0
    #0 0x55944781b238 in void std::_Construct<duckdb::ColumnBinding, duckdb::ColumnBinding&>(duckdb::ColumnBinding*, duckdb::ColumnBinding&) /usr/include/c++/8/bits/stl_construct.h:75
    #1 0x55944781ac9f in duckdb::ColumnBinding* std::__uninitialized_copy<false>::__uninit_copy<__gnu_cxx::__normal_iterator<duckdb::ColumnBinding*, std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> > >, duckdb::ColumnBinding*>(__gnu_cxx::__normal_iterator<duckdb::ColumnBinding*, std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> > >, __gnu_cxx::__normal_iterator<duckdb::ColumnBinding*, std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> > >, duckdb::ColumnBinding*) /usr/include/c++/8/bits/stl_uninitialized.h:83
    #2 0x55944781a1a8 in duckdb::ColumnBinding* std::uninitialized_copy<__gnu_cxx::__normal_iterator<duckdb::ColumnBinding*, std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> > >, duckdb::ColumnBinding*>(__gnu_cxx::__normal_iterator<duckdb::ColumnBinding*, std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> > >, __gnu_cxx::__normal_iterator<duckdb::ColumnBinding*, std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> > >, duckdb::ColumnBinding*) /usr/include/c++/8/bits/stl_uninitialized.h:134
    #3 0x559447818fc4 in duckdb::ColumnBinding* std::__uninitialized_copy_a<__gnu_cxx::__normal_iterator<duckdb::ColumnBinding*, std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> > >, duckdb::ColumnBinding*, duckdb::ColumnBinding>(__gnu_cxx::__normal_iterator<duckdb::ColumnBinding*, std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> > >, __gnu_cxx::__normal_iterator<duckdb::ColumnBinding*, std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> > >, duckdb::ColumnBinding*, std::allocator<duckdb::ColumnBinding>&) /usr/include/c++/8/bits/stl_uninitialized.h:289
    #4 0x55944781747f in void std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> >::_M_range_insert<__gnu_cxx::__normal_iterator<duckdb::ColumnBinding*, std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> > > >(__gnu_cxx::__normal_iterator<duckdb::ColumnBinding*, std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> > >, __gnu_cxx::__normal_iterator<duckdb::ColumnBinding*, std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> > >, __gnu_cxx::__normal_iterator<duckdb::ColumnBinding*, std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> > >, std::forward_iterator_tag) (/duckdb/build/debug/duckdb_cli+0xe1947f)
    #5 0x55944781609c in void std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> >::_M_insert_dispatch<__gnu_cxx::__normal_iterator<duckdb::ColumnBinding*, std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> > > >(__gnu_cxx::__normal_iterator<duckdb::ColumnBinding*, std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> > >, __gnu_cxx::__normal_iterator<duckdb::ColumnBinding*, std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> > >, __gnu_cxx::__normal_iterator<duckdb::ColumnBinding*, std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> > >, std::__false_type) (/duckdb/build/debug/duckdb_cli+0xe1809c)
    #6 0x559447814b2b in __gnu_cxx::__normal_iterator<duckdb::ColumnBinding*, std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> > > std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> >::insert<__gnu_cxx::__normal_iterator<duckdb::ColumnBinding*, std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> > >, void>(__gnu_cxx::__normal_iterator<duckdb::ColumnBinding const*, std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> > >, __gnu_cxx::__normal_iterator<duckdb::ColumnBinding*, std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> > >, __gnu_cxx::__normal_iterator<duckdb::ColumnBinding*, std::vector<duckdb::ColumnBinding, std::allocator<duckdb::ColumnBinding> > >) (/duckdb/build/debug/duckdb_cli+0xe16b2b)
    #7 0x559447810f73 in duckdb::LogicalPruneColumns::GetColumnBindings() /duckdb/src/planner/operator/logical_prune_columns.cpp:9
    #8 0x5594475a3485 in duckdb::ColumnBindingResolver::VisitOperator(duckdb::LogicalOperator&) /duckdb/src/execution/column_binding_resolver.cpp:69
    #9 0x559447833ad2 in duckdb::LogicalOperatorVisitor::VisitOperatorChildren(duckdb::LogicalOperator&) /duckdb/src/planner/logical_operator_visitor.cpp:17
    #10 0x5594475a339f in duckdb::ColumnBindingResolver::VisitOperator(duckdb::LogicalOperator&) /duckdb/src/execution/column_binding_resolver.cpp:65
    #11 0x559447833ad2 in duckdb::LogicalOperatorVisitor::VisitOperatorChildren(duckdb::LogicalOperator&) /duckdb/src/planner/logical_operator_visitor.cpp:17
    #12 0x5594475a339f in duckdb::ColumnBindingResolver::VisitOperator(duckdb::LogicalOperator&) /duckdb/src/execution/column_binding_resolver.cpp:65
    #13 0x559447833ad2 in duckdb::LogicalOperatorVisitor::VisitOperatorChildren(duckdb::LogicalOperator&) /duckdb/src/planner/logical_operator_visitor.cpp:17
    #14 0x5594475a339f in duckdb::ColumnBindingResolver::VisitOperator(duckdb::LogicalOperator&) /duckdb/src/execution/column_binding_resolver.cpp:65
    #15 0x5594475b0c05 in duckdb::PhysicalPlanGenerator::CreatePlan(std::unique_ptr<duckdb::LogicalOperator, std::default_delete<duckdb::LogicalOperator> >) /duckdb/src/execution/physical_plan_generator.cpp:36
    #16 0x5594475fde99 in duckdb::ClientContext::CreatePreparedStatement(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unique_ptr<duckdb::SQLStatement, std::default_delete<duckdb::SQLStatement> >) /duckdb/src/main/client_context.cpp:191
    #17 0x55944760147e in duckdb::ClientContext::RunStatementInternal(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unique_ptr<duckdb::SQLStatement, std::default_delete<duckdb::SQLStatement> >, bool) /duckdb/src/main/client_context.cpp:329
    #18 0x559447601ee7 in duckdb::ClientContext::RunStatement(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unique_ptr<duckdb::SQLStatement, std::default_delete<duckdb::SQLStatement> >, bool) /duckdb/src/main/client_context.cpp:360
    #19 0x5594475ffb26 in duckdb::ClientContext::Prepare(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) /duckdb/src/main/client_context.cpp:274
    #20 0x55944760b449 in duckdb::Connection::Prepare(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) /duckdb/src/main/connection.cpp:71
    #21 0x5594472db3c9 in sqlite3_prepare_v2 /duckdb/tools/sqlite3_api_wrapper/sqlite3_api_wrapper.cpp:140
    #22 0x5594472b709f in shell_exec /duckdb/tools/shell/shell.c:10347
    #23 0x5594472d122d in runOneSqlLine /duckdb/tools/shell/shell.c:15341
    #24 0x5594472d1b67 in process_input /duckdb/tools/shell/shell.c:15442
    #25 0x5594472d4274 in main /duckdb/tools/shell/shell.c:16107
    #26 0x7f632ae13b6a in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x26b6a)
    #27 0x559447291659 in _start (/duckdb/build/debug/duckdb_cli+0x893659)
```

I can reproduce this on the latest master (3f0eb5134512c6097805998ccc5eb44476534736).
SELECT on view with text constant in ORDER BY crashes
Consider the following statements:
```sql
CREATE TABLE t0(c0 INT);
INSERT INTO t0(c0) VALUES (0);
CREATE VIEW v0(c0) AS SELECT 1 FROM t0;
SELECT * FROM v0 ORDER BY 'a'; --  Assertion `types.size() > 0' failed (original test case crashed)
```
Unexpectedly, the `SELECT` results in an assertion error when executing the debug build:
```
/build/debug$ ./duckdb_cli 
SQLite version DuckDB ee09b60a5
Enter ".help" for usage hints.
Connected to a transient in-memory database.
Use ".open FILENAME" to reopen on a persistent database.
sqlite> CREATE TABLE t0(c0 INT);
sqlite> INSERT INTO t0(c0) VALUES (0);
sqlite> CREATE VIEW v0(c0) AS SELECT 1 FROM t0;
sqlite> SELECT * FROM v0 ORDER BY 'a'; -- crash or Assertion `types.size() > 0' failed
duckdb_cli: /home/manuel/research/projects/duckdb_test/duckdb/src/common/types/data_chunk.cpp:25: void duckdb::DataChunk::Initialize(std::vector<duckdb::TypeId>&): Assertion `types.size() > 0' failed.
Aborted
```
The original (larger) test cases resulted in a segfault in the release build. I reduced this test case based on the debug build. I found this based on commit ee09b60a58a5d235b18fd1dc7be4843868efa00a.

</issue>
<code>
[start of README.md]
1: <img align="left" src="logo/duckdb-logo.png" height="120">
2: 
3: # DuckDB, the SQLite for Analytics
4: [![Travis](https://api.travis-ci.org/cwida/duckdb.svg?branch=master)](https://travis-ci.org/cwida/duckdb)
5: [![CodeFactor](https://www.codefactor.io/repository/github/cwida/duckdb/badge)](https://www.codefactor.io/repository/github/cwida/duckdb)
6: [![Coverage Status](https://coveralls.io/repos/github/cwida/duckdb/badge.svg?branch=master)](https://coveralls.io/github/cwida/duckdb?branch=master)
7: 
8: <br>
9: 
10: 
11: # Requirements
12: DuckDB requires [CMake](https://cmake.org) to be installed and a `C++11` compliant compiler. GCC 4.9 and newer, Clang 3.9 and newer and VisualStudio 2017 are tested on each revision.
13: 
14: ## Compiling
15: Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You may run `make unit` and `make allunit` to verify that your version works properly after making changes.
16: 
17: # Usage
18: A command line utility based on `sqlite3` can be found in either `build/release/duckdb_cli` (release, the default) or `build/debug/duckdb_cli` (debug).
19: 
20: # Embedding
21: As DuckDB is an embedded database, there is no database server to launch or client to connect to a running server. However, the database server can be embedded directly into an application using the C or C++ bindings. The main build process creates the shared library `build/release/src/libduckdb.[so|dylib|dll]` that can be linked against. A static library is built as well.
22: 
23: For examples on how to embed DuckDB into your application, see the [examples](https://github.com/cwida/duckdb/tree/master/examples) folder.
24: 
25: ## Benchmarks
26: After compiling, benchmarks can be executed from the root directory by executing `./build/release/benchmark/benchmark_runner`.
27: 
28: ## Standing on the Shoulders of Giants
29: DuckDB is implemented in C++ 11, should compile with GCC and clang, uses CMake to build and [Catch2](https://github.com/catchorg/Catch2) for testing. DuckDB uses some components from various Open-Source databases and draws inspiration from scientific publications. Here is an overview:
30: 
31: * Parser: We use the PostgreSQL parser that was [repackaged as a stand-alone library](https://github.com/lfittl/libpg_query). The translation to our own parse tree is inspired by [Peloton](https://pelotondb.io).
32: * Shell: We have adapted the [SQLite shell](https://sqlite.org/cli.html) to work with DuckDB.
33: * Tests: We use the [SQL Logic Tests from SQLite](https://www.sqlite.org/sqllogictest/doc/trunk/about.wiki) to test DuckDB.
34: * Query fuzzing: We use [SQLsmith](https://github.com/anse1/sqlsmith) to generate random queries for additional testing.
35: * Date Math: We use the date math component from [MonetDB](https://www.monetdb.org).
36: * SQL Window Functions: DuckDB's window functions implementation uses Segment Tree Aggregation as described in the paper "Efficient Processing of Window Functions in Analytical SQL Queries" by Viktor Leis, Kan Kundhikanjana, Alfons Kemper and Thomas Neumann.
37: * Execution engine: The vectorized execution engine is inspired by the paper "MonetDB/X100: Hyper-Pipelining Query Execution" by Peter Boncz, Marcin Zukowski and Niels Nes.
38: * Optimizer: DuckDB's optimizer draws inspiration from the papers "Dynamic programming strikes back" by Guido Moerkotte and Thomas Neumman as well as "Unnesting Arbitrary Queries" by Thomas Neumann and Alfons Kemper.
39: * Concurrency control: Our MVCC implementation is inspired by the paper "Fast Serializable Multi-Version Concurrency Control for Main-Memory Database Systems" by Thomas Neumann, Tobias Mühlbauer and Alfons Kemper.
40: * Regular Expression: DuckDB uses Google's [RE2](https://github.com/google/re2) regular expression engine.
41: 
42: ## Other pages
43: * [Continuous Benchmarking (CB™)](https://www.duckdb.org/benchmarks/index.html), runs TPC-H, TPC-DS and some microbenchmarks on every commit
[end of README.md]
[start of src/common/enums/logical_operator_type.cpp]
1: #include "duckdb/common/enums/logical_operator_type.hpp"
2: 
3: using namespace std;
4: 
5: namespace duckdb {
6: 
7: //===--------------------------------------------------------------------===//
8: // Value <--> String Utilities
9: //===--------------------------------------------------------------------===//
10: string LogicalOperatorToString(LogicalOperatorType type) {
11: 	switch (type) {
12: 	case LogicalOperatorType::GET:
13: 		return "GET";
14: 	case LogicalOperatorType::CHUNK_GET:
15: 		return "CHUNK_GET";
16: 	case LogicalOperatorType::DELIM_GET:
17: 		return "DELIM_GET";
18: 	case LogicalOperatorType::EMPTY_RESULT:
19: 		return "EMPTY_RESULT";
20: 	case LogicalOperatorType::EXPRESSION_GET:
21: 		return "EXPRESSION_GET";
22: 	case LogicalOperatorType::ANY_JOIN:
23: 		return "ANY_JOIN";
24: 	case LogicalOperatorType::COMPARISON_JOIN:
25: 		return "COMPARISON_JOIN";
26: 	case LogicalOperatorType::DELIM_JOIN:
27: 		return "DELIM_JOIN";
28: 	case LogicalOperatorType::PROJECTION:
29: 		return "PROJECTION";
30: 	case LogicalOperatorType::FILTER:
31: 		return "FILTER";
32: 	case LogicalOperatorType::AGGREGATE_AND_GROUP_BY:
33: 		return "AGGREGATE_AND_GROUP_BY";
34: 	case LogicalOperatorType::WINDOW:
35: 		return "WINDOW";
36: 	case LogicalOperatorType::UNNEST:
37: 		return "UNNEST";
38: 	case LogicalOperatorType::LIMIT:
39: 		return "LIMIT";
40: 	case LogicalOperatorType::ORDER_BY:
41: 		return "ORDER_BY";
42: 	case LogicalOperatorType::TOP_N:
43: 		return "TOP_N";
44: 	case LogicalOperatorType::COPY_TO_FILE:
45: 		return "COPY_TO_FILE";
46: 	case LogicalOperatorType::COPY_FROM_FILE:
47: 		return "COPY_FROM_FILE";
48: 	case LogicalOperatorType::JOIN:
49: 		return "JOIN";
50: 	case LogicalOperatorType::CROSS_PRODUCT:
51: 		return "CROSS_PRODUCT";
52: 	case LogicalOperatorType::UNION:
53: 		return "UNION";
54: 	case LogicalOperatorType::EXCEPT:
55: 		return "EXCEPT";
56: 	case LogicalOperatorType::INTERSECT:
57: 		return "INTERSECT";
58: 	case LogicalOperatorType::INSERT:
59: 		return "INSERT";
60: 	case LogicalOperatorType::DISTINCT:
61: 		return "DISTINCT";
62: 	case LogicalOperatorType::DELETE:
63: 		return "DELETE";
64: 	case LogicalOperatorType::UPDATE:
65: 		return "UPDATE";
66: 	case LogicalOperatorType::PREPARE:
67: 		return "PREPARE";
68: 	case LogicalOperatorType::PRUNE_COLUMNS:
69: 		return "PRUNE";
70: 	case LogicalOperatorType::TABLE_FUNCTION:
71: 		return "TABLE_FUNCTION";
72: 	case LogicalOperatorType::CREATE_INDEX:
73: 		return "CREATE_INDEX";
74: 	case LogicalOperatorType::CREATE_TABLE:
75: 		return "CREATE_TABLE";
76: 	case LogicalOperatorType::EXPLAIN:
77: 		return "EXPLAIN";
78: 	case LogicalOperatorType::EXECUTE:
79: 		return "EXECUTE";
80: 	case LogicalOperatorType::VACUUM:
81: 		return "VACUUM";
82: 	case LogicalOperatorType::INDEX_SCAN:
83: 		return "INDEX_SCAN";
84: 	case LogicalOperatorType::RECURSIVE_CTE:
85: 		return "REC_CTE";
86: 	case LogicalOperatorType::CTE_REF:
87: 		return "CTE_SCAN";
88: 	case LogicalOperatorType::INVALID:
89: 	default:
90: 		return "INVALID";
91: 	}
92: }
93: 
94: } // namespace duckdb
[end of src/common/enums/logical_operator_type.cpp]
[start of src/common/enums/physical_operator_type.cpp]
1: #include "duckdb/common/enums/physical_operator_type.hpp"
2: 
3: using namespace std;
4: 
5: namespace duckdb {
6: 
7: string PhysicalOperatorToString(PhysicalOperatorType type) {
8: 	switch (type) {
9: 	case PhysicalOperatorType::LEAF:
10: 		return "LEAF";
11: 	case PhysicalOperatorType::DUMMY_SCAN:
12: 		return "DUMMY_SCAN";
13: 	case PhysicalOperatorType::SEQ_SCAN:
14: 		return "SEQ_SCAN";
15: 	case PhysicalOperatorType::INDEX_SCAN:
16: 		return "INDEX_SCAN";
17: 	case PhysicalOperatorType::CHUNK_SCAN:
18: 		return "CHUNK_SCAN";
19: 	case PhysicalOperatorType::DELIM_SCAN:
20: 		return "DELIM_SCAN";
21: 	case PhysicalOperatorType::EXTERNAL_FILE_SCAN:
22: 		return "EXTERNAL_FILE_SCAN";
23: 	case PhysicalOperatorType::QUERY_DERIVED_SCAN:
24: 		return "QUERY_DERIVED_SCAN";
25: 	case PhysicalOperatorType::ORDER_BY:
26: 		return "ORDER_BY";
27: 	case PhysicalOperatorType::LIMIT:
28: 		return "LIMIT";
29: 	case PhysicalOperatorType::TOP_N:
30: 		return "TOP_N";
31: 	case PhysicalOperatorType::AGGREGATE:
32: 		return "AGGREGATE";
33: 	case PhysicalOperatorType::WINDOW:
34: 		return "WINDOW";
35: 	case PhysicalOperatorType::UNNEST:
36: 		return "UNNEST";
37: 	case PhysicalOperatorType::DISTINCT:
38: 		return "DISTINCT";
39: 	case PhysicalOperatorType::SIMPLE_AGGREGATE:
40: 		return "SIMPLE_AGGREGATE";
41: 	case PhysicalOperatorType::HASH_GROUP_BY:
42: 		return "HASH_GROUP_BY";
43: 	case PhysicalOperatorType::SORT_GROUP_BY:
44: 		return "SORT_GROUP_BY";
45: 	case PhysicalOperatorType::FILTER:
46: 		return "FILTER";
47: 	case PhysicalOperatorType::PROJECTION:
48: 		return "PROJECTION";
49: 	case PhysicalOperatorType::COPY_FROM_FILE:
50: 		return "COPY_FROM_FILE";
51: 	case PhysicalOperatorType::COPY_TO_FILE:
52: 		return "COPY_TO_FILE";
53: 	case PhysicalOperatorType::DELIM_JOIN:
54: 		return "DELIM_JOIN";
55: 	case PhysicalOperatorType::BLOCKWISE_NL_JOIN:
56: 		return "BLOCKWISE_NL_JOIN";
57: 	case PhysicalOperatorType::NESTED_LOOP_JOIN:
58: 		return "NESTED_LOOP_JOIN";
59: 	case PhysicalOperatorType::HASH_JOIN:
60: 		return "HASH_JOIN";
61: 	case PhysicalOperatorType::PIECEWISE_MERGE_JOIN:
62: 		return "PIECEWISE_MERGE_JOIN";
63: 	case PhysicalOperatorType::CROSS_PRODUCT:
64: 		return "CROSS_PRODUCT";
65: 	case PhysicalOperatorType::UNION:
66: 		return "UNION";
67: 	case PhysicalOperatorType::INSERT:
68: 		return "INSERT";
69: 	case PhysicalOperatorType::INSERT_SELECT:
70: 		return "INSERT_SELECT";
71: 	case PhysicalOperatorType::DELETE:
72: 		return "DELETE";
73: 	case PhysicalOperatorType::UPDATE:
74: 		return "UPDATE";
75: 	case PhysicalOperatorType::EXPORT_EXTERNAL_FILE:
76: 		return "EXPORT_EXTERNAL_FILE";
77: 	case PhysicalOperatorType::PRUNE_COLUMNS:
78: 		return "PRUNE";
79: 	case PhysicalOperatorType::EMPTY_RESULT:
80: 		return "EMPTY_RESULT";
81: 	case PhysicalOperatorType::TABLE_FUNCTION:
82: 		return "TABLE_FUNCTION";
83: 	case PhysicalOperatorType::CREATE:
84: 		return "CREATE";
85: 	case PhysicalOperatorType::CREATE_INDEX:
86: 		return "CREATE_INDEX";
87: 	case PhysicalOperatorType::EXPLAIN:
88: 		return "EXPLAIN";
89: 	case PhysicalOperatorType::EXECUTE:
90: 		return "EXECUTE";
91: 	case PhysicalOperatorType::VACUUM:
92: 		return "VACUUM";
93: 	case PhysicalOperatorType::RECURSIVE_CTE:
94: 		return "REC_CTE";
95: 	case PhysicalOperatorType::INVALID:
96: 	default:
97: 		return "INVALID";
98: 	}
99: }
100: 
101: } // namespace duckdb
[end of src/common/enums/physical_operator_type.cpp]
[start of src/execution/operator/helper/CMakeLists.txt]
1: add_library_unity(duckdb_operator_helper
2:                   OBJECT
3:                   physical_execute.cpp
4:                   physical_limit.cpp
5:                   physical_pragma.cpp
6:                   physical_prepare.cpp
7:                   physical_prune_columns.cpp
8:                   physical_transaction.cpp
9:                   physical_vacuum.cpp)
10: set(ALL_OBJECT_FILES ${ALL_OBJECT_FILES}
11:                      $<TARGET_OBJECTS:duckdb_operator_helper> PARENT_SCOPE)
[end of src/execution/operator/helper/CMakeLists.txt]
[start of src/execution/operator/helper/physical_prune_columns.cpp]
1: #include "duckdb/execution/operator/helper/physical_prune_columns.hpp"
2: 
3: #include "duckdb/execution/expression_executor.hpp"
4: 
5: using namespace duckdb;
6: using namespace std;
7: 
8: void PhysicalPruneColumns::GetChunkInternal(ClientContext &context, DataChunk &chunk, PhysicalOperatorState *state_) {
9: 	auto state = reinterpret_cast<PhysicalOperatorState *>(state_);
10: 
11: 	children[0]->GetChunk(context, state->child_chunk, state->child_state.get());
12: 	if (state->child_chunk.size() == 0) {
13: 		return;
14: 	}
15: 	assert(column_limit <= state->child_chunk.column_count());
16: 	chunk.SetCardinality(state->child_chunk.size());
17: 	for (idx_t i = 0; i < column_limit; i++) {
18: 		chunk.data[i].Reference(state->child_chunk.data[i]);
19: 	}
20: }
[end of src/execution/operator/helper/physical_prune_columns.cpp]
[start of src/execution/physical_plan/CMakeLists.txt]
1: add_library_unity(duckdb_physical_plan
2:                   OBJECT
3:                   plan_aggregate.cpp
4:                   plan_any_join.cpp
5:                   plan_chunk_get.cpp
6:                   plan_comparison_join.cpp
7:                   plan_copy_from_file.cpp
8:                   plan_copy_to_file.cpp
9:                   plan_create.cpp
10:                   plan_create_index.cpp
11:                   plan_create_table.cpp
12:                   plan_cross_product.cpp
13:                   plan_delete.cpp
14:                   plan_delim_get.cpp
15:                   plan_delim_join.cpp
16:                   plan_distinct.cpp
17:                   plan_empty_result.cpp
18:                   plan_execute.cpp
19:                   plan_explain.cpp
20:                   plan_filter.cpp
21:                   plan_get.cpp
22:                   plan_index_scan.cpp
23:                   plan_insert.cpp
24:                   plan_limit.cpp
25:                   plan_order.cpp
26:                   plan_prepare.cpp
27:                   plan_projection.cpp
28:                   plan_prune_columns.cpp
29:                   plan_set_operation.cpp
30:                   plan_simple.cpp
31:                   plan_table_function.cpp
32:                   plan_top_n.cpp
33:                   plan_update.cpp
34:                   plan_window.cpp
35:                   plan_unnest.cpp
36:                   plan_expression_get.cpp
37:                   plan_recursive_cte.cpp)
38: set(ALL_OBJECT_FILES
39:     ${ALL_OBJECT_FILES} $<TARGET_OBJECTS:duckdb_physical_plan>
40:     PARENT_SCOPE)
[end of src/execution/physical_plan/CMakeLists.txt]
[start of src/execution/physical_plan/plan_order.cpp]
1: #include "duckdb/execution/operator/order/physical_order.hpp"
2: #include "duckdb/execution/physical_plan_generator.hpp"
3: #include "duckdb/planner/operator/logical_order.hpp"
4: 
5: using namespace duckdb;
6: using namespace std;
7: 
8: unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalOrder &op) {
9: 	assert(op.children.size() == 1);
10: 
11: 	auto plan = CreatePlan(*op.children[0]);
12: 
13: 	auto order = make_unique<PhysicalOrder>(op.types, move(op.orders));
14: 	order->children.push_back(move(plan));
15: 	return move(order);
16: }
[end of src/execution/physical_plan/plan_order.cpp]
[start of src/execution/physical_plan/plan_prune_columns.cpp]
1: #include "duckdb/execution/operator/helper/physical_prune_columns.hpp"
2: #include "duckdb/execution/physical_plan_generator.hpp"
3: #include "duckdb/planner/operator/logical_prune_columns.hpp"
4: 
5: using namespace duckdb;
6: using namespace std;
7: 
8: unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalPruneColumns &op) {
9: 	assert(op.children.size() == 1);
10: 
11: 	auto plan = CreatePlan(*op.children[0]);
12: 	if (plan->GetTypes().size() > op.column_limit) {
13: 		// only prune if we need to
14: 		auto node = make_unique<PhysicalPruneColumns>(op, op.column_limit);
15: 		node->children.push_back(move(plan));
16: 		plan = move(node);
17: 	}
18: 	return plan;
19: }
[end of src/execution/physical_plan/plan_prune_columns.cpp]
[start of src/execution/physical_plan_generator.cpp]
1: #include "duckdb/execution/physical_plan_generator.hpp"
2: 
3: #include "duckdb/catalog/catalog_entry/scalar_function_catalog_entry.hpp"
4: #include "duckdb/execution/column_binding_resolver.hpp"
5: #include "duckdb/main/client_context.hpp"
6: #include "duckdb/planner/expression/bound_function_expression.hpp"
7: 
8: using namespace duckdb;
9: using namespace std;
10: 
11: namespace duckdb {
12: 
13: class DependencyExtractor : public LogicalOperatorVisitor {
14: public:
15: 	DependencyExtractor(unordered_set<CatalogEntry *> &dependencies) : dependencies(dependencies) {
16: 	}
17: 
18: protected:
19: 	unique_ptr<Expression> VisitReplace(BoundFunctionExpression &expr, unique_ptr<Expression> *expr_ptr) override {
20: 		// extract dependencies from the bound function expression
21: 		if (expr.function.dependency) {
22: 			expr.function.dependency(expr, dependencies);
23: 		}
24: 		return nullptr;
25: 	}
26: 
27: private:
28: 	unordered_set<CatalogEntry *> &dependencies;
29: };
30: } // namespace duckdb
31: 
32: unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(unique_ptr<LogicalOperator> op) {
33: 	// first resolve column references
34: 	context.profiler.StartPhase("column_binding");
35: 	ColumnBindingResolver resolver;
36: 	resolver.VisitOperator(*op);
37: 	context.profiler.EndPhase();
38: 
39: 	// now resolve types of all the operators
40: 	context.profiler.StartPhase("resolve_types");
41: 	op->ResolveOperatorTypes();
42: 	context.profiler.EndPhase();
43: 
44: 	// extract dependencies from the logical plan
45: 	DependencyExtractor extractor(dependencies);
46: 	extractor.VisitOperator(*op);
47: 
48: 	// then create the main physical plan
49: 	context.profiler.StartPhase("create_plan");
50: 	auto plan = CreatePlan(*op);
51: 	context.profiler.EndPhase();
52: 	return plan;
53: }
54: 
55: unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalOperator &op) {
56: 	switch (op.type) {
57: 	case LogicalOperatorType::GET:
58: 		return CreatePlan((LogicalGet &)op);
59: 	case LogicalOperatorType::PROJECTION:
60: 		return CreatePlan((LogicalProjection &)op);
61: 	case LogicalOperatorType::EMPTY_RESULT:
62: 		return CreatePlan((LogicalEmptyResult &)op);
63: 	case LogicalOperatorType::FILTER:
64: 		return CreatePlan((LogicalFilter &)op);
65: 	case LogicalOperatorType::AGGREGATE_AND_GROUP_BY:
66: 		return CreatePlan((LogicalAggregate &)op);
67: 	case LogicalOperatorType::WINDOW:
68: 		return CreatePlan((LogicalWindow &)op);
69: 	case LogicalOperatorType::UNNEST:
70: 		return CreatePlan((LogicalUnnest &)op);
71: 	case LogicalOperatorType::LIMIT:
72: 		return CreatePlan((LogicalLimit &)op);
73: 	case LogicalOperatorType::ORDER_BY:
74: 		return CreatePlan((LogicalOrder &)op);
75: 	case LogicalOperatorType::TOP_N:
76: 		return CreatePlan((LogicalTopN &)op);
77: 	case LogicalOperatorType::COPY_FROM_FILE:
78: 		return CreatePlan((LogicalCopyFromFile &)op);
79: 	case LogicalOperatorType::COPY_TO_FILE:
80: 		return CreatePlan((LogicalCopyToFile &)op);
81: 	case LogicalOperatorType::TABLE_FUNCTION:
82: 		return CreatePlan((LogicalTableFunction &)op);
83: 	case LogicalOperatorType::ANY_JOIN:
84: 		return CreatePlan((LogicalAnyJoin &)op);
85: 	case LogicalOperatorType::DELIM_JOIN:
86: 		return CreatePlan((LogicalDelimJoin &)op);
87: 	case LogicalOperatorType::COMPARISON_JOIN:
88: 		return CreatePlan((LogicalComparisonJoin &)op);
89: 	case LogicalOperatorType::CROSS_PRODUCT:
90: 		return CreatePlan((LogicalCrossProduct &)op);
91: 	case LogicalOperatorType::UNION:
92: 	case LogicalOperatorType::EXCEPT:
93: 	case LogicalOperatorType::INTERSECT:
94: 		return CreatePlan((LogicalSetOperation &)op);
95: 	case LogicalOperatorType::INSERT:
96: 		return CreatePlan((LogicalInsert &)op);
97: 	case LogicalOperatorType::DELETE:
98: 		return CreatePlan((LogicalDelete &)op);
99: 	case LogicalOperatorType::CHUNK_GET:
100: 		return CreatePlan((LogicalChunkGet &)op);
101: 	case LogicalOperatorType::DELIM_GET:
102: 		return CreatePlan((LogicalDelimGet &)op);
103: 	case LogicalOperatorType::EXPRESSION_GET:
104: 		return CreatePlan((LogicalExpressionGet &)op);
105: 	case LogicalOperatorType::UPDATE:
106: 		return CreatePlan((LogicalUpdate &)op);
107: 	case LogicalOperatorType::CREATE_TABLE:
108: 		return CreatePlan((LogicalCreateTable &)op);
109: 	case LogicalOperatorType::CREATE_INDEX:
110: 		return CreatePlan((LogicalCreateIndex &)op);
111: 	case LogicalOperatorType::EXPLAIN:
112: 		return CreatePlan((LogicalExplain &)op);
113: 	case LogicalOperatorType::DISTINCT:
114: 		return CreatePlan((LogicalDistinct &)op);
115: 	case LogicalOperatorType::PRUNE_COLUMNS:
116: 		return CreatePlan((LogicalPruneColumns &)op);
117: 	case LogicalOperatorType::PREPARE:
118: 		return CreatePlan((LogicalPrepare &)op);
119: 	case LogicalOperatorType::EXECUTE:
120: 		return CreatePlan((LogicalExecute &)op);
121: 	case LogicalOperatorType::INDEX_SCAN:
122: 		return CreatePlan((LogicalIndexScan &)op);
123: 	case LogicalOperatorType::CREATE_VIEW:
124: 	case LogicalOperatorType::CREATE_SEQUENCE:
125: 	case LogicalOperatorType::CREATE_SCHEMA:
126: 		return CreatePlan((LogicalCreate &)op);
127: 	case LogicalOperatorType::TRANSACTION:
128: 	case LogicalOperatorType::ALTER:
129: 	case LogicalOperatorType::DROP:
130: 	case LogicalOperatorType::PRAGMA:
131: 	case LogicalOperatorType::VACUUM:
132: 		return CreatePlan((LogicalSimple &)op);
133: 	case LogicalOperatorType::RECURSIVE_CTE:
134: 		return CreatePlan((LogicalRecursiveCTE &)op);
135: 	case LogicalOperatorType::CTE_REF:
136: 		return CreatePlan((LogicalCTERef &)op);
137: 	default:
138: 		throw NotImplementedException("Unimplemented logical operator type!");
139: 	}
140: }
[end of src/execution/physical_plan_generator.cpp]
[start of src/function/aggregate/distributive/minmax.cpp]
1: #include "duckdb/function/aggregate/distributive_functions.hpp"
2: #include "duckdb/common/exception.hpp"
3: #include "duckdb/common/vector_operations/vector_operations.hpp"
4: #include "duckdb/common/operator/comparison_operators.hpp"
5: #include "duckdb/common/vector_operations/aggregate_executor.hpp"
6: #include "duckdb/common/operator/aggregate_operators.hpp"
7: #include "duckdb/common/types/null_value.hpp"
8: 
9: using namespace std;
10: 
11: namespace duckdb {
12: 
13: struct MinMaxBase : public StandardDistributiveFunction {
14: 	template <class INPUT_TYPE, class STATE, class OP>
15: 	static void ConstantOperation(STATE *state, INPUT_TYPE *input, nullmask_t &nullmask, idx_t count) {
16: 		assert(!nullmask[0]);
17: 		if (IsNullValue<INPUT_TYPE>(*state)) {
18: 			*state = input[0];
19: 		} else {
20: 			OP::template Execute<INPUT_TYPE, STATE>(state, input[0]);
21: 		}
22: 	}
23: 
24: 	template <class T, class STATE>
25: 	static void Finalize(Vector &result, STATE *state, T *target, nullmask_t &nullmask, idx_t idx) {
26: 		nullmask[idx] = IsNullValue<T>(*state);
27: 		target[idx] = *state;
28: 	}
29: };
30: 
31: struct NumericMinMaxBase : public MinMaxBase {
32: 	template <class INPUT_TYPE, class STATE>
33: 	static void Assign(STATE *state, INPUT_TYPE input) {
34: 		*state = input;
35: 	}
36: };
37: 
38: struct MinOperation : public NumericMinMaxBase {
39: 	template <class INPUT_TYPE, class STATE> static void Execute(STATE *state, INPUT_TYPE input) {
40: 		if (LessThan::Operation<INPUT_TYPE>(input, *state)) {
41: 			*state = input;
42: 		}
43: 	}
44: };
45: 
46: struct MaxOperation : public NumericMinMaxBase {
47: 	template <class INPUT_TYPE, class STATE> static void Execute(STATE *state, INPUT_TYPE input) {
48: 		if (GreaterThan::Operation<INPUT_TYPE>(input, *state)) {
49: 			*state = input;
50: 		}
51: 	}
52: };
53: 
54: struct StringMinMaxBase : public MinMaxBase {
55: 	template <class STATE> static void Destroy(STATE *state) {
56: 		if (!state->IsInlined()) {
57: 			delete[] state->GetData();
58: 		}
59: 	}
60: 
61: 	template <class INPUT_TYPE, class STATE>
62: 	static void Assign(STATE *state, INPUT_TYPE input) {
63: 		if (input.IsInlined()) {
64: 			*state = input;
65: 		} else {
66: 			// non-inlined string, need to allocate space for it
67: 			auto len = input.GetSize();
68: 			auto ptr = new char[len + 1];
69: 			memcpy(ptr, input.GetData(), len + 1);
70: 
71: 			*state = string_t(ptr, len);
72: 		}
73: 	}
74: };
75: 
76: struct MinOperationString : public StringMinMaxBase {
77: 	template <class INPUT_TYPE, class STATE>
78: 	static void Execute(STATE *state, INPUT_TYPE input) {
79: 		if (LessThan::Operation<INPUT_TYPE>(input, *state)) {
80: 			Assign(state, input);
81: 		}
82: 	}
83: };
84: 
85: struct MaxOperationString : public StringMinMaxBase {
86: 	template <class INPUT_TYPE, class STATE>
87: 	static void Execute(STATE *state, INPUT_TYPE input) {
88: 		if (GreaterThan::Operation<INPUT_TYPE>(input, *state)) {
89: 			Assign(state, input);
90: 		}
91: 	}
92: };
93: 
94: template<class OP, class OP_STRING>
95: static void AddMinMaxOperator(AggregateFunctionSet &set) {
96: 	for (auto type : SQLType::ALL_TYPES) {
97: 		if (type.id == SQLTypeId::VARCHAR) {
98: 			set.AddFunction(AggregateFunction::UnaryAggregateDestructor<string_t, string_t, string_t, OP_STRING>(SQLType::VARCHAR, SQLType::VARCHAR));
99: 		} else {
100: 			set.AddFunction(AggregateFunction::GetUnaryAggregate<OP>(type));
101: 		}
102: 	}
103: }
104: 
105: void MinFun::RegisterFunction(BuiltinFunctions &set) {
106: 	AggregateFunctionSet min("min");
107: 	AddMinMaxOperator<MinOperation, MinOperationString>(min);
108: 	set.AddFunction(min);
109: }
110: 
111: void MaxFun::RegisterFunction(BuiltinFunctions &set) {
112: 	AggregateFunctionSet max("max");
113: 	AddMinMaxOperator<MaxOperation, MaxOperationString>(max);
114: 	set.AddFunction(max);
115: }
116: 
117: } // namespace duckdb
[end of src/function/aggregate/distributive/minmax.cpp]
[start of src/function/scalar/operators/bitwise.cpp]
1: #include "duckdb/function/scalar/operators.hpp"
2: #include "duckdb/common/vector_operations/vector_operations.hpp"
3: 
4: using namespace duckdb;
5: using namespace std;
6: 
7: namespace duckdb {
8: 
9: //===--------------------------------------------------------------------===//
10: // & [bitwise_and]
11: //===--------------------------------------------------------------------===//
12: struct BitwiseANDOperator {
13: 	template <class TA, class TB, class TR> static inline TR Operation(TA left, TB right) {
14: 		return left & right;
15: 	}
16: };
17: 
18: void BitwiseAndFun::RegisterFunction(BuiltinFunctions &set) {
19: 	ScalarFunctionSet functions("&");
20: 	for (auto &type : SQLType::INTEGRAL) {
21: 		functions.AddFunction(ScalarFunction({type, type}, type,
22: 		                                     ScalarFunction::GetScalarIntegerBinaryFunction<BitwiseANDOperator>(type)));
23: 	}
24: 	set.AddFunction(functions);
25: }
26: 
27: //===--------------------------------------------------------------------===//
28: // | [bitwise_or]
29: //===--------------------------------------------------------------------===//
30: struct BitwiseOROperator {
31: 	template <class TA, class TB, class TR> static inline TR Operation(TA left, TB right) {
32: 		return left | right;
33: 	}
34: };
35: 
36: void BitwiseOrFun::RegisterFunction(BuiltinFunctions &set) {
37: 	ScalarFunctionSet functions("|");
38: 	for (auto &type : SQLType::INTEGRAL) {
39: 		functions.AddFunction(ScalarFunction({type, type}, type,
40: 		                                     ScalarFunction::GetScalarIntegerBinaryFunction<BitwiseOROperator>(type)));
41: 	}
42: 	set.AddFunction(functions);
43: }
44: 
45: //===--------------------------------------------------------------------===//
46: // # [bitwise_xor]
47: //===--------------------------------------------------------------------===//
48: struct BitwiseXOROperator {
49: 	template <class TA, class TB, class TR> static inline TR Operation(TA left, TB right) {
50: 		return left ^ right;
51: 	}
52: };
53: 
54: void BitwiseXorFun::RegisterFunction(BuiltinFunctions &set) {
55: 	ScalarFunctionSet functions("#");
56: 	for (auto &type : SQLType::INTEGRAL) {
57: 		functions.AddFunction(ScalarFunction({type, type}, type,
58: 		                                     ScalarFunction::GetScalarIntegerBinaryFunction<BitwiseXOROperator>(type)));
59: 	}
60: 	set.AddFunction(functions);
61: }
62: 
63: //===--------------------------------------------------------------------===//
64: // << [bitwise_left_shift]
65: //===--------------------------------------------------------------------===//
66: struct BitwiseShiftLeftOperator {
67: 	template <class TA, class TB, class TR> static inline TR Operation(TA left, TB right) {
68: 		return right < 0 ? 0 : left << right;
69: 	}
70: };
71: 
72: void LeftShiftFun::RegisterFunction(BuiltinFunctions &set) {
73: 	ScalarFunctionSet functions("<<");
74: 	for (auto &type : SQLType::INTEGRAL) {
75: 		functions.AddFunction(ScalarFunction(
76: 		    {type, type}, type, ScalarFunction::GetScalarIntegerBinaryFunction<BitwiseShiftLeftOperator>(type)));
77: 	}
78: 	set.AddFunction(functions);
79: }
80: 
81: //===--------------------------------------------------------------------===//
82: // >> [bitwise_right_shift]
83: //===--------------------------------------------------------------------===//
84: struct BitwiseShiftRightOperator {
85: 	template <class TA, class TB, class TR> static inline TR Operation(TA left, TB right) {
86: 		return right < 0 ? 0 : left >> right;
87: 	}
88: };
89: 
90: void RightShiftFun::RegisterFunction(BuiltinFunctions &set) {
91: 	ScalarFunctionSet functions(">>");
92: 	for (auto &type : SQLType::INTEGRAL) {
93: 		functions.AddFunction(ScalarFunction(
94: 		    {type, type}, type, ScalarFunction::GetScalarIntegerBinaryFunction<BitwiseShiftRightOperator>(type)));
95: 	}
96: 	set.AddFunction(functions);
97: }
98: 
99: } // namespace duckdb
[end of src/function/scalar/operators/bitwise.cpp]
[start of src/include/duckdb/common/enums/logical_operator_type.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/common/enums/logical_operator_type.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/constants.hpp"
12: 
13: namespace duckdb {
14: 
15: //===--------------------------------------------------------------------===//
16: // Logical Operator Types
17: //===--------------------------------------------------------------------===//
18: enum class LogicalOperatorType : uint8_t {
19: 	INVALID,
20: 	PROJECTION,
21: 	FILTER,
22: 	AGGREGATE_AND_GROUP_BY,
23: 	WINDOW,
24: 	UNNEST,
25: 	LIMIT,
26: 	ORDER_BY,
27: 	TOP_N,
28: 	COPY_FROM_FILE,
29: 	COPY_TO_FILE,
30: 	DISTINCT,
31: 	INDEX_SCAN,
32: 	// -----------------------------
33: 	// Data sources
34: 	// -----------------------------
35: 	GET,
36: 	CHUNK_GET,
37: 	DELIM_GET,
38: 	EXPRESSION_GET,
39: 	TABLE_FUNCTION,
40: 	EMPTY_RESULT,
41: 	CTE_REF,
42: 	// -----------------------------
43: 	// Joins
44: 	// -----------------------------
45: 	JOIN,
46: 	DELIM_JOIN,
47: 	COMPARISON_JOIN,
48: 	ANY_JOIN,
49: 	CROSS_PRODUCT,
50: 	// -----------------------------
51: 	// SetOps
52: 	// -----------------------------
53: 	UNION,
54: 	EXCEPT,
55: 	INTERSECT,
56: 	RECURSIVE_CTE,
57: 
58: 	// -----------------------------
59: 	// Updates
60: 	// -----------------------------
61: 	INSERT,
62: 	DELETE,
63: 	UPDATE,
64: 
65: 	// -----------------------------
66: 	// Schema
67: 	// -----------------------------
68: 	ALTER,
69: 	CREATE_TABLE,
70: 	CREATE_INDEX,
71: 	CREATE_SEQUENCE,
72: 	CREATE_VIEW,
73: 	CREATE_SCHEMA,
74: 	DROP,
75: 	PRAGMA,
76: 	TRANSACTION,
77: 
78: 	// -----------------------------
79: 	// Explain
80: 	// -----------------------------
81: 	EXPLAIN,
82: 
83: 	// -----------------------------
84: 	// Helpers
85: 	// -----------------------------
86: 	PRUNE_COLUMNS,
87: 	PREPARE,
88: 	EXECUTE,
89: 	VACUUM
90: };
91: 
92: string LogicalOperatorToString(LogicalOperatorType type);
93: 
94: } // namespace duckdb
[end of src/include/duckdb/common/enums/logical_operator_type.hpp]
[start of src/include/duckdb/common/enums/physical_operator_type.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/common/enums/physical_operator_type.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/constants.hpp"
12: 
13: namespace duckdb {
14: 
15: //===--------------------------------------------------------------------===//
16: // Physical Operator Types
17: //===--------------------------------------------------------------------===//
18: enum class PhysicalOperatorType : uint8_t {
19: 	INVALID,
20: 	LEAF,
21: 	ORDER_BY,
22: 	LIMIT,
23: 	TOP_N,
24: 	AGGREGATE,
25: 	WINDOW,
26: 	UNNEST,
27: 	DISTINCT,
28: 	SIMPLE_AGGREGATE,
29: 	HASH_GROUP_BY,
30: 	SORT_GROUP_BY,
31: 	FILTER,
32: 	PROJECTION,
33: 	COPY_FROM_FILE,
34: 	COPY_TO_FILE,
35: 	TABLE_FUNCTION,
36: 	// -----------------------------
37: 	// Scans
38: 	// -----------------------------
39: 	DUMMY_SCAN,
40: 	SEQ_SCAN,
41: 	INDEX_SCAN,
42: 	CHUNK_SCAN,
43: 	DELIM_SCAN,
44: 	EXTERNAL_FILE_SCAN,
45: 	QUERY_DERIVED_SCAN,
46: 	EXPRESSION_SCAN,
47: 	// -----------------------------
48: 	// Joins
49: 	// -----------------------------
50: 	BLOCKWISE_NL_JOIN,
51: 	NESTED_LOOP_JOIN,
52: 	HASH_JOIN,
53: 	CROSS_PRODUCT,
54: 	PIECEWISE_MERGE_JOIN,
55: 	DELIM_JOIN,
56: 
57: 	// -----------------------------
58: 	// SetOps
59: 	// -----------------------------
60: 	UNION,
61: 	RECURSIVE_CTE,
62: 
63: 	// -----------------------------
64: 	// Updates
65: 	// -----------------------------
66: 	INSERT,
67: 	INSERT_SELECT,
68: 	DELETE,
69: 	UPDATE,
70: 	EXPORT_EXTERNAL_FILE,
71: 
72: 	// -----------------------------
73: 	// Schema
74: 	// -----------------------------
75: 	CREATE,
76: 	CREATE_INDEX,
77: 	ALTER,
78: 	CREATE_SEQUENCE,
79: 	CREATE_VIEW,
80: 	CREATE_SCHEMA,
81: 	DROP,
82: 	PRAGMA,
83: 	TRANSACTION,
84: 
85: 	// -----------------------------
86: 	// Helpers
87: 	// -----------------------------
88: 	PRUNE_COLUMNS,
89: 	EXPLAIN,
90: 	EMPTY_RESULT,
91: 	EXECUTE,
92: 	PREPARE,
93: 	VACUUM
94: };
95: 
96: string PhysicalOperatorToString(PhysicalOperatorType type);
97: 
98: } // namespace duckdb
[end of src/include/duckdb/common/enums/physical_operator_type.hpp]
[start of src/include/duckdb/execution/operator/helper/physical_prune_columns.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/execution/operator/helper/physical_prune_columns.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/execution/physical_operator.hpp"
12: 
13: namespace duckdb {
14: 
15: //! PhysicalPruneColumns prunes (removes) columns from its input
16: class PhysicalPruneColumns : public PhysicalOperator {
17: public:
18: 	PhysicalPruneColumns(LogicalOperator &op, idx_t column_limit)
19: 	    : PhysicalOperator(PhysicalOperatorType::PRUNE_COLUMNS, op.types), column_limit(column_limit) {
20: 	}
21: 
22: 	idx_t column_limit;
23: 
24: public:
25: 	void GetChunkInternal(ClientContext &context, DataChunk &chunk, PhysicalOperatorState *state) override;
26: };
27: } // namespace duckdb
[end of src/include/duckdb/execution/operator/helper/physical_prune_columns.hpp]
[start of src/include/duckdb/execution/operator/list.hpp]
1: #include "duckdb/execution/operator/aggregate/physical_hash_aggregate.hpp"
2: #include "duckdb/execution/operator/aggregate/physical_simple_aggregate.hpp"
3: #include "duckdb/execution/operator/aggregate/physical_window.hpp"
4: #include "duckdb/execution/operator/filter/physical_filter.hpp"
5: #include "duckdb/execution/operator/helper/physical_execute.hpp"
6: #include "duckdb/execution/operator/helper/physical_limit.hpp"
7: #include "duckdb/execution/operator/helper/physical_pragma.hpp"
8: #include "duckdb/execution/operator/helper/physical_prepare.hpp"
9: #include "duckdb/execution/operator/helper/physical_prune_columns.hpp"
10: #include "duckdb/execution/operator/helper/physical_transaction.hpp"
11: #include "duckdb/execution/operator/helper/physical_vacuum.hpp"
12: #include "duckdb/execution/operator/join/physical_blockwise_nl_join.hpp"
13: #include "duckdb/execution/operator/join/physical_comparison_join.hpp"
14: #include "duckdb/execution/operator/join/physical_cross_product.hpp"
15: #include "duckdb/execution/operator/join/physical_delim_join.hpp"
16: #include "duckdb/execution/operator/join/physical_hash_join.hpp"
17: #include "duckdb/execution/operator/join/physical_join.hpp"
18: #include "duckdb/execution/operator/join/physical_nested_loop_join.hpp"
19: #include "duckdb/execution/operator/join/physical_piecewise_merge_join.hpp"
20: #include "duckdb/execution/operator/order/physical_order.hpp"
21: #include "duckdb/execution/operator/order/physical_top_n.hpp"
22: #include "duckdb/execution/operator/persistent/buffered_csv_reader.hpp"
23: #include "duckdb/execution/operator/persistent/physical_copy_from_file.hpp"
24: #include "duckdb/execution/operator/persistent/physical_copy_to_file.hpp"
25: #include "duckdb/execution/operator/persistent/physical_delete.hpp"
26: #include "duckdb/execution/operator/persistent/physical_insert.hpp"
27: #include "duckdb/execution/operator/persistent/physical_update.hpp"
28: #include "duckdb/execution/operator/projection/physical_projection.hpp"
29: #include "duckdb/execution/operator/projection/physical_unnest.hpp"
30: #include "duckdb/execution/operator/scan/physical_chunk_scan.hpp"
31: #include "duckdb/execution/operator/scan/physical_dummy_scan.hpp"
32: #include "duckdb/execution/operator/scan/physical_empty_result.hpp"
33: #include "duckdb/execution/operator/scan/physical_expression_scan.hpp"
34: #include "duckdb/execution/operator/scan/physical_index_scan.hpp"
35: #include "duckdb/execution/operator/scan/physical_table_function.hpp"
36: #include "duckdb/execution/operator/scan/physical_table_scan.hpp"
37: #include "duckdb/execution/operator/schema/physical_alter.hpp"
38: #include "duckdb/execution/operator/schema/physical_create_index.hpp"
39: #include "duckdb/execution/operator/schema/physical_create_schema.hpp"
40: #include "duckdb/execution/operator/schema/physical_create_sequence.hpp"
41: #include "duckdb/execution/operator/schema/physical_create_table.hpp"
42: #include "duckdb/execution/operator/schema/physical_create_view.hpp"
43: #include "duckdb/execution/operator/schema/physical_drop.hpp"
44: #include "duckdb/execution/operator/set/physical_recursive_cte.hpp"
45: #include "duckdb/execution/operator/set/physical_union.hpp"
[end of src/include/duckdb/execution/operator/list.hpp]
[start of src/include/duckdb/execution/physical_plan_generator.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/execution/physical_plan_generator.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/common.hpp"
12: #include "duckdb/execution/physical_operator.hpp"
13: #include "duckdb/planner/logical_operator.hpp"
14: #include "duckdb/planner/logical_tokens.hpp"
15: #include "duckdb/common/types/chunk_collection.hpp"
16: 
17: namespace duckdb {
18: class ClientContext;
19: 
20: //! The physical plan generator generates a physical execution plan from a
21: //! logical query plan
22: class PhysicalPlanGenerator {
23: public:
24: 	PhysicalPlanGenerator(ClientContext &context) : context(context) {
25: 	}
26: 
27: 	unordered_set<CatalogEntry *> dependencies;
28: 	//! Recursive CTEs require at least one ChunkScan, referencing the working_table.
29: 	//! This data structure is used to establish it.
30: 	unordered_map<idx_t, std::shared_ptr<ChunkCollection>> rec_ctes;
31: 
32: public:
33: 	//! Creates a plan from the logical operator. This involves resolving column bindings and generating physical
34: 	//! operator nodes.
35: 	unique_ptr<PhysicalOperator> CreatePlan(unique_ptr<LogicalOperator> logical);
36: 
37: protected:
38: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalOperator &op);
39: 
40: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalAggregate &op);
41: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalAnyJoin &op);
42: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalChunkGet &op);
43: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalComparisonJoin &op);
44: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalCreate &op);
45: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalCreateTable &op);
46: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalCreateIndex &op);
47: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalCrossProduct &op);
48: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalDelete &op);
49: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalDelimGet &op);
50: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalDelimJoin &op);
51: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalDistinct &op);
52: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalEmptyResult &op);
53: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalExpressionGet &op);
54: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalFilter &op);
55: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalGet &op);
56: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalLimit &op);
57: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalIndexScan &op);
58: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalOrder &op);
59: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalTopN &op);
60: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalProjection &op);
61: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalInsert &op);
62: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalCopyFromFile &op);
63: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalCopyToFile &op);
64: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalExplain &op);
65: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalSetOperation &op);
66: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalUpdate &op);
67: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalTableFunction &expr);
68: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalPruneColumns &expr);
69: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalPrepare &expr);
70: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalWindow &expr);
71: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalExecute &op);
72: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalSimple &op);
73: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalUnnest &op);
74: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalRecursiveCTE &op);
75: 	unique_ptr<PhysicalOperator> CreatePlan(LogicalCTERef &op);
76: 
77: 	unique_ptr<PhysicalOperator> CreateDistinct(unique_ptr<PhysicalOperator> child);
78: 	unique_ptr<PhysicalOperator> CreateDistinctOn(unique_ptr<PhysicalOperator> child,
79: 	                                              vector<unique_ptr<Expression>> distinct_targets);
80: 
81: private:
82: 	ClientContext &context;
83: };
84: } // namespace duckdb
[end of src/include/duckdb/execution/physical_plan_generator.hpp]
[start of src/include/duckdb/planner/logical_tokens.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/planner/logical_tokens.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: namespace duckdb {
12: 
13: class LogicalOperator;
14: 
15: class LogicalAggregate;
16: class LogicalAnyJoin;
17: class LogicalChunkGet;
18: class LogicalComparisonJoin;
19: class LogicalCopyFromFile;
20: class LogicalCopyToFile;
21: class LogicalCreate;
22: class LogicalCreateTable;
23: class LogicalCreateIndex;
24: class LogicalCreateTable;
25: class LogicalCrossProduct;
26: class LogicalCTERef;
27: class LogicalDelete;
28: class LogicalDelimGet;
29: class LogicalDelimJoin;
30: class LogicalDistinct;
31: class LogicalEmptyResult;
32: class LogicalExecute;
33: class LogicalExplain;
34: class LogicalExpressionGet;
35: class LogicalFilter;
36: class LogicalGet;
37: class LogicalIndexScan;
38: class LogicalInsert;
39: class LogicalJoin;
40: class LogicalLimit;
41: class LogicalOrder;
42: class LogicalPrepare;
43: class LogicalProjection;
44: class LogicalPruneColumns;
45: class LogicalRecursiveCTE;
46: class LogicalSetOperation;
47: class LogicalSimple;
48: class LogicalTableFunction;
49: class LogicalTopN;
50: class LogicalUnnest;
51: class LogicalUpdate;
52: class LogicalWindow;
53: 
54: } // namespace duckdb
[end of src/include/duckdb/planner/logical_tokens.hpp]
[start of src/include/duckdb/planner/operator/list.hpp]
1: #include "duckdb/planner/operator/logical_aggregate.hpp"
2: #include "duckdb/planner/operator/logical_any_join.hpp"
3: #include "duckdb/planner/operator/logical_chunk_get.hpp"
4: #include "duckdb/planner/operator/logical_comparison_join.hpp"
5: #include "duckdb/planner/operator/logical_copy_from_file.hpp"
6: #include "duckdb/planner/operator/logical_copy_to_file.hpp"
7: #include "duckdb/planner/operator/logical_create.hpp"
8: #include "duckdb/planner/operator/logical_create_index.hpp"
9: #include "duckdb/planner/operator/logical_create_table.hpp"
10: #include "duckdb/planner/operator/logical_cross_product.hpp"
11: #include "duckdb/planner/operator/logical_cteref.hpp"
12: #include "duckdb/planner/operator/logical_delete.hpp"
13: #include "duckdb/planner/operator/logical_delim_get.hpp"
14: #include "duckdb/planner/operator/logical_delim_join.hpp"
15: #include "duckdb/planner/operator/logical_distinct.hpp"
16: #include "duckdb/planner/operator/logical_empty_result.hpp"
17: #include "duckdb/planner/operator/logical_execute.hpp"
18: #include "duckdb/planner/operator/logical_explain.hpp"
19: #include "duckdb/planner/operator/logical_expression_get.hpp"
20: #include "duckdb/planner/operator/logical_filter.hpp"
21: #include "duckdb/planner/operator/logical_get.hpp"
22: #include "duckdb/planner/operator/logical_index_scan.hpp"
23: #include "duckdb/planner/operator/logical_insert.hpp"
24: #include "duckdb/planner/operator/logical_join.hpp"
25: #include "duckdb/planner/operator/logical_limit.hpp"
26: #include "duckdb/planner/operator/logical_order.hpp"
27: #include "duckdb/planner/operator/logical_prepare.hpp"
28: #include "duckdb/planner/operator/logical_projection.hpp"
29: #include "duckdb/planner/operator/logical_prune_columns.hpp"
30: #include "duckdb/planner/operator/logical_recursive_cte.hpp"
31: #include "duckdb/planner/operator/logical_set_operation.hpp"
32: #include "duckdb/planner/operator/logical_simple.hpp"
33: #include "duckdb/planner/operator/logical_table_function.hpp"
34: #include "duckdb/planner/operator/logical_top_n.hpp"
35: #include "duckdb/planner/operator/logical_unnest.hpp"
36: #include "duckdb/planner/operator/logical_update.hpp"
37: #include "duckdb/planner/operator/logical_window.hpp"
[end of src/include/duckdb/planner/operator/list.hpp]
[start of src/include/duckdb/planner/operator/logical_prune_columns.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/planner/operator/logical_prune_columns.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/planner/logical_operator.hpp"
12: 
13: namespace duckdb {
14: 
15: //! LogicalPruneColumns represents a node that prunes extra columns from its
16: //! children
17: class LogicalPruneColumns : public LogicalOperator {
18: public:
19: 	LogicalPruneColumns(idx_t column_limit)
20: 	    : LogicalOperator(LogicalOperatorType::PRUNE_COLUMNS), column_limit(column_limit) {
21: 	}
22: 
23: 	idx_t column_limit;
24: 
25: public:
26: 	vector<ColumnBinding> GetColumnBindings() override;
27: 
28: protected:
29: 	void ResolveTypes() override;
30: };
31: 
32: } // namespace duckdb
[end of src/include/duckdb/planner/operator/logical_prune_columns.hpp]
[start of src/include/duckdb/planner/query_node/bound_select_node.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/planner/query_node/bound_select_node.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/planner/bound_query_node.hpp"
12: #include "duckdb/planner/logical_operator.hpp"
13: #include "duckdb/parser/expression_map.hpp"
14: #include "duckdb/planner/bound_tableref.hpp"
15: 
16: namespace duckdb {
17: 
18: //! Bound equivalent of SelectNode
19: class BoundSelectNode : public BoundQueryNode {
20: public:
21: 	BoundSelectNode() : BoundQueryNode(QueryNodeType::SELECT_NODE) {
22: 	}
23: 
24: 	//! The original unparsed expressions. This is exported after binding, because the binding might change the
25: 	//! expressions (e.g. when a * clause is present)
26: 	vector<unique_ptr<ParsedExpression>> original_expressions;
27: 
28: 	//! The projection list
29: 	vector<unique_ptr<Expression>> select_list;
30: 	//! The FROM clause
31: 	unique_ptr<BoundTableRef> from_table;
32: 	//! The WHERE clause
33: 	unique_ptr<Expression> where_clause;
34: 	//! list of groups
35: 	vector<unique_ptr<Expression>> groups;
36: 	//! HAVING clause
37: 	unique_ptr<Expression> having;
38: 
39: 	//! The amount of columns in the final result
40: 	idx_t column_count;
41: 
42: 	//! Index used by the LogicalProjection
43: 	idx_t projection_index;
44: 
45: 	//! Group index used by the LogicalAggregate (only used if HasAggregation is true)
46: 	idx_t group_index;
47: 	//! Aggregate index used by the LogicalAggregate (only used if HasAggregation is true)
48: 	idx_t aggregate_index;
49: 	//! Aggregate functions to compute (only used if HasAggregation is true)
50: 	vector<unique_ptr<Expression>> aggregates;
51: 
52: 	//! Map from aggregate function to aggregate index (used to eliminate duplicate aggregates)
53: 	expression_map_t<idx_t> aggregate_map;
54: 
55: 	//! Window index used by the LogicalWindow (only used if HasWindow is true)
56: 	idx_t window_index;
57: 	//! Window functions to compute (only used if HasWindow is true)
58: 	vector<unique_ptr<Expression>> windows;
59: 
60: 	idx_t unnest_index;
61: 	//! Unnest expression
62: 	vector<unique_ptr<Expression>> unnests;
63: 
64: public:
65: 	idx_t GetRootIndex() override {
66: 		return projection_index;
67: 	}
68: };
69: }; // namespace duckdb
[end of src/include/duckdb/planner/query_node/bound_select_node.hpp]
[start of src/optimizer/filter_pushdown.cpp]
1: #include "duckdb/optimizer/filter_pushdown.hpp"
2: 
3: #include "duckdb/optimizer/filter_combiner.hpp"
4: #include "duckdb/planner/operator/logical_filter.hpp"
5: #include "duckdb/planner/operator/logical_join.hpp"
6: 
7: using namespace duckdb;
8: using namespace std;
9: 
10: using Filter = FilterPushdown::Filter;
11: 
12: unique_ptr<LogicalOperator> FilterPushdown::Rewrite(unique_ptr<LogicalOperator> op) {
13: 	assert(!combiner.HasFilters());
14: 	switch (op->type) {
15: 	case LogicalOperatorType::AGGREGATE_AND_GROUP_BY:
16: 		return PushdownAggregate(move(op));
17: 	case LogicalOperatorType::FILTER:
18: 		return PushdownFilter(move(op));
19: 	case LogicalOperatorType::CROSS_PRODUCT:
20: 		return PushdownCrossProduct(move(op));
21: 	case LogicalOperatorType::COMPARISON_JOIN:
22: 	case LogicalOperatorType::ANY_JOIN:
23: 	case LogicalOperatorType::DELIM_JOIN:
24: 		return PushdownJoin(move(op));
25: 	case LogicalOperatorType::PROJECTION:
26: 		return PushdownProjection(move(op));
27: 	case LogicalOperatorType::INTERSECT:
28: 	case LogicalOperatorType::EXCEPT:
29: 	case LogicalOperatorType::UNION:
30: 		return PushdownSetOperation(move(op));
31: 	case LogicalOperatorType::DISTINCT:
32: 	case LogicalOperatorType::ORDER_BY:
33: 	case LogicalOperatorType::PRUNE_COLUMNS: {
34: 		// we can just push directly through these operations without any rewriting
35: 		op->children[0] = Rewrite(move(op->children[0]));
36: 		return op;
37: 	}
38: 	case LogicalOperatorType::GET:
39: 		return PushdownGet(move(op));
40: 	default:
41: 		return FinishPushdown(move(op));
42: 	}
43: }
44: 
45: unique_ptr<LogicalOperator> FilterPushdown::PushdownJoin(unique_ptr<LogicalOperator> op) {
46: 	assert(op->type == LogicalOperatorType::COMPARISON_JOIN || op->type == LogicalOperatorType::ANY_JOIN ||
47: 	       op->type == LogicalOperatorType::DELIM_JOIN);
48: 	auto &join = (LogicalJoin &)*op;
49: 	unordered_set<idx_t> left_bindings, right_bindings;
50: 	LogicalJoin::GetTableReferences(*op->children[0], left_bindings);
51: 	LogicalJoin::GetTableReferences(*op->children[1], right_bindings);
52: 
53: 	switch (join.join_type) {
54: 	case JoinType::INNER:
55: 		return PushdownInnerJoin(move(op), left_bindings, right_bindings);
56: 	case JoinType::LEFT:
57: 		return PushdownLeftJoin(move(op), left_bindings, right_bindings);
58: 	case JoinType::MARK:
59: 		return PushdownMarkJoin(move(op), left_bindings, right_bindings);
60: 	case JoinType::SINGLE:
61: 		return PushdownSingleJoin(move(op), left_bindings, right_bindings);
62: 	default:
63: 		// unsupported join type: stop pushing down
64: 		return FinishPushdown(move(op));
65: 	}
66: }
67: void FilterPushdown::PushFilters() {
68: 	for (auto &f : filters) {
69: 		auto result = combiner.AddFilter(move(f->filter));
70: 		assert(result == FilterResult::SUCCESS);
71: 	}
72: 	filters.clear();
73: }
74: FilterResult FilterPushdown::AddFilter(unique_ptr<Expression> expr) {
75: 	PushFilters();
76: 	// split up the filters by AND predicate
77: 	vector<unique_ptr<Expression>> expressions;
78: 	expressions.push_back(move(expr));
79: 	LogicalFilter::SplitPredicates(expressions);
80: 	// push the filters into the combiner
81: 	for (auto &expr : expressions) {
82: 		if (combiner.AddFilter(move(expr)) == FilterResult::UNSATISFIABLE) {
83: 			return FilterResult::UNSATISFIABLE;
84: 		}
85: 	}
86: 	return FilterResult::SUCCESS;
87: }
88: 
89: void FilterPushdown::GenerateFilters() {
90: 	if (filters.size() > 0) {
91: 		assert(!combiner.HasFilters());
92: 		return;
93: 	}
94: 	combiner.GenerateFilters([&](unique_ptr<Expression> filter) {
95: 		auto f = make_unique<Filter>();
96: 		f->filter = move(filter);
97: 		f->ExtractBindings();
98: 		filters.push_back(move(f));
99: 	});
100: }
101: 
102: unique_ptr<LogicalOperator> FilterPushdown::FinishPushdown(unique_ptr<LogicalOperator> op) {
103: 	// unhandled type, first perform filter pushdown in its children
104: 	for (idx_t i = 0; i < op->children.size(); i++) {
105: 		FilterPushdown pushdown(optimizer);
106: 		op->children[i] = pushdown.Rewrite(move(op->children[i]));
107: 	}
108: 	// now push any existing filters
109: 	if (filters.size() == 0) {
110: 		// no filters to push
111: 		return op;
112: 	}
113: 	auto filter = make_unique<LogicalFilter>();
114: 	for (auto &f : filters) {
115: 		filter->expressions.push_back(move(f->filter));
116: 	}
117: 	filter->children.push_back(move(op));
118: 	return move(filter);
119: }
120: 
121: void FilterPushdown::Filter::ExtractBindings() {
122: 	bindings.clear();
123: 	LogicalJoin::GetExpressionBindings(*filter, bindings);
124: }
[end of src/optimizer/filter_pushdown.cpp]
[start of src/planner/binder/query_node/bind_select_node.cpp]
1: #include "duckdb/parser/expression/columnref_expression.hpp"
2: #include "duckdb/parser/expression/constant_expression.hpp"
3: #include "duckdb/parser/query_node/select_node.hpp"
4: #include "duckdb/parser/tableref/joinref.hpp"
5: #include "duckdb/planner/binder.hpp"
6: #include "duckdb/execution/expression_executor.hpp"
7: #include "duckdb/planner/expression_binder/constant_binder.hpp"
8: #include "duckdb/planner/expression_binder/group_binder.hpp"
9: #include "duckdb/planner/expression_binder/having_binder.hpp"
10: #include "duckdb/planner/expression_binder/order_binder.hpp"
11: #include "duckdb/planner/expression_binder/select_binder.hpp"
12: #include "duckdb/planner/expression_binder/where_binder.hpp"
13: #include "duckdb/planner/query_node/bound_select_node.hpp"
14: #include "duckdb/parser/expression/table_star_expression.hpp"
15: 
16: using namespace std;
17: 
18: namespace duckdb {
19: 
20: static int64_t BindConstant(Binder &binder, ClientContext &context, string clause, unique_ptr<ParsedExpression> &expr) {
21: 	ConstantBinder constant_binder(binder, context, clause);
22: 	auto bound_expr = constant_binder.Bind(expr);
23: 	Value value = ExpressionExecutor::EvaluateScalar(*bound_expr);
24: 	if (!TypeIsNumeric(value.type)) {
25: 		throw BinderException("LIMIT clause can only contain numeric constants!");
26: 	}
27: 	int64_t limit_value = value.GetValue<int64_t>();
28: 	if (limit_value < 0) {
29: 		throw BinderException("LIMIT must not be negative");
30: 	}
31: 	return limit_value;
32: }
33: 
34: unique_ptr<Expression> Binder::BindFilter(unique_ptr<ParsedExpression> condition) {
35: 	WhereBinder where_binder(*this, context);
36: 	return where_binder.Bind(condition);
37: }
38: 
39: unique_ptr<Expression> Binder::BindOrderExpression(OrderBinder &order_binder, unique_ptr<ParsedExpression> expr) {
40: 	// we treat the Distinct list as a order by
41: 	auto bound_expr = order_binder.Bind(move(expr));
42: 	if (!bound_expr) {
43: 		// DISTINCT ON non-integer constant
44: 		// remove the expression from the DISTINCT ON list
45: 		return nullptr;
46: 	}
47: 	assert(bound_expr->type == ExpressionType::BOUND_COLUMN_REF);
48: 	return bound_expr;
49: }
50: 
51: unique_ptr<BoundResultModifier> Binder::BindLimit(LimitModifier &limit_mod) {
52: 	auto result = make_unique<BoundLimitModifier>();
53: 	if (limit_mod.limit) {
54: 		result->limit = BindConstant(*this, context, "LIMIT clause", limit_mod.limit);
55: 		result->offset = 0;
56: 	}
57: 	if (limit_mod.offset) {
58: 		result->offset = BindConstant(*this, context, "OFFSET clause", limit_mod.offset);
59: 		if (!limit_mod.limit) {
60: 			result->limit = std::numeric_limits<int64_t>::max();
61: 		}
62: 	}
63: 	return move(result);
64: }
65: 
66: void Binder::BindModifiers(OrderBinder &order_binder, QueryNode &statement, BoundQueryNode &result) {
67: 	for (auto &mod : statement.modifiers) {
68: 		unique_ptr<BoundResultModifier> bound_modifier;
69: 		switch (mod->type) {
70: 		case ResultModifierType::DISTINCT_MODIFIER: {
71: 			auto &distinct = (DistinctModifier &)*mod;
72: 			auto bound_distinct = make_unique<BoundDistinctModifier>();
73: 			for (idx_t i = 0; i < distinct.distinct_on_targets.size(); i++) {
74: 				auto expr = BindOrderExpression(order_binder, move(distinct.distinct_on_targets[i]));
75: 				if (!expr) {
76: 					continue;
77: 				}
78: 				bound_distinct->target_distincts.push_back(move(expr));
79: 			}
80: 			bound_modifier = move(bound_distinct);
81: 			break;
82: 		}
83: 		case ResultModifierType::ORDER_MODIFIER: {
84: 			auto &order = (OrderModifier &)*mod;
85: 			auto bound_order = make_unique<BoundOrderModifier>();
86: 			for (idx_t i = 0; i < order.orders.size(); i++) {
87: 				BoundOrderByNode node;
88: 				node.type = order.orders[i].type;
89: 				node.expression = BindOrderExpression(order_binder, move(order.orders[i].expression));
90: 				if (!node.expression) {
91: 					continue;
92: 				}
93: 				bound_order->orders.push_back(move(node));
94: 			}
95: 			bound_modifier = move(bound_order);
96: 			break;
97: 		}
98: 		case ResultModifierType::LIMIT_MODIFIER:
99: 			bound_modifier = BindLimit((LimitModifier &)*mod);
100: 			break;
101: 		default:
102: 			throw Exception("Unsupported result modifier");
103: 		}
104: 		result.modifiers.push_back(move(bound_modifier));
105: 	}
106: }
107: 
108: void Binder::BindModifierTypes(BoundQueryNode &result, const vector<TypeId> &types, idx_t projection_index) {
109: 	for (auto &bound_mod : result.modifiers) {
110: 		switch (bound_mod->type) {
111: 		case ResultModifierType::DISTINCT_MODIFIER: {
112: 			auto &distinct = (BoundDistinctModifier &)*bound_mod;
113: 			if (distinct.target_distincts.size() == 0) {
114: 				// DISTINCT without a target: push references to the standard select list
115: 				for (idx_t i = 0; i < types.size(); i++) {
116: 					distinct.target_distincts.push_back(
117: 					    make_unique<BoundColumnRefExpression>(types[i], ColumnBinding(projection_index, i)));
118: 				}
119: 			} else {
120: 				// DISTINCT with target list: set types
121: 				for (idx_t i = 0; i < distinct.target_distincts.size(); i++) {
122: 					auto &expr = distinct.target_distincts[i];
123: 					assert(expr->type == ExpressionType::BOUND_COLUMN_REF);
124: 					auto &bound_colref = (BoundColumnRefExpression &)*expr;
125: 					if (bound_colref.binding.column_index == INVALID_INDEX) {
126: 						throw BinderException("Ambiguous name in DISTINCT ON!");
127: 					}
128: 					assert(bound_colref.binding.column_index < types.size());
129: 					bound_colref.return_type = types[bound_colref.binding.column_index];
130: 				}
131: 			}
132: 			break;
133: 		}
134: 		case ResultModifierType::ORDER_MODIFIER: {
135: 			auto &order = (BoundOrderModifier &)*bound_mod;
136: 			for (idx_t i = 0; i < order.orders.size(); i++) {
137: 				auto &expr = order.orders[i].expression;
138: 				assert(expr->type == ExpressionType::BOUND_COLUMN_REF);
139: 				auto &bound_colref = (BoundColumnRefExpression &)*expr;
140: 				if (bound_colref.binding.column_index == INVALID_INDEX) {
141: 					throw BinderException("Ambiguous name in ORDER BY!");
142: 				}
143: 				assert(bound_colref.binding.column_index < types.size());
144: 				bound_colref.return_type = types[bound_colref.binding.column_index];
145: 			}
146: 			break;
147: 		}
148: 		default:
149: 			break;
150: 		}
151: 	}
152: }
153: 
154: unique_ptr<BoundQueryNode> Binder::BindNode(SelectNode &statement) {
155: 	auto result = make_unique<BoundSelectNode>();
156: 	result->projection_index = GenerateTableIndex();
157: 	result->group_index = GenerateTableIndex();
158: 	result->aggregate_index = GenerateTableIndex();
159: 	result->window_index = GenerateTableIndex();
160: 	result->unnest_index = GenerateTableIndex();
161: 
162: 	// first bind the FROM table statement
163: 	result->from_table = Bind(*statement.from_table);
164: 
165: 	// visit the select list and expand any "*" statements
166: 	vector<unique_ptr<ParsedExpression>> new_select_list;
167: 	for (auto &select_element : statement.select_list) {
168: 		if (select_element->GetExpressionType() == ExpressionType::STAR) {
169: 			// * statement, expand to all columns from the FROM clause
170: 			bind_context.GenerateAllColumnExpressions(new_select_list);
171: 		} else if (select_element->GetExpressionType() == ExpressionType::TABLE_STAR) {
172: 			auto table_star =
173: 			    (TableStarExpression *)select_element.get(); // TODO this cast to explicit class is a bit dirty?
174: 			bind_context.GenerateAllColumnExpressions(new_select_list, table_star->relation_name);
175: 		} else {
176: 			// regular statement, add it to the list
177: 			new_select_list.push_back(move(select_element));
178: 		}
179: 	}
180: 	statement.select_list = move(new_select_list);
181: 
182: 	// create a mapping of (alias -> index) and a mapping of (Expression -> index) for the SELECT list
183: 	unordered_map<string, idx_t> alias_map;
184: 	expression_map_t<idx_t> projection_map;
185: 	for (idx_t i = 0; i < statement.select_list.size(); i++) {
186: 		auto &expr = statement.select_list[i];
187: 		result->names.push_back(expr->GetName());
188: 		if (!expr->alias.empty()) {
189: 			alias_map[expr->alias] = i;
190: 		}
191: 		ExpressionBinder::BindTableNames(*this, *expr);
192: 		projection_map[expr.get()] = i;
193: 		result->original_expressions.push_back(expr->Copy());
194: 	}
195: 	result->column_count = statement.select_list.size();
196: 
197: 	// first visit the WHERE clause
198: 	// the WHERE clause happens before the GROUP BY, PROJECTION or HAVING clauses
199: 	if (statement.where_clause) {
200: 		result->where_clause = BindFilter(move(statement.where_clause));
201: 	}
202: 
203: 	// now bind all the result modifiers; including DISTINCT and ORDER BY targets
204: 	OrderBinder order_binder({this}, result->projection_index, statement, alias_map, projection_map);
205: 	BindModifiers(order_binder, statement, *result);
206: 
207: 	vector<unique_ptr<ParsedExpression>> unbound_groups;
208: 	BoundGroupInformation info;
209: 	if (statement.groups.size() > 0) {
210: 		// the statement has a GROUP BY clause, bind it
211: 		unbound_groups.resize(statement.groups.size());
212: 		GroupBinder group_binder(*this, context, statement, result->group_index, alias_map, info.alias_map);
213: 		for (idx_t i = 0; i < statement.groups.size(); i++) {
214: 
215: 			// we keep a copy of the unbound expression;
216: 			// we keep the unbound copy around to check for group references in the SELECT and HAVING clause
217: 			// the reason we want the unbound copy is because we want to figure out whether an expression
218: 			// is a group reference BEFORE binding in the SELECT/HAVING binder
219: 			group_binder.unbound_expression = statement.groups[i]->Copy();
220: 			group_binder.bind_index = i;
221: 
222: 			// bind the groups
223: 			SQLType group_type;
224: 			auto bound_expr = group_binder.Bind(statement.groups[i], &group_type);
225: 			assert(bound_expr->return_type != TypeId::INVALID);
226: 			info.group_types.push_back(group_type);
227: 			result->groups.push_back(move(bound_expr));
228: 
229: 			// in the unbound expression we DO bind the table names of any ColumnRefs
230: 			// we do this to make sure that "table.a" and "a" are treated the same
231: 			// if we wouldn't do this then (SELECT test.a FROM test GROUP BY a) would not work because "test.a" <> "a"
232: 			// hence we convert "a" -> "test.a" in the unbound expression
233: 			unbound_groups[i] = move(group_binder.unbound_expression);
234: 			ExpressionBinder::BindTableNames(*this, *unbound_groups[i]);
235: 			info.map[unbound_groups[i].get()] = i;
236: 		}
237: 	}
238: 
239: 	// bind the HAVING clause, if any
240: 	if (statement.having) {
241: 		HavingBinder having_binder(*this, context, *result, info);
242: 		ExpressionBinder::BindTableNames(*this, *statement.having);
243: 		result->having = having_binder.Bind(statement.having);
244: 	}
245: 
246: 	// after that, we bind to the SELECT list
247: 	SelectBinder select_binder(*this, context, *result, info);
248: 	vector<TypeId> internal_types;
249: 	for (idx_t i = 0; i < statement.select_list.size(); i++) {
250: 		SQLType result_type;
251: 		auto expr = select_binder.Bind(statement.select_list[i], &result_type);
252: 		if (statement.aggregate_handling == AggregateHandling::FORCE_AGGREGATES && select_binder.BoundColumns()) {
253: 			if (select_binder.BoundAggregates()) {
254: 				throw BinderException("Cannot mix aggregates with non-aggregated columns!");
255: 			}
256: 			// we are forcing aggregates, and the node has columns bound
257: 			// this entry becomes a group
258: 			auto group_type = expr->return_type;
259: 			auto group_ref = make_unique<BoundColumnRefExpression>(
260: 			    group_type, ColumnBinding(result->group_index, result->groups.size()));
261: 			result->groups.push_back(move(expr));
262: 			expr = move(group_ref);
263: 		}
264: 		result->select_list.push_back(move(expr));
265: 		if (i < result->column_count) {
266: 			result->types.push_back(result_type);
267: 		}
268: 		internal_types.push_back(GetInternalType(result_type));
269: 		if (statement.aggregate_handling == AggregateHandling::FORCE_AGGREGATES) {
270: 			select_binder.ResetBindings();
271: 		}
272: 	}
273: 	// in the normal select binder, we bind columns as if there is no aggregation
274: 	// i.e. in the query [SELECT i, SUM(i) FROM integers;] the "i" will be bound as a normal column
275: 	// since we have an aggregation, we need to either (1) throw an error, or (2) wrap the column in a FIRST() aggregate
276: 	// we choose the former one [CONTROVERSIAL: this is the PostgreSQL behavior]
277: 	if (result->groups.size() > 0 || result->aggregates.size() > 0 || statement.having) {
278: 		if (statement.aggregate_handling == AggregateHandling::NO_AGGREGATES_ALLOWED) {
279: 			throw BinderException("Aggregates cannot be present in a Project relation!");
280: 		} else if (statement.aggregate_handling == AggregateHandling::STANDARD_HANDLING) {
281: 			if (select_binder.BoundColumns()) {
282: 				throw BinderException("column must appear in the GROUP BY clause or be used in an aggregate function");
283: 			}
284: 		}
285: 	}
286: 
287: 	// now that the SELECT list is bound, we set the types of DISTINCT/ORDER BY expressions
288: 	BindModifierTypes(*result, internal_types, result->projection_index);
289: 	return move(result);
290: }
291: 
292: } // namespace duckdb
[end of src/planner/binder/query_node/bind_select_node.cpp]
[start of src/planner/binder/query_node/plan_select_node.cpp]
1: #include "duckdb/planner/binder.hpp"
2: #include "duckdb/planner/operator/list.hpp"
3: #include "duckdb/planner/query_node/bound_select_node.hpp"
4: #include "duckdb/planner/operator/logical_expression_get.hpp"
5: 
6: using namespace duckdb;
7: using namespace std;
8: 
9: unique_ptr<LogicalOperator> Binder::PlanFilter(unique_ptr<Expression> condition, unique_ptr<LogicalOperator> root) {
10: 	PlanSubqueries(&condition, &root);
11: 	auto filter = make_unique<LogicalFilter>(move(condition));
12: 	filter->AddChild(move(root));
13: 	return move(filter);
14: }
15: 
16: unique_ptr<LogicalOperator> Binder::CreatePlan(BoundSelectNode &statement) {
17: 	unique_ptr<LogicalOperator> root;
18: 	assert(statement.from_table);
19: 	root = CreatePlan(*statement.from_table);
20: 	assert(root);
21: 
22: 	if (statement.where_clause) {
23: 		root = PlanFilter(move(statement.where_clause), move(root));
24: 	}
25: 
26: 	if (statement.aggregates.size() > 0 || statement.groups.size() > 0) {
27: 		if (statement.groups.size() > 0) {
28: 			// visit the groups
29: 			for (idx_t i = 0; i < statement.groups.size(); i++) {
30: 				auto &group = statement.groups[i];
31: 				PlanSubqueries(&group, &root);
32: 			}
33: 		}
34: 		// now visit all aggregate expressions
35: 		for (auto &expr : statement.aggregates) {
36: 			PlanSubqueries(&expr, &root);
37: 		}
38: 		// finally create the aggregate node with the group_index and aggregate_index as obtained from the binder
39: 		auto aggregate =
40: 		    make_unique<LogicalAggregate>(statement.group_index, statement.aggregate_index, move(statement.aggregates));
41: 		aggregate->groups = move(statement.groups);
42: 
43: 		aggregate->AddChild(move(root));
44: 		root = move(aggregate);
45: 	}
46: 
47: 	if (statement.having) {
48: 		PlanSubqueries(&statement.having, &root);
49: 		auto having = make_unique<LogicalFilter>(move(statement.having));
50: 
51: 		having->AddChild(move(root));
52: 		root = move(having);
53: 	}
54: 
55: 	if (statement.windows.size() > 0) {
56: 		auto win = make_unique<LogicalWindow>(statement.window_index);
57: 		win->expressions = move(statement.windows);
58: 		// visit the window expressions
59: 		for (auto &expr : win->expressions) {
60: 			PlanSubqueries(&expr, &root);
61: 		}
62: 		assert(win->expressions.size() > 0);
63: 		win->AddChild(move(root));
64: 		root = move(win);
65: 	}
66: 
67: 	if (statement.unnests.size() > 0) {
68: 		auto unnest = make_unique<LogicalUnnest>(statement.unnest_index);
69: 		unnest->expressions = move(statement.unnests);
70: 		// visit the window expressions
71: 		for (auto &expr : unnest->expressions) {
72: 			PlanSubqueries(&expr, &root);
73: 		}
74: 		assert(unnest->expressions.size() > 0);
75: 		unnest->AddChild(move(root));
76: 		root = move(unnest);
77: 	}
78: 
79: 	for (auto &expr : statement.select_list) {
80: 		PlanSubqueries(&expr, &root);
81: 	}
82: 
83: 	// check if we need to prune extra columns that were introduced into the select list (by e.g. the ORDER BY or HAVING
84: 	// clauses)
85: 	bool prune_columns = statement.select_list.size() > statement.column_count;
86: 
87: 	// create the projection
88: 	auto proj = make_unique<LogicalProjection>(statement.projection_index, move(statement.select_list));
89: 	proj->AddChild(move(root));
90: 	root = move(proj);
91: 
92: 	// finish the plan by handling the elements of the QueryNode
93: 	root = VisitQueryNode(statement, move(root));
94: 
95: 	// add a prune node if necessary
96: 	if (prune_columns) {
97: 		assert(root);
98: 		auto prune = make_unique<LogicalPruneColumns>(statement.column_count);
99: 		prune->AddChild(move(root));
100: 		root = move(prune);
101: 	}
102: 	return root;
103: }
[end of src/planner/binder/query_node/plan_select_node.cpp]
[start of src/planner/operator/CMakeLists.txt]
1: add_library_unity(duckdb_planner_operator
2:                   OBJECT
3:                   logical_aggregate.cpp
4:                   logical_empty_result.cpp
5:                   logical_any_join.cpp
6:                   logical_comparison_join.cpp
7:                   logical_cross_product.cpp
8:                   logical_filter.cpp
9:                   logical_get.cpp
10:                   logical_join.cpp
11:                   logical_projection.cpp
12:                   logical_prune_columns.cpp
13:                   logical_table_function.cpp
14:                   logical_unnest.cpp
15:                   logical_window.cpp
16:                   logical_distinct.cpp)
17: set(ALL_OBJECT_FILES ${ALL_OBJECT_FILES}
18:                      $<TARGET_OBJECTS:duckdb_planner_operator> PARENT_SCOPE)
[end of src/planner/operator/CMakeLists.txt]
[start of src/planner/operator/logical_prune_columns.cpp]
1: #include "duckdb/planner/operator/logical_prune_columns.hpp"
2: 
3: using namespace duckdb;
4: using namespace std;
5: 
6: vector<ColumnBinding> LogicalPruneColumns::GetColumnBindings() {
7: 	vector<ColumnBinding> result;
8: 	auto child_bindings = children[0]->GetColumnBindings();
9: 	result.insert(result.end(), child_bindings.begin(), child_bindings.begin() + column_limit);
10: 	return result;
11: }
12: 
13: void LogicalPruneColumns::ResolveTypes() {
14: 	types.insert(types.end(), children[0]->types.begin(), children[0]->types.begin() + column_limit);
15: }
[end of src/planner/operator/logical_prune_columns.cpp]
[start of src/planner/subquery/flatten_dependent_join.cpp]
1: #include "duckdb/planner/subquery/flatten_dependent_join.hpp"
2: 
3: #include "duckdb/planner/binder.hpp"
4: #include "duckdb/planner/expression/list.hpp"
5: #include "duckdb/planner/logical_operator_visitor.hpp"
6: #include "duckdb/planner/binder.hpp"
7: #include "duckdb/planner/operator/list.hpp"
8: #include "duckdb/planner/subquery/has_correlated_expressions.hpp"
9: #include "duckdb/planner/subquery/rewrite_correlated_expressions.hpp"
10: #include "duckdb/planner/expression/bound_aggregate_expression.hpp"
11: #include "duckdb/catalog/catalog_entry/aggregate_function_catalog_entry.hpp"
12: #include "duckdb/function/aggregate/distributive_functions.hpp"
13: 
14: using namespace duckdb;
15: using namespace std;
16: 
17: FlattenDependentJoins::FlattenDependentJoins(Binder &binder, const vector<CorrelatedColumnInfo> &correlated)
18:     : binder(binder), correlated_columns(correlated) {
19: 	for (idx_t i = 0; i < correlated_columns.size(); i++) {
20: 		auto &col = correlated_columns[i];
21: 		correlated_map[col.binding] = i;
22: 		delim_types.push_back(col.type);
23: 	}
24: }
25: 
26: bool FlattenDependentJoins::DetectCorrelatedExpressions(LogicalOperator *op) {
27: 	assert(op);
28: 	// check if this entry has correlated expressions
29: 	HasCorrelatedExpressions visitor(correlated_columns);
30: 	visitor.VisitOperator(*op);
31: 	bool has_correlation = visitor.has_correlated_expressions;
32: 	// now visit the children of this entry and check if they have correlated expressions
33: 	for (auto &child : op->children) {
34: 		// we OR the property with its children such that has_correlation is true if either
35: 		// (1) this node has a correlated expression or
36: 		// (2) one of its children has a correlated expression
37: 		if (DetectCorrelatedExpressions(child.get())) {
38: 			has_correlation = true;
39: 		}
40: 	}
41: 	// set the entry in the map
42: 	has_correlated_expressions[op] = has_correlation;
43: 	return has_correlation;
44: }
45: 
46: unique_ptr<LogicalOperator> FlattenDependentJoins::PushDownDependentJoin(unique_ptr<LogicalOperator> plan) {
47: 	auto result = PushDownDependentJoinInternal(move(plan));
48: 	if (replacement_map.size() > 0) {
49: 		// check if we have to replace any COUNT aggregates into "CASE WHEN X IS NULL THEN 0 ELSE COUNT END"
50: 		RewriteCountAggregates aggr(replacement_map);
51: 		aggr.VisitOperator(*result);
52: 	}
53: 	return result;
54: }
55: 
56: unique_ptr<LogicalOperator> FlattenDependentJoins::PushDownDependentJoinInternal(unique_ptr<LogicalOperator> plan) {
57: 	// first check if the logical operator has correlated expressions
58: 	auto entry = has_correlated_expressions.find(plan.get());
59: 	assert(entry != has_correlated_expressions.end());
60: 	if (!entry->second) {
61: 		// we reached a node without correlated expressions
62: 		// we can eliminate the dependent join now and create a simple cross product
63: 		auto cross_product = make_unique<LogicalCrossProduct>();
64: 		// now create the duplicate eliminated scan for this node
65: 		auto delim_index = binder.GenerateTableIndex();
66: 		this->base_binding = ColumnBinding(delim_index, 0);
67: 		auto delim_scan = make_unique<LogicalDelimGet>(delim_index, delim_types);
68: 		cross_product->children.push_back(move(delim_scan));
69: 		cross_product->children.push_back(move(plan));
70: 		return move(cross_product);
71: 	}
72: 	switch (plan->type) {
73: 	case LogicalOperatorType::FILTER: {
74: 		// filter
75: 		// first we flatten the dependent join in the child of the filter
76: 		plan->children[0] = PushDownDependentJoinInternal(move(plan->children[0]));
77: 		// then we replace any correlated expressions with the corresponding entry in the correlated_map
78: 		RewriteCorrelatedExpressions rewriter(base_binding, correlated_map);
79: 		rewriter.VisitOperator(*plan);
80: 		return plan;
81: 	}
82: 	case LogicalOperatorType::PROJECTION: {
83: 		// projection
84: 		// first we flatten the dependent join in the child of the projection
85: 		plan->children[0] = PushDownDependentJoinInternal(move(plan->children[0]));
86: 		// then we replace any correlated expressions with the corresponding entry in the correlated_map
87: 		RewriteCorrelatedExpressions rewriter(base_binding, correlated_map);
88: 		rewriter.VisitOperator(*plan);
89: 		// now we add all the columns of the delim_scan to the projection list
90: 		auto proj = (LogicalProjection *)plan.get();
91: 		for (idx_t i = 0; i < correlated_columns.size(); i++) {
92: 			auto colref = make_unique<BoundColumnRefExpression>(
93: 			    correlated_columns[i].type, ColumnBinding(base_binding.table_index, base_binding.column_index + i));
94: 			plan->expressions.push_back(move(colref));
95: 		}
96: 
97: 		base_binding.table_index = proj->table_index;
98: 		this->delim_offset = base_binding.column_index = plan->expressions.size() - correlated_columns.size();
99: 		this->data_offset = 0;
100: 		return plan;
101: 	}
102: 	case LogicalOperatorType::AGGREGATE_AND_GROUP_BY: {
103: 		auto &aggr = (LogicalAggregate &)*plan;
104: 		// aggregate and group by
105: 		// first we flatten the dependent join in the child of the projection
106: 		plan->children[0] = PushDownDependentJoinInternal(move(plan->children[0]));
107: 		// then we replace any correlated expressions with the corresponding entry in the correlated_map
108: 		RewriteCorrelatedExpressions rewriter(base_binding, correlated_map);
109: 		rewriter.VisitOperator(*plan);
110: 		// now we add all the columns of the delim_scan to the grouping operators AND the projection list
111: 		for (idx_t i = 0; i < correlated_columns.size(); i++) {
112: 			auto colref = make_unique<BoundColumnRefExpression>(
113: 			    correlated_columns[i].type, ColumnBinding(base_binding.table_index, base_binding.column_index + i));
114: 			aggr.groups.push_back(move(colref));
115: 		}
116: 		if (aggr.groups.size() == correlated_columns.size()) {
117: 			// we have to perform a LEFT OUTER JOIN between the result of this aggregate and the delim scan
118: 			auto left_outer_join = make_unique<LogicalComparisonJoin>(JoinType::LEFT);
119: 			auto left_index = binder.GenerateTableIndex();
120: 			auto delim_scan = make_unique<LogicalDelimGet>(left_index, delim_types);
121: 			left_outer_join->children.push_back(move(delim_scan));
122: 			left_outer_join->children.push_back(move(plan));
123: 			for (idx_t i = 0; i < correlated_columns.size(); i++) {
124: 				JoinCondition cond;
125: 				cond.left =
126: 				    make_unique<BoundColumnRefExpression>(correlated_columns[i].type, ColumnBinding(left_index, i));
127: 				cond.right = make_unique<BoundColumnRefExpression>(
128: 				    correlated_columns[i].type,
129: 				    ColumnBinding(aggr.group_index, (aggr.groups.size() - correlated_columns.size()) + i));
130: 				cond.comparison = ExpressionType::COMPARE_EQUAL;
131: 				cond.null_values_are_equal = true;
132: 				left_outer_join->conditions.push_back(move(cond));
133: 			}
134: 			// for any COUNT aggregate we replace references to the column with: CASE WHEN COUNT(*) IS NULL THEN 0
135: 			// ELSE COUNT(*) END
136: 			for (idx_t i = 0; i < aggr.expressions.size(); i++) {
137: 				assert(aggr.expressions[i]->GetExpressionClass() == ExpressionClass::BOUND_AGGREGATE);
138: 				auto bound = (BoundAggregateExpression *)&*aggr.expressions[i];
139: 				vector<SQLType> arguments;
140: 				if (bound->function == CountFun::GetFunction() || bound->function == CountStarFun::GetFunction()) {
141: 					// have to replace this ColumnBinding with the CASE expression
142: 					replacement_map[ColumnBinding(aggr.aggregate_index, i)] = i;
143: 				}
144: 			}
145: 			// now we update the delim_index
146: 
147: 			base_binding.table_index = left_index;
148: 			this->delim_offset = base_binding.column_index = 0;
149: 			this->data_offset = 0;
150: 			return move(left_outer_join);
151: 		} else {
152: 			// update the delim_index
153: 			base_binding.table_index = aggr.group_index;
154: 			this->delim_offset = base_binding.column_index = aggr.groups.size() - correlated_columns.size();
155: 			this->data_offset = aggr.groups.size();
156: 			return plan;
157: 		}
158: 	}
159: 	case LogicalOperatorType::CROSS_PRODUCT: {
160: 		// cross product
161: 		// push into both sides of the plan
162: 		bool left_has_correlation = has_correlated_expressions.find(plan->children[0].get())->second;
163: 		bool right_has_correlation = has_correlated_expressions.find(plan->children[1].get())->second;
164: 		if (!right_has_correlation) {
165: 			// only left has correlation: push into left
166: 			plan->children[0] = PushDownDependentJoinInternal(move(plan->children[0]));
167: 			return plan;
168: 		}
169: 		if (!left_has_correlation) {
170: 			// only right has correlation: push into right
171: 			plan->children[1] = PushDownDependentJoinInternal(move(plan->children[1]));
172: 			return plan;
173: 		}
174: 		// both sides have correlation
175: 		// turn into an inner join
176: 		auto join = make_unique<LogicalComparisonJoin>(JoinType::INNER);
177: 		plan->children[0] = PushDownDependentJoinInternal(move(plan->children[0]));
178: 		auto left_binding = this->base_binding;
179: 		plan->children[1] = PushDownDependentJoinInternal(move(plan->children[1]));
180: 		// add the correlated columns to the join conditions
181: 		for (idx_t i = 0; i < correlated_columns.size(); i++) {
182: 			JoinCondition cond;
183: 			cond.left = make_unique<BoundColumnRefExpression>(
184: 			    correlated_columns[i].type, ColumnBinding(left_binding.table_index, left_binding.column_index + i));
185: 			cond.right = make_unique<BoundColumnRefExpression>(
186: 			    correlated_columns[i].type, ColumnBinding(base_binding.table_index, base_binding.column_index + i));
187: 			cond.comparison = ExpressionType::COMPARE_EQUAL;
188: 			cond.null_values_are_equal = true;
189: 			join->conditions.push_back(move(cond));
190: 		}
191: 		join->children.push_back(move(plan->children[0]));
192: 		join->children.push_back(move(plan->children[1]));
193: 		return move(join);
194: 	}
195: 	case LogicalOperatorType::COMPARISON_JOIN: {
196: 		auto &join = (LogicalComparisonJoin &)*plan;
197: 		assert(plan->children.size() == 2);
198: 		// check the correlated expressions in the children of the join
199: 		bool left_has_correlation = has_correlated_expressions.find(plan->children[0].get())->second;
200: 		bool right_has_correlation = has_correlated_expressions.find(plan->children[1].get())->second;
201: 
202: 		if (join.join_type == JoinType::INNER) {
203: 			// inner join
204: 			if (!right_has_correlation) {
205: 				// only left has correlation: push into left
206: 				plan->children[0] = PushDownDependentJoinInternal(move(plan->children[0]));
207: 				return plan;
208: 			}
209: 			if (!left_has_correlation) {
210: 				// only right has correlation: push into right
211: 				plan->children[1] = PushDownDependentJoinInternal(move(plan->children[1]));
212: 				return plan;
213: 			}
214: 		} else if (join.join_type == JoinType::LEFT) {
215: 			// left outer join
216: 			if (!right_has_correlation) {
217: 				// only left has correlation: push into left
218: 				plan->children[0] = PushDownDependentJoinInternal(move(plan->children[0]));
219: 				return plan;
220: 			}
221: 		} else if (join.join_type == JoinType::MARK) {
222: 			if (right_has_correlation) {
223: 				throw Exception("MARK join with correlation in RHS not supported");
224: 			}
225: 			// push the child into the LHS
226: 			plan->children[0] = PushDownDependentJoinInternal(move(plan->children[0]));
227: 			// rewrite expressions in the join conditions
228: 			RewriteCorrelatedExpressions rewriter(base_binding, correlated_map);
229: 			rewriter.VisitOperator(*plan);
230: 			return plan;
231: 		} else {
232: 			throw Exception("Unsupported join type for flattening correlated subquery");
233: 		}
234: 		// both sides have correlation
235: 		// push into both sides
236: 		// NOTE: for OUTER JOINS it matters what the BASE BINDING is after the join
237: 		// for the LEFT OUTER JOIN, we want the LEFT side to be the base binding after we push
238: 		// because the RIGHT binding might contain NULL values
239: 		plan->children[0] = PushDownDependentJoinInternal(move(plan->children[0]));
240: 		auto left_binding = this->base_binding;
241: 		plan->children[1] = PushDownDependentJoinInternal(move(plan->children[1]));
242: 		auto right_binding = this->base_binding;
243: 		if (join.join_type == JoinType::LEFT) {
244: 			this->base_binding = left_binding;
245: 		}
246: 		// add the correlated columns to the join conditions
247: 		for (idx_t i = 0; i < correlated_columns.size(); i++) {
248: 			JoinCondition cond;
249: 
250: 			cond.left = make_unique<BoundColumnRefExpression>(
251: 			    correlated_columns[i].type, ColumnBinding(left_binding.table_index, left_binding.column_index + i));
252: 			cond.right = make_unique<BoundColumnRefExpression>(
253: 			    correlated_columns[i].type, ColumnBinding(right_binding.table_index, right_binding.column_index + i));
254: 			cond.comparison = ExpressionType::COMPARE_EQUAL;
255: 			cond.null_values_are_equal = true;
256: 			join.conditions.push_back(move(cond));
257: 		}
258: 		// then we replace any correlated expressions with the corresponding entry in the correlated_map
259: 		RewriteCorrelatedExpressions rewriter(right_binding, correlated_map);
260: 		rewriter.VisitOperator(*plan);
261: 		return plan;
262: 	}
263: 	case LogicalOperatorType::LIMIT: {
264: 		auto &limit = (LogicalLimit &)*plan;
265: 		if (limit.offset > 0) {
266: 			throw ParserException("OFFSET not supported in correlated subquery");
267: 		}
268: 		plan->children[0] = PushDownDependentJoinInternal(move(plan->children[0]));
269: 		if (limit.limit == 0) {
270: 			// limit = 0 means we return zero columns here
271: 			return plan;
272: 		} else {
273: 			// limit > 0 does nothing
274: 			return move(plan->children[0]);
275: 		}
276: 	}
277: 	case LogicalOperatorType::WINDOW: {
278: 		auto &window = (LogicalWindow &)*plan;
279: 		// push into children
280: 		plan->children[0] = PushDownDependentJoinInternal(move(plan->children[0]));
281: 		// add the correlated columns to the PARTITION BY clauses in the Window
282: 		for (auto &expr : window.expressions) {
283: 			assert(expr->GetExpressionClass() == ExpressionClass::BOUND_WINDOW);
284: 			auto &w = (BoundWindowExpression &)*expr;
285: 			for (idx_t i = 0; i < correlated_columns.size(); i++) {
286: 				w.partitions.push_back(make_unique<BoundColumnRefExpression>(
287: 				    correlated_columns[i].type,
288: 				    ColumnBinding(base_binding.table_index, base_binding.column_index + i)));
289: 			}
290: 		}
291: 		return plan;
292: 	}
293: 	case LogicalOperatorType::EXCEPT:
294: 	case LogicalOperatorType::INTERSECT:
295: 	case LogicalOperatorType::UNION: {
296: 		auto &setop = (LogicalSetOperation &)*plan;
297: 		// set operator, push into both children
298: 		plan->children[0] = PushDownDependentJoin(move(plan->children[0]));
299: 		plan->children[1] = PushDownDependentJoin(move(plan->children[1]));
300: 		// we have to refer to the setop index now
301: 		base_binding.table_index = setop.table_index;
302: 		base_binding.column_index = setop.column_count;
303: 		setop.column_count += correlated_columns.size();
304: 		return plan;
305: 	}
306: 	case LogicalOperatorType::PRUNE_COLUMNS:
307: 	case LogicalOperatorType::DISTINCT:
308: 		plan->children[0] = PushDownDependentJoin(move(plan->children[0]));
309: 		return plan;
310: 	case LogicalOperatorType::ORDER_BY:
311: 		throw ParserException("ORDER BY not supported in correlated subquery");
312: 	default:
313: 		throw NotImplementedException("Logical operator type \"%s\" for dependent join",
314: 		                              LogicalOperatorToString(plan->type).c_str());
315: 	}
316: }
[end of src/planner/subquery/flatten_dependent_join.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: