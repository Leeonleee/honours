{
  "repo": "duckdb/duckdb",
  "pull_number": 11095,
  "instance_id": "duckdb__duckdb-11095",
  "issue_numbers": [
    "11062"
  ],
  "base_commit": "2ded9525af215c14f137fc0d9826be1542f7f5e7",
  "patch": "diff --git a/tools/pythonpkg/src/include/duckdb_python/python_objects.hpp b/tools/pythonpkg/src/include/duckdb_python/python_objects.hpp\nindex 9fbc2fcc733a..56e70e4eb26a 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/python_objects.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/python_objects.hpp\n@@ -32,7 +32,8 @@ namespace duckdb {\n struct PyDictionary {\n public:\n \tPyDictionary(py::object dict);\n-\t// FIXME: should probably remove these, as they aren't used if the dictionary has MAP format\n+\t// These are cached so we don't have to create new objects all the time\n+\t// The CPython API offers PyDict_Keys but that creates a new reference every time, same for values\n \tpy::object keys;\n \tpy::object values;\n \tidx_t len;\n@@ -42,6 +43,11 @@ struct PyDictionary {\n \t\treturn PyDict_GetItem(dict.ptr(), obj.ptr());\n \t}\n \n+public:\n+\tstring ToString() const {\n+\t\treturn string(py::str(dict));\n+\t}\n+\n private:\n \tpy::object dict;\n };\ndiff --git a/tools/pythonpkg/src/native/python_conversion.cpp b/tools/pythonpkg/src/native/python_conversion.cpp\nindex 58337d082ad1..d584c7e30f9e 100644\n--- a/tools/pythonpkg/src/native/python_conversion.cpp\n+++ b/tools/pythonpkg/src/native/python_conversion.cpp\n@@ -69,8 +69,9 @@ Value TransformDictionaryToStruct(const PyDictionary &dict, const LogicalType &t\n \tauto struct_keys = TransformStructKeys(dict.keys, dict.len, target_type);\n \n \tbool struct_target = target_type.id() == LogicalTypeId::STRUCT;\n-\tif (struct_target) {\n-\t\tD_ASSERT(dict.len == StructType::GetChildCount(target_type));\n+\tif (struct_target && dict.len != StructType::GetChildCount(target_type)) {\n+\t\tthrow InvalidInputException(\"We could not convert the object %s to the desired target type (%s)\",\n+\t\t                            dict.ToString(), target_type.ToString());\n \t}\n \n \tchild_list_t<Value> struct_values;\n@@ -136,8 +137,16 @@ Value TransformDictionaryToMap(const PyDictionary &dict, const LogicalType &targ\n \t\treturn EmptyMapValue();\n \t}\n \t// dict == { 'key': [ ... ], 'value' : [ ... ] }\n-\tauto key_list = TransformPythonValue(keys);\n-\tauto value_list = TransformPythonValue(values);\n+\tLogicalType key_target = LogicalTypeId::UNKNOWN;\n+\tLogicalType value_target = LogicalTypeId::UNKNOWN;\n+\n+\tif (target_type.id() != LogicalTypeId::UNKNOWN) {\n+\t\tkey_target = LogicalType::LIST(MapType::KeyType(target_type));\n+\t\tvalue_target = LogicalType::LIST(MapType::ValueType(target_type));\n+\t}\n+\n+\tauto key_list = TransformPythonValue(keys, key_target);\n+\tauto value_list = TransformPythonValue(values, value_target);\n \n \tLogicalType key_type = LogicalType::SQLNULL;\n \tLogicalType value_type = LogicalType::SQLNULL;\ndiff --git a/tools/pythonpkg/src/pandas/analyzer.cpp b/tools/pythonpkg/src/pandas/analyzer.cpp\nindex 15f9dbed1c90..508270894403 100644\n--- a/tools/pythonpkg/src/pandas/analyzer.cpp\n+++ b/tools/pythonpkg/src/pandas/analyzer.cpp\n@@ -8,36 +8,24 @@\n \n namespace duckdb {\n \n-static bool TypeIsNested(LogicalTypeId id) {\n-\tswitch (id) {\n-\tcase LogicalTypeId::STRUCT:\n-\tcase LogicalTypeId::UNION:\n-\tcase LogicalTypeId::LIST:\n-\tcase LogicalTypeId::MAP:\n-\tcase LogicalTypeId::ARRAY:\n+static bool SameTypeRealm(const LogicalType &a, const LogicalType &b) {\n+\tauto a_id = a.id();\n+\tauto b_id = b.id();\n+\tif (a_id == b_id) {\n \t\treturn true;\n-\tdefault:\n-\t\treturn false;\n \t}\n-}\n-\n-static bool UpgradeType(LogicalType &left, const LogicalType &right);\n-\n-static bool SameTypeRealm(LogicalTypeId a, LogicalTypeId b) {\n-\tif (a == b) {\n-\t\treturn true;\n-\t}\n-\tif (a > b) {\n+\tif (a_id > b_id) {\n \t\treturn SameTypeRealm(b, a);\n \t}\n-\tD_ASSERT(a < b);\n+\tD_ASSERT(a_id < b_id);\n \n \t// anything ANY and under can transform to anything\n-\tif (a <= LogicalTypeId::ANY) {\n+\tif (a_id <= LogicalTypeId::ANY) {\n \t\treturn true;\n \t}\n-\tauto a_is_nested = TypeIsNested(a);\n-\tauto b_is_nested = TypeIsNested(b);\n+\n+\tauto a_is_nested = a.IsNested();\n+\tauto b_is_nested = b.IsNested();\n \t// Both a and b are not nested\n \tif (!a_is_nested && !b_is_nested) {\n \t\treturn true;\n@@ -46,16 +34,31 @@ static bool SameTypeRealm(LogicalTypeId a, LogicalTypeId b) {\n \tif (!a_is_nested || !b_is_nested) {\n \t\treturn false;\n \t}\n+\n+\t// From this point on, left and right are both nested\n+\tD_ASSERT(a_id != b_id);\n \t// STRUCT -> LIST is not possible\n-\tif (b == LogicalTypeId::LIST || a == LogicalTypeId::LIST) {\n+\tif (b_id == LogicalTypeId::LIST || a_id == LogicalTypeId::LIST) {\n \t\treturn false;\n \t}\n \treturn true;\n }\n \n-//@return Whether the two logicaltypes are compatible\n+static bool UpgradeType(LogicalType &left, const LogicalType &right);\n+\n static bool CheckTypeCompatibility(const LogicalType &left, const LogicalType &right) {\n-\treturn SameTypeRealm(left.id(), right.id());\n+\tif (!SameTypeRealm(left, right)) {\n+\t\treturn false;\n+\t}\n+\tif (!left.IsNested() || !right.IsNested()) {\n+\t\treturn true;\n+\t}\n+\n+\t// Nested type IDs between left and right have to match\n+\tif (left.id() != right.id()) {\n+\t\treturn false;\n+\t}\n+\treturn true;\n }\n \n static bool IsStructColumnValid(const LogicalType &left, const LogicalType &right) {\n@@ -86,22 +89,25 @@ static bool IsStructColumnValid(const LogicalType &left, const LogicalType &righ\n \treturn true;\n }\n \n+static bool CombineStructTypes(LogicalType &result, const LogicalType &input) {\n+\tD_ASSERT(input.id() == LogicalTypeId::STRUCT);\n+\tauto &children = StructType::GetChildTypes(input);\n+\tfor (auto &type : children) {\n+\t\tif (!UpgradeType(result, type.second)) {\n+\t\t\treturn false;\n+\t\t}\n+\t}\n+\treturn true;\n+}\n+\n static bool SatisfiesMapConstraints(const LogicalType &left, const LogicalType &right, LogicalType &map_value_type) {\n \tD_ASSERT(left.id() == LogicalTypeId::STRUCT && left.id() == right.id());\n \n-\t//! Child types of the two structs\n-\tauto &left_children = StructType::GetChildTypes(left);\n-\tauto &right_children = StructType::GetChildTypes(right);\n-\n-\tfor (auto &type : left_children) {\n-\t\tif (!UpgradeType(map_value_type, type.second)) {\n-\t\t\treturn false;\n-\t\t}\n+\tif (!CombineStructTypes(map_value_type, left)) {\n+\t\treturn false;\n \t}\n-\tfor (auto &type : right_children) {\n-\t\tif (!UpgradeType(map_value_type, type.second)) {\n-\t\t\treturn false;\n-\t\t}\n+\tif (!CombineStructTypes(map_value_type, right)) {\n+\t\treturn false;\n \t}\n \treturn true;\n }\n@@ -111,38 +117,135 @@ static LogicalType ConvertStructToMap(LogicalType &map_value_type) {\n \treturn LogicalType::MAP(LogicalType::VARCHAR, map_value_type);\n }\n \n+// This is similar to ForceMaxLogicalType but we have custom rules around combining STRUCT types\n+// And because of that we have to avoid ForceMaxLogicalType for every nested type\n static bool UpgradeType(LogicalType &left, const LogicalType &right) {\n-\tbool compatible = CheckTypeCompatibility(left, right);\n-\tif (!compatible) {\n-\t\treturn false;\n+\tif (left.id() == LogicalTypeId::SQLNULL) {\n+\t\t// Early out for upgrading null\n+\t\tleft = right;\n+\t\treturn true;\n \t}\n-\t// If struct constraints are not respected, left will be set to MAP\n-\tif (left.id() == LogicalTypeId::STRUCT && right.id() == left.id()) {\n-\t\tbool valid_struct = IsStructColumnValid(left, right);\n-\t\tif (valid_struct) {\n-\t\t\tchild_list_t<LogicalType> children;\n-\t\t\tfor (idx_t i = 0; i < StructType::GetChildCount(right); i++) {\n-\t\t\t\tauto &right_child = StructType::GetChildType(right, i);\n-\t\t\t\tauto new_child = StructType::GetChildType(left, i);\n-\t\t\t\tauto child_name = StructType::GetChildName(left, i);\n-\t\t\t\tif (!UpgradeType(new_child, right_child)) {\n+\n+\tif (left.IsNested() && right.id() == LogicalTypeId::SQLNULL) {\n+\t\treturn true;\n+\t}\n+\n+\tswitch (left.id()) {\n+\tcase LogicalTypeId::LIST: {\n+\t\tif (right.id() != left.id()) {\n+\t\t\t// Not both sides are LIST, not compatible\n+\t\t\t// FIXME: maybe compatible with ARRAY type??\n+\t\t\treturn false;\n+\t\t}\n+\t\tLogicalType child_type = LogicalType::SQLNULL;\n+\t\tif (!UpgradeType(child_type, ListType::GetChildType(left))) {\n+\t\t\treturn false;\n+\t\t}\n+\t\tif (!UpgradeType(child_type, ListType::GetChildType(right))) {\n+\t\t\treturn false;\n+\t\t}\n+\t\tleft = LogicalType::LIST(child_type);\n+\t\treturn true;\n+\t}\n+\tcase LogicalTypeId::ARRAY: {\n+\t\tif (right.id() != left.id()) {\n+\t\t\t// Not both sides are ARRAY, not compatible\n+\t\t\t// FIXME: maybe compatible with LIST type??\n+\t\t\treturn false;\n+\t\t}\n+\t\tLogicalType child_type = LogicalType::SQLNULL;\n+\t\tif (!UpgradeType(child_type, ArrayType::GetChildType(left))) {\n+\t\t\treturn false;\n+\t\t}\n+\t\tif (!UpgradeType(child_type, ArrayType::GetChildType(right))) {\n+\t\t\treturn false;\n+\t\t}\n+\t\tleft = LogicalType::ARRAY(child_type);\n+\t\treturn true;\n+\t}\n+\tcase LogicalTypeId::STRUCT: {\n+\t\tif (right.id() == LogicalTypeId::STRUCT) {\n+\t\t\tbool valid_struct = IsStructColumnValid(left, right);\n+\t\t\tif (valid_struct) {\n+\t\t\t\tchild_list_t<LogicalType> children;\n+\t\t\t\tauto child_count = StructType::GetChildCount(right);\n+\t\t\t\tD_ASSERT(child_count == StructType::GetChildCount(left));\n+\t\t\t\t// Combine all types from left and right\n+\t\t\t\tfor (idx_t i = 0; i < child_count; i++) {\n+\t\t\t\t\tauto &right_child = StructType::GetChildType(right, i);\n+\t\t\t\t\tauto new_child = StructType::GetChildType(left, i);\n+\n+\t\t\t\t\tauto child_name = StructType::GetChildName(left, i);\n+\t\t\t\t\tif (!UpgradeType(new_child, right_child)) {\n+\t\t\t\t\t\treturn false;\n+\t\t\t\t\t}\n+\t\t\t\t\tchildren.push_back(std::make_pair(child_name, new_child));\n+\t\t\t\t}\n+\t\t\t\tleft = LogicalType::STRUCT(std::move(children));\n+\t\t\t} else {\n+\t\t\t\tLogicalType value_type = LogicalType::SQLNULL;\n+\t\t\t\tif (SatisfiesMapConstraints(left, right, value_type)) {\n+\t\t\t\t\t// Combine all the child types together, becoming the value_type for the resulting MAP\n+\t\t\t\t\tleft = ConvertStructToMap(value_type);\n+\t\t\t\t} else {\n \t\t\t\t\treturn false;\n \t\t\t\t}\n-\t\t\t\tchildren.push_back(std::make_pair(child_name, new_child));\n \t\t\t}\n-\t\t\tleft = LogicalType::STRUCT(std::move(children));\n+\t\t} else if (right.id() == LogicalTypeId::MAP) {\n+\t\t\t// Left: STRUCT, Right: MAP\n+\t\t\t// Combine all the child types of the STRUCT into the value type of the MAP\n+\t\t\tauto value_type = MapType::ValueType(right);\n+\t\t\tif (!CombineStructTypes(value_type, left)) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t\tleft = LogicalType::MAP(LogicalType::VARCHAR, value_type);\n+\t\t} else {\n+\t\t\treturn false;\n \t\t}\n-\t\tif (!valid_struct) {\n-\t\t\tLogicalType map_value_type = LogicalType::SQLNULL;\n-\t\t\tif (SatisfiesMapConstraints(left, right, map_value_type)) {\n-\t\t\t\tleft = ConvertStructToMap(map_value_type);\n-\t\t\t} else {\n+\t\treturn true;\n+\t}\n+\tcase LogicalTypeId::UNION: {\n+\t\tthrow NotImplementedException(\"Converting to UNION type is not supported yet\");\n+\t}\n+\tcase LogicalTypeId::MAP: {\n+\t\tif (right.id() == LogicalTypeId::MAP) {\n+\t\t\t// Key Type\n+\t\t\tLogicalType key_type = LogicalType::SQLNULL;\n+\t\t\tif (!UpgradeType(key_type, MapType::KeyType(left))) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t\tif (!UpgradeType(key_type, MapType::KeyType(right))) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\n+\t\t\t// Value Type\n+\t\t\tLogicalType value_type = LogicalType::SQLNULL;\n+\t\t\tif (!UpgradeType(value_type, MapType::ValueType(left))) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t\tif (!UpgradeType(value_type, MapType::ValueType(right))) {\n \t\t\t\treturn false;\n \t\t\t}\n+\t\t\tleft = LogicalType::MAP(key_type, value_type);\n+\t\t} else if (right.id() == LogicalTypeId::STRUCT) {\n+\t\t\tauto value_type = MapType::ValueType(left);\n+\t\t\tif (!CombineStructTypes(value_type, right)) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t\tleft = LogicalType::MAP(LogicalType::VARCHAR, value_type);\n+\t\t} else {\n+\t\t\treturn false;\n+\t\t}\n+\t\treturn true;\n+\t}\n+\tdefault: {\n+\t\tif (!CheckTypeCompatibility(left, right)) {\n+\t\t\treturn false;\n \t\t}\n+\t\tleft = LogicalType::ForceMaxLogicalType(left, right);\n+\t\treturn true;\n+\t}\n \t}\n-\t// If one of the types is map, this will set the resulting type to map\n-\tleft = LogicalType::ForceMaxLogicalType(left, right);\n \treturn true;\n }\n \n@@ -379,7 +482,7 @@ static py::object FindFirstNonNull(const py::handle &row, idx_t offset, idx_t ra\n LogicalType PandasAnalyzer::InnerAnalyze(py::object column, bool &can_convert, bool sample, idx_t increment) {\n \tidx_t rows = py::len(column);\n \n-\tif (!rows) {\n+\tif (rows == 0) {\n \t\treturn LogicalType::SQLNULL;\n \t}\n \n",
  "test_patch": "diff --git a/tools/pythonpkg/tests/fast/pandas/test_df_object_resolution.py b/tools/pythonpkg/tests/fast/pandas/test_df_object_resolution.py\nindex 6207fd4e82af..0f20f9fe0309 100644\n--- a/tools/pythonpkg/tests/fast/pandas/test_df_object_resolution.py\n+++ b/tools/pythonpkg/tests/fast/pandas/test_df_object_resolution.py\n@@ -46,6 +46,40 @@ def ConvertStringToDecimal(data: list, pandas):\n     return data\n \n \n+class ObjectPair:\n+    def __init__(self, obj1, obj2):\n+        self.first = obj1\n+        self.second = obj2\n+\n+    def __repr__(self):\n+        return str([self.first, self.second])\n+\n+\n+def construct_list(pair):\n+    return [[pair.first], [pair.second]]\n+\n+\n+def construct_struct(pair):\n+    return [{'v1': pair.first}, {'v1': pair.second}]\n+\n+\n+def construct_map(pair):\n+    return [\n+        {'key': ['v1', 'v2'], \"value\": [pair.first, pair.first]},\n+        {'key': ['v1', 'v2'], \"value\": [pair.second, pair.second]},\n+    ]\n+\n+\n+def check_struct_upgrade(expected_type: str, creation_method, pair: ObjectPair, pandas, cursor):\n+    column_data = creation_method(pair)\n+    df = pandas.DataFrame(data={\"col\": column_data})\n+    rel = cursor.query(\"select col from df\")\n+    res = rel.fetchall()\n+    print(\"COLUMN_DATA\", column_data)\n+    print(\"RESULT\", res)\n+    assert expected_type == rel.types[0]\n+\n+\n class TestResolveObjectColumns(object):\n     # TODO: add support for ArrowPandas\n     @pytest.mark.parametrize('pandas', [NumpyPandas()])\n@@ -329,6 +363,67 @@ def test_map_fallback_nullkey_coverage(self, pandas, duckdb_cursor):\n         ):\n             converted_col = duckdb_cursor.sql(\"select * from x\").df()\n \n+    @pytest.mark.parametrize('pandas', [NumpyPandas(), ArrowPandas()])\n+    def test_structs_in_nested_types(self, pandas, duckdb_cursor):\n+        # This test is testing a bug that occurred when type upgrades occurred inside nested types\n+        # STRUCT(key1 varchar) + STRUCT(key1 varchar, key2 varchar) turns into MAP\n+        # But when inside a nested structure, this upgrade did not happen properly\n+\n+        pairs = {\n+            'v1': ObjectPair({'key1': 21}, {'key1': 21, 'key2': 42}),\n+            'v2': ObjectPair({'key1': 21}, {'key2': 21}),\n+            'v3': ObjectPair({'key1': 21, 'key2': 42}, {'key1': 21}),\n+            'v4': ObjectPair({}, {'key1': 21}),\n+        }\n+\n+        for _, pair in pairs.items():\n+            check_struct_upgrade('MAP(VARCHAR, INTEGER)[]', construct_list, pair, pandas, duckdb_cursor)\n+\n+        for key, pair in pairs.items():\n+            if key == 'v4':\n+                expected_type = 'MAP(VARCHAR, MAP(VARCHAR, INTEGER))'\n+            else:\n+                expected_type = 'STRUCT(v1 MAP(VARCHAR, INTEGER))'\n+            check_struct_upgrade(expected_type, construct_struct, pair, pandas, duckdb_cursor)\n+\n+        for key, pair in pairs.items():\n+            check_struct_upgrade('MAP(VARCHAR, MAP(VARCHAR, INTEGER))', construct_map, pair, pandas, duckdb_cursor)\n+\n+    @pytest.mark.parametrize('pandas', [NumpyPandas(), ArrowPandas()])\n+    def test_structs_of_different_sizes(self, pandas, duckdb_cursor):\n+        # This list has both a STRUCT(v1) and a STRUCT(v1, v2) member\n+        # Those can't be combined\n+        df = pandas.DataFrame(\n+            data={\n+                \"col\": [\n+                    [\n+                        {\n+                            \"key\": \"value\",\n+                        }\n+                    ],\n+                    [\n+                        {\n+                            \"key\": \"value\",\n+                            \"key1\": \"value\",\n+                        }\n+                    ],\n+                ]\n+            }\n+        )\n+        res = duckdb_cursor.query(\"select typeof(col) from df\").fetchall()\n+        # So we fall back to converting them as VARCHAR instead\n+        assert res == [('MAP(VARCHAR, VARCHAR)[]',), ('MAP(VARCHAR, VARCHAR)[]',)]\n+\n+        malformed_struct = duckdb.Value({\"v1\": 1, \"v2\": 2}, duckdb.struct_type({'v1': int}))\n+        with pytest.raises(\n+            duckdb.InvalidInputException,\n+            match=re.escape(\n+                \"We could not convert the object {'v1': 1, 'v2': 2} to the desired target type (STRUCT(v1 BIGINT))\"\n+            ),\n+        ):\n+            res = duckdb_cursor.execute(\"select $1\", [malformed_struct])\n+            print(res)\n+\n     @pytest.mark.parametrize('pandas', [NumpyPandas(), ArrowPandas()])\n     def test_struct_key_conversion(self, pandas, duckdb_cursor):\n         x = pandas.DataFrame(\n",
  "problem_statement": "Python client crashes when querying lists of differing length structs:  \"INTERNAL error: Attempted to access index N with vector of size N\"\n### What happens?\n\nWhen querying a DataFrame column that contains structs within lists, differing length structs cause the client to error. This doesn't appear to happen when using read_csv_auto or when querying the data directly, but only occurs when querying a DataFrame.\r\n\r\nI don't necessarily expect the client to handle this because trying to run a query like:\r\n\r\n```\r\nselect        [{\r\n            'key1': 'val1',\r\n        }]\r\n        union all\r\nselect        [{\r\n            'key2': 'val2',\r\n            'key3': 'val3',\r\n        }]\r\n```\r\n\r\nErrors in a way I'd expect: `Exception: Mismatch Type Error: Type STRUCT(key2 VARCHAR, key3 VARCHAR) does not match with STRUCT(key1 VARCHAR). Cannot cast STRUCTs of different size`. But I would expect that the Python client shows a similar error and doesn't crash the database.\n\n### To Reproduce\n\nMinimal repro:\r\n\r\n```\r\nimport pandas as pd\r\nimport duckdb\r\ndf = pd.DataFrame(\r\n    data={\r\n        \"col\": [\r\n            [\r\n                {\r\n                    \"key\": \"value\",\r\n                }\r\n            ],\r\n            [\r\n                {\r\n                    \"key\": \"value\",\r\n                    \"key1\": \"value\",\r\n                }\r\n            ],\r\n        ]\r\n    }\r\n)\r\n\r\n\r\nquery_str = \"select * from df\"\r\nwith duckdb.connect(database=':memory:') as conn:\r\n    duckdb_df = conn.execute(query_str).df()\r\n```\r\n\r\nOutputs:\r\n`duckdb.duckdb.InternalException: INTERNAL Error: Attempted to access index 1 within vector of size 1`\n\n### OS:\n\nMacOS, Linux\n\n### DuckDB Version:\n\n0.8.1, 0.9.2, 10.0.0, duckdb-0.10.1.dev969\n\n### DuckDB Client:\n\nPython\n\n### Full Name:\n\nKevin Dunn\n\n### Affiliation:\n\nhex Technologies\n\n### Have you tried this on the latest [nightly build](https://duckdb.org/docs/installation/?version=main)?\n\nI have tested with a nightly build\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] Yes, I have\n",
  "hints_text": "",
  "created_at": "2024-03-11T15:17:17Z"
}