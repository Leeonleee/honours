{
  "repo": "duckdb/duckdb",
  "pull_number": 3738,
  "instance_id": "duckdb__duckdb-3738",
  "issue_numbers": [
    "3730",
    "3730"
  ],
  "base_commit": "ac159c1673f87f0cd489a12eb024c446e7ace285",
  "patch": "diff --git a/src/execution/aggregate_hashtable.cpp b/src/execution/aggregate_hashtable.cpp\nindex 4904f8bf481a..52603c1dfca0 100644\n--- a/src/execution/aggregate_hashtable.cpp\n+++ b/src/execution/aggregate_hashtable.cpp\n@@ -304,28 +304,23 @@ idx_t GroupedAggregateHashTable::AddChunk(DataChunk &groups, Vector &group_hashe\n \t\t\t// value have not been seen yet\n \t\t\tidx_t new_group_count =\n \t\t\t    distinct_hashes[aggr_idx]->FindOrCreateGroups(probe_chunk, dummy_addresses, new_groups);\n-\n-\t\t\t// now fix up the payload and addresses accordingly by creating\n-\t\t\t// a selection vector\n \t\t\tif (new_group_count > 0) {\n+\t\t\t\t// now fix up the payload and addresses accordingly by creating\n+\t\t\t\t// a selection vector\n+\t\t\t\tDataChunk distinct_payload;\n+\t\t\t\tdistinct_payload.Initialize(payload.GetTypes());\n+\t\t\t\tdistinct_payload.Slice(payload, new_groups, new_group_count);\n+\t\t\t\tdistinct_payload.Verify();\n+\n+\t\t\t\tVector distinct_addresses(addresses, new_groups, new_group_count);\n+\t\t\t\tdistinct_addresses.Verify(new_group_count);\n+\n \t\t\t\tif (aggr.filter) {\n-\t\t\t\t\tVector distinct_addresses(addresses, new_groups, new_group_count);\n-\t\t\t\t\tDataChunk distinct_payload;\n-\t\t\t\t\tauto pay_types = payload.GetTypes();\n-\t\t\t\t\tdistinct_payload.Initialize(pay_types);\n-\t\t\t\t\tdistinct_payload.Slice(payload, new_groups, new_group_count);\n-\t\t\t\t\tdistinct_addresses.Verify(new_group_count);\n \t\t\t\t\tdistinct_addresses.Normalify(new_group_count);\n \t\t\t\t\tRowOperations::UpdateFilteredStates(aggr, distinct_addresses, distinct_payload, payload_idx);\n \t\t\t\t} else {\n-\t\t\t\t\tVector distinct_addresses(addresses, new_groups, new_group_count);\n-\t\t\t\t\tfor (idx_t i = 0; i < aggr.child_count; i++) {\n-\t\t\t\t\t\tpayload.data[payload_idx + i].Slice(new_groups, new_group_count);\n-\t\t\t\t\t\tpayload.data[payload_idx + i].Verify(new_group_count);\n-\t\t\t\t\t}\n-\t\t\t\t\tdistinct_addresses.Verify(new_group_count);\n-\n-\t\t\t\t\tRowOperations::UpdateStates(aggr, distinct_addresses, payload, payload_idx, new_group_count);\n+\t\t\t\t\tRowOperations::UpdateStates(aggr, distinct_addresses, distinct_payload, payload_idx,\n+\t\t\t\t\t                            new_group_count);\n \t\t\t\t}\n \t\t\t}\n \t\t} else if (aggr.filter) {\ndiff --git a/src/execution/operator/aggregate/physical_hash_aggregate.cpp b/src/execution/operator/aggregate/physical_hash_aggregate.cpp\nindex b0b13b64d1e3..2961c0ec60db 100644\n--- a/src/execution/operator/aggregate/physical_hash_aggregate.cpp\n+++ b/src/execution/operator/aggregate/physical_hash_aggregate.cpp\n@@ -161,6 +161,7 @@ SinkResultType PhysicalHashAggregate::Sink(ExecutionContext &context, GlobalSink\n \t\tfor (auto &child_expr : aggr.children) {\n \t\t\tD_ASSERT(child_expr->type == ExpressionType::BOUND_REF);\n \t\t\tauto &bound_ref_expr = (BoundReferenceExpression &)*child_expr;\n+\t\t\tD_ASSERT(bound_ref_expr.index < input.data.size());\n \t\t\taggregate_input_chunk.data[aggregate_input_idx++].Reference(input.data[bound_ref_expr.index]);\n \t\t}\n \t}\n@@ -169,6 +170,7 @@ SinkResultType PhysicalHashAggregate::Sink(ExecutionContext &context, GlobalSink\n \t\tif (aggr.filter) {\n \t\t\tauto it = filter_indexes.find(aggr.filter.get());\n \t\t\tD_ASSERT(it != filter_indexes.end());\n+\t\t\tD_ASSERT(it->second < input.data.size());\n \t\t\taggregate_input_chunk.data[aggregate_input_idx++].Reference(input.data[it->second]);\n \t\t}\n \t}\n",
  "test_patch": "diff --git a/test/sql/aggregate/grouping_sets/issue_3730.test b/test/sql/aggregate/grouping_sets/issue_3730.test\nnew file mode 100644\nindex 000000000000..20b4f12b37e4\n--- /dev/null\n+++ b/test/sql/aggregate/grouping_sets/issue_3730.test\n@@ -0,0 +1,50 @@\n+# name: test/sql/aggregate/grouping_sets/issue_3730.test\n+# description: Issue #3730: Segmentation fault on GROUP BY when using ROLLUP/CUBE + COUNT DISTINCT on Parquet\n+# group: [grouping_sets]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+CREATE TABLE response(id BIGINT, response VARCHAR);;\n+\n+statement ok\n+INSERT INTO response VALUES(1,'yes');\n+\n+statement ok\n+INSERT INTO response VALUES(1,'no');\n+\n+statement ok\n+INSERT INTO response VALUES(1,'yes');\n+\n+statement ok\n+INSERT INTO response VALUES(2,'no');\n+\n+statement ok\n+INSERT INTO response VALUES(2,'no');\n+\n+\n+statement ok\n+CREATE TABLE user_pq(id BIGINT, \"name\" VARCHAR);;\n+\n+statement ok\n+INSERT INTO user_pq VALUES(1,'alice');\n+\n+statement ok\n+INSERT INTO user_pq VALUES(2,'bob');\n+\n+query III\n+SELECT id, response, COUNT(DISTINCT id)\n+FROM user_pq\n+JOIN response USING (id)\n+GROUP BY CUBE (id, response)\n+ORDER BY 1 NULLS LAST, 2 NULLS LAST, 3 NULLS LAST\n+----\n+1\tno\t1\n+1\tyes\t1\n+1\tNULL\t1\n+2\tno\t1\n+2\tNULL\t1\n+NULL\tno\t2\n+NULL\tyes\t1\n+NULL\tNULL\t2\n",
  "problem_statement": "Segmentation fault on GROUP BY when using ROLLUP/CUBE + COUNT DISTINCT on Parquet\n#### What happens?\r\n\r\nI have a working `GROUP BY` query that I run on 2 Parquet files that are connected using a `JOIN`. If I change the grouping to use `ROLLUP` or `CUBE` instead, then DuckDB intermittently segfaults.\r\n\r\nOn two large Parquet files, it segfaults 100% of the time. In the smaller example (details below), it segfaults intermittently.\r\n\r\nRemoving the `DISTINCT`, `ROLLUP`, or `CUBE` stops it segfaulting.\r\n\r\n#### To Reproduce\r\n\r\nA SQL query that produces the segfault is:\r\n\r\n```sql\r\nSELECT id, response, COUNT(DISTINCT id)\r\nFROM 'user.parquet'\r\nJOIN 'response.parquet' USING (id)\r\nGROUP BY CUBE (id, response)\r\n```\r\n\r\nIf I remove the `CUBE`, the query works fine. If I use `ROLLUP` or `CUBE`, I get intermittent segfaults.\r\n\r\nIf I change the `COUNT(DISTINCT id)` to `COUNT(*)`, then the query works fine.\r\n\r\nTo create the data files from scratch in a fresh python environment, I did the following:\r\n\r\n```shell\r\n$ pip install pandas\r\n$ pip install fastparquet\r\n$ pip install duckdb --upgrade --pre\r\n```\r\n\r\nThen created the Parquet files and ran DuckDB using the following python script:\r\n\r\n```python\r\nimport pandas\r\nimport duckdb\r\n\r\nuser_df = pandas.DataFrame.from_records(\r\n    [\r\n        (1, \"alice\"),\r\n        (2, \"bob\"),\r\n    ],\r\n    columns=[\"id\", \"name\"],\r\n)\r\n\r\nresponse_df = pandas.DataFrame.from_records(\r\n    [\r\n        (1, \"yes\"),\r\n        (1, \"no\"),\r\n        (1, \"yes\"),\r\n        (2, \"no\"),\r\n        (2, \"no\"),\r\n    ],\r\n    columns=[\"id\", \"response\"],\r\n)\r\n\r\nuser_df.to_parquet(\"user.parquet\")\r\nresponse_df.to_parquet(\"response.parquet\")\r\n\r\nq = \"\"\"\r\nSELECT id, response, COUNT(DISTINCT id)\r\nFROM 'user.parquet'\r\nJOIN 'response.parquet' USING (id)\r\nGROUP BY CUBE (id, response)\r\n\"\"\"\r\n\r\nprint(duckdb.query(q))\r\n```\r\n\r\nThen running the script several times results in a segfault in around 50% of them.\r\n\r\nIn case it helps, this is the backtrace from `catchsegv` on Linux:\r\n\r\n```\r\nBacktrace:\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb16VectorOperations11CombineHashERNS_6VectorES2_m+0x23ef)[0x7fb499333b3f]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb9DataChunk4HashERNS_6VectorE+0x5b)[0x7fb499901aeb]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb25GroupedAggregateHashTable18FindOrCreateGroupsERNS_9DataChunkERNS_6VectorERNS_15SelectionVectorE+0x55)[0x7fb49995b7a5]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb25GroupedAggregateHashTable8AddChunkERNS_9DataChunkERNS_6VectorES2_+0x38d)[0x7fb49995c29d]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb25GroupedAggregateHashTable8AddChunkERNS_9DataChunkES2_+0x5f)[0x7fb49995c52f]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZNK6duckdb25RadixPartitionedHashTable4SinkERNS_16ExecutionContextERNS_15GlobalSinkStateERNS_14LocalSinkStateERNS_9DataChunkES8_+0x203)[0x7fb49995fce3]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZNK6duckdb21PhysicalHashAggregate4SinkERNS_16ExecutionContextERNS_15GlobalSinkStateERNS_14LocalSinkStateERNS_9DataChunkE+0x1fa)[0x7fb499ae5a9a]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb16PipelineExecutor19ExecutePushInternalERNS_9DataChunkEm+0xaa)[0x7fb499fe464a]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb16PipelineExecutor12PushFinalizeEv+0x86)[0x7fb499fe4726]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb16PipelineExecutor7ExecuteEm+0x7d)[0x7fb499fe491d]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb12ExecutorTask7ExecuteENS_17TaskExecutionModeE+0x85)[0x7fb499fe4a05]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb8Executor11ExecuteTaskEv+0x5b)[0x7fb499fe41ab]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb13ClientContext19ExecuteTaskInternalERNS_17ClientContextLockERNS_18PendingQueryResultE+0x23)[0x7fb499f394c3]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb18PendingQueryResult15ExecuteInternalERNS_17ClientContextLockEb+0x2b)[0x7fb499f39fdb]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb13ClientContext27ExecutePendingQueryInternalERNS_17ClientContextLockERNS_18PendingQueryResultEb+0x11)[0x7fb499f3a061]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb13ClientContext20RunStatementInternalERNS_17ClientContextLockERKSsSt10unique_ptrINS_12SQLStatementESt14default_deleteIS6_EEbb+0xf2)[0x7fb499f404b2]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb13ClientContext7ExecuteERKSt10shared_ptrINS_8RelationEE+0xe0)[0x7fb499f41d10]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb8Relation7ExecuteEv+0x5e)[0x7fb499f4244e]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb16DuckDBPyRelation5PrintEv+0x6c)[0x7fb49a18a70c]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(+0x18d0e50)[0x7fb49a18ee50]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(+0x18960eb)[0x7fb49a1540eb]\r\n/usr/local/lib/libpython3.10.so.1.0(+0x154523)[0x7fb4bbdb6523]\r\n/usr/local/lib/libpython3.10.so.1.0(_PyObject_MakeTpCall+0x2ca)[0x7fb4bbdafaba]\r\n/usr/local/lib/libpython3.10.so.1.0(+0x1612b1)[0x7fb4bbdc32b1]\r\n/usr/local/lib/libpython3.10.so.1.0(+0x1b73cf)[0x7fb4bbe193cf]\r\n/usr/local/lib/libpython3.10.so.1.0(+0x245aef)[0x7fb4bbea7aef]\r\n/usr/local/lib/libpython3.10.so.1.0(PyObject_Str+0x144)[0x7fb4bbdce214]\r\n/usr/local/lib/libpython3.10.so.1.0(PyFile_WriteObject+0x3d)[0x7fb4bbe6a25d]\r\n/usr/local/lib/libpython3.10.so.1.0(+0x207c06)[0x7fb4bbe69c06]\r\n/usr/local/lib/libpython3.10.so.1.0(+0x14b54f)[0x7fb4bbdad54f]\r\n/usr/local/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x2f8)[0x7fb4bbda5738]\r\n/usr/local/lib/libpython3.10.so.1.0(+0x202832)[0x7fb4bbe64832]\r\n/usr/local/lib/libpython3.10.so.1.0(PyEval_EvalCode+0x82)[0x7fb4bbe64792]\r\n/usr/local/lib/libpython3.10.so.1.0(+0x21201d)[0x7fb4bbe7401d]\r\n/usr/local/lib/libpython3.10.so.1.0(+0x20db6b)[0x7fb4bbe6fb6b]\r\n/usr/local/lib/libpython3.10.so.1.0(+0xa02e6)[0x7fb4bbd022e6]\r\n/usr/local/lib/libpython3.10.so.1.0(_PyRun_SimpleFileObject+0x387)[0x7fb4bbd01f55]\r\n/usr/local/lib/libpython3.10.so.1.0(_PyRun_AnyFileObject+0x84)[0x7fb4bbd04162]\r\n/usr/local/lib/libpython3.10.so.1.0(Py_RunMain+0x3af)[0x7fb4bbe8008f]\r\n/usr/local/lib/libpython3.10.so.1.0(Py_BytesMain+0x29)[0x7fb4bbe56799]\r\n/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xea)[0x7fb4bbac3d0a]\r\npython(_start+0x2a)[0x55b1393e107a]\r\n```\r\n\r\n#### Environment (please complete the following information):\r\n - OS: Mac OS X and Ubuntu 18\r\n - DuckDB Version: 0.3.4 and master from github\r\n - DuckDB Client: Python (3.10.4)\r\n\r\n#### Before Submitting\r\n\r\n- [x] **Have you tried this on the latest `master` branch?**\r\n* **Python**: `pip install duckdb --upgrade --pre`\r\n* **R**: `install.packages(\"https://github.com/duckdb/duckdb/releases/download/master-builds/duckdb_r_src.tar.gz\", repos = NULL)`\r\n* **Other Platforms**: You can find binaries [here](https://github.com/duckdb/duckdb/releases/tag/master-builds) or compile from source.\r\n\r\n- [x] **Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?**\r\n\nSegmentation fault on GROUP BY when using ROLLUP/CUBE + COUNT DISTINCT on Parquet\n#### What happens?\r\n\r\nI have a working `GROUP BY` query that I run on 2 Parquet files that are connected using a `JOIN`. If I change the grouping to use `ROLLUP` or `CUBE` instead, then DuckDB intermittently segfaults.\r\n\r\nOn two large Parquet files, it segfaults 100% of the time. In the smaller example (details below), it segfaults intermittently.\r\n\r\nRemoving the `DISTINCT`, `ROLLUP`, or `CUBE` stops it segfaulting.\r\n\r\n#### To Reproduce\r\n\r\nA SQL query that produces the segfault is:\r\n\r\n```sql\r\nSELECT id, response, COUNT(DISTINCT id)\r\nFROM 'user.parquet'\r\nJOIN 'response.parquet' USING (id)\r\nGROUP BY CUBE (id, response)\r\n```\r\n\r\nIf I remove the `CUBE`, the query works fine. If I use `ROLLUP` or `CUBE`, I get intermittent segfaults.\r\n\r\nIf I change the `COUNT(DISTINCT id)` to `COUNT(*)`, then the query works fine.\r\n\r\nTo create the data files from scratch in a fresh python environment, I did the following:\r\n\r\n```shell\r\n$ pip install pandas\r\n$ pip install fastparquet\r\n$ pip install duckdb --upgrade --pre\r\n```\r\n\r\nThen created the Parquet files and ran DuckDB using the following python script:\r\n\r\n```python\r\nimport pandas\r\nimport duckdb\r\n\r\nuser_df = pandas.DataFrame.from_records(\r\n    [\r\n        (1, \"alice\"),\r\n        (2, \"bob\"),\r\n    ],\r\n    columns=[\"id\", \"name\"],\r\n)\r\n\r\nresponse_df = pandas.DataFrame.from_records(\r\n    [\r\n        (1, \"yes\"),\r\n        (1, \"no\"),\r\n        (1, \"yes\"),\r\n        (2, \"no\"),\r\n        (2, \"no\"),\r\n    ],\r\n    columns=[\"id\", \"response\"],\r\n)\r\n\r\nuser_df.to_parquet(\"user.parquet\")\r\nresponse_df.to_parquet(\"response.parquet\")\r\n\r\nq = \"\"\"\r\nSELECT id, response, COUNT(DISTINCT id)\r\nFROM 'user.parquet'\r\nJOIN 'response.parquet' USING (id)\r\nGROUP BY CUBE (id, response)\r\n\"\"\"\r\n\r\nprint(duckdb.query(q))\r\n```\r\n\r\nThen running the script several times results in a segfault in around 50% of them.\r\n\r\nIn case it helps, this is the backtrace from `catchsegv` on Linux:\r\n\r\n```\r\nBacktrace:\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb16VectorOperations11CombineHashERNS_6VectorES2_m+0x23ef)[0x7fb499333b3f]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb9DataChunk4HashERNS_6VectorE+0x5b)[0x7fb499901aeb]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb25GroupedAggregateHashTable18FindOrCreateGroupsERNS_9DataChunkERNS_6VectorERNS_15SelectionVectorE+0x55)[0x7fb49995b7a5]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb25GroupedAggregateHashTable8AddChunkERNS_9DataChunkERNS_6VectorES2_+0x38d)[0x7fb49995c29d]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb25GroupedAggregateHashTable8AddChunkERNS_9DataChunkES2_+0x5f)[0x7fb49995c52f]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZNK6duckdb25RadixPartitionedHashTable4SinkERNS_16ExecutionContextERNS_15GlobalSinkStateERNS_14LocalSinkStateERNS_9DataChunkES8_+0x203)[0x7fb49995fce3]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZNK6duckdb21PhysicalHashAggregate4SinkERNS_16ExecutionContextERNS_15GlobalSinkStateERNS_14LocalSinkStateERNS_9DataChunkE+0x1fa)[0x7fb499ae5a9a]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb16PipelineExecutor19ExecutePushInternalERNS_9DataChunkEm+0xaa)[0x7fb499fe464a]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb16PipelineExecutor12PushFinalizeEv+0x86)[0x7fb499fe4726]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb16PipelineExecutor7ExecuteEm+0x7d)[0x7fb499fe491d]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb12ExecutorTask7ExecuteENS_17TaskExecutionModeE+0x85)[0x7fb499fe4a05]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb8Executor11ExecuteTaskEv+0x5b)[0x7fb499fe41ab]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb13ClientContext19ExecuteTaskInternalERNS_17ClientContextLockERNS_18PendingQueryResultE+0x23)[0x7fb499f394c3]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb18PendingQueryResult15ExecuteInternalERNS_17ClientContextLockEb+0x2b)[0x7fb499f39fdb]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb13ClientContext27ExecutePendingQueryInternalERNS_17ClientContextLockERNS_18PendingQueryResultEb+0x11)[0x7fb499f3a061]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb13ClientContext20RunStatementInternalERNS_17ClientContextLockERKSsSt10unique_ptrINS_12SQLStatementESt14default_deleteIS6_EEbb+0xf2)[0x7fb499f404b2]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb13ClientContext7ExecuteERKSt10shared_ptrINS_8RelationEE+0xe0)[0x7fb499f41d10]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb8Relation7ExecuteEv+0x5e)[0x7fb499f4244e]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(_ZN6duckdb16DuckDBPyRelation5PrintEv+0x6c)[0x7fb49a18a70c]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(+0x18d0e50)[0x7fb49a18ee50]\r\n/usr/local/lib/python3.10/site-packages/_duckdb_extension.cpython-310-x86_64-linux-gnu.so(+0x18960eb)[0x7fb49a1540eb]\r\n/usr/local/lib/libpython3.10.so.1.0(+0x154523)[0x7fb4bbdb6523]\r\n/usr/local/lib/libpython3.10.so.1.0(_PyObject_MakeTpCall+0x2ca)[0x7fb4bbdafaba]\r\n/usr/local/lib/libpython3.10.so.1.0(+0x1612b1)[0x7fb4bbdc32b1]\r\n/usr/local/lib/libpython3.10.so.1.0(+0x1b73cf)[0x7fb4bbe193cf]\r\n/usr/local/lib/libpython3.10.so.1.0(+0x245aef)[0x7fb4bbea7aef]\r\n/usr/local/lib/libpython3.10.so.1.0(PyObject_Str+0x144)[0x7fb4bbdce214]\r\n/usr/local/lib/libpython3.10.so.1.0(PyFile_WriteObject+0x3d)[0x7fb4bbe6a25d]\r\n/usr/local/lib/libpython3.10.so.1.0(+0x207c06)[0x7fb4bbe69c06]\r\n/usr/local/lib/libpython3.10.so.1.0(+0x14b54f)[0x7fb4bbdad54f]\r\n/usr/local/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x2f8)[0x7fb4bbda5738]\r\n/usr/local/lib/libpython3.10.so.1.0(+0x202832)[0x7fb4bbe64832]\r\n/usr/local/lib/libpython3.10.so.1.0(PyEval_EvalCode+0x82)[0x7fb4bbe64792]\r\n/usr/local/lib/libpython3.10.so.1.0(+0x21201d)[0x7fb4bbe7401d]\r\n/usr/local/lib/libpython3.10.so.1.0(+0x20db6b)[0x7fb4bbe6fb6b]\r\n/usr/local/lib/libpython3.10.so.1.0(+0xa02e6)[0x7fb4bbd022e6]\r\n/usr/local/lib/libpython3.10.so.1.0(_PyRun_SimpleFileObject+0x387)[0x7fb4bbd01f55]\r\n/usr/local/lib/libpython3.10.so.1.0(_PyRun_AnyFileObject+0x84)[0x7fb4bbd04162]\r\n/usr/local/lib/libpython3.10.so.1.0(Py_RunMain+0x3af)[0x7fb4bbe8008f]\r\n/usr/local/lib/libpython3.10.so.1.0(Py_BytesMain+0x29)[0x7fb4bbe56799]\r\n/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xea)[0x7fb4bbac3d0a]\r\npython(_start+0x2a)[0x55b1393e107a]\r\n```\r\n\r\n#### Environment (please complete the following information):\r\n - OS: Mac OS X and Ubuntu 18\r\n - DuckDB Version: 0.3.4 and master from github\r\n - DuckDB Client: Python (3.10.4)\r\n\r\n#### Before Submitting\r\n\r\n- [x] **Have you tried this on the latest `master` branch?**\r\n* **Python**: `pip install duckdb --upgrade --pre`\r\n* **R**: `install.packages(\"https://github.com/duckdb/duckdb/releases/download/master-builds/duckdb_r_src.tar.gz\", repos = NULL)`\r\n* **Other Platforms**: You can find binaries [here](https://github.com/duckdb/duckdb/releases/tag/master-builds) or compile from source.\r\n\r\n- [x] **Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?**\r\n\n",
  "hints_text": "\n",
  "created_at": "2022-05-30T07:30:41Z"
}