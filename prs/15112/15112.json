{
  "repo": "duckdb/duckdb",
  "pull_number": 15112,
  "instance_id": "duckdb__duckdb-15112",
  "issue_numbers": [
    "15038"
  ],
  "base_commit": "1004fd9cfe69499122ea9f85ec914a380f3b4463",
  "patch": "diff --git a/extension/json/json_functions/json_create.cpp b/extension/json/json_functions/json_create.cpp\nindex 3927daa1b87a..8c587fd0eccd 100644\n--- a/extension/json/json_functions/json_create.cpp\n+++ b/extension/json/json_functions/json_create.cpp\n@@ -40,25 +40,36 @@ static LogicalType GetJSONType(StructNames &const_struct_names, const LogicalTyp\n \t// These types can go directly into JSON\n \tcase LogicalTypeId::SQLNULL:\n \tcase LogicalTypeId::BOOLEAN:\n-\tcase LogicalTypeId::BIGINT:\n-\tcase LogicalTypeId::UBIGINT:\n-\tcase LogicalTypeId::DOUBLE:\n-\t\treturn type;\n-\t// We cast these types to a type that can go into JSON\n \tcase LogicalTypeId::TINYINT:\n \tcase LogicalTypeId::SMALLINT:\n \tcase LogicalTypeId::INTEGER:\n-\t\treturn LogicalType::BIGINT;\n+\tcase LogicalTypeId::BIGINT:\n+\tcase LogicalTypeId::HUGEINT:\n+\tcase LogicalTypeId::UHUGEINT:\n \tcase LogicalTypeId::UTINYINT:\n \tcase LogicalTypeId::USMALLINT:\n \tcase LogicalTypeId::UINTEGER:\n-\t\treturn LogicalType::UBIGINT;\n+\tcase LogicalTypeId::UBIGINT:\n \tcase LogicalTypeId::FLOAT:\n+\tcase LogicalTypeId::DOUBLE:\n+\tcase LogicalTypeId::BIT:\n+\tcase LogicalTypeId::BLOB:\n+\tcase LogicalTypeId::VARCHAR:\n+\tcase LogicalTypeId::AGGREGATE_STATE:\n+\tcase LogicalTypeId::ENUM:\n+\tcase LogicalTypeId::DATE:\n+\tcase LogicalTypeId::INTERVAL:\n+\tcase LogicalTypeId::TIME:\n+\tcase LogicalTypeId::TIME_TZ:\n+\tcase LogicalTypeId::TIMESTAMP:\n+\tcase LogicalTypeId::TIMESTAMP_TZ:\n+\tcase LogicalTypeId::TIMESTAMP_NS:\n+\tcase LogicalTypeId::TIMESTAMP_MS:\n+\tcase LogicalTypeId::TIMESTAMP_SEC:\n+\tcase LogicalTypeId::UUID:\n+\tcase LogicalTypeId::VARINT:\n \tcase LogicalTypeId::DECIMAL:\n-\tcase LogicalTypeId::UHUGEINT:\n-\tcase LogicalTypeId::HUGEINT:\n-\t\treturn LogicalType::DOUBLE;\n-\t// The nested types need to conform as well\n+\t\treturn type;\n \tcase LogicalTypeId::LIST:\n \t\treturn LogicalType::LIST(GetJSONType(const_struct_names, ListType::GetChildType(type)));\n \tcase LogicalTypeId::ARRAY:\n@@ -211,7 +222,7 @@ template <>\n struct CreateJSONValue<hugeint_t, string_t> {\n \tstatic inline yyjson_mut_val *Operation(yyjson_mut_doc *doc, const hugeint_t &input) {\n \t\tconst auto input_string = input.ToString();\n-\t\treturn yyjson_mut_strncpy(doc, input_string.c_str(), input_string.length());\n+\t\treturn yyjson_mut_rawncpy(doc, input_string.c_str(), input_string.length());\n \t}\n };\n \n@@ -219,7 +230,7 @@ template <>\n struct CreateJSONValue<uhugeint_t, string_t> {\n \tstatic inline yyjson_mut_val *Operation(yyjson_mut_doc *doc, const uhugeint_t &input) {\n \t\tconst auto input_string = input.ToString();\n-\t\treturn yyjson_mut_strncpy(doc, input_string.c_str(), input_string.length());\n+\t\treturn yyjson_mut_rawncpy(doc, input_string.c_str(), input_string.length());\n \t}\n };\n \n@@ -287,6 +298,22 @@ static void TemplatedCreateValues(yyjson_mut_doc *doc, yyjson_mut_val *vals[], V\n \t}\n }\n \n+static void CreateRawValues(yyjson_mut_doc *doc, yyjson_mut_val *vals[], Vector &value_v, idx_t count) {\n+\tUnifiedVectorFormat value_data;\n+\tvalue_v.ToUnifiedFormat(count, value_data);\n+\tauto values = UnifiedVectorFormat::GetData<string_t>(value_data);\n+\tfor (idx_t i = 0; i < count; i++) {\n+\t\tidx_t val_idx = value_data.sel->get_index(i);\n+\t\tif (!value_data.validity.RowIsValid(val_idx)) {\n+\t\t\tvals[i] = yyjson_mut_null(doc);\n+\t\t} else {\n+\t\t\tconst auto &str = values[val_idx];\n+\t\t\tvals[i] = yyjson_mut_rawncpy(doc, str.GetData(), str.GetSize());\n+\t\t}\n+\t\tD_ASSERT(vals[i] != nullptr);\n+\t}\n+}\n+\n static void CreateValuesStruct(const StructNames &names, yyjson_mut_doc *doc, yyjson_mut_val *vals[], Vector &value_v,\n                                idx_t count) {\n \t// Structs become values, therefore we initialize vals to JSON values\n@@ -476,7 +503,8 @@ static void CreateValuesArray(const StructNames &names, yyjson_mut_doc *doc, yyj\n \n static void CreateValues(const StructNames &names, yyjson_mut_doc *doc, yyjson_mut_val *vals[], Vector &value_v,\n                          idx_t count) {\n-\tswitch (value_v.GetType().id()) {\n+\tconst auto &type = value_v.GetType();\n+\tswitch (type.id()) {\n \tcase LogicalTypeId::SQLNULL:\n \t\tCreateValuesNull(doc, vals, count);\n \t\tbreak;\n@@ -550,17 +578,28 @@ static void CreateValues(const StructNames &names, yyjson_mut_doc *doc, yyjson_m\n \tcase LogicalTypeId::TIMESTAMP_NS:\n \tcase LogicalTypeId::TIMESTAMP_MS:\n \tcase LogicalTypeId::TIMESTAMP_SEC:\n-\tcase LogicalTypeId::VARINT:\n \tcase LogicalTypeId::UUID: {\n \t\tVector string_vector(LogicalTypeId::VARCHAR, count);\n \t\tVectorOperations::DefaultCast(value_v, string_vector, count);\n \t\tTemplatedCreateValues<string_t, string_t>(doc, vals, string_vector, count);\n \t\tbreak;\n \t}\n+\tcase LogicalTypeId::VARINT: {\n+\t\tVector string_vector(LogicalTypeId::VARCHAR, count);\n+\t\tVectorOperations::DefaultCast(value_v, string_vector, count);\n+\t\tCreateRawValues(doc, vals, string_vector, count);\n+\t\tbreak;\n+\t}\n \tcase LogicalTypeId::DECIMAL: {\n-\t\tVector double_vector(LogicalType::DOUBLE, count);\n-\t\tVectorOperations::DefaultCast(value_v, double_vector, count);\n-\t\tTemplatedCreateValues<double, double>(doc, vals, double_vector, count);\n+\t\tif (DecimalType::GetWidth(type) > 15) {\n+\t\t\tVector string_vector(LogicalTypeId::VARCHAR, count);\n+\t\t\tVectorOperations::DefaultCast(value_v, string_vector, count);\n+\t\t\tCreateRawValues(doc, vals, string_vector, count);\n+\t\t} else {\n+\t\t\tVector double_vector(LogicalType::DOUBLE, count);\n+\t\t\tVectorOperations::DefaultCast(value_v, double_vector, count);\n+\t\t\tTemplatedCreateValues<double, double>(doc, vals, double_vector, count);\n+\t\t}\n \t\tbreak;\n \t}\n \tcase LogicalTypeId::INVALID:\n@@ -604,7 +643,6 @@ static void ObjectFunction(DataChunk &args, ExpressionState &state, Vector &resu\n \tfor (idx_t i = 0; i < count; i++) {\n \t\tobjects[i] = JSONCommon::WriteVal<yyjson_mut_val>(objs[i], alc);\n \t}\n-\n \tif (args.AllConstant()) {\n \t\tresult.SetVectorType(VectorType::CONSTANT_VECTOR);\n \t}\n@@ -637,7 +675,6 @@ static void ArrayFunction(DataChunk &args, ExpressionState &state, Vector &resul\n \tfor (idx_t i = 0; i < count; i++) {\n \t\tobjects[i] = JSONCommon::WriteVal<yyjson_mut_val>(arrs[i], alc);\n \t}\n-\n \tif (args.AllConstant()) {\n \t\tresult.SetVectorType(VectorType::CONSTANT_VECTOR);\n \t}\n@@ -651,22 +688,9 @@ static void ToJSONFunctionInternal(const StructNames &names, Vector &input, cons\n \tCreateValues(names, doc, vals, input, count);\n \n \t// Write JSON values to string\n-\tauto objects = FlatVector::GetData<string_t>(result);\n-\tauto &result_validity = FlatVector::Validity(result);\n-\tUnifiedVectorFormat input_data;\n-\tinput.ToUnifiedFormat(count, input_data);\n-\tfor (idx_t i = 0; i < count; i++) {\n-\t\tidx_t idx = input_data.sel->get_index(i);\n-\t\tif (input_data.validity.RowIsValid(idx)) {\n-\t\t\tobjects[i] = JSONCommon::WriteVal<yyjson_mut_val>(vals[i], alc);\n-\t\t} else {\n-\t\t\tresult_validity.SetInvalid(i);\n-\t\t}\n-\t}\n-\n-\tif (input.GetVectorType() == VectorType::CONSTANT_VECTOR || count == 1) {\n-\t\tresult.SetVectorType(VectorType::CONSTANT_VECTOR);\n-\t}\n+\tUnaryExecutor::ExecuteWithNulls<data_t, string_t>(input, result, count, [&](data_t, ValidityMask &, idx_t index) {\n+\t\treturn JSONCommon::WriteVal<yyjson_mut_val>(vals[index], alc);\n+\t});\n }\n \n static void ToJSONFunction(DataChunk &args, ExpressionState &state, Vector &result) {\ndiff --git a/extension/json/json_functions/json_structure.cpp b/extension/json/json_functions/json_structure.cpp\nindex 7982003fc134..51652bae43bf 100644\n--- a/extension/json/json_functions/json_structure.cpp\n+++ b/extension/json/json_functions/json_structure.cpp\n@@ -1,12 +1,11 @@\n #include \"json_structure.hpp\"\n \n #include \"duckdb/common/enum_util.hpp\"\n+#include \"duckdb/common/extra_type_info.hpp\"\n #include \"json_executors.hpp\"\n #include \"json_scan.hpp\"\n #include \"json_transform.hpp\"\n \n-#include <duckdb/common/extra_type_info.hpp>\n-\n namespace duckdb {\n \n static bool IsNumeric(LogicalTypeId type) {\n",
  "test_patch": "diff --git a/test/sql/json/issues/issue15038.test b/test/sql/json/issues/issue15038.test\nnew file mode 100644\nindex 000000000000..6275406c1cd5\n--- /dev/null\n+++ b/test/sql/json/issues/issue15038.test\n@@ -0,0 +1,71 @@\n+# name: test/sql/json/issues/issue15038.test\n+# description: Test issue 15038 - TO_JSON results in weird number translation\n+# group: [issues]\n+\n+require json\n+\n+# we support full precision in JSON - yyjson supports RAW values\n+query I\n+SELECT to_json(1::HUGEINT << 100)\n+----\n+1267650600228229401496703205376\n+\n+query I\n+SELECT (1::HUGEINT << 100)::JSON\n+----\n+1267650600228229401496703205376\n+\n+query I\n+SELECT to_json(1::UHUGEINT << 100)\n+----\n+1267650600228229401496703205376\n+\n+query I\n+SELECT (1::UHUGEINT << 100)::JSON\n+----\n+1267650600228229401496703205376\n+\n+query I\n+SELECT to_json((1::UHUGEINT << 100)::DECIMAL(38,0))\n+----\n+1267650600228229401496703205376\n+\n+query I\n+SELECT (1::UHUGEINT << 100)::DECIMAL(38,0)::JSON\n+----\n+1267650600228229401496703205376\n+\n+query I\n+SELECT to_json((1::HUGEINT << 100)::VARINT)\n+----\n+1267650600228229401496703205376\n+\n+query I\n+SELECT (1::HUGEINT << 100)::VARINT::JSON\n+----\n+1267650600228229401496703205376\n+\n+# original issue (#15038)\n+query I\n+WITH t1 AS (\n+    SELECT 9007199254740993 AS id\n+    UNION ALL\n+    SELECT 1.2 AS id\n+)\n+SELECT to_json(id) AS json_objects\n+FROM t1 AS t;\n+----\n+9007199254740993.0\n+1.2\n+\n+query I\n+WITH t1 AS (\n+    SELECT 9007199254740993 AS id\n+    UNION ALL\n+    SELECT 1.2 AS id\n+)\n+SELECT id::JSON AS json_objects\n+FROM t1 AS t;\n+----\n+9007199254740993.0\n+1.2\n",
  "problem_statement": "`TO_JSON` results in weird number translation\n### What happens?\r\n\r\n`TO_JSON` translates `9007199254740993` into `9007199254740992.0`.\r\n\r\n### To Reproduce\r\n\r\n```sql\r\n-- this translation creates a strange number\r\nWITH t1 AS ( (\r\n            SELECT 9007199254740993 AS id  )\r\n        UNION ALL (\r\n            SELECT 2.1 AS id  ) )\r\nSELECT To_Json( t ) AS json_objects\r\nFROM t1 AS t;\r\n```\r\n```text\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 JSON_OBJECTS              \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 {\"ID\":9007199254740992.0} \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 {\"ID\":2.1}                \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n```sql\r\n-- although this works\r\n(SELECT 9007199254740993 AS ID)UNION ALL(SELECT 2.1 AS ID);\r\n```\r\n```text\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 ID                       \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 9,007,199,254,740,993.00 \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502                     2.10 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\n### OS:\r\n\r\nLinux\r\n\r\n### DuckDB Version:\r\n\r\n1.1.3\r\n\r\n### DuckDB Client:\r\n\r\nJava\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\nAndreas Reichel\r\n\r\n### Affiliation:\r\n\r\nReichel\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\n",
  "hints_text": "Thanks!\nHi @manticore-projects, this is expected (but unfortunate) behavior.\r\n\r\nYour CTE:\r\n```sql\r\nD SELECT 9007199254740993 AS id UNION ALL SELECT 1.2 AS id;\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502         id         \u2502\r\n\u2502   decimal(20,1)    \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 9007199254740993.0 \u2502\r\n\u2502                1.2 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\nResults in type `DECIMAL(20,1)`.\r\n\r\nJSON only supports integers, strings, floats, and booleans (and nested types object/array). So, to convert this to JSON, we are forced to choose a float. However, floats do not have enough precision to store your large number:\r\n```sql\r\nD WITH cte AS (SELECT 9007199254740993 AS id UNION ALL SELECT 1.2 AS id) SELECT id::DOUBLE FROM cte;\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 CAST(id AS DOUBLE) \u2502\r\n\u2502       double       \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 9007199254740992.0 \u2502\r\n\u2502                1.2 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\nThe cast to `DOUBLE` loses some precision, which is the cast that is used when you do `to_json`.\nThank you very much for the explanation @lnkuiper. I am able to understand what is happening.\r\nAlthough: would it not be better to quote the Number when exceeding the Float? As it is right now it may crash your rocket.",
  "created_at": "2024-12-03T11:43:22Z"
}