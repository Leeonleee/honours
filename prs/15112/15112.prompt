You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes.
In the patch file, please make sure to include the line numbers and a blank line at the end so it can be applied using git apply.

<issue>
`TO_JSON` results in weird number translation
### What happens?

`TO_JSON` translates `9007199254740993` into `9007199254740992.0`.

### To Reproduce

```sql
-- this translation creates a strange number
WITH t1 AS ( (
            SELECT 9007199254740993 AS id  )
        UNION ALL (
            SELECT 2.1 AS id  ) )
SELECT To_Json( t ) AS json_objects
FROM t1 AS t;
```
```text
┌───────────────────────────┐
│ JSON_OBJECTS              │
├───────────────────────────┤
│ {"ID":9007199254740992.0} │
├───────────────────────────┤
│ {"ID":2.1}                │
└───────────────────────────┘
```
```sql
-- although this works
(SELECT 9007199254740993 AS ID)UNION ALL(SELECT 2.1 AS ID);
```
```text
┌──────────────────────────┐
│ ID                       │
├──────────────────────────┤
│ 9,007,199,254,740,993.00 │
├──────────────────────────┤
│                     2.10 │
└──────────────────────────┘
```

### OS:

Linux

### DuckDB Version:

1.1.3

### DuckDB Client:

Java

### Hardware:

_No response_

### Full Name:

Andreas Reichel

### Affiliation:

Reichel

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a stable release

### Did you include all relevant data sets for reproducing the issue?

Yes

### Did you include all code required to reproduce the issue?

- [X] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [X] Yes, I have

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <picture>
3:     <source media="(prefers-color-scheme: light)" srcset="logo/DuckDB_Logo-horizontal.svg">
4:     <source media="(prefers-color-scheme: dark)" srcset="logo/DuckDB_Logo-horizontal-dark-mode.svg">
5:     <img alt="DuckDB logo" src="logo/DuckDB_Logo-horizontal.svg" height="100">
6:   </picture>
7: </div>
8: <br>
9: 
10: <p align="center">
11:   <a href="https://github.com/duckdb/duckdb/actions"><img src="https://github.com/duckdb/duckdb/actions/workflows/Main.yml/badge.svg?branch=main" alt="Github Actions Badge"></a>
12:   <a href="https://discord.gg/tcvwpjfnZx"><img src="https://shields.io/discord/909674491309850675" alt="discord" /></a>
13:   <a href="https://github.com/duckdb/duckdb/releases/"><img src="https://img.shields.io/github/v/release/duckdb/duckdb?color=brightgreen&display_name=tag&logo=duckdb&logoColor=white" alt="Latest Release"></a>
14: </p>
15: 
16: ## DuckDB
17: 
18: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable, portable, and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs, maps), and [several extensions designed to make SQL easier to use](https://duckdb.org/docs/guides/sql_features/friendly_sql).
19: 
20: DuckDB is available as a [standalone CLI application](https://duckdb.org/docs/api/cli/overview) and has clients for [Python](https://duckdb.org/docs/api/python/overview), [R](https://duckdb.org/docs/api/r), [Java](https://duckdb.org/docs/api/java), [Wasm](https://duckdb.org/docs/api/wasm/overview), etc., with deep integrations with packages such as [pandas](https://duckdb.org/docs/guides/python/sql_on_pandas) and [dplyr](https://duckdblabs.github.io/duckplyr/).
21: 
22: For more information on using DuckDB, please refer to the [DuckDB documentation](https://duckdb.org/docs/).
23: 
24: ## Installation
25: 
26: If you want to install DuckDB, please see [our installation page](https://duckdb.org/docs/installation/) for instructions.
27: 
28: ## Data Import
29: 
30: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
31: 
32: ```sql
33: SELECT * FROM 'myfile.csv';
34: SELECT * FROM 'myfile.parquet';
35: ```
36: 
37: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
38: 
39: ## SQL Reference
40: 
41: The documentation contains a [SQL introduction and reference](https://duckdb.org/docs/sql/introduction).
42: 
43: ## Development
44: 
45: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run `BUILD_BENCHMARK=1 BUILD_TPCH=1 make` and then perform several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`. The details of benchmarks are in our [Benchmark Guide](benchmark/README.md).
46: 
47: Please also refer to our [Build Guide](https://duckdb.org/dev/building) and [Contribution Guide](CONTRIBUTING.md).
48: 
49: ## Support
50: 
51: See the [Support Options](https://duckdblabs.com/support/) page.
[end of README.md]
[start of extension/json/json_functions/json_create.cpp]
1: #include "duckdb/function/cast/cast_function_set.hpp"
2: #include "duckdb/function/cast/default_casts.hpp"
3: #include "duckdb/planner/expression/bound_parameter_expression.hpp"
4: #include "json_common.hpp"
5: #include "json_functions.hpp"
6: 
7: namespace duckdb {
8: 
9: using StructNames = unordered_map<string, unique_ptr<Vector>>;
10: 
11: struct JSONCreateFunctionData : public FunctionData {
12: public:
13: 	explicit JSONCreateFunctionData(unordered_map<string, unique_ptr<Vector>> const_struct_names)
14: 	    : const_struct_names(std::move(const_struct_names)) {
15: 	}
16: 	unique_ptr<FunctionData> Copy() const override {
17: 		// Have to do this because we can't implicitly copy Vector
18: 		unordered_map<string, unique_ptr<Vector>> map_copy;
19: 		for (const auto &kv : const_struct_names) {
20: 			// The vectors are const vectors of the key value
21: 			map_copy[kv.first] = make_uniq<Vector>(Value(kv.first));
22: 		}
23: 		return make_uniq<JSONCreateFunctionData>(std::move(map_copy));
24: 	}
25: 	bool Equals(const FunctionData &other_p) const override {
26: 		return true;
27: 	}
28: 
29: public:
30: 	// Const struct name vectors live here so they don't have to be re-initialized for every DataChunk
31: 	StructNames const_struct_names;
32: };
33: 
34: static LogicalType GetJSONType(StructNames &const_struct_names, const LogicalType &type) {
35: 	if (type.IsJSONType()) {
36: 		return type;
37: 	}
38: 
39: 	switch (type.id()) {
40: 	// These types can go directly into JSON
41: 	case LogicalTypeId::SQLNULL:
42: 	case LogicalTypeId::BOOLEAN:
43: 	case LogicalTypeId::BIGINT:
44: 	case LogicalTypeId::UBIGINT:
45: 	case LogicalTypeId::DOUBLE:
46: 		return type;
47: 	// We cast these types to a type that can go into JSON
48: 	case LogicalTypeId::TINYINT:
49: 	case LogicalTypeId::SMALLINT:
50: 	case LogicalTypeId::INTEGER:
51: 		return LogicalType::BIGINT;
52: 	case LogicalTypeId::UTINYINT:
53: 	case LogicalTypeId::USMALLINT:
54: 	case LogicalTypeId::UINTEGER:
55: 		return LogicalType::UBIGINT;
56: 	case LogicalTypeId::FLOAT:
57: 	case LogicalTypeId::DECIMAL:
58: 	case LogicalTypeId::UHUGEINT:
59: 	case LogicalTypeId::HUGEINT:
60: 		return LogicalType::DOUBLE;
61: 	// The nested types need to conform as well
62: 	case LogicalTypeId::LIST:
63: 		return LogicalType::LIST(GetJSONType(const_struct_names, ListType::GetChildType(type)));
64: 	case LogicalTypeId::ARRAY:
65: 		return LogicalType::ARRAY(GetJSONType(const_struct_names, ArrayType::GetChildType(type)),
66: 		                          ArrayType::GetSize(type));
67: 	// Struct and MAP are treated as JSON values
68: 	case LogicalTypeId::STRUCT: {
69: 		child_list_t<LogicalType> child_types;
70: 		for (const auto &child_type : StructType::GetChildTypes(type)) {
71: 			const_struct_names[child_type.first] = make_uniq<Vector>(Value(child_type.first));
72: 			child_types.emplace_back(child_type.first, GetJSONType(const_struct_names, child_type.second));
73: 		}
74: 		return LogicalType::STRUCT(child_types);
75: 	}
76: 	case LogicalTypeId::MAP: {
77: 		return LogicalType::MAP(LogicalType::VARCHAR, GetJSONType(const_struct_names, MapType::ValueType(type)));
78: 	}
79: 	case LogicalTypeId::UNION: {
80: 		child_list_t<LogicalType> member_types;
81: 		for (idx_t member_idx = 0; member_idx < UnionType::GetMemberCount(type); member_idx++) {
82: 			auto &member_name = UnionType::GetMemberName(type, member_idx);
83: 			auto &member_type = UnionType::GetMemberType(type, member_idx);
84: 
85: 			const_struct_names[member_name] = make_uniq<Vector>(Value(member_name));
86: 			member_types.emplace_back(member_name, GetJSONType(const_struct_names, member_type));
87: 		}
88: 		return LogicalType::UNION(member_types);
89: 	}
90: 	// All other types (e.g. date) are cast to VARCHAR
91: 	default:
92: 		return LogicalTypeId::VARCHAR;
93: 	}
94: }
95: 
96: static unique_ptr<FunctionData> JSONCreateBindParams(ScalarFunction &bound_function,
97:                                                      vector<unique_ptr<Expression>> &arguments, bool object) {
98: 	unordered_map<string, unique_ptr<Vector>> const_struct_names;
99: 	for (idx_t i = 0; i < arguments.size(); i++) {
100: 		auto &type = arguments[i]->return_type;
101: 		if (arguments[i]->HasParameter()) {
102: 			throw ParameterNotResolvedException();
103: 		} else if (type == LogicalTypeId::SQLNULL) {
104: 			// This is needed for macro's
105: 			bound_function.arguments.push_back(type);
106: 		} else if (object && i % 2 == 0) {
107: 			// Key, must be varchar
108: 			bound_function.arguments.push_back(LogicalType::VARCHAR);
109: 		} else {
110: 			// Value, cast to types that we can put in JSON
111: 			bound_function.arguments.push_back(GetJSONType(const_struct_names, type));
112: 		}
113: 	}
114: 	return make_uniq<JSONCreateFunctionData>(std::move(const_struct_names));
115: }
116: 
117: static unique_ptr<FunctionData> JSONObjectBind(ClientContext &context, ScalarFunction &bound_function,
118:                                                vector<unique_ptr<Expression>> &arguments) {
119: 	if (arguments.size() % 2 != 0) {
120: 		throw InvalidInputException("json_object() requires an even number of arguments");
121: 	}
122: 	return JSONCreateBindParams(bound_function, arguments, true);
123: }
124: 
125: static unique_ptr<FunctionData> JSONArrayBind(ClientContext &context, ScalarFunction &bound_function,
126:                                               vector<unique_ptr<Expression>> &arguments) {
127: 	return JSONCreateBindParams(bound_function, arguments, false);
128: }
129: 
130: static unique_ptr<FunctionData> ToJSONBind(ClientContext &context, ScalarFunction &bound_function,
131:                                            vector<unique_ptr<Expression>> &arguments) {
132: 	if (arguments.size() != 1) {
133: 		throw InvalidInputException("to_json() takes exactly one argument");
134: 	}
135: 	return JSONCreateBindParams(bound_function, arguments, false);
136: }
137: 
138: static unique_ptr<FunctionData> ArrayToJSONBind(ClientContext &context, ScalarFunction &bound_function,
139:                                                 vector<unique_ptr<Expression>> &arguments) {
140: 	if (arguments.size() != 1) {
141: 		throw InvalidInputException("array_to_json() takes exactly one argument");
142: 	}
143: 	auto arg_id = arguments[0]->return_type.id();
144: 	if (arguments[0]->HasParameter()) {
145: 		throw ParameterNotResolvedException();
146: 	}
147: 	if (arg_id != LogicalTypeId::LIST && arg_id != LogicalTypeId::SQLNULL) {
148: 		throw InvalidInputException("array_to_json() argument type must be LIST");
149: 	}
150: 	return JSONCreateBindParams(bound_function, arguments, false);
151: }
152: 
153: static unique_ptr<FunctionData> RowToJSONBind(ClientContext &context, ScalarFunction &bound_function,
154:                                               vector<unique_ptr<Expression>> &arguments) {
155: 	if (arguments.size() != 1) {
156: 		throw InvalidInputException("row_to_json() takes exactly one argument");
157: 	}
158: 	auto arg_id = arguments[0]->return_type.id();
159: 	if (arguments[0]->HasParameter()) {
160: 		throw ParameterNotResolvedException();
161: 	}
162: 	if (arguments[0]->return_type.id() != LogicalTypeId::STRUCT && arg_id != LogicalTypeId::SQLNULL) {
163: 		throw InvalidInputException("row_to_json() argument type must be STRUCT");
164: 	}
165: 	return JSONCreateBindParams(bound_function, arguments, false);
166: }
167: 
168: template <class INPUT_TYPE, class RESULT_TYPE>
169: struct CreateJSONValue {
170: 	static inline RESULT_TYPE Operation(const INPUT_TYPE &input) {
171: 		throw NotImplementedException("Unsupported type for CreateJSONValue");
172: 	}
173: };
174: 
175: template <class INPUT_TYPE>
176: struct CreateJSONValue<INPUT_TYPE, bool> {
177: 	static inline yyjson_mut_val *Operation(yyjson_mut_doc *doc, const INPUT_TYPE &input) {
178: 		return yyjson_mut_bool(doc, input);
179: 	}
180: };
181: 
182: template <class INPUT_TYPE>
183: struct CreateJSONValue<INPUT_TYPE, uint64_t> {
184: 	static inline yyjson_mut_val *Operation(yyjson_mut_doc *doc, const INPUT_TYPE &input) {
185: 		return yyjson_mut_uint(doc, input);
186: 	}
187: };
188: 
189: template <class INPUT_TYPE>
190: struct CreateJSONValue<INPUT_TYPE, int64_t> {
191: 	static inline yyjson_mut_val *Operation(yyjson_mut_doc *doc, const INPUT_TYPE &input) {
192: 		return yyjson_mut_sint(doc, input);
193: 	}
194: };
195: 
196: template <class INPUT_TYPE>
197: struct CreateJSONValue<INPUT_TYPE, double> {
198: 	static inline yyjson_mut_val *Operation(yyjson_mut_doc *doc, const INPUT_TYPE &input) {
199: 		return yyjson_mut_real(doc, input);
200: 	}
201: };
202: 
203: template <>
204: struct CreateJSONValue<string_t, string_t> {
205: 	static inline yyjson_mut_val *Operation(yyjson_mut_doc *doc, const string_t &input) {
206: 		return yyjson_mut_strncpy(doc, input.GetData(), input.GetSize());
207: 	}
208: };
209: 
210: template <>
211: struct CreateJSONValue<hugeint_t, string_t> {
212: 	static inline yyjson_mut_val *Operation(yyjson_mut_doc *doc, const hugeint_t &input) {
213: 		const auto input_string = input.ToString();
214: 		return yyjson_mut_strncpy(doc, input_string.c_str(), input_string.length());
215: 	}
216: };
217: 
218: template <>
219: struct CreateJSONValue<uhugeint_t, string_t> {
220: 	static inline yyjson_mut_val *Operation(yyjson_mut_doc *doc, const uhugeint_t &input) {
221: 		const auto input_string = input.ToString();
222: 		return yyjson_mut_strncpy(doc, input_string.c_str(), input_string.length());
223: 	}
224: };
225: 
226: template <class T>
227: inline yyjson_mut_val *CreateJSONValueFromJSON(yyjson_mut_doc *doc, const T &value) {
228: 	return nullptr; // This function should only be called with string_t as template
229: }
230: 
231: template <>
232: inline yyjson_mut_val *CreateJSONValueFromJSON(yyjson_mut_doc *doc, const string_t &value) {
233: 	auto value_doc = JSONCommon::ReadDocument(value, JSONCommon::READ_FLAG, &doc->alc);
234: 	auto result = yyjson_val_mut_copy(doc, value_doc->root);
235: 	return result;
236: }
237: 
238: // Forward declaration so we can recurse for nested types
239: static void CreateValues(const StructNames &names, yyjson_mut_doc *doc, yyjson_mut_val *vals[], Vector &value_v,
240:                          idx_t count);
241: 
242: static void AddKeyValuePairs(yyjson_mut_doc *doc, yyjson_mut_val *objs[], Vector &key_v, yyjson_mut_val *vals[],
243:                              idx_t count) {
244: 	UnifiedVectorFormat key_data;
245: 	key_v.ToUnifiedFormat(count, key_data);
246: 	auto keys = UnifiedVectorFormat::GetData<string_t>(key_data);
247: 
248: 	for (idx_t i = 0; i < count; i++) {
249: 		auto key_idx = key_data.sel->get_index(i);
250: 		if (!key_data.validity.RowIsValid(key_idx)) {
251: 			continue;
252: 		}
253: 		auto key = CreateJSONValue<string_t, string_t>::Operation(doc, keys[key_idx]);
254: 		yyjson_mut_obj_add(objs[i], key, vals[i]);
255: 	}
256: }
257: 
258: static void CreateKeyValuePairs(const StructNames &names, yyjson_mut_doc *doc, yyjson_mut_val *objs[],
259:                                 yyjson_mut_val *vals[], Vector &key_v, Vector &value_v, idx_t count) {
260: 	CreateValues(names, doc, vals, value_v, count);
261: 	AddKeyValuePairs(doc, objs, key_v, vals, count);
262: }
263: 
264: static void CreateValuesNull(yyjson_mut_doc *doc, yyjson_mut_val *vals[], idx_t count) {
265: 	for (idx_t i = 0; i < count; i++) {
266: 		vals[i] = yyjson_mut_null(doc);
267: 	}
268: }
269: 
270: template <class INPUT_TYPE, class TARGET_TYPE>
271: static void TemplatedCreateValues(yyjson_mut_doc *doc, yyjson_mut_val *vals[], Vector &value_v, idx_t count) {
272: 	UnifiedVectorFormat value_data;
273: 	value_v.ToUnifiedFormat(count, value_data);
274: 	auto values = UnifiedVectorFormat::GetData<INPUT_TYPE>(value_data);
275: 
276: 	const auto type_is_json = value_v.GetType().IsJSONType();
277: 	for (idx_t i = 0; i < count; i++) {
278: 		idx_t val_idx = value_data.sel->get_index(i);
279: 		if (!value_data.validity.RowIsValid(val_idx)) {
280: 			vals[i] = yyjson_mut_null(doc);
281: 		} else if (type_is_json) {
282: 			vals[i] = CreateJSONValueFromJSON(doc, values[val_idx]);
283: 		} else {
284: 			vals[i] = CreateJSONValue<INPUT_TYPE, TARGET_TYPE>::Operation(doc, values[val_idx]);
285: 		}
286: 		D_ASSERT(vals[i] != nullptr);
287: 	}
288: }
289: 
290: static void CreateValuesStruct(const StructNames &names, yyjson_mut_doc *doc, yyjson_mut_val *vals[], Vector &value_v,
291:                                idx_t count) {
292: 	// Structs become values, therefore we initialize vals to JSON values
293: 	for (idx_t i = 0; i < count; i++) {
294: 		vals[i] = yyjson_mut_obj(doc);
295: 	}
296: 	// Initialize re-usable array for the nested values
297: 	auto nested_vals = JSONCommon::AllocateArray<yyjson_mut_val *>(doc, count);
298: 
299: 	// Add the key/value pairs to the values
300: 	auto &entries = StructVector::GetEntries(value_v);
301: 	for (idx_t entry_i = 0; entry_i < entries.size(); entry_i++) {
302: 		auto &struct_key_v = *names.at(StructType::GetChildName(value_v.GetType(), entry_i));
303: 		auto &struct_val_v = *entries[entry_i];
304: 		CreateKeyValuePairs(names, doc, vals, nested_vals, struct_key_v, struct_val_v, count);
305: 	}
306: 	// Whole struct can be NULL
307: 	UnifiedVectorFormat struct_data;
308: 	value_v.ToUnifiedFormat(count, struct_data);
309: 	for (idx_t i = 0; i < count; i++) {
310: 		idx_t idx = struct_data.sel->get_index(i);
311: 		if (!struct_data.validity.RowIsValid(idx)) {
312: 			vals[i] = yyjson_mut_null(doc);
313: 		}
314: 	}
315: }
316: 
317: static void CreateValuesMap(const StructNames &names, yyjson_mut_doc *doc, yyjson_mut_val *vals[], Vector &value_v,
318:                             idx_t count) {
319: 	// Create nested keys
320: 	auto &map_key_v = MapVector::GetKeys(value_v);
321: 	auto map_key_count = ListVector::GetListSize(value_v);
322: 	Vector map_keys_string(LogicalType::VARCHAR, map_key_count);
323: 	VectorOperations::DefaultCast(map_key_v, map_keys_string, map_key_count);
324: 	auto nested_keys = JSONCommon::AllocateArray<yyjson_mut_val *>(doc, map_key_count);
325: 	TemplatedCreateValues<string_t, string_t>(doc, nested_keys, map_keys_string, map_key_count);
326: 	// Create nested values
327: 	auto &map_val_v = MapVector::GetValues(value_v);
328: 	auto map_val_count = ListVector::GetListSize(value_v);
329: 	auto nested_vals = JSONCommon::AllocateArray<yyjson_mut_val *>(doc, map_val_count);
330: 	CreateValues(names, doc, nested_vals, map_val_v, map_val_count);
331: 	// Add the key/value pairs to the values
332: 	UnifiedVectorFormat map_data;
333: 	value_v.ToUnifiedFormat(count, map_data);
334: 	auto map_key_list_entries = UnifiedVectorFormat::GetData<list_entry_t>(map_data);
335: 	for (idx_t i = 0; i < count; i++) {
336: 		idx_t idx = map_data.sel->get_index(i);
337: 		if (!map_data.validity.RowIsValid(idx)) {
338: 			// Whole map can be NULL
339: 			vals[i] = yyjson_mut_null(doc);
340: 		} else {
341: 			vals[i] = yyjson_mut_obj(doc);
342: 			const auto &key_list_entry = map_key_list_entries[idx];
343: 			for (idx_t child_i = key_list_entry.offset; child_i < key_list_entry.offset + key_list_entry.length;
344: 			     child_i++) {
345: 				if (!unsafe_yyjson_is_null(nested_keys[child_i])) {
346: 					yyjson_mut_obj_add(vals[i], nested_keys[child_i], nested_vals[child_i]);
347: 				}
348: 			}
349: 		}
350: 	}
351: }
352: 
353: static void CreateValuesUnion(const StructNames &names, yyjson_mut_doc *doc, yyjson_mut_val *vals[], Vector &value_v,
354:                               idx_t count) {
355: 	// Structs become values, therefore we initialize vals to JSON values
356: 	UnifiedVectorFormat value_data;
357: 	value_v.ToUnifiedFormat(count, value_data);
358: 	if (value_data.validity.AllValid()) {
359: 		for (idx_t i = 0; i < count; i++) {
360: 			vals[i] = yyjson_mut_obj(doc);
361: 		}
362: 	} else {
363: 		for (idx_t i = 0; i < count; i++) {
364: 			auto index = value_data.sel->get_index(i);
365: 			if (!value_data.validity.RowIsValid(index)) {
366: 				// Make the entry NULL if the Union value is NULL
367: 				vals[i] = yyjson_mut_null(doc);
368: 			} else {
369: 				vals[i] = yyjson_mut_obj(doc);
370: 			}
371: 		}
372: 	}
373: 
374: 	// Initialize re-usable array for the nested values
375: 	auto nested_vals = JSONCommon::AllocateArray<yyjson_mut_val *>(doc, count);
376: 
377: 	auto &tag_v = UnionVector::GetTags(value_v);
378: 	UnifiedVectorFormat tag_data;
379: 	tag_v.ToUnifiedFormat(count, tag_data);
380: 
381: 	// Add the key/value pairs to the values
382: 	for (idx_t member_idx = 0; member_idx < UnionType::GetMemberCount(value_v.GetType()); member_idx++) {
383: 		auto &member_val_v = UnionVector::GetMember(value_v, member_idx);
384: 		auto &member_key_v = *names.at(UnionType::GetMemberName(value_v.GetType(), member_idx));
385: 
386: 		// This implementation is not optimal since we convert the entire member vector,
387: 		// and then skip the rows not matching the tag afterwards.
388: 
389: 		CreateValues(names, doc, nested_vals, member_val_v, count);
390: 
391: 		// This is a inlined copy of AddKeyValuePairs but we also skip null tags
392: 		// and the rows where the member is not matching the tag
393: 		UnifiedVectorFormat key_data;
394: 		member_key_v.ToUnifiedFormat(count, key_data);
395: 		auto keys = UnifiedVectorFormat::GetData<string_t>(key_data);
396: 
397: 		for (idx_t i = 0; i < count; i++) {
398: 			auto value_index = value_data.sel->get_index(i);
399: 			if (!value_data.validity.RowIsValid(value_index)) {
400: 				// This entry is just NULL in it's entirety
401: 				continue;
402: 			}
403: 			auto tag_idx = tag_data.sel->get_index(i);
404: 			if (!tag_data.validity.RowIsValid(tag_idx)) {
405: 				continue;
406: 			}
407: 			auto tag = (UnifiedVectorFormat::GetData<uint8_t>(tag_data))[tag_idx];
408: 			if (tag != member_idx) {
409: 				continue;
410: 			}
411: 			auto key_idx = key_data.sel->get_index(i);
412: 			if (!key_data.validity.RowIsValid(key_idx)) {
413: 				continue;
414: 			}
415: 			auto key = CreateJSONValue<string_t, string_t>::Operation(doc, keys[key_idx]);
416: 			yyjson_mut_obj_add(vals[i], key, nested_vals[i]);
417: 		}
418: 	}
419: }
420: 
421: static void CreateValuesList(const StructNames &names, yyjson_mut_doc *doc, yyjson_mut_val *vals[], Vector &value_v,
422:                              idx_t count) {
423: 	// Initialize array for the nested values
424: 	auto &child_v = ListVector::GetEntry(value_v);
425: 	auto child_count = ListVector::GetListSize(value_v);
426: 	auto nested_vals = JSONCommon::AllocateArray<yyjson_mut_val *>(doc, child_count);
427: 	// Fill nested_vals with list values
428: 	CreateValues(names, doc, nested_vals, child_v, child_count);
429: 	// Now we add the values to the appropriate JSON arrays
430: 	UnifiedVectorFormat list_data;
431: 	value_v.ToUnifiedFormat(count, list_data);
432: 	auto list_entries = UnifiedVectorFormat::GetData<list_entry_t>(list_data);
433: 	for (idx_t i = 0; i < count; i++) {
434: 		idx_t idx = list_data.sel->get_index(i);
435: 		if (!list_data.validity.RowIsValid(idx)) {
436: 			vals[i] = yyjson_mut_null(doc);
437: 		} else {
438: 			vals[i] = yyjson_mut_arr(doc);
439: 			const auto &entry = list_entries[idx];
440: 			for (idx_t child_i = entry.offset; child_i < entry.offset + entry.length; child_i++) {
441: 				yyjson_mut_arr_append(vals[i], nested_vals[child_i]);
442: 			}
443: 		}
444: 	}
445: }
446: 
447: static void CreateValuesArray(const StructNames &names, yyjson_mut_doc *doc, yyjson_mut_val *vals[], Vector &value_v,
448:                               idx_t count) {
449: 
450: 	value_v.Flatten(count);
451: 
452: 	// Initialize array for the nested values
453: 	auto &child_v = ArrayVector::GetEntry(value_v);
454: 	auto array_size = ArrayType::GetSize(value_v.GetType());
455: 	auto child_count = count * array_size;
456: 
457: 	auto nested_vals = JSONCommon::AllocateArray<yyjson_mut_val *>(doc, child_count);
458: 	// Fill nested_vals with list values
459: 	CreateValues(names, doc, nested_vals, child_v, child_count);
460: 	// Now we add the values to the appropriate JSON arrays
461: 	UnifiedVectorFormat list_data;
462: 	value_v.ToUnifiedFormat(count, list_data);
463: 	for (idx_t i = 0; i < count; i++) {
464: 		idx_t idx = list_data.sel->get_index(i);
465: 		if (!list_data.validity.RowIsValid(idx)) {
466: 			vals[i] = yyjson_mut_null(doc);
467: 		} else {
468: 			vals[i] = yyjson_mut_arr(doc);
469: 			auto offset = idx * array_size;
470: 			for (idx_t child_i = offset; child_i < offset + array_size; child_i++) {
471: 				yyjson_mut_arr_append(vals[i], nested_vals[child_i]);
472: 			}
473: 		}
474: 	}
475: }
476: 
477: static void CreateValues(const StructNames &names, yyjson_mut_doc *doc, yyjson_mut_val *vals[], Vector &value_v,
478:                          idx_t count) {
479: 	switch (value_v.GetType().id()) {
480: 	case LogicalTypeId::SQLNULL:
481: 		CreateValuesNull(doc, vals, count);
482: 		break;
483: 	case LogicalTypeId::BOOLEAN:
484: 		TemplatedCreateValues<bool, bool>(doc, vals, value_v, count);
485: 		break;
486: 	case LogicalTypeId::TINYINT:
487: 		TemplatedCreateValues<int8_t, int64_t>(doc, vals, value_v, count);
488: 		break;
489: 	case LogicalTypeId::SMALLINT:
490: 		TemplatedCreateValues<int16_t, int64_t>(doc, vals, value_v, count);
491: 		break;
492: 	case LogicalTypeId::INTEGER:
493: 		TemplatedCreateValues<int32_t, int64_t>(doc, vals, value_v, count);
494: 		break;
495: 	case LogicalTypeId::BIGINT:
496: 		TemplatedCreateValues<int64_t, int64_t>(doc, vals, value_v, count);
497: 		break;
498: 	case LogicalTypeId::HUGEINT:
499: 		TemplatedCreateValues<hugeint_t, string_t>(doc, vals, value_v, count);
500: 		break;
501: 	case LogicalTypeId::UHUGEINT:
502: 		TemplatedCreateValues<uhugeint_t, string_t>(doc, vals, value_v, count);
503: 		break;
504: 	case LogicalTypeId::UTINYINT:
505: 		TemplatedCreateValues<uint8_t, uint64_t>(doc, vals, value_v, count);
506: 		break;
507: 	case LogicalTypeId::USMALLINT:
508: 		TemplatedCreateValues<uint16_t, uint64_t>(doc, vals, value_v, count);
509: 		break;
510: 	case LogicalTypeId::UINTEGER:
511: 		TemplatedCreateValues<uint32_t, uint64_t>(doc, vals, value_v, count);
512: 		break;
513: 	case LogicalTypeId::UBIGINT:
514: 		TemplatedCreateValues<uint64_t, uint64_t>(doc, vals, value_v, count);
515: 		break;
516: 	case LogicalTypeId::FLOAT:
517: 		TemplatedCreateValues<float, double>(doc, vals, value_v, count);
518: 		break;
519: 	case LogicalTypeId::DOUBLE:
520: 		TemplatedCreateValues<double, double>(doc, vals, value_v, count);
521: 		break;
522: 	case LogicalTypeId::BIT:
523: 	case LogicalTypeId::BLOB:
524: 	case LogicalTypeId::VARCHAR:
525: 		TemplatedCreateValues<string_t, string_t>(doc, vals, value_v, count);
526: 		break;
527: 	case LogicalTypeId::STRUCT:
528: 		CreateValuesStruct(names, doc, vals, value_v, count);
529: 		break;
530: 	case LogicalTypeId::MAP:
531: 		CreateValuesMap(names, doc, vals, value_v, count);
532: 		break;
533: 	case LogicalTypeId::LIST:
534: 		CreateValuesList(names, doc, vals, value_v, count);
535: 		break;
536: 	case LogicalTypeId::UNION:
537: 		CreateValuesUnion(names, doc, vals, value_v, count);
538: 		break;
539: 	case LogicalTypeId::ARRAY:
540: 		CreateValuesArray(names, doc, vals, value_v, count);
541: 		break;
542: 	case LogicalTypeId::AGGREGATE_STATE:
543: 	case LogicalTypeId::ENUM:
544: 	case LogicalTypeId::DATE:
545: 	case LogicalTypeId::INTERVAL:
546: 	case LogicalTypeId::TIME:
547: 	case LogicalTypeId::TIME_TZ:
548: 	case LogicalTypeId::TIMESTAMP:
549: 	case LogicalTypeId::TIMESTAMP_TZ:
550: 	case LogicalTypeId::TIMESTAMP_NS:
551: 	case LogicalTypeId::TIMESTAMP_MS:
552: 	case LogicalTypeId::TIMESTAMP_SEC:
553: 	case LogicalTypeId::VARINT:
554: 	case LogicalTypeId::UUID: {
555: 		Vector string_vector(LogicalTypeId::VARCHAR, count);
556: 		VectorOperations::DefaultCast(value_v, string_vector, count);
557: 		TemplatedCreateValues<string_t, string_t>(doc, vals, string_vector, count);
558: 		break;
559: 	}
560: 	case LogicalTypeId::DECIMAL: {
561: 		Vector double_vector(LogicalType::DOUBLE, count);
562: 		VectorOperations::DefaultCast(value_v, double_vector, count);
563: 		TemplatedCreateValues<double, double>(doc, vals, double_vector, count);
564: 		break;
565: 	}
566: 	case LogicalTypeId::INVALID:
567: 	case LogicalTypeId::UNKNOWN:
568: 	case LogicalTypeId::ANY:
569: 	case LogicalTypeId::USER:
570: 	case LogicalTypeId::CHAR:
571: 	case LogicalTypeId::STRING_LITERAL:
572: 	case LogicalTypeId::INTEGER_LITERAL:
573: 	case LogicalTypeId::POINTER:
574: 	case LogicalTypeId::VALIDITY:
575: 	case LogicalTypeId::TABLE:
576: 	case LogicalTypeId::LAMBDA:
577: 		throw InternalException("Unsupported type arrived at JSON create function");
578: 	}
579: }
580: 
581: static void ObjectFunction(DataChunk &args, ExpressionState &state, Vector &result) {
582: 	auto &func_expr = state.expr.Cast<BoundFunctionExpression>();
583: 	const auto &info = func_expr.bind_info->Cast<JSONCreateFunctionData>();
584: 	auto &lstate = JSONFunctionLocalState::ResetAndGet(state);
585: 	auto alc = lstate.json_allocator.GetYYAlc();
586: 
587: 	// Initialize values
588: 	const idx_t count = args.size();
589: 	auto doc = JSONCommon::CreateDocument(alc);
590: 	auto objs = JSONCommon::AllocateArray<yyjson_mut_val *>(doc, count);
591: 	for (idx_t i = 0; i < count; i++) {
592: 		objs[i] = yyjson_mut_obj(doc);
593: 	}
594: 	// Initialize a re-usable value array
595: 	auto vals = JSONCommon::AllocateArray<yyjson_mut_val *>(doc, count);
596: 	// Loop through key/value pairs
597: 	for (idx_t pair_idx = 0; pair_idx < args.data.size() / 2; pair_idx++) {
598: 		Vector &key_v = args.data[pair_idx * 2];
599: 		Vector &value_v = args.data[pair_idx * 2 + 1];
600: 		CreateKeyValuePairs(info.const_struct_names, doc, objs, vals, key_v, value_v, count);
601: 	}
602: 	// Write JSON values to string
603: 	auto objects = FlatVector::GetData<string_t>(result);
604: 	for (idx_t i = 0; i < count; i++) {
605: 		objects[i] = JSONCommon::WriteVal<yyjson_mut_val>(objs[i], alc);
606: 	}
607: 
608: 	if (args.AllConstant()) {
609: 		result.SetVectorType(VectorType::CONSTANT_VECTOR);
610: 	}
611: }
612: 
613: static void ArrayFunction(DataChunk &args, ExpressionState &state, Vector &result) {
614: 	auto &func_expr = state.expr.Cast<BoundFunctionExpression>();
615: 	const auto &info = func_expr.bind_info->Cast<JSONCreateFunctionData>();
616: 	auto &lstate = JSONFunctionLocalState::ResetAndGet(state);
617: 	auto alc = lstate.json_allocator.GetYYAlc();
618: 
619: 	// Initialize arrays
620: 	const idx_t count = args.size();
621: 	auto doc = JSONCommon::CreateDocument(alc);
622: 	auto arrs = JSONCommon::AllocateArray<yyjson_mut_val *>(doc, count);
623: 	for (idx_t i = 0; i < count; i++) {
624: 		arrs[i] = yyjson_mut_arr(doc);
625: 	}
626: 	// Initialize a re-usable value array
627: 	auto vals = JSONCommon::AllocateArray<yyjson_mut_val *>(doc, count);
628: 	// Loop through args
629: 	for (auto &v : args.data) {
630: 		CreateValues(info.const_struct_names, doc, vals, v, count);
631: 		for (idx_t i = 0; i < count; i++) {
632: 			yyjson_mut_arr_append(arrs[i], vals[i]);
633: 		}
634: 	}
635: 	// Write JSON arrays to string
636: 	auto objects = FlatVector::GetData<string_t>(result);
637: 	for (idx_t i = 0; i < count; i++) {
638: 		objects[i] = JSONCommon::WriteVal<yyjson_mut_val>(arrs[i], alc);
639: 	}
640: 
641: 	if (args.AllConstant()) {
642: 		result.SetVectorType(VectorType::CONSTANT_VECTOR);
643: 	}
644: }
645: 
646: static void ToJSONFunctionInternal(const StructNames &names, Vector &input, const idx_t count, Vector &result,
647:                                    yyjson_alc *alc) {
648: 	// Initialize array for values
649: 	auto doc = JSONCommon::CreateDocument(alc);
650: 	auto vals = JSONCommon::AllocateArray<yyjson_mut_val *>(doc, count);
651: 	CreateValues(names, doc, vals, input, count);
652: 
653: 	// Write JSON values to string
654: 	auto objects = FlatVector::GetData<string_t>(result);
655: 	auto &result_validity = FlatVector::Validity(result);
656: 	UnifiedVectorFormat input_data;
657: 	input.ToUnifiedFormat(count, input_data);
658: 	for (idx_t i = 0; i < count; i++) {
659: 		idx_t idx = input_data.sel->get_index(i);
660: 		if (input_data.validity.RowIsValid(idx)) {
661: 			objects[i] = JSONCommon::WriteVal<yyjson_mut_val>(vals[i], alc);
662: 		} else {
663: 			result_validity.SetInvalid(i);
664: 		}
665: 	}
666: 
667: 	if (input.GetVectorType() == VectorType::CONSTANT_VECTOR || count == 1) {
668: 		result.SetVectorType(VectorType::CONSTANT_VECTOR);
669: 	}
670: }
671: 
672: static void ToJSONFunction(DataChunk &args, ExpressionState &state, Vector &result) {
673: 	auto &func_expr = state.expr.Cast<BoundFunctionExpression>();
674: 	const auto &info = func_expr.bind_info->Cast<JSONCreateFunctionData>();
675: 	auto &lstate = JSONFunctionLocalState::ResetAndGet(state);
676: 	auto alc = lstate.json_allocator.GetYYAlc();
677: 
678: 	ToJSONFunctionInternal(info.const_struct_names, args.data[0], args.size(), result, alc);
679: }
680: 
681: ScalarFunctionSet JSONFunctions::GetObjectFunction() {
682: 	ScalarFunction fun("json_object", {}, LogicalType::JSON(), ObjectFunction, JSONObjectBind, nullptr, nullptr,
683: 	                   JSONFunctionLocalState::Init);
684: 	fun.varargs = LogicalType::ANY;
685: 	fun.null_handling = FunctionNullHandling::SPECIAL_HANDLING;
686: 	return ScalarFunctionSet(fun);
687: }
688: 
689: ScalarFunctionSet JSONFunctions::GetArrayFunction() {
690: 	ScalarFunction fun("json_array", {}, LogicalType::JSON(), ArrayFunction, JSONArrayBind, nullptr, nullptr,
691: 	                   JSONFunctionLocalState::Init);
692: 	fun.varargs = LogicalType::ANY;
693: 	fun.null_handling = FunctionNullHandling::SPECIAL_HANDLING;
694: 	return ScalarFunctionSet(fun);
695: }
696: 
697: ScalarFunctionSet JSONFunctions::GetToJSONFunction() {
698: 	ScalarFunction fun("to_json", {}, LogicalType::JSON(), ToJSONFunction, ToJSONBind, nullptr, nullptr,
699: 	                   JSONFunctionLocalState::Init);
700: 	fun.varargs = LogicalType::ANY;
701: 	return ScalarFunctionSet(fun);
702: }
703: 
704: ScalarFunctionSet JSONFunctions::GetArrayToJSONFunction() {
705: 	ScalarFunction fun("array_to_json", {}, LogicalType::JSON(), ToJSONFunction, ArrayToJSONBind, nullptr, nullptr,
706: 	                   JSONFunctionLocalState::Init);
707: 	fun.varargs = LogicalType::ANY;
708: 	return ScalarFunctionSet(fun);
709: }
710: 
711: ScalarFunctionSet JSONFunctions::GetRowToJSONFunction() {
712: 	ScalarFunction fun("row_to_json", {}, LogicalType::JSON(), ToJSONFunction, RowToJSONBind, nullptr, nullptr,
713: 	                   JSONFunctionLocalState::Init);
714: 	fun.varargs = LogicalType::ANY;
715: 	return ScalarFunctionSet(fun);
716: }
717: 
718: struct NestedToJSONCastData : public BoundCastData {
719: public:
720: 	NestedToJSONCastData() {
721: 	}
722: 
723: 	unique_ptr<BoundCastData> Copy() const override {
724: 		auto result = make_uniq<NestedToJSONCastData>();
725: 		for (auto &csn : const_struct_names) {
726: 			result->const_struct_names.emplace(csn.first, make_uniq<Vector>(csn.second->GetValue(0)));
727: 		}
728: 		return std::move(result);
729: 	}
730: 
731: public:
732: 	StructNames const_struct_names;
733: };
734: 
735: static bool AnyToJSONCast(Vector &source, Vector &result, idx_t count, CastParameters &parameters) {
736: 	auto &lstate = parameters.local_state->Cast<JSONFunctionLocalState>();
737: 	lstate.json_allocator.Reset();
738: 	auto alc = lstate.json_allocator.GetYYAlc();
739: 	const auto &names = parameters.cast_data->Cast<NestedToJSONCastData>().const_struct_names;
740: 
741: 	ToJSONFunctionInternal(names, source, count, result, alc);
742: 	return true;
743: }
744: 
745: BoundCastInfo AnyToJSONCastBind(BindCastInput &input, const LogicalType &source, const LogicalType &target) {
746: 	auto cast_data = make_uniq<NestedToJSONCastData>();
747: 	GetJSONType(cast_data->const_struct_names, source);
748: 	return BoundCastInfo(AnyToJSONCast, std::move(cast_data), JSONFunctionLocalState::InitCastLocalState);
749: }
750: 
751: void JSONFunctions::RegisterJSONCreateCastFunctions(CastFunctionSet &casts) {
752: 	// Anything can be cast to JSON
753: 	for (const auto &type : LogicalType::AllTypes()) {
754: 		LogicalType source_type;
755: 		switch (type.id()) {
756: 		case LogicalTypeId::STRUCT:
757: 			source_type = LogicalType::STRUCT({{"any", LogicalType::ANY}});
758: 			break;
759: 		case LogicalTypeId::LIST:
760: 			source_type = LogicalType::LIST(LogicalType::ANY);
761: 			break;
762: 		case LogicalTypeId::MAP:
763: 			source_type = LogicalType::MAP(LogicalType::ANY, LogicalType::ANY);
764: 			break;
765: 		case LogicalTypeId::UNION:
766: 			source_type = LogicalType::UNION({{"any", LogicalType::ANY}});
767: 			break;
768: 		case LogicalTypeId::ARRAY:
769: 			source_type = LogicalType::ARRAY(LogicalType::ANY, optional_idx());
770: 			break;
771: 		case LogicalTypeId::VARCHAR:
772: 			// We skip this one here as it's handled in json_functions.cpp
773: 			continue;
774: 		default:
775: 			source_type = type;
776: 		}
777: 		// We prefer going to JSON over going to VARCHAR if a function can do either
778: 		const auto source_to_json_cost =
779: 		    MaxValue<int64_t>(casts.ImplicitCastCost(source_type, LogicalType::VARCHAR) - 1, 0);
780: 		casts.RegisterCastFunction(source_type, LogicalType::JSON(), AnyToJSONCastBind, source_to_json_cost);
781: 	}
782: }
783: 
784: } // namespace duckdb
[end of extension/json/json_functions/json_create.cpp]
[start of extension/json/json_functions/json_structure.cpp]
1: #include "json_structure.hpp"
2: 
3: #include "duckdb/common/enum_util.hpp"
4: #include "json_executors.hpp"
5: #include "json_scan.hpp"
6: #include "json_transform.hpp"
7: 
8: #include <duckdb/common/extra_type_info.hpp>
9: 
10: namespace duckdb {
11: 
12: static bool IsNumeric(LogicalTypeId type) {
13: 	return type == LogicalTypeId::DOUBLE || type == LogicalTypeId::UBIGINT || type == LogicalTypeId::BIGINT;
14: }
15: 
16: static LogicalTypeId MaxNumericType(const LogicalTypeId &a, const LogicalTypeId &b) {
17: 	D_ASSERT(a != b);
18: 	if (a == LogicalTypeId::DOUBLE || b == LogicalTypeId::DOUBLE) {
19: 		return LogicalTypeId::DOUBLE;
20: 	}
21: 	return LogicalTypeId::BIGINT;
22: }
23: 
24: JSONStructureNode::JSONStructureNode() : count(0), null_count(0) {
25: }
26: 
27: JSONStructureNode::JSONStructureNode(const char *key_ptr, const size_t key_len) : JSONStructureNode() {
28: 	key = make_uniq<string>(key_ptr, key_len);
29: }
30: 
31: JSONStructureNode::JSONStructureNode(yyjson_val *key_p, yyjson_val *val_p, const bool ignore_errors)
32:     : JSONStructureNode(unsafe_yyjson_get_str(key_p), unsafe_yyjson_get_len(key_p)) {
33: 	JSONStructure::ExtractStructure(val_p, *this, ignore_errors);
34: }
35: 
36: static void SwapJSONStructureNode(JSONStructureNode &a, JSONStructureNode &b) noexcept {
37: 	std::swap(a.key, b.key);
38: 	std::swap(a.initialized, b.initialized);
39: 	std::swap(a.descriptions, b.descriptions);
40: 	std::swap(a.count, b.count);
41: 	std::swap(a.null_count, b.null_count);
42: }
43: 
44: JSONStructureNode::JSONStructureNode(JSONStructureNode &&other) noexcept {
45: 	SwapJSONStructureNode(*this, other);
46: }
47: 
48: JSONStructureNode &JSONStructureNode::operator=(JSONStructureNode &&other) noexcept {
49: 	SwapJSONStructureNode(*this, other);
50: 	return *this;
51: }
52: 
53: JSONStructureDescription &JSONStructureNode::GetOrCreateDescription(const LogicalTypeId type) {
54: 	if (descriptions.empty()) {
55: 		// Empty, just put this type in there
56: 		descriptions.emplace_back(type);
57: 		return descriptions.back();
58: 	}
59: 
60: 	if (descriptions.size() == 1 && descriptions[0].type == LogicalTypeId::SQLNULL) {
61: 		// Only a NULL in there, override
62: 		descriptions[0].type = type;
63: 		return descriptions[0];
64: 	}
65: 
66: 	if (type == LogicalTypeId::SQLNULL) {
67: 		// 'descriptions' is non-empty, so let's not add NULL
68: 		return descriptions.back();
69: 	}
70: 
71: 	// Check if type is already in there or if we can merge numerics
72: 	const auto is_numeric = IsNumeric(type);
73: 	for (auto &description : descriptions) {
74: 		if (type == description.type) {
75: 			return description;
76: 		}
77: 		if (is_numeric && IsNumeric(description.type)) {
78: 			description.type = MaxNumericType(type, description.type);
79: 			return description;
80: 		}
81: 	}
82: 	// Type was not there, create a new description
83: 	descriptions.emplace_back(type);
84: 	return descriptions.back();
85: }
86: 
87: bool JSONStructureNode::ContainsVarchar() const {
88: 	if (descriptions.size() != 1) {
89: 		// We can't refine types if we have more than 1 description (yet), defaults to JSON type for now
90: 		return false;
91: 	}
92: 	auto &description = descriptions[0];
93: 	if (description.type == LogicalTypeId::VARCHAR) {
94: 		return true;
95: 	}
96: 	for (auto &child : description.children) {
97: 		if (child.ContainsVarchar()) {
98: 			return true;
99: 		}
100: 	}
101: 
102: 	return false;
103: }
104: 
105: void JSONStructureNode::InitializeCandidateTypes(const idx_t max_depth, const bool convert_strings_to_integers,
106:                                                  const idx_t depth) {
107: 	if (depth >= max_depth) {
108: 		return;
109: 	}
110: 	if (descriptions.size() != 1) {
111: 		// We can't refine types if we have more than 1 description (yet), defaults to JSON type for now
112: 		return;
113: 	}
114: 	auto &description = descriptions[0];
115: 	if (description.type == LogicalTypeId::VARCHAR && !initialized) {
116: 		// We loop through the candidate types and format templates from back to front
117: 		if (convert_strings_to_integers) {
118: 			description.candidate_types = {LogicalTypeId::UUID, LogicalTypeId::BIGINT, LogicalTypeId::TIMESTAMP,
119: 			                               LogicalTypeId::DATE, LogicalTypeId::TIME};
120: 		} else {
121: 			description.candidate_types = {LogicalTypeId::UUID, LogicalTypeId::TIMESTAMP, LogicalTypeId::DATE,
122: 			                               LogicalTypeId::TIME};
123: 		}
124: 		initialized = true;
125: 	} else {
126: 		for (auto &child : description.children) {
127: 			child.InitializeCandidateTypes(max_depth, convert_strings_to_integers, depth + 1);
128: 		}
129: 	}
130: }
131: 
132: void JSONStructureNode::RefineCandidateTypes(yyjson_val *vals[], const idx_t val_count, Vector &string_vector,
133:                                              ArenaAllocator &allocator, DateFormatMap &date_format_map) {
134: 	if (descriptions.size() != 1) {
135: 		// We can't refine types if we have more than 1 description (yet), defaults to JSON type for now
136: 		return;
137: 	}
138: 	if (!ContainsVarchar()) {
139: 		return;
140: 	}
141: 	auto &description = descriptions[0];
142: 	switch (description.type) {
143: 	case LogicalTypeId::LIST:
144: 		return RefineCandidateTypesArray(vals, val_count, string_vector, allocator, date_format_map);
145: 	case LogicalTypeId::STRUCT:
146: 		return RefineCandidateTypesObject(vals, val_count, string_vector, allocator, date_format_map);
147: 	case LogicalTypeId::VARCHAR:
148: 		return RefineCandidateTypesString(vals, val_count, string_vector, date_format_map);
149: 	default:
150: 		return;
151: 	}
152: }
153: 
154: void JSONStructureNode::RefineCandidateTypesArray(yyjson_val *vals[], const idx_t val_count, Vector &string_vector,
155:                                                   ArenaAllocator &allocator, DateFormatMap &date_format_map) {
156: 	D_ASSERT(descriptions.size() == 1 && descriptions[0].type == LogicalTypeId::LIST);
157: 	auto &desc = descriptions[0];
158: 	D_ASSERT(desc.children.size() == 1);
159: 	auto &child = desc.children[0];
160: 
161: 	idx_t total_list_size = 0;
162: 	for (idx_t i = 0; i < val_count; i++) {
163: 		if (vals[i] && !unsafe_yyjson_is_null(vals[i])) {
164: 			D_ASSERT(yyjson_is_arr(vals[i]));
165: 			total_list_size += unsafe_yyjson_get_len(vals[i]);
166: 		}
167: 	}
168: 
169: 	idx_t offset = 0;
170: 	auto child_vals =
171: 	    reinterpret_cast<yyjson_val **>(allocator.AllocateAligned(total_list_size * sizeof(yyjson_val *)));
172: 
173: 	size_t idx, max;
174: 	yyjson_val *child_val;
175: 	for (idx_t i = 0; i < val_count; i++) {
176: 		if (vals[i] && !unsafe_yyjson_is_null(vals[i])) {
177: 			yyjson_arr_foreach(vals[i], idx, max, child_val) {
178: 				child_vals[offset++] = child_val;
179: 			}
180: 		}
181: 	}
182: 	child.RefineCandidateTypes(child_vals, total_list_size, string_vector, allocator, date_format_map);
183: }
184: 
185: void JSONStructureNode::RefineCandidateTypesObject(yyjson_val *vals[], const idx_t val_count, Vector &string_vector,
186:                                                    ArenaAllocator &allocator, DateFormatMap &date_format_map) {
187: 	D_ASSERT(descriptions.size() == 1 && descriptions[0].type == LogicalTypeId::STRUCT);
188: 	auto &desc = descriptions[0];
189: 
190: 	const idx_t child_count = desc.children.size();
191: 	vector<yyjson_val **> child_vals;
192: 	child_vals.reserve(child_count);
193: 	for (idx_t child_idx = 0; child_idx < child_count; child_idx++) {
194: 		child_vals.emplace_back(
195: 		    reinterpret_cast<yyjson_val **>(allocator.AllocateAligned(val_count * sizeof(yyjson_val *))));
196: 	}
197: 
198: 	const auto found_keys = reinterpret_cast<bool *>(allocator.AllocateAligned(sizeof(bool) * child_count));
199: 
200: 	const auto &key_map = desc.key_map;
201: 	size_t idx, max;
202: 	yyjson_val *child_key, *child_val;
203: 	for (idx_t i = 0; i < val_count; i++) {
204: 		if (vals[i] && !unsafe_yyjson_is_null(vals[i])) {
205: 			idx_t found_key_count = 0;
206: 			memset(found_keys, false, child_count);
207: 
208: 			D_ASSERT(yyjson_is_obj(vals[i]));
209: 			yyjson_obj_foreach(vals[i], idx, max, child_key, child_val) {
210: 				D_ASSERT(yyjson_is_str(child_key));
211: 				const auto key_ptr = unsafe_yyjson_get_str(child_key);
212: 				const auto key_len = unsafe_yyjson_get_len(child_key);
213: 				auto it = key_map.find({key_ptr, key_len});
214: 				D_ASSERT(it != key_map.end());
215: 				const auto child_idx = it->second;
216: 				child_vals[child_idx][i] = child_val;
217: 				found_key_count += !found_keys[child_idx];
218: 				found_keys[child_idx] = true;
219: 			}
220: 
221: 			if (found_key_count != child_count) {
222: 				// Set child val to nullptr so recursion doesn't break
223: 				for (idx_t child_idx = 0; child_idx < child_count; child_idx++) {
224: 					if (!found_keys[child_idx]) {
225: 						child_vals[child_idx][i] = nullptr;
226: 					}
227: 				}
228: 			}
229: 		} else {
230: 			for (idx_t child_idx = 0; child_idx < child_count; child_idx++) {
231: 				child_vals[child_idx][i] = nullptr;
232: 			}
233: 		}
234: 	}
235: 
236: 	for (idx_t child_idx = 0; child_idx < child_count; child_idx++) {
237: 		desc.children[child_idx].RefineCandidateTypes(child_vals[child_idx], val_count, string_vector, allocator,
238: 		                                              date_format_map);
239: 	}
240: }
241: 
242: void JSONStructureNode::RefineCandidateTypesString(yyjson_val *vals[], const idx_t val_count, Vector &string_vector,
243:                                                    DateFormatMap &date_format_map) {
244: 	D_ASSERT(descriptions.size() == 1 && descriptions[0].type == LogicalTypeId::VARCHAR);
245: 	if (descriptions[0].candidate_types.empty()) {
246: 		return;
247: 	}
248: 	static JSONTransformOptions OPTIONS;
249: 	JSONTransform::GetStringVector(vals, val_count, LogicalType::SQLNULL, string_vector, OPTIONS);
250: 	EliminateCandidateTypes(val_count, string_vector, date_format_map);
251: }
252: 
253: void JSONStructureNode::EliminateCandidateTypes(const idx_t vec_count, Vector &string_vector,
254:                                                 DateFormatMap &date_format_map) {
255: 	D_ASSERT(descriptions.size() == 1 && descriptions[0].type == LogicalTypeId::VARCHAR);
256: 	auto &description = descriptions[0];
257: 	auto &candidate_types = description.candidate_types;
258: 	while (true) {
259: 		if (candidate_types.empty()) {
260: 			return;
261: 		}
262: 		const auto type = candidate_types.back();
263: 		Vector result_vector(type, vec_count);
264: 		if (date_format_map.HasFormats(type)) {
265: 			auto &formats = date_format_map.GetCandidateFormats(type);
266: 			if (EliminateCandidateFormats(vec_count, string_vector, result_vector, formats)) {
267: 				return;
268: 			} else {
269: 				candidate_types.pop_back();
270: 			}
271: 		} else {
272: 			string error_message;
273: 			if (!VectorOperations::DefaultTryCast(string_vector, result_vector, vec_count, &error_message, true)) {
274: 				candidate_types.pop_back();
275: 			} else {
276: 				return;
277: 			}
278: 		}
279: 	}
280: }
281: 
282: template <class OP, class T>
283: bool TryParse(Vector &string_vector, StrpTimeFormat &format, const idx_t count) {
284: 	const auto strings = FlatVector::GetData<string_t>(string_vector);
285: 	const auto &validity = FlatVector::Validity(string_vector);
286: 
287: 	T result;
288: 	string error_message;
289: 	if (validity.AllValid()) {
290: 		for (idx_t i = 0; i < count; i++) {
291: 			if (!OP::template Operation<T>(format, strings[i], result, error_message)) {
292: 				return false;
293: 			}
294: 		}
295: 	} else {
296: 		for (idx_t i = 0; i < count; i++) {
297: 			if (validity.RowIsValid(i)) {
298: 				if (!OP::template Operation<T>(format, strings[i], result, error_message)) {
299: 					return false;
300: 				}
301: 			}
302: 		}
303: 	}
304: 	return true;
305: }
306: 
307: bool JSONStructureNode::EliminateCandidateFormats(const idx_t vec_count, Vector &string_vector,
308:                                                   const Vector &result_vector, vector<StrpTimeFormat> &formats) {
309: 	D_ASSERT(descriptions.size() == 1 && descriptions[0].type == LogicalTypeId::VARCHAR);
310: 	const auto type = result_vector.GetType().id();
311: 	for (idx_t i = formats.size(); i != 0; i--) {
312: 		const idx_t actual_index = i - 1;
313: 		auto &format = formats[actual_index];
314: 		bool success;
315: 		switch (type) {
316: 		case LogicalTypeId::DATE:
317: 			success = TryParse<TryParseDate, date_t>(string_vector, format, vec_count);
318: 			break;
319: 		case LogicalTypeId::TIMESTAMP:
320: 			success = TryParse<TryParseTimeStamp, timestamp_t>(string_vector, format, vec_count);
321: 			break;
322: 		default:
323: 			throw InternalException("No date/timestamp formats for %s", EnumUtil::ToString(type));
324: 		}
325: 		if (success) {
326: 			while (formats.size() > i) {
327: 				formats.pop_back();
328: 			}
329: 			return true;
330: 		}
331: 	}
332: 	return false;
333: }
334: 
335: JSONStructureDescription::JSONStructureDescription(const LogicalTypeId type_p) : type(type_p) {
336: }
337: 
338: static void SwapJSONStructureDescription(JSONStructureDescription &a, JSONStructureDescription &b) noexcept {
339: 	std::swap(a.type, b.type);
340: 	std::swap(a.key_map, b.key_map);
341: 	std::swap(a.children, b.children);
342: 	std::swap(a.candidate_types, b.candidate_types);
343: }
344: 
345: JSONStructureDescription::JSONStructureDescription(JSONStructureDescription &&other) noexcept {
346: 	SwapJSONStructureDescription(*this, other);
347: }
348: 
349: JSONStructureDescription &JSONStructureDescription::operator=(JSONStructureDescription &&other) noexcept {
350: 	SwapJSONStructureDescription(*this, other);
351: 	return *this;
352: }
353: 
354: JSONStructureNode &JSONStructureDescription::GetOrCreateChild() {
355: 	D_ASSERT(type == LogicalTypeId::LIST);
356: 	if (children.empty()) {
357: 		children.emplace_back();
358: 	}
359: 	D_ASSERT(children.size() == 1);
360: 	return children.back();
361: }
362: 
363: JSONStructureNode &JSONStructureDescription::GetOrCreateChild(const char *key_ptr, const size_t key_size) {
364: 	// Check if there is already a child with the same key
365: 	const JSONKey temp_key {key_ptr, key_size};
366: 	const auto it = key_map.find(temp_key);
367: 	if (it != key_map.end()) {
368: 		return children[it->second]; // Found it
369: 	}
370: 
371: 	// Didn't find, create a new child
372: 	children.emplace_back(key_ptr, key_size);
373: 	const auto &persistent_key_string = *children.back().key;
374: 	JSONKey new_key {persistent_key_string.c_str(), persistent_key_string.length()};
375: 	key_map.emplace(new_key, children.size() - 1);
376: 	return children.back();
377: }
378: 
379: JSONStructureNode &JSONStructureDescription::GetOrCreateChild(yyjson_val *key, yyjson_val *val,
380:                                                               const bool ignore_errors) {
381: 	D_ASSERT(yyjson_is_str(key));
382: 	auto &child = GetOrCreateChild(unsafe_yyjson_get_str(key), unsafe_yyjson_get_len(key));
383: 	JSONStructure::ExtractStructure(val, child, ignore_errors);
384: 	return child;
385: }
386: 
387: static void ExtractStructureArray(yyjson_val *arr, JSONStructureNode &node, const bool ignore_errors) {
388: 	D_ASSERT(yyjson_is_arr(arr));
389: 	auto &description = node.GetOrCreateDescription(LogicalTypeId::LIST);
390: 	auto &child = description.GetOrCreateChild();
391: 
392: 	size_t idx, max;
393: 	yyjson_val *val;
394: 	yyjson_arr_foreach(arr, idx, max, val) {
395: 		JSONStructure::ExtractStructure(val, child, ignore_errors);
396: 	}
397: }
398: 
399: static void ExtractStructureObject(yyjson_val *obj, JSONStructureNode &node, const bool ignore_errors) {
400: 	D_ASSERT(yyjson_is_obj(obj));
401: 	auto &description = node.GetOrCreateDescription(LogicalTypeId::STRUCT);
402: 
403: 	// Keep track of keys so we can detect duplicates
404: 	unordered_set<string> obj_keys;
405: 	case_insensitive_set_t ci_obj_keys;
406: 
407: 	size_t idx, max;
408: 	yyjson_val *key, *val;
409: 	yyjson_obj_foreach(obj, idx, max, key, val) {
410: 		const string obj_key(unsafe_yyjson_get_str(key), unsafe_yyjson_get_len(key));
411: 		auto insert_result = obj_keys.insert(obj_key);
412: 		if (!ignore_errors && !insert_result.second) { // Exact match
413: 			JSONCommon::ThrowValFormatError("Duplicate key \"" + obj_key + "\" in object %s", obj);
414: 		}
415: 		insert_result = ci_obj_keys.insert(obj_key);
416: 		if (!ignore_errors && !insert_result.second) { // Case-insensitive match
417: 			JSONCommon::ThrowValFormatError("Duplicate key (different case) \"" + obj_key + "\" and \"" +
418: 			                                    *insert_result.first + "\" in object %s",
419: 			                                obj);
420: 		}
421: 		description.GetOrCreateChild(key, val, ignore_errors);
422: 	}
423: }
424: 
425: static void ExtractStructureVal(yyjson_val *val, JSONStructureNode &node) {
426: 	D_ASSERT(!yyjson_is_arr(val) && !yyjson_is_obj(val));
427: 	node.GetOrCreateDescription(JSONCommon::ValTypeToLogicalTypeId(val));
428: }
429: 
430: void JSONStructure::ExtractStructure(yyjson_val *val, JSONStructureNode &node, const bool ignore_errors) {
431: 	node.count++;
432: 	const auto tag = yyjson_get_tag(val);
433: 	if (tag == (YYJSON_TYPE_NULL | YYJSON_SUBTYPE_NONE)) {
434: 		node.null_count++;
435: 	}
436: 
437: 	switch (tag) {
438: 	case YYJSON_TYPE_ARR | YYJSON_SUBTYPE_NONE:
439: 		return ExtractStructureArray(val, node, ignore_errors);
440: 	case YYJSON_TYPE_OBJ | YYJSON_SUBTYPE_NONE:
441: 		return ExtractStructureObject(val, node, ignore_errors);
442: 	default:
443: 		return ExtractStructureVal(val, node);
444: 	}
445: }
446: 
447: JSONStructureNode ExtractStructureInternal(yyjson_val *val, const bool ignore_errors) {
448: 	JSONStructureNode node;
449: 	JSONStructure::ExtractStructure(val, node, ignore_errors);
450: 	return node;
451: }
452: 
453: //! Forward declaration for recursion
454: static yyjson_mut_val *ConvertStructure(const JSONStructureNode &node, yyjson_mut_doc *doc);
455: 
456: static yyjson_mut_val *ConvertStructureArray(const JSONStructureNode &node, yyjson_mut_doc *doc) {
457: 	D_ASSERT(node.descriptions.size() == 1 && node.descriptions[0].type == LogicalTypeId::LIST);
458: 	const auto &desc = node.descriptions[0];
459: 	D_ASSERT(desc.children.size() == 1);
460: 
461: 	const auto arr = yyjson_mut_arr(doc);
462: 	yyjson_mut_arr_append(arr, ConvertStructure(desc.children[0], doc));
463: 	return arr;
464: }
465: 
466: static yyjson_mut_val *ConvertStructureObject(const JSONStructureNode &node, yyjson_mut_doc *doc) {
467: 	D_ASSERT(node.descriptions.size() == 1 && node.descriptions[0].type == LogicalTypeId::STRUCT);
468: 	auto &desc = node.descriptions[0];
469: 	if (desc.children.empty()) {
470: 		// Empty struct - let's do JSON instead
471: 		return yyjson_mut_str(doc, LogicalType::JSON_TYPE_NAME);
472: 	}
473: 
474: 	const auto obj = yyjson_mut_obj(doc);
475: 	for (auto &child : desc.children) {
476: 		D_ASSERT(child.key);
477: 		yyjson_mut_obj_add(obj, yyjson_mut_strn(doc, child.key->c_str(), child.key->length()),
478: 		                   ConvertStructure(child, doc));
479: 	}
480: 	return obj;
481: }
482: 
483: static yyjson_mut_val *ConvertStructure(const JSONStructureNode &node, yyjson_mut_doc *doc) {
484: 	if (node.descriptions.empty()) {
485: 		return yyjson_mut_str(doc, JSONCommon::TYPE_STRING_NULL);
486: 	}
487: 	if (node.descriptions.size() != 1) { // Inconsistent types, so we resort to JSON
488: 		return yyjson_mut_str(doc, LogicalType::JSON_TYPE_NAME);
489: 	}
490: 	auto &desc = node.descriptions[0];
491: 	D_ASSERT(desc.type != LogicalTypeId::INVALID);
492: 	switch (desc.type) {
493: 	case LogicalTypeId::LIST:
494: 		return ConvertStructureArray(node, doc);
495: 	case LogicalTypeId::STRUCT:
496: 		return ConvertStructureObject(node, doc);
497: 	default:
498: 		return yyjson_mut_str(doc, EnumUtil::ToChars(desc.type));
499: 	}
500: }
501: 
502: static string_t JSONStructureFunction(yyjson_val *val, yyjson_alc *alc, Vector &, ValidityMask &, idx_t) {
503: 	return JSONCommon::WriteVal<yyjson_mut_val>(
504: 	    ConvertStructure(ExtractStructureInternal(val, true), yyjson_mut_doc_new(alc)), alc);
505: }
506: 
507: static void StructureFunction(DataChunk &args, ExpressionState &state, Vector &result) {
508: 	JSONExecutors::UnaryExecute<string_t>(args, state, result, JSONStructureFunction);
509: }
510: 
511: static void GetStructureFunctionInternal(ScalarFunctionSet &set, const LogicalType &input_type) {
512: 	set.AddFunction(ScalarFunction({input_type}, LogicalType::JSON(), StructureFunction, nullptr, nullptr, nullptr,
513: 	                               JSONFunctionLocalState::Init));
514: }
515: 
516: ScalarFunctionSet JSONFunctions::GetStructureFunction() {
517: 	ScalarFunctionSet set("json_structure");
518: 	GetStructureFunctionInternal(set, LogicalType::VARCHAR);
519: 	GetStructureFunctionInternal(set, LogicalType::JSON());
520: 	return set;
521: }
522: 
523: static LogicalType StructureToTypeArray(ClientContext &context, const JSONStructureNode &node, const idx_t max_depth,
524:                                         const double field_appearance_threshold, const idx_t map_inference_threshold,
525:                                         const idx_t depth, const LogicalType &null_type) {
526: 	D_ASSERT(node.descriptions.size() == 1 && node.descriptions[0].type == LogicalTypeId::LIST);
527: 	const auto &desc = node.descriptions[0];
528: 	D_ASSERT(desc.children.size() == 1);
529: 
530: 	return LogicalType::LIST(JSONStructure::StructureToType(context, desc.children[0], max_depth,
531: 	                                                        field_appearance_threshold, map_inference_threshold,
532: 	                                                        depth + 1, null_type));
533: }
534: 
535: static void MergeNodes(JSONStructureNode &merged, const JSONStructureNode &node);
536: 
537: static void MergeNodeArray(JSONStructureNode &merged, const JSONStructureDescription &child_desc) {
538: 	D_ASSERT(child_desc.type == LogicalTypeId::LIST);
539: 	auto &merged_desc = merged.GetOrCreateDescription(LogicalTypeId::LIST);
540: 	auto &merged_child = merged_desc.GetOrCreateChild();
541: 	for (auto &list_child : child_desc.children) {
542: 		MergeNodes(merged_child, list_child);
543: 	}
544: }
545: 
546: static void MergeNodeObject(JSONStructureNode &merged, const JSONStructureDescription &child_desc) {
547: 	D_ASSERT(child_desc.type == LogicalTypeId::STRUCT);
548: 	auto &merged_desc = merged.GetOrCreateDescription(LogicalTypeId::STRUCT);
549: 	for (auto &struct_child : child_desc.children) {
550: 		const auto &struct_child_key = *struct_child.key;
551: 		auto &merged_child = merged_desc.GetOrCreateChild(struct_child_key.c_str(), struct_child_key.length());
552: 		MergeNodes(merged_child, struct_child);
553: 	}
554: }
555: 
556: static void MergeNodeVal(JSONStructureNode &merged, const JSONStructureDescription &child_desc,
557:                          const bool node_initialized) {
558: 	D_ASSERT(child_desc.type != LogicalTypeId::LIST && child_desc.type != LogicalTypeId::STRUCT);
559: 	auto &merged_desc = merged.GetOrCreateDescription(child_desc.type);
560: 	if (merged_desc.type != LogicalTypeId::VARCHAR || !node_initialized || merged.descriptions.size() != 1) {
561: 		return;
562: 	}
563: 	if (!merged.initialized) {
564: 		merged_desc.candidate_types = child_desc.candidate_types;
565: 	} else if (merged_desc.candidate_types.empty() != child_desc.candidate_types.empty() // both empty or neither empty
566: 	           || (!merged_desc.candidate_types.empty() &&
567: 	               merged_desc.candidate_types.back() != child_desc.candidate_types.back())) { // non-empty: check type
568: 		merged_desc.candidate_types.clear(); // Not the same, default to VARCHAR
569: 	}
570: 
571: 	merged.initialized = true;
572: }
573: 
574: static void MergeNodes(JSONStructureNode &merged, const JSONStructureNode &node) {
575: 	merged.count += node.count;
576: 	merged.null_count += node.null_count;
577: 	for (const auto &child_desc : node.descriptions) {
578: 		switch (child_desc.type) {
579: 		case LogicalTypeId::LIST:
580: 			MergeNodeArray(merged, child_desc);
581: 			break;
582: 		case LogicalTypeId::STRUCT:
583: 			MergeNodeObject(merged, child_desc);
584: 			break;
585: 		default:
586: 			MergeNodeVal(merged, child_desc, node.initialized);
587: 			break;
588: 		}
589: 	}
590: }
591: 
592: static double CalculateTypeSimilarity(const LogicalType &merged, const LogicalType &type, idx_t max_depth, idx_t depth);
593: 
594: static double CalculateMapAndStructSimilarity(const LogicalType &map_type, const LogicalType &struct_type,
595:                                               const bool swapped, const idx_t max_depth, const idx_t depth) {
596: 	const auto &map_value_type = MapType::ValueType(map_type);
597: 	const auto &struct_child_types = StructType::GetChildTypes(struct_type);
598: 	double total_similarity = 0;
599: 	for (const auto &struct_child_type : struct_child_types) {
600: 		const auto similarity =
601: 		    swapped ? CalculateTypeSimilarity(struct_child_type.second, map_value_type, max_depth, depth + 1)
602: 		            : CalculateTypeSimilarity(map_value_type, struct_child_type.second, max_depth, depth + 1);
603: 		if (similarity < 0) {
604: 			return similarity;
605: 		}
606: 		total_similarity += similarity;
607: 	}
608: 	return total_similarity / static_cast<double>(struct_child_types.size());
609: }
610: 
611: static double CalculateTypeSimilarity(const LogicalType &merged, const LogicalType &type, const idx_t max_depth,
612:                                       const idx_t depth) {
613: 	if (depth >= max_depth || merged.id() == LogicalTypeId::SQLNULL || type.id() == LogicalTypeId::SQLNULL) {
614: 		return 1;
615: 	}
616: 	if (merged.IsJSONType()) {
617: 		// Incompatible types
618: 		return -1;
619: 	}
620: 	if (type.IsJSONType() || merged == type) {
621: 		return 1;
622: 	}
623: 
624: 	switch (merged.id()) {
625: 	case LogicalTypeId::STRUCT: {
626: 		if (type.id() == LogicalTypeId::MAP) {
627: 			// This can happen for empty structs/maps ("{}"), or in rare cases where an inconsistent struct becomes
628: 			// consistent when merged, but does not have enough children to be considered a map.
629: 			return CalculateMapAndStructSimilarity(type, merged, true, max_depth, depth);
630: 		}
631: 
632: 		// Only structs can be merged into a struct
633: 		D_ASSERT(type.id() == LogicalTypeId::STRUCT);
634: 		const auto &merged_child_types = StructType::GetChildTypes(merged);
635: 		const auto &type_child_types = StructType::GetChildTypes(type);
636: 
637: 		unordered_map<string, const LogicalType &> merged_child_types_map;
638: 		for (const auto &merged_child : merged_child_types) {
639: 			merged_child_types_map.emplace(merged_child.first, merged_child.second);
640: 		}
641: 
642: 		double total_similarity = 0;
643: 		for (const auto &type_child_type : type_child_types) {
644: 			const auto it = merged_child_types_map.find(type_child_type.first);
645: 			if (it == merged_child_types_map.end()) {
646: 				return -1;
647: 			}
648: 			const auto similarity = CalculateTypeSimilarity(it->second, type_child_type.second, max_depth, depth + 1);
649: 			if (similarity < 0) {
650: 				return similarity;
651: 			}
652: 			total_similarity += similarity;
653: 		}
654: 		return total_similarity / static_cast<double>(merged_child_types.size());
655: 	}
656: 	case LogicalTypeId::MAP: {
657: 		if (type.id() == LogicalTypeId::MAP) {
658: 			return CalculateTypeSimilarity(MapType::ValueType(merged), MapType::ValueType(type), max_depth, depth + 1);
659: 		}
660: 
661: 		// Only maps and structs can be merged into a map
662: 		D_ASSERT(type.id() == LogicalTypeId::STRUCT);
663: 		return CalculateMapAndStructSimilarity(merged, type, false, max_depth, depth);
664: 	}
665: 	case LogicalTypeId::LIST: {
666: 		// Only lists can be merged into a list
667: 		D_ASSERT(type.id() == LogicalTypeId::LIST);
668: 		const auto &merged_child_type = ListType::GetChildType(merged);
669: 		const auto &type_child_type = ListType::GetChildType(type);
670: 		return CalculateTypeSimilarity(merged_child_type, type_child_type, max_depth, depth + 1);
671: 	}
672: 	default:
673: 		// This is only reachable if type has been inferred using candidate_types, but candidate_types were not
674: 		// consistent among all map values
675: 		return 1;
676: 	}
677: }
678: 
679: static bool IsStructureInconsistent(const JSONStructureDescription &desc, const idx_t sample_count,
680:                                     const idx_t null_count, const double field_appearance_threshold) {
681: 	D_ASSERT(sample_count > null_count);
682: 	double total_child_counts = 0;
683: 	for (const auto &child : desc.children) {
684: 		total_child_counts += static_cast<double>(child.count) / static_cast<double>(sample_count - null_count);
685: 	}
686: 	const auto avg_occurrence = total_child_counts / static_cast<double>(desc.children.size());
687: 	return avg_occurrence < field_appearance_threshold;
688: }
689: 
690: static LogicalType GetMergedType(ClientContext &context, const JSONStructureNode &node, const idx_t max_depth,
691:                                  const double field_appearance_threshold, const idx_t map_inference_threshold,
692:                                  const idx_t depth, const LogicalType &null_type) {
693: 	D_ASSERT(node.descriptions.size() == 1);
694: 	auto &desc = node.descriptions[0];
695: 	JSONStructureNode merged;
696: 	for (const auto &child : desc.children) {
697: 		MergeNodes(merged, child);
698: 	}
699: 	return JSONStructure::StructureToType(context, merged, max_depth, field_appearance_threshold,
700: 	                                      map_inference_threshold, depth + 1, null_type);
701: }
702: 
703: static LogicalType StructureToTypeObject(ClientContext &context, const JSONStructureNode &node, const idx_t max_depth,
704:                                          const double field_appearance_threshold, const idx_t map_inference_threshold,
705:                                          const idx_t depth, const LogicalType &null_type) {
706: 	D_ASSERT(node.descriptions.size() == 1 && node.descriptions[0].type == LogicalTypeId::STRUCT);
707: 	auto &desc = node.descriptions[0];
708: 
709: 	if (desc.children.empty()) {
710: 		if (map_inference_threshold != DConstants::INVALID_INDEX) {
711: 			// Empty struct - let's do MAP of JSON instead
712: 			return LogicalType::MAP(LogicalType::VARCHAR, null_type);
713: 		} else {
714: 			return LogicalType::JSON();
715: 		}
716: 	}
717: 
718: 	// If it's an inconsistent object we also just do MAP with the best-possible, recursively-merged value type
719: 	if (map_inference_threshold != DConstants::INVALID_INDEX &&
720: 	    IsStructureInconsistent(desc, node.count, node.null_count, field_appearance_threshold)) {
721: 		return LogicalType::MAP(LogicalType::VARCHAR,
722: 		                        GetMergedType(context, node, max_depth, field_appearance_threshold,
723: 		                                      map_inference_threshold, depth + 1, null_type));
724: 	}
725: 
726: 	// We have a consistent object
727: 	child_list_t<LogicalType> child_types;
728: 	child_types.reserve(desc.children.size());
729: 	for (auto &child : desc.children) {
730: 		D_ASSERT(child.key);
731: 		child_types.emplace_back(*child.key,
732: 		                         JSONStructure::StructureToType(context, child, max_depth, field_appearance_threshold,
733: 		                                                        map_inference_threshold, depth + 1, null_type));
734: 	}
735: 
736: 	// If we have many children and all children have similar-enough types we infer map
737: 	if (desc.children.size() >= map_inference_threshold) {
738: 		LogicalType map_value_type = GetMergedType(context, node, max_depth, field_appearance_threshold,
739: 		                                           map_inference_threshold, depth + 1, LogicalTypeId::SQLNULL);
740: 
741: 		double total_similarity = 0;
742: 		for (const auto &child_type : child_types) {
743: 			const auto similarity = CalculateTypeSimilarity(map_value_type, child_type.second, max_depth, depth + 1);
744: 			if (similarity < 0) {
745: 				total_similarity = similarity;
746: 				break;
747: 			}
748: 			total_similarity += similarity;
749: 		}
750: 		const auto avg_similarity = total_similarity / static_cast<double>(child_types.size());
751: 		if (avg_similarity >= 0.8) {
752: 			if (null_type != LogicalTypeId::SQLNULL) {
753: 				map_value_type = GetMergedType(context, node, max_depth, field_appearance_threshold,
754: 				                               map_inference_threshold, depth + 1, null_type);
755: 			}
756: 			return LogicalType::MAP(LogicalType::VARCHAR, map_value_type);
757: 		}
758: 	}
759: 
760: 	return LogicalType::STRUCT(child_types);
761: }
762: 
763: static LogicalType StructureToTypeString(const JSONStructureNode &node) {
764: 	D_ASSERT(node.descriptions.size() == 1 && node.descriptions[0].type == LogicalTypeId::VARCHAR);
765: 	auto &desc = node.descriptions[0];
766: 	if (desc.candidate_types.empty()) {
767: 		return LogicalTypeId::VARCHAR;
768: 	}
769: 	return desc.candidate_types.back();
770: }
771: 
772: LogicalType JSONStructure::StructureToType(ClientContext &context, const JSONStructureNode &node, const idx_t max_depth,
773:                                            const double field_appearance_threshold, const idx_t map_inference_threshold,
774:                                            const idx_t depth, const LogicalType &null_type) {
775: 	if (depth >= max_depth) {
776: 		return LogicalType::JSON();
777: 	}
778: 	if (node.descriptions.empty()) {
779: 		return null_type;
780: 	}
781: 	if (node.descriptions.size() != 1) { // Inconsistent types, so we resort to JSON
782: 		return LogicalType::JSON();
783: 	}
784: 	auto &desc = node.descriptions[0];
785: 	D_ASSERT(desc.type != LogicalTypeId::INVALID);
786: 	switch (desc.type) {
787: 	case LogicalTypeId::LIST:
788: 		return StructureToTypeArray(context, node, max_depth, field_appearance_threshold, map_inference_threshold,
789: 		                            depth, null_type);
790: 	case LogicalTypeId::STRUCT:
791: 		return StructureToTypeObject(context, node, max_depth, field_appearance_threshold, map_inference_threshold,
792: 		                             depth, null_type);
793: 	case LogicalTypeId::VARCHAR:
794: 		return StructureToTypeString(node);
795: 	case LogicalTypeId::UBIGINT:
796: 		return LogicalTypeId::BIGINT; // We prefer not to return UBIGINT in our type auto-detection
797: 	case LogicalTypeId::SQLNULL:
798: 		return null_type;
799: 	default:
800: 		return desc.type;
801: 	}
802: }
803: 
804: } // namespace duckdb
[end of extension/json/json_functions/json_structure.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: