You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
Unexpected result for SUM() upon overflow
Consider the following statements:
```sql
CREATE TABLE t0(c1 BIGINT);
INSERT INTO t0(c1) VALUES (2);
INSERT INTO t0(c1) VALUES (9223372036854775807);
SELECT SUM(t0.c1) FROM t0; -- expected: {9223372036854776000}, actual: {-9223372036854775807}
```
The overflow here might be unexpected. DBMS like Postgres and MySQL seem to return a floating-point result, avoiding the wraparound. SQLite outputs an integer overflow error. Interestingly, an exact overflow results in `NULL` being computed for DuckDB, which might also be an expected behavior for an overflow:
```sql
CREATE TABLE t0(c1 BIGINT);
INSERT INTO t0(c1) VALUES (1);
INSERT INTO t0(c1) VALUES (9223372036854775807);
SELECT SUM(t0.c1) FROM t0; -- NULL
```
Whether this is a bug is less clear than other cases. Feel free to close this issue, if this is the expected behavior. I found this based on commit b4aada80e3b0614029ec957de01cac0a14d8a785.
RIGHT JOIN results in Assertion `filter->expressions.size() == 1' failed.
Consider the following statements:
```sql
CREATE TABLE t0(c0 INT);
CREATE TABLE t1(c0 INT);
SELECT * FROM t0 RIGHT JOIN t1 ON 0 WHERE t0.c0 OR t1.c0 BETWEEN t0.c0 AND 1; -- Assertion `filter->expressions.size() == 1' failed.
```
When using the debug build, the query results in the following assertion failure:
```
/projects/duckdb/src/optimizer/pushdown/pushdown_left_join.cpp:42: bool FilterRemovesNull(duckdb::ExpressionRewriter&, duckdb::Expression*, std::unordered_set<long unsigned int>&): Assertion `filter->expressions.size() == 1' failed.
```
I found this based on commit 0560e8104008670262d630aefffb640e963576f0.

</issue>
<code>
[start of README.md]
1: <img align="left" src="logo/duckdb-logo.png" height="120">
2: 
3: # DuckDB, the SQLite for Analytics
4: [![Travis](https://api.travis-ci.org/cwida/duckdb.svg?branch=master)](https://travis-ci.org/cwida/duckdb)
5: [![CodeFactor](https://www.codefactor.io/repository/github/cwida/duckdb/badge)](https://www.codefactor.io/repository/github/cwida/duckdb)
6: [![Coverage Status](https://coveralls.io/repos/github/cwida/duckdb/badge.svg?branch=master)](https://coveralls.io/github/cwida/duckdb?branch=master)
7: 
8: <br>
9: 
10: 
11: # Requirements
12: DuckDB requires [CMake](https://cmake.org) to be installed and a `C++11` compliant compiler. GCC 4.9 and newer, Clang 3.9 and newer and VisualStudio 2017 are tested on each revision.
13: 
14: ## Compiling
15: Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You may run `make unit` and `make allunit` to verify that your version works properly after making changes.
16: 
17: # Usage
18: A command line utility based on `sqlite3` can be found in either `build/release/duckdb_cli` (release, the default) or `build/debug/duckdb_cli` (debug).
19: 
20: # Embedding
21: As DuckDB is an embedded database, there is no database server to launch or client to connect to a running server. However, the database server can be embedded directly into an application using the C or C++ bindings. The main build process creates the shared library `build/release/src/libduckdb.[so|dylib|dll]` that can be linked against. A static library is built as well.
22: 
23: For examples on how to embed DuckDB into your application, see the [examples](https://github.com/cwida/duckdb/tree/master/examples) folder.
24: 
25: ## Benchmarks
26: After compiling, benchmarks can be executed from the root directory by executing `./build/release/benchmark/benchmark_runner`.
27: 
28: ## Standing on the Shoulders of Giants
29: DuckDB is implemented in C++ 11, should compile with GCC and clang, uses CMake to build and [Catch2](https://github.com/catchorg/Catch2) for testing. DuckDB uses some components from various Open-Source databases and draws inspiration from scientific publications. Here is an overview:
30: 
31: * Parser: We use the PostgreSQL parser that was [repackaged as a stand-alone library](https://github.com/lfittl/libpg_query). The translation to our own parse tree is inspired by [Peloton](https://pelotondb.io).
32: * Shell: We have adapted the [SQLite shell](https://sqlite.org/cli.html) to work with DuckDB.
33: * Tests: We use the [SQL Logic Tests from SQLite](https://www.sqlite.org/sqllogictest/doc/trunk/about.wiki) to test DuckDB.
34: * Query fuzzing: We use [SQLsmith](https://github.com/anse1/sqlsmith) to generate random queries for additional testing.
35: * Date Math: We use the date math component from [MonetDB](https://www.monetdb.org).
36: * SQL Window Functions: DuckDB's window functions implementation uses Segment Tree Aggregation as described in the paper "Efficient Processing of Window Functions in Analytical SQL Queries" by Viktor Leis, Kan Kundhikanjana, Alfons Kemper and Thomas Neumann.
37: * Execution engine: The vectorized execution engine is inspired by the paper "MonetDB/X100: Hyper-Pipelining Query Execution" by Peter Boncz, Marcin Zukowski and Niels Nes.
38: * Optimizer: DuckDB's optimizer draws inspiration from the papers "Dynamic programming strikes back" by Guido Moerkotte and Thomas Neumman as well as "Unnesting Arbitrary Queries" by Thomas Neumann and Alfons Kemper.
39: * Concurrency control: Our MVCC implementation is inspired by the paper "Fast Serializable Multi-Version Concurrency Control for Main-Memory Database Systems" by Thomas Neumann, Tobias Mühlbauer and Alfons Kemper.
40: * Regular Expression: DuckDB uses Google's [RE2](https://github.com/google/re2) regular expression engine.
41: 
42: ## Other pages
43: * [Continuous Benchmarking (CB™)](https://www.duckdb.org/benchmarks/index.html), runs TPC-H, TPC-DS and some microbenchmarks on every commit
[end of README.md]
[start of src/common/types/vector.cpp]
1: #include <cstring> // strlen() on Solaris
2: 
3: #include "duckdb/common/types/vector.hpp"
4: 
5: #include "duckdb/common/assert.hpp"
6: #include "duckdb/common/exception.hpp"
7: #include "duckdb/common/printer.hpp"
8: #include "duckdb/common/vector_operations/vector_operations.hpp"
9: #include "duckdb/common/types/chunk_collection.hpp"
10: #include "duckdb/common/serializer.hpp"
11: #include "duckdb/common/types/null_value.hpp"
12: 
13: using namespace std;
14: 
15: namespace duckdb {
16: 
17: Vector::Vector(TypeId type, bool create_data, bool zero_data)
18:     : vector_type(VectorType::FLAT_VECTOR), type(type), data(nullptr) {
19: 	if (create_data) {
20: 		Initialize(type, zero_data);
21: 	}
22: }
23: 
24: Vector::Vector(TypeId type) : Vector(type, true, false) {
25: }
26: 
27: Vector::Vector(TypeId type, data_ptr_t dataptr) : vector_type(VectorType::FLAT_VECTOR), type(type), data(dataptr) {
28: 	if (dataptr && type == TypeId::INVALID) {
29: 		throw InvalidTypeException(type, "Cannot create a vector of type INVALID!");
30: 	}
31: }
32: 
33: Vector::Vector(Value value) : vector_type(VectorType::CONSTANT_VECTOR) {
34: 	Reference(value);
35: }
36: 
37: Vector::Vector() : vector_type(VectorType::FLAT_VECTOR), type(TypeId::INVALID), data(nullptr) {
38: }
39: 
40: Vector::Vector(Vector &&other) noexcept
41:     : vector_type(other.vector_type), type(other.type), data(other.data), nullmask(other.nullmask),
42:       buffer(move(other.buffer)), auxiliary(move(other.auxiliary)) {
43: }
44: 
45: void Vector::Reference(Value &value) {
46: 	vector_type = VectorType::CONSTANT_VECTOR;
47: 	type = value.type;
48: 	buffer = VectorBuffer::CreateConstantVector(type);
49: 	auxiliary.reset();
50: 	data = buffer->GetData();
51: 	SetValue(0, value);
52: }
53: 
54: void Vector::Reference(Vector &other) {
55: 	vector_type = other.vector_type;
56: 	buffer = other.buffer;
57: 	auxiliary = other.auxiliary;
58: 	data = other.data;
59: 	type = other.type;
60: 	nullmask = other.nullmask;
61: }
62: 
63: void Vector::Slice(Vector &other, idx_t offset) {
64: 	if (other.vector_type == VectorType::CONSTANT_VECTOR) {
65: 		Reference(other);
66: 		return;
67: 	}
68: 	assert(other.vector_type == VectorType::FLAT_VECTOR);
69: 
70: 	// create a reference to the other vector
71: 	Reference(other);
72: 	if (offset > 0) {
73: 		data = data + GetTypeIdSize(type) * offset;
74: 		nullmask <<= offset;
75: 	}
76: }
77: 
78: void Vector::Slice(Vector &other, const SelectionVector &sel, idx_t count) {
79: 	Reference(other);
80: 	Slice(sel, count);
81: }
82: 
83: void Vector::Slice(const SelectionVector &sel, idx_t count) {
84: 	if (vector_type == VectorType::CONSTANT_VECTOR) {
85: 		// dictionary on a constant is just a constant
86: 		return;
87: 	}
88: 	if (vector_type == VectorType::DICTIONARY_VECTOR) {
89: 		// already a dictionary, slice the current dictionary
90: 		auto &current_sel = DictionaryVector::SelVector(*this);
91: 		auto sliced_dictionary = current_sel.Slice(sel, count);
92: 		buffer = make_unique<DictionaryBuffer>(move(sliced_dictionary));
93: 		return;
94: 	}
95: 	auto child_ref = make_buffer<VectorChildBuffer>();
96: 	child_ref->data.Reference(*this);
97: 
98: 	auto dict_buffer = make_unique<DictionaryBuffer>(sel);
99: 	buffer = move(dict_buffer);
100: 	auxiliary = move(child_ref);
101: 	vector_type = VectorType::DICTIONARY_VECTOR;
102: }
103: 
104: void Vector::Slice(const SelectionVector &sel, idx_t count, sel_cache_t &cache) {
105: 	if (vector_type == VectorType::DICTIONARY_VECTOR) {
106: 		// dictionary vector: need to merge dictionaries
107: 		// check if we have a cached entry
108: 		auto &current_sel = DictionaryVector::SelVector(*this);
109: 		auto target_data = current_sel.data();
110: 		auto entry = cache.find(target_data);
111: 		if (entry != cache.end()) {
112: 			// cached entry exists: use that
113: 			this->buffer = entry->second;
114: 		} else {
115: 			Slice(sel, count);
116: 			cache[target_data] = this->buffer;
117: 		}
118: 	} else {
119: 		Slice(sel, count);
120: 	}
121: }
122: 
123: void Vector::Initialize(TypeId new_type, bool zero_data) {
124: 	if (new_type != TypeId::INVALID) {
125: 		type = new_type;
126: 	}
127: 	vector_type = VectorType::FLAT_VECTOR;
128: 	buffer.reset();
129: 	auxiliary.reset();
130: 	nullmask.reset();
131: 	if (GetTypeIdSize(type) > 0) {
132: 		buffer = VectorBuffer::CreateStandardVector(type);
133: 		data = buffer->GetData();
134: 		if (zero_data) {
135: 			memset(data, 0, STANDARD_VECTOR_SIZE * GetTypeIdSize(type));
136: 		}
137: 	}
138: }
139: 
140: void Vector::SetValue(idx_t index, Value val) {
141: 	if (vector_type == VectorType::DICTIONARY_VECTOR) {
142: 		// dictionary: apply dictionary and forward to child
143: 		auto &sel_vector = DictionaryVector::SelVector(*this);
144: 		auto &child = DictionaryVector::Child(*this);
145: 		return child.SetValue(sel_vector.get_index(index), move(val));
146: 	}
147: 	Value newVal = val.CastAs(type);
148: 
149: 	nullmask[index] = newVal.is_null;
150: 	if (newVal.is_null) {
151: 		return;
152: 	}
153: 	switch (type) {
154: 	case TypeId::BOOL:
155: 		((bool *)data)[index] = newVal.value_.boolean;
156: 		break;
157: 	case TypeId::INT8:
158: 		((int8_t *)data)[index] = newVal.value_.tinyint;
159: 		break;
160: 	case TypeId::INT16:
161: 		((int16_t *)data)[index] = newVal.value_.smallint;
162: 		break;
163: 	case TypeId::INT32:
164: 		((int32_t *)data)[index] = newVal.value_.integer;
165: 		break;
166: 	case TypeId::INT64:
167: 		((int64_t *)data)[index] = newVal.value_.bigint;
168: 		break;
169: 	case TypeId::FLOAT:
170: 		((float *)data)[index] = newVal.value_.float_;
171: 		break;
172: 	case TypeId::DOUBLE:
173: 		((double *)data)[index] = newVal.value_.double_;
174: 		break;
175: 	case TypeId::POINTER:
176: 		((uintptr_t *)data)[index] = newVal.value_.pointer;
177: 		break;
178: 	case TypeId::VARCHAR: {
179: 		((string_t *)data)[index] = StringVector::AddString(*this, newVal.str_value);
180: 		break;
181: 	}
182: 	case TypeId::STRUCT: {
183: 		if (!auxiliary || StructVector::GetEntries(*this).size() == 0) {
184: 			for (size_t i = 0; i < val.struct_value.size(); i++) {
185: 				auto &struct_child = val.struct_value[i];
186: 				auto cv = make_unique<Vector>(struct_child.second.type);
187: 				cv->vector_type = vector_type;
188: 				StructVector::AddEntry(*this, struct_child.first, move(cv));
189: 			}
190: 		}
191: 
192: 		auto &children = StructVector::GetEntries(*this);
193: 		assert(children.size() == val.struct_value.size());
194: 
195: 		for (size_t i = 0; i < val.struct_value.size(); i++) {
196: 			auto &struct_child = val.struct_value[i];
197: 			assert(vector_type == VectorType::CONSTANT_VECTOR || vector_type == VectorType::FLAT_VECTOR);
198: 			auto &vec_child = children[i];
199: 			assert(vec_child.first == struct_child.first);
200: 			vec_child.second->SetValue(index, struct_child.second);
201: 		}
202: 	} break;
203: 
204: 	case TypeId::LIST: {
205: 		if (!auxiliary) {
206: 			auto cc = make_unique<ChunkCollection>();
207: 			ListVector::SetEntry(*this, move(cc));
208: 		}
209: 		auto &child_cc = ListVector::GetEntry(*this);
210: 		// TODO optimization: in-place update if fits
211: 		auto offset = child_cc.count;
212: 		if (val.list_value.size() > 0) {
213: 			idx_t append_idx = 0;
214: 			while (append_idx < val.list_value.size()) {
215: 				idx_t this_append_len = min((idx_t)STANDARD_VECTOR_SIZE, val.list_value.size() - append_idx);
216: 
217: 				DataChunk child_append_chunk;
218: 				child_append_chunk.SetCardinality(this_append_len);
219: 				vector<TypeId> types;
220: 				types.push_back(val.list_value[0].type);
221: 				child_append_chunk.Initialize(types);
222: 				for (idx_t i = 0; i < this_append_len; i++) {
223: 					child_append_chunk.data[0].SetValue(i, val.list_value[i + append_idx]);
224: 				}
225: 				child_cc.Append(child_append_chunk);
226: 				append_idx += this_append_len;
227: 			}
228: 		}
229: 		// now set the pointer
230: 		auto &entry = ((list_entry_t *)data)[index];
231: 		entry.length = val.list_value.size();
232: 		entry.offset = offset;
233: 	} break;
234: 	default:
235: 		throw NotImplementedException("Unimplemented type for Vector::SetValue");
236: 	}
237: }
238: 
239: Value Vector::GetValue(idx_t index) const {
240: 	if (vector_type == VectorType::CONSTANT_VECTOR) {
241: 		index = 0;
242: 	} else if (vector_type == VectorType::DICTIONARY_VECTOR) {
243: 		// dictionary: apply dictionary and forward to child
244: 		auto &sel_vector = DictionaryVector::SelVector(*this);
245: 		auto &child = DictionaryVector::Child(*this);
246: 		return child.GetValue(sel_vector.get_index(index));
247: 	} else {
248: 		assert(vector_type == VectorType::FLAT_VECTOR);
249: 	}
250: 
251: 	if (nullmask[index]) {
252: 		return Value(type);
253: 	}
254: 	switch (type) {
255: 	case TypeId::BOOL:
256: 		return Value::BOOLEAN(((bool *)data)[index]);
257: 	case TypeId::INT8:
258: 		return Value::TINYINT(((int8_t *)data)[index]);
259: 	case TypeId::INT16:
260: 		return Value::SMALLINT(((int16_t *)data)[index]);
261: 	case TypeId::INT32:
262: 		return Value::INTEGER(((int32_t *)data)[index]);
263: 	case TypeId::INT64:
264: 		return Value::BIGINT(((int64_t *)data)[index]);
265: 	case TypeId::HASH:
266: 		return Value::HASH(((hash_t *)data)[index]);
267: 	case TypeId::POINTER:
268: 		return Value::POINTER(((uintptr_t *)data)[index]);
269: 	case TypeId::FLOAT:
270: 		return Value::FLOAT(((float *)data)[index]);
271: 	case TypeId::DOUBLE:
272: 		return Value::DOUBLE(((double *)data)[index]);
273: 	case TypeId::VARCHAR: {
274: 		auto str = ((string_t *)data)[index];
275: 		return Value(str.GetString());
276: 	}
277: 	case TypeId::STRUCT: {
278: 		Value ret(TypeId::STRUCT);
279: 		ret.is_null = false;
280: 		// we can derive the value schema from the vector schema
281: 		for (auto &struct_child : StructVector::GetEntries(*this)) {
282: 			ret.struct_value.push_back(pair<string, Value>(struct_child.first, struct_child.second->GetValue(index)));
283: 		}
284: 		return ret;
285: 	}
286: 	case TypeId::LIST: {
287: 		Value ret(TypeId::LIST);
288: 		ret.is_null = false;
289: 		auto offlen = ((list_entry_t *)data)[index];
290: 		auto &child_cc = ListVector::GetEntry(*this);
291: 		for (idx_t i = offlen.offset; i < offlen.offset + offlen.length; i++) {
292: 			ret.list_value.push_back(child_cc.GetValue(0, i));
293: 		}
294: 		return ret;
295: 	}
296: 	default:
297: 		throw NotImplementedException("Unimplemented type for value access");
298: 	}
299: }
300: 
301: string VectorTypeToString(VectorType type) {
302: 	switch (type) {
303: 	case VectorType::FLAT_VECTOR:
304: 		return "FLAT";
305: 	case VectorType::SEQUENCE_VECTOR:
306: 		return "SEQUENCE";
307: 	case VectorType::DICTIONARY_VECTOR:
308: 		return "DICTIONARY";
309: 	case VectorType::CONSTANT_VECTOR:
310: 		return "CONSTANT";
311: 	default:
312: 		return "UNKNOWN";
313: 	}
314: }
315: 
316: string Vector::ToString(idx_t count) const {
317: 	string retval = VectorTypeToString(vector_type) + " " + TypeIdToString(type) + ": " + to_string(count) + " = [ ";
318: 	switch (vector_type) {
319: 	case VectorType::FLAT_VECTOR:
320: 	case VectorType::DICTIONARY_VECTOR:
321: 		for (idx_t i = 0; i < count; i++) {
322: 			retval += GetValue(i).ToString() + (i == count - 1 ? "" : ", ");
323: 		}
324: 		break;
325: 	case VectorType::CONSTANT_VECTOR:
326: 		retval += GetValue(0).ToString();
327: 		break;
328: 	case VectorType::SEQUENCE_VECTOR: {
329: 		int64_t start, increment;
330: 		SequenceVector::GetSequence(*this, start, increment);
331: 		for (idx_t i = 0; i < count; i++) {
332: 			retval += to_string(start + increment * i) + (i == count - 1 ? "" : ", ");
333: 		}
334: 		break;
335: 	}
336: 	default:
337: 		retval += "UNKNOWN VECTOR TYPE";
338: 		break;
339: 	}
340: 	retval += "]";
341: 	return retval;
342: }
343: 
344: void Vector::Print(idx_t count) {
345: 	Printer::Print(ToString(count));
346: }
347: 
348: string Vector::ToString() const {
349: 	string retval = VectorTypeToString(vector_type) + " " + TypeIdToString(type) + ": (UNKNOWN COUNT) [ ";
350: 	switch (vector_type) {
351: 	case VectorType::FLAT_VECTOR:
352: 	case VectorType::DICTIONARY_VECTOR:
353: 		break;
354: 	case VectorType::CONSTANT_VECTOR:
355: 		retval += GetValue(0).ToString();
356: 		break;
357: 	case VectorType::SEQUENCE_VECTOR: {
358: 		break;
359: 	}
360: 	default:
361: 		retval += "UNKNOWN VECTOR TYPE";
362: 		break;
363: 	}
364: 	retval += "]";
365: 	return retval;
366: }
367: 
368: void Vector::Print() {
369: 	Printer::Print(ToString());
370: }
371: 
372: template <class T> static void flatten_constant_vector_loop(data_ptr_t data, data_ptr_t old_data, idx_t count) {
373: 	auto constant = *((T *)old_data);
374: 	auto output = (T *)data;
375: 	for (idx_t i = 0; i < count; i++) {
376: 		output[i] = constant;
377: 	}
378: }
379: 
380: void Vector::Normalify(idx_t count) {
381: 	switch (vector_type) {
382: 	case VectorType::FLAT_VECTOR:
383: 		// already a flat vector
384: 		break;
385: 	case VectorType::DICTIONARY_VECTOR: {
386: 		// create a new flat vector of this type
387: 		Vector other(type);
388: 		// now copy the data of this vector to the other vector, removing the selection vector in the process
389: 		VectorOperations::Copy(*this, other, count, 0, 0);
390: 		// create a reference to the data in the other vector
391: 		this->Reference(other);
392: 		break;
393: 	}
394: 	case VectorType::CONSTANT_VECTOR: {
395: 		vector_type = VectorType::FLAT_VECTOR;
396: 		// allocate a new buffer for the vector
397: 		auto old_buffer = move(buffer);
398: 		auto old_data = data;
399: 		buffer = VectorBuffer::CreateStandardVector(type);
400: 		data = buffer->GetData();
401: 		if (nullmask[0]) {
402: 			// constant NULL, set nullmask
403: 			nullmask.set();
404: 			return;
405: 		}
406: 		// non-null constant: have to repeat the constant
407: 		switch (type) {
408: 		case TypeId::BOOL:
409: 		case TypeId::INT8:
410: 			flatten_constant_vector_loop<int8_t>(data, old_data, count);
411: 			break;
412: 		case TypeId::INT16:
413: 			flatten_constant_vector_loop<int16_t>(data, old_data, count);
414: 			break;
415: 		case TypeId::INT32:
416: 			flatten_constant_vector_loop<int32_t>(data, old_data, count);
417: 			break;
418: 		case TypeId::INT64:
419: 			flatten_constant_vector_loop<int64_t>(data, old_data, count);
420: 			break;
421: 		case TypeId::FLOAT:
422: 			flatten_constant_vector_loop<float>(data, old_data, count);
423: 			break;
424: 		case TypeId::DOUBLE:
425: 			flatten_constant_vector_loop<double>(data, old_data, count);
426: 			break;
427: 		case TypeId::HASH:
428: 			flatten_constant_vector_loop<hash_t>(data, old_data, count);
429: 			break;
430: 		case TypeId::POINTER:
431: 			flatten_constant_vector_loop<uintptr_t>(data, old_data, count);
432: 			break;
433: 		case TypeId::VARCHAR:
434: 			flatten_constant_vector_loop<string_t>(data, old_data, count);
435: 			break;
436: 		case TypeId::LIST: {
437: 			flatten_constant_vector_loop<list_entry_t>(data, old_data, count);
438: 			break;
439: 		}
440: 		case TypeId::STRUCT: {
441: 			for (auto &child : StructVector::GetEntries(*this)) {
442: 				assert(child.second->vector_type == VectorType::CONSTANT_VECTOR);
443: 				child.second->Normalify(count);
444: 			}
445: 		} break;
446: 		default:
447: 			throw NotImplementedException("Unimplemented type for VectorOperations::Normalify");
448: 		}
449: 		break;
450: 	}
451: 	case VectorType::SEQUENCE_VECTOR: {
452: 		int64_t start, increment;
453: 		SequenceVector::GetSequence(*this, start, increment);
454: 
455: 		vector_type = VectorType::FLAT_VECTOR;
456: 		buffer = VectorBuffer::CreateStandardVector(type);
457: 		data = buffer->GetData();
458: 		VectorOperations::GenerateSequence(*this, count, start, increment);
459: 		break;
460: 	}
461: 	default:
462: 		throw NotImplementedException("FIXME: unimplemented type for normalify");
463: 	}
464: }
465: 
466: void Vector::Normalify(const SelectionVector &sel, idx_t count) {
467: 	switch (vector_type) {
468: 	case VectorType::FLAT_VECTOR:
469: 		// already a flat vector
470: 		break;
471: 	case VectorType::SEQUENCE_VECTOR: {
472: 		int64_t start, increment;
473: 		SequenceVector::GetSequence(*this, start, increment);
474: 
475: 		vector_type = VectorType::FLAT_VECTOR;
476: 		buffer = VectorBuffer::CreateStandardVector(type);
477: 		data = buffer->GetData();
478: 		VectorOperations::GenerateSequence(*this, count, sel, start, increment);
479: 		break;
480: 	}
481: 	default:
482: 		throw NotImplementedException("Unimplemented type for normalify with selection vector");
483: 	}
484: }
485: 
486: void Vector::Orrify(idx_t count, VectorData &data) {
487: 	switch (vector_type) {
488: 	case VectorType::DICTIONARY_VECTOR: {
489: 		auto &sel = DictionaryVector::SelVector(*this);
490: 		auto &child = DictionaryVector::Child(*this);
491: 		child.Normalify(sel, count);
492: 
493: 		data.sel = &sel;
494: 		data.data = FlatVector::GetData(child);
495: 		data.nullmask = &FlatVector::Nullmask(child);
496: 		break;
497: 	}
498: 	case VectorType::CONSTANT_VECTOR:
499: 		data.sel = &ConstantVector::ZeroSelectionVector;
500: 		data.data = ConstantVector::GetData(*this);
501: 		data.nullmask = &nullmask;
502: 		break;
503: 	default:
504: 		Normalify(count);
505: 		data.sel = &FlatVector::IncrementalSelectionVector;
506: 		data.data = FlatVector::GetData(*this);
507: 		data.nullmask = &nullmask;
508: 		break;
509: 	}
510: }
511: 
512: void Vector::Sequence(int64_t start, int64_t increment) {
513: 	vector_type = VectorType::SEQUENCE_VECTOR;
514: 	this->buffer = make_buffer<VectorBuffer>(sizeof(int64_t) * 2);
515: 	auto data = (int64_t *)buffer->GetData();
516: 	data[0] = start;
517: 	data[1] = increment;
518: 	nullmask.reset();
519: 	auxiliary.reset();
520: }
521: 
522: void Vector::Serialize(idx_t count, Serializer &serializer) {
523: 	if (TypeIsConstantSize(type)) {
524: 		// constant size type: simple copy
525: 		idx_t write_size = GetTypeIdSize(type) * count;
526: 		auto ptr = unique_ptr<data_t[]>(new data_t[write_size]);
527: 		VectorOperations::WriteToStorage(*this, count, ptr.get());
528: 		serializer.WriteData(ptr.get(), write_size);
529: 	} else {
530: 		VectorData vdata;
531: 		Orrify(count, vdata);
532: 
533: 		switch (type) {
534: 		case TypeId::VARCHAR: {
535: 			auto strings = (string_t *)vdata.data;
536: 			for (idx_t i = 0; i < count; i++) {
537: 				auto idx = vdata.sel->get_index(i);
538: 				auto source = (*vdata.nullmask)[idx] ? NullValue<const char *>() : strings[idx].GetData();
539: 				serializer.WriteString(source);
540: 			}
541: 			break;
542: 		}
543: 		default:
544: 			throw NotImplementedException("Unimplemented type for Vector::Serialize!");
545: 		}
546: 	}
547: }
548: 
549: void Vector::Deserialize(idx_t count, Deserializer &source) {
550: 	if (TypeIsConstantSize(type)) {
551: 		// constant size type: read fixed amount of data from
552: 		auto column_size = GetTypeIdSize(type) * count;
553: 		auto ptr = unique_ptr<data_t[]>(new data_t[column_size]);
554: 		source.ReadData(ptr.get(), column_size);
555: 
556: 		VectorOperations::ReadFromStorage(ptr.get(), count, *this);
557: 	} else {
558: 		auto strings = FlatVector::GetData<string_t>(*this);
559: 		auto &nullmask = FlatVector::Nullmask(*this);
560: 		for (idx_t i = 0; i < count; i++) {
561: 			// read the strings
562: 			auto str = source.Read<string>();
563: 			// now add the string to the StringHeap of the vector
564: 			// and write the pointer into the vector
565: 			if (IsNullValue<const char *>((const char *)str.c_str())) {
566: 				nullmask[i] = true;
567: 			} else {
568: 				strings[i] = StringVector::AddString(*this, str);
569: 			}
570: 		}
571: 	}
572: }
573: 
574: void Vector::Verify(const SelectionVector &sel, idx_t count) {
575: #ifdef DEBUG
576: 	if (count == 0) {
577: 		return;
578: 	}
579: 	if (vector_type == VectorType::DICTIONARY_VECTOR) {
580: 		auto &child = DictionaryVector::Child(*this);
581: 		auto &dict_sel = DictionaryVector::SelVector(*this);
582: 		for (idx_t i = 0; i < count; i++) {
583: 			auto oidx = sel.get_index(i);
584: 			auto idx = dict_sel.get_index(oidx);
585: 			assert(idx < STANDARD_VECTOR_SIZE);
586: 		}
587: 		// merge the selection vectors and verify the child
588: 		auto new_buffer = dict_sel.Slice(sel, count);
589: 		SelectionVector new_sel(new_buffer);
590: 		child.Verify(new_sel, count);
591: 		return;
592: 	}
593: 	if (type == TypeId::VARCHAR) {
594: 		// we just touch all the strings and let the sanitizer figure out if any
595: 		// of them are deallocated/corrupt
596: 		switch (vector_type) {
597: 		case VectorType::CONSTANT_VECTOR: {
598: 			auto string = ConstantVector::GetData<string_t>(*this);
599: 			if (!ConstantVector::IsNull(*this)) {
600: 				string->Verify();
601: 			}
602: 			break;
603: 		}
604: 		case VectorType::FLAT_VECTOR: {
605: 			auto strings = FlatVector::GetData<string_t>(*this);
606: 			for (idx_t i = 0; i < count; i++) {
607: 				auto oidx = sel.get_index(i);
608: 				if (!nullmask[oidx]) {
609: 					strings[oidx].Verify();
610: 				}
611: 			}
612: 			break;
613: 		}
614: 		default:
615: 			break;
616: 		}
617: 	}
618: 	if (type == TypeId::DOUBLE) {
619: 		// verify that there are no INF or NAN values
620: 		switch (vector_type) {
621: 		case VectorType::CONSTANT_VECTOR: {
622: 			auto dbl = ConstantVector::GetData<double>(*this);
623: 			if (!ConstantVector::IsNull(*this)) {
624: 				assert(Value::DoubleIsValid(*dbl));
625: 			}
626: 			break;
627: 		}
628: 		case VectorType::FLAT_VECTOR: {
629: 			auto doubles = FlatVector::GetData<double>(*this);
630: 			for (idx_t i = 0; i < count; i++) {
631: 				auto oidx = sel.get_index(i);
632: 				if (!nullmask[oidx]) {
633: 					assert(Value::DoubleIsValid(doubles[oidx]));
634: 				}
635: 			}
636: 			break;
637: 		}
638: 		default:
639: 			break;
640: 		}
641: 	}
642: 
643: 	if (type == TypeId::STRUCT) {
644: 		if (vector_type == VectorType::FLAT_VECTOR || vector_type == VectorType::CONSTANT_VECTOR) {
645: 			auto &children = StructVector::GetEntries(*this);
646: 			assert(children.size() > 0);
647: 			for (auto &child : children) {
648: 				child.second->Verify(sel, count);
649: 			}
650: 		}
651: 	}
652: 
653: 	if (type == TypeId::LIST) {
654: 		if (vector_type == VectorType::CONSTANT_VECTOR) {
655: 			if (!ConstantVector::IsNull(*this)) {
656: 				ListVector::GetEntry(*this).Verify();
657: 				auto le = ConstantVector::GetData<list_entry_t>(*this);
658: 				assert(le->offset + le->length <= ListVector::GetEntry(*this).count);
659: 			}
660: 		} else if (vector_type == VectorType::FLAT_VECTOR) {
661: 			if (ListVector::HasEntry(*this)) {
662: 				ListVector::GetEntry(*this).Verify();
663: 			}
664: 			auto list_data = FlatVector::GetData<list_entry_t>(*this);
665: 			for (idx_t i = 0; i < count; i++) {
666: 				auto idx = sel.get_index(i);
667: 				auto &le = list_data[idx];
668: 				if (!nullmask[idx]) {
669: 					assert(le.offset + le.length <= ListVector::GetEntry(*this).count);
670: 				}
671: 			}
672: 		}
673: 	}
674: // TODO verify list and struct
675: #endif
676: }
677: 
678: void Vector::Verify(idx_t count) {
679: 	Verify(FlatVector::IncrementalSelectionVector, count);
680: }
681: 
682: string_t StringVector::AddString(Vector &vector, const char *data, idx_t len) {
683: 	return StringVector::AddString(vector, string_t(data, len));
684: }
685: 
686: string_t StringVector::AddString(Vector &vector, const char *data) {
687: 	return StringVector::AddString(vector, string_t(data, strlen(data)));
688: }
689: 
690: string_t StringVector::AddString(Vector &vector, const string &data) {
691: 	return StringVector::AddString(vector, string_t(data.c_str(), data.size()));
692: }
693: 
694: string_t StringVector::AddString(Vector &vector, string_t data) {
695: 	assert(vector.type == TypeId::VARCHAR);
696: 	if (data.IsInlined()) {
697: 		// string will be inlined: no need to store in string heap
698: 		return data;
699: 	}
700: 	if (!vector.auxiliary) {
701: 		vector.auxiliary = make_buffer<VectorStringBuffer>();
702: 	}
703: 	assert(vector.auxiliary->type == VectorBufferType::STRING_BUFFER);
704: 	auto &string_buffer = (VectorStringBuffer &)*vector.auxiliary;
705: 	return string_buffer.AddString(data);
706: }
707: 
708: string_t StringVector::EmptyString(Vector &vector, idx_t len) {
709: 	assert(vector.type == TypeId::VARCHAR);
710: 	if (len < string_t::INLINE_LENGTH) {
711: 		return string_t(len);
712: 	}
713: 	if (!vector.auxiliary) {
714: 		vector.auxiliary = make_buffer<VectorStringBuffer>();
715: 	}
716: 	assert(vector.auxiliary->type == VectorBufferType::STRING_BUFFER);
717: 	auto &string_buffer = (VectorStringBuffer &)*vector.auxiliary;
718: 	return string_buffer.EmptyString(len);
719: }
720: 
721: void StringVector::AddHeapReference(Vector &vector, Vector &other) {
722: 	assert(vector.type == TypeId::VARCHAR);
723: 	assert(other.type == TypeId::VARCHAR);
724: 
725: 	if (!other.auxiliary) {
726: 		return;
727: 	}
728: 	if (!vector.auxiliary) {
729: 		vector.auxiliary = make_buffer<VectorStringBuffer>();
730: 	}
731: 	assert(vector.auxiliary->type == VectorBufferType::STRING_BUFFER);
732: 	assert(other.auxiliary->type == VectorBufferType::STRING_BUFFER);
733: 	auto &string_buffer = (VectorStringBuffer &)*vector.auxiliary;
734: 	string_buffer.AddHeapReference(other.auxiliary);
735: }
736: 
737: bool StructVector::HasEntries(const Vector &vector) {
738: 	assert(vector.type == TypeId::STRUCT);
739: 	assert(vector.vector_type == VectorType::FLAT_VECTOR || vector.vector_type == VectorType::CONSTANT_VECTOR);
740: 	assert(vector.auxiliary == nullptr || vector.auxiliary->type == VectorBufferType::STRUCT_BUFFER);
741: 	return vector.auxiliary != nullptr;
742: }
743: 
744: child_list_t<unique_ptr<Vector>> &StructVector::GetEntries(const Vector &vector) {
745: 	assert(vector.type == TypeId::STRUCT);
746: 	assert(vector.vector_type == VectorType::FLAT_VECTOR || vector.vector_type == VectorType::CONSTANT_VECTOR);
747: 	assert(vector.auxiliary);
748: 	assert(vector.auxiliary->type == VectorBufferType::STRUCT_BUFFER);
749: 	return ((VectorStructBuffer *)vector.auxiliary.get())->GetChildren();
750: }
751: 
752: void StructVector::AddEntry(Vector &vector, string name, unique_ptr<Vector> entry) {
753: 	// TODO asser that an entry with this name does not already exist
754: 	assert(vector.type == TypeId::STRUCT);
755: 	assert(vector.vector_type == VectorType::FLAT_VECTOR || vector.vector_type == VectorType::CONSTANT_VECTOR);
756: 	if (!vector.auxiliary) {
757: 		vector.auxiliary = make_buffer<VectorStructBuffer>();
758: 	}
759: 	assert(vector.auxiliary);
760: 	assert(vector.auxiliary->type == VectorBufferType::STRUCT_BUFFER);
761: 	((VectorStructBuffer *)vector.auxiliary.get())->AddChild(name, move(entry));
762: }
763: 
764: bool ListVector::HasEntry(const Vector &vector) {
765: 	assert(vector.type == TypeId::LIST);
766: 	if (vector.vector_type == VectorType::DICTIONARY_VECTOR) {
767: 		auto &child = DictionaryVector::Child(vector);
768: 		return ListVector::HasEntry(child);
769: 	}
770: 	assert(vector.vector_type == VectorType::FLAT_VECTOR || vector.vector_type == VectorType::CONSTANT_VECTOR);
771: 	return vector.auxiliary != nullptr;
772: }
773: 
774: ChunkCollection &ListVector::GetEntry(const Vector &vector) {
775: 	assert(vector.type == TypeId::LIST);
776: 	if (vector.vector_type == VectorType::DICTIONARY_VECTOR) {
777: 		auto &child = DictionaryVector::Child(vector);
778: 		return ListVector::GetEntry(child);
779: 	}
780: 	assert(vector.vector_type == VectorType::FLAT_VECTOR || vector.vector_type == VectorType::CONSTANT_VECTOR);
781: 	assert(vector.auxiliary);
782: 	assert(vector.auxiliary->type == VectorBufferType::LIST_BUFFER);
783: 	return ((VectorListBuffer *)vector.auxiliary.get())->GetChild();
784: }
785: 
786: void ListVector::SetEntry(Vector &vector, unique_ptr<ChunkCollection> cc) {
787: 	assert(vector.type == TypeId::LIST);
788: 	assert(vector.vector_type == VectorType::FLAT_VECTOR || vector.vector_type == VectorType::CONSTANT_VECTOR);
789: 	if (!vector.auxiliary) {
790: 		vector.auxiliary = make_buffer<VectorListBuffer>();
791: 	}
792: 	assert(vector.auxiliary);
793: 	assert(vector.auxiliary->type == VectorBufferType::LIST_BUFFER);
794: 	((VectorListBuffer *)vector.auxiliary.get())->SetChild(move(cc));
795: }
796: 
797: } // namespace duckdb
[end of src/common/types/vector.cpp]
[start of src/function/aggregate/distributive/sum.cpp]
1: #include "duckdb/function/aggregate/distributive_functions.hpp"
2: #include "duckdb/common/exception.hpp"
3: #include "duckdb/common/types/null_value.hpp"
4: #include "duckdb/common/vector_operations/vector_operations.hpp"
5: #include "duckdb/common/vector_operations/aggregate_executor.hpp"
6: #include "duckdb/common/operator/numeric_binary_operators.hpp"
7: 
8: using namespace std;
9: 
10: namespace duckdb {
11: 
12: struct SumOperation : public StandardDistributiveFunction {
13: 	template <class INPUT_TYPE, class STATE>
14: 	static void Assign(STATE *state, INPUT_TYPE input) {
15: 		*state = input;
16: 	}
17: 
18: 	template <class INPUT_TYPE, class STATE> static void Execute(STATE *state, INPUT_TYPE input) {
19: 		*state += input;
20: 	}
21: 
22: 	template <class INPUT_TYPE, class STATE, class OP>
23: 	static void ConstantOperation(STATE *state, INPUT_TYPE *input, nullmask_t &nullmask, idx_t count) {
24: 		assert(!nullmask[0]);
25: 		if (IsNullValue<INPUT_TYPE>(*state)) {
26: 			*state = 0;
27: 		}
28: 		*state += input[0] * count;
29: 	}
30: 
31: 	template <class T, class STATE>
32: 	static void Finalize(Vector &result, STATE *state, T *target, nullmask_t &nullmask, idx_t idx) {
33: 		nullmask[idx] = IsNullValue<T>(*state);
34: 		target[idx] = *state;
35: 	}
36: };
37: 
38: template <>
39: void SumOperation::Finalize(Vector &result, double *state, double *target, nullmask_t &nullmask, idx_t idx) {
40: 	if (!Value::DoubleIsValid(*state)) {
41: 		throw OutOfRangeException("SUM is out of range!");
42: 	}
43: 	nullmask[idx] = IsNullValue<double>(*state);
44: 	target[idx] = *state;
45: }
46: 
47: void SumFun::RegisterFunction(BuiltinFunctions &set) {
48: 	AggregateFunctionSet sum("sum");
49: 	// integer sums to bigint
50: 	sum.AddFunction(
51: 	    AggregateFunction::UnaryAggregate<int64_t, int64_t, int64_t, SumOperation>(SQLType::BIGINT, SQLType::BIGINT));
52: 	// float sums to float
53: 	sum.AddFunction(
54: 	    AggregateFunction::UnaryAggregate<double, double, double, SumOperation>(SQLType::DOUBLE, SQLType::DOUBLE));
55: 
56: 	set.AddFunction(sum);
57: }
58: 
59: } // namespace duckdb
[end of src/function/aggregate/distributive/sum.cpp]
[start of src/optimizer/pushdown/pushdown_left_join.cpp]
1: #include "duckdb/execution/expression_executor.hpp"
2: #include "duckdb/optimizer/filter_pushdown.hpp"
3: #include "duckdb/optimizer/optimizer.hpp"
4: #include "duckdb/planner/expression/bound_columnref_expression.hpp"
5: #include "duckdb/planner/expression/bound_comparison_expression.hpp"
6: #include "duckdb/planner/expression/bound_constant_expression.hpp"
7: #include "duckdb/planner/expression_iterator.hpp"
8: #include "duckdb/planner/operator/logical_comparison_join.hpp"
9: #include "duckdb/planner/operator/logical_filter.hpp"
10: 
11: using namespace duckdb;
12: using namespace std;
13: 
14: using Filter = FilterPushdown::Filter;
15: 
16: static unique_ptr<Expression> ReplaceColRefWithNull(unique_ptr<Expression> expr, unordered_set<idx_t> &right_bindings) {
17: 	if (expr->type == ExpressionType::BOUND_COLUMN_REF) {
18: 		auto &bound_colref = (BoundColumnRefExpression &)*expr;
19: 		if (right_bindings.find(bound_colref.binding.table_index) != right_bindings.end()) {
20: 			// bound colref belongs to RHS
21: 			// replace it with a constant NULL
22: 			return make_unique<BoundConstantExpression>(Value(expr->return_type));
23: 		}
24: 		return expr;
25: 	}
26: 	ExpressionIterator::EnumerateChildren(*expr, [&](unique_ptr<Expression> child) -> unique_ptr<Expression> {
27: 		return ReplaceColRefWithNull(move(child), right_bindings);
28: 	});
29: 	return expr;
30: }
31: 
32: static bool FilterRemovesNull(ExpressionRewriter &rewriter, Expression *expr, unordered_set<idx_t> &right_bindings) {
33: 	// make a copy of the expression
34: 	auto copy = expr->Copy();
35: 	// replace all BoundColumnRef expressions frmo the RHS with NULL constants in the copied expression
36: 	copy = ReplaceColRefWithNull(move(copy), right_bindings);
37: 
38: 	// attempt to flatten the expression by running the expression rewriter on it
39: 	auto filter = make_unique<LogicalFilter>();
40: 	filter->expressions.push_back(move(copy));
41: 	rewriter.Apply(*filter);
42: 	assert(filter->expressions.size() == 1);
43: 
44: 	if (filter->expressions[0]->type != ExpressionType::VALUE_CONSTANT) {
45: 		// could not flatten the result
46: 		assert(!filter->expressions[0]->IsFoldable());
47: 		return false;
48: 	}
49: 	// we flattened the result into a scalar, check if it is FALSE or NULL
50: 	auto val = ((BoundConstantExpression &)*filter->expressions[0]).value.CastAs(TypeId::BOOL);
51: 	// if the result of the expression with all expressions replaced with NULL is "NULL" or "false"
52: 	// then any extra entries generated by the LEFT OUTER JOIN will be filtered out!
53: 	// hence the LEFT OUTER JOIN is equivalent to an inner join
54: 	return val.is_null || !val.value_.boolean;
55: }
56: 
57: unique_ptr<LogicalOperator> FilterPushdown::PushdownLeftJoin(unique_ptr<LogicalOperator> op,
58:                                                              unordered_set<idx_t> &left_bindings,
59:                                                              unordered_set<idx_t> &right_bindings) {
60: 	auto &join = (LogicalJoin &)*op;
61: 	assert(join.join_type == JoinType::LEFT);
62: 	assert(op->type != LogicalOperatorType::DELIM_JOIN);
63: 	FilterPushdown left_pushdown(optimizer), right_pushdown(optimizer);
64: 	// for a comparison join we create a FilterCombiner that checks if we can push conditions on LHS join conditions
65: 	// into the RHS of the join
66: 	FilterCombiner filter_combiner;
67: 	if (op->type == LogicalOperatorType::COMPARISON_JOIN) {
68: 		// add all comparison conditions
69: 		auto &comparison_join = (LogicalComparisonJoin &)*op;
70: 		for (auto &cond : comparison_join.conditions) {
71: 			filter_combiner.AddFilter(
72: 			    make_unique<BoundComparisonExpression>(cond.comparison, cond.left->Copy(), cond.right->Copy()));
73: 		}
74: 	}
75: 	// now check the set of filters
76: 	for (idx_t i = 0; i < filters.size(); i++) {
77: 		auto side = JoinSide::GetJoinSide(filters[i]->bindings, left_bindings, right_bindings);
78: 		if (side == JoinSide::LEFT) {
79: 			// bindings match left side
80: 			// we can push the filter into the left side
81: 			if (op->type == LogicalOperatorType::COMPARISON_JOIN) {
82: 				// we MIGHT be able to push it down the RHS as well, but only if it is a comparison that matches the
83: 				// join predicates we use the FilterCombiner to figure this out add the expression to the FilterCombiner
84: 				filter_combiner.AddFilter(filters[i]->filter->Copy());
85: 			}
86: 			left_pushdown.filters.push_back(move(filters[i]));
87: 			// erase the filter from the list of filters
88: 			filters.erase(filters.begin() + i);
89: 			i--;
90: 		} else {
91: 			// bindings match right side or both sides: we cannot directly push it into the right
92: 			// however, if the filter removes rows with null values from the RHS we can turn the left outer join
93: 			// in an inner join, and then push down as we would push down an inner join
94: 			if (FilterRemovesNull(optimizer.rewriter, filters[i]->filter.get(), right_bindings)) {
95: 				// the filter removes NULL values, turn it into an inner join
96: 				join.join_type = JoinType::INNER;
97: 				// now we can do more pushdown
98: 				// move all filters we added to the left_pushdown back into the filter list
99: 				for (auto &left_filter : left_pushdown.filters) {
100: 					filters.push_back(move(left_filter));
101: 				}
102: 				// now push down the inner join
103: 				return PushdownInnerJoin(move(op), left_bindings, right_bindings);
104: 			}
105: 		}
106: 	}
107: 	// finally we check the FilterCombiner to see if there are any predicates we can push into the RHS
108: 	// we only added (1) predicates that have JoinSide::BOTH from the conditions, and
109: 	// (2) predicates that have JoinSide::LEFT from the filters
110: 	// we check now if this combination generated any new filters that are only on JoinSide::RIGHT
111: 	// this happens if, e.g. a join condition is (i=a) and there is a filter (i=500), we can then push the filter
112: 	// (a=500) into the RHS
113: 	filter_combiner.GenerateFilters([&](unique_ptr<Expression> filter) {
114: 		if (JoinSide::GetJoinSide(*filter, left_bindings, right_bindings) == JoinSide::RIGHT) {
115: 			right_pushdown.AddFilter(move(filter));
116: 		}
117: 	});
118: 	right_pushdown.GenerateFilters();
119: 	op->children[0] = left_pushdown.Rewrite(move(op->children[0]));
120: 	op->children[1] = right_pushdown.Rewrite(move(op->children[1]));
121: 	return FinishPushdown(move(op));
122: }
[end of src/optimizer/pushdown/pushdown_left_join.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: