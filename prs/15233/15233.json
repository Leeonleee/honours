{
  "repo": "duckdb/duckdb",
  "pull_number": 15233,
  "instance_id": "duckdb__duckdb-15233",
  "issue_numbers": [
    "15221",
    "15221"
  ],
  "base_commit": "07780a0d22a03ab0bfd058c1ecc1fa16dc86fd18",
  "patch": "diff --git a/extension/parquet/include/parquet_statistics.hpp b/extension/parquet/include/parquet_statistics.hpp\nindex d4e0a4a4d0be..ad1f939c8ef6 100644\n--- a/extension/parquet/include/parquet_statistics.hpp\n+++ b/extension/parquet/include/parquet_statistics.hpp\n@@ -35,6 +35,10 @@ struct ParquetStatisticsUtils {\n \n \tstatic bool BloomFilterExcludes(const TableFilter &filter, const duckdb_parquet::ColumnMetaData &column_meta_data,\n \t                                duckdb_apache::thrift::protocol::TProtocol &file_proto, Allocator &allocator);\n+\n+private:\n+\tstatic Value ConvertValueInternal(const LogicalType &type, const duckdb_parquet::SchemaElement &schema_ele,\n+\t                                  const std::string &stats);\n };\n \n class ParquetBloomFilter {\ndiff --git a/extension/parquet/parquet_statistics.cpp b/extension/parquet/parquet_statistics.cpp\nindex 477bda0a574d..b20510be9408 100644\n--- a/extension/parquet/parquet_statistics.cpp\n+++ b/extension/parquet/parquet_statistics.cpp\n@@ -30,16 +30,16 @@ static unique_ptr<BaseStatistics> CreateNumericStats(const LogicalType &type,\n \tValue min;\n \tValue max;\n \tif (parquet_stats.__isset.min_value) {\n-\t\tmin = ParquetStatisticsUtils::ConvertValue(type, schema_ele, parquet_stats.min_value).DefaultCastAs(type);\n+\t\tmin = ParquetStatisticsUtils::ConvertValue(type, schema_ele, parquet_stats.min_value);\n \t} else if (parquet_stats.__isset.min) {\n-\t\tmin = ParquetStatisticsUtils::ConvertValue(type, schema_ele, parquet_stats.min).DefaultCastAs(type);\n+\t\tmin = ParquetStatisticsUtils::ConvertValue(type, schema_ele, parquet_stats.min);\n \t} else {\n \t\tmin = Value(type);\n \t}\n \tif (parquet_stats.__isset.max_value) {\n-\t\tmax = ParquetStatisticsUtils::ConvertValue(type, schema_ele, parquet_stats.max_value).DefaultCastAs(type);\n+\t\tmax = ParquetStatisticsUtils::ConvertValue(type, schema_ele, parquet_stats.max_value);\n \t} else if (parquet_stats.__isset.max) {\n-\t\tmax = ParquetStatisticsUtils::ConvertValue(type, schema_ele, parquet_stats.max).DefaultCastAs(type);\n+\t\tmax = ParquetStatisticsUtils::ConvertValue(type, schema_ele, parquet_stats.max);\n \t} else {\n \t\tmax = Value(type);\n \t}\n@@ -50,6 +50,17 @@ static unique_ptr<BaseStatistics> CreateNumericStats(const LogicalType &type,\n \n Value ParquetStatisticsUtils::ConvertValue(const LogicalType &type, const duckdb_parquet::SchemaElement &schema_ele,\n                                            const std::string &stats) {\n+\tValue result;\n+\tstring error;\n+\tauto stats_val = ConvertValueInternal(type, schema_ele, stats);\n+\tif (!stats_val.DefaultTryCastAs(type, result, &error)) {\n+\t\treturn Value(type);\n+\t}\n+\treturn result;\n+}\n+Value ParquetStatisticsUtils::ConvertValueInternal(const LogicalType &type,\n+                                                   const duckdb_parquet::SchemaElement &schema_ele,\n+                                                   const std::string &stats) {\n \tauto stats_data = const_data_ptr_cast(stats.c_str());\n \tswitch (type.id()) {\n \tcase LogicalTypeId::BOOLEAN: {\n",
  "test_patch": "diff --git a/data/parquet-testing/out_of_range_stats.parquet b/data/parquet-testing/out_of_range_stats.parquet\nnew file mode 100644\nindex 000000000000..3c3be2cb7f11\nBinary files /dev/null and b/data/parquet-testing/out_of_range_stats.parquet differ\ndiff --git a/test/sql/copy/parquet/parquet_corrupt_stats.test b/test/sql/copy/parquet/parquet_corrupt_stats.test\nnew file mode 100644\nindex 000000000000..fb5a5362dfcd\n--- /dev/null\n+++ b/test/sql/copy/parquet/parquet_corrupt_stats.test\n@@ -0,0 +1,10 @@\n+# name: test/sql/copy/parquet/parquet_corrupt_stats.test\n+# description: Test reading a Parquet file with stats that are out-of-range of the type\n+# group: [parquet]\n+\n+require parquet\n+\n+query I\n+FROM 'data/parquet-testing/out_of_range_stats.parquet'\n+----\n+255\n",
  "problem_statement": "\"out of range\" error when reading parquet with unsigned tinyint or unsigned smallint\n### What happens?\r\n\r\n\"out of range\" error when reading parquet with unsigned tinyint (unsigned int8) or unsigned smallint (unsigned int16).  \r\n\r\nError message for tinyint:\r\n```\r\nInvalid Input Error: Failed to cast value: Type UINT32 with value 4294967295 can't be cast because the value is out of range for the destination type UINT8\r\n```\r\n\r\nError message for smallint:\r\n```\r\nInvalid Input Error: Failed to cast value: Type UINT32 with value 4294967295 can't be cast because the value is out of range for the destination type UINT16\r\n```\r\n\r\n### To Reproduce\r\n\r\nCreate a **parquet** file **containing at least 1 row** with this **schema**:\r\n```\r\nmessage schema {\r\n  OPTIONAL INT32 hcol0 (INTEGER(8,false));\r\n}\r\n```\r\nor\r\n```\r\nmessage schema {\r\n  OPTIONAL INT32 hcol0 (INTEGER(16,false));\r\n}\r\n```\r\n\r\nUse Duckdb to query the parquet:\r\n```sql\r\nselect hcol0 from READ_PARQUET('data.parquet');\r\n```\r\n\r\nExample parquet files (the extension is put as `.txt` to be able to upload here)\r\n[utinyint.txt](https://github.com/user-attachments/files/18060837/utinyint.txt)\r\n[usmallint.txt](https://github.com/user-attachments/files/18060836/usmallint.txt)\r\n\r\n```sql\r\nselect hcol0 from read_parquet('utinyint.txt');\r\nselect hcol0 from read_parquet('usmallint.txt');\r\n```\r\n\r\n### OS:\r\n\r\nlinux\r\n\r\n### DuckDB Version:\r\n\r\n1.1.3\r\n\r\n### DuckDB Client:\r\n\r\nCLI\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\nDat Bui\r\n\r\n### Affiliation:\r\n\r\nholistics.io\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\n\"out of range\" error when reading parquet with unsigned tinyint or unsigned smallint\n### What happens?\r\n\r\n\"out of range\" error when reading parquet with unsigned tinyint (unsigned int8) or unsigned smallint (unsigned int16).  \r\n\r\nError message for tinyint:\r\n```\r\nInvalid Input Error: Failed to cast value: Type UINT32 with value 4294967295 can't be cast because the value is out of range for the destination type UINT8\r\n```\r\n\r\nError message for smallint:\r\n```\r\nInvalid Input Error: Failed to cast value: Type UINT32 with value 4294967295 can't be cast because the value is out of range for the destination type UINT16\r\n```\r\n\r\n### To Reproduce\r\n\r\nCreate a **parquet** file **containing at least 1 row** with this **schema**:\r\n```\r\nmessage schema {\r\n  OPTIONAL INT32 hcol0 (INTEGER(8,false));\r\n}\r\n```\r\nor\r\n```\r\nmessage schema {\r\n  OPTIONAL INT32 hcol0 (INTEGER(16,false));\r\n}\r\n```\r\n\r\nUse Duckdb to query the parquet:\r\n```sql\r\nselect hcol0 from READ_PARQUET('data.parquet');\r\n```\r\n\r\nExample parquet files (the extension is put as `.txt` to be able to upload here)\r\n[utinyint.txt](https://github.com/user-attachments/files/18060837/utinyint.txt)\r\n[usmallint.txt](https://github.com/user-attachments/files/18060836/usmallint.txt)\r\n\r\n```sql\r\nselect hcol0 from read_parquet('utinyint.txt');\r\nselect hcol0 from read_parquet('usmallint.txt');\r\n```\r\n\r\n### OS:\r\n\r\nlinux\r\n\r\n### DuckDB Version:\r\n\r\n1.1.3\r\n\r\n### DuckDB Client:\r\n\r\nCLI\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\nDat Bui\r\n\r\n### Affiliation:\r\n\r\nholistics.io\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\n",
  "hints_text": "also reproducible with duckdb cli `v1.1.4-dev2261 ed90e384ef`\nThanks, I could reproduce the issue!\nalso reproducible with duckdb cli `v1.1.4-dev2261 ed90e384ef`\nThanks, I could reproduce the issue!",
  "created_at": "2024-12-09T16:58:38Z"
}