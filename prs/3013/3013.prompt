You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
array_slice prevents row values to be used more than once
#### What happens?

Function `array_slice` prevents table rows to be used more than once.

- `Q1` (see the examples below) works just fine. `p.loc` is used exactly once in `array_slice(arr, NULL, loc)`.
- `Q2` works, too. Again, `p.loc` is used once in the `WHERE`-clause `AND y = loc`.
- `Q3` uses `p.loc` twice, once in `array_slice`, once in the `WHERE`-clause. This fails with:
   `Error: Not implemented Error: FIXME unimplemented vector type for VectorOperations::Copy`
- The error disappears, when `array_slice(arr, NULL, loc)` is replaced with `array[arr[loc]]` in `Q3`.

These tests lead me to believe that `array_slice` is causing this strange behavior.

#### To Reproduce

```sql
CREATE TABLE p(loc int8);
INSERT INTO p VALUES (1);

-- Q1: (works fine)
WITH RECURSIVE t(y, arr) AS
(
  SELECT 1, array[1,2,3,4,5,6]
    UNION ALL
  SELECT y+1, array_slice(arr, NULL, loc)
  FROM   t, p
  WHERE y < 10
--    AND y = loc
) SELECT * FROM t;

-- Q2: (works fine)
WITH RECURSIVE t(y, arr) AS
(
  SELECT 1, array[1,2,3,4,5,6]
    UNION ALL
  SELECT y+1, arr --array_slice(arr, NULL, loc)
  FROM   t, p
  WHERE y < 10
    AND y = loc
) SELECT * FROM t;

-- Q3: (does not work)
WITH RECURSIVE t(y, arr) AS
(
  SELECT 1, array[1,2,3,4,5,6]
    UNION ALL
  SELECT y+1, array_slice(arr, NULL, loc)
  FROM   t, p
  WHERE y < 10
    AND y = loc
) SELECT * FROM t;
```

#### Environment (please complete the following information):
 - OS: macOS Monterey
 - DuckDB Version: git head
 - DuckDB Client: shell

#### Before Submitting

- [x] **Have you tried this on the latest `master` branch?**
* **Python**: `pip install duckdb --upgrade --pre`
* **R**: `install.packages("https://github.com/duckdb/duckdb/releases/download/master-builds/duckdb_r_src.tar.gz", repos = NULL)`
* **Other Platforms**: You can find binaries [here](https://github.com/duckdb/duckdb/releases/tag/master-builds) or compile from source.

- [x] **Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?**

array_slice prevents row values to be used more than once
#### What happens?

Function `array_slice` prevents table rows to be used more than once.

- `Q1` (see the examples below) works just fine. `p.loc` is used exactly once in `array_slice(arr, NULL, loc)`.
- `Q2` works, too. Again, `p.loc` is used once in the `WHERE`-clause `AND y = loc`.
- `Q3` uses `p.loc` twice, once in `array_slice`, once in the `WHERE`-clause. This fails with:
   `Error: Not implemented Error: FIXME unimplemented vector type for VectorOperations::Copy`
- The error disappears, when `array_slice(arr, NULL, loc)` is replaced with `array[arr[loc]]` in `Q3`.

These tests lead me to believe that `array_slice` is causing this strange behavior.

#### To Reproduce

```sql
CREATE TABLE p(loc int8);
INSERT INTO p VALUES (1);

-- Q1: (works fine)
WITH RECURSIVE t(y, arr) AS
(
  SELECT 1, array[1,2,3,4,5,6]
    UNION ALL
  SELECT y+1, array_slice(arr, NULL, loc)
  FROM   t, p
  WHERE y < 10
--    AND y = loc
) SELECT * FROM t;

-- Q2: (works fine)
WITH RECURSIVE t(y, arr) AS
(
  SELECT 1, array[1,2,3,4,5,6]
    UNION ALL
  SELECT y+1, arr --array_slice(arr, NULL, loc)
  FROM   t, p
  WHERE y < 10
    AND y = loc
) SELECT * FROM t;

-- Q3: (does not work)
WITH RECURSIVE t(y, arr) AS
(
  SELECT 1, array[1,2,3,4,5,6]
    UNION ALL
  SELECT y+1, array_slice(arr, NULL, loc)
  FROM   t, p
  WHERE y < 10
    AND y = loc
) SELECT * FROM t;
```

#### Environment (please complete the following information):
 - OS: macOS Monterey
 - DuckDB Version: git head
 - DuckDB Client: shell

#### Before Submitting

- [x] **Have you tried this on the latest `master` branch?**
* **Python**: `pip install duckdb --upgrade --pre`
* **R**: `install.packages("https://github.com/duckdb/duckdb/releases/download/master-builds/duckdb_r_src.tar.gz", repos = NULL)`
* **Other Platforms**: You can find binaries [here](https://github.com/duckdb/duckdb/releases/tag/master-builds) or compile from source.

- [x] **Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?**


</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
3: </div>
4: <p>&nbsp;</p>
5: 
6: <p align="center">
7:   <a href="https://github.com/duckdb/duckdb/actions">
8:     <img src="https://github.com/cwida/duckdb/workflows/.github/workflows/main.yml/badge.svg?branch=master" alt=".github/workflows/main.yml">
9:   </a>
10:   <a href="https://www.codefactor.io/repository/github/cwida/duckdb">
11:     <img src="https://www.codefactor.io/repository/github/cwida/duckdb/badge" alt="CodeFactor"/>
12:   </a>
13:   <a href="https://app.codecov.io/gh/duckdb/duckdb">
14:     <img src="https://codecov.io/gh/duckdb/duckdb/branch/master/graph/badge.svg?token=FaxjcfFghN" alt="codecov"/>
15:   </a>
16:   <a href="https://discord.gg/tcvwpjfnZx">
17:     <img src="https://shields.io/discord/909674491309850675" alt="discord" />
18:   </a>
19: </p>
20: 
21: ## DuckDB
22: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on the goals of DuckDB, please refer to [the Why DuckDB page on our website](https://duckdb.org/why_duckdb).
23: 
24: ## Installation
25: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
26: 
27: ## Data Import
28: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
29: 
30: ```sql
31: SELECT * FROM 'myfile.csv';
32: SELECT * FROM 'myfile.parquet';
33: ```
34: 
35: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
36: 
37: ## SQL Reference
38: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
39: 
40: ## Development
41: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`.
42: 
43: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
44: 
45: 
[end of README.md]
[start of src/function/scalar/list/array_slice.cpp]
1: #include "duckdb/planner/expression/bound_function_expression.hpp"
2: #include "duckdb/common/string_util.hpp"
3: #include "duckdb/parser/expression/bound_expression.hpp"
4: #include "duckdb/function/scalar/nested_functions.hpp"
5: #include "duckdb/common/types/chunk_collection.hpp"
6: #include "duckdb/common/types/data_chunk.hpp"
7: #include "duckdb/common/pair.hpp"
8: #include "duckdb/function/scalar/string_functions.hpp"
9: 
10: namespace duckdb {
11: 
12: template <typename INPUT_TYPE, typename INDEX_TYPE>
13: INDEX_TYPE ValueOffset(const INPUT_TYPE &value) {
14: 	return 0;
15: }
16: 
17: template <>
18: int64_t ValueOffset(const list_entry_t &value) {
19: 	return value.offset;
20: }
21: 
22: template <typename INPUT_TYPE, typename INDEX_TYPE>
23: INDEX_TYPE ValueLength(const INPUT_TYPE &value) {
24: 	return 0;
25: }
26: 
27: template <>
28: int64_t ValueLength(const list_entry_t &value) {
29: 	return value.length;
30: }
31: 
32: template <>
33: int32_t ValueLength(const string_t &value) {
34: 	return LengthFun::Length<string_t, int32_t>(value);
35: }
36: 
37: template <typename INPUT_TYPE, typename INDEX_TYPE>
38: bool ClampIndex(INDEX_TYPE &index, const INPUT_TYPE &value) {
39: 	const auto length = ValueLength<INPUT_TYPE, INDEX_TYPE>(value);
40: 	if (index < 0) {
41: 		if (-index > length) {
42: 			return false;
43: 		}
44: 		index = length + index;
45: 	} else if (index > length) {
46: 		index = length;
47: 	}
48: 	return true;
49: }
50: 
51: template <typename INPUT_TYPE, typename INDEX_TYPE>
52: static bool ClampSlice(const INPUT_TYPE &value, INDEX_TYPE &begin, INDEX_TYPE &end, bool begin_valid, bool end_valid) {
53: 	// Clamp offsets
54: 	begin = begin_valid ? begin : 0;
55: 	end = end_valid ? end : ValueLength<INPUT_TYPE, INDEX_TYPE>(value);
56: 	if (!ClampIndex(begin, value) || !ClampIndex(end, value)) {
57: 		return false;
58: 	}
59: 	end = MaxValue<INDEX_TYPE>(begin, end);
60: 
61: 	return true;
62: }
63: 
64: template <typename INPUT_TYPE, typename INDEX_TYPE>
65: INPUT_TYPE SliceValue(Vector &result, INPUT_TYPE input, INDEX_TYPE begin, INDEX_TYPE end) {
66: 	return input;
67: }
68: 
69: template <>
70: list_entry_t SliceValue(Vector &result, list_entry_t input, int64_t begin, int64_t end) {
71: 	input.offset += begin;
72: 	input.length = end - begin;
73: 	return input;
74: }
75: 
76: template <>
77: string_t SliceValue(Vector &result, string_t input, int32_t begin, int32_t end) {
78: 	// one-based - zero has strange semantics
79: 	return SubstringFun::SubstringScalarFunction(result, input, begin + 1, end - begin);
80: }
81: 
82: template <typename INPUT_TYPE, typename INDEX_TYPE>
83: static void ExecuteSlice(Vector &result, Vector &s, Vector &b, Vector &e, const idx_t count) {
84: 	if (result.GetVectorType() == VectorType::CONSTANT_VECTOR) {
85: 		auto rdata = ConstantVector::GetData<INPUT_TYPE>(result);
86: 		auto sdata = ConstantVector::GetData<INPUT_TYPE>(s);
87: 		auto bdata = ConstantVector::GetData<INDEX_TYPE>(b);
88: 		auto edata = ConstantVector::GetData<INDEX_TYPE>(e);
89: 
90: 		auto sliced = sdata[0];
91: 		auto begin = bdata[0];
92: 		auto end = edata[0];
93: 
94: 		auto svalid = !ConstantVector::IsNull(s);
95: 		auto bvalid = !ConstantVector::IsNull(b);
96: 		auto evalid = !ConstantVector::IsNull(e);
97: 
98: 		// Try to slice
99: 		if (!svalid || !ClampSlice(sliced, begin, end, bvalid, evalid)) {
100: 			ConstantVector::SetNull(result, true);
101: 		} else {
102: 			rdata[0] = SliceValue<INPUT_TYPE, INDEX_TYPE>(result, sliced, begin, end);
103: 		}
104: 	} else {
105: 		VectorData sdata, bdata, edata;
106: 
107: 		s.Orrify(count, sdata);
108: 		b.Orrify(count, bdata);
109: 		e.Orrify(count, edata);
110: 
111: 		auto rdata = FlatVector::GetData<INPUT_TYPE>(result);
112: 		auto &rmask = FlatVector::Validity(result);
113: 
114: 		for (idx_t i = 0; i < count; ++i) {
115: 			auto sidx = sdata.sel->get_index(i);
116: 			auto bidx = bdata.sel->get_index(i);
117: 			auto eidx = edata.sel->get_index(i);
118: 
119: 			auto sliced = ((INPUT_TYPE *)sdata.data)[sidx];
120: 			auto begin = ((INDEX_TYPE *)bdata.data)[bidx];
121: 			auto end = ((INDEX_TYPE *)edata.data)[eidx];
122: 
123: 			auto svalid = sdata.validity.RowIsValid(sidx);
124: 			auto bvalid = bdata.validity.RowIsValid(bidx);
125: 			auto evalid = edata.validity.RowIsValid(eidx);
126: 
127: 			// Try to slice
128: 			if (!svalid || !ClampSlice(sliced, begin, end, bvalid, evalid)) {
129: 				rmask.SetInvalid(i);
130: 			} else {
131: 				rdata[i] = SliceValue<INPUT_TYPE, INDEX_TYPE>(result, sliced, begin, end);
132: 			}
133: 		}
134: 	}
135: 
136: 	result.Verify(count);
137: }
138: 
139: static void ArraySliceFunction(DataChunk &args, ExpressionState &state, Vector &result) {
140: 	D_ASSERT(args.ColumnCount() == 3);
141: 	D_ASSERT(args.data.size() == 3);
142: 	auto count = args.size();
143: 
144: 	result.SetVectorType(VectorType::CONSTANT_VECTOR);
145: 	for (idx_t i = 0; i < args.ColumnCount(); i++) {
146: 		if (args.data[i].GetVectorType() != VectorType::CONSTANT_VECTOR) {
147: 			result.SetVectorType(VectorType::FLAT_VECTOR);
148: 		}
149: 	}
150: 
151: 	Vector &s = args.data[0];
152: 	Vector &b = args.data[1];
153: 	Vector &e = args.data[2];
154: 
155: 	switch (result.GetType().id()) {
156: 	case LogicalTypeId::LIST:
157: 		// Share the value dictionary as we are just going to slice it
158: 		ListVector::ReferenceEntry(result, s);
159: 		ExecuteSlice<list_entry_t, int64_t>(result, s, b, e, count);
160: 		break;
161: 	case LogicalTypeId::VARCHAR:
162: 		ExecuteSlice<string_t, int32_t>(result, s, b, e, count);
163: 		break;
164: 	default:
165: 		throw NotImplementedException("Specifier type not implemented");
166: 	}
167: }
168: 
169: static unique_ptr<FunctionData> ArraySliceBind(ClientContext &context, ScalarFunction &bound_function,
170:                                                vector<unique_ptr<Expression>> &arguments) {
171: 	D_ASSERT(bound_function.arguments.size() == 3);
172: 	switch (arguments[0]->return_type.id()) {
173: 	case LogicalTypeId::LIST:
174: 		// The result is the same type
175: 		bound_function.return_type = arguments[0]->return_type;
176: 		break;
177: 	case LogicalTypeId::VARCHAR:
178: 		// string slice returns a string, but can only accept 32 bit integers
179: 		bound_function.return_type = arguments[0]->return_type;
180: 		bound_function.arguments[1] = LogicalType::INTEGER;
181: 		bound_function.arguments[2] = LogicalType::INTEGER;
182: 		break;
183: 	default:
184: 		throw BinderException("ARRAY_SLICE can only operate on LISTs and VARCHARs");
185: 	}
186: 
187: 	return make_unique<VariableReturnBindData>(bound_function.return_type);
188: }
189: 
190: void ArraySliceFun::RegisterFunction(BuiltinFunctions &set) {
191: 	// the arguments and return types are actually set in the binder function
192: 	ScalarFunction fun({LogicalType::ANY, LogicalType::BIGINT, LogicalType::BIGINT}, LogicalType::ANY,
193: 	                   ArraySliceFunction, false, ArraySliceBind);
194: 	fun.varargs = LogicalType::ANY;
195: 	set.AddFunction({"array_slice", "list_slice"}, fun);
196: }
197: 
198: } // namespace duckdb
[end of src/function/scalar/list/array_slice.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: