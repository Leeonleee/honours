diff --git a/extension/parquet/column_reader.cpp b/extension/parquet/column_reader.cpp
index 667932f957c1..da0b6359b13a 100644
--- a/extension/parquet/column_reader.cpp
+++ b/extension/parquet/column_reader.cpp
@@ -157,7 +157,7 @@ unique_ptr<ColumnReader> ColumnReader::CreateReader(ParquetReader &reader, const
 				throw InternalException("Unrecognized type for Decimal");
 			}
 		default:
-			throw NotImplementedException("Unrecognized type for Decimal");
+			throw NotImplementedException("Unrecognized Parquet type for Decimal");
 		}
 		break;
 	default:
@@ -564,8 +564,7 @@ StructColumnReader::StructColumnReader(ParquetReader &reader, LogicalType type_p
                                        vector<unique_ptr<ColumnReader>> child_readers_p)
     : ColumnReader(reader, move(type_p), schema_p, schema_idx_p, max_define_p, max_repeat_p),
       child_readers(move(child_readers_p)) {
-	D_ASSERT(type.id() == LogicalTypeId::STRUCT);
-	D_ASSERT(!StructType::GetChildTypes(type).empty());
+	D_ASSERT(type.InternalType() == PhysicalType::STRUCT);
 }
 
 ColumnReader *StructColumnReader::GetChildReader(idx_t child_idx) {
diff --git a/extension/parquet/column_writer.cpp b/extension/parquet/column_writer.cpp
index 5de7cfcfca26..6d3c5d6883b9 100644
--- a/extension/parquet/column_writer.cpp
+++ b/extension/parquet/column_writer.cpp
@@ -40,8 +40,10 @@ using duckdb_parquet::format::Type;
 //===--------------------------------------------------------------------===//
 // ColumnWriter
 //===--------------------------------------------------------------------===//
-ColumnWriter::ColumnWriter(ParquetWriter &writer, idx_t schema_idx, idx_t max_repeat, idx_t max_define)
-    : writer(writer), schema_idx(schema_idx), max_repeat(max_repeat), max_define(max_define) {
+ColumnWriter::ColumnWriter(ParquetWriter &writer, idx_t schema_idx, idx_t max_repeat, idx_t max_define,
+                           bool can_have_nulls)
+    : writer(writer), schema_idx(schema_idx), max_repeat(max_repeat), max_define(max_define),
+      can_have_nulls(can_have_nulls) {
 }
 ColumnWriter::~ColumnWriter() {
 }
@@ -196,6 +198,9 @@ void ColumnWriter::HandleDefineLevels(ColumnWriterState &state, ColumnWriterStat
 			} else if (validity.RowIsValid(vector_index)) {
 				state.definition_levels.push_back(define_value);
 			} else {
+				if (!can_have_nulls) {
+					throw IOException("Parquet writer: map key column is not allowed to contain NULL values");
+				}
 				state.definition_levels.push_back(null_value);
 			}
 			if (parent->is_empty.empty() || !parent->is_empty[current_index]) {
@@ -208,6 +213,9 @@ void ColumnWriter::HandleDefineLevels(ColumnWriterState &state, ColumnWriterStat
 			if (validity.RowIsValid(i)) {
 				state.definition_levels.push_back(define_value);
 			} else {
+				if (!can_have_nulls) {
+					throw IOException("Parquet writer: map key column is not allowed to contain NULL values");
+				}
 				state.definition_levels.push_back(null_value);
 			}
 		}
@@ -490,8 +498,9 @@ static void TemplatedWritePlain(Vector &col, idx_t chunk_start, idx_t chunk_end,
 template <class SRC, class TGT, class OP = ParquetCastOperator>
 class StandardColumnWriter : public ColumnWriter {
 public:
-	StandardColumnWriter(ParquetWriter &writer, idx_t schema_idx, idx_t max_repeat, idx_t max_define)
-	    : ColumnWriter(writer, schema_idx, max_repeat, max_define) {
+	StandardColumnWriter(ParquetWriter &writer, idx_t schema_idx, idx_t max_repeat, idx_t max_define,
+	                     bool can_have_nulls)
+	    : ColumnWriter(writer, schema_idx, max_repeat, max_define, can_have_nulls) {
 	}
 	~StandardColumnWriter() override = default;
 
@@ -518,8 +527,9 @@ class BooleanWriterPageState : public ColumnWriterPageState {
 
 class BooleanColumnWriter : public ColumnWriter {
 public:
-	BooleanColumnWriter(ParquetWriter &writer, idx_t schema_idx, idx_t max_repeat, idx_t max_define)
-	    : ColumnWriter(writer, schema_idx, max_repeat, max_define) {
+	BooleanColumnWriter(ParquetWriter &writer, idx_t schema_idx, idx_t max_repeat, idx_t max_define,
+	                    bool can_have_nulls)
+	    : ColumnWriter(writer, schema_idx, max_repeat, max_define, can_have_nulls) {
 	}
 	~BooleanColumnWriter() override = default;
 
@@ -570,8 +580,9 @@ class BooleanColumnWriter : public ColumnWriter {
 //===--------------------------------------------------------------------===//
 class DecimalColumnWriter : public ColumnWriter {
 public:
-	DecimalColumnWriter(ParquetWriter &writer, idx_t schema_idx, idx_t max_repeat, idx_t max_define)
-	    : ColumnWriter(writer, schema_idx, max_repeat, max_define) {
+	DecimalColumnWriter(ParquetWriter &writer, idx_t schema_idx, idx_t max_repeat, idx_t max_define,
+	                    bool can_have_nulls)
+	    : ColumnWriter(writer, schema_idx, max_repeat, max_define, can_have_nulls) {
 	}
 	~DecimalColumnWriter() override = default;
 
@@ -596,8 +607,8 @@ class DecimalColumnWriter : public ColumnWriter {
 //===--------------------------------------------------------------------===//
 class StringColumnWriter : public ColumnWriter {
 public:
-	StringColumnWriter(ParquetWriter &writer, idx_t schema_idx, idx_t max_repeat, idx_t max_define)
-	    : ColumnWriter(writer, schema_idx, max_repeat, max_define) {
+	StringColumnWriter(ParquetWriter &writer, idx_t schema_idx, idx_t max_repeat, idx_t max_define, bool can_have_nulls)
+	    : ColumnWriter(writer, schema_idx, max_repeat, max_define, can_have_nulls) {
 	}
 	~StringColumnWriter() override = default;
 
@@ -627,8 +638,9 @@ class StringColumnWriter : public ColumnWriter {
 class StructColumnWriter : public ColumnWriter {
 public:
 	StructColumnWriter(ParquetWriter &writer, idx_t schema_idx, idx_t max_repeat, idx_t max_define,
-	                   vector<unique_ptr<ColumnWriter>> child_writers_p)
-	    : ColumnWriter(writer, schema_idx, max_repeat, max_define), child_writers(move(child_writers_p)) {
+	                   vector<unique_ptr<ColumnWriter>> child_writers_p, bool can_have_nulls)
+	    : ColumnWriter(writer, schema_idx, max_repeat, max_define, can_have_nulls),
+	      child_writers(move(child_writers_p)) {
 	}
 	~StructColumnWriter() override = default;
 
@@ -723,8 +735,8 @@ void StructColumnWriter::FinalizeWrite(ColumnWriterState &state_p) {
 class ListColumnWriter : public ColumnWriter {
 public:
 	ListColumnWriter(ParquetWriter &writer, idx_t schema_idx, idx_t max_repeat, idx_t max_define,
-	                 unique_ptr<ColumnWriter> child_writer_p)
-	    : ColumnWriter(writer, schema_idx, max_repeat, max_define), child_writer(move(child_writer_p)) {
+	                 unique_ptr<ColumnWriter> child_writer_p, bool can_have_nulls)
+	    : ColumnWriter(writer, schema_idx, max_repeat, max_define, can_have_nulls), child_writer(move(child_writer_p)) {
 	}
 	~ListColumnWriter() override = default;
 
@@ -810,6 +822,9 @@ void ListColumnWriter::Prepare(ColumnWriterState &state_p, ColumnWriterState *pa
 				state.is_empty.push_back(false);
 			}
 		} else {
+			if (!can_have_nulls) {
+				throw IOException("Parquet writer: map key column is not allowed to contain NULL values");
+			}
 			state.definition_levels.push_back(max_define - 1);
 			state.repetition_levels.push_back(first_repeat_level);
 			state.is_empty.push_back(true);
@@ -846,13 +861,18 @@ void ListColumnWriter::FinalizeWrite(ColumnWriterState &state_p) {
 //===--------------------------------------------------------------------===//
 unique_ptr<ColumnWriter> ColumnWriter::CreateWriterRecursive(vector<duckdb_parquet::format::SchemaElement> &schemas,
                                                              ParquetWriter &writer, const LogicalType &type,
-                                                             const string &name, idx_t max_repeat, idx_t max_define) {
+                                                             const string &name, idx_t max_repeat, idx_t max_define,
+                                                             bool can_have_nulls) {
+	auto null_type = can_have_nulls ? FieldRepetitionType::OPTIONAL : FieldRepetitionType::REQUIRED;
+	if (!can_have_nulls) {
+		max_define--;
+	}
 	idx_t schema_idx = schemas.size();
 	if (type.id() == LogicalTypeId::STRUCT) {
 		auto &child_types = StructType::GetChildTypes(type);
 		// set up the schema element for this struct
 		duckdb_parquet::format::SchemaElement schema_element;
-		schema_element.repetition_type = FieldRepetitionType::OPTIONAL;
+		schema_element.repetition_type = null_type;
 		schema_element.num_children = child_types.size();
 		schema_element.__isset.num_children = true;
 		schema_element.__isset.type = false;
@@ -866,7 +886,8 @@ unique_ptr<ColumnWriter> ColumnWriter::CreateWriterRecursive(vector<duckdb_parqu
 			child_writers.push_back(CreateWriterRecursive(schemas, writer, child_type.second, child_type.first,
 			                                              max_repeat, max_define + 1));
 		}
-		return make_unique<StructColumnWriter>(writer, schema_idx, max_repeat, max_define, move(child_writers));
+		return make_unique<StructColumnWriter>(writer, schema_idx, max_repeat, max_define, move(child_writers),
+		                                       can_have_nulls);
 	}
 	if (type.id() == LogicalTypeId::LIST) {
 		auto &child_type = ListType::GetChildType(type);
@@ -874,7 +895,7 @@ unique_ptr<ColumnWriter> ColumnWriter::CreateWriterRecursive(vector<duckdb_parqu
 		// for some reason we only set the converted type in the OPTIONAL element
 		// first an OPTIONAL element
 		duckdb_parquet::format::SchemaElement optional_element;
-		optional_element.repetition_type = FieldRepetitionType::OPTIONAL;
+		optional_element.repetition_type = null_type;
 		optional_element.num_children = 1;
 		optional_element.converted_type = ConvertedType::LIST;
 		optional_element.__isset.num_children = true;
@@ -894,12 +915,63 @@ unique_ptr<ColumnWriter> ColumnWriter::CreateWriterRecursive(vector<duckdb_parqu
 		repeated_element.name = "list";
 		schemas.push_back(move(repeated_element));
 
-		auto child_writer = CreateWriterRecursive(schemas, writer, child_type, "child", max_repeat + 1, max_define + 2);
-		return make_unique<ListColumnWriter>(writer, schema_idx, max_repeat, max_define, move(child_writer));
+		auto child_writer =
+		    CreateWriterRecursive(schemas, writer, child_type, "element", max_repeat + 1, max_define + 2);
+		return make_unique<ListColumnWriter>(writer, schema_idx, max_repeat, max_define, move(child_writer),
+		                                     can_have_nulls);
+	}
+	if (type.id() == LogicalTypeId::MAP) {
+		// map type
+		// maps are stored as follows:
+		// <map-repetition> group <name> (MAP) {
+		// 	repeated group key_value {
+		// 		required <key-type> key;
+		// 		<value-repetition> <value-type> value;
+		// 	}
+		// }
+		// top map element
+		duckdb_parquet::format::SchemaElement top_element;
+		top_element.repetition_type = null_type;
+		top_element.num_children = 1;
+		top_element.converted_type = ConvertedType::MAP;
+		top_element.__isset.repetition_type = true;
+		top_element.__isset.num_children = true;
+		top_element.__isset.converted_type = true;
+		top_element.__isset.type = false;
+		top_element.name = name;
+		schemas.push_back(move(top_element));
+
+		// key_value element
+		duckdb_parquet::format::SchemaElement kv_element;
+		kv_element.repetition_type = FieldRepetitionType::REPEATED;
+		kv_element.num_children = 2;
+		kv_element.__isset.repetition_type = true;
+		kv_element.__isset.num_children = true;
+		kv_element.__isset.type = false;
+		kv_element.name = "key_value";
+		schemas.push_back(move(kv_element));
+
+		// construct the child types recursively
+		vector<LogicalType> kv_types {ListType::GetChildType(MapType::KeyType(type)),
+		                              ListType::GetChildType(MapType::ValueType(type))};
+		vector<string> kv_names {"key", "value"};
+		vector<unique_ptr<ColumnWriter>> child_writers;
+		child_writers.reserve(2);
+		for (idx_t i = 0; i < 2; i++) {
+			// key needs to be marked as REQUIRED
+			bool is_key = i == 0;
+			auto child_writer = CreateWriterRecursive(schemas, writer, kv_types[i], kv_names[i], max_repeat + 1,
+			                                          max_define + 2, !is_key);
+			auto list_writer = make_unique<ListColumnWriter>(writer, schema_idx, max_repeat, max_define,
+			                                                 move(child_writer), can_have_nulls);
+			child_writers.push_back(move(list_writer));
+		}
+		return make_unique<StructColumnWriter>(writer, schema_idx, max_repeat, max_define, move(child_writers),
+		                                       can_have_nulls);
 	}
 	duckdb_parquet::format::SchemaElement schema_element;
 	schema_element.type = ParquetWriter::DuckDBTypeToParquetType(type);
-	schema_element.repetition_type = FieldRepetitionType::OPTIONAL;
+	schema_element.repetition_type = null_type;
 	schema_element.num_children = 0;
 	schema_element.__isset.num_children = true;
 	schema_element.__isset.type = true;
@@ -911,44 +983,54 @@ unique_ptr<ColumnWriter> ColumnWriter::CreateWriterRecursive(vector<duckdb_parqu
 
 	switch (type.id()) {
 	case LogicalTypeId::BOOLEAN:
-		return make_unique<BooleanColumnWriter>(writer, schema_idx, max_repeat, max_define);
+		return make_unique<BooleanColumnWriter>(writer, schema_idx, max_repeat, max_define, can_have_nulls);
 	case LogicalTypeId::TINYINT:
-		return make_unique<StandardColumnWriter<int8_t, int32_t>>(writer, schema_idx, max_repeat, max_define);
+		return make_unique<StandardColumnWriter<int8_t, int32_t>>(writer, schema_idx, max_repeat, max_define,
+		                                                          can_have_nulls);
 	case LogicalTypeId::SMALLINT:
-		return make_unique<StandardColumnWriter<int16_t, int32_t>>(writer, schema_idx, max_repeat, max_define);
+		return make_unique<StandardColumnWriter<int16_t, int32_t>>(writer, schema_idx, max_repeat, max_define,
+		                                                           can_have_nulls);
 	case LogicalTypeId::INTEGER:
 	case LogicalTypeId::DATE:
-		return make_unique<StandardColumnWriter<int32_t, int32_t>>(writer, schema_idx, max_repeat, max_define);
+		return make_unique<StandardColumnWriter<int32_t, int32_t>>(writer, schema_idx, max_repeat, max_define,
+		                                                           can_have_nulls);
 	case LogicalTypeId::BIGINT:
 	case LogicalTypeId::TIMESTAMP:
 	case LogicalTypeId::TIMESTAMP_MS:
-		return make_unique<StandardColumnWriter<int64_t, int64_t>>(writer, schema_idx, max_repeat, max_define);
+		return make_unique<StandardColumnWriter<int64_t, int64_t>>(writer, schema_idx, max_repeat, max_define,
+		                                                           can_have_nulls);
 	case LogicalTypeId::HUGEINT:
-		return make_unique<StandardColumnWriter<hugeint_t, double, ParquetHugeintOperator>>(writer, schema_idx,
-		                                                                                    max_repeat, max_define);
+		return make_unique<StandardColumnWriter<hugeint_t, double, ParquetHugeintOperator>>(
+		    writer, schema_idx, max_repeat, max_define, can_have_nulls);
 	case LogicalTypeId::TIMESTAMP_NS:
-		return make_unique<StandardColumnWriter<int64_t, int64_t, ParquetTimestampNSOperator>>(writer, schema_idx,
-		                                                                                       max_repeat, max_define);
+		return make_unique<StandardColumnWriter<int64_t, int64_t, ParquetTimestampNSOperator>>(
+		    writer, schema_idx, max_repeat, max_define, can_have_nulls);
 	case LogicalTypeId::TIMESTAMP_SEC:
-		return make_unique<StandardColumnWriter<int64_t, int64_t, ParquetTimestampSOperator>>(writer, schema_idx,
-		                                                                                      max_repeat, max_define);
+		return make_unique<StandardColumnWriter<int64_t, int64_t, ParquetTimestampSOperator>>(
+		    writer, schema_idx, max_repeat, max_define, can_have_nulls);
 	case LogicalTypeId::UTINYINT:
-		return make_unique<StandardColumnWriter<uint8_t, int32_t>>(writer, schema_idx, max_repeat, max_define);
+		return make_unique<StandardColumnWriter<uint8_t, int32_t>>(writer, schema_idx, max_repeat, max_define,
+		                                                           can_have_nulls);
 	case LogicalTypeId::USMALLINT:
-		return make_unique<StandardColumnWriter<uint16_t, int32_t>>(writer, schema_idx, max_repeat, max_define);
+		return make_unique<StandardColumnWriter<uint16_t, int32_t>>(writer, schema_idx, max_repeat, max_define,
+		                                                            can_have_nulls);
 	case LogicalTypeId::UINTEGER:
-		return make_unique<StandardColumnWriter<uint32_t, uint32_t>>(writer, schema_idx, max_repeat, max_define);
+		return make_unique<StandardColumnWriter<uint32_t, uint32_t>>(writer, schema_idx, max_repeat, max_define,
+		                                                             can_have_nulls);
 	case LogicalTypeId::UBIGINT:
-		return make_unique<StandardColumnWriter<uint64_t, uint64_t>>(writer, schema_idx, max_repeat, max_define);
+		return make_unique<StandardColumnWriter<uint64_t, uint64_t>>(writer, schema_idx, max_repeat, max_define,
+		                                                             can_have_nulls);
 	case LogicalTypeId::FLOAT:
-		return make_unique<StandardColumnWriter<float, float>>(writer, schema_idx, max_repeat, max_define);
+		return make_unique<StandardColumnWriter<float, float>>(writer, schema_idx, max_repeat, max_define,
+		                                                       can_have_nulls);
 	case LogicalTypeId::DOUBLE:
-		return make_unique<StandardColumnWriter<double, double>>(writer, schema_idx, max_repeat, max_define);
+		return make_unique<StandardColumnWriter<double, double>>(writer, schema_idx, max_repeat, max_define,
+		                                                         can_have_nulls);
 	case LogicalTypeId::DECIMAL:
-		return make_unique<DecimalColumnWriter>(writer, schema_idx, max_repeat, max_define);
+		return make_unique<DecimalColumnWriter>(writer, schema_idx, max_repeat, max_define, can_have_nulls);
 	case LogicalTypeId::BLOB:
 	case LogicalTypeId::VARCHAR:
-		return make_unique<StringColumnWriter>(writer, schema_idx, max_repeat, max_define);
+		return make_unique<StringColumnWriter>(writer, schema_idx, max_repeat, max_define, can_have_nulls);
 	default:
 		throw InternalException("Unsupported type in Parquet writer");
 	}
diff --git a/extension/parquet/include/column_writer.hpp b/extension/parquet/include/column_writer.hpp
index a412ec4140c0..e840281a2a6c 100644
--- a/extension/parquet/include/column_writer.hpp
+++ b/extension/parquet/include/column_writer.hpp
@@ -31,20 +31,21 @@ class ColumnWriter {
 	static constexpr const idx_t MAX_UNCOMPRESSED_PAGE_SIZE = 100000000;
 
 public:
-	ColumnWriter(ParquetWriter &writer, idx_t schema_idx, idx_t max_repeat, idx_t max_define);
+	ColumnWriter(ParquetWriter &writer, idx_t schema_idx, idx_t max_repeat, idx_t max_define, bool can_have_nulls);
 	virtual ~ColumnWriter();
 
 	ParquetWriter &writer;
 	idx_t schema_idx;
 	idx_t max_repeat;
 	idx_t max_define;
+	bool can_have_nulls;
 
 public:
 	//! Create the column writer for a specific type recursively
 	static unique_ptr<ColumnWriter> CreateWriterRecursive(vector<duckdb_parquet::format::SchemaElement> &schemas,
 	                                                      ParquetWriter &writer, const LogicalType &type,
 	                                                      const string &name, idx_t max_repeat = 0,
-	                                                      idx_t max_define = 1);
+	                                                      idx_t max_define = 1, bool can_have_nulls = true);
 
 	virtual unique_ptr<ColumnWriterState> InitializeWriteState(duckdb_parquet::format::RowGroup &row_group,
 	                                                           vector<string> schema_path);
diff --git a/extension/parquet/parquet_reader.cpp b/extension/parquet/parquet_reader.cpp
index 85b815a731cc..6e44da18fb44 100644
--- a/extension/parquet/parquet_reader.cpp
+++ b/extension/parquet/parquet_reader.cpp
@@ -261,7 +261,32 @@ unique_ptr<ColumnReader> ParquetReader::CreateReaderRecursive(const FileMetaData
 		bool is_repeated = s_ele.repetition_type == FieldRepetitionType::REPEATED;
 		bool is_list = s_ele.__isset.converted_type && s_ele.converted_type == ConvertedType::LIST;
 		bool is_map = s_ele.__isset.converted_type && s_ele.converted_type == ConvertedType::MAP;
-		// if we only have a single child no reason to create a struct ay
+		bool is_map_kv = s_ele.__isset.converted_type && s_ele.converted_type == ConvertedType::MAP_KEY_VALUE;
+		if (!is_map_kv && this_idx > 0) {
+			// check if the parent node of this is a map
+			auto &p_ele = file_meta_data->schema[this_idx - 1];
+			bool parent_is_map = p_ele.__isset.converted_type && p_ele.converted_type == ConvertedType::MAP;
+			bool parent_has_children = p_ele.__isset.num_children && p_ele.num_children == 1;
+			is_map_kv = parent_is_map && parent_has_children;
+		}
+
+		if (is_map_kv) {
+			if (child_types.size() != 2) {
+				throw IOException("MAP_KEY_VALUE requires two children");
+			}
+			if (!is_repeated) {
+				throw IOException("MAP_KEY_VALUE needs to be repeated");
+			}
+			result_type = LogicalType::MAP(move(child_types[0].second), move(child_types[1].second));
+			for (auto &child_reader : child_readers) {
+				auto child_type = LogicalType::LIST(child_reader->Type());
+				child_reader = make_unique<ListColumnReader>(*this, move(child_type), s_ele, this_idx, max_define,
+				                                             max_repeat, move(child_reader));
+			}
+			result = make_unique<StructColumnReader>(*this, result_type, s_ele, this_idx, max_define - 1,
+			                                         max_repeat - 1, move(child_readers));
+			return result;
+		}
 		if (child_types.size() > 1 || (!is_list && !is_map && !is_repeated)) {
 			result_type = LogicalType::STRUCT(move(child_types));
 			result = make_unique<StructColumnReader>(*this, result_type, s_ele, this_idx, max_define, max_repeat,
@@ -278,7 +303,6 @@ unique_ptr<ColumnReader> ParquetReader::CreateReaderRecursive(const FileMetaData
 		}
 		return result;
 	} else { // leaf node
-
 		if (s_ele.repetition_type == FieldRepetitionType::REPEATED) {
 			const auto derived_type = DeriveLogicalType(s_ele);
 			auto list_type = LogicalType::LIST(derived_type);
diff --git a/src/common/types.cpp b/src/common/types.cpp
index b3de9ed5308d..6a580e5594de 100644
--- a/src/common/types.cpp
+++ b/src/common/types.cpp
@@ -975,6 +975,9 @@ LogicalType LogicalType::STRUCT(child_list_t<LogicalType> children) {
 	return LogicalType(LogicalTypeId::STRUCT, move(info));
 }
 
+//===--------------------------------------------------------------------===//
+// Map Type
+//===--------------------------------------------------------------------===//
 LogicalType LogicalType::MAP(child_list_t<LogicalType> children) {
 	auto info = make_shared<StructTypeInfo>(move(children));
 	return LogicalType(LogicalTypeId::MAP, move(info));
@@ -987,6 +990,16 @@ LogicalType LogicalType::MAP(LogicalType key, LogicalType value) {
 	return LogicalType::MAP(move(child_types));
 }
 
+const LogicalType &MapType::KeyType(const LogicalType &type) {
+	D_ASSERT(type.id() == LogicalTypeId::MAP);
+	return StructType::GetChildTypes(type)[0].second;
+}
+
+const LogicalType &MapType::ValueType(const LogicalType &type) {
+	D_ASSERT(type.id() == LogicalTypeId::MAP);
+	return StructType::GetChildTypes(type)[1].second;
+}
+
 //===--------------------------------------------------------------------===//
 // User Type
 //===--------------------------------------------------------------------===//
diff --git a/src/include/duckdb/common/types.hpp b/src/include/duckdb/common/types.hpp
index 2f0c94f5977b..cb33df4b8518 100644
--- a/src/include/duckdb/common/types.hpp
+++ b/src/include/duckdb/common/types.hpp
@@ -522,6 +522,11 @@ struct StructType {
 	DUCKDB_API static idx_t GetChildCount(const LogicalType &type);
 };
 
+struct MapType {
+	DUCKDB_API static const LogicalType &KeyType(const LogicalType &type);
+	DUCKDB_API static const LogicalType &ValueType(const LogicalType &type);
+};
+
 
 string LogicalTypeIdToString(LogicalTypeId type);
 
