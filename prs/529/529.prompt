You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
GROUP BY clause results in non-deterministic result
Consider the following statements:
```sql
CREATE TABLE t0(c0 NUMERIC);
INSERT INTO t0(c0) VALUES (-515965088);
INSERT INTO t0(c0) VALUES (1), (-5.15965088E8);
CREATE INDEX i0 ON t0(c0);
SELECT t0.c0 FROM t0 GROUP BY t0.c0, REVERSE(t0.c0); -- non-deterministic result
```
Unexpectedly, the query's result set is non-deterministic. In most executions, `-515965088.0` is contained twice in the result set, but sometimes it is contained only once.

For example, the following console output demonstrates that the result can change:
```
sqlite> SELECT t0.c0 FROM t0 GROUP BY t0.c0, REVERSE(t0.c0);
-515965088.0
-515965088.0
1.0
sqlite> SELECT t0.c0 FROM t0 GROUP BY t0.c0, REVERSE(t0.c0);
-515965088.0
-515965088.0
1.0
sqlite> SELECT t0.c0 FROM t0 GROUP BY t0.c0, REVERSE(t0.c0);
-515965088.0
-515965088.0
1.0
sqlite> SELECT t0.c0 FROM t0 GROUP BY t0.c0, REVERSE(t0.c0);
-515965088.0
1.0
sqlite> SELECT t0.c0 FROM t0 GROUP BY t0.c0, REVERSE(t0.c0);
-515965088.0
1.0
sqlite> SELECT t0.c0 FROM t0 GROUP BY t0.c0, REVERSE(t0.c0);
-515965088.0
```
When executing this based on a debug build, an assertion error occurs:
```sql
sqlite> SELECT t0.c0 FROM t0 GROUP BY t0.c0, REVERSE(t0.c0); -- cardinality: 27;
duckdb_cli: /duckdb/src/common/types/string_type.cpp:27: void duckdb::string_t::Verify(): Assertion `prefix[i] == dataptr[i]' failed.
Aborted
```
I can reproduce this on the latest master commit (3f0eb5134512c6097805998ccc5eb44476534736).

</issue>
<code>
[start of README.md]
1: <img align="left" src="logo/duckdb-logo.png" height="120">
2: 
3: # DuckDB, the SQLite for Analytics
4: [![Travis](https://api.travis-ci.org/cwida/duckdb.svg?branch=master)](https://travis-ci.org/cwida/duckdb)
5: [![CodeFactor](https://www.codefactor.io/repository/github/cwida/duckdb/badge)](https://www.codefactor.io/repository/github/cwida/duckdb)
6: [![Coverage Status](https://coveralls.io/repos/github/cwida/duckdb/badge.svg?branch=master)](https://coveralls.io/github/cwida/duckdb?branch=master)
7: 
8: <br>
9: 
10: 
11: # Requirements
12: DuckDB requires [CMake](https://cmake.org) to be installed and a `C++11` compliant compiler. GCC 4.9 and newer, Clang 3.9 and newer and VisualStudio 2017 are tested on each revision.
13: 
14: ## Compiling
15: Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You may run `make unit` and `make allunit` to verify that your version works properly after making changes.
16: 
17: # Usage
18: A command line utility based on `sqlite3` can be found in either `build/release/duckdb_cli` (release, the default) or `build/debug/duckdb_cli` (debug).
19: 
20: # Embedding
21: As DuckDB is an embedded database, there is no database server to launch or client to connect to a running server. However, the database server can be embedded directly into an application using the C or C++ bindings. The main build process creates the shared library `build/release/src/libduckdb.[so|dylib|dll]` that can be linked against. A static library is built as well.
22: 
23: For examples on how to embed DuckDB into your application, see the [examples](https://github.com/cwida/duckdb/tree/master/examples) folder.
24: 
25: ## Benchmarks
26: After compiling, benchmarks can be executed from the root directory by executing `./build/release/benchmark/benchmark_runner`.
27: 
28: ## Standing on the Shoulders of Giants
29: DuckDB is implemented in C++ 11, should compile with GCC and clang, uses CMake to build and [Catch2](https://github.com/catchorg/Catch2) for testing. DuckDB uses some components from various Open-Source databases and draws inspiration from scientific publications. Here is an overview:
30: 
31: * Parser: We use the PostgreSQL parser that was [repackaged as a stand-alone library](https://github.com/lfittl/libpg_query). The translation to our own parse tree is inspired by [Peloton](https://pelotondb.io).
32: * Shell: We have adapted the [SQLite shell](https://sqlite.org/cli.html) to work with DuckDB.
33: * Tests: We use the [SQL Logic Tests from SQLite](https://www.sqlite.org/sqllogictest/doc/trunk/about.wiki) to test DuckDB.
34: * Query fuzzing: We use [SQLsmith](https://github.com/anse1/sqlsmith) to generate random queries for additional testing.
35: * Date Math: We use the date math component from [MonetDB](https://www.monetdb.org).
36: * SQL Window Functions: DuckDB's window functions implementation uses Segment Tree Aggregation as described in the paper "Efficient Processing of Window Functions in Analytical SQL Queries" by Viktor Leis, Kan Kundhikanjana, Alfons Kemper and Thomas Neumann.
37: * Execution engine: The vectorized execution engine is inspired by the paper "MonetDB/X100: Hyper-Pipelining Query Execution" by Peter Boncz, Marcin Zukowski and Niels Nes.
38: * Optimizer: DuckDB's optimizer draws inspiration from the papers "Dynamic programming strikes back" by Guido Moerkotte and Thomas Neumman as well as "Unnesting Arbitrary Queries" by Thomas Neumann and Alfons Kemper.
39: * Concurrency control: Our MVCC implementation is inspired by the paper "Fast Serializable Multi-Version Concurrency Control for Main-Memory Database Systems" by Thomas Neumann, Tobias Mühlbauer and Alfons Kemper.
40: * Regular Expression: DuckDB uses Google's [RE2](https://github.com/google/re2) regular expression engine.
41: 
42: ## Other pages
43: * [Continuous Benchmarking (CB™)](https://www.duckdb.org/benchmarks/index.html), runs TPC-H, TPC-DS and some microbenchmarks on every commit
[end of README.md]
[start of src/common/types/value.cpp]
1: #include "duckdb/common/types/value.hpp"
2: 
3: #include "duckdb/common/exception.hpp"
4: #include "duckdb/common/limits.hpp"
5: #include "duckdb/common/operator/aggregate_operators.hpp"
6: #include "duckdb/common/operator/cast_operators.hpp"
7: #include "duckdb/common/operator/comparison_operators.hpp"
8: 
9: #include "utf8proc_wrapper.hpp"
10: #include "duckdb/common/operator/numeric_binary_operators.hpp"
11: #include "duckdb/common/printer.hpp"
12: #include "duckdb/common/serializer.hpp"
13: #include "duckdb/common/types/date.hpp"
14: #include "duckdb/common/types/null_value.hpp"
15: #include "duckdb/common/types/time.hpp"
16: #include "duckdb/common/types/timestamp.hpp"
17: #include "duckdb/common/types/vector.hpp"
18: #include "duckdb/common/value_operations/value_operations.hpp"
19: #include "duckdb/common/vector_operations/vector_operations.hpp"
20: #include "duckdb/common/string_util.hpp"
21: 
22: using namespace duckdb;
23: using namespace std;
24: 
25: Value::Value(string_t val) : Value(string(val.GetData(), val.GetSize())) {
26: }
27: 
28: Value::Value(string val) : type(TypeId::VARCHAR), is_null(false) {
29: 	auto utf_type = Utf8Proc::Analyze(val);
30: 	switch (utf_type) {
31: 	case UnicodeType::INVALID:
32: 		throw Exception("String value is not valid UTF8");
33: 	case UnicodeType::ASCII:
34: 		str_value = val;
35: 		break;
36: 	case UnicodeType::UNICODE:
37: 		str_value = Utf8Proc::Normalize(val);
38: 		break;
39: 	}
40: }
41: 
42: Value Value::MinimumValue(TypeId type) {
43: 	Value result;
44: 	result.type = type;
45: 	result.is_null = false;
46: 	switch (type) {
47: 	case TypeId::BOOL:
48: 		result.value_.boolean = false;
49: 		break;
50: 	case TypeId::INT8:
51: 		result.value_.tinyint = std::numeric_limits<int8_t>::min();
52: 		break;
53: 	case TypeId::INT16:
54: 		result.value_.smallint = std::numeric_limits<int16_t>::min();
55: 		break;
56: 	case TypeId::INT32:
57: 		result.value_.integer = std::numeric_limits<int32_t>::min();
58: 		break;
59: 	case TypeId::INT64:
60: 		result.value_.bigint = std::numeric_limits<int64_t>::min();
61: 		break;
62: 	case TypeId::FLOAT:
63: 		result.value_.float_ = std::numeric_limits<float>::min();
64: 		break;
65: 	case TypeId::DOUBLE:
66: 		result.value_.double_ = std::numeric_limits<double>::min();
67: 		break;
68: 	case TypeId::POINTER:
69: 		result.value_.pointer = std::numeric_limits<uintptr_t>::min();
70: 		break;
71: 	default:
72: 		throw InvalidTypeException(type, "MinimumValue requires numeric type");
73: 	}
74: 	return result;
75: }
76: 
77: Value Value::MaximumValue(TypeId type) {
78: 	Value result;
79: 	result.type = type;
80: 	result.is_null = false;
81: 	switch (type) {
82: 	case TypeId::BOOL:
83: 		result.value_.boolean = true;
84: 		break;
85: 	case TypeId::INT8:
86: 		result.value_.tinyint = std::numeric_limits<int8_t>::max();
87: 		break;
88: 	case TypeId::INT16:
89: 		result.value_.smallint = std::numeric_limits<int16_t>::max();
90: 		break;
91: 	case TypeId::INT32:
92: 		result.value_.integer = std::numeric_limits<int32_t>::max();
93: 		break;
94: 	case TypeId::INT64:
95: 		result.value_.bigint = std::numeric_limits<int64_t>::max();
96: 		break;
97: 	case TypeId::FLOAT:
98: 		result.value_.float_ = std::numeric_limits<float>::max();
99: 		break;
100: 	case TypeId::DOUBLE:
101: 		result.value_.double_ = std::numeric_limits<double>::max();
102: 		break;
103: 	case TypeId::POINTER:
104: 		result.value_.pointer = std::numeric_limits<uintptr_t>::max();
105: 		break;
106: 	default:
107: 		throw InvalidTypeException(type, "MaximumValue requires numeric type");
108: 	}
109: 	return result;
110: }
111: 
112: Value Value::BOOLEAN(int8_t value) {
113: 	Value result(TypeId::BOOL);
114: 	result.value_.boolean = value ? true : false;
115: 	result.is_null = false;
116: 	return result;
117: }
118: 
119: Value Value::TINYINT(int8_t value) {
120: 	Value result(TypeId::INT8);
121: 	result.value_.tinyint = value;
122: 	result.is_null = false;
123: 	return result;
124: }
125: 
126: Value Value::SMALLINT(int16_t value) {
127: 	Value result(TypeId::INT16);
128: 	result.value_.smallint = value;
129: 	result.is_null = false;
130: 	return result;
131: }
132: 
133: Value Value::INTEGER(int32_t value) {
134: 	Value result(TypeId::INT32);
135: 	result.value_.integer = value;
136: 	result.is_null = false;
137: 	return result;
138: }
139: 
140: Value Value::BIGINT(int64_t value) {
141: 	Value result(TypeId::INT64);
142: 	result.value_.bigint = value;
143: 	result.is_null = false;
144: 	return result;
145: }
146: 
147: Value Value::FLOAT(float value) {
148: 	Value result(TypeId::FLOAT);
149: 	result.value_.float_ = value;
150: 	result.is_null = false;
151: 	return result;
152: }
153: 
154: Value Value::DOUBLE(double value) {
155: 	Value result(TypeId::DOUBLE);
156: 	result.value_.double_ = value;
157: 	result.is_null = false;
158: 	return result;
159: }
160: 
161: Value Value::HASH(hash_t value) {
162: 	Value result(TypeId::HASH);
163: 	result.value_.hash = value;
164: 	result.is_null = false;
165: 	return result;
166: }
167: 
168: Value Value::POINTER(uintptr_t value) {
169: 	Value result(TypeId::POINTER);
170: 	result.value_.pointer = value;
171: 	result.is_null = false;
172: 	return result;
173: }
174: 
175: Value Value::DATE(int32_t year, int32_t month, int32_t day) {
176: 	return Value::INTEGER(Date::FromDate(year, month, day));
177: }
178: 
179: Value Value::TIME(int32_t hour, int32_t min, int32_t sec, int32_t msec) {
180: 	return Value::INTEGER(Time::FromTime(hour, min, sec, msec));
181: }
182: 
183: Value Value::TIMESTAMP(timestamp_t timestamp) {
184: 	return Value::BIGINT(timestamp);
185: }
186: 
187: Value Value::TIMESTAMP(date_t date, dtime_t time) {
188: 	return Value::BIGINT(Timestamp::FromDatetime(date, time));
189: }
190: 
191: Value Value::TIMESTAMP(int32_t year, int32_t month, int32_t day, int32_t hour, int32_t min, int32_t sec, int32_t msec) {
192: 	return Value::TIMESTAMP(Date::FromDate(year, month, day), Time::FromTime(hour, min, sec, msec));
193: }
194: 
195: Value Value::STRUCT(child_list_t<Value> values) {
196: 	Value result(TypeId::STRUCT);
197: 	result.struct_value = move(values);
198: 	result.is_null = false;
199: 	return result;
200: }
201: 
202: Value Value::LIST(vector<Value> values) {
203: 	Value result(TypeId::LIST);
204: 	result.list_value = move(values);
205: 	result.is_null = false;
206: 	return result;
207: }
208: 
209: //===--------------------------------------------------------------------===//
210: // CreateValue
211: //===--------------------------------------------------------------------===//
212: template <> Value Value::CreateValue(bool value) {
213: 	return Value::BOOLEAN(value);
214: }
215: 
216: template <> Value Value::CreateValue(int8_t value) {
217: 	return Value::TINYINT(value);
218: }
219: 
220: template <> Value Value::CreateValue(int16_t value) {
221: 	return Value::SMALLINT(value);
222: }
223: 
224: template <> Value Value::CreateValue(int32_t value) {
225: 	return Value::INTEGER(value);
226: }
227: 
228: template <> Value Value::CreateValue(int64_t value) {
229: 	return Value::BIGINT(value);
230: }
231: 
232: template <> Value Value::CreateValue(const char *value) {
233: 	return Value(string(value));
234: }
235: 
236: template <> Value Value::CreateValue(string value) {
237: 	return Value(value);
238: }
239: 
240: template <> Value Value::CreateValue(string_t value) {
241: 	return Value(value);
242: }
243: 
244: template <> Value Value::CreateValue(float value) {
245: 	return Value::FLOAT(value);
246: }
247: 
248: template <> Value Value::CreateValue(double value) {
249: 	return Value::DOUBLE(value);
250: }
251: 
252: //===--------------------------------------------------------------------===//
253: // GetValue
254: //===--------------------------------------------------------------------===//
255: template <class T> T Value::GetValueInternal() {
256: 	if (is_null) {
257: 		return NullValue<T>();
258: 	}
259: 	switch (type) {
260: 	case TypeId::BOOL:
261: 		return Cast::Operation<bool, T>(value_.boolean);
262: 	case TypeId::INT8:
263: 		return Cast::Operation<int8_t, T>(value_.tinyint);
264: 	case TypeId::INT16:
265: 		return Cast::Operation<int16_t, T>(value_.smallint);
266: 	case TypeId::INT32:
267: 		return Cast::Operation<int32_t, T>(value_.integer);
268: 	case TypeId::INT64:
269: 		return Cast::Operation<int64_t, T>(value_.bigint);
270: 	case TypeId::FLOAT:
271: 		return Cast::Operation<float, T>(value_.float_);
272: 	case TypeId::DOUBLE:
273: 		return Cast::Operation<double, T>(value_.double_);
274: 	case TypeId::VARCHAR:
275: 		return Cast::Operation<string_t, T>(str_value.c_str());
276: 	default:
277: 		throw NotImplementedException("Unimplemented type for GetValue()");
278: 	}
279: }
280: 
281: template <> bool Value::GetValue() {
282: 	return GetValueInternal<bool>();
283: }
284: template <> int8_t Value::GetValue() {
285: 	return GetValueInternal<int8_t>();
286: }
287: template <> int16_t Value::GetValue() {
288: 	return GetValueInternal<int16_t>();
289: }
290: template <> int32_t Value::GetValue() {
291: 	return GetValueInternal<int32_t>();
292: }
293: template <> int64_t Value::GetValue() {
294: 	return GetValueInternal<int64_t>();
295: }
296: template <> string Value::GetValue() {
297: 	return GetValueInternal<string>();
298: }
299: template <> float Value::GetValue() {
300: 	return GetValueInternal<float>();
301: }
302: template <> double Value::GetValue() {
303: 	return GetValueInternal<double>();
304: }
305: 
306: Value Value::Numeric(TypeId type, int64_t value) {
307: 	assert(!TypeIsIntegral(type) ||
308: 	       (value >= duckdb::MinimumValue(type) && (value < 0 || (uint64_t)value <= duckdb::MaximumValue(type))));
309: 	Value val(type);
310: 	val.is_null = false;
311: 	switch (type) {
312: 	case TypeId::INT8:
313: 		assert(value <= std::numeric_limits<int8_t>::max());
314: 		return Value::TINYINT((int8_t)value);
315: 	case TypeId::INT16:
316: 		assert(value <= std::numeric_limits<int16_t>::max());
317: 		return Value::SMALLINT((int16_t)value);
318: 	case TypeId::INT32:
319: 		assert(value <= std::numeric_limits<int32_t>::max());
320: 		return Value::INTEGER((int32_t)value);
321: 	case TypeId::INT64:
322: 		return Value::BIGINT(value);
323: 	case TypeId::FLOAT:
324: 		return Value((float)value);
325: 	case TypeId::DOUBLE:
326: 		return Value((double)value);
327: 	case TypeId::HASH:
328: 		return Value::HASH(value);
329: 	case TypeId::POINTER:
330: 		return Value::POINTER(value);
331: 	default:
332: 		throw InvalidTypeException(type, "Numeric requires numeric type");
333: 	}
334: 	return val;
335: }
336: 
337: string Value::ToString(SQLType sql_type) const {
338: 	if (is_null) {
339: 		return "NULL";
340: 	}
341: 	switch (sql_type.id) {
342: 	case SQLTypeId::BOOLEAN:
343: 		return value_.boolean ? "True" : "False";
344: 	case SQLTypeId::TINYINT:
345: 		return to_string(value_.tinyint);
346: 	case SQLTypeId::SMALLINT:
347: 		return to_string(value_.smallint);
348: 	case SQLTypeId::INTEGER:
349: 		return to_string(value_.integer);
350: 	case SQLTypeId::BIGINT:
351: 		return to_string(value_.bigint);
352: 	case SQLTypeId::FLOAT:
353: 		return to_string(value_.float_);
354: 	case SQLTypeId::DOUBLE:
355: 		return to_string(value_.double_);
356: 	case SQLTypeId::DATE:
357: 		return Date::ToString(value_.integer);
358: 	case SQLTypeId::TIME:
359: 		return Time::ToString(value_.integer);
360: 	case SQLTypeId::TIMESTAMP:
361: 		return Timestamp::ToString(value_.bigint);
362: 	case SQLTypeId::VARCHAR:
363: 		return str_value;
364: 	case SQLTypeId::STRUCT: {
365: 		string ret = "<";
366: 		for (size_t i = 0; i < struct_value.size(); i++) {
367: 			auto &child = struct_value[i];
368: 			ret += child.first + ": " + child.second.ToString();
369: 			if (i < struct_value.size() - 1) {
370: 				ret += ", ";
371: 			}
372: 		}
373: 		ret += ">";
374: 		return ret;
375: 	}
376: 	case SQLTypeId::LIST: {
377: 		string ret = "[";
378: 		for (size_t i = 0; i < list_value.size(); i++) {
379: 			auto &child = list_value[i];
380: 			ret += child.ToString();
381: 			if (i < list_value.size() - 1) {
382: 				ret += ", ";
383: 			}
384: 		}
385: 		ret += "]";
386: 		return ret;
387: 	}
388: 	default:
389: 		throw NotImplementedException("Unimplemented type for printing");
390: 	}
391: }
392: 
393: string Value::ToString() const {
394: 	switch (type) {
395: 	case TypeId::POINTER:
396: 		return to_string(value_.pointer);
397: 	case TypeId::HASH:
398: 		return to_string(value_.hash);
399: 	default:
400: 		return ToString(SQLTypeFromInternalType(type));
401: 	}
402: }
403: 
404: //===--------------------------------------------------------------------===//
405: // Numeric Operators
406: //===--------------------------------------------------------------------===//
407: Value Value::operator+(const Value &rhs) const {
408: 	return ValueOperations::Add(*this, rhs);
409: }
410: 
411: Value Value::operator-(const Value &rhs) const {
412: 	return ValueOperations::Subtract(*this, rhs);
413: }
414: 
415: Value Value::operator*(const Value &rhs) const {
416: 	return ValueOperations::Multiply(*this, rhs);
417: }
418: 
419: Value Value::operator/(const Value &rhs) const {
420: 	return ValueOperations::Divide(*this, rhs);
421: }
422: 
423: Value Value::operator%(const Value &rhs) const {
424: 	throw NotImplementedException("value modulo");
425: 	// return ValueOperations::Modulo(*this, rhs);
426: }
427: 
428: //===--------------------------------------------------------------------===//
429: // Comparison Operators
430: //===--------------------------------------------------------------------===//
431: bool Value::operator==(const Value &rhs) const {
432: 	return ValueOperations::Equals(*this, rhs);
433: }
434: 
435: bool Value::operator!=(const Value &rhs) const {
436: 	return ValueOperations::NotEquals(*this, rhs);
437: }
438: 
439: bool Value::operator<(const Value &rhs) const {
440: 	return ValueOperations::LessThan(*this, rhs);
441: }
442: 
443: bool Value::operator>(const Value &rhs) const {
444: 	return ValueOperations::GreaterThan(*this, rhs);
445: }
446: 
447: bool Value::operator<=(const Value &rhs) const {
448: 	return ValueOperations::LessThanEquals(*this, rhs);
449: }
450: 
451: bool Value::operator>=(const Value &rhs) const {
452: 	return ValueOperations::GreaterThanEquals(*this, rhs);
453: }
454: 
455: bool Value::operator==(const int64_t &rhs) const {
456: 	return *this == Value::Numeric(type, rhs);
457: }
458: 
459: bool Value::operator!=(const int64_t &rhs) const {
460: 	return *this != Value::Numeric(type, rhs);
461: }
462: 
463: bool Value::operator<(const int64_t &rhs) const {
464: 	return *this < Value::Numeric(type, rhs);
465: }
466: 
467: bool Value::operator>(const int64_t &rhs) const {
468: 	return *this > Value::Numeric(type, rhs);
469: }
470: 
471: bool Value::operator<=(const int64_t &rhs) const {
472: 	return *this <= Value::Numeric(type, rhs);
473: }
474: 
475: bool Value::operator>=(const int64_t &rhs) const {
476: 	return *this >= Value::Numeric(type, rhs);
477: }
478: 
479: Value Value::CastAs(SQLType source_type, SQLType target_type) {
480: 	if (source_type == target_type) {
481: 		return Copy();
482: 	}
483: 	Vector input, result;
484: 	input.Reference(*this);
485: 	result.Initialize(GetInternalType(target_type));
486: 	VectorOperations::Cast(input, result, source_type, target_type, 1);
487: 	return result.GetValue(0);
488: }
489: 
490: Value Value::CastAs(TypeId target_type) const {
491: 	if (target_type == type) {
492: 		return Copy(); // in case of types that have no SQLType equivalent such as POINTER
493: 	}
494: 	return Copy().CastAs(SQLTypeFromInternalType(type), SQLTypeFromInternalType(target_type));
495: }
496: 
497: void Value::Serialize(Serializer &serializer) {
498: 	serializer.Write<TypeId>(type);
499: 	serializer.Write<bool>(is_null);
500: 	if (!is_null) {
501: 		switch (type) {
502: 		case TypeId::BOOL:
503: 			serializer.Write<int8_t>(value_.boolean);
504: 			break;
505: 		case TypeId::INT8:
506: 			serializer.Write<int8_t>(value_.tinyint);
507: 			break;
508: 		case TypeId::INT16:
509: 			serializer.Write<int16_t>(value_.smallint);
510: 			break;
511: 		case TypeId::INT32:
512: 			serializer.Write<int32_t>(value_.integer);
513: 			break;
514: 		case TypeId::INT64:
515: 			serializer.Write<int64_t>(value_.bigint);
516: 			break;
517: 		case TypeId::FLOAT:
518: 			serializer.Write<double>(value_.float_);
519: 			break;
520: 		case TypeId::DOUBLE:
521: 			serializer.Write<double>(value_.double_);
522: 			break;
523: 		case TypeId::POINTER:
524: 			serializer.Write<uintptr_t>(value_.pointer);
525: 			break;
526: 		case TypeId::VARCHAR:
527: 			serializer.WriteString(str_value);
528: 			break;
529: 		default:
530: 			throw NotImplementedException("Value type not implemented for serialization!");
531: 		}
532: 	}
533: }
534: 
535: Value Value::Deserialize(Deserializer &source) {
536: 	auto type = source.Read<TypeId>();
537: 	auto is_null = source.Read<bool>();
538: 	Value new_value = Value(type);
539: 	if (is_null) {
540: 		return new_value;
541: 	}
542: 	new_value.is_null = false;
543: 	switch (type) {
544: 	case TypeId::BOOL:
545: 		new_value.value_.boolean = source.Read<int8_t>();
546: 		break;
547: 	case TypeId::INT8:
548: 		new_value.value_.tinyint = source.Read<int8_t>();
549: 		break;
550: 	case TypeId::INT16:
551: 		new_value.value_.smallint = source.Read<int16_t>();
552: 		break;
553: 	case TypeId::INT32:
554: 		new_value.value_.integer = source.Read<int32_t>();
555: 		break;
556: 	case TypeId::INT64:
557: 		new_value.value_.bigint = source.Read<int64_t>();
558: 		break;
559: 	case TypeId::FLOAT:
560: 		new_value.value_.float_ = source.Read<float>();
561: 		break;
562: 	case TypeId::DOUBLE:
563: 		new_value.value_.double_ = source.Read<double>();
564: 		break;
565: 	case TypeId::POINTER:
566: 		new_value.value_.pointer = source.Read<uint64_t>();
567: 		break;
568: 	case TypeId::VARCHAR:
569: 		new_value.str_value = source.Read<string>();
570: 		break;
571: 	default:
572: 		throw NotImplementedException("Value type not implemented for deserialization");
573: 	}
574: 	return new_value;
575: }
576: 
577: void Value::Print() {
578: 	Printer::Print(ToString());
579: }
580: 
581: bool Value::ValuesAreEqual(Value result_value, Value value) {
582: 	if (result_value.is_null && value.is_null) {
583: 		// NULL = NULL in checking code
584: 		return true;
585: 	}
586: 	switch (value.type) {
587: 	case TypeId::FLOAT: {
588: 		auto other = result_value.CastAs(TypeId::FLOAT);
589: 		float ldecimal = value.value_.float_;
590: 		float rdecimal = other.value_.float_;
591: 		return ApproxEqual(ldecimal, rdecimal);
592: 	}
593: 	case TypeId::DOUBLE: {
594: 		auto other = result_value.CastAs(TypeId::DOUBLE);
595: 		double ldecimal = value.value_.double_;
596: 		double rdecimal = other.value_.double_;
597: 		return ApproxEqual(ldecimal, rdecimal);
598: 	}
599: 	case TypeId::VARCHAR: {
600: 		auto other = result_value.CastAs(TypeId::VARCHAR);
601: 		// some results might contain padding spaces, e.g. when rendering
602: 		// VARCHAR(10) and the string only has 6 characters, they will be padded
603: 		// with spaces to 10 in the rendering. We don't do that here yet as we
604: 		// are looking at internal structures. So just ignore any extra spaces
605: 		// on the right
606: 		string left = other.str_value;
607: 		string right = value.str_value;
608: 		StringUtil::RTrim(left);
609: 		StringUtil::RTrim(right);
610: 		return left == right;
611: 	}
612: 	default:
613: 		return value == result_value;
614: 	}
615: }
[end of src/common/types/value.cpp]
[start of src/execution/expression_executor.cpp]
1: #include "duckdb/execution/expression_executor.hpp"
2: 
3: #include "duckdb/common/vector_operations/vector_operations.hpp"
4: 
5: using namespace duckdb;
6: using namespace std;
7: 
8: ExpressionExecutor::ExpressionExecutor() {
9: }
10: 
11: ExpressionExecutor::ExpressionExecutor(Expression *expression) {
12: 	assert(expression);
13: 	AddExpression(*expression);
14: }
15: 
16: ExpressionExecutor::ExpressionExecutor(Expression &expression) {
17: 	AddExpression(expression);
18: }
19: 
20: ExpressionExecutor::ExpressionExecutor(vector<unique_ptr<Expression>> &exprs) {
21: 	assert(exprs.size() > 0);
22: 	for (auto &expr : exprs) {
23: 		AddExpression(*expr);
24: 	}
25: }
26: 
27: void ExpressionExecutor::AddExpression(Expression &expr) {
28: 	expressions.push_back(&expr);
29: 	auto state = make_unique<ExpressionExecutorState>();
30: 	Initialize(expr, *state);
31: 	states.push_back(move(state));
32: }
33: 
34: void ExpressionExecutor::Initialize(Expression &expression, ExpressionExecutorState &state) {
35: 	state.root_state = InitializeState(expression, state);
36: 	state.executor = this;
37: }
38: 
39: void ExpressionExecutor::Execute(DataChunk *input, DataChunk &result) {
40: 	SetChunk(input);
41: 
42: 	assert(expressions.size() == result.column_count());
43: 	assert(expressions.size() > 0);
44: 	result.Reset();
45: 	for (idx_t i = 0; i < expressions.size(); i++) {
46: 		ExecuteExpression(i, result.data[i]);
47: 	}
48: 	result.SetCardinality(input ? input->size() : 1);
49: 	result.Verify();
50: }
51: 
52: void ExpressionExecutor::ExecuteExpression(DataChunk &input, Vector &result) {
53: 	SetChunk(&input);
54: 	ExecuteExpression(result);
55: }
56: 
57: idx_t ExpressionExecutor::SelectExpression(DataChunk &input, SelectionVector &sel) {
58: 	assert(expressions.size() == 1);
59: 	SetChunk(&input);
60: 	return Select(*expressions[0], states[0]->root_state.get(), nullptr, input.size(), &sel, nullptr);
61: }
62: 
63: void ExpressionExecutor::ExecuteExpression(Vector &result) {
64: 	assert(expressions.size() == 1);
65: 	ExecuteExpression(0, result);
66: }
67: 
68: void ExpressionExecutor::ExecuteExpression(idx_t expr_idx, Vector &result) {
69: 	assert(expr_idx < expressions.size());
70: 	assert(result.type == expressions[expr_idx]->return_type);
71: 	Execute(*expressions[expr_idx], states[expr_idx]->root_state.get(), nullptr, chunk ? chunk->size() : 1, result);
72: }
73: 
74: Value ExpressionExecutor::EvaluateScalar(Expression &expr) {
75: 	assert(expr.IsFoldable());
76: 	// use an ExpressionExecutor to execute the expression
77: 	ExpressionExecutor executor(expr);
78: 
79: 	Vector result(expr.return_type);
80: 	executor.ExecuteExpression(result);
81: 
82: 	assert(result.vector_type == VectorType::CONSTANT_VECTOR);
83: 	return result.GetValue(0);
84: }
85: 
86: void ExpressionExecutor::Verify(Expression &expr, Vector &vector, idx_t count) {
87: 	assert(expr.return_type == vector.type);
88: 	vector.Verify(count);
89: }
90: 
91: unique_ptr<ExpressionState> ExpressionExecutor::InitializeState(Expression &expr, ExpressionExecutorState &state) {
92: 	switch (expr.expression_class) {
93: 	case ExpressionClass::BOUND_REF:
94: 		return InitializeState((BoundReferenceExpression &)expr, state);
95: 	case ExpressionClass::BOUND_BETWEEN:
96: 		return InitializeState((BoundBetweenExpression &)expr, state);
97: 	case ExpressionClass::BOUND_CASE:
98: 		return InitializeState((BoundCaseExpression &)expr, state);
99: 	case ExpressionClass::BOUND_CAST:
100: 		return InitializeState((BoundCastExpression &)expr, state);
101: 	case ExpressionClass::BOUND_COMPARISON:
102: 		return InitializeState((BoundComparisonExpression &)expr, state);
103: 	case ExpressionClass::BOUND_CONJUNCTION:
104: 		return InitializeState((BoundConjunctionExpression &)expr, state);
105: 	case ExpressionClass::BOUND_CONSTANT:
106: 		return InitializeState((BoundConstantExpression &)expr, state);
107: 	case ExpressionClass::BOUND_FUNCTION:
108: 		return InitializeState((BoundFunctionExpression &)expr, state);
109: 	case ExpressionClass::BOUND_OPERATOR:
110: 		return InitializeState((BoundOperatorExpression &)expr, state);
111: 	case ExpressionClass::BOUND_PARAMETER:
112: 		return InitializeState((BoundParameterExpression &)expr, state);
113: 	default:
114: 		throw NotImplementedException("Attempting to initialize state of expression of unknown type!");
115: 	}
116: }
117: 
118: void ExpressionExecutor::Execute(Expression &expr, ExpressionState *state, const SelectionVector *sel, idx_t count,
119:                                  Vector &result) {
120: 	switch (expr.expression_class) {
121: 	case ExpressionClass::BOUND_BETWEEN:
122: 		Execute((BoundBetweenExpression &)expr, state, sel, count, result);
123: 		break;
124: 	case ExpressionClass::BOUND_REF:
125: 		Execute((BoundReferenceExpression &)expr, state, sel, count, result);
126: 		break;
127: 	case ExpressionClass::BOUND_CASE:
128: 		Execute((BoundCaseExpression &)expr, state, sel, count, result);
129: 		break;
130: 	case ExpressionClass::BOUND_CAST:
131: 		Execute((BoundCastExpression &)expr, state, sel, count, result);
132: 		break;
133: 	case ExpressionClass::BOUND_COMPARISON:
134: 		Execute((BoundComparisonExpression &)expr, state, sel, count, result);
135: 		break;
136: 	case ExpressionClass::BOUND_CONJUNCTION:
137: 		Execute((BoundConjunctionExpression &)expr, state, sel, count, result);
138: 		break;
139: 	case ExpressionClass::BOUND_CONSTANT:
140: 		Execute((BoundConstantExpression &)expr, state, sel, count, result);
141: 		break;
142: 	case ExpressionClass::BOUND_FUNCTION:
143: 		Execute((BoundFunctionExpression &)expr, state, sel, count, result);
144: 		break;
145: 	case ExpressionClass::BOUND_OPERATOR:
146: 		Execute((BoundOperatorExpression &)expr, state, sel, count, result);
147: 		break;
148: 	case ExpressionClass::BOUND_PARAMETER:
149: 		Execute((BoundParameterExpression &)expr, state, sel, count, result);
150: 		break;
151: 	default:
152: 		throw NotImplementedException("Attempting to execute expression of unknown type!");
153: 	}
154: 	Verify(expr, result, count);
155: }
156: 
157: idx_t ExpressionExecutor::Select(Expression &expr, ExpressionState *state, const SelectionVector *sel, idx_t count,
158:                                  SelectionVector *true_sel, SelectionVector *false_sel) {
159: 	assert(true_sel || false_sel);
160: 	assert(expr.return_type == TypeId::BOOL);
161: 	switch (expr.expression_class) {
162: 	case ExpressionClass::BOUND_BETWEEN:
163: 		return Select((BoundBetweenExpression &)expr, state, sel, count, true_sel, false_sel);
164: 	case ExpressionClass::BOUND_COMPARISON:
165: 		return Select((BoundComparisonExpression &)expr, state, sel, count, true_sel, false_sel);
166: 	case ExpressionClass::BOUND_CONJUNCTION:
167: 		return Select((BoundConjunctionExpression &)expr, state, sel, count, true_sel, false_sel);
168: 	default:
169: 		return DefaultSelect(expr, state, sel, count, true_sel, false_sel);
170: 	}
171: }
172: 
173: template <bool NO_NULL, bool HAS_TRUE_SEL, bool HAS_FALSE_SEL>
174: static inline idx_t DefaultSelectLoop(const SelectionVector *bsel, bool *__restrict bdata, nullmask_t &nullmask,
175:                                       const SelectionVector *sel, idx_t count, SelectionVector *true_sel,
176:                                       SelectionVector *false_sel) {
177: 	idx_t true_count = 0, false_count = 0;
178: 	for (idx_t i = 0; i < count; i++) {
179: 		auto bidx = bsel->get_index(i);
180: 		auto result_idx = sel->get_index(i);
181: 		if (bdata[bidx] && (NO_NULL || !nullmask[bidx])) {
182: 			if (HAS_TRUE_SEL) {
183: 				true_sel->set_index(true_count++, result_idx);
184: 			}
185: 		} else {
186: 			if (HAS_FALSE_SEL) {
187: 				false_sel->set_index(false_count++, result_idx);
188: 			}
189: 		}
190: 	}
191: 	if (HAS_TRUE_SEL) {
192: 		return true_count;
193: 	} else {
194: 		return count - false_count;
195: 	}
196: }
197: 
198: template <bool NO_NULL>
199: static inline idx_t DefaultSelectSwitch(VectorData &idata, const SelectionVector *sel, idx_t count,
200:                                         SelectionVector *true_sel, SelectionVector *false_sel) {
201: 	if (true_sel && false_sel) {
202: 		return DefaultSelectLoop<NO_NULL, true, true>(idata.sel, (bool *)idata.data, *idata.nullmask, sel, count,
203: 		                                              true_sel, false_sel);
204: 	} else if (true_sel) {
205: 		return DefaultSelectLoop<NO_NULL, true, false>(idata.sel, (bool *)idata.data, *idata.nullmask, sel, count,
206: 		                                               true_sel, false_sel);
207: 	} else {
208: 		assert(false_sel);
209: 		return DefaultSelectLoop<NO_NULL, false, true>(idata.sel, (bool *)idata.data, *idata.nullmask, sel, count,
210: 		                                               true_sel, false_sel);
211: 	}
212: }
213: 
214: idx_t ExpressionExecutor::DefaultSelect(Expression &expr, ExpressionState *state, const SelectionVector *sel,
215:                                         idx_t count, SelectionVector *true_sel, SelectionVector *false_sel) {
216: 	// generic selection of boolean expression:
217: 	// resolve the true/false expression first
218: 	// then use that to generate the selection vector
219: 	bool intermediate_bools[STANDARD_VECTOR_SIZE];
220: 	Vector intermediate(TypeId::BOOL, (data_ptr_t)intermediate_bools);
221: 	Execute(expr, state, sel, count, intermediate);
222: 
223: 	VectorData idata;
224: 	intermediate.Orrify(count, idata);
225: 	if (!sel) {
226: 		sel = &FlatVector::IncrementalSelectionVector;
227: 	}
228: 	if (idata.nullmask->any()) {
229: 		return DefaultSelectSwitch<false>(idata, sel, count, true_sel, false_sel);
230: 	} else {
231: 		return DefaultSelectSwitch<true>(idata, sel, count, true_sel, false_sel);
232: 	}
233: }
[end of src/execution/expression_executor.cpp]
[start of src/execution/expression_executor/execute_cast.cpp]
1: #include "duckdb/common/vector_operations/vector_operations.hpp"
2: #include "duckdb/execution/expression_executor.hpp"
3: #include "duckdb/planner/expression/bound_cast_expression.hpp"
4: 
5: using namespace duckdb;
6: using namespace std;
7: 
8: unique_ptr<ExpressionState> ExpressionExecutor::InitializeState(BoundCastExpression &expr,
9:                                                                 ExpressionExecutorState &root) {
10: 	auto result = make_unique<ExpressionState>(expr, root);
11: 	result->AddChild(expr.child.get());
12: 	return result;
13: }
14: 
15: void ExpressionExecutor::Execute(BoundCastExpression &expr, ExpressionState *state, const SelectionVector *sel,
16:                                  idx_t count, Vector &result) {
17: 	// resolve the child
18: 	Vector child(expr.child->return_type);
19: 	auto child_state = state->child_states[0].get();
20: 
21: 	Execute(*expr.child, child_state, sel, count, child);
22: 	if (child.type == expr.return_type) {
23: 		// NOP cast
24: 		result.Reference(child);
25: 	} else {
26: 		// cast it to the type specified by the cast expression
27: 		VectorOperations::Cast(child, result, expr.source_type, expr.target_type, count);
28: 	}
29: }
[end of src/execution/expression_executor/execute_cast.cpp]
[start of src/execution/physical_plan/plan_filter.cpp]
1: #include "duckdb/execution/operator/filter/physical_filter.hpp"
2: #include "duckdb/execution/operator/projection/physical_projection.hpp"
3: #include "duckdb/execution/physical_plan_generator.hpp"
4: #include "duckdb/optimizer/matcher/expression_matcher.hpp"
5: #include "duckdb/planner/expression/bound_comparison_expression.hpp"
6: #include "duckdb/planner/expression/bound_constant_expression.hpp"
7: #include "duckdb/planner/expression/bound_reference_expression.hpp"
8: #include "duckdb/planner/operator/logical_filter.hpp"
9: #include "duckdb/planner/operator/logical_get.hpp"
10: 
11: using namespace duckdb;
12: using namespace std;
13: 
14: unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalFilter &op) {
15: 	assert(op.children.size() == 1);
16: 	unique_ptr<PhysicalOperator> plan = CreatePlan(*op.children[0]);
17: 	if (op.expressions.size() > 0) {
18: 		// create a filter if there is anything to filter
19: 		auto filter = make_unique<PhysicalFilter>(op.children[0]->types, move(op.expressions));
20: 		filter->children.push_back(move(plan));
21: 		plan = move(filter);
22: 
23: 		if (op.projection_map.size() > 0) {
24: 			// there is a projection map, generate a physical projection
25: 			vector<unique_ptr<Expression>> select_list;
26: 			for (idx_t i = 0; i < op.projection_map.size(); i++) {
27: 				select_list.push_back(make_unique<BoundReferenceExpression>(op.types[i], op.projection_map[i]));
28: 			}
29: 			auto proj = make_unique<PhysicalProjection>(op.types, move(select_list));
30: 			proj->children.push_back(move(plan));
31: 			plan = move(proj);
32: 		}
33: 	}
34: 	return plan;
35: }
[end of src/execution/physical_plan/plan_filter.cpp]
[start of src/function/aggregate/distributive/minmax.cpp]
1: #include "duckdb/function/aggregate/distributive_functions.hpp"
2: #include "duckdb/common/exception.hpp"
3: #include "duckdb/common/vector_operations/vector_operations.hpp"
4: #include "duckdb/common/operator/comparison_operators.hpp"
5: #include "duckdb/common/vector_operations/aggregate_executor.hpp"
6: #include "duckdb/common/operator/aggregate_operators.hpp"
7: #include "duckdb/common/types/null_value.hpp"
8: 
9: using namespace std;
10: 
11: namespace duckdb {
12: 
13: struct MinMaxBase : public StandardDistributiveFunction {
14: 	template <class INPUT_TYPE, class STATE, class OP>
15: 	static void ConstantOperation(STATE *state, INPUT_TYPE *input, nullmask_t &nullmask, idx_t count) {
16: 		assert(!nullmask[0]);
17: 		if (IsNullValue<INPUT_TYPE>(*state)) {
18: 			*state = input[0];
19: 		} else {
20: 			OP::template Execute<INPUT_TYPE, STATE>(state, input[0]);
21: 		}
22: 	}
23: };
24: 
25: struct MinOperation : public MinMaxBase {
26: 	template <class INPUT_TYPE, class STATE> static void Execute(STATE *state, INPUT_TYPE input) {
27: 		if (LessThan::Operation<INPUT_TYPE>(input, *state)) {
28: 			*state = input;
29: 		}
30: 	}
31: };
32: 
33: struct MaxOperation : public MinMaxBase {
34: 	template <class INPUT_TYPE, class STATE> static void Execute(STATE *state, INPUT_TYPE input) {
35: 		if (GreaterThan::Operation<INPUT_TYPE>(input, *state)) {
36: 			*state = input;
37: 		}
38: 	}
39: };
40: 
41: void MinFun::RegisterFunction(BuiltinFunctions &set) {
42: 	AggregateFunctionSet min("min");
43: 	for (auto type : SQLType::ALL_TYPES) {
44: 		min.AddFunction(AggregateFunction::GetUnaryAggregate<MinOperation>(type));
45: 	}
46: 	set.AddFunction(min);
47: }
48: 
49: void MaxFun::RegisterFunction(BuiltinFunctions &set) {
50: 	AggregateFunctionSet max("max");
51: 	for (auto type : SQLType::ALL_TYPES) {
52: 		max.AddFunction(AggregateFunction::GetUnaryAggregate<MaxOperation>(type));
53: 	}
54: 	set.AddFunction(max);
55: }
56: 
57: } // namespace duckdb
[end of src/function/aggregate/distributive/minmax.cpp]
[start of src/function/aggregate/distributive/sum.cpp]
1: #include "duckdb/function/aggregate/distributive_functions.hpp"
2: #include "duckdb/common/exception.hpp"
3: #include "duckdb/common/types/null_value.hpp"
4: #include "duckdb/common/vector_operations/vector_operations.hpp"
5: #include "duckdb/common/vector_operations/aggregate_executor.hpp"
6: #include "duckdb/common/operator/numeric_binary_operators.hpp"
7: 
8: using namespace std;
9: 
10: namespace duckdb {
11: 
12: struct SumOperation : public StandardDistributiveFunction {
13: 	template <class INPUT_TYPE, class STATE> static void Execute(STATE *state, INPUT_TYPE input) {
14: 		*state += input;
15: 	}
16: 
17: 	template <class INPUT_TYPE, class STATE, class OP>
18: 	static void ConstantOperation(STATE *state, INPUT_TYPE *input, nullmask_t &nullmask, idx_t count) {
19: 		assert(!nullmask[0]);
20: 		if (IsNullValue<INPUT_TYPE>(*state)) {
21: 			*state = 0;
22: 		}
23: 		*state += input[0] * count;
24: 	}
25: };
26: 
27: void SumFun::RegisterFunction(BuiltinFunctions &set) {
28: 	AggregateFunctionSet sum("sum");
29: 	// integer sums to bigint
30: 	sum.AddFunction(
31: 	    AggregateFunction::UnaryAggregate<int64_t, int64_t, int64_t, SumOperation>(SQLType::BIGINT, SQLType::BIGINT));
32: 	// float sums to float
33: 	sum.AddFunction(
34: 	    AggregateFunction::UnaryAggregate<double, double, double, SumOperation>(SQLType::DOUBLE, SQLType::DOUBLE));
35: 
36: 	set.AddFunction(sum);
37: }
38: 
39: } // namespace duckdb
[end of src/function/aggregate/distributive/sum.cpp]
[start of src/function/scalar/math/numeric.cpp]
1: #include "duckdb/function/scalar/math_functions.hpp"
2: #include "duckdb/common/vector_operations/vector_operations.hpp"
3: 
4: #include <algorithm>
5: #include <cmath>
6: 
7: using namespace std;
8: 
9: namespace duckdb {
10: 
11: //===--------------------------------------------------------------------===//
12: // abs
13: //===--------------------------------------------------------------------===//
14: struct AbsOperator {
15: 	template <class TA, class TR> static inline TR Operation(TA left) {
16: 		return left < 0 ? left * -1 : left;
17: 	}
18: };
19: 
20: void AbsFun::RegisterFunction(BuiltinFunctions &set) {
21: 	ScalarFunctionSet abs("abs");
22: 	for (auto &type : SQLType::NUMERIC) {
23: 		abs.AddFunction(ScalarFunction({type}, type, ScalarFunction::GetScalarUnaryFunction<AbsOperator>(type)));
24: 	}
25: 	set.AddFunction(abs);
26: }
27: 
28: //===--------------------------------------------------------------------===//
29: // sign
30: //===--------------------------------------------------------------------===//
31: struct SignOperator {
32: 	template <class TA, class TR> static inline TR Operation(TA left) {
33: 		if (left == TA(0))
34: 			return 0;
35: 		else if (left > TA(0))
36: 			return 1;
37: 		else
38: 			return -1;
39: 	}
40: };
41: 
42: void SignFun::RegisterFunction(BuiltinFunctions &set) {
43: 	ScalarFunctionSet sign("sign");
44: 	for (auto &type : SQLType::NUMERIC) {
45: 		sign.AddFunction(ScalarFunction({type}, SQLType::TINYINT,
46: 		                                ScalarFunction::GetScalarUnaryFunctionFixedReturn<int8_t, SignOperator>(type)));
47: 	}
48: 	set.AddFunction(sign);
49: }
50: 
51: //===--------------------------------------------------------------------===//
52: // ceil
53: //===--------------------------------------------------------------------===//
54: struct CeilOperator {
55: 	template <class TA, class TR> static inline TR Operation(TA left) {
56: 		return ceil(left);
57: 	}
58: };
59: 
60: void CeilFun::RegisterFunction(BuiltinFunctions &set) {
61: 	ScalarFunctionSet ceil("ceil");
62: 	for (auto &type : SQLType::NUMERIC) {
63: 		scalar_function_t func;
64: 		if (type.IsIntegral()) {
65: 			// ceil on integral type is a nop
66: 			func = ScalarFunction::NopFunction;
67: 		} else {
68: 			func = ScalarFunction::GetScalarUnaryFunction<CeilOperator>(type);
69: 		}
70: 		ceil.AddFunction(ScalarFunction({type}, type, func));
71: 	}
72: 	set.AddFunction(ceil);
73: 	ceil.name = "ceiling";
74: 	set.AddFunction(ceil);
75: }
76: 
77: //===--------------------------------------------------------------------===//
78: // floor
79: //===--------------------------------------------------------------------===//
80: struct FloorOperator {
81: 	template <class TA, class TR> static inline TR Operation(TA left) {
82: 		return floor(left);
83: 	}
84: };
85: 
86: void FloorFun::RegisterFunction(BuiltinFunctions &set) {
87: 	ScalarFunctionSet floor("floor");
88: 	for (auto &type : SQLType::NUMERIC) {
89: 		scalar_function_t func;
90: 		if (type.IsIntegral()) {
91: 			// floor on integral type is a nop
92: 			func = ScalarFunction::NopFunction;
93: 		} else {
94: 			func = ScalarFunction::GetScalarUnaryFunction<FloorOperator>(type);
95: 		}
96: 		floor.AddFunction(ScalarFunction({type}, type, func));
97: 	}
98: 	set.AddFunction(floor);
99: }
100: 
101: //===--------------------------------------------------------------------===//
102: // round
103: //===--------------------------------------------------------------------===//
104: struct RoundOperator {
105: 	template <class TA, class TB, class TR> static inline TR Operation(TA input, TB precision) {
106: 		if (precision < 0) {
107: 			precision = 0;
108: 		}
109: 		TA modifier = pow(10, precision);
110: 		return (round(input * modifier)) / modifier;
111: 	}
112: };
113: 
114: void RoundFun::RegisterFunction(BuiltinFunctions &set) {
115: 	ScalarFunctionSet round("round");
116: 	for (auto &type : SQLType::NUMERIC) {
117: 		scalar_function_t func;
118: 		if (type.IsIntegral()) {
119: 			// round on integral type is a nop
120: 			func = ScalarFunction::NopFunction;
121: 		} else if (type.id == SQLTypeId::FLOAT) {
122: 			func = ScalarFunction::BinaryFunction<float, int32_t, float, RoundOperator>;
123: 		} else {
124: 			assert(type.id == SQLTypeId::DOUBLE || type.id == SQLTypeId::DECIMAL);
125: 			func = ScalarFunction::BinaryFunction<double, int32_t, double, RoundOperator>;
126: 		}
127: 		round.AddFunction(ScalarFunction({type, SQLType::INTEGER}, type, func));
128: 	}
129: 	set.AddFunction(round);
130: }
131: 
132: //===--------------------------------------------------------------------===//
133: // exp
134: //===--------------------------------------------------------------------===//
135: struct ExpOperator {
136: 	template <class TA, class TR> static inline TR Operation(TA left) {
137: 		return exp(left);
138: 	}
139: };
140: 
141: void ExpFun::RegisterFunction(BuiltinFunctions &set) {
142: 	set.AddFunction(ScalarFunction("exp", {SQLType::DOUBLE}, SQLType::DOUBLE,
143: 	                               ScalarFunction::UnaryFunction<double, double, ExpOperator>));
144: }
145: 
146: //===--------------------------------------------------------------------===//
147: // pow
148: //===--------------------------------------------------------------------===//
149: struct PowOperator {
150: 	template <class TA, class TB, class TR> static inline TR Operation(TA base, TB exponent) {
151: 		return pow(base, exponent);
152: 	}
153: };
154: 
155: void PowFun::RegisterFunction(BuiltinFunctions &set) {
156: 	ScalarFunction power_function("pow", {SQLType::DOUBLE, SQLType::DOUBLE}, SQLType::DOUBLE,
157: 	                              ScalarFunction::BinaryFunction<double, double, double, PowOperator>);
158: 	set.AddFunction(power_function);
159: 	power_function.name = "power";
160: 	set.AddFunction(power_function);
161: }
162: 
163: //===--------------------------------------------------------------------===//
164: // Unary wrappers to turn values < 0 or <= 0 into NULL
165: //===--------------------------------------------------------------------===//
166: struct UnaryNegativeWrapper {
167: 	template <class FUNC, class OP, class INPUT_TYPE, class RESULT_TYPE>
168: 	static inline RESULT_TYPE Operation(FUNC fun, INPUT_TYPE input, nullmask_t &nullmask, idx_t idx) {
169: 		if (input < 0) {
170: 			nullmask[idx] = true;
171: 			return 0;
172: 		} else {
173: 			return OP::template Operation<INPUT_TYPE, RESULT_TYPE>(input);
174: 		}
175: 	}
176: };
177: 
178: struct UnaryZeroOrNegativeWrapper {
179: 	template <class FUNC, class OP, class INPUT_TYPE, class RESULT_TYPE>
180: 	static inline RESULT_TYPE Operation(FUNC fun, INPUT_TYPE input, nullmask_t &nullmask, idx_t idx) {
181: 		if (input <= 0) {
182: 			nullmask[idx] = true;
183: 			return 0;
184: 		} else {
185: 			return OP::template Operation<INPUT_TYPE, RESULT_TYPE>(input);
186: 		}
187: 	}
188: };
189: 
190: template <class T, class OP, class OPWRAPPER>
191: static void UnaryScalarFunctionWrapper(DataChunk &input, ExpressionState &state, Vector &result) {
192: 	UnaryExecutor::Execute<T, T, OP, true, OPWRAPPER>(input.data[0], result, input.size());
193: }
194: //===--------------------------------------------------------------------===//
195: // sqrt
196: //===--------------------------------------------------------------------===//
197: struct SqrtOperator {
198: 	template <class TA, class TR> static inline TR Operation(TA left) {
199: 		return sqrt(left);
200: 	}
201: };
202: 
203: void SqrtFun::RegisterFunction(BuiltinFunctions &set) {
204: 	set.AddFunction(ScalarFunction("sqrt", {SQLType::DOUBLE}, SQLType::DOUBLE,
205: 	                               UnaryScalarFunctionWrapper<double, SqrtOperator, UnaryNegativeWrapper>));
206: }
207: 
208: //===--------------------------------------------------------------------===//
209: // cbrt
210: //===--------------------------------------------------------------------===//
211: struct CbRtOperator {
212: 	template <class TA, class TR> static inline TR Operation(TA left) {
213: 		return cbrt(left);
214: 	}
215: };
216: 
217: void CbrtFun::RegisterFunction(BuiltinFunctions &set) {
218: 	set.AddFunction(ScalarFunction("cbrt", {SQLType::DOUBLE}, SQLType::DOUBLE,
219: 	                               ScalarFunction::UnaryFunction<double, double, CbRtOperator>));
220: }
221: 
222: //===--------------------------------------------------------------------===//
223: // ln
224: //===--------------------------------------------------------------------===//
225: 
226: struct LnOperator {
227: 	template <class TA, class TR> static inline TR Operation(TA left) {
228: 		return log(left);
229: 	}
230: };
231: 
232: void LnFun::RegisterFunction(BuiltinFunctions &set) {
233: 	set.AddFunction(ScalarFunction("ln", {SQLType::DOUBLE}, SQLType::DOUBLE,
234: 	                               UnaryScalarFunctionWrapper<double, LnOperator, UnaryZeroOrNegativeWrapper>));
235: }
236: 
237: //===--------------------------------------------------------------------===//
238: // log
239: //===--------------------------------------------------------------------===//
240: struct Log10Operator {
241: 	template <class TA, class TR> static inline TR Operation(TA left) {
242: 		return log10(left);
243: 	}
244: };
245: 
246: void Log10Fun::RegisterFunction(BuiltinFunctions &set) {
247: 	ScalarFunction log_function("log10", {SQLType::DOUBLE}, SQLType::DOUBLE,
248: 	                               UnaryScalarFunctionWrapper<double, Log10Operator, UnaryZeroOrNegativeWrapper>);
249: 	set.AddFunction(log_function);
250: 	// "log" is an alias for "log10"
251: 	log_function.name = "log";
252: 	set.AddFunction(log_function);
253: }
254: 
255: //===--------------------------------------------------------------------===//
256: // log2
257: //===--------------------------------------------------------------------===//
258: struct Log2Operator {
259: 	template <class TA, class TR> static inline TR Operation(TA left) {
260: 		return log2(left);
261: 	}
262: };
263: 
264: void Log2Fun::RegisterFunction(BuiltinFunctions &set) {
265: 	set.AddFunction(ScalarFunction("log2", {SQLType::DOUBLE}, SQLType::DOUBLE,
266: 	                               UnaryScalarFunctionWrapper<double, Log2Operator, UnaryZeroOrNegativeWrapper>));
267: }
268: 
269: //===--------------------------------------------------------------------===//
270: // pi
271: //===--------------------------------------------------------------------===//
272: Value pi_value = Value::DOUBLE(PI);
273: 
274: static void pi_function(DataChunk &args, ExpressionState &state, Vector &result) {
275: 	assert(args.column_count() == 0);
276: 	result.Reference(pi_value);
277: }
278: 
279: void PiFun::RegisterFunction(BuiltinFunctions &set) {
280: 	set.AddFunction(ScalarFunction("pi", {}, SQLType::DOUBLE, pi_function));
281: }
282: 
283: //===--------------------------------------------------------------------===//
284: // degrees
285: //===--------------------------------------------------------------------===//
286: struct DegreesOperator {
287: 	template <class TA, class TR> static inline TR Operation(TA left) {
288: 		return left * (180 / PI);
289: 	}
290: };
291: 
292: void DegreesFun::RegisterFunction(BuiltinFunctions &set) {
293: 	set.AddFunction(ScalarFunction("degrees", {SQLType::DOUBLE}, SQLType::DOUBLE,
294: 	                               ScalarFunction::UnaryFunction<double, double, DegreesOperator>));
295: }
296: 
297: //===--------------------------------------------------------------------===//
298: // radians
299: //===--------------------------------------------------------------------===//
300: struct RadiansOperator {
301: 	template <class TA, class TR> static inline TR Operation(TA left) {
302: 		return left * (PI / 180);
303: 	}
304: };
305: 
306: void RadiansFun::RegisterFunction(BuiltinFunctions &set) {
307: 	set.AddFunction(ScalarFunction("radians", {SQLType::DOUBLE}, SQLType::DOUBLE,
308: 	                               ScalarFunction::UnaryFunction<double, double, RadiansOperator>));
309: }
310: 
311: } // namespace duckdb
[end of src/function/scalar/math/numeric.cpp]
[start of src/function/scalar/string/reverse.cpp]
1: #include "duckdb/function/scalar/string_functions.hpp"
2: 
3: #include "duckdb/common/exception.hpp"
4: #include "duckdb/common/vector_operations/vector_operations.hpp"
5: #include "duckdb/common/vector_operations/unary_executor.hpp"
6: 
7: #include <string.h>
8: 
9: using namespace std;
10: 
11: namespace duckdb {
12: 
13: static void strreverse(const char *input, idx_t n, char *output) {
14: 	idx_t bytes = 0;
15: 
16: 	output[n] = 0;
17: 
18: 	while (*input) {
19: 		if (!(*input & 0x80)) { // !*input & 0b10000000
20: 			bytes = 1;
21: 		} else if ((*input & 0xe0) == 0xc0) { // (*input & 0b1110_0000 == 0b1100_0000)
22: 			bytes = 2;
23: 		} else if ((*input & 0xf0) == 0xe0) { // (*input & 0b1111_0000 == 0b1110_0000)
24: 			bytes = 3;
25: 		} else if ((*input & 0xf8) == 0xf0) { // (*input & 0b1111_1000 == 0b1111_0000)
26: 			bytes = 4;
27: 		} else {
28: 			assert(false);
29: 		}
30: 
31: 		memcpy(&output[n - bytes], input, bytes);
32: 		input += bytes;
33: 		n -= bytes;
34: 	}
35: }
36: 
37: static void reverse_chunk_function(DataChunk &args, ExpressionState &state, Vector &result) {
38: 	assert(args.column_count() == 1);
39: 	assert(args.data[0].type == TypeId::VARCHAR);
40: 
41: 	UnaryExecutor::Execute<string_t, string_t, true>(args.data[0], result, args.size(), [&](string_t input) {
42: 		auto input_data = input.GetData();
43: 		auto input_length = input.GetSize();
44: 
45: 		auto target = StringVector::EmptyString(result, input_length);
46: 		strreverse(input_data, input_length, target.GetData());
47: 		return target;
48: 	});
49: }
50: 
51: void ReverseFun::RegisterFunction(BuiltinFunctions &set) {
52: 	set.AddFunction(ScalarFunction("reverse", {SQLType::VARCHAR}, SQLType::VARCHAR, reverse_chunk_function));
53: }
54: 
55: } // namespace duckdb
[end of src/function/scalar/string/reverse.cpp]
[start of src/include/duckdb/common/types.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/common/types.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/assert.hpp"
12: #include "duckdb/common/constants.hpp"
13: 
14: #include <type_traits>
15: 
16: namespace duckdb {
17: 
18: class Serializer;
19: class Deserializer;
20: 
21: struct blob_t {
22: 	data_ptr_t data;
23: 	idx_t size;
24: };
25: 
26: struct string_t;
27: 
28: template <class T> using child_list_t = std::vector<std::pair<std::string, T>>;
29: template <class T> using buffer_ptr = std::shared_ptr<T>;
30: 
31: template <class T, typename... Args> buffer_ptr<T> make_buffer(Args &&... args) {
32: 	return std::make_shared<T>(std::forward<Args>(args)...);
33: }
34: 
35: struct list_entry_t {
36: 	list_entry_t() = default;
37: 	list_entry_t(uint64_t offset, uint64_t length) : offset(offset), length(length) {
38: 	}
39: 
40: 	uint64_t offset;
41: 	uint64_t length;
42: };
43: 
44: //===--------------------------------------------------------------------===//
45: // Internal Types
46: //===--------------------------------------------------------------------===//
47: 
48: // taken from arrow's type.h
49: enum class TypeId : uint8_t {
50: 	/// A NULL type having no physical storage
51: 	NA = 0,
52: 
53: 	/// Boolean as 1 bit, LSB bit-packed ordering
54: 	BOOL = 1,
55: 
56: 	/// Unsigned 8-bit little-endian integer
57: 	UINT8 = 2,
58: 
59: 	/// Signed 8-bit little-endian integer
60: 	INT8 = 3,
61: 
62: 	/// Unsigned 16-bit little-endian integer
63: 	UINT16 = 4,
64: 
65: 	/// Signed 16-bit little-endian integer
66: 	INT16 = 5,
67: 
68: 	/// Unsigned 32-bit little-endian integer
69: 	UINT32 = 6,
70: 
71: 	/// Signed 32-bit little-endian integer
72: 	INT32 = 7,
73: 
74: 	/// Unsigned 64-bit little-endian integer
75: 	UINT64 = 8,
76: 
77: 	/// Signed 64-bit little-endian integer
78: 	INT64 = 9,
79: 
80: 	/// 2-byte floating point value
81: 	HALF_FLOAT = 10,
82: 
83: 	/// 4-byte floating point value
84: 	FLOAT = 11,
85: 
86: 	/// 8-byte floating point value
87: 	DOUBLE = 12,
88: 
89: 	/// UTF8 variable-length string as List<Char>
90: 	STRING = 13,
91: 
92: 	/// Variable-length bytes (no guarantee of UTF8-ness)
93: 	BINARY = 14,
94: 
95: 	/// Fixed-size binary. Each value occupies the same number of bytes
96: 	FIXED_SIZE_BINARY = 15,
97: 
98: 	/// int32_t days since the UNIX epoch
99: 	DATE32 = 16,
100: 
101: 	/// int64_t milliseconds since the UNIX epoch
102: 	DATE64 = 17,
103: 
104: 	/// Exact timestamp encoded with int64 since UNIX epoch
105: 	/// Default unit millisecond
106: 	TIMESTAMP = 18,
107: 
108: 	/// Time as signed 32-bit integer, representing either seconds or
109: 	/// milliseconds since midnight
110: 	TIME32 = 19,
111: 
112: 	/// Time as signed 64-bit integer, representing either microseconds or
113: 	/// nanoseconds since midnight
114: 	TIME64 = 20,
115: 
116: 	/// YEAR_MONTH or DAY_TIME interval in SQL style
117: 	INTERVAL = 21,
118: 
119: 	/// Precision- and scale-based decimal type. Storage type depends on the
120: 	/// parameters.
121: 	DECIMAL = 22,
122: 
123: 	/// A list of some logical data type
124: 	LIST = 23,
125: 
126: 	/// Struct of logical types
127: 	STRUCT = 24,
128: 
129: 	/// Unions of logical types
130: 	UNION = 25,
131: 
132: 	/// Dictionary-encoded type, also called "categorical" or "factor"
133: 	/// in other programming languages. Holds the dictionary value
134: 	/// type but not the dictionary itself, which is part of the
135: 	/// ArrayData struct
136: 	DICTIONARY = 26,
137: 
138: 	/// Map, a repeated struct logical type
139: 	MAP = 27,
140: 
141: 	/// Custom data type, implemented by user
142: 	EXTENSION = 28,
143: 
144: 	/// Fixed size list of some logical type
145: 	FIXED_SIZE_LIST = 29,
146: 
147: 	/// Measure of elapsed time in either seconds, milliseconds, microseconds
148: 	/// or nanoseconds.
149: 	DURATION = 30,
150: 
151: 	/// Like STRING, but with 64-bit offsets
152: 	LARGE_STRING = 31,
153: 
154: 	/// Like BINARY, but with 64-bit offsets
155: 	LARGE_BINARY = 32,
156: 
157: 	/// Like LIST, but with 64-bit offsets
158: 	LARGE_LIST = 33,
159: 
160: 	// DuckDB Extensions
161: 	VARCHAR = 200, // our own string representation, different from STRING and LARGE_STRING above
162: 	VARBINARY = 201,
163: 	POINTER = 202,
164: 	HASH = 203,
165: 
166: 	INVALID = 255
167: };
168: 
169: //===--------------------------------------------------------------------===//
170: // SQL Types
171: //===--------------------------------------------------------------------===//
172: enum class SQLTypeId : uint8_t {
173: 	INVALID = 0,
174: 	SQLNULL = 1, /* NULL type, used for constant NULL */
175: 	UNKNOWN = 2, /* unknown type, used for parameter expressions */
176: 	ANY = 3,     /* ANY type, used for functions that accept any type as parameter */
177: 
178: 	BOOLEAN = 10,
179: 	TINYINT = 11,
180: 	SMALLINT = 12,
181: 	INTEGER = 13,
182: 	BIGINT = 14,
183: 	DATE = 15,
184: 	TIME = 16,
185: 	TIMESTAMP = 17,
186: 	FLOAT = 18,
187: 	DOUBLE = 19,
188: 	DECIMAL = 20,
189: 	CHAR = 21,
190: 	VARCHAR = 22,
191: 	VARBINARY = 23,
192: 
193: 	STRUCT = 100,
194: 	LIST = 101
195: };
196: 
197: struct SQLType {
198: 	SQLTypeId id;
199: 	uint16_t width;
200: 	uint8_t scale;
201: 
202: 	// TODO serialize this
203: 	child_list_t<SQLType> child_type;
204: 
205: 	SQLType(SQLTypeId id = SQLTypeId::INVALID, uint16_t width = 0, uint8_t scale = 0)
206: 	    : id(id), width(width), scale(scale) {
207: 	}
208: 
209: 	bool operator==(const SQLType &rhs) const {
210: 		return id == rhs.id && width == rhs.width && scale == rhs.scale;
211: 	}
212: 	bool operator!=(const SQLType &rhs) const {
213: 		return !(*this == rhs);
214: 	}
215: 
216: 	//! Serializes a SQLType to a stand-alone binary blob
217: 	void Serialize(Serializer &serializer);
218: 	//! Deserializes a blob back into an SQLType
219: 	static SQLType Deserialize(Deserializer &source);
220: 
221: 	bool IsIntegral() const;
222: 	bool IsNumeric() const;
223: 
224: public:
225: 	static const SQLType SQLNULL;
226: 	static const SQLType BOOLEAN;
227: 	static const SQLType TINYINT;
228: 	static const SQLType SMALLINT;
229: 	static const SQLType INTEGER;
230: 	static const SQLType BIGINT;
231: 	static const SQLType FLOAT;
232: 	static const SQLType DOUBLE;
233: 	static const SQLType DATE;
234: 	static const SQLType TIMESTAMP;
235: 	static const SQLType TIME;
236: 	static const SQLType VARCHAR;
237: 	static const SQLType STRUCT;
238: 	static const SQLType LIST;
239: 	static const SQLType ANY;
240: 
241: 	//! A list of all NUMERIC types (integral and floating point types)
242: 	static const vector<SQLType> NUMERIC;
243: 	//! A list of all INTEGRAL types
244: 	static const vector<SQLType> INTEGRAL;
245: 	//! A list of ALL SQL types
246: 	static const vector<SQLType> ALL_TYPES;
247: };
248: 
249: string SQLTypeIdToString(SQLTypeId type);
250: string SQLTypeToString(SQLType type);
251: 
252: SQLType MaxSQLType(SQLType left, SQLType right);
253: SQLType TransformStringToSQLType(string str);
254: 
255: //! Gets the internal type associated with the given SQL type
256: TypeId GetInternalType(SQLType type);
257: //! Returns the "simplest" SQL type corresponding to the given type id (e.g. TypeId::INT32 -> SQLTypeId::INTEGER)
258: SQLType SQLTypeFromInternalType(TypeId type);
259: 
260: //! Returns the TypeId for the given type
261: template <class T> TypeId GetTypeId() {
262: 	if (std::is_same<T, bool>()) {
263: 		return TypeId::BOOL;
264: 	} else if (std::is_same<T, int8_t>()) {
265: 		return TypeId::INT8;
266: 	} else if (std::is_same<T, int16_t>()) {
267: 		return TypeId::INT16;
268: 	} else if (std::is_same<T, int32_t>()) {
269: 		return TypeId::INT32;
270: 	} else if (std::is_same<T, int64_t>()) {
271: 		return TypeId::INT64;
272: 	} else if (std::is_same<T, uint64_t>()) {
273: 		return TypeId::HASH;
274: 	} else if (std::is_same<T, uintptr_t>()) {
275: 		return TypeId::POINTER;
276: 	} else if (std::is_same<T, double>()) {
277: 		return TypeId::DOUBLE;
278: 	} else if (std::is_same<T, const char *>() || std::is_same<T, char *>()) {
279: 		return TypeId::VARCHAR;
280: 	} else {
281: 		return TypeId::INVALID;
282: 	}
283: }
284: 
285: template <class T> bool IsValidType() {
286: 	return GetTypeId<T>() != TypeId::INVALID;
287: }
288: 
289: //! The TypeId used by the row identifiers column
290: extern const TypeId ROW_TYPE;
291: 
292: string TypeIdToString(TypeId type);
293: idx_t GetTypeIdSize(TypeId type);
294: bool TypeIsConstantSize(TypeId type);
295: bool TypeIsIntegral(TypeId type);
296: bool TypeIsNumeric(TypeId type);
297: bool TypeIsInteger(TypeId type);
298: 
299: template <class T> bool IsIntegerType() {
300: 	return TypeIsIntegral(GetTypeId<T>());
301: }
302: 
303: bool ApproxEqual(float l, float r);
304: bool ApproxEqual(double l, double r);
305: 
306: }; // namespace duckdb
[end of src/include/duckdb/common/types.hpp]
[start of src/include/duckdb/common/types/value.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/common/types/value.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/common.hpp"
12: #include "duckdb/common/exception.hpp"
13: 
14: #include <iosfwd>
15: #include <memory.h>
16: 
17: namespace duckdb {
18: 
19: class Deserializer;
20: class Serializer;
21: 
22: //! The Value object holds a single arbitrary value of any type that can be
23: //! stored in the database.
24: class Value {
25: 	friend class Vector;
26: 
27: public:
28: 	//! Create an empty NULL value of the specified type
29: 	Value(TypeId type = TypeId::INT32) : type(type), is_null(true) {
30: 	}
31: 	//! Create a BIGINT value
32: 	Value(int32_t val) : type(TypeId::INT32), is_null(false) {
33: 		value_.integer = val;
34: 	}
35: 	//! Create a FLOAT value
36: 	Value(float val) : type(TypeId::FLOAT), is_null(false) {
37: 		value_.float_ = val;
38: 	}
39: 	//! Create a DOUBLE value
40: 	Value(double val) : type(TypeId::DOUBLE), is_null(false) {
41: 		value_.double_ = val;
42: 	}
43: 	//! Create a VARCHAR value
44: 	Value(const char *val) : Value(val ? string(val) : string()) {
45: 	}
46: 	Value(string_t val);
47: 	//! Create a VARCHAR value
48: 	Value(string val);
49: 
50: 	//! Create the lowest possible value of a given type (numeric only)
51: 	static Value MinimumValue(TypeId type);
52: 	//! Create the highest possible value of a given type (numeric only)
53: 	static Value MaximumValue(TypeId type);
54: 	//! Create a Numeric value of the specified type with the specified value
55: 	static Value Numeric(TypeId id, int64_t value);
56: 
57: 	//! Create a tinyint Value from a specified value
58: 	static Value BOOLEAN(int8_t value);
59: 	//! Create a tinyint Value from a specified value
60: 	static Value TINYINT(int8_t value);
61: 	//! Create a smallint Value from a specified value
62: 	static Value SMALLINT(int16_t value);
63: 	//! Create an integer Value from a specified value
64: 	static Value INTEGER(int32_t value);
65: 	//! Create a bigint Value from a specified value
66: 	static Value BIGINT(int64_t value);
67: 	//! Create a hash Value from a specified value
68: 	static Value HASH(hash_t value);
69: 	//! Create a pointer Value from a specified value
70: 	static Value POINTER(uintptr_t value);
71: 	//! Create a date Value from a specified date
72: 	static Value DATE(int32_t year, int32_t month, int32_t day);
73: 	//! Create a time Value from a specified date
74: 	static Value TIME(int32_t hour, int32_t min, int32_t sec, int32_t msec);
75: 	//! Create a timestamp Value from a specified date/time combination
76: 	static Value TIMESTAMP(date_t date, dtime_t time);
77: 	//! Create a timestamp Value from a specified timestamp
78: 	static Value TIMESTAMP(timestamp_t timestamp);
79: 	//! Create a timestamp Value from a specified timestamp in separate values
80: 	static Value TIMESTAMP(int32_t year, int32_t month, int32_t day, int32_t hour, int32_t min, int32_t sec,
81: 	                       int32_t msec);
82: 
83: 	//! Create a float Value from a specified value
84: 	static Value FLOAT(float value);
85: 	//! Create a double Value from a specified value
86: 	static Value DOUBLE(double value);
87: 	//! Create a struct value with given list of entries
88: 	static Value STRUCT(child_list_t<Value> values);
89: 	//! Create a list value with the given entries
90: 	static Value LIST(std::vector<Value> values);
91: 
92: 	template <class T> T GetValue() {
93: 		throw NotImplementedException("Unimplemented template type for Value::GetValue");
94: 	}
95: 	template <class T> static Value CreateValue(T value) {
96: 		throw NotImplementedException("Unimplemented template type for Value::CreateValue");
97: 	}
98: 
99: 	//! Return a copy of this value
100: 	Value Copy() const {
101: 		return Value(*this);
102: 	}
103: 
104: 	//! Convert this value to a string
105: 	string ToString() const;
106: 	//! Convert this value to a string, with the given display format
107: 	string ToString(SQLType type) const;
108: 
109: 	//! Cast this value to another type
110: 	Value CastAs(TypeId target_type) const;
111: 	//! Cast this value to another type
112: 	Value CastAs(SQLType source_type, SQLType target_type);
113: 
114: 	//! The type of the value
115: 	TypeId type;
116: 	//! Whether or not the value is NULL
117: 	bool is_null;
118: 
119: 	//! The value of the object, if it is of a constant size Type
120: 	union Val {
121: 		int8_t boolean;
122: 		int8_t tinyint;
123: 		int16_t smallint;
124: 		int32_t integer;
125: 		int64_t bigint;
126: 		float float_;
127: 		double double_;
128: 		uintptr_t pointer;
129: 		uint64_t hash;
130: 	} value_;
131: 
132: 	//! The value of the object, if it is of a variable size type
133: 	string str_value;
134: 
135: 	child_list_t<Value> struct_value;
136: 	std::vector<Value> list_value;
137: 
138: 	//! Serializes a Value to a stand-alone binary blob
139: 	void Serialize(Serializer &serializer);
140: 	//! Deserializes a Value from a blob
141: 	static Value Deserialize(Deserializer &source);
142: 
143: 	//===--------------------------------------------------------------------===//
144: 	// Numeric Operators
145: 	//===--------------------------------------------------------------------===//
146: 	Value operator+(const Value &rhs) const;
147: 	Value operator-(const Value &rhs) const;
148: 	Value operator*(const Value &rhs) const;
149: 	Value operator/(const Value &rhs) const;
150: 	Value operator%(const Value &rhs) const;
151: 
152: 	//===--------------------------------------------------------------------===//
153: 	// Comparison Operators
154: 	//===--------------------------------------------------------------------===//
155: 	bool operator==(const Value &rhs) const;
156: 	bool operator!=(const Value &rhs) const;
157: 	bool operator<(const Value &rhs) const;
158: 	bool operator>(const Value &rhs) const;
159: 	bool operator<=(const Value &rhs) const;
160: 	bool operator>=(const Value &rhs) const;
161: 
162: 	bool operator==(const int64_t &rhs) const;
163: 	bool operator!=(const int64_t &rhs) const;
164: 	bool operator<(const int64_t &rhs) const;
165: 	bool operator>(const int64_t &rhs) const;
166: 	bool operator<=(const int64_t &rhs) const;
167: 	bool operator>=(const int64_t &rhs) const;
168: 
169: 	static bool IsUTF8String(const char *s);
170: 	static bool IsUTF8String(string_t s);
171: 	//! Returns true if the values are (approximately) equivalent. Note this is NOT the SQL equivalence. For this
172: 	//! function, NULL values are equivalent and floating point values that are close are equivalent.
173: 	static bool ValuesAreEqual(Value result_value, Value value);
174: 
175: 	friend std::ostream &operator<<(std::ostream &out, const Value &val) {
176: 		out << val.ToString();
177: 		return out;
178: 	}
179: 	void Print();
180: 
181: private:
182: 	template <class T> T GetValueInternal();
183: 	//! Templated helper function for casting
184: 	template <class DST, class OP> static DST _cast(const Value &v);
185: 
186: 	//! Templated helper function for binary operations
187: 	template <class OP>
188: 	static void _templated_binary_operation(const Value &left, const Value &right, Value &result, bool ignore_null);
189: 
190: 	//! Templated helper function for boolean operations
191: 	template <class OP> static bool _templated_boolean_operation(const Value &left, const Value &right);
192: };
193: 
194: template <> Value Value::CreateValue(bool value);
195: template <> Value Value::CreateValue(int8_t value);
196: template <> Value Value::CreateValue(int16_t value);
197: template <> Value Value::CreateValue(int32_t value);
198: template <> Value Value::CreateValue(int64_t value);
199: template <> Value Value::CreateValue(const char *value);
200: template <> Value Value::CreateValue(string value);
201: template <> Value Value::CreateValue(string_t value);
202: template <> Value Value::CreateValue(float value);
203: template <> Value Value::CreateValue(double value);
204: 
205: template <> bool Value::GetValue();
206: template <> int8_t Value::GetValue();
207: template <> int16_t Value::GetValue();
208: template <> int32_t Value::GetValue();
209: template <> int64_t Value::GetValue();
210: template <> string Value::GetValue();
211: template <> float Value::GetValue();
212: template <> double Value::GetValue();
213: 
214: } // namespace duckdb
[end of src/include/duckdb/common/types/value.hpp]
[start of src/include/duckdb/function/aggregate/distributive_functions.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/function/aggregate/distributive_functions.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/function/aggregate_function.hpp"
12: #include "duckdb/function/function_set.hpp"
13: #include "duckdb/common/types/null_value.hpp"
14: 
15: namespace duckdb {
16: 
17: struct StandardDistributiveFunction {
18: 	template <class STATE> static void Initialize(STATE *state) {
19: 		*state = NullValue<STATE>();
20: 	}
21: 
22: 	template <class INPUT_TYPE, class STATE, class OP>
23: 	static void Operation(STATE *state, INPUT_TYPE *input, nullmask_t &nullmask, idx_t idx) {
24: 		if (IsNullValue<INPUT_TYPE>(*state)) {
25: 			*state = input[idx];
26: 		} else {
27: 			OP::template Execute<INPUT_TYPE, STATE>(state, input[idx]);
28: 		}
29: 	}
30: 
31: 	template <class T, class STATE>
32: 	static void Finalize(Vector &result, STATE *state, T *target, nullmask_t &nullmask, idx_t idx) {
33: 		nullmask[idx] = IsNullValue<T>(*state);
34: 		target[idx] = *state;
35: 	}
36: 
37: 	template <class STATE, class OP> static void Combine(STATE source, STATE *target) {
38: 		if (IsNullValue<STATE>(source)) {
39: 			// source is NULL, nothing to do
40: 			return;
41: 		}
42: 		if (IsNullValue<STATE>(*target)) {
43: 			// target is NULL, use source value directly
44: 			*target = source;
45: 		} else {
46: 			// else perform the operation
47: 			OP::template Execute<STATE, STATE>(target, source);
48: 		}
49: 	}
50: 
51: 	static bool IgnoreNull() {
52: 		return true;
53: 	}
54: };
55: 
56: struct CountStarFun {
57: 	static AggregateFunction GetFunction();
58: 
59: 	static void RegisterFunction(BuiltinFunctions &set);
60: };
61: 
62: struct CountFun {
63: 	static AggregateFunction GetFunction();
64: 
65: 	static void RegisterFunction(BuiltinFunctions &set);
66: };
67: 
68: struct FirstFun {
69: 	static AggregateFunction GetFunction(SQLType type);
70: 
71: 	static void RegisterFunction(BuiltinFunctions &set);
72: };
73: 
74: struct MaxFun {
75: 	static void RegisterFunction(BuiltinFunctions &set);
76: };
77: 
78: struct MinFun {
79: 	static void RegisterFunction(BuiltinFunctions &set);
80: };
81: 
82: struct SumFun {
83: 	static void RegisterFunction(BuiltinFunctions &set);
84: };
85: 
86: struct StringAggFun {
87: 	static void RegisterFunction(BuiltinFunctions &set);
88: };
89: 
90: } // namespace duckdb
[end of src/include/duckdb/function/aggregate/distributive_functions.hpp]
[start of src/include/duckdb/main/connection.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/main/connection.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/main/materialized_query_result.hpp"
12: #include "duckdb/main/query_result.hpp"
13: #include "duckdb/main/stream_query_result.hpp"
14: #include "duckdb/main/prepared_statement.hpp"
15: #include "duckdb/main/table_description.hpp"
16: #include "duckdb/main/relation.hpp"
17: #include "duckdb/common/enums/profiler_format.hpp"
18: #include "duckdb/parser/sql_statement.hpp"
19: 
20: namespace duckdb {
21: 
22: class ClientContext;
23: class DuckDB;
24: 
25: typedef void (*warning_callback)(std::string);
26: 
27: //! A connection to a database. This represents a (client) connection that can
28: //! be used to query the database.
29: class Connection {
30: public:
31: 	Connection(DuckDB &database);
32: 	~Connection();
33: 
34: 	DuckDB &db;
35: 	unique_ptr<ClientContext> context;
36: 	warning_callback warning_cb;
37: 
38: public:
39: 	//! Returns query profiling information for the current query
40: 	string GetProfilingInformation(ProfilerPrintFormat format = ProfilerPrintFormat::QUERY_TREE);
41: 
42: 	//! Interrupt execution of the current query
43: 	void Interrupt();
44: 
45: 	//! Enable query profiling
46: 	void EnableProfiling();
47: 	//! Disable query profiling
48: 	void DisableProfiling();
49: 
50: 	void SetWarningCallback(warning_callback);
51: 
52: 	//! Enable aggressive verification/testing of queries, should only be used in testing
53: 	void EnableQueryVerification();
54: 
55: 	//! Issues a query to the database and returns a QueryResult. This result can be either a StreamQueryResult or a
56: 	//! MaterializedQueryResult. The result can be stepped through with calls to Fetch(). Note that there can only be
57: 	//! one active StreamQueryResult per Connection object. Calling SendQuery() will invalidate any previously existing
58: 	//! StreamQueryResult.
59: 	unique_ptr<QueryResult> SendQuery(string query);
60: 	//! Issues a query to the database and materializes the result (if necessary). Always returns a
61: 	//! MaterializedQueryResult.
62: 	unique_ptr<MaterializedQueryResult> Query(string query);
63: 	// prepared statements
64: 	template <typename... Args> unique_ptr<QueryResult> Query(string query, Args... args) {
65: 		vector<Value> values;
66: 		return QueryParamsRecursive(query, values, args...);
67: 	}
68: 
69: 	//! Prepare the specified query, returning a prepared statement object
70: 	unique_ptr<PreparedStatement> Prepare(string query);
71: 
72: 	//! Get the table info of a specific table (in the default schema), or nullptr if it cannot be found
73: 	unique_ptr<TableDescription> TableInfo(string table_name);
74: 	//! Get the table info of a specific table, or nullptr if it cannot be found
75: 	unique_ptr<TableDescription> TableInfo(string schema_name, string table_name);
76: 
77: 	//! Extract a set of SQL statements from a specific query
78: 	vector<unique_ptr<SQLStatement>> ExtractStatements(string query);
79: 
80: 	//! Appends a DataChunk to the specified table
81: 	void Append(TableDescription &description, DataChunk &chunk);
82: 
83: 	//! Returns a relation that produces a table from this connection
84: 	shared_ptr<Relation> Table(string tname);
85: 	//! Returns a relation that produces a table from this connection
86: 	shared_ptr<Relation> Table(string schema_name, string table_name);
87: 	//! Returns a relation that produces values
88: 	shared_ptr<Relation> Values(vector<vector<Value>> values);
89: 	shared_ptr<Relation> Values(vector<vector<Value>> values, vector<string> column_names, string alias = "values");
90: 	shared_ptr<Relation> Values(string values);
91: 	shared_ptr<Relation> Values(string values, vector<string> column_names, string alias = "values");
92: 	//! Reads CSV file
93: 	shared_ptr<Relation> ReadCSV(string csv_file, vector<string> columns);
94: 
95: 	void BeginTransaction();
96: 	void Commit();
97: 	void Rollback();
98: 
99: private:
100: 	unique_ptr<QueryResult> QueryParamsRecursive(string query, vector<Value> &values);
101: 
102: 	template <typename T, typename... Args>
103: 	unique_ptr<QueryResult> QueryParamsRecursive(string query, vector<Value> &values, T value, Args... args) {
104: 		values.push_back(Value::CreateValue<T>(value));
105: 		return QueryParamsRecursive(query, values, args...);
106: 	}
107: };
108: 
109: } // namespace duckdb
[end of src/include/duckdb/main/connection.hpp]
[start of src/main/client_context.cpp]
1: #include "duckdb/main/client_context.hpp"
2: 
3: #include "duckdb/catalog/catalog_entry/table_catalog_entry.hpp"
4: #include "duckdb/common/serializer/buffered_deserializer.hpp"
5: #include "duckdb/common/serializer/buffered_serializer.hpp"
6: #include "duckdb/execution/physical_plan_generator.hpp"
7: #include "duckdb/main/database.hpp"
8: #include "duckdb/main/materialized_query_result.hpp"
9: #include "duckdb/main/query_result.hpp"
10: #include "duckdb/main/stream_query_result.hpp"
11: #include "duckdb/optimizer/optimizer.hpp"
12: #include "duckdb/parser/parser.hpp"
13: #include "duckdb/parser/expression/constant_expression.hpp"
14: #include "duckdb/parser/statement/drop_statement.hpp"
15: #include "duckdb/parser/statement/execute_statement.hpp"
16: #include "duckdb/parser/statement/explain_statement.hpp"
17: #include "duckdb/parser/statement/prepare_statement.hpp"
18: #include "duckdb/planner/operator/logical_execute.hpp"
19: #include "duckdb/planner/planner.hpp"
20: #include "duckdb/transaction/transaction_manager.hpp"
21: #include "duckdb/transaction/transaction.hpp"
22: #include "duckdb/storage/data_table.hpp"
23: #include "duckdb/main/appender.hpp"
24: #include "duckdb/main/relation.hpp"
25: #include "duckdb/planner/expression_binder/where_binder.hpp"
26: #include "duckdb/parser/statement/relation_statement.hpp"
27: 
28: using namespace duckdb;
29: using namespace std;
30: 
31: ClientContext::ClientContext(DuckDB &database)
32:     : db(database), transaction(*database.transaction_manager), interrupted(false), catalog(*database.catalog),
33:       temporary_objects(make_unique<SchemaCatalogEntry>(db.catalog.get(), TEMP_SCHEMA)),
34:       prepared_statements(make_unique<CatalogSet>(*db.catalog)), open_result(nullptr) {
35: 	random_device rd;
36: 	random_engine.seed(rd());
37: }
38: 
39: void ClientContext::Cleanup() {
40: 	lock_guard<mutex> client_guard(context_lock);
41: 	if (is_invalidated || !prepared_statements) {
42: 		return;
43: 	}
44: 	if (transaction.HasActiveTransaction()) {
45: 		ActiveTransaction().active_query = MAXIMUM_QUERY_ID;
46: 		if (!transaction.IsAutoCommit()) {
47: 			transaction.Rollback();
48: 		}
49: 	}
50: 	assert(prepared_statements);
51: 	db.transaction_manager->AddCatalogSet(*this, move(prepared_statements));
52: 	// invalidate any prepared statements
53: 	for (auto &statement : prepared_statement_objects) {
54: 		statement->is_invalidated = true;
55: 	}
56: 	for (auto &appender : appenders) {
57: 		appender->Invalidate("Connection has been closed!", false);
58: 	}
59: 	CleanupInternal();
60: }
61: 
62: void ClientContext::RegisterAppender(Appender *appender) {
63: 	lock_guard<mutex> client_guard(context_lock);
64: 	if (is_invalidated) {
65: 		throw Exception("Database that this connection belongs to has been closed!");
66: 	}
67: 	appenders.insert(appender);
68: }
69: 
70: void ClientContext::RemoveAppender(Appender *appender) {
71: 	lock_guard<mutex> client_guard(context_lock);
72: 	if (is_invalidated) {
73: 		return;
74: 	}
75: 	appenders.erase(appender);
76: }
77: 
78: unique_ptr<DataChunk> ClientContext::Fetch() {
79: 	lock_guard<mutex> client_guard(context_lock);
80: 	if (!open_result) {
81: 		// no result to fetch from
82: 		return nullptr;
83: 	}
84: 	if (is_invalidated) {
85: 		// ClientContext is invalidated: database has been closed
86: 		open_result->error = "Database that this connection belongs to has been closed!";
87: 		open_result->success = false;
88: 		return nullptr;
89: 	}
90: 	try {
91: 		// fetch the chunk and return it
92: 		auto chunk = FetchInternal();
93: 		return chunk;
94: 	} catch (Exception &ex) {
95: 		open_result->error = ex.what();
96: 	} catch (...) {
97: 		open_result->error = "Unhandled exception in Fetch";
98: 	}
99: 	open_result->success = false;
100: 	CleanupInternal();
101: 	return nullptr;
102: }
103: 
104: string ClientContext::FinalizeQuery(bool success) {
105: 	profiler.EndQuery();
106: 
107: 	execution_context.Reset();
108: 
109: 	string error;
110: 	if (transaction.HasActiveTransaction()) {
111: 		ActiveTransaction().active_query = MAXIMUM_QUERY_ID;
112: 		try {
113: 			if (transaction.IsAutoCommit()) {
114: 				if (success) {
115: 					// query was successful: commit
116: 					transaction.Commit();
117: 				} else {
118: 					// query was unsuccessful: rollback
119: 					transaction.Rollback();
120: 				}
121: 			}
122: 		} catch (Exception &ex) {
123: 			error = ex.what();
124: 		} catch (...) {
125: 			error = "Unhandled exception!";
126: 		}
127: 	}
128: 	return error;
129: }
130: 
131: void ClientContext::CleanupInternal() {
132: 	if (!open_result) {
133: 		// no result currently open
134: 		return;
135: 	}
136: 
137: 	auto error = FinalizeQuery(open_result->success);
138: 	if (open_result->success) {
139: 		// if an error occurred while committing report it in the result
140: 		open_result->error = error;
141: 		open_result->success = error.empty();
142: 	}
143: 
144: 	open_result->is_open = false;
145: 	open_result = nullptr;
146: }
147: 
148: unique_ptr<DataChunk> ClientContext::FetchInternal() {
149: 	assert(execution_context.physical_plan);
150: 	auto chunk = make_unique<DataChunk>();
151: 	// run the plan to get the next chunks
152: 	execution_context.physical_plan->InitializeChunk(*chunk);
153: 	execution_context.physical_plan->GetChunk(*this, *chunk, execution_context.physical_state.get());
154: 	return chunk;
155: }
156: 
157: unique_ptr<PreparedStatementData> ClientContext::CreatePreparedStatement(const string &query,
158:                                                                          unique_ptr<SQLStatement> statement) {
159: 	StatementType statement_type = statement->type;
160: 	auto result = make_unique<PreparedStatementData>(statement_type);
161: 
162: 	profiler.StartPhase("planner");
163: 	Planner planner(*this);
164: 	planner.CreatePlan(move(statement));
165: 	assert(planner.plan);
166: 	profiler.EndPhase();
167: 
168: 	auto plan = move(planner.plan);
169: 	// extract the result column names from the plan
170: 	result->read_only = planner.read_only;
171: 	result->requires_valid_transaction = planner.requires_valid_transaction;
172: 	result->names = planner.names;
173: 	result->sql_types = planner.sql_types;
174: 	result->value_map = move(planner.value_map);
175: 
176: #ifdef DEBUG
177: 	if (enable_optimizer) {
178: #endif
179: 		profiler.StartPhase("optimizer");
180: 		Optimizer optimizer(planner.binder, *this);
181: 		plan = optimizer.Optimize(move(plan));
182: 		assert(plan);
183: 		profiler.EndPhase();
184: #ifdef DEBUG
185: 	}
186: #endif
187: 
188: 	profiler.StartPhase("physical_planner");
189: 	// now convert logical query plan into a physical query plan
190: 	PhysicalPlanGenerator physical_planner(*this);
191: 	auto physical_plan = physical_planner.CreatePlan(move(plan));
192: 	profiler.EndPhase();
193: 
194: 	result->dependencies = move(physical_planner.dependencies);
195: 	result->types = physical_plan->types;
196: 	result->plan = move(physical_plan);
197: 	return result;
198: }
199: 
200: unique_ptr<QueryResult> ClientContext::ExecutePreparedStatement(const string &query, PreparedStatementData &statement,
201:                                                                 vector<Value> bound_values, bool allow_stream_result) {
202: 	if (ActiveTransaction().is_invalidated && statement.requires_valid_transaction) {
203: 		throw Exception("Current transaction is aborted (please ROLLBACK)");
204: 	}
205: 	if (db.access_mode == AccessMode::READ_ONLY && !statement.read_only) {
206: 		throw Exception(StringUtil::Format("Cannot execute statement of type \"%s\" in read-only mode!",
207: 		                                   StatementTypeToString(statement.statement_type).c_str()));
208: 	}
209: 
210: 	// bind the bound values before execution
211: 	statement.Bind(move(bound_values));
212: 
213: 	bool create_stream_result = statement.statement_type == StatementType::SELECT && allow_stream_result;
214: 
215: 	// store the physical plan in the context for calls to Fetch()
216: 	execution_context.physical_plan = move(statement.plan);
217: 	execution_context.physical_state = execution_context.physical_plan->GetOperatorState();
218: 
219: 	auto types = execution_context.physical_plan->GetTypes();
220: 	assert(types.size() == statement.sql_types.size());
221: 
222: 	if (create_stream_result) {
223: 		// successfully compiled SELECT clause and it is the last statement
224: 		// return a StreamQueryResult so the client can call Fetch() on it and stream the result
225: 		return make_unique<StreamQueryResult>(statement.statement_type, *this, statement.sql_types, types,
226: 		                                      statement.names);
227: 	}
228: 	// create a materialized result by continuously fetching
229: 	auto result =
230: 	    make_unique<MaterializedQueryResult>(statement.statement_type, statement.sql_types, types, statement.names);
231: 	while (true) {
232: 		auto chunk = FetchInternal();
233: 		if (chunk->size() == 0) {
234: 			break;
235: 		}
236: 		result->collection.Append(*chunk);
237: 	}
238: 	return move(result);
239: }
240: 
241: void ClientContext::InitialCleanup() {
242: 	if (is_invalidated) {
243: 		throw Exception("Database that this connection belongs to has been closed!");
244: 	}
245: 	//! Cleanup any open results and reset the interrupted flag
246: 	CleanupInternal();
247: 	interrupted = false;
248: }
249: 
250: unique_ptr<PreparedStatement> ClientContext::Prepare(string query) {
251: 	lock_guard<mutex> client_guard(context_lock);
252: 	// prepare the query
253: 	try {
254: 		InitialCleanup();
255: 
256: 		// first parse the query
257: 		Parser parser;
258: 		parser.ParseQuery(query.c_str());
259: 		if (parser.statements.size() == 0) {
260: 			throw Exception("No statement to prepare!");
261: 		}
262: 		if (parser.statements.size() > 1) {
263: 			throw Exception("Cannot prepare multiple statements at once!");
264: 		}
265: 		// now write the prepared statement data into the catalog
266: 		string prepare_name = "____duckdb_internal_prepare_" + to_string(prepare_count);
267: 		prepare_count++;
268: 		// create a prepare statement out of the underlying statement
269: 		auto prepare = make_unique<PrepareStatement>();
270: 		prepare->name = prepare_name;
271: 		prepare->statement = move(parser.statements[0]);
272: 
273: 		// now perform the actual PREPARE query
274: 		auto result = RunStatement(query, move(prepare), false);
275: 		if (!result->success) {
276: 			throw Exception(result->error);
277: 		}
278: 		auto prepared_catalog = (PreparedStatementCatalogEntry *)prepared_statements->GetRootEntry(prepare_name);
279: 		auto prepared_object = make_unique<PreparedStatement>(this, prepare_name, query, *prepared_catalog->prepared,
280: 		                                                      parser.n_prepared_parameters);
281: 		prepared_statement_objects.insert(prepared_object.get());
282: 		return prepared_object;
283: 	} catch (Exception &ex) {
284: 		return make_unique<PreparedStatement>(ex.what());
285: 	}
286: }
287: 
288: unique_ptr<QueryResult> ClientContext::Execute(string name, vector<Value> &values, bool allow_stream_result,
289:                                                string query) {
290: 	lock_guard<mutex> client_guard(context_lock);
291: 	try {
292: 		InitialCleanup();
293: 	} catch (std::exception &ex) {
294: 		return make_unique<MaterializedQueryResult>(ex.what());
295: 	}
296: 
297: 	// create the execute statement
298: 	auto execute = make_unique<ExecuteStatement>();
299: 	execute->name = name;
300: 	for (auto &val : values) {
301: 		execute->values.push_back(make_unique<ConstantExpression>(SQLTypeFromInternalType(val.type), val));
302: 	}
303: 
304: 	return RunStatement(query, move(execute), allow_stream_result);
305: }
306: void ClientContext::RemovePreparedStatement(PreparedStatement *statement) {
307: 	lock_guard<mutex> client_guard(context_lock);
308: 	if (!statement->success || statement->is_invalidated || is_invalidated) {
309: 		return;
310: 	}
311: 	try {
312: 		InitialCleanup();
313: 	} catch (...) {
314: 		return;
315: 	}
316: 	// erase the object from the list of prepared statements
317: 	prepared_statement_objects.erase(statement);
318: 	// drop it from the catalog
319: 	auto deallocate_statement = make_unique<DropStatement>();
320: 	deallocate_statement->info->type = CatalogType::PREPARED_STATEMENT;
321: 	deallocate_statement->info->name = statement->name;
322: 	string query = "DEALLOCATE " + statement->name;
323: 	RunStatement(query, move(deallocate_statement), false);
324: }
325: 
326: unique_ptr<QueryResult> ClientContext::RunStatementInternal(const string &query, unique_ptr<SQLStatement> statement,
327:                                                             bool allow_stream_result) {
328: 	// prepare the query for execution
329: 	auto prepared = CreatePreparedStatement(query, move(statement));
330: 	// by default, no values are bound
331: 	vector<Value> bound_values;
332: 	// execute the prepared statement
333: 	return ExecutePreparedStatement(query, *prepared, move(bound_values), allow_stream_result);
334: }
335: 
336: unique_ptr<QueryResult> ClientContext::RunStatement(const string &query, unique_ptr<SQLStatement> statement,
337:                                                     bool allow_stream_result) {
338: 	unique_ptr<QueryResult> result;
339: 	// check if we are on AutoCommit. In this case we should start a transaction.
340: 	if (transaction.IsAutoCommit()) {
341: 		transaction.BeginTransaction();
342: 	}
343: 	ActiveTransaction().active_query = db.transaction_manager->GetQueryNumber();
344: 	if (statement->type == StatementType::SELECT && query_verification_enabled) {
345: 		// query verification is enabled:
346: 		// create a copy of the statement and verify the original statement
347: 		auto copied_statement = ((SelectStatement &)*statement).Copy();
348: 		string error = VerifyQuery(query, move(statement));
349: 		if (!error.empty()) {
350: 			// query failed: abort now
351: 			FinalizeQuery(false);
352: 			// error in verifying query
353: 			return make_unique<MaterializedQueryResult>(error);
354: 		}
355: 		statement = move(copied_statement);
356: 	}
357: 	// start the profiler
358: 	profiler.StartQuery(query, *statement);
359: 	try {
360: 		result = RunStatementInternal(query, move(statement), allow_stream_result);
361: 	} catch (StandardException &ex) {
362: 		// standard exceptions do not invalidate the current transaction
363: 		result = make_unique<MaterializedQueryResult>(ex.what());
364: 	} catch (std::exception &ex) {
365: 		// other types of exceptions do invalidate the current transaction
366: 		if (transaction.HasActiveTransaction()) {
367: 			ActiveTransaction().is_invalidated = true;
368: 		}
369: 		result = make_unique<MaterializedQueryResult>(ex.what());
370: 	}
371: 	if (!result->success) {
372: 		// initial failures should always be reported as MaterializedResult
373: 		assert(result->type != QueryResultType::STREAM_RESULT);
374: 		// query failed: abort now
375: 		FinalizeQuery(false);
376: 		return result;
377: 	}
378: 	// query succeeded, append to list of results
379: 	if (result->type == QueryResultType::STREAM_RESULT) {
380: 		// store as currently open result if it is a stream result
381: 		this->open_result = (StreamQueryResult *)result.get();
382: 	} else {
383: 		// finalize the query if it is not a stream result
384: 		string error = FinalizeQuery(true);
385: 		if (!error.empty()) {
386: 			// failure in committing transaction
387: 			return make_unique<MaterializedQueryResult>(error);
388: 		}
389: 	}
390: 	return result;
391: }
392: 
393: unique_ptr<QueryResult> ClientContext::RunStatements(const string &query, vector<unique_ptr<SQLStatement>> &statements,
394:                                                      bool allow_stream_result) {
395: 	// now we have a list of statements
396: 	// iterate over them and execute them one by one
397: 	unique_ptr<QueryResult> result;
398: 	QueryResult *last_result = nullptr;
399: 	for (idx_t i = 0; i < statements.size(); i++) {
400: 		auto &statement = statements[i];
401: 		bool is_last_statement = i + 1 == statements.size();
402: 		auto current_result = RunStatement(query, move(statement), allow_stream_result && is_last_statement);
403: 		// now append the result to the list of results
404: 		if (!last_result) {
405: 			// first result of the query
406: 			result = move(current_result);
407: 			last_result = result.get();
408: 		} else {
409: 			// later results; attach to the result chain
410: 			last_result->next = move(current_result);
411: 			last_result = last_result->next.get();
412: 		}
413: 	}
414: 	return result;
415: }
416: 
417: unique_ptr<QueryResult> ClientContext::Query(string query, bool allow_stream_result) {
418: 	lock_guard<mutex> client_guard(context_lock);
419: 
420: 	Parser parser;
421: 	try {
422: 		InitialCleanup();
423: 		// parse the query and transform it into a set of statements
424: 		parser.ParseQuery(query.c_str());
425: 	} catch (std::exception &ex) {
426: 		return make_unique<MaterializedQueryResult>(ex.what());
427: 	}
428: 
429: 	if (parser.statements.size() == 0) {
430: 		// no statements, return empty successful result
431: 		return make_unique<MaterializedQueryResult>(StatementType::INVALID);
432: 	}
433: 
434: 	return RunStatements(query, parser.statements, allow_stream_result);
435: }
436: 
437: void ClientContext::Interrupt() {
438: 	interrupted = true;
439: }
440: 
441: void ClientContext::EnableProfiling() {
442: 	lock_guard<mutex> client_guard(context_lock);
443: 	profiler.Enable();
444: }
445: 
446: void ClientContext::DisableProfiling() {
447: 	lock_guard<mutex> client_guard(context_lock);
448: 	profiler.Disable();
449: }
450: 
451: void ClientContext::Invalidate() {
452: 	// interrupt any running query before attempting to obtain the lock
453: 	// this way we don't have to wait for the entire query to finish
454: 	Interrupt();
455: 	// now obtain the context lock
456: 	lock_guard<mutex> client_guard(context_lock);
457: 	// invalidate this context and the TransactionManager
458: 	is_invalidated = true;
459: 	transaction.Invalidate();
460: 	// also close any open result
461: 	if (open_result) {
462: 		open_result->is_open = false;
463: 	}
464: 	// and close any open appenders and prepared statements
465: 	for (auto &statement : prepared_statement_objects) {
466: 		statement->is_invalidated = true;
467: 	}
468: 	for (auto &appender : appenders) {
469: 		appender->Invalidate("Database that this appender belongs to has been closed!", false);
470: 	}
471: 	appenders.clear();
472: }
473: 
474: string ClientContext::VerifyQuery(string query, unique_ptr<SQLStatement> statement) {
475: 	assert(statement->type == StatementType::SELECT);
476: 	// aggressive query verification
477: 
478: 	// the purpose of this function is to test correctness of otherwise hard to test features:
479: 	// Copy() of statements and expressions
480: 	// Serialize()/Deserialize() of expressions
481: 	// Hash() of expressions
482: 	// Equality() of statements and expressions
483: 	// Correctness of plans both with and without optimizers
484: 
485: 	// copy the statement
486: 	auto select_stmt = (SelectStatement *)statement.get();
487: 	auto copied_stmt = select_stmt->Copy();
488: 	auto unoptimized_stmt = select_stmt->Copy();
489: 
490: 	BufferedSerializer serializer;
491: 	select_stmt->Serialize(serializer);
492: 	BufferedDeserializer source(serializer);
493: 	auto deserialized_stmt = SelectStatement::Deserialize(source);
494: 	// all the statements should be equal
495: 	assert(copied_stmt->Equals(statement.get()));
496: 	assert(deserialized_stmt->Equals(statement.get()));
497: 	assert(copied_stmt->Equals(deserialized_stmt.get()));
498: 
499: 	// now perform checking on the expressions
500: #ifdef DEBUG
501: 	auto &orig_expr_list = select_stmt->node->GetSelectList();
502: 	auto &de_expr_list = deserialized_stmt->node->GetSelectList();
503: 	auto &cp_expr_list = copied_stmt->node->GetSelectList();
504: 	assert(orig_expr_list.size() == de_expr_list.size() && cp_expr_list.size() == de_expr_list.size());
505: 	for (idx_t i = 0; i < orig_expr_list.size(); i++) {
506: 		// run the ToString, to verify that it doesn't crash
507: 		orig_expr_list[i]->ToString();
508: 		// check that the expressions are equivalent
509: 		assert(orig_expr_list[i]->Equals(de_expr_list[i].get()));
510: 		assert(orig_expr_list[i]->Equals(cp_expr_list[i].get()));
511: 		assert(de_expr_list[i]->Equals(cp_expr_list[i].get()));
512: 		// check that the hashes are equivalent too
513: 		assert(orig_expr_list[i]->Hash() == de_expr_list[i]->Hash());
514: 		assert(orig_expr_list[i]->Hash() == cp_expr_list[i]->Hash());
515: 	}
516: 	// now perform additional checking within the expressions
517: 	for (idx_t outer_idx = 0; outer_idx < orig_expr_list.size(); outer_idx++) {
518: 		auto hash = orig_expr_list[outer_idx]->Hash();
519: 		for (idx_t inner_idx = 0; inner_idx < orig_expr_list.size(); inner_idx++) {
520: 			auto hash2 = orig_expr_list[inner_idx]->Hash();
521: 			if (hash != hash2) {
522: 				// if the hashes are not equivalent, the expressions should not be equivalent
523: 				assert(!orig_expr_list[outer_idx]->Equals(orig_expr_list[inner_idx].get()));
524: 			}
525: 		}
526: 	}
527: #endif
528: 
529: 	// disable profiling if it is enabled
530: 	bool profiling_is_enabled = profiler.IsEnabled();
531: 	if (profiling_is_enabled) {
532: 		profiler.Disable();
533: 	}
534: 
535: 	// see below
536: 	auto statement_copy_for_explain = select_stmt->Copy();
537: 
538: 	auto original_result = make_unique<MaterializedQueryResult>(StatementType::SELECT),
539: 	     copied_result = make_unique<MaterializedQueryResult>(StatementType::SELECT),
540: 	     deserialized_result = make_unique<MaterializedQueryResult>(StatementType::SELECT),
541: 	     unoptimized_result = make_unique<MaterializedQueryResult>(StatementType::SELECT);
542: 	// execute the original statement
543: 	try {
544: 		auto result = RunStatementInternal(query, move(statement), false);
545: 		original_result = unique_ptr_cast<QueryResult, MaterializedQueryResult>(move(result));
546: 	} catch (Exception &ex) {
547: 		original_result->error = ex.what();
548: 		original_result->success = false;
549: 	}
550: 
551: 	// check explain, only if q does not already contain EXPLAIN
552: 	if (original_result->success) {
553: 		auto explain_q = "EXPLAIN " + query;
554: 		auto explain_stmt = make_unique<ExplainStatement>(move(statement_copy_for_explain));
555: 		try {
556: 			RunStatementInternal(explain_q, move(explain_stmt), false);
557: 		} catch (std::exception &ex) {
558: 			return "EXPLAIN failed but query did not (" + string(ex.what()) + ")";
559: 		}
560: 	}
561: 
562: 	// now execute the copied statement
563: 	try {
564: 		auto result = RunStatementInternal(query, move(copied_stmt), false);
565: 		copied_result = unique_ptr_cast<QueryResult, MaterializedQueryResult>(move(result));
566: 	} catch (Exception &ex) {
567: 		copied_result->error = ex.what();
568: 	}
569: 	// now execute the deserialized statement
570: 	try {
571: 		auto result = RunStatementInternal(query, move(deserialized_stmt), false);
572: 		deserialized_result = unique_ptr_cast<QueryResult, MaterializedQueryResult>(move(result));
573: 	} catch (Exception &ex) {
574: 		deserialized_result->error = ex.what();
575: 	}
576: 	// now execute the unoptimized statement
577: 	enable_optimizer = false;
578: 	try {
579: 		auto result = RunStatementInternal(query, move(unoptimized_stmt), false);
580: 		unoptimized_result = unique_ptr_cast<QueryResult, MaterializedQueryResult>(move(result));
581: 	} catch (Exception &ex) {
582: 		unoptimized_result->error = ex.what();
583: 	}
584: 
585: 	enable_optimizer = true;
586: 	if (profiling_is_enabled) {
587: 		profiler.Enable();
588: 	}
589: 
590: 	// now compare the results
591: 	// the results of all four runs should be identical
592: 	if (!original_result->collection.Equals(copied_result->collection)) {
593: 		string result = "Copied result differs from original result!\n";
594: 		result += "Original Result:\n" + original_result->ToString();
595: 		result += "Copied Result\n" + copied_result->ToString();
596: 		return result;
597: 	}
598: 	if (!original_result->collection.Equals(deserialized_result->collection)) {
599: 		string result = "Deserialized result differs from original result!\n";
600: 		result += "Original Result:\n" + original_result->ToString();
601: 		result += "Deserialized Result\n" + deserialized_result->ToString();
602: 		return result;
603: 	}
604: 	if (!original_result->collection.Equals(unoptimized_result->collection)) {
605: 		string result = "Unoptimized result differs from original result!\n";
606: 		result += "Original Result:\n" + original_result->ToString();
607: 		result += "Unoptimized Result\n" + unoptimized_result->ToString();
608: 		return result;
609: 	}
610: 
611: 	return "";
612: }
613: 
614: template <class T> void ClientContext::RunFunctionInTransaction(T &&fun) {
615: 	lock_guard<mutex> client_guard(context_lock);
616: 	if (is_invalidated) {
617: 		throw Exception("Failed: database has been closed!");
618: 	}
619: 	if (transaction.HasActiveTransaction() && transaction.ActiveTransaction().is_invalidated) {
620: 		throw Exception("Failed: transaction has been invalidated!");
621: 	}
622: 	// check if we are on AutoCommit. In this case we should start a transaction
623: 	if (transaction.IsAutoCommit()) {
624: 		transaction.BeginTransaction();
625: 	}
626: 	try {
627: 		fun();
628: 	} catch (Exception &ex) {
629: 		if (transaction.IsAutoCommit()) {
630: 			transaction.Rollback();
631: 		} else {
632: 			transaction.Invalidate();
633: 		}
634: 		throw ex;
635: 	}
636: 	if (transaction.IsAutoCommit()) {
637: 		transaction.Commit();
638: 	}
639: }
640: 
641: unique_ptr<TableDescription> ClientContext::TableInfo(string schema_name, string table_name) {
642: 	unique_ptr<TableDescription> result;
643: 	RunFunctionInTransaction([&]() {
644: 		// obtain the table info
645: 		auto table = db.catalog->GetEntry<TableCatalogEntry>(*this, schema_name, table_name, true);
646: 		if (!table) {
647: 			return;
648: 		}
649: 		// write the table info to the result
650: 		result = make_unique<TableDescription>();
651: 		result->schema = schema_name;
652: 		result->table = table_name;
653: 		for (auto &column : table->columns) {
654: 			result->columns.push_back(ColumnDefinition(column.name, column.type));
655: 		}
656: 	});
657: 	return result;
658: }
659: 
660: void ClientContext::Append(TableDescription &description, DataChunk &chunk) {
661: 	RunFunctionInTransaction([&]() {
662: 		auto table_entry = db.catalog->GetEntry<TableCatalogEntry>(*this, description.schema, description.table);
663: 		// verify that the table columns and types match up
664: 		if (description.columns.size() != table_entry->columns.size()) {
665: 			throw Exception("Failed to append: table entry has different number of columns!");
666: 		}
667: 		for (idx_t i = 0; i < description.columns.size(); i++) {
668: 			if (description.columns[i].type != table_entry->columns[i].type) {
669: 				throw Exception("Failed to append: table entry has different number of columns!");
670: 			}
671: 		}
672: 		table_entry->storage->Append(*table_entry, *this, chunk);
673: 	});
674: }
675: 
676: void ClientContext::TryBindRelation(Relation &relation, vector<ColumnDefinition> &result_columns) {
677: 	RunFunctionInTransaction([&]() {
678: 		// bind the expressions
679: 		Binder binder(*this);
680: 		auto result = relation.Bind(binder);
681: 		assert(result.names.size() == result.types.size());
682: 		for (idx_t i = 0; i < result.names.size(); i++) {
683: 			result_columns.push_back(ColumnDefinition(result.names[i], result.types[i]));
684: 		}
685: 	});
686: }
687: 
688: unique_ptr<QueryResult> ClientContext::Execute(shared_ptr<Relation> relation) {
689: 	string query;
690: 	if (query_verification_enabled) {
691: 		// run the ToString method of any relation we run, mostly to ensure it doesn't crash
692: 		relation->ToString();
693: 		if (relation->IsReadOnly()) {
694: 			// verify read only statements by running a select statement
695: 			auto select = make_unique<SelectStatement>();
696: 			select->node = relation->GetQueryNode();
697: 			RunStatement(query, move(select), false);
698: 		}
699: 	}
700: 	auto &expected_columns = relation->Columns();
701: 	auto relation_stmt = make_unique<RelationStatement>(relation);
702: 	auto result = RunStatement(query, move(relation_stmt), false);
703: 	// verify that the result types and result names of the query match the expected result types/names
704: 	if (result->types.size() == expected_columns.size()) {
705: 		bool mismatch = false;
706: 		for(idx_t i = 0; i < result->types.size(); i++) {
707: 			if (result->sql_types[i] != expected_columns[i].type || result->names[i] != expected_columns[i].name) {
708: 				mismatch = true;
709: 				break;
710: 			}
711: 		}
712: 		if (!mismatch) {
713: 			// all is as expected: return the result
714: 			return result;
715: 		}
716: 	}
717: 	// result mismatch
718: 	string err_str = "Result mismatch in query!\nExpected the following columns: ";
719: 	for(idx_t i = 0; i < expected_columns.size(); i++) {
720: 		err_str += i == 0 ? "[" : ", ";
721: 		err_str += expected_columns[i].name + " " + SQLTypeToString(expected_columns[i].type);
722: 	}
723: 	err_str += "]\nBut result contained the following: ";
724: 	for(idx_t i = 0; i < result->types.size(); i++) {
725: 		err_str += i == 0 ? "[" : ", ";
726: 		err_str += result->names[i] + " " + SQLTypeToString(result->sql_types[i]);
727: 	}
728: 	err_str += "]";
729: 	return make_unique<MaterializedQueryResult>(err_str);
730: }
[end of src/main/client_context.cpp]
[start of src/main/connection.cpp]
1: #include "duckdb/main/connection.hpp"
2: 
3: #include "duckdb/main/client_context.hpp"
4: #include "duckdb/main/connection_manager.hpp"
5: #include "duckdb/main/database.hpp"
6: #include "duckdb/main/appender.hpp"
7: #include "duckdb/main/relation/read_csv_relation.hpp"
8: #include "duckdb/main/relation/table_relation.hpp"
9: #include "duckdb/main/relation/value_relation.hpp"
10: #include "duckdb/parser/parser.hpp"
11: 
12: using namespace duckdb;
13: using namespace std;
14: 
15: Connection::Connection(DuckDB &database) : db(database), context(make_unique<ClientContext>(database)) {
16: 	db.connection_manager->AddConnection(this);
17: #ifdef DEBUG
18: 	EnableProfiling();
19: #endif
20: }
21: 
22: Connection::~Connection() {
23: 	if (!context->is_invalidated) {
24: 		context->Cleanup();
25: 		db.connection_manager->RemoveConnection(this);
26: 	}
27: }
28: 
29: string Connection::GetProfilingInformation(ProfilerPrintFormat format) {
30: 	if (context->is_invalidated) {
31: 		return "Context is invalidated.";
32: 	}
33: 	if (format == ProfilerPrintFormat::JSON) {
34: 		return context->profiler.ToJSON();
35: 	} else {
36: 		return context->profiler.ToString();
37: 	}
38: }
39: 
40: void Connection::Interrupt() {
41: 	context->Interrupt();
42: }
43: 
44: void Connection::EnableProfiling() {
45: 	context->EnableProfiling();
46: }
47: 
48: void Connection::DisableProfiling() {
49: 	context->DisableProfiling();
50: }
51: 
52: void Connection::EnableQueryVerification() {
53: #ifdef DEBUG
54: 	context->query_verification_enabled = true;
55: #endif
56: }
57: 
58: unique_ptr<QueryResult> Connection::SendQuery(string query) {
59: 	return context->Query(query, true);
60: }
61: 
62: unique_ptr<MaterializedQueryResult> Connection::Query(string query) {
63: 	auto result = context->Query(query, false);
64: 	assert(result->type == QueryResultType::MATERIALIZED_RESULT);
65: 	return unique_ptr_cast<QueryResult, MaterializedQueryResult>(move(result));
66: }
67: 
68: unique_ptr<PreparedStatement> Connection::Prepare(string query) {
69: 	return context->Prepare(query);
70: }
71: 
72: unique_ptr<QueryResult> Connection::QueryParamsRecursive(string query, vector<Value> &values) {
73: 	auto statement = Prepare(query);
74: 	if (!statement->success) {
75: 		return make_unique<MaterializedQueryResult>(statement->error);
76: 	}
77: 	return statement->Execute(values);
78: }
79: 
80: unique_ptr<TableDescription> Connection::TableInfo(string table_name) {
81: 	return TableInfo(DEFAULT_SCHEMA, table_name);
82: }
83: 
84: unique_ptr<TableDescription> Connection::TableInfo(string schema_name, string table_name) {
85: 	return context->TableInfo(schema_name, table_name);
86: }
87: 
88: vector<unique_ptr<SQLStatement>> Connection::ExtractStatements(string query) {
89: 	Parser parser;
90: 	parser.ParseQuery(query);
91: 	return move(parser.statements);
92: }
93: 
94: void Connection::Append(TableDescription &description, DataChunk &chunk) {
95: 	context->Append(description, chunk);
96: }
97: 
98: shared_ptr<Relation> Connection::Table(string table_name) {
99: 	return Table(DEFAULT_SCHEMA, move(table_name));
100: }
101: 
102: shared_ptr<Relation> Connection::Table(string schema_name, string table_name) {
103: 	auto table_info = TableInfo(schema_name, table_name);
104: 	if (!table_info) {
105: 		throw Exception("Table does not exist!");
106: 	}
107: 	return make_shared<TableRelation>(*context, move(table_info));
108: }
109: 
110: shared_ptr<Relation> Connection::Values(vector<vector<Value>> values) {
111: 	vector<string> column_names;
112: 	return Values(move(values), move(column_names));
113: }
114: 
115: shared_ptr<Relation> Connection::Values(vector<vector<Value>> values, vector<string> column_names, string alias) {
116: 	return make_shared<ValueRelation>(*context, move(values), move(column_names), alias);
117: }
118: 
119: shared_ptr<Relation> Connection::Values(string values) {
120: 	vector<string> column_names;
121: 	return Values(move(values), move(column_names));
122: }
123: 
124: shared_ptr<Relation> Connection::Values(string values, vector<string> column_names, string alias) {
125: 	return make_shared<ValueRelation>(*context, move(values), move(column_names), alias);
126: }
127: 
128: shared_ptr<Relation> Connection::ReadCSV(string csv_file, vector<string> columns) {
129: 	// parse columns
130: 	vector<ColumnDefinition> column_list;
131: 	for (auto &column : columns) {
132: 		auto col_list = Parser::ParseColumnList(column);
133: 		if (col_list.size() != 1) {
134: 			throw ParserException("Expected a singlec olumn definition");
135: 		}
136: 		column_list.push_back(move(col_list[0]));
137: 	}
138: 	return make_shared<ReadCSVRelation>(*context, csv_file, move(column_list));
139: }
140: 
141: void Connection::BeginTransaction() {
142: 	auto result = Query("BEGIN TRANSACTION");
143: 	if (!result->success) {
144: 		throw Exception(result->error);
145: 	}
146: }
147: 
148: void Connection::Commit() {
149: 	auto result = Query("COMMIT");
150: 	if (!result->success) {
151: 		throw Exception(result->error);
152: 	}
153: }
154: 
155: void Connection::Rollback() {
156: 	auto result = Query("ROLLBACK");
157: 	if (!result->success) {
158: 		throw Exception(result->error);
159: 	}
160: }
[end of src/main/connection.cpp]
[start of src/optimizer/regex_range_filter.cpp]
1: #include "duckdb/optimizer/regex_range_filter.hpp"
2: 
3: #include "duckdb/catalog/catalog_entry/scalar_function_catalog_entry.hpp"
4: 
5: #include "duckdb/function/scalar/string_functions.hpp"
6: 
7: #include "duckdb/planner/expression.hpp"
8: #include "duckdb/planner/expression/bound_comparison_expression.hpp"
9: #include "duckdb/planner/expression/bound_conjunction_expression.hpp"
10: #include "duckdb/planner/expression/bound_constant_expression.hpp"
11: #include "duckdb/planner/expression/bound_function_expression.hpp"
12: #include "duckdb/planner/operator/logical_filter.hpp"
13: 
14: using namespace duckdb;
15: using namespace std;
16: 
17: unique_ptr<LogicalOperator> RegexRangeFilter::Rewrite(unique_ptr<LogicalOperator> op) {
18: 
19: 	for (idx_t child_idx = 0; child_idx < op->children.size(); child_idx++) {
20: 		op->children[child_idx] = Rewrite(move(op->children[child_idx]));
21: 	}
22: 
23: 	if (op->type != LogicalOperatorType::FILTER) {
24: 		return op;
25: 	}
26: 
27: 	auto new_filter = make_unique<LogicalFilter>();
28: 
29: 	for (auto &expr : op->expressions) {
30: 		if (expr->type == ExpressionType::BOUND_FUNCTION) {
31: 			auto &func = (BoundFunctionExpression &)*expr.get();
32: 			if (func.function.name != "regexp_matches" || func.children.size() != 2) {
33: 				continue;
34: 			}
35: 			auto &info = (RegexpMatchesBindData &)*func.bind_info;
36: 			if (!info.range_success) {
37: 				continue;
38: 			}
39: 			auto filter_left = make_unique<BoundComparisonExpression>(
40: 			    ExpressionType::COMPARE_GREATERTHANOREQUALTO, func.children[0]->Copy(),
41: 			    make_unique<BoundConstantExpression>(Value(info.range_min)));
42: 			auto filter_right = make_unique<BoundComparisonExpression>(
43: 			    ExpressionType::COMPARE_LESSTHANOREQUALTO, func.children[0]->Copy(),
44: 			    make_unique<BoundConstantExpression>(Value(info.range_max)));
45: 			auto filter_expr = make_unique<BoundConjunctionExpression>(ExpressionType::CONJUNCTION_AND,
46: 			                                                           move(filter_left), move(filter_right));
47: 
48: 			new_filter->expressions.push_back(move(filter_expr));
49: 		}
50: 	}
51: 
52: 	if (new_filter->expressions.size() > 0) {
53: 		new_filter->children = move(op->children);
54: 		op->children.clear();
55: 		op->children.push_back(move(new_filter));
56: 	}
57: 
58: 	return op;
59: }
[end of src/optimizer/regex_range_filter.cpp]
[start of src/parser/transform/statement/transform_prepare.cpp]
1: #include "duckdb/parser/statement/drop_statement.hpp"
2: #include "duckdb/parser/statement/execute_statement.hpp"
3: #include "duckdb/parser/statement/prepare_statement.hpp"
4: #include "duckdb/parser/transformer.hpp"
5: 
6: using namespace duckdb;
7: using namespace std;
8: 
9: unique_ptr<PrepareStatement> Transformer::TransformPrepare(PGNode *node) {
10: 	auto stmt = reinterpret_cast<PGPrepareStmt *>(node);
11: 	assert(stmt);
12: 
13: 	if (stmt->argtypes && stmt->argtypes->length > 0) {
14: 		throw NotImplementedException("Prepared statement argument types are not supported, use CAST");
15: 	}
16: 
17: 	auto result = make_unique<PrepareStatement>();
18: 	result->name = string(stmt->name);
19: 	result->statement = TransformStatement(stmt->query);
20: 	prepared_statement_parameter_index = 0;
21: 
22: 	return result;
23: }
24: 
25: unique_ptr<ExecuteStatement> Transformer::TransformExecute(PGNode *node) {
26: 	auto stmt = reinterpret_cast<PGExecuteStmt *>(node);
27: 	assert(stmt);
28: 
29: 	auto result = make_unique<ExecuteStatement>();
30: 	result->name = string(stmt->name);
31: 
32: 	TransformExpressionList(stmt->params, result->values);
33: 	for (auto &expr : result->values) {
34: 		if (expr->GetExpressionType() != ExpressionType::VALUE_CONSTANT &&
35: 		    expr->GetExpressionType() != ExpressionType::VALUE_NULL) {
36: 			throw Exception("Only scalar parameters or NULL supported for EXECUTE");
37: 		}
38: 	}
39: 
40: 	return result;
41: }
42: 
43: unique_ptr<DropStatement> Transformer::TransformDeallocate(PGNode *node) {
44: 	auto stmt = reinterpret_cast<PGDeallocateStmt *>(node);
45: 	assert(stmt);
46: 
47: 	auto result = make_unique<DropStatement>();
48: 	result->info->type = CatalogType::PREPARED_STATEMENT;
49: 	result->info->name = string(stmt->name);
50: 	return result;
51: }
[end of src/parser/transform/statement/transform_prepare.cpp]
[start of src/storage/string_segment.cpp]
1: #include "duckdb/storage/string_segment.hpp"
2: #include "duckdb/storage/buffer_manager.hpp"
3: #include "duckdb/storage/numeric_segment.hpp"
4: #include "duckdb/transaction/update_info.hpp"
5: #include "duckdb/common/vector_operations/vector_operations.hpp"
6: 
7: using namespace duckdb;
8: using namespace std;
9: 
10: StringSegment::StringSegment(BufferManager &manager, idx_t row_start, block_id_t block)
11:     : UncompressedSegment(manager, TypeId::VARCHAR, row_start) {
12: 	this->max_vector_count = 0;
13: 	this->dictionary_offset = 0;
14: 	// the vector_size is given in the size of the dictionary offsets
15: 	this->vector_size = STANDARD_VECTOR_SIZE * sizeof(int32_t) + sizeof(nullmask_t);
16: 	this->string_updates = nullptr;
17: 
18: 	this->block_id = block;
19: 	if (block_id == INVALID_BLOCK) {
20: 		// start off with an empty string segment: allocate space for it
21: 		auto handle = manager.Allocate(Storage::BLOCK_ALLOC_SIZE);
22: 		this->block_id = handle->block_id;
23: 
24: 		ExpandStringSegment(handle->node->buffer);
25: 	}
26: }
27: 
28: StringSegment::~StringSegment() {
29: 	while (head) {
30: 		manager.DestroyBuffer(head->block_id);
31: 		head = move(head->next);
32: 	}
33: }
34: 
35: void StringSegment::ExpandStringSegment(data_ptr_t baseptr) {
36: 	// clear the nullmask for this vector
37: 	auto mask = (nullmask_t *)(baseptr + (max_vector_count * vector_size));
38: 	mask->reset();
39: 
40: 	max_vector_count++;
41: 	if (versions) {
42: 		auto new_versions = unique_ptr<UpdateInfo *[]>(new UpdateInfo *[max_vector_count]);
43: 		memcpy(new_versions.get(), versions.get(), (max_vector_count - 1) * sizeof(UpdateInfo *));
44: 		new_versions[max_vector_count - 1] = nullptr;
45: 		versions = move(new_versions);
46: 	}
47: 
48: 	if (string_updates) {
49: 		auto new_string_updates = unique_ptr<string_update_info_t[]>(new string_update_info_t[max_vector_count]);
50: 		for (idx_t i = 0; i < max_vector_count - 1; i++) {
51: 			new_string_updates[i] = move(string_updates[i]);
52: 		}
53: 		new_string_updates[max_vector_count - 1] = 0;
54: 		string_updates = move(new_string_updates);
55: 	}
56: }
57: 
58: //===--------------------------------------------------------------------===//
59: // Scan
60: //===--------------------------------------------------------------------===//
61: void StringSegment::InitializeScan(ColumnScanState &state) {
62: 	// pin the primary buffer
63: 	state.primary_handle = manager.Pin(block_id);
64: }
65: 
66: //===--------------------------------------------------------------------===//
67: // Fetch base data
68: //===--------------------------------------------------------------------===//
69: void StringSegment::FetchBaseData(ColumnScanState &state, idx_t vector_index, Vector &result) {
70: 	// clear any previously locked buffers and get the primary buffer handle
71: 	auto handle = state.primary_handle.get();
72: 	state.handles.clear();
73: 
74: 	// fetch the data from the base segment
75: 	FetchBaseData(state, handle->node->buffer, vector_index, result, GetVectorCount(vector_index));
76: }
77: 
78: void StringSegment::FetchBaseData(ColumnScanState &state, data_ptr_t baseptr, idx_t vector_index, Vector &result,
79:                                   idx_t count) {
80: 	auto base = baseptr + vector_index * vector_size;
81: 
82: 	auto &base_nullmask = *((nullmask_t *)base);
83: 	auto base_data = (int32_t *)(base + sizeof(nullmask_t));
84: 	auto result_data = FlatVector::GetData<string_t>(result);
85: 
86: 	if (string_updates && string_updates[vector_index]) {
87: 		// there are updates: merge them in
88: 		auto &info = *string_updates[vector_index];
89: 		idx_t update_idx = 0;
90: 		for (idx_t i = 0; i < count; i++) {
91: 			if (update_idx < info.count && info.ids[update_idx] == i) {
92: 				// use update info
93: 				result_data[i] = ReadString(state.handles, info.block_ids[update_idx], info.offsets[update_idx]);
94: 				update_idx++;
95: 			} else {
96: 				// use base table info
97: 				result_data[i] = FetchStringFromDict(state.handles, baseptr, base_data[i]);
98: 			}
99: 		}
100: 	} else {
101: 		// no updates: fetch only from the string dictionary
102: 		for (idx_t i = 0; i < count; i++) {
103: 			result_data[i] = FetchStringFromDict(state.handles, baseptr, base_data[i]);
104: 		}
105: 	}
106: 	FlatVector::SetNullmask(result, base_nullmask);
107: }
108: 
109: //===--------------------------------------------------------------------===//
110: // Fetch update data
111: //===--------------------------------------------------------------------===//
112: void StringSegment::FetchUpdateData(ColumnScanState &state, Transaction &transaction, UpdateInfo *info,
113:                                     Vector &result) {
114: 	// fetch data from updates
115: 	auto handle = state.primary_handle.get();
116: 
117: 	auto result_data = FlatVector::GetData<string_t>(result);
118: 	auto &result_mask = FlatVector::Nullmask(result);
119: 	UpdateInfo::UpdatesForTransaction(info, transaction, [&](UpdateInfo *current) {
120: 		auto info_data = (string_location_t *)current->tuple_data;
121: 		for (idx_t i = 0; i < current->N; i++) {
122: 			auto string = FetchString(state.handles, handle->node->buffer, info_data[i]);
123: 			result_data[current->tuples[i]] = string;
124: 			result_mask[current->tuples[i]] = current->nullmask[current->tuples[i]];
125: 		}
126: 	});
127: }
128: 
129: //===--------------------------------------------------------------------===//
130: // Fetch strings
131: //===--------------------------------------------------------------------===//
132: void StringSegment::FetchStringLocations(data_ptr_t baseptr, row_t *ids, idx_t vector_index, idx_t vector_offset,
133:                                          idx_t count, string_location_t result[]) {
134: 	auto base = baseptr + vector_index * vector_size;
135: 	auto base_data = (int32_t *)(base + sizeof(nullmask_t));
136: 
137: 	if (string_updates && string_updates[vector_index]) {
138: 		// there are updates: merge them in
139: 		auto &info = *string_updates[vector_index];
140: 		idx_t update_idx = 0;
141: 		for (idx_t i = 0; i < count; i++) {
142: 			auto id = ids[i] - vector_offset;
143: 			while (update_idx < info.count && info.ids[update_idx] < id) {
144: 				update_idx++;
145: 			}
146: 			if (update_idx < info.count && info.ids[update_idx] == id) {
147: 				// use update info
148: 				result[i].block_id = info.block_ids[update_idx];
149: 				result[i].offset = info.offsets[update_idx];
150: 				update_idx++;
151: 			} else {
152: 				// use base table info
153: 				result[i] = FetchStringLocation(baseptr, base_data[id]);
154: 			}
155: 		}
156: 	} else {
157: 		// no updates: fetch strings from base vector
158: 		for (idx_t i = 0; i < count; i++) {
159: 			auto id = ids[i] - vector_offset;
160: 			result[i] = FetchStringLocation(baseptr, base_data[id]);
161: 		}
162: 	}
163: }
164: 
165: string_location_t StringSegment::FetchStringLocation(data_ptr_t baseptr, int32_t dict_offset) {
166: 	if (dict_offset == 0) {
167: 		return string_location_t(INVALID_BLOCK, 0);
168: 	}
169: 	// look up result in dictionary
170: 	auto dict_end = baseptr + Storage::BLOCK_SIZE;
171: 	auto dict_pos = dict_end - dict_offset;
172: 	auto string_length = *((uint16_t *)dict_pos);
173: 	string_location_t result;
174: 	if (string_length == BIG_STRING_MARKER) {
175: 		ReadStringMarker(dict_pos, result.block_id, result.offset);
176: 	} else {
177: 		result.block_id = INVALID_BLOCK;
178: 		result.offset = dict_offset;
179: 	}
180: 	return result;
181: }
182: 
183: string_t StringSegment::FetchStringFromDict(buffer_handle_set_t &handles, data_ptr_t baseptr, int32_t dict_offset) {
184: 	// fetch base data
185: 	string_location_t location = FetchStringLocation(baseptr, dict_offset);
186: 	return FetchString(handles, baseptr, location);
187: }
188: 
189: string_t StringSegment::FetchString(buffer_handle_set_t &handles, data_ptr_t baseptr, string_location_t location) {
190: 	if (location.block_id != INVALID_BLOCK) {
191: 		// big string marker: read from separate block
192: 		return ReadString(handles, location.block_id, location.offset);
193: 	} else {
194: 		if (location.offset == 0) {
195: 			return string_t(nullptr, 0);
196: 		}
197: 		// normal string: read string from this block
198: 		auto dict_end = baseptr + Storage::BLOCK_SIZE;
199: 		auto dict_pos = dict_end - location.offset;
200: 		auto string_length = *((uint16_t *)dict_pos);
201: 
202: 		auto str_ptr = (char *)(dict_pos + sizeof(uint16_t));
203: 		return string_t(str_ptr, string_length);
204: 	}
205: }
206: 
207: void StringSegment::FetchRow(ColumnFetchState &state, Transaction &transaction, row_t row_id, Vector &result,
208:                              idx_t result_idx) {
209: 	auto read_lock = lock.GetSharedLock();
210: 
211: 	idx_t vector_index = row_id / STANDARD_VECTOR_SIZE;
212: 	idx_t id_in_vector = row_id - vector_index * STANDARD_VECTOR_SIZE;
213: 	assert(vector_index < max_vector_count);
214: 
215: 	data_ptr_t baseptr;
216: 
217: 	// fetch a single row from the string segment
218: 	// first pin the main buffer if it is not already pinned
219: 	auto entry = state.handles.find(block_id);
220: 	if (entry == state.handles.end()) {
221: 		// not pinned yet: pin it
222: 		auto handle = manager.Pin(block_id);
223: 		baseptr = handle->node->buffer;
224: 		state.handles[block_id] = move(handle);
225: 	} else {
226: 		// already pinned: use the pinned handle
227: 		baseptr = entry->second->node->buffer;
228: 	}
229: 
230: 	auto base = baseptr + vector_index * vector_size;
231: 	auto &base_nullmask = *((nullmask_t *)base);
232: 	auto base_data = (int32_t *)(base + sizeof(nullmask_t));
233: 	auto result_data = FlatVector::GetData<string_t>(result);
234: 	auto &result_mask = FlatVector::Nullmask(result);
235: 
236: 	bool found_data = false;
237: 	// first see if there is any updated version of this tuple we must fetch
238: 	if (versions && versions[vector_index]) {
239: 		UpdateInfo::UpdatesForTransaction(versions[vector_index], transaction, [&](UpdateInfo *current) {
240: 			auto info_data = (string_location_t *)current->tuple_data;
241: 			// loop over the tuples in this UpdateInfo
242: 			for (idx_t i = 0; i < current->N; i++) {
243: 				if (current->tuples[i] == row_id) {
244: 					// found the relevant tuple
245: 					found_data = true;
246: 					result_data[result_idx] = FetchString(state.handles, baseptr, info_data[i]);
247: 					result_mask[result_idx] = current->nullmask[current->tuples[i]];
248: 					break;
249: 				} else if (current->tuples[i] > row_id) {
250: 					// tuples are sorted: so if the current tuple is > row_id we will not find it anymore
251: 					break;
252: 				}
253: 			}
254: 		});
255: 	}
256: 	if (!found_data) {
257: 		// there was no updated version to be fetched: fetch the base version instead
258: 		if (string_updates && string_updates[vector_index]) {
259: 			// there are updates: check if we should use them
260: 			auto &info = *string_updates[vector_index];
261: 			for (idx_t i = 0; i < info.count; i++) {
262: 				if (info.ids[i] == id_in_vector) {
263: 					// use the update
264: 					result_data[result_idx] = ReadString(state.handles, info.block_ids[i], info.offsets[i]);
265: 					break;
266: 				} else if (info.ids[i] > id_in_vector) {
267: 					break;
268: 				}
269: 			}
270: 		} else {
271: 			// no version was found yet: fetch base table version
272: 			result_data[result_idx] = FetchStringFromDict(state.handles, baseptr, base_data[id_in_vector]);
273: 		}
274: 	}
275: 	result_mask[result_idx] = base_nullmask[id_in_vector];
276: }
277: 
278: //===--------------------------------------------------------------------===//
279: // Append
280: //===--------------------------------------------------------------------===//
281: idx_t StringSegment::Append(SegmentStatistics &stats, Vector &data, idx_t offset, idx_t count) {
282: 	assert(data.type == TypeId::VARCHAR);
283: 	auto handle = manager.Pin(block_id);
284: 
285: 	idx_t initial_count = tuple_count;
286: 	while (count > 0) {
287: 		// get the vector index of the vector to append to and see how many tuples we can append to that vector
288: 		idx_t vector_index = tuple_count / STANDARD_VECTOR_SIZE;
289: 		if (vector_index == max_vector_count) {
290: 			// we are at the maximum vector, check if there is space to increase the maximum vector count
291: 			// as a heuristic, we only allow another vector to be added if we have at least 32 bytes per string
292: 			// remaining (32KB out of a 256KB block, or around 12% empty)
293: 			if (RemainingSpace() >= STANDARD_VECTOR_SIZE * 32) {
294: 				// we have enough remaining space to add another vector
295: 				ExpandStringSegment(handle->node->buffer);
296: 			} else {
297: 				break;
298: 			}
299: 		}
300: 		idx_t current_tuple_count = tuple_count - vector_index * STANDARD_VECTOR_SIZE;
301: 		idx_t append_count = std::min(STANDARD_VECTOR_SIZE - current_tuple_count, count);
302: 
303: 		// now perform the actual append
304: 		AppendData(stats, handle->node->buffer + vector_size * vector_index, handle->node->buffer + Storage::BLOCK_SIZE,
305: 		           current_tuple_count, data, offset, append_count);
306: 
307: 		count -= append_count;
308: 		offset += append_count;
309: 		tuple_count += append_count;
310: 	}
311: 	return tuple_count - initial_count;
312: }
313: 
314: void StringSegment::AppendData(SegmentStatistics &stats, data_ptr_t target, data_ptr_t end, idx_t target_offset,
315:                                Vector &source, idx_t offset, idx_t count) {
316: 	VectorData adata;
317: 	source.Orrify(count, adata);
318: 
319: 	auto sdata = (string_t *)adata.data;
320: 	auto &result_nullmask = *((nullmask_t *)target);
321: 	auto result_data = (int32_t *)(target + sizeof(nullmask_t));
322: 
323: 	idx_t remaining_strings = STANDARD_VECTOR_SIZE - (this->tuple_count % STANDARD_VECTOR_SIZE);
324: 	for (idx_t i = 0; i < count; i++) {
325: 		auto source_idx = adata.sel->get_index(offset + i);
326: 		auto target_idx = target_offset + i;
327: 		if ((*adata.nullmask)[source_idx]) {
328: 			// null value is stored as -1
329: 			result_data[target_idx] = 0;
330: 			result_nullmask[target_idx] = true;
331: 			stats.has_null = true;
332: 		} else {
333: 			assert(dictionary_offset < Storage::BLOCK_SIZE);
334: 			// non-null value, check if we can fit it within the block
335: 			idx_t string_length = sdata[source_idx].GetSize();
336: 			idx_t total_length = string_length + 1 + sizeof(uint16_t);
337: 
338: 			if (string_length > stats.max_string_length) {
339: 				stats.max_string_length = string_length;
340: 			}
341: 			// determine hwether or not the string needs to be stored in an overflow block
342: 			// we never place small strings in the overflow blocks: the pointer would take more space than the
343: 			// string itself we always place big strings (>= STRING_BLOCK_LIMIT) in the overflow blocks we also have
344: 			// to always leave enough room for BIG_STRING_MARKER_SIZE for each of the remaining strings
345: 			if (total_length > BIG_STRING_MARKER_BASE_SIZE &&
346: 			    (total_length >= STRING_BLOCK_LIMIT ||
347: 			     total_length + (remaining_strings * BIG_STRING_MARKER_SIZE) > RemainingSpace())) {
348: 				assert(RemainingSpace() >= BIG_STRING_MARKER_SIZE);
349: 				// string is too big for block: write to overflow blocks
350: 				block_id_t block;
351: 				int32_t offset;
352: 				// write the string into the current string block
353: 				WriteString(sdata[source_idx], block, offset);
354: 
355: 				dictionary_offset += BIG_STRING_MARKER_SIZE;
356: 				auto dict_pos = end - dictionary_offset;
357: 
358: 				// write a big string marker into the dictionary
359: 				WriteStringMarker(dict_pos, block, offset);
360: 
361: 				stats.has_overflow_strings = true;
362: 			} else {
363: 				// string fits in block, append to dictionary and increment dictionary position
364: 				assert(string_length < std::numeric_limits<uint16_t>::max());
365: 				dictionary_offset += total_length;
366: 				auto dict_pos = end - dictionary_offset;
367: 
368: 				// first write the length as u16
369: 				uint16_t string_length_u16 = string_length;
370: 				memcpy(dict_pos, &string_length_u16, sizeof(uint16_t));
371: 				// now write the actual string data into the dictionary
372: 				memcpy(dict_pos + sizeof(uint16_t), sdata[source_idx].GetData(), string_length + 1);
373: 			}
374: 			// place the dictionary offset into the set of vectors
375: 			result_data[target_idx] = dictionary_offset;
376: 		}
377: 		remaining_strings--;
378: 	}
379: }
380: 
381: void StringSegment::WriteString(string_t string, block_id_t &result_block, int32_t &result_offset) {
382: 	assert(strlen(string.GetData()) == string.GetSize());
383: 	if (overflow_writer) {
384: 		// overflow writer is set: write string there
385: 		overflow_writer->WriteString(string, result_block, result_offset);
386: 	} else {
387: 		// default overflow behavior: use in-memory buffer to store the overflow string
388: 		WriteStringMemory(string, result_block, result_offset);
389: 	}
390: }
391: 
392: void StringSegment::WriteStringMemory(string_t string, block_id_t &result_block, int32_t &result_offset) {
393: 	uint32_t total_length = string.GetSize() + 1 + sizeof(uint32_t);
394: 	unique_ptr<BufferHandle> handle;
395: 	// check if the string fits in the current block
396: 	if (!head || head->offset + total_length >= head->size) {
397: 		// string does not fit, allocate space for it
398: 		// create a new string block
399: 		idx_t alloc_size = std::max((idx_t)total_length, (idx_t)Storage::BLOCK_ALLOC_SIZE);
400: 		auto new_block = make_unique<StringBlock>();
401: 		new_block->offset = 0;
402: 		new_block->size = alloc_size;
403: 		// allocate an in-memory buffer for it
404: 		handle = manager.Allocate(alloc_size);
405: 		new_block->block_id = handle->block_id;
406: 		new_block->next = move(head);
407: 		head = move(new_block);
408: 	} else {
409: 		// string fits, copy it into the current block
410: 		handle = manager.Pin(head->block_id);
411: 	}
412: 
413: 	result_block = head->block_id;
414: 	result_offset = head->offset;
415: 
416: 	// copy the string and the length there
417: 	auto ptr = handle->node->buffer + head->offset;
418: 	memcpy(ptr, &string.length, sizeof(uint32_t));
419: 	ptr += sizeof(uint32_t);
420: 	memcpy(ptr, string.GetData(), string.length + 1);
421: 	head->offset += total_length;
422: }
423: 
424: string_t StringSegment::ReadString(buffer_handle_set_t &handles, block_id_t block, int32_t offset) {
425: 	assert(offset < Storage::BLOCK_SIZE);
426: 	if (block == INVALID_BLOCK) {
427: 		return string_t(nullptr, 0);
428: 	}
429: 	if (block < MAXIMUM_BLOCK) {
430: 		// read the overflow string from disk
431: 		// pin the initial handle and read the length
432: 		auto handle = manager.Pin(block);
433: 		uint32_t length = *((uint32_t *)(handle->node->buffer + offset));
434: 		uint32_t remaining = length + 1;
435: 		offset += sizeof(uint32_t);
436: 
437: 		// allocate a buffer to store the string
438: 		auto alloc_size = std::max((idx_t)Storage::BLOCK_ALLOC_SIZE, (idx_t)length + 1 + sizeof(uint32_t));
439: 		auto target_handle = manager.Allocate(alloc_size, true);
440: 		auto target_ptr = target_handle->node->buffer;
441: 		// write the length in this block as well
442: 		*((uint32_t *)target_ptr) = length;
443: 		target_ptr += sizeof(uint32_t);
444: 		// now append the string to the single buffer
445: 		while (remaining > 0) {
446: 			idx_t to_write = std::min((idx_t)remaining, (idx_t)(Storage::BLOCK_SIZE - sizeof(block_id_t) - offset));
447: 			memcpy(target_ptr, handle->node->buffer + offset, to_write);
448: 
449: 			remaining -= to_write;
450: 			offset += to_write;
451: 			target_ptr += to_write;
452: 			if (remaining > 0) {
453: 				// read the next block
454: 				block_id_t next_block = *((block_id_t *)(handle->node->buffer + offset));
455: 				handle = manager.Pin(next_block);
456: 				offset = 0;
457: 			}
458: 		}
459: 
460: 		auto final_buffer = target_handle->node->buffer;
461: 		handles.insert(make_pair(target_handle->block_id, move(target_handle)));
462: 		return ReadString(final_buffer, 0);
463: 	} else {
464: 		// read the overflow string from memory
465: 		// first pin the handle, if it is not pinned yet
466: 		BufferHandle *handle;
467: 		auto entry = handles.find(block);
468: 		if (entry == handles.end()) {
469: 			auto pinned_handle = manager.Pin(block);
470: 			handle = pinned_handle.get();
471: 
472: 			handles.insert(make_pair(block, move(pinned_handle)));
473: 		} else {
474: 			handle = entry->second.get();
475: 		}
476: 		return ReadString(handle->node->buffer, offset);
477: 	}
478: }
479: 
480: string_t StringSegment::ReadString(data_ptr_t target, int32_t offset) {
481: 	auto ptr = target + offset;
482: 	auto str_length = *((uint32_t *)ptr);
483: 	auto str_ptr = (char *)(ptr + sizeof(uint32_t));
484: 	return string_t(str_ptr, str_length);
485: }
486: 
487: void StringSegment::WriteStringMarker(data_ptr_t target, block_id_t block_id, int32_t offset) {
488: 	uint16_t length = BIG_STRING_MARKER;
489: 	memcpy(target, &length, sizeof(uint16_t));
490: 	target += sizeof(uint16_t);
491: 	memcpy(target, &block_id, sizeof(block_id_t));
492: 	target += sizeof(block_id_t);
493: 	memcpy(target, &offset, sizeof(int32_t));
494: }
495: 
496: void StringSegment::ReadStringMarker(data_ptr_t target, block_id_t &block_id, int32_t &offset) {
497: 	target += sizeof(uint16_t);
498: 	memcpy(&block_id, target, sizeof(block_id_t));
499: 	target += sizeof(block_id_t);
500: 	memcpy(&offset, target, sizeof(int32_t));
501: }
502: 
503: //===--------------------------------------------------------------------===//
504: // String Update
505: //===--------------------------------------------------------------------===//
506: string_update_info_t StringSegment::CreateStringUpdate(SegmentStatistics &stats, Vector &update, row_t *ids,
507:                                                        idx_t count, idx_t vector_offset) {
508: 	auto info = make_unique<StringUpdateInfo>();
509: 	info->count = count;
510: 	auto strings = FlatVector::GetData<string_t>(update);
511: 	auto &update_nullmask = FlatVector::Nullmask(update);
512: 	for (idx_t i = 0; i < count; i++) {
513: 		info->ids[i] = ids[i] - vector_offset;
514: 		// copy the string into the block
515: 		if (!update_nullmask[i]) {
516: 			WriteString(strings[i], info->block_ids[i], info->offsets[i]);
517: 		} else {
518: 			info->block_ids[i] = INVALID_BLOCK;
519: 			info->offsets[i] = 0;
520: 		}
521: 	}
522: 	return info;
523: }
524: 
525: string_update_info_t StringSegment::MergeStringUpdate(SegmentStatistics &stats, Vector &update, row_t *ids,
526:                                                       idx_t update_count, idx_t vector_offset,
527:                                                       StringUpdateInfo &update_info) {
528: 	auto info = make_unique<StringUpdateInfo>();
529: 
530: 	// perform a merge between the new and old indexes
531: 	auto strings = FlatVector::GetData<string_t>(update);
532: 	auto &update_nullmask = FlatVector::Nullmask(update);
533: 	auto pick_new = [&](idx_t id, idx_t idx, idx_t count) {
534: 		info->ids[count] = id;
535: 		if (!update_nullmask[idx]) {
536: 			WriteString(strings[idx], info->block_ids[count], info->offsets[count]);
537: 		} else {
538: 			info->block_ids[count] = INVALID_BLOCK;
539: 			info->offsets[count] = 0;
540: 		}
541: 	};
542: 	auto merge = [&](idx_t id, idx_t aidx, idx_t bidx, idx_t count) {
543: 		// merge: only pick new entry
544: 		pick_new(id, aidx, count);
545: 	};
546: 	auto pick_old = [&](idx_t id, idx_t bidx, idx_t count) {
547: 		// pick old entry
548: 		info->ids[count] = id;
549: 		info->block_ids[count] = update_info.block_ids[bidx];
550: 		info->offsets[count] = update_info.offsets[bidx];
551: 	};
552: 
553: 	info->count =
554: 	    merge_loop(ids, update_info.ids, update_count, update_info.count, vector_offset, merge, pick_new, pick_old);
555: 	return info;
556: }
557: 
558: //===--------------------------------------------------------------------===//
559: // Update Info
560: //===--------------------------------------------------------------------===//
561: void StringSegment::MergeUpdateInfo(UpdateInfo *node, row_t *ids, idx_t update_count, idx_t vector_offset,
562:                                     string_location_t base_data[], nullmask_t base_nullmask) {
563: 	auto info_data = (string_location_t *)node->tuple_data;
564: 
565: 	// first we copy the old update info into a temporary structure
566: 	sel_t old_ids[STANDARD_VECTOR_SIZE];
567: 	string_location_t old_data[STANDARD_VECTOR_SIZE];
568: 
569: 	memcpy(old_ids, node->tuples, node->N * sizeof(sel_t));
570: 	memcpy(old_data, node->tuple_data, node->N * sizeof(string_location_t));
571: 
572: 	// now we perform a merge of the new ids with the old ids
573: 	auto merge = [&](idx_t id, idx_t aidx, idx_t bidx, idx_t count) {
574: 		// new_id and old_id are the same, insert the old data in the UpdateInfo
575: 		assert(old_data[bidx].IsValid());
576: 		info_data[count] = old_data[bidx];
577: 		node->tuples[count] = id;
578: 	};
579: 	auto pick_new = [&](idx_t id, idx_t aidx, idx_t count) {
580: 		// new_id comes before the old id, insert the base table data into the update info
581: 		assert(base_data[aidx].IsValid());
582: 		info_data[count] = base_data[aidx];
583: 		node->nullmask[id] = base_nullmask[aidx];
584: 
585: 		node->tuples[count] = id;
586: 	};
587: 	auto pick_old = [&](idx_t id, idx_t bidx, idx_t count) {
588: 		// old_id comes before new_id, insert the old data
589: 		assert(old_data[bidx].IsValid());
590: 		info_data[count] = old_data[bidx];
591: 		node->tuples[count] = id;
592: 	};
593: 	// perform the merge
594: 	node->N = merge_loop(ids, old_ids, update_count, node->N, vector_offset, merge, pick_new, pick_old);
595: }
596: 
597: //===--------------------------------------------------------------------===//
598: // Update
599: //===--------------------------------------------------------------------===//
600: void StringSegment::Update(ColumnData &column_data, SegmentStatistics &stats, Transaction &transaction, Vector &update,
601:                            row_t *ids, idx_t count, idx_t vector_index, idx_t vector_offset, UpdateInfo *node) {
602: 	if (!string_updates) {
603: 		string_updates = unique_ptr<string_update_info_t[]>(new string_update_info_t[max_vector_count]);
604: 	}
605: 
606: 	// first pin the base block
607: 	auto handle = manager.Pin(block_id);
608: 	auto baseptr = handle->node->buffer;
609: 	auto base = baseptr + vector_index * vector_size;
610: 	auto &base_nullmask = *((nullmask_t *)base);
611: 
612: 	// fetch the original string locations and copy the original nullmask
613: 	string_location_t string_locations[STANDARD_VECTOR_SIZE];
614: 	nullmask_t original_nullmask = base_nullmask;
615: 	FetchStringLocations(baseptr, ids, vector_index, vector_offset, count, string_locations);
616: 
617: 	string_update_info_t new_update_info;
618: 	// next up: create the updates
619: 	if (!string_updates[vector_index]) {
620: 		// no string updates yet, allocate a block and place the updates there
621: 		new_update_info = CreateStringUpdate(stats, update, ids, count, vector_offset);
622: 	} else {
623: 		// string updates already exist, merge the string updates together
624: 		new_update_info = MergeStringUpdate(stats, update, ids, count, vector_offset, *string_updates[vector_index]);
625: 	}
626: 
627: 	// now update the original nullmask
628: 	auto &update_nullmask = FlatVector::Nullmask(update);
629: 	for (idx_t i = 0; i < count; i++) {
630: 		base_nullmask[ids[i] - vector_offset] = update_nullmask[i];
631: 	}
632: 
633: 	// now that the original strings are placed in the undo buffer and the updated strings are placed in the base table
634: 	// create the update node
635: 	if (!node) {
636: 		// create a new node in the undo buffer for this update
637: 		node = CreateUpdateInfo(column_data, transaction, ids, count, vector_index, vector_offset,
638: 		                        sizeof(string_location_t));
639: 
640: 		// copy the string location data into the undo buffer
641: 		node->nullmask = original_nullmask;
642: 		memcpy(node->tuple_data, string_locations, sizeof(string_location_t) * count);
643: 	} else {
644: 		// node in the update info already exists, merge the new updates in
645: 		MergeUpdateInfo(node, ids, count, vector_offset, string_locations, original_nullmask);
646: 	}
647: 	// finally move the string updates in place
648: 	string_updates[vector_index] = move(new_update_info);
649: }
650: 
651: void StringSegment::RollbackUpdate(UpdateInfo *info) {
652: 	auto lock_handle = lock.GetExclusiveLock();
653: 
654: 	idx_t new_count = 0;
655: 	auto &update_info = *string_updates[info->vector_index];
656: 	auto string_locations = (string_location_t *)info->tuple_data;
657: 
658: 	// put the previous NULL values back
659: 	auto handle = manager.Pin(block_id);
660: 	auto baseptr = handle->node->buffer;
661: 	auto base = baseptr + info->vector_index * vector_size;
662: 	auto &base_nullmask = *((nullmask_t *)base);
663: 	for (idx_t i = 0; i < info->N; i++) {
664: 		base_nullmask[info->tuples[i]] = info->nullmask[info->tuples[i]];
665: 	}
666: 
667: 	// now put the original values back into the update info
668: 	idx_t old_idx = 0;
669: 	for (idx_t i = 0; i < update_info.count; i++) {
670: 		if (old_idx >= info->N || update_info.ids[i] != info->tuples[old_idx]) {
671: 			assert(old_idx >= info->N || update_info.ids[i] < info->tuples[old_idx]);
672: 			// this entry is not rolled back: insert entry directly
673: 			update_info.ids[new_count] = update_info.ids[i];
674: 			update_info.block_ids[new_count] = update_info.block_ids[i];
675: 			update_info.offsets[new_count] = update_info.offsets[i];
676: 			new_count++;
677: 		} else {
678: 			// this entry is being rolled back
679: 			auto &old_location = string_locations[old_idx];
680: 			if (old_location.block_id != INVALID_BLOCK) {
681: 				// not rolled back to base table: insert entry again
682: 				update_info.ids[new_count] = update_info.ids[i];
683: 				update_info.block_ids[new_count] = old_location.block_id;
684: 				update_info.offsets[new_count] = old_location.offset;
685: 				new_count++;
686: 			}
687: 			old_idx++;
688: 		}
689: 	}
690: 
691: 	if (new_count == 0) {
692: 		// all updates are rolled back: delete the string update vector
693: 		string_updates[info->vector_index].reset();
694: 	} else {
695: 		// set the count of the new string update vector
696: 		update_info.count = new_count;
697: 	}
698: 	CleanupUpdate(info);
699: }
[end of src/storage/string_segment.cpp]
[start of tools/rpkg/src/duckdbr.cpp]
1: #include "duckdb.h"
2: 
3: #include <Rdefines.h>
4: #include <algorithm>
5: 
6: // motherfucker
7: #undef error
8: 
9: using namespace duckdb;
10: using namespace std;
11: 
12: struct RStatement {
13: 	unique_ptr<PreparedStatement> stmt;
14: 	vector<Value> parameters;
15: };
16: 
17: // converter for primitive types
18: template <class SRC, class DEST>
19: static void vector_to_r(Vector &src_vec, size_t count, void *dest, uint64_t dest_offset, DEST na_val) {
20: 	auto src_ptr = FlatVector::GetData<SRC>(src_vec);
21: 	auto &nullmask = FlatVector::Nullmask(src_vec);
22: 	auto dest_ptr = ((DEST *)dest) + dest_offset;
23: 	for (size_t row_idx = 0; row_idx < count; row_idx++) {
24: 		dest_ptr[row_idx] = nullmask[row_idx] ? na_val : src_ptr[row_idx];
25: 	}
26: }
27: 
28: struct RDoubleType {
29: 	static bool IsNull(double val) {
30: 		return ISNA(val);
31: 	}
32: 
33: 	static double Convert(double val) {
34: 		return val;
35: 	}
36: };
37: 
38: struct RDateType {
39: 	static bool IsNull(double val) {
40: 		return RDoubleType::IsNull(val);
41: 	}
42: 
43: 	static double Convert(double val) {
44: 		return (date_t)val + 719528; // MAGIC!
45: 	}
46: };
47: 
48: struct RTimestampType {
49: 	static bool IsNull(double val) {
50: 		return RDoubleType::IsNull(val);
51: 	}
52: 
53: 	static timestamp_t Convert(double val) {
54: 		date_t date = Date::EpochToDate((int64_t)val);
55: 		dtime_t time = (dtime_t)(((int64_t)val % (60 * 60 * 24)) * 1000);
56: 		return Timestamp::FromDatetime(date, time);
57: 	}
58: };
59: 
60: struct RIntegerType {
61: 	static bool IsNull(int val) {
62: 		return val == NA_INTEGER;
63: 	}
64: 
65: 	static int Convert(int val) {
66: 		return val;
67: 	}
68: };
69: 
70: struct RBooleanType {
71: 	static bool IsNull(int val) {
72: 		return RIntegerType::IsNull(val);
73: 	}
74: 
75: 	static bool Convert(int val) {
76: 		return val;
77: 	}
78: };
79: 
80: template <class SRC, class DST, class RTYPE>
81: static void AppendColumnSegment(SRC *source_data, Vector &result, idx_t count) {
82: 	auto result_data = FlatVector::GetData<DST>(result);
83: 	auto &result_mask = FlatVector::Nullmask(result);
84: 	for (idx_t i = 0; i < count; i++) {
85: 		auto val = source_data[i];
86: 		if (RTYPE::IsNull(val)) {
87: 			result_mask[i] = true;
88: 		} else {
89: 			result_data[i] = RTYPE::Convert(val);
90: 		}
91: 	}
92: }
93: 
94: static void AppendStringSegment(SEXP coldata, Vector &result, idx_t row_idx, idx_t count) {
95: 	auto result_data = FlatVector::GetData<string_t>(result);
96: 	auto &result_mask = FlatVector::Nullmask(result);
97: 	for (idx_t i = 0; i < count; i++) {
98: 		SEXP val = STRING_ELT(coldata, row_idx + i);
99: 		if (val == NA_STRING) {
100: 			result_mask[i] = true;
101: 		} else {
102: 			result_data[i] = string_t((char *)CHAR(val));
103: 		}
104: 	}
105: }
106: 
107: static void AppendFactor(SEXP coldata, Vector &result, idx_t row_idx, idx_t count) {
108: 	auto source_data = INTEGER_POINTER(coldata) + row_idx;
109: 	auto result_data = FlatVector::GetData<string_t>(result);
110: 	auto &result_mask = FlatVector::Nullmask(result);
111: 	SEXP factor_levels = GET_LEVELS(coldata);
112: 	for (idx_t i = 0; i < count; i++) {
113: 		int val = source_data[i];
114: 		if (RIntegerType::IsNull(val)) {
115: 			result_mask[i] = true;
116: 		} else {
117: 			result_data[i] = string_t(CHAR(STRING_ELT(factor_levels, val - 1)));
118: 		}
119: 	}
120: }
121: 
122: static SEXP cstr_to_charsexp(const char *s) {
123: 	SEXP retsexp = PROTECT(mkCharCE(s, CE_UTF8));
124: 	if (!retsexp) {
125: 		Rf_error("cpp_str_to_charsexp: Memory allocation failed");
126: 		UNPROTECT(1);
127: 	}
128: 	return retsexp;
129: }
130: 
131: static SEXP cpp_str_to_charsexp(string s) {
132: 	return cstr_to_charsexp(s.c_str());
133: }
134: 
135: static SEXP cpp_str_to_strsexp(vector<string> s) {
136: 	SEXP retsexp = PROTECT(NEW_STRING(s.size()));
137: 	if (!retsexp) {
138: 		Rf_error("cpp_str_to_strsexp: Memory allocation failed");
139: 		UNPROTECT(1);
140: 	}
141: 	for (idx_t i = 0; i < s.size(); i++) {
142: 		SET_STRING_ELT(retsexp, i, cpp_str_to_charsexp(s[i]));
143: 		UNPROTECT(1);
144: 	}
145: 	return retsexp;
146: }
147: 
148: enum class RType { UNKNOWN, LOGICAL, INTEGER, NUMERIC, STRING, FACTOR, DATE, TIMESTAMP };
149: 
150: static RType detect_rtype(SEXP v) {
151: 	if (TYPEOF(v) == REALSXP && TYPEOF(GET_CLASS(v)) == STRSXP &&
152: 	    strcmp("POSIXct", CHAR(STRING_ELT(GET_CLASS(v), 0))) == 0) {
153: 		return RType::TIMESTAMP;
154: 	} else if (TYPEOF(v) == REALSXP && TYPEOF(GET_CLASS(v)) == STRSXP &&
155: 	           strcmp("Date", CHAR(STRING_ELT(GET_CLASS(v), 0))) == 0) {
156: 		return RType::DATE;
157: 	} else if (isFactor(v) && TYPEOF(v) == INTSXP) {
158: 		return RType::FACTOR;
159: 	} else if (TYPEOF(v) == LGLSXP) {
160: 		return RType::LOGICAL;
161: 	} else if (TYPEOF(v) == INTSXP) {
162: 		return RType::INTEGER;
163: 	} else if (TYPEOF(v) == REALSXP) {
164: 		return RType::NUMERIC;
165: 	} else if (TYPEOF(v) == STRSXP) {
166: 		return RType::STRING;
167: 	}
168: 	return RType::UNKNOWN;
169: }
170: 
171: extern "C" {
172: 
173: SEXP duckdb_release_R(SEXP stmtsexp) {
174: 	if (TYPEOF(stmtsexp) != EXTPTRSXP) {
175: 		Rf_error("duckdb_release_R: Need external pointer parameter");
176: 	}
177: 	RStatement *stmtholder = (RStatement *)R_ExternalPtrAddr(stmtsexp);
178: 	if (stmtsexp) {
179: 		R_ClearExternalPtr(stmtsexp);
180: 		delete stmtholder;
181: 	}
182: 	return R_NilValue;
183: }
184: 
185: SEXP duckdb_finalize_statement_R(SEXP stmtsexp) {
186: 	return duckdb_release_R(stmtsexp);
187: }
188: 
189: SEXP duckdb_prepare_R(SEXP connsexp, SEXP querysexp) {
190: 	if (TYPEOF(querysexp) != STRSXP || LENGTH(querysexp) != 1) {
191: 		Rf_error("duckdb_prepare_R: Need single string parameter for query");
192: 	}
193: 	if (TYPEOF(connsexp) != EXTPTRSXP) {
194: 		Rf_error("duckdb_prepare_R: Need external pointer parameter for connections");
195: 	}
196: 
197: 	char *query = (char *)CHAR(STRING_ELT(querysexp, 0));
198: 	if (!query) {
199: 		Rf_error("duckdb_prepare_R: No query");
200: 	}
201: 
202: 	Connection *conn = (Connection *)R_ExternalPtrAddr(connsexp);
203: 	if (!conn) {
204: 		Rf_error("duckdb_prepare_R: Invalid connection");
205: 	}
206: 
207: 	auto stmt = conn->Prepare(query);
208: 	if (!stmt->success) {
209: 		Rf_error("duckdb_prepare_R: Failed to prepare query %s\nError: %s", query, stmt->error.c_str());
210: 	}
211: 
212: 	auto stmtholder = new RStatement();
213: 	stmtholder->stmt = move(stmt);
214: 
215: 	SEXP stmtsexp = PROTECT(R_MakeExternalPtr(stmtholder, R_NilValue, R_NilValue));
216: 	R_RegisterCFinalizer(stmtsexp, (void (*)(SEXP))duckdb_finalize_statement_R);
217: 
218: 	SEXP retlist = PROTECT(NEW_LIST(6));
219: 	if (!retlist) {
220: 		UNPROTECT(2); // retlist, stmtsexp
221: 		Rf_error("duckdb_prepare_R: Memory allocation failed");
222: 	}
223: 	SEXP ret_names = cpp_str_to_strsexp({"str", "ref", "type", "names", "rtypes", "n_param"});
224: 	SET_NAMES(retlist, ret_names);
225: 	UNPROTECT(1); // ret_names
226: 
227: 	SET_VECTOR_ELT(retlist, 0, querysexp);
228: 	SET_VECTOR_ELT(retlist, 1, stmtsexp);
229: 	UNPROTECT(1); // stmtsxp
230: 
231: 	SEXP stmt_type = cpp_str_to_strsexp({StatementTypeToString(stmtholder->stmt->type)});
232: 	SET_VECTOR_ELT(retlist, 2, stmt_type);
233: 	UNPROTECT(1); // stmt_type
234: 
235: 	SEXP col_names = cpp_str_to_strsexp(stmtholder->stmt->names);
236: 	SET_VECTOR_ELT(retlist, 3, col_names);
237: 	UNPROTECT(1); // col_names
238: 
239: 	vector<string> rtypes;
240: 
241: 	for (auto &stype : stmtholder->stmt->types) {
242: 		string rtype = "";
243: 		switch (stype.id) {
244: 		case SQLTypeId::BOOLEAN:
245: 			rtype = "logical";
246: 			break;
247: 		case SQLTypeId::TINYINT:
248: 		case SQLTypeId::SMALLINT:
249: 		case SQLTypeId::INTEGER:
250: 			rtype = "integer";
251: 			break;
252: 		case SQLTypeId::TIMESTAMP:
253: 			rtype = "POSIXct";
254: 			break;
255: 		case SQLTypeId::DATE:
256: 			rtype = "Date";
257: 			break;
258: 		case SQLTypeId::TIME:
259: 			rtype = "difftime";
260: 			break;
261: 		case SQLTypeId::BIGINT:
262: 		case SQLTypeId::FLOAT:
263: 		case SQLTypeId::DOUBLE:
264: 			rtype = "numeric";
265: 			break;
266: 		case SQLTypeId::VARCHAR: {
267: 			rtype = "character";
268: 			break;
269: 		}
270: 		default:
271: 			UNPROTECT(1); // retlist
272: 			Rf_error("duckdb_prepare_R: Unknown column type %s", SQLTypeToString(stype).c_str());
273: 			break;
274: 		}
275: 		rtypes.push_back(rtype);
276: 	}
277: 
278: 	SEXP rtypessexp = cpp_str_to_strsexp(rtypes);
279: 	SET_VECTOR_ELT(retlist, 4, rtypessexp);
280: 	UNPROTECT(1); // rtypessexp
281: 
282: 	SET_VECTOR_ELT(retlist, 5, ScalarInteger(stmtholder->stmt->n_param));
283: 
284: 	UNPROTECT(1); // retlist
285: 	return retlist;
286: }
287: 
288: SEXP duckdb_bind_R(SEXP stmtsexp, SEXP paramsexp) {
289: 	if (TYPEOF(stmtsexp) != EXTPTRSXP) {
290: 		Rf_error("duckdb_bind_R: Need external pointer parameter");
291: 	}
292: 	RStatement *stmtholder = (RStatement *)R_ExternalPtrAddr(stmtsexp);
293: 	if (!stmtholder || !stmtholder->stmt) {
294: 		Rf_error("duckdb_bind_R: Invalid statement");
295: 	}
296: 
297: 	stmtholder->parameters.clear();
298: 	stmtholder->parameters.resize(stmtholder->stmt->n_param);
299: 
300: 	if (stmtholder->stmt->n_param == 0) {
301: 		Rf_error("duckdb_bind_R: dbBind called but query takes no parameters");
302: 		return R_NilValue;
303: 	}
304: 
305: 	if (TYPEOF(paramsexp) != VECSXP || LENGTH(paramsexp) != stmtholder->stmt->n_param) {
306: 		Rf_error("duckdb_bind_R: bind parameters need to be a list of length %i", stmtholder->stmt->n_param);
307: 	}
308: 
309: 	for (idx_t param_idx = 0; param_idx < LENGTH(paramsexp); param_idx++) {
310: 		Value val;
311: 		SEXP valsexp = VECTOR_ELT(paramsexp, param_idx);
312: 		if (LENGTH(valsexp) != 1) {
313: 			Rf_error("duckdb_bind_R: bind parameter values need to have length 1");
314: 		}
315: 		auto rtype = detect_rtype(valsexp);
316: 		switch (rtype) {
317: 		case RType::LOGICAL: {
318: 			auto lgl_val = INTEGER_POINTER(valsexp)[0];
319: 			val = Value::BOOLEAN(lgl_val);
320: 			val.is_null = RBooleanType::IsNull(lgl_val);
321: 			break;
322: 		}
323: 		case RType::INTEGER: {
324: 			auto int_val = INTEGER_POINTER(valsexp)[0];
325: 			val = Value::INTEGER(int_val);
326: 			val.is_null = RIntegerType::IsNull(int_val);
327: 			break;
328: 		}
329: 		case RType::NUMERIC: {
330: 			auto dbl_val = NUMERIC_POINTER(valsexp)[0];
331: 			val = Value::DOUBLE(dbl_val);
332: 			val.is_null = RDoubleType::IsNull(dbl_val);
333: 			break;
334: 		}
335: 		case RType::STRING: {
336: 			auto str_val = STRING_ELT(valsexp, 0);
337: 			val = Value(CHAR(str_val));
338: 			val.is_null = str_val == NA_STRING;
339: 			break;
340: 		}
341: 		case RType::FACTOR: {
342: 			auto int_val = INTEGER_POINTER(valsexp)[0];
343: 			auto levels = GET_LEVELS(valsexp);
344: 			val.type = TypeId::VARCHAR;
345: 			val.is_null = RIntegerType::IsNull(int_val);
346: 			if (!val.is_null) {
347: 				auto str_val = STRING_ELT(levels, int_val - 1);
348: 				val.str_value = string(CHAR(str_val));
349: 			}
350: 			break;
351: 		}
352: 		case RType::TIMESTAMP: {
353: 			auto ts_val = NUMERIC_POINTER(valsexp)[0];
354: 			val = Value::TIMESTAMP(RTimestampType::Convert(ts_val));
355: 			val.is_null = RTimestampType::IsNull(ts_val);
356: 			break;
357: 		}
358: 		case RType::DATE: {
359: 			auto d_val = NUMERIC_POINTER(valsexp)[0];
360: 			val = Value::INTEGER(RDateType::Convert(d_val));
361: 			val.is_null = RDateType::IsNull(d_val);
362: 			break;
363: 		}
364: 		default:
365: 			Rf_error("duckdb_bind_R: Unsupported parameter type");
366: 		}
367: 		stmtholder->parameters[param_idx] = val;
368: 	}
369: 	return R_NilValue;
370: }
371: 
372: SEXP duckdb_execute_R(SEXP stmtsexp) {
373: 	if (TYPEOF(stmtsexp) != EXTPTRSXP) {
374: 		Rf_error("duckdb_execute_R: Need external pointer parameter");
375: 	}
376: 	RStatement *stmtholder = (RStatement *)R_ExternalPtrAddr(stmtsexp);
377: 	if (!stmtholder || !stmtholder->stmt) {
378: 		Rf_error("duckdb_execute_R: Invalid statement");
379: 	}
380: 
381: 	auto generic_result = stmtholder->stmt->Execute(stmtholder->parameters, false);
382: 
383: 	if (!generic_result->success) {
384: 		Rf_error("duckdb_execute_R: Failed to run query\nError: %s", generic_result->error.c_str());
385: 	}
386: 	assert(generic_result->type == QueryResultType::MATERIALIZED_RESULT);
387: 	MaterializedQueryResult *result = (MaterializedQueryResult *)generic_result.get();
388: 
389: 	// step 2: create result data frame and allocate columns
390: 	uint32_t ncols = result->types.size();
391: 	uint64_t nrows = result->collection.count;
392: 
393: 	if (ncols > 0) {
394: 		SEXP retlist = PROTECT(NEW_LIST(ncols));
395: 		if (!retlist) {
396: 			UNPROTECT(1); // retlist
397: 			Rf_error("duckdb_execute_R: Memory allocation failed");
398: 		}
399: 		SET_NAMES(retlist, cpp_str_to_strsexp(result->names));
400: 		UNPROTECT(1); // names
401: 
402: 		for (size_t col_idx = 0; col_idx < ncols; col_idx++) {
403: 			SEXP varvalue = NULL;
404: 			switch (result->sql_types[col_idx].id) {
405: 			case SQLTypeId::BOOLEAN:
406: 				varvalue = PROTECT(NEW_LOGICAL(nrows));
407: 				break;
408: 			case SQLTypeId::TINYINT:
409: 			case SQLTypeId::SMALLINT:
410: 			case SQLTypeId::INTEGER:
411: 				varvalue = PROTECT(NEW_INTEGER(nrows));
412: 				break;
413: 			case SQLTypeId::BIGINT:
414: 			case SQLTypeId::FLOAT:
415: 			case SQLTypeId::DOUBLE:
416: 			case SQLTypeId::DECIMAL:
417: 			case SQLTypeId::TIMESTAMP:
418: 			case SQLTypeId::DATE:
419: 			case SQLTypeId::TIME:
420: 				varvalue = PROTECT(NEW_NUMERIC(nrows));
421: 				break;
422: 			case SQLTypeId::VARCHAR:
423: 				varvalue = PROTECT(NEW_STRING(nrows));
424: 				break;
425: 			default:
426: 				UNPROTECT(1); // retlist
427: 				Rf_error("duckdb_execute_R: Unknown column type %s/%s",
428: 				         SQLTypeToString(result->sql_types[col_idx]).c_str(),
429: 				         TypeIdToString(result->types[col_idx]).c_str());
430: 			}
431: 			if (!varvalue) {
432: 				UNPROTECT(2); // varvalue, retlist
433: 				Rf_error("duckdb_execute_R: Memory allocation failed");
434: 			}
435: 			SET_VECTOR_ELT(retlist, col_idx, varvalue);
436: 			UNPROTECT(1); /* varvalue */
437: 		}
438: 
439: 		// at this point retlist is fully allocated and the only protected SEXP
440: 
441: 		// step 3: set values from chunks
442: 		uint64_t dest_offset = 0;
443: 		while (true) {
444: 			auto chunk = result->Fetch();
445: 			if (chunk->size() == 0) {
446: 				break;
447: 			}
448: 			assert(chunk->column_count() == ncols);
449: 			assert(chunk->column_count() == LENGTH(retlist));
450: 			for (size_t col_idx = 0; col_idx < chunk->column_count(); col_idx++) {
451: 				SEXP dest = VECTOR_ELT(retlist, col_idx);
452: 				switch (result->sql_types[col_idx].id) {
453: 				case SQLTypeId::BOOLEAN:
454: 					vector_to_r<int8_t, uint32_t>(chunk->data[col_idx], chunk->size(), LOGICAL_POINTER(dest),
455: 					                              dest_offset, NA_LOGICAL);
456: 					break;
457: 				case SQLTypeId::TINYINT:
458: 					vector_to_r<int8_t, uint32_t>(chunk->data[col_idx], chunk->size(), INTEGER_POINTER(dest),
459: 					                              dest_offset, NA_INTEGER);
460: 					break;
461: 				case SQLTypeId::SMALLINT:
462: 					vector_to_r<int16_t, uint32_t>(chunk->data[col_idx], chunk->size(), INTEGER_POINTER(dest),
463: 					                               dest_offset, NA_INTEGER);
464: 					break;
465: 				case SQLTypeId::INTEGER:
466: 					vector_to_r<int32_t, uint32_t>(chunk->data[col_idx], chunk->size(), INTEGER_POINTER(dest),
467: 					                               dest_offset, NA_INTEGER);
468: 					break;
469: 				case SQLTypeId::TIMESTAMP: {
470: 					auto &src_vec = chunk->data[col_idx];
471: 					auto src_data = FlatVector::GetData<int64_t>(src_vec);
472: 					auto &nullmask = FlatVector::Nullmask(src_vec);
473: 					double *dest_ptr = ((double *)NUMERIC_POINTER(dest)) + dest_offset;
474: 					for (size_t row_idx = 0; row_idx < chunk->size(); row_idx++) {
475: 						dest_ptr[row_idx] =
476: 						    nullmask[row_idx] ? NA_REAL : (double)Timestamp::GetEpoch(src_data[row_idx]);
477: 					}
478: 
479: 					// some dresssup for R
480: 					SEXP cl = PROTECT(NEW_STRING(2));
481: 					SET_STRING_ELT(cl, 0, PROTECT(mkChar("POSIXct")));
482: 					SET_STRING_ELT(cl, 1, PROTECT(mkChar("POSIXt")));
483: 					SET_CLASS(dest, cl);
484: 					setAttrib(dest, install("tzone"), PROTECT(mkString("UTC")));
485: 					UNPROTECT(4);
486: 					break;
487: 				}
488: 				case SQLTypeId::DATE: {
489: 					auto &src_vec = chunk->data[col_idx];
490: 					auto src_data = FlatVector::GetData<int32_t>(src_vec);
491: 					auto &nullmask = FlatVector::Nullmask(src_vec);
492: 					double *dest_ptr = ((double *)NUMERIC_POINTER(dest)) + dest_offset;
493: 					for (size_t row_idx = 0; row_idx < chunk->size(); row_idx++) {
494: 						dest_ptr[row_idx] = nullmask[row_idx] ? NA_REAL : (double)(src_data[row_idx]) - 719528;
495: 					}
496: 
497: 					// some dresssup for R
498: 					SET_CLASS(dest, PROTECT(mkString("Date")));
499: 					UNPROTECT(1);
500: 					break;
501: 				}
502: 				case SQLTypeId::TIME: {
503: 					auto &src_vec = chunk->data[col_idx];
504: 					auto src_data = FlatVector::GetData<int32_t>(src_vec);
505: 					auto &nullmask = FlatVector::Nullmask(src_vec);
506: 					double *dest_ptr = ((double *)NUMERIC_POINTER(dest)) + dest_offset;
507: 					for (size_t row_idx = 0; row_idx < chunk->size(); row_idx++) {
508: 
509: 						if (nullmask[row_idx]) {
510: 							dest_ptr[row_idx] = NA_REAL;
511: 						} else {
512: 							time_t n = src_data[row_idx];
513: 							int h;
514: 							double frac;
515: 							h = n / 3600000;
516: 							n -= h * 3600000;
517: 							frac = (n / 60000.0) / 60.0;
518: 							dest_ptr[row_idx] = h + frac;
519: 						}
520: 					}
521: 
522: 					// some dresssup for R
523: 					SET_CLASS(dest, PROTECT(mkString("difftime")));
524: 					setAttrib(dest, install("units"), PROTECT(mkString("hours")));
525: 					UNPROTECT(2);
526: 					break;
527: 				}
528: 				case SQLTypeId::BIGINT:
529: 					vector_to_r<int64_t, double>(chunk->data[col_idx], chunk->size(), NUMERIC_POINTER(dest),
530: 					                             dest_offset, NA_REAL);
531: 					break;
532: 				case SQLTypeId::FLOAT:
533: 					vector_to_r<float, double>(chunk->data[col_idx], chunk->size(), NUMERIC_POINTER(dest), dest_offset,
534: 					                           NA_REAL);
535: 					break;
536: 
537: 				case SQLTypeId::DOUBLE:
538: 					vector_to_r<double, double>(chunk->data[col_idx], chunk->size(), NUMERIC_POINTER(dest), dest_offset,
539: 					                            NA_REAL);
540: 					break;
541: 				case SQLTypeId::VARCHAR: {
542: 					auto src_ptr = FlatVector::GetData<string_t>(chunk->data[col_idx]);
543: 					auto &nullmask = FlatVector::Nullmask(chunk->data[col_idx]);
544: 					for (size_t row_idx = 0; row_idx < chunk->size(); row_idx++) {
545: 						if (nullmask[row_idx]) {
546: 							SET_STRING_ELT(dest, dest_offset + row_idx, NA_STRING);
547: 						} else {
548: 							SET_STRING_ELT(dest, dest_offset + row_idx, mkCharCE(src_ptr[row_idx].GetData(), CE_UTF8));
549: 						}
550: 					}
551: 					break;
552: 				}
553: 				default:
554: 					Rf_error("duckdb_execute_R: Unknown column type %s",
555: 					         TypeIdToString(chunk->GetTypes()[col_idx]).c_str());
556: 					break;
557: 				}
558: 			}
559: 			dest_offset += chunk->size();
560: 		}
561: 
562: 		assert(dest_offset == nrows);
563: 		UNPROTECT(1); /* retlist */
564: 		return retlist;
565: 	}
566: 	return ScalarReal(0); // no need for protection because no allocation can happen afterwards
567: }
568: 
569: static SEXP duckdb_finalize_database_R(SEXP dbsexp) {
570: 	if (TYPEOF(dbsexp) != EXTPTRSXP) {
571: 		Rf_error("duckdb_finalize_connection_R: Need external pointer parameter");
572: 	}
573: 	DuckDB *dbaddr = (DuckDB *)R_ExternalPtrAddr(dbsexp);
574: 	if (dbaddr) {
575: 		warning("duckdb_finalize_database_R: Database is garbage-collected, use dbDisconnect(con, shutdown=TRUE) or "
576: 		        "duckdb::duckdb_shutdown(drv) to avoid this.");
577: 		R_ClearExternalPtr(dbsexp);
578: 		delete dbaddr;
579: 	}
580: 	return R_NilValue;
581: }
582: 
583: struct DataFrameScanFunctionData : public TableFunctionData {
584: 	DataFrameScanFunctionData(SEXP df, idx_t row_count, vector<RType> rtypes)
585: 	    : df(df), row_count(row_count), rtypes(rtypes), position(0) {
586: 	}
587: 	SEXP df;
588: 	idx_t row_count;
589: 	vector<RType> rtypes;
590: 	idx_t position;
591: };
592: 
593: struct DataFrameScanFunction : public TableFunction {
594: 	DataFrameScanFunction()
595: 	    : TableFunction("dataframe_scan", {SQLType::VARCHAR}, dataframe_scan_bind, dataframe_scan_function, nullptr){};
596: 
597: 	static unique_ptr<FunctionData> dataframe_scan_bind(ClientContext &context, vector<Value> inputs,
598: 	                                                    vector<SQLType> &return_types, vector<string> &names) {
599: 		// TODO have a better way to pass this pointer
600: 		SEXP df((SEXP)stoul(inputs[0].GetValue<string>(), nullptr, 16));
601: 
602: 		auto df_names = GET_NAMES(df);
603: 		vector<RType> rtypes;
604: 
605: 		for (idx_t col_idx = 0; col_idx < LENGTH(df); col_idx++) {
606: 			names.push_back(string(CHAR(STRING_ELT(df_names, col_idx))));
607: 			SEXP coldata = VECTOR_ELT(df, col_idx);
608: 			rtypes.push_back(detect_rtype(coldata));
609: 			SQLType duckdb_col_type;
610: 			switch (rtypes[col_idx]) {
611: 			case RType::LOGICAL:
612: 				duckdb_col_type = SQLType::BOOLEAN;
613: 				break;
614: 			case RType::INTEGER:
615: 				duckdb_col_type = SQLType::INTEGER;
616: 				break;
617: 			case RType::NUMERIC:
618: 				duckdb_col_type = SQLType::DOUBLE;
619: 				break;
620: 			case RType::FACTOR:
621: 			case RType::STRING:
622: 				duckdb_col_type = SQLType::VARCHAR;
623: 				break;
624: 			case RType::TIMESTAMP:
625: 				duckdb_col_type = SQLType::TIMESTAMP;
626: 				break;
627: 			case RType::DATE:
628: 				duckdb_col_type = SQLType::DATE;
629: 				break;
630: 			default:
631: 				Rf_error("Unsupported column type for scan");
632: 			}
633: 			return_types.push_back(duckdb_col_type);
634: 		}
635: 
636: 		auto row_count = LENGTH(VECTOR_ELT(df, 0));
637: 		return make_unique<DataFrameScanFunctionData>(df, row_count, rtypes);
638: 	}
639: 
640: 	static void dataframe_scan_function(ClientContext &context, vector<Value> &input, DataChunk &output,
641: 	                                    FunctionData *dataptr) {
642: 		auto &data = *((DataFrameScanFunctionData *)dataptr);
643: 
644: 		if (data.position >= data.row_count) {
645: 			return;
646: 		}
647: 		idx_t this_count = std::min((idx_t)STANDARD_VECTOR_SIZE, data.row_count - data.position);
648: 
649: 		output.SetCardinality(this_count);
650: 
651: 		// TODO this is quite similar to append, unify!
652: 		for (idx_t col_idx = 0; col_idx < output.column_count(); col_idx++) {
653: 			auto &v = output.data[col_idx];
654: 			SEXP coldata = VECTOR_ELT(data.df, col_idx);
655: 
656: 			switch (data.rtypes[col_idx]) {
657: 			case RType::LOGICAL: {
658: 				auto data_ptr = INTEGER_POINTER(coldata) + data.position;
659: 				AppendColumnSegment<int, bool, RBooleanType>(data_ptr, v, this_count);
660: 				break;
661: 			}
662: 			case RType::INTEGER: {
663: 				auto data_ptr = INTEGER_POINTER(coldata) + data.position;
664: 				AppendColumnSegment<int, int, RIntegerType>(data_ptr, v, this_count);
665: 				break;
666: 			}
667: 			case RType::NUMERIC: {
668: 				auto data_ptr = NUMERIC_POINTER(coldata) + data.position;
669: 				AppendColumnSegment<double, double, RDoubleType>(data_ptr, v, this_count);
670: 				break;
671: 			}
672: 			case RType::STRING:
673: 				AppendStringSegment(coldata, v, data.position, this_count);
674: 				break;
675: 			case RType::FACTOR:
676: 				AppendFactor(coldata, v, data.position, this_count);
677: 				break;
678: 			case RType::TIMESTAMP: {
679: 				auto data_ptr = NUMERIC_POINTER(coldata) + data.position;
680: 				AppendColumnSegment<double, timestamp_t, RTimestampType>(data_ptr, v, this_count);
681: 				break;
682: 			}
683: 			case RType::DATE: {
684: 				auto data_ptr = NUMERIC_POINTER(coldata) + data.position;
685: 				AppendColumnSegment<double, date_t, RDateType>(data_ptr, v, this_count);
686: 				break;
687: 			}
688: 			default:
689: 				throw;
690: 			}
691: 		}
692: 
693: 		data.position += this_count;
694: 	}
695: };
696: 
697: SEXP duckdb_startup_R(SEXP dbdirsexp, SEXP readonlysexp) {
698: 	if (TYPEOF(dbdirsexp) != STRSXP || LENGTH(dbdirsexp) != 1) {
699: 		Rf_error("duckdb_startup_R: Need string parameter for dbdir");
700: 	}
701: 	char *dbdir = (char *)CHAR(STRING_ELT(dbdirsexp, 0));
702: 
703: 	if (TYPEOF(readonlysexp) != LGLSXP || LENGTH(readonlysexp) != 1) {
704: 		Rf_error("duckdb_startup_R: Need string parameter for read_only");
705: 	}
706: 	bool read_only = (bool)LOGICAL_ELT(readonlysexp, 0);
707: 
708: 	if (strlen(dbdir) == 0 || strcmp(dbdir, ":memory:") == 0) {
709: 		dbdir = NULL;
710: 	}
711: 
712: 	DBConfig config;
713: 	config.access_mode = AccessMode::READ_WRITE;
714: 	if (read_only) {
715: 		config.access_mode = AccessMode::READ_ONLY;
716: 	}
717: 	DuckDB *dbaddr;
718: 	try {
719: 		dbaddr = new DuckDB(dbdir, &config);
720: 	} catch (...) {
721: 		Rf_error("duckdb_startup_R: Failed to open database");
722: 	}
723: 
724: 	DataFrameScanFunction scan_fun;
725: 	CreateTableFunctionInfo info(scan_fun);
726: 	Connection conn(*dbaddr);
727: 	auto &context = *conn.context;
728: 	context.transaction.BeginTransaction();
729: 	context.catalog.CreateTableFunction(context, &info);
730: 	context.transaction.Commit();
731: 
732: 	SEXP dbsexp = PROTECT(R_MakeExternalPtr(dbaddr, R_NilValue, R_NilValue));
733: 	R_RegisterCFinalizer(dbsexp, (void (*)(SEXP))duckdb_finalize_database_R);
734: 	UNPROTECT(1);
735: 	return dbsexp;
736: }
737: 
738: SEXP duckdb_shutdown_R(SEXP dbsexp) {
739: 	if (TYPEOF(dbsexp) != EXTPTRSXP) {
740: 		Rf_error("duckdb_finalize_connection_R: Need external pointer parameter");
741: 	}
742: 	DuckDB *dbaddr = (DuckDB *)R_ExternalPtrAddr(dbsexp);
743: 	if (dbaddr) {
744: 		R_ClearExternalPtr(dbsexp);
745: 		delete dbaddr;
746: 	}
747: 
748: 	return R_NilValue;
749: }
750: 
751: static SEXP duckdb_finalize_connection_R(SEXP connsexp) {
752: 	if (TYPEOF(connsexp) != EXTPTRSXP) {
753: 		Rf_error("duckdb_finalize_connection_R: Need external pointer parameter");
754: 	}
755: 	Connection *connaddr = (Connection *)R_ExternalPtrAddr(connsexp);
756: 	if (connaddr) {
757: 		warning("duckdb_finalize_connection_R: Connection is garbage-collected, use dbDisconnect() to avoid this.");
758: 		R_ClearExternalPtr(connsexp);
759: 		delete connaddr;
760: 	}
761: 	return R_NilValue;
762: }
763: 
764: SEXP duckdb_register_R(SEXP connsexp, SEXP namesexp, SEXP valuesexp) {
765: 
766: 	if (TYPEOF(connsexp) != EXTPTRSXP) {
767: 		Rf_error("duckdb_append_R: Need external pointer parameter for connection");
768: 	}
769: 
770: 	Connection *conn = (Connection *)R_ExternalPtrAddr(connsexp);
771: 	if (!conn) {
772: 		Rf_error("duckdb_append_R: Invalid connection");
773: 	}
774: 
775: 	if (TYPEOF(namesexp) != STRSXP || LENGTH(namesexp) != 1) {
776: 		Rf_error("duckdb_append_R: Need single string parameter for name");
777: 	}
778: 	auto name = string(CHAR(STRING_ELT(namesexp, 0)));
779: 
780: 	if (TYPEOF(valuesexp) != VECSXP || LENGTH(valuesexp) < 1 ||
781: 	    strcmp("data.frame", CHAR(STRING_ELT(GET_CLASS(valuesexp), 0))) != 0) {
782: 		Rf_error("duckdb_append_R: Need at least one-column data frame parameter for value");
783: 	}
784: 
785: 	auto key = install(("_registered_df_" + name).c_str());
786: 	setAttrib(connsexp, key, valuesexp);
787: 
788: 	// TODO put it into a conn attr that contains a named list to keep from gc!
789: 	std::ostringstream address;
790: 	address << (void const *)valuesexp;
791: 	string pointer_str = address.str();
792: 
793: 	// hack alert: put the pointer address into the function call as a string
794: 	auto res = conn->Query("CREATE OR REPLACE TEMPORARY VIEW \"" + name + "\" AS SELECT * FROM dataframe_scan('" +
795: 	                       pointer_str + "')");
796: 	if (!res->success) {
797: 		Rf_error(res->error.c_str());
798: 	}
799: 	return R_NilValue;
800: }
801: 
802: SEXP duckdb_unregister_R(SEXP connsexp, SEXP namesexp) {
803: 
804: 	if (TYPEOF(connsexp) != EXTPTRSXP) {
805: 		Rf_error("duckdb_append_R: Need external pointer parameter for connection");
806: 	}
807: 
808: 	Connection *conn = (Connection *)R_ExternalPtrAddr(connsexp);
809: 	if (!conn) {
810: 		Rf_error("duckdb_append_R: Invalid connection");
811: 	}
812: 
813: 	if (TYPEOF(namesexp) != STRSXP || LENGTH(namesexp) != 1) {
814: 		Rf_error("duckdb_append_R: Need single string parameter for name");
815: 	}
816: 	auto name = string(CHAR(STRING_ELT(namesexp, 0)));
817: 
818: 	auto key = install(("_registered_df_" + name).c_str());
819: 	setAttrib(connsexp, key, R_NilValue);
820: 
821: 	auto res = conn->Query("DROP VIEW IF EXISTS \"" + name + "\"");
822: 	if (!res->success) {
823: 		Rf_error(res->error.c_str());
824: 	}
825: 
826: 	// TODO
827: 	return R_NilValue;
828: }
829: 
830: SEXP duckdb_connect_R(SEXP dbsexp) {
831: 	if (TYPEOF(dbsexp) != EXTPTRSXP) {
832: 		Rf_error("duckdb_connect_R: Need external pointer parameter");
833: 	}
834: 	DuckDB *dbaddr = (DuckDB *)R_ExternalPtrAddr(dbsexp);
835: 	if (!dbaddr) {
836: 		Rf_error("duckdb_connect_R: Invalid database reference");
837: 	}
838: 
839: 	SEXP connsexp = PROTECT(R_MakeExternalPtr(new Connection(*dbaddr), R_NilValue, R_NilValue));
840: 	R_RegisterCFinalizer(connsexp, (void (*)(SEXP))duckdb_finalize_connection_R);
841: 	UNPROTECT(1);
842: 
843: 	return connsexp;
844: }
845: 
846: SEXP duckdb_disconnect_R(SEXP connsexp) {
847: 	if (TYPEOF(connsexp) != EXTPTRSXP) {
848: 		Rf_error("duckdb_disconnect_R: Need external pointer parameter");
849: 	}
850: 	Connection *connaddr = (Connection *)R_ExternalPtrAddr(connsexp);
851: 	if (connaddr) {
852: 		R_ClearExternalPtr(connsexp);
853: 		delete connaddr;
854: 	}
855: 	return R_NilValue;
856: }
857: 
858: SEXP duckdb_ptr_to_str(SEXP extptr) {
859: 	if (TYPEOF(extptr) != EXTPTRSXP) {
860: 		Rf_error("duckdb_ptr_to_str: Need external pointer parameter");
861: 	}
862: 	SEXP ret = PROTECT(NEW_STRING(1));
863: 	SET_STRING_ELT(ret, 0, NA_STRING);
864: 	void *ptr = R_ExternalPtrAddr(extptr);
865: 	if (ptr != NULL) {
866: 		char buf[100];
867: 		snprintf(buf, 100, "%p", ptr);
868: 		SET_STRING_ELT(ret, 0, mkChar(buf));
869: 	}
870: 	UNPROTECT(1);
871: 	return ret;
872: }
873: 
874: // R native routine registration
875: #define CALLDEF(name, n)                                                                                               \
876: 	{ #name, (DL_FUNC)&name, n }
877: static const R_CallMethodDef R_CallDef[] = {CALLDEF(duckdb_startup_R, 2),
878:                                             CALLDEF(duckdb_connect_R, 1),
879:                                             CALLDEF(duckdb_prepare_R, 2),
880:                                             CALLDEF(duckdb_bind_R, 2),
881:                                             CALLDEF(duckdb_execute_R, 1),
882:                                             CALLDEF(duckdb_release_R, 1),
883:                                             CALLDEF(duckdb_register_R, 3),
884:                                             CALLDEF(duckdb_unregister_R, 2),
885:                                             CALLDEF(duckdb_disconnect_R, 1),
886:                                             CALLDEF(duckdb_shutdown_R, 1),
887:                                             CALLDEF(duckdb_ptr_to_str, 1),
888: 
889:                                             {NULL, NULL, 0}};
890: 
891: void R_init_duckdb(DllInfo *dll) {
892: 	R_registerRoutines(dll, NULL, R_CallDef, NULL, NULL);
893: 	R_useDynamicSymbols(dll, FALSE);
894: }
895: }
[end of tools/rpkg/src/duckdbr.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: