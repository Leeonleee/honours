{
  "repo": "duckdb/duckdb",
  "pull_number": 5829,
  "instance_id": "duckdb__duckdb-5829",
  "issue_numbers": [
    "5828"
  ],
  "base_commit": "a27022be675e9ee4c593028c10c7bed39d19e68c",
  "patch": "diff --git a/.github/workflows/Python.yml b/.github/workflows/Python.yml\nindex abe02b315c20..82891f8eefce 100644\n--- a/.github/workflows/Python.yml\n+++ b/.github/workflows/Python.yml\n@@ -51,12 +51,16 @@ jobs:\n       with:\n         key: ${{ github.job }}\n \n-    - name: Build\n+    - name: Build source dist\n       shell: bash\n+      working-directory: tools/pythonpkg\n       run: |\n-        cd tools/pythonpkg\n         python setup.py sdist\n         mkdir duckdb_tarball && tar xvf dist/duckdb-*.tar.gz --strip-components=1 -C duckdb_tarball\n+    - name: Build\n+      shell: bash\n+      working-directory: tools/pythonpkg\n+      run: |\n         export DISTUTILS_C_COMPILER_LAUNCHER=ccache\n         # TODO: Use ccache inside container, see https://github.com/pypa/cibuildwheel/issues/1030\n         cibuildwheel --output-dir wheelhouse --config-file cibw.toml duckdb_tarball\n@@ -344,7 +348,8 @@ jobs:\n \n       - name: Install\n         shell: bash\n-        run: pip install numpy pytest pandas mypy psutil\n+        working-directory: tools/pythonpkg\n+        run: pip install -r requirements-dev.txt\n \n       - name: Setup Ccache\n         uses: hendrikmuhs/ccache-action@main\ndiff --git a/extension/httpfs/include/s3fs.hpp b/extension/httpfs/include/s3fs.hpp\nindex 5534f8a86164..4d1af6dd133e 100644\n--- a/extension/httpfs/include/s3fs.hpp\n+++ b/extension/httpfs/include/s3fs.hpp\n@@ -164,6 +164,7 @@ class S3FileSystem : public HTTPFileSystem {\n \tuint16_t threads_waiting_for_memory = 0;\n \n \tBufferManager &buffer_manager;\n+\tstring GetName() const override;\n \n public:\n \t// HTTP Requests\ndiff --git a/extension/httpfs/s3fs.cpp b/extension/httpfs/s3fs.cpp\nindex 5befeec880db..675ed89723c0 100644\n--- a/extension/httpfs/s3fs.cpp\n+++ b/extension/httpfs/s3fs.cpp\n@@ -921,6 +921,10 @@ vector<string> S3FileSystem::Glob(const string &glob_pattern, FileOpener *opener\n \treturn result;\n }\n \n+string S3FileSystem::GetName() const {\n+\treturn \"S3FileSystem\";\n+}\n+\n string AWSListObjectV2::Request(string &path, HTTPParams &http_params, S3AuthParams &s3_auth_params,\n                                 string &continuation_token, HTTPStats *stats, bool use_delimiter) {\n \tauto parsed_url = S3FileSystem::S3UrlParse(path, s3_auth_params);\ndiff --git a/extension/parquet/parquet_reader.cpp b/extension/parquet/parquet_reader.cpp\nindex f674a61c9fe3..89a55925d9bf 100644\n--- a/extension/parquet/parquet_reader.cpp\n+++ b/extension/parquet/parquet_reader.cpp\n@@ -546,10 +546,10 @@ ParquetReader::ParquetReader(ClientContext &context_p, string file_name_p, const\n \t// If object cached is disabled\n \t// or if this file has cached metadata\n \t// or if the cached version already expired\n-\tauto last_modify_time = fs.GetLastModifiedTime(*file_handle);\n \tif (!ObjectCache::ObjectCacheEnabled(context_p)) {\n \t\tmetadata = LoadMetadata(allocator, *file_handle, *file_opener);\n \t} else {\n+\t\tauto last_modify_time = fs.GetLastModifiedTime(*file_handle);\n \t\tmetadata = ObjectCache::GetObjectCache(context_p).Get<ParquetFileMetadataCache>(file_name);\n \t\tif (!metadata || (last_modify_time + 10 >= metadata->read_time)) {\n \t\t\tmetadata = LoadMetadata(allocator, *file_handle, *file_opener);\ndiff --git a/src/common/file_system.cpp b/src/common/file_system.cpp\nindex f32ff51494d5..d609c9edd6b7 100644\n--- a/src/common/file_system.cpp\n+++ b/src/common/file_system.cpp\n@@ -307,6 +307,14 @@ void FileSystem::RegisterSubSystem(FileCompressionType compression_type, unique_\n \tthrow NotImplementedException(\"%s: Can't register a sub system on a non-virtual file system\", GetName());\n }\n \n+void FileSystem::UnregisterSubSystem(const string &name) {\n+\tthrow NotImplementedException(\"%s: Can't unregister a sub system on a non-virtual file system\", GetName());\n+}\n+\n+vector<string> FileSystem::ListSubSystems() {\n+\tthrow NotImplementedException(\"%s: Can't list sub systems on a non-virtual file system\", GetName());\n+}\n+\n bool FileSystem::CanHandleFile(const string &fpath) {\n \tthrow NotImplementedException(\"%s: CanHandleFile is not implemented!\", GetName());\n }\ndiff --git a/src/include/duckdb/common/file_system.hpp b/src/include/duckdb/common/file_system.hpp\nindex 4106ac360e7e..1348352de000 100644\n--- a/src/include/duckdb/common/file_system.hpp\n+++ b/src/include/duckdb/common/file_system.hpp\n@@ -9,11 +9,11 @@\n #pragma once\n \n #include \"duckdb/common/constants.hpp\"\n+#include \"duckdb/common/enums/file_compression_type.hpp\"\n+#include \"duckdb/common/exception.hpp\"\n #include \"duckdb/common/file_buffer.hpp\"\n-#include \"duckdb/common/vector.hpp\"\n #include \"duckdb/common/unordered_map.hpp\"\n-#include \"duckdb/common/exception.hpp\"\n-#include \"duckdb/common/enums/file_compression_type.hpp\"\n+#include \"duckdb/common/vector.hpp\"\n \n #include <functional>\n \n@@ -187,6 +187,12 @@ class FileSystem {\n \tDUCKDB_API virtual void RegisterSubSystem(unique_ptr<FileSystem> sub_fs);\n \tDUCKDB_API virtual void RegisterSubSystem(FileCompressionType compression_type, unique_ptr<FileSystem> fs);\n \n+\t//! Unregister a sub-filesystem by name\n+\tDUCKDB_API virtual void UnregisterSubSystem(const string &name);\n+\n+\t//! List registered sub-filesystems, including builtin ones\n+\tDUCKDB_API virtual vector<string> ListSubSystems();\n+\n \t//! Whether or not a sub-system can handle a specific file path\n \tDUCKDB_API virtual bool CanHandleFile(const string &fpath);\n \n@@ -207,7 +213,6 @@ class FileSystem {\n \t//! Create a LocalFileSystem.\n \tDUCKDB_API static unique_ptr<FileSystem> CreateLocal();\n \n-protected:\n \t//! Return the name of the filesytem. Used for forming diagnosis messages.\n \tDUCKDB_API virtual std::string GetName() const = 0;\n };\ndiff --git a/src/include/duckdb/common/virtual_file_system.hpp b/src/include/duckdb/common/virtual_file_system.hpp\nindex 7c2f6aafeeeb..b51c1dc595c4 100644\n--- a/src/include/duckdb/common/virtual_file_system.hpp\n+++ b/src/include/duckdb/common/virtual_file_system.hpp\n@@ -95,10 +95,28 @@ class VirtualFileSystem : public FileSystem {\n \t\tsub_systems.push_back(std::move(fs));\n \t}\n \n+\tvoid UnregisterSubSystem(const string &name) override {\n+\t\tfor (auto sub_system = sub_systems.begin(); sub_system != sub_systems.end(); sub_system++) {\n+\t\t\tif (sub_system->get()->GetName() == name) {\n+\t\t\t\tsub_systems.erase(sub_system);\n+\t\t\t\treturn;\n+\t\t\t}\n+\t\t}\n+\t\tthrow InvalidInputException(\"Could not find filesystem with name %s\", name);\n+\t}\n+\n \tvoid RegisterSubSystem(FileCompressionType compression_type, unique_ptr<FileSystem> fs) override {\n \t\tcompressed_fs[compression_type] = std::move(fs);\n \t}\n \n+\tvector<string> ListSubSystems() override {\n+\t\tvector<string> names(sub_systems.size());\n+\t\tfor (idx_t i = 0; i < sub_systems.size(); i++) {\n+\t\t\tnames[i] = sub_systems[i]->GetName();\n+\t\t}\n+\t\treturn names;\n+\t}\n+\n \tstd::string GetName() const override {\n \t\treturn \"VirtualFileSystem\";\n \t}\ndiff --git a/tools/pythonpkg/cibw.toml b/tools/pythonpkg/cibw.toml\nindex 07c10dd11ad3..03bf81ddb856 100644\n--- a/tools/pythonpkg/cibw.toml\n+++ b/tools/pythonpkg/cibw.toml\n@@ -3,8 +3,7 @@\n # Default config runs all tests and requires at least one extension to be tested against\n [tool.cibuildwheel]\n environment = \"PIP_CONSTRAINT='build-constraints.txt'\"\n-before-build = 'pip install --prefer-binary \"pandas>=0.24\" \"pytest>=4.3\"'\n-before-test = 'pip install --prefer-binary \"pandas>=0.24\" pytest-timeout mypy \"psutil>=5.9.0\" && pip install --prefer-binary \"requests>=2.26\" && (pip install --prefer-binary \"pyarrow>=8.0\" || true)'\n+before-test = 'pip install --prefer-binary \"pandas>=0.24\" pytest-timeout mypy \"psutil>=5.9.0\" \"requests>=2.26\" fsspec && (pip install --prefer-binary \"pyarrow>=8.0\" || true)'\n test-requires = 'pytest'\n test-command = 'DUCKDB_PYTHON_TEST_EXTENSION_PATH={project} DUCKDB_PYTHON_TEST_EXTENSION_REQUIRED=1 python -m pytest {project}/tests'\n \ndiff --git a/tools/pythonpkg/duckdb-stubs/__init__.pyi b/tools/pythonpkg/duckdb-stubs/__init__.pyi\nindex b036970564e1..0fa380e24a7d 100644\n--- a/tools/pythonpkg/duckdb-stubs/__init__.pyi\n+++ b/tools/pythonpkg/duckdb-stubs/__init__.pyi\n@@ -10,6 +10,7 @@ from typing import overload\n import pandas\n # stubgen override - unfortunately we need this for version checks\n import sys\n+import fsspec\n import pyarrow.lib\n # stubgen override - This should probably not be exposed\n #_clean_default_connection: Any\n@@ -77,13 +78,16 @@ class DuckDBPyConnection:\n     def from_substrait_json(self, json: str) -> DuckDBPyRelation: ...\n     def get_table_names(self, query: str) -> Set[str]: ...\n     def install_extension(self, *args, **kwargs) -> None: ...\n+    def list_filesystems(self) -> list: ...\n     def load_extension(self, extension: str) -> None: ...\n     def query(self, query: str, alias: str = ...) -> DuckDBPyRelation: ...\n     def register(self, view_name: str, python_object: object) -> DuckDBPyConnection: ...\n+    def register_filesystem(self, filesystem: fsspec.AbstractFileSystem) -> None: ...\n     def rollback(self) -> DuckDBPyConnection: ...\n     def table(self, table_name: str) -> DuckDBPyRelation: ...\n     def table_function(self, name: str, parameters: object = ...) -> DuckDBPyRelation: ...\n     def unregister(self, view_name: str) -> DuckDBPyConnection: ...\n+    def unregister_filesystem(self, name: str) -> None: ...\n     def values(self, values: object) -> DuckDBPyRelation: ...\n     def view(self, view_name: str) -> DuckDBPyRelation: ...\n     def __enter__(self) -> DuckDBPyConnection: ...\n@@ -288,14 +292,17 @@ def get_substrait(query: str, connection: DuckDBPyConnection = ...) -> DuckDBPyR\n def get_substrait_json(query: str, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...\n def get_table_names(query: str, connection: DuckDBPyConnection = ...) -> Set[str]: ...\n def install_extension(*args, connection: DuckDBPyConnection = ..., **kwargs) -> None: ...\n+def list_filesystems(connection: DuckDBPyConnection = ...) -> list: ...\n def load_extension(extension: str, connection: DuckDBPyConnection = ...) -> None: ...\n-def query(query: str, alias: str = ..., connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...\n+def query(query: str, alias: str = 'query_relation', connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...\n def register(view_name: str, python_object: object, connection: DuckDBPyConnection = ...) -> DuckDBPyConnection: ...\n+def register_filesystem(filesystem: fsspec.AbstractFileSystem, connection: DuckDBPyConnection = ...) -> None: ...\n def rollback(connection: DuckDBPyConnection = ...) -> DuckDBPyConnection: ...\n def table(table_name: str, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...\n def table_function(name: str, parameters: object = ..., connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...\n def unregister(view_name: str, connection: DuckDBPyConnection = ...) -> DuckDBPyConnection: ...\n def query_df(df: pandas.DataFrame, virtual_table_name: str, sql_query: str, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...\n+def unregister_filesystem(name: str, connection: DuckDBPyConnection = ...) -> None: ...\n def tokenize(query: str) -> object: ...\n def values(values: object, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...\n def view(view_name: str, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...\ndiff --git a/tools/pythonpkg/duckdb_python.cpp b/tools/pythonpkg/duckdb_python.cpp\nindex 829c4ddbd82d..8d18af18e7c9 100644\n--- a/tools/pythonpkg/duckdb_python.cpp\n+++ b/tools/pythonpkg/duckdb_python.cpp\n@@ -155,7 +155,13 @@ static void InitializeConnectionMethods(py::module_ &m) {\n \t    .def(\"install_extension\", &PyConnectionWrapper::InstallExtension, \"Install an extension by name\",\n \t         py::arg(\"extension\"), py::kw_only(), py::arg(\"force_install\") = false, py::arg(\"connection\") = py::none())\n \t    .def(\"load_extension\", &PyConnectionWrapper::LoadExtension, \"Load an installed extension\", py::arg(\"extension\"),\n-\t         py::arg(\"connection\") = py::none());\n+\t         py::arg(\"connection\") = py::none())\n+\t    .def(\"register_filesystem\", &PyConnectionWrapper::RegisterFilesystem, \"Register a fsspec compliant filesystem\",\n+\t         py::arg(\"filesystem\"), py::arg(\"connection\") = py::none())\n+\t    .def(\"unregister_filesystem\", &PyConnectionWrapper::UnregisterFilesystem, \"Unregister a filesystem\",\n+\t         py::arg(\"name\"), py::arg(\"connection\") = py::none())\n+\t    .def(\"list_filesystems\", &PyConnectionWrapper::ListFilesystems,\n+\t         \"List registered filesystems, including builtin ones\", py::arg(\"connection\") = py::none());\n }\n \n PYBIND11_MODULE(DUCKDB_PYTHON_LIB_NAME, m) {\ndiff --git a/tools/pythonpkg/requirements-dev.txt b/tools/pythonpkg/requirements-dev.txt\nindex cc9484838a24..b15e2c578c68 100644\n--- a/tools/pythonpkg/requirements-dev.txt\n+++ b/tools/pythonpkg/requirements-dev.txt\n@@ -6,4 +6,5 @@ pytest\n pandas\n pyarrow\n mypy\n-psutil>=5.9.0\n\\ No newline at end of file\n+psutil>=5.9.0\n+fsspec\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/connection_wrapper.hpp b/tools/pythonpkg/src/include/duckdb_python/connection_wrapper.hpp\nindex c38ee2c58dc3..b905cb5c4479 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/connection_wrapper.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/connection_wrapper.hpp\n@@ -101,5 +101,9 @@ class PyConnectionWrapper {\n \n \tstatic duckdb::pyarrow::RecordBatchReader FetchRecordBatchReader(const idx_t chunk_size,\n \t                                                                 shared_ptr<DuckDBPyConnection> conn = nullptr);\n+\n+\tstatic void RegisterFilesystem(AbstractFileSystem file_system, shared_ptr<DuckDBPyConnection> conn);\n+\tstatic void UnregisterFilesystem(const py::str &name, shared_ptr<DuckDBPyConnection> conn);\n+\tstatic py::list ListFilesystems(shared_ptr<DuckDBPyConnection> conn);\n };\n } // namespace duckdb\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/pyconnection.hpp b/tools/pythonpkg/src/include/duckdb_python/pyconnection.hpp\nindex a9fec4fe3a04..a115233f4438 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/pyconnection.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/pyconnection.hpp\n@@ -18,6 +18,7 @@\n #include \"duckdb_python/registered_py_object.hpp\"\n #include \"duckdb_python/pandas_type.hpp\"\n #include \"duckdb_python/pyrelation.hpp\"\n+#include \"duckdb_python/pyfilesystem.hpp\"\n \n namespace duckdb {\n \n@@ -142,6 +143,10 @@ struct DuckDBPyConnection : public std::enable_shared_from_this<DuckDBPyConnecti\n \n \tstatic vector<Value> TransformPythonParamList(const py::handle &params);\n \n+\tvoid RegisterFilesystem(AbstractFileSystem filesystem);\n+\tvoid UnregisterFilesystem(const py::str &name);\n+\tpy::list ListFilesystems();\n+\n \t//! Default connection to an in-memory database\n \tstatic shared_ptr<DuckDBPyConnection> default_connection;\n \t//! Caches and provides an interface to get frequently used modules+subtypes\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/pyfilesystem.hpp b/tools/pythonpkg/src/include/duckdb_python/pyfilesystem.hpp\nnew file mode 100644\nindex 000000000000..572804f07505\n--- /dev/null\n+++ b/tools/pythonpkg/src/include/duckdb_python/pyfilesystem.hpp\n@@ -0,0 +1,100 @@\n+#pragma once\n+\n+#include \"duckdb/common/file_system.hpp\"\n+#include \"duckdb/common/string_util.hpp\"\n+#include \"duckdb_python/pybind_wrapper.hpp\"\n+#include \"duckdb_python/python_object_container.hpp\"\n+\n+#include <vector>\n+\n+namespace duckdb {\n+\n+class AbstractFileSystem : public py::object {\n+public:\n+\tusing py::object::object;\n+\n+public:\n+\tstatic bool check_(const py::handle &object) {\n+\t\treturn py::isinstance(object, py::module::import(\"fsspec\").attr(\"AbstractFileSystem\"));\n+\t}\n+};\n+\n+class PythonFileHandle : public FileHandle {\n+public:\n+\tPythonFileHandle(FileSystem &file_system, const string &path, const py::object handle);\n+\n+\tvoid Close() override {\n+\t\tPythonGILWrapper gil;\n+\t\thandle.attr(\"close\")();\n+\t}\n+\n+\tstatic const py::object &GetHandle(const FileHandle &handle) {\n+\t\treturn ((PythonFileHandle &)handle).handle;\n+\t}\n+\n+private:\n+\tpy::object handle;\n+};\n+class PythonFilesystem : public FileSystem {\n+private:\n+\tconst vector<string> protocols;\n+\tconst AbstractFileSystem filesystem;\n+\tstring stripPrefix(string input) {\n+\t\tfor (const auto &protocol : protocols) {\n+\t\t\tauto prefix = protocol + \"://\";\n+\t\t\tif (StringUtil::StartsWith(input, prefix)) {\n+\t\t\t\treturn input.substr(prefix.size());\n+\t\t\t}\n+\t\t}\n+\t\treturn input;\n+\t}\n+\n+public:\n+\texplicit PythonFilesystem(vector<string> protocols, AbstractFileSystem filesystem)\n+\t    : protocols(std::move(protocols)), filesystem(std::move(filesystem)) {\n+\t}\n+\n+protected:\n+\tstring GetName() const override {\n+\t\treturn protocols[0];\n+\t}\n+\n+public:\n+\tunique_ptr<FileHandle> OpenFile(const string &path, uint8_t flags, FileLockType lock,\n+\t                                FileCompressionType compression, FileOpener *opener) override;\n+\tvoid Seek(duckdb::FileHandle &handle, uint64_t location) override;\n+\tFileType GetFileType(FileHandle &handle) override {\n+\t\treturn FileType::FILE_TYPE_REGULAR;\n+\t}\n+\tint64_t Read(FileHandle &handle, void *buffer, int64_t nr_bytes) override;\n+\tvoid Read(duckdb::FileHandle &handle, void *buffer, int64_t nr_bytes, uint64_t location) override;\n+\n+\tvoid Write(FileHandle &handle, void *buffer, int64_t nr_bytes, idx_t location) override;\n+\tint64_t Write(FileHandle &handle, void *buffer, int64_t nr_bytes) override;\n+\n+\tbool FileExists(const string &filename) override;\n+\tvector<string> Glob(const string &path, FileOpener *opener) override;\n+\tbool CanHandleFile(const string &fpath) override;\n+\tbool CanSeek() override {\n+\t\treturn true;\n+\t}\n+\tbool OnDiskFile(FileHandle &handle) override {\n+\t\treturn false;\n+\t}\n+\tint64_t GetFileSize(FileHandle &handle) override;\n+\tvoid RemoveFile(const string &filename) override;\n+\tvoid MoveFile(const string &source, const string &dest) override;\n+\ttime_t GetLastModifiedTime(FileHandle &handle) override;\n+\tvoid FileSync(FileHandle &handle) override;\n+};\n+\n+} // namespace duckdb\n+\n+namespace pybind11 {\n+namespace detail {\n+template <>\n+struct handle_type_name<duckdb::AbstractFileSystem> {\n+\tstatic constexpr auto name = const_name(\"fsspec.AbstractFileSystem\");\n+};\n+} // namespace detail\n+} // namespace pybind11\ndiff --git a/tools/pythonpkg/src/pyconnection.cpp b/tools/pythonpkg/src/pyconnection.cpp\nindex af4ee15aa952..9247d72ced02 100644\n--- a/tools/pythonpkg/src/pyconnection.cpp\n+++ b/tools/pythonpkg/src/pyconnection.cpp\n@@ -23,6 +23,7 @@\n #include \"duckdb_python/python_conversion.hpp\"\n #include \"duckdb/main/prepared_statement.hpp\"\n #include \"duckdb_python/jupyter_progress_bar_display.hpp\"\n+#include \"duckdb_python/pyfilesystem.hpp\"\n #include \"duckdb/main/client_config.hpp\"\n \n #include <random>\n@@ -71,6 +72,12 @@ bool DuckDBPyConnection::IsJupyter() {\n \n static void InitializeConnectionMethods(py::class_<DuckDBPyConnection, shared_ptr<DuckDBPyConnection>> &m) {\n \tm.def(\"cursor\", &DuckDBPyConnection::Cursor, \"Create a duplicate of the current connection\")\n+\t    .def(\"register_filesystem\", &DuckDBPyConnection::RegisterFilesystem, \"Register a fsspec compliant filesystem\",\n+\t         py::arg(\"filesystem\"))\n+\t    .def(\"unregister_filesystem\", &DuckDBPyConnection::UnregisterFilesystem, \"Unregister a filesystem\",\n+\t         py::arg(\"name\"))\n+\t    .def(\"list_filesystems\", &DuckDBPyConnection::ListFilesystems,\n+\t         \"List registered filesystems, including builtin ones\")\n \t    .def(\"duplicate\", &DuckDBPyConnection::Cursor, \"Create a duplicate of the current connection\")\n \t    .def(\"execute\", &DuckDBPyConnection::Execute,\n \t         \"Execute the given SQL query, optionally using prepared statements with parameters set\", py::arg(\"query\"),\n@@ -153,6 +160,47 @@ static void InitializeConnectionMethods(py::class_<DuckDBPyConnection, shared_pt\n \t    .def(\"load_extension\", &DuckDBPyConnection::LoadExtension, \"Load an installed extension\", py::arg(\"extension\"));\n }\n \n+void DuckDBPyConnection::UnregisterFilesystem(const py::str &name) {\n+\tauto &fs = database->GetFileSystem();\n+\n+\tfs.UnregisterSubSystem(name);\n+}\n+\n+void DuckDBPyConnection::RegisterFilesystem(AbstractFileSystem filesystem) {\n+\tPythonGILWrapper gil_wrapper;\n+\n+\tif (!py::isinstance<AbstractFileSystem>(filesystem)) {\n+\t\tthrow InvalidInputException(\"Bad filesystem instance\");\n+\t}\n+\n+\tauto &fs = database->GetFileSystem();\n+\n+\tauto protocol = filesystem.attr(\"protocol\");\n+\tif (protocol.is_none() || py::str(\"abstract\").equal(protocol)) {\n+\t\tthrow InvalidInputException(\"Must provide concrete fsspec implementation\");\n+\t}\n+\n+\tvector<string> protocols;\n+\tif (py::isinstance<py::str>(protocol)) {\n+\t\tprotocols.push_back(py::str(protocol));\n+\t} else {\n+\t\tfor (const auto &sub_protocol : protocol) {\n+\t\t\tprotocols.push_back(py::str(sub_protocol));\n+\t\t}\n+\t}\n+\n+\tfs.RegisterSubSystem(make_unique<PythonFilesystem>(std::move(protocols), std::move(filesystem)));\n+}\n+\n+py::list DuckDBPyConnection::ListFilesystems() {\n+\tauto subsystems = database->GetFileSystem().ListSubSystems();\n+\tpy::list names;\n+\tfor (auto &name : subsystems) {\n+\t\tnames.append(py::str(name));\n+\t}\n+\treturn names;\n+}\n+\n void DuckDBPyConnection::Initialize(py::handle &m) {\n \tauto connection_module =\n \t    py::class_<DuckDBPyConnection, shared_ptr<DuckDBPyConnection>>(m, \"DuckDBPyConnection\", py::module_local());\ndiff --git a/tools/pythonpkg/src/pyduckdb/connection_wrapper.cpp b/tools/pythonpkg/src/pyduckdb/connection_wrapper.cpp\nindex 97fb9e5b8d15..5a68cb22b2fe 100644\n--- a/tools/pythonpkg/src/pyduckdb/connection_wrapper.cpp\n+++ b/tools/pythonpkg/src/pyduckdb/connection_wrapper.cpp\n@@ -277,4 +277,23 @@ duckdb::pyarrow::RecordBatchReader PyConnectionWrapper::FetchRecordBatchReader(c\n \treturn conn->FetchRecordBatchReader(chunk_size);\n }\n \n+void PyConnectionWrapper::RegisterFilesystem(AbstractFileSystem file_system, shared_ptr<DuckDBPyConnection> conn) {\n+\tif (!conn) {\n+\t\tconn = DuckDBPyConnection::DefaultConnection();\n+\t}\n+\treturn conn->RegisterFilesystem(std::move(file_system));\n+}\n+void PyConnectionWrapper::UnregisterFilesystem(const py::str &name, shared_ptr<DuckDBPyConnection> conn) {\n+\tif (!conn) {\n+\t\tconn = DuckDBPyConnection::DefaultConnection();\n+\t}\n+\treturn conn->UnregisterFilesystem(name);\n+}\n+py::list PyConnectionWrapper::ListFilesystems(shared_ptr<DuckDBPyConnection> conn) {\n+\tif (!conn) {\n+\t\tconn = DuckDBPyConnection::DefaultConnection();\n+\t}\n+\treturn conn->ListFilesystems();\n+}\n+\n } // namespace duckdb\ndiff --git a/tools/pythonpkg/src/pyfilesystem.cpp b/tools/pythonpkg/src/pyfilesystem.cpp\nnew file mode 100644\nindex 000000000000..3aebc2e3691d\n--- /dev/null\n+++ b/tools/pythonpkg/src/pyfilesystem.cpp\n@@ -0,0 +1,135 @@\n+#include \"duckdb_python/pyfilesystem.hpp\"\n+\n+#include \"duckdb/common/string_util.hpp\"\n+#include \"duckdb_python/pybind_wrapper.hpp\"\n+#include \"duckdb_python/python_object_container.hpp\"\n+\n+namespace duckdb {\n+\n+PythonFileHandle::PythonFileHandle(FileSystem &file_system, const string &path, const py::object handle)\n+    : FileHandle(file_system, path), handle(handle) {\n+}\n+\n+unique_ptr<FileHandle> PythonFilesystem::OpenFile(const string &path, uint8_t flags, FileLockType lock,\n+                                                  FileCompressionType compression, FileOpener *opener) {\n+\tPythonGILWrapper gil;\n+\n+\tif (compression != FileCompressionType::UNCOMPRESSED) {\n+\t\tthrow IOException(\"Compression not supported\");\n+\t}\n+\n+\t// TODO: lock support?\n+\n+\tstring flags_s;\n+\tif (flags & FileFlags::FILE_FLAGS_READ) {\n+\t\tflags_s = \"rb\";\n+\t} else if (flags & FileFlags::FILE_FLAGS_WRITE) {\n+\t\tflags_s = \"wb\";\n+\t} else if (flags & FileFlags::FILE_FLAGS_APPEND) {\n+\t\tflags_s = \"ab\";\n+\t} else {\n+\t\tthrow InvalidInputException(\"%s: unsupported file flags\", GetName());\n+\t}\n+\n+\tconst auto &handle = filesystem.attr(\"open\")(py::str(stripPrefix(path)), py::str(flags_s));\n+\treturn make_unique<PythonFileHandle>(*this, path, handle);\n+}\n+\n+int64_t PythonFilesystem::Write(FileHandle &handle, void *buffer, int64_t nr_bytes) {\n+\tPythonGILWrapper gil;\n+\n+\tconst auto &write = PythonFileHandle::GetHandle(handle).attr(\"write\");\n+\n+\tauto data = py::bytes(std::string((const char *)buffer, nr_bytes));\n+\n+\treturn py::int_(write(data));\n+}\n+void PythonFilesystem::Write(FileHandle &handle, void *buffer, int64_t nr_bytes, idx_t location) {\n+\tSeek(handle, location);\n+\n+\tWrite(handle, buffer, nr_bytes);\n+}\n+\n+int64_t PythonFilesystem::Read(FileHandle &handle, void *buffer, int64_t nr_bytes) {\n+\tPythonGILWrapper gil;\n+\n+\tconst auto &read = PythonFileHandle::GetHandle(handle).attr(\"read\");\n+\n+\tstring data = py::bytes(read(nr_bytes));\n+\n+\tmemcpy(buffer, data.c_str(), data.size());\n+\n+\treturn data.size();\n+}\n+\n+void PythonFilesystem::Read(duckdb::FileHandle &handle, void *buffer, int64_t nr_bytes, uint64_t location) {\n+\tSeek(handle, location);\n+\n+\tRead(handle, buffer, nr_bytes);\n+}\n+bool PythonFilesystem::FileExists(const string &filename) {\n+\tPythonGILWrapper gil;\n+\n+\treturn py::bool_(filesystem.attr(\"exists\")(filename));\n+}\n+vector<string> PythonFilesystem::Glob(const string &path, FileOpener *opener) {\n+\tPythonGILWrapper gil;\n+\n+\tif (!path.size()) {\n+\t\treturn {path};\n+\t}\n+\tauto returner = py::list(filesystem.attr(\"glob\")(py::str(stripPrefix(path))));\n+\n+\tstd::vector<string> results;\n+\tauto unstrip_protocol = filesystem.attr(\"unstrip_protocol\");\n+\tfor (auto item : returner) {\n+\t\tresults.push_back(py::str(unstrip_protocol(py::str(item))));\n+\t}\n+\treturn results;\n+}\n+int64_t PythonFilesystem::GetFileSize(FileHandle &handle) {\n+\t// TODO: this value should be cached on the PythonFileHandle\n+\tPythonGILWrapper gil;\n+\n+\treturn py::int_(filesystem.attr(\"size\")(stripPrefix(handle.path)));\n+}\n+void PythonFilesystem::Seek(duckdb::FileHandle &handle, uint64_t location) {\n+\tPythonGILWrapper gil;\n+\n+\tauto seek = PythonFileHandle::GetHandle(handle).attr(\"seek\");\n+\tseek(location);\n+}\n+bool PythonFilesystem::CanHandleFile(const string &fpath) {\n+\tfor (const auto &protocol : protocols) {\n+\t\tif (StringUtil::StartsWith(fpath, protocol + \"://\")) {\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\treturn false;\n+}\n+void PythonFilesystem::MoveFile(const string &source, const string &dest) {\n+\tPythonGILWrapper gil;\n+\n+\tauto move = filesystem.attr(\"mv\");\n+\tmove(py::str(source), py::str(dest));\n+}\n+void PythonFilesystem::RemoveFile(const string &filename) {\n+\tPythonGILWrapper gil;\n+\n+\tauto remove = filesystem.attr(\"rm\");\n+\tremove(py::str(filename));\n+}\n+time_t PythonFilesystem::GetLastModifiedTime(FileHandle &handle) {\n+\t// TODO: this value should be cached on the PythonFileHandle\n+\tPythonGILWrapper gil;\n+\n+\tauto last_mod = filesystem.attr(\"modified\")(handle.path);\n+\n+\treturn py::int_(last_mod.attr(\"timestamp\")());\n+}\n+void PythonFilesystem::FileSync(FileHandle &handle) {\n+\tPythonGILWrapper gil;\n+\n+\tPythonFileHandle::GetHandle(handle).attr(\"flush\")();\n+}\n+} // namespace duckdb\n",
  "test_patch": "diff --git a/tools/pythonpkg/tests/conftest.py b/tools/pythonpkg/tests/conftest.py\nindex bd9b87eb580b..13efb59e20a5 100644\n--- a/tools/pythonpkg/tests/conftest.py\n+++ b/tools/pythonpkg/tests/conftest.py\n@@ -46,7 +46,7 @@ def _require(extension_name, db_name=''):\n                 conn = duckdb.connect(db_name, config={'allow_unsigned_extensions' : 'true'})\n                 conn.execute(f\"LOAD '{path}'\")\n                 return conn\n-        return None\n+        pytest.skip(f'could not load {extension_name}')\n \n     return _require\n \ndiff --git a/tools/pythonpkg/tests/fast/test_filesystem.py b/tools/pythonpkg/tests/fast/test_filesystem.py\nnew file mode 100644\nindex 000000000000..d02e3a4e4ed0\n--- /dev/null\n+++ b/tools/pythonpkg/tests/fast/test_filesystem.py\n@@ -0,0 +1,106 @@\n+import logging\n+import sys\n+from pathlib import Path\n+from shutil import copyfileobj\n+from typing import Callable\n+\n+from duckdb import DuckDBPyConnection, InvalidInputException\n+from pytest import raises, importorskip, fixture, MonkeyPatch\n+\n+importorskip('fsspec', '2022.11.0')\n+from fsspec import filesystem, AbstractFileSystem\n+from fsspec.implementations.memory import MemoryFileSystem\n+\n+FILENAME = 'integers.csv'\n+\n+logging.basicConfig(level=logging.DEBUG)\n+\n+\n+@fixture()\n+def memory():\n+    fs = filesystem('memory', skip_instance_cache=True)\n+    # copy csv into memory filesystem\n+    add_file(fs)\n+    return fs\n+\n+\n+def add_file(fs, filename=FILENAME):\n+    with (Path(__file__).parent / 'data' / filename).open('rb') as source, fs.open(filename, 'wb') as dest:\n+        copyfileobj(source, dest)\n+\n+\n+class TestPythonFilesystem:\n+    def test_unregister_non_existent_filesystem(self, duckdb_cursor: DuckDBPyConnection):\n+        with raises(InvalidInputException):\n+            duckdb_cursor.unregister_filesystem('fake')\n+\n+    def test_memory_filesystem(self, duckdb_cursor: DuckDBPyConnection, memory: AbstractFileSystem):\n+        duckdb_cursor.register_filesystem(memory)\n+\n+        assert memory.protocol == 'memory'\n+\n+        duckdb_cursor.execute(f\"select * from 'memory://{FILENAME}'\")\n+\n+        assert duckdb_cursor.fetchall() == [(1, 10, 0), (2, 50, 30)]\n+\n+        duckdb_cursor.unregister_filesystem('memory')\n+\n+    def test_reject_abstract_filesystem(self, duckdb_cursor: DuckDBPyConnection):\n+        with raises(InvalidInputException):\n+            duckdb_cursor.register_filesystem(AbstractFileSystem())\n+\n+    def test_unregister_builtin(self, require: Callable[[str], DuckDBPyConnection]):\n+        duckdb_cursor = require('httpfs')\n+        assert 'S3FileSystem' in duckdb_cursor.list_filesystems()\n+        duckdb_cursor.unregister_filesystem('S3FileSystem')\n+\n+    def test_multiple_protocol_filesystems(self, duckdb_cursor: DuckDBPyConnection):\n+        memory = MemoryFileSystem(skip_instance_cache=True)\n+        add_file(memory)\n+        memory.protocol = ('file', 'local')\n+        duckdb_cursor.register_filesystem(memory)\n+\n+        for protocol in memory.protocol:\n+            duckdb_cursor.execute(f\"select * from '{protocol}://{FILENAME}'\")\n+\n+            assert duckdb_cursor.fetchall() == [(1, 10, 0), (2, 50, 30)]\n+\n+    def test_write(self, duckdb_cursor: DuckDBPyConnection, memory: AbstractFileSystem):\n+        duckdb_cursor.register_filesystem(memory)\n+\n+        duckdb_cursor.execute(\"copy (select 1) to 'memory://01.csv' (FORMAT CSV)\")\n+\n+        assert memory.open('01.csv').read() == b'1\\n'\n+\n+    def test_null_bytes(self, duckdb_cursor: DuckDBPyConnection, memory: AbstractFileSystem):\n+        with memory.open('test.csv', 'wb') as fh:\n+            fh.write(b'hello\\n\\0world\\0')\n+        duckdb_cursor.register_filesystem(memory)\n+\n+        duckdb_cursor.execute('select * from \"memory://test.csv\"')\n+\n+        assert duckdb_cursor.fetchall() == [('hello',), ('\\0world\\0',)]\n+\n+    def test_read_parquet(self, duckdb_cursor: DuckDBPyConnection, memory: AbstractFileSystem):\n+        filename = 'binary_string.parquet'\n+        add_file(memory, filename)\n+\n+        duckdb_cursor.register_filesystem(memory)\n+\n+        duckdb_cursor.execute(f\"select * from read_parquet('memory://{filename}')\")\n+\n+        assert duckdb_cursor.fetchall() == [(b'foo',), (b'bar',), (b'baz',)]\n+\n+    def test_write_parquet(self, duckdb_cursor: DuckDBPyConnection, memory: AbstractFileSystem):\n+        duckdb_cursor.register_filesystem(memory)\n+        filename = 'output.parquet'\n+\n+        duckdb_cursor.execute(f'''COPY (SELECT 1) TO 'memory://{filename}' (FORMAT PARQUET);''')\n+\n+        assert memory.open(filename).read().startswith(b'PAR1')\n+\n+    def test_when_fsspec_not_installed(self, duckdb_cursor: DuckDBPyConnection, monkeypatch: MonkeyPatch):\n+        monkeypatch.setitem(sys.modules, 'fsspec', None)\n+\n+        with raises(ModuleNotFoundError):\n+            duckdb_cursor.register_filesystem(None)\ndiff --git a/tools/pythonpkg/tests/stubs/mypy.ini b/tools/pythonpkg/tests/stubs/mypy.ini\nindex e11f0054572a..1c1a17a095a9 100644\n--- a/tools/pythonpkg/tests/stubs/mypy.ini\n+++ b/tools/pythonpkg/tests/stubs/mypy.ini\n@@ -1,7 +1,9 @@\n [mypy]\n+[mypy-fsspec]\n+ignore_missing_imports = True\n [mypy-pandas]\n ignore_missing_imports = True\n [mypy-pyarrow]\n ignore_missing_imports = True\n [mypy-pyarrow.lib]\n-ignore_missing_imports = True\n\\ No newline at end of file\n+ignore_missing_imports = True\ndiff --git a/tools/pythonpkg/tests/stubs/test_stubs.py b/tools/pythonpkg/tests/stubs/test_stubs.py\nindex 85d5fbb8616c..c2d26417a069 100644\n--- a/tools/pythonpkg/tests/stubs/test_stubs.py\n+++ b/tools/pythonpkg/tests/stubs/test_stubs.py\n@@ -11,7 +11,7 @@ def test_generated_stubs():\n \tstubtest.test_stubs(stubtest.parse_options(['duckdb', '--mypy-config-file', MYPY_INI_PATH]))\n \n \tbroken_stubs = [\n-\t\terror\n+\t\terror.get_description()\n \t\tfor error in stubtest.test_module('duckdb')\n \t\tif not any(skip in error.get_description() for skip in skip_stubs_errors)\n \t]\n",
  "problem_statement": "Add fsspec support to DuckDB\n[`fsspec`](https://filesystem-spec.readthedocs.io/en/latest/?badge=latest) was initially created to abstract over various filesystem implementations for dask and pyarrow, and it makes reading from various object stores really easy, and very pluggable\n\nI'm built a test of it integrating it with DuckDB, and although there is a perf cost due to the bindings being largely written in Python, I believe the convenience is worth it. Below is an example of what using it looks like:\n\n```py\nimport logging\nimport duckdb\nfrom adlfs.spec import AzureBlobFileSystem\n\nlogging.basicConfig(level=logging.DEBUG)\n\nconnection = duckdb.connect()\n\nconnection.register_filesystem(AzureBlobFileSystem(account_name='azureopendatastorage'))\n\nquery = connection.execute(\n    '''\n    select *\n    from read_parquet('abfs://nyctlc/green/puYear=2019/puMonth=*/*.parquet', hive_partitioning=true)\n    limit 10\n    '''\n)\n\nprint(query.fetchall())\n\nconnection.unregister_filesystem('abfs')\n```\n\n\nSome bindings are missing the `modified`, which we want to use for the object cache. I've raised some PR's to fix that, so don't need to introduce that knowledge into our code\n- https://github.com/fsspec/adlfs/pull/381\n- https://github.com/fsspec/gcsfs/pull/516\n\nAdditionally, we can probably add a fsspec \"extra\" (a python packaging concept) to make installing this stuff easier\n\n\n",
  "hints_text": "",
  "created_at": "2023-01-05T16:23:41Z"
}