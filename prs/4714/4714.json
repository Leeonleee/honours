{
  "repo": "duckdb/duckdb",
  "pull_number": 4714,
  "instance_id": "duckdb__duckdb-4714",
  "issue_numbers": [
    "4442",
    "4442"
  ],
  "base_commit": "a5b74ff1cdd60c1a64c6a5ba41e57a2dc20336c0",
  "patch": "diff --git a/extension/parquet/column_reader.cpp b/extension/parquet/column_reader.cpp\nindex a029885bc9b0..7c55cb4b14c0 100644\n--- a/extension/parquet/column_reader.cpp\n+++ b/extension/parquet/column_reader.cpp\n@@ -1140,15 +1140,29 @@ unique_ptr<ColumnReader> ColumnReader::CreateReader(ParquetReader &reader, const\n \t\t\treturn make_unique<CallbackColumnReader<Int96, timestamp_t, ImpalaTimestampToTimestamp>>(\n \t\t\t    reader, type_p, schema_p, file_idx_p, max_define, max_repeat);\n \t\tcase Type::INT64:\n-\t\t\tswitch (schema_p.converted_type) {\n-\t\t\tcase ConvertedType::TIMESTAMP_MICROS:\n-\t\t\t\treturn make_unique<CallbackColumnReader<int64_t, timestamp_t, ParquetTimestampMicrosToTimestamp>>(\n-\t\t\t\t    reader, type_p, schema_p, file_idx_p, max_define, max_repeat);\n-\t\t\tcase ConvertedType::TIMESTAMP_MILLIS:\n-\t\t\t\treturn make_unique<CallbackColumnReader<int64_t, timestamp_t, ParquetTimestampMsToTimestamp>>(\n-\t\t\t\t    reader, type_p, schema_p, file_idx_p, max_define, max_repeat);\n-\t\t\tdefault:\n-\t\t\t\tbreak;\n+\t\t\tif (schema_p.__isset.logicalType && schema_p.logicalType.__isset.TIMESTAMP) {\n+\t\t\t\tif (schema_p.logicalType.TIMESTAMP.unit.__isset.MILLIS) {\n+\t\t\t\t\treturn make_unique<CallbackColumnReader<int64_t, timestamp_t, ParquetTimestampMsToTimestamp>>(\n+\t\t\t\t\t    reader, type_p, schema_p, file_idx_p, max_define, max_repeat);\n+\t\t\t\t} else if (schema_p.logicalType.TIMESTAMP.unit.__isset.MICROS) {\n+\t\t\t\t\treturn make_unique<CallbackColumnReader<int64_t, timestamp_t, ParquetTimestampMicrosToTimestamp>>(\n+\t\t\t\t\t    reader, type_p, schema_p, file_idx_p, max_define, max_repeat);\n+\t\t\t\t} else if (schema_p.logicalType.TIMESTAMP.unit.__isset.NANOS) {\n+\t\t\t\t\treturn make_unique<CallbackColumnReader<int64_t, timestamp_t, ParquetTimestampNsToTimestamp>>(\n+\t\t\t\t\t    reader, type_p, schema_p, file_idx_p, max_define, max_repeat);\n+\t\t\t\t}\n+\n+\t\t\t} else if (schema_p.__isset.converted_type) {\n+\t\t\t\tswitch (schema_p.converted_type) {\n+\t\t\t\tcase ConvertedType::TIMESTAMP_MICROS:\n+\t\t\t\t\treturn make_unique<CallbackColumnReader<int64_t, timestamp_t, ParquetTimestampMicrosToTimestamp>>(\n+\t\t\t\t\t    reader, type_p, schema_p, file_idx_p, max_define, max_repeat);\n+\t\t\t\tcase ConvertedType::TIMESTAMP_MILLIS:\n+\t\t\t\t\treturn make_unique<CallbackColumnReader<int64_t, timestamp_t, ParquetTimestampMsToTimestamp>>(\n+\t\t\t\t\t    reader, type_p, schema_p, file_idx_p, max_define, max_repeat);\n+\t\t\t\tdefault:\n+\t\t\t\t\tbreak;\n+\t\t\t\t}\n \t\t\t}\n \t\tdefault:\n \t\t\tbreak;\ndiff --git a/extension/parquet/include/parquet_timestamp.hpp b/extension/parquet/include/parquet_timestamp.hpp\nindex 9291399375f1..a44bd79ff121 100644\n--- a/extension/parquet/include/parquet_timestamp.hpp\n+++ b/extension/parquet/include/parquet_timestamp.hpp\n@@ -21,6 +21,7 @@ timestamp_t ImpalaTimestampToTimestamp(const Int96 &raw_ts);\n Int96 TimestampToImpalaTimestamp(timestamp_t &ts);\n timestamp_t ParquetTimestampMicrosToTimestamp(const int64_t &raw_ts);\n timestamp_t ParquetTimestampMsToTimestamp(const int64_t &raw_ts);\n+timestamp_t ParquetTimestampNsToTimestamp(const int64_t &raw_ts);\n date_t ParquetIntToDate(const int32_t &raw_date);\n dtime_t ParquetIntToTime(const int64_t &raw_time);\n \ndiff --git a/extension/parquet/parquet_reader.cpp b/extension/parquet/parquet_reader.cpp\nindex 34ca3a463925..123d100c3239 100644\n--- a/extension/parquet/parquet_reader.cpp\n+++ b/extension/parquet/parquet_reader.cpp\n@@ -95,8 +95,14 @@ LogicalType ParquetReader::DeriveLogicalType(const SchemaElement &s_ele, bool bi\n \tif (s_ele.type == Type::FIXED_LEN_BYTE_ARRAY && !s_ele.__isset.type_length) {\n \t\tthrow IOException(\"FIXED_LEN_BYTE_ARRAY requires length to be set\");\n \t}\n-\tif (s_ele.type == Type::FIXED_LEN_BYTE_ARRAY && s_ele.__isset.logicalType && s_ele.logicalType.__isset.UUID) {\n-\t\treturn LogicalType::UUID;\n+\tif (s_ele.__isset.logicalType) {\n+\t\tif (s_ele.logicalType.__isset.UUID) {\n+\t\t\tif (s_ele.type == Type::FIXED_LEN_BYTE_ARRAY) {\n+\t\t\t\treturn LogicalType::UUID;\n+\t\t\t}\n+\t\t} else if (s_ele.logicalType.__isset.TIMESTAMP) {\n+\t\t\treturn LogicalType::TIMESTAMP;\n+\t\t}\n \t}\n \tif (s_ele.__isset.converted_type) {\n \t\tswitch (s_ele.converted_type) {\ndiff --git a/extension/parquet/parquet_timestamp.cpp b/extension/parquet/parquet_timestamp.cpp\nindex ddb3ee1b489c..ae65a8c25454 100644\n--- a/extension/parquet/parquet_timestamp.cpp\n+++ b/extension/parquet/parquet_timestamp.cpp\n@@ -44,6 +44,9 @@ timestamp_t ParquetTimestampMicrosToTimestamp(const int64_t &raw_ts) {\n timestamp_t ParquetTimestampMsToTimestamp(const int64_t &raw_ts) {\n \treturn Timestamp::FromEpochMs(raw_ts);\n }\n+timestamp_t ParquetTimestampNsToTimestamp(const int64_t &raw_ts) {\n+\treturn Timestamp::FromEpochNanoSeconds(raw_ts);\n+}\n \n date_t ParquetIntToDate(const int32_t &raw_date) {\n \treturn date_t(raw_date);\n",
  "test_patch": "diff --git a/data/parquet-testing/bug4442.parquet b/data/parquet-testing/bug4442.parquet\nnew file mode 100644\nindex 000000000000..1fde26ba8da6\nBinary files /dev/null and b/data/parquet-testing/bug4442.parquet differ\ndiff --git a/test/sql/copy/parquet/parquet_4442.test b/test/sql/copy/parquet/parquet_4442.test\nnew file mode 100644\nindex 000000000000..a1175713b254\n--- /dev/null\n+++ b/test/sql/copy/parquet/parquet_4442.test\n@@ -0,0 +1,10 @@\n+# name: test/sql/copy/parquet/parquet_4442.test\n+# description: Issue #4442: Parquet reader converts timestamp to i64 *sometimes*\n+# group: [parquet]\n+\n+require parquet\n+\n+query IIIIIIIIIIIIIIIII\n+SELECT * FROM 'data/parquet-testing/bug4442.parquet'\n+----\n+12\t5184\t1\t22\t2011-10-06 22:21:49.58\toutbound\t323020033\t{}\t2100\t33\t0\t7\t10\t0\t1317427200000\t1317939709580\t11\n\\ No newline at end of file\n",
  "problem_statement": "Parquet reader converts timestamp to i64 *sometimes*\n### What happens?\n\nI have a parquet file that is correctly read by both `pandas` and `polars`.\r\nThe `call_date` of that file is of type `datetime[ns,UTC]`.\r\n\r\nReading it with DuckDB converts the `call_date` field to an `int64` for no apparent reason.\r\n\n\n### To Reproduce\n\n`SELECT * FROM 'b.parquet'`\r\n\r\n\r\n[b.parquet.zip](https://github.com/duckdb/duckdb/files/9378104/b.parquet.zip)\r\n\r\n\r\nReading with `pandas` and `polars` in Jupyter notebook (or any other Python env).\r\n\r\n```python\r\nimport pandas as pd\r\nimport polars as pl\r\nimport duckdb\r\n\r\ndf_pandas = pd.read_parquet(\"b.parquet\")\r\ndisplay(df_pandas)\r\ndf_polars = pl.read_parquet(\"b.parquet\")\r\ndisplay(df_polars)\r\n\r\ncon = duckdb.connect()\r\ndf = con.execute(\"SELECT * FROM 'b.parquet'\").df()\r\ndf\r\n```\r\n\r\nAlso, reading the schema yields `INT64` for that column type.\r\n\r\n```python\r\nimport duckdb\r\n\r\ncon = duckdb.connect()\r\ndf = con.execute(\"SELECT * FROM parquet_metadata('b.parquet')\").df()\r\ndf[df['path_in_schema'] == 'call_date'][[\"path_in_schema\", \"type\"]]\r\n```\r\n\r\n```\r\npath_in_schema\ttype\r\n4\tcall_date\tINT64\r\n```\r\n\r\n\r\nConverting the initial `SELECT` to `arrow` also gives `int64`\r\n\r\n```python\r\nimport duckdb\r\n\r\ncon = duckdb.connect()\r\ndf = con.execute(\"SELECT * FROM 'b.parquet'\").arrow()\r\ndf\r\n```\r\n\r\n```\r\npyarrow.Table\r\nlinkback_length: int64\r\nagent_call_sid: int64\r\nclient_sid: int64\r\nagent_sid: int64\r\ncall_date: int64\r\ncall_type: string\r\ncall_sid: int64\r\nskills: string\r\nresult: int64\r\ncall_wait_duration: int64\r\ntransfer_duration: int64\r\nwrap_up_duration: int64\r\ntalk_duration: int64\r\nhold_duration: int64\r\ncall_month_epoch: int64\r\ncall_date_epoch: int64\r\n_version: int32\r\n```\n\n### OS:\n\nLinux\n\n### DuckDB Version:\n\n0.4.0\n\n### DuckDB Client:\n\nPython\n\n### Full Name:\n\nAlexandru Pirvulescu\n\n### Affiliation:\n\nTCN\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\nParquet reader converts timestamp to i64 *sometimes*\n### What happens?\n\nI have a parquet file that is correctly read by both `pandas` and `polars`.\r\nThe `call_date` of that file is of type `datetime[ns,UTC]`.\r\n\r\nReading it with DuckDB converts the `call_date` field to an `int64` for no apparent reason.\r\n\n\n### To Reproduce\n\n`SELECT * FROM 'b.parquet'`\r\n\r\n\r\n[b.parquet.zip](https://github.com/duckdb/duckdb/files/9378104/b.parquet.zip)\r\n\r\n\r\nReading with `pandas` and `polars` in Jupyter notebook (or any other Python env).\r\n\r\n```python\r\nimport pandas as pd\r\nimport polars as pl\r\nimport duckdb\r\n\r\ndf_pandas = pd.read_parquet(\"b.parquet\")\r\ndisplay(df_pandas)\r\ndf_polars = pl.read_parquet(\"b.parquet\")\r\ndisplay(df_polars)\r\n\r\ncon = duckdb.connect()\r\ndf = con.execute(\"SELECT * FROM 'b.parquet'\").df()\r\ndf\r\n```\r\n\r\nAlso, reading the schema yields `INT64` for that column type.\r\n\r\n```python\r\nimport duckdb\r\n\r\ncon = duckdb.connect()\r\ndf = con.execute(\"SELECT * FROM parquet_metadata('b.parquet')\").df()\r\ndf[df['path_in_schema'] == 'call_date'][[\"path_in_schema\", \"type\"]]\r\n```\r\n\r\n```\r\npath_in_schema\ttype\r\n4\tcall_date\tINT64\r\n```\r\n\r\n\r\nConverting the initial `SELECT` to `arrow` also gives `int64`\r\n\r\n```python\r\nimport duckdb\r\n\r\ncon = duckdb.connect()\r\ndf = con.execute(\"SELECT * FROM 'b.parquet'\").arrow()\r\ndf\r\n```\r\n\r\n```\r\npyarrow.Table\r\nlinkback_length: int64\r\nagent_call_sid: int64\r\nclient_sid: int64\r\nagent_sid: int64\r\ncall_date: int64\r\ncall_type: string\r\ncall_sid: int64\r\nskills: string\r\nresult: int64\r\ncall_wait_duration: int64\r\ntransfer_duration: int64\r\nwrap_up_duration: int64\r\ntalk_duration: int64\r\nhold_duration: int64\r\ncall_month_epoch: int64\r\ncall_date_epoch: int64\r\n_version: int32\r\n```\n\n### OS:\n\nLinux\n\n### DuckDB Version:\n\n0.4.0\n\n### DuckDB Client:\n\nPython\n\n### Full Name:\n\nAlexandru Pirvulescu\n\n### Affiliation:\n\nTCN\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\n",
  "hints_text": "\n",
  "created_at": "2022-09-14T12:46:10Z"
}