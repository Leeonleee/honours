{
  "repo": "duckdb/duckdb",
  "pull_number": 3952,
  "instance_id": "duckdb__duckdb-3952",
  "issue_numbers": [
    "3438"
  ],
  "base_commit": "995622ad3be05d322f2da90e6eda42288bb876db",
  "patch": "diff --git a/src/common/local_file_system.cpp b/src/common/local_file_system.cpp\nindex 99969f32086a..878f4acad069 100644\n--- a/src/common/local_file_system.cpp\n+++ b/src/common/local_file_system.cpp\n@@ -12,12 +12,12 @@\n \n #include <cstdint>\n #include <cstdio>\n+#include <sys/stat.h>\n \n #ifndef _WIN32\n #include <dirent.h>\n #include <fcntl.h>\n #include <string.h>\n-#include <sys/stat.h>\n #include <sys/types.h>\n #include <unistd.h>\n #else\n@@ -27,7 +27,6 @@\n #include <string>\n \n #ifdef __MINGW32__\n-#include <sys/stat.h>\n // need to manually define this for mingw\n extern \"C\" WINBASEAPI BOOL WINAPI GetPhysicallyInstalledSystemMemory(PULONGLONG);\n #endif\n@@ -52,33 +51,6 @@ static void AssertValidFileFlags(uint8_t flags) {\n #endif\n }\n \n-#ifdef __MINGW32__\n-bool LocalFileSystem::FileExists(const string &filename) {\n-\tauto unicode_path = WindowsUtil::UTF8ToUnicode(filename.c_str());\n-\tconst wchar_t *wpath = unicode_path.c_str();\n-\tif (_waccess(wpath, 0) == 0) {\n-\t\tstruct _stat64i32 status;\n-\t\t_wstat64i32(wpath, &status);\n-\t\tif (status.st_size > 0) {\n-\t\t\treturn true;\n-\t\t}\n-\t}\n-\treturn false;\n-}\n-bool LocalFileSystem::IsPipe(const string &filename) {\n-\tauto unicode_path = WindowsUtil::UTF8ToUnicode(filename.c_str());\n-\tconst wchar_t *wpath = unicode_path.c_str();\n-\tif (_waccess(wpath, 0) == 0) {\n-\t\tstruct _stat64i32 status;\n-\t\t_wstat64i32(wpath, &status);\n-\t\tif (status.st_size == 0) {\n-\t\t\treturn true;\n-\t\t}\n-\t}\n-\treturn false;\n-}\n-\n-#else\n #ifndef _WIN32\n bool LocalFileSystem::FileExists(const string &filename) {\n \tif (!filename.empty()) {\n@@ -113,8 +85,8 @@ bool LocalFileSystem::FileExists(const string &filename) {\n \tauto unicode_path = WindowsUtil::UTF8ToUnicode(filename.c_str());\n \tconst wchar_t *wpath = unicode_path.c_str();\n \tif (_waccess(wpath, 0) == 0) {\n-\t\tstruct _stat64i32 status;\n-\t\t_wstat(wpath, &status);\n+\t\tstruct _stati64 status;\n+\t\t_wstati64(wpath, &status);\n \t\tif (status.st_mode & S_IFREG) {\n \t\t\treturn true;\n \t\t}\n@@ -125,8 +97,8 @@ bool LocalFileSystem::IsPipe(const string &filename) {\n \tauto unicode_path = WindowsUtil::UTF8ToUnicode(filename.c_str());\n \tconst wchar_t *wpath = unicode_path.c_str();\n \tif (_waccess(wpath, 0) == 0) {\n-\t\tstruct _stat64i32 status;\n-\t\t_wstat(wpath, &status);\n+\t\tstruct _stati64 status;\n+\t\t_wstati64(wpath, &status);\n \t\tif (status.st_mode & _S_IFCHR) {\n \t\t\treturn true;\n \t\t}\n@@ -134,7 +106,6 @@ bool LocalFileSystem::IsPipe(const string &filename) {\n \treturn false;\n }\n #endif\n-#endif\n \n #ifndef _WIN32\n // somehow sometimes this is missing\n",
  "test_patch": "diff --git a/test/sql/copy/csv/overwrite/test_overwrite_pipe_windows.test b/test/sql/copy/csv/overwrite/test_overwrite_pipe_windows.test\nindex ff9bb209440b..a061e330b51f 100644\n--- a/test/sql/copy/csv/overwrite/test_overwrite_pipe_windows.test\n+++ b/test/sql/copy/csv/overwrite/test_overwrite_pipe_windows.test\n@@ -4,6 +4,8 @@\n \n require windows\n \n+require notmingw\n+\n # Write to pipe - should pass since .tmp is not added when writing to a pipe\n statement ok\n-copy (select 42) to 'con:'\n\\ No newline at end of file\n+copy (select 42) to 'con:'\ndiff --git a/test/sql/storage/test_large_parquet_storage.test_slow b/test/sql/storage/test_large_parquet_storage.test_slow\nnew file mode 100644\nindex 000000000000..92864b2857cf\n--- /dev/null\n+++ b/test/sql/storage/test_large_parquet_storage.test_slow\n@@ -0,0 +1,15 @@\n+# name: test/sql/storage/test_large_parquet_storage.test_slow\n+# description: Test storage of large parquet files\n+# group: [storage]\n+\n+require parquet\n+\n+require 64bit\n+\n+statement ok\n+COPY (SELECT ((i::UBIGINT*129371982737)%2478526729)::BIGINT a,  ((i::UBIGINT*12937198273679)%2478527)::BIGINT::VARCHAR b FROM range(150000000) t(i)) TO '__TEST_DIR__/big.parquet' (FORMAT PARQUET, COMPRESSION UNCOMPRESSED);\n+\n+query I\n+SELECT COUNT(*) FROM '__TEST_DIR__/big.parquet'\n+----\n+150000000\n",
  "problem_statement": "Question, Importing data from Parquet does not work ? \nI am importing the following parquet files, https://drive.google.com/drive/folders/1mZC3NuPBZC4mjP3_kH18c9fLrv8ME7RU\r\n\r\nthe size in Parquet is around 2.5 GB\r\nDuckdb DB size is 8.2 GB\r\n\r\nI am using this python script\r\n\r\n```\r\nimport duckdb \r\ncon = duckdb.connect(database='db_import')\r\n\r\n\r\ndf =con.execute('''\r\n\r\n\r\nCREATE TABLE partsupp AS SELECT * FROM 'C:/Users/mimoune.djouallah/Desktop/TPC-H-SF10/Parquet/partsupp.parquet';\r\nCREATE TABLE part AS SELECT * FROM 'C:/Users/mimoune.djouallah/Desktop/TPC-H-SF10/Parquet/part.parquet';\r\nCREATE TABLE supplier AS SELECT * FROM 'C:/Users/mimoune.djouallah/Desktop/TPC-H-SF10/Parquet/supplier.parquet';\r\nCREATE TABLE nation AS SELECT * FROM 'C:/Users/mimoune.djouallah/Desktop/TPC-H-SF10/Parquet/nation.parquet';\r\nCREATE TABLE region AS SELECT * FROM 'C:/Users/mimoune.djouallah/Desktop/TPC-H-SF10/Parquet/region.parquet';\r\nCREATE TABLE lineitem AS SELECT * FROM 'C:/Users/mimoune.djouallah/Desktop/TPC-H-SF10/Parquet/lineitem.parquet';\r\nCREATE TABLE orders AS SELECT * FROM 'C:/Users/mimoune.djouallah/Desktop/TPC-H-SF10/Parquet/orders.parquet';\r\nCREATE TABLE customer AS SELECT * FROM 'C:/Users/mimoune.djouallah/Desktop/TPC-H-SF10/Parquet/customer.parquet';\r\n\r\n''')\r\n```\r\n\r\nwhen I run\r\nPRAGMA show_tables;\r\n\r\nit show nothing, how I check why the import is not working ?\n",
  "hints_text": "Hello!\r\nIt is somewhat expected that DuckDB is less compressed than Parquet at the moment. We aspire to get there over time! The reason for the difference is that DuckDB needs to support more granular access to the data as well as individual updates and deletes. We need to be able to write a small piece of data to the DB rather than rewrite the whole file like parquet does.\r\n\r\nCheck this out to see the details:\r\n```sql\r\nSelect * from pragma_storage_info('mytable')\r\n``` \nhmm, something is not ok, when I run show tables, I got an empty dataframe ? , running Select * from pragma_storage_info('part'), give me error ; the table part does not exist, I am using the dev edition on windows 10 \nI find the issue I was using copy table from parquet which did not generate an error, but obviously is not working properly \r\nnow I am using insert into table select * from parquet and everything works\nSo the copy statement wasn't working? This syntax should be equivalent:\r\n\r\n```sql\r\nCOPY tbl FROM 'input.parquet' (FORMAT PARQUET)\r\n```\r\n\r\nhttps://duckdb.org/docs/guides/import/parquet_import\nyes I missed the (FORMAT PARQUET); part \nfor some reason, the issue with the parquet file lineitem, it does corrupt the database storage, it works fine when I query it directly though\nWould you be able to post the exact code giving the error, and the parquet file causing the issue? That will help us set up a test so it doesn't happen again!\nhere is the parquet https://drive.google.com/file/d/18gv0Yd_a-Zc7CSolol8qeYVAAzSthnSN/view?usp=sharing\r\n\r\nthere is no error, it did import, but when I try to query it from the database, it say there is no table\nMind posting your import code as well, even though it had no error? That will help!\nsure\r\n```\r\nimport duckdb \r\n\r\ncon = duckdb.connect(database='db_import')\r\ncon.execute('''\r\n\r\ncreate table  LINEITEM as select * FROM read_parquet('C:/Users/mimoune.djouallah/Desktop/TPC-H-SF10/Parquet/lineitem.parquet');\r\n\r\n\r\n''')\r\n```\nany update on this ?\nI can't reproduce this issue, this seems to work fine for me:\r\n\r\n```py\r\n>>> import duckdb\r\n>>> con = duckdb.connect(database='db_import')\r\n>>> con.execute('create table  LINEITEM as select * FROM lineitem.parquet')\r\n>>> exit()\r\n\r\n\r\n>>> import duckdb\r\n>>> con = duckdb.connect(database='db_import')\r\n>>> con.execute('select count(*) from lineitem').df()\r\n   count_star()\r\n0      59986052\r\n```\nI am using windows, is there a way to check if duckdb storage file is not corrupted, all different parquet works fine except the big ones ?\nI've only ever used DuckDB on Windows, so there is other Windows usage in production if that is some comfort!\r\n\r\nI don't believe we have any corruption tests. Is this a new error that you are seeing or the same issue as before?\nI have the same issue as  @djouallah.\r\nI've created a testcase (see below), which probably is redudant, but for the sake of future reference, this is what I did. \r\nAfter running the code below a 3Gb duckdb is created, but when queried, for example with DBeaver, it does not show the 'example'-table in the database, and 'PRAGMA SHOW_TABLES;' is empty.\r\n\r\n\r\n## create dummy parquet-file (51Mb)\r\nCreate a dummy parquet-file that can be shared. \r\n\r\n```python\r\nimport pandas as pd\r\nfpath = 'C:\\exampledata\\example.parquet'\r\n\r\ndf = pd.read_csv('https://www.stats.govt.nz/assets/Uploads/International-trade/International-trade-March-2022-quarter/Download-data/overseas-trade-indexes-March-2022-quarter-provisional-csv.csv', low_memory=False)\r\nfor i in range(8):\r\n    df = pd.concat([df,df])\r\n    \r\ndf.to_parquet(fpath, index=False)\r\n```\r\n\r\n# import dummydata to duckdb\r\n\r\n```python\r\nimport duckdb\r\nfpath = 'C:\\exampledata\\example.parquet'\r\nduckdb_path = 'C:\\exampledata\\example.duckdb'\r\ndb_name = 'test_db2'\r\n\r\nduckdb_con = duckdb.connect(duckdb_path, read_only=False)\r\n\r\n\r\nq_drop_table = f\"DROP TABLE IF EXISTS {db_name};\"\r\nduckdb_con.execute(q_drop_table)\r\n\r\ncreate = f\"\"\"CREATE TABLE {db_name}(Series_reference     VARCHAR,\r\n                                    Period              FLOAT,\r\n                                    Data_value          FLOAT,\r\n                                    STATUS               VARCHAR,\r\n                                    UNITS                VARCHAR,\r\n                                    MAGNTUDE             BIGINT,\r\n                                    Subject              VARCHAR,\r\n                                    \"Group\"              VARCHAR,\r\n                                    Series_title_1       VARCHAR,\r\n                                    Series_title_2       VARCHAR,\r\n                                    Series_title_3       VARCHAR,\r\n                                    Series_title_4       VARCHAR,\r\n                                    Series_title_5       VARCHAR)\"\"\"\r\n        \r\nduckdb_con.execute(create)\r\n\r\n\r\ncopy = f\"COPY {db_name} FROM '{fpath}' (FORMAT PARQUET);\"\r\n\r\nfor i in range(8):\r\n    print('run-number: ', i)\r\n    duckdb_con.execute(copy)\r\n```\nHi, it seens this issue remains as of duckdb version `0.4.0`. I will put some notes about what I have found so far:\r\n- It is related to the parquet file size: a file (either compressed or uncompressed) slightly above 2Gb shows the error `IO Error: No files found that match the pattern \"<file-path>\"`, but a file slightly below this threshold does not show the error. Here is a dummy generated test file: [duckdb_io_error_gzip.parquet](https://drive.google.com/file/d/1xuJu0ridROGUswLwEQE8zK-YC1M80eLp/view?usp=sharing).\r\n- It is a regression bug that was introduced after `0.3.2` release, because this release does not show this error but release `0.3.3-0.3.4` do.\r\n- It does not seems a memory issue, because it affects the schema and metadata queries too (see below) and I have tested in environments with more than 500Gb RAM.\r\n\r\n#### What happens?\r\nQuerying Parquet files above 2Gb shows the error `IO Error: No files found that match the pattern \"<file-path>\"` in the Windows enviroment.\r\n\r\n#### To Reproduce\r\n1) Generate dummy test file. Here is one example: [duckdb_io_error_gzip.parquet](https://drive.google.com/file/d/1xuJu0ridROGUswLwEQE8zK-YC1M80eLp/view?usp=sharing)\r\n2) Try one of those queries:\r\n- `SELECT * FROM parquet_schema('M:\\Temp\\duckdb_io_error_gzip.parquet')`\r\n- `SELECT * FROM parquet_metadata('M:\\Temp\\duckdb_io_error_gzip.parquet')`\r\n- `SELECT * FROM parquet_scan('M:\\Temp\\duckdb_io_error_gzip.parquet') LIMIT 100`\r\n- `CREATE VIEW duckdb_io_error AS SELECT * FROM parquet_scan('M:\\Temp\\duckdb_io_error_gzip.parquet')`\r\n- ...\r\n\r\n#### Environment:\r\n - OS: Windows 10 64bit\r\n - DuckDB Version: 0.4.0\r\n - DuckDB Client: Python, R, JDBC and CLI\r\n\r\n#### Identity Disclosure:\r\n - Full Name: Fabio Monteiro Vaz\r\n - Affiliation: Ipea\r\n\r\n#### Before Submitting\r\n\r\n- [v] **Have you tried this on the latest `master` branch?**\r\n* **Python**: `pip install duckdb --upgrade --pre`\r\n* **R**: `install.packages(\"https://github.com/duckdb/duckdb/releases/download/v0.4.0/duckdb_r_src.tar.gz\", type = \"source\", repos = NULL)`\r\n* **Other Platforms**: You can find binaries [here](https://github.com/duckdb/duckdb/releases/tag/master-builds) or compile from source.\r\n\r\n- [v] **Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?**\r\n\nThanks for the investigations, I will have a look at this",
  "created_at": "2022-06-24T13:55:12Z"
}