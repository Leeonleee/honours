{
  "repo": "duckdb/duckdb",
  "pull_number": 9127,
  "instance_id": "duckdb__duckdb-9127",
  "issue_numbers": [
    "9110"
  ],
  "base_commit": "b77f8def85add4e4cc385da56e7ad960a59c11e5",
  "patch": "diff --git a/tools/pythonpkg/src/numpy/array_wrapper.cpp b/tools/pythonpkg/src/numpy/array_wrapper.cpp\nindex f0f011b88237..4aedf295e063 100644\n--- a/tools/pythonpkg/src/numpy/array_wrapper.cpp\n+++ b/tools/pythonpkg/src/numpy/array_wrapper.cpp\n@@ -216,7 +216,7 @@ struct StringConvert {\n \tstatic NUMPY_T NullValue(bool &set_mask) {\n \t\tif (PANDAS) {\n \t\t\tset_mask = false;\n-\t\t\treturn Py_None;\n+\t\t\tPy_RETURN_NONE;\n \t\t}\n \t\tset_mask = true;\n \t\treturn nullptr;\n",
  "test_patch": "diff --git a/tools/pythonpkg/tests/fast/pandas/test_pandas_df_none.py b/tools/pythonpkg/tests/fast/pandas/test_pandas_df_none.py\nnew file mode 100644\nindex 000000000000..50e1553c47f7\n--- /dev/null\n+++ b/tools/pythonpkg/tests/fast/pandas/test_pandas_df_none.py\n@@ -0,0 +1,12 @@\n+import pandas as pd\n+import pytest\n+import duckdb\n+import sys\n+import gc\n+\n+\n+class TestPandasDFNone(object):\n+    # This used to decrease the ref count of None\n+    def test_none_deref(self):\n+        con = duckdb.connect()\n+        df = con.sql(\"select NULL::VARCHAR as a from range(1000000)\").df()\n",
  "problem_statement": "fetchdf in DuckDB 0.9.0 is deallocating None\n### What happens?\r\n\r\nAfter upgrading to 0.9.0 from 0.8.1, and executing a long batch of analytic queries, I'm running into random SIGABORTS.\r\n\r\nThis is from the reference to None being decremented in C API to the point where it gets deleted. \r\n\r\nAfter reverting to 0.8.1, I no longer have this issue. \r\n\r\n### To Reproduce\r\n\r\n\r\n```shell\r\n$ python -m ...\r\n 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                       | 54/68 [01:03<00:14,  1.00s/it]\r\n\r\nFatal Python error: none_dealloc: deallocating None\r\nPython runtime state: initialized\r\n\r\n...\r\n\r\nfish: Job 1, 'python -m \u2026' terminated by signal SIGABRT (Abort)\r\n```\r\n\r\n\r\n\r\n### OS:\r\n\r\nLinux x86 \r\n\r\n### DuckDB Version:\r\n\r\n0.9.0\r\n\r\n### DuckDB Client:\r\n\r\npython\r\n\r\n### Full Name:\r\n\r\nJoshua Shaffer\r\n\r\n### Affiliation:\r\n\r\nSelf\r\n\r\n### Have you tried this on the latest `main` branch?\r\n\r\nI have tested with a release build (and could not test with a main build)\r\n\r\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\r\n\r\n- [X] Yes, I have\n",
  "hints_text": "Thanks for raising the error, I would love an actual reproduction though\r\nI have never run into this before\nMy code triggers it reliably. But you only find out it happened later when some unrelated code tries to use None later. It's an action-at-a-distance sort of bug. \nHmm I appreciate the extra info, can you give me a list of some duckdb python methods you interact with in your script?\r\nThat might help narrow down the search area\r\n\r\nAnd give me an indication of external types you use in combination with duckdb, such as pandas dataframes, arrow arrays, polars dataframes\nSame for me for a script that is mostly doing Select queries from a .parquet file into a dataframe. \r\nPanda version is 2.0.3. The following error occurs at the very end of the script:\r\n`Fatal Python error: none_dealloc: deallocating None: bug likely caused by a refcount error in a C extension`\r\nI had to revert to 0.8.1\r\n\r\n\n> Same for me for a script that is mostly doing Select queries from a .parquet file into a dataframe. \n> Panda version is 2.0.3. The following error occurs at the very end of the script:\n> `Fatal Python error: none_dealloc: deallocating None: bug likely caused by a refcount error in a C extension`\n> I had to revert to 0.8.1\n> \n> \n\nAre you able to provide a script that reproduces the issue?\nI was able to create a simple example that has this behavior. \r\n\r\n```python\r\nimport duckdb\r\nimport sys\r\n\r\nwith duckdb.connect('bad.db') as con:\r\n    i = 0\r\n    while True:\r\n        # con.begin()\r\n        p = con.execute('select * from ok').fetchdf()\r\n        if i % 1000000:\r\n            print(f'{sys.getrefcount(None)=}')\r\n        # con.commit()\r\n\r\n        i += 1\r\n```\r\n\r\n```shell\r\n$ python bad.py\r\nFatal Python error: none_dealloc: deallocating None\r\nPython runtime state: initialized\r\n\r\nCurrent thread 0x00007f1eab50f000 (most recent call first):\r\n  File \"/tmp/bad.py\", line 8 in <module>\r\n\r\nExtension modules: numpy.core._multiarray_umath, numpy.core._multiarray_tests, numpy.linalg._umath_linalg, numpy.fft._pocketfft_internal, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pandas._libs.ops, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.indexing, pandas._libs.index, pandas._libs.internals, pandas._libs.join, pandas._libs.writers, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing (total: 52)\r\nfish: Job 1, 'python bad.py' terminated by signal SIGABRT (Abort)\r\n```\r\n\r\n```shell\r\n~/Repos/duckdb/duckdb-0.9.0 bad.db\r\nv0.9.0 0d84ccf478\r\nEnter \".help\" for usage hints.\r\nD .schema\r\nCREATE TABLE ok(a INTEGER NOT NULL, b MAP(VARCHAR, DOUBLE) NOT NULL, c MAP(VARCHAR, DOUBLE), d BOOLEAN NOT NULL DEFAULT(CAST('t' AS BOOLEAN)), e VARCHAR, f VARCHAR, g DOUBLE, h STRUCT(i DOUBLE, j DOUBLE, k DOUBLE, l DOUBLE, m DOUBLE, n DOUBLE, o DOUBLE, p DOUBLE, q DOUBLE, r DOUBLE, s DOUBLE, t DOUBLE, u DOUBLE, v DOUBLE, w DOUBLE, x DOUBLE, u DOUBLE, z DOUBLE, z1 DOUBLE, z2 DOUBLE, z3 DOUBLE));\r\nD select count(*) from ok;\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 count_star() \u2502\r\n\u2502    int64     \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502        91516 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\nD \r\n```\nAfter removing .fetchdf(), it no longer does this. \nIt happens on the very first iteration if I modify it as,\r\n\r\n```python\r\nimport duckdb\r\nimport sys\r\n\r\nwith duckdb.connect('bad.db') as con:\r\n    i = 0\r\n    while True:\r\n        p = con.execute('select * from ok').fetchdf()\r\n        print(f'{i=} {sys.getrefcount(None)=}')\r\n        i += 1\r\n```\r\n\r\n```sh\r\ni=0 sys.getrefcount(None)=22042\r\nFatal Python error: none_dealloc: deallocating None\r\nPython runtime state: initialized\r\n\r\nCurrent thread 0x00007f70312da000 (most recent call first):\r\n  File \"/tmp/bad.py\", line 7 in <module>\r\n\r\nExtension modules: numpy.core._multiarray_umath, numpy.core._multiarray_tests, numpy.linalg._umath_linalg, numpy.fft._pocketfft_internal, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pandas._libs.ops, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.indexing, pandas._libs.index, pandas._libs.internals, pandas._libs.join, pandas._libs.writers, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing (total: 52)\r\nfish: Job 1, 'python bad.py' terminated by signal SIGABRT (Abort)\r\n```\nHi @joshuashaffer - are you able to give a bit more info? Which Python version you're using, maybe the `bad.db` file? I'm unable to reproduce so far\n```shell\r\n$ uname -a\r\nLinux redacted 6.4.6-76060406-generic #202307241739~1692717645~22.04~5597803 SMP PREEMPT_DYNAMIC Tue A x86_64 x86_64 x86_64 GNU/Linux\r\n$ lsb_release -a\r\nDistributor ID:\tPop\r\nDescription:\tPop!_OS 22.04 LTS\r\nRelease:\t22.04\r\nCodename:\tjammy\r\n$ which python\r\n/tmp/duck-venv/bin/python\r\n$ python --version\r\nPython 3.10.12\r\n$ pip freeze \r\nblack==22.1.0\r\nblue==0.9.1\r\nclick==8.1.7\r\nduckdb==0.9.0\r\nflake8==4.0.1\r\nmccabe==0.6.1\r\nmypy-extensions==1.0.0\r\nnumpy==1.26.0\r\npandas==2.1.1\r\npathspec==0.11.2\r\nplatformdirs==3.10.0\r\npycodestyle==2.8.0\r\npyflakes==2.4.0\r\npython-dateutil==2.8.2\r\npytz==2023.3.post1\r\nsix==1.16.0\r\ntomli==2.0.1\r\ntzdata==2023.3\r\n```\r\n\r\nThe database needs to be medium size (larger than a chunk?). Doing this with a database with just a few rows will not trigger this.\nAre you able to reproduce with the following?\r\n\r\n```py\r\nimport duckdb\r\nimport sys\r\n\r\nwith duckdb.connect('bad.db') as con:\r\n    con.execute('''\r\n            CREATE OR REPLACE TABLE ok(a INTEGER NOT NULL, b MAP(VARCHAR, DOUBLE) NOT NULL, c MAP(VARCHAR, DOUBLE), d BOOLEAN NOT NULL DEFAULT(CAST('t' AS BOOLEAN)), e VARCHAR, f VARCHAR, g DOUBLE, h STRUCT(i DOUBLE, j DOUBLE, k DOUBLE, l DOUBLE, m DOUBLE, n DOUBLE, o DOUBLE, p DOUBLE, q DOUBLE, r DOUBLE, s DOUBLE, t DOUBLE, u DOUBLE, v DOUBLE, w DOUBLE, x DOUBLE, ui DOUBLE, z DOUBLE, z1 DOUBLE, z2 DOUBLE, z3 DOUBLE));\r\n            ''')\r\n    con.execute('''INSERT INTO ok FROM (SELECT range, MAP {}, MAP {}, true, '', range, NULL, NULL FROM range(91000))''');\r\n\r\nwith duckdb.connect('bad.db') as con:\r\n    i = 0\r\n    while True:\r\n        p = con.execute('select * from ok').fetchdf()\r\n        print(f'{i=} {sys.getrefcount(None)=}')\r\n        i += 1\r\n```\nFor reference\r\n\r\n<details><summary>Details</summary>\r\n<p>\r\n\r\n```\r\n$ uname -a\r\nLinux ****** 5.15.0-84-generic #93-Ubuntu SMP Tue Sep 5 17:16:10 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux\r\n$ lsb_release -a\r\nNo LSB modules are available.\r\nDistributor ID: Ubuntu\r\nDescription:    Ubuntu 22.04.3 LTS\r\nRelease:        22.04\r\nCodename:       jammy\r\n$ python3 --version\r\nPython 3.10.12\r\n```\r\n\r\n</p>\r\n</details> \nSort of. The reference count for None is going down but slowly..\r\n\r\n```shell\r\ni=0 sys.getrefcount(None)=21960\r\ni=10 sys.getrefcount(None)=21957\r\ni=20 sys.getrefcount(None)=21957\r\ni=30 sys.getrefcount(None)=21955\r\ni=40 sys.getrefcount(None)=21955\r\ni=50 sys.getrefcount(None)=21952\r\ni=60 sys.getrefcount(None)=21948\r\n\r\n```\nIt stays the same for a random number of iterations, then it decrements by one.  \nAre you able to write a self contained script that repro's?\r\n\r\nAlso, we do have a discord if that's easier to communicate on this: https://discord.duckdb.org/\nThanks, I managed to reproduce the issue with:\r\n```py\r\nimport duckdb\r\nimport sys\r\n\r\nPATH = 'tmp/bad.db'\r\n\r\nimport os\r\nif not os.path.exists(PATH):\r\n\tcon = duckdb.connect(PATH)\r\n\tall_types = [\r\n\t\t\"varchar\"\r\n\t]\r\n\tprojection = ', '.join([f'\"{x}\"' for x in all_types])\r\n\r\n\tcon.execute(f\"create table tbl as select {projection} from test_all_types()\")\r\n\tcon.close()\r\n\r\nwith duckdb.connect(PATH) as con:\r\n    i = 0\r\n    while True:\r\n        p = con.execute('select * from tbl').fetchdf()\r\n        print(f'{i=} {sys.getrefcount(None)=}')\r\n        i += 1\r\n```\r\n\r\nLikely has to do with https://github.com/duckdb/duckdb/pull/8745",
  "created_at": "2023-09-27T10:38:36Z"
}