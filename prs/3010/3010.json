{
  "repo": "duckdb/duckdb",
  "pull_number": 3010,
  "instance_id": "duckdb__duckdb-3010",
  "issue_numbers": [
    "2734"
  ],
  "base_commit": "d7a24678d7686d7cbeaeda1f67567b63ccd7564c",
  "patch": "diff --git a/tools/rpkg/src/statement.cpp b/tools/rpkg/src/statement.cpp\nindex aa245507ca1b..4dc0cc478903 100644\n--- a/tools/rpkg/src/statement.cpp\n+++ b/tools/rpkg/src/statement.cpp\n@@ -94,7 +94,11 @@ SEXP RApi::Prepare(SEXP connsexp, SEXP querysexp) {\n \t\tcase LogicalTypeId::INTEGER:\n \t\t\trtype = \"integer\";\n \t\t\tbreak;\n+\t\tcase LogicalTypeId::TIMESTAMP_SEC:\n+\t\tcase LogicalTypeId::TIMESTAMP_MS:\n \t\tcase LogicalTypeId::TIMESTAMP:\n+\t\tcase LogicalTypeId::TIMESTAMP_TZ:\n+\t\tcase LogicalTypeId::TIMESTAMP_NS:\n \t\t\trtype = \"POSIXct\";\n \t\t\tbreak;\n \t\tcase LogicalTypeId::DATE:\n@@ -215,7 +219,11 @@ static SEXP allocate(const LogicalType &type, RProtector &r_varvalue, idx_t nrow\n \tcase LogicalTypeId::FLOAT:\n \tcase LogicalTypeId::DOUBLE:\n \tcase LogicalTypeId::DECIMAL:\n+\tcase LogicalTypeId::TIMESTAMP_SEC:\n+\tcase LogicalTypeId::TIMESTAMP_MS:\n \tcase LogicalTypeId::TIMESTAMP:\n+\tcase LogicalTypeId::TIMESTAMP_TZ:\n+\tcase LogicalTypeId::TIMESTAMP_NS:\n \tcase LogicalTypeId::DATE:\n \tcase LogicalTypeId::TIME:\n \t\tvarvalue = r_varvalue.Protect(NEW_NUMERIC(nrows));\n@@ -249,6 +257,52 @@ static SEXP allocate(const LogicalType &type, RProtector &r_varvalue, idx_t nrow\n \treturn varvalue;\n }\n \n+// Convert DuckDB's timestamp to R's timestamp (POSIXct). This is a represented as the number of seconds since the\n+// epoch, stored as a double.\n+template <LogicalTypeId>\n+double ConvertTimestampValue(int64_t timestamp);\n+\n+template <>\n+double ConvertTimestampValue<LogicalTypeId::TIMESTAMP_SEC>(int64_t timestamp) {\n+\treturn static_cast<double>(timestamp);\n+}\n+\n+template <>\n+double ConvertTimestampValue<LogicalTypeId::TIMESTAMP_MS>(int64_t timestamp) {\n+\treturn static_cast<double>(timestamp) / Interval::MSECS_PER_SEC;\n+}\n+\n+template <>\n+double ConvertTimestampValue<LogicalTypeId::TIMESTAMP>(int64_t timestamp) {\n+\treturn static_cast<double>(timestamp) / Interval::MICROS_PER_SEC;\n+}\n+\n+template <>\n+double ConvertTimestampValue<LogicalTypeId::TIMESTAMP_TZ>(int64_t timestamp) {\n+\treturn ConvertTimestampValue<LogicalTypeId::TIMESTAMP>(timestamp);\n+}\n+\n+template <>\n+double ConvertTimestampValue<LogicalTypeId::TIMESTAMP_NS>(int64_t timestamp) {\n+\treturn static_cast<double>(timestamp) / Interval::NANOS_PER_SEC;\n+}\n+\n+template <LogicalTypeId LT>\n+void ConvertTimestampVector(Vector &src_vec, size_t count, SEXP &dest, uint64_t dest_offset) {\n+\tauto src_data = FlatVector::GetData<int64_t>(src_vec);\n+\tauto &mask = FlatVector::Validity(src_vec);\n+\tdouble *dest_ptr = ((double *)NUMERIC_POINTER(dest)) + dest_offset;\n+\tfor (size_t row_idx = 0; row_idx < count; row_idx++) {\n+\t\tdest_ptr[row_idx] = !mask.RowIsValid(row_idx) ? NA_REAL : ConvertTimestampValue<LT>(src_data[row_idx]);\n+\t}\n+\n+\t// some dresssup for R\n+\tSET_CLASS(dest, RStrings::get().POSIXct_POSIXt_str);\n+\tRf_setAttrib(dest, RStrings::get().tzone_sym, RStrings::get().UTC_str);\n+}\n+\n+std::once_flag nanosecond_coercion_warning;\n+\n static void transform(Vector &src_vec, SEXP &dest, idx_t dest_offset, idx_t n) {\n \tswitch (src_vec.GetType().id()) {\n \tcase LogicalTypeId::BOOLEAN:\n@@ -269,20 +323,23 @@ static void transform(Vector &src_vec, SEXP &dest, idx_t dest_offset, idx_t n) {\n \tcase LogicalTypeId::INTEGER:\n \t\tVectorToR<int32_t, uint32_t>(src_vec, n, INTEGER_POINTER(dest), dest_offset, NA_INTEGER);\n \t\tbreak;\n-\tcase LogicalTypeId::TIMESTAMP: {\n-\t\tauto src_data = FlatVector::GetData<timestamp_t>(src_vec);\n-\t\tauto &mask = FlatVector::Validity(src_vec);\n-\t\tdouble *dest_ptr = ((double *)NUMERIC_POINTER(dest)) + dest_offset;\n-\t\tfor (size_t row_idx = 0; row_idx < n; row_idx++) {\n-\t\t\tdest_ptr[row_idx] =\n-\t\t\t    !mask.RowIsValid(row_idx) ? NA_REAL : (double)Timestamp::GetEpochSeconds(src_data[row_idx]);\n-\t\t}\n-\n-\t\t// some dresssup for R\n-\t\tSET_CLASS(dest, RStrings::get().POSIXct_POSIXt_str);\n-\t\tRf_setAttrib(dest, RStrings::get().tzone_sym, RStrings::get().UTC_str);\n+\tcase LogicalTypeId::TIMESTAMP_SEC:\n+\t\tConvertTimestampVector<LogicalTypeId::TIMESTAMP_SEC>(src_vec, n, dest, dest_offset);\n+\t\tbreak;\n+\tcase LogicalTypeId::TIMESTAMP_MS:\n+\t\tConvertTimestampVector<LogicalTypeId::TIMESTAMP_MS>(src_vec, n, dest, dest_offset);\n+\t\tbreak;\n+\tcase LogicalTypeId::TIMESTAMP:\n+\t\tConvertTimestampVector<LogicalTypeId::TIMESTAMP>(src_vec, n, dest, dest_offset);\n+\t\tbreak;\n+\tcase LogicalTypeId::TIMESTAMP_TZ:\n+\t\tConvertTimestampVector<LogicalTypeId::TIMESTAMP_TZ>(src_vec, n, dest, dest_offset);\n+\t\tbreak;\n+\tcase LogicalTypeId::TIMESTAMP_NS:\n+\t\tConvertTimestampVector<LogicalTypeId::TIMESTAMP_NS>(src_vec, n, dest, dest_offset);\n+\t\tstd::call_once(nanosecond_coercion_warning, Rf_warning,\n+\t\t               \"Coercing nanoseconds to a lower resolution may result in a loss of data.\");\n \t\tbreak;\n-\t}\n \tcase LogicalTypeId::DATE: {\n \t\tauto src_data = FlatVector::GetData<date_t>(src_vec);\n \t\tauto &mask = FlatVector::Validity(src_vec);\n",
  "test_patch": "diff --git a/tools/rpkg/tests/testthat/test_register_arrow.R b/tools/rpkg/tests/testthat/test_register_arrow.R\nindex cacf70980b13..2671273c28f0 100644\n--- a/tools/rpkg/tests/testthat/test_register_arrow.R\n+++ b/tools/rpkg/tests/testthat/test_register_arrow.R\n@@ -374,3 +374,36 @@ test_that(\"we can list registered arrow tables\", {\n \n   expect_equal(length(duckdb::duckdb_list_arrow(con)), 0)\n })\n+\n+\n+test_that(\"duckdb can read arrow timestamps\", {\n+  con <- DBI::dbConnect(duckdb::duckdb(), timezone_out = \"UTC\")\n+  on.exit(dbDisconnect(con, shutdown = TRUE))\n+\n+  timestamp <- as.POSIXct(\"2022-01-30 11:59:29\")\n+\n+  for (unit in c(\"s\", \"ms\", \"us\", \"ns\")) {\n+    tbl <- arrow::arrow_table(t = arrow::Array$create(timestamp, type = arrow::timestamp(unit)))\n+    duckdb::duckdb_register_arrow(con, \"timestamps\", tbl)\n+\n+    if (unit == \"ns\") {\n+      # warning when precision loss\n+      expect_warning({ res <- dbGetQuery(con, \"SELECT t FROM timestamps\") })\n+    } else {\n+      expect_warning({ res <- dbGetQuery(con, \"SELECT t FROM timestamps\") }, regexp = NA)\n+    }\n+    expect_equal(res[[1]], as.POSIXct(as.character(timestamp), tz = \"UTC\"))\n+\n+    res <- dbGetQuery(con, \"SELECT year(t), month(t), day(t), hour(t), minute(t), second(t) FROM timestamps\")\n+\n+    expect_equal(res[[1]], 2022)\n+    expect_equal(res[[2]], 1)\n+    expect_equal(res[[3]], 30)\n+    expect_equal(res[[4]], 11)\n+    expect_equal(res[[5]], 59)\n+    expect_equal(res[[6]], 29)\n+\n+    duckdb::duckdb_unregister_arrow(con, \"timestamps\")\n+  }\n+})\n+\n",
  "problem_statement": "  duckdb_prepare_R: Unknown column type for prepare: TIMESTAMP (NS)\n#### What happens?\r\n\r\n`arrow::to_duckdb()` fails to handle TIMESTAMP data in NS format in parquet files which duckdb created.  \r\n\r\n#### To Reproduce\r\n\r\n- I export data from duckdb to parquet; works as expected.\r\n- I read the parquet with `arrow::open_dataset` from R, works as expected\r\n- I try `arrow::to_duckb()` and get the error on any timestamp-type column\r\n\r\n```\r\n  duckdb_prepare_R: Unknown column type for prepare: TIMESTAMP (NS)\r\n```\r\n\r\n(Guessing this is a just a datatype that still needs to be implemented on the parquet reader, at least for the R client?  lemme know if a copy-paste example of R would help)\r\n\r\n#### Environment (please complete the following information):\r\n - OS: Linux\r\n - DuckDB Version: current\r\n - DuckDB Client: R\r\n\r\n#### Before Submitting\r\n\r\n- [x] **Have you tried this on the latest `master` branch?**\r\n* **Python**: `pip install duckdb --upgrade --pre`\r\n* **R**: `install.packages(\"https://github.com/duckdb/duckdb/releases/download/master-builds/duckdb_r_src.tar.gz\", repos = NULL)`\r\n* **Other Platforms**: You can find binaries [here](https://github.com/duckdb/duckdb/releases/tag/master-builds) or compile from source.\r\n\r\n- [x] **Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?**\r\n\n",
  "hints_text": "Copy paste example would be very appreciated its likely just a missing type somewhere\nSure thing, I should have done so first!  This should do it: (in R):\r\n\r\n``` r\r\nlibrary(duckdb)\r\nlibrary(arrow)\r\nlibrary(dplyr)\r\ndb <- dbConnect(duckdb())\r\ndf <- data.frame(date = Sys.Date())\r\ndbWriteTable(db, \"table\", df)\r\n\r\ndir <- \"test\"\r\nquery <- paste0(\"EXPORT DATABASE '\", dir, \"' (FORMAT PARQUET);\")\r\ndbExecute(db, query)\r\n#> [1] 0\r\nds <- open_dataset(\"test\")\r\nto_duckdb(ds)\r\n#> Error in .local(conn, statement, ...): duckdb_prepare_R: Unknown column type for prepare: TIMESTAMP (NS)\r\n```\r\n\r\n<sup>Created on 2021-12-04 by the [reprex package](https://reprex.tidyverse.org) (v2.0.1)</sup>\r\n\nAlso bumped into this with milliseconds. There are some case statements missing here: https://github.com/duckdb/duckdb/blob/0d3fee81ba83d69adf362d92482101a82a4a5de1/tools/rpkg/src/statement.cpp#L96-L98\r\n\r\nAside from the missing case statements, there is the issue of what R type can handle these higher resolutions. POSIXct is a double with fractional seconds so it has enough accuracy to handle milliseconds. Adding this should be trivial.\r\n\r\nNanoseconds are trickier as POSIXct doesn't have enough bits. The [nanotime](https://cran.r-project.org/web/packages/nanotime/index.html) package can handle this but it would be another dependency.\nThanks @james-atkins , that's a good point.  IMHO, in the case of nanosecond encoding, I think the default behavior of the R client should just round this to millisecond precision with a one-time warning about the precision loss.  In my experience, many data serializations merely encode data to the finest available precision of the software, often this precision is not only not necessary but not justified by the data collection mechanism (as illustrated in the reproducible example above!)\r\n\r\nOf course that would still be problematic in cases where nanosecond precision is critical, but that edge case could be handled at a later point?  ",
  "created_at": "2022-01-30T13:22:38Z"
}