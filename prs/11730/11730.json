{
  "repo": "duckdb/duckdb",
  "pull_number": 11730,
  "instance_id": "duckdb__duckdb-11730",
  "issue_numbers": [
    "11115"
  ],
  "base_commit": "aec0375c9c5585b9c92e5db5391c01913fc4d629",
  "patch": "diff --git a/src/common/enum_util.cpp b/src/common/enum_util.cpp\nindex b2db02f412c9..12a94a2b0f1c 100644\n--- a/src/common/enum_util.cpp\n+++ b/src/common/enum_util.cpp\n@@ -3802,14 +3802,10 @@ const char* EnumUtil::ToChars<MapInvalidReason>(MapInvalidReason value) {\n \tswitch(value) {\n \tcase MapInvalidReason::VALID:\n \t\treturn \"VALID\";\n-\tcase MapInvalidReason::NULL_KEY_LIST:\n-\t\treturn \"NULL_KEY_LIST\";\n \tcase MapInvalidReason::NULL_KEY:\n \t\treturn \"NULL_KEY\";\n \tcase MapInvalidReason::DUPLICATE_KEY:\n \t\treturn \"DUPLICATE_KEY\";\n-\tcase MapInvalidReason::NULL_VALUE_LIST:\n-\t\treturn \"NULL_VALUE_LIST\";\n \tcase MapInvalidReason::NOT_ALIGNED:\n \t\treturn \"NOT_ALIGNED\";\n \tcase MapInvalidReason::INVALID_PARAMS:\n@@ -3824,18 +3820,12 @@ MapInvalidReason EnumUtil::FromString<MapInvalidReason>(const char *value) {\n \tif (StringUtil::Equals(value, \"VALID\")) {\n \t\treturn MapInvalidReason::VALID;\n \t}\n-\tif (StringUtil::Equals(value, \"NULL_KEY_LIST\")) {\n-\t\treturn MapInvalidReason::NULL_KEY_LIST;\n-\t}\n \tif (StringUtil::Equals(value, \"NULL_KEY\")) {\n \t\treturn MapInvalidReason::NULL_KEY;\n \t}\n \tif (StringUtil::Equals(value, \"DUPLICATE_KEY\")) {\n \t\treturn MapInvalidReason::DUPLICATE_KEY;\n \t}\n-\tif (StringUtil::Equals(value, \"NULL_VALUE_LIST\")) {\n-\t\treturn MapInvalidReason::NULL_VALUE_LIST;\n-\t}\n \tif (StringUtil::Equals(value, \"NOT_ALIGNED\")) {\n \t\treturn MapInvalidReason::NOT_ALIGNED;\n \t}\ndiff --git a/src/common/types/vector.cpp b/src/common/types/vector.cpp\nindex e61ad46dd259..112dc0de96ab 100644\n--- a/src/common/types/vector.cpp\n+++ b/src/common/types/vector.cpp\n@@ -2089,10 +2089,6 @@ void MapVector::EvalMapInvalidReason(MapInvalidReason reason) {\n \t\tthrow InvalidInputException(\"Map keys must be unique.\");\n \tcase MapInvalidReason::NULL_KEY:\n \t\tthrow InvalidInputException(\"Map keys can not be NULL.\");\n-\tcase MapInvalidReason::NULL_KEY_LIST:\n-\t\tthrow InvalidInputException(\"The list of map keys must not be NULL.\");\n-\tcase MapInvalidReason::NULL_VALUE_LIST:\n-\t\tthrow InvalidInputException(\"The list of map values must not be NULL.\");\n \tcase MapInvalidReason::NOT_ALIGNED:\n \t\tthrow InvalidInputException(\"The map key list does not align with the map value list.\");\n \tcase MapInvalidReason::INVALID_PARAMS:\ndiff --git a/src/core_functions/scalar/map/map.cpp b/src/core_functions/scalar/map/map.cpp\nindex e27fe3fd6503..ab67475d151b 100644\n--- a/src/core_functions/scalar/map/map.cpp\n+++ b/src/core_functions/scalar/map/map.cpp\n@@ -21,14 +21,38 @@ static void MapFunctionEmptyInput(Vector &result, const idx_t row_count) {\n \tresult.Verify(row_count);\n }\n \n+static bool MapIsNull(DataChunk &chunk) {\n+\tif (chunk.data.empty()) {\n+\t\treturn false;\n+\t}\n+\tD_ASSERT(chunk.data.size() == 2);\n+\tauto &keys = chunk.data[0];\n+\tauto &values = chunk.data[1];\n+\n+\tif (keys.GetType().id() == LogicalTypeId::SQLNULL) {\n+\t\treturn true;\n+\t}\n+\tif (values.GetType().id() == LogicalTypeId::SQLNULL) {\n+\t\treturn true;\n+\t}\n+\treturn false;\n+}\n+\n static void MapFunction(DataChunk &args, ExpressionState &, Vector &result) {\n \n \t// internal MAP representation\n \t// - LIST-vector that contains STRUCTs as child entries\n \t// - STRUCTs have exactly two fields, a key-field, and a value-field\n \t// - key names are unique\n-\n \tD_ASSERT(result.GetType().id() == LogicalTypeId::MAP);\n+\n+\tif (MapIsNull(args)) {\n+\t\tauto &validity = FlatVector::Validity(result);\n+\t\tvalidity.SetInvalid(0);\n+\t\tresult.SetVectorType(VectorType::CONSTANT_VECTOR);\n+\t\treturn;\n+\t}\n+\n \tauto row_count = args.size();\n \n \t// early-out, if no data\n@@ -63,13 +87,15 @@ static void MapFunction(DataChunk &args, ExpressionState &, Vector &result) {\n \tUnifiedVectorFormat result_data;\n \tresult.ToUnifiedFormat(row_count, result_data);\n \tauto result_entries = UnifiedVectorFormat::GetDataNoConst<list_entry_t>(result_data);\n-\tresult_data.validity.SetAllValid(row_count);\n+\n+\tauto &result_validity = FlatVector::Validity(result);\n \n \t// get the resulting size of the key/value child lists\n \tidx_t result_child_size = 0;\n \tfor (idx_t row_idx = 0; row_idx < row_count; row_idx++) {\n \t\tauto keys_idx = keys_data.sel->get_index(row_idx);\n-\t\tif (!keys_data.validity.RowIsValid(keys_idx)) {\n+\t\tauto values_idx = values_data.sel->get_index(row_idx);\n+\t\tif (!keys_data.validity.RowIsValid(keys_idx) || !values_data.validity.RowIsValid(values_idx)) {\n \t\t\tcontinue;\n \t\t}\n \t\tauto keys_entry = keys_entries[keys_idx];\n@@ -87,22 +113,15 @@ static void MapFunction(DataChunk &args, ExpressionState &, Vector &result) {\n \t\tauto values_idx = values_data.sel->get_index(row_idx);\n \t\tauto result_idx = result_data.sel->get_index(row_idx);\n \n-\t\t// empty map\n-\t\tif (!keys_data.validity.RowIsValid(keys_idx) && !values_data.validity.RowIsValid(values_idx)) {\n-\t\t\tresult_entries[result_idx] = list_entry_t();\n+\t\t// NULL MAP\n+\t\tif (!keys_data.validity.RowIsValid(keys_idx) || !values_data.validity.RowIsValid(values_idx)) {\n+\t\t\tresult_validity.SetInvalid(row_idx);\n \t\t\tcontinue;\n \t\t}\n \n \t\tauto keys_entry = keys_entries[keys_idx];\n \t\tauto values_entry = values_entries[values_idx];\n \n-\t\t// validity checks\n-\t\tif (!keys_data.validity.RowIsValid(keys_idx)) {\n-\t\t\tMapVector::EvalMapInvalidReason(MapInvalidReason::NULL_KEY_LIST);\n-\t\t}\n-\t\tif (!values_data.validity.RowIsValid(values_idx)) {\n-\t\t\tMapVector::EvalMapInvalidReason(MapInvalidReason::NULL_VALUE_LIST);\n-\t\t}\n \t\tif (keys_entry.length != values_entry.length) {\n \t\t\tMapVector::EvalMapInvalidReason(MapInvalidReason::NOT_ALIGNED);\n \t\t}\n@@ -160,8 +179,19 @@ static unique_ptr<FunctionData> MapBind(ClientContext &, ScalarFunction &bound_f\n \t\tMapVector::EvalMapInvalidReason(MapInvalidReason::INVALID_PARAMS);\n \t}\n \n-\t// bind an empty MAP\n+\tbool is_null = false;\n \tif (arguments.empty()) {\n+\t\tis_null = true;\n+\t}\n+\tif (!is_null) {\n+\t\tauto key_id = arguments[0]->return_type.id();\n+\t\tauto value_id = arguments[1]->return_type.id();\n+\t\tif (key_id == LogicalTypeId::SQLNULL || value_id == LogicalTypeId::SQLNULL) {\n+\t\t\tis_null = true;\n+\t\t}\n+\t}\n+\n+\tif (is_null) {\n \t\tbound_function.return_type = LogicalType::MAP(LogicalTypeId::SQLNULL, LogicalTypeId::SQLNULL);\n \t\treturn make_uniq<VariableReturnBindData>(bound_function.return_type);\n \t}\ndiff --git a/src/function/table/arrow_conversion.cpp b/src/function/table/arrow_conversion.cpp\nindex 78d4cca859f6..c1759ef8484c 100644\n--- a/src/function/table/arrow_conversion.cpp\n+++ b/src/function/table/arrow_conversion.cpp\n@@ -317,9 +317,6 @@ static void ArrowToDuckDBMapVerify(Vector &vector, idx_t count) {\n \tcase MapInvalidReason::NULL_KEY: {\n \t\tthrow InvalidInputException(\"Arrow map contains NULL as map key, which isn't supported by DuckDB map type\");\n \t}\n-\tcase MapInvalidReason::NULL_KEY_LIST: {\n-\t\tthrow InvalidInputException(\"Arrow map contains NULL as key list, which isn't supported by DuckDB map type\");\n-\t}\n \tdefault: {\n \t\tthrow InternalException(\"MapInvalidReason not implemented\");\n \t}\ndiff --git a/src/include/duckdb/common/types/vector.hpp b/src/include/duckdb/common/types/vector.hpp\nindex b0786597a662..49cb9111c464 100644\n--- a/src/include/duckdb/common/types/vector.hpp\n+++ b/src/include/duckdb/common/types/vector.hpp\n@@ -464,15 +464,7 @@ struct FSSTVector {\n \tDUCKDB_API static idx_t GetCount(Vector &vector);\n };\n \n-enum class MapInvalidReason : uint8_t {\n-\tVALID,\n-\tNULL_KEY_LIST,\n-\tNULL_KEY,\n-\tDUPLICATE_KEY,\n-\tNULL_VALUE_LIST,\n-\tNOT_ALIGNED,\n-\tINVALID_PARAMS\n-};\n+enum class MapInvalidReason : uint8_t { VALID, NULL_KEY, DUPLICATE_KEY, NOT_ALIGNED, INVALID_PARAMS };\n \n struct MapVector {\n \tDUCKDB_API static const Vector &GetKeys(const Vector &vector);\ndiff --git a/tools/pythonpkg/src/native/python_conversion.cpp b/tools/pythonpkg/src/native/python_conversion.cpp\nindex cbdbb9f57f00..133d3fb768f1 100644\n--- a/tools/pythonpkg/src/native/python_conversion.cpp\n+++ b/tools/pythonpkg/src/native/python_conversion.cpp\n@@ -37,6 +37,20 @@ vector<string> TransformStructKeys(py::handle keys, idx_t size, const LogicalTyp\n \treturn res;\n }\n \n+static bool IsValidMapComponent(const py::handle &component) {\n+\t// The component is either NULL\n+\tif (py::none().is(component)) {\n+\t\treturn true;\n+\t}\n+\tif (!py::hasattr(component, \"__getitem__\")) {\n+\t\treturn false;\n+\t}\n+\tif (!py::hasattr(component, \"__len__\")) {\n+\t\treturn false;\n+\t}\n+\treturn true;\n+}\n+\n bool DictionaryHasMapFormat(const PyDictionary &dict) {\n \tif (dict.len != 2) {\n \t\treturn false;\n@@ -51,13 +65,19 @@ bool DictionaryHasMapFormat(const PyDictionary &dict) {\n \t\treturn false;\n \t}\n \n-\t// Dont check for 'py::list' to allow ducktyping\n-\tif (!py::hasattr(keys, \"__getitem__\") || !py::hasattr(keys, \"__len__\")) {\n+\tif (!IsValidMapComponent(keys)) {\n \t\treturn false;\n \t}\n-\tif (!py::hasattr(values, \"__getitem__\") || !py::hasattr(values, \"__len__\")) {\n+\tif (!IsValidMapComponent(values)) {\n \t\treturn false;\n \t}\n+\n+\t// If either of the components is NULL, return early\n+\tif (py::none().is(keys) || py::none().is(values)) {\n+\t\treturn true;\n+\t}\n+\n+\t// Verify that both the keys and values are of the same length\n \tauto size = py::len(keys);\n \tif (size != py::len(values)) {\n \t\treturn false;\n@@ -91,6 +111,11 @@ Value TransformStructFormatDictionaryToMap(const PyDictionary &dict, const Logic\n \tif (target_type.id() != LogicalTypeId::MAP) {\n \t\tthrow InvalidInputException(\"Please provide a valid target type for transform from Python to Value\");\n \t}\n+\n+\tif (py::none().is(dict.keys) || py::none().is(dict.values)) {\n+\t\treturn Value(LogicalType::MAP(LogicalTypeId::SQLNULL, LogicalTypeId::SQLNULL));\n+\t}\n+\n \tauto size = py::len(dict.keys);\n \tD_ASSERT(size == py::len(dict.values));\n \n@@ -130,12 +155,18 @@ Value TransformDictionaryToMap(const PyDictionary &dict, const LogicalType &targ\n \tauto keys = dict.values.attr(\"__getitem__\")(0);\n \tauto values = dict.values.attr(\"__getitem__\")(1);\n \n+\tif (py::none().is(keys) || py::none().is(values)) {\n+\t\t// Either 'key' or 'value' is None, return early with a NULL value\n+\t\treturn Value(LogicalType::MAP(LogicalTypeId::SQLNULL, LogicalTypeId::SQLNULL));\n+\t}\n+\n \tauto key_size = py::len(keys);\n \tD_ASSERT(key_size == py::len(values));\n \tif (key_size == 0) {\n \t\t// dict == { 'key': [], 'value': [] }\n \t\treturn EmptyMapValue();\n \t}\n+\n \t// dict == { 'key': [ ... ], 'value' : [ ... ] }\n \tLogicalType key_target = LogicalTypeId::UNKNOWN;\n \tLogicalType value_target = LogicalTypeId::UNKNOWN;\ndiff --git a/tools/pythonpkg/src/numpy/numpy_scan.cpp b/tools/pythonpkg/src/numpy/numpy_scan.cpp\nindex 032d3b97f014..b4b1d3dbe276 100644\n--- a/tools/pythonpkg/src/numpy/numpy_scan.cpp\n+++ b/tools/pythonpkg/src/numpy/numpy_scan.cpp\n@@ -153,8 +153,6 @@ static void VerifyMapConstraints(Vector &vec, idx_t count) {\n \t\treturn;\n \tcase MapInvalidReason::DUPLICATE_KEY:\n \t\tthrow InvalidInputException(\"Dict->Map conversion failed because 'key' list contains duplicates\");\n-\tcase MapInvalidReason::NULL_KEY_LIST:\n-\t\tthrow InvalidInputException(\"Dict->Map conversion failed because 'key' list is None\");\n \tcase MapInvalidReason::NULL_KEY:\n \t\tthrow InvalidInputException(\"Dict->Map conversion failed because 'key' list contains None\");\n \tdefault:\ndiff --git a/tools/pythonpkg/src/pandas/analyzer.cpp b/tools/pythonpkg/src/pandas/analyzer.cpp\nindex 508270894403..660d1fb2b3d2 100644\n--- a/tools/pythonpkg/src/pandas/analyzer.cpp\n+++ b/tools/pythonpkg/src/pandas/analyzer.cpp\n@@ -331,6 +331,10 @@ LogicalType PandasAnalyzer::DictToMap(const PyDictionary &dict, bool &can_conver\n \tauto keys = dict.values.attr(\"__getitem__\")(0);\n \tauto values = dict.values.attr(\"__getitem__\")(1);\n \n+\tif (py::none().is(keys) || py::none().is(values)) {\n+\t\treturn LogicalType::MAP(LogicalTypeId::SQLNULL, LogicalTypeId::SQLNULL);\n+\t}\n+\n \tauto key_type = GetListType(keys, can_convert);\n \tif (!can_convert) {\n \t\treturn EmptyMap();\n",
  "test_patch": "diff --git a/test/sql/types/map/map_null.test b/test/sql/types/map/map_null.test\nnew file mode 100644\nindex 000000000000..68dc58be808a\n--- /dev/null\n+++ b/test/sql/types/map/map_null.test\n@@ -0,0 +1,69 @@\n+# name: test/sql/types/map/map_null.test\n+# group: [map]\n+\n+statement ok\n+pragma enable_verification;\n+\n+query I\n+select map(NULL::INT[], [1,2,3])\n+----\n+NULL\n+\n+query I\n+select map(NULL, [1,2,3])\n+----\n+NULL\n+\n+query I\n+select map(NULL, NULL)\n+----\n+NULL\n+\n+query I\n+select map(NULL, [1,2,3]) IS NULL\n+----\n+true\n+\n+query I\n+select map([1,2,3], NULL)\n+----\n+NULL\n+\n+query I\n+select map([1,2,3], NULL::INT[])\n+----\n+NULL\n+\n+query I\n+SELECT * FROM ( VALUES\n+\t(MAP(NULL, NULL)),\n+\t(MAP(NULL::INT[], NULL::INT[])),\n+\t(MAP([1,2,3], [1,2,3]))\n+)\n+----\n+NULL\n+NULL\n+{1=1, 2=2, 3=3}\n+\n+query I\n+select MAP(a, b) FROM ( VALUES\n+\t(NULL, ['b', 'c']),\n+\t(NULL::INT[], NULL),\n+\t(NULL::INT[], NULL::VARCHAR[]),\n+\t(NULL::INT[], ['a', 'b', 'c']),\n+\t(NULL, ['longer string than inlined', 'smol']),\n+\t(NULL, NULL),\n+\t([1,2,3], NULL),\n+\t([1,2,3], ['z', 'y', 'x']),\n+\t([1,2,3], NULL::VARCHAR[]),\n+) t(a, b)\n+----\n+NULL\n+NULL\n+NULL\n+NULL\n+NULL\n+NULL\n+NULL\n+{1=z, 2=y, 3=x}\n+NULL\ndiff --git a/test/sql/types/nested/map/map_error.test b/test/sql/types/nested/map/map_error.test\nindex 315a1620ea7a..f67c19d4ead2 100644\n--- a/test/sql/types/nested/map/map_error.test\n+++ b/test/sql/types/nested/map/map_error.test\n@@ -75,10 +75,11 @@ CREATE TABLE null_keys_list (k INT[], v INT[]);\n statement ok\n INSERT INTO null_keys_list VALUES ([1], [2]), (NULL, [4]);\n \n-statement error\n+query I\n SELECT MAP(k, v) FROM null_keys_list;\n ----\n-The list of map keys must not be NULL.\n+{1=2}\n+NULL\n \n statement ok\n CREATE TABLE null_values_list (k INT[], v INT[]);\n@@ -86,7 +87,8 @@ CREATE TABLE null_values_list (k INT[], v INT[]);\n statement ok\n INSERT INTO null_values_list VALUES ([1], [2]), ([4], NULL);\n \n-statement error\n+query I\n SELECT MAP(k, v) FROM null_values_list;\n ----\n-The list of map values must not be NULL.\n\\ No newline at end of file\n+{1=2}\n+NULL\ndiff --git a/test/sql/types/nested/map/test_map_subscript.test b/test/sql/types/nested/map/test_map_subscript.test\nindex f75482857dad..8ad48d29e48b 100644\n--- a/test/sql/types/nested/map/test_map_subscript.test\n+++ b/test/sql/types/nested/map/test_map_subscript.test\n@@ -2,6 +2,9 @@\n # description: Test cardinality function for maps\n # group: [map]\n \n+statement ok\n+pragma enable_verification\n+\n # Single element on map\n query I\n select m[1] from (select MAP(LIST_VALUE(1, 2, 3, 4),LIST_VALUE(10, 9, 8, 7)) as m) as T\ndiff --git a/tools/pythonpkg/tests/fast/arrow/test_nested_arrow.py b/tools/pythonpkg/tests/fast/arrow/test_nested_arrow.py\nindex 592778146835..9c6ceb06b4fe 100644\n--- a/tools/pythonpkg/tests/fast/arrow/test_nested_arrow.py\n+++ b/tools/pythonpkg/tests/fast/arrow/test_nested_arrow.py\n@@ -183,6 +183,15 @@ def test_map_arrow_to_duckdb(self, duckdb_cursor):\n         ):\n             rel = duckdb.from_arrow(arrow_table).fetchall()\n \n+    def test_null_map_arrow_to_duckdb(self, duckdb_cursor):\n+        if not can_run:\n+            return\n+        map_type = pa.map_(pa.int32(), pa.int32())\n+        values = [None, [(5, 42)]]\n+        arrow_table = pa.table({'detail': pa.array(values, map_type)})\n+        res = duckdb_cursor.sql(\"select * from arrow_table\").fetchall()\n+        assert res == [(None,), ({'key': [5], 'value': [42]},)]\n+\n     def test_map_arrow_to_pandas(self, duckdb_cursor):\n         if not can_run:\n             return\ndiff --git a/tools/pythonpkg/tests/fast/pandas/test_df_object_resolution.py b/tools/pythonpkg/tests/fast/pandas/test_df_object_resolution.py\nindex 0f20f9fe0309..1a07e47fc8f4 100644\n--- a/tools/pythonpkg/tests/fast/pandas/test_df_object_resolution.py\n+++ b/tools/pythonpkg/tests/fast/pandas/test_df_object_resolution.py\n@@ -324,7 +324,7 @@ def test_map_duplicate(self, pandas, duckdb_cursor):\n         with pytest.raises(\n             duckdb.InvalidInputException, match=\"Dict->Map conversion failed because 'key' list contains duplicates\"\n         ):\n-            converted_col = duckdb_cursor.sql(\"select * from x\").df()\n+            duckdb_cursor.sql(\"select * from x\").show()\n \n     @pytest.mark.parametrize('pandas', [NumpyPandas(), ArrowPandas()])\n     def test_map_nullkey(self, pandas, duckdb_cursor):\n@@ -337,9 +337,8 @@ def test_map_nullkey(self, pandas, duckdb_cursor):\n     @pytest.mark.parametrize('pandas', [NumpyPandas(), ArrowPandas()])\n     def test_map_nullkeylist(self, pandas, duckdb_cursor):\n         x = pandas.DataFrame([[{'key': None, 'value': None}]])\n-        # Isn't actually converted to MAP because isinstance(None, list) != True\n         converted_col = duckdb_cursor.sql(\"select * from x\").df()\n-        duckdb_col = duckdb_cursor.sql(\"SELECT {key: NULL, value: NULL} as '0'\").df()\n+        duckdb_col = duckdb_cursor.sql(\"SELECT MAP(NULL, NULL) as '0'\").df()\n         pandas.testing.assert_frame_equal(duckdb_col, converted_col)\n \n     @pytest.mark.parametrize('pandas', [NumpyPandas(), ArrowPandas()])\n",
  "problem_statement": "Maps can't handle NULL keys or values\n### What happens?\r\n\r\n```sql\r\nSELECT MAP(NULL::INT[], [1, 2, 3]); \r\n--- Binder Error: Key and value list sizes don't match\r\nSELECT MAP([1,2,3], NULL::INT[]);\r\n--- Binder Error: Key and value list sizes don't match\r\nSELECT MAP(NULL::INT[], NULL::INT[]);\r\n--- results in {}, I would expect NULL\r\n--- This only is apparent in the CLI version.\r\n--- If I try this on shell.duckdb.org, you can't see a result as a result of unrelated bug https://github.com/duckdb/duckdb-wasm/issues/1671\r\n--- As a workaround to that bug:\r\nSELECT MAP(NULL::INT[], NULL::INT[]) IS NULL;\r\n--- gives false, should be true\r\n```\r\n\r\nI would expect all of these to give me NULL\r\n\r\n### To Reproduce\r\n\r\nsee above\r\n\r\n### OS:\r\n\r\nshell.duckdb.org\r\n\r\n### DuckDB Version:\r\n\r\n0.10.0\r\n\r\n### DuckDB Client:\r\n\r\n@duckdb/duckdb-wasm@1.28.1-dev166.0\r\n\r\n### Full Name:\r\n\r\nNick Crews\r\n\r\n### Affiliation:\r\n\r\nShip Creek Group\r\n\r\n### Have you tried this on the latest [nightly build](https://duckdb.org/docs/installation/?version=main)?\r\n\r\nI have tested with a nightly build\r\n\r\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\r\n\r\n- [X] Yes, I have\n",
  "hints_text": "@szarnyasg Note I just updated the original post, I originally thought `SELECT MAP(NULL::INT[], NULL::INT[]);` gave NULL, but it actually gives `{}`. So that is also incorrect.\noooh, I just tested on `0.10.1-dev1206`, and now the errors are slightly different (but I think still incorrect):\r\n\r\n```python\r\n# https://github.com/duckdb/duckdb/issues/11117\r\nimport duckdb\r\n\r\nprint(duckdb.__version__)\r\n# 0.10.1-dev1206\r\n\r\nconn = duckdb.connect(\":memory:\")\r\n\r\ntry:\r\n    conn.sql(\"SELECT MAP(NULL::INT[], [1, 2, 3]);\").fetchall()\r\nexcept Exception as e:\r\n    print(e)\r\n    # Invalid Input Error: The list of map keys must not be NULL.\r\n\r\ntry:\r\n    conn.sql(\"SELECT MAP([1, 2, 3], NULL::INT[]);\").fetchall()\r\nexcept Exception as e:\r\n    print(e)\r\n    # Invalid Input Error: The list of map values must not be NULL.\r\n\r\nprint(conn.sql(\"SELECT MAP(NULL::INT[], NULL::INT[]);\"))\r\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n# \u2502 map(CAST(NULL AS INTEGER[]), CAST(NULL AS INTEGER[])) \u2502\r\n# \u2502                 map(integer, integer)                 \u2502\r\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n# \u2502 {}                                                    \u2502\r\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\nThanks for the report, but this is expected behavior as far as we are concerned, is there a good reason to change this?\nIt feels inconsistent with the NULL propagation behavior with many other functions. For example `SELECT map_from_entries(NULL) IS NULL;` gives `true`. Especially the last (null, null) -> {} behavior is weird. Is there another example of a constructor-like function that takes all nulls and gives a non-null that I'm not thinking of?\r\n\r\nAlso, in https://github.com/ibis-project/ibis/pull/8649 I am adding workarounds to Ibis to make duckdb behave the same as the other backends, so the other backends (besides postgres, which does something else entirely, see that PR) all have the behavior that I'm asking for.\r\n\r\nDoes the current behavior have inherent advantages, or is it just that we should prefer stability, and so we should lean towards the status quo?\n@gforsyth @cpcloud in case they have thoughts\nTrino is probably the database I'm aware of that supports generic maps and adheres to a pretty rigorous interpretation of SQL and is relatively close to DuckDB in terms of semantics and SQL functionality.\r\n\r\nTheir `MAP` constructor returns `NULL` if any argument is `NULL`.\r\n\r\n```\r\ntrino:default> select map(null, null);\r\n _col0\r\n-------\r\n NULL\r\n(1 row)\r\n\r\nQuery 20240319_181750_02725_36bw5, FINISHED, 1 node\r\nSplits: 1 total, 1 done (100.00%)\r\n0.07 [0 rows, 0B] [0 rows/s, 0B/s]\r\n\r\ntrino:default> select map(null, array[1]);\r\n _col0\r\n-------\r\n NULL\r\n(1 row)\r\n\r\nQuery 20240319_181922_02782_36bw5, FINISHED, 1 node\r\nSplits: 1 total, 1 done (100.00%)\r\n0.03 [0 rows, 0B] [0 rows/s, 0B/s]\r\n\r\ntrino:default> select map(array[1], null);\r\n _col0\r\n-------\r\n NULL\r\n(1 row)\r\n```\nEmpty map doesn't really makes sense IMO since `NULL` in nearly every other case functions as \"unknown\", and so you can't say whether the keys, values, or both are empty or not.\n@Tishj Friendly ping here, duckdb differs from every other engine that supports nullable maps AFAICT (Trino, PySpark, Snowflake).\nI ran these through PySpark because I could not get Trino to function locally in a reasonable enough time (might need to go the docker route, I've seen that that is less painful)\r\n\r\n```py\r\n>>> con.sql(\"SELECT MAP(CAST(NULL AS ARRAY<INT>), CAST(NULL AS ARRAY<INT>)) IS NULL\").show()\r\n+-------------------------+\r\n|(map(NULL, NULL) IS NULL)|\r\n+-------------------------+\r\n|                    false|\r\n+-------------------------+\r\n```\r\n\r\n```py\r\n>>> con.sql(\"SELECT MAP(CAST(NULL AS ARRAY<INT>), CAST(NULL AS ARRAY<INT>))\").show()\r\npyspark.errors.exceptions.captured.SparkRuntimeException: [NULL_MAP_KEY] Cannot use null as map key.\r\n```\r\n\r\n```py\r\n>>> con.sql(\"SELECT MAP(CAST(NULL AS ARRAY<INT>), ARRAY(1, 2, 3))\").show()\r\npyspark.errors.exceptions.captured.SparkRuntimeException: [NULL_MAP_KEY] Cannot use null as map key.\r\n```\r\n\r\n```py\r\n>>> con.sql(\"SELECT MAP(ARRAY(1, 2, 3), CAST(NULL AS ARRAY<INT>))\").show()\r\n+-------------------------+\r\n|map(array(1, 2, 3), NULL)|\r\n+-------------------------+\r\n|      {[1, 2, 3] -> NULL}|\r\n+-------------------------+\r\n```\r\n\r\nIt's a little confusing that in the `IS NULL` query it doesn't seem to complain about the NULL keys, but without it we get an error ?\n```py\r\ncon.sql(\"SELECT map_from_entries(ARRAY(STRUCT(NULL, NULL), STRUCT(NULL, NULL)))\").show()\r\npyspark.errors.exceptions.captured.SparkRuntimeException: [NULL_MAP_KEY] Cannot use null as map key.\r\n```\r\n\r\n```py\r\n>>> con.sql(\"SELECT map_from_entries(ARRAY(STRUCT(NULL, NULL), STRUCT(NULL, NULL))) IS NULL\").show()\r\n+-------------------------------------------------------------------------+\r\n|(map_from_entries(array(struct(NULL, NULL), struct(NULL, NULL))) IS NULL)|\r\n+-------------------------------------------------------------------------+\r\n|                                                                    false|\r\n+-------------------------------------------------------------------------+\r\n```\r\n\r\nActually this is still not equivalent to our MAP function, for that we need MAP_FROM_ARRAYS\n```py\r\n>>> con.sql(\"SELECT map_from_arrays(CAST(NULL AS ARRAY<INT>), CAST(NULL AS ARRAY<INT>))\").show()\r\n+---------------------------+\r\n|map_from_arrays(NULL, NULL)|\r\n+---------------------------+\r\n|                       NULL|\r\n+---------------------------+\r\n```\r\n\r\n```py\r\n>>> con.sql(\"SELECT map_from_arrays(CAST(NULL AS ARRAY<INT>), CAST(NULL AS ARRAY<INT>)) IS NULL\").show()\r\n+-------------------------------------+\r\n|(map_from_arrays(NULL, NULL) IS NULL)|\r\n+-------------------------------------+\r\n|                                 true|\r\n+-------------------------------------+\r\n```\r\n\r\n```py\r\n>>> con.sql(\"SELECT map_from_arrays(ARRAY(1, 2, 3), CAST(NULL AS ARRAY<INT>))\").show()\r\n+-------------------------------------+\r\n|map_from_arrays(array(1, 2, 3), NULL)|\r\n+-------------------------------------+\r\n|                                 NULL|\r\n+-------------------------------------+\r\n```\r\n\r\n```py\r\n>>> con.sql(\"SELECT map_from_arrays(CAST(NULL AS ARRAY<INT>), ARRAY(1, 2, 3))\").show()\r\n+-------------------------------------+\r\n|map_from_arrays(NULL, array(1, 2, 3))|\r\n+-------------------------------------+\r\n|                                 NULL|\r\n+-------------------------------------+\r\n```",
  "created_at": "2024-04-19T08:12:09Z"
}