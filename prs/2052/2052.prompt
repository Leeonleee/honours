You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
No error displayed after an INSERT violates a UNIQUE constraint
Creating a unique index then inserting duplicates doesn't show any error. See related #514

```CREATE TABLE t0(c0 INT);
CREATE UNIQUE INDEX i0 ON t0(c0);
INSERT INTO t0(c0) VALUES (1);
INSERT INTO t0(c0) VALUES (1); -- expected error, actual no error
SELECT * FROM t0 WHERE t0.c0 = 1; -- as expected : expected: {1}, actual: {1}
```
However, if we create the table with the unique constraints, then constraint error is printed as it should.

</issue>
<code>
[start of README.md]
1: <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
2: 
3: ![.github/workflows/main.yml](https://github.com/cwida/duckdb/workflows/.github/workflows/main.yml/badge.svg?branch=master)
4: [![CodeFactor](https://www.codefactor.io/repository/github/cwida/duckdb/badge)](https://www.codefactor.io/repository/github/cwida/duckdb)
5: [![codecov](https://codecov.io/gh/duckdb/duckdb/branch/master/graph/badge.svg?token=FaxjcfFghN)](https://codecov.io/gh/duckdb/duckdb)
6: 
7: 
8: ## Installation
9: If you just want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
10: 
11: ## Development
12: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`.
13: 
14: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
15: 
16: 
[end of README.md]
[start of src/planner/binder/statement/bind_copy.cpp]
1: #include "duckdb/catalog/catalog.hpp"
2: #include "duckdb/parser/statement/copy_statement.hpp"
3: #include "duckdb/planner/binder.hpp"
4: #include "duckdb/parser/statement/insert_statement.hpp"
5: #include "duckdb/planner/operator/logical_copy_to_file.hpp"
6: #include "duckdb/planner/operator/logical_get.hpp"
7: #include "duckdb/planner/operator/logical_insert.hpp"
8: #include "duckdb/catalog/catalog_entry/copy_function_catalog_entry.hpp"
9: #include "duckdb/main/client_context.hpp"
10: #include "duckdb/main/database.hpp"
11: 
12: #include "duckdb/parser/expression/columnref_expression.hpp"
13: #include "duckdb/parser/expression/star_expression.hpp"
14: #include "duckdb/parser/tableref/basetableref.hpp"
15: #include "duckdb/parser/query_node/select_node.hpp"
16: 
17: #include <algorithm>
18: 
19: namespace duckdb {
20: 
21: BoundStatement Binder::BindCopyTo(CopyStatement &stmt) {
22: 	// COPY TO a file
23: 	auto &config = DBConfig::GetConfig(context);
24: 	if (!config.enable_external_access) {
25: 		throw Exception("COPY TO is disabled by configuration");
26: 	}
27: 	BoundStatement result;
28: 	result.types = {LogicalType::BIGINT};
29: 	result.names = {"Count"};
30: 
31: 	// bind the select statement
32: 	auto select_node = Bind(*stmt.select_statement);
33: 
34: 	// lookup the format in the catalog
35: 	auto &catalog = Catalog::GetCatalog(context);
36: 	auto copy_function = catalog.GetEntry<CopyFunctionCatalogEntry>(context, DEFAULT_SCHEMA, stmt.info->format);
37: 	if (!copy_function->function.copy_to_bind) {
38: 		throw NotImplementedException("COPY TO is not supported for FORMAT \"%s\"", stmt.info->format);
39: 	}
40: 
41: 	auto function_data =
42: 	    copy_function->function.copy_to_bind(context, *stmt.info, select_node.names, select_node.types);
43: 	// now create the copy information
44: 	auto copy = make_unique<LogicalCopyToFile>(copy_function->function, move(function_data));
45: 	copy->AddChild(move(select_node.plan));
46: 
47: 	result.plan = move(copy);
48: 
49: 	return result;
50: }
51: 
52: BoundStatement Binder::BindCopyFrom(CopyStatement &stmt) {
53: 	auto &config = DBConfig::GetConfig(context);
54: 	if (!config.enable_external_access) {
55: 		throw Exception("COPY FROM is disabled by configuration");
56: 	}
57: 	BoundStatement result;
58: 	result.types = {LogicalType::BIGINT};
59: 	result.names = {"Count"};
60: 
61: 	D_ASSERT(!stmt.info->table.empty());
62: 	// COPY FROM a file
63: 	// generate an insert statement for the the to-be-inserted table
64: 	InsertStatement insert;
65: 	insert.table = stmt.info->table;
66: 	insert.schema = stmt.info->schema;
67: 	insert.columns = stmt.info->select_list;
68: 
69: 	// bind the insert statement to the base table
70: 	auto insert_statement = Bind(insert);
71: 	D_ASSERT(insert_statement.plan->type == LogicalOperatorType::LOGICAL_INSERT);
72: 
73: 	auto &bound_insert = (LogicalInsert &)*insert_statement.plan;
74: 
75: 	// lookup the format in the catalog
76: 	auto &catalog = Catalog::GetCatalog(context);
77: 	auto copy_function = catalog.GetEntry<CopyFunctionCatalogEntry>(context, DEFAULT_SCHEMA, stmt.info->format);
78: 	if (!copy_function->function.copy_from_bind) {
79: 		throw NotImplementedException("COPY FROM is not supported for FORMAT \"%s\"", stmt.info->format);
80: 	}
81: 	// lookup the table to copy into
82: 	auto table = Catalog::GetCatalog(context).GetEntry<TableCatalogEntry>(context, stmt.info->schema, stmt.info->table);
83: 	vector<string> expected_names;
84: 	if (!bound_insert.column_index_map.empty()) {
85: 		expected_names.resize(bound_insert.expected_types.size());
86: 		for (idx_t i = 0; i < table->columns.size(); i++) {
87: 			if (bound_insert.column_index_map[i] != INVALID_INDEX) {
88: 				expected_names[bound_insert.column_index_map[i]] = table->columns[i].name;
89: 			}
90: 		}
91: 	} else {
92: 		expected_names.reserve(bound_insert.expected_types.size());
93: 		for (idx_t i = 0; i < table->columns.size(); i++) {
94: 			expected_names.push_back(table->columns[i].name);
95: 		}
96: 	}
97: 
98: 	auto function_data =
99: 	    copy_function->function.copy_from_bind(context, *stmt.info, expected_names, bound_insert.expected_types);
100: 	auto get = make_unique<LogicalGet>(0, copy_function->function.copy_from_function, move(function_data),
101: 	                                   bound_insert.expected_types, expected_names);
102: 	for (idx_t i = 0; i < bound_insert.expected_types.size(); i++) {
103: 		get->column_ids.push_back(i);
104: 	}
105: 	insert_statement.plan->children.push_back(move(get));
106: 	result.plan = move(insert_statement.plan);
107: 	return result;
108: }
109: 
110: BoundStatement Binder::Bind(CopyStatement &stmt) {
111: 	if (!stmt.info->is_from && !stmt.select_statement) {
112: 		// copy table into file without a query
113: 		// generate SELECT * FROM table;
114: 		auto ref = make_unique<BaseTableRef>();
115: 		ref->schema_name = stmt.info->schema;
116: 		ref->table_name = stmt.info->table;
117: 
118: 		auto statement = make_unique<SelectNode>();
119: 		statement->from_table = move(ref);
120: 		if (!stmt.info->select_list.empty()) {
121: 			for (auto &name : stmt.info->select_list) {
122: 				statement->select_list.push_back(make_unique<ColumnRefExpression>(name));
123: 			}
124: 		} else {
125: 			statement->select_list.push_back(make_unique<StarExpression>());
126: 		}
127: 		stmt.select_statement = move(statement);
128: 	}
129: 	if (stmt.info->is_from) {
130: 		return BindCopyFrom(stmt);
131: 	} else {
132: 		return BindCopyTo(stmt);
133: 	}
134: }
135: 
136: } // namespace duckdb
[end of src/planner/binder/statement/bind_copy.cpp]
[start of src/planner/binder/statement/bind_create_table.cpp]
1: #include "duckdb/parser/constraints/list.hpp"
2: #include "duckdb/parser/expression/cast_expression.hpp"
3: #include "duckdb/planner/binder.hpp"
4: #include "duckdb/planner/constraints/list.hpp"
5: #include "duckdb/planner/expression/bound_constant_expression.hpp"
6: #include "duckdb/planner/expression_binder/check_binder.hpp"
7: #include "duckdb/planner/expression_binder/constant_binder.hpp"
8: #include "duckdb/parser/parsed_data/create_table_info.hpp"
9: #include "duckdb/planner/parsed_data/bound_create_table_info.hpp"
10: #include <algorithm>
11: 
12: namespace duckdb {
13: 
14: static void CreateColumnMap(BoundCreateTableInfo &info) {
15: 	auto &base = (CreateTableInfo &)*info.base;
16: 
17: 	for (uint64_t oid = 0; oid < base.columns.size(); oid++) {
18: 		auto &col = base.columns[oid];
19: 		if (info.name_map.find(col.name) != info.name_map.end()) {
20: 			throw CatalogException("Column with name %s already exists!", col.name);
21: 		}
22: 
23: 		info.name_map[col.name] = oid;
24: 		col.oid = oid;
25: 	}
26: }
27: 
28: static void BindConstraints(Binder &binder, BoundCreateTableInfo &info) {
29: 	auto &base = (CreateTableInfo &)*info.base;
30: 
31: 	bool has_primary_key = false;
32: 	vector<idx_t> primary_keys;
33: 	for (idx_t i = 0; i < base.constraints.size(); i++) {
34: 		auto &cond = base.constraints[i];
35: 		switch (cond->type) {
36: 		case ConstraintType::CHECK: {
37: 			auto bound_constraint = make_unique<BoundCheckConstraint>();
38: 			// check constraint: bind the expression
39: 			CheckBinder check_binder(binder, binder.context, base.table, base.columns, bound_constraint->bound_columns);
40: 			auto &check = (CheckConstraint &)*cond;
41: 			// create a copy of the unbound expression because the binding destroys the constraint
42: 			auto unbound_expression = check.expression->Copy();
43: 			// now bind the constraint and create a new BoundCheckConstraint
44: 			bound_constraint->expression = check_binder.Bind(check.expression);
45: 			info.bound_constraints.push_back(move(bound_constraint));
46: 			// move the unbound constraint back into the original check expression
47: 			check.expression = move(unbound_expression);
48: 			break;
49: 		}
50: 		case ConstraintType::NOT_NULL: {
51: 			auto &not_null = (NotNullConstraint &)*cond;
52: 			info.bound_constraints.push_back(make_unique<BoundNotNullConstraint>(not_null.index));
53: 			break;
54: 		}
55: 		case ConstraintType::UNIQUE: {
56: 			auto &unique = (UniqueConstraint &)*cond;
57: 			// have to resolve columns of the unique constraint
58: 			vector<idx_t> keys;
59: 			unordered_set<idx_t> key_set;
60: 			if (unique.index != INVALID_INDEX) {
61: 				D_ASSERT(unique.index < base.columns.size());
62: 				// unique constraint is given by single index
63: 				unique.columns.push_back(base.columns[unique.index].name);
64: 				keys.push_back(unique.index);
65: 				key_set.insert(unique.index);
66: 			} else {
67: 				// unique constraint is given by list of names
68: 				// have to resolve names
69: 				D_ASSERT(unique.columns.size() > 0);
70: 				for (auto &keyname : unique.columns) {
71: 					auto entry = info.name_map.find(keyname);
72: 					if (entry == info.name_map.end()) {
73: 						throw ParserException("column \"%s\" named in key does not exist", keyname);
74: 					}
75: 					if (key_set.find(entry->second) != key_set.end()) {
76: 						throw ParserException("column \"%s\" appears twice in "
77: 						                      "primary key constraint",
78: 						                      keyname);
79: 					}
80: 					keys.push_back(entry->second);
81: 					key_set.insert(entry->second);
82: 				}
83: 			}
84: 
85: 			if (unique.is_primary_key) {
86: 				// we can only have one primary key per table
87: 				if (has_primary_key) {
88: 					throw ParserException("table \"%s\" has more than one primary key", base.table);
89: 				}
90: 				has_primary_key = true;
91: 				primary_keys = keys;
92: 			}
93: 			info.bound_constraints.push_back(
94: 			    make_unique<BoundUniqueConstraint>(move(keys), move(key_set), unique.is_primary_key));
95: 			break;
96: 		}
97: 		default:
98: 			throw NotImplementedException("unrecognized constraint type in bind");
99: 		}
100: 	}
101: 	if (has_primary_key) {
102: 		// if there is a primary key index, also create a NOT NULL constraint for each of the columns
103: 		for (auto &column_index : primary_keys) {
104: 			base.constraints.push_back(make_unique<NotNullConstraint>(column_index));
105: 			info.bound_constraints.push_back(make_unique<BoundNotNullConstraint>(column_index));
106: 		}
107: 	}
108: }
109: 
110: void Binder::BindDefaultValues(vector<ColumnDefinition> &columns, vector<unique_ptr<Expression>> &bound_defaults) {
111: 	for (idx_t i = 0; i < columns.size(); i++) {
112: 		unique_ptr<Expression> bound_default;
113: 		if (columns[i].default_value) {
114: 			// we bind a copy of the DEFAULT value because binding is destructive
115: 			// and we want to keep the original expression around for serialization
116: 			auto default_copy = columns[i].default_value->Copy();
117: 			ConstantBinder default_binder(*this, context, "DEFAULT value");
118: 			default_binder.target_type = columns[i].type;
119: 			bound_default = default_binder.Bind(default_copy);
120: 		} else {
121: 			// no default value specified: push a default value of constant null
122: 			bound_default = make_unique<BoundConstantExpression>(Value(columns[i].type));
123: 		}
124: 		bound_defaults.push_back(move(bound_default));
125: 	}
126: }
127: 
128: unique_ptr<BoundCreateTableInfo> Binder::BindCreateTableInfo(unique_ptr<CreateInfo> info) {
129: 	auto &base = (CreateTableInfo &)*info;
130: 
131: 	auto result = make_unique<BoundCreateTableInfo>(move(info));
132: 	result->schema = BindSchema(*result->base);
133: 	if (base.query) {
134: 		// construct the result object
135: 		auto query_obj = Bind(*base.query);
136: 		result->query = move(query_obj.plan);
137: 
138: 		// construct the set of columns based on the names and types of the query
139: 		auto &names = query_obj.names;
140: 		auto &sql_types = query_obj.types;
141: 		D_ASSERT(names.size() == sql_types.size());
142: 		for (idx_t i = 0; i < names.size(); i++) {
143: 			base.columns.emplace_back(names[i], sql_types[i]);
144: 		}
145: 		// create the name map for the statement
146: 		CreateColumnMap(*result);
147: 	} else {
148: 		// create the name map for the statement
149: 		CreateColumnMap(*result);
150: 		// bind any constraints
151: 		BindConstraints(*this, *result);
152: 		// bind the default values
153: 		BindDefaultValues(base.columns, result->bound_defaults);
154: 	}
155: 	// bind collations to detect any unsupported collation errors
156: 	for (auto &column : base.columns) {
157: 		ExpressionBinder::TestCollation(context, StringType::GetCollation(column.type));
158: 	}
159: 	return result;
160: }
161: 
162: } // namespace duckdb
[end of src/planner/binder/statement/bind_create_table.cpp]
[start of src/planner/binder/statement/bind_delete.cpp]
1: #include "duckdb/parser/statement/delete_statement.hpp"
2: #include "duckdb/planner/binder.hpp"
3: #include "duckdb/planner/expression_binder/where_binder.hpp"
4: #include "duckdb/planner/operator/logical_delete.hpp"
5: #include "duckdb/planner/operator/logical_filter.hpp"
6: #include "duckdb/planner/operator/logical_get.hpp"
7: #include "duckdb/planner/bound_tableref.hpp"
8: #include "duckdb/planner/tableref/bound_basetableref.hpp"
9: #include "duckdb/planner/operator/logical_cross_product.hpp"
10: 
11: namespace duckdb {
12: 
13: BoundStatement Binder::Bind(DeleteStatement &stmt) {
14: 	BoundStatement result;
15: 
16: 	// visit the table reference
17: 	auto bound_table = Bind(*stmt.table);
18: 	if (bound_table->type != TableReferenceType::BASE_TABLE) {
19: 		throw BinderException("Can only delete from base table!");
20: 	}
21: 	auto &table_binding = (BoundBaseTableRef &)*bound_table;
22: 	auto table = table_binding.table;
23: 
24: 	auto root = CreatePlan(*bound_table);
25: 	auto &get = (LogicalGet &)*root;
26: 	D_ASSERT(root->type == LogicalOperatorType::LOGICAL_GET);
27: 
28: 	if (!table->temporary) {
29: 		// delete from persistent table: not read only!
30: 		this->read_only = false;
31: 	}
32: 
33: 	// plan any tables from the various using clauses
34: 	if (!stmt.using_clauses.empty()) {
35: 		unique_ptr<LogicalOperator> child_operator;
36: 		for (auto &using_clause : stmt.using_clauses) {
37: 			// bind the using clause
38: 			auto bound_node = Bind(*using_clause);
39: 			auto op = CreatePlan(*bound_node);
40: 			if (child_operator) {
41: 				// already bound a child: create a cross product to unify the two
42: 				auto cross_product = make_unique<LogicalCrossProduct>();
43: 				cross_product->children.push_back(move(child_operator));
44: 				cross_product->children.push_back(move(op));
45: 				child_operator = move(cross_product);
46: 			} else {
47: 				child_operator = move(op);
48: 			}
49: 		}
50: 		if (child_operator) {
51: 			auto cross_product = make_unique<LogicalCrossProduct>();
52: 			cross_product->children.push_back(move(root));
53: 			cross_product->children.push_back(move(child_operator));
54: 			root = move(cross_product);
55: 		}
56: 	}
57: 
58: 	// project any additional columns required for the condition
59: 	unique_ptr<Expression> condition;
60: 	if (stmt.condition) {
61: 		WhereBinder binder(*this, context);
62: 		condition = binder.Bind(stmt.condition);
63: 
64: 		PlanSubqueries(&condition, &root);
65: 		auto filter = make_unique<LogicalFilter>(move(condition));
66: 		filter->AddChild(move(root));
67: 		root = move(filter);
68: 	}
69: 	// create the delete node
70: 	auto del = make_unique<LogicalDelete>(table);
71: 	del->AddChild(move(root));
72: 
73: 	// set up the delete expression
74: 	del->expressions.push_back(
75: 	    make_unique<BoundColumnRefExpression>(LOGICAL_ROW_TYPE, ColumnBinding(get.table_index, get.column_ids.size())));
76: 	get.column_ids.push_back(COLUMN_IDENTIFIER_ROW_ID);
77: 
78: 	result.plan = move(del);
79: 	result.names = {"Count"};
80: 	result.types = {LogicalType::BIGINT};
81: 	return result;
82: }
83: 
84: } // namespace duckdb
[end of src/planner/binder/statement/bind_delete.cpp]
[start of src/planner/binder/statement/bind_drop.cpp]
1: #include "duckdb/parser/statement/drop_statement.hpp"
2: #include "duckdb/planner/binder.hpp"
3: #include "duckdb/planner/operator/logical_simple.hpp"
4: #include "duckdb/catalog/catalog.hpp"
5: #include "duckdb/catalog/standard_entry.hpp"
6: #include "duckdb/catalog/catalog_entry/schema_catalog_entry.hpp"
7: 
8: namespace duckdb {
9: 
10: BoundStatement Binder::Bind(DropStatement &stmt) {
11: 	BoundStatement result;
12: 
13: 	switch (stmt.info->type) {
14: 	case CatalogType::PREPARED_STATEMENT:
15: 		// dropping prepared statements is always possible
16: 		// it also does not require a valid transaction
17: 		this->requires_valid_transaction = false;
18: 		break;
19: 	case CatalogType::SCHEMA_ENTRY:
20: 		// dropping a schema is never read-only because there are no temporary schemas
21: 		this->read_only = false;
22: 		break;
23: 	case CatalogType::VIEW_ENTRY:
24: 	case CatalogType::SEQUENCE_ENTRY:
25: 	case CatalogType::MACRO_ENTRY:
26: 	case CatalogType::INDEX_ENTRY:
27: 	case CatalogType::TABLE_ENTRY: {
28: 		auto entry = (StandardEntry *)Catalog::GetCatalog(context).GetEntry(context, stmt.info->type, stmt.info->schema,
29: 		                                                                    stmt.info->name, true);
30: 		if (!entry) {
31: 			break;
32: 		}
33: 		if (!entry->temporary) {
34: 			// we can only drop temporary tables in read-only mode
35: 			this->read_only = false;
36: 		}
37: 		stmt.info->schema = entry->schema->name;
38: 		break;
39: 	}
40: 	default:
41: 		throw BinderException("Unknown catalog type for drop statement!");
42: 	}
43: 	result.plan = make_unique<LogicalSimple>(LogicalOperatorType::LOGICAL_DROP, move(stmt.info));
44: 	result.names = {"Success"};
45: 	result.types = {LogicalType::BOOLEAN};
46: 	return result;
47: }
48: 
49: } // namespace duckdb
[end of src/planner/binder/statement/bind_drop.cpp]
[start of src/planner/binder/statement/bind_export.cpp]
1: #include "duckdb/catalog/catalog.hpp"
2: #include "duckdb/parser/statement/export_statement.hpp"
3: #include "duckdb/planner/binder.hpp"
4: #include "duckdb/planner/operator/logical_export.hpp"
5: #include "duckdb/catalog/catalog_entry/copy_function_catalog_entry.hpp"
6: #include "duckdb/parser/statement/copy_statement.hpp"
7: #include "duckdb/main/client_context.hpp"
8: #include "duckdb/main/database.hpp"
9: #include "duckdb/common/file_system.hpp"
10: #include "duckdb/planner/operator/logical_set_operation.hpp"
11: #include "duckdb/parser/parsed_data/exported_table_data.hpp"
12: 
13: #include "duckdb/common/string_util.hpp"
14: #include <algorithm>
15: 
16: namespace duckdb {
17: 
18: //! Sanitizes a string to have only low case chars and underscores
19: string SanitizeExportIdentifier(const string &str) {
20: 	// Copy the original string to result
21: 	string result(str);
22: 
23: 	for (idx_t i = 0; i < str.length(); ++i) {
24: 		auto c = str[i];
25: 		if (c >= 'a' && c <= 'z') {
26: 			// If it is lower case just continue
27: 			continue;
28: 		}
29: 
30: 		if (c >= 'A' && c <= 'Z') {
31: 			// To lowercase
32: 			result[i] = tolower(c);
33: 		} else {
34: 			// Substitute to underscore
35: 			result[i] = '_';
36: 		}
37: 	}
38: 
39: 	return result;
40: }
41: 
42: BoundStatement Binder::Bind(ExportStatement &stmt) {
43: 	// COPY TO a file
44: 	auto &config = DBConfig::GetConfig(context);
45: 	if (!config.enable_external_access) {
46: 		throw Exception("COPY TO is disabled by configuration");
47: 	}
48: 	BoundStatement result;
49: 	result.types = {LogicalType::BOOLEAN};
50: 	result.names = {"Success"};
51: 
52: 	// lookup the format in the catalog
53: 	auto &catalog = Catalog::GetCatalog(context);
54: 	auto copy_function = catalog.GetEntry<CopyFunctionCatalogEntry>(context, DEFAULT_SCHEMA, stmt.info->format);
55: 	if (!copy_function->function.copy_to_bind) {
56: 		throw NotImplementedException("COPY TO is not supported for FORMAT \"%s\"", stmt.info->format);
57: 	}
58: 
59: 	// gather a list of all the tables
60: 	vector<TableCatalogEntry *> tables;
61: 	auto schemas = catalog.schemas->GetEntries<SchemaCatalogEntry>(context);
62: 	for (auto &schema : schemas) {
63: 		schema->Scan(context, CatalogType::TABLE_ENTRY, [&](CatalogEntry *entry) {
64: 			if (entry->type == CatalogType::TABLE_ENTRY) {
65: 				tables.push_back((TableCatalogEntry *)entry);
66: 			}
67: 		});
68: 	}
69: 
70: 	// now generate the COPY statements for each of the tables
71: 	auto &fs = FileSystem::GetFileSystem(context);
72: 	unique_ptr<LogicalOperator> child_operator;
73: 
74: 	BoundExportData exported_tables;
75: 
76: 	idx_t id = 0; // Id for table
77: 	for (auto &table : tables) {
78: 		auto info = make_unique<CopyInfo>();
79: 		// we copy the options supplied to the EXPORT
80: 		info->format = stmt.info->format;
81: 		info->options = stmt.info->options;
82: 		// set up the file name for the COPY TO
83: 
84: 		auto exported_data = ExportedTableData();
85: 		if (table->schema->name == DEFAULT_SCHEMA) {
86: 			info->file_path =
87: 			    fs.JoinPath(stmt.info->file_path,
88: 			                StringUtil::Format("%s_%s.%s", to_string(id), SanitizeExportIdentifier(table->name),
89: 			                                   copy_function->function.extension));
90: 		} else {
91: 			info->file_path = fs.JoinPath(
92: 			    stmt.info->file_path,
93: 			    StringUtil::Format("%s_%s_%s.%s", SanitizeExportIdentifier(table->schema->name), to_string(id),
94: 			                       SanitizeExportIdentifier(table->name), copy_function->function.extension));
95: 		}
96: 		info->is_from = false;
97: 		info->schema = table->schema->name;
98: 		info->table = table->name;
99: 
100: 		exported_data.table_name = info->table;
101: 		exported_data.schema_name = info->schema;
102: 		exported_data.file_path = info->file_path;
103: 
104: 		exported_tables.data[table] = exported_data;
105: 		id++;
106: 
107: 		// generate the copy statement and bind it
108: 		CopyStatement copy_stmt;
109: 		copy_stmt.info = move(info);
110: 
111: 		auto copy_binder = Binder::CreateBinder(context);
112: 		auto bound_statement = copy_binder->Bind(copy_stmt);
113: 		if (child_operator) {
114: 			// use UNION ALL to combine the individual copy statements into a single node
115: 			auto copy_union =
116: 			    make_unique<LogicalSetOperation>(GenerateTableIndex(), 1, move(child_operator),
117: 			                                     move(bound_statement.plan), LogicalOperatorType::LOGICAL_UNION);
118: 			child_operator = move(copy_union);
119: 		} else {
120: 			child_operator = move(bound_statement.plan);
121: 		}
122: 	}
123: 
124: 	// try to create the directory, if it doesn't exist yet
125: 	// a bit hacky to do it here, but we need to create the directory BEFORE the copy statements run
126: 	if (!fs.DirectoryExists(stmt.info->file_path)) {
127: 		fs.CreateDirectory(stmt.info->file_path);
128: 	}
129: 
130: 	// create the export node
131: 	auto export_node = make_unique<LogicalExport>(copy_function->function, move(stmt.info), exported_tables);
132: 
133: 	if (child_operator) {
134: 		export_node->children.push_back(move(child_operator));
135: 	}
136: 
137: 	result.plan = move(export_node);
138: 	return result;
139: }
140: 
141: } // namespace duckdb
[end of src/planner/binder/statement/bind_export.cpp]
[start of src/planner/binder/statement/bind_insert.cpp]
1: #include "duckdb/catalog/catalog.hpp"
2: #include "duckdb/parser/expression/constant_expression.hpp"
3: #include "duckdb/parser/statement/insert_statement.hpp"
4: #include "duckdb/parser/query_node/select_node.hpp"
5: #include "duckdb/parser/tableref/expressionlistref.hpp"
6: #include "duckdb/planner/binder.hpp"
7: #include "duckdb/planner/expression_binder/insert_binder.hpp"
8: #include "duckdb/planner/operator/logical_insert.hpp"
9: #include "duckdb/common/string_util.hpp"
10: 
11: namespace duckdb {
12: 
13: static void CheckInsertColumnCountMismatch(int64_t expected_columns, int64_t result_columns, bool columns_provided,
14:                                            const char *tname) {
15: 	if (result_columns != expected_columns) {
16: 		string msg = StringUtil::Format(!columns_provided ? "table %s has %lld columns but %lld values were supplied"
17: 		                                                  : "Column name/value mismatch for insert on %s: "
18: 		                                                    "expected %lld columns but %lld values were supplied",
19: 		                                tname, expected_columns, result_columns);
20: 		throw BinderException(msg);
21: 	}
22: }
23: 
24: BoundStatement Binder::Bind(InsertStatement &stmt) {
25: 	BoundStatement result;
26: 	result.names = {"Count"};
27: 	result.types = {LogicalType::BIGINT};
28: 
29: 	auto table = Catalog::GetCatalog(context).GetEntry<TableCatalogEntry>(context, stmt.schema, stmt.table);
30: 	D_ASSERT(table);
31: 	if (!table->temporary) {
32: 		// inserting into a non-temporary table: alters underlying database
33: 		this->read_only = false;
34: 	}
35: 
36: 	auto insert = make_unique<LogicalInsert>(table);
37: 
38: 	vector<idx_t> named_column_map;
39: 	if (!stmt.columns.empty()) {
40: 		// insertion statement specifies column list
41: 
42: 		// create a mapping of (list index) -> (column index)
43: 		unordered_map<string, idx_t> column_name_map;
44: 		for (idx_t i = 0; i < stmt.columns.size(); i++) {
45: 			column_name_map[stmt.columns[i]] = i;
46: 			auto entry = table->name_map.find(stmt.columns[i]);
47: 			if (entry == table->name_map.end()) {
48: 				throw BinderException("Column %s not found in table %s", stmt.columns[i], table->name);
49: 			}
50: 			if (entry->second == COLUMN_IDENTIFIER_ROW_ID) {
51: 				throw BinderException("Cannot explicitly insert values into rowid column");
52: 			}
53: 			insert->expected_types.push_back(table->columns[entry->second].type);
54: 			named_column_map.push_back(entry->second);
55: 		}
56: 		for (idx_t i = 0; i < table->columns.size(); i++) {
57: 			auto &col = table->columns[i];
58: 			auto entry = column_name_map.find(col.name);
59: 			if (entry == column_name_map.end()) {
60: 				// column not specified, set index to INVALID_INDEX
61: 				insert->column_index_map.push_back(INVALID_INDEX);
62: 			} else {
63: 				// column was specified, set to the index
64: 				insert->column_index_map.push_back(entry->second);
65: 			}
66: 		}
67: 	} else {
68: 		for (idx_t i = 0; i < table->columns.size(); i++) {
69: 			insert->expected_types.push_back(table->columns[i].type);
70: 		}
71: 	}
72: 
73: 	// bind the default values
74: 	BindDefaultValues(table->columns, insert->bound_defaults);
75: 	if (!stmt.select_statement) {
76: 		result.plan = move(insert);
77: 		return result;
78: 	}
79: 
80: 	idx_t expected_columns = stmt.columns.empty() ? table->columns.size() : stmt.columns.size();
81: 	// special case: check if we are inserting from a VALUES statement
82: 	if (stmt.select_statement->node->type == QueryNodeType::SELECT_NODE) {
83: 		auto &node = (SelectNode &)*stmt.select_statement->node;
84: 		if (node.from_table->type == TableReferenceType::EXPRESSION_LIST) {
85: 			auto &expr_list = (ExpressionListRef &)*node.from_table;
86: 			expr_list.expected_types.resize(expected_columns);
87: 			expr_list.expected_names.resize(expected_columns);
88: 
89: 			D_ASSERT(expr_list.values.size() > 0);
90: 			CheckInsertColumnCountMismatch(expected_columns, expr_list.values[0].size(), !stmt.columns.empty(),
91: 			                               table->name.c_str());
92: 
93: 			// VALUES list!
94: 			for (idx_t col_idx = 0; col_idx < expected_columns; col_idx++) {
95: 				idx_t table_col_idx = stmt.columns.empty() ? col_idx : named_column_map[col_idx];
96: 				D_ASSERT(table_col_idx < table->columns.size());
97: 
98: 				// set the expected types as the types for the INSERT statement
99: 				auto &column = table->columns[table_col_idx];
100: 				expr_list.expected_types[col_idx] = column.type;
101: 				expr_list.expected_names[col_idx] = column.name;
102: 
103: 				// now replace any DEFAULT values with the corresponding default expression
104: 				for (idx_t list_idx = 0; list_idx < expr_list.values.size(); list_idx++) {
105: 					if (expr_list.values[list_idx][col_idx]->type == ExpressionType::VALUE_DEFAULT) {
106: 						// DEFAULT value! replace the entry
107: 						if (column.default_value) {
108: 							expr_list.values[list_idx][col_idx] = column.default_value->Copy();
109: 						} else {
110: 							expr_list.values[list_idx][col_idx] = make_unique<ConstantExpression>(Value(column.type));
111: 						}
112: 					}
113: 				}
114: 			}
115: 		}
116: 	}
117: 
118: 	// insert from select statement
119: 	// parse select statement and add to logical plan
120: 	auto root_select = Bind(*stmt.select_statement);
121: 	CheckInsertColumnCountMismatch(expected_columns, root_select.types.size(), !stmt.columns.empty(),
122: 	                               table->name.c_str());
123: 
124: 	auto root = CastLogicalOperatorToTypes(root_select.types, insert->expected_types, move(root_select.plan));
125: 	insert->AddChild(move(root));
126: 
127: 	result.plan = move(insert);
128: 	return result;
129: }
130: 
131: } // namespace duckdb
[end of src/planner/binder/statement/bind_insert.cpp]
[start of src/planner/binder/statement/bind_load.cpp]
1: #include "duckdb/parser/statement/load_statement.hpp"
2: #include "duckdb/planner/binder.hpp"
3: #include "duckdb/planner/operator/logical_simple.hpp"
4: #include <algorithm>
5: 
6: namespace duckdb {
7: 
8: BoundStatement Binder::Bind(LoadStatement &stmt) {
9: 	BoundStatement result;
10: 	result.types = {LogicalType::BOOLEAN};
11: 	result.names = {"Success"};
12: 
13: 	result.plan = make_unique<LogicalSimple>(LogicalOperatorType::LOGICAL_LOAD, move(stmt.info));
14: 	return result;
15: }
16: 
17: } // namespace duckdb
[end of src/planner/binder/statement/bind_load.cpp]
[start of src/planner/binder/statement/bind_update.cpp]
1: #include "duckdb/parser/statement/update_statement.hpp"
2: #include "duckdb/planner/binder.hpp"
3: #include "duckdb/planner/expression/bound_columnref_expression.hpp"
4: #include "duckdb/planner/expression/bound_default_expression.hpp"
5: #include "duckdb/planner/expression_binder/update_binder.hpp"
6: #include "duckdb/planner/expression_binder/where_binder.hpp"
7: #include "duckdb/planner/operator/logical_filter.hpp"
8: #include "duckdb/planner/operator/logical_get.hpp"
9: #include "duckdb/planner/operator/logical_projection.hpp"
10: #include "duckdb/planner/operator/logical_update.hpp"
11: #include "duckdb/planner/constraints/bound_check_constraint.hpp"
12: #include "duckdb/parser/expression/columnref_expression.hpp"
13: #include "duckdb/storage/data_table.hpp"
14: #include "duckdb/planner/bound_tableref.hpp"
15: #include "duckdb/planner/tableref/bound_basetableref.hpp"
16: #include "duckdb/planner/tableref/bound_crossproductref.hpp"
17: #include <algorithm>
18: 
19: namespace duckdb {
20: 
21: static void BindExtraColumns(TableCatalogEntry &table, LogicalGet &get, LogicalProjection &proj, LogicalUpdate &update,
22:                              unordered_set<column_t> &bound_columns) {
23: 	if (bound_columns.size() <= 1) {
24: 		return;
25: 	}
26: 	idx_t found_column_count = 0;
27: 	unordered_set<idx_t> found_columns;
28: 	for (idx_t i = 0; i < update.columns.size(); i++) {
29: 		if (bound_columns.find(update.columns[i]) != bound_columns.end()) {
30: 			// this column is referenced in the CHECK constraint
31: 			found_column_count++;
32: 			found_columns.insert(update.columns[i]);
33: 		}
34: 	}
35: 	if (found_column_count > 0 && found_column_count != bound_columns.size()) {
36: 		// columns in this CHECK constraint were referenced, but not all were part of the UPDATE
37: 		// add them to the scan and update set
38: 		for (auto &check_column_id : bound_columns) {
39: 			if (found_columns.find(check_column_id) != found_columns.end()) {
40: 				// column is already projected
41: 				continue;
42: 			}
43: 			// column is not projected yet: project it by adding the clause "i=i" to the set of updated columns
44: 			auto &column = table.columns[check_column_id];
45: 			update.expressions.push_back(make_unique<BoundColumnRefExpression>(
46: 			    column.type, ColumnBinding(proj.table_index, proj.expressions.size())));
47: 			proj.expressions.push_back(make_unique<BoundColumnRefExpression>(
48: 			    column.type, ColumnBinding(get.table_index, get.column_ids.size())));
49: 			get.column_ids.push_back(check_column_id);
50: 			update.columns.push_back(check_column_id);
51: 		}
52: 	}
53: }
54: 
55: static bool TypeSupportsRegularUpdate(const LogicalType &type) {
56: 	switch (type.id()) {
57: 	case LogicalTypeId::LIST:
58: 	case LogicalTypeId::MAP:
59: 		// lists and maps don't support updates directly
60: 		return false;
61: 	case LogicalTypeId::STRUCT: {
62: 		auto &child_types = StructType::GetChildTypes(type);
63: 		for (auto &entry : child_types) {
64: 			if (!TypeSupportsRegularUpdate(entry.second)) {
65: 				return false;
66: 			}
67: 		}
68: 		return true;
69: 	}
70: 	default:
71: 		return true;
72: 	}
73: }
74: 
75: static void BindUpdateConstraints(TableCatalogEntry &table, LogicalGet &get, LogicalProjection &proj,
76:                                   LogicalUpdate &update) {
77: 	// check the constraints and indexes of the table to see if we need to project any additional columns
78: 	// we do this for indexes with multiple columns and CHECK constraints in the UPDATE clause
79: 	// suppose we have a constraint CHECK(i + j < 10); now we need both i and j to check the constraint
80: 	// if we are only updating one of the two columns we add the other one to the UPDATE set
81: 	// with a "useless" update (i.e. i=i) so we can verify that the CHECK constraint is not violated
82: 	for (auto &constraint : table.bound_constraints) {
83: 		if (constraint->type == ConstraintType::CHECK) {
84: 			auto &check = *reinterpret_cast<BoundCheckConstraint *>(constraint.get());
85: 			// check constraint! check if we need to add any extra columns to the UPDATE clause
86: 			BindExtraColumns(table, get, proj, update, check.bound_columns);
87: 		}
88: 	}
89: 	// for index updates we always turn any update into an insert and a delete
90: 	// we thus need all the columns to be available, hence we check if the update touches any index columns
91: 	update.update_is_del_and_insert = false;
92: 	table.storage->info->indexes.Scan([&](Index &index) {
93: 		if (index.IndexIsUpdated(update.columns)) {
94: 			update.update_is_del_and_insert = true;
95: 			return true;
96: 		}
97: 		return false;
98: 	});
99: 
100: 	// we also convert any updates on LIST columns into delete + insert
101: 	for (auto &col : update.columns) {
102: 		if (!TypeSupportsRegularUpdate(table.columns[col].type)) {
103: 			update.update_is_del_and_insert = true;
104: 			break;
105: 		}
106: 	}
107: 
108: 	if (update.update_is_del_and_insert) {
109: 		// the update updates a column required by an index, push projections for all columns
110: 		unordered_set<column_t> all_columns;
111: 		for (idx_t i = 0; i < table.storage->types.size(); i++) {
112: 			all_columns.insert(i);
113: 		}
114: 		BindExtraColumns(table, get, proj, update, all_columns);
115: 	}
116: }
117: 
118: BoundStatement Binder::Bind(UpdateStatement &stmt) {
119: 	BoundStatement result;
120: 	unique_ptr<LogicalOperator> root;
121: 	LogicalGet *get;
122: 
123: 	// visit the table reference
124: 	auto bound_table = Bind(*stmt.table);
125: 	if (bound_table->type != TableReferenceType::BASE_TABLE) {
126: 		throw BinderException("Can only update base table!");
127: 	}
128: 	auto &table_binding = (BoundBaseTableRef &)*bound_table;
129: 	auto table = table_binding.table;
130: 
131: 	if (stmt.from_table) {
132: 		BoundCrossProductRef bound_crossproduct;
133: 		bound_crossproduct.left = move(bound_table);
134: 		bound_crossproduct.right = Bind(*stmt.from_table);
135: 		root = CreatePlan(bound_crossproduct);
136: 		get = (LogicalGet *)root->children[0].get();
137: 	} else {
138: 		root = CreatePlan(*bound_table);
139: 		get = (LogicalGet *)root.get();
140: 	}
141: 
142: 	if (!table->temporary) {
143: 		// update of persistent table: not read only!
144: 		this->read_only = false;
145: 	}
146: 	auto update = make_unique<LogicalUpdate>(table);
147: 	// bind the default values
148: 	BindDefaultValues(table->columns, update->bound_defaults);
149: 
150: 	// project any additional columns required for the condition/expressions
151: 	if (stmt.condition) {
152: 		WhereBinder binder(*this, context);
153: 		auto condition = binder.Bind(stmt.condition);
154: 
155: 		PlanSubqueries(&condition, &root);
156: 		auto filter = make_unique<LogicalFilter>(move(condition));
157: 		filter->AddChild(move(root));
158: 		root = move(filter);
159: 	}
160: 
161: 	D_ASSERT(stmt.columns.size() == stmt.expressions.size());
162: 
163: 	auto proj_index = GenerateTableIndex();
164: 	vector<unique_ptr<Expression>> projection_expressions;
165: 	for (idx_t i = 0; i < stmt.columns.size(); i++) {
166: 		auto &colname = stmt.columns[i];
167: 		auto &expr = stmt.expressions[i];
168: 		if (!table->ColumnExists(colname)) {
169: 			throw BinderException("Referenced update column %s not found in table!", colname);
170: 		}
171: 		auto &column = table->GetColumn(colname);
172: 		if (std::find(update->columns.begin(), update->columns.end(), column.oid) != update->columns.end()) {
173: 			throw BinderException("Multiple assignments to same column \"%s\"", colname);
174: 		}
175: 		update->columns.push_back(column.oid);
176: 
177: 		if (expr->type == ExpressionType::VALUE_DEFAULT) {
178: 			update->expressions.push_back(make_unique<BoundDefaultExpression>(column.type));
179: 		} else {
180: 			UpdateBinder binder(*this, context);
181: 			binder.target_type = column.type;
182: 			auto bound_expr = binder.Bind(expr);
183: 			PlanSubqueries(&bound_expr, &root);
184: 
185: 			update->expressions.push_back(make_unique<BoundColumnRefExpression>(
186: 			    bound_expr->return_type, ColumnBinding(proj_index, projection_expressions.size())));
187: 			projection_expressions.push_back(move(bound_expr));
188: 		}
189: 	}
190: 	// now create the projection
191: 	auto proj = make_unique<LogicalProjection>(proj_index, move(projection_expressions));
192: 	proj->AddChild(move(root));
193: 
194: 	// bind any extra columns necessary for CHECK constraints or indexes
195: 	BindUpdateConstraints(*table, *get, *proj, *update);
196: 
197: 	// finally add the row id column to the projection list
198: 	proj->expressions.push_back(make_unique<BoundColumnRefExpression>(
199: 	    LOGICAL_ROW_TYPE, ColumnBinding(get->table_index, get->column_ids.size())));
200: 	get->column_ids.push_back(COLUMN_IDENTIFIER_ROW_ID);
201: 
202: 	// set the projection as child of the update node and finalize the result
203: 	update->AddChild(move(proj));
204: 
205: 	result.names = {"Count"};
206: 	result.types = {LogicalType::BIGINT};
207: 	result.plan = move(update);
208: 	return result;
209: }
210: 
211: } // namespace duckdb
[end of src/planner/binder/statement/bind_update.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: