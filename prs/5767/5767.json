{
  "repo": "duckdb/duckdb",
  "pull_number": 5767,
  "instance_id": "duckdb__duckdb-5767",
  "issue_numbers": [
    "5744",
    "5744"
  ],
  "base_commit": "c9893aabda76a0b19fb22dd617090427039b7461",
  "patch": "diff --git a/extension/parquet/column_reader.cpp b/extension/parquet/column_reader.cpp\nindex 26de1d6ed27b..232e81ec63e4 100644\n--- a/extension/parquet/column_reader.cpp\n+++ b/extension/parquet/column_reader.cpp\n@@ -212,10 +212,17 @@ void ColumnReader::PreparePageV2(PageHeader &page_hdr) {\n \tauto &trans = (ThriftFileTransport &)*protocol->getTransport();\n \n \tAllocateBlock(page_hdr.uncompressed_page_size + 1);\n+\tbool uncompressed = false;\n+\tif (page_hdr.data_page_header_v2.__isset.is_compressed && !page_hdr.data_page_header_v2.is_compressed) {\n+\t\tuncompressed = true;\n+\t}\n \tif (chunk->meta_data.codec == CompressionCodec::UNCOMPRESSED) {\n \t\tif (page_hdr.compressed_page_size != page_hdr.uncompressed_page_size) {\n \t\t\tthrow std::runtime_error(\"Page size mismatch\");\n \t\t}\n+\t\tuncompressed = true;\n+\t}\n+\tif (uncompressed) {\n \t\ttrans.read((uint8_t *)block->ptr, page_hdr.compressed_page_size);\n \t\treturn;\n \t}\n",
  "test_patch": "diff --git a/data/parquet-testing/parquet_go.parquet b/data/parquet-testing/parquet_go.parquet\nnew file mode 100644\nindex 000000000000..7862f339bd78\nBinary files /dev/null and b/data/parquet-testing/parquet_go.parquet differ\ndiff --git a/test/sql/copy/parquet/parquet_go.test b/test/sql/copy/parquet/parquet_go.test\nnew file mode 100644\nindex 000000000000..3b40d86e9327\n--- /dev/null\n+++ b/test/sql/copy/parquet/parquet_go.test\n@@ -0,0 +1,17 @@\n+# name: test/sql/copy/parquet/parquet_go.test\n+# description: Issue #5744: Fail to import .parquet file created with parquet-go\n+# group: [parquet]\n+\n+require parquet\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+query II\n+SELECT * FROM 'data/parquet-testing/parquet_go.parquet'\n+----\n+John\tHello World\n+John\tHello World\n+John\tHello World\n+John\tHello World\n+John\tHello World\n",
  "problem_statement": "Fail to import .parquet file created with parquet-go\n### What happens?\n\nWhen trying to import a column which uses snappy compression, duckdb throws the error:\r\n\r\n```\r\nError: Invalid Error: Snappy decompression failure: Uncompressed data size mismatch\r\n```\r\n\r\neven though this column can be loaded by both `pandas` and `parquet-tools`.\n\n### To Reproduce\n\nI've attached the .parquet file to this issue, if you want to skip the Golang step.\r\n\r\n1. Create the parquet file using the following code:\r\n\r\n```\r\npackage main\r\n\r\nimport (\r\n[out.zip](https://github.com/duckdb/duckdb/files/10268874/out.zip)\r\n\r\n\t\"fmt\"\r\n\t\"os\"\r\n\r\n\t\"github.com/segmentio/parquet-go\"\r\n)\r\n\r\ntype RowType struct {\r\n\t// Need dict encoding for all fields\r\n\t// Snappy compression for FirstName\r\n\tFirstName string `parquet:\"FirstName,dict,snappy\"`\r\n\tData      []byte `parquet:\"Data,dict\"`\r\n}\r\n\r\nfunc main() {\r\n\t// create 5 rows, with random data & FirstName \"John\"\r\n\trows := make([]RowType, 5)\r\n\tfor i := 0; i < 5; i++ {\r\n\t\trow := RowType{\r\n\t\t\tFirstName: \"Baz\",\r\n\t\t\tData:      []byte(\"Hello World\"),\r\n\t\t}\r\n\t\trows[i] = row\r\n\t}\r\n\tfmt.Println(\"# of rows:\", len(rows))\r\n\r\n\t// Check if file exists\r\n\tname := \"test.parquet\"\r\n\tif _, err := os.Stat(name); err == nil {\r\n\t\tfmt.Println(\"File exists, deleting...\")\r\n\t\tos.Remove(name)\r\n\t}\r\n\r\n\t// Open a file for writing\r\n\tf, err := os.Create(name)\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\r\n\twtr := parquet.NewGenericWriter[RowType](f)\r\n\t_, err = wtr.Write(rows)\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tif err := wtr.Close(); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n}\r\n```\r\n\r\n2.\r\n\r\nRun the following SQL:\r\n```\r\nselect FirstName from \"wherever-you-put-the-file\";\r\n```\r\n\r\nit should give the error:\r\n```\r\nError: Invalid Error: Snappy decompression failure: Uncompressed data size mismatch\r\n```\n\n### OS:\n\nUbuntu 20.04.5 LTS\n\n### DuckDB Version:\n\nv0.6.1 919cad22e8\n\n### DuckDB Client:\n\nCLI\n\n### Full Name:\n\nVedant Roy\n\n### Affiliation:\n\nMyself\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\nFail to import .parquet file created with parquet-go\n### What happens?\n\nWhen trying to import a column which uses snappy compression, duckdb throws the error:\r\n\r\n```\r\nError: Invalid Error: Snappy decompression failure: Uncompressed data size mismatch\r\n```\r\n\r\neven though this column can be loaded by both `pandas` and `parquet-tools`.\n\n### To Reproduce\n\nI've attached the .parquet file to this issue, if you want to skip the Golang step.\r\n\r\n1. Create the parquet file using the following code:\r\n\r\n```\r\npackage main\r\n\r\nimport (\r\n[out.zip](https://github.com/duckdb/duckdb/files/10268874/out.zip)\r\n\r\n\t\"fmt\"\r\n\t\"os\"\r\n\r\n\t\"github.com/segmentio/parquet-go\"\r\n)\r\n\r\ntype RowType struct {\r\n\t// Need dict encoding for all fields\r\n\t// Snappy compression for FirstName\r\n\tFirstName string `parquet:\"FirstName,dict,snappy\"`\r\n\tData      []byte `parquet:\"Data,dict\"`\r\n}\r\n\r\nfunc main() {\r\n\t// create 5 rows, with random data & FirstName \"John\"\r\n\trows := make([]RowType, 5)\r\n\tfor i := 0; i < 5; i++ {\r\n\t\trow := RowType{\r\n\t\t\tFirstName: \"Baz\",\r\n\t\t\tData:      []byte(\"Hello World\"),\r\n\t\t}\r\n\t\trows[i] = row\r\n\t}\r\n\tfmt.Println(\"# of rows:\", len(rows))\r\n\r\n\t// Check if file exists\r\n\tname := \"test.parquet\"\r\n\tif _, err := os.Stat(name); err == nil {\r\n\t\tfmt.Println(\"File exists, deleting...\")\r\n\t\tos.Remove(name)\r\n\t}\r\n\r\n\t// Open a file for writing\r\n\tf, err := os.Create(name)\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\r\n\twtr := parquet.NewGenericWriter[RowType](f)\r\n\t_, err = wtr.Write(rows)\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tif err := wtr.Close(); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n}\r\n```\r\n\r\n2.\r\n\r\nRun the following SQL:\r\n```\r\nselect FirstName from \"wherever-you-put-the-file\";\r\n```\r\n\r\nit should give the error:\r\n```\r\nError: Invalid Error: Snappy decompression failure: Uncompressed data size mismatch\r\n```\n\n### OS:\n\nUbuntu 20.04.5 LTS\n\n### DuckDB Version:\n\nv0.6.1 919cad22e8\n\n### DuckDB Client:\n\nCLI\n\n### Full Name:\n\nVedant Roy\n\n### Affiliation:\n\nMyself\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\n",
  "hints_text": "Not sure if the file got uploaded, so attaching it again to this comment.\r\n[out.zip](https://github.com/duckdb/duckdb/files/10268886/out.zip)\r\n\nNot sure if the file got uploaded, so attaching it again to this comment.\r\n[out.zip](https://github.com/duckdb/duckdb/files/10268886/out.zip)\r\n",
  "created_at": "2022-12-22T13:38:04Z"
}