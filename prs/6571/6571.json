{
  "repo": "duckdb/duckdb",
  "pull_number": 6571,
  "instance_id": "duckdb__duckdb-6571",
  "issue_numbers": [
    "6532"
  ],
  "base_commit": "07d54d53bb7f03928abf660a900923967134788f",
  "patch": "diff --git a/tools/pythonpkg/src/array_wrapper.cpp b/tools/pythonpkg/src/array_wrapper.cpp\nindex a36fb15dbe39..c41a47ceb75d 100644\n--- a/tools/pythonpkg/src/array_wrapper.cpp\n+++ b/tools/pythonpkg/src/array_wrapper.cpp\n@@ -535,55 +535,41 @@ RawArrayWrapper::RawArrayWrapper(const LogicalType &type) : data(nullptr), type(\n \t}\n }\n \n-void RawArrayWrapper::Initialize(idx_t capacity) {\n-\tstring dtype;\n+string RawArrayWrapper::DuckDBToNumpyDtype(const LogicalType &type) {\n \tswitch (type.id()) {\n \tcase LogicalTypeId::BOOLEAN:\n-\t\tdtype = \"bool\";\n-\t\tbreak;\n+\t\treturn \"bool\";\n \tcase LogicalTypeId::TINYINT:\n-\t\tdtype = \"int8\";\n-\t\tbreak;\n+\t\treturn \"int8\";\n \tcase LogicalTypeId::SMALLINT:\n-\t\tdtype = \"int16\";\n-\t\tbreak;\n+\t\treturn \"int16\";\n \tcase LogicalTypeId::INTEGER:\n-\t\tdtype = \"int32\";\n-\t\tbreak;\n+\t\treturn \"int32\";\n \tcase LogicalTypeId::BIGINT:\n-\t\tdtype = \"int64\";\n-\t\tbreak;\n+\t\treturn \"int64\";\n \tcase LogicalTypeId::UTINYINT:\n-\t\tdtype = \"uint8\";\n-\t\tbreak;\n+\t\treturn \"uint8\";\n \tcase LogicalTypeId::USMALLINT:\n-\t\tdtype = \"uint16\";\n-\t\tbreak;\n+\t\treturn \"uint16\";\n \tcase LogicalTypeId::UINTEGER:\n-\t\tdtype = \"uint32\";\n-\t\tbreak;\n+\t\treturn \"uint32\";\n \tcase LogicalTypeId::UBIGINT:\n-\t\tdtype = \"uint64\";\n-\t\tbreak;\n+\t\treturn \"uint64\";\n \tcase LogicalTypeId::FLOAT:\n-\t\tdtype = \"float32\";\n-\t\tbreak;\n+\t\treturn \"float32\";\n \tcase LogicalTypeId::HUGEINT:\n \tcase LogicalTypeId::DOUBLE:\n \tcase LogicalTypeId::DECIMAL:\n-\t\tdtype = \"float64\";\n-\t\tbreak;\n+\t\treturn \"float64\";\n \tcase LogicalTypeId::TIMESTAMP:\n \tcase LogicalTypeId::TIMESTAMP_TZ:\n \tcase LogicalTypeId::TIMESTAMP_NS:\n \tcase LogicalTypeId::TIMESTAMP_MS:\n \tcase LogicalTypeId::TIMESTAMP_SEC:\n \tcase LogicalTypeId::DATE:\n-\t\tdtype = \"datetime64[ns]\";\n-\t\tbreak;\n+\t\treturn \"datetime64[ns]\";\n \tcase LogicalTypeId::INTERVAL:\n-\t\tdtype = \"timedelta64[ns]\";\n-\t\tbreak;\n+\t\treturn \"timedelta64[ns]\";\n \tcase LogicalTypeId::TIME:\n \tcase LogicalTypeId::TIME_TZ:\n \tcase LogicalTypeId::VARCHAR:\n@@ -593,23 +579,27 @@ void RawArrayWrapper::Initialize(idx_t capacity) {\n \tcase LogicalTypeId::MAP:\n \tcase LogicalTypeId::STRUCT:\n \tcase LogicalTypeId::UUID:\n-\t\tdtype = \"object\";\n-\t\tbreak;\n+\t\treturn \"object\";\n \tcase LogicalTypeId::ENUM: {\n \t\tauto size = EnumType::GetSize(type);\n \t\tif (size <= (idx_t)NumericLimits<int8_t>::Maximum()) {\n-\t\t\tdtype = \"int8\";\n+\t\t\treturn \"int8\";\n \t\t} else if (size <= (idx_t)NumericLimits<int16_t>::Maximum()) {\n-\t\t\tdtype = \"int16\";\n+\t\t\treturn \"int16\";\n \t\t} else if (size <= (idx_t)NumericLimits<int32_t>::Maximum()) {\n-\t\t\tdtype = \"int32\";\n+\t\t\treturn \"int32\";\n \t\t} else {\n \t\t\tthrow InternalException(\"Size not supported on ENUM types\");\n \t\t}\n-\t} break;\n+\t}\n \tdefault:\n \t\tthrow NotImplementedException(\"Unsupported type \\\"%s\\\"\", type.ToString());\n \t}\n+}\n+\n+void RawArrayWrapper::Initialize(idx_t capacity) {\n+\tstring dtype = DuckDBToNumpyDtype(type);\n+\n \tarray = py::array(py::dtype(dtype), capacity);\n \tdata = (data_ptr_t)array.mutable_data();\n }\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/array_wrapper.hpp b/tools/pythonpkg/src/include/duckdb_python/array_wrapper.hpp\nindex 0ca0c268cf51..aa2c4b3be3fa 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/array_wrapper.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/array_wrapper.hpp\n@@ -13,6 +13,7 @@\n \n namespace duckdb {\n struct RawArrayWrapper {\n+\n \texplicit RawArrayWrapper(const LogicalType &type);\n \n \tpy::array array;\n@@ -22,6 +23,7 @@ struct RawArrayWrapper {\n \tidx_t count;\n \n public:\n+\tstatic string DuckDBToNumpyDtype(const LogicalType &type);\n \tvoid Initialize(idx_t capacity);\n \tvoid Resize(idx_t new_capacity);\n \tvoid Append(idx_t current_offset, Vector &input, idx_t count);\ndiff --git a/tools/pythonpkg/src/map.cpp b/tools/pythonpkg/src/map.cpp\nindex 4f6140db5004..935289c1ee95 100644\n--- a/tools/pythonpkg/src/map.cpp\n+++ b/tools/pythonpkg/src/map.cpp\n@@ -41,6 +41,42 @@ static py::handle FunctionCall(NumpyResultConversion &conversion, vector<string>\n \treturn df;\n }\n \n+static bool ContainsNullType(const vector<LogicalType> &types) {\n+\tfor (auto &type : types) {\n+\t\tif (type.id() == LogicalTypeId::SQLNULL) {\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\treturn false;\n+}\n+\n+static void OverrideNullType(vector<LogicalType> &return_types, const vector<string> &return_names,\n+                             const vector<LogicalType> &original_types, const vector<string> &original_names) {\n+\tif (!ContainsNullType(return_types)) {\n+\t\t// Nothing to override, none of the returned types are NULL\n+\t\treturn;\n+\t}\n+\tif (return_types.size() != original_types.size()) {\n+\t\t// FIXME: we can probably infer from the names in this case\n+\t\t//  Cant infer what the type should be\n+\t\treturn;\n+\t}\n+\tfor (idx_t i = 0; i < return_types.size(); i++) {\n+\t\tauto &return_type = return_types[i];\n+\t\tauto &original_type = original_types[i];\n+\n+\t\tif (return_type != LogicalTypeId::SQLNULL) {\n+\t\t\tcontinue;\n+\t\t}\n+\t\tif (return_names[i] != original_names[i]) {\n+\t\t\tthrow InvalidInputException(\n+\t\t\t    \"Returned dataframe contains NULL type, and we could not infer the desired type\");\n+\t\t}\n+\t\t// Override the NULL with the original type\n+\t\treturn_type = original_type;\n+\t}\n+}\n+\n // we call the passed function with a zero-row data frame to infer the output columns and their names.\n // they better not change in the actual execution ^^\n unique_ptr<FunctionData> MapFunction::MapFunctionBind(ClientContext &context, TableFunctionBindInput &input,\n@@ -58,6 +94,9 @@ unique_ptr<FunctionData> MapFunction::MapFunctionBind(ClientContext &context, Ta\n \tvector<PandasColumnBindData> pandas_bind_data; // unused\n \tVectorConversion::BindPandas(DBConfig::GetConfig(context), df, pandas_bind_data, return_types, names);\n \n+\t// output types are potentially NULL, this happens for types that map to 'object' dtype\n+\tOverrideNullType(return_types, names, data.in_types, data.in_names);\n+\n \tdata.out_names = names;\n \tdata.out_types = return_types;\n \treturn std::move(data_uptr);\n",
  "test_patch": "diff --git a/tools/pythonpkg/tests/fast/test_map.py b/tools/pythonpkg/tests/fast/test_map.py\nindex e4bab4a8ca71..04866ef9160c 100644\n--- a/tools/pythonpkg/tests/fast/test_map.py\n+++ b/tools/pythonpkg/tests/fast/test_map.py\n@@ -25,7 +25,7 @@ def evil1(df):\n         # column type differs from bind\n         def evil2(df):\n             if len(df) == 0:\n-                df['col0'] = df['col0'].astype('string')\n+                df['col0'] = df['col0'].astype('int')\n             return df\n \n         # column name differs from bind\n@@ -90,6 +90,16 @@ def return_empty_df(df):\n         with pytest.raises(duckdb.InvalidInputException, match='Need a DataFrame with at least one column'):\n             testrel.map(return_empty_df).df()\n \n+    def test_map_with_object_column(self, duckdb_cursor):\n+        def return_with_no_modification(df):\n+            return df\n+\n+        # BLOB maps to 'object'\n+        # when a dataframe with 'object' column is returned, we use the content to infer the type\n+        # when the dataframe is empty, this results in NULL, which is not desirable\n+        # in this case we assume the returned type should be the same as the input type\n+        duckdb_cursor.values([b'1234']).map(return_with_no_modification).fetchall()\n+\n     def test_isse_3237(self, duckdb_cursor):\n         def process(rel):\n             def mapper(x):\n",
  "problem_statement": "UDF column type mismatch, expected [NULL], got [BLOB]\n### What happens?\n\nWhen trying to apply a `map` to a BLOB column an error is returned:\r\n```\r\nInvalidInputException: Invalid Input Error: UDF column type mismatch, expected [NULL], got [BLOB]\r\n```\n\n### To Reproduce\n\n```\r\nimport duckdb\r\n\r\ndef nop(df):\r\n    return df\r\n\r\nduckdb.values([b'1234']).map(nop)\r\n\r\n---------------------------------------------------------------------------\r\nInvalidInputException                     Traceback (most recent call last)\r\nFile /data/data/Code/orc/python/venv/lib/python3.8/site-packages/IPython/core/formatters.py:706, in PlainTextFormatter.__call__(self, obj)\r\n    699 stream = StringIO()\r\n    700 printer = pretty.RepresentationPrinter(stream, self.verbose,\r\n    701     self.max_width, self.newline,\r\n    702     max_seq_length=self.max_seq_length,\r\n    703     singleton_pprinters=self.singleton_printers,\r\n    704     type_pprinters=self.type_printers,\r\n    705     deferred_pprinters=self.deferred_printers)\r\n--> 706 printer.pretty(obj)\r\n    707 printer.flush()\r\n    708 return stream.getvalue()\r\n\r\nFile /data/data/Code/orc/python/venv/lib/python3.8/site-packages/IPython/lib/pretty.py:410, in RepresentationPrinter.pretty(self, obj)\r\n    407                         return meth(obj, self, cycle)\r\n    408                 if cls is not object \\\r\n    409                         and callable(cls.__dict__.get('__repr__')):\r\n--> 410                     return _repr_pprint(obj, self, cycle)\r\n    412     return _default_pprint(obj, self, cycle)\r\n    413 finally:\r\n\r\nFile /data/data/Code/orc/python/venv/lib/python3.8/site-packages/IPython/lib/pretty.py:778, in _repr_pprint(obj, p, cycle)\r\n    776 \"\"\"A pprint that just redirects to the normal repr function.\"\"\"\r\n    777 # Find newlines and replace them with p.break_()\r\n...\r\n--> 778 output = repr(obj)\r\n    779 lines = output.splitlines()\r\n    780 with p.group():\r\n\r\nInvalidInputException: Invalid Input Error: UDF column type mismatch, expected [NULL], got [BLOB]\r\n```\n\n### OS:\n\nlinux\n\n### DuckDB Version:\n\n0.7.1\n\n### DuckDB Client:\n\npython\n\n### Full Name:\n\nHinko Kocevar\n\n### Affiliation:\n\nESS ERIC\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\n",
  "hints_text": "I don't think that's caused by the BLOB column, the current implementation of `map` will call the UDF first with an empty dataframe during bind time.\r\nWe use the return value of this to figure out the schema of the result of the function.\r\n\r\nAfter altering the udf to print the dtypes of the dataframe, I think I know what's going on:\r\n```py\r\ndef nop(df):\r\n\tprint(df.dtypes)\r\n\treturn df\r\n\r\nduckdb.values([b'1234']).map(nop).fetchall()\r\n```\r\n```\r\ncol0    object\r\ndtype: object\r\ncol0    object\r\ndtype: object\r\ncol0    object\r\ndtype: object\r\n```\r\n\r\nHmm actually, it is a problem on our side, but I don't see a way to fix this.\r\nA little insight:\r\nWhen we create a numpy array, it goes through a switch to figure out the type:\r\n```c++\r\n\tcase LogicalTypeId::TIME:\r\n\tcase LogicalTypeId::TIME_TZ:\r\n\tcase LogicalTypeId::VARCHAR:\r\n\tcase LogicalTypeId::BIT:\r\n\tcase LogicalTypeId::BLOB:\r\n\tcase LogicalTypeId::ENUM:\r\n\tcase LogicalTypeId::LIST:\r\n\tcase LogicalTypeId::MAP:\r\n\tcase LogicalTypeId::STRUCT:\r\n\tcase LogicalTypeId::UUID:\r\n\t\ttype_width = sizeof(PyObject *);\r\n\t\tbreak;\r\n```\r\nAs you can see BLOB maps to PyObject* (becomes an 'object' column in pandas)\r\nWhen we receive a pandas object column, we have to figure out what DuckDB type it maps to, this is done by sampling the column.\r\nAt first the type starts off as NULL, and for every non-null value we find, we upgrade the type\r\nBut since we call the UDF the first time with an empty dataframe (to essentially ask you what the return type is), and you return that dataframe with an object column, the analyzer has nothing to go off of, so it returns NULL as the type.\r\n\nActually, since we know the original types, we can check if the original type was a type that maps to 'object', and also check if the analyzed type is NULL - and then override it to the original type\r\n\r\nThat might work",
  "created_at": "2023-03-04T13:26:37Z"
}