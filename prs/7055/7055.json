{
  "repo": "duckdb/duckdb",
  "pull_number": 7055,
  "instance_id": "duckdb__duckdb-7055",
  "issue_numbers": [
    "6924"
  ],
  "base_commit": "e8610c85fb4dee687813bd94b16b8d5881f5fc86",
  "patch": "diff --git a/tools/juliapkg/src/result.jl b/tools/juliapkg/src/result.jl\nindex e5f7e3e719dd..43c8eec46a54 100644\n--- a/tools/juliapkg/src/result.jl\n+++ b/tools/juliapkg/src/result.jl\n@@ -148,9 +148,9 @@ function convert_vector(\n     ::Type{SRC},\n     ::Type{DST}\n ) where {SRC, DST}\n-    array = get_array(vector, SRC)\n+    array = get_array(vector, SRC, size)\n     if !all_valid\n-        validity = get_validity(vector)\n+        validity = get_validity(vector, size)\n     end\n     for i in 1:size\n         if all_valid || isvalid(validity, i)\n@@ -175,7 +175,7 @@ function convert_vector_string(\n     raw_ptr = duckdb_vector_get_data(vector.handle)\n     ptr = Base.unsafe_convert(Ptr{duckdb_string_t}, raw_ptr)\n     if !all_valid\n-        validity = get_validity(vector)\n+        validity = get_validity(vector, size)\n     end\n     for i in 1:size\n         if all_valid || isvalid(validity, i)\n@@ -218,9 +218,9 @@ function convert_vector_list(\n         ldata.target_type\n     )\n \n-    array = get_array(vector, SRC)\n+    array = get_array(vector, SRC, size)\n     if !all_valid\n-        validity = get_validity(vector)\n+        validity = get_validity(vector, size)\n     end\n     for i in 1:size\n         if all_valid || isvalid(validity, i)\n@@ -276,7 +276,7 @@ function convert_vector_struct(\n     child_arrays = convert_struct_children(column_data, vector, size)\n \n     if !all_valid\n-        validity = get_validity(vector)\n+        validity = get_validity(vector, size)\n     end\n     for i in 1:size\n         if all_valid || isvalid(validity, i)\n@@ -305,7 +305,7 @@ function convert_vector_union(\n     child_arrays = convert_struct_children(column_data, vector, size)\n \n     if !all_valid\n-        validity = get_validity(vector)\n+        validity = get_validity(vector, size)\n     end\n     for row in 1:size\n         # For every row/record\n@@ -359,9 +359,9 @@ function convert_vector_map(\n     keys = child_arrays[1]\n     values = child_arrays[2]\n \n-    array = get_array(vector, SRC)\n+    array = get_array(vector, SRC, size)\n     if !all_valid\n-        validity = get_validity(vector)\n+        validity = get_validity(vector, size)\n     end\n     for i in 1:size\n         if all_valid || isvalid(validity, i)\ndiff --git a/tools/juliapkg/src/vector.jl b/tools/juliapkg/src/vector.jl\nindex 086104b65b84..c67472864564 100644\n--- a/tools/juliapkg/src/vector.jl\n+++ b/tools/juliapkg/src/vector.jl\n@@ -10,17 +10,18 @@ struct Vec\n     end\n end\n \n-function get_array(vector::Vec, ::Type{T})::Vector{T} where {T}\n+function get_array(vector::Vec, ::Type{T}, size = VECTOR_SIZE)::Vector{T} where {T}\n     raw_ptr = duckdb_vector_get_data(vector.handle)\n     ptr = Base.unsafe_convert(Ptr{T}, raw_ptr)\n-    return unsafe_wrap(Vector{T}, ptr, VECTOR_SIZE, own = false)\n+    return unsafe_wrap(Vector{T}, ptr, size, own = false)\n end\n \n-function get_validity(vector::Vec)::ValidityMask\n+function get_validity(vector::Vec, size = VECTOR_SIZE)::ValidityMask\n     duckdb_vector_ensure_validity_writable(vector.handle)\n     validity_ptr = duckdb_vector_get_validity(vector.handle)\n     ptr = Base.unsafe_convert(Ptr{UInt64}, validity_ptr)\n-    validity_vector = unsafe_wrap(Vector{UInt64}, ptr, VECTOR_SIZE \u00f7 BITS_PER_VALUE, own = false)\n+    size_words = div(size, BITS_PER_VALUE, RoundUp)\n+    validity_vector = unsafe_wrap(Vector{UInt64}, ptr, size_words, own = false)\n     return ValidityMask(validity_vector)\n end\n \n",
  "test_patch": "diff --git a/tools/juliapkg/test/runtests.jl b/tools/juliapkg/test/runtests.jl\nindex d6895bd41267..9adb0f95bede 100644\n--- a/tools/juliapkg/test/runtests.jl\n+++ b/tools/juliapkg/test/runtests.jl\n@@ -8,6 +8,7 @@ using UUIDs\n test_files = [\n     \"test_appender.jl\",\n     \"test_basic_queries.jl\",\n+    \"test_big_nested.jl\",\n     \"test_config.jl\",\n     \"test_connection.jl\",\n     \"test_df_scan.jl\",\ndiff --git a/tools/juliapkg/test/test_big_nested.jl b/tools/juliapkg/test/test_big_nested.jl\nnew file mode 100644\nindex 000000000000..3c8f1e1cc62a\n--- /dev/null\n+++ b/tools/juliapkg/test/test_big_nested.jl\n@@ -0,0 +1,77 @@\n+\n+@testset \"Test big list\" begin\n+    con = DBInterface.connect(DuckDB.DB)\n+\n+    DBInterface.execute(con, \"CREATE TABLE list_table (int_list INT[]);\")\n+    DBInterface.execute(con, \"INSERT INTO list_table VALUES (range(2049));\")\n+    df = DataFrame(DBInterface.execute(con, \"SELECT * FROM list_table;\"))\n+    @test length(df[1, :int_list]) == 2049\n+\n+    DBInterface.close!(con)\n+end\n+\n+@testset \"Test big bitstring\" begin\n+    con = DBInterface.connect(DuckDB.DB)\n+\n+    DBInterface.execute(con, \"CREATE TABLE bit_table (bits BIT);\")\n+    # 131073 = 64 * 2048 + 1\n+    DBInterface.execute(con, \"INSERT INTO bit_table VALUES (bitstring('1010'::BIT, 131073));\")\n+    df = DataFrame(DBInterface.execute(con, \"SELECT * FROM bit_table;\"))\n+    # Currently mapped to Julia in an odd way.\n+    # Can reenable following https://github.com/duckdb/duckdb/issues/7065\n+    # Can't use skip = true prior to Julia 1.7\n+    @static if VERSION \u2265 v\"1.7\"\n+        @test length(df[1, :bits]) == 131073 skip = true\n+    end\n+\n+    DBInterface.close!(con)\n+end\n+\n+@testset \"Test big string\" begin\n+    con = DBInterface.connect(DuckDB.DB)\n+\n+    DBInterface.execute(con, \"CREATE TABLE str_table (str VARCHAR);\")\n+    DBInterface.execute(con, \"INSERT INTO str_table VALUES (repeat('\ud83e\udd86', 1024) || '\ud83e\udebf');\")\n+    df = DataFrame(DBInterface.execute(con, \"SELECT * FROM str_table;\"))\n+    @test length(df[1, :str]) == 1025\n+\n+    DBInterface.close!(con)\n+end\n+\n+@testset \"Test big map\" begin\n+    con = DBInterface.connect(DuckDB.DB)\n+\n+    DBInterface.execute(con, \"CREATE TABLE map_table (map MAP(VARCHAR, INT));\")\n+    DBInterface.execute(\n+        con,\n+        \"INSERT INTO map_table VALUES (map_from_entries([{'k': 'billy' || num, 'v': num} for num in range(2049)]));\"\n+    )\n+    df = DataFrame(DBInterface.execute(con, \"SELECT * FROM map_table;\"))\n+    @test length(df[1, :map]) == 2049\n+\n+    DBInterface.close!(con)\n+end\n+\n+@testset \"Test big struct\" begin\n+    con = DBInterface.connect(DuckDB.DB)\n+\n+    DBInterface.execute(con, \"CREATE TABLE struct_table (stct STRUCT(a INT[], b INT[]));\")\n+    DBInterface.execute(con, \"INSERT INTO struct_table VALUES ({'a': range(1024), 'b': range(1025)});\")\n+    df = DataFrame(DBInterface.execute(con, \"SELECT * FROM struct_table;\"))\n+    s = df[1, :stct]\n+    @test length(s.a) == 1024\n+    @test length(s.b) == 1025\n+\n+    DBInterface.close!(con)\n+end\n+\n+@testset \"Test big union\" begin\n+    con = DBInterface.connect(DuckDB.DB)\n+\n+    DBInterface.execute(con, \"CREATE TABLE union_table (uni UNION(a INT[], b INT));\")\n+    DBInterface.execute(con, \"INSERT INTO union_table (uni) VALUES (union_value(a := range(2049))), (42);\")\n+    df = DataFrame(DBInterface.execute(con, \"SELECT * FROM union_table;\"))\n+    @test length(df[1, :uni]) == 2049\n+\n+    DBInterface.close!(con)\n+end\n",
  "problem_statement": "Converting result set with column with cumulative array size of >2048 (= VECTOR_SIZE) to Julia DataFrame causes bounds error \n### What happens?\r\n\r\nWhen converting a DuckDB result set to a Julia DataFrame with the Julia library, there is a bounds error that seems to be from trying to read the validity vector beyond VECTOR_SIZE bits. This happens when the summed length of a list/vector column is greater than VECTOR_SIZE = 2048. Here's the exception you might get:\r\n\r\n```\r\nERROR: LoadError: BoundsError: attempt to access 32-element Vector{UInt64} at index [33]\r\nStacktrace:\r\n  [1] getindex\r\n    @ ./essentials.jl:13 [inlined]\r\n  [2] getindex\r\n    @ ./abstractarray.jl:1297 [inlined]\r\n  [3] isvalid\r\n    @ ~/sources/duckdb/tools/juliapkg/src/validity_mask.jl:33 [inlined]\r\n  [4] convert_vector(column_data::DuckDB.ColumnConversionData, vector::DuckDB.Vec, size::UInt64, convert_func::typeof(DuckDB.nop_convert), result::Vector{Union{Missing, Int32}}, position::Int64, all_valid::Bool, #unused#::Type{Int32}, #unused#::Type{Int32})\r\n    @ DuckDB ~/sources/duckdb/tools/juliapkg/src/result.jl:156\r\n  [5] convert_vector_list(column_data::DuckDB.ColumnConversionData, vector::DuckDB.Vec, size::UInt64, convert_func::Function, result::Vector{Union{Missing, Vector{Union{Missing, Int32}}}}, position::Int64, all_valid::Bool, #unused#::Type{DuckDB.duckdb_list_entry_t}, #unused#::Type{Vector{Union{Missing, Int32}}})\r\n    @ DuckDB ~/sources/duckdb/tools/juliapkg/src/result.jl:209\r\n  [6] convert_column_loop(column_data::DuckDB.ColumnConversionData, convert_func::Function, #unused#::Type{DuckDB.duckdb_list_entry_t}, #unused#::Type{Vector{Union{Missing, Int32}}}, convert_vector_func::typeof(DuckDB.convert_vector_list))\r\n    @ DuckDB ~/sources/duckdb/tools/juliapkg/src/result.jl:402\r\n  [7] convert_column(column_data::DuckDB.ColumnConversionData)\r\n    @ DuckDB ~/sources/duckdb/tools/juliapkg/src/result.jl:553\r\n  [8] toDataFrame(q::DuckDB.QueryResult)\r\n    @ DuckDB ~/sources/duckdb/tools/juliapkg/src/result.jl:579\r\n  [9] show\r\n    @ ~/sources/duckdb/tools/juliapkg/src/result.jl:845 [inlined]\r\n [10] print(io::Base.TTY, x::DuckDB.QueryResult)\r\n    @ Base ./strings/io.jl:35\r\n [11] print(::Base.TTY, ::DuckDB.QueryResult, ::String)\r\n    @ Base ./strings/io.jl:46\r\n [12] println(io::Base.TTY, xs::DuckDB.QueryResult)\r\n    @ Base ./strings/io.jl:75\r\n [13] println(xs::DuckDB.QueryResult)\r\n    @ Base ./coreio.jl:4\r\n...\r\n```\r\n\r\nI took a quick look but couldn't really figure it out. I tried seeing if I could modify `get_validity` to read the validity vector beyond 2048, but this caused a segmentation fault. Is the rest of the list in another chunk somewhere? I see one \"list\" and one \"child list\". Are there more children hiding somewhere with the rest of the entries?\r\n\r\nI guess this might be rather a quick fix for someone else, but I've dug into it a little bit so I would also happy to receive some direction to put together a PR myself in case this would help.\r\n\r\n### To Reproduce\r\n\r\nMain reproducing script:\r\n\r\n```\r\nusing DuckDB\r\nusing DBInterface: connect, execute\r\n\r\n\r\nfunction main()\r\n    con = connect(DuckDB.DB, \":memory:\")\r\n    execute(con, \"CREATE TABLE list_table (int_list INT[]);\")\r\n    execute(con, \"INSERT INTO list_table VALUES (range(2049));\")\r\n    df = execute(con, \"SELECT * FROM list_table;\")\r\n    println(df)\r\nend\r\n\r\nmain()\r\n```\r\n\r\nShowing it is the sum of all lists:\r\n\r\n```\r\nusing DuckDB\r\nusing DBInterface: connect, execute\r\n\r\n\r\nfunction main()\r\n    # This causes and error!\r\n    con = connect(DuckDB.DB, \":memory:\")\r\n    df = execute(con, \"SELECT * FROM range(2049)\")\r\n    println(df)\r\n\r\n    # This is fine\r\n    execute(con, \"CREATE TABLE list_table (int_list INT[]);\")\r\n    execute(con, \"INSERT INTO list_table VALUES (range(1024));\")\r\n    execute(con, \"INSERT INTO list_table VALUES (range(1025));\")\r\n    df = execute(con, \"SELECT * FROM list_table LIMIT 1;\")\r\n    println(df)\r\n    df = execute(con, \"SELECT * FROM list_table LIMIT 1 OFFSET 1;\")\r\n    println(df)\r\n\r\n    # But this is not -- another error!\r\n    df = execute(con, \"SELECT * FROM list_table;\")\r\n    println(df)\r\nend\r\n\r\nmain()\r\n```\r\n\r\n### OS:\r\n\r\nLinux x64\r\n\r\n### DuckDB Version:\r\n\r\nv0.7.0 and master\r\n\r\n### DuckDB Client:\r\n\r\nJulia\r\n\r\n### Full Name:\r\n\r\nFrankie Robertson\r\n\r\n### Affiliation:\r\n\r\nUniversity of Jyv\u00e4skyl\u00e4\r\n\r\n### Have you tried this on the latest `master` branch?\r\n\r\n- [X] I agree\r\n\r\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\r\n\r\n- [X] I agree\n",
  "hints_text": "All columns in duckdb are Vectors, but for some - like LIST - there is another level to this.\nSince LISTs need to be aware of the bounds of every list entry, its primary data is occupied by `list_entry_t`s. This is a small struct containing an offset and a length.\nNext to this data a LIST Vector stores a child Vector - this contains the underlying data of the list. And the offsets in the `list_entry_t` refer to this child Vector.",
  "created_at": "2023-04-12T15:45:56Z"
}