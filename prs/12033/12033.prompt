You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes.
In the patch file, please make sure to include the line numbers and a blank line at the end so it can be applied using git apply.

<issue>
Escaping string double quote in JSON Path Not Working
### What happens?

I’m encountering an issue with DuckDB when trying to extract a key from a JSON object using the json_extract function. The key contains special characters, specifically the string quote (") and the square bracket ([),
As per the DuckDB documentation, I am using double quotes in the JSON path (e.g., $.<key>) to escape the special characters. However, my key itself contains a double quote, which is causing the issue. The query fails with a JSON path error. I’ve tried escaping the double quote in the key with a backslash (\), but it doesn’t seem to work
Any help or guidance on how to correctly escape special characters in JSON paths, especially double quotes within the key, or a potential fix for this issue would be greatly appreciated. Thank you!

### To Reproduce

Here’s an example of the query that’s causing the problem:
```sql
select json_extract_string(json('{"j[so]n_\"key": 67}'), '$."j[so]n_\"key"');
```
or 
```sql
select json('{"j[so]n_\"key": 67}')->>'$."j[so]n_\"key"';
```
gives error
```
Binder Error: JSON path error near 'key"'
```

### OS:

Ubuntu 20.04.5 LTS

### DuckDB Version:

0.10.2

### DuckDB Client:

python

### Full Name:

Sam

### Affiliation:

Freelancing

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a stable release

### Did you include all relevant data sets for reproducing the issue?

Yes

### Did you include all code required to reproduce the issue?

- [X] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [X] Yes, I have

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <picture>
3:     <source media="(prefers-color-scheme: light)" srcset="logo/DuckDB_Logo-horizontal.svg">
4:     <source media="(prefers-color-scheme: dark)" srcset="logo/DuckDB_Logo-horizontal-dark-mode.svg">
5:     <img alt="DuckDB logo" src="logo/DuckDB_Logo-horizontal.svg" height="100">
6:   </picture>
7: </div>
8: <br>
9: 
10: <p align="center">
11:   <a href="https://github.com/duckdb/duckdb/actions"><img src="https://github.com/duckdb/duckdb/actions/workflows/Main.yml/badge.svg?branch=main" alt="Github Actions Badge"></a>
12:   <a href="https://discord.gg/tcvwpjfnZx"><img src="https://shields.io/discord/909674491309850675" alt="discord" /></a>
13:   <a href="https://github.com/duckdb/duckdb/releases/"><img src="https://img.shields.io/github/v/release/duckdb/duckdb?color=brightgreen&display_name=tag&logo=duckdb&logoColor=white" alt="Latest Release"></a>
14: </p>
15: 
16: ## DuckDB
17: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable, portable, and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on using DuckDB, please refer to the [DuckDB documentation](https://duckdb.org/docs/).
18: 
19: ## Installation
20: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
21: 
22: ## Data Import
23: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
24: 
25: ```sql
26: SELECT * FROM 'myfile.csv';
27: SELECT * FROM 'myfile.parquet';
28: ```
29: 
30: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
31: 
32: ## SQL Reference
33: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
34: 
35: ## Development
36: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run `BUILD_BENCHMARK=1 BUILD_TPCH=1 make` and then perform several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`. The details of benchmarks are in our [Benchmark Guide](benchmark/README.md).
37: 
38: Please also refer to our [Build Guide](https://duckdb.org/dev/building) and [Contribution Guide](CONTRIBUTING.md).
39: 
40: ## Support
41: See the [Support Options](https://duckdblabs.com/support/) page.
[end of README.md]
[start of extension/json/json_common.cpp]
1: #include "json_common.hpp"
2: #include "duckdb/common/exception/binder_exception.hpp"
3: 
4: namespace duckdb {
5: 
6: using JSONPathType = JSONCommon::JSONPathType;
7: 
8: string JSONCommon::ValToString(yyjson_val *val, idx_t max_len) {
9: 	JSONAllocator json_allocator(Allocator::DefaultAllocator());
10: 	idx_t len;
11: 	auto data = JSONCommon::WriteVal<yyjson_val>(val, json_allocator.GetYYAlc(), len);
12: 	if (max_len < len) {
13: 		return string(data, max_len) + "...";
14: 	} else {
15: 		return string(data, len);
16: 	}
17: }
18: 
19: void JSONCommon::ThrowValFormatError(string error_string, yyjson_val *val) {
20: 	error_string = StringUtil::Format(error_string, JSONCommon::ValToString(val));
21: 	throw InvalidInputException(error_string);
22: }
23: 
24: string ThrowPathError(const char *ptr, const char *end, const bool binder) {
25: 	ptr--;
26: 	auto msg = StringUtil::Format("JSON path error near '%s'", string(ptr, end - ptr));
27: 	if (binder) {
28: 		throw BinderException(msg);
29: 	} else {
30: 		throw InvalidInputException(msg);
31: 	}
32: }
33: 
34: static inline idx_t ReadString(const char *ptr, const char *const end, const bool escaped) {
35: 	const char *const before = ptr;
36: 	if (escaped) {
37: 		while (ptr != end) {
38: 			if (*ptr == '"') {
39: 				break;
40: 			}
41: 			ptr++;
42: 		}
43: 		return ptr == end ? 0 : ptr - before;
44: 	} else {
45: 		while (ptr != end) {
46: 			if (*ptr == '.' || *ptr == '[') {
47: 				break;
48: 			}
49: 			ptr++;
50: 		}
51: 		return ptr - before;
52: 	}
53: }
54: 
55: static inline idx_t ReadInteger(const char *ptr, const char *const end, idx_t &idx) {
56: 	static constexpr auto IDX_T_SAFE_DIG = 19;
57: 	static constexpr auto IDX_T_MAX = ((idx_t)(~(idx_t)0));
58: 
59: 	const char *const before = ptr;
60: 	idx = 0;
61: 	for (idx_t i = 0; i < IDX_T_SAFE_DIG; i++) {
62: 		if (ptr == end) {
63: 			// No closing ']'
64: 			return 0;
65: 		}
66: 		if (*ptr == ']') {
67: 			break;
68: 		}
69: 		uint8_t add = (uint8_t)(*ptr - '0');
70: 		if (add <= 9) {
71: 			idx = add + idx * 10;
72: 		} else {
73: 			// Not a digit
74: 			return 0;
75: 		}
76: 		ptr++;
77: 	}
78: 	// Invalid if overflow
79: 	return idx >= (idx_t)IDX_T_MAX ? 0 : ptr - before;
80: }
81: 
82: static inline bool ReadKey(const char *&ptr, const char *const end, const char *&key_ptr, idx_t &key_len) {
83: 	D_ASSERT(ptr != end);
84: 	if (*ptr == '*') { // Wildcard
85: 		ptr++;
86: 		key_len = DConstants::INVALID_INDEX;
87: 		return true;
88: 	}
89: 	bool escaped = false;
90: 	if (*ptr == '"') {
91: 		ptr++; // Skip past opening '"'
92: 		escaped = true;
93: 	}
94: 	key_ptr = ptr;
95: 	key_len = ReadString(ptr, end, escaped);
96: 	if (key_len == 0) {
97: 		return false;
98: 	}
99: 	ptr += key_len;
100: 	if (escaped) {
101: 		ptr++; // Skip past closing '"'
102: 	}
103: 	return true;
104: }
105: 
106: static inline bool ReadArrayIndex(const char *&ptr, const char *const end, idx_t &array_index, bool &from_back) {
107: 	D_ASSERT(ptr != end);
108: 	from_back = false;
109: 	if (*ptr == '*') { // Wildcard
110: 		ptr++;
111: 		if (ptr == end || *ptr != ']') {
112: 			return false;
113: 		}
114: 		array_index = DConstants::INVALID_INDEX;
115: 	} else {
116: 		if (*ptr == '#') { // SQLite syntax to index from back of array
117: 			ptr++;         // Skip over '#'
118: 			if (ptr == end) {
119: 				return false;
120: 			}
121: 			if (*ptr == ']') {
122: 				// [#] always returns NULL in SQLite, so we return an array index that will do the same
123: 				array_index = NumericLimits<uint32_t>::Maximum();
124: 				ptr++;
125: 				return true;
126: 			}
127: 			if (*ptr != '-') {
128: 				return false;
129: 			}
130: 			from_back = true;
131: 		}
132: 		if (*ptr == '-') {
133: 			ptr++; // Skip over '-'
134: 			from_back = true;
135: 		}
136: 		auto idx_len = ReadInteger(ptr, end, array_index);
137: 		if (idx_len == 0) {
138: 			return false;
139: 		}
140: 		ptr += idx_len;
141: 	}
142: 	ptr++; // Skip past closing ']'
143: 	return true;
144: }
145: 
146: JSONPathType JSONCommon::ValidatePath(const char *ptr, const idx_t &len, const bool binder) {
147: 	D_ASSERT(len >= 1 && *ptr == '$');
148: 	JSONPathType path_type = JSONPathType::REGULAR;
149: 	const char *const end = ptr + len;
150: 	ptr++; // Skip past '$'
151: 	while (ptr != end) {
152: 		const auto &c = *ptr++;
153: 		if (ptr == end) {
154: 			ThrowPathError(ptr, end, binder);
155: 		}
156: 		switch (c) {
157: 		case '.': { // Object field
158: 			const char *key_ptr;
159: 			idx_t key_len;
160: 			if (!ReadKey(ptr, end, key_ptr, key_len)) {
161: 				ThrowPathError(ptr, end, binder);
162: 			}
163: 			if (key_len == DConstants::INVALID_INDEX) {
164: 				path_type = JSONPathType::WILDCARD;
165: 			}
166: 			break;
167: 		}
168: 		case '[': { // Array index
169: 			idx_t array_index;
170: 			bool from_back;
171: 			if (!ReadArrayIndex(ptr, end, array_index, from_back)) {
172: 				ThrowPathError(ptr, end, binder);
173: 			}
174: 			if (array_index == DConstants::INVALID_INDEX) {
175: 				path_type = JSONPathType::WILDCARD;
176: 			}
177: 			break;
178: 		}
179: 		default:
180: 			ThrowPathError(ptr, end, binder);
181: 		}
182: 	}
183: 	return path_type;
184: }
185: 
186: yyjson_val *JSONCommon::GetPath(yyjson_val *val, const char *ptr, const idx_t &len) {
187: 	// Path has been validated at this point
188: 	const char *const end = ptr + len;
189: 	ptr++; // Skip past '$'
190: 	while (val != nullptr && ptr != end) {
191: 		const auto &c = *ptr++;
192: 		D_ASSERT(ptr != end);
193: 		switch (c) {
194: 		case '.': { // Object field
195: 			if (!unsafe_yyjson_is_obj(val)) {
196: 				return nullptr;
197: 			}
198: 			const char *key_ptr;
199: 			idx_t key_len;
200: #ifdef DEBUG
201: 			bool success =
202: #endif
203: 			    ReadKey(ptr, end, key_ptr, key_len);
204: #ifdef DEBUG
205: 			D_ASSERT(success);
206: #endif
207: 			val = yyjson_obj_getn(val, key_ptr, key_len);
208: 			break;
209: 		}
210: 		case '[': { // Array index
211: 			if (!unsafe_yyjson_is_arr(val)) {
212: 				return nullptr;
213: 			}
214: 			idx_t array_index;
215: 			bool from_back;
216: #ifdef DEBUG
217: 			bool success =
218: #endif
219: 			    ReadArrayIndex(ptr, end, array_index, from_back);
220: #ifdef DEBUG
221: 			D_ASSERT(success);
222: #endif
223: 			if (from_back && array_index != 0) {
224: 				array_index = unsafe_yyjson_get_len(val) - array_index;
225: 			}
226: 			val = yyjson_arr_get(val, array_index);
227: 			break;
228: 		}
229: 		default: // LCOV_EXCL_START
230: 			throw InternalException(
231: 			    "Invalid JSON Path encountered in JSONCommon::GetPath, call JSONCommon::ValidatePath first!");
232: 		} // LCOV_EXCL_STOP
233: 	}
234: 	return val;
235: }
236: 
237: void GetWildcardPathInternal(yyjson_val *val, const char *ptr, const char *const end, vector<yyjson_val *> &vals) {
238: 	while (val != nullptr && ptr != end) {
239: 		const auto &c = *ptr++;
240: 		D_ASSERT(ptr != end);
241: 		switch (c) {
242: 		case '.': { // Object field
243: 			if (!unsafe_yyjson_is_obj(val)) {
244: 				return;
245: 			}
246: 			const char *key_ptr;
247: 			idx_t key_len;
248: #ifdef DEBUG
249: 			bool success =
250: #endif
251: 			    ReadKey(ptr, end, key_ptr, key_len);
252: #ifdef DEBUG
253: 			D_ASSERT(success);
254: #endif
255: 			if (key_len == DConstants::INVALID_INDEX) { // Wildcard
256: 				size_t idx, max;
257: 				yyjson_val *key, *obj_val;
258: 				yyjson_obj_foreach(val, idx, max, key, obj_val) {
259: 					GetWildcardPathInternal(obj_val, ptr, end, vals);
260: 				}
261: 				return;
262: 			}
263: 			val = yyjson_obj_getn(val, key_ptr, key_len);
264: 			break;
265: 		}
266: 		case '[': { // Array index
267: 			if (!unsafe_yyjson_is_arr(val)) {
268: 				return;
269: 			}
270: 			idx_t array_index;
271: 			bool from_back;
272: #ifdef DEBUG
273: 			bool success =
274: #endif
275: 			    ReadArrayIndex(ptr, end, array_index, from_back);
276: #ifdef DEBUG
277: 			D_ASSERT(success);
278: #endif
279: 
280: 			if (array_index == DConstants::INVALID_INDEX) { // Wildcard
281: 				size_t idx, max;
282: 				yyjson_val *arr_val;
283: 				yyjson_arr_foreach(val, idx, max, arr_val) {
284: 					GetWildcardPathInternal(arr_val, ptr, end, vals);
285: 				}
286: 				return;
287: 			}
288: 			if (from_back && array_index != 0) {
289: 				array_index = unsafe_yyjson_get_len(val) - array_index;
290: 			}
291: 			val = yyjson_arr_get(val, array_index);
292: 			break;
293: 		}
294: 		default: // LCOV_EXCL_START
295: 			throw InternalException(
296: 			    "Invalid JSON Path encountered in GetWildcardPathInternal, call JSONCommon::ValidatePath first!");
297: 		} // LCOV_EXCL_STOP
298: 	}
299: 	if (val != nullptr) {
300: 		vals.emplace_back(val);
301: 	}
302: }
303: 
304: void JSONCommon::GetWildcardPath(yyjson_val *val, const char *ptr, const idx_t &len, vector<yyjson_val *> &vals) {
305: 	// Path has been validated at this point
306: 	const char *const end = ptr + len;
307: 	ptr++; // Skip past '$'
308: 	GetWildcardPathInternal(val, ptr, end, vals);
309: }
310: 
311: } // namespace duckdb
[end of extension/json/json_common.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: