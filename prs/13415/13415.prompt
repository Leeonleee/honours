You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes.
In the patch file, please make sure to include the line numbers and a blank line at the end so it can be applied using git apply.

<issue>
Fields for indexes are not present anywhere  in metadata/information schema
### What happens?

When querying `duckdb_indexes()` the fields belonging to the index are not present.

According to this link: https://discord.com/channels/909674491309850675/921073327009853451/1273234124177408051
The fields should be present under `expressions` but is not.



### To Reproduce

```
create table test_index (id integer primary key, name varchar, age tinyint, class int);

CREATE UNIQUE INDEX test_idx ON test_index (name, age, class);

select * from duckdb_indexes() WHERE table_name ='test_index' ;
```

### OS:

MacOS Sonoma

### DuckDB Version:

v1.0.0 1f98600c2c

### DuckDB Client:

Command Line

### Full Name:

Yuv

### Affiliation:

N/A

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a stable release

### Did you include all relevant data sets for reproducing the issue?

Yes

### Did you include all code required to reproduce the issue?

- [X] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [X] Yes, I have

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <picture>
3:     <source media="(prefers-color-scheme: light)" srcset="logo/DuckDB_Logo-horizontal.svg">
4:     <source media="(prefers-color-scheme: dark)" srcset="logo/DuckDB_Logo-horizontal-dark-mode.svg">
5:     <img alt="DuckDB logo" src="logo/DuckDB_Logo-horizontal.svg" height="100">
6:   </picture>
7: </div>
8: <br>
9: 
10: <p align="center">
11:   <a href="https://github.com/duckdb/duckdb/actions"><img src="https://github.com/duckdb/duckdb/actions/workflows/Main.yml/badge.svg?branch=main" alt="Github Actions Badge"></a>
12:   <a href="https://discord.gg/tcvwpjfnZx"><img src="https://shields.io/discord/909674491309850675" alt="discord" /></a>
13:   <a href="https://github.com/duckdb/duckdb/releases/"><img src="https://img.shields.io/github/v/release/duckdb/duckdb?color=brightgreen&display_name=tag&logo=duckdb&logoColor=white" alt="Latest Release"></a>
14: </p>
15: 
16: ## DuckDB
17: 
18: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable, portable, and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs, maps), and [several extensions designed to make SQL easier to use](https://duckdb.org/docs/guides/sql_features/friendly_sql).
19: 
20: DuckDB is available as a [standalone CLI application](https://duckdb.org/docs/api/cli/overview) and has clients for [Python](https://duckdb.org/docs/api/python/overview), [R](https://duckdb.org/docs/api/r), [Java](https://duckdb.org/docs/api/java), [Wasm](https://duckdb.org/docs/api/wasm/overview), etc., with deep integrations with packages such as [pandas](https://duckdb.org/docs/guides/python/sql_on_pandas) and [dplyr](https://duckdblabs.github.io/duckplyr/).
21: 
22: For more information on using DuckDB, please refer to the [DuckDB documentation](https://duckdb.org/docs/).
23: 
24: ## Installation
25: 
26: If you want to install DuckDB, please see [our installation page](https://www.duckdb.org/docs/installation) for instructions.
27: 
28: ## Data Import
29: 
30: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
31: 
32: ```sql
33: SELECT * FROM 'myfile.csv';
34: SELECT * FROM 'myfile.parquet';
35: ```
36: 
37: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
38: 
39: ## SQL Reference
40: 
41: The documentation contains a [SQL introduction and reference](https://duckdb.org/docs/sql/introduction).
42: 
43: ## Development
44: 
45: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run `BUILD_BENCHMARK=1 BUILD_TPCH=1 make` and then perform several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`. The details of benchmarks are in our [Benchmark Guide](benchmark/README.md).
46: 
47: Please also refer to our [Build Guide](https://duckdb.org/dev/building) and [Contribution Guide](CONTRIBUTING.md).
48: 
49: ## Support
50: 
51: See the [Support Options](https://duckdblabs.com/support/) page.
[end of README.md]
[start of src/function/table/system/duckdb_indexes.cpp]
1: #include "duckdb/catalog/catalog.hpp"
2: #include "duckdb/catalog/catalog_entry/index_catalog_entry.hpp"
3: #include "duckdb/catalog/catalog_entry/schema_catalog_entry.hpp"
4: #include "duckdb/catalog/catalog_entry/table_catalog_entry.hpp"
5: #include "duckdb/common/exception.hpp"
6: #include "duckdb/function/table/system_functions.hpp"
7: #include "duckdb/main/client_data.hpp"
8: 
9: namespace duckdb {
10: 
11: struct DuckDBIndexesData : public GlobalTableFunctionState {
12: 	DuckDBIndexesData() : offset(0) {
13: 	}
14: 
15: 	vector<reference<CatalogEntry>> entries;
16: 	idx_t offset;
17: };
18: 
19: static unique_ptr<FunctionData> DuckDBIndexesBind(ClientContext &context, TableFunctionBindInput &input,
20:                                                   vector<LogicalType> &return_types, vector<string> &names) {
21: 	names.emplace_back("database_name");
22: 	return_types.emplace_back(LogicalType::VARCHAR);
23: 
24: 	names.emplace_back("database_oid");
25: 	return_types.emplace_back(LogicalType::BIGINT);
26: 
27: 	names.emplace_back("schema_name");
28: 	return_types.emplace_back(LogicalType::VARCHAR);
29: 
30: 	names.emplace_back("schema_oid");
31: 	return_types.emplace_back(LogicalType::BIGINT);
32: 
33: 	names.emplace_back("index_name");
34: 	return_types.emplace_back(LogicalType::VARCHAR);
35: 
36: 	names.emplace_back("index_oid");
37: 	return_types.emplace_back(LogicalType::BIGINT);
38: 
39: 	names.emplace_back("table_name");
40: 	return_types.emplace_back(LogicalType::VARCHAR);
41: 
42: 	names.emplace_back("table_oid");
43: 	return_types.emplace_back(LogicalType::BIGINT);
44: 
45: 	names.emplace_back("comment");
46: 	return_types.emplace_back(LogicalType::VARCHAR);
47: 
48: 	names.emplace_back("tags");
49: 	return_types.emplace_back(LogicalType::MAP(LogicalType::VARCHAR, LogicalType::VARCHAR));
50: 
51: 	names.emplace_back("is_unique");
52: 	return_types.emplace_back(LogicalType::BOOLEAN);
53: 
54: 	names.emplace_back("is_primary");
55: 	return_types.emplace_back(LogicalType::BOOLEAN);
56: 
57: 	names.emplace_back("expressions");
58: 	return_types.emplace_back(LogicalType::VARCHAR);
59: 
60: 	names.emplace_back("sql");
61: 	return_types.emplace_back(LogicalType::VARCHAR);
62: 
63: 	return nullptr;
64: }
65: 
66: unique_ptr<GlobalTableFunctionState> DuckDBIndexesInit(ClientContext &context, TableFunctionInitInput &input) {
67: 	auto result = make_uniq<DuckDBIndexesData>();
68: 
69: 	// scan all the schemas for tables and collect them
70: 	auto schemas = Catalog::GetAllSchemas(context);
71: 	for (auto &schema : schemas) {
72: 		schema.get().Scan(context, CatalogType::INDEX_ENTRY,
73: 		                  [&](CatalogEntry &entry) { result->entries.push_back(entry); });
74: 	};
75: 	return std::move(result);
76: }
77: 
78: void DuckDBIndexesFunction(ClientContext &context, TableFunctionInput &data_p, DataChunk &output) {
79: 	auto &data = data_p.global_state->Cast<DuckDBIndexesData>();
80: 	if (data.offset >= data.entries.size()) {
81: 		// finished returning values
82: 		return;
83: 	}
84: 	// start returning values
85: 	// either fill up the chunk or return all the remaining columns
86: 	idx_t count = 0;
87: 	while (data.offset < data.entries.size() && count < STANDARD_VECTOR_SIZE) {
88: 		auto &entry = data.entries[data.offset++].get();
89: 
90: 		auto &index = entry.Cast<IndexCatalogEntry>();
91: 		// return values:
92: 
93: 		idx_t col = 0;
94: 		// database_name, VARCHAR
95: 		output.SetValue(col++, count, index.catalog.GetName());
96: 		// database_oid, BIGINT
97: 		output.SetValue(col++, count, Value::BIGINT(NumericCast<int64_t>(index.catalog.GetOid())));
98: 		// schema_name, VARCHAR
99: 		output.SetValue(col++, count, Value(index.schema.name));
100: 		// schema_oid, BIGINT
101: 		output.SetValue(col++, count, Value::BIGINT(NumericCast<int64_t>(index.schema.oid)));
102: 		// index_name, VARCHAR
103: 		output.SetValue(col++, count, Value(index.name));
104: 		// index_oid, BIGINT
105: 		output.SetValue(col++, count, Value::BIGINT(NumericCast<int64_t>(index.oid)));
106: 		// find the table in the catalog
107: 		auto &table_entry =
108: 		    index.schema.catalog.GetEntry<TableCatalogEntry>(context, index.GetSchemaName(), index.GetTableName());
109: 		// table_name, VARCHAR
110: 		output.SetValue(col++, count, Value(table_entry.name));
111: 		// table_oid, BIGINT
112: 		output.SetValue(col++, count, Value::BIGINT(NumericCast<int64_t>(table_entry.oid)));
113: 		// comment, VARCHAR
114: 		output.SetValue(col++, count, Value(index.comment));
115: 		// tags, MAP
116: 		output.SetValue(col++, count, Value::MAP(index.tags));
117: 		// is_unique, BOOLEAN
118: 		output.SetValue(col++, count, Value::BOOLEAN(index.IsUnique()));
119: 		// is_primary, BOOLEAN
120: 		output.SetValue(col++, count, Value::BOOLEAN(index.IsPrimary()));
121: 		// expressions, VARCHAR
122: 		output.SetValue(col++, count, Value());
123: 		// sql, VARCHAR
124: 		auto sql = index.ToSQL();
125: 		output.SetValue(col++, count, sql.empty() ? Value() : Value(std::move(sql)));
126: 
127: 		count++;
128: 	}
129: 	output.SetCardinality(count);
130: }
131: 
132: void DuckDBIndexesFun::RegisterFunction(BuiltinFunctions &set) {
133: 	set.AddFunction(TableFunction("duckdb_indexes", {}, DuckDBIndexesFunction, DuckDBIndexesBind, DuckDBIndexesInit));
134: }
135: 
136: } // namespace duckdb
[end of src/function/table/system/duckdb_indexes.cpp]
[start of src/include/duckdb/parser/parsed_data/create_index_info.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/parser/parsed_data/create_index_info.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/case_insensitive_map.hpp"
12: #include "duckdb/common/enums/index_constraint_type.hpp"
13: #include "duckdb/common/types/value.hpp"
14: #include "duckdb/common/vector.hpp"
15: #include "duckdb/parser/parsed_data/create_info.hpp"
16: #include "duckdb/parser/parsed_expression.hpp"
17: 
18: namespace duckdb {
19: 
20: struct CreateIndexInfo : public CreateInfo {
21: 	CreateIndexInfo();
22: 	CreateIndexInfo(const CreateIndexInfo &info);
23: 
24: 	//! The table name of the underlying table
25: 	string table;
26: 	//! The name of the index
27: 	string index_name;
28: 
29: 	//! Options values (WITH ...)
30: 	case_insensitive_map_t<Value> options;
31: 
32: 	//! The index type (ART, B+-tree, Skip-List, ...)
33: 	string index_type;
34: 	//! The index constraint type
35: 	IndexConstraintType constraint_type;
36: 	//! The column ids of the indexed table
37: 	vector<column_t> column_ids;
38: 	//! The set of expressions to index by
39: 	vector<unique_ptr<ParsedExpression>> expressions;
40: 	vector<unique_ptr<ParsedExpression>> parsed_expressions;
41: 
42: 	//! The types of the logical columns (necessary for scanning the table during CREATE INDEX)
43: 	vector<LogicalType> scan_types;
44: 	//! The names of the logical columns (necessary for scanning the table during CREATE INDEX)
45: 	vector<string> names;
46: 
47: public:
48: 	DUCKDB_API unique_ptr<CreateInfo> Copy() const override;
49: 
50: 	string ToString() const override;
51: 	void Serialize(Serializer &serializer) const override;
52: 	static unique_ptr<CreateInfo> Deserialize(Deserializer &deserializer);
53: };
54: 
55: } // namespace duckdb
[end of src/include/duckdb/parser/parsed_data/create_index_info.hpp]
[start of src/parser/parsed_data/create_index_info.cpp]
1: #include "duckdb/parser/parsed_data/create_index_info.hpp"
2: #include "duckdb/parser/parsed_expression_iterator.hpp"
3: #include "duckdb/parser/expression/columnref_expression.hpp"
4: 
5: namespace duckdb {
6: 
7: CreateIndexInfo::CreateIndexInfo() : CreateInfo(CatalogType::INDEX_ENTRY) {
8: }
9: 
10: CreateIndexInfo::CreateIndexInfo(const duckdb::CreateIndexInfo &info)
11:     : CreateInfo(CatalogType::INDEX_ENTRY), table(info.table), index_name(info.index_name), options(info.options),
12:       index_type(info.index_type), constraint_type(info.constraint_type), column_ids(info.column_ids),
13:       scan_types(info.scan_types), names(info.names) {
14: }
15: 
16: static void RemoveTableQualificationRecursive(unique_ptr<ParsedExpression> &expr, const string &table_name) {
17: 	if (expr->GetExpressionType() == ExpressionType::COLUMN_REF) {
18: 		auto &col_ref = expr->Cast<ColumnRefExpression>();
19: 		auto &col_names = col_ref.column_names;
20: 		if (col_ref.IsQualified() && col_ref.GetTableName() == table_name) {
21: 			col_names.erase(col_names.begin());
22: 		}
23: 	} else {
24: 		ParsedExpressionIterator::EnumerateChildren(*expr, [&table_name](unique_ptr<ParsedExpression> &child) {
25: 			RemoveTableQualificationRecursive(child, table_name);
26: 		});
27: 	}
28: }
29: 
30: string CreateIndexInfo::ToString() const {
31: 	string result;
32: 
33: 	result += "CREATE";
34: 	D_ASSERT(constraint_type == IndexConstraintType::UNIQUE || constraint_type == IndexConstraintType::NONE);
35: 	if (constraint_type == IndexConstraintType::UNIQUE) {
36: 		result += " UNIQUE";
37: 	}
38: 	result += " INDEX ";
39: 	if (on_conflict == OnCreateConflict::IGNORE_ON_CONFLICT) {
40: 		result += "IF NOT EXISTS ";
41: 	}
42: 	result += KeywordHelper::WriteOptionallyQuoted(index_name);
43: 	result += " ON ";
44: 	result += QualifierToString(temporary ? "" : catalog, schema, table);
45: 	if (index_type != "ART") {
46: 		result += " USING ";
47: 		result += KeywordHelper::WriteOptionallyQuoted(index_type);
48: 		result += " ";
49: 	}
50: 	result += "(";
51: 	for (idx_t i = 0; i < parsed_expressions.size(); i++) {
52: 		auto &expr = parsed_expressions[i];
53: 		auto copy = expr->Copy();
54: 		if (i > 0) {
55: 			result += ", ";
56: 		}
57: 		// column ref expressions are qualified with the table name
58: 		// we need to remove them to reproduce the original query
59: 		RemoveTableQualificationRecursive(copy, table);
60: 		bool add_parenthesis = true;
61: 		if (copy->type == ExpressionType::COLUMN_REF) {
62: 			auto &column_ref = copy->Cast<ColumnRefExpression>();
63: 			if (!column_ref.IsQualified()) {
64: 				// Only when column references are not qualified, i.e (col1, col2)
65: 				// then these expressions do not need to be wrapped in parenthesis
66: 				add_parenthesis = false;
67: 			}
68: 		}
69: 		if (add_parenthesis) {
70: 			result += StringUtil::Format("(%s)", copy->ToString());
71: 		} else {
72: 			result += StringUtil::Format("%s", copy->ToString());
73: 		}
74: 	}
75: 	result += ")";
76: 	if (!options.empty()) {
77: 		result += " WITH (";
78: 		idx_t i = 0;
79: 		for (auto &opt : options) {
80: 			result += StringUtil::Format("%s = %s", opt.first, opt.second.ToString());
81: 			if (i > 0) {
82: 				result += ", ";
83: 			}
84: 			i++;
85: 		}
86: 		result += " )";
87: 	}
88: 	result += ";";
89: 	return result;
90: }
91: 
92: unique_ptr<CreateInfo> CreateIndexInfo::Copy() const {
93: 
94: 	auto result = make_uniq<CreateIndexInfo>(*this);
95: 	CopyProperties(*result);
96: 
97: 	for (auto &expr : expressions) {
98: 		result->expressions.push_back(expr->Copy());
99: 	}
100: 	for (auto &expr : parsed_expressions) {
101: 		result->parsed_expressions.push_back(expr->Copy());
102: 	}
103: 
104: 	return std::move(result);
105: }
106: 
107: } // namespace duckdb
[end of src/parser/parsed_data/create_index_info.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: