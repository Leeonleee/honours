diff --git a/test/api/capi/test_capi_prepared.cpp b/test/api/capi/test_capi_prepared.cpp
index bddc23f9d919..414845108b5a 100644
--- a/test/api/capi/test_capi_prepared.cpp
+++ b/test/api/capi/test_capi_prepared.cpp
@@ -520,3 +520,20 @@ TEST_CASE("Prepared streaming result", "[capi]") {
 		duckdb_destroy_extracted(&stmts);
 	}
 }
+
+TEST_CASE("Test STRING LITERAL parameter type", "[capi]") {
+	duckdb_database db;
+	duckdb_connection conn;
+	duckdb_prepared_statement stmt;
+
+	REQUIRE(duckdb_open("", &db) == DuckDBSuccess);
+	REQUIRE(duckdb_connect(db, &conn) == DuckDBSuccess);
+
+	REQUIRE(duckdb_prepare(conn, "SELECT ?", &stmt) == DuckDBSuccess);
+	REQUIRE(duckdb_bind_varchar(stmt, 1, "a") == DuckDBSuccess);
+	REQUIRE(duckdb_param_type(stmt, 1) == DUCKDB_TYPE_STRING_LITERAL);
+	duckdb_destroy_prepare(&stmt);
+
+	duckdb_disconnect(&conn);
+	duckdb_close(&db);
+}
diff --git a/test/optimizer/column_lifetime_analyzer/summary_column_lifetime.test b/test/optimizer/column_lifetime_analyzer/summary_column_lifetime.test
new file mode 100644
index 000000000000..2bb177aca0df
--- /dev/null
+++ b/test/optimizer/column_lifetime_analyzer/summary_column_lifetime.test
@@ -0,0 +1,9 @@
+# name: test/optimizer/column_lifetime_analyzer/summary_column_lifetime.test
+# description: Test column lifetime analyzer with SUMMARY (internal issue #4138)
+# group: [column_lifetime_analyzer]
+
+statement ok
+create table data as select * from range(0,4000) tbl(col);
+
+statement ok
+SELECT * FROM summary((SELECT col FROM data ORDER BY col));
diff --git a/test/optimizer/pushdown/issue_16104.test b/test/optimizer/pushdown/issue_16104.test
new file mode 100644
index 000000000000..2a73b1daba42
--- /dev/null
+++ b/test/optimizer/pushdown/issue_16104.test
@@ -0,0 +1,15 @@
+# name: test/optimizer/pushdown/issue_16104.test
+# description: Test expressions in filter preserve the order in Push Down
+# group: [pushdown]
+
+statement ok
+PRAGMA explain_output = OPTIMIZED_ONLY;
+
+statement ok
+WITH random_data AS (
+    SELECT random() * 2 AS col_double
+    FROM generate_series(1, 100)
+)
+SELECT *
+FROM random_data
+WHERE abs(col_double) < 1 AND acos(col_double) > 0;
\ No newline at end of file
diff --git a/test/sql/alter/add_pk/test_add_pk_naming_conflict.test b/test/sql/alter/add_pk/test_add_pk_naming_conflict.test
index 1f74e6b01156..0abc0beaa49a 100644
--- a/test/sql/alter/add_pk/test_add_pk_naming_conflict.test
+++ b/test/sql/alter/add_pk/test_add_pk_naming_conflict.test
@@ -22,7 +22,7 @@ CREATE INDEX PRIMARY_tbl_i ON tbl(i);
 statement error
 ALTER TABLE tbl ADD PRIMARY KEY (i);
 ----
-<REGEX>:Catalog Error.*an index with that name already exists for this table: PRIMARY_tbl_i.*
+<REGEX>:Catalog Error.*already exists.*
 
 restart
 
@@ -32,7 +32,7 @@ PRAGMA enable_verification;
 statement error
 ALTER TABLE tbl ADD PRIMARY KEY (i);
 ----
-<REGEX>:Catalog Error.*an index with that name already exists for this table: PRIMARY_tbl_i.*
+<REGEX>:Catalog Error.*already exists.*
 
 # Let's do it the other way around now.
 
diff --git a/test/sql/copy/csv/test_sniffer_hang.test b/test/sql/copy/csv/test_sniffer_hang.test
new file mode 100644
index 000000000000..cc4e171c62d8
--- /dev/null
+++ b/test/sql/copy/csv/test_sniffer_hang.test
@@ -0,0 +1,11 @@
+# name: test/sql/copy/csv/test_sniffer_hang.test
+# description: Test csv files with hanging behavior
+# group: [csv]
+
+statement ok
+PRAGMA enable_verification
+
+statement error
+FROM read_csv('data/csv/bad_csv_file_2047.csv', sample_size = -1)
+----
+Error when sniffing file
\ No newline at end of file
diff --git a/test/sql/index/art/create_drop/test_art_create_if_exists.test b/test/sql/index/art/create_drop/test_art_create_if_exists.test
new file mode 100644
index 000000000000..01595a888dec
--- /dev/null
+++ b/test/sql/index/art/create_drop/test_art_create_if_exists.test
@@ -0,0 +1,63 @@
+# name: test/sql/index/art/create_drop/test_art_create_if_exists.test
+# description: Test ART creation with the same index already existing
+# group: [create_drop]
+
+statement ok
+PRAGMA enable_verification;
+
+statement ok
+PRAGMA immediate_transaction_mode = True;
+
+statement ok
+CREATE TABLE tbl AS SELECT range AS i FROM range(100);
+
+# Trigger write-write conflict.
+
+statement ok con1
+BEGIN;
+
+statement ok con1
+CREATE INDEX IF NOT EXISTS my_idx ON tbl(i);
+
+statement ok con2
+BEGIN;
+
+statement error con2
+CREATE INDEX IF NOT EXISTS my_idx ON tbl(i);
+----
+<REGEX>:TransactionContext Error.*write-write.*
+
+statement ok con1
+COMMIT;
+
+statement ok con2
+COMMIT;
+
+query I
+SELECT COUNT(*) FROM duckdb_indexes;
+----
+1
+
+statement ok
+DROP INDEX my_idx;
+
+# Trigger early-out.
+
+statement ok
+CREATE INDEX IF NOT EXISTS my_idx ON tbl(i);
+
+statement ok
+CREATE INDEX IF NOT EXISTS my_idx ON tbl(i);
+
+statement error
+CREATE INDEX my_idx ON tbl(i);
+----
+<REGEX>:Catalog Error.*already exists.*
+
+query I
+SELECT COUNT(*) FROM duckdb_indexes;
+----
+1
+
+statement ok
+DROP INDEX my_idx;
diff --git a/test/sql/json/test_json_copy.test_slow b/test/sql/json/test_json_copy.test_slow
index 9041e5d4d6ec..56c2c6a36803 100644
--- a/test/sql/json/test_json_copy.test_slow
+++ b/test/sql/json/test_json_copy.test_slow
@@ -1,5 +1,5 @@
 # name: test/sql/json/test_json_copy.test_slow
-# description: Test JSON COPY using TPC-H
+# description: Test JSON COPY
 # group: [json]
 
 require json
diff --git a/test/sql/json/test_json_copy_tpch.test_slow b/test/sql/json/test_json_copy_tpch.test_slow
index ab614e4b7d11..41db483ad968 100644
--- a/test/sql/json/test_json_copy_tpch.test_slow
+++ b/test/sql/json/test_json_copy_tpch.test_slow
@@ -38,7 +38,7 @@ statement ok
 set memory_limit='100mb'
 
 statement ok
-COPY lineitem from '__TEST_DIR__/lineitem.json' (ARRAY)
+COPY lineitem FROM '__TEST_DIR__/lineitem.json' (ARRAY)
 
 # 500mb should be enough for the rest
 statement ok
@@ -49,6 +49,13 @@ PRAGMA tpch(1)
 ----
 <FILE>:extension/tpch/dbgen/answers/sf0.1/q01.csv
 
+# also test gzipped
+statement ok
+COPY lineitem TO '__TEST_DIR__/lineitem.json.gz'
+
+statement ok
+FROM '__TEST_DIR__/lineitem.json.gz'
+
 statement ok
 rollback
 
diff --git a/test/sql/sample/get_multiple_samples_small.test_slow b/test/sql/sample/get_multiple_samples_small.test_slow
new file mode 100644
index 000000000000..31bbf57ec2c0
--- /dev/null
+++ b/test/sql/sample/get_multiple_samples_small.test_slow
@@ -0,0 +1,21 @@
+# name: test/sql/sample/get_multiple_samples_small.test_slow
+# description: Run a sample multiple times (internal#4236)
+# group: [sample]
+
+statement ok
+pragma memory_limit='10G';
+
+
+statement ok
+CREATE OR REPLACE TABLE blah as (
+        SELECT *
+        FROM range(10_000_000)
+    );
+
+
+loop i 0 500
+
+statement ok
+SELECT * FROM blah TABLESAMPLE 100 ROWS;
+
+endloop
\ No newline at end of file
diff --git a/tools/pythonpkg/tests/fast/test_expression.py b/tools/pythonpkg/tests/fast/test_expression.py
index 0309c22538ea..0cb923d771a2 100644
--- a/tools/pythonpkg/tests/fast/test_expression.py
+++ b/tools/pythonpkg/tests/fast/test_expression.py
@@ -320,10 +320,13 @@ def test_subtract_expression(self):
         col1 = ColumnExpression('a')
         col2 = ColumnExpression('b')
         expr = col1 - col2
-        rel = rel.select(expr)
-        res = rel.fetchall()
+        rel2 = rel.select(expr)
+        res = rel2.fetchall()
         assert res == [(2,)]
 
+        res = rel.select(1 - col1).fetchall()
+        assert res == [(-2,)]
+
     def test_multiply_expression(self):
         con = duckdb.connect()
 
@@ -860,6 +863,20 @@ def test_filter_mixed(self, filter_rel):
         assert len(res) == 2
         assert res == [(1, 'a'), (4, 'a')]
 
+    def test_empty_in(self, filter_rel):
+        expr = ColumnExpression("a")
+        with pytest.raises(
+            duckdb.InvalidInputException, match="Incorrect amount of parameters to 'isin', needs at least 1 parameter"
+        ):
+            expr = expr.isin()
+
+        expr = ColumnExpression("a")
+        with pytest.raises(
+            duckdb.InvalidInputException,
+            match="Incorrect amount of parameters to 'isnotin', needs at least 1 parameter",
+        ):
+            expr = expr.isnotin()
+
     def test_filter_in(self, filter_rel):
         # IN expression
         expr = ColumnExpression("a")
