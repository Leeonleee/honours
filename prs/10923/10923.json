{
  "repo": "duckdb/duckdb",
  "pull_number": 10923,
  "instance_id": "duckdb__duckdb-10923",
  "issue_numbers": [
    "9975"
  ],
  "base_commit": "46fd3339263c83d5999c820e1eadd960afca61e2",
  "patch": "diff --git a/src/include/duckdb/common/enums/statement_type.hpp b/src/include/duckdb/common/enums/statement_type.hpp\nindex 3a52b5283f63..26ecce70ad6a 100644\n--- a/src/include/duckdb/common/enums/statement_type.hpp\n+++ b/src/include/duckdb/common/enums/statement_type.hpp\n@@ -65,6 +65,8 @@ struct StatementProperties {\n \t      return_type(StatementReturnType::QUERY_RESULT), parameter_count(0), always_require_rebind(false) {\n \t}\n \n+\t//! The set of databases this statement will read from\n+\tunordered_set<string> read_databases;\n \t//! The set of databases this statement will modify\n \tunordered_set<string> modified_databases;\n \t//! Whether or not the statement requires a valid transaction. Almost all statements require this, with the\ndiff --git a/src/include/duckdb/transaction/meta_transaction.hpp b/src/include/duckdb/transaction/meta_transaction.hpp\nindex e858b5c8037e..aafc3e4291e9 100644\n--- a/src/include/duckdb/transaction/meta_transaction.hpp\n+++ b/src/include/duckdb/transaction/meta_transaction.hpp\n@@ -41,7 +41,7 @@ class MetaTransaction {\n \n public:\n \tDUCKDB_API static MetaTransaction &Get(ClientContext &context);\n-\ttimestamp_t GetCurrentTransactionStartTimestamp() {\n+\ttimestamp_t GetCurrentTransactionStartTimestamp() const {\n \t\treturn start_timestamp;\n \t}\n \ndiff --git a/src/main/client_context.cpp b/src/main/client_context.cpp\nindex d77389b0e91c..f7e4527e4e06 100644\n--- a/src/main/client_context.cpp\n+++ b/src/main/client_context.cpp\n@@ -319,7 +319,6 @@ ClientContext::CreatePreparedStatement(ClientContextLock &lock, const string &qu\n \tresult->types = planner.types;\n \tresult->value_map = std::move(planner.value_map);\n \tresult->catalog_version = MetaTransaction::Get(*this).catalog_version;\n-\n \tif (!planner.properties.bound_all_parameters) {\n \t\treturn result;\n \t}\ndiff --git a/src/main/prepared_statement_data.cpp b/src/main/prepared_statement_data.cpp\nindex ed129d426e66..a6eb943a6ea3 100644\n--- a/src/main/prepared_statement_data.cpp\n+++ b/src/main/prepared_statement_data.cpp\n@@ -2,6 +2,8 @@\n #include \"duckdb/execution/physical_operator.hpp\"\n #include \"duckdb/parser/sql_statement.hpp\"\n #include \"duckdb/common/exception/binder_exception.hpp\"\n+#include \"duckdb/main/database_manager.hpp\"\n+#include \"duckdb/transaction/transaction.hpp\"\n \n namespace duckdb {\n \n@@ -19,12 +21,19 @@ void PreparedStatementData::CheckParameterCount(idx_t parameter_count) {\n \t}\n }\n \n+void StartTransactionInCatalog(ClientContext &context, const string &catalog_name) {\n+\tauto database = DatabaseManager::Get(context).GetDatabase(context, catalog_name);\n+\tif (!database) {\n+\t\tthrow BinderException(\"Prepared statement requires database %s but it was not attached\", catalog_name);\n+\t}\n+\tTransaction::Get(context, *database);\n+}\n+\n bool PreparedStatementData::RequireRebind(ClientContext &context, optional_ptr<case_insensitive_map_t<Value>> values) {\n \tidx_t count = values ? values->size() : 0;\n \tCheckParameterCount(count);\n \tif (!unbound_statement) {\n-\t\t// no unbound statement!? cannot rebind?\n-\t\treturn false;\n+\t\tthrow InternalException(\"Prepared statement without unbound statement\");\n \t}\n \tif (properties.always_require_rebind) {\n \t\t// this statement must always be re-bound\n@@ -34,10 +43,6 @@ bool PreparedStatementData::RequireRebind(ClientContext &context, optional_ptr<c\n \t\t// parameters not yet bound: query always requires a rebind\n \t\treturn true;\n \t}\n-\tif (Catalog::GetSystemCatalog(context).GetCatalogVersion() != catalog_version) {\n-\t\t//! context is out of bounds\n-\t\treturn true;\n-\t}\n \tfor (auto &it : value_map) {\n \t\tauto &identifier = it.first;\n \t\tauto lookup = values->find(identifier);\n@@ -48,6 +53,18 @@ bool PreparedStatementData::RequireRebind(ClientContext &context, optional_ptr<c\n \t\t\treturn true;\n \t\t}\n \t}\n+\t// prior to checking the catalog version we need to explicitly start transactions in all affected databases\n+\t// this ensures all catalog entries we rely on are cached\n+\tfor (auto &catalog_name : properties.read_databases) {\n+\t\tStartTransactionInCatalog(context, catalog_name);\n+\t}\n+\tfor (auto &catalog_name : properties.modified_databases) {\n+\t\tStartTransactionInCatalog(context, catalog_name);\n+\t}\n+\tif (Catalog::GetSystemCatalog(context).GetCatalogVersion() != catalog_version) {\n+\t\t//! context is out of bounds\n+\t\treturn true;\n+\t}\n \treturn false;\n }\n \ndiff --git a/src/planner/binder/tableref/bind_basetableref.cpp b/src/planner/binder/tableref/bind_basetableref.cpp\nindex f8d04c5bf344..5259511cc887 100644\n--- a/src/planner/binder/tableref/bind_basetableref.cpp\n+++ b/src/planner/binder/tableref/bind_basetableref.cpp\n@@ -181,14 +181,17 @@ unique_ptr<BoundTableRef> Binder::Bind(BaseTableRef &ref) {\n \t\t}\n \n \t\t// could not find an alternative: bind again to get the error\n-\t\ttable_or_view = Catalog::GetEntry(context, CatalogType::TABLE_ENTRY, ref.catalog_name, ref.schema_name,\n-\t\t                                  ref.table_name, OnEntryNotFound::THROW_EXCEPTION, error_context);\n+\t\tCatalog::GetEntry(context, CatalogType::TABLE_ENTRY, ref.catalog_name, ref.schema_name, ref.table_name,\n+\t\t                  OnEntryNotFound::THROW_EXCEPTION, error_context);\n+\t\tthrow InternalException(\"Catalog::GetEntry should have thrown an exception above\");\n \t}\n+\n \tswitch (table_or_view->type) {\n \tcase CatalogType::TABLE_ENTRY: {\n \t\t// base table: create the BoundBaseTableRef node\n \t\tauto table_index = GenerateTableIndex();\n \t\tauto &table = table_or_view->Cast<TableCatalogEntry>();\n+\t\tproperties.read_databases.insert(table.ParentCatalog().GetName());\n \n \t\tunique_ptr<FunctionData> bind_data;\n \t\tauto scan_function = table.GetScanFunction(context, bind_data);\ndiff --git a/src/transaction/commit_state.cpp b/src/transaction/commit_state.cpp\nindex 257cb56d7bf4..46cd9e49ac5a 100644\n--- a/src/transaction/commit_state.cpp\n+++ b/src/transaction/commit_state.cpp\n@@ -284,6 +284,8 @@ void CommitState::CommitEntry(UndoFlags type, data_ptr_t data) {\n \t\tif (!StringUtil::CIEquals(catalog_entry->name, catalog_entry->Parent().name)) {\n \t\t\tcatalog_entry->set->UpdateTimestamp(*catalog_entry, commit_id);\n \t\t}\n+\t\t// modify catalog on commit\n+\t\tduck_catalog.ModifyCatalog();\n \n \t\tif (HAS_LOG) {\n \t\t\t// push the catalog update to the WAL\n",
  "test_patch": "diff --git a/test/sql/parallelism/interquery/CMakeLists.txt b/test/sql/parallelism/interquery/CMakeLists.txt\nindex de19f56cee85..49a1685bb912 100644\n--- a/test/sql/parallelism/interquery/CMakeLists.txt\n+++ b/test/sql/parallelism/interquery/CMakeLists.txt\n@@ -8,6 +8,7 @@ add_library_unity(\n   test_concurrent_index.cpp\n   test_concurrentupdate.cpp\n   test_concurrent_sequence.cpp\n+  test_concurrent_prepared.cpp\n   test_default_catalog.cpp)\n set(ALL_OBJECT_FILES\n     ${ALL_OBJECT_FILES} $<TARGET_OBJECTS:test_sql_interquery_parallelism>\ndiff --git a/test/sql/parallelism/interquery/test_concurrent_prepared.cpp b/test/sql/parallelism/interquery/test_concurrent_prepared.cpp\nnew file mode 100644\nindex 000000000000..55b00460728d\n--- /dev/null\n+++ b/test/sql/parallelism/interquery/test_concurrent_prepared.cpp\n@@ -0,0 +1,40 @@\n+#include \"catch.hpp\"\n+#include \"test_helpers.hpp\"\n+#include <iostream>\n+#include <thread>\n+\n+using namespace duckdb;\n+using namespace std;\n+\n+static void SelectTable(Connection con) {\n+\tfor (idx_t i = 0; i < 1000; i++) {\n+\t\tauto prepare = con.Prepare(\"select * from foo\");\n+\t\tREQUIRE_NO_FAIL(prepare->Execute());\n+\t}\n+}\n+\n+static void RecreateTable(Connection con) {\n+\tfor (idx_t i = 0; i < 1000; i++) {\n+\t\tauto prepare = con.Prepare(\"create or replace table foo as select * from foo\");\n+\t\tREQUIRE_NO_FAIL(prepare->Execute());\n+\t}\n+}\n+\n+TEST_CASE(\"Test concurrent prepared\", \"[api][.]\") {\n+\tduckdb::unique_ptr<QueryResult> result;\n+\tDuckDB db(nullptr);\n+\tConnection con(db);\n+\tcon.EnableQueryVerification();\n+\n+\tREQUIRE_NO_FAIL(con.Query(\"create table foo as select unnest(generate_series(1, 10));\"));\n+\n+\tConnection select_conn(db);\n+\tConnection recreate_conn(db);\n+\tselect_conn.EnableQueryVerification();\n+\n+\tstd::thread select_function(SelectTable, std::move(select_conn));\n+\tstd::thread recreate_function(RecreateTable, std::move(recreate_conn));\n+\n+\tselect_function.join();\n+\trecreate_function.join();\n+}\n",
  "problem_statement": "Segmentation fault when selecting from a recreated table.\n### What happens?\n\nWhen reading from a table which is being `create or repace`d by another thread, a segmentation fault occurs.\r\n\r\nThe setup is to do `create or replace table foo as select * from foo` in one thread, and `select * from foo` in another. The reading thread throws a segmentation fault.\r\n\r\nHowever, if the read is wrapped by a transaction (conn.begin() before reading from the recreated table followed by a conn.commit()), the segfault is prevented. So the workaround is to wrap similar reads in a transaction.\n\n### To Reproduce\n\nRun the following python script and observe a segfault\r\n\r\n```python\r\nfrom threading import Thread\r\n\r\nimport duckdb\r\n\r\nconn = duckdb.connect()\r\n\r\n# Create a table which we'll be recreating later\r\nconn.execute(\"create table foo(bar int); insert into foo(bar) select unnest(generate_series(1, 10));\")\r\n\r\n\r\nclass ReadingThread(Thread):\r\n    def __init__(self, conn):\r\n        super().__init__()\r\n        self.cursor = conn.cursor()\r\n\r\n    def run(self):\r\n        while True:\r\n            # To prevent the segfault, do self.cursor.begin() here\r\n            self.cursor.execute(\"select * from foo\")\r\n            # To prevent the segfault, do self.cursor.commit() here\r\n\r\n\r\nclass RecreatingThread(Thread):\r\n    def __init__(self, conn):\r\n        super().__init__()\r\n        self.cursor = conn.cursor()\r\n\r\n    def run(self):\r\n        while True:\r\n            self.cursor.execute(\"create or replace table foo as select * from foo\")\r\n\r\n\r\nRecreatingThread(conn).start()\r\nReadingThread(conn).start()\r\n```\n\n### OS:\n\nUbuntu x64 in WSL on Windows 11\n\n### DuckDB Version:\n\nv0.9.2 3c695d7ba9\n\n### DuckDB Client:\n\nPython\n\n### Full Name:\n\nM\u00edma Hlav\u00e1\u010dek\n\n### Affiliation:\n\nBlindspot.ai\n\n### Have you tried this on the latest `main` branch?\n\nI have tested with a main build\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] Yes, I have\n",
  "hints_text": "",
  "created_at": "2024-02-29T17:07:45Z"
}