You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
SEGV in duckdb::EncodeStringDataPrefix
#### What happens?
SEGV in duckdb::EncodeStringDataPrefix(unsigned char*, duckdb::string_t, unsigned long) /root/duckdb/src/common/radix.cpp:162:2

#### To Reproduce
```sql
CREATE TABLE strings(b REAL, a INTEGER);
INSERT INTO strings VALUES
  (5, 10), (10, 20), (13, 26), (13, 26),
  (15, 30), (20, 40), (22,80), (30, 90);
CREATE TABLE id(c TEXT, strings_with_null INTEGER);
INSERT INTO id VALUES('c', NULL);
SELECT sum(a) OVER (
    PARTITION BY (
SELECT c FROM id WHERE strings_with_null=a
    ) ORDER BY a
  ) FROM strings;
```

#### Environment (please complete the following information):
 - OS: linux
 - DuckDB Version: v0.3.3-dev1395 80ae1e12d
 - DuckDB Client: /usr/local/bin/duckdb

#### Before Submitting

- [x] **Have you tried this on the latest `master` branch?**
* **Python**: `pip install duckdb --upgrade --pre`
* **R**: `install.packages("https://github.com/duckdb/duckdb/releases/download/master-builds/duckdb_r_src.tar.gz", repos = NULL)`
* **Other Platforms**: You can find binaries [here](https://github.com/duckdb/duckdb/releases/tag/master-builds) or compile from source.

- [x] **Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?**

#### ASAN detail

```
AddressSanitizer:DEADLYSIGNAL
=================================================================
==39778==ERROR: AddressSanitizer: SEGV on unknown address (pc 0x000001ab00b2 bp 0x7fff4c997350 sp 0x7fff4c996b08 T0)
==39778==The signal is caused by a READ memory access.
==39778==Hint: this fault was caused by a dereference of a high value address (see register values below).  Disassemble the provided pc to learn which register was used.
    #0 0x1ab00b2 in __asan::QuickCheckForUnpoisonedRegion(unsigned long, unsigned long) (/root/bld_asan/duckdb+0x1ab00b2)
    #1 0x1aaff6a in __asan_memcpy (/root/bld_asan/duckdb+0x1aaff6a)
    #2 0x2a4349e in duckdb::EncodeStringDataPrefix(unsigned char*, duckdb::string_t, unsigned long) /root/duckdb/src/common/radix.cpp:162:2
    #3 0x56835b7 in duckdb::RadixScatterStringVector(duckdb::VectorData&, duckdb::SelectionVector const&, unsigned long, unsigned char**, bool, bool, bool, unsigned long, unsigned long) /root/duckdb/src/common/row_operations/row_radix_scatter.cpp:87:4
    #4 0x56877bc in duckdb::RowOperations::RadixScatter(duckdb::Vector&, unsigned long, duckdb::SelectionVector const&, unsigned long, unsigned char**, bool, bool, bool, unsigned long, unsigned long, unsigned long) /root/duckdb/src/common/row_operations/row_radix_scatter.cpp:269:3
    #5 0x57be86a in duckdb::LocalSortState::SinkChunk(duckdb::DataChunk&, duckdb::DataChunk&) /root/duckdb/src/common/sort/sort_state.cpp:165:3
    #6 0x5cbcd86 in duckdb::SortCollectionForPartition(duckdb::WindowOperatorState&, duckdb::BoundWindowExpression*, duckdb::ChunkCollection&, duckdb::ChunkCollection&, duckdb::ChunkCollection*, unsigned long, unsigned long) /root/duckdb/src/execution/operator/aggregate/physical_window.cpp:403:20
    #7 0x5cb68d4 in duckdb::GeneratePartition(duckdb::WindowOperatorState&, duckdb::WindowGlobalState&, unsigned long) /root/duckdb/src/execution/operator/aggregate/physical_window.cpp:1221:3
    #8 0x5cb5208 in duckdb::PhysicalWindow::GetData(duckdb::ExecutionContext&, duckdb::DataChunk&, duckdb::GlobalSourceState&, duckdb::LocalSourceState&) const /root/duckdb/src/execution/operator/aggregate/physical_window.cpp:1376:4
    #9 0x3826288 in duckdb::PipelineExecutor::FetchFromSource(duckdb::DataChunk&) /root/duckdb/src/parallel/pipeline_executor.cpp:316:19
    #10 0x3818efd in duckdb::PipelineExecutor::ExecutePull(duckdb::DataChunk&) /root/duckdb/src/parallel/pipeline_executor.cpp:194:5
    #11 0x3818538 in duckdb::Executor::FetchChunk() /root/duckdb/src/parallel/executor.cpp:729:18
    #12 0x3588278 in duckdb::ClientContext::FetchInternal(duckdb::ClientContextLock&, duckdb::Executor&, duckdb::BaseQueryResult&) /root/duckdb/src/main/client_context.cpp:96:25
    #13 0x3588038 in duckdb::ClientContext::Fetch(duckdb::ClientContextLock&, duckdb::StreamQueryResult&) /root/duckdb/src/main/client_context.cpp:88:9
    #14 0x35fe8a5 in duckdb::StreamQueryResult::FetchRaw() /root/duckdb/src/main/stream_query_result.cpp:47:20
    #15 0x35f44b1 in duckdb::QueryResult::Fetch() /root/duckdb/src/main/query_result.cpp:50:15
    #16 0x1c1023e in duckdb::QueryResult::TryFetch(std::unique_ptr<duckdb::DataChunk, std::default_delete<duckdb::DataChunk> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) /root/duckdb/src/include/duckdb/main/query_result.hpp:85:13
    #17 0x1bf98f6 in sqlite3_step /root/duckdb/tools/sqlite3_api_wrapper/sqlite3_api_wrapper.cpp:229:23
    #18 0x1bd32da in exec_prepared_stmt_columnar /root/duckdb/tools/shell/shell.c:12710:8
    #19 0x1bd0f53 in exec_prepared_stmt /root/duckdb/tools/shell/shell.c:12886:5
    #20 0x1b396ab in shell_exec /root/duckdb/tools/shell/shell.c:13204:7
    #21 0x1bdc4ca in runOneSqlLine /root/duckdb/tools/shell/shell.c:19991:8
    #22 0x1b3c71d in process_input /root/duckdb/tools/shell/shell.c:20106:17
    #23 0x1b03651 in main /root/duckdb/tools/shell/shell.c:20908:12
    #24 0x7f387b7510b2 in __libc_start_main /build/glibc-sMfBJT/glibc-2.31/csu/../csu/libc-start.c:308:16
    #25 0x1a3597d in _start (/root/bld_asan/duckdb+0x1a3597d)

AddressSanitizer can not provide additional info.
SUMMARY: AddressSanitizer: SEGV (/root/bld_asan/duckdb+0x1ab00b2) in __asan::QuickCheckForUnpoisonedRegion(unsigned long, unsigned long)
==39778==ABORTING
```

SEGV in duckdb::EncodeStringDataPrefix
#### What happens?
SEGV in duckdb::EncodeStringDataPrefix(unsigned char*, duckdb::string_t, unsigned long) /root/duckdb/src/common/radix.cpp:162:2

#### To Reproduce
```sql
CREATE TABLE strings(b REAL, a INTEGER);
INSERT INTO strings VALUES
  (5, 10), (10, 20), (13, 26), (13, 26),
  (15, 30), (20, 40), (22,80), (30, 90);
CREATE TABLE id(c TEXT, strings_with_null INTEGER);
INSERT INTO id VALUES('c', NULL);
SELECT sum(a) OVER (
    PARTITION BY (
SELECT c FROM id WHERE strings_with_null=a
    ) ORDER BY a
  ) FROM strings;
```

#### Environment (please complete the following information):
 - OS: linux
 - DuckDB Version: v0.3.3-dev1395 80ae1e12d
 - DuckDB Client: /usr/local/bin/duckdb

#### Before Submitting

- [x] **Have you tried this on the latest `master` branch?**
* **Python**: `pip install duckdb --upgrade --pre`
* **R**: `install.packages("https://github.com/duckdb/duckdb/releases/download/master-builds/duckdb_r_src.tar.gz", repos = NULL)`
* **Other Platforms**: You can find binaries [here](https://github.com/duckdb/duckdb/releases/tag/master-builds) or compile from source.

- [x] **Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?**

#### ASAN detail

```
AddressSanitizer:DEADLYSIGNAL
=================================================================
==39778==ERROR: AddressSanitizer: SEGV on unknown address (pc 0x000001ab00b2 bp 0x7fff4c997350 sp 0x7fff4c996b08 T0)
==39778==The signal is caused by a READ memory access.
==39778==Hint: this fault was caused by a dereference of a high value address (see register values below).  Disassemble the provided pc to learn which register was used.
    #0 0x1ab00b2 in __asan::QuickCheckForUnpoisonedRegion(unsigned long, unsigned long) (/root/bld_asan/duckdb+0x1ab00b2)
    #1 0x1aaff6a in __asan_memcpy (/root/bld_asan/duckdb+0x1aaff6a)
    #2 0x2a4349e in duckdb::EncodeStringDataPrefix(unsigned char*, duckdb::string_t, unsigned long) /root/duckdb/src/common/radix.cpp:162:2
    #3 0x56835b7 in duckdb::RadixScatterStringVector(duckdb::VectorData&, duckdb::SelectionVector const&, unsigned long, unsigned char**, bool, bool, bool, unsigned long, unsigned long) /root/duckdb/src/common/row_operations/row_radix_scatter.cpp:87:4
    #4 0x56877bc in duckdb::RowOperations::RadixScatter(duckdb::Vector&, unsigned long, duckdb::SelectionVector const&, unsigned long, unsigned char**, bool, bool, bool, unsigned long, unsigned long, unsigned long) /root/duckdb/src/common/row_operations/row_radix_scatter.cpp:269:3
    #5 0x57be86a in duckdb::LocalSortState::SinkChunk(duckdb::DataChunk&, duckdb::DataChunk&) /root/duckdb/src/common/sort/sort_state.cpp:165:3
    #6 0x5cbcd86 in duckdb::SortCollectionForPartition(duckdb::WindowOperatorState&, duckdb::BoundWindowExpression*, duckdb::ChunkCollection&, duckdb::ChunkCollection&, duckdb::ChunkCollection*, unsigned long, unsigned long) /root/duckdb/src/execution/operator/aggregate/physical_window.cpp:403:20
    #7 0x5cb68d4 in duckdb::GeneratePartition(duckdb::WindowOperatorState&, duckdb::WindowGlobalState&, unsigned long) /root/duckdb/src/execution/operator/aggregate/physical_window.cpp:1221:3
    #8 0x5cb5208 in duckdb::PhysicalWindow::GetData(duckdb::ExecutionContext&, duckdb::DataChunk&, duckdb::GlobalSourceState&, duckdb::LocalSourceState&) const /root/duckdb/src/execution/operator/aggregate/physical_window.cpp:1376:4
    #9 0x3826288 in duckdb::PipelineExecutor::FetchFromSource(duckdb::DataChunk&) /root/duckdb/src/parallel/pipeline_executor.cpp:316:19
    #10 0x3818efd in duckdb::PipelineExecutor::ExecutePull(duckdb::DataChunk&) /root/duckdb/src/parallel/pipeline_executor.cpp:194:5
    #11 0x3818538 in duckdb::Executor::FetchChunk() /root/duckdb/src/parallel/executor.cpp:729:18
    #12 0x3588278 in duckdb::ClientContext::FetchInternal(duckdb::ClientContextLock&, duckdb::Executor&, duckdb::BaseQueryResult&) /root/duckdb/src/main/client_context.cpp:96:25
    #13 0x3588038 in duckdb::ClientContext::Fetch(duckdb::ClientContextLock&, duckdb::StreamQueryResult&) /root/duckdb/src/main/client_context.cpp:88:9
    #14 0x35fe8a5 in duckdb::StreamQueryResult::FetchRaw() /root/duckdb/src/main/stream_query_result.cpp:47:20
    #15 0x35f44b1 in duckdb::QueryResult::Fetch() /root/duckdb/src/main/query_result.cpp:50:15
    #16 0x1c1023e in duckdb::QueryResult::TryFetch(std::unique_ptr<duckdb::DataChunk, std::default_delete<duckdb::DataChunk> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) /root/duckdb/src/include/duckdb/main/query_result.hpp:85:13
    #17 0x1bf98f6 in sqlite3_step /root/duckdb/tools/sqlite3_api_wrapper/sqlite3_api_wrapper.cpp:229:23
    #18 0x1bd32da in exec_prepared_stmt_columnar /root/duckdb/tools/shell/shell.c:12710:8
    #19 0x1bd0f53 in exec_prepared_stmt /root/duckdb/tools/shell/shell.c:12886:5
    #20 0x1b396ab in shell_exec /root/duckdb/tools/shell/shell.c:13204:7
    #21 0x1bdc4ca in runOneSqlLine /root/duckdb/tools/shell/shell.c:19991:8
    #22 0x1b3c71d in process_input /root/duckdb/tools/shell/shell.c:20106:17
    #23 0x1b03651 in main /root/duckdb/tools/shell/shell.c:20908:12
    #24 0x7f387b7510b2 in __libc_start_main /build/glibc-sMfBJT/glibc-2.31/csu/../csu/libc-start.c:308:16
    #25 0x1a3597d in _start (/root/bld_asan/duckdb+0x1a3597d)

AddressSanitizer can not provide additional info.
SUMMARY: AddressSanitizer: SEGV (/root/bld_asan/duckdb+0x1ab00b2) in __asan::QuickCheckForUnpoisonedRegion(unsigned long, unsigned long)
==39778==ABORTING
```


</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
3: </div>
4: <p>&nbsp;</p>
5: 
6: <p align="center">
7:   <a href="https://github.com/duckdb/duckdb/actions">
8:     <img src="https://github.com/cwida/duckdb/workflows/.github/workflows/main.yml/badge.svg?branch=master" alt=".github/workflows/main.yml">
9:   </a>
10:   <a href="https://www.codefactor.io/repository/github/cwida/duckdb">
11:     <img src="https://www.codefactor.io/repository/github/cwida/duckdb/badge" alt="CodeFactor"/>
12:   </a>
13:   <a href="https://app.codecov.io/gh/duckdb/duckdb">
14:     <img src="https://codecov.io/gh/duckdb/duckdb/branch/master/graph/badge.svg?token=FaxjcfFghN" alt="codecov"/>
15:   </a>
16:   <a href="https://discord.gg/tcvwpjfnZx">
17:     <img src="https://shields.io/discord/909674491309850675" alt="discord" />
18:   </a>
19: </p>
20: 
21: ## DuckDB
22: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on the goals of DuckDB, please refer to [the Why DuckDB page on our website](https://duckdb.org/why_duckdb).
23: 
24: ## Installation
25: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
26: 
27: ## Data Import
28: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
29: 
30: ```sql
31: SELECT * FROM 'myfile.csv';
32: SELECT * FROM 'myfile.parquet';
33: ```
34: 
35: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
36: 
37: ## SQL Reference
38: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
39: 
40: ## Development
41: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`.
42: 
43: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
44: 
45: 
[end of README.md]
[start of src/execution/operator/join/physical_comparison_join.cpp]
1: #include "duckdb/execution/operator/join/physical_comparison_join.hpp"
2: #include "duckdb/common/types/chunk_collection.hpp"
3: 
4: namespace duckdb {
5: 
6: PhysicalComparisonJoin::PhysicalComparisonJoin(LogicalOperator &op, PhysicalOperatorType type,
7:                                                vector<JoinCondition> conditions_p, JoinType join_type,
8:                                                idx_t estimated_cardinality)
9:     : PhysicalJoin(op, type, join_type, estimated_cardinality) {
10: 	conditions.resize(conditions_p.size());
11: 	// we reorder conditions so the ones with COMPARE_EQUAL occur first
12: 	idx_t equal_position = 0;
13: 	idx_t other_position = conditions_p.size() - 1;
14: 	for (idx_t i = 0; i < conditions_p.size(); i++) {
15: 		if (conditions_p[i].comparison == ExpressionType::COMPARE_EQUAL ||
16: 		    conditions_p[i].comparison == ExpressionType::COMPARE_NOT_DISTINCT_FROM) {
17: 			// COMPARE_EQUAL and COMPARE_NOT_DISTINCT_FROM, move to the start
18: 			conditions[equal_position++] = std::move(conditions_p[i]);
19: 		} else {
20: 			// other expression, move to the end
21: 			conditions[other_position--] = std::move(conditions_p[i]);
22: 		}
23: 	}
24: }
25: 
26: string PhysicalComparisonJoin::ParamsToString() const {
27: 	string extra_info = JoinTypeToString(join_type) + "\n";
28: 	for (auto &it : conditions) {
29: 		string op = ExpressionTypeToOperator(it.comparison);
30: 		extra_info += it.left->GetName() + op + it.right->GetName() + "\n";
31: 	}
32: 	return extra_info;
33: }
34: 
35: void PhysicalComparisonJoin::ConstructEmptyJoinResult(JoinType join_type, bool has_null, DataChunk &input,
36:                                                       DataChunk &result) {
37: 	// empty hash table, special case
38: 	if (join_type == JoinType::ANTI) {
39: 		// anti join with empty hash table, NOP join
40: 		// return the input
41: 		D_ASSERT(input.ColumnCount() == result.ColumnCount());
42: 		result.Reference(input);
43: 	} else if (join_type == JoinType::MARK) {
44: 		// MARK join with empty hash table
45: 		D_ASSERT(join_type == JoinType::MARK);
46: 		D_ASSERT(result.ColumnCount() == input.ColumnCount() + 1);
47: 		auto &result_vector = result.data.back();
48: 		D_ASSERT(result_vector.GetType() == LogicalType::BOOLEAN);
49: 		// for every data vector, we just reference the child chunk
50: 		result.SetCardinality(input);
51: 		for (idx_t i = 0; i < input.ColumnCount(); i++) {
52: 			result.data[i].Reference(input.data[i]);
53: 		}
54: 		// for the MARK vector:
55: 		// if the HT has no NULL values (i.e. empty result set), return a vector that has false for every input
56: 		// entry if the HT has NULL values (i.e. result set had values, but all were NULL), return a vector that
57: 		// has NULL for every input entry
58: 		if (!has_null) {
59: 			auto bool_result = FlatVector::GetData<bool>(result_vector);
60: 			for (idx_t i = 0; i < result.size(); i++) {
61: 				bool_result[i] = false;
62: 			}
63: 		} else {
64: 			FlatVector::Validity(result_vector).SetAllInvalid(result.size());
65: 		}
66: 	} else if (join_type == JoinType::LEFT || join_type == JoinType::OUTER || join_type == JoinType::SINGLE) {
67: 		// LEFT/FULL OUTER/SINGLE join and build side is empty
68: 		// for the LHS we reference the data
69: 		result.SetCardinality(input.size());
70: 		for (idx_t i = 0; i < input.ColumnCount(); i++) {
71: 			result.data[i].Reference(input.data[i]);
72: 		}
73: 		// for the RHS
74: 		for (idx_t k = input.ColumnCount(); k < result.ColumnCount(); k++) {
75: 			result.data[k].SetVectorType(VectorType::CONSTANT_VECTOR);
76: 			ConstantVector::SetNull(result.data[k], true);
77: 		}
78: 	}
79: }
80: 
81: void PhysicalComparisonJoin::ConstructFullOuterJoinResult(bool *found_match, ChunkCollection &input, DataChunk &result,
82:                                                           idx_t &scan_position) {
83: 	// fill in NULL values for the LHS
84: 	SelectionVector rsel(STANDARD_VECTOR_SIZE);
85: 	while (scan_position < input.Count()) {
86: 		auto &rhs_chunk = input.GetChunk(scan_position / STANDARD_VECTOR_SIZE);
87: 		idx_t result_count = 0;
88: 		// figure out which tuples didn't find a match in the RHS
89: 		for (idx_t i = 0; i < rhs_chunk.size(); i++) {
90: 			if (!found_match[scan_position + i]) {
91: 				rsel.set_index(result_count++, i);
92: 			}
93: 		}
94: 		scan_position += STANDARD_VECTOR_SIZE;
95: 		if (result_count > 0) {
96: 			// if there were any tuples that didn't find a match, output them
97: 			idx_t left_column_count = result.ColumnCount() - input.ColumnCount();
98: 			for (idx_t i = 0; i < left_column_count; i++) {
99: 				result.data[i].SetVectorType(VectorType::CONSTANT_VECTOR);
100: 				ConstantVector::SetNull(result.data[i], true);
101: 			}
102: 			for (idx_t col_idx = 0; col_idx < rhs_chunk.ColumnCount(); col_idx++) {
103: 				result.data[left_column_count + col_idx].Slice(rhs_chunk.data[col_idx], rsel, result_count);
104: 			}
105: 			result.SetCardinality(result_count);
106: 			return;
107: 		}
108: 	}
109: }
110: 
111: } // namespace duckdb
[end of src/execution/operator/join/physical_comparison_join.cpp]
[start of src/optimizer/statistics/operator/propagate_join.cpp]
1: #include "duckdb/common/types/hugeint.hpp"
2: #include "duckdb/optimizer/statistics_propagator.hpp"
3: #include "duckdb/planner/expression/bound_columnref_expression.hpp"
4: #include "duckdb/planner/operator/logical_any_join.hpp"
5: #include "duckdb/planner/operator/logical_comparison_join.hpp"
6: #include "duckdb/planner/operator/logical_cross_product.hpp"
7: #include "duckdb/planner/operator/logical_join.hpp"
8: #include "duckdb/storage/statistics/validity_statistics.hpp"
9: 
10: namespace duckdb {
11: 
12: void StatisticsPropagator::PropagateStatistics(LogicalComparisonJoin &join, unique_ptr<LogicalOperator> *node_ptr) {
13: 	for (idx_t i = 0; i < join.conditions.size(); i++) {
14: 		auto &condition = join.conditions[i];
15: 		auto stats_left = PropagateExpression(condition.left);
16: 		auto stats_right = PropagateExpression(condition.right);
17: 		if (stats_left && stats_right) {
18: 			if ((condition.comparison == ExpressionType::COMPARE_DISTINCT_FROM ||
19: 			     condition.comparison == ExpressionType::COMPARE_NOT_DISTINCT_FROM) &&
20: 			    stats_left->CanHaveNull() && stats_right->CanHaveNull()) {
21: 				// null values are equal in this join, and both sides can have null values
22: 				// nothing to do here
23: 				continue;
24: 			}
25: 			auto prune_result = PropagateComparison(*stats_left, *stats_right, condition.comparison);
26: 			// Add stats to logical_join for perfect hash join
27: 			join.join_stats.push_back(move(stats_left));
28: 			join.join_stats.push_back(move(stats_right));
29: 			switch (prune_result) {
30: 			case FilterPropagateResult::FILTER_FALSE_OR_NULL:
31: 			case FilterPropagateResult::FILTER_ALWAYS_FALSE:
32: 				// filter is always false or null, none of the join conditions matter
33: 				switch (join.join_type) {
34: 				case JoinType::SEMI:
35: 				case JoinType::INNER:
36: 					// semi or inner join on false; entire node can be pruned
37: 					ReplaceWithEmptyResult(*node_ptr);
38: 					return;
39: 				case JoinType::ANTI:
40: 					// anti join: replace entire join with LHS
41: 					*node_ptr = move(join.children[0]);
42: 					return;
43: 				case JoinType::LEFT:
44: 					// anti/left outer join: replace right side with empty node
45: 					ReplaceWithEmptyResult(join.children[1]);
46: 					return;
47: 				case JoinType::RIGHT:
48: 					// right outer join: replace left side with empty node
49: 					ReplaceWithEmptyResult(join.children[0]);
50: 					return;
51: 				default:
52: 					// other join types: can't do much meaningful with this information
53: 					// full outer join requires both sides anyway; we can skip the execution of the actual join, but eh
54: 					// mark/single join requires knowing if the rhs has null values or not
55: 					break;
56: 				}
57: 				break;
58: 			case FilterPropagateResult::FILTER_ALWAYS_TRUE:
59: 				// filter is always true
60: 				if (join.conditions.size() > 1) {
61: 					// there are multiple conditions: erase this condition
62: 					join.conditions.erase(join.conditions.begin() + i);
63: 					i--;
64: 					continue;
65: 				} else {
66: 					// this is the only condition and it is always true: all conditions are true
67: 					switch (join.join_type) {
68: 					case JoinType::SEMI:
69: 						// semi join on true: replace entire join with LHS
70: 						*node_ptr = move(join.children[0]);
71: 						return;
72: 					case JoinType::INNER:
73: 					case JoinType::LEFT:
74: 					case JoinType::RIGHT:
75: 					case JoinType::OUTER: {
76: 						// inner/left/right/full outer join, replace with cross product
77: 						// since the condition is always true, left/right/outer join are equivalent to inner join here
78: 						auto cross_product = make_unique<LogicalCrossProduct>();
79: 						cross_product->children = move(join.children);
80: 						*node_ptr = move(cross_product);
81: 						return;
82: 					}
83: 					case JoinType::ANTI:
84: 						// anti join on true: empty result
85: 						ReplaceWithEmptyResult(*node_ptr);
86: 						return;
87: 					default:
88: 						// we don't handle mark/single join here yet
89: 						break;
90: 					}
91: 				}
92: 				break;
93: 			default:
94: 				break;
95: 			}
96: 		}
97: 		// after we have propagated, we can update the statistics on both sides
98: 		// note that it is fine to do this now, even if the same column is used again later
99: 		// e.g. if we have i=j AND i=k, and the stats for j and k are disjoint, we know there are no results
100: 		// so if we have e.g. i: [0, 100], j: [0, 25], k: [75, 100]
101: 		// we can set i: [0, 25] after the first comparison, and statically determine that the second comparison is fals
102: 
103: 		// note that we can't update statistics the same for all join types
104: 		// mark and single joins don't filter any tuples -> so there is no propagation possible
105: 		// anti joins have inverse statistics propagation
106: 		// (i.e. if we have an anti join on i: [0, 100] and j: [0, 25], the resulting stats are i:[25,100])
107: 		// for now we don't handle anti joins
108: 		if (condition.comparison == ExpressionType::COMPARE_DISTINCT_FROM ||
109: 		    condition.comparison == ExpressionType::COMPARE_NOT_DISTINCT_FROM) {
110: 			// skip update when null values are equal (for now?)
111: 			continue;
112: 		}
113: 		switch (join.join_type) {
114: 		case JoinType::INNER:
115: 		case JoinType::SEMI: {
116: 			UpdateFilterStatistics(*condition.left, *condition.right, condition.comparison);
117: 			auto stats_left = PropagateExpression(condition.left);
118: 			auto stats_right = PropagateExpression(condition.right);
119: 			// Update join_stats when is already part of the join
120: 			if (join.join_stats.size() == 2) {
121: 				join.join_stats[0] = move(stats_left);
122: 				join.join_stats[1] = move(stats_right);
123: 			}
124: 			break;
125: 		}
126: 		default:
127: 			break;
128: 		}
129: 	}
130: }
131: 
132: void StatisticsPropagator::PropagateStatistics(LogicalAnyJoin &join, unique_ptr<LogicalOperator> *node_ptr) {
133: 	// propagate the expression into the join condition
134: 	PropagateExpression(join.condition);
135: }
136: 
137: void StatisticsPropagator::MultiplyCardinalities(unique_ptr<NodeStatistics> &stats, NodeStatistics &new_stats) {
138: 	if (!stats->has_estimated_cardinality || !new_stats.has_estimated_cardinality || !stats->has_max_cardinality ||
139: 	    !new_stats.has_max_cardinality) {
140: 		stats = nullptr;
141: 		return;
142: 	}
143: 	stats->estimated_cardinality = MaxValue<idx_t>(stats->estimated_cardinality, new_stats.estimated_cardinality);
144: 	auto new_max = Hugeint::Multiply(stats->max_cardinality, new_stats.max_cardinality);
145: 	if (new_max < NumericLimits<int64_t>::Maximum()) {
146: 		int64_t result;
147: 		if (!Hugeint::TryCast<int64_t>(new_max, result)) {
148: 			throw InternalException("Overflow in cast in statistics propagation");
149: 		}
150: 		D_ASSERT(result >= 0);
151: 		stats->max_cardinality = idx_t(result);
152: 	} else {
153: 		stats = nullptr;
154: 	}
155: }
156: 
157: unique_ptr<NodeStatistics> StatisticsPropagator::PropagateStatistics(LogicalJoin &join,
158:                                                                      unique_ptr<LogicalOperator> *node_ptr) {
159: 	// first propagate through the children of the join
160: 	node_stats = PropagateStatistics(join.children[0]);
161: 	for (idx_t child_idx = 1; child_idx < join.children.size(); child_idx++) {
162: 		auto child_stats = PropagateStatistics(join.children[child_idx]);
163: 		if (!child_stats) {
164: 			node_stats = nullptr;
165: 		} else if (node_stats) {
166: 			MultiplyCardinalities(node_stats, *child_stats);
167: 		}
168: 	}
169: 
170: 	auto join_type = join.join_type;
171: 	vector<ColumnBinding> left_bindings, right_bindings;
172: 	if (IsRightOuterJoin(join_type)) {
173: 		left_bindings = join.children[0]->GetColumnBindings();
174: 	}
175: 	if (IsLeftOuterJoin(join_type)) {
176: 		right_bindings = join.children[1]->GetColumnBindings();
177: 	}
178: 
179: 	// then propagate into the join conditions
180: 	switch (join.type) {
181: 	case LogicalOperatorType::LOGICAL_COMPARISON_JOIN:
182: 		PropagateStatistics((LogicalComparisonJoin &)join, node_ptr);
183: 		break;
184: 	case LogicalOperatorType::LOGICAL_ANY_JOIN:
185: 		PropagateStatistics((LogicalAnyJoin &)join, node_ptr);
186: 		break;
187: 	default:
188: 		break;
189: 	}
190: 
191: 	// now depending on the join type, we might need to alter the statistics
192: 	// LEFT, FULL and RIGHT OUTER joins can introduce null values
193: 	// this requires us to alter the statistics after this point in the query plan
194: 	if (IsLeftOuterJoin(join_type)) {
195: 		// left or full outer join: set IsNull() to true for all rhs statistics
196: 		for (auto &binding : right_bindings) {
197: 			auto stats = statistics_map.find(binding);
198: 			if (stats != statistics_map.end()) {
199: 				stats->second->validity_stats = make_unique<ValidityStatistics>(true);
200: 			}
201: 		}
202: 	}
203: 	if (IsRightOuterJoin(join_type)) {
204: 		// right or full outer join: set IsNull() to true for all lhs statistics
205: 		for (auto &binding : left_bindings) {
206: 			auto stats = statistics_map.find(binding);
207: 			if (stats != statistics_map.end()) {
208: 				stats->second->validity_stats = make_unique<ValidityStatistics>(true);
209: 			}
210: 		}
211: 	}
212: 	return move(node_stats);
213: }
214: 
215: } // namespace duckdb
[end of src/optimizer/statistics/operator/propagate_join.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: