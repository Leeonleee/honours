{
  "repo": "duckdb/duckdb",
  "pull_number": 1842,
  "instance_id": "duckdb__duckdb-1842",
  "issue_numbers": [
    "1763"
  ],
  "base_commit": "54758ff05e45cfc9ccb0ec482ad810ca18c7ce67",
  "patch": "diff --git a/src/common/types.cpp b/src/common/types.cpp\nindex 2746c11b4f3e..38d34f58ed92 100644\n--- a/src/common/types.cpp\n+++ b/src/common/types.cpp\n@@ -92,12 +92,11 @@ PhysicalType LogicalType::GetInternalType() {\n \t\treturn PhysicalType::VARCHAR;\n \tcase LogicalTypeId::INTERVAL:\n \t\treturn PhysicalType::INTERVAL;\n+\tcase LogicalTypeId::MAP:\n \tcase LogicalTypeId::STRUCT:\n \t\treturn PhysicalType::STRUCT;\n \tcase LogicalTypeId::LIST:\n \t\treturn PhysicalType::LIST;\n-\tcase LogicalTypeId::MAP:\n-\t\treturn PhysicalType::MAP;\n \tcase LogicalTypeId::HASH:\n \t\treturn PhysicalType::HASH;\n \tcase LogicalTypeId::POINTER:\n@@ -210,8 +209,6 @@ string TypeIdToString(PhysicalType type) {\n \t\treturn \"STRUCT<?>\";\n \tcase PhysicalType::LIST:\n \t\treturn \"LIST<?>\";\n-\tcase PhysicalType::MAP:\n-\t\treturn \"MAP<?>\";\n \tcase PhysicalType::INVALID:\n \t\treturn \"INVALID\";\n \tcase PhysicalType::BIT:\n@@ -256,7 +253,6 @@ idx_t GetTypeIdSize(PhysicalType type) {\n \t\treturn sizeof(string_t);\n \tcase PhysicalType::INTERVAL:\n \t\treturn sizeof(interval_t);\n-\tcase PhysicalType::MAP:\n \tcase PhysicalType::STRUCT:\n \t\treturn 0; // no own payload\n \tcase PhysicalType::LIST:\n@@ -737,6 +733,21 @@ LogicalType LogicalType::MaxLogicalType(const LogicalType &left, const LogicalTy\n \t\t\t    make_pair(left.child_types()[0].first,\n \t\t\t              MaxLogicalType(left.child_types()[0].second, right.child_types()[0].second)));\n \t\t\treturn LogicalType(LogicalTypeId::LIST, move(child_types));\n+\t\t} else if (left.id() == LogicalTypeId::STRUCT) {\n+\t\t\t// struct: perform recursively\n+\t\t\tauto &left_child_types = left.child_types();\n+\t\t\tauto &right_child_types = right.child_types();\n+\t\t\tif (left_child_types.size() != right_child_types.size()) {\n+\t\t\t\t// child types are not of equal size, we can't cast anyway\n+\t\t\t\t// just return the left child\n+\t\t\t\treturn left;\n+\t\t\t}\n+\t\t\tchild_list_t<LogicalType> child_types;\n+\t\t\tfor (idx_t i = 0; i < left_child_types.size(); i++) {\n+\t\t\t\tauto child_type = MaxLogicalType(left_child_types[i].second, right_child_types[i].second);\n+\t\t\t\tchild_types.push_back(make_pair(left_child_types[i].first, move(child_type)));\n+\t\t\t}\n+\t\t\treturn LogicalType(LogicalTypeId::STRUCT, move(child_types));\n \t\t} else {\n \t\t\t// types are equal but no extra specifier: just return the type\n \t\t\t// FIXME: LIST and STRUCT?\ndiff --git a/src/common/types/chunk_collection.cpp b/src/common/types/chunk_collection.cpp\nindex 55639fb20335..1120aade2785 100644\n--- a/src/common/types/chunk_collection.cpp\n+++ b/src/common/types/chunk_collection.cpp\n@@ -438,7 +438,6 @@ void ChunkCollection::MaterializeSortedChunk(DataChunk &target, idx_t order[], i\n \t\tcase PhysicalType::INTERVAL:\n \t\t\tTemplatedSetValues<interval_t>(this, target.data[col_idx], order, col_idx, start_offset, remaining_data);\n \t\t\tbreak;\n-\t\tcase PhysicalType::MAP:\n \t\tcase PhysicalType::LIST:\n \t\tcase PhysicalType::STRUCT: {\n \t\t\tfor (idx_t row_idx = 0; row_idx < remaining_data; row_idx++) {\n@@ -602,7 +601,6 @@ idx_t ChunkCollection::MaterializeHeapChunk(DataChunk &target, idx_t order[], id\n \t\t\tTemplatedSetValues<string_t>(this, target.data[col_idx], order, col_idx, start_offset, remaining_data);\n \t\t\tbreak;\n \t\t// TODO this is ugly and sloooow!\n-\t\tcase PhysicalType::MAP:\n \t\tcase PhysicalType::STRUCT:\n \t\tcase PhysicalType::LIST: {\n \t\t\tfor (idx_t row_idx = 0; row_idx < remaining_data; row_idx++) {\ndiff --git a/src/common/types/row_data_collection.cpp b/src/common/types/row_data_collection.cpp\nindex fd33f821a1e2..a8d15b58c018 100644\n--- a/src/common/types/row_data_collection.cpp\n+++ b/src/common/types/row_data_collection.cpp\n@@ -271,7 +271,6 @@ void RowDataCollection::ComputeEntrySizes(Vector &v, idx_t entry_sizes[], idx_t\n \t\tcase PhysicalType::VARCHAR:\n \t\t\tComputeStringEntrySizes(v, entry_sizes, vcount, offset);\n \t\t\tbreak;\n-\t\tcase PhysicalType::MAP:\n \t\tcase PhysicalType::STRUCT:\n \t\t\tComputeStructEntrySizes(v, entry_sizes, vcount, offset);\n \t\t\tbreak;\n@@ -596,7 +595,6 @@ void RowDataCollection::SerializeVector(Vector &v, idx_t vcount, const Selection\n \t\tcase PhysicalType::VARCHAR:\n \t\t\tSerializeStringVector(v, vcount, sel, ser_count, col_idx, key_locations, validitymask_locations, offset);\n \t\t\tbreak;\n-\t\tcase PhysicalType::MAP:\n \t\tcase PhysicalType::STRUCT:\n \t\t\tSerializeStructVector(v, vcount, sel, ser_count, col_idx, key_locations, validitymask_locations, offset);\n \t\t\tbreak;\n@@ -910,7 +908,6 @@ void RowDataCollection::DeserializeIntoVector(Vector &v, const idx_t &vcount, co\n \tcase PhysicalType::VARCHAR:\n \t\tDeserializeIntoStringVector(v, vcount, col_idx, key_locations, validitymask_locations);\n \t\tbreak;\n-\tcase PhysicalType::MAP:\n \tcase PhysicalType::STRUCT:\n \t\tDeserializeIntoStructVector(v, vcount, col_idx, key_locations, validitymask_locations);\n \t\tbreak;\ndiff --git a/src/common/types/vector.cpp b/src/common/types/vector.cpp\nindex 82daa9d47eb9..b9a004a2c062 100644\n--- a/src/common/types/vector.cpp\n+++ b/src/common/types/vector.cpp\n@@ -155,11 +155,13 @@ void Vector::Initialize(const LogicalType &new_type, bool zero_data) {\n \n \t\tauxiliary = move(struct_buffer);\n \t}\n-\tif (GetTypeIdSize(type.InternalType()) > 0) {\n+\tauto internal_type = type.InternalType();\n+\tauto type_size = GetTypeIdSize(internal_type);\n+\tif (type_size > 0) {\n \t\tbuffer = VectorBuffer::CreateStandardVector(VectorType::FLAT_VECTOR, type);\n \t\tdata = buffer->GetData();\n \t\tif (zero_data) {\n-\t\t\tmemset(data, 0, STANDARD_VECTOR_SIZE * GetTypeIdSize(type.InternalType()));\n+\t\t\tmemset(data, 0, STANDARD_VECTOR_SIZE * type_size);\n \t\t}\n \t} else {\n \t\tbuffer = VectorBuffer::CreateStandardVector(VectorType::FLAT_VECTOR, type);\n@@ -247,7 +249,9 @@ void Vector::SetValue(idx_t index, const Value &val) {\n \n \tvalidity.EnsureWritable();\n \tvalidity.Set(index, !val.is_null);\n-\tif (val.is_null) {\n+\tif (val.is_null && GetType().InternalType() != PhysicalType::STRUCT) {\n+\t\t// for structs we still need to set the child-entries to NULL\n+\t\t// so we do not bail out yet\n \t\treturn;\n \t}\n \n@@ -326,14 +330,18 @@ void Vector::SetValue(idx_t index, const Value &val) {\n \t\tbreak;\n \tcase LogicalTypeId::MAP:\n \tcase LogicalTypeId::STRUCT: {\n-\t\tauto &children = StructVector::GetEntries(*this);\n-\t\tD_ASSERT(children.size() == val.struct_value.size());\n+\t\tD_ASSERT(GetVectorType() == VectorType::CONSTANT_VECTOR || GetVectorType() == VectorType::FLAT_VECTOR);\n \n-\t\tfor (size_t i = 0; i < val.struct_value.size(); i++) {\n-\t\t\tauto &struct_child = val.struct_value[i];\n-\t\t\tD_ASSERT(GetVectorType() == VectorType::CONSTANT_VECTOR || GetVectorType() == VectorType::FLAT_VECTOR);\n+\t\tauto &children = StructVector::GetEntries(*this);\n+\t\tD_ASSERT(val.is_null || children.size() == val.struct_value.size());\n+\t\tfor (size_t i = 0; i < children.size(); i++) {\n \t\t\tauto &vec_child = children[i];\n-\t\t\tvec_child->SetValue(index, struct_child);\n+\t\t\tif (!val.is_null) {\n+\t\t\t\tauto &struct_child = val.struct_value[i];\n+\t\t\t\tvec_child->SetValue(index, struct_child);\n+\t\t\t} else {\n+\t\t\t\tvec_child->SetValue(index, Value());\n+\t\t\t}\n \t\t}\n \t\tbreak;\n \t}\n@@ -638,7 +646,6 @@ void Vector::Normalify(idx_t count) {\n \t\t\tTemplatedFlattenConstantVector<list_entry_t>(data, old_data, count);\n \t\t\tbreak;\n \t\t}\n-\t\tcase PhysicalType::MAP:\n \t\tcase PhysicalType::STRUCT: {\n \t\t\tauto &child_entries = StructVector::GetEntries(*this);\n \t\t\tfor (auto &child : child_entries) {\n@@ -745,7 +752,6 @@ void Vector::Serialize(idx_t count, Serializer &serializer) {\n \t\t}\n \t\tserializer.WriteData((const_data_ptr_t)flat_mask.GetData(), flat_mask.ValidityMaskSize(count));\n \t}\n-\n \tif (TypeIsConstantSize(type.InternalType())) {\n \t\t// constant size type: simple copy\n \t\tidx_t write_size = GetTypeIdSize(type.InternalType()) * count;\n@@ -763,6 +769,14 @@ void Vector::Serialize(idx_t count, Serializer &serializer) {\n \t\t\t}\n \t\t\tbreak;\n \t\t}\n+\t\tcase PhysicalType::STRUCT: {\n+\t\t\tNormalify(count);\n+\t\t\tauto &entries = StructVector::GetEntries(*this);\n+\t\t\tfor (auto &entry : entries) {\n+\t\t\t\tentry->Serialize(count, serializer);\n+\t\t\t}\n+\t\t\tbreak;\n+\t\t}\n \t\tdefault:\n \t\t\tthrow NotImplementedException(\"Unimplemented variable width type for Vector::Serialize!\");\n \t\t}\n@@ -788,15 +802,39 @@ void Vector::Deserialize(idx_t count, Deserializer &source) {\n \n \t\tVectorOperations::ReadFromStorage(ptr.get(), count, *this);\n \t} else {\n-\t\tauto strings = FlatVector::GetData<string_t>(*this);\n-\t\tfor (idx_t i = 0; i < count; i++) {\n-\t\t\t// read the strings\n-\t\t\tauto str = source.Read<string>();\n-\t\t\t// now add the string to the StringHeap of the vector\n-\t\t\t// and write the pointer into the vector\n-\t\t\tif (validity.RowIsValid(i)) {\n-\t\t\t\tstrings[i] = StringVector::AddStringOrBlob(*this, str);\n+\t\tswitch (type.InternalType()) {\n+\t\tcase PhysicalType::VARCHAR: {\n+\t\t\tauto strings = FlatVector::GetData<string_t>(*this);\n+\t\t\tfor (idx_t i = 0; i < count; i++) {\n+\t\t\t\t// read the strings\n+\t\t\t\tauto str = source.Read<string>();\n+\t\t\t\t// now add the string to the StringHeap of the vector\n+\t\t\t\t// and write the pointer into the vector\n+\t\t\t\tif (validity.RowIsValid(i)) {\n+\t\t\t\t\tstrings[i] = StringVector::AddStringOrBlob(*this, str);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\tbreak;\n+\t\t}\n+\t\tcase PhysicalType::STRUCT: {\n+\t\t\tauto &entries = StructVector::GetEntries(*this);\n+\t\t\tfor (auto &entry : entries) {\n+\t\t\t\tentry->Deserialize(count, source);\n \t\t\t}\n+\t\t\tbreak;\n+\t\t}\n+\t\tdefault:\n+\t\t\tthrow NotImplementedException(\"Unimplemented variable width type for Vector::Deserialize!\");\n+\t\t}\n+\t}\n+}\n+\n+void Vector::SetVectorType(VectorType vector_type) {\n+\tbuffer->SetVectorType(vector_type);\n+\tif (vector_type == VectorType::CONSTANT_VECTOR && GetType().InternalType() == PhysicalType::STRUCT) {\n+\t\tauto &entries = StructVector::GetEntries(*this);\n+\t\tfor (auto &entry : entries) {\n+\t\t\tentry->SetVectorType(vector_type);\n \t\t}\n \t}\n }\n@@ -904,13 +942,17 @@ void Vector::Verify(const SelectionVector &sel, idx_t count) {\n \t\t}\n \t}\n \n-\tif (GetType().InternalType() == PhysicalType::STRUCT || GetType().InternalType() == PhysicalType::MAP) {\n+\tif (GetType().InternalType() == PhysicalType::STRUCT) {\n \t\tauto &child_types = GetType().child_types();\n \t\tD_ASSERT(child_types.size() > 0);\n \t\tif (GetVectorType() == VectorType::FLAT_VECTOR || GetVectorType() == VectorType::CONSTANT_VECTOR) {\n+\t\t\t// create a selection vector of the non-null entries of the struct vector\n \t\t\tauto &children = StructVector::GetEntries(*this);\n \t\t\tD_ASSERT(child_types.size() == children.size());\n \t\t\tfor (idx_t child_idx = 0; child_idx < children.size(); child_idx++) {\n+\t\t\t\tif (GetVectorType() == VectorType::CONSTANT_VECTOR) {\n+\t\t\t\t\tD_ASSERT(children[child_idx]->GetVectorType() == VectorType::CONSTANT_VECTOR);\n+\t\t\t\t}\n \t\t\t\tD_ASSERT(children[child_idx]->GetType() == child_types[child_idx].second);\n \t\t\t\tchildren[child_idx]->Verify(sel, count);\n \t\t\t}\n@@ -954,6 +996,30 @@ void Vector::Verify(idx_t count) {\n \t}\n }\n \n+void ConstantVector::SetNull(Vector &vector, bool is_null) {\n+\tD_ASSERT(vector.GetVectorType() == VectorType::CONSTANT_VECTOR);\n+\tvector.validity.Set(0, !is_null);\n+\tif (is_null && vector.GetType().InternalType() == PhysicalType::STRUCT) {\n+\t\t// set all child entries to null as well\n+\t\tauto &entries = StructVector::GetEntries(vector);\n+\t\tfor (auto &entry : entries) {\n+\t\t\tentry->SetVectorType(VectorType::CONSTANT_VECTOR);\n+\t\t\tConstantVector::SetNull(*entry, is_null);\n+\t\t}\n+\t}\n+}\n+\n+const SelectionVector *ConstantVector::ZeroSelectionVector(idx_t count, SelectionVector &owned_sel) {\n+\tif (count <= STANDARD_VECTOR_SIZE) {\n+\t\treturn &ConstantVector::ZERO_SELECTION_VECTOR;\n+\t}\n+\towned_sel.Initialize(count);\n+\tfor (idx_t i = 0; i < count; i++) {\n+\t\towned_sel.set_index(i, 0);\n+\t}\n+\treturn &owned_sel;\n+}\n+\n string_t StringVector::AddString(Vector &vector, const char *data, idx_t len) {\n \treturn StringVector::AddString(vector, string_t(data, len));\n }\ndiff --git a/src/common/value_operations/comparison_operations.cpp b/src/common/value_operations/comparison_operations.cpp\nindex 4b58daea8c85..f55824ee3a54 100644\n--- a/src/common/value_operations/comparison_operations.cpp\n+++ b/src/common/value_operations/comparison_operations.cpp\n@@ -53,7 +53,6 @@ static bool TemplatedBooleanOperation(const Value &left, const Value &right) {\n \t\treturn OP::Operation(left.value_.interval, right.value_.interval);\n \tcase PhysicalType::VARCHAR:\n \t\treturn OP::Operation(left.str_value, right.str_value);\n-\tcase PhysicalType::MAP:\n \tcase PhysicalType::STRUCT: {\n \t\t// this should be enforced by the type\n \t\tD_ASSERT(left.struct_value.size() == right.struct_value.size());\ndiff --git a/src/common/value_operations/hash.cpp b/src/common/value_operations/hash.cpp\nindex c9abf6533fec..eb624ed6f65b 100644\n--- a/src/common/value_operations/hash.cpp\n+++ b/src/common/value_operations/hash.cpp\n@@ -47,7 +47,6 @@ hash_t ValueOperations::Hash(const Value &op) {\n \t\t}\n \t\treturn hash;\n \t}\n-\tcase PhysicalType::MAP:\n \tcase PhysicalType::STRUCT: {\n \t\thash_t hash = 0;\n \t\tfor (auto &entry : op.struct_value) {\ndiff --git a/src/common/vector_operations/vector_cast.cpp b/src/common/vector_operations/vector_cast.cpp\nindex 94d42e15191e..a581673c7af3 100644\n--- a/src/common/vector_operations/vector_cast.cpp\n+++ b/src/common/vector_operations/vector_cast.cpp\n@@ -634,22 +634,22 @@ static void StructCastSwitch(Vector &source, Vector &result, idx_t count) {\n \t\tauto &source_children = StructVector::GetEntries(source);\n \t\tD_ASSERT(source_children.size() == source.GetType().child_types().size());\n \n-\t\tbool is_constant = true;\n \t\tauto &result_children = StructVector::GetEntries(result);\n \t\tfor (idx_t c_idx = 0; c_idx < result.GetType().child_types().size(); c_idx++) {\n \t\t\tauto &result_child_vector = result_children[c_idx];\n \t\t\tauto &source_child_vector = *source_children[c_idx];\n-\t\t\tif (source_child_vector.GetVectorType() != VectorType::CONSTANT_VECTOR) {\n-\t\t\t\tis_constant = false;\n-\t\t\t}\n \t\t\tif (result_child_vector->GetType() != source_child_vector.GetType()) {\n \t\t\t\tVectorOperations::Cast(source_child_vector, *result_child_vector, count, false);\n \t\t\t} else {\n \t\t\t\tresult_child_vector->Reference(source_child_vector);\n \t\t\t}\n \t\t}\n-\t\tif (is_constant) {\n+\t\tif (source.GetVectorType() == VectorType::CONSTANT_VECTOR) {\n \t\t\tresult.SetVectorType(VectorType::CONSTANT_VECTOR);\n+\t\t\tConstantVector::SetNull(result, ConstantVector::IsNull(source));\n+\t\t} else {\n+\t\t\tsource.Normalify(count);\n+\t\t\tFlatVector::Validity(result) = FlatVector::Validity(source);\n \t\t}\n \n \t\tbreak;\ndiff --git a/src/common/vector_operations/vector_copy.cpp b/src/common/vector_operations/vector_copy.cpp\nindex 3b3e8a40cbe4..ca2ab714907c 100644\n--- a/src/common/vector_operations/vector_copy.cpp\n+++ b/src/common/vector_operations/vector_copy.cpp\n@@ -28,6 +28,9 @@ void VectorOperations::Copy(const Vector &source, Vector &target, const Selectio\n \tD_ASSERT(source_offset <= source_count);\n \tD_ASSERT(target.GetVectorType() == VectorType::FLAT_VECTOR);\n \tD_ASSERT(source.GetType() == target.GetType());\n+\tidx_t copy_count = source_count - source_offset;\n+\n+\tSelectionVector owned_sel;\n \tconst SelectionVector *sel = &sel_p;\n \tswitch (source.GetVectorType()) {\n \tcase VectorType::DICTIONARY_VECTOR: {\n@@ -49,7 +52,7 @@ void VectorOperations::Copy(const Vector &source, Vector &target, const Selectio\n \t\treturn;\n \t}\n \tcase VectorType::CONSTANT_VECTOR:\n-\t\tsel = &ConstantVector::ZERO_SELECTION_VECTOR;\n+\t\tsel = ConstantVector::ZeroSelectionVector(copy_count, owned_sel);\n \t\tbreak; // carry on with below code\n \tcase VectorType::FLAT_VECTOR:\n \t\tbreak;\n@@ -57,7 +60,6 @@ void VectorOperations::Copy(const Vector &source, Vector &target, const Selectio\n \t\tthrow NotImplementedException(\"FIXME unimplemented vector type for VectorOperations::Copy\");\n \t}\n \n-\tidx_t copy_count = source_count - source_offset;\n \tif (copy_count == 0) {\n \t\treturn;\n \t}\n@@ -137,7 +139,6 @@ void VectorOperations::Copy(const Vector &source, Vector &target, const Selectio\n \t\t}\n \t\tbreak;\n \t}\n-\tcase PhysicalType::MAP:\n \tcase PhysicalType::STRUCT: {\n \t\tauto &source_children = StructVector::GetEntries(source);\n \t\tauto &target_children = StructVector::GetEntries(target);\ndiff --git a/src/execution/expression_executor/execute_case.cpp b/src/execution/expression_executor/execute_case.cpp\nindex 47844f7aa8e7..8def4429d621 100644\n--- a/src/execution/expression_executor/execute_case.cpp\n+++ b/src/execution/expression_executor/execute_case.cpp\n@@ -80,6 +80,27 @@ void TemplatedFillLoop(Vector &vector, Vector &result, SelectionVector &sel, sel\n \t}\n }\n \n+void ValidityFillLoop(Vector &vector, Vector &result, SelectionVector &sel, sel_t count) {\n+\tresult.SetVectorType(VectorType::FLAT_VECTOR);\n+\tauto &result_mask = FlatVector::Validity(result);\n+\tif (vector.GetVectorType() == VectorType::CONSTANT_VECTOR) {\n+\t\tif (ConstantVector::IsNull(vector)) {\n+\t\t\tfor (idx_t i = 0; i < count; i++) {\n+\t\t\t\tresult_mask.SetInvalid(sel.get_index(i));\n+\t\t\t}\n+\t\t}\n+\t} else {\n+\t\tVectorData vdata;\n+\t\tvector.Orrify(count, vdata);\n+\t\tfor (idx_t i = 0; i < count; i++) {\n+\t\t\tauto source_idx = vdata.sel->get_index(i);\n+\t\t\tauto res_idx = sel.get_index(i);\n+\n+\t\t\tresult_mask.Set(res_idx, vdata.validity.RowIsValid(source_idx));\n+\t\t}\n+\t}\n+}\n+\n template <class T>\n void TemplatedCaseLoop(Vector &res_true, Vector &res_false, Vector &result, SelectionVector &tside, idx_t tcount,\n                        SelectionVector &fside, idx_t fcount) {\n@@ -87,6 +108,12 @@ void TemplatedCaseLoop(Vector &res_true, Vector &res_false, Vector &result, Sele\n \tTemplatedFillLoop<T>(res_false, result, fside, fcount);\n }\n \n+void ValidityCaseLoop(Vector &res_true, Vector &res_false, Vector &result, SelectionVector &tside, idx_t tcount,\n+                      SelectionVector &fside, idx_t fcount) {\n+\tValidityFillLoop(res_true, result, tside, tcount);\n+\tValidityFillLoop(res_false, result, fside, fcount);\n+}\n+\n void Case(Vector &res_true, Vector &res_false, Vector &result, SelectionVector &tside, idx_t tcount,\n           SelectionVector &fside, idx_t fcount) {\n \tD_ASSERT(res_true.GetType() == res_false.GetType() && res_true.GetType() == result.GetType());\n@@ -131,6 +158,18 @@ void Case(Vector &res_true, Vector &res_false, Vector &result, SelectionVector &\n \t\tStringVector::AddHeapReference(result, res_true);\n \t\tStringVector::AddHeapReference(result, res_false);\n \t\tbreak;\n+\tcase PhysicalType::STRUCT: {\n+\t\tauto &res_true_entries = StructVector::GetEntries(res_true);\n+\t\tauto &res_false_entries = StructVector::GetEntries(res_false);\n+\t\tauto &result_entries = StructVector::GetEntries(result);\n+\t\tD_ASSERT(res_true_entries.size() == res_false_entries.size() &&\n+\t\t         res_true_entries.size() == result_entries.size());\n+\t\tValidityCaseLoop(res_true, res_false, result, tside, tcount, fside, fcount);\n+\t\tfor (idx_t i = 0; i < res_true_entries.size(); i++) {\n+\t\t\tCase(*res_true_entries[i], *res_false_entries[i], *result_entries[i], tside, tcount, fside, fcount);\n+\t\t}\n+\t\tbreak;\n+\t}\n \tcase PhysicalType::LIST: {\n \t\tauto result_vector = make_unique<Vector>(result.GetType().child_types()[0].second);\n \t\tListVector::SetEntry(result, move(result_vector));\ndiff --git a/src/function/aggregate/nested/histogram.cpp b/src/function/aggregate/nested/histogram.cpp\nindex 977d65a9463d..1bd398a28963 100644\n--- a/src/function/aggregate/nested/histogram.cpp\n+++ b/src/function/aggregate/nested/histogram.cpp\n@@ -115,10 +115,15 @@ static void HistogramFinalize(Vector &state_vector, FunctionData *, Vector &resu\n \tauto &child_entries = StructVector::GetEntries(result);\n \tauto &bucket_list = child_entries[0];\n \tauto &count_list = child_entries[1];\n+\n+\tauto &bucket_validity = FlatVector::Validity(*bucket_list);\n+\tauto &count_validity = FlatVector::Validity(*count_list);\n \tfor (idx_t i = 0; i < count; i++) {\n \t\tauto state = states[sdata.sel->get_index(i)];\n \t\tif (!state->hist) {\n \t\t\tmask.SetInvalid(i);\n+\t\t\tbucket_validity.SetInvalid(i);\n+\t\t\tcount_validity.SetInvalid(i);\n \t\t\tcontinue;\n \t\t}\n \t\tfor (auto &entry : *state->hist) {\ndiff --git a/src/function/scalar/nested/map/map.cpp b/src/function/scalar/nested/map/map.cpp\nindex fdc654c665cb..c5366cc52e9e 100644\n--- a/src/function/scalar/nested/map/map.cpp\n+++ b/src/function/scalar/nested/map/map.cpp\n@@ -29,16 +29,21 @@ static void MapFunction(DataChunk &args, ExpressionState &state, Vector &result)\n \t\tauto list_child = make_unique<Vector>(LogicalTypeId::SQLNULL);\n \t\tListVector::SetEntry(*key_vector, move(list_child));\n \t\tListVector::SetListSize(*key_vector, 0);\n-\t\tauto list_data = FlatVector::GetData<list_entry_t>(*key_vector);\n+\t\tkey_vector->SetVectorType(VectorType::CONSTANT_VECTOR);\n+\t\tauto list_data = ConstantVector::GetData<list_entry_t>(*key_vector);\n \t\tlist_data->offset = 0;\n \t\tlist_data->length = 0;\n \n \t\tlist_child = make_unique<Vector>(LogicalTypeId::SQLNULL);\n+\t\tlist_child->SetVectorType(VectorType::CONSTANT_VECTOR);\n \t\tListVector::SetEntry(*value_vector, move(list_child));\n \t\tListVector::SetListSize(*value_vector, 0);\n-\t\tlist_data = FlatVector::GetData<list_entry_t>(*value_vector);\n+\t\tvalue_vector->SetVectorType(VectorType::CONSTANT_VECTOR);\n+\t\tlist_data = ConstantVector::GetData<list_entry_t>(*value_vector);\n \t\tlist_data->offset = 0;\n \t\tlist_data->length = 0;\n+\n+\t\tresult.Verify(args.size());\n \t\treturn;\n \t}\n \ndiff --git a/src/function/scalar/nested/struct_extract.cpp b/src/function/scalar/nested/struct_extract.cpp\nindex 2e912862fffd..01d64674c80b 100644\n--- a/src/function/scalar/nested/struct_extract.cpp\n+++ b/src/function/scalar/nested/struct_extract.cpp\n@@ -2,6 +2,7 @@\n #include \"duckdb/execution/expression_executor.hpp\"\n #include \"duckdb/planner/expression/bound_function_expression.hpp\"\n #include \"duckdb/common/string_util.hpp\"\n+#include \"duckdb/storage/statistics/struct_statistics.hpp\"\n \n namespace duckdb {\n \n@@ -89,9 +90,20 @@ static unique_ptr<FunctionData> StructExtractBind(ClientContext &context, Scalar\n \treturn make_unique<StructExtractBindData>(key, key_index, return_type);\n }\n \n+static unique_ptr<BaseStatistics> PropagateStructExtractStats(ClientContext &context, BoundFunctionExpression &expr,\n+                                                              FunctionData *bind_data,\n+                                                              vector<unique_ptr<BaseStatistics>> &child_stats) {\n+\tif (!child_stats[0]) {\n+\t\treturn nullptr;\n+\t}\n+\tauto &struct_stats = (StructStatistics &)*child_stats[0];\n+\tauto &info = (StructExtractBindData &)*bind_data;\n+\treturn info.index < struct_stats.child_stats.size() ? struct_stats.child_stats[info.index]->Copy() : nullptr;\n+}\n+\n ScalarFunction StructExtractFun::GetFunction() {\n \treturn ScalarFunction(\"struct_extract\", {LogicalType::STRUCT, LogicalType::VARCHAR}, LogicalType::ANY,\n-\t                      StructExtractFunction, false, StructExtractBind);\n+\t                      StructExtractFunction, false, StructExtractBind, nullptr, PropagateStructExtractStats);\n }\n \n void StructExtractFun::RegisterFunction(BuiltinFunctions &set) {\ndiff --git a/src/include/duckdb/common/helper.hpp b/src/include/duckdb/common/helper.hpp\nindex 78389b8343c6..2c5921d412dc 100644\n--- a/src/include/duckdb/common/helper.hpp\n+++ b/src/include/duckdb/common/helper.hpp\n@@ -34,6 +34,20 @@ unique_ptr<S> unique_ptr_cast(unique_ptr<T> src) {\n \treturn unique_ptr<S>(static_cast<S *>(src.release()));\n }\n \n+struct SharedConstructor {\n+\ttemplate <class T, typename... ARGS>\n+\tstatic shared_ptr<T> Create(ARGS &&...args) {\n+\t\treturn make_shared<T>(std::forward<ARGS>(args)...);\n+\t}\n+};\n+\n+struct UniqueConstructor {\n+\ttemplate <class T, typename... ARGS>\n+\tstatic unique_ptr<T> Create(ARGS &&...args) {\n+\t\treturn make_unique<T>(std::forward<ARGS>(args)...);\n+\t}\n+};\n+\n template <typename T>\n T MaxValue(T a, T b) {\n \treturn a > b ? a : b;\ndiff --git a/src/include/duckdb/common/types/validity_mask.hpp b/src/include/duckdb/common/types/validity_mask.hpp\nindex 5958b98224fa..d35ed58c3baa 100644\n--- a/src/include/duckdb/common/types/validity_mask.hpp\n+++ b/src/include/duckdb/common/types/validity_mask.hpp\n@@ -195,7 +195,6 @@ struct TemplatedValidityMask {\n \n \t//! Marks \"count\" entries in the validity mask as invalid (null)\n \tinline void SetAllInvalid(idx_t count) {\n-\t\tD_ASSERT(count <= STANDARD_VECTOR_SIZE);\n \t\tEnsureWritable();\n \t\tfor (idx_t i = 0; i < ValidityBuffer::EntryCount(count); i++) {\n \t\t\tvalidity_mask[i] = 0;\n@@ -204,7 +203,6 @@ struct TemplatedValidityMask {\n \n \t//! Marks \"count\" entries in the validity mask as valid (not null)\n \tinline void SetAllValid(idx_t count) {\n-\t\tD_ASSERT(count <= STANDARD_VECTOR_SIZE);\n \t\tEnsureWritable();\n \t\tfor (idx_t i = 0; i < ValidityBuffer::EntryCount(count); i++) {\n \t\t\tvalidity_mask[i] = ValidityBuffer::MAX_ENTRY;\ndiff --git a/src/include/duckdb/common/types/vector.hpp b/src/include/duckdb/common/types/vector.hpp\nindex e50f7394b637..86094a59068d 100644\n--- a/src/include/duckdb/common/types/vector.hpp\n+++ b/src/include/duckdb/common/types/vector.hpp\n@@ -145,9 +145,7 @@ class Vector {\n \t}\n \n \t// Setters\n-\tinline void SetVectorType(VectorType vector_type) {\n-\t\tbuffer->SetVectorType(vector_type);\n-\t}\n+\tDUCKDB_API void SetVectorType(VectorType vector_type);\n \tinline void SetType(const LogicalType &type) {\n \t\tbuffer->SetType(type);\n \t}\n@@ -200,14 +198,12 @@ struct ConstantVector {\n \t\tD_ASSERT(vector.GetVectorType() == VectorType::CONSTANT_VECTOR);\n \t\treturn !vector.validity.RowIsValid(0);\n \t}\n-\tstatic inline void SetNull(Vector &vector, bool is_null) {\n-\t\tD_ASSERT(vector.GetVectorType() == VectorType::CONSTANT_VECTOR);\n-\t\tvector.validity.Set(0, !is_null);\n-\t}\n+\tDUCKDB_API static void SetNull(Vector &vector, bool is_null);\n \tstatic inline ValidityMask &Validity(Vector &vector) {\n \t\tD_ASSERT(vector.GetVectorType() == VectorType::CONSTANT_VECTOR);\n \t\treturn vector.validity;\n \t}\n+\tDUCKDB_API static const SelectionVector *ZeroSelectionVector(idx_t count, SelectionVector &owned_sel);\n \n \tstatic const sel_t ZERO_VECTOR[STANDARD_VECTOR_SIZE];\n \tstatic const SelectionVector ZERO_SELECTION_VECTOR;\n@@ -279,49 +275,49 @@ struct FlatVector {\n };\n \n struct ListVector {\n-\tstatic const Vector &GetEntry(const Vector &vector);\n-\tstatic Vector &GetEntry(Vector &vector);\n-\tstatic idx_t GetListSize(const Vector &vector);\n-\tstatic void SetListSize(Vector &vec, idx_t size);\n-\tstatic bool HasEntry(const Vector &vector);\n-\tstatic void SetEntry(Vector &vector, unique_ptr<Vector> entry);\n-\tstatic void Append(Vector &target, const Vector &source, idx_t source_size, idx_t source_offset = 0);\n-\tstatic void Append(Vector &target, const Vector &source, const SelectionVector &sel, idx_t source_size,\n-\t                   idx_t source_offset = 0);\n-\tstatic void PushBack(Vector &target, Value &insert);\n-\tstatic void Initialize(Vector &vec);\n-\tstatic vector<idx_t> Search(Vector &list, Value &key, idx_t row);\n-\tstatic Value GetValuesFromOffsets(Vector &list, vector<idx_t> &offsets);\n+\tDUCKDB_API static const Vector &GetEntry(const Vector &vector);\n+\tDUCKDB_API static Vector &GetEntry(Vector &vector);\n+\tDUCKDB_API static idx_t GetListSize(const Vector &vector);\n+\tDUCKDB_API static void SetListSize(Vector &vec, idx_t size);\n+\tDUCKDB_API static bool HasEntry(const Vector &vector);\n+\tDUCKDB_API static void SetEntry(Vector &vector, unique_ptr<Vector> entry);\n+\tDUCKDB_API static void Append(Vector &target, const Vector &source, idx_t source_size, idx_t source_offset = 0);\n+\tDUCKDB_API static void Append(Vector &target, const Vector &source, const SelectionVector &sel, idx_t source_size,\n+\t                              idx_t source_offset = 0);\n+\tDUCKDB_API static void PushBack(Vector &target, Value &insert);\n+\tDUCKDB_API static void Initialize(Vector &vec);\n+\tDUCKDB_API static vector<idx_t> Search(Vector &list, Value &key, idx_t row);\n+\tDUCKDB_API static Value GetValuesFromOffsets(Vector &list, vector<idx_t> &offsets);\n \t//! Share the entry of the other list vector\n-\tstatic void ReferenceEntry(Vector &vector, Vector &other);\n+\tDUCKDB_API static void ReferenceEntry(Vector &vector, Vector &other);\n };\n \n struct StringVector {\n \t//! Add a string to the string heap of the vector (auxiliary data)\n-\tstatic string_t AddString(Vector &vector, const char *data, idx_t len);\n+\tDUCKDB_API static string_t AddString(Vector &vector, const char *data, idx_t len);\n \t//! Add a string to the string heap of the vector (auxiliary data)\n-\tstatic string_t AddString(Vector &vector, const char *data);\n+\tDUCKDB_API static string_t AddString(Vector &vector, const char *data);\n \t//! Add a string to the string heap of the vector (auxiliary data)\n-\tstatic string_t AddString(Vector &vector, string_t data);\n+\tDUCKDB_API static string_t AddString(Vector &vector, string_t data);\n \t//! Add a string to the string heap of the vector (auxiliary data)\n-\tstatic string_t AddString(Vector &vector, const string &data);\n+\tDUCKDB_API static string_t AddString(Vector &vector, const string &data);\n \t//! Add a string or a blob to the string heap of the vector (auxiliary data)\n \t//! This function is the same as ::AddString, except the added data does not need to be valid UTF8\n-\tstatic string_t AddStringOrBlob(Vector &vector, string_t data);\n+\tDUCKDB_API static string_t AddStringOrBlob(Vector &vector, string_t data);\n \t//! Allocates an empty string of the specified size, and returns a writable pointer that can be used to store the\n \t//! result of an operation\n-\tstatic string_t EmptyString(Vector &vector, idx_t len);\n+\tDUCKDB_API static string_t EmptyString(Vector &vector, idx_t len);\n \t//! Adds a reference to a handle that stores strings of this vector\n-\tstatic void AddHandle(Vector &vector, unique_ptr<BufferHandle> handle);\n+\tDUCKDB_API static void AddHandle(Vector &vector, unique_ptr<BufferHandle> handle);\n \t//! Adds a reference to an unspecified vector buffer that stores strings of this vector\n-\tstatic void AddBuffer(Vector &vector, buffer_ptr<VectorBuffer> buffer);\n+\tDUCKDB_API static void AddBuffer(Vector &vector, buffer_ptr<VectorBuffer> buffer);\n \t//! Add a reference from this vector to the string heap of the provided vector\n-\tstatic void AddHeapReference(Vector &vector, Vector &other);\n+\tDUCKDB_API static void AddHeapReference(Vector &vector, Vector &other);\n };\n \n struct StructVector {\n-\tstatic const vector<unique_ptr<Vector>> &GetEntries(const Vector &vector);\n-\tstatic vector<unique_ptr<Vector>> &GetEntries(Vector &vector);\n+\tDUCKDB_API static const vector<unique_ptr<Vector>> &GetEntries(const Vector &vector);\n+\tDUCKDB_API static vector<unique_ptr<Vector>> &GetEntries(Vector &vector);\n };\n \n struct SequenceVector {\ndiff --git a/src/include/duckdb/planner/expression_binder.hpp b/src/include/duckdb/planner/expression_binder.hpp\nindex 03da4d1323a8..f67a2954d7b7 100644\n--- a/src/include/duckdb/planner/expression_binder.hpp\n+++ b/src/include/duckdb/planner/expression_binder.hpp\n@@ -48,6 +48,11 @@ class ExpressionBinder {\n \tExpressionBinder(Binder &binder, ClientContext &context, bool replace_binder = false);\n \tvirtual ~ExpressionBinder();\n \n+\t//! The target type that should result from the binder. If the result is not of this type, a cast to this type will\n+\t//! be added. Defaults to INVALID.\n+\tLogicalType target_type;\n+\n+public:\n \tunique_ptr<Expression> Bind(unique_ptr<ParsedExpression> &expr, LogicalType *result_type = nullptr,\n \t                            bool root_expression = true);\n \n@@ -67,10 +72,6 @@ class ExpressionBinder {\n \n \tbool BindCorrelatedColumns(unique_ptr<ParsedExpression> &expr);\n \n-\t//! The target type that should result from the binder. If the result is not of this type, a cast to this type will\n-\t//! be added. Defaults to INVALID.\n-\tLogicalType target_type;\n-\n \tvoid BindChild(unique_ptr<ParsedExpression> &expr, idx_t depth, string &error);\n \tstatic void ExtractCorrelatedExpressions(Binder &binder, Expression &expr);\n \ndiff --git a/src/include/duckdb/storage/statistics/base_statistics.hpp b/src/include/duckdb/storage/statistics/base_statistics.hpp\nindex 31dcdbe6e354..4f6c50fd97e1 100644\n--- a/src/include/duckdb/storage/statistics/base_statistics.hpp\n+++ b/src/include/duckdb/storage/statistics/base_statistics.hpp\n@@ -12,6 +12,7 @@\n #include \"duckdb/common/types.hpp\"\n #include \"duckdb/common/operator/comparison_operators.hpp\"\n #include \"duckdb/common/enums/expression_type.hpp\"\n+#include \"duckdb/common/types/value.hpp\"\n \n namespace duckdb {\n class Serializer;\ndiff --git a/src/include/duckdb/storage/statistics/string_statistics.hpp b/src/include/duckdb/storage/statistics/string_statistics.hpp\nindex 89b263630354..786431ce8a9d 100644\n--- a/src/include/duckdb/storage/statistics/string_statistics.hpp\n+++ b/src/include/duckdb/storage/statistics/string_statistics.hpp\n@@ -10,6 +10,7 @@\n \n #include \"duckdb/storage/statistics/base_statistics.hpp\"\n #include \"duckdb/common/enums/filter_propagate_result.hpp\"\n+#include \"duckdb/storage/statistics/validity_statistics.hpp\"\n \n namespace duckdb {\n \ndiff --git a/src/include/duckdb/storage/statistics/struct_statistics.hpp b/src/include/duckdb/storage/statistics/struct_statistics.hpp\nnew file mode 100644\nindex 000000000000..4a50438daf58\n--- /dev/null\n+++ b/src/include/duckdb/storage/statistics/struct_statistics.hpp\n@@ -0,0 +1,36 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/storage/statistics/struct_statistics.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#pragma once\n+\n+#include \"duckdb/storage/statistics/base_statistics.hpp\"\n+#include \"duckdb/common/enums/filter_propagate_result.hpp\"\n+#include \"duckdb/storage/statistics/validity_statistics.hpp\"\n+\n+namespace duckdb {\n+class Value;\n+\n+class StructStatistics : public BaseStatistics {\n+public:\n+\texplicit StructStatistics(LogicalType type);\n+\n+\tvector<unique_ptr<BaseStatistics>> child_stats;\n+\n+public:\n+\tvoid Merge(const BaseStatistics &other) override;\n+\tFilterPropagateResult CheckZonemap(ExpressionType comparison_type, const Value &constant);\n+\n+\tunique_ptr<BaseStatistics> Copy() override;\n+\tvoid Serialize(Serializer &serializer) override;\n+\tstatic unique_ptr<BaseStatistics> Deserialize(Deserializer &source, LogicalType type);\n+\tvoid Verify(Vector &vector, idx_t count) override;\n+\n+\tstring ToString() override;\n+};\n+\n+} // namespace duckdb\ndiff --git a/src/include/duckdb/storage/table/column_data.hpp b/src/include/duckdb/storage/table/column_data.hpp\nindex 1210f06f141d..7e5ae913efd4 100644\n--- a/src/include/duckdb/storage/table/column_data.hpp\n+++ b/src/include/duckdb/storage/table/column_data.hpp\n@@ -62,10 +62,12 @@ class ColumnData {\n \t//! Scan the next vector from the column\n \tvirtual void Scan(Transaction &transaction, idx_t vector_index, ColumnScanState &state, Vector &result);\n \tvirtual void ScanCommitted(idx_t vector_index, ColumnScanState &state, Vector &result, bool allow_updates);\n+\tvirtual void ScanCommittedRange(idx_t row_group_start, idx_t offset_in_row_group, idx_t count, Vector &result);\n+\n \t//! Initialize an appending phase for this column\n \tvirtual void InitializeAppend(ColumnAppendState &state);\n \t//! Append a vector of type [type] to the end of the column\n-\tvoid Append(BaseStatistics &stats, ColumnAppendState &state, Vector &vector, idx_t count);\n+\tvirtual void Append(BaseStatistics &stats, ColumnAppendState &state, Vector &vector, idx_t count);\n \tvirtual void AppendData(BaseStatistics &stats, ColumnAppendState &state, VectorData &vdata, idx_t count);\n \t//! Revert a set of appends to the ColumnData\n \tvirtual void RevertAppend(row_t start_row);\n@@ -85,19 +87,25 @@ class ColumnData {\n \tvirtual void CommitDropColumn();\n \n \tvirtual unique_ptr<ColumnCheckpointState> CreateCheckpointState(RowGroup &row_group, TableDataWriter &writer);\n-\tvirtual unique_ptr<ColumnCheckpointState> Checkpoint(RowGroup &row_group, TableDataWriter &writer,\n-\t                                                     idx_t column_idx);\n+\tvirtual unique_ptr<ColumnCheckpointState> Checkpoint(RowGroup &row_group, TableDataWriter &writer);\n+\n+\tvirtual void CheckpointScan(ColumnSegment *segment, ColumnScanState &state, idx_t row_group_start,\n+\t                            idx_t base_row_index, idx_t count, Vector &scan_vector);\n \n \tvirtual void Initialize(PersistentColumnData &column_data);\n \n-\tstatic void BaseDeserialize(DatabaseInstance &db, Deserializer &source, const LogicalType &type,\n-\t                            ColumnData &result);\n+\tvirtual void DeserializeColumn(Deserializer &source);\n \tstatic shared_ptr<ColumnData> Deserialize(DataTableInfo &info, idx_t column_index, idx_t start_row,\n-\t                                          Deserializer &source, const LogicalType &type);\n+\t                                          Deserializer &source, const LogicalType &type, ColumnData *parent);\n \n \tvirtual void GetStorageInfo(idx_t row_group_index, vector<idx_t> col_path, vector<vector<Value>> &result);\n \tvirtual void Verify(RowGroup &parent);\n \n+\tstatic shared_ptr<ColumnData> CreateColumn(DataTableInfo &info, idx_t column_index, idx_t start_row,\n+\t                                           const LogicalType &type, ColumnData *parent = nullptr);\n+\tstatic unique_ptr<ColumnData> CreateColumnUnique(DataTableInfo &info, idx_t column_index, idx_t start_row,\n+\t                                                 const LogicalType &type, ColumnData *parent = nullptr);\n+\n protected:\n \t//! Append a transient segment\n \tvoid AppendTransientSegment(idx_t start_row);\ndiff --git a/src/include/duckdb/storage/table/persistent_table_data.hpp b/src/include/duckdb/storage/table/persistent_table_data.hpp\nindex cdd0d1f9c3c3..7ad186720d1f 100644\n--- a/src/include/duckdb/storage/table/persistent_table_data.hpp\n+++ b/src/include/duckdb/storage/table/persistent_table_data.hpp\n@@ -31,6 +31,12 @@ class StandardPersistentColumnData : public PersistentColumnData {\n \tunique_ptr<PersistentColumnData> validity;\n };\n \n+class StructPersistentColumnData : public PersistentColumnData {\n+public:\n+\tunique_ptr<PersistentColumnData> validity;\n+\tvector<unique_ptr<PersistentColumnData>> child_data;\n+};\n+\n class PersistentTableData {\n public:\n \texplicit PersistentTableData(idx_t column_count);\ndiff --git a/src/include/duckdb/storage/table/standard_column_data.hpp b/src/include/duckdb/storage/table/standard_column_data.hpp\nindex 46e0230c2ca4..07237b5bca9d 100644\n--- a/src/include/duckdb/storage/table/standard_column_data.hpp\n+++ b/src/include/duckdb/storage/table/standard_column_data.hpp\n@@ -44,10 +44,11 @@ class StandardColumnData : public ColumnData {\n \tvoid Initialize(PersistentColumnData &column_data) override;\n \n \tunique_ptr<ColumnCheckpointState> CreateCheckpointState(RowGroup &row_group, TableDataWriter &writer) override;\n-\tunique_ptr<ColumnCheckpointState> Checkpoint(RowGroup &row_group, TableDataWriter &writer,\n-\t                                             idx_t column_idx) override;\n-\tstatic shared_ptr<ColumnData> Deserialize(DataTableInfo &info, idx_t column_index, idx_t start_row,\n-\t                                          Deserializer &source, const LogicalType &type);\n+\tunique_ptr<ColumnCheckpointState> Checkpoint(RowGroup &row_group, TableDataWriter &writer) override;\n+\tvoid CheckpointScan(ColumnSegment *segment, ColumnScanState &state, idx_t row_group_start, idx_t base_row_index,\n+\t                    idx_t count, Vector &scan_vector) override;\n+\n+\tvoid DeserializeColumn(Deserializer &source) override;\n \n \tvoid GetStorageInfo(idx_t row_group_index, vector<idx_t> col_path, vector<vector<Value>> &result) override;\n \ndiff --git a/src/include/duckdb/storage/table/struct_column_data.hpp b/src/include/duckdb/storage/table/struct_column_data.hpp\nnew file mode 100644\nindex 000000000000..01d368ebf466\n--- /dev/null\n+++ b/src/include/duckdb/storage/table/struct_column_data.hpp\n@@ -0,0 +1,56 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/storage/table/struct_column_data.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#pragma once\n+\n+#include \"duckdb/storage/table/column_data.hpp\"\n+#include \"duckdb/storage/table/validity_column_data.hpp\"\n+\n+namespace duckdb {\n+\n+//! Struct column data represents a struct\n+class StructColumnData : public ColumnData {\n+public:\n+\tStructColumnData(DataTableInfo &info, idx_t column_index, idx_t start_row, LogicalType type,\n+\t                 ColumnData *parent = nullptr);\n+\n+\t//! The sub-columns of the struct\n+\tvector<unique_ptr<ColumnData>> sub_columns;\n+\t//! The validity column data of the struct\n+\tValidityColumnData validity;\n+\n+public:\n+\tbool CheckZonemap(ColumnScanState &state, TableFilter &filter) override;\n+\tvoid InitializeScan(ColumnScanState &state) override;\n+\tvoid InitializeScanWithOffset(ColumnScanState &state, idx_t row_idx) override;\n+\tvoid Scan(Transaction &transaction, idx_t vector_index, ColumnScanState &state, Vector &result) override;\n+\tvoid ScanCommitted(idx_t vector_index, ColumnScanState &state, Vector &result, bool allow_updates) override;\n+\tvoid InitializeAppend(ColumnAppendState &state) override;\n+\tvoid Append(BaseStatistics &stats, ColumnAppendState &state, Vector &vector, idx_t count) override;\n+\tvoid RevertAppend(row_t start_row) override;\n+\tvoid Fetch(ColumnScanState &state, row_t row_id, Vector &result) override;\n+\tvoid FetchRow(Transaction &transaction, ColumnFetchState &state, row_t row_id, Vector &result,\n+\t              idx_t result_idx) override;\n+\tvoid Update(Transaction &transaction, idx_t column_index, Vector &update_vector, row_t *row_ids,\n+\t            idx_t update_count) override;\n+\tvoid UpdateColumn(Transaction &transaction, const vector<column_t> &column_path, Vector &update_vector,\n+\t                  row_t *row_ids, idx_t update_count, idx_t depth) override;\n+\tunique_ptr<BaseStatistics> GetUpdateStatistics() override;\n+\n+\tvoid CommitDropColumn() override;\n+\tvoid Initialize(PersistentColumnData &column_data) override;\n+\n+\tunique_ptr<ColumnCheckpointState> CreateCheckpointState(RowGroup &row_group, TableDataWriter &writer) override;\n+\tunique_ptr<ColumnCheckpointState> Checkpoint(RowGroup &row_group, TableDataWriter &writer) override;\n+\n+\tvoid DeserializeColumn(Deserializer &source) override;\n+\n+\tvoid GetStorageInfo(idx_t row_group_index, vector<idx_t> col_path, vector<vector<Value>> &result) override;\n+};\n+\n+} // namespace duckdb\ndiff --git a/src/planner/expression_binder.cpp b/src/planner/expression_binder.cpp\nindex 2d3ef525c421..25091c718954 100644\n--- a/src/planner/expression_binder.cpp\n+++ b/src/planner/expression_binder.cpp\n@@ -111,6 +111,45 @@ void ExpressionBinder::ExtractCorrelatedExpressions(Binder &binder, Expression &\n \t                                      [&](Expression &child) { ExtractCorrelatedExpressions(binder, child); });\n }\n \n+static bool ContainsNullType(const LogicalType &type) {\n+\tswitch (type.id()) {\n+\tcase LogicalTypeId::STRUCT:\n+\tcase LogicalTypeId::MAP:\n+\tcase LogicalTypeId::LIST: {\n+\t\tauto &child_types = type.child_types();\n+\t\tfor (auto &child_type : child_types) {\n+\t\t\tif (ContainsNullType(child_type.second)) {\n+\t\t\t\treturn true;\n+\t\t\t}\n+\t\t}\n+\t\treturn false;\n+\t}\n+\tcase LogicalTypeId::SQLNULL:\n+\t\treturn true;\n+\tdefault:\n+\t\treturn false;\n+\t}\n+}\n+\n+static void ExchangeNullType(LogicalType &type) {\n+\tswitch (type.id()) {\n+\tcase LogicalTypeId::STRUCT:\n+\tcase LogicalTypeId::MAP:\n+\tcase LogicalTypeId::LIST: {\n+\t\tauto &child_types = type.child_types();\n+\t\tfor (auto &child_type : child_types) {\n+\t\t\tExchangeNullType((LogicalType &)child_type.second);\n+\t\t}\n+\t\tbreak;\n+\t}\n+\tcase LogicalTypeId::SQLNULL:\n+\t\ttype = LogicalType::INTEGER;\n+\t\tbreak;\n+\tdefault:\n+\t\tbreak;\n+\t}\n+}\n+\n unique_ptr<Expression> ExpressionBinder::Bind(unique_ptr<ParsedExpression> &expr, LogicalType *result_type,\n                                               bool root_expression) {\n \t// bind the main expression\n@@ -131,10 +170,12 @@ unique_ptr<Expression> ExpressionBinder::Bind(unique_ptr<ParsedExpression> &expr\n \t\t// the binder has a specific target type: add a cast to that type\n \t\tresult = BoundCastExpression::AddCastToType(move(result), target_type);\n \t} else {\n-\t\tif (result->return_type.id() == LogicalTypeId::SQLNULL) {\n-\t\t\t// SQL NULL type is only used internally in the binder\n-\t\t\t// cast to INTEGER if we encounter it outside of the binder\n-\t\t\tresult = BoundCastExpression::AddCastToType(move(result), LogicalType::INTEGER);\n+\t\t// SQL NULL type is only used internally in the binder\n+\t\t// cast to INTEGER if we encounter it outside of the binder\n+\t\tif (ContainsNullType(result->return_type)) {\n+\t\t\tauto result_type = result->return_type;\n+\t\t\tExchangeNullType(result_type);\n+\t\t\tresult = BoundCastExpression::AddCastToType(move(result), result_type);\n \t\t}\n \t}\n \tif (result_type) {\ndiff --git a/src/storage/numeric_segment.cpp b/src/storage/numeric_segment.cpp\nindex c62dae7cb00d..56d09b24acda 100644\n--- a/src/storage/numeric_segment.cpp\n+++ b/src/storage/numeric_segment.cpp\n@@ -9,6 +9,7 @@\n #include \"duckdb/common/vector_size.hpp\"\n #include \"duckdb/storage/statistics/numeric_statistics.hpp\"\n #include \"duckdb/planner/table_filter.hpp\"\n+#include \"duckdb/common/types/null_value.hpp\"\n \n namespace duckdb {\n \n@@ -100,6 +101,10 @@ static void AppendLoop(SegmentStatistics &stats, data_ptr_t target, idx_t target\n \t\t\tif (!is_null) {\n \t\t\t\tNumericStatistics::Update<T>(stats, sdata[source_idx]);\n \t\t\t\ttdata[target_idx] = sdata[source_idx];\n+\t\t\t} else {\n+\t\t\t\t// we insert a NullValue<T> in the null gap for debuggability\n+\t\t\t\t// this value should never be used or read anywhere\n+\t\t\t\ttdata[target_idx] = NullValue<T>();\n \t\t\t}\n \t\t}\n \t} else {\ndiff --git a/src/storage/statistics/CMakeLists.txt b/src/storage/statistics/CMakeLists.txt\nindex f6b530aa718f..5d7adf479cf9 100644\n--- a/src/storage/statistics/CMakeLists.txt\n+++ b/src/storage/statistics/CMakeLists.txt\n@@ -5,6 +5,7 @@ add_library_unity(\n   numeric_statistics.cpp\n   segment_statistics.cpp\n   string_statistics.cpp\n+  struct_statistics.cpp\n   validity_statistics.cpp)\n set(ALL_OBJECT_FILES\n     ${ALL_OBJECT_FILES} $<TARGET_OBJECTS:duckdb_storage_statistics>\ndiff --git a/src/storage/statistics/base_statistics.cpp b/src/storage/statistics/base_statistics.cpp\nindex a5de988483e8..8bec42243686 100644\n--- a/src/storage/statistics/base_statistics.cpp\n+++ b/src/storage/statistics/base_statistics.cpp\n@@ -1,5 +1,6 @@\n #include \"duckdb/storage/statistics/numeric_statistics.hpp\"\n #include \"duckdb/storage/statistics/string_statistics.hpp\"\n+#include \"duckdb/storage/statistics/struct_statistics.hpp\"\n #include \"duckdb/common/serializer.hpp\"\n #include \"duckdb/common/exception.hpp\"\n #include \"duckdb/common/string_util.hpp\"\n@@ -61,9 +62,13 @@ unique_ptr<BaseStatistics> BaseStatistics::CreateEmpty(LogicalType type) {\n \t\treturn make_unique<NumericStatistics>(move(type));\n \tcase PhysicalType::VARCHAR:\n \t\treturn make_unique<StringStatistics>(move(type));\n+\tcase PhysicalType::STRUCT:\n+\t\treturn make_unique<StructStatistics>(move(type));\n \tcase PhysicalType::INTERVAL:\n \tdefault:\n-\t\treturn make_unique<BaseStatistics>(move(type));\n+\t\tauto base_stats = make_unique<BaseStatistics>(move(type));\n+\t\tbase_stats->validity_stats = make_unique<ValidityStatistics>(false);\n+\t\treturn base_stats;\n \t}\n }\n \n@@ -94,15 +99,16 @@ unique_ptr<BaseStatistics> BaseStatistics::Deserialize(Deserializer &source, Log\n \tcase PhysicalType::VARCHAR:\n \t\tresult = StringStatistics::Deserialize(source, move(type));\n \t\tbreak;\n+\tcase PhysicalType::STRUCT:\n+\t\tresult = StructStatistics::Deserialize(source, move(type));\n+\t\tbreak;\n \tcase PhysicalType::INTERVAL:\n \t\tresult = make_unique<BaseStatistics>(move(type));\n \t\tbreak;\n \tdefault:\n \t\tthrow InternalException(\"Unimplemented type for statistics deserialization\");\n \t}\n-\tif (!can_have_null) {\n-\t\tresult->validity_stats = make_unique<ValidityStatistics>(can_have_null);\n-\t}\n+\tresult->validity_stats = make_unique<ValidityStatistics>(can_have_null);\n \treturn result;\n }\n \ndiff --git a/src/storage/statistics/numeric_statistics.cpp b/src/storage/statistics/numeric_statistics.cpp\nindex 4fadd058cd87..ad9980a44bfd 100644\n--- a/src/storage/statistics/numeric_statistics.cpp\n+++ b/src/storage/statistics/numeric_statistics.cpp\n@@ -77,6 +77,7 @@ void NumericStatistics::Update<interval_t>(SegmentStatistics &stats, interval_t\n NumericStatistics::NumericStatistics(LogicalType type_p) : BaseStatistics(move(type_p)) {\n \tmin = Value::MaximumValue(type);\n \tmax = Value::MinimumValue(type);\n+\tvalidity_stats = make_unique<ValidityStatistics>(false);\n }\n \n NumericStatistics::NumericStatistics(LogicalType type_p, Value min_p, Value max_p)\n@@ -174,8 +175,8 @@ unique_ptr<BaseStatistics> NumericStatistics::Deserialize(Deserializer &source,\n }\n \n string NumericStatistics::ToString() {\n-\treturn StringUtil::Format(\"Numeric Statistics<%s> %s[Min: %s, Max: %s]\", type.ToString(),\n-\t                          validity_stats ? validity_stats->ToString() : \"\", min.ToString(), max.ToString());\n+\treturn StringUtil::Format(\"[Min: %s, Max: %s]%s\", min.ToString(), max.ToString(),\n+\t                          validity_stats ? validity_stats->ToString() : \"\");\n }\n \n template <class T>\ndiff --git a/src/storage/statistics/string_statistics.cpp b/src/storage/statistics/string_statistics.cpp\nindex 9eba9cddabc9..b6768761ee08 100644\n--- a/src/storage/statistics/string_statistics.cpp\n+++ b/src/storage/statistics/string_statistics.cpp\n@@ -14,6 +14,7 @@ StringStatistics::StringStatistics(LogicalType type_p) : BaseStatistics(move(typ\n \tmax_string_length = 0;\n \thas_unicode = false;\n \thas_overflow_strings = false;\n+\tvalidity_stats = make_unique<ValidityStatistics>(false);\n }\n \n unique_ptr<BaseStatistics> StringStatistics::Copy() {\n@@ -146,24 +147,24 @@ FilterPropagateResult StringStatistics::CheckZonemap(ExpressionType comparison_t\n }\n \n static idx_t GetValidMinMaxSubstring(data_ptr_t data) {\n-\tidx_t len = 0;\n \tfor (idx_t i = 0; i < StringStatistics::MAX_STRING_MINMAX_SIZE; i++) {\n \t\tif (data[i] == '\\0') {\n \t\t\treturn i;\n \t\t}\n-\t\tif ((data[i] & 0xC0) != 0x80) {\n-\t\t\tlen = i;\n+\t\tif ((data[i] & 0x80) != 0) {\n+\t\t\treturn i;\n \t\t}\n \t}\n-\treturn len;\n+\treturn StringStatistics::MAX_STRING_MINMAX_SIZE;\n }\n \n string StringStatistics::ToString() {\n \tidx_t min_len = GetValidMinMaxSubstring(min);\n \tidx_t max_len = GetValidMinMaxSubstring(max);\n-\treturn StringUtil::Format(\"String Statistics %s[Min: %s, Max: %s, Has Unicode: %s, Max String Length: %lld]\",\n-\t                          validity_stats ? validity_stats->ToString() : \"\", string((const char *)min, min_len),\n-\t                          string((const char *)max, max_len), has_unicode ? \"true\" : \"false\", max_string_length);\n+\treturn StringUtil::Format(\"[Min: %s, Max: %s, Has Unicode: %s, Max String Length: %lld]%s\",\n+\t                          string((const char *)min, min_len), string((const char *)max, max_len),\n+\t                          has_unicode ? \"true\" : \"false\", max_string_length,\n+\t                          validity_stats ? validity_stats->ToString() : \"\");\n }\n \n void StringStatistics::Verify(Vector &vector, idx_t count) {\ndiff --git a/src/storage/statistics/struct_statistics.cpp b/src/storage/statistics/struct_statistics.cpp\nnew file mode 100644\nindex 000000000000..3b11764abbe0\n--- /dev/null\n+++ b/src/storage/statistics/struct_statistics.cpp\n@@ -0,0 +1,89 @@\n+#include \"duckdb/storage/statistics/struct_statistics.hpp\"\n+#include \"duckdb/common/types/vector.hpp\"\n+\n+namespace duckdb {\n+\n+StructStatistics::StructStatistics(LogicalType type_p) : BaseStatistics(move(type_p)) {\n+\tD_ASSERT(type.InternalType() == PhysicalType::STRUCT);\n+\n+\tauto &child_types = type.child_types();\n+\tchild_stats.resize(child_types.size());\n+\tfor (idx_t i = 0; i < child_types.size(); i++) {\n+\t\tchild_stats[i] = BaseStatistics::CreateEmpty(child_types[i].second);\n+\t}\n+\tvalidity_stats = make_unique<ValidityStatistics>(false);\n+}\n+\n+void StructStatistics::Merge(const BaseStatistics &other_p) {\n+\tBaseStatistics::Merge(other_p);\n+\n+\tauto &other = (const StructStatistics &)other_p;\n+\tD_ASSERT(other.child_stats.size() == child_stats.size());\n+\tfor (idx_t i = 0; i < child_stats.size(); i++) {\n+\t\tif (child_stats[i] && other.child_stats[i]) {\n+\t\t\tchild_stats[i]->Merge(*other.child_stats[i]);\n+\t\t}\n+\t}\n+}\n+\n+FilterPropagateResult StructStatistics::CheckZonemap(ExpressionType comparison_type, const Value &constant) {\n+\t// for now...\n+\treturn FilterPropagateResult::NO_PRUNING_POSSIBLE;\n+}\n+\n+unique_ptr<BaseStatistics> StructStatistics::Copy() {\n+\tauto copy = make_unique<StructStatistics>(type);\n+\tif (validity_stats) {\n+\t\tcopy->validity_stats = validity_stats->Copy();\n+\t}\n+\tfor (idx_t i = 0; i < child_stats.size(); i++) {\n+\t\tif (child_stats[i]) {\n+\t\t\tcopy->child_stats[i] = child_stats[i]->Copy();\n+\t\t}\n+\t}\n+\treturn move(copy);\n+}\n+\n+void StructStatistics::Serialize(Serializer &serializer) {\n+\tBaseStatistics::Serialize(serializer);\n+\tfor (idx_t i = 0; i < child_stats.size(); i++) {\n+\t\tD_ASSERT(child_stats[i]);\n+\t\tchild_stats[i]->Serialize(serializer);\n+\t}\n+}\n+\n+unique_ptr<BaseStatistics> StructStatistics::Deserialize(Deserializer &source, LogicalType type) {\n+\tD_ASSERT(type.id() == LogicalTypeId::STRUCT);\n+\tauto result = make_unique<StructStatistics>(move(type));\n+\tauto &child_types = result->type.child_types();\n+\tfor (idx_t i = 0; i < child_types.size(); i++) {\n+\t\tresult->child_stats[i] = BaseStatistics::Deserialize(source, child_types[i].second);\n+\t}\n+\treturn move(result);\n+}\n+\n+string StructStatistics::ToString() {\n+\tstring result;\n+\tresult += \" {\";\n+\tauto &child_types = type.child_types();\n+\tfor (idx_t i = 0; i < child_types.size(); i++) {\n+\t\tif (i > 0) {\n+\t\t\tresult += \", \";\n+\t\t}\n+\t\tresult += child_types[i].first + \": \" + (child_stats[i] ? child_stats[i]->ToString() : \"No Stats\");\n+\t}\n+\tresult += \"}\";\n+\tresult += validity_stats ? validity_stats->ToString() : \"\";\n+\treturn result;\n+}\n+\n+void StructStatistics::Verify(Vector &vector, idx_t count) {\n+\tBaseStatistics::Verify(vector, count);\n+\n+\tauto &child_entries = StructVector::GetEntries(vector);\n+\tfor (idx_t i = 0; i < child_entries.size(); i++) {\n+\t\tchild_stats[i]->Verify(*child_entries[i], count);\n+\t}\n+}\n+\n+} // namespace duckdb\ndiff --git a/src/storage/table/CMakeLists.txt b/src/storage/table/CMakeLists.txt\nindex dfafa0b01755..dc00dc41342d 100644\n--- a/src/storage/table/CMakeLists.txt\n+++ b/src/storage/table/CMakeLists.txt\n@@ -10,6 +10,7 @@ add_library_unity(\n   persistent_segment.cpp\n   row_group.cpp\n   standard_column_data.cpp\n+  struct_column_data.cpp\n   transient_segment.cpp\n   validity_column_data.cpp\n   validity_segment.cpp)\ndiff --git a/src/storage/table/column_data.cpp b/src/storage/table/column_data.cpp\nindex 287f0ccd8718..b602d345d9b3 100644\n--- a/src/storage/table/column_data.cpp\n+++ b/src/storage/table/column_data.cpp\n@@ -9,6 +9,7 @@\n #include \"duckdb/planner/table_filter.hpp\"\n #include \"duckdb/common/vector_operations/vector_operations.hpp\"\n #include \"duckdb/storage/table/validity_segment.hpp\"\n+#include \"duckdb/storage/table/struct_column_data.hpp\"\n \n #include \"duckdb/storage/numeric_segment.hpp\"\n #include \"duckdb/storage/string_segment.hpp\"\n@@ -111,6 +112,15 @@ void ColumnData::ScanCommitted(idx_t vector_index, ColumnScanState &state, Vecto\n \t}\n }\n \n+void ColumnData::ScanCommittedRange(idx_t row_group_start, idx_t offset_in_row_group, idx_t count, Vector &result) {\n+\tColumnScanState child_state;\n+\tInitializeScanWithOffset(child_state, row_group_start + offset_in_row_group);\n+\tScanVector(child_state, result);\n+\tif (updates) {\n+\t\tupdates->FetchCommittedRange(offset_in_row_group, count, result);\n+\t}\n+}\n+\n void ColumnScanState::Next() {\n \t//! There is no column segment\n \tif (!current) {\n@@ -379,8 +389,15 @@ void ColumnCheckpointState::FlushToDisk() {\n \t}\n }\n \n-unique_ptr<ColumnCheckpointState> ColumnData::Checkpoint(RowGroup &row_group, TableDataWriter &writer,\n-                                                         idx_t column_idx) {\n+void ColumnData::CheckpointScan(ColumnSegment *segment, ColumnScanState &state, idx_t row_group_start,\n+                                idx_t base_row_index, idx_t count, Vector &scan_vector) {\n+\tsegment->Scan(state, base_row_index, count, scan_vector, 0);\n+\tif (updates) {\n+\t\tupdates->FetchCommittedRange(segment->start - row_group_start + base_row_index, count, scan_vector);\n+\t}\n+}\n+\n+unique_ptr<ColumnCheckpointState> ColumnData::Checkpoint(RowGroup &row_group, TableDataWriter &writer) {\n \t// scan the segments of the column data\n \t// set up the checkpoint state\n \tauto checkpoint_state = CreateCheckpointState(row_group, writer);\n@@ -394,7 +411,9 @@ unique_ptr<ColumnCheckpointState> ColumnData::Checkpoint(RowGroup &row_group, Ta\n \n \tauto &block_manager = BlockManager::GetBlockManager(GetDatabase());\n \tcheckpoint_state->CreateEmptySegment();\n-\tVector intermediate(row_group.columns[column_idx]->type);\n+\n+\tbool is_validity = type.id() == LogicalTypeId::VALIDITY;\n+\tVector intermediate(is_validity ? LogicalType::BOOLEAN : type, true, is_validity);\n \t// we create a new segment tree with all the new segments\n \t// we do this by scanning the current segments of the column and checking for changes\n \t// if there are any changes (e.g. updates or deletes) we write the new changes\n@@ -456,10 +475,8 @@ unique_ptr<ColumnCheckpointState> ColumnData::Checkpoint(RowGroup &row_group, Ta\n \n \t\t\tidx_t count = MinValue<idx_t>(segment->count - base_row_index, STANDARD_VECTOR_SIZE);\n \t\t\tstate.row_index = segment->start + base_row_index;\n-\t\t\tsegment->Scan(state, base_row_index, count, scan_vector, 0);\n-\t\t\tif (updates) {\n-\t\t\t\tupdates->FetchCommittedRange(segment->start - row_group.start + base_row_index, count, scan_vector);\n-\t\t\t}\n+\n+\t\t\tCheckpointScan(segment, state, row_group.start, base_row_index, count, scan_vector);\n \n \t\t\tcheckpoint_state->AppendData(scan_vector, count);\n \t\t}\n@@ -487,8 +504,7 @@ void ColumnData::Initialize(PersistentColumnData &column_data) {\n \t}\n }\n \n-void ColumnData::BaseDeserialize(DatabaseInstance &db, Deserializer &source, const LogicalType &type,\n-                                 ColumnData &result) {\n+void ColumnData::DeserializeColumn(Deserializer &source) {\n \t// load the data pointers for the column\n \tidx_t data_pointer_count = source.Read<idx_t>();\n \tfor (idx_t data_ptr = 0; data_ptr < data_pointer_count; data_ptr++) {\n@@ -501,16 +517,18 @@ void ColumnData::BaseDeserialize(DatabaseInstance &db, Deserializer &source, con\n \t\tdata_pointer.statistics = BaseStatistics::Deserialize(source, type);\n \n \t\t// create a persistent segment\n-\t\tauto segment = make_unique<PersistentSegment>(db, data_pointer.block_pointer.block_id,\n+\t\tauto segment = make_unique<PersistentSegment>(GetDatabase(), data_pointer.block_pointer.block_id,\n \t\t                                              data_pointer.block_pointer.offset, type, data_pointer.row_start,\n \t\t                                              data_pointer.tuple_count, move(data_pointer.statistics));\n-\t\tresult.data.AppendSegment(move(segment));\n+\t\tdata.AppendSegment(move(segment));\n \t}\n }\n \n shared_ptr<ColumnData> ColumnData::Deserialize(DataTableInfo &info, idx_t column_index, idx_t start_row,\n-                                               Deserializer &source, const LogicalType &type) {\n-\treturn StandardColumnData::Deserialize(info, column_index, start_row, source, type);\n+                                               Deserializer &source, const LogicalType &type, ColumnData *parent) {\n+\tauto entry = ColumnData::CreateColumn(info, column_index, start_row, type, parent);\n+\tentry->DeserializeColumn(source);\n+\treturn entry;\n }\n \n void ColumnData::GetStorageInfo(idx_t row_group_index, vector<idx_t> col_path, vector<vector<Value>> &result) {\n@@ -588,9 +606,32 @@ void ColumnData::Verify(RowGroup &parent) {\n \t\t\troot = root->next.get();\n \t\t}\n \t} else {\n-\t\tD_ASSERT(parent.count == 0);\n+\t\tif (type.id() != LogicalTypeId::STRUCT) {\n+\t\t\tD_ASSERT(parent.count == 0);\n+\t\t}\n \t}\n #endif\n }\n \n+template <class RET, class OP>\n+static RET CreateColumnInternal(DataTableInfo &info, idx_t column_index, idx_t start_row, const LogicalType &type,\n+                                ColumnData *parent) {\n+\tif (type.InternalType() == PhysicalType::STRUCT) {\n+\t\treturn OP::template Create<StructColumnData>(info, column_index, start_row, type, parent);\n+\t} else if (type.id() == LogicalTypeId::VALIDITY) {\n+\t\treturn OP::template Create<ValidityColumnData>(info, column_index, start_row, parent);\n+\t}\n+\treturn OP::template Create<StandardColumnData>(info, column_index, start_row, type, parent);\n+}\n+\n+shared_ptr<ColumnData> ColumnData::CreateColumn(DataTableInfo &info, idx_t column_index, idx_t start_row,\n+                                                const LogicalType &type, ColumnData *parent) {\n+\treturn CreateColumnInternal<shared_ptr<ColumnData>, SharedConstructor>(info, column_index, start_row, type, parent);\n+}\n+\n+unique_ptr<ColumnData> ColumnData::CreateColumnUnique(DataTableInfo &info, idx_t column_index, idx_t start_row,\n+                                                      const LogicalType &type, ColumnData *parent) {\n+\treturn CreateColumnInternal<unique_ptr<ColumnData>, UniqueConstructor>(info, column_index, start_row, type, parent);\n+}\n+\n } // namespace duckdb\ndiff --git a/src/storage/table/row_group.cpp b/src/storage/table/row_group.cpp\nindex e79d2edc0afc..230ca417f029 100644\n--- a/src/storage/table/row_group.cpp\n+++ b/src/storage/table/row_group.cpp\n@@ -33,7 +33,7 @@ RowGroup::RowGroup(DatabaseInstance &db, DataTableInfo &table_info, const vector\n \t\tauto &block_pointer = pointer.data_pointers[i];\n \t\tMetaBlockReader column_data_reader(db, block_pointer.block_id);\n \t\tcolumn_data_reader.offset = block_pointer.offset;\n-\t\tthis->columns.push_back(ColumnData::Deserialize(table_info, i, start, column_data_reader, types[i]));\n+\t\tthis->columns.push_back(ColumnData::Deserialize(table_info, i, start, column_data_reader, types[i], nullptr));\n \t}\n \n \t// set up the statistics\n@@ -51,7 +51,7 @@ RowGroup::~RowGroup() {\n void RowGroup::InitializeEmpty(const vector<LogicalType> &types) {\n \t// set up the segment trees for the column segments\n \tfor (idx_t i = 0; i < types.size(); i++) {\n-\t\tauto column_data = make_shared<StandardColumnData>(GetTableInfo(), i, start, types[i]);\n+\t\tauto column_data = ColumnData::CreateColumn(GetTableInfo(), i, start, types[i]);\n \t\tstats.push_back(make_shared<SegmentStatistics>(types[i]));\n \t\tcolumns.push_back(move(column_data));\n \t}\n@@ -111,7 +111,7 @@ unique_ptr<RowGroup> RowGroup::AlterType(ClientContext &context, const LogicalTy\n \tVerify();\n \n \t// construct a new column data for this type\n-\tauto column_data = make_shared<StandardColumnData>(GetTableInfo(), changed_idx, start, target_type);\n+\tauto column_data = ColumnData::CreateColumn(GetTableInfo(), changed_idx, start, target_type);\n \n \tColumnAppendState append_state;\n \tcolumn_data->InitializeAppend(append_state);\n@@ -156,7 +156,7 @@ unique_ptr<RowGroup> RowGroup::AddColumn(ClientContext &context, ColumnDefinitio\n \tVerify();\n \n \t// construct a new column data for the new column\n-\tauto added_column = make_shared<StandardColumnData>(GetTableInfo(), columns.size(), start, new_column.type);\n+\tauto added_column = ColumnData::CreateColumn(GetTableInfo(), columns.size(), start, new_column.type);\n \n \tauto added_col_stats = make_shared<SegmentStatistics>(new_column.type);\n \tidx_t rows_to_write = this->count;\n@@ -568,7 +568,7 @@ RowGroupPointer RowGroup::Checkpoint(TableDataWriter &writer, vector<unique_ptr<\n \t// checkpoint the individual columns of the row group\n \tfor (idx_t column_idx = 0; column_idx < columns.size(); column_idx++) {\n \t\tauto &column = columns[column_idx];\n-\t\tauto checkpoint_state = column->Checkpoint(*this, writer, column_idx);\n+\t\tauto checkpoint_state = column->Checkpoint(*this, writer);\n \t\tD_ASSERT(checkpoint_state);\n \n \t\tauto stats = checkpoint_state->GetStatistics();\n@@ -590,7 +590,7 @@ RowGroupPointer RowGroup::Checkpoint(TableDataWriter &writer, vector<unique_ptr<\n \n \t\t// store the stats and the data pointers in the row group pointers\n \t\trow_group_pointer.data_pointers.push_back(pointer);\n-\t\trow_group_pointer.statistics.push_back(move(state->global_stats));\n+\t\trow_group_pointer.statistics.push_back(state->GetStatistics());\n \n \t\t// now flush the actual column data to disk\n \t\tstate->FlushToDisk();\n@@ -636,6 +636,9 @@ shared_ptr<VersionNode> RowGroup::DeserializeDeletes(Deserializer &source) {\n \tauto version_info = make_shared<VersionNode>();\n \tfor (idx_t i = 0; i < chunk_count; i++) {\n \t\tidx_t vector_index = source.Read<idx_t>();\n+\t\tif (vector_index >= RowGroup::ROW_GROUP_VECTOR_COUNT) {\n+\t\t\tthrow Exception(\"In DeserializeDeletes, vector_index is out of range for the row group. Corrupted file?\");\n+\t\t}\n \t\tversion_info->info[vector_index] = ChunkInfo::Deserialize(source);\n \t}\n \treturn version_info;\ndiff --git a/src/storage/table/standard_column_data.cpp b/src/storage/table/standard_column_data.cpp\nindex 800b9feb192f..7da88be2c271 100644\n--- a/src/storage/table/standard_column_data.cpp\n+++ b/src/storage/table/standard_column_data.cpp\n@@ -154,12 +154,14 @@ struct StandardColumnCheckpointState : public ColumnCheckpointState {\n \t    : ColumnCheckpointState(row_group, column_data, writer) {\n \t}\n \n+\tunique_ptr<ColumnCheckpointState> validity_state;\n+\n+public:\n \tunique_ptr<BaseStatistics> GetStatistics() override {\n \t\tauto stats = global_stats->Copy();\n \t\tstats->validity_stats = validity_state->GetStatistics();\n \t\treturn stats;\n \t}\n-\tunique_ptr<ColumnCheckpointState> validity_state;\n \n \tvoid FlushToDisk() override {\n \t\tColumnCheckpointState::FlushToDisk();\n@@ -172,26 +174,31 @@ unique_ptr<ColumnCheckpointState> StandardColumnData::CreateCheckpointState(RowG\n \treturn make_unique<StandardColumnCheckpointState>(row_group, *this, writer);\n }\n \n-unique_ptr<ColumnCheckpointState> StandardColumnData::Checkpoint(RowGroup &row_group, TableDataWriter &writer,\n-                                                                 idx_t column_idx) {\n-\tauto base_state = ColumnData::Checkpoint(row_group, writer, column_idx);\n+unique_ptr<ColumnCheckpointState> StandardColumnData::Checkpoint(RowGroup &row_group, TableDataWriter &writer) {\n+\tauto validity_state = validity.Checkpoint(row_group, writer);\n+\tauto base_state = ColumnData::Checkpoint(row_group, writer);\n \tauto &checkpoint_state = (StandardColumnCheckpointState &)*base_state;\n-\tcheckpoint_state.validity_state = validity.Checkpoint(row_group, writer, column_idx);\n+\tcheckpoint_state.validity_state = move(validity_state);\n \treturn base_state;\n }\n \n+void StandardColumnData::CheckpointScan(ColumnSegment *segment, ColumnScanState &state, idx_t row_group_start,\n+                                        idx_t base_row_index, idx_t count, Vector &scan_vector) {\n+\tColumnData::CheckpointScan(segment, state, row_group_start, base_row_index, count, scan_vector);\n+\n+\tidx_t offset_in_row_group = segment->start - row_group_start + base_row_index;\n+\tvalidity.ScanCommittedRange(row_group_start, offset_in_row_group, count, scan_vector);\n+}\n+\n void StandardColumnData::Initialize(PersistentColumnData &column_data) {\n \tauto &persistent = (StandardPersistentColumnData &)column_data;\n \tColumnData::Initialize(column_data);\n \tvalidity.Initialize(*persistent.validity);\n }\n \n-shared_ptr<ColumnData> StandardColumnData::Deserialize(DataTableInfo &info, idx_t column_index, idx_t start_row,\n-                                                       Deserializer &source, const LogicalType &type) {\n-\tauto result = make_shared<StandardColumnData>(info, column_index, start_row, type, nullptr);\n-\tBaseDeserialize(info.db, source, type, *result);\n-\tColumnData::BaseDeserialize(info.db, source, LogicalType(LogicalTypeId::VALIDITY), result->validity);\n-\treturn move(result);\n+void StandardColumnData::DeserializeColumn(Deserializer &source) {\n+\tColumnData::DeserializeColumn(source);\n+\tvalidity.DeserializeColumn(source);\n }\n \n void StandardColumnData::GetStorageInfo(idx_t row_group_index, vector<idx_t> col_path, vector<vector<Value>> &result) {\ndiff --git a/src/storage/table/struct_column_data.cpp b/src/storage/table/struct_column_data.cpp\nnew file mode 100644\nindex 000000000000..bdd1cd110115\n--- /dev/null\n+++ b/src/storage/table/struct_column_data.cpp\n@@ -0,0 +1,263 @@\n+#include \"duckdb/storage/table/struct_column_data.hpp\"\n+#include \"duckdb/storage/statistics/struct_statistics.hpp\"\n+\n+namespace duckdb {\n+\n+StructColumnData::StructColumnData(DataTableInfo &info, idx_t column_index, idx_t start_row, LogicalType type_p,\n+                                   ColumnData *parent)\n+    : ColumnData(info, column_index, start_row, move(type_p), parent), validity(info, 0, start_row, this) {\n+\tD_ASSERT(type.InternalType() == PhysicalType::STRUCT);\n+\tauto &child_types = type.child_types();\n+\tD_ASSERT(child_types.size() > 0);\n+\t// the sub column index, starting at 1 (0 is the validity mask)\n+\tidx_t sub_column_index = 1;\n+\tfor (auto &child_type : child_types) {\n+\t\tsub_columns.push_back(\n+\t\t    ColumnData::CreateColumnUnique(info, sub_column_index, start_row, child_type.second, this));\n+\t\tsub_column_index++;\n+\t}\n+}\n+\n+bool StructColumnData::CheckZonemap(ColumnScanState &state, TableFilter &filter) {\n+\t// table filters are not supported yet for struct columns\n+\treturn false;\n+}\n+\n+void StructColumnData::InitializeScan(ColumnScanState &state) {\n+\t// initialize the validity segment\n+\tColumnScanState validity_state;\n+\tvalidity.InitializeScan(validity_state);\n+\tstate.child_states.push_back(move(validity_state));\n+\n+\t// initialize the sub-columns\n+\tfor (auto &sub_column : sub_columns) {\n+\t\tColumnScanState child_state;\n+\t\tsub_column->InitializeScan(child_state);\n+\t\tstate.child_states.push_back(move(child_state));\n+\t}\n+}\n+\n+void StructColumnData::InitializeScanWithOffset(ColumnScanState &state, idx_t row_idx) {\n+\t// initialize the validity segment\n+\tColumnScanState validity_state;\n+\tvalidity.InitializeScanWithOffset(validity_state, row_idx);\n+\tstate.child_states.push_back(move(validity_state));\n+\n+\t// initialize the sub-columns\n+\tfor (auto &sub_column : sub_columns) {\n+\t\tColumnScanState child_state;\n+\t\tsub_column->InitializeScanWithOffset(child_state, row_idx);\n+\t\tstate.child_states.push_back(move(child_state));\n+\t}\n+}\n+\n+void StructColumnData::Scan(Transaction &transaction, idx_t vector_index, ColumnScanState &state, Vector &result) {\n+\tvalidity.Scan(transaction, vector_index, state.child_states[0], result);\n+\tauto &child_entries = StructVector::GetEntries(result);\n+\tfor (idx_t i = 0; i < sub_columns.size(); i++) {\n+\t\tsub_columns[i]->Scan(transaction, vector_index, state.child_states[i + 1], *child_entries[i]);\n+\t}\n+\tstate.child_states[0].Next();\n+}\n+\n+void StructColumnData::ScanCommitted(idx_t vector_index, ColumnScanState &state, Vector &result, bool allow_updates) {\n+\tvalidity.ScanCommitted(vector_index, state.child_states[0], result, allow_updates);\n+\tauto &child_entries = StructVector::GetEntries(result);\n+\tfor (idx_t i = 0; i < sub_columns.size(); i++) {\n+\t\tsub_columns[i]->ScanCommitted(vector_index, state.child_states[i + 1], *child_entries[i], allow_updates);\n+\t}\n+\tstate.child_states[0].Next();\n+}\n+\n+void StructColumnData::InitializeAppend(ColumnAppendState &state) {\n+\tColumnAppendState validity_append;\n+\tvalidity.InitializeAppend(validity_append);\n+\tstate.child_appends.push_back(move(validity_append));\n+\n+\tfor (auto &sub_column : sub_columns) {\n+\t\tColumnAppendState child_append;\n+\t\tsub_column->InitializeAppend(child_append);\n+\t\tstate.child_appends.push_back(move(child_append));\n+\t}\n+}\n+\n+void StructColumnData::Append(BaseStatistics &stats, ColumnAppendState &state, Vector &vector, idx_t count) {\n+\tvector.Normalify(count);\n+\n+\t// append the null values\n+\tvalidity.Append(*stats.validity_stats, state.child_appends[0], vector, count);\n+\n+\tauto &struct_validity = FlatVector::Validity(vector);\n+\n+\tauto &struct_stats = (StructStatistics &)stats;\n+\tauto &child_entries = StructVector::GetEntries(vector);\n+\tfor (idx_t i = 0; i < child_entries.size(); i++) {\n+\t\tif (!struct_validity.AllValid()) {\n+\t\t\t// we set the child entries of the struct to NULL\n+\t\t\t// for any values in which the struct itself is NULL\n+\t\t\tchild_entries[i]->Normalify(count);\n+\n+\t\t\tauto &child_validity = FlatVector::Validity(*child_entries[i]);\n+\t\t\tchild_validity.Combine(struct_validity, count);\n+\t\t}\n+\t\tsub_columns[i]->Append(*struct_stats.child_stats[i], state.child_appends[i + 1], *child_entries[i], count);\n+\t}\n+}\n+\n+void StructColumnData::RevertAppend(row_t start_row) {\n+\tvalidity.RevertAppend(start_row);\n+\tfor (auto &sub_column : sub_columns) {\n+\t\tsub_column->RevertAppend(start_row);\n+\t}\n+}\n+\n+void StructColumnData::Fetch(ColumnScanState &state, row_t row_id, Vector &result) {\n+\t// fetch validity mask\n+\tauto &child_entries = StructVector::GetEntries(result);\n+\t// insert any child states that are required\n+\tfor (idx_t i = state.child_states.size(); i < child_entries.size() + 1; i++) {\n+\t\tColumnScanState child_state;\n+\t\tstate.child_states.push_back(move(child_state));\n+\t}\n+\t// fetch the validity state\n+\tvalidity.Fetch(state.child_states[0], row_id, result);\n+\t// fetch the sub-column states\n+\tfor (idx_t i = 0; i < child_entries.size(); i++) {\n+\t\tsub_columns[i]->Fetch(state.child_states[i + 1], row_id, *child_entries[i]);\n+\t}\n+}\n+\n+void StructColumnData::Update(Transaction &transaction, idx_t column_index, Vector &update_vector, row_t *row_ids,\n+                              idx_t update_count) {\n+\tvalidity.Update(transaction, column_index, update_vector, row_ids, update_count);\n+\tauto &child_entries = StructVector::GetEntries(update_vector);\n+\tfor (idx_t i = 0; i < child_entries.size(); i++) {\n+\t\tsub_columns[i]->Update(transaction, column_index, *child_entries[i], row_ids, update_count);\n+\t}\n+}\n+\n+void StructColumnData::UpdateColumn(Transaction &transaction, const vector<column_t> &column_path,\n+                                    Vector &update_vector, row_t *row_ids, idx_t update_count, idx_t depth) {\n+\t// we can never DIRECTLY update a struct column\n+\tif (depth >= column_path.size()) {\n+\t\tthrow InternalException(\"Attempting to directly update a struct column - this should not be possible\");\n+\t}\n+\tauto update_column = column_path[depth];\n+\tif (update_column == 0) {\n+\t\t// update the validity column\n+\t\tvalidity.UpdateColumn(transaction, column_path, update_vector, row_ids, update_count, depth + 1);\n+\t} else {\n+\t\tif (update_column > sub_columns.size()) {\n+\t\t\tthrow InternalException(\"Update column_path out of range\");\n+\t\t}\n+\t\tsub_columns[update_column - 1]->UpdateColumn(transaction, column_path, update_vector, row_ids, update_count,\n+\t\t                                             depth + 1);\n+\t}\n+}\n+\n+unique_ptr<BaseStatistics> StructColumnData::GetUpdateStatistics() {\n+\t// check if any child column has updates\n+\tauto stats = BaseStatistics::CreateEmpty(type);\n+\tauto &struct_stats = (StructStatistics &)*stats;\n+\tstats->validity_stats = validity.GetUpdateStatistics();\n+\tfor (idx_t i = 0; i < sub_columns.size(); i++) {\n+\t\tauto child_stats = sub_columns[i]->GetUpdateStatistics();\n+\t\tif (child_stats) {\n+\t\t\tstruct_stats.child_stats[i] = move(child_stats);\n+\t\t}\n+\t}\n+\treturn stats;\n+}\n+\n+void StructColumnData::FetchRow(Transaction &transaction, ColumnFetchState &state, row_t row_id, Vector &result,\n+                                idx_t result_idx) {\n+\t// fetch validity mask\n+\tauto &child_entries = StructVector::GetEntries(result);\n+\t// insert any child states that are required\n+\tfor (idx_t i = state.child_states.size(); i < child_entries.size() + 1; i++) {\n+\t\tauto child_state = make_unique<ColumnFetchState>();\n+\t\tstate.child_states.push_back(move(child_state));\n+\t}\n+\t// fetch the validity state\n+\tvalidity.FetchRow(transaction, *state.child_states[0], row_id, result, result_idx);\n+\t// fetch the sub-column states\n+\tfor (idx_t i = 0; i < child_entries.size(); i++) {\n+\t\tsub_columns[i]->FetchRow(transaction, *state.child_states[i + 1], row_id, *child_entries[i], result_idx);\n+\t}\n+}\n+\n+void StructColumnData::CommitDropColumn() {\n+\tvalidity.CommitDropColumn();\n+\tfor (auto &sub_column : sub_columns) {\n+\t\tsub_column->CommitDropColumn();\n+\t}\n+}\n+\n+struct StructColumnCheckpointState : public ColumnCheckpointState {\n+\tStructColumnCheckpointState(RowGroup &row_group, ColumnData &column_data, TableDataWriter &writer)\n+\t    : ColumnCheckpointState(row_group, column_data, writer) {\n+\t\tglobal_stats = make_unique<StructStatistics>(column_data.type);\n+\t}\n+\n+\tunique_ptr<ColumnCheckpointState> validity_state;\n+\tvector<unique_ptr<ColumnCheckpointState>> child_states;\n+\n+public:\n+\tunique_ptr<BaseStatistics> GetStatistics() override {\n+\t\tauto stats = make_unique<StructStatistics>(column_data.type);\n+\t\tD_ASSERT(stats->child_stats.size() == child_states.size());\n+\t\tstats->validity_stats = validity_state->GetStatistics();\n+\t\tfor (idx_t i = 0; i < child_states.size(); i++) {\n+\t\t\tstats->child_stats[i] = child_states[i]->GetStatistics();\n+\t\t\tD_ASSERT(stats->child_stats[i]);\n+\t\t}\n+\t\treturn move(stats);\n+\t}\n+\n+\tvoid FlushToDisk() override {\n+\t\tvalidity_state->FlushToDisk();\n+\t\tfor (auto &state : child_states) {\n+\t\t\tstate->FlushToDisk();\n+\t\t}\n+\t}\n+};\n+\n+unique_ptr<ColumnCheckpointState> StructColumnData::CreateCheckpointState(RowGroup &row_group,\n+                                                                          TableDataWriter &writer) {\n+\treturn make_unique<StructColumnCheckpointState>(row_group, *this, writer);\n+}\n+\n+unique_ptr<ColumnCheckpointState> StructColumnData::Checkpoint(RowGroup &row_group, TableDataWriter &writer) {\n+\tauto checkpoint_state = make_unique<StructColumnCheckpointState>(row_group, *this, writer);\n+\tcheckpoint_state->validity_state = validity.Checkpoint(row_group, writer);\n+\tfor (auto &sub_column : sub_columns) {\n+\t\tcheckpoint_state->child_states.push_back(sub_column->Checkpoint(row_group, writer));\n+\t}\n+\treturn move(checkpoint_state);\n+}\n+\n+void StructColumnData::Initialize(PersistentColumnData &column_data) {\n+\tauto &persistent = (StructPersistentColumnData &)column_data;\n+\tvalidity.Initialize(*persistent.validity);\n+\tfor (idx_t i = 0; i < sub_columns.size(); i++) {\n+\t\tsub_columns[i]->Initialize(*persistent.child_data[i]);\n+\t}\n+}\n+\n+void StructColumnData::DeserializeColumn(Deserializer &source) {\n+\tvalidity.DeserializeColumn(source);\n+\tfor (auto &sub_column : sub_columns) {\n+\t\tsub_column->DeserializeColumn(source);\n+\t}\n+}\n+\n+void StructColumnData::GetStorageInfo(idx_t row_group_index, vector<idx_t> col_path, vector<vector<Value>> &result) {\n+\tcol_path.push_back(0);\n+\tvalidity.GetStorageInfo(row_group_index, col_path, result);\n+\tfor (idx_t i = 0; i < sub_columns.size(); i++) {\n+\t\tcol_path.back() = i + 1;\n+\t\tsub_columns[i]->GetStorageInfo(row_group_index, col_path, result);\n+\t}\n+}\n+\n+} // namespace duckdb\ndiff --git a/src/storage/table/update_segment.cpp b/src/storage/table/update_segment.cpp\nindex 689adadd70eb..0fd4270e7556 100644\n--- a/src/storage/table/update_segment.cpp\n+++ b/src/storage/table/update_segment.cpp\n@@ -984,6 +984,8 @@ void UpdateSegment::Update(Transaction &transaction, idx_t column_index, Vector\n \t// obtain an exclusive lock\n \tauto write_lock = lock.GetExclusiveLock();\n \n+\tupdate.Normalify(count);\n+\n \t// update statistics\n \tSelectionVector sel;\n \t{\ndiff --git a/src/storage/table/validity_segment.cpp b/src/storage/table/validity_segment.cpp\nindex b138de189565..5707afd067cd 100644\n--- a/src/storage/table/validity_segment.cpp\n+++ b/src/storage/table/validity_segment.cpp\n@@ -229,13 +229,17 @@ void ValiditySegment::Scan(ColumnScanState &state, idx_t start, idx_t scan_count\n \n \tauto &result_mask = FlatVector::Validity(result);\n \tauto input_data = (validity_t *)state.primary_handle->node->buffer;\n-\tauto result_data = (validity_t *)result_mask.GetData();\n \n-\t// the code below does this, but using bitwise ops:\n-\t// ValidityMask source_mask(input_data);\n-\t// for (idx_t i = 0; i < scan_count; i++) {\n-\t//     result_mask.Set(result_offset + i, source_mask.RowIsValid(start + i));\n-\t// }\n+#if STANDARD_VECTOR_SIZE < 128\n+\t// fallback for tiny vector sizes\n+\t// the bitwise ops we use below don't work if the vector size is too small\n+\tValidityMask source_mask(input_data);\n+\tfor (idx_t i = 0; i < scan_count; i++) {\n+\t\tresult_mask.Set(result_offset + i, source_mask.RowIsValid(start + i));\n+\t}\n+#else\n+\t// the code below does what the fallback code above states, but using bitwise ops:\n+\tauto result_data = (validity_t *)result_mask.GetData();\n \n \t// set up the initial positions\n \t// we need to find the validity_entry to modify, together with the bit-index WITHIN the validity entry\n@@ -315,6 +319,7 @@ void ValiditySegment::Scan(ColumnScanState &state, idx_t start, idx_t scan_count\n \t\t\tresult_data[current_result_idx] &= input_mask;\n \t\t}\n \t}\n+#endif\n \n #ifdef DEBUG\n \t// verify that we actually accomplished the bitwise ops equivalent that we wanted to do\n",
  "test_patch": "diff --git a/test/optimizer/statistics/statistics_struct.test b/test/optimizer/statistics/statistics_struct.test\nnew file mode 100644\nindex 000000000000..1a080b84620f\n--- /dev/null\n+++ b/test/optimizer/statistics/statistics_struct.test\n@@ -0,0 +1,30 @@\n+# name: test/optimizer/statistics/statistics_struct.test\n+# description: Statistics propagation test with structs\n+# group: [statistics]\n+\n+statement ok\n+PRAGMA enable_verification;\n+\n+statement ok\n+CREATE TABLE structs AS SELECT {'i': i} c FROM range(4) tbl(i);\n+\n+statement ok\n+PRAGMA explain_output = OPTIMIZED_ONLY;\n+\n+# we can statically determine IS NULL/IS NOT NULL are false, if there are no null values for this column\n+query II\n+EXPLAIN SELECT c IS NULL FROM structs;\n+----\n+logical_opt\t<!REGEX>:.*IS_NULL.*\n+\n+# the same applies to c['i']\n+query II\n+EXPLAIN SELECT c['i'] IS NULL FROM structs;\n+----\n+logical_opt\t<!REGEX>:.*IS_NULL.*\n+\n+# filter is out of range\n+query II\n+EXPLAIN SELECT * FROM structs WHERE c['i']=4;\n+----\n+logical_opt\t<REGEX>:.*EMPTY_RESULT.*\ndiff --git a/test/sql/aggregate/aggregates/test_histogram.test b/test/sql/aggregate/aggregates/test_histogram.test\nindex 07f835e0310b..e460556052aa 100644\n--- a/test/sql/aggregate/aggregates/test_histogram.test\n+++ b/test/sql/aggregate/aggregates/test_histogram.test\n@@ -5,18 +5,14 @@\n statement ok\n PRAGMA enable_verification\n \n-# Empty Table\n query I\n-SELECT histogram(i) FROM range(100) tbl(i) WHERE 1=0;\n+select histogram(NULL)\n ----\n NULL\n \n-#Corner cases\n-statement error\n-select histogram()\n-\n+# Empty Table\n query I\n-select histogram(NULL)\n+SELECT histogram(i) FROM range(100) tbl(i) WHERE 1=0;\n ----\n NULL\n \n@@ -25,9 +21,6 @@ select histogram(1)\n ----\n {1=1}\n \n-statement error\n-select histogram(*)\n-\n query I\n SELECT histogram(2) FROM range(100);\n ----\n@@ -90,4 +83,9 @@ select g,histogram(g) over (partition by g%2)\n 3\t{1=2, 3=1, 5=1}\n 5\t{1=2, 3=1, 5=1}\n \n+#Corner cases\n+statement error\n+select histogram()\n \n+statement error\n+select histogram(*)\ndiff --git a/test/sql/function/time/test_extract_stats.test b/test/sql/function/time/test_extract_stats.test\nindex f4ee42886e9e..05a9db0d2bfc 100644\n--- a/test/sql/function/time/test_extract_stats.test\n+++ b/test/sql/function/time/test_extract_stats.test\n@@ -18,29 +18,29 @@ PRAGMA disable_verification\n query I\n SELECT stats(EXTRACT(second FROM i)) FROM times LIMIT 1\n ----\n-<REGEX>:.*true.*0.*60.*\n+<REGEX>:.*0.*60.*true.*\n \n query I\n SELECT stats(EXTRACT(minute FROM i)) FROM times LIMIT 1\n ----\n-<REGEX>:.*true.*0.*60.*\n+<REGEX>:.*0.*60.*true.*\n \n query I\n SELECT stats(EXTRACT(hour FROM i)) FROM times LIMIT 1\n ----\n-<REGEX>:.*true.*0.*24.*\n+<REGEX>:.*0.*24.*true.*\n \n query I\n SELECT stats(EXTRACT(milliseconds FROM i)) FROM times LIMIT 1\n ----\n-<REGEX>:.*true.*0.*60000.*\n+<REGEX>:.*0.*60000.*true.*\n \n query I\n SELECT stats(EXTRACT(microseconds FROM i)) FROM times LIMIT 1\n ----\n-<REGEX>:.*true.*0.*60000000.*\n+<REGEX>:.*0.*60000000.*true.*\n \n query I\n SELECT stats(EXTRACT(epoch FROM i)) FROM times LIMIT 1\n ----\n-<REGEX>:.*true.*0.*86400.*\n+<REGEX>:.*0.*86400.*true.*\ndiff --git a/test/sql/pragma/test_storage_info.test b/test/sql/pragma/test_storage_info.test\nindex f719f48b56cf..008273f6f131 100644\n--- a/test/sql/pragma/test_storage_info.test\n+++ b/test/sql/pragma/test_storage_info.test\n@@ -24,6 +24,16 @@ CREATE VIEW v1 AS SELECT 42\n statement error\n PRAGMA storage_info('v1')\n \n-# non-existant table\n+# non-existent table\n statement error\n-PRAGMA storage_info('bla')\n\\ No newline at end of file\n+PRAGMA storage_info('bla')\n+\n+# different types\n+statement ok\n+CREATE TABLE different_types(i INTEGER, j VARCHAR, k STRUCT(k INTEGER, l VARCHAR))\n+\n+statement ok\n+INSERT INTO different_types VALUES (1, 'hello', {'k': 3, 'l': 'hello'})\n+\n+statement ok\n+PRAGMA storage_info('different_types')\ndiff --git a/test/sql/storage/test_store_nulls_strings.test b/test/sql/storage/test_store_nulls_strings.test\nindex 5a26d95eced7..2b6e63add585 100644\n--- a/test/sql/storage/test_store_nulls_strings.test\n+++ b/test/sql/storage/test_store_nulls_strings.test\n@@ -15,6 +15,13 @@ INSERT INTO test VALUES (NULL, 'hello'), (13, 'abcdefgh'), (12, NULL)\n statement ok\n CHECKPOINT\n \n+query II\n+SELECT a, b FROM test ORDER BY a\n+----\n+NULL\thello\n+12\tNULL\n+13\tabcdefgh\n+\n restart\n \n query II\ndiff --git a/test/sql/storage/types/map/map_storage.test b/test/sql/storage/types/map/map_storage.test\nnew file mode 100644\nindex 000000000000..ffa5c89e4d5c\n--- /dev/null\n+++ b/test/sql/storage/types/map/map_storage.test\n@@ -0,0 +1,31 @@\n+# name: test/sql/storage/types/map/map_storage.test\n+# description: Test maps with persistent storage\n+# group: [map]\n+\n+# FIXME: maps need list support in storage\n+\n+mode skip\n+\n+# load the DB from disk\n+load __TEST_DIR__/map_storage_test.db\n+\n+statement ok\n+CREATE TABLE a(b MAP(INTEGER,INTEGER));\n+\n+statement ok\n+INSERT INTO a VALUES (MAP([1], [2])), (MAP([1, 2, 3], [4, 5, 6]));\n+\n+query I\n+SELECT * FROM a;\n+----\n+{1=2}\n+{1=4, 2=5, 3=6}\n+\n+restart\n+\n+query I\n+SELECT * FROM a;\n+----\n+{1=2}\n+{1=4, 2=5, 3=6}\n+\ndiff --git a/test/sql/storage/types/struct/nested_struct_storage.test b/test/sql/storage/types/struct/nested_struct_storage.test\nnew file mode 100644\nindex 000000000000..0d150dffdd14\n--- /dev/null\n+++ b/test/sql/storage/types/struct/nested_struct_storage.test\n@@ -0,0 +1,157 @@\n+# name: test/sql/storage/types/struct/nested_struct_storage.test\n+# description: Test structs with persistent storage\n+# group: [struct]\n+\n+# load the DB from disk\n+load __TEST_DIR__/struct_storage_test.db\n+\n+statement ok\n+CREATE TABLE a AS SELECT {\n+\t'r1': {\n+\t\t'a': 'hello',\n+\t\t'b': 3\n+\t},\n+\t'r2': {\n+\t\t'a': 'world',\n+\t\t'b': 17,\n+\t\t'c': NULL\n+\t}\n+} c\n+\n+query I\n+SELECT * FROM a\n+----\n+{'r1': {'a': hello, 'b': 3}, 'r2': {'a': world, 'b': 17, 'c': NULL}}\n+\n+query I\n+SELECT c['r1']['a'] from a\n+----\n+hello\n+\n+restart\n+\n+query I\n+SELECT * FROM a\n+----\n+{'r1': {'a': hello, 'b': 3}, 'r2': {'a': world, 'b': 17, 'c': NULL}}\n+\n+query I\n+SELECT c['r1']['a'] from a\n+----\n+hello\n+\n+# update\n+statement ok\n+UPDATE a SET c={\n+\t'r1': {\n+\t\t'a': 'blabla',\n+\t\t'b': 3\n+\t},\n+\t'r2': {\n+\t\t'a': 'world',\n+\t\t'b': 18,\n+\t\t'c': NULL\n+\t}\n+}\n+\n+query I\n+SELECT * FROM a\n+----\n+{'r1': {'a': blabla, 'b': 3}, 'r2': {'a': world, 'b': 18, 'c': NULL}}\n+\n+query I\n+SELECT c['r1']['a'] from a\n+----\n+blabla\n+\n+restart\n+\n+query I\n+SELECT * FROM a\n+----\n+{'r1': {'a': blabla, 'b': 3}, 'r2': {'a': world, 'b': 18, 'c': NULL}}\n+\n+query I\n+SELECT c['r1']['a'] from a\n+----\n+blabla\n+\n+# nulls at different levels\n+statement ok\n+INSERT INTO a VALUES (\n+{\n+\t'r1': {\n+\t\t'a': NULL,\n+\t\t'b': 3\n+\t},\n+\t'r2': {\n+\t\t'a': NULL,\n+\t\t'b': 17,\n+\t\t'c': NULL\n+\t}\n+})\n+\n+query I\n+SELECT * FROM a\n+----\n+{'r1': {'a': blabla, 'b': 3}, 'r2': {'a': world, 'b': 18, 'c': NULL}}\n+{'r1': {'a': NULL, 'b': 3}, 'r2': {'a': NULL, 'b': 17, 'c': NULL}}\n+\n+statement ok\n+INSERT INTO a VALUES ({\n+\t'r1': NULL,\n+\t'r2': {\n+\t\t'a': NULL,\n+\t\t'b': 17,\n+\t\t'c': NULL\n+\t}\n+})\n+\n+query I\n+SELECT * FROM a\n+----\n+{'r1': {'a': blabla, 'b': 3}, 'r2': {'a': world, 'b': 18, 'c': NULL}}\n+{'r1': {'a': NULL, 'b': 3}, 'r2': {'a': NULL, 'b': 17, 'c': NULL}}\n+{'r1': NULL, 'r2': {'a': NULL, 'b': 17, 'c': NULL}}\n+\n+statement ok\n+INSERT INTO a VALUES ({\n+\t'r1': NULL,\n+\t'r2': NULL\n+})\n+\n+query I\n+SELECT * FROM a\n+----\n+{'r1': {'a': blabla, 'b': 3}, 'r2': {'a': world, 'b': 18, 'c': NULL}}\n+{'r1': {'a': NULL, 'b': 3}, 'r2': {'a': NULL, 'b': 17, 'c': NULL}}\n+{'r1': NULL, 'r2': {'a': NULL, 'b': 17, 'c': NULL}}\n+{'r1': NULL, 'r2': NULL}\n+\n+statement ok\n+INSERT INTO a VALUES(NULL)\n+\n+query I\n+SELECT * FROM a\n+----\n+{'r1': {'a': blabla, 'b': 3}, 'r2': {'a': world, 'b': 18, 'c': NULL}}\n+{'r1': {'a': NULL, 'b': 3}, 'r2': {'a': NULL, 'b': 17, 'c': NULL}}\n+{'r1': NULL, 'r2': {'a': NULL, 'b': 17, 'c': NULL}}\n+{'r1': NULL, 'r2': NULL}\n+NULL\n+\n+restart\n+\n+query I\n+SELECT * FROM a\n+----\n+{'r1': {'a': blabla, 'b': 3}, 'r2': {'a': world, 'b': 18, 'c': NULL}}\n+{'r1': {'a': NULL, 'b': 3}, 'r2': {'a': NULL, 'b': 17, 'c': NULL}}\n+{'r1': NULL, 'r2': {'a': NULL, 'b': 17, 'c': NULL}}\n+{'r1': NULL, 'r2': NULL}\n+NULL\n+\n+# verify that no null values have crept their way into the stats\n+query II\n+select column_path, stats from pragma_storage_info('a') where  stats LIKE '%[Min: -2147483648, Max: -2147483648]%'\n+----\ndiff --git a/test/sql/storage/types/struct/struct_large_nulls.test_slow b/test/sql/storage/types/struct/struct_large_nulls.test_slow\nnew file mode 100644\nindex 000000000000..8f4117893262\n--- /dev/null\n+++ b/test/sql/storage/types/struct/struct_large_nulls.test_slow\n@@ -0,0 +1,108 @@\n+# name: test/sql/storage/types/struct/struct_large_nulls.test_slow\n+# description: Test that we reclaim space when dropping tables with struct columns\n+# group: [struct]\n+\n+load __TEST_DIR__/test_struct_large_nulls.db\n+\n+statement ok\n+CREATE TABLE structs AS SELECT -i-1 id, {'i': -i-1, 'j': i::VARCHAR} c FROM range(10000000) tbl(i);\n+\n+statement ok\n+INSERT INTO structs SELECT i id, {'i': i, 'j': i::VARCHAR} c FROM range(1000) tbl(i);\n+\n+query III\n+SELECT COUNT(*), COUNT(c['i']), COUNT(c['j']) FROM structs\n+----\n+10001000\t10001000\t10001000\n+\n+query I\n+SELECT COUNT(*) FROM structs WHERE c['i'] >= 0\n+----\n+1000\n+\n+# verify that no null values have crept their way into the stats\n+query II\n+select column_path, stats from pragma_storage_info('structs') where stats LIKE '%[Min: -2147483648, Max: -2147483648]%'\n+----\n+\n+query I\n+UPDATE structs SET id=NULL, c={'i': NULL, 'j': c['i']::VARCHAR} WHERE c['i'] >= 0 AND c['i'] % 4 = 0\n+----\n+250\n+\n+# verify that no null values have crept their way into the stats\n+query II\n+select column_path, stats from pragma_storage_info('structs') where stats LIKE '%[Min: -2147483648, Max: -2147483648]%'\n+----\n+\n+query I\n+UPDATE structs SET c={'i': c['i'], 'j': NULL} WHERE c['i'] >= 0 AND c['i'] % 4 = 1\n+----\n+250\n+\n+# verify that no null values have crept their way into the stats\n+query II\n+select column_path, stats from pragma_storage_info('structs') where stats LIKE '%[Min: -2147483648, Max: -2147483648]%'\n+----\n+\n+query I\n+UPDATE structs SET id=NULL, c={'i': NULL, 'j': NULL} WHERE c['i'] >= 0 AND c['i'] % 4 = 2\n+----\n+250\n+\n+# verify that no null values have crept their way into the stats\n+query II\n+select column_path, stats from pragma_storage_info('structs') where stats LIKE '%[Min: -2147483648, Max: -2147483648]%'\n+----\n+\n+query I\n+UPDATE structs SET id=NULL, c=NULL WHERE c['i'] >= 0 AND c['i'] % 4 = 3\n+----\n+250\n+\n+# verify that no null values have crept their way into the stats\n+query II\n+select column_path, stats from pragma_storage_info('structs') where stats LIKE '%[Min: -2147483648, Max: -2147483648]%'\n+----\n+\n+# query the null values\n+query I\n+SELECT COUNT(*) FROM structs WHERE c IS NULL\n+----\n+250\n+\n+query I\n+SELECT COUNT(*) FROM structs WHERE c['i'] IS NULL\n+----\n+750\n+\n+query I\n+SELECT COUNT(*) FROM structs WHERE c['j'] IS NULL\n+----\n+750\n+\n+query I\n+SELECT COUNT(c['j']) FROM structs WHERE (c['i'] >= 0 OR c['i'] IS NULL)\n+----\n+250\n+\n+query I nosort sum_result\n+SELECT SUM(id) FROM structs WHERE id >= 0\n+----\n+\n+query I nosort sum_result\n+SELECT SUM(c['i']) FROM structs WHERE c['i'] >= 0\n+----\n+\n+query I nosort sum_result_nofilter\n+SELECT SUM(id) FROM structs\n+----\n+\n+query I nosort sum_result_nofilter\n+SELECT SUM(c['i']) FROM structs\n+----\n+\n+query III\n+SELECT COUNT(c['j']), MIN(c['j']), MAX(c['j']) FROM structs WHERE (c['i'] >= 0 OR c['i'] IS NULL)\n+----\n+250\t0\t996\ndiff --git a/test/sql/storage/types/struct/struct_reclaim_space_drop.test_slow b/test/sql/storage/types/struct/struct_reclaim_space_drop.test_slow\nnew file mode 100644\nindex 000000000000..2b8369d48c7b\n--- /dev/null\n+++ b/test/sql/storage/types/struct/struct_reclaim_space_drop.test_slow\n@@ -0,0 +1,48 @@\n+# name: test/sql/storage/types/struct/struct_reclaim_space_drop.test_slow\n+# description: Test that we reclaim space when dropping tables with struct columns\n+# group: [struct]\n+\n+load __TEST_DIR__/test_reclaim_space.db\n+\n+statement ok\n+PRAGMA force_checkpoint;\n+\n+statement ok\n+CREATE TABLE structs AS SELECT {'i': i, 'j': i::VARCHAR} c FROM range(10000000) tbl(i);\n+\n+statement ok\n+CHECKPOINT;\n+\n+statement ok\n+CHECKPOINT;\n+\n+query III\n+SELECT MIN(c['i']), MAX(c['i']), COUNT(*) FROM structs\n+----\n+0\t9999999\t10000000\n+\n+loop i 0 10\n+\n+statement ok\n+DROP TABLE structs;\n+\n+statement ok\n+CREATE TABLE structs AS SELECT {'i': i, 'j': i::VARCHAR} c FROM range(10000000) tbl(i);\n+\n+query III\n+SELECT MIN(c['i']), MAX(c['i']), COUNT(*) FROM structs\n+----\n+0\t9999999\t10000000\n+\n+statement ok\n+CHECKPOINT;\n+\n+query I nosort expected_blocks\n+select round(total_blocks / 100.0) from pragma_database_size();\n+\n+query III\n+SELECT MIN(c['i']), MAX(c['i']), COUNT(*) FROM structs\n+----\n+0\t9999999\t10000000\n+\n+endloop\ndiff --git a/test/sql/storage/types/struct/struct_storage.test b/test/sql/storage/types/struct/struct_storage.test\nnew file mode 100644\nindex 000000000000..45ec1994326f\n--- /dev/null\n+++ b/test/sql/storage/types/struct/struct_storage.test\n@@ -0,0 +1,95 @@\n+# name: test/sql/storage/types/struct/struct_storage.test\n+# description: Test structs with persistent storage\n+# group: [struct]\n+\n+# load the DB from disk\n+load __TEST_DIR__/struct_storage_test.db\n+\n+statement ok\n+CREATE TABLE a(b STRUCT(i INTEGER, j INTEGER));\n+\n+statement ok\n+INSERT INTO a VALUES ({'i': 1, 'j': 2}), (NULL), ({'i': NULL, 'j': 2}), (ROW(1, NULL));\n+\n+query I\n+SELECT * FROM a;\n+----\n+{'i': 1, 'j': 2}\n+NULL\n+{'i': NULL, 'j': 2}\n+{'i': 1, 'j': NULL}\n+\n+query I\n+SELECT COUNT(*) FROM a WHERE b IS NULL;\n+----\n+1\n+\n+restart\n+\n+query I\n+SELECT * FROM a;\n+----\n+{'i': 1, 'j': 2}\n+NULL\n+{'i': NULL, 'j': 2}\n+{'i': 1, 'j': NULL}\n+\n+query I\n+SELECT COUNT(*) FROM a WHERE b IS NULL;\n+----\n+1\n+\n+# deletes\n+query I\n+DELETE FROM a WHERE (b).i=1\n+----\n+2\n+\n+query I\n+SELECT * FROM a;\n+----\n+NULL\n+{'i': NULL, 'j': 2}\n+\n+restart\n+\n+query I\n+SELECT * FROM a;\n+----\n+NULL\n+{'i': NULL, 'j': 2}\n+\n+query I\n+SELECT COUNT(*) FROM a WHERE b IS NULL;\n+----\n+1\n+\n+# updates\n+query I\n+UPDATE a SET b={i: 7, j: 9} WHERE b IS NULL\n+----\n+1\n+\n+query I\n+SELECT * FROM a;\n+----\n+{'i': 7, 'j': 9}\n+{'i': NULL, 'j': 2}\n+\n+query I\n+SELECT COUNT(*) FROM a WHERE b IS NULL;\n+----\n+0\n+\n+restart\n+\n+query I\n+SELECT * FROM a;\n+----\n+{'i': 7, 'j': 9}\n+{'i': NULL, 'j': 2}\n+\n+query I\n+SELECT COUNT(*) FROM a WHERE b IS NULL;\n+----\n+0\ndiff --git a/test/sql/storage/types/struct/wal_struct_storage.test b/test/sql/storage/types/struct/wal_struct_storage.test\nnew file mode 100644\nindex 000000000000..3544f887c4b5\n--- /dev/null\n+++ b/test/sql/storage/types/struct/wal_struct_storage.test\n@@ -0,0 +1,113 @@\n+# name: test/sql/storage/types/struct/wal_struct_storage.test\n+# description: Test structs with persistent storage\n+# group: [struct]\n+\n+# load the DB from disk\n+load __TEST_DIR__/struct_storage_test.db\n+\n+statement ok\n+PRAGMA disable_checkpoint_on_shutdown\n+\n+statement ok\n+PRAGMA wal_autocheckpoint='1TB';\n+\n+statement ok\n+CREATE TABLE a(b STRUCT(i INTEGER, j INTEGER));\n+\n+statement ok\n+INSERT INTO a VALUES ({'i': 1, 'j': 2}), (NULL), ({'i': NULL, 'j': 2}), (ROW(1, NULL));\n+\n+query I\n+SELECT * FROM a;\n+----\n+{'i': 1, 'j': 2}\n+NULL\n+{'i': NULL, 'j': 2}\n+{'i': 1, 'j': NULL}\n+\n+query I\n+SELECT COUNT(*) FROM a WHERE b IS NULL;\n+----\n+1\n+\n+restart\n+\n+statement ok\n+PRAGMA disable_checkpoint_on_shutdown\n+\n+statement ok\n+PRAGMA wal_autocheckpoint='1TB';\n+\n+query I\n+SELECT * FROM a;\n+----\n+{'i': 1, 'j': 2}\n+NULL\n+{'i': NULL, 'j': 2}\n+{'i': 1, 'j': NULL}\n+\n+query I\n+SELECT COUNT(*) FROM a WHERE b IS NULL;\n+----\n+1\n+\n+# deletes\n+query I\n+DELETE FROM a WHERE (b).i=1\n+----\n+2\n+\n+query I\n+SELECT * FROM a;\n+----\n+NULL\n+{'i': NULL, 'j': 2}\n+\n+restart\n+\n+statement ok\n+PRAGMA disable_checkpoint_on_shutdown\n+\n+statement ok\n+PRAGMA wal_autocheckpoint='1TB';\n+\n+query I\n+SELECT * FROM a;\n+----\n+NULL\n+{'i': NULL, 'j': 2}\n+\n+query I\n+SELECT COUNT(*) FROM a WHERE b IS NULL;\n+----\n+1\n+\n+# updates\n+query I\n+UPDATE a SET b={i: 7, j: 9} WHERE b IS NULL\n+----\n+1\n+\n+query I\n+SELECT * FROM a;\n+----\n+{'i': 7, 'j': 9}\n+{'i': NULL, 'j': 2}\n+\n+query I\n+SELECT COUNT(*) FROM a WHERE b IS NULL;\n+----\n+0\n+\n+restart\n+\n+query I\n+SELECT * FROM a;\n+----\n+{'i': 7, 'j': 9}\n+{'i': NULL, 'j': 2}\n+\n+query I\n+SELECT COUNT(*) FROM a WHERE b IS NULL;\n+----\n+0\ndiff --git a/test/sql/tpch/tpch_sf001_struct.test_slow b/test/sql/tpch/tpch_sf001_struct.test_slow\nnew file mode 100644\nindex 000000000000..e957d69665cb\n--- /dev/null\n+++ b/test/sql/tpch/tpch_sf001_struct.test_slow\n@@ -0,0 +1,214 @@\n+# name: test/sql/tpch/tpch_sf001_struct.test_slow\n+# description: Test TPC-H SF0.01\n+# group: [tpch]\n+\n+require tpch\n+\n+load __TEST_DIR__/tpch_sf001_struct.db\n+\n+statement ok\n+CALL dbgen(sf=0.01, suffix='_normal');\n+\n+statement ok\n+CREATE TABLE lineitem_struct AS SELECT {\n+'l_orderkey': l_orderkey,\n+'l_partkey': l_partkey,\n+'l_suppkey': l_suppkey,\n+'l_linenumber': l_linenumber,\n+'l_quantity': l_quantity,\n+'l_extendedprice': l_extendedprice,\n+'l_discount': l_discount,\n+'l_tax': l_tax,\n+'l_returnflag': l_returnflag,\n+'l_linestatus': l_linestatus,\n+'l_shipdate': l_shipdate,\n+'l_commitdate': l_commitdate,\n+'l_receiptdate': l_receiptdate,\n+'l_shipinstruct': l_shipinstruct,\n+'l_shipmode': l_shipmode,\n+'l_comment': l_comment\n+} c FROM lineitem_normal;\n+\n+statement ok\n+CREATE VIEW lineitem AS SELECT\n+c['l_orderkey'] AS l_orderkey,\n+c['l_partkey'] AS l_partkey,\n+c['l_suppkey'] AS l_suppkey,\n+c['l_linenumber'] AS l_linenumber,\n+c['l_quantity'] AS l_quantity,\n+c['l_extendedprice'] AS l_extendedprice,\n+c['l_discount'] AS l_discount,\n+c['l_tax'] AS l_tax,\n+c['l_returnflag'] AS l_returnflag,\n+c['l_linestatus'] AS l_linestatus,\n+c['l_shipdate'] AS l_shipdate,\n+c['l_commitdate'] AS l_commitdate,\n+c['l_receiptdate'] AS l_receiptdate,\n+c['l_shipinstruct'] AS l_shipinstruct,\n+c['l_shipmode'] AS l_shipmode,\n+c['l_comment'] AS l_comment\n+FROM lineitem_struct\n+\n+statement ok\n+CREATE TABLE orders_struct AS SELECT {\n+'o_orderkey': o_orderkey,\n+'o_custkey': o_custkey,\n+'o_orderstatus': o_orderstatus,\n+'o_totalprice': o_totalprice,\n+'o_orderdate': o_orderdate,\n+'o_orderpriority': o_orderpriority,\n+'o_clerk': o_clerk,\n+'o_shippriority': o_shippriority,\n+'o_comment': o_comment\n+} c FROM orders_normal;\n+\n+statement ok\n+CREATE VIEW orders AS SELECT\n+c['o_orderkey'] AS o_orderkey,\n+c['o_custkey'] AS o_custkey,\n+c['o_orderstatus'] AS o_orderstatus,\n+c['o_totalprice'] AS o_totalprice,\n+c['o_orderdate'] AS o_orderdate,\n+c['o_orderpriority'] AS o_orderpriority,\n+c['o_clerk'] AS o_clerk,\n+c['o_shippriority'] AS o_shippriority,\n+c['o_comment'] AS o_comment\n+FROM orders_struct\n+\n+statement ok\n+CREATE TABLE part_struct AS SELECT {\n+'p_partkey': p_partkey,\n+'p_name': p_name,\n+'p_mfgr': p_mfgr,\n+'p_brand': p_brand,\n+'p_type': p_type,\n+'p_size': p_size,\n+'p_container': p_container,\n+'p_retailprice': p_retailprice,\n+'p_comment': p_comment\n+} c FROM part_normal;\n+\n+statement ok\n+CREATE VIEW part AS SELECT\n+c['p_partkey'] AS p_partkey,\n+c['p_name'] AS p_name,\n+c['p_mfgr'] AS p_mfgr,\n+c['p_brand'] AS p_brand,\n+c['p_type'] AS p_type,\n+c['p_size'] AS p_size,\n+c['p_container'] AS p_container,\n+c['p_retailprice'] AS p_retailprice,\n+c['p_comment'] AS p_comment\n+FROM part_struct\n+\n+statement ok\n+CREATE TABLE partsupp_struct AS SELECT {\n+'ps_partkey': ps_partkey,\n+'ps_suppkey': ps_suppkey,\n+'ps_availqty': ps_availqty,\n+'ps_supplycost': ps_supplycost,\n+'ps_comment': ps_comment\n+} c FROM partsupp_normal;\n+\n+statement ok\n+CREATE VIEW partsupp AS SELECT\n+c['ps_partkey'] AS ps_partkey,\n+c['ps_suppkey'] AS ps_suppkey,\n+c['ps_availqty'] AS ps_availqty,\n+c['ps_supplycost'] AS ps_supplycost,\n+c['ps_comment'] AS ps_comment\n+FROM partsupp_struct\n+\n+statement ok\n+CREATE TABLE customer_struct AS SELECT {\n+'c_custkey': c_custkey,\n+'c_name': c_name,\n+'c_address': c_address,\n+'c_nationkey': c_nationkey,\n+'c_phone': c_phone,\n+'c_acctbal': c_acctbal,\n+'c_mktsegment': c_mktsegment,\n+'c_comment': c_comment\n+} c FROM customer_normal;\n+\n+statement ok\n+CREATE VIEW customer AS SELECT\n+c['c_custkey'] AS c_custkey,\n+c['c_name'] AS c_name,\n+c['c_address'] AS c_address,\n+c['c_nationkey'] AS c_nationkey,\n+c['c_phone'] AS c_phone,\n+c['c_acctbal'] AS c_acctbal,\n+c['c_mktsegment'] AS c_mktsegment,\n+c['c_comment'] AS c_comment\n+FROM customer_struct\n+\n+statement ok\n+CREATE TABLE region_struct AS SELECT {\n+'r_regionkey': r_regionkey,\n+'r_name': r_name,\n+'r_comment': r_comment\n+} c FROM region_normal;\n+\n+statement ok\n+CREATE VIEW region AS SELECT\n+c['r_regionkey'] AS r_regionkey,\n+c['r_name'] AS r_name,\n+c['r_comment'] AS r_comment\n+FROM region_struct\n+\n+statement ok\n+CREATE TABLE supplier_struct AS SELECT {\n+'s_suppkey': s_suppkey,\n+'s_name': s_name,\n+'s_address': s_address,\n+'s_nationkey': s_nationkey,\n+'s_phone': s_phone,\n+'s_acctbal': s_acctbal,\n+'s_comment': s_comment\n+} c FROM supplier_normal;\n+\n+statement ok\n+CREATE VIEW supplier AS SELECT\n+c['s_suppkey'] AS s_suppkey,\n+c['s_name'] AS s_name,\n+c['s_address'] AS s_address,\n+c['s_nationkey'] AS s_nationkey,\n+c['s_phone'] AS s_phone,\n+c['s_acctbal'] AS s_acctbal,\n+c['s_comment'] AS s_comment\n+FROM supplier_struct\n+\n+statement ok\n+CREATE TABLE nation_struct AS SELECT {\n+'n_nationkey': n_nationkey,\n+'n_name': n_name,\n+'n_regionkey': n_regionkey,\n+'n_comment': n_comment\n+} c FROM nation_normal;\n+\n+statement ok\n+CREATE VIEW nation AS SELECT\n+c['n_nationkey'] AS n_nationkey,\n+c['n_name'] AS n_name,\n+c['n_regionkey'] AS n_regionkey,\n+c['n_comment'] AS n_comment\n+FROM nation_struct\n+\n+loop i 1 9\n+\n+query I\n+PRAGMA tpch(${i})\n+----\n+<FILE>:extension/tpch/dbgen/answers/sf0.01/q0${i}.csv\n+\n+endloop\n+\n+loop i 10 23\n+\n+query I\n+PRAGMA tpch(${i})\n+----\n+<FILE>:extension/tpch/dbgen/answers/sf0.01/q${i}.csv\n+\n+endloop\ndiff --git a/test/sql/tpch/tpch_sf1_struct.test_slow b/test/sql/tpch/tpch_sf1_struct.test_slow\nnew file mode 100644\nindex 000000000000..6f90a4ef8578\n--- /dev/null\n+++ b/test/sql/tpch/tpch_sf1_struct.test_slow\n@@ -0,0 +1,214 @@\n+# name: test/sql/tpch/tpch_sf1_struct.test_slow\n+# description: Test TPC-H SF1\n+# group: [tpch]\n+\n+require tpch\n+\n+load __TEST_DIR__/tpch_sf1_struct.db\n+\n+statement ok\n+CALL dbgen(sf=1, suffix='_normal');\n+\n+statement ok\n+CREATE TABLE lineitem_struct AS SELECT {\n+'l_orderkey': l_orderkey,\n+'l_partkey': l_partkey,\n+'l_suppkey': l_suppkey,\n+'l_linenumber': l_linenumber,\n+'l_quantity': l_quantity,\n+'l_extendedprice': l_extendedprice,\n+'l_discount': l_discount,\n+'l_tax': l_tax,\n+'l_returnflag': l_returnflag,\n+'l_linestatus': l_linestatus,\n+'l_shipdate': l_shipdate,\n+'l_commitdate': l_commitdate,\n+'l_receiptdate': l_receiptdate,\n+'l_shipinstruct': l_shipinstruct,\n+'l_shipmode': l_shipmode,\n+'l_comment': l_comment\n+} c FROM lineitem_normal;\n+\n+statement ok\n+CREATE VIEW lineitem AS SELECT\n+c['l_orderkey'] AS l_orderkey,\n+c['l_partkey'] AS l_partkey,\n+c['l_suppkey'] AS l_suppkey,\n+c['l_linenumber'] AS l_linenumber,\n+c['l_quantity'] AS l_quantity,\n+c['l_extendedprice'] AS l_extendedprice,\n+c['l_discount'] AS l_discount,\n+c['l_tax'] AS l_tax,\n+c['l_returnflag'] AS l_returnflag,\n+c['l_linestatus'] AS l_linestatus,\n+c['l_shipdate'] AS l_shipdate,\n+c['l_commitdate'] AS l_commitdate,\n+c['l_receiptdate'] AS l_receiptdate,\n+c['l_shipinstruct'] AS l_shipinstruct,\n+c['l_shipmode'] AS l_shipmode,\n+c['l_comment'] AS l_comment\n+FROM lineitem_struct\n+\n+statement ok\n+CREATE TABLE orders_struct AS SELECT {\n+'o_orderkey': o_orderkey,\n+'o_custkey': o_custkey,\n+'o_orderstatus': o_orderstatus,\n+'o_totalprice': o_totalprice,\n+'o_orderdate': o_orderdate,\n+'o_orderpriority': o_orderpriority,\n+'o_clerk': o_clerk,\n+'o_shippriority': o_shippriority,\n+'o_comment': o_comment\n+} c FROM orders_normal;\n+\n+statement ok\n+CREATE VIEW orders AS SELECT\n+c['o_orderkey'] AS o_orderkey,\n+c['o_custkey'] AS o_custkey,\n+c['o_orderstatus'] AS o_orderstatus,\n+c['o_totalprice'] AS o_totalprice,\n+c['o_orderdate'] AS o_orderdate,\n+c['o_orderpriority'] AS o_orderpriority,\n+c['o_clerk'] AS o_clerk,\n+c['o_shippriority'] AS o_shippriority,\n+c['o_comment'] AS o_comment\n+FROM orders_struct\n+\n+statement ok\n+CREATE TABLE part_struct AS SELECT {\n+'p_partkey': p_partkey,\n+'p_name': p_name,\n+'p_mfgr': p_mfgr,\n+'p_brand': p_brand,\n+'p_type': p_type,\n+'p_size': p_size,\n+'p_container': p_container,\n+'p_retailprice': p_retailprice,\n+'p_comment': p_comment\n+} c FROM part_normal;\n+\n+statement ok\n+CREATE VIEW part AS SELECT\n+c['p_partkey'] AS p_partkey,\n+c['p_name'] AS p_name,\n+c['p_mfgr'] AS p_mfgr,\n+c['p_brand'] AS p_brand,\n+c['p_type'] AS p_type,\n+c['p_size'] AS p_size,\n+c['p_container'] AS p_container,\n+c['p_retailprice'] AS p_retailprice,\n+c['p_comment'] AS p_comment\n+FROM part_struct\n+\n+statement ok\n+CREATE TABLE partsupp_struct AS SELECT {\n+'ps_partkey': ps_partkey,\n+'ps_suppkey': ps_suppkey,\n+'ps_availqty': ps_availqty,\n+'ps_supplycost': ps_supplycost,\n+'ps_comment': ps_comment\n+} c FROM partsupp_normal;\n+\n+statement ok\n+CREATE VIEW partsupp AS SELECT\n+c['ps_partkey'] AS ps_partkey,\n+c['ps_suppkey'] AS ps_suppkey,\n+c['ps_availqty'] AS ps_availqty,\n+c['ps_supplycost'] AS ps_supplycost,\n+c['ps_comment'] AS ps_comment\n+FROM partsupp_struct\n+\n+statement ok\n+CREATE TABLE customer_struct AS SELECT {\n+'c_custkey': c_custkey,\n+'c_name': c_name,\n+'c_address': c_address,\n+'c_nationkey': c_nationkey,\n+'c_phone': c_phone,\n+'c_acctbal': c_acctbal,\n+'c_mktsegment': c_mktsegment,\n+'c_comment': c_comment\n+} c FROM customer_normal;\n+\n+statement ok\n+CREATE VIEW customer AS SELECT\n+c['c_custkey'] AS c_custkey,\n+c['c_name'] AS c_name,\n+c['c_address'] AS c_address,\n+c['c_nationkey'] AS c_nationkey,\n+c['c_phone'] AS c_phone,\n+c['c_acctbal'] AS c_acctbal,\n+c['c_mktsegment'] AS c_mktsegment,\n+c['c_comment'] AS c_comment\n+FROM customer_struct\n+\n+statement ok\n+CREATE TABLE region_struct AS SELECT {\n+'r_regionkey': r_regionkey,\n+'r_name': r_name,\n+'r_comment': r_comment\n+} c FROM region_normal;\n+\n+statement ok\n+CREATE VIEW region AS SELECT\n+c['r_regionkey'] AS r_regionkey,\n+c['r_name'] AS r_name,\n+c['r_comment'] AS r_comment\n+FROM region_struct\n+\n+statement ok\n+CREATE TABLE supplier_struct AS SELECT {\n+'s_suppkey': s_suppkey,\n+'s_name': s_name,\n+'s_address': s_address,\n+'s_nationkey': s_nationkey,\n+'s_phone': s_phone,\n+'s_acctbal': s_acctbal,\n+'s_comment': s_comment\n+} c FROM supplier_normal;\n+\n+statement ok\n+CREATE VIEW supplier AS SELECT\n+c['s_suppkey'] AS s_suppkey,\n+c['s_name'] AS s_name,\n+c['s_address'] AS s_address,\n+c['s_nationkey'] AS s_nationkey,\n+c['s_phone'] AS s_phone,\n+c['s_acctbal'] AS s_acctbal,\n+c['s_comment'] AS s_comment\n+FROM supplier_struct\n+\n+statement ok\n+CREATE TABLE nation_struct AS SELECT {\n+'n_nationkey': n_nationkey,\n+'n_name': n_name,\n+'n_regionkey': n_regionkey,\n+'n_comment': n_comment\n+} c FROM nation_normal;\n+\n+statement ok\n+CREATE VIEW nation AS SELECT\n+c['n_nationkey'] AS n_nationkey,\n+c['n_name'] AS n_name,\n+c['n_regionkey'] AS n_regionkey,\n+c['n_comment'] AS n_comment\n+FROM nation_struct\n+\n+loop i 1 9\n+\n+query I\n+PRAGMA tpch(${i})\n+----\n+<FILE>:extension/tpch/dbgen/answers/sf1/q0${i}.csv\n+\n+endloop\n+\n+loop i 10 23\n+\n+query I\n+PRAGMA tpch(${i})\n+----\n+<FILE>:extension/tpch/dbgen/answers/sf1/q${i}.csv\n+\n+endloop\ndiff --git a/test/sql/types/list/test_nested_list.test b/test/sql/types/list/test_nested_list.test\nindex 2c3a02c97173..f2c81b957dbf 100644\n--- a/test/sql/types/list/test_nested_list.test\n+++ b/test/sql/types/list/test_nested_list.test\n@@ -9,6 +9,12 @@ PRAGMA enable_verification\n statement ok\n PRAGMA threads=1\n \n+# scalar nested lists\n+query I\n+SELECT [{'i': 1,'j': [2, 3]}, NULL, {'i': 1, 'j': [2, 3]}];\n+----\n+[{'i': 1, 'j': [2, 3]}, NULL, {'i': 1, 'j': [2, 3]}]\n+\n statement ok\n CREATE TABLE list_data (g INTEGER, e INTEGER)\n \ndiff --git a/test/sql/types/struct/nested_structs.test b/test/sql/types/struct/nested_structs.test\nnew file mode 100644\nindex 000000000000..215ed9da3092\n--- /dev/null\n+++ b/test/sql/types/struct/nested_structs.test\n@@ -0,0 +1,85 @@\n+# name: test/sql/types/struct/nested_structs.test\n+# description: Test storing nested structs in tables\n+# group: [struct]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+CREATE TABLE a(c ROW(i ROW(a INTEGER), j INTEGER));\n+\n+statement ok\n+INSERT INTO a VALUES ({\n+\t'i': {\n+\t\t'a': 3\n+\t},\n+\t'j': 4\n+})\n+\n+query I\n+SELECT * FROM a\n+----\n+{'i': {'a': 3}, 'j': 4}\n+\n+query I\n+SELECT ((c).i).a FROM a\n+----\n+3\n+\n+statement ok\n+INSERT INTO a VALUES (NULL)\n+\n+query I\n+SELECT * FROM a\n+----\n+{'i': {'a': 3}, 'j': 4}\n+NULL\n+\n+query I\n+SELECT ((c).i).a FROM a\n+----\n+3\n+NULL\n+\n+# nulls at different levels\n+statement ok\n+INSERT INTO a VALUES (ROW(ROW(NULL), 1))\n+\n+statement ok\n+INSERT INTO a VALUES (ROW(ROW(1), NULL))\n+\n+statement ok\n+INSERT INTO a VALUES (ROW(NULL, 1))\n+\n+query I\n+SELECT * FROM a\n+----\n+{'i': {'a': 3}, 'j': 4}\n+NULL\n+{'i': {'a': NULL}, 'j': 1}\n+{'i': {'a': 1}, 'j': NULL}\n+{'i': NULL, 'j': 1}\n+\n+# create table as\n+statement ok\n+CREATE TABLE b AS SELECT {\n+\t'a': {\n+\t\t'a': 1,\n+\t\t'b': 'hello'\n+\t}\n+} c;\n+\n+query I\n+SELECT (c).a FROM b\n+----\n+{'a': 1, 'b': hello}\n+\n+# nested struct mismatch on insertion\n+statement error\n+INSERT INTO a VALUES (1)\n+\n+statement error\n+INSERT INTO a VALUES (ROW(1, 2))\n+\n+statement error\n+INSERT INTO a VALUES (ROW(ROW(1, 2, 3), 1))\ndiff --git a/test/sql/types/struct/struct_case.test b/test/sql/types/struct/struct_case.test\nnew file mode 100644\nindex 000000000000..46666823d069\n--- /dev/null\n+++ b/test/sql/types/struct/struct_case.test\n@@ -0,0 +1,104 @@\n+# name: test/sql/types/struct/struct_case.test\n+# description: Test struct case statement\n+# group: [struct]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+# constant case\n+query I\n+SELECT CASE WHEN 1=1 THEN {'i': 1} ELSE {'i': 2} END\n+----\n+{'i': 1}\n+\n+query I\n+SELECT CASE WHEN 1=0 THEN {'i': 1} ELSE {'i': 2} END\n+----\n+{'i': 2}\n+\n+# null values\n+query I\n+SELECT CASE WHEN 1=1 THEN NULL ELSE {'i': 2} END\n+----\n+NULL\n+\n+query I\n+SELECT CASE WHEN 1=0 THEN NULL ELSE {'i': NULL} END\n+----\n+{'i': NULL}\n+\n+# now with a table\n+query II\n+SELECT i, CASE WHEN i%2=0 THEN {'i': 1} ELSE {'i': 2} END FROM range(6) tbl(i)\n+----\n+0\t{'i': 1}\n+1\t{'i': 2}\n+2\t{'i': 1}\n+3\t{'i': 2}\n+4\t{'i': 1}\n+5\t{'i': 2}\n+\n+# strings\n+query II\n+SELECT i, CASE WHEN i%2=0 THEN {'i': 'hello'} ELSE {'i': 'world'} END FROM range(6) tbl(i)\n+----\n+0\t{'i': hello}\n+1\t{'i': world}\n+2\t{'i': hello}\n+3\t{'i': world}\n+4\t{'i': hello}\n+5\t{'i': world}\n+\n+# nested structs\n+query II\n+SELECT i, CASE WHEN i%2=0 THEN {'i': 'hello', 'j': {'a': 3, 'b': NULL}} ELSE {'i': 'world', 'j': {'a': 7, 'b': 22}} END FROM range(6) tbl(i)\n+----\n+0\t{'i': hello, 'j': {'a': 3, 'b': NULL}}\n+1\t{'i': world, 'j': {'a': 7, 'b': 22}}\n+2\t{'i': hello, 'j': {'a': 3, 'b': NULL}}\n+3\t{'i': world, 'j': {'a': 7, 'b': 22}}\n+4\t{'i': hello, 'j': {'a': 3, 'b': NULL}}\n+5\t{'i': world, 'j': {'a': 7, 'b': 22}}\n+\n+# lists in structs\n+query II\n+SELECT i, CASE WHEN i%2=0 THEN {'i': [1,2,3]} ELSE {'i': [7,8]} END FROM range(6) tbl(i)\n+----\n+0\t{'i': [1, 2, 3]}\n+1\t{'i': [7, 8]}\n+2\t{'i': [1, 2, 3]}\n+3\t{'i': [7, 8]}\n+4\t{'i': [1, 2, 3]}\n+5\t{'i': [7, 8]}\n+\n+# null values\n+query II\n+SELECT i, CASE WHEN i%2=0 THEN {'i': [1,2,3]} ELSE NULL END FROM range(6) tbl(i)\n+----\n+0\t{'i': [1, 2, 3]}\n+1\tNULL\n+2\t{'i': [1, 2, 3]}\n+3\tNULL\n+4\t{'i': [1, 2, 3]}\n+5\tNULL\n+\n+query II\n+SELECT i, CASE WHEN i%2=0 THEN {'i': [1,2,3]} ELSE {'i': NULL} END FROM range(6) tbl(i)\n+----\n+0\t{'i': [1, 2, 3]}\n+1\t{'i': NULL}\n+2\t{'i': [1, 2, 3]}\n+3\t{'i': NULL}\n+4\t{'i': [1, 2, 3]}\n+5\t{'i': NULL}\n+\n+# different types on child lists\n+query II\n+SELECT i, CASE WHEN i%2=0 THEN {'i': [1,2,3]} ELSE {'i': ['hello']} END FROM range(6) tbl(i)\n+----\n+0\t{'i': [1, 2, 3]}\n+1\t{'i': [hello]}\n+2\t{'i': [1, 2, 3]}\n+3\t{'i': [hello]}\n+4\t{'i': [1, 2, 3]}\n+5\t{'i': [hello]}\ndiff --git a/test/sql/types/struct/struct_cast.test b/test/sql/types/struct/struct_cast.test\nnew file mode 100644\nindex 000000000000..061506d17f86\n--- /dev/null\n+++ b/test/sql/types/struct/struct_cast.test\n@@ -0,0 +1,112 @@\n+# name: test/sql/types/struct/struct_cast.test\n+# description: Test struct cast\n+# group: [struct]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+# constant casts\n+query I\n+SELECT {'i': 1, 'j': 2}::ROW(i BIGINT, j VARCHAR);\n+----\n+{'i': 1, 'j': 2}\n+\n+query I\n+SELECT {'i': NULL, 'j': 'hello'}::ROW(i BIGINT, j VARCHAR);\n+----\n+{'i': NULL, 'j': hello}\n+\n+query I\n+SELECT {'i': NULL, 'j': NULL}::ROW(i BIGINT, j VARCHAR);\n+----\n+{'i': NULL, 'j': NULL}\n+\n+query I\n+SELECT NULL::ROW(i BIGINT, j VARCHAR);\n+----\n+NULL\n+\n+# cast and extract\n+query I\n+SELECT ({'i': NULL, 'j': NULL}::ROW(i BIGINT, j VARCHAR))['i'];\n+----\n+NULL\n+\n+query I\n+SELECT ({'i': NULL, 'j': NULL})['i']\n+----\n+NULL\n+\n+query I\n+SELECT (NULL::ROW(i BIGINT, j VARCHAR))['i'];\n+----\n+NULL\n+\n+# nested struct casts\n+query I\n+SELECT {'i': 1, 'j': {'a': 2, 'b': 3}}::ROW(i BIGINT, j ROW(a BIGINT, b VARCHAR));\n+----\n+{'i': 1, 'j': {'a': 2, 'b': 3}}\n+\n+query I\n+SELECT {'i': 1, 'j': {'a': NULL, 'b': 3}}::ROW(i BIGINT, j ROW(a BIGINT, b VARCHAR));\n+----\n+{'i': 1, 'j': {'a': NULL, 'b': 3}}\n+\n+query I\n+SELECT {'i': 1, 'j': {'a': 2, 'b': NULL}}::ROW(i BIGINT, j ROW(a BIGINT, b VARCHAR));\n+----\n+{'i': 1, 'j': {'a': 2, 'b': NULL}}\n+\n+query I\n+SELECT {'i': 1, 'j': NULL}::ROW(i BIGINT, j ROW(a BIGINT, b VARCHAR));\n+----\n+{'i': 1, 'j': NULL}\n+\n+# cast and extract\n+query I\n+SELECT ({'i': 1, 'j': NULL}::ROW(i BIGINT, j ROW(a BIGINT, b VARCHAR)))['j']['a'];\n+----\n+NULL\n+\n+query I\n+SELECT NULL::ROW(i BIGINT, j ROW(a BIGINT, b VARCHAR));\n+----\n+NULL\n+\n+# now the same but non-constant\n+statement ok\n+CREATE TABLE structs(s ROW(i INTEGER, j INTEGER))\n+\n+statement ok\n+INSERT INTO structs VALUES ({'i': 1, 'j': 2}), ({'i': NULL, 'j': 2}), ({'i': 1, 'j': NULL}), (NULL)\n+\n+query I\n+SELECT s::ROW(i BIGINT, j VARCHAR) FROM structs\n+----\n+{'i': 1, 'j': 2}\n+{'i': NULL, 'j': 2}\n+{'i': 1, 'j': NULL}\n+NULL\n+\n+# nested struct\n+statement ok\n+CREATE TABLE nested_structs(s ROW(i INTEGER, j ROW(a INTEGER, b INTEGER)))\n+\n+statement ok\n+INSERT INTO nested_structs VALUES\n+({'i': 1, 'j': {'a': 2, 'b': 3}}),\n+({'i': 1, 'j': {'a': NULL, 'b': 3}}),\n+({'i': 1, 'j': {'a': 2, 'b': NULL}}),\n+({'i': 1, 'j': NULL}),\n+(NULL)\n+\n+\n+query I\n+SELECT s::ROW(i BIGINT, j ROW(a BIGINT, b VARCHAR)) FROM nested_structs\n+----\n+{'i': 1, 'j': {'a': 2, 'b': 3}}\n+{'i': 1, 'j': {'a': NULL, 'b': 3}}\n+{'i': 1, 'j': {'a': 2, 'b': NULL}}\n+{'i': 1, 'j': NULL}\n+NULL\ndiff --git a/test/sql/types/struct/struct_dict.test b/test/sql/types/struct/struct_dict.test\nindex 7c71a4be8cb6..e65585819b51 100644\n--- a/test/sql/types/struct/struct_dict.test\n+++ b/test/sql/types/struct/struct_dict.test\n@@ -2,6 +2,9 @@\n # description: Test dict syntax for structs\n # group: [struct]\n \n+statement ok\n+PRAGMA enable_verification\n+\n query I\n SELECT {'i': 1, 'j': 2};\n ----\ndiff --git a/test/sql/types/struct/struct_index.test b/test/sql/types/struct/struct_index.test\nnew file mode 100644\nindex 000000000000..45e3c82bc626\n--- /dev/null\n+++ b/test/sql/types/struct/struct_index.test\n@@ -0,0 +1,112 @@\n+# name: test/sql/types/struct/struct_index.test\n+# description: Test struct lookups using an index\n+# group: [struct]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+CREATE TABLE a(id INTEGER PRIMARY KEY, c ROW(i ROW(a INTEGER), j INTEGER));\n+\n+statement ok\n+INSERT INTO a VALUES (1, {\n+\t'i': {\n+\t\t'a': 3\n+\t},\n+\t'j': 4\n+})\n+\n+# simple lookup\n+query II\n+SELECT * FROM a WHERE id=1\n+----\n+1\t{'i': {'a': 3}, 'j': 4}\n+\n+# now with null values at different levels\n+statement ok\n+INSERT INTO a VALUES (2, NULL)\n+\n+statement ok\n+INSERT INTO a VALUES (3, ROW(ROW(NULL), 1))\n+\n+statement ok\n+INSERT INTO a VALUES (4, ROW(ROW(1), NULL))\n+\n+statement ok\n+INSERT INTO a VALUES (5, ROW(NULL, 1))\n+\n+query II\n+SELECT * FROM a WHERE id=2\n+----\n+2\tNULL\n+\n+query II\n+SELECT * FROM a WHERE id=3\n+----\n+3\t{'i': {'a': NULL}, 'j': 1}\n+\n+query II\n+SELECT * FROM a WHERE id=4\n+----\n+4\t{'i': {'a': 1}, 'j': NULL}\n+\n+query II\n+SELECT * FROM a WHERE id=5\n+----\n+5\t{'i': NULL, 'j': 1}\n+\n+# test index construction on a table with structs\n+statement ok\n+DROP TABLE a;\n+\n+statement ok\n+CREATE TABLE a(id INTEGER, c ROW(i ROW(a INTEGER), j INTEGER));\n+\n+statement ok\n+INSERT INTO a VALUES (1, {\n+\t'i': {\n+\t\t'a': 3\n+\t},\n+\t'j': 4\n+})\n+\n+statement ok\n+INSERT INTO a VALUES (2, NULL)\n+\n+statement ok\n+INSERT INTO a VALUES (3, ROW(ROW(NULL), 1))\n+\n+statement ok\n+INSERT INTO a VALUES (4, ROW(ROW(1), NULL))\n+\n+statement ok\n+INSERT INTO a VALUES (5, ROW(NULL, 1))\n+\n+statement ok\n+CREATE INDEX a_index ON a(id);\n+\n+query II\n+SELECT * FROM a WHERE id=1\n+----\n+1\t{'i': {'a': 3}, 'j': 4}\n+\n+query II\n+SELECT * FROM a WHERE id=2\n+----\n+2\tNULL\n+\n+query II\n+SELECT * FROM a WHERE id=3\n+----\n+3\t{'i': {'a': NULL}, 'j': 1}\n+\n+query II\n+SELECT * FROM a WHERE id=4\n+----\n+4\t{'i': {'a': 1}, 'j': NULL}\n+\n+query II\n+SELECT * FROM a WHERE id=5\n+----\n+5\t{'i': NULL, 'j': 1}\n+\ndiff --git a/test/sql/types/struct/struct_operations.test b/test/sql/types/struct/struct_operations.test\nnew file mode 100644\nindex 000000000000..df57ed589696\n--- /dev/null\n+++ b/test/sql/types/struct/struct_operations.test\n@@ -0,0 +1,50 @@\n+# name: test/sql/types/struct/struct_operations.test\n+# description: Test various operations on structs\n+# group: [struct]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+CREATE TABLE a(id INTEGER, b ROW(i INTEGER, j INTEGER));\n+\n+statement ok\n+INSERT INTO a VALUES (1, {i: 1, j: 2});\n+\n+statement ok\n+CREATE TABLE b(id INTEGER, j VARCHAR);\n+\n+statement ok\n+INSERT INTO b VALUES (1, 'hello');\n+\n+# unequality join\n+query IIII\n+SELECT * FROM a LEFT JOIN b ON a.id<>b.id\n+----\n+1\t{'i': 1, 'j': 2}\tNULL\tNULL\n+\n+query IIII\n+SELECT * FROM a RIGHT JOIN b ON a.id<>b.id\n+----\n+NULL\tNULL\t1\thello\n+\n+# range join\n+query IIII\n+SELECT * FROM a LEFT JOIN b ON a.id>b.id\n+----\n+1\t{'i': 1, 'j': 2}\tNULL\tNULL\n+\n+query IIII\n+SELECT * FROM a RIGHT JOIN b ON a.id>b.id\n+----\n+NULL\tNULL\t1\thello\n+\n+# unsupported operations\n+# TODO\n+mode skip\n+\n+# subquery\n+query I\n+SELECT (SELECT b FROM a)\n+----\n+{'i': 1, 'j': 2}\n\\ No newline at end of file\ndiff --git a/test/sql/types/struct/struct_tables.test b/test/sql/types/struct/struct_tables.test\nnew file mode 100644\nindex 000000000000..a1abf898db39\n--- /dev/null\n+++ b/test/sql/types/struct/struct_tables.test\n@@ -0,0 +1,68 @@\n+# name: test/sql/types/struct/struct_tables.test\n+# description: Test storing structs in in-memory tables\n+# group: [struct]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+CREATE TABLE a(b ROW(i INTEGER, j INTEGER));\n+\n+# insert standard struct\n+statement ok\n+INSERT INTO a VALUES (STRUCT_PACK(i := 1, j:= 2));\n+\n+query I\n+SELECT * FROM a ORDER BY (b).i;\n+----\n+{'i': 1, 'j': 2}\n+\n+statement ok\n+INSERT INTO a VALUES (NULL);\n+\n+query I\n+SELECT * FROM a ORDER BY (b).i;\n+----\n+NULL\n+{'i': 1, 'j': 2}\n+\n+# unnamed struct\n+statement ok\n+INSERT INTO a VALUES (ROW(2, 3));\n+\n+query I\n+SELECT * FROM a ORDER BY (b).i;\n+----\n+NULL\n+{'i': 1, 'j': 2}\n+{'i': 2, 'j': 3}\n+\n+# null values in children\n+statement ok\n+INSERT INTO a VALUES (ROW(3, NULL)), (ROW(NULL, 4));\n+\n+query I\n+SELECT * FROM a ORDER BY (b).i, (b).j;\n+----\n+NULL\n+{'i': NULL, 'j': 4}\n+{'i': 1, 'j': 2}\n+{'i': 2, 'j': 3}\n+{'i': 3, 'j': NULL}\n+\n+# incorrect number of struct entries\n+statement error\n+INSERT INTO a VALUES (ROW(1, 2, 3))\n+\n+statement error\n+INSERT INTO a VALUES (ROW(1))\n+\n+# incorrect types\n+statement error\n+INSERT INTO a VALUES (ROW('hello', 1))\n+\n+statement error\n+INSERT INTO a VALUES (ROW('hello', [1, 2]))\n+\n+statement error\n+INSERT INTO a VALUES (ROW(1, ROW(1, 7)))\ndiff --git a/test/sql/types/struct/struct_updates.test b/test/sql/types/struct/struct_updates.test\nnew file mode 100644\nindex 000000000000..86c28f834cf2\n--- /dev/null\n+++ b/test/sql/types/struct/struct_updates.test\n@@ -0,0 +1,103 @@\n+# name: test/sql/types/struct/struct_updates.test\n+# description: Test updates on struct tables\n+# group: [struct]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+CREATE TABLE a(b ROW(i INTEGER, j INTEGER));\n+\n+statement ok\n+INSERT INTO a VALUES ({'i': 1, 'j': 2});\n+\n+query I\n+SELECT * FROM a ORDER BY (b).i;\n+----\n+{'i': 1, 'j': 2}\n+\n+# standard update\n+statement ok\n+UPDATE a SET b={'i': 3, 'j': 4}\n+\n+query I\n+SELECT * FROM a ORDER BY (b).i;\n+----\n+{'i': 3, 'j': 4}\n+\n+# NULL update\n+statement ok\n+UPDATE a SET b=NULL\n+\n+query I\n+SELECT * FROM a ORDER BY (b).i;\n+----\n+NULL\n+\n+statement ok\n+UPDATE a SET b={'i': NULL, 'j': 4}\n+\n+query I\n+SELECT * FROM a ORDER BY (b).i;\n+----\n+{'i': NULL, 'j': 4}\n+\n+statement ok\n+UPDATE a SET b={'i': 3, 'j': NULL}\n+\n+query I\n+SELECT * FROM a ORDER BY (b).i;\n+----\n+{'i': 3, 'j': NULL}\n+\n+# rollbacks\n+statement ok\n+BEGIN TRANSACTION;\n+\n+statement ok\n+UPDATE a SET b={'i': 3, 'j': 4}\n+\n+query I\n+SELECT * FROM a ORDER BY (b).i;\n+----\n+{'i': 3, 'j': 4}\n+\n+statement ok\n+ROLLBACK;\n+\n+query I\n+SELECT * FROM a ORDER BY (b).i;\n+----\n+{'i': 3, 'j': NULL}\n+\n+# updates with a filter\n+statement ok\n+INSERT INTO a VALUES ({'i': 2, 'j': 3});\n+\n+query I\n+SELECT * FROM a\n+----\n+{'i': 3, 'j': NULL}\n+{'i': 2, 'j': 3}\n+\n+statement ok\n+INSERT INTO a VALUES ({'i': 3, 'j': 4});\n+\n+query I\n+SELECT * FROM a\n+----\n+{'i': 3, 'j': NULL}\n+{'i': 2, 'j': 3}\n+{'i': 3, 'j': 4}\n+\n+query I\n+UPDATE a SET b={'i': NULL, 'j': NULL} WHERE (b).j>=3\n+----\n+2\n+\n+query I\n+SELECT * FROM a\n+----\n+{'i': 3, 'j': NULL}\n+{'i': NULL, 'j': NULL}\n+{'i': NULL, 'j': NULL}\ndiff --git a/test/sql/types/struct/test_struct.test b/test/sql/types/struct/test_struct.test\nindex 8628227611fe..caed103e6685 100644\n--- a/test/sql/types/struct/test_struct.test\n+++ b/test/sql/types/struct/test_struct.test\n@@ -173,7 +173,7 @@ SELECT STRUCT_EXTRACT(STRUCT_PACK(xx := e, yy := g), g) FROM struct_data\n statement error\n SELECT STRUCT_EXTRACT(STRUCT_PACK(xx := e, yy := g), '42') FROM struct_data\n \n-statement error\n+statement ok\n CREATE TABLE test AS SELECT e, STRUCT_PACK(e) FROM struct_data\n \n statement ok\n",
  "problem_statement": "Segfault when using struct column and inserting null in it\n**What does happen?**\r\n\r\n```sql\r\ncreate table test(s struct(a int));\r\ninsert into test(s) values (null);\r\n```\r\n\r\nI get `fish: \u201cduckdb pouet.db\u201d terminated by signal SIGSEGV (Address boundary error)`\r\n\r\n**What should happen?**\r\nA `null` value should be inserted into a new row.\r\n\r\n**Environment (please complete the following information):**\r\n - OS: Ubuntu 21.04\r\n - DuckDB Version 0.2.6 and also current master\r\n\r\n**Before submitting**\r\n- [x] Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\r\n- [x] Have you tried this on the latest `master` branch? In case you cannot compile, you may find some binaries here: https://github.com/duckdb/duckdb/releases/tag/master-builds\r\n\n",
  "hints_text": "Creating persistent tables with STRUCTs in them is not supported yet. Regardless, it should of course not crash.\ndo you mean that for now structs and lists are only used in views ?\r\n\r\nany idea when this feature will be available ?\nI'm going to work on struct storage next. This will most likely be part of the next release.",
  "created_at": "2021-06-04T20:45:48Z"
}