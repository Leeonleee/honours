diff --git a/src/common/types.cpp b/src/common/types.cpp
index 2746c11b4f3e..38d34f58ed92 100644
--- a/src/common/types.cpp
+++ b/src/common/types.cpp
@@ -92,12 +92,11 @@ PhysicalType LogicalType::GetInternalType() {
 		return PhysicalType::VARCHAR;
 	case LogicalTypeId::INTERVAL:
 		return PhysicalType::INTERVAL;
+	case LogicalTypeId::MAP:
 	case LogicalTypeId::STRUCT:
 		return PhysicalType::STRUCT;
 	case LogicalTypeId::LIST:
 		return PhysicalType::LIST;
-	case LogicalTypeId::MAP:
-		return PhysicalType::MAP;
 	case LogicalTypeId::HASH:
 		return PhysicalType::HASH;
 	case LogicalTypeId::POINTER:
@@ -210,8 +209,6 @@ string TypeIdToString(PhysicalType type) {
 		return "STRUCT<?>";
 	case PhysicalType::LIST:
 		return "LIST<?>";
-	case PhysicalType::MAP:
-		return "MAP<?>";
 	case PhysicalType::INVALID:
 		return "INVALID";
 	case PhysicalType::BIT:
@@ -256,7 +253,6 @@ idx_t GetTypeIdSize(PhysicalType type) {
 		return sizeof(string_t);
 	case PhysicalType::INTERVAL:
 		return sizeof(interval_t);
-	case PhysicalType::MAP:
 	case PhysicalType::STRUCT:
 		return 0; // no own payload
 	case PhysicalType::LIST:
@@ -737,6 +733,21 @@ LogicalType LogicalType::MaxLogicalType(const LogicalType &left, const LogicalTy
 			    make_pair(left.child_types()[0].first,
 			              MaxLogicalType(left.child_types()[0].second, right.child_types()[0].second)));
 			return LogicalType(LogicalTypeId::LIST, move(child_types));
+		} else if (left.id() == LogicalTypeId::STRUCT) {
+			// struct: perform recursively
+			auto &left_child_types = left.child_types();
+			auto &right_child_types = right.child_types();
+			if (left_child_types.size() != right_child_types.size()) {
+				// child types are not of equal size, we can't cast anyway
+				// just return the left child
+				return left;
+			}
+			child_list_t<LogicalType> child_types;
+			for (idx_t i = 0; i < left_child_types.size(); i++) {
+				auto child_type = MaxLogicalType(left_child_types[i].second, right_child_types[i].second);
+				child_types.push_back(make_pair(left_child_types[i].first, move(child_type)));
+			}
+			return LogicalType(LogicalTypeId::STRUCT, move(child_types));
 		} else {
 			// types are equal but no extra specifier: just return the type
 			// FIXME: LIST and STRUCT?
diff --git a/src/common/types/chunk_collection.cpp b/src/common/types/chunk_collection.cpp
index 55639fb20335..1120aade2785 100644
--- a/src/common/types/chunk_collection.cpp
+++ b/src/common/types/chunk_collection.cpp
@@ -438,7 +438,6 @@ void ChunkCollection::MaterializeSortedChunk(DataChunk &target, idx_t order[], i
 		case PhysicalType::INTERVAL:
 			TemplatedSetValues<interval_t>(this, target.data[col_idx], order, col_idx, start_offset, remaining_data);
 			break;
-		case PhysicalType::MAP:
 		case PhysicalType::LIST:
 		case PhysicalType::STRUCT: {
 			for (idx_t row_idx = 0; row_idx < remaining_data; row_idx++) {
@@ -602,7 +601,6 @@ idx_t ChunkCollection::MaterializeHeapChunk(DataChunk &target, idx_t order[], id
 			TemplatedSetValues<string_t>(this, target.data[col_idx], order, col_idx, start_offset, remaining_data);
 			break;
 		// TODO this is ugly and sloooow!
-		case PhysicalType::MAP:
 		case PhysicalType::STRUCT:
 		case PhysicalType::LIST: {
 			for (idx_t row_idx = 0; row_idx < remaining_data; row_idx++) {
diff --git a/src/common/types/row_data_collection.cpp b/src/common/types/row_data_collection.cpp
index fd33f821a1e2..a8d15b58c018 100644
--- a/src/common/types/row_data_collection.cpp
+++ b/src/common/types/row_data_collection.cpp
@@ -271,7 +271,6 @@ void RowDataCollection::ComputeEntrySizes(Vector &v, idx_t entry_sizes[], idx_t
 		case PhysicalType::VARCHAR:
 			ComputeStringEntrySizes(v, entry_sizes, vcount, offset);
 			break;
-		case PhysicalType::MAP:
 		case PhysicalType::STRUCT:
 			ComputeStructEntrySizes(v, entry_sizes, vcount, offset);
 			break;
@@ -596,7 +595,6 @@ void RowDataCollection::SerializeVector(Vector &v, idx_t vcount, const Selection
 		case PhysicalType::VARCHAR:
 			SerializeStringVector(v, vcount, sel, ser_count, col_idx, key_locations, validitymask_locations, offset);
 			break;
-		case PhysicalType::MAP:
 		case PhysicalType::STRUCT:
 			SerializeStructVector(v, vcount, sel, ser_count, col_idx, key_locations, validitymask_locations, offset);
 			break;
@@ -910,7 +908,6 @@ void RowDataCollection::DeserializeIntoVector(Vector &v, const idx_t &vcount, co
 	case PhysicalType::VARCHAR:
 		DeserializeIntoStringVector(v, vcount, col_idx, key_locations, validitymask_locations);
 		break;
-	case PhysicalType::MAP:
 	case PhysicalType::STRUCT:
 		DeserializeIntoStructVector(v, vcount, col_idx, key_locations, validitymask_locations);
 		break;
diff --git a/src/common/types/vector.cpp b/src/common/types/vector.cpp
index 82daa9d47eb9..b9a004a2c062 100644
--- a/src/common/types/vector.cpp
+++ b/src/common/types/vector.cpp
@@ -155,11 +155,13 @@ void Vector::Initialize(const LogicalType &new_type, bool zero_data) {
 
 		auxiliary = move(struct_buffer);
 	}
-	if (GetTypeIdSize(type.InternalType()) > 0) {
+	auto internal_type = type.InternalType();
+	auto type_size = GetTypeIdSize(internal_type);
+	if (type_size > 0) {
 		buffer = VectorBuffer::CreateStandardVector(VectorType::FLAT_VECTOR, type);
 		data = buffer->GetData();
 		if (zero_data) {
-			memset(data, 0, STANDARD_VECTOR_SIZE * GetTypeIdSize(type.InternalType()));
+			memset(data, 0, STANDARD_VECTOR_SIZE * type_size);
 		}
 	} else {
 		buffer = VectorBuffer::CreateStandardVector(VectorType::FLAT_VECTOR, type);
@@ -247,7 +249,9 @@ void Vector::SetValue(idx_t index, const Value &val) {
 
 	validity.EnsureWritable();
 	validity.Set(index, !val.is_null);
-	if (val.is_null) {
+	if (val.is_null && GetType().InternalType() != PhysicalType::STRUCT) {
+		// for structs we still need to set the child-entries to NULL
+		// so we do not bail out yet
 		return;
 	}
 
@@ -326,14 +330,18 @@ void Vector::SetValue(idx_t index, const Value &val) {
 		break;
 	case LogicalTypeId::MAP:
 	case LogicalTypeId::STRUCT: {
-		auto &children = StructVector::GetEntries(*this);
-		D_ASSERT(children.size() == val.struct_value.size());
+		D_ASSERT(GetVectorType() == VectorType::CONSTANT_VECTOR || GetVectorType() == VectorType::FLAT_VECTOR);
 
-		for (size_t i = 0; i < val.struct_value.size(); i++) {
-			auto &struct_child = val.struct_value[i];
-			D_ASSERT(GetVectorType() == VectorType::CONSTANT_VECTOR || GetVectorType() == VectorType::FLAT_VECTOR);
+		auto &children = StructVector::GetEntries(*this);
+		D_ASSERT(val.is_null || children.size() == val.struct_value.size());
+		for (size_t i = 0; i < children.size(); i++) {
 			auto &vec_child = children[i];
-			vec_child->SetValue(index, struct_child);
+			if (!val.is_null) {
+				auto &struct_child = val.struct_value[i];
+				vec_child->SetValue(index, struct_child);
+			} else {
+				vec_child->SetValue(index, Value());
+			}
 		}
 		break;
 	}
@@ -638,7 +646,6 @@ void Vector::Normalify(idx_t count) {
 			TemplatedFlattenConstantVector<list_entry_t>(data, old_data, count);
 			break;
 		}
-		case PhysicalType::MAP:
 		case PhysicalType::STRUCT: {
 			auto &child_entries = StructVector::GetEntries(*this);
 			for (auto &child : child_entries) {
@@ -745,7 +752,6 @@ void Vector::Serialize(idx_t count, Serializer &serializer) {
 		}
 		serializer.WriteData((const_data_ptr_t)flat_mask.GetData(), flat_mask.ValidityMaskSize(count));
 	}
-
 	if (TypeIsConstantSize(type.InternalType())) {
 		// constant size type: simple copy
 		idx_t write_size = GetTypeIdSize(type.InternalType()) * count;
@@ -763,6 +769,14 @@ void Vector::Serialize(idx_t count, Serializer &serializer) {
 			}
 			break;
 		}
+		case PhysicalType::STRUCT: {
+			Normalify(count);
+			auto &entries = StructVector::GetEntries(*this);
+			for (auto &entry : entries) {
+				entry->Serialize(count, serializer);
+			}
+			break;
+		}
 		default:
 			throw NotImplementedException("Unimplemented variable width type for Vector::Serialize!");
 		}
@@ -788,15 +802,39 @@ void Vector::Deserialize(idx_t count, Deserializer &source) {
 
 		VectorOperations::ReadFromStorage(ptr.get(), count, *this);
 	} else {
-		auto strings = FlatVector::GetData<string_t>(*this);
-		for (idx_t i = 0; i < count; i++) {
-			// read the strings
-			auto str = source.Read<string>();
-			// now add the string to the StringHeap of the vector
-			// and write the pointer into the vector
-			if (validity.RowIsValid(i)) {
-				strings[i] = StringVector::AddStringOrBlob(*this, str);
+		switch (type.InternalType()) {
+		case PhysicalType::VARCHAR: {
+			auto strings = FlatVector::GetData<string_t>(*this);
+			for (idx_t i = 0; i < count; i++) {
+				// read the strings
+				auto str = source.Read<string>();
+				// now add the string to the StringHeap of the vector
+				// and write the pointer into the vector
+				if (validity.RowIsValid(i)) {
+					strings[i] = StringVector::AddStringOrBlob(*this, str);
+				}
+			}
+			break;
+		}
+		case PhysicalType::STRUCT: {
+			auto &entries = StructVector::GetEntries(*this);
+			for (auto &entry : entries) {
+				entry->Deserialize(count, source);
 			}
+			break;
+		}
+		default:
+			throw NotImplementedException("Unimplemented variable width type for Vector::Deserialize!");
+		}
+	}
+}
+
+void Vector::SetVectorType(VectorType vector_type) {
+	buffer->SetVectorType(vector_type);
+	if (vector_type == VectorType::CONSTANT_VECTOR && GetType().InternalType() == PhysicalType::STRUCT) {
+		auto &entries = StructVector::GetEntries(*this);
+		for (auto &entry : entries) {
+			entry->SetVectorType(vector_type);
 		}
 	}
 }
@@ -904,13 +942,17 @@ void Vector::Verify(const SelectionVector &sel, idx_t count) {
 		}
 	}
 
-	if (GetType().InternalType() == PhysicalType::STRUCT || GetType().InternalType() == PhysicalType::MAP) {
+	if (GetType().InternalType() == PhysicalType::STRUCT) {
 		auto &child_types = GetType().child_types();
 		D_ASSERT(child_types.size() > 0);
 		if (GetVectorType() == VectorType::FLAT_VECTOR || GetVectorType() == VectorType::CONSTANT_VECTOR) {
+			// create a selection vector of the non-null entries of the struct vector
 			auto &children = StructVector::GetEntries(*this);
 			D_ASSERT(child_types.size() == children.size());
 			for (idx_t child_idx = 0; child_idx < children.size(); child_idx++) {
+				if (GetVectorType() == VectorType::CONSTANT_VECTOR) {
+					D_ASSERT(children[child_idx]->GetVectorType() == VectorType::CONSTANT_VECTOR);
+				}
 				D_ASSERT(children[child_idx]->GetType() == child_types[child_idx].second);
 				children[child_idx]->Verify(sel, count);
 			}
@@ -954,6 +996,30 @@ void Vector::Verify(idx_t count) {
 	}
 }
 
+void ConstantVector::SetNull(Vector &vector, bool is_null) {
+	D_ASSERT(vector.GetVectorType() == VectorType::CONSTANT_VECTOR);
+	vector.validity.Set(0, !is_null);
+	if (is_null && vector.GetType().InternalType() == PhysicalType::STRUCT) {
+		// set all child entries to null as well
+		auto &entries = StructVector::GetEntries(vector);
+		for (auto &entry : entries) {
+			entry->SetVectorType(VectorType::CONSTANT_VECTOR);
+			ConstantVector::SetNull(*entry, is_null);
+		}
+	}
+}
+
+const SelectionVector *ConstantVector::ZeroSelectionVector(idx_t count, SelectionVector &owned_sel) {
+	if (count <= STANDARD_VECTOR_SIZE) {
+		return &ConstantVector::ZERO_SELECTION_VECTOR;
+	}
+	owned_sel.Initialize(count);
+	for (idx_t i = 0; i < count; i++) {
+		owned_sel.set_index(i, 0);
+	}
+	return &owned_sel;
+}
+
 string_t StringVector::AddString(Vector &vector, const char *data, idx_t len) {
 	return StringVector::AddString(vector, string_t(data, len));
 }
diff --git a/src/common/value_operations/comparison_operations.cpp b/src/common/value_operations/comparison_operations.cpp
index 4b58daea8c85..f55824ee3a54 100644
--- a/src/common/value_operations/comparison_operations.cpp
+++ b/src/common/value_operations/comparison_operations.cpp
@@ -53,7 +53,6 @@ static bool TemplatedBooleanOperation(const Value &left, const Value &right) {
 		return OP::Operation(left.value_.interval, right.value_.interval);
 	case PhysicalType::VARCHAR:
 		return OP::Operation(left.str_value, right.str_value);
-	case PhysicalType::MAP:
 	case PhysicalType::STRUCT: {
 		// this should be enforced by the type
 		D_ASSERT(left.struct_value.size() == right.struct_value.size());
diff --git a/src/common/value_operations/hash.cpp b/src/common/value_operations/hash.cpp
index c9abf6533fec..eb624ed6f65b 100644
--- a/src/common/value_operations/hash.cpp
+++ b/src/common/value_operations/hash.cpp
@@ -47,7 +47,6 @@ hash_t ValueOperations::Hash(const Value &op) {
 		}
 		return hash;
 	}
-	case PhysicalType::MAP:
 	case PhysicalType::STRUCT: {
 		hash_t hash = 0;
 		for (auto &entry : op.struct_value) {
diff --git a/src/common/vector_operations/vector_cast.cpp b/src/common/vector_operations/vector_cast.cpp
index 94d42e15191e..a581673c7af3 100644
--- a/src/common/vector_operations/vector_cast.cpp
+++ b/src/common/vector_operations/vector_cast.cpp
@@ -634,22 +634,22 @@ static void StructCastSwitch(Vector &source, Vector &result, idx_t count) {
 		auto &source_children = StructVector::GetEntries(source);
 		D_ASSERT(source_children.size() == source.GetType().child_types().size());
 
-		bool is_constant = true;
 		auto &result_children = StructVector::GetEntries(result);
 		for (idx_t c_idx = 0; c_idx < result.GetType().child_types().size(); c_idx++) {
 			auto &result_child_vector = result_children[c_idx];
 			auto &source_child_vector = *source_children[c_idx];
-			if (source_child_vector.GetVectorType() != VectorType::CONSTANT_VECTOR) {
-				is_constant = false;
-			}
 			if (result_child_vector->GetType() != source_child_vector.GetType()) {
 				VectorOperations::Cast(source_child_vector, *result_child_vector, count, false);
 			} else {
 				result_child_vector->Reference(source_child_vector);
 			}
 		}
-		if (is_constant) {
+		if (source.GetVectorType() == VectorType::CONSTANT_VECTOR) {
 			result.SetVectorType(VectorType::CONSTANT_VECTOR);
+			ConstantVector::SetNull(result, ConstantVector::IsNull(source));
+		} else {
+			source.Normalify(count);
+			FlatVector::Validity(result) = FlatVector::Validity(source);
 		}
 
 		break;
diff --git a/src/common/vector_operations/vector_copy.cpp b/src/common/vector_operations/vector_copy.cpp
index 3b3e8a40cbe4..ca2ab714907c 100644
--- a/src/common/vector_operations/vector_copy.cpp
+++ b/src/common/vector_operations/vector_copy.cpp
@@ -28,6 +28,9 @@ void VectorOperations::Copy(const Vector &source, Vector &target, const Selectio
 	D_ASSERT(source_offset <= source_count);
 	D_ASSERT(target.GetVectorType() == VectorType::FLAT_VECTOR);
 	D_ASSERT(source.GetType() == target.GetType());
+	idx_t copy_count = source_count - source_offset;
+
+	SelectionVector owned_sel;
 	const SelectionVector *sel = &sel_p;
 	switch (source.GetVectorType()) {
 	case VectorType::DICTIONARY_VECTOR: {
@@ -49,7 +52,7 @@ void VectorOperations::Copy(const Vector &source, Vector &target, const Selectio
 		return;
 	}
 	case VectorType::CONSTANT_VECTOR:
-		sel = &ConstantVector::ZERO_SELECTION_VECTOR;
+		sel = ConstantVector::ZeroSelectionVector(copy_count, owned_sel);
 		break; // carry on with below code
 	case VectorType::FLAT_VECTOR:
 		break;
@@ -57,7 +60,6 @@ void VectorOperations::Copy(const Vector &source, Vector &target, const Selectio
 		throw NotImplementedException("FIXME unimplemented vector type for VectorOperations::Copy");
 	}
 
-	idx_t copy_count = source_count - source_offset;
 	if (copy_count == 0) {
 		return;
 	}
@@ -137,7 +139,6 @@ void VectorOperations::Copy(const Vector &source, Vector &target, const Selectio
 		}
 		break;
 	}
-	case PhysicalType::MAP:
 	case PhysicalType::STRUCT: {
 		auto &source_children = StructVector::GetEntries(source);
 		auto &target_children = StructVector::GetEntries(target);
diff --git a/src/execution/expression_executor/execute_case.cpp b/src/execution/expression_executor/execute_case.cpp
index 47844f7aa8e7..8def4429d621 100644
--- a/src/execution/expression_executor/execute_case.cpp
+++ b/src/execution/expression_executor/execute_case.cpp
@@ -80,6 +80,27 @@ void TemplatedFillLoop(Vector &vector, Vector &result, SelectionVector &sel, sel
 	}
 }
 
+void ValidityFillLoop(Vector &vector, Vector &result, SelectionVector &sel, sel_t count) {
+	result.SetVectorType(VectorType::FLAT_VECTOR);
+	auto &result_mask = FlatVector::Validity(result);
+	if (vector.GetVectorType() == VectorType::CONSTANT_VECTOR) {
+		if (ConstantVector::IsNull(vector)) {
+			for (idx_t i = 0; i < count; i++) {
+				result_mask.SetInvalid(sel.get_index(i));
+			}
+		}
+	} else {
+		VectorData vdata;
+		vector.Orrify(count, vdata);
+		for (idx_t i = 0; i < count; i++) {
+			auto source_idx = vdata.sel->get_index(i);
+			auto res_idx = sel.get_index(i);
+
+			result_mask.Set(res_idx, vdata.validity.RowIsValid(source_idx));
+		}
+	}
+}
+
 template <class T>
 void TemplatedCaseLoop(Vector &res_true, Vector &res_false, Vector &result, SelectionVector &tside, idx_t tcount,
                        SelectionVector &fside, idx_t fcount) {
@@ -87,6 +108,12 @@ void TemplatedCaseLoop(Vector &res_true, Vector &res_false, Vector &result, Sele
 	TemplatedFillLoop<T>(res_false, result, fside, fcount);
 }
 
+void ValidityCaseLoop(Vector &res_true, Vector &res_false, Vector &result, SelectionVector &tside, idx_t tcount,
+                      SelectionVector &fside, idx_t fcount) {
+	ValidityFillLoop(res_true, result, tside, tcount);
+	ValidityFillLoop(res_false, result, fside, fcount);
+}
+
 void Case(Vector &res_true, Vector &res_false, Vector &result, SelectionVector &tside, idx_t tcount,
           SelectionVector &fside, idx_t fcount) {
 	D_ASSERT(res_true.GetType() == res_false.GetType() && res_true.GetType() == result.GetType());
@@ -131,6 +158,18 @@ void Case(Vector &res_true, Vector &res_false, Vector &result, SelectionVector &
 		StringVector::AddHeapReference(result, res_true);
 		StringVector::AddHeapReference(result, res_false);
 		break;
+	case PhysicalType::STRUCT: {
+		auto &res_true_entries = StructVector::GetEntries(res_true);
+		auto &res_false_entries = StructVector::GetEntries(res_false);
+		auto &result_entries = StructVector::GetEntries(result);
+		D_ASSERT(res_true_entries.size() == res_false_entries.size() &&
+		         res_true_entries.size() == result_entries.size());
+		ValidityCaseLoop(res_true, res_false, result, tside, tcount, fside, fcount);
+		for (idx_t i = 0; i < res_true_entries.size(); i++) {
+			Case(*res_true_entries[i], *res_false_entries[i], *result_entries[i], tside, tcount, fside, fcount);
+		}
+		break;
+	}
 	case PhysicalType::LIST: {
 		auto result_vector = make_unique<Vector>(result.GetType().child_types()[0].second);
 		ListVector::SetEntry(result, move(result_vector));
diff --git a/src/function/aggregate/nested/histogram.cpp b/src/function/aggregate/nested/histogram.cpp
index 977d65a9463d..1bd398a28963 100644
--- a/src/function/aggregate/nested/histogram.cpp
+++ b/src/function/aggregate/nested/histogram.cpp
@@ -115,10 +115,15 @@ static void HistogramFinalize(Vector &state_vector, FunctionData *, Vector &resu
 	auto &child_entries = StructVector::GetEntries(result);
 	auto &bucket_list = child_entries[0];
 	auto &count_list = child_entries[1];
+
+	auto &bucket_validity = FlatVector::Validity(*bucket_list);
+	auto &count_validity = FlatVector::Validity(*count_list);
 	for (idx_t i = 0; i < count; i++) {
 		auto state = states[sdata.sel->get_index(i)];
 		if (!state->hist) {
 			mask.SetInvalid(i);
+			bucket_validity.SetInvalid(i);
+			count_validity.SetInvalid(i);
 			continue;
 		}
 		for (auto &entry : *state->hist) {
diff --git a/src/function/scalar/nested/map/map.cpp b/src/function/scalar/nested/map/map.cpp
index fdc654c665cb..c5366cc52e9e 100644
--- a/src/function/scalar/nested/map/map.cpp
+++ b/src/function/scalar/nested/map/map.cpp
@@ -29,16 +29,21 @@ static void MapFunction(DataChunk &args, ExpressionState &state, Vector &result)
 		auto list_child = make_unique<Vector>(LogicalTypeId::SQLNULL);
 		ListVector::SetEntry(*key_vector, move(list_child));
 		ListVector::SetListSize(*key_vector, 0);
-		auto list_data = FlatVector::GetData<list_entry_t>(*key_vector);
+		key_vector->SetVectorType(VectorType::CONSTANT_VECTOR);
+		auto list_data = ConstantVector::GetData<list_entry_t>(*key_vector);
 		list_data->offset = 0;
 		list_data->length = 0;
 
 		list_child = make_unique<Vector>(LogicalTypeId::SQLNULL);
+		list_child->SetVectorType(VectorType::CONSTANT_VECTOR);
 		ListVector::SetEntry(*value_vector, move(list_child));
 		ListVector::SetListSize(*value_vector, 0);
-		list_data = FlatVector::GetData<list_entry_t>(*value_vector);
+		value_vector->SetVectorType(VectorType::CONSTANT_VECTOR);
+		list_data = ConstantVector::GetData<list_entry_t>(*value_vector);
 		list_data->offset = 0;
 		list_data->length = 0;
+
+		result.Verify(args.size());
 		return;
 	}
 
diff --git a/src/function/scalar/nested/struct_extract.cpp b/src/function/scalar/nested/struct_extract.cpp
index 2e912862fffd..01d64674c80b 100644
--- a/src/function/scalar/nested/struct_extract.cpp
+++ b/src/function/scalar/nested/struct_extract.cpp
@@ -2,6 +2,7 @@
 #include "duckdb/execution/expression_executor.hpp"
 #include "duckdb/planner/expression/bound_function_expression.hpp"
 #include "duckdb/common/string_util.hpp"
+#include "duckdb/storage/statistics/struct_statistics.hpp"
 
 namespace duckdb {
 
@@ -89,9 +90,20 @@ static unique_ptr<FunctionData> StructExtractBind(ClientContext &context, Scalar
 	return make_unique<StructExtractBindData>(key, key_index, return_type);
 }
 
+static unique_ptr<BaseStatistics> PropagateStructExtractStats(ClientContext &context, BoundFunctionExpression &expr,
+                                                              FunctionData *bind_data,
+                                                              vector<unique_ptr<BaseStatistics>> &child_stats) {
+	if (!child_stats[0]) {
+		return nullptr;
+	}
+	auto &struct_stats = (StructStatistics &)*child_stats[0];
+	auto &info = (StructExtractBindData &)*bind_data;
+	return info.index < struct_stats.child_stats.size() ? struct_stats.child_stats[info.index]->Copy() : nullptr;
+}
+
 ScalarFunction StructExtractFun::GetFunction() {
 	return ScalarFunction("struct_extract", {LogicalType::STRUCT, LogicalType::VARCHAR}, LogicalType::ANY,
-	                      StructExtractFunction, false, StructExtractBind);
+	                      StructExtractFunction, false, StructExtractBind, nullptr, PropagateStructExtractStats);
 }
 
 void StructExtractFun::RegisterFunction(BuiltinFunctions &set) {
diff --git a/src/include/duckdb/common/helper.hpp b/src/include/duckdb/common/helper.hpp
index 78389b8343c6..2c5921d412dc 100644
--- a/src/include/duckdb/common/helper.hpp
+++ b/src/include/duckdb/common/helper.hpp
@@ -34,6 +34,20 @@ unique_ptr<S> unique_ptr_cast(unique_ptr<T> src) {
 	return unique_ptr<S>(static_cast<S *>(src.release()));
 }
 
+struct SharedConstructor {
+	template <class T, typename... ARGS>
+	static shared_ptr<T> Create(ARGS &&...args) {
+		return make_shared<T>(std::forward<ARGS>(args)...);
+	}
+};
+
+struct UniqueConstructor {
+	template <class T, typename... ARGS>
+	static unique_ptr<T> Create(ARGS &&...args) {
+		return make_unique<T>(std::forward<ARGS>(args)...);
+	}
+};
+
 template <typename T>
 T MaxValue(T a, T b) {
 	return a > b ? a : b;
diff --git a/src/include/duckdb/common/types/validity_mask.hpp b/src/include/duckdb/common/types/validity_mask.hpp
index 5958b98224fa..d35ed58c3baa 100644
--- a/src/include/duckdb/common/types/validity_mask.hpp
+++ b/src/include/duckdb/common/types/validity_mask.hpp
@@ -195,7 +195,6 @@ struct TemplatedValidityMask {
 
 	//! Marks "count" entries in the validity mask as invalid (null)
 	inline void SetAllInvalid(idx_t count) {
-		D_ASSERT(count <= STANDARD_VECTOR_SIZE);
 		EnsureWritable();
 		for (idx_t i = 0; i < ValidityBuffer::EntryCount(count); i++) {
 			validity_mask[i] = 0;
@@ -204,7 +203,6 @@ struct TemplatedValidityMask {
 
 	//! Marks "count" entries in the validity mask as valid (not null)
 	inline void SetAllValid(idx_t count) {
-		D_ASSERT(count <= STANDARD_VECTOR_SIZE);
 		EnsureWritable();
 		for (idx_t i = 0; i < ValidityBuffer::EntryCount(count); i++) {
 			validity_mask[i] = ValidityBuffer::MAX_ENTRY;
diff --git a/src/include/duckdb/common/types/vector.hpp b/src/include/duckdb/common/types/vector.hpp
index e50f7394b637..86094a59068d 100644
--- a/src/include/duckdb/common/types/vector.hpp
+++ b/src/include/duckdb/common/types/vector.hpp
@@ -145,9 +145,7 @@ class Vector {
 	}
 
 	// Setters
-	inline void SetVectorType(VectorType vector_type) {
-		buffer->SetVectorType(vector_type);
-	}
+	DUCKDB_API void SetVectorType(VectorType vector_type);
 	inline void SetType(const LogicalType &type) {
 		buffer->SetType(type);
 	}
@@ -200,14 +198,12 @@ struct ConstantVector {
 		D_ASSERT(vector.GetVectorType() == VectorType::CONSTANT_VECTOR);
 		return !vector.validity.RowIsValid(0);
 	}
-	static inline void SetNull(Vector &vector, bool is_null) {
-		D_ASSERT(vector.GetVectorType() == VectorType::CONSTANT_VECTOR);
-		vector.validity.Set(0, !is_null);
-	}
+	DUCKDB_API static void SetNull(Vector &vector, bool is_null);
 	static inline ValidityMask &Validity(Vector &vector) {
 		D_ASSERT(vector.GetVectorType() == VectorType::CONSTANT_VECTOR);
 		return vector.validity;
 	}
+	DUCKDB_API static const SelectionVector *ZeroSelectionVector(idx_t count, SelectionVector &owned_sel);
 
 	static const sel_t ZERO_VECTOR[STANDARD_VECTOR_SIZE];
 	static const SelectionVector ZERO_SELECTION_VECTOR;
@@ -279,49 +275,49 @@ struct FlatVector {
 };
 
 struct ListVector {
-	static const Vector &GetEntry(const Vector &vector);
-	static Vector &GetEntry(Vector &vector);
-	static idx_t GetListSize(const Vector &vector);
-	static void SetListSize(Vector &vec, idx_t size);
-	static bool HasEntry(const Vector &vector);
-	static void SetEntry(Vector &vector, unique_ptr<Vector> entry);
-	static void Append(Vector &target, const Vector &source, idx_t source_size, idx_t source_offset = 0);
-	static void Append(Vector &target, const Vector &source, const SelectionVector &sel, idx_t source_size,
-	                   idx_t source_offset = 0);
-	static void PushBack(Vector &target, Value &insert);
-	static void Initialize(Vector &vec);
-	static vector<idx_t> Search(Vector &list, Value &key, idx_t row);
-	static Value GetValuesFromOffsets(Vector &list, vector<idx_t> &offsets);
+	DUCKDB_API static const Vector &GetEntry(const Vector &vector);
+	DUCKDB_API static Vector &GetEntry(Vector &vector);
+	DUCKDB_API static idx_t GetListSize(const Vector &vector);
+	DUCKDB_API static void SetListSize(Vector &vec, idx_t size);
+	DUCKDB_API static bool HasEntry(const Vector &vector);
+	DUCKDB_API static void SetEntry(Vector &vector, unique_ptr<Vector> entry);
+	DUCKDB_API static void Append(Vector &target, const Vector &source, idx_t source_size, idx_t source_offset = 0);
+	DUCKDB_API static void Append(Vector &target, const Vector &source, const SelectionVector &sel, idx_t source_size,
+	                              idx_t source_offset = 0);
+	DUCKDB_API static void PushBack(Vector &target, Value &insert);
+	DUCKDB_API static void Initialize(Vector &vec);
+	DUCKDB_API static vector<idx_t> Search(Vector &list, Value &key, idx_t row);
+	DUCKDB_API static Value GetValuesFromOffsets(Vector &list, vector<idx_t> &offsets);
 	//! Share the entry of the other list vector
-	static void ReferenceEntry(Vector &vector, Vector &other);
+	DUCKDB_API static void ReferenceEntry(Vector &vector, Vector &other);
 };
 
 struct StringVector {
 	//! Add a string to the string heap of the vector (auxiliary data)
-	static string_t AddString(Vector &vector, const char *data, idx_t len);
+	DUCKDB_API static string_t AddString(Vector &vector, const char *data, idx_t len);
 	//! Add a string to the string heap of the vector (auxiliary data)
-	static string_t AddString(Vector &vector, const char *data);
+	DUCKDB_API static string_t AddString(Vector &vector, const char *data);
 	//! Add a string to the string heap of the vector (auxiliary data)
-	static string_t AddString(Vector &vector, string_t data);
+	DUCKDB_API static string_t AddString(Vector &vector, string_t data);
 	//! Add a string to the string heap of the vector (auxiliary data)
-	static string_t AddString(Vector &vector, const string &data);
+	DUCKDB_API static string_t AddString(Vector &vector, const string &data);
 	//! Add a string or a blob to the string heap of the vector (auxiliary data)
 	//! This function is the same as ::AddString, except the added data does not need to be valid UTF8
-	static string_t AddStringOrBlob(Vector &vector, string_t data);
+	DUCKDB_API static string_t AddStringOrBlob(Vector &vector, string_t data);
 	//! Allocates an empty string of the specified size, and returns a writable pointer that can be used to store the
 	//! result of an operation
-	static string_t EmptyString(Vector &vector, idx_t len);
+	DUCKDB_API static string_t EmptyString(Vector &vector, idx_t len);
 	//! Adds a reference to a handle that stores strings of this vector
-	static void AddHandle(Vector &vector, unique_ptr<BufferHandle> handle);
+	DUCKDB_API static void AddHandle(Vector &vector, unique_ptr<BufferHandle> handle);
 	//! Adds a reference to an unspecified vector buffer that stores strings of this vector
-	static void AddBuffer(Vector &vector, buffer_ptr<VectorBuffer> buffer);
+	DUCKDB_API static void AddBuffer(Vector &vector, buffer_ptr<VectorBuffer> buffer);
 	//! Add a reference from this vector to the string heap of the provided vector
-	static void AddHeapReference(Vector &vector, Vector &other);
+	DUCKDB_API static void AddHeapReference(Vector &vector, Vector &other);
 };
 
 struct StructVector {
-	static const vector<unique_ptr<Vector>> &GetEntries(const Vector &vector);
-	static vector<unique_ptr<Vector>> &GetEntries(Vector &vector);
+	DUCKDB_API static const vector<unique_ptr<Vector>> &GetEntries(const Vector &vector);
+	DUCKDB_API static vector<unique_ptr<Vector>> &GetEntries(Vector &vector);
 };
 
 struct SequenceVector {
diff --git a/src/include/duckdb/planner/expression_binder.hpp b/src/include/duckdb/planner/expression_binder.hpp
index 03da4d1323a8..f67a2954d7b7 100644
--- a/src/include/duckdb/planner/expression_binder.hpp
+++ b/src/include/duckdb/planner/expression_binder.hpp
@@ -48,6 +48,11 @@ class ExpressionBinder {
 	ExpressionBinder(Binder &binder, ClientContext &context, bool replace_binder = false);
 	virtual ~ExpressionBinder();
 
+	//! The target type that should result from the binder. If the result is not of this type, a cast to this type will
+	//! be added. Defaults to INVALID.
+	LogicalType target_type;
+
+public:
 	unique_ptr<Expression> Bind(unique_ptr<ParsedExpression> &expr, LogicalType *result_type = nullptr,
 	                            bool root_expression = true);
 
@@ -67,10 +72,6 @@ class ExpressionBinder {
 
 	bool BindCorrelatedColumns(unique_ptr<ParsedExpression> &expr);
 
-	//! The target type that should result from the binder. If the result is not of this type, a cast to this type will
-	//! be added. Defaults to INVALID.
-	LogicalType target_type;
-
 	void BindChild(unique_ptr<ParsedExpression> &expr, idx_t depth, string &error);
 	static void ExtractCorrelatedExpressions(Binder &binder, Expression &expr);
 
diff --git a/src/include/duckdb/storage/statistics/base_statistics.hpp b/src/include/duckdb/storage/statistics/base_statistics.hpp
index 31dcdbe6e354..4f6c50fd97e1 100644
--- a/src/include/duckdb/storage/statistics/base_statistics.hpp
+++ b/src/include/duckdb/storage/statistics/base_statistics.hpp
@@ -12,6 +12,7 @@
 #include "duckdb/common/types.hpp"
 #include "duckdb/common/operator/comparison_operators.hpp"
 #include "duckdb/common/enums/expression_type.hpp"
+#include "duckdb/common/types/value.hpp"
 
 namespace duckdb {
 class Serializer;
diff --git a/src/include/duckdb/storage/statistics/string_statistics.hpp b/src/include/duckdb/storage/statistics/string_statistics.hpp
index 89b263630354..786431ce8a9d 100644
--- a/src/include/duckdb/storage/statistics/string_statistics.hpp
+++ b/src/include/duckdb/storage/statistics/string_statistics.hpp
@@ -10,6 +10,7 @@
 
 #include "duckdb/storage/statistics/base_statistics.hpp"
 #include "duckdb/common/enums/filter_propagate_result.hpp"
+#include "duckdb/storage/statistics/validity_statistics.hpp"
 
 namespace duckdb {
 
diff --git a/src/include/duckdb/storage/statistics/struct_statistics.hpp b/src/include/duckdb/storage/statistics/struct_statistics.hpp
new file mode 100644
index 000000000000..4a50438daf58
--- /dev/null
+++ b/src/include/duckdb/storage/statistics/struct_statistics.hpp
@@ -0,0 +1,36 @@
+//===----------------------------------------------------------------------===//
+//                         DuckDB
+//
+// duckdb/storage/statistics/struct_statistics.hpp
+//
+//
+//===----------------------------------------------------------------------===//
+
+#pragma once
+
+#include "duckdb/storage/statistics/base_statistics.hpp"
+#include "duckdb/common/enums/filter_propagate_result.hpp"
+#include "duckdb/storage/statistics/validity_statistics.hpp"
+
+namespace duckdb {
+class Value;
+
+class StructStatistics : public BaseStatistics {
+public:
+	explicit StructStatistics(LogicalType type);
+
+	vector<unique_ptr<BaseStatistics>> child_stats;
+
+public:
+	void Merge(const BaseStatistics &other) override;
+	FilterPropagateResult CheckZonemap(ExpressionType comparison_type, const Value &constant);
+
+	unique_ptr<BaseStatistics> Copy() override;
+	void Serialize(Serializer &serializer) override;
+	static unique_ptr<BaseStatistics> Deserialize(Deserializer &source, LogicalType type);
+	void Verify(Vector &vector, idx_t count) override;
+
+	string ToString() override;
+};
+
+} // namespace duckdb
diff --git a/src/include/duckdb/storage/table/column_data.hpp b/src/include/duckdb/storage/table/column_data.hpp
index 1210f06f141d..7e5ae913efd4 100644
--- a/src/include/duckdb/storage/table/column_data.hpp
+++ b/src/include/duckdb/storage/table/column_data.hpp
@@ -62,10 +62,12 @@ class ColumnData {
 	//! Scan the next vector from the column
 	virtual void Scan(Transaction &transaction, idx_t vector_index, ColumnScanState &state, Vector &result);
 	virtual void ScanCommitted(idx_t vector_index, ColumnScanState &state, Vector &result, bool allow_updates);
+	virtual void ScanCommittedRange(idx_t row_group_start, idx_t offset_in_row_group, idx_t count, Vector &result);
+
 	//! Initialize an appending phase for this column
 	virtual void InitializeAppend(ColumnAppendState &state);
 	//! Append a vector of type [type] to the end of the column
-	void Append(BaseStatistics &stats, ColumnAppendState &state, Vector &vector, idx_t count);
+	virtual void Append(BaseStatistics &stats, ColumnAppendState &state, Vector &vector, idx_t count);
 	virtual void AppendData(BaseStatistics &stats, ColumnAppendState &state, VectorData &vdata, idx_t count);
 	//! Revert a set of appends to the ColumnData
 	virtual void RevertAppend(row_t start_row);
@@ -85,19 +87,25 @@ class ColumnData {
 	virtual void CommitDropColumn();
 
 	virtual unique_ptr<ColumnCheckpointState> CreateCheckpointState(RowGroup &row_group, TableDataWriter &writer);
-	virtual unique_ptr<ColumnCheckpointState> Checkpoint(RowGroup &row_group, TableDataWriter &writer,
-	                                                     idx_t column_idx);
+	virtual unique_ptr<ColumnCheckpointState> Checkpoint(RowGroup &row_group, TableDataWriter &writer);
+
+	virtual void CheckpointScan(ColumnSegment *segment, ColumnScanState &state, idx_t row_group_start,
+	                            idx_t base_row_index, idx_t count, Vector &scan_vector);
 
 	virtual void Initialize(PersistentColumnData &column_data);
 
-	static void BaseDeserialize(DatabaseInstance &db, Deserializer &source, const LogicalType &type,
-	                            ColumnData &result);
+	virtual void DeserializeColumn(Deserializer &source);
 	static shared_ptr<ColumnData> Deserialize(DataTableInfo &info, idx_t column_index, idx_t start_row,
-	                                          Deserializer &source, const LogicalType &type);
+	                                          Deserializer &source, const LogicalType &type, ColumnData *parent);
 
 	virtual void GetStorageInfo(idx_t row_group_index, vector<idx_t> col_path, vector<vector<Value>> &result);
 	virtual void Verify(RowGroup &parent);
 
+	static shared_ptr<ColumnData> CreateColumn(DataTableInfo &info, idx_t column_index, idx_t start_row,
+	                                           const LogicalType &type, ColumnData *parent = nullptr);
+	static unique_ptr<ColumnData> CreateColumnUnique(DataTableInfo &info, idx_t column_index, idx_t start_row,
+	                                                 const LogicalType &type, ColumnData *parent = nullptr);
+
 protected:
 	//! Append a transient segment
 	void AppendTransientSegment(idx_t start_row);
diff --git a/src/include/duckdb/storage/table/persistent_table_data.hpp b/src/include/duckdb/storage/table/persistent_table_data.hpp
index cdd0d1f9c3c3..7ad186720d1f 100644
--- a/src/include/duckdb/storage/table/persistent_table_data.hpp
+++ b/src/include/duckdb/storage/table/persistent_table_data.hpp
@@ -31,6 +31,12 @@ class StandardPersistentColumnData : public PersistentColumnData {
 	unique_ptr<PersistentColumnData> validity;
 };
 
+class StructPersistentColumnData : public PersistentColumnData {
+public:
+	unique_ptr<PersistentColumnData> validity;
+	vector<unique_ptr<PersistentColumnData>> child_data;
+};
+
 class PersistentTableData {
 public:
 	explicit PersistentTableData(idx_t column_count);
diff --git a/src/include/duckdb/storage/table/standard_column_data.hpp b/src/include/duckdb/storage/table/standard_column_data.hpp
index 46e0230c2ca4..07237b5bca9d 100644
--- a/src/include/duckdb/storage/table/standard_column_data.hpp
+++ b/src/include/duckdb/storage/table/standard_column_data.hpp
@@ -44,10 +44,11 @@ class StandardColumnData : public ColumnData {
 	void Initialize(PersistentColumnData &column_data) override;
 
 	unique_ptr<ColumnCheckpointState> CreateCheckpointState(RowGroup &row_group, TableDataWriter &writer) override;
-	unique_ptr<ColumnCheckpointState> Checkpoint(RowGroup &row_group, TableDataWriter &writer,
-	                                             idx_t column_idx) override;
-	static shared_ptr<ColumnData> Deserialize(DataTableInfo &info, idx_t column_index, idx_t start_row,
-	                                          Deserializer &source, const LogicalType &type);
+	unique_ptr<ColumnCheckpointState> Checkpoint(RowGroup &row_group, TableDataWriter &writer) override;
+	void CheckpointScan(ColumnSegment *segment, ColumnScanState &state, idx_t row_group_start, idx_t base_row_index,
+	                    idx_t count, Vector &scan_vector) override;
+
+	void DeserializeColumn(Deserializer &source) override;
 
 	void GetStorageInfo(idx_t row_group_index, vector<idx_t> col_path, vector<vector<Value>> &result) override;
 
diff --git a/src/include/duckdb/storage/table/struct_column_data.hpp b/src/include/duckdb/storage/table/struct_column_data.hpp
new file mode 100644
index 000000000000..01d368ebf466
--- /dev/null
+++ b/src/include/duckdb/storage/table/struct_column_data.hpp
@@ -0,0 +1,56 @@
+//===----------------------------------------------------------------------===//
+//                         DuckDB
+//
+// duckdb/storage/table/struct_column_data.hpp
+//
+//
+//===----------------------------------------------------------------------===//
+
+#pragma once
+
+#include "duckdb/storage/table/column_data.hpp"
+#include "duckdb/storage/table/validity_column_data.hpp"
+
+namespace duckdb {
+
+//! Struct column data represents a struct
+class StructColumnData : public ColumnData {
+public:
+	StructColumnData(DataTableInfo &info, idx_t column_index, idx_t start_row, LogicalType type,
+	                 ColumnData *parent = nullptr);
+
+	//! The sub-columns of the struct
+	vector<unique_ptr<ColumnData>> sub_columns;
+	//! The validity column data of the struct
+	ValidityColumnData validity;
+
+public:
+	bool CheckZonemap(ColumnScanState &state, TableFilter &filter) override;
+	void InitializeScan(ColumnScanState &state) override;
+	void InitializeScanWithOffset(ColumnScanState &state, idx_t row_idx) override;
+	void Scan(Transaction &transaction, idx_t vector_index, ColumnScanState &state, Vector &result) override;
+	void ScanCommitted(idx_t vector_index, ColumnScanState &state, Vector &result, bool allow_updates) override;
+	void InitializeAppend(ColumnAppendState &state) override;
+	void Append(BaseStatistics &stats, ColumnAppendState &state, Vector &vector, idx_t count) override;
+	void RevertAppend(row_t start_row) override;
+	void Fetch(ColumnScanState &state, row_t row_id, Vector &result) override;
+	void FetchRow(Transaction &transaction, ColumnFetchState &state, row_t row_id, Vector &result,
+	              idx_t result_idx) override;
+	void Update(Transaction &transaction, idx_t column_index, Vector &update_vector, row_t *row_ids,
+	            idx_t update_count) override;
+	void UpdateColumn(Transaction &transaction, const vector<column_t> &column_path, Vector &update_vector,
+	                  row_t *row_ids, idx_t update_count, idx_t depth) override;
+	unique_ptr<BaseStatistics> GetUpdateStatistics() override;
+
+	void CommitDropColumn() override;
+	void Initialize(PersistentColumnData &column_data) override;
+
+	unique_ptr<ColumnCheckpointState> CreateCheckpointState(RowGroup &row_group, TableDataWriter &writer) override;
+	unique_ptr<ColumnCheckpointState> Checkpoint(RowGroup &row_group, TableDataWriter &writer) override;
+
+	void DeserializeColumn(Deserializer &source) override;
+
+	void GetStorageInfo(idx_t row_group_index, vector<idx_t> col_path, vector<vector<Value>> &result) override;
+};
+
+} // namespace duckdb
diff --git a/src/planner/expression_binder.cpp b/src/planner/expression_binder.cpp
index 2d3ef525c421..25091c718954 100644
--- a/src/planner/expression_binder.cpp
+++ b/src/planner/expression_binder.cpp
@@ -111,6 +111,45 @@ void ExpressionBinder::ExtractCorrelatedExpressions(Binder &binder, Expression &
 	                                      [&](Expression &child) { ExtractCorrelatedExpressions(binder, child); });
 }
 
+static bool ContainsNullType(const LogicalType &type) {
+	switch (type.id()) {
+	case LogicalTypeId::STRUCT:
+	case LogicalTypeId::MAP:
+	case LogicalTypeId::LIST: {
+		auto &child_types = type.child_types();
+		for (auto &child_type : child_types) {
+			if (ContainsNullType(child_type.second)) {
+				return true;
+			}
+		}
+		return false;
+	}
+	case LogicalTypeId::SQLNULL:
+		return true;
+	default:
+		return false;
+	}
+}
+
+static void ExchangeNullType(LogicalType &type) {
+	switch (type.id()) {
+	case LogicalTypeId::STRUCT:
+	case LogicalTypeId::MAP:
+	case LogicalTypeId::LIST: {
+		auto &child_types = type.child_types();
+		for (auto &child_type : child_types) {
+			ExchangeNullType((LogicalType &)child_type.second);
+		}
+		break;
+	}
+	case LogicalTypeId::SQLNULL:
+		type = LogicalType::INTEGER;
+		break;
+	default:
+		break;
+	}
+}
+
 unique_ptr<Expression> ExpressionBinder::Bind(unique_ptr<ParsedExpression> &expr, LogicalType *result_type,
                                               bool root_expression) {
 	// bind the main expression
@@ -131,10 +170,12 @@ unique_ptr<Expression> ExpressionBinder::Bind(unique_ptr<ParsedExpression> &expr
 		// the binder has a specific target type: add a cast to that type
 		result = BoundCastExpression::AddCastToType(move(result), target_type);
 	} else {
-		if (result->return_type.id() == LogicalTypeId::SQLNULL) {
-			// SQL NULL type is only used internally in the binder
-			// cast to INTEGER if we encounter it outside of the binder
-			result = BoundCastExpression::AddCastToType(move(result), LogicalType::INTEGER);
+		// SQL NULL type is only used internally in the binder
+		// cast to INTEGER if we encounter it outside of the binder
+		if (ContainsNullType(result->return_type)) {
+			auto result_type = result->return_type;
+			ExchangeNullType(result_type);
+			result = BoundCastExpression::AddCastToType(move(result), result_type);
 		}
 	}
 	if (result_type) {
diff --git a/src/storage/numeric_segment.cpp b/src/storage/numeric_segment.cpp
index c62dae7cb00d..56d09b24acda 100644
--- a/src/storage/numeric_segment.cpp
+++ b/src/storage/numeric_segment.cpp
@@ -9,6 +9,7 @@
 #include "duckdb/common/vector_size.hpp"
 #include "duckdb/storage/statistics/numeric_statistics.hpp"
 #include "duckdb/planner/table_filter.hpp"
+#include "duckdb/common/types/null_value.hpp"
 
 namespace duckdb {
 
@@ -100,6 +101,10 @@ static void AppendLoop(SegmentStatistics &stats, data_ptr_t target, idx_t target
 			if (!is_null) {
 				NumericStatistics::Update<T>(stats, sdata[source_idx]);
 				tdata[target_idx] = sdata[source_idx];
+			} else {
+				// we insert a NullValue<T> in the null gap for debuggability
+				// this value should never be used or read anywhere
+				tdata[target_idx] = NullValue<T>();
 			}
 		}
 	} else {
diff --git a/src/storage/statistics/CMakeLists.txt b/src/storage/statistics/CMakeLists.txt
index f6b530aa718f..5d7adf479cf9 100644
--- a/src/storage/statistics/CMakeLists.txt
+++ b/src/storage/statistics/CMakeLists.txt
@@ -5,6 +5,7 @@ add_library_unity(
   numeric_statistics.cpp
   segment_statistics.cpp
   string_statistics.cpp
+  struct_statistics.cpp
   validity_statistics.cpp)
 set(ALL_OBJECT_FILES
     ${ALL_OBJECT_FILES} $<TARGET_OBJECTS:duckdb_storage_statistics>
diff --git a/src/storage/statistics/base_statistics.cpp b/src/storage/statistics/base_statistics.cpp
index a5de988483e8..8bec42243686 100644
--- a/src/storage/statistics/base_statistics.cpp
+++ b/src/storage/statistics/base_statistics.cpp
@@ -1,5 +1,6 @@
 #include "duckdb/storage/statistics/numeric_statistics.hpp"
 #include "duckdb/storage/statistics/string_statistics.hpp"
+#include "duckdb/storage/statistics/struct_statistics.hpp"
 #include "duckdb/common/serializer.hpp"
 #include "duckdb/common/exception.hpp"
 #include "duckdb/common/string_util.hpp"
@@ -61,9 +62,13 @@ unique_ptr<BaseStatistics> BaseStatistics::CreateEmpty(LogicalType type) {
 		return make_unique<NumericStatistics>(move(type));
 	case PhysicalType::VARCHAR:
 		return make_unique<StringStatistics>(move(type));
+	case PhysicalType::STRUCT:
+		return make_unique<StructStatistics>(move(type));
 	case PhysicalType::INTERVAL:
 	default:
-		return make_unique<BaseStatistics>(move(type));
+		auto base_stats = make_unique<BaseStatistics>(move(type));
+		base_stats->validity_stats = make_unique<ValidityStatistics>(false);
+		return base_stats;
 	}
 }
 
@@ -94,15 +99,16 @@ unique_ptr<BaseStatistics> BaseStatistics::Deserialize(Deserializer &source, Log
 	case PhysicalType::VARCHAR:
 		result = StringStatistics::Deserialize(source, move(type));
 		break;
+	case PhysicalType::STRUCT:
+		result = StructStatistics::Deserialize(source, move(type));
+		break;
 	case PhysicalType::INTERVAL:
 		result = make_unique<BaseStatistics>(move(type));
 		break;
 	default:
 		throw InternalException("Unimplemented type for statistics deserialization");
 	}
-	if (!can_have_null) {
-		result->validity_stats = make_unique<ValidityStatistics>(can_have_null);
-	}
+	result->validity_stats = make_unique<ValidityStatistics>(can_have_null);
 	return result;
 }
 
diff --git a/src/storage/statistics/numeric_statistics.cpp b/src/storage/statistics/numeric_statistics.cpp
index 4fadd058cd87..ad9980a44bfd 100644
--- a/src/storage/statistics/numeric_statistics.cpp
+++ b/src/storage/statistics/numeric_statistics.cpp
@@ -77,6 +77,7 @@ void NumericStatistics::Update<interval_t>(SegmentStatistics &stats, interval_t
 NumericStatistics::NumericStatistics(LogicalType type_p) : BaseStatistics(move(type_p)) {
 	min = Value::MaximumValue(type);
 	max = Value::MinimumValue(type);
+	validity_stats = make_unique<ValidityStatistics>(false);
 }
 
 NumericStatistics::NumericStatistics(LogicalType type_p, Value min_p, Value max_p)
@@ -174,8 +175,8 @@ unique_ptr<BaseStatistics> NumericStatistics::Deserialize(Deserializer &source,
 }
 
 string NumericStatistics::ToString() {
-	return StringUtil::Format("Numeric Statistics<%s> %s[Min: %s, Max: %s]", type.ToString(),
-	                          validity_stats ? validity_stats->ToString() : "", min.ToString(), max.ToString());
+	return StringUtil::Format("[Min: %s, Max: %s]%s", min.ToString(), max.ToString(),
+	                          validity_stats ? validity_stats->ToString() : "");
 }
 
 template <class T>
diff --git a/src/storage/statistics/string_statistics.cpp b/src/storage/statistics/string_statistics.cpp
index 9eba9cddabc9..b6768761ee08 100644
--- a/src/storage/statistics/string_statistics.cpp
+++ b/src/storage/statistics/string_statistics.cpp
@@ -14,6 +14,7 @@ StringStatistics::StringStatistics(LogicalType type_p) : BaseStatistics(move(typ
 	max_string_length = 0;
 	has_unicode = false;
 	has_overflow_strings = false;
+	validity_stats = make_unique<ValidityStatistics>(false);
 }
 
 unique_ptr<BaseStatistics> StringStatistics::Copy() {
@@ -146,24 +147,24 @@ FilterPropagateResult StringStatistics::CheckZonemap(ExpressionType comparison_t
 }
 
 static idx_t GetValidMinMaxSubstring(data_ptr_t data) {
-	idx_t len = 0;
 	for (idx_t i = 0; i < StringStatistics::MAX_STRING_MINMAX_SIZE; i++) {
 		if (data[i] == '\0') {
 			return i;
 		}
-		if ((data[i] & 0xC0) != 0x80) {
-			len = i;
+		if ((data[i] & 0x80) != 0) {
+			return i;
 		}
 	}
-	return len;
+	return StringStatistics::MAX_STRING_MINMAX_SIZE;
 }
 
 string StringStatistics::ToString() {
 	idx_t min_len = GetValidMinMaxSubstring(min);
 	idx_t max_len = GetValidMinMaxSubstring(max);
-	return StringUtil::Format("String Statistics %s[Min: %s, Max: %s, Has Unicode: %s, Max String Length: %lld]",
-	                          validity_stats ? validity_stats->ToString() : "", string((const char *)min, min_len),
-	                          string((const char *)max, max_len), has_unicode ? "true" : "false", max_string_length);
+	return StringUtil::Format("[Min: %s, Max: %s, Has Unicode: %s, Max String Length: %lld]%s",
+	                          string((const char *)min, min_len), string((const char *)max, max_len),
+	                          has_unicode ? "true" : "false", max_string_length,
+	                          validity_stats ? validity_stats->ToString() : "");
 }
 
 void StringStatistics::Verify(Vector &vector, idx_t count) {
diff --git a/src/storage/statistics/struct_statistics.cpp b/src/storage/statistics/struct_statistics.cpp
new file mode 100644
index 000000000000..3b11764abbe0
--- /dev/null
+++ b/src/storage/statistics/struct_statistics.cpp
@@ -0,0 +1,89 @@
+#include "duckdb/storage/statistics/struct_statistics.hpp"
+#include "duckdb/common/types/vector.hpp"
+
+namespace duckdb {
+
+StructStatistics::StructStatistics(LogicalType type_p) : BaseStatistics(move(type_p)) {
+	D_ASSERT(type.InternalType() == PhysicalType::STRUCT);
+
+	auto &child_types = type.child_types();
+	child_stats.resize(child_types.size());
+	for (idx_t i = 0; i < child_types.size(); i++) {
+		child_stats[i] = BaseStatistics::CreateEmpty(child_types[i].second);
+	}
+	validity_stats = make_unique<ValidityStatistics>(false);
+}
+
+void StructStatistics::Merge(const BaseStatistics &other_p) {
+	BaseStatistics::Merge(other_p);
+
+	auto &other = (const StructStatistics &)other_p;
+	D_ASSERT(other.child_stats.size() == child_stats.size());
+	for (idx_t i = 0; i < child_stats.size(); i++) {
+		if (child_stats[i] && other.child_stats[i]) {
+			child_stats[i]->Merge(*other.child_stats[i]);
+		}
+	}
+}
+
+FilterPropagateResult StructStatistics::CheckZonemap(ExpressionType comparison_type, const Value &constant) {
+	// for now...
+	return FilterPropagateResult::NO_PRUNING_POSSIBLE;
+}
+
+unique_ptr<BaseStatistics> StructStatistics::Copy() {
+	auto copy = make_unique<StructStatistics>(type);
+	if (validity_stats) {
+		copy->validity_stats = validity_stats->Copy();
+	}
+	for (idx_t i = 0; i < child_stats.size(); i++) {
+		if (child_stats[i]) {
+			copy->child_stats[i] = child_stats[i]->Copy();
+		}
+	}
+	return move(copy);
+}
+
+void StructStatistics::Serialize(Serializer &serializer) {
+	BaseStatistics::Serialize(serializer);
+	for (idx_t i = 0; i < child_stats.size(); i++) {
+		D_ASSERT(child_stats[i]);
+		child_stats[i]->Serialize(serializer);
+	}
+}
+
+unique_ptr<BaseStatistics> StructStatistics::Deserialize(Deserializer &source, LogicalType type) {
+	D_ASSERT(type.id() == LogicalTypeId::STRUCT);
+	auto result = make_unique<StructStatistics>(move(type));
+	auto &child_types = result->type.child_types();
+	for (idx_t i = 0; i < child_types.size(); i++) {
+		result->child_stats[i] = BaseStatistics::Deserialize(source, child_types[i].second);
+	}
+	return move(result);
+}
+
+string StructStatistics::ToString() {
+	string result;
+	result += " {";
+	auto &child_types = type.child_types();
+	for (idx_t i = 0; i < child_types.size(); i++) {
+		if (i > 0) {
+			result += ", ";
+		}
+		result += child_types[i].first + ": " + (child_stats[i] ? child_stats[i]->ToString() : "No Stats");
+	}
+	result += "}";
+	result += validity_stats ? validity_stats->ToString() : "";
+	return result;
+}
+
+void StructStatistics::Verify(Vector &vector, idx_t count) {
+	BaseStatistics::Verify(vector, count);
+
+	auto &child_entries = StructVector::GetEntries(vector);
+	for (idx_t i = 0; i < child_entries.size(); i++) {
+		child_stats[i]->Verify(*child_entries[i], count);
+	}
+}
+
+} // namespace duckdb
diff --git a/src/storage/table/CMakeLists.txt b/src/storage/table/CMakeLists.txt
index dfafa0b01755..dc00dc41342d 100644
--- a/src/storage/table/CMakeLists.txt
+++ b/src/storage/table/CMakeLists.txt
@@ -10,6 +10,7 @@ add_library_unity(
   persistent_segment.cpp
   row_group.cpp
   standard_column_data.cpp
+  struct_column_data.cpp
   transient_segment.cpp
   validity_column_data.cpp
   validity_segment.cpp)
diff --git a/src/storage/table/column_data.cpp b/src/storage/table/column_data.cpp
index 287f0ccd8718..b602d345d9b3 100644
--- a/src/storage/table/column_data.cpp
+++ b/src/storage/table/column_data.cpp
@@ -9,6 +9,7 @@
 #include "duckdb/planner/table_filter.hpp"
 #include "duckdb/common/vector_operations/vector_operations.hpp"
 #include "duckdb/storage/table/validity_segment.hpp"
+#include "duckdb/storage/table/struct_column_data.hpp"
 
 #include "duckdb/storage/numeric_segment.hpp"
 #include "duckdb/storage/string_segment.hpp"
@@ -111,6 +112,15 @@ void ColumnData::ScanCommitted(idx_t vector_index, ColumnScanState &state, Vecto
 	}
 }
 
+void ColumnData::ScanCommittedRange(idx_t row_group_start, idx_t offset_in_row_group, idx_t count, Vector &result) {
+	ColumnScanState child_state;
+	InitializeScanWithOffset(child_state, row_group_start + offset_in_row_group);
+	ScanVector(child_state, result);
+	if (updates) {
+		updates->FetchCommittedRange(offset_in_row_group, count, result);
+	}
+}
+
 void ColumnScanState::Next() {
 	//! There is no column segment
 	if (!current) {
@@ -379,8 +389,15 @@ void ColumnCheckpointState::FlushToDisk() {
 	}
 }
 
-unique_ptr<ColumnCheckpointState> ColumnData::Checkpoint(RowGroup &row_group, TableDataWriter &writer,
-                                                         idx_t column_idx) {
+void ColumnData::CheckpointScan(ColumnSegment *segment, ColumnScanState &state, idx_t row_group_start,
+                                idx_t base_row_index, idx_t count, Vector &scan_vector) {
+	segment->Scan(state, base_row_index, count, scan_vector, 0);
+	if (updates) {
+		updates->FetchCommittedRange(segment->start - row_group_start + base_row_index, count, scan_vector);
+	}
+}
+
+unique_ptr<ColumnCheckpointState> ColumnData::Checkpoint(RowGroup &row_group, TableDataWriter &writer) {
 	// scan the segments of the column data
 	// set up the checkpoint state
 	auto checkpoint_state = CreateCheckpointState(row_group, writer);
@@ -394,7 +411,9 @@ unique_ptr<ColumnCheckpointState> ColumnData::Checkpoint(RowGroup &row_group, Ta
 
 	auto &block_manager = BlockManager::GetBlockManager(GetDatabase());
 	checkpoint_state->CreateEmptySegment();
-	Vector intermediate(row_group.columns[column_idx]->type);
+
+	bool is_validity = type.id() == LogicalTypeId::VALIDITY;
+	Vector intermediate(is_validity ? LogicalType::BOOLEAN : type, true, is_validity);
 	// we create a new segment tree with all the new segments
 	// we do this by scanning the current segments of the column and checking for changes
 	// if there are any changes (e.g. updates or deletes) we write the new changes
@@ -456,10 +475,8 @@ unique_ptr<ColumnCheckpointState> ColumnData::Checkpoint(RowGroup &row_group, Ta
 
 			idx_t count = MinValue<idx_t>(segment->count - base_row_index, STANDARD_VECTOR_SIZE);
 			state.row_index = segment->start + base_row_index;
-			segment->Scan(state, base_row_index, count, scan_vector, 0);
-			if (updates) {
-				updates->FetchCommittedRange(segment->start - row_group.start + base_row_index, count, scan_vector);
-			}
+
+			CheckpointScan(segment, state, row_group.start, base_row_index, count, scan_vector);
 
 			checkpoint_state->AppendData(scan_vector, count);
 		}
@@ -487,8 +504,7 @@ void ColumnData::Initialize(PersistentColumnData &column_data) {
 	}
 }
 
-void ColumnData::BaseDeserialize(DatabaseInstance &db, Deserializer &source, const LogicalType &type,
-                                 ColumnData &result) {
+void ColumnData::DeserializeColumn(Deserializer &source) {
 	// load the data pointers for the column
 	idx_t data_pointer_count = source.Read<idx_t>();
 	for (idx_t data_ptr = 0; data_ptr < data_pointer_count; data_ptr++) {
@@ -501,16 +517,18 @@ void ColumnData::BaseDeserialize(DatabaseInstance &db, Deserializer &source, con
 		data_pointer.statistics = BaseStatistics::Deserialize(source, type);
 
 		// create a persistent segment
-		auto segment = make_unique<PersistentSegment>(db, data_pointer.block_pointer.block_id,
+		auto segment = make_unique<PersistentSegment>(GetDatabase(), data_pointer.block_pointer.block_id,
 		                                              data_pointer.block_pointer.offset, type, data_pointer.row_start,
 		                                              data_pointer.tuple_count, move(data_pointer.statistics));
-		result.data.AppendSegment(move(segment));
+		data.AppendSegment(move(segment));
 	}
 }
 
 shared_ptr<ColumnData> ColumnData::Deserialize(DataTableInfo &info, idx_t column_index, idx_t start_row,
-                                               Deserializer &source, const LogicalType &type) {
-	return StandardColumnData::Deserialize(info, column_index, start_row, source, type);
+                                               Deserializer &source, const LogicalType &type, ColumnData *parent) {
+	auto entry = ColumnData::CreateColumn(info, column_index, start_row, type, parent);
+	entry->DeserializeColumn(source);
+	return entry;
 }
 
 void ColumnData::GetStorageInfo(idx_t row_group_index, vector<idx_t> col_path, vector<vector<Value>> &result) {
@@ -588,9 +606,32 @@ void ColumnData::Verify(RowGroup &parent) {
 			root = root->next.get();
 		}
 	} else {
-		D_ASSERT(parent.count == 0);
+		if (type.id() != LogicalTypeId::STRUCT) {
+			D_ASSERT(parent.count == 0);
+		}
 	}
 #endif
 }
 
+template <class RET, class OP>
+static RET CreateColumnInternal(DataTableInfo &info, idx_t column_index, idx_t start_row, const LogicalType &type,
+                                ColumnData *parent) {
+	if (type.InternalType() == PhysicalType::STRUCT) {
+		return OP::template Create<StructColumnData>(info, column_index, start_row, type, parent);
+	} else if (type.id() == LogicalTypeId::VALIDITY) {
+		return OP::template Create<ValidityColumnData>(info, column_index, start_row, parent);
+	}
+	return OP::template Create<StandardColumnData>(info, column_index, start_row, type, parent);
+}
+
+shared_ptr<ColumnData> ColumnData::CreateColumn(DataTableInfo &info, idx_t column_index, idx_t start_row,
+                                                const LogicalType &type, ColumnData *parent) {
+	return CreateColumnInternal<shared_ptr<ColumnData>, SharedConstructor>(info, column_index, start_row, type, parent);
+}
+
+unique_ptr<ColumnData> ColumnData::CreateColumnUnique(DataTableInfo &info, idx_t column_index, idx_t start_row,
+                                                      const LogicalType &type, ColumnData *parent) {
+	return CreateColumnInternal<unique_ptr<ColumnData>, UniqueConstructor>(info, column_index, start_row, type, parent);
+}
+
 } // namespace duckdb
diff --git a/src/storage/table/row_group.cpp b/src/storage/table/row_group.cpp
index e79d2edc0afc..230ca417f029 100644
--- a/src/storage/table/row_group.cpp
+++ b/src/storage/table/row_group.cpp
@@ -33,7 +33,7 @@ RowGroup::RowGroup(DatabaseInstance &db, DataTableInfo &table_info, const vector
 		auto &block_pointer = pointer.data_pointers[i];
 		MetaBlockReader column_data_reader(db, block_pointer.block_id);
 		column_data_reader.offset = block_pointer.offset;
-		this->columns.push_back(ColumnData::Deserialize(table_info, i, start, column_data_reader, types[i]));
+		this->columns.push_back(ColumnData::Deserialize(table_info, i, start, column_data_reader, types[i], nullptr));
 	}
 
 	// set up the statistics
@@ -51,7 +51,7 @@ RowGroup::~RowGroup() {
 void RowGroup::InitializeEmpty(const vector<LogicalType> &types) {
 	// set up the segment trees for the column segments
 	for (idx_t i = 0; i < types.size(); i++) {
-		auto column_data = make_shared<StandardColumnData>(GetTableInfo(), i, start, types[i]);
+		auto column_data = ColumnData::CreateColumn(GetTableInfo(), i, start, types[i]);
 		stats.push_back(make_shared<SegmentStatistics>(types[i]));
 		columns.push_back(move(column_data));
 	}
@@ -111,7 +111,7 @@ unique_ptr<RowGroup> RowGroup::AlterType(ClientContext &context, const LogicalTy
 	Verify();
 
 	// construct a new column data for this type
-	auto column_data = make_shared<StandardColumnData>(GetTableInfo(), changed_idx, start, target_type);
+	auto column_data = ColumnData::CreateColumn(GetTableInfo(), changed_idx, start, target_type);
 
 	ColumnAppendState append_state;
 	column_data->InitializeAppend(append_state);
@@ -156,7 +156,7 @@ unique_ptr<RowGroup> RowGroup::AddColumn(ClientContext &context, ColumnDefinitio
 	Verify();
 
 	// construct a new column data for the new column
-	auto added_column = make_shared<StandardColumnData>(GetTableInfo(), columns.size(), start, new_column.type);
+	auto added_column = ColumnData::CreateColumn(GetTableInfo(), columns.size(), start, new_column.type);
 
 	auto added_col_stats = make_shared<SegmentStatistics>(new_column.type);
 	idx_t rows_to_write = this->count;
@@ -568,7 +568,7 @@ RowGroupPointer RowGroup::Checkpoint(TableDataWriter &writer, vector<unique_ptr<
 	// checkpoint the individual columns of the row group
 	for (idx_t column_idx = 0; column_idx < columns.size(); column_idx++) {
 		auto &column = columns[column_idx];
-		auto checkpoint_state = column->Checkpoint(*this, writer, column_idx);
+		auto checkpoint_state = column->Checkpoint(*this, writer);
 		D_ASSERT(checkpoint_state);
 
 		auto stats = checkpoint_state->GetStatistics();
@@ -590,7 +590,7 @@ RowGroupPointer RowGroup::Checkpoint(TableDataWriter &writer, vector<unique_ptr<
 
 		// store the stats and the data pointers in the row group pointers
 		row_group_pointer.data_pointers.push_back(pointer);
-		row_group_pointer.statistics.push_back(move(state->global_stats));
+		row_group_pointer.statistics.push_back(state->GetStatistics());
 
 		// now flush the actual column data to disk
 		state->FlushToDisk();
@@ -636,6 +636,9 @@ shared_ptr<VersionNode> RowGroup::DeserializeDeletes(Deserializer &source) {
 	auto version_info = make_shared<VersionNode>();
 	for (idx_t i = 0; i < chunk_count; i++) {
 		idx_t vector_index = source.Read<idx_t>();
+		if (vector_index >= RowGroup::ROW_GROUP_VECTOR_COUNT) {
+			throw Exception("In DeserializeDeletes, vector_index is out of range for the row group. Corrupted file?");
+		}
 		version_info->info[vector_index] = ChunkInfo::Deserialize(source);
 	}
 	return version_info;
diff --git a/src/storage/table/standard_column_data.cpp b/src/storage/table/standard_column_data.cpp
index 800b9feb192f..7da88be2c271 100644
--- a/src/storage/table/standard_column_data.cpp
+++ b/src/storage/table/standard_column_data.cpp
@@ -154,12 +154,14 @@ struct StandardColumnCheckpointState : public ColumnCheckpointState {
 	    : ColumnCheckpointState(row_group, column_data, writer) {
 	}
 
+	unique_ptr<ColumnCheckpointState> validity_state;
+
+public:
 	unique_ptr<BaseStatistics> GetStatistics() override {
 		auto stats = global_stats->Copy();
 		stats->validity_stats = validity_state->GetStatistics();
 		return stats;
 	}
-	unique_ptr<ColumnCheckpointState> validity_state;
 
 	void FlushToDisk() override {
 		ColumnCheckpointState::FlushToDisk();
@@ -172,26 +174,31 @@ unique_ptr<ColumnCheckpointState> StandardColumnData::CreateCheckpointState(RowG
 	return make_unique<StandardColumnCheckpointState>(row_group, *this, writer);
 }
 
-unique_ptr<ColumnCheckpointState> StandardColumnData::Checkpoint(RowGroup &row_group, TableDataWriter &writer,
-                                                                 idx_t column_idx) {
-	auto base_state = ColumnData::Checkpoint(row_group, writer, column_idx);
+unique_ptr<ColumnCheckpointState> StandardColumnData::Checkpoint(RowGroup &row_group, TableDataWriter &writer) {
+	auto validity_state = validity.Checkpoint(row_group, writer);
+	auto base_state = ColumnData::Checkpoint(row_group, writer);
 	auto &checkpoint_state = (StandardColumnCheckpointState &)*base_state;
-	checkpoint_state.validity_state = validity.Checkpoint(row_group, writer, column_idx);
+	checkpoint_state.validity_state = move(validity_state);
 	return base_state;
 }
 
+void StandardColumnData::CheckpointScan(ColumnSegment *segment, ColumnScanState &state, idx_t row_group_start,
+                                        idx_t base_row_index, idx_t count, Vector &scan_vector) {
+	ColumnData::CheckpointScan(segment, state, row_group_start, base_row_index, count, scan_vector);
+
+	idx_t offset_in_row_group = segment->start - row_group_start + base_row_index;
+	validity.ScanCommittedRange(row_group_start, offset_in_row_group, count, scan_vector);
+}
+
 void StandardColumnData::Initialize(PersistentColumnData &column_data) {
 	auto &persistent = (StandardPersistentColumnData &)column_data;
 	ColumnData::Initialize(column_data);
 	validity.Initialize(*persistent.validity);
 }
 
-shared_ptr<ColumnData> StandardColumnData::Deserialize(DataTableInfo &info, idx_t column_index, idx_t start_row,
-                                                       Deserializer &source, const LogicalType &type) {
-	auto result = make_shared<StandardColumnData>(info, column_index, start_row, type, nullptr);
-	BaseDeserialize(info.db, source, type, *result);
-	ColumnData::BaseDeserialize(info.db, source, LogicalType(LogicalTypeId::VALIDITY), result->validity);
-	return move(result);
+void StandardColumnData::DeserializeColumn(Deserializer &source) {
+	ColumnData::DeserializeColumn(source);
+	validity.DeserializeColumn(source);
 }
 
 void StandardColumnData::GetStorageInfo(idx_t row_group_index, vector<idx_t> col_path, vector<vector<Value>> &result) {
diff --git a/src/storage/table/struct_column_data.cpp b/src/storage/table/struct_column_data.cpp
new file mode 100644
index 000000000000..bdd1cd110115
--- /dev/null
+++ b/src/storage/table/struct_column_data.cpp
@@ -0,0 +1,263 @@
+#include "duckdb/storage/table/struct_column_data.hpp"
+#include "duckdb/storage/statistics/struct_statistics.hpp"
+
+namespace duckdb {
+
+StructColumnData::StructColumnData(DataTableInfo &info, idx_t column_index, idx_t start_row, LogicalType type_p,
+                                   ColumnData *parent)
+    : ColumnData(info, column_index, start_row, move(type_p), parent), validity(info, 0, start_row, this) {
+	D_ASSERT(type.InternalType() == PhysicalType::STRUCT);
+	auto &child_types = type.child_types();
+	D_ASSERT(child_types.size() > 0);
+	// the sub column index, starting at 1 (0 is the validity mask)
+	idx_t sub_column_index = 1;
+	for (auto &child_type : child_types) {
+		sub_columns.push_back(
+		    ColumnData::CreateColumnUnique(info, sub_column_index, start_row, child_type.second, this));
+		sub_column_index++;
+	}
+}
+
+bool StructColumnData::CheckZonemap(ColumnScanState &state, TableFilter &filter) {
+	// table filters are not supported yet for struct columns
+	return false;
+}
+
+void StructColumnData::InitializeScan(ColumnScanState &state) {
+	// initialize the validity segment
+	ColumnScanState validity_state;
+	validity.InitializeScan(validity_state);
+	state.child_states.push_back(move(validity_state));
+
+	// initialize the sub-columns
+	for (auto &sub_column : sub_columns) {
+		ColumnScanState child_state;
+		sub_column->InitializeScan(child_state);
+		state.child_states.push_back(move(child_state));
+	}
+}
+
+void StructColumnData::InitializeScanWithOffset(ColumnScanState &state, idx_t row_idx) {
+	// initialize the validity segment
+	ColumnScanState validity_state;
+	validity.InitializeScanWithOffset(validity_state, row_idx);
+	state.child_states.push_back(move(validity_state));
+
+	// initialize the sub-columns
+	for (auto &sub_column : sub_columns) {
+		ColumnScanState child_state;
+		sub_column->InitializeScanWithOffset(child_state, row_idx);
+		state.child_states.push_back(move(child_state));
+	}
+}
+
+void StructColumnData::Scan(Transaction &transaction, idx_t vector_index, ColumnScanState &state, Vector &result) {
+	validity.Scan(transaction, vector_index, state.child_states[0], result);
+	auto &child_entries = StructVector::GetEntries(result);
+	for (idx_t i = 0; i < sub_columns.size(); i++) {
+		sub_columns[i]->Scan(transaction, vector_index, state.child_states[i + 1], *child_entries[i]);
+	}
+	state.child_states[0].Next();
+}
+
+void StructColumnData::ScanCommitted(idx_t vector_index, ColumnScanState &state, Vector &result, bool allow_updates) {
+	validity.ScanCommitted(vector_index, state.child_states[0], result, allow_updates);
+	auto &child_entries = StructVector::GetEntries(result);
+	for (idx_t i = 0; i < sub_columns.size(); i++) {
+		sub_columns[i]->ScanCommitted(vector_index, state.child_states[i + 1], *child_entries[i], allow_updates);
+	}
+	state.child_states[0].Next();
+}
+
+void StructColumnData::InitializeAppend(ColumnAppendState &state) {
+	ColumnAppendState validity_append;
+	validity.InitializeAppend(validity_append);
+	state.child_appends.push_back(move(validity_append));
+
+	for (auto &sub_column : sub_columns) {
+		ColumnAppendState child_append;
+		sub_column->InitializeAppend(child_append);
+		state.child_appends.push_back(move(child_append));
+	}
+}
+
+void StructColumnData::Append(BaseStatistics &stats, ColumnAppendState &state, Vector &vector, idx_t count) {
+	vector.Normalify(count);
+
+	// append the null values
+	validity.Append(*stats.validity_stats, state.child_appends[0], vector, count);
+
+	auto &struct_validity = FlatVector::Validity(vector);
+
+	auto &struct_stats = (StructStatistics &)stats;
+	auto &child_entries = StructVector::GetEntries(vector);
+	for (idx_t i = 0; i < child_entries.size(); i++) {
+		if (!struct_validity.AllValid()) {
+			// we set the child entries of the struct to NULL
+			// for any values in which the struct itself is NULL
+			child_entries[i]->Normalify(count);
+
+			auto &child_validity = FlatVector::Validity(*child_entries[i]);
+			child_validity.Combine(struct_validity, count);
+		}
+		sub_columns[i]->Append(*struct_stats.child_stats[i], state.child_appends[i + 1], *child_entries[i], count);
+	}
+}
+
+void StructColumnData::RevertAppend(row_t start_row) {
+	validity.RevertAppend(start_row);
+	for (auto &sub_column : sub_columns) {
+		sub_column->RevertAppend(start_row);
+	}
+}
+
+void StructColumnData::Fetch(ColumnScanState &state, row_t row_id, Vector &result) {
+	// fetch validity mask
+	auto &child_entries = StructVector::GetEntries(result);
+	// insert any child states that are required
+	for (idx_t i = state.child_states.size(); i < child_entries.size() + 1; i++) {
+		ColumnScanState child_state;
+		state.child_states.push_back(move(child_state));
+	}
+	// fetch the validity state
+	validity.Fetch(state.child_states[0], row_id, result);
+	// fetch the sub-column states
+	for (idx_t i = 0; i < child_entries.size(); i++) {
+		sub_columns[i]->Fetch(state.child_states[i + 1], row_id, *child_entries[i]);
+	}
+}
+
+void StructColumnData::Update(Transaction &transaction, idx_t column_index, Vector &update_vector, row_t *row_ids,
+                              idx_t update_count) {
+	validity.Update(transaction, column_index, update_vector, row_ids, update_count);
+	auto &child_entries = StructVector::GetEntries(update_vector);
+	for (idx_t i = 0; i < child_entries.size(); i++) {
+		sub_columns[i]->Update(transaction, column_index, *child_entries[i], row_ids, update_count);
+	}
+}
+
+void StructColumnData::UpdateColumn(Transaction &transaction, const vector<column_t> &column_path,
+                                    Vector &update_vector, row_t *row_ids, idx_t update_count, idx_t depth) {
+	// we can never DIRECTLY update a struct column
+	if (depth >= column_path.size()) {
+		throw InternalException("Attempting to directly update a struct column - this should not be possible");
+	}
+	auto update_column = column_path[depth];
+	if (update_column == 0) {
+		// update the validity column
+		validity.UpdateColumn(transaction, column_path, update_vector, row_ids, update_count, depth + 1);
+	} else {
+		if (update_column > sub_columns.size()) {
+			throw InternalException("Update column_path out of range");
+		}
+		sub_columns[update_column - 1]->UpdateColumn(transaction, column_path, update_vector, row_ids, update_count,
+		                                             depth + 1);
+	}
+}
+
+unique_ptr<BaseStatistics> StructColumnData::GetUpdateStatistics() {
+	// check if any child column has updates
+	auto stats = BaseStatistics::CreateEmpty(type);
+	auto &struct_stats = (StructStatistics &)*stats;
+	stats->validity_stats = validity.GetUpdateStatistics();
+	for (idx_t i = 0; i < sub_columns.size(); i++) {
+		auto child_stats = sub_columns[i]->GetUpdateStatistics();
+		if (child_stats) {
+			struct_stats.child_stats[i] = move(child_stats);
+		}
+	}
+	return stats;
+}
+
+void StructColumnData::FetchRow(Transaction &transaction, ColumnFetchState &state, row_t row_id, Vector &result,
+                                idx_t result_idx) {
+	// fetch validity mask
+	auto &child_entries = StructVector::GetEntries(result);
+	// insert any child states that are required
+	for (idx_t i = state.child_states.size(); i < child_entries.size() + 1; i++) {
+		auto child_state = make_unique<ColumnFetchState>();
+		state.child_states.push_back(move(child_state));
+	}
+	// fetch the validity state
+	validity.FetchRow(transaction, *state.child_states[0], row_id, result, result_idx);
+	// fetch the sub-column states
+	for (idx_t i = 0; i < child_entries.size(); i++) {
+		sub_columns[i]->FetchRow(transaction, *state.child_states[i + 1], row_id, *child_entries[i], result_idx);
+	}
+}
+
+void StructColumnData::CommitDropColumn() {
+	validity.CommitDropColumn();
+	for (auto &sub_column : sub_columns) {
+		sub_column->CommitDropColumn();
+	}
+}
+
+struct StructColumnCheckpointState : public ColumnCheckpointState {
+	StructColumnCheckpointState(RowGroup &row_group, ColumnData &column_data, TableDataWriter &writer)
+	    : ColumnCheckpointState(row_group, column_data, writer) {
+		global_stats = make_unique<StructStatistics>(column_data.type);
+	}
+
+	unique_ptr<ColumnCheckpointState> validity_state;
+	vector<unique_ptr<ColumnCheckpointState>> child_states;
+
+public:
+	unique_ptr<BaseStatistics> GetStatistics() override {
+		auto stats = make_unique<StructStatistics>(column_data.type);
+		D_ASSERT(stats->child_stats.size() == child_states.size());
+		stats->validity_stats = validity_state->GetStatistics();
+		for (idx_t i = 0; i < child_states.size(); i++) {
+			stats->child_stats[i] = child_states[i]->GetStatistics();
+			D_ASSERT(stats->child_stats[i]);
+		}
+		return move(stats);
+	}
+
+	void FlushToDisk() override {
+		validity_state->FlushToDisk();
+		for (auto &state : child_states) {
+			state->FlushToDisk();
+		}
+	}
+};
+
+unique_ptr<ColumnCheckpointState> StructColumnData::CreateCheckpointState(RowGroup &row_group,
+                                                                          TableDataWriter &writer) {
+	return make_unique<StructColumnCheckpointState>(row_group, *this, writer);
+}
+
+unique_ptr<ColumnCheckpointState> StructColumnData::Checkpoint(RowGroup &row_group, TableDataWriter &writer) {
+	auto checkpoint_state = make_unique<StructColumnCheckpointState>(row_group, *this, writer);
+	checkpoint_state->validity_state = validity.Checkpoint(row_group, writer);
+	for (auto &sub_column : sub_columns) {
+		checkpoint_state->child_states.push_back(sub_column->Checkpoint(row_group, writer));
+	}
+	return move(checkpoint_state);
+}
+
+void StructColumnData::Initialize(PersistentColumnData &column_data) {
+	auto &persistent = (StructPersistentColumnData &)column_data;
+	validity.Initialize(*persistent.validity);
+	for (idx_t i = 0; i < sub_columns.size(); i++) {
+		sub_columns[i]->Initialize(*persistent.child_data[i]);
+	}
+}
+
+void StructColumnData::DeserializeColumn(Deserializer &source) {
+	validity.DeserializeColumn(source);
+	for (auto &sub_column : sub_columns) {
+		sub_column->DeserializeColumn(source);
+	}
+}
+
+void StructColumnData::GetStorageInfo(idx_t row_group_index, vector<idx_t> col_path, vector<vector<Value>> &result) {
+	col_path.push_back(0);
+	validity.GetStorageInfo(row_group_index, col_path, result);
+	for (idx_t i = 0; i < sub_columns.size(); i++) {
+		col_path.back() = i + 1;
+		sub_columns[i]->GetStorageInfo(row_group_index, col_path, result);
+	}
+}
+
+} // namespace duckdb
diff --git a/src/storage/table/update_segment.cpp b/src/storage/table/update_segment.cpp
index 689adadd70eb..0fd4270e7556 100644
--- a/src/storage/table/update_segment.cpp
+++ b/src/storage/table/update_segment.cpp
@@ -984,6 +984,8 @@ void UpdateSegment::Update(Transaction &transaction, idx_t column_index, Vector
 	// obtain an exclusive lock
 	auto write_lock = lock.GetExclusiveLock();
 
+	update.Normalify(count);
+
 	// update statistics
 	SelectionVector sel;
 	{
diff --git a/src/storage/table/validity_segment.cpp b/src/storage/table/validity_segment.cpp
index b138de189565..5707afd067cd 100644
--- a/src/storage/table/validity_segment.cpp
+++ b/src/storage/table/validity_segment.cpp
@@ -229,13 +229,17 @@ void ValiditySegment::Scan(ColumnScanState &state, idx_t start, idx_t scan_count
 
 	auto &result_mask = FlatVector::Validity(result);
 	auto input_data = (validity_t *)state.primary_handle->node->buffer;
-	auto result_data = (validity_t *)result_mask.GetData();
 
-	// the code below does this, but using bitwise ops:
-	// ValidityMask source_mask(input_data);
-	// for (idx_t i = 0; i < scan_count; i++) {
-	//     result_mask.Set(result_offset + i, source_mask.RowIsValid(start + i));
-	// }
+#if STANDARD_VECTOR_SIZE < 128
+	// fallback for tiny vector sizes
+	// the bitwise ops we use below don't work if the vector size is too small
+	ValidityMask source_mask(input_data);
+	for (idx_t i = 0; i < scan_count; i++) {
+		result_mask.Set(result_offset + i, source_mask.RowIsValid(start + i));
+	}
+#else
+	// the code below does what the fallback code above states, but using bitwise ops:
+	auto result_data = (validity_t *)result_mask.GetData();
 
 	// set up the initial positions
 	// we need to find the validity_entry to modify, together with the bit-index WITHIN the validity entry
@@ -315,6 +319,7 @@ void ValiditySegment::Scan(ColumnScanState &state, idx_t start, idx_t scan_count
 			result_data[current_result_idx] &= input_mask;
 		}
 	}
+#endif
 
 #ifdef DEBUG
 	// verify that we actually accomplished the bitwise ops equivalent that we wanted to do
