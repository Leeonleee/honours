{
  "repo": "duckdb/duckdb",
  "pull_number": 6807,
  "instance_id": "duckdb__duckdb-6807",
  "issue_numbers": [
    "6799",
    "6799"
  ],
  "base_commit": "227bd4bddc85d30fa8b851c3a2d30e93271996d9",
  "patch": "diff --git a/src/common/operator/cast_operators.cpp b/src/common/operator/cast_operators.cpp\nindex 55e9d90756f9..f1062e7a6b5a 100644\n--- a/src/common/operator/cast_operators.cpp\n+++ b/src/common/operator/cast_operators.cpp\n@@ -1477,7 +1477,7 @@ bool TryCastToBit::Operation(string_t input, string_t &result, Vector &result_ve\n \t}\n \n \tresult = StringVector::EmptyString(result_vector, result_size);\n-\tBit::ToBit(input, (data_ptr_t)result.GetDataWriteable());\n+\tBit::ToBit(input, result);\n \tresult.Finalize();\n \treturn true;\n }\ndiff --git a/src/common/types/bit.cpp b/src/common/types/bit.cpp\nindex eda1db50594d..500853e15792 100644\n--- a/src/common/types/bit.cpp\n+++ b/src/common/types/bit.cpp\n@@ -10,26 +10,53 @@ static char ComputePadding(idx_t len) {\n }\n \n idx_t Bit::ComputeBitstringLen(idx_t len) {\n-\tlen = len % 8 ? (len / 8) + 1 : len / 8;\n-\treturn ++len; // additional first byte to store info on zero padding\n+\tidx_t result = len / 8;\n+\tif (len % 8 != 0) {\n+\t\tresult++;\n+\t}\n+\t// additional first byte to store info on zero padding\n+\tresult++;\n+\treturn result;\n }\n \n-inline idx_t Bit::GetPadding(const string_t &bit_string) {\n+static inline idx_t GetBitPadding(const string_t &bit_string) {\n \tauto data = (const_data_ptr_t)bit_string.GetDataUnsafe();\n+\tD_ASSERT(idx_t(data[0]) <= 8);\n \treturn data[0];\n }\n \n+static inline idx_t GetBitSize(const string_t &str) {\n+\tstring error_message;\n+\tidx_t str_len;\n+\tif (!Bit::TryGetBitStringSize(str, str_len, &error_message)) {\n+\t\tthrow ConversionException(error_message);\n+\t}\n+\treturn str_len;\n+}\n+\n+void Bit::Finalize(string_t &str) {\n+\t// bit strings require all padding bits to be set to 1\n+\t// this method sets all padding bits to 1\n+\tauto padding = GetBitPadding(str);\n+\tfor (idx_t i = 0; i < idx_t(padding); i++) {\n+\t\tBit::SetBitInternal(str, i, 1);\n+\t}\n+\tBit::Verify(str);\n+}\n+\n void Bit::SetEmptyBitString(string_t &target, string_t &input) {\n \tchar *res_buf = target.GetDataWriteable();\n \tconst char *buf = input.GetDataUnsafe();\n \tmemset(res_buf, 0, input.GetSize());\n \tres_buf[0] = buf[0];\n+\tBit::Finalize(target);\n }\n \n void Bit::SetEmptyBitString(string_t &target, idx_t len) {\n \tchar *res_buf = target.GetDataWriteable();\n \tmemset(res_buf, 0, target.GetSize());\n \tres_buf[0] = ComputePadding(len);\n+\tBit::Finalize(target);\n }\n \n // **** casting functions ****\n@@ -37,7 +64,7 @@ void Bit::ToString(string_t bits, char *output) {\n \tauto data = (const_data_ptr_t)bits.GetDataUnsafe();\n \tauto len = bits.GetSize();\n \n-\tidx_t padding = GetPadding(bits);\n+\tidx_t padding = GetBitPadding(bits);\n \tidx_t output_idx = 0;\n \tfor (idx_t bit_idx = padding; bit_idx < 8; bit_idx++) {\n \t\toutput[output_idx++] = data[1] & (1 << (7 - bit_idx)) ? '1' : '0';\n@@ -79,18 +106,10 @@ bool Bit::TryGetBitStringSize(string_t str, idx_t &str_len, string *error_messag\n \treturn true;\n }\n \n-idx_t Bit::GetBitSize(string_t str) {\n-\tstring error_message;\n-\tidx_t str_len;\n-\tif (!Bit::TryGetBitStringSize(str, str_len, &error_message)) {\n-\t\tthrow ConversionException(error_message);\n-\t}\n-\treturn str_len;\n-}\n-\n-void Bit::ToBit(string_t str, data_ptr_t output) {\n+void Bit::ToBit(string_t str, string_t &output_str) {\n \tauto data = (const_data_ptr_t)str.GetDataUnsafe();\n \tauto len = str.GetSize();\n+\tauto output = output_str.GetDataWriteable();\n \n \tchar byte = 0;\n \tidx_t padded_byte = len % 8;\n@@ -115,33 +134,38 @@ void Bit::ToBit(string_t str, data_ptr_t output) {\n \t\t}\n \t\t*(output++) = byte;\n \t}\n+\tBit::Finalize(output_str);\n+\tBit::Verify(output_str);\n }\n \n string Bit::ToBit(string_t str) {\n \tauto bit_len = GetBitSize(str);\n \tauto buffer = std::unique_ptr<char[]>(new char[bit_len]);\n-\tBit::ToBit(str, (data_ptr_t)buffer.get());\n-\treturn string(buffer.get(), bit_len);\n+\tstring_t output_str(buffer.get(), bit_len);\n+\tBit::ToBit(str, output_str);\n+\treturn output_str.GetString();\n }\n \n // **** scalar functions ****\n-void Bit::BitString(const string_t &input, const idx_t &len, string_t &result) {\n+void Bit::BitString(const string_t &input, const idx_t &bit_length, string_t &result) {\n \tchar *res_buf = result.GetDataWriteable();\n \tconst char *buf = input.GetDataUnsafe();\n \n-\tres_buf[0] = ComputePadding(len);\n-\tfor (idx_t i = 0; i < Bit::BitLength(result); i++) {\n-\t\tif (i < len - input.GetSize()) {\n+\tauto padding = ComputePadding(bit_length);\n+\tres_buf[0] = padding;\n+\tfor (idx_t i = 0; i < bit_length; i++) {\n+\t\tif (i < bit_length - input.GetSize()) {\n \t\t\tBit::SetBit(result, i, 0);\n \t\t} else {\n-\t\t\tidx_t bit = buf[i - (len - input.GetSize())] == '1' ? 1 : 0;\n+\t\t\tidx_t bit = buf[i - (bit_length - input.GetSize())] == '1' ? 1 : 0;\n \t\t\tBit::SetBit(result, i, bit);\n \t\t}\n \t}\n+\tBit::Finalize(result);\n }\n \n idx_t Bit::BitLength(string_t bits) {\n-\treturn ((bits.GetSize() - 1) * 8) - GetPadding(bits);\n+\treturn ((bits.GetSize() - 1) * 8) - GetBitPadding(bits);\n }\n \n idx_t Bit::OctetLength(string_t bits) {\n@@ -156,7 +180,7 @@ idx_t Bit::BitCount(string_t bits) {\n \t\t\tcount += (buf[byte_idx] & (1 << bit_idx)) ? 1 : 0;\n \t\t}\n \t}\n-\treturn count;\n+\treturn count - GetBitPadding(bits);\n }\n \n idx_t Bit::BitPosition(string_t substring, string_t bits) {\n@@ -165,12 +189,12 @@ idx_t Bit::BitPosition(string_t substring, string_t bits) {\n \tauto substr_len = BitLength(substring);\n \tidx_t substr_idx = 0;\n \n-\tfor (idx_t bit_idx = GetPadding(bits); bit_idx < 8; bit_idx++) {\n+\tfor (idx_t bit_idx = GetBitPadding(bits); bit_idx < 8; bit_idx++) {\n \t\tidx_t bit = buf[1] & (1 << (7 - bit_idx)) ? 1 : 0;\n \t\tif (bit == GetBit(substring, substr_idx)) {\n \t\t\tsubstr_idx++;\n \t\t\tif (substr_idx == substr_len) {\n-\t\t\t\treturn (bit_idx - GetPadding(bits)) - substr_len + 2;\n+\t\t\t\treturn (bit_idx - GetBitPadding(bits)) - substr_len + 2;\n \t\t\t}\n \t\t} else {\n \t\t\tsubstr_idx = 0;\n@@ -183,7 +207,7 @@ idx_t Bit::BitPosition(string_t substring, string_t bits) {\n \t\t\tif (bit == GetBit(substring, substr_idx)) {\n \t\t\t\tsubstr_idx++;\n \t\t\t\tif (substr_idx == substr_len) {\n-\t\t\t\t\treturn (((byte_idx - 1) * 8) + bit_idx - GetPadding(bits)) - substr_len + 2;\n+\t\t\t\t\treturn (((byte_idx - 1) * 8) + bit_idx - GetBitPadding(bits)) - substr_len + 2;\n \t\t\t\t}\n \t\t\t} else {\n \t\t\t\tsubstr_idx = 0;\n@@ -194,38 +218,36 @@ idx_t Bit::BitPosition(string_t substring, string_t bits) {\n }\n \n idx_t Bit::GetBit(string_t bit_string, idx_t n) {\n-\tconst char *buf = bit_string.GetDataUnsafe();\n-\tn += GetPadding(bit_string);\n+\treturn Bit::GetBitInternal(bit_string, n + GetBitPadding(bit_string));\n+}\n \n-\tchar byte = buf[(n / 8) + 1] >> (7 - (n % 8));\n-\treturn (byte & 1 ? 1 : 0);\n+idx_t Bit::GetBitIndex(idx_t n) {\n+\treturn n / 8 + 1;\n }\n \n-void Bit::SetBit(const string_t &bit_string, idx_t n, idx_t new_value, string_t &result) {\n-\tchar *result_buf = result.GetDataWriteable();\n+idx_t Bit::GetBitInternal(string_t bit_string, idx_t n) {\n \tconst char *buf = bit_string.GetDataUnsafe();\n-\tn += GetPadding(bit_string);\n-\n-\tmemcpy(result_buf, buf, bit_string.GetSize());\n-\tchar shift_byte = 1 << (7 - (n % 8));\n-\tif (new_value == 0) {\n-\t\tshift_byte = ~shift_byte;\n-\t\tresult_buf[(n / 8) + 1] = buf[(n / 8) + 1] & shift_byte;\n-\t} else {\n-\t\tresult_buf[(n / 8) + 1] = buf[(n / 8) + 1] | shift_byte;\n-\t}\n+\tauto idx = Bit::GetBitIndex(n);\n+\tD_ASSERT(idx < bit_string.GetSize());\n+\tchar byte = buf[idx] >> (7 - (n % 8));\n+\treturn (byte & 1 ? 1 : 0);\n }\n \n void Bit::SetBit(string_t &bit_string, idx_t n, idx_t new_value) {\n+\tSetBitInternal(bit_string, n + GetBitPadding(bit_string), new_value);\n+}\n+\n+void Bit::SetBitInternal(string_t &bit_string, idx_t n, idx_t new_value) {\n \tchar *buf = bit_string.GetDataWriteable();\n-\tn += GetPadding(bit_string);\n \n+\tauto idx = Bit::GetBitIndex(n);\n+\tD_ASSERT(idx < bit_string.GetSize());\n \tchar shift_byte = 1 << (7 - (n % 8));\n \tif (new_value == 0) {\n \t\tshift_byte = ~shift_byte;\n-\t\tbuf[(n / 8) + 1] &= shift_byte;\n+\t\tbuf[idx] &= shift_byte;\n \t} else {\n-\t\tbuf[(n / 8) + 1] |= shift_byte;\n+\t\tbuf[idx] |= shift_byte;\n \t}\n }\n \n@@ -242,6 +264,7 @@ void Bit::RightShift(const string_t &bit_string, const idx_t &shift, string_t &r\n \t\t\tBit::SetBit(result, i, bit);\n \t\t}\n \t}\n+\tBit::Finalize(result);\n }\n \n void Bit::LeftShift(const string_t &bit_string, const idx_t &shift, string_t &result) {\n@@ -256,6 +279,8 @@ void Bit::LeftShift(const string_t &bit_string, const idx_t &shift, string_t &re\n \t\t\tBit::SetBit(result, i, 0);\n \t\t}\n \t}\n+\tBit::Finalize(result);\n+\tBit::Verify(result);\n }\n \n void Bit::BitwiseAnd(const string_t &rhs, const string_t &lhs, string_t &result) {\n@@ -271,6 +296,8 @@ void Bit::BitwiseAnd(const string_t &rhs, const string_t &lhs, string_t &result)\n \tfor (idx_t i = 1; i < lhs.GetSize(); i++) {\n \t\tbuf[i] = l_buf[i] & r_buf[i];\n \t}\n+\t// and should preserve padding bits\n+\tBit::Verify(result);\n }\n \n void Bit::BitwiseOr(const string_t &rhs, const string_t &lhs, string_t &result) {\n@@ -286,6 +313,8 @@ void Bit::BitwiseOr(const string_t &rhs, const string_t &lhs, string_t &result)\n \tfor (idx_t i = 1; i < lhs.GetSize(); i++) {\n \t\tbuf[i] = l_buf[i] | r_buf[i];\n \t}\n+\t// or should preserve padding bits\n+\tBit::Verify(result);\n }\n \n void Bit::BitwiseXor(const string_t &rhs, const string_t &lhs, string_t &result) {\n@@ -301,6 +330,7 @@ void Bit::BitwiseXor(const string_t &rhs, const string_t &lhs, string_t &result)\n \tfor (idx_t i = 1; i < lhs.GetSize(); i++) {\n \t\tbuf[i] = l_buf[i] ^ r_buf[i];\n \t}\n+\tBit::Finalize(result);\n }\n \n void Bit::BitwiseNot(const string_t &input, string_t &result) {\n@@ -311,5 +341,17 @@ void Bit::BitwiseNot(const string_t &input, string_t &result) {\n \tfor (idx_t i = 1; i < input.GetSize(); i++) {\n \t\tresult_buf[i] = ~buf[i];\n \t}\n+\tBit::Finalize(result);\n }\n+\n+void Bit::Verify(const string_t &input) {\n+#ifdef DEBUG\n+\t// bit strings require all padding bits to be set to 1\n+\tauto padding = GetBitPadding(input);\n+\tfor (idx_t i = 0; i < padding; i++) {\n+\t\tD_ASSERT(Bit::GetBitInternal(input, i));\n+\t}\n+#endif\n+}\n+\n } // namespace duckdb\ndiff --git a/src/common/types/column_data_collection.cpp b/src/common/types/column_data_collection.cpp\nindex 972ed7037374..9b454be05a5f 100644\n--- a/src/common/types/column_data_collection.cpp\n+++ b/src/common/types/column_data_collection.cpp\n@@ -5,6 +5,7 @@\n #include \"duckdb/common/types/column_data_collection_segment.hpp\"\n #include \"duckdb/common/vector_operations/vector_operations.hpp\"\n #include \"duckdb/storage/buffer_manager.hpp\"\n+#include \"duckdb/common/types/value_map.hpp\"\n \n namespace duckdb {\n \n@@ -944,6 +945,12 @@ void ColumnDataCollection::Reset() {\n \tallocator = make_shared<ColumnDataAllocator>(*allocator);\n }\n \n+struct ValueResultEquals {\n+\tbool operator()(const Value &a, const Value &b) const {\n+\t\treturn Value::DefaultValuesAreEqual(a, b);\n+\t}\n+};\n+\n bool ColumnDataCollection::ResultEquals(const ColumnDataCollection &left, const ColumnDataCollection &right,\n                                         string &error_message) {\n \tif (left.ColumnCount() != right.ColumnCount()) {\n@@ -959,13 +966,43 @@ bool ColumnDataCollection::ResultEquals(const ColumnDataCollection &left, const\n \tfor (idx_t r = 0; r < left.Count(); r++) {\n \t\tfor (idx_t c = 0; c < left.ColumnCount(); c++) {\n \t\t\tauto lvalue = left_rows.GetValue(c, r);\n-\t\t\tauto rvalue = left_rows.GetValue(c, r);\n+\t\t\tauto rvalue = right_rows.GetValue(c, r);\n \t\t\tif (!Value::DefaultValuesAreEqual(lvalue, rvalue)) {\n \t\t\t\terror_message =\n \t\t\t\t    StringUtil::Format(\"%s <> %s (row: %lld, col: %lld)\\n\", lvalue.ToString(), rvalue.ToString(), r, c);\n-\t\t\t\treturn false;\n+\t\t\t\tbreak;\n \t\t\t}\n \t\t}\n+\t\tif (!error_message.empty()) {\n+\t\t\tbreak;\n+\t\t}\n+\t}\n+\tif (!error_message.empty()) {\n+\t\t// do an unordered comparison\n+\t\tbool found_all = true;\n+\t\tfor (idx_t c = 0; c < left.ColumnCount(); c++) {\n+\t\t\tstd::unordered_multiset<Value, ValueHashFunction, ValueResultEquals> lvalues;\n+\t\t\tfor (idx_t r = 0; r < left.Count(); r++) {\n+\t\t\t\tauto lvalue = left_rows.GetValue(c, r);\n+\t\t\t\tlvalues.insert(lvalue);\n+\t\t\t}\n+\t\t\tfor (idx_t r = 0; r < right.Count(); r++) {\n+\t\t\t\tauto rvalue = right_rows.GetValue(c, r);\n+\t\t\t\tauto entry = lvalues.find(rvalue);\n+\t\t\t\tif (entry == lvalues.end()) {\n+\t\t\t\t\tfound_all = false;\n+\t\t\t\t\tbreak;\n+\t\t\t\t}\n+\t\t\t\tlvalues.erase(entry);\n+\t\t\t}\n+\t\t\tif (!found_all) {\n+\t\t\t\tbreak;\n+\t\t\t}\n+\t\t}\n+\t\tif (!found_all) {\n+\t\t\treturn false;\n+\t\t}\n+\t\terror_message = string();\n \t}\n \treturn true;\n }\ndiff --git a/src/common/types/vector.cpp b/src/common/types/vector.cpp\nindex 1232431dd384..85ec6c77485f 100644\n--- a/src/common/types/vector.cpp\n+++ b/src/common/types/vector.cpp\n@@ -17,6 +17,7 @@\n #include \"duckdb/common/types/value.hpp\"\n #include \"duckdb/common/fsst.hpp\"\n #include \"fsst.h\"\n+#include \"duckdb/common/types/bit.hpp\"\n \n #include \"duckdb/common/serializer/format_serializer.hpp\"\n #include \"duckdb/common/serializer/format_deserializer.hpp\"\n@@ -1286,6 +1287,7 @@ void Vector::Verify(Vector &vector_p, const SelectionVector &sel_p, idx_t count)\n \t\t\t\tif (validity.RowIsValid(oidx)) {\n \t\t\t\t\tauto buf = strings[oidx].GetDataUnsafe();\n \t\t\t\t\tD_ASSERT(*buf >= 0 && *buf < 8);\n+\t\t\t\t\tBit::Verify(strings[oidx]);\n \t\t\t\t}\n \t\t\t}\n \t\t\tbreak;\ndiff --git a/src/execution/index/art/art.cpp b/src/execution/index/art/art.cpp\nindex a618a77bab62..72fb5cd156a6 100644\n--- a/src/execution/index/art/art.cpp\n+++ b/src/execution/index/art/art.cpp\n@@ -654,6 +654,7 @@ bool ART::SearchEqual(Key &key, idx_t max_count, vector<row_t> &result_ids) {\n }\n \n void ART::SearchEqualJoinNoFetch(Key &key, idx_t &result_size) {\n+\tresult_size = 0;\n \n \t// we need to look for a leaf\n \tauto old_memory_size = memory_size;\ndiff --git a/src/execution/operator/join/physical_index_join.cpp b/src/execution/operator/join/physical_index_join.cpp\nindex f75fb77827c7..45d0b7e070ab 100644\n--- a/src/execution/operator/join/physical_index_join.cpp\n+++ b/src/execution/operator/join/physical_index_join.cpp\n@@ -64,6 +64,8 @@ PhysicalIndexJoin::PhysicalIndexJoin(LogicalOperator &op, unique_ptr<PhysicalOpe\n     : CachingPhysicalOperator(PhysicalOperatorType::INDEX_JOIN, std::move(op.types), estimated_cardinality),\n       left_projection_map(left_projection_map_p), right_projection_map(std::move(right_projection_map_p)),\n       index(index_p), conditions(std::move(cond)), join_type(join_type), lhs_first(lhs_first) {\n+\tD_ASSERT(right->type == PhysicalOperatorType::TABLE_SCAN);\n+\tauto &tbl_scan = (PhysicalTableScan &)*right;\n \tcolumn_ids = std::move(column_ids_p);\n \tchildren.push_back(std::move(left));\n \tchildren.push_back(std::move(right));\n@@ -74,11 +76,17 @@ PhysicalIndexJoin::PhysicalIndexJoin(LogicalOperator &op, unique_ptr<PhysicalOpe\n \tfor (auto &index_id : index->column_ids) {\n \t\tindex_ids.insert(index_id);\n \t}\n-\tfor (idx_t column_id = 0; column_id < column_ids.size(); column_id++) {\n-\t\tauto it = index_ids.find(column_ids[column_id]);\n+\n+\tfor (idx_t i = 0; i < column_ids.size(); i++) {\n+\t\tauto column_id = column_ids[i];\n+\t\tauto it = index_ids.find(column_id);\n \t\tif (it == index_ids.end()) {\n-\t\t\tfetch_ids.push_back(column_ids[column_id]);\n-\t\t\tfetch_types.push_back(children[1]->types[column_id]);\n+\t\t\tfetch_ids.push_back(column_id);\n+\t\t\tif (column_id == COLUMN_IDENTIFIER_ROW_ID) {\n+\t\t\t\tfetch_types.emplace_back(LogicalType::ROW_TYPE);\n+\t\t\t} else {\n+\t\t\t\tfetch_types.push_back(tbl_scan.returned_types[column_id]);\n+\t\t\t}\n \t\t}\n \t}\n \tif (right_projection_map.empty()) {\ndiff --git a/src/execution/physical_plan/plan_comparison_join.cpp b/src/execution/physical_plan/plan_comparison_join.cpp\nindex ac804d9f3e09..332f85a640f3 100644\n--- a/src/execution/physical_plan/plan_comparison_join.cpp\n+++ b/src/execution/physical_plan/plan_comparison_join.cpp\n@@ -152,30 +152,80 @@ static void CanUseIndexJoin(TableScanBindData *tbl, Expression &expr, Index **re\n \t});\n }\n \n-void TransformIndexJoin(ClientContext &context, LogicalComparisonJoin &op, Index **left_index, Index **right_index,\n-                        PhysicalOperator *left, PhysicalOperator *right) {\n+Index *CheckIndexJoin(ClientContext &context, LogicalComparisonJoin &op, PhysicalOperator &plan,\n+                      Expression &condition) {\n \tif (op.type == LogicalOperatorType::LOGICAL_DELIM_JOIN) {\n-\t\treturn;\n+\t\treturn nullptr;\n \t}\n \t// check if one of the tables has an index on column\n-\tif (op.join_type == JoinType::INNER && op.conditions.size() == 1) {\n-\t\t// check if one of the children are table scans and if they have an index in the join attribute\n-\t\t// (op.condition)\n-\t\tif (left->type == PhysicalOperatorType::TABLE_SCAN) {\n-\t\t\tauto &tbl_scan = (PhysicalTableScan &)*left;\n-\t\t\tauto tbl = dynamic_cast<TableScanBindData *>(tbl_scan.bind_data.get());\n-\t\t\tif (CanPlanIndexJoin(context, tbl, tbl_scan)) {\n-\t\t\t\tCanUseIndexJoin(tbl, *op.conditions[0].left, left_index);\n-\t\t\t}\n-\t\t}\n-\t\tif (right->type == PhysicalOperatorType::TABLE_SCAN) {\n-\t\t\tauto &tbl_scan = (PhysicalTableScan &)*right;\n-\t\t\tauto tbl = dynamic_cast<TableScanBindData *>(tbl_scan.bind_data.get());\n-\t\t\tif (CanPlanIndexJoin(context, tbl, tbl_scan)) {\n-\t\t\t\tCanUseIndexJoin(tbl, *op.conditions[0].right, right_index);\n-\t\t\t}\n-\t\t}\n+\tif (op.join_type != JoinType::INNER) {\n+\t\treturn nullptr;\n+\t}\n+\tif (op.conditions.size() != 1) {\n+\t\treturn nullptr;\n \t}\n+\t// check if the child is (1) a table scan, and (2) has an index on the join condition\n+\tif (plan.type != PhysicalOperatorType::TABLE_SCAN) {\n+\t\treturn nullptr;\n+\t}\n+\tauto &tbl_scan = (PhysicalTableScan &)plan;\n+\tauto tbl = dynamic_cast<TableScanBindData *>(tbl_scan.bind_data.get());\n+\tIndex *result = nullptr;\n+\tif (CanPlanIndexJoin(context, tbl, tbl_scan)) {\n+\t\tCanUseIndexJoin(tbl, condition, &result);\n+\t}\n+\treturn result;\n+}\n+\n+static bool PlanIndexJoin(ClientContext &context, LogicalComparisonJoin &op, unique_ptr<PhysicalOperator> &plan,\n+                          unique_ptr<PhysicalOperator> &left, unique_ptr<PhysicalOperator> &right, Index *index,\n+                          bool swap_condition = false) {\n+\tif (!index) {\n+\t\treturn false;\n+\t}\n+\t// index joins are not supported if there are pushed down table filters\n+\tD_ASSERT(right->type == PhysicalOperatorType::TABLE_SCAN);\n+\tauto &tbl_scan = (PhysicalTableScan &)*right;\n+\t//\tif (tbl_scan.table_filters && !tbl_scan.table_filters->filters.empty()) {\n+\t//\t\treturn false;\n+\t//\t}\n+\t// index joins are disabled if enable_optimizer is false\n+\tif (!ClientConfig::GetConfig(context).enable_optimizer) {\n+\t\treturn false;\n+\t}\n+\t// check if the cardinality difference justifies an index join\n+\tif (!((ClientConfig::GetConfig(context).force_index_join ||\n+\t       left->estimated_cardinality < 0.01 * right->estimated_cardinality))) {\n+\t\treturn false;\n+\t}\n+\n+\t// plan the index join\n+\tif (swap_condition) {\n+\t\tswap(op.conditions[0].left, op.conditions[0].right);\n+\t\tswap(op.left_projection_map, op.right_projection_map);\n+\t}\n+\tplan = make_unique<PhysicalIndexJoin>(op, std::move(left), std::move(right), std::move(op.conditions), op.join_type,\n+\t                                      op.left_projection_map, op.right_projection_map, tbl_scan.column_ids, index,\n+\t                                      !swap_condition, op.estimated_cardinality);\n+\treturn true;\n+}\n+\n+static bool PlanIndexJoin(ClientContext &context, LogicalComparisonJoin &op, unique_ptr<PhysicalOperator> &plan,\n+                          unique_ptr<PhysicalOperator> &left, unique_ptr<PhysicalOperator> &right) {\n+\tif (op.conditions.empty()) {\n+\t\treturn false;\n+\t}\n+\t// check if we can plan an index join on the RHS\n+\tauto right_index = CheckIndexJoin(context, op, *right, *op.conditions[0].right);\n+\tif (PlanIndexJoin(context, op, plan, left, right, right_index)) {\n+\t\treturn true;\n+\t}\n+\t// else check if we can plan an index join on the left side\n+\tauto left_index = CheckIndexJoin(context, op, *left, *op.conditions[0].left);\n+\tif (PlanIndexJoin(context, op, plan, right, left, left_index, true)) {\n+\t\treturn true;\n+\t}\n+\treturn false;\n }\n \n static void RewriteJoinCondition(Expression &expr, idx_t offset) {\n@@ -193,6 +243,8 @@ unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalComparison\n \tidx_t rhs_cardinality = op.children[1]->EstimateCardinality(context);\n \tauto left = CreatePlan(*op.children[0]);\n \tauto right = CreatePlan(*op.children[1]);\n+\tleft->estimated_cardinality = lhs_cardinality;\n+\tright->estimated_cardinality = rhs_cardinality;\n \tD_ASSERT(left && right);\n \n \tif (op.conditions.empty()) {\n@@ -227,22 +279,9 @@ unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalComparison\n \n \tunique_ptr<PhysicalOperator> plan;\n \tif (has_equality) {\n-\t\tIndex *left_index {}, *right_index {};\n-\t\tTransformIndexJoin(context, op, &left_index, &right_index, left.get(), right.get());\n-\t\tif (left_index &&\n-\t\t    (ClientConfig::GetConfig(context).force_index_join || rhs_cardinality < 0.01 * lhs_cardinality)) {\n-\t\t\tauto &tbl_scan = (PhysicalTableScan &)*left;\n-\t\t\tswap(op.conditions[0].left, op.conditions[0].right);\n-\t\t\treturn make_unique<PhysicalIndexJoin>(op, std::move(right), std::move(left), std::move(op.conditions),\n-\t\t\t                                      op.join_type, op.right_projection_map, op.left_projection_map,\n-\t\t\t                                      tbl_scan.column_ids, left_index, false, op.estimated_cardinality);\n-\t\t}\n-\t\tif (right_index &&\n-\t\t    (ClientConfig::GetConfig(context).force_index_join || lhs_cardinality < 0.01 * rhs_cardinality)) {\n-\t\t\tauto &tbl_scan = (PhysicalTableScan &)*right;\n-\t\t\treturn make_unique<PhysicalIndexJoin>(op, std::move(left), std::move(right), std::move(op.conditions),\n-\t\t\t                                      op.join_type, op.left_projection_map, op.right_projection_map,\n-\t\t\t                                      tbl_scan.column_ids, right_index, true, op.estimated_cardinality);\n+\t\t// check if we can use an index join\n+\t\tif (PlanIndexJoin(context, op, plan, left, right)) {\n+\t\t\treturn plan;\n \t\t}\n \t\t// Equality join with small number of keys : possible perfect join optimization\n \t\tPerfectHashJoinStats perfect_join_stats;\ndiff --git a/src/function/scalar/bit/bitstring.cpp b/src/function/scalar/bit/bitstring.cpp\nindex 456cc72fc444..e7996e59be03 100644\n--- a/src/function/scalar/bit/bitstring.cpp\n+++ b/src/function/scalar/bit/bitstring.cpp\n@@ -14,7 +14,7 @@ static void BitStringFunction(DataChunk &args, ExpressionState &state, Vector &r\n \t\t    if (n < 0) {\n \t\t\t    throw InvalidInputException(\"The bitstring length cannot be negative\");\n \t\t    }\n-\t\t    if ((idx_t)n < input.GetSize()) {\n+\t\t    if (idx_t(n) < input.GetSize()) {\n \t\t\t    throw InvalidInputException(\"Length must be equal or larger than input string\");\n \t\t    }\n \t\t    idx_t len;\n@@ -22,8 +22,8 @@ static void BitStringFunction(DataChunk &args, ExpressionState &state, Vector &r\n \n \t\t    len = Bit::ComputeBitstringLen(n);\n \t\t    string_t target = StringVector::EmptyString(result, len);\n-\n \t\t    Bit::BitString(input, n, target);\n+\t\t    target.Finalize();\n \t\t    return target;\n \t    });\n }\n@@ -68,7 +68,8 @@ static void SetBitOperation(DataChunk &args, ExpressionState &state, Vector &res\n \t\t\t                              NumericHelper::ToString(Bit::BitLength(input) - 1));\n \t\t    }\n \t\t    string_t target = StringVector::EmptyString(result, input.GetSize());\n-\t\t    Bit::SetBit(input, n, new_value, target);\n+\t\t    memcpy(target.GetDataWriteable(), input.GetDataUnsafe(), input.GetSize());\n+\t\t    Bit::SetBit(target, n, new_value);\n \t\t    return target;\n \t    });\n }\ndiff --git a/src/include/duckdb/common/types/bit.hpp b/src/include/duckdb/common/types/bit.hpp\nindex 5deff41239b3..a4b16e09fde8 100644\n--- a/src/include/duckdb/common/types/bit.hpp\n+++ b/src/include/duckdb/common/types/bit.hpp\n@@ -25,7 +25,6 @@ class Bit {\n \t//! Extracts the nth bit from bit string; the first (leftmost) bit is indexed 0\n \tDUCKDB_API static idx_t GetBit(string_t bit_string, idx_t n);\n \t//! Sets the nth bit in bit string to newvalue; the first (leftmost) bit is indexed 0\n-\tDUCKDB_API static void SetBit(const string_t &bit_string, idx_t n, idx_t new_value, string_t &result);\n \tDUCKDB_API static void SetBit(string_t &bit_string, idx_t n, idx_t new_value);\n \t//! Returns first starting index of the specified substring within bits, or zero if it's not present.\n \tDUCKDB_API static idx_t BitPosition(string_t substring, string_t bits);\n@@ -37,7 +36,7 @@ class Bit {\n \tDUCKDB_API static bool TryGetBitStringSize(string_t str, idx_t &result_size, string *error_message);\n \t//! Convert a string to a bit. This function should ONLY be called after calling GetBitSize, since it does NOT\n \t//! perform data validation.\n-\tDUCKDB_API static void ToBit(string_t str, data_ptr_t output);\n+\tDUCKDB_API static void ToBit(string_t str, string_t &output);\n \tDUCKDB_API static string ToBit(string_t str);\n \t//! Creates a new bitstring of determined length\n \tDUCKDB_API static void BitString(const string_t &input, const idx_t &len, string_t &result);\n@@ -52,10 +51,12 @@ class Bit {\n \tDUCKDB_API static void BitwiseXor(const string_t &rhs, const string_t &lhs, string_t &result);\n \tDUCKDB_API static void BitwiseNot(const string_t &rhs, string_t &result);\n \n+\tDUCKDB_API static void Verify(const string_t &input);\n+\n private:\n-\t//! Returns the amount of padded zeroes to fill up to a full byte. This information is stored in the first byte of\n-\t//! the bitstring.\n-\tDUCKDB_API static idx_t GetPadding(const string_t &bit_string);\n-\tDUCKDB_API static idx_t GetBitSize(string_t str);\n+\tstatic void Finalize(string_t &str);\n+\tstatic idx_t GetBitInternal(string_t bit_string, idx_t n);\n+\tstatic void SetBitInternal(string_t &bit_string, idx_t n, idx_t new_value);\n+\tstatic idx_t GetBitIndex(idx_t n);\n };\n } // namespace duckdb\ndiff --git a/src/include/duckdb/common/types/value_map.hpp b/src/include/duckdb/common/types/value_map.hpp\nindex 54dfec1119ff..dfe4d77de8d1 100644\n--- a/src/include/duckdb/common/types/value_map.hpp\n+++ b/src/include/duckdb/common/types/value_map.hpp\n@@ -1,7 +1,7 @@\n //===----------------------------------------------------------------------===//\n //                         DuckDB\n //\n-// duckdb/parser/value_map.hpp\n+// duckdb/common/types/value_map.hpp\n //\n //\n //===----------------------------------------------------------------------===//\n",
  "test_patch": "diff --git a/test/arrow_roundtrip/arrow_roundtrip.cpp b/test/arrow_roundtrip/arrow_roundtrip.cpp\nindex e3e5b5de0a3b..8195811666dd 100644\n--- a/test/arrow_roundtrip/arrow_roundtrip.cpp\n+++ b/test/arrow_roundtrip/arrow_roundtrip.cpp\n@@ -219,8 +219,8 @@ TEST_CASE(\"Test arrow roundtrip\", \"[arrow]\") {\n \t// FIXME: there seems to be a bug in the enum arrow reader in this test when run with vsize=2\n \treturn;\n #endif\n-\tTestArrowRoundtrip(\"SELECT * REPLACE \"\n-\t                   \"(interval (1) seconds AS interval) FROM test_all_types()\");\n+\tTestArrowRoundtrip(\"SELECT * EXCLUDE(bit) REPLACE \"\n+\t                   \"(interval (1) seconds AS interval, hugeint::DOUBLE as hugeint) FROM test_all_types()\");\n }\n \n TEST_CASE(\"Test Parquet Files round-trip\", \"[arrow][.]\") {\ndiff --git a/test/fuzzer/pedro/nan_as_seed.test b/test/fuzzer/pedro/nan_as_seed.test\nindex dbb446dc9949..c249040055bf 100644\n--- a/test/fuzzer/pedro/nan_as_seed.test\n+++ b/test/fuzzer/pedro/nan_as_seed.test\n@@ -2,9 +2,6 @@\n # description: Issue #4984 (42): Nan as seed\n # group: [pedro]\n \n-statement ok\n-pragma enable_verification\n-\n statement ok\n create table test as select range i from range(10000)\n \ndiff --git a/test/sql/index/art/index_join_pushdown.test b/test/sql/index/art/index_join_pushdown.test\nnew file mode 100644\nindex 000000000000..6d53a276cd40\n--- /dev/null\n+++ b/test/sql/index/art/index_join_pushdown.test\n@@ -0,0 +1,113 @@\n+# name: test/sql/index/art/index_join_pushdown.test\n+# description: Test index join\n+# group: [art]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+CREATE TABLE Person (name VARCHAR, phone HUGEINT, id bigint PRIMARY KEY, address VARCHAR, famous_percentage SMALLINT);\n+\n+statement ok\n+CREATE TABLE Person_knows_Person (Person1id bigint, Person2id bigint, relation VARCHAR);\n+\n+statement ok\n+INSERT INTO Person VALUES\n+   ('John', 123456789, 1, 'Canada', 100),\n+   ('Bill', 3754519434, 2, 'US', 80),\n+   ('Moss', 1189998819901197253, 3, 'UK', 50),\n+   ('Roy', 15, 4, 'UK', 40),\n+   ('Douglas Reynholm', 1, 5, 'UK', 20);\n+\n+statement ok\n+INSERT INTO Person_knows_Person VALUES\n+   (3, 4, 'Coworker'),\n+   (3, 5, 'Employee'),\n+   (4, 5, 'Employee'),\n+   (2, 5, 'Business Contact'),\n+   (1, 2, 'Secret Admirer');\n+\n+statement ok\n+PRAGMA force_index_join;\n+\n+query IIIIIIII nosort join_result\n+SELECT pkp.*, p1.*\n+FROM Person_knows_Person pkp\n+JOIN Person p1\n+  ON p1.id = pkp.Person1id\n+ORDER BY ALL\n+----\n+\n+# invert join condition\n+query IIIIIIII nosort join_result\n+SELECT pkp.*, p1.*\n+FROM Person_knows_Person pkp\n+JOIN Person p1\n+  ON pkp.Person1id = p1.id\n+ORDER BY ALL\n+----\n+\n+# swap sides\n+query IIIIIIII nosort join_result\n+SELECT pkp.*, p1.*\n+FROM Person p1\n+JOIN Person_knows_Person pkp\n+  ON p1.id = pkp.Person1id\n+ORDER BY ALL\n+----\n+\n+query IIIIIIII nosort join_result\n+SELECT pkp.*, p1.*\n+FROM Person p1\n+JOIN Person_knows_Person pkp\n+  ON pkp.Person1id = p1.id\n+ORDER BY ALL\n+----\n+\n+# now add filter pushdown\n+query IIIIIIII nosort pushdown\n+SELECT pkp.*, p1.*\n+FROM Person_knows_Person pkp\n+JOIN Person p1\n+  ON p1.id = pkp.Person1id\n+WHERE p1.phone >= 3754519434\n+ORDER BY ALL\n+----\n+\n+query IIIIIIII nosort pushdown\n+SELECT pkp.*, p1.*\n+FROM Person p1\n+JOIN Person_knows_Person pkp\n+  ON p1.id = pkp.Person1id\n+WHERE p1.phone >= 3754519434\n+ORDER BY ALL\n+----\n+\n+# strip the columns of p1\n+query II\n+SELECT p1.id, p1.name\n+FROM Person p1\n+JOIN Person_knows_Person pkp\n+  ON p1.id = pkp.Person1id\n+WHERE p1.phone >= 3754519434\n+ORDER BY ALL\n+----\n+2\tBill\n+3\tMoss\n+3\tMoss\n+\n+# multiple joins\n+query IIIII\n+SELECT p1.name, p2.name, pkp.relation, p1.famous_percentage, p2.famous_percentage\n+FROM Person_knows_Person pkp\n+JOIN Person p1\n+  ON p1.id = pkp.Person1id\n+JOIN Person p2\n+  ON p2.id = pkp.Person2id\n+ORDER BY ALL\n+----\n+Bill\tDouglas Reynholm\tBusiness Contact\t80\t20\n+John\tBill\tSecret Admirer\t100\t80\n+Moss\tDouglas Reynholm\tEmployee\t50\t20\n+Moss\tRoy\tCoworker\t50\t40\n+Roy\tDouglas Reynholm\tEmployee\t40\t20\ndiff --git a/test/sql/index/art/issue_6603_index_join.test b/test/sql/index/art/issue_6603_index_join.test\nnew file mode 100644\nindex 000000000000..69827af1f4ad\n--- /dev/null\n+++ b/test/sql/index/art/issue_6603_index_join.test\n@@ -0,0 +1,47 @@\n+# name: test/sql/index/art/issue_6603_index_join.test\n+# description: Test index join\n+# group: [art]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+BEGIN;\n+\n+statement ok\n+CREATE TABLE path (\n+    it  INTEGER,\n+    x0  TEXT NOT NULL,\n+    x1  TEXT NOT NULL\n+);\n+\n+statement ok\n+CREATE SEQUENCE seq;\n+\n+statement ok\n+CREATE TABLE edge (\n+  id  INTEGER DEFAULT nextval('seq'),\n+  it  INTEGER DEFAULT 0,\n+  x0  TEXT,\n+  x1  TEXT\n+);\n+\n+statement ok\n+CREATE INDEX edge1_idx ON edge (x1);\n+\n+statement ok\n+INSERT INTO edge (x0, x1) VALUES ('n2880','n3966');\n+\n+statement ok\n+COMMIT;\n+\n+statement ok\n+BEGIN;\n+\n+statement ok\n+INSERT INTO path SELECT 1, y0, y1 FROM (SELECT DISTINCT edge0.x0 AS y0, edge0.x1 AS y1 FROM edge AS edge0 WHERE edge0.it = 0 AND true AND NOT EXISTS (SELECT * from path AS pre WHERE pre.x0 = edge0.x0 AND pre.x1 = edge0.x1));\n+\n+query III\n+SELECT 1, y0, y1 FROM (SELECT DISTINCT edge0.x0 AS y0, path1.x1 AS y1 FROM edge AS edge0,path AS path1 WHERE edge0.it = 0 AND edge0.x1 = path1.x0 AND NOT EXISTS (SELECT * from path AS pre WHERE pre.x0 = edge0.x0 AND pre.x1 = path1.x1));\n+----\n+\ndiff --git a/test/sql/index/art/issue_6799_index_join.test b/test/sql/index/art/issue_6799_index_join.test\nnew file mode 100644\nindex 000000000000..d0f7764e7b53\n--- /dev/null\n+++ b/test/sql/index/art/issue_6799_index_join.test\n@@ -0,0 +1,35 @@\n+# name: test/sql/index/art/issue_6799_index_join.test\n+# description: Test index join\n+# group: [art]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+CREATE TABLE key_value_pairs (key VARCHAR PRIMARY KEY, value VARCHAR)\n+\n+statement ok\n+INSERT INTO key_value_pairs\n+\tSELECT concat('key_', i::VARCHAR), concat('value_', i::VARCHAR)\n+\tFROM range(10000) t(i)\n+\tWHERE random() < 0.5\n+\n+statement ok\n+CREATE TABLE keys_to_lookup (key VARCHAR PRIMARY KEY)\n+\n+statement ok\n+INSERT INTO keys_to_lookup\n+\tSELECT concat('key_', i::VARCHAR)\n+\tFROM range(100) t(i)\n+\n+statement ok\n+PRAGMA force_index_join\n+\n+statement ok\n+SELECT COUNT(*) FROM\n+(\n+\tSELECT key, value\n+\tFROM\n+\t\tkeys_to_lookup\n+\t\tJOIN key_value_pairs USING(key)\n+)\ndiff --git a/test/sql/types/bit/test_bit.test b/test/sql/types/bit/test_bit.test\nindex 6d7ae9a8a255..a64bb9be9796 100644\n--- a/test/sql/types/bit/test_bit.test\n+++ b/test/sql/types/bit/test_bit.test\n@@ -33,16 +33,32 @@ SELECT bitstring('1', 6);\n statement error\n SELECT bitstring('0101011', 3);\n ----\n-Invalid Input Error: Length must be equal or larger than input string\n+Length must be equal or larger than input string\n \n statement error\n-SELECT bitstring('', 6);\n+SELECT bitstring('', 0);\n+----\n+Cannot cast empty string to BIT\n+\n+query I\n+SELECT bitstring('1', 1);\n+----\n+1\n \n statement error\n SELECT bitstring('5', 10);\n+----\n+Invalid character encountered\n \n statement error\n SELECT bitstring('0101011');\n+----\n+No function matches\n+\n+query I\n+SELECT bitstring('0101011', 203);\n+----\n+00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000101011\n \n # insert valid bit strings\n statement ok\ndiff --git a/test/sql/types/bit/test_bit_equality.test b/test/sql/types/bit/test_bit_equality.test\nnew file mode 100644\nindex 000000000000..2e1dffa1023e\n--- /dev/null\n+++ b/test/sql/types/bit/test_bit_equality.test\n@@ -0,0 +1,11 @@\n+# name: test/sql/types/bit/test_bit_equality.test\n+# description: BIT equality\n+# group: [bit]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+query I\n+select bitstring('1', 6) from range(100000) group by 1;\n+----\n+000001\n",
  "problem_statement": "\"SELECT x FROM table1 JOIN table2(x)\" sometimes returns results that aren't in table2\n### What happens?\n\n`SELECT x FROM table1 JOIN table2(x)` sometimes returns results that aren't in `table2`.\r\n\r\nSpecifically, I can reproduce this when:\r\n1. The optimizer decides to do an INDEX_JOIN on `x`\r\n2. `x` is the only column being selected from the RHS table (`table2`)\r\n3. There are a significant number of results (e.g. tens of thousands)\n\n### To Reproduce\n\nThis Python script reproduces the issue for me:\r\n\r\n```python\r\nimport random\r\n\r\nimport duckdb\r\ndb = duckdb.connect(\":memory:\")\r\ndb.execute(\"PRAGMA force_index_join\")\r\n\r\n# Create a table with key-value pairs from 0...100k, but randomly omit 50% of them\r\n\r\nrandom.seed(42)\r\nkey_value_pairs = {\r\n    f\"key_{i}\": f\"value_{i}\"\r\n    for i in range(100000)\r\n    if random.random() < 0.5\r\n}\r\n\r\ndb.execute(\"CREATE TABLE key_value_pairs (key VARCHAR PRIMARY KEY, value VARCHAR)\")\r\ndb.execute(\r\n    \"INSERT INTO key_value_pairs VALUES \"\r\n    + \", \".join(f\"('{k}', '{v}')\" for k, v in key_value_pairs.items())\r\n)\r\n\r\n# Create a table with keys from 0...10k\r\n\r\nkeys_to_lookup = [\r\n    f\"key_{i}\"\r\n    for i in range(10000)\r\n]\r\n\r\ndb.execute(\"CREATE TABLE keys_to_lookup (key VARCHAR PRIMARY KEY)\")\r\ndb.execute(\r\n    \"INSERT INTO keys_to_lookup VALUES \"\r\n    + \", \".join(f\"('{k}')\" for k in keys_to_lookup)\r\n)\r\n\r\n# When we join these tables, we expect to find approximately half of the keys in the range 0...9999\r\n\r\nexpected_results = [\r\n    key\r\n    for key in keys_to_lookup\r\n    if key in key_value_pairs\r\n]\r\nprint(f\"{len(expected_results)=}\")\r\n\r\n# A join that returns the \"value\" column works as expected\r\n    \r\nresults_1 = db.execute(\r\n    \"\"\"\r\n    SELECT key, value\r\n    FROM\r\n        keys_to_lookup\r\n        JOIN key_value_pairs USING(key)\r\n    \"\"\"\r\n).fetchall()\r\n\r\n# This works as expected; len(results_1) == len(expected_results)\r\nprint(f\"{len(results_1)=}\")\r\nfor (key, value) in results_1:\r\n    assert key in key_value_pairs\r\n\r\n# But a join that omits \"value\" returns keys that aren't present in key_value_pairs!\r\n\r\nresults_2 = db.execute(\r\n    \"\"\"\r\n    SELECT key\r\n    FROM\r\n        keys_to_lookup\r\n        JOIN key_value_pairs USING(key)\r\n    \"\"\"\r\n).fetchall()\r\n\r\n# This does _not_ work as expected; len(results_2) > len(expected_results), and the assertion fails\r\nprint(f\"{len(results_2)=}\")\r\nfor (key,) in results_2:\r\n    assert key in key_value_pairs\r\n```\r\n\r\nI looked at the DuckDB implementation, and I _think_ I might see what the bug is. DuckDB takes a different code path depending on whether any non-index columns are being fetched from the RHS table or not: https://github.com/duckdb/duckdb/blob/v0.6.1/src/execution/operator/join/physical_index_join.cpp#L167 Specifically, in the \"no non-index columns\" case, we call `SearchEqualJoinNoFetch`. But if no leaf is found, `SearchEqualJoinNoFetch` returns without modifying `result_size`. And AFAICT, `physical_index_join.cpp` is re-using the `result_sizes` array from batch to batch, without zeroing it between batches. So we'll carry over the value of `result_size` from the last batch. If the last batch found a match at this index, then the current batch will act as though it found at match, even if it didn't.\r\n\r\n(Admittedly, I'm very unfamiliar with the DuckDB codebase, and I could have easily misunderstood something!)\n\n### OS:\n\nMacOS 13.2.1 (M1 Pro)\n\n### DuckDB Version:\n\n0.7.2-dev899\n\n### DuckDB Client:\n\nPython\n\n### Full Name:\n\nTim Maxwell\n\n### Affiliation:\n\nAnthropic\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\n\"SELECT x FROM table1 JOIN table2(x)\" sometimes returns results that aren't in table2\n### What happens?\n\n`SELECT x FROM table1 JOIN table2(x)` sometimes returns results that aren't in `table2`.\r\n\r\nSpecifically, I can reproduce this when:\r\n1. The optimizer decides to do an INDEX_JOIN on `x`\r\n2. `x` is the only column being selected from the RHS table (`table2`)\r\n3. There are a significant number of results (e.g. tens of thousands)\n\n### To Reproduce\n\nThis Python script reproduces the issue for me:\r\n\r\n```python\r\nimport random\r\n\r\nimport duckdb\r\ndb = duckdb.connect(\":memory:\")\r\ndb.execute(\"PRAGMA force_index_join\")\r\n\r\n# Create a table with key-value pairs from 0...100k, but randomly omit 50% of them\r\n\r\nrandom.seed(42)\r\nkey_value_pairs = {\r\n    f\"key_{i}\": f\"value_{i}\"\r\n    for i in range(100000)\r\n    if random.random() < 0.5\r\n}\r\n\r\ndb.execute(\"CREATE TABLE key_value_pairs (key VARCHAR PRIMARY KEY, value VARCHAR)\")\r\ndb.execute(\r\n    \"INSERT INTO key_value_pairs VALUES \"\r\n    + \", \".join(f\"('{k}', '{v}')\" for k, v in key_value_pairs.items())\r\n)\r\n\r\n# Create a table with keys from 0...10k\r\n\r\nkeys_to_lookup = [\r\n    f\"key_{i}\"\r\n    for i in range(10000)\r\n]\r\n\r\ndb.execute(\"CREATE TABLE keys_to_lookup (key VARCHAR PRIMARY KEY)\")\r\ndb.execute(\r\n    \"INSERT INTO keys_to_lookup VALUES \"\r\n    + \", \".join(f\"('{k}')\" for k in keys_to_lookup)\r\n)\r\n\r\n# When we join these tables, we expect to find approximately half of the keys in the range 0...9999\r\n\r\nexpected_results = [\r\n    key\r\n    for key in keys_to_lookup\r\n    if key in key_value_pairs\r\n]\r\nprint(f\"{len(expected_results)=}\")\r\n\r\n# A join that returns the \"value\" column works as expected\r\n    \r\nresults_1 = db.execute(\r\n    \"\"\"\r\n    SELECT key, value\r\n    FROM\r\n        keys_to_lookup\r\n        JOIN key_value_pairs USING(key)\r\n    \"\"\"\r\n).fetchall()\r\n\r\n# This works as expected; len(results_1) == len(expected_results)\r\nprint(f\"{len(results_1)=}\")\r\nfor (key, value) in results_1:\r\n    assert key in key_value_pairs\r\n\r\n# But a join that omits \"value\" returns keys that aren't present in key_value_pairs!\r\n\r\nresults_2 = db.execute(\r\n    \"\"\"\r\n    SELECT key\r\n    FROM\r\n        keys_to_lookup\r\n        JOIN key_value_pairs USING(key)\r\n    \"\"\"\r\n).fetchall()\r\n\r\n# This does _not_ work as expected; len(results_2) > len(expected_results), and the assertion fails\r\nprint(f\"{len(results_2)=}\")\r\nfor (key,) in results_2:\r\n    assert key in key_value_pairs\r\n```\r\n\r\nI looked at the DuckDB implementation, and I _think_ I might see what the bug is. DuckDB takes a different code path depending on whether any non-index columns are being fetched from the RHS table or not: https://github.com/duckdb/duckdb/blob/v0.6.1/src/execution/operator/join/physical_index_join.cpp#L167 Specifically, in the \"no non-index columns\" case, we call `SearchEqualJoinNoFetch`. But if no leaf is found, `SearchEqualJoinNoFetch` returns without modifying `result_size`. And AFAICT, `physical_index_join.cpp` is re-using the `result_sizes` array from batch to batch, without zeroing it between batches. So we'll carry over the value of `result_size` from the last batch. If the last batch found a match at this index, then the current batch will act as though it found at match, even if it didn't.\r\n\r\n(Admittedly, I'm very unfamiliar with the DuckDB codebase, and I could have easily misunderstood something!)\n\n### OS:\n\nMacOS 13.2.1 (M1 Pro)\n\n### DuckDB Version:\n\n0.7.2-dev899\n\n### DuckDB Client:\n\nPython\n\n### Full Name:\n\nTim Maxwell\n\n### Affiliation:\n\nAnthropic\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\n",
  "hints_text": "Interesting behavior:\r\n- Without primary keys, everything indeed runs perfectly as expected: results_1 and results_2 contain only the expected values.\r\n- With only a primary key on keys_to_lookup, but not key_value_pairs, results_1 and results_2 are both invalid... they contain all the values from key_value_pairs. \r\n- And, with primary keys on both keys_to_lookup and key_value_pairs, only results_2 is invalid\r\n\r\nIncidentally, it doesn't matter if you rewrite to a JOIN ON syntax vs JOIN USING, or use an \"int\" key type. \n@paultiq Interesting. I _think_ I understand what causes each of those three cases:\r\n* Without primary keys, I'm guessing the database does a HASH_JOIN instead of INDEX_JOIN; I hypothesize that the bug is only in INDEX_JOIN.\r\n* With only a primary key on `keys_to_lookup`, I'm guessing the optimizer chooses `key_value_pairs` as the \"LHS\" of the join and `keys_to_lookup` as the \"RHS\". The bug occurs when the index used for the join covers all of the columns we're selecting from the RHS. The only column in `keys_to_lookup` is `key`, which is the index we're joining on; so if `keys_to_lookup` is the RHS, then the bug always occurs.\r\n* With primary keys on both tables, I'm guessing the optimizer chooses `key_value_pairs` as the RHS. So the bug is triggered when we `SELECT keys`, but not when we `SELECT keys, values`, because `values` is not covered by the index used for the join.\r\n\r\nDoes that sound plausible?\r\n\r\n(Also, did you see my note above about the potential bug in `SearchEqualJoinNoFetch`?)\nInteresting behavior:\r\n- Without primary keys, everything indeed runs perfectly as expected: results_1 and results_2 contain only the expected values.\r\n- With only a primary key on keys_to_lookup, but not key_value_pairs, results_1 and results_2 are both invalid... they contain all the values from key_value_pairs. \r\n- And, with primary keys on both keys_to_lookup and key_value_pairs, only results_2 is invalid\r\n\r\nIncidentally, it doesn't matter if you rewrite to a JOIN ON syntax vs JOIN USING, or use an \"int\" key type. \n@paultiq Interesting. I _think_ I understand what causes each of those three cases:\r\n* Without primary keys, I'm guessing the database does a HASH_JOIN instead of INDEX_JOIN; I hypothesize that the bug is only in INDEX_JOIN.\r\n* With only a primary key on `keys_to_lookup`, I'm guessing the optimizer chooses `key_value_pairs` as the \"LHS\" of the join and `keys_to_lookup` as the \"RHS\". The bug occurs when the index used for the join covers all of the columns we're selecting from the RHS. The only column in `keys_to_lookup` is `key`, which is the index we're joining on; so if `keys_to_lookup` is the RHS, then the bug always occurs.\r\n* With primary keys on both tables, I'm guessing the optimizer chooses `key_value_pairs` as the RHS. So the bug is triggered when we `SELECT keys`, but not when we `SELECT keys, values`, because `values` is not covered by the index used for the join.\r\n\r\nDoes that sound plausible?\r\n\r\n(Also, did you see my note above about the potential bug in `SearchEqualJoinNoFetch`?)",
  "created_at": "2023-03-21T11:30:02Z"
}