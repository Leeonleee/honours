{
  "repo": "duckdb/duckdb",
  "pull_number": 5382,
  "instance_id": "duckdb__duckdb-5382",
  "issue_numbers": [
    "5342"
  ],
  "base_commit": "0f0461113f3341135471805c9928c4d71d1f5874",
  "patch": "diff --git a/extension/icu/icu-datepart.cpp b/extension/icu/icu-datepart.cpp\nindex 9b85d128ab31..4931ebac6af8 100644\n--- a/extension/icu/icu-datepart.cpp\n+++ b/extension/icu/icu-datepart.cpp\n@@ -329,24 +329,24 @@ struct ICUDatePart : public ICUDateFunc {\n \t\t\tfor (idx_t i = 0; i < count; ++i) {\n \t\t\t\tconst auto idx = rdata.sel->get_index(i);\n \t\t\t\tif (arg_valid.RowIsValid(idx)) {\n-\t\t\t\t\tres_valid.SetValid(idx);\n+\t\t\t\t\tres_valid.SetValid(i);\n \t\t\t\t\tauto micros = SetTime(calendar, tdata[idx]);\n \t\t\t\t\tconst auto is_finite = Timestamp::IsFinite(tdata[idx]);\n \t\t\t\t\tfor (size_t col = 0; col < child_entries.size(); ++col) {\n \t\t\t\t\t\tauto &child_entry = child_entries[col];\n \t\t\t\t\t\tif (is_finite) {\n-\t\t\t\t\t\t\tFlatVector::Validity(*child_entry).SetValid(idx);\n+\t\t\t\t\t\t\tFlatVector::Validity(*child_entry).SetValid(i);\n \t\t\t\t\t\t\tauto pdata = FlatVector::GetData<int64_t>(*child_entry);\n \t\t\t\t\t\t\tauto adapter = info.adapters[col];\n-\t\t\t\t\t\t\tpdata[idx] = adapter(calendar, micros);\n+\t\t\t\t\t\t\tpdata[i] = adapter(calendar, micros);\n \t\t\t\t\t\t} else {\n-\t\t\t\t\t\t\tFlatVector::Validity(*child_entry).SetInvalid(idx);\n+\t\t\t\t\t\t\tFlatVector::Validity(*child_entry).SetInvalid(i);\n \t\t\t\t\t\t}\n \t\t\t\t\t}\n \t\t\t\t} else {\n-\t\t\t\t\tres_valid.SetInvalid(idx);\n+\t\t\t\t\tres_valid.SetInvalid(i);\n \t\t\t\t\tfor (auto &child_entry : child_entries) {\n-\t\t\t\t\t\tFlatVector::Validity(*child_entry).SetInvalid(idx);\n+\t\t\t\t\t\tFlatVector::Validity(*child_entry).SetInvalid(i);\n \t\t\t\t\t}\n \t\t\t\t}\n \t\t\t}\ndiff --git a/src/function/scalar/date/date_part.cpp b/src/function/scalar/date/date_part.cpp\nindex c400fc72f863..4f5fd859679c 100644\n--- a/src/function/scalar/date/date_part.cpp\n+++ b/src/function/scalar/date/date_part.cpp\n@@ -1420,16 +1420,16 @@ struct StructDatePart {\n \t\t\t\tconst auto idx = rdata.sel->get_index(i);\n \t\t\t\tif (arg_valid.RowIsValid(idx)) {\n \t\t\t\t\tif (Value::IsFinite(tdata[idx])) {\n-\t\t\t\t\t\tDatePart::StructOperator::Operation(part_values.data(), tdata[idx], idx, part_mask);\n+\t\t\t\t\t\tDatePart::StructOperator::Operation(part_values.data(), tdata[idx], i, part_mask);\n \t\t\t\t\t} else {\n \t\t\t\t\t\tfor (auto &child_entry : child_entries) {\n-\t\t\t\t\t\t\tFlatVector::Validity(*child_entry).SetInvalid(idx);\n+\t\t\t\t\t\t\tFlatVector::Validity(*child_entry).SetInvalid(i);\n \t\t\t\t\t\t}\n \t\t\t\t\t}\n \t\t\t\t} else {\n-\t\t\t\t\tres_valid.SetInvalid(idx);\n+\t\t\t\t\tres_valid.SetInvalid(i);\n \t\t\t\t\tfor (auto &child_entry : child_entries) {\n-\t\t\t\t\t\tFlatVector::Validity(*child_entry).SetInvalid(idx);\n+\t\t\t\t\t\tFlatVector::Validity(*child_entry).SetInvalid(i);\n \t\t\t\t\t}\n \t\t\t\t}\n \t\t\t}\n",
  "test_patch": "diff --git a/test/sql/copy/csv/auto/test_csv_auto.test b/test/sql/copy/csv/auto/test_csv_auto.test\nindex 21618919091c..ba6e19e7ff42 100644\n--- a/test/sql/copy/csv/auto/test_csv_auto.test\n+++ b/test/sql/copy/csv/auto/test_csv_auto.test\n@@ -6,7 +6,7 @@ require vector_size 512\n \n \n statement ok\n-SET experimental_parallel_csv=true;\n+SET experimental_parallel_csv=false;\n \n \n # CSV file with RFC-conform dialect\n@@ -230,4 +230,4 @@ SELECT a, b FROM test;\n 1\t2\n \n statement ok\n-DROP TABLE test;\n\\ No newline at end of file\n+DROP TABLE test;\ndiff --git a/test/sql/function/date/test_date_part.test b/test/sql/function/date/test_date_part.test\nindex d35b7b62d019..7f8f90af1890 100644\n--- a/test/sql/function/date/test_date_part.test\n+++ b/test/sql/function/date/test_date_part.test\n@@ -455,6 +455,15 @@ NULL\tNULL\n 2022-01-01\t{'isoyear': 2021, 'week': 52, 'yearweek': 202152}\n infinity\t{'isoyear': NULL, 'week': NULL, 'yearweek': NULL}\n \n+# Selective filtering (Issue #5342)\n+query II\n+SELECT d, DATE_PART(['year', 'month', 'day'], d) AS parts\n+FROM dates\n+WHERE s = 'day'\n+ORDER BY 1;\n+----\n+1992-05-05\t{'year': 1992, 'month': 5, 'day': 5}\n+\n # Invalid parts\n \n foreach hour minute second millisecond microsecond timezone timezone_hour timezone_minute\ndiff --git a/test/sql/function/timestamp/test_icu_datepart.test b/test/sql/function/timestamp/test_icu_datepart.test\nindex 71fce4c4281c..aa34c7e6b961 100644\n--- a/test/sql/function/timestamp/test_icu_datepart.test\n+++ b/test/sql/function/timestamp/test_icu_datepart.test\n@@ -628,6 +628,15 @@ WHERE p IS DISTINCT FROM s['${partcode}'];\n \n endloop\n \n+# Selective filtering (Issue #5342)\n+query II\n+SELECT ts, DATE_PART(['year', 'month', 'day'], ts) AS parts\n+FROM timestamps\n+WHERE part = 'day'\n+ORDER BY 1;\n+----\n+2021-12-24 14:00:00-08\t{'year': 2021, 'month': 12, 'day': 24}\n+\n # Invalid parts\n statement error\n SELECT DATE_PART(['duck', 'minute', 'microsecond', 'timezone'], ts), ts\n",
  "problem_statement": "Strange error with make_date/date_part on large dataset\n### What happens?\n\nWe've encountered a strange bug on a specific query over a large sample dataset. With a certain set of filters we are encountering an error evaluating `make_date(date_part(['year', 'month', 'day'], \"timestamtz_column\"))`, which we use as a workaround to convert `timestamptz` columns to `date`s while respecting the configured `TimeZone`.\r\n\r\nI don't have a very good sense for what specifically might be triggering the issue. We ran into it accidentally and the repro presented here is isolated from that test case but isn't particularly minimal (exported as a ~2m row parquet file). But I don't believe it is a case of bad/corrupt input data because as shown in the repro steps we can successfully execute a couple of similar queries that seemingly should hit the same case if it were down to a bad row.\n\n### To Reproduce\n\nTo make things easier I have created a [little git repo](https://github.com/dylanscott/duckdb-repro) containing the parquet file and code to repro, as well as a couple of scripts to setup a virtualenv with the required dependencies and run the repro in it. I've tested this case with DuckDB 0.5.1, the new 0.6 release, and the latest master branch for good measure. The `repro.py` case contains the following:\r\n\r\nFirst we read the contents of the parquet file with pandas and register it with DuckDB:\r\n\r\n```python\r\nimport duckdb\r\nimport pandas\r\n\r\nconn = duckdb.connect(database=':memory:')\r\n\r\nrepro_df = pandas.read_parquet('repro.parquet', engine='fastparquet')\r\nconn.register('repro', repro_df)\r\n```\r\n\r\nThen we run a couple of queries that intend to show that this is a bug and not an issue with the input data. First we show that we can successfully run that `timestamptz` -> `date` conversion code for all rows in the dataset:\r\n\r\n```python\r\nall_converted_df = conn.execute(\"\"\"\r\nselect make_date(date_part(['year', 'month', 'day'], \"ACTUAL_DATE\")) as \"ACTUAL_DATE\" from repro\r\n\"\"\").df()\r\n```\r\n\r\nThe 2nd query gets closer to the erroring query - moving the date conversion into the where clause and filtering by the `FLAG` column, but this one still succeeds:\r\n\r\n```python\r\nless_filtered_df = conn.execute(\"\"\"\r\nselect * from repro\r\nwhere \"FLAG\" = true\r\n      AND make_date(date_part(['year', 'month', 'day'], \"ACTUAL_DATE\")) >= '2021-01-01'\r\n\"\"\").df()\r\n```\r\n\r\nFinally we add a filter on the `HASH` column, which should run on a subset of the rows from the previous query but for some reason now hits an error:\r\n\r\n```python\r\nerroring_df = conn.execute(\"\"\"\r\nselect * from repro\r\nwhere \"FLAG\" = true\r\n      AND \"HASH\" = 'be763d263e00fe8a7c1e37ef441c5519'\r\n      AND make_date(date_part(['year', 'month', 'day'], \"ACTUAL_DATE\")) >= '2021-01-01'\r\n\"\"\").df()\r\n```\r\n\r\n```\r\nduckdb.ConversionException: Conversion Error: Date out of range: 0-0-0\r\n```\r\n\r\nFrom grepping the DuckDB codebase it seems like that error is coming from the `make_date` call and indicates that it's getting zeros for year/month/day, even though it doesn't seem to be in the other queries. Weird!\r\n\r\nAlso this may or may not be useful but here are a few things I encountered while isolating this repro that seemed interesting:\r\n\r\n- Selecting directly from the parquet file rather than reading with Pandas and registering doesn't repro the issue.\r\n  - The main difference I could see is I think `ACTUAL_DATE` ends up as a `timestamp` (without time zone) when reading directly from the parquet file whereas Pandas reads it into a `datetime64[ns, UTC]` column which should map to `timestamptz` \r\n- I get the `Date out of range: 0-0-0` error when reproing on my M1 Mac, but I get different values in the error when we initially encountered the error in our app where the Python process is running in an x86-64 Linux VM. Specifically: `Date out of range: 1514828672-1514828656-1514828656`\r\n- The only existing issue I could find that seemed like it might be related was #2860 which also concerns a weird date conversion error manifesting on large datasets.\r\n  - Though the only comment said it looks like an issue with the optimizer and I tested with `pragma disable_optimizer;` and still hit the issue.\n\n### OS:\n\nmacOS, Linux\n\n### DuckDB Version:\n\n0.6, 0.5.1\n\n### DuckDB Client:\n\nPython\n\n### Full Name:\n\nDylan Scott\n\n### Affiliation:\n\nHex Technologies\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\n",
  "hints_text": "Thanks for making the reproducible example. I am getting the same error here. To me this looks like this is going wrong in date_part. I was able to remove Python from the example using the Parquet file you provided:\r\n\r\n```SQL\r\nCREATE TABLE test5342 as from 'repro.parquet';\r\nSELECT ACTUAL_DATE, date_part(['year', 'month', 'day'], ACTUAL_DATE) date_part from test5342\r\nwhere HASH = 'be763d263e00fe8a7c1e37ef441c5519' limit 10;\r\n```\r\n\r\n```\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502     ACTUAL_DATE     \u2502                   date_part                   \u2502\r\n\u2502      timestamp      \u2502 struct(year bigint, month bigint, day bigint) \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 2020-12-13 00:00:00 \u2502 {'year': 0, 'month': 0, 'day': 0}             \u2502\r\n\u2502 2020-12-14 00:00:00 \u2502 {'year': 0, 'month': 0, 'day': 0}             \u2502\r\n\u2502 2020-12-15 00:00:00 \u2502 {'year': 0, 'month': 0, 'day': 0}             \u2502\r\n\u2502 2020-12-16 00:00:00 \u2502 {'year': 226, 'month': 226, 'day': 226}       \u2502\r\n\u2502 2020-12-17 00:00:00 \u2502 {'year': 0, 'month': 0, 'day': 0}             \u2502\r\n\u2502 2020-12-18 00:00:00 \u2502 {'year': 0, 'month': 0, 'day': 0}             \u2502\r\n\u2502 2020-12-19 00:00:00 \u2502 {'year': 0, 'month': 0, 'day': 0}             \u2502\r\n\u2502 2020-12-20 00:00:00 \u2502 {'year': 0, 'month': 0, 'day': 0}             \u2502\r\n\u2502 2020-12-21 00:00:00 \u2502 {'year': 0, 'month': 0, 'day': 0}             \u2502\r\n\u2502 2020-12-22 00:00:00 \u2502 {'year': 0, 'month': 0, 'day': 0}             \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 10 rows                                                   2 columns \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\nThis looks related to the list parameter/struct out feature of `date_part`, separate calls to e.g. `date_part('day', ACTUAL_DATE)` work fine\nMaybe @hawkfish can have a look?\nHmm doesn't repro if I just create a table with the TS values.\nLooks like a constant vs flat size 1 issue. The filter usually produces only 1 value in a block.\nOutput indexing confusion. This will happen whenever there is a selective filter.\nAlso busted in ICU.",
  "created_at": "2022-11-16T23:04:02Z"
}