{
  "repo": "duckdb/duckdb",
  "pull_number": 6326,
  "instance_id": "duckdb__duckdb-6326",
  "issue_numbers": [
    "6315",
    "6315"
  ],
  "base_commit": "eb65c593fee1f1f302d279110ec0a95b322e0e8c",
  "patch": "diff --git a/tools/pythonpkg/duckdb_python.cpp b/tools/pythonpkg/duckdb_python.cpp\nindex 41bc4d4672ef..27663aeffcdb 100644\n--- a/tools/pythonpkg/duckdb_python.cpp\n+++ b/tools/pythonpkg/duckdb_python.cpp\n@@ -58,7 +58,7 @@ static py::list PyTokenize(const string &query) {\n \t\t}\n \t\tresult.append(tuple);\n \t}\n-\treturn std::move(result);\n+\treturn result;\n }\n \n static void InitializeConnectionMethods(py::module_ &m) {\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/pyrelation.hpp b/tools/pythonpkg/src/include/duckdb_python/pyrelation.hpp\nindex c1a0d8f68cb3..bf5cb72da553 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/pyrelation.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/pyrelation.hpp\n@@ -43,8 +43,6 @@ struct DuckDBPyRelation {\n \texplicit DuckDBPyRelation(shared_ptr<Relation> rel);\n \texplicit DuckDBPyRelation(unique_ptr<DuckDBPyResult> result);\n \n-\tshared_ptr<Relation> rel;\n-\n public:\n \tstatic void Initialize(py::handle &m);\n \n@@ -244,6 +242,8 @@ struct DuckDBPyRelation {\n \n \tstatic bool IsRelation(const py::object &object);\n \n+\tRelation &GetRel();\n+\n private:\n \tstring GenerateExpressionList(const string &function_name, const string &aggregated_columns,\n \t                              const string &groups = \"\", const string &function_parameter = \"\",\n@@ -258,6 +258,9 @@ struct DuckDBPyRelation {\n \tunique_ptr<QueryResult> ExecuteInternal();\n \n private:\n+\tshared_ptr<Relation> rel;\n+\tvector<LogicalType> types;\n+\tvector<string> names;\n \tunique_ptr<DuckDBPyResult> result;\n \tstd::string rendered_result;\n };\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/pyresult.hpp b/tools/pythonpkg/src/include/duckdb_python/pyresult.hpp\nindex 241360a1293a..e03c8eb43db7 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/pyresult.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/pyresult.hpp\n@@ -17,18 +17,7 @@ namespace duckdb {\n \n struct DuckDBPyResult {\n public:\n-\tidx_t chunk_offset = 0;\n-\n-\tunique_ptr<QueryResult> result;\n-\tunique_ptr<DataChunk> current_chunk;\n-\t// Holds the categories of Categorical/ENUM types\n-\tunordered_map<idx_t, py::list> categories;\n-\t// Holds the categorical type of Categorical/ENUM types\n-\tunordered_map<idx_t, py::object> categories_type;\n-\n-\tstring timezone_config;\n-\n-\texplicit DuckDBPyResult() {};\n+\texplicit DuckDBPyResult(unique_ptr<QueryResult> result);\n \n public:\n \tOptional<py::tuple> Fetchone();\n@@ -50,12 +39,16 @@ struct DuckDBPyResult {\n \tduckdb::pyarrow::RecordBatchReader FetchRecordBatchReader(idx_t chunk_size);\n \n \tstatic py::list GetDescription(const vector<string> &names, const vector<LogicalType> &types);\n-\tpy::list Description();\n \n \tvoid Close();\n \n \tbool IsClosed() const;\n \n+\tunique_ptr<DataChunk> FetchChunk();\n+\n+\tconst vector<string> &GetNames();\n+\tconst vector<LogicalType> &GetTypes();\n+\n private:\n \tvoid FillNumpy(py::dict &res, idx_t col_idx, NumpyResultConversion &conversion, const char *name);\n \n@@ -71,6 +64,17 @@ struct DuckDBPyResult {\n \tunique_ptr<DataChunk> FetchNextRaw(QueryResult &result);\n \n private:\n+\tidx_t chunk_offset = 0;\n+\n+\tunique_ptr<QueryResult> result;\n+\tunique_ptr<DataChunk> current_chunk;\n+\t// Holds the categories of Categorical/ENUM types\n+\tunordered_map<idx_t, py::list> categories;\n+\t// Holds the categorical type of Categorical/ENUM types\n+\tunordered_map<idx_t, py::object> categories_type;\n+\n+\tstring timezone_config;\n+\n \tbool result_closed = false;\n };\n \ndiff --git a/tools/pythonpkg/src/pyconnection.cpp b/tools/pythonpkg/src/pyconnection.cpp\nindex 4303c4f82323..7566a7d03e28 100644\n--- a/tools/pythonpkg/src/pyconnection.cpp\n+++ b/tools/pythonpkg/src/pyconnection.cpp\n@@ -397,8 +397,7 @@ unique_ptr<QueryResult> DuckDBPyConnection::ExecuteInternal(const string &query,\n shared_ptr<DuckDBPyConnection> DuckDBPyConnection::Execute(const string &query, py::object params, bool many) {\n \tauto res = ExecuteInternal(query, std::move(params), many);\n \tif (res) {\n-\t\tauto py_result = make_unique<DuckDBPyResult>();\n-\t\tpy_result->result = std::move(res);\n+\t\tauto py_result = make_unique<DuckDBPyResult>(std::move(res));\n \t\tresult = make_unique<DuckDBPyRelation>(std::move(py_result));\n \t}\n \treturn shared_from_this();\n@@ -828,10 +827,10 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromDF(const DataFrame &value)\n \tauto new_df = PandasScanFunction::PandasReplaceCopiedNames(value);\n \tvector<Value> params;\n \tparams.emplace_back(Value::POINTER((uintptr_t)new_df.ptr()));\n-\tauto rel = make_unique<DuckDBPyRelation>(connection->TableFunction(\"pandas_scan\", params)->Alias(name));\n-\trel->rel->extra_dependencies =\n+\tauto rel = connection->TableFunction(\"pandas_scan\", params)->Alias(name);\n+\trel->extra_dependencies =\n \t    make_unique<PythonDependencies>(make_unique<RegisteredObject>(value), make_unique<RegisteredObject>(new_df));\n-\treturn rel;\n+\treturn make_unique<DuckDBPyRelation>(std::move(rel));\n }\n \n unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromParquet(const string &file_glob, bool binary_as_string,\n@@ -907,15 +906,14 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromArrow(py::object &arrow_obj\n \tauto stream_factory_produce = PythonTableArrowArrayStreamFactory::Produce;\n \tauto stream_factory_get_schema = PythonTableArrowArrayStreamFactory::GetSchema;\n \n-\tauto rel = make_unique<DuckDBPyRelation>(\n-\t    connection\n-\t        ->TableFunction(\"arrow_scan\", {Value::POINTER((uintptr_t)stream_factory.get()),\n-\t                                       Value::POINTER((uintptr_t)stream_factory_produce),\n-\t                                       Value::POINTER((uintptr_t)stream_factory_get_schema)})\n-\t        ->Alias(name));\n-\trel->rel->extra_dependencies =\n+\tauto rel = connection\n+\t               ->TableFunction(\"arrow_scan\", {Value::POINTER((uintptr_t)stream_factory.get()),\n+\t                                              Value::POINTER((uintptr_t)stream_factory_produce),\n+\t                                              Value::POINTER((uintptr_t)stream_factory_get_schema)})\n+\t               ->Alias(name);\n+\trel->extra_dependencies =\n \t    make_unique<PythonDependencies>(make_unique<RegisteredArrow>(std::move(stream_factory), arrow_object));\n-\treturn rel;\n+\treturn make_unique<DuckDBPyRelation>(std::move(rel));\n }\n \n unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromSubstrait(py::bytes &proto) {\n@@ -1128,7 +1126,7 @@ static unique_ptr<TableRef> TryReplacement(py::dict &dict, py::str &table_name,\n \t\tauto pyrel = py::cast<DuckDBPyRelation *>(entry);\n \t\t// create a subquery from the underlying relation object\n \t\tauto select = make_unique<SelectStatement>();\n-\t\tselect->node = pyrel->rel->GetQueryNode();\n+\t\tselect->node = pyrel->GetRel().GetQueryNode();\n \n \t\tauto subquery = make_unique<SubqueryRef>(std::move(select));\n \t\treturn std::move(subquery);\ndiff --git a/tools/pythonpkg/src/pyfilesystem.cpp b/tools/pythonpkg/src/pyfilesystem.cpp\nindex b81f15b9c542..670b32cc154b 100644\n--- a/tools/pythonpkg/src/pyfilesystem.cpp\n+++ b/tools/pythonpkg/src/pyfilesystem.cpp\n@@ -21,7 +21,6 @@ string PythonFilesystem::DecodeFlags(uint8_t flags) {\n \tbool write = flags & FileFlags::FILE_FLAGS_WRITE;\n \tbool append = flags & FileFlags::FILE_FLAGS_APPEND;\n \tbool truncate = flags & FileFlags::FILE_FLAGS_FILE_CREATE_NEW;\n-\tbool create = flags & FileFlags::FILE_FLAGS_FILE_CREATE;\n \n \tstring flags_s;\n \tif (read && write && truncate) {\ndiff --git a/tools/pythonpkg/src/pyrelation.cpp b/tools/pythonpkg/src/pyrelation.cpp\nindex 7c4bc48beaa9..631e51d1d261 100644\n--- a/tools/pythonpkg/src/pyrelation.cpp\n+++ b/tools/pythonpkg/src/pyrelation.cpp\n@@ -14,10 +14,23 @@\n \n namespace duckdb {\n \n-DuckDBPyRelation::DuckDBPyRelation(shared_ptr<Relation> rel) : rel(std::move(rel)) {\n+DuckDBPyRelation::DuckDBPyRelation(shared_ptr<Relation> rel_p) : rel(std::move(rel_p)) {\n+\tif (!rel) {\n+\t\tthrow InternalException(\"DuckDBPyRelation created without a relation\");\n+\t}\n+\tauto &columns = rel->Columns();\n+\tfor (auto &col : columns) {\n+\t\tnames.push_back(col.GetName());\n+\t\ttypes.push_back(col.GetType());\n+\t}\n }\n \n-DuckDBPyRelation::DuckDBPyRelation(unique_ptr<DuckDBPyResult> result) : rel(nullptr), result(std::move(result)) {\n+DuckDBPyRelation::DuckDBPyRelation(unique_ptr<DuckDBPyResult> result_p) : rel(nullptr), result(std::move(result_p)) {\n+\tif (!result) {\n+\t\tthrow InternalException(\"DuckDBPyRelation created without a result\");\n+\t}\n+\tthis->types = result->GetTypes();\n+\tthis->names = result->GetNames();\n }\n \n unique_ptr<DuckDBPyRelation> DuckDBPyRelation::FromDf(const DataFrame &df, shared_ptr<DuckDBPyConnection> conn) {\n@@ -193,24 +206,20 @@ void DuckDBPyRelation::AssertRelation() const {\n }\n \n void DuckDBPyRelation::AssertResultOpen() const {\n-\tif (result && result->IsClosed()) {\n+\tif (!result || result->IsClosed()) {\n \t\tthrow InvalidInputException(\"No open result set\");\n \t}\n }\n \n py::list DuckDBPyRelation::Description() {\n-\tif (rel) {\n-\t\tauto &columns = rel->Columns();\n-\t\tvector<string> names;\n-\t\tvector<LogicalType> types;\n-\t\tfor (auto &col : columns) {\n-\t\t\tnames.push_back(col.GetName());\n-\t\t\ttypes.push_back(col.GetType());\n-\t\t}\n-\t\treturn DuckDBPyResult::GetDescription(names, types);\n+\treturn DuckDBPyResult::GetDescription(names, types);\n+}\n+\n+Relation &DuckDBPyRelation::GetRel() {\n+\tif (!rel) {\n+\t\tthrow InternalException(\"DuckDBPyRelation - calling GetRel, but no rel was present\");\n \t}\n-\tAssertResultOpen();\n-\treturn result->Description();\n+\treturn *rel;\n }\n \n struct DescribeAggregateInfo {\n@@ -391,9 +400,9 @@ unique_ptr<DuckDBPyRelation> DuckDBPyRelation::SEM(const string &aggr_columns, c\n idx_t DuckDBPyRelation::Length() {\n \tauto aggregate_rel = GenericAggregator(\"count\", \"*\");\n \taggregate_rel->Execute();\n-\tD_ASSERT(aggregate_rel->result && aggregate_rel->result->result);\n+\tD_ASSERT(aggregate_rel->result);\n \tauto tmp_res = std::move(aggregate_rel->result);\n-\treturn tmp_res->result->Fetch()->GetValue(0, 0).GetValue<idx_t>();\n+\treturn tmp_res->FetchChunk()->GetValue(0, 0).GetValue<idx_t>();\n }\n \n py::tuple DuckDBPyRelation::Shape() {\n@@ -466,15 +475,14 @@ unique_ptr<QueryResult> DuckDBPyRelation::ExecuteInternal() {\n }\n \n void DuckDBPyRelation::ExecuteOrThrow() {\n-\tauto tmp_result = make_unique<DuckDBPyResult>();\n-\ttmp_result->result = ExecuteInternal();\n-\tif (!tmp_result->result) {\n+\tauto query_result = ExecuteInternal();\n+\tif (!query_result) {\n \t\tthrow InternalException(\"ExecuteOrThrow - no query available to execute\");\n \t}\n-\tif (tmp_result->result->HasError()) {\n-\t\ttmp_result->result->ThrowError();\n+\tif (query_result->HasError()) {\n+\t\tquery_result->ThrowError();\n \t}\n-\tresult = std::move(tmp_result);\n+\tresult = make_unique<DuckDBPyResult>(std::move(query_result));\n }\n \n DataFrame DuckDBPyRelation::FetchDF(bool date_as_object) {\n@@ -531,7 +539,7 @@ py::list DuckDBPyRelation::FetchAll() {\n \t}\n \tauto res = result->Fetchall();\n \tresult = nullptr;\n-\treturn std::move(res);\n+\treturn res;\n }\n \n py::dict DuckDBPyRelation::FetchNumpy() {\n@@ -636,7 +644,7 @@ unique_ptr<DuckDBPyRelation> DuckDBPyRelation::Join(DuckDBPyRelation *other, con\n \t} else if (type_string == \"left\") {\n \t\tdtype = JoinType::LEFT;\n \t} else {\n-\t\tthrow InvalidInputException(\"Unsupported join type %s try 'inner' or 'left'\", type_string);\n+\t\tthrow InvalidInputException(\"Unsupported join type %s\t try 'inner' or 'left'\", type_string);\n \t}\n \treturn make_unique<DuckDBPyRelation>(rel->Join(other->rel, condition, dtype));\n }\ndiff --git a/tools/pythonpkg/src/pyresult.cpp b/tools/pythonpkg/src/pyresult.cpp\nindex f7cd0e4bba23..298c0ba6a53b 100644\n--- a/tools/pythonpkg/src/pyresult.cpp\n+++ b/tools/pythonpkg/src/pyresult.cpp\n@@ -17,6 +17,33 @@\n \n namespace duckdb {\n \n+DuckDBPyResult::DuckDBPyResult(unique_ptr<QueryResult> result_p) : result(std::move(result_p)) {\n+\tif (!result) {\n+\t\tthrow InternalException(\"PyResult created without a result object\");\n+\t}\n+}\n+\n+const vector<string> &DuckDBPyResult::GetNames() {\n+\tif (!result) {\n+\t\tthrow InternalException(\"Calling GetNames without a result object\");\n+\t}\n+\treturn result->names;\n+}\n+\n+const vector<LogicalType> &DuckDBPyResult::GetTypes() {\n+\tif (!result) {\n+\t\tthrow InternalException(\"Calling GetTypes without a result object\");\n+\t}\n+\treturn result->types;\n+}\n+\n+unique_ptr<DataChunk> DuckDBPyResult::FetchChunk() {\n+\tif (!result) {\n+\t\tthrow InternalException(\"FetchChunk called without a result object\");\n+\t}\n+\treturn FetchNext(*result);\n+}\n+\n unique_ptr<DataChunk> DuckDBPyResult::FetchNext(QueryResult &result) {\n \tif (!result_closed && result.type == QueryResultType::STREAM_RESULT && !((StreamQueryResult &)result).IsOpen()) {\n \t\tresult_closed = true;\n@@ -267,7 +294,7 @@ py::list DuckDBPyResult::FetchAllArrowChunks(idx_t chunk_size) {\n \n \twhile (FetchArrowChunk(result.get(), batches, chunk_size)) {\n \t}\n-\treturn std::move(batches);\n+\treturn batches;\n }\n \n duckdb::pyarrow::Table DuckDBPyResult::FetchArrowTable(idx_t chunk_size) {\n@@ -375,10 +402,6 @@ py::list DuckDBPyResult::GetDescription(const vector<string> &names, const vecto\n \treturn desc;\n }\n \n-py::list DuckDBPyResult::Description() {\n-\treturn GetDescription(result->names, result->types);\n-}\n-\n void DuckDBPyResult::Close() {\n \tresult = nullptr;\n }\n",
  "test_patch": "diff --git a/tools/pythonpkg/tests/fast/api/test_6315.py b/tools/pythonpkg/tests/fast/api/test_6315.py\nnew file mode 100644\nindex 000000000000..ed5487d6057f\n--- /dev/null\n+++ b/tools/pythonpkg/tests/fast/api/test_6315.py\n@@ -0,0 +1,22 @@\n+import duckdb\n+\n+class Test6315(object):\n+    def test_6315(self, duckdb_cursor):\n+        # segfault when accessing description after fetching rows\n+        c = duckdb.connect(\":memory:\")\n+        rv = c.execute(\"select * from sqlite_master where type = 'table'\")\n+        rv.fetchall()\n+        desc = rv.description\n+        names = [x[0] for x in desc]\n+        assert names == ['type', 'name', 'tbl_name', 'rootpage', 'sql']\n+\n+        # description of relation\n+        rel = c.sql(\"select * from sqlite_master where type = 'table'\")\n+        desc = rel.description\n+        names = [x[0] for x in desc]\n+        assert names == ['type', 'name', 'tbl_name', 'rootpage', 'sql']\n+\n+        rel.fetchall()\n+        desc = rel.description\n+        names = [x[0] for x in desc]\n+        assert names == ['type', 'name', 'tbl_name', 'rootpage', 'sql']\n",
  "problem_statement": "python: segfault when accessing `description` after fetching rows\n### What happens?\n\nPython code that worked in 0.6.1 segfaults in 0.7.0.\n\n### To Reproduce\n\n```\r\npython3 -mvenv venv\r\n. venv/bin/activate\r\npip install duckdb==0.7.0\r\npython3\r\n>>> import duckdb\r\n>>> c = duckdb.connect()\r\n>>> rv = c.execute(\"select * from sqlite_master where type = 'table'\")\r\n>>> rv.fetchall()\r\n[]\r\n>>> rv.description\r\nSegmentation fault (core dumped)\r\n```\r\n\r\nContrasting with 0.6.1:\r\n\r\n```\r\n>>> import duckdb\r\n>>> c = duckdb.connect()\r\n>>> rv = c.execute(\"select * from sqlite_master where type = 'table'\")\r\n>>> rv.fetchall()\r\n[]\r\n>>> rv.description\r\n[('type', 'STRING', None, None, None, None, None), ('name', 'STRING', None, None, None, None, None), ('tbl_name', 'STRING', None, None, None, None, None), ('rootpage', 'NUMBER', None, None, None, None, None), ('sql', 'STRING', None, None, None, None, None)]\r\n```\n\n### OS:\n\nUbuntu 20.04.3, x64\n\n### DuckDB Version:\n\n0.7.0\n\n### DuckDB Client:\n\nPython\n\n### Full Name:\n\nColin Dellow\n\n### Affiliation:\n\nHobbyist\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\npython: segfault when accessing `description` after fetching rows\n### What happens?\n\nPython code that worked in 0.6.1 segfaults in 0.7.0.\n\n### To Reproduce\n\n```\r\npython3 -mvenv venv\r\n. venv/bin/activate\r\npip install duckdb==0.7.0\r\npython3\r\n>>> import duckdb\r\n>>> c = duckdb.connect()\r\n>>> rv = c.execute(\"select * from sqlite_master where type = 'table'\")\r\n>>> rv.fetchall()\r\n[]\r\n>>> rv.description\r\nSegmentation fault (core dumped)\r\n```\r\n\r\nContrasting with 0.6.1:\r\n\r\n```\r\n>>> import duckdb\r\n>>> c = duckdb.connect()\r\n>>> rv = c.execute(\"select * from sqlite_master where type = 'table'\")\r\n>>> rv.fetchall()\r\n[]\r\n>>> rv.description\r\n[('type', 'STRING', None, None, None, None, None), ('name', 'STRING', None, None, None, None, None), ('tbl_name', 'STRING', None, None, None, None, None), ('rootpage', 'NUMBER', None, None, None, None, None), ('sql', 'STRING', None, None, None, None, None)]\r\n```\n\n### OS:\n\nUbuntu 20.04.3, x64\n\n### DuckDB Version:\n\n0.7.0\n\n### DuckDB Client:\n\nPython\n\n### Full Name:\n\nColin Dellow\n\n### Affiliation:\n\nHobbyist\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\n",
  "hints_text": "Does this only happen when querying the sqlite_master view?\nHm, good question. Looks like it happens for simpler queries:\r\n\r\n```\r\n>>> import duckdb\r\n>>> c = duckdb.connect()\r\n>>> rv = c.execute('select 1')\r\n>>> rv.fetchall()\r\n[(1,)]\r\n>>> rv.description\r\nSegmentation fault (core dumped)\r\n```\nAh, but I can access the description before I retrieve the rows:\r\n\r\n```\r\n>>> import duckdb\r\n>>> c = duckdb.connect()\r\n>>> rv = c.execute('select 1')\r\n>>> rv.description\r\n[('1', 'NUMBER', None, None, None, None, None)]\r\n>>> rv.fetchall()\r\n[(1,)]\r\n>>> rv.description\r\nSegmentation fault (core dumped)\r\n```\nI guess that explains how it wasn't caught before? In most cases you'd get the description first\nAh, could be! I'm not very familiar with the DB API best practices. I was translating some stuff from SQLite to DuckDB and just fiddled away until it worked.\nDoes this only happen when querying the sqlite_master view?\nHm, good question. Looks like it happens for simpler queries:\r\n\r\n```\r\n>>> import duckdb\r\n>>> c = duckdb.connect()\r\n>>> rv = c.execute('select 1')\r\n>>> rv.fetchall()\r\n[(1,)]\r\n>>> rv.description\r\nSegmentation fault (core dumped)\r\n```\nAh, but I can access the description before I retrieve the rows:\r\n\r\n```\r\n>>> import duckdb\r\n>>> c = duckdb.connect()\r\n>>> rv = c.execute('select 1')\r\n>>> rv.description\r\n[('1', 'NUMBER', None, None, None, None, None)]\r\n>>> rv.fetchall()\r\n[(1,)]\r\n>>> rv.description\r\nSegmentation fault (core dumped)\r\n```\nI guess that explains how it wasn't caught before? In most cases you'd get the description first\nAh, could be! I'm not very familiar with the DB API best practices. I was translating some stuff from SQLite to DuckDB and just fiddled away until it worked.",
  "created_at": "2023-02-16T14:40:27Z"
}