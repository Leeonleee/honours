{
  "repo": "duckdb/duckdb",
  "pull_number": 14708,
  "instance_id": "duckdb__duckdb-14708",
  "issue_numbers": [
    "14701",
    "14701"
  ],
  "base_commit": "059ac75f6225fde78b686bc85f23d2e70af1dbe0",
  "patch": "diff --git a/src/storage/table/array_column_data.cpp b/src/storage/table/array_column_data.cpp\nindex 95ba4df3802a..148f3fd84f0d 100644\n--- a/src/storage/table/array_column_data.cpp\n+++ b/src/storage/table/array_column_data.cpp\n@@ -114,7 +114,13 @@ void ArrayColumnData::InitializeAppend(ColumnAppendState &state) {\n }\n \n void ArrayColumnData::Append(BaseStatistics &stats, ColumnAppendState &state, Vector &vector, idx_t count) {\n-\tvector.Flatten(count);\n+\tif (vector.GetVectorType() != VectorType::FLAT_VECTOR) {\n+\t\tVector append_vector(vector);\n+\t\tappend_vector.Flatten(count);\n+\t\tAppend(stats, state, append_vector, count);\n+\t\treturn;\n+\t}\n+\n \t// Append validity\n \tvalidity.Append(stats, state.child_appends[0], vector, count);\n \t// Append child column\ndiff --git a/src/storage/table/struct_column_data.cpp b/src/storage/table/struct_column_data.cpp\nindex 9ac2b0c0f0cc..d6e2ef8d4ed4 100644\n--- a/src/storage/table/struct_column_data.cpp\n+++ b/src/storage/table/struct_column_data.cpp\n@@ -127,7 +127,12 @@ void StructColumnData::InitializeAppend(ColumnAppendState &state) {\n }\n \n void StructColumnData::Append(BaseStatistics &stats, ColumnAppendState &state, Vector &vector, idx_t count) {\n-\tvector.Flatten(count);\n+\tif (vector.GetVectorType() != VectorType::FLAT_VECTOR) {\n+\t\tVector append_vector(vector);\n+\t\tappend_vector.Flatten(count);\n+\t\tAppend(stats, state, append_vector, count);\n+\t\treturn;\n+\t}\n \n \t// append the null values\n \tvalidity.Append(stats, state.child_appends[0], vector, count);\n",
  "test_patch": "diff --git a/test/sql/storage/struct_default_entries.test_slow b/test/sql/storage/struct_default_entries.test_slow\nnew file mode 100644\nindex 000000000000..b3f1bb82c9bd\n--- /dev/null\n+++ b/test/sql/storage/struct_default_entries.test_slow\n@@ -0,0 +1,31 @@\n+# name: test/sql/storage/struct_default_entries.test_slow\n+# description: Test struct with many default entries\n+# group: [storage]\n+\n+statement ok\n+CREATE TABLE test_table (\n+\t  \"id\" VARCHAR,\n+\t  \"str\" STRUCT(\n+\t\t  a VARCHAR\n+\t  )\n+  );\n+\n+statement ok\n+INSERT INTO test_table(\n+  \"id\"\n+)\n+(\n+  SELECT\n+\t  \"id\",\n+  FROM\n+\t  range(2000000) t(id)\n+  QUALIFY\n+\t  ROW_NUMBER() OVER (\n+\t\t  PARTITION BY id\n+\t  ) = 1\n+);\n+\n+query IIII\n+SELECT COUNT(DISTINCT id), COUNT(*), COUNT(\"str\"), COUNT(\"str\".a) FROM test_table\n+----\n+2000000\t2000000\t0\t0\n",
  "problem_statement": "DuckDB SEGV when loading 2 million entries to a table with STRUCT in schema\n### What happens?\r\n\r\nLoading 2 million entries to a table reliably crashes, if the table contains STRUCT in the schema. The STRUCT in the schema ifself is triggering the crash, the data does not have to be loaded in the column.\r\nThis is reproducible in the latest DuckDB 1.1.3 as well as earlier versions, except the stable 1.0.0 release.\r\n\r\nbzipped crash_data.parquet file required for the code to run:\r\nhttps://drive.google.com/file/d/1C4s5mTDTzoGewUaGMvFm6NE4h0X6xQvY/view?usp=share_link\r\n(please ignore \"large file\" virus warnings from Google)\r\n\r\nPython SEGFAULT report:\r\n```\r\nFatal Python error: Segmentation fault\r\n\r\nThread 0x00000001e8e04f40 (most recent call first):\r\n  File \"/Users/dmitrykalinin/src/duckdb_crash/crash.py\", line 19 in <module>\r\nzsh: segmentation fault  python crash.py\r\n```\r\nExample C++ stack trace:\r\n```\r\nThread 35 Crashed:\r\n0   libsystem_platform.dylib      \t       0x180fde1d4 _platform_memmove + 52\r\n1   duckdb.cpython-312-darwin.so  \t       0x1144cb538 duckdb::StringVector::AddStringOrBlob(duckdb::Vector&, duckdb::string_t) + 160\r\n2   duckdb.cpython-312-darwin.so  \t       0x113df914c duckdb::VectorOperations::Copy(duckdb::Vector const&, duckdb::Vector&, duckdb::SelectionVector const&, unsigned long long, unsigned long long, unsigned long long, unsigned long long) + 2492\r\n3   duckdb.cpython-312-darwin.so  \t       0x113df8fd8 duckdb::VectorOperations::Copy(duckdb::Vector const&, duckdb::Vector&, duckdb::SelectionVector const&, unsigned long long, unsigned long long, unsigned long long, unsigned long long) + 2120\r\n4   duckdb.cpython-312-darwin.so  \t       0x1144988c4 duckdb::Vector::Flatten(unsigned long long) + 480\r\n5   duckdb.cpython-312-darwin.so  \t       0x115436b58 duckdb::StructColumnData::Append(duckdb::BaseStatistics&, duckdb::ColumnAppendState&, duckdb::Vector&, unsigned long long) + 64\r\n6   duckdb.cpython-312-darwin.so  \t       0x11542c480 duckdb::RowGroupCollection::Append(duckdb::DataChunk&, duckdb::TableAppendState&) + 324\r\n7   duckdb.cpython-312-darwin.so  \t       0x114c7ab8c duckdb::PhysicalInsert::Sink(duckdb::ExecutionContext&, duckdb::DataChunk&, duckdb::OperatorSinkInput&) const + 432\r\n8   duckdb.cpython-312-darwin.so  \t       0x11518b8f0 duckdb::PipelineExecutor::ExecutePushInternal(duckdb::DataChunk&, unsigned long long) + 268\r\n9   duckdb.cpython-312-darwin.so  \t       0x1151886b4 duckdb::PipelineExecutor::Execute(unsigned long long) + 328\r\n10  duckdb.cpython-312-darwin.so  \t       0x1151883bc duckdb::PipelineTask::ExecuteTask(duckdb::TaskExecutionMode) + 328\r\n11  duckdb.cpython-312-darwin.so  \t       0x11518073c duckdb::ExecutorTask::Execute(duckdb::TaskExecutionMode) + 140\r\n12  duckdb.cpython-312-darwin.so  \t       0x11518ebf4 duckdb::TaskScheduler::ExecuteForever(std::__1::atomic<bool>*) + 612\r\n13  duckdb.cpython-312-darwin.so  \t       0x11519605c void* std::__1::__thread_proxy[abi:ue170006]<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void (*)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*, std::__1::atomic<bool>*>>(void*) + 56\r\n14  libsystem_pthread.dylib       \t       0x180fadf94 _pthread_start + 136\r\n15  libsystem_pthread.dylib       \t       0x180fa8d34 thread_start + 8\r\n```\r\n\r\n### To Reproduce\r\n\r\n```\r\nimport duckdb\r\nimport faulthandler\r\n\r\nfaulthandler.enable()\r\nconn = duckdb.connect()\r\ncursor = conn.cursor()\r\n\r\nconn.execute(\"\"\"\r\n    CREATE TABLE test_table (\r\n        \"id\" VARCHAR,\r\n\r\n        \"str\" STRUCT(\r\n            a VARCHAR\r\n        ),\r\n        PRIMARY KEY (id)\r\n    )\r\n\"\"\")\r\n\r\nconn.execute(\"\"\"\r\nINSERT INTO test_table(\r\n    \"id\"   \r\n)\r\n(\r\n    SELECT\r\n        \"id\", \r\n    FROM\r\n        read_parquet(['crash_data.parquet'])\r\n    QUALIFY\r\n        ROW_NUMBER() OVER (\r\n            PARTITION BY id\r\n        ) = 1\r\n)\r\n\"\"\")\r\n\r\n```\r\n\r\n### OS:\r\n\r\nMacOS\r\n\r\n### DuckDB Version:\r\n\r\n1.1.3\r\n\r\n### DuckDB Client:\r\n\r\nPython 3.11.10\r\n\r\n### Hardware:\r\n\r\nMacbook M3 with 36GB RAM\r\n\r\n### Full Name:\r\n\r\nDimi Kalyn\r\n\r\n### Affiliation:\r\n\r\nExaforce, Inc\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\nDuckDB SEGV when loading 2 million entries to a table with STRUCT in schema\n### What happens?\r\n\r\nLoading 2 million entries to a table reliably crashes, if the table contains STRUCT in the schema. The STRUCT in the schema ifself is triggering the crash, the data does not have to be loaded in the column.\r\nThis is reproducible in the latest DuckDB 1.1.3 as well as earlier versions, except the stable 1.0.0 release.\r\n\r\nbzipped crash_data.parquet file required for the code to run:\r\nhttps://drive.google.com/file/d/1C4s5mTDTzoGewUaGMvFm6NE4h0X6xQvY/view?usp=share_link\r\n(please ignore \"large file\" virus warnings from Google)\r\n\r\nPython SEGFAULT report:\r\n```\r\nFatal Python error: Segmentation fault\r\n\r\nThread 0x00000001e8e04f40 (most recent call first):\r\n  File \"/Users/dmitrykalinin/src/duckdb_crash/crash.py\", line 19 in <module>\r\nzsh: segmentation fault  python crash.py\r\n```\r\nExample C++ stack trace:\r\n```\r\nThread 35 Crashed:\r\n0   libsystem_platform.dylib      \t       0x180fde1d4 _platform_memmove + 52\r\n1   duckdb.cpython-312-darwin.so  \t       0x1144cb538 duckdb::StringVector::AddStringOrBlob(duckdb::Vector&, duckdb::string_t) + 160\r\n2   duckdb.cpython-312-darwin.so  \t       0x113df914c duckdb::VectorOperations::Copy(duckdb::Vector const&, duckdb::Vector&, duckdb::SelectionVector const&, unsigned long long, unsigned long long, unsigned long long, unsigned long long) + 2492\r\n3   duckdb.cpython-312-darwin.so  \t       0x113df8fd8 duckdb::VectorOperations::Copy(duckdb::Vector const&, duckdb::Vector&, duckdb::SelectionVector const&, unsigned long long, unsigned long long, unsigned long long, unsigned long long) + 2120\r\n4   duckdb.cpython-312-darwin.so  \t       0x1144988c4 duckdb::Vector::Flatten(unsigned long long) + 480\r\n5   duckdb.cpython-312-darwin.so  \t       0x115436b58 duckdb::StructColumnData::Append(duckdb::BaseStatistics&, duckdb::ColumnAppendState&, duckdb::Vector&, unsigned long long) + 64\r\n6   duckdb.cpython-312-darwin.so  \t       0x11542c480 duckdb::RowGroupCollection::Append(duckdb::DataChunk&, duckdb::TableAppendState&) + 324\r\n7   duckdb.cpython-312-darwin.so  \t       0x114c7ab8c duckdb::PhysicalInsert::Sink(duckdb::ExecutionContext&, duckdb::DataChunk&, duckdb::OperatorSinkInput&) const + 432\r\n8   duckdb.cpython-312-darwin.so  \t       0x11518b8f0 duckdb::PipelineExecutor::ExecutePushInternal(duckdb::DataChunk&, unsigned long long) + 268\r\n9   duckdb.cpython-312-darwin.so  \t       0x1151886b4 duckdb::PipelineExecutor::Execute(unsigned long long) + 328\r\n10  duckdb.cpython-312-darwin.so  \t       0x1151883bc duckdb::PipelineTask::ExecuteTask(duckdb::TaskExecutionMode) + 328\r\n11  duckdb.cpython-312-darwin.so  \t       0x11518073c duckdb::ExecutorTask::Execute(duckdb::TaskExecutionMode) + 140\r\n12  duckdb.cpython-312-darwin.so  \t       0x11518ebf4 duckdb::TaskScheduler::ExecuteForever(std::__1::atomic<bool>*) + 612\r\n13  duckdb.cpython-312-darwin.so  \t       0x11519605c void* std::__1::__thread_proxy[abi:ue170006]<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void (*)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*, std::__1::atomic<bool>*>>(void*) + 56\r\n14  libsystem_pthread.dylib       \t       0x180fadf94 _pthread_start + 136\r\n15  libsystem_pthread.dylib       \t       0x180fa8d34 thread_start + 8\r\n```\r\n\r\n### To Reproduce\r\n\r\n```\r\nimport duckdb\r\nimport faulthandler\r\n\r\nfaulthandler.enable()\r\nconn = duckdb.connect()\r\ncursor = conn.cursor()\r\n\r\nconn.execute(\"\"\"\r\n    CREATE TABLE test_table (\r\n        \"id\" VARCHAR,\r\n\r\n        \"str\" STRUCT(\r\n            a VARCHAR\r\n        ),\r\n        PRIMARY KEY (id)\r\n    )\r\n\"\"\")\r\n\r\nconn.execute(\"\"\"\r\nINSERT INTO test_table(\r\n    \"id\"   \r\n)\r\n(\r\n    SELECT\r\n        \"id\", \r\n    FROM\r\n        read_parquet(['crash_data.parquet'])\r\n    QUALIFY\r\n        ROW_NUMBER() OVER (\r\n            PARTITION BY id\r\n        ) = 1\r\n)\r\n\"\"\")\r\n\r\n```\r\n\r\n### OS:\r\n\r\nMacOS\r\n\r\n### DuckDB Version:\r\n\r\n1.1.3\r\n\r\n### DuckDB Client:\r\n\r\nPython 3.11.10\r\n\r\n### Hardware:\r\n\r\nMacbook M3 with 36GB RAM\r\n\r\n### Full Name:\r\n\r\nDimi Kalyn\r\n\r\n### Affiliation:\r\n\r\nExaforce, Inc\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\n",
  "hints_text": "\n",
  "created_at": "2024-11-05T09:04:44Z"
}