{
  "repo": "duckdb/duckdb",
  "pull_number": 6205,
  "instance_id": "duckdb__duckdb-6205",
  "issue_numbers": [
    "6204",
    "6204"
  ],
  "base_commit": "3ee9cbb0ea40212d326e2d147b08b1f569ed3f13",
  "patch": "diff --git a/src/common/types/column_data_collection.cpp b/src/common/types/column_data_collection.cpp\nindex ae4c65d7b78a..972ed7037374 100644\n--- a/src/common/types/column_data_collection.cpp\n+++ b/src/common/types/column_data_collection.cpp\n@@ -125,21 +125,13 @@ ColumnDataRowCollection::ColumnDataRowCollection(const ColumnDataCollection &col\n \t}\n \t// read all the chunks\n \tColumnDataScanState temp_scan_state;\n-\tcollection.InitializeScan(temp_scan_state);\n+\tcollection.InitializeScan(temp_scan_state, ColumnDataScanProperties::DISALLOW_ZERO_COPY);\n \twhile (true) {\n \t\tauto chunk = make_unique<DataChunk>();\n \t\tcollection.InitializeScanChunk(*chunk);\n \t\tif (!collection.Scan(temp_scan_state, *chunk)) {\n \t\t\tbreak;\n \t\t}\n-\t\t// we keep the BufferHandles that are needed for the materialized collection pinned in the supplied scan_state\n-\t\tauto &temp_handles = temp_scan_state.current_chunk_state.handles;\n-\t\tauto &scan_handles = scan_state.current_chunk_state.handles;\n-\t\tfor (auto &temp_handle_pair : temp_handles) {\n-\t\t\tauto handle_copy =\n-\t\t\t    make_pair<uint32_t, BufferHandle>(scan_handles.size(), std::move(temp_handle_pair.second));\n-\t\t\tscan_state.current_chunk_state.handles.insert(std::move(handle_copy));\n-\t\t}\n \t\tchunks.push_back(std::move(chunk));\n \t}\n \t// now create all of the column data rows\n",
  "test_patch": "diff --git a/tools/shell/shell-test.py b/tools/shell/shell-test.py\nindex a0ce713b1be5..098ed203b1b0 100644\n--- a/tools/shell/shell-test.py\n+++ b/tools/shell/shell-test.py\n@@ -341,6 +341,11 @@ def tf():\n if b'42' not in outstr:\n      raise Exception('.output test failed')\n \n+# issue 6204\n+test('''\n+.output foo.txt\n+select * from range(2049);\n+''')\n \n outfile = tf()\n test('''\n",
  "problem_statement": "Segmentation fault outputting to file more than 2048 records\n### What happens?\r\n\r\nduckdb CLI crashes when output to file exceeds 2048 rows with:\r\n```\r\nSegmentation fault: 11\r\n```\r\n\r\nUnder lldb: \r\n```\r\nProcess 10060 stopped\r\n* thread #1, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x1000400)\r\n(lldb) thread backtrace\r\n* thread #1, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x1000400)\r\n  * frame #0: 0x000000010060a268 duckdb`duckdb::Vector::GetValueInternal(duckdb::Vector const&, unsigned long long) + 188\r\n    frame #1: 0x000000010060b238 duckdb`duckdb::Vector::GetValue(duckdb::Vector const&, unsigned long long) + 24\r\n    frame #2: 0x00000001006c61c4 duckdb`duckdb::BoxRenderer::GetRenderValue(duckdb::ColumnDataRowCollection&, unsigned long long, unsigned long long) + 48\r\n    frame #3: 0x00000001006c7900 duckdb`duckdb::BoxRenderer::RenderValues(std::__1::list<duckdb::ColumnDataCollection, std::__1::allocator<duckdb::ColumnDataCollection> > const&, std::__1::vector<unsigned long long, std::__1::allocator<unsigned long long> > const&, std::__1::vector<unsigned long long, std::__1::allocator<unsigned long long> > const&, std::__1::vector<duckdb::LogicalType, std::__1::allocator<duckdb::LogicalType> > const&, std::__1::basic_ostream<char, std::__1::char_traits<char> >&) + 720\r\n    frame #4: 0x00000001006c42cc duckdb`duckdb::BoxRenderer::Render(duckdb::ClientContext&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, duckdb::ColumnDataCollection const&, std::__1::basic_ostream<char, std::__1::char_traits<char> >&) + 980\r\n    frame #5: 0x00000001006c3ce0 duckdb`duckdb::BoxRenderer::ToString(duckdb::ClientContext&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, duckdb::ColumnDataCollection const&) + 84\r\n    frame #6: 0x000000010001d004 duckdb`duckdb_shell_sqlite3_print_duckbox + 1072\r\n    frame #7: 0x000000010001778c duckdb`exec_prepared_stmt + 1356\r\n    frame #8: 0x000000010000cd14 duckdb`shell_exec + 488\r\n    frame #9: 0x00000001000185c4 duckdb`runOneSqlLine + 156\r\n    frame #10: 0x000000010000d9d0 duckdb`process_input + 1004\r\n    frame #11: 0x0000000100005ba8 duckdb`main + 3944\r\n    frame #12: 0x000000018d7c3e50 dyld`start + 2544\r\n```\r\n\r\n### To Reproduce\r\n\r\n```\r\n$ duckdb\r\nv0.6.1 919cad22e8\r\nEnter \".help\" for usage hints.\r\nConnected to a transient in-memory database.\r\nUse \".open FILENAME\" to reopen on a persistent database.\r\nD .output foo.txt\r\nD select * from range(2048); -- OK\r\nD select * from range(2049); -- Will crash\r\nSegmentation fault: 11\r\n```\r\n\r\n### OS:\r\n\r\nMacOS Ventura 13.2 (22D49)\r\n\r\n### DuckDB Version:\r\n\r\nv0.6.1 919cad22e8\r\n\r\n### DuckDB Client:\r\n\r\nduckdb_cli\r\n\r\n### Full Name:\r\n\r\nMina Naguib\r\n\r\n### Affiliation:\r\n\r\nHivestack\r\n\r\n### Have you tried this on the latest `master` branch?\r\n\r\n- [X] I agree\r\n\r\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\r\n\r\n- [X] I agree\nSegmentation fault outputting to file more than 2048 records\n### What happens?\r\n\r\nduckdb CLI crashes when output to file exceeds 2048 rows with:\r\n```\r\nSegmentation fault: 11\r\n```\r\n\r\nUnder lldb: \r\n```\r\nProcess 10060 stopped\r\n* thread #1, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x1000400)\r\n(lldb) thread backtrace\r\n* thread #1, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x1000400)\r\n  * frame #0: 0x000000010060a268 duckdb`duckdb::Vector::GetValueInternal(duckdb::Vector const&, unsigned long long) + 188\r\n    frame #1: 0x000000010060b238 duckdb`duckdb::Vector::GetValue(duckdb::Vector const&, unsigned long long) + 24\r\n    frame #2: 0x00000001006c61c4 duckdb`duckdb::BoxRenderer::GetRenderValue(duckdb::ColumnDataRowCollection&, unsigned long long, unsigned long long) + 48\r\n    frame #3: 0x00000001006c7900 duckdb`duckdb::BoxRenderer::RenderValues(std::__1::list<duckdb::ColumnDataCollection, std::__1::allocator<duckdb::ColumnDataCollection> > const&, std::__1::vector<unsigned long long, std::__1::allocator<unsigned long long> > const&, std::__1::vector<unsigned long long, std::__1::allocator<unsigned long long> > const&, std::__1::vector<duckdb::LogicalType, std::__1::allocator<duckdb::LogicalType> > const&, std::__1::basic_ostream<char, std::__1::char_traits<char> >&) + 720\r\n    frame #4: 0x00000001006c42cc duckdb`duckdb::BoxRenderer::Render(duckdb::ClientContext&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, duckdb::ColumnDataCollection const&, std::__1::basic_ostream<char, std::__1::char_traits<char> >&) + 980\r\n    frame #5: 0x00000001006c3ce0 duckdb`duckdb::BoxRenderer::ToString(duckdb::ClientContext&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, duckdb::ColumnDataCollection const&) + 84\r\n    frame #6: 0x000000010001d004 duckdb`duckdb_shell_sqlite3_print_duckbox + 1072\r\n    frame #7: 0x000000010001778c duckdb`exec_prepared_stmt + 1356\r\n    frame #8: 0x000000010000cd14 duckdb`shell_exec + 488\r\n    frame #9: 0x00000001000185c4 duckdb`runOneSqlLine + 156\r\n    frame #10: 0x000000010000d9d0 duckdb`process_input + 1004\r\n    frame #11: 0x0000000100005ba8 duckdb`main + 3944\r\n    frame #12: 0x000000018d7c3e50 dyld`start + 2544\r\n```\r\n\r\n### To Reproduce\r\n\r\n```\r\n$ duckdb\r\nv0.6.1 919cad22e8\r\nEnter \".help\" for usage hints.\r\nConnected to a transient in-memory database.\r\nUse \".open FILENAME\" to reopen on a persistent database.\r\nD .output foo.txt\r\nD select * from range(2048); -- OK\r\nD select * from range(2049); -- Will crash\r\nSegmentation fault: 11\r\n```\r\n\r\n### OS:\r\n\r\nMacOS Ventura 13.2 (22D49)\r\n\r\n### DuckDB Version:\r\n\r\nv0.6.1 919cad22e8\r\n\r\n### DuckDB Client:\r\n\r\nduckdb_cli\r\n\r\n### Full Name:\r\n\r\nMina Naguib\r\n\r\n### Affiliation:\r\n\r\nHivestack\r\n\r\n### Have you tried this on the latest `master` branch?\r\n\r\n- [X] I agree\r\n\r\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\r\n\r\n- [X] I agree\n",
  "hints_text": "\n",
  "created_at": "2023-02-10T19:20:18Z"
}