{
  "repo": "duckdb/duckdb",
  "pull_number": 8620,
  "instance_id": "duckdb__duckdb-8620",
  "issue_numbers": [
    "8588"
  ],
  "base_commit": "b105af71bbff371f7069b23e250be9183a350aa5",
  "patch": "diff --git a/tools/pythonpkg/src/include/duckdb_python/numpy/numpy_type.hpp b/tools/pythonpkg/src/include/duckdb_python/numpy/numpy_type.hpp\nindex 7c92d3949e7f..ab26b22b7a29 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/numpy/numpy_type.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/numpy/numpy_type.hpp\n@@ -12,34 +12,43 @@\n #include \"duckdb_python/pybind11/pybind_wrapper.hpp\"\n \n namespace duckdb {\n+\n // Pandas has two different sets of types\n // NumPy dtypes (e.g., bool, int8,...)\n // Pandas Specific Types (e.g., categorical, datetime_tz,...)\n enum class NumpyNullableType : uint8_t {\n \t//! NumPy dtypes\n-\tBOOL,      //! bool_, bool8\n-\tINT_8,     //! byte, int8\n-\tUINT_8,    //! ubyte, uint8\n-\tINT_16,    //! int16, short\n-\tUINT_16,   //! uint16, ushort\n-\tINT_32,    //! int32, intc\n-\tUINT_32,   //! uint32, uintc,\n-\tINT_64,    //! int64, int0, int_, intp, matrix\n-\tUINT_64,   //! uint64, uint, uint0, uintp\n-\tFLOAT_16,  //! float16, half\n-\tFLOAT_32,  //! float32, single\n-\tFLOAT_64,  //! float64, float_, double\n-\tOBJECT,    //! object\n-\tUNICODE,   //! <U1, unicode_, str_, str0\n-\tDATETIME,  //! datetime64[D], datetime64\n-\tTIMEDELTA, //! timedelta64[D], timedelta64\n+\tBOOL,        //! bool_, bool8\n+\tINT_8,       //! byte, int8\n+\tUINT_8,      //! ubyte, uint8\n+\tINT_16,      //! int16, short\n+\tUINT_16,     //! uint16, ushort\n+\tINT_32,      //! int32, intc\n+\tUINT_32,     //! uint32, uintc,\n+\tINT_64,      //! int64, int0, int_, intp, matrix\n+\tUINT_64,     //! uint64, uint, uint0, uintp\n+\tFLOAT_16,    //! float16, half\n+\tFLOAT_32,    //! float32, single\n+\tFLOAT_64,    //! float64, float_, double\n+\tOBJECT,      //! object\n+\tUNICODE,     //! <U1, unicode_, str_, str0\n+\tDATETIME_S,  //! datetime64[s], <M8[s]\n+\tDATETIME_MS, //! datetime64[ms], <M8[ms]\n+\tDATETIME_NS, //! datetime64[ns], <M8[ns]\n+\tDATETIME_US, //! datetime64[us], <M8[us]\n+\tTIMEDELTA,   //! timedelta64[D], timedelta64\n \n \t//! ------------------------------------------------------------\n \t//! Extension Types\n \t//! ------------------------------------------------------------\n-\tCATEGORY,    //! category\n-\tDATETIME_TZ, //! datetime64[ns, TZ]\n+\tCATEGORY, //! category\n+};\n \n+struct NumpyType {\n+\tNumpyNullableType type;\n+\t//! Optionally if the type is a DATETIME,\n+\t//! this indicates whether the type has timezone information\n+\tbool has_timezone = false;\n };\n \n enum class NumpyObjectType : uint8_t {\n@@ -51,7 +60,7 @@ enum class NumpyObjectType : uint8_t {\n \tDICT,      //! dict of numpy arrays of shape (n,)\n };\n \n-NumpyNullableType ConvertNumpyType(const py::handle &col_type);\n-LogicalType NumpyToLogicalType(const NumpyNullableType &col_type);\n+NumpyType ConvertNumpyType(const py::handle &col_type);\n+LogicalType NumpyToLogicalType(const NumpyType &col_type);\n \n } // namespace duckdb\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/pandas/pandas_bind.hpp b/tools/pythonpkg/src/include/duckdb_python/pandas/pandas_bind.hpp\nindex 30625e571a44..d85f18815164 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/pandas/pandas_bind.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/pandas/pandas_bind.hpp\n@@ -12,7 +12,7 @@ struct RegisteredArray;\n class ClientContext;\n \n struct PandasColumnBindData {\n-\tNumpyNullableType numpy_type;\n+\tNumpyType numpy_type;\n \tunique_ptr<PandasColumn> pandas_col;\n \tunique_ptr<RegisteredArray> mask;\n \t//! Only for categorical types\ndiff --git a/tools/pythonpkg/src/numpy/array_wrapper.cpp b/tools/pythonpkg/src/numpy/array_wrapper.cpp\nindex fbd27914b4b0..6f95280ad593 100644\n--- a/tools/pythonpkg/src/numpy/array_wrapper.cpp\n+++ b/tools/pythonpkg/src/numpy/array_wrapper.cpp\n@@ -574,11 +574,17 @@ string RawArrayWrapper::DuckDBToNumpyDtype(const LogicalType &type) {\n \tcase LogicalTypeId::DECIMAL:\n \t\treturn \"float64\";\n \tcase LogicalTypeId::TIMESTAMP:\n+\t\treturn \"datetime64[us]\";\n \tcase LogicalTypeId::TIMESTAMP_TZ:\n+\t\treturn \"datetime64[us]\";\n \tcase LogicalTypeId::TIMESTAMP_NS:\n+\t\treturn \"datetime64[ns]\";\n \tcase LogicalTypeId::TIMESTAMP_MS:\n+\t\treturn \"datetime64[ms]\";\n \tcase LogicalTypeId::TIMESTAMP_SEC:\n+\t\treturn \"datetime64[s]\";\n \tcase LogicalTypeId::DATE:\n+\t\t// FIXME: should this not be 'date64[ns]' ?\n \t\treturn \"datetime64[ns]\";\n \tcase LogicalTypeId::INTERVAL:\n \t\treturn \"timedelta64[ns]\";\n@@ -705,17 +711,8 @@ void ArrayWrapper::Append(idx_t current_offset, Vector &input, idx_t count) {\n \t\tbreak;\n \tcase LogicalTypeId::TIMESTAMP:\n \tcase LogicalTypeId::TIMESTAMP_TZ:\n-\t\tmay_have_null = ConvertColumn<timestamp_t, int64_t, duckdb_py_convert::TimestampConvert>(\n-\t\t    current_offset, dataptr, maskptr, idata, count);\n-\t\tbreak;\n \tcase LogicalTypeId::TIMESTAMP_SEC:\n-\t\tmay_have_null = ConvertColumn<timestamp_t, int64_t, duckdb_py_convert::TimestampConvertSec>(\n-\t\t    current_offset, dataptr, maskptr, idata, count);\n-\t\tbreak;\n \tcase LogicalTypeId::TIMESTAMP_MS:\n-\t\tmay_have_null = ConvertColumn<timestamp_t, int64_t, duckdb_py_convert::TimestampConvertMilli>(\n-\t\t    current_offset, dataptr, maskptr, idata, count);\n-\t\tbreak;\n \tcase LogicalTypeId::TIMESTAMP_NS:\n \t\tmay_have_null = ConvertColumn<timestamp_t, int64_t, duckdb_py_convert::TimestampConvertNano>(\n \t\t    current_offset, dataptr, maskptr, idata, count);\ndiff --git a/tools/pythonpkg/src/numpy/numpy_bind.cpp b/tools/pythonpkg/src/numpy/numpy_bind.cpp\nindex e4614503e34a..ef30706a3ed1 100644\n--- a/tools/pythonpkg/src/numpy/numpy_bind.cpp\n+++ b/tools/pythonpkg/src/numpy/numpy_bind.cpp\n@@ -33,13 +33,13 @@ void NumpyBind::Bind(const ClientContext &context, py::handle df, vector<PandasC\n \n \t\tauto column = get_fun(df_columns[col_idx]);\n \n-\t\tif (bind_data.numpy_type == NumpyNullableType::FLOAT_16) {\n+\t\tif (bind_data.numpy_type.type == NumpyNullableType::FLOAT_16) {\n \t\t\tbind_data.pandas_col = make_uniq<PandasNumpyColumn>(py::array(column.attr(\"astype\")(\"float32\")));\n-\t\t\tbind_data.numpy_type = NumpyNullableType::FLOAT_32;\n+\t\t\tbind_data.numpy_type.type = NumpyNullableType::FLOAT_32;\n \t\t\tduckdb_col_type = NumpyToLogicalType(bind_data.numpy_type);\n-\t\t} else if (bind_data.numpy_type == NumpyNullableType::OBJECT &&\n+\t\t} else if (bind_data.numpy_type.type == NumpyNullableType::OBJECT &&\n \t\t           string(py::str(df_types[col_idx])) == \"string\") {\n-\t\t\tbind_data.numpy_type = NumpyNullableType::CATEGORY;\n+\t\t\tbind_data.numpy_type.type = NumpyNullableType::CATEGORY;\n \t\t\tauto enum_name = string(py::str(df_columns[col_idx]));\n \t\t\t// here we call numpy.unique\n \t\t\t// this function call will return the unique values of a given array\n@@ -61,7 +61,7 @@ void NumpyBind::Bind(const ClientContext &context, py::handle df, vector<PandasC\n \t\t\tduckdb_col_type = NumpyToLogicalType(bind_data.numpy_type);\n \t\t}\n \n-\t\tif (bind_data.numpy_type == NumpyNullableType::OBJECT) {\n+\t\tif (bind_data.numpy_type.type == NumpyNullableType::OBJECT) {\n \t\t\tPandasAnalyzer analyzer(config);\n \t\t\tif (analyzer.Analyze(get_fun(df_columns[col_idx]))) {\n \t\t\t\tduckdb_col_type = analyzer.AnalyzedType();\ndiff --git a/tools/pythonpkg/src/numpy/numpy_scan.cpp b/tools/pythonpkg/src/numpy/numpy_scan.cpp\nindex b5a8eb5978cc..f7f21c671c88 100644\n--- a/tools/pythonpkg/src/numpy/numpy_scan.cpp\n+++ b/tools/pythonpkg/src/numpy/numpy_scan.cpp\n@@ -200,7 +200,7 @@ void NumpyScan::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset,\n \tauto &numpy_col = reinterpret_cast<PandasNumpyColumn &>(*bind_data.pandas_col);\n \tauto &array = numpy_col.array;\n \n-\tswitch (bind_data.numpy_type) {\n+\tswitch (bind_data.numpy_type.type) {\n \tcase NumpyNullableType::BOOL:\n \t\tScanNumpyMasked<bool>(bind_data, count, offset, out);\n \t\tbreak;\n@@ -234,12 +234,49 @@ void NumpyScan::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset,\n \tcase NumpyNullableType::FLOAT_64:\n \t\tScanNumpyFpColumn<double>(reinterpret_cast<const double *>(array.data()), numpy_col.stride, count, offset, out);\n \t\tbreak;\n-\tcase NumpyNullableType::DATETIME:\n-\tcase NumpyNullableType::DATETIME_TZ: {\n+\tcase NumpyNullableType::DATETIME_NS:\n+\tcase NumpyNullableType::DATETIME_MS:\n+\tcase NumpyNullableType::DATETIME_US:\n+\tcase NumpyNullableType::DATETIME_S: {\n \t\tauto src_ptr = reinterpret_cast<const int64_t *>(array.data());\n \t\tauto tgt_ptr = FlatVector::GetData<timestamp_t>(out);\n \t\tauto &mask = FlatVector::Validity(out);\n \n+\t\tusing timestamp_convert_func = std::function<timestamp_t(int64_t)>;\n+\t\ttimestamp_convert_func convert_func;\n+\n+\t\tswitch (bind_data.numpy_type.type) {\n+\t\tcase NumpyNullableType::DATETIME_NS:\n+\t\t\tif (bind_data.numpy_type.has_timezone) {\n+\t\t\t\t// Our timezone type is US, so we need to convert from NS to US\n+\t\t\t\tconvert_func = Timestamp::FromEpochNanoSeconds;\n+\t\t\t} else {\n+\t\t\t\tconvert_func = Timestamp::FromEpochMicroSeconds;\n+\t\t\t}\n+\t\t\tbreak;\n+\t\tcase NumpyNullableType::DATETIME_MS:\n+\t\t\tif (bind_data.numpy_type.has_timezone) {\n+\t\t\t\t// Our timezone type is US, so we need to convert from MS to US\n+\t\t\t\tconvert_func = Timestamp::FromEpochMs;\n+\t\t\t} else {\n+\t\t\t\tconvert_func = Timestamp::FromEpochMicroSeconds;\n+\t\t\t}\n+\t\t\tbreak;\n+\t\tcase NumpyNullableType::DATETIME_US:\n+\t\t\tconvert_func = Timestamp::FromEpochMicroSeconds;\n+\t\t\tbreak;\n+\t\tcase NumpyNullableType::DATETIME_S:\n+\t\t\tif (bind_data.numpy_type.has_timezone) {\n+\t\t\t\t// Our timezone type is US, so we need to convert from S to US\n+\t\t\t\tconvert_func = Timestamp::FromEpochSeconds;\n+\t\t\t} else {\n+\t\t\t\tconvert_func = Timestamp::FromEpochMicroSeconds;\n+\t\t\t}\n+\t\t\tbreak;\n+\t\tdefault:\n+\t\t\tthrow NotImplementedException(\"Scan for datetime of this type is not supported yet\");\n+\t\t};\n+\n \t\tfor (idx_t row = 0; row < count; row++) {\n \t\t\tauto source_idx = offset + row;\n \t\t\tif (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {\n@@ -247,7 +284,8 @@ void NumpyScan::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset,\n \t\t\t\tmask.SetInvalid(row);\n \t\t\t\tcontinue;\n \t\t\t}\n-\t\t\ttgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);\n+\t\t\t// Direct conversion, we've already matched the numpy type with the equivalent duckdb type\n+\t\t\ttgt_ptr[row] = convert_func(src_ptr[source_idx]);\n \t\t}\n \t\tbreak;\n \t}\n@@ -297,7 +335,7 @@ void NumpyScan::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset,\n \n \t\t\t// Get the pointer to the object\n \t\t\tPyObject *val = src_ptr[source_idx];\n-\t\t\tif (bind_data.numpy_type == NumpyNullableType::OBJECT && !py::isinstance<py::str>(val)) {\n+\t\t\tif (bind_data.numpy_type.type == NumpyNullableType::OBJECT && !py::isinstance<py::str>(val)) {\n \t\t\t\tif (val == Py_None) {\n \t\t\t\t\tout_mask.SetInvalid(row);\n \t\t\t\t\tcontinue;\ndiff --git a/tools/pythonpkg/src/numpy/type.cpp b/tools/pythonpkg/src/numpy/type.cpp\nindex 31bb13104a94..00d86cab4df6 100644\n--- a/tools/pythonpkg/src/numpy/type.cpp\n+++ b/tools/pythonpkg/src/numpy/type.cpp\n@@ -6,72 +6,110 @@\n \n namespace duckdb {\n \n-static bool IsDateTime(const string &col_type_str) {\n-\tif (StringUtil::StartsWith(col_type_str, \"datetime64[ns\")) {\n-\t\treturn true;\n-\t}\n-\tif (StringUtil::StartsWith(col_type_str, \"datetime64[us\")) {\n+static bool IsDateTime(NumpyNullableType type) {\n+\tswitch (type) {\n+\tcase NumpyNullableType::DATETIME_NS:\n+\tcase NumpyNullableType::DATETIME_S:\n+\tcase NumpyNullableType::DATETIME_MS:\n+\tcase NumpyNullableType::DATETIME_US:\n \t\treturn true;\n-\t}\n-\tif (StringUtil::StartsWith(col_type_str, \"datetime64[ms\")) {\n-\t\treturn true;\n-\t}\n-\tif (StringUtil::StartsWith(col_type_str, \"datetime64[s\")) {\n-\t\treturn true;\n-\t}\n-\tif (col_type_str == \"<M8[ns]\") {\n-\t\treturn true;\n-\t}\n-\treturn false;\n+\tdefault:\n+\t\treturn false;\n+\t};\n }\n \n-NumpyNullableType ConvertNumpyType(const py::handle &col_type) {\n-\tauto col_type_str = string(py::str(col_type));\n-\n+static NumpyNullableType ConvertNumpyTypeInternal(const string &col_type_str) {\n \tif (col_type_str == \"bool\" || col_type_str == \"boolean\") {\n \t\treturn NumpyNullableType::BOOL;\n-\t} else if (col_type_str == \"uint8\" || col_type_str == \"UInt8\") {\n+\t}\n+\tif (col_type_str == \"uint8\" || col_type_str == \"UInt8\") {\n \t\treturn NumpyNullableType::UINT_8;\n-\t} else if (col_type_str == \"uint16\" || col_type_str == \"UInt16\") {\n+\t}\n+\tif (col_type_str == \"uint16\" || col_type_str == \"UInt16\") {\n \t\treturn NumpyNullableType::UINT_16;\n-\t} else if (col_type_str == \"uint32\" || col_type_str == \"UInt32\") {\n+\t}\n+\tif (col_type_str == \"uint32\" || col_type_str == \"UInt32\") {\n \t\treturn NumpyNullableType::UINT_32;\n-\t} else if (col_type_str == \"uint64\" || col_type_str == \"UInt64\") {\n+\t}\n+\tif (col_type_str == \"uint64\" || col_type_str == \"UInt64\") {\n \t\treturn NumpyNullableType::UINT_64;\n-\t} else if (col_type_str == \"int8\" || col_type_str == \"Int8\") {\n+\t}\n+\tif (col_type_str == \"int8\" || col_type_str == \"Int8\") {\n \t\treturn NumpyNullableType::INT_8;\n-\t} else if (col_type_str == \"int16\" || col_type_str == \"Int16\") {\n+\t}\n+\tif (col_type_str == \"int16\" || col_type_str == \"Int16\") {\n \t\treturn NumpyNullableType::INT_16;\n-\t} else if (col_type_str == \"int32\" || col_type_str == \"Int32\") {\n+\t}\n+\tif (col_type_str == \"int32\" || col_type_str == \"Int32\") {\n \t\treturn NumpyNullableType::INT_32;\n-\t} else if (col_type_str == \"int64\" || col_type_str == \"Int64\") {\n+\t}\n+\tif (col_type_str == \"int64\" || col_type_str == \"Int64\") {\n \t\treturn NumpyNullableType::INT_64;\n-\t} else if (col_type_str == \"float16\" || col_type_str == \"Float16\") {\n+\t}\n+\tif (col_type_str == \"float16\" || col_type_str == \"Float16\") {\n \t\treturn NumpyNullableType::FLOAT_16;\n-\t} else if (col_type_str == \"float32\" || col_type_str == \"Float32\") {\n+\t}\n+\tif (col_type_str == \"float32\" || col_type_str == \"Float32\") {\n \t\treturn NumpyNullableType::FLOAT_32;\n-\t} else if (col_type_str == \"float64\" || col_type_str == \"Float64\") {\n+\t}\n+\tif (col_type_str == \"float64\" || col_type_str == \"Float64\") {\n \t\treturn NumpyNullableType::FLOAT_64;\n-\t} else if (col_type_str == \"object\" || col_type_str == \"string\") {\n+\t}\n+\tif (col_type_str == \"object\" || col_type_str == \"string\") {\n \t\t//! this better be castable to strings\n \t\treturn NumpyNullableType::OBJECT;\n-\t} else if (col_type_str == \"timedelta64[ns]\") {\n+\t}\n+\tif (col_type_str == \"timedelta64[ns]\") {\n \t\treturn NumpyNullableType::TIMEDELTA;\n-\t} else if (IsDateTime(col_type_str)) {\n+\t}\n+\t// We use 'StartsWith' because it might have ', tz' at the end, indicating timezone\n+\tif (StringUtil::StartsWith(col_type_str, \"datetime64[ns\")) {\n+\t\treturn NumpyNullableType::DATETIME_NS;\n+\t}\n+\tif (StringUtil::StartsWith(col_type_str, \"datetime64[us\")) {\n+\t\treturn NumpyNullableType::DATETIME_US;\n+\t}\n+\tif (StringUtil::StartsWith(col_type_str, \"datetime64[ms\")) {\n+\t\treturn NumpyNullableType::DATETIME_MS;\n+\t}\n+\tif (StringUtil::StartsWith(col_type_str, \"datetime64[s\")) {\n+\t\treturn NumpyNullableType::DATETIME_S;\n+\t}\n+\t// Legacy datetime type indicators\n+\tif (StringUtil::StartsWith(col_type_str, \"<M8[ns\")) {\n+\t\treturn NumpyNullableType::DATETIME_NS;\n+\t}\n+\tif (StringUtil::StartsWith(col_type_str, \"<M8[s\")) {\n+\t\treturn NumpyNullableType::DATETIME_S;\n+\t}\n+\tif (StringUtil::StartsWith(col_type_str, \"<M8[us\")) {\n+\t\treturn NumpyNullableType::DATETIME_US;\n+\t}\n+\tif (StringUtil::StartsWith(col_type_str, \"<M8[ms\")) {\n+\t\treturn NumpyNullableType::DATETIME_MS;\n+\t}\n+\tif (col_type_str == \"category\") {\n+\t\treturn NumpyNullableType::CATEGORY;\n+\t}\n+\tthrow NotImplementedException(\"Data type '%s' not recognized\", col_type_str);\n+}\n+\n+NumpyType ConvertNumpyType(const py::handle &col_type) {\n+\tauto col_type_str = string(py::str(col_type));\n+\tNumpyType numpy_type;\n+\n+\tnumpy_type.type = ConvertNumpyTypeInternal(col_type_str);\n+\tif (IsDateTime(numpy_type.type)) {\n \t\tif (hasattr(col_type, \"tz\")) {\n \t\t\t// The datetime has timezone information.\n-\t\t\treturn NumpyNullableType::DATETIME_TZ;\n+\t\t\tnumpy_type.has_timezone = true;\n \t\t}\n-\t\treturn NumpyNullableType::DATETIME;\n-\t} else if (col_type_str == \"category\") {\n-\t\treturn NumpyNullableType::CATEGORY;\n-\t} else {\n-\t\tthrow NotImplementedException(\"Data type '%s' not recognized\", col_type_str);\n \t}\n+\treturn numpy_type;\n }\n \n-LogicalType NumpyToLogicalType(const NumpyNullableType &col_type) {\n-\tswitch (col_type) {\n+LogicalType NumpyToLogicalType(const NumpyType &col_type) {\n+\tswitch (col_type.type) {\n \tcase NumpyNullableType::BOOL:\n \t\treturn LogicalType::BOOLEAN;\n \tcase NumpyNullableType::INT_8:\n@@ -100,10 +138,30 @@ LogicalType NumpyToLogicalType(const NumpyNullableType &col_type) {\n \t\treturn LogicalType::VARCHAR;\n \tcase NumpyNullableType::TIMEDELTA:\n \t\treturn LogicalType::INTERVAL;\n-\tcase NumpyNullableType::DATETIME:\n+\tcase NumpyNullableType::DATETIME_MS: {\n+\t\tif (col_type.has_timezone) {\n+\t\t\treturn LogicalType::TIMESTAMP_TZ;\n+\t\t}\n+\t\treturn LogicalType::TIMESTAMP_MS;\n+\t}\n+\tcase NumpyNullableType::DATETIME_NS: {\n+\t\tif (col_type.has_timezone) {\n+\t\t\treturn LogicalType::TIMESTAMP_TZ;\n+\t\t}\n+\t\treturn LogicalType::TIMESTAMP_NS;\n+\t}\n+\tcase NumpyNullableType::DATETIME_S: {\n+\t\tif (col_type.has_timezone) {\n+\t\t\treturn LogicalType::TIMESTAMP_TZ;\n+\t\t}\n+\t\treturn LogicalType::TIMESTAMP_S;\n+\t}\n+\tcase NumpyNullableType::DATETIME_US: {\n+\t\tif (col_type.has_timezone) {\n+\t\t\treturn LogicalType::TIMESTAMP_TZ;\n+\t\t}\n \t\treturn LogicalType::TIMESTAMP;\n-\tcase NumpyNullableType::DATETIME_TZ:\n-\t\treturn LogicalType::TIMESTAMP_TZ;\n+\t}\n \tdefault:\n \t\tthrow InternalException(\"No known conversion for NumpyNullableType '%d' to LogicalType\");\n \t}\ndiff --git a/tools/pythonpkg/src/pandas/analyzer.cpp b/tools/pythonpkg/src/pandas/analyzer.cpp\nindex 32ea4242f395..dafb5d05eaf8 100644\n--- a/tools/pythonpkg/src/pandas/analyzer.cpp\n+++ b/tools/pythonpkg/src/pandas/analyzer.cpp\n@@ -335,7 +335,7 @@ LogicalType PandasAnalyzer::GetItemType(py::object ele, bool &can_convert) {\n \t\tauto extended_type = ConvertNumpyType(ele.attr(\"dtype\"));\n \t\tLogicalType ltype;\n \t\tltype = NumpyToLogicalType(extended_type);\n-\t\tif (extended_type == NumpyNullableType::OBJECT) {\n+\t\tif (extended_type.type == NumpyNullableType::OBJECT) {\n \t\t\tLogicalType converted_type = InnerAnalyze(ele, can_convert, false, 1);\n \t\t\tif (can_convert) {\n \t\t\t\tltype = converted_type;\ndiff --git a/tools/pythonpkg/src/pandas/bind.cpp b/tools/pythonpkg/src/pandas/bind.cpp\nindex b7e1bf29c893..c4204ae2264e 100644\n--- a/tools/pythonpkg/src/pandas/bind.cpp\n+++ b/tools/pythonpkg/src/pandas/bind.cpp\n@@ -58,15 +58,15 @@ static LogicalType BindColumn(PandasBindColumn &column_p, PandasColumnBindData &\n \t\tbind_data.mask = make_uniq<RegisteredArray>(column.attr(\"array\").attr(\"_mask\"));\n \t}\n \n-\tif (bind_data.numpy_type == NumpyNullableType::CATEGORY) {\n+\tif (bind_data.numpy_type.type == NumpyNullableType::CATEGORY) {\n \t\t// for category types, we create an ENUM type for string or use the converted numpy type for the rest\n \t\tD_ASSERT(py::hasattr(column, \"cat\"));\n \t\tD_ASSERT(py::hasattr(column.attr(\"cat\"), \"categories\"));\n \t\tauto categories = py::array(column.attr(\"cat\").attr(\"categories\"));\n \t\tauto categories_pd_type = ConvertNumpyType(categories.attr(\"dtype\"));\n-\t\tif (categories_pd_type == NumpyNullableType::OBJECT) {\n+\t\tif (categories_pd_type.type == NumpyNullableType::OBJECT) {\n \t\t\t// Let's hope the object type is a string.\n-\t\t\tbind_data.numpy_type = NumpyNullableType::CATEGORY;\n+\t\t\tbind_data.numpy_type.type = NumpyNullableType::CATEGORY;\n \t\t\tauto enum_name = string(py::str(column_p.name));\n \t\t\tvector<string> enum_entries = py::cast<vector<string>>(categories);\n \t\t\tidx_t size = enum_entries.size();\n@@ -88,10 +88,10 @@ static LogicalType BindColumn(PandasBindColumn &column_p, PandasColumnBindData &\n \t\t\tbind_data.numpy_type = ConvertNumpyType(numpy_type);\n \t\t\tcolumn_type = NumpyToLogicalType(bind_data.numpy_type);\n \t\t}\n-\t} else if (bind_data.numpy_type == NumpyNullableType::FLOAT_16) {\n+\t} else if (bind_data.numpy_type.type == NumpyNullableType::FLOAT_16) {\n \t\tauto pandas_array = column.attr(\"array\");\n \t\tbind_data.pandas_col = make_uniq<PandasNumpyColumn>(py::array(column.attr(\"to_numpy\")(\"float32\")));\n-\t\tbind_data.numpy_type = NumpyNullableType::FLOAT_32;\n+\t\tbind_data.numpy_type.type = NumpyNullableType::FLOAT_32;\n \t\tcolumn_type = NumpyToLogicalType(bind_data.numpy_type);\n \t} else {\n \t\tauto pandas_array = column.attr(\"array\");\n@@ -108,7 +108,7 @@ static LogicalType BindColumn(PandasBindColumn &column_p, PandasColumnBindData &\n \t\tcolumn_type = NumpyToLogicalType(bind_data.numpy_type);\n \t}\n \t// Analyze the inner data type of the 'object' column\n-\tif (bind_data.numpy_type == NumpyNullableType::OBJECT) {\n+\tif (bind_data.numpy_type.type == NumpyNullableType::OBJECT) {\n \t\tPandasAnalyzer analyzer(config);\n \t\tif (analyzer.Analyze(column)) {\n \t\t\tcolumn_type = analyzer.AnalyzedType();\n",
  "test_patch": "diff --git a/tools/pythonpkg/tests/fast/api/test_dbapi00.py b/tools/pythonpkg/tests/fast/api/test_dbapi00.py\nindex f13f5079d711..28aa1044c978 100644\n--- a/tools/pythonpkg/tests/fast/api/test_dbapi00.py\n+++ b/tools/pythonpkg/tests/fast/api/test_dbapi00.py\n@@ -88,6 +88,8 @@ def test_numpy_selection(self, duckdb_cursor):\n \n     @pytest.mark.parametrize('pandas', [NumpyPandas(), ArrowPandas()])\n     def test_pandas_selection(self, duckdb_cursor, pandas):\n+        import datetime\n+\n         duckdb_cursor.execute('SELECT * FROM integers')\n         result = duckdb_cursor.fetchdf()\n         arr = numpy.ma.masked_array(numpy.arange(11))\n@@ -98,7 +100,18 @@ def test_pandas_selection(self, duckdb_cursor, pandas):\n \n         duckdb_cursor.execute('SELECT * FROM timestamps')\n         result = duckdb_cursor.fetchdf()\n-        df = pandas.DataFrame({'t': pandas.to_datetime(['1992-10-03 18:34:45', '2010-01-01 00:00:01', None])})\n+        df = pandas.DataFrame(\n+            {\n+                't': pandas.Series(\n+                    data=[\n+                        datetime.datetime(year=1992, month=10, day=3, hour=18, minute=34, second=45),\n+                        datetime.datetime(year=2010, month=1, day=1, hour=0, minute=0, second=1),\n+                        None,\n+                    ],\n+                    dtype='datetime64[us]',\n+                )\n+            }\n+        )\n         pandas.testing.assert_frame_equal(result, df)\n \n     # def test_numpy_creation(self, duckdb_cursor):\ndiff --git a/tools/pythonpkg/tests/fast/pandas/test_datetime_timestamp.py b/tools/pythonpkg/tests/fast/pandas/test_datetime_timestamp.py\nindex 76dcab868c82..a2592a886f44 100644\n--- a/tools/pythonpkg/tests/fast/pandas/test_datetime_timestamp.py\n+++ b/tools/pythonpkg/tests/fast/pandas/test_datetime_timestamp.py\n@@ -13,18 +13,40 @@ class TestDateTimeTimeStamp(object):\n     def test_timestamp_high(self, pandas):\n         duckdb_time = duckdb.query(\"SELECT '2260-01-01 23:59:00'::TIMESTAMP AS '0'\").df()\n         df_in = pandas.DataFrame(\n-            {0: pandas.Series(data=[datetime.datetime(year=2260, month=1, day=1, hour=23, minute=59)], dtype='object')}\n+            {\n+                0: pandas.Series(\n+                    data=[datetime.datetime(year=2260, month=1, day=1, hour=23, minute=59)],\n+                    dtype='datetime64[us]',\n+                )\n+            }\n         )\n         df_out = duckdb.query_df(df_in, \"df\", \"select * from df\").df()\n         pandas.testing.assert_frame_equal(df_out, duckdb_time)\n \n     @pytest.mark.parametrize('pandas', [NumpyPandas(), ArrowPandas()])\n     def test_timestamp_low(self, pandas):\n-        duckdb_time = duckdb.query(\"SELECT '1680-01-01 23:59:00'::TIMESTAMP AS '0'\").df()\n+        duckdb_time = duckdb.query(\n+            \"\"\"\n+            SELECT '1680-01-01 23:59:00.234243'::TIMESTAMP AS '0'\n+        \"\"\"\n+        ).df()\n         df_in = pandas.DataFrame(\n-            {0: pandas.Series(data=[datetime.datetime(year=1680, month=1, day=1, hour=23, minute=59)], dtype='object')}\n+            {\n+                '0': pandas.Series(\n+                    data=[\n+                        pandas.Timestamp(\n+                            datetime.datetime(year=1680, month=1, day=1, hour=23, minute=59, microsecond=234243),\n+                            unit='us',\n+                        )\n+                    ],\n+                    dtype='datetime64[us]',\n+                )\n+            }\n         )\n+        print('original:', duckdb_time['0'].dtype)\n+        print('df_in:', df_in['0'].dtype)\n         df_out = duckdb.query_df(df_in, \"df\", \"select * from df\").df()\n+        print('df_out:', df_out['0'].dtype)\n         pandas.testing.assert_frame_equal(df_out, duckdb_time)\n \n     @pytest.mark.skipif(\ndiff --git a/tools/pythonpkg/tests/fast/pandas/test_timestamp.py b/tools/pythonpkg/tests/fast/pandas/test_timestamp.py\nindex 72b1bb4fdff0..b704fa5d2815 100644\n--- a/tools/pythonpkg/tests/fast/pandas/test_timestamp.py\n+++ b/tools/pythonpkg/tests/fast/pandas/test_timestamp.py\n@@ -6,29 +6,44 @@\n \n \n class TestPandasTimestamps(object):\n-    def test_timestamp_types_roundtrip(self, duckdb_cursor):\n+    @pytest.mark.parametrize('unit', ['s', 'ms', 'us', 'ns'])\n+    def test_timestamp_types_roundtrip(self, unit):\n         d = {\n-            'a': [pd.Timestamp(datetime.datetime.now(), unit='s')],\n-            'b': [pd.Timestamp(datetime.datetime.now(), unit='ms')],\n-            'c': [pd.Timestamp(datetime.datetime.now(), unit='us')],\n-            'd': [pd.Timestamp(datetime.datetime.now(), unit='ns')],\n+            'time': pd.Series(\n+                [pd.Timestamp(datetime.datetime(2020, 6, 12, 14, 43, 24, 394587), unit=unit)],\n+                dtype=f'datetime64[{unit}]',\n+            )\n         }\n         df = pd.DataFrame(data=d)\n         df_from_duck = duckdb.from_df(df).df()\n         assert df_from_duck.equals(df)\n \n-    def test_timestamp_nulls(self, duckdb_cursor):\n+    @pytest.mark.parametrize('unit', ['s', 'ms', 'us', 'ns'])\n+    def test_timestamp_timezone_roundtrip(self, unit):\n+        conn = duckdb.connect()\n+        conn.execute(\"SET TimeZone =UTC\")\n         d = {\n-            'a': [pd.Timestamp(None, unit='s')],\n-            'b': [pd.Timestamp(None, unit='ms')],\n-            'c': [pd.Timestamp(None, unit='us')],\n-            'd': [pd.Timestamp(None, unit='ns')],\n+            'time': pd.Series(\n+                [pd.Timestamp(datetime.datetime(2020, 6, 12, 14, 43, 24, 394587), unit=unit, tz='UTC')],\n+                dtype=f'datetime64[{unit}, UTC]',\n+            )\n         }\n         df = pd.DataFrame(data=d)\n+\n+        # Our timezone aware type is in US (microseconds), when we scan a timestamp column that isn't US and has timezone info,\n+        # we convert the time unit to US\n+        expected = pd.DataFrame(data=d, dtype='datetime64[us, UTC]')\n+        df_from_duck = conn.from_df(df).df()\n+        assert df_from_duck.equals(expected)\n+\n+    @pytest.mark.parametrize('unit', ['s', 'ms', 'us', 'ns'])\n+    def test_timestamp_nulls(self, unit):\n+        d = {'time': pd.Series([pd.Timestamp(None, unit=unit)], dtype=f'datetime64[{unit}]')}\n+        df = pd.DataFrame(data=d)\n         df_from_duck = duckdb.from_df(df).df()\n         assert df_from_duck.equals(df)\n \n-    def test_timestamp_timedelta(self, duckdb_cursor):\n+    def test_timestamp_timedelta(self):\n         df = pd.DataFrame(\n             {\n                 'a': [pd.Timedelta(1, unit='s')],\n",
  "problem_statement": "Pandas DataFrame returns incorrect datetime values (date = epoch zero point / 1970-01-01)\n### What happens?\r\n\r\nI use duckdb to work with pandas.  I find duckdb return wrong datetime after execute sql on the DataFrame. \r\nThe following pandas DataFrame with name 'stdd' has a column 'datetime'\r\n```\r\n     datetime  voli\r\n0 2005-01-04   NaN\r\n1 2005-01-05   0.0\r\n2 2005-01-06   0.0\r\n3 2005-01-07   0.0\r\n4 2005-01-10   0.0\r\n```\r\nthe result of `con.execute(\"select * from stdd\").df()` is:\r\n```\r\n                     datetime  voli\r\n0 1970-01-01 00:00:01.104796   NaN\r\n1 1970-01-01 00:00:01.104883   0.0\r\n2 1970-01-01 00:00:01.104969   0.0\r\n3 1970-01-01 00:00:01.105056   0.0\r\n4 1970-01-01 00:00:01.105315   0.0\r\n```\r\nI have tried the latest master build version: 0.8.2-dev2850\r\n\r\n### To Reproduce\r\n\r\nNeed the pickle file to reproduce : [stdd.tar.gz](https://github.com/duckdb/duckdb/files/12356094/stdd.tar.gz)\r\nI save the pandas DataFrame 'stdd' in pickle file, and tar it for uploading policy.\r\n\r\n1. dowdload the gz file [stdd.tar.gz](https://github.com/duckdb/duckdb/files/12356094/stdd.tar.gz)\uff0cand tar it to pickle file\r\n```\r\ntar xzvf stdd.tar.gz\r\n```\r\n2. run the following python script to reproduce:\r\n```\r\nimport duckdb\r\nimport pickle\r\ncon=duckdb.connect()\r\nprint(\"duckdb version: \",duckdb.__version__)\r\n\r\nwith open(\"stdd.pk\",\"rb\") as f:\r\n    stdd=pickle.load(f)\r\n\r\nstdd_df=con.execute(\"select * from stdd\").df()\r\nprint(\"DataFrame stdd:\\n\",stdd)\r\nprint(\"DataFrame stdd from duckdb:\\n\",stdd_df)\r\n```\r\n3.  output:\r\n```\r\nduckdb version:  0.8.2-dev2850\r\nDataFrame stdd:\r\n   Paste\r\n0  Select All\r\n1\r\n2  How-to disable mouse\r\n3 2005-01-07   0.0\r\n4 2005-01-10   0.0\r\nDataFrame stdd from duckdb:\r\n                     datetime  voli\r\n0 1970-01-01 00:00:01.104796   NaN\r\n1 1970-01-01 00:00:01.104883   0.0\r\n2 1970-01-01 00:00:01.104969   0.0\r\n3 1970-01-01 00:00:01.105056   0.0\r\n4 1970-01-01 00:00:01.105315   0.0\r\n```\r\n\r\n### OS:\r\n\r\ndebian 11\r\n\r\n### DuckDB Version:\r\n\r\n0.8.2-dev2850\r\n\r\n### DuckDB Client:\r\n\r\nPython\r\n\r\n### Full Name:\r\n\r\nyang\r\n\r\n### Affiliation:\r\n\r\nqc\r\n\r\n### Have you tried this on the latest `master` branch?\r\n\r\nI have tested with a master build\r\n\r\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\r\n\r\n- [X] Yes, I have\n",
  "hints_text": "",
  "created_at": "2023-08-18T15:03:48Z"
}