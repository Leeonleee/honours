diff --git a/src/catalog/catalog_entry/table_catalog_entry.cpp b/src/catalog/catalog_entry/table_catalog_entry.cpp
index 4acb9d76f821..14e7c63bc81a 100644
--- a/src/catalog/catalog_entry/table_catalog_entry.cpp
+++ b/src/catalog/catalog_entry/table_catalog_entry.cpp
@@ -428,7 +428,14 @@ void TableCatalogEntry::Serialize(Serializer &serializer) {
 
 string TableCatalogEntry::ToSQL() {
 	std::stringstream ss;
-	ss << "CREATE TABLE " << KeywordHelper::WriteOptionallyQuoted(name) << "(";
+
+	ss << "CREATE TABLE ";
+
+	if (schema->name != DEFAULT_SCHEMA) {
+		ss << KeywordHelper::WriteOptionallyQuoted(schema->name) << ".";
+	}
+
+	ss << KeywordHelper::WriteOptionallyQuoted(name) << "(";
 
 	// find all columns that have NOT NULL specified, but are NOT primary key columns
 	unordered_set<idx_t> not_null_columns;
diff --git a/src/execution/operator/persistent/physical_export.cpp b/src/execution/operator/persistent/physical_export.cpp
index 3f7e17b09166..a554e01aceec 100644
--- a/src/execution/operator/persistent/physical_export.cpp
+++ b/src/execution/operator/persistent/physical_export.cpp
@@ -4,6 +4,7 @@
 #include "duckdb/common/file_system.hpp"
 #include "duckdb/catalog/catalog_entry/schema_catalog_entry.hpp"
 #include "duckdb/common/string_util.hpp"
+#include "duckdb/parser/keyword_helper.hpp"
 
 #include <algorithm>
 #include <sstream>
@@ -36,17 +37,16 @@ static void WriteValueAsSQL(stringstream &ss, Value &val) {
 }
 
 static void WriteCopyStatement(FileSystem &fs, stringstream &ss, TableCatalogEntry *table, CopyInfo &info,
-                               const CopyFunction &function) {
-	string table_file_path;
+                               ExportedTableData &exported_table, CopyFunction const &function) {
 	ss << "COPY ";
-	if (table->schema->name != DEFAULT_SCHEMA) {
-		table_file_path = fs.JoinPath(
-		    info.file_path, StringUtil::Format("%s.%s.%s", table->schema->name, table->name, function.extension));
-		ss << table->schema->name << ".";
-	} else {
-		table_file_path = fs.JoinPath(info.file_path, StringUtil::Format("%s.%s", table->name, function.extension));
+
+	if (exported_table.schema_name != DEFAULT_SCHEMA) {
+		ss << KeywordHelper::WriteOptionallyQuoted(exported_table.schema_name) << ".";
 	}
-	ss << table->name << " FROM '" << table_file_path << "' (";
+
+	ss << KeywordHelper::WriteOptionallyQuoted(exported_table.table_name) << " FROM '" << exported_table.file_path
+	   << "' (";
+
 	// write the copy options
 	ss << "FORMAT '" << info.format << "'";
 	if (info.format == "csv") {
@@ -118,8 +118,10 @@ void PhysicalExport::GetChunkInternal(ExecutionContext &context, DataChunk &chun
 	// write the load.sql file
 	// for every table, we write COPY INTO statement with the specified options
 	stringstream load_ss;
-	for (auto &table : tables) {
-		WriteCopyStatement(fs, load_ss, (TableCatalogEntry *)table, *info, function);
+	for (auto const &kv : exported_tables.data) {
+		auto table = kv.first;
+		auto exported_table_info = kv.second;
+		WriteCopyStatement(fs, load_ss, table, *info, exported_table_info, function);
 	}
 	WriteStringStreamToFile(fs, load_ss, fs.JoinPath(info->file_path, "load.sql"));
 	state->finished = true;
diff --git a/src/execution/physical_plan/plan_export.cpp b/src/execution/physical_plan/plan_export.cpp
index a832692a1bbb..a4141c557f9e 100644
--- a/src/execution/physical_plan/plan_export.cpp
+++ b/src/execution/physical_plan/plan_export.cpp
@@ -5,7 +5,8 @@
 namespace duckdb {
 
 unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalExport &op) {
-	auto export_node = make_unique<PhysicalExport>(op.types, op.function, move(op.copy_info), op.estimated_cardinality);
+	auto export_node = make_unique<PhysicalExport>(op.types, op.function, move(op.copy_info), op.estimated_cardinality,
+	                                               op.exported_tables);
 	// plan the underlying copy statements, if any
 	if (!op.children.empty()) {
 		auto plan = CreatePlan(*op.children[0]);
diff --git a/src/include/duckdb/execution/operator/persistent/physical_export.hpp b/src/include/duckdb/execution/operator/persistent/physical_export.hpp
index f36ed9378e5b..79a175445357 100644
--- a/src/include/duckdb/execution/operator/persistent/physical_export.hpp
+++ b/src/include/duckdb/execution/operator/persistent/physical_export.hpp
@@ -13,21 +13,24 @@
 #include "duckdb/execution/physical_operator.hpp"
 #include "duckdb/function/copy_function.hpp"
 #include "duckdb/parser/parsed_data/copy_info.hpp"
+#include "duckdb/parser/parsed_data/exported_table_data.hpp"
 
 namespace duckdb {
 //! Parse a file from disk using a specified copy function and return the set of chunks retrieved from the file
 class PhysicalExport : public PhysicalOperator {
 public:
 	PhysicalExport(vector<LogicalType> types, CopyFunction function, unique_ptr<CopyInfo> info,
-	               idx_t estimated_cardinality)
+	               idx_t estimated_cardinality, BoundExportData exported_tables)
 	    : PhysicalOperator(PhysicalOperatorType::EXPORT, move(types), estimated_cardinality),
-	      function(std::move(function)), info(move(info)) {
+	      function(std::move(function)), info(move(info)), exported_tables(move(exported_tables)) {
 	}
 
 	//! The copy function to use to read the file
 	CopyFunction function;
 	//! The binding info containing the set of options for reading the file
 	unique_ptr<CopyInfo> info;
+	//! The table info for each table that will be exported
+	BoundExportData exported_tables;
 
 public:
 	void GetChunkInternal(ExecutionContext &context, DataChunk &chunk, PhysicalOperatorState *state) const override;
diff --git a/src/include/duckdb/parser/parsed_data/exported_table_data.hpp b/src/include/duckdb/parser/parsed_data/exported_table_data.hpp
new file mode 100644
index 000000000000..6f8295881cb9
--- /dev/null
+++ b/src/include/duckdb/parser/parsed_data/exported_table_data.hpp
@@ -0,0 +1,31 @@
+//===----------------------------------------------------------------------===//
+//                         DuckDB
+//
+// duckdb/parser/parsed_data/export_table_data.hpp
+//
+//
+//===----------------------------------------------------------------------===//
+
+#pragma once
+
+#include "duckdb/parser/parsed_data/parse_info.hpp"
+#include "duckdb/common/types/value.hpp"
+
+namespace duckdb {
+
+struct ExportedTableData {
+	//! Name of the exported table
+	string table_name;
+
+	//! Name of the schema
+	string schema_name;
+
+	//! Path to be exported
+	string file_path;
+};
+
+struct BoundExportData : public ParseInfo {
+	unordered_map<TableCatalogEntry *, ExportedTableData> data;
+};
+
+} // namespace duckdb
diff --git a/src/include/duckdb/planner/operator/logical_export.hpp b/src/include/duckdb/planner/operator/logical_export.hpp
index 4f4d06038c86..291561fedfd6 100644
--- a/src/include/duckdb/planner/operator/logical_export.hpp
+++ b/src/include/duckdb/planner/operator/logical_export.hpp
@@ -9,6 +9,7 @@
 #pragma once
 
 #include "duckdb/parser/parsed_data/copy_info.hpp"
+#include "duckdb/parser/parsed_data/exported_table_data.hpp"
 #include "duckdb/planner/logical_operator.hpp"
 #include "duckdb/function/copy_function.hpp"
 
@@ -16,11 +17,13 @@ namespace duckdb {
 
 class LogicalExport : public LogicalOperator {
 public:
-	LogicalExport(CopyFunction function, unique_ptr<CopyInfo> copy_info)
-	    : LogicalOperator(LogicalOperatorType::LOGICAL_EXPORT), function(function), copy_info(move(copy_info)) {
+	LogicalExport(CopyFunction function, unique_ptr<CopyInfo> copy_info, BoundExportData exported_tables)
+	    : LogicalOperator(LogicalOperatorType::LOGICAL_EXPORT), function(function), copy_info(move(copy_info)),
+	      exported_tables(move(exported_tables)) {
 	}
 	CopyFunction function;
 	unique_ptr<CopyInfo> copy_info;
+	BoundExportData exported_tables;
 
 protected:
 	void ResolveTypes() override {
diff --git a/src/planner/binder/statement/bind_export.cpp b/src/planner/binder/statement/bind_export.cpp
index b361ebde5d6a..48250de65a75 100644
--- a/src/planner/binder/statement/bind_export.cpp
+++ b/src/planner/binder/statement/bind_export.cpp
@@ -8,11 +8,37 @@
 #include "duckdb/main/database.hpp"
 #include "duckdb/common/file_system.hpp"
 #include "duckdb/planner/operator/logical_set_operation.hpp"
+#include "duckdb/parser/parsed_data/exported_table_data.hpp"
+
 #include "duckdb/common/string_util.hpp"
 #include <algorithm>
 
 namespace duckdb {
 
+//! Sanitizes a string to have only low case chars and underscores
+string SanitizeExportIdentifier(const string &str) {
+	// Copy the original string to result
+	string result(str);
+
+	for (idx_t i = 0; i < str.length(); ++i) {
+		auto c = str[i];
+		if (c >= 'a' && c <= 'z') {
+			// If it is lower case just continue
+			continue;
+		}
+
+		if (c >= 'A' && c <= 'Z') {
+			// To lowercase
+			result[i] = tolower(c);
+		} else {
+			// Substitute to underscore
+			result[i] = '_';
+		}
+	}
+
+	return result;
+}
+
 BoundStatement Binder::Bind(ExportStatement &stmt) {
 	// COPY TO a file
 	auto &config = DBConfig::GetConfig(context);
@@ -44,24 +70,40 @@ BoundStatement Binder::Bind(ExportStatement &stmt) {
 	// now generate the COPY statements for each of the tables
 	auto &fs = FileSystem::GetFileSystem(context);
 	unique_ptr<LogicalOperator> child_operator;
+
+	BoundExportData exported_tables;
+
+	idx_t id = 0; // Id for table
 	for (auto &table : tables) {
 		auto info = make_unique<CopyInfo>();
 		// we copy the options supplied to the EXPORT
 		info->format = stmt.info->format;
 		info->options = stmt.info->options;
 		// set up the file name for the COPY TO
+
+		auto exported_data = ExportedTableData();
 		if (table->schema->name == DEFAULT_SCHEMA) {
-			info->file_path = fs.JoinPath(stmt.info->file_path,
-			                              StringUtil::Format("%s.%s", table->name, copy_function->function.extension));
-		} else {
 			info->file_path =
-			    fs.JoinPath(stmt.info->file_path, StringUtil::Format("%s.%s.%s", table->schema->name, table->name,
-			                                                         copy_function->function.extension));
+			    fs.JoinPath(stmt.info->file_path,
+			                StringUtil::Format("%s_%s.%s", to_string(id), SanitizeExportIdentifier(table->name),
+			                                   copy_function->function.extension));
+		} else {
+			info->file_path = fs.JoinPath(
+			    stmt.info->file_path,
+			    StringUtil::Format("%s_%s_%s.%s", SanitizeExportIdentifier(table->schema->name), to_string(id),
+			                       SanitizeExportIdentifier(table->name), copy_function->function.extension));
 		}
 		info->is_from = false;
 		info->schema = table->schema->name;
 		info->table = table->name;
 
+		exported_data.table_name = info->table;
+		exported_data.schema_name = info->schema;
+		exported_data.file_path = info->file_path;
+
+		exported_tables.data[table] = exported_data;
+		id++;
+
 		// generate the copy statement and bind it
 		CopyStatement copy_stmt;
 		copy_stmt.info = move(info);
@@ -86,7 +128,7 @@ BoundStatement Binder::Bind(ExportStatement &stmt) {
 	}
 
 	// create the export node
-	auto export_node = make_unique<LogicalExport>(copy_function->function, move(stmt.info));
+	auto export_node = make_unique<LogicalExport>(copy_function->function, move(stmt.info), exported_tables);
 
 	if (child_operator) {
 		export_node->children.push_back(move(child_operator));
