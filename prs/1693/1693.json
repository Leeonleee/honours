{
  "repo": "duckdb/duckdb",
  "pull_number": 1693,
  "instance_id": "duckdb__duckdb-1693",
  "issue_numbers": [
    "1690"
  ],
  "base_commit": "0109d4301b8ed005ca5396c177cf5ef36bef5274",
  "patch": "diff --git a/src/catalog/catalog_entry/table_catalog_entry.cpp b/src/catalog/catalog_entry/table_catalog_entry.cpp\nindex 4acb9d76f821..14e7c63bc81a 100644\n--- a/src/catalog/catalog_entry/table_catalog_entry.cpp\n+++ b/src/catalog/catalog_entry/table_catalog_entry.cpp\n@@ -428,7 +428,14 @@ void TableCatalogEntry::Serialize(Serializer &serializer) {\n \n string TableCatalogEntry::ToSQL() {\n \tstd::stringstream ss;\n-\tss << \"CREATE TABLE \" << KeywordHelper::WriteOptionallyQuoted(name) << \"(\";\n+\n+\tss << \"CREATE TABLE \";\n+\n+\tif (schema->name != DEFAULT_SCHEMA) {\n+\t\tss << KeywordHelper::WriteOptionallyQuoted(schema->name) << \".\";\n+\t}\n+\n+\tss << KeywordHelper::WriteOptionallyQuoted(name) << \"(\";\n \n \t// find all columns that have NOT NULL specified, but are NOT primary key columns\n \tunordered_set<idx_t> not_null_columns;\ndiff --git a/src/execution/operator/persistent/physical_export.cpp b/src/execution/operator/persistent/physical_export.cpp\nindex 3f7e17b09166..a554e01aceec 100644\n--- a/src/execution/operator/persistent/physical_export.cpp\n+++ b/src/execution/operator/persistent/physical_export.cpp\n@@ -4,6 +4,7 @@\n #include \"duckdb/common/file_system.hpp\"\n #include \"duckdb/catalog/catalog_entry/schema_catalog_entry.hpp\"\n #include \"duckdb/common/string_util.hpp\"\n+#include \"duckdb/parser/keyword_helper.hpp\"\n \n #include <algorithm>\n #include <sstream>\n@@ -36,17 +37,16 @@ static void WriteValueAsSQL(stringstream &ss, Value &val) {\n }\n \n static void WriteCopyStatement(FileSystem &fs, stringstream &ss, TableCatalogEntry *table, CopyInfo &info,\n-                               const CopyFunction &function) {\n-\tstring table_file_path;\n+                               ExportedTableData &exported_table, CopyFunction const &function) {\n \tss << \"COPY \";\n-\tif (table->schema->name != DEFAULT_SCHEMA) {\n-\t\ttable_file_path = fs.JoinPath(\n-\t\t    info.file_path, StringUtil::Format(\"%s.%s.%s\", table->schema->name, table->name, function.extension));\n-\t\tss << table->schema->name << \".\";\n-\t} else {\n-\t\ttable_file_path = fs.JoinPath(info.file_path, StringUtil::Format(\"%s.%s\", table->name, function.extension));\n+\n+\tif (exported_table.schema_name != DEFAULT_SCHEMA) {\n+\t\tss << KeywordHelper::WriteOptionallyQuoted(exported_table.schema_name) << \".\";\n \t}\n-\tss << table->name << \" FROM '\" << table_file_path << \"' (\";\n+\n+\tss << KeywordHelper::WriteOptionallyQuoted(exported_table.table_name) << \" FROM '\" << exported_table.file_path\n+\t   << \"' (\";\n+\n \t// write the copy options\n \tss << \"FORMAT '\" << info.format << \"'\";\n \tif (info.format == \"csv\") {\n@@ -118,8 +118,10 @@ void PhysicalExport::GetChunkInternal(ExecutionContext &context, DataChunk &chun\n \t// write the load.sql file\n \t// for every table, we write COPY INTO statement with the specified options\n \tstringstream load_ss;\n-\tfor (auto &table : tables) {\n-\t\tWriteCopyStatement(fs, load_ss, (TableCatalogEntry *)table, *info, function);\n+\tfor (auto const &kv : exported_tables.data) {\n+\t\tauto table = kv.first;\n+\t\tauto exported_table_info = kv.second;\n+\t\tWriteCopyStatement(fs, load_ss, table, *info, exported_table_info, function);\n \t}\n \tWriteStringStreamToFile(fs, load_ss, fs.JoinPath(info->file_path, \"load.sql\"));\n \tstate->finished = true;\ndiff --git a/src/execution/physical_plan/plan_export.cpp b/src/execution/physical_plan/plan_export.cpp\nindex a832692a1bbb..a4141c557f9e 100644\n--- a/src/execution/physical_plan/plan_export.cpp\n+++ b/src/execution/physical_plan/plan_export.cpp\n@@ -5,7 +5,8 @@\n namespace duckdb {\n \n unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalExport &op) {\n-\tauto export_node = make_unique<PhysicalExport>(op.types, op.function, move(op.copy_info), op.estimated_cardinality);\n+\tauto export_node = make_unique<PhysicalExport>(op.types, op.function, move(op.copy_info), op.estimated_cardinality,\n+\t                                               op.exported_tables);\n \t// plan the underlying copy statements, if any\n \tif (!op.children.empty()) {\n \t\tauto plan = CreatePlan(*op.children[0]);\ndiff --git a/src/include/duckdb/execution/operator/persistent/physical_export.hpp b/src/include/duckdb/execution/operator/persistent/physical_export.hpp\nindex f36ed9378e5b..79a175445357 100644\n--- a/src/include/duckdb/execution/operator/persistent/physical_export.hpp\n+++ b/src/include/duckdb/execution/operator/persistent/physical_export.hpp\n@@ -13,21 +13,24 @@\n #include \"duckdb/execution/physical_operator.hpp\"\n #include \"duckdb/function/copy_function.hpp\"\n #include \"duckdb/parser/parsed_data/copy_info.hpp\"\n+#include \"duckdb/parser/parsed_data/exported_table_data.hpp\"\n \n namespace duckdb {\n //! Parse a file from disk using a specified copy function and return the set of chunks retrieved from the file\n class PhysicalExport : public PhysicalOperator {\n public:\n \tPhysicalExport(vector<LogicalType> types, CopyFunction function, unique_ptr<CopyInfo> info,\n-\t               idx_t estimated_cardinality)\n+\t               idx_t estimated_cardinality, BoundExportData exported_tables)\n \t    : PhysicalOperator(PhysicalOperatorType::EXPORT, move(types), estimated_cardinality),\n-\t      function(std::move(function)), info(move(info)) {\n+\t      function(std::move(function)), info(move(info)), exported_tables(move(exported_tables)) {\n \t}\n \n \t//! The copy function to use to read the file\n \tCopyFunction function;\n \t//! The binding info containing the set of options for reading the file\n \tunique_ptr<CopyInfo> info;\n+\t//! The table info for each table that will be exported\n+\tBoundExportData exported_tables;\n \n public:\n \tvoid GetChunkInternal(ExecutionContext &context, DataChunk &chunk, PhysicalOperatorState *state) const override;\ndiff --git a/src/include/duckdb/parser/parsed_data/exported_table_data.hpp b/src/include/duckdb/parser/parsed_data/exported_table_data.hpp\nnew file mode 100644\nindex 000000000000..6f8295881cb9\n--- /dev/null\n+++ b/src/include/duckdb/parser/parsed_data/exported_table_data.hpp\n@@ -0,0 +1,31 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/parser/parsed_data/export_table_data.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#pragma once\n+\n+#include \"duckdb/parser/parsed_data/parse_info.hpp\"\n+#include \"duckdb/common/types/value.hpp\"\n+\n+namespace duckdb {\n+\n+struct ExportedTableData {\n+\t//! Name of the exported table\n+\tstring table_name;\n+\n+\t//! Name of the schema\n+\tstring schema_name;\n+\n+\t//! Path to be exported\n+\tstring file_path;\n+};\n+\n+struct BoundExportData : public ParseInfo {\n+\tunordered_map<TableCatalogEntry *, ExportedTableData> data;\n+};\n+\n+} // namespace duckdb\ndiff --git a/src/include/duckdb/planner/operator/logical_export.hpp b/src/include/duckdb/planner/operator/logical_export.hpp\nindex 4f4d06038c86..291561fedfd6 100644\n--- a/src/include/duckdb/planner/operator/logical_export.hpp\n+++ b/src/include/duckdb/planner/operator/logical_export.hpp\n@@ -9,6 +9,7 @@\n #pragma once\n \n #include \"duckdb/parser/parsed_data/copy_info.hpp\"\n+#include \"duckdb/parser/parsed_data/exported_table_data.hpp\"\n #include \"duckdb/planner/logical_operator.hpp\"\n #include \"duckdb/function/copy_function.hpp\"\n \n@@ -16,11 +17,13 @@ namespace duckdb {\n \n class LogicalExport : public LogicalOperator {\n public:\n-\tLogicalExport(CopyFunction function, unique_ptr<CopyInfo> copy_info)\n-\t    : LogicalOperator(LogicalOperatorType::LOGICAL_EXPORT), function(function), copy_info(move(copy_info)) {\n+\tLogicalExport(CopyFunction function, unique_ptr<CopyInfo> copy_info, BoundExportData exported_tables)\n+\t    : LogicalOperator(LogicalOperatorType::LOGICAL_EXPORT), function(function), copy_info(move(copy_info)),\n+\t      exported_tables(move(exported_tables)) {\n \t}\n \tCopyFunction function;\n \tunique_ptr<CopyInfo> copy_info;\n+\tBoundExportData exported_tables;\n \n protected:\n \tvoid ResolveTypes() override {\ndiff --git a/src/planner/binder/statement/bind_export.cpp b/src/planner/binder/statement/bind_export.cpp\nindex b361ebde5d6a..48250de65a75 100644\n--- a/src/planner/binder/statement/bind_export.cpp\n+++ b/src/planner/binder/statement/bind_export.cpp\n@@ -8,11 +8,37 @@\n #include \"duckdb/main/database.hpp\"\n #include \"duckdb/common/file_system.hpp\"\n #include \"duckdb/planner/operator/logical_set_operation.hpp\"\n+#include \"duckdb/parser/parsed_data/exported_table_data.hpp\"\n+\n #include \"duckdb/common/string_util.hpp\"\n #include <algorithm>\n \n namespace duckdb {\n \n+//! Sanitizes a string to have only low case chars and underscores\n+string SanitizeExportIdentifier(const string &str) {\n+\t// Copy the original string to result\n+\tstring result(str);\n+\n+\tfor (idx_t i = 0; i < str.length(); ++i) {\n+\t\tauto c = str[i];\n+\t\tif (c >= 'a' && c <= 'z') {\n+\t\t\t// If it is lower case just continue\n+\t\t\tcontinue;\n+\t\t}\n+\n+\t\tif (c >= 'A' && c <= 'Z') {\n+\t\t\t// To lowercase\n+\t\t\tresult[i] = tolower(c);\n+\t\t} else {\n+\t\t\t// Substitute to underscore\n+\t\t\tresult[i] = '_';\n+\t\t}\n+\t}\n+\n+\treturn result;\n+}\n+\n BoundStatement Binder::Bind(ExportStatement &stmt) {\n \t// COPY TO a file\n \tauto &config = DBConfig::GetConfig(context);\n@@ -44,24 +70,40 @@ BoundStatement Binder::Bind(ExportStatement &stmt) {\n \t// now generate the COPY statements for each of the tables\n \tauto &fs = FileSystem::GetFileSystem(context);\n \tunique_ptr<LogicalOperator> child_operator;\n+\n+\tBoundExportData exported_tables;\n+\n+\tidx_t id = 0; // Id for table\n \tfor (auto &table : tables) {\n \t\tauto info = make_unique<CopyInfo>();\n \t\t// we copy the options supplied to the EXPORT\n \t\tinfo->format = stmt.info->format;\n \t\tinfo->options = stmt.info->options;\n \t\t// set up the file name for the COPY TO\n+\n+\t\tauto exported_data = ExportedTableData();\n \t\tif (table->schema->name == DEFAULT_SCHEMA) {\n-\t\t\tinfo->file_path = fs.JoinPath(stmt.info->file_path,\n-\t\t\t                              StringUtil::Format(\"%s.%s\", table->name, copy_function->function.extension));\n-\t\t} else {\n \t\t\tinfo->file_path =\n-\t\t\t    fs.JoinPath(stmt.info->file_path, StringUtil::Format(\"%s.%s.%s\", table->schema->name, table->name,\n-\t\t\t                                                         copy_function->function.extension));\n+\t\t\t    fs.JoinPath(stmt.info->file_path,\n+\t\t\t                StringUtil::Format(\"%s_%s.%s\", to_string(id), SanitizeExportIdentifier(table->name),\n+\t\t\t                                   copy_function->function.extension));\n+\t\t} else {\n+\t\t\tinfo->file_path = fs.JoinPath(\n+\t\t\t    stmt.info->file_path,\n+\t\t\t    StringUtil::Format(\"%s_%s_%s.%s\", SanitizeExportIdentifier(table->schema->name), to_string(id),\n+\t\t\t                       SanitizeExportIdentifier(table->name), copy_function->function.extension));\n \t\t}\n \t\tinfo->is_from = false;\n \t\tinfo->schema = table->schema->name;\n \t\tinfo->table = table->name;\n \n+\t\texported_data.table_name = info->table;\n+\t\texported_data.schema_name = info->schema;\n+\t\texported_data.file_path = info->file_path;\n+\n+\t\texported_tables.data[table] = exported_data;\n+\t\tid++;\n+\n \t\t// generate the copy statement and bind it\n \t\tCopyStatement copy_stmt;\n \t\tcopy_stmt.info = move(info);\n@@ -86,7 +128,7 @@ BoundStatement Binder::Bind(ExportStatement &stmt) {\n \t}\n \n \t// create the export node\n-\tauto export_node = make_unique<LogicalExport>(copy_function->function, move(stmt.info));\n+\tauto export_node = make_unique<LogicalExport>(copy_function->function, move(stmt.info), exported_tables);\n \n \tif (child_operator) {\n \t\texport_node->children.push_back(move(child_operator));\n",
  "test_patch": "diff --git a/test/sql/export/export_database.test b/test/sql/export/export_database.test\nindex a5ca8502e9cc..73eddaa2794d 100644\n--- a/test/sql/export/export_database.test\n+++ b/test/sql/export/export_database.test\n@@ -19,9 +19,35 @@ INSERT INTO integers VALUES (1, 3), (4, 2), (NULL, 1)\n statement ok\n INSERT INTO strings VALUES ('NULL', DATE '1992-01-01'), (NULL, DATE '1993-01-01');\n \n+statement ok\n+CREATE TABLE \"table.with-symbols\"(i INTEGER)\n+\n+statement ok\n+INSERT INTO \"table.with-symbols\" VALUES (1), (4), (NULL)\n+\n+statement ok\n+CREATE TABLE \"table \"\".\" ( \"col \"\".\" TEXT)\n+\n+statement ok\n+INSERT INTO \"table \"\".\" (\"col \"\".\") VALUES ('quote_escaped_quote_''')\n+\n+statement ok\n+CREATE TABLE \"SAME_NAME\"(i INTEGER, j INTEGER);\n+\n+statement ok\n+CREATE TABLE \"same_name\"(i INTEGER, j INTEGER);\n+\n+statement ok\n+INSERT INTO \"SAME_NAME\" VALUES (1, 1), (2, 2)\n+\n+statement ok\n+INSERT INTO \"same_name\" VALUES (3, 3), (4, 4)\n+\n statement ok\n CREATE VIEW v1 AS SELECT * FROM integers WHERE i>3; --\n CREATE VIEW v2 AS SELECT * FROM integers WHERE i < 3;\n+CREATE VIEW \"view.with-symbols\" AS SELECT * FROM \"table.with-symbols\" WHERE i < 3;\n+CREATE VIEW \"view \"\".\" AS SELECT * FROM \"table.with-symbols\" WHERE i < 3;\n \n statement ok\n CREATE VIEW v3 AS SELECT * FROM integers WHERE i IS NULL --\n@@ -68,6 +94,75 @@ SELECT * FROM v3 ORDER BY 1\n ----\n NULL\t1\n \n+query I\n+SELECT * FROM \"table.with-symbols\" ORDER BY 1\n+----\n+NULL\n+1\n+4\n+\n+query I\n+SELECT * FROM \"view.with-symbols\" ORDER BY 1\n+----\n+1\n+\n+\n+query TT\n+SELECT \"table \"\".\".\"col \"\".\", \"col \"\".\" FROM \"table \"\".\";\n+----\n+quote_escaped_quote_'\tquote_escaped_quote_'\n+\n+query I\n+SELECT * FROM \"view \"\".\" ORDER BY 1\n+----\n+1\n+\n+query II\n+SELECT * FROM \"SAME_NAME\" ORDER BY i\n+----\n+1\t1\n+2\t2\n+\n+query II\n+SELECT * FROM \"same_name\" ORDER BY i\n+----\n+3\t3\n+4\t4\n+\n+statement ok\n+CREATE SCHEMA s1;\n+CREATE SCHEMA s2;\n+\n+\n+statement ok\n+CREATE TABLE table01(i INTEGER, j INTEGER);\n+CREATE TABLE s1.table01(i INTEGER, j INTEGER);\n+CREATE TABLE s2.table01(i INTEGER, j INTEGER);\n+\n+statement ok\n+INSERT INTO table01 VALUES (1, 1), (2, 2);\n+INSERT INTO s1.table01 VALUES (3, 3), (4, 4);\n+INSERT INTO s2.table01 VALUES (5, 5), (6, 6);\n+\n+\n+query II\n+SELECT * FROM table01 ORDER BY i;\n+----\n+1\t1\n+2\t2\n+\n+query II\n+SELECT * FROM s1.table01 ORDER BY i;\n+----\n+3\t3\n+4\t4\n+\n+query II\n+SELECT * FROM s2.table01 ORDER BY i;\n+----\n+5\t5\n+6\t6\n+\n # now export the db\n statement ok\n EXPORT DATABASE '__TEST_DIR__/export_test' (FORMAT CSV)\n@@ -113,6 +208,58 @@ SELECT nextval('seq')\n ----\n 2\n \n+query I\n+SELECT * FROM \"table.with-symbols\" ORDER BY 1\n+----\n+NULL\n+1\n+4\n+\n+query I\n+SELECT * FROM \"view.with-symbols\" ORDER BY 1\n+----\n+1\n+\n+query TT\n+SELECT \"table \"\".\".\"col \"\".\", \"col \"\".\" FROM \"table \"\".\";\n+----\n+quote_escaped_quote_'\tquote_escaped_quote_'\n+\n+query I\n+SELECT * FROM \"view \"\".\" ORDER BY 1\n+----\n+1\n+\n+query II\n+SELECT * FROM \"SAME_NAME\" ORDER BY i\n+----\n+1\t1\n+2\t2\n+\n+query II\n+SELECT * FROM \"same_name\" ORDER BY i\n+----\n+3\t3\n+4\t4\n+\n+query II\n+SELECT * FROM table01 ORDER BY i;\n+----\n+1\t1\n+2\t2\n+\n+query II\n+SELECT * FROM s1.table01 ORDER BY i;\n+----\n+3\t3\n+4\t4\n+\n+query II\n+SELECT * FROM s2.table01 ORDER BY i;\n+----\n+5\t5\n+6\t6\n+\n # verify that constraints are still there\n statement error\n INSERT INTO integers VALUES (5, 6)\n",
  "problem_statement": "Import database fails when table's name have '.' or '-'\n**What does happen?**\r\nFails to import a database created via the export command. This happens when the exported table has some symbols in its name (like . or -).\r\n\r\n**What should happen?**\r\nGiven that DuckDB accepts creating these tables it also should be able to load tables with symbol when using EXPORT + IMPORT.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior. Bonus points if those are only SQL queries.\r\n1. `duckdb original_db`\r\n2. CREATE TABLE \"a-1\"(id int);\r\n3. INSERT INTO \"a-1\" VALUES (1);\r\n4. EXPORT DATABASE 'exported';\r\n5. .quit\r\n6. `duckdb imported`\r\n7. IMPORT DATABASE 'exported';\r\n```\r\nError: Parser Error: syntax error at or near \"-\"\r\nLINE 7: COPY a-1...\r\n```\r\n\r\n**Environment (please complete the following information):**\r\n - OS: macOS Big Sur 11.2.3\r\n - DuckDB Version: master\r\n\r\n**Before submitting**\r\n- [X] Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\r\n- [X] Have you tried this on the latest `master` branch? In case you cannot compile, you may find some binaries here: https://github.com/duckdb/duckdb/releases/tag/master-builds\r\n\n",
  "hints_text": "Looks some quotes are missing in the export. Happy to review a PR.",
  "created_at": "2021-04-29T14:31:36Z"
}