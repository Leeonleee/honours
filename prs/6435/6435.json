{
  "repo": "duckdb/duckdb",
  "pull_number": 6435,
  "instance_id": "duckdb__duckdb-6435",
  "issue_numbers": [
    "6284"
  ],
  "base_commit": "baf04ba00975fb8eff8f49206d0e3095836be326",
  "patch": "diff --git a/src/execution/physical_operator.cpp b/src/execution/physical_operator.cpp\nindex 395577444606..e52a25840c8e 100644\n--- a/src/execution/physical_operator.cpp\n+++ b/src/execution/physical_operator.cpp\n@@ -252,15 +252,15 @@ OperatorResultType CachingPhysicalOperator::Execute(ExecutionContext &context, D\n \tif (!state.initialized) {\n \t\tstate.initialized = true;\n \t\tstate.can_cache_chunk = true;\n+\n \t\tif (!context.pipeline || !caching_supported) {\n \t\t\tstate.can_cache_chunk = false;\n-\t\t}\n-\n-\t\tif (context.pipeline->GetSink() && context.pipeline->GetSink()->RequiresBatchIndex()) {\n+\t\t} else if (!context.pipeline->GetSink()) {\n+\t\t\t// Disabling for pipelines without Sink, i.e. when pulling\n \t\t\tstate.can_cache_chunk = false;\n-\t\t}\n-\n-\t\tif (context.pipeline->IsOrderDependent()) {\n+\t\t} else if (context.pipeline->GetSink()->RequiresBatchIndex()) {\n+\t\t\tstate.can_cache_chunk = false;\n+\t\t} else if (context.pipeline->IsOrderDependent()) {\n \t\t\tstate.can_cache_chunk = false;\n \t\t}\n \t}\ndiff --git a/src/include/duckdb/parallel/pipeline_executor.hpp b/src/include/duckdb/parallel/pipeline_executor.hpp\nindex 94425d85ca3c..f07e0b0e0932 100644\n--- a/src/include/duckdb/parallel/pipeline_executor.hpp\n+++ b/src/include/duckdb/parallel/pipeline_executor.hpp\n@@ -69,13 +69,6 @@ class PipelineExecutor {\n \t//! The final chunk used for moving data into the sink\n \tDataChunk final_chunk;\n \n-\t//! Indicates that the first non-finished operator in the pipeline with RequireFinalExecute has some pending result\n-\tbool pending_final_execute = false;\n-\t//! The OperatorFinalizeResultType corresponding to the currently pending final_execute result\n-\tOperatorFinalizeResultType cached_final_execute_result;\n-\t//! Source has been exhausted\n-\tbool source_empty = false;\n-\n \t//! The operators that are not yet finished executing and have data remaining\n \t//! If the stack of in_process_operators is empty, we fetch from the source instead\n \tstack<idx_t> in_process_operators;\ndiff --git a/src/parallel/pipeline_executor.cpp b/src/parallel/pipeline_executor.cpp\nindex b37b4623752e..415af0b220c9 100644\n--- a/src/parallel/pipeline_executor.cpp\n+++ b/src/parallel/pipeline_executor.cpp\n@@ -114,52 +114,6 @@ OperatorResultType PipelineExecutor::ExecutePushInternal(DataChunk &input, idx_t\n \t}\n }\n \n-// Pull a single DataChunk from the pipeline by flushing any operators holding cached output\n-void PipelineExecutor::FlushCachingOperatorsPull(DataChunk &result) {\n-\tidx_t start_idx = IsFinished() ? idx_t(finished_processing_idx) : 0;\n-\tidx_t op_idx = start_idx;\n-\twhile (op_idx < pipeline.operators.size()) {\n-\t\tif (!pipeline.operators[op_idx]->RequiresFinalExecute()) {\n-\t\t\top_idx++;\n-\t\t\tcontinue;\n-\t\t}\n-\n-\t\tOperatorFinalizeResultType finalize_result;\n-\t\tDataChunk &curr_chunk =\n-\t\t    op_idx + 1 >= intermediate_chunks.size() ? final_chunk : *intermediate_chunks[op_idx + 1];\n-\n-\t\tif (pending_final_execute) {\n-\t\t\t// Still have a cached chunk from a last pull, reuse chunk\n-\t\t\tfinalize_result = cached_final_execute_result;\n-\t\t} else {\n-\t\t\t// Flush the current operator\n-\t\t\tauto current_operator = pipeline.operators[op_idx];\n-\t\t\tStartOperator(current_operator);\n-\t\t\tfinalize_result = current_operator->FinalExecute(context, curr_chunk, *current_operator->op_state,\n-\t\t\t                                                 *intermediate_states[op_idx]);\n-\t\t\tEndOperator(current_operator, &curr_chunk);\n-\t\t}\n-\n-\t\tauto execute_result = Execute(curr_chunk, result, op_idx + 1);\n-\n-\t\tif (execute_result == OperatorResultType::HAVE_MORE_OUTPUT) {\n-\t\t\tpending_final_execute = true;\n-\t\t\tcached_final_execute_result = finalize_result;\n-\t\t} else {\n-\t\t\tpending_final_execute = false;\n-\t\t\tif (finalize_result == OperatorFinalizeResultType::FINISHED) {\n-\t\t\t\tFinishProcessing(op_idx);\n-\t\t\t\top_idx++;\n-\t\t\t}\n-\t\t}\n-\n-\t\t// Some non-empty result was pulled from some caching operator, we're done for this pull\n-\t\tif (result.size() > 0) {\n-\t\t\tbreak;\n-\t\t}\n-\t}\n-}\n-\n // Push all remaining cached operator output through the pipeline\n void PipelineExecutor::FlushCachingOperatorsPush() {\n \tidx_t start_idx = IsFinished() ? idx_t(finished_processing_idx) : 0;\n@@ -223,21 +177,13 @@ void PipelineExecutor::ExecutePull(DataChunk &result) {\n \t\tD_ASSERT(!pipeline.sink);\n \t\tauto &source_chunk = pipeline.operators.empty() ? result : *intermediate_chunks[0];\n \t\twhile (result.size() == 0) {\n-\t\t\tif (source_empty) {\n-\t\t\t\tFlushCachingOperatorsPull(result);\n-\t\t\t\tbreak;\n-\t\t\t}\n-\n \t\t\tif (in_process_operators.empty()) {\n \t\t\t\tsource_chunk.Reset();\n \t\t\t\tFetchFromSource(source_chunk);\n-\n \t\t\t\tif (source_chunk.size() == 0) {\n-\t\t\t\t\tsource_empty = true;\n-\t\t\t\t\tcontinue;\n+\t\t\t\t\tbreak;\n \t\t\t\t}\n \t\t\t}\n-\n \t\t\tif (!pipeline.operators.empty()) {\n \t\t\t\tauto state = Execute(source_chunk, result);\n \t\t\t\tif (state == OperatorResultType::FINISHED) {\n",
  "test_patch": "diff --git a/test/api/test_api.cpp b/test/api/test_api.cpp\nindex 661e5aad4d3c..86d52600f8bb 100644\n--- a/test/api/test_api.cpp\n+++ b/test/api/test_api.cpp\n@@ -554,3 +554,44 @@ TEST_CASE(\"Issue #4583: Catch Insert/Update/Delete errors\", \"[api]\") {\n \tresult = con.SendQuery(\"SELECT MIN(c0) FROM t0;\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {1}));\n }\n+\n+TEST_CASE(\"Issue #6284: CachingPhysicalOperator in pull causes issues\", \"[api][.]\") {\n+\n+\tDBConfig config;\n+\tconfig.options.maximum_threads = 8;\n+\tDuckDB db(nullptr, &config);\n+\tConnection con(db);\n+\n+\tREQUIRE_NO_FAIL(con.Query(\"select setseed(0.1); CREATE TABLE T0 AS SELECT DISTINCT (RANDOM()*9999999)::BIGINT \"\n+\t                          \"record_nb, 0.0 x_0, 1.0 y_0 FROM range(1000000) tbl\"));\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE T1 AS SELECT record_nb, 0.0 x_1, 1.0 y_1 FROM T0\"));\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE T2 AS SELECT record_nb, 0.0 x_2, 1.0 y_2 FROM T0\"));\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE T3 AS SELECT record_nb, 0.0 x_3, 1.0 y_3 FROM T0\"));\n+\tauto result = con.SendQuery(R\"(\n+        SELECT T0.record_nb,\n+            T1.x_1 x_1,\n+            T1.y_1 y_1,\n+            T2.x_2 x_2,\n+            T2.y_2 y_2,\n+            T3.x_3 x_3,\n+            T3.y_3 y_3\n+         FROM T0\n+           INNER JOIN T1 on T0.record_nb = T1.record_nb\n+           INNER JOIN T2 on T0.record_nb = T2.record_nb\n+           INNER JOIN T3 on T0.record_nb = T3.record_nb\n+    )\");\n+\n+\tidx_t count = 0;\n+\twhile (true) {\n+\t\tauto chunk = result->Fetch();\n+\t\tif (!chunk) {\n+\t\t\tbreak;\n+\t\t}\n+\t\tif (chunk->size() == 0) {\n+\t\t\tbreak;\n+\t\t}\n+\t\tcount += chunk->size();\n+\t}\n+\n+\tREQUIRE(951446 - count == 0);\n+}\ndiff --git a/test/sql/filter/filter_cache.cpp b/test/sql/filter/filter_cache.cpp\nindex 759b46e125ff..120067c11e9b 100644\n--- a/test/sql/filter/filter_cache.cpp\n+++ b/test/sql/filter/filter_cache.cpp\n@@ -4,20 +4,6 @@\n using namespace duckdb;\n using namespace std;\n \n-TEST_CASE(\"Streaming result with filter operation applies operator caching\", \"[filter][.]\") {\n-\tDuckDB db(nullptr);\n-\tConnection con(db);\n-\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test as SELECT i FROM range(0,100000) tbl(i)\"));\n-\t// now create a streaming result\n-\tauto result = con.SendQuery(\"SELECT * FROM test where i % 20000 = 0\");\n-\tREQUIRE_NO_FAIL(*result);\n-\t// initial query does not fail!\n-\tauto chunk = result->Fetch();\n-\tREQUIRE(chunk);\n-\t// the chunk should contain all 5 values if chunk caching is applied correctly\n-\tREQUIRE(chunk->size() == 5);\n-}\n-\n // This test triggers an edge case where data that is flushed from a caching operator in pulled into an operator\n // that needs to see this chunk more that once. handling this case requires temporarily caching the flushed result.\n TEST_CASE(\"Streaming result with a filter and a cross product\", \"[filter][.]\") {\ndiff --git a/test/sql/function/table/table_in_out.cpp b/test/sql/function/table/table_in_out.cpp\nindex fb34499f8ab1..d0a2bd7b5e33 100644\n--- a/test/sql/function/table/table_in_out.cpp\n+++ b/test/sql/function/table/table_in_out.cpp\n@@ -90,28 +90,7 @@ TEST_CASE(\"Caching TableInOutFunction\", \"[filter][.]\") {\n \tREQUIRE(result2->ColumnCount() == 1);\n \tREQUIRE(CHECK_COLUMN(result2, 0, {1, 3, 5}));\n \n-\t// Check stream result\n-\tauto result =\n-\t    con.SendQuery(\"SELECT * FROM throttling_sum((select i::INTEGER, (i+1)::INTEGER as j from range(0,3) tbl(i)));\");\n-\tREQUIRE_NO_FAIL(*result);\n-\n-\tauto chunk = result->Fetch();\n-\tREQUIRE(chunk);\n-\tREQUIRE(chunk->size() == 1);\n-\tREQUIRE(chunk->data[0].GetValue(0).GetValue<int>() == 1);\n-\n-\tchunk = result->Fetch();\n-\tREQUIRE(chunk);\n-\tREQUIRE(chunk->size() == 1);\n-\tREQUIRE(chunk->data[0].GetValue(0).GetValue<int>() == 3);\n-\n-\tchunk = result->Fetch();\n-\tREQUIRE(chunk);\n-\tREQUIRE(chunk->size() == 1);\n-\tREQUIRE(chunk->data[0].GetValue(0).GetValue<int>() == 5);\n-\n-\tchunk = result->Fetch();\n-\tREQUIRE(!chunk);\n+\t// TODO: streaming these is currently unsupported\n \n \t// Large result into aggregation\n \tauto result3 = con.Query(\n",
  "problem_statement": "Four table inner join drops rows unless joins are sequential\n### What happens?\n\nI have 15 tables with the same schema, to join on an integer column.  All tables have the same number of records and same values in the PK join column.  Joining any 3 works, but joining 4 or more drops a small percentage of the rows.  I join like so\r\n\r\n```\r\n   FROM T0 INNER JOIN T1 on T1.record_nb = T0.record_nb\r\n           INNER JOIN T2 on T2.record_nb = T0.record_nb\r\n   ...\r\n           INNER JOIN T14 on T14.record_nb = T0.record_nb\r\n```\r\n\r\nAltering this to join each table on the previous table causes the SQL to succeed.  No rows are dropped.  IOW, this works:\r\n\r\n```\r\n   FROM T0 INNER JOIN T1 on T1.record_nb = T0.record_nb\r\n           INNER JOIN T2 on T2.record_nb = T1.record_nb\r\n   ...\r\n           INNER JOIN T14 on T14.record_nb = T13.record_nb\r\n```\r\n\r\nbut uses significantly more memory.\r\n\r\nAny 3 tables join properly with either FROM clause, but any 4 or more yield inconsistent results.  Each execution yields a different number of rows.\r\n\n\n### To Reproduce\n\nThis drops rows:\r\n```python\r\nimport polars as pl\r\nimport duckdb\r\nimport random\r\n\r\nrecord_nb = set(random.randint(1,9_999_999) for _ in range(2_000_000))\r\n\r\nframes = [pl.DataFrame({'record_nb': list(record_nb), f'x_{i}': 0.0, f'y_{i}': 1.0}) \r\n          for i in range(4)]\r\ntbls = [df.to_arrow() for df in frames]\r\nwith duckdb.connect() as con:\r\n    select_ = 'SELECT T0.record_nb'\r\n    from_ = ' FROM T0 '\r\n    for i, (tbl, df) in enumerate((zip(tbls, frames))):\r\n        con.register(f'T{i}', tbl)\r\n        select_ += ',' + ','.join(f'\\n    T{i}.{x} {x}' for x in (f'x_{i}', f'y_{i}') )\r\n        if i > 0:\r\n            from_ += f'\\n   INNER JOIN T{i} on T0.record_nb = T{i}.record_nb'\r\n    sql = f'{select_}\\n{from_}'\r\n    con.execute(sql)\r\n    result_pd = con.fetchdf()\r\n\r\nprint(f'frames have shape {frames[0].shape} and joined result has shape {result_pd.shape}')\r\n```\r\nSince all frames have the same values in the column being joined, the result should have the same number of rows, but the output is:\r\n\r\n`frames have shape (1812272, 3) and joined result has shape (1811160, 9)`\r\n\r\nIf the `with duckdb.connect() as con` block is run repeatedly, the number of rows in the result changes each time.\r\n\r\nReducing the dataframe sizes by 10x, or number of tables to 3 eliminates the discrepancy.  If I change `T0.record_nb` to `T{i-1}.record_nb` in the `INNER JOIN` expression, the problem disappears.\r\n\r\nI tried using `.to_pandas()` in place of `.to_arrow()` but had the same result.\r\n\n\n### OS:\n\nUbuntu 18.04 on x64\n\n### DuckDB Version:\n\n0.7.0\n\n### DuckDB Client:\n\nPython\n\n### Full Name:\n\nKendall Bailey\n\n### Affiliation:\n\nFigure Technologies\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\n",
  "hints_text": "Implicit joins seem to work.\r\n\r\n```\r\n   FROM T0, T1, ..., TN\r\n   WHERE\r\n       T0.record_nb = T1.record_nb AND\r\n       ...\r\n       T0.record_nb = TN.record_nb\r\n```\r\nworks as expected.\nThanks for the report!\r\n\r\nI took a brief look at this and the problem seems to be in the result conversion code - not in the actual join code. When doing a `COUNT(*)` over the join or storing the result in a table the rows do not seem to be cut-off. I will see if I can push a fix tomorrow.\nAfter some more investigation this seems to be caused by operator caching not working correctly in case of a `StreamQueryResult`, CC @samansmink \nAs a work-around, if you use the new `.sql` method (that works using the Relation objects) no streaming result is created. As such the problem does not exist there:\r\n\r\n```py\r\nimport polars as pl\r\nimport duckdb\r\nimport random\r\n\r\nrecord_nb = set(random.randint(1,9_999_999) for _ in range(2_000_000))\r\n\r\nframes = [pl.DataFrame({'record_nb': list(record_nb), f'x_{i}': 0.0, f'y_{i}': 1.0}) \r\n          for i in range(4)]\r\ntbls = [df.to_arrow() for df in frames]\r\nwith duckdb.connect() as con:\r\n    select_ = 'SELECT T0.record_nb'\r\n    from_ = ' FROM T0 '\r\n    for i, (tbl, df) in enumerate((zip(tbls, frames))):\r\n        con.register(f'T{i}', tbl)\r\n        select_ += ',' + ','.join(f'\\n    T{i}.{x} {x}' for x in (f'x_{i}', f'y_{i}') )\r\n        if i > 0:\r\n            from_ += f'\\n   INNER JOIN T{i} on T0.record_nb = T{i}.record_nb'\r\n    sql = f'{select_}\\n{from_}'\r\n    ############################################\r\n    # use the .sql method instead\r\n    ############################################\r\n    result_pd = con.sql(sql).fetchdf()\r\n\r\nprint(f'frames have shape {frames[0].shape} and joined result has shape {result_pd.shape}')\r\n```\r\n\r\n```\r\nframes have shape (1813447, 3) and joined result has shape (1813447, 9)\r\n```\nI will add that we're also seeing this issue and are unable to upgrade to the newest version of duck as a result. I'll work on transforming our use-case into a minimally reproducible example soon. ",
  "created_at": "2023-02-23T09:41:43Z"
}