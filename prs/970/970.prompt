You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
R: Incorrect results from rolling window summation
I would imagine that this affects duckdb as a whole, but here is an example in R of computing a size 2 rolling summation of the current row + 1 row before it. I've compared with SQLite for the correct results:

``` r
library(duckdb)
library(RSQLite)
library(DBI)

con_sqlite <- dbConnect(SQLite())
con_duck <- dbConnect(duckdb())

dbWriteTable(con_sqlite, "cars", mtcars)
dbWriteTable(con_duck, "cars", mtcars)

query <- "
  SELECT 
    mpg, 
    SUM(mpg) OVER (ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS mpg_roll
  FROM
    cars
"

head(dbGetQuery(con_sqlite, query), n = 10)
#>     mpg mpg_roll
#> 1  21.0     21.0
#> 2  21.0     42.0
#> 3  22.8     43.8
#> 4  21.4     44.2
#> 5  18.7     40.1
#> 6  18.1     36.8
#> 7  14.3     32.4
#> 8  24.4     38.7
#> 9  22.8     47.2
#> 10 19.2     42.0

head(dbGetQuery(con_duck, query), n = 10)
#>     mpg mpg_roll
#> 1  21.0    642.9
#> 2  21.0    642.9
#> 3  22.8    621.9
#> 4  21.4    600.9
#> 5  18.7    578.1
#> 6  18.1    556.7
#> 7  14.3    538.0
#> 8  24.4    519.9
#> 9  22.8    505.6
#> 10 19.2    481.2
```

<sup>Created on 2020-09-28 by the [reprex package](https://reprex.tidyverse.org) (v0.3.0.9001)</sup>

</issue>
<code>
[start of README.md]
1: <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="30">
2: 
3: [![Travis](https://api.travis-ci.org/cwida/duckdb.svg?branch=master)](https://travis-ci.org/cwida/duckdb)
4: [![CodeFactor](https://www.codefactor.io/repository/github/cwida/duckdb/badge)](https://www.codefactor.io/repository/github/cwida/duckdb)
5: [![Coverage Status](https://coveralls.io/repos/github/cwida/duckdb/badge.svg?branch=master)](https://coveralls.io/github/cwida/duckdb?branch=master)
6: [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3901452.svg)](https://zenodo.org/record/3901452)
7: 
8: 
9: ## Installation
10: If you just want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
11: 
12: ## Development
13: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`.
14: 
15: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
16: 
17: 
[end of README.md]
[start of src/execution/window_segment_tree.cpp]
1: #include "duckdb/execution/window_segment_tree.hpp"
2: 
3: #include "duckdb/common/vector_operations/vector_operations.hpp"
4: #include "duckdb/common/algorithm.hpp"
5: 
6: #include <cmath>
7: 
8: namespace duckdb {
9: using namespace std;
10: 
11: WindowSegmentTree::WindowSegmentTree(AggregateFunction &aggregate, LogicalType result_type, ChunkCollection *input)
12:     : aggregate(aggregate), state(aggregate.state_size()), statep(LogicalTypeId::POINTER), result_type(result_type),
13:       input_ref(input) {
14: #if STANDARD_VECTOR_SIZE < 512
15: 	throw NotImplementedException("Window functions are not supported for vector sizes < 512");
16: #endif
17: 
18: 	Value ptr_val = Value::POINTER((idx_t)state.data());
19: 	statep.Reference(ptr_val);
20: 	statep.Normalify(STANDARD_VECTOR_SIZE);
21: 
22: 	if (input_ref && input_ref->column_count() > 0) {
23: 		inputs.Initialize(input_ref->types);
24: 		if (aggregate.combine) {
25: 			ConstructTree();
26: 		}
27: 	}
28: }
29: 
30: void WindowSegmentTree::AggregateInit() {
31: 	aggregate.initialize(state.data());
32: }
33: 
34: Value WindowSegmentTree::AggegateFinal() {
35: 	Vector statev(Value::POINTER((idx_t)state.data()));
36: 	Vector result(result_type);
37: 	result.vector_type = VectorType::CONSTANT_VECTOR;
38: 	ConstantVector::SetNull(result, false);
39: 	aggregate.finalize(statev, result, 1);
40: 
41: 	return result.GetValue(0);
42: }
43: 
44: void WindowSegmentTree::WindowSegmentValue(idx_t l_idx, idx_t begin, idx_t end) {
45: 	assert(begin <= end);
46: 	if (begin == end) {
47: 		return;
48: 	}
49: 	inputs.SetCardinality(end - begin);
50: 
51: 	idx_t start_in_vector = begin % STANDARD_VECTOR_SIZE;
52: 	Vector s;
53: 	s.Slice(statep, 0);
54: 	if (l_idx == 0) {
55: 		const auto input_count = input_ref->column_count();
56: 		if (start_in_vector + inputs.size() < STANDARD_VECTOR_SIZE) {
57: 			auto &chunk = input_ref->GetChunk(begin);
58: 			for (idx_t i = 0; i < input_count; ++i) {
59: 				auto &v = inputs.data[i];
60: 				auto &vec = chunk.data[i];
61: 				v.Slice(vec, start_in_vector);
62: 				v.Verify(inputs.size());
63: 			}
64: 		} else {
65: 			// we cannot just slice the individual vector!
66: 			auto &chunk_a = input_ref->GetChunk(begin);
67: 			auto &chunk_b = input_ref->GetChunk(end);
68: 			idx_t chunk_a_count = chunk_a.size() - start_in_vector;
69: 			idx_t chunk_b_count = inputs.size() - chunk_a_count;
70: 			for (idx_t i = 0; i < input_count; ++i) {
71: 				auto &v = inputs.data[i];
72: 				VectorOperations::Copy(chunk_a.data[i], v, chunk_a.size(), start_in_vector, 0);
73: 				VectorOperations::Copy(chunk_b.data[i], v, chunk_b_count, 0, chunk_a_count);
74: 			}
75: 		}
76: 		aggregate.update(&inputs.data[0], input_count, s, inputs.size());
77: 	} else {
78: 		assert(end - begin <= STANDARD_VECTOR_SIZE);
79: 		// find out where the states begin
80: 		data_ptr_t begin_ptr = levels_flat_native.get() + state.size() * (begin + levels_flat_start[l_idx - 1]);
81: 		// set up a vector of pointers that point towards the set of states
82: 		Vector v(LogicalType::POINTER);
83: 		auto pdata = FlatVector::GetData<data_ptr_t>(v);
84: 		for (idx_t i = 0; i < inputs.size(); i++) {
85: 			pdata[i] = begin_ptr + i * state.size();
86: 		}
87: 		v.Verify(inputs.size());
88: 		aggregate.combine(v, s, inputs.size());
89: 	}
90: }
91: 
92: void WindowSegmentTree::ConstructTree() {
93: 	assert(input_ref);
94: 	assert(inputs.column_count() > 0);
95: 
96: 	// compute space required to store internal nodes of segment tree
97: 	idx_t internal_nodes = 0;
98: 	idx_t level_nodes = input_ref->count;
99: 	do {
100: 		level_nodes = (idx_t)ceil((double)level_nodes / TREE_FANOUT);
101: 		internal_nodes += level_nodes;
102: 	} while (level_nodes > 1);
103: 	levels_flat_native = unique_ptr<data_t[]>(new data_t[internal_nodes * state.size()]);
104: 	levels_flat_start.push_back(0);
105: 
106: 	idx_t levels_flat_offset = 0;
107: 	idx_t level_current = 0;
108: 	// level 0 is data itself
109: 	idx_t level_size;
110: 	while ((level_size = (level_current == 0 ? input_ref->count
111: 	                                         : levels_flat_offset - levels_flat_start[level_current - 1])) > 1) {
112: 		for (idx_t pos = 0; pos < level_size; pos += TREE_FANOUT) {
113: 			AggregateInit();
114: 			WindowSegmentValue(level_current, pos, min(level_size, pos + TREE_FANOUT));
115: 
116: 			memcpy(levels_flat_native.get() + (levels_flat_offset * state.size()), state.data(), state.size());
117: 
118: 			levels_flat_offset++;
119: 		}
120: 
121: 		levels_flat_start.push_back(levels_flat_offset);
122: 		level_current++;
123: 	}
124: }
125: 
126: Value WindowSegmentTree::Compute(idx_t begin, idx_t end) {
127: 	assert(input_ref);
128: 
129: 	// No arguments, so just count
130: 	if (inputs.column_count() == 0) {
131: 		return Value::Numeric(result_type, end - begin);
132: 	}
133: 
134: 	AggregateInit();
135: 
136: 	// Aggregate everything at once if we can't combine states
137: 	if (!aggregate.combine) {
138: 		WindowSegmentValue(0, begin, end);
139: 		return AggegateFinal();
140: 	}
141: 
142: 	for (idx_t l_idx = 0; l_idx < levels_flat_start.size() + 1; l_idx++) {
143: 		idx_t parent_begin = begin / TREE_FANOUT;
144: 		idx_t parent_end = end / TREE_FANOUT;
145: 		if (parent_begin == parent_end) {
146: 			WindowSegmentValue(l_idx, begin, end);
147: 			return AggegateFinal();
148: 		}
149: 		idx_t group_begin = parent_begin * TREE_FANOUT;
150: 		if (begin != group_begin) {
151: 			WindowSegmentValue(l_idx, begin, group_begin + TREE_FANOUT);
152: 			parent_begin++;
153: 		}
154: 		idx_t group_end = parent_end * TREE_FANOUT;
155: 		if (end != group_end) {
156: 			WindowSegmentValue(l_idx, group_end, end);
157: 		}
158: 		begin = parent_begin;
159: 		end = parent_end;
160: 	}
161: 
162: 	return AggegateFinal();
163: }
164: 
165: } // namespace duckdb
[end of src/execution/window_segment_tree.cpp]
[start of src/parser/transform/expression/transform_function.cpp]
1: #include "duckdb/parser/expression/case_expression.hpp"
2: #include "duckdb/parser/expression/cast_expression.hpp"
3: #include "duckdb/parser/expression/function_expression.hpp"
4: #include "duckdb/parser/expression/operator_expression.hpp"
5: #include "duckdb/parser/expression/star_expression.hpp"
6: #include "duckdb/parser/expression/window_expression.hpp"
7: #include "duckdb/parser/transformer.hpp"
8: #include "duckdb/common/string_util.hpp"
9: 
10: namespace duckdb {
11: using namespace std;
12: using namespace duckdb_libpgquery;
13: 
14: static ExpressionType WindowToExpressionType(string &fun_name) {
15: 	if (fun_name == "rank") {
16: 		return ExpressionType::WINDOW_RANK;
17: 	} else if (fun_name == "rank_dense" || fun_name == "dense_rank") {
18: 		return ExpressionType::WINDOW_RANK_DENSE;
19: 	} else if (fun_name == "percent_rank") {
20: 		return ExpressionType::WINDOW_PERCENT_RANK;
21: 	} else if (fun_name == "row_number") {
22: 		return ExpressionType::WINDOW_ROW_NUMBER;
23: 	} else if (fun_name == "first_value" || fun_name == "first") {
24: 		return ExpressionType::WINDOW_FIRST_VALUE;
25: 	} else if (fun_name == "last_value" || fun_name == "last") {
26: 		return ExpressionType::WINDOW_LAST_VALUE;
27: 	} else if (fun_name == "cume_dist") {
28: 		return ExpressionType::WINDOW_CUME_DIST;
29: 	} else if (fun_name == "lead") {
30: 		return ExpressionType::WINDOW_LEAD;
31: 	} else if (fun_name == "lag") {
32: 		return ExpressionType::WINDOW_LAG;
33: 	} else if (fun_name == "ntile") {
34: 		return ExpressionType::WINDOW_NTILE;
35: 	}
36: 
37: 	return ExpressionType::WINDOW_AGGREGATE;
38: }
39: 
40: void Transformer::TransformWindowDef(PGWindowDef *window_spec, WindowExpression *expr) {
41: 	assert(window_spec);
42: 	assert(expr);
43: 
44: 	// next: partitioning/ordering expressions
45: 	TransformExpressionList(window_spec->partitionClause, expr->partitions);
46: 	TransformOrderBy(window_spec->orderClause, expr->orders);
47: 
48: 	// finally: specifics of bounds
49: 	expr->start_expr = TransformExpression(window_spec->startOffset);
50: 	expr->end_expr = TransformExpression(window_spec->endOffset);
51: 
52: 	if ((window_spec->frameOptions & FRAMEOPTION_END_UNBOUNDED_PRECEDING) ||
53: 	    (window_spec->frameOptions & FRAMEOPTION_START_UNBOUNDED_FOLLOWING)) {
54: 		throw Exception(
55: 		    "Window frames starting with unbounded following or ending in unbounded preceding make no sense");
56: 	}
57: 
58: 	if (window_spec->frameOptions & FRAMEOPTION_START_UNBOUNDED_PRECEDING) {
59: 		expr->start = WindowBoundary::UNBOUNDED_PRECEDING;
60: 	} else if (window_spec->frameOptions & FRAMEOPTION_START_UNBOUNDED_FOLLOWING) {
61: 		expr->start = WindowBoundary::UNBOUNDED_FOLLOWING;
62: 	} else if (window_spec->frameOptions & FRAMEOPTION_START_VALUE_PRECEDING) {
63: 		expr->start = WindowBoundary::EXPR_PRECEDING;
64: 	} else if (window_spec->frameOptions & FRAMEOPTION_START_VALUE_FOLLOWING) {
65: 		expr->start = WindowBoundary::EXPR_FOLLOWING;
66: 	} else if (window_spec->frameOptions & (FRAMEOPTION_START_CURRENT_ROW | FRAMEOPTION_RANGE)) {
67: 		expr->start = WindowBoundary::CURRENT_ROW_RANGE;
68: 	} else if (window_spec->frameOptions & (FRAMEOPTION_START_CURRENT_ROW | FRAMEOPTION_ROWS)) {
69: 		expr->start = WindowBoundary::CURRENT_ROW_ROWS;
70: 	}
71: 
72: 	if (window_spec->frameOptions & FRAMEOPTION_END_UNBOUNDED_PRECEDING) {
73: 		expr->end = WindowBoundary::UNBOUNDED_PRECEDING;
74: 	} else if (window_spec->frameOptions & FRAMEOPTION_END_UNBOUNDED_FOLLOWING) {
75: 		expr->end = WindowBoundary::UNBOUNDED_FOLLOWING;
76: 	} else if (window_spec->frameOptions & FRAMEOPTION_END_VALUE_PRECEDING) {
77: 		expr->end = WindowBoundary::EXPR_PRECEDING;
78: 	} else if (window_spec->frameOptions & FRAMEOPTION_END_VALUE_FOLLOWING) {
79: 		expr->end = WindowBoundary::EXPR_FOLLOWING;
80: 	} else if (window_spec->frameOptions & (FRAMEOPTION_END_CURRENT_ROW | FRAMEOPTION_RANGE)) {
81: 		expr->end = WindowBoundary::CURRENT_ROW_RANGE;
82: 	} else if (window_spec->frameOptions & (FRAMEOPTION_END_CURRENT_ROW | FRAMEOPTION_ROWS)) {
83: 		expr->end = WindowBoundary::CURRENT_ROW_ROWS;
84: 	}
85: 
86: 	assert(expr->start != WindowBoundary::INVALID && expr->end != WindowBoundary::INVALID);
87: 	if (((expr->start == WindowBoundary::EXPR_PRECEDING || expr->start == WindowBoundary::EXPR_PRECEDING) &&
88: 	     !expr->start_expr) ||
89: 	    ((expr->end == WindowBoundary::EXPR_PRECEDING || expr->end == WindowBoundary::EXPR_PRECEDING) &&
90: 	     !expr->end_expr)) {
91: 		throw Exception("Failed to transform window boundary expression");
92: 	}
93: }
94: 
95: unique_ptr<ParsedExpression> Transformer::TransformFuncCall(PGFuncCall *root) {
96: 	auto name = root->funcname;
97: 	string schema, function_name;
98: 	if (name->length == 2) {
99: 		// schema + name
100: 		schema = reinterpret_cast<PGValue *>(name->head->data.ptr_value)->val.str;
101: 		function_name = reinterpret_cast<PGValue *>(name->head->next->data.ptr_value)->val.str;
102: 	} else {
103: 		// unqualified name
104: 		//		schema = DEFAULT_SCHEMA;
105: 		schema = INVALID_SCHEMA;
106: 		function_name = reinterpret_cast<PGValue *>(name->head->data.ptr_value)->val.str;
107: 	}
108: 
109: 	auto lowercase_name = StringUtil::Lower(function_name);
110: 
111: 	if (root->agg_filter) {
112: 		throw ParserException("FILTER is not implemented for aggregates");
113: 	}
114: 	if (root->agg_order) {
115: 		throw ParserException("ORDER BY is not implemented for aggregates");
116: 	}
117: 
118: 	if (root->over) {
119: 		if (root->agg_distinct) {
120: 			throw ParserException("DISTINCT is not implemented for window functions!");
121: 		}
122: 
123: 		auto win_fun_type = WindowToExpressionType(lowercase_name);
124: 		if (win_fun_type == ExpressionType::INVALID) {
125: 			throw Exception("Unknown/unsupported window function");
126: 		}
127: 
128: 		auto expr = make_unique<WindowExpression>(win_fun_type, schema, lowercase_name);
129: 
130: 		if (root->args) {
131: 			vector<unique_ptr<ParsedExpression>> function_list;
132: 			auto res = TransformExpressionList(root->args, function_list);
133: 			if (!res) {
134: 				throw Exception("Failed to transform window function children");
135: 			}
136: 			if (win_fun_type == ExpressionType::WINDOW_AGGREGATE) {
137: 				for (auto &child : function_list) {
138: 					expr->children.push_back(move(child));
139: 				}
140: 			} else {
141: 				if (function_list.size() > 0) {
142: 					expr->children.push_back(move(function_list[0]));
143: 				}
144: 				if (function_list.size() > 1) {
145: 					assert(win_fun_type == ExpressionType::WINDOW_LEAD || win_fun_type == ExpressionType::WINDOW_LAG);
146: 					expr->offset_expr = move(function_list[1]);
147: 				}
148: 				if (function_list.size() > 2) {
149: 					assert(win_fun_type == ExpressionType::WINDOW_LEAD || win_fun_type == ExpressionType::WINDOW_LAG);
150: 					expr->default_expr = move(function_list[2]);
151: 				}
152: 				assert(function_list.size() <= 3);
153: 			}
154: 		}
155: 		auto window_spec = reinterpret_cast<PGWindowDef *>(root->over);
156: 		if (window_spec->name) {
157: 			auto it = window_clauses.find(StringUtil::Lower(string(window_spec->name)));
158: 			if (it == window_clauses.end()) {
159: 				throw ParserException("window \"%s\" does not exist", window_spec->name);
160: 			}
161: 			window_spec = it->second;
162: 			assert(window_spec);
163: 		}
164: 		TransformWindowDef(window_spec, expr.get());
165: 
166: 		return move(expr);
167: 	}
168: 
169: 	//  TransformExpressionList??
170: 	vector<unique_ptr<ParsedExpression>> children;
171: 	if (root->args != nullptr) {
172: 		for (auto node = root->args->head; node != nullptr; node = node->next) {
173: 			auto child_expr = TransformExpression((PGNode *)node->data.ptr_value);
174: 			children.push_back(move(child_expr));
175: 		}
176: 	}
177: 
178: 	if (lowercase_name == "if") {
179: 		if (children.size() != 3) {
180: 			throw ParserException("Wrong number of arguments to IF.");
181: 		}
182: 		auto expr = make_unique<CaseExpression>();
183: 		expr->check = move(children[0]);
184: 		expr->result_if_true = move(children[1]);
185: 		expr->result_if_false = move(children[2]);
186: 		return move(expr);
187: 	}
188: 
189: 	else if (lowercase_name == "ifnull") {
190: 		if (children.size() != 2) {
191: 			throw ParserException("Wrong number of arguments to IFNULL.");
192: 		}
193: 
194: 		//  Two-argument COALESCE
195: 		auto expr = make_unique<CaseExpression>();
196: 		expr->check = make_unique<OperatorExpression>(ExpressionType::OPERATOR_IS_NOT_NULL, children[0]->Copy());
197: 		expr->result_if_true = move(children[0]);
198: 		expr->result_if_false = move(children[1]);
199: 		return move(expr);
200: 	}
201: 
202: 	return make_unique<FunctionExpression>(schema, lowercase_name.c_str(), children, root->agg_distinct);
203: }
204: 
205: static string SQLValueOpToString(PGSQLValueFunctionOp op) {
206: 	switch (op) {
207: 	case PG_SVFOP_CURRENT_DATE:
208: 		return "current_date";
209: 	case PG_SVFOP_CURRENT_TIME:
210: 		return "current_time";
211: 	case PG_SVFOP_CURRENT_TIME_N:
212: 		return "current_time_n";
213: 	case PG_SVFOP_CURRENT_TIMESTAMP:
214: 		return "current_timestamp";
215: 	case PG_SVFOP_CURRENT_TIMESTAMP_N:
216: 		return "current_timestamp_n";
217: 	case PG_SVFOP_LOCALTIME:
218: 		return "current_localtime";
219: 	case PG_SVFOP_LOCALTIME_N:
220: 		return "current_localtime_n";
221: 	case PG_SVFOP_LOCALTIMESTAMP:
222: 		return "current_localtimestamp";
223: 	case PG_SVFOP_LOCALTIMESTAMP_N:
224: 		return "current_localtimestamp_n";
225: 	case PG_SVFOP_CURRENT_ROLE:
226: 		return "current_role";
227: 	case PG_SVFOP_CURRENT_USER:
228: 		return "current_user";
229: 	case PG_SVFOP_USER:
230: 		return "user";
231: 	case PG_SVFOP_SESSION_USER:
232: 		return "session_user";
233: 	case PG_SVFOP_CURRENT_CATALOG:
234: 		return "current_catalog";
235: 	case PG_SVFOP_CURRENT_SCHEMA:
236: 		return "current_schema";
237: 	default:
238: 		throw Exception("Could not find named SQL value function specification " + to_string((int)op));
239: 	}
240: }
241: 
242: unique_ptr<ParsedExpression> Transformer::TransformSQLValueFunction(PGSQLValueFunction *node) {
243: 	if (!node) {
244: 		return nullptr;
245: 	}
246: 	vector<unique_ptr<ParsedExpression>> children;
247: 	auto fname = SQLValueOpToString(node->op);
248: 	return make_unique<FunctionExpression>(DEFAULT_SCHEMA, fname, children);
249: }
250: 
251: } // namespace duckdb
[end of src/parser/transform/expression/transform_function.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: