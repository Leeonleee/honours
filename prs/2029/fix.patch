diff --git a/.github/workflows/main.yml b/.github/workflows/main.yml
index 5191b0a8142f..60256e959d15 100644
--- a/.github/workflows/main.yml
+++ b/.github/workflows/main.yml
@@ -879,7 +879,7 @@ jobs:
       CIBW_BUILD: 'cp36-* cp37-* cp38-* cp39-*'
       CIBW_BEFORE_BUILD: 'pip install --prefer-binary "pandas>=0.24" "pytest>=4.3"'
       CIBW_TEST_REQUIRES: 'pytest'
-      CIBW_BEFORE_TEST: 'pip install --prefer-binary "pandas>=0.24" && pip install --prefer-binary "requests>=2.26" && (pip install --prefer-binary "pyarrow>=4.0.0" || true)'
+      CIBW_BEFORE_TEST: 'pip install --prefer-binary "pandas>=0.24" && pip install --prefer-binary "requests>=2.26" && (pip install --extra-index-url https://pypi.fury.io/arrow-nightlies/ --prefer-binary --pre pyarrow || true)'
       CIBW_TEST_COMMAND: 'python -m pytest {project}/tests'
       SETUPTOOLS_SCM_NO_LOCAL: 'yes'
       TWINE_USERNAME: 'hfmuehleisen'
@@ -919,7 +919,7 @@ jobs:
       CIBW_BUILD: 'cp36-* cp37-* cp38-* cp39-*'
       CIBW_BEFORE_BUILD: 'yum install -y openssl-devel && pip install --prefer-binary "pandas>=0.24" "pytest>=4.3"'
       CIBW_TEST_REQUIRES: 'pytest'
-      CIBW_BEFORE_TEST: 'yum install -y openssl && pip install --prefer-binary "pandas>=0.24"  && pip install --prefer-binary "requests>=2.26" && (pip install --prefer-binary "pyarrow>=4.0.0" || true)'
+      CIBW_BEFORE_TEST: 'yum install -y openssl && pip install --prefer-binary "pandas>=0.24"  && pip install --prefer-binary "requests>=2.26" && (pip install --extra-index-url https://pypi.fury.io/arrow-nightlies/ --prefer-binary --pre pyarrow || true)'
       CIBW_TEST_COMMAND: 'python -m pytest {project}/tests'
       CIBW_ENVIRONMENT: 'BUILD_HTTPFS=1'
       SETUPTOOLS_SCM_NO_LOCAL: 'yes'
@@ -953,7 +953,7 @@ jobs:
       CIBW_BUILD: 'cp36-* cp37-* cp38-* cp39-*'
       CIBW_BEFORE_BUILD: 'pip install --prefer-binary "pandas>=0.24" "pytest>=4.3"'
       CIBW_TEST_REQUIRES: 'pytest'
-      CIBW_BEFORE_TEST: 'pip install --prefer-binary "pandas>=0.24" "requests>=2.26" "pyarrow>=4.0.0"'
+      CIBW_BEFORE_TEST: 'pip install --prefer-binary "pandas>=0.24" "requests>=2.26" && (pip install --extra-index-url https://pypi.fury.io/arrow-nightlies/ --prefer-binary --pre pyarrow || true)'
       CIBW_TEST_COMMAND: 'python -m pytest {project}/tests'
       CIBW_ARCHS_MACOS: 'x86_64 universal2 arm64'
       SETUPTOOLS_SCM_NO_LOCAL: 'yes'
diff --git a/src/function/table/arrow.cpp b/src/function/table/arrow.cpp
index db2d43060c20..7f2757201d9f 100644
--- a/src/function/table/arrow.cpp
+++ b/src/function/table/arrow.cpp
@@ -16,6 +16,7 @@
 #include "utf8proc_wrapper.hpp"
 
 #include "duckdb/common/operator/multiply.hpp"
+#include "duckdb/common/mutex.hpp"
 namespace duckdb {
 
 LogicalType GetArrowLogicalType(ArrowSchema &schema,
@@ -1034,9 +1035,12 @@ bool ArrowTableFunction::ArrowScanParallelStateNext(ClientContext &context, cons
                                                     ParallelState *parallel_state_p) {
 	auto &bind_data = (const ArrowScanFunctionData &)*bind_data_p;
 	auto &state = (ArrowScanState &)*operator_state;
-
+	auto &parallel_state = (ParallelArrowScanState &)*parallel_state_p;
+	lock_guard<mutex> parallel_lock(parallel_state.lock);
 	state.chunk_offset = 0;
+
 	state.chunk = bind_data.stream->GetNextChunk();
+
 	//! have we run out of chunks? we are done
 	if (!state.chunk->arrow_array.release) {
 		return false;
diff --git a/src/include/duckdb/function/table/arrow.hpp b/src/include/duckdb/function/table/arrow.hpp
index 96951f637b65..837e5b952ef7 100644
--- a/src/include/duckdb/function/table/arrow.hpp
+++ b/src/include/duckdb/function/table/arrow.hpp
@@ -66,7 +66,7 @@ struct ArrowScanState : public FunctionOperatorData {
 struct ParallelArrowScanState : public ParallelState {
 	ParallelArrowScanState() {
 	}
-	bool finished = false;
+	std::mutex lock;
 };
 
 struct ArrowTableFunction {
diff --git a/tools/pythonpkg/src/arrow_array_stream.cpp b/tools/pythonpkg/src/arrow_array_stream.cpp
index 9a230b60ff01..c89c4a82b642 100644
--- a/tools/pythonpkg/src/arrow_array_stream.cpp
+++ b/tools/pythonpkg/src/arrow_array_stream.cpp
@@ -4,98 +4,29 @@
 
 namespace duckdb {
 
-PythonTableArrowArrayStream::PythonTableArrowArrayStream(PyObject *arrow_table_p,
-                                                         PythonTableArrowArrayStreamFactory *factory)
-    : factory(factory), arrow_table(arrow_table_p), chunk_idx(0) {
-	stream = make_unique<ArrowArrayStreamWrapper>();
-	InitializeFunctionPointers(&stream->arrow_array_stream);
-	py::handle table_handle(arrow_table_p);
-	batches = table_handle.attr("to_batches")();
-	py::int_ num_rows_func = -1;
-	if (py::hasattr(table_handle, "num_rows")) {
-		num_rows_func = table_handle.attr("num_rows");
-	}
-	stream->number_of_rows = num_rows_func;
-
-	stream->arrow_array_stream.private_data = this;
-}
-
-void PythonTableArrowArrayStream::InitializeFunctionPointers(ArrowArrayStream *stream) {
-	stream->get_schema = PythonTableArrowArrayStream::GetSchema;
-	stream->get_next = PythonTableArrowArrayStream::GetNext;
-	stream->release = PythonTableArrowArrayStream::Release;
-	stream->get_last_error = PythonTableArrowArrayStream::GetLastError;
-}
-
 unique_ptr<ArrowArrayStreamWrapper> PythonTableArrowArrayStreamFactory::Produce(uintptr_t factory_ptr) {
 	py::gil_scoped_acquire acquire;
 	PythonTableArrowArrayStreamFactory *factory = (PythonTableArrowArrayStreamFactory *)factory_ptr;
 	if (!factory->arrow_table) {
 		return nullptr;
 	}
-	//! This is a bit hacky, but has to be this way to hide pybind from the main duckdb lib
-	auto table_stream = new PythonTableArrowArrayStream(factory->arrow_table, factory);
-	return move(table_stream->stream);
+	py::handle table(factory->arrow_table);
+	py::object scanner;
+	py::object arrow_scanner = py::module_::import("pyarrow.dataset").attr("Scanner").attr("from_dataset");
+	auto py_object_type = string(py::str(table.get_type().attr("__name__")));
+
+	if (py_object_type == "Table") {
+		auto arrow_dataset = py::module_::import("pyarrow.dataset").attr("dataset");
+		auto dataset = arrow_dataset(table);
+		scanner = arrow_scanner(dataset);
+	} else {
+		scanner = arrow_scanner(table);
+	}
+	auto record_batches = scanner.attr("to_reader")();
+	auto res = make_unique<ArrowArrayStreamWrapper>();
+	auto export_to_c = record_batches.attr("_export_to_c");
+	export_to_c((uint64_t)&res->arrow_array_stream);
+	return res;
 }
 
-int PythonTableArrowArrayStream::PythonTableArrowArrayStream::GetSchema(ArrowArrayStream *stream,
-                                                                        struct ArrowSchema *out) {
-	D_ASSERT(stream->private_data);
-	py::gil_scoped_acquire acquire;
-	auto my_stream = (PythonTableArrowArrayStream *)stream->private_data;
-	if (!stream->release) {
-		my_stream->last_error = "stream was released";
-		return -1;
-	}
-	py::handle table_handle(my_stream->arrow_table);
-	auto schema = table_handle.attr("schema");
-	if (!py::hasattr(schema, "_export_to_c")) {
-		my_stream->last_error = "failed to acquire export_to_c function";
-		return -1;
-	}
-	auto export_to_c = schema.attr("_export_to_c");
-	export_to_c((uint64_t)out);
-	return 0;
-}
-
-int PythonTableArrowArrayStream::GetNext(struct ArrowArrayStream *stream, struct ArrowArray *out) {
-	D_ASSERT(stream->private_data);
-	py::gil_scoped_acquire acquire;
-	auto my_stream = (PythonTableArrowArrayStream *)stream->private_data;
-	if (!stream->release) {
-		my_stream->last_error = "stream was released";
-		return -1;
-	}
-	if (my_stream->chunk_idx >= py::len(my_stream->batches)) {
-		out->release = nullptr;
-		return 0;
-	}
-	auto stream_batch = my_stream->batches[my_stream->chunk_idx++];
-	if (!py::hasattr(stream_batch, "_export_to_c")) {
-		my_stream->last_error = "failed to acquire export_to_c function";
-		return -1;
-	}
-	auto export_to_c = stream_batch.attr("_export_to_c");
-	export_to_c((uint64_t)out);
-	return 0;
-}
-
-void PythonTableArrowArrayStream::Release(struct ArrowArrayStream *stream) {
-	py::gil_scoped_acquire acquire;
-	if (!stream->release) {
-		return;
-	}
-	stream->release = nullptr;
-	auto private_data = (PythonTableArrowArrayStream *)stream->private_data;
-	delete (PythonTableArrowArrayStream *)stream->private_data;
-}
-
-const char *PythonTableArrowArrayStream::GetLastError(struct ArrowArrayStream *stream) {
-	if (!stream->release) {
-		return "stream was released";
-	}
-	D_ASSERT(stream->private_data);
-	auto my_stream = (PythonTableArrowArrayStream *)stream->private_data;
-	return my_stream->last_error.c_str();
-}
 } // namespace duckdb
\ No newline at end of file
diff --git a/tools/pythonpkg/src/include/duckdb_python/arrow_array_stream.hpp b/tools/pythonpkg/src/include/duckdb_python/arrow_array_stream.hpp
index 443a2c2fe586..2befdef306c9 100644
--- a/tools/pythonpkg/src/include/duckdb_python/arrow_array_stream.hpp
+++ b/tools/pythonpkg/src/include/duckdb_python/arrow_array_stream.hpp
@@ -20,24 +20,4 @@ class PythonTableArrowArrayStreamFactory {
 	static unique_ptr<ArrowArrayStreamWrapper> Produce(uintptr_t factory);
 	PyObject *arrow_table;
 };
-
-class PythonTableArrowArrayStream {
-public:
-	explicit PythonTableArrowArrayStream(PyObject *arrow_table, PythonTableArrowArrayStreamFactory *factory);
-
-	unique_ptr<ArrowArrayStreamWrapper> stream;
-	PythonTableArrowArrayStreamFactory *factory;
-
-private:
-	static void InitializeFunctionPointers(ArrowArrayStream *stream);
-	static int GetSchema(struct ArrowArrayStream *stream, struct ArrowSchema *out);
-	static int GetNext(struct ArrowArrayStream *stream, struct ArrowArray *out);
-	static void Release(struct ArrowArrayStream *stream);
-	static const char *GetLastError(struct ArrowArrayStream *stream);
-
-	std::string last_error;
-	PyObject *arrow_table;
-	py::list batches;
-	std::atomic<idx_t> chunk_idx;
-};
 } // namespace duckdb
\ No newline at end of file
diff --git a/tools/pythonpkg/src/pyconnection.cpp b/tools/pythonpkg/src/pyconnection.cpp
index 5445aaf62eac..5aaf50803845 100644
--- a/tools/pythonpkg/src/pyconnection.cpp
+++ b/tools/pythonpkg/src/pyconnection.cpp
@@ -167,10 +167,6 @@ DuckDBPyConnection *DuckDBPyConnection::RegisterArrow(const string &name, py::ob
 	if (!connection) {
 		throw std::runtime_error("connection closed");
 	}
-	auto py_object_type = string(py::str(table.get_type().attr("__name__")));
-	if (table.is_none() || (py_object_type != "Table" && py_object_type != "FileSystemDataset")) {
-		throw std::runtime_error("Only arrow tables/datasets are supported");
-	}
 	auto stream_factory = make_unique<PythonTableArrowArrayStreamFactory>(table.ptr());
 
 	auto stream_factory_produce = PythonTableArrowArrayStreamFactory::Produce;
@@ -270,13 +266,6 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromArrowTable(py::object &tabl
 		throw std::runtime_error("connection closed");
 	}
 	py::gil_scoped_acquire acquire;
-
-	// the following is a careful dance around having to depend on pyarrow
-	auto py_object_type = string(py::str(table.get_type().attr("__name__")));
-	if (table.is_none() || (py_object_type != "Table" && py_object_type != "FileSystemDataset")) {
-		throw std::runtime_error("Only arrow tables/datasets are supported");
-	}
-
 	string name = "arrow_table_" + GenerateRandomName();
 
 	auto stream_factory = make_unique<PythonTableArrowArrayStreamFactory>(table.ptr());
