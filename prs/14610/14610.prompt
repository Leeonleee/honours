You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes.
In the patch file, please make sure to include the line numbers and a blank line at the end so it can be applied using git apply.

<issue>
INTERNAL error when using a macro to expand json[] array (`json_each`)
### What happens?

When I use the macro defined below with a `json[]` column, it errors out, but text and json types convert correctly.

INTERNAL Error: Failed to cast logical operator to type - logical operator type mismatch
This error signals an assertion failure within DuckDB. This usually occurs due to unexpected conditions or errors in the program's logic.
For more information, see https://duckdb.org/docs/dev/internal_errors

### To Reproduce

From the cli:
```sh
duckdb -c "
  CREATE OR REPLACE MACRO json_each(input) AS
    TABLE (
      SELECT
          CASE json_type (val::json)
          WHEN 'ARRAY' THEN
              unnest(RANGE (json_array_length(val::json)::bigint)) ::varchar
          ELSE
              unnest(json_keys (val::json))
          END AS key,
          json_extract (val::json, key) AS value
      FROM (SELECT input as val)
    );

  FROM (SELECT '[1,2,3]' as message) CROSS JOIN json_each(message);
  FROM (SELECT '[1,2,3]'::json as message) CROSS JOIN json_each(message);
  FROM (SELECT '[1,2,3]'::json[] as message) CROSS JOIN json_each(message);
  "
```

Output:
```
┌─────────┬─────────┬───────┐
│ message │   key   │ value │
│ varchar │ varchar │ json  │
├─────────┼─────────┼───────┤
│ [1,2,3] │ 0       │ 1     │
│ [1,2,3] │ 1       │ 2     │
│ [1,2,3] │ 2       │ 3     │
└─────────┴─────────┴───────┘
┌─────────┬─────────┬───────┐
│ message │   key   │ value │
│  json   │ varchar │ json  │
├─────────┼─────────┼───────┤
│ [1,2,3] │ 0       │ 1     │
│ [1,2,3] │ 1       │ 2     │
│ [1,2,3] │ 2       │ 3     │
└─────────┴─────────┴───────┘
INTERNAL Error: Failed to cast logical operator to type - logical operator type mismatch
This error signals an assertion failure within DuckDB. This usually occurs due to unexpected conditions or errors in the program's logic.
For more information, see https://duckdb.org/docs/dev/internal_errors
```

### OS:

linux

### DuckDB Version:

1.0.0, 1.1.0

### DuckDB Client:

CLI

### Hardware:

_No response_

### Full Name:

Ashkan Kiani

### Affiliation:

Jane Street

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a stable release

### Did you include all relevant data sets for reproducing the issue?

Yes

### Did you include all code required to reproduce the issue?

- [X] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [X] Yes, I have
INTERNAL error when using a macro to expand json[] array (`json_each`)
### What happens?

When I use the macro defined below with a `json[]` column, it errors out, but text and json types convert correctly.

INTERNAL Error: Failed to cast logical operator to type - logical operator type mismatch
This error signals an assertion failure within DuckDB. This usually occurs due to unexpected conditions or errors in the program's logic.
For more information, see https://duckdb.org/docs/dev/internal_errors

### To Reproduce

From the cli:
```sh
duckdb -c "
  CREATE OR REPLACE MACRO json_each(input) AS
    TABLE (
      SELECT
          CASE json_type (val::json)
          WHEN 'ARRAY' THEN
              unnest(RANGE (json_array_length(val::json)::bigint)) ::varchar
          ELSE
              unnest(json_keys (val::json))
          END AS key,
          json_extract (val::json, key) AS value
      FROM (SELECT input as val)
    );

  FROM (SELECT '[1,2,3]' as message) CROSS JOIN json_each(message);
  FROM (SELECT '[1,2,3]'::json as message) CROSS JOIN json_each(message);
  FROM (SELECT '[1,2,3]'::json[] as message) CROSS JOIN json_each(message);
  "
```

Output:
```
┌─────────┬─────────┬───────┐
│ message │   key   │ value │
│ varchar │ varchar │ json  │
├─────────┼─────────┼───────┤
│ [1,2,3] │ 0       │ 1     │
│ [1,2,3] │ 1       │ 2     │
│ [1,2,3] │ 2       │ 3     │
└─────────┴─────────┴───────┘
┌─────────┬─────────┬───────┐
│ message │   key   │ value │
│  json   │ varchar │ json  │
├─────────┼─────────┼───────┤
│ [1,2,3] │ 0       │ 1     │
│ [1,2,3] │ 1       │ 2     │
│ [1,2,3] │ 2       │ 3     │
└─────────┴─────────┴───────┘
INTERNAL Error: Failed to cast logical operator to type - logical operator type mismatch
This error signals an assertion failure within DuckDB. This usually occurs due to unexpected conditions or errors in the program's logic.
For more information, see https://duckdb.org/docs/dev/internal_errors
```

### OS:

linux

### DuckDB Version:

1.0.0, 1.1.0

### DuckDB Client:

CLI

### Hardware:

_No response_

### Full Name:

Ashkan Kiani

### Affiliation:

Jane Street

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a stable release

### Did you include all relevant data sets for reproducing the issue?

Yes

### Did you include all code required to reproduce the issue?

- [X] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [X] Yes, I have

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <picture>
3:     <source media="(prefers-color-scheme: light)" srcset="logo/DuckDB_Logo-horizontal.svg">
4:     <source media="(prefers-color-scheme: dark)" srcset="logo/DuckDB_Logo-horizontal-dark-mode.svg">
5:     <img alt="DuckDB logo" src="logo/DuckDB_Logo-horizontal.svg" height="100">
6:   </picture>
7: </div>
8: <br>
9: 
10: <p align="center">
11:   <a href="https://github.com/duckdb/duckdb/actions"><img src="https://github.com/duckdb/duckdb/actions/workflows/Main.yml/badge.svg?branch=main" alt="Github Actions Badge"></a>
12:   <a href="https://discord.gg/tcvwpjfnZx"><img src="https://shields.io/discord/909674491309850675" alt="discord" /></a>
13:   <a href="https://github.com/duckdb/duckdb/releases/"><img src="https://img.shields.io/github/v/release/duckdb/duckdb?color=brightgreen&display_name=tag&logo=duckdb&logoColor=white" alt="Latest Release"></a>
14: </p>
15: 
16: ## DuckDB
17: 
18: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable, portable, and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs, maps), and [several extensions designed to make SQL easier to use](https://duckdb.org/docs/guides/sql_features/friendly_sql).
19: 
20: DuckDB is available as a [standalone CLI application](https://duckdb.org/docs/api/cli/overview) and has clients for [Python](https://duckdb.org/docs/api/python/overview), [R](https://duckdb.org/docs/api/r), [Java](https://duckdb.org/docs/api/java), [Wasm](https://duckdb.org/docs/api/wasm/overview), etc., with deep integrations with packages such as [pandas](https://duckdb.org/docs/guides/python/sql_on_pandas) and [dplyr](https://duckdblabs.github.io/duckplyr/).
21: 
22: For more information on using DuckDB, please refer to the [DuckDB documentation](https://duckdb.org/docs/).
23: 
24: ## Installation
25: 
26: If you want to install DuckDB, please see [our installation page](https://duckdb.org/docs/installation/) for instructions.
27: 
28: ## Data Import
29: 
30: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
31: 
32: ```sql
33: SELECT * FROM 'myfile.csv';
34: SELECT * FROM 'myfile.parquet';
35: ```
36: 
37: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
38: 
39: ## SQL Reference
40: 
41: The documentation contains a [SQL introduction and reference](https://duckdb.org/docs/sql/introduction).
42: 
43: ## Development
44: 
45: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run `BUILD_BENCHMARK=1 BUILD_TPCH=1 make` and then perform several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`. The details of benchmarks are in our [Benchmark Guide](benchmark/README.md).
46: 
47: Please also refer to our [Build Guide](https://duckdb.org/dev/building) and [Contribution Guide](CONTRIBUTING.md).
48: 
49: ## Support
50: 
51: See the [Support Options](https://duckdblabs.com/support/) page.
[end of README.md]
[start of src/include/duckdb/optimizer/unnest_rewriter.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/optimizer/unnest_rewriter.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/planner/logical_operator.hpp"
12: #include "duckdb/common/pair.hpp"
13: 
14: namespace duckdb {
15: 
16: class Optimizer;
17: 
18: struct ReplaceBinding {
19: 	ReplaceBinding() {};
20: 	ReplaceBinding(ColumnBinding old_binding, ColumnBinding new_binding)
21: 	    : old_binding(old_binding), new_binding(new_binding) {
22: 	}
23: 	ColumnBinding old_binding;
24: 	ColumnBinding new_binding;
25: };
26: 
27: struct LHSBinding {
28: 	LHSBinding() {};
29: 	LHSBinding(ColumnBinding binding, LogicalType type_p) : binding(binding), type(std::move(type_p)) {
30: 	}
31: 	ColumnBinding binding;
32: 	LogicalType type;
33: 	string alias;
34: };
35: 
36: //! The UnnestRewriterPlanUpdater updates column bindings after changing the operator plan
37: class UnnestRewriterPlanUpdater : LogicalOperatorVisitor {
38: public:
39: 	UnnestRewriterPlanUpdater() {
40: 	}
41: 	//! Update each operator of the plan after moving an UNNEST into a projection
42: 	void VisitOperator(LogicalOperator &op) override;
43: 	//! Visit an expression and update its column bindings after moving and UNNEST into a projection
44: 	void VisitExpression(unique_ptr<Expression> *expression) override;
45: 
46: 	//! Contains all bindings that need to be updated
47: 	vector<ReplaceBinding> replace_bindings;
48: 	//! Stores the table index of the former child of the LOGICAL_UNNEST
49: 	idx_t overwritten_tbl_idx;
50: };
51: 
52: //! The UnnestRewriter optimizer traverses the logical operator tree and rewrites duplicate
53: //! eliminated joins that contain UNNESTs by moving the UNNESTs into the projection of
54: //! the SELECT
55: class UnnestRewriter {
56: public:
57: 	UnnestRewriter() {
58: 	}
59: 	//! Rewrite duplicate eliminated joins with UNNESTs
60: 	unique_ptr<LogicalOperator> Optimize(unique_ptr<LogicalOperator> op);
61: 
62: private:
63: 	//! Find delim joins that contain an UNNEST
64: 	void FindCandidates(unique_ptr<LogicalOperator> *op_ptr, vector<unique_ptr<LogicalOperator> *> &candidates);
65: 	//! Rewrite a delim join that contains an UNNEST
66: 	bool RewriteCandidate(unique_ptr<LogicalOperator> *candidate);
67: 	//! Update the bindings of the RHS sequence of LOGICAL_PROJECTION(s)
68: 	void UpdateRHSBindings(unique_ptr<LogicalOperator> *plan_ptr, unique_ptr<LogicalOperator> *candidate,
69: 	                       UnnestRewriterPlanUpdater &updater);
70: 	//! Update the bindings of the BOUND_UNNEST expression of the LOGICAL_UNNEST
71: 	void UpdateBoundUnnestBindings(UnnestRewriterPlanUpdater &updater, unique_ptr<LogicalOperator> *candidate);
72: 
73: 	//! Store all delim columns of the delim join
74: 	void GetDelimColumns(LogicalOperator &op);
75: 	//! Store all LHS expressions of the LOGICAL_PROJECTION
76: 	void GetLHSExpressions(LogicalOperator &op);
77: 
78: 	//! Keep track of the delim columns to find the correct UNNEST column
79: 	vector<ColumnBinding> delim_columns;
80: 	//! Store the column bindings of the LHS child of the LOGICAL_DELIM_JOIN
81: 	vector<LHSBinding> lhs_bindings;
82: 	//! Stores the table index of the former child of the LOGICAL_UNNEST
83: 	idx_t overwritten_tbl_idx;
84: 	//! The number of distinct columns to unnest
85: 	idx_t distinct_unnest_count;
86: };
87: 
88: } // namespace duckdb
[end of src/include/duckdb/optimizer/unnest_rewriter.hpp]
[start of src/optimizer/unnest_rewriter.cpp]
1: #include "duckdb/optimizer/unnest_rewriter.hpp"
2: 
3: #include "duckdb/common/pair.hpp"
4: #include "duckdb/planner/operator/logical_delim_get.hpp"
5: #include "duckdb/planner/operator/logical_comparison_join.hpp"
6: #include "duckdb/planner/operator/logical_unnest.hpp"
7: #include "duckdb/planner/operator/logical_projection.hpp"
8: #include "duckdb/planner/operator/logical_window.hpp"
9: #include "duckdb/planner/expression/bound_unnest_expression.hpp"
10: #include "duckdb/planner/expression/bound_columnref_expression.hpp"
11: 
12: namespace duckdb {
13: 
14: void UnnestRewriterPlanUpdater::VisitOperator(LogicalOperator &op) {
15: 	VisitOperatorChildren(op);
16: 	VisitOperatorExpressions(op);
17: }
18: 
19: void UnnestRewriterPlanUpdater::VisitExpression(unique_ptr<Expression> *expression) {
20: 	auto &expr = *expression;
21: 
22: 	if (expr->expression_class == ExpressionClass::BOUND_COLUMN_REF) {
23: 		auto &bound_column_ref = expr->Cast<BoundColumnRefExpression>();
24: 		for (idx_t i = 0; i < replace_bindings.size(); i++) {
25: 			if (bound_column_ref.binding == replace_bindings[i].old_binding) {
26: 				bound_column_ref.binding = replace_bindings[i].new_binding;
27: 				break;
28: 			}
29: 		}
30: 	}
31: 
32: 	VisitExpressionChildren(**expression);
33: }
34: 
35: unique_ptr<LogicalOperator> UnnestRewriter::Optimize(unique_ptr<LogicalOperator> op) {
36: 
37: 	UnnestRewriterPlanUpdater updater;
38: 	vector<unique_ptr<LogicalOperator> *> candidates;
39: 	FindCandidates(&op, candidates);
40: 
41: 	// rewrite the plan and update the bindings
42: 	for (auto &candidate : candidates) {
43: 
44: 		// rearrange the logical operators
45: 		if (RewriteCandidate(candidate)) {
46: 			updater.overwritten_tbl_idx = overwritten_tbl_idx;
47: 			// update the bindings of the BOUND_UNNEST expression
48: 			UpdateBoundUnnestBindings(updater, candidate);
49: 			// update the sequence of LOGICAL_PROJECTION(s)
50: 			UpdateRHSBindings(&op, candidate, updater);
51: 			// reset
52: 			delim_columns.clear();
53: 			lhs_bindings.clear();
54: 		}
55: 	}
56: 
57: 	return op;
58: }
59: 
60: void UnnestRewriter::FindCandidates(unique_ptr<LogicalOperator> *op_ptr,
61:                                     vector<unique_ptr<LogicalOperator> *> &candidates) {
62: 	auto op = op_ptr->get();
63: 	// search children before adding, so that we add candidates bottom-up
64: 	for (auto &child : op->children) {
65: 		FindCandidates(&child, candidates);
66: 	}
67: 
68: 	// search for operator that has a LOGICAL_DELIM_JOIN as its child
69: 	if (op->children.size() != 1) {
70: 		return;
71: 	}
72: 	if (op->children[0]->type != LogicalOperatorType::LOGICAL_DELIM_JOIN) {
73: 		return;
74: 	}
75: 
76: 	// found a delim join
77: 	auto &delim_join = op->children[0]->Cast<LogicalComparisonJoin>();
78: 	// only support INNER delim joins
79: 	if (delim_join.join_type != JoinType::INNER) {
80: 		return;
81: 	}
82: 	// INNER delim join must have exactly one condition
83: 	if (delim_join.conditions.size() != 1) {
84: 		return;
85: 	}
86: 
87: 	// LHS child is a window
88: 	idx_t delim_idx = delim_join.delim_flipped ? 1 : 0;
89: 	idx_t other_idx = 1 - delim_idx;
90: 	if (delim_join.children[delim_idx]->type != LogicalOperatorType::LOGICAL_WINDOW) {
91: 		return;
92: 	}
93: 
94: 	// RHS child must be projection(s) followed by an UNNEST
95: 	auto curr_op = &delim_join.children[other_idx];
96: 	while (curr_op->get()->type == LogicalOperatorType::LOGICAL_PROJECTION) {
97: 		if (curr_op->get()->children.size() != 1) {
98: 			break;
99: 		}
100: 		curr_op = &curr_op->get()->children[0];
101: 	}
102: 
103: 	if (curr_op->get()->type == LogicalOperatorType::LOGICAL_UNNEST) {
104: 		candidates.push_back(op_ptr);
105: 	}
106: }
107: 
108: bool UnnestRewriter::RewriteCandidate(unique_ptr<LogicalOperator> *candidate) {
109: 
110: 	auto &topmost_op = (LogicalOperator &)**candidate;
111: 	if (topmost_op.type != LogicalOperatorType::LOGICAL_PROJECTION &&
112: 	    topmost_op.type != LogicalOperatorType::LOGICAL_WINDOW &&
113: 	    topmost_op.type != LogicalOperatorType::LOGICAL_FILTER &&
114: 	    topmost_op.type != LogicalOperatorType::LOGICAL_AGGREGATE_AND_GROUP_BY &&
115: 	    topmost_op.type != LogicalOperatorType::LOGICAL_UNNEST) {
116: 		return false;
117: 	}
118: 
119: 	// get the LOGICAL_DELIM_JOIN, which is a child of the candidate
120: 	D_ASSERT(topmost_op.children.size() == 1);
121: 	auto &delim_join = topmost_op.children[0]->Cast<LogicalComparisonJoin>();
122: 	D_ASSERT(delim_join.type == LogicalOperatorType::LOGICAL_DELIM_JOIN);
123: 	GetDelimColumns(delim_join);
124: 
125: 	// LHS of the LOGICAL_DELIM_JOIN is a LOGICAL_WINDOW that contains a LOGICAL_PROJECTION
126: 	// this lhs_proj later becomes the child of the UNNEST
127: 
128: 	idx_t delim_idx = delim_join.delim_flipped ? 1 : 0;
129: 	idx_t other_idx = 1 - delim_idx;
130: 	auto &window = *delim_join.children[delim_idx];
131: 	auto &lhs_op = window.children[0];
132: 	GetLHSExpressions(*lhs_op);
133: 
134: 	// find the LOGICAL_UNNEST
135: 	// and get the path down to the LOGICAL_UNNEST
136: 	vector<unique_ptr<LogicalOperator> *> path_to_unnest;
137: 	auto curr_op = &delim_join.children[other_idx];
138: 	while (curr_op->get()->type == LogicalOperatorType::LOGICAL_PROJECTION) {
139: 		path_to_unnest.push_back(curr_op);
140: 		curr_op = &curr_op->get()->children[0];
141: 	}
142: 
143: 	// store the table index of the child of the LOGICAL_UNNEST
144: 	// then update the plan by making the lhs_proj the child of the LOGICAL_UNNEST
145: 	D_ASSERT(curr_op->get()->type == LogicalOperatorType::LOGICAL_UNNEST);
146: 	auto &unnest = curr_op->get()->Cast<LogicalUnnest>();
147: 	D_ASSERT(unnest.children[0]->type == LogicalOperatorType::LOGICAL_DELIM_GET);
148: 	overwritten_tbl_idx = unnest.children[0]->Cast<LogicalDelimGet>().table_index;
149: 
150: 	D_ASSERT(!unnest.children.empty());
151: 	auto &delim_get = unnest.children[0]->Cast<LogicalDelimGet>();
152: 	D_ASSERT(delim_get.chunk_types.size() > 1);
153: 	distinct_unnest_count = delim_get.chunk_types.size();
154: 	unnest.children[0] = std::move(lhs_op);
155: 
156: 	// replace the LOGICAL_DELIM_JOIN with its RHS child operator
157: 	topmost_op.children[0] = std::move(*path_to_unnest.front());
158: 	return true;
159: }
160: 
161: void UnnestRewriter::UpdateRHSBindings(unique_ptr<LogicalOperator> *plan_ptr, unique_ptr<LogicalOperator> *candidate,
162:                                        UnnestRewriterPlanUpdater &updater) {
163: 
164: 	auto &topmost_op = (LogicalOperator &)**candidate;
165: 	idx_t shift = lhs_bindings.size();
166: 
167: 	vector<unique_ptr<LogicalOperator> *> path_to_unnest;
168: 	auto curr_op = &topmost_op.children[0];
169: 	while (curr_op->get()->type == LogicalOperatorType::LOGICAL_PROJECTION) {
170: 
171: 		path_to_unnest.push_back(curr_op);
172: 		D_ASSERT(curr_op->get()->type == LogicalOperatorType::LOGICAL_PROJECTION);
173: 		auto &proj = curr_op->get()->Cast<LogicalProjection>();
174: 
175: 		// pop the unnest columns and the delim index
176: 		D_ASSERT(proj.expressions.size() > distinct_unnest_count);
177: 		for (idx_t i = 0; i < distinct_unnest_count; i++) {
178: 			proj.expressions.pop_back();
179: 		}
180: 
181: 		// store all shifted current bindings
182: 		idx_t tbl_idx = proj.table_index;
183: 		for (idx_t i = 0; i < proj.expressions.size(); i++) {
184: 			ReplaceBinding replace_binding(ColumnBinding(tbl_idx, i), ColumnBinding(tbl_idx, i + shift));
185: 			updater.replace_bindings.push_back(replace_binding);
186: 		}
187: 
188: 		curr_op = &curr_op->get()->children[0];
189: 	}
190: 
191: 	// update all bindings by shifting them
192: 	updater.VisitOperator(*plan_ptr->get());
193: 	updater.replace_bindings.clear();
194: 
195: 	// update all bindings coming from the LHS to RHS bindings
196: 	D_ASSERT(topmost_op.children[0]->type == LogicalOperatorType::LOGICAL_PROJECTION);
197: 	auto &top_proj = topmost_op.children[0]->Cast<LogicalProjection>();
198: 	for (idx_t i = 0; i < lhs_bindings.size(); i++) {
199: 		ReplaceBinding replace_binding(lhs_bindings[i].binding, ColumnBinding(top_proj.table_index, i));
200: 		updater.replace_bindings.push_back(replace_binding);
201: 	}
202: 
203: 	// temporarily remove the BOUND_UNNESTs and the child of the LOGICAL_UNNEST from the plan
204: 	D_ASSERT(curr_op->get()->type == LogicalOperatorType::LOGICAL_UNNEST);
205: 	auto &unnest = curr_op->get()->Cast<LogicalUnnest>();
206: 	vector<unique_ptr<Expression>> temp_bound_unnests;
207: 	for (auto &temp_bound_unnest : unnest.expressions) {
208: 		temp_bound_unnests.push_back(std::move(temp_bound_unnest));
209: 	}
210: 	D_ASSERT(unnest.children.size() == 1);
211: 	auto temp_unnest_child = std::move(unnest.children[0]);
212: 	unnest.expressions.clear();
213: 	unnest.children.clear();
214: 	// update the bindings of the plan
215: 	updater.VisitOperator(*plan_ptr->get());
216: 	updater.replace_bindings.clear();
217: 	// add the children again
218: 	for (auto &temp_bound_unnest : temp_bound_unnests) {
219: 		unnest.expressions.push_back(std::move(temp_bound_unnest));
220: 	}
221: 	unnest.children.push_back(std::move(temp_unnest_child));
222: 
223: 	// add the LHS expressions to each LOGICAL_PROJECTION
224: 	for (idx_t i = path_to_unnest.size(); i > 0; i--) {
225: 
226: 		D_ASSERT(path_to_unnest[i - 1]->get()->type == LogicalOperatorType::LOGICAL_PROJECTION);
227: 		auto &proj = path_to_unnest[i - 1]->get()->Cast<LogicalProjection>();
228: 
229: 		// temporarily store the existing expressions
230: 		vector<unique_ptr<Expression>> existing_expressions;
231: 		for (idx_t expr_idx = 0; expr_idx < proj.expressions.size(); expr_idx++) {
232: 			existing_expressions.push_back(std::move(proj.expressions[expr_idx]));
233: 		}
234: 
235: 		proj.expressions.clear();
236: 
237: 		// add the new expressions
238: 		for (idx_t expr_idx = 0; expr_idx < lhs_bindings.size(); expr_idx++) {
239: 			auto new_expr = make_uniq<BoundColumnRefExpression>(
240: 			    lhs_bindings[expr_idx].alias, lhs_bindings[expr_idx].type, lhs_bindings[expr_idx].binding);
241: 			proj.expressions.push_back(std::move(new_expr));
242: 
243: 			// update the table index
244: 			lhs_bindings[expr_idx].binding.table_index = proj.table_index;
245: 			lhs_bindings[expr_idx].binding.column_index = expr_idx;
246: 		}
247: 
248: 		// add the existing expressions again
249: 		for (idx_t expr_idx = 0; expr_idx < existing_expressions.size(); expr_idx++) {
250: 			proj.expressions.push_back(std::move(existing_expressions[expr_idx]));
251: 		}
252: 	}
253: }
254: 
255: void UnnestRewriter::UpdateBoundUnnestBindings(UnnestRewriterPlanUpdater &updater,
256:                                                unique_ptr<LogicalOperator> *candidate) {
257: 
258: 	auto &topmost_op = (LogicalOperator &)**candidate;
259: 
260: 	// traverse LOGICAL_PROJECTION(s)
261: 	auto curr_op = &topmost_op.children[0];
262: 	while (curr_op->get()->type == LogicalOperatorType::LOGICAL_PROJECTION) {
263: 		curr_op = &curr_op->get()->children[0];
264: 	}
265: 
266: 	// found the LOGICAL_UNNEST
267: 	D_ASSERT(curr_op->get()->type == LogicalOperatorType::LOGICAL_UNNEST);
268: 	auto &unnest = curr_op->get()->Cast<LogicalUnnest>();
269: 
270: 	D_ASSERT(unnest.children.size() == 1);
271: 	auto unnest_cols = unnest.children[0]->GetColumnBindings();
272: 
273: 	for (idx_t i = 0; i < delim_columns.size(); i++) {
274: 		auto delim_binding = delim_columns[i];
275: 
276: 		auto unnest_it = unnest_cols.begin();
277: 		while (unnest_it != unnest_cols.end()) {
278: 			auto unnest_binding = *unnest_it;
279: 
280: 			if (delim_binding.table_index == unnest_binding.table_index) {
281: 				unnest_binding.table_index = overwritten_tbl_idx;
282: 				unnest_binding.column_index++;
283: 				updater.replace_bindings.emplace_back(unnest_binding, delim_binding);
284: 				unnest_cols.erase(unnest_it);
285: 				break;
286: 			}
287: 			unnest_it++;
288: 		}
289: 	}
290: 
291: 	// update bindings
292: 	for (auto &unnest_expr : unnest.expressions) {
293: 		updater.VisitExpression(&unnest_expr);
294: 	}
295: 	updater.replace_bindings.clear();
296: }
297: 
298: void UnnestRewriter::GetDelimColumns(LogicalOperator &op) {
299: 
300: 	D_ASSERT(op.type == LogicalOperatorType::LOGICAL_DELIM_JOIN);
301: 	auto &delim_join = op.Cast<LogicalComparisonJoin>();
302: 	for (idx_t i = 0; i < delim_join.duplicate_eliminated_columns.size(); i++) {
303: 		auto &expr = *delim_join.duplicate_eliminated_columns[i];
304: 		D_ASSERT(expr.type == ExpressionType::BOUND_COLUMN_REF);
305: 		auto &bound_colref_expr = expr.Cast<BoundColumnRefExpression>();
306: 		delim_columns.push_back(bound_colref_expr.binding);
307: 	}
308: }
309: 
310: void UnnestRewriter::GetLHSExpressions(LogicalOperator &op) {
311: 
312: 	op.ResolveOperatorTypes();
313: 	auto col_bindings = op.GetColumnBindings();
314: 	D_ASSERT(op.types.size() == col_bindings.size());
315: 
316: 	bool set_alias = false;
317: 	// we can easily extract the alias for LOGICAL_PROJECTION(s)
318: 	if (op.type == LogicalOperatorType::LOGICAL_PROJECTION) {
319: 		auto &proj = op.Cast<LogicalProjection>();
320: 		if (proj.expressions.size() == op.types.size()) {
321: 			set_alias = true;
322: 		}
323: 	}
324: 
325: 	for (idx_t i = 0; i < op.types.size(); i++) {
326: 		lhs_bindings.emplace_back(col_bindings[i], op.types[i]);
327: 		if (set_alias) {
328: 			auto &proj = op.Cast<LogicalProjection>();
329: 			lhs_bindings.back().alias = proj.expressions[i]->alias;
330: 		}
331: 	}
332: }
333: 
334: } // namespace duckdb
[end of src/optimizer/unnest_rewriter.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: