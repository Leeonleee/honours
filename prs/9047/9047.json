{
  "repo": "duckdb/duckdb",
  "pull_number": 9047,
  "instance_id": "duckdb__duckdb-9047",
  "issue_numbers": [
    "6722"
  ],
  "base_commit": "13c627a65e0253a916c98149b8a48e1a16f2fc55",
  "patch": "diff --git a/data/json/duplicate_column_names.json b/data/json/duplicate_column_names.json\nnew file mode 100644\nindex 000000000000..cd1db52b159f\n--- /dev/null\n+++ b/data/json/duplicate_column_names.json\n@@ -0,0 +1,1 @@\n+{\"id\": 42, \"Id\": 43, \"iD\": 44, \"ID\": 45}\ndiff --git a/extension/json/json_functions/read_json.cpp b/extension/json/json_functions/read_json.cpp\nindex fc6fe6736cb8..238660a1e207 100644\n--- a/extension/json/json_functions/read_json.cpp\n+++ b/extension/json/json_functions/read_json.cpp\n@@ -229,6 +229,21 @@ unique_ptr<FunctionData> ReadJSONBind(ClientContext &context, TableFunctionBindI\n \ttransform_options.error_unknown_key = bind_data->auto_detect && !bind_data->ignore_errors;\n \ttransform_options.delay_error = true;\n \n+\tif (bind_data->auto_detect) {\n+\t\t// JSON may contain columns such as \"id\" and \"Id\", which are duplicates for us due to case-insensitivity\n+\t\t// We rename them so we can parse the file anyway. Note that we can't change bind_data->names,\n+\t\t// because the JSON reader gets columns by exact name, not position\n+\t\tcase_insensitive_map_t<idx_t> name_count_map;\n+\t\tfor (auto &name : names) {\n+\t\t\tauto it = name_count_map.find(name);\n+\t\t\tif (it == name_count_map.end()) {\n+\t\t\t\tname_count_map[name] = 1;\n+\t\t\t} else {\n+\t\t\t\tname = StringUtil::Format(\"%s_%llu\", name, it->second++);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n \treturn std::move(bind_data);\n }\n \n",
  "test_patch": "diff --git a/test/sql/json/issues/issue6722.test b/test/sql/json/issues/issue6722.test\nnew file mode 100644\nindex 000000000000..b00843052533\n--- /dev/null\n+++ b/test/sql/json/issues/issue6722.test\n@@ -0,0 +1,23 @@\n+# name: test/sql/json/issues/issue6722.test\n+# description: Test issue 6722 - INTERNAL Error: read_json_auto and read_json(auto_detect=true) fail to handle property name case sensitivities\n+# group: [issues]\n+\n+require json\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+# this file has 4 columns, name \"id\", \"Id\", \"iD\", and \"ID\"\n+query IIII\n+FROM 'data/json/duplicate_column_names.json'\n+----\n+42\t43\t44\t45\n+\n+# due to case-insensitivity these column names would cause an error, but we add a number to de-duplicate them\n+query IIIIII\n+DESCRIBE FROM 'data/json/duplicate_column_names.json'\n+----\n+id\tBIGINT\tYES\tNULL\tNULL\tNULL\n+Id_1\tBIGINT\tYES\tNULL\tNULL\tNULL\n+iD_2\tBIGINT\tYES\tNULL\tNULL\tNULL\n+ID_3\tBIGINT\tYES\tNULL\tNULL\tNULL\n",
  "problem_statement": "read_json_auto and read_json(auto_detect=true) fail to handle property name case sensitivities\n### What happens?\n\nI am receiving json log files that occasionally have payloads in which both `id` and `Id` properties are represented, like this:\r\n\r\n```\r\n{\r\n\t\"Status\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\",\r\n\t\"event_simpleName\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\",\r\n\t\"ErrorText\": \"\ud83e\udd86\",\r\n\t\"ConfigStateHash\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\",\r\n\t\"aip\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\",\r\n\t\"SHA256HashData\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\",\r\n\t\"ConfigBuild\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\",\r\n\t\"event_platform\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\",\r\n\t\"Entitlements\": \"\ud83e\udd86\",\r\n\t\"name\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\",\r\n\t\"id\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\",\r\n\t\"Id\": \"\ud83e\udd86\",\r\n\t\"EffectiveTransmissionClass\": \"\ud83e\udd86\",\r\n\t\"aid\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\",\r\n\t\"CloudErrorCode\": \"\ud83e\udd86\",\r\n\t\"timestamp\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\",\r\n\t\"cid\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\",\r\n\t\"TargetFileName\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\"\r\n}\r\n```\r\n\r\nThis is technically valid json, but when duckdb tries to auto-discover the schema via `read_json_auto` or `read_json(auto_detect=true)` it \ud83d\udc80 \u2620\ufe0f  the \ud83e\udd86:\r\n\r\n```\r\nselect * from read_json('sample.json', auto_detect=true);\r\nError: Binder Error: table \"read_json\" has duplicate column name \"Id\"\r\n```\r\n\r\n\r\nIt is completely understandable why this is happening (and my workaround is manually declaring the columns), but it would be awesome if the json extension could retain case sensitivities.\r\n\r\n\n\n### To Reproduce\n\nDrop this payload into a `sample.json` file:\r\n\r\n```\r\n{\"Status\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\",\"event_simpleName\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\",\"ErrorText\": \"\ud83e\udd86\",\"ConfigStateHash\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\",\"aip\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\",\"SHA256HashData\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\",\"ConfigBuild\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\",\"event_platform\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\",\"Entitlements\": \"\ud83e\udd86\",\"name\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\",\"id\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\",\"Id\": \"\ud83e\udd86\",\"EffectiveTransmissionClass\": \"\ud83e\udd86\",\"aid\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\",\"CloudErrorCode\": \"\ud83e\udd86\",\"timestamp\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\",\"cid\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\",\"TargetFileName\": \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\ud83e\udd86\"}\r\n```\r\n\r\n\r\nAnd execute:\r\n\r\n```\r\nselect * from read_json_auto('sample.json');\r\n```\r\n\r\nor\r\n\r\n```\r\nselect * from read_json('sample.json', auto_detect=true)\r\n```\n\n### OS:\n\nmacos\n\n### DuckDB Version:\n\n0.7.2\n\n### DuckDB Client:\n\nUsing the cli, but would assume all of them\n\n### Full Name:\n\nJake Thomas\n\n### Affiliation:\n\nOkta\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\n",
  "hints_text": "Hi @jakthom, thanks for the bug report! I don't think the issue here is specific to the JSON reader but is a design choice in DuckDB: Our column names are case-insensitive, so this does not work:\r\n```sql\r\ncreate table test(\"id\" int, \"Id\" int);\r\nError: Catalog Error: Column with name Id already exists!\r\n```\r\n\r\nOur JSON reader can disambiguate between the two because it is not case-insensitive, but the resulting column would have to be renamed to `\"id2\"` for it to be valid in DuckDB.\nIndeed, I have the same issue with `postgres_attach`.\nThis issue is stale because it has been open 90 days with no activity. Remove stale label or comment or this will be closed in 30 days.\nStill valid.",
  "created_at": "2023-09-22T12:23:30Z"
}