{
  "repo": "duckdb/duckdb",
  "pull_number": 14693,
  "instance_id": "duckdb__duckdb-14693",
  "issue_numbers": [
    "14639"
  ],
  "base_commit": "0ccf3c25ccbb25fb90616e77b38f6d138f82950d",
  "patch": "diff --git a/src/catalog/catalog.cpp b/src/catalog/catalog.cpp\nindex cc2a9cd4e17d..aadaf1fcb404 100644\n--- a/src/catalog/catalog.cpp\n+++ b/src/catalog/catalog.cpp\n@@ -396,7 +396,12 @@ vector<CatalogSearchEntry> GetCatalogEntries(CatalogEntryRetriever &retriever, c\n \t\t\tentries.emplace_back(catalog_name, schema);\n \t\t}\n \t\tif (entries.empty()) {\n-\t\t\tentries.emplace_back(DatabaseManager::GetDefaultDatabase(context), schema);\n+\t\t\tauto &default_entry = search_path.GetDefault();\n+\t\t\tif (!IsInvalidCatalog(default_entry.catalog)) {\n+\t\t\t\tentries.emplace_back(default_entry.catalog, schema);\n+\t\t\t} else {\n+\t\t\t\tentries.emplace_back(DatabaseManager::GetDefaultDatabase(context), schema);\n+\t\t\t}\n \t\t}\n \t} else if (IsInvalidSchema(schema)) {\n \t\tauto schemas = search_path.GetSchemasForCatalog(catalog);\ndiff --git a/src/execution/physical_plan_generator.cpp b/src/execution/physical_plan_generator.cpp\nindex 9dead09094d7..1ac6f61b206b 100644\n--- a/src/execution/physical_plan_generator.cpp\n+++ b/src/execution/physical_plan_generator.cpp\n@@ -13,24 +13,6 @@\n \n namespace duckdb {\n \n-class DependencyExtractor : public LogicalOperatorVisitor {\n-public:\n-\texplicit DependencyExtractor(LogicalDependencyList &dependencies) : dependencies(dependencies) {\n-\t}\n-\n-protected:\n-\tunique_ptr<Expression> VisitReplace(BoundFunctionExpression &expr, unique_ptr<Expression> *expr_ptr) override {\n-\t\t// extract dependencies from the bound function expression\n-\t\tif (expr.function.dependency) {\n-\t\t\texpr.function.dependency(expr, dependencies);\n-\t\t}\n-\t\treturn nullptr;\n-\t}\n-\n-private:\n-\tLogicalDependencyList &dependencies;\n-};\n-\n PhysicalPlanGenerator::PhysicalPlanGenerator(ClientContext &context) : context(context) {\n }\n \n@@ -51,10 +33,6 @@ unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(unique_ptr<Logica\n \top->ResolveOperatorTypes();\n \tprofiler.EndPhase();\n \n-\t// extract dependencies from the logical plan\n-\tDependencyExtractor extractor(dependencies);\n-\textractor.VisitOperator(*op);\n-\n \t// then create the main physical plan\n \tprofiler.StartPhase(MetricsType::PHYSICAL_PLANNER_CREATE_PLAN);\n \tauto plan = CreatePlan(*op);\ndiff --git a/src/function/function_binder.cpp b/src/function/function_binder.cpp\nindex 9aff648a480e..5a554401f153 100644\n--- a/src/function/function_binder.cpp\n+++ b/src/function/function_binder.cpp\n@@ -16,7 +16,9 @@\n \n namespace duckdb {\n \n-FunctionBinder::FunctionBinder(ClientContext &context) : context(context) {\n+FunctionBinder::FunctionBinder(ClientContext &context_p) : binder(nullptr), context(context_p) {\n+}\n+FunctionBinder::FunctionBinder(Binder &binder_p) : binder(&binder_p), context(binder_p.context) {\n }\n \n optional_idx FunctionBinder::BindVarArgsFunctionCost(const SimpleFunction &func, const vector<LogicalType> &arguments) {\n@@ -440,7 +442,16 @@ unique_ptr<Expression> FunctionBinder::BindScalarFunction(ScalarFunction bound_f\n \n \tif (bound_function.bind) {\n \t\tbind_info = bound_function.bind(context, bound_function, children);\n+\t} else if (bound_function.bind_extended) {\n+\t\tif (!binder) {\n+\t\t\tthrow InternalException(\"Function '%s' has a 'bind_extended' but the FunctionBinder was created without \"\n+\t\t\t                        \"a reference to a Binder\",\n+\t\t\t                        bound_function.name);\n+\t\t}\n+\t\tScalarFunctionBindInput bind_input(*binder);\n+\t\tbind_info = bound_function.bind_extended(bind_input, bound_function, children);\n \t}\n+\n \tif (bound_function.get_modified_databases && binder) {\n \t\tauto &properties = binder->GetStatementProperties();\n \t\tFunctionModifiedDatabasesInput input(bind_info, properties);\ndiff --git a/src/function/scalar/sequence/nextval.cpp b/src/function/scalar/sequence/nextval.cpp\nindex d70168c9a784..b5ae85c86f44 100644\n--- a/src/function/scalar/sequence/nextval.cpp\n+++ b/src/function/scalar/sequence/nextval.cpp\n@@ -29,15 +29,23 @@ struct NextSequenceValueOperator {\n \t}\n };\n \n-SequenceCatalogEntry &BindSequence(ClientContext &context, string &catalog, string &schema, const string &name) {\n+SequenceCatalogEntry &BindSequence(Binder &binder, string &catalog, string &schema, const string &name) {\n \t// fetch the sequence from the catalog\n+\tBinder::BindSchemaOrCatalog(binder.context, catalog, schema);\n+\treturn binder.EntryRetriever()\n+\t    .GetEntry(CatalogType::SEQUENCE_ENTRY, catalog, schema, name)\n+\t    ->Cast<SequenceCatalogEntry>();\n+}\n+\n+SequenceCatalogEntry &BindSequenceFromContext(ClientContext &context, string &catalog, string &schema,\n+                                              const string &name) {\n \tBinder::BindSchemaOrCatalog(context, catalog, schema);\n \treturn Catalog::GetEntry<SequenceCatalogEntry>(context, catalog, schema, name);\n }\n \n-SequenceCatalogEntry &BindSequence(ClientContext &context, const string &name) {\n+SequenceCatalogEntry &BindSequence(Binder &binder, const string &name) {\n \tauto qname = QualifiedName::Parse(name);\n-\treturn BindSequence(context, qname.catalog, qname.schema, qname.name);\n+\treturn BindSequence(binder, qname.catalog, qname.schema, qname.name);\n }\n \n struct NextValLocalState : public FunctionLocalState {\n@@ -81,30 +89,23 @@ static void NextValFunction(DataChunk &args, ExpressionState &state, Vector &res\n \t}\n }\n \n-static unique_ptr<FunctionData> NextValBind(ClientContext &context, ScalarFunction &,\n+static unique_ptr<FunctionData> NextValBind(ScalarFunctionBindInput &bind_input, ScalarFunction &,\n                                             vector<unique_ptr<Expression>> &arguments) {\n \tif (!arguments[0]->IsFoldable()) {\n \t\tthrow NotImplementedException(\n \t\t    \"currval/nextval requires a constant sequence - non-constant sequences are no longer supported\");\n \t}\n+\tauto &binder = bind_input.binder;\n \t// parameter to nextval function is a foldable constant\n \t// evaluate the constant and perform the catalog lookup already\n-\tauto seqname = ExpressionExecutor::EvaluateScalar(context, *arguments[0]);\n+\tauto seqname = ExpressionExecutor::EvaluateScalar(binder.context, *arguments[0]);\n \tif (seqname.IsNull()) {\n \t\treturn nullptr;\n \t}\n-\tauto &seq = BindSequence(context, seqname.ToString());\n+\tauto &seq = BindSequence(binder, seqname.ToString());\n \treturn make_uniq<NextvalBindData>(seq);\n }\n \n-static void NextValDependency(BoundFunctionExpression &expr, LogicalDependencyList &dependencies) {\n-\tif (!expr.bind_info) {\n-\t\treturn;\n-\t}\n-\tauto &info = expr.bind_info->Cast<NextvalBindData>();\n-\tdependencies.AddDependency(info.sequence);\n-}\n-\n void Serialize(Serializer &serializer, const optional_ptr<FunctionData> bind_data, const ScalarFunction &) {\n \tauto &next_val_bind_data = bind_data->Cast<NextvalBindData>();\n \tserializer.WritePropertyWithDefault(100, \"sequence_create_info\", next_val_bind_data.create_info);\n@@ -118,7 +119,7 @@ unique_ptr<FunctionData> Deserialize(Deserializer &deserializer, ScalarFunction\n \t}\n \tauto &seq_info = create_info->Cast<CreateSequenceInfo>();\n \tauto &context = deserializer.Get<ClientContext &>();\n-\tauto &sequence = BindSequence(context, seq_info.catalog, seq_info.schema, seq_info.name);\n+\tauto &sequence = BindSequenceFromContext(context, seq_info.catalog, seq_info.schema, seq_info.name);\n \treturn make_uniq<NextvalBindData>(sequence);\n }\n \n@@ -132,7 +133,8 @@ void NextValModifiedDatabases(ClientContext &context, FunctionModifiedDatabasesI\n \n ScalarFunction NextvalFun::GetFunction() {\n \tScalarFunction next_val(\"nextval\", {LogicalType::VARCHAR}, LogicalType::BIGINT,\n-\t                        NextValFunction<NextSequenceValueOperator>, NextValBind, NextValDependency);\n+\t                        NextValFunction<NextSequenceValueOperator>, nullptr, nullptr);\n+\tnext_val.bind_extended = NextValBind;\n \tnext_val.stability = FunctionStability::VOLATILE;\n \tnext_val.serialize = Serialize;\n \tnext_val.deserialize = Deserialize;\n@@ -143,7 +145,8 @@ ScalarFunction NextvalFun::GetFunction() {\n \n ScalarFunction CurrvalFun::GetFunction() {\n \tScalarFunction curr_val(\"currval\", {LogicalType::VARCHAR}, LogicalType::BIGINT,\n-\t                        NextValFunction<CurrentSequenceValueOperator>, NextValBind, NextValDependency);\n+\t                        NextValFunction<CurrentSequenceValueOperator>, nullptr, nullptr);\n+\tcurr_val.bind_extended = NextValBind;\n \tcurr_val.stability = FunctionStability::VOLATILE;\n \tcurr_val.serialize = Serialize;\n \tcurr_val.deserialize = Deserialize;\ndiff --git a/src/function/scalar_function.cpp b/src/function/scalar_function.cpp\nindex 75d74cf50970..a627643fd518 100644\n--- a/src/function/scalar_function.cpp\n+++ b/src/function/scalar_function.cpp\n@@ -10,28 +10,28 @@ ScalarFunctionInfo::~ScalarFunctionInfo() {\n \n ScalarFunction::ScalarFunction(string name, vector<LogicalType> arguments, LogicalType return_type,\n                                scalar_function_t function, bind_scalar_function_t bind,\n-                               dependency_function_t dependency, function_statistics_t statistics,\n+                               bind_scalar_function_extended_t bind_extended, function_statistics_t statistics,\n                                init_local_state_t init_local_state, LogicalType varargs, FunctionStability side_effects,\n                                FunctionNullHandling null_handling, bind_lambda_function_t bind_lambda)\n     : BaseScalarFunction(std::move(name), std::move(arguments), std::move(return_type), side_effects,\n                          std::move(varargs), null_handling),\n-      function(std::move(function)), bind(bind), init_local_state(init_local_state), dependency(dependency),\n+      function(std::move(function)), bind(bind), bind_extended(bind_extended), init_local_state(init_local_state),\n       statistics(statistics), bind_lambda(bind_lambda), bind_expression(nullptr), get_modified_databases(nullptr),\n       serialize(nullptr), deserialize(nullptr) {\n }\n \n ScalarFunction::ScalarFunction(vector<LogicalType> arguments, LogicalType return_type, scalar_function_t function,\n-                               bind_scalar_function_t bind, dependency_function_t dependency,\n+                               bind_scalar_function_t bind, bind_scalar_function_extended_t bind_extended,\n                                function_statistics_t statistics, init_local_state_t init_local_state,\n                                LogicalType varargs, FunctionStability side_effects, FunctionNullHandling null_handling,\n                                bind_lambda_function_t bind_lambda)\n-    : ScalarFunction(string(), std::move(arguments), std::move(return_type), std::move(function), bind, dependency,\n+    : ScalarFunction(string(), std::move(arguments), std::move(return_type), std::move(function), bind, bind_extended,\n                      statistics, init_local_state, std::move(varargs), side_effects, null_handling, bind_lambda) {\n }\n \n bool ScalarFunction::operator==(const ScalarFunction &rhs) const {\n \treturn name == rhs.name && arguments == rhs.arguments && return_type == rhs.return_type && varargs == rhs.varargs &&\n-\t       bind == rhs.bind && dependency == rhs.dependency && statistics == rhs.statistics &&\n+\t       bind == rhs.bind && bind_extended == rhs.bind_extended && statistics == rhs.statistics &&\n \t       bind_lambda == rhs.bind_lambda;\n }\n \ndiff --git a/src/include/duckdb/function/function_binder.hpp b/src/include/duckdb/function/function_binder.hpp\nindex 9f1fb315df3d..53e90b2ef346 100644\n--- a/src/include/duckdb/function/function_binder.hpp\n+++ b/src/include/duckdb/function/function_binder.hpp\n@@ -21,8 +21,10 @@ namespace duckdb {\n //! The FunctionBinder class is responsible for binding functions\n class FunctionBinder {\n public:\n+\tDUCKDB_API explicit FunctionBinder(Binder &binder);\n \tDUCKDB_API explicit FunctionBinder(ClientContext &context);\n \n+\toptional_ptr<Binder> binder;\n \tClientContext &context;\n \n public:\ndiff --git a/src/include/duckdb/function/scalar_function.hpp b/src/include/duckdb/function/scalar_function.hpp\nindex 2a8b15330c00..236356b9af8e 100644\n--- a/src/include/duckdb/function/scalar_function.hpp\n+++ b/src/include/duckdb/function/scalar_function.hpp\n@@ -51,7 +51,6 @@ struct ScalarFunctionInfo {\n \n class Binder;\n class BoundFunctionExpression;\n-class LogicalDependencyList;\n class ScalarFunctionCatalogEntry;\n \n struct StatementProperties;\n@@ -88,17 +87,25 @@ struct FunctionBindExpressionInput {\n \tBoundFunctionExpression &function;\n };\n \n+struct ScalarFunctionBindInput {\n+\texplicit ScalarFunctionBindInput(Binder &binder) : binder(binder) {\n+\t}\n+\n+\tBinder &binder;\n+};\n+\n //! The scalar function type\n typedef std::function<void(DataChunk &, ExpressionState &, Vector &)> scalar_function_t;\n //! The type to bind the scalar function and to create the function data\n typedef unique_ptr<FunctionData> (*bind_scalar_function_t)(ClientContext &context, ScalarFunction &bound_function,\n                                                            vector<unique_ptr<Expression>> &arguments);\n+typedef unique_ptr<FunctionData> (*bind_scalar_function_extended_t)(ScalarFunctionBindInput &bind_input,\n+                                                                    ScalarFunction &bound_function,\n+                                                                    vector<unique_ptr<Expression>> &arguments);\n //! The type to initialize a thread local state for the scalar function\n typedef unique_ptr<FunctionLocalState> (*init_local_state_t)(ExpressionState &state,\n                                                              const BoundFunctionExpression &expr,\n                                                              FunctionData *bind_data);\n-//! The type to add the dependencies of this BoundFunctionExpression to the set of dependencies\n-typedef void (*dependency_function_t)(BoundFunctionExpression &expr, LogicalDependencyList &dependencies);\n //! The type to propagate statistics for this scalar function\n typedef unique_ptr<BaseStatistics> (*function_statistics_t)(ClientContext &context, FunctionStatisticsInput &input);\n //! The type to bind lambda-specific parameter types\n@@ -117,15 +124,16 @@ class ScalarFunction : public BaseScalarFunction { // NOLINT: work-around bug in\n public:\n \tDUCKDB_API ScalarFunction(string name, vector<LogicalType> arguments, LogicalType return_type,\n \t                          scalar_function_t function, bind_scalar_function_t bind = nullptr,\n-\t                          dependency_function_t dependency = nullptr, function_statistics_t statistics = nullptr,\n-\t                          init_local_state_t init_local_state = nullptr,\n+\t                          bind_scalar_function_extended_t bind_extended = nullptr,\n+\t                          function_statistics_t statistics = nullptr, init_local_state_t init_local_state = nullptr,\n \t                          LogicalType varargs = LogicalType(LogicalTypeId::INVALID),\n \t                          FunctionStability stability = FunctionStability::CONSISTENT,\n \t                          FunctionNullHandling null_handling = FunctionNullHandling::DEFAULT_NULL_HANDLING,\n \t                          bind_lambda_function_t bind_lambda = nullptr);\n \n \tDUCKDB_API ScalarFunction(vector<LogicalType> arguments, LogicalType return_type, scalar_function_t function,\n-\t                          bind_scalar_function_t bind = nullptr, dependency_function_t dependency = nullptr,\n+\t                          bind_scalar_function_t bind = nullptr,\n+\t                          bind_scalar_function_extended_t bind_extended = nullptr,\n \t                          function_statistics_t statistics = nullptr, init_local_state_t init_local_state = nullptr,\n \t                          LogicalType varargs = LogicalType(LogicalTypeId::INVALID),\n \t                          FunctionStability stability = FunctionStability::CONSISTENT,\n@@ -136,10 +144,10 @@ class ScalarFunction : public BaseScalarFunction { // NOLINT: work-around bug in\n \tscalar_function_t function;\n \t//! The bind function (if any)\n \tbind_scalar_function_t bind;\n+\t//! The bind function that receives extra input to perform more complex binding operations (if any)\n+\tbind_scalar_function_extended_t bind_extended = nullptr;\n \t//! Init thread local state for the function (if any)\n \tinit_local_state_t init_local_state;\n-\t//! The dependency function (if any)\n-\tdependency_function_t dependency;\n \t//! The statistics propagation function (if any)\n \tfunction_statistics_t statistics;\n \t//! The lambda bind function (if any)\ndiff --git a/src/include/duckdb/planner/binder.hpp b/src/include/duckdb/planner/binder.hpp\nindex ba6de071e016..7da3b6c5d87f 100644\n--- a/src/include/duckdb/planner/binder.hpp\n+++ b/src/include/duckdb/planner/binder.hpp\n@@ -210,6 +210,9 @@ class Binder : public enable_shared_from_this<Binder> {\n \toptional_ptr<SQLStatement> GetRootStatement() {\n \t\treturn root_statement;\n \t}\n+\tCatalogEntryRetriever &EntryRetriever() {\n+\t\treturn entry_retriever;\n+\t}\n \n \tvoid SetCanContainNulls(bool can_contain_nulls);\n \tvoid SetAlwaysRequireRebind();\n@@ -256,7 +259,8 @@ class Binder : public enable_shared_from_this<Binder> {\n \t//! Bind the expressions of generated columns to check for errors\n \tvoid BindGeneratedColumns(BoundCreateTableInfo &info);\n \t//! Bind the default values of the columns of a table\n-\tvoid BindDefaultValues(const ColumnList &columns, vector<unique_ptr<Expression>> &bound_defaults);\n+\tvoid BindDefaultValues(const ColumnList &columns, vector<unique_ptr<Expression>> &bound_defaults,\n+\t                       const string &catalog = \"\", const string &schema = \"\");\n \t//! Bind a limit value (LIMIT or OFFSET)\n \tBoundLimitNode BindLimitValue(OrderBinder &order_binder, unique_ptr<ParsedExpression> limit_val, bool is_percentage,\n \t                              bool is_offset);\ndiff --git a/src/planner/binder/expression/bind_aggregate_expression.cpp b/src/planner/binder/expression/bind_aggregate_expression.cpp\nindex c58214a002c2..97d690c3dcca 100644\n--- a/src/planner/binder/expression/bind_aggregate_expression.cpp\n+++ b/src/planner/binder/expression/bind_aggregate_expression.cpp\n@@ -240,7 +240,7 @@ BindResult BaseSelectBinder::BindAggregate(FunctionExpression &aggr, AggregateFu\n \t}\n \n \t// bind the aggregate\n-\tFunctionBinder function_binder(context);\n+\tFunctionBinder function_binder(binder);\n \tauto best_function = function_binder.BindFunction(func.name, func.functions, types, error);\n \tif (!best_function.IsValid()) {\n \t\terror.AddQueryLocation(aggr);\ndiff --git a/src/planner/binder/expression/bind_function_expression.cpp b/src/planner/binder/expression/bind_function_expression.cpp\nindex 0477c0481db8..6af70584b717 100644\n--- a/src/planner/binder/expression/bind_function_expression.cpp\n+++ b/src/planner/binder/expression/bind_function_expression.cpp\n@@ -125,7 +125,7 @@ BindResult ExpressionBinder::BindFunction(FunctionExpression &function, ScalarFu\n \t\tchildren.push_back(std::move(child));\n \t}\n \n-\tFunctionBinder function_binder(context);\n+\tFunctionBinder function_binder(binder);\n \tauto result = function_binder.BindScalarFunction(func, std::move(children), error, function.is_operator, &binder);\n \tif (!result) {\n \t\terror.AddQueryLocation(function);\n@@ -218,7 +218,7 @@ BindResult ExpressionBinder::BindLambdaFunction(FunctionExpression &function, Sc\n \tauto &bound_lambda_expr = children.back()->Cast<BoundLambdaExpression>();\n \tCaptureLambdaColumns(bound_lambda_expr, bound_lambda_expr.lambda_expr, &bind_lambda_function, list_child_type);\n \n-\tFunctionBinder function_binder(context);\n+\tFunctionBinder function_binder(binder);\n \tunique_ptr<Expression> result =\n \t    function_binder.BindScalarFunction(func, std::move(children), error, function.is_operator, &binder);\n \tif (!result) {\ndiff --git a/src/planner/binder/query_node/bind_select_node.cpp b/src/planner/binder/query_node/bind_select_node.cpp\nindex 93e0b60c5a7f..1d61ae056e1a 100644\n--- a/src/planner/binder/query_node/bind_select_node.cpp\n+++ b/src/planner/binder/query_node/bind_select_node.cpp\n@@ -497,7 +497,7 @@ unique_ptr<BoundQueryNode> Binder::BindSelectNode(SelectNode &statement, unique_\n \t\t\t\t// FIXME: would be better to just refer to this expression, but for now we copy\n \t\t\t\tfirst_children.push_back(bound_expr_ref.Copy());\n \n-\t\t\t\tFunctionBinder function_binder(context);\n+\t\t\t\tFunctionBinder function_binder(*this);\n \t\t\t\tauto function = function_binder.BindAggregateFunction(first_fun, std::move(first_children));\n \t\t\t\tfunction->alias = \"__collated_group\";\n \t\t\t\tresult->aggregates.push_back(std::move(function));\ndiff --git a/src/planner/binder/query_node/plan_subquery.cpp b/src/planner/binder/query_node/plan_subquery.cpp\nindex 807fa6c7b494..4b5857f573e7 100644\n--- a/src/planner/binder/query_node/plan_subquery.cpp\n+++ b/src/planner/binder/query_node/plan_subquery.cpp\n@@ -37,7 +37,7 @@ static unique_ptr<Expression> PlanUncorrelatedSubquery(Binder &binder, BoundSubq\n \t\t// now we push a COUNT(*) aggregate onto the limit, this will be either 0 or 1 (EXISTS or NOT EXISTS)\n \t\tauto count_star_fun = CountStarFun::GetFunction();\n \n-\t\tFunctionBinder function_binder(binder.context);\n+\t\tFunctionBinder function_binder(binder);\n \t\tauto count_star =\n \t\t    function_binder.BindAggregateFunction(count_star_fun, {}, nullptr, AggregateType::NON_DISTINCT);\n \t\tauto idx_type = count_star->return_type;\n@@ -87,7 +87,7 @@ static unique_ptr<Expression> PlanUncorrelatedSubquery(Binder &binder, BoundSubq\n \t\tvector<unique_ptr<Expression>> first_children;\n \t\tfirst_children.push_back(std::move(bound));\n \n-\t\tFunctionBinder function_binder(binder.context);\n+\t\tFunctionBinder function_binder(binder);\n \t\tauto first_agg =\n \t\t    function_binder.BindAggregateFunction(FirstFunctionGetter::GetFunction(expr.return_type),\n \t\t                                          std::move(first_children), nullptr, AggregateType::NON_DISTINCT);\ndiff --git a/src/planner/binder/statement/bind_create_table.cpp b/src/planner/binder/statement/bind_create_table.cpp\nindex 670bdf58661e..6a6bd564da23 100644\n--- a/src/planner/binder/statement/bind_create_table.cpp\n+++ b/src/planner/binder/statement/bind_create_table.cpp\n@@ -262,7 +262,21 @@ void Binder::BindGeneratedColumns(BoundCreateTableInfo &info) {\n \t}\n }\n \n-void Binder::BindDefaultValues(const ColumnList &columns, vector<unique_ptr<Expression>> &bound_defaults) {\n+void Binder::BindDefaultValues(const ColumnList &columns, vector<unique_ptr<Expression>> &bound_defaults,\n+                               const string &catalog_name, const string &schema_p) {\n+\tstring schema_name = schema_p;\n+\tif (schema_p.empty()) {\n+\t\tschema_name = DEFAULT_SCHEMA;\n+\t}\n+\n+\t// FIXME: We might want to save the existing search path of the binder\n+\tvector<CatalogSearchEntry> defaults_search_path;\n+\tdefaults_search_path.emplace_back(catalog_name, schema_name);\n+\tif (schema_name != DEFAULT_SCHEMA) {\n+\t\tdefaults_search_path.emplace_back(catalog_name, DEFAULT_SCHEMA);\n+\t}\n+\tentry_retriever.SetSearchPath(std::move(defaults_search_path));\n+\n \tfor (auto &column : columns.Physical()) {\n \t\tunique_ptr<Expression> bound_default;\n \t\tif (column.HasDefaultValue()) {\n@@ -283,32 +297,6 @@ void Binder::BindDefaultValues(const ColumnList &columns, vector<unique_ptr<Expr\n \t}\n }\n \n-static void ExtractExpressionDependencies(Expression &expr, LogicalDependencyList &dependencies) {\n-\tif (expr.type == ExpressionType::BOUND_FUNCTION) {\n-\t\tauto &function = expr.Cast<BoundFunctionExpression>();\n-\t\tif (function.function.dependency) {\n-\t\t\tfunction.function.dependency(function, dependencies);\n-\t\t}\n-\t}\n-\tExpressionIterator::EnumerateChildren(\n-\t    expr, [&](Expression &child) { ExtractExpressionDependencies(child, dependencies); });\n-}\n-\n-static void ExtractDependencies(BoundCreateTableInfo &info, vector<unique_ptr<Expression>> &defaults,\n-                                vector<unique_ptr<BoundConstraint>> &constraints) {\n-\tfor (auto &default_value : defaults) {\n-\t\tif (default_value) {\n-\t\t\tExtractExpressionDependencies(*default_value, info.dependencies);\n-\t\t}\n-\t}\n-\tfor (auto &constraint : constraints) {\n-\t\tif (constraint->type == ConstraintType::CHECK) {\n-\t\t\tauto &bound_check = constraint->Cast<BoundCheckConstraint>();\n-\t\t\tExtractExpressionDependencies(*bound_check.expression, info.dependencies);\n-\t\t}\n-\t}\n-}\n-\n unique_ptr<BoundCreateTableInfo> Binder::BindCreateTableInfo(unique_ptr<CreateInfo> info, SchemaCatalogEntry &schema) {\n \tvector<unique_ptr<Expression>> bound_defaults;\n \treturn BindCreateTableInfo(std::move(info), schema, bound_defaults);\n@@ -376,10 +364,10 @@ unique_ptr<BoundCreateTableInfo> Binder::BindCreateTableInfo(unique_ptr<CreateIn\n \t\t// bind any constraints\n \t\tbound_constraints = BindNewConstraints(base.constraints, base.table, base.columns);\n \t\t// bind the default values\n-\t\tBindDefaultValues(base.columns, bound_defaults);\n+\t\tauto &catalog_name = schema.ParentCatalog().GetName();\n+\t\tauto &schema_name = schema.name;\n+\t\tBindDefaultValues(base.columns, bound_defaults, catalog_name, schema_name);\n \t}\n-\t// extract dependencies from any default values or CHECK constraints\n-\tExtractDependencies(*result, bound_defaults, bound_constraints);\n \n \tif (base.columns.PhysicalColumnCount() == 0) {\n \t\tthrow BinderException(\"Creating a table without physical (non-generated) columns is not supported\");\ndiff --git a/src/planner/binder/statement/bind_insert.cpp b/src/planner/binder/statement/bind_insert.cpp\nindex f02be80009d1..adc3a1d7c1af 100644\n--- a/src/planner/binder/statement/bind_insert.cpp\n+++ b/src/planner/binder/statement/bind_insert.cpp\n@@ -540,7 +540,9 @@ BoundStatement Binder::Bind(InsertStatement &stmt) {\n \t}\n \n \t// bind the default values\n-\tBindDefaultValues(table.GetColumns(), insert->bound_defaults);\n+\tauto &catalog_name = table.ParentCatalog().GetName();\n+\tauto &schema_name = table.ParentSchema().name;\n+\tBindDefaultValues(table.GetColumns(), insert->bound_defaults, catalog_name, schema_name);\n \tinsert->bound_constraints = BindConstraints(table);\n \tif (!stmt.select_statement && !stmt.default_values) {\n \t\tresult.plan = std::move(insert);\ndiff --git a/src/planner/binder/statement/bind_pragma.cpp b/src/planner/binder/statement/bind_pragma.cpp\nindex 8f89dec5b667..3955cf89753e 100644\n--- a/src/planner/binder/statement/bind_pragma.cpp\n+++ b/src/planner/binder/statement/bind_pragma.cpp\n@@ -29,7 +29,7 @@ unique_ptr<BoundPragmaInfo> Binder::BindPragma(PragmaInfo &info, QueryErrorConte\n \n \t// bind the pragma function\n \tauto &entry = Catalog::GetEntry<PragmaFunctionCatalogEntry>(context, INVALID_CATALOG, DEFAULT_SCHEMA, info.name);\n-\tFunctionBinder function_binder(context);\n+\tFunctionBinder function_binder(*this);\n \tErrorData error;\n \tauto bound_idx = function_binder.BindFunction(entry.name, entry.functions, params, error);\n \tif (!bound_idx.IsValid()) {\ndiff --git a/src/planner/binder/statement/bind_update.cpp b/src/planner/binder/statement/bind_update.cpp\nindex 4e27e161042a..83afa5a8681e 100644\n--- a/src/planner/binder/statement/bind_update.cpp\n+++ b/src/planner/binder/statement/bind_update.cpp\n@@ -106,7 +106,9 @@ BoundStatement Binder::Bind(UpdateStatement &stmt) {\n \t\tupdate->return_chunk = true;\n \t}\n \t// bind the default values\n-\tBindDefaultValues(table.GetColumns(), update->bound_defaults);\n+\tauto &catalog_name = table.ParentCatalog().GetName();\n+\tauto &schema_name = table.ParentSchema().name;\n+\tBindDefaultValues(table.GetColumns(), update->bound_defaults, catalog_name, schema_name);\n \tupdate->bound_constraints = BindConstraints(table);\n \n \t// project any additional columns required for the condition/expressions\ndiff --git a/src/planner/binder/tableref/bind_table_function.cpp b/src/planner/binder/tableref/bind_table_function.cpp\nindex 79972fefb869..f4efdd7dec2d 100644\n--- a/src/planner/binder/tableref/bind_table_function.cpp\n+++ b/src/planner/binder/tableref/bind_table_function.cpp\n@@ -306,7 +306,7 @@ unique_ptr<BoundTableRef> Binder::Bind(TableFunctionRef &ref) {\n \t}\n \n \t// select the function based on the input parameters\n-\tFunctionBinder function_binder(context);\n+\tFunctionBinder function_binder(*this);\n \tauto best_function_idx = function_binder.BindFunction(function.name, function.functions, arguments, error);\n \tif (!best_function_idx.IsValid()) {\n \t\terror.AddQueryLocation(ref);\n",
  "test_patch": "diff --git a/test/fuzzer/pedro/temp_sequence_reconnect.test b/test/fuzzer/pedro/temp_sequence_reconnect.test\nindex 6b781bf0ef15..7feda944cbf7 100644\n--- a/test/fuzzer/pedro/temp_sequence_reconnect.test\n+++ b/test/fuzzer/pedro/temp_sequence_reconnect.test\n@@ -13,22 +13,20 @@ statement ok\n CREATE SEQUENCE t1;\n \n statement ok\n-CREATE TABLE t1 (c1 INT, CHECK(nextval('t1')));\n+CREATE TABLE t1 (\n+\tc1 INT,\n+\tCHECK(nextval('t1'))\n+);\n \n statement ok\n CREATE TEMP SEQUENCE t1;\n \n-statement error\n+statement ok\n ALTER TABLE t1 ADD c0 INT;\n-----\n-Cross catalog dependencies are not supported\n \n statement ok\n DROP SEQUENCE temp.t1\n \n-statement ok\n-ALTER TABLE t1 ADD c0 INT;\n-\n reconnect\n \n statement ok\ndiff --git a/test/sql/attach/attach_sequence.test b/test/sql/attach/attach_sequence.test\nindex 90e2ef852d73..78d66fc71550 100644\n--- a/test/sql/attach/attach_sequence.test\n+++ b/test/sql/attach/attach_sequence.test\n@@ -13,7 +13,7 @@ CREATE SEQUENCE seq;\n statement error\n CREATE TABLE db1.integers(i INTEGER DEFAULT nextval('seq'))\n ----\n-Cross catalog dependencies are not supported\n+TransactionContext Error: Attempting to write to database \"db1\" in a transaction that has already modified database\n \n statement ok\n CREATE SEQUENCE db1.seq\n@@ -34,7 +34,7 @@ SELECT nextval('seq')\n statement error\n CREATE TABLE integers(i INTEGER DEFAULT nextval('db1.seq'))\n ----\n-Cross catalog dependencies are not supported\n+<REGEX>:TransactionContext Error:.*in a transaction that has already modified database \"db1\".*\n \n statement ok\n detach db1;\ndiff --git a/test/sql/copy_database/copy_table_with_sequence.test b/test/sql/copy_database/copy_table_with_sequence.test\nnew file mode 100644\nindex 000000000000..65b87ed4a677\n--- /dev/null\n+++ b/test/sql/copy_database/copy_table_with_sequence.test\n@@ -0,0 +1,108 @@\n+# name: test/sql/copy_database/copy_table_with_sequence.test\n+# group: [copy_database]\n+\n+require noforcestorage\n+\n+statement ok\n+pragma enable_verification;\n+\n+statement ok\n+attach '__TEST_DIR__/backup.db';\n+\n+## Only specifying a sequence name\n+\n+statement ok\n+create sequence seq start 1;\n+\n+statement ok\n+create table tbl (\n+\tid int default nextval('seq')\n+);\n+\n+statement ok\n+insert into tbl values (DEFAULT);\n+insert into tbl values (DEFAULT);\n+\n+statement ok\n+copy from database memory to backup;\n+\n+statement ok\n+drop sequence seq cascade;\n+\n+query I\n+select * from backup.tbl;\n+----\n+1\n+2\n+\n+query I\n+select currval('backup.main.seq');\n+----\n+3\n+\n+statement ok\n+drop sequence backup.main.seq cascade;\n+\n+## Explicitly specifying the schema\n+\n+statement ok\n+create schema my_schema;\n+\n+statement ok\n+create sequence my_schema.seq start 1;\n+\n+statement ok\n+create table tbl (\n+\tid int default nextval('my_schema.seq')\n+);\n+\n+statement ok\n+copy from database memory to backup;\n+\n+statement ok\n+drop sequence my_schema.seq cascade;\n+\n+statement ok\n+drop sequence backup.my_schema.seq cascade;\n+\n+## Explicitly specifying the schema, with the same name as the catalog\n+\n+statement ok\n+create schema backup;\n+\n+statement ok\n+create sequence memory.backup.seq start 1;\n+\n+statement error\n+create table tbl (\n+\tid int default nextval('backup.seq')\n+);\n+----\n+Ambiguous reference to catalog or schema \"backup\"\n+\n+statement ok\n+drop schema backup cascade;\n+\n+## Explicitly specifying the catalog + schema (results in an error)\n+\n+statement ok\n+create schema backup;\n+\n+statement ok\n+create sequence memory.backup.seq start 1;\n+\n+statement ok\n+create table tbl (\n+\tid int default nextval('memory.backup.seq')\n+);\n+\n+statement error\n+copy from database memory to backup;\n+----\n+<REGEX>:TransactionContext Error: Attempting to write to database .* in a transaction that has already modified database .*\n+\n+statement ok\n+drop sequence memory.backup.seq cascade;\n+\n+statement ok\n+drop sequence backup.backup.seq cascade;\n",
  "problem_statement": "Sequences in COPY FROM <database>TO <otherDB> causes Dependency Error\n### What happens?\r\n\r\n> ./duckdb original.db\r\nv1.1.2 f680b7d08f\r\nEnter \".help\" for usage hints.\r\nD create sequence seq start 1;\r\nD create table tbl (id int default nextval('seq'));\r\nD attach 'backup.db';\r\nD copy from database original to backup;\r\nDependency Error: Error adding dependency for object \"tbl\" - dependency \"seq\" is in catalog \"original\", which does not match the catalog \"backup\".\r\nCross catalog dependencies are not supported.\r\n\r\n### To Reproduce\r\n\r\n```bash\r\n./duckdb original.db\r\n```\r\n```sql\r\ncreate sequence seq start 1;\r\ncreate table tbl (id int default nextval('seq'));\r\nattach 'backup.db';\r\ncopy from database original to backup;\r\n```\r\n```console\r\nDependency Error: Error adding dependency for object \"tbl\" - dependency \"seq\" is in catalog \"original\", which does not match the catalog \"backup\".\r\nCross catalog dependencies are not supported.\r\n```\r\n### OS:\r\n\r\nWindows 10\r\n\r\n### DuckDB Version:\r\n\r\n1.1.2\r\n\r\n### DuckDB Client:\r\n\r\nCLI\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\njohndapps\r\n\r\n### Affiliation:\r\n\r\n4LP\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nNot applicable - the reproduction does not require a data set\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\n",
  "hints_text": "Reproduced, thanks!",
  "created_at": "2024-11-04T16:46:50Z"
}