You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes.
In the patch file, please make sure to include the line numbers and a blank line at the end so it can be applied using git apply.

<issue>
NULL pointer dereference scanning from arrow with lists of structs
### What happens?

There's a segfault when trying to select a column from an arrow batch that has two lists and one of them is a list of structs. Maybe there's a simpler explanation, but this is what I've been able to trivially reproduce. I first filed this under https://github.com/marcboeker/go-duckdb/issues/321, but it's not very go specific, and the Python support seems more first-class so this repro seemed more likely to get some attention.

### To Reproduce

Create an arrow batch with lists of structs and then try to scan one of them. Below is an example in Python, but it also happens using the C-API from go. 

```python
# /// script
# requires-python = ">=3.12"
# dependencies = [
#     "duckdb",
#     "pyarrow",
# ]
# ///

import pyarrow as pa

schema = pa.schema([
    pa.field("m", pa.struct([
        pa.field("array", pa.list_(
            pa.struct([pa.field("a", pa.int64())])
        ))
    ])),
    pa.field("a", pa.struct([
        pa.field("array", pa.list_(pa.int64()))
    ]))
])
m_a_values = pa.array([1], type=pa.int64())  # Values for "a"
m_array = pa.ListArray.from_arrays(
    offsets=pa.array([0, 1], type=pa.int32()),  # One list with one element
    values=pa.StructArray.from_arrays([m_a_values], names=["a"])
)
m = pa.StructArray.from_arrays([m_array], names=["array"])
a_array_values = pa.array([1], type=pa.int64())  # Values for the list
a_array = pa.ListArray.from_arrays(
    offsets=pa.array([0, 1], type=pa.int32()),  # One list with one element
    values=a_array_values
)
a = pa.StructArray.from_arrays([a_array], names=["array"])
record_batch = pa.RecordBatch.from_arrays([m, a], schema.names)

import duckdb
con = duckdb.connect()
results = con.execute("SELECT a FROM record_batch").arrow()
```

```
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
duckdb.duckdb.InternalException: INTERNAL Error: Attempted to dereference unique_ptr that is NULL!
This error signals an assertion failure within DuckDB. This usually occurs due to unexpected conditions or errors in the program's logic.
For more information, see https://duckdb.org/docs/dev/internal_errors
```

### OS:

linux x86_64

### DuckDB Version:

1.1.3

### DuckDB Client:

Python

### Hardware:

_No response_

### Full Name:

Andrew Werner

### Affiliation:

Data Ex Machina, Inc

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a stable release

### Did you include all relevant data sets for reproducing the issue?

Yes

### Did you include all code required to reproduce the issue?

- [X] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [X] Yes, I have

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <picture>
3:     <source media="(prefers-color-scheme: light)" srcset="logo/DuckDB_Logo-horizontal.svg">
4:     <source media="(prefers-color-scheme: dark)" srcset="logo/DuckDB_Logo-horizontal-dark-mode.svg">
5:     <img alt="DuckDB logo" src="logo/DuckDB_Logo-horizontal.svg" height="100">
6:   </picture>
7: </div>
8: <br>
9: 
10: <p align="center">
11:   <a href="https://github.com/duckdb/duckdb/actions"><img src="https://github.com/duckdb/duckdb/actions/workflows/Main.yml/badge.svg?branch=main" alt="Github Actions Badge"></a>
12:   <a href="https://discord.gg/tcvwpjfnZx"><img src="https://shields.io/discord/909674491309850675" alt="discord" /></a>
13:   <a href="https://github.com/duckdb/duckdb/releases/"><img src="https://img.shields.io/github/v/release/duckdb/duckdb?color=brightgreen&display_name=tag&logo=duckdb&logoColor=white" alt="Latest Release"></a>
14: </p>
15: 
16: ## DuckDB
17: 
18: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable, portable, and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs, maps), and [several extensions designed to make SQL easier to use](https://duckdb.org/docs/guides/sql_features/friendly_sql).
19: 
20: DuckDB is available as a [standalone CLI application](https://duckdb.org/docs/api/cli/overview) and has clients for [Python](https://duckdb.org/docs/api/python/overview), [R](https://duckdb.org/docs/api/r), [Java](https://duckdb.org/docs/api/java), [Wasm](https://duckdb.org/docs/api/wasm/overview), etc., with deep integrations with packages such as [pandas](https://duckdb.org/docs/guides/python/sql_on_pandas) and [dplyr](https://duckdblabs.github.io/duckplyr/).
21: 
22: For more information on using DuckDB, please refer to the [DuckDB documentation](https://duckdb.org/docs/).
23: 
24: ## Installation
25: 
26: If you want to install DuckDB, please see [our installation page](https://duckdb.org/docs/installation/) for instructions.
27: 
28: ## Data Import
29: 
30: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
31: 
32: ```sql
33: SELECT * FROM 'myfile.csv';
34: SELECT * FROM 'myfile.parquet';
35: ```
36: 
37: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
38: 
39: ## SQL Reference
40: 
41: The documentation contains a [SQL introduction and reference](https://duckdb.org/docs/sql/introduction).
42: 
43: ## Development
44: 
45: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run `BUILD_BENCHMARK=1 BUILD_TPCH=1 make` and then perform several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`. The details of benchmarks are in our [Benchmark Guide](benchmark/README.md).
46: 
47: Please also refer to our [Build Guide](https://duckdb.org/dev/building) and [Contribution Guide](CONTRIBUTING.md).
48: 
49: ## Support
50: 
51: See the [Support Options](https://duckdblabs.com/support/) page.
[end of README.md]
[start of src/function/table/arrow.cpp]
1: #include "duckdb/common/arrow/arrow.hpp"
2: 
3: #include "duckdb.hpp"
4: #include "duckdb/common/arrow/arrow_wrapper.hpp"
5: #include "duckdb/common/limits.hpp"
6: #include "duckdb/common/to_string.hpp"
7: #include "duckdb/common/types/date.hpp"
8: #include "duckdb/common/types/vector_buffer.hpp"
9: #include "duckdb/function/table/arrow.hpp"
10: #include "duckdb/function/table/arrow/arrow_duck_schema.hpp"
11: #include "duckdb/function/table/arrow/arrow_type_info.hpp"
12: #include "duckdb/function/table_function.hpp"
13: #include "duckdb/parser/parsed_data/create_table_function_info.hpp"
14: #include "duckdb/parser/tableref/table_function_ref.hpp"
15: #include "utf8proc_wrapper.hpp"
16: #include "duckdb/common/arrow/schema_metadata.hpp"
17: 
18: namespace duckdb {
19: 
20: static unique_ptr<ArrowType> CreateListType(ArrowSchema &child, ArrowVariableSizeType size_type, bool view) {
21: 	auto child_type = ArrowTableFunction::GetArrowLogicalType(child);
22: 
23: 	unique_ptr<ArrowTypeInfo> type_info;
24: 	auto type = LogicalType::LIST(child_type->GetDuckType());
25: 	if (view) {
26: 		type_info = ArrowListInfo::ListView(std::move(child_type), size_type);
27: 	} else {
28: 		type_info = ArrowListInfo::List(std::move(child_type), size_type);
29: 	}
30: 	return make_uniq<ArrowType>(type, std::move(type_info));
31: }
32: 
33: static unique_ptr<ArrowType> GetArrowExtensionType(const ArrowSchemaMetadata &extension_type, const string &format) {
34: 	auto arrow_extension = extension_type.GetExtensionName();
35: 	// Check for arrow canonical extensions
36: 	if (arrow_extension == "arrow.uuid") {
37: 		if (format != "w:16") {
38: 			std::ostringstream error;
39: 			error
40: 			    << "arrow.uuid must be a fixed-size binary of 16 bytes (i.e., \'w:16\'). It is incorrectly defined as:"
41: 			    << format;
42: 			return make_uniq<ArrowType>(error.str());
43: 		}
44: 		return make_uniq<ArrowType>(LogicalType::UUID);
45: 	} else if (arrow_extension == "arrow.json") {
46: 		if (format == "u") {
47: 			return make_uniq<ArrowType>(LogicalType::JSON(), make_uniq<ArrowStringInfo>(ArrowVariableSizeType::NORMAL));
48: 		} else if (format == "U") {
49: 			return make_uniq<ArrowType>(LogicalType::JSON(),
50: 			                            make_uniq<ArrowStringInfo>(ArrowVariableSizeType::SUPER_SIZE));
51: 		} else if (format == "vu") {
52: 			return make_uniq<ArrowType>(LogicalType::JSON(), make_uniq<ArrowStringInfo>(ArrowVariableSizeType::VIEW));
53: 		} else {
54: 			std::ostringstream error;
55: 			error
56: 			    << "arrow.json must be of a varchar format (i.e., \'u\',\'U\' or \'vu\'). It is incorrectly defined as:"
57: 			    << format;
58: 			return make_uniq<ArrowType>(error.str());
59: 		}
60: 	}
61: 	// Check for DuckDB canonical extensions
62: 	else if (arrow_extension == "duckdb.hugeint") {
63: 		if (format != "w:16") {
64: 			std::ostringstream error;
65: 			error << "duckdb.hugeint must be a fixed-size binary of 16 bytes (i.e., \'w:16\'). It is incorrectly "
66: 			         "defined as:"
67: 			      << format;
68: 			return make_uniq<ArrowType>(error.str());
69: 		}
70: 		return make_uniq<ArrowType>(LogicalType::HUGEINT);
71: 	} else if (arrow_extension == "duckdb.uhugeint") {
72: 		if (format != "w:16") {
73: 			std::ostringstream error;
74: 			error << "duckdb.uhugeint must be a fixed-size binary of 16 bytes (i.e., \'w:16\'). It is incorrectly "
75: 			         "defined as:"
76: 			      << format;
77: 			return make_uniq<ArrowType>(error.str());
78: 		}
79: 		return make_uniq<ArrowType>(LogicalType::UHUGEINT);
80: 	} else if (arrow_extension == "duckdb.time_tz") {
81: 		if (format != "w:8") {
82: 			std::ostringstream error;
83: 			error << "duckdb.time_tz must be a fixed-size binary of 8 bytes (i.e., \'w:8\'). It is incorrectly defined "
84: 			         "as:"
85: 			      << format;
86: 			return make_uniq<ArrowType>(error.str());
87: 		}
88: 		return make_uniq<ArrowType>(LogicalType::TIME_TZ,
89: 		                            make_uniq<ArrowDateTimeInfo>(ArrowDateTimeType::MICROSECONDS));
90: 	} else if (arrow_extension == "duckdb.bit") {
91: 		if (format != "z" && format != "Z") {
92: 			std::ostringstream error;
93: 			error << "duckdb.bit must be a blob (i.e., \'z\' or \'Z\'). It is incorrectly defined as:" << format;
94: 			return make_uniq<ArrowType>(error.str());
95: 		} else if (format == "z") {
96: 			auto type_info = make_uniq<ArrowStringInfo>(ArrowVariableSizeType::NORMAL);
97: 			return make_uniq<ArrowType>(LogicalType::BIT, std::move(type_info));
98: 		}
99: 		auto type_info = make_uniq<ArrowStringInfo>(ArrowVariableSizeType::SUPER_SIZE);
100: 		return make_uniq<ArrowType>(LogicalType::BIT, std::move(type_info));
101: 
102: 	} else if (arrow_extension == "duckdb.varint") {
103: 		if (format != "z" && format != "Z") {
104: 			std::ostringstream error;
105: 			error << "duckdb.bit must be a blob (i.e., \'z\'). It is incorrectly defined as:" << format;
106: 			return make_uniq<ArrowType>(error.str());
107: 		}
108: 		unique_ptr<ArrowStringInfo> type_info;
109: 		if (format == "z") {
110: 			type_info = make_uniq<ArrowStringInfo>(ArrowVariableSizeType::NORMAL);
111: 		} else {
112: 			type_info = make_uniq<ArrowStringInfo>(ArrowVariableSizeType::SUPER_SIZE);
113: 		}
114: 		return make_uniq<ArrowType>(LogicalType::VARINT, std::move(type_info));
115: 	} else {
116: 		std::ostringstream error;
117: 		error << "Arrow Type with extension name: " << arrow_extension << " and format: " << format
118: 		      << ", is not currently supported in DuckDB.";
119: 		return make_uniq<ArrowType>(error.str(), true);
120: 	}
121: }
122: static unique_ptr<ArrowType> GetArrowLogicalTypeNoDictionary(ArrowSchema &schema) {
123: 	auto format = string(schema.format);
124: 	// Let's first figure out if this type is an extension type
125: 	ArrowSchemaMetadata schema_metadata(schema.metadata);
126: 	if (schema_metadata.HasExtension()) {
127: 		return GetArrowExtensionType(schema_metadata, format);
128: 	}
129: 	// If not, we just check the format itself
130: 	if (format == "n") {
131: 		return make_uniq<ArrowType>(LogicalType::SQLNULL);
132: 	} else if (format == "b") {
133: 		return make_uniq<ArrowType>(LogicalType::BOOLEAN);
134: 	} else if (format == "c") {
135: 		return make_uniq<ArrowType>(LogicalType::TINYINT);
136: 	} else if (format == "s") {
137: 		return make_uniq<ArrowType>(LogicalType::SMALLINT);
138: 	} else if (format == "i") {
139: 		return make_uniq<ArrowType>(LogicalType::INTEGER);
140: 	} else if (format == "l") {
141: 		return make_uniq<ArrowType>(LogicalType::BIGINT);
142: 	} else if (format == "C") {
143: 		return make_uniq<ArrowType>(LogicalType::UTINYINT);
144: 	} else if (format == "S") {
145: 		return make_uniq<ArrowType>(LogicalType::USMALLINT);
146: 	} else if (format == "I") {
147: 		return make_uniq<ArrowType>(LogicalType::UINTEGER);
148: 	} else if (format == "L") {
149: 		return make_uniq<ArrowType>(LogicalType::UBIGINT);
150: 	} else if (format == "f") {
151: 		return make_uniq<ArrowType>(LogicalType::FLOAT);
152: 	} else if (format == "g") {
153: 		return make_uniq<ArrowType>(LogicalType::DOUBLE);
154: 	} else if (format[0] == 'd') { //! this can be either decimal128 or decimal 256 (e.g., d:38,0)
155: 		auto extra_info = StringUtil::Split(format, ':');
156: 		if (extra_info.size() != 2) {
157: 			throw InvalidInputException(
158: 			    "Decimal format of Arrow object is incomplete, it is missing the scale and width. Current format: %s",
159: 			    format);
160: 		}
161: 		auto parameters = StringUtil::Split(extra_info[1], ",");
162: 		// Parameters must always be 2 or 3 values (i.e., width, scale and an optional bit-width)
163: 		if (parameters.size() != 2 && parameters.size() != 3) {
164: 			throw InvalidInputException(
165: 			    "Decimal format of Arrow object is incomplete, it is missing the scale or width. Current format: %s",
166: 			    format);
167: 		}
168: 		uint64_t width = std::stoull(parameters[0]);
169: 		uint64_t scale = std::stoull(parameters[1]);
170: 		uint64_t bitwidth = 128;
171: 		if (parameters.size() == 3) {
172: 			// We have a bit-width defined
173: 			bitwidth = std::stoull(parameters[2]);
174: 		}
175: 		if (width > 38 || bitwidth > 128) {
176: 			throw NotImplementedException("Unsupported Internal Arrow Type for Decimal %s", format);
177: 		}
178: 		return make_uniq<ArrowType>(LogicalType::DECIMAL(NumericCast<uint8_t>(width), NumericCast<uint8_t>(scale)));
179: 	} else if (format == "u") {
180: 		return make_uniq<ArrowType>(LogicalType::VARCHAR, make_uniq<ArrowStringInfo>(ArrowVariableSizeType::NORMAL));
181: 	} else if (format == "U") {
182: 		return make_uniq<ArrowType>(LogicalType::VARCHAR,
183: 		                            make_uniq<ArrowStringInfo>(ArrowVariableSizeType::SUPER_SIZE));
184: 	} else if (format == "vu") {
185: 		return make_uniq<ArrowType>(LogicalType::VARCHAR, make_uniq<ArrowStringInfo>(ArrowVariableSizeType::VIEW));
186: 	} else if (format == "tsn:") {
187: 		return make_uniq<ArrowType>(LogicalTypeId::TIMESTAMP_NS);
188: 	} else if (format == "tsu:") {
189: 		return make_uniq<ArrowType>(LogicalTypeId::TIMESTAMP);
190: 	} else if (format == "tsm:") {
191: 		return make_uniq<ArrowType>(LogicalTypeId::TIMESTAMP_MS);
192: 	} else if (format == "tss:") {
193: 		return make_uniq<ArrowType>(LogicalTypeId::TIMESTAMP_SEC);
194: 	} else if (format == "tdD") {
195: 		return make_uniq<ArrowType>(LogicalType::DATE, make_uniq<ArrowDateTimeInfo>(ArrowDateTimeType::DAYS));
196: 	} else if (format == "tdm") {
197: 		return make_uniq<ArrowType>(LogicalType::DATE, make_uniq<ArrowDateTimeInfo>(ArrowDateTimeType::MILLISECONDS));
198: 	} else if (format == "tts") {
199: 		return make_uniq<ArrowType>(LogicalType::TIME, make_uniq<ArrowDateTimeInfo>(ArrowDateTimeType::SECONDS));
200: 	} else if (format == "ttm") {
201: 		return make_uniq<ArrowType>(LogicalType::TIME, make_uniq<ArrowDateTimeInfo>(ArrowDateTimeType::MILLISECONDS));
202: 	} else if (format == "ttu") {
203: 		return make_uniq<ArrowType>(LogicalType::TIME, make_uniq<ArrowDateTimeInfo>(ArrowDateTimeType::MICROSECONDS));
204: 	} else if (format == "ttn") {
205: 		return make_uniq<ArrowType>(LogicalType::TIME, make_uniq<ArrowDateTimeInfo>(ArrowDateTimeType::NANOSECONDS));
206: 	} else if (format == "tDs") {
207: 		return make_uniq<ArrowType>(LogicalType::INTERVAL, make_uniq<ArrowDateTimeInfo>(ArrowDateTimeType::SECONDS));
208: 	} else if (format == "tDm") {
209: 		return make_uniq<ArrowType>(LogicalType::INTERVAL,
210: 		                            make_uniq<ArrowDateTimeInfo>(ArrowDateTimeType::MILLISECONDS));
211: 	} else if (format == "tDu") {
212: 		return make_uniq<ArrowType>(LogicalType::INTERVAL,
213: 		                            make_uniq<ArrowDateTimeInfo>(ArrowDateTimeType::MICROSECONDS));
214: 	} else if (format == "tDn") {
215: 		return make_uniq<ArrowType>(LogicalType::INTERVAL,
216: 		                            make_uniq<ArrowDateTimeInfo>(ArrowDateTimeType::NANOSECONDS));
217: 	} else if (format == "tiD") {
218: 		return make_uniq<ArrowType>(LogicalType::INTERVAL, make_uniq<ArrowDateTimeInfo>(ArrowDateTimeType::DAYS));
219: 	} else if (format == "tiM") {
220: 		return make_uniq<ArrowType>(LogicalType::INTERVAL, make_uniq<ArrowDateTimeInfo>(ArrowDateTimeType::MONTHS));
221: 	} else if (format == "tin") {
222: 		return make_uniq<ArrowType>(LogicalType::INTERVAL,
223: 		                            make_uniq<ArrowDateTimeInfo>(ArrowDateTimeType::MONTH_DAY_NANO));
224: 	} else if (format == "+l") {
225: 		return CreateListType(*schema.children[0], ArrowVariableSizeType::NORMAL, false);
226: 	} else if (format == "+L") {
227: 		return CreateListType(*schema.children[0], ArrowVariableSizeType::SUPER_SIZE, false);
228: 	} else if (format == "+vl") {
229: 		return CreateListType(*schema.children[0], ArrowVariableSizeType::NORMAL, true);
230: 	} else if (format == "+vL") {
231: 		return CreateListType(*schema.children[0], ArrowVariableSizeType::SUPER_SIZE, true);
232: 	} else if (format[0] == '+' && format[1] == 'w') {
233: 		std::string parameters = format.substr(format.find(':') + 1);
234: 		auto fixed_size = NumericCast<idx_t>(std::stoi(parameters));
235: 		auto child_type = ArrowTableFunction::GetArrowLogicalType(*schema.children[0]);
236: 
237: 		auto array_type = LogicalType::ARRAY(child_type->GetDuckType(), fixed_size);
238: 		auto type_info = make_uniq<ArrowArrayInfo>(std::move(child_type), fixed_size);
239: 		return make_uniq<ArrowType>(array_type, std::move(type_info));
240: 	} else if (format == "+s") {
241: 		child_list_t<LogicalType> child_types;
242: 		vector<unique_ptr<ArrowType>> children;
243: 		if (schema.n_children == 0) {
244: 			throw InvalidInputException(
245: 			    "Attempted to convert a STRUCT with no fields to DuckDB which is not supported");
246: 		}
247: 		for (idx_t type_idx = 0; type_idx < (idx_t)schema.n_children; type_idx++) {
248: 			children.emplace_back(ArrowTableFunction::GetArrowLogicalType(*schema.children[type_idx]));
249: 			child_types.emplace_back(schema.children[type_idx]->name, children.back()->GetDuckType());
250: 		}
251: 		auto type_info = make_uniq<ArrowStructInfo>(std::move(children));
252: 		auto struct_type = make_uniq<ArrowType>(LogicalType::STRUCT(std::move(child_types)), std::move(type_info));
253: 		return struct_type;
254: 	} else if (format[0] == '+' && format[1] == 'u') {
255: 		if (format[2] != 's') {
256: 			throw NotImplementedException("Unsupported Internal Arrow Type: \"%c\" Union", format[2]);
257: 		}
258: 		D_ASSERT(format[3] == ':');
259: 
260: 		std::string prefix = "+us:";
261: 		// TODO: what are these type ids actually for?
262: 		auto type_ids = StringUtil::Split(format.substr(prefix.size()), ',');
263: 
264: 		child_list_t<LogicalType> members;
265: 		vector<unique_ptr<ArrowType>> children;
266: 		if (schema.n_children == 0) {
267: 			throw InvalidInputException("Attempted to convert a UNION with no fields to DuckDB which is not supported");
268: 		}
269: 		for (idx_t type_idx = 0; type_idx < (idx_t)schema.n_children; type_idx++) {
270: 			auto type = schema.children[type_idx];
271: 
272: 			children.emplace_back(ArrowTableFunction::GetArrowLogicalType(*type));
273: 			members.emplace_back(type->name, children.back()->GetDuckType());
274: 		}
275: 
276: 		auto type_info = make_uniq<ArrowStructInfo>(std::move(children));
277: 		auto union_type = make_uniq<ArrowType>(LogicalType::UNION(members), std::move(type_info));
278: 		return union_type;
279: 	} else if (format == "+r") {
280: 		child_list_t<LogicalType> members;
281: 		vector<unique_ptr<ArrowType>> children;
282: 		idx_t n_children = idx_t(schema.n_children);
283: 		D_ASSERT(n_children == 2);
284: 		D_ASSERT(string(schema.children[0]->name) == "run_ends");
285: 		D_ASSERT(string(schema.children[1]->name) == "values");
286: 		for (idx_t i = 0; i < n_children; i++) {
287: 			auto type = schema.children[i];
288: 			children.emplace_back(ArrowTableFunction::GetArrowLogicalType(*type));
289: 			members.emplace_back(type->name, children.back()->GetDuckType());
290: 		}
291: 
292: 		auto type_info = make_uniq<ArrowStructInfo>(std::move(children));
293: 		auto struct_type = make_uniq<ArrowType>(LogicalType::STRUCT(members), std::move(type_info));
294: 		struct_type->SetRunEndEncoded();
295: 		return struct_type;
296: 	} else if (format == "+m") {
297: 		auto &arrow_struct_type = *schema.children[0];
298: 		D_ASSERT(arrow_struct_type.n_children == 2);
299: 		auto key_type = ArrowTableFunction::GetArrowLogicalType(*arrow_struct_type.children[0]);
300: 		auto value_type = ArrowTableFunction::GetArrowLogicalType(*arrow_struct_type.children[1]);
301: 		child_list_t<LogicalType> key_value;
302: 		key_value.emplace_back(std::make_pair("key", key_type->GetDuckType()));
303: 		key_value.emplace_back(std::make_pair("value", value_type->GetDuckType()));
304: 
305: 		auto map_type = LogicalType::MAP(key_type->GetDuckType(), value_type->GetDuckType());
306: 		vector<unique_ptr<ArrowType>> children;
307: 		children.reserve(2);
308: 		children.push_back(std::move(key_type));
309: 		children.push_back(std::move(value_type));
310: 		auto inner_struct = make_uniq<ArrowType>(LogicalType::STRUCT(std::move(key_value)),
311: 		                                         make_uniq<ArrowStructInfo>(std::move(children)));
312: 		auto map_type_info = ArrowListInfo::List(std::move(inner_struct), ArrowVariableSizeType::NORMAL);
313: 		return make_uniq<ArrowType>(map_type, std::move(map_type_info));
314: 	} else if (format == "z") {
315: 		auto type_info = make_uniq<ArrowStringInfo>(ArrowVariableSizeType::NORMAL);
316: 		return make_uniq<ArrowType>(LogicalType::BLOB, std::move(type_info));
317: 	} else if (format == "Z") {
318: 		auto type_info = make_uniq<ArrowStringInfo>(ArrowVariableSizeType::SUPER_SIZE);
319: 		return make_uniq<ArrowType>(LogicalType::BLOB, std::move(type_info));
320: 	} else if (format[0] == 'w') {
321: 		string parameters = format.substr(format.find(':') + 1);
322: 		auto fixed_size = NumericCast<idx_t>(std::stoi(parameters));
323: 		auto type_info = make_uniq<ArrowStringInfo>(fixed_size);
324: 		return make_uniq<ArrowType>(LogicalType::BLOB, std::move(type_info));
325: 	} else if (format[0] == 't' && format[1] == 's') {
326: 		// Timestamp with Timezone
327: 		// TODO right now we just get the UTC value. We probably want to support this properly in the future
328: 		unique_ptr<ArrowTypeInfo> type_info;
329: 		if (format[2] == 'n') {
330: 			type_info = make_uniq<ArrowDateTimeInfo>(ArrowDateTimeType::NANOSECONDS);
331: 		} else if (format[2] == 'u') {
332: 			type_info = make_uniq<ArrowDateTimeInfo>(ArrowDateTimeType::MICROSECONDS);
333: 		} else if (format[2] == 'm') {
334: 			type_info = make_uniq<ArrowDateTimeInfo>(ArrowDateTimeType::MILLISECONDS);
335: 		} else if (format[2] == 's') {
336: 			type_info = make_uniq<ArrowDateTimeInfo>(ArrowDateTimeType::SECONDS);
337: 		} else {
338: 			throw NotImplementedException(" Timestamptz precision of not accepted");
339: 		}
340: 		return make_uniq<ArrowType>(LogicalType::TIMESTAMP_TZ, std::move(type_info));
341: 	} else {
342: 		throw NotImplementedException("Unsupported Internal Arrow Type %s", format);
343: 	}
344: }
345: 
346: unique_ptr<ArrowType> ArrowTableFunction::GetArrowLogicalType(ArrowSchema &schema) {
347: 	auto arrow_type = GetArrowLogicalTypeNoDictionary(schema);
348: 	if (schema.dictionary) {
349: 		auto dictionary = GetArrowLogicalType(*schema.dictionary);
350: 		arrow_type->SetDictionary(std::move(dictionary));
351: 	}
352: 	return arrow_type;
353: }
354: 
355: void ArrowTableFunction::PopulateArrowTableType(ArrowTableType &arrow_table, ArrowSchemaWrapper &schema_p,
356:                                                 vector<string> &names, vector<LogicalType> &return_types) {
357: 	for (idx_t col_idx = 0; col_idx < (idx_t)schema_p.arrow_schema.n_children; col_idx++) {
358: 		auto &schema = *schema_p.arrow_schema.children[col_idx];
359: 		if (!schema.release) {
360: 			throw InvalidInputException("arrow_scan: released schema passed");
361: 		}
362: 		auto arrow_type = GetArrowLogicalType(schema);
363: 		return_types.emplace_back(arrow_type->GetDuckType(true));
364: 		arrow_table.AddColumn(col_idx, std::move(arrow_type));
365: 		auto name = string(schema.name);
366: 		if (name.empty()) {
367: 			name = string("v") + to_string(col_idx);
368: 		}
369: 		names.push_back(name);
370: 	}
371: }
372: 
373: unique_ptr<FunctionData> ArrowTableFunction::ArrowScanBind(ClientContext &context, TableFunctionBindInput &input,
374:                                                            vector<LogicalType> &return_types, vector<string> &names) {
375: 	if (input.inputs[0].IsNull() || input.inputs[1].IsNull() || input.inputs[2].IsNull()) {
376: 		throw BinderException("arrow_scan: pointers cannot be null");
377: 	}
378: 	auto &ref = input.ref;
379: 
380: 	shared_ptr<DependencyItem> dependency;
381: 	if (ref.external_dependency) {
382: 		// This was created during the replacement scan for Python (see python_replacement_scan.cpp)
383: 		// this object is the owning reference to 'stream_factory_ptr' and has to be kept alive.
384: 		dependency = ref.external_dependency->GetDependency("replacement_cache");
385: 		D_ASSERT(dependency);
386: 	}
387: 
388: 	auto stream_factory_ptr = input.inputs[0].GetPointer();
389: 	auto stream_factory_produce = (stream_factory_produce_t)input.inputs[1].GetPointer();       // NOLINT
390: 	auto stream_factory_get_schema = (stream_factory_get_schema_t)input.inputs[2].GetPointer(); // NOLINT
391: 
392: 	auto res = make_uniq<ArrowScanFunctionData>(stream_factory_produce, stream_factory_ptr, std::move(dependency));
393: 
394: 	auto &data = *res;
395: 	stream_factory_get_schema(reinterpret_cast<ArrowArrayStream *>(stream_factory_ptr), data.schema_root.arrow_schema);
396: 	PopulateArrowTableType(res->arrow_table, data.schema_root, names, return_types);
397: 	QueryResult::DeduplicateColumns(names);
398: 	res->all_types = return_types;
399: 	if (return_types.empty()) {
400: 		throw InvalidInputException("Provided table/dataframe must have at least one column");
401: 	}
402: 	return std::move(res);
403: }
404: 
405: unique_ptr<ArrowArrayStreamWrapper> ProduceArrowScan(const ArrowScanFunctionData &function,
406:                                                      const vector<column_t> &column_ids, TableFilterSet *filters) {
407: 	//! Generate Projection Pushdown Vector
408: 	ArrowStreamParameters parameters;
409: 	D_ASSERT(!column_ids.empty());
410: 	auto &arrow_types = function.arrow_table.GetColumns();
411: 	for (idx_t idx = 0; idx < column_ids.size(); idx++) {
412: 		auto col_idx = column_ids[idx];
413: 		if (col_idx != COLUMN_IDENTIFIER_ROW_ID) {
414: 			auto &schema = *function.schema_root.arrow_schema.children[col_idx];
415: 			arrow_types.at(col_idx)->ThrowIfInvalid();
416: 			parameters.projected_columns.projection_map[idx] = schema.name;
417: 			parameters.projected_columns.columns.emplace_back(schema.name);
418: 			parameters.projected_columns.filter_to_col[idx] = col_idx;
419: 		}
420: 	}
421: 	parameters.filters = filters;
422: 	return function.scanner_producer(function.stream_factory_ptr, parameters);
423: }
424: 
425: idx_t ArrowTableFunction::ArrowScanMaxThreads(ClientContext &context, const FunctionData *bind_data_p) {
426: 	return context.db->NumberOfThreads();
427: }
428: 
429: bool ArrowTableFunction::ArrowScanParallelStateNext(ClientContext &context, const FunctionData *bind_data_p,
430:                                                     ArrowScanLocalState &state, ArrowScanGlobalState &parallel_state) {
431: 	lock_guard<mutex> parallel_lock(parallel_state.main_mutex);
432: 	if (parallel_state.done) {
433: 		return false;
434: 	}
435: 	state.Reset();
436: 	state.batch_index = ++parallel_state.batch_index;
437: 
438: 	auto current_chunk = parallel_state.stream->GetNextChunk();
439: 	while (current_chunk->arrow_array.length == 0 && current_chunk->arrow_array.release) {
440: 		current_chunk = parallel_state.stream->GetNextChunk();
441: 	}
442: 	state.chunk = std::move(current_chunk);
443: 	//! have we run out of chunks? we are done
444: 	if (!state.chunk->arrow_array.release) {
445: 		parallel_state.done = true;
446: 		return false;
447: 	}
448: 	return true;
449: }
450: 
451: unique_ptr<GlobalTableFunctionState> ArrowTableFunction::ArrowScanInitGlobal(ClientContext &context,
452:                                                                              TableFunctionInitInput &input) {
453: 	auto &bind_data = input.bind_data->Cast<ArrowScanFunctionData>();
454: 	auto result = make_uniq<ArrowScanGlobalState>();
455: 	result->stream = ProduceArrowScan(bind_data, input.column_ids, input.filters.get());
456: 	result->max_threads = ArrowScanMaxThreads(context, input.bind_data.get());
457: 	if (!input.projection_ids.empty()) {
458: 		result->projection_ids = input.projection_ids;
459: 		for (const auto &col_idx : input.column_ids) {
460: 			if (col_idx == COLUMN_IDENTIFIER_ROW_ID) {
461: 				result->scanned_types.emplace_back(LogicalType::ROW_TYPE);
462: 			} else {
463: 				result->scanned_types.push_back(bind_data.all_types[col_idx]);
464: 			}
465: 		}
466: 	}
467: 	return std::move(result);
468: }
469: 
470: unique_ptr<LocalTableFunctionState>
471: ArrowTableFunction::ArrowScanInitLocalInternal(ClientContext &context, TableFunctionInitInput &input,
472:                                                GlobalTableFunctionState *global_state_p) {
473: 	auto &global_state = global_state_p->Cast<ArrowScanGlobalState>();
474: 	auto current_chunk = make_uniq<ArrowArrayWrapper>();
475: 	auto result = make_uniq<ArrowScanLocalState>(std::move(current_chunk));
476: 	result->column_ids = input.column_ids;
477: 	result->filters = input.filters.get();
478: 	if (!input.projection_ids.empty()) {
479: 		auto &asgs = global_state_p->Cast<ArrowScanGlobalState>();
480: 		result->all_columns.Initialize(context, asgs.scanned_types);
481: 	}
482: 	if (!ArrowScanParallelStateNext(context, input.bind_data.get(), *result, global_state)) {
483: 		return nullptr;
484: 	}
485: 	return std::move(result);
486: }
487: 
488: unique_ptr<LocalTableFunctionState> ArrowTableFunction::ArrowScanInitLocal(ExecutionContext &context,
489:                                                                            TableFunctionInitInput &input,
490:                                                                            GlobalTableFunctionState *global_state_p) {
491: 	return ArrowScanInitLocalInternal(context.client, input, global_state_p);
492: }
493: 
494: void ArrowTableFunction::ArrowScanFunction(ClientContext &context, TableFunctionInput &data_p, DataChunk &output) {
495: 	if (!data_p.local_state) {
496: 		return;
497: 	}
498: 	auto &data = data_p.bind_data->CastNoConst<ArrowScanFunctionData>(); // FIXME
499: 	auto &state = data_p.local_state->Cast<ArrowScanLocalState>();
500: 	auto &global_state = data_p.global_state->Cast<ArrowScanGlobalState>();
501: 
502: 	//! Out of tuples in this chunk
503: 	if (state.chunk_offset >= (idx_t)state.chunk->arrow_array.length) {
504: 		if (!ArrowScanParallelStateNext(context, data_p.bind_data.get(), state, global_state)) {
505: 			return;
506: 		}
507: 	}
508: 	auto output_size =
509: 	    MinValue<idx_t>(STANDARD_VECTOR_SIZE, NumericCast<idx_t>(state.chunk->arrow_array.length) - state.chunk_offset);
510: 	data.lines_read += output_size;
511: 	if (global_state.CanRemoveFilterColumns()) {
512: 		state.all_columns.Reset();
513: 		state.all_columns.SetCardinality(output_size);
514: 		ArrowToDuckDB(state, data.arrow_table.GetColumns(), state.all_columns, data.lines_read - output_size);
515: 		output.ReferenceColumns(state.all_columns, global_state.projection_ids);
516: 	} else {
517: 		output.SetCardinality(output_size);
518: 		ArrowToDuckDB(state, data.arrow_table.GetColumns(), output, data.lines_read - output_size);
519: 	}
520: 
521: 	output.Verify();
522: 	state.chunk_offset += output.size();
523: }
524: 
525: unique_ptr<NodeStatistics> ArrowTableFunction::ArrowScanCardinality(ClientContext &context, const FunctionData *data) {
526: 	return make_uniq<NodeStatistics>();
527: }
528: 
529: OperatorPartitionData ArrowTableFunction::ArrowGetPartitionData(ClientContext &context,
530:                                                                 TableFunctionGetPartitionInput &input) {
531: 	if (input.partition_info.RequiresPartitionColumns()) {
532: 		throw InternalException("ArrowTableFunction::GetPartitionData: partition columns not supported");
533: 	}
534: 	auto &state = input.local_state->Cast<ArrowScanLocalState>();
535: 	return OperatorPartitionData(state.batch_index);
536: }
537: 
538: bool ArrowTableFunction::ArrowPushdownType(const LogicalType &type) {
539: 	switch (type.id()) {
540: 	case LogicalTypeId::BOOLEAN:
541: 	case LogicalTypeId::TINYINT:
542: 	case LogicalTypeId::SMALLINT:
543: 	case LogicalTypeId::INTEGER:
544: 	case LogicalTypeId::BIGINT:
545: 	case LogicalTypeId::DATE:
546: 	case LogicalTypeId::TIME:
547: 	case LogicalTypeId::TIMESTAMP:
548: 	case LogicalTypeId::TIMESTAMP_MS:
549: 	case LogicalTypeId::TIMESTAMP_NS:
550: 	case LogicalTypeId::TIMESTAMP_SEC:
551: 	case LogicalTypeId::TIMESTAMP_TZ:
552: 	case LogicalTypeId::UTINYINT:
553: 	case LogicalTypeId::USMALLINT:
554: 	case LogicalTypeId::UINTEGER:
555: 	case LogicalTypeId::UBIGINT:
556: 	case LogicalTypeId::FLOAT:
557: 	case LogicalTypeId::DOUBLE:
558: 	case LogicalTypeId::VARCHAR:
559: 	case LogicalTypeId::BLOB:
560: 		return true;
561: 	case LogicalTypeId::DECIMAL: {
562: 		switch (type.InternalType()) {
563: 		case PhysicalType::INT16:
564: 		case PhysicalType::INT32:
565: 		case PhysicalType::INT64:
566: 			return true;
567: 		default:
568: 			return false;
569: 		}
570: 	} break;
571: 	case LogicalTypeId::STRUCT: {
572: 		auto struct_types = StructType::GetChildTypes(type);
573: 		for (auto &struct_type : struct_types) {
574: 			if (!ArrowPushdownType(struct_type.second)) {
575: 				return false;
576: 			}
577: 		}
578: 		return true;
579: 	}
580: 	default:
581: 		return false;
582: 	}
583: }
584: 
585: void ArrowTableFunction::RegisterFunction(BuiltinFunctions &set) {
586: 	TableFunction arrow("arrow_scan", {LogicalType::POINTER, LogicalType::POINTER, LogicalType::POINTER},
587: 	                    ArrowScanFunction, ArrowScanBind, ArrowScanInitGlobal, ArrowScanInitLocal);
588: 	arrow.cardinality = ArrowScanCardinality;
589: 	arrow.get_partition_data = ArrowGetPartitionData;
590: 	arrow.projection_pushdown = true;
591: 	arrow.filter_pushdown = true;
592: 	arrow.filter_prune = true;
593: 	arrow.supports_pushdown_type = ArrowPushdownType;
594: 	set.AddFunction(arrow);
595: 
596: 	TableFunction arrow_dumb("arrow_scan_dumb", {LogicalType::POINTER, LogicalType::POINTER, LogicalType::POINTER},
597: 	                         ArrowScanFunction, ArrowScanBind, ArrowScanInitGlobal, ArrowScanInitLocal);
598: 	arrow_dumb.cardinality = ArrowScanCardinality;
599: 	arrow_dumb.get_partition_data = ArrowGetPartitionData;
600: 	arrow_dumb.projection_pushdown = false;
601: 	arrow_dumb.filter_pushdown = false;
602: 	arrow_dumb.filter_prune = false;
603: 	set.AddFunction(arrow_dumb);
604: }
605: 
606: void BuiltinFunctions::RegisterArrowFunctions() {
607: 	ArrowTableFunction::RegisterFunction(*this);
608: }
609: } // namespace duckdb
[end of src/function/table/arrow.cpp]
[start of src/function/table/arrow_conversion.cpp]
1: #include "duckdb/common/exception/conversion_exception.hpp"
2: #include "duckdb/common/limits.hpp"
3: #include "duckdb/common/operator/multiply.hpp"
4: #include "duckdb/common/types/arrow_aux_data.hpp"
5: #include "duckdb/common/types/arrow_string_view_type.hpp"
6: #include "duckdb/common/types/hugeint.hpp"
7: #include "duckdb/function/scalar/nested_functions.hpp"
8: #include "duckdb/function/table/arrow.hpp"
9: 
10: #include "duckdb/common/bswap.hpp"
11: 
12: namespace duckdb {
13: 
14: namespace {
15: 
16: enum class ArrowArrayPhysicalType : uint8_t { DICTIONARY_ENCODED, RUN_END_ENCODED, DEFAULT };
17: 
18: ArrowArrayPhysicalType GetArrowArrayPhysicalType(const ArrowType &type) {
19: 	if (type.HasDictionary()) {
20: 		return ArrowArrayPhysicalType::DICTIONARY_ENCODED;
21: 	}
22: 	if (type.RunEndEncoded()) {
23: 		return ArrowArrayPhysicalType::RUN_END_ENCODED;
24: 	}
25: 	return ArrowArrayPhysicalType::DEFAULT;
26: }
27: 
28: } // namespace
29: 
30: static void ShiftRight(unsigned char *ar, int size, int shift) {
31: 	int carry = 0;
32: 	while (shift--) {
33: 		for (int i = size - 1; i >= 0; --i) {
34: 			int next = (ar[i] & 1) ? 0x80 : 0;
35: 			ar[i] = UnsafeNumericCast<unsigned char>(carry | (ar[i] >> 1));
36: 			carry = next;
37: 		}
38: 	}
39: }
40: 
41: idx_t GetEffectiveOffset(const ArrowArray &array, int64_t parent_offset, const ArrowScanLocalState &state,
42:                          int64_t nested_offset = -1) {
43: 	if (nested_offset != -1) {
44: 		// The parent of this array is a list
45: 		// We just ignore the parent offset, it's already applied to the list
46: 		return UnsafeNumericCast<idx_t>(array.offset + nested_offset);
47: 	}
48: 	// Parent offset is set in the case of a struct, it applies to all child arrays
49: 	// 'chunk_offset' is how much of the chunk we've already scanned, in case the chunk size exceeds
50: 	// STANDARD_VECTOR_SIZE
51: 	return UnsafeNumericCast<idx_t>(array.offset + parent_offset) + state.chunk_offset;
52: }
53: 
54: template <class T>
55: T *ArrowBufferData(ArrowArray &array, idx_t buffer_idx) {
56: 	return (T *)array.buffers[buffer_idx]; // NOLINT
57: }
58: 
59: static void GetValidityMask(ValidityMask &mask, ArrowArray &array, const ArrowScanLocalState &scan_state, idx_t size,
60:                             int64_t parent_offset, int64_t nested_offset = -1, bool add_null = false) {
61: 	// In certains we don't need to or cannot copy arrow's validity mask to duckdb.
62: 	//
63: 	// The conditions where we do want to copy arrow's mask to duckdb are:
64: 	// 1. nulls exist
65: 	// 2. n_buffers > 0, meaning the array's arrow type is not `null`
66: 	// 3. the validity buffer (the first buffer) is not a nullptr
67: 	if (array.null_count != 0 && array.n_buffers > 0 && array.buffers[0]) {
68: 		auto bit_offset = GetEffectiveOffset(array, parent_offset, scan_state, nested_offset);
69: 		mask.EnsureWritable();
70: #if STANDARD_VECTOR_SIZE > 64
71: 		auto n_bitmask_bytes = (size + 8 - 1) / 8;
72: 		if (bit_offset % 8 == 0) {
73: 			//! just memcpy nullmask
74: 			memcpy((void *)mask.GetData(), ArrowBufferData<uint8_t>(array, 0) + bit_offset / 8, n_bitmask_bytes);
75: 		} else {
76: 			//! need to re-align nullmask
77: 			vector<uint8_t> temp_nullmask(n_bitmask_bytes + 1);
78: 			memcpy(temp_nullmask.data(), ArrowBufferData<uint8_t>(array, 0) + bit_offset / 8, n_bitmask_bytes + 1);
79: 			ShiftRight(temp_nullmask.data(), NumericCast<int>(n_bitmask_bytes + 1),
80: 			           NumericCast<int>(bit_offset % 8ull)); //! why this has to be a right shift is a mystery to me
81: 			memcpy((void *)mask.GetData(), data_ptr_cast(temp_nullmask.data()), n_bitmask_bytes);
82: 		}
83: #else
84: 		auto byte_offset = bit_offset / 8;
85: 		auto source_data = ArrowBufferData<uint8_t>(array, 0);
86: 		bit_offset %= 8;
87: 		for (idx_t i = 0; i < size; i++) {
88: 			mask.Set(i, source_data[byte_offset] & (1 << bit_offset));
89: 			bit_offset++;
90: 			if (bit_offset == 8) {
91: 				bit_offset = 0;
92: 				byte_offset++;
93: 			}
94: 		}
95: #endif
96: 	}
97: 	if (add_null) {
98: 		//! We are setting a validity mask of the data part of dictionary vector
99: 		//! For some reason, Nulls are allowed to be indexes, hence we need to set the last element here to be null
100: 		//! We might have to resize the mask
101: 		mask.Resize(size + 1);
102: 		mask.SetInvalid(size);
103: 	}
104: }
105: 
106: static void SetValidityMask(Vector &vector, ArrowArray &array, const ArrowScanLocalState &scan_state, idx_t size,
107:                             int64_t parent_offset, int64_t nested_offset, bool add_null = false) {
108: 	D_ASSERT(vector.GetVectorType() == VectorType::FLAT_VECTOR);
109: 	auto &mask = FlatVector::Validity(vector);
110: 	GetValidityMask(mask, array, scan_state, size, parent_offset, nested_offset, add_null);
111: }
112: 
113: static void ColumnArrowToDuckDBRunEndEncoded(Vector &vector, const ArrowArray &array, ArrowArrayScanState &array_state,
114:                                              idx_t size, const ArrowType &arrow_type, int64_t nested_offset = -1,
115:                                              ValidityMask *parent_mask = nullptr, uint64_t parent_offset = 0);
116: 
117: static void ColumnArrowToDuckDB(Vector &vector, ArrowArray &array, ArrowArrayScanState &array_state, idx_t size,
118:                                 const ArrowType &arrow_type, int64_t nested_offset = -1,
119:                                 ValidityMask *parent_mask = nullptr, uint64_t parent_offset = 0);
120: 
121: static void ColumnArrowToDuckDBDictionary(Vector &vector, ArrowArray &array, ArrowArrayScanState &array_state,
122:                                           idx_t size, const ArrowType &arrow_type, int64_t nested_offset = -1,
123:                                           const ValidityMask *parent_mask = nullptr, uint64_t parent_offset = 0);
124: 
125: namespace {
126: 
127: struct ArrowListOffsetData {
128: 	idx_t list_size = 0;
129: 	idx_t start_offset = 0;
130: };
131: 
132: } // namespace
133: 
134: template <class BUFFER_TYPE>
135: static ArrowListOffsetData ConvertArrowListOffsetsTemplated(Vector &vector, ArrowArray &array, idx_t size,
136:                                                             idx_t effective_offset) {
137: 	ArrowListOffsetData result;
138: 	auto &start_offset = result.start_offset;
139: 	auto &list_size = result.list_size;
140: 
141: 	if (size == 0) {
142: 		start_offset = 0;
143: 		list_size = 0;
144: 		return result;
145: 	}
146: 
147: 	idx_t cur_offset = 0;
148: 	auto offsets = ArrowBufferData<BUFFER_TYPE>(array, 1) + effective_offset;
149: 	start_offset = offsets[0];
150: 	auto list_data = FlatVector::GetData<list_entry_t>(vector);
151: 	for (idx_t i = 0; i < size; i++) {
152: 		auto &le = list_data[i];
153: 		le.offset = cur_offset;
154: 		le.length = offsets[i + 1] - offsets[i];
155: 		cur_offset += le.length;
156: 	}
157: 	list_size = offsets[size];
158: 	list_size -= start_offset;
159: 	return result;
160: }
161: 
162: template <class BUFFER_TYPE>
163: static ArrowListOffsetData ConvertArrowListViewOffsetsTemplated(Vector &vector, ArrowArray &array, idx_t size,
164:                                                                 idx_t effective_offset) {
165: 	ArrowListOffsetData result;
166: 	auto &start_offset = result.start_offset;
167: 	auto &list_size = result.list_size;
168: 
169: 	list_size = 0;
170: 	auto offsets = ArrowBufferData<BUFFER_TYPE>(array, 1) + effective_offset;
171: 	auto sizes = ArrowBufferData<BUFFER_TYPE>(array, 2) + effective_offset;
172: 
173: 	// In ListArrays the offsets have to be sequential
174: 	// ListViewArrays do not have this same constraint
175: 	// for that reason we need to keep track of the lowest offset, so we can skip all the data that comes before it
176: 	// when we scan the child data
177: 
178: 	auto lowest_offset = size ? offsets[0] : 0;
179: 	auto list_data = FlatVector::GetData<list_entry_t>(vector);
180: 	for (idx_t i = 0; i < size; i++) {
181: 		auto &le = list_data[i];
182: 		le.offset = offsets[i];
183: 		le.length = sizes[i];
184: 		list_size += le.length;
185: 		if (sizes[i] != 0) {
186: 			lowest_offset = MinValue(lowest_offset, offsets[i]);
187: 		}
188: 	}
189: 	start_offset = lowest_offset;
190: 	if (start_offset) {
191: 		// We start scanning the child data at the 'start_offset' so we need to fix up the created list entries
192: 		for (idx_t i = 0; i < size; i++) {
193: 			auto &le = list_data[i];
194: 			le.offset = le.offset <= start_offset ? 0 : le.offset - start_offset;
195: 		}
196: 	}
197: 	return result;
198: }
199: 
200: static ArrowListOffsetData ConvertArrowListOffsets(Vector &vector, ArrowArray &array, idx_t size,
201:                                                    const ArrowType &arrow_type, idx_t effective_offset) {
202: 	auto &list_info = arrow_type.GetTypeInfo<ArrowListInfo>();
203: 	auto size_type = list_info.GetSizeType();
204: 	if (list_info.IsView()) {
205: 		if (size_type == ArrowVariableSizeType::NORMAL) {
206: 			return ConvertArrowListViewOffsetsTemplated<uint32_t>(vector, array, size, effective_offset);
207: 		} else {
208: 			D_ASSERT(size_type == ArrowVariableSizeType::SUPER_SIZE);
209: 			return ConvertArrowListViewOffsetsTemplated<uint64_t>(vector, array, size, effective_offset);
210: 		}
211: 	} else {
212: 		if (size_type == ArrowVariableSizeType::NORMAL) {
213: 			return ConvertArrowListOffsetsTemplated<uint32_t>(vector, array, size, effective_offset);
214: 		} else {
215: 			D_ASSERT(size_type == ArrowVariableSizeType::SUPER_SIZE);
216: 			return ConvertArrowListOffsetsTemplated<uint64_t>(vector, array, size, effective_offset);
217: 		}
218: 	}
219: }
220: 
221: static void ArrowToDuckDBList(Vector &vector, ArrowArray &array, ArrowArrayScanState &array_state, idx_t size,
222:                               const ArrowType &arrow_type, int64_t nested_offset, const ValidityMask *parent_mask,
223:                               int64_t parent_offset) {
224: 	auto &scan_state = array_state.state;
225: 
226: 	auto &list_info = arrow_type.GetTypeInfo<ArrowListInfo>();
227: 	SetValidityMask(vector, array, scan_state, size, parent_offset, nested_offset);
228: 
229: 	auto effective_offset = GetEffectiveOffset(array, parent_offset, scan_state, nested_offset);
230: 	auto list_data = ConvertArrowListOffsets(vector, array, size, arrow_type, effective_offset);
231: 	auto &start_offset = list_data.start_offset;
232: 	auto &list_size = list_data.list_size;
233: 
234: 	ListVector::Reserve(vector, list_size);
235: 	ListVector::SetListSize(vector, list_size);
236: 	auto &child_vector = ListVector::GetEntry(vector);
237: 	SetValidityMask(child_vector, *array.children[0], scan_state, list_size, array.offset,
238: 	                NumericCast<int64_t>(start_offset));
239: 	auto &list_mask = FlatVector::Validity(vector);
240: 	if (parent_mask) {
241: 		//! Since this List is owned by a struct we must guarantee their validity map matches on Null
242: 		if (!parent_mask->AllValid()) {
243: 			for (idx_t i = 0; i < size; i++) {
244: 				if (!parent_mask->RowIsValid(i)) {
245: 					list_mask.SetInvalid(i);
246: 				}
247: 			}
248: 		}
249: 	}
250: 	auto &child_state = array_state.GetChild(0);
251: 	auto &child_array = *array.children[0];
252: 	auto &child_type = list_info.GetChild();
253: 
254: 	if (list_size == 0 && start_offset == 0) {
255: 		D_ASSERT(!child_array.dictionary);
256: 		ColumnArrowToDuckDB(child_vector, child_array, child_state, list_size, child_type, -1);
257: 		return;
258: 	}
259: 
260: 	auto array_physical_type = GetArrowArrayPhysicalType(child_type);
261: 	switch (array_physical_type) {
262: 	case ArrowArrayPhysicalType::DICTIONARY_ENCODED:
263: 		// TODO: add support for offsets
264: 		ColumnArrowToDuckDBDictionary(child_vector, child_array, child_state, list_size, child_type,
265: 		                              NumericCast<int64_t>(start_offset));
266: 		break;
267: 	case ArrowArrayPhysicalType::RUN_END_ENCODED:
268: 		ColumnArrowToDuckDBRunEndEncoded(child_vector, child_array, child_state, list_size, child_type,
269: 		                                 NumericCast<int64_t>(start_offset));
270: 		break;
271: 	case ArrowArrayPhysicalType::DEFAULT:
272: 		ColumnArrowToDuckDB(child_vector, child_array, child_state, list_size, child_type,
273: 		                    NumericCast<int64_t>(start_offset));
274: 		break;
275: 	default:
276: 		throw NotImplementedException("ArrowArrayPhysicalType not recognized");
277: 	}
278: }
279: 
280: static void ArrowToDuckDBArray(Vector &vector, ArrowArray &array, ArrowArrayScanState &array_state, idx_t size,
281:                                const ArrowType &arrow_type, int64_t nested_offset, const ValidityMask *parent_mask,
282:                                int64_t parent_offset) {
283: 
284: 	auto &array_info = arrow_type.GetTypeInfo<ArrowArrayInfo>();
285: 	auto &scan_state = array_state.state;
286: 	auto array_size = array_info.FixedSize();
287: 	auto child_count = array_size * size;
288: 	auto child_offset = GetEffectiveOffset(array, parent_offset, scan_state, nested_offset) * array_size;
289: 
290: 	SetValidityMask(vector, array, scan_state, size, parent_offset, nested_offset);
291: 
292: 	auto &child_vector = ArrayVector::GetEntry(vector);
293: 	SetValidityMask(child_vector, *array.children[0], scan_state, child_count, array.offset,
294: 	                NumericCast<int64_t>(child_offset));
295: 
296: 	auto &array_mask = FlatVector::Validity(vector);
297: 	if (parent_mask) {
298: 		//! Since this List is owned by a struct we must guarantee their validity map matches on Null
299: 		if (!parent_mask->AllValid()) {
300: 			for (idx_t i = 0; i < size; i++) {
301: 				if (!parent_mask->RowIsValid(i)) {
302: 					array_mask.SetInvalid(i);
303: 				}
304: 			}
305: 		}
306: 	}
307: 
308: 	// Broadcast the validity mask to the child vector
309: 	if (!array_mask.AllValid()) {
310: 		auto &child_validity_mask = FlatVector::Validity(child_vector);
311: 		for (idx_t i = 0; i < size; i++) {
312: 			if (!array_mask.RowIsValid(i)) {
313: 				for (idx_t j = 0; j < array_size; j++) {
314: 					child_validity_mask.SetInvalid(i * array_size + j);
315: 				}
316: 			}
317: 		}
318: 	}
319: 
320: 	auto &child_state = array_state.GetChild(0);
321: 	auto &child_array = *array.children[0];
322: 	auto &child_type = array_info.GetChild();
323: 	if (child_count == 0 && child_offset == 0) {
324: 		D_ASSERT(!child_array.dictionary);
325: 		ColumnArrowToDuckDB(child_vector, child_array, child_state, child_count, child_type, -1);
326: 	} else {
327: 		if (child_array.dictionary) {
328: 			ColumnArrowToDuckDBDictionary(child_vector, child_array, child_state, child_count, child_type,
329: 			                              NumericCast<int64_t>(child_offset));
330: 		} else {
331: 			ColumnArrowToDuckDB(child_vector, child_array, child_state, child_count, child_type,
332: 			                    NumericCast<int64_t>(child_offset));
333: 		}
334: 	}
335: }
336: 
337: static void ArrowToDuckDBBlob(Vector &vector, ArrowArray &array, const ArrowScanLocalState &scan_state, idx_t size,
338:                               const ArrowType &arrow_type, int64_t nested_offset, int64_t parent_offset) {
339: 	SetValidityMask(vector, array, scan_state, size, parent_offset, nested_offset);
340: 	auto &string_info = arrow_type.GetTypeInfo<ArrowStringInfo>();
341: 	auto size_type = string_info.GetSizeType();
342: 	if (size_type == ArrowVariableSizeType::FIXED_SIZE) {
343: 		auto fixed_size = string_info.FixedSize();
344: 		//! Have to check validity mask before setting this up
345: 		idx_t offset = GetEffectiveOffset(array, parent_offset, scan_state, nested_offset) * fixed_size;
346: 		auto cdata = ArrowBufferData<char>(array, 1);
347: 		for (idx_t row_idx = 0; row_idx < size; row_idx++) {
348: 			if (FlatVector::IsNull(vector, row_idx)) {
349: 				continue;
350: 			}
351: 			auto bptr = cdata + offset;
352: 			auto blob_len = fixed_size;
353: 			FlatVector::GetData<string_t>(vector)[row_idx] = StringVector::AddStringOrBlob(vector, bptr, blob_len);
354: 			offset += blob_len;
355: 		}
356: 	} else if (size_type == ArrowVariableSizeType::NORMAL) {
357: 		auto offsets =
358: 		    ArrowBufferData<uint32_t>(array, 1) + GetEffectiveOffset(array, parent_offset, scan_state, nested_offset);
359: 		auto cdata = ArrowBufferData<char>(array, 2);
360: 		for (idx_t row_idx = 0; row_idx < size; row_idx++) {
361: 			if (FlatVector::IsNull(vector, row_idx)) {
362: 				continue;
363: 			}
364: 			auto bptr = cdata + offsets[row_idx];
365: 			auto blob_len = offsets[row_idx + 1] - offsets[row_idx];
366: 			FlatVector::GetData<string_t>(vector)[row_idx] = StringVector::AddStringOrBlob(vector, bptr, blob_len);
367: 		}
368: 	} else {
369: 		//! Check if last offset is higher than max uint32
370: 		if (ArrowBufferData<uint64_t>(array, 1)[array.length] > NumericLimits<uint32_t>::Maximum()) { // LCOV_EXCL_START
371: 			throw ConversionException("DuckDB does not support Blobs over 4GB");
372: 		} // LCOV_EXCL_STOP
373: 		auto offsets =
374: 		    ArrowBufferData<uint64_t>(array, 1) + GetEffectiveOffset(array, parent_offset, scan_state, nested_offset);
375: 		auto cdata = ArrowBufferData<char>(array, 2);
376: 		for (idx_t row_idx = 0; row_idx < size; row_idx++) {
377: 			if (FlatVector::IsNull(vector, row_idx)) {
378: 				continue;
379: 			}
380: 			auto bptr = cdata + offsets[row_idx];
381: 			auto blob_len = offsets[row_idx + 1] - offsets[row_idx];
382: 			FlatVector::GetData<string_t>(vector)[row_idx] = StringVector::AddStringOrBlob(vector, bptr, blob_len);
383: 		}
384: 	}
385: }
386: 
387: static void ArrowToDuckDBMapVerify(Vector &vector, idx_t count) {
388: 	auto valid_check = MapVector::CheckMapValidity(vector, count);
389: 	switch (valid_check) {
390: 	case MapInvalidReason::VALID:
391: 		break;
392: 	case MapInvalidReason::DUPLICATE_KEY: {
393: 		throw InvalidInputException("Arrow map contains duplicate key, which isn't supported by DuckDB map type");
394: 	}
395: 	case MapInvalidReason::NULL_KEY: {
396: 		throw InvalidInputException("Arrow map contains NULL as map key, which isn't supported by DuckDB map type");
397: 	}
398: 	default: {
399: 		throw InternalException("MapInvalidReason not implemented");
400: 	}
401: 	}
402: }
403: 
404: template <class T>
405: static void SetVectorString(Vector &vector, idx_t size, char *cdata, T *offsets) {
406: 	auto strings = FlatVector::GetData<string_t>(vector);
407: 	for (idx_t row_idx = 0; row_idx < size; row_idx++) {
408: 		if (FlatVector::IsNull(vector, row_idx)) {
409: 			continue;
410: 		}
411: 		auto cptr = cdata + offsets[row_idx];
412: 		auto str_len = offsets[row_idx + 1] - offsets[row_idx];
413: 		if (str_len > NumericLimits<uint32_t>::Maximum()) { // LCOV_EXCL_START
414: 			throw ConversionException("DuckDB does not support Strings over 4GB");
415: 		} // LCOV_EXCL_STOP
416: 		strings[row_idx] = string_t(cptr, UnsafeNumericCast<uint32_t>(str_len));
417: 	}
418: }
419: 
420: static void SetVectorStringView(Vector &vector, idx_t size, ArrowArray &array, idx_t current_pos) {
421: 	auto strings = FlatVector::GetData<string_t>(vector);
422: 	auto arrow_string = ArrowBufferData<arrow_string_view_t>(array, 1) + current_pos;
423: 
424: 	for (idx_t row_idx = 0; row_idx < size; row_idx++) {
425: 		if (FlatVector::IsNull(vector, row_idx)) {
426: 			continue;
427: 		}
428: 		auto length = UnsafeNumericCast<uint32_t>(arrow_string[row_idx].Length());
429: 		if (arrow_string[row_idx].IsInline()) {
430: 			//	This string is inlined
431: 			//  | Bytes 0-3  | Bytes 4-15                            |
432: 			//  |------------|---------------------------------------|
433: 			//  | length     | data (padded with 0)                  |
434: 			strings[row_idx] = string_t(arrow_string[row_idx].GetInlineData(), length);
435: 		} else {
436: 			//  This string is not inlined, we have to check a different buffer and offsets
437: 			//  | Bytes 0-3  | Bytes 4-7  | Bytes 8-11 | Bytes 12-15 |
438: 			//  |------------|------------|------------|-------------|
439: 			//  | length     | prefix     | buf. index | offset      |
440: 			auto buffer_index = UnsafeNumericCast<uint32_t>(arrow_string[row_idx].GetBufferIndex());
441: 			int32_t offset = arrow_string[row_idx].GetOffset();
442: 			D_ASSERT(array.n_buffers > 2 + buffer_index);
443: 			auto c_data = ArrowBufferData<char>(array, 2 + buffer_index);
444: 			strings[row_idx] = string_t(&c_data[offset], length);
445: 		}
446: 	}
447: }
448: 
449: static void DirectConversion(Vector &vector, ArrowArray &array, const ArrowScanLocalState &scan_state,
450:                              int64_t nested_offset, uint64_t parent_offset) {
451: 	auto internal_type = GetTypeIdSize(vector.GetType().InternalType());
452: 	auto data_ptr =
453: 	    ArrowBufferData<data_t>(array, 1) +
454: 	    internal_type * GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset), scan_state, nested_offset);
455: 	FlatVector::SetData(vector, data_ptr);
456: }
457: 
458: template <class T>
459: static void TimeConversion(Vector &vector, ArrowArray &array, const ArrowScanLocalState &scan_state,
460:                            int64_t nested_offset, int64_t parent_offset, idx_t size, int64_t conversion) {
461: 	auto tgt_ptr = FlatVector::GetData<dtime_t>(vector);
462: 	auto &validity_mask = FlatVector::Validity(vector);
463: 	auto src_ptr =
464: 	    static_cast<const T *>(array.buffers[1]) + GetEffectiveOffset(array, parent_offset, scan_state, nested_offset);
465: 	for (idx_t row = 0; row < size; row++) {
466: 		if (!validity_mask.RowIsValid(row)) {
467: 			continue;
468: 		}
469: 		if (!TryMultiplyOperator::Operation(static_cast<int64_t>(src_ptr[row]), conversion, tgt_ptr[row].micros)) {
470: 			throw ConversionException("Could not convert Time to Microsecond");
471: 		}
472: 	}
473: }
474: 
475: static void UUIDConversion(Vector &vector, const ArrowArray &array, const ArrowScanLocalState &scan_state,
476:                            int64_t nested_offset, int64_t parent_offset, idx_t size) {
477: 	auto tgt_ptr = FlatVector::GetData<hugeint_t>(vector);
478: 	auto &validity_mask = FlatVector::Validity(vector);
479: 	auto src_ptr = static_cast<const hugeint_t *>(array.buffers[1]) +
480: 	               GetEffectiveOffset(array, parent_offset, scan_state, nested_offset);
481: 	for (idx_t row = 0; row < size; row++) {
482: 		if (!validity_mask.RowIsValid(row)) {
483: 			continue;
484: 		}
485: 		tgt_ptr[row].lower = static_cast<uint64_t>(BSwap(src_ptr[row].upper));
486: 		// flip Upper MSD
487: 		tgt_ptr[row].upper =
488: 		    static_cast<int64_t>(static_cast<uint64_t>(BSwap(src_ptr[row].lower)) ^ (static_cast<uint64_t>(1) << 63));
489: 	}
490: }
491: 
492: static void TimestampTZConversion(Vector &vector, ArrowArray &array, const ArrowScanLocalState &scan_state,
493:                                   int64_t nested_offset, int64_t parent_offset, idx_t size, int64_t conversion) {
494: 	auto tgt_ptr = FlatVector::GetData<timestamp_t>(vector);
495: 	auto &validity_mask = FlatVector::Validity(vector);
496: 	auto src_ptr =
497: 	    ArrowBufferData<int64_t>(array, 1) + GetEffectiveOffset(array, parent_offset, scan_state, nested_offset);
498: 	for (idx_t row = 0; row < size; row++) {
499: 		if (!validity_mask.RowIsValid(row)) {
500: 			continue;
501: 		}
502: 		if (!TryMultiplyOperator::Operation(src_ptr[row], conversion, tgt_ptr[row].value)) {
503: 			throw ConversionException("Could not convert TimestampTZ to Microsecond");
504: 		}
505: 	}
506: }
507: 
508: static void IntervalConversionUs(Vector &vector, ArrowArray &array, const ArrowScanLocalState &scan_state,
509:                                  int64_t nested_offset, int64_t parent_offset, idx_t size, int64_t conversion) {
510: 	auto tgt_ptr = FlatVector::GetData<interval_t>(vector);
511: 	auto src_ptr =
512: 	    ArrowBufferData<int64_t>(array, 1) + GetEffectiveOffset(array, parent_offset, scan_state, nested_offset);
513: 	for (idx_t row = 0; row < size; row++) {
514: 		tgt_ptr[row].days = 0;
515: 		tgt_ptr[row].months = 0;
516: 		if (!TryMultiplyOperator::Operation(src_ptr[row], conversion, tgt_ptr[row].micros)) {
517: 			throw ConversionException("Could not convert Interval to Microsecond");
518: 		}
519: 	}
520: }
521: 
522: static void IntervalConversionMonths(Vector &vector, ArrowArray &array, const ArrowScanLocalState &scan_state,
523:                                      int64_t nested_offset, int64_t parent_offset, idx_t size) {
524: 	auto tgt_ptr = FlatVector::GetData<interval_t>(vector);
525: 	auto src_ptr =
526: 	    ArrowBufferData<int32_t>(array, 1) + GetEffectiveOffset(array, parent_offset, scan_state, nested_offset);
527: 	for (idx_t row = 0; row < size; row++) {
528: 		tgt_ptr[row].days = 0;
529: 		tgt_ptr[row].micros = 0;
530: 		tgt_ptr[row].months = src_ptr[row];
531: 	}
532: }
533: 
534: static void IntervalConversionMonthDayNanos(Vector &vector, ArrowArray &array, const ArrowScanLocalState &scan_state,
535:                                             int64_t nested_offset, int64_t parent_offset, idx_t size) {
536: 	auto tgt_ptr = FlatVector::GetData<interval_t>(vector);
537: 	auto src_ptr =
538: 	    ArrowBufferData<ArrowInterval>(array, 1) + GetEffectiveOffset(array, parent_offset, scan_state, nested_offset);
539: 	for (idx_t row = 0; row < size; row++) {
540: 		tgt_ptr[row].days = src_ptr[row].days;
541: 		tgt_ptr[row].micros = src_ptr[row].nanoseconds / Interval::NANOS_PER_MICRO;
542: 		tgt_ptr[row].months = src_ptr[row].months;
543: 	}
544: }
545: 
546: // Find the index of the first run-end that is strictly greater than the offset.
547: // count is returned if no such run-end is found.
548: template <class RUN_END_TYPE>
549: static idx_t FindRunIndex(const RUN_END_TYPE *run_ends, idx_t count, idx_t offset) {
550: 	// Binary-search within the [0, count) range. For example:
551: 	// [0, 0, 0, 1, 1, 2] encoded as
552: 	// run_ends: [3, 5, 6]:
553: 	// 0, 1, 2 -> 0
554: 	//    3, 4 -> 1
555: 	//       5 -> 2
556: 	// 6, 7 .. -> 3 (3 == count [not found])
557: 	idx_t begin = 0;
558: 	idx_t end = count;
559: 	while (begin < end) {
560: 		idx_t middle = (begin + end) / 2;
561: 		// begin < end implies middle < end
562: 		if (offset >= static_cast<idx_t>(run_ends[middle])) {
563: 			// keep searching in [middle + 1, end)
564: 			begin = middle + 1;
565: 		} else {
566: 			// offset < run_ends[middle], so keep searching in [begin, middle)
567: 			end = middle;
568: 		}
569: 	}
570: 	return begin;
571: }
572: 
573: template <class RUN_END_TYPE, class VALUE_TYPE>
574: static void FlattenRunEnds(Vector &result, ArrowRunEndEncodingState &run_end_encoding, idx_t compressed_size,
575:                            idx_t scan_offset, idx_t count) {
576: 	auto &runs = *run_end_encoding.run_ends;
577: 	auto &values = *run_end_encoding.values;
578: 
579: 	UnifiedVectorFormat run_end_format;
580: 	UnifiedVectorFormat value_format;
581: 	runs.ToUnifiedFormat(compressed_size, run_end_format);
582: 	values.ToUnifiedFormat(compressed_size, value_format);
583: 	auto run_ends_data = run_end_format.GetData<RUN_END_TYPE>(run_end_format);
584: 	auto values_data = value_format.GetData<VALUE_TYPE>(value_format);
585: 	auto result_data = FlatVector::GetData<VALUE_TYPE>(result);
586: 	auto &validity = FlatVector::Validity(result);
587: 
588: 	// According to the arrow spec, the 'run_ends' array is always valid
589: 	// so we will assume this is true and not check the validity map
590: 
591: 	// Now construct the result vector from the run_ends and the values
592: 
593: 	auto run = FindRunIndex(run_ends_data, compressed_size, scan_offset);
594: 	idx_t logical_index = scan_offset;
595: 	idx_t index = 0;
596: 	if (value_format.validity.AllValid()) {
597: 		// None of the compressed values are NULL
598: 		for (; run < compressed_size; ++run) {
599: 			auto run_end_index = run_end_format.sel->get_index(run);
600: 			auto value_index = value_format.sel->get_index(run);
601: 			auto &value = values_data[value_index];
602: 			auto run_end = static_cast<idx_t>(run_ends_data[run_end_index]);
603: 
604: 			D_ASSERT(run_end > (logical_index + index));
605: 			auto to_scan = run_end - (logical_index + index);
606: 			// Cap the amount to scan so we don't go over size
607: 			to_scan = MinValue<idx_t>(to_scan, (count - index));
608: 
609: 			for (idx_t i = 0; i < to_scan; i++) {
610: 				result_data[index + i] = value;
611: 			}
612: 			index += to_scan;
613: 			if (index >= count) {
614: 				if (logical_index + index >= run_end) {
615: 					// The last run was completed, forward the run index
616: 					++run;
617: 				}
618: 				break;
619: 			}
620: 		}
621: 	} else {
622: 		for (; run < compressed_size; ++run) {
623: 			auto run_end_index = run_end_format.sel->get_index(run);
624: 			auto value_index = value_format.sel->get_index(run);
625: 			auto run_end = static_cast<idx_t>(run_ends_data[run_end_index]);
626: 
627: 			D_ASSERT(run_end > (logical_index + index));
628: 			auto to_scan = run_end - (logical_index + index);
629: 			// Cap the amount to scan so we don't go over size
630: 			to_scan = MinValue<idx_t>(to_scan, (count - index));
631: 
632: 			if (value_format.validity.RowIsValidUnsafe(value_index)) {
633: 				auto &value = values_data[value_index];
634: 				for (idx_t i = 0; i < to_scan; i++) {
635: 					result_data[index + i] = value;
636: 					validity.SetValid(index + i);
637: 				}
638: 			} else {
639: 				for (idx_t i = 0; i < to_scan; i++) {
640: 					validity.SetInvalid(index + i);
641: 				}
642: 			}
643: 			index += to_scan;
644: 			if (index >= count) {
645: 				if (logical_index + index >= run_end) {
646: 					// The last run was completed, forward the run index
647: 					++run;
648: 				}
649: 				break;
650: 			}
651: 		}
652: 	}
653: }
654: 
655: template <class RUN_END_TYPE>
656: static void FlattenRunEndsSwitch(Vector &result, ArrowRunEndEncodingState &run_end_encoding, idx_t compressed_size,
657:                                  idx_t scan_offset, idx_t size) {
658: 	auto &values = *run_end_encoding.values;
659: 	auto physical_type = values.GetType().InternalType();
660: 
661: 	switch (physical_type) {
662: 	case PhysicalType::INT8:
663: 		FlattenRunEnds<RUN_END_TYPE, int8_t>(result, run_end_encoding, compressed_size, scan_offset, size);
664: 		break;
665: 	case PhysicalType::INT16:
666: 		FlattenRunEnds<RUN_END_TYPE, int16_t>(result, run_end_encoding, compressed_size, scan_offset, size);
667: 		break;
668: 	case PhysicalType::INT32:
669: 		FlattenRunEnds<RUN_END_TYPE, int32_t>(result, run_end_encoding, compressed_size, scan_offset, size);
670: 		break;
671: 	case PhysicalType::INT64:
672: 		FlattenRunEnds<RUN_END_TYPE, int64_t>(result, run_end_encoding, compressed_size, scan_offset, size);
673: 		break;
674: 	case PhysicalType::INT128:
675: 		FlattenRunEnds<RUN_END_TYPE, hugeint_t>(result, run_end_encoding, compressed_size, scan_offset, size);
676: 		break;
677: 	case PhysicalType::UINT8:
678: 		FlattenRunEnds<RUN_END_TYPE, uint8_t>(result, run_end_encoding, compressed_size, scan_offset, size);
679: 		break;
680: 	case PhysicalType::UINT16:
681: 		FlattenRunEnds<RUN_END_TYPE, uint16_t>(result, run_end_encoding, compressed_size, scan_offset, size);
682: 		break;
683: 	case PhysicalType::UINT32:
684: 		FlattenRunEnds<RUN_END_TYPE, uint32_t>(result, run_end_encoding, compressed_size, scan_offset, size);
685: 		break;
686: 	case PhysicalType::UINT64:
687: 		FlattenRunEnds<RUN_END_TYPE, uint64_t>(result, run_end_encoding, compressed_size, scan_offset, size);
688: 		break;
689: 	case PhysicalType::BOOL:
690: 		FlattenRunEnds<RUN_END_TYPE, bool>(result, run_end_encoding, compressed_size, scan_offset, size);
691: 		break;
692: 	case PhysicalType::FLOAT:
693: 		FlattenRunEnds<RUN_END_TYPE, float>(result, run_end_encoding, compressed_size, scan_offset, size);
694: 		break;
695: 	case PhysicalType::DOUBLE:
696: 		FlattenRunEnds<RUN_END_TYPE, double>(result, run_end_encoding, compressed_size, scan_offset, size);
697: 		break;
698: 	case PhysicalType::INTERVAL:
699: 		FlattenRunEnds<RUN_END_TYPE, interval_t>(result, run_end_encoding, compressed_size, scan_offset, size);
700: 		break;
701: 	case PhysicalType::VARCHAR: {
702: 		// Share the string heap, we don't need to allocate new strings, we just reference the existing ones
703: 		result.SetAuxiliary(values.GetAuxiliary());
704: 		FlattenRunEnds<RUN_END_TYPE, string_t>(result, run_end_encoding, compressed_size, scan_offset, size);
705: 		break;
706: 	}
707: 	default:
708: 		throw NotImplementedException("RunEndEncoded value type '%s' not supported yet", TypeIdToString(physical_type));
709: 	}
710: }
711: 
712: static void ColumnArrowToDuckDBRunEndEncoded(Vector &vector, const ArrowArray &array, ArrowArrayScanState &array_state,
713:                                              idx_t size, const ArrowType &arrow_type, int64_t nested_offset,
714:                                              ValidityMask *parent_mask, uint64_t parent_offset) {
715: 	// Scan the 'run_ends' array
716: 	D_ASSERT(array.n_children == 2);
717: 	auto &run_ends_array = *array.children[0];
718: 	auto &values_array = *array.children[1];
719: 
720: 	auto &struct_info = arrow_type.GetTypeInfo<ArrowStructInfo>();
721: 	auto &run_ends_type = struct_info.GetChild(0);
722: 	auto &values_type = struct_info.GetChild(1);
723: 	D_ASSERT(vector.GetType() == values_type.GetDuckType());
724: 
725: 	auto &scan_state = array_state.state;
726: 
727: 	D_ASSERT(run_ends_array.length == values_array.length);
728: 	auto compressed_size = NumericCast<idx_t>(run_ends_array.length);
729: 	// Create a vector for the run ends and the values
730: 	auto &run_end_encoding = array_state.RunEndEncoding();
731: 	if (!run_end_encoding.run_ends) {
732: 		// The run ends and values have not been scanned yet for this array
733: 		D_ASSERT(!run_end_encoding.values);
734: 		run_end_encoding.run_ends = make_uniq<Vector>(run_ends_type.GetDuckType(), compressed_size);
735: 		run_end_encoding.values = make_uniq<Vector>(values_type.GetDuckType(), compressed_size);
736: 
737: 		ColumnArrowToDuckDB(*run_end_encoding.run_ends, run_ends_array, array_state, compressed_size, run_ends_type);
738: 		auto &values = *run_end_encoding.values;
739: 		SetValidityMask(values, values_array, scan_state, compressed_size, NumericCast<int64_t>(parent_offset),
740: 		                nested_offset);
741: 		ColumnArrowToDuckDB(values, values_array, array_state, compressed_size, values_type);
742: 	}
743: 
744: 	idx_t scan_offset = GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset), scan_state, nested_offset);
745: 	auto physical_type = run_ends_type.GetDuckType().InternalType();
746: 	switch (physical_type) {
747: 	case PhysicalType::INT16:
748: 		FlattenRunEndsSwitch<int16_t>(vector, run_end_encoding, compressed_size, scan_offset, size);
749: 		break;
750: 	case PhysicalType::INT32:
751: 		FlattenRunEndsSwitch<int32_t>(vector, run_end_encoding, compressed_size, scan_offset, size);
752: 		break;
753: 	case PhysicalType::INT64:
754: 		FlattenRunEndsSwitch<int32_t>(vector, run_end_encoding, compressed_size, scan_offset, size);
755: 		break;
756: 	default:
757: 		throw NotImplementedException("Type '%s' not implemented for RunEndEncoding", TypeIdToString(physical_type));
758: 	}
759: }
760: 
761: static void ColumnArrowToDuckDB(Vector &vector, ArrowArray &array, ArrowArrayScanState &array_state, idx_t size,
762:                                 const ArrowType &arrow_type, int64_t nested_offset, ValidityMask *parent_mask,
763:                                 uint64_t parent_offset) {
764: 	auto &scan_state = array_state.state;
765: 	D_ASSERT(!array.dictionary);
766: 
767: 	switch (vector.GetType().id()) {
768: 	case LogicalTypeId::SQLNULL:
769: 		vector.Reference(Value());
770: 		break;
771: 	case LogicalTypeId::BOOLEAN: {
772: 		//! Arrow bit-packs boolean values
773: 		//! Lets first figure out where we are in the source array
774: 		auto effective_offset =
775: 		    GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset), scan_state, nested_offset);
776: 		auto src_ptr = ArrowBufferData<uint8_t>(array, 1) + effective_offset / 8;
777: 		auto tgt_ptr = (uint8_t *)FlatVector::GetData(vector);
778: 		int src_pos = 0;
779: 		idx_t cur_bit = effective_offset % 8;
780: 		for (idx_t row = 0; row < size; row++) {
781: 			if ((src_ptr[src_pos] & (1 << cur_bit)) == 0) {
782: 				tgt_ptr[row] = 0;
783: 			} else {
784: 				tgt_ptr[row] = 1;
785: 			}
786: 			cur_bit++;
787: 			if (cur_bit == 8) {
788: 				src_pos++;
789: 				cur_bit = 0;
790: 			}
791: 		}
792: 		break;
793: 	}
794: 	case LogicalTypeId::TINYINT:
795: 	case LogicalTypeId::SMALLINT:
796: 	case LogicalTypeId::INTEGER:
797: 	case LogicalTypeId::FLOAT:
798: 	case LogicalTypeId::DOUBLE:
799: 	case LogicalTypeId::UTINYINT:
800: 	case LogicalTypeId::USMALLINT:
801: 	case LogicalTypeId::UINTEGER:
802: 	case LogicalTypeId::UBIGINT:
803: 	case LogicalTypeId::BIGINT:
804: 	case LogicalTypeId::HUGEINT:
805: 	case LogicalTypeId::UHUGEINT:
806: 	case LogicalTypeId::TIMESTAMP:
807: 	case LogicalTypeId::TIMESTAMP_SEC:
808: 	case LogicalTypeId::TIMESTAMP_MS:
809: 	case LogicalTypeId::TIMESTAMP_NS:
810: 	case LogicalTypeId::TIME_TZ: {
811: 		DirectConversion(vector, array, scan_state, nested_offset, parent_offset);
812: 		break;
813: 	}
814: 	case LogicalTypeId::UUID:
815: 		UUIDConversion(vector, array, scan_state, nested_offset, NumericCast<int64_t>(parent_offset), size);
816: 		break;
817: 	case LogicalTypeId::VARCHAR: {
818: 		auto &string_info = arrow_type.GetTypeInfo<ArrowStringInfo>();
819: 		auto size_type = string_info.GetSizeType();
820: 		switch (size_type) {
821: 		case ArrowVariableSizeType::SUPER_SIZE: {
822: 			auto cdata = ArrowBufferData<char>(array, 2);
823: 			auto offsets = ArrowBufferData<uint64_t>(array, 1) +
824: 			               GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset), scan_state, nested_offset);
825: 			SetVectorString(vector, size, cdata, offsets);
826: 			break;
827: 		}
828: 		case ArrowVariableSizeType::NORMAL:
829: 		case ArrowVariableSizeType::FIXED_SIZE: {
830: 			auto cdata = ArrowBufferData<char>(array, 2);
831: 			auto offsets = ArrowBufferData<uint32_t>(array, 1) +
832: 			               GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset), scan_state, nested_offset);
833: 			SetVectorString(vector, size, cdata, offsets);
834: 			break;
835: 		}
836: 		case ArrowVariableSizeType::VIEW: {
837: 			SetVectorStringView(
838: 			    vector, size, array,
839: 			    GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset), scan_state, nested_offset));
840: 			break;
841: 		}
842: 		}
843: 		break;
844: 	}
845: 	case LogicalTypeId::DATE: {
846: 		auto &datetime_info = arrow_type.GetTypeInfo<ArrowDateTimeInfo>();
847: 		auto precision = datetime_info.GetDateTimeType();
848: 		switch (precision) {
849: 		case ArrowDateTimeType::DAYS: {
850: 			DirectConversion(vector, array, scan_state, nested_offset, parent_offset);
851: 			break;
852: 		}
853: 		case ArrowDateTimeType::MILLISECONDS: {
854: 			//! convert date from nanoseconds to days
855: 			auto src_ptr = ArrowBufferData<uint64_t>(array, 1) +
856: 			               GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset), scan_state, nested_offset);
857: 			auto tgt_ptr = FlatVector::GetData<date_t>(vector);
858: 			for (idx_t row = 0; row < size; row++) {
859: 				tgt_ptr[row] = date_t(UnsafeNumericCast<int32_t>(static_cast<int64_t>(src_ptr[row]) /
860: 				                                                 static_cast<int64_t>(1000 * 60 * 60 * 24)));
861: 			}
862: 			break;
863: 		}
864: 		default:
865: 			throw NotImplementedException("Unsupported precision for Date Type ");
866: 		}
867: 		break;
868: 	}
869: 	case LogicalTypeId::TIME: {
870: 		auto &datetime_info = arrow_type.GetTypeInfo<ArrowDateTimeInfo>();
871: 		auto precision = datetime_info.GetDateTimeType();
872: 		switch (precision) {
873: 		case ArrowDateTimeType::SECONDS: {
874: 			TimeConversion<int32_t>(vector, array, scan_state, nested_offset, NumericCast<int64_t>(parent_offset), size,
875: 			                        1000000);
876: 			break;
877: 		}
878: 		case ArrowDateTimeType::MILLISECONDS: {
879: 			TimeConversion<int32_t>(vector, array, scan_state, nested_offset, NumericCast<int64_t>(parent_offset), size,
880: 			                        1000);
881: 			break;
882: 		}
883: 		case ArrowDateTimeType::MICROSECONDS: {
884: 			TimeConversion<int64_t>(vector, array, scan_state, nested_offset, NumericCast<int64_t>(parent_offset), size,
885: 			                        1);
886: 			break;
887: 		}
888: 		case ArrowDateTimeType::NANOSECONDS: {
889: 			auto tgt_ptr = FlatVector::GetData<dtime_t>(vector);
890: 			auto src_ptr = ArrowBufferData<int64_t>(array, 1) +
891: 			               GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset), scan_state, nested_offset);
892: 			for (idx_t row = 0; row < size; row++) {
893: 				tgt_ptr[row].micros = src_ptr[row] / 1000;
894: 			}
895: 			break;
896: 		}
897: 		default:
898: 			throw NotImplementedException("Unsupported precision for Time Type ");
899: 		}
900: 		break;
901: 	}
902: 	case LogicalTypeId::TIMESTAMP_TZ: {
903: 		auto &datetime_info = arrow_type.GetTypeInfo<ArrowDateTimeInfo>();
904: 		auto precision = datetime_info.GetDateTimeType();
905: 		switch (precision) {
906: 		case ArrowDateTimeType::SECONDS: {
907: 			TimestampTZConversion(vector, array, scan_state, nested_offset, NumericCast<int64_t>(parent_offset), size,
908: 			                      1000000);
909: 			break;
910: 		}
911: 		case ArrowDateTimeType::MILLISECONDS: {
912: 			TimestampTZConversion(vector, array, scan_state, nested_offset, NumericCast<int64_t>(parent_offset), size,
913: 			                      1000);
914: 			break;
915: 		}
916: 		case ArrowDateTimeType::MICROSECONDS: {
917: 			DirectConversion(vector, array, scan_state, nested_offset, parent_offset);
918: 			break;
919: 		}
920: 		case ArrowDateTimeType::NANOSECONDS: {
921: 			auto tgt_ptr = FlatVector::GetData<timestamp_t>(vector);
922: 			auto src_ptr = ArrowBufferData<int64_t>(array, 1) +
923: 			               GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset), scan_state, nested_offset);
924: 			for (idx_t row = 0; row < size; row++) {
925: 				tgt_ptr[row].value = src_ptr[row] / 1000;
926: 			}
927: 			break;
928: 		}
929: 		default:
930: 			throw NotImplementedException("Unsupported precision for TimestampTZ Type ");
931: 		}
932: 		break;
933: 	}
934: 	case LogicalTypeId::INTERVAL: {
935: 		auto &datetime_info = arrow_type.GetTypeInfo<ArrowDateTimeInfo>();
936: 		auto precision = datetime_info.GetDateTimeType();
937: 		switch (precision) {
938: 		case ArrowDateTimeType::SECONDS: {
939: 			IntervalConversionUs(vector, array, scan_state, nested_offset, NumericCast<int64_t>(parent_offset), size,
940: 			                     1000000);
941: 			break;
942: 		}
943: 		case ArrowDateTimeType::DAYS:
944: 		case ArrowDateTimeType::MILLISECONDS: {
945: 			IntervalConversionUs(vector, array, scan_state, nested_offset, NumericCast<int64_t>(parent_offset), size,
946: 			                     1000);
947: 			break;
948: 		}
949: 		case ArrowDateTimeType::MICROSECONDS: {
950: 			IntervalConversionUs(vector, array, scan_state, nested_offset, NumericCast<int64_t>(parent_offset), size,
951: 			                     1);
952: 			break;
953: 		}
954: 		case ArrowDateTimeType::NANOSECONDS: {
955: 			auto tgt_ptr = FlatVector::GetData<interval_t>(vector);
956: 			auto src_ptr = ArrowBufferData<int64_t>(array, 1) +
957: 			               GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset), scan_state, nested_offset);
958: 			for (idx_t row = 0; row < size; row++) {
959: 				tgt_ptr[row].micros = src_ptr[row] / 1000;
960: 				tgt_ptr[row].days = 0;
961: 				tgt_ptr[row].months = 0;
962: 			}
963: 			break;
964: 		}
965: 		case ArrowDateTimeType::MONTHS: {
966: 			IntervalConversionMonths(vector, array, scan_state, nested_offset, NumericCast<int64_t>(parent_offset),
967: 			                         size);
968: 			break;
969: 		}
970: 		case ArrowDateTimeType::MONTH_DAY_NANO: {
971: 			IntervalConversionMonthDayNanos(vector, array, scan_state, nested_offset,
972: 			                                NumericCast<int64_t>(parent_offset), size);
973: 			break;
974: 		}
975: 		default:
976: 			throw NotImplementedException("Unsupported precision for Interval/Duration Type ");
977: 		}
978: 		break;
979: 	}
980: 	case LogicalTypeId::DECIMAL: {
981: 		auto val_mask = FlatVector::Validity(vector);
982: 		//! We have to convert from INT128
983: 		auto src_ptr = ArrowBufferData<hugeint_t>(array, 1) +
984: 		               GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset), scan_state, nested_offset);
985: 		switch (vector.GetType().InternalType()) {
986: 		case PhysicalType::INT16: {
987: 			auto tgt_ptr = FlatVector::GetData<int16_t>(vector);
988: 			for (idx_t row = 0; row < size; row++) {
989: 				if (val_mask.RowIsValid(row)) {
990: 					auto result = Hugeint::TryCast(src_ptr[row], tgt_ptr[row]);
991: 					D_ASSERT(result);
992: 					(void)result;
993: 				}
994: 			}
995: 			break;
996: 		}
997: 		case PhysicalType::INT32: {
998: 			auto tgt_ptr = FlatVector::GetData<int32_t>(vector);
999: 			for (idx_t row = 0; row < size; row++) {
1000: 				if (val_mask.RowIsValid(row)) {
1001: 					auto result = Hugeint::TryCast(src_ptr[row], tgt_ptr[row]);
1002: 					D_ASSERT(result);
1003: 					(void)result;
1004: 				}
1005: 			}
1006: 			break;
1007: 		}
1008: 		case PhysicalType::INT64: {
1009: 			auto tgt_ptr = FlatVector::GetData<int64_t>(vector);
1010: 			for (idx_t row = 0; row < size; row++) {
1011: 				if (val_mask.RowIsValid(row)) {
1012: 					auto result = Hugeint::TryCast(src_ptr[row], tgt_ptr[row]);
1013: 					D_ASSERT(result);
1014: 					(void)result;
1015: 				}
1016: 			}
1017: 			break;
1018: 		}
1019: 		case PhysicalType::INT128: {
1020: 			FlatVector::SetData(vector, ArrowBufferData<data_t>(array, 1) +
1021: 			                                GetTypeIdSize(vector.GetType().InternalType()) *
1022: 			                                    GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset),
1023: 			                                                       scan_state, nested_offset));
1024: 			break;
1025: 		}
1026: 		default:
1027: 			throw NotImplementedException("Unsupported physical type for Decimal: %s",
1028: 			                              TypeIdToString(vector.GetType().InternalType()));
1029: 		}
1030: 		break;
1031: 	}
1032: 	case LogicalTypeId::BLOB:
1033: 	case LogicalTypeId::BIT:
1034: 	case LogicalTypeId::VARINT: {
1035: 		ArrowToDuckDBBlob(vector, array, scan_state, size, arrow_type, nested_offset,
1036: 		                  NumericCast<int64_t>(parent_offset));
1037: 		break;
1038: 	}
1039: 	case LogicalTypeId::LIST: {
1040: 		ArrowToDuckDBList(vector, array, array_state, size, arrow_type, nested_offset, parent_mask,
1041: 		                  NumericCast<int64_t>(parent_offset));
1042: 		break;
1043: 	}
1044: 	case LogicalTypeId::ARRAY: {
1045: 		ArrowToDuckDBArray(vector, array, array_state, size, arrow_type, nested_offset, parent_mask,
1046: 		                   NumericCast<int64_t>(parent_offset));
1047: 		break;
1048: 	}
1049: 	case LogicalTypeId::MAP: {
1050: 		ArrowToDuckDBList(vector, array, array_state, size, arrow_type, nested_offset, parent_mask,
1051: 		                  NumericCast<int64_t>(parent_offset));
1052: 		ArrowToDuckDBMapVerify(vector, size);
1053: 		break;
1054: 	}
1055: 	case LogicalTypeId::STRUCT: {
1056: 		//! Fill the children
1057: 		auto &struct_info = arrow_type.GetTypeInfo<ArrowStructInfo>();
1058: 		auto &child_entries = StructVector::GetEntries(vector);
1059: 		auto &struct_validity_mask = FlatVector::Validity(vector);
1060: 		for (idx_t child_idx = 0; child_idx < NumericCast<idx_t>(array.n_children); child_idx++) {
1061: 			auto &child_entry = *child_entries[child_idx];
1062: 			auto &child_array = *array.children[child_idx];
1063: 			auto &child_type = struct_info.GetChild(child_idx);
1064: 			auto &child_state = array_state.GetChild(child_idx);
1065: 
1066: 			SetValidityMask(child_entry, child_array, scan_state, size, array.offset, nested_offset);
1067: 			if (!struct_validity_mask.AllValid()) {
1068: 				auto &child_validity_mark = FlatVector::Validity(child_entry);
1069: 				for (idx_t i = 0; i < size; i++) {
1070: 					if (!struct_validity_mask.RowIsValid(i)) {
1071: 						child_validity_mark.SetInvalid(i);
1072: 					}
1073: 				}
1074: 			}
1075: 
1076: 			auto array_physical_type = GetArrowArrayPhysicalType(child_type);
1077: 			switch (array_physical_type) {
1078: 			case ArrowArrayPhysicalType::DICTIONARY_ENCODED:
1079: 				ColumnArrowToDuckDBDictionary(child_entry, child_array, child_state, size, child_type, nested_offset,
1080: 				                              &struct_validity_mask, NumericCast<uint64_t>(array.offset));
1081: 				break;
1082: 			case ArrowArrayPhysicalType::RUN_END_ENCODED:
1083: 				ColumnArrowToDuckDBRunEndEncoded(child_entry, child_array, child_state, size, child_type, nested_offset,
1084: 				                                 &struct_validity_mask, NumericCast<uint64_t>(array.offset));
1085: 				break;
1086: 			case ArrowArrayPhysicalType::DEFAULT:
1087: 				ColumnArrowToDuckDB(child_entry, child_array, child_state, size, child_type, nested_offset,
1088: 				                    &struct_validity_mask, NumericCast<uint64_t>(array.offset));
1089: 				break;
1090: 			default:
1091: 				throw NotImplementedException("ArrowArrayPhysicalType not recognized");
1092: 			}
1093: 		}
1094: 		break;
1095: 	}
1096: 	case LogicalTypeId::UNION: {
1097: 		auto type_ids = ArrowBufferData<int8_t>(array, array.n_buffers == 1 ? 0 : 1);
1098: 		D_ASSERT(type_ids);
1099: 		auto members = UnionType::CopyMemberTypes(vector.GetType());
1100: 
1101: 		auto &validity_mask = FlatVector::Validity(vector);
1102: 		auto &union_info = arrow_type.GetTypeInfo<ArrowStructInfo>();
1103: 		duckdb::vector<Vector> children;
1104: 		for (idx_t child_idx = 0; child_idx < NumericCast<idx_t>(array.n_children); child_idx++) {
1105: 			Vector child(members[child_idx].second, size);
1106: 			auto &child_array = *array.children[child_idx];
1107: 			auto &child_state = array_state.GetChild(child_idx);
1108: 			auto &child_type = union_info.GetChild(child_idx);
1109: 
1110: 			SetValidityMask(child, child_array, scan_state, size, NumericCast<int64_t>(parent_offset), nested_offset);
1111: 			auto array_physical_type = GetArrowArrayPhysicalType(child_type);
1112: 
1113: 			switch (array_physical_type) {
1114: 			case ArrowArrayPhysicalType::DICTIONARY_ENCODED:
1115: 				ColumnArrowToDuckDBDictionary(child, child_array, child_state, size, child_type);
1116: 				break;
1117: 			case ArrowArrayPhysicalType::RUN_END_ENCODED:
1118: 				ColumnArrowToDuckDBRunEndEncoded(child, child_array, child_state, size, child_type);
1119: 				break;
1120: 			case ArrowArrayPhysicalType::DEFAULT:
1121: 				ColumnArrowToDuckDB(child, child_array, child_state, size, child_type, nested_offset, &validity_mask);
1122: 				break;
1123: 			default:
1124: 				throw NotImplementedException("ArrowArrayPhysicalType not recognized");
1125: 			}
1126: 
1127: 			children.push_back(std::move(child));
1128: 		}
1129: 
1130: 		for (idx_t row_idx = 0; row_idx < size; row_idx++) {
1131: 			auto tag = NumericCast<uint8_t>(type_ids[row_idx]);
1132: 
1133: 			auto out_of_range = tag >= array.n_children;
1134: 			if (out_of_range) {
1135: 				throw InvalidInputException("Arrow union tag out of range: %d", tag);
1136: 			}
1137: 
1138: 			const Value &value = children[tag].GetValue(row_idx);
1139: 			vector.SetValue(row_idx, value.IsNull() ? Value() : Value::UNION(members, tag, value));
1140: 		}
1141: 
1142: 		break;
1143: 	}
1144: 	default:
1145: 		throw NotImplementedException("Unsupported type for arrow conversion: %s", vector.GetType().ToString());
1146: 	}
1147: }
1148: 
1149: template <class T>
1150: static void SetSelectionVectorLoop(SelectionVector &sel, data_ptr_t indices_p, idx_t size) {
1151: 	auto indices = reinterpret_cast<T *>(indices_p);
1152: 	for (idx_t row = 0; row < size; row++) {
1153: 		sel.set_index(row, UnsafeNumericCast<idx_t>(indices[row]));
1154: 	}
1155: }
1156: 
1157: template <class T>
1158: static void SetSelectionVectorLoopWithChecks(SelectionVector &sel, data_ptr_t indices_p, idx_t size) {
1159: 
1160: 	auto indices = reinterpret_cast<T *>(indices_p);
1161: 	for (idx_t row = 0; row < size; row++) {
1162: 		if (indices[row] > NumericLimits<uint32_t>::Maximum()) {
1163: 			throw ConversionException("DuckDB only supports indices that fit on an uint32");
1164: 		}
1165: 		sel.set_index(row, NumericCast<idx_t>(indices[row]));
1166: 	}
1167: }
1168: 
1169: template <class T>
1170: static void SetMaskedSelectionVectorLoop(SelectionVector &sel, data_ptr_t indices_p, idx_t size, ValidityMask &mask,
1171:                                          idx_t last_element_pos) {
1172: 	auto indices = reinterpret_cast<T *>(indices_p);
1173: 	for (idx_t row = 0; row < size; row++) {
1174: 		if (mask.RowIsValid(row)) {
1175: 			sel.set_index(row, UnsafeNumericCast<idx_t>(indices[row]));
1176: 		} else {
1177: 			//! Need to point out to last element
1178: 			sel.set_index(row, last_element_pos);
1179: 		}
1180: 	}
1181: }
1182: 
1183: static void SetSelectionVector(SelectionVector &sel, data_ptr_t indices_p, const LogicalType &logical_type, idx_t size,
1184:                                ValidityMask *mask = nullptr, idx_t last_element_pos = 0) {
1185: 	sel.Initialize(size);
1186: 
1187: 	if (mask) {
1188: 		switch (logical_type.id()) {
1189: 		case LogicalTypeId::UTINYINT:
1190: 			SetMaskedSelectionVectorLoop<uint8_t>(sel, indices_p, size, *mask, last_element_pos);
1191: 			break;
1192: 		case LogicalTypeId::TINYINT:
1193: 			SetMaskedSelectionVectorLoop<int8_t>(sel, indices_p, size, *mask, last_element_pos);
1194: 			break;
1195: 		case LogicalTypeId::USMALLINT:
1196: 			SetMaskedSelectionVectorLoop<uint16_t>(sel, indices_p, size, *mask, last_element_pos);
1197: 			break;
1198: 		case LogicalTypeId::SMALLINT:
1199: 			SetMaskedSelectionVectorLoop<int16_t>(sel, indices_p, size, *mask, last_element_pos);
1200: 			break;
1201: 		case LogicalTypeId::UINTEGER:
1202: 			if (last_element_pos > NumericLimits<uint32_t>::Maximum()) {
1203: 				//! Its guaranteed that our indices will point to the last element, so just throw an error
1204: 				throw ConversionException("DuckDB only supports indices that fit on an uint32");
1205: 			}
1206: 			SetMaskedSelectionVectorLoop<uint32_t>(sel, indices_p, size, *mask, last_element_pos);
1207: 			break;
1208: 		case LogicalTypeId::INTEGER:
1209: 			SetMaskedSelectionVectorLoop<int32_t>(sel, indices_p, size, *mask, last_element_pos);
1210: 			break;
1211: 		case LogicalTypeId::UBIGINT:
1212: 			if (last_element_pos > NumericLimits<uint32_t>::Maximum()) {
1213: 				//! Its guaranteed that our indices will point to the last element, so just throw an error
1214: 				throw ConversionException("DuckDB only supports indices that fit on an uint32");
1215: 			}
1216: 			SetMaskedSelectionVectorLoop<uint64_t>(sel, indices_p, size, *mask, last_element_pos);
1217: 			break;
1218: 		case LogicalTypeId::BIGINT:
1219: 			if (last_element_pos > NumericLimits<uint32_t>::Maximum()) {
1220: 				//! Its guaranteed that our indices will point to the last element, so just throw an error
1221: 				throw ConversionException("DuckDB only supports indices that fit on an uint32");
1222: 			}
1223: 			SetMaskedSelectionVectorLoop<int64_t>(sel, indices_p, size, *mask, last_element_pos);
1224: 			break;
1225: 
1226: 		default:
1227: 			throw NotImplementedException("(Arrow) Unsupported type for selection vectors %s", logical_type.ToString());
1228: 		}
1229: 
1230: 	} else {
1231: 		switch (logical_type.id()) {
1232: 		case LogicalTypeId::UTINYINT:
1233: 			SetSelectionVectorLoop<uint8_t>(sel, indices_p, size);
1234: 			break;
1235: 		case LogicalTypeId::TINYINT:
1236: 			SetSelectionVectorLoop<int8_t>(sel, indices_p, size);
1237: 			break;
1238: 		case LogicalTypeId::USMALLINT:
1239: 			SetSelectionVectorLoop<uint16_t>(sel, indices_p, size);
1240: 			break;
1241: 		case LogicalTypeId::SMALLINT:
1242: 			SetSelectionVectorLoop<int16_t>(sel, indices_p, size);
1243: 			break;
1244: 		case LogicalTypeId::UINTEGER:
1245: 			SetSelectionVectorLoop<uint32_t>(sel, indices_p, size);
1246: 			break;
1247: 		case LogicalTypeId::INTEGER:
1248: 			SetSelectionVectorLoop<int32_t>(sel, indices_p, size);
1249: 			break;
1250: 		case LogicalTypeId::UBIGINT:
1251: 			if (last_element_pos > NumericLimits<uint32_t>::Maximum()) {
1252: 				//! We need to check if our indexes fit in a uint32_t
1253: 				SetSelectionVectorLoopWithChecks<uint64_t>(sel, indices_p, size);
1254: 			} else {
1255: 				SetSelectionVectorLoop<uint64_t>(sel, indices_p, size);
1256: 			}
1257: 			break;
1258: 		case LogicalTypeId::BIGINT:
1259: 			if (last_element_pos > NumericLimits<uint32_t>::Maximum()) {
1260: 				//! We need to check if our indexes fit in a uint32_t
1261: 				SetSelectionVectorLoopWithChecks<int64_t>(sel, indices_p, size);
1262: 			} else {
1263: 				SetSelectionVectorLoop<int64_t>(sel, indices_p, size);
1264: 			}
1265: 			break;
1266: 		default:
1267: 			throw ConversionException("(Arrow) Unsupported type for selection vectors %s", logical_type.ToString());
1268: 		}
1269: 	}
1270: }
1271: 
1272: static bool CanContainNull(const ArrowArray &array, const ValidityMask *parent_mask) {
1273: 	if (array.null_count > 0) {
1274: 		return true;
1275: 	}
1276: 	if (!parent_mask) {
1277: 		return false;
1278: 	}
1279: 	return !parent_mask->AllValid();
1280: }
1281: 
1282: static void ColumnArrowToDuckDBDictionary(Vector &vector, ArrowArray &array, ArrowArrayScanState &array_state,
1283:                                           idx_t size, const ArrowType &arrow_type, int64_t nested_offset,
1284:                                           const ValidityMask *parent_mask, uint64_t parent_offset) {
1285: 	D_ASSERT(arrow_type.HasDictionary());
1286: 	auto &scan_state = array_state.state;
1287: 	const bool has_nulls = CanContainNull(array, parent_mask);
1288: 	if (array_state.CacheOutdated(array.dictionary)) {
1289: 		//! We need to set the dictionary data for this column
1290: 		auto base_vector = make_uniq<Vector>(vector.GetType(), NumericCast<idx_t>(array.dictionary->length));
1291: 		SetValidityMask(*base_vector, *array.dictionary, scan_state, NumericCast<idx_t>(array.dictionary->length), 0, 0,
1292: 		                has_nulls);
1293: 		auto &dictionary_type = arrow_type.GetDictionary();
1294: 		auto arrow_physical_type = GetArrowArrayPhysicalType(dictionary_type);
1295: 		switch (arrow_physical_type) {
1296: 		case ArrowArrayPhysicalType::DICTIONARY_ENCODED:
1297: 			ColumnArrowToDuckDBDictionary(*base_vector, *array.dictionary, array_state,
1298: 			                              NumericCast<idx_t>(array.dictionary->length), dictionary_type);
1299: 			break;
1300: 		case ArrowArrayPhysicalType::RUN_END_ENCODED:
1301: 			ColumnArrowToDuckDBRunEndEncoded(*base_vector, *array.dictionary, array_state,
1302: 			                                 NumericCast<idx_t>(array.dictionary->length), dictionary_type);
1303: 			break;
1304: 		case ArrowArrayPhysicalType::DEFAULT:
1305: 			ColumnArrowToDuckDB(*base_vector, *array.dictionary, array_state,
1306: 			                    NumericCast<idx_t>(array.dictionary->length), dictionary_type);
1307: 			break;
1308: 		default:
1309: 			throw NotImplementedException("ArrowArrayPhysicalType not recognized");
1310: 		};
1311: 		array_state.AddDictionary(std::move(base_vector), array.dictionary);
1312: 	}
1313: 	auto offset_type = arrow_type.GetDuckType();
1314: 	//! Get Pointer to Indices of Dictionary
1315: 	auto indices = ArrowBufferData<data_t>(array, 1) +
1316: 	               GetTypeIdSize(offset_type.InternalType()) *
1317: 	                   GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset), scan_state, nested_offset);
1318: 
1319: 	SelectionVector sel;
1320: 	if (has_nulls) {
1321: 		ValidityMask indices_validity;
1322: 		GetValidityMask(indices_validity, array, scan_state, size, NumericCast<int64_t>(parent_offset));
1323: 		if (parent_mask && !parent_mask->AllValid()) {
1324: 			auto &struct_validity_mask = *parent_mask;
1325: 			for (idx_t i = 0; i < size; i++) {
1326: 				if (!struct_validity_mask.RowIsValid(i)) {
1327: 					indices_validity.SetInvalid(i);
1328: 				}
1329: 			}
1330: 		}
1331: 		SetSelectionVector(sel, indices, offset_type, size, &indices_validity,
1332: 		                   NumericCast<idx_t>(array.dictionary->length));
1333: 	} else {
1334: 		SetSelectionVector(sel, indices, offset_type, size);
1335: 	}
1336: 	vector.Slice(array_state.GetDictionary(), sel, size);
1337: 	vector.Verify(size);
1338: }
1339: 
1340: void ArrowTableFunction::ArrowToDuckDB(ArrowScanLocalState &scan_state, const arrow_column_map_t &arrow_convert_data,
1341:                                        DataChunk &output, idx_t start, bool arrow_scan_is_projected) {
1342: 	for (idx_t idx = 0; idx < output.ColumnCount(); idx++) {
1343: 		auto col_idx = scan_state.column_ids[idx];
1344: 
1345: 		// If projection was not pushed down into the arrow scanner, but projection pushdown is enabled on the
1346: 		// table function, we need to use original column ids here.
1347: 		auto arrow_array_idx = arrow_scan_is_projected ? idx : col_idx;
1348: 
1349: 		if (col_idx == COLUMN_IDENTIFIER_ROW_ID) {
1350: 			// This column is skipped by the projection pushdown
1351: 			continue;
1352: 		}
1353: 
1354: 		auto &parent_array = scan_state.chunk->arrow_array;
1355: 		auto &array = *scan_state.chunk->arrow_array.children[arrow_array_idx];
1356: 		if (!array.release) {
1357: 			throw InvalidInputException("arrow_scan: released array passed");
1358: 		}
1359: 		if (array.length != scan_state.chunk->arrow_array.length) {
1360: 			throw InvalidInputException("arrow_scan: array length mismatch");
1361: 		}
1362: 
1363: 		D_ASSERT(arrow_convert_data.find(col_idx) != arrow_convert_data.end());
1364: 		auto &arrow_type = *arrow_convert_data.at(col_idx);
1365: 		auto &array_state = scan_state.GetState(col_idx);
1366: 
1367: 		// Make sure this Vector keeps the Arrow chunk alive in case we can zero-copy the data
1368: 		if (!array_state.owned_data) {
1369: 			array_state.owned_data = scan_state.chunk;
1370: 		}
1371: 		output.data[idx].GetBuffer()->SetAuxiliaryData(make_uniq<ArrowAuxiliaryData>(array_state.owned_data));
1372: 
1373: 		auto array_physical_type = GetArrowArrayPhysicalType(arrow_type);
1374: 
1375: 		switch (array_physical_type) {
1376: 		case ArrowArrayPhysicalType::DICTIONARY_ENCODED:
1377: 			ColumnArrowToDuckDBDictionary(output.data[idx], array, array_state, output.size(), arrow_type);
1378: 			break;
1379: 		case ArrowArrayPhysicalType::RUN_END_ENCODED:
1380: 			ColumnArrowToDuckDBRunEndEncoded(output.data[idx], array, array_state, output.size(), arrow_type);
1381: 			break;
1382: 		case ArrowArrayPhysicalType::DEFAULT:
1383: 			SetValidityMask(output.data[idx], array, scan_state, output.size(), parent_array.offset, -1);
1384: 			ColumnArrowToDuckDB(output.data[idx], array, array_state, output.size(), arrow_type);
1385: 			break;
1386: 		default:
1387: 			throw NotImplementedException("ArrowArrayPhysicalType not recognized");
1388: 		}
1389: 	}
1390: }
1391: 
1392: } // namespace duckdb
[end of src/function/table/arrow_conversion.cpp]
[start of src/include/duckdb/function/table/arrow.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/function/table/arrow.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/function/table_function.hpp"
12: #include "duckdb/common/arrow/arrow_wrapper.hpp"
13: #include "duckdb/common/atomic.hpp"
14: #include "duckdb/common/mutex.hpp"
15: #include "duckdb/common/pair.hpp"
16: #include "duckdb/common/thread.hpp"
17: #include "duckdb/common/unordered_map.hpp"
18: #include "duckdb/function/built_in_functions.hpp"
19: #include "duckdb/function/table/arrow/arrow_duck_schema.hpp"
20: 
21: namespace duckdb {
22: 
23: struct ArrowInterval {
24: 	int32_t months;
25: 	int32_t days;
26: 	int64_t nanoseconds;
27: 
28: 	inline bool operator==(const ArrowInterval &rhs) const {
29: 		return this->days == rhs.days && this->months == rhs.months && this->nanoseconds == rhs.nanoseconds;
30: 	}
31: };
32: 
33: struct ArrowProjectedColumns {
34: 	unordered_map<idx_t, string> projection_map;
35: 	vector<string> columns;
36: 	// Map from filter index to column index
37: 	unordered_map<idx_t, idx_t> filter_to_col;
38: };
39: 
40: struct ArrowStreamParameters {
41: 	ArrowProjectedColumns projected_columns;
42: 	TableFilterSet *filters;
43: };
44: 
45: typedef unique_ptr<ArrowArrayStreamWrapper> (*stream_factory_produce_t)(uintptr_t stream_factory_ptr,
46:                                                                         ArrowStreamParameters &parameters);
47: typedef void (*stream_factory_get_schema_t)(ArrowArrayStream *stream_factory_ptr, ArrowSchema &schema);
48: 
49: struct ArrowScanFunctionData : public TableFunctionData {
50: public:
51: 	ArrowScanFunctionData(stream_factory_produce_t scanner_producer_p, uintptr_t stream_factory_ptr_p,
52: 	                      shared_ptr<DependencyItem> dependency = nullptr)
53: 	    : lines_read(0), stream_factory_ptr(stream_factory_ptr_p), scanner_producer(scanner_producer_p),
54: 	      dependency(std::move(dependency)) {
55: 	}
56: 	vector<LogicalType> all_types;
57: 	atomic<idx_t> lines_read;
58: 	ArrowSchemaWrapper schema_root;
59: 	idx_t rows_per_thread;
60: 	//! Pointer to the scanner factory
61: 	uintptr_t stream_factory_ptr;
62: 	//! Pointer to the scanner factory produce
63: 	stream_factory_produce_t scanner_producer;
64: 	//! The (optional) dependency of this function (used in Python for example)
65: 	shared_ptr<DependencyItem> dependency;
66: 	//! Arrow table data
67: 	ArrowTableType arrow_table;
68: };
69: 
70: struct ArrowRunEndEncodingState {
71: public:
72: 	ArrowRunEndEncodingState() {
73: 	}
74: 
75: public:
76: 	unique_ptr<Vector> run_ends;
77: 	unique_ptr<Vector> values;
78: 
79: public:
80: 	void Reset() {
81: 		run_ends.reset();
82: 		values.reset();
83: 	}
84: };
85: 
86: struct ArrowScanLocalState;
87: struct ArrowArrayScanState {
88: public:
89: 	explicit ArrowArrayScanState(ArrowScanLocalState &state);
90: 
91: public:
92: 	ArrowScanLocalState &state;
93: 	// Hold ownership over the Arrow Arrays owned by DuckDB to allow for zero-copy
94: 	shared_ptr<ArrowArrayWrapper> owned_data;
95: 	unordered_map<idx_t, unique_ptr<ArrowArrayScanState>> children;
96: 	// Optionally holds the pointer that was used to create the cached dictionary
97: 	optional_ptr<ArrowArray> arrow_dictionary = nullptr;
98: 	// Cache the (optional) dictionary of this array
99: 	unique_ptr<Vector> dictionary;
100: 	//! Run-end-encoding state
101: 	ArrowRunEndEncodingState run_end_encoding;
102: 
103: public:
104: 	ArrowArrayScanState &GetChild(idx_t child_idx);
105: 	void AddDictionary(unique_ptr<Vector> dictionary_p, ArrowArray *arrow_dict);
106: 	bool HasDictionary() const;
107: 	bool CacheOutdated(ArrowArray *dictionary) const;
108: 	Vector &GetDictionary();
109: 	ArrowRunEndEncodingState &RunEndEncoding() {
110: 		return run_end_encoding;
111: 	}
112: 
113: public:
114: 	void Reset() {
115: 		// Note: dictionary is not reset
116: 		// the dictionary should be the same for every array scanned of this column
117: 		run_end_encoding.Reset();
118: 		for (auto &child : children) {
119: 			child.second->Reset();
120: 		}
121: 		owned_data.reset();
122: 	}
123: };
124: 
125: struct ArrowScanLocalState : public LocalTableFunctionState {
126: public:
127: 	explicit ArrowScanLocalState(unique_ptr<ArrowArrayWrapper> current_chunk) : chunk(current_chunk.release()) {
128: 	}
129: 
130: public:
131: 	unique_ptr<ArrowArrayStreamWrapper> stream;
132: 	shared_ptr<ArrowArrayWrapper> chunk;
133: 	idx_t chunk_offset = 0;
134: 	idx_t batch_index = 0;
135: 	vector<column_t> column_ids;
136: 	unordered_map<idx_t, unique_ptr<ArrowArrayScanState>> array_states;
137: 	TableFilterSet *filters = nullptr;
138: 	//! The DataChunk containing all read columns (even filter columns that are immediately removed)
139: 	DataChunk all_columns;
140: 
141: public:
142: 	void Reset() {
143: 		chunk_offset = 0;
144: 		for (auto &col : array_states) {
145: 			col.second->Reset();
146: 		}
147: 	}
148: 	ArrowArrayScanState &GetState(idx_t child_idx) {
149: 		auto it = array_states.find(child_idx);
150: 		if (it == array_states.end()) {
151: 			auto child_p = make_uniq<ArrowArrayScanState>(*this);
152: 			auto &child = *child_p;
153: 			array_states.emplace(child_idx, std::move(child_p));
154: 			return child;
155: 		}
156: 		return *it->second;
157: 	}
158: };
159: 
160: struct ArrowScanGlobalState : public GlobalTableFunctionState {
161: 	unique_ptr<ArrowArrayStreamWrapper> stream;
162: 	mutex main_mutex;
163: 	idx_t max_threads = 1;
164: 	idx_t batch_index = 0;
165: 	bool done = false;
166: 
167: 	vector<idx_t> projection_ids;
168: 	vector<LogicalType> scanned_types;
169: 
170: 	idx_t MaxThreads() const override {
171: 		return max_threads;
172: 	}
173: 
174: 	bool CanRemoveFilterColumns() const {
175: 		return !projection_ids.empty();
176: 	}
177: };
178: 
179: struct ArrowTableFunction {
180: public:
181: 	static void RegisterFunction(BuiltinFunctions &set);
182: 
183: public:
184: 	//! Binds an arrow table
185: 	static unique_ptr<FunctionData> ArrowScanBind(ClientContext &context, TableFunctionBindInput &input,
186: 	                                              vector<LogicalType> &return_types, vector<string> &names);
187: 	//! Actual conversion from Arrow to DuckDB
188: 	static void ArrowToDuckDB(ArrowScanLocalState &scan_state, const arrow_column_map_t &arrow_convert_data,
189: 	                          DataChunk &output, idx_t start, bool arrow_scan_is_projected = true);
190: 
191: 	//! Get next scan state
192: 	static bool ArrowScanParallelStateNext(ClientContext &context, const FunctionData *bind_data_p,
193: 	                                       ArrowScanLocalState &state, ArrowScanGlobalState &parallel_state);
194: 
195: 	//! Initialize Global State
196: 	static unique_ptr<GlobalTableFunctionState> ArrowScanInitGlobal(ClientContext &context,
197: 	                                                                TableFunctionInitInput &input);
198: 
199: 	//! Initialize Local State
200: 	static unique_ptr<LocalTableFunctionState> ArrowScanInitLocalInternal(ClientContext &context,
201: 	                                                                      TableFunctionInitInput &input,
202: 	                                                                      GlobalTableFunctionState *global_state);
203: 	static unique_ptr<LocalTableFunctionState> ArrowScanInitLocal(ExecutionContext &context,
204: 	                                                              TableFunctionInitInput &input,
205: 	                                                              GlobalTableFunctionState *global_state);
206: 
207: 	//! Scan Function
208: 	static void ArrowScanFunction(ClientContext &context, TableFunctionInput &data, DataChunk &output);
209: 	static void PopulateArrowTableType(ArrowTableType &arrow_table, ArrowSchemaWrapper &schema_p, vector<string> &names,
210: 	                                   vector<LogicalType> &return_types);
211: 
212: protected:
213: 	//! Defines Maximum Number of Threads
214: 	static idx_t ArrowScanMaxThreads(ClientContext &context, const FunctionData *bind_data);
215: 
216: 	//! Allows parallel Create Table / Insertion
217: 	static OperatorPartitionData ArrowGetPartitionData(ClientContext &context, TableFunctionGetPartitionInput &input);
218: 
219: 	//! Specify if a given type can be pushed-down by the arrow engine
220: 	static bool ArrowPushdownType(const LogicalType &type);
221: 	//! -----Utility Functions:-----
222: 	//! Gets Arrow Table's Cardinality
223: 	static unique_ptr<NodeStatistics> ArrowScanCardinality(ClientContext &context, const FunctionData *bind_data);
224: 	//! Gets the progress on the table scan, used for Progress Bars
225: 	static double ArrowProgress(ClientContext &context, const FunctionData *bind_data,
226: 	                            const GlobalTableFunctionState *global_state);
227: 
228: public:
229: 	//! Helper function to get the DuckDB logical type
230: 	static unique_ptr<ArrowType> GetArrowLogicalType(ArrowSchema &schema);
231: };
232: 
233: } // namespace duckdb
[end of src/include/duckdb/function/table/arrow.hpp]
[start of tools/pythonpkg/duckdb_extension_config.cmake]
1: ################################################################################
2: # Python DuckDB extension config
3: ################################################################################
4: #
5: # This is the default extension configuration for Python builds. Basically it means that all these extensions are
6: # "baked in" to the python binaries. Note that the configuration here is only when building Python using the main
7: # CMakeLists.txt file with the `BUILD_PYTHON` variable.
8: # TODO: unify this by making setup.py also use this configuration, making this the config for all python builds
9: duckdb_extension_load(json)
10: duckdb_extension_load(fts)
11: duckdb_extension_load(tpcds)
12: duckdb_extension_load(tpch)
13: duckdb_extension_load(parquet)
14: duckdb_extension_load(icu)
[end of tools/pythonpkg/duckdb_extension_config.cmake]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: