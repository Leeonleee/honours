{
  "repo": "duckdb/duckdb",
  "pull_number": 13283,
  "instance_id": "duckdb__duckdb-13283",
  "issue_numbers": [
    "13272",
    "13272"
  ],
  "base_commit": "f7e8437d10bc694f69785d692688a7a67fe5fd48",
  "patch": "diff --git a/extension/parquet/parquet_statistics.cpp b/extension/parquet/parquet_statistics.cpp\nindex 60383b5c99ff..26896c5769e9 100644\n--- a/extension/parquet/parquet_statistics.cpp\n+++ b/extension/parquet/parquet_statistics.cpp\n@@ -188,7 +188,9 @@ Value ParquetStatisticsUtils::ConvertValue(const LogicalType &type,\n \t}\n \tcase LogicalTypeId::TIME_TZ: {\n \t\tint64_t val;\n-\t\tif (stats.size() == sizeof(int64_t)) {\n+\t\tif (stats.size() == sizeof(int32_t)) {\n+\t\t\tval = Load<int32_t>(stats_data);\n+\t\t} else if (stats.size() == sizeof(int64_t)) {\n \t\t\tval = Load<int64_t>(stats_data);\n \t\t} else {\n \t\t\tthrow InternalException(\"Incorrect stats size for type TIMETZ\");\n",
  "test_patch": "diff --git a/data/parquet-testing/timetz_4byte_stats.parquet b/data/parquet-testing/timetz_4byte_stats.parquet\nnew file mode 100644\nindex 000000000000..a3357557e9b7\nBinary files /dev/null and b/data/parquet-testing/timetz_4byte_stats.parquet differ\ndiff --git a/test/sql/copy/parquet/timetz_parquet.test b/test/sql/copy/parquet/timetz_parquet.test\nnew file mode 100644\nindex 000000000000..4371535a1065\n--- /dev/null\n+++ b/test/sql/copy/parquet/timetz_parquet.test\n@@ -0,0 +1,13 @@\n+# name: test/sql/copy/parquet/timetz_parquet.test\n+# description: Test correct reading of stats for timetz columns\n+# group: [parquet]\n+\n+require parquet\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+query II\n+select * from 'data/parquet-testing/timetz_4byte_stats.parquet' order by 1;\n+----\n+00:00:00+00\t00:00:00+00\n",
  "problem_statement": "INTERNAL Error: Incorrect stats size for type TIMETZ\n### What happens?\n\nLoading parquet file into DuckDB table with read_parquet leads to internal error. But, the R arrow package can successfully load the parquet file with no issues leading me to think that the parquet is fine and the duckdb parquet reader may have an issue.\n\n### To Reproduce\n\nReading these time columns leads to an internal error.\r\n```\r\nlibrary(duckdb)\r\ncon <- dbConnect(duckdb())\r\ndbSendQuery(con, \"CREATE TABLE mytable AS FROM read_parquet('times.parquet');\")\r\n```\r\nGives error:\r\n```\r\nError: rapi_prepare: Failed to prepare query CREATE TABLE mytable AS FROM read_parquet('pk/1.pk');\r\nError: INTERNAL Error: Incorrect stats size for type TIMETZ\r\nThis error signals an assertion failure within DuckDB. This usually occurs due to unexpected conditions or errors in the program's logic.\r\nFor more information, see https://duckdb.org/docs/dev/internal_errors\r\n```\r\nBut using arrow package I get : \r\n```\r\narrow::read_parquet('times.parquet')\r\n# A tibble: 1 \u00d7 2\r\n  col1   col2  \r\n  <time> <time>\r\n1 00'00\" 00'00\"\r\n```\r\nI've reduced the original file down to the minimum required to reproduce the internal error, 1 line, 2 columns. I didn't check if only one column is the issue or if its both.\r\n[times.zip](https://github.com/user-attachments/files/16467664/times.zip)\r\n\n\n### OS:\n\nWindows 10 Professionnel x64\n\n### DuckDB Version:\n\nR package version 1.0.0-2\n\n### DuckDB Client:\n\nR version 4.3.2\n\n### Full Name:\n\nEli Daniels\n\n### Affiliation:\n\nArData\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a source build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [X] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [X] Yes, I have\nINTERNAL Error: Incorrect stats size for type TIMETZ\n### What happens?\n\nLoading parquet file into DuckDB table with read_parquet leads to internal error. But, the R arrow package can successfully load the parquet file with no issues leading me to think that the parquet is fine and the duckdb parquet reader may have an issue.\n\n### To Reproduce\n\nReading these time columns leads to an internal error.\r\n```\r\nlibrary(duckdb)\r\ncon <- dbConnect(duckdb())\r\ndbSendQuery(con, \"CREATE TABLE mytable AS FROM read_parquet('times.parquet');\")\r\n```\r\nGives error:\r\n```\r\nError: rapi_prepare: Failed to prepare query CREATE TABLE mytable AS FROM read_parquet('pk/1.pk');\r\nError: INTERNAL Error: Incorrect stats size for type TIMETZ\r\nThis error signals an assertion failure within DuckDB. This usually occurs due to unexpected conditions or errors in the program's logic.\r\nFor more information, see https://duckdb.org/docs/dev/internal_errors\r\n```\r\nBut using arrow package I get : \r\n```\r\narrow::read_parquet('times.parquet')\r\n# A tibble: 1 \u00d7 2\r\n  col1   col2  \r\n  <time> <time>\r\n1 00'00\" 00'00\"\r\n```\r\nI've reduced the original file down to the minimum required to reproduce the internal error, 1 line, 2 columns. I didn't check if only one column is the issue or if its both.\r\n[times.zip](https://github.com/user-attachments/files/16467664/times.zip)\r\n\n\n### OS:\n\nWindows 10 Professionnel x64\n\n### DuckDB Version:\n\nR package version 1.0.0-2\n\n### DuckDB Client:\n\nR version 4.3.2\n\n### Full Name:\n\nEli Daniels\n\n### Affiliation:\n\nArData\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a source build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [X] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [X] Yes, I have\n",
  "hints_text": "Thanks! This also reproduces from the CLI client:\r\n\r\n```sql\r\nCREATE TABLE mytable AS FROM read_parquet('times.parquet');\r\n```\nThanks! This also reproduces from the CLI client:\r\n\r\n```sql\r\nCREATE TABLE mytable AS FROM read_parquet('times.parquet');\r\n```",
  "created_at": "2024-08-02T13:17:51Z"
}