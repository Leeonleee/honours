{
  "repo": "duckdb/duckdb",
  "pull_number": 6396,
  "instance_id": "duckdb__duckdb-6396",
  "issue_numbers": [
    "6214"
  ],
  "base_commit": "e4384e1f04bfc5fb2c2b4b4f20938b0645b15d18",
  "patch": "diff --git a/src/catalog/catalog.cpp b/src/catalog/catalog.cpp\nindex 170d6efca335..082d2f0547f8 100644\n--- a/src/catalog/catalog.cpp\n+++ b/src/catalog/catalog.cpp\n@@ -2,6 +2,7 @@\n \n #include \"duckdb/catalog/catalog_search_path.hpp\"\n #include \"duckdb/catalog/catalog_entry/list.hpp\"\n+#include \"duckdb/catalog/catalog_entry/table_catalog_entry.hpp\"\n #include \"duckdb/catalog/catalog_set.hpp\"\n #include \"duckdb/catalog/default/default_schemas.hpp\"\n #include \"duckdb/catalog/catalog_entry/type_catalog_entry.hpp\"\n@@ -251,6 +252,20 @@ CatalogEntry *Catalog::CreateCollation(CatalogTransaction transaction, SchemaCat\n \treturn schema->CreateCollation(transaction, info);\n }\n \n+//===--------------------------------------------------------------------===//\n+// Index\n+//===--------------------------------------------------------------------===//\n+CatalogEntry *Catalog::CreateIndex(CatalogTransaction transaction, CreateIndexInfo *info) {\n+\tauto &context = transaction.GetContext();\n+\treturn CreateIndex(context, info);\n+}\n+\n+CatalogEntry *Catalog::CreateIndex(ClientContext &context, CreateIndexInfo *info) {\n+\tauto schema = GetSchema(context, info->schema);\n+\tauto table = GetEntry<TableCatalogEntry>(context, schema->name, info->table->table_name);\n+\treturn schema->CreateIndex(context, info, table);\n+}\n+\n //===--------------------------------------------------------------------===//\n // Lookup Structures\n //===--------------------------------------------------------------------===//\ndiff --git a/src/catalog/catalog_entry/index_catalog_entry.cpp b/src/catalog/catalog_entry/index_catalog_entry.cpp\nindex 5c8f47a0da23..d690ebef26bf 100644\n--- a/src/catalog/catalog_entry/index_catalog_entry.cpp\n+++ b/src/catalog/catalog_entry/index_catalog_entry.cpp\n@@ -19,10 +19,11 @@ string IndexCatalogEntry::ToSQL() {\n \treturn sql;\n }\n \n-void IndexCatalogEntry::Serialize(duckdb::MetaBlockWriter &serializer) {\n-\t// Here we serialize the index metadata in the following order:\n-\t// schema name, table name, index name, sql, index type, index constraint type, expression list.\n-\t// column_ids, unbound_expression\n+void IndexCatalogEntry::Serialize(Serializer &serializer) {\n+\t// here we serialize the index metadata in the following order:\n+\t// schema name, table name, index name, sql, index type, index constraint type, expression list, parsed expressions,\n+\t// column IDs\n+\n \tFieldWriter writer(serializer);\n \twriter.WriteString(GetSchemaName());\n \twriter.WriteString(GetTableName());\n@@ -37,9 +38,9 @@ void IndexCatalogEntry::Serialize(duckdb::MetaBlockWriter &serializer) {\n }\n \n unique_ptr<CreateIndexInfo> IndexCatalogEntry::Deserialize(Deserializer &source, ClientContext &context) {\n-\t// Here we deserialize the index metadata in the following order:\n-\t// root block, root offset, schema name, table name, index name, sql, index type, index constraint type, expression\n-\t// list.\n+\t// here we deserialize the index metadata in the following order:\n+\t// schema name, table schema name, table name, index name, sql, index type, index constraint type, expression list,\n+\t// parsed expression list, column IDs\n \n \tauto create_index_info = make_unique<CreateIndexInfo>();\n \ndiff --git a/src/execution/index/art/art.cpp b/src/execution/index/art/art.cpp\nindex 8dc5cd85c157..17ce11723bd6 100644\n--- a/src/execution/index/art/art.cpp\n+++ b/src/execution/index/art/art.cpp\n@@ -27,7 +27,10 @@ ART::ART(const vector<column_t> &column_ids, TableIOManager &table_io_manager,\n \ttree = nullptr;\n \tif (block_id != DConstants::INVALID_INDEX) {\n \t\ttree = Node::Deserialize(*this, block_id, block_offset);\n-\t\tART::Verify();\n+\t\tVerify();\n+\t\tif (track_memory) {\n+\t\t\tbuffer_manager.IncreaseUsedMemory(memory_size);\n+\t\t}\n \t}\n \tserialized_data_pointer = BlockPointer(block_id, block_offset);\n \n@@ -58,7 +61,7 @@ ART::~ART() {\n \tif (!tree) {\n \t\treturn;\n \t}\n-\tART::Verify();\n+\tVerify();\n \tif (track_memory) {\n \t\tbuffer_manager.DecreaseUsedMemory(memory_size);\n \t}\n@@ -72,6 +75,7 @@ ART::~ART() {\n \n unique_ptr<IndexScanState> ART::InitializeScanSinglePredicate(const Transaction &transaction, const Value &value,\n                                                               ExpressionType expression_type) {\n+\t// initialize point lookup\n \tauto result = make_unique<ARTIndexScanState>();\n \tresult->values[0] = value;\n \tresult->expressions[0] = expression_type;\n@@ -81,6 +85,7 @@ unique_ptr<IndexScanState> ART::InitializeScanSinglePredicate(const Transaction\n unique_ptr<IndexScanState> ART::InitializeScanTwoPredicates(Transaction &transaction, const Value &low_value,\n                                                             ExpressionType low_expression_type, const Value &high_value,\n                                                             ExpressionType high_expression_type) {\n+\t// initialize range lookup\n \tauto result = make_unique<ARTIndexScanState>();\n \tresult->values[0] = low_value;\n \tresult->expressions[0] = low_expression_type;\n@@ -103,7 +108,7 @@ static void TemplatedGenerateKeys(ArenaAllocator &allocator, Vector &input, idx_\n \tfor (idx_t i = 0; i < count; i++) {\n \t\tauto idx = idata.sel->get_index(i);\n \t\tif (idata.validity.RowIsValid(idx)) {\n-\t\t\tKey::CreateKey<T>(allocator, keys[i], input_data[idx]);\n+\t\t\tKey::CreateKey<T>(allocator, input.GetType(), keys[i], input_data[idx]);\n \t\t}\n \t}\n }\n@@ -123,7 +128,7 @@ static void ConcatenateKeys(ArenaAllocator &allocator, Vector &input, idx_t coun\n \t\t\t\t// this column entry is NULL, set whole key to NULL\n \t\t\t\tkeys[i] = Key();\n \t\t\t} else {\n-\t\t\t\tauto other_key = Key::CreateKey<T>(allocator, input_data[idx]);\n+\t\t\t\tauto other_key = Key::CreateKey<T>(allocator, input.GetType(), input_data[idx]);\n \t\t\t\tkeys[i].ConcatenateKey(allocator, other_key);\n \t\t\t}\n \t\t}\n@@ -225,7 +230,7 @@ void ART::GenerateKeys(ArenaAllocator &allocator, DataChunk &input, vector<Key>\n }\n \n //===--------------------------------------------------------------------===//\n-// Construct from sorted data\n+// Construct from sorted data (only during CREATE (UNIQUE) INDEX statements)\n //===--------------------------------------------------------------------===//\n \n struct KeySection {\n@@ -283,7 +288,7 @@ bool Construct(ART &art, vector<Key> &keys, row_t *row_ids, Node *&node, KeySect\n \t\t} else {\n \t\t\tnode = Leaf::New(start_key, prefix_start, row_ids + key_section.start, num_row_ids);\n \t\t}\n-\t\tart.memory_size += node->MemorySize(art, false);\n+\t\tart.IncreaseMemorySize(node->MemorySize(art, false));\n \t\treturn true;\n \t}\n \t// create a new node and recurse\n@@ -297,7 +302,7 @@ bool Construct(ART &art, vector<Key> &keys, row_t *row_ids, Node *&node, KeySect\n \n \tauto prefix_length = key_section.depth - prefix_start;\n \tnode->prefix = Prefix(start_key, prefix_start, prefix_length);\n-\tart.memory_size += node->MemorySize(art, false);\n+\tart.IncreaseMemorySize(node->MemorySize(art, false));\n \n \t// recurse on each child section\n \tfor (auto &child_section : child_sections) {\n@@ -323,7 +328,7 @@ bool ART::ConstructFromSorted(idx_t count, vector<Key> &keys, Vector &row_identi\n }\n \n //===--------------------------------------------------------------------===//\n-// Insert\n+// Insert / Verification / Constraint Checking\n //===--------------------------------------------------------------------===//\n \n bool ART::Insert(IndexLock &lock, DataChunk &input, Vector &row_ids) {\n@@ -331,13 +336,13 @@ bool ART::Insert(IndexLock &lock, DataChunk &input, Vector &row_ids) {\n \tD_ASSERT(row_ids.GetType().InternalType() == ROW_TYPE);\n \tD_ASSERT(logical_types[0] == input.data[0].GetType());\n \n+\tauto old_memory_size = memory_size;\n+\n \t// generate the keys for the given input\n \tArenaAllocator arena_allocator(BufferAllocator::Get(db));\n \tvector<Key> keys(input.size());\n \tGenerateKeys(arena_allocator, input, keys);\n \n-\tauto old_memory_size = this->memory_size;\n-\n \t// get the corresponding row IDs\n \trow_ids.Flatten(input.size());\n \tauto row_identifiers = FlatVector::GetData<row_t>(row_ids);\n@@ -356,9 +361,9 @@ bool ART::Insert(IndexLock &lock, DataChunk &input, Vector &row_ids) {\n \t\t\tbreak;\n \t\t}\n \t}\n-\tif (failed_index != DConstants::INVALID_INDEX) {\n \n-\t\t// failed to insert because of constraint violation: remove previously inserted entries\n+\t// failed to insert because of constraint violation: remove previously inserted entries\n+\tif (failed_index != DConstants::INVALID_INDEX) {\n \t\tfor (idx_t i = 0; i < failed_index; i++) {\n \t\t\tif (keys[i].Empty()) {\n \t\t\t\tcontinue;\n@@ -366,14 +371,11 @@ bool ART::Insert(IndexLock &lock, DataChunk &input, Vector &row_ids) {\n \t\t\trow_t row_id = row_identifiers[i];\n \t\t\tErase(tree, keys[i], 0, row_id);\n \t\t}\n-\t\t// nothing changed, no need to update the buffer memory size\n-\t\treturn false;\n \t}\n \n-\tD_ASSERT(old_memory_size <= memory_size);\n-\tVerify();\n-\tif (track_memory) {\n-\t\tbuffer_manager.IncreaseUsedMemory(memory_size - old_memory_size);\n+\tIncreaseAndVerifyMemorySize(old_memory_size);\n+\tif (failed_index != DConstants::INVALID_INDEX) {\n+\t\treturn false;\n \t}\n \treturn true;\n }\n@@ -391,25 +393,12 @@ bool ART::Append(IndexLock &lock, DataChunk &appended_data, Vector &row_identifi\n \n void ART::VerifyAppend(DataChunk &chunk) {\n \tConflictManager conflict_manager(VerifyExistenceType::APPEND, chunk.size());\n-\tLookupValues(chunk, conflict_manager);\n+\tCheckConstraintsForChunk(chunk, conflict_manager);\n }\n \n void ART::VerifyAppend(DataChunk &chunk, ConflictManager &conflict_manager) {\n \tD_ASSERT(conflict_manager.LookupType() == VerifyExistenceType::APPEND);\n-\tLookupValues(chunk, conflict_manager);\n-}\n-\n-void ART::VerifyAppendForeignKey(DataChunk &chunk) {\n-\tConflictManager conflict_manager(VerifyExistenceType::APPEND_FK, chunk.size());\n-\tLookupValues(chunk, conflict_manager);\n-}\n-\n-void ART::VerifyDeleteForeignKey(DataChunk &chunk) {\n-\tif (!IsUnique()) {\n-\t\treturn;\n-\t}\n-\tConflictManager conflict_manager(VerifyExistenceType::DELETE_FK, chunk.size());\n-\tLookupValues(chunk, conflict_manager);\n+\tCheckConstraintsForChunk(chunk, conflict_manager);\n }\n \n bool ART::InsertToLeaf(Leaf &leaf, row_t row_id) {\n@@ -430,7 +419,7 @@ bool ART::Insert(Node *&node, Key &key, idx_t depth, row_t row_id) {\n \tif (!node) {\n \t\t// node is currently empty, create a leaf here with the key\n \t\tnode = Leaf::New(key, depth, row_id);\n-\t\tthis->memory_size += node->MemorySize(*this, false);\n+\t\tIncreaseMemorySize(node->MemorySize(*this, false));\n \t\treturn true;\n \t}\n \n@@ -455,14 +444,14 @@ bool ART::Insert(Node *&node, Key &key, idx_t depth, row_t row_id) {\n \n \t\tNode *new_node = Node4::New();\n \t\tnew_node->prefix = Prefix(key, depth, new_prefix_length);\n-\t\tthis->memory_size += new_node->MemorySize(*this, false);\n+\t\tIncreaseMemorySize(new_node->MemorySize(*this, false));\n \n \t\tauto key_byte = node->prefix.Reduce(*this, new_prefix_length);\n \t\tNode4::InsertChild(*this, new_node, key_byte, node);\n \n \t\tNode *leaf_node = Leaf::New(key, depth + new_prefix_length + 1, row_id);\n \t\tNode4::InsertChild(*this, new_node, key[depth + new_prefix_length], leaf_node);\n-\t\tthis->memory_size += leaf_node->MemorySize(*this, false);\n+\t\tIncreaseMemorySize(leaf_node->MemorySize(*this, false));\n \n \t\tnode = new_node;\n \t\treturn true;\n@@ -476,7 +465,7 @@ bool ART::Insert(Node *&node, Key &key, idx_t depth, row_t row_id) {\n \t\t\t// prefix differs, create new node\n \t\t\tNode *new_node = Node4::New();\n \t\t\tnew_node->prefix = Prefix(key, depth, mismatch_pos);\n-\t\t\tthis->memory_size += new_node->MemorySize(*this, false);\n+\t\t\tIncreaseMemorySize(new_node->MemorySize(*this, false));\n \n \t\t\t// break up prefix\n \t\t\tauto key_byte = node->prefix.Reduce(*this, mismatch_pos);\n@@ -484,7 +473,7 @@ bool ART::Insert(Node *&node, Key &key, idx_t depth, row_t row_id) {\n \n \t\t\tNode *leaf_node = Leaf::New(key, depth + mismatch_pos + 1, row_id);\n \t\t\tNode4::InsertChild(*this, new_node, key[depth + mismatch_pos], leaf_node);\n-\t\t\tthis->memory_size += leaf_node->MemorySize(*this, false);\n+\t\t\tIncreaseMemorySize(leaf_node->MemorySize(*this, false));\n \n \t\t\tnode = new_node;\n \t\t\treturn true;\n@@ -504,7 +493,7 @@ bool ART::Insert(Node *&node, Key &key, idx_t depth, row_t row_id) {\n \n \tNode *leaf_node = Leaf::New(key, depth + 1, row_id);\n \tNode::InsertChild(*this, node, key[depth], leaf_node);\n-\tthis->memory_size += leaf_node->MemorySize(*this, false);\n+\tIncreaseMemorySize(leaf_node->MemorySize(*this, false));\n \treturn true;\n }\n \n@@ -525,7 +514,7 @@ void ART::Delete(IndexLock &state, DataChunk &input, Vector &row_ids) {\n \tvector<Key> keys(expression.size());\n \tGenerateKeys(arena_allocator, expression, keys);\n \n-\tauto old_memory_size = this->memory_size;\n+\tauto old_memory_size = memory_size;\n \n \t// now erase the elements from the database\n \trow_ids.Flatten(input.size());\n@@ -547,10 +536,13 @@ void ART::Delete(IndexLock &state, DataChunk &input, Vector &row_ids) {\n #endif\n \t}\n \n-\tD_ASSERT(old_memory_size >= memory_size);\n+\t// if we deserialize nodes while erasing, then we might end up with more\n+\t// memory afterwards, so we have to either increase or decrease the used memory\n \tVerify();\n-\tif (track_memory) {\n+\tif (track_memory && old_memory_size >= memory_size) {\n \t\tbuffer_manager.DecreaseUsedMemory(old_memory_size - memory_size);\n+\t} else if (track_memory) {\n+\t\tbuffer_manager.IncreaseUsedMemory(memory_size - old_memory_size);\n \t}\n }\n \n@@ -566,8 +558,7 @@ void ART::Erase(Node *&node, Key &key, idx_t depth, row_t row_id) {\n \t\tleaf->Remove(*this, row_id);\n \n \t\tif (leaf->count == 0) {\n-\t\t\tD_ASSERT(this->memory_size >= leaf->MemorySize(*this, false));\n-\t\t\tthis->memory_size -= leaf->MemorySize(*this, false);\n+\t\t\tDecreaseMemorySize(leaf->MemorySize(*this, false));\n \t\t\tNode::Delete(node);\n \t\t\tnode = nullptr;\n \t\t}\n@@ -606,38 +597,38 @@ void ART::Erase(Node *&node, Key &key, idx_t depth, row_t row_id) {\n }\n \n //===--------------------------------------------------------------------===//\n-// Point Query\n+// Point Query (Equal)\n //===--------------------------------------------------------------------===//\n \n static Key CreateKey(ArenaAllocator &allocator, PhysicalType type, Value &value) {\n \tD_ASSERT(type == value.type().InternalType());\n \tswitch (type) {\n \tcase PhysicalType::BOOL:\n-\t\treturn Key::CreateKey<bool>(allocator, value);\n+\t\treturn Key::CreateKey<bool>(allocator, value.type(), value);\n \tcase PhysicalType::INT8:\n-\t\treturn Key::CreateKey<int8_t>(allocator, value);\n+\t\treturn Key::CreateKey<int8_t>(allocator, value.type(), value);\n \tcase PhysicalType::INT16:\n-\t\treturn Key::CreateKey<int16_t>(allocator, value);\n+\t\treturn Key::CreateKey<int16_t>(allocator, value.type(), value);\n \tcase PhysicalType::INT32:\n-\t\treturn Key::CreateKey<int32_t>(allocator, value);\n+\t\treturn Key::CreateKey<int32_t>(allocator, value.type(), value);\n \tcase PhysicalType::INT64:\n-\t\treturn Key::CreateKey<int64_t>(allocator, value);\n+\t\treturn Key::CreateKey<int64_t>(allocator, value.type(), value);\n \tcase PhysicalType::UINT8:\n-\t\treturn Key::CreateKey<uint8_t>(allocator, value);\n+\t\treturn Key::CreateKey<uint8_t>(allocator, value.type(), value);\n \tcase PhysicalType::UINT16:\n-\t\treturn Key::CreateKey<uint16_t>(allocator, value);\n+\t\treturn Key::CreateKey<uint16_t>(allocator, value.type(), value);\n \tcase PhysicalType::UINT32:\n-\t\treturn Key::CreateKey<uint32_t>(allocator, value);\n+\t\treturn Key::CreateKey<uint32_t>(allocator, value.type(), value);\n \tcase PhysicalType::UINT64:\n-\t\treturn Key::CreateKey<uint64_t>(allocator, value);\n+\t\treturn Key::CreateKey<uint64_t>(allocator, value.type(), value);\n \tcase PhysicalType::INT128:\n-\t\treturn Key::CreateKey<hugeint_t>(allocator, value);\n+\t\treturn Key::CreateKey<hugeint_t>(allocator, value.type(), value);\n \tcase PhysicalType::FLOAT:\n-\t\treturn Key::CreateKey<float>(allocator, value);\n+\t\treturn Key::CreateKey<float>(allocator, value.type(), value);\n \tcase PhysicalType::DOUBLE:\n-\t\treturn Key::CreateKey<double>(allocator, value);\n+\t\treturn Key::CreateKey<double>(allocator, value.type(), value);\n \tcase PhysicalType::VARCHAR:\n-\t\treturn Key::CreateKey<string_t>(allocator, value);\n+\t\treturn Key::CreateKey<string_t>(allocator, value.type(), value);\n \tdefault:\n \t\tthrow InternalException(\"Invalid type for index\");\n \t}\n@@ -645,7 +636,10 @@ static Key CreateKey(ArenaAllocator &allocator, PhysicalType type, Value &value)\n \n bool ART::SearchEqual(Key &key, idx_t max_count, vector<row_t> &result_ids) {\n \n+\tauto old_memory_size = memory_size;\n \tauto leaf = (Leaf *)(Lookup(tree, key, 0));\n+\tIncreaseAndVerifyMemorySize(old_memory_size);\n+\n \tif (!leaf) {\n \t\treturn true;\n \t}\n@@ -662,19 +656,28 @@ bool ART::SearchEqual(Key &key, idx_t max_count, vector<row_t> &result_ids) {\n void ART::SearchEqualJoinNoFetch(Key &key, idx_t &result_size) {\n \n \t// we need to look for a leaf\n+\tauto old_memory_size = memory_size;\n \tauto leaf = Lookup(tree, key, 0);\n+\tIncreaseAndVerifyMemorySize(old_memory_size);\n+\n \tif (!leaf) {\n \t\treturn;\n \t}\n \tresult_size = leaf->count;\n }\n \n+//===--------------------------------------------------------------------===//\n+// Lookup\n+//===--------------------------------------------------------------------===//\n+\n Leaf *ART::Lookup(Node *node, Key &key, idx_t depth) {\n+\n \twhile (node) {\n \t\tif (node->type == NodeType::NLeaf) {\n \t\t\tauto leaf = (Leaf *)node;\n \t\t\tauto &leaf_prefix = leaf->prefix;\n-\t\t\t//! Check leaf\n+\n+\t\t\t// check if leaf contains key\n \t\t\tfor (idx_t i = 0; i < leaf->prefix.Size(); i++) {\n \t\t\t\tif (leaf_prefix[i] != key[i + depth]) {\n \t\t\t\t\treturn nullptr;\n@@ -682,22 +685,29 @@ Leaf *ART::Lookup(Node *node, Key &key, idx_t depth) {\n \t\t\t}\n \t\t\treturn (Leaf *)node;\n \t\t}\n+\n \t\tif (node->prefix.Size()) {\n \t\t\tfor (idx_t pos = 0; pos < node->prefix.Size(); pos++) {\n \t\t\t\tif (key[depth + pos] != node->prefix[pos]) {\n+\t\t\t\t\t// prefix mismatch, does not contain key\n \t\t\t\t\treturn nullptr;\n \t\t\t\t}\n \t\t\t}\n \t\t\tdepth += node->prefix.Size();\n \t\t}\n+\n+\t\t// prefix matches key, but no child at byte, does not contain key\n \t\tidx_t pos = node->GetChildPos(key[depth]);\n \t\tif (pos == DConstants::INVALID_INDEX) {\n \t\t\treturn nullptr;\n \t\t}\n+\n+\t\t// recurse into child\n \t\tnode = node->GetChild(*this, pos);\n \t\tD_ASSERT(node);\n \t\tdepth++;\n \t}\n+\n \treturn nullptr;\n }\n \n@@ -710,6 +720,7 @@ Leaf *ART::Lookup(Node *node, Key &key, idx_t depth) {\n bool ART::SearchGreater(ARTIndexScanState *state, Key &key, bool inclusive, idx_t max_count,\n                         vector<row_t> &result_ids) {\n \n+\tauto old_memory_size = memory_size;\n \tIterator *it = &state->iterator;\n \n \t// greater than scan: first set the iterator to the node at which we will start our scan by finding the lowest node\n@@ -718,13 +729,16 @@ bool ART::SearchGreater(ARTIndexScanState *state, Key &key, bool inclusive, idx_\n \t\tit->art = this;\n \t\tbool found = it->LowerBound(tree, key, inclusive);\n \t\tif (!found) {\n+\t\t\tIncreaseAndVerifyMemorySize(old_memory_size);\n \t\t\treturn true;\n \t\t}\n \t}\n \t// after that we continue the scan; we don't need to check the bounds as any value following this value is\n \t// automatically bigger and hence satisfies our predicate\n \tKey empty_key = Key();\n-\treturn it->Scan(empty_key, max_count, result_ids, false);\n+\tauto success = it->Scan(empty_key, max_count, result_ids, false);\n+\tIncreaseAndVerifyMemorySize(old_memory_size);\n+\treturn success;\n }\n \n //===--------------------------------------------------------------------===//\n@@ -738,6 +752,7 @@ bool ART::SearchLess(ARTIndexScanState *state, Key &upper_bound, bool inclusive,\n \t\treturn true;\n \t}\n \n+\tauto old_memory_size = memory_size;\n \tIterator *it = &state->iterator;\n \n \tif (!it->art) {\n@@ -746,11 +761,14 @@ bool ART::SearchLess(ARTIndexScanState *state, Key &upper_bound, bool inclusive,\n \t\tit->FindMinimum(*tree);\n \t\t// early out min value higher than upper bound query\n \t\tif (it->cur_key > upper_bound) {\n+\t\t\tIncreaseAndVerifyMemorySize(old_memory_size);\n \t\t\treturn true;\n \t\t}\n \t}\n \t// now continue the scan until we reach the upper bound\n-\treturn it->Scan(upper_bound, max_count, result_ids, inclusive);\n+\tauto success = it->Scan(upper_bound, max_count, result_ids, inclusive);\n+\tIncreaseAndVerifyMemorySize(old_memory_size);\n+\treturn success;\n }\n \n //===--------------------------------------------------------------------===//\n@@ -760,6 +778,7 @@ bool ART::SearchLess(ARTIndexScanState *state, Key &upper_bound, bool inclusive,\n bool ART::SearchCloseRange(ARTIndexScanState *state, Key &lower_bound, Key &upper_bound, bool left_inclusive,\n                            bool right_inclusive, idx_t max_count, vector<row_t> &result_ids) {\n \n+\tauto old_memory_size = memory_size;\n \tIterator *it = &state->iterator;\n \n \t// first find the first node that satisfies the left predicate\n@@ -767,11 +786,14 @@ bool ART::SearchCloseRange(ARTIndexScanState *state, Key &lower_bound, Key &uppe\n \t\tit->art = this;\n \t\tbool found = it->LowerBound(tree, lower_bound, left_inclusive);\n \t\tif (!found) {\n+\t\t\tIncreaseAndVerifyMemorySize(old_memory_size);\n \t\t\treturn true;\n \t\t}\n \t}\n \t// now continue the scan until we reach the upper bound\n-\treturn it->Scan(upper_bound, max_count, result_ids, right_inclusive);\n+\tauto success = it->Scan(upper_bound, max_count, result_ids, right_inclusive);\n+\tIncreaseAndVerifyMemorySize(old_memory_size);\n+\treturn success;\n }\n \n bool ART::Scan(Transaction &transaction, DataTable &table, IndexScanState &table_state, idx_t max_count,\n@@ -844,8 +866,15 @@ bool ART::Scan(Transaction &transaction, DataTable &table, IndexScanState &table\n \treturn true;\n }\n \n+//===--------------------------------------------------------------------===//\n+// More Verification / Constraint Checking\n+//===--------------------------------------------------------------------===//\n+\n string ART::GenerateErrorKeyName(DataChunk &input, idx_t row) {\n-\t// re-executing the expressions is not very fast, but we're going to throw anyways, so we don't care\n+\n+\t// FIXME: why exactly can we not pass the expression_chunk as an argument to this\n+\t// FIXME: function instead of re-executing?\n+\t// re-executing the expressions is not very fast, but we're going to throw, so we don't care\n \tDataChunk expression_chunk;\n \texpression_chunk.Initialize(Allocator::DefaultAllocator(), logical_types);\n \tExecuteExpressions(input, expression_chunk);\n@@ -883,11 +912,13 @@ string ART::GenerateConstraintErrorMessage(VerifyExistenceType verify_type, cons\n \t}\n }\n \n-void ART::LookupValues(DataChunk &input, ConflictManager &conflict_manager) {\n+void ART::CheckConstraintsForChunk(DataChunk &input, ConflictManager &conflict_manager) {\n \n \t// don't alter the index during constraint checking\n \tlock_guard<mutex> l(lock);\n \n+\tauto old_memory_size = memory_size;\n+\n \t// first resolve the expressions for the index\n \tDataChunk expression_chunk;\n \texpression_chunk.Initialize(Allocator::DefaultAllocator(), logical_types);\n@@ -900,12 +931,14 @@ void ART::LookupValues(DataChunk &input, ConflictManager &conflict_manager) {\n \n \tidx_t found_conflict = DConstants::INVALID_INDEX;\n \tfor (idx_t i = 0; found_conflict == DConstants::INVALID_INDEX && i < input.size(); i++) {\n+\n \t\tif (keys[i].Empty()) {\n \t\t\tif (conflict_manager.AddNull(i)) {\n \t\t\t\tfound_conflict = i;\n \t\t\t}\n \t\t\tcontinue;\n \t\t}\n+\n \t\tLeaf *leaf_ptr = Lookup(tree, keys[i], 0);\n \t\tif (leaf_ptr == nullptr) {\n \t\t\tif (conflict_manager.AddMiss(i)) {\n@@ -913,6 +946,7 @@ void ART::LookupValues(DataChunk &input, ConflictManager &conflict_manager) {\n \t\t\t}\n \t\t\tcontinue;\n \t\t}\n+\n \t\t// When we find a node, we need to update the 'matches' and 'row_ids'\n \t\t// NOTE: Leafs can have more than one row_id, but for UNIQUE/PRIMARY KEY they will only have one\n \t\tD_ASSERT(leaf_ptr->count == 1);\n@@ -921,11 +955,15 @@ void ART::LookupValues(DataChunk &input, ConflictManager &conflict_manager) {\n \t\t\tfound_conflict = i;\n \t\t}\n \t}\n+\n \tconflict_manager.FinishLookup();\n+\tIncreaseAndVerifyMemorySize(old_memory_size);\n+\n \tif (found_conflict == DConstants::INVALID_INDEX) {\n \t\t// No conflicts detected\n \t\treturn;\n \t}\n+\n \tauto key_name = GenerateErrorKeyName(input, found_conflict);\n \tauto exception_msg = GenerateConstraintErrorMessage(conflict_manager.LookupType(), key_name);\n \tthrow ConstraintException(exception_msg);\n@@ -935,13 +973,15 @@ void ART::LookupValues(DataChunk &input, ConflictManager &conflict_manager) {\n // Serialization\n //===--------------------------------------------------------------------===//\n \n-BlockPointer ART::Serialize(duckdb::MetaBlockWriter &writer) {\n+BlockPointer ART::Serialize(MetaBlockWriter &writer) {\n \tlock_guard<mutex> l(lock);\n+\tauto old_memory_size = memory_size;\n \tif (tree) {\n \t\tserialized_data_pointer = tree->Serialize(*this, writer);\n \t} else {\n \t\tserialized_data_pointer = {(block_id_t)DConstants::INVALID_INDEX, (uint32_t)DConstants::INVALID_INDEX};\n \t}\n+\tIncreaseAndVerifyMemorySize(old_memory_size);\n \treturn serialized_data_pointer;\n }\n \n@@ -954,8 +994,8 @@ bool ART::MergeIndexes(IndexLock &state, Index *other_index) {\n \tauto other_art = (ART *)other_index;\n \n \tif (!this->tree) {\n-\t\tthis->memory_size += other_art->memory_size;\n-\t\tthis->tree = other_art->tree;\n+\t\tIncreaseMemorySize(other_art->memory_size);\n+\t\ttree = other_art->tree;\n \t\tother_art->tree = nullptr;\n \t\treturn true;\n \t}\n@@ -987,4 +1027,14 @@ void ART::Verify() {\n #endif\n }\n \n+void ART::IncreaseAndVerifyMemorySize(idx_t old_memory_size) {\n+\t// since we lazily deserialize ART nodes, it is possible that its in-memory size\n+\t// increased during lookups\n+\tVerify();\n+\tD_ASSERT(memory_size >= old_memory_size);\n+\tif (track_memory) {\n+\t\tbuffer_manager.IncreaseUsedMemory(memory_size - old_memory_size);\n+\t}\n+}\n+\n } // namespace duckdb\ndiff --git a/src/execution/index/art/art_key.cpp b/src/execution/index/art/art_key.cpp\nindex f3b65135144d..9c867f4eed60 100644\n--- a/src/execution/index/art/art_key.cpp\n+++ b/src/execution/index/art/art_key.cpp\n@@ -15,40 +15,52 @@ Key::Key(ArenaAllocator &allocator, idx_t len) : len(len) {\n }\n \n template <>\n-Key Key::CreateKey(ArenaAllocator &allocator, string_t value) {\n+Key Key::CreateKey(ArenaAllocator &allocator, const LogicalType &type, string_t value) {\n \tidx_t len = value.GetSize() + 1;\n \tauto data = allocator.Allocate(len);\n \tmemcpy(data, value.GetDataUnsafe(), len - 1);\n \n-\tif (len > 1 && data[len - 2] == '\\0') {\n-\t\t// FIXME: rethink this\n-\t\tthrow NotImplementedException(\"Indexes cannot have contain null-terminated decoded BLOBs.\");\n+\t// FIXME: rethink this\n+\tif (type == LogicalType::BLOB || type == LogicalType::VARCHAR) {\n+\t\t// indexes cannot contain BLOBs (or BLOBs cast to VARCHARs) that contain null-terminated bytes\n+\t\tfor (idx_t i = 0; i < len - 1; i++) {\n+\t\t\tif (data[i] == '\\0') {\n+\t\t\t\tthrow NotImplementedException(\"Indexes cannot contain BLOBs that contain null-terminated bytes.\");\n+\t\t\t}\n+\t\t}\n \t}\n+\n \tdata[len - 1] = '\\0';\n \treturn Key(data, len);\n }\n \n template <>\n-Key Key::CreateKey(ArenaAllocator &allocator, const char *value) {\n-\treturn Key::CreateKey(allocator, string_t(value, strlen(value)));\n+Key Key::CreateKey(ArenaAllocator &allocator, const LogicalType &type, const char *value) {\n+\treturn Key::CreateKey(allocator, type, string_t(value, strlen(value)));\n }\n \n template <>\n-void Key::CreateKey(ArenaAllocator &allocator, Key &key, string_t value) {\n+void Key::CreateKey(ArenaAllocator &allocator, const LogicalType &type, Key &key, string_t value) {\n \tkey.len = value.GetSize() + 1;\n \tkey.data = allocator.Allocate(key.len);\n \tmemcpy(key.data, value.GetDataUnsafe(), key.len - 1);\n \n-\tif (key.len > 1 && key.data[key.len - 2] == '\\0') {\n-\t\t// FIXME: rethink this\n-\t\tthrow NotImplementedException(\"Indexes cannot have contain null-terminated decoded BLOBs.\");\n+\t// FIXME: rethink this\n+\tif (type == LogicalType::BLOB || type == LogicalType::VARCHAR) {\n+\t\t// indexes cannot contain BLOBs (or BLOBs cast to VARCHARs) that contain null-terminated bytes\n+\t\tfor (idx_t i = 0; i < key.len - 1; i++) {\n+\t\t\tif (key.data[i] == '\\0') {\n+\t\t\t\tthrow NotImplementedException(\"Indexes cannot contain BLOBs that contain null-terminated bytes.\");\n+\t\t\t}\n+\t\t}\n \t}\n+\n \tkey.data[key.len - 1] = '\\0';\n }\n \n template <>\n-void Key::CreateKey(ArenaAllocator &allocator, Key &key, const char *value) {\n-\tKey::CreateKey(allocator, key, string_t(value, strlen(value)));\n+void Key::CreateKey(ArenaAllocator &allocator, const LogicalType &type, Key &key, const char *value) {\n+\tKey::CreateKey(allocator, type, key, string_t(value, strlen(value)));\n }\n \n bool Key::operator>(const Key &k) const {\ndiff --git a/src/execution/index/art/leaf.cpp b/src/execution/index/art/leaf.cpp\nindex f9e5b7b0b79c..43715b1692fc 100644\n--- a/src/execution/index/art/leaf.cpp\n+++ b/src/execution/index/art/leaf.cpp\n@@ -109,9 +109,9 @@ void Leaf::Insert(ART &art, row_t row_id) {\n \tif (count == capacity) {\n \t\t// grow array\n \t\tif (IsInlined()) {\n-\t\t\tart.memory_size += (capacity + 1) * sizeof(row_t);\n+\t\t\tart.IncreaseMemorySize((capacity + 1) * sizeof(row_t));\n \t\t} else {\n-\t\t\tart.memory_size += capacity * sizeof(row_t);\n+\t\t\tart.IncreaseMemorySize(capacity * sizeof(row_t));\n \t\t}\n \t\trow_ids = Resize(row_ids, count, capacity * 2);\n \t}\n@@ -143,6 +143,7 @@ void Leaf::Remove(ART &art, row_t row_id) {\n \t\treturn;\n \t}\n \n+\tauto capacity = GetCapacity();\n \tcount--;\n \tif (count == 1) {\n \t\t// after erasing we can now inline the leaf\n@@ -150,18 +151,16 @@ void Leaf::Remove(ART &art, row_t row_id) {\n \t\tauto remaining_row_id = row_ids[0] == row_id ? row_ids[1] : row_ids[0];\n \t\tDeleteArray<row_t>(rowids.ptr, rowids.ptr[0] + 1);\n \t\trowids.inlined = remaining_row_id;\n-\t\tD_ASSERT(art.memory_size >= sizeof(row_t));\n-\t\tart.memory_size -= 2 * sizeof(row_t);\n+\t\tart.DecreaseMemorySize(capacity * sizeof(row_t));\n \t\treturn;\n \t}\n \n \t// shrink array, if less than half full\n-\tauto capacity = GetCapacity();\n+\tcapacity = GetCapacity();\n \tif (capacity > 2 && count < capacity / 2) {\n \n \t\tauto new_capacity = capacity / 2;\n-\t\tD_ASSERT(art.memory_size >= (capacity - new_capacity) * sizeof(row_t));\n-\t\tart.memory_size -= (capacity - new_capacity) * sizeof(row_t);\n+\t\tart.DecreaseMemorySize((capacity - new_capacity) * sizeof(row_t));\n \n \t\tauto new_allocation = AllocateArray<row_t>(new_capacity + 1);\n \t\tnew_allocation[0] = new_capacity;\n@@ -200,7 +199,7 @@ void Leaf::Merge(ART &art, Node *&l_node, Node *&r_node) {\n \tif (l_n->count + r_n->count > l_capacity) {\n \t\tauto capacity = l_n->GetCapacity();\n \t\tauto new_capacity = NextPowerOfTwo(l_n->count + r_n->count);\n-\t\tart.memory_size += sizeof(row_t) * (new_capacity - capacity);\n+\t\tart.IncreaseMemorySize(sizeof(row_t) * (new_capacity - capacity));\n \t\tl_row_ids = l_n->Resize(l_row_ids, l_n->count, new_capacity);\n \t}\n \ndiff --git a/src/execution/index/art/node.cpp b/src/execution/index/art/node.cpp\nindex 6af3a40b0836..d45d602b7f18 100644\n--- a/src/execution/index/art/node.cpp\n+++ b/src/execution/index/art/node.cpp\n@@ -299,16 +299,11 @@ Node *Node::Deserialize(ART &art, idx_t block_id, idx_t offset) {\n \tNodeType node_type((NodeType)(n));\n \n \tNode *deserialized_node = nullptr;\n-\tauto old_memory_size = art.memory_size;\n \tswitch (node_type) {\n \tcase NodeType::NLeaf: {\n \t\tauto leaf = Leaf::New();\n \t\tleaf->Deserialize(art, reader);\n-\t\tart.memory_size += leaf->MemorySize(art, false);\n-\t\tD_ASSERT(art.memory_size >= old_memory_size);\n-\t\tif (art.track_memory) {\n-\t\t\tart.buffer_manager.IncreaseUsedMemory(art.memory_size - old_memory_size);\n-\t\t}\n+\t\tart.IncreaseMemorySize(leaf->MemorySize(art, false));\n \t\treturn leaf;\n \t}\n \tcase NodeType::N4: {\n@@ -331,11 +326,7 @@ Node *Node::Deserialize(ART &art, idx_t block_id, idx_t offset) {\n \t\tthrow InternalException(\"Unrecognized node type\");\n \t}\n \tdeserialized_node->DeserializeInternal(art, reader);\n-\tart.memory_size += deserialized_node->MemorySize(art, false);\n-\tD_ASSERT(art.memory_size >= old_memory_size);\n-\tif (art.track_memory) {\n-\t\tart.buffer_manager.IncreaseUsedMemory(art.memory_size - old_memory_size);\n-\t}\n+\tart.IncreaseMemorySize(deserialized_node->MemorySize(art, false));\n \treturn deserialized_node;\n }\n \n@@ -356,12 +347,10 @@ void SwapNodes(MergeInfo &info, ParentsOfNodes &parents) {\n \tauto l_node_memory_size = info.l_node->MemorySize(*info.l_art, true);\n \tauto r_node_memory_size = info.r_node->MemorySize(*info.r_art, true);\n \n-\tD_ASSERT(info.root_l_art->memory_size >= l_node_memory_size);\n-\tD_ASSERT(info.root_r_art->memory_size >= r_node_memory_size);\n-\tinfo.root_l_art->memory_size -= l_node_memory_size;\n-\tinfo.root_r_art->memory_size -= r_node_memory_size;\n-\tinfo.root_l_art->memory_size += r_node_memory_size;\n-\tinfo.root_r_art->memory_size += l_node_memory_size;\n+\tinfo.root_l_art->DecreaseMemorySize(l_node_memory_size);\n+\tinfo.root_r_art->DecreaseMemorySize(r_node_memory_size);\n+\tinfo.root_l_art->IncreaseMemorySize(r_node_memory_size);\n+\tinfo.root_r_art->IncreaseMemorySize(l_node_memory_size);\n \n \t// actual swap\n \tswap(info.l_art, info.r_art);\n@@ -409,9 +398,8 @@ bool Merge(MergeInfo &info, ParentsOfNodes &parents) {\n \t\t\tauto r_memory_size = r_child->MemorySize(*info.r_art, true);\n \t\t\tNode::InsertChild(*info.root_l_art, info.l_node, key_byte, r_child);\n \n-\t\t\tinfo.root_l_art->memory_size += r_memory_size;\n-\t\t\tD_ASSERT(info.root_r_art->memory_size >= r_memory_size);\n-\t\t\tinfo.root_r_art->memory_size -= r_memory_size;\n+\t\t\tinfo.root_l_art->IncreaseMemorySize(r_memory_size);\n+\t\t\tinfo.root_r_art->DecreaseMemorySize(r_memory_size);\n \t\t\tif (parents.l_parent) {\n \t\t\t\tparents.l_parent->ReplaceChildPointer(parents.l_pos, info.l_node);\n \t\t\t}\n@@ -473,9 +461,8 @@ bool ResolvePrefixesAndMerge(MergeInfo &info, ParentsOfNodes &parents) {\n \t\t\tauto r_memory_size = r_node->MemorySize(*info.r_art, true);\n \t\t\tNode::InsertChild(*info.root_l_art, l_node, mismatch_byte, r_node);\n \n-\t\t\tinfo.root_l_art->memory_size += r_memory_size;\n-\t\t\tD_ASSERT(info.root_r_art->memory_size >= r_memory_size);\n-\t\t\tinfo.root_r_art->memory_size -= r_memory_size;\n+\t\t\tinfo.root_l_art->IncreaseMemorySize(r_memory_size);\n+\t\t\tinfo.root_r_art->DecreaseMemorySize(r_memory_size);\n \t\t\tUpdateParentsOfNodes(l_node, null_parent, parents);\n \t\t\tr_node = nullptr;\n \t\t\treturn true;\n@@ -493,7 +480,7 @@ bool ResolvePrefixesAndMerge(MergeInfo &info, ParentsOfNodes &parents) {\n \t// create new node\n \tNode *new_node = Node4::New();\n \tnew_node->prefix = Prefix(l_node->prefix, mismatch_pos);\n-\tinfo.root_l_art->memory_size += new_node->MemorySize(*info.l_art, false);\n+\tinfo.root_l_art->IncreaseMemorySize(new_node->MemorySize(*info.l_art, false));\n \n \t// insert l_node, break up prefix of l_node\n \tauto key_byte = l_node->prefix.Reduce(*info.root_l_art, mismatch_pos);\n@@ -504,9 +491,8 @@ bool ResolvePrefixesAndMerge(MergeInfo &info, ParentsOfNodes &parents) {\n \tauto r_memory_size = r_node->MemorySize(*info.r_art, true);\n \tNode4::InsertChild(*info.root_l_art, new_node, key_byte, r_node);\n \n-\tinfo.root_l_art->memory_size += r_memory_size;\n-\tD_ASSERT(info.root_r_art->memory_size >= r_memory_size);\n-\tinfo.root_r_art->memory_size -= r_memory_size;\n+\tinfo.root_l_art->IncreaseMemorySize(r_memory_size);\n+\tinfo.root_r_art->DecreaseMemorySize(r_memory_size);\n \n \tl_node = new_node;\n \tUpdateParentsOfNodes(l_node, null_parent, parents);\ndiff --git a/src/execution/index/art/node16.cpp b/src/execution/index/art/node16.cpp\nindex f54977512d73..ecf95705bc81 100644\n--- a/src/execution/index/art/node16.cpp\n+++ b/src/execution/index/art/node16.cpp\n@@ -104,7 +104,7 @@ void Node16::InsertChild(ART &art, Node *&node, uint8_t key_byte, Node *new_chil\n \t} else {\n \t\t// node is full, grow to Node48\n \t\tauto new_node = Node48::New();\n-\t\tart.memory_size += new_node->MemorySize(art, false);\n+\t\tart.IncreaseMemorySize(new_node->MemorySize(art, false));\n \t\tnew_node->count = node->count;\n \t\tnew_node->prefix = std::move(n->prefix);\n \n@@ -114,8 +114,7 @@ void Node16::InsertChild(ART &art, Node *&node, uint8_t key_byte, Node *new_chil\n \t\t\tn->children[i] = nullptr;\n \t\t}\n \n-\t\tD_ASSERT(art.memory_size >= node->MemorySize(art, false));\n-\t\tart.memory_size -= node->MemorySize(art, false);\n+\t\tart.DecreaseMemorySize(node->MemorySize(art, false));\n \t\tNode::Delete(node);\n \t\tnode = new_node;\n \t\tNode48::InsertChild(art, node, key_byte, new_child);\n@@ -130,8 +129,7 @@ void Node16::EraseChild(ART &art, Node *&node, idx_t pos) {\n \t// adjust the ART size\n \tif (n->ChildIsInMemory(pos)) {\n \t\tauto child = n->GetChild(art, pos);\n-\t\tD_ASSERT(art.memory_size >= child->MemorySize(art, true));\n-\t\tart.memory_size -= child->MemorySize(art, true);\n+\t\tart.DecreaseMemorySize(child->MemorySize(art, true));\n \t}\n \n \t// erase the child and decrease the count\n@@ -155,7 +153,7 @@ void Node16::EraseChild(ART &art, Node *&node, idx_t pos) {\n \tif (node->count < Node4::GetSize()) {\n \n \t\tauto new_node = Node4::New();\n-\t\tart.memory_size += new_node->MemorySize(art, false);\n+\t\tart.IncreaseMemorySize(new_node->MemorySize(art, false));\n \t\tnew_node->prefix = std::move(n->prefix);\n \n \t\tfor (idx_t i = 0; i < n->count; i++) {\n@@ -164,8 +162,7 @@ void Node16::EraseChild(ART &art, Node *&node, idx_t pos) {\n \t\t\tn->children[i] = nullptr;\n \t\t}\n \n-\t\tD_ASSERT(art.memory_size >= node->MemorySize(art, false));\n-\t\tart.memory_size -= node->MemorySize(art, false);\n+\t\tart.DecreaseMemorySize(node->MemorySize(art, false));\n \t\tNode::Delete(node);\n \t\tnode = new_node;\n \t}\ndiff --git a/src/execution/index/art/node256.cpp b/src/execution/index/art/node256.cpp\nindex 0ee325406b77..a8c728500d10 100644\n--- a/src/execution/index/art/node256.cpp\n+++ b/src/execution/index/art/node256.cpp\n@@ -92,8 +92,7 @@ void Node256::EraseChild(ART &art, Node *&node, idx_t pos) {\n \t// adjust the ART size\n \tif (n->ChildIsInMemory(pos)) {\n \t\tauto child = n->GetChild(art, pos);\n-\t\tD_ASSERT(art.memory_size >= child->MemorySize(art, true));\n-\t\tart.memory_size -= child->MemorySize(art, true);\n+\t\tart.DecreaseMemorySize(child->MemorySize(art, true));\n \t}\n \n \t// erase the child and decrease the count\n@@ -104,7 +103,7 @@ void Node256::EraseChild(ART &art, Node *&node, idx_t pos) {\n \tif (node->count <= NODE_256_SHRINK_THRESHOLD) {\n \n \t\tauto new_node = Node48::New();\n-\t\tart.memory_size += new_node->MemorySize(art, false);\n+\t\tart.IncreaseMemorySize(new_node->MemorySize(art, false));\n \t\tnew_node->prefix = std::move(n->prefix);\n \n \t\tfor (idx_t i = 0; i < Node256::GetSize(); i++) {\n@@ -115,8 +114,7 @@ void Node256::EraseChild(ART &art, Node *&node, idx_t pos) {\n \t\t\t}\n \t\t}\n \n-\t\tD_ASSERT(art.memory_size >= node->MemorySize(art, false));\n-\t\tart.memory_size -= node->MemorySize(art, false);\n+\t\tart.DecreaseMemorySize(node->MemorySize(art, false));\n \t\tNode::Delete(node);\n \t\tnode = new_node;\n \t}\ndiff --git a/src/execution/index/art/node4.cpp b/src/execution/index/art/node4.cpp\nindex af85280647b7..5b67c0a1972c 100644\n--- a/src/execution/index/art/node4.cpp\n+++ b/src/execution/index/art/node4.cpp\n@@ -101,7 +101,7 @@ void Node4::InsertChild(ART &art, Node *&node, uint8_t key_byte, Node *new_child\n \t} else {\n \t\t// node is full, grow to Node16\n \t\tauto new_node = Node16::New();\n-\t\tart.memory_size += new_node->MemorySize(art, false);\n+\t\tart.IncreaseMemorySize(new_node->MemorySize(art, false));\n \t\tnew_node->count = n->count;\n \t\tnew_node->prefix = std::move(node->prefix);\n \n@@ -112,8 +112,7 @@ void Node4::InsertChild(ART &art, Node *&node, uint8_t key_byte, Node *new_child\n \t\t}\n \t\tn->count = 0;\n \n-\t\tD_ASSERT(art.memory_size >= node->MemorySize(art, false));\n-\t\tart.memory_size -= node->MemorySize(art, false);\n+\t\tart.DecreaseMemorySize(node->MemorySize(art, false));\n \t\tNode::Delete(node);\n \t\tnode = new_node;\n \t\tNode16::InsertChild(art, node, key_byte, new_child);\n@@ -129,8 +128,7 @@ void Node4::EraseChild(ART &art, Node *&node, idx_t pos) {\n \t// adjust the ART size\n \tif (n->ChildIsInMemory(pos)) {\n \t\tauto child = n->GetChild(art, pos);\n-\t\tD_ASSERT(art.memory_size >= child->MemorySize(art, true));\n-\t\tart.memory_size -= child->MemorySize(art, true);\n+\t\tart.DecreaseMemorySize(child->MemorySize(art, true));\n \t}\n \n \t// erase the child and decrease the count\n@@ -158,8 +156,7 @@ void Node4::EraseChild(ART &art, Node *&node, idx_t pos) {\n \t\t// ensure that when deleting the node, we do not delete the child (because we move it)\n \t\tn->children[0] = nullptr;\n \n-\t\tD_ASSERT(art.memory_size >= n->MemorySize(art, false));\n-\t\tart.memory_size -= n->MemorySize(art, false);\n+\t\tart.DecreaseMemorySize(n->MemorySize(art, false));\n \t\tNode::Delete(node);\n \t\tnode = child_ref;\n \t}\ndiff --git a/src/execution/index/art/node48.cpp b/src/execution/index/art/node48.cpp\nindex 33f04a2e90d5..574b3890d051 100644\n--- a/src/execution/index/art/node48.cpp\n+++ b/src/execution/index/art/node48.cpp\n@@ -105,7 +105,7 @@ void Node48::InsertChild(ART &art, Node *&node, uint8_t key_byte, Node *new_chil\n \t} else {\n \t\t// node is full, grow to Node256\n \t\tauto new_node = Node256::New();\n-\t\tart.memory_size += new_node->MemorySize(art, false);\n+\t\tart.IncreaseMemorySize(new_node->MemorySize(art, false));\n \t\tnew_node->count = n->count;\n \t\tnew_node->prefix = std::move(n->prefix);\n \n@@ -116,8 +116,7 @@ void Node48::InsertChild(ART &art, Node *&node, uint8_t key_byte, Node *new_chil\n \t\t\t}\n \t\t}\n \n-\t\tD_ASSERT(art.memory_size >= node->MemorySize(art, false));\n-\t\tart.memory_size -= node->MemorySize(art, false);\n+\t\tart.DecreaseMemorySize(node->MemorySize(art, false));\n \t\tNode::Delete(node);\n \t\tnode = new_node;\n \t\tNode256::InsertChild(art, node, key_byte, new_child);\n@@ -130,8 +129,7 @@ void Node48::EraseChild(ART &art, Node *&node, idx_t pos) {\n \t// adjust the ART size\n \tif (n->ChildIsInMemory(pos)) {\n \t\tauto child = n->GetChild(art, pos);\n-\t\tD_ASSERT(art.memory_size >= child->MemorySize(art, true));\n-\t\tart.memory_size -= child->MemorySize(art, true);\n+\t\tart.DecreaseMemorySize(child->MemorySize(art, true));\n \t}\n \n \t// erase the child and decrease the count\n@@ -143,7 +141,7 @@ void Node48::EraseChild(ART &art, Node *&node, idx_t pos) {\n \tif (node->count < NODE_48_SHRINK_THRESHOLD) {\n \n \t\tauto new_node = Node16::New();\n-\t\tart.memory_size += new_node->MemorySize(art, false);\n+\t\tart.IncreaseMemorySize(new_node->MemorySize(art, false));\n \t\tnew_node->prefix = std::move(n->prefix);\n \n \t\tfor (idx_t i = 0; i < Node256::GetSize(); i++) {\n@@ -154,8 +152,7 @@ void Node48::EraseChild(ART &art, Node *&node, idx_t pos) {\n \t\t\t}\n \t\t}\n \n-\t\tD_ASSERT(art.memory_size >= node->MemorySize(art, false));\n-\t\tart.memory_size -= node->MemorySize(art, false);\n+\t\tart.DecreaseMemorySize(node->MemorySize(art, false));\n \t\tNode::Delete(node);\n \t\tnode = new_node;\n \t}\ndiff --git a/src/execution/index/art/prefix.cpp b/src/execution/index/art/prefix.cpp\nindex 2c3217bacd5a..b7f74fe4b0d5 100644\n--- a/src/execution/index/art/prefix.cpp\n+++ b/src/execution/index/art/prefix.cpp\n@@ -113,7 +113,7 @@ void Prefix::Overwrite(uint32_t new_size, uint8_t *data) {\n \n void Prefix::Concatenate(ART &art, uint8_t key, Prefix &other) {\n \tauto new_size = size + 1 + other.size;\n-\tart.memory_size += (new_size - size) * sizeof(uint8_t);\n+\tart.IncreaseMemorySize((new_size - size) * sizeof(uint8_t));\n \t// have to allocate space in our prefix array\n \tauto new_prefix = AllocateArray<uint8_t>(new_size);\n \tidx_t new_prefix_idx = 0;\n@@ -136,8 +136,7 @@ void Prefix::Concatenate(ART &art, uint8_t key, Prefix &other) {\n \n uint8_t Prefix::Reduce(ART &art, uint32_t n) {\n \tauto new_size = size - n - 1;\n-\tD_ASSERT(art.memory_size >= (size - new_size) * sizeof(uint8_t));\n-\tart.memory_size -= (size - new_size) * sizeof(uint8_t);\n+\tart.DecreaseMemorySize((size - new_size) * sizeof(uint8_t));\n \tauto prefix = GetPrefixData();\n \tauto partial_key = prefix[n];\n \ndiff --git a/src/function/table/table_scan.cpp b/src/function/table/table_scan.cpp\nindex c344ed3b4fc4..bdae6419c951 100644\n--- a/src/function/table/table_scan.cpp\n+++ b/src/function/table/table_scan.cpp\n@@ -287,9 +287,12 @@ void TableScanPushdownComplexFilter(ClientContext &context, LogicalGet &get, Fun\n \t// behold\n \tstorage.info->indexes.Scan([&](Index &index) {\n \t\t// first rewrite the index expression so the ColumnBindings align with the column bindings of the current table\n+\n \t\tif (index.unbound_expressions.size() > 1) {\n+\t\t\t// NOTE: index scans are not (yet) supported for compound index keys\n \t\t\treturn false;\n \t\t}\n+\n \t\tauto index_expression = index.unbound_expressions[0]->Copy();\n \t\tbool rewrite_possible = true;\n \t\tRewriteIndexExpression(index, get, *index_expression, rewrite_possible);\ndiff --git a/src/include/duckdb/catalog/catalog.hpp b/src/include/duckdb/catalog/catalog.hpp\nindex 2fd42f042176..f14a3869d917 100644\n--- a/src/include/duckdb/catalog/catalog.hpp\n+++ b/src/include/duckdb/catalog/catalog.hpp\n@@ -29,6 +29,7 @@ struct CreateFunctionInfo;\n struct CreateViewInfo;\n struct CreateSequenceInfo;\n struct CreateCollationInfo;\n+struct CreateIndexInfo;\n struct CreateTypeInfo;\n struct CreateTableInfo;\n struct DatabaseSize;\n@@ -137,6 +138,9 @@ class Catalog {\n \t//! Creates a collation in the catalog\n \tDUCKDB_API CatalogEntry *CreateCollation(CatalogTransaction transaction, CreateCollationInfo *info);\n \tDUCKDB_API CatalogEntry *CreateCollation(ClientContext &context, CreateCollationInfo *info);\n+\t//! Creates an index in the catalog\n+\tDUCKDB_API CatalogEntry *CreateIndex(CatalogTransaction transaction, CreateIndexInfo *info);\n+\tDUCKDB_API CatalogEntry *CreateIndex(ClientContext &context, CreateIndexInfo *info);\n \n \t//! Creates a table in the catalog.\n \tDUCKDB_API CatalogEntry *CreateTable(CatalogTransaction transaction, SchemaCatalogEntry *schema,\n@@ -153,7 +157,7 @@ class Catalog {\n \t//! Create a scalar or aggregate function in the catalog\n \tDUCKDB_API CatalogEntry *CreateFunction(CatalogTransaction transaction, SchemaCatalogEntry *schema,\n \t                                        CreateFunctionInfo *info);\n-\t//! Creates a table in the catalog.\n+\t//! Creates a view in the catalog\n \tDUCKDB_API CatalogEntry *CreateView(CatalogTransaction transaction, SchemaCatalogEntry *schema,\n \t                                    CreateViewInfo *info);\n \t//! Creates a table in the catalog.\ndiff --git a/src/include/duckdb/catalog/catalog_entry/duck_index_entry.hpp b/src/include/duckdb/catalog/catalog_entry/duck_index_entry.hpp\nindex b438ed5ea786..a3f085250d3d 100644\n--- a/src/include/duckdb/catalog/catalog_entry/duck_index_entry.hpp\n+++ b/src/include/duckdb/catalog/catalog_entry/duck_index_entry.hpp\n@@ -1,7 +1,7 @@\n //===----------------------------------------------------------------------===//\n //                         DuckDB\n //\n-// duckdb/catalog/catalog_entry/dindex_catalog_entry.hpp\n+// duckdb/catalog/catalog_entry/duck_index_entry.hpp\n //\n //\n //===----------------------------------------------------------------------===//\ndiff --git a/src/include/duckdb/catalog/catalog_entry/index_catalog_entry.hpp b/src/include/duckdb/catalog/catalog_entry/index_catalog_entry.hpp\nindex 769cab9495c5..e71c7e38f05d 100644\n--- a/src/include/duckdb/catalog/catalog_entry/index_catalog_entry.hpp\n+++ b/src/include/duckdb/catalog/catalog_entry/index_catalog_entry.hpp\n@@ -34,7 +34,7 @@ class IndexCatalogEntry : public StandardEntry {\n \n public:\n \tstring ToSQL() override;\n-\tvoid Serialize(duckdb::MetaBlockWriter &serializer);\n+\tvoid Serialize(Serializer &serializer);\n \tstatic unique_ptr<CreateIndexInfo> Deserialize(Deserializer &source, ClientContext &context);\n \n \tvirtual string GetSchemaName() = 0;\ndiff --git a/src/include/duckdb/common/enums/wal_type.hpp b/src/include/duckdb/common/enums/wal_type.hpp\nindex 6f3167556bd4..b18fa9f16ba7 100644\n--- a/src/include/duckdb/common/enums/wal_type.hpp\n+++ b/src/include/duckdb/common/enums/wal_type.hpp\n@@ -41,6 +41,9 @@ enum class WALType : uint8_t {\n \tCREATE_TABLE_MACRO = 21,\n \tDROP_TABLE_MACRO = 22,\n \n+\tCREATE_INDEX = 23,\n+\tDROP_INDEX = 24,\n+\n \t// -----------------------------\n \t// Data\n \t// -----------------------------\ndiff --git a/src/include/duckdb/execution/index/art/art.hpp b/src/include/duckdb/execution/index/art/art.hpp\nindex b9c4286192bc..669ea66824f5 100644\n--- a/src/include/duckdb/execution/index/art/art.hpp\n+++ b/src/include/duckdb/execution/index/art/art.hpp\n@@ -29,24 +29,21 @@ namespace duckdb {\n class ConflictManager;\n \n struct ARTIndexScanState : public IndexScanState {\n-\tARTIndexScanState() : checked(false), result_index(0) {\n-\t}\n \n+\t//! Scan predicates (single predicate scan or range scan)\n \tValue values[2];\n+\t//! Expressions of the scan predicates\n \tExpressionType expressions[2];\n-\tbool checked;\n+\tbool checked = false;\n+\t//! All scanned row IDs\n \tvector<row_t> result_ids;\n \tIterator iterator;\n-\t//! Stores the current leaf\n-\tLeaf *cur_leaf = nullptr;\n-\t//! Offset to leaf\n-\tidx_t result_index = 0;\n };\n \n enum class VerifyExistenceType : uint8_t {\n-\tAPPEND = 0,    // for purpose to append into table\n-\tAPPEND_FK = 1, // for purpose to append into table has foreign key\n-\tDELETE_FK = 2  // for purpose to delete from table related to foreign key\n+\tAPPEND = 0,    // appends to a table\n+\tAPPEND_FK = 1, // appends to a table that has a foreign key\n+\tDELETE_FK = 2  // delete from a table that has a foreign key\n };\n \n class ART : public Index {\n@@ -62,47 +59,44 @@ class ART : public Index {\n \tNode *tree;\n \n public:\n-\t//! Initialize a scan on the index with the given expression and column ids\n-\t//! to fetch from the base table for a single predicate\n+\t//! Initialize a single predicate scan on the index with the given expression and column IDs\n \tunique_ptr<IndexScanState> InitializeScanSinglePredicate(const Transaction &transaction, const Value &value,\n \t                                                         ExpressionType expression_type) override;\n-\n-\t//! Initialize a scan on the index with the given expression and column ids\n-\t//! to fetch from the base table for two predicates\n+\t//! Initialize a two predicate scan on the index with the given expression and column IDs\n \tunique_ptr<IndexScanState> InitializeScanTwoPredicates(Transaction &transaction, const Value &low_value,\n \t                                                       ExpressionType low_expression_type, const Value &high_value,\n \t                                                       ExpressionType high_expression_type) override;\n-\n-\t//! Perform a lookup on the index\n+\t//! Performs a lookup on the index, fetching up to max_count result IDs. Returns true if all row IDs were fetched,\n+\t//! and false otherwise\n \tbool Scan(Transaction &transaction, DataTable &table, IndexScanState &state, idx_t max_count,\n \t          vector<row_t> &result_ids) override;\n-\t//! Append entries to the index\n+\n+\t//! Called when data is appended to the index. The lock obtained from InitializeLock must be held\n \tbool Append(IndexLock &lock, DataChunk &entries, Vector &row_identifiers) override;\n-\t//! Verify that data can be appended to the index\n+\t//! Verify that data can be appended to the index without a constraint violation\n \tvoid VerifyAppend(DataChunk &chunk) override;\n-\t//! Verify that data can be appended to the index\n+\t//! Verify that data can be appended to the index without a constraint violation using the conflict manager\n \tvoid VerifyAppend(DataChunk &chunk, ConflictManager &conflict_manager) override;\n-\t//! Verify that data can be appended to the index for foreign key constraint\n-\tvoid VerifyAppendForeignKey(DataChunk &chunk) override;\n-\t//! Verify that data can be delete from the index for foreign key constraint\n-\tvoid VerifyDeleteForeignKey(DataChunk &chunk) override;\n-\t//! Delete entries in the index\n+\t//! Delete a chunk of entries from the index. The lock obtained from InitializeLock must be held\n \tvoid Delete(IndexLock &lock, DataChunk &entries, Vector &row_identifiers) override;\n-\t//! Insert data into the index\n+\t//! Insert a chunk of entries into the index\n \tbool Insert(IndexLock &lock, DataChunk &data, Vector &row_ids) override;\n \n \t//! Construct an ART from a vector of sorted keys\n \tbool ConstructFromSorted(idx_t count, vector<Key> &keys, Vector &row_identifiers);\n \n-\t//! Search Equal and fetches the row IDs\n+\t//! Search equal values and fetches the row IDs\n \tbool SearchEqual(Key &key, idx_t max_count, vector<row_t> &result_ids);\n-\t//! Search Equal used for Joins that do not need to fetch data\n+\t//! Search equal values used for joins that do not need to fetch data\n \tvoid SearchEqualJoinNoFetch(Key &key, idx_t &result_size);\n-\t//! Serialized the ART\n+\n+\t//! Serializes the index and returns the pair of block_id offset positions\n \tBlockPointer Serialize(duckdb::MetaBlockWriter &writer) override;\n \n-\t//! Merge two ARTs\n+\t//! Merge another index into this index. The lock obtained from InitializeLock must be held, and the other\n+\t//! index must also be locked during the merge\n \tbool MergeIndexes(IndexLock &state, Index *other_index) override;\n+\n \t//! Generate ART keys for an input chunk\n \tstatic void GenerateKeys(ArenaAllocator &allocator, DataChunk &input, vector<Key> &keys);\n \n@@ -110,30 +104,32 @@ class ART : public Index {\n \tstring GenerateErrorKeyName(DataChunk &input, idx_t row);\n \t//! Generate the matching error message for a constraint violation\n \tstring GenerateConstraintErrorMessage(VerifyExistenceType verify_type, const string &key_name);\n+\t//! Performs constraint checking for a chunk of input data\n+\tvoid CheckConstraintsForChunk(DataChunk &input, ConflictManager &conflict_manager) override;\n \n \t//! Returns the string representation of an ART\n \tstring ToString() override;\n-\t//! Verifies that the memory_size value of the ART matches its actual size\n+\t//! Verifies that the in-memory size value of the index matches its actual size\n \tvoid Verify() override;\n+\t//! Increases the memory size by the difference between the old size and the current size\n+\t//! and performs verifications\n+\tvoid IncreaseAndVerifyMemorySize(idx_t old_memory_size) override;\n \n private:\n-\t//! Insert a row id into a leaf node\n+\t//! Insert a row ID into a leaf\n \tbool InsertToLeaf(Leaf &leaf, row_t row_id);\n-\t//! Insert the leaf value into the tree\n+\t//! Insert a key into the tree\n \tbool Insert(Node *&node, Key &key, idx_t depth, row_t row_id);\n-\n-\t//! Erase element from leaf (if leaf has more than one value) or eliminate the leaf itself\n+\t//! Erase a key from the tree (if a leaf has more than one value) or erase the leaf itself\n \tvoid Erase(Node *&node, Key &key, idx_t depth, row_t row_id);\n-\n-\t//! Perform 'Lookup' for an entire chunk, marking which succeeded\n-\tvoid LookupValues(DataChunk &input, ConflictManager &conflict_manager) final override;\n-\n-\t//! Find the node with a matching key, optimistic version\n+\t//! Find the node with a matching key, or return nullptr if not found\n \tLeaf *Lookup(Node *node, Key &key, idx_t depth);\n-\n+\t//! Returns all row IDs belonging to a key greater (or equal) than the search key\n \tbool SearchGreater(ARTIndexScanState *state, Key &key, bool inclusive, idx_t max_count, vector<row_t> &result_ids);\n+\t//! Returns all row IDs belonging to a key less (or equal) than the upper_bound\n \tbool SearchLess(ARTIndexScanState *state, Key &upper_bound, bool inclusive, idx_t max_count,\n \t                vector<row_t> &result_ids);\n+\t//! Returns all row IDs belonging to a key within the range of lower_bound and upper_bound\n \tbool SearchCloseRange(ARTIndexScanState *state, Key &lower_bound, Key &upper_bound, bool left_inclusive,\n \t                      bool right_inclusive, idx_t max_count, vector<row_t> &result_ids);\n };\ndiff --git a/src/include/duckdb/execution/index/art/art_key.hpp b/src/include/duckdb/execution/index/art/art_key.hpp\nindex 1b840cfee825..fcde605095b0 100644\n--- a/src/include/duckdb/execution/index/art/art_key.hpp\n+++ b/src/include/duckdb/execution/index/art/art_key.hpp\n@@ -28,24 +28,24 @@ class Key {\n \n public:\n \ttemplate <class T>\n-\tstatic inline Key CreateKey(ArenaAllocator &allocator, T element) {\n+\tstatic inline Key CreateKey(ArenaAllocator &allocator, const LogicalType &type, T element) {\n \t\tauto data = Key::CreateData<T>(allocator, element);\n \t\treturn Key(data, sizeof(element));\n \t}\n \n \ttemplate <class T>\n-\tstatic inline Key CreateKey(ArenaAllocator &allocator, const Value &element) {\n-\t\treturn CreateKey(allocator, element.GetValueUnsafe<T>());\n+\tstatic inline Key CreateKey(ArenaAllocator &allocator, const LogicalType &type, const Value &element) {\n+\t\treturn CreateKey(allocator, type, element.GetValueUnsafe<T>());\n \t}\n \n \ttemplate <class T>\n-\tstatic inline void CreateKey(ArenaAllocator &allocator, Key &key, T element) {\n+\tstatic inline void CreateKey(ArenaAllocator &allocator, const LogicalType &type, Key &key, T element) {\n \t\tkey.data = Key::CreateData<T>(allocator, element);\n \t\tkey.len = sizeof(element);\n \t}\n \n \ttemplate <class T>\n-\tstatic inline void CreateKey(ArenaAllocator &allocator, Key &key, const Value element) {\n+\tstatic inline void CreateKey(ArenaAllocator &allocator, const LogicalType &type, Key &key, const Value element) {\n \t\tkey.data = Key::CreateData<T>(allocator, element.GetValueUnsafe<T>());\n \t\tkey.len = sizeof(element);\n \t}\n@@ -76,12 +76,9 @@ class Key {\n };\n \n template <>\n-Key Key::CreateKey(ArenaAllocator &allocator, string_t value);\n+Key Key::CreateKey(ArenaAllocator &allocator, const LogicalType &type, string_t value);\n template <>\n-Key Key::CreateKey(ArenaAllocator &allocator, const char *value);\n+Key Key::CreateKey(ArenaAllocator &allocator, const LogicalType &type, const char *value);\n template <>\n-void Key::CreateKey(ArenaAllocator &allocator, Key &key, string_t value);\n-template <>\n-void Key::CreateKey(ArenaAllocator &allocator, Key &key, const char *value);\n-\n+void Key::CreateKey(ArenaAllocator &allocator, const LogicalType &type, Key &key, string_t value);\n } // namespace duckdb\ndiff --git a/src/include/duckdb/planner/binder.hpp b/src/include/duckdb/planner/binder.hpp\nindex 576216ca2a06..aa0b654047d0 100644\n--- a/src/include/duckdb/planner/binder.hpp\n+++ b/src/include/duckdb/planner/binder.hpp\n@@ -108,6 +108,9 @@ class Binder : public std::enable_shared_from_this<Binder> {\n \n \tunique_ptr<BoundCreateTableInfo> BindCreateTableInfo(unique_ptr<CreateInfo> info);\n \tunique_ptr<BoundCreateTableInfo> BindCreateTableInfo(unique_ptr<CreateInfo> info, SchemaCatalogEntry *schema);\n+\n+\tvector<unique_ptr<Expression>> BindCreateIndexExpressions(TableCatalogEntry *table, CreateIndexInfo *info);\n+\n \tvoid BindCreateViewInfo(CreateViewInfo &base);\n \tSchemaCatalogEntry *BindSchema(CreateInfo &info);\n \tSchemaCatalogEntry *BindCreateFunctionInfo(CreateInfo &info);\ndiff --git a/src/include/duckdb/planner/expression_binder/index_binder.hpp b/src/include/duckdb/planner/expression_binder/index_binder.hpp\nindex 13b6ec22ca09..f238b70f4830 100644\n--- a/src/include/duckdb/planner/expression_binder/index_binder.hpp\n+++ b/src/include/duckdb/planner/expression_binder/index_binder.hpp\n@@ -10,20 +10,27 @@\n \n #include \"duckdb/planner/expression_binder.hpp\"\n #include \"duckdb/common/unordered_map.hpp\"\n+#include \"duckdb/parser/parsed_data/create_index_info.hpp\"\n+#include \"duckdb/catalog/catalog_entry/table_catalog_entry.hpp\"\n \n namespace duckdb {\n class BoundColumnRefExpression;\n \n-//! The INDEX binder is responsible for binding an expression within an Index statement\n+//! The IndexBinder is responsible for binding an expression within an index statement\n class IndexBinder : public ExpressionBinder {\n public:\n-\tIndexBinder(Binder &binder, ClientContext &context);\n+\tIndexBinder(Binder &binder, ClientContext &context, TableCatalogEntry *table = nullptr,\n+\t            CreateIndexInfo *info = nullptr);\n \n protected:\n \tBindResult BindExpression(unique_ptr<ParsedExpression> *expr_ptr, idx_t depth,\n \t                          bool root_expression = false) override;\n-\n \tstring UnsupportedAggregateMessage() override;\n+\n+private:\n+\t// only for WAL replay\n+\tTableCatalogEntry *table;\n+\tCreateIndexInfo *info;\n };\n \n } // namespace duckdb\ndiff --git a/src/include/duckdb/storage/data_table.hpp b/src/include/duckdb/storage/data_table.hpp\nindex ceff4e4e6e22..aa4612c0fe15 100644\n--- a/src/include/duckdb/storage/data_table.hpp\n+++ b/src/include/duckdb/storage/data_table.hpp\n@@ -122,6 +122,12 @@ class DataTable {\n \tvoid UpdateColumn(TableCatalogEntry &table, ClientContext &context, Vector &row_ids,\n \t                  const vector<column_t> &column_path, DataChunk &updates);\n \n+\t//! Add an index to the DataTable. NOTE: for CREATE (UNIQUE) INDEX statements, we use the PhysicalCreateIndex\n+\t//! operator. This function is only used during the WAL replay, and is a much less performant index creation\n+\t//! approach.\n+\tvoid WALAddIndex(ClientContext &context, unique_ptr<Index> index,\n+\t                 const vector<unique_ptr<Expression>> &expressions);\n+\n \t//! Fetches an append lock\n \tvoid AppendLock(TableAppendState &state);\n \t//! Begin appending structs to this table, obtaining necessary locks, etc\n@@ -176,7 +182,7 @@ class DataTable {\n \tstatic bool IsForeignKeyIndex(const vector<PhysicalIndex> &fk_keys, Index &index, ForeignKeyType fk_type);\n \n \t//! Initializes a special scan that is used to create an index on the table, it keeps locks on the table\n-\tvoid InitializeCreateIndexScan(CreateIndexScanState &state, const vector<column_t> &column_ids);\n+\tvoid InitializeWALCreateIndexScan(CreateIndexScanState &state, const vector<column_t> &column_ids);\n \t//! Scans the next chunk for the CREATE INDEX operator\n \tbool CreateIndexScan(TableScanState &state, DataChunk &result, TableScanType type);\n \ndiff --git a/src/include/duckdb/storage/index.hpp b/src/include/duckdb/storage/index.hpp\nindex 564448ebd839..7383654085f2 100644\n--- a/src/include/duckdb/storage/index.hpp\n+++ b/src/include/duckdb/storage/index.hpp\n@@ -40,11 +40,11 @@ class Index {\n \tIndexType type;\n \t//! Associated table io manager\n \tTableIOManager &table_io_manager;\n-\t//! Column identifiers to extract from the base table\n+\t//! Column identifiers to extract key columns from the base table\n \tvector<column_t> column_ids;\n-\t//! Unordered_set of column_ids used by the index\n+\t//! Unordered set of column_ids used by the index\n \tunordered_set<column_t> column_id_set;\n-\t//! Unbound expressions used by the index\n+\t//! Unbound expressions used by the index during optimizations\n \tvector<unique_ptr<Expression>> unbound_expressions;\n \t//! The physical types stored in the index\n \tvector<PhysicalType> types;\n@@ -64,94 +64,103 @@ class Index {\n \tbool track_memory;\n \n public:\n-\t//! Initialize a scan on the index with the given expression and column ids\n-\t//! to fetch from the base table when we only have one query predicate\n+\t//! Initialize a single predicate scan on the index with the given expression and column IDs\n \tvirtual unique_ptr<IndexScanState> InitializeScanSinglePredicate(const Transaction &transaction, const Value &value,\n \t                                                                 ExpressionType expressionType) = 0;\n-\t//! Initialize a scan on the index with the given expression and column ids\n-\t//! to fetch from the base table for two query predicates\n+\t//! Initialize a two predicate scan on the index with the given expression and column IDs\n \tvirtual unique_ptr<IndexScanState> InitializeScanTwoPredicates(Transaction &transaction, const Value &low_value,\n \t                                                               ExpressionType low_expression_type,\n \t                                                               const Value &high_value,\n \t                                                               ExpressionType high_expression_type) = 0;\n-\t//! Perform a lookup on the index, fetching up to max_count result ids. Returns true if all row ids were fetched,\n-\t//! and false otherwise.\n+\t//! Performs a lookup on the index, fetching up to max_count result IDs. Returns true if all row IDs were fetched,\n+\t//! and false otherwise\n \tvirtual bool Scan(Transaction &transaction, DataTable &table, IndexScanState &state, idx_t max_count,\n \t                  vector<row_t> &result_ids) = 0;\n \n \t//! Obtain a lock on the index\n \tvirtual void InitializeLock(IndexLock &state);\n-\t//! Called when data is appended to the index. The lock obtained from InitializeAppend must be held\n+\t//! Called when data is appended to the index. The lock obtained from InitializeLock must be held\n \tvirtual bool Append(IndexLock &state, DataChunk &entries, Vector &row_identifiers) = 0;\n+\t//! Obtains a lock and calls Append while holding that lock\n \tbool Append(DataChunk &entries, Vector &row_identifiers);\n-\t//! Verify that data can be appended to the index\n+\t//! Verify that data can be appended to the index without a constraint violation\n \tvirtual void VerifyAppend(DataChunk &chunk) = 0;\n-\t//! Verify that data can be appended to the index\n+\t//! Verify that data can be appended to the index without a constraint violation using the conflict manager\n \tvirtual void VerifyAppend(DataChunk &chunk, ConflictManager &conflict_manager) = 0;\n-\t//! Verify that data can be appended to the index for foreign key constraint\n-\tvirtual void VerifyAppendForeignKey(DataChunk &chunk) = 0;\n-\t//! Verify that data can be delete from the index for foreign key constraint\n-\tvirtual void VerifyDeleteForeignKey(DataChunk &chunk) = 0;\n+\t//! Performs constraint checking for a chunk of input data\n+\tvirtual void CheckConstraintsForChunk(DataChunk &input, ConflictManager &conflict_manager) = 0;\n \n-\t//! Called when data inside the index is Deleted\n+\t//! Delete a chunk of entries from the index. The lock obtained from InitializeLock must be held\n \tvirtual void Delete(IndexLock &state, DataChunk &entries, Vector &row_identifiers) = 0;\n+\t//! Obtains a lock and calls Delete while holding that lock\n \tvoid Delete(DataChunk &entries, Vector &row_identifiers);\n \n-\t//! Insert data into the index. Does not lock the index.\n+\t//! Insert a chunk of entries into the index\n \tvirtual bool Insert(IndexLock &lock, DataChunk &input, Vector &row_identifiers) = 0;\n \n-\t//! Merge other_index into this index.\n+\t//! Merge another index into this index. The lock obtained from InitializeLock must be held, and the other\n+\t//! index must also be locked during the merge\n \tvirtual bool MergeIndexes(IndexLock &state, Index *other_index) = 0;\n+\t//! Obtains a lock and calls MergeIndexes while holding that lock\n \tbool MergeIndexes(Index *other_index);\n \n \t//! Returns the string representation of an index\n \tvirtual string ToString() = 0;\n-\t//! Verifies that the memory_size value of the index matches its actual size\n+\t//! Verifies that the in-memory size value of the index matches its actual size\n \tvirtual void Verify() = 0;\n-\n-\t//! Returns true if the index is affected by updates on the specified column ids, and false otherwise\n+\t//! Increases the memory size by the difference between the old size and the current size\n+\t//! and performs verifications\n+\tvirtual void IncreaseAndVerifyMemorySize(idx_t old_memory_size) = 0;\n+\n+\t//! Increases the in-memory size value\n+\tinline void IncreaseMemorySize(idx_t size) {\n+\t\tmemory_size += size;\n+\t};\n+\t//! Decreases the in-memory size value\n+\tinline void DecreaseMemorySize(idx_t size) {\n+\t\tD_ASSERT(memory_size >= size);\n+\t\tmemory_size -= size;\n+\t};\n+\n+\t//! Returns true if the index is affected by updates on the specified column IDs, and false otherwise\n \tbool IndexIsUpdated(const vector<PhysicalIndex> &column_ids) const;\n \n-\t//! Returns how many of the input values were found in the 'input' chunk, with the option to also record what those\n-\t//! matches were. For this purpose, nulls count as a match, and are returned in 'null_count'\n-\tvirtual void LookupValues(DataChunk &input, ConflictManager &conflict_manager) = 0;\n-\n \t//! Returns unique flag\n \tbool IsUnique() {\n \t\treturn (constraint_type == IndexConstraintType::UNIQUE || constraint_type == IndexConstraintType::PRIMARY);\n \t}\n-\t//! Returns primary flag\n+\t//! Returns primary key flag\n \tbool IsPrimary() {\n \t\treturn (constraint_type == IndexConstraintType::PRIMARY);\n \t}\n-\t//! Returns foreign flag\n+\t//! Returns foreign key flag\n \tbool IsForeign() {\n \t\treturn (constraint_type == IndexConstraintType::FOREIGN);\n \t}\n-\t//! Serializes the index and returns the pair of block_id offset positions\n-\tvirtual BlockPointer Serialize(duckdb::MetaBlockWriter &writer);\n-\tBlockPointer GetBlockPointer();\n \n-\t//! Returns block/offset of where index was most recently serialized.\n+\t//! Serializes the index and returns the pair of block_id offset positions\n+\tvirtual BlockPointer Serialize(MetaBlockWriter &writer);\n+\t//! Returns the serialized data pointer to the block and offset of the serialized index\n \tBlockPointer GetSerializedDataPointer() const {\n \t\treturn serialized_data_pointer;\n \t}\n \n-protected:\n+\t//! Execute the index expressions on an input chunk\n \tvoid ExecuteExpressions(DataChunk &input, DataChunk &result);\n \n-\t//! Lock used for updating the index\n+protected:\n+\t//! Lock used for any changes to the index\n \tmutex lock;\n-\n-\t//! Pointer to most recently checkpointed index data.\n+\t//! Pointer to serialized index data\n \tBlockPointer serialized_data_pointer;\n \n private:\n-\t//! Bound expressions used by the index\n+\t//! Bound expressions used during expression execution\n \tvector<unique_ptr<Expression>> bound_expressions;\n-\t//! Expression executor for the index expressions\n+\t//! Expression executor to execute the index expressions\n \tExpressionExecutor executor;\n \n+\t//! Bind the unbound expressions of the index\n \tunique_ptr<Expression> BindExpression(unique_ptr<Expression> expr);\n };\n \ndiff --git a/src/include/duckdb/storage/write_ahead_log.hpp b/src/include/duckdb/storage/write_ahead_log.hpp\nindex 1d9c70608229..653445241987 100644\n--- a/src/include/duckdb/storage/write_ahead_log.hpp\n+++ b/src/include/duckdb/storage/write_ahead_log.hpp\n@@ -15,6 +15,7 @@\n #include \"duckdb/catalog/catalog_entry/scalar_macro_catalog_entry.hpp\"\n #include \"duckdb/catalog/catalog_entry/sequence_catalog_entry.hpp\"\n #include \"duckdb/catalog/catalog_entry/table_macro_catalog_entry.hpp\"\n+#include \"duckdb/catalog/catalog_entry/index_catalog_entry.hpp\"\n #include \"duckdb/main/attached_database.hpp\"\n #include \"duckdb/storage/storage_info.hpp\"\n \n@@ -77,6 +78,9 @@ class ReplayState {\n \tvoid ReplayCreateTableMacro();\n \tvoid ReplayDropTableMacro();\n \n+\tvoid ReplayCreateIndex();\n+\tvoid ReplayDropIndex();\n+\n \tvoid ReplayUseTable();\n \tvoid ReplayInsert();\n \tvoid ReplayDelete();\n@@ -125,6 +129,9 @@ class WriteAheadLog {\n \tvoid WriteCreateTableMacro(TableMacroCatalogEntry *entry);\n \tvoid WriteDropTableMacro(TableMacroCatalogEntry *entry);\n \n+\tvoid WriteCreateIndex(IndexCatalogEntry *entry);\n+\tvoid WriteDropIndex(IndexCatalogEntry *entry);\n+\n \tvoid WriteCreateType(TypeCatalogEntry *entry);\n \tvoid WriteDropType(TypeCatalogEntry *entry);\n \t//! Sets the table used for subsequent insert/delete/update commands\ndiff --git a/src/parser/parsed_data/create_index_info.cpp b/src/parser/parsed_data/create_index_info.cpp\nindex bbf7371be318..dd9608009dc3 100644\n--- a/src/parser/parsed_data/create_index_info.cpp\n+++ b/src/parser/parsed_data/create_index_info.cpp\n@@ -16,6 +16,9 @@ unique_ptr<CreateInfo> CreateIndexInfo::Copy() const {\n \tfor (auto &expr : expressions) {\n \t\tresult->expressions.push_back(expr->Copy());\n \t}\n+\tfor (auto &expr : parsed_expressions) {\n+\t\tresult->parsed_expressions.push_back(expr->Copy());\n+\t}\n \n \tresult->scan_types = scan_types;\n \tresult->names = names;\ndiff --git a/src/planner/binder/statement/bind_create_table.cpp b/src/planner/binder/statement/bind_create_table.cpp\nindex e36f9bd55b9d..2e81ddf2bde1 100644\n--- a/src/planner/binder/statement/bind_create_table.cpp\n+++ b/src/planner/binder/statement/bind_create_table.cpp\n@@ -16,6 +16,8 @@\n #include \"duckdb/parser/expression/list.hpp\"\n #include \"duckdb/common/index_map.hpp\"\n #include \"duckdb/planner/expression_iterator.hpp\"\n+#include \"duckdb/planner/expression_binder/index_binder.hpp\"\n+#include \"duckdb/parser/parsed_data/create_index_info.hpp\"\n \n #include <algorithm>\n \n@@ -300,4 +302,15 @@ unique_ptr<BoundCreateTableInfo> Binder::BindCreateTableInfo(unique_ptr<CreateIn\n \treturn BindCreateTableInfo(std::move(info), schema);\n }\n \n+vector<unique_ptr<Expression>> Binder::BindCreateIndexExpressions(TableCatalogEntry *table, CreateIndexInfo *info) {\n+\tvector<unique_ptr<Expression>> expressions;\n+\n+\tauto index_binder = IndexBinder(*this, this->context, table, info);\n+\tfor (auto &expr : info->expressions) {\n+\t\texpressions.push_back(index_binder.Bind(expr));\n+\t}\n+\n+\treturn expressions;\n+}\n+\n } // namespace duckdb\ndiff --git a/src/planner/expression_binder/index_binder.cpp b/src/planner/expression_binder/index_binder.cpp\nindex 62a376ec37ab..750e657c146c 100644\n--- a/src/planner/expression_binder/index_binder.cpp\n+++ b/src/planner/expression_binder/index_binder.cpp\n@@ -1,8 +1,14 @@\n #include \"duckdb/planner/expression_binder/index_binder.hpp\"\n \n+#include \"duckdb/parser/parsed_data/create_index_info.hpp\"\n+#include \"duckdb/parser/expression/columnref_expression.hpp\"\n+#include \"duckdb/planner/expression/bound_columnref_expression.hpp\"\n+#include \"duckdb/planner/column_binding.hpp\"\n+\n namespace duckdb {\n \n-IndexBinder::IndexBinder(Binder &binder, ClientContext &context) : ExpressionBinder(binder, context) {\n+IndexBinder::IndexBinder(Binder &binder, ClientContext &context, TableCatalogEntry *table, CreateIndexInfo *info)\n+    : ExpressionBinder(binder, context), table(table), info(info) {\n }\n \n BindResult IndexBinder::BindExpression(unique_ptr<ParsedExpression> *expr_ptr, idx_t depth, bool root_expression) {\n@@ -12,6 +18,31 @@ BindResult IndexBinder::BindExpression(unique_ptr<ParsedExpression> *expr_ptr, i\n \t\treturn BindResult(\"window functions are not allowed in index expressions\");\n \tcase ExpressionClass::SUBQUERY:\n \t\treturn BindResult(\"cannot use subquery in index expressions\");\n+\tcase ExpressionClass::COLUMN_REF: {\n+\t\tif (table) {\n+\t\t\t// WAL replay\n+\t\t\t// we assume that the parsed expressions have qualified column names\n+\t\t\t// and that the columns exist in the table\n+\t\t\tauto &col_ref = (ColumnRefExpression &)expr;\n+\t\t\tauto col_idx = table->GetColumnIndex(col_ref.column_names.back());\n+\t\t\tauto col_type = table->GetColumn(col_idx).GetType();\n+\n+\t\t\t// find the col_idx in the index.column_ids\n+\t\t\tauto col_id_idx = DConstants::INVALID_INDEX;\n+\t\t\tfor (idx_t i = 0; i < info->column_ids.size(); i++) {\n+\t\t\t\tif (col_idx.index == info->column_ids[i]) {\n+\t\t\t\t\tcol_id_idx = i;\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif (col_id_idx == DConstants::INVALID_INDEX) {\n+\t\t\t\tthrow InternalException(\"failed to replay CREATE INDEX statement - column id not found\");\n+\t\t\t}\n+\t\t\treturn BindResult(\n+\t\t\t    make_unique<BoundColumnRefExpression>(col_ref.alias, col_type, ColumnBinding(0, col_id_idx)));\n+\t\t}\n+\t\treturn ExpressionBinder::BindExpression(expr_ptr, depth);\n+\t}\n \tdefault:\n \t\treturn ExpressionBinder::BindExpression(expr_ptr, depth);\n \t}\ndiff --git a/src/storage/data_table.cpp b/src/storage/data_table.cpp\nindex 77f45ffc710d..fa1c998ed839 100644\n--- a/src/storage/data_table.cpp\n+++ b/src/storage/data_table.cpp\n@@ -1144,15 +1144,78 @@ void DataTable::UpdateColumn(TableCatalogEntry &table, ClientContext &context, V\n }\n \n //===--------------------------------------------------------------------===//\n-// Create Index Scan\n+// Index Scan\n //===--------------------------------------------------------------------===//\n-void DataTable::InitializeCreateIndexScan(CreateIndexScanState &state, const vector<column_t> &column_ids) {\n+void DataTable::InitializeWALCreateIndexScan(CreateIndexScanState &state, const vector<column_t> &column_ids) {\n \t// we grab the append lock to make sure nothing is appended until AFTER we finish the index scan\n \tstate.append_lock = std::unique_lock<mutex>(append_lock);\n-\trow_groups->InitializeCreateIndexScan(state);\n \tInitializeScan(state, column_ids);\n }\n \n+void DataTable::WALAddIndex(ClientContext &context, unique_ptr<Index> index,\n+                            const vector<unique_ptr<Expression>> &expressions) {\n+\n+\t// if the data table is empty\n+\tif (row_groups->IsEmpty()) {\n+\t\tinfo->indexes.AddIndex(std::move(index));\n+\t\treturn;\n+\t}\n+\n+\tauto &allocator = Allocator::Get(db);\n+\n+\tDataChunk result;\n+\tresult.Initialize(allocator, index->logical_types);\n+\n+\tDataChunk intermediate;\n+\tvector<LogicalType> intermediate_types;\n+\tauto column_ids = index->column_ids;\n+\tcolumn_ids.push_back(COLUMN_IDENTIFIER_ROW_ID);\n+\tfor (auto &id : index->column_ids) {\n+\t\tauto &col = column_definitions[id];\n+\t\tintermediate_types.push_back(col.Type());\n+\t}\n+\tintermediate_types.emplace_back(LogicalType::ROW_TYPE);\n+\tintermediate.Initialize(allocator, intermediate_types);\n+\n+\t// initialize an index scan\n+\tCreateIndexScanState state;\n+\tInitializeWALCreateIndexScan(state, column_ids);\n+\n+\tif (!is_root) {\n+\t\tthrow InternalException(\"Error during WAL replay. Cannot add an index to a table that has been altered.\");\n+\t}\n+\n+\t// now start incrementally building the index\n+\t{\n+\t\tIndexLock lock;\n+\t\tindex->InitializeLock(lock);\n+\n+\t\twhile (true) {\n+\t\t\tintermediate.Reset();\n+\t\t\tresult.Reset();\n+\t\t\t// scan a new chunk from the table to index\n+\t\t\tCreateIndexScan(state, intermediate, TableScanType::TABLE_SCAN_COMMITTED_ROWS_OMIT_PERMANENTLY_DELETED);\n+\t\t\tif (intermediate.size() == 0) {\n+\t\t\t\t// finished scanning for index creation\n+\t\t\t\t// release all locks\n+\t\t\t\tbreak;\n+\t\t\t}\n+\t\t\t// resolve the expressions for this chunk\n+\t\t\tindex->ExecuteExpressions(intermediate, result);\n+\n+\t\t\t// insert into the index\n+\t\t\tif (!index->Insert(lock, result, intermediate.data[intermediate.ColumnCount() - 1])) {\n+\t\t\t\tthrow InternalException(\"Error during WAL replay. Can't create unique index, table contains \"\n+\t\t\t\t                        \"duplicate data on indexed column(s).\");\n+\t\t\t}\n+\t\t}\n+\t}\n+\tinfo->indexes.AddIndex(std::move(index));\n+}\n+\n+//===--------------------------------------------------------------------===//\n+// Statistics\n+//===--------------------------------------------------------------------===//\n unique_ptr<BaseStatistics> DataTable::GetStatistics(ClientContext &context, column_t column_id) {\n \tif (column_id == COLUMN_IDENTIFIER_ROW_ID) {\n \t\treturn nullptr;\ndiff --git a/src/storage/index.cpp b/src/storage/index.cpp\nindex 066927809a18..73e63414b8e2 100644\n--- a/src/storage/index.cpp\n+++ b/src/storage/index.cpp\n@@ -86,7 +86,7 @@ bool Index::IndexIsUpdated(const vector<PhysicalIndex> &column_ids) const {\n \treturn false;\n }\n \n-BlockPointer Index::Serialize(duckdb::MetaBlockWriter &writer) {\n+BlockPointer Index::Serialize(MetaBlockWriter &writer) {\n \tthrow NotImplementedException(\"The implementation of this index serialization does not exist.\");\n }\n \ndiff --git a/src/storage/local_storage.cpp b/src/storage/local_storage.cpp\nindex 6140fc0fd93f..69e6d86f9a25 100644\n--- a/src/storage/local_storage.cpp\n+++ b/src/storage/local_storage.cpp\n@@ -127,7 +127,7 @@ LocalTableStorage::LocalTableStorage(DataTable &table)\n \t\t\t\tunbound_expressions.push_back(expr->Copy());\n \t\t\t}\n \t\t\tindexes.AddIndex(make_unique<ART>(art.column_ids, art.table_io_manager, std::move(unbound_expressions),\n-\t\t\t                                  art.constraint_type, art.db, false));\n+\t\t\t                                  art.constraint_type, art.db, true));\n \t\t}\n \t\treturn false;\n \t});\ndiff --git a/src/storage/table_index_list.cpp b/src/storage/table_index_list.cpp\nindex 6ec6075fd3eb..386fe9fe5d6e 100644\n--- a/src/storage/table_index_list.cpp\n+++ b/src/storage/table_index_list.cpp\n@@ -60,8 +60,7 @@ void TableIndexList::VerifyForeignKey(const vector<PhysicalIndex> &fk_keys, Data\n \t\tthrow InternalException(\"Internal Foreign Key error: could not find index to verify...\");\n \t}\n \tconflict_manager.SetIndexCount(1);\n-\n-\tindex->LookupValues(chunk, conflict_manager);\n+\tindex->CheckConstraintsForChunk(chunk, conflict_manager);\n }\n \n vector<column_t> TableIndexList::GetRequiredColumns() {\ndiff --git a/src/storage/wal_replay.cpp b/src/storage/wal_replay.cpp\nindex 1c5a2d999510..c75ce674b502 100644\n--- a/src/storage/wal_replay.cpp\n+++ b/src/storage/wal_replay.cpp\n@@ -18,6 +18,8 @@\n #include \"duckdb/storage/write_ahead_log.hpp\"\n #include \"duckdb/storage/storage_manager.hpp\"\n #include \"duckdb/main/attached_database.hpp\"\n+#include \"duckdb/execution/index/art/art.hpp\"\n+#include \"duckdb/catalog/catalog_entry/duck_index_entry.hpp\"\n \n namespace duckdb {\n \n@@ -154,6 +156,12 @@ void ReplayState::ReplayEntry(WALType entry_type) {\n \tcase WALType::DROP_TABLE_MACRO:\n \t\tReplayDropTableMacro();\n \t\tbreak;\n+\tcase WALType::CREATE_INDEX:\n+\t\tReplayCreateIndex();\n+\t\tbreak;\n+\tcase WALType::DROP_INDEX:\n+\t\tReplayDropIndex();\n+\t\tbreak;\n \tcase WALType::USE_TABLE:\n \t\tReplayUseTable();\n \t\tbreak;\n@@ -379,6 +387,66 @@ void ReplayState::ReplayDropTableMacro() {\n \tcatalog.DropEntry(context, &info);\n }\n \n+//===--------------------------------------------------------------------===//\n+// Replay Index\n+//===--------------------------------------------------------------------===//\n+void ReplayState::ReplayCreateIndex() {\n+\n+\tauto info = IndexCatalogEntry::Deserialize(source, context);\n+\tif (deserialize_only) {\n+\t\treturn;\n+\t}\n+\n+\t// get the physical table to which we'll add the index\n+\tauto table = catalog.GetEntry<TableCatalogEntry>(context, info->schema, info->table->table_name);\n+\tauto &data_table = table->GetStorage();\n+\n+\t// bind the parsed expressions\n+\tif (info->expressions.empty()) {\n+\t\tfor (auto &parsed_expr : info->parsed_expressions) {\n+\t\t\tinfo->expressions.push_back(parsed_expr->Copy());\n+\t\t}\n+\t}\n+\tauto binder = Binder::CreateBinder(context);\n+\tauto expressions = binder->BindCreateIndexExpressions(table, info.get());\n+\n+\t// create the empty index\n+\tunique_ptr<Index> index;\n+\tswitch (info->index_type) {\n+\tcase IndexType::ART: {\n+\t\tindex = make_unique<ART>(info->column_ids, TableIOManager::Get(data_table), expressions, info->constraint_type,\n+\t\t                         data_table.db, true);\n+\t\tbreak;\n+\t}\n+\tdefault:\n+\t\tthrow InternalException(\"Unimplemented index type\");\n+\t}\n+\n+\t// add the index to the catalog\n+\tauto index_entry = (DuckIndexEntry *)catalog.CreateIndex(context, info.get());\n+\tindex_entry->index = index.get();\n+\tindex_entry->info = data_table.info;\n+\tfor (auto &parsed_expr : info->parsed_expressions) {\n+\t\tindex_entry->parsed_expressions.push_back(parsed_expr->Copy());\n+\t}\n+\n+\t// physically add the index to the data table storage\n+\tdata_table.WALAddIndex(context, std::move(index), expressions);\n+}\n+\n+void ReplayState::ReplayDropIndex() {\n+\n+\tDropInfo info;\n+\tinfo.type = CatalogType::INDEX_ENTRY;\n+\tinfo.schema = source.Read<string>();\n+\tinfo.name = source.Read<string>();\n+\tif (deserialize_only) {\n+\t\treturn;\n+\t}\n+\n+\tcatalog.DropEntry(context, &info);\n+}\n+\n //===--------------------------------------------------------------------===//\n // Replay Data\n //===--------------------------------------------------------------------===//\ndiff --git a/src/storage/write_ahead_log.cpp b/src/storage/write_ahead_log.cpp\nindex efecb9e9906b..7294431e4a7a 100644\n--- a/src/storage/write_ahead_log.cpp\n+++ b/src/storage/write_ahead_log.cpp\n@@ -119,7 +119,7 @@ void WriteAheadLog::WriteSequenceValue(SequenceCatalogEntry *entry, SequenceValu\n }\n \n //===--------------------------------------------------------------------===//\n-// MACRO'S\n+// MACROS\n //===--------------------------------------------------------------------===//\n void WriteAheadLog::WriteCreateMacro(ScalarMacroCatalogEntry *entry) {\n \tif (skip_writing) {\n@@ -155,6 +155,26 @@ void WriteAheadLog::WriteDropTableMacro(TableMacroCatalogEntry *entry) {\n \twriter->WriteString(entry->name);\n }\n \n+//===--------------------------------------------------------------------===//\n+// Indexes\n+//===--------------------------------------------------------------------===//\n+void WriteAheadLog::WriteCreateIndex(IndexCatalogEntry *entry) {\n+\tif (skip_writing) {\n+\t\treturn;\n+\t}\n+\twriter->Write<WALType>(WALType::CREATE_INDEX);\n+\tentry->Serialize(*writer);\n+}\n+\n+void WriteAheadLog::WriteDropIndex(IndexCatalogEntry *entry) {\n+\tif (skip_writing) {\n+\t\treturn;\n+\t}\n+\twriter->Write<WALType>(WALType::DROP_INDEX);\n+\twriter->WriteString(entry->schema->name);\n+\twriter->WriteString(entry->name);\n+}\n+\n //===--------------------------------------------------------------------===//\n // Custom Types\n //===--------------------------------------------------------------------===//\ndiff --git a/src/transaction/commit_state.cpp b/src/transaction/commit_state.cpp\nindex d8ff4caa4953..44f7bfa4da81 100644\n--- a/src/transaction/commit_state.cpp\n+++ b/src/transaction/commit_state.cpp\n@@ -87,7 +87,9 @@ void CommitState::WriteCatalogEntry(CatalogEntry *entry, data_ptr_t dataptr) {\n \tcase CatalogType::TABLE_MACRO_ENTRY:\n \t\tlog->WriteCreateTableMacro((TableMacroCatalogEntry *)parent);\n \t\tbreak;\n-\n+\tcase CatalogType::INDEX_ENTRY:\n+\t\tlog->WriteCreateIndex((IndexCatalogEntry *)parent);\n+\t\tbreak;\n \tcase CatalogType::TYPE_ENTRY:\n \t\tlog->WriteCreateType((TypeCatalogEntry *)parent);\n \t\tbreak;\n@@ -119,6 +121,8 @@ void CommitState::WriteCatalogEntry(CatalogEntry *entry, data_ptr_t dataptr) {\n \t\t\tlog->WriteDropType((TypeCatalogEntry *)entry);\n \t\t\tbreak;\n \t\tcase CatalogType::INDEX_ENTRY:\n+\t\t\tlog->WriteDropIndex((IndexCatalogEntry *)entry);\n+\t\t\tbreak;\n \t\tcase CatalogType::PREPARED_STATEMENT:\n \t\tcase CatalogType::SCALAR_FUNCTION_ENTRY:\n \t\t\t// do nothing, indexes/prepared statements/functions aren't persisted to disk\n@@ -127,7 +131,6 @@ void CommitState::WriteCatalogEntry(CatalogEntry *entry, data_ptr_t dataptr) {\n \t\t\tthrow InternalException(\"Don't know how to drop this type!\");\n \t\t}\n \t\tbreak;\n-\tcase CatalogType::INDEX_ENTRY:\n \tcase CatalogType::PREPARED_STATEMENT:\n \tcase CatalogType::AGGREGATE_FUNCTION_ENTRY:\n \tcase CatalogType::SCALAR_FUNCTION_ENTRY:\n",
  "test_patch": "diff --git a/test/fuzzer/pedro/art_prefix_error.test b/test/fuzzer/pedro/art_prefix_error.test\nnew file mode 100644\nindex 000000000000..158ce59ae605\n--- /dev/null\n+++ b/test/fuzzer/pedro/art_prefix_error.test\n@@ -0,0 +1,11 @@\n+# name: test/fuzzer/pedro/art_prefix_error.test\n+# description: Issue #5984, number 59\n+# group: [pedro]\n+\n+statement ok\n+CREATE TABLE t0 (c0 BLOB PRIMARY KEY);\n+\n+statement error\n+INSERT INTO t0(c0) VALUES (BLOB '\\x00a'), (BLOB '');\n+----\n+Not implemented Error: Indexes cannot contain BLOBs that contain null-terminated bytes.\n\\ No newline at end of file\ndiff --git a/test/fuzzer/pedro/buffer_manager_resize_issue.test b/test/fuzzer/pedro/buffer_manager_resize_issue.test\nnew file mode 100644\nindex 000000000000..e60d23fd2107\n--- /dev/null\n+++ b/test/fuzzer/pedro/buffer_manager_resize_issue.test\n@@ -0,0 +1,35 @@\n+# name: test/fuzzer/pedro/buffer_manager_resize_issue.test\n+# description: Issue #5984, number 49\n+# group: [pedro]\n+\n+statement ok\n+CREATE TABLE t1 (c1 INT, c0 INT);\n+\n+statement ok\n+CREATE TABLE t2 (c1 INT, c0 INT);\n+\n+statement ok\n+START TRANSACTION;\n+\n+statement ok\n+CREATE INDEX i1 ON t2 (c1);\n+\n+statement error\n+CREATE INDEX i1 ON t1 (c0);\n+----\n+Catalog Error: Index with name \"i1\" already exists!\n+\n+# actually a ROLLBACK, because we threw an exception in the transaction\n+statement ok\n+COMMIT;\n+\n+statement ok\n+CREATE UNIQUE INDEX i1 ON t2 (c1);\n+\n+statement ok\n+INSERT INTO t2(c1,c0) VALUES (235,36),(43,81),(246,187),(28,149),(206,20),(135,11),(170,205),(202,63),(69,78),(160,50),(6,34),(207,28);\n+\n+statement error\n+INSERT INTO t2(c1,c0) VALUES (86,98),(96,107),(237,190),(253,242),(229,9),(6,147);\n+----\n+TransactionContext Error: Failed to commit: Constraint Error: PRIMARY KEY or UNIQUE constraint violated: duplicated key\n\\ No newline at end of file\ndiff --git a/test/fuzzer/pedro/pushdown_error.test b/test/fuzzer/pedro/pushdown_error.test\nnew file mode 100644\nindex 000000000000..ff9e3dbab264\n--- /dev/null\n+++ b/test/fuzzer/pedro/pushdown_error.test\n@@ -0,0 +1,36 @@\n+# name: test/fuzzer/pedro/pushdown_error.test\n+# description: WAL cannot alter table\n+# group: [pedro]\n+\n+# fuzzer\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+load __TEST_DIR__/wal_crash.db\n+\n+statement ok\n+CREATE TABLE t2(c1 INT);\n+\n+statement ok\n+CREATE INDEX i0 ON t2(c1);\n+\n+statement ok\n+CHECKPOINT;\n+\n+statement ok\n+SET wal_autocheckpoint='1TB';\n+\n+statement ok\n+PRAGMA disable_checkpoint_on_shutdown;\n+\n+statement ok\n+DROP INDEX i0;\n+\n+statement ok\n+ALTER TABLE t2 ALTER c1 SET DEFAULT 0;\n+\n+restart\n+\n+query I\n+SELECT * FROM t2;\n\\ No newline at end of file\ndiff --git a/test/sql/index/art/test_art_fuzzer_issues.test b/test/sql/index/art/test_art_fuzzer_issues.test\nindex b64b3a551fcd..869d0b26f0f1 100644\n--- a/test/sql/index/art/test_art_fuzzer_issues.test\n+++ b/test/sql/index/art/test_art_fuzzer_issues.test\n@@ -30,7 +30,10 @@ CREATE INDEX i2 ON t2 (c1);\n statement error\n INSERT INTO t2 VALUES (decode('g\\x00'::BLOB)::VARCHAR),('g');\n ----\n-TransactionContext Error: Failed to commit: Not implemented Error: Indexes cannot have contain null-terminated decoded BLOBs.\n+TransactionContext Error: Failed to commit: Not implemented Error: Indexes cannot contain BLOBs that contain null-terminated bytes.\n+\n+statement ok\n+INSERT INTO t2 VALUES ('\\0');\n \n statement ok\n CREATE INDEX i22 ON t2 (c1);\n@@ -89,7 +92,7 @@ CREATE INDEX i21 ON t21 (c1, \"decode\"('\\x00'::BLOB));\n statement error\n INSERT INTO t21 VALUES (1);\n ----\n-TransactionContext Error: Failed to commit: Not implemented Error: Indexes cannot have contain null-terminated decoded BLOBs.\n+TransactionContext Error: Failed to commit: Not implemented Error: Indexes cannot contain BLOBs that contain null-terminated bytes.\n \n statement error\n CREATE INDEX i21 ON t21 (c1);\n\\ No newline at end of file\ndiff --git a/test/sql/index/art/test_art_import_export.test b/test/sql/index/art/test_art_import_export.test\nnew file mode 100644\nindex 000000000000..298461650071\n--- /dev/null\n+++ b/test/sql/index/art/test_art_import_export.test\n@@ -0,0 +1,36 @@\n+# name: test/sql/index/art/test_art_import_export.test\n+# description: Test that the index is correctly exported and imported\n+# group: [art]\n+\n+# issue 4126\n+\n+load __TEST_DIR__/test_art_export.db\n+\n+statement ok\n+CREATE TABLE raw(\n+    \"year\" SMALLINT,\n+    \"month\" TINYINT,\n+    \"day\" TINYINT,\n+    \"customer_ID\" BIGINT\n+);\n+\n+statement ok\n+INSERT INTO raw VALUES (1, 1, 1, 1);\n+\n+statement ok\n+CREATE UNIQUE INDEX customer_year_month_idx ON raw (customer_ID, year, month);\n+\n+restart\n+\n+statement ok\n+EXPORT DATABASE '__TEST_DIR__/export_index_db' (FORMAT CSV)\n+\n+load __TEST_DIR__/test_art_import.db\n+\n+statement ok\n+IMPORT DATABASE '__TEST_DIR__/export_index_db'\n+\n+statement error\n+INSERT INTO raw VALUES (1, 1, 1, 1);\n+----\n+TransactionContext Error: Failed to commit: Constraint Error: PRIMARY KEY or UNIQUE constraint violated: duplicated key\n\\ No newline at end of file\ndiff --git a/test/sql/index/test_art_keys.cpp b/test/sql/index/test_art_keys.cpp\nindex e2202f8018da..1d46c1e9a8b3 100644\n--- a/test/sql/index/test_art_keys.cpp\n+++ b/test/sql/index/test_art_keys.cpp\n@@ -47,8 +47,9 @@ static void TestKeys(vector<Key> &keys) {\n \n static Key CreateCompoundKey(ArenaAllocator &arena_allocator, string str_val, int32_t int_val) {\n \n-\tauto key_left = Key::CreateKey<string_t>(arena_allocator, string_t(str_val.c_str(), str_val.size()));\n-\tauto key_right = Key::CreateKey<int32_t>(arena_allocator, int_val);\n+\tauto key_left =\n+\t    Key::CreateKey<string_t>(arena_allocator, LogicalType::VARCHAR, string_t(str_val.c_str(), str_val.size()));\n+\tauto key_right = Key::CreateKey<int32_t>(arena_allocator, LogicalType::VARCHAR, int_val);\n \n \tauto data = arena_allocator.Allocate(key_left.len + key_right.len);\n \tmemcpy(data, key_left.data, key_left.len);\n@@ -62,124 +63,124 @@ TEST_CASE(\"Test correct functioning of art keys\", \"[art]\") {\n \n \t// Test tiny int\n \tvector<Key> keys;\n-\tkeys.push_back(Key::CreateKey<int8_t>(arena_allocator, -127));\n-\tkeys.push_back(Key::CreateKey<int8_t>(arena_allocator, -55));\n-\tkeys.push_back(Key::CreateKey<int8_t>(arena_allocator, -1));\n-\tkeys.push_back(Key::CreateKey<int8_t>(arena_allocator, 0));\n-\tkeys.push_back(Key::CreateKey<int8_t>(arena_allocator, 1));\n-\tkeys.push_back(Key::CreateKey<int8_t>(arena_allocator, 55));\n-\tkeys.push_back(Key::CreateKey<int8_t>(arena_allocator, 127));\n+\tkeys.push_back(Key::CreateKey<int8_t>(arena_allocator, LogicalType::TINYINT, -127));\n+\tkeys.push_back(Key::CreateKey<int8_t>(arena_allocator, LogicalType::TINYINT, -55));\n+\tkeys.push_back(Key::CreateKey<int8_t>(arena_allocator, LogicalType::TINYINT, -1));\n+\tkeys.push_back(Key::CreateKey<int8_t>(arena_allocator, LogicalType::TINYINT, 0));\n+\tkeys.push_back(Key::CreateKey<int8_t>(arena_allocator, LogicalType::TINYINT, 1));\n+\tkeys.push_back(Key::CreateKey<int8_t>(arena_allocator, LogicalType::TINYINT, 55));\n+\tkeys.push_back(Key::CreateKey<int8_t>(arena_allocator, LogicalType::TINYINT, 127));\n \tTestKeys(keys);\n \n \tkeys.clear();\n \n \t// Test small int\n-\tkeys.push_back(Key::CreateKey<int16_t>(arena_allocator, -32767));\n-\tkeys.push_back(Key::CreateKey<int16_t>(arena_allocator, -127));\n-\tkeys.push_back(Key::CreateKey<int16_t>(arena_allocator, -55));\n-\tkeys.push_back(Key::CreateKey<int16_t>(arena_allocator, -1));\n-\tkeys.push_back(Key::CreateKey<int16_t>(arena_allocator, 0));\n-\tkeys.push_back(Key::CreateKey<int16_t>(arena_allocator, 1));\n-\tkeys.push_back(Key::CreateKey<int16_t>(arena_allocator, 55));\n-\tkeys.push_back(Key::CreateKey<int16_t>(arena_allocator, 127));\n-\tkeys.push_back(Key::CreateKey<int16_t>(arena_allocator, 32767));\n+\tkeys.push_back(Key::CreateKey<int16_t>(arena_allocator, LogicalType::SMALLINT, -32767));\n+\tkeys.push_back(Key::CreateKey<int16_t>(arena_allocator, LogicalType::SMALLINT, -127));\n+\tkeys.push_back(Key::CreateKey<int16_t>(arena_allocator, LogicalType::SMALLINT, -55));\n+\tkeys.push_back(Key::CreateKey<int16_t>(arena_allocator, LogicalType::SMALLINT, -1));\n+\tkeys.push_back(Key::CreateKey<int16_t>(arena_allocator, LogicalType::SMALLINT, 0));\n+\tkeys.push_back(Key::CreateKey<int16_t>(arena_allocator, LogicalType::SMALLINT, 1));\n+\tkeys.push_back(Key::CreateKey<int16_t>(arena_allocator, LogicalType::SMALLINT, 55));\n+\tkeys.push_back(Key::CreateKey<int16_t>(arena_allocator, LogicalType::SMALLINT, 127));\n+\tkeys.push_back(Key::CreateKey<int16_t>(arena_allocator, LogicalType::SMALLINT, 32767));\n \tTestKeys(keys);\n \n \tkeys.clear();\n \n \t// Test int\n-\tkeys.push_back(Key::CreateKey<int32_t>(arena_allocator, -2147483647));\n-\tkeys.push_back(Key::CreateKey<int32_t>(arena_allocator, -8388608));\n-\tkeys.push_back(Key::CreateKey<int32_t>(arena_allocator, -32767));\n-\tkeys.push_back(Key::CreateKey<int32_t>(arena_allocator, -1));\n-\tkeys.push_back(Key::CreateKey<int32_t>(arena_allocator, 0));\n-\tkeys.push_back(Key::CreateKey<int32_t>(arena_allocator, 1));\n-\tkeys.push_back(Key::CreateKey<int32_t>(arena_allocator, 32767));\n-\tkeys.push_back(Key::CreateKey<int32_t>(arena_allocator, 8388608));\n-\tkeys.push_back(Key::CreateKey<int32_t>(arena_allocator, 2147483647));\n+\tkeys.push_back(Key::CreateKey<int32_t>(arena_allocator, LogicalType::INTEGER, -2147483647));\n+\tkeys.push_back(Key::CreateKey<int32_t>(arena_allocator, LogicalType::INTEGER, -8388608));\n+\tkeys.push_back(Key::CreateKey<int32_t>(arena_allocator, LogicalType::INTEGER, -32767));\n+\tkeys.push_back(Key::CreateKey<int32_t>(arena_allocator, LogicalType::INTEGER, -1));\n+\tkeys.push_back(Key::CreateKey<int32_t>(arena_allocator, LogicalType::INTEGER, 0));\n+\tkeys.push_back(Key::CreateKey<int32_t>(arena_allocator, LogicalType::INTEGER, 1));\n+\tkeys.push_back(Key::CreateKey<int32_t>(arena_allocator, LogicalType::INTEGER, 32767));\n+\tkeys.push_back(Key::CreateKey<int32_t>(arena_allocator, LogicalType::INTEGER, 8388608));\n+\tkeys.push_back(Key::CreateKey<int32_t>(arena_allocator, LogicalType::INTEGER, 2147483647));\n \tTestKeys(keys);\n \n \tkeys.clear();\n \n \t// Test big int\n-\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, -9223372036854775807));\n-\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, -72057594037927936));\n-\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, -281474976710656));\n-\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, -1099511627776));\n-\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, -2147483647));\n-\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, -8388608));\n-\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, -32767));\n-\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, -1));\n-\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, 0));\n-\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, 1));\n-\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, 32767));\n-\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, 8388608));\n-\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, 2147483647));\n-\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, 1099511627776));\n-\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, 281474976710656));\n-\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, 72057594037927936));\n-\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, 9223372036854775807));\n+\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, LogicalType::BIGINT, -9223372036854775807));\n+\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, LogicalType::BIGINT, -72057594037927936));\n+\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, LogicalType::BIGINT, -281474976710656));\n+\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, LogicalType::BIGINT, -1099511627776));\n+\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, LogicalType::BIGINT, -2147483647));\n+\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, LogicalType::BIGINT, -8388608));\n+\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, LogicalType::BIGINT, -32767));\n+\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, LogicalType::BIGINT, -1));\n+\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, LogicalType::BIGINT, 0));\n+\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, LogicalType::BIGINT, 1));\n+\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, LogicalType::BIGINT, 32767));\n+\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, LogicalType::BIGINT, 8388608));\n+\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, LogicalType::BIGINT, 2147483647));\n+\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, LogicalType::BIGINT, 1099511627776));\n+\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, LogicalType::BIGINT, 281474976710656));\n+\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, LogicalType::BIGINT, 72057594037927936));\n+\tkeys.push_back(Key::CreateKey<int64_t>(arena_allocator, LogicalType::BIGINT, 9223372036854775807));\n \tTestKeys(keys);\n \n \tkeys.clear();\n \n \t// Test utiny int\n-\tkeys.push_back(Key::CreateKey<uint8_t>(arena_allocator, 0));\n-\tkeys.push_back(Key::CreateKey<uint8_t>(arena_allocator, 1));\n-\tkeys.push_back(Key::CreateKey<uint8_t>(arena_allocator, 55));\n-\tkeys.push_back(Key::CreateKey<uint8_t>(arena_allocator, 127));\n-\tkeys.push_back(Key::CreateKey<uint8_t>(arena_allocator, 200));\n-\tkeys.push_back(Key::CreateKey<uint8_t>(arena_allocator, 250));\n+\tkeys.push_back(Key::CreateKey<uint8_t>(arena_allocator, LogicalType::UTINYINT, 0));\n+\tkeys.push_back(Key::CreateKey<uint8_t>(arena_allocator, LogicalType::UTINYINT, 1));\n+\tkeys.push_back(Key::CreateKey<uint8_t>(arena_allocator, LogicalType::UTINYINT, 55));\n+\tkeys.push_back(Key::CreateKey<uint8_t>(arena_allocator, LogicalType::UTINYINT, 127));\n+\tkeys.push_back(Key::CreateKey<uint8_t>(arena_allocator, LogicalType::UTINYINT, 200));\n+\tkeys.push_back(Key::CreateKey<uint8_t>(arena_allocator, LogicalType::UTINYINT, 250));\n \tTestKeys(keys);\n \n \tkeys.clear();\n \n-\t// Test small int\n-\tkeys.push_back(Key::CreateKey<uint16_t>(arena_allocator, 0));\n-\tkeys.push_back(Key::CreateKey<uint16_t>(arena_allocator, 1));\n-\tkeys.push_back(Key::CreateKey<uint16_t>(arena_allocator, 55));\n-\tkeys.push_back(Key::CreateKey<uint16_t>(arena_allocator, 127));\n-\tkeys.push_back(Key::CreateKey<uint16_t>(arena_allocator, 32767));\n-\tkeys.push_back(Key::CreateKey<uint16_t>(arena_allocator, 40000));\n-\tkeys.push_back(Key::CreateKey<uint16_t>(arena_allocator, 60000));\n+\t// Test usmall int\n+\tkeys.push_back(Key::CreateKey<uint16_t>(arena_allocator, LogicalType::USMALLINT, 0));\n+\tkeys.push_back(Key::CreateKey<uint16_t>(arena_allocator, LogicalType::USMALLINT, 1));\n+\tkeys.push_back(Key::CreateKey<uint16_t>(arena_allocator, LogicalType::USMALLINT, 55));\n+\tkeys.push_back(Key::CreateKey<uint16_t>(arena_allocator, LogicalType::USMALLINT, 127));\n+\tkeys.push_back(Key::CreateKey<uint16_t>(arena_allocator, LogicalType::USMALLINT, 32767));\n+\tkeys.push_back(Key::CreateKey<uint16_t>(arena_allocator, LogicalType::USMALLINT, 40000));\n+\tkeys.push_back(Key::CreateKey<uint16_t>(arena_allocator, LogicalType::USMALLINT, 60000));\n \n \tTestKeys(keys);\n \n \tkeys.clear();\n \n-\t// Test int\n-\tkeys.push_back(Key::CreateKey<uint32_t>(arena_allocator, 0));\n-\tkeys.push_back(Key::CreateKey<uint32_t>(arena_allocator, 1));\n-\tkeys.push_back(Key::CreateKey<uint32_t>(arena_allocator, 32767));\n-\tkeys.push_back(Key::CreateKey<uint32_t>(arena_allocator, 8388608));\n-\tkeys.push_back(Key::CreateKey<uint32_t>(arena_allocator, 2147483647));\n-\tkeys.push_back(Key::CreateKey<uint32_t>(arena_allocator, 3047483647));\n-\tkeys.push_back(Key::CreateKey<uint32_t>(arena_allocator, 4047483647));\n+\t// Test uint\n+\tkeys.push_back(Key::CreateKey<uint32_t>(arena_allocator, LogicalType::UINTEGER, 0));\n+\tkeys.push_back(Key::CreateKey<uint32_t>(arena_allocator, LogicalType::UINTEGER, 1));\n+\tkeys.push_back(Key::CreateKey<uint32_t>(arena_allocator, LogicalType::UINTEGER, 32767));\n+\tkeys.push_back(Key::CreateKey<uint32_t>(arena_allocator, LogicalType::UINTEGER, 8388608));\n+\tkeys.push_back(Key::CreateKey<uint32_t>(arena_allocator, LogicalType::UINTEGER, 2147483647));\n+\tkeys.push_back(Key::CreateKey<uint32_t>(arena_allocator, LogicalType::UINTEGER, 3047483647));\n+\tkeys.push_back(Key::CreateKey<uint32_t>(arena_allocator, LogicalType::UINTEGER, 4047483647));\n \tTestKeys(keys);\n \n \tkeys.clear();\n \n-\t// Test big int\n-\tkeys.push_back(Key::CreateKey<uint64_t>(arena_allocator, 0));\n-\tkeys.push_back(Key::CreateKey<uint64_t>(arena_allocator, 1));\n-\tkeys.push_back(Key::CreateKey<uint64_t>(arena_allocator, 32767));\n-\tkeys.push_back(Key::CreateKey<uint64_t>(arena_allocator, 8388608));\n-\tkeys.push_back(Key::CreateKey<uint64_t>(arena_allocator, 2147483647));\n-\tkeys.push_back(Key::CreateKey<uint64_t>(arena_allocator, 1099511627776));\n-\tkeys.push_back(Key::CreateKey<uint64_t>(arena_allocator, 281474976710656));\n-\tkeys.push_back(Key::CreateKey<uint64_t>(arena_allocator, 72057594037927936));\n+\t// Test ubig int\n+\tkeys.push_back(Key::CreateKey<uint64_t>(arena_allocator, LogicalType::UBIGINT, 0));\n+\tkeys.push_back(Key::CreateKey<uint64_t>(arena_allocator, LogicalType::UBIGINT, 1));\n+\tkeys.push_back(Key::CreateKey<uint64_t>(arena_allocator, LogicalType::UBIGINT, 32767));\n+\tkeys.push_back(Key::CreateKey<uint64_t>(arena_allocator, LogicalType::UBIGINT, 8388608));\n+\tkeys.push_back(Key::CreateKey<uint64_t>(arena_allocator, LogicalType::UBIGINT, 2147483647));\n+\tkeys.push_back(Key::CreateKey<uint64_t>(arena_allocator, LogicalType::UBIGINT, 1099511627776));\n+\tkeys.push_back(Key::CreateKey<uint64_t>(arena_allocator, LogicalType::UBIGINT, 281474976710656));\n+\tkeys.push_back(Key::CreateKey<uint64_t>(arena_allocator, LogicalType::UBIGINT, 72057594037927936));\n \tTestKeys(keys);\n \n \tkeys.clear();\n \n \t// Test strings\n-\tkeys.push_back(Key::CreateKey<const char *>(arena_allocator, \"abc\"));\n-\tkeys.push_back(Key::CreateKey<const char *>(arena_allocator, \"babababa\"));\n-\tkeys.push_back(Key::CreateKey<const char *>(arena_allocator, \"hello\"));\n-\tkeys.push_back(Key::CreateKey<const char *>(arena_allocator, \"hellow\"));\n-\tkeys.push_back(Key::CreateKey<const char *>(arena_allocator, \"torororororo\"));\n-\tkeys.push_back(Key::CreateKey<const char *>(arena_allocator, \"torororororp\"));\n-\tkeys.push_back(Key::CreateKey<const char *>(arena_allocator, \"z\"));\n+\tkeys.push_back(Key::CreateKey<const char *>(arena_allocator, LogicalType::VARCHAR, \"abc\"));\n+\tkeys.push_back(Key::CreateKey<const char *>(arena_allocator, LogicalType::VARCHAR, \"babababa\"));\n+\tkeys.push_back(Key::CreateKey<const char *>(arena_allocator, LogicalType::VARCHAR, \"hello\"));\n+\tkeys.push_back(Key::CreateKey<const char *>(arena_allocator, LogicalType::VARCHAR, \"hellow\"));\n+\tkeys.push_back(Key::CreateKey<const char *>(arena_allocator, LogicalType::VARCHAR, \"torororororo\"));\n+\tkeys.push_back(Key::CreateKey<const char *>(arena_allocator, LogicalType::VARCHAR, \"torororororp\"));\n+\tkeys.push_back(Key::CreateKey<const char *>(arena_allocator, LogicalType::VARCHAR, \"z\"));\n \n \tTestKeys(keys);\n \n@@ -200,10 +201,10 @@ TEST_CASE(\"Test correct functioning of art keys\", \"[art]\") {\n \n \tkeys.clear();\n \n-\tkeys.push_back(Key::CreateKey<double>(arena_allocator, 0));\n-\tkeys.push_back(Key::CreateKey<double>(arena_allocator, 0.1));\n-\tkeys.push_back(Key::CreateKey<double>(arena_allocator, 488566));\n-\tkeys.push_back(Key::CreateKey<double>(arena_allocator, 1163404482));\n+\tkeys.push_back(Key::CreateKey<double>(arena_allocator, LogicalType::DOUBLE, 0));\n+\tkeys.push_back(Key::CreateKey<double>(arena_allocator, LogicalType::DOUBLE, 0.1));\n+\tkeys.push_back(Key::CreateKey<double>(arena_allocator, LogicalType::DOUBLE, 488566));\n+\tkeys.push_back(Key::CreateKey<double>(arena_allocator, LogicalType::DOUBLE, 1163404482));\n \n \tTestKeys(keys);\n \ndiff --git a/test/sql/storage/null_byte_storage.test b/test/sql/storage/null_byte_storage.test\nindex bf6f0ded5935..c4f753e4f8ab 100644\n--- a/test/sql/storage/null_byte_storage.test\n+++ b/test/sql/storage/null_byte_storage.test\n@@ -27,8 +27,10 @@ SELECT * FROM null_byte WHERE v=concat('goo', chr(0), 42)\n goo\\042\n \n # null byte in index\n-statement ok\n+statement error\n CREATE INDEX i_index ON null_byte(v)\n+----\n+Not implemented Error: Indexes cannot contain BLOBs that contain null-terminated bytes.\n \n query I\n SELECT * FROM null_byte WHERE v=concat('goo', chr(0), 42)\ndiff --git a/test/sql/storage/test_unique_index_checkpoint.test b/test/sql/storage/test_unique_index_checkpoint.test\nnew file mode 100644\nindex 000000000000..27a5beacf404\n--- /dev/null\n+++ b/test/sql/storage/test_unique_index_checkpoint.test\n@@ -0,0 +1,41 @@\n+# name: test/sql/storage/test_unique_index_checkpoint.test\n+# description: Verify that unique indexes are correctly checkpointed\n+# group: [storage]\n+\n+# issue #6214\n+\n+load __TEST_DIR__/test_unique_index.db\n+\n+statement ok\n+CREATE TABLE test(i INTEGER, j INTEGER);\n+\n+statement ok\n+INSERT INTO test VALUES (1,100),(2,200);\n+\n+statement ok\n+CREATE UNIQUE INDEX idx ON test (i);\n+\n+restart\n+\n+statement error\n+INSERT INTO test VALUES (1,101),(2,201);\n+----\n+TransactionContext Error: Failed to commit: Constraint Error: PRIMARY KEY or UNIQUE constraint violated: duplicated key\n+\n+restart\n+\n+statement ok\n+CREATE TABLE IF NOT EXISTS unique_index_test AS\n+SELECT i AS ordernumber, j AS quantity FROM test;\n+\n+restart\n+\n+statement ok\n+CREATE UNIQUE INDEX unique_index_test_ordernumber_idx_unique ON unique_index_test (ordernumber);\n+\n+restart\n+\n+statement error\n+INSERT INTO unique_index_test VALUES (1,101),(2,201);\n+----\n+TransactionContext Error: Failed to commit: Constraint Error: PRIMARY KEY or UNIQUE constraint violated: duplicated key\n\\ No newline at end of file\ndiff --git a/test/sql/storage/wal/wal_create_index.test b/test/sql/storage/wal/wal_create_index.test\nnew file mode 100644\nindex 000000000000..9c9a3b684e74\n--- /dev/null\n+++ b/test/sql/storage/wal/wal_create_index.test\n@@ -0,0 +1,170 @@\n+# name: test/sql/storage/wal/wal_create_index.test\n+# description: Test serialization of index to WAL\n+# group: [wal]\n+\n+# load the DB from disk\n+load __TEST_DIR__/test_wal_create_index.db\n+\n+statement ok\n+PRAGMA disable_checkpoint_on_shutdown;\n+\n+statement ok\n+PRAGMA wal_autocheckpoint='1TB';\n+\n+statement ok\n+PRAGMA explain_output = OPTIMIZED_ONLY;\n+\n+statement ok\n+CREATE TABLE integers(i INTEGER, j INTEGER);\n+\n+statement ok\n+INSERT INTO integers VALUES (1,1), (2,2), (3,3);\n+\n+# Test single column\n+statement ok\n+CREATE UNIQUE INDEX i_index ON integers(i);\n+\n+query II\n+EXPLAIN SELECT i FROM integers WHERE i = 1\n+----\n+logical_opt\t<REGEX>:.*INDEX_SCAN.*\n+\n+restart\n+\n+statement ok\n+PRAGMA disable_checkpoint_on_shutdown;\n+\n+statement ok\n+PRAGMA wal_autocheckpoint='1TB';\n+\n+query II\n+EXPLAIN SELECT i FROM integers WHERE i = 1\n+----\n+logical_opt\t<REGEX>:.*INDEX_SCAN.*\n+\n+statement error\n+INSERT INTO integers VALUES (1, 1);\n+----\n+TransactionContext Error: Failed to commit: Constraint Error: PRIMARY KEY or UNIQUE constraint violated: duplicated key\n+\n+restart\n+\n+statement ok\n+PRAGMA disable_checkpoint_on_shutdown;\n+\n+statement ok\n+PRAGMA wal_autocheckpoint='1TB';\n+\n+statement ok\n+DROP INDEX i_index;\n+\n+restart\n+\n+# test more complex expressions\n+\n+statement ok\n+PRAGMA disable_checkpoint_on_shutdown;\n+\n+statement ok\n+PRAGMA wal_autocheckpoint='1TB';\n+\n+statement ok\n+CREATE UNIQUE INDEX i_index ON integers USING art((i + j));\n+\n+query II\n+EXPLAIN SELECT i FROM integers WHERE i + j = 2;\n+----\n+logical_opt\t<REGEX>:.*INDEX_SCAN.*\n+\n+restart\n+\n+statement ok\n+PRAGMA disable_checkpoint_on_shutdown;\n+\n+statement ok\n+PRAGMA wal_autocheckpoint='1TB';\n+\n+query II\n+EXPLAIN SELECT i FROM integers WHERE i + j = 2;\n+----\n+logical_opt\t<REGEX>:.*INDEX_SCAN.*\n+\n+query I\n+SELECT i FROM integers WHERE i + j = 2\n+----\n+1\n+\n+statement error\n+INSERT INTO integers VALUES (1, 1);\n+----\n+TransactionContext Error: Failed to commit: Constraint Error: PRIMARY KEY or UNIQUE constraint violated: duplicated key\n+\n+statement ok\n+DROP INDEX i_index;\n+\n+restart\n+\n+# change the order of the columns in the index expressions\n+\n+statement ok\n+PRAGMA disable_checkpoint_on_shutdown;\n+\n+statement ok\n+PRAGMA wal_autocheckpoint='1TB';\n+\n+statement ok\n+CREATE UNIQUE INDEX i_index ON integers USING art((j + i));\n+\n+query II\n+EXPLAIN SELECT i FROM integers WHERE j + i = 2;\n+----\n+logical_opt\t<REGEX>:.*INDEX_SCAN.*\n+\n+restart\n+\n+statement ok\n+PRAGMA disable_checkpoint_on_shutdown;\n+\n+statement ok\n+PRAGMA wal_autocheckpoint='1TB';\n+\n+query II\n+EXPLAIN SELECT i FROM integers WHERE j + i = 2;\n+----\n+logical_opt\t<REGEX>:.*INDEX_SCAN.*\n+\n+query I\n+SELECT i FROM integers WHERE j + i = 2\n+----\n+1\n+\n+statement error\n+INSERT INTO integers VALUES (1, 1);\n+----\n+TransactionContext Error: Failed to commit: Constraint Error: PRIMARY KEY or UNIQUE constraint violated: duplicated key\n+\n+statement ok\n+DROP INDEX i_index;\n+\n+restart\n+\n+# compound keys\n+\n+statement ok\n+PRAGMA disable_checkpoint_on_shutdown;\n+\n+statement ok\n+PRAGMA wal_autocheckpoint='1TB';\n+\n+statement ok\n+CREATE UNIQUE INDEX i_index ON integers USING art((j + i), j, i);\n+\n+restart\n+\n+statement error\n+INSERT INTO integers VALUES (1, 1);\n+----\n+TransactionContext Error: Failed to commit: Constraint Error: PRIMARY KEY or UNIQUE constraint violated: duplicated key\n+\n+statement ok\n+DROP INDEX i_index;\n\\ No newline at end of file\n",
  "problem_statement": "CREATE UNIQUE INDEX not persistent\n### What happens?\n\nCREATE UNIQUE INDEX is not persistent\r\n\r\nAlso tested in `v0.6.2-dev2363 7b258fd9a0`\n\n### To Reproduce\n\nFrom #4891\r\n\r\nHi @Mytherin,\r\n\r\nrunning `CHECKPOINT` after `CREATE UNIQUE INDEX` doesn't presist the index (as you asked me in #4126). I stripped down my script so you could exactly see, what I'm doing:\r\n\r\n```shell\r\n#!/bin/bash\r\n\r\nduckdb --version\r\n\r\ncat << EOF | duckdb ./unique-index-test.db\r\nCREATE TABLE unique_index_test_import(i INTEGER, j INTEGER);\r\nEOF\r\n\r\ncat << EOF | duckdb ./unique-index-test.db\r\nINSERT INTO unique_index_test_import VALUES (1,100),(2,200);\r\nEOF\r\n\r\n\r\n\r\ncat << EOF | duckdb ./unique-index-test.db\r\nCREATE TABLE IF NOT EXISTS unique_index_test AS\r\nSELECT\r\n  i AS ordernumber,\r\n  j AS quantity\r\nFROM unique_index_test_import\r\n;\r\nEOF\r\n\r\ncat << EOF | duckdb ./unique-index-test.db\r\nCREATE UNIQUE INDEX unique_index_test_ordernumber_idx_unique ON unique_index_test (ordernumber);\r\nCHECKPOINT;\r\nEOF\r\n\r\ncat << EOF | duckdb ./unique-index-test.db\r\nINSERT INTO unique_index_test VALUES (1,101),(2,201);\r\nEOF\r\n\r\ncat << EOF | duckdb ./unique-index-test.db\r\nSELECT * FROM unique_index_test;\r\nEOF\r\n```\r\n\r\nThe first run of the script is without `CHECKPOINT` the second run with `CHECKPOINT`. \r\n\r\n```\r\nxxx@yyy \ue0b0 ~/tmp-duckdb \ue0b0 \ue0a0 main \u00b1 \ue0b0 ./unique-index-test.sh                           \r\nv0.6.1 919cad22e8\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 ordernumber \u2502 quantity \u2502\r\n\u2502    int32    \u2502  int32   \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502           1 \u2502      100 \u2502\r\n\u2502           2 \u2502      200 \u2502\r\n\u2502           1 \u2502      101 \u2502\r\n\u2502           2 \u2502      201 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n xxx@yyy \ue0b0 ~/tmp-duckdb \ue0b0 \ue0a0 main \u00b1 \ue0b0 rm unique-index-test.db\r\n xxx@yyy \ue0b0 ~/tmp-duckdb \ue0b0 \ue0a0 main \u00b1 \ue0b0 ./unique-index-test.sh \r\nv0.6.1 919cad22e8\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 Success \u2502\r\n\u2502 boolean \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 0 rows  \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 ordernumber \u2502 quantity \u2502\r\n\u2502    int32    \u2502  int32   \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502           1 \u2502      100 \u2502\r\n\u2502           2 \u2502      200 \u2502\r\n\u2502           1 \u2502      101 \u2502\r\n\u2502           2 \u2502      201 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n xxx@yyy \ue0b0 ~/tmp-duckdb \ue0b0 \ue0a0 main \u00b1 \ue0b0\r\n```\r\nAs you can see, the result is the same for both cases.\n\n### OS:\n\nLinux\n\n### DuckDB Version:\n\n0.6.1\n\n### DuckDB Client:\n\nCLI\n\n### Full Name:\n\nKorbinian Pauli\n\n### Affiliation:\n\nprivate\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\n",
  "hints_text": "Hi @korpa. I am currently working on the WAL support for indexes and will have a look at this, too.",
  "created_at": "2023-02-21T09:08:30Z"
}