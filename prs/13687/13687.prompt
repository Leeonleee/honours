You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes.
In the patch file, please make sure to include the line numbers and a blank line at the end so it can be applied using git apply.

<issue>
json_deserialize_sql(): Error: Attempted to dereference unique_ptr that is NULL
### What happens?

Playing around with `json_deserialize_sql()` with some malformed JSON leads to this error:

```
duckdb.duckdb.InvalidInputException: Invalid Input Error: Attempting to execute an unsuccessful or closed pending query result
Error: INTERNAL Error: Attempted to dereference unique_ptr that is NULL!
This error signals an assertion failure within DuckDB. This usually occurs due to unexpected conditions or errors in the program's logic.
For more information, see https://duckdb.org/docs/dev/internal_errors
```


I know that the JSON that I've provided isn't actually a valid serialized statement, I was just testing the capabilities if it would the `json_deserialize_sql()` would deserialize a part of a statement.



### To Reproduce

```python
import duckdb
import json

con = duckdb.connect(":memory:")

filter_json = {
    "expression_class": "BOUND_COMPARISON",
    "type": "COMPARE_EQUAL",
    "left": {
        "expression_class": "BOUND_COLUMN_REF",
        "type": "BOUND_COLUMN_REF",
        "alias": "r",
        "return_type": {"id": "VARCHAR"},
    },
    "right": {
        "expression_class": "BOUND_CONSTANT",
        "type": "VALUE_CONSTANT",
        "value": {
            "type": {"id": "VARCHAR"},
            "is_null": False,
            "value": "u",
        },
    },
}

result = con.execute(
    "select json_deserialize_sql(?)", [json.dumps({"statements": [filter_json]})]
).fetchall()
```

### OS:

Mac OS X

### DuckDB Version:

v1.0.0 1f98600c2c

### DuckDB Client:

Python

### Full Name:

Rusty Conover

### Affiliation:

self

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a stable release

### Did you include all relevant data sets for reproducing the issue?

Yes

### Did you include all code required to reproduce the issue?

- [X] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [X] Yes, I have

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <picture>
3:     <source media="(prefers-color-scheme: light)" srcset="logo/DuckDB_Logo-horizontal.svg">
4:     <source media="(prefers-color-scheme: dark)" srcset="logo/DuckDB_Logo-horizontal-dark-mode.svg">
5:     <img alt="DuckDB logo" src="logo/DuckDB_Logo-horizontal.svg" height="100">
6:   </picture>
7: </div>
8: <br>
9: 
10: <p align="center">
11:   <a href="https://github.com/duckdb/duckdb/actions"><img src="https://github.com/duckdb/duckdb/actions/workflows/Main.yml/badge.svg?branch=main" alt="Github Actions Badge"></a>
12:   <a href="https://discord.gg/tcvwpjfnZx"><img src="https://shields.io/discord/909674491309850675" alt="discord" /></a>
13:   <a href="https://github.com/duckdb/duckdb/releases/"><img src="https://img.shields.io/github/v/release/duckdb/duckdb?color=brightgreen&display_name=tag&logo=duckdb&logoColor=white" alt="Latest Release"></a>
14: </p>
15: 
16: ## DuckDB
17: 
18: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable, portable, and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs, maps), and [several extensions designed to make SQL easier to use](https://duckdb.org/docs/guides/sql_features/friendly_sql).
19: 
20: DuckDB is available as a [standalone CLI application](https://duckdb.org/docs/api/cli/overview) and has clients for [Python](https://duckdb.org/docs/api/python/overview), [R](https://duckdb.org/docs/api/r), [Java](https://duckdb.org/docs/api/java), [Wasm](https://duckdb.org/docs/api/wasm/overview), etc., with deep integrations with packages such as [pandas](https://duckdb.org/docs/guides/python/sql_on_pandas) and [dplyr](https://duckdblabs.github.io/duckplyr/).
21: 
22: For more information on using DuckDB, please refer to the [DuckDB documentation](https://duckdb.org/docs/).
23: 
24: ## Installation
25: 
26: If you want to install DuckDB, please see [our installation page](https://duckdb.org/docs/installation) for instructions.
27: 
28: ## Data Import
29: 
30: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
31: 
32: ```sql
33: SELECT * FROM 'myfile.csv';
34: SELECT * FROM 'myfile.parquet';
35: ```
36: 
37: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
38: 
39: ## SQL Reference
40: 
41: The documentation contains a [SQL introduction and reference](https://duckdb.org/docs/sql/introduction).
42: 
43: ## Development
44: 
45: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run `BUILD_BENCHMARK=1 BUILD_TPCH=1 make` and then perform several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`. The details of benchmarks are in our [Benchmark Guide](benchmark/README.md).
46: 
47: Please also refer to our [Build Guide](https://duckdb.org/dev/building) and [Contribution Guide](CONTRIBUTING.md).
48: 
49: ## Support
50: 
51: See the [Support Options](https://duckdblabs.com/support/) page.
[end of README.md]
[start of extension/json/json_functions/json_serialize_sql.cpp]
1: #include "duckdb/execution/expression_executor.hpp"
2: #include "duckdb/main/connection.hpp"
3: #include "duckdb/main/database.hpp"
4: #include "duckdb/parser/parsed_data/create_pragma_function_info.hpp"
5: #include "duckdb/parser/parser.hpp"
6: #include "json_deserializer.hpp"
7: #include "json_functions.hpp"
8: #include "json_serializer.hpp"
9: 
10: namespace duckdb {
11: 
12: struct JsonSerializeBindData : public FunctionData {
13: 	bool skip_if_null = false;
14: 	bool skip_if_empty = false;
15: 	bool skip_if_default = false;
16: 	bool format = false;
17: 
18: 	JsonSerializeBindData(bool skip_if_null_p, bool skip_if_empty_p, bool skip_if_default_p, bool format_p)
19: 	    : skip_if_null(skip_if_null_p), skip_if_empty(skip_if_empty_p), skip_if_default(skip_if_default_p),
20: 	      format(format_p) {
21: 	}
22: 
23: public:
24: 	unique_ptr<FunctionData> Copy() const override {
25: 		return make_uniq<JsonSerializeBindData>(skip_if_null, skip_if_empty, skip_if_default, format);
26: 	}
27: 	bool Equals(const FunctionData &other_p) const override {
28: 		return true;
29: 	}
30: };
31: 
32: static unique_ptr<FunctionData> JsonSerializeBind(ClientContext &context, ScalarFunction &bound_function,
33:                                                   vector<unique_ptr<Expression>> &arguments) {
34: 	if (arguments.empty()) {
35: 		throw BinderException("json_serialize_sql takes at least one argument");
36: 	}
37: 
38: 	if (arguments[0]->return_type != LogicalType::VARCHAR) {
39: 		throw InvalidTypeException("json_serialize_sql first argument must be a VARCHAR");
40: 	}
41: 
42: 	// Optional arguments
43: 
44: 	bool skip_if_null = false;
45: 	bool skip_if_empty = false;
46: 	bool skip_if_default = false;
47: 	bool format = false;
48: 
49: 	for (idx_t i = 1; i < arguments.size(); i++) {
50: 		auto &arg = arguments[i];
51: 		if (arg->HasParameter()) {
52: 			throw ParameterNotResolvedException();
53: 		}
54: 		if (!arg->IsFoldable()) {
55: 			throw BinderException("json_serialize_sql: arguments must be constant");
56: 		}
57: 		if (arg->alias == "skip_null") {
58: 			if (arg->return_type.id() != LogicalTypeId::BOOLEAN) {
59: 				throw BinderException("json_serialize_sql: 'skip_null' argument must be a boolean");
60: 			}
61: 			skip_if_null = BooleanValue::Get(ExpressionExecutor::EvaluateScalar(context, *arg));
62: 		} else if (arg->alias == "skip_empty") {
63: 			if (arg->return_type.id() != LogicalTypeId::BOOLEAN) {
64: 				throw BinderException("json_serialize_sql: 'skip_empty' argument must be a boolean");
65: 			}
66: 			skip_if_empty = BooleanValue::Get(ExpressionExecutor::EvaluateScalar(context, *arg));
67: 		} else if (arg->alias == "format") {
68: 			if (arg->return_type.id() != LogicalTypeId::BOOLEAN) {
69: 				throw BinderException("json_serialize_sql: 'format' argument must be a boolean");
70: 			}
71: 			format = BooleanValue::Get(ExpressionExecutor::EvaluateScalar(context, *arg));
72: 		} else if (arg->alias == "skip_default") {
73: 			if (arg->return_type.id() != LogicalTypeId::BOOLEAN) {
74: 				throw BinderException("json_serialize_sql: 'skip_default' argument must be a boolean");
75: 			}
76: 			skip_if_default = BooleanValue::Get(ExpressionExecutor::EvaluateScalar(context, *arg));
77: 		} else {
78: 			throw BinderException(StringUtil::Format("json_serialize_sql: Unknown argument '%s'", arg->alias));
79: 		}
80: 	}
81: 	return make_uniq<JsonSerializeBindData>(skip_if_null, skip_if_empty, skip_if_default, format);
82: }
83: 
84: static void JsonSerializeFunction(DataChunk &args, ExpressionState &state, Vector &result) {
85: 	auto &local_state = JSONFunctionLocalState::ResetAndGet(state);
86: 	auto alc = local_state.json_allocator.GetYYAlc();
87: 	auto &inputs = args.data[0];
88: 
89: 	auto &func_expr = state.expr.Cast<BoundFunctionExpression>();
90: 	const auto &info = func_expr.bind_info->Cast<JsonSerializeBindData>();
91: 
92: 	UnaryExecutor::Execute<string_t, string_t>(inputs, result, args.size(), [&](string_t input) {
93: 		auto doc = JSONCommon::CreateDocument(alc);
94: 		auto result_obj = yyjson_mut_obj(doc);
95: 		yyjson_mut_doc_set_root(doc, result_obj);
96: 
97: 		try {
98: 			auto parser = Parser();
99: 			parser.ParseQuery(input.GetString());
100: 
101: 			auto statements_arr = yyjson_mut_arr(doc);
102: 
103: 			for (auto &statement : parser.statements) {
104: 				if (statement->type != StatementType::SELECT_STATEMENT) {
105: 					throw NotImplementedException("Only SELECT statements can be serialized to json!");
106: 				}
107: 				auto &select = statement->Cast<SelectStatement>();
108: 				auto json =
109: 				    JsonSerializer::Serialize(select, doc, info.skip_if_null, info.skip_if_empty, info.skip_if_default);
110: 
111: 				yyjson_mut_arr_append(statements_arr, json);
112: 			}
113: 
114: 			yyjson_mut_obj_add_false(doc, result_obj, "error");
115: 			yyjson_mut_obj_add_val(doc, result_obj, "statements", statements_arr);
116: 			idx_t len;
117: 			auto data = yyjson_mut_val_write_opts(result_obj,
118: 			                                      info.format ? JSONCommon::WRITE_PRETTY_FLAG : JSONCommon::WRITE_FLAG,
119: 			                                      alc, reinterpret_cast<size_t *>(&len), nullptr);
120: 			if (data == nullptr) {
121: 				throw SerializationException(
122: 				    "Failed to serialize json, perhaps the query contains invalid utf8 characters?");
123: 			}
124: 			return StringVector::AddString(result, data, len);
125: 
126: 		} catch (std::exception &ex) {
127: 			ErrorData error(ex);
128: 			yyjson_mut_obj_add_true(doc, result_obj, "error");
129: 			yyjson_mut_obj_add_strcpy(doc, result_obj, "error_type",
130: 			                          StringUtil::Lower(Exception::ExceptionTypeToString(error.Type())).c_str());
131: 			yyjson_mut_obj_add_strcpy(doc, result_obj, "error_message", error.RawMessage().c_str());
132: 			// add extra info
133: 			for (auto &entry : error.ExtraInfo()) {
134: 				yyjson_mut_obj_add_strcpy(doc, result_obj, entry.first.c_str(), entry.second.c_str());
135: 			}
136: 
137: 			idx_t len;
138: 			auto data = yyjson_mut_val_write_opts(result_obj,
139: 			                                      info.format ? JSONCommon::WRITE_PRETTY_FLAG : JSONCommon::WRITE_FLAG,
140: 			                                      alc, reinterpret_cast<size_t *>(&len), nullptr);
141: 			return StringVector::AddString(result, data, len);
142: 		}
143: 	});
144: }
145: 
146: ScalarFunctionSet JSONFunctions::GetSerializeSqlFunction() {
147: 	ScalarFunctionSet set("json_serialize_sql");
148: 	set.AddFunction(ScalarFunction({LogicalType::VARCHAR}, LogicalType::JSON(), JsonSerializeFunction,
149: 	                               JsonSerializeBind, nullptr, nullptr, JSONFunctionLocalState::Init));
150: 
151: 	set.AddFunction(ScalarFunction({LogicalType::VARCHAR, LogicalType::BOOLEAN}, LogicalType::JSON(),
152: 	                               JsonSerializeFunction, JsonSerializeBind, nullptr, nullptr,
153: 	                               JSONFunctionLocalState::Init));
154: 
155: 	set.AddFunction(ScalarFunction({LogicalType::VARCHAR, LogicalType::BOOLEAN, LogicalType::BOOLEAN},
156: 	                               LogicalType::JSON(), JsonSerializeFunction, JsonSerializeBind, nullptr, nullptr,
157: 	                               JSONFunctionLocalState::Init));
158: 
159: 	set.AddFunction(ScalarFunction(
160: 	    {LogicalType::VARCHAR, LogicalType::BOOLEAN, LogicalType::BOOLEAN, LogicalType::BOOLEAN}, LogicalType::JSON(),
161: 	    JsonSerializeFunction, JsonSerializeBind, nullptr, nullptr, JSONFunctionLocalState::Init));
162: 
163: 	return set;
164: }
165: 
166: //----------------------------------------------------------------------
167: // JSON DESERIALIZE
168: //----------------------------------------------------------------------
169: static unique_ptr<SelectStatement> DeserializeSelectStatement(string_t input, yyjson_alc *alc) {
170: 	auto doc = JSONCommon::ReadDocument(input, JSONCommon::READ_FLAG, alc);
171: 	if (!doc) {
172: 		throw ParserException("Could not parse json");
173: 	}
174: 	auto root = doc->root;
175: 	auto err = yyjson_obj_get(root, "error");
176: 	if (err && yyjson_is_true(err)) {
177: 		auto err_type = yyjson_obj_get(root, "error_type");
178: 		auto err_msg = yyjson_obj_get(root, "error_message");
179: 		if (err_type && err_msg) {
180: 			throw ParserException("Error parsing json: %s: %s", yyjson_get_str(err_type), yyjson_get_str(err_msg));
181: 		}
182: 		throw ParserException(
183: 		    "Error parsing json, expected error property to contain 'error_type' and 'error_message'");
184: 	}
185: 
186: 	auto statements = yyjson_obj_get(root, "statements");
187: 	if (!statements || !yyjson_is_arr(statements)) {
188: 		throw ParserException("Error parsing json: no statements array");
189: 	}
190: 	auto size = yyjson_arr_size(statements);
191: 	if (size == 0) {
192: 		throw ParserException("Error parsing json: no statements");
193: 	}
194: 	if (size > 1) {
195: 		throw ParserException("Error parsing json: more than one statement");
196: 	}
197: 	auto stmt_json = yyjson_arr_get(statements, 0);
198: 	JsonDeserializer deserializer(stmt_json, doc);
199: 	return SelectStatement::Deserialize(deserializer);
200: }
201: 
202: //----------------------------------------------------------------------
203: // JSON DESERIALIZE SQL FUNCTION
204: //----------------------------------------------------------------------
205: static void JsonDeserializeFunction(DataChunk &args, ExpressionState &state, Vector &result) {
206: 
207: 	auto &local_state = JSONFunctionLocalState::ResetAndGet(state);
208: 	auto alc = local_state.json_allocator.GetYYAlc();
209: 	auto &inputs = args.data[0];
210: 
211: 	UnaryExecutor::Execute<string_t, string_t>(inputs, result, args.size(), [&](string_t input) {
212: 		auto stmt = DeserializeSelectStatement(input, alc);
213: 		return StringVector::AddString(result, stmt->ToString());
214: 	});
215: }
216: 
217: ScalarFunctionSet JSONFunctions::GetDeserializeSqlFunction() {
218: 	ScalarFunctionSet set("json_deserialize_sql");
219: 	set.AddFunction(ScalarFunction({LogicalType::JSON()}, LogicalType::VARCHAR, JsonDeserializeFunction, nullptr,
220: 	                               nullptr, nullptr, JSONFunctionLocalState::Init));
221: 	return set;
222: }
223: 
224: //----------------------------------------------------------------------
225: // JSON EXECUTE SERIALIZED SQL (PRAGMA)
226: //----------------------------------------------------------------------
227: static string ExecuteJsonSerializedSqlPragmaFunction(ClientContext &context, const FunctionParameters &parameters) {
228: 	JSONFunctionLocalState local_state(context);
229: 	auto alc = local_state.json_allocator.GetYYAlc();
230: 
231: 	auto input = parameters.values[0].GetValueUnsafe<string_t>();
232: 	auto stmt = DeserializeSelectStatement(input, alc);
233: 	return stmt->ToString();
234: }
235: 
236: PragmaFunctionSet JSONFunctions::GetExecuteJsonSerializedSqlPragmaFunction() {
237: 	return PragmaFunctionSet(PragmaFunction::PragmaCall(
238: 	    "json_execute_serialized_sql", ExecuteJsonSerializedSqlPragmaFunction, {LogicalType::VARCHAR}));
239: }
240: 
241: //----------------------------------------------------------------------
242: // JSON EXECUTE SERIALIZED SQL (TABLE FUNCTION)
243: //----------------------------------------------------------------------
244: struct ExecuteSqlTableFunction {
245: 	struct BindData : public TableFunctionData {
246: 		shared_ptr<Relation> plan;
247: 		unique_ptr<QueryResult> result;
248: 		unique_ptr<Connection> con;
249: 	};
250: 
251: 	static unique_ptr<FunctionData> Bind(ClientContext &context, TableFunctionBindInput &input,
252: 	                                     vector<LogicalType> &return_types, vector<string> &names) {
253: 		JSONFunctionLocalState local_state(context);
254: 		auto alc = local_state.json_allocator.GetYYAlc();
255: 
256: 		auto result = make_uniq<BindData>();
257: 
258: 		result->con = make_uniq<Connection>(*context.db);
259: 		if (input.inputs[0].IsNull()) {
260: 			throw BinderException("json_execute_serialized_sql cannot execute NULL plan");
261: 		}
262: 		auto serialized = input.inputs[0].GetValueUnsafe<string>();
263: 		auto stmt = DeserializeSelectStatement(serialized, alc);
264: 		result->plan = result->con->RelationFromQuery(std::move(stmt));
265: 
266: 		for (auto &col : result->plan->Columns()) {
267: 			return_types.emplace_back(col.Type());
268: 			names.emplace_back(col.Name());
269: 		}
270: 		return std::move(result);
271: 	}
272: 
273: 	static void Function(ClientContext &context, TableFunctionInput &data_p, DataChunk &output) {
274: 		auto &data = (BindData &)*data_p.bind_data;
275: 		if (!data.result) {
276: 			data.result = data.plan->Execute();
277: 		}
278: 		auto result_chunk = data.result->Fetch();
279: 		if (!result_chunk) {
280: 			return;
281: 		}
282: 		output.Move(*result_chunk);
283: 	}
284: };
285: 
286: TableFunctionSet JSONFunctions::GetExecuteJsonSerializedSqlFunction() {
287: 	TableFunction func("json_execute_serialized_sql", {LogicalType::VARCHAR}, ExecuteSqlTableFunction::Function,
288: 	                   ExecuteSqlTableFunction::Bind);
289: 	return TableFunctionSet(func);
290: }
291: 
292: } // namespace duckdb
[end of extension/json/json_functions/json_serialize_sql.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: