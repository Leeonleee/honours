diff --git a/src/execution/aggregate_hashtable.cpp b/src/execution/aggregate_hashtable.cpp
index ebee45c3720c..66a36a439b1c 100644
--- a/src/execution/aggregate_hashtable.cpp
+++ b/src/execution/aggregate_hashtable.cpp
@@ -677,7 +677,9 @@ idx_t GroupedAggregateHashTable::Scan(idx_t &scan_position, DataChunk &result) {
 }
 
 void GroupedAggregateHashTable::Finalize() {
-	D_ASSERT(!is_finalized);
+	if (is_finalized) {
+		return;
+	}
 
 	// early release hashes, not needed for partition/scan
 	hashes_hdl.reset();
diff --git a/src/execution/operator/scan/physical_expression_scan.cpp b/src/execution/operator/scan/physical_expression_scan.cpp
index d2e411c5ec13..6bed84636c2c 100644
--- a/src/execution/operator/scan/physical_expression_scan.cpp
+++ b/src/execution/operator/scan/physical_expression_scan.cpp
@@ -4,7 +4,7 @@
 
 namespace duckdb {
 
-class ExpressionScanState : public GlobalSourceState {
+class ExpressionScanState : public OperatorState {
 public:
 	explicit ExpressionScanState(const PhysicalExpressionScan &op) : expression_index(0) {
 		temp_chunk.Initialize(op.GetTypes());
@@ -16,16 +16,26 @@ class ExpressionScanState : public GlobalSourceState {
 	DataChunk temp_chunk;
 };
 
-class ExpressionSinkState : public GlobalSinkState {
-public:
-	ExpressionSinkState() {
-	}
+unique_ptr<OperatorState> PhysicalExpressionScan::GetOperatorState(ClientContext &context) const {
+	return make_unique<ExpressionScanState>(*this);
+}
 
-	DataChunk child_chunk;
-};
+OperatorResultType PhysicalExpressionScan::Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,
+                                                   OperatorState &state_p) const {
+	auto &state = (ExpressionScanState &)state_p;
 
-unique_ptr<GlobalSourceState> PhysicalExpressionScan::GetGlobalSourceState(ClientContext &context) const {
-	return make_unique<ExpressionScanState>(*this);
+	for (; chunk.size() + input.size() <= STANDARD_VECTOR_SIZE && state.expression_index < expressions.size();
+	     state.expression_index++) {
+		state.temp_chunk.Reset();
+		EvaluateExpression(state.expression_index, &input, state.temp_chunk);
+		chunk.Append(state.temp_chunk);
+	}
+	if (state.expression_index < expressions.size()) {
+		return OperatorResultType::HAVE_MORE_OUTPUT;
+	} else {
+		state.expression_index = 0;
+		return OperatorResultType::NEED_MORE_INPUT;
+	}
 }
 
 void PhysicalExpressionScan::EvaluateExpression(idx_t expression_idx, DataChunk *child_chunk, DataChunk &result) const {
@@ -38,20 +48,6 @@ void PhysicalExpressionScan::EvaluateExpression(idx_t expression_idx, DataChunk
 	}
 }
 
-void PhysicalExpressionScan::GetData(ExecutionContext &context, DataChunk &chunk, GlobalSourceState &gstate_p,
-                                     LocalSourceState &lstate) const {
-	D_ASSERT(sink_state);
-	auto &state = (ExpressionScanState &)gstate_p;
-	auto &gstate = (ExpressionSinkState &)*sink_state;
-
-	for (; chunk.size() < STANDARD_VECTOR_SIZE && state.expression_index < expressions.size();
-	     state.expression_index++) {
-		state.temp_chunk.Reset();
-		EvaluateExpression(state.expression_index, &gstate.child_chunk, state.temp_chunk);
-		chunk.Append(state.temp_chunk);
-	}
-}
-
 bool PhysicalExpressionScan::IsFoldable() const {
 	for (auto &expr_list : expressions) {
 		for (auto &expr : expr_list) {
@@ -63,22 +59,4 @@ bool PhysicalExpressionScan::IsFoldable() const {
 	return true;
 }
 
-SinkResultType PhysicalExpressionScan::Sink(ExecutionContext &context, GlobalSinkState &gstate_p,
-                                            LocalSinkState &lstate, DataChunk &input) const {
-	auto &gstate = (ExpressionSinkState &)gstate_p;
-
-	D_ASSERT(children.size() == 1);
-	D_ASSERT(gstate.child_chunk.size() == 0);
-	if (input.size() != 1) {
-		throw InternalException("Expected expression scan child to have exactly one element");
-	}
-	gstate.child_chunk.Move(input);
-	gstate.child_chunk.Verify();
-	return SinkResultType::FINISHED;
-}
-
-unique_ptr<GlobalSinkState> PhysicalExpressionScan::GetGlobalSinkState(ClientContext &context) const {
-	return make_unique<ExpressionSinkState>();
-}
-
 } // namespace duckdb
diff --git a/src/include/duckdb/execution/operator/scan/physical_expression_scan.hpp b/src/include/duckdb/execution/operator/scan/physical_expression_scan.hpp
index 180a828bdc2c..141c966ba24c 100644
--- a/src/include/duckdb/execution/operator/scan/physical_expression_scan.hpp
+++ b/src/include/duckdb/execution/operator/scan/physical_expression_scan.hpp
@@ -27,18 +27,11 @@ class PhysicalExpressionScan : public PhysicalOperator {
 	vector<vector<unique_ptr<Expression>>> expressions;
 
 public:
-	unique_ptr<GlobalSourceState> GetGlobalSourceState(ClientContext &context) const override;
-	void GetData(ExecutionContext &context, DataChunk &chunk, GlobalSourceState &gstate,
-	             LocalSourceState &lstate) const override;
+	unique_ptr<OperatorState> GetOperatorState(ClientContext &context) const override;
+	OperatorResultType Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,
+	                           OperatorState &state) const override;
 
-public:
-	// Sink interface
-	SinkResultType Sink(ExecutionContext &context, GlobalSinkState &gstate, LocalSinkState &lstate,
-	                    DataChunk &input) const override;
-
-	unique_ptr<GlobalSinkState> GetGlobalSinkState(ClientContext &context) const override;
-
-	bool IsSink() const override {
+	bool ParallelOperator() const override {
 		return true;
 	}
 
diff --git a/src/parallel/executor.cpp b/src/parallel/executor.cpp
index 7a2b2c249b92..a6c081c09dfa 100644
--- a/src/parallel/executor.cpp
+++ b/src/parallel/executor.cpp
@@ -410,7 +410,6 @@ void Executor::BuildPipelines(PhysicalOperator *op, Pipeline *current) {
 		case PhysicalOperatorType::TOP_N:
 		case PhysicalOperatorType::COPY_TO_FILE:
 		case PhysicalOperatorType::LIMIT:
-		case PhysicalOperatorType::EXPRESSION_SCAN:
 		case PhysicalOperatorType::EXPLAIN_ANALYZE:
 			D_ASSERT(op->children.size() == 1);
 			// single operator:
diff --git a/src/planner/expression_iterator.cpp b/src/planner/expression_iterator.cpp
index 5077105ee916..17cce4b6a819 100644
--- a/src/planner/expression_iterator.cpp
+++ b/src/planner/expression_iterator.cpp
@@ -146,6 +146,15 @@ void ExpressionIterator::EnumerateTableRefChildren(BoundTableRef &ref,
 		EnumerateTableRefChildren(*bound_crossproduct.right, callback);
 		break;
 	}
+	case TableReferenceType::EXPRESSION_LIST: {
+		auto &bound_expr_list = (BoundExpressionListRef &)ref;
+		for (auto &expr_list : bound_expr_list.values) {
+			for (auto &expr : expr_list) {
+				EnumerateExpression(expr, callback);
+			}
+		}
+		break;
+	}
 	case TableReferenceType::JOIN: {
 		auto &bound_join = (BoundJoinRef &)ref;
 		EnumerateExpression(bound_join.condition, callback);
diff --git a/src/planner/subquery/flatten_dependent_join.cpp b/src/planner/subquery/flatten_dependent_join.cpp
index 6263dc401088..46e91e85cdfb 100644
--- a/src/planner/subquery/flatten_dependent_join.cpp
+++ b/src/planner/subquery/flatten_dependent_join.cpp
@@ -314,6 +314,29 @@ unique_ptr<LogicalOperator> FlattenDependentJoins::PushDownDependentJoinInternal
 	case LogicalOperatorType::LOGICAL_DISTINCT:
 		plan->children[0] = PushDownDependentJoin(move(plan->children[0]));
 		return plan;
+	case LogicalOperatorType::LOGICAL_EXPRESSION_GET: {
+		// expression get
+		// first we flatten the dependent join in the child
+		plan->children[0] = PushDownDependentJoinInternal(move(plan->children[0]));
+		// then we replace any correlated expressions with the corresponding entry in the correlated_map
+		RewriteCorrelatedExpressions rewriter(base_binding, correlated_map);
+		rewriter.VisitOperator(*plan);
+		// now we add all the correlated columns to each of the expressions of the expression scan
+		auto expr_get = (LogicalExpressionGet *)plan.get();
+		for (idx_t i = 0; i < correlated_columns.size(); i++) {
+			for (auto &expr_list : expr_get->expressions) {
+				auto colref = make_unique<BoundColumnRefExpression>(
+				    correlated_columns[i].type, ColumnBinding(base_binding.table_index, base_binding.column_index + i));
+				expr_list.push_back(move(colref));
+			}
+			expr_get->expr_types.push_back(correlated_columns[i].type);
+		}
+
+		base_binding.table_index = expr_get->table_index;
+		this->delim_offset = base_binding.column_index = expr_get->expr_types.size() - correlated_columns.size();
+		this->data_offset = 0;
+		return plan;
+	}
 	case LogicalOperatorType::LOGICAL_ORDER_BY:
 		throw ParserException("ORDER BY not supported in correlated subquery");
 	default:
