{
  "repo": "duckdb/duckdb",
  "pull_number": 621,
  "instance_id": "duckdb__duckdb-621",
  "issue_numbers": [
    "629",
    "628"
  ],
  "base_commit": "0e4b94f958b120fdaad45bda594933a2b84fced5",
  "patch": "diff --git a/src/catalog/catalog_entry/table_catalog_entry.cpp b/src/catalog/catalog_entry/table_catalog_entry.cpp\nindex 323189376e0f..b037f5c976b5 100644\n--- a/src/catalog/catalog_entry/table_catalog_entry.cpp\n+++ b/src/catalog/catalog_entry/table_catalog_entry.cpp\n@@ -62,7 +62,7 @@ TableCatalogEntry::TableCatalogEntry(Catalog *catalog, SchemaCatalogEntry *schem\n \t\t\t\t\tcolumn_ids.push_back(key);\n \t\t\t\t}\n \t\t\t\t// create an adaptive radix tree around the expressions\n-\t\t\t\tauto art = make_unique<ART>(*storage, column_ids, move(unbound_expressions), true);\n+\t\t\t\tauto art = make_unique<ART>(column_ids, move(unbound_expressions), true);\n \t\t\t\tstorage->AddIndex(move(art), bound_expressions);\n \t\t\t}\n \t\t}\n@@ -246,9 +246,21 @@ unique_ptr<CatalogEntry> TableCatalogEntry::RemoveColumn(ClientContext &context,\n \t\t\t}\n \t\t\tbreak;\n \t\t}\n-\t\tcase ConstraintType::UNIQUE:\n-\t\t\tcreate_info->constraints.push_back(constraint->Copy());\n+\t\tcase ConstraintType::UNIQUE: {\n+\t\t\tauto copy = constraint->Copy();\n+\t\t\tauto &unique = (UniqueConstraint &) *copy;\n+\t\t\tif (unique.index != INVALID_INDEX) {\n+\t\t\t\tif (unique.index == removed_index) {\n+\t\t\t\t\tthrow CatalogException(\n+\t\t\t\t\t    \"Cannot drop column \\\"%s\\\" because there is a UNIQUE constraint that depends on it\",\n+\t\t\t\t\t    info.removed_column.c_str());\n+\t\t\t\t} else if (unique.index > removed_index) {\n+\t\t\t\t\tunique.index--;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\tcreate_info->constraints.push_back(move(copy));\n \t\t\tbreak;\n+\t\t}\n \t\tdefault:\n \t\t\tthrow InternalException(\"Unsupported constraint for entry!\");\n \t\t}\n@@ -337,10 +349,13 @@ unique_ptr<CatalogEntry> TableCatalogEntry::ChangeColumnType(ClientContext &cont\n \tAlterBinder expr_binder(binder, context, name, columns, bound_columns, info.target_type);\n \tauto expression = info.expression->Copy();\n \tauto bound_expression = expr_binder.Bind(expression);\n+\tauto bound_create_info = binder.BindCreateTableInfo(move(create_info));\n+\tif (bound_columns.size() == 0) {\n+\t\tbound_columns.push_back(COLUMN_IDENTIFIER_ROW_ID);\n+\t}\n+\n \tauto new_storage =\n \t    make_shared<DataTable>(context, *storage, change_idx, info.target_type, move(bound_columns), *bound_expression);\n-\n-\tauto bound_create_info = binder.BindCreateTableInfo(move(create_info));\n \treturn make_unique<TableCatalogEntry>(catalog, schema, (BoundCreateTableInfo *)bound_create_info.get(),\n \t                                      new_storage);\n }\ndiff --git a/src/execution/index/art/art.cpp b/src/execution/index/art/art.cpp\nindex 74d3a161cdc1..dfa900a9d05e 100644\n--- a/src/execution/index/art/art.cpp\n+++ b/src/execution/index/art/art.cpp\n@@ -7,9 +7,9 @@\n using namespace duckdb;\n using namespace std;\n \n-ART::ART(DataTable &table, vector<column_t> column_ids, vector<unique_ptr<Expression>> unbound_expressions,\n+ART::ART(vector<column_t> column_ids, vector<unique_ptr<Expression>> unbound_expressions,\n          bool is_unique)\n-    : Index(IndexType::ART, table, column_ids, move(unbound_expressions)), is_unique(is_unique) {\n+    : Index(IndexType::ART, column_ids, move(unbound_expressions)), is_unique(is_unique) {\n \ttree = nullptr;\n \texpression_result.Initialize(types);\n \tint n = 1;\n@@ -724,7 +724,7 @@ void ART::SearchCloseRange(vector<row_t> &result_ids, ARTIndexScanState *state,\n \t}\n }\n \n-void ART::Scan(Transaction &transaction, TableIndexScanState &table_state, DataChunk &result) {\n+void ART::Scan(Transaction &transaction, DataTable &table, TableIndexScanState &table_state, DataChunk &result) {\n \tauto state = (ARTIndexScanState *)table_state.index_state.get();\n \n \t// scan the index\ndiff --git a/src/execution/operator/schema/physical_create_index.cpp b/src/execution/operator/schema/physical_create_index.cpp\nindex bed54e94b995..4b82fb920f63 100644\n--- a/src/execution/operator/schema/physical_create_index.cpp\n+++ b/src/execution/operator/schema/physical_create_index.cpp\n@@ -24,7 +24,7 @@ void PhysicalCreateIndex::GetChunkInternal(ClientContext &context, DataChunk &ch\n \tunique_ptr<Index> index;\n \tswitch (info->index_type) {\n \tcase IndexType::ART: {\n-\t\tindex = make_unique<ART>(*table.storage, column_ids, move(unbound_expressions), info->unique);\n+\t\tindex = make_unique<ART>(column_ids, move(unbound_expressions), info->unique);\n \t\tbreak;\n \t}\n \tdefault:\ndiff --git a/src/include/duckdb/execution/index/art/art.hpp b/src/include/duckdb/execution/index/art/art.hpp\nindex 895a4e7f8b01..a867d0c75dd9 100644\n--- a/src/include/duckdb/execution/index/art/art.hpp\n+++ b/src/include/duckdb/execution/index/art/art.hpp\n@@ -54,8 +54,7 @@ struct ARTIndexScanState : public IndexScanState {\n \n class ART : public Index {\n public:\n-\tART(DataTable &table, vector<column_t> column_ids, vector<unique_ptr<Expression>> unbound_expressions,\n-\t    bool is_unique = false);\n+\tART(vector<column_t> column_ids, vector<unique_ptr<Expression>> unbound_expressions, bool is_unique = false);\n \t~ART();\n \n \t//! Root of the tree\n@@ -79,7 +78,7 @@ class ART : public Index {\n \t                                                       ExpressionType high_expression_type) override;\n \n \t//! Perform a lookup on the index\n-\tvoid Scan(Transaction &transaction, TableIndexScanState &state, DataChunk &result) override;\n+\tvoid Scan(Transaction &transaction, DataTable &table, TableIndexScanState &state, DataChunk &result) override;\n \t//! Append entries to the index\n \tbool Append(IndexLock &lock, DataChunk &entries, Vector &row_identifiers) override;\n \t//! Verify that data can be appended to the index\ndiff --git a/src/include/duckdb/storage/index.hpp b/src/include/duckdb/storage/index.hpp\nindex f8e80a728b06..0f12d477adb8 100644\n--- a/src/include/duckdb/storage/index.hpp\n+++ b/src/include/duckdb/storage/index.hpp\n@@ -19,7 +19,6 @@\n namespace duckdb {\n \n class ClientContext;\n-class DataTable;\n class Transaction;\n \n struct IndexLock;\n@@ -27,7 +26,7 @@ struct IndexLock;\n //! The index is an abstract base class that serves as the basis for indexes\n class Index {\n public:\n-\tIndex(IndexType type, DataTable &table, vector<column_t> column_ids,\n+\tIndex(IndexType type, vector<column_t> column_ids,\n \t      vector<unique_ptr<Expression>> unbound_expressions);\n \tvirtual ~Index() = default;\n \n@@ -35,8 +34,6 @@ class Index {\n \tstd::mutex lock;\n \t//! The type of the index\n \tIndexType type;\n-\t//! The table\n-\tDataTable &table;\n \t//! Column identifiers to extract from the base table\n \tvector<column_t> column_ids;\n \t//! unordered_set of column_ids used by the index\n@@ -59,7 +56,7 @@ class Index {\n \t                                                               ExpressionType low_expression_type, Value high_value,\n \t                                                               ExpressionType high_expression_type) = 0;\n \t//! Perform a lookup on the index\n-\tvirtual void Scan(Transaction &transaction, TableIndexScanState &state, DataChunk &result) = 0;\n+\tvirtual void Scan(Transaction &transaction, DataTable &table, TableIndexScanState &state, DataChunk &result) = 0;\n \n \t//! Obtain a lock on the index\n \tvirtual void InitializeLock(IndexLock &state);\ndiff --git a/src/storage/data_table.cpp b/src/storage/data_table.cpp\nindex 908e9cf9c813..27e0ccea6e01 100644\n--- a/src/storage/data_table.cpp\n+++ b/src/storage/data_table.cpp\n@@ -47,8 +47,6 @@ DataTable::DataTable(ClientContext &context, DataTable &parent, ColumnDefinition\n       transient_manager(parent.transient_manager), columns(parent.columns), is_root(true) {\n \t// prevent any new tuples from being added to the parent\n \tlock_guard<mutex> parent_lock(parent.append_lock);\n-\t// this table replaces the previous table, hence the parent is no longer the root DataTable\n-\tparent.is_root = false;\n \t// add the new column to this DataTable\n \tauto new_column_type = GetInternalType(new_column.type);\n \tidx_t new_column_idx = columns.size();\n@@ -84,6 +82,9 @@ DataTable::DataTable(ClientContext &context, DataTable &parent, ColumnDefinition\n \t}\n \t// also add this column to client local storage\n \tTransaction::GetTransaction(context).storage.AddColumn(&parent, this, new_column, default_value);\n+\n+\t// this table replaces the previous table, hence the parent is no longer the root DataTable\n+\tparent.is_root = false;\n }\n \n DataTable::DataTable(ClientContext &context, DataTable &parent, idx_t removed_column)\n@@ -101,12 +102,13 @@ DataTable::DataTable(ClientContext &context, DataTable &parent, idx_t removed_co\n \t\t\t}\n \t\t}\n \t}\n-\t// this table replaces the previous table, hence the parent is no longer the root DataTable\n-\tparent.is_root = false;\n \t// erase the column from this DataTable\n \tassert(removed_column < types.size());\n \ttypes.erase(types.begin() + removed_column);\n \tcolumns.erase(columns.begin() + removed_column);\n+\n+\t// this table replaces the previous table, hence the parent is no longer the root DataTable\n+\tparent.is_root = false;\n }\n \n DataTable::DataTable(ClientContext &context, DataTable &parent, idx_t changed_idx, SQLType target_type,\n@@ -115,9 +117,9 @@ DataTable::DataTable(ClientContext &context, DataTable &parent, idx_t changed_id\n       transient_manager(parent.transient_manager), columns(parent.columns), is_root(true) {\n \n \t// prevent any new tuples from being added to the parent\n-\tlock_guard<mutex> parent_lock(parent.append_lock);\n-\t// this table replaces the previous table, hence the parent is no longer the root DataTable\n-\tparent.is_root = false;\n+\tCreateIndexScanState scan_state;\n+\tparent.InitializeCreateIndexScan(scan_state, bound_columns);\n+\n \t// first check if there are any indexes that exist that point to the changed column\n \tfor (auto &index : info->indexes) {\n \t\tfor (auto &column_id : index->column_ids) {\n@@ -140,17 +142,18 @@ DataTable::DataTable(ClientContext &context, DataTable &parent, idx_t changed_id\n \n \t// scan the original table, and fill the new column with the transformed value\n \tauto &transaction = Transaction::GetTransaction(context);\n-\tTableScanState scan_state;\n \n \tvector<TypeId> types;\n \tfor (idx_t i = 0; i < bound_columns.size(); i++) {\n-\t\ttypes.push_back(parent.types[i]);\n+\t\tif (bound_columns[i] == COLUMN_IDENTIFIER_ROW_ID) {\n+\t\t\ttypes.push_back(ROW_TYPE);\n+\t\t} else {\n+\t\t\ttypes.push_back(parent.types[bound_columns[i]]);\n+\t\t}\n \t}\n-\tparent.InitializeScan(transaction, scan_state, bound_columns, nullptr);\n \n \tDataChunk scan_chunk;\n \tscan_chunk.Initialize(types);\n-\tunordered_map<idx_t, vector<TableFilter>> dummy_filters;\n \n \tExpressionExecutor executor;\n \texecutor.AddExpression(cast_expr);\n@@ -158,7 +161,8 @@ DataTable::DataTable(ClientContext &context, DataTable &parent, idx_t changed_id\n \tVector append_vector(new_type);\n \twhile (true) {\n \t\t// scan the table\n-\t\tparent.Scan(transaction, scan_chunk, scan_state, dummy_filters);\n+\t\tscan_chunk.Reset();\n+\t\tparent.CreateIndexScan(scan_state, scan_chunk);\n \t\tif (scan_chunk.size() == 0) {\n \t\t\tbreak;\n \t\t}\n@@ -170,6 +174,9 @@ DataTable::DataTable(ClientContext &context, DataTable &parent, idx_t changed_id\n \ttransaction.storage.ChangeType(&parent, this, changed_idx, target_type, bound_columns, cast_expr);\n \n \tcolumns[changed_idx] = move(column_data);\n+\n+\t// this table replaces the previous table, hence the parent is no longer the root DataTable\n+\tparent.is_root = false;\n }\n \n //===--------------------------------------------------------------------===//\n@@ -448,7 +455,7 @@ void DataTable::IndexScan(Transaction &transaction, DataChunk &result, TableInde\n \t// clear any previously pinned blocks\n \tstate.fetch_state.handles.clear();\n \t// scan the index\n-\tstate.index->Scan(transaction, state, result);\n+\tstate.index->Scan(transaction, *this, state, result);\n \tif (result.size() > 0) {\n \t\treturn;\n \t}\ndiff --git a/src/storage/index.cpp b/src/storage/index.cpp\nindex 805442c019f7..fa0176b74ca2 100644\n--- a/src/storage/index.cpp\n+++ b/src/storage/index.cpp\n@@ -8,9 +8,9 @@\n using namespace duckdb;\n using namespace std;\n \n-Index::Index(IndexType type, DataTable &table, vector<column_t> column_ids,\n+Index::Index(IndexType type, vector<column_t> column_ids,\n              vector<unique_ptr<Expression>> unbound_expressions)\n-    : type(type), table(table), column_ids(column_ids), unbound_expressions(move(unbound_expressions)) {\n+    : type(type), column_ids(column_ids), unbound_expressions(move(unbound_expressions)) {\n \tfor (auto &expr : this->unbound_expressions) {\n \t\ttypes.push_back(expr->return_type);\n \t\tbound_expressions.push_back(BindExpression(expr->Copy()));\ndiff --git a/src/storage/local_storage.cpp b/src/storage/local_storage.cpp\nindex 9f9b4a1dc4bc..90003c6faa47 100644\n--- a/src/storage/local_storage.cpp\n+++ b/src/storage/local_storage.cpp\n@@ -18,7 +18,7 @@ LocalTableStorage::LocalTableStorage(DataTable &table) : max_row(0) {\n \t\t\tfor (auto &expr : art.unbound_expressions) {\n \t\t\t\tunbound_expressions.push_back(expr->Copy());\n \t\t\t}\n-\t\t\tindexes.push_back(make_unique<ART>(table, art.column_ids, move(unbound_expressions), true));\n+\t\t\tindexes.push_back(make_unique<ART>(art.column_ids, move(unbound_expressions), true));\n \t\t}\n \t}\n }\n",
  "test_patch": "diff --git a/test/rigger/test_rigger.cpp b/test/rigger/test_rigger.cpp\nindex 37644302d706..18f1be727a28 100644\n--- a/test/rigger/test_rigger.cpp\n+++ b/test/rigger/test_rigger.cpp\n@@ -678,4 +678,55 @@ TEST_CASE(\"Tests found by Rigger\", \"[rigger]\") {\n \t\tresult = con.Query(\"SELECT MIN(100000000000000000<<t0.rowid) FROM t0 WHERE NOT c0;\");\n \t\tREQUIRE(CHECK_COLUMN(result, 0, {Value::BIGINT(-8802109549835190272LL)}));\n \t}\n+\tSECTION(\"618\") {\n+\t\t// Failed ALTER COLUMN results in a \"Transaction conflict\" error that cannot be aborted\n+\t\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE t0(c0 DATE);\"));\n+\t\tREQUIRE_NO_FAIL(con.Query(\"INSERT INTO t0 VALUES (DATE '2000-01-01');\"));\n+\t\tREQUIRE_FAIL(con.Query(\"ALTER TABLE t0 ALTER COLUMN c0 SET DATA TYPE INT;\"));\n+\t\tREQUIRE_NO_FAIL(con.Query(\"INSERT INTO t0 VALUES (DEFAULT);\"));\n+\t}\n+\tSECTION(\"619\") {\n+\t\t// Query on altered table results in a segmentation fault\n+\t\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE t0(c0 INT UNIQUE, c1 DATE);\"));\n+\t\tREQUIRE_NO_FAIL(con.Query(\"ALTER TABLE t0 ALTER c1 TYPE INT;\"));\n+\t\tREQUIRE_NO_FAIL(con.Query(\"INSERT INTO t0(c0) VALUES(-1);\"));\n+\n+\t\tresult = con.Query(\"SELECT * FROM t0 WHERE c0 < 0;\");\n+\t\tREQUIRE(CHECK_COLUMN(result, 0, {-1}));\n+\t\tREQUIRE(CHECK_COLUMN(result, 1, {Value()}));\n+\t}\n+\tSECTION(\"622\") {\n+\t\t// UPDATE on altered table results in an error \"Could not find node in column segment tree\"\n+\t\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE t0(c0 TIMESTAMP);\"));\n+\t\tREQUIRE_NO_FAIL(con.Query(\"INSERT INTO t0 VALUES(NULL);\"));\n+\t\tREQUIRE_NO_FAIL(con.Query(\"DELETE FROM t0;\"));\n+\t\tREQUIRE_NO_FAIL(con.Query(\"ALTER TABLE t0 ALTER c0 TYPE DATE;\"));\n+\t\tREQUIRE_NO_FAIL(con.Query(\"INSERT INTO t0 VALUES(NULL);\"));\n+\t\tREQUIRE_NO_FAIL(con.Query(\"UPDATE t0 SET c0 = '1969-12-18'; \"));\n+\t}\n+\tSECTION(\"624\") {\n+\t\t// ALTER TABLE results in an assertion failure \"Assertion `expr.return_type == vector.type' failed\"\n+\t\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE t0(c0 INT, c1 VARCHAR);\"));\n+\t\tREQUIRE_NO_FAIL(con.Query(\"INSERT INTO t0(c1) VALUES(NULL);\"));\n+\t\tREQUIRE_NO_FAIL(con.Query(\"ALTER TABLE t0 ALTER c1 TYPE TIMESTAMP;\"));\n+\t}\n+\tSECTION(\"625\") {\n+\t\t// DROP column results in an assertion failure unique.index < base.columns.size()\n+\t\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE t0(c0 INT, c INT UNIQUE);\"));\n+\t\t// we don't support this case yet\n+\t\tREQUIRE_FAIL(con.Query(\"ALTER TABLE t0 DROP c0;\"));\n+\t\t// check that unique constraint still works\n+\t\tREQUIRE_NO_FAIL(con.Query(\"INSERT INTO t0 (c) VALUES (1);\"));\n+\t\tREQUIRE_FAIL(con.Query(\"INSERT INTO t0 (c) VALUES (1);\"));\n+\t}\n+\tSECTION(\"628\") {\n+\t\t// DROP column results in an assertion failure unique.index < base.columns.size()\n+\t\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE t0(c0 INT, c1 INT UNIQUE);\"));\n+\t\tREQUIRE_FAIL(con.Query(\"ALTER TABLE t0 DROP c1;\"));\n+\t}\n+\tSECTION(\"629\") {\n+\t\t// ALTER TYPE with USING results in an assertion failure \"types.size() > 0\"\n+\t\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE t0(c0 INT);\"));\n+\t\tREQUIRE_NO_FAIL(con.Query(\"ALTER TABLE t0 ALTER c0 TYPE VARCHAR USING ''; \"));\n+\t}\n }\n",
  "problem_statement": "ALTER TYPE with USING results in an assertion failure \"types.size() > 0\"\nConsider the following statements:\r\n```sql\r\nCREATE TABLE t0(c0 INT);\r\nALTER TABLE t0 ALTER c0 TYPE VARCHAR USING ''; -- Assertion `types.size() > 0' failed.\r\n```\r\nUnexpectedly, the `ALTER TABLE` results in an assertion failure:\r\n```\r\n/duckdb/src/common/types/data_chunk.cpp:25: void duckdb::DataChunk::Initialize(std::vector<duckdb::TypeId>&): Assertion `types.size() > 0' failed.\r\n```\r\nI found this based on commit b6665e723c5f3d9cbd7b0018ce8c242260ac6dc3.\nDROP column results in an assertion failure unique.index < base.columns.size() 2\nConsider the following statements:\r\n```sql\r\nCREATE TABLE t0(c0 INT, c1 INT UNIQUE);\r\nALTER TABLE t0 DROP c1; -- Assertion `unique.index < base.columns.size()' failed.\r\n```\r\nUnexpectedly, the `ALTER TABLE` results in an assertion failure:\r\n```\r\n/duckdb/src/planner/binder/statement/bind_create_table.cpp:60: void BindConstraints(duckdb::Binder&, duckdb::BoundCreateTableInfo&): Assertion `unique.index < base.columns.size()' failed.\r\n```\r\nThis seems to be a very similar underlying issue as https://github.com/cwida/duckdb/issues/625. However, the fix for that issue does not fix the one reported in this bug report. I found this based on commit b6665e723c5f3d9cbd7b0018ce8c242260ac6dc3.\n",
  "hints_text": "\n",
  "created_at": "2020-05-05T08:58:52Z"
}