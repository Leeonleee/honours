{
  "repo": "duckdb/duckdb",
  "pull_number": 5893,
  "instance_id": "duckdb__duckdb-5893",
  "issue_numbers": [
    "4967"
  ],
  "base_commit": "82810801b42516b43ff01f270c4f19f7e0d6f462",
  "patch": "diff --git a/benchmark/micro/index/create_index.benchmark b/benchmark/micro/index/create/create_index.benchmark\nsimilarity index 78%\nrename from benchmark/micro/index/create_index.benchmark\nrename to benchmark/micro/index/create/create_index.benchmark\nindex 79cf64a8f09c..f56d2132e737 100644\n--- a/benchmark/micro/index/create_index.benchmark\n+++ b/benchmark/micro/index/create/create_index.benchmark\n@@ -1,6 +1,6 @@\n-# name: benchmark/micro/index/create_index.benchmark\n+# name: benchmark/micro/index/create/create_index.benchmark\n # description: Create index on 10000000 integer tuples\n-# group: [index]\n+# group: [create]\n \n name Create Index\n group index\ndiff --git a/benchmark/micro/index/create/create_index_duplicates.benchmark b/benchmark/micro/index/create/create_index_duplicates.benchmark\nnew file mode 100644\nindex 000000000000..52662827b1b5\n--- /dev/null\n+++ b/benchmark/micro/index/create/create_index_duplicates.benchmark\n@@ -0,0 +1,15 @@\n+# name: benchmark/micro/index/create/create_index_duplicates.benchmark\n+# description: Create index on 100000000 random integers with many duplicates\n+# group: [create]\n+\n+name Create Index Duplicates\n+group index\n+\n+load\n+CREATE TABLE art AS SELECT (random() * 100)::INT AS id FROM range(100000000);\n+\n+run\n+CREATE INDEX idx ON art(id);\n+\n+cleanup\n+DROP INDEX idx;\ndiff --git a/benchmark/micro/index/create/create_index_random.benchmark b/benchmark/micro/index/create/create_index_random.benchmark\nnew file mode 100644\nindex 000000000000..c97f5c30767a\n--- /dev/null\n+++ b/benchmark/micro/index/create/create_index_random.benchmark\n@@ -0,0 +1,15 @@\n+# name: benchmark/micro/index/create/create_index_random.benchmark\n+# description: Create index on 100000000 random integers\n+# group: [create]\n+\n+name Create Index Random\n+group index\n+\n+load\n+CREATE TABLE art AS SELECT (random() * 1000000)::INT AS id FROM range(100000000);\n+\n+run\n+CREATE INDEX idx ON art(id);\n+\n+cleanup\n+DROP INDEX idx;\ndiff --git a/benchmark/micro/index/create/create_index_sorted.benchmark b/benchmark/micro/index/create/create_index_sorted.benchmark\nnew file mode 100644\nindex 000000000000..8cb5350430a6\n--- /dev/null\n+++ b/benchmark/micro/index/create/create_index_sorted.benchmark\n@@ -0,0 +1,15 @@\n+# name: benchmark/micro/index/create/create_index_sorted.benchmark\n+# description: Create index on 1000000 sorted integers\n+# group: [create]\n+\n+name Create Index Sorted\n+group index\n+\n+load\n+CREATE TABLE art AS SELECT range id FROM range(1000000);\n+\n+run\n+CREATE INDEX idx ON art(id);\n+\n+cleanup\n+DROP INDEX idx;\ndiff --git a/benchmark/micro/index/create/create_index_varchar.benchmark b/benchmark/micro/index/create/create_index_varchar.benchmark\nnew file mode 100644\nindex 000000000000..1687cbfddf8d\n--- /dev/null\n+++ b/benchmark/micro/index/create/create_index_varchar.benchmark\n@@ -0,0 +1,15 @@\n+# name: benchmark/micro/index/create/create_index_varchar.benchmark\n+# description: Create index on 10000000 random varchars\n+# group: [create]\n+\n+name Create Index Varchar\n+group index\n+\n+load\n+CREATE TABLE art AS SELECT range || '-not-inlined-' id FROM range(10000000);\n+\n+run\n+CREATE INDEX idx ON art(id);\n+\n+cleanup\n+DROP INDEX idx;\ndiff --git a/benchmark/micro/index/delete/delete.benchmark b/benchmark/micro/index/delete/delete.benchmark\nnew file mode 100644\nindex 000000000000..6745e0e899be\n--- /dev/null\n+++ b/benchmark/micro/index/delete/delete.benchmark\n@@ -0,0 +1,17 @@\n+# name: benchmark/micro/index/delete/delete.benchmark\n+# description: Delete 10000000 integers from index\n+# group: [delete]\n+\n+name Delete Index\n+group index\n+\n+load\n+CREATE TABLE art (id INTEGER);\n+CREATE INDEX idx ON art(id);\n+INSERT INTO art (SELECT range id FROM range(10000000));\n+\n+run\n+DELETE FROM art;\n+\n+cleanup\n+INSERT INTO art (SELECT range id FROM range(10000000));\ndiff --git a/benchmark/micro/index/delete/delete_unique.benchmark b/benchmark/micro/index/delete/delete_unique.benchmark\nnew file mode 100644\nindex 000000000000..34ed44c9b474\n--- /dev/null\n+++ b/benchmark/micro/index/delete/delete_unique.benchmark\n@@ -0,0 +1,17 @@\n+# name: benchmark/micro/index/delete/delete_unique.benchmark\n+# description: Delete 10000000 integers from unique index\n+# group: [delete]\n+\n+name Delete Index Unique\n+group index\n+\n+load\n+CREATE TABLE art (id INTEGER);\n+CREATE UNIQUE INDEX idx ON art(id);\n+INSERT INTO art (SELECT range id FROM range(10000000));\n+\n+run\n+DELETE FROM art;\n+\n+cleanup\n+INSERT INTO art (SELECT range id FROM range(10000000));\ndiff --git a/benchmark/micro/index/insert/insert.benchmark b/benchmark/micro/index/insert/insert.benchmark\nnew file mode 100644\nindex 000000000000..a469f397f6ef\n--- /dev/null\n+++ b/benchmark/micro/index/insert/insert.benchmark\n@@ -0,0 +1,16 @@\n+# name: benchmark/micro/index/insert/insert.benchmark\n+# description: Insert 10000000 integers into index\n+# group: [insert]\n+\n+name Insert Index\n+group index\n+\n+load\n+CREATE TABLE art (id INTEGER);\n+CREATE INDEX idx ON art(id);\n+\n+run\n+INSERT INTO art (SELECT range id FROM range(10000000));\n+\n+cleanup\n+DELETE FROM art;\ndiff --git a/benchmark/micro/index/insert/insert_unique.benchmark b/benchmark/micro/index/insert/insert_unique.benchmark\nnew file mode 100644\nindex 000000000000..09d639e550c1\n--- /dev/null\n+++ b/benchmark/micro/index/insert/insert_unique.benchmark\n@@ -0,0 +1,16 @@\n+# name: benchmark/micro/index/insert/insert_unique.benchmark\n+# description: Insert 10000000 integers into unique index\n+# group: [insert]\n+\n+name Insert Index Unique\n+group index\n+\n+load\n+CREATE TABLE art (id INTEGER);\n+CREATE UNIQUE INDEX idx ON art(id);\n+\n+run\n+INSERT INTO art (SELECT range id FROM range(10000000));\n+\n+cleanup\n+DELETE FROM art;\ndiff --git a/benchmark/micro/index/join/index_join.benchmark b/benchmark/micro/index/join/index_join.benchmark\nnew file mode 100644\nindex 000000000000..5b09863f5cb7\n--- /dev/null\n+++ b/benchmark/micro/index/join/index_join.benchmark\n@@ -0,0 +1,17 @@\n+# name: benchmark/micro/index/join/index_join.benchmark\n+# description: Perform an index nested loop join between two tables\n+# group: [join]\n+\n+name Index Join\n+group index\n+\n+load\n+PRAGMA force_index_join;\n+CREATE TABLE Person (id bigint PRIMARY KEY);\n+CREATE TABLE Person_knows_Person (Person1id bigint, Person2id bigint);\n+INSERT INTO Person SELECT range id FROM range(100000);\n+INSERT INTO Person_knows_Person SELECT range AS Person1id, range + 1 AS Person2id FROM range(99999);\n+INSERT INTO Person_knows_Person SELECT range AS Person1id, range + 5 AS Person2id FROM range(99995);\n+\n+run\n+SELECT p1.id FROM Person_knows_Person pkp JOIN Person p1 ON p1.id = pkp.Person1id;\n\\ No newline at end of file\ndiff --git a/benchmark/micro/index/point_query_with_index.benchmark b/benchmark/micro/index/point/point_query_with_index.benchmark\nsimilarity index 80%\nrename from benchmark/micro/index/point_query_with_index.benchmark\nrename to benchmark/micro/index/point/point_query_with_index.benchmark\nindex 41f7844d702d..9bcd4da0fef8 100644\n--- a/benchmark/micro/index/point_query_with_index.benchmark\n+++ b/benchmark/micro/index/point/point_query_with_index.benchmark\n@@ -1,6 +1,6 @@\n-# name: benchmark/micro/index/point_query_with_index.benchmark\n+# name: benchmark/micro/index/point/point_query_with_index.benchmark\n # description: Point query with an index on randomly ordered data\n-# group: [index]\n+# group: [point]\n \n name Point Query (Index)\n group index\ndiff --git a/benchmark/micro/index/point_query_without_index.benchmark b/benchmark/micro/index/point/point_query_without_index.benchmark\nsimilarity index 78%\nrename from benchmark/micro/index/point_query_without_index.benchmark\nrename to benchmark/micro/index/point/point_query_without_index.benchmark\nindex 929d781bb2ed..ac36e7a2a61f 100644\n--- a/benchmark/micro/index/point_query_without_index.benchmark\n+++ b/benchmark/micro/index/point/point_query_without_index.benchmark\n@@ -1,6 +1,6 @@\n-# name: benchmark/micro/index/point_query_without_index.benchmark\n+# name: benchmark/micro/index/point/point_query_without_index.benchmark\n # description: Point query without index on randomly ordered data\n-# group: [index]\n+# group: [point]\n \n name Point Query (No Index, Random Data)\n group index\ndiff --git a/benchmark/micro/index/point_query_without_index_sequential.benchmark b/benchmark/micro/index/point/point_query_without_index_sequential.benchmark\nsimilarity index 72%\nrename from benchmark/micro/index/point_query_without_index_sequential.benchmark\nrename to benchmark/micro/index/point/point_query_without_index_sequential.benchmark\nindex 0280d906a569..22d6541c5d03 100644\n--- a/benchmark/micro/index/point_query_without_index_sequential.benchmark\n+++ b/benchmark/micro/index/point/point_query_without_index_sequential.benchmark\n@@ -1,6 +1,6 @@\n-# name: benchmark/micro/index/point_query_without_index_sequential.benchmark\n+# name: benchmark/micro/index/point/point_query_without_index_sequential.benchmark\n # description: Point query without on sequentially ordered data\n-# group: [index]\n+# group: [point]\n \n name Point Query (No Index, Ordered Data)\n group index\ndiff --git a/benchmark/micro/index/range_query_with_index.benchmark b/benchmark/micro/index/range/range_query_with_index.benchmark\nsimilarity index 77%\nrename from benchmark/micro/index/range_query_with_index.benchmark\nrename to benchmark/micro/index/range/range_query_with_index.benchmark\nindex f951a7813aee..20fd1c9c0690 100644\n--- a/benchmark/micro/index/range_query_with_index.benchmark\n+++ b/benchmark/micro/index/range/range_query_with_index.benchmark\n@@ -1,6 +1,6 @@\n-# name: benchmark/micro/index/range_query_with_index.benchmark\n+# name: benchmark/micro/index/range/range_query_with_index.benchmark\n # description: Range query with index\n-# group: [index]\n+# group: [range]\n \n name Range Query (Index)\n group index\ndiff --git a/benchmark/micro/index/range_query_without_index.benchmark b/benchmark/micro/index/range/range_query_without_index.benchmark\nsimilarity index 73%\nrename from benchmark/micro/index/range_query_without_index.benchmark\nrename to benchmark/micro/index/range/range_query_without_index.benchmark\nindex e2abe9ebf4b1..eb419c6df921 100644\n--- a/benchmark/micro/index/range_query_without_index.benchmark\n+++ b/benchmark/micro/index/range/range_query_without_index.benchmark\n@@ -1,6 +1,6 @@\n-# name: benchmark/micro/index/range_query_without_index.benchmark\n+# name: benchmark/micro/index/range/range_query_without_index.benchmark\n # description: Range query without index\n-# group: [index]\n+# group: [range]\n \n name Range Query (No Index)\n group index\ndiff --git a/benchmark/micro/index/wide_range_query_with_index.benchmark b/benchmark/micro/index/range/wide_range_query_with_index.benchmark\nsimilarity index 77%\nrename from benchmark/micro/index/wide_range_query_with_index.benchmark\nrename to benchmark/micro/index/range/wide_range_query_with_index.benchmark\nindex d7d5d18bf126..3062b4b02398 100644\n--- a/benchmark/micro/index/wide_range_query_with_index.benchmark\n+++ b/benchmark/micro/index/range/wide_range_query_with_index.benchmark\n@@ -1,6 +1,6 @@\n-# name: benchmark/micro/index/wide_range_query_with_index.benchmark\n+# name: benchmark/micro/index/range/wide_range_query_with_index.benchmark\n # description: Wide (non-selective) range query with index\n-# group: [index]\n+# group: [range]\n \n name Big Range Query (Index)\n group index\ndiff --git a/benchmark/micro/index/wide_range_query_without_index.benchmark b/benchmark/micro/index/range/wide_range_query_without_index.benchmark\nsimilarity index 74%\nrename from benchmark/micro/index/wide_range_query_without_index.benchmark\nrename to benchmark/micro/index/range/wide_range_query_without_index.benchmark\nindex 092caa0ad2ec..c896754110fa 100644\n--- a/benchmark/micro/index/wide_range_query_without_index.benchmark\n+++ b/benchmark/micro/index/range/wide_range_query_without_index.benchmark\n@@ -1,6 +1,6 @@\n-# name: benchmark/micro/index/wide_range_query_without_index.benchmark\n+# name: benchmark/micro/index/range/wide_range_query_without_index.benchmark\n # description: Wide (non-selective) range query without index\n-# group: [index]\n+# group: [range]\n \n name Big Range Query (No Index)\n group index\ndiff --git a/src/catalog/catalog_entry/table_catalog_entry.cpp b/src/catalog/catalog_entry/table_catalog_entry.cpp\nindex feac2ba00ba1..efe0ff4f6767 100644\n--- a/src/catalog/catalog_entry/table_catalog_entry.cpp\n+++ b/src/catalog/catalog_entry/table_catalog_entry.cpp\n@@ -65,10 +65,10 @@ void AddDataTableIndex(DataTable *storage, const ColumnList &columns, const vect\n \t// create an adaptive radix tree around the expressions\n \tif (index_block) {\n \t\tart = make_unique<ART>(column_ids, TableIOManager::Get(*storage), std::move(unbound_expressions),\n-\t\t                       constraint_type, storage->db, index_block->block_id, index_block->offset);\n+\t\t                       constraint_type, storage->db, true, index_block->block_id, index_block->offset);\n \t} else {\n \t\tart = make_unique<ART>(column_ids, TableIOManager::Get(*storage), std::move(unbound_expressions),\n-\t\t                       constraint_type, storage->db);\n+\t\t                       constraint_type, storage->db, true);\n \t\tif (!storage->IsRoot()) {\n \t\t\tthrow TransactionException(\"Transaction conflict: cannot add an index to a table that has been altered!\");\n \t\t}\ndiff --git a/src/execution/index/art/art.cpp b/src/execution/index/art/art.cpp\nindex bd5a3e39e55f..f522a44156bb 100644\n--- a/src/execution/index/art/art.cpp\n+++ b/src/execution/index/art/art.cpp\n@@ -15,66 +15,61 @@ namespace duckdb {\n \n ART::ART(const vector<column_t> &column_ids, TableIOManager &table_io_manager,\n          const vector<unique_ptr<Expression>> &unbound_expressions, IndexConstraintType constraint_type,\n-         AttachedDatabase &db, idx_t block_id, idx_t block_offset)\n+         AttachedDatabase &db, bool track_memory, idx_t block_id, idx_t block_offset)\n \n-    : Index(IndexType::ART, table_io_manager, column_ids, unbound_expressions, constraint_type), db(db),\n-      estimated_art_size(0), estimated_key_size(16) {\n+    : Index(db, IndexType::ART, table_io_manager, column_ids, unbound_expressions, constraint_type, track_memory) {\n \n \tif (!Radix::IsLittleEndian()) {\n \t\tthrow NotImplementedException(\"ART indexes are not supported on big endian architectures\");\n \t}\n \n+\t// set the root node of the tree\n+\ttree = nullptr;\n \tif (block_id != DConstants::INVALID_INDEX) {\n \t\ttree = Node::Deserialize(*this, block_id, block_offset);\n-\t} else {\n-\t\ttree = nullptr;\n+\t\tVerify();\n \t}\n-\n \tserialized_data_pointer = BlockPointer(block_id, block_offset);\n+\n+\t// validate the types of the key columns\n \tfor (idx_t i = 0; i < types.size(); i++) {\n \t\tswitch (types[i]) {\n \t\tcase PhysicalType::BOOL:\n \t\tcase PhysicalType::INT8:\n-\t\tcase PhysicalType::UINT8:\n-\t\t\testimated_key_size += sizeof(int8_t);\n-\t\t\tbreak;\n \t\tcase PhysicalType::INT16:\n-\t\tcase PhysicalType::UINT16:\n-\t\t\testimated_key_size += sizeof(int16_t);\n-\t\t\tbreak;\n \t\tcase PhysicalType::INT32:\n-\t\tcase PhysicalType::UINT32:\n-\t\tcase PhysicalType::FLOAT:\n-\t\t\testimated_key_size += sizeof(int32_t);\n-\t\t\tbreak;\n \t\tcase PhysicalType::INT64:\n+\t\tcase PhysicalType::INT128:\n+\t\tcase PhysicalType::UINT8:\n+\t\tcase PhysicalType::UINT16:\n+\t\tcase PhysicalType::UINT32:\n \t\tcase PhysicalType::UINT64:\n+\t\tcase PhysicalType::FLOAT:\n \t\tcase PhysicalType::DOUBLE:\n-\t\t\testimated_key_size += sizeof(int64_t);\n-\t\t\tbreak;\n-\t\tcase PhysicalType::INT128:\n-\t\t\testimated_key_size += sizeof(hugeint_t);\n-\t\t\tbreak;\n \t\tcase PhysicalType::VARCHAR:\n-\t\t\testimated_key_size += 16; // oh well\n \t\t\tbreak;\n \t\tdefault:\n-\t\t\tthrow InvalidTypeException(logical_types[i], \"Invalid type for index\");\n+\t\t\tthrow InvalidTypeException(logical_types[i], \"Invalid type for index key.\");\n \t\t}\n \t}\n }\n \n ART::~ART() {\n-\tif (estimated_art_size > 0) {\n-\t\tBufferManager::GetBufferManager(db).FreeReservedMemory(estimated_art_size);\n-\t\testimated_art_size = 0;\n+\tif (!tree) {\n+\t\treturn;\n \t}\n-\tif (tree) {\n-\t\tNode::Delete(tree);\n-\t\ttree = nullptr;\n+\tVerify();\n+\tif (track_memory) {\n+\t\tbuffer_manager.DecreaseUsedMemory(memory_size);\n \t}\n+\tNode::Delete(tree);\n+\ttree = nullptr;\n }\n \n+//===--------------------------------------------------------------------===//\n+// Initialize Predicate Scans\n+//===--------------------------------------------------------------------===//\n+\n unique_ptr<IndexScanState> ART::InitializeScanSinglePredicate(Transaction &transaction, Value value,\n                                                               ExpressionType expression_type) {\n \tauto result = make_unique<ARTIndexScanState>();\n@@ -230,7 +225,7 @@ void ART::GenerateKeys(ArenaAllocator &allocator, DataChunk &input, vector<Key>\n }\n \n //===--------------------------------------------------------------------===//\n-// Insert\n+// Construct from sorted data\n //===--------------------------------------------------------------------===//\n \n struct KeySection {\n@@ -256,7 +251,8 @@ void GetChildSections(vector<KeySection> &child_sections, vector<Key> &keys, Key\n \tchild_sections.emplace_back(child_start_idx, key_section.end, keys, key_section);\n }\n \n-void Construct(vector<Key> &keys, row_t *row_ids, Node *&node, KeySection &key_section, bool &has_constraint) {\n+void Construct(ART &art, vector<Key> &keys, row_t *row_ids, Node *&node, KeySection &key_section,\n+               bool &has_constraint) {\n \n \tD_ASSERT(key_section.start < keys.size());\n \tD_ASSERT(key_section.end < keys.size());\n@@ -284,9 +280,11 @@ void Construct(vector<Key> &keys, row_t *row_ids, Node *&node, KeySection &key_s\n \n \t\tif (single_row_id) {\n \t\t\tnode = Leaf::New(start_key, prefix_start, row_ids[key_section.start]);\n+\t\t\tart.memory_size += node->MemorySize(art, false);\n \t\t\treturn;\n \t\t}\n \t\tnode = Leaf::New(start_key, prefix_start, row_ids + key_section.start, num_row_ids);\n+\t\tart.memory_size += node->MemorySize(art, false);\n \n \t} else { // create a new node and recurse\n \n@@ -299,12 +297,13 @@ void Construct(vector<Key> &keys, row_t *row_ids, Node *&node, KeySection &key_s\n \n \t\tauto prefix_length = key_section.depth - prefix_start;\n \t\tnode->prefix = Prefix(start_key, prefix_start, prefix_length);\n+\t\tart.memory_size += node->MemorySize(art, false);\n \n \t\t// recurse on each child section\n \t\tfor (auto &child_section : child_sections) {\n \t\t\tNode *new_child = nullptr;\n-\t\t\tConstruct(keys, row_ids, new_child, child_section, has_constraint);\n-\t\t\tNode::InsertChild(node, child_section.key_byte, new_child);\n+\t\t\tConstruct(art, keys, row_ids, new_child, child_section, has_constraint);\n+\t\t\tNode::InsertChild(art, node, child_section.key_byte, new_child);\n \t\t}\n \t}\n }\n@@ -317,10 +316,15 @@ void ART::ConstructFromSorted(idx_t count, vector<Key> &keys, Vector &row_identi\n \n \tauto key_section = KeySection(0, count - 1, 0, 0);\n \tauto has_constraint = IsUnique();\n-\tConstruct(keys, row_ids, this->tree, key_section, has_constraint);\n+\tConstruct(*this, keys, row_ids, this->tree, key_section, has_constraint);\n }\n \n+//===--------------------------------------------------------------------===//\n+// Insert\n+//===--------------------------------------------------------------------===//\n+\n bool ART::Insert(IndexLock &lock, DataChunk &input, Vector &row_ids) {\n+\n \tD_ASSERT(row_ids.GetType().InternalType() == ROW_TYPE);\n \tD_ASSERT(logical_types[0] == input.data[0].GetType());\n \n@@ -329,13 +333,13 @@ bool ART::Insert(IndexLock &lock, DataChunk &input, Vector &row_ids) {\n \tvector<Key> keys(input.size());\n \tGenerateKeys(arena_allocator, input, keys);\n \n-\tidx_t extra_memory = estimated_key_size * input.size();\n-\tBufferManager::GetBufferManager(db).ReserveMemory(extra_memory);\n-\testimated_art_size += extra_memory;\n+\tauto old_memory_size = this->memory_size;\n \n-\t// now insert the elements into the index\n+\t// get the corresponding row IDs\n \trow_ids.Flatten(input.size());\n \tauto row_identifiers = FlatVector::GetData<row_t>(row_ids);\n+\n+\t// now insert the elements into the index\n \tidx_t failed_index = DConstants::INVALID_INDEX;\n \tfor (idx_t i = 0; i < input.size(); i++) {\n \t\tif (keys[i].Empty()) {\n@@ -359,8 +363,15 @@ bool ART::Insert(IndexLock &lock, DataChunk &input, Vector &row_ids) {\n \t\t\trow_t row_id = row_identifiers[i];\n \t\t\tErase(tree, keys[i], 0, row_id);\n \t\t}\n+\t\t// nothing changed, no need to update the buffer memory size\n \t\treturn false;\n \t}\n+\n+\tD_ASSERT(old_memory_size <= memory_size);\n+\tVerify();\n+\tif (track_memory) {\n+\t\tbuffer_manager.IncreaseUsedMemory(memory_size - old_memory_size);\n+\t}\n \treturn true;\n }\n \n@@ -407,7 +418,7 @@ bool ART::InsertToLeaf(Leaf &leaf, row_t row_id) {\n \tif (IsUnique() && leaf.count != 0) {\n \t\treturn false;\n \t}\n-\tleaf.Insert(row_id);\n+\tleaf.Insert(*this, row_id);\n \treturn true;\n }\n \n@@ -416,23 +427,24 @@ bool ART::Insert(Node *&node, Key &key, idx_t depth, row_t row_id) {\n \tif (!node) {\n \t\t// node is currently empty, create a leaf here with the key\n \t\tnode = Leaf::New(key, depth, row_id);\n+\t\tthis->memory_size += node->MemorySize(*this, false);\n \t\treturn true;\n \t}\n \n \tif (node->type == NodeType::NLeaf) {\n-\t\t// Replace leaf with Node4 and store both leaves in it\n+\t\t// replace leaf with Node4 and store both leaves in it\n+\t\t// or add a row ID to a leaf, if they have the same key\n \t\tauto leaf = (Leaf *)node;\n-\n-\t\tauto &leaf_prefix = leaf->prefix;\n \t\tuint32_t new_prefix_length = 0;\n \n-\t\t// Leaf node is already there (its key matches the current key), update row_id vector\n+\t\t// FIXME: this code (if and while) can be optimized, less branching, see Construct\n+\t\t// leaf node is already there (its key matches the current key), update row_id vector\n \t\tif (new_prefix_length == leaf->prefix.Size() && depth + leaf->prefix.Size() == key.len) {\n \t\t\treturn InsertToLeaf(*leaf, row_id);\n \t\t}\n-\t\twhile (leaf_prefix[new_prefix_length] == key[depth + new_prefix_length]) {\n+\t\twhile (leaf->prefix[new_prefix_length] == key[depth + new_prefix_length]) {\n \t\t\tnew_prefix_length++;\n-\t\t\t// Leaf node is already there (its key matches the current key), update row_id vector\n+\t\t\t// leaf node is already there (its key matches the current key), update row_id vector\n \t\t\tif (new_prefix_length == leaf->prefix.Size() && depth + leaf->prefix.Size() == key.len) {\n \t\t\t\treturn InsertToLeaf(*leaf, row_id);\n \t\t\t}\n@@ -440,34 +452,44 @@ bool ART::Insert(Node *&node, Key &key, idx_t depth, row_t row_id) {\n \n \t\tNode *new_node = Node4::New();\n \t\tnew_node->prefix = Prefix(key, depth, new_prefix_length);\n-\t\tauto key_byte = node->prefix.Reduce(new_prefix_length);\n-\t\tNode4::InsertChild(new_node, key_byte, node);\n+\t\tthis->memory_size += new_node->MemorySize(*this, false);\n+\n+\t\tauto key_byte = node->prefix.Reduce(*this, new_prefix_length);\n+\t\tNode4::InsertChild(*this, new_node, key_byte, node);\n+\n \t\tNode *leaf_node = Leaf::New(key, depth + new_prefix_length + 1, row_id);\n-\t\tNode4::InsertChild(new_node, key[depth + new_prefix_length], leaf_node);\n+\t\tNode4::InsertChild(*this, new_node, key[depth + new_prefix_length], leaf_node);\n+\t\tthis->memory_size += leaf_node->MemorySize(*this, false);\n+\n \t\tnode = new_node;\n \t\treturn true;\n \t}\n \n-\t// Handle prefix of inner node\n+\t// handle prefix of inner node\n \tif (node->prefix.Size()) {\n+\n \t\tuint32_t mismatch_pos = node->prefix.KeyMismatchPosition(key, depth);\n \t\tif (mismatch_pos != node->prefix.Size()) {\n-\t\t\t// Prefix differs, create new node\n+\t\t\t// prefix differs, create new node\n \t\t\tNode *new_node = Node4::New();\n \t\t\tnew_node->prefix = Prefix(key, depth, mismatch_pos);\n-\t\t\t// Break up prefix\n-\t\t\tauto key_byte = node->prefix.Reduce(mismatch_pos);\n-\t\t\tNode4::InsertChild(new_node, key_byte, node);\n+\t\t\tthis->memory_size += new_node->MemorySize(*this, false);\n+\n+\t\t\t// break up prefix\n+\t\t\tauto key_byte = node->prefix.Reduce(*this, mismatch_pos);\n+\t\t\tNode4::InsertChild(*this, new_node, key_byte, node);\n \n \t\t\tNode *leaf_node = Leaf::New(key, depth + mismatch_pos + 1, row_id);\n-\t\t\tNode4::InsertChild(new_node, key[depth + mismatch_pos], leaf_node);\n+\t\t\tNode4::InsertChild(*this, new_node, key[depth + mismatch_pos], leaf_node);\n+\t\t\tthis->memory_size += leaf_node->MemorySize(*this, false);\n+\n \t\t\tnode = new_node;\n \t\t\treturn true;\n \t\t}\n \t\tdepth += node->prefix.Size();\n \t}\n \n-\t// Recurse\n+\t// recurse\n \tD_ASSERT(depth < key.len);\n \tidx_t pos = node->GetChildPos(key[depth]);\n \tif (pos != DConstants::INVALID_INDEX) {\n@@ -476,30 +498,32 @@ bool ART::Insert(Node *&node, Key &key, idx_t depth, row_t row_id) {\n \t\tnode->ReplaceChildPointer(pos, child);\n \t\treturn insertion_result;\n \t}\n-\tNode *new_node = Leaf::New(key, depth + 1, row_id);\n-\tNode::InsertChild(node, key[depth], new_node);\n+\n+\tNode *leaf_node = Leaf::New(key, depth + 1, row_id);\n+\tNode::InsertChild(*this, node, key[depth], leaf_node);\n+\tthis->memory_size += leaf_node->MemorySize(*this, false);\n \treturn true;\n }\n \n //===--------------------------------------------------------------------===//\n // Delete\n //===--------------------------------------------------------------------===//\n+\n void ART::Delete(IndexLock &state, DataChunk &input, Vector &row_ids) {\n+\n \tDataChunk expression;\n \texpression.Initialize(Allocator::DefaultAllocator(), logical_types);\n \n \t// first resolve the expressions\n \tExecuteExpressions(input, expression);\n \n-\tidx_t released_memory = MinValue<idx_t>(estimated_art_size, estimated_key_size * input.size());\n-\tBufferManager::GetBufferManager(db).FreeReservedMemory(released_memory);\n-\testimated_art_size -= released_memory;\n-\n \t// then generate the keys for the given input\n \tArenaAllocator arena_allocator(BufferAllocator::Get(db));\n \tvector<Key> keys(expression.size());\n \tGenerateKeys(arena_allocator, expression, keys);\n \n+\tauto old_memory_size = this->memory_size;\n+\n \t// now erase the elements from the database\n \trow_ids.Flatten(input.size());\n \tauto row_identifiers = FlatVector::GetData<row_t>(row_ids);\n@@ -512,54 +536,66 @@ void ART::Delete(IndexLock &state, DataChunk &input, Vector &row_ids) {\n #ifdef DEBUG\n \t\tauto node = Lookup(tree, keys[i], 0);\n \t\tif (node) {\n-\t\t\tauto leaf = static_cast<Leaf *>(node);\n+\t\t\tauto leaf = (Leaf *)node;\n \t\t\tfor (idx_t k = 0; k < leaf->count; k++) {\n \t\t\t\tD_ASSERT(leaf->GetRowId(k) != row_identifiers[i]);\n \t\t\t}\n \t\t}\n #endif\n \t}\n+\n+\tD_ASSERT(old_memory_size >= memory_size);\n+\tVerify();\n+\tif (track_memory) {\n+\t\tbuffer_manager.DecreaseUsedMemory(old_memory_size - memory_size);\n+\t}\n }\n \n void ART::Erase(Node *&node, Key &key, idx_t depth, row_t row_id) {\n+\n \tif (!node) {\n \t\treturn;\n \t}\n-\t// Delete a leaf from a tree\n+\n+\t// delete a leaf from a tree\n \tif (node->type == NodeType::NLeaf) {\n-\t\t// Make sure we have the right leaf\n-\t\tauto leaf = static_cast<Leaf *>(node);\n-\t\tleaf->Remove(row_id);\n+\t\tauto leaf = (Leaf *)node;\n+\t\tleaf->Remove(*this, row_id);\n+\n \t\tif (leaf->count == 0) {\n+\t\t\tD_ASSERT(this->memory_size >= leaf->MemorySize(*this, false));\n+\t\t\tthis->memory_size -= leaf->MemorySize(*this, false);\n \t\t\tNode::Delete(node);\n \t\t\tnode = nullptr;\n \t\t}\n-\n \t\treturn;\n \t}\n \n-\t// Handle prefix\n+\t// handle prefix\n \tif (node->prefix.Size()) {\n \t\tif (node->prefix.KeyMismatchPosition(key, depth) != node->prefix.Size()) {\n \t\t\treturn;\n \t\t}\n \t\tdepth += node->prefix.Size();\n \t}\n+\n \tidx_t pos = node->GetChildPos(key[depth]);\n \tif (pos != DConstants::INVALID_INDEX) {\n \t\tauto child = node->GetChild(*this, pos);\n \t\tD_ASSERT(child);\n \n \t\tif (child->type == NodeType::NLeaf) {\n-\t\t\t// Leaf found, remove entry\n+\t\t\t// leaf found, remove entry\n \t\t\tauto leaf = (Leaf *)child;\n-\t\t\tleaf->Remove(row_id);\n+\t\t\tleaf->Remove(*this, row_id);\n+\n \t\t\tif (leaf->count == 0) {\n-\t\t\t\t// Leaf is empty, delete leaf, decrement node counter and maybe shrink node\n-\t\t\t\tNode::EraseChild(node, pos, *this);\n+\t\t\t\t// leaf is empty, delete leaf, decrement node counter and maybe shrink node\n+\t\t\t\tNode::EraseChild(*this, node, pos);\n \t\t\t}\n+\n \t\t} else {\n-\t\t\t// Recurse\n+\t\t\t// recurse\n \t\t\tErase(child, key, depth + 1, row_id);\n \t\t\tnode->ReplaceChildPointer(pos, child);\n \t\t}\n@@ -569,6 +605,7 @@ void ART::Erase(Node *&node, Key &key, idx_t depth, row_t row_id) {\n //===--------------------------------------------------------------------===//\n // Point Query\n //===--------------------------------------------------------------------===//\n+\n static Key CreateKey(ArenaAllocator &allocator, PhysicalType type, Value &value) {\n \tD_ASSERT(type == value.type().InternalType());\n \tswitch (type) {\n@@ -605,7 +642,7 @@ static Key CreateKey(ArenaAllocator &allocator, PhysicalType type, Value &value)\n \n bool ART::SearchEqual(Key &key, idx_t max_count, vector<row_t> &result_ids) {\n \n-\tauto leaf = static_cast<Leaf *>(Lookup(tree, key, 0));\n+\tauto leaf = (Leaf *)(Lookup(tree, key, 0));\n \tif (!leaf) {\n \t\treturn true;\n \t}\n@@ -666,6 +703,7 @@ Leaf *ART::Lookup(Node *node, Key &key, idx_t depth) {\n // Returns: True (If found leaf >= key)\n //          False (Otherwise)\n //===--------------------------------------------------------------------===//\n+\n bool ART::SearchGreater(ARTIndexScanState *state, Key &key, bool inclusive, idx_t max_count,\n                         vector<row_t> &result_ids) {\n \n@@ -689,6 +727,7 @@ bool ART::SearchGreater(ARTIndexScanState *state, Key &key, bool inclusive, idx_\n //===--------------------------------------------------------------------===//\n // Less Than\n //===--------------------------------------------------------------------===//\n+\n bool ART::SearchLess(ARTIndexScanState *state, Key &upper_bound, bool inclusive, idx_t max_count,\n                      vector<row_t> &result_ids) {\n \n@@ -714,6 +753,7 @@ bool ART::SearchLess(ARTIndexScanState *state, Key &upper_bound, bool inclusive,\n //===--------------------------------------------------------------------===//\n // Closed Range Query\n //===--------------------------------------------------------------------===//\n+\n bool ART::SearchCloseRange(ARTIndexScanState *state, Key &lower_bound, Key &upper_bound, bool left_inclusive,\n                            bool right_inclusive, idx_t max_count, vector<row_t> &result_ids) {\n \n@@ -820,18 +860,19 @@ string ART::GenerateErrorKeyName(DataChunk &input, idx_t row) {\n string ART::GenerateConstraintErrorMessage(VerifyExistenceType verify_type, const string &key_name) {\n \tswitch (verify_type) {\n \tcase VerifyExistenceType::APPEND: {\n-\t\t// This node already exists in the tree\n+\t\t// APPEND to PK/UNIQUE table, but node/key already exists in PK/UNIQUE table\n \t\tstring type = IsPrimary() ? \"primary key\" : \"unique\";\n \t\treturn StringUtil::Format(\"Duplicate key \\\"%s\\\" violates %s constraint\", key_name, type);\n \t}\n \tcase VerifyExistenceType::APPEND_FK: {\n-\t\t// The node we tried to insert does not exist in the foreign table\n+\t\t// APPEND_FK to FK table, node/key does not exist in PK/UNIQUE table\n \t\treturn StringUtil::Format(\n-\t\t    \"Violates foreign key constraint because key \\\"%s\\\" does not exist in referenced table\", key_name);\n+\t\t    \"Violates foreign key constraint because key \\\"%s\\\" does not exist in the referenced table\", key_name);\n \t}\n \tcase VerifyExistenceType::DELETE_FK: {\n-\t\t// The node we tried to delete still exists in the foreign table\n-\t\treturn StringUtil::Format(\"Violates foreign key constraint because key \\\"%s\\\" exists in table has foreign key\",\n+\t\t// DELETE_FK that still exists in a FK table, i.e., not a valid delete\n+\t\treturn StringUtil::Format(\"Violates foreign key constraint because key \\\"%s\\\" is still referenced by a foreign \"\n+\t\t                          \"key in a different table\",\n \t\t                          key_name);\n \t}\n \tdefault:\n@@ -840,13 +881,13 @@ string ART::GenerateConstraintErrorMessage(VerifyExistenceType verify_type, cons\n }\n \n void ART::LookupValues(DataChunk &input, ConflictManager &conflict_manager) {\n-\tDataChunk expression_chunk;\n-\texpression_chunk.Initialize(Allocator::DefaultAllocator(), logical_types);\n \n-\t// unique index, check\n+\t// don't alter the index during constraint checking\n \tlock_guard<mutex> l(lock);\n \n \t// first resolve the expressions for the index\n+\tDataChunk expression_chunk;\n+\texpression_chunk.Initialize(Allocator::DefaultAllocator(), logical_types);\n \tExecuteExpressions(input, expression_chunk);\n \n \t// generate the keys for the given input\n@@ -890,6 +931,7 @@ void ART::LookupValues(DataChunk &input, ConflictManager &conflict_manager) {\n //===--------------------------------------------------------------------===//\n // Serialization\n //===--------------------------------------------------------------------===//\n+\n BlockPointer ART::Serialize(duckdb::MetaBlockWriter &writer) {\n \tlock_guard<mutex> l(lock);\n \tif (tree) {\n@@ -901,13 +943,15 @@ BlockPointer ART::Serialize(duckdb::MetaBlockWriter &writer) {\n }\n \n //===--------------------------------------------------------------------===//\n-// Merge ARTs\n+// Merging\n //===--------------------------------------------------------------------===//\n+\n bool ART::MergeIndexes(IndexLock &state, Index *other_index) {\n+\n \tauto other_art = (ART *)other_index;\n-\testimated_art_size += other_art->estimated_art_size;\n-\tother_art->estimated_art_size = 0;\n+\n \tif (!this->tree) {\n+\t\tthis->memory_size += other_art->memory_size;\n \t\tthis->tree = other_art->tree;\n \t\tother_art->tree = nullptr;\n \t\treturn true;\n@@ -916,6 +960,10 @@ bool ART::MergeIndexes(IndexLock &state, Index *other_index) {\n \treturn Node::MergeARTs(this, other_art);\n }\n \n+//===--------------------------------------------------------------------===//\n+// Utility\n+//===--------------------------------------------------------------------===//\n+\n string ART::ToString() {\n \tif (tree) {\n \t\treturn tree->ToString(*this);\n@@ -923,4 +971,17 @@ string ART::ToString() {\n \treturn \"[empty]\";\n }\n \n+void ART::Verify() {\n+#ifdef DEBUG\n+\tidx_t current_mem_size = 0;\n+\tif (tree) {\n+\t\tcurrent_mem_size = tree->MemorySize(*this, true);\n+\t}\n+\tif (memory_size != current_mem_size) {\n+\t\tthrow InternalException(\"Memory_size value (%d) does not match actual memory size (%d).\", memory_size,\n+\t\t                        current_mem_size);\n+\t}\n+#endif\n+}\n+\n } // namespace duckdb\ndiff --git a/src/execution/index/art/leaf.cpp b/src/execution/index/art/leaf.cpp\nindex 94cd17312e57..f9e5b7b0b79c 100644\n--- a/src/execution/index/art/leaf.cpp\n+++ b/src/execution/index/art/leaf.cpp\n@@ -1,5 +1,6 @@\n #include \"duckdb/execution/index/art/leaf.hpp\"\n \n+#include \"duckdb/execution/index/art/art.hpp\"\n #include \"duckdb/execution/index/art/node.hpp\"\n #include \"duckdb/execution/index/art/prefix.hpp\"\n #include \"duckdb/storage/meta_block_reader.hpp\"\n@@ -32,6 +33,9 @@ row_t *Leaf::GetRowIds() {\n \t}\n }\n \n+Leaf::Leaf() : Node(NodeType::NLeaf) {\n+}\n+\n Leaf::Leaf(Key &value, uint32_t depth, row_t row_id) : Node(NodeType::NLeaf) {\n \tcount = 1;\n \trowids.inlined = row_id;\n@@ -75,6 +79,13 @@ Leaf::~Leaf() {\n \t}\n }\n \n+idx_t Leaf::MemorySize(ART &, const bool &) {\n+\tif (IsInlined()) {\n+\t\treturn prefix.MemorySize() + sizeof(*this) + sizeof(row_t);\n+\t}\n+\treturn prefix.MemorySize() + sizeof(*this) + sizeof(row_t) * (GetCapacity() + 1);\n+}\n+\n row_t *Leaf::Resize(row_t *current_row_ids, uint32_t current_count, idx_t new_capacity) {\n \tD_ASSERT(new_capacity >= current_count);\n \tauto new_allocation = AllocateArray<row_t>(new_capacity + 1);\n@@ -90,34 +101,48 @@ row_t *Leaf::Resize(row_t *current_row_ids, uint32_t current_count, idx_t new_ca\n \treturn new_row_ids;\n }\n \n-void Leaf::Insert(row_t row_id) {\n+void Leaf::Insert(ART &art, row_t row_id) {\n \tauto capacity = GetCapacity();\n \trow_t *row_ids = GetRowIds();\n \tD_ASSERT(count <= capacity);\n+\n \tif (count == capacity) {\n-\t\t// Grow array\n+\t\t// grow array\n+\t\tif (IsInlined()) {\n+\t\t\tart.memory_size += (capacity + 1) * sizeof(row_t);\n+\t\t} else {\n+\t\t\tart.memory_size += capacity * sizeof(row_t);\n+\t\t}\n \t\trow_ids = Resize(row_ids, count, capacity * 2);\n \t}\n+\t// insert new row ID\n \trow_ids[count++] = row_id;\n }\n \n-void Leaf::Remove(row_t row_id) {\n+void Leaf::Remove(ART &art, row_t row_id) {\n \tidx_t entry_offset = DConstants::INVALID_INDEX;\n \trow_t *row_ids = GetRowIds();\n+\n+\t// find the row ID in the leaf\n \tfor (idx_t i = 0; i < count; i++) {\n \t\tif (row_ids[i] == row_id) {\n \t\t\tentry_offset = i;\n \t\t\tbreak;\n \t\t}\n \t}\n+\n+\t// didn't find the row ID\n \tif (entry_offset == DConstants::INVALID_INDEX) {\n \t\treturn;\n \t}\n+\n+\t// now empty leaf\n \tif (IsInlined()) {\n \t\tD_ASSERT(count == 1);\n \t\tcount--;\n \t\treturn;\n \t}\n+\n \tcount--;\n \tif (count == 1) {\n \t\t// after erasing we can now inline the leaf\n@@ -125,21 +150,31 @@ void Leaf::Remove(row_t row_id) {\n \t\tauto remaining_row_id = row_ids[0] == row_id ? row_ids[1] : row_ids[0];\n \t\tDeleteArray<row_t>(rowids.ptr, rowids.ptr[0] + 1);\n \t\trowids.inlined = remaining_row_id;\n+\t\tD_ASSERT(art.memory_size >= sizeof(row_t));\n+\t\tart.memory_size -= 2 * sizeof(row_t);\n \t\treturn;\n \t}\n+\n+\t// shrink array, if less than half full\n \tauto capacity = GetCapacity();\n \tif (capacity > 2 && count < capacity / 2) {\n-\t\t// Shrink array, if less than half full\n+\n \t\tauto new_capacity = capacity / 2;\n+\t\tD_ASSERT(art.memory_size >= (capacity - new_capacity) * sizeof(row_t));\n+\t\tart.memory_size -= (capacity - new_capacity) * sizeof(row_t);\n+\n \t\tauto new_allocation = AllocateArray<row_t>(new_capacity + 1);\n \t\tnew_allocation[0] = new_capacity;\n+\n \t\tauto new_row_ids = new_allocation + 1;\n \t\tmemcpy(new_row_ids, row_ids, entry_offset * sizeof(row_t));\n \t\tmemcpy(new_row_ids + entry_offset, row_ids + entry_offset + 1, (count - entry_offset) * sizeof(row_t));\n+\n \t\tDeleteArray<row_t>(rowids.ptr, rowids.ptr[0] + 1);\n \t\trowids.ptr = new_allocation;\n+\n \t} else {\n-\t\t// Copy the rest\n+\t\t// move the trailing row IDs (after entry_offset)\n \t\tmemmove(row_ids + entry_offset, row_ids + entry_offset + 1, (count - entry_offset) * sizeof(row_t));\n \t}\n }\n@@ -154,7 +189,7 @@ string Leaf::ToString(Node *node) {\n \treturn str + \"]\";\n }\n \n-void Leaf::Merge(Node *&l_node, Node *&r_node) {\n+void Leaf::Merge(ART &art, Node *&l_node, Node *&r_node) {\n \tLeaf *l_n = (Leaf *)l_node;\n \tLeaf *r_n = (Leaf *)r_node;\n \n@@ -163,24 +198,24 @@ void Leaf::Merge(Node *&l_node, Node *&r_node) {\n \tauto r_row_ids = r_n->GetRowIds();\n \n \tif (l_n->count + r_n->count > l_capacity) {\n+\t\tauto capacity = l_n->GetCapacity();\n \t\tauto new_capacity = NextPowerOfTwo(l_n->count + r_n->count);\n+\t\tart.memory_size += sizeof(row_t) * (new_capacity - capacity);\n \t\tl_row_ids = l_n->Resize(l_row_ids, l_n->count, new_capacity);\n \t}\n \n+\t// append row_ids to l_n\n \tmemcpy(l_row_ids + l_n->count, r_row_ids, r_n->count * sizeof(row_t));\n \tl_n->count += r_n->count;\n }\n \n BlockPointer Leaf::Serialize(duckdb::MetaBlockWriter &writer) {\n+\n \tauto ptr = writer.GetBlockPointer();\n-\t// Write Node Type\n \twriter.Write(type);\n-\t// Write compression Info\n \tprefix.Serialize(writer);\n-\t// Write Row Ids\n-\t// Length\n \twriter.Write<uint16_t>(count);\n-\t// Actual Row Ids\n+\n \tauto row_ids = GetRowIds();\n \tfor (idx_t i = 0; i < count; i++) {\n \t\twriter.Write(row_ids[i]);\n@@ -188,22 +223,23 @@ BlockPointer Leaf::Serialize(duckdb::MetaBlockWriter &writer) {\n \treturn ptr;\n }\n \n-Leaf *Leaf::Deserialize(MetaBlockReader &reader) {\n-\tPrefix prefix;\n+void Leaf::Deserialize(ART &art, MetaBlockReader &reader) {\n+\n \tprefix.Deserialize(reader);\n-\tauto num_elements = reader.Read<uint16_t>();\n-\tif (num_elements == 1) {\n+\tcount = reader.Read<uint16_t>();\n+\tif (count == 1) {\n \t\t// inlined\n-\t\tauto element = reader.Read<row_t>();\n-\t\treturn Leaf::New(element, prefix);\n+\t\tauto row_id = reader.Read<row_t>();\n+\t\trowids.inlined = row_id;\n+\n \t} else {\n \t\t// non-inlined\n-\t\tauto elements = AllocateArray<row_t>(num_elements + 1);\n-\t\telements[0] = num_elements;\n-\t\tfor (idx_t i = 0; i < num_elements; i++) {\n-\t\t\telements[i + 1] = reader.Read<row_t>();\n+\t\tauto row_ids = AllocateArray<row_t>(count + 1);\n+\t\trow_ids[0] = count;\n+\t\tfor (idx_t i = 0; i < count; i++) {\n+\t\t\trow_ids[i + 1] = reader.Read<row_t>();\n \t\t}\n-\t\treturn Leaf::New(elements, num_elements, prefix);\n+\t\trowids.ptr = row_ids;\n \t}\n }\n \ndiff --git a/src/execution/index/art/node.cpp b/src/execution/index/art/node.cpp\nindex a62a7e3ec757..6af3a40b0836 100644\n--- a/src/execution/index/art/node.cpp\n+++ b/src/execution/index/art/node.cpp\n@@ -46,6 +46,10 @@ Node::Node(NodeType type) : count(0), type(type) {\n }\n \n // LCOV_EXCL_START\n+idx_t Node::MemorySize(ART &, const bool &) {\n+\tthrow InternalException(\"MemorySize not implemented for the specific node type.\");\n+}\n+\n idx_t Node::GetMin() {\n \tthrow InternalException(\"GetMin not implemented for the specific node type.\");\n }\n@@ -57,46 +61,50 @@ Node *Node::GetChild(ART &art, idx_t pos) {\n void Node::ReplaceChildPointer(idx_t pos, Node *node) {\n \tthrow InternalException(\"ReplaceChildPointer not implemented for the specific node type.\");\n }\n+\n+bool Node::ChildIsInMemory(idx_t) {\n+\tthrow InternalException(\"ChildIsInMemory not implemented for the specific node type.\");\n+}\n // LCOV_EXCL_STOP\n \n-void Node::InsertChild(Node *&node, uint8_t key_byte, Node *new_child) {\n+void Node::InsertChild(ART &art, Node *&node, uint8_t key_byte, Node *new_child) {\n \tswitch (node->type) {\n \tcase NodeType::N4:\n-\t\tNode4::InsertChild(node, key_byte, new_child);\n+\t\tNode4::InsertChild(art, node, key_byte, new_child);\n \t\tbreak;\n \tcase NodeType::N16:\n-\t\tNode16::InsertChild(node, key_byte, new_child);\n+\t\tNode16::InsertChild(art, node, key_byte, new_child);\n \t\tbreak;\n \tcase NodeType::N48:\n-\t\tNode48::InsertChild(node, key_byte, new_child);\n+\t\tNode48::InsertChild(art, node, key_byte, new_child);\n \t\tbreak;\n \tcase NodeType::N256:\n-\t\tNode256::InsertChild(node, key_byte, new_child);\n+\t\tNode256::InsertChild(art, node, key_byte, new_child);\n \t\tbreak;\n \tdefault:\n-\t\tthrow InternalException(\"Unrecognized leaf type for insert\");\n+\t\tthrow InternalException(\"Unrecognized node type for insert.\");\n \t}\n }\n \n-void Node::EraseChild(Node *&node, idx_t pos, ART &art) {\n+void Node::EraseChild(ART &art, Node *&node, idx_t pos) {\n \tswitch (node->type) {\n \tcase NodeType::N4: {\n-\t\tNode4::EraseChild(node, pos, art);\n+\t\tNode4::EraseChild(art, node, pos);\n \t\tbreak;\n \t}\n \tcase NodeType::N16: {\n-\t\tNode16::EraseChild(node, pos, art);\n+\t\tNode16::EraseChild(art, node, pos);\n \t\tbreak;\n \t}\n \tcase NodeType::N48: {\n-\t\tNode48::EraseChild(node, pos, art);\n+\t\tNode48::EraseChild(art, node, pos);\n \t\tbreak;\n \t}\n \tcase NodeType::N256:\n-\t\tNode256::EraseChild(node, pos, art);\n+\t\tNode256::EraseChild(art, node, pos);\n \t\tbreak;\n \tdefault:\n-\t\tthrow InternalException(\"Unrecognized leaf type for erase\");\n+\t\tthrow InternalException(\"Unrecognized node type for erase.\");\n \t}\n }\n \n@@ -113,7 +121,7 @@ NodeType Node::GetTypeBySize(idx_t size) {\n \treturn NodeType::N256;\n }\n \n-void Node::New(NodeType &type, Node *&node) {\n+void Node::New(const NodeType &type, Node *&node) {\n \tswitch (type) {\n \tcase NodeType::N4:\n \t\tnode = (Node *)Node4::New();\n@@ -128,7 +136,7 @@ void Node::New(NodeType &type, Node *&node) {\n \t\tnode = (Node *)Node256::New();\n \t\treturn;\n \tdefault:\n-\t\tthrow InternalException(\"Unrecognized type for new node creation!\");\n+\t\tthrow InternalException(\"Unrecognized node type for new node creation.\");\n \t}\n }\n \n@@ -148,6 +156,10 @@ Node256 *Node256::New() {\n \treturn AllocateObject<Node256>();\n }\n \n+Leaf *Leaf::New() {\n+\treturn AllocateObject<Leaf>();\n+}\n+\n Leaf *Leaf::New(Key &value, uint32_t depth, row_t row_id) {\n \treturn AllocateObject<Leaf>(value, depth, row_id);\n }\n@@ -182,7 +194,7 @@ void Node::Delete(Node *ptr) {\n \t\tDestroyObject((Node256 *)ptr);\n \t\tbreak;\n \tdefault:\n-\t\tthrow InternalException(\"eek\");\n+\t\tthrow InternalException(\"Invalid node type for delete.\");\n \t}\n }\n \n@@ -217,23 +229,24 @@ string Node::ToString(ART &art) {\n }\n \n BlockPointer Node::SerializeInternal(ART &art, duckdb::MetaBlockWriter &writer, InternalType &internal_type) {\n-\t// Iterate through children and annotate their offsets\n+\n+\t// iterate through children and annotate their offsets\n \tvector<BlockPointer> child_offsets;\n \tfor (idx_t i = 0; i < internal_type.children_size; i++) {\n \t\tchild_offsets.emplace_back(internal_type.children[i].Serialize(art, writer));\n \t}\n \tauto ptr = writer.GetBlockPointer();\n-\t// Write Node Type\n+\n \twriter.Write(type);\n-\t// Write count\n \twriter.Write<uint16_t>(count);\n-\t// Write Prefix\n \tprefix.Serialize(writer);\n-\t// Write Key values\n+\n+\t// write key values\n \tfor (idx_t i = 0; i < internal_type.key_size; i++) {\n \t\twriter.Write(internal_type.key[i]);\n \t}\n-\t// Write child offsets\n+\n+\t// write child offsets\n \tfor (auto &offsets : child_offsets) {\n \t\twriter.Write(offsets.block_id);\n \t\twriter.Write(offsets.offset);\n@@ -242,6 +255,7 @@ BlockPointer Node::SerializeInternal(ART &art, duckdb::MetaBlockWriter &writer,\n }\n \n BlockPointer Node::Serialize(ART &art, duckdb::MetaBlockWriter &writer) {\n+\n \tswitch (type) {\n \tcase NodeType::N4:\n \tcase NodeType::N16:\n@@ -255,33 +269,48 @@ BlockPointer Node::Serialize(ART &art, duckdb::MetaBlockWriter &writer) {\n \t\treturn leaf->Serialize(writer);\n \t}\n \tdefault:\n-\t\tthrow InternalException(\"Invalid ART Node\");\n+\t\tthrow InternalException(\"Invalid ART node for serialize.\");\n \t}\n }\n \n-void Node::DeserializeInternal(duckdb::MetaBlockReader &reader) {\n+void Node::DeserializeInternal(ART &art, duckdb::MetaBlockReader &reader) {\n+\n \tInternalType internal_type(this);\n \tcount = reader.Read<uint16_t>();\n \tprefix.Deserialize(reader);\n-\t// Get Key values\n+\n+\t// read key values\n \tfor (idx_t i = 0; i < internal_type.key_size; i++) {\n \t\tinternal_type.key[i] = reader.Read<uint8_t>();\n \t}\n-\t// Get Child offsets\n+\n+\t// read child offsets\n \tfor (idx_t i = 0; i < internal_type.children_size; i++) {\n \t\tinternal_type.children[i] = ARTPointer(reader);\n \t}\n }\n \n Node *Node::Deserialize(ART &art, idx_t block_id, idx_t offset) {\n+\n \tMetaBlockReader reader(art.table_io_manager.GetIndexBlockManager(), block_id);\n \treader.offset = offset;\n+\n \tauto n = reader.Read<uint8_t>();\n-\tNodeType node_type(static_cast<NodeType>(n));\n+\tNodeType node_type((NodeType)(n));\n+\n \tNode *deserialized_node = nullptr;\n+\tauto old_memory_size = art.memory_size;\n \tswitch (node_type) {\n-\tcase NodeType::NLeaf:\n-\t\treturn Leaf::Deserialize(reader);\n+\tcase NodeType::NLeaf: {\n+\t\tauto leaf = Leaf::New();\n+\t\tleaf->Deserialize(art, reader);\n+\t\tart.memory_size += leaf->MemorySize(art, false);\n+\t\tD_ASSERT(art.memory_size >= old_memory_size);\n+\t\tif (art.track_memory) {\n+\t\t\tart.buffer_manager.IncreaseUsedMemory(art.memory_size - old_memory_size);\n+\t\t}\n+\t\treturn leaf;\n+\t}\n \tcase NodeType::N4: {\n \t\tdeserialized_node = (Node *)Node4::New();\n \t\tbreak;\n@@ -301,7 +330,12 @@ Node *Node::Deserialize(ART &art, idx_t block_id, idx_t offset) {\n \tdefault:\n \t\tthrow InternalException(\"Unrecognized node type\");\n \t}\n-\tdeserialized_node->DeserializeInternal(reader);\n+\tdeserialized_node->DeserializeInternal(art, reader);\n+\tart.memory_size += deserialized_node->MemorySize(art, false);\n+\tD_ASSERT(art.memory_size >= old_memory_size);\n+\tif (art.track_memory) {\n+\t\tart.buffer_manager.IncreaseUsedMemory(art.memory_size - old_memory_size);\n+\t}\n \treturn deserialized_node;\n }\n \n@@ -315,9 +349,30 @@ void UpdateParentsOfNodes(Node *&l_node, Node *&r_node, ParentsOfNodes &parents)\n }\n \n // forward declaration\n-bool ResolvePrefixesAndMerge(MergeInfo &info, idx_t depth, ParentsOfNodes &parents);\n+bool ResolvePrefixesAndMerge(MergeInfo &info, ParentsOfNodes &parents);\n+\n+void SwapNodes(MergeInfo &info, ParentsOfNodes &parents) {\n+\t// adjust the memory sizes\n+\tauto l_node_memory_size = info.l_node->MemorySize(*info.l_art, true);\n+\tauto r_node_memory_size = info.r_node->MemorySize(*info.r_art, true);\n+\n+\tD_ASSERT(info.root_l_art->memory_size >= l_node_memory_size);\n+\tD_ASSERT(info.root_r_art->memory_size >= r_node_memory_size);\n+\tinfo.root_l_art->memory_size -= l_node_memory_size;\n+\tinfo.root_r_art->memory_size -= r_node_memory_size;\n+\tinfo.root_l_art->memory_size += r_node_memory_size;\n+\tinfo.root_r_art->memory_size += l_node_memory_size;\n+\n+\t// actual swap\n+\tswap(info.l_art, info.r_art);\n+\tswap(info.l_node, info.r_node);\n+\tUpdateParentsOfNodes(info.l_node, info.r_node, parents);\n+}\n \n-bool Merge(MergeInfo &info, idx_t depth, ParentsOfNodes &parents) {\n+bool Merge(MergeInfo &info, ParentsOfNodes &parents) {\n+\n+\tD_ASSERT(info.l_node);\n+\tD_ASSERT(info.r_node);\n \n \t// always try to merge the smaller node into the bigger node\n \t// because maybe there is enough free space in the bigger node to fit the smaller one\n@@ -325,9 +380,7 @@ bool Merge(MergeInfo &info, idx_t depth, ParentsOfNodes &parents) {\n \n \tif (info.l_node->type < info.r_node->type) {\n \t\t// swap subtrees to ensure that l_node has the bigger node type\n-\t\tswap(info.l_art, info.r_art);\n-\t\tswap(info.l_node, info.r_node);\n-\t\tUpdateParentsOfNodes(info.l_node, info.r_node, parents);\n+\t\tSwapNodes(info, parents);\n \t}\n \n \tif (info.r_node->type == NodeType::NLeaf) {\n@@ -336,7 +389,7 @@ bool Merge(MergeInfo &info, idx_t depth, ParentsOfNodes &parents) {\n \t\tif (info.l_art->IsUnique()) {\n \t\t\treturn false;\n \t\t}\n-\t\tLeaf::Merge(info.l_node, info.r_node);\n+\t\tLeaf::Merge(*info.root_l_art, info.l_node, info.r_node);\n \t\treturn true;\n \t}\n \n@@ -353,7 +406,12 @@ bool Merge(MergeInfo &info, idx_t depth, ParentsOfNodes &parents) {\n \n \t\tif (l_child_pos == DConstants::INVALID_INDEX) {\n \t\t\t// insert child at empty position\n-\t\t\tNode::InsertChild(info.l_node, key_byte, r_child);\n+\t\t\tauto r_memory_size = r_child->MemorySize(*info.r_art, true);\n+\t\t\tNode::InsertChild(*info.root_l_art, info.l_node, key_byte, r_child);\n+\n+\t\t\tinfo.root_l_art->memory_size += r_memory_size;\n+\t\t\tD_ASSERT(info.root_r_art->memory_size >= r_memory_size);\n+\t\t\tinfo.root_r_art->memory_size -= r_memory_size;\n \t\t\tif (parents.l_parent) {\n \t\t\t\tparents.l_parent->ReplaceChildPointer(parents.l_pos, info.l_node);\n \t\t\t}\n@@ -362,9 +420,9 @@ bool Merge(MergeInfo &info, idx_t depth, ParentsOfNodes &parents) {\n \t\t} else {\n \t\t\t// recurse\n \t\t\tauto l_child = info.l_node->GetChild(*info.l_art, l_child_pos);\n-\t\t\tMergeInfo child_info(info.l_art, info.r_art, l_child, r_child);\n+\t\t\tMergeInfo child_info(info.l_art, info.r_art, info.root_l_art, info.root_r_art, l_child, r_child);\n \t\t\tParentsOfNodes child_parents(info.l_node, l_child_pos, info.r_node, r_child_pos);\n-\t\t\tif (!ResolvePrefixesAndMerge(child_info, depth + 1, child_parents)) {\n+\t\t\tif (!ResolvePrefixesAndMerge(child_info, child_parents)) {\n \t\t\t\treturn false;\n \t\t\t}\n \t\t}\n@@ -372,29 +430,28 @@ bool Merge(MergeInfo &info, idx_t depth, ParentsOfNodes &parents) {\n \treturn true;\n }\n \n-bool ResolvePrefixesAndMerge(MergeInfo &info, idx_t depth, ParentsOfNodes &parents) {\n-\tauto &l_node = info.l_node;\n-\tauto &r_node = info.r_node;\n-\tNode *null_parent = nullptr;\n-\n+bool ResolvePrefixesAndMerge(MergeInfo &info, ParentsOfNodes &parents) {\n \t// NOTE: we always merge into the left ART\n-\tD_ASSERT(l_node);\n-\tauto l_prefix_size = l_node->prefix.Size();\n-\tauto r_prefix_size = r_node->prefix.Size();\n+\n+\tD_ASSERT(info.l_node);\n+\tD_ASSERT(info.r_node);\n \n \t// make sure that r_node has the longer (or equally long) prefix\n-\tif (l_prefix_size > r_prefix_size) {\n-\t\tswap(info.l_art, info.r_art);\n-\t\tswap(l_node, r_node);\n-\t\tswap(l_prefix_size, r_prefix_size);\n-\t\tUpdateParentsOfNodes(l_node, r_node, parents);\n+\tif (info.l_node->prefix.Size() > info.r_node->prefix.Size()) {\n+\t\tSwapNodes(info, parents);\n \t}\n \n+\tNode *null_parent = nullptr;\n+\tauto &l_node = info.l_node;\n+\tauto &r_node = info.r_node;\n+\tauto l_prefix_size = l_node->prefix.Size();\n+\tauto r_prefix_size = r_node->prefix.Size();\n+\n \tauto mismatch_pos = l_node->prefix.MismatchPosition(r_node->prefix);\n \n \t// both nodes have no prefix or the same prefix\n \tif (mismatch_pos == l_prefix_size && l_prefix_size == r_prefix_size) {\n-\t\treturn Merge(info, depth + mismatch_pos, parents);\n+\t\treturn Merge(info, parents);\n \t}\n \n \tif (mismatch_pos == l_prefix_size) {\n@@ -408,11 +465,17 @@ bool ResolvePrefixesAndMerge(MergeInfo &info, idx_t depth, ParentsOfNodes &paren\n \t\tauto child_pos = l_node->GetChildPos(mismatch_byte);\n \n \t\t// update the prefix of r_node to only consist of the bytes after mismatch_pos\n-\t\tr_node->prefix.Reduce(mismatch_pos);\n+\t\tr_node->prefix.Reduce(*info.root_r_art, mismatch_pos);\n \n \t\t// insert r_node as a child of l_node at empty position\n \t\tif (child_pos == DConstants::INVALID_INDEX) {\n-\t\t\tNode::InsertChild(l_node, mismatch_byte, r_node);\n+\n+\t\t\tauto r_memory_size = r_node->MemorySize(*info.r_art, true);\n+\t\t\tNode::InsertChild(*info.root_l_art, l_node, mismatch_byte, r_node);\n+\n+\t\t\tinfo.root_l_art->memory_size += r_memory_size;\n+\t\t\tD_ASSERT(info.root_r_art->memory_size >= r_memory_size);\n+\t\t\tinfo.root_r_art->memory_size -= r_memory_size;\n \t\t\tUpdateParentsOfNodes(l_node, null_parent, parents);\n \t\t\tr_node = nullptr;\n \t\t\treturn true;\n@@ -420,9 +483,9 @@ bool ResolvePrefixesAndMerge(MergeInfo &info, idx_t depth, ParentsOfNodes &paren\n \n \t\t// recurse\n \t\tauto child_node = l_node->GetChild(*info.l_art, child_pos);\n-\t\tMergeInfo child_info(info.l_art, info.r_art, child_node, r_node);\n+\t\tMergeInfo child_info(info.l_art, info.r_art, info.root_l_art, info.root_r_art, child_node, r_node);\n \t\tParentsOfNodes child_parents(l_node, child_pos, parents.r_parent, parents.r_pos);\n-\t\treturn ResolvePrefixesAndMerge(child_info, depth + mismatch_pos, child_parents);\n+\t\treturn ResolvePrefixesAndMerge(child_info, child_parents);\n \t}\n \n \t// prefixes differ, create new node and insert both nodes as children\n@@ -430,14 +493,20 @@ bool ResolvePrefixesAndMerge(MergeInfo &info, idx_t depth, ParentsOfNodes &paren\n \t// create new node\n \tNode *new_node = Node4::New();\n \tnew_node->prefix = Prefix(l_node->prefix, mismatch_pos);\n+\tinfo.root_l_art->memory_size += new_node->MemorySize(*info.l_art, false);\n \n \t// insert l_node, break up prefix of l_node\n-\tauto key_byte = l_node->prefix.Reduce(mismatch_pos);\n-\tNode4::InsertChild(new_node, key_byte, l_node);\n+\tauto key_byte = l_node->prefix.Reduce(*info.root_l_art, mismatch_pos);\n+\tNode4::InsertChild(*info.root_l_art, new_node, key_byte, l_node);\n \n \t// insert r_node, break up prefix of r_node\n-\tkey_byte = r_node->prefix.Reduce(mismatch_pos);\n-\tNode4::InsertChild(new_node, key_byte, r_node);\n+\tkey_byte = r_node->prefix.Reduce(*info.root_r_art, mismatch_pos);\n+\tauto r_memory_size = r_node->MemorySize(*info.r_art, true);\n+\tNode4::InsertChild(*info.root_l_art, new_node, key_byte, r_node);\n+\n+\tinfo.root_l_art->memory_size += r_memory_size;\n+\tD_ASSERT(info.root_r_art->memory_size >= r_memory_size);\n+\tinfo.root_r_art->memory_size -= r_memory_size;\n \n \tl_node = new_node;\n \tUpdateParentsOfNodes(l_node, null_parent, parents);\n@@ -448,9 +517,26 @@ bool ResolvePrefixesAndMerge(MergeInfo &info, idx_t depth, ParentsOfNodes &paren\n bool Node::MergeARTs(ART *l_art, ART *r_art) {\n \n \tNode *null_parent = nullptr;\n-\tMergeInfo info(l_art, r_art, l_art->tree, r_art->tree);\n+\tMergeInfo info(l_art, r_art, l_art, r_art, l_art->tree, r_art->tree);\n \tParentsOfNodes parents(null_parent, 0, null_parent, 0);\n-\treturn ResolvePrefixesAndMerge(info, 0, parents);\n+\treturn ResolvePrefixesAndMerge(info, parents);\n+}\n+\n+idx_t Node::RecursiveMemorySize(ART &art) {\n+\n+\t// get the size of all children\n+\tauto memory_size_children = 0;\n+\n+\tauto next_pos = GetNextPos(DConstants::INVALID_INDEX);\n+\twhile (next_pos != DConstants::INVALID_INDEX) {\n+\t\tif (ChildIsInMemory(next_pos)) {\n+\t\t\tauto child = GetChild(art, next_pos);\n+\t\t\tmemory_size_children += child->MemorySize(art, true);\n+\t\t}\n+\t\tnext_pos = GetNextPos(next_pos);\n+\t}\n+\n+\treturn memory_size_children;\n }\n \n } // namespace duckdb\ndiff --git a/src/execution/index/art/node16.cpp b/src/execution/index/art/node16.cpp\nindex 26616582b228..f54977512d73 100644\n--- a/src/execution/index/art/node16.cpp\n+++ b/src/execution/index/art/node16.cpp\n@@ -1,5 +1,6 @@\n #include \"duckdb/execution/index/art/node16.hpp\"\n \n+#include \"duckdb/execution/index/art/art.hpp\"\n #include \"duckdb/execution/index/art/node4.hpp\"\n #include \"duckdb/execution/index/art/node48.hpp\"\n \n@@ -11,6 +12,13 @@ Node16::Node16() : Node(NodeType::N16) {\n \tmemset(key, 16, sizeof(key));\n }\n \n+idx_t Node16::MemorySize(ART &art, const bool &recurse) {\n+\tif (recurse) {\n+\t\treturn prefix.MemorySize() + sizeof(*this) + RecursiveMemorySize(art);\n+\t}\n+\treturn prefix.MemorySize() + sizeof(*this);\n+}\n+\n idx_t Node16::GetChildPos(uint8_t k) {\n \tfor (idx_t pos = 0; pos < count; pos++) {\n \t\tif (key[pos] == k) {\n@@ -69,12 +77,16 @@ void Node16::ReplaceChildPointer(idx_t pos, Node *node) {\n \tchildren[pos] = node;\n }\n \n-void Node16::InsertChild(Node *&node, uint8_t key_byte, Node *new_child) {\n+bool Node16::ChildIsInMemory(idx_t pos) {\n+\treturn children[pos] && !children[pos].IsSwizzled();\n+}\n+\n+void Node16::InsertChild(ART &art, Node *&node, uint8_t key_byte, Node *new_child) {\n \tNode16 *n = (Node16 *)node;\n \n-\t// Insert new child node into node\n-\tif (n->count < 16) {\n-\t\t// Insert element\n+\t// insert new child node into node\n+\tif (n->count < Node16::GetSize()) {\n+\t\t// still space, just insert the child\n \t\tidx_t pos = 0;\n \t\twhile (pos < node->count && n->key[pos] < key_byte) {\n \t\t\tpos++;\n@@ -88,57 +100,74 @@ void Node16::InsertChild(Node *&node, uint8_t key_byte, Node *new_child) {\n \t\tn->key[pos] = key_byte;\n \t\tn->children[pos] = new_child;\n \t\tn->count++;\n+\n \t} else {\n-\t\t// Grow to Node48\n+\t\t// node is full, grow to Node48\n \t\tauto new_node = Node48::New();\n+\t\tart.memory_size += new_node->MemorySize(art, false);\n+\t\tnew_node->count = node->count;\n+\t\tnew_node->prefix = std::move(n->prefix);\n+\n \t\tfor (idx_t i = 0; i < node->count; i++) {\n \t\t\tnew_node->child_index[n->key[i]] = i;\n \t\t\tnew_node->children[i] = n->children[i];\n \t\t\tn->children[i] = nullptr;\n \t\t}\n-\t\tnew_node->prefix = std::move(n->prefix);\n-\t\tnew_node->count = node->count;\n+\n+\t\tD_ASSERT(art.memory_size >= node->MemorySize(art, false));\n+\t\tart.memory_size -= node->MemorySize(art, false);\n \t\tNode::Delete(node);\n \t\tnode = new_node;\n-\n-\t\tNode48::InsertChild(node, key_byte, new_child);\n+\t\tNode48::InsertChild(art, node, key_byte, new_child);\n \t}\n }\n \n-void Node16::EraseChild(Node *&node, int pos, ART &art) {\n+void Node16::EraseChild(ART &art, Node *&node, idx_t pos) {\n+\n \tauto n = (Node16 *)node;\n+\tD_ASSERT(pos < n->count);\n+\n+\t// adjust the ART size\n+\tif (n->ChildIsInMemory(pos)) {\n+\t\tauto child = n->GetChild(art, pos);\n+\t\tD_ASSERT(art.memory_size >= child->MemorySize(art, true));\n+\t\tart.memory_size -= child->MemorySize(art, true);\n+\t}\n+\n \t// erase the child and decrease the count\n \tn->children[pos].Reset();\n \tn->count--;\n+\n \t// potentially move any children backwards\n \tfor (; pos < n->count; pos++) {\n \t\tn->key[pos] = n->key[pos + 1];\n \t\tn->children[pos] = n->children[pos + 1];\n \t}\n \t// set any remaining nodes as nullptr\n-\tfor (; pos < 16; pos++) {\n+\tfor (; pos < Node16::GetSize(); pos++) {\n \t\tif (!n->children[pos]) {\n \t\t\tbreak;\n \t\t}\n \t\tn->children[pos] = nullptr;\n \t}\n \n-\tif (node->count <= 3) {\n-\t\t// Shrink node\n+\t// shrink node to Node4\n+\tif (node->count < Node4::GetSize()) {\n+\n \t\tauto new_node = Node4::New();\n-\t\tfor (unsigned i = 0; i < n->count; i++) {\n+\t\tart.memory_size += new_node->MemorySize(art, false);\n+\t\tnew_node->prefix = std::move(n->prefix);\n+\n+\t\tfor (idx_t i = 0; i < n->count; i++) {\n \t\t\tnew_node->key[new_node->count] = n->key[i];\n \t\t\tnew_node->children[new_node->count++] = n->children[i];\n \t\t\tn->children[i] = nullptr;\n \t\t}\n-\t\tnew_node->prefix = std::move(n->prefix);\n+\n+\t\tD_ASSERT(art.memory_size >= node->MemorySize(art, false));\n+\t\tart.memory_size -= node->MemorySize(art, false);\n \t\tNode::Delete(node);\n \t\tnode = new_node;\n \t}\n }\n-\n-idx_t Node16::GetSize() {\n-\treturn 16;\n-}\n-\n } // namespace duckdb\ndiff --git a/src/execution/index/art/node256.cpp b/src/execution/index/art/node256.cpp\nindex 60ecb667f6e5..0ee325406b77 100644\n--- a/src/execution/index/art/node256.cpp\n+++ b/src/execution/index/art/node256.cpp\n@@ -1,5 +1,6 @@\n #include \"duckdb/execution/index/art/node256.hpp\"\n \n+#include \"duckdb/execution/index/art/art.hpp\"\n #include \"duckdb/execution/index/art/node48.hpp\"\n \n namespace duckdb {\n@@ -7,6 +8,13 @@ namespace duckdb {\n Node256::Node256() : Node(NodeType::N256) {\n }\n \n+idx_t Node256::MemorySize(ART &art, const bool &recurse) {\n+\tif (recurse) {\n+\t\treturn prefix.MemorySize() + sizeof(*this) + RecursiveMemorySize(art);\n+\t}\n+\treturn prefix.MemorySize() + sizeof(*this);\n+}\n+\n idx_t Node256::GetChildPos(uint8_t k) {\n \tif (children[k]) {\n \t\treturn k;\n@@ -16,7 +24,7 @@ idx_t Node256::GetChildPos(uint8_t k) {\n }\n \n idx_t Node256::GetChildGreaterEqual(uint8_t k, bool &equal) {\n-\tfor (idx_t pos = k; pos < 256; pos++) {\n+\tfor (idx_t pos = k; pos < Node256::GetSize(); pos++) {\n \t\tif (children[pos]) {\n \t\t\tif (pos == k) {\n \t\t\t\tequal = true;\n@@ -30,7 +38,7 @@ idx_t Node256::GetChildGreaterEqual(uint8_t k, bool &equal) {\n }\n \n idx_t Node256::GetMin() {\n-\tfor (idx_t i = 0; i < 256; i++) {\n+\tfor (idx_t i = 0; i < Node256::GetSize(); i++) {\n \t\tif (children[i]) {\n \t\t\treturn i;\n \t\t}\n@@ -39,7 +47,8 @@ idx_t Node256::GetMin() {\n }\n \n idx_t Node256::GetNextPos(idx_t pos) {\n-\tfor (pos == DConstants::INVALID_INDEX ? pos = 0 : pos++; pos < 256; pos++) {\n+\tpos == DConstants::INVALID_INDEX ? pos = 0 : pos++;\n+\tfor (; pos < Node256::GetSize(); pos++) {\n \t\tif (children[pos]) {\n \t\t\treturn pos;\n \t\t}\n@@ -48,7 +57,8 @@ idx_t Node256::GetNextPos(idx_t pos) {\n }\n \n idx_t Node256::GetNextPosAndByte(idx_t pos, uint8_t &byte) {\n-\tfor (pos == DConstants::INVALID_INDEX ? pos = 0 : pos++; pos < 256; pos++) {\n+\tpos == DConstants::INVALID_INDEX ? pos = 0 : pos++;\n+\tfor (; pos < Node256::GetSize(); pos++) {\n \t\tif (children[pos]) {\n \t\t\tbyte = uint8_t(pos);\n \t\t\treturn pos;\n@@ -65,35 +75,50 @@ void Node256::ReplaceChildPointer(idx_t pos, Node *node) {\n \tchildren[pos] = node;\n }\n \n-void Node256::InsertChild(Node *&node, uint8_t key_byte, Node *new_child) {\n+bool Node256::ChildIsInMemory(idx_t pos) {\n+\treturn children[pos] && !children[pos].IsSwizzled();\n+}\n+\n+void Node256::InsertChild(ART &, Node *&node, uint8_t key_byte, Node *new_child) {\n \tauto n = (Node256 *)(node);\n \n \tn->count++;\n \tn->children[key_byte] = new_child;\n }\n \n-void Node256::EraseChild(Node *&node, int pos, ART &art) {\n+void Node256::EraseChild(ART &art, Node *&node, idx_t pos) {\n \tauto n = (Node256 *)(node);\n+\n+\t// adjust the ART size\n+\tif (n->ChildIsInMemory(pos)) {\n+\t\tauto child = n->GetChild(art, pos);\n+\t\tD_ASSERT(art.memory_size >= child->MemorySize(art, true));\n+\t\tart.memory_size -= child->MemorySize(art, true);\n+\t}\n+\n+\t// erase the child and decrease the count\n \tn->children[pos].Reset();\n \tn->count--;\n-\tif (node->count <= 36) {\n+\n+\t// shrink node to Node48\n+\tif (node->count <= NODE_256_SHRINK_THRESHOLD) {\n+\n \t\tauto new_node = Node48::New();\n+\t\tart.memory_size += new_node->MemorySize(art, false);\n \t\tnew_node->prefix = std::move(n->prefix);\n-\t\tfor (idx_t i = 0; i < 256; i++) {\n+\n+\t\tfor (idx_t i = 0; i < Node256::GetSize(); i++) {\n \t\t\tif (n->children[i]) {\n \t\t\t\tnew_node->child_index[i] = new_node->count;\n-\t\t\t\tnew_node->children[new_node->count] = n->children[i];\n+\t\t\t\tnew_node->children[new_node->count++] = n->children[i];\n \t\t\t\tn->children[i] = nullptr;\n-\t\t\t\tnew_node->count++;\n \t\t\t}\n \t\t}\n+\n+\t\tD_ASSERT(art.memory_size >= node->MemorySize(art, false));\n+\t\tart.memory_size -= node->MemorySize(art, false);\n \t\tNode::Delete(node);\n \t\tnode = new_node;\n \t}\n }\n-\n-idx_t Node256::GetSize() {\n-\treturn 256;\n-}\n-\n } // namespace duckdb\ndiff --git a/src/execution/index/art/node4.cpp b/src/execution/index/art/node4.cpp\nindex e152d1a09e1c..af85280647b7 100644\n--- a/src/execution/index/art/node4.cpp\n+++ b/src/execution/index/art/node4.cpp\n@@ -1,7 +1,7 @@\n #include \"duckdb/execution/index/art/node4.hpp\"\n \n-#include \"duckdb/execution/index/art/node16.hpp\"\n #include \"duckdb/execution/index/art/art.hpp\"\n+#include \"duckdb/execution/index/art/node16.hpp\"\n #include \"duckdb/storage/meta_block_reader.hpp\"\n \n namespace duckdb {\n@@ -10,6 +10,13 @@ Node4::Node4() : Node(NodeType::N4) {\n \tmemset(key, 0, sizeof(key));\n }\n \n+idx_t Node4::MemorySize(ART &art, const bool &recurse) {\n+\tif (recurse) {\n+\t\treturn prefix.MemorySize() + sizeof(*this) + RecursiveMemorySize(art);\n+\t}\n+\treturn prefix.MemorySize() + sizeof(*this);\n+}\n+\n idx_t Node4::GetChildPos(uint8_t k) {\n \tfor (idx_t pos = 0; pos < count; pos++) {\n \t\tif (key[pos] == k) {\n@@ -67,12 +74,16 @@ void Node4::ReplaceChildPointer(idx_t pos, Node *node) {\n \tchildren[pos] = node;\n }\n \n-void Node4::InsertChild(Node *&node, uint8_t key_byte, Node *new_child) {\n+bool Node4::ChildIsInMemory(idx_t pos) {\n+\treturn children[pos] && !children[pos].IsSwizzled();\n+}\n+\n+void Node4::InsertChild(ART &art, Node *&node, uint8_t key_byte, Node *new_child) {\n \tNode4 *n = (Node4 *)node;\n \n-\t// Insert new child node into node\n-\tif (node->count < 4) {\n-\t\t// Insert element\n+\t// insert new child node into node\n+\tif (node->count < Node4::GetSize()) {\n+\t\t// still space, just insert the child\n \t\tidx_t pos = 0;\n \t\twhile ((pos < node->count) && (n->key[pos] < key_byte)) {\n \t\t\tpos++;\n@@ -86,52 +97,71 @@ void Node4::InsertChild(Node *&node, uint8_t key_byte, Node *new_child) {\n \t\tn->key[pos] = key_byte;\n \t\tn->children[pos] = new_child;\n \t\tn->count++;\n+\n \t} else {\n-\t\t// Grow to Node16\n+\t\t// node is full, grow to Node16\n \t\tauto new_node = Node16::New();\n-\t\tnew_node->count = 4;\n+\t\tart.memory_size += new_node->MemorySize(art, false);\n+\t\tnew_node->count = n->count;\n \t\tnew_node->prefix = std::move(node->prefix);\n-\t\tfor (idx_t i = 0; i < 4; i++) {\n+\n+\t\tfor (idx_t i = 0; i < n->count; i++) {\n \t\t\tnew_node->key[i] = n->key[i];\n \t\t\tnew_node->children[i] = n->children[i];\n \t\t\tn->children[i] = nullptr;\n \t\t}\n-\t\t// Delete old node and replace it with new Node16\n+\t\tn->count = 0;\n+\n+\t\tD_ASSERT(art.memory_size >= node->MemorySize(art, false));\n+\t\tart.memory_size -= node->MemorySize(art, false);\n \t\tNode::Delete(node);\n \t\tnode = new_node;\n-\t\tNode16::InsertChild(node, key_byte, new_child);\n+\t\tNode16::InsertChild(art, node, key_byte, new_child);\n \t}\n }\n \n-void Node4::EraseChild(Node *&node, int pos, ART &art) {\n+void Node4::EraseChild(ART &art, Node *&node, idx_t pos) {\n+\n \tNode4 *n = (Node4 *)node;\n \tD_ASSERT(pos < n->count);\n+\tD_ASSERT(n->count > 1);\n+\n+\t// adjust the ART size\n+\tif (n->ChildIsInMemory(pos)) {\n+\t\tauto child = n->GetChild(art, pos);\n+\t\tD_ASSERT(art.memory_size >= child->MemorySize(art, true));\n+\t\tart.memory_size -= child->MemorySize(art, true);\n+\t}\n+\n \t// erase the child and decrease the count\n \tn->children[pos].Reset();\n \tn->count--;\n+\tD_ASSERT(n->count >= 1);\n+\n \t// potentially move any children backwards\n \tfor (; pos < n->count; pos++) {\n \t\tn->key[pos] = n->key[pos + 1];\n \t\tn->children[pos] = n->children[pos + 1];\n \t}\n \t// set any remaining nodes as nullptr\n-\tfor (; pos < 4; pos++) {\n+\tfor (; pos < Node4::GetSize(); pos++) {\n \t\tn->children[pos] = nullptr;\n \t}\n \n-\t// This is a one way node\n+\t// this is a one way node, compress\n \tif (n->count == 1) {\n+\n+\t\t// get only child and concatenate prefixes\n \t\tauto child_ref = n->GetChild(art, 0);\n \t\t// concatenate prefixes\n-\t\tchild_ref->prefix.Concatenate(n->key[0], node->prefix);\n+\t\tchild_ref->prefix.Concatenate(art, n->key[0], node->prefix);\n+\t\t// ensure that when deleting the node, we do not delete the child (because we move it)\n \t\tn->children[0] = nullptr;\n+\n+\t\tD_ASSERT(art.memory_size >= n->MemorySize(art, false));\n+\t\tart.memory_size -= n->MemorySize(art, false);\n \t\tNode::Delete(node);\n \t\tnode = child_ref;\n \t}\n }\n-\n-idx_t Node4::GetSize() {\n-\treturn 4;\n-}\n-\n } // namespace duckdb\ndiff --git a/src/execution/index/art/node48.cpp b/src/execution/index/art/node48.cpp\nindex 35a8bbacc29e..33f04a2e90d5 100644\n--- a/src/execution/index/art/node48.cpp\n+++ b/src/execution/index/art/node48.cpp\n@@ -1,5 +1,6 @@\n #include \"duckdb/execution/index/art/node48.hpp\"\n \n+#include \"duckdb/execution/index/art/art.hpp\"\n #include \"duckdb/execution/index/art/node16.hpp\"\n #include \"duckdb/execution/index/art/node256.hpp\"\n \n@@ -11,6 +12,13 @@ Node48::Node48() : Node(NodeType::N48) {\n \t}\n }\n \n+idx_t Node48::MemorySize(ART &art, const bool &recurse) {\n+\tif (recurse) {\n+\t\treturn prefix.MemorySize() + sizeof(*this) + RecursiveMemorySize(art);\n+\t}\n+\treturn prefix.MemorySize() + sizeof(*this);\n+}\n+\n idx_t Node48::GetChildPos(uint8_t k) {\n \tif (child_index[k] == Node::EMPTY_MARKER) {\n \t\treturn DConstants::INVALID_INDEX;\n@@ -20,7 +28,7 @@ idx_t Node48::GetChildPos(uint8_t k) {\n }\n \n idx_t Node48::GetChildGreaterEqual(uint8_t k, bool &equal) {\n-\tfor (idx_t pos = k; pos < 256; pos++) {\n+\tfor (idx_t pos = k; pos < Node256::GetSize(); pos++) {\n \t\tif (child_index[pos] != Node::EMPTY_MARKER) {\n \t\t\tif (pos == k) {\n \t\t\t\tequal = true;\n@@ -34,7 +42,7 @@ idx_t Node48::GetChildGreaterEqual(uint8_t k, bool &equal) {\n }\n \n idx_t Node48::GetMin() {\n-\tfor (idx_t i = 0; i < 256; i++) {\n+\tfor (idx_t i = 0; i < Node256::GetSize(); i++) {\n \t\tif (child_index[i] != Node::EMPTY_MARKER) {\n \t\t\treturn i;\n \t\t}\n@@ -43,7 +51,8 @@ idx_t Node48::GetMin() {\n }\n \n idx_t Node48::GetNextPos(idx_t pos) {\n-\tfor (pos == DConstants::INVALID_INDEX ? pos = 0 : pos++; pos < 256; pos++) {\n+\tpos == DConstants::INVALID_INDEX ? pos = 0 : pos++;\n+\tfor (; pos < Node256::GetSize(); pos++) {\n \t\tif (child_index[pos] != Node::EMPTY_MARKER) {\n \t\t\treturn pos;\n \t\t}\n@@ -52,7 +61,8 @@ idx_t Node48::GetNextPos(idx_t pos) {\n }\n \n idx_t Node48::GetNextPosAndByte(idx_t pos, uint8_t &byte) {\n-\tfor (pos == DConstants::INVALID_INDEX ? pos = 0 : pos++; pos < 256; pos++) {\n+\tpos == DConstants::INVALID_INDEX ? pos = 0 : pos++;\n+\tfor (; pos < Node256::GetSize(); pos++) {\n \t\tif (child_index[pos] != Node::EMPTY_MARKER) {\n \t\t\tbyte = uint8_t(pos);\n \t\t\treturn pos;\n@@ -70,12 +80,16 @@ void Node48::ReplaceChildPointer(idx_t pos, Node *node) {\n \tchildren[child_index[pos]] = node;\n }\n \n-void Node48::InsertChild(Node *&node, uint8_t key_byte, Node *new_child) {\n+bool Node48::ChildIsInMemory(idx_t pos) {\n+\treturn children[child_index[pos]] && !children[child_index[pos]].IsSwizzled();\n+}\n+\n+void Node48::InsertChild(ART &art, Node *&node, uint8_t key_byte, Node *new_child) {\n \tauto n = (Node48 *)node;\n \n-\t// Insert new child node into node\n-\tif (node->count < 48) {\n-\t\t// Insert element\n+\t// insert new child node into node\n+\tif (node->count < Node48::GetSize()) {\n+\t\t// still space, just insert the child\n \t\tidx_t pos = n->count;\n \t\tif (n->children[pos]) {\n \t\t\t// find an empty position in the node list if the current position is occupied\n@@ -87,45 +101,63 @@ void Node48::InsertChild(Node *&node, uint8_t key_byte, Node *new_child) {\n \t\tn->children[pos] = new_child;\n \t\tn->child_index[key_byte] = pos;\n \t\tn->count++;\n+\n \t} else {\n-\t\t// Grow to Node256\n+\t\t// node is full, grow to Node256\n \t\tauto new_node = Node256::New();\n-\t\tfor (idx_t i = 0; i < 256; i++) {\n+\t\tart.memory_size += new_node->MemorySize(art, false);\n+\t\tnew_node->count = n->count;\n+\t\tnew_node->prefix = std::move(n->prefix);\n+\n+\t\tfor (idx_t i = 0; i < Node256::GetSize(); i++) {\n \t\t\tif (n->child_index[i] != Node::EMPTY_MARKER) {\n \t\t\t\tnew_node->children[i] = n->children[n->child_index[i]];\n \t\t\t\tn->children[n->child_index[i]] = nullptr;\n \t\t\t}\n \t\t}\n-\t\tnew_node->count = n->count;\n-\t\tnew_node->prefix = std::move(n->prefix);\n+\n+\t\tD_ASSERT(art.memory_size >= node->MemorySize(art, false));\n+\t\tart.memory_size -= node->MemorySize(art, false);\n \t\tNode::Delete(node);\n \t\tnode = new_node;\n-\t\tNode256::InsertChild(node, key_byte, new_child);\n+\t\tNode256::InsertChild(art, node, key_byte, new_child);\n \t}\n }\n \n-void Node48::EraseChild(Node *&node, int pos, ART &art) {\n+void Node48::EraseChild(ART &art, Node *&node, idx_t pos) {\n \tauto n = (Node48 *)(node);\n+\n+\t// adjust the ART size\n+\tif (n->ChildIsInMemory(pos)) {\n+\t\tauto child = n->GetChild(art, pos);\n+\t\tD_ASSERT(art.memory_size >= child->MemorySize(art, true));\n+\t\tart.memory_size -= child->MemorySize(art, true);\n+\t}\n+\n+\t// erase the child and decrease the count\n \tn->children[n->child_index[pos]].Reset();\n \tn->child_index[pos] = Node::EMPTY_MARKER;\n \tn->count--;\n-\tif (node->count <= 12) {\n+\n+\t// shrink node to Node16\n+\tif (node->count < NODE_48_SHRINK_THRESHOLD) {\n+\n \t\tauto new_node = Node16::New();\n+\t\tart.memory_size += new_node->MemorySize(art, false);\n \t\tnew_node->prefix = std::move(n->prefix);\n-\t\tfor (idx_t i = 0; i < 256; i++) {\n+\n+\t\tfor (idx_t i = 0; i < Node256::GetSize(); i++) {\n \t\t\tif (n->child_index[i] != Node::EMPTY_MARKER) {\n \t\t\t\tnew_node->key[new_node->count] = i;\n \t\t\t\tnew_node->children[new_node->count++] = n->children[n->child_index[i]];\n \t\t\t\tn->children[n->child_index[i]] = nullptr;\n \t\t\t}\n \t\t}\n+\n+\t\tD_ASSERT(art.memory_size >= node->MemorySize(art, false));\n+\t\tart.memory_size -= node->MemorySize(art, false);\n \t\tNode::Delete(node);\n \t\tnode = new_node;\n \t}\n }\n-\n-idx_t Node48::GetSize() {\n-\treturn 48;\n-}\n-\n } // namespace duckdb\ndiff --git a/src/execution/index/art/prefix.cpp b/src/execution/index/art/prefix.cpp\nindex 108cc5663127..2c3217bacd5a 100644\n--- a/src/execution/index/art/prefix.cpp\n+++ b/src/execution/index/art/prefix.cpp\n@@ -1,5 +1,7 @@\n #include \"duckdb/execution/index/art/prefix.hpp\"\n \n+#include \"duckdb/execution/index/art/art.hpp\"\n+\n namespace duckdb {\n \n bool Prefix::IsInlined() const {\n@@ -56,6 +58,10 @@ Prefix::~Prefix() {\n \tDestroy();\n }\n \n+idx_t Prefix::MemorySize() {\n+\treturn sizeof(*this) + sizeof(uint8_t) * size;\n+}\n+\n void Prefix::Destroy() {\n \tif (!IsInlined()) {\n \t\tDeleteArray<uint8_t>(value.ptr, size);\n@@ -95,6 +101,7 @@ void Prefix::Overwrite(uint32_t new_size, uint8_t *data) {\n \t\t\tprefix[i] = data[i];\n \t\t}\n \t\tDeleteArray<uint8_t>(data, new_size);\n+\n \t} else {\n \t\t// new entry would not be inlined\n \t\t// take over the data directly\n@@ -104,40 +111,47 @@ void Prefix::Overwrite(uint32_t new_size, uint8_t *data) {\n \t}\n }\n \n-void Prefix::Concatenate(uint8_t key, Prefix &other) {\n-\tauto new_length = size + 1 + other.size;\n+void Prefix::Concatenate(ART &art, uint8_t key, Prefix &other) {\n+\tauto new_size = size + 1 + other.size;\n+\tart.memory_size += (new_size - size) * sizeof(uint8_t);\n \t// have to allocate space in our prefix array\n-\tauto new_prefix = AllocateArray<uint8_t>(new_length);\n+\tauto new_prefix = AllocateArray<uint8_t>(new_size);\n \tidx_t new_prefix_idx = 0;\n+\n \t// 1) add the to-be deleted node's prefix\n \tfor (uint32_t i = 0; i < other.size; i++) {\n \t\tnew_prefix[new_prefix_idx++] = other[i];\n \t}\n-\t// 2) now move the current key as part of the prefix\n+\n+\t// 2) now move the current partial key byte as part of the prefix\n \tnew_prefix[new_prefix_idx++] = key;\n+\n \t// 3) move the existing prefix (if any)\n \tauto prefix = GetPrefixData();\n \tfor (uint32_t i = 0; i < size; i++) {\n \t\tnew_prefix[new_prefix_idx++] = prefix[i];\n \t}\n-\tOverwrite(new_length, new_prefix);\n+\tOverwrite(new_size, new_prefix);\n }\n \n-uint8_t Prefix::Reduce(uint32_t n) {\n+uint8_t Prefix::Reduce(ART &art, uint32_t n) {\n \tauto new_size = size - n - 1;\n+\tD_ASSERT(art.memory_size >= (size - new_size) * sizeof(uint8_t));\n+\tart.memory_size -= (size - new_size) * sizeof(uint8_t);\n \tauto prefix = GetPrefixData();\n-\tauto key = prefix[n];\n+\tauto partial_key = prefix[n];\n+\n \tif (new_size == 0) {\n \t\tDestroy();\n \t\tsize = 0;\n-\t\treturn key;\n+\t\treturn partial_key;\n \t}\n \tauto new_prefix = AllocateArray<uint8_t>(new_size);\n \tfor (idx_t i = 0; i < new_size; i++) {\n \t\tnew_prefix[i] = prefix[i + n + 1];\n \t}\n \tOverwrite(new_size, new_prefix);\n-\treturn key;\n+\treturn partial_key;\n }\n \n void Prefix::Serialize(duckdb::MetaBlockWriter &writer) {\n@@ -153,7 +167,7 @@ void Prefix::Deserialize(duckdb::MetaBlockReader &reader) {\n \treader.ReadData(prefix, size);\n }\n \n-uint32_t Prefix::KeyMismatchPosition(Key &key, uint64_t depth) {\n+uint32_t Prefix::KeyMismatchPosition(Key &key, uint32_t depth) {\n \tuint64_t pos;\n \tauto prefix = GetPrefixData();\n \tfor (pos = 0; pos < size; pos++) {\ndiff --git a/src/execution/index/art/swizzleable_pointer.cpp b/src/execution/index/art/swizzleable_pointer.cpp\nindex 49c3d095d398..9b17e3dfbcda 100644\n--- a/src/execution/index/art/swizzleable_pointer.cpp\n+++ b/src/execution/index/art/swizzleable_pointer.cpp\n@@ -1,5 +1,7 @@\n #include \"duckdb/execution/index/art/swizzleable_pointer.hpp\"\n \n+#include \"duckdb/execution/index/art/art.hpp\"\n+\n namespace duckdb {\n SwizzleablePointer::~SwizzleablePointer() {\n \tif (pointer) {\n@@ -78,6 +80,7 @@ Node *SwizzleablePointer::Unswizzle(ART &art) {\n \t\t// first we unset the bae\n \t\tauto block_info = GetSwizzledBlockInfo();\n \t\t*this = Node::Deserialize(art, block_info.block_id, block_info.offset);\n+\t\tart.Verify();\n \t}\n \treturn (Node *)pointer;\n }\ndiff --git a/src/execution/operator/schema/physical_create_index.cpp b/src/execution/operator/schema/physical_create_index.cpp\nindex 3ea42a11e135..e8b9e016e808 100644\n--- a/src/execution/operator/schema/physical_create_index.cpp\n+++ b/src/execution/operator/schema/physical_create_index.cpp\n@@ -35,7 +35,7 @@ unique_ptr<GlobalSinkState> PhysicalCreateIndex::GetGlobalSinkState(ClientContex\n \tswitch (info->index_type) {\n \tcase IndexType::ART: {\n \t\tstate->global_index = make_unique<ART>(storage_ids, TableIOManager::Get(*table.storage), unbound_expressions,\n-\t\t                                       info->constraint_type, table.storage->db);\n+\t\t                                       info->constraint_type, table.storage->db, true);\n \t\tbreak;\n \t}\n \tdefault:\n@@ -52,7 +52,7 @@ unique_ptr<LocalSinkState> PhysicalCreateIndex::GetLocalSinkState(ExecutionConte\n \tswitch (info->index_type) {\n \tcase IndexType::ART: {\n \t\tstate->local_index = make_unique<ART>(storage_ids, TableIOManager::Get(*table.storage), unbound_expressions,\n-\t\t                                      info->constraint_type, table.storage->db);\n+\t\t                                      info->constraint_type, table.storage->db, false);\n \t\tbreak;\n \t}\n \tdefault:\n@@ -81,16 +81,12 @@ SinkResultType PhysicalCreateIndex::Sink(ExecutionContext &context, GlobalSinkSt\n \n \tauto art = make_unique<ART>(lstate.local_index->column_ids, lstate.local_index->table_io_manager,\n \t                            lstate.local_index->unbound_expressions, lstate.local_index->constraint_type,\n-\t                            table.storage->db);\n+\t                            table.storage->db, false);\n \tart->ConstructFromSorted(lstate.key_chunk.size(), lstate.keys, row_identifiers);\n \n \t// merge into the local ART\n-\t{\n-\t\tIndexLock local_lock;\n-\t\tlstate.local_index->InitializeLock(local_lock);\n-\t\tif (!lstate.local_index->MergeIndexes(local_lock, art.get())) {\n-\t\t\tthrow ConstraintException(\"Data contains duplicates on indexed column(s)\");\n-\t\t}\n+\tif (!lstate.local_index->MergeIndexes(art.get())) {\n+\t\tthrow ConstraintException(\"Data contains duplicates on indexed column(s)\");\n \t}\n \treturn SinkResultType::NEED_MORE_INPUT;\n }\n@@ -102,7 +98,9 @@ void PhysicalCreateIndex::Combine(ExecutionContext &context, GlobalSinkState &gs\n \tauto &lstate = (CreateIndexLocalSinkState &)lstate_p;\n \n \t// merge the local index into the global index\n-\tgstate.global_index->MergeIndexes(lstate.local_index.get());\n+\tif (!gstate.global_index->MergeIndexes(lstate.local_index.get())) {\n+\t\tthrow ConstraintException(\"Data contains duplicates on indexed column(s)\");\n+\t}\n }\n \n SinkFinalizeType PhysicalCreateIndex::Finalize(Pipeline &pipeline, Event &event, ClientContext &context,\n@@ -111,11 +109,15 @@ SinkFinalizeType PhysicalCreateIndex::Finalize(Pipeline &pipeline, Event &event,\n \t// here, we just set the resulting global index as the newly created index of the table\n \n \tauto &state = (CreateIndexGlobalSinkState &)gstate_p;\n-\n \tif (!table.storage->IsRoot()) {\n \t\tthrow TransactionException(\"Transaction conflict: cannot add an index to a table that has been altered!\");\n \t}\n \n+\tstate.global_index->Verify();\n+\tif (state.global_index->track_memory) {\n+\t\tstate.global_index->buffer_manager.IncreaseUsedMemory(state.global_index->memory_size);\n+\t}\n+\n \tauto &schema = *table.schema;\n \tauto index_entry = (IndexCatalogEntry *)schema.CreateIndex(context, info.get(), &table);\n \tif (!index_entry) {\ndiff --git a/src/execution/physical_plan/plan_create_index.cpp b/src/execution/physical_plan/plan_create_index.cpp\nindex c38d087f5773..a2767c33282b 100644\n--- a/src/execution/physical_plan/plan_create_index.cpp\n+++ b/src/execution/physical_plan/plan_create_index.cpp\n@@ -24,11 +24,9 @@ unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalCreateInde\n \t// because they make deletions and lookups unfeasible\n \tfor (idx_t i = 0; i < op.unbound_expressions.size(); i++) {\n \t\tauto &expr = op.unbound_expressions[i];\n-\t\tif (expr->expression_class == ExpressionClass::BOUND_FUNCTION) {\n-\t\t\tauto &func_expr = (BoundFunctionExpression &)*expr;\n-\t\t\tif (func_expr.function.side_effects == FunctionSideEffects::HAS_SIDE_EFFECTS) {\n-\t\t\t\tthrow BinderException(\"Index keys cannot contain the \\\"%s\\\" function.\", func_expr.function.name);\n-\t\t\t}\n+\t\tif (expr->HasSideEffects()) {\n+\t\t\tthrow BinderException(\"Index keys cannot contain expressions with side \"\n+\t\t\t                      \"effects.\");\n \t\t}\n \t}\n \ndiff --git a/src/include/duckdb/execution/index/art/art.hpp b/src/include/duckdb/execution/index/art/art.hpp\nindex 1facefec2994..8202ecaf0bc0 100644\n--- a/src/include/duckdb/execution/index/art/art.hpp\n+++ b/src/include/duckdb/execution/index/art/art.hpp\n@@ -54,14 +54,12 @@ class ART : public Index {\n \t//! Constructs an ART containing the bound expressions, which are resolved during index construction\n \tART(const vector<column_t> &column_ids, TableIOManager &table_io_manager,\n \t    const vector<unique_ptr<Expression>> &unbound_expressions, IndexConstraintType constraint_type,\n-\t    AttachedDatabase &db, idx_t block_id = DConstants::INVALID_INDEX,\n+\t    AttachedDatabase &db, bool track_memory, idx_t block_id = DConstants::INVALID_INDEX,\n \t    idx_t block_offset = DConstants::INVALID_INDEX);\n \t~ART() override;\n \n \t//! Root of the tree\n \tNode *tree;\n-\t//! Attached database\n-\tAttachedDatabase &db;\n \n public:\n \t//! Initialize a scan on the index with the given expression and column ids\n@@ -90,9 +88,10 @@ class ART : public Index {\n \tvoid VerifyDeleteForeignKey(DataChunk &chunk) override;\n \t//! Delete entries in the index\n \tvoid Delete(IndexLock &lock, DataChunk &entries, Vector &row_identifiers) override;\n-\t//! Insert data into the index.\n+\t//! Insert data into the index\n \tbool Insert(IndexLock &lock, DataChunk &data, Vector &row_ids) override;\n \n+\t//! Construct an ART from a vector of sorted keys\n \tvoid ConstructFromSorted(idx_t count, vector<Key> &keys, Vector &row_identifiers);\n \n \t//! Search Equal and fetches the row IDs\n@@ -106,12 +105,17 @@ class ART : public Index {\n \tbool MergeIndexes(IndexLock &state, Index *other_index) override;\n \t//! Generate ART keys for an input chunk\n \tstatic void GenerateKeys(ArenaAllocator &allocator, DataChunk &input, vector<Key> &keys);\n-\t//! Returns the string representation of an ART\n-\tstring ToString() override;\n \n+\t//! Generate a string containing all the expressions and their respective values that violate a constraint\n \tstring GenerateErrorKeyName(DataChunk &input, idx_t row);\n+\t//! Generate the matching error message for a constraint violation\n \tstring GenerateConstraintErrorMessage(VerifyExistenceType verify_type, const string &key_name);\n \n+\t//! Returns the string representation of an ART\n+\tstring ToString() override;\n+\t//! Verifies that the memory_size value of the ART matches its actual size\n+\tvoid Verify() override;\n+\n private:\n \t//! Insert a row id into a leaf node\n \tbool InsertToLeaf(Leaf &leaf, row_t row_id);\n@@ -132,12 +136,6 @@ class ART : public Index {\n \t                vector<row_t> &result_ids);\n \tbool SearchCloseRange(ARTIndexScanState *state, Key &lower_bound, Key &upper_bound, bool left_inclusive,\n \t                      bool right_inclusive, idx_t max_count, vector<row_t> &result_ids);\n-\n-private:\n-\t//! The estimated ART memory consumption\n-\tidx_t estimated_art_size;\n-\t//! The estimated memory consumption of a single key\n-\tidx_t estimated_key_size;\n };\n \n } // namespace duckdb\ndiff --git a/src/include/duckdb/execution/index/art/leaf.hpp b/src/include/duckdb/execution/index/art/leaf.hpp\nindex 4160f1bde169..b94c433c45de 100644\n--- a/src/include/duckdb/execution/index/art/leaf.hpp\n+++ b/src/include/duckdb/execution/index/art/leaf.hpp\n@@ -15,36 +15,45 @@ namespace duckdb {\n \n class Leaf : public Node {\n public:\n+\texplicit Leaf();\n \tLeaf(Key &value, uint32_t depth, row_t row_id);\n \tLeaf(Key &value, uint32_t depth, row_t *row_ids, idx_t num_elements);\n \tLeaf(row_t *row_ids, idx_t num_elements, Prefix &prefix);\n \tLeaf(row_t row_id, Prefix &prefix);\n \t~Leaf();\n \n-\trow_t GetRowId(idx_t index);\n+\t//! Get the row ID at idx\n+\trow_t GetRowId(idx_t idx);\n+\t//! Get the maximum capacity of the leaf, must not match with its count\n \tidx_t GetCapacity() const;\n+\t//! Returns whether a leaf holds exactly one inlined row ID or multiple row IDs\n \tbool IsInlined() const;\n+\t//! Returns a pointer to all row IDs of the leaf\n \trow_t *GetRowIds();\n \n public:\n+\tstatic Leaf *New();\n \tstatic Leaf *New(Key &value, uint32_t depth, row_t row_id);\n \tstatic Leaf *New(Key &value, uint32_t depth, row_t *row_ids, idx_t num_elements);\n \tstatic Leaf *New(row_t *row_ids, idx_t num_elements, Prefix &prefix);\n \tstatic Leaf *New(row_t row_id, Prefix &prefix);\n-\t//! Insert a row_id into a leaf\n-\tvoid Insert(row_t row_id);\n-\t//! Remove a row_id from a leaf\n-\tvoid Remove(row_t row_id);\n+\n+\t//! Returns the memory size of the leaf\n+\tidx_t MemorySize(ART &art, const bool &recurse) override;\n+\t//! Insert a row ID into a leaf\n+\tvoid Insert(ART &art, row_t row_id);\n+\t//! Remove a row ID from a leaf\n+\tvoid Remove(ART &art, row_t row_id);\n \n \t//! Returns the string representation of a leaf\n \tstatic string ToString(Node *node);\n \t//! Merge two NLeaf nodes\n-\tstatic void Merge(Node *&l_node, Node *&r_node);\n+\tstatic void Merge(ART &art, Node *&l_node, Node *&r_node);\n \n \t//! Serialize a leaf\n \tBlockPointer Serialize(duckdb::MetaBlockWriter &writer);\n-\t// Deserialize a leaf\n-\tstatic Leaf *Deserialize(duckdb::MetaBlockReader &reader);\n+\t//! Deserialize a leaf\n+\tvoid Deserialize(ART &art, duckdb::MetaBlockReader &reader);\n \n private:\n \tunion {\ndiff --git a/src/include/duckdb/execution/index/art/node.hpp b/src/include/duckdb/execution/index/art/node.hpp\nindex 8dce65e49bda..2f08cd209b91 100644\n--- a/src/include/duckdb/execution/index/art/node.hpp\n+++ b/src/include/duckdb/execution/index/art/node.hpp\n@@ -37,10 +37,12 @@ struct InternalType {\n };\n \n struct MergeInfo {\n-\tMergeInfo(ART *l_art, ART *r_art, Node *&l_node, Node *&r_node)\n-\t    : l_art(l_art), r_art(r_art), l_node(l_node), r_node(r_node) {};\n+\tMergeInfo(ART *l_art, ART *r_art, ART *root_l_art, ART *root_r_art, Node *&l_node, Node *&r_node)\n+\t    : l_art(l_art), r_art(r_art), root_l_art(root_l_art), root_r_art(root_r_art), l_node(l_node), r_node(r_node) {};\n \tART *l_art;\n \tART *r_art;\n+\tART *root_l_art;\n+\tART *root_r_art;\n \tNode *&l_node;\n \tNode *&r_node;\n };\n@@ -57,6 +59,8 @@ struct ParentsOfNodes {\n class Node {\n public:\n \tstatic const uint8_t EMPTY_MARKER = 48;\n+\tstatic const uint8_t NODE_48_SHRINK_THRESHOLD = 12;\n+\tstatic const uint8_t NODE_256_SHRINK_THRESHOLD = 36;\n \n public:\n \texplicit Node(NodeType type);\n@@ -71,6 +75,8 @@ class Node {\n \tPrefix prefix;\n \n \tstatic void Delete(Node *node);\n+\t//! Returns the memory size of the node\n+\tvirtual idx_t MemorySize(ART &art, const bool &recurse);\n \t//! Get the position of a child corresponding exactly to the specific byte, returns DConstants::INVALID_INDEX if not\n \t//! exists\n \tvirtual idx_t GetChildPos(uint8_t k) {\n@@ -98,20 +104,24 @@ class Node {\n \tvirtual Node *GetChild(ART &art, idx_t pos);\n \t//! Replaces the pointer to a child node\n \tvirtual void ReplaceChildPointer(idx_t pos, Node *node);\n+\t//! Returns whether the child at pos is in memory\n+\tvirtual bool ChildIsInMemory(idx_t pos);\n \n \t//! Insert a new child node at key_byte into the node\n-\tstatic void InsertChild(Node *&node, uint8_t key_byte, Node *new_child);\n+\tstatic void InsertChild(ART &art, Node *&node, uint8_t key_byte, Node *new_child);\n \t//! Erase child node entry from node\n-\tstatic void EraseChild(Node *&node, idx_t pos, ART &art);\n+\tstatic void EraseChild(ART &art, Node *&node, idx_t pos);\n \t//! Get the corresponding node type for the provided size\n \tstatic NodeType GetTypeBySize(idx_t size);\n \t//! Create a new node of the specified type\n-\tstatic void New(NodeType &type, Node *&node);\n+\tstatic void New(const NodeType &type, Node *&node);\n \n \t//! Returns the string representation of a node\n \tstring ToString(ART &art);\n \t//! Serialize this node\n \tBlockPointer Serialize(ART &art, duckdb::MetaBlockWriter &writer);\n+\t//! Returns the memory size of the node\n+\tidx_t RecursiveMemorySize(ART &art);\n \n \t//! Deserialize this node\n \tstatic Node *Deserialize(ART &art, idx_t block_id, idx_t offset);\n@@ -122,7 +132,7 @@ class Node {\n \t//! Serialize internal nodes\n \tBlockPointer SerializeInternal(ART &art, duckdb::MetaBlockWriter &writer, InternalType &internal_type);\n \t//! Deserialize internal nodes\n-\tvoid DeserializeInternal(duckdb::MetaBlockReader &reader);\n+\tvoid DeserializeInternal(ART &art, duckdb::MetaBlockReader &reader);\n };\n \n } // namespace duckdb\ndiff --git a/src/include/duckdb/execution/index/art/node16.hpp b/src/include/duckdb/execution/index/art/node16.hpp\nindex dd55c48e6d47..ae958ad175b7 100644\n--- a/src/include/duckdb/execution/index/art/node16.hpp\n+++ b/src/include/duckdb/execution/index/art/node16.hpp\n@@ -14,12 +14,17 @@ namespace duckdb {\n \n class Node16 : public Node {\n public:\n+\t//! Empty Node16\n \texplicit Node16();\n+\t//! Array containing all partial key bytes\n \tuint8_t key[16];\n+\t//! ART pointers to the child nodes\n \tARTPointer children[16];\n \n public:\n \tstatic Node16 *New();\n+\t//! Returns the memory size of the Node16\n+\tidx_t MemorySize(ART &art, const bool &recurse) override;\n \t//! Get position of a specific byte, returns DConstants::INVALID_INDEX if not exists\n \tidx_t GetChildPos(uint8_t k) override;\n \t//! Get the position of the first child that is greater or equal to the specific byte, or DConstants::INVALID_INDEX\n@@ -35,12 +40,17 @@ class Node16 : public Node {\n \tNode *GetChild(ART &art, idx_t pos) override;\n \t//! Replace child pointer\n \tvoid ReplaceChildPointer(idx_t pos, Node *node) override;\n+\t//! Returns whether the child at pos is in memory\n+\tbool ChildIsInMemory(idx_t pos) override;\n \n \t//! Insert a new child node at key_byte into the Node16\n-\tstatic void InsertChild(Node *&node, uint8_t key_byte, Node *new_child);\n+\tstatic void InsertChild(ART &art, Node *&node, uint8_t key_byte, Node *new_child);\n \t//! Erase the child at pos and (if necessary) shrink to Node4\n-\tstatic void EraseChild(Node *&node, int pos, ART &art);\n+\tstatic void EraseChild(ART &art, Node *&node, idx_t pos);\n+\n \t//! Returns the size (maximum capacity) of the Node16\n-\tstatic idx_t GetSize();\n+\tstatic constexpr idx_t GetSize() {\n+\t\treturn 16;\n+\t}\n };\n } // namespace duckdb\ndiff --git a/src/include/duckdb/execution/index/art/node256.hpp b/src/include/duckdb/execution/index/art/node256.hpp\nindex 7e6d7f366df7..80347147c7e8 100644\n--- a/src/include/duckdb/execution/index/art/node256.hpp\n+++ b/src/include/duckdb/execution/index/art/node256.hpp\n@@ -14,11 +14,15 @@ namespace duckdb {\n \n class Node256 : public Node {\n public:\n+\t//! Empty Node256\n \texplicit Node256();\n+\t//! ART pointers to the child nodes\n \tARTPointer children[256];\n \n public:\n \tstatic Node256 *New();\n+\t//! Returns the memory size of the Node256\n+\tidx_t MemorySize(ART &art, const bool &recurse) override;\n \t//! Get position of a specific byte, returns DConstants::INVALID_INDEX if not exists\n \tidx_t GetChildPos(uint8_t k) override;\n \t//! Get the position of the first child that is greater or equal to the specific byte, or DConstants::INVALID_INDEX\n@@ -34,12 +38,17 @@ class Node256 : public Node {\n \tNode *GetChild(ART &art, idx_t pos) override;\n \t//! Replace child pointer\n \tvoid ReplaceChildPointer(idx_t pos, Node *node) override;\n+\t//! Returns whether the child at pos is in memory\n+\tbool ChildIsInMemory(idx_t pos) override;\n \n \t//! Insert a new child node at key_byte into the Node256\n-\tstatic void InsertChild(Node *&node, uint8_t key_byte, Node *new_child);\n+\tstatic void InsertChild(ART &art, Node *&node, uint8_t key_byte, Node *new_child);\n \t//! Erase the child at pos and (if necessary) shrink to Node48\n-\tstatic void EraseChild(Node *&node, int pos, ART &art);\n+\tstatic void EraseChild(ART &art, Node *&node, idx_t pos);\n+\n \t//! Returns the size (maximum capacity) of the Node256\n-\tstatic idx_t GetSize();\n+\tstatic constexpr idx_t GetSize() {\n+\t\treturn 256;\n+\t}\n };\n } // namespace duckdb\ndiff --git a/src/include/duckdb/execution/index/art/node4.hpp b/src/include/duckdb/execution/index/art/node4.hpp\nindex 4edca4f6ba26..6f47b50ada47 100644\n--- a/src/include/duckdb/execution/index/art/node4.hpp\n+++ b/src/include/duckdb/execution/index/art/node4.hpp\n@@ -14,14 +14,17 @@ namespace duckdb {\n \n class Node4 : public Node {\n public:\n-\tNode4();\n-\n+\t//! Empty Node4\n+\texplicit Node4();\n+\t//! Array containing all partial key bytes\n \tuint8_t key[4];\n-\t// Pointers to the child nodes\n+\t//! ART pointers to the child nodes\n \tARTPointer children[4];\n \n public:\n \tstatic Node4 *New();\n+\t//! Returns the memory size of the Node4\n+\tidx_t MemorySize(ART &art, const bool &recurse) override;\n \t//! Get position of a byte, returns DConstants::INVALID_INDEX if not exists\n \tidx_t GetChildPos(uint8_t k) override;\n \t//! Get the position of the first child that is greater or equal to the specific byte, or DConstants::INVALID_INDEX\n@@ -37,12 +40,17 @@ class Node4 : public Node {\n \tNode *GetChild(ART &art, idx_t pos) override;\n \t//! Replace child pointer\n \tvoid ReplaceChildPointer(idx_t pos, Node *node) override;\n+\t//! Returns whether the child at pos is in memory\n+\tbool ChildIsInMemory(idx_t pos) override;\n \n \t//! Insert a new child node at key_byte into the Node4\n-\tstatic void InsertChild(Node *&node, uint8_t key_byte, Node *new_child);\n+\tstatic void InsertChild(ART &art, Node *&node, uint8_t key_byte, Node *new_child);\n \t//! Erase the child at pos and (if necessary) merge with last child\n-\tstatic void EraseChild(Node *&node, int pos, ART &art);\n+\tstatic void EraseChild(ART &art, Node *&node, idx_t pos);\n+\n \t//! Returns the size (maximum capacity) of the Node4\n-\tstatic idx_t GetSize();\n+\tstatic constexpr idx_t GetSize() {\n+\t\treturn 4;\n+\t}\n };\n } // namespace duckdb\ndiff --git a/src/include/duckdb/execution/index/art/node48.hpp b/src/include/duckdb/execution/index/art/node48.hpp\nindex e15bfc677d66..ba2b4f75012f 100644\n--- a/src/include/duckdb/execution/index/art/node48.hpp\n+++ b/src/include/duckdb/execution/index/art/node48.hpp\n@@ -14,12 +14,17 @@ namespace duckdb {\n \n class Node48 : public Node {\n public:\n+\t//! Empty Node48\n \texplicit Node48();\n+\t//! Array containing all possible partial key bytes, those not set have an EMPTY_MARKER\n \tuint8_t child_index[256];\n+\t//! ART pointers to the child nodes\n \tARTPointer children[48];\n \n public:\n \tstatic Node48 *New();\n+\t//! Returns the memory size of the Node48\n+\tidx_t MemorySize(ART &art, const bool &recurse) override;\n \t//! Get position of a specific byte, returns DConstants::INVALID_INDEX if not exists\n \tidx_t GetChildPos(uint8_t k) override;\n \t//! Get the position of the first child that is greater or equal to the specific byte, or DConstants::INVALID_INDEX\n@@ -35,12 +40,16 @@ class Node48 : public Node {\n \tNode *GetChild(ART &art, idx_t pos) override;\n \t//! Replace child pointer\n \tvoid ReplaceChildPointer(idx_t pos, Node *node) override;\n+\t//! Returns whether the child at pos is in memory\n+\tbool ChildIsInMemory(idx_t pos) override;\n \n \t//! Insert a new child node at key_byte into the Node48\n-\tstatic void InsertChild(Node *&node, uint8_t key_byte, Node *new_child);\n+\tstatic void InsertChild(ART &art, Node *&node, uint8_t key_byte, Node *new_child);\n \t//! Erase the child at pos and (if necessary) shrink to Node16\n-\tstatic void EraseChild(Node *&node, int pos, ART &art);\n+\tstatic void EraseChild(ART &art, Node *&node, idx_t pos);\n \t//! Returns the size (maximum capacity) of the Node48\n-\tstatic idx_t GetSize();\n+\tstatic constexpr idx_t GetSize() {\n+\t\treturn 48;\n+\t}\n };\n } // namespace duckdb\ndiff --git a/src/include/duckdb/execution/index/art/prefix.hpp b/src/include/duckdb/execution/index/art/prefix.hpp\nindex 8cdbd13a3bf9..cdb07a0f027c 100644\n--- a/src/include/duckdb/execution/index/art/prefix.hpp\n+++ b/src/include/duckdb/execution/index/art/prefix.hpp\n@@ -12,47 +12,51 @@\n #include \"duckdb/storage/meta_block_writer.hpp\"\n \n namespace duckdb {\n+class ART;\n+\n class Prefix {\n \tstatic constexpr idx_t PREFIX_INLINE_BYTES = 8;\n \n public:\n+\t//! Empty prefix\n \tPrefix();\n-\t// Prefix created from key starting on `depth`\n+\t//! Construct prefix from key starting at depth\n \tPrefix(Key &key, uint32_t depth, uint32_t size);\n-\t// Prefix created from other prefix up to size\n+\t//! Construct prefix from other prefix up to size\n \tPrefix(Prefix &other_prefix, uint32_t size);\n \t~Prefix();\n \n-\t//! Returns the Prefix's size\n+\t//! Returns the prefix size\n \tinline uint32_t Size() const {\n \t\treturn size;\n \t}\n-\t//! Return a pointer to the prefix data\n+\t//! Returns the memory size of the prefix\n+\tidx_t MemorySize();\n+\t//! Returns a pointer to the prefix data\n \tuint8_t *GetPrefixData();\n+\t//! Returns a const pointer to the prefix data\n \tconst uint8_t *GetPrefixData() const;\n \n-\t// Subscript operator\n+\t//! Subscript operator\n \tuint8_t &operator[](idx_t idx);\n-\n-\t// Assign operator\n+\t//! Assign operator\n \tPrefix &operator=(const Prefix &src);\n-\n-\t// Move operator\n+\t//! Move operator\n \tPrefix &operator=(Prefix &&other) noexcept;\n \n-\t// Concatenate Prefix with a key and another prefix\n-\t// Used when deleting a Node.\n-\t// other.prefix + key + this->Prefix\n-\tvoid Concatenate(uint8_t key, Prefix &other);\n-\t// Reduces the prefix in n elements, and returns what would be the first one as a key\n-\tuint8_t Reduce(uint32_t n);\n-\t// Serializes Prefix\n+\t//! Concatenate prefix with a partial key byte and another prefix: other.prefix + byte + this->prefix\n+\t//! Used when deleting a node\n+\tvoid Concatenate(ART &art, uint8_t key, Prefix &other);\n+\t//! Reduces the prefix in n bytes, and returns the new first byte\n+\tuint8_t Reduce(ART &art, uint32_t n);\n+\n+\t//! Serializes the prefix\n \tvoid Serialize(duckdb::MetaBlockWriter &writer);\n-\t// Deserializes Prefix\n+\t//! Deserializes the prefix\n \tvoid Deserialize(duckdb::MetaBlockReader &reader);\n \n-\t// Compare the key with the prefix of the node, return the position where it mismatches\n-\tuint32_t KeyMismatchPosition(Key &key, uint64_t depth);\n+\t//! Compare the key with the prefix of the node, return the position where they mismatch\n+\tuint32_t KeyMismatchPosition(Key &key, uint32_t depth);\n \t//! Compare this prefix to another prefix, return the position where they mismatch, or size otherwise\n \tuint32_t MismatchPosition(Prefix &other);\n \ndiff --git a/src/include/duckdb/execution/index/art/swizzleable_pointer.hpp b/src/include/duckdb/execution/index/art/swizzleable_pointer.hpp\nindex 482dfec40c5e..e52bb062e218 100644\n--- a/src/include/duckdb/execution/index/art/swizzleable_pointer.hpp\n+++ b/src/include/duckdb/execution/index/art/swizzleable_pointer.hpp\n@@ -27,6 +27,8 @@ class SwizzleablePointer {\n \t//! Transforms from Node* to uint64_t\n \tSwizzleablePointer &operator=(const Node *ptr);\n \n+\t//! Checks if pointer is swizzled\n+\tbool IsSwizzled();\n \t//! Unswizzle the pointer (if possible)\n \tNode *Unswizzle(ART &art);\n \n@@ -34,7 +36,7 @@ class SwizzleablePointer {\n \t\treturn pointer;\n \t}\n \n-\t//! Deletes the underlying object (if necessary) and set the pointer to null_ptr\n+\t//! Deletes the underlying object (if necessary) and set the pointer to nullptr\n \tvoid Reset();\n \n private:\n@@ -42,10 +44,8 @@ class SwizzleablePointer {\n \n \tfriend bool operator!=(const SwizzleablePointer &s_ptr, const uint64_t &ptr);\n \n-\t//! Extracts block info from swizzled pointer\n+\t//! Extracts the block info from swizzled pointer\n \tBlockPointer GetSwizzledBlockInfo();\n-\t//! Checks if pointer is swizzled\n-\tbool IsSwizzled();\n };\n \n } // namespace duckdb\ndiff --git a/src/include/duckdb/storage/buffer_manager.hpp b/src/include/duckdb/storage/buffer_manager.hpp\nindex 329650f8833f..eafb43c26dee 100644\n--- a/src/include/duckdb/storage/buffer_manager.hpp\n+++ b/src/include/duckdb/storage/buffer_manager.hpp\n@@ -61,13 +61,20 @@ class BufferManager {\n \tDUCKDB_API static BufferManager &GetBufferManager(DatabaseInstance &db);\n \tDUCKDB_API static BufferManager &GetBufferManager(AttachedDatabase &db);\n \n+\t//! Returns the currently allocated memory\n \tidx_t GetUsedMemory() {\n \t\treturn current_memory;\n \t}\n+\t//! Returns the maximum available memory\n \tidx_t GetMaxMemory() {\n \t\treturn maximum_memory;\n \t}\n \n+\t//! Increases the currently allocated memory, but the actual allocation does not go through the buffer manager\n+\tvoid IncreaseUsedMemory(idx_t size);\n+\t//! Decrease the currently allocated memory, but the actual deallocation does not go through the buffer manager\n+\tvoid DecreaseUsedMemory(idx_t size);\n+\n \tconst string &GetTemporaryDirectory() {\n \t\treturn temp_directory;\n \t}\ndiff --git a/src/include/duckdb/storage/index.hpp b/src/include/duckdb/storage/index.hpp\nindex 293f4dff4e95..bb14a260bce7 100644\n--- a/src/include/duckdb/storage/index.hpp\n+++ b/src/include/duckdb/storage/index.hpp\n@@ -31,8 +31,9 @@ struct IndexLock;\n //! The index is an abstract base class that serves as the basis for indexes\n class Index {\n public:\n-\tIndex(IndexType type, TableIOManager &table_io_manager, const vector<column_t> &column_ids,\n-\t      const vector<unique_ptr<Expression>> &unbound_expressions, IndexConstraintType constraint_type);\n+\tIndex(AttachedDatabase &db, IndexType type, TableIOManager &table_io_manager, const vector<column_t> &column_ids,\n+\t      const vector<unique_ptr<Expression>> &unbound_expressions, IndexConstraintType constraint_type,\n+\t      bool track_memory);\n \tvirtual ~Index() = default;\n \n \t//! The type of the index\n@@ -52,6 +53,16 @@ class Index {\n \t//! Index constraint type (primary key, foreign key, ...)\n \tIndexConstraintType constraint_type;\n \n+\t//! Attached database instance\n+\tAttachedDatabase &db;\n+\t//! Buffer manager of the database instance\n+\tBufferManager &buffer_manager;\n+\t//! The size of the index in memory\n+\t//! This does not track the size of the index meta information, but only allocated nodes and leaves\n+\tidx_t memory_size;\n+\t//! Flag determining if this index's size is tracked by the buffer manager\n+\tbool track_memory;\n+\n public:\n \t//! Initialize a scan on the index with the given expression and column ids\n \t//! to fetch from the base table when we only have one query predicate\n@@ -94,14 +105,14 @@ class Index {\n \n \t//! Returns the string representation of an index\n \tvirtual string ToString() = 0;\n+\t//! Verifies that the memory_size value of the index matches its actual size\n+\tvirtual void Verify() = 0;\n \n \t//! Returns true if the index is affected by updates on the specified column ids, and false otherwise\n \tbool IndexIsUpdated(const vector<PhysicalIndex> &column_ids) const;\n \n \t//! Returns how many of the input values were found in the 'input' chunk, with the option to also record what those\n-\t//! matches were\n-\t//  what row_ids those matches have\n-\t//  for this purpose, nulls count as a match, and are returned in 'null_count'\n+\t//! matches were. For this purpose, nulls count as a match, and are returned in 'null_count'\n \tvirtual void LookupValues(DataChunk &input, ConflictManager &conflict_manager) = 0;\n \n \t//! Returns unique flag\ndiff --git a/src/storage/buffer_manager.cpp b/src/storage/buffer_manager.cpp\nindex 0af01fe94f27..59701d0cbe51 100644\n--- a/src/storage/buffer_manager.cpp\n+++ b/src/storage/buffer_manager.cpp\n@@ -554,6 +554,18 @@ void BufferManager::SetLimit(idx_t limit) {\n \t}\n }\n \n+void BufferManager::IncreaseUsedMemory(idx_t size) {\n+\tif (current_memory + size > maximum_memory) {\n+\t\tthrow OutOfMemoryException(\"Failed to allocate data of size %lld%s\", size, InMemoryWarning());\n+\t}\n+\tcurrent_memory += size;\n+}\n+\n+void BufferManager::DecreaseUsedMemory(idx_t size) {\n+\tD_ASSERT(current_memory >= size);\n+\tcurrent_memory -= size;\n+}\n+\n //===--------------------------------------------------------------------===//\n // Temporary File Management\n //===--------------------------------------------------------------------===//\ndiff --git a/src/storage/checkpoint_manager.cpp b/src/storage/checkpoint_manager.cpp\nindex aaeba0588ed0..c4d052a32717 100644\n--- a/src/storage/checkpoint_manager.cpp\n+++ b/src/storage/checkpoint_manager.cpp\n@@ -381,7 +381,7 @@ void CheckpointReader::ReadIndex(ClientContext &context, MetaBlockReader &reader\n \tcase IndexType::ART: {\n \t\tauto art = make_unique<ART>(info->column_ids, TableIOManager::Get(*table_catalog->storage),\n \t\t                            std::move(unbound_expressions), info->constraint_type, table_catalog->storage->db,\n-\t\t                            root_block_id, root_offset);\n+\t\t                            true, root_block_id, root_offset);\n \t\tindex_catalog->index = art.get();\n \t\ttable_catalog->storage->info->indexes.AddIndex(std::move(art));\n \t\tbreak;\ndiff --git a/src/storage/index.cpp b/src/storage/index.cpp\nindex eb538851d04e..06be592b7bed 100644\n--- a/src/storage/index.cpp\n+++ b/src/storage/index.cpp\n@@ -8,10 +8,12 @@\n \n namespace duckdb {\n \n-Index::Index(IndexType type, TableIOManager &table_io_manager, const vector<column_t> &column_ids_p,\n-             const vector<unique_ptr<Expression>> &unbound_expressions, IndexConstraintType constraint_type_p)\n+Index::Index(AttachedDatabase &db, IndexType type, TableIOManager &table_io_manager,\n+             const vector<column_t> &column_ids_p, const vector<unique_ptr<Expression>> &unbound_expressions,\n+             IndexConstraintType constraint_type_p, bool track_memory)\n \n-    : type(type), table_io_manager(table_io_manager), column_ids(column_ids_p), constraint_type(constraint_type_p) {\n+    : type(type), table_io_manager(table_io_manager), column_ids(column_ids_p), constraint_type(constraint_type_p),\n+      db(db), buffer_manager(BufferManager::GetBufferManager(db)), memory_size(0), track_memory(track_memory) {\n \n \tfor (auto &expr : unbound_expressions) {\n \t\ttypes.push_back(expr->return_type.InternalType());\n@@ -23,6 +25,8 @@ Index::Index(IndexType type, TableIOManager &table_io_manager, const vector<colu\n \tfor (auto &bound_expr : bound_expressions) {\n \t\texecutor.AddExpression(*bound_expr);\n \t}\n+\n+\t// create the column id set\n \tfor (auto column_id : column_ids) {\n \t\tcolumn_id_set.insert(column_id);\n \t}\ndiff --git a/src/storage/local_storage.cpp b/src/storage/local_storage.cpp\nindex cb4914411ca3..aca6d7929aed 100644\n--- a/src/storage/local_storage.cpp\n+++ b/src/storage/local_storage.cpp\n@@ -127,7 +127,7 @@ LocalTableStorage::LocalTableStorage(DataTable &table)\n \t\t\t\tunbound_expressions.push_back(expr->Copy());\n \t\t\t}\n \t\t\tindexes.AddIndex(make_unique<ART>(art.column_ids, art.table_io_manager, std::move(unbound_expressions),\n-\t\t\t                                  art.constraint_type, art.db));\n+\t\t\t                                  art.constraint_type, art.db, false));\n \t\t}\n \t\treturn false;\n \t});\n",
  "test_patch": "diff --git a/test/fuzzer/pedro/index_current_timestamp.test b/test/fuzzer/pedro/index_current_timestamp.test\nindex a4c1cfdc10de..ae95e2e2cd97 100644\n--- a/test/fuzzer/pedro/index_current_timestamp.test\n+++ b/test/fuzzer/pedro/index_current_timestamp.test\n@@ -16,17 +16,17 @@ CREATE SEQUENCE seq\n statement error\n CREATE INDEX i1 ON t1((get_current_timestamp()), c1);\n ----\n-Binder Error: Index keys cannot contain the \"get_current_timestamp\" function.\n+Index keys cannot contain expressions with side effects.\n \n statement error\n CREATE INDEX i1 ON t1((random()), c1);\n ----\n-Binder Error: Index keys cannot contain the \"random\" function.\n+Index keys cannot contain expressions with side effects.\n \n statement error\n CREATE INDEX i1 ON t1((nextval('seq')), c1);\n ----\n-Binder Error: Index keys cannot contain the \"nextval\" function.\n+Index keys cannot contain expressions with side effects.\n \n statement ok\n DELETE FROM t1;\n@@ -36,7 +36,7 @@ DELETE FROM t1;\n statement error\n CREATE INDEX i1 ON t1((get_current_timestamp()), c1);\n ----\n-Binder Error: Index keys cannot contain the \"get_current_timestamp\" function.\n+Index keys cannot contain expressions with side effects.\n \n # but attempting to insert a value borks it up\n statement ok\n@@ -47,7 +47,7 @@ restart\n statement error\n CREATE INDEX i1 ON t1((get_current_timestamp()), c1);\n ----\n-Binder Error: Index keys cannot contain the \"get_current_timestamp\" function.\n+Index keys cannot contain expressions with side effects.\n \n statement ok\n INSERT INTO t1 VALUES (42, 'hello')\ndiff --git a/test/sql/index/CMakeLists.txt b/test/sql/index/CMakeLists.txt\nindex 71a99c7918b8..fae764eb1663 100644\n--- a/test/sql/index/CMakeLists.txt\n+++ b/test/sql/index/CMakeLists.txt\n@@ -1,7 +1,5 @@\n-add_library_unity(\n-  test_index OBJECT test_art_index.cpp test_art_keys.cpp\n-  # test_concurrent_index.cpp\n-)\n+add_library_unity(test_index OBJECT test_art_index.cpp test_art_keys.cpp\n+                  test_art_mem_size.cpp)\n set(ALL_OBJECT_FILES\n     ${ALL_OBJECT_FILES} $<TARGET_OBJECTS:test_index>\n     PARENT_SCOPE)\ndiff --git a/test/sql/index/test_art_mem_size.cpp b/test/sql/index/test_art_mem_size.cpp\nnew file mode 100644\nindex 000000000000..0102a1855f72\n--- /dev/null\n+++ b/test/sql/index/test_art_mem_size.cpp\n@@ -0,0 +1,79 @@\n+#include \"catch.hpp\"\n+#include \"duckdb/storage/buffer_manager.hpp\"\n+#include \"duckdb/storage/storage_info.hpp\"\n+#include \"test_helpers.hpp\"\n+#include \"duckdb/main/client_context.hpp\"\n+\n+#include \"duckdb/execution/index/art/prefix.hpp\"\n+#include \"duckdb/execution/index/art/leaf.hpp\"\n+#include \"duckdb/execution/index/art/node4.hpp\"\n+#include \"duckdb/execution/index/art/node16.hpp\"\n+#include \"duckdb/execution/index/art/node48.hpp\"\n+#include \"duckdb/execution/index/art/node256.hpp\"\n+\n+using namespace duckdb;\n+\n+TEST_CASE(\"Test ART memory size\", \"[art][.]\") {\n+\tauto storage_database = TestCreatePath(\"storage_test\");\n+\tauto config = GetTestConfig();\n+\t// make sure the database does not exist\n+\tDeleteDatabase(storage_database);\n+\tDuckDB db(storage_database, config.get());\n+\tConnection con(db);\n+\n+\t// get some variables for calculations\n+\tauto prefix_size = sizeof(Prefix);\n+\tauto leaf_size = sizeof(Leaf);\n+\tauto node4_size = sizeof(Node4);\n+\tauto node16_size = sizeof(Node16);\n+\tauto node48_size = sizeof(Node48);\n+\tauto node256_size = sizeof(Node256);\n+\n+\tidx_t current_memory = 0;\n+\tauto &buffer_manager = BufferManager::GetBufferManager(*con.context);\n+\tREQUIRE(buffer_manager.GetUsedMemory() == current_memory);\n+\n+\t// test single leaf node with duplicates\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE leaf AS SELECT 42 AS id FROM range(42);\"));\n+\tcurrent_memory = buffer_manager.GetUsedMemory();\n+\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE INDEX idx_leaf ON leaf(id);\"));\n+\tauto leaf_mem = prefix_size + 4 * sizeof(uint8_t) + leaf_size + 42 * sizeof(row_t) + sizeof(row_t);\n+\tREQUIRE(buffer_manager.GetUsedMemory() - current_memory == leaf_mem);\n+\n+\t// test Node4\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE node4 AS SELECT range % 4 AS id FROM range(16);\"));\n+\tcurrent_memory = buffer_manager.GetUsedMemory();\n+\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE INDEX idx_node4 ON node4(id);\"));\n+\tauto node4_mem = prefix_size + 7 * sizeof(uint8_t) + node4_size;\n+\tnode4_mem += 4 * (prefix_size + leaf_size + 4 * sizeof(row_t) + sizeof(row_t));\n+\tREQUIRE(buffer_manager.GetUsedMemory() - current_memory == node4_mem);\n+\n+\t// test Node16\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE node16 AS SELECT range % 16 AS id FROM range(32);\"));\n+\tcurrent_memory = buffer_manager.GetUsedMemory();\n+\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE INDEX idx_node16 ON node16(id);\"));\n+\tauto node16_mem = prefix_size + 7 * sizeof(uint8_t) + node16_size;\n+\tnode16_mem += 16 * (prefix_size + leaf_size + 2 * sizeof(row_t) + sizeof(row_t));\n+\tREQUIRE(buffer_manager.GetUsedMemory() - current_memory == node16_mem);\n+\n+\t// test Node48\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE node48 AS SELECT range % 48 AS id FROM range(96);\"));\n+\tcurrent_memory = buffer_manager.GetUsedMemory();\n+\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE INDEX idx_node48 ON node48(id);\"));\n+\tauto node48_mem = prefix_size + 7 * sizeof(uint8_t) + node48_size;\n+\tnode48_mem += 48 * (prefix_size + leaf_size + 2 * sizeof(row_t) + sizeof(row_t));\n+\tREQUIRE(buffer_manager.GetUsedMemory() - current_memory == node48_mem);\n+\n+\t// test Node256\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE node256 AS SELECT range % 256 AS id FROM range(512);\"));\n+\tcurrent_memory = buffer_manager.GetUsedMemory();\n+\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE INDEX idx_node256 ON node256(id);\"));\n+\tauto node256_mem = prefix_size + 7 * sizeof(uint8_t) + node256_size;\n+\tnode256_mem += 256 * (prefix_size + leaf_size + 2 * sizeof(row_t) + sizeof(row_t));\n+\tREQUIRE(buffer_manager.GetUsedMemory() - current_memory == node256_mem);\n+}\n",
  "problem_statement": "Index sizes do not appear to be accounted for in pragma database_size\n### What happens?\r\n\r\nAccording to [this comment](https://github.com/duckdb/duckdb/issues/1546#issuecomment-1263525113) indexes should be managed by the buffer manager and thus contribute to the memory size listed when running `pragma database_size`. However, in some experiments with the CLI this doesn't appear to be the case.\r\n\r\nI'm not sure if this is an actual bug or if I'm interpreting things incorrectly.\r\n\r\n### To Reproduce\r\n\r\nBelow are some screenshots illustrating what I'm seeing. I was running duckdb built from commit 91a9fc49a5. So while not the absolute latest & greatest, it's pretty close.\r\n\r\nThe data being used is 100k rows of an integer and 10 varchars. It's contrived data, here's the first few rows\r\n```csv\r\nid,A0,A1,A2,A3,A4,A5,A6,A7,A8,A9,\r\n0,\"ccccccccccccccc00\",\"ccccccccccccccc01\",\"ccccccccccccccc02\",\"ccccccccccccccc03\",\"ccccccccccccccc04\",\"ccccccccccccccc05\",\"ccccccccccccccc06\",\"ccccccccccccccc07\",\"ccccccccccccccc08\",\"ccccccccccccccc09\",\r\n1,\"ccccccccccccccc10\",\"ccccccccccccccc11\",\"ccccccccccccccc12\",\"ccccccccccccccc13\",\"ccccccccccccccc14\",\"ccccccccccccccc15\",\"ccccccccccccccc16\",\"ccccccccccccccc17\",\"ccccccccccccccc18\",\"ccccccccccccccc19\",\r\n2,\"ccccccccccccccc20\",\"ccccccccccccccc21\",\"ccccccccccccccc22\",\"ccccccccccccccc23\",\"ccccccccccccccc24\",\"ccccccccccccccc25\",\"ccccccccccccccc26\",\"ccccccccccccccc27\",\"ccccccccccccccc28\",\"ccccccccccccccc29\",\r\n```\r\n\r\nIn the first set of screenshots I've created a table with a primary key on the ID which will also create an index on that column. They show a discrepancy between what DuckDB is reporting versus what the OS is reporting.\r\n\r\n![image](https://user-images.githubusercontent.com/8935186/195381451-4b6cd5a1-6310-4ad2-8eec-eed242a93874.png)\r\n![image](https://user-images.githubusercontent.com/8935186/195381526-c2f09aeb-d674-49c8-9174-070e666f25fa.png)\r\n\r\n(The 0.4.0 and 0.5.1 instances of duckdb are running with the same table created from the same data set.)\r\n\r\nThe next set of screenshots show the same table loaded with the same data, except now the `id` column is not a primary key.\r\n\r\n![image](https://user-images.githubusercontent.com/8935186/195381905-ffafb403-9582-473e-8ef1-63857ea78cd8.png)\r\n![image](https://user-images.githubusercontent.com/8935186/195381935-11b67b99-ccf3-44ea-b92b-e35ebe401fbf.png)\r\n\r\nWhile I don't have a screenshot for it, if I manually create an index, `create index id_idx on t(id);` the OS-reported memory usage goes back up to about 41.0MB.\r\n\r\n\r\n### OS:\r\n\r\nMacOS\r\n\r\n### DuckDB Version:\r\n\r\n0.5.1\r\n\r\n### DuckDB Client:\r\n\r\nCLI\r\n\r\n### Full Name:\r\n\r\nMichael Albers\r\n\r\n### Affiliation:\r\n\r\nMode\r\n\r\n### Have you tried this on the latest `master` branch?\r\n\r\n- [X] I agree\r\n\r\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\r\n\r\n- [X] I agree\n",
  "hints_text": "@pdet or @taniabogatsch can one of you have a look at this issue?\nThis should be partially resolved by #5292 which adds approximate memory tracking to the ART index (pending exact memory tracking in a future PR).",
  "created_at": "2023-01-12T15:49:09Z"
}