{
  "repo": "duckdb/duckdb",
  "pull_number": 12964,
  "instance_id": "duckdb__duckdb-12964",
  "issue_numbers": [
    "12721"
  ],
  "base_commit": "8809fdd6da39d6a99b79dd66685a009be2c31b5f",
  "patch": "diff --git a/tools/pythonpkg/src/include/duckdb_python/numpy/numpy_result_conversion.hpp b/tools/pythonpkg/src/include/duckdb_python/numpy/numpy_result_conversion.hpp\nindex e7922fae3b4f..e2bee2046cdd 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/numpy/numpy_result_conversion.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/numpy/numpy_result_conversion.hpp\n@@ -24,6 +24,9 @@ class NumpyResultConversion {\n \tpy::object ToArray(idx_t col_idx) {\n \t\treturn owned_data[col_idx].ToArray();\n \t}\n+\tbool ToPandas() const {\n+\t\treturn pandas;\n+\t}\n \n private:\n \tvoid Resize(idx_t new_capacity);\n@@ -32,6 +35,7 @@ class NumpyResultConversion {\n \tvector<ArrayWrapper> owned_data;\n \tidx_t count;\n \tidx_t capacity;\n+\tbool pandas;\n };\n \n } // namespace duckdb\ndiff --git a/tools/pythonpkg/src/numpy/array_wrapper.cpp b/tools/pythonpkg/src/numpy/array_wrapper.cpp\nindex a242af973956..6f45d344b9f5 100644\n--- a/tools/pythonpkg/src/numpy/array_wrapper.cpp\n+++ b/tools/pythonpkg/src/numpy/array_wrapper.cpp\n@@ -665,7 +665,8 @@ void ArrayWrapper::Append(idx_t current_offset, Vector &input, idx_t source_size\n \t\t} else {\n \t\t\tthrow InternalException(\"Size not supported on ENUM types\");\n \t\t}\n-\t} break;\n+\t\tbreak;\n+\t}\n \tcase LogicalTypeId::BOOLEAN:\n \t\tmay_have_null = ConvertColumnRegular<bool>(append_data);\n \t\tbreak;\ndiff --git a/tools/pythonpkg/src/numpy/numpy_result_conversion.cpp b/tools/pythonpkg/src/numpy/numpy_result_conversion.cpp\nindex c2105baec2e7..f511baed5ed4 100644\n--- a/tools/pythonpkg/src/numpy/numpy_result_conversion.cpp\n+++ b/tools/pythonpkg/src/numpy/numpy_result_conversion.cpp\n@@ -5,7 +5,7 @@ namespace duckdb {\n \n NumpyResultConversion::NumpyResultConversion(const vector<LogicalType> &types, idx_t initial_capacity,\n                                              const ClientProperties &client_properties, bool pandas)\n-    : count(0), capacity(0) {\n+    : count(0), capacity(0), pandas(pandas) {\n \towned_data.reserve(types.size());\n \tfor (auto &type : types) {\n \t\towned_data.emplace_back(type, client_properties, pandas);\ndiff --git a/tools/pythonpkg/src/pyresult.cpp b/tools/pythonpkg/src/pyresult.cpp\nindex 21c2c8ec1248..9a57b7c89eec 100644\n--- a/tools/pythonpkg/src/pyresult.cpp\n+++ b/tools/pythonpkg/src/pyresult.cpp\n@@ -175,6 +175,9 @@ void DuckDBPyResult::FillNumpy(py::dict &res, idx_t col_idx, NumpyResultConversi\n \t\tres[name] = py::module::import(\"pandas\")\n \t\t                .attr(\"Categorical\")\n \t\t                .attr(\"from_codes\")(conversion.ToArray(col_idx), py::arg(\"dtype\") = categories_type[col_idx]);\n+\t\tif (!conversion.ToPandas()) {\n+\t\t\tres[name] = res[name].attr(\"to_numpy\")();\n+\t\t}\n \t} else {\n \t\tres[name] = conversion.ToArray(col_idx);\n \t}\n",
  "test_patch": "diff --git a/tools/pythonpkg/tests/fast/types/test_numpy.py b/tools/pythonpkg/tests/fast/types/test_numpy.py\nindex 6c8c13243755..42ae33a089b2 100644\n--- a/tools/pythonpkg/tests/fast/types/test_numpy.py\n+++ b/tools/pythonpkg/tests/fast/types/test_numpy.py\n@@ -26,3 +26,9 @@ def test_numpy_datetime_big(self):\n         res1 = duckdb_con.execute(\"select * from test\").fetchnumpy()\n         date_value = {'date': np.array(['2263-02-28'], dtype='datetime64[us]')}\n         assert res1 == date_value\n+\n+    def test_numpy_enum_conversion(self, duckdb_cursor):\n+        arr = np.array(['a', 'b', 'c'])\n+        rel = duckdb_cursor.sql(\"select * from arr\")\n+        res = rel.fetchnumpy()['column0']\n+        np.testing.assert_equal(res, arr)\n",
  "problem_statement": "`fetchnumpy()` returns non-NumPy objects (i.e., pandas.core.arrays.categorical.Categorical)\n### What happens?\r\n\r\nThe `fetchnumpy()` function returns a Pandas object for (at least) NumPy unicode dtypes, not a NumPy object. As the name of the function is `fetchnumpy()`, it seems the result should consist only of NumPy objects. \r\n\r\n### To Reproduce\r\n\r\n```python\r\n>>> import numpy as np\r\n>>> import duckdb\r\n>>> a1 = np.array(('a', 'b', 'c'))\r\n>>> a1\r\narray(['a', 'b', 'c'], dtype='<U1')\r\n>>> d = duckdb.connect().execute('select * from a1').fetchnumpy()\r\n>>> d['column0']\r\n['a', 'b', 'c']\r\nCategories (3, object): ['a' < 'b' < 'c']\r\n>>> type(d['column0'])\r\n<class 'pandas.core.arrays.categorical.Categorical'>\r\n```\r\n\r\n### OS:\r\n\r\nMacOS 14.1.1, arm64\r\n\r\n### DuckDB Version:\r\n\r\n1.0.0\r\n\r\n### DuckDB Client:\r\n\r\nPython\r\n\r\n### Full Name:\r\n\r\nChristopher Ariza\r\n\r\n### Affiliation:\r\n\r\nSelf\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nNot applicable - the reproduction does not require a data set\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\n",
  "hints_text": "",
  "created_at": "2024-07-12T08:59:14Z"
}