You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes.
In the patch file, please make sure to include the line numbers and a blank line at the end so it can be applied using git apply.

<issue>
`fetchnumpy()` returns non-NumPy objects (i.e., pandas.core.arrays.categorical.Categorical)
### What happens?

The `fetchnumpy()` function returns a Pandas object for (at least) NumPy unicode dtypes, not a NumPy object. As the name of the function is `fetchnumpy()`, it seems the result should consist only of NumPy objects. 

### To Reproduce

```python
>>> import numpy as np
>>> import duckdb
>>> a1 = np.array(('a', 'b', 'c'))
>>> a1
array(['a', 'b', 'c'], dtype='<U1')
>>> d = duckdb.connect().execute('select * from a1').fetchnumpy()
>>> d['column0']
['a', 'b', 'c']
Categories (3, object): ['a' < 'b' < 'c']
>>> type(d['column0'])
<class 'pandas.core.arrays.categorical.Categorical'>
```

### OS:

MacOS 14.1.1, arm64

### DuckDB Version:

1.0.0

### DuckDB Client:

Python

### Full Name:

Christopher Ariza

### Affiliation:

Self

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a stable release

### Did you include all relevant data sets for reproducing the issue?

Not applicable - the reproduction does not require a data set

### Did you include all code required to reproduce the issue?

- [X] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [X] Yes, I have

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <picture>
3:     <source media="(prefers-color-scheme: light)" srcset="logo/DuckDB_Logo-horizontal.svg">
4:     <source media="(prefers-color-scheme: dark)" srcset="logo/DuckDB_Logo-horizontal-dark-mode.svg">
5:     <img alt="DuckDB logo" src="logo/DuckDB_Logo-horizontal.svg" height="100">
6:   </picture>
7: </div>
8: <br>
9: 
10: <p align="center">
11:   <a href="https://github.com/duckdb/duckdb/actions"><img src="https://github.com/duckdb/duckdb/actions/workflows/Main.yml/badge.svg?branch=main" alt="Github Actions Badge"></a>
12:   <a href="https://discord.gg/tcvwpjfnZx"><img src="https://shields.io/discord/909674491309850675" alt="discord" /></a>
13:   <a href="https://github.com/duckdb/duckdb/releases/"><img src="https://img.shields.io/github/v/release/duckdb/duckdb?color=brightgreen&display_name=tag&logo=duckdb&logoColor=white" alt="Latest Release"></a>
14: </p>
15: 
16: ## DuckDB
17: 
18: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable, portable, and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs, maps), and [several extensions designed to make SQL easier to use](https://duckdb.org/docs/guides/sql_features/friendly_sql).
19: 
20: DuckDB is available as a [standalone CLI application](https://duckdb.org/docs/api/cli/overview) and has clients for [Python](https://duckdb.org/docs/api/python/overview), [R](https://duckdb.org/docs/api/r), [Java](https://duckdb.org/docs/api/java), [Wasm](https://duckdb.org/docs/api/wasm/overview), etc., with deep integrations with packages such as [pandas](https://duckdb.org/docs/guides/python/sql_on_pandas) and [dplyr](https://duckdblabs.github.io/duckplyr/).
21: 
22: For more information on using DuckDB, please refer to the [DuckDB documentation](https://duckdb.org/docs/).
23: 
24: ## Installation
25: 
26: If you want to install DuckDB, please see [our installation page](https://www.duckdb.org/docs/installation) for instructions.
27: 
28: ## Data Import
29: 
30: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
31: 
32: ```sql
33: SELECT * FROM 'myfile.csv';
34: SELECT * FROM 'myfile.parquet';
35: ```
36: 
37: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
38: 
39: ## SQL Reference
40: 
41: The documentation contains a [SQL introduction and reference](https://duckdb.org/docs/sql/introduction).
42: 
43: ## Development
44: 
45: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run `BUILD_BENCHMARK=1 BUILD_TPCH=1 make` and then perform several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`. The details of benchmarks are in our [Benchmark Guide](benchmark/README.md).
46: 
47: Please also refer to our [Build Guide](https://duckdb.org/dev/building) and [Contribution Guide](CONTRIBUTING.md).
48: 
49: ## Support
50: 
51: See the [Support Options](https://duckdblabs.com/support/) page.
[end of README.md]
[start of tools/pythonpkg/src/include/duckdb_python/numpy/numpy_result_conversion.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb_python/numpy/numpy_result_conversion.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb_python/pybind11/pybind_wrapper.hpp"
12: #include "duckdb_python/numpy/array_wrapper.hpp"
13: #include "duckdb.hpp"
14: 
15: namespace duckdb {
16: 
17: class NumpyResultConversion {
18: public:
19: 	NumpyResultConversion(const vector<LogicalType> &types, idx_t initial_capacity,
20: 	                      const ClientProperties &client_properties, bool pandas = false);
21: 
22: 	void Append(DataChunk &chunk);
23: 
24: 	py::object ToArray(idx_t col_idx) {
25: 		return owned_data[col_idx].ToArray();
26: 	}
27: 
28: private:
29: 	void Resize(idx_t new_capacity);
30: 
31: private:
32: 	vector<ArrayWrapper> owned_data;
33: 	idx_t count;
34: 	idx_t capacity;
35: };
36: 
37: } // namespace duckdb
[end of tools/pythonpkg/src/include/duckdb_python/numpy/numpy_result_conversion.hpp]
[start of tools/pythonpkg/src/numpy/array_wrapper.cpp]
1: #include "duckdb_python/numpy/array_wrapper.hpp"
2: #include "duckdb/common/types/date.hpp"
3: #include "duckdb/common/types/hugeint.hpp"
4: #include "duckdb/common/types/time.hpp"
5: #include "duckdb/common/types/timestamp.hpp"
6: #include "utf8proc_wrapper.hpp"
7: #include "duckdb/common/types/interval.hpp"
8: #include "duckdb_python/pyrelation.hpp"
9: #include "duckdb_python/python_objects.hpp"
10: #include "duckdb_python/pyconnection/pyconnection.hpp"
11: #include "duckdb_python/pyresult.hpp"
12: #include "duckdb/common/types/uuid.hpp"
13: 
14: namespace duckdb {
15: 
16: namespace duckdb_py_convert {
17: 
18: struct RegularConvert {
19: 	template <class DUCKDB_T, class NUMPY_T>
20: 	static NUMPY_T ConvertValue(DUCKDB_T val, NumpyAppendData &append_data) {
21: 		(void)append_data;
22: 		return (NUMPY_T)val;
23: 	}
24: 
25: 	template <class NUMPY_T, bool PANDAS>
26: 	static NUMPY_T NullValue(bool &set_mask) {
27: 		set_mask = true;
28: 		return 0;
29: 	}
30: };
31: 
32: struct TimestampConvert {
33: 	template <class DUCKDB_T, class NUMPY_T>
34: 	static int64_t ConvertValue(timestamp_t val, NumpyAppendData &append_data) {
35: 		(void)append_data;
36: 		if (!Timestamp::IsFinite(val)) {
37: 			return val.value;
38: 		}
39: 		return Timestamp::GetEpochNanoSeconds(val);
40: 	}
41: 
42: 	template <class NUMPY_T, bool PANDAS>
43: 	static NUMPY_T NullValue(bool &set_mask) {
44: 		set_mask = true;
45: 		return 0;
46: 	}
47: };
48: 
49: struct TimestampConvertSec {
50: 	template <class DUCKDB_T, class NUMPY_T>
51: 	static int64_t ConvertValue(timestamp_t val, NumpyAppendData &append_data) {
52: 		(void)append_data;
53: 		if (!Timestamp::IsFinite(val)) {
54: 			return val.value;
55: 		}
56: 		return Timestamp::GetEpochNanoSeconds(Timestamp::FromEpochSeconds(val.value));
57: 	}
58: 
59: 	template <class NUMPY_T, bool PANDAS>
60: 	static NUMPY_T NullValue(bool &set_mask) {
61: 		set_mask = true;
62: 		return 0;
63: 	}
64: };
65: 
66: struct TimestampConvertMilli {
67: 	template <class DUCKDB_T, class NUMPY_T>
68: 	static int64_t ConvertValue(timestamp_t val, NumpyAppendData &append_data) {
69: 		(void)append_data;
70: 		if (!Timestamp::IsFinite(val)) {
71: 			return val.value;
72: 		}
73: 		return Timestamp::GetEpochNanoSeconds(Timestamp::FromEpochMs(val.value));
74: 	}
75: 
76: 	template <class NUMPY_T, bool PANDAS>
77: 	static NUMPY_T NullValue(bool &set_mask) {
78: 		set_mask = true;
79: 		return 0;
80: 	}
81: };
82: 
83: struct TimestampConvertNano {
84: 	template <class DUCKDB_T, class NUMPY_T>
85: 	static int64_t ConvertValue(timestamp_t val, NumpyAppendData &append_data) {
86: 		(void)append_data;
87: 		return val.value;
88: 	}
89: 
90: 	template <class NUMPY_T, bool PANDAS>
91: 	static NUMPY_T NullValue(bool &set_mask) {
92: 		set_mask = true;
93: 		return 0;
94: 	}
95: };
96: 
97: struct DateConvert {
98: 	template <class DUCKDB_T, class NUMPY_T>
99: 	static int64_t ConvertValue(date_t val, NumpyAppendData &append_data) {
100: 		(void)append_data;
101: 		return Date::EpochMicroseconds(val);
102: 	}
103: 
104: 	template <class NUMPY_T, bool PANDAS>
105: 	static NUMPY_T NullValue(bool &set_mask) {
106: 		set_mask = true;
107: 		return 0;
108: 	}
109: };
110: 
111: struct IntervalConvert {
112: 	template <class DUCKDB_T, class NUMPY_T>
113: 	static int64_t ConvertValue(interval_t val, NumpyAppendData &append_data) {
114: 		(void)append_data;
115: 		return Interval::GetNanoseconds(val);
116: 	}
117: 
118: 	template <class NUMPY_T, bool PANDAS>
119: 	static NUMPY_T NullValue(bool &set_mask) {
120: 		set_mask = true;
121: 		return 0;
122: 	}
123: };
124: 
125: struct TimeConvert {
126: 	template <class DUCKDB_T, class NUMPY_T>
127: 	static PyObject *ConvertValue(dtime_t val, NumpyAppendData &append_data) {
128: 		auto &client_properties = append_data.client_properties;
129: 		auto value = Value::TIME(val);
130: 		auto py_obj = PythonObject::FromValue(value, LogicalType::TIME, client_properties);
131: 		// Release ownership of the PyObject* without decreasing refcount
132: 		// this returns a handle, of which we take the ptr to get the PyObject*
133: 		return py_obj.release().ptr();
134: 	}
135: 
136: 	template <class NUMPY_T, bool PANDAS>
137: 	static NUMPY_T NullValue(bool &set_mask) {
138: 		set_mask = true;
139: 		return nullptr;
140: 	}
141: };
142: 
143: struct StringConvert {
144: 	template <class T>
145: 	static void ConvertUnicodeValueTemplated(T *result, int32_t *codepoints, idx_t codepoint_count, const char *data,
146: 	                                         idx_t ascii_count) {
147: 		// we first fill in the batch of ascii characters directly
148: 		for (idx_t i = 0; i < ascii_count; i++) {
149: 			result[i] = data[i];
150: 		}
151: 		// then we fill in the remaining codepoints from our codepoint array
152: 		for (idx_t i = 0; i < codepoint_count; i++) {
153: 			result[ascii_count + i] = codepoints[i];
154: 		}
155: 	}
156: 
157: 	static PyObject *ConvertUnicodeValue(const char *data, idx_t len, idx_t start_pos) {
158: 		// slow path: check the code points
159: 		// we know that all characters before "start_pos" were ascii characters, so we don't need to check those
160: 
161: 		// allocate an array of code points so we only have to convert the codepoints once
162: 		// short-string optimization
163: 		// we know that the max amount of codepoints is the length of the string
164: 		// for short strings (less than 64 bytes) we simply statically allocate an array of 256 bytes (64x int32)
165: 		// this avoids memory allocation for small strings (common case)
166: 		idx_t remaining = len - start_pos;
167: 		unique_ptr<int32_t[]> allocated_codepoints;
168: 		int32_t static_codepoints[64];
169: 		int32_t *codepoints;
170: 		if (remaining > 64) {
171: 			allocated_codepoints = unique_ptr<int32_t[]>(new int32_t[remaining]);
172: 			codepoints = allocated_codepoints.get();
173: 		} else {
174: 			codepoints = static_codepoints;
175: 		}
176: 		// now we iterate over the remainder of the string to convert the UTF8 string into a sequence of codepoints
177: 		// and to find the maximum codepoint
178: 		int32_t max_codepoint = 127;
179: 		int sz;
180: 		idx_t pos = start_pos;
181: 		idx_t codepoint_count = 0;
182: 		while (pos < len) {
183: 			codepoints[codepoint_count] = Utf8Proc::UTF8ToCodepoint(data + pos, sz);
184: 			pos += sz;
185: 			if (codepoints[codepoint_count] > max_codepoint) {
186: 				max_codepoint = codepoints[codepoint_count];
187: 			}
188: 			codepoint_count++;
189: 		}
190: 		// based on the max codepoint, we construct the result string
191: 		auto result = PyUnicode_New(start_pos + codepoint_count, max_codepoint);
192: 		// based on the resulting unicode kind, we fill in the code points
193: 		auto result_handle = py::handle(result);
194: 		auto kind = PyUtil::PyUnicodeKind(result_handle);
195: 		switch (kind) {
196: 		case PyUnicode_1BYTE_KIND:
197: 			ConvertUnicodeValueTemplated<Py_UCS1>(PyUtil::PyUnicode1ByteData(result_handle), codepoints,
198: 			                                      codepoint_count, data, start_pos);
199: 			break;
200: 		case PyUnicode_2BYTE_KIND:
201: 			ConvertUnicodeValueTemplated<Py_UCS2>(PyUtil::PyUnicode2ByteData(result_handle), codepoints,
202: 			                                      codepoint_count, data, start_pos);
203: 			break;
204: 		case PyUnicode_4BYTE_KIND:
205: 			ConvertUnicodeValueTemplated<Py_UCS4>(PyUtil::PyUnicode4ByteData(result_handle), codepoints,
206: 			                                      codepoint_count, data, start_pos);
207: 			break;
208: 		default:
209: 			throw NotImplementedException("Unsupported typekind constant '%d' for Python Unicode Compact decode", kind);
210: 		}
211: 		return result;
212: 	}
213: 
214: 	template <class DUCKDB_T, class NUMPY_T>
215: 	static PyObject *ConvertValue(string_t val, NumpyAppendData &append_data) {
216: 		(void)append_data;
217: 		// we could use PyUnicode_FromStringAndSize here, but it does a lot of verification that we don't need
218: 		// because of that it is a lot slower than it needs to be
219: 		auto data = const_data_ptr_cast(val.GetData());
220: 		auto len = val.GetSize();
221: 		// check if there are any non-ascii characters in there
222: 		for (idx_t i = 0; i < len; i++) {
223: 			if (data[i] > 127) {
224: 				// there are! fallback to slower case
225: 				return ConvertUnicodeValue(const_char_ptr_cast(data), len, i);
226: 			}
227: 		}
228: 		// no unicode: fast path
229: 		// directly construct the string and memcpy it
230: 		auto result = PyUnicode_New(len, 127);
231: 		auto result_handle = py::handle(result);
232: 		auto target_data = PyUtil::PyUnicodeDataMutable(result_handle);
233: 		memcpy(target_data, data, len);
234: 		return result;
235: 	}
236: 	template <class NUMPY_T, bool PANDAS>
237: 	static NUMPY_T NullValue(bool &set_mask) {
238: 		if (PANDAS) {
239: 			set_mask = false;
240: 			Py_RETURN_NONE;
241: 		}
242: 		set_mask = true;
243: 		return nullptr;
244: 	}
245: };
246: 
247: struct BlobConvert {
248: 	template <class DUCKDB_T, class NUMPY_T>
249: 	static PyObject *ConvertValue(string_t val, NumpyAppendData &append_data) {
250: 		(void)append_data;
251: 		return PyByteArray_FromStringAndSize(val.GetData(), val.GetSize());
252: 	}
253: 
254: 	template <class NUMPY_T, bool PANDAS>
255: 	static NUMPY_T NullValue(bool &set_mask) {
256: 		set_mask = true;
257: 		return nullptr;
258: 	}
259: };
260: 
261: struct BitConvert {
262: 	template <class DUCKDB_T, class NUMPY_T>
263: 	static PyObject *ConvertValue(string_t val, NumpyAppendData &append_data) {
264: 		(void)append_data;
265: 		return PyBytes_FromStringAndSize(val.GetData(), val.GetSize());
266: 	}
267: 
268: 	template <class NUMPY_T, bool PANDAS>
269: 	static NUMPY_T NullValue(bool &set_mask) {
270: 		set_mask = true;
271: 		return nullptr;
272: 	}
273: };
274: 
275: struct UUIDConvert {
276: 	template <class DUCKDB_T, class NUMPY_T>
277: 	static PyObject *ConvertValue(hugeint_t val, NumpyAppendData &append_data) {
278: 		(void)append_data;
279: 		auto &import_cache = *DuckDBPyConnection::ImportCache();
280: 		py::handle h = import_cache.uuid.UUID()(UUID::ToString(val)).release();
281: 		return h.ptr();
282: 	}
283: 
284: 	template <class NUMPY_T, bool PANDAS>
285: 	static NUMPY_T NullValue(bool &set_mask) {
286: 		set_mask = true;
287: 		return nullptr;
288: 	}
289: };
290: 
291: static py::object InternalCreateList(Vector &input, idx_t total_size, idx_t offset, idx_t size,
292:                                      NumpyAppendData &append_data) {
293: 	// Initialize the array we'll append the list data to
294: 	auto &type = input.GetType();
295: 	ArrayWrapper result(type, append_data.client_properties, append_data.pandas);
296: 	result.Initialize(size);
297: 
298: 	D_ASSERT(offset + size <= total_size);
299: 	result.Append(0, input, total_size, offset, size);
300: 	return result.ToArray();
301: }
302: 
303: struct ListConvert {
304: 	static py::object ConvertValue(Vector &input, idx_t chunk_offset, NumpyAppendData &append_data) {
305: 		auto &client_properties = append_data.client_properties;
306: 		auto &list_data = append_data.idata;
307: 
308: 		// Get the list entry information from the parent
309: 		const auto list_sel = *list_data.sel;
310: 		const auto list_entries = UnifiedVectorFormat::GetData<list_entry_t>(list_data);
311: 		auto list_index = list_sel.get_index(chunk_offset);
312: 		auto list_entry = list_entries[list_index];
313: 
314: 		auto list_size = list_entry.length;
315: 		auto list_offset = list_entry.offset;
316: 		auto child_size = ListVector::GetListSize(input);
317: 		auto &child_vector = ListVector::GetEntry(input);
318: 
319: 		return InternalCreateList(child_vector, child_size, list_offset, list_size, append_data);
320: 	}
321: };
322: 
323: struct ArrayConvert {
324: 	static py::object ConvertValue(Vector &input, idx_t chunk_offset, NumpyAppendData &append_data) {
325: 		auto &array_data = append_data.idata;
326: 
327: 		// Get the list entry information from the parent
328: 		const auto array_sel = *array_data.sel;
329: 		auto array_index = array_sel.get_index(chunk_offset);
330: 
331: 		auto &array_type = input.GetType();
332: 		D_ASSERT(array_type.id() == LogicalTypeId::ARRAY);
333: 
334: 		auto array_size = ArrayType::GetSize(array_type);
335: 		auto array_offset = array_index * array_size;
336: 		auto child_size = ArrayVector::GetTotalSize(input);
337: 		auto &child_vector = ArrayVector::GetEntry(input);
338: 
339: 		return InternalCreateList(child_vector, child_size, array_offset, array_size, append_data);
340: 	}
341: };
342: 
343: struct StructConvert {
344: 	static py::dict ConvertValue(Vector &input, idx_t chunk_offset, NumpyAppendData &append_data) {
345: 		auto &client_properties = append_data.client_properties;
346: 
347: 		py::dict py_struct;
348: 		auto val = input.GetValue(chunk_offset);
349: 		auto &child_types = StructType::GetChildTypes(input.GetType());
350: 		auto &struct_children = StructValue::GetChildren(val);
351: 
352: 		for (idx_t i = 0; i < struct_children.size(); i++) {
353: 			auto &child_entry = child_types[i];
354: 			auto &child_name = child_entry.first;
355: 			auto &child_type = child_entry.second;
356: 			py_struct[child_name.c_str()] = PythonObject::FromValue(struct_children[i], child_type, client_properties);
357: 		}
358: 		return py_struct;
359: 	}
360: };
361: 
362: struct UnionConvert {
363: 	static py::object ConvertValue(Vector &input, idx_t chunk_offset, NumpyAppendData &append_data) {
364: 		auto &client_properties = append_data.client_properties;
365: 		auto val = input.GetValue(chunk_offset);
366: 		auto value = UnionValue::GetValue(val);
367: 
368: 		return PythonObject::FromValue(value, UnionValue::GetType(val), client_properties);
369: 	}
370: };
371: 
372: struct MapConvert {
373: 	static py::dict ConvertValue(Vector &input, idx_t chunk_offset, NumpyAppendData &append_data) {
374: 		auto &client_properties = append_data.client_properties;
375: 		auto val = input.GetValue(chunk_offset);
376: 		return PythonObject::FromValue(val, input.GetType(), client_properties);
377: 	}
378: };
379: 
380: struct IntegralConvert {
381: 	template <class DUCKDB_T, class NUMPY_T>
382: 	static NUMPY_T ConvertValue(DUCKDB_T val, NumpyAppendData &append_data) {
383: 		(void)append_data;
384: 		return NUMPY_T(val);
385: 	}
386: 
387: 	template <class NUMPY_T, bool PANDAS>
388: 	static NUMPY_T NullValue(bool &set_mask) {
389: 		set_mask = true;
390: 		return 0;
391: 	}
392: };
393: 
394: template <>
395: double IntegralConvert::ConvertValue(hugeint_t val, NumpyAppendData &append_data) {
396: 	(void)append_data;
397: 	double result;
398: 	Hugeint::TryCast(val, result);
399: 	return result;
400: }
401: 
402: template <>
403: double IntegralConvert::ConvertValue(uhugeint_t val, NumpyAppendData &append_data) {
404: 	(void)append_data;
405: 	double result;
406: 	Uhugeint::TryCast(val, result);
407: 	return result;
408: }
409: 
410: } // namespace duckdb_py_convert
411: 
412: template <class DUCKDB_T, class NUMPY_T, class CONVERT, bool HAS_NULLS, bool PANDAS>
413: static bool ConvertColumnTemplated(NumpyAppendData &append_data) {
414: 	auto target_offset = append_data.target_offset;
415: 	auto target_data = append_data.target_data;
416: 	auto target_mask = append_data.target_mask;
417: 	auto &idata = append_data.idata;
418: 	auto count = append_data.count;
419: 	auto source_offset = append_data.source_offset;
420: 
421: 	auto src_ptr = UnifiedVectorFormat::GetData<DUCKDB_T>(idata);
422: 	auto out_ptr = reinterpret_cast<NUMPY_T *>(target_data);
423: 	bool mask_is_set = false;
424: 	for (idx_t i = 0; i < count; i++) {
425: 		idx_t src_idx = idata.sel->get_index(i + source_offset);
426: 		idx_t offset = target_offset + i;
427: 		if (HAS_NULLS && !idata.validity.RowIsValidUnsafe(src_idx)) {
428: 			out_ptr[offset] = CONVERT::template NullValue<NUMPY_T, PANDAS>(target_mask[offset]);
429: 			mask_is_set = mask_is_set || target_mask[offset];
430: 		} else {
431: 			out_ptr[offset] = CONVERT::template ConvertValue<DUCKDB_T, NUMPY_T>(src_ptr[src_idx], append_data);
432: 			target_mask[offset] = false;
433: 		}
434: 	}
435: 	return mask_is_set;
436: }
437: 
438: template <class DUCKDB_T, class NUMPY_T, class CONVERT>
439: static bool ConvertColumn(NumpyAppendData &append_data) {
440: 	auto target_offset = append_data.target_offset;
441: 	auto target_data = append_data.target_data;
442: 	auto &idata = append_data.idata;
443: 
444: 	auto src_ptr = UnifiedVectorFormat::GetData<DUCKDB_T>(idata);
445: 	auto out_ptr = reinterpret_cast<NUMPY_T *>(target_data);
446: 	if (!idata.validity.AllValid()) {
447: 		if (append_data.pandas) {
448: 			return ConvertColumnTemplated<DUCKDB_T, NUMPY_T, CONVERT, /*has_nulls=*/true, /*pandas=*/true>(append_data);
449: 		} else {
450: 			return ConvertColumnTemplated<DUCKDB_T, NUMPY_T, CONVERT, /*has_nulls=*/true, /*pandas=*/false>(
451: 			    append_data);
452: 		}
453: 	} else {
454: 		if (append_data.pandas) {
455: 			return ConvertColumnTemplated<DUCKDB_T, NUMPY_T, CONVERT, /*has_nulls=*/false, /*pandas=*/true>(
456: 			    append_data);
457: 		} else {
458: 			return ConvertColumnTemplated<DUCKDB_T, NUMPY_T, CONVERT, /*has_nulls=*/false, /*pandas=*/false>(
459: 			    append_data);
460: 		}
461: 	}
462: }
463: 
464: template <class DUCKDB_T, class NUMPY_T>
465: static bool ConvertColumnCategoricalTemplate(NumpyAppendData &append_data) {
466: 	auto target_offset = append_data.target_offset;
467: 	auto target_data = append_data.target_data;
468: 	auto &idata = append_data.idata;
469: 	auto count = append_data.count;
470: 	auto source_offset = append_data.source_offset;
471: 
472: 	auto src_ptr = UnifiedVectorFormat::GetData<DUCKDB_T>(idata);
473: 	auto out_ptr = reinterpret_cast<NUMPY_T *>(target_data);
474: 	if (!idata.validity.AllValid()) {
475: 		for (idx_t i = 0; i < count; i++) {
476: 			idx_t src_idx = idata.sel->get_index(i + source_offset);
477: 			idx_t offset = target_offset + i;
478: 			if (!idata.validity.RowIsValidUnsafe(src_idx)) {
479: 				out_ptr[offset] = static_cast<NUMPY_T>(-1);
480: 			} else {
481: 				out_ptr[offset] = duckdb_py_convert::RegularConvert::template ConvertValue<DUCKDB_T, NUMPY_T>(
482: 				    src_ptr[src_idx], append_data);
483: 			}
484: 		}
485: 	} else {
486: 		for (idx_t i = 0; i < count; i++) {
487: 			idx_t src_idx = idata.sel->get_index(i + source_offset);
488: 			idx_t offset = target_offset + i;
489: 			out_ptr[offset] = duckdb_py_convert::RegularConvert::template ConvertValue<DUCKDB_T, NUMPY_T>(
490: 			    src_ptr[src_idx], append_data);
491: 		}
492: 	}
493: 	// Null values are encoded in the data itself
494: 	return false;
495: }
496: 
497: template <class NUMPY_T, class CONVERT>
498: static bool ConvertNested(NumpyAppendData &append_data) {
499: 	auto target_offset = append_data.target_offset;
500: 	auto target_data = append_data.target_data;
501: 	auto target_mask = append_data.target_mask;
502: 	auto &input = append_data.input;
503: 	auto &idata = append_data.idata;
504: 	auto &client_properties = append_data.client_properties;
505: 	auto count = append_data.count;
506: 	auto source_offset = append_data.source_offset;
507: 
508: 	auto out_ptr = reinterpret_cast<NUMPY_T *>(target_data);
509: 	if (!idata.validity.AllValid()) {
510: 		bool requires_mask = false;
511: 		for (idx_t i = 0; i < count; i++) {
512: 			idx_t index = i + source_offset;
513: 			idx_t src_idx = idata.sel->get_index(index);
514: 			idx_t offset = target_offset + i;
515: 			if (!idata.validity.RowIsValidUnsafe(src_idx)) {
516: 				out_ptr[offset] = py::none();
517: 				requires_mask = true;
518: 				target_mask[offset] = true;
519: 			} else {
520: 				out_ptr[offset] = CONVERT::ConvertValue(input, index, append_data);
521: 				target_mask[offset] = false;
522: 			}
523: 		}
524: 		return requires_mask;
525: 	} else {
526: 		for (idx_t i = 0; i < count; i++) {
527: 			// NOTE: we do not apply the selection vector here,
528: 			// because we use GetValue inside ConvertValue, which *also* applies the selection vector
529: 			idx_t index = i + source_offset;
530: 			idx_t offset = target_offset + i;
531: 			out_ptr[offset] = CONVERT::ConvertValue(input, index, append_data);
532: 			target_mask[offset] = false;
533: 		}
534: 		return false;
535: 	}
536: }
537: 
538: template <class NUMPY_T>
539: static bool ConvertColumnCategorical(NumpyAppendData &append_data) {
540: 	auto physical_type = append_data.physical_type;
541: 	switch (physical_type) {
542: 	case PhysicalType::UINT8:
543: 		return ConvertColumnCategoricalTemplate<uint8_t, NUMPY_T>(append_data);
544: 	case PhysicalType::UINT16:
545: 		return ConvertColumnCategoricalTemplate<uint16_t, NUMPY_T>(append_data);
546: 	case PhysicalType::UINT32:
547: 		return ConvertColumnCategoricalTemplate<uint32_t, NUMPY_T>(append_data);
548: 	default:
549: 		throw InternalException("Enum Physical Type not Allowed");
550: 	}
551: }
552: 
553: template <class T>
554: static bool ConvertColumnRegular(NumpyAppendData &append_data) {
555: 	return ConvertColumn<T, T, duckdb_py_convert::RegularConvert>(append_data);
556: }
557: 
558: template <class DUCKDB_T>
559: static bool ConvertDecimalInternal(NumpyAppendData &append_data, double division) {
560: 	auto target_offset = append_data.target_offset;
561: 	auto target_data = append_data.target_data;
562: 	auto target_mask = append_data.target_mask;
563: 	auto &idata = append_data.idata;
564: 	auto count = append_data.count;
565: 	auto source_offset = append_data.source_offset;
566: 
567: 	auto src_ptr = UnifiedVectorFormat::GetData<DUCKDB_T>(idata);
568: 	auto out_ptr = reinterpret_cast<double *>(target_data);
569: 	if (!idata.validity.AllValid()) {
570: 		for (idx_t i = 0; i < count; i++) {
571: 			idx_t src_idx = idata.sel->get_index(i + source_offset);
572: 			idx_t offset = target_offset + i;
573: 			if (!idata.validity.RowIsValidUnsafe(src_idx)) {
574: 				target_mask[offset] = true;
575: 			} else {
576: 				out_ptr[offset] =
577: 				    duckdb_py_convert::IntegralConvert::ConvertValue<DUCKDB_T, double>(src_ptr[src_idx], append_data) /
578: 				    division;
579: 				target_mask[offset] = false;
580: 			}
581: 		}
582: 		return true;
583: 	} else {
584: 		for (idx_t i = 0; i < count; i++) {
585: 			idx_t src_idx = idata.sel->get_index(i + source_offset);
586: 			idx_t offset = target_offset + i;
587: 			out_ptr[offset] =
588: 			    duckdb_py_convert::IntegralConvert::ConvertValue<DUCKDB_T, double>(src_ptr[src_idx], append_data) /
589: 			    division;
590: 			target_mask[offset] = false;
591: 		}
592: 		return false;
593: 	}
594: }
595: 
596: static bool ConvertDecimal(NumpyAppendData &append_data) {
597: 	auto &decimal_type = append_data.input.GetType();
598: 	auto dec_scale = DecimalType::GetScale(decimal_type);
599: 	double division = pow(10, dec_scale);
600: 	switch (decimal_type.InternalType()) {
601: 	case PhysicalType::INT16:
602: 		return ConvertDecimalInternal<int16_t>(append_data, division);
603: 	case PhysicalType::INT32:
604: 		return ConvertDecimalInternal<int32_t>(append_data, division);
605: 	case PhysicalType::INT64:
606: 		return ConvertDecimalInternal<int64_t>(append_data, division);
607: 	case PhysicalType::INT128:
608: 		return ConvertDecimalInternal<hugeint_t>(append_data, division);
609: 	default:
610: 		throw NotImplementedException("Unimplemented internal type for DECIMAL");
611: 	}
612: }
613: 
614: ArrayWrapper::ArrayWrapper(const LogicalType &type, const ClientProperties &client_properties_p, bool pandas)
615:     : requires_mask(false), client_properties(client_properties_p), pandas(pandas) {
616: 	data = make_uniq<RawArrayWrapper>(type);
617: 	mask = make_uniq<RawArrayWrapper>(LogicalType::BOOLEAN);
618: }
619: 
620: void ArrayWrapper::Initialize(idx_t capacity) {
621: 	data->Initialize(capacity);
622: 	mask->Initialize(capacity);
623: }
624: 
625: void ArrayWrapper::Resize(idx_t new_capacity) {
626: 	data->Resize(new_capacity);
627: 	mask->Resize(new_capacity);
628: }
629: 
630: void ArrayWrapper::Append(idx_t current_offset, Vector &input, idx_t source_size, idx_t source_offset, idx_t count) {
631: 	auto dataptr = data->data;
632: 	auto maskptr = reinterpret_cast<bool *>(mask->data);
633: 	D_ASSERT(dataptr);
634: 	D_ASSERT(maskptr);
635: 	D_ASSERT(input.GetType() == data->type);
636: 	bool may_have_null;
637: 
638: 	UnifiedVectorFormat idata;
639: 	input.ToUnifiedFormat(source_size, idata);
640: 
641: 	if (count == DConstants::INVALID_INDEX) {
642: 		D_ASSERT(source_size != DConstants::INVALID_INDEX);
643: 		count = source_size;
644: 	}
645: 
646: 	NumpyAppendData append_data(idata, client_properties, input);
647: 	append_data.target_offset = current_offset;
648: 	append_data.target_data = dataptr;
649: 	append_data.source_offset = source_offset;
650: 	append_data.source_size = source_size;
651: 	append_data.count = count;
652: 	append_data.target_mask = maskptr;
653: 	append_data.pandas = pandas;
654: 
655: 	switch (input.GetType().id()) {
656: 	case LogicalTypeId::ENUM: {
657: 		auto size = EnumType::GetSize(input.GetType());
658: 		append_data.physical_type = input.GetType().InternalType();
659: 		if (size <= (idx_t)NumericLimits<int8_t>::Maximum()) {
660: 			may_have_null = ConvertColumnCategorical<int8_t>(append_data);
661: 		} else if (size <= (idx_t)NumericLimits<int16_t>::Maximum()) {
662: 			may_have_null = ConvertColumnCategorical<int16_t>(append_data);
663: 		} else if (size <= (idx_t)NumericLimits<int32_t>::Maximum()) {
664: 			may_have_null = ConvertColumnCategorical<int32_t>(append_data);
665: 		} else {
666: 			throw InternalException("Size not supported on ENUM types");
667: 		}
668: 	} break;
669: 	case LogicalTypeId::BOOLEAN:
670: 		may_have_null = ConvertColumnRegular<bool>(append_data);
671: 		break;
672: 	case LogicalTypeId::TINYINT:
673: 		may_have_null = ConvertColumnRegular<int8_t>(append_data);
674: 		break;
675: 	case LogicalTypeId::SMALLINT:
676: 		may_have_null = ConvertColumnRegular<int16_t>(append_data);
677: 		break;
678: 	case LogicalTypeId::INTEGER:
679: 		may_have_null = ConvertColumnRegular<int32_t>(append_data);
680: 		break;
681: 	case LogicalTypeId::BIGINT:
682: 		may_have_null = ConvertColumnRegular<int64_t>(append_data);
683: 		break;
684: 	case LogicalTypeId::UTINYINT:
685: 		may_have_null = ConvertColumnRegular<uint8_t>(append_data);
686: 		break;
687: 	case LogicalTypeId::USMALLINT:
688: 		may_have_null = ConvertColumnRegular<uint16_t>(append_data);
689: 		break;
690: 	case LogicalTypeId::UINTEGER:
691: 		may_have_null = ConvertColumnRegular<uint32_t>(append_data);
692: 		break;
693: 	case LogicalTypeId::UBIGINT:
694: 		may_have_null = ConvertColumnRegular<uint64_t>(append_data);
695: 		break;
696: 	case LogicalTypeId::HUGEINT:
697: 		may_have_null = ConvertColumn<hugeint_t, double, duckdb_py_convert::IntegralConvert>(append_data);
698: 		break;
699: 	case LogicalTypeId::UHUGEINT:
700: 		may_have_null = ConvertColumn<uhugeint_t, double, duckdb_py_convert::IntegralConvert>(append_data);
701: 		break;
702: 	case LogicalTypeId::FLOAT:
703: 		may_have_null = ConvertColumnRegular<float>(append_data);
704: 		break;
705: 	case LogicalTypeId::DOUBLE:
706: 		may_have_null = ConvertColumnRegular<double>(append_data);
707: 		break;
708: 	case LogicalTypeId::DECIMAL:
709: 		may_have_null = ConvertDecimal(append_data);
710: 		break;
711: 	case LogicalTypeId::TIMESTAMP:
712: 	case LogicalTypeId::TIMESTAMP_TZ:
713: 	case LogicalTypeId::TIMESTAMP_SEC:
714: 	case LogicalTypeId::TIMESTAMP_MS:
715: 	case LogicalTypeId::TIMESTAMP_NS:
716: 		may_have_null = ConvertColumn<timestamp_t, int64_t, duckdb_py_convert::TimestampConvertNano>(append_data);
717: 		break;
718: 	case LogicalTypeId::DATE:
719: 		may_have_null = ConvertColumn<date_t, int64_t, duckdb_py_convert::DateConvert>(append_data);
720: 		break;
721: 	case LogicalTypeId::TIME:
722: 		may_have_null = ConvertColumn<dtime_t, PyObject *, duckdb_py_convert::TimeConvert>(append_data);
723: 		break;
724: 	case LogicalTypeId::INTERVAL:
725: 		may_have_null = ConvertColumn<interval_t, int64_t, duckdb_py_convert::IntervalConvert>(append_data);
726: 		break;
727: 	case LogicalTypeId::VARCHAR:
728: 		may_have_null = ConvertColumn<string_t, PyObject *, duckdb_py_convert::StringConvert>(append_data);
729: 		break;
730: 	case LogicalTypeId::BLOB:
731: 		may_have_null = ConvertColumn<string_t, PyObject *, duckdb_py_convert::BlobConvert>(append_data);
732: 		break;
733: 	case LogicalTypeId::BIT:
734: 		may_have_null = ConvertColumn<string_t, PyObject *, duckdb_py_convert::BitConvert>(append_data);
735: 		break;
736: 	case LogicalTypeId::LIST:
737: 		may_have_null = ConvertNested<py::object, duckdb_py_convert::ListConvert>(append_data);
738: 		break;
739: 	case LogicalTypeId::ARRAY:
740: 		may_have_null = ConvertNested<py::object, duckdb_py_convert::ArrayConvert>(append_data);
741: 		break;
742: 	case LogicalTypeId::MAP:
743: 		may_have_null = ConvertNested<py::object, duckdb_py_convert::MapConvert>(append_data);
744: 		break;
745: 	case LogicalTypeId::UNION:
746: 		may_have_null = ConvertNested<py::object, duckdb_py_convert::UnionConvert>(append_data);
747: 		break;
748: 	case LogicalTypeId::STRUCT:
749: 		may_have_null = ConvertNested<py::object, duckdb_py_convert::StructConvert>(append_data);
750: 		break;
751: 	case LogicalTypeId::UUID:
752: 		may_have_null = ConvertColumn<hugeint_t, PyObject *, duckdb_py_convert::UUIDConvert>(append_data);
753: 		break;
754: 
755: 	default:
756: 		throw NotImplementedException("Unsupported type \"%s\"", input.GetType().ToString());
757: 	}
758: 	if (may_have_null) {
759: 		requires_mask = true;
760: 	}
761: 	data->count += count;
762: 	mask->count += count;
763: }
764: 
765: py::object ArrayWrapper::ToArray() const {
766: 	D_ASSERT(data->array && mask->array);
767: 	data->Resize(data->count);
768: 	if (!requires_mask) {
769: 		return std::move(data->array);
770: 	}
771: 	mask->Resize(mask->count);
772: 	// construct numpy arrays from the data and the mask
773: 	auto values = std::move(data->array);
774: 	auto nullmask = std::move(mask->array);
775: 
776: 	// create masked array and return it
777: 	auto masked_array = py::module::import("numpy.ma").attr("masked_array")(values, nullmask);
778: 	return masked_array;
779: }
780: 
781: } // namespace duckdb
[end of tools/pythonpkg/src/numpy/array_wrapper.cpp]
[start of tools/pythonpkg/src/numpy/numpy_result_conversion.cpp]
1: #include "duckdb_python/numpy/array_wrapper.hpp"
2: #include "duckdb_python/numpy/numpy_result_conversion.hpp"
3: 
4: namespace duckdb {
5: 
6: NumpyResultConversion::NumpyResultConversion(const vector<LogicalType> &types, idx_t initial_capacity,
7:                                              const ClientProperties &client_properties, bool pandas)
8:     : count(0), capacity(0) {
9: 	owned_data.reserve(types.size());
10: 	for (auto &type : types) {
11: 		owned_data.emplace_back(type, client_properties, pandas);
12: 	}
13: 	Resize(initial_capacity);
14: }
15: 
16: void NumpyResultConversion::Resize(idx_t new_capacity) {
17: 	if (capacity == 0) {
18: 		for (auto &data : owned_data) {
19: 			data.Initialize(new_capacity);
20: 		}
21: 	} else {
22: 		for (auto &data : owned_data) {
23: 			data.Resize(new_capacity);
24: 		}
25: 	}
26: 	capacity = new_capacity;
27: }
28: 
29: void NumpyResultConversion::Append(DataChunk &chunk) {
30: 	if (count + chunk.size() > capacity) {
31: 		Resize(capacity * 2);
32: 	}
33: 	auto chunk_types = chunk.GetTypes();
34: 	auto source_offset = 0;
35: 	auto source_size = chunk.size();
36: 	auto to_append = chunk.size();
37: 	for (idx_t col_idx = 0; col_idx < owned_data.size(); col_idx++) {
38: 		owned_data[col_idx].Append(count, chunk.data[col_idx], source_size, source_offset, to_append);
39: 	}
40: 	count += to_append;
41: #ifdef DEBUG
42: 	for (auto &data : owned_data) {
43: 		D_ASSERT(data.data->count == count);
44: 		D_ASSERT(data.mask->count == count);
45: 	}
46: #endif
47: }
48: 
49: } // namespace duckdb
[end of tools/pythonpkg/src/numpy/numpy_result_conversion.cpp]
[start of tools/pythonpkg/src/pyresult.cpp]
1: #include "duckdb_python/pyrelation.hpp"
2: #include "duckdb_python/pyconnection/pyconnection.hpp"
3: #include "duckdb_python/pyresult.hpp"
4: #include "duckdb_python/python_objects.hpp"
5: 
6: #include "duckdb_python/arrow/arrow_array_stream.hpp"
7: #include "duckdb/common/arrow/arrow.hpp"
8: #include "duckdb/common/arrow/arrow_converter.hpp"
9: #include "duckdb/common/arrow/arrow_wrapper.hpp"
10: #include "duckdb/common/arrow/result_arrow_wrapper.hpp"
11: #include "duckdb/common/types/date.hpp"
12: #include "duckdb/common/types/hugeint.hpp"
13: #include "duckdb/common/types/uhugeint.hpp"
14: #include "duckdb/common/types/time.hpp"
15: #include "duckdb/common/types/timestamp.hpp"
16: #include "duckdb/common/types/uuid.hpp"
17: #include "duckdb_python/numpy/array_wrapper.hpp"
18: #include "duckdb/common/exception.hpp"
19: #include "duckdb/common/enums/stream_execution_result.hpp"
20: #include "duckdb_python/arrow/arrow_export_utils.hpp"
21: #include "duckdb/main/chunk_scan_state/query_result.hpp"
22: 
23: namespace duckdb {
24: 
25: DuckDBPyResult::DuckDBPyResult(unique_ptr<QueryResult> result_p) : result(std::move(result_p)) {
26: 	if (!result) {
27: 		throw InternalException("PyResult created without a result object");
28: 	}
29: }
30: 
31: DuckDBPyResult::~DuckDBPyResult() {
32: 	try {
33: 		py::gil_scoped_release gil;
34: 		result.reset();
35: 		current_chunk.reset();
36: 	} catch (...) { // NOLINT
37: 	}
38: }
39: 
40: const vector<string> &DuckDBPyResult::GetNames() {
41: 	if (!result) {
42: 		throw InternalException("Calling GetNames without a result object");
43: 	}
44: 	return result->names;
45: }
46: 
47: const vector<LogicalType> &DuckDBPyResult::GetTypes() {
48: 	if (!result) {
49: 		throw InternalException("Calling GetTypes without a result object");
50: 	}
51: 	return result->types;
52: }
53: 
54: unique_ptr<DataChunk> DuckDBPyResult::FetchChunk() {
55: 	if (!result) {
56: 		throw InternalException("FetchChunk called without a result object");
57: 	}
58: 	return FetchNext(*result);
59: }
60: 
61: unique_ptr<DataChunk> DuckDBPyResult::FetchNext(QueryResult &query_result) {
62: 	if (!result_closed && query_result.type == QueryResultType::STREAM_RESULT &&
63: 	    !query_result.Cast<StreamQueryResult>().IsOpen()) {
64: 		result_closed = true;
65: 		return nullptr;
66: 	}
67: 	if (query_result.type == QueryResultType::STREAM_RESULT) {
68: 		auto &stream_result = query_result.Cast<StreamQueryResult>();
69: 		StreamExecutionResult execution_result;
70: 		while (!StreamQueryResult::IsChunkReady(execution_result = stream_result.ExecuteTask())) {
71: 			{
72: 				py::gil_scoped_acquire gil;
73: 				if (PyErr_CheckSignals() != 0) {
74: 					throw std::runtime_error("Query interrupted");
75: 				}
76: 			}
77: 			if (execution_result == StreamExecutionResult::BLOCKED) {
78: 				stream_result.WaitForTask();
79: 			}
80: 		}
81: 		if (execution_result == StreamExecutionResult::EXECUTION_CANCELLED) {
82: 			throw InvalidInputException("The execution of the query was cancelled before it could finish, likely "
83: 			                            "caused by executing a different query");
84: 		}
85: 		if (execution_result == StreamExecutionResult::EXECUTION_ERROR) {
86: 			stream_result.ThrowError();
87: 		}
88: 	}
89: 	auto chunk = query_result.Fetch();
90: 	if (query_result.HasError()) {
91: 		query_result.ThrowError();
92: 	}
93: 	return chunk;
94: }
95: 
96: unique_ptr<DataChunk> DuckDBPyResult::FetchNextRaw(QueryResult &query_result) {
97: 	if (!result_closed && query_result.type == QueryResultType::STREAM_RESULT &&
98: 	    !query_result.Cast<StreamQueryResult>().IsOpen()) {
99: 		result_closed = true;
100: 		return nullptr;
101: 	}
102: 	auto chunk = query_result.FetchRaw();
103: 	if (query_result.HasError()) {
104: 		query_result.ThrowError();
105: 	}
106: 	return chunk;
107: }
108: 
109: Optional<py::tuple> DuckDBPyResult::Fetchone() {
110: 	{
111: 		py::gil_scoped_release release;
112: 		if (!result) {
113: 			throw InvalidInputException("result closed");
114: 		}
115: 		if (!current_chunk || chunk_offset >= current_chunk->size()) {
116: 			current_chunk = FetchNext(*result);
117: 			chunk_offset = 0;
118: 		}
119: 	}
120: 
121: 	if (!current_chunk || current_chunk->size() == 0) {
122: 		return py::none();
123: 	}
124: 	py::tuple res(result->types.size());
125: 
126: 	for (idx_t col_idx = 0; col_idx < result->types.size(); col_idx++) {
127: 		auto &mask = FlatVector::Validity(current_chunk->data[col_idx]);
128: 		if (!mask.RowIsValid(chunk_offset)) {
129: 			res[col_idx] = py::none();
130: 			continue;
131: 		}
132: 		auto val = current_chunk->data[col_idx].GetValue(chunk_offset);
133: 		res[col_idx] = PythonObject::FromValue(val, result->types[col_idx], result->client_properties);
134: 	}
135: 	chunk_offset++;
136: 	return res;
137: }
138: 
139: py::list DuckDBPyResult::Fetchmany(idx_t size) {
140: 	py::list res;
141: 	for (idx_t i = 0; i < size; i++) {
142: 		auto fres = Fetchone();
143: 		if (fres.is_none()) {
144: 			break;
145: 		}
146: 		res.append(fres);
147: 	}
148: 	return res;
149: }
150: 
151: py::list DuckDBPyResult::Fetchall() {
152: 	py::list res;
153: 	while (true) {
154: 		auto fres = Fetchone();
155: 		if (fres.is_none()) {
156: 			break;
157: 		}
158: 		res.append(fres);
159: 	}
160: 	return res;
161: }
162: 
163: py::dict DuckDBPyResult::FetchNumpy() {
164: 	return FetchNumpyInternal();
165: }
166: 
167: void DuckDBPyResult::FillNumpy(py::dict &res, idx_t col_idx, NumpyResultConversion &conversion, const char *name) {
168: 	if (result->types[col_idx].id() == LogicalTypeId::ENUM) {
169: 		// first we (might) need to create the categorical type
170: 		if (categories_type.find(col_idx) == categories_type.end()) {
171: 			// Equivalent to: pandas.CategoricalDtype(['a', 'b'], ordered=True)
172: 			categories_type[col_idx] = py::module::import("pandas").attr("CategoricalDtype")(categories[col_idx], true);
173: 		}
174: 		// Equivalent to: pandas.Categorical.from_codes(codes=[0, 1, 0, 1], dtype=dtype)
175: 		res[name] = py::module::import("pandas")
176: 		                .attr("Categorical")
177: 		                .attr("from_codes")(conversion.ToArray(col_idx), py::arg("dtype") = categories_type[col_idx]);
178: 	} else {
179: 		res[name] = conversion.ToArray(col_idx);
180: 	}
181: }
182: 
183: void InsertCategory(QueryResult &result, unordered_map<idx_t, py::list> &categories) {
184: 	for (idx_t col_idx = 0; col_idx < result.types.size(); col_idx++) {
185: 		auto &type = result.types[col_idx];
186: 		if (type.id() == LogicalTypeId::ENUM) {
187: 			// It's an ENUM type, in addition to converting the codes we must convert the categories
188: 			if (categories.find(col_idx) == categories.end()) {
189: 				auto &categories_list = EnumType::GetValuesInsertOrder(type);
190: 				auto categories_size = EnumType::GetSize(type);
191: 				for (idx_t i = 0; i < categories_size; i++) {
192: 					categories[col_idx].append(py::cast(categories_list.GetValue(i).ToString()));
193: 				}
194: 			}
195: 		}
196: 	}
197: }
198: 
199: unique_ptr<NumpyResultConversion> DuckDBPyResult::InitializeNumpyConversion(bool pandas) {
200: 	if (!result) {
201: 		throw InvalidInputException("result closed");
202: 	}
203: 
204: 	idx_t initial_capacity = STANDARD_VECTOR_SIZE * 2ULL;
205: 	if (result->type == QueryResultType::MATERIALIZED_RESULT) {
206: 		// materialized query result: we know exactly how much space we need
207: 		auto &materialized = result->Cast<MaterializedQueryResult>();
208: 		initial_capacity = materialized.RowCount();
209: 	}
210: 
211: 	auto conversion =
212: 	    make_uniq<NumpyResultConversion>(result->types, initial_capacity, result->client_properties, pandas);
213: 	return conversion;
214: }
215: 
216: py::dict DuckDBPyResult::FetchNumpyInternal(bool stream, idx_t vectors_per_chunk,
217:                                             unique_ptr<NumpyResultConversion> conversion_p) {
218: 	if (!result) {
219: 		throw InvalidInputException("result closed");
220: 	}
221: 	if (!conversion_p) {
222: 		conversion_p = InitializeNumpyConversion();
223: 	}
224: 	auto &conversion = *conversion_p;
225: 
226: 	if (result->type == QueryResultType::MATERIALIZED_RESULT) {
227: 		auto &materialized = result->Cast<MaterializedQueryResult>();
228: 		for (auto &chunk : materialized.Collection().Chunks()) {
229: 			conversion.Append(chunk);
230: 		}
231: 		InsertCategory(materialized, categories);
232: 		materialized.Collection().Reset();
233: 	} else {
234: 		D_ASSERT(result->type == QueryResultType::STREAM_RESULT);
235: 		if (!stream) {
236: 			vectors_per_chunk = NumericLimits<idx_t>::Maximum();
237: 		}
238: 		auto &stream_result = result->Cast<StreamQueryResult>();
239: 		for (idx_t count_vec = 0; count_vec < vectors_per_chunk; count_vec++) {
240: 			if (!stream_result.IsOpen()) {
241: 				break;
242: 			}
243: 			unique_ptr<DataChunk> chunk;
244: 			{
245: 				py::gil_scoped_release release;
246: 				chunk = FetchNextRaw(stream_result);
247: 			}
248: 			if (!chunk || chunk->size() == 0) {
249: 				//! finished
250: 				break;
251: 			}
252: 			conversion.Append(*chunk);
253: 			InsertCategory(stream_result, categories);
254: 		}
255: 	}
256: 
257: 	// now that we have materialized the result in contiguous arrays, construct the actual NumPy arrays or categorical
258: 	// types
259: 	py::dict res;
260: 	auto names = result->names;
261: 	QueryResult::DeduplicateColumns(names);
262: 	for (idx_t col_idx = 0; col_idx < result->names.size(); col_idx++) {
263: 		auto &name = names[col_idx];
264: 		FillNumpy(res, col_idx, conversion, name.c_str());
265: 	}
266: 	return res;
267: }
268: 
269: // TODO: unify these with an enum/flag to indicate which conversions to do
270: void DuckDBPyResult::ChangeToTZType(PandasDataFrame &df) {
271: 	auto names = df.attr("columns").cast<vector<string>>();
272: 
273: 	for (idx_t i = 0; i < result->ColumnCount(); i++) {
274: 		if (result->types[i] == LogicalType::TIMESTAMP_TZ) {
275: 			// first localize to UTC then convert to timezone_config
276: 			auto utc_local = df[names[i].c_str()].attr("dt").attr("tz_localize")("UTC");
277: 			df.attr("__setitem__")(names[i].c_str(),
278: 			                       utc_local.attr("dt").attr("tz_convert")(result->client_properties.time_zone));
279: 		}
280: 	}
281: }
282: 
283: // TODO: unify these with an enum/flag to indicate which conversions to perform
284: void DuckDBPyResult::ChangeDateToDatetime(PandasDataFrame &df) {
285: 	auto names = df.attr("columns").cast<vector<string>>();
286: 
287: 	for (idx_t i = 0; i < result->ColumnCount(); i++) {
288: 		if (result->types[i] == LogicalType::DATE) {
289: 			df.attr("__setitem__")(names[i].c_str(), df[names[i].c_str()].attr("dt").attr("date"));
290: 		}
291: 	}
292: }
293: 
294: PandasDataFrame DuckDBPyResult::FrameFromNumpy(bool date_as_object, const py::handle &o) {
295: 	PandasDataFrame df = py::cast<PandasDataFrame>(py::module::import("pandas").attr("DataFrame").attr("from_dict")(o));
296: 	// Unfortunately we have to do a type change here for timezones since these types are not supported by numpy
297: 	ChangeToTZType(df);
298: 	if (date_as_object) {
299: 		ChangeDateToDatetime(df);
300: 	}
301: 	return df;
302: }
303: 
304: PandasDataFrame DuckDBPyResult::FetchDF(bool date_as_object) {
305: 	auto conversion = InitializeNumpyConversion(true);
306: 	return FrameFromNumpy(date_as_object, FetchNumpyInternal(false, 1, std::move(conversion)));
307: }
308: 
309: PandasDataFrame DuckDBPyResult::FetchDFChunk(idx_t num_of_vectors, bool date_as_object) {
310: 	auto conversion = InitializeNumpyConversion(true);
311: 	return FrameFromNumpy(date_as_object, FetchNumpyInternal(true, num_of_vectors, std::move(conversion)));
312: }
313: 
314: py::dict DuckDBPyResult::FetchPyTorch() {
315: 	auto result_dict = FetchNumpyInternal();
316: 	auto from_numpy = py::module::import("torch").attr("from_numpy");
317: 	for (auto &item : result_dict) {
318: 		result_dict[item.first] = from_numpy(item.second);
319: 	}
320: 	return result_dict;
321: }
322: 
323: py::dict DuckDBPyResult::FetchTF() {
324: 	auto result_dict = FetchNumpyInternal();
325: 	auto convert_to_tensor = py::module::import("tensorflow").attr("convert_to_tensor");
326: 	for (auto &item : result_dict) {
327: 		result_dict[item.first] = convert_to_tensor(item.second);
328: 	}
329: 	return result_dict;
330: }
331: 
332: bool DuckDBPyResult::FetchArrowChunk(ChunkScanState &scan_state, py::list &batches, idx_t rows_per_batch,
333:                                      bool to_polars) {
334: 	ArrowArray data;
335: 	idx_t count;
336: 	auto &query_result = *result.get();
337: 	{
338: 		py::gil_scoped_release release;
339: 		count = ArrowUtil::FetchChunk(scan_state, query_result.client_properties, rows_per_batch, &data);
340: 	}
341: 	if (count == 0) {
342: 		return false;
343: 	}
344: 	ArrowSchema arrow_schema;
345: 	auto names = query_result.names;
346: 	if (to_polars) {
347: 		QueryResult::DeduplicateColumns(names);
348: 	}
349: 	ArrowConverter::ToArrowSchema(&arrow_schema, query_result.types, names, query_result.client_properties);
350: 	TransformDuckToArrowChunk(arrow_schema, data, batches);
351: 	return true;
352: }
353: 
354: py::list DuckDBPyResult::FetchAllArrowChunks(idx_t rows_per_batch, bool to_polars) {
355: 	if (!result) {
356: 		throw InvalidInputException("result closed");
357: 	}
358: 	auto pyarrow_lib_module = py::module::import("pyarrow").attr("lib");
359: 
360: 	py::list batches;
361: 	QueryResultChunkScanState scan_state(*result.get());
362: 	while (FetchArrowChunk(scan_state, batches, rows_per_batch, to_polars)) {
363: 	}
364: 	return batches;
365: }
366: 
367: duckdb::pyarrow::Table DuckDBPyResult::FetchArrowTable(idx_t rows_per_batch, bool to_polars) {
368: 	if (!result) {
369: 		throw InvalidInputException("There is no query result");
370: 	}
371: 	auto names = result->names;
372: 	if (to_polars) {
373: 		QueryResult::DeduplicateColumns(names);
374: 	}
375: 	return pyarrow::ToArrowTable(result->types, names, FetchAllArrowChunks(rows_per_batch, to_polars),
376: 	                             result->client_properties);
377: }
378: 
379: duckdb::pyarrow::RecordBatchReader DuckDBPyResult::FetchRecordBatchReader(idx_t rows_per_batch) {
380: 	if (!result) {
381: 		throw InvalidInputException("There is no query result");
382: 	}
383: 	py::gil_scoped_acquire acquire;
384: 	auto pyarrow_lib_module = py::module::import("pyarrow").attr("lib");
385: 	auto record_batch_reader_func = pyarrow_lib_module.attr("RecordBatchReader").attr("_import_from_c");
386: 	//! We have to construct an Arrow Array Stream
387: 	ResultArrowArrayStreamWrapper *result_stream = new ResultArrowArrayStreamWrapper(std::move(result), rows_per_batch);
388: 	py::object record_batch_reader = record_batch_reader_func((uint64_t)&result_stream->stream); // NOLINT
389: 	return py::cast<duckdb::pyarrow::RecordBatchReader>(record_batch_reader);
390: }
391: 
392: py::str GetTypeToPython(const LogicalType &type) {
393: 	switch (type.id()) {
394: 	case LogicalTypeId::BOOLEAN:
395: 		return py::str("bool");
396: 	case LogicalTypeId::TINYINT:
397: 	case LogicalTypeId::SMALLINT:
398: 	case LogicalTypeId::INTEGER:
399: 	case LogicalTypeId::BIGINT:
400: 	case LogicalTypeId::UTINYINT:
401: 	case LogicalTypeId::USMALLINT:
402: 	case LogicalTypeId::UINTEGER:
403: 	case LogicalTypeId::UBIGINT:
404: 	case LogicalTypeId::HUGEINT:
405: 	case LogicalTypeId::UHUGEINT:
406: 	case LogicalTypeId::FLOAT:
407: 	case LogicalTypeId::DOUBLE:
408: 	case LogicalTypeId::DECIMAL: {
409: 		return py::str("NUMBER");
410: 	}
411: 	case LogicalTypeId::VARCHAR: {
412: 		if (type.HasAlias() && type.GetAlias() == "JSON") {
413: 			return py::str("JSON");
414: 		} else {
415: 			return py::str("STRING");
416: 		}
417: 	}
418: 	case LogicalTypeId::BLOB:
419: 	case LogicalTypeId::BIT:
420: 		return py::str("BINARY");
421: 	case LogicalTypeId::TIMESTAMP:
422: 	case LogicalTypeId::TIMESTAMP_TZ:
423: 	case LogicalTypeId::TIMESTAMP_MS:
424: 	case LogicalTypeId::TIMESTAMP_NS:
425: 	case LogicalTypeId::TIMESTAMP_SEC: {
426: 		return py::str("DATETIME");
427: 	}
428: 	case LogicalTypeId::TIME:
429: 	case LogicalTypeId::TIME_TZ: {
430: 		return py::str("Time");
431: 	}
432: 	case LogicalTypeId::DATE: {
433: 		return py::str("Date");
434: 	}
435: 	case LogicalTypeId::STRUCT:
436: 	case LogicalTypeId::MAP:
437: 		return py::str("dict");
438: 	case LogicalTypeId::LIST: {
439: 		return py::str("list");
440: 	}
441: 	case LogicalTypeId::INTERVAL: {
442: 		return py::str("TIMEDELTA");
443: 	}
444: 	case LogicalTypeId::UUID: {
445: 		return py::str("UUID");
446: 	}
447: 	default:
448: 		return py::str(type.ToString());
449: 	}
450: }
451: 
452: py::list DuckDBPyResult::GetDescription(const vector<string> &names, const vector<LogicalType> &types) {
453: 	py::list desc;
454: 
455: 	for (idx_t col_idx = 0; col_idx < names.size(); col_idx++) {
456: 		auto py_name = py::str(names[col_idx]);
457: 		auto py_type = GetTypeToPython(types[col_idx]);
458: 		desc.append(py::make_tuple(py_name, py_type, py::none(), py::none(), py::none(), py::none(), py::none()));
459: 	}
460: 	return desc;
461: }
462: 
463: void DuckDBPyResult::Close() {
464: 	result = nullptr;
465: }
466: 
467: bool DuckDBPyResult::IsClosed() const {
468: 	return result_closed;
469: }
470: 
471: } // namespace duckdb
[end of tools/pythonpkg/src/pyresult.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: