You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
Support FROM clause in UPDATE statement
The FROM clause in the UPDATE statement currently gets silently ignored. It should either throw an error (as in SQLite) or be supported (as in Postgres).

```sql
CREATE TABLE terms(docid INTEGER, term INTEGER);
CREATE TABLE docs(id INTEGER, len INTEGER);
insert into docs values (1, 0), (2, 0);
insert into terms values (1, 1);
insert into terms values (2, 1);
insert into terms values (2, 2);
insert into terms values (2, 3);

UPDATE docs 
SET len = sq.len 
FROM ( 
    SELECT docid AS id, count(term) AS len 
    FROM terms 
    GROUP BY docid 
    ORDER BY docid 
) AS sq 
WHERE docs.id = sq.id;
select * from docs;
-- expected answer:
-- 1, 1
-- 2, 3
```

</issue>
<code>
[start of README.md]
1: <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="30">
2: 
3: [![Travis](https://api.travis-ci.org/cwida/duckdb.svg?branch=master)](https://travis-ci.org/cwida/duckdb)
4: [![CodeFactor](https://www.codefactor.io/repository/github/cwida/duckdb/badge)](https://www.codefactor.io/repository/github/cwida/duckdb)
5: [![Coverage Status](https://coveralls.io/repos/github/cwida/duckdb/badge.svg?branch=master)](https://coveralls.io/github/cwida/duckdb?branch=master)
6: [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3901452.svg)](https://zenodo.org/record/3901452)
7: 
8: 
9: ## Installation
10: If you just want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
11: 
12: ## Development
13: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`.
14: 
15: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
16: 
17: 
[end of README.md]
[start of src/include/duckdb/parser/statement/update_statement.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/parser/statement/update_statement.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/parser/parsed_expression.hpp"
12: #include "duckdb/parser/sql_statement.hpp"
13: #include "duckdb/parser/tableref.hpp"
14: #include "duckdb/common/vector.hpp"
15: 
16: namespace duckdb {
17: 
18: class UpdateStatement : public SQLStatement {
19: public:
20: 	UpdateStatement() : SQLStatement(StatementType::UPDATE_STATEMENT) {
21: 	}
22: 
23: 	unique_ptr<ParsedExpression> condition;
24: 	unique_ptr<TableRef> table;
25: 
26: 	vector<string> columns;
27: 	vector<unique_ptr<ParsedExpression>> expressions;
28: };
29: } // namespace duckdb
[end of src/include/duckdb/parser/statement/update_statement.hpp]
[start of src/parser/transform/statement/transform_update.cpp]
1: #include "duckdb/parser/statement/update_statement.hpp"
2: #include "duckdb/parser/transformer.hpp"
3: 
4: namespace duckdb {
5: using namespace std;
6: using namespace duckdb_libpgquery;
7: 
8: unique_ptr<UpdateStatement> Transformer::TransformUpdate(PGNode *node) {
9: 	auto stmt = reinterpret_cast<PGUpdateStmt *>(node);
10: 	assert(stmt);
11: 
12: 	auto result = make_unique<UpdateStatement>();
13: 
14: 	result->table = TransformRangeVar(stmt->relation);
15: 	result->condition = TransformExpression(stmt->whereClause);
16: 
17: 	auto root = stmt->targetList;
18: 	for (auto cell = root->head; cell != NULL; cell = cell->next) {
19: 		auto target = (PGResTarget *)(cell->data.ptr_value);
20: 		result->columns.push_back(target->name);
21: 		result->expressions.push_back(TransformExpression(target->val));
22: 	}
23: 	return result;
24: }
25: 
26: } // namespace duckdb
[end of src/parser/transform/statement/transform_update.cpp]
[start of src/planner/binder/statement/bind_update.cpp]
1: #include "duckdb/parser/statement/update_statement.hpp"
2: #include "duckdb/planner/binder.hpp"
3: #include "duckdb/planner/expression/bound_columnref_expression.hpp"
4: #include "duckdb/planner/expression/bound_default_expression.hpp"
5: #include "duckdb/planner/expression_binder/update_binder.hpp"
6: #include "duckdb/planner/expression_binder/where_binder.hpp"
7: #include "duckdb/planner/operator/logical_filter.hpp"
8: #include "duckdb/planner/operator/logical_get.hpp"
9: #include "duckdb/planner/operator/logical_projection.hpp"
10: #include "duckdb/planner/operator/logical_update.hpp"
11: #include "duckdb/planner/constraints/bound_check_constraint.hpp"
12: #include "duckdb/parser/expression/columnref_expression.hpp"
13: #include "duckdb/storage/data_table.hpp"
14: #include "duckdb/planner/bound_tableref.hpp"
15: #include "duckdb/planner/tableref/bound_basetableref.hpp"
16: 
17: #include <algorithm>
18: 
19: using namespace std;
20: 
21: namespace duckdb {
22: 
23: static void BindExtraColumns(TableCatalogEntry &table, LogicalGet &get, LogicalProjection &proj, LogicalUpdate &update,
24:                              unordered_set<column_t> &bound_columns) {
25: 	if (bound_columns.size() <= 1) {
26: 		return;
27: 	}
28: 	idx_t found_column_count = 0;
29: 	unordered_set<idx_t> found_columns;
30: 	for (idx_t i = 0; i < update.columns.size(); i++) {
31: 		if (bound_columns.find(update.columns[i]) != bound_columns.end()) {
32: 			// this column is referenced in the CHECK constraint
33: 			found_column_count++;
34: 			found_columns.insert(update.columns[i]);
35: 		}
36: 	}
37: 	if (found_column_count > 0 && found_column_count != bound_columns.size()) {
38: 		// columns in this CHECK constraint were referenced, but not all were part of the UPDATE
39: 		// add them to the scan and update set
40: 		for (auto &check_column_id : bound_columns) {
41: 			if (found_columns.find(check_column_id) != found_columns.end()) {
42: 				// column is already projected
43: 				continue;
44: 			}
45: 			// column is not projected yet: project it by adding the clause "i=i" to the set of updated columns
46: 			auto &column = table.columns[check_column_id];
47: 			// first add
48: 			update.expressions.push_back(make_unique<BoundColumnRefExpression>(
49: 			    column.type, ColumnBinding(proj.table_index, proj.expressions.size())));
50: 			proj.expressions.push_back(make_unique<BoundColumnRefExpression>(
51: 			    column.type, ColumnBinding(get.table_index, get.column_ids.size())));
52: 			get.column_ids.push_back(check_column_id);
53: 			update.columns.push_back(check_column_id);
54: 		}
55: 	}
56: }
57: 
58: static void BindUpdateConstraints(TableCatalogEntry &table, LogicalGet &get, LogicalProjection &proj,
59:                                   LogicalUpdate &update) {
60: 	// check the constraints and indexes of the table to see if we need to project any additional columns
61: 	// we do this for indexes with multiple columns and CHECK constraints in the UPDATE clause
62: 	// suppose we have a constraint CHECK(i + j < 10); now we need both i and j to check the constraint
63: 	// if we are only updating one of the two columns we add the other one to the UPDATE set
64: 	// with a "useless" update (i.e. i=i) so we can verify that the CHECK constraint is not violated
65: 	for (auto &constraint : table.bound_constraints) {
66: 		if (constraint->type == ConstraintType::CHECK) {
67: 			auto &check = *reinterpret_cast<BoundCheckConstraint *>(constraint.get());
68: 			// check constraint! check if we need to add any extra columns to the UPDATE clause
69: 			BindExtraColumns(table, get, proj, update, check.bound_columns);
70: 		}
71: 	}
72: 	// for index updates, we do the same, however, for index updates we always turn any update into an insert and a
73: 	// delete for the insert, we thus need all the columns to be available, hence we check if the update touches any
74: 	// index columns
75: 	update.is_index_update = false;
76: 	for (auto &index : table.storage->info->indexes) {
77: 		if (index->IndexIsUpdated(update.columns)) {
78: 			update.is_index_update = true;
79: 		}
80: 	}
81: 	if (update.is_index_update) {
82: 		// the update updates a column required by an index, push projections for all columns
83: 		unordered_set<column_t> all_columns;
84: 		for (idx_t i = 0; i < table.storage->types.size(); i++) {
85: 			all_columns.insert(i);
86: 		}
87: 		BindExtraColumns(table, get, proj, update, all_columns);
88: 	}
89: }
90: 
91: BoundStatement Binder::Bind(UpdateStatement &stmt) {
92: 	BoundStatement result;
93: 	// visit the table reference
94: 	auto bound_table = Bind(*stmt.table);
95: 	if (bound_table->type != TableReferenceType::BASE_TABLE) {
96: 		throw BinderException("Can only update base table!");
97: 	}
98: 	auto &table_binding = (BoundBaseTableRef &)*bound_table;
99: 	auto table = table_binding.table;
100: 
101: 	auto root = CreatePlan(*bound_table);
102: 	auto &get = (LogicalGet &)*root;
103: 	assert(root->type == LogicalOperatorType::GET);
104: 
105: 	if (!table->temporary) {
106: 		// update of persistent table: not read only!
107: 		this->read_only = false;
108: 	}
109: 	auto update = make_unique<LogicalUpdate>(table);
110: 	// bind the default values
111: 	BindDefaultValues(table->columns, update->bound_defaults);
112: 
113: 	// project any additional columns required for the condition/expressions
114: 	if (stmt.condition) {
115: 		WhereBinder binder(*this, context);
116: 		auto condition = binder.Bind(stmt.condition);
117: 
118: 		PlanSubqueries(&condition, &root);
119: 		auto filter = make_unique<LogicalFilter>(move(condition));
120: 		filter->AddChild(move(root));
121: 		root = move(filter);
122: 	}
123: 
124: 	assert(stmt.columns.size() == stmt.expressions.size());
125: 
126: 	auto proj_index = GenerateTableIndex();
127: 	vector<unique_ptr<Expression>> projection_expressions;
128: 	for (idx_t i = 0; i < stmt.columns.size(); i++) {
129: 		auto &colname = stmt.columns[i];
130: 		auto &expr = stmt.expressions[i];
131: 		if (!table->ColumnExists(colname)) {
132: 			throw BinderException("Referenced update column %s not found in table!", colname);
133: 		}
134: 		auto &column = table->GetColumn(colname);
135: 		if (std::find(update->columns.begin(), update->columns.end(), column.oid) != update->columns.end()) {
136: 			throw BinderException("Multiple assignments to same column \"%s\"", colname);
137: 		}
138: 		update->columns.push_back(column.oid);
139: 
140: 		if (expr->type == ExpressionType::VALUE_DEFAULT) {
141: 			update->expressions.push_back(make_unique<BoundDefaultExpression>(column.type));
142: 		} else {
143: 			UpdateBinder binder(*this, context);
144: 			binder.target_type = column.type;
145: 			auto bound_expr = binder.Bind(expr);
146: 			PlanSubqueries(&bound_expr, &root);
147: 
148: 			update->expressions.push_back(make_unique<BoundColumnRefExpression>(
149: 			    bound_expr->return_type, ColumnBinding(proj_index, projection_expressions.size())));
150: 			projection_expressions.push_back(move(bound_expr));
151: 		}
152: 	}
153: 	// now create the projection
154: 	auto proj = make_unique<LogicalProjection>(proj_index, move(projection_expressions));
155: 	proj->AddChild(move(root));
156: 
157: 	// bind any extra columns necessary for CHECK constraints or indexes
158: 	BindUpdateConstraints(*table, get, *proj, *update);
159: 
160: 	// finally add the row id column to the projection list
161: 	proj->expressions.push_back(
162: 	    make_unique<BoundColumnRefExpression>(LOGICAL_ROW_TYPE, ColumnBinding(get.table_index, get.column_ids.size())));
163: 	get.column_ids.push_back(COLUMN_IDENTIFIER_ROW_ID);
164: 
165: 	// set the projection as child of the update node and finalize the result
166: 	update->AddChild(move(proj));
167: 
168: 	result.names = {"Count"};
169: 	result.types = {LogicalType::BIGINT};
170: 	result.plan = move(update);
171: 	return result;
172: }
173: 
174: } // namespace duckdb
[end of src/planner/binder/statement/bind_update.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: