You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
select * from range(4,15,6) miss one value 10
```
D select range(4,15,6)a;
|    a    |
|---------|
| [4, 10] |
Run Time: real 0.000 user 0.000000 sys 0.000000
D select * from range(4,15,6)a;
| range |
|-------|
| 4     |
Run Time: real 0.000 user 0.000000 sys 0.000000
D select * from range(4,15)a;
| range |
|-------|
| 4     |
| 5     |
| 6     |
| 7     |
| 8     |
| 9     |
| 10    |
| 11    |
| 12    |
| 13    |
| 14    |
Run Time: real 0.310 user 0.000000 sys 0.000000
D select * from range(4,15,3)a;
| range |
|-------|
| 4     |
| 7     |
| 10    |
Run Time: real 0.080 user 0.000000 sys 0.000000
D select * from range(4,15,5)a;
| range |
|-------|
| 4     |
| 9     |
Run Time: real 0.000 user 0.000000 sys 0.000000
```
tested on
DuckDB Web Shell
Database: v0.3.1-dev535
same problem. 

SELECT * FROM range(4,16,7) also miss 11

select * from range(4,15,6) miss one value 10
```
D select range(4,15,6)a;
|    a    |
|---------|
| [4, 10] |
Run Time: real 0.000 user 0.000000 sys 0.000000
D select * from range(4,15,6)a;
| range |
|-------|
| 4     |
Run Time: real 0.000 user 0.000000 sys 0.000000
D select * from range(4,15)a;
| range |
|-------|
| 4     |
| 5     |
| 6     |
| 7     |
| 8     |
| 9     |
| 10    |
| 11    |
| 12    |
| 13    |
| 14    |
Run Time: real 0.310 user 0.000000 sys 0.000000
D select * from range(4,15,3)a;
| range |
|-------|
| 4     |
| 7     |
| 10    |
Run Time: real 0.080 user 0.000000 sys 0.000000
D select * from range(4,15,5)a;
| range |
|-------|
| 4     |
| 9     |
Run Time: real 0.000 user 0.000000 sys 0.000000
```
tested on
DuckDB Web Shell
Database: v0.3.1-dev535
same problem. 

SELECT * FROM range(4,16,7) also miss 11


</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
3: </div>
4: <p>&nbsp;</p>
5: 
6: <p align="center">
7:   <a href="https://github.com/duckdb/duckdb/actions">
8:     <img src="https://github.com/cwida/duckdb/workflows/.github/workflows/main.yml/badge.svg?branch=master" alt=".github/workflows/main.yml">
9:   </a>
10:   <a href="https://www.codefactor.io/repository/github/cwida/duckdb">
11:     <img src="https://www.codefactor.io/repository/github/cwida/duckdb/badge" alt="CodeFactor"/>
12:   </a>
13:   <a href="https://app.codecov.io/gh/duckdb/duckdb">
14:     <img src="https://codecov.io/gh/duckdb/duckdb/branch/master/graph/badge.svg?token=FaxjcfFghN" alt="codecov"/>
15:   </a>
16: </p>
17: 
18: ## DuckDB
19: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on the goals of DuckDB, please refer to [the Why DuckDB page on our website](https://duckdb.org/docs/why_duckdb.html).
20: 
21: ## Installation
22: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
23: 
24: ## Data Import
25: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
26: 
27: ```sql
28: SELECT * FROM 'myfile.csv';
29: SELECT * FROM 'myfile.parquet';
30: ```
31: 
32: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
33: 
34: ## SQL Reference
35: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
36: 
37: ## Development
38: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`.
39: 
40: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
41: 
42: 
[end of README.md]
[start of src/common/vector_operations/generators.cpp]
1: //===--------------------------------------------------------------------===//
2: // generators.cpp
3: // Description: This file contains the implementation of different generators
4: //===--------------------------------------------------------------------===//
5: 
6: #include "duckdb/common/exception.hpp"
7: #include "duckdb/common/vector_operations/vector_operations.hpp"
8: #include "duckdb/common/limits.hpp"
9: 
10: namespace duckdb {
11: 
12: template <class T>
13: void TemplatedGenerateSequence(Vector &result, idx_t count, int64_t start, int64_t increment) {
14: 	D_ASSERT(result.GetType().IsNumeric());
15: 	if (start > NumericLimits<T>::Maximum() || increment > NumericLimits<T>::Maximum()) {
16: 		throw Exception("Sequence start or increment out of type range");
17: 	}
18: 	result.SetVectorType(VectorType::FLAT_VECTOR);
19: 	auto result_data = FlatVector::GetData<T>(result);
20: 	auto value = (T)start;
21: 	for (idx_t i = 0; i < count; i++) {
22: 		result_data[i] = value;
23: 		value += increment;
24: 	}
25: }
26: 
27: void VectorOperations::GenerateSequence(Vector &result, idx_t count, int64_t start, int64_t increment) {
28: 	if (!result.GetType().IsNumeric()) {
29: 		throw InvalidTypeException(result.GetType(), "Can only generate sequences for numeric values!");
30: 	}
31: 	switch (result.GetType().InternalType()) {
32: 	case PhysicalType::INT8:
33: 		TemplatedGenerateSequence<int8_t>(result, count, start, increment);
34: 		break;
35: 	case PhysicalType::INT16:
36: 		TemplatedGenerateSequence<int16_t>(result, count, start, increment);
37: 		break;
38: 	case PhysicalType::INT32:
39: 		TemplatedGenerateSequence<int32_t>(result, count, start, increment);
40: 		break;
41: 	case PhysicalType::INT64:
42: 		TemplatedGenerateSequence<int64_t>(result, count, start, increment);
43: 		break;
44: 	case PhysicalType::FLOAT:
45: 		TemplatedGenerateSequence<float>(result, count, start, increment);
46: 		break;
47: 	case PhysicalType::DOUBLE:
48: 		TemplatedGenerateSequence<double>(result, count, start, increment);
49: 		break;
50: 	default:
51: 		throw NotImplementedException("Unimplemented type for generate sequence");
52: 	}
53: }
54: 
55: template <class T>
56: void TemplatedGenerateSequence(Vector &result, idx_t count, const SelectionVector &sel, int64_t start,
57:                                int64_t increment) {
58: 	D_ASSERT(result.GetType().IsNumeric());
59: 	if (start > NumericLimits<T>::Maximum() || increment > NumericLimits<T>::Maximum()) {
60: 		throw Exception("Sequence start or increment out of type range");
61: 	}
62: 	result.SetVectorType(VectorType::FLAT_VECTOR);
63: 	auto result_data = FlatVector::GetData<T>(result);
64: 	auto value = (T)start;
65: 	for (idx_t i = 0; i < count; i++) {
66: 		auto idx = sel.get_index(i);
67: 		result_data[idx] = value + increment * idx;
68: 	}
69: }
70: 
71: void VectorOperations::GenerateSequence(Vector &result, idx_t count, const SelectionVector &sel, int64_t start,
72:                                         int64_t increment) {
73: 	if (!result.GetType().IsNumeric()) {
74: 		throw InvalidTypeException(result.GetType(), "Can only generate sequences for numeric values!");
75: 	}
76: 	switch (result.GetType().InternalType()) {
77: 	case PhysicalType::INT8:
78: 		TemplatedGenerateSequence<int8_t>(result, count, sel, start, increment);
79: 		break;
80: 	case PhysicalType::INT16:
81: 		TemplatedGenerateSequence<int16_t>(result, count, sel, start, increment);
82: 		break;
83: 	case PhysicalType::INT32:
84: 		TemplatedGenerateSequence<int32_t>(result, count, sel, start, increment);
85: 		break;
86: 	case PhysicalType::INT64:
87: 		TemplatedGenerateSequence<int64_t>(result, count, sel, start, increment);
88: 		break;
89: 	case PhysicalType::FLOAT:
90: 		TemplatedGenerateSequence<float>(result, count, sel, start, increment);
91: 		break;
92: 	case PhysicalType::DOUBLE:
93: 		TemplatedGenerateSequence<double>(result, count, sel, start, increment);
94: 		break;
95: 	default:
96: 		throw NotImplementedException("Unimplemented type for generate sequence");
97: 	}
98: }
99: 
100: } // namespace duckdb
[end of src/common/vector_operations/generators.cpp]
[start of src/function/table/range.cpp]
1: #include "duckdb/function/table/range.hpp"
2: #include "duckdb/function/table/summary.hpp"
3: #include "duckdb/function/table_function.hpp"
4: #include "duckdb/function/function_set.hpp"
5: #include "duckdb/common/algorithm.hpp"
6: #include "duckdb/common/operator/add.hpp"
7: 
8: namespace duckdb {
9: 
10: //===--------------------------------------------------------------------===//
11: // Range (integers)
12: //===--------------------------------------------------------------------===//
13: struct RangeFunctionBindData : public TableFunctionData {
14: 	int64_t start;
15: 	int64_t end;
16: 	int64_t increment;
17: };
18: 
19: template <bool GENERATE_SERIES>
20: static unique_ptr<FunctionData>
21: RangeFunctionBind(ClientContext &context, vector<Value> &inputs, unordered_map<string, Value> &named_parameters,
22:                   vector<LogicalType> &input_table_types, vector<string> &input_table_names,
23:                   vector<LogicalType> &return_types, vector<string> &names) {
24: 	auto result = make_unique<RangeFunctionBindData>();
25: 	if (inputs.size() < 2) {
26: 		// single argument: only the end is specified
27: 		result->start = 0;
28: 		result->end = inputs[0].GetValue<int64_t>();
29: 	} else {
30: 		// two arguments: first two arguments are start and end
31: 		result->start = inputs[0].GetValue<int64_t>();
32: 		result->end = inputs[1].GetValue<int64_t>();
33: 	}
34: 	if (inputs.size() < 3) {
35: 		result->increment = 1;
36: 	} else {
37: 		result->increment = inputs[2].GetValue<int64_t>();
38: 	}
39: 	if (result->increment == 0) {
40: 		throw BinderException("interval cannot be 0!");
41: 	}
42: 	if (result->start > result->end && result->increment > 0) {
43: 		throw BinderException("start is bigger than end, but increment is positive: cannot generate infinite series");
44: 	} else if (result->start < result->end && result->increment < 0) {
45: 		throw BinderException("start is smaller than end, but increment is negative: cannot generate infinite series");
46: 	}
47: 	return_types.push_back(LogicalType::BIGINT);
48: 	if (GENERATE_SERIES) {
49: 		// generate_series has inclusive bounds on the RHS
50: 		if (result->increment < 0) {
51: 			result->end = result->end - 1;
52: 		} else {
53: 			result->end = result->end + 1;
54: 		}
55: 		names.emplace_back("generate_series");
56: 	} else {
57: 		names.emplace_back("range");
58: 	}
59: 	return move(result);
60: }
61: 
62: struct RangeFunctionState : public FunctionOperatorData {
63: 	RangeFunctionState() : current_idx(0) {
64: 	}
65: 
66: 	int64_t current_idx;
67: };
68: 
69: static unique_ptr<FunctionOperatorData> RangeFunctionInit(ClientContext &context, const FunctionData *bind_data,
70:                                                           const vector<column_t> &column_ids,
71:                                                           TableFilterCollection *filters) {
72: 	return make_unique<RangeFunctionState>();
73: }
74: 
75: static void RangeFunction(ClientContext &context, const FunctionData *bind_data_p, FunctionOperatorData *state_p,
76:                           DataChunk *input, DataChunk &output) {
77: 	auto &bind_data = (RangeFunctionBindData &)*bind_data_p;
78: 	auto &state = (RangeFunctionState &)*state_p;
79: 
80: 	auto increment = bind_data.increment;
81: 	auto end = bind_data.end;
82: 	int64_t current_value = bind_data.start + (int64_t)increment * state.current_idx;
83: 	// set the result vector as a sequence vector
84: 	output.data[0].Sequence(current_value, increment);
85: 	idx_t remaining = MinValue<idx_t>((end - current_value) / increment, STANDARD_VECTOR_SIZE);
86: 	// increment the index pointer by the remaining count
87: 	state.current_idx += remaining;
88: 	output.SetCardinality(remaining);
89: }
90: 
91: unique_ptr<NodeStatistics> RangeCardinality(ClientContext &context, const FunctionData *bind_data_p) {
92: 	auto &bind_data = (RangeFunctionBindData &)*bind_data_p;
93: 	idx_t cardinality = (bind_data.end - bind_data.start) / bind_data.increment;
94: 	return make_unique<NodeStatistics>(cardinality, cardinality);
95: }
96: 
97: //===--------------------------------------------------------------------===//
98: // Range (timestamp)
99: //===--------------------------------------------------------------------===//
100: struct RangeDateTimeBindData : public TableFunctionData {
101: 	timestamp_t start;
102: 	timestamp_t end;
103: 	interval_t increment;
104: 	bool inclusive_bound;
105: 	bool greater_than_check;
106: 
107: 	bool Finished(timestamp_t current_value) {
108: 		if (greater_than_check) {
109: 			if (inclusive_bound) {
110: 				return current_value > end;
111: 			} else {
112: 				return current_value >= end;
113: 			}
114: 		} else {
115: 			if (inclusive_bound) {
116: 				return current_value < end;
117: 			} else {
118: 				return current_value <= end;
119: 			}
120: 		}
121: 	}
122: };
123: 
124: template <bool GENERATE_SERIES>
125: static unique_ptr<FunctionData>
126: RangeDateTimeBind(ClientContext &context, vector<Value> &inputs, unordered_map<string, Value> &named_parameters,
127:                   vector<LogicalType> &input_table_types, vector<string> &input_table_names,
128:                   vector<LogicalType> &return_types, vector<string> &names) {
129: 	auto result = make_unique<RangeDateTimeBindData>();
130: 	D_ASSERT(inputs.size() == 3);
131: 	result->start = inputs[0].GetValue<timestamp_t>();
132: 	result->end = inputs[1].GetValue<timestamp_t>();
133: 	result->increment = inputs[2].GetValue<interval_t>();
134: 
135: 	if (result->increment.months == 0 && result->increment.days == 0 && result->increment.micros == 0) {
136: 		throw BinderException("interval cannot be 0!");
137: 	}
138: 	// all elements should point in the same direction
139: 	if (result->increment.months > 0 || result->increment.days > 0 || result->increment.micros > 0) {
140: 		if (result->increment.months < 0 || result->increment.days < 0 || result->increment.micros < 0) {
141: 			throw BinderException("RANGE with composite interval that has mixed signs is not supported");
142: 		}
143: 		result->greater_than_check = true;
144: 		if (result->start > result->end) {
145: 			throw BinderException(
146: 			    "start is bigger than end, but increment is positive: cannot generate infinite series");
147: 		}
148: 	} else {
149: 		result->greater_than_check = false;
150: 		if (result->start < result->end) {
151: 			throw BinderException(
152: 			    "start is smaller than end, but increment is negative: cannot generate infinite series");
153: 		}
154: 	}
155: 	return_types.push_back(inputs[0].type());
156: 	if (GENERATE_SERIES) {
157: 		// generate_series has inclusive bounds on the RHS
158: 		result->inclusive_bound = true;
159: 		names.emplace_back("generate_series");
160: 	} else {
161: 		result->inclusive_bound = false;
162: 		names.emplace_back("range");
163: 	}
164: 	return move(result);
165: }
166: 
167: struct RangeDateTimeState : public FunctionOperatorData {
168: 	explicit RangeDateTimeState(timestamp_t start_p) : current_state(start_p) {
169: 	}
170: 
171: 	timestamp_t current_state;
172: 	bool finished = false;
173: };
174: 
175: static unique_ptr<FunctionOperatorData> RangeDateTimeInit(ClientContext &context, const FunctionData *bind_data_p,
176:                                                           const vector<column_t> &column_ids,
177:                                                           TableFilterCollection *filters) {
178: 	auto &bind_data = (RangeDateTimeBindData &)*bind_data_p;
179: 	return make_unique<RangeDateTimeState>(bind_data.start);
180: }
181: 
182: static void RangeDateTimeFunction(ClientContext &context, const FunctionData *bind_data_p,
183:                                   FunctionOperatorData *state_p, DataChunk *input, DataChunk &output) {
184: 	auto &bind_data = (RangeDateTimeBindData &)*bind_data_p;
185: 	auto &state = (RangeDateTimeState &)*state_p;
186: 	if (state.finished) {
187: 		return;
188: 	}
189: 
190: 	idx_t size = 0;
191: 	auto data = FlatVector::GetData<timestamp_t>(output.data[0]);
192: 	while (true) {
193: 		data[size++] = state.current_state;
194: 		state.current_state =
195: 		    AddOperator::Operation<timestamp_t, interval_t, timestamp_t>(state.current_state, bind_data.increment);
196: 		if (bind_data.Finished(state.current_state)) {
197: 			state.finished = true;
198: 			break;
199: 		}
200: 		if (size >= STANDARD_VECTOR_SIZE) {
201: 			break;
202: 		}
203: 	}
204: 	output.SetCardinality(size);
205: }
206: 
207: void RangeTableFunction::RegisterFunction(BuiltinFunctions &set) {
208: 	TableFunctionSet range("range");
209: 
210: 	// single argument range: (end) - implicit start = 0 and increment = 1
211: 	range.AddFunction(TableFunction({LogicalType::BIGINT}, RangeFunction, RangeFunctionBind<false>, RangeFunctionInit,
212: 	                                nullptr, nullptr, nullptr, RangeCardinality));
213: 	// two arguments range: (start, end) - implicit increment = 1
214: 	range.AddFunction(TableFunction({LogicalType::BIGINT, LogicalType::BIGINT}, RangeFunction, RangeFunctionBind<false>,
215: 	                                RangeFunctionInit, nullptr, nullptr, nullptr, RangeCardinality));
216: 	// three arguments range: (start, end, increment)
217: 	range.AddFunction(TableFunction({LogicalType::BIGINT, LogicalType::BIGINT, LogicalType::BIGINT}, RangeFunction,
218: 	                                RangeFunctionBind<false>, RangeFunctionInit, nullptr, nullptr, nullptr,
219: 	                                RangeCardinality));
220: 	range.AddFunction(TableFunction({LogicalType::TIMESTAMP, LogicalType::TIMESTAMP, LogicalType::INTERVAL},
221: 	                                RangeDateTimeFunction, RangeDateTimeBind<false>, RangeDateTimeInit));
222: 	set.AddFunction(range);
223: 	// generate_series: similar to range, but inclusive instead of exclusive bounds on the RHS
224: 	TableFunctionSet generate_series("generate_series");
225: 	generate_series.AddFunction(TableFunction({LogicalType::BIGINT}, RangeFunction, RangeFunctionBind<true>,
226: 	                                          RangeFunctionInit, nullptr, nullptr, nullptr, RangeCardinality));
227: 	generate_series.AddFunction(TableFunction({LogicalType::BIGINT, LogicalType::BIGINT}, RangeFunction,
228: 	                                          RangeFunctionBind<true>, RangeFunctionInit, nullptr, nullptr, nullptr,
229: 	                                          RangeCardinality));
230: 	generate_series.AddFunction(TableFunction({LogicalType::BIGINT, LogicalType::BIGINT, LogicalType::BIGINT},
231: 	                                          RangeFunction, RangeFunctionBind<true>, RangeFunctionInit, nullptr,
232: 	                                          nullptr, nullptr, RangeCardinality));
233: 	generate_series.AddFunction(TableFunction({LogicalType::TIMESTAMP, LogicalType::TIMESTAMP, LogicalType::INTERVAL},
234: 	                                          RangeDateTimeFunction, RangeDateTimeBind<true>, RangeDateTimeInit));
235: 	set.AddFunction(generate_series);
236: }
237: 
238: void BuiltinFunctions::RegisterTableFunctions() {
239: 	CheckpointFunction::RegisterFunction(*this);
240: 	GlobTableFunction::RegisterFunction(*this);
241: 	RangeTableFunction::RegisterFunction(*this);
242: 	RepeatTableFunction::RegisterFunction(*this);
243: 	SummaryTableFunction::RegisterFunction(*this);
244: 	UnnestTableFunction::RegisterFunction(*this);
245: }
246: 
247: } // namespace duckdb
[end of src/function/table/range.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: