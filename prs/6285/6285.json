{
  "repo": "duckdb/duckdb",
  "pull_number": 6285,
  "instance_id": "duckdb__duckdb-6285",
  "issue_numbers": [
    "6341"
  ],
  "base_commit": "e1a465d8e9e1eb38772881b86035f559c8483492",
  "patch": "diff --git a/.github/workflows/CodeQuality.yml b/.github/workflows/CodeQuality.yml\nindex 17b706a8018a..7f1cdb74c5ca 100644\n--- a/.github/workflows/CodeQuality.yml\n+++ b/.github/workflows/CodeQuality.yml\n@@ -3,8 +3,13 @@ on:\n   schedule:\n     - cron: \"0 2 * * *\"\n   push:\n+    branches:\n+      - '**'\n+      - '!master'\n+      - '!feature'\n     paths-ignore:\n       - '**.md'\n+\n   pull_request:\n     paths-ignore:\n       - '**.md'\n@@ -116,7 +121,7 @@ jobs:\n           curl --fail --data-binary @.codecov.yml https://codecov.io/validate\n \n       - name: Set up Python 3.9\n-        uses: actions/setup-python@v2\n+        uses: actions/setup-python@v4\n         with:\n           python-version: '3.9'\n \ndiff --git a/.github/workflows/ExtensionRebuild.yml b/.github/workflows/ExtensionRebuild.yml\nindex 264e088722df..9eac56898185 100644\n--- a/.github/workflows/ExtensionRebuild.yml\n+++ b/.github/workflows/ExtensionRebuild.yml\n@@ -86,7 +86,7 @@ jobs:\n         run: |\n           echo -e 'name,url,commit,options\\n${{ inputs.extension_name }},${{ inputs.extension_repo }},${{ inputs.extension_ref }},true' > duckdb-old/.github/config/extensions.csv\n \n-      - uses: actions/setup-python@v2\n+      - uses: actions/setup-python@v4\n         with:\n           python-version: '3.7'\n \n@@ -138,7 +138,7 @@ jobs:\n        run: |\n          echo -e 'name,url,commit,options\\n${{ inputs.extension_name }},${{ inputs.extension_repo }},${{ inputs.extension_ref }},true' > duckdb-old/.github/config/extensions.csv\n \n-     - uses: actions/setup-python@v2\n+     - uses: actions/setup-python@v4\n        with:\n          python-version: '3.7'\n \ndiff --git a/.github/workflows/Java.yml b/.github/workflows/Java.yml\nindex 139014e708ea..b3e1ecf29ae4 100644\n--- a/.github/workflows/Java.yml\n+++ b/.github/workflows/Java.yml\n@@ -6,6 +6,7 @@ on:\n     branches:\n       - '**'\n       - '!master'\n+      - '!feature'\n     paths-ignore:\n       - '**.md'\n   pull_request:\ndiff --git a/.github/workflows/Julia.yml b/.github/workflows/Julia.yml\nindex 7bb89dbc1d1d..f7d31dabbb06 100644\n--- a/.github/workflows/Julia.yml\n+++ b/.github/workflows/Julia.yml\n@@ -6,6 +6,7 @@ on:\n     branches:\n       - '**'\n       - '!master'\n+      - '!feature'\n     paths-ignore:\n       - '**.md'\n   pull_request:\n@@ -13,11 +14,8 @@ on:\n       - '**.md'\n       - 'examples/**'\n       - 'test/**'\n-      - 'tools/odbc/**'\n-      - 'tools/jdbc/**'\n-      - 'tools/nodejs/**'\n-      - 'tools/pythonpkg/**'\n-      - 'tools/rpkg/**'\n+      - 'tools/**'\n+      - '!tools/juliapkg/**'\n       - '.github/workflows/**'\n       - '!.github/workflows/Julia.yml'\n \ndiff --git a/.github/workflows/LinuxRelease.yml b/.github/workflows/LinuxRelease.yml\nindex 8b620f846828..c3a1e9a31588 100644\n--- a/.github/workflows/LinuxRelease.yml\n+++ b/.github/workflows/LinuxRelease.yml\n@@ -6,16 +6,13 @@ on:\n     branches:\n       - '**'\n       - '!master'\n+      - '!feature'\n     paths-ignore:\n       - '**.md'\n   pull_request:\n     paths-ignore:\n       - '**.md'\n-      - 'tools/jdbc/**'\n-      - 'tools/nodejs/**'\n-      - 'tools/juliapkg/**'\n-      - 'tools/pythonpkg/**'\n-      - 'tools/rpkg/**'\n+      - 'tools/**'\n       - '.github/workflows/**'\n       - '!.github/workflows/LinuxRelease.yml'\n \n@@ -249,7 +246,7 @@ jobs:\n       with:\n         fetch-depth: 0\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.9'\n \n@@ -333,7 +330,7 @@ jobs:\n       with:\n         fetch-depth: 0\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.7'\n \n@@ -400,7 +397,7 @@ jobs:\n         version: \"14.0\"\n         directory: '/home/runner/work/llvm'\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.7'\n \n@@ -432,7 +429,7 @@ jobs:\n       with:\n         fetch-depth: 0\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.7'\n \n@@ -512,7 +509,7 @@ jobs:\n       with:\n         fetch-depth: 0\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.7'\n \n@@ -583,7 +580,7 @@ jobs:\n       with:\n         fetch-depth: 0\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.7'\n \n@@ -613,7 +610,7 @@ jobs:\n       with:\n         fetch-depth: 0\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.7'\n \n@@ -659,7 +656,7 @@ jobs:\n       with:\n         fetch-depth: 0\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.7'\n \n@@ -703,7 +700,7 @@ jobs:\n       with:\n         fetch-depth: 0\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.7'\n \ndiff --git a/.github/workflows/Main.yml b/.github/workflows/Main.yml\nindex 6f5adf27fc88..33abd9a4f674 100644\n--- a/.github/workflows/Main.yml\n+++ b/.github/workflows/Main.yml\n@@ -5,14 +5,14 @@ on:\n   push:\n     paths-ignore:\n       - '**.md'\n+    branches:\n+      - '**'\n+      - '!master'\n+      - '!feature'\n   pull_request:\n     paths-ignore:\n       - '**.md'\n-      - 'tools/jdbc/**'\n-      - 'tools/nodejs/**'\n-      - 'tools/juliapkg/**'\n-      - 'tools/pythonpkg/**'\n-      - 'tools/rpkg/**'\n+      - 'tools/**'\n       - '.github/workflows/**'\n       - '!.github/workflows/Main.yml'\n \n@@ -293,7 +293,7 @@ jobs:\n       run: git clone https://github.com/duckdb/duckdb-web\n \n     - name: Set up Python 3.9\n-      uses: actions/setup-python@v2\n+      uses: actions/setup-python@v4\n       with:\n         python-version: '3.9'\n \n@@ -379,7 +379,7 @@ jobs:\n       with:\n         fetch-depth: 0\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.7'\n \ndiff --git a/.github/workflows/NodeJS.yml b/.github/workflows/NodeJS.yml\nindex 37ec0cba65b5..2aba928b7d3b 100644\n--- a/.github/workflows/NodeJS.yml\n+++ b/.github/workflows/NodeJS.yml\n@@ -6,6 +6,7 @@ on:\n     branches:\n       - '**'\n       - '!master'\n+      - '!feature'\n     paths-ignore:\n       - '**.md'\n   pull_request:\n@@ -14,11 +15,8 @@ on:\n       - 'data/**'\n       - 'examples/**'\n       - 'test/**'\n-      - 'tools/odbc/**'\n-      - 'tools/jdbc/**'\n-      - 'tools/juliapkg/**'\n-      - 'tools/pythonpkg/**'\n-      - 'tools/rpkg/**'\n+      - 'tools/**'\n+      - '!tools/nodejs/**'\n       - '.github/workflows/**'\n       - '!.github/workflows/NodeJS.yml'\n \n@@ -225,7 +223,7 @@ jobs:\n             node: 18\n \n     steps:\n-      - uses: actions/setup-python@v2\n+      - uses: actions/setup-python@v4\n         with:\n           python-version: '3.8'\n \ndiff --git a/.github/workflows/OSX.yml b/.github/workflows/OSX.yml\nindex fa10f22726d0..5dc3327aaaeb 100644\n--- a/.github/workflows/OSX.yml\n+++ b/.github/workflows/OSX.yml\n@@ -6,6 +6,7 @@ on:\n     branches:\n       - '**'\n       - '!master'\n+      - '!feature'\n     paths-ignore:\n       - '**.md'\n   pull_request:\n@@ -32,7 +33,7 @@ jobs:\n       with:\n         fetch-depth: 0\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.7'\n \n@@ -79,7 +80,7 @@ jobs:\n       with:\n         fetch-depth: 0\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.7'\n \n@@ -148,7 +149,7 @@ jobs:\n         with:\n           fetch-depth: 0\n \n-      - uses: actions/setup-python@v2\n+      - uses: actions/setup-python@v4\n         with:\n           python-version: '3.7'\n \ndiff --git a/.github/workflows/Python.yml b/.github/workflows/Python.yml\nindex c769f229c116..c7d4380a90cc 100644\n--- a/.github/workflows/Python.yml\n+++ b/.github/workflows/Python.yml\n@@ -6,6 +6,7 @@ on:\n     branches:\n       - '**'\n       - '!master'\n+      - '!feature'\n     paths-ignore:\n       - '**.md'\n   pull_request:\n@@ -13,11 +14,8 @@ on:\n       - '**.md'\n       - 'examples/**'\n       - 'test/**'\n-      - 'tools/odbc/**'\n-      - 'tools/jdbc/**'\n-      - 'tools/juliapkg/**'\n-      - 'tools/nodejs/**'\n-      - 'tools/rpkg/**'\n+      - 'tools/**'\n+      - '!tools/pythonpkg/**'\n       - '.github/workflows/**'\n       - '!.github/workflows/Python.yml'\n \n@@ -45,7 +43,7 @@ jobs:\n       with:\n         fetch-depth: 0\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.7'\n \n@@ -140,7 +138,7 @@ jobs:\n       with:\n         fetch-depth: 0\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.7'\n \n@@ -209,7 +207,7 @@ jobs:\n         with:\n           fetch-depth: 0\n \n-      - uses: actions/setup-python@v2\n+      - uses: actions/setup-python@v4\n         with:\n           python-version: '3.7'\n \n@@ -274,7 +272,7 @@ jobs:\n         with:\n           fetch-depth: 0\n \n-      - uses: actions/setup-python@v2\n+      - uses: actions/setup-python@v4\n         with:\n           python-version: '3.7'\n \n@@ -318,7 +316,7 @@ jobs:\n         with:\n           fetch-depth: 0\n \n-      - uses: actions/setup-python@v2\n+      - uses: actions/setup-python@v4\n         with:\n           python-version: '3.7'\n \n@@ -424,7 +422,7 @@ jobs:\n         with:\n           fetch-depth: 0\n \n-      - uses: actions/setup-python@v2\n+      - uses: actions/setup-python@v4\n         with:\n           python-version: '3.7'\n \ndiff --git a/.github/workflows/R.yml b/.github/workflows/R.yml\nindex 38ea80cf1334..867930939f27 100644\n--- a/.github/workflows/R.yml\n+++ b/.github/workflows/R.yml\n@@ -6,6 +6,7 @@ on:\n     branches:\n       - '**'\n       - '!master'\n+      - '!feature'\n     paths-ignore:\n       - '**.md'\n   pull_request:\n@@ -13,11 +14,8 @@ on:\n       - '**.md'\n       - 'examples/**'\n       - 'test/**'\n-      - 'tools/odbc/**'\n-      - 'tools/jdbc/**'\n-      - 'tools/juliapkg/**'\n-      - 'tools/nodejs/**'\n-      - 'tools/pythonpkg/**'\n+      - 'tools/**'\n+      - '!tools/rpkg/**'\n       - '.github/workflows/**'\n       - '!.github/workflows/R.yml'\n \n@@ -70,7 +68,7 @@ jobs:\n       with:\n         fetch-depth: 0\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.7'\n \n@@ -171,7 +169,7 @@ jobs:\n       with:\n         fetch-depth: 0\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.7'\n \n@@ -210,7 +208,7 @@ jobs:\n       with:\n         fetch-depth: 0\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.7'\n \n@@ -254,7 +252,7 @@ jobs:\n       with:\n         fetch-depth: 0\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.7'\n \ndiff --git a/.github/workflows/Regression.yml b/.github/workflows/Regression.yml\nindex d5772fe94f30..ed3c0df48a2a 100644\n--- a/.github/workflows/Regression.yml\n+++ b/.github/workflows/Regression.yml\n@@ -4,16 +4,14 @@ on:\n     branches:\n       - '**'\n       - '!master'\n+      - '!feature'\n     paths-ignore:\n       - '**.md'\n   pull_request:\n     paths-ignore:\n       - '**.md'\n-      - 'tools/odbc/**'\n-      - 'tools/jdbc/**'\n-      - 'tools/juliapkg/**'\n-      - 'tools/nodejs/**'\n-      - 'tools/rpkg/**'\n+      - 'tools/**'\n+      - '!tools/pythonpkg/**'\n       - '.github/workflows/**'\n       - '!.github/workflows/Regression.yml'\n \n@@ -43,7 +41,7 @@ jobs:\n       with:\n         fetch-depth: 0\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.7'\n \n@@ -116,7 +114,7 @@ jobs:\n       with:\n         fetch-depth: 0\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.7'\n \n@@ -157,7 +155,7 @@ jobs:\n       with:\n         fetch-depth: 0\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.7'\n \n@@ -226,7 +224,7 @@ jobs:\n       with:\n         fetch-depth: 0\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.7'\n \ndiff --git a/.github/workflows/Windows.yml b/.github/workflows/Windows.yml\nindex ff7b0cc5e36e..299a21565e66 100644\n--- a/.github/workflows/Windows.yml\n+++ b/.github/workflows/Windows.yml\n@@ -6,16 +6,14 @@ on:\n     branches:\n       - '**'\n       - '!master'\n+      - '!feature'\n     paths-ignore:\n       - '**.md'\n   pull_request:\n     paths-ignore:\n       - '**.md'\n-      - 'tools/jdbc/**'\n-      - 'tools/juliapkg/**'\n-      - 'tools/nodejs/**'\n-      - 'tools/pythonpkg/**'\n-      - 'tools/rpkg/**'\n+      - 'tools/**'\n+      - '!tools/odbc/**'\n       - '.github/workflows/**'\n       - '!.github/workflows/Windows.yml'\n \n@@ -35,7 +33,7 @@ jobs:\n       with:\n         fetch-depth: 0\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.7'\n \n@@ -94,7 +92,7 @@ jobs:\n       with:\n         fetch-depth: 0\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.7'\n \n@@ -179,7 +177,7 @@ jobs:\n       with:\n         fetch-depth: 0\n \n-    - uses: actions/setup-python@v2\n+    - uses: actions/setup-python@v4\n       with:\n         python-version: '3.7'\n \n@@ -240,7 +238,7 @@ jobs:\n        with:\n          fetch-depth: 0\n \n-     - uses: actions/setup-python@v2\n+     - uses: actions/setup-python@v4\n        with:\n          python-version: '3.7'\n \ndiff --git a/.github/workflows/cifuzz.yml b/.github/workflows/cifuzz.yml\nindex 05910e2fdf38..42bd0c525711 100644\n--- a/.github/workflows/cifuzz.yml\n+++ b/.github/workflows/cifuzz.yml\n@@ -3,8 +3,13 @@ on:\n   schedule:\n     - cron: \"0 2 * * *\"\n   push:\n+    branches:\n+      - '**'\n+      - '!master'\n+      - '!feature'\n     paths-ignore:\n       - '**.md'\n+      - 'tools/**'\n \n concurrency:\n   group: ${{ github.workflow }}-${{ github.ref }}-${{ github.head_ref || '' }}-${{ github.base_ref || '' }}-${{ github.ref != 'refs/heads/master' || github.sha }}\n@@ -87,7 +92,7 @@ jobs:\n         with:\n           fetch-depth: 0\n \n-      - uses: actions/setup-python@v2\n+      - uses: actions/setup-python@v4\n         with:\n           python-version: '3.9'\n \ndiff --git a/data/csv/csv_quoted_newline_odd.csv b/data/csv/csv_quoted_newline_odd.csv\nnew file mode 100644\nindex 000000000000..305b24c66636\n--- /dev/null\n+++ b/data/csv/csv_quoted_newline_odd.csv\n@@ -0,0 +1,11 @@\n+content\n+\"RT @Truffaut: \ud83c\udf81#Concours\n+Vos animaux vont \u00eatre g\u00e2t\u00e9s \u00e0 No\u00ebl ! Avec Purina, nous vous proposons de remporter l'une des 10 cartes cadeaux Truffaut de 20\u20ac pour offrir un joli cadeau \u00e0 votre animal \ud83d\udc08\u2728\n+\n+Pour jouer :\n+\ud83d\udc36 RT\n+\ud83d\ude3a Follow @PurinaFr et @Truffaut\n+\n+TAS le 06/12 !\n+Bonne chance \u00e0 tous \ud83e\udd1e https://twitter.com/Truffaut/status/1597871806160986112/photo/1\"\n+84,hello world\ndiff --git a/extension/icu/CMakeLists.txt b/extension/icu/CMakeLists.txt\nindex d7f7b24c9b52..3a4ac2ed119f 100644\n--- a/extension/icu/CMakeLists.txt\n+++ b/extension/icu/CMakeLists.txt\n@@ -17,6 +17,7 @@ set(ICU_EXTENSION_FILES\n     icu-datesub.cpp\n     icu-datetrunc.cpp\n     icu-makedate.cpp\n+    icu-table-range.cpp\n     icu-strptime.cpp\n     icu-timebucket.cpp\n     icu-timezone.cpp)\ndiff --git a/extension/icu/icu-extension.cpp b/extension/icu/icu-extension.cpp\nindex 4b3a09e1ac24..6e3ed57630ca 100644\n--- a/extension/icu/icu-extension.cpp\n+++ b/extension/icu/icu-extension.cpp\n@@ -13,6 +13,7 @@\n #include \"include/icu-datesub.hpp\"\n #include \"include/icu-datetrunc.hpp\"\n #include \"include/icu-makedate.hpp\"\n+#include \"include/icu-table-range.hpp\"\n #include \"include/icu-strptime.hpp\"\n #include \"include/icu-timebucket.hpp\"\n #include \"include/icu-timezone.hpp\"\n@@ -266,6 +267,7 @@ void ICUExtension::Load(DuckDB &db) {\n \tRegisterICUDateSubFunctions(*con.context);\n \tRegisterICUDateTruncFunctions(*con.context);\n \tRegisterICUMakeDateFunctions(*con.context);\n+\tRegisterICUTableRangeFunctions(*con.context);\n \tRegisterICUStrptimeFunctions(*con.context);\n \tRegisterICUTimeBucketFunctions(*con.context);\n \tRegisterICUTimeZoneFunctions(*con.context);\ndiff --git a/extension/icu/icu-table-range.cpp b/extension/icu/icu-table-range.cpp\nnew file mode 100644\nindex 000000000000..6fc79d2e832a\n--- /dev/null\n+++ b/extension/icu/icu-table-range.cpp\n@@ -0,0 +1,194 @@\n+#include \"duckdb/common/exception.hpp\"\n+#include \"duckdb/common/types/interval.hpp\"\n+#include \"duckdb/common/types/timestamp.hpp\"\n+#include \"duckdb/function/function_set.hpp\"\n+#include \"duckdb/function/table_function.hpp\"\n+#include \"duckdb/parser/parsed_data/create_table_function_info.hpp\"\n+#include \"include/icu-datefunc.hpp\"\n+#include \"unicode/calendar.h\"\n+\n+namespace duckdb {\n+\n+struct ICUTableRange {\n+\tusing CalendarPtr = unique_ptr<icu::Calendar>;\n+\n+\tstruct BindData : public TableFunctionData {\n+\t\texplicit BindData(const BindData &other)\n+\t\t    : tz_setting(other.tz_setting), cal_setting(other.cal_setting), calendar(other.calendar->clone()),\n+\t\t      start(other.start), end(other.end), increment(other.increment), inclusive_bound(other.inclusive_bound),\n+\t\t      greater_than_check(other.greater_than_check) {\n+\t\t}\n+\n+\t\tBindData(ClientContext &context) {\n+\t\t\tValue tz_value;\n+\t\t\tif (context.TryGetCurrentSetting(\"TimeZone\", tz_value)) {\n+\t\t\t\ttz_setting = tz_value.ToString();\n+\t\t\t}\n+\t\t\tauto tz = icu::TimeZone::createTimeZone(icu::UnicodeString::fromUTF8(icu::StringPiece(tz_setting)));\n+\n+\t\t\tstring cal_id(\"@calendar=\");\n+\t\t\tValue cal_value;\n+\t\t\tif (context.TryGetCurrentSetting(\"Calendar\", cal_value)) {\n+\t\t\t\tcal_setting = cal_value.ToString();\n+\t\t\t\tcal_id += cal_setting;\n+\t\t\t} else {\n+\t\t\t\tcal_id += \"gregorian\";\n+\t\t\t}\n+\n+\t\t\ticu::Locale locale(cal_id.c_str());\n+\n+\t\t\tUErrorCode success = U_ZERO_ERROR;\n+\t\t\tcalendar.reset(icu::Calendar::createInstance(tz, locale, success));\n+\t\t\tif (U_FAILURE(success)) {\n+\t\t\t\tthrow Exception(\"Unable to create ICU calendar.\");\n+\t\t\t}\n+\t\t}\n+\n+\t\tstring tz_setting;\n+\t\tstring cal_setting;\n+\t\tCalendarPtr calendar;\n+\n+\t\ttimestamp_t start;\n+\t\ttimestamp_t end;\n+\t\tinterval_t increment;\n+\t\tbool inclusive_bound;\n+\t\tbool greater_than_check;\n+\n+\t\tbool Equals(const FunctionData &other_p) const {\n+\t\t\tauto &other = (const BindData &)other_p;\n+\t\t\treturn other.start == start && other.end == end && other.increment == increment &&\n+\t\t\t       other.inclusive_bound == inclusive_bound && other.greater_than_check == greater_than_check &&\n+\t\t\t       *calendar == *other.calendar;\n+\t\t}\n+\n+\t\tunique_ptr<FunctionData> Copy() const {\n+\t\t\treturn make_unique<BindData>(*this);\n+\t\t}\n+\n+\t\tbool Finished(timestamp_t current_value) {\n+\t\t\tif (greater_than_check) {\n+\t\t\t\tif (inclusive_bound) {\n+\t\t\t\t\treturn current_value > end;\n+\t\t\t\t} else {\n+\t\t\t\t\treturn current_value >= end;\n+\t\t\t\t}\n+\t\t\t} else {\n+\t\t\t\tif (inclusive_bound) {\n+\t\t\t\t\treturn current_value < end;\n+\t\t\t\t} else {\n+\t\t\t\t\treturn current_value <= end;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t};\n+\n+\ttemplate <bool GENERATE_SERIES>\n+\tstatic unique_ptr<FunctionData> Bind(ClientContext &context, TableFunctionBindInput &input,\n+\t                                     vector<LogicalType> &return_types, vector<string> &names) {\n+\t\tauto result = make_unique<BindData>(context);\n+\n+\t\tauto &inputs = input.inputs;\n+\t\tD_ASSERT(inputs.size() == 3);\n+\t\tresult->start = inputs[0].GetValue<timestamp_t>();\n+\t\tresult->end = inputs[1].GetValue<timestamp_t>();\n+\t\tresult->increment = inputs[2].GetValue<interval_t>();\n+\n+\t\t// Infinities either cause errors or infinite loops, so just ban them\n+\t\tif (!Timestamp::IsFinite(result->start) || !Timestamp::IsFinite(result->end)) {\n+\t\t\tthrow BinderException(\"RANGE with infinite bounds is not supported\");\n+\t\t}\n+\n+\t\tif (result->increment.months == 0 && result->increment.days == 0 && result->increment.micros == 0) {\n+\t\t\tthrow BinderException(\"interval cannot be 0!\");\n+\t\t}\n+\t\t// all elements should point in the same direction\n+\t\tif (result->increment.months > 0 || result->increment.days > 0 || result->increment.micros > 0) {\n+\t\t\tif (result->increment.months < 0 || result->increment.days < 0 || result->increment.micros < 0) {\n+\t\t\t\tthrow BinderException(\"RANGE with composite interval that has mixed signs is not supported\");\n+\t\t\t}\n+\t\t\tresult->greater_than_check = true;\n+\t\t\tif (result->start > result->end) {\n+\t\t\t\tthrow BinderException(\n+\t\t\t\t    \"start is bigger than end, but increment is positive: cannot generate infinite series\");\n+\t\t\t}\n+\t\t} else {\n+\t\t\tresult->greater_than_check = false;\n+\t\t\tif (result->start < result->end) {\n+\t\t\t\tthrow BinderException(\n+\t\t\t\t    \"start is smaller than end, but increment is negative: cannot generate infinite series\");\n+\t\t\t}\n+\t\t}\n+\t\treturn_types.push_back(inputs[0].type());\n+\t\tif (GENERATE_SERIES) {\n+\t\t\t// generate_series has inclusive bounds on the RHS\n+\t\t\tresult->inclusive_bound = true;\n+\t\t\tnames.emplace_back(\"generate_series\");\n+\t\t} else {\n+\t\t\tresult->inclusive_bound = false;\n+\t\t\tnames.emplace_back(\"range\");\n+\t\t}\n+\t\treturn std::move(result);\n+\t}\n+\n+\tstruct State : public GlobalTableFunctionState {\n+\t\texplicit State(timestamp_t start_p) : current_state(start_p) {\n+\t\t}\n+\n+\t\ttimestamp_t current_state;\n+\t\tbool finished = false;\n+\t};\n+\n+\tstatic unique_ptr<GlobalTableFunctionState> Init(ClientContext &context, TableFunctionInitInput &input) {\n+\t\tauto &bind_data = (BindData &)*input.bind_data;\n+\t\treturn make_unique<State>(bind_data.start);\n+\t}\n+\n+\tstatic void ICUTableRangeFunction(ClientContext &context, TableFunctionInput &data_p, DataChunk &output) {\n+\t\tauto &bind_data = (BindData &)*data_p.bind_data;\n+\t\tCalendarPtr calendar_ptr(bind_data.calendar->clone());\n+\t\tauto calendar = calendar_ptr.get();\n+\t\tauto &state = (State &)*data_p.global_state;\n+\t\tif (state.finished) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tidx_t size = 0;\n+\t\tauto data = FlatVector::GetData<timestamp_t>(output.data[0]);\n+\t\twhile (true) {\n+\t\t\tdata[size++] = state.current_state;\n+\t\t\tstate.current_state = ICUDateFunc::Add(calendar, state.current_state, bind_data.increment);\n+\t\t\tif (bind_data.Finished(state.current_state)) {\n+\t\t\t\tstate.finished = true;\n+\t\t\t\tbreak;\n+\t\t\t}\n+\t\t\tif (size >= STANDARD_VECTOR_SIZE) {\n+\t\t\t\tbreak;\n+\t\t\t}\n+\t\t}\n+\t\toutput.SetCardinality(size);\n+\t}\n+\n+\tstatic void AddICUTableRangeFunction(ClientContext &context) {\n+\t\tauto &catalog = Catalog::GetSystemCatalog(context);\n+\n+\t\tTableFunctionSet range(\"range\");\n+\t\trange.AddFunction(TableFunction({LogicalType::TIMESTAMP_TZ, LogicalType::TIMESTAMP_TZ, LogicalType::INTERVAL},\n+\t\t                                ICUTableRangeFunction, Bind<false>, Init));\n+\t\tCreateTableFunctionInfo range_func_info(range);\n+\t\tcatalog.AddFunction(context, &range_func_info);\n+\n+\t\t// generate_series: similar to range, but inclusive instead of exclusive bounds on the RHS\n+\t\tTableFunctionSet generate_series(\"generate_series\");\n+\t\tgenerate_series.AddFunction(\n+\t\t    TableFunction({LogicalType::TIMESTAMP_TZ, LogicalType::TIMESTAMP_TZ, LogicalType::INTERVAL},\n+\t\t                  ICUTableRangeFunction, Bind<true>, Init));\n+\t\tCreateTableFunctionInfo generate_series_func_info(generate_series);\n+\t\tcatalog.AddFunction(context, &generate_series_func_info);\n+\t}\n+};\n+\n+void RegisterICUTableRangeFunctions(ClientContext &context) {\n+\tICUTableRange::AddICUTableRangeFunction(context);\n+}\n+\n+} // namespace duckdb\ndiff --git a/extension/icu/include/icu-table-range.hpp b/extension/icu/include/icu-table-range.hpp\nnew file mode 100644\nindex 000000000000..c916d195b5d0\n--- /dev/null\n+++ b/extension/icu/include/icu-table-range.hpp\n@@ -0,0 +1,17 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// icu-table-range.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#pragma once\n+\n+#include \"duckdb.hpp\"\n+\n+namespace duckdb {\n+\n+void RegisterICUTableRangeFunctions(ClientContext &context);\n+\n+} // namespace duckdb\ndiff --git a/src/catalog/catalog_entry/duck_schema_entry.cpp b/src/catalog/catalog_entry/duck_schema_entry.cpp\nindex db1655f3cdea..8f8b25d1ece7 100644\n--- a/src/catalog/catalog_entry/duck_schema_entry.cpp\n+++ b/src/catalog/catalog_entry/duck_schema_entry.cpp\n@@ -145,6 +145,10 @@ CatalogEntry *DuckSchemaEntry::CreateFunction(CatalogTransaction transaction, Cr\n \t\tfunction = make_unique_base<StandardEntry, ScalarFunctionCatalogEntry>(catalog, this,\n \t\t                                                                       (CreateScalarFunctionInfo *)info);\n \t\tbreak;\n+\tcase CatalogType::TABLE_FUNCTION_ENTRY:\n+\t\tfunction =\n+\t\t    make_unique_base<StandardEntry, TableFunctionCatalogEntry>(catalog, this, (CreateTableFunctionInfo *)info);\n+\t\tbreak;\n \tcase CatalogType::MACRO_ENTRY:\n \t\t// create a macro function\n \t\tfunction = make_unique_base<StandardEntry, ScalarMacroCatalogEntry>(catalog, this, (CreateMacroInfo *)info);\ndiff --git a/src/catalog/catalog_entry/scalar_function_catalog_entry.cpp b/src/catalog/catalog_entry/scalar_function_catalog_entry.cpp\nindex cfa9038b1d5e..2ade6e1e9524 100644\n--- a/src/catalog/catalog_entry/scalar_function_catalog_entry.cpp\n+++ b/src/catalog/catalog_entry/scalar_function_catalog_entry.cpp\n@@ -1,5 +1,5 @@\n #include \"duckdb/catalog/catalog_entry/scalar_function_catalog_entry.hpp\"\n-#include \"duckdb/parser/parsed_data/alter_function_info.hpp\"\n+#include \"duckdb/parser/parsed_data/alter_scalar_function_info.hpp\"\n \n namespace duckdb {\n \n@@ -9,14 +9,15 @@ ScalarFunctionCatalogEntry::ScalarFunctionCatalogEntry(Catalog *catalog, SchemaC\n }\n \n unique_ptr<CatalogEntry> ScalarFunctionCatalogEntry::AlterEntry(ClientContext &context, AlterInfo *info) {\n-\tif (info->type != AlterType::ALTER_FUNCTION) {\n+\tif (info->type != AlterType::ALTER_SCALAR_FUNCTION) {\n \t\tthrow InternalException(\"Attempting to alter ScalarFunctionCatalogEntry with unsupported alter type\");\n \t}\n-\tauto &function_info = (AlterFunctionInfo &)*info;\n-\tif (function_info.alter_function_type != AlterFunctionType::ADD_FUNCTION_OVERLOADS) {\n-\t\tthrow InternalException(\"Attempting to alter ScalarFunctionCatalogEntry with unsupported alter function type\");\n+\tauto &function_info = (AlterScalarFunctionInfo &)*info;\n+\tif (function_info.alter_scalar_function_type != AlterScalarFunctionType::ADD_FUNCTION_OVERLOADS) {\n+\t\tthrow InternalException(\n+\t\t    \"Attempting to alter ScalarFunctionCatalogEntry with unsupported alter scalar function type\");\n \t}\n-\tauto &add_overloads = (AddFunctionOverloadInfo &)function_info;\n+\tauto &add_overloads = (AddScalarFunctionOverloadInfo &)function_info;\n \n \tScalarFunctionSet new_set = functions;\n \tif (!new_set.MergeFunctionSet(add_overloads.new_overloads)) {\ndiff --git a/src/catalog/catalog_entry/table_function_catalog_entry.cpp b/src/catalog/catalog_entry/table_function_catalog_entry.cpp\nindex 01502e808db4..921af3497b9f 100644\n--- a/src/catalog/catalog_entry/table_function_catalog_entry.cpp\n+++ b/src/catalog/catalog_entry/table_function_catalog_entry.cpp\n@@ -1,5 +1,5 @@\n #include \"duckdb/catalog/catalog_entry/table_function_catalog_entry.hpp\"\n-#include \"duckdb/parser/parsed_data/create_table_function_info.hpp\"\n+#include \"duckdb/parser/parsed_data/alter_table_function_info.hpp\"\n \n namespace duckdb {\n \n@@ -10,4 +10,23 @@ TableFunctionCatalogEntry::TableFunctionCatalogEntry(Catalog *catalog, SchemaCat\n \tD_ASSERT(this->functions.Size() > 0);\n }\n \n+unique_ptr<CatalogEntry> TableFunctionCatalogEntry::AlterEntry(ClientContext &context, AlterInfo *info) {\n+\tif (info->type != AlterType::ALTER_TABLE_FUNCTION) {\n+\t\tthrow InternalException(\"Attempting to alter TableFunctionCatalogEntry with unsupported alter type\");\n+\t}\n+\tauto &function_info = (AlterTableFunctionInfo &)*info;\n+\tif (function_info.alter_table_function_type != AlterTableFunctionType::ADD_FUNCTION_OVERLOADS) {\n+\t\tthrow InternalException(\n+\t\t    \"Attempting to alter TableFunctionCatalogEntry with unsupported alter table function type\");\n+\t}\n+\tauto &add_overloads = (AddTableFunctionOverloadInfo &)function_info;\n+\n+\tTableFunctionSet new_set = functions;\n+\tif (!new_set.MergeFunctionSet(add_overloads.new_overloads)) {\n+\t\tthrow BinderException(\"Failed to add new function overloads to function \\\"%s\\\": function already exists\", name);\n+\t}\n+\tCreateTableFunctionInfo new_info(std::move(new_set));\n+\treturn make_unique<TableFunctionCatalogEntry>(catalog, schema, &new_info);\n+}\n+\n } // namespace duckdb\ndiff --git a/src/execution/operator/persistent/buffered_csv_reader.cpp b/src/execution/operator/persistent/buffered_csv_reader.cpp\nindex a1fa0e697e96..77670af860d4 100644\n--- a/src/execution/operator/persistent/buffered_csv_reader.cpp\n+++ b/src/execution/operator/persistent/buffered_csv_reader.cpp\n@@ -893,6 +893,12 @@ vector<LogicalType> BufferedCSVReader::SniffCSV(const vector<LogicalType> &reque\n \tDetectCandidateTypes(type_candidates, format_template_candidates, info_candidates, original_options, best_num_cols,\n \t                     best_sql_types_candidates, best_format_candidates, best_header_row);\n \n+\tif (best_format_candidates.empty() || best_header_row.size() == 0) {\n+\t\tthrow InvalidInputException(\n+\t\t    \"Error in file \\\"%s\\\": CSV options could not be auto-detected. Consider setting parser options manually.\",\n+\t\t    original_options.file_path);\n+\t}\n+\n \t// #######\n \t// ### header detection\n \t// #######\ndiff --git a/src/function/table_function.cpp b/src/function/table_function.cpp\nindex 9f7dd6ba4576..47dfcd1ffb8d 100644\n--- a/src/function/table_function.cpp\n+++ b/src/function/table_function.cpp\n@@ -35,4 +35,23 @@ TableFunction::TableFunction()\n       filter_pushdown(false), filter_prune(false) {\n }\n \n+bool TableFunction::Equal(const TableFunction &rhs) const {\n+\t// number of types\n+\tif (this->arguments.size() != rhs.arguments.size()) {\n+\t\treturn false;\n+\t}\n+\t// argument types\n+\tfor (idx_t i = 0; i < this->arguments.size(); ++i) {\n+\t\tif (this->arguments[i] != rhs.arguments[i]) {\n+\t\t\treturn false;\n+\t\t}\n+\t}\n+\t// varargs\n+\tif (this->varargs != rhs.varargs) {\n+\t\treturn false;\n+\t}\n+\n+\treturn true; // they are equal\n+}\n+\n } // namespace duckdb\ndiff --git a/src/include/duckdb/catalog/catalog_entry/table_function_catalog_entry.hpp b/src/include/duckdb/catalog/catalog_entry/table_function_catalog_entry.hpp\nindex 8b557923e6f5..496c588ca09c 100644\n--- a/src/include/duckdb/catalog/catalog_entry/table_function_catalog_entry.hpp\n+++ b/src/include/duckdb/catalog/catalog_entry/table_function_catalog_entry.hpp\n@@ -9,17 +9,12 @@\n #pragma once\n \n #include \"duckdb/catalog/standard_entry.hpp\"\n-#include \"duckdb/function/table_function.hpp\"\n-#include \"duckdb/common/vector.hpp\"\n-#include \"duckdb/function/function_set.hpp\"\n+#include \"duckdb/catalog/catalog_set.hpp\"\n+#include \"duckdb/function/function.hpp\"\n+#include \"duckdb/parser/parsed_data/create_table_function_info.hpp\"\n \n namespace duckdb {\n \n-class Catalog;\n-class Constraint;\n-\n-struct CreateTableFunctionInfo;\n-\n //! A table function in the catalog\n class TableFunctionCatalogEntry : public StandardEntry {\n public:\n@@ -31,5 +26,8 @@ class TableFunctionCatalogEntry : public StandardEntry {\n \n \t//! The table function\n \tTableFunctionSet functions;\n+\n+public:\n+\tunique_ptr<CatalogEntry> AlterEntry(ClientContext &context, AlterInfo *info) override;\n };\n } // namespace duckdb\ndiff --git a/src/include/duckdb/common/radix_partitioning.hpp b/src/include/duckdb/common/radix_partitioning.hpp\nindex bc7f065b1b9a..a38eb271aecb 100644\n--- a/src/include/duckdb/common/radix_partitioning.hpp\n+++ b/src/include/duckdb/common/radix_partitioning.hpp\n@@ -78,13 +78,13 @@ class RadixPartitionedColumnData : public PartitionedColumnData {\n \t\tcase 2:\n \t\tcase 3:\n \t\tcase 4:\n-\t\t\treturn GetBufferSize(1);\n+\t\t\treturn GetBufferSize(1 << 1);\n \t\tcase 5:\n-\t\t\treturn GetBufferSize(2);\n+\t\t\treturn GetBufferSize(1 << 2);\n \t\tcase 6:\n-\t\t\treturn GetBufferSize(3);\n+\t\t\treturn GetBufferSize(1 << 3);\n \t\tdefault:\n-\t\t\treturn GetBufferSize(4);\n+\t\t\treturn GetBufferSize(1 << 4);\n \t\t}\n \t}\n \tvoid InitializeAppendStateInternal(PartitionedColumnDataAppendState &state) const override;\ndiff --git a/src/include/duckdb/function/table_function.hpp b/src/include/duckdb/function/table_function.hpp\nindex 0a22ad50ba5c..82341965be7d 100644\n--- a/src/include/duckdb/function/table_function.hpp\n+++ b/src/include/duckdb/function/table_function.hpp\n@@ -235,6 +235,8 @@ class TableFunction : public SimpleNamedParameterFunction {\n \tbool filter_prune;\n \t//! Additional function info, passed to the bind\n \tshared_ptr<TableFunctionInfo> function_info;\n+\n+\tDUCKDB_API bool Equal(const TableFunction &rhs) const;\n };\n \n } // namespace duckdb\ndiff --git a/src/include/duckdb/parser/parsed_data/alter_info.hpp b/src/include/duckdb/parser/parsed_data/alter_info.hpp\nindex c2a7f9cd3f94..293c32236d45 100644\n--- a/src/include/duckdb/parser/parsed_data/alter_info.hpp\n+++ b/src/include/duckdb/parser/parsed_data/alter_info.hpp\n@@ -20,7 +20,8 @@ enum class AlterType : uint8_t {\n \tALTER_VIEW = 2,\n \tALTER_SEQUENCE = 3,\n \tCHANGE_OWNERSHIP = 4,\n-\tALTER_FUNCTION = 5\n+\tALTER_SCALAR_FUNCTION = 5,\n+\tALTER_TABLE_FUNCTION = 6\n };\n \n struct AlterEntryData {\ndiff --git a/src/include/duckdb/parser/parsed_data/alter_function_info.hpp b/src/include/duckdb/parser/parsed_data/alter_scalar_function_info.hpp\nsimilarity index 60%\nrename from src/include/duckdb/parser/parsed_data/alter_function_info.hpp\nrename to src/include/duckdb/parser/parsed_data/alter_scalar_function_info.hpp\nindex 799ff0ee85af..95e6e621ce9f 100644\n--- a/src/include/duckdb/parser/parsed_data/alter_function_info.hpp\n+++ b/src/include/duckdb/parser/parsed_data/alter_scalar_function_info.hpp\n@@ -1,29 +1,29 @@\n //===----------------------------------------------------------------------===//\n //                         DuckDB\n //\n-// duckdb/parser/parsed_data/alter_function_info.hpp\n+// duckdb/parser/parsed_data/alter_scalar_function_info.hpp\n //\n //\n //===----------------------------------------------------------------------===//\n \n #pragma once\n \n-#include \"duckdb/parser/parsed_data/alter_info.hpp\"\n-#include \"duckdb/function/scalar_function.hpp\"\n #include \"duckdb/function/function_set.hpp\"\n+#include \"duckdb/function/scalar_function.hpp\"\n+#include \"duckdb/parser/parsed_data/alter_info.hpp\"\n \n namespace duckdb {\n \n //===--------------------------------------------------------------------===//\n-// Alter Table\n+// Alter Scalar Function\n //===--------------------------------------------------------------------===//\n-enum class AlterFunctionType : uint8_t { INVALID = 0, ADD_FUNCTION_OVERLOADS = 1 };\n+enum class AlterScalarFunctionType : uint8_t { INVALID = 0, ADD_FUNCTION_OVERLOADS = 1 };\n \n-struct AlterFunctionInfo : public AlterInfo {\n-\tAlterFunctionInfo(AlterFunctionType type, AlterEntryData data);\n-\tvirtual ~AlterFunctionInfo() override;\n+struct AlterScalarFunctionInfo : public AlterInfo {\n+\tAlterScalarFunctionInfo(AlterScalarFunctionType type, AlterEntryData data);\n+\tvirtual ~AlterScalarFunctionInfo() override;\n \n-\tAlterFunctionType alter_function_type;\n+\tAlterScalarFunctionType alter_scalar_function_type;\n \n public:\n \tCatalogType GetCatalogType() const override;\n@@ -32,11 +32,11 @@ struct AlterFunctionInfo : public AlterInfo {\n };\n \n //===--------------------------------------------------------------------===//\n-// AddFunctionOverloadInfo\n+// AddScalarFunctionOverloadInfo\n //===--------------------------------------------------------------------===//\n-struct AddFunctionOverloadInfo : public AlterFunctionInfo {\n-\tAddFunctionOverloadInfo(AlterEntryData data, ScalarFunctionSet new_overloads);\n-\t~AddFunctionOverloadInfo() override;\n+struct AddScalarFunctionOverloadInfo : public AlterScalarFunctionInfo {\n+\tAddScalarFunctionOverloadInfo(AlterEntryData data, ScalarFunctionSet new_overloads);\n+\t~AddScalarFunctionOverloadInfo() override;\n \n \tScalarFunctionSet new_overloads;\n \ndiff --git a/src/include/duckdb/parser/parsed_data/alter_table_function_info.hpp b/src/include/duckdb/parser/parsed_data/alter_table_function_info.hpp\nnew file mode 100644\nindex 000000000000..17330e46d6f9\n--- /dev/null\n+++ b/src/include/duckdb/parser/parsed_data/alter_table_function_info.hpp\n@@ -0,0 +1,47 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/parser/parsed_data/alter_scalar_function_info.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#pragma once\n+\n+#include \"duckdb/function/function_set.hpp\"\n+#include \"duckdb/function/table_function.hpp\"\n+#include \"duckdb/parser/parsed_data/alter_info.hpp\"\n+\n+namespace duckdb {\n+\n+//===--------------------------------------------------------------------===//\n+// Alter Table Function\n+//===--------------------------------------------------------------------===//\n+enum class AlterTableFunctionType : uint8_t { INVALID = 0, ADD_FUNCTION_OVERLOADS = 1 };\n+\n+struct AlterTableFunctionInfo : public AlterInfo {\n+\tAlterTableFunctionInfo(AlterTableFunctionType type, AlterEntryData data);\n+\tvirtual ~AlterTableFunctionInfo() override;\n+\n+\tAlterTableFunctionType alter_table_function_type;\n+\n+public:\n+\tCatalogType GetCatalogType() const override;\n+\tvoid Serialize(FieldWriter &writer) const override;\n+\tstatic unique_ptr<AlterInfo> Deserialize(FieldReader &reader);\n+};\n+\n+//===--------------------------------------------------------------------===//\n+// AddTableFunctionOverloadInfo\n+//===--------------------------------------------------------------------===//\n+struct AddTableFunctionOverloadInfo : public AlterTableFunctionInfo {\n+\tAddTableFunctionOverloadInfo(AlterEntryData data, TableFunctionSet new_overloads);\n+\t~AddTableFunctionOverloadInfo() override;\n+\n+\tTableFunctionSet new_overloads;\n+\n+public:\n+\tunique_ptr<AlterInfo> Copy() const override;\n+};\n+\n+} // namespace duckdb\ndiff --git a/src/include/duckdb/parser/parsed_data/create_table_function_info.hpp b/src/include/duckdb/parser/parsed_data/create_table_function_info.hpp\nindex a50c139103f8..1e64b6c60741 100644\n--- a/src/include/duckdb/parser/parsed_data/create_table_function_info.hpp\n+++ b/src/include/duckdb/parser/parsed_data/create_table_function_info.hpp\n@@ -21,7 +21,8 @@ struct CreateTableFunctionInfo : public CreateFunctionInfo {\n \tTableFunctionSet functions;\n \n public:\n-\tDUCKDB_API unique_ptr<CreateInfo> Copy() const;\n+\tDUCKDB_API unique_ptr<CreateInfo> Copy() const override;\n+\tDUCKDB_API unique_ptr<AlterInfo> GetAlterInfo() const override;\n };\n \n } // namespace duckdb\ndiff --git a/src/optimizer/statistics/operator/propagate_join.cpp b/src/optimizer/statistics/operator/propagate_join.cpp\nindex 9262c2c79c26..b26641ac724e 100644\n--- a/src/optimizer/statistics/operator/propagate_join.cpp\n+++ b/src/optimizer/statistics/operator/propagate_join.cpp\n@@ -83,12 +83,8 @@ void StatisticsPropagator::PropagateStatistics(LogicalComparisonJoin &join, uniq\n \t\t\t\t\t\t*node_ptr = std::move(cross_product);\n \t\t\t\t\t\treturn;\n \t\t\t\t\t}\n-\t\t\t\t\tcase JoinType::INNER:\n-\t\t\t\t\tcase JoinType::LEFT:\n-\t\t\t\t\tcase JoinType::RIGHT:\n-\t\t\t\t\tcase JoinType::OUTER: {\n-\t\t\t\t\t\t// inner/left/right/full outer join, replace with cross product\n-\t\t\t\t\t\t// since the condition is always true, left/right/outer join are equivalent to inner join here\n+\t\t\t\t\tcase JoinType::INNER: {\n+\t\t\t\t\t\t// inner, replace with cross product\n \t\t\t\t\t\tauto cross_product =\n \t\t\t\t\t\t    LogicalCrossProduct::Create(std::move(join.children[0]), std::move(join.children[1]));\n \t\t\t\t\t\t*node_ptr = std::move(cross_product);\ndiff --git a/src/parser/parsed_data/CMakeLists.txt b/src/parser/parsed_data/CMakeLists.txt\nindex 89e3ee0368e7..483863ffb168 100644\n--- a/src/parser/parsed_data/CMakeLists.txt\n+++ b/src/parser/parsed_data/CMakeLists.txt\n@@ -1,8 +1,9 @@\n add_library_unity(\n   duckdb_parsed_data\n   OBJECT\n-  alter_function_info.cpp\n   alter_info.cpp\n+  alter_scalar_function_info.cpp\n+  alter_table_function_info.cpp\n   alter_table_info.cpp\n   create_info.cpp\n   create_index_info.cpp\ndiff --git a/src/parser/parsed_data/alter_function_info.cpp b/src/parser/parsed_data/alter_function_info.cpp\ndeleted file mode 100644\nindex afe43d5c39bc..000000000000\n--- a/src/parser/parsed_data/alter_function_info.cpp\n+++ /dev/null\n@@ -1,55 +0,0 @@\n-#include \"duckdb/parser/parsed_data/alter_function_info.hpp\"\n-\n-#include \"duckdb/common/field_writer.hpp\"\n-#include \"duckdb/parser/constraint.hpp\"\n-\n-namespace duckdb {\n-\n-//===--------------------------------------------------------------------===//\n-// AlterFunctionInfo\n-//===--------------------------------------------------------------------===//\n-AlterFunctionInfo::AlterFunctionInfo(AlterFunctionType type, AlterEntryData data)\n-    : AlterInfo(AlterType::ALTER_FUNCTION, std::move(data.catalog), std::move(data.schema), std::move(data.name),\n-                data.if_exists),\n-      alter_function_type(type) {\n-}\n-AlterFunctionInfo::~AlterFunctionInfo() {\n-}\n-\n-CatalogType AlterFunctionInfo::GetCatalogType() const {\n-\treturn CatalogType::SCALAR_FUNCTION_ENTRY;\n-}\n-\n-void AlterFunctionInfo::Serialize(FieldWriter &writer) const {\n-\twriter.WriteField<AlterFunctionType>(alter_function_type);\n-\twriter.WriteString(catalog);\n-\twriter.WriteString(schema);\n-\twriter.WriteString(name);\n-\twriter.WriteField(if_exists);\n-}\n-\n-unique_ptr<AlterInfo> AlterFunctionInfo::Deserialize(FieldReader &reader) {\n-\t//\tauto type = reader.ReadRequired<AlterFunctionType>();\n-\t//\tauto schema = reader.ReadRequired<string>();\n-\t//\tauto table = reader.ReadRequired<string>();\n-\t//\tauto if_exists = reader.ReadRequired<bool>();\n-\n-\tthrow NotImplementedException(\"AlterFunctionInfo cannot be deserialized\");\n-}\n-\n-//===--------------------------------------------------------------------===//\n-// AddFunctionOverloadInfo\n-//===--------------------------------------------------------------------===//\n-AddFunctionOverloadInfo::AddFunctionOverloadInfo(AlterEntryData data, ScalarFunctionSet new_overloads_p)\n-    : AlterFunctionInfo(AlterFunctionType::ADD_FUNCTION_OVERLOADS, std::move(data)),\n-      new_overloads(std::move(new_overloads_p)) {\n-\tthis->allow_internal = true;\n-}\n-AddFunctionOverloadInfo::~AddFunctionOverloadInfo() {\n-}\n-\n-unique_ptr<AlterInfo> AddFunctionOverloadInfo::Copy() const {\n-\treturn make_unique_base<AlterInfo, AddFunctionOverloadInfo>(GetAlterEntryData(), new_overloads);\n-}\n-\n-} // namespace duckdb\ndiff --git a/src/parser/parsed_data/alter_info.cpp b/src/parser/parsed_data/alter_info.cpp\nindex 84e14be10b23..40d641546f20 100644\n--- a/src/parser/parsed_data/alter_info.cpp\n+++ b/src/parser/parsed_data/alter_info.cpp\n@@ -1,6 +1,7 @@\n #include \"duckdb/parser/parsed_data/alter_info.hpp\"\n #include \"duckdb/parser/parsed_data/alter_table_info.hpp\"\n-#include \"duckdb/parser/parsed_data/alter_function_info.hpp\"\n+#include \"duckdb/parser/parsed_data/alter_scalar_function_info.hpp\"\n+#include \"duckdb/parser/parsed_data/alter_table_function_info.hpp\"\n \n #include \"duckdb/common/field_writer.hpp\"\n \n@@ -33,8 +34,11 @@ unique_ptr<AlterInfo> AlterInfo::Deserialize(Deserializer &source) {\n \tcase AlterType::ALTER_VIEW:\n \t\tresult = AlterViewInfo::Deserialize(reader);\n \t\tbreak;\n-\tcase AlterType::ALTER_FUNCTION:\n-\t\tresult = AlterFunctionInfo::Deserialize(reader);\n+\tcase AlterType::ALTER_SCALAR_FUNCTION:\n+\t\tresult = AlterScalarFunctionInfo::Deserialize(reader);\n+\t\tbreak;\n+\tcase AlterType::ALTER_TABLE_FUNCTION:\n+\t\tresult = AlterTableFunctionInfo::Deserialize(reader);\n \t\tbreak;\n \tdefault:\n \t\tthrow SerializationException(\"Unknown alter type for deserialization!\");\ndiff --git a/src/parser/parsed_data/alter_scalar_function_info.cpp b/src/parser/parsed_data/alter_scalar_function_info.cpp\nnew file mode 100644\nindex 000000000000..43e5c6abb019\n--- /dev/null\n+++ b/src/parser/parsed_data/alter_scalar_function_info.cpp\n@@ -0,0 +1,56 @@\n+#include \"duckdb/parser/parsed_data/alter_scalar_function_info.hpp\"\n+\n+#include \"duckdb/common/field_writer.hpp\"\n+#include \"duckdb/parser/constraint.hpp\"\n+\n+namespace duckdb {\n+\n+//===--------------------------------------------------------------------===//\n+// AlterScalarFunctionInfo\n+//===--------------------------------------------------------------------===//\n+AlterScalarFunctionInfo::AlterScalarFunctionInfo(AlterScalarFunctionType type, AlterEntryData data)\n+    : AlterInfo(AlterType::ALTER_SCALAR_FUNCTION, std::move(data.catalog), std::move(data.schema), std::move(data.name),\n+                data.if_exists),\n+      alter_scalar_function_type(type) {\n+}\n+AlterScalarFunctionInfo::~AlterScalarFunctionInfo() {\n+}\n+\n+CatalogType AlterScalarFunctionInfo::GetCatalogType() const {\n+\treturn CatalogType::SCALAR_FUNCTION_ENTRY;\n+}\n+\n+void AlterScalarFunctionInfo::Serialize(FieldWriter &writer) const {\n+\twriter.WriteField<AlterScalarFunctionType>(alter_scalar_function_type);\n+\twriter.WriteString(catalog);\n+\twriter.WriteString(schema);\n+\twriter.WriteString(name);\n+\twriter.WriteField(if_exists);\n+}\n+\n+unique_ptr<AlterInfo> AlterScalarFunctionInfo::Deserialize(FieldReader &reader) {\n+\t//\tauto type = reader.ReadRequired<AlterScalarFunctionType>();\n+\t//\tauto schema = reader.ReadRequired<string>();\n+\t//\tauto table = reader.ReadRequired<string>();\n+\t//\tauto if_exists = reader.ReadRequired<bool>();\n+\n+\tthrow NotImplementedException(\"AlterScalarFunctionInfo cannot be deserialized\");\n+}\n+\n+//===--------------------------------------------------------------------===//\n+// AddScalarFunctionOverloadInfo\n+//===--------------------------------------------------------------------===//\n+AddScalarFunctionOverloadInfo::AddScalarFunctionOverloadInfo(AlterEntryData data, ScalarFunctionSet new_overloads_p)\n+    : AlterScalarFunctionInfo(AlterScalarFunctionType::ADD_FUNCTION_OVERLOADS, std::move(data)),\n+      new_overloads(std::move(new_overloads_p)) {\n+\tthis->allow_internal = true;\n+}\n+\n+AddScalarFunctionOverloadInfo::~AddScalarFunctionOverloadInfo() {\n+}\n+\n+unique_ptr<AlterInfo> AddScalarFunctionOverloadInfo::Copy() const {\n+\treturn make_unique_base<AlterInfo, AddScalarFunctionOverloadInfo>(GetAlterEntryData(), new_overloads);\n+}\n+\n+} // namespace duckdb\ndiff --git a/src/parser/parsed_data/alter_table_function_info.cpp b/src/parser/parsed_data/alter_table_function_info.cpp\nnew file mode 100644\nindex 000000000000..01a9f642f929\n--- /dev/null\n+++ b/src/parser/parsed_data/alter_table_function_info.cpp\n@@ -0,0 +1,51 @@\n+#include \"duckdb/parser/parsed_data/alter_table_function_info.hpp\"\n+\n+#include \"duckdb/common/field_writer.hpp\"\n+#include \"duckdb/parser/constraint.hpp\"\n+\n+namespace duckdb {\n+\n+//===--------------------------------------------------------------------===//\n+// AlterTableFunctionInfo\n+//===--------------------------------------------------------------------===//\n+AlterTableFunctionInfo::AlterTableFunctionInfo(AlterTableFunctionType type, AlterEntryData data)\n+    : AlterInfo(AlterType::ALTER_TABLE_FUNCTION, std::move(data.catalog), std::move(data.schema), std::move(data.name),\n+                data.if_exists),\n+      alter_table_function_type(type) {\n+}\n+AlterTableFunctionInfo::~AlterTableFunctionInfo() {\n+}\n+\n+CatalogType AlterTableFunctionInfo::GetCatalogType() const {\n+\treturn CatalogType::TABLE_FUNCTION_ENTRY;\n+}\n+\n+void AlterTableFunctionInfo::Serialize(FieldWriter &writer) const {\n+\twriter.WriteField<AlterTableFunctionType>(alter_table_function_type);\n+\twriter.WriteString(catalog);\n+\twriter.WriteString(schema);\n+\twriter.WriteString(name);\n+\twriter.WriteField(if_exists);\n+}\n+\n+unique_ptr<AlterInfo> AlterTableFunctionInfo::Deserialize(FieldReader &reader) {\n+\tthrow NotImplementedException(\"AlterTableFunctionInfo cannot be deserialized\");\n+}\n+\n+//===--------------------------------------------------------------------===//\n+// AddTableFunctionOverloadInfo\n+//===--------------------------------------------------------------------===//\n+AddTableFunctionOverloadInfo::AddTableFunctionOverloadInfo(AlterEntryData data, TableFunctionSet new_overloads_p)\n+    : AlterTableFunctionInfo(AlterTableFunctionType::ADD_FUNCTION_OVERLOADS, std::move(data)),\n+      new_overloads(std::move(new_overloads_p)) {\n+\tthis->allow_internal = true;\n+}\n+\n+AddTableFunctionOverloadInfo::~AddTableFunctionOverloadInfo() {\n+}\n+\n+unique_ptr<AlterInfo> AddTableFunctionOverloadInfo::Copy() const {\n+\treturn make_unique_base<AlterInfo, AddTableFunctionOverloadInfo>(GetAlterEntryData(), new_overloads);\n+}\n+\n+} // namespace duckdb\ndiff --git a/src/parser/parsed_data/create_scalar_function_info.cpp b/src/parser/parsed_data/create_scalar_function_info.cpp\nindex 4c69e1c60ac8..9ea84368fc63 100644\n--- a/src/parser/parsed_data/create_scalar_function_info.cpp\n+++ b/src/parser/parsed_data/create_scalar_function_info.cpp\n@@ -1,5 +1,5 @@\n #include \"duckdb/parser/parsed_data/create_scalar_function_info.hpp\"\n-#include \"duckdb/parser/parsed_data/alter_function_info.hpp\"\n+#include \"duckdb/parser/parsed_data/alter_scalar_function_info.hpp\"\n \n namespace duckdb {\n \n@@ -27,7 +27,8 @@ unique_ptr<CreateInfo> CreateScalarFunctionInfo::Copy() const {\n }\n \n unique_ptr<AlterInfo> CreateScalarFunctionInfo::GetAlterInfo() const {\n-\treturn make_unique_base<AlterInfo, AddFunctionOverloadInfo>(AlterEntryData(catalog, schema, name, true), functions);\n+\treturn make_unique_base<AlterInfo, AddScalarFunctionOverloadInfo>(AlterEntryData(catalog, schema, name, true),\n+\t                                                                  functions);\n }\n \n } // namespace duckdb\ndiff --git a/src/parser/parsed_data/create_table_function_info.cpp b/src/parser/parsed_data/create_table_function_info.cpp\nindex 8c32ca05809c..dcfcd3dd5c82 100644\n--- a/src/parser/parsed_data/create_table_function_info.cpp\n+++ b/src/parser/parsed_data/create_table_function_info.cpp\n@@ -1,4 +1,5 @@\n #include \"duckdb/parser/parsed_data/create_table_function_info.hpp\"\n+#include \"duckdb/parser/parsed_data/alter_table_function_info.hpp\"\n \n namespace duckdb {\n \n@@ -25,4 +26,9 @@ unique_ptr<CreateInfo> CreateTableFunctionInfo::Copy() const {\n \treturn std::move(result);\n }\n \n+unique_ptr<AlterInfo> CreateTableFunctionInfo::GetAlterInfo() const {\n+\treturn make_unique_base<AlterInfo, AddTableFunctionOverloadInfo>(AlterEntryData(catalog, schema, name, true),\n+\t                                                                 functions);\n+}\n+\n } // namespace duckdb\ndiff --git a/third_party/fmt/include/fmt/core.h b/third_party/fmt/include/fmt/core.h\nindex 6094a5ab3987..3ffed651d849 100644\n--- a/third_party/fmt/include/fmt/core.h\n+++ b/third_party/fmt/include/fmt/core.h\n@@ -359,12 +359,11 @@ using wstring_view = basic_string_view<wchar_t>;\n #if FMT_HAS_FEATURE(__cpp_char8_t)\n typedef char8_t fmt_char8_t;\n #else\n-typedef unsigned char fmt_char8_t;\n+typedef char fmt_char8_t;\n #endif\n \n /** Specifies if ``T`` is a character type. Can be specialized by users. */\n template <typename T> struct is_char : std::false_type {};\n-template <> struct is_char<char> : std::true_type {};\n template <> struct is_char<wchar_t> : std::true_type {};\n template <> struct is_char<fmt_char8_t> : std::true_type {};\n template <> struct is_char<char16_t> : std::true_type {};\ndiff --git a/tools/pythonpkg/cibw.toml b/tools/pythonpkg/cibw.toml\nindex 1ec2919141bd..bdc8ea5489df 100644\n--- a/tools/pythonpkg/cibw.toml\n+++ b/tools/pythonpkg/cibw.toml\n@@ -4,7 +4,7 @@\n [tool.cibuildwheel]\n environment = \"PIP_CONSTRAINT='build-constraints.txt'\"\n before-build = 'pip install oldest-supported-numpy'\n-before-test = 'pip install --prefer-binary \"pandas>=0.24\" pytest-timeout mypy \"psutil>=5.9.0\" \"requests>=2.26\" fsspec && (pip install --prefer-binary \"pyarrow>=8.0\" || true)'\n+before-test = 'pip install --prefer-binary \"pandas>=0.24\" pytest-timeout mypy \"psutil>=5.9.0\" \"requests>=2.26\" fsspec && (pip install --prefer-binary \"pyarrow>=8.0\" || true) && (pip install --prefer-binary \"polars\" || true)'\n test-requires = 'pytest'\n test-command = 'DUCKDB_PYTHON_TEST_EXTENSION_PATH={project} DUCKDB_PYTHON_TEST_EXTENSION_REQUIRED=1 python -m pytest {project}/tests'\n \ndiff --git a/tools/pythonpkg/src/CMakeLists.txt b/tools/pythonpkg/src/CMakeLists.txt\nindex 43b087d5a794..fce2637eb8bb 100644\n--- a/tools/pythonpkg/src/CMakeLists.txt\n+++ b/tools/pythonpkg/src/CMakeLists.txt\n@@ -15,6 +15,7 @@ add_library(\n   pyconnection.cpp\n   python_import_cache.cpp\n   pyrelation.cpp\n+  dataframe.cpp\n   pyresult.cpp\n   map.cpp\n   vector_conversion.cpp\ndiff --git a/tools/pythonpkg/src/dataframe.cpp b/tools/pythonpkg/src/dataframe.cpp\nnew file mode 100644\nindex 000000000000..fd9c16518949\n--- /dev/null\n+++ b/tools/pythonpkg/src/dataframe.cpp\n@@ -0,0 +1,31 @@\n+#include \"duckdb_python/dataframe.hpp\"\n+#include \"duckdb_python/pyconnection.hpp\"\n+\n+namespace duckdb {\n+bool PolarsDataFrame::IsDataFrame(const py::handle &object) {\n+\tif (!ModuleIsLoaded<PolarsCacheItem>()) {\n+\t\treturn false;\n+\t}\n+\tauto &import_cache = *DuckDBPyConnection::ImportCache();\n+\treturn import_cache.polars().DataFrame.IsInstance(object);\n+}\n+\n+bool PolarsDataFrame::IsLazyFrame(const py::handle &object) {\n+\tif (!ModuleIsLoaded<PolarsCacheItem>()) {\n+\t\treturn false;\n+\t}\n+\tauto &import_cache = *DuckDBPyConnection::ImportCache();\n+\treturn import_cache.polars().LazyFrame.IsInstance(object);\n+}\n+\n+bool DataFrame::check_(const py::handle &object) { // NOLINT\n+\tauto &import_cache = *DuckDBPyConnection::ImportCache();\n+\treturn import_cache.pandas().DataFrame.IsInstance(object);\n+}\n+\n+bool PolarsDataFrame::check_(const py::handle &object) { // NOLINT\n+\tauto &import_cache = *DuckDBPyConnection::ImportCache();\n+\treturn import_cache.polars().DataFrame.IsInstance(object);\n+}\n+\n+} // namespace duckdb\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/dataframe.hpp b/tools/pythonpkg/src/include/duckdb_python/dataframe.hpp\nnew file mode 100644\nindex 000000000000..3852830cb08f\n--- /dev/null\n+++ b/tools/pythonpkg/src/include/duckdb_python/dataframe.hpp\n@@ -0,0 +1,37 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb_python/pandas_dataframe.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#pragma once\n+\n+#include \"duckdb/common/types.hpp\"\n+#include \"duckdb_python/pybind_wrapper.hpp\"\n+\n+namespace duckdb {\n+\n+class DataFrame : public py::object {\n+public:\n+\tDataFrame(const py::object &o) : py::object(o, borrowed_t {}) {\n+\t}\n+\tusing py::object::object;\n+\n+public:\n+\tstatic bool check_(const py::handle &object); // NOLINT\n+};\n+\n+class PolarsDataFrame : public py::object {\n+public:\n+\tPolarsDataFrame(const py::object &o) : py::object(o, borrowed_t {}) {\n+\t}\n+\tusing py::object::object;\n+\n+public:\n+\tstatic bool IsDataFrame(const py::handle &object);\n+\tstatic bool IsLazyFrame(const py::handle &object);\n+\tstatic bool check_(const py::handle &object); // NOLINT\n+};\n+} // namespace duckdb\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/pandas_type.hpp b/tools/pythonpkg/src/include/duckdb_python/pandas_type.hpp\nindex 2d19de3c76fc..8176b126d6dc 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/pandas_type.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/pandas_type.hpp\n@@ -1,33 +1,18 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb_python/pandas_type.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n #pragma once\n \n-#include \"duckdb_python/pybind_wrapper.hpp\"\n #include \"duckdb/common/types.hpp\"\n+#include \"duckdb_python/pybind_wrapper.hpp\"\n+#include \"duckdb_python/dataframe.hpp\"\n \n namespace duckdb {\n-\n-class DataFrame : public py::object {\n-public:\n-\tDataFrame(const py::object &o) : py::object(o, borrowed_t {}) {\n-\t}\n-\tusing py::object::object;\n-\n-public:\n-\tstatic bool check_(const py::handle &object) {\n-\t\treturn !object.is_none();\n-\t}\n-};\n-\n-class PolarsDataFrame : public py::object {\n-public:\n-\tPolarsDataFrame(const py::object &o) : py::object(o, borrowed_t {}) {\n-\t}\n-\tusing py::object::object;\n-\n-public:\n-\tstatic bool IsDataFrame(const py::handle &object);\n-\tstatic bool IsLazyFrame(const py::handle &object);\n-};\n-\n // Pandas has two different sets of types\n // NumPy dtypes (e.g., bool, int8,...)\n // Pandas Specific Types (e.g., categorical, datetime_tz,...)\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/pyconnection.hpp b/tools/pythonpkg/src/include/duckdb_python/pyconnection.hpp\nindex 6066deb4c539..343c9431a48a 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/pyconnection.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/pyconnection.hpp\n@@ -7,9 +7,6 @@\n //===----------------------------------------------------------------------===//\n \n #pragma once\n-\n-#include <utility>\n-\n #include \"arrow_array_stream.hpp\"\n #include \"duckdb.hpp\"\n #include \"duckdb_python/pybind_wrapper.hpp\"\n@@ -180,4 +177,10 @@ struct DuckDBPyConnection : public std::enable_shared_from_this<DuckDBPyConnecti\n \tstatic void DetectEnvironment();\n };\n \n+template <class T>\n+static bool ModuleIsLoaded() {\n+\tauto dict = pybind11::module_::import(\"sys\").attr(\"modules\");\n+\treturn dict.contains(py::str(T::Name));\n+}\n+\n } // namespace duckdb\ndiff --git a/tools/pythonpkg/src/pyconnection.cpp b/tools/pythonpkg/src/pyconnection.cpp\nindex 7566a7d03e28..3b221d29b9f8 100644\n--- a/tools/pythonpkg/src/pyconnection.cpp\n+++ b/tools/pythonpkg/src/pyconnection.cpp\n@@ -1,15 +1,21 @@\n #include \"duckdb_python/pyconnection.hpp\"\n \n+#include \"duckdb/catalog/default/default_types.hpp\"\n #include \"duckdb/common/arrow/arrow.hpp\"\n+#include \"duckdb/common/enums/file_compression_type.hpp\"\n #include \"duckdb/common/printer.hpp\"\n #include \"duckdb/common/types.hpp\"\n #include \"duckdb/common/types/vector.hpp\"\n+#include \"duckdb/function/table/read_csv.hpp\"\n+#include \"duckdb/main/client_config.hpp\"\n #include \"duckdb/main/client_context.hpp\"\n #include \"duckdb/main/config.hpp\"\n-#include \"duckdb/main/relation/read_csv_relation.hpp\"\n-#include \"duckdb/main/relation/read_json_relation.hpp\"\n #include \"duckdb/main/db_instance_cache.hpp\"\n #include \"duckdb/main/extension_helper.hpp\"\n+#include \"duckdb/main/prepared_statement.hpp\"\n+#include \"duckdb/main/relation/read_csv_relation.hpp\"\n+#include \"duckdb/main/relation/read_json_relation.hpp\"\n+#include \"duckdb/main/relation/value_relation.hpp\"\n #include \"duckdb/parser/expression/constant_expression.hpp\"\n #include \"duckdb/parser/expression/function_expression.hpp\"\n #include \"duckdb/parser/parsed_data/create_table_function_info.hpp\"\n@@ -41,12 +47,6 @@ DBInstanceCache instance_cache;\n shared_ptr<PythonImportCache> DuckDBPyConnection::import_cache = nullptr;\n PythonEnvironmentType DuckDBPyConnection::environment = PythonEnvironmentType::NORMAL;\n \n-template <class T>\n-static bool ModuleIsLoaded() {\n-\tauto dict = pybind11::module_::import(\"sys\").attr(\"modules\");\n-\treturn dict.contains(py::str(T::Name));\n-}\n-\n void DuckDBPyConnection::DetectEnvironment() {\n \t// If __main__ does not have a __file__ attribute, we are in interactive mode\n \tauto main_module = py::module_::import(\"__main__\");\n@@ -1301,22 +1301,6 @@ void DuckDBPyConnection::Cleanup() {\n \timport_cache.reset();\n }\n \n-bool PolarsDataFrame::IsDataFrame(const py::handle &object) {\n-\tif (!ModuleIsLoaded<PolarsCacheItem>()) {\n-\t\treturn false;\n-\t}\n-\tauto &import_cache = *DuckDBPyConnection::ImportCache();\n-\treturn import_cache.polars().DataFrame.IsInstance(object);\n-}\n-\n-bool PolarsDataFrame::IsLazyFrame(const py::handle &object) {\n-\tif (!ModuleIsLoaded<PolarsCacheItem>()) {\n-\t\treturn false;\n-\t}\n-\tauto &import_cache = *DuckDBPyConnection::ImportCache();\n-\treturn import_cache.polars().LazyFrame.IsInstance(object);\n-}\n-\n bool DuckDBPyConnection::IsPandasDataframe(const py::object &object) {\n \tif (!ModuleIsLoaded<PandasCacheItem>()) {\n \t\treturn false;\ndiff --git a/tools/rpkg/src/relational.cpp b/tools/rpkg/src/relational.cpp\nindex 5fd48993df78..e16605c4ad9f 100644\n--- a/tools/rpkg/src/relational.cpp\n+++ b/tools/rpkg/src/relational.cpp\n@@ -168,7 +168,7 @@ external_pointer<T> make_external(const string &rclass, ARGS &&... args) {\n \tvector<OrderByNode> res_orders;\n \n \tfor (expr_extptr_t expr : orders) {\n-\t\tres_orders.emplace_back(OrderType::ASCENDING, OrderByNullType::NULLS_FIRST, expr->Copy());\n+\t\tres_orders.emplace_back(OrderType::ASCENDING, OrderByNullType::NULLS_LAST, expr->Copy());\n \t}\n \n \tauto res = std::make_shared<OrderRelation>(rel->rel, std::move(res_orders));\n",
  "test_patch": "diff --git a/test/optimizer/statistics/statistics_join.test b/test/optimizer/statistics/statistics_join.test\nindex 637a96020ed7..74aacecc4f87 100644\n--- a/test/optimizer/statistics/statistics_join.test\n+++ b/test/optimizer/statistics/statistics_join.test\n@@ -67,12 +67,6 @@ EXPLAIN SELECT i1.i FROM integers i1 LEFT JOIN integers2 i2 ON i1.i=i2.i ORDER B\n ----\n logical_opt\t<REGEX>:.*EMPTY_RESULT.*\n \n-# left join with guaranteed match: same as inner join\n-query II\n-EXPLAIN SELECT i1.i FROM integers i1 LEFT JOIN integers2 i2 ON i1.i<i2.i ORDER BY 1;\n-----\n-logical_opt\t<REGEX>:.*CROSS_PRODUCT.*\n-\n # semi join\n # join cannot match: replaced with empty result\n query II\ndiff --git a/test/sql/copy/csv/csv_quoted_newline_incorrect.test b/test/sql/copy/csv/csv_quoted_newline_incorrect.test\nnew file mode 100644\nindex 000000000000..8831b8b34588\n--- /dev/null\n+++ b/test/sql/copy/csv/csv_quoted_newline_incorrect.test\n@@ -0,0 +1,13 @@\n+# name: test/sql/copy/csv/csv_quoted_newline_incorrect.test\n+# description: Read a CSV with a null byte\n+# group: [csv]\n+\n+require vector_size 512\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement error\n+select * from 'data/csv/csv_quoted_newline_odd.csv';\n+----\n+csv_quoted_newline_odd.csv\": CSV options could not be auto-detected\ndiff --git a/test/sql/join/left_outer/left_join_issue_6341.test b/test/sql/join/left_outer/left_join_issue_6341.test\nnew file mode 100644\nindex 000000000000..3ad233d08b28\n--- /dev/null\n+++ b/test/sql/join/left_outer/left_join_issue_6341.test\n@@ -0,0 +1,37 @@\n+# name: test/sql/join/left_outer/left_join_issue_6341.test\n+# description: Issue #6341: No rows returned in LEFT JOIN with < or > against table having no rows\n+# group: [left_outer]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+CREATE TABLE foo (ts TIMESTAMP);\n+\n+statement ok\n+CREATE TABLE bar (ts TIMESTAMP);\n+\n+\n+statement ok\n+INSERT INTO foo VALUES ('2023-01-01 00:00:00');\n+\n+statement ok\n+INSERT INTO foo VALUES ('2023-01-01 00:00:01');\n+\n+query II\n+SELECT foo.ts foo, bar.ts bar FROM foo LEFT JOIN bar ON foo.ts = bar.ts;\n+----\n+2023-01-01 00:00:00\tNULL\n+2023-01-01 00:00:01\tNULL\n+\n+query II\n+SELECT foo.ts foo, bar.ts bar FROM foo LEFT JOIN bar ON foo.ts < bar.ts;\n+----\n+2023-01-01 00:00:00\tNULL\n+2023-01-01 00:00:01\tNULL\n+\n+query II\n+SELECT foo.ts foo, bar.ts bar FROM foo LEFT JOIN bar ON foo.ts > bar.ts;\n+----\n+2023-01-01 00:00:00\tNULL\n+2023-01-01 00:00:01\tNULL\ndiff --git a/test/sql/table_function/icu_range_timestamptz.test b/test/sql/table_function/icu_range_timestamptz.test\nnew file mode 100644\nindex 000000000000..70afcd278f4f\n--- /dev/null\n+++ b/test/sql/table_function/icu_range_timestamptz.test\n@@ -0,0 +1,144 @@\n+# name: test/sql/table_function/icu_range_timestamptz.test\n+# description: Test range function with TIMESTAMPTZ\n+# group: [table_function]\n+\n+require icu\n+\n+statement ok\n+SET Calendar = 'gregorian';\n+\n+statement ok\n+SET TimeZone = 'America/Los_Angeles';\n+\n+query I\n+SELECT d FROM range(TIMESTAMPTZ '1992-01-01 00:00:00-08', TIMESTAMPTZ '1992-01-01 12:00:00-08', INTERVAL (1) HOUR) tbl(d)\n+----\n+1992-01-01 00:00:00-08\n+1992-01-01 01:00:00-08\n+1992-01-01 02:00:00-08\n+1992-01-01 03:00:00-08\n+1992-01-01 04:00:00-08\n+1992-01-01 05:00:00-08\n+1992-01-01 06:00:00-08\n+1992-01-01 07:00:00-08\n+1992-01-01 08:00:00-08\n+1992-01-01 09:00:00-08\n+1992-01-01 10:00:00-08\n+1992-01-01 11:00:00-08\n+\n+# negative interval\n+query I\n+SELECT d FROM range(TIMESTAMPTZ '1992-01-01 00:00:00-08', TIMESTAMPTZ'1991-06-01 00:00:00-07', INTERVAL '1 MONTH ago') tbl(d)\n+----\n+1992-01-01 00:00:00-08\n+1991-12-01 00:00:00-08\n+1991-11-01 00:00:00-08\n+1991-10-01 00:00:00-07\n+1991-09-01 00:00:00-07\n+1991-08-01 00:00:00-07\n+1991-07-01 00:00:00-07\n+\n+query I\n+SELECT d FROM generate_series(TIMESTAMPTZ '1992-01-01 00:00:00-08', TIMESTAMPTZ '1991-06-01 00:00:00-07', -INTERVAL '1 MONTH') tbl(d)\n+----\n+1992-01-01 00:00:00-08\n+1991-12-01 00:00:00-08\n+1991-11-01 00:00:00-08\n+1991-10-01 00:00:00-07\n+1991-09-01 00:00:00-07\n+1991-08-01 00:00:00-07\n+1991-07-01 00:00:00-07\n+1991-06-01 00:00:00-07\n+\n+# composite interval\n+query I\n+SELECT d FROM range(TIMESTAMPTZ '1992-01-01 00:00:00-08', TIMESTAMPTZ '1992-12-31 12:00:00-08', INTERVAL '1 MONTH 1 DAY 1 HOUR') tbl(d)\n+----\n+1992-01-01 00:00:00-08\n+1992-02-02 01:00:00-08\n+1992-03-03 02:00:00-08\n+1992-04-04 03:00:00-08\n+1992-05-05 04:00:00-07\n+1992-06-06 05:00:00-07\n+1992-07-07 06:00:00-07\n+1992-08-08 07:00:00-07\n+1992-09-09 08:00:00-07\n+1992-10-10 09:00:00-07\n+1992-11-11 10:00:00-08\n+1992-12-12 11:00:00-08\n+\n+# DST boundaries\n+query I\n+SELECT d FROM generate_series(TIMESTAMPTZ '1992-04-05 00:00:00-08', TIMESTAMPTZ '1992-04-05 12:00:00-07', INTERVAL '1 HOUR') tbl(d)\n+----\n+1992-04-05 00:00:00-08\n+1992-04-05 01:00:00-08\n+1992-04-05 03:00:00-07\n+1992-04-05 04:00:00-07\n+1992-04-05 05:00:00-07\n+1992-04-05 06:00:00-07\n+1992-04-05 07:00:00-07\n+1992-04-05 08:00:00-07\n+1992-04-05 09:00:00-07\n+1992-04-05 10:00:00-07\n+1992-04-05 11:00:00-07\n+1992-04-05 12:00:00-07\n+\n+query I\n+SELECT d FROM generate_series(TIMESTAMPTZ '1992-10-25 00:00:00-07', TIMESTAMPTZ '1992-10-25 12:00:00-08', INTERVAL '1 HOUR') tbl(d)\n+----\n+1992-10-25 00:00:00-07\n+1992-10-25 01:00:00-07\n+1992-10-25 01:00:00-08\n+1992-10-25 02:00:00-08\n+1992-10-25 03:00:00-08\n+1992-10-25 04:00:00-08\n+1992-10-25 05:00:00-08\n+1992-10-25 06:00:00-08\n+1992-10-25 07:00:00-08\n+1992-10-25 08:00:00-08\n+1992-10-25 09:00:00-08\n+1992-10-25 10:00:00-08\n+1992-10-25 11:00:00-08\n+1992-10-25 12:00:00-08\n+\n+\n+# large result\n+query I\n+SELECT COUNT(*) FROM range(TIMESTAMPTZ '1992-01-01 00:00:00-08', TIMESTAMPTZ '2020-01-01 00:00:00-08', INTERVAL '1 DAY') tbl(d)\n+----\n+10227\n+\n+query I\n+SELECT COUNT(*) FROM generate_series(TIMESTAMPTZ '1992-01-01 00:00:00-08', TIMESTAMPTZ '2020-01-01 00:00:00-08', INTERVAL '1 DAY') tbl(d)\n+----\n+10228\n+\n+# zero interval not supported\n+statement error\n+SELECT d FROM range(TIMESTAMPTZ '1992-01-01 00:00:00-08', TIMESTAMPTZ '1992-12-31 12:00:00-08', INTERVAL '0 MONTH') tbl(d)\n+\n+# start is smaller than end but we have a negative interval\n+statement error\n+SELECT d FROM range(TIMESTAMPTZ '1992-01-01 00:00:00-08', TIMESTAMPTZ '1992-12-31 12:00:00-08', INTERVAL '1 MONTH ago') tbl(d)\n+\n+# start is bigger than end but we have a positive interval\n+statement error\n+SELECT d FROM range(TIMESTAMPTZ '1993-01-01 00:00:00-08', TIMESTAMPTZ '1992-01-01 00:00:00-08', INTERVAL '1 MONTH') tbl(d)\n+\n+# composite interval with negative types not supported\n+statement error\n+SELECT d FROM range(TIMESTAMPTZ '1992-01-01 00:00:00-08', TIMESTAMPTZ '1992-12-31 12:00:00-08', INTERVAL '1 MONTH' - INTERVAL '1 HOUR') tbl(d)\n+\n+# Infinities will overflow or cause infinite loops (PG behaviour!) so we ban them\n+statement error\n+SELECT COUNT(*) FROM generate_series('294247-01-09'::TIMESTAMPTZ, 'infinity'::TIMESTAMPTZ, INTERVAL '1 DAY');\n+\n+statement error\n+SELECT COUNT(*) FROM range('294247-01-09'::TIMESTAMPTZ, 'infinity'::TIMESTAMPTZ, INTERVAL '1 DAY');\n+\n+statement error\n+SELECT COUNT(*) FROM generate_series('-infinity'::TIMESTAMPTZ, '290303-12-11 (BC) 00:00:00'::TIMESTAMPTZ, INTERVAL '1 DAY');\n+\n+statement error\n+SELECT COUNT(*) FROM range('-infinity'::TIMESTAMPTZ, '290303-12-11 (BC) 00:00:00'::TIMESTAMPTZ, INTERVAL '1 DAY');\ndiff --git a/tools/pythonpkg/tests/fast/arrow/test_polars.py b/tools/pythonpkg/tests/fast/arrow/test_polars.py\nindex ee422076f36b..6849f809b200 100644\n--- a/tools/pythonpkg/tests/fast/arrow/test_polars.py\n+++ b/tools/pythonpkg/tests/fast/arrow/test_polars.py\n@@ -4,6 +4,8 @@\n class TestPolars(object):\n     def test_polars(self,duckdb_cursor):\n         pl = pytest.importorskip(\"polars\")\n+        # We also need arrow to do this conversion\n+        arrow = pytest.importorskip(\"pyarrow\")\n         pl_testing = pytest.importorskip(\"polars.testing\")\n         df = pl.DataFrame(\n             {\ndiff --git a/tools/pythonpkg/tests/fast/test_runtime_error.py b/tools/pythonpkg/tests/fast/test_runtime_error.py\nindex 71fc36a7be01..2092bcba8c8b 100644\n--- a/tools/pythonpkg/tests/fast/test_runtime_error.py\n+++ b/tools/pythonpkg/tests/fast/test_runtime_error.py\n@@ -122,7 +122,7 @@ def test_closed_conn_exceptions(self):\n             conn.table_function(\"bla\")\n \n         with closed():\n-            conn.from_df(\"bla\")\n+            conn.from_df(df_in)\n \n         with closed():\n             conn.from_csv_auto(\"bla\")\ndiff --git a/tools/rpkg/tests/testthat/test_relational.R b/tools/rpkg/tests/testthat/test_relational.R\nindex f217f208fb73..707c133612fe 100644\n--- a/tools/rpkg/tests/testthat/test_relational.R\n+++ b/tools/rpkg/tests/testthat/test_relational.R\n@@ -121,6 +121,18 @@ test_that(\"we can get the relation object back from an altrep df\", {\n   expect_true(TRUE)\n })\n \n+test_that(\"rel_order() sorts NAs last\", {\n+  test_df <- rel_from_df(con, data.frame(a = c(NA, 1:3)))\n+\n+  orders <- list(expr_reference(\"a\"))\n+\n+  rel <- rel_order(test_df, orders)\n+  rel_df <- rel_to_altrep(rel)\n+  expect_false(df_is_materialized(rel_df))\n+\n+  expected_result <- data.frame(a = c(1:3, NA))\n+  expect_equal(rel_df, expected_result)\n+})\n \n test_that(\"Inner join returns all inner relations\", {\n     dbExecute(con, \"CREATE OR REPLACE MACRO eq(a, b) AS a = b\")\n",
  "problem_statement": "No rows returned in LEFT JOIN with < or > against table having no rows inserted\n### What happens?\r\n\r\nSee repro below.\r\n\r\nNote it only occurs with `<` and `>`, but not `=`, so perhaps an ordering issue?\r\n\r\n### To Reproduce\r\n\r\n```sql\r\nCREATE TABLE foo (ts TIMESTAMP);\r\nCREATE TABLE bar (ts TIMESTAMP);\r\n\r\nINSERT INTO foo VALUES ('2023-01-01 00:00:00');\r\nINSERT INTO foo VALUES ('2023-01-01 00:00:01');\r\n\r\n.print no rows in bar, no rows returned for < or >:\r\nSELECT foo.ts foo, bar.ts bar FROM foo LEFT JOIN bar ON foo.ts = bar.ts;\r\nSELECT foo.ts foo, bar.ts bar FROM foo LEFT JOIN bar ON foo.ts < bar.ts;\r\nSELECT foo.ts foo, bar.ts bar FROM foo LEFT JOIN bar ON foo.ts > bar.ts;\r\n\r\n.print with row in bar works as expected:\r\nINSERT INTO bar VALUES ('2023-01-01 00:00:01');\r\nSELECT foo.ts foo, bar.ts bar FROM foo LEFT JOIN bar ON foo.ts = bar.ts;\r\nSELECT foo.ts foo, bar.ts bar FROM foo LEFT JOIN bar ON foo.ts < bar.ts;\r\nSELECT foo.ts foo, bar.ts bar FROM foo LEFT JOIN bar ON foo.ts > bar.ts;\r\n\r\n.print delete row in bar and still works as expected:\r\nDELETE FROM bar;\r\nSELECT foo.ts foo, bar.ts bar FROM foo LEFT JOIN bar ON foo.ts = bar.ts;\r\nSELECT foo.ts foo, bar.ts bar FROM foo LEFT JOIN bar ON foo.ts < bar.ts;\r\nSELECT foo.ts foo, bar.ts bar FROM foo LEFT JOIN bar ON foo.ts > bar.ts;\r\n```\r\n\r\n\r\n---\r\n\r\n```\r\nno rows in bar, no rows returned for < or >:\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502         foo         \u2502    bar    \u2502\r\n\u2502      timestamp      \u2502 timestamp \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 2023-01-01 00:00:00 \u2502           \u2502\r\n\u2502 2023-01-01 00:00:01 \u2502           \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502    foo    \u2502    bar    \u2502\r\n\u2502 timestamp \u2502 timestamp \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502        0 rows         \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502    foo    \u2502    bar    \u2502\r\n\u2502 timestamp \u2502 timestamp \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502        0 rows         \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\n```\r\nwith row in bar works as expected:\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502         foo         \u2502         bar         \u2502\r\n\u2502      timestamp      \u2502      timestamp      \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 2023-01-01 00:00:01 \u2502 2023-01-01 00:00:01 \u2502\r\n\u2502 2023-01-01 00:00:00 \u2502                     \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502         foo         \u2502         bar         \u2502\r\n\u2502      timestamp      \u2502      timestamp      \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 2023-01-01 00:00:00 \u2502 2023-01-01 00:00:01 \u2502\r\n\u2502 2023-01-01 00:00:01 \u2502                     \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502         foo         \u2502    bar    \u2502\r\n\u2502      timestamp      \u2502 timestamp \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 2023-01-01 00:00:00 \u2502           \u2502\r\n\u2502 2023-01-01 00:00:01 \u2502           \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n```\r\ndelete row in bar and still works as expected:\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502         foo         \u2502    bar    \u2502\r\n\u2502      timestamp      \u2502 timestamp \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 2023-01-01 00:00:00 \u2502           \u2502\r\n\u2502 2023-01-01 00:00:01 \u2502           \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502         foo         \u2502    bar    \u2502\r\n\u2502      timestamp      \u2502 timestamp \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 2023-01-01 00:00:00 \u2502           \u2502\r\n\u2502 2023-01-01 00:00:01 \u2502           \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502         foo         \u2502    bar    \u2502\r\n\u2502      timestamp      \u2502 timestamp \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 2023-01-01 00:00:00 \u2502           \u2502\r\n\u2502 2023-01-01 00:00:01 \u2502           \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\n### OS:\r\n\r\nLinux\r\n\r\n### DuckDB Version:\r\n\r\nv0.7.1-dev57 8da10c8e33\r\n\r\n### DuckDB Client:\r\n\r\nCLI\r\n\r\n### Full Name:\r\n\r\nDave Tapley\r\n\r\n### Affiliation:\r\n\r\nJE Fuller\r\n\r\n### Have you tried this on the latest `master` branch?\r\n\r\n- [X] I agree\r\n\r\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\r\n\r\n- [X] I agree\n",
  "hints_text": "",
  "created_at": "2023-02-14T17:02:05Z"
}