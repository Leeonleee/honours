{"repo": "duckdb/duckdb", "pull_number": 17180, "instance_id": "duckdb__duckdb-17180", "issue_numbers": ["17170", "17170"], "base_commit": "92a5b7b32fb014e0fabe92cd6c1e95945fb6679c", "patch": "diff --git a/src/common/types/selection_vector.cpp b/src/common/types/selection_vector.cpp\nindex a65319a31d72..52f7f46a55c8 100644\n--- a/src/common/types/selection_vector.cpp\n+++ b/src/common/types/selection_vector.cpp\n@@ -28,6 +28,10 @@ string SelectionVector::ToString(idx_t count) const {\n \treturn result;\n }\n \n+void SelectionVector::Sort(idx_t count) {\n+\tstd::sort(sel_vector, sel_vector + count);\n+}\n+\n void SelectionVector::Print(idx_t count) const {\n \tPrinter::Print(ToString(count));\n }\ndiff --git a/src/execution/expression_executor/execute_conjunction.cpp b/src/execution/expression_executor/execute_conjunction.cpp\nindex 1b2bc3a4ea6a..d7488a639a25 100644\n--- a/src/execution/expression_executor/execute_conjunction.cpp\n+++ b/src/execution/expression_executor/execute_conjunction.cpp\n@@ -130,6 +130,9 @@ idx_t ExpressionExecutor::Select(const BoundConjunctionExpression &expr, Express\n \t\t\t\tcurrent_sel = false_sel;\n \t\t\t}\n \t\t}\n+\t\tif (true_sel) {\n+\t\t\ttrue_sel->Sort(result_count);\n+\t\t}\n \n \t\t// adapt runtime statistics\n \t\tstate.adaptive_filter->EndFilter(filter_state);\ndiff --git a/src/include/duckdb/common/types/selection_vector.hpp b/src/include/duckdb/common/types/selection_vector.hpp\nindex 5aa104758652..4074c80cc574 100644\n--- a/src/include/duckdb/common/types/selection_vector.hpp\n+++ b/src/include/duckdb/common/types/selection_vector.hpp\n@@ -116,6 +116,7 @@ struct SelectionVector {\n \t\treturn sel_vector;\n \t}\n \tvoid Verify(idx_t count, idx_t vector_size) const;\n+\tvoid Sort(idx_t count);\n \n private:\n \tsel_t *sel_vector;\n", "test_patch": "diff --git a/test/sql/conjunction/or_comparison.test b/test/sql/conjunction/or_comparison.test\nindex aaa4b994c0e6..9b9d950bf807 100644\n--- a/test/sql/conjunction/or_comparison.test\n+++ b/test/sql/conjunction/or_comparison.test\n@@ -48,3 +48,9 @@ SELECT pk FROM tab0 WHERE col0 < 84 OR col0 < 8 ;\n 5\n 7\n 8\n+\n+query I\n+select pk from tab0 where col0 = 37 or col0 = 86\n+----\n+0\n+1\n", "problem_statement": "No order preservation for OR in where clause\n### What happens?\n\nhttps://duckdb.org/docs/stable/sql/dialect/order_preservation.html says that the prefer of results is preserved with where clauses. But this does not work when there is an `or` in the query.\n\n### To Reproduce\n\n```sql\nCREATE TABLE tbl AS\n    SELECT *\n    FROM (VALUES (1, 'a'), (2, 'b'), (3, 'c')) t(x, y);\n\nSELECT *\nFROM tbl;\n```\n\n```sql\n select * from tbl where y = 'b' or y = 'a';\n```\n\nResults in \n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   x   \u2502    y    \u2502\n\u2502 int32 \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     2 \u2502 b       \u2502\n\u2502     1 \u2502 a       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nwhen it should be \n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   x   \u2502    y    \u2502\n\u2502 int32 \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502 a       \u2502\n\u2502     2 \u2502 b       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n### OS:\n\nmacOS\n\n### DuckDB Version:\n\nv1.2.2 7c039464e4\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nDominik Moritz\n\n### Affiliation:\n\nCMU\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [ ] Yes, I have\nNo order preservation for OR in where clause\n### What happens?\n\nhttps://duckdb.org/docs/stable/sql/dialect/order_preservation.html says that the prefer of results is preserved with where clauses. But this does not work when there is an `or` in the query.\n\n### To Reproduce\n\n```sql\nCREATE TABLE tbl AS\n    SELECT *\n    FROM (VALUES (1, 'a'), (2, 'b'), (3, 'c')) t(x, y);\n\nSELECT *\nFROM tbl;\n```\n\n```sql\n select * from tbl where y = 'b' or y = 'a';\n```\n\nResults in \n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   x   \u2502    y    \u2502\n\u2502 int32 \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     2 \u2502 b       \u2502\n\u2502     1 \u2502 a       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nwhen it should be \n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   x   \u2502    y    \u2502\n\u2502 int32 \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502 a       \u2502\n\u2502     2 \u2502 b       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n### OS:\n\nmacOS\n\n### DuckDB Version:\n\nv1.2.2 7c039464e4\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nDominik Moritz\n\n### Affiliation:\n\nCMU\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [ ] Yes, I have\n", "hints_text": "\n", "created_at": "2025-04-18T11:15:17Z"}
{"repo": "duckdb/duckdb", "pull_number": 17139, "instance_id": "duckdb__duckdb-17139", "issue_numbers": ["16213", "16213"], "base_commit": "88c4366deacd3c98b6f3c54ebe3306552a374877", "patch": "diff --git a/src/execution/physical_plan/plan_delim_join.cpp b/src/execution/physical_plan/plan_delim_join.cpp\nindex 27a9de5e65b6..02424b0b125d 100644\n--- a/src/execution/physical_plan/plan_delim_join.cpp\n+++ b/src/execution/physical_plan/plan_delim_join.cpp\n@@ -49,8 +49,9 @@ PhysicalOperator &PhysicalPlanGenerator::PlanDelimJoin(LogicalComparisonJoin &op\n \t}\n \n \t// we still have to create the DISTINCT clause that is used to generate the duplicate eliminated chunk\n-\tauto &distinct = Make<PhysicalHashAggregate>(context, delim_types, std::move(distinct_expressions),\n-\t                                             std::move(distinct_groups), op.estimated_cardinality);\n+\tauto &distinct =\n+\t    Make<PhysicalHashAggregate>(context, delim_types, std::move(distinct_expressions), std::move(distinct_groups),\n+\t                                delim_scans[0].get().estimated_cardinality);\n \n \t// Create the duplicate eliminated join.\n \tif (op.delim_flipped) {\ndiff --git a/src/include/duckdb/optimizer/join_order/cardinality_estimator.hpp b/src/include/duckdb/optimizer/join_order/cardinality_estimator.hpp\nindex 8aec1cd02c46..5390357102b2 100644\n--- a/src/include/duckdb/optimizer/join_order/cardinality_estimator.hpp\n+++ b/src/include/duckdb/optimizer/join_order/cardinality_estimator.hpp\n@@ -88,7 +88,6 @@ class CardinalityHelper {\n class CardinalityEstimator {\n public:\n \tstatic constexpr double DEFAULT_SEMI_ANTI_SELECTIVITY = 5;\n-\tstatic constexpr double DEFAULT_LT_GT_MULTIPLIER = 2.5;\n \texplicit CardinalityEstimator() {};\n \n private:\ndiff --git a/src/optimizer/join_order/cardinality_estimator.cpp b/src/optimizer/join_order/cardinality_estimator.cpp\nindex 4b5e22adad1e..2539bf37ac39 100644\n--- a/src/optimizer/join_order/cardinality_estimator.cpp\n+++ b/src/optimizer/join_order/cardinality_estimator.cpp\n@@ -9,6 +9,8 @@\n #include \"duckdb/planner/operator/logical_comparison_join.hpp\"\n #include \"duckdb/storage/data_table.hpp\"\n \n+#include <math.h>\n+\n namespace duckdb {\n \n // The filter was made on top of a logical sample or other projection,\n@@ -216,16 +218,14 @@ double CardinalityEstimator::CalculateUpdatedDenom(Subgraph2Denominator left, Su\n \tdouble new_denom = left.denom * right.denom;\n \tswitch (filter.filter_info->join_type) {\n \tcase JoinType::INNER: {\n-\t\tbool set = false;\n-\t\tExpressionType comparison_type = ExpressionType::COMPARE_EQUAL;\n+\t\t// Collect comparison types\n+\t\tExpressionType comparison_type = ExpressionType::INVALID;\n \t\tExpressionIterator::EnumerateExpression(filter.filter_info->filter, [&](Expression &expr) {\n \t\t\tif (expr.GetExpressionClass() == ExpressionClass::BOUND_COMPARISON) {\n \t\t\t\tcomparison_type = expr.GetExpressionType();\n-\t\t\t\tset = true;\n-\t\t\t\treturn;\n \t\t\t}\n \t\t});\n-\t\tif (!set) {\n+\t\tif (comparison_type == ExpressionType::INVALID) {\n \t\t\tnew_denom *=\n \t\t\t    filter.has_tdom_hll ? static_cast<double>(filter.tdom_hll) : static_cast<double>(filter.tdom_no_hll);\n \t\t\t// no comparison is taking place, so the denominator is just the product of the left and right\n@@ -237,22 +237,20 @@ double CardinalityEstimator::CalculateUpdatedDenom(Subgraph2Denominator left, Su\n \t\tswitch (comparison_type) {\n \t\tcase ExpressionType::COMPARE_EQUAL:\n \t\tcase ExpressionType::COMPARE_NOT_DISTINCT_FROM:\n-\t\t\t// extra ration stays 1\n-\t\t\textra_ratio = filter.has_tdom_hll ? (double)filter.tdom_hll : (double)filter.tdom_no_hll;\n+\t\t\t// extra ratio stays 1\n+\t\t\textra_ratio =\n+\t\t\t    filter.has_tdom_hll ? static_cast<double>(filter.tdom_hll) : static_cast<double>(filter.tdom_no_hll);\n \t\t\tbreak;\n \t\tcase ExpressionType::COMPARE_LESSTHANOREQUALTO:\n \t\tcase ExpressionType::COMPARE_LESSTHAN:\n \t\tcase ExpressionType::COMPARE_GREATERTHANOREQUALTO:\n \t\tcase ExpressionType::COMPARE_GREATERTHAN:\n-\t\t\t// start with the selectivity of equality\n-\t\t\textra_ratio = filter.has_tdom_hll ? (double)filter.tdom_hll : (double)filter.tdom_no_hll;\n-\t\t\t// now assume every tuple will match 2.5 times (on average)\n-\t\t\textra_ratio *= static_cast<double>(1) / CardinalityEstimator::DEFAULT_LT_GT_MULTIPLIER;\n-\t\t\tbreak;\n \t\tcase ExpressionType::COMPARE_NOTEQUAL:\n \t\tcase ExpressionType::COMPARE_DISTINCT_FROM:\n-\t\t\t// basically assume cross product.\n-\t\t\textra_ratio = 1;\n+\t\t\t// Assume this blows up, but use the tdom to bound it a bit\n+\t\t\textra_ratio =\n+\t\t\t    filter.has_tdom_hll ? static_cast<double>(filter.tdom_hll) : static_cast<double>(filter.tdom_no_hll);\n+\t\t\textra_ratio = pow(extra_ratio, 2.0 / 3.0);\n \t\t\tbreak;\n \t\tdefault:\n \t\t\tbreak;\ndiff --git a/src/optimizer/join_order/relation_manager.cpp b/src/optimizer/join_order/relation_manager.cpp\nindex d4f7032d676d..cfc829da7808 100644\n--- a/src/optimizer/join_order/relation_manager.cpp\n+++ b/src/optimizer/join_order/relation_manager.cpp\n@@ -418,7 +418,9 @@ bool RelationManager::ExtractJoinRelations(JoinOrderOptimizer &optimizer, Logica\n \t\t// create dummy aggregation for the duplicate elimination\n \t\tauto dummy_aggr = make_uniq<LogicalAggregate>(DConstants::INVALID_INDEX - 1, DConstants::INVALID_INDEX,\n \t\t                                              vector<unique_ptr<Expression>>());\n+\t\tdummy_aggr->grouping_sets.emplace_back();\n \t\tfor (auto &delim_col : delim_join.duplicate_eliminated_columns) {\n+\t\t\tdummy_aggr->grouping_sets.back().insert(dummy_aggr->groups.size());\n \t\t\tdummy_aggr->groups.push_back(delim_col->Copy());\n \t\t}\n \t\tauto lhs_delim_stats = RelationStatisticsHelper::ExtractAggregationStats(*dummy_aggr, lhs_stats);\n@@ -429,6 +431,36 @@ bool RelationManager::ExtractJoinRelations(JoinOrderOptimizer &optimizer, Logica\n \t\trhs_optimizer.AddDelimScanStats(lhs_delim_stats);\n \t\top->children[1] = rhs_optimizer.Optimize(std::move(op->children[1]), rhs_stats);\n \n+\t\tRelationStats dj_stats;\n+\t\tswitch (delim_join.join_type) {\n+\t\tcase JoinType::LEFT:\n+\t\tcase JoinType::INNER:\n+\t\tcase JoinType::OUTER:\n+\t\tcase JoinType::SINGLE:\n+\t\tcase JoinType::MARK:\n+\t\tcase JoinType::SEMI:\n+\t\tcase JoinType::ANTI:\n+\t\t\tdj_stats = lhs_stats;\n+\t\t\tbreak;\n+\t\tcase JoinType::RIGHT:\n+\t\tcase JoinType::RIGHT_SEMI:\n+\t\tcase JoinType::RIGHT_ANTI:\n+\t\t\tdj_stats = rhs_stats;\n+\t\t\tbreak;\n+\t\tdefault:\n+\t\t\tthrow NotImplementedException(\"Unsupported join type\");\n+\t\t}\n+\n+\t\tif (delim_join.join_type == JoinType::SEMI || delim_join.join_type == JoinType::ANTI ||\n+\t\t    delim_join.join_type == JoinType::RIGHT_SEMI || delim_join.join_type == JoinType::RIGHT_ANTI) {\n+\t\t\tdj_stats.cardinality =\n+\t\t\t    MaxValue<idx_t>(LossyNumericCast<idx_t>(static_cast<double>(dj_stats.cardinality) /\n+\t\t\t                                            CardinalityEstimator::DEFAULT_SEMI_ANTI_SELECTIVITY),\n+\t\t\t                    1);\n+\t\t}\n+\n+\t\tAddAggregateOrWindowRelation(input_op, parent, dj_stats, op->type);\n+\n \t\treturn false;\n \t}\n \tcase LogicalOperatorType::LOGICAL_DELIM_GET: {\ndiff --git a/src/optimizer/join_order/relation_statistics_helper.cpp b/src/optimizer/join_order/relation_statistics_helper.cpp\nindex 6340d9c02cd8..33edb135e7d0 100644\n--- a/src/optimizer/join_order/relation_statistics_helper.cpp\n+++ b/src/optimizer/join_order/relation_statistics_helper.cpp\n@@ -9,6 +9,8 @@\n #include \"duckdb/storage/data_table.hpp\"\n #include \"duckdb/planner/filter/constant_filter.hpp\"\n \n+#include <math.h>\n+\n namespace duckdb {\n \n static ExpressionBinding GetChildColumnBinding(Expression &expr) {\n@@ -328,8 +330,9 @@ RelationStats RelationStatisticsHelper::ExtractAggregationStats(LogicalAggregate\n \t// TODO: look at child distinct count to better estimate cardinality.\n \tstats.cardinality = child_stats.cardinality;\n \tstats.column_distinct_count = child_stats.column_distinct_count;\n-\tdouble new_card = -1;\n+\tvector<double> distinct_counts;\n \tfor (auto &g_set : aggr.grouping_sets) {\n+\t\tvector<double> set_distinct_counts;\n \t\tfor (auto &ind : g_set) {\n \t\t\tif (aggr.groups[ind]->GetExpressionClass() != ExpressionClass::BOUND_COLUMN_REF) {\n \t\t\t\tcontinue;\n@@ -343,26 +346,59 @@ RelationStats RelationStatisticsHelper::ExtractAggregationStats(LogicalAggregate\n \t\t\t\t// be grouped by. Hopefully this can be fixed with duckdb-internal#606\n \t\t\t\tcontinue;\n \t\t\t}\n-\t\t\tdouble distinct_count = double(child_stats.column_distinct_count[col_index].distinct_count);\n-\t\t\tif (new_card < distinct_count) {\n-\t\t\t\tnew_card = distinct_count;\n-\t\t\t}\n+\t\t\tdouble distinct_count = static_cast<double>(child_stats.column_distinct_count[col_index].distinct_count);\n+\t\t\tset_distinct_counts.push_back(distinct_count == 0 ? 1 : distinct_count);\n+\t\t}\n+\t\t// We use the grouping set with the most group key columns for cardinality estimation\n+\t\tif (set_distinct_counts.size() > distinct_counts.size()) {\n+\t\t\tdistinct_counts = std::move(set_distinct_counts);\n \t\t}\n \t}\n-\tif (new_card < 0 || new_card >= double(child_stats.cardinality)) {\n+\n+\tdouble new_card;\n+\tif (distinct_counts.empty()) {\n \t\t// We have no good statistics on distinct count.\n \t\t// most likely we are running on parquet files. Therefore we divide by 2.\n-\t\tnew_card = (double)child_stats.cardinality / 2;\n+\t\tnew_card = static_cast<double>(child_stats.cardinality) / 2.0;\n+\t} else {\n+\t\t// Multiply distinct counts\n+\t\tdouble product = 1;\n+\t\tfor (const auto &distinct_count : distinct_counts) {\n+\t\t\tproduct *= distinct_count;\n+\t\t}\n+\n+\t\t// Assume slight correlation for each grouping column\n+\t\tconst auto correction = pow(0.95, static_cast<double>(distinct_counts.size() - 1));\n+\t\tproduct *= correction;\n+\n+\t\t// Estimate using the \"Occupancy Problem\",\n+\t\t// where \"product\" is number of bins, and \"child_stats.cardinality\" is number of balls\n+\t\tconst auto mult = 1.0 - exp(-static_cast<double>(child_stats.cardinality) / product);\n+\t\tif (mult == 0) { // Can become 0 with very large estimates due to double imprecision\n+\t\t\tnew_card = static_cast<double>(child_stats.cardinality);\n+\t\t} else {\n+\t\t\tnew_card = product * mult;\n+\t\t}\n+\t\tnew_card = MinValue(new_card, static_cast<double>(child_stats.cardinality));\n \t}\n+\n \t// an ungrouped aggregate has 1 row\n \tstats.cardinality = aggr.groups.empty() ? 1 : LossyNumericCast<idx_t>(new_card);\n \tstats.column_names = child_stats.column_names;\n \tstats.stats_initialized = true;\n-\tauto num_child_columns = aggr.GetColumnBindings().size();\n+\tconst auto aggr_column_bindings = aggr.GetColumnBindings();\n+\tauto num_child_columns = aggr_column_bindings.size();\n \n-\tfor (idx_t column_index = child_stats.column_distinct_count.size(); column_index < num_child_columns;\n-\t     column_index++) {\n-\t\tstats.column_distinct_count.push_back(DistinctCount({child_stats.cardinality, false}));\n+\tfor (idx_t column_index = 0; column_index < num_child_columns; column_index++) {\n+\t\tconst auto &binding = aggr_column_bindings[column_index];\n+\t\tif (binding.table_index == aggr.group_index && column_index < distinct_counts.size()) {\n+\t\t\t// Group column that we have the HLL of\n+\t\t\tstats.column_distinct_count.push_back(\n+\t\t\t    DistinctCount({LossyNumericCast<idx_t>(distinct_counts[column_index]), true}));\n+\t\t} else {\n+\t\t\t// Non-group column, or we don't have the HLL\n+\t\t\tstats.column_distinct_count.push_back(DistinctCount({child_stats.cardinality, false}));\n+\t\t}\n \t\tstats.column_names.push_back(\"aggregate\");\n \t}\n \treturn stats;\n", "test_patch": "diff --git a/test/api/adbc/test_adbc.cpp b/test/api/adbc/test_adbc.cpp\nindex eb45ccd4d623..7eef329a9dd4 100644\n--- a/test/api/adbc/test_adbc.cpp\n+++ b/test/api/adbc/test_adbc.cpp\n@@ -1433,12 +1433,13 @@ TEST_CASE(\"Test AdbcConnectionGetObjects\", \"[adbc]\") {\n \t\tAdbcConnectionGetObjects(&db.adbc_connection, ADBC_OBJECT_DEPTH_COLUMNS, nullptr, nullptr, \"bla\", nullptr,\n \t\t                         nullptr, &arrow_stream, &adbc_error);\n \t\tdb.CreateTable(\"result\", arrow_stream);\n-\t\tres = db.Query(\"Select * from result order by catalog_name asc\");\n+\t\tres = db.Query(\"Select catalog_name, list_sort(catalog_db_schemas) as catalog_db_schemas from result order by \"\n+\t\t               \"catalog_name asc\");\n \t\tREQUIRE((res->ColumnCount() == 2));\n \t\tREQUIRE((res->RowCount() == 3));\n \t\tREQUIRE((res->GetValue(1, 0).ToString() ==\n-\t\t         \"[{'db_schema_name': pg_catalog, 'db_schema_tables': NULL}, {'db_schema_name': information_schema, \"\n-\t\t         \"'db_schema_tables': NULL}, {'db_schema_name': main, 'db_schema_tables': NULL}]\"));\n+\t\t         \"[{'db_schema_name': information_schema, 'db_schema_tables': NULL}, {'db_schema_name': main, \"\n+\t\t         \"'db_schema_tables': NULL}, {'db_schema_name': pg_catalog, 'db_schema_tables': NULL}]\"));\n \t\tdb.Query(\"Drop table result;\");\n \n \t\tAdbcConnectionGetObjects(&db.adbc_connection, ADBC_OBJECT_DEPTH_COLUMNS, nullptr, nullptr, nullptr, nullptr,\ndiff --git a/test/issues/general/test_16213.test_slow b/test/issues/general/test_16213.test_slow\nnew file mode 100644\nindex 000000000000..447123fbb332\n--- /dev/null\n+++ b/test/issues/general/test_16213.test_slow\n@@ -0,0 +1,56 @@\n+# name: test/issues/general/test_16213.test_slow\n+# description: Issue 16213 - Specific query not finishing since v1.1.0 and filling up all temp disk space\n+# group: [general]\n+\n+require icu\n+\n+# replicate date generation in issue, but in SQL\n+statement ok\n+create table records as\n+\tselect\n+\t\trange id,\n+\t\tto_timestamp(1514764800 + range / 1_000_000 * (1704067200 - 1514764800)) as creation_dt,\n+\t\tcreation_dt::date as creation_day,\n+\t\tprintf('%02X', range % 200) category,\n+\tfrom range(1_000_000);\n+\n+statement ok\n+create table labels as\n+\tselect\n+\t\tid,\n+\t\tcreation_dt + (1 * 60 * 60 + random() * (125 * 24 * 60 * 60 - 1 * 60 * 60) || ' seconds')::interval as label_dt,\n+\t\t1::bigint as label,\n+\tfrom (\n+\t\tfrom records\n+\t\tusing sample 50_000\n+\t);\n+\n+# this should not time out\n+statement ok\n+with\n+day_cat_rows as\n+  (select category,\n+          creation_day\n+   from records\n+   group by category,\n+            creation_day),\n+recs as\n+  (select category,\n+          records.creation_dt,\n+          labels.label_dt,\n+          labels.label\n+   from records\n+   left join labels on labels.id = records.id),\n+counts as\n+  (select day_cat_rows.creation_day,\n+          category,\n+     (select count(1)\n+      from recs\n+      where recs.creation_dt > day_cat_rows.creation_day - '30 days'::interval\n+        and recs.creation_dt <= day_cat_rows.creation_day\n+        and recs.category = day_cat_rows.category\n+        and recs.label_dt <= day_cat_rows.creation_day\n+        and recs.label = 1) as num_labeled_30d,\n+   from day_cat_rows)\n+select *\n+from counts;\n\\ No newline at end of file\n", "problem_statement": "Specific query not finishing since v1.1.0 and filling up all temp disk space\n### What happens?\n\nWe have a specific query (involving a join and subqueries for counting), of which a minimal reproducible example has been derived below. It operates on two tables, one with over a million rows, the other 4-5% of that. The query works fine in DuckDB 1.0.0 and finishes very fast (at most a few seconds). However, in later releases it never seems to finish -- instead, a temporary directory gets created that keeps growing (and the progress bar remains stuck at 50%).\n\nA `git bisect` helped point out that the commit introducing the problem seems to be https://github.com/duckdb/duckdb/commit/91b0fb71d17090e9f68332e65673ab899d691bca .\n\n### To Reproduce\n\nGenerate dummy data (two Parquet files) using the following Python script (with numpy, pandas, and duckdb):\n\n```python\nimport numpy as np\nimport pandas as pd\nimport duckdb\n\n\nnp.random.seed(12345)\n\ndates = np.random.randint(low=1514764800.0, high=1704067200.0, size=(1000000,))\ncategories = np.random.randint(low=0, high=200, size=(1000000,))\ndates.sort()\n\nrecords = pd.DataFrame({\n    \"creation_dt\": dates,\n    \"category\": categories,\n}).reset_index().rename(columns={\"index\": \"id\"})\nrecords[\"creation_dt\"] = records[\"creation_dt\"].map(lambda x: pd.Timestamp(x * 1e9))\nrecords[\"category\"] = records[\"category\"].map('{:02X}'.format)\n\nlabels = records.sample(frac=0.05, random_state=23456)\nlabel_delays = np.random.randint(low=1 * 60 * 60, high=125 * 24 * 60 * 60, size=(len(labels.index),))\nlabels[\"label_dt\"] = labels[\"creation_dt\"] + pd.to_timedelta(label_delays, \"s\")\nlabels[\"label\"] = 1\n\ndb = duckdb.connect()\ndb.sql(\"\"\"\n    copy (\n       select id, creation_dt::timestamp as creation_dt, creation_dt::date as creation_day, category from records\n    ) to 'records.parquet'\n\"\"\")\ndb.sql(\"\"\"\n    copy (\n       select id, label_dt::timestamp as label_dt, label from labels\n    ) to 'labels.parquet'\n\"\"\")\n```\n\n`records.parquet` has a million rows looking like this:\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  id   \u2502     creation_dt     \u2502 creation_day \u2502 category \u2502\n\u2502 int64 \u2502      timestamp      \u2502     date     \u2502 varchar  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     0 \u2502 2018-01-01 00:02:15 \u2502 2018-01-01   \u2502 A5       \u2502\n\u2502     1 \u2502 2018-01-01 00:17:21 \u2502 2018-01-01   \u2502 62       \u2502\n\u2502     2 \u2502 2018-01-01 00:22:10 \u2502 2018-01-01   \u2502 07       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n5% of which has a corresponding row in `labels.parquet` looking like this:\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   id   \u2502      label_dt       \u2502 label \u2502\n\u2502 int64  \u2502      timestamp      \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 970100 \u2502 2024-02-13 10:14:11 \u2502     1 \u2502\n\u2502 524709 \u2502 2021-05-15 17:11:48 \u2502     1 \u2502\n\u2502 800619 \u2502 2022-11-28 23:57:17 \u2502     1 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n\n\nThen run the following SQL (on an in-memory database or on a file, same result). The query should result into a table that has a row for each combination of `creation_day` and `category` appearing in `records` with a third column `num_labeled_30d` that contains a count of how many records with that `category` have been labeled in the 30 days prior to `creation_day`.\n\n```sql\ncreate or replace table records as\nfrom 'records.parquet';\n\n\ncreate or replace table labels as\nfrom 'labels.parquet';\n\nwith\nday_cat_rows as\n  (select category,\n          creation_day\n   from records\n   group by category,\n            creation_day),\nrecs as\n  (select category,\n          records.creation_dt,\n          labels.label_dt,\n          labels.label\n   from records\n   left join labels on labels.id = records.id),\ncounts as\n  (select day_cat_rows.creation_day,\n          category,\n\n     (select count(1)\n      from recs\n      where recs.creation_dt > day_cat_rows.creation_day - '30 days'::interval\n        and recs.creation_dt <= day_cat_rows.creation_day\n        and recs.category = day_cat_rows.category\n        and recs.label_dt <= day_cat_rows.creation_day\n        and recs.label = 1) as num_labeled_30d,\n   from day_cat_rows)\nselect *\nfrom counts;\n```\n\nDuckDB 1.0.0 will give an output that looks like this:\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 creation_day \u2502 category \u2502 num_labeled_30d \u2502\n\u2502     date     \u2502 varchar  \u2502      int64      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 2023-11-25   \u2502 05       \u2502               2 \u2502\n\u2502 2023-11-25   \u2502 3A       \u2502               0 \u2502\n\u2502 2023-11-25   \u2502 09       \u2502               0 \u2502\n\u2502 2023-11-25   \u2502 62       \u2502               0 \u2502\n\u2502 2023-11-25   \u2502 32       \u2502               1 \u2502\n\u2502 2023-11-25   \u2502 83       \u2502               1 \u2502\n\u2502 2023-11-25   \u2502 92       \u2502               0 \u2502\n\u2502 2023-11-25   \u2502 21       \u2502               0 \u2502\n\u2502 2023-11-25   \u2502 BA       \u2502               2 \u2502\n\u2502 2023-11-25   \u2502 96       \u2502               0 \u2502\n\u2502 2023-11-25   \u2502 6F       \u2502               1 \u2502\n\u2502 2023-11-25   \u2502 64       \u2502               0 \u2502\n\u2502 2023-11-25   \u2502 24       \u2502               1 \u2502\n\u2502 2023-11-25   \u2502 14       \u2502               0 \u2502\n\u2502 2023-11-25   \u2502 5D       \u2502               0 \u2502\n\u2502 2023-11-25   \u2502 6A       \u2502               0 \u2502\n\u2502 2023-11-25   \u2502 4D       \u2502               0 \u2502\n\u2502 2023-11-25   \u2502 B7       \u2502               0 \u2502\n\u2502 2023-11-25   \u2502 9E       \u2502               1 \u2502\n\u2502 2023-11-25   \u2502 1F       \u2502               0 \u2502\n\u2502     \u00b7        \u2502 \u00b7        \u2502               \u00b7 \u2502\n\u2502     \u00b7        \u2502 \u00b7        \u2502               \u00b7 \u2502\n\u2502     \u00b7        \u2502 \u00b7        \u2502               \u00b7 \u2502\n\u2502 2021-09-07   \u2502 3F       \u2502               1 \u2502\n\u2502 2021-09-07   \u2502 74       \u2502               0 \u2502\n\u2502 2021-09-07   \u2502 06       \u2502               0 \u2502\n\u2502 2021-09-07   \u2502 52       \u2502               0 \u2502\n\u2502 2021-09-07   \u2502 2F       \u2502               0 \u2502\n\u2502 2021-09-07   \u2502 8B       \u2502               0 \u2502\n\u2502 2021-09-07   \u2502 17       \u2502               0 \u2502\n\u2502 2021-09-07   \u2502 89       \u2502               1 \u2502\n\u2502 2021-09-07   \u2502 39       \u2502               1 \u2502\n\u2502 2021-09-07   \u2502 5A       \u2502               1 \u2502\n\u2502 2021-09-07   \u2502 7E       \u2502               0 \u2502\n\u2502 2021-09-07   \u2502 82       \u2502               0 \u2502\n\u2502 2021-09-07   \u2502 7B       \u2502               0 \u2502\n\u2502 2021-09-07   \u2502 90       \u2502               0 \u2502\n\u2502 2021-09-08   \u2502 6D       \u2502               1 \u2502\n\u2502 2021-09-08   \u2502 A0       \u2502               1 \u2502\n\u2502 2021-09-08   \u2502 67       \u2502               2 \u2502\n\u2502 2021-09-08   \u2502 94       \u2502               0 \u2502\n\u2502 2021-09-08   \u2502 61       \u2502               0 \u2502\n\u2502 2021-09-08   \u2502 60       \u2502               1 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 393154 rows (40 shown)          3 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\nBut in later releases, it does not finish.\n\n### OS:\n\nmacOS 15.3, arm64\n\n### DuckDB Version:\n\n1.1.0 and later\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\nM1 Pro chip, 32 GB RAM\n\n### Full Name:\n\nThomas Daniels\n\n### Affiliation:\n\nDNS Belgium\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a source build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nSpecific query not finishing since v1.1.0 and filling up all temp disk space\n### What happens?\n\nWe have a specific query (involving a join and subqueries for counting), of which a minimal reproducible example has been derived below. It operates on two tables, one with over a million rows, the other 4-5% of that. The query works fine in DuckDB 1.0.0 and finishes very fast (at most a few seconds). However, in later releases it never seems to finish -- instead, a temporary directory gets created that keeps growing (and the progress bar remains stuck at 50%).\n\nA `git bisect` helped point out that the commit introducing the problem seems to be https://github.com/duckdb/duckdb/commit/91b0fb71d17090e9f68332e65673ab899d691bca .\n\n### To Reproduce\n\nGenerate dummy data (two Parquet files) using the following Python script (with numpy, pandas, and duckdb):\n\n```python\nimport numpy as np\nimport pandas as pd\nimport duckdb\n\n\nnp.random.seed(12345)\n\ndates = np.random.randint(low=1514764800.0, high=1704067200.0, size=(1000000,))\ncategories = np.random.randint(low=0, high=200, size=(1000000,))\ndates.sort()\n\nrecords = pd.DataFrame({\n    \"creation_dt\": dates,\n    \"category\": categories,\n}).reset_index().rename(columns={\"index\": \"id\"})\nrecords[\"creation_dt\"] = records[\"creation_dt\"].map(lambda x: pd.Timestamp(x * 1e9))\nrecords[\"category\"] = records[\"category\"].map('{:02X}'.format)\n\nlabels = records.sample(frac=0.05, random_state=23456)\nlabel_delays = np.random.randint(low=1 * 60 * 60, high=125 * 24 * 60 * 60, size=(len(labels.index),))\nlabels[\"label_dt\"] = labels[\"creation_dt\"] + pd.to_timedelta(label_delays, \"s\")\nlabels[\"label\"] = 1\n\ndb = duckdb.connect()\ndb.sql(\"\"\"\n    copy (\n       select id, creation_dt::timestamp as creation_dt, creation_dt::date as creation_day, category from records\n    ) to 'records.parquet'\n\"\"\")\ndb.sql(\"\"\"\n    copy (\n       select id, label_dt::timestamp as label_dt, label from labels\n    ) to 'labels.parquet'\n\"\"\")\n```\n\n`records.parquet` has a million rows looking like this:\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  id   \u2502     creation_dt     \u2502 creation_day \u2502 category \u2502\n\u2502 int64 \u2502      timestamp      \u2502     date     \u2502 varchar  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     0 \u2502 2018-01-01 00:02:15 \u2502 2018-01-01   \u2502 A5       \u2502\n\u2502     1 \u2502 2018-01-01 00:17:21 \u2502 2018-01-01   \u2502 62       \u2502\n\u2502     2 \u2502 2018-01-01 00:22:10 \u2502 2018-01-01   \u2502 07       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n5% of which has a corresponding row in `labels.parquet` looking like this:\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   id   \u2502      label_dt       \u2502 label \u2502\n\u2502 int64  \u2502      timestamp      \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 970100 \u2502 2024-02-13 10:14:11 \u2502     1 \u2502\n\u2502 524709 \u2502 2021-05-15 17:11:48 \u2502     1 \u2502\n\u2502 800619 \u2502 2022-11-28 23:57:17 \u2502     1 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n\n\nThen run the following SQL (on an in-memory database or on a file, same result). The query should result into a table that has a row for each combination of `creation_day` and `category` appearing in `records` with a third column `num_labeled_30d` that contains a count of how many records with that `category` have been labeled in the 30 days prior to `creation_day`.\n\n```sql\ncreate or replace table records as\nfrom 'records.parquet';\n\n\ncreate or replace table labels as\nfrom 'labels.parquet';\n\nwith\nday_cat_rows as\n  (select category,\n          creation_day\n   from records\n   group by category,\n            creation_day),\nrecs as\n  (select category,\n          records.creation_dt,\n          labels.label_dt,\n          labels.label\n   from records\n   left join labels on labels.id = records.id),\ncounts as\n  (select day_cat_rows.creation_day,\n          category,\n\n     (select count(1)\n      from recs\n      where recs.creation_dt > day_cat_rows.creation_day - '30 days'::interval\n        and recs.creation_dt <= day_cat_rows.creation_day\n        and recs.category = day_cat_rows.category\n        and recs.label_dt <= day_cat_rows.creation_day\n        and recs.label = 1) as num_labeled_30d,\n   from day_cat_rows)\nselect *\nfrom counts;\n```\n\nDuckDB 1.0.0 will give an output that looks like this:\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 creation_day \u2502 category \u2502 num_labeled_30d \u2502\n\u2502     date     \u2502 varchar  \u2502      int64      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 2023-11-25   \u2502 05       \u2502               2 \u2502\n\u2502 2023-11-25   \u2502 3A       \u2502               0 \u2502\n\u2502 2023-11-25   \u2502 09       \u2502               0 \u2502\n\u2502 2023-11-25   \u2502 62       \u2502               0 \u2502\n\u2502 2023-11-25   \u2502 32       \u2502               1 \u2502\n\u2502 2023-11-25   \u2502 83       \u2502               1 \u2502\n\u2502 2023-11-25   \u2502 92       \u2502               0 \u2502\n\u2502 2023-11-25   \u2502 21       \u2502               0 \u2502\n\u2502 2023-11-25   \u2502 BA       \u2502               2 \u2502\n\u2502 2023-11-25   \u2502 96       \u2502               0 \u2502\n\u2502 2023-11-25   \u2502 6F       \u2502               1 \u2502\n\u2502 2023-11-25   \u2502 64       \u2502               0 \u2502\n\u2502 2023-11-25   \u2502 24       \u2502               1 \u2502\n\u2502 2023-11-25   \u2502 14       \u2502               0 \u2502\n\u2502 2023-11-25   \u2502 5D       \u2502               0 \u2502\n\u2502 2023-11-25   \u2502 6A       \u2502               0 \u2502\n\u2502 2023-11-25   \u2502 4D       \u2502               0 \u2502\n\u2502 2023-11-25   \u2502 B7       \u2502               0 \u2502\n\u2502 2023-11-25   \u2502 9E       \u2502               1 \u2502\n\u2502 2023-11-25   \u2502 1F       \u2502               0 \u2502\n\u2502     \u00b7        \u2502 \u00b7        \u2502               \u00b7 \u2502\n\u2502     \u00b7        \u2502 \u00b7        \u2502               \u00b7 \u2502\n\u2502     \u00b7        \u2502 \u00b7        \u2502               \u00b7 \u2502\n\u2502 2021-09-07   \u2502 3F       \u2502               1 \u2502\n\u2502 2021-09-07   \u2502 74       \u2502               0 \u2502\n\u2502 2021-09-07   \u2502 06       \u2502               0 \u2502\n\u2502 2021-09-07   \u2502 52       \u2502               0 \u2502\n\u2502 2021-09-07   \u2502 2F       \u2502               0 \u2502\n\u2502 2021-09-07   \u2502 8B       \u2502               0 \u2502\n\u2502 2021-09-07   \u2502 17       \u2502               0 \u2502\n\u2502 2021-09-07   \u2502 89       \u2502               1 \u2502\n\u2502 2021-09-07   \u2502 39       \u2502               1 \u2502\n\u2502 2021-09-07   \u2502 5A       \u2502               1 \u2502\n\u2502 2021-09-07   \u2502 7E       \u2502               0 \u2502\n\u2502 2021-09-07   \u2502 82       \u2502               0 \u2502\n\u2502 2021-09-07   \u2502 7B       \u2502               0 \u2502\n\u2502 2021-09-07   \u2502 90       \u2502               0 \u2502\n\u2502 2021-09-08   \u2502 6D       \u2502               1 \u2502\n\u2502 2021-09-08   \u2502 A0       \u2502               1 \u2502\n\u2502 2021-09-08   \u2502 67       \u2502               2 \u2502\n\u2502 2021-09-08   \u2502 94       \u2502               0 \u2502\n\u2502 2021-09-08   \u2502 61       \u2502               0 \u2502\n\u2502 2021-09-08   \u2502 60       \u2502               1 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 393154 rows (40 shown)          3 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\nBut in later releases, it does not finish.\n\n### OS:\n\nmacOS 15.3, arm64\n\n### DuckDB Version:\n\n1.1.0 and later\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\nM1 Pro chip, 32 GB RAM\n\n### Full Name:\n\nThomas Daniels\n\n### Affiliation:\n\nDNS Belgium\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a source build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "Same result on a Mac with 2 GHz Quad-Core Intel Core i5 processor running MacOS Version 15.3 (24D60)\nJust tried this query as well. \nSetting SET disabled_optimizers = 'join_order,build_side_probe_side'; \nor changing the recs cte part  to reduce the #rows and materialize seems to solve the problem for now.\n\nwith\nday_cat_rows as \n  (select category,\n          creation_day\n   from records\n   group by category,\n            creation_day),\nrecs as materialized\n  (select category,\n          records.creation_dt,\n          labels.label_dt\n   from records\n   inner join labels on labels.id = records.id and labels.label = 1),\ncounts as\n  (select day_cat_rows.creation_day,\n          category,\n\n     (select count(1)\n      from recs\n      where recs.creation_dt > day_cat_rows.creation_day - '30 days'::interval\n        and recs.creation_dt <= day_cat_rows.creation_day\n        and recs.category = day_cat_rows.category\n        and recs.label_dt <= day_cat_rows.creation_day\n      ) as num_labeled_30d,\n   from day_cat_rows)\nselect *\nfrom counts\norder by creation_day \n\nthanks for the suggestion @cmettler, just adding the `materialized` keyword appears to make it work (both for the query in this issue and our original query). I'll leave the issue open because I suppose there is still an underlying issue that makes the original query stuck without materializing `recs`\nSame result on a Mac with 2 GHz Quad-Core Intel Core i5 processor running MacOS Version 15.3 (24D60)\nJust tried this query as well. \nSetting SET disabled_optimizers = 'join_order,build_side_probe_side'; \nor changing the recs cte part  to reduce the #rows and materialize seems to solve the problem for now.\n\nwith\nday_cat_rows as \n  (select category,\n          creation_day\n   from records\n   group by category,\n            creation_day),\nrecs as materialized\n  (select category,\n          records.creation_dt,\n          labels.label_dt\n   from records\n   inner join labels on labels.id = records.id and labels.label = 1),\ncounts as\n  (select day_cat_rows.creation_day,\n          category,\n\n     (select count(1)\n      from recs\n      where recs.creation_dt > day_cat_rows.creation_day - '30 days'::interval\n        and recs.creation_dt <= day_cat_rows.creation_day\n        and recs.category = day_cat_rows.category\n        and recs.label_dt <= day_cat_rows.creation_day\n      ) as num_labeled_30d,\n   from day_cat_rows)\nselect *\nfrom counts\norder by creation_day \n\nthanks for the suggestion @cmettler, just adding the `materialized` keyword appears to make it work (both for the query in this issue and our original query). I'll leave the issue open because I suppose there is still an underlying issue that makes the original query stuck without materializing `recs`", "created_at": "2025-04-16T08:02:24Z"}
{"repo": "duckdb/duckdb", "pull_number": 17138, "instance_id": "duckdb__duckdb-17138", "issue_numbers": ["16684"], "base_commit": "9e7fedd4c0af54f16f8fd89367f4cdb87295d22e", "patch": "diff --git a/src/common/operator/cast_operators.cpp b/src/common/operator/cast_operators.cpp\nindex 602c2e1c8506..80c9102952b0 100644\n--- a/src/common/operator/cast_operators.cpp\n+++ b/src/common/operator/cast_operators.cpp\n@@ -1462,7 +1462,7 @@ string_t CastFromUUID::Operation(hugeint_t input, Vector &vector) {\n //===--------------------------------------------------------------------===//\n template <>\n bool TryCastToUUID::Operation(string_t input, hugeint_t &result, Vector &result_vector, CastParameters &parameters) {\n-\treturn UUID::FromString(input.GetString(), result);\n+\treturn UUID::FromString(input.GetString(), result, parameters.strict);\n }\n \n //===--------------------------------------------------------------------===//\ndiff --git a/src/common/types/uuid.cpp b/src/common/types/uuid.cpp\nindex 79875fba4ba8..16563a66c4cc 100644\n--- a/src/common/types/uuid.cpp\n+++ b/src/common/types/uuid.cpp\n@@ -6,7 +6,7 @@ namespace duckdb {\n //////////////////\n // Base UUID\n //////////////////\n-bool BaseUUID::FromString(const string &str, hugeint_t &result) {\n+bool BaseUUID::FromString(const string &str, hugeint_t &result, bool strict) {\n \tauto hex2char = [](char ch) -> unsigned char {\n \t\tif (ch >= '0' && ch <= '9') {\n \t\t\treturn UnsafeNumericCast<unsigned char>(ch - '0');\n@@ -34,6 +34,17 @@ bool BaseUUID::FromString(const string &str, hugeint_t &result) {\n \t\treturn false;\n \t}\n \n+\tif (strict) {\n+\t\t// 32 characters and 4 hyphens\n+\t\tif (str.length() != 36) {\n+\t\t\treturn false;\n+\t\t}\n+\t\tconst auto c_str = str.c_str();\n+\t\tif (c_str[8] != '-' || c_str[13] != '-' || c_str[18] != '-' || c_str[23] != '-') {\n+\t\t\treturn false;\n+\t\t}\n+\t}\n+\n \tresult.lower = 0;\n \tresult.upper = 0;\n \tsize_t count = 0;\ndiff --git a/src/include/duckdb/common/types/uuid.hpp b/src/include/duckdb/common/types/uuid.hpp\nindex 16b1e082dc68..9bc5fe20927c 100644\n--- a/src/include/duckdb/common/types/uuid.hpp\n+++ b/src/include/duckdb/common/types/uuid.hpp\n@@ -21,7 +21,7 @@ class BaseUUID {\n public:\n \tconstexpr static const uint8_t STRING_SIZE = 36;\n \t//! Convert a uuid string to a hugeint object\n-\tstatic bool FromString(const string &str, hugeint_t &result);\n+\tstatic bool FromString(const string &str, hugeint_t &result, bool strict = false);\n \t//! Convert a uuid string to a hugeint object\n \tstatic bool FromCString(const char *str, idx_t len, hugeint_t &result) {\n \t\treturn FromString(string(str, 0, len), result);\n", "test_patch": "diff --git a/test/sql/json/issues/issue16684.test b/test/sql/json/issues/issue16684.test\nnew file mode 100644\nindex 000000000000..43c4bb634fe4\n--- /dev/null\n+++ b/test/sql/json/issues/issue16684.test\n@@ -0,0 +1,26 @@\n+# name: test/sql/json/issues/issue16684.test\n+# description: Test issue 16684 - When using read_json to read data, it always converts the md5 string to uuid format.\n+# group: [issues]\n+\n+require json\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+copy (select '00000000000000000000000000000000' md5) to '__TEST_DIR__/issue16684.json'\n+\n+# should be varchar, not uuid (no hyphens)\n+query II\n+select md5, typeof(md5) from '__TEST_DIR__/issue16684.json'\n+----\n+00000000000000000000000000000000\tVARCHAR\n+\n+statement ok\n+copy (select '00000000-0000-0000-0000-000000000000' id) to '__TEST_DIR__/issue16684.json'\n+\n+# if we add hyphens we get a uuid\n+query II\n+select id, typeof(id) from '__TEST_DIR__/issue16684.json'\n+----\n+00000000-0000-0000-0000-000000000000\tUUID\n", "problem_statement": "When using read_json to read data, it always converts the md5 string to uuid format.\n### What happens?\n\nAny 32-character string that conforms to the UUID specification will be converted to a UUID.\n\n\n### To Reproduce\n\nFor the following json file, `iss16684.json`:\n\n```json\n{\"md5\":\"00000000000000000000000000000000\"}\n```\n\nExecute:\n\n```\nFROM 'iss16684.json';\n```\n\nActual\n\n```text\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 md5                  \u2502\n\u2502                 uuid                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 00000000-0000-0000-0000-000000000000 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n```\n---\nExpected\n\n```text\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                md5                \u2502\n\u2502              varchar              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 00000000000000000000000000000000  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n```\n\n### OS:\n\nWindows\n\n### DuckDB Version:\n\nv1.2.1 8e52ec4395\n\n### DuckDB Client:\n\ncli\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nJim Zhang\n\n### Affiliation:\n\nWinhc Co.\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "https://github.com/duckdb/duckdb/issues/10934\n\nAccording to this issue, the conversion to uuid is intentional. Can you provide a switch to turn off this feature? Currently, in my file, many columns are md5 strings.\ni welcome a flag to disable this behavior as well. it's quite unexpected behavior if the data changes just from reading it.", "created_at": "2025-04-16T07:59:50Z"}
{"repo": "duckdb/duckdb", "pull_number": 17045, "instance_id": "duckdb__duckdb-17045", "issue_numbers": ["17042"], "base_commit": "5141aa45606ea74dd46cc86cbe60a04134037145", "patch": "diff --git a/src/optimizer/pushdown/pushdown_left_join.cpp b/src/optimizer/pushdown/pushdown_left_join.cpp\nindex 002bb2540de8..d8ef8b17e4d3 100644\n--- a/src/optimizer/pushdown/pushdown_left_join.cpp\n+++ b/src/optimizer/pushdown/pushdown_left_join.cpp\n@@ -127,15 +127,16 @@ unique_ptr<LogicalOperator> FilterPushdown::PushdownLeftJoin(unique_ptr<LogicalO\n \t\t\t\tfor (auto &left_filter : left_pushdown.filters) {\n \t\t\t\t\tfilters.push_back(std::move(left_filter));\n \t\t\t\t}\n+\t\t\t\tfor (auto &filter : remaining_filters) {\n+\t\t\t\t\tfilters.push_back(std::move(filter));\n+\t\t\t\t}\n \t\t\t\t// now push down the inner join\n \t\t\t\treturn PushdownInnerJoin(std::move(op), left_bindings, right_bindings);\n \t\t\t}\n-\t\t\t// we should keep the filters which only matched the right side\n-\t\t\tif (side == JoinSide::RIGHT) {\n-\t\t\t\tremaining_filters.push_back(std::move(filters[i]));\n-\t\t\t\tfilters.erase_at(i);\n-\t\t\t\ti--;\n-\t\t\t}\n+\t\t\t// we should keep the filters which do not remove NULL values\n+\t\t\tremaining_filters.push_back(std::move(filters[i]));\n+\t\t\tfilters.erase_at(i);\n+\t\t\ti--;\n \t\t}\n \t}\n \t// finally we check the FilterCombiner to see if there are any predicates we can push into the RHS\n", "test_patch": "diff --git a/test/optimizer/pushdown/issue_17042.test b/test/optimizer/pushdown/issue_17042.test\nnew file mode 100644\nindex 000000000000..58030d71f88f\n--- /dev/null\n+++ b/test/optimizer/pushdown/issue_17042.test\n@@ -0,0 +1,38 @@\n+# name: test/optimizer/pushdown/issue_17042.test\n+# description: Test left join filter lost in filter pushdown\n+# group: [pushdown]\n+\n+statement ok\n+pragma explain_output = optimized_only\n+\n+statement ok\n+pragma enable_verification\n+\n+statement ok\n+CREATE  TABLE  t2(c1 INTEGER);\n+\n+statement ok\n+CREATE  TABLE  t0(c1 DOUBLE);\n+\n+statement ok\n+INSERT INTO t0(c1) VALUES (0.1);\n+\n+statement ok\n+INSERT INTO t2(c1) VALUES (2);\n+\n+query II\n+SELECT * FROM t2 LEFT JOIN t0 ON true WHERE ((t0.c1<t2.c1) IS NULL);\n+----\n+\n+statement ok\n+INSERT INTO t2(c1) VALUES (NULL);\n+\n+query II\n+SELECT * FROM t2 LEFT JOIN t0 ON true WHERE ((t0.c1<t2.c1) IS NULL);\n+----\n+NULL\t0.1\n+\n+query II\n+explain SELECT * FROM t2 LEFT JOIN t0 ON true WHERE (t0.c1 is distinct from t2.c1) and (t2.c1 > t0.c1);\n+----\n+logical_opt\t<REGEX>:.*INNER.*CAST\\(c1 AS DOUBLE\\) > c1.*CAST\\(c1 AS DOUBLE\\) IS.*DISTINCT FROM c1.*\n", "problem_statement": "Unexpected result when using `LEFT JOIN`\n### What happens?\n\nConsider the below test case. The third query returns an unexpected result since the expression `t0.c1 < t2.c1` cannot be evaluated as `true` or `NULL` at the same time. \n\n### To Reproduce\n\n```sql\nCREATE  TABLE  t2(c1 INTEGER);\nCREATE  TABLE  t0(c1 DOUBLE);\nINSERT INTO t0(c1) VALUES ( 0.1);\nINSERT INTO t2(c1) VALUES (2);\n\nSELECT * FROM t2 LEFT  JOIN t0 ON true; -- 2 0.1\nSELECT * FROM t2 LEFT  JOIN t0 ON true WHERE (t0.c1<t2.c1); -- 2 0.1\nSELECT * FROM t2 LEFT  JOIN t0 ON true WHERE ((t0.c1<t2.c1) IS NULL);\n-- Expected: empty result set\n-- Actual: 2 0.1\n\n```\n\n### OS:\n\nUbuntu 22.04\n\n### DuckDB Version:\n\nv1.3.0-dev2262 589e10ae54\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nSuyang Zhong\n\n### Affiliation:\n\nNUS\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a source build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNot applicable - the reproduction does not require a data set\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "", "created_at": "2025-04-09T11:19:04Z"}
{"repo": "duckdb/duckdb", "pull_number": 17037, "instance_id": "duckdb__duckdb-17037", "issue_numbers": ["16942", "16959", "16959"], "base_commit": "5141aa45606ea74dd46cc86cbe60a04134037145", "patch": "diff --git a/.github/actions/build_extensions/action.yml b/.github/actions/build_extensions/action.yml\nindex 02f82c66e7e0..4b581851954b 100644\n--- a/.github/actions/build_extensions/action.yml\n+++ b/.github/actions/build_extensions/action.yml\n@@ -88,9 +88,6 @@ inputs:\n     description: 'Flags to be passed to cmake'\n     default: ''\n \n-env:\n-  CMAKE_POLICY_VERSION_MINIMUM: 3.5\n-\n runs:\n   using: \"composite\"\n   steps:\ndiff --git a/.github/actions/build_extensions_dockerized/action.yml b/.github/actions/build_extensions_dockerized/action.yml\nindex 9a2b3303a20b..0e0eb7fd54e4 100644\n--- a/.github/actions/build_extensions_dockerized/action.yml\n+++ b/.github/actions/build_extensions_dockerized/action.yml\n@@ -59,7 +59,6 @@ runs:\n           echo \"OPENSSL_DIR=/duckdb_build_dir/build/release/vcpkg_installed/${{ inputs.vcpkg_target_triplet }}\" >> docker_env.txt\n           echo \"OPENSSL_USE_STATIC_LIBS=true\" >> docker_env.txt\n           echo \"DUCKDB_PLATFORM=${{ inputs.duckdb_arch }}\" >> docker_env.txt\n-          echo \"CMAKE_POLICY_VERSION_MINIMUM=3.5\" >> docker_env.txt\n           echo \"OVERRIDE_GIT_DESCRIBE=${{ inputs.override_git_describe }}\" >> docker_env.txt\n           echo \"LINUX_CI_IN_DOCKER=1\" >> docker_env.txt\n           echo \"TOOLCHAIN_FLAGS=${{ inputs.duckdb_arch == 'linux_arm64' && '-DCMAKE_C_COMPILER=aarch64-linux-gnu-gcc -DCMAKE_CXX_COMPILER=aarch64-linux-gnu-g++ -DCMAKE_Fortran_COMPILER=aarch64-linux-gnu-gfortran' || '' }}\" >> docker_env.txt\ndiff --git a/.github/config/out_of_tree_extensions.cmake b/.github/config/out_of_tree_extensions.cmake\nindex 0719c73e0420..62bbac5ed740 100644\n--- a/.github/config/out_of_tree_extensions.cmake\n+++ b/.github/config/out_of_tree_extensions.cmake\n@@ -28,12 +28,24 @@ duckdb_extension_load(httpfs\n     INCLUDE_DIR extension/httpfs/include\n     )\n \n+### Skip due to missing patch\n+if(FALSE)\n+################# AVRO\n+if (NOT MINGW)\n+    duckdb_extension_load(avro\n+            LOAD_TESTS DONT_LINK\n+            GIT_URL https://github.com/duckdb/duckdb-avro\n+            GIT_TAG ed18629fa56a97e0796a3582110b51ddd125159d\n+    )\n+endif()\n+endif()\n+\n ################## AWS\n if (NOT MINGW AND NOT ${WASM_ENABLED})\n     duckdb_extension_load(aws\n-            LOAD_TESTS\n+            ### TODO: re-enable LOAD_TESTS\n             GIT_URL https://github.com/duckdb/duckdb-aws\n-            GIT_TAG b3050f35c6e99fa35465230493eeab14a78a0409\n+            GIT_TAG e92e45b30ba17594b1101db22699a2244adfaeb1\n             APPLY_PATCHES\n             )\n endif()\n@@ -43,7 +55,7 @@ if (NOT MINGW AND NOT ${WASM_ENABLED})\n     duckdb_extension_load(azure\n             LOAD_TESTS\n             GIT_URL https://github.com/duckdb/duckdb-azure\n-            GIT_TAG e707cf361d76358743969cddf3acf97cfc87677b\n+            GIT_TAG 1593cb56745a51eb7d8415c1fd7d11a15f20f413\n             )\n endif()\n \n@@ -54,6 +66,7 @@ if (FALSE)\n if (NOT MINGW AND NOT \"${OS_NAME}\" STREQUAL \"linux\" AND NOT ${WASM_ENABLED})\n     duckdb_extension_load(delta\n             GIT_URL https://github.com/duckdb/duckdb-delta\n+            ## TODO: GIT_TAG 90f244b3d572c1692867950b562df8183957b7a8\n             GIT_TAG 6d626173e9efa6615c25eb08d979d1372100d5db\n             APPLY_PATCHES\n     )\n@@ -64,14 +77,13 @@ endif()\n duckdb_extension_load(excel\n     LOAD_TESTS\n     GIT_URL https://github.com/duckdb/duckdb-excel\n-    GIT_TAG f14e7c3beaf379c54b47b996aa896a1d814e1be8\n+    GIT_TAG b724b308b2b3a3c5644272cc84ec140fbcc7617d\n     INCLUDE_DIR src/excel/include\n     )\n \n ################# ICEBERG\n # Windows tests for iceberg currently not working\n-if(FALSE)\n-if (NOT WIN32)\n+IF (NOT WIN32)\n     set(LOAD_ICEBERG_TESTS \"LOAD_TESTS\")\n else ()\n     set(LOAD_ICEBERG_TESTS \"\")\n@@ -81,10 +93,9 @@ if (NOT MINGW AND NOT ${WASM_ENABLED} AND NOT ${MUSL_ENABLED})\n     duckdb_extension_load(iceberg\n #            ${LOAD_ICEBERG_TESTS} TODO: re-enable once autoloading test is fixed\n             GIT_URL https://github.com/duckdb/duckdb-iceberg\n-            GIT_TAG 43b4e37f6e859d6c1c67b787ac511659e9e0b6fb\n+            GIT_TAG 2db98c685f67373b347c3a8c435ef2e01c509697\n             )\n endif()\n-endif()\n \n ################# INET\n duckdb_extension_load(inet\n@@ -103,7 +114,7 @@ if (NOT MINGW AND NOT ${WASM_ENABLED})\n     duckdb_extension_load(postgres_scanner\n             DONT_LINK\n             GIT_URL https://github.com/duckdb/duckdb-postgres\n-            GIT_TAG 8461ed8b6f726564934e9c831cdc88d431e3148f\n+            GIT_TAG 98482ce5c144287f01e738275892cdb84ea9b5ce\n             APPLY_PATCHES\n             )\n endif()\n@@ -114,10 +125,9 @@ if (NOT MINGW)\n duckdb_extension_load(spatial\n     DONT_LINK LOAD_TESTS\n     GIT_URL https://github.com/duckdb/duckdb-spatial\n-    GIT_TAG 2905968a85703e5ca3698976daafd759554e1744\n+    GIT_TAG 4be6065edc313a53ff2196ff79c11a0d5e249720\n     INCLUDE_DIR spatial/include\n     TEST_DIR test/sql\n-    APPLY_PATCHES\n     )\n endif()\n \n@@ -132,7 +142,7 @@ endif()\n duckdb_extension_load(sqlite_scanner\n         ${STATIC_LINK_SQLITE} LOAD_TESTS\n         GIT_URL https://github.com/duckdb/duckdb-sqlite\n-        GIT_TAG 96e451c043afa40ee39b7581009ba0c72a523a12\n+        GIT_TAG 66a5fa2448398379dc21c18308e3b95d42d84015\n         APPLY_PATCHES\n         )\n \n@@ -147,7 +157,7 @@ duckdb_extension_load(vss\n         LOAD_TESTS\n         DONT_LINK\n         GIT_URL https://github.com/duckdb/duckdb-vss\n-        GIT_TAG 580e8918eb89f478cf2d233ca908ffbd3ec752c5\n+        GIT_TAG ba199a7215b75e83821ece13f6b921ccfcebd6ac\n         TEST_DIR test/sql\n         APPLY_PATCHES\n     )\n@@ -158,7 +168,7 @@ if (NOT MINGW AND NOT ${WASM_ENABLED} AND NOT ${MUSL_ENABLED})\n             DONT_LINK\n             LOAD_TESTS\n             GIT_URL https://github.com/duckdb/duckdb-mysql\n-            GIT_TAG c2a56813a9fe9cb8c24c424be646d41ab2f8e64f\n+            GIT_TAG 93469fc39a317acf916627e0ddc724a076bf7302\n             APPLY_PATCHES\n             )\n endif()\ndiff --git a/.github/patches/extensions/spatial/fix.patch b/.github/patches/extensions/spatial/fix.patch\ndeleted file mode 100644\nindex a81f3b637a89..000000000000\n--- a/.github/patches/extensions/spatial/fix.patch\n+++ /dev/null\n@@ -1,265 +0,0 @@\n-diff --git a/src/spatial/index/rtree/rtree_index.hpp b/src/spatial/index/rtree/rtree_index.hpp\n-index 3462613..126f220 100644\n---- a/src/spatial/index/rtree/rtree_index.hpp\n-+++ b/src/spatial/index/rtree/rtree_index.hpp\n-@@ -34,7 +34,7 @@ public:\n- \t\treturn std::move(res);\n- \t}\n- \n--\tstatic unique_ptr<PhysicalOperator> CreatePlan(PlanIndexInput &input);\n-+\tstatic PhysicalOperator &CreatePlan(PlanIndexInput &input);\n- \n- public:\n- \t//! Called when data is appended to the index. The lock obtained from InitializeLock must be held\n-diff --git a/src/spatial/index/rtree/rtree_index_create_logical.cpp b/src/spatial/index/rtree/rtree_index_create_logical.cpp\n-index 9c891e3..a2f7448 100644\n---- a/src/spatial/index/rtree/rtree_index_create_logical.cpp\n-+++ b/src/spatial/index/rtree/rtree_index_create_logical.cpp\n-@@ -39,8 +39,8 @@ void LogicalCreateRTreeIndex::ResolveColumnBindings(ColumnBindingResolver &res,\n- \t                                             [&](unique_ptr<Expression> *child) { res.VisitExpression(child); });\n- }\n- \n--static unique_ptr<PhysicalOperator> CreateNullFilter(const LogicalOperator &op, const vector<LogicalType> &types,\n--                                                     ClientContext &context) {\n-+static PhysicalOperator &CreateNullFilter(PhysicalPlanGenerator &generator, const LogicalOperator &op,\n-+                                          const vector<LogicalType> &types, ClientContext &context) {\n- \tvector<unique_ptr<Expression>> filter_select_list;\n- \n- \t// Filter NOT NULL on the GEOMETRY column\n-@@ -66,14 +66,13 @@ static unique_ptr<PhysicalOperator> CreateNullFilter(const LogicalOperator &op,\n- \t// Combine into an AND\n- \tauto and_expr = make_uniq_base<Expression, BoundConjunctionExpression>(\n- \t    ExpressionType::CONJUNCTION_AND, std::move(is_not_null_expr), std::move(is_not_empty_expr));\n--\n- \tfilter_select_list.push_back(std::move(and_expr));\n- \n--\treturn make_uniq<PhysicalFilter>(types, std::move(filter_select_list), op.estimated_cardinality);\n-+\treturn generator.Make<PhysicalFilter>(types, std::move(filter_select_list), op.estimated_cardinality);\n- }\n- \n--static unique_ptr<PhysicalOperator>\n--CreateBoundingBoxProjection(const LogicalOperator &op, const vector<LogicalType> &types, ClientContext &context) {\n-+static PhysicalOperator &CreateBoundingBoxProjection(PhysicalPlanGenerator &planner, const LogicalOperator &op,\n-+                                                     const vector<LogicalType> &types, ClientContext &context) {\n- \tauto &catalog = Catalog::GetSystemCatalog(context);\n- \n- \t// Get the bounding box function\n-@@ -96,11 +95,11 @@ CreateBoundingBoxProjection(const LogicalOperator &op, const vector<LogicalType>\n- \tselect_list.push_back(std::move(bbox_expr));\n- \tselect_list.push_back(std::move(rowid_expr));\n- \n--\treturn make_uniq<PhysicalProjection>(types, std::move(select_list), op.estimated_cardinality);\n-+\treturn planner.Make<PhysicalProjection>(types, std::move(select_list), op.estimated_cardinality);\n- }\n- \n--static unique_ptr<PhysicalOperator> CreateOrderByMinX(const LogicalOperator &op, const vector<LogicalType> &types,\n--                                                      ClientContext &context) {\n-+static PhysicalOperator &CreateOrderByMinX(PhysicalPlanGenerator &planner, const LogicalOperator &op,\n-+                                           const vector<LogicalType> &types, ClientContext &context) {\n- \tauto &catalog = Catalog::GetSystemCatalog(context);\n- \n- \t// Get the centroid value function\n-@@ -130,14 +129,15 @@ static unique_ptr<PhysicalOperator> CreateOrderByMinX(const LogicalOperator &op,\n- \tvector<BoundOrderByNode> orders;\n- \torders.emplace_back(OrderType::ASCENDING, OrderByNullType::NULLS_FIRST, std::move(xmin_expr));\n- \tvector<idx_t> projections = {0, 1};\n--\treturn make_uniq<PhysicalOrder>(types, std::move(orders), projections, op.estimated_cardinality);\n-+\treturn planner.Make<PhysicalOrder>(types, std::move(orders), projections, op.estimated_cardinality);\n- }\n- \n--unique_ptr<PhysicalOperator> RTreeIndex::CreatePlan(PlanIndexInput &input) {\n-+PhysicalOperator &RTreeIndex::CreatePlan(PlanIndexInput &input) {\n- \n- \tauto &op = input.op;\n- \tauto &table_scan = input.table_scan;\n- \tauto &context = input.context;\n-+\tauto &planner = input.planner;\n- \n- \t// generate a physical plan for the parallel index creation which consists of the following operators\n- \t// table scan - projection (for expression execution) - filter (NOT NULL) - order - create index\n-@@ -175,38 +175,35 @@ unique_ptr<PhysicalOperator> RTreeIndex::CreatePlan(PlanIndexInput &input) {\n- \tselect_list.push_back(make_uniq<BoundReferenceExpression>(LogicalType::ROW_TYPE, op.info->scan_types.size() - 1));\n- \n- \t// Project the expressions\n--\tauto projection = make_uniq<PhysicalProjection>(new_column_types, std::move(select_list), op.estimated_cardinality);\n--\tprojection->children.push_back(std::move(table_scan));\n-+\tauto &projection =\n-+\t    planner.Make<PhysicalProjection>(new_column_types, std::move(select_list), op.estimated_cardinality);\n-+\tprojection.children.push_back(table_scan);\n- \n- \t// Filter operator for (IS_NOT_NULL) and (NOT ST_IsEmpty) on the geometry column\n--\tauto null_filter = CreateNullFilter(op, new_column_types, context);\n--\tnull_filter->children.push_back(std::move(projection));\n-+\tauto &null_filter = CreateNullFilter(planner, op, new_column_types, context);\n-+\tnull_filter.children.push_back(projection);\n- \n- \t// Project the bounding box and the row ID\n- \tvector<LogicalType> projected_types = {GeoTypes::BOX_2DF(), LogicalType::ROW_TYPE};\n--\tauto bbox_proj = CreateBoundingBoxProjection(op, projected_types, context);\n--\tbbox_proj->children.push_back(std::move(null_filter));\n-+\tauto &bbox_proj = CreateBoundingBoxProjection(planner, op, projected_types, context);\n-+\tbbox_proj.children.push_back(null_filter);\n- \n- \t// Create an ORDER_BY operator to sort the bounding boxes by the xmin value\n--\tauto physical_order = CreateOrderByMinX(op, projected_types, context);\n--\tphysical_order->children.push_back(std::move(bbox_proj));\n-+\tauto &physical_order = CreateOrderByMinX(planner, op, projected_types, context);\n-+\tphysical_order.children.push_back(bbox_proj);\n- \n- \t// Now finally create the actual physical create index operator\n--\tauto physical_create_index =\n--\t    make_uniq<PhysicalCreateRTreeIndex>(op, op.table, op.info->column_ids, std::move(op.info),\n--\t                                        std::move(op.unbound_expressions), op.estimated_cardinality);\n--\n--\tphysical_create_index->children.push_back(std::move(physical_order));\n--\n--\treturn std::move(physical_create_index);\n-+\tauto &physical_create_index =\n-+\t    planner.Make<PhysicalCreateRTreeIndex>(op, op.table, op.info->column_ids, std::move(op.info),\n-+\t                                           std::move(op.unbound_expressions), op.estimated_cardinality);\n-+\tphysical_create_index.children.push_back(physical_order);\n-+\treturn physical_create_index;\n- }\n- \n- // TODO: Remove this\n--unique_ptr<PhysicalOperator> LogicalCreateRTreeIndex::CreatePlan(ClientContext &context,\n--                                                                 PhysicalPlanGenerator &generator) {\n--\n--\tauto table_scan = generator.CreatePlan(std::move(children[0]));\n-+PhysicalOperator &LogicalCreateRTreeIndex::CreatePlan(ClientContext &context, PhysicalPlanGenerator &planner) {\n- \n-+\tauto &table_scan = planner.CreatePlan(*children[0]);\n- \tauto &op = *this;\n- \n- \t// generate a physical plan for the parallel index creation which consists of the following operators\n-@@ -235,7 +232,7 @@ unique_ptr<PhysicalOperator> LogicalCreateRTreeIndex::CreatePlan(ClientContext &\n- \tD_ASSERT(op.info->index_type == RTreeIndex::TYPE_NAME);\n- \n- \t// table scan operator for index key columns and row IDs\n--\tgenerator.dependencies.AddDependency(op.table);\n-+\tplanner.dependencies.AddDependency(op.table);\n- \n- \tD_ASSERT(op.info->scan_types.size() - 1 <= op.info->names.size());\n- \tD_ASSERT(op.info->scan_types.size() - 1 <= op.info->column_ids.size());\n-@@ -255,30 +252,29 @@ unique_ptr<PhysicalOperator> LogicalCreateRTreeIndex::CreatePlan(ClientContext &\n- \tselect_list.push_back(make_uniq<BoundReferenceExpression>(LogicalType::ROW_TYPE, op.info->scan_types.size() - 1));\n- \n- \t// Project the expressions\n--\tauto projection = make_uniq<PhysicalProjection>(new_column_types, std::move(select_list), op.estimated_cardinality);\n--\tprojection->children.push_back(std::move(table_scan));\n-+\tauto &projection =\n-+\t    planner.Make<PhysicalProjection>(new_column_types, std::move(select_list), op.estimated_cardinality);\n-+\tprojection.children.push_back(table_scan);\n- \n- \t// Filter operator for (IS_NOT_NULL) and (NOT ST_IsEmpty) on the geometry column\n--\tauto null_filter = CreateNullFilter(op, new_column_types, context);\n--\tnull_filter->children.push_back(std::move(projection));\n-+\tauto &null_filter = CreateNullFilter(planner, op, new_column_types, context);\n-+\tnull_filter.children.push_back(projection);\n- \n- \t// Project the bounding box and the row ID\n- \tvector<LogicalType> projected_types = {GeoTypes::BOX_2DF(), LogicalType::ROW_TYPE};\n--\tauto bbox_proj = CreateBoundingBoxProjection(op, projected_types, context);\n--\tbbox_proj->children.push_back(std::move(null_filter));\n-+\tauto &bbox_proj = CreateBoundingBoxProjection(planner, op, projected_types, context);\n-+\tbbox_proj.children.push_back(null_filter);\n- \n- \t// Create an ORDER_BY operator to sort the bounding boxes by the xmin value\n--\tauto physical_order = CreateOrderByMinX(op, projected_types, context);\n--\tphysical_order->children.push_back(std::move(bbox_proj));\n-+\tauto &physical_order = CreateOrderByMinX(planner, op, projected_types, context);\n-+\tphysical_order.children.push_back(bbox_proj);\n- \n- \t// Now finally create the actual physical create index operator\n--\tauto physical_create_index =\n--\t    make_uniq<PhysicalCreateRTreeIndex>(op, op.table, op.info->column_ids, std::move(op.info),\n--\t                                        std::move(op.unbound_expressions), op.estimated_cardinality);\n--\n--\tphysical_create_index->children.push_back(std::move(physical_order));\n--\n--\treturn std::move(physical_create_index);\n-+\tauto &physical_create_index =\n-+\t    planner.Make<PhysicalCreateRTreeIndex>(op, op.table, op.info->column_ids, std::move(op.info),\n-+\t                                           std::move(op.unbound_expressions), op.estimated_cardinality);\n-+\tphysical_create_index.children.push_back(physical_order);\n-+\treturn physical_create_index;\n- }\n- \n- } // namespace duckdb\n-diff --git a/src/spatial/index/rtree/rtree_index_create_logical.hpp b/src/spatial/index/rtree/rtree_index_create_logical.hpp\n-index e960069..2b73e36 100644\n---- a/src/spatial/index/rtree/rtree_index_create_logical.hpp\n-+++ b/src/spatial/index/rtree/rtree_index_create_logical.hpp\n-@@ -25,7 +25,7 @@ public:\n- \tvoid ResolveColumnBindings(ColumnBindingResolver &res, vector<ColumnBinding> &bindings) override;\n- \n- \t// Actually create and plan the index creation\n--\tunique_ptr<PhysicalOperator> CreatePlan(ClientContext &context, PhysicalPlanGenerator &generator) override;\n-+\tPhysicalOperator &CreatePlan(ClientContext &context, PhysicalPlanGenerator &planner) override;\n- \n- \tvoid Serialize(Serializer &writer) const override {\n- \t\tLogicalExtensionOperator::Serialize(writer);\n-diff --git a/src/spatial/index/rtree/rtree_index_scan.cpp b/src/spatial/index/rtree/rtree_index_scan.cpp\n-index 2cb8db3..adf0135 100644\n---- a/src/spatial/index/rtree/rtree_index_scan.cpp\n-+++ b/src/spatial/index/rtree/rtree_index_scan.cpp\n-@@ -60,7 +60,7 @@ static unique_ptr<GlobalTableFunctionState> RTreeIndexScanInitGlobal(ClientConte\n- \t}\n- \n- \t// Initialize the storage scan state\n--\tresult->local_storage_state.Initialize(result->column_ids, input.filters.get());\n-+\tresult->local_storage_state.Initialize(result->column_ids, context, input.filters);\n- \tlocal_storage.InitializeScan(bind_data.table.GetStorage(), result->local_storage_state.local_state, input.filters);\n- \n- \t// Initialize the scan state for the index\n-diff --git a/src/spatial/modules/gdal/gdal_module.cpp b/src/spatial/modules/gdal/gdal_module.cpp\n-index b96928d..69307c0 100644\n---- a/src/spatial/modules/gdal/gdal_module.cpp\n-+++ b/src/spatial/modules/gdal/gdal_module.cpp\n-@@ -9,7 +9,7 @@\n- // DuckDB\n- #include \"duckdb/main/database.hpp\"\n- #include \"duckdb/common/enums/file_glob_options.hpp\"\n--#include \"duckdb/common/multi_file_reader.hpp\"\n-+#include \"duckdb/common/multi_file/multi_file_reader.hpp\"\n- #include \"duckdb/function/table/arrow.hpp\"\n- #include \"duckdb/main/extension_util.hpp\"\n- #include \"duckdb/parser/parsed_data/create_table_function_info.hpp\"\n-diff --git a/src/spatial/modules/shapefile/shapefile_module.cpp b/src/spatial/modules/shapefile/shapefile_module.cpp\n-index 5659fc8..4b51d75 100644\n---- a/src/spatial/modules/shapefile/shapefile_module.cpp\n-+++ b/src/spatial/modules/shapefile/shapefile_module.cpp\n-@@ -3,7 +3,7 @@\n- #include \"spatial/geometry/sgl.hpp\"\n- #include \"spatial/spatial_types.hpp\"\n- \n--#include \"duckdb/common/multi_file_reader.hpp\"\n-+#include \"duckdb/common/multi_file/multi_file_reader.hpp\"\n- #include \"duckdb/function/replacement_scan.hpp\"\n- #include \"duckdb/main/extension_util.hpp\"\n- #include \"duckdb/parser/expression/constant_expression.hpp\"\n-diff --git a/test/sql/geometry/st_dump.test b/test/sql/geometry/st_dump.test\n-index 3346f5f..c181720 100644\n---- a/test/sql/geometry/st_dump.test\n-+++ b/test/sql/geometry/st_dump.test\n-@@ -25,7 +25,7 @@ SElECT ST_Dump(ST_GeomFromText('GEOMETRYCOLLECTION EMPTY'));\n- query I\n- SElECT ST_Dump(ST_GeomFromText('GEOMETRYCOLLECTION (POINT (0 0))'));\n- ----\n--[{'geom': POINT (0 0), 'path': [1]}]\n-+[{'geom': 'POINT (0 0)', 'path': [1]}]\n- \n- # Test with multipoint\n- query II\n-@@ -69,9 +69,9 @@ FROM (VALUES\n-     (ST_GeomFromText('GEOMETRYCOLLECTION (POINT (1 1), GEOMETRYCOLLECTION(POINT (3 3)), POINT (2 2))'))\n- ) as t(geom)\n- ----\n--[{'geom': POINT (1 1), 'path': [1]}, {'geom': POINT (2 2), 'path': [2]}, {'geom': POINT (3 3), 'path': [3, 1]}]\n-+[{'geom': 'POINT (1 1)', 'path': [1]}, {'geom': 'POINT (2 2)', 'path': [2]}, {'geom': 'POINT (3 3)', 'path': [3, 1]}]\n- NULL\n--[{'geom': POINT (1 1), 'path': [1]}, {'geom': POINT (3 3), 'path': [2, 1]}, {'geom': POINT (2 2), 'path': [3]}]\n-+[{'geom': 'POINT (1 1)', 'path': [1]}, {'geom': 'POINT (3 3)', 'path': [2, 1]}, {'geom': 'POINT (2 2)', 'path': [3]}]\n- \n- \n- # With Z and M\ndiff --git a/.github/workflows/Wasm.yml b/.github/workflows/Wasm.yml\nindex ad246525e6e2..9fe7d1931d56 100644\n--- a/.github/workflows/Wasm.yml\n+++ b/.github/workflows/Wasm.yml\n@@ -31,7 +31,6 @@ concurrency:\n \n env:\n   GH_TOKEN: ${{ secrets.GH_TOKEN }}\n-  CMAKE_POLICY_VERSION_MINIMUM: 3.5\n \n jobs:\n  wasm-extensions:\ndiff --git a/scripts/generate_extensions_function.py b/scripts/generate_extensions_function.py\nindex d6e861bfc6e9..586a8b87968b 100644\n--- a/scripts/generate_extensions_function.py\n+++ b/scripts/generate_extensions_function.py\n@@ -730,6 +730,7 @@ def write_header(data: ExtensionData):\n                                                                 {\"s3/credential_chain\", \"aws\"},\n                                                                 {\"gcs/credential_chain\", \"aws\"},\n                                                                 {\"r2/credential_chain\", \"aws\"},\n+                                                                {\"aws/credential_chain\", \"aws\"},\n                                                                 {\"azure/access_token\", \"azure\"},\n                                                                 {\"azure/config\", \"azure\"},\n                                                                 {\"azure/credential_chain\", \"azure\"},\ndiff --git a/src/common/exception.cpp b/src/common/exception.cpp\nindex 02b25f02b7cf..99b3d2662dec 100644\n--- a/src/common/exception.cpp\n+++ b/src/common/exception.cpp\n@@ -334,8 +334,7 @@ FatalException::FatalException(ExceptionType type, const string &msg) : Exceptio\n \n InternalException::InternalException(const string &msg) : Exception(ExceptionType::INTERNAL, msg) {\n #ifdef DUCKDB_CRASH_ON_ASSERT\n-\tPrinter::Print(\"ABORT THROWN BY INTERNAL EXCEPTION: \" + msg);\n-\tPrinter::Print(StackTrace::GetStackTrace());\n+\tPrinter::Print(\"ABORT THROWN BY INTERNAL EXCEPTION: \" + msg + \"\\n\" + StackTrace::GetStackTrace());\n \tabort();\n #endif\n }\ndiff --git a/src/common/printer.cpp b/src/common/printer.cpp\nindex 0c704b74d99e..e07d3f8f2bc9 100644\n--- a/src/common/printer.cpp\n+++ b/src/common/printer.cpp\n@@ -30,11 +30,17 @@ void Printer::RawPrint(OutputStream stream, const string &str) {\n #endif\n }\n \n-// LCOV_EXCL_START\n-void Printer::Print(OutputStream stream, const string &str) {\n+void Printer::DefaultLinePrint(OutputStream stream, const string &str) {\n \tPrinter::RawPrint(stream, str);\n \tPrinter::RawPrint(stream, \"\\n\");\n }\n+\n+line_printer_f Printer::line_printer = Printer::DefaultLinePrint;\n+\n+// LCOV_EXCL_START\n+void Printer::Print(OutputStream stream, const string &str) {\n+\tPrinter::line_printer(stream, str);\n+}\n void Printer::Flush(OutputStream stream) {\n #ifndef DUCKDB_DISABLE_PRINT\n \tfflush(stream == OutputStream::STREAM_STDERR ? stderr : stdout);\ndiff --git a/src/execution/operator/persistent/physical_insert.cpp b/src/execution/operator/persistent/physical_insert.cpp\nindex 6e02f0ff5983..0ecec8f10856 100644\n--- a/src/execution/operator/persistent/physical_insert.cpp\n+++ b/src/execution/operator/persistent/physical_insert.cpp\n@@ -276,7 +276,7 @@ static idx_t PerformOnConflictAction(InsertLocalState &lstate, InsertGlobalState\n \t\t}\n \t\tauto &local_storage = LocalStorage::Get(context.client, data_table.db);\n \t\tif (gstate.initialized) {\n-\t\t\t// Flush the data first, it might be referenced by the Update\n+\t\t\t// Flush any local appends that could be referenced by the UPDATE.\n \t\t\tdata_table.FinalizeLocalAppend(gstate.append_state);\n \t\t\tgstate.initialized = false;\n \t\t}\n@@ -289,6 +289,11 @@ static idx_t PerformOnConflictAction(InsertLocalState &lstate, InsertGlobalState\n \t\tdata_table.Delete(delete_state, context.client, row_ids, update_chunk.size());\n \t} else {\n \t\tauto &local_storage = LocalStorage::Get(context.client, data_table.db);\n+\t\tif (gstate.initialized) {\n+\t\t\t// Flush any local appends that could be referenced by the DELETE.\n+\t\t\tdata_table.FinalizeLocalAppend(gstate.append_state);\n+\t\t\tgstate.initialized = false;\n+\t\t}\n \t\tlocal_storage.Delete(data_table, row_ids, update_chunk.size());\n \t}\n \ndiff --git a/src/include/duckdb/common/printer.hpp b/src/include/duckdb/common/printer.hpp\nindex eba11c336b8e..b3cb27e5d730 100644\n--- a/src/include/duckdb/common/printer.hpp\n+++ b/src/include/duckdb/common/printer.hpp\n@@ -15,6 +15,8 @@ namespace duckdb {\n \n enum class OutputStream : uint8_t { STREAM_STDOUT = 1, STREAM_STDERR = 2 };\n \n+typedef void (*line_printer_f)(OutputStream stream, const string &str);\n+\n //! Printer is a static class that allows printing to logs or stdout/stderr\n class Printer {\n public:\n@@ -40,5 +42,11 @@ class Printer {\n \tDUCKDB_API static bool IsTerminal(OutputStream stream);\n \t//! The terminal width\n \tDUCKDB_API static idx_t TerminalWidth();\n+\n+\t// hook to allow capturing the output and routing it somewhere else / reformat it};\n+\tstatic line_printer_f line_printer;\n+\n+private:\n+\tstatic void DefaultLinePrint(OutputStream stream, const string &str);\n };\n } // namespace duckdb\ndiff --git a/src/include/duckdb/main/client_context_state.hpp b/src/include/duckdb/main/client_context_state.hpp\nindex 80cdc8b8f33c..fcedae943dea 100644\n--- a/src/include/duckdb/main/client_context_state.hpp\n+++ b/src/include/duckdb/main/client_context_state.hpp\n@@ -13,6 +13,7 @@\n #include \"duckdb/common/optional_ptr.hpp\"\n #include \"duckdb/main/config.hpp\"\n #include \"duckdb/main/valid_checker.hpp\"\n+#include \"duckdb/planner/expression/bound_parameter_data.hpp\"\n #include \"duckdb/transaction/meta_transaction.hpp\"\n #include \"duckdb/transaction/transaction_manager.hpp\"\n #include \"duckdb/main/database_manager.hpp\"\n@@ -39,6 +40,11 @@ struct PreparedStatementCallbackInfo {\n \tconst PendingQueryParameters &parameters;\n };\n \n+struct BindPreparedStatementCallbackInfo {\n+\tPreparedStatementData &prepared_statement;\n+\toptional_ptr<case_insensitive_map_t<BoundParameterData>> parameters;\n+};\n+\n //! ClientContextState is virtual base class for ClientContext-local (or Query-Local, using QueryEnd callback) state\n //! e.g. caches that need to live as long as a ClientContext or Query.\n class ClientContextState {\n@@ -78,6 +84,10 @@ class ClientContextState {\n \t                                          RebindQueryInfo current_rebind) {\n \t\treturn RebindQueryInfo::DO_NOT_REBIND;\n \t}\n+\tvirtual RebindQueryInfo OnRebindPreparedStatement(ClientContext &context, BindPreparedStatementCallbackInfo &info,\n+\t                                                  RebindQueryInfo current_rebind) {\n+\t\treturn RebindQueryInfo::DO_NOT_REBIND;\n+\t}\n \tvirtual void WriteProfilingInformation(std::ostream &ss) {\n \t}\n \tvirtual void OnTaskStart(ClientContext &context) {\ndiff --git a/src/include/duckdb/main/extension_entries.hpp b/src/include/duckdb/main/extension_entries.hpp\nindex e4a585d59b5b..9e906a2a09c4 100644\n--- a/src/include/duckdb/main/extension_entries.hpp\n+++ b/src/include/duckdb/main/extension_entries.hpp\n@@ -527,6 +527,7 @@ static constexpr ExtensionFunctionEntry EXTENSION_FUNCTIONS[] = {\n     {\"sqlite_scan\", \"sqlite_scanner\", CatalogType::TABLE_FUNCTION_ENTRY},\n     {\"sqlsmith\", \"sqlsmith\", CatalogType::TABLE_FUNCTION_ENTRY},\n     {\"sqrt\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n+    {\"st_affine\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_area\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_area_spheroid\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_asgeojson\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n@@ -536,6 +537,7 @@ static constexpr ExtensionFunctionEntry EXTENSION_FUNCTIONS[] = {\n     {\"st_aswkb\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_boundary\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_buffer\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n+    {\"st_buildarea\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_centroid\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_collect\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_collectionextract\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n@@ -543,6 +545,12 @@ static constexpr ExtensionFunctionEntry EXTENSION_FUNCTIONS[] = {\n     {\"st_contains\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_containsproperly\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_convexhull\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n+    {\"st_coverageinvalidedges\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n+    {\"st_coverageinvalidedges_agg\", \"spatial\", CatalogType::AGGREGATE_FUNCTION_ENTRY},\n+    {\"st_coveragesimplify\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n+    {\"st_coveragesimplify_agg\", \"spatial\", CatalogType::AGGREGATE_FUNCTION_ENTRY},\n+    {\"st_coverageunion\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n+    {\"st_coverageunion_agg\", \"spatial\", CatalogType::AGGREGATE_FUNCTION_ENTRY},\n     {\"st_coveredby\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_covers\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_crosses\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n@@ -600,12 +608,14 @@ static constexpr ExtensionFunctionEntry EXTENSION_FUNCTIONS[] = {\n     {\"st_makeline\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_makepolygon\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_makevalid\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n+    {\"st_maximuminscribedcircle\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_minimumrotatedrectangle\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_mmax\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_mmin\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_multi\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_ngeometries\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_ninteriorrings\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n+    {\"st_node\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_normalize\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_npoints\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_numgeometries\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n@@ -623,6 +633,7 @@ static constexpr ExtensionFunctionEntry EXTENSION_FUNCTIONS[] = {\n     {\"st_pointonsurface\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_points\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_polygon2dfromwkb\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n+    {\"st_polygonize\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_quadkey\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_read\", \"spatial\", CatalogType::TABLE_FUNCTION_ENTRY},\n     {\"st_read_meta\", \"spatial\", CatalogType::TABLE_FUNCTION_ENTRY},\n@@ -631,12 +642,19 @@ static constexpr ExtensionFunctionEntry EXTENSION_FUNCTIONS[] = {\n     {\"st_reduceprecision\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_removerepeatedpoints\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_reverse\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n+    {\"st_rotate\", \"spatial\", CatalogType::MACRO_ENTRY},\n+    {\"st_rotatex\", \"spatial\", CatalogType::MACRO_ENTRY},\n+    {\"st_rotatey\", \"spatial\", CatalogType::MACRO_ENTRY},\n+    {\"st_rotatez\", \"spatial\", CatalogType::MACRO_ENTRY},\n+    {\"st_scale\", \"spatial\", CatalogType::MACRO_ENTRY},\n     {\"st_shortestline\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_simplify\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_simplifypreservetopology\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_startpoint\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_touches\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_transform\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n+    {\"st_translate\", \"spatial\", CatalogType::MACRO_ENTRY},\n+    {\"st_transscale\", \"spatial\", CatalogType::MACRO_ENTRY},\n     {\"st_union\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_union_agg\", \"spatial\", CatalogType::AGGREGATE_FUNCTION_ENTRY},\n     {\"st_voronoidiagram\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n@@ -1075,6 +1093,7 @@ static constexpr ExtensionEntry EXTENSION_SECRET_PROVIDERS[] = {\n     {\"s3/credential_chain\", \"aws\"},\n     {\"gcs/credential_chain\", \"aws\"},\n     {\"r2/credential_chain\", \"aws\"},\n+    {\"aws/credential_chain\", \"aws\"},\n     {\"azure/access_token\", \"azure\"},\n     {\"azure/config\", \"azure\"},\n     {\"azure/credential_chain\", \"azure\"},\ndiff --git a/src/include/duckdb/parser/constraints/unique_constraint.hpp b/src/include/duckdb/parser/constraints/unique_constraint.hpp\nindex a3811160ae66..ded23b0d3bfd 100644\n--- a/src/include/duckdb/parser/constraints/unique_constraint.hpp\n+++ b/src/include/duckdb/parser/constraints/unique_constraint.hpp\n@@ -22,6 +22,7 @@ class UniqueConstraint : public Constraint {\n \n public:\n \tDUCKDB_API UniqueConstraint(const LogicalIndex index, const bool is_primary_key);\n+\tDUCKDB_API UniqueConstraint(const LogicalIndex index, string column_name, const bool is_primary_key);\n \tDUCKDB_API UniqueConstraint(vector<string> columns, const bool is_primary_key);\n \n public:\n@@ -46,8 +47,6 @@ class UniqueConstraint : public Constraint {\n \tvector<LogicalIndex> GetLogicalIndexes(const ColumnList &columns) const;\n \t//! Get the name of the constraint.\n \tstring GetName(const string &table_name) const;\n-\t//! Sets a single column name. Does nothing, if the name is already set.\n-\tvoid SetColumnName(const string &name);\n \n private:\n \tUniqueConstraint();\ndiff --git a/src/include/duckdb/planner/binder.hpp b/src/include/duckdb/planner/binder.hpp\nindex df08140694bf..d0601ec79282 100644\n--- a/src/include/duckdb/planner/binder.hpp\n+++ b/src/include/duckdb/planner/binder.hpp\n@@ -143,8 +143,9 @@ class Binder : public enable_shared_from_this<Binder> {\n \tvector<unique_ptr<BoundConstraint>> BindConstraints(const TableCatalogEntry &table);\n \tvector<unique_ptr<BoundConstraint>> BindNewConstraints(vector<unique_ptr<Constraint>> &constraints,\n \t                                                       const string &table_name, const ColumnList &columns);\n-\tunique_ptr<BoundConstraint> BindConstraint(Constraint &constraint, const string &table, const ColumnList &columns);\n-\tunique_ptr<BoundConstraint> BindUniqueConstraint(Constraint &constraint, const string &table,\n+\tunique_ptr<BoundConstraint> BindConstraint(const Constraint &constraint, const string &table,\n+\t                                           const ColumnList &columns);\n+\tunique_ptr<BoundConstraint> BindUniqueConstraint(const Constraint &constraint, const string &table,\n \t                                                 const ColumnList &columns);\n \n \tBoundStatement BindAlterAddIndex(BoundStatement &result, CatalogEntry &entry, unique_ptr<AlterInfo> alter_info);\ndiff --git a/src/parser/constraints/unique_constraint.cpp b/src/parser/constraints/unique_constraint.cpp\nindex 51c4631b39c6..d3379be42b91 100644\n--- a/src/parser/constraints/unique_constraint.cpp\n+++ b/src/parser/constraints/unique_constraint.cpp\n@@ -10,6 +10,10 @@ UniqueConstraint::UniqueConstraint() : Constraint(ConstraintType::UNIQUE), index\n UniqueConstraint::UniqueConstraint(const LogicalIndex index, const bool is_primary_key)\n     : Constraint(ConstraintType::UNIQUE), index(index), is_primary_key(is_primary_key) {\n }\n+UniqueConstraint::UniqueConstraint(const LogicalIndex index, string column_name_p, const bool is_primary_key)\n+    : UniqueConstraint(index, is_primary_key) {\n+\tcolumns.push_back(std::move(column_name_p));\n+}\n \n UniqueConstraint::UniqueConstraint(vector<string> columns, const bool is_primary_key)\n     : Constraint(ConstraintType::UNIQUE), index(DConstants::INVALID_INDEX), columns(std::move(columns)),\n@@ -32,10 +36,7 @@ unique_ptr<Constraint> UniqueConstraint::Copy() const {\n \t\treturn make_uniq<UniqueConstraint>(columns, is_primary_key);\n \t}\n \n-\tauto result = make_uniq<UniqueConstraint>(index, is_primary_key);\n-\tif (!columns.empty()) {\n-\t\tresult->columns.push_back(columns[0]);\n-\t}\n+\tauto result = make_uniq<UniqueConstraint>(index, columns.empty() ? string() : columns[0], is_primary_key);\n \treturn std::move(result);\n }\n \n@@ -95,11 +96,4 @@ string UniqueConstraint::GetName(const string &table_name) const {\n \treturn type_name + \"_\" + table_name + name;\n }\n \n-void UniqueConstraint::SetColumnName(const string &column_name) {\n-\tif (!columns.empty()) {\n-\t\treturn;\n-\t}\n-\tcolumns.push_back(column_name);\n-}\n-\n } // namespace duckdb\ndiff --git a/src/parser/transform/constraint/transform_constraint.cpp b/src/parser/transform/constraint/transform_constraint.cpp\nindex 8439fc863258..e73b15cdc47a 100644\n--- a/src/parser/transform/constraint/transform_constraint.cpp\n+++ b/src/parser/transform/constraint/transform_constraint.cpp\n@@ -105,9 +105,9 @@ unique_ptr<Constraint> Transformer::TransformConstraint(duckdb_libpgquery::PGCon\n \tcase duckdb_libpgquery::PG_CONSTR_CHECK:\n \t\treturn TransformConstraint(constraint);\n \tcase duckdb_libpgquery::PG_CONSTR_PRIMARY:\n-\t\treturn make_uniq<UniqueConstraint>(LogicalIndex(index), true);\n+\t\treturn make_uniq<UniqueConstraint>(LogicalIndex(index), column.GetName(), true);\n \tcase duckdb_libpgquery::PG_CONSTR_UNIQUE:\n-\t\treturn make_uniq<UniqueConstraint>(LogicalIndex(index), false);\n+\t\treturn make_uniq<UniqueConstraint>(LogicalIndex(index), column.GetName(), false);\n \tcase duckdb_libpgquery::PG_CONSTR_NULL:\n \t\treturn nullptr;\n \tcase duckdb_libpgquery::PG_CONSTR_GENERATED_VIRTUAL: {\ndiff --git a/src/planner/binder/statement/bind_create_table.cpp b/src/planner/binder/statement/bind_create_table.cpp\nindex 8c7943ff77fc..9a9c16f05712 100644\n--- a/src/planner/binder/statement/bind_create_table.cpp\n+++ b/src/planner/binder/statement/bind_create_table.cpp\n@@ -102,7 +102,7 @@ vector<unique_ptr<BoundConstraint>> Binder::BindNewConstraints(vector<unique_ptr\n \treturn bound_constraints;\n }\n \n-unique_ptr<BoundConstraint> BindCheckConstraint(Binder &binder, Constraint &constraint, const string &table,\n+unique_ptr<BoundConstraint> BindCheckConstraint(Binder &binder, const Constraint &constraint, const string &table,\n                                                 const ColumnList &columns) {\n \tauto bound_constraint = make_uniq<BoundCheckConstraint>();\n \tauto &bound_check = bound_constraint->Cast<BoundCheckConstraint>();\n@@ -112,15 +112,14 @@ unique_ptr<BoundConstraint> BindCheckConstraint(Binder &binder, Constraint &cons\n \tauto &check = constraint.Cast<CheckConstraint>();\n \n \t// Create a copy of the unbound expression because binding can invalidate it.\n-\tauto unbound_expression = check.expression->Copy();\n+\tauto check_copy = check.expression->Copy();\n \n \t// Bind the constraint and reset the original expression.\n-\tbound_check.expression = check_binder.Bind(check.expression);\n-\tcheck.expression = std::move(unbound_expression);\n+\tbound_check.expression = check_binder.Bind(check_copy);\n \treturn std::move(bound_constraint);\n }\n \n-unique_ptr<BoundConstraint> Binder::BindUniqueConstraint(Constraint &constraint, const string &table,\n+unique_ptr<BoundConstraint> Binder::BindUniqueConstraint(const Constraint &constraint, const string &table,\n                                                          const ColumnList &columns) {\n \tauto &unique = constraint.Cast<UniqueConstraint>();\n \n@@ -132,7 +131,6 @@ unique_ptr<BoundConstraint> Binder::BindUniqueConstraint(Constraint &constraint,\n \t// If set, then the UNIQUE constraint is defined on a single column.\n \tif (unique.HasIndex()) {\n \t\tauto &col = columns.GetColumn(unique.GetIndex());\n-\t\tunique.SetColumnName(col.Name());\n \t\tindexes.push_back(col.Physical());\n \t\tindex_set.insert(col.Physical());\n \t\treturn make_uniq<BoundUniqueConstraint>(std::move(indexes), std::move(index_set), unique.IsPrimaryKey());\n@@ -159,7 +157,7 @@ unique_ptr<BoundConstraint> Binder::BindUniqueConstraint(Constraint &constraint,\n \treturn make_uniq<BoundUniqueConstraint>(std::move(indexes), std::move(index_set), unique.IsPrimaryKey());\n }\n \n-unique_ptr<BoundConstraint> BindForeignKey(Constraint &constraint) {\n+unique_ptr<BoundConstraint> BindForeignKey(const Constraint &constraint) {\n \tauto &fk = constraint.Cast<ForeignKeyConstraint>();\n \tD_ASSERT((fk.info.type == ForeignKeyType::FK_TYPE_FOREIGN_KEY_TABLE && !fk.info.pk_keys.empty()) ||\n \t         (fk.info.type == ForeignKeyType::FK_TYPE_PRIMARY_KEY_TABLE && !fk.info.pk_keys.empty()) ||\n@@ -184,7 +182,7 @@ unique_ptr<BoundConstraint> BindForeignKey(Constraint &constraint) {\n \treturn make_uniq<BoundForeignKeyConstraint>(fk.info, std::move(pk_key_set), std::move(fk_key_set));\n }\n \n-unique_ptr<BoundConstraint> Binder::BindConstraint(Constraint &constraint, const string &table,\n+unique_ptr<BoundConstraint> Binder::BindConstraint(const Constraint &constraint, const string &table,\n                                                    const ColumnList &columns) {\n \tswitch (constraint.type) {\n \tcase ConstraintType::CHECK: {\ndiff --git a/src/planner/binder/statement/bind_execute.cpp b/src/planner/binder/statement/bind_execute.cpp\nindex 86799dc9514c..cceb6796cd37 100644\n--- a/src/planner/binder/statement/bind_execute.cpp\n+++ b/src/planner/binder/statement/bind_execute.cpp\n@@ -61,7 +61,18 @@ BoundStatement Binder::Bind(ExecuteStatement &stmt) {\n \t}\n \tunique_ptr<LogicalOperator> rebound_plan;\n \n-\tif (prepared->RequireRebind(context, &bind_values)) {\n+\tRebindQueryInfo rebind = RebindQueryInfo::DO_NOT_REBIND;\n+\tif (prepared->RequireRebind(context, bind_values)) {\n+\t\trebind = RebindQueryInfo::ATTEMPT_TO_REBIND;\n+\t}\n+\tfor (auto &state : context.registered_state->States()) {\n+\t\tBindPreparedStatementCallbackInfo info {*prepared, bind_values};\n+\t\tauto new_rebind = state->OnRebindPreparedStatement(context, info, rebind);\n+\t\tif (new_rebind == RebindQueryInfo::ATTEMPT_TO_REBIND) {\n+\t\t\trebind = RebindQueryInfo::ATTEMPT_TO_REBIND;\n+\t\t}\n+\t}\n+\tif (rebind == RebindQueryInfo::ATTEMPT_TO_REBIND) {\n \t\t// catalog was modified or statement does not have clear types: rebind the statement before running the execute\n \t\tPlanner prepared_planner(context);\n \t\tprepared_planner.parameter_data = bind_values;\ndiff --git a/tools/pythonpkg/src/arrow/arrow_array_stream.cpp b/tools/pythonpkg/src/arrow/arrow_array_stream.cpp\nindex 69cc0a3e87b1..cee4f0b1023d 100644\n--- a/tools/pythonpkg/src/arrow/arrow_array_stream.cpp\n+++ b/tools/pythonpkg/src/arrow/arrow_array_stream.cpp\n@@ -306,6 +306,37 @@ py::object TransformFilterRecursive(TableFilter &filter, vector<string> column_r\n \t\tauto &constant_filter = filter.Cast<ConstantFilter>();\n \t\tauto constant_field = field(py::tuple(py::cast(column_ref)));\n \t\tauto constant_value = GetScalar(constant_filter.constant, timezone_config, type);\n+\n+\t\tbool is_nan = false;\n+\t\tauto &constant = constant_filter.constant;\n+\t\tauto &constant_type = constant.type();\n+\t\tif (constant_type.id() == LogicalTypeId::FLOAT) {\n+\t\t\tis_nan = Value::IsNan(constant.GetValue<float>());\n+\t\t} else if (constant_type.id() == LogicalTypeId::DOUBLE) {\n+\t\t\tis_nan = Value::IsNan(constant.GetValue<double>());\n+\t\t}\n+\n+\t\t// Special handling for NaN comparisons (to explicitly violate IEEE-754)\n+\t\tif (is_nan) {\n+\t\t\tswitch (constant_filter.comparison_type) {\n+\t\t\tcase ExpressionType::COMPARE_EQUAL:\n+\t\t\tcase ExpressionType::COMPARE_GREATERTHANOREQUALTO:\n+\t\t\t\treturn constant_field.attr(\"is_nan\")();\n+\t\t\tcase ExpressionType::COMPARE_LESSTHAN:\n+\t\t\tcase ExpressionType::COMPARE_NOTEQUAL:\n+\t\t\t\treturn constant_field.attr(\"is_nan\")().attr(\"__invert__\")();\n+\t\t\tcase ExpressionType::COMPARE_GREATERTHAN:\n+\t\t\t\t// Nothing is greater than NaN\n+\t\t\t\treturn import_cache.pyarrow.dataset().attr(\"scalar\")(false);\n+\t\t\tcase ExpressionType::COMPARE_LESSTHANOREQUALTO:\n+\t\t\t\t// Everything is less than or equal to NaN\n+\t\t\t\treturn import_cache.pyarrow.dataset().attr(\"scalar\")(true);\n+\t\t\tdefault:\n+\t\t\t\tthrow NotImplementedException(\"Unsupported comparison type (%s) for NaN values\",\n+\t\t\t\t                              EnumUtil::ToString(constant_filter.comparison_type));\n+\t\t\t}\n+\t\t}\n+\n \t\tswitch (constant_filter.comparison_type) {\n \t\tcase ExpressionType::COMPARE_EQUAL:\n \t\t\treturn constant_field.attr(\"__eq__\")(constant_value);\n", "test_patch": "diff --git a/test/sql/catalog/table/test_concurrent_constraints.test_slow b/test/sql/catalog/table/test_concurrent_constraints.test_slow\nnew file mode 100644\nindex 000000000000..be716efe456f\n--- /dev/null\n+++ b/test/sql/catalog/table/test_concurrent_constraints.test_slow\n@@ -0,0 +1,15 @@\n+# name: test/sql/catalog/table/test_concurrent_constraints.test_slow\n+# group: [table]\n+\n+statement ok\n+CREATE TABLE tbl_constraints(pk INT PRIMARY KEY, u INT UNIQUE, s INT CHECK (s > 42), d INT CHECK (d + 1 < 42));\n+\n+\n+concurrentloop threadid 0 100\n+\n+statement ok\n+SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n+      FROM pg_catalog.pg_constraint c\n+      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n+\n+endloop\ndiff --git a/test/sql/index/art/constraints/test_art_upsert_duplicate.test b/test/sql/index/art/constraints/test_art_upsert_duplicate.test\nnew file mode 100644\nindex 000000000000..9cd7161ec307\n--- /dev/null\n+++ b/test/sql/index/art/constraints/test_art_upsert_duplicate.test\n@@ -0,0 +1,28 @@\n+# name: test/sql/index/art/constraints/test_art_upsert_duplicate.test\n+# description: Test an UPSERT with a duplicate in the VALUES list.\n+# group: [constraints]\n+\n+statement ok\n+PRAGMA enable_verification;\n+\n+statement ok\n+CREATE TABLE hero (\n+        name VARCHAR NOT NULL,\n+        secret_name VARCHAR NOT NULL,\n+        age INTEGER,\n+        PRIMARY KEY (name));\n+\n+statement ok\n+CREATE INDEX ix_hero_age ON hero (age);\n+\n+statement ok\n+INSERT INTO hero (name, secret_name, age)\n+VALUES\n+\t('Captain North America', 'Esteban Rogelios', 93),\n+\t('Rusty-Man', 'Tommy Sharp', 48),\n+\t('Tarantula', 'Natalia Roman-on', 32),\n+\t('Spider-Boy', 'Pedro Parqueador', 17),\n+\t('Captain North America', 'Esteban Rogelios', 93)\n+ON CONFLICT (name) DO UPDATE\n+SET\tsecret_name = EXCLUDED.secret_name,\n+\tage = EXCLUDED.age;\n\\ No newline at end of file\ndiff --git a/test/sql/storage/compression/alprd/alprd_tpcds.test_slow b/test/sql/storage/compression/alprd/alprd_tpcds.test_slow\nindex 58a31e21bc39..3007a4927f25 100644\n--- a/test/sql/storage/compression/alprd/alprd_tpcds.test_slow\n+++ b/test/sql/storage/compression/alprd/alprd_tpcds.test_slow\n@@ -656,7 +656,17 @@ PRAGMA tpcds(${i})\n \n endloop\n \n-loop i 50 99\n+# skip tpcds 67 - inconsistent without decimals\n+loop i 50 66\n+\n+query I\n+PRAGMA tpcds(${i})\n+----\n+<FILE>:extension/tpcds/dsdgen/answers/sf1/${i}.csv\n+\n+endloop\n+\n+loop i 68 99\n \n query I\n PRAGMA tpcds(${i})\ndiff --git a/tools/pythonpkg/tests/fast/arrow/test_filter_pushdown.py b/tools/pythonpkg/tests/fast/arrow/test_filter_pushdown.py\nindex 9a8cc743f96d..2d999c5dd584 100644\n--- a/tools/pythonpkg/tests/fast/arrow/test_filter_pushdown.py\n+++ b/tools/pythonpkg/tests/fast/arrow/test_filter_pushdown.py\n@@ -986,3 +986,30 @@ def test_pushdown_of_optional_filter(self, duckdb_cursor):\n             ('product_code', 100),\n             ('price', 100),\n         ]\n+\n+    # DuckDB intentionally violates IEEE-754 when it comes to NaNs, ensuring a total ordering where NaN is the greatest value\n+    def test_nan_filter_pushdown(self, duckdb_cursor):\n+        duckdb_cursor.execute(\n+            \"\"\"\n+            create table test as select a::DOUBLE a from VALUES\n+                ('inf'),\n+                ('nan'),\n+                ('0.34234'),\n+                ('34234234.00005'),\n+                ('-nan')\n+            t(a);\n+        \"\"\"\n+        )\n+\n+        def assert_equal_results(con, arrow_table, query):\n+            duckdb_res = con.sql(query.format(table='test')).fetchall()\n+            arrow_res = con.sql(query.format(table='arrow_table')).fetchall()\n+            assert len(duckdb_res) == len(arrow_res)\n+\n+        arrow_table = duckdb_cursor.table('test').arrow()\n+        assert_equal_results(duckdb_cursor, arrow_table, \"select * from {table} where a > 'NaN'::FLOAT\")\n+        assert_equal_results(duckdb_cursor, arrow_table, \"select * from {table} where a >= 'NaN'::FLOAT\")\n+        assert_equal_results(duckdb_cursor, arrow_table, \"select * from {table} where a < 'NaN'::FLOAT\")\n+        assert_equal_results(duckdb_cursor, arrow_table, \"select * from {table} where a <= 'NaN'::FLOAT\")\n+        assert_equal_results(duckdb_cursor, arrow_table, \"select * from {table} where a = 'NaN'::FLOAT\")\n+        assert_equal_results(duckdb_cursor, arrow_table, \"select * from {table} where a != 'NaN'::FLOAT\")\n", "problem_statement": "Can't filter for NaN in polars replacement scan\n### What happens?\n\nDuckDB fails to filter for nan values in polars dataframe, even though it does display them correctly without filter (and it filters correctly on more complicated queries). The same problem happens with parquets (written in C# using ParquetSharp) but it's much harder to produce a MWE for that.\n\n### To Reproduce\n\n```python\nimport duckdb \nimport polars as pl\nimport numpy as np\ndf = pl.DataFrame({'number': [-np.nan, np.nan]})\nduckdb.query(\"\"\"FROM df\"\"\")\n```\n```\n# correct replacement scan\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 number \u2502\n\u2502 double \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   -nan \u2502\n\u2502    nan \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n```python\nduckdb.query(\"\"\"FROM df WHERE number = 'NaN'::FLOAT\"\"\")\n```\n```\n# incorrect, should show two rows because NaNs compare equal to all other NaNs in DuckDB according to https://duckdb.org/docs/stable/sql/dialect/sql_quirks#nan-values\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 number \u2502\n\u2502 double \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 0 rows \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n```python\nduckdb.query(\"\"\"SELECT DISTINCT * FROM df\"\"\")\n```\n```\n#correct, shows one rows because all nans are equal to each other\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 number \u2502\n\u2502 double \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    nan \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nIn pure DuckDB, `NaN` always compare equal:\n\n```sql\nCREATE OR REPLACE TABLE tbl AS (SELECT -'NaN'::FLOAT AS number UNION ALL SELECT 'NaN'::FLOAT);\nFROM tbl WHERE number = 'NaN'::FLOAT\n```\n```\n# correct\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 number \u2502\n\u2502 float  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   -nan \u2502\n\u2502    nan \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n\n### OS:\n\nLinux\n\n### DuckDB Version:\n\n'1.2.2-dev83'\n\n### DuckDB Client:\n\nPython\n\n### Hardware:\n\n.\n\n### Full Name:\n\nSoeren Wolfers\n\n### Affiliation:\n\nG-Research\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have not tested with any build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNo - Other reason (please specify in the issue body)\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n\"Cannot copy bound expression\" random error\n### What happens?\n\n In the test.ddb database, \n \n ```SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n FROM pg_catalog. pg_constraint c\n INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n```\n \nIf I do this sentence over and over again, I get random errors.\n\nThe test.ddb datafile is available for download below.\nhttps://github.com/goosedb-net/goosedb-download/releases/download/test/test.tgz\n\n\n\n__STAGE__$ cat /etc/os-release \nPRETTY_NAME=\"Ubuntu 24.04.1 LTS\"\nNAME=\"Ubuntu\"\nVERSION_ID=\"24.04\"\nVERSION=\"24.04.1 LTS (Noble Numbat)\"\nVERSION_CODENAME=noble\nID=ubuntu\nID_LIKE=debian\nHOME_URL=\"https://www.ubuntu.com/\"\nSUPPORT_URL=\"https://help.ubuntu.com/\"\nBUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\nPRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\nUBUNTU_CODENAME=noble\nLOGO=ubuntu-logo\n(myenv) [goose@tnt-factory:/tmp/test]\n__STAGE__$ \n\n\n```\n#################################################################################################################################\n# case 1\n#################################################################################################################################\n\n__STAGE__$ duckdb test.ddb \nv1.2.1 8e52ec4395\nEnter \".help\" for usage hints.\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n  FROM pg_catalog.pg_constraint c\n  INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 \u2026 \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                28 columns (13 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n  FROM pg_catalog.pg_constraint c\n  INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 \u2026 \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                28 columns (13 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n  FROM pg_catalog.pg_constraint c\n  INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 \u2026 \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                28 columns (13 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n  FROM pg_catalog.pg_constraint c\n  INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\nSegmentation fault (core dumped)\n(myenv) [goose@tnt-factory:/tmp/test]\n__STAGE__$\n\n\n#################################################################################################################################\n# case 2\n#################################################################################################################################\n\n__STAGE__$ duckdb test.ddb \nv1.2.1 8e52ec4395\nEnter \".help\" for usage hints.\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n    FROM pg_catalog.pg_constraint c\n    INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\nSerialization Error:\nCannot copy bound expression\nD \n\n__STAGE__$ \n\n#################################################################################################################################\n# case 3\n#################################################################################################################################\n\n\n__STAGE__$ duckdb test.ddb \nv1.2.1 8e52ec4395\nEnter \".help\" for usage hints.\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\nSerialization Error:\nCannot copy bound expression\nD \n\n\n#################################################################################################################################\n# case 4\n#################################################################################################################################\n\n__STAGE__$ duckdb test.ddb \nv1.2.1 8e52ec4395\nEnter \".help\" for usage hints.\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n    FROM pg_catalog.pg_constraint c\n    INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 593000003 \u2502 593000003 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 695000007 \u2502 695000007 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 701000011 \u2502 701000011 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 707000015 \u2502 707000015 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u2502 713000016 \u2502 713000016 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_branches  \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n    FROM pg_catalog.pg_constraint c\n    INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\nSerialization Error:\nCannot copy bound expression\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n    FROM pg_catalog.pg_constraint c\n    INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\nSerialization Error:\nCannot copy bound expression\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n    FROM pg_catalog.pg_constraint c\n    INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 593000003 \u2502 593000003 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 695000007 \u2502 695000007 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 701000011 \u2502 701000011 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 707000015 \u2502 707000015 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u2502 713000016 \u2502 713000016 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_branches  \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n    FROM pg_catalog.pg_constraint c\n    INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n```\n\n### To Reproduce\n\nin test.ddb database, \n \n \"SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n FROM pg_catalog. pg_constraint c\n INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\" \n \nIf I do this sentence over and over again, I get random errors.\n\n### OS:\n\nUbuntu 24.04.1 LTS\n\n### DuckDB Version:\n\n1.2.1\n\n### DuckDB Client:\n\ncli\n\n### Hardware:\n\n8core 16gb\n\n### Full Name:\n\nSeongSik\n\n### Affiliation:\n\nOraScope\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n\"Cannot copy bound expression\" random error\n### What happens?\n\n In the test.ddb database, \n \n ```SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n FROM pg_catalog. pg_constraint c\n INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n```\n \nIf I do this sentence over and over again, I get random errors.\n\nThe test.ddb datafile is available for download below.\nhttps://github.com/goosedb-net/goosedb-download/releases/download/test/test.tgz\n\n\n\n__STAGE__$ cat /etc/os-release \nPRETTY_NAME=\"Ubuntu 24.04.1 LTS\"\nNAME=\"Ubuntu\"\nVERSION_ID=\"24.04\"\nVERSION=\"24.04.1 LTS (Noble Numbat)\"\nVERSION_CODENAME=noble\nID=ubuntu\nID_LIKE=debian\nHOME_URL=\"https://www.ubuntu.com/\"\nSUPPORT_URL=\"https://help.ubuntu.com/\"\nBUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\nPRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\nUBUNTU_CODENAME=noble\nLOGO=ubuntu-logo\n(myenv) [goose@tnt-factory:/tmp/test]\n__STAGE__$ \n\n\n```\n#################################################################################################################################\n# case 1\n#################################################################################################################################\n\n__STAGE__$ duckdb test.ddb \nv1.2.1 8e52ec4395\nEnter \".help\" for usage hints.\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n  FROM pg_catalog.pg_constraint c\n  INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 \u2026 \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                28 columns (13 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n  FROM pg_catalog.pg_constraint c\n  INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 \u2026 \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                28 columns (13 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n  FROM pg_catalog.pg_constraint c\n  INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 \u2026 \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                28 columns (13 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n  FROM pg_catalog.pg_constraint c\n  INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\nSegmentation fault (core dumped)\n(myenv) [goose@tnt-factory:/tmp/test]\n__STAGE__$\n\n\n#################################################################################################################################\n# case 2\n#################################################################################################################################\n\n__STAGE__$ duckdb test.ddb \nv1.2.1 8e52ec4395\nEnter \".help\" for usage hints.\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n    FROM pg_catalog.pg_constraint c\n    INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\nSerialization Error:\nCannot copy bound expression\nD \n\n__STAGE__$ \n\n#################################################################################################################################\n# case 3\n#################################################################################################################################\n\n\n__STAGE__$ duckdb test.ddb \nv1.2.1 8e52ec4395\nEnter \".help\" for usage hints.\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\nSerialization Error:\nCannot copy bound expression\nD \n\n\n#################################################################################################################################\n# case 4\n#################################################################################################################################\n\n__STAGE__$ duckdb test.ddb \nv1.2.1 8e52ec4395\nEnter \".help\" for usage hints.\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n    FROM pg_catalog.pg_constraint c\n    INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 593000003 \u2502 593000003 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 695000007 \u2502 695000007 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 701000011 \u2502 701000011 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 707000015 \u2502 707000015 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u2502 713000016 \u2502 713000016 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_branches  \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n    FROM pg_catalog.pg_constraint c\n    INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\nSerialization Error:\nCannot copy bound expression\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n    FROM pg_catalog.pg_constraint c\n    INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\nSerialization Error:\nCannot copy bound expression\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n    FROM pg_catalog.pg_constraint c\n    INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 593000003 \u2502 593000003 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 695000007 \u2502 695000007 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 701000011 \u2502 701000011 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 707000015 \u2502 707000015 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u2502 713000016 \u2502 713000016 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_branches  \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n    FROM pg_catalog.pg_constraint c\n    INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n```\n\n### To Reproduce\n\nin test.ddb database, \n \n \"SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n FROM pg_catalog. pg_constraint c\n INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\" \n \nIf I do this sentence over and over again, I get random errors.\n\n### OS:\n\nUbuntu 24.04.1 LTS\n\n### DuckDB Version:\n\n1.2.1\n\n### DuckDB Client:\n\ncli\n\n### Hardware:\n\n8core 16gb\n\n### Full Name:\n\nSeongSik\n\n### Affiliation:\n\nOraScope\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "\n\n", "created_at": "2025-04-08T12:21:39Z"}
{"repo": "duckdb/duckdb", "pull_number": 17031, "instance_id": "duckdb__duckdb-17031", "issue_numbers": ["17029"], "base_commit": "7455c078f0834d870c3795fa3797ab96ef91ebb5", "patch": "diff --git a/extension/parquet/column_reader.cpp b/extension/parquet/column_reader.cpp\nindex aaa27bbb0879..6118653fcd80 100644\n--- a/extension/parquet/column_reader.cpp\n+++ b/extension/parquet/column_reader.cpp\n@@ -318,12 +318,14 @@ void ColumnReader::PreparePageV2(PageHeader &page_hdr) {\n \n \tauto compressed_bytes = page_hdr.compressed_page_size - uncompressed_bytes;\n \n-\tResizeableBuffer compressed_buffer;\n-\tcompressed_buffer.resize(GetAllocator(), compressed_bytes);\n-\treader.ReadData(*protocol, compressed_buffer.ptr, compressed_bytes);\n+\tif (compressed_bytes > 0) {\n+\t\tResizeableBuffer compressed_buffer;\n+\t\tcompressed_buffer.resize(GetAllocator(), compressed_bytes);\n+\t\treader.ReadData(*protocol, compressed_buffer.ptr, compressed_bytes);\n \n-\tDecompressInternal(chunk->meta_data.codec, compressed_buffer.ptr, compressed_bytes, block->ptr + uncompressed_bytes,\n-\t                   page_hdr.uncompressed_page_size - uncompressed_bytes);\n+\t\tDecompressInternal(chunk->meta_data.codec, compressed_buffer.ptr, compressed_bytes,\n+\t\t                   block->ptr + uncompressed_bytes, page_hdr.uncompressed_page_size - uncompressed_bytes);\n+\t}\n }\n \n void ColumnReader::AllocateBlock(idx_t size) {\n", "test_patch": "diff --git a/data/parquet-testing/compression/empty_datapage_v2.snappy.parquet b/data/parquet-testing/compression/empty_datapage_v2.snappy.parquet\nnew file mode 100644\nindex 000000000000..30d6fa7a687b\nBinary files /dev/null and b/data/parquet-testing/compression/empty_datapage_v2.snappy.parquet differ\ndiff --git a/test/parquet/test_parquet_reader_compression.test b/test/parquet/test_parquet_reader_compression.test\nindex b33f1596608e..dd2d146a5842 100644\n--- a/test/parquet/test_parquet_reader_compression.test\n+++ b/test/parquet/test_parquet_reader_compression.test\n@@ -78,4 +78,9 @@ SELECT * FROM parquet_scan('data/parquet-testing/compression/generated/data_page\n 28\t7\t{'string': foo, 'int': 34}\t[20, 1, 18, 20, 1, 3, 25, 2, 31, 22, NULL, 40, 23, 32, 40, 10]\n 29\t13\t{'string': bar, 'int': 8}\t[40, 32, 9, 2, 2, 40, 7, 0, 32, 31, 11, 14, 4, 14, 40, 20, 29, 17, 41]\n \n+query I\n+SELECT * FROM parquet_scan('data/parquet-testing/compression/empty_datapage_v2.snappy.parquet', hive_partitioning=0) limit 50\n+----\n+NULL\n+\n endloop\n\\ No newline at end of file\n", "problem_statement": "Handle Parquet with compressed empty DataPage v2\n### What happens?\n\nAn empty bytes buffer cannot be decompressed. Spark's Parquet writer stores a DataPage v2 with only `null` values as an empty byte buffer, rather than compressed bytes that decompress to zero bytes.\n\nThe code currently tries to decompress a 0 bytes buffer, which is not allowed. This causes an error:\n\n    Invalid Error: Snappy decompression failure\n\nThe issue is identical to this Apache Arrow issue: https://github.com/apache/arrow/issues/22459\nThe fix is identical to Apache Arrow fix: https://github.com/apache/arrow/pull/45252\n\n### To Reproduce\n\n```bash\n./spark-3.5.5-bin-hadoop3/bin/spark-shell --conf spark.hadoop.parquet.writer.version=\"v2\"\nSpark session available as 'spark'.\nWelcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.5.5\n      /_/\n         \nUsing Scala version 2.12.18 (OpenJDK 64-Bit Server VM, Java 11.0.26)\nType in expressions to have them evaluated.\nType :help for more information.\n\nscala> Seq(Option.empty[Float]).toDS.write.parquet(\"parquet-v2-example.parquet\")\n```\n\nDuckDB:\n```sql\nSELECT * FROM parquet_scan('parquet-v2-example.parquet/*.parquet', hive_partitioning=0) limit 50;\n```\n```\nInvalid Error: Snappy decompression failure\n```\n\n### OS:\n\nUbuntu x86_64\n\n### DuckDB Version:\n\nmain branch (451315955f969523e608e0b883a7fd58ffae0758)\n\n### DuckDB Client:\n\nmake unit\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nEnrico Minack\n\n### Affiliation:\n\nself-employed\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a source build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "", "created_at": "2025-04-08T10:21:40Z"}
{"repo": "duckdb/duckdb", "pull_number": 16971, "instance_id": "duckdb__duckdb-16971", "issue_numbers": ["16959", "16959"], "base_commit": "099fba2a4b5563dd40b5a462fd6fac0594560a4c", "patch": "diff --git a/src/include/duckdb/parser/constraints/unique_constraint.hpp b/src/include/duckdb/parser/constraints/unique_constraint.hpp\nindex a3811160ae66..ded23b0d3bfd 100644\n--- a/src/include/duckdb/parser/constraints/unique_constraint.hpp\n+++ b/src/include/duckdb/parser/constraints/unique_constraint.hpp\n@@ -22,6 +22,7 @@ class UniqueConstraint : public Constraint {\n \n public:\n \tDUCKDB_API UniqueConstraint(const LogicalIndex index, const bool is_primary_key);\n+\tDUCKDB_API UniqueConstraint(const LogicalIndex index, string column_name, const bool is_primary_key);\n \tDUCKDB_API UniqueConstraint(vector<string> columns, const bool is_primary_key);\n \n public:\n@@ -46,8 +47,6 @@ class UniqueConstraint : public Constraint {\n \tvector<LogicalIndex> GetLogicalIndexes(const ColumnList &columns) const;\n \t//! Get the name of the constraint.\n \tstring GetName(const string &table_name) const;\n-\t//! Sets a single column name. Does nothing, if the name is already set.\n-\tvoid SetColumnName(const string &name);\n \n private:\n \tUniqueConstraint();\ndiff --git a/src/include/duckdb/planner/binder.hpp b/src/include/duckdb/planner/binder.hpp\nindex 717d69979383..6a1e8dcc3187 100644\n--- a/src/include/duckdb/planner/binder.hpp\n+++ b/src/include/duckdb/planner/binder.hpp\n@@ -134,8 +134,9 @@ class Binder : public enable_shared_from_this<Binder> {\n \tvector<unique_ptr<BoundConstraint>> BindConstraints(const TableCatalogEntry &table);\n \tvector<unique_ptr<BoundConstraint>> BindNewConstraints(vector<unique_ptr<Constraint>> &constraints,\n \t                                                       const string &table_name, const ColumnList &columns);\n-\tunique_ptr<BoundConstraint> BindConstraint(Constraint &constraint, const string &table, const ColumnList &columns);\n-\tunique_ptr<BoundConstraint> BindUniqueConstraint(Constraint &constraint, const string &table,\n+\tunique_ptr<BoundConstraint> BindConstraint(const Constraint &constraint, const string &table,\n+\t                                           const ColumnList &columns);\n+\tunique_ptr<BoundConstraint> BindUniqueConstraint(const Constraint &constraint, const string &table,\n \t                                                 const ColumnList &columns);\n \n \tBoundStatement BindAlterAddIndex(BoundStatement &result, CatalogEntry &entry, unique_ptr<AlterInfo> alter_info);\ndiff --git a/src/parser/constraints/unique_constraint.cpp b/src/parser/constraints/unique_constraint.cpp\nindex 51c4631b39c6..d3379be42b91 100644\n--- a/src/parser/constraints/unique_constraint.cpp\n+++ b/src/parser/constraints/unique_constraint.cpp\n@@ -10,6 +10,10 @@ UniqueConstraint::UniqueConstraint() : Constraint(ConstraintType::UNIQUE), index\n UniqueConstraint::UniqueConstraint(const LogicalIndex index, const bool is_primary_key)\n     : Constraint(ConstraintType::UNIQUE), index(index), is_primary_key(is_primary_key) {\n }\n+UniqueConstraint::UniqueConstraint(const LogicalIndex index, string column_name_p, const bool is_primary_key)\n+    : UniqueConstraint(index, is_primary_key) {\n+\tcolumns.push_back(std::move(column_name_p));\n+}\n \n UniqueConstraint::UniqueConstraint(vector<string> columns, const bool is_primary_key)\n     : Constraint(ConstraintType::UNIQUE), index(DConstants::INVALID_INDEX), columns(std::move(columns)),\n@@ -32,10 +36,7 @@ unique_ptr<Constraint> UniqueConstraint::Copy() const {\n \t\treturn make_uniq<UniqueConstraint>(columns, is_primary_key);\n \t}\n \n-\tauto result = make_uniq<UniqueConstraint>(index, is_primary_key);\n-\tif (!columns.empty()) {\n-\t\tresult->columns.push_back(columns[0]);\n-\t}\n+\tauto result = make_uniq<UniqueConstraint>(index, columns.empty() ? string() : columns[0], is_primary_key);\n \treturn std::move(result);\n }\n \n@@ -95,11 +96,4 @@ string UniqueConstraint::GetName(const string &table_name) const {\n \treturn type_name + \"_\" + table_name + name;\n }\n \n-void UniqueConstraint::SetColumnName(const string &column_name) {\n-\tif (!columns.empty()) {\n-\t\treturn;\n-\t}\n-\tcolumns.push_back(column_name);\n-}\n-\n } // namespace duckdb\ndiff --git a/src/parser/transform/constraint/transform_constraint.cpp b/src/parser/transform/constraint/transform_constraint.cpp\nindex 8439fc863258..e73b15cdc47a 100644\n--- a/src/parser/transform/constraint/transform_constraint.cpp\n+++ b/src/parser/transform/constraint/transform_constraint.cpp\n@@ -105,9 +105,9 @@ unique_ptr<Constraint> Transformer::TransformConstraint(duckdb_libpgquery::PGCon\n \tcase duckdb_libpgquery::PG_CONSTR_CHECK:\n \t\treturn TransformConstraint(constraint);\n \tcase duckdb_libpgquery::PG_CONSTR_PRIMARY:\n-\t\treturn make_uniq<UniqueConstraint>(LogicalIndex(index), true);\n+\t\treturn make_uniq<UniqueConstraint>(LogicalIndex(index), column.GetName(), true);\n \tcase duckdb_libpgquery::PG_CONSTR_UNIQUE:\n-\t\treturn make_uniq<UniqueConstraint>(LogicalIndex(index), false);\n+\t\treturn make_uniq<UniqueConstraint>(LogicalIndex(index), column.GetName(), false);\n \tcase duckdb_libpgquery::PG_CONSTR_NULL:\n \t\treturn nullptr;\n \tcase duckdb_libpgquery::PG_CONSTR_GENERATED_VIRTUAL: {\ndiff --git a/src/planner/binder/statement/bind_create_table.cpp b/src/planner/binder/statement/bind_create_table.cpp\nindex 15a553b81605..4a6eccf8040e 100644\n--- a/src/planner/binder/statement/bind_create_table.cpp\n+++ b/src/planner/binder/statement/bind_create_table.cpp\n@@ -102,7 +102,7 @@ vector<unique_ptr<BoundConstraint>> Binder::BindNewConstraints(vector<unique_ptr\n \treturn bound_constraints;\n }\n \n-unique_ptr<BoundConstraint> BindCheckConstraint(Binder &binder, Constraint &constraint, const string &table,\n+unique_ptr<BoundConstraint> BindCheckConstraint(Binder &binder, const Constraint &constraint, const string &table,\n                                                 const ColumnList &columns) {\n \tauto bound_constraint = make_uniq<BoundCheckConstraint>();\n \tauto &bound_check = bound_constraint->Cast<BoundCheckConstraint>();\n@@ -112,15 +112,14 @@ unique_ptr<BoundConstraint> BindCheckConstraint(Binder &binder, Constraint &cons\n \tauto &check = constraint.Cast<CheckConstraint>();\n \n \t// Create a copy of the unbound expression because binding can invalidate it.\n-\tauto unbound_expression = check.expression->Copy();\n+\tauto check_copy = check.expression->Copy();\n \n \t// Bind the constraint and reset the original expression.\n-\tbound_check.expression = check_binder.Bind(check.expression);\n-\tcheck.expression = std::move(unbound_expression);\n+\tbound_check.expression = check_binder.Bind(check_copy);\n \treturn std::move(bound_constraint);\n }\n \n-unique_ptr<BoundConstraint> Binder::BindUniqueConstraint(Constraint &constraint, const string &table,\n+unique_ptr<BoundConstraint> Binder::BindUniqueConstraint(const Constraint &constraint, const string &table,\n                                                          const ColumnList &columns) {\n \tauto &unique = constraint.Cast<UniqueConstraint>();\n \n@@ -132,7 +131,6 @@ unique_ptr<BoundConstraint> Binder::BindUniqueConstraint(Constraint &constraint,\n \t// If set, then the UNIQUE constraint is defined on a single column.\n \tif (unique.HasIndex()) {\n \t\tauto &col = columns.GetColumn(unique.GetIndex());\n-\t\tunique.SetColumnName(col.Name());\n \t\tindexes.push_back(col.Physical());\n \t\tindex_set.insert(col.Physical());\n \t\treturn make_uniq<BoundUniqueConstraint>(std::move(indexes), std::move(index_set), unique.IsPrimaryKey());\n@@ -159,7 +157,7 @@ unique_ptr<BoundConstraint> Binder::BindUniqueConstraint(Constraint &constraint,\n \treturn make_uniq<BoundUniqueConstraint>(std::move(indexes), std::move(index_set), unique.IsPrimaryKey());\n }\n \n-unique_ptr<BoundConstraint> BindForeignKey(Constraint &constraint) {\n+unique_ptr<BoundConstraint> BindForeignKey(const Constraint &constraint) {\n \tauto &fk = constraint.Cast<ForeignKeyConstraint>();\n \tD_ASSERT((fk.info.type == ForeignKeyType::FK_TYPE_FOREIGN_KEY_TABLE && !fk.info.pk_keys.empty()) ||\n \t         (fk.info.type == ForeignKeyType::FK_TYPE_PRIMARY_KEY_TABLE && !fk.info.pk_keys.empty()) ||\n@@ -184,7 +182,7 @@ unique_ptr<BoundConstraint> BindForeignKey(Constraint &constraint) {\n \treturn make_uniq<BoundForeignKeyConstraint>(fk.info, std::move(pk_key_set), std::move(fk_key_set));\n }\n \n-unique_ptr<BoundConstraint> Binder::BindConstraint(Constraint &constraint, const string &table,\n+unique_ptr<BoundConstraint> Binder::BindConstraint(const Constraint &constraint, const string &table,\n                                                    const ColumnList &columns) {\n \tswitch (constraint.type) {\n \tcase ConstraintType::CHECK: {\n", "test_patch": "diff --git a/test/sql/catalog/table/test_concurrent_constraints.test_slow b/test/sql/catalog/table/test_concurrent_constraints.test_slow\nnew file mode 100644\nindex 000000000000..be716efe456f\n--- /dev/null\n+++ b/test/sql/catalog/table/test_concurrent_constraints.test_slow\n@@ -0,0 +1,15 @@\n+# name: test/sql/catalog/table/test_concurrent_constraints.test_slow\n+# group: [table]\n+\n+statement ok\n+CREATE TABLE tbl_constraints(pk INT PRIMARY KEY, u INT UNIQUE, s INT CHECK (s > 42), d INT CHECK (d + 1 < 42));\n+\n+\n+concurrentloop threadid 0 100\n+\n+statement ok\n+SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n+      FROM pg_catalog.pg_constraint c\n+      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n+\n+endloop\n", "problem_statement": "\"Cannot copy bound expression\" random error\n### What happens?\n\n In the test.ddb database, \n \n ```SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n FROM pg_catalog. pg_constraint c\n INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n```\n \nIf I do this sentence over and over again, I get random errors.\n\nThe test.ddb datafile is available for download below.\nhttps://github.com/goosedb-net/goosedb-download/releases/download/test/test.tgz\n\n\n\n__STAGE__$ cat /etc/os-release \nPRETTY_NAME=\"Ubuntu 24.04.1 LTS\"\nNAME=\"Ubuntu\"\nVERSION_ID=\"24.04\"\nVERSION=\"24.04.1 LTS (Noble Numbat)\"\nVERSION_CODENAME=noble\nID=ubuntu\nID_LIKE=debian\nHOME_URL=\"https://www.ubuntu.com/\"\nSUPPORT_URL=\"https://help.ubuntu.com/\"\nBUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\nPRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\nUBUNTU_CODENAME=noble\nLOGO=ubuntu-logo\n(myenv) [goose@tnt-factory:/tmp/test]\n__STAGE__$ \n\n\n```\n#################################################################################################################################\n# case 1\n#################################################################################################################################\n\n__STAGE__$ duckdb test.ddb \nv1.2.1 8e52ec4395\nEnter \".help\" for usage hints.\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n  FROM pg_catalog.pg_constraint c\n  INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 \u2026 \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                28 columns (13 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n  FROM pg_catalog.pg_constraint c\n  INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 \u2026 \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                28 columns (13 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n  FROM pg_catalog.pg_constraint c\n  INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 \u2026 \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                28 columns (13 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n  FROM pg_catalog.pg_constraint c\n  INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\nSegmentation fault (core dumped)\n(myenv) [goose@tnt-factory:/tmp/test]\n__STAGE__$\n\n\n#################################################################################################################################\n# case 2\n#################################################################################################################################\n\n__STAGE__$ duckdb test.ddb \nv1.2.1 8e52ec4395\nEnter \".help\" for usage hints.\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n    FROM pg_catalog.pg_constraint c\n    INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\nSerialization Error:\nCannot copy bound expression\nD \n\n__STAGE__$ \n\n#################################################################################################################################\n# case 3\n#################################################################################################################################\n\n\n__STAGE__$ duckdb test.ddb \nv1.2.1 8e52ec4395\nEnter \".help\" for usage hints.\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\nSerialization Error:\nCannot copy bound expression\nD \n\n\n#################################################################################################################################\n# case 4\n#################################################################################################################################\n\n__STAGE__$ duckdb test.ddb \nv1.2.1 8e52ec4395\nEnter \".help\" for usage hints.\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n    FROM pg_catalog.pg_constraint c\n    INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 593000003 \u2502 593000003 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 695000007 \u2502 695000007 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 701000011 \u2502 701000011 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 707000015 \u2502 707000015 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u2502 713000016 \u2502 713000016 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_branches  \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n    FROM pg_catalog.pg_constraint c\n    INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\nSerialization Error:\nCannot copy bound expression\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n    FROM pg_catalog.pg_constraint c\n    INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\nSerialization Error:\nCannot copy bound expression\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n    FROM pg_catalog.pg_constraint c\n    INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 593000003 \u2502 593000003 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 695000007 \u2502 695000007 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 701000011 \u2502 701000011 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 707000015 \u2502 707000015 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u2502 713000016 \u2502 713000016 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_branches  \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n    FROM pg_catalog.pg_constraint c\n    INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n```\n\n### To Reproduce\n\nin test.ddb database, \n \n \"SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n FROM pg_catalog. pg_constraint c\n INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\" \n \nIf I do this sentence over and over again, I get random errors.\n\n### OS:\n\nUbuntu 24.04.1 LTS\n\n### DuckDB Version:\n\n1.2.1\n\n### DuckDB Client:\n\ncli\n\n### Hardware:\n\n8core 16gb\n\n### Full Name:\n\nSeongSik\n\n### Affiliation:\n\nOraScope\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n\"Cannot copy bound expression\" random error\n### What happens?\n\n In the test.ddb database, \n \n ```SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n FROM pg_catalog. pg_constraint c\n INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n```\n \nIf I do this sentence over and over again, I get random errors.\n\nThe test.ddb datafile is available for download below.\nhttps://github.com/goosedb-net/goosedb-download/releases/download/test/test.tgz\n\n\n\n__STAGE__$ cat /etc/os-release \nPRETTY_NAME=\"Ubuntu 24.04.1 LTS\"\nNAME=\"Ubuntu\"\nVERSION_ID=\"24.04\"\nVERSION=\"24.04.1 LTS (Noble Numbat)\"\nVERSION_CODENAME=noble\nID=ubuntu\nID_LIKE=debian\nHOME_URL=\"https://www.ubuntu.com/\"\nSUPPORT_URL=\"https://help.ubuntu.com/\"\nBUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\nPRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\nUBUNTU_CODENAME=noble\nLOGO=ubuntu-logo\n(myenv) [goose@tnt-factory:/tmp/test]\n__STAGE__$ \n\n\n```\n#################################################################################################################################\n# case 1\n#################################################################################################################################\n\n__STAGE__$ duckdb test.ddb \nv1.2.1 8e52ec4395\nEnter \".help\" for usage hints.\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n  FROM pg_catalog.pg_constraint c\n  INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 \u2026 \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                28 columns (13 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n  FROM pg_catalog.pg_constraint c\n  INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 \u2026 \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                28 columns (13 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n  FROM pg_catalog.pg_constraint c\n  INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 \u2026 \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                28 columns (13 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n  FROM pg_catalog.pg_constraint c\n  INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\nSegmentation fault (core dumped)\n(myenv) [goose@tnt-factory:/tmp/test]\n__STAGE__$\n\n\n#################################################################################################################################\n# case 2\n#################################################################################################################################\n\n__STAGE__$ duckdb test.ddb \nv1.2.1 8e52ec4395\nEnter \".help\" for usage hints.\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n    FROM pg_catalog.pg_constraint c\n    INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\nSerialization Error:\nCannot copy bound expression\nD \n\n__STAGE__$ \n\n#################################################################################################################################\n# case 3\n#################################################################################################################################\n\n\n__STAGE__$ duckdb test.ddb \nv1.2.1 8e52ec4395\nEnter \".help\" for usage hints.\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 552000002 \u2502 552000002 \u2502 NOT NULL \u2502          550 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 postgres_type     \u2502 NULL        \u2502\n\u2502 763000006 \u2502 763000006 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 865000010 \u2502 865000010 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 871000014 \u2502 871000014 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 877000018 \u2502 877000018 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n      FROM pg_catalog.pg_constraint c\n      INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\nSerialization Error:\nCannot copy bound expression\nD \n\n\n#################################################################################################################################\n# case 4\n#################################################################################################################################\n\n__STAGE__$ duckdb test.ddb \nv1.2.1 8e52ec4395\nEnter \".help\" for usage hints.\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n    FROM pg_catalog.pg_constraint c\n    INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 593000003 \u2502 593000003 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 695000007 \u2502 695000007 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 701000011 \u2502 701000011 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 707000015 \u2502 707000015 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u2502 713000016 \u2502 713000016 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_branches  \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n    FROM pg_catalog.pg_constraint c\n    INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\nSerialization Error:\nCannot copy bound expression\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n    FROM pg_catalog.pg_constraint c\n    INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\nSerialization Error:\nCannot copy bound expression\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n    FROM pg_catalog.pg_constraint c\n    INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    oid    \u2502    oid    \u2502 conname  \u2502 connamespace \u2502 contype \u2502 condeferrable \u2502 condeferred \u2502 convalidated \u2502 \u2026 \u2502 conpfeqop \u2502 conppeqop \u2502 conffeqop \u2502 conexclop \u2502 conbin  \u2502    tabrelname     \u2502 consrc_copy \u2502\n\u2502   int64   \u2502   int64   \u2502 varchar  \u2502    int64     \u2502 varchar \u2502    boolean    \u2502   boolean   \u2502   boolean    \u2502   \u2502   int32   \u2502   int32   \u2502   int32   \u2502   int32   \u2502 varchar \u2502      varchar      \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 593000003 \u2502 593000003 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 example           \u2502 NULL        \u2502\n\u2502 695000007 \u2502 695000007 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts1 \u2502 NULL        \u2502\n\u2502 701000011 \u2502 701000011 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts2 \u2502 NULL        \u2502\n\u2502 707000015 \u2502 707000015 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_accounts3 \u2502 NULL        \u2502\n\u2502 713000016 \u2502 713000016 \u2502 NOT NULL \u2502          548 \u2502 x       \u2502 false         \u2502 false       \u2502 true         \u2502 \u2026 \u2502      NULL \u2502      NULL \u2502      NULL \u2502      NULL \u2502 NULL    \u2502 pgbench_branches  \u2502 NULL        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 5 rows                                                                                                                                                                           28 columns (15 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nD SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n    FROM pg_catalog.pg_constraint c\n    INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n```\n\n### To Reproduce\n\nin test.ddb database, \n \n \"SELECT c.oid,c.*,t.relname as tabrelname, case when c.contype='c' then substring(pg_get_constraintdef(c.oid), 7) else null end consrc_copy\n FROM pg_catalog. pg_constraint c\n INNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\" \n \nIf I do this sentence over and over again, I get random errors.\n\n### OS:\n\nUbuntu 24.04.1 LTS\n\n### DuckDB Version:\n\n1.2.1\n\n### DuckDB Client:\n\ncli\n\n### Hardware:\n\n8core 16gb\n\n### Full Name:\n\nSeongSik\n\n### Affiliation:\n\nOraScope\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "```\n############################################################################################################\n# Not Reproduced\n############################################################################################################\nFROM pg_catalog.pg_constraint c\nINNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\n############################################################################################################\n# Reproduced\n############################################################################################################\nSELECT pg_get_constraintdef(c.oid)\nFROM pg_catalog.pg_constraint c\nINNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\n```\n```\n############################################################################################################\n# Not Reproduced\n############################################################################################################\nFROM pg_catalog.pg_constraint c\nINNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\n############################################################################################################\n# Reproduced\n############################################################################################################\nSELECT pg_get_constraintdef(c.oid)\nFROM pg_catalog.pg_constraint c\nINNER JOIN pg_catalog.pg_class t ON t.oid=c.conrelid limit 5;\n\n```", "created_at": "2025-04-03T11:26:26Z"}
{"repo": "duckdb/duckdb", "pull_number": 16952, "instance_id": "duckdb__duckdb-16952", "issue_numbers": ["16942"], "base_commit": "1329f339b23287373d7bd9bb49ab44c61de0d3bd", "patch": "diff --git a/tools/pythonpkg/src/arrow/arrow_array_stream.cpp b/tools/pythonpkg/src/arrow/arrow_array_stream.cpp\nindex 2b13ddfc2451..3fbb9420e9ef 100644\n--- a/tools/pythonpkg/src/arrow/arrow_array_stream.cpp\n+++ b/tools/pythonpkg/src/arrow/arrow_array_stream.cpp\n@@ -302,6 +302,37 @@ py::object TransformFilterRecursive(TableFilter &filter, vector<string> column_r\n \t\tauto &constant_filter = filter.Cast<ConstantFilter>();\n \t\tauto constant_field = field(py::tuple(py::cast(column_ref)));\n \t\tauto constant_value = GetScalar(constant_filter.constant, timezone_config, type);\n+\n+\t\tbool is_nan = false;\n+\t\tauto &constant = constant_filter.constant;\n+\t\tauto &constant_type = constant.type();\n+\t\tif (constant_type.id() == LogicalTypeId::FLOAT) {\n+\t\t\tis_nan = Value::IsNan(constant.GetValue<float>());\n+\t\t} else if (constant_type.id() == LogicalTypeId::DOUBLE) {\n+\t\t\tis_nan = Value::IsNan(constant.GetValue<double>());\n+\t\t}\n+\n+\t\t// Special handling for NaN comparisons (to explicitly violate IEEE-754)\n+\t\tif (is_nan) {\n+\t\t\tswitch (constant_filter.comparison_type) {\n+\t\t\tcase ExpressionType::COMPARE_EQUAL:\n+\t\t\tcase ExpressionType::COMPARE_GREATERTHANOREQUALTO:\n+\t\t\t\treturn constant_field.attr(\"is_nan\")();\n+\t\t\tcase ExpressionType::COMPARE_LESSTHAN:\n+\t\t\tcase ExpressionType::COMPARE_NOTEQUAL:\n+\t\t\t\treturn constant_field.attr(\"is_nan\")().attr(\"__invert__\")();\n+\t\t\tcase ExpressionType::COMPARE_GREATERTHAN:\n+\t\t\t\t// Nothing is greater than NaN\n+\t\t\t\treturn import_cache.pyarrow.dataset().attr(\"scalar\")(false);\n+\t\t\tcase ExpressionType::COMPARE_LESSTHANOREQUALTO:\n+\t\t\t\t// Everything is less than or equal to NaN\n+\t\t\t\treturn import_cache.pyarrow.dataset().attr(\"scalar\")(true);\n+\t\t\tdefault:\n+\t\t\t\tthrow NotImplementedException(\"Unsupported comparison type (%s) for NaN values\",\n+\t\t\t\t                              EnumUtil::ToString(constant_filter.comparison_type));\n+\t\t\t}\n+\t\t}\n+\n \t\tswitch (constant_filter.comparison_type) {\n \t\tcase ExpressionType::COMPARE_EQUAL:\n \t\t\treturn constant_field.attr(\"__eq__\")(constant_value);\n", "test_patch": "diff --git a/tools/pythonpkg/tests/fast/arrow/test_filter_pushdown.py b/tools/pythonpkg/tests/fast/arrow/test_filter_pushdown.py\nindex 142d1dace103..82cb4414b8f6 100644\n--- a/tools/pythonpkg/tests/fast/arrow/test_filter_pushdown.py\n+++ b/tools/pythonpkg/tests/fast/arrow/test_filter_pushdown.py\n@@ -986,3 +986,30 @@ def test_pushdown_of_optional_filter(self, duckdb_cursor):\n             ('product_code', 100),\n             ('price', 100),\n         ]\n+\n+    # DuckDB intentionally violates IEEE-754 when it comes to NaNs, ensuring a total ordering where NaN is the greatest value\n+    def test_nan_filter_pushdown(self, duckdb_cursor):\n+        duckdb_cursor.execute(\n+            \"\"\"\n+            create table test as select a::DOUBLE a from VALUES\n+                ('inf'),\n+                ('nan'),\n+                ('0.34234'),\n+                ('34234234.00005'),\n+                ('-nan')\n+            t(a);\n+        \"\"\"\n+        )\n+\n+        def assert_equal_results(con, arrow_table, query):\n+            duckdb_res = con.sql(query.format(table='test')).fetchall()\n+            arrow_res = con.sql(query.format(table='arrow_table')).fetchall()\n+            assert len(duckdb_res) == len(arrow_res)\n+\n+        arrow_table = duckdb_cursor.table('test').arrow()\n+        assert_equal_results(duckdb_cursor, arrow_table, \"select * from {table} where a > 'NaN'::FLOAT\")\n+        assert_equal_results(duckdb_cursor, arrow_table, \"select * from {table} where a >= 'NaN'::FLOAT\")\n+        assert_equal_results(duckdb_cursor, arrow_table, \"select * from {table} where a < 'NaN'::FLOAT\")\n+        assert_equal_results(duckdb_cursor, arrow_table, \"select * from {table} where a <= 'NaN'::FLOAT\")\n+        assert_equal_results(duckdb_cursor, arrow_table, \"select * from {table} where a = 'NaN'::FLOAT\")\n+        assert_equal_results(duckdb_cursor, arrow_table, \"select * from {table} where a != 'NaN'::FLOAT\")\n", "problem_statement": "Can't filter for NaN in polars replacement scan\n### What happens?\n\nDuckDB fails to filter for nan values in polars dataframe, even though it does display them correctly without filter (and it filters correctly on more complicated queries). The same problem happens with parquets (written in C# using ParquetSharp) but it's much harder to produce a MWE for that.\n\n### To Reproduce\n\n```python\nimport duckdb \nimport polars as pl\nimport numpy as np\ndf = pl.DataFrame({'number': [-np.nan, np.nan]})\nduckdb.query(\"\"\"FROM df\"\"\")\n```\n```\n# correct replacement scan\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 number \u2502\n\u2502 double \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   -nan \u2502\n\u2502    nan \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n```python\nduckdb.query(\"\"\"FROM df WHERE number = 'NaN'::FLOAT\"\"\")\n```\n```\n# incorrect, should show two rows because NaNs compare equal to all other NaNs in DuckDB according to https://duckdb.org/docs/stable/sql/dialect/sql_quirks#nan-values\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 number \u2502\n\u2502 double \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 0 rows \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n```python\nduckdb.query(\"\"\"SELECT DISTINCT * FROM df\"\"\")\n```\n```\n#correct, shows one rows because all nans are equal to each other\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 number \u2502\n\u2502 double \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    nan \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nIn pure DuckDB, `NaN` always compare equal:\n\n```sql\nCREATE OR REPLACE TABLE tbl AS (SELECT -'NaN'::FLOAT AS number UNION ALL SELECT 'NaN'::FLOAT);\nFROM tbl WHERE number = 'NaN'::FLOAT\n```\n```\n# correct\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 number \u2502\n\u2502 float  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   -nan \u2502\n\u2502    nan \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n\n### OS:\n\nLinux\n\n### DuckDB Version:\n\n'1.2.2-dev83'\n\n### DuckDB Client:\n\nPython\n\n### Hardware:\n\n.\n\n### Full Name:\n\nSoeren Wolfers\n\n### Affiliation:\n\nG-Research\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have not tested with any build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNo - Other reason (please specify in the issue body)\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "Sounds like you're running into [this](https://duckdb.org/docs/stable/sql/dialect/sql_quirks#nan-values) ?\n\nFor example:\n```sql\nduckdb.query(\"\"\"FROM df WHERE isnan(number)\"\"\").show()\n```\n\ndoes work.\n@Tishj No, that link says that `NaN`s should always compare equal in DuckDB. I also edited the OP to show that that's the case in pure DuckDB.\nThanks, I missed that \ud83d\udc4d \n\nFigured out the issue, it's the pyarrow filter pushdown, see:\n```py\nimport duckdb \nimport polars as pl\nimport numpy as np\ndf = pl.DataFrame({'number': [-np.nan, np.nan]})\n\n# From capsule\npl_capsule = df.__arrow_c_stream__()\nduckdb.sql(\"select * from pl_capsule where number = 'NaN'::FLOAT\").show()\n\n# From Arrow\npl_arrow = df.to_arrow()\nduckdb.sql(\"select * from pl_arrow where number = 'NaN'::FLOAT\").show()\n```\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 number \u2502\n\u2502 double \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   -nan \u2502\n\u2502    nan \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 number \u2502\n\u2502 double \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 0 rows \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nWhen we scan from a pycapsule we intentionally dont push down filters using pyarrow, so that's why the result *is* correct when we fetch the capsule and scan that\nDo you also know how this could affect parquet reads? That's where I initially ran into this. \nThe issue in Parquet is most likely related to Parquet statistics not containing whether or not there are NaN values - which leads to the optimizer stripping comparisons against NaN values or pruning row groups that might contain NaN values - see e.g. https://github.com/duckdb/duckdb/issues/7803. We've seen that issue reported in the past but haven't fixed it yet.", "created_at": "2025-04-02T10:20:35Z"}
{"repo": "duckdb/duckdb", "pull_number": 16939, "instance_id": "duckdb__duckdb-16939", "issue_numbers": ["16836", "16836"], "base_commit": "7d4736c40b03686d3f30bf10c594ba4c8f3f9ee0", "patch": "diff --git a/.github/workflows/LinuxRelease.yml b/.github/workflows/LinuxRelease.yml\nindex b11dbe916d0d..06525d024dee 100644\n--- a/.github/workflows/LinuxRelease.yml\n+++ b/.github/workflows/LinuxRelease.yml\n@@ -107,6 +107,7 @@ jobs:\n         path: |\n           libduckdb-linux-${{ matrix.config.arch }}.zip\n           duckdb_cli-linux-${{ matrix.config.arch }}.zip\n+          duckdb_cli-linux-${{ matrix.config.arch }}.gz\n \n     - name: Test\n       shell: bash\ndiff --git a/.github/workflows/Python.yml b/.github/workflows/Python.yml\nindex 1deedc3babe1..0326d2c94ad7 100644\n--- a/.github/workflows/Python.yml\n+++ b/.github/workflows/Python.yml\n@@ -59,7 +59,7 @@ concurrency:\n env:\n   GH_TOKEN: ${{ secrets.GH_TOKEN }}\n   OVERRIDE_GIT_DESCRIBE: ${{ inputs.override_git_describe }}\n-  CIBW_TEST_SKIP: ${{ inputs.skip_tests == 'true' && '*-*' || 'cp37-*' }}\n+  CIBW_TEST_SKIP: ${{ inputs.skip_tests == 'true' && '*-*' || '{cp37,cp38}-*' }}\n \n jobs:\n # This is just a sanity check of Python 3.10 running with Arrow\n@@ -126,6 +126,7 @@ jobs:\n   manylinux-extensions-x64:\n     name: Linux Extensions (linux_amd64_gcc4)\n     needs: linux-python3-10\n+    if: false\n     runs-on: ubuntu-latest\n     strategy:\n       matrix:\n@@ -160,6 +161,7 @@ jobs:\n \n   upload-linux-extensions-gcc4:\n     name: Upload Linux Extensions (gcc4)\n+    if: false\n     needs: manylinux-extensions-x64\n     strategy:\n       matrix:\n@@ -173,7 +175,8 @@ jobs:\n \n   linux-python3:\n     name: Python 3 Linux\n-    needs: manylinux-extensions-x64\n+    # needs: manylinux-extensions-x64\n+    needs: linux-python3-10\n     runs-on: ubuntu-22.04\n     strategy:\n       fail-fast: false\n@@ -248,7 +251,8 @@ jobs:\n         python -m pip install numpy --config-settings=setup-args=\"-Dallow-noblas=true\"\n \n     - uses: actions/download-artifact@v4\n-      if: ${{ matrix.arch == 'x86_64' }}\n+      if: false\n+      # if: ${{ matrix.arch == 'x86_64' }}\n       with:\n         name: duckdb-extensions-${{ matrix.duckdb_arch }}\n         path: tools/pythonpkg\ndiff --git a/CMakeLists.txt b/CMakeLists.txt\nindex d45687cf7313..fcb3e0f81e51 100644\n--- a/CMakeLists.txt\n+++ b/CMakeLists.txt\n@@ -945,7 +945,8 @@ function(build_loadable_extension_directory NAME ABI_TYPE OUTPUT_DIRECTORY EXTEN\n   if(EMSCRIPTEN)\n     # Compile the library into the actual wasm file\n     string(TOUPPER ${NAME} EXTENSION_NAME_UPPERCASE)\n-    string(REPLACE \";\" \" \" TO_BE_LINKED \"${DUCKDB_EXTENSION_${EXTENSION_NAME_UPPERCASE}_LINKED_LIBS}\")\n+    set(TO_BE_LINKED ${DUCKDB_EXTENSION_${EXTENSION_NAME_UPPERCASE}_LINKED_LIBS} )\n+    separate_arguments(TO_BE_LINKED)\n     if (${ABI_TYPE} STREQUAL \"CPP\")\n       set(EXPORTED_FUNCTIONS \"_${NAME}_init,_${NAME}_version\")\n     elseif (${ABI_TYPE} STREQUAL \"C_STRUCT\" OR ${ABI_TYPE} STREQUAL \"C_STRUCT_UNSTABLE\")\ndiff --git a/data/csv/16857.csv b/data/csv/16857.csv\nnew file mode 100644\nindex 000000000000..4a74efc186ac\n--- /dev/null\n+++ b/data/csv/16857.csv\n@@ -0,0 +1,211 @@\n+intCol,tinyIntCol,smallIntCol,bigIntCol,doubleCol,doubleCol,decimalCol,,stringCol!@#$%^&*(),timeStampCol,binaryCol,arrayCol,mapCol,structCol,varCharCol,charCol,dateCol,Right_RowID,INT_with_scientific_notation,singlechar,singlechar_with_singlequotes,singlechar_with_doublequotes,emojis,arabic_column,french_chars,\r\n+,null,-15906,5035218741361664,1292.412231445,5799.643102009,5292.029,false,!@#$%^&*(),1990-08-05 15:20:03,ukuclnqrqmzfoawrawqyrxhucmiskw==,\"[3697,4006,8856,2643,8157,3966,3652,9256,6544,218,6844]\",\"{\"\"key1\"\":\"\"NMkbDREYfH\"\",\"\"key2\"\":\"\"hd7X3zO3Pk\"\",\"\"key3\"\":\"\"Z9ZIyZs59c\"\",\"\"key4\"\":\"\"SZzGskMufb\"\"}\",\"{\"\"id\"\":\"\"sjrod\"\",\"\"val1\"\":\"\"qdlhr\"\",\"\"val2\"\":\"\"dvegw\"\"}\",iumixtiqivrwyrw,kycsmrupwf,1986-11-25 00:00:00,19,,q,'q',\"\"\"q\"\"\",\u2705,\u0644\u0628\u0649,M\u00c8RE ,\u05e8\u05d7\u05dc\u05d9\u05dd\r\n+-955939840,13,28595,4458733335951872,8748.717773438,1547.018290286,2994.118,false,ommetzkgoe,1970-04-26 07:48:00,ayrbgvzejhwqfsczxcrygqcedbqetw==,,\"{\"\"key1\"\":\"\"ze4uTLJCIS\"\",\"\"key2\"\":\"\"KJvGWmVD4k\"\",\"\"key3\"\":\"\"EAj5tjtJIY\"\",\"\"key4\"\":\"\"sGZyLdFZTL\"\"}\",\"{\"\"id\"\":\"\"zavzf\"\",\"\"val1\"\":\"\"cvpte\"\",\"\"val2\"\":\"\"wpihw\"\"}\",waoexcjeezmxrsi,scnzxnuxan,1985-04-11 00:00:00,4,-4123000000000,r,'r',\"\"\"r\"\"\",\ud83c\udf8a,\u0645\u0646\u0632\u0644\u0647,M\u00c8RE ,\u05de\u05d2\u05d3\u05dc\u05d9\u05dd\r\n+-946041088,20,4028,6488644051956704,2068.969238281,6867.608431199,2096.338,false,aftxkrhbse,1995-07-21 00:19:48,okvcbxnhykbxgmodzdwgybzwioikng==,[606],\"{\"\"key1\"\":\"\"lh6d4g6AdX\"\",\"\"key2\"\":\"\"m7NXz1Drky\"\",\"\"key3\"\":\"\"PE0h2QSxpA\"\",\"\"key4\"\":\"\"6R2Esbvp9X\"\"}\",\"{\"\"id\"\":\"\"uegms\"\",\"\"val1\"\":\"\"grjhb\"\",\"\"val2\"\":\"\"wzptz\"\"}\",ukampuhnwymbxok,pwumbaiqhj,1980-08-31 00:00:00,5,-4123000000000,s,'s',\"\"\"s\"\"\",\u2b07\ufe0f,\u0645\u0627\u062a\u062c\u064a\u0646\u064a,M\u00c8RE ,\u05d7\u05d5\u05de\u05e9\r\n+190064639,85,-16861,745854179121920,3006.978027344,5300.161841,590.341,false,pwpphjeqey,1971-11-03 14:46:40,csdhfkmtpzkznemtvmumlbcetlgfqg==,\"[4828,2281]\",\"{\"\"key1\"\":\"\"381OAMa9cm\"\",\"\"key2\"\":\"\"kVqFCSMW5N\"\",\"\"key3\"\":\"\"SORmXvLRX2\"\",\"\"key4\"\":\"\"yjMtCtXnrM\"\"}\",\"{\"\"id\"\":\"\"bqodb\"\",\"\"val1\"\":\"\"mnxzv\"\",\"\"val2\"\":\"\"uebln\"\"}\",qumqyheavhhvwkc,lbidykbvuz,1977-12-01 00:00:00,10,-7.4423e-12,s,'s',\"\"\"s\"\"\",\u26a0\ufe0f,\u0648\u0648\u0642\u0641,DE NO\u00cbL ,\u05e2\u05e0\u05d1\r\n+-1355749376,28,-6594,6217661610739712,1575.131469727,4710.247816849,719.935,false,wkrxvnrrmw,1977-04-11 02:09:53,qiutbarcseuaqboaojdlihgwvwiqwQ==,\"[7066,6223,9555,9906,8967,4096,2286,9385,4793,2865,57,7801,1261,5671,8650,8967,7999,7792,2867]\",\"{\"\"key1\"\":\"\"HlwjPoYNOZ\"\",\"\"key2\"\":\"\"hnbly8aGKW\"\",\"\"key3\"\":\"\"2nSgdIRftI\"\",\"\"key4\"\":\"\"8sxcVvxtbj\"\"}\",\"{\"\"id\"\":\"\"hwuon\"\",\"\"val1\"\":\"\"wuuon\"\",\"\"val2\"\":\"\"icggg\"\"}\",gmmgstuttnbjxpy,vhdgledyvc,1994-10-13 00:00:00,2,-1.2345678e+22,m,'m',\"\"\"m\"\"\",\u2764\ufe0f,\u062f\u0639\u0648\u062a\u0647,EN D\u00c9CEMBRE,\u05e0\u05d2\u05d5\u05d4\u05d5\u05ea\r\n+623428607,52,-12058,1099140924791552,1668.521118164,7082.408967932,3390.096,false,dyspcsmwhq,1979-11-10 12:56:35,eydynjfcrsmjwwcjyqtcwskjmaulyg==,\"[1826,8833,371,2946,1848,661,3918,7866,3517,9457,3681]\",\"{\"\"key1\"\":\"\"BahZ52XrL1\"\",\"\"key2\"\":\"\"ZP6eRPsIEd\"\",\"\"key3\"\":\"\"VBMjjPITQw\"\",\"\"key4\"\":\"\"1rSnwpb9sq\"\"}\",\"{\"\"id\"\":\"\"bfggr\"\",\"\"val1\"\":\"\"nxflc\"\",\"\"val2\"\":\"\"elsjm\"\"}\",gqouiupeqligvhn,ykwavphlbv,2002-01-11 00:00:00,13,4.94065e-32,d,'d',\"\"\"d\"\"\",\ud83d\udfe8, \u062e\u0627\u0635\u0629,M\u00c8RE ,\u05d4\u05e8 \u05d1\u05e8\u05db\u05d4 \u05d1\u05e8\u05db\u05d4\r\n+340231167,-103,32314,6727076822845952,490.876434326,521.782040839,689.131,false,ynbspwxszn,2006-09-11 04:44:46,yybegwugseeyfyyzzxssndxpceskbg==,\"[7387,5827,3530,5417,2764,3977,7112,6065,2894,6651,9171,6785,5125]\",\"{\"\"key1\"\":\"\"SL6KOlo6yS\"\",\"\"key2\"\":\"\"6hwmQ2uKSH\"\",\"\"key3\"\":\"\"ECjxaAa7Su\"\",\"\"key4\"\":\"\"OY8xWw8ut0\"\"}\",\"{\"\"id\"\":\"\"avewu\"\",\"\"val1\"\":\"\"rttto\"\",\"\"val2\"\":\"\"mndbq\"\"}\",gmknpbmxtkuyfvw,rzxfoedloj,1999-07-03 00:00:00,12,-7.4423e-12,a,'a',\"\"\"a\"\"\",\ud83d\udcdd,\u0627\u0644\u0637\u0644\u0627\u0642 ,EN D\u00c9CEMBRE,\u05d7\u05e8\u05de\u05e9\r\n+59571531,-120,2726,499568922236435,5693.273925781,831.917259298,5970.561,false,srcyitzady,1976-01-17 22:33:07,uomxckzjwvhrhuqvxvjmntzosoyudQ==,\"[1663,9022,6558]\",\"{\"\"key1\"\":\"\"GqtZfwU56W\"\",\"\"key2\"\":\"\"hjDJcwofzW\"\",\"\"key3\"\":\"\"wAS2lqzSh0\"\",\"\"key4\"\":\"\"ieeRmIe0pZ\"\"}\",\"{\"\"id\"\":\"\"jmsyp\"\",\"\"val1\"\":\"\"tjrjc\"\",\"\"val2\"\":\"\"fwuue\"\"}\",ekatpkqdtbrdopr,vsusznjtum,2002-01-30 00:00:00,9,-0.00445124654,g,'g',\"\"\"g\"\"\",\ud83d\udd37,\u0635\u062f\u064a\u0642\u0647,FRAN\u00c7AISE ,\u05e7\u05d3\u05d9\u05dd\r\n+955388927,36,-14711,234259271632640,5292.765136719,821.385383988,8358.519,true,krzqufbilr,2012-10-22 05:07:34,owkzlgegaqgzpbomgtgdmmqaigfmog==,\"[4974,9911,5595,6472,7765,1797,1908,1014,5229]\",\"{\"\"key1\"\":\"\"xydc0YQBBL\"\",\"\"key2\"\":\"\"8tW4c8Gm4M\"\",\"\"key3\"\":\"\"aGblhlIIrx\"\",\"\"key4\"\":\"\"v30H3CJPMy\"\"}\",\"{\"\"id\"\":\"\"eqoya\"\",\"\"val1\"\":\"\"ypims\"\",\"\"val2\"\":\"\"blsod\"\"}\",sumfztrbmpwkjon,bypzxafltm,2013-06-15 00:00:00,14,7.4423e-12,j,'j',\"\"\"j\"\"\",\ud83c\udd97, \u0639\u0644\u064a ,DE NO\u00cbL ,\u05e9\u05d1\u05d9 \u05e9\u05d5\u05de\u05e8\u05d5\u05df\r\n+1838367743,-76,7387,2747089955464832,8975.13671875,704.915821881,272.055,true,ouxvftfobi,1971-06-30 18:49:15,acidfzuquvceiuuzqqvnljpljdcnzg==,\"[9936,6185,781,912,2509,4330]\",\"{\"\"key1\"\":\"\"94j6CTgyit\"\",\"\"key2\"\":\"\"smHeSsm3fX\"\",\"\"key3\"\":\"\"PD7ADcq9JW\"\",\"\"key4\"\":\"\"eqjA1uBW3e\"\"}\",\"{\"\"id\"\":\"\"gmimc\"\",\"\"val1\"\":\"\"oyksy\"\",\"\"val2\"\":\"\"bavue\"\"}\",aowrnboisicvkex,rucsmrzxvu,2011-09-01 00:00:00,18,1.79769e+308,w,'w',\"\"\"w\"\"\",\u274c,\u0635\u062f\u064a\u0642\u0647,FRAN\u00c7AISE ,\u05e1\u05e0\u05e1\u05e0\u05d4\r\n+-703343616,19,7048,1887435007823552,3118.254150391,3798.277379851,1502.739,true,hwhwhwafby,2008-03-06 02:00:46,wwcjyqtcwskjmaulygxoqwfedjiyrg==,\"[4259,717,7166,7868,1323,4157,6358,6232,2556,9900,3363,6799,60,5880,7990,4743,8200,5670,6079]\",\"{\"\"key1\"\":\"\"XIVSXvg33a\"\",\"\"key2\"\":\"\"2HsXhn6Ee2\"\",\"\"key3\"\":\"\"03o5vQeeLf\"\",\"\"key4\"\":\"\"GzX7WcQrRx\"\"}\",\"{\"\"id\"\":\"\"hryfw\"\",\"\"val1\"\":\"\"wkcgw\"\",\"\"val2\"\":\"\"sjmns\"\"}\",yyshjqkviglwvhz,uclwpzskje,1983-03-28 00:00:00,6,-179623157,t,'t',\"\"\"t\"\"\",\u2757\ufe0f,\u0648\u0648\u0642\u0641,DE NO\u00cbL ,\u05ea\u05dc\u05dd\r\n+1671645295,-54,12191,8891823575776256,4349.600097656,5313.086512179,9153.266,false,htxiqenedt,1999-03-30 20:05:28,iskynmcvdrnpbysmtjkcguptilqefw==,,\"{\"\"key1\"\":\"\"3badsBTnEu\"\",\"\"key2\"\":\"\"w2t7fCA5if\"\",\"\"key3\"\":\"\"jiavckw8PW\"\",\"\"key4\"\":\"\"21LcTl7GEk\"\"}\",\"{\"\"id\"\":\"\"wpica\"\",\"\"val1\"\":\"\"wptoy\"\",\"\"val2\"\":\"\"iryuo\"\"}\",oeshqwtudywyksw,qenziyaaqm,2003-03-16 00:00:00,16,1.2345678e+22,e,'e',\"\"\"e\"\"\",\u270f\ufe0f,\u062f\u0639\u0648\u062a\u0647,CUISINE LE D\u00ceNER ,\u05d9\u05e6\u05d4\u05e8\r\n+-1684013568,118,-24306,7313791764174080,287.703582764,3151.620627917,6181.187,true,nohqcyneqj,1970-11-10 05:03:07,ccdehmtplyzrksyweivpvhyvmlywyQ==,\"[5533,9469,8400,1236,26,9435]\",\"{\"\"key1\"\":\"\"vyMNJLBCZ8\"\",\"\"key2\"\":\"\"Jh7CiBItY8\"\",\"\"key3\"\":\"\"bESrtP2bb7\"\",\"\"key4\"\":\"\"wTaLbfFDcs\"\"}\",\"{\"\"id\"\":\"\"bavjh\"\",\"\"val1\"\":\"\"pnnih\"\",\"\"val2\"\":\"\"vjrjh\"\"}\",igizjxvkxfvbfca,zdvpuszdnh,2013-03-24 00:00:00,1,-1.2345678e+22,s,'s',\"\"\"s\"\"\",\ud83d\ude21,\u0647\u062f\u064a\u0629,EN D\u00c9CEMBRE,\u05d0\u05d1\u05e0\u05d9 \u05d7\u05e4\u05e5\r\n+12284927,50,-23596,3090497741838080,7133.937988281,1689.871550393,361.979,false,nucvnzflzq,1982-03-01 14:38:42,mohmdorwphgpbeydynjfcrsmjwwcjw==,\"[4116,3479,1659,585,1774,9875,6875,2468,9124,3381,2819,7152,8430,9381,3429,3882,5494]\",\"{\"\"key1\"\":\"\"fYMgi49MuZ\"\",\"\"key2\"\":\"\"tEZ0xIaoWn\"\",\"\"key3\"\":\"\"jLyevsUqXL\"\",\"\"key4\"\":\"\"EcbkujjhB0\"\"}\",\"{\"\"id\"\":\"\"kstoy\"\",\"\"val1\"\":\"\"mndgw\"\",\"\"val2\"\":\"\"elnir\"\"}\",yiezdlzhndhzkum,wfomgoetsc,2001-01-11 00:00:00,8,-179.763157,a,'a',\"\"\"a\"\"\",\ud83d\ude00,\u0633\u064a\u0647\u062f\u064a\u0647 ,DE NO\u00cbL ,\u05e9\u05d0-\u05e0\u05d5\u05e8\r\n+1462738431,-14,6340,634171097409536,1516.799316406,5888.129773498,9240.135,false,kypzqcadqz,2000-03-16 18:38:10,qwalydjzhtcfqbssmydjzuycysoccw==,\"[7760,604,4336,4251]\",\"{\"\"key1\"\":\"\"LPd7EsQfFI\"\",\"\"key2\"\":\"\"Z3oIisw6Ai\"\",\"\"key3\"\":\"\"vRPV7oKuhy\"\",\"\"key4\"\":\"\"wh0uRNvY8Z\"\"}\",\"{\"\"id\"\":\"\"fgbqy\"\",\"\"val1\"\":\"\"dvebf\"\",\"\"val2\"\":\"\"aqdbf\"\"}\",ceqzycmpezypklu,zxcqjyiqhy,2001-04-30 00:00:00,15,123.45678,g,'g',\"\"\"g\"\"\",\ud83d\ude0a, \u0642\u0627\u0626\u0644\u0627\u064b,CUISINE LE D\u00ceNER ,\u05d0\u05d9\u05ea\u05de\u05e8\r\n+2032854015,124,-6867,2971557475748552,7684.747070313,2829.404176599,7425.072,true,ynuxibyskr,1971-10-01 22:22:22,omgtgdmmqaigfmohmdorwphgpbeydw==,\"[4041,7619,1172,9022,2349,2213,5804,1965,4390,4060,2752]\",\"{\"\"key1\"\":\"\"ZIrea4F10F\"\",\"\"key2\"\":\"\"xCQ6E60w71\"\",\"\"key3\"\":\"\"S7sa9dvHDG\"\",\"\"key4\"\":\"\"oOp7CL6LhN\"\"}\",\"{\"\"id\"\":\"\"xuoiw\"\",\"\"val1\"\":\"\"jroyf\"\",\"\"val2\"\":\"\"ihmni\"\"}\",eiwcmxrrdqllsyr,pcddgowuzv,1997-05-31 00:00:00,20,-4.940656,t,'t',\"\"\"t\"\"\",\ud83c\udf40,\u0648\u0623\u0639\u0644\u0646 ,FRAN\u00c7AISE ,\u05de\u05d1\u05d5\u05d0 \u05d3\u05d5\u05ea\u05df\r\n+1805124607,91,6447,2525964422257088,8623.229492188,8118.9394035,8176.205,false,ruszqcqjwp,1976-11-24 00:31:34,ukmdhvhsbxvjpbowkzlgegaqgzpbog==,\"[5599,972,9379,351,4476,8111,5519,5949,4540,848,1050,5422,767,7645,4393,8164,4643,3916,3250]\",\"{\"\"key1\"\":\"\"dU3uIQ8NM1\"\",\"\"key2\"\":\"\"v482CaKybl\"\",\"\"key3\"\":\"\"uabKB3zls9\"\",\"\"key4\"\":\"\"5KzVA5ivwz\"\"}\",\"{\"\"id\"\":\"\"ttzkh\"\",\"\"val1\"\":\"\"kcavj\"\",\"\"val2\"\":\"\"wkclh\"\"}\",agyrupinwbeztta,lwhbibqmws,1978-03-31 00:00:00,17,1.7976e+30,d,'d',\"\"\"d\"\"\",\ud83c\udf89,  \u0641\u0631\u0641\u0636\u0647\u0627,FRAN\u00c7AISE ,\u05db\u05e4\u05e8 \u05ea\u05e4\u05d5\u05d7\r\n+-1057157632,-77,-17825,6684227018091776,3754.662353516,1227.72216854,7412.237,true,iwaigqusuc,1996-12-26 01:28:37,ccxpeexihihokaudhmuplzphtfccdQ==,\"[9781,9643]\",\"{\"\"key1\"\":\"\"PjgjuUKVC4\"\",\"\"key2\"\":\"\"9nGNkoyTfb\"\",\"\"key3\"\":\"\"UcWQ9Yk3ff\"\",\"\"key4\"\":\"\"ZOG77yFk4S\"\"}\",\"{\"\"id\"\":\"\"sosyf\"\",\"\"val1\"\":\"\"ujhrt\"\",\"\"val2\"\":\"\"rjxza\"\"}\",kqwyafcfaclzfgg,jtscynuscn,1975-06-02 00:00:00,3,-17976157000000,y,'y',\"\"\"y\"\"\",\ud83d\udcd5,\u0623\u0646\u0647 ,CUISINE LE D\u00ceNER ,\u05d0\u05dc\u05d5\u05df \u05de\u05d5\u05e8\u05d4\r\n+268149759,25,26299,863534107491584,4555.274414063,779.365301495,2038.987,false,kycfdgtzsu,1997-06-29 02:57:33,ywycfpatthdxjswjtizeahtpojyybQ==,\"[7165,780,4823,5610,8150,9640,2670,4954,3538]\",\"{\"\"key1\"\":\"\"qegPrwEXxt\"\",\"\"key2\"\":\"\"AZhgaO5l7R\"\",\"\"key3\"\":\"\"TjQeE1T5r4\"\",\"\"key4\"\":\"\"7iMEn717cy\"\"}\",\"{\"\"id\"\":\"\"gwpdl\"\",\"\"val1\"\":\"\"niwzf\"\",\"\"val2\"\":\"\"lnica\"\"}\",ucatyvfobyjejgq,wxfbvcvspp,1972-02-21 00:00:00,11,-7.4423e-12,w,'w',\"\"\"w\"\"\",\ud83c\udf4e,\u0623\u0645\u0627\u0645 ,EN D\u00c9CEMBRE,\u05d2\u05e0\u05d9\u05dd\r\n+-669752208,-47,-15665,4986790849161728,3570.342041016,7889.261249401,3128.891,true,wnhbaiojlo,1972-06-13 22:37:55,qetzsvpouvqqhgelfbzdzqymgficdQ==,\"[8466,6224,483,2088,8626]\",\"{\"\"key1\"\":\"\"DHI5hSpnD8\"\",\"\"key2\"\":\"\"ZX1CFWZaEe\"\",\"\"key3\"\":\"\"4TkLHzJLoN\"\",\"\"key4\"\":\"\"xYjtvEEQ7o\"\"}\",\"{\"\"id\"\":\"\"zakhb\"\",\"\"val1\"\":\"\"welnn\"\",\"\"val2\"\":\"\"xzkms\"\"}\",ygoubokubqbesfz,ppphdtzkbs,1990-04-11 00:00:00,7,-1797.23157,d,'d',\"\"\"d\"\"\",\u23fa,\u062f\u0639\u0648\u062a\u0647,CUISINE LE D\u00ceNER ,\u05d1\u05d9\u05ea \u05d7\u05d2\u05d9 \u05d7\u05d2\u05d9\r\n+null,null,,,,,,,,,,,\"\"\"\"\"\",,,,,,,,,,,,,\r\n+,null,-15906,5035218741361664,1292.412231445,5799.643102009,5292.029,false,!@#$%^&*(),1990-08-05 15:20:03,ukuclnqrqmzfoawrawqyrxhucmiskw==,\"[3697,4006,8856,2643,8157,3966,3652,9256,6544,218,6844]\",\"{\"\"key1\"\":\"\"NMkbDREYfH\"\",\"\"key2\"\":\"\"hd7X3zO3Pk\"\",\"\"key3\"\":\"\"Z9ZIyZs59c\"\",\"\"key4\"\":\"\"SZzGskMufb\"\"}\",\"{\"\"id\"\":\"\"sjrod\"\",\"\"val1\"\":\"\"qdlhr\"\",\"\"val2\"\":\"\"dvegw\"\"}\",iumixtiqivrwyrw,kycsmrupwf,1986-11-25 00:00:00,19,,q,'q',\"\"\"q\"\"\",\u2705,\u0644\u0628\u0649,M\u00c8RE ,\u05e8\u05d7\u05dc\u05d9\u05dd\r\n+-955939840,13,28595,4458733335951872,8748.717773438,1547.018290286,2994.118,false,ommetzkgoe,1970-04-26 07:48:00,ayrbgvzejhwqfsczxcrygqcedbqetw==,,\"{\"\"key1\"\":\"\"ze4uTLJCIS\"\",\"\"key2\"\":\"\"KJvGWmVD4k\"\",\"\"key3\"\":\"\"EAj5tjtJIY\"\",\"\"key4\"\":\"\"sGZyLdFZTL\"\"}\",\"{\"\"id\"\":\"\"zavzf\"\",\"\"val1\"\":\"\"cvpte\"\",\"\"val2\"\":\"\"wpihw\"\"}\",waoexcjeezmxrsi,scnzxnuxan,1985-04-11 00:00:00,4,-4123000000000,r,'r',\"\"\"r\"\"\",\ud83c\udf8a,\u0645\u0646\u0632\u0644\u0647,M\u00c8RE ,\u05de\u05d2\u05d3\u05dc\u05d9\u05dd\r\n+-946041088,20,4028,6488644051956704,2068.969238281,6867.608431199,2096.338,false,aftxkrhbse,1995-07-21 00:19:48,okvcbxnhykbxgmodzdwgybzwioikng==,[606],\"{\"\"key1\"\":\"\"lh6d4g6AdX\"\",\"\"key2\"\":\"\"m7NXz1Drky\"\",\"\"key3\"\":\"\"PE0h2QSxpA\"\",\"\"key4\"\":\"\"6R2Esbvp9X\"\"}\",\"{\"\"id\"\":\"\"uegms\"\",\"\"val1\"\":\"\"grjhb\"\",\"\"val2\"\":\"\"wzptz\"\"}\",ukampuhnwymbxok,pwumbaiqhj,1980-08-31 00:00:00,5,-4123000000000,s,'s',\"\"\"s\"\"\",\u2b07\ufe0f,\u0645\u0627\u062a\u062c\u064a\u0646\u064a,M\u00c8RE ,\u05d7\u05d5\u05de\u05e9\r\n+190064639,85,-16861,745854179121920,3006.978027344,5300.161841,590.341,false,pwpphjeqey,1971-11-03 14:46:40,csdhfkmtpzkznemtvmumlbcetlgfqg==,\"[4828,2281]\",\"{\"\"key1\"\":\"\"381OAMa9cm\"\",\"\"key2\"\":\"\"kVqFCSMW5N\"\",\"\"key3\"\":\"\"SORmXvLRX2\"\",\"\"key4\"\":\"\"yjMtCtXnrM\"\"}\",\"{\"\"id\"\":\"\"bqodb\"\",\"\"val1\"\":\"\"mnxzv\"\",\"\"val2\"\":\"\"uebln\"\"}\",qumqyheavhhvwkc,lbidykbvuz,1977-12-01 00:00:00,10,-7.4423e-12,s,'s',\"\"\"s\"\"\",\u26a0\ufe0f,\u0648\u0648\u0642\u0641,DE NO\u00cbL ,\u05e2\u05e0\u05d1\r\n+-1355749376,28,-6594,6217661610739712,1575.131469727,4710.247816849,719.935,false,wkrxvnrrmw,1977-04-11 02:09:53,qiutbarcseuaqboaojdlihgwvwiqwQ==,\"[7066,6223,9555,9906,8967,4096,2286,9385,4793,2865,57,7801,1261,5671,8650,8967,7999,7792,2867]\",\"{\"\"key1\"\":\"\"HlwjPoYNOZ\"\",\"\"key2\"\":\"\"hnbly8aGKW\"\",\"\"key3\"\":\"\"2nSgdIRftI\"\",\"\"key4\"\":\"\"8sxcVvxtbj\"\"}\",\"{\"\"id\"\":\"\"hwuon\"\",\"\"val1\"\":\"\"wuuon\"\",\"\"val2\"\":\"\"icggg\"\"}\",gmmgstuttnbjxpy,vhdgledyvc,1994-10-13 00:00:00,2,-1.2345678e+22,m,'m',\"\"\"m\"\"\",\u2764\ufe0f,\u062f\u0639\u0648\u062a\u0647,EN D\u00c9CEMBRE,\u05e0\u05d2\u05d5\u05d4\u05d5\u05ea\r\n+623428607,52,-12058,1099140924791552,1668.521118164,7082.408967932,3390.096,false,dyspcsmwhq,1979-11-10 12:56:35,eydynjfcrsmjwwcjyqtcwskjmaulyg==,\"[1826,8833,371,2946,1848,661,3918,7866,3517,9457,3681]\",\"{\"\"key1\"\":\"\"BahZ52XrL1\"\",\"\"key2\"\":\"\"ZP6eRPsIEd\"\",\"\"key3\"\":\"\"VBMjjPITQw\"\",\"\"key4\"\":\"\"1rSnwpb9sq\"\"}\",\"{\"\"id\"\":\"\"bfggr\"\",\"\"val1\"\":\"\"nxflc\"\",\"\"val2\"\":\"\"elsjm\"\"}\",gqouiupeqligvhn,ykwavphlbv,2002-01-11 00:00:00,13,4.94065e-32,d,'d',\"\"\"d\"\"\",\ud83d\udfe8, \u062e\u0627\u0635\u0629,M\u00c8RE ,\u05d4\u05e8 \u05d1\u05e8\u05db\u05d4 \u05d1\u05e8\u05db\u05d4\r\n+340231167,-103,32314,6727076822845952,490.876434326,521.782040839,689.131,false,ynbspwxszn,2006-09-11 04:44:46,yybegwugseeyfyyzzxssndxpceskbg==,\"[7387,5827,3530,5417,2764,3977,7112,6065,2894,6651,9171,6785,5125]\",\"{\"\"key1\"\":\"\"SL6KOlo6yS\"\",\"\"key2\"\":\"\"6hwmQ2uKSH\"\",\"\"key3\"\":\"\"ECjxaAa7Su\"\",\"\"key4\"\":\"\"OY8xWw8ut0\"\"}\",\"{\"\"id\"\":\"\"avewu\"\",\"\"val1\"\":\"\"rttto\"\",\"\"val2\"\":\"\"mndbq\"\"}\",gmknpbmxtkuyfvw,rzxfoedloj,1999-07-03 00:00:00,12,-7.4423e-12,a,'a',\"\"\"a\"\"\",\ud83d\udcdd,\u0627\u0644\u0637\u0644\u0627\u0642 ,EN D\u00c9CEMBRE,\u05d7\u05e8\u05de\u05e9\r\n+59571531,-120,2726,499568922236435,5693.273925781,831.917259298,5970.561,false,srcyitzady,1976-01-17 22:33:07,uomxckzjwvhrhuqvxvjmntzosoyudQ==,\"[1663,9022,6558]\",\"{\"\"key1\"\":\"\"GqtZfwU56W\"\",\"\"key2\"\":\"\"hjDJcwofzW\"\",\"\"key3\"\":\"\"wAS2lqzSh0\"\",\"\"key4\"\":\"\"ieeRmIe0pZ\"\"}\",\"{\"\"id\"\":\"\"jmsyp\"\",\"\"val1\"\":\"\"tjrjc\"\",\"\"val2\"\":\"\"fwuue\"\"}\",ekatpkqdtbrdopr,vsusznjtum,2002-01-30 00:00:00,9,-0.00445124654,g,'g',\"\"\"g\"\"\",\ud83d\udd37,\u0635\u062f\u064a\u0642\u0647,FRAN\u00c7AISE ,\u05e7\u05d3\u05d9\u05dd\r\n+955388927,36,-14711,234259271632640,5292.765136719,821.385383988,8358.519,true,krzqufbilr,2012-10-22 05:07:34,owkzlgegaqgzpbomgtgdmmqaigfmog==,\"[4974,9911,5595,6472,7765,1797,1908,1014,5229]\",\"{\"\"key1\"\":\"\"xydc0YQBBL\"\",\"\"key2\"\":\"\"8tW4c8Gm4M\"\",\"\"key3\"\":\"\"aGblhlIIrx\"\",\"\"key4\"\":\"\"v30H3CJPMy\"\"}\",\"{\"\"id\"\":\"\"eqoya\"\",\"\"val1\"\":\"\"ypims\"\",\"\"val2\"\":\"\"blsod\"\"}\",sumfztrbmpwkjon,bypzxafltm,2013-06-15 00:00:00,14,7.4423e-12,j,'j',\"\"\"j\"\"\",\ud83c\udd97, \u0639\u0644\u064a ,DE NO\u00cbL ,\u05e9\u05d1\u05d9 \u05e9\u05d5\u05de\u05e8\u05d5\u05df\r\n+1838367743,-76,7387,2747089955464832,8975.13671875,704.915821881,272.055,true,ouxvftfobi,1971-06-30 18:49:15,acidfzuquvceiuuzqqvnljpljdcnzg==,\"[9936,6185,781,912,2509,4330]\",\"{\"\"key1\"\":\"\"94j6CTgyit\"\",\"\"key2\"\":\"\"smHeSsm3fX\"\",\"\"key3\"\":\"\"PD7ADcq9JW\"\",\"\"key4\"\":\"\"eqjA1uBW3e\"\"}\",\"{\"\"id\"\":\"\"gmimc\"\",\"\"val1\"\":\"\"oyksy\"\",\"\"val2\"\":\"\"bavue\"\"}\",aowrnboisicvkex,rucsmrzxvu,2011-09-01 00:00:00,18,1.79769e+308,w,'w',\"\"\"w\"\"\",\u274c,\u0635\u062f\u064a\u0642\u0647,FRAN\u00c7AISE ,\u05e1\u05e0\u05e1\u05e0\u05d4\r\n+-703343616,19,7048,1887435007823552,3118.254150391,3798.277379851,1502.739,true,hwhwhwafby,2008-03-06 02:00:46,wwcjyqtcwskjmaulygxoqwfedjiyrg==,\"[4259,717,7166,7868,1323,4157,6358,6232,2556,9900,3363,6799,60,5880,7990,4743,8200,5670,6079]\",\"{\"\"key1\"\":\"\"XIVSXvg33a\"\",\"\"key2\"\":\"\"2HsXhn6Ee2\"\",\"\"key3\"\":\"\"03o5vQeeLf\"\",\"\"key4\"\":\"\"GzX7WcQrRx\"\"}\",\"{\"\"id\"\":\"\"hryfw\"\",\"\"val1\"\":\"\"wkcgw\"\",\"\"val2\"\":\"\"sjmns\"\"}\",yyshjqkviglwvhz,uclwpzskje,1983-03-28 00:00:00,6,-179623157,t,'t',\"\"\"t\"\"\",\u2757\ufe0f,\u0648\u0648\u0642\u0641,DE NO\u00cbL ,\u05ea\u05dc\u05dd\r\n+1671645295,-54,12191,8891823575776256,4349.600097656,5313.086512179,9153.266,false,htxiqenedt,1999-03-30 20:05:28,iskynmcvdrnpbysmtjkcguptilqefw==,,\"{\"\"key1\"\":\"\"3badsBTnEu\"\",\"\"key2\"\":\"\"w2t7fCA5if\"\",\"\"key3\"\":\"\"jiavckw8PW\"\",\"\"key4\"\":\"\"21LcTl7GEk\"\"}\",\"{\"\"id\"\":\"\"wpica\"\",\"\"val1\"\":\"\"wptoy\"\",\"\"val2\"\":\"\"iryuo\"\"}\",oeshqwtudywyksw,qenziyaaqm,2003-03-16 00:00:00,16,1.2345678e+22,e,'e',\"\"\"e\"\"\",\u270f\ufe0f,\u062f\u0639\u0648\u062a\u0647,CUISINE LE D\u00ceNER ,\u05d9\u05e6\u05d4\u05e8\r\n+-1684013568,118,-24306,7313791764174080,287.703582764,3151.620627917,6181.187,true,nohqcyneqj,1970-11-10 05:03:07,ccdehmtplyzrksyweivpvhyvmlywyQ==,\"[5533,9469,8400,1236,26,9435]\",\"{\"\"key1\"\":\"\"vyMNJLBCZ8\"\",\"\"key2\"\":\"\"Jh7CiBItY8\"\",\"\"key3\"\":\"\"bESrtP2bb7\"\",\"\"key4\"\":\"\"wTaLbfFDcs\"\"}\",\"{\"\"id\"\":\"\"bavjh\"\",\"\"val1\"\":\"\"pnnih\"\",\"\"val2\"\":\"\"vjrjh\"\"}\",igizjxvkxfvbfca,zdvpuszdnh,2013-03-24 00:00:00,1,-1.2345678e+22,s,'s',\"\"\"s\"\"\",\ud83d\ude21,\u0647\u062f\u064a\u0629,EN D\u00c9CEMBRE,\u05d0\u05d1\u05e0\u05d9 \u05d7\u05e4\u05e5\r\n+12284927,50,-23596,3090497741838080,7133.937988281,1689.871550393,361.979,false,nucvnzflzq,1982-03-01 14:38:42,mohmdorwphgpbeydynjfcrsmjwwcjw==,\"[4116,3479,1659,585,1774,9875,6875,2468,9124,3381,2819,7152,8430,9381,3429,3882,5494]\",\"{\"\"key1\"\":\"\"fYMgi49MuZ\"\",\"\"key2\"\":\"\"tEZ0xIaoWn\"\",\"\"key3\"\":\"\"jLyevsUqXL\"\",\"\"key4\"\":\"\"EcbkujjhB0\"\"}\",\"{\"\"id\"\":\"\"kstoy\"\",\"\"val1\"\":\"\"mndgw\"\",\"\"val2\"\":\"\"elnir\"\"}\",yiezdlzhndhzkum,wfomgoetsc,2001-01-11 00:00:00,8,-179.763157,a,'a',\"\"\"a\"\"\",\ud83d\ude00,\u0633\u064a\u0647\u062f\u064a\u0647 ,DE NO\u00cbL ,\u05e9\u05d0-\u05e0\u05d5\u05e8\r\n+1462738431,-14,6340,634171097409536,1516.799316406,5888.129773498,9240.135,false,kypzqcadqz,2000-03-16 18:38:10,qwalydjzhtcfqbssmydjzuycysoccw==,\"[7760,604,4336,4251]\",\"{\"\"key1\"\":\"\"LPd7EsQfFI\"\",\"\"key2\"\":\"\"Z3oIisw6Ai\"\",\"\"key3\"\":\"\"vRPV7oKuhy\"\",\"\"key4\"\":\"\"wh0uRNvY8Z\"\"}\",\"{\"\"id\"\":\"\"fgbqy\"\",\"\"val1\"\":\"\"dvebf\"\",\"\"val2\"\":\"\"aqdbf\"\"}\",ceqzycmpezypklu,zxcqjyiqhy,2001-04-30 00:00:00,15,123.45678,g,'g',\"\"\"g\"\"\",\ud83d\ude0a, \u0642\u0627\u0626\u0644\u0627\u064b,CUISINE LE D\u00ceNER ,\u05d0\u05d9\u05ea\u05de\u05e8\r\n+2032854015,124,-6867,2971557475748552,7684.747070313,2829.404176599,7425.072,true,ynuxibyskr,1971-10-01 22:22:22,omgtgdmmqaigfmohmdorwphgpbeydw==,\"[4041,7619,1172,9022,2349,2213,5804,1965,4390,4060,2752]\",\"{\"\"key1\"\":\"\"ZIrea4F10F\"\",\"\"key2\"\":\"\"xCQ6E60w71\"\",\"\"key3\"\":\"\"S7sa9dvHDG\"\",\"\"key4\"\":\"\"oOp7CL6LhN\"\"}\",\"{\"\"id\"\":\"\"xuoiw\"\",\"\"val1\"\":\"\"jroyf\"\",\"\"val2\"\":\"\"ihmni\"\"}\",eiwcmxrrdqllsyr,pcddgowuzv,1997-05-31 00:00:00,20,-4.940656,t,'t',\"\"\"t\"\"\",\ud83c\udf40,\u0648\u0623\u0639\u0644\u0646 ,FRAN\u00c7AISE ,\u05de\u05d1\u05d5\u05d0 \u05d3\u05d5\u05ea\u05df\r\n+1805124607,91,6447,2525964422257088,8623.229492188,8118.9394035,8176.205,false,ruszqcqjwp,1976-11-24 00:31:34,ukmdhvhsbxvjpbowkzlgegaqgzpbog==,\"[5599,972,9379,351,4476,8111,5519,5949,4540,848,1050,5422,767,7645,4393,8164,4643,3916,3250]\",\"{\"\"key1\"\":\"\"dU3uIQ8NM1\"\",\"\"key2\"\":\"\"v482CaKybl\"\",\"\"key3\"\":\"\"uabKB3zls9\"\",\"\"key4\"\":\"\"5KzVA5ivwz\"\"}\",\"{\"\"id\"\":\"\"ttzkh\"\",\"\"val1\"\":\"\"kcavj\"\",\"\"val2\"\":\"\"wkclh\"\"}\",agyrupinwbeztta,lwhbibqmws,1978-03-31 00:00:00,17,1.7976e+30,d,'d',\"\"\"d\"\"\",\ud83c\udf89,  \u0641\u0631\u0641\u0636\u0647\u0627,FRAN\u00c7AISE ,\u05db\u05e4\u05e8 \u05ea\u05e4\u05d5\u05d7\r\n+-1057157632,-77,-17825,6684227018091776,3754.662353516,1227.72216854,7412.237,true,iwaigqusuc,1996-12-26 01:28:37,ccxpeexihihokaudhmuplzphtfccdQ==,\"[9781,9643]\",\"{\"\"key1\"\":\"\"PjgjuUKVC4\"\",\"\"key2\"\":\"\"9nGNkoyTfb\"\",\"\"key3\"\":\"\"UcWQ9Yk3ff\"\",\"\"key4\"\":\"\"ZOG77yFk4S\"\"}\",\"{\"\"id\"\":\"\"sosyf\"\",\"\"val1\"\":\"\"ujhrt\"\",\"\"val2\"\":\"\"rjxza\"\"}\",kqwyafcfaclzfgg,jtscynuscn,1975-06-02 00:00:00,3,-17976157000000,y,'y',\"\"\"y\"\"\",\ud83d\udcd5,\u0623\u0646\u0647 ,CUISINE LE D\u00ceNER ,\u05d0\u05dc\u05d5\u05df \u05de\u05d5\u05e8\u05d4\r\n+268149759,25,26299,863534107491584,4555.274414063,779.365301495,2038.987,false,kycfdgtzsu,1997-06-29 02:57:33,ywycfpatthdxjswjtizeahtpojyybQ==,\"[7165,780,4823,5610,8150,9640,2670,4954,3538]\",\"{\"\"key1\"\":\"\"qegPrwEXxt\"\",\"\"key2\"\":\"\"AZhgaO5l7R\"\",\"\"key3\"\":\"\"TjQeE1T5r4\"\",\"\"key4\"\":\"\"7iMEn717cy\"\"}\",\"{\"\"id\"\":\"\"gwpdl\"\",\"\"val1\"\":\"\"niwzf\"\",\"\"val2\"\":\"\"lnica\"\"}\",ucatyvfobyjejgq,wxfbvcvspp,1972-02-21 00:00:00,11,-7.4423e-12,w,'w',\"\"\"w\"\"\",\ud83c\udf4e,\u0623\u0645\u0627\u0645 ,EN D\u00c9CEMBRE,\u05d2\u05e0\u05d9\u05dd\r\n+-669752208,-47,-15665,4986790849161728,3570.342041016,7889.261249401,3128.891,true,wnhbaiojlo,1972-06-13 22:37:55,qetzsvpouvqqhgelfbzdzqymgficdQ==,\"[8466,6224,483,2088,8626]\",\"{\"\"key1\"\":\"\"DHI5hSpnD8\"\",\"\"key2\"\":\"\"ZX1CFWZaEe\"\",\"\"key3\"\":\"\"4TkLHzJLoN\"\",\"\"key4\"\":\"\"xYjtvEEQ7o\"\"}\",\"{\"\"id\"\":\"\"zakhb\"\",\"\"val1\"\":\"\"welnn\"\",\"\"val2\"\":\"\"xzkms\"\"}\",ygoubokubqbesfz,ppphdtzkbs,1990-04-11 00:00:00,7,-1797.23157,d,'d',\"\"\"d\"\"\",\u23fa,\u062f\u0639\u0648\u062a\u0647,CUISINE LE D\u00ceNER ,\u05d1\u05d9\u05ea \u05d7\u05d2\u05d9 \u05d7\u05d2\u05d9\r\n+null,null,,,,,,,,,,,\"\"\"\"\"\",,,,,,,,,,,,,\r\n+,null,-15906,5035218741361664,1292.412231445,5799.643102009,5292.029,false,!@#$%^&*(),1990-08-05 15:20:03,ukuclnqrqmzfoawrawqyrxhucmiskw==,\"[3697,4006,8856,2643,8157,3966,3652,9256,6544,218,6844]\",\"{\"\"key1\"\":\"\"NMkbDREYfH\"\",\"\"key2\"\":\"\"hd7X3zO3Pk\"\",\"\"key3\"\":\"\"Z9ZIyZs59c\"\",\"\"key4\"\":\"\"SZzGskMufb\"\"}\",\"{\"\"id\"\":\"\"sjrod\"\",\"\"val1\"\":\"\"qdlhr\"\",\"\"val2\"\":\"\"dvegw\"\"}\",iumixtiqivrwyrw,kycsmrupwf,1986-11-25 00:00:00,19,,q,'q',\"\"\"q\"\"\",\u2705,\u0644\u0628\u0649,M\u00c8RE ,\u05e8\u05d7\u05dc\u05d9\u05dd\r\n+-955939840,13,28595,4458733335951872,8748.717773438,1547.018290286,2994.118,false,ommetzkgoe,1970-04-26 07:48:00,ayrbgvzejhwqfsczxcrygqcedbqetw==,,\"{\"\"key1\"\":\"\"ze4uTLJCIS\"\",\"\"key2\"\":\"\"KJvGWmVD4k\"\",\"\"key3\"\":\"\"EAj5tjtJIY\"\",\"\"key4\"\":\"\"sGZyLdFZTL\"\"}\",\"{\"\"id\"\":\"\"zavzf\"\",\"\"val1\"\":\"\"cvpte\"\",\"\"val2\"\":\"\"wpihw\"\"}\",waoexcjeezmxrsi,scnzxnuxan,1985-04-11 00:00:00,4,-4123000000000,r,'r',\"\"\"r\"\"\",\ud83c\udf8a,\u0645\u0646\u0632\u0644\u0647,M\u00c8RE ,\u05de\u05d2\u05d3\u05dc\u05d9\u05dd\r\n+-946041088,20,4028,6488644051956704,2068.969238281,6867.608431199,2096.338,false,aftxkrhbse,1995-07-21 00:19:48,okvcbxnhykbxgmodzdwgybzwioikng==,[606],\"{\"\"key1\"\":\"\"lh6d4g6AdX\"\",\"\"key2\"\":\"\"m7NXz1Drky\"\",\"\"key3\"\":\"\"PE0h2QSxpA\"\",\"\"key4\"\":\"\"6R2Esbvp9X\"\"}\",\"{\"\"id\"\":\"\"uegms\"\",\"\"val1\"\":\"\"grjhb\"\",\"\"val2\"\":\"\"wzptz\"\"}\",ukampuhnwymbxok,pwumbaiqhj,1980-08-31 00:00:00,5,-4123000000000,s,'s',\"\"\"s\"\"\",\u2b07\ufe0f,\u0645\u0627\u062a\u062c\u064a\u0646\u064a,M\u00c8RE ,\u05d7\u05d5\u05de\u05e9\r\n+190064639,85,-16861,745854179121920,3006.978027344,5300.161841,590.341,false,pwpphjeqey,1971-11-03 14:46:40,csdhfkmtpzkznemtvmumlbcetlgfqg==,\"[4828,2281]\",\"{\"\"key1\"\":\"\"381OAMa9cm\"\",\"\"key2\"\":\"\"kVqFCSMW5N\"\",\"\"key3\"\":\"\"SORmXvLRX2\"\",\"\"key4\"\":\"\"yjMtCtXnrM\"\"}\",\"{\"\"id\"\":\"\"bqodb\"\",\"\"val1\"\":\"\"mnxzv\"\",\"\"val2\"\":\"\"uebln\"\"}\",qumqyheavhhvwkc,lbidykbvuz,1977-12-01 00:00:00,10,-7.4423e-12,s,'s',\"\"\"s\"\"\",\u26a0\ufe0f,\u0648\u0648\u0642\u0641,DE NO\u00cbL ,\u05e2\u05e0\u05d1\r\n+-1355749376,28,-6594,6217661610739712,1575.131469727,4710.247816849,719.935,false,wkrxvnrrmw,1977-04-11 02:09:53,qiutbarcseuaqboaojdlihgwvwiqwQ==,\"[7066,6223,9555,9906,8967,4096,2286,9385,4793,2865,57,7801,1261,5671,8650,8967,7999,7792,2867]\",\"{\"\"key1\"\":\"\"HlwjPoYNOZ\"\",\"\"key2\"\":\"\"hnbly8aGKW\"\",\"\"key3\"\":\"\"2nSgdIRftI\"\",\"\"key4\"\":\"\"8sxcVvxtbj\"\"}\",\"{\"\"id\"\":\"\"hwuon\"\",\"\"val1\"\":\"\"wuuon\"\",\"\"val2\"\":\"\"icggg\"\"}\",gmmgstuttnbjxpy,vhdgledyvc,1994-10-13 00:00:00,2,-1.2345678e+22,m,'m',\"\"\"m\"\"\",\u2764\ufe0f,\u062f\u0639\u0648\u062a\u0647,EN D\u00c9CEMBRE,\u05e0\u05d2\u05d5\u05d4\u05d5\u05ea\r\n+623428607,52,-12058,1099140924791552,1668.521118164,7082.408967932,3390.096,false,dyspcsmwhq,1979-11-10 12:56:35,eydynjfcrsmjwwcjyqtcwskjmaulyg==,\"[1826,8833,371,2946,1848,661,3918,7866,3517,9457,3681]\",\"{\"\"key1\"\":\"\"BahZ52XrL1\"\",\"\"key2\"\":\"\"ZP6eRPsIEd\"\",\"\"key3\"\":\"\"VBMjjPITQw\"\",\"\"key4\"\":\"\"1rSnwpb9sq\"\"}\",\"{\"\"id\"\":\"\"bfggr\"\",\"\"val1\"\":\"\"nxflc\"\",\"\"val2\"\":\"\"elsjm\"\"}\",gqouiupeqligvhn,ykwavphlbv,2002-01-11 00:00:00,13,4.94065e-32,d,'d',\"\"\"d\"\"\",\ud83d\udfe8, \u062e\u0627\u0635\u0629,M\u00c8RE ,\u05d4\u05e8 \u05d1\u05e8\u05db\u05d4 \u05d1\u05e8\u05db\u05d4\r\n+340231167,-103,32314,6727076822845952,490.876434326,521.782040839,689.131,false,ynbspwxszn,2006-09-11 04:44:46,yybegwugseeyfyyzzxssndxpceskbg==,\"[7387,5827,3530,5417,2764,3977,7112,6065,2894,6651,9171,6785,5125]\",\"{\"\"key1\"\":\"\"SL6KOlo6yS\"\",\"\"key2\"\":\"\"6hwmQ2uKSH\"\",\"\"key3\"\":\"\"ECjxaAa7Su\"\",\"\"key4\"\":\"\"OY8xWw8ut0\"\"}\",\"{\"\"id\"\":\"\"avewu\"\",\"\"val1\"\":\"\"rttto\"\",\"\"val2\"\":\"\"mndbq\"\"}\",gmknpbmxtkuyfvw,rzxfoedloj,1999-07-03 00:00:00,12,-7.4423e-12,a,'a',\"\"\"a\"\"\",\ud83d\udcdd,\u0627\u0644\u0637\u0644\u0627\u0642 ,EN D\u00c9CEMBRE,\u05d7\u05e8\u05de\u05e9\r\n+59571531,-120,2726,499568922236435,5693.273925781,831.917259298,5970.561,false,srcyitzady,1976-01-17 22:33:07,uomxckzjwvhrhuqvxvjmntzosoyudQ==,\"[1663,9022,6558]\",\"{\"\"key1\"\":\"\"GqtZfwU56W\"\",\"\"key2\"\":\"\"hjDJcwofzW\"\",\"\"key3\"\":\"\"wAS2lqzSh0\"\",\"\"key4\"\":\"\"ieeRmIe0pZ\"\"}\",\"{\"\"id\"\":\"\"jmsyp\"\",\"\"val1\"\":\"\"tjrjc\"\",\"\"val2\"\":\"\"fwuue\"\"}\",ekatpkqdtbrdopr,vsusznjtum,2002-01-30 00:00:00,9,-0.00445124654,g,'g',\"\"\"g\"\"\",\ud83d\udd37,\u0635\u062f\u064a\u0642\u0647,FRAN\u00c7AISE ,\u05e7\u05d3\u05d9\u05dd\r\n+955388927,36,-14711,234259271632640,5292.765136719,821.385383988,8358.519,true,krzqufbilr,2012-10-22 05:07:34,owkzlgegaqgzpbomgtgdmmqaigfmog==,\"[4974,9911,5595,6472,7765,1797,1908,1014,5229]\",\"{\"\"key1\"\":\"\"xydc0YQBBL\"\",\"\"key2\"\":\"\"8tW4c8Gm4M\"\",\"\"key3\"\":\"\"aGblhlIIrx\"\",\"\"key4\"\":\"\"v30H3CJPMy\"\"}\",\"{\"\"id\"\":\"\"eqoya\"\",\"\"val1\"\":\"\"ypims\"\",\"\"val2\"\":\"\"blsod\"\"}\",sumfztrbmpwkjon,bypzxafltm,2013-06-15 00:00:00,14,7.4423e-12,j,'j',\"\"\"j\"\"\",\ud83c\udd97, \u0639\u0644\u064a ,DE NO\u00cbL ,\u05e9\u05d1\u05d9 \u05e9\u05d5\u05de\u05e8\u05d5\u05df\r\n+1838367743,-76,7387,2747089955464832,8975.13671875,704.915821881,272.055,true,ouxvftfobi,1971-06-30 18:49:15,acidfzuquvceiuuzqqvnljpljdcnzg==,\"[9936,6185,781,912,2509,4330]\",\"{\"\"key1\"\":\"\"94j6CTgyit\"\",\"\"key2\"\":\"\"smHeSsm3fX\"\",\"\"key3\"\":\"\"PD7ADcq9JW\"\",\"\"key4\"\":\"\"eqjA1uBW3e\"\"}\",\"{\"\"id\"\":\"\"gmimc\"\",\"\"val1\"\":\"\"oyksy\"\",\"\"val2\"\":\"\"bavue\"\"}\",aowrnboisicvkex,rucsmrzxvu,2011-09-01 00:00:00,18,1.79769e+308,w,'w',\"\"\"w\"\"\",\u274c,\u0635\u062f\u064a\u0642\u0647,FRAN\u00c7AISE ,\u05e1\u05e0\u05e1\u05e0\u05d4\r\n+-703343616,19,7048,1887435007823552,3118.254150391,3798.277379851,1502.739,true,hwhwhwafby,2008-03-06 02:00:46,wwcjyqtcwskjmaulygxoqwfedjiyrg==,\"[4259,717,7166,7868,1323,4157,6358,6232,2556,9900,3363,6799,60,5880,7990,4743,8200,5670,6079]\",\"{\"\"key1\"\":\"\"XIVSXvg33a\"\",\"\"key2\"\":\"\"2HsXhn6Ee2\"\",\"\"key3\"\":\"\"03o5vQeeLf\"\",\"\"key4\"\":\"\"GzX7WcQrRx\"\"}\",\"{\"\"id\"\":\"\"hryfw\"\",\"\"val1\"\":\"\"wkcgw\"\",\"\"val2\"\":\"\"sjmns\"\"}\",yyshjqkviglwvhz,uclwpzskje,1983-03-28 00:00:00,6,-179623157,t,'t',\"\"\"t\"\"\",\u2757\ufe0f,\u0648\u0648\u0642\u0641,DE NO\u00cbL ,\u05ea\u05dc\u05dd\r\n+1671645295,-54,12191,8891823575776256,4349.600097656,5313.086512179,9153.266,false,htxiqenedt,1999-03-30 20:05:28,iskynmcvdrnpbysmtjkcguptilqefw==,,\"{\"\"key1\"\":\"\"3badsBTnEu\"\",\"\"key2\"\":\"\"w2t7fCA5if\"\",\"\"key3\"\":\"\"jiavckw8PW\"\",\"\"key4\"\":\"\"21LcTl7GEk\"\"}\",\"{\"\"id\"\":\"\"wpica\"\",\"\"val1\"\":\"\"wptoy\"\",\"\"val2\"\":\"\"iryuo\"\"}\",oeshqwtudywyksw,qenziyaaqm,2003-03-16 00:00:00,16,1.2345678e+22,e,'e',\"\"\"e\"\"\",\u270f\ufe0f,\u062f\u0639\u0648\u062a\u0647,CUISINE LE D\u00ceNER ,\u05d9\u05e6\u05d4\u05e8\r\n+-1684013568,118,-24306,7313791764174080,287.703582764,3151.620627917,6181.187,true,nohqcyneqj,1970-11-10 05:03:07,ccdehmtplyzrksyweivpvhyvmlywyQ==,\"[5533,9469,8400,1236,26,9435]\",\"{\"\"key1\"\":\"\"vyMNJLBCZ8\"\",\"\"key2\"\":\"\"Jh7CiBItY8\"\",\"\"key3\"\":\"\"bESrtP2bb7\"\",\"\"key4\"\":\"\"wTaLbfFDcs\"\"}\",\"{\"\"id\"\":\"\"bavjh\"\",\"\"val1\"\":\"\"pnnih\"\",\"\"val2\"\":\"\"vjrjh\"\"}\",igizjxvkxfvbfca,zdvpuszdnh,2013-03-24 00:00:00,1,-1.2345678e+22,s,'s',\"\"\"s\"\"\",\ud83d\ude21,\u0647\u062f\u064a\u0629,EN D\u00c9CEMBRE,\u05d0\u05d1\u05e0\u05d9 \u05d7\u05e4\u05e5\r\n+12284927,50,-23596,3090497741838080,7133.937988281,1689.871550393,361.979,false,nucvnzflzq,1982-03-01 14:38:42,mohmdorwphgpbeydynjfcrsmjwwcjw==,\"[4116,3479,1659,585,1774,9875,6875,2468,9124,3381,2819,7152,8430,9381,3429,3882,5494]\",\"{\"\"key1\"\":\"\"fYMgi49MuZ\"\",\"\"key2\"\":\"\"tEZ0xIaoWn\"\",\"\"key3\"\":\"\"jLyevsUqXL\"\",\"\"key4\"\":\"\"EcbkujjhB0\"\"}\",\"{\"\"id\"\":\"\"kstoy\"\",\"\"val1\"\":\"\"mndgw\"\",\"\"val2\"\":\"\"elnir\"\"}\",yiezdlzhndhzkum,wfomgoetsc,2001-01-11 00:00:00,8,-179.763157,a,'a',\"\"\"a\"\"\",\ud83d\ude00,\u0633\u064a\u0647\u062f\u064a\u0647 ,DE NO\u00cbL ,\u05e9\u05d0-\u05e0\u05d5\u05e8\r\n+1462738431,-14,6340,634171097409536,1516.799316406,5888.129773498,9240.135,false,kypzqcadqz,2000-03-16 18:38:10,qwalydjzhtcfqbssmydjzuycysoccw==,\"[7760,604,4336,4251]\",\"{\"\"key1\"\":\"\"LPd7EsQfFI\"\",\"\"key2\"\":\"\"Z3oIisw6Ai\"\",\"\"key3\"\":\"\"vRPV7oKuhy\"\",\"\"key4\"\":\"\"wh0uRNvY8Z\"\"}\",\"{\"\"id\"\":\"\"fgbqy\"\",\"\"val1\"\":\"\"dvebf\"\",\"\"val2\"\":\"\"aqdbf\"\"}\",ceqzycmpezypklu,zxcqjyiqhy,2001-04-30 00:00:00,15,123.45678,g,'g',\"\"\"g\"\"\",\ud83d\ude0a, \u0642\u0627\u0626\u0644\u0627\u064b,CUISINE LE D\u00ceNER ,\u05d0\u05d9\u05ea\u05de\u05e8\r\n+2032854015,124,-6867,2971557475748552,7684.747070313,2829.404176599,7425.072,true,ynuxibyskr,1971-10-01 22:22:22,omgtgdmmqaigfmohmdorwphgpbeydw==,\"[4041,7619,1172,9022,2349,2213,5804,1965,4390,4060,2752]\",\"{\"\"key1\"\":\"\"ZIrea4F10F\"\",\"\"key2\"\":\"\"xCQ6E60w71\"\",\"\"key3\"\":\"\"S7sa9dvHDG\"\",\"\"key4\"\":\"\"oOp7CL6LhN\"\"}\",\"{\"\"id\"\":\"\"xuoiw\"\",\"\"val1\"\":\"\"jroyf\"\",\"\"val2\"\":\"\"ihmni\"\"}\",eiwcmxrrdqllsyr,pcddgowuzv,1997-05-31 00:00:00,20,-4.940656,t,'t',\"\"\"t\"\"\",\ud83c\udf40,\u0648\u0623\u0639\u0644\u0646 ,FRAN\u00c7AISE ,\u05de\u05d1\u05d5\u05d0 \u05d3\u05d5\u05ea\u05df\r\n+1805124607,91,6447,2525964422257088,8623.229492188,8118.9394035,8176.205,false,ruszqcqjwp,1976-11-24 00:31:34,ukmdhvhsbxvjpbowkzlgegaqgzpbog==,\"[5599,972,9379,351,4476,8111,5519,5949,4540,848,1050,5422,767,7645,4393,8164,4643,3916,3250]\",\"{\"\"key1\"\":\"\"dU3uIQ8NM1\"\",\"\"key2\"\":\"\"v482CaKybl\"\",\"\"key3\"\":\"\"uabKB3zls9\"\",\"\"key4\"\":\"\"5KzVA5ivwz\"\"}\",\"{\"\"id\"\":\"\"ttzkh\"\",\"\"val1\"\":\"\"kcavj\"\",\"\"val2\"\":\"\"wkclh\"\"}\",agyrupinwbeztta,lwhbibqmws,1978-03-31 00:00:00,17,1.7976e+30,d,'d',\"\"\"d\"\"\",\ud83c\udf89,  \u0641\u0631\u0641\u0636\u0647\u0627,FRAN\u00c7AISE ,\u05db\u05e4\u05e8 \u05ea\u05e4\u05d5\u05d7\r\n+-1057157632,-77,-17825,6684227018091776,3754.662353516,1227.72216854,7412.237,true,iwaigqusuc,1996-12-26 01:28:37,ccxpeexihihokaudhmuplzphtfccdQ==,\"[9781,9643]\",\"{\"\"key1\"\":\"\"PjgjuUKVC4\"\",\"\"key2\"\":\"\"9nGNkoyTfb\"\",\"\"key3\"\":\"\"UcWQ9Yk3ff\"\",\"\"key4\"\":\"\"ZOG77yFk4S\"\"}\",\"{\"\"id\"\":\"\"sosyf\"\",\"\"val1\"\":\"\"ujhrt\"\",\"\"val2\"\":\"\"rjxza\"\"}\",kqwyafcfaclzfgg,jtscynuscn,1975-06-02 00:00:00,3,-17976157000000,y,'y',\"\"\"y\"\"\",\ud83d\udcd5,\u0623\u0646\u0647 ,CUISINE LE D\u00ceNER ,\u05d0\u05dc\u05d5\u05df \u05de\u05d5\u05e8\u05d4\r\n+268149759,25,26299,863534107491584,4555.274414063,779.365301495,2038.987,false,kycfdgtzsu,1997-06-29 02:57:33,ywycfpatthdxjswjtizeahtpojyybQ==,\"[7165,780,4823,5610,8150,9640,2670,4954,3538]\",\"{\"\"key1\"\":\"\"qegPrwEXxt\"\",\"\"key2\"\":\"\"AZhgaO5l7R\"\",\"\"key3\"\":\"\"TjQeE1T5r4\"\",\"\"key4\"\":\"\"7iMEn717cy\"\"}\",\"{\"\"id\"\":\"\"gwpdl\"\",\"\"val1\"\":\"\"niwzf\"\",\"\"val2\"\":\"\"lnica\"\"}\",ucatyvfobyjejgq,wxfbvcvspp,1972-02-21 00:00:00,11,-7.4423e-12,w,'w',\"\"\"w\"\"\",\ud83c\udf4e,\u0623\u0645\u0627\u0645 ,EN D\u00c9CEMBRE,\u05d2\u05e0\u05d9\u05dd\r\n+-669752208,-47,-15665,4986790849161728,3570.342041016,7889.261249401,3128.891,true,wnhbaiojlo,1972-06-13 22:37:55,qetzsvpouvqqhgelfbzdzqymgficdQ==,\"[8466,6224,483,2088,8626]\",\"{\"\"key1\"\":\"\"DHI5hSpnD8\"\",\"\"key2\"\":\"\"ZX1CFWZaEe\"\",\"\"key3\"\":\"\"4TkLHzJLoN\"\",\"\"key4\"\":\"\"xYjtvEEQ7o\"\"}\",\"{\"\"id\"\":\"\"zakhb\"\",\"\"val1\"\":\"\"welnn\"\",\"\"val2\"\":\"\"xzkms\"\"}\",ygoubokubqbesfz,ppphdtzkbs,1990-04-11 00:00:00,7,-1797.23157,d,'d',\"\"\"d\"\"\",\u23fa,\u062f\u0639\u0648\u062a\u0647,CUISINE LE D\u00ceNER ,\u05d1\u05d9\u05ea \u05d7\u05d2\u05d9 \u05d7\u05d2\u05d9\r\n+null,null,,,,,,,,,,,\"\"\"\"\"\",,,,,,,,,,,,,\r\n+,null,-15906,5035218741361664,1292.412231445,5799.643102009,5292.029,false,!@#$%^&*(),1990-08-05 15:20:03,ukuclnqrqmzfoawrawqyrxhucmiskw==,\"[3697,4006,8856,2643,8157,3966,3652,9256,6544,218,6844]\",\"{\"\"key1\"\":\"\"NMkbDREYfH\"\",\"\"key2\"\":\"\"hd7X3zO3Pk\"\",\"\"key3\"\":\"\"Z9ZIyZs59c\"\",\"\"key4\"\":\"\"SZzGskMufb\"\"}\",\"{\"\"id\"\":\"\"sjrod\"\",\"\"val1\"\":\"\"qdlhr\"\",\"\"val2\"\":\"\"dvegw\"\"}\",iumixtiqivrwyrw,kycsmrupwf,1986-11-25 00:00:00,19,,q,'q',\"\"\"q\"\"\",\u2705,\u0644\u0628\u0649,M\u00c8RE ,\u05e8\u05d7\u05dc\u05d9\u05dd\r\n+-955939840,13,28595,4458733335951872,8748.717773438,1547.018290286,2994.118,false,ommetzkgoe,1970-04-26 07:48:00,ayrbgvzejhwqfsczxcrygqcedbqetw==,,\"{\"\"key1\"\":\"\"ze4uTLJCIS\"\",\"\"key2\"\":\"\"KJvGWmVD4k\"\",\"\"key3\"\":\"\"EAj5tjtJIY\"\",\"\"key4\"\":\"\"sGZyLdFZTL\"\"}\",\"{\"\"id\"\":\"\"zavzf\"\",\"\"val1\"\":\"\"cvpte\"\",\"\"val2\"\":\"\"wpihw\"\"}\",waoexcjeezmxrsi,scnzxnuxan,1985-04-11 00:00:00,4,-4123000000000,r,'r',\"\"\"r\"\"\",\ud83c\udf8a,\u0645\u0646\u0632\u0644\u0647,M\u00c8RE ,\u05de\u05d2\u05d3\u05dc\u05d9\u05dd\r\n+-946041088,20,4028,6488644051956704,2068.969238281,6867.608431199,2096.338,false,aftxkrhbse,1995-07-21 00:19:48,okvcbxnhykbxgmodzdwgybzwioikng==,[606],\"{\"\"key1\"\":\"\"lh6d4g6AdX\"\",\"\"key2\"\":\"\"m7NXz1Drky\"\",\"\"key3\"\":\"\"PE0h2QSxpA\"\",\"\"key4\"\":\"\"6R2Esbvp9X\"\"}\",\"{\"\"id\"\":\"\"uegms\"\",\"\"val1\"\":\"\"grjhb\"\",\"\"val2\"\":\"\"wzptz\"\"}\",ukampuhnwymbxok,pwumbaiqhj,1980-08-31 00:00:00,5,-4123000000000,s,'s',\"\"\"s\"\"\",\u2b07\ufe0f,\u0645\u0627\u062a\u062c\u064a\u0646\u064a,M\u00c8RE ,\u05d7\u05d5\u05de\u05e9\r\n+190064639,85,-16861,745854179121920,3006.978027344,5300.161841,590.341,false,pwpphjeqey,1971-11-03 14:46:40,csdhfkmtpzkznemtvmumlbcetlgfqg==,\"[4828,2281]\",\"{\"\"key1\"\":\"\"381OAMa9cm\"\",\"\"key2\"\":\"\"kVqFCSMW5N\"\",\"\"key3\"\":\"\"SORmXvLRX2\"\",\"\"key4\"\":\"\"yjMtCtXnrM\"\"}\",\"{\"\"id\"\":\"\"bqodb\"\",\"\"val1\"\":\"\"mnxzv\"\",\"\"val2\"\":\"\"uebln\"\"}\",qumqyheavhhvwkc,lbidykbvuz,1977-12-01 00:00:00,10,-7.4423e-12,s,'s',\"\"\"s\"\"\",\u26a0\ufe0f,\u0648\u0648\u0642\u0641,DE NO\u00cbL ,\u05e2\u05e0\u05d1\r\n+-1355749376,28,-6594,6217661610739712,1575.131469727,4710.247816849,719.935,false,wkrxvnrrmw,1977-04-11 02:09:53,qiutbarcseuaqboaojdlihgwvwiqwQ==,\"[7066,6223,9555,9906,8967,4096,2286,9385,4793,2865,57,7801,1261,5671,8650,8967,7999,7792,2867]\",\"{\"\"key1\"\":\"\"HlwjPoYNOZ\"\",\"\"key2\"\":\"\"hnbly8aGKW\"\",\"\"key3\"\":\"\"2nSgdIRftI\"\",\"\"key4\"\":\"\"8sxcVvxtbj\"\"}\",\"{\"\"id\"\":\"\"hwuon\"\",\"\"val1\"\":\"\"wuuon\"\",\"\"val2\"\":\"\"icggg\"\"}\",gmmgstuttnbjxpy,vhdgledyvc,1994-10-13 00:00:00,2,-1.2345678e+22,m,'m',\"\"\"m\"\"\",\u2764\ufe0f,\u062f\u0639\u0648\u062a\u0647,EN D\u00c9CEMBRE,\u05e0\u05d2\u05d5\u05d4\u05d5\u05ea\r\n+623428607,52,-12058,1099140924791552,1668.521118164,7082.408967932,3390.096,false,dyspcsmwhq,1979-11-10 12:56:35,eydynjfcrsmjwwcjyqtcwskjmaulyg==,\"[1826,8833,371,2946,1848,661,3918,7866,3517,9457,3681]\",\"{\"\"key1\"\":\"\"BahZ52XrL1\"\",\"\"key2\"\":\"\"ZP6eRPsIEd\"\",\"\"key3\"\":\"\"VBMjjPITQw\"\",\"\"key4\"\":\"\"1rSnwpb9sq\"\"}\",\"{\"\"id\"\":\"\"bfggr\"\",\"\"val1\"\":\"\"nxflc\"\",\"\"val2\"\":\"\"elsjm\"\"}\",gqouiupeqligvhn,ykwavphlbv,2002-01-11 00:00:00,13,4.94065e-32,d,'d',\"\"\"d\"\"\",\ud83d\udfe8, \u062e\u0627\u0635\u0629,M\u00c8RE ,\u05d4\u05e8 \u05d1\u05e8\u05db\u05d4 \u05d1\u05e8\u05db\u05d4\r\n+340231167,-103,32314,6727076822845952,490.876434326,521.782040839,689.131,false,ynbspwxszn,2006-09-11 04:44:46,yybegwugseeyfyyzzxssndxpceskbg==,\"[7387,5827,3530,5417,2764,3977,7112,6065,2894,6651,9171,6785,5125]\",\"{\"\"key1\"\":\"\"SL6KOlo6yS\"\",\"\"key2\"\":\"\"6hwmQ2uKSH\"\",\"\"key3\"\":\"\"ECjxaAa7Su\"\",\"\"key4\"\":\"\"OY8xWw8ut0\"\"}\",\"{\"\"id\"\":\"\"avewu\"\",\"\"val1\"\":\"\"rttto\"\",\"\"val2\"\":\"\"mndbq\"\"}\",gmknpbmxtkuyfvw,rzxfoedloj,1999-07-03 00:00:00,12,-7.4423e-12,a,'a',\"\"\"a\"\"\",\ud83d\udcdd,\u0627\u0644\u0637\u0644\u0627\u0642 ,EN D\u00c9CEMBRE,\u05d7\u05e8\u05de\u05e9\r\n+59571531,-120,2726,499568922236435,5693.273925781,831.917259298,5970.561,false,srcyitzady,1976-01-17 22:33:07,uomxckzjwvhrhuqvxvjmntzosoyudQ==,\"[1663,9022,6558]\",\"{\"\"key1\"\":\"\"GqtZfwU56W\"\",\"\"key2\"\":\"\"hjDJcwofzW\"\",\"\"key3\"\":\"\"wAS2lqzSh0\"\",\"\"key4\"\":\"\"ieeRmIe0pZ\"\"}\",\"{\"\"id\"\":\"\"jmsyp\"\",\"\"val1\"\":\"\"tjrjc\"\",\"\"val2\"\":\"\"fwuue\"\"}\",ekatpkqdtbrdopr,vsusznjtum,2002-01-30 00:00:00,9,-0.00445124654,g,'g',\"\"\"g\"\"\",\ud83d\udd37,\u0635\u062f\u064a\u0642\u0647,FRAN\u00c7AISE ,\u05e7\u05d3\u05d9\u05dd\r\n+955388927,36,-14711,234259271632640,5292.765136719,821.385383988,8358.519,true,krzqufbilr,2012-10-22 05:07:34,owkzlgegaqgzpbomgtgdmmqaigfmog==,\"[4974,9911,5595,6472,7765,1797,1908,1014,5229]\",\"{\"\"key1\"\":\"\"xydc0YQBBL\"\",\"\"key2\"\":\"\"8tW4c8Gm4M\"\",\"\"key3\"\":\"\"aGblhlIIrx\"\",\"\"key4\"\":\"\"v30H3CJPMy\"\"}\",\"{\"\"id\"\":\"\"eqoya\"\",\"\"val1\"\":\"\"ypims\"\",\"\"val2\"\":\"\"blsod\"\"}\",sumfztrbmpwkjon,bypzxafltm,2013-06-15 00:00:00,14,7.4423e-12,j,'j',\"\"\"j\"\"\",\ud83c\udd97, \u0639\u0644\u064a ,DE NO\u00cbL ,\u05e9\u05d1\u05d9 \u05e9\u05d5\u05de\u05e8\u05d5\u05df\r\n+1838367743,-76,7387,2747089955464832,8975.13671875,704.915821881,272.055,true,ouxvftfobi,1971-06-30 18:49:15,acidfzuquvceiuuzqqvnljpljdcnzg==,\"[9936,6185,781,912,2509,4330]\",\"{\"\"key1\"\":\"\"94j6CTgyit\"\",\"\"key2\"\":\"\"smHeSsm3fX\"\",\"\"key3\"\":\"\"PD7ADcq9JW\"\",\"\"key4\"\":\"\"eqjA1uBW3e\"\"}\",\"{\"\"id\"\":\"\"gmimc\"\",\"\"val1\"\":\"\"oyksy\"\",\"\"val2\"\":\"\"bavue\"\"}\",aowrnboisicvkex,rucsmrzxvu,2011-09-01 00:00:00,18,1.79769e+308,w,'w',\"\"\"w\"\"\",\u274c,\u0635\u062f\u064a\u0642\u0647,FRAN\u00c7AISE ,\u05e1\u05e0\u05e1\u05e0\u05d4\r\n+-703343616,19,7048,1887435007823552,3118.254150391,3798.277379851,1502.739,true,hwhwhwafby,2008-03-06 02:00:46,wwcjyqtcwskjmaulygxoqwfedjiyrg==,\"[4259,717,7166,7868,1323,4157,6358,6232,2556,9900,3363,6799,60,5880,7990,4743,8200,5670,6079]\",\"{\"\"key1\"\":\"\"XIVSXvg33a\"\",\"\"key2\"\":\"\"2HsXhn6Ee2\"\",\"\"key3\"\":\"\"03o5vQeeLf\"\",\"\"key4\"\":\"\"GzX7WcQrRx\"\"}\",\"{\"\"id\"\":\"\"hryfw\"\",\"\"val1\"\":\"\"wkcgw\"\",\"\"val2\"\":\"\"sjmns\"\"}\",yyshjqkviglwvhz,uclwpzskje,1983-03-28 00:00:00,6,-179623157,t,'t',\"\"\"t\"\"\",\u2757\ufe0f,\u0648\u0648\u0642\u0641,DE NO\u00cbL ,\u05ea\u05dc\u05dd\r\n+1671645295,-54,12191,8891823575776256,4349.600097656,5313.086512179,9153.266,false,htxiqenedt,1999-03-30 20:05:28,iskynmcvdrnpbysmtjkcguptilqefw==,,\"{\"\"key1\"\":\"\"3badsBTnEu\"\",\"\"key2\"\":\"\"w2t7fCA5if\"\",\"\"key3\"\":\"\"jiavckw8PW\"\",\"\"key4\"\":\"\"21LcTl7GEk\"\"}\",\"{\"\"id\"\":\"\"wpica\"\",\"\"val1\"\":\"\"wptoy\"\",\"\"val2\"\":\"\"iryuo\"\"}\",oeshqwtudywyksw,qenziyaaqm,2003-03-16 00:00:00,16,1.2345678e+22,e,'e',\"\"\"e\"\"\",\u270f\ufe0f,\u062f\u0639\u0648\u062a\u0647,CUISINE LE D\u00ceNER ,\u05d9\u05e6\u05d4\u05e8\r\n+-1684013568,118,-24306,7313791764174080,287.703582764,3151.620627917,6181.187,true,nohqcyneqj,1970-11-10 05:03:07,ccdehmtplyzrksyweivpvhyvmlywyQ==,\"[5533,9469,8400,1236,26,9435]\",\"{\"\"key1\"\":\"\"vyMNJLBCZ8\"\",\"\"key2\"\":\"\"Jh7CiBItY8\"\",\"\"key3\"\":\"\"bESrtP2bb7\"\",\"\"key4\"\":\"\"wTaLbfFDcs\"\"}\",\"{\"\"id\"\":\"\"bavjh\"\",\"\"val1\"\":\"\"pnnih\"\",\"\"val2\"\":\"\"vjrjh\"\"}\",igizjxvkxfvbfca,zdvpuszdnh,2013-03-24 00:00:00,1,-1.2345678e+22,s,'s',\"\"\"s\"\"\",\ud83d\ude21,\u0647\u062f\u064a\u0629,EN D\u00c9CEMBRE,\u05d0\u05d1\u05e0\u05d9 \u05d7\u05e4\u05e5\r\n+12284927,50,-23596,3090497741838080,7133.937988281,1689.871550393,361.979,false,nucvnzflzq,1982-03-01 14:38:42,mohmdorwphgpbeydynjfcrsmjwwcjw==,\"[4116,3479,1659,585,1774,9875,6875,2468,9124,3381,2819,7152,8430,9381,3429,3882,5494]\",\"{\"\"key1\"\":\"\"fYMgi49MuZ\"\",\"\"key2\"\":\"\"tEZ0xIaoWn\"\",\"\"key3\"\":\"\"jLyevsUqXL\"\",\"\"key4\"\":\"\"EcbkujjhB0\"\"}\",\"{\"\"id\"\":\"\"kstoy\"\",\"\"val1\"\":\"\"mndgw\"\",\"\"val2\"\":\"\"elnir\"\"}\",yiezdlzhndhzkum,wfomgoetsc,2001-01-11 00:00:00,8,-179.763157,a,'a',\"\"\"a\"\"\",\ud83d\ude00,\u0633\u064a\u0647\u062f\u064a\u0647 ,DE NO\u00cbL ,\u05e9\u05d0-\u05e0\u05d5\u05e8\r\n+1462738431,-14,6340,634171097409536,1516.799316406,5888.129773498,9240.135,false,kypzqcadqz,2000-03-16 18:38:10,qwalydjzhtcfqbssmydjzuycysoccw==,\"[7760,604,4336,4251]\",\"{\"\"key1\"\":\"\"LPd7EsQfFI\"\",\"\"key2\"\":\"\"Z3oIisw6Ai\"\",\"\"key3\"\":\"\"vRPV7oKuhy\"\",\"\"key4\"\":\"\"wh0uRNvY8Z\"\"}\",\"{\"\"id\"\":\"\"fgbqy\"\",\"\"val1\"\":\"\"dvebf\"\",\"\"val2\"\":\"\"aqdbf\"\"}\",ceqzycmpezypklu,zxcqjyiqhy,2001-04-30 00:00:00,15,123.45678,g,'g',\"\"\"g\"\"\",\ud83d\ude0a, \u0642\u0627\u0626\u0644\u0627\u064b,CUISINE LE D\u00ceNER ,\u05d0\u05d9\u05ea\u05de\u05e8\r\n+2032854015,124,-6867,2971557475748552,7684.747070313,2829.404176599,7425.072,true,ynuxibyskr,1971-10-01 22:22:22,omgtgdmmqaigfmohmdorwphgpbeydw==,\"[4041,7619,1172,9022,2349,2213,5804,1965,4390,4060,2752]\",\"{\"\"key1\"\":\"\"ZIrea4F10F\"\",\"\"key2\"\":\"\"xCQ6E60w71\"\",\"\"key3\"\":\"\"S7sa9dvHDG\"\",\"\"key4\"\":\"\"oOp7CL6LhN\"\"}\",\"{\"\"id\"\":\"\"xuoiw\"\",\"\"val1\"\":\"\"jroyf\"\",\"\"val2\"\":\"\"ihmni\"\"}\",eiwcmxrrdqllsyr,pcddgowuzv,1997-05-31 00:00:00,20,-4.940656,t,'t',\"\"\"t\"\"\",\ud83c\udf40,\u0648\u0623\u0639\u0644\u0646 ,FRAN\u00c7AISE ,\u05de\u05d1\u05d5\u05d0 \u05d3\u05d5\u05ea\u05df\r\n+1805124607,91,6447,2525964422257088,8623.229492188,8118.9394035,8176.205,false,ruszqcqjwp,1976-11-24 00:31:34,ukmdhvhsbxvjpbowkzlgegaqgzpbog==,\"[5599,972,9379,351,4476,8111,5519,5949,4540,848,1050,5422,767,7645,4393,8164,4643,3916,3250]\",\"{\"\"key1\"\":\"\"dU3uIQ8NM1\"\",\"\"key2\"\":\"\"v482CaKybl\"\",\"\"key3\"\":\"\"uabKB3zls9\"\",\"\"key4\"\":\"\"5KzVA5ivwz\"\"}\",\"{\"\"id\"\":\"\"ttzkh\"\",\"\"val1\"\":\"\"kcavj\"\",\"\"val2\"\":\"\"wkclh\"\"}\",agyrupinwbeztta,lwhbibqmws,1978-03-31 00:00:00,17,1.7976e+30,d,'d',\"\"\"d\"\"\",\ud83c\udf89,  \u0641\u0631\u0641\u0636\u0647\u0627,FRAN\u00c7AISE ,\u05db\u05e4\u05e8 \u05ea\u05e4\u05d5\u05d7\r\n+-1057157632,-77,-17825,6684227018091776,3754.662353516,1227.72216854,7412.237,true,iwaigqusuc,1996-12-26 01:28:37,ccxpeexihihokaudhmuplzphtfccdQ==,\"[9781,9643]\",\"{\"\"key1\"\":\"\"PjgjuUKVC4\"\",\"\"key2\"\":\"\"9nGNkoyTfb\"\",\"\"key3\"\":\"\"UcWQ9Yk3ff\"\",\"\"key4\"\":\"\"ZOG77yFk4S\"\"}\",\"{\"\"id\"\":\"\"sosyf\"\",\"\"val1\"\":\"\"ujhrt\"\",\"\"val2\"\":\"\"rjxza\"\"}\",kqwyafcfaclzfgg,jtscynuscn,1975-06-02 00:00:00,3,-17976157000000,y,'y',\"\"\"y\"\"\",\ud83d\udcd5,\u0623\u0646\u0647 ,CUISINE LE D\u00ceNER ,\u05d0\u05dc\u05d5\u05df \u05de\u05d5\u05e8\u05d4\r\n+268149759,25,26299,863534107491584,4555.274414063,779.365301495,2038.987,false,kycfdgtzsu,1997-06-29 02:57:33,ywycfpatthdxjswjtizeahtpojyybQ==,\"[7165,780,4823,5610,8150,9640,2670,4954,3538]\",\"{\"\"key1\"\":\"\"qegPrwEXxt\"\",\"\"key2\"\":\"\"AZhgaO5l7R\"\",\"\"key3\"\":\"\"TjQeE1T5r4\"\",\"\"key4\"\":\"\"7iMEn717cy\"\"}\",\"{\"\"id\"\":\"\"gwpdl\"\",\"\"val1\"\":\"\"niwzf\"\",\"\"val2\"\":\"\"lnica\"\"}\",ucatyvfobyjejgq,wxfbvcvspp,1972-02-21 00:00:00,11,-7.4423e-12,w,'w',\"\"\"w\"\"\",\ud83c\udf4e,\u0623\u0645\u0627\u0645 ,EN D\u00c9CEMBRE,\u05d2\u05e0\u05d9\u05dd\r\n+-669752208,-47,-15665,4986790849161728,3570.342041016,7889.261249401,3128.891,true,wnhbaiojlo,1972-06-13 22:37:55,qetzsvpouvqqhgelfbzdzqymgficdQ==,\"[8466,6224,483,2088,8626]\",\"{\"\"key1\"\":\"\"DHI5hSpnD8\"\",\"\"key2\"\":\"\"ZX1CFWZaEe\"\",\"\"key3\"\":\"\"4TkLHzJLoN\"\",\"\"key4\"\":\"\"xYjtvEEQ7o\"\"}\",\"{\"\"id\"\":\"\"zakhb\"\",\"\"val1\"\":\"\"welnn\"\",\"\"val2\"\":\"\"xzkms\"\"}\",ygoubokubqbesfz,ppphdtzkbs,1990-04-11 00:00:00,7,-1797.23157,d,'d',\"\"\"d\"\"\",\u23fa,\u062f\u0639\u0648\u062a\u0647,CUISINE LE D\u00ceNER ,\u05d1\u05d9\u05ea \u05d7\u05d2\u05d9 \u05d7\u05d2\u05d9\r\n+null,null,,,,,,,,,,,\"\"\"\"\"\",,,,,,,,,,,,,\r\n+,null,-15906,5035218741361664,1292.412231445,5799.643102009,5292.029,false,!@#$%^&*(),1990-08-05 15:20:03,ukuclnqrqmzfoawrawqyrxhucmiskw==,\"[3697,4006,8856,2643,8157,3966,3652,9256,6544,218,6844]\",\"{\"\"key1\"\":\"\"NMkbDREYfH\"\",\"\"key2\"\":\"\"hd7X3zO3Pk\"\",\"\"key3\"\":\"\"Z9ZIyZs59c\"\",\"\"key4\"\":\"\"SZzGskMufb\"\"}\",\"{\"\"id\"\":\"\"sjrod\"\",\"\"val1\"\":\"\"qdlhr\"\",\"\"val2\"\":\"\"dvegw\"\"}\",iumixtiqivrwyrw,kycsmrupwf,1986-11-25 00:00:00,19,,q,'q',\"\"\"q\"\"\",\u2705,\u0644\u0628\u0649,M\u00c8RE ,\u05e8\u05d7\u05dc\u05d9\u05dd\r\n+-955939840,13,28595,4458733335951872,8748.717773438,1547.018290286,2994.118,false,ommetzkgoe,1970-04-26 07:48:00,ayrbgvzejhwqfsczxcrygqcedbqetw==,,\"{\"\"key1\"\":\"\"ze4uTLJCIS\"\",\"\"key2\"\":\"\"KJvGWmVD4k\"\",\"\"key3\"\":\"\"EAj5tjtJIY\"\",\"\"key4\"\":\"\"sGZyLdFZTL\"\"}\",\"{\"\"id\"\":\"\"zavzf\"\",\"\"val1\"\":\"\"cvpte\"\",\"\"val2\"\":\"\"wpihw\"\"}\",waoexcjeezmxrsi,scnzxnuxan,1985-04-11 00:00:00,4,-4123000000000,r,'r',\"\"\"r\"\"\",\ud83c\udf8a,\u0645\u0646\u0632\u0644\u0647,M\u00c8RE ,\u05de\u05d2\u05d3\u05dc\u05d9\u05dd\r\n+-946041088,20,4028,6488644051956704,2068.969238281,6867.608431199,2096.338,false,aftxkrhbse,1995-07-21 00:19:48,okvcbxnhykbxgmodzdwgybzwioikng==,[606],\"{\"\"key1\"\":\"\"lh6d4g6AdX\"\",\"\"key2\"\":\"\"m7NXz1Drky\"\",\"\"key3\"\":\"\"PE0h2QSxpA\"\",\"\"key4\"\":\"\"6R2Esbvp9X\"\"}\",\"{\"\"id\"\":\"\"uegms\"\",\"\"val1\"\":\"\"grjhb\"\",\"\"val2\"\":\"\"wzptz\"\"}\",ukampuhnwymbxok,pwumbaiqhj,1980-08-31 00:00:00,5,-4123000000000,s,'s',\"\"\"s\"\"\",\u2b07\ufe0f,\u0645\u0627\u062a\u062c\u064a\u0646\u064a,M\u00c8RE ,\u05d7\u05d5\u05de\u05e9\r\n+190064639,85,-16861,745854179121920,3006.978027344,5300.161841,590.341,false,pwpphjeqey,1971-11-03 14:46:40,csdhfkmtpzkznemtvmumlbcetlgfqg==,\"[4828,2281]\",\"{\"\"key1\"\":\"\"381OAMa9cm\"\",\"\"key2\"\":\"\"kVqFCSMW5N\"\",\"\"key3\"\":\"\"SORmXvLRX2\"\",\"\"key4\"\":\"\"yjMtCtXnrM\"\"}\",\"{\"\"id\"\":\"\"bqodb\"\",\"\"val1\"\":\"\"mnxzv\"\",\"\"val2\"\":\"\"uebln\"\"}\",qumqyheavhhvwkc,lbidykbvuz,1977-12-01 00:00:00,10,-7.4423e-12,s,'s',\"\"\"s\"\"\",\u26a0\ufe0f,\u0648\u0648\u0642\u0641,DE NO\u00cbL ,\u05e2\u05e0\u05d1\r\n+-1355749376,28,-6594,6217661610739712,1575.131469727,4710.247816849,719.935,false,wkrxvnrrmw,1977-04-11 02:09:53,qiutbarcseuaqboaojdlihgwvwiqwQ==,\"[7066,6223,9555,9906,8967,4096,2286,9385,4793,2865,57,7801,1261,5671,8650,8967,7999,7792,2867]\",\"{\"\"key1\"\":\"\"HlwjPoYNOZ\"\",\"\"key2\"\":\"\"hnbly8aGKW\"\",\"\"key3\"\":\"\"2nSgdIRftI\"\",\"\"key4\"\":\"\"8sxcVvxtbj\"\"}\",\"{\"\"id\"\":\"\"hwuon\"\",\"\"val1\"\":\"\"wuuon\"\",\"\"val2\"\":\"\"icggg\"\"}\",gmmgstuttnbjxpy,vhdgledyvc,1994-10-13 00:00:00,2,-1.2345678e+22,m,'m',\"\"\"m\"\"\",\u2764\ufe0f,\u062f\u0639\u0648\u062a\u0647,EN D\u00c9CEMBRE,\u05e0\u05d2\u05d5\u05d4\u05d5\u05ea\r\n+623428607,52,-12058,1099140924791552,1668.521118164,7082.408967932,3390.096,false,dyspcsmwhq,1979-11-10 12:56:35,eydynjfcrsmjwwcjyqtcwskjmaulyg==,\"[1826,8833,371,2946,1848,661,3918,7866,3517,9457,3681]\",\"{\"\"key1\"\":\"\"BahZ52XrL1\"\",\"\"key2\"\":\"\"ZP6eRPsIEd\"\",\"\"key3\"\":\"\"VBMjjPITQw\"\",\"\"key4\"\":\"\"1rSnwpb9sq\"\"}\",\"{\"\"id\"\":\"\"bfggr\"\",\"\"val1\"\":\"\"nxflc\"\",\"\"val2\"\":\"\"elsjm\"\"}\",gqouiupeqligvhn,ykwavphlbv,2002-01-11 00:00:00,13,4.94065e-32,d,'d',\"\"\"d\"\"\",\ud83d\udfe8, \u062e\u0627\u0635\u0629,M\u00c8RE ,\u05d4\u05e8 \u05d1\u05e8\u05db\u05d4 \u05d1\u05e8\u05db\u05d4\r\n+340231167,-103,32314,6727076822845952,490.876434326,521.782040839,689.131,false,ynbspwxszn,2006-09-11 04:44:46,yybegwugseeyfyyzzxssndxpceskbg==,\"[7387,5827,3530,5417,2764,3977,7112,6065,2894,6651,9171,6785,5125]\",\"{\"\"key1\"\":\"\"SL6KOlo6yS\"\",\"\"key2\"\":\"\"6hwmQ2uKSH\"\",\"\"key3\"\":\"\"ECjxaAa7Su\"\",\"\"key4\"\":\"\"OY8xWw8ut0\"\"}\",\"{\"\"id\"\":\"\"avewu\"\",\"\"val1\"\":\"\"rttto\"\",\"\"val2\"\":\"\"mndbq\"\"}\",gmknpbmxtkuyfvw,rzxfoedloj,1999-07-03 00:00:00,12,-7.4423e-12,a,'a',\"\"\"a\"\"\",\ud83d\udcdd,\u0627\u0644\u0637\u0644\u0627\u0642 ,EN D\u00c9CEMBRE,\u05d7\u05e8\u05de\u05e9\r\n+59571531,-120,2726,499568922236435,5693.273925781,831.917259298,5970.561,false,srcyitzady,1976-01-17 22:33:07,uomxckzjwvhrhuqvxvjmntzosoyudQ==,\"[1663,9022,6558]\",\"{\"\"key1\"\":\"\"GqtZfwU56W\"\",\"\"key2\"\":\"\"hjDJcwofzW\"\",\"\"key3\"\":\"\"wAS2lqzSh0\"\",\"\"key4\"\":\"\"ieeRmIe0pZ\"\"}\",\"{\"\"id\"\":\"\"jmsyp\"\",\"\"val1\"\":\"\"tjrjc\"\",\"\"val2\"\":\"\"fwuue\"\"}\",ekatpkqdtbrdopr,vsusznjtum,2002-01-30 00:00:00,9,-0.00445124654,g,'g',\"\"\"g\"\"\",\ud83d\udd37,\u0635\u062f\u064a\u0642\u0647,FRAN\u00c7AISE ,\u05e7\u05d3\u05d9\u05dd\r\n+955388927,36,-14711,234259271632640,5292.765136719,821.385383988,8358.519,true,krzqufbilr,2012-10-22 05:07:34,owkzlgegaqgzpbomgtgdmmqaigfmog==,\"[4974,9911,5595,6472,7765,1797,1908,1014,5229]\",\"{\"\"key1\"\":\"\"xydc0YQBBL\"\",\"\"key2\"\":\"\"8tW4c8Gm4M\"\",\"\"key3\"\":\"\"aGblhlIIrx\"\",\"\"key4\"\":\"\"v30H3CJPMy\"\"}\",\"{\"\"id\"\":\"\"eqoya\"\",\"\"val1\"\":\"\"ypims\"\",\"\"val2\"\":\"\"blsod\"\"}\",sumfztrbmpwkjon,bypzxafltm,2013-06-15 00:00:00,14,7.4423e-12,j,'j',\"\"\"j\"\"\",\ud83c\udd97, \u0639\u0644\u064a ,DE NO\u00cbL ,\u05e9\u05d1\u05d9 \u05e9\u05d5\u05de\u05e8\u05d5\u05df\r\n+1838367743,-76,7387,2747089955464832,8975.13671875,704.915821881,272.055,true,ouxvftfobi,1971-06-30 18:49:15,acidfzuquvceiuuzqqvnljpljdcnzg==,\"[9936,6185,781,912,2509,4330]\",\"{\"\"key1\"\":\"\"94j6CTgyit\"\",\"\"key2\"\":\"\"smHeSsm3fX\"\",\"\"key3\"\":\"\"PD7ADcq9JW\"\",\"\"key4\"\":\"\"eqjA1uBW3e\"\"}\",\"{\"\"id\"\":\"\"gmimc\"\",\"\"val1\"\":\"\"oyksy\"\",\"\"val2\"\":\"\"bavue\"\"}\",aowrnboisicvkex,rucsmrzxvu,2011-09-01 00:00:00,18,1.79769e+308,w,'w',\"\"\"w\"\"\",\u274c,\u0635\u062f\u064a\u0642\u0647,FRAN\u00c7AISE ,\u05e1\u05e0\u05e1\u05e0\u05d4\r\n+-703343616,19,7048,1887435007823552,3118.254150391,3798.277379851,1502.739,true,hwhwhwafby,2008-03-06 02:00:46,wwcjyqtcwskjmaulygxoqwfedjiyrg==,\"[4259,717,7166,7868,1323,4157,6358,6232,2556,9900,3363,6799,60,5880,7990,4743,8200,5670,6079]\",\"{\"\"key1\"\":\"\"XIVSXvg33a\"\",\"\"key2\"\":\"\"2HsXhn6Ee2\"\",\"\"key3\"\":\"\"03o5vQeeLf\"\",\"\"key4\"\":\"\"GzX7WcQrRx\"\"}\",\"{\"\"id\"\":\"\"hryfw\"\",\"\"val1\"\":\"\"wkcgw\"\",\"\"val2\"\":\"\"sjmns\"\"}\",yyshjqkviglwvhz,uclwpzskje,1983-03-28 00:00:00,6,-179623157,t,'t',\"\"\"t\"\"\",\u2757\ufe0f,\u0648\u0648\u0642\u0641,DE NO\u00cbL ,\u05ea\u05dc\u05dd\r\n+1671645295,-54,12191,8891823575776256,4349.600097656,5313.086512179,9153.266,false,htxiqenedt,1999-03-30 20:05:28,iskynmcvdrnpbysmtjkcguptilqefw==,,\"{\"\"key1\"\":\"\"3badsBTnEu\"\",\"\"key2\"\":\"\"w2t7fCA5if\"\",\"\"key3\"\":\"\"jiavckw8PW\"\",\"\"key4\"\":\"\"21LcTl7GEk\"\"}\",\"{\"\"id\"\":\"\"wpica\"\",\"\"val1\"\":\"\"wptoy\"\",\"\"val2\"\":\"\"iryuo\"\"}\",oeshqwtudywyksw,qenziyaaqm,2003-03-16 00:00:00,16,1.2345678e+22,e,'e',\"\"\"e\"\"\",\u270f\ufe0f,\u062f\u0639\u0648\u062a\u0647,CUISINE LE D\u00ceNER ,\u05d9\u05e6\u05d4\u05e8\r\n+-1684013568,118,-24306,7313791764174080,287.703582764,3151.620627917,6181.187,true,nohqcyneqj,1970-11-10 05:03:07,ccdehmtplyzrksyweivpvhyvmlywyQ==,\"[5533,9469,8400,1236,26,9435]\",\"{\"\"key1\"\":\"\"vyMNJLBCZ8\"\",\"\"key2\"\":\"\"Jh7CiBItY8\"\",\"\"key3\"\":\"\"bESrtP2bb7\"\",\"\"key4\"\":\"\"wTaLbfFDcs\"\"}\",\"{\"\"id\"\":\"\"bavjh\"\",\"\"val1\"\":\"\"pnnih\"\",\"\"val2\"\":\"\"vjrjh\"\"}\",igizjxvkxfvbfca,zdvpuszdnh,2013-03-24 00:00:00,1,-1.2345678e+22,s,'s',\"\"\"s\"\"\",\ud83d\ude21,\u0647\u062f\u064a\u0629,EN D\u00c9CEMBRE,\u05d0\u05d1\u05e0\u05d9 \u05d7\u05e4\u05e5\r\n+12284927,50,-23596,3090497741838080,7133.937988281,1689.871550393,361.979,false,nucvnzflzq,1982-03-01 14:38:42,mohmdorwphgpbeydynjfcrsmjwwcjw==,\"[4116,3479,1659,585,1774,9875,6875,2468,9124,3381,2819,7152,8430,9381,3429,3882,5494]\",\"{\"\"key1\"\":\"\"fYMgi49MuZ\"\",\"\"key2\"\":\"\"tEZ0xIaoWn\"\",\"\"key3\"\":\"\"jLyevsUqXL\"\",\"\"key4\"\":\"\"EcbkujjhB0\"\"}\",\"{\"\"id\"\":\"\"kstoy\"\",\"\"val1\"\":\"\"mndgw\"\",\"\"val2\"\":\"\"elnir\"\"}\",yiezdlzhndhzkum,wfomgoetsc,2001-01-11 00:00:00,8,-179.763157,a,'a',\"\"\"a\"\"\",\ud83d\ude00,\u0633\u064a\u0647\u062f\u064a\u0647 ,DE NO\u00cbL ,\u05e9\u05d0-\u05e0\u05d5\u05e8\r\n+1462738431,-14,6340,634171097409536,1516.799316406,5888.129773498,9240.135,false,kypzqcadqz,2000-03-16 18:38:10,qwalydjzhtcfqbssmydjzuycysoccw==,\"[7760,604,4336,4251]\",\"{\"\"key1\"\":\"\"LPd7EsQfFI\"\",\"\"key2\"\":\"\"Z3oIisw6Ai\"\",\"\"key3\"\":\"\"vRPV7oKuhy\"\",\"\"key4\"\":\"\"wh0uRNvY8Z\"\"}\",\"{\"\"id\"\":\"\"fgbqy\"\",\"\"val1\"\":\"\"dvebf\"\",\"\"val2\"\":\"\"aqdbf\"\"}\",ceqzycmpezypklu,zxcqjyiqhy,2001-04-30 00:00:00,15,123.45678,g,'g',\"\"\"g\"\"\",\ud83d\ude0a, \u0642\u0627\u0626\u0644\u0627\u064b,CUISINE LE D\u00ceNER ,\u05d0\u05d9\u05ea\u05de\u05e8\r\n+2032854015,124,-6867,2971557475748552,7684.747070313,2829.404176599,7425.072,true,ynuxibyskr,1971-10-01 22:22:22,omgtgdmmqaigfmohmdorwphgpbeydw==,\"[4041,7619,1172,9022,2349,2213,5804,1965,4390,4060,2752]\",\"{\"\"key1\"\":\"\"ZIrea4F10F\"\",\"\"key2\"\":\"\"xCQ6E60w71\"\",\"\"key3\"\":\"\"S7sa9dvHDG\"\",\"\"key4\"\":\"\"oOp7CL6LhN\"\"}\",\"{\"\"id\"\":\"\"xuoiw\"\",\"\"val1\"\":\"\"jroyf\"\",\"\"val2\"\":\"\"ihmni\"\"}\",eiwcmxrrdqllsyr,pcddgowuzv,1997-05-31 00:00:00,20,-4.940656,t,'t',\"\"\"t\"\"\",\ud83c\udf40,\u0648\u0623\u0639\u0644\u0646 ,FRAN\u00c7AISE ,\u05de\u05d1\u05d5\u05d0 \u05d3\u05d5\u05ea\u05df\r\n+1805124607,91,6447,2525964422257088,8623.229492188,8118.9394035,8176.205,false,ruszqcqjwp,1976-11-24 00:31:34,ukmdhvhsbxvjpbowkzlgegaqgzpbog==,\"[5599,972,9379,351,4476,8111,5519,5949,4540,848,1050,5422,767,7645,4393,8164,4643,3916,3250]\",\"{\"\"key1\"\":\"\"dU3uIQ8NM1\"\",\"\"key2\"\":\"\"v482CaKybl\"\",\"\"key3\"\":\"\"uabKB3zls9\"\",\"\"key4\"\":\"\"5KzVA5ivwz\"\"}\",\"{\"\"id\"\":\"\"ttzkh\"\",\"\"val1\"\":\"\"kcavj\"\",\"\"val2\"\":\"\"wkclh\"\"}\",agyrupinwbeztta,lwhbibqmws,1978-03-31 00:00:00,17,1.7976e+30,d,'d',\"\"\"d\"\"\",\ud83c\udf89,  \u0641\u0631\u0641\u0636\u0647\u0627,FRAN\u00c7AISE ,\u05db\u05e4\u05e8 \u05ea\u05e4\u05d5\u05d7\r\n+-1057157632,-77,-17825,6684227018091776,3754.662353516,1227.72216854,7412.237,true,iwaigqusuc,1996-12-26 01:28:37,ccxpeexihihokaudhmuplzphtfccdQ==,\"[9781,9643]\",\"{\"\"key1\"\":\"\"PjgjuUKVC4\"\",\"\"key2\"\":\"\"9nGNkoyTfb\"\",\"\"key3\"\":\"\"UcWQ9Yk3ff\"\",\"\"key4\"\":\"\"ZOG77yFk4S\"\"}\",\"{\"\"id\"\":\"\"sosyf\"\",\"\"val1\"\":\"\"ujhrt\"\",\"\"val2\"\":\"\"rjxza\"\"}\",kqwyafcfaclzfgg,jtscynuscn,1975-06-02 00:00:00,3,-17976157000000,y,'y',\"\"\"y\"\"\",\ud83d\udcd5,\u0623\u0646\u0647 ,CUISINE LE D\u00ceNER ,\u05d0\u05dc\u05d5\u05df \u05de\u05d5\u05e8\u05d4\r\n+268149759,25,26299,863534107491584,4555.274414063,779.365301495,2038.987,false,kycfdgtzsu,1997-06-29 02:57:33,ywycfpatthdxjswjtizeahtpojyybQ==,\"[7165,780,4823,5610,8150,9640,2670,4954,3538]\",\"{\"\"key1\"\":\"\"qegPrwEXxt\"\",\"\"key2\"\":\"\"AZhgaO5l7R\"\",\"\"key3\"\":\"\"TjQeE1T5r4\"\",\"\"key4\"\":\"\"7iMEn717cy\"\"}\",\"{\"\"id\"\":\"\"gwpdl\"\",\"\"val1\"\":\"\"niwzf\"\",\"\"val2\"\":\"\"lnica\"\"}\",ucatyvfobyjejgq,wxfbvcvspp,1972-02-21 00:00:00,11,-7.4423e-12,w,'w',\"\"\"w\"\"\",\ud83c\udf4e,\u0623\u0645\u0627\u0645 ,EN D\u00c9CEMBRE,\u05d2\u05e0\u05d9\u05dd\r\n+-669752208,-47,-15665,4986790849161728,3570.342041016,7889.261249401,3128.891,true,wnhbaiojlo,1972-06-13 22:37:55,qetzsvpouvqqhgelfbzdzqymgficdQ==,\"[8466,6224,483,2088,8626]\",\"{\"\"key1\"\":\"\"DHI5hSpnD8\"\",\"\"key2\"\":\"\"ZX1CFWZaEe\"\",\"\"key3\"\":\"\"4TkLHzJLoN\"\",\"\"key4\"\":\"\"xYjtvEEQ7o\"\"}\",\"{\"\"id\"\":\"\"zakhb\"\",\"\"val1\"\":\"\"welnn\"\",\"\"val2\"\":\"\"xzkms\"\"}\",ygoubokubqbesfz,ppphdtzkbs,1990-04-11 00:00:00,7,-1797.23157,d,'d',\"\"\"d\"\"\",\u23fa,\u062f\u0639\u0648\u062a\u0647,CUISINE LE D\u00ceNER ,\u05d1\u05d9\u05ea \u05d7\u05d2\u05d9 \u05d7\u05d2\u05d9\r\n+null,null,,,,,,,,,,,\"\"\"\"\"\",,,,,,,,,,,,,\r\n+,null,-15906,5035218741361664,1292.412231445,5799.643102009,5292.029,false,!@#$%^&*(),1990-08-05 15:20:03,ukuclnqrqmzfoawrawqyrxhucmiskw==,\"[3697,4006,8856,2643,8157,3966,3652,9256,6544,218,6844]\",\"{\"\"key1\"\":\"\"NMkbDREYfH\"\",\"\"key2\"\":\"\"hd7X3zO3Pk\"\",\"\"key3\"\":\"\"Z9ZIyZs59c\"\",\"\"key4\"\":\"\"SZzGskMufb\"\"}\",\"{\"\"id\"\":\"\"sjrod\"\",\"\"val1\"\":\"\"qdlhr\"\",\"\"val2\"\":\"\"dvegw\"\"}\",iumixtiqivrwyrw,kycsmrupwf,1986-11-25 00:00:00,19,,q,'q',\"\"\"q\"\"\",\u2705,\u0644\u0628\u0649,M\u00c8RE ,\u05e8\u05d7\u05dc\u05d9\u05dd\r\n+-955939840,13,28595,4458733335951872,8748.717773438,1547.018290286,2994.118,false,ommetzkgoe,1970-04-26 07:48:00,ayrbgvzejhwqfsczxcrygqcedbqetw==,,\"{\"\"key1\"\":\"\"ze4uTLJCIS\"\",\"\"key2\"\":\"\"KJvGWmVD4k\"\",\"\"key3\"\":\"\"EAj5tjtJIY\"\",\"\"key4\"\":\"\"sGZyLdFZTL\"\"}\",\"{\"\"id\"\":\"\"zavzf\"\",\"\"val1\"\":\"\"cvpte\"\",\"\"val2\"\":\"\"wpihw\"\"}\",waoexcjeezmxrsi,scnzxnuxan,1985-04-11 00:00:00,4,-4123000000000,r,'r',\"\"\"r\"\"\",\ud83c\udf8a,\u0645\u0646\u0632\u0644\u0647,M\u00c8RE ,\u05de\u05d2\u05d3\u05dc\u05d9\u05dd\r\n+-946041088,20,4028,6488644051956704,2068.969238281,6867.608431199,2096.338,false,aftxkrhbse,1995-07-21 00:19:48,okvcbxnhykbxgmodzdwgybzwioikng==,[606],\"{\"\"key1\"\":\"\"lh6d4g6AdX\"\",\"\"key2\"\":\"\"m7NXz1Drky\"\",\"\"key3\"\":\"\"PE0h2QSxpA\"\",\"\"key4\"\":\"\"6R2Esbvp9X\"\"}\",\"{\"\"id\"\":\"\"uegms\"\",\"\"val1\"\":\"\"grjhb\"\",\"\"val2\"\":\"\"wzptz\"\"}\",ukampuhnwymbxok,pwumbaiqhj,1980-08-31 00:00:00,5,-4123000000000,s,'s',\"\"\"s\"\"\",\u2b07\ufe0f,\u0645\u0627\u062a\u062c\u064a\u0646\u064a,M\u00c8RE ,\u05d7\u05d5\u05de\u05e9\r\n+190064639,85,-16861,745854179121920,3006.978027344,5300.161841,590.341,false,pwpphjeqey,1971-11-03 14:46:40,csdhfkmtpzkznemtvmumlbcetlgfqg==,\"[4828,2281]\",\"{\"\"key1\"\":\"\"381OAMa9cm\"\",\"\"key2\"\":\"\"kVqFCSMW5N\"\",\"\"key3\"\":\"\"SORmXvLRX2\"\",\"\"key4\"\":\"\"yjMtCtXnrM\"\"}\",\"{\"\"id\"\":\"\"bqodb\"\",\"\"val1\"\":\"\"mnxzv\"\",\"\"val2\"\":\"\"uebln\"\"}\",qumqyheavhhvwkc,lbidykbvuz,1977-12-01 00:00:00,10,-7.4423e-12,s,'s',\"\"\"s\"\"\",\u26a0\ufe0f,\u0648\u0648\u0642\u0641,DE NO\u00cbL ,\u05e2\u05e0\u05d1\r\n+-1355749376,28,-6594,6217661610739712,1575.131469727,4710.247816849,719.935,false,wkrxvnrrmw,1977-04-11 02:09:53,qiutbarcseuaqboaojdlihgwvwiqwQ==,\"[7066,6223,9555,9906,8967,4096,2286,9385,4793,2865,57,7801,1261,5671,8650,8967,7999,7792,2867]\",\"{\"\"key1\"\":\"\"HlwjPoYNOZ\"\",\"\"key2\"\":\"\"hnbly8aGKW\"\",\"\"key3\"\":\"\"2nSgdIRftI\"\",\"\"key4\"\":\"\"8sxcVvxtbj\"\"}\",\"{\"\"id\"\":\"\"hwuon\"\",\"\"val1\"\":\"\"wuuon\"\",\"\"val2\"\":\"\"icggg\"\"}\",gmmgstuttnbjxpy,vhdgledyvc,1994-10-13 00:00:00,2,-1.2345678e+22,m,'m',\"\"\"m\"\"\",\u2764\ufe0f,\u062f\u0639\u0648\u062a\u0647,EN D\u00c9CEMBRE,\u05e0\u05d2\u05d5\u05d4\u05d5\u05ea\r\n+623428607,52,-12058,1099140924791552,1668.521118164,7082.408967932,3390.096,false,dyspcsmwhq,1979-11-10 12:56:35,eydynjfcrsmjwwcjyqtcwskjmaulyg==,\"[1826,8833,371,2946,1848,661,3918,7866,3517,9457,3681]\",\"{\"\"key1\"\":\"\"BahZ52XrL1\"\",\"\"key2\"\":\"\"ZP6eRPsIEd\"\",\"\"key3\"\":\"\"VBMjjPITQw\"\",\"\"key4\"\":\"\"1rSnwpb9sq\"\"}\",\"{\"\"id\"\":\"\"bfggr\"\",\"\"val1\"\":\"\"nxflc\"\",\"\"val2\"\":\"\"elsjm\"\"}\",gqouiupeqligvhn,ykwavphlbv,2002-01-11 00:00:00,13,4.94065e-32,d,'d',\"\"\"d\"\"\",\ud83d\udfe8, \u062e\u0627\u0635\u0629,M\u00c8RE ,\u05d4\u05e8 \u05d1\u05e8\u05db\u05d4 \u05d1\u05e8\u05db\u05d4\r\n+340231167,-103,32314,6727076822845952,490.876434326,521.782040839,689.131,false,ynbspwxszn,2006-09-11 04:44:46,yybegwugseeyfyyzzxssndxpceskbg==,\"[7387,5827,3530,5417,2764,3977,7112,6065,2894,6651,9171,6785,5125]\",\"{\"\"key1\"\":\"\"SL6KOlo6yS\"\",\"\"key2\"\":\"\"6hwmQ2uKSH\"\",\"\"key3\"\":\"\"ECjxaAa7Su\"\",\"\"key4\"\":\"\"OY8xWw8ut0\"\"}\",\"{\"\"id\"\":\"\"avewu\"\",\"\"val1\"\":\"\"rttto\"\",\"\"val2\"\":\"\"mndbq\"\"}\",gmknpbmxtkuyfvw,rzxfoedloj,1999-07-03 00:00:00,12,-7.4423e-12,a,'a',\"\"\"a\"\"\",\ud83d\udcdd,\u0627\u0644\u0637\u0644\u0627\u0642 ,EN D\u00c9CEMBRE,\u05d7\u05e8\u05de\u05e9\r\n+59571531,-120,2726,499568922236435,5693.273925781,831.917259298,5970.561,false,srcyitzady,1976-01-17 22:33:07,uomxckzjwvhrhuqvxvjmntzosoyudQ==,\"[1663,9022,6558]\",\"{\"\"key1\"\":\"\"GqtZfwU56W\"\",\"\"key2\"\":\"\"hjDJcwofzW\"\",\"\"key3\"\":\"\"wAS2lqzSh0\"\",\"\"key4\"\":\"\"ieeRmIe0pZ\"\"}\",\"{\"\"id\"\":\"\"jmsyp\"\",\"\"val1\"\":\"\"tjrjc\"\",\"\"val2\"\":\"\"fwuue\"\"}\",ekatpkqdtbrdopr,vsusznjtum,2002-01-30 00:00:00,9,-0.00445124654,g,'g',\"\"\"g\"\"\",\ud83d\udd37,\u0635\u062f\u064a\u0642\u0647,FRAN\u00c7AISE ,\u05e7\u05d3\u05d9\u05dd\r\n+955388927,36,-14711,234259271632640,5292.765136719,821.385383988,8358.519,true,krzqufbilr,2012-10-22 05:07:34,owkzlgegaqgzpbomgtgdmmqaigfmog==,\"[4974,9911,5595,6472,7765,1797,1908,1014,5229]\",\"{\"\"key1\"\":\"\"xydc0YQBBL\"\",\"\"key2\"\":\"\"8tW4c8Gm4M\"\",\"\"key3\"\":\"\"aGblhlIIrx\"\",\"\"key4\"\":\"\"v30H3CJPMy\"\"}\",\"{\"\"id\"\":\"\"eqoya\"\",\"\"val1\"\":\"\"ypims\"\",\"\"val2\"\":\"\"blsod\"\"}\",sumfztrbmpwkjon,bypzxafltm,2013-06-15 00:00:00,14,7.4423e-12,j,'j',\"\"\"j\"\"\",\ud83c\udd97, \u0639\u0644\u064a ,DE NO\u00cbL ,\u05e9\u05d1\u05d9 \u05e9\u05d5\u05de\u05e8\u05d5\u05df\r\n+1838367743,-76,7387,2747089955464832,8975.13671875,704.915821881,272.055,true,ouxvftfobi,1971-06-30 18:49:15,acidfzuquvceiuuzqqvnljpljdcnzg==,\"[9936,6185,781,912,2509,4330]\",\"{\"\"key1\"\":\"\"94j6CTgyit\"\",\"\"key2\"\":\"\"smHeSsm3fX\"\",\"\"key3\"\":\"\"PD7ADcq9JW\"\",\"\"key4\"\":\"\"eqjA1uBW3e\"\"}\",\"{\"\"id\"\":\"\"gmimc\"\",\"\"val1\"\":\"\"oyksy\"\",\"\"val2\"\":\"\"bavue\"\"}\",aowrnboisicvkex,rucsmrzxvu,2011-09-01 00:00:00,18,1.79769e+308,w,'w',\"\"\"w\"\"\",\u274c,\u0635\u062f\u064a\u0642\u0647,FRAN\u00c7AISE ,\u05e1\u05e0\u05e1\u05e0\u05d4\r\n+-703343616,19,7048,1887435007823552,3118.254150391,3798.277379851,1502.739,true,hwhwhwafby,2008-03-06 02:00:46,wwcjyqtcwskjmaulygxoqwfedjiyrg==,\"[4259,717,7166,7868,1323,4157,6358,6232,2556,9900,3363,6799,60,5880,7990,4743,8200,5670,6079]\",\"{\"\"key1\"\":\"\"XIVSXvg33a\"\",\"\"key2\"\":\"\"2HsXhn6Ee2\"\",\"\"key3\"\":\"\"03o5vQeeLf\"\",\"\"key4\"\":\"\"GzX7WcQrRx\"\"}\",\"{\"\"id\"\":\"\"hryfw\"\",\"\"val1\"\":\"\"wkcgw\"\",\"\"val2\"\":\"\"sjmns\"\"}\",yyshjqkviglwvhz,uclwpzskje,1983-03-28 00:00:00,6,-179623157,t,'t',\"\"\"t\"\"\",\u2757\ufe0f,\u0648\u0648\u0642\u0641,DE NO\u00cbL ,\u05ea\u05dc\u05dd\r\n+1671645295,-54,12191,8891823575776256,4349.600097656,5313.086512179,9153.266,false,htxiqenedt,1999-03-30 20:05:28,iskynmcvdrnpbysmtjkcguptilqefw==,,\"{\"\"key1\"\":\"\"3badsBTnEu\"\",\"\"key2\"\":\"\"w2t7fCA5if\"\",\"\"key3\"\":\"\"jiavckw8PW\"\",\"\"key4\"\":\"\"21LcTl7GEk\"\"}\",\"{\"\"id\"\":\"\"wpica\"\",\"\"val1\"\":\"\"wptoy\"\",\"\"val2\"\":\"\"iryuo\"\"}\",oeshqwtudywyksw,qenziyaaqm,2003-03-16 00:00:00,16,1.2345678e+22,e,'e',\"\"\"e\"\"\",\u270f\ufe0f,\u062f\u0639\u0648\u062a\u0647,CUISINE LE D\u00ceNER ,\u05d9\u05e6\u05d4\u05e8\r\n+-1684013568,118,-24306,7313791764174080,287.703582764,3151.620627917,6181.187,true,nohqcyneqj,1970-11-10 05:03:07,ccdehmtplyzrksyweivpvhyvmlywyQ==,\"[5533,9469,8400,1236,26,9435]\",\"{\"\"key1\"\":\"\"vyMNJLBCZ8\"\",\"\"key2\"\":\"\"Jh7CiBItY8\"\",\"\"key3\"\":\"\"bESrtP2bb7\"\",\"\"key4\"\":\"\"wTaLbfFDcs\"\"}\",\"{\"\"id\"\":\"\"bavjh\"\",\"\"val1\"\":\"\"pnnih\"\",\"\"val2\"\":\"\"vjrjh\"\"}\",igizjxvkxfvbfca,zdvpuszdnh,2013-03-24 00:00:00,1,-1.2345678e+22,s,'s',\"\"\"s\"\"\",\ud83d\ude21,\u0647\u062f\u064a\u0629,EN D\u00c9CEMBRE,\u05d0\u05d1\u05e0\u05d9 \u05d7\u05e4\u05e5\r\n+12284927,50,-23596,3090497741838080,7133.937988281,1689.871550393,361.979,false,nucvnzflzq,1982-03-01 14:38:42,mohmdorwphgpbeydynjfcrsmjwwcjw==,\"[4116,3479,1659,585,1774,9875,6875,2468,9124,3381,2819,7152,8430,9381,3429,3882,5494]\",\"{\"\"key1\"\":\"\"fYMgi49MuZ\"\",\"\"key2\"\":\"\"tEZ0xIaoWn\"\",\"\"key3\"\":\"\"jLyevsUqXL\"\",\"\"key4\"\":\"\"EcbkujjhB0\"\"}\",\"{\"\"id\"\":\"\"kstoy\"\",\"\"val1\"\":\"\"mndgw\"\",\"\"val2\"\":\"\"elnir\"\"}\",yiezdlzhndhzkum,wfomgoetsc,2001-01-11 00:00:00,8,-179.763157,a,'a',\"\"\"a\"\"\",\ud83d\ude00,\u0633\u064a\u0647\u062f\u064a\u0647 ,DE NO\u00cbL ,\u05e9\u05d0-\u05e0\u05d5\u05e8\r\n+1462738431,-14,6340,634171097409536,1516.799316406,5888.129773498,9240.135,false,kypzqcadqz,2000-03-16 18:38:10,qwalydjzhtcfqbssmydjzuycysoccw==,\"[7760,604,4336,4251]\",\"{\"\"key1\"\":\"\"LPd7EsQfFI\"\",\"\"key2\"\":\"\"Z3oIisw6Ai\"\",\"\"key3\"\":\"\"vRPV7oKuhy\"\",\"\"key4\"\":\"\"wh0uRNvY8Z\"\"}\",\"{\"\"id\"\":\"\"fgbqy\"\",\"\"val1\"\":\"\"dvebf\"\",\"\"val2\"\":\"\"aqdbf\"\"}\",ceqzycmpezypklu,zxcqjyiqhy,2001-04-30 00:00:00,15,123.45678,g,'g',\"\"\"g\"\"\",\ud83d\ude0a, \u0642\u0627\u0626\u0644\u0627\u064b,CUISINE LE D\u00ceNER ,\u05d0\u05d9\u05ea\u05de\u05e8\r\n+2032854015,124,-6867,2971557475748552,7684.747070313,2829.404176599,7425.072,true,ynuxibyskr,1971-10-01 22:22:22,omgtgdmmqaigfmohmdorwphgpbeydw==,\"[4041,7619,1172,9022,2349,2213,5804,1965,4390,4060,2752]\",\"{\"\"key1\"\":\"\"ZIrea4F10F\"\",\"\"key2\"\":\"\"xCQ6E60w71\"\",\"\"key3\"\":\"\"S7sa9dvHDG\"\",\"\"key4\"\":\"\"oOp7CL6LhN\"\"}\",\"{\"\"id\"\":\"\"xuoiw\"\",\"\"val1\"\":\"\"jroyf\"\",\"\"val2\"\":\"\"ihmni\"\"}\",eiwcmxrrdqllsyr,pcddgowuzv,1997-05-31 00:00:00,20,-4.940656,t,'t',\"\"\"t\"\"\",\ud83c\udf40,\u0648\u0623\u0639\u0644\u0646 ,FRAN\u00c7AISE ,\u05de\u05d1\u05d5\u05d0 \u05d3\u05d5\u05ea\u05df\r\n+1805124607,91,6447,2525964422257088,8623.229492188,8118.9394035,8176.205,false,ruszqcqjwp,1976-11-24 00:31:34,ukmdhvhsbxvjpbowkzlgegaqgzpbog==,\"[5599,972,9379,351,4476,8111,5519,5949,4540,848,1050,5422,767,7645,4393,8164,4643,3916,3250]\",\"{\"\"key1\"\":\"\"dU3uIQ8NM1\"\",\"\"key2\"\":\"\"v482CaKybl\"\",\"\"key3\"\":\"\"uabKB3zls9\"\",\"\"key4\"\":\"\"5KzVA5ivwz\"\"}\",\"{\"\"id\"\":\"\"ttzkh\"\",\"\"val1\"\":\"\"kcavj\"\",\"\"val2\"\":\"\"wkclh\"\"}\",agyrupinwbeztta,lwhbibqmws,1978-03-31 00:00:00,17,1.7976e+30,d,'d',\"\"\"d\"\"\",\ud83c\udf89,  \u0641\u0631\u0641\u0636\u0647\u0627,FRAN\u00c7AISE ,\u05db\u05e4\u05e8 \u05ea\u05e4\u05d5\u05d7\r\n+-1057157632,-77,-17825,6684227018091776,3754.662353516,1227.72216854,7412.237,true,iwaigqusuc,1996-12-26 01:28:37,ccxpeexihihokaudhmuplzphtfccdQ==,\"[9781,9643]\",\"{\"\"key1\"\":\"\"PjgjuUKVC4\"\",\"\"key2\"\":\"\"9nGNkoyTfb\"\",\"\"key3\"\":\"\"UcWQ9Yk3ff\"\",\"\"key4\"\":\"\"ZOG77yFk4S\"\"}\",\"{\"\"id\"\":\"\"sosyf\"\",\"\"val1\"\":\"\"ujhrt\"\",\"\"val2\"\":\"\"rjxza\"\"}\",kqwyafcfaclzfgg,jtscynuscn,1975-06-02 00:00:00,3,-17976157000000,y,'y',\"\"\"y\"\"\",\ud83d\udcd5,\u0623\u0646\u0647 ,CUISINE LE D\u00ceNER ,\u05d0\u05dc\u05d5\u05df \u05de\u05d5\u05e8\u05d4\r\n+268149759,25,26299,863534107491584,4555.274414063,779.365301495,2038.987,false,kycfdgtzsu,1997-06-29 02:57:33,ywycfpatthdxjswjtizeahtpojyybQ==,\"[7165,780,4823,5610,8150,9640,2670,4954,3538]\",\"{\"\"key1\"\":\"\"qegPrwEXxt\"\",\"\"key2\"\":\"\"AZhgaO5l7R\"\",\"\"key3\"\":\"\"TjQeE1T5r4\"\",\"\"key4\"\":\"\"7iMEn717cy\"\"}\",\"{\"\"id\"\":\"\"gwpdl\"\",\"\"val1\"\":\"\"niwzf\"\",\"\"val2\"\":\"\"lnica\"\"}\",ucatyvfobyjejgq,wxfbvcvspp,1972-02-21 00:00:00,11,-7.4423e-12,w,'w',\"\"\"w\"\"\",\ud83c\udf4e,\u0623\u0645\u0627\u0645 ,EN D\u00c9CEMBRE,\u05d2\u05e0\u05d9\u05dd\r\n+-669752208,-47,-15665,4986790849161728,3570.342041016,7889.261249401,3128.891,true,wnhbaiojlo,1972-06-13 22:37:55,qetzsvpouvqqhgelfbzdzqymgficdQ==,\"[8466,6224,483,2088,8626]\",\"{\"\"key1\"\":\"\"DHI5hSpnD8\"\",\"\"key2\"\":\"\"ZX1CFWZaEe\"\",\"\"key3\"\":\"\"4TkLHzJLoN\"\",\"\"key4\"\":\"\"xYjtvEEQ7o\"\"}\",\"{\"\"id\"\":\"\"zakhb\"\",\"\"val1\"\":\"\"welnn\"\",\"\"val2\"\":\"\"xzkms\"\"}\",ygoubokubqbesfz,ppphdtzkbs,1990-04-11 00:00:00,7,-1797.23157,d,'d',\"\"\"d\"\"\",\u23fa,\u062f\u0639\u0648\u062a\u0647,CUISINE LE D\u00ceNER ,\u05d1\u05d9\u05ea \u05d7\u05d2\u05d9 \u05d7\u05d2\u05d9\r\n+null,null,,,,,,,,,,,\"\"\"\"\"\",,,,,,,,,,,,,\r\n+,null,-15906,5035218741361664,1292.412231445,5799.643102009,5292.029,false,!@#$%^&*(),1990-08-05 15:20:03,ukuclnqrqmzfoawrawqyrxhucmiskw==,\"[3697,4006,8856,2643,8157,3966,3652,9256,6544,218,6844]\",\"{\"\"key1\"\":\"\"NMkbDREYfH\"\",\"\"key2\"\":\"\"hd7X3zO3Pk\"\",\"\"key3\"\":\"\"Z9ZIyZs59c\"\",\"\"key4\"\":\"\"SZzGskMufb\"\"}\",\"{\"\"id\"\":\"\"sjrod\"\",\"\"val1\"\":\"\"qdlhr\"\",\"\"val2\"\":\"\"dvegw\"\"}\",iumixtiqivrwyrw,kycsmrupwf,1986-11-25 00:00:00,19,,q,'q',\"\"\"q\"\"\",\u2705,\u0644\u0628\u0649,M\u00c8RE ,\u05e8\u05d7\u05dc\u05d9\u05dd\r\n+-955939840,13,28595,4458733335951872,8748.717773438,1547.018290286,2994.118,false,ommetzkgoe,1970-04-26 07:48:00,ayrbgvzejhwqfsczxcrygqcedbqetw==,,\"{\"\"key1\"\":\"\"ze4uTLJCIS\"\",\"\"key2\"\":\"\"KJvGWmVD4k\"\",\"\"key3\"\":\"\"EAj5tjtJIY\"\",\"\"key4\"\":\"\"sGZyLdFZTL\"\"}\",\"{\"\"id\"\":\"\"zavzf\"\",\"\"val1\"\":\"\"cvpte\"\",\"\"val2\"\":\"\"wpihw\"\"}\",waoexcjeezmxrsi,scnzxnuxan,1985-04-11 00:00:00,4,-4123000000000,r,'r',\"\"\"r\"\"\",\ud83c\udf8a,\u0645\u0646\u0632\u0644\u0647,M\u00c8RE ,\u05de\u05d2\u05d3\u05dc\u05d9\u05dd\r\n+-946041088,20,4028,6488644051956704,2068.969238281,6867.608431199,2096.338,false,aftxkrhbse,1995-07-21 00:19:48,okvcbxnhykbxgmodzdwgybzwioikng==,[606],\"{\"\"key1\"\":\"\"lh6d4g6AdX\"\",\"\"key2\"\":\"\"m7NXz1Drky\"\",\"\"key3\"\":\"\"PE0h2QSxpA\"\",\"\"key4\"\":\"\"6R2Esbvp9X\"\"}\",\"{\"\"id\"\":\"\"uegms\"\",\"\"val1\"\":\"\"grjhb\"\",\"\"val2\"\":\"\"wzptz\"\"}\",ukampuhnwymbxok,pwumbaiqhj,1980-08-31 00:00:00,5,-4123000000000,s,'s',\"\"\"s\"\"\",\u2b07\ufe0f,\u0645\u0627\u062a\u062c\u064a\u0646\u064a,M\u00c8RE ,\u05d7\u05d5\u05de\u05e9\r\n+190064639,85,-16861,745854179121920,3006.978027344,5300.161841,590.341,false,pwpphjeqey,1971-11-03 14:46:40,csdhfkmtpzkznemtvmumlbcetlgfqg==,\"[4828,2281]\",\"{\"\"key1\"\":\"\"381OAMa9cm\"\",\"\"key2\"\":\"\"kVqFCSMW5N\"\",\"\"key3\"\":\"\"SORmXvLRX2\"\",\"\"key4\"\":\"\"yjMtCtXnrM\"\"}\",\"{\"\"id\"\":\"\"bqodb\"\",\"\"val1\"\":\"\"mnxzv\"\",\"\"val2\"\":\"\"uebln\"\"}\",qumqyheavhhvwkc,lbidykbvuz,1977-12-01 00:00:00,10,-7.4423e-12,s,'s',\"\"\"s\"\"\",\u26a0\ufe0f,\u0648\u0648\u0642\u0641,DE NO\u00cbL ,\u05e2\u05e0\u05d1\r\n+-1355749376,28,-6594,6217661610739712,1575.131469727,4710.247816849,719.935,false,wkrxvnrrmw,1977-04-11 02:09:53,qiutbarcseuaqboaojdlihgwvwiqwQ==,\"[7066,6223,9555,9906,8967,4096,2286,9385,4793,2865,57,7801,1261,5671,8650,8967,7999,7792,2867]\",\"{\"\"key1\"\":\"\"HlwjPoYNOZ\"\",\"\"key2\"\":\"\"hnbly8aGKW\"\",\"\"key3\"\":\"\"2nSgdIRftI\"\",\"\"key4\"\":\"\"8sxcVvxtbj\"\"}\",\"{\"\"id\"\":\"\"hwuon\"\",\"\"val1\"\":\"\"wuuon\"\",\"\"val2\"\":\"\"icggg\"\"}\",gmmgstuttnbjxpy,vhdgledyvc,1994-10-13 00:00:00,2,-1.2345678e+22,m,'m',\"\"\"m\"\"\",\u2764\ufe0f,\u062f\u0639\u0648\u062a\u0647,EN D\u00c9CEMBRE,\u05e0\u05d2\u05d5\u05d4\u05d5\u05ea\r\n+623428607,52,-12058,1099140924791552,1668.521118164,7082.408967932,3390.096,false,dyspcsmwhq,1979-11-10 12:56:35,eydynjfcrsmjwwcjyqtcwskjmaulyg==,\"[1826,8833,371,2946,1848,661,3918,7866,3517,9457,3681]\",\"{\"\"key1\"\":\"\"BahZ52XrL1\"\",\"\"key2\"\":\"\"ZP6eRPsIEd\"\",\"\"key3\"\":\"\"VBMjjPITQw\"\",\"\"key4\"\":\"\"1rSnwpb9sq\"\"}\",\"{\"\"id\"\":\"\"bfggr\"\",\"\"val1\"\":\"\"nxflc\"\",\"\"val2\"\":\"\"elsjm\"\"}\",gqouiupeqligvhn,ykwavphlbv,2002-01-11 00:00:00,13,4.94065e-32,d,'d',\"\"\"d\"\"\",\ud83d\udfe8, \u062e\u0627\u0635\u0629,M\u00c8RE ,\u05d4\u05e8 \u05d1\u05e8\u05db\u05d4 \u05d1\u05e8\u05db\u05d4\r\n+340231167,-103,32314,6727076822845952,490.876434326,521.782040839,689.131,false,ynbspwxszn,2006-09-11 04:44:46,yybegwugseeyfyyzzxssndxpceskbg==,\"[7387,5827,3530,5417,2764,3977,7112,6065,2894,6651,9171,6785,5125]\",\"{\"\"key1\"\":\"\"SL6KOlo6yS\"\",\"\"key2\"\":\"\"6hwmQ2uKSH\"\",\"\"key3\"\":\"\"ECjxaAa7Su\"\",\"\"key4\"\":\"\"OY8xWw8ut0\"\"}\",\"{\"\"id\"\":\"\"avewu\"\",\"\"val1\"\":\"\"rttto\"\",\"\"val2\"\":\"\"mndbq\"\"}\",gmknpbmxtkuyfvw,rzxfoedloj,1999-07-03 00:00:00,12,-7.4423e-12,a,'a',\"\"\"a\"\"\",\ud83d\udcdd,\u0627\u0644\u0637\u0644\u0627\u0642 ,EN D\u00c9CEMBRE,\u05d7\u05e8\u05de\u05e9\r\n+59571531,-120,2726,499568922236435,5693.273925781,831.917259298,5970.561,false,srcyitzady,1976-01-17 22:33:07,uomxckzjwvhrhuqvxvjmntzosoyudQ==,\"[1663,9022,6558]\",\"{\"\"key1\"\":\"\"GqtZfwU56W\"\",\"\"key2\"\":\"\"hjDJcwofzW\"\",\"\"key3\"\":\"\"wAS2lqzSh0\"\",\"\"key4\"\":\"\"ieeRmIe0pZ\"\"}\",\"{\"\"id\"\":\"\"jmsyp\"\",\"\"val1\"\":\"\"tjrjc\"\",\"\"val2\"\":\"\"fwuue\"\"}\",ekatpkqdtbrdopr,vsusznjtum,2002-01-30 00:00:00,9,-0.00445124654,g,'g',\"\"\"g\"\"\",\ud83d\udd37,\u0635\u062f\u064a\u0642\u0647,FRAN\u00c7AISE ,\u05e7\u05d3\u05d9\u05dd\r\n+955388927,36,-14711,234259271632640,5292.765136719,821.385383988,8358.519,true,krzqufbilr,2012-10-22 05:07:34,owkzlgegaqgzpbomgtgdmmqaigfmog==,\"[4974,9911,5595,6472,7765,1797,1908,1014,5229]\",\"{\"\"key1\"\":\"\"xydc0YQBBL\"\",\"\"key2\"\":\"\"8tW4c8Gm4M\"\",\"\"key3\"\":\"\"aGblhlIIrx\"\",\"\"key4\"\":\"\"v30H3CJPMy\"\"}\",\"{\"\"id\"\":\"\"eqoya\"\",\"\"val1\"\":\"\"ypims\"\",\"\"val2\"\":\"\"blsod\"\"}\",sumfztrbmpwkjon,bypzxafltm,2013-06-15 00:00:00,14,7.4423e-12,j,'j',\"\"\"j\"\"\",\ud83c\udd97, \u0639\u0644\u064a ,DE NO\u00cbL ,\u05e9\u05d1\u05d9 \u05e9\u05d5\u05de\u05e8\u05d5\u05df\r\n+1838367743,-76,7387,2747089955464832,8975.13671875,704.915821881,272.055,true,ouxvftfobi,1971-06-30 18:49:15,acidfzuquvceiuuzqqvnljpljdcnzg==,\"[9936,6185,781,912,2509,4330]\",\"{\"\"key1\"\":\"\"94j6CTgyit\"\",\"\"key2\"\":\"\"smHeSsm3fX\"\",\"\"key3\"\":\"\"PD7ADcq9JW\"\",\"\"key4\"\":\"\"eqjA1uBW3e\"\"}\",\"{\"\"id\"\":\"\"gmimc\"\",\"\"val1\"\":\"\"oyksy\"\",\"\"val2\"\":\"\"bavue\"\"}\",aowrnboisicvkex,rucsmrzxvu,2011-09-01 00:00:00,18,1.79769e+308,w,'w',\"\"\"w\"\"\",\u274c,\u0635\u062f\u064a\u0642\u0647,FRAN\u00c7AISE ,\u05e1\u05e0\u05e1\u05e0\u05d4\r\n+-703343616,19,7048,1887435007823552,3118.254150391,3798.277379851,1502.739,true,hwhwhwafby,2008-03-06 02:00:46,wwcjyqtcwskjmaulygxoqwfedjiyrg==,\"[4259,717,7166,7868,1323,4157,6358,6232,2556,9900,3363,6799,60,5880,7990,4743,8200,5670,6079]\",\"{\"\"key1\"\":\"\"XIVSXvg33a\"\",\"\"key2\"\":\"\"2HsXhn6Ee2\"\",\"\"key3\"\":\"\"03o5vQeeLf\"\",\"\"key4\"\":\"\"GzX7WcQrRx\"\"}\",\"{\"\"id\"\":\"\"hryfw\"\",\"\"val1\"\":\"\"wkcgw\"\",\"\"val2\"\":\"\"sjmns\"\"}\",yyshjqkviglwvhz,uclwpzskje,1983-03-28 00:00:00,6,-179623157,t,'t',\"\"\"t\"\"\",\u2757\ufe0f,\u0648\u0648\u0642\u0641,DE NO\u00cbL ,\u05ea\u05dc\u05dd\r\n+1671645295,-54,12191,8891823575776256,4349.600097656,5313.086512179,9153.266,false,htxiqenedt,1999-03-30 20:05:28,iskynmcvdrnpbysmtjkcguptilqefw==,,\"{\"\"key1\"\":\"\"3badsBTnEu\"\",\"\"key2\"\":\"\"w2t7fCA5if\"\",\"\"key3\"\":\"\"jiavckw8PW\"\",\"\"key4\"\":\"\"21LcTl7GEk\"\"}\",\"{\"\"id\"\":\"\"wpica\"\",\"\"val1\"\":\"\"wptoy\"\",\"\"val2\"\":\"\"iryuo\"\"}\",oeshqwtudywyksw,qenziyaaqm,2003-03-16 00:00:00,16,1.2345678e+22,e,'e',\"\"\"e\"\"\",\u270f\ufe0f,\u062f\u0639\u0648\u062a\u0647,CUISINE LE D\u00ceNER ,\u05d9\u05e6\u05d4\u05e8\r\n+-1684013568,118,-24306,7313791764174080,287.703582764,3151.620627917,6181.187,true,nohqcyneqj,1970-11-10 05:03:07,ccdehmtplyzrksyweivpvhyvmlywyQ==,\"[5533,9469,8400,1236,26,9435]\",\"{\"\"key1\"\":\"\"vyMNJLBCZ8\"\",\"\"key2\"\":\"\"Jh7CiBItY8\"\",\"\"key3\"\":\"\"bESrtP2bb7\"\",\"\"key4\"\":\"\"wTaLbfFDcs\"\"}\",\"{\"\"id\"\":\"\"bavjh\"\",\"\"val1\"\":\"\"pnnih\"\",\"\"val2\"\":\"\"vjrjh\"\"}\",igizjxvkxfvbfca,zdvpuszdnh,2013-03-24 00:00:00,1,-1.2345678e+22,s,'s',\"\"\"s\"\"\",\ud83d\ude21,\u0647\u062f\u064a\u0629,EN D\u00c9CEMBRE,\u05d0\u05d1\u05e0\u05d9 \u05d7\u05e4\u05e5\r\n+12284927,50,-23596,3090497741838080,7133.937988281,1689.871550393,361.979,false,nucvnzflzq,1982-03-01 14:38:42,mohmdorwphgpbeydynjfcrsmjwwcjw==,\"[4116,3479,1659,585,1774,9875,6875,2468,9124,3381,2819,7152,8430,9381,3429,3882,5494]\",\"{\"\"key1\"\":\"\"fYMgi49MuZ\"\",\"\"key2\"\":\"\"tEZ0xIaoWn\"\",\"\"key3\"\":\"\"jLyevsUqXL\"\",\"\"key4\"\":\"\"EcbkujjhB0\"\"}\",\"{\"\"id\"\":\"\"kstoy\"\",\"\"val1\"\":\"\"mndgw\"\",\"\"val2\"\":\"\"elnir\"\"}\",yiezdlzhndhzkum,wfomgoetsc,2001-01-11 00:00:00,8,-179.763157,a,'a',\"\"\"a\"\"\",\ud83d\ude00,\u0633\u064a\u0647\u062f\u064a\u0647 ,DE NO\u00cbL ,\u05e9\u05d0-\u05e0\u05d5\u05e8\r\n+1462738431,-14,6340,634171097409536,1516.799316406,5888.129773498,9240.135,false,kypzqcadqz,2000-03-16 18:38:10,qwalydjzhtcfqbssmydjzuycysoccw==,\"[7760,604,4336,4251]\",\"{\"\"key1\"\":\"\"LPd7EsQfFI\"\",\"\"key2\"\":\"\"Z3oIisw6Ai\"\",\"\"key3\"\":\"\"vRPV7oKuhy\"\",\"\"key4\"\":\"\"wh0uRNvY8Z\"\"}\",\"{\"\"id\"\":\"\"fgbqy\"\",\"\"val1\"\":\"\"dvebf\"\",\"\"val2\"\":\"\"aqdbf\"\"}\",ceqzycmpezypklu,zxcqjyiqhy,2001-04-30 00:00:00,15,123.45678,g,'g',\"\"\"g\"\"\",\ud83d\ude0a, \u0642\u0627\u0626\u0644\u0627\u064b,CUISINE LE D\u00ceNER ,\u05d0\u05d9\u05ea\u05de\u05e8\r\n+2032854015,124,-6867,2971557475748552,7684.747070313,2829.404176599,7425.072,true,ynuxibyskr,1971-10-01 22:22:22,omgtgdmmqaigfmohmdorwphgpbeydw==,\"[4041,7619,1172,9022,2349,2213,5804,1965,4390,4060,2752]\",\"{\"\"key1\"\":\"\"ZIrea4F10F\"\",\"\"key2\"\":\"\"xCQ6E60w71\"\",\"\"key3\"\":\"\"S7sa9dvHDG\"\",\"\"key4\"\":\"\"oOp7CL6LhN\"\"}\",\"{\"\"id\"\":\"\"xuoiw\"\",\"\"val1\"\":\"\"jroyf\"\",\"\"val2\"\":\"\"ihmni\"\"}\",eiwcmxrrdqllsyr,pcddgowuzv,1997-05-31 00:00:00,20,-4.940656,t,'t',\"\"\"t\"\"\",\ud83c\udf40,\u0648\u0623\u0639\u0644\u0646 ,FRAN\u00c7AISE ,\u05de\u05d1\u05d5\u05d0 \u05d3\u05d5\u05ea\u05df\r\n+1805124607,91,6447,2525964422257088,8623.229492188,8118.9394035,8176.205,false,ruszqcqjwp,1976-11-24 00:31:34,ukmdhvhsbxvjpbowkzlgegaqgzpbog==,\"[5599,972,9379,351,4476,8111,5519,5949,4540,848,1050,5422,767,7645,4393,8164,4643,3916,3250]\",\"{\"\"key1\"\":\"\"dU3uIQ8NM1\"\",\"\"key2\"\":\"\"v482CaKybl\"\",\"\"key3\"\":\"\"uabKB3zls9\"\",\"\"key4\"\":\"\"5KzVA5ivwz\"\"}\",\"{\"\"id\"\":\"\"ttzkh\"\",\"\"val1\"\":\"\"kcavj\"\",\"\"val2\"\":\"\"wkclh\"\"}\",agyrupinwbeztta,lwhbibqmws,1978-03-31 00:00:00,17,1.7976e+30,d,'d',\"\"\"d\"\"\",\ud83c\udf89,  \u0641\u0631\u0641\u0636\u0647\u0627,FRAN\u00c7AISE ,\u05db\u05e4\u05e8 \u05ea\u05e4\u05d5\u05d7\r\n+-1057157632,-77,-17825,6684227018091776,3754.662353516,1227.72216854,7412.237,true,iwaigqusuc,1996-12-26 01:28:37,ccxpeexihihokaudhmuplzphtfccdQ==,\"[9781,9643]\",\"{\"\"key1\"\":\"\"PjgjuUKVC4\"\",\"\"key2\"\":\"\"9nGNkoyTfb\"\",\"\"key3\"\":\"\"UcWQ9Yk3ff\"\",\"\"key4\"\":\"\"ZOG77yFk4S\"\"}\",\"{\"\"id\"\":\"\"sosyf\"\",\"\"val1\"\":\"\"ujhrt\"\",\"\"val2\"\":\"\"rjxza\"\"}\",kqwyafcfaclzfgg,jtscynuscn,1975-06-02 00:00:00,3,-17976157000000,y,'y',\"\"\"y\"\"\",\ud83d\udcd5,\u0623\u0646\u0647 ,CUISINE LE D\u00ceNER ,\u05d0\u05dc\u05d5\u05df \u05de\u05d5\u05e8\u05d4\r\n+268149759,25,26299,863534107491584,4555.274414063,779.365301495,2038.987,false,kycfdgtzsu,1997-06-29 02:57:33,ywycfpatthdxjswjtizeahtpojyybQ==,\"[7165,780,4823,5610,8150,9640,2670,4954,3538]\",\"{\"\"key1\"\":\"\"qegPrwEXxt\"\",\"\"key2\"\":\"\"AZhgaO5l7R\"\",\"\"key3\"\":\"\"TjQeE1T5r4\"\",\"\"key4\"\":\"\"7iMEn717cy\"\"}\",\"{\"\"id\"\":\"\"gwpdl\"\",\"\"val1\"\":\"\"niwzf\"\",\"\"val2\"\":\"\"lnica\"\"}\",ucatyvfobyjejgq,wxfbvcvspp,1972-02-21 00:00:00,11,-7.4423e-12,w,'w',\"\"\"w\"\"\",\ud83c\udf4e,\u0623\u0645\u0627\u0645 ,EN D\u00c9CEMBRE,\u05d2\u05e0\u05d9\u05dd\r\n+-669752208,-47,-15665,4986790849161728,3570.342041016,7889.261249401,3128.891,true,wnhbaiojlo,1972-06-13 22:37:55,qetzsvpouvqqhgelfbzdzqymgficdQ==,\"[8466,6224,483,2088,8626]\",\"{\"\"key1\"\":\"\"DHI5hSpnD8\"\",\"\"key2\"\":\"\"ZX1CFWZaEe\"\",\"\"key3\"\":\"\"4TkLHzJLoN\"\",\"\"key4\"\":\"\"xYjtvEEQ7o\"\"}\",\"{\"\"id\"\":\"\"zakhb\"\",\"\"val1\"\":\"\"welnn\"\",\"\"val2\"\":\"\"xzkms\"\"}\",ygoubokubqbesfz,ppphdtzkbs,1990-04-11 00:00:00,7,-1797.23157,d,'d',\"\"\"d\"\"\",\u23fa,\u062f\u0639\u0648\u062a\u0647,CUISINE LE D\u00ceNER ,\u05d1\u05d9\u05ea \u05d7\u05d2\u05d9 \u05d7\u05d2\u05d9\r\n+null,null,,,,,,,,,,,\"\"\"\"\"\",,,,,,,,,,,,,\r\n+,null,-15906,5035218741361664,1292.412231445,5799.643102009,5292.029,false,!@#$%^&*(),1990-08-05 15:20:03,ukuclnqrqmzfoawrawqyrxhucmiskw==,\"[3697,4006,8856,2643,8157,3966,3652,9256,6544,218,6844]\",\"{\"\"key1\"\":\"\"NMkbDREYfH\"\",\"\"key2\"\":\"\"hd7X3zO3Pk\"\",\"\"key3\"\":\"\"Z9ZIyZs59c\"\",\"\"key4\"\":\"\"SZzGskMufb\"\"}\",\"{\"\"id\"\":\"\"sjrod\"\",\"\"val1\"\":\"\"qdlhr\"\",\"\"val2\"\":\"\"dvegw\"\"}\",iumixtiqivrwyrw,kycsmrupwf,1986-11-25 00:00:00,19,,q,'q',\"\"\"q\"\"\",\u2705,\u0644\u0628\u0649,M\u00c8RE ,\u05e8\u05d7\u05dc\u05d9\u05dd\r\n+-955939840,13,28595,4458733335951872,8748.717773438,1547.018290286,2994.118,false,ommetzkgoe,1970-04-26 07:48:00,ayrbgvzejhwqfsczxcrygqcedbqetw==,,\"{\"\"key1\"\":\"\"ze4uTLJCIS\"\",\"\"key2\"\":\"\"KJvGWmVD4k\"\",\"\"key3\"\":\"\"EAj5tjtJIY\"\",\"\"key4\"\":\"\"sGZyLdFZTL\"\"}\",\"{\"\"id\"\":\"\"zavzf\"\",\"\"val1\"\":\"\"cvpte\"\",\"\"val2\"\":\"\"wpihw\"\"}\",waoexcjeezmxrsi,scnzxnuxan,1985-04-11 00:00:00,4,-4123000000000,r,'r',\"\"\"r\"\"\",\ud83c\udf8a,\u0645\u0646\u0632\u0644\u0647,M\u00c8RE ,\u05de\u05d2\u05d3\u05dc\u05d9\u05dd\r\n+-946041088,20,4028,6488644051956704,2068.969238281,6867.608431199,2096.338,false,aftxkrhbse,1995-07-21 00:19:48,okvcbxnhykbxgmodzdwgybzwioikng==,[606],\"{\"\"key1\"\":\"\"lh6d4g6AdX\"\",\"\"key2\"\":\"\"m7NXz1Drky\"\",\"\"key3\"\":\"\"PE0h2QSxpA\"\",\"\"key4\"\":\"\"6R2Esbvp9X\"\"}\",\"{\"\"id\"\":\"\"uegms\"\",\"\"val1\"\":\"\"grjhb\"\",\"\"val2\"\":\"\"wzptz\"\"}\",ukampuhnwymbxok,pwumbaiqhj,1980-08-31 00:00:00,5,-4123000000000,s,'s',\"\"\"s\"\"\",\u2b07\ufe0f,\u0645\u0627\u062a\u062c\u064a\u0646\u064a,M\u00c8RE ,\u05d7\u05d5\u05de\u05e9\r\n+190064639,85,-16861,745854179121920,3006.978027344,5300.161841,590.341,false,pwpphjeqey,1971-11-03 14:46:40,csdhfkmtpzkznemtvmumlbcetlgfqg==,\"[4828,2281]\",\"{\"\"key1\"\":\"\"381OAMa9cm\"\",\"\"key2\"\":\"\"kVqFCSMW5N\"\",\"\"key3\"\":\"\"SORmXvLRX2\"\",\"\"key4\"\":\"\"yjMtCtXnrM\"\"}\",\"{\"\"id\"\":\"\"bqodb\"\",\"\"val1\"\":\"\"mnxzv\"\",\"\"val2\"\":\"\"uebln\"\"}\",qumqyheavhhvwkc,lbidykbvuz,1977-12-01 00:00:00,10,-7.4423e-12,s,'s',\"\"\"s\"\"\",\u26a0\ufe0f,\u0648\u0648\u0642\u0641,DE NO\u00cbL ,\u05e2\u05e0\u05d1\r\n+-1355749376,28,-6594,6217661610739712,1575.131469727,4710.247816849,719.935,false,wkrxvnrrmw,1977-04-11 02:09:53,qiutbarcseuaqboaojdlihgwvwiqwQ==,\"[7066,6223,9555,9906,8967,4096,2286,9385,4793,2865,57,7801,1261,5671,8650,8967,7999,7792,2867]\",\"{\"\"key1\"\":\"\"HlwjPoYNOZ\"\",\"\"key2\"\":\"\"hnbly8aGKW\"\",\"\"key3\"\":\"\"2nSgdIRftI\"\",\"\"key4\"\":\"\"8sxcVvxtbj\"\"}\",\"{\"\"id\"\":\"\"hwuon\"\",\"\"val1\"\":\"\"wuuon\"\",\"\"val2\"\":\"\"icggg\"\"}\",gmmgstuttnbjxpy,vhdgledyvc,1994-10-13 00:00:00,2,-1.2345678e+22,m,'m',\"\"\"m\"\"\",\u2764\ufe0f,\u062f\u0639\u0648\u062a\u0647,EN D\u00c9CEMBRE,\u05e0\u05d2\u05d5\u05d4\u05d5\u05ea\r\n+623428607,52,-12058,1099140924791552,1668.521118164,7082.408967932,3390.096,false,dyspcsmwhq,1979-11-10 12:56:35,eydynjfcrsmjwwcjyqtcwskjmaulyg==,\"[1826,8833,371,2946,1848,661,3918,7866,3517,9457,3681]\",\"{\"\"key1\"\":\"\"BahZ52XrL1\"\",\"\"key2\"\":\"\"ZP6eRPsIEd\"\",\"\"key3\"\":\"\"VBMjjPITQw\"\",\"\"key4\"\":\"\"1rSnwpb9sq\"\"}\",\"{\"\"id\"\":\"\"bfggr\"\",\"\"val1\"\":\"\"nxflc\"\",\"\"val2\"\":\"\"elsjm\"\"}\",gqouiupeqligvhn,ykwavphlbv,2002-01-11 00:00:00,13,4.94065e-32,d,'d',\"\"\"d\"\"\",\ud83d\udfe8, \u062e\u0627\u0635\u0629,M\u00c8RE ,\u05d4\u05e8 \u05d1\u05e8\u05db\u05d4 \u05d1\u05e8\u05db\u05d4\r\n+340231167,-103,32314,6727076822845952,490.876434326,521.782040839,689.131,false,ynbspwxszn,2006-09-11 04:44:46,yybegwugseeyfyyzzxssndxpceskbg==,\"[7387,5827,3530,5417,2764,3977,7112,6065,2894,6651,9171,6785,5125]\",\"{\"\"key1\"\":\"\"SL6KOlo6yS\"\",\"\"key2\"\":\"\"6hwmQ2uKSH\"\",\"\"key3\"\":\"\"ECjxaAa7Su\"\",\"\"key4\"\":\"\"OY8xWw8ut0\"\"}\",\"{\"\"id\"\":\"\"avewu\"\",\"\"val1\"\":\"\"rttto\"\",\"\"val2\"\":\"\"mndbq\"\"}\",gmknpbmxtkuyfvw,rzxfoedloj,1999-07-03 00:00:00,12,-7.4423e-12,a,'a',\"\"\"a\"\"\",\ud83d\udcdd,\u0627\u0644\u0637\u0644\u0627\u0642 ,EN D\u00c9CEMBRE,\u05d7\u05e8\u05de\u05e9\r\n+59571531,-120,2726,499568922236435,5693.273925781,831.917259298,5970.561,false,srcyitzady,1976-01-17 22:33:07,uomxckzjwvhrhuqvxvjmntzosoyudQ==,\"[1663,9022,6558]\",\"{\"\"key1\"\":\"\"GqtZfwU56W\"\",\"\"key2\"\":\"\"hjDJcwofzW\"\",\"\"key3\"\":\"\"wAS2lqzSh0\"\",\"\"key4\"\":\"\"ieeRmIe0pZ\"\"}\",\"{\"\"id\"\":\"\"jmsyp\"\",\"\"val1\"\":\"\"tjrjc\"\",\"\"val2\"\":\"\"fwuue\"\"}\",ekatpkqdtbrdopr,vsusznjtum,2002-01-30 00:00:00,9,-0.00445124654,g,'g',\"\"\"g\"\"\",\ud83d\udd37,\u0635\u062f\u064a\u0642\u0647,FRAN\u00c7AISE ,\u05e7\u05d3\u05d9\u05dd\r\n+955388927,36,-14711,234259271632640,5292.765136719,821.385383988,8358.519,true,krzqufbilr,2012-10-22 05:07:34,owkzlgegaqgzpbomgtgdmmqaigfmog==,\"[4974,9911,5595,6472,7765,1797,1908,1014,5229]\",\"{\"\"key1\"\":\"\"xydc0YQBBL\"\",\"\"key2\"\":\"\"8tW4c8Gm4M\"\",\"\"key3\"\":\"\"aGblhlIIrx\"\",\"\"key4\"\":\"\"v30H3CJPMy\"\"}\",\"{\"\"id\"\":\"\"eqoya\"\",\"\"val1\"\":\"\"ypims\"\",\"\"val2\"\":\"\"blsod\"\"}\",sumfztrbmpwkjon,bypzxafltm,2013-06-15 00:00:00,14,7.4423e-12,j,'j',\"\"\"j\"\"\",\ud83c\udd97, \u0639\u0644\u064a ,DE NO\u00cbL ,\u05e9\u05d1\u05d9 \u05e9\u05d5\u05de\u05e8\u05d5\u05df\r\n+1838367743,-76,7387,2747089955464832,8975.13671875,704.915821881,272.055,true,ouxvftfobi,1971-06-30 18:49:15,acidfzuquvceiuuzqqvnljpljdcnzg==,\"[9936,6185,781,912,2509,4330]\",\"{\"\"key1\"\":\"\"94j6CTgyit\"\",\"\"key2\"\":\"\"smHeSsm3fX\"\",\"\"key3\"\":\"\"PD7ADcq9JW\"\",\"\"key4\"\":\"\"eqjA1uBW3e\"\"}\",\"{\"\"id\"\":\"\"gmimc\"\",\"\"val1\"\":\"\"oyksy\"\",\"\"val2\"\":\"\"bavue\"\"}\",aowrnboisicvkex,rucsmrzxvu,2011-09-01 00:00:00,18,1.79769e+308,w,'w',\"\"\"w\"\"\",\u274c,\u0635\u062f\u064a\u0642\u0647,FRAN\u00c7AISE ,\u05e1\u05e0\u05e1\u05e0\u05d4\r\n+-703343616,19,7048,1887435007823552,3118.254150391,3798.277379851,1502.739,true,hwhwhwafby,2008-03-06 02:00:46,wwcjyqtcwskjmaulygxoqwfedjiyrg==,\"[4259,717,7166,7868,1323,4157,6358,6232,2556,9900,3363,6799,60,5880,7990,4743,8200,5670,6079]\",\"{\"\"key1\"\":\"\"XIVSXvg33a\"\",\"\"key2\"\":\"\"2HsXhn6Ee2\"\",\"\"key3\"\":\"\"03o5vQeeLf\"\",\"\"key4\"\":\"\"GzX7WcQrRx\"\"}\",\"{\"\"id\"\":\"\"hryfw\"\",\"\"val1\"\":\"\"wkcgw\"\",\"\"val2\"\":\"\"sjmns\"\"}\",yyshjqkviglwvhz,uclwpzskje,1983-03-28 00:00:00,6,-179623157,t,'t',\"\"\"t\"\"\",\u2757\ufe0f,\u0648\u0648\u0642\u0641,DE NO\u00cbL ,\u05ea\u05dc\u05dd\r\n+1671645295,-54,12191,8891823575776256,4349.600097656,5313.086512179,9153.266,false,htxiqenedt,1999-03-30 20:05:28,iskynmcvdrnpbysmtjkcguptilqefw==,,\"{\"\"key1\"\":\"\"3badsBTnEu\"\",\"\"key2\"\":\"\"w2t7fCA5if\"\",\"\"key3\"\":\"\"jiavckw8PW\"\",\"\"key4\"\":\"\"21LcTl7GEk\"\"}\",\"{\"\"id\"\":\"\"wpica\"\",\"\"val1\"\":\"\"wptoy\"\",\"\"val2\"\":\"\"iryuo\"\"}\",oeshqwtudywyksw,qenziyaaqm,2003-03-16 00:00:00,16,1.2345678e+22,e,'e',\"\"\"e\"\"\",\u270f\ufe0f,\u062f\u0639\u0648\u062a\u0647,CUISINE LE D\u00ceNER ,\u05d9\u05e6\u05d4\u05e8\r\n+-1684013568,118,-24306,7313791764174080,287.703582764,3151.620627917,6181.187,true,nohqcyneqj,1970-11-10 05:03:07,ccdehmtplyzrksyweivpvhyvmlywyQ==,\"[5533,9469,8400,1236,26,9435]\",\"{\"\"key1\"\":\"\"vyMNJLBCZ8\"\",\"\"key2\"\":\"\"Jh7CiBItY8\"\",\"\"key3\"\":\"\"bESrtP2bb7\"\",\"\"key4\"\":\"\"wTaLbfFDcs\"\"}\",\"{\"\"id\"\":\"\"bavjh\"\",\"\"val1\"\":\"\"pnnih\"\",\"\"val2\"\":\"\"vjrjh\"\"}\",igizjxvkxfvbfca,zdvpuszdnh,2013-03-24 00:00:00,1,-1.2345678e+22,s,'s',\"\"\"s\"\"\",\ud83d\ude21,\u0647\u062f\u064a\u0629,EN D\u00c9CEMBRE,\u05d0\u05d1\u05e0\u05d9 \u05d7\u05e4\u05e5\r\n+12284927,50,-23596,3090497741838080,7133.937988281,1689.871550393,361.979,false,nucvnzflzq,1982-03-01 14:38:42,mohmdorwphgpbeydynjfcrsmjwwcjw==,\"[4116,3479,1659,585,1774,9875,6875,2468,9124,3381,2819,7152,8430,9381,3429,3882,5494]\",\"{\"\"key1\"\":\"\"fYMgi49MuZ\"\",\"\"key2\"\":\"\"tEZ0xIaoWn\"\",\"\"key3\"\":\"\"jLyevsUqXL\"\",\"\"key4\"\":\"\"EcbkujjhB0\"\"}\",\"{\"\"id\"\":\"\"kstoy\"\",\"\"val1\"\":\"\"mndgw\"\",\"\"val2\"\":\"\"elnir\"\"}\",yiezdlzhndhzkum,wfomgoetsc,2001-01-11 00:00:00,8,-179.763157,a,'a',\"\"\"a\"\"\",\ud83d\ude00,\u0633\u064a\u0647\u062f\u064a\u0647 ,DE NO\u00cbL ,\u05e9\u05d0-\u05e0\u05d5\u05e8\r\n+1462738431,-14,6340,634171097409536,1516.799316406,5888.129773498,9240.135,false,kypzqcadqz,2000-03-16 18:38:10,qwalydjzhtcfqbssmydjzuycysoccw==,\"[7760,604,4336,4251]\",\"{\"\"key1\"\":\"\"LPd7EsQfFI\"\",\"\"key2\"\":\"\"Z3oIisw6Ai\"\",\"\"key3\"\":\"\"vRPV7oKuhy\"\",\"\"key4\"\":\"\"wh0uRNvY8Z\"\"}\",\"{\"\"id\"\":\"\"fgbqy\"\",\"\"val1\"\":\"\"dvebf\"\",\"\"val2\"\":\"\"aqdbf\"\"}\",ceqzycmpezypklu,zxcqjyiqhy,2001-04-30 00:00:00,15,123.45678,g,'g',\"\"\"g\"\"\",\ud83d\ude0a, \u0642\u0627\u0626\u0644\u0627\u064b,CUISINE LE D\u00ceNER ,\u05d0\u05d9\u05ea\u05de\u05e8\r\n+2032854015,124,-6867,2971557475748552,7684.747070313,2829.404176599,7425.072,true,ynuxibyskr,1971-10-01 22:22:22,omgtgdmmqaigfmohmdorwphgpbeydw==,\"[4041,7619,1172,9022,2349,2213,5804,1965,4390,4060,2752]\",\"{\"\"key1\"\":\"\"ZIrea4F10F\"\",\"\"key2\"\":\"\"xCQ6E60w71\"\",\"\"key3\"\":\"\"S7sa9dvHDG\"\",\"\"key4\"\":\"\"oOp7CL6LhN\"\"}\",\"{\"\"id\"\":\"\"xuoiw\"\",\"\"val1\"\":\"\"jroyf\"\",\"\"val2\"\":\"\"ihmni\"\"}\",eiwcmxrrdqllsyr,pcddgowuzv,1997-05-31 00:00:00,20,-4.940656,t,'t',\"\"\"t\"\"\",\ud83c\udf40,\u0648\u0623\u0639\u0644\u0646 ,FRAN\u00c7AISE ,\u05de\u05d1\u05d5\u05d0 \u05d3\u05d5\u05ea\u05df\r\n+1805124607,91,6447,2525964422257088,8623.229492188,8118.9394035,8176.205,false,ruszqcqjwp,1976-11-24 00:31:34,ukmdhvhsbxvjpbowkzlgegaqgzpbog==,\"[5599,972,9379,351,4476,8111,5519,5949,4540,848,1050,5422,767,7645,4393,8164,4643,3916,3250]\",\"{\"\"key1\"\":\"\"dU3uIQ8NM1\"\",\"\"key2\"\":\"\"v482CaKybl\"\",\"\"key3\"\":\"\"uabKB3zls9\"\",\"\"key4\"\":\"\"5KzVA5ivwz\"\"}\",\"{\"\"id\"\":\"\"ttzkh\"\",\"\"val1\"\":\"\"kcavj\"\",\"\"val2\"\":\"\"wkclh\"\"}\",agyrupinwbeztta,lwhbibqmws,1978-03-31 00:00:00,17,1.7976e+30,d,'d',\"\"\"d\"\"\",\ud83c\udf89,  \u0641\u0631\u0641\u0636\u0647\u0627,FRAN\u00c7AISE ,\u05db\u05e4\u05e8 \u05ea\u05e4\u05d5\u05d7\r\n+-1057157632,-77,-17825,6684227018091776,3754.662353516,1227.72216854,7412.237,true,iwaigqusuc,1996-12-26 01:28:37,ccxpeexihihokaudhmuplzphtfccdQ==,\"[9781,9643]\",\"{\"\"key1\"\":\"\"PjgjuUKVC4\"\",\"\"key2\"\":\"\"9nGNkoyTfb\"\",\"\"key3\"\":\"\"UcWQ9Yk3ff\"\",\"\"key4\"\":\"\"ZOG77yFk4S\"\"}\",\"{\"\"id\"\":\"\"sosyf\"\",\"\"val1\"\":\"\"ujhrt\"\",\"\"val2\"\":\"\"rjxza\"\"}\",kqwyafcfaclzfgg,jtscynuscn,1975-06-02 00:00:00,3,-17976157000000,y,'y',\"\"\"y\"\"\",\ud83d\udcd5,\u0623\u0646\u0647 ,CUISINE LE D\u00ceNER ,\u05d0\u05dc\u05d5\u05df \u05de\u05d5\u05e8\u05d4\r\n+268149759,25,26299,863534107491584,4555.274414063,779.365301495,2038.987,false,kycfdgtzsu,1997-06-29 02:57:33,ywycfpatthdxjswjtizeahtpojyybQ==,\"[7165,780,4823,5610,8150,9640,2670,4954,3538]\",\"{\"\"key1\"\":\"\"qegPrwEXxt\"\",\"\"key2\"\":\"\"AZhgaO5l7R\"\",\"\"key3\"\":\"\"TjQeE1T5r4\"\",\"\"key4\"\":\"\"7iMEn717cy\"\"}\",\"{\"\"id\"\":\"\"gwpdl\"\",\"\"val1\"\":\"\"niwzf\"\",\"\"val2\"\":\"\"lnica\"\"}\",ucatyvfobyjejgq,wxfbvcvspp,1972-02-21 00:00:00,11,-7.4423e-12,w,'w',\"\"\"w\"\"\",\ud83c\udf4e,\u0623\u0645\u0627\u0645 ,EN D\u00c9CEMBRE,\u05d2\u05e0\u05d9\u05dd\r\n+-669752208,-47,-15665,4986790849161728,3570.342041016,7889.261249401,3128.891,true,wnhbaiojlo,1972-06-13 22:37:55,qetzsvpouvqqhgelfbzdzqymgficdQ==,\"[8466,6224,483,2088,8626]\",\"{\"\"key1\"\":\"\"DHI5hSpnD8\"\",\"\"key2\"\":\"\"ZX1CFWZaEe\"\",\"\"key3\"\":\"\"4TkLHzJLoN\"\",\"\"key4\"\":\"\"xYjtvEEQ7o\"\"}\",\"{\"\"id\"\":\"\"zakhb\"\",\"\"val1\"\":\"\"welnn\"\",\"\"val2\"\":\"\"xzkms\"\"}\",ygoubokubqbesfz,ppphdtzkbs,1990-04-11 00:00:00,7,-1797.23157,d,'d',\"\"\"d\"\"\",\u23fa,\u062f\u0639\u0648\u062a\u0647,CUISINE LE D\u00ceNER ,\u05d1\u05d9\u05ea \u05d7\u05d2\u05d9 \u05d7\u05d2\u05d9\r\n+null,null,,,,,,,,,,,\"\"\"\"\"\",,,,,,,,,,,,,\r\n+,null,-15906,5035218741361664,1292.412231445,5799.643102009,5292.029,false,!@#$%^&*(),1990-08-05 15:20:03,ukuclnqrqmzfoawrawqyrxhucmiskw==,\"[3697,4006,8856,2643,8157,3966,3652,9256,6544,218,6844]\",\"{\"\"key1\"\":\"\"NMkbDREYfH\"\",\"\"key2\"\":\"\"hd7X3zO3Pk\"\",\"\"key3\"\":\"\"Z9ZIyZs59c\"\",\"\"key4\"\":\"\"SZzGskMufb\"\"}\",\"{\"\"id\"\":\"\"sjrod\"\",\"\"val1\"\":\"\"qdlhr\"\",\"\"val2\"\":\"\"dvegw\"\"}\",iumixtiqivrwyrw,kycsmrupwf,1986-11-25 00:00:00,19,,q,'q',\"\"\"q\"\"\",\u2705,\u0644\u0628\u0649,M\u00c8RE ,\u05e8\u05d7\u05dc\u05d9\u05dd\r\n+-955939840,13,28595,4458733335951872,8748.717773438,1547.018290286,2994.118,false,ommetzkgoe,1970-04-26 07:48:00,ayrbgvzejhwqfsczxcrygqcedbqetw==,,\"{\"\"key1\"\":\"\"ze4uTLJCIS\"\",\"\"key2\"\":\"\"KJvGWmVD4k\"\",\"\"key3\"\":\"\"EAj5tjtJIY\"\",\"\"key4\"\":\"\"sGZyLdFZTL\"\"}\",\"{\"\"id\"\":\"\"zavzf\"\",\"\"val1\"\":\"\"cvpte\"\",\"\"val2\"\":\"\"wpihw\"\"}\",waoexcjeezmxrsi,scnzxnuxan,1985-04-11 00:00:00,4,-4123000000000,r,'r',\"\"\"r\"\"\",\ud83c\udf8a,\u0645\u0646\u0632\u0644\u0647,M\u00c8RE ,\u05de\u05d2\u05d3\u05dc\u05d9\u05dd\r\n+-946041088,20,4028,6488644051956704,2068.969238281,6867.608431199,2096.338,false,aftxkrhbse,1995-07-21 00:19:48,okvcbxnhykbxgmodzdwgybzwioikng==,[606],\"{\"\"key1\"\":\"\"lh6d4g6AdX\"\",\"\"key2\"\":\"\"m7NXz1Drky\"\",\"\"key3\"\":\"\"PE0h2QSxpA\"\",\"\"key4\"\":\"\"6R2Esbvp9X\"\"}\",\"{\"\"id\"\":\"\"uegms\"\",\"\"val1\"\":\"\"grjhb\"\",\"\"val2\"\":\"\"wzptz\"\"}\",ukampuhnwymbxok,pwumbaiqhj,1980-08-31 00:00:00,5,-4123000000000,s,'s',\"\"\"s\"\"\",\u2b07\ufe0f,\u0645\u0627\u062a\u062c\u064a\u0646\u064a,M\u00c8RE ,\u05d7\u05d5\u05de\u05e9\r\n+190064639,85,-16861,745854179121920,3006.978027344,5300.161841,590.341,false,pwpphjeqey,1971-11-03 14:46:40,csdhfkmtpzkznemtvmumlbcetlgfqg==,\"[4828,2281]\",\"{\"\"key1\"\":\"\"381OAMa9cm\"\",\"\"key2\"\":\"\"kVqFCSMW5N\"\",\"\"key3\"\":\"\"SORmXvLRX2\"\",\"\"key4\"\":\"\"yjMtCtXnrM\"\"}\",\"{\"\"id\"\":\"\"bqodb\"\",\"\"val1\"\":\"\"mnxzv\"\",\"\"val2\"\":\"\"uebln\"\"}\",qumqyheavhhvwkc,lbidykbvuz,1977-12-01 00:00:00,10,-7.4423e-12,s,'s',\"\"\"s\"\"\",\u26a0\ufe0f,\u0648\u0648\u0642\u0641,DE NO\u00cbL ,\u05e2\u05e0\u05d1\r\n+-1355749376,28,-6594,6217661610739712,1575.131469727,4710.247816849,719.935,false,wkrxvnrrmw,1977-04-11 02:09:53,qiutbarcseuaqboaojdlihgwvwiqwQ==,\"[7066,6223,9555,9906,8967,4096,2286,9385,4793,2865,57,7801,1261,5671,8650,8967,7999,7792,2867]\",\"{\"\"key1\"\":\"\"HlwjPoYNOZ\"\",\"\"key2\"\":\"\"hnbly8aGKW\"\",\"\"key3\"\":\"\"2nSgdIRftI\"\",\"\"key4\"\":\"\"8sxcVvxtbj\"\"}\",\"{\"\"id\"\":\"\"hwuon\"\",\"\"val1\"\":\"\"wuuon\"\",\"\"val2\"\":\"\"icggg\"\"}\",gmmgstuttnbjxpy,vhdgledyvc,1994-10-13 00:00:00,2,-1.2345678e+22,m,'m',\"\"\"m\"\"\",\u2764\ufe0f,\u062f\u0639\u0648\u062a\u0647,EN D\u00c9CEMBRE,\u05e0\u05d2\u05d5\u05d4\u05d5\u05ea\r\n+623428607,52,-12058,1099140924791552,1668.521118164,7082.408967932,3390.096,false,dyspcsmwhq,1979-11-10 12:56:35,eydynjfcrsmjwwcjyqtcwskjmaulyg==,\"[1826,8833,371,2946,1848,661,3918,7866,3517,9457,3681]\",\"{\"\"key1\"\":\"\"BahZ52XrL1\"\",\"\"key2\"\":\"\"ZP6eRPsIEd\"\",\"\"key3\"\":\"\"VBMjjPITQw\"\",\"\"key4\"\":\"\"1rSnwpb9sq\"\"}\",\"{\"\"id\"\":\"\"bfggr\"\",\"\"val1\"\":\"\"nxflc\"\",\"\"val2\"\":\"\"elsjm\"\"}\",gqouiupeqligvhn,ykwavphlbv,2002-01-11 00:00:00,13,4.94065e-32,d,'d',\"\"\"d\"\"\",\ud83d\udfe8, \u062e\u0627\u0635\u0629,M\u00c8RE ,\u05d4\u05e8 \u05d1\u05e8\u05db\u05d4 \u05d1\u05e8\u05db\u05d4\r\n+340231167,-103,32314,6727076822845952,490.876434326,521.782040839,689.131,false,ynbspwxszn,2006-09-11 04:44:46,yybegwugseeyfyyzzxssndxpceskbg==,\"[7387,5827,3530,5417,2764,3977,7112,6065,2894,6651,9171,6785,5125]\",\"{\"\"key1\"\":\"\"SL6KOlo6yS\"\",\"\"key2\"\":\"\"6hwmQ2uKSH\"\",\"\"key3\"\":\"\"ECjxaAa7Su\"\",\"\"key4\"\":\"\"OY8xWw8ut0\"\"}\",\"{\"\"id\"\":\"\"avewu\"\",\"\"val1\"\":\"\"rttto\"\",\"\"val2\"\":\"\"mndbq\"\"}\",gmknpbmxtkuyfvw,rzxfoedloj,1999-07-03 00:00:00,12,-7.4423e-12,a,'a',\"\"\"a\"\"\",\ud83d\udcdd,\u0627\u0644\u0637\u0644\u0627\u0642 ,EN D\u00c9CEMBRE,\u05d7\u05e8\u05de\u05e9\r\n+59571531,-120,2726,499568922236435,5693.273925781,831.917259298,5970.561,false,srcyitzady,1976-01-17 22:33:07,uomxckzjwvhrhuqvxvjmntzosoyudQ==,\"[1663,9022,6558]\",\"{\"\"key1\"\":\"\"GqtZfwU56W\"\",\"\"key2\"\":\"\"hjDJcwofzW\"\",\"\"key3\"\":\"\"wAS2lqzSh0\"\",\"\"key4\"\":\"\"ieeRmIe0pZ\"\"}\",\"{\"\"id\"\":\"\"jmsyp\"\",\"\"val1\"\":\"\"tjrjc\"\",\"\"val2\"\":\"\"fwuue\"\"}\",ekatpkqdtbrdopr,vsusznjtum,2002-01-30 00:00:00,9,-0.00445124654,g,'g',\"\"\"g\"\"\",\ud83d\udd37,\u0635\u062f\u064a\u0642\u0647,FRAN\u00c7AISE ,\u05e7\u05d3\u05d9\u05dd\r\n+955388927,36,-14711,234259271632640,5292.765136719,821.385383988,8358.519,true,krzqufbilr,2012-10-22 05:07:34,owkzlgegaqgzpbomgtgdmmqaigfmog==,\"[4974,9911,5595,6472,7765,1797,1908,1014,5229]\",\"{\"\"key1\"\":\"\"xydc0YQBBL\"\",\"\"key2\"\":\"\"8tW4c8Gm4M\"\",\"\"key3\"\":\"\"aGblhlIIrx\"\",\"\"key4\"\":\"\"v30H3CJPMy\"\"}\",\"{\"\"id\"\":\"\"eqoya\"\",\"\"val1\"\":\"\"ypims\"\",\"\"val2\"\":\"\"blsod\"\"}\",sumfztrbmpwkjon,bypzxafltm,2013-06-15 00:00:00,14,7.4423e-12,j,'j',\"\"\"j\"\"\",\ud83c\udd97, \u0639\u0644\u064a ,DE NO\u00cbL ,\u05e9\u05d1\u05d9 \u05e9\u05d5\u05de\u05e8\u05d5\u05df\r\n+1838367743,-76,7387,2747089955464832,8975.13671875,704.915821881,272.055,true,ouxvftfobi,1971-06-30 18:49:15,acidfzuquvceiuuzqqvnljpljdcnzg==,\"[9936,6185,781,912,2509,4330]\",\"{\"\"key1\"\":\"\"94j6CTgyit\"\",\"\"key2\"\":\"\"smHeSsm3fX\"\",\"\"key3\"\":\"\"PD7ADcq9JW\"\",\"\"key4\"\":\"\"eqjA1uBW3e\"\"}\",\"{\"\"id\"\":\"\"gmimc\"\",\"\"val1\"\":\"\"oyksy\"\",\"\"val2\"\":\"\"bavue\"\"}\",aowrnboisicvkex,rucsmrzxvu,2011-09-01 00:00:00,18,1.79769e+308,w,'w',\"\"\"w\"\"\",\u274c,\u0635\u062f\u064a\u0642\u0647,FRAN\u00c7AISE ,\u05e1\u05e0\u05e1\u05e0\u05d4\r\n+-703343616,19,7048,1887435007823552,3118.254150391,3798.277379851,1502.739,true,hwhwhwafby,2008-03-06 02:00:46,wwcjyqtcwskjmaulygxoqwfedjiyrg==,\"[4259,717,7166,7868,1323,4157,6358,6232,2556,9900,3363,6799,60,5880,7990,4743,8200,5670,6079]\",\"{\"\"key1\"\":\"\"XIVSXvg33a\"\",\"\"key2\"\":\"\"2HsXhn6Ee2\"\",\"\"key3\"\":\"\"03o5vQeeLf\"\",\"\"key4\"\":\"\"GzX7WcQrRx\"\"}\",\"{\"\"id\"\":\"\"hryfw\"\",\"\"val1\"\":\"\"wkcgw\"\",\"\"val2\"\":\"\"sjmns\"\"}\",yyshjqkviglwvhz,uclwpzskje,1983-03-28 00:00:00,6,-179623157,t,'t',\"\"\"t\"\"\",\u2757\ufe0f,\u0648\u0648\u0642\u0641,DE NO\u00cbL ,\u05ea\u05dc\u05dd\r\n+1671645295,-54,12191,8891823575776256,4349.600097656,5313.086512179,9153.266,false,htxiqenedt,1999-03-30 20:05:28,iskynmcvdrnpbysmtjkcguptilqefw==,,\"{\"\"key1\"\":\"\"3badsBTnEu\"\",\"\"key2\"\":\"\"w2t7fCA5if\"\",\"\"key3\"\":\"\"jiavckw8PW\"\",\"\"key4\"\":\"\"21LcTl7GEk\"\"}\",\"{\"\"id\"\":\"\"wpica\"\",\"\"val1\"\":\"\"wptoy\"\",\"\"val2\"\":\"\"iryuo\"\"}\",oeshqwtudywyksw,qenziyaaqm,2003-03-16 00:00:00,16,1.2345678e+22,e,'e',\"\"\"e\"\"\",\u270f\ufe0f,\u062f\u0639\u0648\u062a\u0647,CUISINE LE D\u00ceNER ,\u05d9\u05e6\u05d4\u05e8\r\n+-1684013568,118,-24306,7313791764174080,287.703582764,3151.620627917,6181.187,true,nohqcyneqj,1970-11-10 05:03:07,ccdehmtplyzrksyweivpvhyvmlywyQ==,\"[5533,9469,8400,1236,26,9435]\",\"{\"\"key1\"\":\"\"vyMNJLBCZ8\"\",\"\"key2\"\":\"\"Jh7CiBItY8\"\",\"\"key3\"\":\"\"bESrtP2bb7\"\",\"\"key4\"\":\"\"wTaLbfFDcs\"\"}\",\"{\"\"id\"\":\"\"bavjh\"\",\"\"val1\"\":\"\"pnnih\"\",\"\"val2\"\":\"\"vjrjh\"\"}\",igizjxvkxfvbfca,zdvpuszdnh,2013-03-24 00:00:00,1,-1.2345678e+22,s,'s',\"\"\"s\"\"\",\ud83d\ude21,\u0647\u062f\u064a\u0629,EN D\u00c9CEMBRE,\u05d0\u05d1\u05e0\u05d9 \u05d7\u05e4\u05e5\r\n+12284927,50,-23596,3090497741838080,7133.937988281,1689.871550393,361.979,false,nucvnzflzq,1982-03-01 14:38:42,mohmdorwphgpbeydynjfcrsmjwwcjw==,\"[4116,3479,1659,585,1774,9875,6875,2468,9124,3381,2819,7152,8430,9381,3429,3882,5494]\",\"{\"\"key1\"\":\"\"fYMgi49MuZ\"\",\"\"key2\"\":\"\"tEZ0xIaoWn\"\",\"\"key3\"\":\"\"jLyevsUqXL\"\",\"\"key4\"\":\"\"EcbkujjhB0\"\"}\",\"{\"\"id\"\":\"\"kstoy\"\",\"\"val1\"\":\"\"mndgw\"\",\"\"val2\"\":\"\"elnir\"\"}\",yiezdlzhndhzkum,wfomgoetsc,2001-01-11 00:00:00,8,-179.763157,a,'a',\"\"\"a\"\"\",\ud83d\ude00,\u0633\u064a\u0647\u062f\u064a\u0647 ,DE NO\u00cbL ,\u05e9\u05d0-\u05e0\u05d5\u05e8\r\n+1462738431,-14,6340,634171097409536,1516.799316406,5888.129773498,9240.135,false,kypzqcadqz,2000-03-16 18:38:10,qwalydjzhtcfqbssmydjzuycysoccw==,\"[7760,604,4336,4251]\",\"{\"\"key1\"\":\"\"LPd7EsQfFI\"\",\"\"key2\"\":\"\"Z3oIisw6Ai\"\",\"\"key3\"\":\"\"vRPV7oKuhy\"\",\"\"key4\"\":\"\"wh0uRNvY8Z\"\"}\",\"{\"\"id\"\":\"\"fgbqy\"\",\"\"val1\"\":\"\"dvebf\"\",\"\"val2\"\":\"\"aqdbf\"\"}\",ceqzycmpezypklu,zxcqjyiqhy,2001-04-30 00:00:00,15,123.45678,g,'g',\"\"\"g\"\"\",\ud83d\ude0a, \u0642\u0627\u0626\u0644\u0627\u064b,CUISINE LE D\u00ceNER ,\u05d0\u05d9\u05ea\u05de\u05e8\r\n+2032854015,124,-6867,2971557475748552,7684.747070313,2829.404176599,7425.072,true,ynuxibyskr,1971-10-01 22:22:22,omgtgdmmqaigfmohmdorwphgpbeydw==,\"[4041,7619,1172,9022,2349,2213,5804,1965,4390,4060,2752]\",\"{\"\"key1\"\":\"\"ZIrea4F10F\"\",\"\"key2\"\":\"\"xCQ6E60w71\"\",\"\"key3\"\":\"\"S7sa9dvHDG\"\",\"\"key4\"\":\"\"oOp7CL6LhN\"\"}\",\"{\"\"id\"\":\"\"xuoiw\"\",\"\"val1\"\":\"\"jroyf\"\",\"\"val2\"\":\"\"ihmni\"\"}\",eiwcmxrrdqllsyr,pcddgowuzv,1997-05-31 00:00:00,20,-4.940656,t,'t',\"\"\"t\"\"\",\ud83c\udf40,\u0648\u0623\u0639\u0644\u0646 ,FRAN\u00c7AISE ,\u05de\u05d1\u05d5\u05d0 \u05d3\u05d5\u05ea\u05df\r\n+1805124607,91,6447,2525964422257088,8623.229492188,8118.9394035,8176.205,false,ruszqcqjwp,1976-11-24 00:31:34,ukmdhvhsbxvjpbowkzlgegaqgzpbog==,\"[5599,972,9379,351,4476,8111,5519,5949,4540,848,1050,5422,767,7645,4393,8164,4643,3916,3250]\",\"{\"\"key1\"\":\"\"dU3uIQ8NM1\"\",\"\"key2\"\":\"\"v482CaKybl\"\",\"\"key3\"\":\"\"uabKB3zls9\"\",\"\"key4\"\":\"\"5KzVA5ivwz\"\"}\",\"{\"\"id\"\":\"\"ttzkh\"\",\"\"val1\"\":\"\"kcavj\"\",\"\"val2\"\":\"\"wkclh\"\"}\",agyrupinwbeztta,lwhbibqmws,1978-03-31 00:00:00,17,1.7976e+30,d,'d',\"\"\"d\"\"\",\ud83c\udf89,  \u0641\u0631\u0641\u0636\u0647\u0627,FRAN\u00c7AISE ,\u05db\u05e4\u05e8 \u05ea\u05e4\u05d5\u05d7\r\n+-1057157632,-77,-17825,6684227018091776,3754.662353516,1227.72216854,7412.237,true,iwaigqusuc,1996-12-26 01:28:37,ccxpeexihihokaudhmuplzphtfccdQ==,\"[9781,9643]\",\"{\"\"key1\"\":\"\"PjgjuUKVC4\"\",\"\"key2\"\":\"\"9nGNkoyTfb\"\",\"\"key3\"\":\"\"UcWQ9Yk3ff\"\",\"\"key4\"\":\"\"ZOG77yFk4S\"\"}\",\"{\"\"id\"\":\"\"sosyf\"\",\"\"val1\"\":\"\"ujhrt\"\",\"\"val2\"\":\"\"rjxza\"\"}\",kqwyafcfaclzfgg,jtscynuscn,1975-06-02 00:00:00,3,-17976157000000,y,'y',\"\"\"y\"\"\",\ud83d\udcd5,\u0623\u0646\u0647 ,CUISINE LE D\u00ceNER ,\u05d0\u05dc\u05d5\u05df \u05de\u05d5\u05e8\u05d4\r\n+268149759,25,26299,863534107491584,4555.274414063,779.365301495,2038.987,false,kycfdgtzsu,1997-06-29 02:57:33,ywycfpatthdxjswjtizeahtpojyybQ==,\"[7165,780,4823,5610,8150,9640,2670,4954,3538]\",\"{\"\"key1\"\":\"\"qegPrwEXxt\"\",\"\"key2\"\":\"\"AZhgaO5l7R\"\",\"\"key3\"\":\"\"TjQeE1T5r4\"\",\"\"key4\"\":\"\"7iMEn717cy\"\"}\",\"{\"\"id\"\":\"\"gwpdl\"\",\"\"val1\"\":\"\"niwzf\"\",\"\"val2\"\":\"\"lnica\"\"}\",ucatyvfobyjejgq,wxfbvcvspp,1972-02-21 00:00:00,11,-7.4423e-12,w,'w',\"\"\"w\"\"\",\ud83c\udf4e,\u0623\u0645\u0627\u0645 ,EN D\u00c9CEMBRE,\u05d2\u05e0\u05d9\u05dd\r\n+-669752208,-47,-15665,4986790849161728,3570.342041016,7889.261249401,3128.891,true,wnhbaiojlo,1972-06-13 22:37:55,qetzsvpouvqqhgelfbzdzqymgficdQ==,\"[8466,6224,483,2088,8626]\",\"{\"\"key1\"\":\"\"DHI5hSpnD8\"\",\"\"key2\"\":\"\"ZX1CFWZaEe\"\",\"\"key3\"\":\"\"4TkLHzJLoN\"\",\"\"key4\"\":\"\"xYjtvEEQ7o\"\"}\",\"{\"\"id\"\":\"\"zakhb\"\",\"\"val1\"\":\"\"welnn\"\",\"\"val2\"\":\"\"xzkms\"\"}\",ygoubokubqbesfz,ppphdtzkbs,1990-04-11 00:00:00,7,-1797.23157,d,'d',\"\"\"d\"\"\",\u23fa,\u062f\u0639\u0648\u062a\u0647,CUISINE LE D\u00ceNER ,\u05d1\u05d9\u05ea \u05d7\u05d2\u05d9 \u05d7\u05d2\u05d9\r\n+null,null,,,,,,,,,,,\"\"\"\"\"\",,,,,,,,,,,,,\r\n+,null,-15906,5035218741361664,1292.412231445,5799.643102009,5292.029,false,!@#$%^&*(),1990-08-05 15:20:03,ukuclnqrqmzfoawrawqyrxhucmiskw==,\"[3697,4006,8856,2643,8157,3966,3652,9256,6544,218,6844]\",\"{\"\"key1\"\":\"\"NMkbDREYfH\"\",\"\"key2\"\":\"\"hd7X3zO3Pk\"\",\"\"key3\"\":\"\"Z9ZIyZs59c\"\",\"\"key4\"\":\"\"SZzGskMufb\"\"}\",\"{\"\"id\"\":\"\"sjrod\"\",\"\"val1\"\":\"\"qdlhr\"\",\"\"val2\"\":\"\"dvegw\"\"}\",iumixtiqivrwyrw,kycsmrupwf,1986-11-25 00:00:00,19,,q,'q',\"\"\"q\"\"\",\u2705,\u0644\u0628\u0649,M\u00c8RE ,\u05e8\u05d7\u05dc\u05d9\u05dd\r\n+-955939840,13,28595,4458733335951872,8748.717773438,1547.018290286,2994.118,false,ommetzkgoe,1970-04-26 07:48:00,ayrbgvzejhwqfsczxcrygqcedbqetw==,,\"{\"\"key1\"\":\"\"ze4uTLJCIS\"\",\"\"key2\"\":\"\"KJvGWmVD4k\"\",\"\"key3\"\":\"\"EAj5tjtJIY\"\",\"\"key4\"\":\"\"sGZyLdFZTL\"\"}\",\"{\"\"id\"\":\"\"zavzf\"\",\"\"val1\"\":\"\"cvpte\"\",\"\"val2\"\":\"\"wpihw\"\"}\",waoexcjeezmxrsi,scnzxnuxan,1985-04-11 00:00:00,4,-4123000000000,r,'r',\"\"\"r\"\"\",\ud83c\udf8a,\u0645\u0646\u0632\u0644\u0647,M\u00c8RE ,\u05de\u05d2\u05d3\u05dc\u05d9\u05dd\r\n+-946041088,20,4028,6488644051956704,2068.969238281,6867.608431199,2096.338,false,aftxkrhbse,1995-07-21 00:19:48,okvcbxnhykbxgmodzdwgybzwioikng==,[606],\"{\"\"key1\"\":\"\"lh6d4g6AdX\"\",\"\"key2\"\":\"\"m7NXz1Drky\"\",\"\"key3\"\":\"\"PE0h2QSxpA\"\",\"\"key4\"\":\"\"6R2Esbvp9X\"\"}\",\"{\"\"id\"\":\"\"uegms\"\",\"\"val1\"\":\"\"grjhb\"\",\"\"val2\"\":\"\"wzptz\"\"}\",ukampuhnwymbxok,pwumbaiqhj,1980-08-31 00:00:00,5,-4123000000000,s,'s',\"\"\"s\"\"\",\u2b07\ufe0f,\u0645\u0627\u062a\u062c\u064a\u0646\u064a,M\u00c8RE ,\u05d7\u05d5\u05de\u05e9\r\n+190064639,85,-16861,745854179121920,3006.978027344,5300.161841,590.341,false,pwpphjeqey,1971-11-03 14:46:40,csdhfkmtpzkznemtvmumlbcetlgfqg==,\"[4828,2281]\",\"{\"\"key1\"\":\"\"381OAMa9cm\"\",\"\"key2\"\":\"\"kVqFCSMW5N\"\",\"\"key3\"\":\"\"SORmXvLRX2\"\",\"\"key4\"\":\"\"yjMtCtXnrM\"\"}\",\"{\"\"id\"\":\"\"bqodb\"\",\"\"val1\"\":\"\"mnxzv\"\",\"\"val2\"\":\"\"uebln\"\"}\",qumqyheavhhvwkc,lbidykbvuz,1977-12-01 00:00:00,10,-7.4423e-12,s,'s',\"\"\"s\"\"\",\u26a0\ufe0f,\u0648\u0648\u0642\u0641,DE NO\u00cbL ,\u05e2\u05e0\u05d1\r\n+-1355749376,28,-6594,6217661610739712,1575.131469727,4710.247816849,719.935,false,wkrxvnrrmw,1977-04-11 02:09:53,qiutbarcseuaqboaojdlihgwvwiqwQ==,\"[7066,6223,9555,9906,8967,4096,2286,9385,4793,2865,57,7801,1261,5671,8650,8967,7999,7792,2867]\",\"{\"\"key1\"\":\"\"HlwjPoYNOZ\"\",\"\"key2\"\":\"\"hnbly8aGKW\"\",\"\"key3\"\":\"\"2nSgdIRftI\"\",\"\"key4\"\":\"\"8sxcVvxtbj\"\"}\",\"{\"\"id\"\":\"\"hwuon\"\",\"\"val1\"\":\"\"wuuon\"\",\"\"val2\"\":\"\"icggg\"\"}\",gmmgstuttnbjxpy,vhdgledyvc,1994-10-13 00:00:00,2,-1.2345678e+22,m,'m',\"\"\"m\"\"\",\u2764\ufe0f,\u062f\u0639\u0648\u062a\u0647,EN D\u00c9CEMBRE,\u05e0\u05d2\u05d5\u05d4\u05d5\u05ea\r\n+623428607,52,-12058,1099140924791552,1668.521118164,7082.408967932,3390.096,false,dyspcsmwhq,1979-11-10 12:56:35,eydynjfcrsmjwwcjyqtcwskjmaulyg==,\"[1826,8833,371,2946,1848,661,3918,7866,3517,9457,3681]\",\"{\"\"key1\"\":\"\"BahZ52XrL1\"\",\"\"key2\"\":\"\"ZP6eRPsIEd\"\",\"\"key3\"\":\"\"VBMjjPITQw\"\",\"\"key4\"\":\"\"1rSnwpb9sq\"\"}\",\"{\"\"id\"\":\"\"bfggr\"\",\"\"val1\"\":\"\"nxflc\"\",\"\"val2\"\":\"\"elsjm\"\"}\",gqouiupeqligvhn,ykwavphlbv,2002-01-11 00:00:00,13,4.94065e-32,d,'d',\"\"\"d\"\"\",\ud83d\udfe8, \u062e\u0627\u0635\u0629,M\u00c8RE ,\u05d4\u05e8 \u05d1\u05e8\u05db\u05d4 \u05d1\u05e8\u05db\u05d4\r\n+340231167,-103,32314,6727076822845952,490.876434326,521.782040839,689.131,false,ynbspwxszn,2006-09-11 04:44:46,yybegwugseeyfyyzzxssndxpceskbg==,\"[7387,5827,3530,5417,2764,3977,7112,6065,2894,6651,9171,6785,5125]\",\"{\"\"key1\"\":\"\"SL6KOlo6yS\"\",\"\"key2\"\":\"\"6hwmQ2uKSH\"\",\"\"key3\"\":\"\"ECjxaAa7Su\"\",\"\"key4\"\":\"\"OY8xWw8ut0\"\"}\",\"{\"\"id\"\":\"\"avewu\"\",\"\"val1\"\":\"\"rttto\"\",\"\"val2\"\":\"\"mndbq\"\"}\",gmknpbmxtkuyfvw,rzxfoedloj,1999-07-03 00:00:00,12,-7.4423e-12,a,'a',\"\"\"a\"\"\",\ud83d\udcdd,\u0627\u0644\u0637\u0644\u0627\u0642 ,EN D\u00c9CEMBRE,\u05d7\u05e8\u05de\u05e9\r\n+59571531,-120,2726,499568922236435,5693.273925781,831.917259298,5970.561,false,srcyitzady,1976-01-17 22:33:07,uomxckzjwvhrhuqvxvjmntzosoyudQ==,\"[1663,9022,6558]\",\"{\"\"key1\"\":\"\"GqtZfwU56W\"\",\"\"key2\"\":\"\"hjDJcwofzW\"\",\"\"key3\"\":\"\"wAS2lqzSh0\"\",\"\"key4\"\":\"\"ieeRmIe0pZ\"\"}\",\"{\"\"id\"\":\"\"jmsyp\"\",\"\"val1\"\":\"\"tjrjc\"\",\"\"val2\"\":\"\"fwuue\"\"}\",ekatpkqdtbrdopr,vsusznjtum,2002-01-30 00:00:00,9,-0.00445124654,g,'g',\"\"\"g\"\"\",\ud83d\udd37,\u0635\u062f\u064a\u0642\u0647,FRAN\u00c7AISE ,\u05e7\u05d3\u05d9\u05dd\r\n+955388927,36,-14711,234259271632640,5292.765136719,821.385383988,8358.519,true,krzqufbilr,2012-10-22 05:07:34,owkzlgegaqgzpbomgtgdmmqaigfmog==,\"[4974,9911,5595,6472,7765,1797,1908,1014,5229]\",\"{\"\"key1\"\":\"\"xydc0YQBBL\"\",\"\"key2\"\":\"\"8tW4c8Gm4M\"\",\"\"key3\"\":\"\"aGblhlIIrx\"\",\"\"key4\"\":\"\"v30H3CJPMy\"\"}\",\"{\"\"id\"\":\"\"eqoya\"\",\"\"val1\"\":\"\"ypims\"\",\"\"val2\"\":\"\"blsod\"\"}\",sumfztrbmpwkjon,bypzxafltm,2013-06-15 00:00:00,14,7.4423e-12,j,'j',\"\"\"j\"\"\",\ud83c\udd97, \u0639\u0644\u064a ,DE NO\u00cbL ,\u05e9\u05d1\u05d9 \u05e9\u05d5\u05de\u05e8\u05d5\u05df\r\n+1838367743,-76,7387,2747089955464832,8975.13671875,704.915821881,272.055,true,ouxvftfobi,1971-06-30 18:49:15,acidfzuquvceiuuzqqvnljpljdcnzg==,\"[9936,6185,781,912,2509,4330]\",\"{\"\"key1\"\":\"\"94j6CTgyit\"\",\"\"key2\"\":\"\"smHeSsm3fX\"\",\"\"key3\"\":\"\"PD7ADcq9JW\"\",\"\"key4\"\":\"\"eqjA1uBW3e\"\"}\",\"{\"\"id\"\":\"\"gmimc\"\",\"\"val1\"\":\"\"oyksy\"\",\"\"val2\"\":\"\"bavue\"\"}\",aowrnboisicvkex,rucsmrzxvu,2011-09-01 00:00:00,18,1.79769e+308,w,'w',\"\"\"w\"\"\",\u274c,\u0635\u062f\u064a\u0642\u0647,FRAN\u00c7AISE ,\u05e1\u05e0\u05e1\u05e0\u05d4\r\n+-703343616,19,7048,1887435007823552,3118.254150391,3798.277379851,1502.739,true,hwhwhwafby,2008-03-06 02:00:46,wwcjyqtcwskjmaulygxoqwfedjiyrg==,\"[4259,717,7166,7868,1323,4157,6358,6232,2556,9900,3363,6799,60,5880,7990,4743,8200,5670,6079]\",\"{\"\"key1\"\":\"\"XIVSXvg33a\"\",\"\"key2\"\":\"\"2HsXhn6Ee2\"\",\"\"key3\"\":\"\"03o5vQeeLf\"\",\"\"key4\"\":\"\"GzX7WcQrRx\"\"}\",\"{\"\"id\"\":\"\"hryfw\"\",\"\"val1\"\":\"\"wkcgw\"\",\"\"val2\"\":\"\"sjmns\"\"}\",yyshjqkviglwvhz,uclwpzskje,1983-03-28 00:00:00,6,-179623157,t,'t',\"\"\"t\"\"\",\u2757\ufe0f,\u0648\u0648\u0642\u0641,DE NO\u00cbL ,\u05ea\u05dc\u05dd\r\n+1671645295,-54,12191,8891823575776256,4349.600097656,5313.086512179,9153.266,false,htxiqenedt,1999-03-30 20:05:28,iskynmcvdrnpbysmtjkcguptilqefw==,,\"{\"\"key1\"\":\"\"3badsBTnEu\"\",\"\"key2\"\":\"\"w2t7fCA5if\"\",\"\"key3\"\":\"\"jiavckw8PW\"\",\"\"key4\"\":\"\"21LcTl7GEk\"\"}\",\"{\"\"id\"\":\"\"wpica\"\",\"\"val1\"\":\"\"wptoy\"\",\"\"val2\"\":\"\"iryuo\"\"}\",oeshqwtudywyksw,qenziyaaqm,2003-03-16 00:00:00,16,1.2345678e+22,e,'e',\"\"\"e\"\"\",\u270f\ufe0f,\u062f\u0639\u0648\u062a\u0647,CUISINE LE D\u00ceNER ,\u05d9\u05e6\u05d4\u05e8\r\n+-1684013568,118,-24306,7313791764174080,287.703582764,3151.620627917,6181.187,true,nohqcyneqj,1970-11-10 05:03:07,ccdehmtplyzrksyweivpvhyvmlywyQ==,\"[5533,9469,8400,1236,26,9435]\",\"{\"\"key1\"\":\"\"vyMNJLBCZ8\"\",\"\"key2\"\":\"\"Jh7CiBItY8\"\",\"\"key3\"\":\"\"bESrtP2bb7\"\",\"\"key4\"\":\"\"wTaLbfFDcs\"\"}\",\"{\"\"id\"\":\"\"bavjh\"\",\"\"val1\"\":\"\"pnnih\"\",\"\"val2\"\":\"\"vjrjh\"\"}\",igizjxvkxfvbfca,zdvpuszdnh,2013-03-24 00:00:00,1,-1.2345678e+22,s,'s',\"\"\"s\"\"\",\ud83d\ude21,\u0647\u062f\u064a\u0629,EN D\u00c9CEMBRE,\u05d0\u05d1\u05e0\u05d9 \u05d7\u05e4\u05e5\r\n+12284927,50,-23596,3090497741838080,7133.937988281,1689.871550393,361.979,false,nucvnzflzq,1982-03-01 14:38:42,mohmdorwphgpbeydynjfcrsmjwwcjw==,\"[4116,3479,1659,585,1774,9875,6875,2468,9124,3381,2819,7152,8430,9381,3429,3882,5494]\",\"{\"\"key1\"\":\"\"fYMgi49MuZ\"\",\"\"key2\"\":\"\"tEZ0xIaoWn\"\",\"\"key3\"\":\"\"jLyevsUqXL\"\",\"\"key4\"\":\"\"EcbkujjhB0\"\"}\",\"{\"\"id\"\":\"\"kstoy\"\",\"\"val1\"\":\"\"mndgw\"\",\"\"val2\"\":\"\"elnir\"\"}\",yiezdlzhndhzkum,wfomgoetsc,2001-01-11 00:00:00,8,-179.763157,a,'a',\"\"\"a\"\"\",\ud83d\ude00,\u0633\u064a\u0647\u062f\u064a\u0647 ,DE NO\u00cbL ,\u05e9\u05d0-\u05e0\u05d5\u05e8\r\n+1462738431,-14,6340,634171097409536,1516.799316406,5888.129773498,9240.135,false,kypzqcadqz,2000-03-16 18:38:10,qwalydjzhtcfqbssmydjzuycysoccw==,\"[7760,604,4336,4251]\",\"{\"\"key1\"\":\"\"LPd7EsQfFI\"\",\"\"key2\"\":\"\"Z3oIisw6Ai\"\",\"\"key3\"\":\"\"vRPV7oKuhy\"\",\"\"key4\"\":\"\"wh0uRNvY8Z\"\"}\",\"{\"\"id\"\":\"\"fgbqy\"\",\"\"val1\"\":\"\"dvebf\"\",\"\"val2\"\":\"\"aqdbf\"\"}\",ceqzycmpezypklu,zxcqjyiqhy,2001-04-30 00:00:00,15,123.45678,g,'g',\"\"\"g\"\"\",\ud83d\ude0a, \u0642\u0627\u0626\u0644\u0627\u064b,CUISINE LE D\u00ceNER ,\u05d0\u05d9\u05ea\u05de\u05e8\r\n+2032854015,124,-6867,2971557475748552,7684.747070313,2829.404176599,7425.072,true,ynuxibyskr,1971-10-01 22:22:22,omgtgdmmqaigfmohmdorwphgpbeydw==,\"[4041,7619,1172,9022,2349,2213,5804,1965,4390,4060,2752]\",\"{\"\"key1\"\":\"\"ZIrea4F10F\"\",\"\"key2\"\":\"\"xCQ6E60w71\"\",\"\"key3\"\":\"\"S7sa9dvHDG\"\",\"\"key4\"\":\"\"oOp7CL6LhN\"\"}\",\"{\"\"id\"\":\"\"xuoiw\"\",\"\"val1\"\":\"\"jroyf\"\",\"\"val2\"\":\"\"ihmni\"\"}\",eiwcmxrrdqllsyr,pcddgowuzv,1997-05-31 00:00:00,20,-4.940656,t,'t',\"\"\"t\"\"\",\ud83c\udf40,\u0648\u0623\u0639\u0644\u0646 ,FRAN\u00c7AISE ,\u05de\u05d1\u05d5\u05d0 \u05d3\u05d5\u05ea\u05df\r\n+1805124607,91,6447,2525964422257088,8623.229492188,8118.9394035,8176.205,false,ruszqcqjwp,1976-11-24 00:31:34,ukmdhvhsbxvjpbowkzlgegaqgzpbog==,\"[5599,972,9379,351,4476,8111,5519,5949,4540,848,1050,5422,767,7645,4393,8164,4643,3916,3250]\",\"{\"\"key1\"\":\"\"dU3uIQ8NM1\"\",\"\"key2\"\":\"\"v482CaKybl\"\",\"\"key3\"\":\"\"uabKB3zls9\"\",\"\"key4\"\":\"\"5KzVA5ivwz\"\"}\",\"{\"\"id\"\":\"\"ttzkh\"\",\"\"val1\"\":\"\"kcavj\"\",\"\"val2\"\":\"\"wkclh\"\"}\",agyrupinwbeztta,lwhbibqmws,1978-03-31 00:00:00,17,1.7976e+30,d,'d',\"\"\"d\"\"\",\ud83c\udf89,  \u0641\u0631\u0641\u0636\u0647\u0627,FRAN\u00c7AISE ,\u05db\u05e4\u05e8 \u05ea\u05e4\u05d5\u05d7\r\n+-1057157632,-77,-17825,6684227018091776,3754.662353516,1227.72216854,7412.237,true,iwaigqusuc,1996-12-26 01:28:37,ccxpeexihihokaudhmuplzphtfccdQ==,\"[9781,9643]\",\"{\"\"key1\"\":\"\"PjgjuUKVC4\"\",\"\"key2\"\":\"\"9nGNkoyTfb\"\",\"\"key3\"\":\"\"UcWQ9Yk3ff\"\",\"\"key4\"\":\"\"ZOG77yFk4S\"\"}\",\"{\"\"id\"\":\"\"sosyf\"\",\"\"val1\"\":\"\"ujhrt\"\",\"\"val2\"\":\"\"rjxza\"\"}\",kqwyafcfaclzfgg,jtscynuscn,1975-06-02 00:00:00,3,-17976157000000,y,'y',\"\"\"y\"\"\",\ud83d\udcd5,\u0623\u0646\u0647 ,CUISINE LE D\u00ceNER ,\u05d0\u05dc\u05d5\u05df \u05de\u05d5\u05e8\u05d4\r\n+268149759,25,26299,863534107491584,4555.274414063,779.365301495,2038.987,false,kycfdgtzsu,1997-06-29 02:57:33,ywycfpatthdxjswjtizeahtpojyybQ==,\"[7165,780,4823,5610,8150,9640,2670,4954,3538]\",\"{\"\"key1\"\":\"\"qegPrwEXxt\"\",\"\"key2\"\":\"\"AZhgaO5l7R\"\",\"\"key3\"\":\"\"TjQeE1T5r4\"\",\"\"key4\"\":\"\"7iMEn717cy\"\"}\",\"{\"\"id\"\":\"\"gwpdl\"\",\"\"val1\"\":\"\"niwzf\"\",\"\"val2\"\":\"\"lnica\"\"}\",ucatyvfobyjejgq,wxfbvcvspp,1972-02-21 00:00:00,11,-7.4423e-12,w,'w',\"\"\"w\"\"\",\ud83c\udf4e,\u0623\u0645\u0627\u0645 ,EN D\u00c9CEMBRE,\u05d2\u05e0\u05d9\u05dd\r\n+-669752208,-47,-15665,4986790849161728,3570.342041016,7889.261249401,3128.891,true,wnhbaiojlo,1972-06-13 22:37:55,qetzsvpouvqqhgelfbzdzqymgficdQ==,\"[8466,6224,483,2088,8626]\",\"{\"\"key1\"\":\"\"DHI5hSpnD8\"\",\"\"key2\"\":\"\"ZX1CFWZaEe\"\",\"\"key3\"\":\"\"4TkLHzJLoN\"\",\"\"key4\"\":\"\"xYjtvEEQ7o\"\"}\",\"{\"\"id\"\":\"\"zakhb\"\",\"\"val1\"\":\"\"welnn\"\",\"\"val2\"\":\"\"xzkms\"\"}\",ygoubokubqbesfz,ppphdtzkbs,1990-04-11 00:00:00,7,-1797.23157,d,'d',\"\"\"d\"\"\",\u23fa,\u062f\u0639\u0648\u062a\u0647,CUISINE LE D\u00ceNER ,\u05d1\u05d9\u05ea \u05d7\u05d2\u05d9 \u05d7\u05d2\u05d9\r\n+null,null,,,,,,,,,,,\"\"\"\"\"\",,,,,,,,,,,,,\r\ndiff --git a/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp b/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\nindex c379cc7163dc..2ed6d602d654 100644\n--- a/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\n+++ b/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\n@@ -1894,6 +1894,7 @@ void StringValueScanner::FinalizeChunkProcess() {\n \t\t}\n \t\tif (states.IsQuotedCurrent() && !found_error &&\n \t\t    state_machine->dialect_options.state_machine_options.strict_mode.GetValue()) {\n+\t\t\ttype = UNTERMINATED_QUOTES;\n \t\t\t// If we finish the execution of a buffer, and we end in a quoted state, it means we have unterminated\n \t\t\t// quotes\n \t\t\tresult.current_errors.Insert(type, result.cur_col_id, result.chunk_col_id, result.last_position);\ndiff --git a/src/execution/operator/csv_scanner/sniffer/dialect_detection.cpp b/src/execution/operator/csv_scanner/sniffer/dialect_detection.cpp\nindex ef7c3c101248..a1eb04a03bd6 100644\n--- a/src/execution/operator/csv_scanner/sniffer/dialect_detection.cpp\n+++ b/src/execution/operator/csv_scanner/sniffer/dialect_detection.cpp\n@@ -391,7 +391,8 @@ void CSVSniffer::AnalyzeDialectCandidate(unique_ptr<ColumnCountScanner> scanner,\n \t\t\t\treturn;\n \t\t\t} else {\n \t\t\t\t// Give preference to one that got escaped\n-\t\t\t\tif (!scanner->ever_escaped && candidates.front()->ever_escaped) {\n+\t\t\t\tif (!scanner->ever_escaped && candidates.front()->ever_escaped &&\n+\t\t\t\t    sniffing_state_machine.dialect_options.state_machine_options.strict_mode.GetValue()) {\n \t\t\t\t\treturn;\n \t\t\t\t}\n \t\t\t\tif (best_consistent_rows == consistent_rows && num_cols >= max_columns_found) {\n@@ -413,9 +414,19 @@ void CSVSniffer::AnalyzeDialectCandidate(unique_ptr<ColumnCountScanner> scanner,\n \t\t\treturn;\n \t\t}\n \t\tif (quoted && num_cols < max_columns_found) {\n-\t\t\tfor (auto &candidate : candidates) {\n-\t\t\t\tif (candidate->ever_quoted) {\n-\t\t\t\t\treturn;\n+\t\t\tif (scanner->ever_escaped &&\n+\t\t\t    sniffing_state_machine.dialect_options.state_machine_options.strict_mode.GetValue()) {\n+\t\t\t\tfor (auto &candidate : candidates) {\n+\t\t\t\t\tif (candidate->ever_quoted && candidate->ever_escaped) {\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t} else {\n+\t\t\t\tfor (auto &candidate : candidates) {\n+\t\t\t\t\tif (candidate->ever_quoted) {\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n \t\t\t\t}\n \t\t\t}\n \t\t}\n@@ -434,7 +445,6 @@ void CSVSniffer::AnalyzeDialectCandidate(unique_ptr<ColumnCountScanner> scanner,\n \t\t} else if (!options.null_padding) {\n \t\t\tsniffing_state_machine.dialect_options.skip_rows = dirty_notes;\n \t\t}\n-\n \t\tcandidates.clear();\n \t\tsniffing_state_machine.dialect_options.num_cols = num_cols;\n \t\tlines_sniffed = sniffed_column_counts.result_position;\ndiff --git a/src/function/window/window_value_function.cpp b/src/function/window/window_value_function.cpp\nindex fbd1551a2e50..79b85e371e5a 100644\n--- a/src/function/window/window_value_function.cpp\n+++ b/src/function/window/window_value_function.cpp\n@@ -101,8 +101,10 @@ void WindowValueLocalState::Sink(WindowExecutorGlobalState &gstate, DataChunk &s\n \t\tchild.ToUnifiedFormat(coll_count, child_data);\n \t\tconst auto &validity = child_data.validity;\n \t\tif (gstate.executor.wexpr.ignore_nulls && !validity.AllValid()) {\n+\t\t\tconst auto &sel = *child_data.sel;\n \t\t\tfor (sel_t i = 0; i < coll_count; ++i) {\n-\t\t\t\tif (validity.RowIsValidUnsafe(i)) {\n+\t\t\t\tconst auto idx = sel.get_index(i);\n+\t\t\t\tif (validity.RowIsValidUnsafe(idx)) {\n \t\t\t\t\tsort_nulls[filtered++] = i;\n \t\t\t\t}\n \t\t\t}\ndiff --git a/src/include/duckdb/common/types/row/tuple_data_states.hpp b/src/include/duckdb/common/types/row/tuple_data_states.hpp\nindex ac014be75f8d..17b18cc82693 100644\n--- a/src/include/duckdb/common/types/row/tuple_data_states.hpp\n+++ b/src/include/duckdb/common/types/row/tuple_data_states.hpp\n@@ -10,8 +10,8 @@\n \n #include \"duckdb/common/mutex.hpp\"\n #include \"duckdb/common/types.hpp\"\n-#include \"duckdb/common/types/vector.hpp\"\n #include \"duckdb/common/types/vector_cache.hpp\"\n+#include \"duckdb/common/types/vector.hpp\"\n \n namespace duckdb {\n \ndiff --git a/src/include/duckdb/execution/operator/csv_scanner/base_scanner.hpp b/src/include/duckdb/execution/operator/csv_scanner/base_scanner.hpp\nindex f50ddd3209fd..9b355e271cdf 100644\n--- a/src/include/duckdb/execution/operator/csv_scanner/base_scanner.hpp\n+++ b/src/include/duckdb/execution/operator/csv_scanner/base_scanner.hpp\n@@ -288,6 +288,7 @@ class BaseScanner {\n \t\t\tcase CSVState::QUOTED: {\n \t\t\t\tif ((states.states[0] == CSVState::UNQUOTED || states.states[0] == CSVState::MAYBE_QUOTED) &&\n \t\t\t\t    has_escaped_value) {\n+\t\t\t\t\tever_escaped = true;\n \t\t\t\t\tT::SetEscaped(result);\n \t\t\t\t}\n \t\t\t\tever_quoted = true;\n@@ -311,6 +312,7 @@ class BaseScanner {\n \t\t\t} break;\n \t\t\tcase CSVState::UNQUOTED: {\n \t\t\t\tif (states.states[0] == CSVState::MAYBE_QUOTED) {\n+\t\t\t\t\tever_escaped = true;\n \t\t\t\t\tT::SetEscaped(result);\n \t\t\t\t}\n \t\t\t\tT::SetUnquoted(result);\ndiff --git a/src/main/error_manager.cpp b/src/main/error_manager.cpp\nindex 4ec024c13aa6..2feab024f2b4 100644\n--- a/src/main/error_manager.cpp\n+++ b/src/main/error_manager.cpp\n@@ -2,6 +2,7 @@\n #include \"duckdb/main/config.hpp\"\n #include \"utf8proc_wrapper.hpp\"\n #include \"duckdb/common/exception/list.hpp\"\n+#include \"duckdb/common/string_util.hpp\"\n \n namespace duckdb {\n \n@@ -16,7 +17,7 @@ static const DefaultError internal_errors[] = {\n      \"are disabled by configuration (allow_unsigned_extensions)\"},\n     {ErrorType::INVALIDATED_TRANSACTION, \"Current transaction is aborted (please ROLLBACK)\"},\n     {ErrorType::INVALIDATED_DATABASE, \"Failed: database has been invalidated because of a previous fatal error. The \"\n-                                      \"database must be restarted prior to being used again.\\nOriginal error: \\\"%s\\\"\"},\n+                                      \"database must be restarted prior to being used again.\\n\"},\n     {ErrorType::INVALID, nullptr}};\n \n string ErrorManager::FormatExceptionRecursive(ErrorType error_type, vector<ExceptionFormatValue> &values) {\n@@ -25,13 +26,26 @@ string ErrorManager::FormatExceptionRecursive(ErrorType error_type, vector<Excep\n \t}\n \tauto entry = custom_errors.find(error_type);\n \tstring error;\n-\tif (entry == custom_errors.end()) {\n-\t\t// error was not overwritten\n-\t\terror = internal_errors[int(error_type)].error;\n-\t} else {\n-\t\t// error was overwritten\n+\tif (entry != custom_errors.end()) {\n+\t\t// Error was overwritten.\n \t\terror = entry->second;\n+\t\treturn ExceptionFormatValue::Format(error, values);\n \t}\n+\n+\t// Error was not overwritten.\n+\terror = internal_errors[int(error_type)].error;\n+\n+\tif (error_type != ErrorType::INVALIDATED_DATABASE) {\n+\t\treturn ExceptionFormatValue::Format(error, values);\n+\t}\n+\n+\tfor (const auto &val : values) {\n+\t\tif (StringUtil::Contains(val.str_val, error)) {\n+\t\t\terror = \"%s\";\n+\t\t\treturn ExceptionFormatValue::Format(error, values);\n+\t\t}\n+\t}\n+\terror += \"Original error: \\\"%s\\\"\";\n \treturn ExceptionFormatValue::Format(error, values);\n }\n \ndiff --git a/src/storage/compression/roaring/common.cpp b/src/storage/compression/roaring/common.cpp\nindex 190e6dbf682e..c8450c32d7b8 100644\n--- a/src/storage/compression/roaring/common.cpp\n+++ b/src/storage/compression/roaring/common.cpp\n@@ -225,10 +225,6 @@ void RoaringScanPartial(ColumnSegment &segment, ColumnScanState &state, idx_t sc\n }\n \n void RoaringScan(ColumnSegment &segment, ColumnScanState &state, idx_t scan_count, Vector &result) {\n-\tif (result.GetVectorType() == VectorType::DICTIONARY_VECTOR) {\n-\t\t// dictionary encoding handles the validity itself\n-\t\treturn;\n-\t}\n \tRoaringScanPartial(segment, state, scan_count, result, 0);\n }\n \ndiff --git a/src/storage/compression/validity_uncompressed.cpp b/src/storage/compression/validity_uncompressed.cpp\nindex 48f2ec749ed3..8fa4acca9923 100644\n--- a/src/storage/compression/validity_uncompressed.cpp\n+++ b/src/storage/compression/validity_uncompressed.cpp\n@@ -401,10 +401,6 @@ void ValidityScanPartial(ColumnSegment &segment, ColumnScanState &state, idx_t s\n }\n \n void ValidityScan(ColumnSegment &segment, ColumnScanState &state, idx_t scan_count, Vector &result) {\n-\tif (result.GetVectorType() == VectorType::DICTIONARY_VECTOR) {\n-\t\t// dictionary encoding handles the validity itself\n-\t\treturn;\n-\t}\n \tresult.Flatten(scan_count);\n \n \tauto start = segment.GetRelativeIndex(state.row_index);\ndiff --git a/src/storage/table/chunk_info.cpp b/src/storage/table/chunk_info.cpp\nindex 6460f6f992bd..3b7b11d7be84 100644\n--- a/src/storage/table/chunk_info.cpp\n+++ b/src/storage/table/chunk_info.cpp\n@@ -204,7 +204,11 @@ idx_t ChunkVectorInfo::Delete(transaction_t transaction_id, row_t rows[], idx_t\n \t\t}\n \t\t// first check the chunk for conflicts\n \t\tif (deleted[rows[i]] != NOT_DELETED_ID) {\n-\t\t\t// tuple was already deleted by another transaction\n+\t\t\t// tuple was already deleted by another transaction - conflict\n+\t\t\t// unset any deleted tuples we set in this loop\n+\t\t\tfor (idx_t k = 0; k < i; k++) {\n+\t\t\t\tdeleted[rows[k]] = NOT_DELETED_ID;\n+\t\t\t}\n \t\t\tthrow TransactionException(\"Conflict on tuple deletion!\");\n \t\t}\n \t\t// after verifying that there are no conflicts we mark the tuple as deleted\n", "test_patch": "diff --git a/test/sql/copy/csv/test_sniff_csv.test b/test/sql/copy/csv/test_sniff_csv.test\nindex 9bdb7a19ac8f..bf70f8e82bf8 100644\n--- a/test/sql/copy/csv/test_sniff_csv.test\n+++ b/test/sql/copy/csv/test_sniff_csv.test\n@@ -8,6 +8,16 @@ PRAGMA enable_verification\n # requires notwindows because tests will return \\r\\n to be used in the parameters\n require notwindows\n \n+query II\n+SELECT quote, escape from sniff_csv('data/csv/16857.csv', ignore_errors = true);\n+----\n+\"\t\"\n+\n+query II\n+SELECT quote, escape from sniff_csv('data/csv/16857.csv');\n+----\n+\"\t\"\n+\n query III\n SELECT escape,quote, delimiter from sniff_csv('data/csv/later_quotes.csv');\n ----\ndiff --git a/test/sql/delete/cleanup_delete_on_conflict.test b/test/sql/delete/cleanup_delete_on_conflict.test\nnew file mode 100644\nindex 000000000000..99abf9d33f99\n--- /dev/null\n+++ b/test/sql/delete/cleanup_delete_on_conflict.test\n@@ -0,0 +1,37 @@\n+# name: test/sql/delete/cleanup_delete_on_conflict.test\n+# description: Verify that partial deletes are cleaned up on conflicts\n+# group: [delete]\n+\n+statement ok\n+CREATE TABLE tbl(i INTEGER);\n+\n+statement ok\n+INSERT INTO tbl FROM range(1000) t(i);\n+\n+statement ok\n+SET immediate_transaction_mode=true\n+\n+statement ok con1\n+BEGIN\n+\n+statement ok con2\n+BEGIN\n+\n+statement ok con1\n+DELETE FROM tbl WHERE i BETWEEN 200 AND 300\n+\n+statement error con2\n+DELETE FROM tbl WHERE i <= 500\n+----\n+Conflict on tuple deletion\n+\n+statement ok con1\n+COMMIT\n+\n+statement ok con2\n+ROLLBACK\n+\n+query I\n+DELETE FROM tbl WHERE i <= 500\n+----\n+400\ndiff --git a/test/sql/storage/update/dictionary_update_null.test b/test/sql/storage/update/dictionary_update_null.test\nnew file mode 100644\nindex 000000000000..038d4b21dcbe\n--- /dev/null\n+++ b/test/sql/storage/update/dictionary_update_null.test\n@@ -0,0 +1,21 @@\n+# name: test/sql/storage/update/dictionary_update_null.test\n+# description: Test updating only the validity mask of a dictionary compressed column\n+# group: [update]\n+\n+# load the DB from disk\n+load __TEST_DIR__/dictionary_update_null.db\n+\n+statement ok\n+SET force_compression='dictionary'\n+\n+statement ok\n+CREATE OR REPLACE TABLE 'everflow_daily' AS SELECT case when i%10=0 THEN uuid()::VARCHAR ELSE 'N/A' END sub4 FROM range(10000) t(i)\n+\n+statement ok\n+UPDATE everflow_daily SET sub4 = NULL WHERE sub4 = 'N/A';\n+\n+query I\n+select count(*) from everflow_daily\n+where sub4 = 'N/A'\n+----\n+0\n", "problem_statement": "Regression: incorrect results after UPDATE operation when migrating from DuckDB 1.1.2 to 1.2.1\n### What happens?\n\nhttps://github.com/duckdb/duckdb/issues/16780\nI was able to reproduce it, I've hashed certain columns but still don't feel comfortable sharing them in public, but I have the archive.\n\n### To Reproduce\n\nunarchive the 7z file\nrun this in python 3.12.7 duckdb 1.1.2 in the same folder.\n```\nimport duckdb\nwith duckdb.connect('ddb.db') as conn:\n    conn.execute(fr\"\"\"\n            CREATE OR REPLACE TABLE 'everflow_daily' AS SELECT * FROM read_csv_auto('myexport/*.csv', union_by_name = true, filename = true);\n        UPDATE everflow_daily SET sub5 = replace(sub5, '''', '');\n        UPDATE everflow_daily SET sub5 = lower(trim(sub5));\n        UPDATE everflow_daily SET sub5 = NULL WHERE sub5 = 'n/a';\n        UPDATE everflow_daily SET sub4 = NULL WHERE sub4 = 'N/A';\n        UPDATE everflow_daily SET sub3 = NULL WHERE sub3 = 'N/A';\n        ALTER TABLE everflow_daily\n        ADD offer_type VARCHAR(32);\n\n        UPDATE everflow_daily\n        SET offer_type = CASE \n            WHEN UPPER(offer_name) LIKE '%CPA%' THEN 'CPA'\n            WHEN UPPER(offer_name) LIKE '%CPC%' THEN 'CPC'\n            WHEN UPPER(offer_name) LIKE '%CPL%' THEN 'CPL'\n            ELSE 'Other'\n        END;\n            \"\"\")\n\n```\n\nrun this to see results\n\n```\nselect sub4, sum(revenue), len(sub4), count(*) from everflow_daily\nwhere network_affiliate_id <> 16201\nand sub4 = 'N/A'\nor sub4 = ''\nor sub4 is null\ngroup by 1\norder by 2 desc\n```\n\n![Image](https://github.com/user-attachments/assets/1f11c7a8-f21a-41ec-8dd1-5d20e5b8c8bf)\n\n\nthen run it again in 1.2.1 CLI\n\n![Image](https://github.com/user-attachments/assets/e10ed15e-8690-4d99-b40f-52bca3601937)\n\n### OS:\n\nlinux\n\n### DuckDB Version:\n\n1.2.1\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nJohn Doe\n\n### Affiliation:\n\nJohn Doe\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nRegression: incorrect results after UPDATE operation when migrating from DuckDB 1.1.2 to 1.2.1\n### What happens?\n\nhttps://github.com/duckdb/duckdb/issues/16780\nI was able to reproduce it, I've hashed certain columns but still don't feel comfortable sharing them in public, but I have the archive.\n\n### To Reproduce\n\nunarchive the 7z file\nrun this in python 3.12.7 duckdb 1.1.2 in the same folder.\n```\nimport duckdb\nwith duckdb.connect('ddb.db') as conn:\n    conn.execute(fr\"\"\"\n            CREATE OR REPLACE TABLE 'everflow_daily' AS SELECT * FROM read_csv_auto('myexport/*.csv', union_by_name = true, filename = true);\n        UPDATE everflow_daily SET sub5 = replace(sub5, '''', '');\n        UPDATE everflow_daily SET sub5 = lower(trim(sub5));\n        UPDATE everflow_daily SET sub5 = NULL WHERE sub5 = 'n/a';\n        UPDATE everflow_daily SET sub4 = NULL WHERE sub4 = 'N/A';\n        UPDATE everflow_daily SET sub3 = NULL WHERE sub3 = 'N/A';\n        ALTER TABLE everflow_daily\n        ADD offer_type VARCHAR(32);\n\n        UPDATE everflow_daily\n        SET offer_type = CASE \n            WHEN UPPER(offer_name) LIKE '%CPA%' THEN 'CPA'\n            WHEN UPPER(offer_name) LIKE '%CPC%' THEN 'CPC'\n            WHEN UPPER(offer_name) LIKE '%CPL%' THEN 'CPL'\n            ELSE 'Other'\n        END;\n            \"\"\")\n\n```\n\nrun this to see results\n\n```\nselect sub4, sum(revenue), len(sub4), count(*) from everflow_daily\nwhere network_affiliate_id <> 16201\nand sub4 = 'N/A'\nor sub4 = ''\nor sub4 is null\ngroup by 1\norder by 2 desc\n```\n\n![Image](https://github.com/user-attachments/assets/1f11c7a8-f21a-41ec-8dd1-5d20e5b8c8bf)\n\n\nthen run it again in 1.2.1 CLI\n\n![Image](https://github.com/user-attachments/assets/e10ed15e-8690-4d99-b40f-52bca3601937)\n\n### OS:\n\nlinux\n\n### DuckDB Version:\n\n1.2.1\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nJohn Doe\n\n### Affiliation:\n\nJohn Doe\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "\n", "created_at": "2025-04-01T16:09:51Z"}
{"repo": "duckdb/duckdb", "pull_number": 16880, "instance_id": "duckdb__duckdb-16880", "issue_numbers": ["16863"], "base_commit": "ca91dfd833972619a0ada1dacd719f884c669e25", "patch": "diff --git a/src/optimizer/pushdown/pushdown_left_join.cpp b/src/optimizer/pushdown/pushdown_left_join.cpp\nindex 8ac7d3e8472c..002bb2540de8 100644\n--- a/src/optimizer/pushdown/pushdown_left_join.cpp\n+++ b/src/optimizer/pushdown/pushdown_left_join.cpp\n@@ -6,6 +6,7 @@\n #include \"duckdb/common/types/value.hpp\"\n #include \"duckdb/common/unique_ptr.hpp\"\n #include \"duckdb/common/unordered_map.hpp\"\n+#include \"duckdb/common/vector.hpp\"\n #include \"duckdb/execution/expression_executor.hpp\"\n #include \"duckdb/optimizer/filter_pushdown.hpp\"\n #include \"duckdb/optimizer/optimizer.hpp\"\n@@ -15,6 +16,7 @@\n #include \"duckdb/planner/expression/bound_comparison_expression.hpp\"\n #include \"duckdb/planner/expression/bound_constant_expression.hpp\"\n #include \"duckdb/planner/expression_iterator.hpp\"\n+#include \"duckdb/planner/joinside.hpp\"\n #include \"duckdb/planner/logical_operator.hpp\"\n #include \"duckdb/planner/operator/logical_any_join.hpp\"\n #include \"duckdb/planner/operator/logical_comparison_join.hpp\"\n@@ -95,6 +97,7 @@ unique_ptr<LogicalOperator> FilterPushdown::PushdownLeftJoin(unique_ptr<LogicalO\n \t\t}\n \t}\n \t// now check the set of filters\n+\tvector<unique_ptr<Filter>> remaining_filters;\n \tfor (idx_t i = 0; i < filters.size(); i++) {\n \t\tauto side = JoinSide::GetJoinSide(filters[i]->bindings, left_bindings, right_bindings);\n \t\tif (side == JoinSide::LEFT) {\n@@ -127,6 +130,12 @@ unique_ptr<LogicalOperator> FilterPushdown::PushdownLeftJoin(unique_ptr<LogicalO\n \t\t\t\t// now push down the inner join\n \t\t\t\treturn PushdownInnerJoin(std::move(op), left_bindings, right_bindings);\n \t\t\t}\n+\t\t\t// we should keep the filters which only matched the right side\n+\t\t\tif (side == JoinSide::RIGHT) {\n+\t\t\t\tremaining_filters.push_back(std::move(filters[i]));\n+\t\t\t\tfilters.erase_at(i);\n+\t\t\t\ti--;\n+\t\t\t}\n \t\t}\n \t}\n \t// finally we check the FilterCombiner to see if there are any predicates we can push into the RHS\n@@ -185,6 +194,10 @@ unique_ptr<LogicalOperator> FilterPushdown::PushdownLeftJoin(unique_ptr<LogicalO\n \t\top->children[1] = right_pushdown.Rewrite(std::move(op->children[1]));\n \t}\n \n+\tfor (auto &filter : remaining_filters) {\n+\t\tfilters.push_back(std::move(filter));\n+\t}\n+\n \treturn PushFinalFilters(std::move(op));\n }\n \n", "test_patch": "diff --git a/test/optimizer/pushdown/issue_16863.test b/test/optimizer/pushdown/issue_16863.test\nnew file mode 100644\nindex 000000000000..2919d379393b\n--- /dev/null\n+++ b/test/optimizer/pushdown/issue_16863.test\n@@ -0,0 +1,18 @@\n+# name: test/optimizer/pushdown/issue_16863.test\n+# description: Test right join filter lost in filter pushdown\n+# group: [pushdown]\n+\n+statement ok\n+pragma enable_verification\n+\n+statement ok\n+CREATE TABLE t1 (c1 DATE);\n+\n+statement ok\n+INSERT INTO t1 (c1) VALUES ('2023-10-31');\n+\n+query II\n+SELECT t1.c1, (t1.c1 IS NULL)\n+FROM t1 RIGHT JOIN (SELECT NULL AS col0 FROM t1) AS sub0 ON true\n+WHERE (t1.c1 IS NULL);\n+----\n", "problem_statement": "Unexpected result when `RIGHT JOIN` with a subquery\n### What happens?\n\nConsider the following test case. The query unexpectedly returns a row `2023-10-31 false`. If the expression `t1.c1 IS NULL` is evaluated as `false`, then the filter should be evaluated as `false` and the query should return an empty result.\n\nMySQL or PostgreSQL can return the expected results.\n\n### To Reproduce\n\n```sql\nCREATE TABLE t1 (c1 DATE);\nINSERT INTO t1 (c1) VALUES ('2023-10-31');\n\nSELECT t1.c1, (t1.c1 IS NULL)\nFROM t1 RIGHT JOIN (SELECT NULL AS col0 FROM t1) AS sub0 ON true\nWHERE (t1.c1 IS NULL);\n-- Expected: empty\n-- Actual: 2023-10-31 false\n\n```\n\n### OS:\n\nUbuntu 22.04\n\n### DuckDB Version:\n\nv1.3.0-dev1894 77849ba91c\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nSuyang Zhong\n\n### Affiliation:\n\nNUS\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a source build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNot applicable - the reproduction does not require a data set\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "", "created_at": "2025-03-28T07:13:49Z"}
{"repo": "duckdb/duckdb", "pull_number": 16870, "instance_id": "duckdb__duckdb-16870", "issue_numbers": ["16639"], "base_commit": "b61d24f8f0e57030d82d335476ab829b29b7dcbf", "patch": "diff --git a/src/function/scalar/string/concat.cpp b/src/function/scalar/string/concat.cpp\nindex a6a495a95a6b..0ee57a752d6b 100644\n--- a/src/function/scalar/string/concat.cpp\n+++ b/src/function/scalar/string/concat.cpp\n@@ -335,9 +335,9 @@ static unique_ptr<BaseStatistics> ListConcatStats(ClientContext &context, Functi\n \n ScalarFunction ListConcatFun::GetFunction() {\n \t// The arguments and return types are set in the binder function.\n-\tauto fun = ScalarFunction({LogicalType::LIST(LogicalType::ANY), LogicalType::LIST(LogicalType::ANY)},\n-\t                          LogicalType::LIST(LogicalType::ANY), ConcatFunction, BindConcatFunction, nullptr,\n+\tauto fun = ScalarFunction({}, LogicalType::LIST(LogicalType::ANY), ConcatFunction, BindConcatFunction, nullptr,\n \t                          ListConcatStats);\n+\tfun.varargs = LogicalType::LIST(LogicalType::ANY);\n \tfun.null_handling = FunctionNullHandling::SPECIAL_HANDLING;\n \treturn fun;\n }\n", "test_patch": "diff --git a/test/sql/function/list/list_concat.test b/test/sql/function/list/list_concat.test\nindex a7a73702c61f..5e8aaed4c305 100644\n--- a/test/sql/function/list/list_concat.test\n+++ b/test/sql/function/list/list_concat.test\n@@ -41,6 +41,36 @@ SELECT list_concat([1, 2], [])\n ----\n [1, 2]\n \n+query T\n+SELECT list_concat([1, 2], [3, 4], [5, 6])\n+----\n+[1, 2, 3, 4, 5, 6]\n+\n+query T\n+SELECT list_concat([1, 2], [3, 4], [])\n+----\n+[1, 2, 3, 4]\n+\n+query T\n+SELECT list_concat([1, 2], [], [5, 6])\n+----\n+[1, 2, 5, 6]\n+\n+query T\n+SELECT list_concat([], [3, 4], [5, 6])\n+----\n+[3, 4, 5, 6]\n+\n+query T\n+SELECT list_concat([], [], [5, 6])\n+----\n+[5, 6]\n+\n+query T\n+SELECT list_concat([1, 2], [3, 4], [5, 6], [7, 8])\n+----\n+[1, 2, 3, 4, 5, 6, 7, 8]\n+\n statement error\n SELECT list_concat([1, 2], 3)\n ----\n@@ -96,22 +126,52 @@ SELECT list_concat([NULL], [3, 4])\n ----\n [NULL, 3, 4]\n \n+query T\n+SELECT list_concat([1, 2], [3, 4], [NULL])\n+----\n+[1, 2, 3, 4, NULL]\n+\n+query T\n+SELECT list_concat([1, 2], [3, 4], NULL)\n+----\n+[1, 2, 3, 4]\n+\n+query T\n+SELECT list_concat(NULL, [3, 4], [5, 6])\n+----\n+[3, 4, 5, 6]\n+\n+# nested types\n query T\n SELECT list_concat([[1, 2]], [[3, 4]])\n ----\n [[1, 2], [3, 4]]\n \n-# nested types\n+query T\n+SELECT list_concat([[1, 2]], [[3, 4]], [[5, 6]])\n+----\n+[[1, 2], [3, 4], [5, 6]]\n+\n query T\n SELECT list_concat([{a: 1}, {a: 2}], [{a: 3}, {a: 4}])\n ----\n [{'a': 1}, {'a': 2}, {'a': 3}, {'a': 4}]\n \n+query T\n+SELECT list_concat([{a: 1}, {a: 2}], [{a: 3}, {a: 4}], [{a: 5}, {a: 6}])\n+----\n+[{'a': 1}, {'a': 2}, {'a': 3}, {'a': 4}, {'a': 5}, {'a': 6}]\n+\n query T\n SELECT list_concat([[[1], [2]], [[3], [4]]], [[[5], [6]], [[7], [8]]])\n ----\n [[[1], [2]], [[3], [4]], [[5], [6]], [[7], [8]]]\n \n+query T\n+SELECT list_concat([[[1], [2]], [[3], [4]]], [[[5], [6]], [[7], [8]]], [[[9], [10]], [[11], [12]]])\n+----\n+[[[1], [2]], [[3], [4]], [[5], [6]], [[7], [8]], [[9], [10]], [[11], [12]]]\n+\n statement ok\n CREATE TABLE test AS SELECT range % 4 i, range j, range k FROM range(16)\n \n@@ -126,6 +186,14 @@ SELECT i, list_concat(j, k) FROM lists\n 2\t[2, 6, 10, 14, 2, 6, 10, 14]\n 3\t[3, 7, 11, 15, 3, 7, 11, 15]\n \n+query II rowsort\n+SELECT i, list_concat(j, k, j, k, j, k) FROM lists\n+----\n+0\t[0, 4, 8, 12, 0, 4, 8, 12, 0, 4, 8, 12, 0, 4, 8, 12, 0, 4, 8, 12, 0, 4, 8, 12]\n+1\t[1, 5, 9, 13, 1, 5, 9, 13, 1, 5, 9, 13, 1, 5, 9, 13, 1, 5, 9, 13, 1, 5, 9, 13]\n+2\t[2, 6, 10, 14, 2, 6, 10, 14, 2, 6, 10, 14, 2, 6, 10, 14, 2, 6, 10, 14, 2, 6, 10, 14]\n+3\t[3, 7, 11, 15, 3, 7, 11, 15, 3, 7, 11, 15, 3, 7, 11, 15, 3, 7, 11, 15, 3, 7, 11, 15]\n+\n statement error\n SELECT i, list_concat(j, cast(k AS VARCHAR)) FROM lists\n ----\n@@ -208,3 +276,5 @@ statement error\n SELECT concat([42], [84], 'str')\n ----\n an explicit cast is required\n+\n+\ndiff --git a/test/sql/function/string/test_concat_binding.test b/test/sql/function/string/test_concat_binding.test\nindex 7904df568af7..950e5a4a464d 100644\n--- a/test/sql/function/string/test_concat_binding.test\n+++ b/test/sql/function/string/test_concat_binding.test\n@@ -53,15 +53,25 @@ select concat([1], 'hello');\n ----\n Binder Error: Cannot concatenate types INTEGER[] and VARCHAR\n \n+statement error\n+SELECT list_concat([1, 2], ['3', '4'])\n+----\n+Binder Error: Cannot concatenate lists of types INTEGER[] and VARCHAR[]\n+\n+statement error\n+SELECT list_concat([1, 2], 4)\n+----\n+Binder Error: No function matches the given name and argument types 'list_concat(INTEGER[], INTEGER_LITERAL)'. You might need to add explicit type casts.\n+\n query I\n select 'hi' || NULL;\n ----\n NULL\n \n-statement error\n+query I\n select list_concat([1], [2], [3]);\n ----\n-Binder Error: No function matches the given name and argument types 'list_concat(INTEGER[], INTEGER[], INTEGER[])'.\n+[1, 2, 3]\n \n query I\n select [1] || [2] || [3];\ndiff --git a/test/sql/types/list/list_concat_null.test b/test/sql/types/list/list_concat_null.test\nindex de269df30d64..46decac505bd 100644\n--- a/test/sql/types/list/list_concat_null.test\n+++ b/test/sql/types/list/list_concat_null.test\n@@ -14,6 +14,12 @@ SELECT b || NULL from x1;\n statement ok\n SELECT NULL || NULL from x1;\n \n+statement ok\n+SELECT NULL || b || NULL from x1;\n+\n+statement ok\n+SELECT b || NULL || b from x1;\n+\n query I\n select concat([42]);\n ----\n@@ -28,3 +34,23 @@ query I\n select concat([42]::INT[1], [43]::INT[1], NULL::INT[1], [44]::INT[1], NULL::INT[1], [45]::INT[1]);\n ----\n [42, 43, 44, 45]\n+\n+query I\n+select list_concat([42]);\n+----\n+[42]\n+\n+query I\n+select list_concat([42], [43], [], [44], [], [45]);\n+----\n+[42, 43, 44, 45]\n+\n+query I\n+select list_concat([42]::INT[1], [43]::INT[1], NULL::INT[1], [44]::INT[1], NULL::INT[1], [45]::INT[1]);\n+----\n+[42, 43, 44, 45]\n+\n+query I\n+select list_concat([1]::INT[1], [2, 3]::INT[2]);\n+----\n+[1, 2, 3]\n", "problem_statement": "list_concat() only accepts 2 args whereas concat() accepts n args\n### What happens?\n\nAccording to https://github.com/duckdb/duckdb/pull/14443, it looks like the intention was to make `list_concat` work with N args. But if we test this, it errors: `SELECT list_concat([2, 3], [4, 5, 6], [7]);`\n\nIt looks like this PR got merged because only the concat() function was tested, which DOES accent N args: `SELECT concat([2, 3], [4, 5, 6], [7]);`\n\nSo, I propose that we should make the list_concat be an alias for concat, and behave exactly the same (skipping NULLs, accepting N args). Similarly, then the `||` operator will work the same for strings and arrays, propagating NULLs.\n\n### To Reproduce\n\n`SELECT list_concat([2, 3], [4, 5, 6], [7]);`\n\n### OS:\n\nNA\n\n### DuckDB Version:\n\n1.2.1\n\n### DuckDB Client:\n\nNA\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nNick Crews\n\n### Affiliation:\n\nShip Creek Group\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "", "created_at": "2025-03-27T14:35:26Z"}
{"repo": "duckdb/duckdb", "pull_number": 16851, "instance_id": "duckdb__duckdb-16851", "issue_numbers": ["16836", "16836"], "base_commit": "a4380e7c0895ebdb879bf1c32616004643834ff8", "patch": "diff --git a/src/storage/compression/roaring/common.cpp b/src/storage/compression/roaring/common.cpp\nindex 190e6dbf682e..c8450c32d7b8 100644\n--- a/src/storage/compression/roaring/common.cpp\n+++ b/src/storage/compression/roaring/common.cpp\n@@ -225,10 +225,6 @@ void RoaringScanPartial(ColumnSegment &segment, ColumnScanState &state, idx_t sc\n }\n \n void RoaringScan(ColumnSegment &segment, ColumnScanState &state, idx_t scan_count, Vector &result) {\n-\tif (result.GetVectorType() == VectorType::DICTIONARY_VECTOR) {\n-\t\t// dictionary encoding handles the validity itself\n-\t\treturn;\n-\t}\n \tRoaringScanPartial(segment, state, scan_count, result, 0);\n }\n \ndiff --git a/src/storage/compression/validity_uncompressed.cpp b/src/storage/compression/validity_uncompressed.cpp\nindex 48f2ec749ed3..8fa4acca9923 100644\n--- a/src/storage/compression/validity_uncompressed.cpp\n+++ b/src/storage/compression/validity_uncompressed.cpp\n@@ -401,10 +401,6 @@ void ValidityScanPartial(ColumnSegment &segment, ColumnScanState &state, idx_t s\n }\n \n void ValidityScan(ColumnSegment &segment, ColumnScanState &state, idx_t scan_count, Vector &result) {\n-\tif (result.GetVectorType() == VectorType::DICTIONARY_VECTOR) {\n-\t\t// dictionary encoding handles the validity itself\n-\t\treturn;\n-\t}\n \tresult.Flatten(scan_count);\n \n \tauto start = segment.GetRelativeIndex(state.row_index);\n", "test_patch": "diff --git a/test/sql/storage/update/dictionary_update_null.test b/test/sql/storage/update/dictionary_update_null.test\nnew file mode 100644\nindex 000000000000..038d4b21dcbe\n--- /dev/null\n+++ b/test/sql/storage/update/dictionary_update_null.test\n@@ -0,0 +1,21 @@\n+# name: test/sql/storage/update/dictionary_update_null.test\n+# description: Test updating only the validity mask of a dictionary compressed column\n+# group: [update]\n+\n+# load the DB from disk\n+load __TEST_DIR__/dictionary_update_null.db\n+\n+statement ok\n+SET force_compression='dictionary'\n+\n+statement ok\n+CREATE OR REPLACE TABLE 'everflow_daily' AS SELECT case when i%10=0 THEN uuid()::VARCHAR ELSE 'N/A' END sub4 FROM range(10000) t(i)\n+\n+statement ok\n+UPDATE everflow_daily SET sub4 = NULL WHERE sub4 = 'N/A';\n+\n+query I\n+select count(*) from everflow_daily\n+where sub4 = 'N/A'\n+----\n+0\n", "problem_statement": "Regression: incorrect results after UPDATE operation when migrating from DuckDB 1.1.2 to 1.2.1\n### What happens?\n\nhttps://github.com/duckdb/duckdb/issues/16780\nI was able to reproduce it, I've hashed certain columns but still don't feel comfortable sharing them in public, but I have the archive.\n\n### To Reproduce\n\nunarchive the 7z file\nrun this in python 3.12.7 duckdb 1.1.2 in the same folder.\n```\nimport duckdb\nwith duckdb.connect('ddb.db') as conn:\n    conn.execute(fr\"\"\"\n            CREATE OR REPLACE TABLE 'everflow_daily' AS SELECT * FROM read_csv_auto('myexport/*.csv', union_by_name = true, filename = true);\n        UPDATE everflow_daily SET sub5 = replace(sub5, '''', '');\n        UPDATE everflow_daily SET sub5 = lower(trim(sub5));\n        UPDATE everflow_daily SET sub5 = NULL WHERE sub5 = 'n/a';\n        UPDATE everflow_daily SET sub4 = NULL WHERE sub4 = 'N/A';\n        UPDATE everflow_daily SET sub3 = NULL WHERE sub3 = 'N/A';\n        ALTER TABLE everflow_daily\n        ADD offer_type VARCHAR(32);\n\n        UPDATE everflow_daily\n        SET offer_type = CASE \n            WHEN UPPER(offer_name) LIKE '%CPA%' THEN 'CPA'\n            WHEN UPPER(offer_name) LIKE '%CPC%' THEN 'CPC'\n            WHEN UPPER(offer_name) LIKE '%CPL%' THEN 'CPL'\n            ELSE 'Other'\n        END;\n            \"\"\")\n\n```\n\nrun this to see results\n\n```\nselect sub4, sum(revenue), len(sub4), count(*) from everflow_daily\nwhere network_affiliate_id <> 16201\nand sub4 = 'N/A'\nor sub4 = ''\nor sub4 is null\ngroup by 1\norder by 2 desc\n```\n\n![Image](https://github.com/user-attachments/assets/1f11c7a8-f21a-41ec-8dd1-5d20e5b8c8bf)\n\n\nthen run it again in 1.2.1 CLI\n\n![Image](https://github.com/user-attachments/assets/e10ed15e-8690-4d99-b40f-52bca3601937)\n\n### OS:\n\nlinux\n\n### DuckDB Version:\n\n1.2.1\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nJohn Doe\n\n### Affiliation:\n\nJohn Doe\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nRegression: incorrect results after UPDATE operation when migrating from DuckDB 1.1.2 to 1.2.1\n### What happens?\n\nhttps://github.com/duckdb/duckdb/issues/16780\nI was able to reproduce it, I've hashed certain columns but still don't feel comfortable sharing them in public, but I have the archive.\n\n### To Reproduce\n\nunarchive the 7z file\nrun this in python 3.12.7 duckdb 1.1.2 in the same folder.\n```\nimport duckdb\nwith duckdb.connect('ddb.db') as conn:\n    conn.execute(fr\"\"\"\n            CREATE OR REPLACE TABLE 'everflow_daily' AS SELECT * FROM read_csv_auto('myexport/*.csv', union_by_name = true, filename = true);\n        UPDATE everflow_daily SET sub5 = replace(sub5, '''', '');\n        UPDATE everflow_daily SET sub5 = lower(trim(sub5));\n        UPDATE everflow_daily SET sub5 = NULL WHERE sub5 = 'n/a';\n        UPDATE everflow_daily SET sub4 = NULL WHERE sub4 = 'N/A';\n        UPDATE everflow_daily SET sub3 = NULL WHERE sub3 = 'N/A';\n        ALTER TABLE everflow_daily\n        ADD offer_type VARCHAR(32);\n\n        UPDATE everflow_daily\n        SET offer_type = CASE \n            WHEN UPPER(offer_name) LIKE '%CPA%' THEN 'CPA'\n            WHEN UPPER(offer_name) LIKE '%CPC%' THEN 'CPC'\n            WHEN UPPER(offer_name) LIKE '%CPL%' THEN 'CPL'\n            ELSE 'Other'\n        END;\n            \"\"\")\n\n```\n\nrun this to see results\n\n```\nselect sub4, sum(revenue), len(sub4), count(*) from everflow_daily\nwhere network_affiliate_id <> 16201\nand sub4 = 'N/A'\nor sub4 = ''\nor sub4 is null\ngroup by 1\norder by 2 desc\n```\n\n![Image](https://github.com/user-attachments/assets/1f11c7a8-f21a-41ec-8dd1-5d20e5b8c8bf)\n\n\nthen run it again in 1.2.1 CLI\n\n![Image](https://github.com/user-attachments/assets/e10ed15e-8690-4d99-b40f-52bca3601937)\n\n### OS:\n\nlinux\n\n### DuckDB Version:\n\n1.2.1\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nJohn Doe\n\n### Affiliation:\n\nJohn Doe\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "Hi, thanks for your work on a reproducer. Is it possible to share the archive in private? If so, please email them to gabor@duckdblabs.com or reach out and we'll discuss a way to transfer it.\nHi, thanks for your work on a reproducer. Is it possible to share the archive in private? If so, please email them to gabor@duckdblabs.com or reach out and we'll discuss a way to transfer it.", "created_at": "2025-03-26T18:09:49Z"}
{"repo": "duckdb/duckdb", "pull_number": 16832, "instance_id": "duckdb__duckdb-16832", "issue_numbers": ["16783", "16783"], "base_commit": "d34a98dc0d2bb23e97994d28c69c83419691191e", "patch": "diff --git a/extension/jemalloc/jemalloc/include/jemalloc/jemalloc.h b/extension/jemalloc/jemalloc/include/jemalloc/jemalloc.h\nindex 8d4c1b13f259..3e6c661733ac 100644\n--- a/extension/jemalloc/jemalloc/include/jemalloc/jemalloc.h\n+++ b/extension/jemalloc/jemalloc/include/jemalloc/jemalloc.h\n@@ -5,8 +5,8 @@\n extern \"C\" {\n #endif\n \n-// DuckDB uses a 5s decay\n-#define DUCKDB_JEMALLOC_DECAY 5\n+// DuckDB uses a 1s decay\n+#define DUCKDB_JEMALLOC_DECAY 1\n \n /* Defined if __attribute__((...)) syntax is supported. */\n #define JEMALLOC_HAVE_ATTR\ndiff --git a/src/common/adbc/adbc.cpp b/src/common/adbc/adbc.cpp\nindex 71617e1e9376..e9dd12f7623a 100644\n--- a/src/common/adbc/adbc.cpp\n+++ b/src/common/adbc/adbc.cpp\n@@ -17,7 +17,7 @@\n #include \"duckdb/common/adbc/options.h\"\n #include \"duckdb/common/adbc/single_batch_array_stream.hpp\"\n #include \"duckdb/function/table/arrow.hpp\"\n-\n+#include \"duckdb/common/adbc/wrappers.hpp\"\n #include <stdlib.h>\n #include <string.h>\n \n@@ -249,7 +249,9 @@ AdbcStatusCode ConnectionNew(struct AdbcConnection *connection, struct AdbcError\n \t\treturn ADBC_STATUS_INVALID_ARGUMENT;\n \t}\n \n-\tconnection->private_data = nullptr;\n+\tauto connection_wrapper = new duckdb::DuckDBAdbcConnectionWrapper();\n+\tconnection_wrapper->connection = nullptr;\n+\tconnection->private_data = connection_wrapper;\n \treturn ADBC_STATUS_OK;\n }\n \n@@ -263,45 +265,65 @@ AdbcStatusCode ExecuteQuery(duckdb::Connection *conn, const char *query, struct\n \treturn ADBC_STATUS_OK;\n }\n \n+AdbcStatusCode InternalSetOption(duckdb::Connection &conn, std::unordered_map<std::string, std::string> &options,\n+                                 struct AdbcError *error) {\n+\t// If we got here, the options have already been validated and are acceptable\n+\tfor (auto &option : options) {\n+\t\tif (strcmp(option.first.c_str(), ADBC_CONNECTION_OPTION_AUTOCOMMIT) == 0) {\n+\t\t\tif (strcmp(option.second.c_str(), ADBC_OPTION_VALUE_ENABLED) == 0) {\n+\t\t\t\tif (conn.HasActiveTransaction()) {\n+\t\t\t\t\tAdbcStatusCode status = ExecuteQuery(&conn, \"COMMIT\", error);\n+\t\t\t\t\tif (status != ADBC_STATUS_OK) {\n+\t\t\t\t\t\toptions.clear();\n+\t\t\t\t\t\treturn status;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t} else if (strcmp(option.second.c_str(), ADBC_OPTION_VALUE_DISABLED) == 0) {\n+\t\t\t\tif (!conn.HasActiveTransaction()) {\n+\t\t\t\t\tAdbcStatusCode status = ExecuteQuery(&conn, \"START TRANSACTION\", error);\n+\t\t\t\t\tif (status != ADBC_STATUS_OK) {\n+\t\t\t\t\t\toptions.clear();\n+\t\t\t\t\t\treturn status;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\toptions.clear();\n+\treturn ADBC_STATUS_OK;\n+}\n AdbcStatusCode ConnectionSetOption(struct AdbcConnection *connection, const char *key, const char *value,\n                                    struct AdbcError *error) {\n \tif (!connection) {\n \t\tSetError(error, \"Connection is not set\");\n \t\treturn ADBC_STATUS_INVALID_ARGUMENT;\n \t}\n-\n-\tauto conn = static_cast<duckdb::Connection *>(connection->private_data);\n+\tstd::string key_string = std::string(key);\n+\tstd::string key_value = std::string(value);\n+\tauto conn_wrapper = static_cast<duckdb::DuckDBAdbcConnectionWrapper *>(connection->private_data);\n \tif (strcmp(key, ADBC_CONNECTION_OPTION_AUTOCOMMIT) == 0) {\n \t\tif (strcmp(value, ADBC_OPTION_VALUE_ENABLED) == 0) {\n-\t\t\tif (conn->HasActiveTransaction()) {\n-\t\t\t\tAdbcStatusCode status = ExecuteQuery(conn, \"COMMIT\", error);\n-\t\t\t\tif (status != ADBC_STATUS_OK) {\n-\t\t\t\t\treturn status;\n-\t\t\t\t}\n-\t\t\t} else {\n-\t\t\t\t// no-op\n-\t\t\t}\n+\t\t\tconn_wrapper->options[key_string] = key_value;\n \t\t} else if (strcmp(value, ADBC_OPTION_VALUE_DISABLED) == 0) {\n-\t\t\tif (conn->HasActiveTransaction()) {\n-\t\t\t\t// no-op\n-\t\t\t} else {\n-\t\t\t\t// begin\n-\t\t\t\tAdbcStatusCode status = ExecuteQuery(conn, \"START TRANSACTION\", error);\n-\t\t\t\tif (status != ADBC_STATUS_OK) {\n-\t\t\t\t\treturn status;\n-\t\t\t\t}\n-\t\t\t}\n+\t\t\tconn_wrapper->options[key_string] = key_value;\n \t\t} else {\n \t\t\tauto error_message = \"Invalid connection option value \" + std::string(key) + \"=\" + std::string(value);\n \t\t\tSetError(error, error_message);\n \t\t\treturn ADBC_STATUS_INVALID_ARGUMENT;\n \t\t}\n+\t} else {\n+\t\t// This is an unknown option to the DuckDB driver\n+\t\tauto error_message =\n+\t\t    \"Unknown connection option \" + std::string(key) + \"=\" + (value ? std::string(value) : \"(NULL)\");\n+\t\tSetError(error, error_message);\n+\t\treturn ADBC_STATUS_NOT_IMPLEMENTED;\n+\t}\n+\tif (!conn_wrapper->connection) {\n+\t\t// If the connection has not yet been initialized, we just return here.\n \t\treturn ADBC_STATUS_OK;\n \t}\n-\tauto error_message =\n-\t    \"Unknown connection option \" + std::string(key) + \"=\" + (value ? std::string(value) : \"(NULL)\");\n-\tSetError(error, error_message);\n-\treturn ADBC_STATUS_NOT_IMPLEMENTED;\n+\tauto conn = reinterpret_cast<duckdb::Connection *>(conn_wrapper->connection);\n+\treturn InternalSetOption(*conn, conn_wrapper->options, error);\n }\n \n AdbcStatusCode ConnectionReadPartition(struct AdbcConnection *connection, const uint8_t *serialized_partition,\n@@ -323,7 +345,8 @@ AdbcStatusCode ConnectionCommit(struct AdbcConnection *connection, struct AdbcEr\n \t\tSetError(error, \"Connection is not set\");\n \t\treturn ADBC_STATUS_INVALID_ARGUMENT;\n \t}\n-\tauto conn = static_cast<duckdb::Connection *>(connection->private_data);\n+\tauto conn_wrapper = static_cast<duckdb::DuckDBAdbcConnectionWrapper *>(connection->private_data);\n+\tauto conn = reinterpret_cast<duckdb::Connection *>(conn_wrapper->connection);\n \tif (!conn->HasActiveTransaction()) {\n \t\tSetError(error, \"No active transaction, cannot commit\");\n \t\treturn ADBC_STATUS_INVALID_STATE;\n@@ -341,7 +364,8 @@ AdbcStatusCode ConnectionRollback(struct AdbcConnection *connection, struct Adbc\n \t\tSetError(error, \"Connection is not set\");\n \t\treturn ADBC_STATUS_INVALID_ARGUMENT;\n \t}\n-\tauto conn = static_cast<duckdb::Connection *>(connection->private_data);\n+\tauto conn_wrapper = static_cast<duckdb::DuckDBAdbcConnectionWrapper *>(connection->private_data);\n+\tauto conn = reinterpret_cast<duckdb::Connection *>(conn_wrapper->connection);\n \tif (!conn->HasActiveTransaction()) {\n \t\tSetError(error, \"No active transaction, cannot rollback\");\n \t\treturn ADBC_STATUS_INVALID_STATE;\n@@ -479,16 +503,25 @@ AdbcStatusCode ConnectionInit(struct AdbcConnection *connection, struct AdbcData\n \t\treturn ADBC_STATUS_INVALID_ARGUMENT;\n \t}\n \tauto database_wrapper = static_cast<DuckDBAdbcDatabaseWrapper *>(database->private_data);\n+\tauto conn_wrapper = static_cast<duckdb::DuckDBAdbcConnectionWrapper *>(connection->private_data);\n+\tconn_wrapper->connection = nullptr;\n \n-\tconnection->private_data = nullptr;\n-\tauto res =\n-\t    duckdb_connect(database_wrapper->database, reinterpret_cast<duckdb_connection *>(&connection->private_data));\n-\treturn CheckResult(res, error, \"Failed to connect to Database\");\n+\tauto res = duckdb_connect(database_wrapper->database, &conn_wrapper->connection);\n+\tauto adbc_status = CheckResult(res, error, \"Failed to connect to Database\");\n+\tif (adbc_status != ADBC_STATUS_OK) {\n+\t\treturn adbc_status;\n+\t}\n+\t// We might have options to set\n+\tauto conn = reinterpret_cast<duckdb::Connection *>(conn_wrapper->connection);\n+\treturn InternalSetOption(*conn, conn_wrapper->options, error);\n }\n \n AdbcStatusCode ConnectionRelease(struct AdbcConnection *connection, struct AdbcError *error) {\n \tif (connection && connection->private_data) {\n-\t\tduckdb_disconnect(reinterpret_cast<duckdb_connection *>(&connection->private_data));\n+\t\tauto conn_wrapper = static_cast<duckdb::DuckDBAdbcConnectionWrapper *>(connection->private_data);\n+\t\tauto conn = reinterpret_cast<duckdb::Connection *>(conn_wrapper->connection);\n+\t\tduckdb_disconnect(reinterpret_cast<duckdb_connection *>(&conn));\n+\t\tdelete conn_wrapper;\n \t\tconnection->private_data = nullptr;\n \t}\n \treturn ADBC_STATUS_OK;\n@@ -638,7 +671,9 @@ AdbcStatusCode StatementNew(struct AdbcConnection *connection, struct AdbcStatem\n \t}\n \n \tstatement->private_data = statement_wrapper;\n-\tstatement_wrapper->connection = static_cast<duckdb_connection>(connection->private_data);\n+\tauto conn_wrapper = static_cast<duckdb::DuckDBAdbcConnectionWrapper *>(connection->private_data);\n+\n+\tstatement_wrapper->connection = conn_wrapper->connection;\n \tstatement_wrapper->statement = nullptr;\n \tstatement_wrapper->result = nullptr;\n \tstatement_wrapper->ingestion_stream.release = nullptr;\ndiff --git a/src/common/adbc/driver_manager.cpp b/src/common/adbc/driver_manager.cpp\nindex 1d2bc1f233c3..9ac932380aee 100644\n--- a/src/common/adbc/driver_manager.cpp\n+++ b/src/common/adbc/driver_manager.cpp\n@@ -1080,6 +1080,7 @@ AdbcStatusCode AdbcConnectionGetTableTypes(struct AdbcConnection *connection, st\n \n AdbcStatusCode AdbcConnectionInit(struct AdbcConnection *connection, struct AdbcDatabase *database,\n                                   struct AdbcError *error) {\n+\n \tif (!connection->private_data) {\n \t\tSetError(error, \"Must call AdbcConnectionNew first\");\n \t\treturn ADBC_STATUS_INVALID_STATE;\n@@ -1087,6 +1088,7 @@ AdbcStatusCode AdbcConnectionInit(struct AdbcConnection *connection, struct Adbc\n \t\tSetError(error, \"Database is not initialized\");\n \t\treturn ADBC_STATUS_INVALID_ARGUMENT;\n \t}\n+\n \tTempConnection *args = reinterpret_cast<TempConnection *>(connection->private_data);\n \tconnection->private_data = nullptr;\n \tstd::unordered_map<std::string, std::string> options = std::move(args->options);\n@@ -1176,7 +1178,7 @@ AdbcStatusCode AdbcConnectionRollback(struct AdbcConnection *connection, struct\n \n AdbcStatusCode AdbcConnectionSetOption(struct AdbcConnection *connection, const char *key, const char *value,\n                                        struct AdbcError *error) {\n-\tif (!connection->private_data) {\n+\tif (!connection || !connection->private_data) {\n \t\tSetError(error, \"AdbcConnectionSetOption: must AdbcConnectionNew first\");\n \t\treturn ADBC_STATUS_INVALID_STATE;\n \t}\ndiff --git a/src/common/arrow/appender/CMakeLists.txt b/src/common/arrow/appender/CMakeLists.txt\nindex a342652e23a3..090e7bb15925 100644\n--- a/src/common/arrow/appender/CMakeLists.txt\n+++ b/src/common/arrow/appender/CMakeLists.txt\n@@ -1,5 +1,11 @@\n-add_library_unity(duckdb_common_arrow_appender OBJECT bool_data.cpp\n-                  struct_data.cpp union_data.cpp fixed_size_list_data.cpp)\n+add_library_unity(\n+  duckdb_common_arrow_appender\n+  OBJECT\n+  bool_data.cpp\n+  fixed_size_list_data.cpp\n+  null_data.cpp\n+  struct_data.cpp\n+  union_data.cpp)\n set(ALL_OBJECT_FILES\n     ${ALL_OBJECT_FILES} $<TARGET_OBJECTS:duckdb_common_arrow_appender>\n     PARENT_SCOPE)\ndiff --git a/src/common/arrow/appender/null_data.cpp b/src/common/arrow/appender/null_data.cpp\nnew file mode 100644\nindex 000000000000..5f8806ed6761\n--- /dev/null\n+++ b/src/common/arrow/appender/null_data.cpp\n@@ -0,0 +1,19 @@\n+#include \"duckdb/common/arrow/arrow_appender.hpp\"\n+#include \"duckdb/common/arrow/appender/null_data.hpp\"\n+\n+namespace duckdb {\n+\n+void ArrowNullData::Initialize(ArrowAppendData &result, const LogicalType &type, idx_t capacity) {\n+\t// nop\n+}\n+\n+void ArrowNullData::Append(ArrowAppendData &append_data, Vector &input, idx_t from, idx_t to, idx_t input_size) {\n+\tidx_t size = to - from;\n+\tappend_data.row_count += size;\n+}\n+\n+void ArrowNullData::Finalize(ArrowAppendData &append_data, const LogicalType &type, ArrowArray *result) {\n+\tresult->n_buffers = 0;\n+}\n+\n+} // namespace duckdb\ndiff --git a/src/common/arrow/arrow_appender.cpp b/src/common/arrow/arrow_appender.cpp\nindex 83f190b5700d..ee49bdd85c4e 100644\n--- a/src/common/arrow/arrow_appender.cpp\n+++ b/src/common/arrow/arrow_appender.cpp\n@@ -144,6 +144,9 @@ static void InitializeAppenderForType(ArrowAppendData &append_data) {\n static void InitializeFunctionPointers(ArrowAppendData &append_data, const LogicalType &type) {\n \t// handle special logical types\n \tswitch (type.id()) {\n+\tcase LogicalTypeId::SQLNULL:\n+\t\tInitializeAppenderForType<ArrowNullData>(append_data);\n+\t\tbreak;\n \tcase LogicalTypeId::BOOLEAN:\n \t\tInitializeAppenderForType<ArrowBoolData>(append_data);\n \t\tbreak;\ndiff --git a/src/common/arrow/arrow_converter.cpp b/src/common/arrow/arrow_converter.cpp\nindex 02b3999a06d0..5369b3d423d9 100644\n--- a/src/common/arrow/arrow_converter.cpp\n+++ b/src/common/arrow/arrow_converter.cpp\n@@ -61,6 +61,30 @@ void InitializeChild(ArrowSchema &child, DuckDBArrowSchemaHolder &root_holder, c\n void SetArrowFormat(DuckDBArrowSchemaHolder &root_holder, ArrowSchema &child, const LogicalType &type,\n                     ClientProperties &options, ClientContext &context);\n \n+void SetArrowStructFormat(DuckDBArrowSchemaHolder &root_holder, ArrowSchema &child, const LogicalType &type,\n+                          ClientProperties &options, ClientContext &context, bool map_is_parent = false) {\n+\tchild.format = \"+s\";\n+\tauto &child_types = StructType::GetChildTypes(type);\n+\tchild.n_children = NumericCast<int64_t>(child_types.size());\n+\troot_holder.nested_children.emplace_back();\n+\troot_holder.nested_children.back().resize(child_types.size());\n+\troot_holder.nested_children_ptr.emplace_back();\n+\troot_holder.nested_children_ptr.back().resize(child_types.size());\n+\tfor (idx_t type_idx = 0; type_idx < child_types.size(); type_idx++) {\n+\t\troot_holder.nested_children_ptr.back()[type_idx] = &root_holder.nested_children.back()[type_idx];\n+\t}\n+\tchild.children = &root_holder.nested_children_ptr.back()[0];\n+\tfor (size_t type_idx = 0; type_idx < child_types.size(); type_idx++) {\n+\t\tInitializeChild(*child.children[type_idx], root_holder);\n+\t\troot_holder.owned_type_names.push_back(AddName(child_types[type_idx].first));\n+\t\tchild.children[type_idx]->name = root_holder.owned_type_names.back().get();\n+\t\tSetArrowFormat(root_holder, *child.children[type_idx], child_types[type_idx].second, options, context);\n+\t}\n+\tif (map_is_parent) {\n+\t\tchild.children[0]->flags = 0; // Set the 'keys' field to non-nullable\n+\t}\n+}\n+\n void SetArrowMapFormat(DuckDBArrowSchemaHolder &root_holder, ArrowSchema &child, const LogicalType &type,\n                        ClientProperties &options, ClientContext &context) {\n \tchild.format = \"+m\";\n@@ -74,7 +98,7 @@ void SetArrowMapFormat(DuckDBArrowSchemaHolder &root_holder, ArrowSchema &child,\n \tchild.children = &root_holder.nested_children_ptr.back()[0];\n \tchild.children[0]->name = \"entries\";\n \tchild.children[0]->flags = 0; // Set the 'entries' field to non-nullable\n-\tSetArrowFormat(root_holder, **child.children, ListType::GetChildType(type), options, context);\n+\tSetArrowStructFormat(root_holder, **child.children, ListType::GetChildType(type), options, context, true);\n }\n \n bool SetArrowExtension(DuckDBArrowSchemaHolder &root_holder, ArrowSchema &child, const LogicalType &type,\n@@ -265,26 +289,7 @@ void SetArrowFormat(DuckDBArrowSchemaHolder &root_holder, ArrowSchema &child, co\n \t\tbreak;\n \t}\n \tcase LogicalTypeId::STRUCT: {\n-\t\tchild.format = \"+s\";\n-\t\tauto &child_types = StructType::GetChildTypes(type);\n-\t\tchild.n_children = NumericCast<int64_t>(child_types.size());\n-\t\troot_holder.nested_children.emplace_back();\n-\t\troot_holder.nested_children.back().resize(child_types.size());\n-\t\troot_holder.nested_children_ptr.emplace_back();\n-\t\troot_holder.nested_children_ptr.back().resize(child_types.size());\n-\t\tfor (idx_t type_idx = 0; type_idx < child_types.size(); type_idx++) {\n-\t\t\troot_holder.nested_children_ptr.back()[type_idx] = &root_holder.nested_children.back()[type_idx];\n-\t\t}\n-\t\tchild.children = &root_holder.nested_children_ptr.back()[0];\n-\t\tfor (size_t type_idx = 0; type_idx < child_types.size(); type_idx++) {\n-\n-\t\t\tInitializeChild(*child.children[type_idx], root_holder);\n-\n-\t\t\troot_holder.owned_type_names.push_back(AddName(child_types[type_idx].first));\n-\n-\t\t\tchild.children[type_idx]->name = root_holder.owned_type_names.back().get();\n-\t\t\tSetArrowFormat(root_holder, *child.children[type_idx], child_types[type_idx].second, options, context);\n-\t\t}\n+\t\tSetArrowStructFormat(root_holder, child, type, options, context);\n \t\tbreak;\n \t}\n \tcase LogicalTypeId::ARRAY: {\ndiff --git a/src/execution/operator/csv_scanner/sniffer/header_detection.cpp b/src/execution/operator/csv_scanner/sniffer/header_detection.cpp\nindex 2459deff7fbc..4d77bf3f99a3 100644\n--- a/src/execution/operator/csv_scanner/sniffer/header_detection.cpp\n+++ b/src/execution/operator/csv_scanner/sniffer/header_detection.cpp\n@@ -45,6 +45,11 @@ static string TrimWhitespace(const string &col_name) {\n \treturn col_name.substr(begin, end - begin);\n }\n \n+bool NormalizeThis(const KeywordCategory category, const string &col_name) {\n+\treturn category == KeywordCategory::KEYWORD_UNRESERVED || category == KeywordCategory::KEYWORD_TYPE_FUNC ||\n+\t       category == KeywordCategory::KEYWORD_RESERVED;\n+}\n+\n static string NormalizeColumnName(const string &col_name) {\n \t// normalize UTF8 characters to NFKD\n \tauto nfkd = utf8proc_NFKD(reinterpret_cast<const utf8proc_uint8_t *>(col_name.c_str()),\n@@ -89,8 +94,8 @@ static string NormalizeColumnName(const string &col_name) {\n \n \t// prepend _ if name starts with a digit or is a reserved keyword\n \tauto keyword = KeywordHelper::KeywordCategoryType(col_name_cleaned);\n-\tif (keyword == KeywordCategory::KEYWORD_TYPE_FUNC || keyword == KeywordCategory::KEYWORD_RESERVED ||\n-\t    (col_name_cleaned[0] >= '0' && col_name_cleaned[0] <= '9')) {\n+\n+\tif (NormalizeThis(keyword, col_name_cleaned) || (col_name_cleaned[0] >= '0' && col_name_cleaned[0] <= '9')) {\n \t\tcol_name_cleaned = \"_\" + col_name_cleaned;\n \t}\n \treturn col_name_cleaned;\ndiff --git a/src/execution/operator/order/physical_top_n.cpp b/src/execution/operator/order/physical_top_n.cpp\nindex 669c25a5ed80..cba653a8e5c9 100644\n--- a/src/execution/operator/order/physical_top_n.cpp\n+++ b/src/execution/operator/order/physical_top_n.cpp\n@@ -163,8 +163,8 @@ TopNHeap::TopNHeap(ClientContext &context, Allocator &allocator, const vector<Lo\n                    const vector<BoundOrderByNode> &orders_p, idx_t limit, idx_t offset)\n     : allocator(allocator), buffer_manager(BufferManager::GetBufferManager(context)), payload_types(payload_types_p),\n       orders(orders_p), limit(limit), offset(offset), heap_size(limit + offset), executor(context),\n-      matching_sel(STANDARD_VECTOR_SIZE), final_sel(STANDARD_VECTOR_SIZE), true_sel(STANDARD_VECTOR_SIZE),\n-      false_sel(STANDARD_VECTOR_SIZE), new_remaining_sel(STANDARD_VECTOR_SIZE) {\n+      sort_key_heap(allocator), matching_sel(STANDARD_VECTOR_SIZE), final_sel(STANDARD_VECTOR_SIZE),\n+      true_sel(STANDARD_VECTOR_SIZE), false_sel(STANDARD_VECTOR_SIZE), new_remaining_sel(STANDARD_VECTOR_SIZE) {\n \t// initialize the executor and the sort_chunk\n \tvector<LogicalType> sort_types;\n \tfor (auto &order : orders) {\n@@ -190,7 +190,7 @@ TopNHeap::TopNHeap(ClientContext &context, const vector<LogicalType> &payload_ty\n \n TopNHeap::TopNHeap(ExecutionContext &context, const vector<LogicalType> &payload_types,\n                    const vector<BoundOrderByNode> &orders, idx_t limit, idx_t offset)\n-    : TopNHeap(context.client, Allocator::Get(context.client), payload_types, orders, limit, offset) {\n+    : TopNHeap(context.client, BufferAllocator::Get(context.client), payload_types, orders, limit, offset) {\n }\n \n void TopNHeap::AddSmallHeap(DataChunk &input, Vector &sort_keys_vec) {\ndiff --git a/src/function/aggregate/sorted_aggregate_function.cpp b/src/function/aggregate/sorted_aggregate_function.cpp\nindex 5e3747cb462f..b6dbb7ece8c7 100644\n--- a/src/function/aggregate/sorted_aggregate_function.cpp\n+++ b/src/function/aggregate/sorted_aggregate_function.cpp\n@@ -133,18 +133,20 @@ struct SortedAggregateState {\n \t\t}\n \t}\n \n-\tstatic inline void InitializeChunk(unique_ptr<DataChunk> &chunk, const vector<LogicalType> &types) {\n+\tstatic inline void InitializeChunk(Allocator &allocator, unique_ptr<DataChunk> &chunk,\n+\t                                   const vector<LogicalType> &types) {\n \t\tif (!chunk && !types.empty()) {\n \t\t\tchunk = make_uniq<DataChunk>();\n-\t\t\tchunk->Initialize(Allocator::DefaultAllocator(), types);\n+\t\t\tchunk->Initialize(allocator, types);\n \t\t}\n \t}\n \n \tvoid InitializeChunks(const SortedAggregateBindData &order_bind) {\n \t\t// Lazy instantiation of the buffer chunks\n-\t\tInitializeChunk(sort_chunk, order_bind.sort_types);\n+\t\tauto &allocator = BufferManager::GetBufferManager(order_bind.context).GetBufferAllocator();\n+\t\tInitializeChunk(allocator, sort_chunk, order_bind.sort_types);\n \t\tif (!order_bind.sorted_on_args) {\n-\t\t\tInitializeChunk(arg_chunk, order_bind.arg_types);\n+\t\t\tInitializeChunk(allocator, arg_chunk, order_bind.arg_types);\n \t\t}\n \t}\n \n@@ -565,10 +567,12 @@ struct SortedAggregateFunction {\n \t\tauto &context = order_bind.context;\n \t\tRowLayout payload_layout;\n \t\tpayload_layout.Initialize(order_bind.arg_types);\n+\n+\t\tauto &buffer_allocator = BufferManager::GetBufferManager(order_bind.context).GetBufferAllocator();\n \t\tDataChunk chunk;\n-\t\tchunk.Initialize(Allocator::DefaultAllocator(), order_bind.arg_types);\n+\t\tchunk.Initialize(buffer_allocator, order_bind.arg_types);\n \t\tDataChunk sliced;\n-\t\tsliced.Initialize(Allocator::DefaultAllocator(), order_bind.arg_types);\n+\t\tsliced.Initialize(buffer_allocator, order_bind.arg_types);\n \n \t\t//\t Reusable inner state\n \t\tauto &aggr = order_bind.function;\n@@ -607,7 +611,7 @@ struct SortedAggregateFunction {\n \t\tlocal_sort->Initialize(*global_sort, global_sort->buffer_manager);\n \n \t\tDataChunk prefixed;\n-\t\tprefixed.Initialize(Allocator::DefaultAllocator(), global_sort->sort_layout.logical_types);\n+\t\tprefixed.Initialize(buffer_allocator, global_sort->sort_layout.logical_types);\n \n \t\t//\tGo through the states accumulating values to sort until we hit the sort threshold\n \t\tidx_t unsorted_count = 0;\ndiff --git a/src/function/table/system/duckdb_memory.cpp b/src/function/table/system/duckdb_memory.cpp\nindex a1eb044b7589..c5b2084c5103 100644\n--- a/src/function/table/system/duckdb_memory.cpp\n+++ b/src/function/table/system/duckdb_memory.cpp\n@@ -31,6 +31,13 @@ unique_ptr<GlobalTableFunctionState> DuckDBMemoryInit(ClientContext &context, Ta\n \treturn std::move(result);\n }\n \n+int64_t ClampReportedMemory(idx_t memory_usage) {\n+\tif (memory_usage > static_cast<idx_t>(NumericLimits<int64_t>::Maximum())) {\n+\t\treturn 0;\n+\t}\n+\treturn UnsafeNumericCast<int64_t>(memory_usage);\n+}\n+\n void DuckDBMemoryFunction(ClientContext &context, TableFunctionInput &data_p, DataChunk &output) {\n \tauto &data = data_p.global_state->Cast<DuckDBMemoryData>();\n \tif (data.offset >= data.entries.size()) {\n@@ -47,9 +54,9 @@ void DuckDBMemoryFunction(ClientContext &context, TableFunctionInput &data_p, Da\n \t\t// tag, VARCHAR\n \t\toutput.SetValue(col++, count, EnumUtil::ToString(entry.tag));\n \t\t// memory_usage_bytes, BIGINT\n-\t\toutput.SetValue(col++, count, Value::BIGINT(NumericCast<int64_t>(entry.size)));\n+\t\toutput.SetValue(col++, count, Value::BIGINT(ClampReportedMemory(entry.size)));\n \t\t// temporary_storage_bytes, BIGINT\n-\t\toutput.SetValue(col++, count, Value::BIGINT(NumericCast<int64_t>(entry.evicted_data)));\n+\t\toutput.SetValue(col++, count, Value::BIGINT(ClampReportedMemory(entry.evicted_data)));\n \t\tcount++;\n \t}\n \toutput.SetCardinality(count);\ndiff --git a/src/include/duckdb/common/adbc/wrappers.hpp b/src/include/duckdb/common/adbc/wrappers.hpp\nnew file mode 100644\nindex 000000000000..01d59dc901b5\n--- /dev/null\n+++ b/src/include/duckdb/common/adbc/wrappers.hpp\n@@ -0,0 +1,21 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/common/adbc/wrappers.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#pragma once\n+\n+#include \"duckdb.h\"\n+#include \"duckdb/common/string.hpp\"\n+#include \"duckdb/common/unordered_map.hpp\"\n+\n+namespace duckdb {\n+\n+struct DuckDBAdbcConnectionWrapper {\n+\tduckdb_connection connection;\n+\tunordered_map<string, string> options;\n+};\n+} // namespace duckdb\ndiff --git a/src/include/duckdb/common/arrow/appender/append_data.hpp b/src/include/duckdb/common/arrow/appender/append_data.hpp\nindex 1b5a5e02ab9e..c136100ae23b 100644\n--- a/src/include/duckdb/common/arrow/appender/append_data.hpp\n+++ b/src/include/duckdb/common/arrow/appender/append_data.hpp\n@@ -1,3 +1,11 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/common/arrow/appender/append_data.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n #pragma once\n \n #include \"duckdb/common/types.hpp\"\ndiff --git a/src/include/duckdb/common/arrow/appender/bool_data.hpp b/src/include/duckdb/common/arrow/appender/bool_data.hpp\nindex 59313faa3696..3b8a4f142cbd 100644\n--- a/src/include/duckdb/common/arrow/appender/bool_data.hpp\n+++ b/src/include/duckdb/common/arrow/appender/bool_data.hpp\n@@ -1,3 +1,11 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/common/arrow/appender/bool_data.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n #pragma once\n \n #include \"duckdb/common/arrow/appender/append_data.hpp\"\ndiff --git a/src/include/duckdb/common/arrow/appender/enum_data.hpp b/src/include/duckdb/common/arrow/appender/enum_data.hpp\nindex 90473d9b540f..a5d066abbd44 100644\n--- a/src/include/duckdb/common/arrow/appender/enum_data.hpp\n+++ b/src/include/duckdb/common/arrow/appender/enum_data.hpp\n@@ -1,7 +1,16 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/common/arrow/appender/enum_data.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n #pragma once\n \n #include \"duckdb/common/arrow/appender/append_data.hpp\"\n #include \"duckdb/common/arrow/appender/scalar_data.hpp\"\n+#include \"duckdb/common/arrow/arrow_appender.hpp\"\n \n namespace duckdb {\n \ndiff --git a/src/include/duckdb/common/arrow/appender/fixed_size_list_data.hpp b/src/include/duckdb/common/arrow/appender/fixed_size_list_data.hpp\nindex 4ad609441393..775fb2e17b05 100644\n--- a/src/include/duckdb/common/arrow/appender/fixed_size_list_data.hpp\n+++ b/src/include/duckdb/common/arrow/appender/fixed_size_list_data.hpp\n@@ -1,3 +1,11 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/common/arrow/appender/fixed_size_list_data.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===/\n+\n #pragma once\n \n #include \"duckdb/common/arrow/appender/append_data.hpp\"\ndiff --git a/src/include/duckdb/common/arrow/appender/list.hpp b/src/include/duckdb/common/arrow/appender/list.hpp\nindex 6ce97b5285f9..1fd664ff2150 100644\n--- a/src/include/duckdb/common/arrow/appender/list.hpp\n+++ b/src/include/duckdb/common/arrow/appender/list.hpp\n@@ -1,9 +1,18 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/common/arrow/appender/list.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n #include \"duckdb/common/arrow/appender/bool_data.hpp\"\n #include \"duckdb/common/arrow/appender/enum_data.hpp\"\n #include \"duckdb/common/arrow/appender/fixed_size_list_data.hpp\"\n #include \"duckdb/common/arrow/appender/list_data.hpp\"\n #include \"duckdb/common/arrow/appender/list_view_data.hpp\"\n #include \"duckdb/common/arrow/appender/map_data.hpp\"\n+#include \"duckdb/common/arrow/appender/null_data.hpp\"\n #include \"duckdb/common/arrow/appender/scalar_data.hpp\"\n #include \"duckdb/common/arrow/appender/struct_data.hpp\"\n #include \"duckdb/common/arrow/appender/union_data.hpp\"\ndiff --git a/src/include/duckdb/common/arrow/appender/list_data.hpp b/src/include/duckdb/common/arrow/appender/list_data.hpp\nindex 5f0f8621539f..21274da486ec 100644\n--- a/src/include/duckdb/common/arrow/appender/list_data.hpp\n+++ b/src/include/duckdb/common/arrow/appender/list_data.hpp\n@@ -1,3 +1,11 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/common/arrow/appender/list_data.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n #pragma once\n \n #include \"duckdb/common/arrow/appender/append_data.hpp\"\ndiff --git a/src/include/duckdb/common/arrow/appender/list_view_data.hpp b/src/include/duckdb/common/arrow/appender/list_view_data.hpp\nindex 158120c46341..f46b316dd9cb 100644\n--- a/src/include/duckdb/common/arrow/appender/list_view_data.hpp\n+++ b/src/include/duckdb/common/arrow/appender/list_view_data.hpp\n@@ -1,3 +1,11 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/common/arrow/appender/list_view_data.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n #pragma once\n \n #include \"duckdb/common/arrow/appender/append_data.hpp\"\ndiff --git a/src/include/duckdb/common/arrow/appender/map_data.hpp b/src/include/duckdb/common/arrow/appender/map_data.hpp\nindex afc67decdc59..7f82f401fc2f 100644\n--- a/src/include/duckdb/common/arrow/appender/map_data.hpp\n+++ b/src/include/duckdb/common/arrow/appender/map_data.hpp\n@@ -1,3 +1,11 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/common/arrow/appender/map_data.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n #pragma once\n \n #include \"duckdb/common/arrow/arrow_appender.hpp\"\ndiff --git a/src/include/duckdb/common/arrow/appender/null_data.hpp b/src/include/duckdb/common/arrow/appender/null_data.hpp\nnew file mode 100644\nindex 000000000000..d39b5d8f38dd\n--- /dev/null\n+++ b/src/include/duckdb/common/arrow/appender/null_data.hpp\n@@ -0,0 +1,23 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/common/arrow/appender/null_data.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#pragma once\n+\n+#include \"duckdb/common/arrow/appender/append_data.hpp\"\n+#include \"duckdb/common/types/vector.hpp\"\n+\n+namespace duckdb {\n+\n+struct ArrowNullData {\n+public:\n+\tstatic void Initialize(ArrowAppendData &result, const LogicalType &type, idx_t capacity);\n+\tstatic void Append(ArrowAppendData &append_data, Vector &input, idx_t from, idx_t to, idx_t input_size);\n+\tstatic void Finalize(ArrowAppendData &append_data, const LogicalType &type, ArrowArray *result);\n+};\n+\n+} // namespace duckdb\ndiff --git a/src/include/duckdb/common/arrow/appender/scalar_data.hpp b/src/include/duckdb/common/arrow/appender/scalar_data.hpp\nindex 00326a6a55c0..a6729b46070d 100644\n--- a/src/include/duckdb/common/arrow/appender/scalar_data.hpp\n+++ b/src/include/duckdb/common/arrow/appender/scalar_data.hpp\n@@ -1,3 +1,11 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/common/arrow/appender/scalar_data.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n #pragma once\n \n #include \"duckdb/common/arrow/appender/append_data.hpp\"\ndiff --git a/src/include/duckdb/common/arrow/appender/struct_data.hpp b/src/include/duckdb/common/arrow/appender/struct_data.hpp\nindex de2514fc1e18..299a05bab0dd 100644\n--- a/src/include/duckdb/common/arrow/appender/struct_data.hpp\n+++ b/src/include/duckdb/common/arrow/appender/struct_data.hpp\n@@ -1,3 +1,11 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/common/arrow/appender/struct_data.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n #pragma once\n \n #include \"duckdb/common/arrow/appender/append_data.hpp\"\ndiff --git a/src/include/duckdb/common/arrow/appender/union_data.hpp b/src/include/duckdb/common/arrow/appender/union_data.hpp\nindex 8b2850fca3a2..df8fc848f6b9 100644\n--- a/src/include/duckdb/common/arrow/appender/union_data.hpp\n+++ b/src/include/duckdb/common/arrow/appender/union_data.hpp\n@@ -1,3 +1,11 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/common/arrow/appender/union_data.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n #pragma once\n \n #include \"duckdb/common/arrow/appender/append_data.hpp\"\ndiff --git a/src/include/duckdb/common/arrow/appender/varchar_data.hpp b/src/include/duckdb/common/arrow/appender/varchar_data.hpp\nindex 6dc37652d5d6..45e9c14a985e 100644\n--- a/src/include/duckdb/common/arrow/appender/varchar_data.hpp\n+++ b/src/include/duckdb/common/arrow/appender/varchar_data.hpp\n@@ -1,3 +1,11 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/common/arrow/appender/varchar_data.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n #pragma once\n \n #include \"duckdb/common/arrow/appender/append_data.hpp\"\ndiff --git a/src/include/duckdb/common/numeric_utils.hpp b/src/include/duckdb/common/numeric_utils.hpp\nindex 813213dde179..f61b927ab2ef 100644\n--- a/src/include/duckdb/common/numeric_utils.hpp\n+++ b/src/include/duckdb/common/numeric_utils.hpp\n@@ -76,17 +76,17 @@ struct NumericCastImpl<TO, FROM, false> {\n \n \t\tif (!NumericLimits<FROM>::IsSigned() && !NumericLimits<TO>::IsSigned() &&\n \t\t    (unsigned_in < unsigned_min || unsigned_in > unsigned_max)) {\n-\t\t\tThrowNumericCastError(val, minval, maxval);\n+\t\t\tThrowNumericCastError(val, static_cast<TO>(unsigned_min), static_cast<TO>(unsigned_max));\n \t\t}\n \n \t\tif (NumericLimits<FROM>::IsSigned() && NumericLimits<TO>::IsSigned() &&\n \t\t    (signed_in < signed_min || signed_in > signed_max)) {\n-\t\t\tThrowNumericCastError(val, minval, maxval);\n+\t\t\tThrowNumericCastError(val, static_cast<TO>(signed_min), static_cast<TO>(signed_max));\n \t\t}\n \n \t\tif (NumericLimits<FROM>::IsSigned() != NumericLimits<TO>::IsSigned() &&\n \t\t    (signed_in < signed_min || unsigned_in > unsigned_max)) {\n-\t\t\tThrowNumericCastError(val, minval, maxval);\n+\t\t\tThrowNumericCastError(val, static_cast<TO>(signed_min), static_cast<TO>(unsigned_max));\n \t\t}\n \n \t\treturn static_cast<TO>(val);\ndiff --git a/src/optimizer/rule/distributivity.cpp b/src/optimizer/rule/distributivity.cpp\nindex b1b18617c024..149557eacb23 100644\n--- a/src/optimizer/rule/distributivity.cpp\n+++ b/src/optimizer/rule/distributivity.cpp\n@@ -42,9 +42,10 @@ unique_ptr<Expression> DistributivityRule::ExtractExpression(BoundConjunctionExp\n \t\tif (and_expr.children.size() == 1) {\n \t\t\tconj.children[idx] = std::move(and_expr.children[0]);\n \t\t}\n-\t} else {\n-\t\t// not an AND node! remove the entire expression\n-\t\t// this happens in the case of e.g. (X AND B) OR X\n+\t}\n+\t// not an AND node(e.g. (X AND B) OR X) or this is the last expr,\n+\t// remove the entire expression\n+\tif (!result) {\n \t\tD_ASSERT(child->Equals(expr));\n \t\tresult = std::move(child);\n \t\tconj.children[idx] = nullptr;\ndiff --git a/src/planner/binder/tableref/bind_basetableref.cpp b/src/planner/binder/tableref/bind_basetableref.cpp\nindex 4ba150bcf885..ce6f33a2bcaf 100644\n--- a/src/planner/binder/tableref/bind_basetableref.cpp\n+++ b/src/planner/binder/tableref/bind_basetableref.cpp\n@@ -105,6 +105,16 @@ vector<CatalogSearchEntry> Binder::GetSearchPath(Catalog &catalog, const string\n \treturn view_search_path;\n }\n \n+static vector<LogicalType> ExchangeAllNullTypes(const vector<LogicalType> &types) {\n+\tvector<LogicalType> result = types;\n+\tfor (auto &type : result) {\n+\t\tif (ExpressionBinder::ContainsNullType(type)) {\n+\t\t\ttype = ExpressionBinder::ExchangeNullType(type);\n+\t\t}\n+\t}\n+\treturn result;\n+}\n+\n unique_ptr<BoundTableRef> Binder::Bind(BaseTableRef &ref) {\n \tQueryErrorContext error_context(ref.query_location);\n \t// CTEs and views are also referred to using BaseTableRefs, hence need to distinguish here\n@@ -340,9 +350,14 @@ unique_ptr<BoundTableRef> Binder::Bind(BaseTableRef &ref) {\n \t\t// verify that the types and names match up with the expected types and names if the view has type info defined\n \t\tauto &bound_subquery = bound_child->Cast<BoundSubqueryRef>();\n \t\tif (GetBindingMode() != BindingMode::EXTRACT_NAMES && view_catalog_entry.HasTypes()) {\n-\t\t\tif (bound_subquery.subquery->types != view_catalog_entry.types) {\n-\t\t\t\tauto actual_types = StringUtil::ToString(bound_subquery.subquery->types, \", \");\n-\t\t\t\tauto expected_types = StringUtil::ToString(view_catalog_entry.types, \", \");\n+\t\t\t// we bind the view subquery and the original view with different \"can_contain_nulls\",\n+\t\t\t// but we don't want to throw an error when SQLNULL does not match up with INTEGER,\n+\t\t\t// so we exchange all SQLNULL with INTEGER here before comparing\n+\t\t\tauto bound_types = ExchangeAllNullTypes(bound_subquery.subquery->types);\n+\t\t\tauto view_types = ExchangeAllNullTypes(view_catalog_entry.types);\n+\t\t\tif (bound_types != view_types) {\n+\t\t\t\tauto actual_types = StringUtil::ToString(bound_types, \", \");\n+\t\t\t\tauto expected_types = StringUtil::ToString(view_types, \", \");\n \t\t\t\tthrow BinderException(\n \t\t\t\t    \"Contents of view were altered: types don't match! Expected [%s], but found [%s] instead\",\n \t\t\t\t    expected_types, actual_types);\ndiff --git a/tools/shell/shell.cpp b/tools/shell/shell.cpp\nindex 4ebb5fd854bc..9f6c1e0c05e2 100644\n--- a/tools/shell/shell.cpp\n+++ b/tools/shell/shell.cpp\n@@ -4687,7 +4687,7 @@ static const char zOptions[] =\n     \"   -markdown            set output mode to 'markdown'\\n\"\n     \"   -newline SEP         set output row separator. Default: '\\\\n'\\n\"\n     \"   -no-stdin            exit after processing options instead of reading stdin\\n\"\n-    \"   -nullvalue TEXT      set text string for NULL values. Default ''\\n\"\n+    \"   -nullvalue TEXT      set text string for NULL values. Default 'NULL'\\n\"\n     \"   -quote               set output mode to 'quote'\\n\"\n     \"   -readonly            open the database read-only\\n\"\n     \"   -s COMMAND           run \\\"COMMAND\\\" and exit\\n\"\n", "test_patch": "diff --git a/data/csv/test_commit_rollback.csv b/data/csv/test_commit_rollback.csv\nnew file mode 100644\nindex 000000000000..b3beb57a4113\n--- /dev/null\n+++ b/data/csv/test_commit_rollback.csv\n@@ -0,0 +1,2 @@\n+commit,rollback, abort\n+1,1,1\n\\ No newline at end of file\ndiff --git a/test/api/adbc/test_adbc.cpp b/test/api/adbc/test_adbc.cpp\nindex f2a534bac958..eb45ccd4d623 100644\n--- a/test/api/adbc/test_adbc.cpp\n+++ b/test/api/adbc/test_adbc.cpp\n@@ -1,8 +1,8 @@\n #include \"arrow/arrow_test_helper.hpp\"\n #include \"catch.hpp\"\n #include \"duckdb/common/adbc/adbc.hpp\"\n-\n-#include <duckdb/common/adbc/options.h>\n+#include \"duckdb/common/adbc/wrappers.hpp\"\n+#include \"duckdb/common/adbc/options.h\"\n #include <iostream>\n \n namespace duckdb {\n@@ -54,12 +54,15 @@ class ADBCTestDatabase {\n \n \tbool QueryAndCheck(const string &query) {\n \t\tQueryArrow(query);\n-\t\tauto cconn = static_cast<Connection *>(adbc_connection.private_data);\n+\t\tauto conn_wrapper = static_cast<DuckDBAdbcConnectionWrapper *>(adbc_connection.private_data);\n+\n+\t\tauto cconn = reinterpret_cast<Connection *>(conn_wrapper->connection);\n \t\treturn ArrowTestHelper::RunArrowComparison(*cconn, query, arrow_stream);\n \t}\n \n \tunique_ptr<MaterializedQueryResult> Query(const string &query) {\n-\t\tauto cconn = static_cast<Connection *>(adbc_connection.private_data);\n+\t\tauto conn_wrapper = static_cast<DuckDBAdbcConnectionWrapper *>(adbc_connection.private_data);\n+\t\tauto cconn = reinterpret_cast<Connection *>(conn_wrapper->connection);\n \t\treturn cconn->Query(query);\n \t}\n \n@@ -1113,6 +1116,40 @@ TEST_CASE(\"Test AdbcConnectionGetTableTypes\", \"[adbc]\") {\n \tREQUIRE((res->GetValue(0, 0).ToString() == \"BASE TABLE\"));\n }\n \n+TEST_CASE(\"Test Segfault Option Set\", \"[adbc]\") {\n+\tif (!duckdb_lib) {\n+\t\treturn;\n+\t}\n+\n+\tAdbcDatabase adbc_database;\n+\tAdbcConnection adbc_connection;\n+\n+\tAdbcError adbc_error;\n+\tInitializeADBCError(&adbc_error);\n+\n+\tREQUIRE(SUCCESS(AdbcDatabaseNew(&adbc_database, &adbc_error)));\n+\tREQUIRE(SUCCESS(AdbcDatabaseSetOption(&adbc_database, \"driver\", duckdb_lib, &adbc_error)));\n+\tREQUIRE(SUCCESS(AdbcDatabaseSetOption(&adbc_database, \"entrypoint\", \"duckdb_adbc_init\", &adbc_error)));\n+\tREQUIRE(SUCCESS(AdbcDatabaseSetOption(&adbc_database, \"path\", \":memory:\", &adbc_error)));\n+\n+\tREQUIRE(SUCCESS(AdbcDatabaseInit(&adbc_database, &adbc_error)));\n+\n+\tREQUIRE(SUCCESS(AdbcConnectionNew(&adbc_connection, &adbc_error)));\n+\n+\tREQUIRE(SUCCESS(AdbcConnectionSetOption(&adbc_connection, ADBC_CONNECTION_OPTION_AUTOCOMMIT,\n+\t                                        ADBC_OPTION_VALUE_DISABLED, &adbc_error)));\n+\n+\tREQUIRE(SUCCESS(AdbcConnectionInit(&adbc_connection, &adbc_database, &adbc_error)));\n+\n+\tauto conn_wrapper = static_cast<DuckDBAdbcConnectionWrapper *>(adbc_connection.private_data);\n+\tauto cconn = reinterpret_cast<Connection *>(conn_wrapper->connection);\n+\n+\tREQUIRE(!cconn->IsAutoCommit());\n+\n+\tREQUIRE(SUCCESS(AdbcConnectionRelease(&adbc_connection, &adbc_error)));\n+\tREQUIRE(SUCCESS(AdbcDatabaseRelease(&adbc_database, &adbc_error)));\n+}\n+\n TEST_CASE(\"Test AdbcConnectionGetObjects\", \"[adbc]\") {\n \tif (!duckdb_lib) {\n \t\treturn;\ndiff --git a/test/issues/general/test_16662.test b/test/issues/general/test_16662.test\nnew file mode 100644\nindex 000000000000..d18c37d8c16d\n--- /dev/null\n+++ b/test/issues/general/test_16662.test\n@@ -0,0 +1,63 @@\n+# name: test/issues/general/test_16662.test\n+# description: Issue 16662 - Unexpected binder error when using a CTE multiple times\n+# group: [general]\n+\n+statement ok\n+pragma enable_verification\n+\n+statement ok\n+CREATE VIEW\n+  \"tbl1\" AS\n+  -- End of EXAMPLE 4 (pt1)\n+WITH\n+  data_infra as (\n+    select\n+      'a' as AMES,\n+      'b' as TONG\n+      -- Example 6: Unomment out the following line to see it work\n+      -- If there is more than one resulting row in the group by then there is not error\n+      -- union all\n+      -- select\n+      --   'c' as AMES,\n+      --   'b' as TONG\n+      --End Example 6\n+      -- Example 5: Comment out the following line to see it work\n+      -- If there is no group by then there is an error\n+    group by\n+      1\n+      -- End of Example 5\n+  )\n+SELECT\n+  -- Example 1: Comment the following lines to see it work\n+  -- If the CTE is used only once then there is no error\n+  case\n+    when 'b' in (\n+      select\n+        TONG\n+      from\n+        data_infra\n+    ) then 'tong'\n+    else 'Various'\n+  end as collapsed_TONG,\n+  --- End of Example 1\n+  -- Example 2: Comment the following lines to see it work\n+  -- If the CTE is used only once then there is no error\n+  case\n+    when 'ba' in (\n+      select\n+        TONG\n+      from\n+        data_infra\n+    ) then 'ames'\n+    else null\n+  end as collapsed_AMES,\n+  --- End of Example 2\n+  -- Example 3: Delete this line to see it work\n+  -- If there is no null column there is no error\n+  NULL AS NULL_COL;\n+\n+statement ok\n+SELECT\n+  *\n+FROM\n+  \"tbl1\";\ndiff --git a/test/issues/general/test_16783.test b/test/issues/general/test_16783.test\nnew file mode 100644\nindex 000000000000..0ee2ce6e81da\n--- /dev/null\n+++ b/test/issues/general/test_16783.test\n@@ -0,0 +1,18 @@\n+# name: test/issues/general/test_16783.test\n+# description: Issue 16783 - Anti-join meets INTERNAL Error: Attempted to dereference unique_ptr that is NULL\n+# group: [general]\n+\n+statement ok\n+pragma enable_verification;\n+\n+statement ok\n+CREATE TABLE t0(c0 FLOAT);\n+\n+statement ok\n+CREATE TABLE t1(c0 FLOAT);\n+\n+statement ok\n+select * from t0\n+where not exists(\n+    select 1 from t1 where (((((t0.c0) AND ((t1.c0 BETWEEN t0.c0 AND t0.c0)))) OR (((t0.c0) AND ((t1.c0 BETWEEN t0.c0 AND t0.c0))))))\n+);\ndiff --git a/test/sql/copy/csv/afl/test_fuzz_4086.test b/test/sql/copy/csv/afl/test_fuzz_4086.test\nindex 08d2d36a80aa..23ed7869f1f0 100644\n--- a/test/sql/copy/csv/afl/test_fuzz_4086.test\n+++ b/test/sql/copy/csv/afl/test_fuzz_4086.test\n@@ -4,8 +4,7 @@\n \n require json\n \n-statement ok\n-PRAGMA enable_verification\n+loop i 0 2\n \n statement maybe\n FROM read_csv('data/csv/afl/4086/case_1.csv', auto_detect=false, columns={'json': 'JSON'}, delim=NULL, buffer_size=42, store_rejects=true, rejects_limit=658694493994253607);\n@@ -18,3 +17,8 @@ FROM read_csv('data/csv/afl/4086/case_2.csv', auto_detect=false, columns={'json'\n statement maybe\n FROM read_csv('data/csv/afl/4086/case_3.csv', auto_detect=false, columns={'json': 'JSON'}, delim='\\0', buffer_size=42, store_rejects=true, rejects_limit=658694493994253607);\n ----\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+endloop\n\\ No newline at end of file\ndiff --git a/test/sql/copy/csv/auto/test_normalize_names.test b/test/sql/copy/csv/auto/test_normalize_names.test\nindex a8ffbd5ef299..25e73786a720 100644\n--- a/test/sql/copy/csv/auto/test_normalize_names.test\n+++ b/test/sql/copy/csv/auto/test_normalize_names.test\n@@ -5,6 +5,10 @@\n statement ok\n PRAGMA enable_verification\n \n+query I\n+select columns from sniff_csv('data/csv/test_commit_rollback.csv',  normalize_names = true)\n+----\n+[{'name': _commit, 'type': BIGINT}, {'name': _rollback, 'type': BIGINT}, {'name': _abort, 'type': BIGINT}]\n \n # CSV file with uppercase header\n statement ok\n@@ -36,7 +40,7 @@ DROP TABLE test;\n query I\n select columns from sniff_csv('data/csv/auto/normalize_names_2.csv', normalize_names = true)\n ----\n-[{'name': _select, 'type': BIGINT}, {'name': insert, 'type': VARCHAR}, {'name': _join, 'type': VARCHAR}]\n+[{'name': _select, 'type': BIGINT}, {'name': _insert, 'type': VARCHAR}, {'name': _join, 'type': VARCHAR}]\n \n \n # CSV file with keywords in header\n@@ -44,7 +48,7 @@ statement ok\n CREATE TABLE test AS SELECT * FROM read_csv_auto ('data/csv/auto/normalize_names_2.csv', normalize_names=TRUE);\n \n query ITT\n-SELECT _select, insert, _join FROM test ORDER BY _select;\n+SELECT _select, _insert, _join FROM test ORDER BY _select;\n ----\n 123\tTEST1\ttext1\n 345\tTEST1\ttext2\n@@ -107,4 +111,4 @@ DROP TABLE test;\n query I\n select columns from sniff_csv('data/csv/normalize.csv', normalize_names = true)\n ----\n-[{'name': name, 'type': VARCHAR}, {'name': text, 'type': VARCHAR}]\n+[{'name': _name, 'type': VARCHAR}, {'name': _text, 'type': VARCHAR}]\ndiff --git a/test/sql/index/art/constraints/test_art_eager_batch_insert.test b/test/sql/index/art/constraints/test_art_eager_batch_insert.test\nnew file mode 100644\nindex 000000000000..1da9a7f5d7be\n--- /dev/null\n+++ b/test/sql/index/art/constraints/test_art_eager_batch_insert.test\n@@ -0,0 +1,51 @@\n+# name: test/sql/index/art/constraints/test_art_eager_batch_insert.test\n+# description: Test eager constraint checking during batch inserts.\n+# group: [constraints]\n+\n+statement ok\n+PRAGMA enable_verification;\n+\n+statement ok\n+CREATE TABLE test1 (id INT PRIMARY KEY, payload VARCHAR);\n+\n+statement ok\n+CREATE TABLE test2 (id INT PRIMARY KEY, payload VARCHAR);\n+\n+statement ok\n+INSERT INTO test1 VALUES (1, 'row 1');\n+\n+statement ok\n+INSERT INTO test2 VALUES (1, 'row 1 from test 2');\n+\n+query II\n+SELECT id, payload FROM test1;\n+----\n+1\trow 1\n+\n+statement ok\n+BEGIN;\n+\n+statement ok\n+DELETE FROM test1 WHERE id = 1;\n+\n+query II\n+SELECT id, payload FROM test1;\n+----\n+\n+statement ok\n+INSERT INTO test1 SELECT * FROM test2;\n+\n+query II\n+SELECT id, payload FROM test1;\n+----\n+1\trow 1 from test 2\n+\n+statement ok\n+COMMIT\n+\n+query II\n+SELECT id, payload FROM test1;\n+----\n+1\trow 1 from test 2\n+\n+\ndiff --git a/test/sql/storage_version/storage_version.db b/test/sql/storage_version/storage_version.db\nindex 6342d80a5d0b..eb3c37a6d8ba 100644\nBinary files a/test/sql/storage_version/storage_version.db and b/test/sql/storage_version/storage_version.db differ\n", "problem_statement": "Anti-join meets INTERNAL Error: Attempted to dereference unique_ptr that is NULL\n### What happens?\n\nThe following not exists query meet the internal error.\n```\nCREATE TABLE t0(c0 FLOAT);\nCREATE TABLE t1(c0 FLOAT);\nselect * from t0\nwhere not exists(\n    select 1 from t1 where (((((t0.c0) AND ((t1.c0 BETWEEN t0.c0 AND t0.c0)))) OR (((t0.c0) AND ((t1.c0 BETWEEN t0.c0 AND t0.c0))))))\n);\n```\n```\nINTERNAL Error:\nAttempted to dereference unique_ptr that is NULL!\n\nStack Trace:\n\n0        duckdb::Exception::Exception(duckdb::ExceptionType, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&) + 64\n1        duckdb::InternalException::InternalException(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&) + 20\n2        duckdb::DistributivityRule::Apply(duckdb::LogicalOperator&, duckdb::vector<std::__1::reference_wrapper<duckdb::Expression>, true>&, bool&, bool) + 1488\n3        duckdb::ExpressionRewriter::ApplyRules(duckdb::LogicalOperator&, duckdb::vector<std::__1::reference_wrapper<duckdb::Rule>, true> const&, duckdb::unique_ptr<duckdb::Expression, std::__1::default_delete<duckdb::Expression>, true>, bool&, bool) + 324\n4        duckdb::ExpressionRewriter::VisitExpression(duckdb::unique_ptr<duckdb::Expression, std::__1::default_delete<duckdb::Expression>, true>*) + 96\n5        duckdb::LogicalOperatorVisitor::EnumerateExpressions(duckdb::LogicalOperator&, std::__1::function<void (duckdb::unique_ptr<duckdb::Expression, std::__1::default_delete<duckdb::Expression>, true>*)> const&) + 852\n6        duckdb::LogicalOperatorVisitor::VisitOperatorExpressions(duckdb::LogicalOperator&) + 68\n7        duckdb::ExpressionRewriter::VisitOperator(duckdb::LogicalOperator&) + 440\n8        duckdb::LogicalOperatorVisitor::VisitOperatorChildren(duckdb::LogicalOperator&) + 108\n9        duckdb::ExpressionRewriter::VisitOperator(duckdb::LogicalOperator&) + 44\n10       duckdb::LogicalOperatorVisitor::VisitOperatorChildren(duckdb::LogicalOperator&) + 108\n11       duckdb::ExpressionRewriter::VisitOperator(duckdb::LogicalOperator&) + 44\n12       duckdb::LogicalOperatorVisitor::VisitOperatorChildren(duckdb::LogicalOperator&) + 108\n13       duckdb::ExpressionRewriter::VisitOperator(duckdb::LogicalOperator&) + 44\n14       duckdb::LogicalOperatorVisitor::VisitOperatorChildren(duckdb::LogicalOperator&) + 108\n15       duckdb::ExpressionRewriter::VisitOperator(duckdb::LogicalOperator&) + 44\n16       duckdb::Optimizer::RunOptimizer(duckdb::OptimizerType, std::__1::function<void ()> const&) + 152\n17       duckdb::Optimizer::RunBuiltInOptimizers() + 160\n18       duckdb::Optimizer::Optimize(duckdb::unique_ptr<duckdb::LogicalOperator, std::__1::default_delete<duckdb::LogicalOperator>, true>) + 244\n19       duckdb::ClientContext::CreatePreparedStatementInternal(duckdb::ClientContextLock&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, duckdb::optional_ptr<std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, duckdb::BoundParameterData, duckdb::CaseInsensitiveStringHashFunction, duckdb::CaseInsensitiveStringEquality, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const, duckdb::BoundParameterData>>>, true>) + 988\n20       duckdb::ClientContext::CreatePreparedStatement(duckdb::ClientContextLock&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, duckdb::optional_ptr<std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, duckdb::BoundParameterData, duckdb::CaseInsensitiveStringHashFunction, duckdb::CaseInsensitiveStringEquality, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const, duckdb::BoundParameterData>>>, true>, duckdb::PreparedStatementMode) + 916\n21       duckdb::ClientContext::PendingStatementInternal(duckdb::ClientContextLock&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, duckdb::PendingQueryParameters const&) + 128\n22       duckdb::ClientContext::PendingStatementOrPreparedStatement(duckdb::ClientContextLock&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, duckdb::shared_ptr<duckdb::PreparedStatementData, true>&, duckdb::PendingQueryParameters const&) + 332\n23       duckdb::ClientContext::PendingStatementOrPreparedStatementInternal(duckdb::ClientContextLock&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, duckdb::shared_ptr<duckdb::PreparedStatementData, true>&, duckdb::PendingQueryParameters const&) + 1556\n24       duckdb::ClientContext::PendingQueryInternal(duckdb::ClientContextLock&, duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, duckdb::PendingQueryParameters const&, bool) + 144\n25       duckdb::ClientContext::PendingQuery(duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, duckdb::BoundParameterData, duckdb::CaseInsensitiveStringHashFunction, duckdb::CaseInsensitiveStringEquality, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const, duckdb::BoundParameterData>>>&, bool) + 288\n26       duckdb::ClientContext::PendingQuery(duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, bool) + 64\n27       duckdb::Connection::PendingQuery(duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, bool) + 64\n28       duckdb_shell_sqlite3_prepare_v2 + 996\n29       duckdb_shell::ShellState::ExecuteSQL(char const*, char**) + 148\n30       duckdb_shell::ShellState::RunOneSqlLine(char*) + 248\n31       duckdb_shell::ShellState::ProcessInput() + 1148\n32       main + 3436\n33       start + 6000\n```\n\n### To Reproduce\n\n```\nCREATE TABLE t0(c0 FLOAT);\nCREATE TABLE t1(c0 FLOAT);\nselect * from t0\nwhere not exists(\n    select 1 from t1 where (((((t0.c0) AND ((t1.c0 BETWEEN t0.c0 AND t0.c0)))) OR (((t0.c0) AND ((t1.c0 BETWEEN t0.c0 AND t0.c0))))))\n);\n```\n\n### OS:\n\nMacOS\n\n### DuckDB Version:\n\nv1.3.0-dev1736 c87ae7a200\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nTheoristCoder\n\n### Affiliation:\n\n NUS\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nAnti-join meets INTERNAL Error: Attempted to dereference unique_ptr that is NULL\n### What happens?\n\nThe following not exists query meet the internal error.\n```\nCREATE TABLE t0(c0 FLOAT);\nCREATE TABLE t1(c0 FLOAT);\nselect * from t0\nwhere not exists(\n    select 1 from t1 where (((((t0.c0) AND ((t1.c0 BETWEEN t0.c0 AND t0.c0)))) OR (((t0.c0) AND ((t1.c0 BETWEEN t0.c0 AND t0.c0))))))\n);\n```\n```\nINTERNAL Error:\nAttempted to dereference unique_ptr that is NULL!\n\nStack Trace:\n\n0        duckdb::Exception::Exception(duckdb::ExceptionType, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&) + 64\n1        duckdb::InternalException::InternalException(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&) + 20\n2        duckdb::DistributivityRule::Apply(duckdb::LogicalOperator&, duckdb::vector<std::__1::reference_wrapper<duckdb::Expression>, true>&, bool&, bool) + 1488\n3        duckdb::ExpressionRewriter::ApplyRules(duckdb::LogicalOperator&, duckdb::vector<std::__1::reference_wrapper<duckdb::Rule>, true> const&, duckdb::unique_ptr<duckdb::Expression, std::__1::default_delete<duckdb::Expression>, true>, bool&, bool) + 324\n4        duckdb::ExpressionRewriter::VisitExpression(duckdb::unique_ptr<duckdb::Expression, std::__1::default_delete<duckdb::Expression>, true>*) + 96\n5        duckdb::LogicalOperatorVisitor::EnumerateExpressions(duckdb::LogicalOperator&, std::__1::function<void (duckdb::unique_ptr<duckdb::Expression, std::__1::default_delete<duckdb::Expression>, true>*)> const&) + 852\n6        duckdb::LogicalOperatorVisitor::VisitOperatorExpressions(duckdb::LogicalOperator&) + 68\n7        duckdb::ExpressionRewriter::VisitOperator(duckdb::LogicalOperator&) + 440\n8        duckdb::LogicalOperatorVisitor::VisitOperatorChildren(duckdb::LogicalOperator&) + 108\n9        duckdb::ExpressionRewriter::VisitOperator(duckdb::LogicalOperator&) + 44\n10       duckdb::LogicalOperatorVisitor::VisitOperatorChildren(duckdb::LogicalOperator&) + 108\n11       duckdb::ExpressionRewriter::VisitOperator(duckdb::LogicalOperator&) + 44\n12       duckdb::LogicalOperatorVisitor::VisitOperatorChildren(duckdb::LogicalOperator&) + 108\n13       duckdb::ExpressionRewriter::VisitOperator(duckdb::LogicalOperator&) + 44\n14       duckdb::LogicalOperatorVisitor::VisitOperatorChildren(duckdb::LogicalOperator&) + 108\n15       duckdb::ExpressionRewriter::VisitOperator(duckdb::LogicalOperator&) + 44\n16       duckdb::Optimizer::RunOptimizer(duckdb::OptimizerType, std::__1::function<void ()> const&) + 152\n17       duckdb::Optimizer::RunBuiltInOptimizers() + 160\n18       duckdb::Optimizer::Optimize(duckdb::unique_ptr<duckdb::LogicalOperator, std::__1::default_delete<duckdb::LogicalOperator>, true>) + 244\n19       duckdb::ClientContext::CreatePreparedStatementInternal(duckdb::ClientContextLock&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, duckdb::optional_ptr<std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, duckdb::BoundParameterData, duckdb::CaseInsensitiveStringHashFunction, duckdb::CaseInsensitiveStringEquality, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const, duckdb::BoundParameterData>>>, true>) + 988\n20       duckdb::ClientContext::CreatePreparedStatement(duckdb::ClientContextLock&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, duckdb::optional_ptr<std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, duckdb::BoundParameterData, duckdb::CaseInsensitiveStringHashFunction, duckdb::CaseInsensitiveStringEquality, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const, duckdb::BoundParameterData>>>, true>, duckdb::PreparedStatementMode) + 916\n21       duckdb::ClientContext::PendingStatementInternal(duckdb::ClientContextLock&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, duckdb::PendingQueryParameters const&) + 128\n22       duckdb::ClientContext::PendingStatementOrPreparedStatement(duckdb::ClientContextLock&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, duckdb::shared_ptr<duckdb::PreparedStatementData, true>&, duckdb::PendingQueryParameters const&) + 332\n23       duckdb::ClientContext::PendingStatementOrPreparedStatementInternal(duckdb::ClientContextLock&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, duckdb::shared_ptr<duckdb::PreparedStatementData, true>&, duckdb::PendingQueryParameters const&) + 1556\n24       duckdb::ClientContext::PendingQueryInternal(duckdb::ClientContextLock&, duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, duckdb::PendingQueryParameters const&, bool) + 144\n25       duckdb::ClientContext::PendingQuery(duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, duckdb::BoundParameterData, duckdb::CaseInsensitiveStringHashFunction, duckdb::CaseInsensitiveStringEquality, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const, duckdb::BoundParameterData>>>&, bool) + 288\n26       duckdb::ClientContext::PendingQuery(duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, bool) + 64\n27       duckdb::Connection::PendingQuery(duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, bool) + 64\n28       duckdb_shell_sqlite3_prepare_v2 + 996\n29       duckdb_shell::ShellState::ExecuteSQL(char const*, char**) + 148\n30       duckdb_shell::ShellState::RunOneSqlLine(char*) + 248\n31       duckdb_shell::ShellState::ProcessInput() + 1148\n32       main + 3436\n33       start + 6000\n```\n\n### To Reproduce\n\n```\nCREATE TABLE t0(c0 FLOAT);\nCREATE TABLE t1(c0 FLOAT);\nselect * from t0\nwhere not exists(\n    select 1 from t1 where (((((t0.c0) AND ((t1.c0 BETWEEN t0.c0 AND t0.c0)))) OR (((t0.c0) AND ((t1.c0 BETWEEN t0.c0 AND t0.c0))))))\n);\n```\n\n### OS:\n\nMacOS\n\n### DuckDB Version:\n\nv1.3.0-dev1736 c87ae7a200\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nTheoristCoder\n\n### Affiliation:\n\n NUS\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "\n", "created_at": "2025-03-25T19:50:11Z"}
{"repo": "duckdb/duckdb", "pull_number": 16804, "instance_id": "duckdb__duckdb-16804", "issue_numbers": ["16783", "16783"], "base_commit": "3c9d9ddc6056a565d4320024b6ca0221854cb6be", "patch": "diff --git a/src/optimizer/rule/distributivity.cpp b/src/optimizer/rule/distributivity.cpp\nindex b1b18617c024..149557eacb23 100644\n--- a/src/optimizer/rule/distributivity.cpp\n+++ b/src/optimizer/rule/distributivity.cpp\n@@ -42,9 +42,10 @@ unique_ptr<Expression> DistributivityRule::ExtractExpression(BoundConjunctionExp\n \t\tif (and_expr.children.size() == 1) {\n \t\t\tconj.children[idx] = std::move(and_expr.children[0]);\n \t\t}\n-\t} else {\n-\t\t// not an AND node! remove the entire expression\n-\t\t// this happens in the case of e.g. (X AND B) OR X\n+\t}\n+\t// not an AND node(e.g. (X AND B) OR X) or this is the last expr,\n+\t// remove the entire expression\n+\tif (!result) {\n \t\tD_ASSERT(child->Equals(expr));\n \t\tresult = std::move(child);\n \t\tconj.children[idx] = nullptr;\n", "test_patch": "diff --git a/test/issues/general/test_16783.test b/test/issues/general/test_16783.test\nnew file mode 100644\nindex 000000000000..0ee2ce6e81da\n--- /dev/null\n+++ b/test/issues/general/test_16783.test\n@@ -0,0 +1,18 @@\n+# name: test/issues/general/test_16783.test\n+# description: Issue 16783 - Anti-join meets INTERNAL Error: Attempted to dereference unique_ptr that is NULL\n+# group: [general]\n+\n+statement ok\n+pragma enable_verification;\n+\n+statement ok\n+CREATE TABLE t0(c0 FLOAT);\n+\n+statement ok\n+CREATE TABLE t1(c0 FLOAT);\n+\n+statement ok\n+select * from t0\n+where not exists(\n+    select 1 from t1 where (((((t0.c0) AND ((t1.c0 BETWEEN t0.c0 AND t0.c0)))) OR (((t0.c0) AND ((t1.c0 BETWEEN t0.c0 AND t0.c0))))))\n+);\n", "problem_statement": "Anti-join meets INTERNAL Error: Attempted to dereference unique_ptr that is NULL\n### What happens?\n\nThe following not exists query meet the internal error.\n```\nCREATE TABLE t0(c0 FLOAT);\nCREATE TABLE t1(c0 FLOAT);\nselect * from t0\nwhere not exists(\n    select 1 from t1 where (((((t0.c0) AND ((t1.c0 BETWEEN t0.c0 AND t0.c0)))) OR (((t0.c0) AND ((t1.c0 BETWEEN t0.c0 AND t0.c0))))))\n);\n```\n```\nINTERNAL Error:\nAttempted to dereference unique_ptr that is NULL!\n\nStack Trace:\n\n0        duckdb::Exception::Exception(duckdb::ExceptionType, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&) + 64\n1        duckdb::InternalException::InternalException(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&) + 20\n2        duckdb::DistributivityRule::Apply(duckdb::LogicalOperator&, duckdb::vector<std::__1::reference_wrapper<duckdb::Expression>, true>&, bool&, bool) + 1488\n3        duckdb::ExpressionRewriter::ApplyRules(duckdb::LogicalOperator&, duckdb::vector<std::__1::reference_wrapper<duckdb::Rule>, true> const&, duckdb::unique_ptr<duckdb::Expression, std::__1::default_delete<duckdb::Expression>, true>, bool&, bool) + 324\n4        duckdb::ExpressionRewriter::VisitExpression(duckdb::unique_ptr<duckdb::Expression, std::__1::default_delete<duckdb::Expression>, true>*) + 96\n5        duckdb::LogicalOperatorVisitor::EnumerateExpressions(duckdb::LogicalOperator&, std::__1::function<void (duckdb::unique_ptr<duckdb::Expression, std::__1::default_delete<duckdb::Expression>, true>*)> const&) + 852\n6        duckdb::LogicalOperatorVisitor::VisitOperatorExpressions(duckdb::LogicalOperator&) + 68\n7        duckdb::ExpressionRewriter::VisitOperator(duckdb::LogicalOperator&) + 440\n8        duckdb::LogicalOperatorVisitor::VisitOperatorChildren(duckdb::LogicalOperator&) + 108\n9        duckdb::ExpressionRewriter::VisitOperator(duckdb::LogicalOperator&) + 44\n10       duckdb::LogicalOperatorVisitor::VisitOperatorChildren(duckdb::LogicalOperator&) + 108\n11       duckdb::ExpressionRewriter::VisitOperator(duckdb::LogicalOperator&) + 44\n12       duckdb::LogicalOperatorVisitor::VisitOperatorChildren(duckdb::LogicalOperator&) + 108\n13       duckdb::ExpressionRewriter::VisitOperator(duckdb::LogicalOperator&) + 44\n14       duckdb::LogicalOperatorVisitor::VisitOperatorChildren(duckdb::LogicalOperator&) + 108\n15       duckdb::ExpressionRewriter::VisitOperator(duckdb::LogicalOperator&) + 44\n16       duckdb::Optimizer::RunOptimizer(duckdb::OptimizerType, std::__1::function<void ()> const&) + 152\n17       duckdb::Optimizer::RunBuiltInOptimizers() + 160\n18       duckdb::Optimizer::Optimize(duckdb::unique_ptr<duckdb::LogicalOperator, std::__1::default_delete<duckdb::LogicalOperator>, true>) + 244\n19       duckdb::ClientContext::CreatePreparedStatementInternal(duckdb::ClientContextLock&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, duckdb::optional_ptr<std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, duckdb::BoundParameterData, duckdb::CaseInsensitiveStringHashFunction, duckdb::CaseInsensitiveStringEquality, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const, duckdb::BoundParameterData>>>, true>) + 988\n20       duckdb::ClientContext::CreatePreparedStatement(duckdb::ClientContextLock&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, duckdb::optional_ptr<std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, duckdb::BoundParameterData, duckdb::CaseInsensitiveStringHashFunction, duckdb::CaseInsensitiveStringEquality, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const, duckdb::BoundParameterData>>>, true>, duckdb::PreparedStatementMode) + 916\n21       duckdb::ClientContext::PendingStatementInternal(duckdb::ClientContextLock&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, duckdb::PendingQueryParameters const&) + 128\n22       duckdb::ClientContext::PendingStatementOrPreparedStatement(duckdb::ClientContextLock&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, duckdb::shared_ptr<duckdb::PreparedStatementData, true>&, duckdb::PendingQueryParameters const&) + 332\n23       duckdb::ClientContext::PendingStatementOrPreparedStatementInternal(duckdb::ClientContextLock&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, duckdb::shared_ptr<duckdb::PreparedStatementData, true>&, duckdb::PendingQueryParameters const&) + 1556\n24       duckdb::ClientContext::PendingQueryInternal(duckdb::ClientContextLock&, duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, duckdb::PendingQueryParameters const&, bool) + 144\n25       duckdb::ClientContext::PendingQuery(duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, duckdb::BoundParameterData, duckdb::CaseInsensitiveStringHashFunction, duckdb::CaseInsensitiveStringEquality, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const, duckdb::BoundParameterData>>>&, bool) + 288\n26       duckdb::ClientContext::PendingQuery(duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, bool) + 64\n27       duckdb::Connection::PendingQuery(duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, bool) + 64\n28       duckdb_shell_sqlite3_prepare_v2 + 996\n29       duckdb_shell::ShellState::ExecuteSQL(char const*, char**) + 148\n30       duckdb_shell::ShellState::RunOneSqlLine(char*) + 248\n31       duckdb_shell::ShellState::ProcessInput() + 1148\n32       main + 3436\n33       start + 6000\n```\n\n### To Reproduce\n\n```\nCREATE TABLE t0(c0 FLOAT);\nCREATE TABLE t1(c0 FLOAT);\nselect * from t0\nwhere not exists(\n    select 1 from t1 where (((((t0.c0) AND ((t1.c0 BETWEEN t0.c0 AND t0.c0)))) OR (((t0.c0) AND ((t1.c0 BETWEEN t0.c0 AND t0.c0))))))\n);\n```\n\n### OS:\n\nMacOS\n\n### DuckDB Version:\n\nv1.3.0-dev1736 c87ae7a200\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nTheoristCoder\n\n### Affiliation:\n\n NUS\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nAnti-join meets INTERNAL Error: Attempted to dereference unique_ptr that is NULL\n### What happens?\n\nThe following not exists query meet the internal error.\n```\nCREATE TABLE t0(c0 FLOAT);\nCREATE TABLE t1(c0 FLOAT);\nselect * from t0\nwhere not exists(\n    select 1 from t1 where (((((t0.c0) AND ((t1.c0 BETWEEN t0.c0 AND t0.c0)))) OR (((t0.c0) AND ((t1.c0 BETWEEN t0.c0 AND t0.c0))))))\n);\n```\n```\nINTERNAL Error:\nAttempted to dereference unique_ptr that is NULL!\n\nStack Trace:\n\n0        duckdb::Exception::Exception(duckdb::ExceptionType, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&) + 64\n1        duckdb::InternalException::InternalException(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&) + 20\n2        duckdb::DistributivityRule::Apply(duckdb::LogicalOperator&, duckdb::vector<std::__1::reference_wrapper<duckdb::Expression>, true>&, bool&, bool) + 1488\n3        duckdb::ExpressionRewriter::ApplyRules(duckdb::LogicalOperator&, duckdb::vector<std::__1::reference_wrapper<duckdb::Rule>, true> const&, duckdb::unique_ptr<duckdb::Expression, std::__1::default_delete<duckdb::Expression>, true>, bool&, bool) + 324\n4        duckdb::ExpressionRewriter::VisitExpression(duckdb::unique_ptr<duckdb::Expression, std::__1::default_delete<duckdb::Expression>, true>*) + 96\n5        duckdb::LogicalOperatorVisitor::EnumerateExpressions(duckdb::LogicalOperator&, std::__1::function<void (duckdb::unique_ptr<duckdb::Expression, std::__1::default_delete<duckdb::Expression>, true>*)> const&) + 852\n6        duckdb::LogicalOperatorVisitor::VisitOperatorExpressions(duckdb::LogicalOperator&) + 68\n7        duckdb::ExpressionRewriter::VisitOperator(duckdb::LogicalOperator&) + 440\n8        duckdb::LogicalOperatorVisitor::VisitOperatorChildren(duckdb::LogicalOperator&) + 108\n9        duckdb::ExpressionRewriter::VisitOperator(duckdb::LogicalOperator&) + 44\n10       duckdb::LogicalOperatorVisitor::VisitOperatorChildren(duckdb::LogicalOperator&) + 108\n11       duckdb::ExpressionRewriter::VisitOperator(duckdb::LogicalOperator&) + 44\n12       duckdb::LogicalOperatorVisitor::VisitOperatorChildren(duckdb::LogicalOperator&) + 108\n13       duckdb::ExpressionRewriter::VisitOperator(duckdb::LogicalOperator&) + 44\n14       duckdb::LogicalOperatorVisitor::VisitOperatorChildren(duckdb::LogicalOperator&) + 108\n15       duckdb::ExpressionRewriter::VisitOperator(duckdb::LogicalOperator&) + 44\n16       duckdb::Optimizer::RunOptimizer(duckdb::OptimizerType, std::__1::function<void ()> const&) + 152\n17       duckdb::Optimizer::RunBuiltInOptimizers() + 160\n18       duckdb::Optimizer::Optimize(duckdb::unique_ptr<duckdb::LogicalOperator, std::__1::default_delete<duckdb::LogicalOperator>, true>) + 244\n19       duckdb::ClientContext::CreatePreparedStatementInternal(duckdb::ClientContextLock&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, duckdb::optional_ptr<std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, duckdb::BoundParameterData, duckdb::CaseInsensitiveStringHashFunction, duckdb::CaseInsensitiveStringEquality, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const, duckdb::BoundParameterData>>>, true>) + 988\n20       duckdb::ClientContext::CreatePreparedStatement(duckdb::ClientContextLock&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, duckdb::optional_ptr<std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, duckdb::BoundParameterData, duckdb::CaseInsensitiveStringHashFunction, duckdb::CaseInsensitiveStringEquality, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const, duckdb::BoundParameterData>>>, true>, duckdb::PreparedStatementMode) + 916\n21       duckdb::ClientContext::PendingStatementInternal(duckdb::ClientContextLock&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, duckdb::PendingQueryParameters const&) + 128\n22       duckdb::ClientContext::PendingStatementOrPreparedStatement(duckdb::ClientContextLock&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, duckdb::shared_ptr<duckdb::PreparedStatementData, true>&, duckdb::PendingQueryParameters const&) + 332\n23       duckdb::ClientContext::PendingStatementOrPreparedStatementInternal(duckdb::ClientContextLock&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, duckdb::shared_ptr<duckdb::PreparedStatementData, true>&, duckdb::PendingQueryParameters const&) + 1556\n24       duckdb::ClientContext::PendingQueryInternal(duckdb::ClientContextLock&, duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, duckdb::PendingQueryParameters const&, bool) + 144\n25       duckdb::ClientContext::PendingQuery(duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, duckdb::BoundParameterData, duckdb::CaseInsensitiveStringHashFunction, duckdb::CaseInsensitiveStringEquality, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const, duckdb::BoundParameterData>>>&, bool) + 288\n26       duckdb::ClientContext::PendingQuery(duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, bool) + 64\n27       duckdb::Connection::PendingQuery(duckdb::unique_ptr<duckdb::SQLStatement, std::__1::default_delete<duckdb::SQLStatement>, true>, bool) + 64\n28       duckdb_shell_sqlite3_prepare_v2 + 996\n29       duckdb_shell::ShellState::ExecuteSQL(char const*, char**) + 148\n30       duckdb_shell::ShellState::RunOneSqlLine(char*) + 248\n31       duckdb_shell::ShellState::ProcessInput() + 1148\n32       main + 3436\n33       start + 6000\n```\n\n### To Reproduce\n\n```\nCREATE TABLE t0(c0 FLOAT);\nCREATE TABLE t1(c0 FLOAT);\nselect * from t0\nwhere not exists(\n    select 1 from t1 where (((((t0.c0) AND ((t1.c0 BETWEEN t0.c0 AND t0.c0)))) OR (((t0.c0) AND ((t1.c0 BETWEEN t0.c0 AND t0.c0))))))\n);\n```\n\n### OS:\n\nMacOS\n\n### DuckDB Version:\n\nv1.3.0-dev1736 c87ae7a200\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nTheoristCoder\n\n### Affiliation:\n\n NUS\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "\n", "created_at": "2025-03-24T13:00:04Z"}
{"repo": "duckdb/duckdb", "pull_number": 16751, "instance_id": "duckdb__duckdb-16751", "issue_numbers": ["16554", "16554", "16719"], "base_commit": "0b3d9e754a505641b56d11016198cdeacb032c77", "patch": "diff --git a/.github/workflows/BundleStaticLibs.yml b/.github/workflows/BundleStaticLibs.yml\nindex e9e4e6690d3b..3fbe60961d93 100644\n--- a/.github/workflows/BundleStaticLibs.yml\n+++ b/.github/workflows/BundleStaticLibs.yml\n@@ -80,7 +80,8 @@ jobs:\n \n       - name: Bundle static library\n         shell: bash\n-        run: make bundle-library-o\n+        run: |\n+          make gather-libs\n \n       - name: Print platform\n         shell: bash\n@@ -93,14 +94,14 @@ jobs:\n           AWS_SECRET_ACCESS_KEY: ${{ secrets.S3_DUCKDB_STAGING_KEY }}\n         run: |\n           python3 scripts/amalgamation.py\n-          zip -j static-lib-osx-${{ matrix.architecture }}.zip src/include/duckdb.h build/release/libduckdb_bundle.a\n-          ./scripts/upload-assets-to-staging.sh github_release static-lib-osx-${{ matrix.architecture }}.zip\n+          zip -r -j static-libs-osx-${{ matrix.architecture }}.zip src/include/duckdb.h build/release/libs/\n+          ./scripts/upload-assets-to-staging.sh github_release static-libs-osx-${{ matrix.architecture }}.zip\n \n       - uses: actions/upload-artifact@v4\n         with:\n-          name: duckdb-static-lib-osx-${{ matrix.architecture }}\n+          name: duckdb-static-libs-osx-${{ matrix.architecture }}\n           path: |\n-            static-lib-osx-${{ matrix.architecture }}.zip\n+            static-libs-osx-${{ matrix.architecture }}.zip\n \n   bundle-mingw-static-lib:\n     name: Windows MingW static libs\n@@ -142,7 +143,7 @@ jobs:\n       - name: Bundle static library\n         shell: bash\n         run: |\n-          make bundle-library-obj\n+          make gather-libs\n \n       - name: Deploy\n         shell: bash\n@@ -150,14 +151,14 @@ jobs:\n           AWS_ACCESS_KEY_ID: ${{ secrets.S3_DUCKDB_STAGING_ID }}\n           AWS_SECRET_ACCESS_KEY: ${{ secrets.S3_DUCKDB_STAGING_KEY }}\n         run: |\n-          zip -j static-lib-windows-mingw.zip src/include/duckdb.h build/release/libduckdb_bundle.a\n-          ./scripts/upload-assets-to-staging.sh github_release static-lib-windows-mingw.zip\n+          zip -r -j static-libs-windows-mingw.zip src/include/duckdb.h build/release/libs/\n+          ./scripts/upload-assets-to-staging.sh github_release static-libs-windows-mingw.zip\n \n       - uses: actions/upload-artifact@v4\n         with:\n-          name: duckdb-static-lib-windows-mingw\n+          name: duckdb-static-libs-windows-mingw\n           path: |\n-            static-lib-windows-mingw.zip\n+            static-libs-windows-mingw.zip\n   bundle-linux-arm64-static-libs:\n     name: Linux arm64 static libs\n     runs-on: ubuntu-latest\n@@ -183,7 +184,7 @@ jobs:\n           -e FORCE_WARN_UNUSED=1                                                 \\\n           -e DUCKDB_PLATFORM=linux_arm64                                         \\\n           ubuntu:18.04                                                           \\\n-          bash -c \"/duckdb/scripts/setup_ubuntu1804.sh && git config --global --add safe.directory /duckdb && make bundle-library -C /duckdb\"\n+          bash -c \"/duckdb/scripts/setup_ubuntu1804.sh && git config --global --add safe.directory /duckdb && make gather-libs -C /duckdb\"\n       - name: Deploy\n         shell: bash\n         env:\n@@ -191,13 +192,13 @@ jobs:\n           AWS_SECRET_ACCESS_KEY: ${{ secrets.S3_DUCKDB_STAGING_KEY }}\n         run: |\n           python3 scripts/amalgamation.py\n-          zip -j static-lib-linux-arm64.zip src/include/duckdb.h build/release/libduckdb_bundle.a\n-          ./scripts/upload-assets-to-staging.sh github_release static-lib-linux-arm64.zip\n+          zip -r -j static-libs-linux-arm64.zip src/include/duckdb.h build/release/libs/\n+          ./scripts/upload-assets-to-staging.sh github_release static-libs-linux-arm64.zip\n       - uses: actions/upload-artifact@v4\n         with:\n-          name: duckdb-static-lib-linux-arm64\n+          name: duckdb-static-libs-linux-arm64\n           path: |\n-            static-lib-linux-arm64.zip\n+            static-libs-linux-arm64.zip\n   bundle-linux-amd64-static-libs:\n     name: Linux amd64 static libs\n     runs-on: ubuntu-latest\n@@ -225,7 +226,7 @@ jobs:\n           -e BUILD_BENCHMARK=1                                                   \\\n           -e FORCE_WARN_UNUSED=1                                                 \\\n           quay.io/pypa/manylinux2014_x86_64                                      \\\n-          bash -c \"yum install -y perl-IPC-Cmd && git config --global --add safe.directory $PWD && make bundle-library -C $PWD\"\n+          bash -c \"yum install -y perl-IPC-Cmd && git config --global --add safe.directory $PWD && make gather-libs -C $PWD\"\n       - name: Print platform\n         shell: bash\n         run: ./build/release/duckdb -c \"PRAGMA platform;\"\n@@ -237,10 +238,10 @@ jobs:\n           AWS_SECRET_ACCESS_KEY: ${{ secrets.S3_DUCKDB_STAGING_KEY }}\n         run: |\n           python3 scripts/amalgamation.py\n-          zip -j static-lib-linux-amd64.zip src/include/duckdb.h build/release/libduckdb_bundle.a\n-          ./scripts/upload-assets-to-staging.sh github_release static-lib-linux-amd64.zip\n+          zip -r -j static-libs-linux-amd64.zip src/include/duckdb.h build/release/libs/\n+          ./scripts/upload-assets-to-staging.sh github_release static-libs-linux-amd64.zip\n       - uses: actions/upload-artifact@v4\n         with:\n-          name: duckdb-static-lib-linux-amd64\n+          name: duckdb-static-libs-linux-amd64\n           path: |\n-            static-lib-linux-amd64.zip\n\\ No newline at end of file\n+            static-libs-linux-amd64.zip\n\\ No newline at end of file\ndiff --git a/Makefile b/Makefile\nindex 38ee1c99dab5..b17c7e6ff66b 100644\n--- a/Makefile\n+++ b/Makefile\n@@ -524,3 +524,11 @@ bundle-library-obj: bundle-setup\n \n bundle-library: release\n \tmake bundle-library-o\n+\n+gather-libs: release\n+\tcd build/release && \\\n+\trm -rf libs && \\\n+\tmkdir -p libs && \\\n+\tcp src/libduckdb_static.a libs/. && \\\n+\tcp third_party/*/libduckdb_*.a libs/. && \\\n+\tcp extension/*/lib*_extension.a libs/.\n\\ No newline at end of file\ndiff --git a/data/csv/afl/4086/case_1.csv b/data/csv/afl/4086/case_1.csv\nnew file mode 100644\nindex 000000000000..0b404fbd4d54\n--- /dev/null\n+++ b/data/csv/afl/4086/case_1.csv\n@@ -0,0 +1,2 @@\n+\ufffd\r\n+\ufffd\n\\ No newline at end of file\ndiff --git a/data/csv/afl/4086/case_2.csv b/data/csv/afl/4086/case_2.csv\nnew file mode 100644\nindex 000000000000..c9bf78e836f7\n--- /dev/null\n+++ b/data/csv/afl/4086/case_2.csv\n@@ -0,0 +1,149 @@\n+\r\n+>\r\n+?\r\n+@\r\n+A\r\n+B\r\n+C\r\n+D\r\n+E\r\n+F\r\n+G\r\n+H\r\n+I\r\n+J\r\n+K\r\n+L\r\n+M\r\n+N\r\n+O\r\n+P\r\n+Q\r\n+R\r\n+S\r\n+T\r\n+U\r\n+V\r\n+W\r\n+X\r\n+Y\r\n+Z\r\n+[\r\n+\\\r\n+]\r\n+^\r\n+_\r\n+`\r\n+a\r\n+b\r\n+c\r\n+j\r\n+k\r\n+l\r\n+\r\n+\ufffd\r\n+\ufffd\r\n+\n+F\r\n+G\r\n+H\r\n+I\r\n+J\r\n+K\r\n+L\r\n+M\r\n+N\r\n+O\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffdw\r\n+x\r\n+y\r\n+z\r\n+{\r\n+|\r\n+}\r\n+~\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd}}}}}}}}}}}}}}}}}}}}}}\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+2\r\n+3\r\n+4\r\n+5\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\r\n+\ufffd\n\\ No newline at end of file\ndiff --git a/data/csv/afl/4086/case_3.csv b/data/csv/afl/4086/case_3.csv\nnew file mode 100644\nindex 000000000000..501156bee996\nBinary files /dev/null and b/data/csv/afl/4086/case_3.csv differ\ndiff --git a/extension/core_functions/include/core_functions/aggregate/quantile_sort_tree.hpp b/extension/core_functions/include/core_functions/aggregate/quantile_sort_tree.hpp\nindex a330c0a4bbef..b6a088786b7e 100644\n--- a/extension/core_functions/include/core_functions/aggregate/quantile_sort_tree.hpp\n+++ b/extension/core_functions/include/core_functions/aggregate/quantile_sort_tree.hpp\n@@ -8,17 +8,13 @@\n \n #pragma once\n \n-#include \"duckdb/common/sort/sort.hpp\"\n #include \"duckdb/common/types/column/column_data_collection.hpp\"\n-#include \"duckdb/common/types/row/row_layout.hpp\"\n #include \"core_functions/aggregate/quantile_helpers.hpp\"\n-#include \"duckdb/execution/merge_sort_tree.hpp\"\n #include \"duckdb/common/operator/cast_operators.hpp\"\n #include \"duckdb/common/operator/multiply.hpp\"\n #include \"duckdb/planner/expression/bound_constant_expression.hpp\"\n #include \"duckdb/function/window/window_index_tree.hpp\"\n #include <algorithm>\n-#include <numeric>\n #include <stdlib.h>\n #include <utility>\n \n@@ -89,7 +85,7 @@ struct QuantileDirect {\n \tusing RESULT_TYPE = T;\n \n \tinline const INPUT_TYPE &operator()(const INPUT_TYPE &x) const {\n-\t\treturn x;\n+\t\treturn x; // NOLINT\n \t}\n };\n \n@@ -365,7 +361,7 @@ struct QuantileSortTree {\n \t}\n \n \tinline idx_t SelectNth(const SubFrames &frames, size_t n) const {\n-\t\treturn index_tree->SelectNth(frames, n);\n+\t\treturn index_tree->SelectNth(frames, n).first;\n \t}\n \n \ttemplate <typename INPUT_TYPE, typename RESULT_TYPE, bool DISCRETE>\ndiff --git a/extension/core_functions/include/core_functions/aggregate/quantile_state.hpp b/extension/core_functions/include/core_functions/aggregate/quantile_state.hpp\nindex 00f4baf77735..cdf242ae9c9c 100644\n--- a/extension/core_functions/include/core_functions/aggregate/quantile_state.hpp\n+++ b/extension/core_functions/include/core_functions/aggregate/quantile_state.hpp\n@@ -207,6 +207,9 @@ struct WindowQuantileState {\n \t\t\t\tdest[0] = skips[0].second;\n \t\t\t\tif (skips.size() > 1) {\n \t\t\t\t\tdest[1] = skips[1].second;\n+\t\t\t\t} else {\n+\t\t\t\t\t// Avoid UMA\n+\t\t\t\t\tdest[1] = skips[0].second;\n \t\t\t\t}\n \t\t\t\treturn interp.template Extract<INPUT_TYPE, RESULT_TYPE>(dest.data(), result);\n \t\t\t} catch (const duckdb_skiplistlib::skip_list::IndexError &idx_err) {\ndiff --git a/scripts/generate_extensions_function.py b/scripts/generate_extensions_function.py\nindex da2181121abe..d6e861bfc6e9 100644\n--- a/scripts/generate_extensions_function.py\n+++ b/scripts/generate_extensions_function.py\n@@ -742,6 +742,7 @@ def write_header(data: ExtensionData):\n }; // EXTENSION_SECRET_PROVIDERS\n \n static constexpr const char *AUTOLOADABLE_EXTENSIONS[] = {\n+    \"avro\",\n     \"aws\",\n     \"azure\",\n     \"autocomplete\",\ndiff --git a/src/common/types/row/tuple_data_segment.cpp b/src/common/types/row/tuple_data_segment.cpp\nindex d14c0e0bad4c..c3383f3cb26f 100644\n--- a/src/common/types/row/tuple_data_segment.cpp\n+++ b/src/common/types/row/tuple_data_segment.cpp\n@@ -15,23 +15,23 @@ void TupleDataChunkPart::SetHeapEmpty() {\n \tbase_heap_ptr = nullptr;\n }\n \n-void SwapTupleDataChunkPart(TupleDataChunkPart &a, TupleDataChunkPart &b) {\n-\tstd::swap(a.row_block_index, b.row_block_index);\n-\tstd::swap(a.row_block_offset, b.row_block_offset);\n-\tstd::swap(a.heap_block_index, b.heap_block_index);\n-\tstd::swap(a.heap_block_offset, b.heap_block_offset);\n-\tstd::swap(a.base_heap_ptr, b.base_heap_ptr);\n-\tstd::swap(a.total_heap_size, b.total_heap_size);\n-\tstd::swap(a.count, b.count);\n+void MoveTupleDataChunkPart(TupleDataChunkPart &a, TupleDataChunkPart &b) {\n+\ta.row_block_index = b.row_block_index;\n+\ta.row_block_offset = b.row_block_offset;\n+\ta.heap_block_index = b.heap_block_index;\n+\ta.heap_block_offset = b.heap_block_offset;\n+\ta.base_heap_ptr = b.base_heap_ptr;\n+\ta.total_heap_size = b.total_heap_size;\n+\ta.count = b.count;\n \tstd::swap(a.lock, b.lock);\n }\n \n TupleDataChunkPart::TupleDataChunkPart(TupleDataChunkPart &&other) noexcept : lock((other.lock)) {\n-\tSwapTupleDataChunkPart(*this, other);\n+\tMoveTupleDataChunkPart(*this, other);\n }\n \n TupleDataChunkPart &TupleDataChunkPart::operator=(TupleDataChunkPart &&other) noexcept {\n-\tSwapTupleDataChunkPart(*this, other);\n+\tMoveTupleDataChunkPart(*this, other);\n \treturn *this;\n }\n \ndiff --git a/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp b/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\nindex 476e4f4bb468..386c5552cf76 100644\n--- a/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\n+++ b/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\n@@ -63,9 +63,9 @@ StringValueResult::StringValueResult(CSVStates &states, CSVStateMachine &state_m\n \t\t\t    \"Mismatch between the number of columns (%d) in the CSV file and what is expected in the scanner (%d).\",\n \t\t\t    number_of_columns, csv_file_scan->file_types.size());\n \t\t}\n-\t\tbool icu_loaded = csv_file_scan->buffer_manager->context.db->ExtensionIsLoaded(\"icu\");\n+\t\ticu_loaded = csv_file_scan->buffer_manager->context.db->ExtensionIsLoaded(\"icu\");\n \t\tfor (idx_t i = 0; i < csv_file_scan->file_types.size(); i++) {\n-\t\t\tauto &type = csv_file_scan->file_types[i];\n+\t\t\tauto type = csv_file_scan->file_types[i];\n \t\t\tif (type.IsJSONType()) {\n \t\t\t\ttype = LogicalType::VARCHAR;\n \t\t\t}\n@@ -436,6 +436,8 @@ void StringValueResult::AddValueToVector(const char *value_ptr, const idx_t size\n \t\t\t}\n \t\t\t// If we got here, we are ignoring errors, hence we must ignore this line.\n \t\t\tcurrent_errors.Insert(INVALID_UNICODE, cur_col_id, chunk_col_id, last_position);\n+\t\t\tstatic_cast<string_t *>(vector_ptr[chunk_col_id])[number_of_rows] = StringVector::AddStringOrBlob(\n+\t\t\t    parse_chunk.data[chunk_col_id], string_t(value_ptr, UnsafeNumericCast<uint32_t>(0)));\n \t\t\tbreak;\n \t\t}\n \t\tif (allocate) {\n@@ -606,7 +608,7 @@ void StringValueResult::AddValue(StringValueResult &result, const idx_t buffer_p\n \n void StringValueResult::HandleUnicodeError(idx_t col_idx, LinePosition &error_position) {\n \n-\tbool first_nl;\n+\tbool first_nl = false;\n \tauto borked_line = current_line_position.ReconstructCurrentLine(first_nl, buffer_handles, PrintErrorLine());\n \tLinesPerBoundary lines_per_batch(iterator.GetBoundaryIdx(), lines_read);\n \tif (current_line_position.begin == error_position) {\n@@ -673,6 +675,9 @@ bool LineError::HandleErrors(StringValueResult &result) {\n \t\t\t\t    result.current_line_position.begin.GetGlobalPosition(result.requested_size, first_nl),\n \t\t\t\t    line_pos.GetGlobalPosition(result.requested_size), result.path);\n \t\t\t}\n+\t\t\tif (!StringValueScanner::CanDirectlyCast(result.csv_file_scan->file_types[col_idx], result.icu_loaded)) {\n+\t\t\t\tresult.number_of_rows--;\n+\t\t\t}\n \t\t\tbreak;\n \t\t}\n \t\tcase UNTERMINATED_QUOTES:\n@@ -690,7 +695,7 @@ bool LineError::HandleErrors(StringValueResult &result) {\n \t\t\tbreak;\n \t\tcase CAST_ERROR: {\n \t\t\tstring column_name;\n-\t\t\tLogicalTypeId type_id;\n+\t\t\tLogicalTypeId type_id = LogicalTypeId::INVALID;\n \t\t\tif (cur_error.col_idx < result.names.size()) {\n \t\t\t\tcolumn_name = result.names[cur_error.col_idx];\n \t\t\t}\n@@ -768,7 +773,7 @@ void StringValueResult::NullPaddingQuotedNewlineCheck() const {\n string FullLinePosition::ReconstructCurrentLine(bool &first_char_nl,\n                                                 unordered_map<idx_t, shared_ptr<CSVBufferHandle>> &buffer_handles,\n                                                 bool reconstruct_line) const {\n-\tif (!reconstruct_line) {\n+\tif (!reconstruct_line || begin == end) {\n \t\treturn {};\n \t}\n \tstring result;\n@@ -822,6 +827,8 @@ bool StringValueResult::AddRowInternal() {\n \t}\n \n \tif (current_errors.HandleErrors(*this)) {\n+\t\tD_ASSERT(buffer_handles.find(current_line_position.begin.buffer_idx) != buffer_handles.end());\n+\t\tD_ASSERT(buffer_handles.find(current_line_position.end.buffer_idx) != buffer_handles.end());\n \t\tline_positions_per_row[static_cast<idx_t>(number_of_rows)] = current_line_position;\n \t\tnumber_of_rows++;\n \t\tif (static_cast<idx_t>(number_of_rows) >= result_size) {\n@@ -881,6 +888,8 @@ bool StringValueResult::AddRowInternal() {\n \t\t\tRemoveLastLine();\n \t\t}\n \t}\n+\tD_ASSERT(buffer_handles.find(current_line_position.begin.buffer_idx) != buffer_handles.end());\n+\tD_ASSERT(buffer_handles.find(current_line_position.end.buffer_idx) != buffer_handles.end());\n \tline_positions_per_row[static_cast<idx_t>(number_of_rows)] = current_line_position;\n \tcur_col_id = 0;\n \tchunk_col_id = 0;\n@@ -1024,6 +1033,7 @@ void StringValueScanner::Flush(DataChunk &insert_chunk) {\n \t\tauto &process_result = ParseChunk();\n \t\t// First Get Parsed Chunk\n \t\tauto &parse_chunk = process_result.ToChunk();\n+\t\tinsert_chunk.Reset();\n \t\t// We have to check if we got to error\n \t\terror_handler->ErrorIfNeeded();\n \t\tif (parse_chunk.size() == 0) {\n@@ -1086,7 +1096,7 @@ void StringValueScanner::Flush(DataChunk &insert_chunk) {\n \t\t\t\t\tif (!state_machine->options.IgnoreErrors()) {\n \t\t\t\t\t\tLinesPerBoundary lines_per_batch(iterator.GetBoundaryIdx(),\n \t\t\t\t\t\t                                 lines_read - parse_chunk.size() + line_error);\n-\t\t\t\t\t\tbool first_nl;\n+\t\t\t\t\t\tbool first_nl = false;\n \t\t\t\t\t\tauto borked_line = result.line_positions_per_row[line_error].ReconstructCurrentLine(\n \t\t\t\t\t\t    first_nl, result.buffer_handles, result.PrintErrorLine());\n \t\t\t\t\t\tstd::ostringstream error;\n@@ -1094,11 +1104,15 @@ void StringValueScanner::Flush(DataChunk &insert_chunk) {\n \t\t\t\t\t\t      << type.ToString() << \"\\'\";\n \t\t\t\t\t\tstring error_msg = error.str();\n \t\t\t\t\t\tSanitizeError(error_msg);\n+\t\t\t\t\t\tidx_t row_byte_pos = 0;\n+\t\t\t\t\t\tif (!(result.line_positions_per_row[line_error].begin ==\n+\t\t\t\t\t\t      result.line_positions_per_row[line_error].end)) {\n+\t\t\t\t\t\t\trow_byte_pos = result.line_positions_per_row[line_error].begin.GetGlobalPosition(\n+\t\t\t\t\t\t\t    result.result_size, first_nl);\n+\t\t\t\t\t\t}\n \t\t\t\t\t\tauto csv_error = CSVError::CastError(\n \t\t\t\t\t\t    state_machine->options, names[col_idx], error_msg, col_idx, borked_line, lines_per_batch,\n-\t\t\t\t\t\t    result.line_positions_per_row[line_error].begin.GetGlobalPosition(result.result_size,\n-\t\t\t\t\t\t                                                                      first_nl),\n-\t\t\t\t\t\t    optional_idx::Invalid(), result_vector.GetType().id(), result.path);\n+\t\t\t\t\t\t    row_byte_pos, optional_idx::Invalid(), result_vector.GetType().id(), result.path);\n \t\t\t\t\t\terror_handler->Error(csv_error);\n \t\t\t\t\t}\n \t\t\t\t}\n@@ -1116,7 +1130,7 @@ void StringValueScanner::Flush(DataChunk &insert_chunk) {\n \t\t\t\t\t\tif (!state_machine->options.IgnoreErrors()) {\n \t\t\t\t\t\t\tLinesPerBoundary lines_per_batch(iterator.GetBoundaryIdx(),\n \t\t\t\t\t\t\t                                 lines_read - parse_chunk.size() + line_error);\n-\t\t\t\t\t\t\tbool first_nl;\n+\t\t\t\t\t\t\tbool first_nl = false;\n \t\t\t\t\t\t\tauto borked_line = result.line_positions_per_row[line_error].ReconstructCurrentLine(\n \t\t\t\t\t\t\t    first_nl, result.buffer_handles, result.PrintErrorLine());\n \t\t\t\t\t\t\tstd::ostringstream error;\n@@ -1148,6 +1162,7 @@ void StringValueScanner::Flush(DataChunk &insert_chunk) {\n \t\t\t}\n \t\t\t// Now we slice the result\n \t\t\tinsert_chunk.Slice(successful_rows, sel_idx);\n+\t\t\tresult.borked_rows.clear();\n \t\t}\n \t\tif (insert_chunk.size() == 0 && cur_buffer_handle) {\n \t\t\tidx_t to_pos;\n@@ -1697,13 +1712,14 @@ bool StringValueScanner::CanDirectlyCast(const LogicalType &type, bool icu_loade\n \tcase LogicalTypeId::TIMESTAMP:\n \tcase LogicalTypeId::TIME:\n \tcase LogicalTypeId::DECIMAL:\n-\tcase LogicalType::VARCHAR:\n \tcase LogicalType::BOOLEAN:\n \t\treturn true;\n \tcase LogicalType::TIMESTAMP_TZ:\n \t\t// We only try to do direct cast of timestamp tz if the ICU extension is not loaded, otherwise, it needs to go\n \t\t// through string -> timestamp_tz casting\n \t\treturn !icu_loaded;\n+\tcase LogicalType::VARCHAR:\n+\t\treturn !type.IsJSONType();\n \tdefault:\n \t\treturn false;\n \t}\n@@ -1884,7 +1900,6 @@ void StringValueScanner::FinalizeChunkProcess() {\n \t\tif (result.current_errors.HandleErrors(result)) {\n \t\t\tresult.number_of_rows++;\n \t\t}\n-\n \t\tif (states.IsQuotedCurrent() && !found_error &&\n \t\t    state_machine->dialect_options.state_machine_options.strict_mode.GetValue()) {\n \t\t\t// If we finish the execution of a buffer, and we end in a quoted state, it means we have unterminated\ndiff --git a/src/execution/operator/csv_scanner/state_machine/csv_state_machine_cache.cpp b/src/execution/operator/csv_scanner/state_machine/csv_state_machine_cache.cpp\nindex 431b5ab6feca..332937d5bc55 100644\n--- a/src/execution/operator/csv_scanner/state_machine/csv_state_machine_cache.cpp\n+++ b/src/execution/operator/csv_scanner/state_machine/csv_state_machine_cache.cpp\n@@ -58,14 +58,19 @@ void CSVStateMachineCache::Insert(const CSVStateMachineOptions &state_machine_op\n \t}\n \n \tconst auto delimiter_value = state_machine_options.delimiter.GetValue();\n-\tconst auto delimiter_first_byte = static_cast<uint8_t>(delimiter_value[0]);\n+\tuint8_t delimiter_first_byte;\n+\tif (!delimiter_value.empty()) {\n+\t\tdelimiter_first_byte = static_cast<uint8_t>(delimiter_value[0]);\n+\t} else {\n+\t\tdelimiter_first_byte = static_cast<uint8_t>('\\0');\n+\t}\n \tconst auto quote = static_cast<uint8_t>(state_machine_options.quote.GetValue());\n \tconst auto escape = static_cast<uint8_t>(state_machine_options.escape.GetValue());\n \tconst auto comment = static_cast<uint8_t>(state_machine_options.comment.GetValue());\n \n \tconst auto new_line_id = state_machine_options.new_line.GetValue();\n \n-\tconst bool multi_byte_delimiter = delimiter_value.size() != 1;\n+\tconst bool multi_byte_delimiter = delimiter_value.size() > 1;\n \n \tconst bool enable_unquoted_escape = state_machine_options.strict_mode.GetValue() == false &&\n \t                                    state_machine_options.quote != state_machine_options.escape &&\n@@ -149,7 +154,7 @@ void CSVStateMachineCache::Insert(const CSVStateMachineOptions &state_machine_op\n \t\ttransition_array[static_cast<uint8_t>(delimiter_value[1])]\n \t\t                [static_cast<uint8_t>(CSVState::DELIMITER_FIRST_BYTE)] = CSVState::DELIMITER;\n \t} else if (delimiter_value.size() == 3) {\n-\t\tif (delimiter_value[0] == delimiter_value[1]) {\n+\t\tif (delimiter_first_byte == delimiter_value[1]) {\n \t\t\ttransition_array[static_cast<uint8_t>(delimiter_value[1])]\n \t\t\t                [static_cast<uint8_t>(CSVState::DELIMITER_SECOND_BYTE)] = CSVState::DELIMITER_SECOND_BYTE;\n \t\t}\n@@ -158,11 +163,11 @@ void CSVStateMachineCache::Insert(const CSVStateMachineOptions &state_machine_op\n \t\ttransition_array[static_cast<uint8_t>(delimiter_value[2])]\n \t\t                [static_cast<uint8_t>(CSVState::DELIMITER_SECOND_BYTE)] = CSVState::DELIMITER;\n \t} else if (delimiter_value.size() == 4) {\n-\t\tif (delimiter_value[0] == delimiter_value[2]) {\n+\t\tif (delimiter_first_byte == delimiter_value[2]) {\n \t\t\ttransition_array[static_cast<uint8_t>(delimiter_value[1])]\n \t\t\t                [static_cast<uint8_t>(CSVState::DELIMITER_THIRD_BYTE)] = CSVState::DELIMITER_SECOND_BYTE;\n \t\t}\n-\t\tif (delimiter_value[0] == delimiter_value[1] && delimiter_value[1] == delimiter_value[2]) {\n+\t\tif (delimiter_first_byte == delimiter_value[1] && delimiter_value[1] == delimiter_value[2]) {\n \t\t\ttransition_array[static_cast<uint8_t>(delimiter_value[1])]\n \t\t\t                [static_cast<uint8_t>(CSVState::DELIMITER_THIRD_BYTE)] = CSVState::DELIMITER_THIRD_BYTE;\n \t\t}\ndiff --git a/src/execution/operator/csv_scanner/util/csv_error.cpp b/src/execution/operator/csv_scanner/util/csv_error.cpp\nindex f0d9a8cf735b..fbc1f8cd5e99 100644\n--- a/src/execution/operator/csv_scanner/util/csv_error.cpp\n+++ b/src/execution/operator/csv_scanner/util/csv_error.cpp\n@@ -20,19 +20,32 @@ CSVErrorHandler::CSVErrorHandler(bool ignore_errors_p) : ignore_errors(ignore_er\n }\n \n void CSVErrorHandler::ThrowError(const CSVError &csv_error) {\n+\tauto error_to_throw = csv_error;\n+\tidx_t error_to_throw_row = GetLineInternal(error_to_throw.error_info);\n+\tif (PrintLineNumber(error_to_throw) && !errors.empty()) {\n+\t\t// We stored a previous error here, we pick the one that happens the earliest to throw\n+\t\tfor (const auto &error : errors) {\n+\t\t\tif (CanGetLine(error.GetBoundaryIndex())) {\n+\t\t\t\tidx_t cur_error_to_throw = GetLineInternal(error.error_info);\n+\t\t\t\tif (cur_error_to_throw < error_to_throw_row) {\n+\t\t\t\t\terror_to_throw = error;\n+\t\t\t\t\terror_to_throw_row = cur_error_to_throw;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n \tstd::ostringstream error;\n-\tif (PrintLineNumber(csv_error)) {\n-\t\terror << \"CSV Error on Line: \" << GetLineInternal(csv_error.error_info) << '\\n';\n-\t\tif (!csv_error.csv_row.empty()) {\n-\t\t\terror << \"Original Line: \" << csv_error.csv_row << '\\n';\n+\tif (PrintLineNumber(error_to_throw)) {\n+\t\terror << \"CSV Error on Line: \" << error_to_throw_row << '\\n';\n+\t\tif (!error_to_throw.csv_row.empty()) {\n+\t\t\terror << \"Original Line: \" << error_to_throw.csv_row << '\\n';\n \t\t}\n \t}\n-\tif (csv_error.full_error_message.empty()) {\n-\t\terror << csv_error.error_message;\n+\tif (error_to_throw.full_error_message.empty()) {\n+\t\terror << error_to_throw.error_message;\n \t} else {\n-\t\terror << csv_error.full_error_message;\n+\t\terror << error_to_throw.full_error_message;\n \t}\n-\n \tswitch (csv_error.type) {\n \tcase CAST_ERROR:\n \t\tthrow ConversionException(error.str());\ndiff --git a/src/execution/operator/csv_scanner/util/csv_reader_options.cpp b/src/execution/operator/csv_scanner/util/csv_reader_options.cpp\nindex 8fe70d0ac1db..70fec93ab1ec 100644\n--- a/src/execution/operator/csv_scanner/util/csv_reader_options.cpp\n+++ b/src/execution/operator/csv_scanner/util/csv_reader_options.cpp\n@@ -125,9 +125,6 @@ void CSVReaderOptions::SetDelimiter(const string &input) {\n \tif (delim_str.size() > 4) {\n \t\tthrow InvalidInputException(\"The delimiter option cannot exceed a size of 4 bytes.\");\n \t}\n-\tif (input.empty()) {\n-\t\tdelim_str = string(\"\\0\", 1);\n-\t}\n \tthis->dialect_options.state_machine_options.delimiter.Set(delim_str);\n }\n \ndiff --git a/src/execution/operator/persistent/physical_export.cpp b/src/execution/operator/persistent/physical_export.cpp\nindex 66afb4c97498..45e449aab64d 100644\n--- a/src/execution/operator/persistent/physical_export.cpp\n+++ b/src/execution/operator/persistent/physical_export.cpp\n@@ -41,7 +41,7 @@ static void WriteCatalogEntries(stringstream &ss, catalog_entry_vector_t &entrie\n \t\t} catch (const NotImplementedException &) {\n \t\t\tss << entry.get().ToSQL();\n \t\t}\n-\t\tss << '\\n';\n+\t\tss << \";\\n\";\n \t}\n \tss << '\\n';\n }\ndiff --git a/src/execution/physical_plan/plan_insert.cpp b/src/execution/physical_plan/plan_insert.cpp\nindex c960fe1130aa..d4cbc48801b9 100644\n--- a/src/execution/physical_plan/plan_insert.cpp\n+++ b/src/execution/physical_plan/plan_insert.cpp\n@@ -10,7 +10,7 @@\n \n namespace duckdb {\n \n-static OrderPreservationType OrderPreservationRecursive(PhysicalOperator &op) {\n+OrderPreservationType PhysicalPlanGenerator::OrderPreservationRecursive(PhysicalOperator &op) {\n \tif (op.IsSource()) {\n \t\treturn op.SourceOrder();\n \t}\ndiff --git a/src/function/aggregate/sorted_aggregate_function.cpp b/src/function/aggregate/sorted_aggregate_function.cpp\nindex 88941c040b7d..5e3747cb462f 100644\n--- a/src/function/aggregate/sorted_aggregate_function.cpp\n+++ b/src/function/aggregate/sorted_aggregate_function.cpp\n@@ -9,7 +9,6 @@\n #include \"duckdb/planner/expression/bound_aggregate_expression.hpp\"\n #include \"duckdb/planner/expression/bound_constant_expression.hpp\"\n #include \"duckdb/parser/expression_map.hpp\"\n-#include \"duckdb/function/aggregate/distributive_functions.hpp\"\n \n namespace duckdb {\n \n@@ -770,6 +769,17 @@ void FunctionBinder::BindSortedAggregate(ClientContext &context, BoundAggregateE\n }\n \n void FunctionBinder::BindSortedAggregate(ClientContext &context, BoundWindowExpression &expr) {\n+\t//\tMake implicit orderings explicit\n+\tauto &aggregate = *expr.aggregate;\n+\tif (aggregate.order_dependent == AggregateOrderDependent::ORDER_DEPENDENT && expr.arg_orders.empty()) {\n+\t\tfor (auto &order : expr.orders) {\n+\t\t\tconst auto type = order.type;\n+\t\t\tconst auto null_order = order.null_order;\n+\t\t\tauto expression = order.expression->Copy();\n+\t\t\texpr.arg_orders.emplace_back(BoundOrderByNode(type, null_order, std::move(expression)));\n+\t\t}\n+\t}\n+\n \tif (expr.arg_orders.empty() || expr.children.empty()) {\n \t\t// not a sorted aggregate: return\n \t\treturn;\n@@ -781,7 +791,6 @@ void FunctionBinder::BindSortedAggregate(ClientContext &context, BoundWindowExpr\n \t\t\treturn;\n \t\t}\n \t}\n-\tauto &aggregate = *expr.aggregate;\n \tauto &children = expr.children;\n \tauto &arg_orders = expr.arg_orders;\n \tauto sorted_bind = make_uniq<SortedAggregateBindData>(context, expr);\ndiff --git a/src/function/window/window_index_tree.cpp b/src/function/window/window_index_tree.cpp\nindex 5791b2af747f..48fb5b1bef0a 100644\n--- a/src/function/window/window_index_tree.cpp\n+++ b/src/function/window/window_index_tree.cpp\n@@ -1,6 +1,5 @@\n #include \"duckdb/function/window/window_index_tree.hpp\"\n \n-#include <thread>\n #include <utility>\n \n namespace duckdb {\n@@ -52,11 +51,21 @@ void WindowIndexTreeLocalState::BuildLeaves() {\n \t}\n }\n \n-idx_t WindowIndexTree::SelectNth(const SubFrames &frames, idx_t n) const {\n+pair<idx_t, idx_t> WindowIndexTree::SelectNth(const SubFrames &frames, idx_t n) const {\n \tif (mst32) {\n-\t\treturn mst32->NthElement(mst32->SelectNth(frames, n));\n+\t\tconst auto nth = mst32->SelectNth(frames, n);\n+\t\tif (nth.second) {\n+\t\t\treturn nth;\n+\t\t} else {\n+\t\t\treturn {mst32->NthElement(nth.first), 0};\n+\t\t}\n \t} else {\n-\t\treturn mst64->NthElement(mst64->SelectNth(frames, n));\n+\t\tconst auto nth = mst64->SelectNth(frames, n);\n+\t\tif (nth.second) {\n+\t\t\treturn nth;\n+\t\t} else {\n+\t\t\treturn {mst64->NthElement(nth.first), 0};\n+\t\t}\n \t}\n }\n \ndiff --git a/src/function/window/window_value_function.cpp b/src/function/window/window_value_function.cpp\nindex 6b8a7038ebb3..fbd1551a2e50 100644\n--- a/src/function/window/window_value_function.cpp\n+++ b/src/function/window/window_value_function.cpp\n@@ -311,7 +311,12 @@ void WindowLeadLagExecutor::EvaluateInternal(WindowExecutorGlobalState &gstate,\n \t\t\t\tconst auto n = NumericCast<idx_t>(val_idx);\n \t\t\t\tconst auto nth_index = glstate.value_tree->SelectNth(frames, n);\n \t\t\t\t// (4) evaluate the expression provided to LEAD/LAG on this row.\n-\t\t\t\tcursor.CopyCell(0, nth_index, result, i);\n+\t\t\t\tif (nth_index.second) {\n+\t\t\t\t\t//\tOverflow\n+\t\t\t\t\tFlatVector::SetNull(result, i, true);\n+\t\t\t\t} else {\n+\t\t\t\t\tcursor.CopyCell(0, nth_index.first, result, i);\n+\t\t\t\t}\n \t\t\t} else if (wexpr.default_expr) {\n \t\t\t\tleadlag_default.CopyCell(result, i);\n \t\t\t} else {\n@@ -425,7 +430,8 @@ void WindowFirstValueExecutor::EvaluateInternal(WindowExecutorGlobalState &gstat\n \n \t\t\tif (frame_width) {\n \t\t\t\tconst auto first_idx = gvstate.value_tree->SelectNth(frames, 0);\n-\t\t\t\tcursor.CopyCell(0, first_idx, result, i);\n+\t\t\t\tD_ASSERT(first_idx.second == 0);\n+\t\t\t\tcursor.CopyCell(0, first_idx.first, result, i);\n \t\t\t} else {\n \t\t\t\tFlatVector::SetNull(result, i, true);\n \t\t\t}\n@@ -474,8 +480,19 @@ void WindowLastValueExecutor::EvaluateInternal(WindowExecutorGlobalState &gstate\n \t\t\t}\n \n \t\t\tif (frame_width) {\n-\t\t\t\tconst auto last_idx = gvstate.value_tree->SelectNth(frames, frame_width - 1);\n-\t\t\t\tcursor.CopyCell(0, last_idx, result, i);\n+\t\t\t\tauto n = frame_width - 1;\n+\t\t\t\tauto last_idx = gvstate.value_tree->SelectNth(frames, n);\n+\t\t\t\tif (last_idx.second && last_idx.second <= n) {\n+\t\t\t\t\t//\tFrame larger than data. Since we want last, we back off by the overflow\n+\t\t\t\t\tn -= last_idx.second;\n+\t\t\t\t\tlast_idx = gvstate.value_tree->SelectNth(frames, n);\n+\t\t\t\t}\n+\t\t\t\tif (last_idx.second) {\n+\t\t\t\t\t//\tNo last value - give up.\n+\t\t\t\t\tFlatVector::SetNull(result, i, true);\n+\t\t\t\t} else {\n+\t\t\t\t\tcursor.CopyCell(0, last_idx.first, result, i);\n+\t\t\t\t}\n \t\t\t} else {\n \t\t\t\tFlatVector::SetNull(result, i, true);\n \t\t\t}\n@@ -541,7 +558,12 @@ void WindowNthValueExecutor::EvaluateInternal(WindowExecutorGlobalState &gstate,\n \n \t\t\tif (n < frame_width) {\n \t\t\t\tconst auto nth_index = gvstate.value_tree->SelectNth(frames, n - 1);\n-\t\t\t\tcursor.CopyCell(0, nth_index, result, i);\n+\t\t\t\tif (nth_index.second) {\n+\t\t\t\t\t// Past end of frame\n+\t\t\t\t\tFlatVector::SetNull(result, i, true);\n+\t\t\t\t} else {\n+\t\t\t\t\tcursor.CopyCell(0, nth_index.first, result, i);\n+\t\t\t\t}\n \t\t\t} else {\n \t\t\t\tFlatVector::SetNull(result, i, true);\n \t\t\t}\ndiff --git a/src/include/duckdb/execution/merge_sort_tree.hpp b/src/include/duckdb/execution/merge_sort_tree.hpp\nindex 672aaa56cd4a..8c04ecde03cf 100644\n--- a/src/include/duckdb/execution/merge_sort_tree.hpp\n+++ b/src/include/duckdb/execution/merge_sort_tree.hpp\n@@ -118,7 +118,8 @@ struct MergeSortTree {\n \n \tvoid Build();\n \n-\tidx_t SelectNth(const SubFrames &frames, idx_t n) const;\n+\t//\t{nth index, remainder}\n+\tpair<idx_t, idx_t> SelectNth(const SubFrames &frames, idx_t n) const;\n \n \tinline ElementType NthElement(idx_t i) const {\n \t\treturn tree.front().first[i];\n@@ -436,10 +437,10 @@ void MergeSortTree<E, O, CMP, F, C>::BuildRun(idx_t level_idx, idx_t run_idx) {\n }\n \n template <typename E, typename O, typename CMP, uint64_t F, uint64_t C>\n-idx_t MergeSortTree<E, O, CMP, F, C>::SelectNth(const SubFrames &frames, idx_t n) const {\n+pair<idx_t, idx_t> MergeSortTree<E, O, CMP, F, C>::SelectNth(const SubFrames &frames, idx_t n) const {\n \t// Handle special case of a one-element tree\n \tif (tree.size() < 2) {\n-\t\treturn 0;\n+\t\treturn {0, 0};\n \t}\n \n \t// \tThe first level contains a single run,\n@@ -566,7 +567,7 @@ idx_t MergeSortTree<E, O, CMP, F, C>::SelectNth(const SubFrames &frames, idx_t n\n \t\t}\n \t}\n \n-\treturn result;\n+\treturn {result, n};\n }\n \n template <typename E, typename O, typename CMP, uint64_t F, uint64_t C>\ndiff --git a/src/include/duckdb/execution/operator/csv_scanner/string_value_scanner.hpp b/src/include/duckdb/execution/operator/csv_scanner/string_value_scanner.hpp\nindex a18a0eb5f0bd..dc73e17fc32c 100644\n--- a/src/include/duckdb/execution/operator/csv_scanner/string_value_scanner.hpp\n+++ b/src/include/duckdb/execution/operator/csv_scanner/string_value_scanner.hpp\n@@ -195,6 +195,8 @@ class StringValueResult : public ScannerResult {\n \tbool projecting_columns = false;\n \tidx_t chunk_col_id = 0;\n \n+\tbool icu_loaded = false;\n+\n \t//! We must ensure that we keep the buffers alive until processing the query result\n \tunordered_map<idx_t, shared_ptr<CSVBufferHandle>> buffer_handles;\n \ndiff --git a/src/include/duckdb/execution/physical_plan_generator.hpp b/src/include/duckdb/execution/physical_plan_generator.hpp\nindex ebd172492bc5..ee635c16adcd 100644\n--- a/src/include/duckdb/execution/physical_plan_generator.hpp\n+++ b/src/include/duckdb/execution/physical_plan_generator.hpp\n@@ -74,6 +74,8 @@ class PhysicalPlanGenerator {\n \tstatic bool UseBatchIndex(ClientContext &context, PhysicalOperator &plan);\n \t//! Whether or not we should preserve insertion order for executing the given sink\n \tstatic bool PreserveInsertionOrder(ClientContext &context, PhysicalOperator &plan);\n+\t//! The order preservation type of the given operator decided by recursively looking at its children\n+\tstatic OrderPreservationType OrderPreservationRecursive(PhysicalOperator &op);\n \n \ttemplate <class T, class... ARGS>\n \tPhysicalOperator &Make(ARGS &&... args) {\ndiff --git a/src/include/duckdb/function/window/window_index_tree.hpp b/src/include/duckdb/function/window/window_index_tree.hpp\nindex e9f9f4014188..e95b522747d6 100644\n--- a/src/include/duckdb/function/window/window_index_tree.hpp\n+++ b/src/include/duckdb/function/window/window_index_tree.hpp\n@@ -36,7 +36,8 @@ class WindowIndexTree : public WindowMergeSortTree {\n \tunique_ptr<WindowAggregatorState> GetLocalState() override;\n \n \t//! Find the Nth index in the set of subframes\n-\tidx_t SelectNth(const SubFrames &frames, idx_t n) const;\n+\t//! Returns {nth index, 0} or {nth offset, overflow}\n+\tpair<idx_t, idx_t> SelectNth(const SubFrames &frames, idx_t n) const;\n };\n \n } // namespace duckdb\ndiff --git a/src/include/duckdb/main/extension_entries.hpp b/src/include/duckdb/main/extension_entries.hpp\nindex 89108ef34bca..6f86738a66a6 100644\n--- a/src/include/duckdb/main/extension_entries.hpp\n+++ b/src/include/duckdb/main/extension_entries.hpp\n@@ -478,6 +478,7 @@ static constexpr ExtensionFunctionEntry EXTENSION_FUNCTIONS[] = {\n     {\"quantile_disc\", \"core_functions\", CatalogType::AGGREGATE_FUNCTION_ENTRY},\n     {\"radians\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"random\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n+    {\"read_avro\", \"avro\", CatalogType::TABLE_FUNCTION_ENTRY},\n     {\"read_json\", \"json\", CatalogType::TABLE_FUNCTION_ENTRY},\n     {\"read_json_auto\", \"json\", CatalogType::TABLE_FUNCTION_ENTRY},\n     {\"read_json_objects\", \"json\", CatalogType::TABLE_FUNCTION_ENTRY},\n@@ -1086,16 +1087,28 @@ static constexpr ExtensionEntry EXTENSION_SECRET_PROVIDERS[] = {\n     {\"mysql/config\", \"mysql_scanner\"},\n     {\"postgres/config\", \"postgres_scanner\"}}; // EXTENSION_SECRET_PROVIDERS\n \n-static constexpr const char *AUTOLOADABLE_EXTENSIONS[] = {\"aws\",          \"azure\",\n-                                                          \"autocomplete\", \"core_functions\",\n-                                                          \"delta\",        \"excel\",\n-                                                          \"fts\",          \"httpfs\",\n-                                                          \"iceberg\",      \"inet\",\n-                                                          \"icu\",          \"json\",\n-                                                          \"motherduck\",   \"mysql_scanner\",\n-                                                          \"parquet\",      \"sqlite_scanner\",\n-                                                          \"sqlsmith\",     \"postgres_scanner\",\n-                                                          \"tpcds\",        \"tpch\",\n-                                                          \"uc_catalog\",   \"ui\"}; // END_OF_AUTOLOADABLE_EXTENSIONS\n+static constexpr const char *AUTOLOADABLE_EXTENSIONS[] = {\"avro\",\n+                                                          \"aws\",\n+                                                          \"azure\",\n+                                                          \"autocomplete\",\n+                                                          \"core_functions\",\n+                                                          \"delta\",\n+                                                          \"excel\",\n+                                                          \"fts\",\n+                                                          \"httpfs\",\n+                                                          \"iceberg\",\n+                                                          \"inet\",\n+                                                          \"icu\",\n+                                                          \"json\",\n+                                                          \"motherduck\",\n+                                                          \"mysql_scanner\",\n+                                                          \"parquet\",\n+                                                          \"sqlite_scanner\",\n+                                                          \"sqlsmith\",\n+                                                          \"postgres_scanner\",\n+                                                          \"tpcds\",\n+                                                          \"tpch\",\n+                                                          \"uc_catalog\",\n+                                                          \"ui\"}; // END_OF_AUTOLOADABLE_EXTENSIONS\n \n } // namespace duckdb\ndiff --git a/src/parser/parsed_data/create_type_info.cpp b/src/parser/parsed_data/create_type_info.cpp\nindex 1ce0327c3c31..4ee92f525a3f 100644\n--- a/src/parser/parsed_data/create_type_info.cpp\n+++ b/src/parser/parsed_data/create_type_info.cpp\n@@ -61,6 +61,7 @@ string CreateTypeInfo::ToString() const {\n \t\tresult += \" AS \";\n \t\tresult += type.ToString();\n \t}\n+\tresult += \";\";\n \treturn result;\n }\n \ndiff --git a/src/storage/statistics/numeric_stats.cpp b/src/storage/statistics/numeric_stats.cpp\nindex a9379812292e..4283ea78988e 100644\n--- a/src/storage/statistics/numeric_stats.cpp\n+++ b/src/storage/statistics/numeric_stats.cpp\n@@ -147,6 +147,7 @@ FilterPropagateResult CheckZonemapTemplated(const BaseStatistics &stats, Express\n                                             T max_value, T constant) {\n \tswitch (comparison_type) {\n \tcase ExpressionType::COMPARE_EQUAL:\n+\tcase ExpressionType::COMPARE_NOT_DISTINCT_FROM:\n \t\tif (ConstantExactRange(min_value, max_value, constant)) {\n \t\t\treturn FilterPropagateResult::FILTER_ALWAYS_TRUE;\n \t\t}\n@@ -155,6 +156,7 @@ FilterPropagateResult CheckZonemapTemplated(const BaseStatistics &stats, Express\n \t\t}\n \t\treturn FilterPropagateResult::FILTER_ALWAYS_FALSE;\n \tcase ExpressionType::COMPARE_NOTEQUAL:\n+\tcase ExpressionType::COMPARE_DISTINCT_FROM:\n \t\tif (!ConstantValueInRange(min_value, max_value, constant)) {\n \t\t\treturn FilterPropagateResult::FILTER_ALWAYS_TRUE;\n \t\t} else if (ConstantExactRange(min_value, max_value, constant)) {\ndiff --git a/src/storage/statistics/string_stats.cpp b/src/storage/statistics/string_stats.cpp\nindex 62262d448349..230944ab1446 100644\n--- a/src/storage/statistics/string_stats.cpp\n+++ b/src/storage/statistics/string_stats.cpp\n@@ -216,12 +216,14 @@ FilterPropagateResult StringStats::CheckZonemap(const_data_ptr_t min_data, idx_t\n \tint max_comp = StringValueComparison(data, MinValue(max_len, size), max_data);\n \tswitch (comparison_type) {\n \tcase ExpressionType::COMPARE_EQUAL:\n+\tcase ExpressionType::COMPARE_NOT_DISTINCT_FROM:\n \t\tif (min_comp >= 0 && max_comp <= 0) {\n \t\t\treturn FilterPropagateResult::NO_PRUNING_POSSIBLE;\n \t\t} else {\n \t\t\treturn FilterPropagateResult::FILTER_ALWAYS_FALSE;\n \t\t}\n \tcase ExpressionType::COMPARE_NOTEQUAL:\n+\tcase ExpressionType::COMPARE_DISTINCT_FROM:\n \t\tif (min_comp < 0 || max_comp > 0) {\n \t\t\treturn FilterPropagateResult::FILTER_ALWAYS_TRUE;\n \t\t}\ndiff --git a/third_party/fsst/fsst.h b/third_party/fsst/fsst.h\nindex 8e143db8782a..86909be5b5f2 100644\n--- a/third_party/fsst/fsst.h\n+++ b/third_party/fsst/fsst.h\n@@ -196,7 +196,7 @@ duckdb_fsst_decompress(\n          }\n       }\n    }\n-   if (posOut+24 <= size) { // handle the possibly 3 last bytes without a loop\n+   if (posOut+32 <= size) { // handle the possibly 3 last bytes without a loop\n       if (posIn+2 <= lenIn) { \n \t strOut[posOut] = strIn[posIn+1]; \n          if (strIn[posIn] != FSST_ESC) {\ndiff --git a/tools/shell/shell.cpp b/tools/shell/shell.cpp\nindex 72c7cf55f020..ba31af324940 100644\n--- a/tools/shell/shell.cpp\n+++ b/tools/shell/shell.cpp\n@@ -1736,11 +1736,7 @@ void ShellState::ExecutePreparedStatement(sqlite3_stmt *pStmt) {\n \t\t/* extract the data and data types */\n \t\tfor (int i = 0; i < nCol; i++) {\n \t\t\tresult.types[i] = sqlite3_column_type(pStmt, i);\n-\t\t\tif (result.types[i] == SQLITE_BLOB && cMode == RenderMode::INSERT) {\n-\t\t\t\tresult.data[i] = \"\";\n-\t\t\t} else {\n-\t\t\t\tresult.data[i] = (const char *)sqlite3_column_text(pStmt, i);\n-\t\t\t}\n+\t\t\tresult.data[i] = (const char *)sqlite3_column_text(pStmt, i);\n \t\t\tif (!result.data[i] && result.types[i] != SQLITE_NULL) {\n \t\t\t\t// OOM\n \t\t\t\trc = SQLITE_NOMEM;\n", "test_patch": "diff --git a/test/optimizer/pushdown/distinct_from_pushdown.test b/test/optimizer/pushdown/distinct_from_pushdown.test\nnew file mode 100644\nindex 000000000000..fa50f3094948\n--- /dev/null\n+++ b/test/optimizer/pushdown/distinct_from_pushdown.test\n@@ -0,0 +1,27 @@\n+# name: test/optimizer/pushdown/distinct_from_pushdown.test\n+# description: Test DISTINCT FROM pushed down into scans\n+# group: [pushdown]\n+\n+statement ok\n+create table test as select 'tst' as tst;\n+\n+query I\n+select * from test where tst is not distinct from 'a' or tst is not distinct from 'b';\n+----\n+\n+query I\n+select * from test where tst is distinct from 'a' or tst is distinct from 'b';\n+----\n+tst\n+\n+statement ok\n+create table test2 as select 42 as tst;\n+\n+query I\n+select * from test2 where tst is not distinct from 12 or tst is not distinct from 13;\n+----\n+\n+query I\n+select * from test2 where tst is distinct from 12 or tst is distinct from 13\n+----\n+42\ndiff --git a/test/sql/copy/csv/afl/test_fuzz_4086.test b/test/sql/copy/csv/afl/test_fuzz_4086.test\nnew file mode 100644\nindex 000000000000..08d2d36a80aa\n--- /dev/null\n+++ b/test/sql/copy/csv/afl/test_fuzz_4086.test\n@@ -0,0 +1,20 @@\n+# name: test/sql/copy/csv/afl/test_fuzz_4086.test\n+# description: fuzzer generated csv files - should not raise internal exception (by failed assertion).\n+# group: [afl]\n+\n+require json\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/4086/case_1.csv', auto_detect=false, columns={'json': 'JSON'}, delim=NULL, buffer_size=42, store_rejects=true, rejects_limit=658694493994253607);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/4086/case_2.csv', auto_detect=false, columns={'json': 'JSON'}, delim=NULL, buffer_size=42, store_rejects=true, rejects_limit=658694493994253607);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/4086/case_3.csv', auto_detect=false, columns={'json': 'JSON'}, delim='\\0', buffer_size=42, store_rejects=true, rejects_limit=658694493994253607);\n+----\ndiff --git a/test/sql/window/test_value_orderby.test b/test/sql/window/test_value_orderby.test\nindex 8b51198f277c..8fbb3e9e4cd1 100644\n--- a/test/sql/window/test_value_orderby.test\n+++ b/test/sql/window/test_value_orderby.test\n@@ -29,3 +29,19 @@ ORDER BY 2\n 9\t8\t9\t1\t7\n 6\t9\t9\t1\t6\n 3\t10\t9\t1\t6\n+\n+# Frame larger than data\n+query I\n+with IDS as (\n+    select * as idx from generate_series(1,4)\n+),DATA as (\n+    select *, (case when idx != 3 then idx * 1.0 else NULL end) as value from IDS\n+)\n+SELECT \n+ last(value ORDER BY idx IGNORE NULLS) OVER (ORDER BY idx ROWS BETWEEN UNBOUNDED PRECEDING AND 0 FOLLOWING)\n+FROM DATA\n+----\n+1.0\n+2.0\n+2.0\n+4.0\ndiff --git a/test/sql/window/test_window_constant_aggregate.test b/test/sql/window/test_window_constant_aggregate.test\nindex 6aafb23d0742..f16d221152b9 100644\n--- a/test/sql/window/test_window_constant_aggregate.test\n+++ b/test/sql/window/test_window_constant_aggregate.test\n@@ -205,7 +205,7 @@ ORDER BY ALL\n statement ok\n pragma threads=2\n \n-loop i 0 100\n+loop i 0 20\n \n query III\n with table_1 AS (\n@@ -285,3 +285,27 @@ fb30cf47-6f6b-42ef-dec2-3f984479a2aa\t2024-04-01 00:00:00\t12\n 7d1cc557-2d45-6900-a1ed-b2c64f5d9200\t2024-02-01 00:00:00\tNULL\n \n endloop\n+\n+# Test implicit ordering for aggregates\n+loop i 0 20\n+\n+query I\n+with repro2 AS (\n+\tSELECT range // 59 AS id, random() AS value\n+\tFROM range(1475)\n+), X AS (\n+\tSELECT\n+\t\tlist(value) OVER (\n+\t\t\tPARTITION BY id \n+\t\t\tORDER BY value \n+\t\t\tROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n+\t\t\t) AS values\n+\tFROM repro2\n+)\n+select count(*) \n+from X \n+where values[1] != list_aggregate(values, 'min')\n+----\n+0\n+\n+endloop\ndiff --git a/tools/shell/tests/test_shell_basics.py b/tools/shell/tests/test_shell_basics.py\nindex e2c554bb5a2d..1523ac2ccef2 100644\n--- a/tools/shell/tests/test_shell_basics.py\n+++ b/tools/shell/tests/test_shell_basics.py\n@@ -834,6 +834,17 @@ def test_dump_mixed(shell):\n     result = test.run()\n     result.check_stdout('CREATE TABLE a(d DATE, k FLOAT, t TIMESTAMP);')\n \n+def test_dump_blobs(shell):\n+    test = (\n+        ShellTest(shell)\n+        .statement(\"create table test(t VARCHAR, b BLOB);\")\n+        .statement(\".changes off\")\n+        .statement(\"insert into test values('literal blob', '\\\\x07\\\\x08\\\\x09');\")\n+        .statement(\".dump\")\n+    )\n+    result = test.run()\n+    result.check_stdout(\"'\\\\x07\\\\x08\\\\x09'\")\n+\n def test_invalid_csv(shell, tmp_path):\n     file = tmp_path / 'nonsencsv.csv'\n     with open(file, 'wb+') as f:\n@@ -869,18 +880,6 @@ def test_mode_trash(shell):\n     result = test.run()\n     result.check_stdout('')\n \n-@pytest.mark.skip(reason=\"Broken test, ported directly, was commented out\")\n-def test_dump_blobs(shell):\n-    test = (\n-        ShellTest(shell)\n-        .statement(\"CREATE TABLE a (b BLOB);\")\n-        .statement(\".changes off\")\n-        .statement(\"INSERT INTO a VALUES (DATE '1992-01-01', 0.3, NOW());\")\n-        .statement(\".dump\")\n-    )\n-    result = test.run()\n-    result.check_stdout('COMMIT')\n-\n def test_sqlite_comments(shell):\n     # Using /* <comment> */\n     test = (\n", "problem_statement": "[CLI] Empty strings for BLOB values in .mode insert / .dump\n### What happens?\n\nFor tables (or queries) with BLOB columns, `.dump` (or `.mode insert`) only produce empty strings instead of some kind \"literal BLOB value\".\n\nIn duckdb-cli 1.2.0 and 1.2.1.  \nAlso checked with 1.1.3, there the BLOBs are emitted as sqlite style BLOB literal ( `X'01F32B'` ) which is just wrong (as it is somewhat strangly interpreded as string with a prefixed X `'x01F32B'` - parser glitch ?)\n\nIt would make sense to emit these as eg `'\\x01\\xF3\\x2B'::BLOB`.\n\n### To Reproduce\n\n#### code\n```\ncreate table test(t VARCHAR, b BLOB);\ninsert into test values('literal blob', '\\x07\\x08\\x09');\ninsert into test values('text-as-blob', 'ABC'::BLOB);\ninsert into test values('unhex', unhex('040506'));\n\nselect * from test;\n\n.mode insert TEST\nselect * from test;\n\n.dump\n```\n\n#### results on 1.2.0/1.2.1 / BLOBs missing\n```\n-- select * from test;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      t       \u2502      b       \u2502\n\u2502   varchar    \u2502     blob     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 literal blob \u2502 \\x07\\x08\\x09 \u2502\n\u2502 text-as-blob \u2502 ABC          \u2502\n\u2502 unhex        \u2502 \\x04\\x05\\x06 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- .mode insert TEST\n-- select * from test;\nINSERT INTO TEST(t,b) VALUES('literal blob','');\nINSERT INTO TEST(t,b) VALUES('text-as-blob','');\nINSERT INTO TEST(t,b) VALUES('unhex','');\n\n-- .dump\nBEGIN TRANSACTION;\nCREATE TABLE test(t VARCHAR, b BLOB);;\nINSERT INTO test VALUES('literal blob','');\nINSERT INTO test VALUES('text-as-blob','');\nINSERT INTO test VALUES('unhex','');\nCOMMIT;\n```\n\n#### results on 1.1.3 / BLOBs as invalid (sqlite-style) literals\n```\n-- select * from test;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      t       \u2502      b       \u2502\n\u2502   varchar    \u2502     blob     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 literal blob \u2502 \\x07\\x08\\x09 \u2502\n\u2502 text-as-blob \u2502 ABC          \u2502\n\u2502 unhex        \u2502 \\x04\\x05\\x06 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- .mode insert TEST\n-- select * from test;\nINSERT INTO TEST(t,b) VALUES('literal blob',X'070809');\nINSERT INTO TEST(t,b) VALUES('text-as-blob',X'414243');\nINSERT INTO TEST(t,b) VALUES('unhex',X'040506');\n\n-- .dump\nPRAGMA foreign_keys=OFF;\nBEGIN TRANSACTION;\nCREATE TABLE test(t VARCHAR, b BLOB);;\nINSERT INTO test VALUES('literal blob',X'070809');\nINSERT INTO test VALUES('text-as-blob',X'414243');\nINSERT INTO test VALUES('unhex',X'040506');\nCOMMIT;\n```\n\n### OS:\n\nLinux (Ubuntu 24.04), x86_x64\n\n### DuckDB Version:\n\n1.2.1\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nMarc Gerber\n\n### Affiliation:\n\nprivate\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [ ] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n[CLI] Empty strings for BLOB values in .mode insert / .dump\n### What happens?\n\nFor tables (or queries) with BLOB columns, `.dump` (or `.mode insert`) only produce empty strings instead of some kind \"literal BLOB value\".\n\nIn duckdb-cli 1.2.0 and 1.2.1.  \nAlso checked with 1.1.3, there the BLOBs are emitted as sqlite style BLOB literal ( `X'01F32B'` ) which is just wrong (as it is somewhat strangly interpreded as string with a prefixed X `'x01F32B'` - parser glitch ?)\n\nIt would make sense to emit these as eg `'\\x01\\xF3\\x2B'::BLOB`.\n\n### To Reproduce\n\n#### code\n```\ncreate table test(t VARCHAR, b BLOB);\ninsert into test values('literal blob', '\\x07\\x08\\x09');\ninsert into test values('text-as-blob', 'ABC'::BLOB);\ninsert into test values('unhex', unhex('040506'));\n\nselect * from test;\n\n.mode insert TEST\nselect * from test;\n\n.dump\n```\n\n#### results on 1.2.0/1.2.1 / BLOBs missing\n```\n-- select * from test;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      t       \u2502      b       \u2502\n\u2502   varchar    \u2502     blob     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 literal blob \u2502 \\x07\\x08\\x09 \u2502\n\u2502 text-as-blob \u2502 ABC          \u2502\n\u2502 unhex        \u2502 \\x04\\x05\\x06 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- .mode insert TEST\n-- select * from test;\nINSERT INTO TEST(t,b) VALUES('literal blob','');\nINSERT INTO TEST(t,b) VALUES('text-as-blob','');\nINSERT INTO TEST(t,b) VALUES('unhex','');\n\n-- .dump\nBEGIN TRANSACTION;\nCREATE TABLE test(t VARCHAR, b BLOB);;\nINSERT INTO test VALUES('literal blob','');\nINSERT INTO test VALUES('text-as-blob','');\nINSERT INTO test VALUES('unhex','');\nCOMMIT;\n```\n\n#### results on 1.1.3 / BLOBs as invalid (sqlite-style) literals\n```\n-- select * from test;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      t       \u2502      b       \u2502\n\u2502   varchar    \u2502     blob     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 literal blob \u2502 \\x07\\x08\\x09 \u2502\n\u2502 text-as-blob \u2502 ABC          \u2502\n\u2502 unhex        \u2502 \\x04\\x05\\x06 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- .mode insert TEST\n-- select * from test;\nINSERT INTO TEST(t,b) VALUES('literal blob',X'070809');\nINSERT INTO TEST(t,b) VALUES('text-as-blob',X'414243');\nINSERT INTO TEST(t,b) VALUES('unhex',X'040506');\n\n-- .dump\nPRAGMA foreign_keys=OFF;\nBEGIN TRANSACTION;\nCREATE TABLE test(t VARCHAR, b BLOB);;\nINSERT INTO test VALUES('literal blob',X'070809');\nINSERT INTO test VALUES('text-as-blob',X'414243');\nINSERT INTO test VALUES('unhex',X'040506');\nCOMMIT;\n```\n\n### OS:\n\nLinux (Ubuntu 24.04), x86_x64\n\n### DuckDB Version:\n\n1.2.1\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nMarc Gerber\n\n### Affiliation:\n\nprivate\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [ ] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nEXPORT DATABASE containing types misses semicolon\n### What happens?\n\nHi and thanks for this amazing project.\n\nSeems like exporting databases containing type declarations is currently broken.\n\n### To Reproduce\n\nTo reproduce the issue:\n\n```\ncreate type one as text;\ncreate type two as text;\nexport database 'typeissue';\n```\n\nThen in a new DB:\n\n```\nimport database 'typeissue';\n```\n\nThis results in:\n\n\n```\nParser Error:\nsyntax error at or near \"CREATE\"\n\nLINE 1: import database 'typeissue';\n```\n\nSemicolons are missing in `schema.sql`. Contents:\n\n```\nCREATE TYPE one AS VARCHAR\nCREATE TYPE two AS VARCHAR\n```\n\n### OS:\n\nx86_64\n\n### DuckDB Version:\n\n`v1.2.0 5f5512b827`\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nJorin Vogel\n\n### Affiliation:\n\ntaleshape.com\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "\n\n", "created_at": "2025-03-20T11:48:17Z"}
{"repo": "duckdb/duckdb", "pull_number": 16732, "instance_id": "duckdb__duckdb-16732", "issue_numbers": ["16662", "16662"], "base_commit": "09bf1d736d031fb7c49a56201a436a390545c16e", "patch": "diff --git a/src/planner/binder/tableref/bind_basetableref.cpp b/src/planner/binder/tableref/bind_basetableref.cpp\nindex d0302a1086e5..a8cf487f4e84 100644\n--- a/src/planner/binder/tableref/bind_basetableref.cpp\n+++ b/src/planner/binder/tableref/bind_basetableref.cpp\n@@ -92,6 +92,16 @@ vector<CatalogSearchEntry> Binder::GetSearchPath(Catalog &catalog, const string\n \treturn view_search_path;\n }\n \n+static vector<LogicalType> ExchangeAllNullTypes(const vector<LogicalType> &types) {\n+\tvector<LogicalType> result = types;\n+\tfor (auto &type : result) {\n+\t\tif (ExpressionBinder::ContainsNullType(type)) {\n+\t\t\ttype = ExpressionBinder::ExchangeNullType(type);\n+\t\t}\n+\t}\n+\treturn result;\n+}\n+\n unique_ptr<BoundTableRef> Binder::Bind(BaseTableRef &ref) {\n \tQueryErrorContext error_context(ref.query_location);\n \t// CTEs and views are also referred to using BaseTableRefs, hence need to distinguish here\n@@ -305,9 +315,14 @@ unique_ptr<BoundTableRef> Binder::Bind(BaseTableRef &ref) {\n \t\t// verify that the types and names match up with the expected types and names\n \t\tauto &bound_subquery = bound_child->Cast<BoundSubqueryRef>();\n \t\tif (GetBindingMode() != BindingMode::EXTRACT_NAMES) {\n-\t\t\tif (bound_subquery.subquery->types != view_catalog_entry.types) {\n-\t\t\t\tauto actual_types = StringUtil::ToString(bound_subquery.subquery->types, \", \");\n-\t\t\t\tauto expected_types = StringUtil::ToString(view_catalog_entry.types, \", \");\n+\t\t\t// we bind the view subquery and the original view with different \"can_contain_nulls\",\n+\t\t\t// but we don't want to throw an error when SQLNULL does not match up with INTEGER,\n+\t\t\t// so we exchange all SQLNULL with INTEGER here before comparing\n+\t\t\tauto bound_types = ExchangeAllNullTypes(bound_subquery.subquery->types);\n+\t\t\tauto view_types = ExchangeAllNullTypes(view_catalog_entry.types);\n+\t\t\tif (bound_types != view_types) {\n+\t\t\t\tauto actual_types = StringUtil::ToString(bound_types, \", \");\n+\t\t\t\tauto expected_types = StringUtil::ToString(view_types, \", \");\n \t\t\t\tthrow BinderException(\n \t\t\t\t    \"Contents of view were altered: types don't match! Expected [%s], but found [%s] instead\",\n \t\t\t\t    expected_types, actual_types);\n", "test_patch": "diff --git a/test/issues/general/test_16662.test b/test/issues/general/test_16662.test\nnew file mode 100644\nindex 000000000000..d18c37d8c16d\n--- /dev/null\n+++ b/test/issues/general/test_16662.test\n@@ -0,0 +1,63 @@\n+# name: test/issues/general/test_16662.test\n+# description: Issue 16662 - Unexpected binder error when using a CTE multiple times\n+# group: [general]\n+\n+statement ok\n+pragma enable_verification\n+\n+statement ok\n+CREATE VIEW\n+  \"tbl1\" AS\n+  -- End of EXAMPLE 4 (pt1)\n+WITH\n+  data_infra as (\n+    select\n+      'a' as AMES,\n+      'b' as TONG\n+      -- Example 6: Unomment out the following line to see it work\n+      -- If there is more than one resulting row in the group by then there is not error\n+      -- union all\n+      -- select\n+      --   'c' as AMES,\n+      --   'b' as TONG\n+      --End Example 6\n+      -- Example 5: Comment out the following line to see it work\n+      -- If there is no group by then there is an error\n+    group by\n+      1\n+      -- End of Example 5\n+  )\n+SELECT\n+  -- Example 1: Comment the following lines to see it work\n+  -- If the CTE is used only once then there is no error\n+  case\n+    when 'b' in (\n+      select\n+        TONG\n+      from\n+        data_infra\n+    ) then 'tong'\n+    else 'Various'\n+  end as collapsed_TONG,\n+  --- End of Example 1\n+  -- Example 2: Comment the following lines to see it work\n+  -- If the CTE is used only once then there is no error\n+  case\n+    when 'ba' in (\n+      select\n+        TONG\n+      from\n+        data_infra\n+    ) then 'ames'\n+    else null\n+  end as collapsed_AMES,\n+  --- End of Example 2\n+  -- Example 3: Delete this line to see it work\n+  -- If there is no null column there is no error\n+  NULL AS NULL_COL;\n+\n+statement ok\n+SELECT\n+  *\n+FROM\n+  \"tbl1\";\n", "problem_statement": "Unexpected binder error when using a CTE multiple times\n### What happens?\n\nWe think we found a very specific edge case when upgrading from 1.0.0 to 1.1.0 or 1.2.0. \n\nThe following reproduction sql produces this error and the error can be avoided with any of the changes I have listed in the sql block.  \n\n```\nBinder Error:\nContents of view were altered: types don't match! Expected [VARCHAR, VARCHAR, INTEGER], but found [VARCHAR, VARCHAR, \"NULL\"] instead\n```\n\nWe believe the specific case that causes this error is sql which:\n- creates a view with a null column\n- uses a CTE multiple times\n- the CTE in question needs to have `group by` which results in only a single group (in this example we use group by 1 and have a single row)\n\nThanks so much! \n\n### To Reproduce\n\n```\n-- EXAMPLE 4 (pt1): Comment the following lines to see it work\n-- If you don't create a view then there is no error\nCREATE VIEW\n  \"tbl1\" AS\n  -- End of EXAMPLE 4 (pt1)\nWITH\n  data_infra as (\n    select\n      'a' as AMES,\n      'b' as TONG\n      -- Example 6: Unomment out the following line to see it work\n      -- If there is more than one resulting row in the group by then there is not error\n      -- union all\n      -- select\n      --   'c' as AMES,\n      --   'b' as TONG\n      --End Example 6\n      -- Example 5: Comment out the following line to see it work\n      -- If there is no group by then there is an error\n    group by\n      1\n      -- End of Example 5\n  )\nSELECT\n  -- Example 1: Comment the following lines to see it work\n  -- If the CTE is used only once then there is no error\n  case\n    when 'b' in (\n      select\n        TONG\n      from\n        data_infra\n    ) then 'tong'\n    else 'Various'\n  end as collapsed_TONG,\n  --- End of Example 1\n  -- Example 2: Comment the following lines to see it work\n  -- If the CTE is used only once then there is no error\n  case\n    when 'ba' in (\n      select\n        TONG\n      from\n        data_infra\n    ) then 'ames'\n    else null\n  end as collapsed_AMES,\n  --- End of Example 2\n  -- Example 3: Delete this line to see it work\n  -- If there is no null column there is no error\n  NULL AS NULL_COL;\n\n-- Example 4 (pt2): Comment out the following line to see it work\nSELECT\n  *\nFROM\n  \"tbl1\";\n\n-- End of EXAMPLE 4 (pt2)Exam\n```\n\n### OS:\n\nosx arm64\n\n### DuckDB Version:\n\n1.1.0 or 1.2.0\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nAmes Holm\n\n### Affiliation:\n\nWatershed\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNot applicable - the reproduction does not require a data set\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nUnexpected binder error when using a CTE multiple times\n### What happens?\n\nWe think we found a very specific edge case when upgrading from 1.0.0 to 1.1.0 or 1.2.0. \n\nThe following reproduction sql produces this error and the error can be avoided with any of the changes I have listed in the sql block.  \n\n```\nBinder Error:\nContents of view were altered: types don't match! Expected [VARCHAR, VARCHAR, INTEGER], but found [VARCHAR, VARCHAR, \"NULL\"] instead\n```\n\nWe believe the specific case that causes this error is sql which:\n- creates a view with a null column\n- uses a CTE multiple times\n- the CTE in question needs to have `group by` which results in only a single group (in this example we use group by 1 and have a single row)\n\nThanks so much! \n\n### To Reproduce\n\n```\n-- EXAMPLE 4 (pt1): Comment the following lines to see it work\n-- If you don't create a view then there is no error\nCREATE VIEW\n  \"tbl1\" AS\n  -- End of EXAMPLE 4 (pt1)\nWITH\n  data_infra as (\n    select\n      'a' as AMES,\n      'b' as TONG\n      -- Example 6: Unomment out the following line to see it work\n      -- If there is more than one resulting row in the group by then there is not error\n      -- union all\n      -- select\n      --   'c' as AMES,\n      --   'b' as TONG\n      --End Example 6\n      -- Example 5: Comment out the following line to see it work\n      -- If there is no group by then there is an error\n    group by\n      1\n      -- End of Example 5\n  )\nSELECT\n  -- Example 1: Comment the following lines to see it work\n  -- If the CTE is used only once then there is no error\n  case\n    when 'b' in (\n      select\n        TONG\n      from\n        data_infra\n    ) then 'tong'\n    else 'Various'\n  end as collapsed_TONG,\n  --- End of Example 1\n  -- Example 2: Comment the following lines to see it work\n  -- If the CTE is used only once then there is no error\n  case\n    when 'ba' in (\n      select\n        TONG\n      from\n        data_infra\n    ) then 'ames'\n    else null\n  end as collapsed_AMES,\n  --- End of Example 2\n  -- Example 3: Delete this line to see it work\n  -- If there is no null column there is no error\n  NULL AS NULL_COL;\n\n-- Example 4 (pt2): Comment out the following line to see it work\nSELECT\n  *\nFROM\n  \"tbl1\";\n\n-- End of EXAMPLE 4 (pt2)Exam\n```\n\n### OS:\n\nosx arm64\n\n### DuckDB Version:\n\n1.1.0 or 1.2.0\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nAmes Holm\n\n### Affiliation:\n\nWatershed\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNot applicable - the reproduction does not require a data set\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "Thanks for the bug report! I can confirm that this issue was introduced somewhere between v1.0.0 and v1.1.0. I will look into the cause and try to fix.\nAs a workaround, you can do:\n```sql\nSET disabled_optimizers TO 'MATERIALIZED_CTE';\n```\nThanks for the bug report! I can confirm that this issue was introduced somewhere between v1.0.0 and v1.1.0. I will look into the cause and try to fix.\nAs a workaround, you can do:\n```sql\nSET disabled_optimizers TO 'MATERIALIZED_CTE';\n```", "created_at": "2025-03-19T16:05:33Z"}
{"repo": "duckdb/duckdb", "pull_number": 16729, "instance_id": "duckdb__duckdb-16729", "issue_numbers": ["16572", "16572"], "base_commit": "d89d5fc44b4424bdd4adbdc921ab459b3eb5ec16", "patch": "diff --git a/data/json/sample_utf8_bom.json b/data/json/sample_utf8_bom.json\nnew file mode 100644\nindex 000000000000..e94bf1147245\n--- /dev/null\n+++ b/data/json/sample_utf8_bom.json\n@@ -0,0 +1,24 @@\n+\ufeff{\n+    \"users\": [\n+        {\n+            \"id\": 1,\n+            \"name\": \"Alice\",\n+            \"email\": \"alice@example.com\"\n+        },\n+        {\n+            \"id\": 2,\n+            \"name\": \"Bob\",\n+            \"email\": \"bob@example.com\"\n+        },\n+        {\n+            \"id\": 3,\n+            \"name\": \"Charlie\",\n+            \"email\": \"charlie@example.com\"\n+        }\n+    ],\n+    \"metadata\": {\n+        \"description\": \"Sample JSON file with UTF-8 BOM\",\n+        \"version\": \"1.0\",\n+        \"generated\": \"2025-03-09T12:00:00Z\"\n+    }\n+}\n\\ No newline at end of file\ndiff --git a/extension/core_functions/scalar/list/array_slice.cpp b/extension/core_functions/scalar/list/array_slice.cpp\nindex 0962b3c2eeff..92f1c1efb53a 100644\n--- a/extension/core_functions/scalar/list/array_slice.cpp\n+++ b/extension/core_functions/scalar/list/array_slice.cpp\n@@ -416,7 +416,12 @@ static unique_ptr<FunctionData> ArraySliceBind(ClientContext &context, ScalarFun\n \t\t\t    \"Slice with steps has not been implemented for string types, you can consider rewriting your query as \"\n \t\t\t    \"follows:\\n SELECT array_to_string((str_split(string, '')[begin:end:step], '');\");\n \t\t}\n-\t\tbound_function.return_type = arguments[0]->return_type;\n+\t\tif (arguments[0]->return_type.IsJSONType()) {\n+\t\t\t// This is needed to avoid producing invalid JSON\n+\t\t\tbound_function.return_type = LogicalType::VARCHAR;\n+\t\t} else {\n+\t\t\tbound_function.return_type = arguments[0]->return_type;\n+\t\t}\n \t\tfor (idx_t i = 1; i < 3; i++) {\n \t\t\tif (arguments[i]->return_type.id() != LogicalTypeId::LIST) {\n \t\t\t\tbound_function.arguments[i] = LogicalType::BIGINT;\ndiff --git a/extension/json/json_functions/copy_json.cpp b/extension/json/json_functions/copy_json.cpp\nindex 7cb196576907..0cc42cb2d5e8 100644\n--- a/extension/json/json_functions/copy_json.cpp\n+++ b/extension/json/json_functions/copy_json.cpp\n@@ -120,7 +120,7 @@ CopyFunction JSONFunctions::GetJSONCopyFunction() {\n \n \tfunction.copy_from_bind = MultiFileReaderFunction<JSONMultiFileInfo>::MultiFileBindCopy;\n \tfunction.copy_from_function = JSONFunctions::GetReadJSONTableFunction(make_shared_ptr<JSONScanInfo>(\n-\t    JSONScanType::READ_JSON, JSONFormat::NEWLINE_DELIMITED, JSONRecordType::RECORDS, false));\n+\t    JSONScanType::READ_JSON, JSONFormat::AUTO_DETECT, JSONRecordType::RECORDS, false));\n \n \treturn function;\n }\ndiff --git a/extension/json/json_multi_file_info.cpp b/extension/json/json_multi_file_info.cpp\nindex ca91fc941b55..58e539686af2 100644\n--- a/extension/json/json_multi_file_info.cpp\n+++ b/extension/json/json_multi_file_info.cpp\n@@ -21,8 +21,10 @@ unique_ptr<BaseFileReaderOptions> JSONMultiFileInfo::InitializeOptions(ClientCon\n \t\t}\n \t} else {\n \t\t// COPY\n+\t\toptions.type = JSONScanType::READ_JSON;\n \t\toptions.record_type = JSONRecordType::RECORDS;\n-\t\toptions.format = JSONFormat::NEWLINE_DELIMITED;\n+\t\toptions.format = JSONFormat::AUTO_DETECT;\n+\t\toptions.auto_detect = false;\n \t}\n \treturn std::move(reader_options);\n }\n@@ -76,6 +78,9 @@ bool JSONMultiFileInfo::ParseOption(ClientContext &context, const string &key, c\n \t\tfor (idx_t i = 0; i < struct_children.size(); i++) {\n \t\t\tauto &name = StructType::GetChildName(child_type, i);\n \t\t\tauto &val = struct_children[i];\n+\t\t\tif (val.IsNull()) {\n+\t\t\t\tthrow BinderException(\"read_json \\\"columns\\\" parameter type specification cannot be NULL.\");\n+\t\t\t}\n \t\t\toptions.name_list.push_back(name);\n \t\t\tif (val.type().id() != LogicalTypeId::VARCHAR) {\n \t\t\t\tthrow BinderException(\"read_json \\\"columns\\\" parameter type specification must be VARCHAR.\");\n@@ -222,6 +227,7 @@ bool JSONMultiFileInfo::ParseCopyOption(ClientContext &context, const string &ke\n \t\t} else {\n \t\t\tJSONCheckSingleParameter(key, values);\n \t\t\toptions.auto_detect = BooleanValue::Get(values.back().DefaultCastAs(LogicalTypeId::BOOLEAN));\n+\t\t\toptions.format = JSONFormat::NEWLINE_DELIMITED;\n \t\t}\n \t\treturn true;\n \t}\n@@ -238,6 +244,9 @@ bool JSONMultiFileInfo::ParseCopyOption(ClientContext &context, const string &ke\n \t\t\tJSONCheckSingleParameter(key, values);\n \t\t\tif (BooleanValue::Get(values.back().DefaultCastAs(LogicalTypeId::BOOLEAN))) {\n \t\t\t\toptions.format = JSONFormat::ARRAY;\n+\t\t\t} else {\n+\t\t\t\t// Default to newline-delimited otherwise\n+\t\t\t\toptions.format = JSONFormat::NEWLINE_DELIMITED;\n \t\t\t}\n \t\t}\n \t\treturn true;\ndiff --git a/extension/json/json_reader.cpp b/extension/json/json_reader.cpp\nindex 1ee91452a4d6..241ea1509c66 100644\n--- a/extension/json/json_reader.cpp\n+++ b/extension/json/json_reader.cpp\n@@ -903,8 +903,11 @@ void JSONReader::FinalizeBuffer(JSONReaderScanState &scan_state) {\n \t// we read something\n \t// skip over the array start if required\n \tif (!scan_state.is_last) {\n-\t\tif (scan_state.buffer_index.GetIndex() == 0 && GetFormat() == JSONFormat::ARRAY) {\n-\t\t\tSkipOverArrayStart(scan_state);\n+\t\tif (scan_state.buffer_index.GetIndex() == 0) {\n+\t\t\tStringUtil::SkipBOM(scan_state.buffer_ptr, scan_state.buffer_size, scan_state.buffer_offset);\n+\t\t\tif (GetFormat() == JSONFormat::ARRAY) {\n+\t\t\t\tSkipOverArrayStart(scan_state);\n+\t\t\t}\n \t\t}\n \t}\n \t// then finalize the buffer\ndiff --git a/src/common/string_util.cpp b/src/common/string_util.cpp\nindex b0d4b8731ca8..f7a817b5065f 100644\n--- a/src/common/string_util.cpp\n+++ b/src/common/string_util.cpp\n@@ -846,6 +846,13 @@ void StringUtil::URLDecodeBuffer(const char *input, idx_t input_size, char *outp\n \t}\n }\n \n+void StringUtil::SkipBOM(const char *buffer_ptr, const idx_t &buffer_size, idx_t &buffer_pos) {\n+\tif (buffer_size >= 3 && buffer_ptr[0] == '\\xEF' && buffer_ptr[1] == '\\xBB' && buffer_ptr[2] == '\\xBF' &&\n+\t    buffer_pos == 0) {\n+\t\tbuffer_pos = 3;\n+\t}\n+}\n+\n string StringUtil::URLDecode(const string &input, bool plus_to_space) {\n \tidx_t result_size = URLDecodeSize(input.c_str(), input.size(), plus_to_space);\n \tauto result_data = make_uniq_array<char>(result_size);\ndiff --git a/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp b/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\nindex 476e4f4bb468..51d508834fe4 100644\n--- a/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\n+++ b/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\n@@ -1578,10 +1578,7 @@ bool StringValueScanner::MoveToNextBuffer() {\n }\n \n void StringValueResult::SkipBOM() const {\n-\tif (buffer_size >= 3 && buffer_ptr[0] == '\\xEF' && buffer_ptr[1] == '\\xBB' && buffer_ptr[2] == '\\xBF' &&\n-\t    iterator.pos.buffer_pos == 0) {\n-\t\titerator.pos.buffer_pos = 3;\n-\t}\n+\tStringUtil::SkipBOM(buffer_ptr, buffer_size, iterator.pos.buffer_pos);\n }\n \n void StringValueResult::RemoveLastLine() {\ndiff --git a/src/execution/operator/set/physical_union.cpp b/src/execution/operator/set/physical_union.cpp\nindex de2a6282d60a..0071de2513e4 100644\n--- a/src/execution/operator/set/physical_union.cpp\n+++ b/src/execution/operator/set/physical_union.cpp\n@@ -17,6 +17,18 @@ PhysicalUnion::PhysicalUnion(vector<LogicalType> types, PhysicalOperator &top, P\n //===--------------------------------------------------------------------===//\n // Pipeline Construction\n //===--------------------------------------------------------------------===//\n+static bool ContainsSink(PhysicalOperator &op) {\n+\tif (op.IsSink()) {\n+\t\treturn true;\n+\t}\n+\tfor (auto &child : op.children) {\n+\t\tif (ContainsSink(child)) {\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\treturn false;\n+}\n+\n void PhysicalUnion::BuildPipelines(Pipeline &current, MetaPipeline &meta_pipeline) {\n \top_state.reset();\n \tsink_state.reset();\n@@ -52,7 +64,11 @@ void PhysicalUnion::BuildPipelines(Pipeline &current, MetaPipeline &meta_pipelin\n \n \tvector<shared_ptr<Pipeline>> dependencies;\n \toptional_ptr<MetaPipeline> last_child_ptr;\n-\tconst auto can_saturate_threads = children[0].get().CanSaturateThreads(current.GetClientContext());\n+\t// users commonly UNION ALL together a bunch of cheap scan pipelines (e.g., instead of a multi file list)\n+\t// in these cases, we don't want to avoid breadth-first plan evaluation,\n+\t// as it doesn't pose a threat to memory usage (it's just a bunch of straight scans)\n+\tconst auto can_saturate_threads =\n+\t    ContainsSink(children[0]) && children[0].get().CanSaturateThreads(current.GetClientContext());\n \tif (order_matters || can_saturate_threads) {\n \t\t// we add dependencies if order matters: union_pipeline comes after all pipelines created by building current\n \t\tdependencies = meta_pipeline.AddDependenciesFrom(union_pipeline, union_pipeline, false);\ndiff --git a/src/include/duckdb/common/string_util.hpp b/src/include/duckdb/common/string_util.hpp\nindex c46453952ad7..8c0c19bef93a 100644\n--- a/src/include/duckdb/common/string_util.hpp\n+++ b/src/include/duckdb/common/string_util.hpp\n@@ -165,6 +165,9 @@ class StringUtil {\n \tDUCKDB_API static void URLDecodeBuffer(const char *input, idx_t input_size, char *output,\n \t                                       bool plus_to_space = false);\n \n+\t//! BOM skipping (https://en.wikipedia.org/wiki/Byte_order_mark)\n+\tDUCKDB_API static void SkipBOM(const char *buffer_ptr, const idx_t &buffer_size, idx_t &buffer_pos);\n+\n \tDUCKDB_API static idx_t ToUnsigned(const string &str);\n \n \ttemplate <class T>\n", "test_patch": "diff --git a/test/sql/json/issues/internal_issue4389.test b/test/sql/json/issues/internal_issue4389.test\nnew file mode 100644\nindex 000000000000..dea3a10afe59\n--- /dev/null\n+++ b/test/sql/json/issues/internal_issue4389.test\n@@ -0,0 +1,20 @@\n+# name: test/sql/json/issues/internal_issue4389.test\n+# description: Test internal issue 4389 - auto_detect is false for COPY + JSON\n+# group: [issues]\n+\n+require json\n+\n+statement ok\n+pragma enable_verification\n+\n+statement ok\n+CREATE TABLE todos (userId UBIGINT, id UBIGINT, title VARCHAR, completed BOOLEAN);\n+\n+statement ok\n+insert into todos values (42, 42, 'duck', true)\n+\n+statement ok\n+copy todos to '__TEST_DIR__/todos.json' (ARRAY)\n+\n+statement ok\n+copy todos from '__TEST_DIR__/todos.json'\ndiff --git a/test/sql/json/issues/internal_issue4403.test b/test/sql/json/issues/internal_issue4403.test\nnew file mode 100644\nindex 000000000000..8507d2ff27d7\n--- /dev/null\n+++ b/test/sql/json/issues/internal_issue4403.test\n@@ -0,0 +1,13 @@\n+# name: test/sql/json/issues/internal_issue4403.test\n+# description: Test internal issue 4403 - AFL fuzzer crash (NULL type specification)\n+# group: [issues]\n+\n+require json\n+\n+statement ok\n+pragma enable_verification\n+\n+statement error\n+SELECT * FROM read_json('data/json/example_n.ndjson', columns={id: NULL::VARCHAR, name: NULL::VARCHAR})\n+----\n+Binder Error\ndiff --git a/test/sql/json/issues/issue16568.test b/test/sql/json/issues/issue16568.test\nnew file mode 100644\nindex 000000000000..a884d637c6a9\n--- /dev/null\n+++ b/test/sql/json/issues/issue16568.test\n@@ -0,0 +1,13 @@\n+# name: test/sql/json/issues/issue16568.test\n+# description: Test issue 16568 - Error when loading JSON files with UTF-8 Byte Order Mark (BOM)\n+# group: [issues]\n+\n+require json\n+\n+statement ok\n+pragma enable_verification\n+\n+query I\n+select count(*) from 'data/json/sample_utf8_bom.json'\n+----\n+1\ndiff --git a/test/sql/json/issues/issue16570.test b/test/sql/json/issues/issue16570.test\nnew file mode 100644\nindex 000000000000..f4caf2f548e7\n--- /dev/null\n+++ b/test/sql/json/issues/issue16570.test\n@@ -0,0 +1,17 @@\n+# name: test/sql/json/issues/issue16570.test\n+# description: Test issue 16570 - JSON type: string slice operation results in result value with JSON type, expected VARCHAR\n+# group: [issues]\n+\n+require json\n+\n+statement ok\n+pragma enable_verification\n+\n+query II\n+with cte as (\n+    select '{\"a\":1}'::JSON as j\n+)\n+select typeof(j[2:3]), typeof(substring(j, 2, 3))\n+from cte\n+----\n+VARCHAR\tVARCHAR\ndiff --git a/test/sql/json/test_json_copy.test_slow b/test/sql/json/test_json_copy.test_slow\nindex b1beee17c385..0c3f07291712 100644\n--- a/test/sql/json/test_json_copy.test_slow\n+++ b/test/sql/json/test_json_copy.test_slow\n@@ -160,14 +160,15 @@ select * from '__TEST_DIR__/out.json'\n statement ok\n create table conclusions (conclusion varchar)\n \n-# this doesn't work because we assume NDJSON records\n-statement error\n+# works because we auto-detect by default\n+statement ok\n copy conclusions from 'data/json/top_level_array.json'\n-----\n \n-# but works if we tell it to auto-detect\n-statement ok\n-copy conclusions from 'data/json/top_level_array.json' (AUTO_DETECT TRUE)\n+# doesn't work if we disable auto-detection\n+statement error\n+copy conclusions from 'data/json/top_level_array.json' (AUTO_DETECT FALSE)\n+----\n+Invalid Input Error\n \n statement ok\n delete from conclusions;\n", "problem_statement": "Performance issue: No multi-threading unless I partition and union manually\n### What happens?\n\nI have an aggregation that I need to do per customer. \nFor each customer, I have a number of files scattered around my file-system; the mapping from customer to files is provided by a third party tool that spits out strings of the form:\n\n```sql\nSELECT customer1 AS customer, * FROM '02q340234.parquet'\nUNION ALL\nSELECT customer1 AS customer, * FROM '014afe123.parquet'\nUNION ALL \nSELECT customer2 AS customer, * FROM '39fefe934.parquet'\nUNION ALL\nSELECT customer2 AS customer, * FROM '93feas023.parquet'\nUNION ALL\n...\n```\n\n\nIf I run \n\n```sql\nSELECT\n  customer,\n  <someaggregation>\nFROM <third_party_tool_output>\nGROUP BY customer\n```\n\nDuckDB doesn't seem to use multi-threading. If I manually run that same query separately on the files pertaining to each customer (by splitting the third party output manually), and take the union of results afterwards, all my 4 CPU cores are busy and I get the results 4x faster.\n\n### To Reproduce\n\n```python\nimport pandas as pd\nimport numpy as np\nimport duckdb\nimport itertools\nfrom collections import defaultdict\n\nm = 40\nn_customers = 8\nrows = 1_000_000\n\nraw_data = defaultdict(list)\nfor i in range(m):\n    path = f\"/tmp/test{i}.parquet\"\n    pd.DataFrame(np.random.rand(rows, 1), columns=['value']).reset_index().to_parquet(path)\n    customer = i % n_customers\n    raw_data[customer].append(f\"\"\"SELECT '{customer}' AS customer, * FROM '{path}'\"\"\")\n    \ndef my_query(inputs):\n    q = \"\\nUNION ALL\\n\".join(inputs)\n    return f\"\"\"SELECT df1.customer, sum(df1.value * df2.value) FROM ({q}) df1 JOIN ({q}) df2 USING (customer, index) GROUP BY ALL\"\"\"\n\nq1 = my_query(itertools.chain(*raw_data.values()))\nduckdb.query(q1) # slow \n\nq2 = \"\\nUNION ALL\\n\".join([my_query(inputs) for inputs in raw_data.values()])\nduckdb.query(q2) # fast but ugly\n```\n\n### OS:\n\nLinux\n\n### DuckDB Version:\n\n1.2.2-dev15\n\n### DuckDB Client:\n\nPython\n\n### Hardware:\n\nAMD64, Intel, 4 physical cores, 8 logical cores\n\n### Full Name:\n\nSoeren Wolfers\n\n### Affiliation:\n\nG-Research\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a nightly build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNot applicable - the reproduction does not require a data set\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nPerformance issue: No multi-threading unless I partition and union manually\n### What happens?\n\nI have an aggregation that I need to do per customer. \nFor each customer, I have a number of files scattered around my file-system; the mapping from customer to files is provided by a third party tool that spits out strings of the form:\n\n```sql\nSELECT customer1 AS customer, * FROM '02q340234.parquet'\nUNION ALL\nSELECT customer1 AS customer, * FROM '014afe123.parquet'\nUNION ALL \nSELECT customer2 AS customer, * FROM '39fefe934.parquet'\nUNION ALL\nSELECT customer2 AS customer, * FROM '93feas023.parquet'\nUNION ALL\n...\n```\n\n\nIf I run \n\n```sql\nSELECT\n  customer,\n  <someaggregation>\nFROM <third_party_tool_output>\nGROUP BY customer\n```\n\nDuckDB doesn't seem to use multi-threading. If I manually run that same query separately on the files pertaining to each customer (by splitting the third party output manually), and take the union of results afterwards, all my 4 CPU cores are busy and I get the results 4x faster.\n\n### To Reproduce\n\n```python\nimport pandas as pd\nimport numpy as np\nimport duckdb\nimport itertools\nfrom collections import defaultdict\n\nm = 40\nn_customers = 8\nrows = 1_000_000\n\nraw_data = defaultdict(list)\nfor i in range(m):\n    path = f\"/tmp/test{i}.parquet\"\n    pd.DataFrame(np.random.rand(rows, 1), columns=['value']).reset_index().to_parquet(path)\n    customer = i % n_customers\n    raw_data[customer].append(f\"\"\"SELECT '{customer}' AS customer, * FROM '{path}'\"\"\")\n    \ndef my_query(inputs):\n    q = \"\\nUNION ALL\\n\".join(inputs)\n    return f\"\"\"SELECT df1.customer, sum(df1.value * df2.value) FROM ({q}) df1 JOIN ({q}) df2 USING (customer, index) GROUP BY ALL\"\"\"\n\nq1 = my_query(itertools.chain(*raw_data.values()))\nduckdb.query(q1) # slow \n\nq2 = \"\\nUNION ALL\\n\".join([my_query(inputs) for inputs in raw_data.values()])\nduckdb.query(q2) # fast but ugly\n```\n\n### OS:\n\nLinux\n\n### DuckDB Version:\n\n1.2.2-dev15\n\n### DuckDB Client:\n\nPython\n\n### Hardware:\n\nAMD64, Intel, 4 physical cores, 8 logical cores\n\n### Full Name:\n\nSoeren Wolfers\n\n### Affiliation:\n\nG-Research\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a nightly build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNot applicable - the reproduction does not require a data set\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "we can confirm this as well. we have a lot of queries we need to union at the end. and it seems like every query is processed in serial with one thread. would be great to have multithreaded unions.\n@OneCyrus I'm not sure you have the same problem as described in this issue. In my case, both versions of the query contain unions and the one where the unions are the outer operation is actually faster. Thus, from my perspective, this seems to be a missed optimization of some aspect in the `GROUP BY` or `JOIN` clause that would allow DuckDB to logically do the same thing as the second query, i.e. run independent subqueries by customer, rather than creating one big hash map for the joins / group bys over all customers. \nwe can confirm this as well. we have a lot of queries we need to union at the end. and it seems like every query is processed in serial with one thread. would be great to have multithreaded unions.\n@OneCyrus I'm not sure you have the same problem as described in this issue. In my case, both versions of the query contain unions and the one where the unions are the outer operation is actually faster. Thus, from my perspective, this seems to be a missed optimization of some aspect in the `GROUP BY` or `JOIN` clause that would allow DuckDB to logically do the same thing as the second query, i.e. run independent subqueries by customer, rather than creating one big hash map for the joins / group bys over all customers. ", "created_at": "2025-03-19T14:19:37Z"}
{"repo": "duckdb/duckdb", "pull_number": 16693, "instance_id": "duckdb__duckdb-16693", "issue_numbers": ["16554", "16554"], "base_commit": "b5375825e66b71dfd352f070d7c496201c79dae4", "patch": "diff --git a/tools/shell/shell.cpp b/tools/shell/shell.cpp\nindex 60aa2368105e..3a3cdff9fd5e 100644\n--- a/tools/shell/shell.cpp\n+++ b/tools/shell/shell.cpp\n@@ -1739,11 +1739,7 @@ void ShellState::ExecutePreparedStatement(sqlite3_stmt *pStmt) {\n \t\t/* extract the data and data types */\n \t\tfor (int i = 0; i < nCol; i++) {\n \t\t\tresult.types[i] = sqlite3_column_type(pStmt, i);\n-\t\t\tif (result.types[i] == SQLITE_BLOB && cMode == RenderMode::INSERT) {\n-\t\t\t\tresult.data[i] = \"\";\n-\t\t\t} else {\n-\t\t\t\tresult.data[i] = (const char *)sqlite3_column_text(pStmt, i);\n-\t\t\t}\n+\t\t\tresult.data[i] = (const char *)sqlite3_column_text(pStmt, i);\n \t\t\tif (!result.data[i] && result.types[i] != SQLITE_NULL) {\n \t\t\t\t// OOM\n \t\t\t\trc = SQLITE_NOMEM;\n", "test_patch": "diff --git a/tools/shell/tests/test_shell_basics.py b/tools/shell/tests/test_shell_basics.py\nindex e2c554bb5a2d..1523ac2ccef2 100644\n--- a/tools/shell/tests/test_shell_basics.py\n+++ b/tools/shell/tests/test_shell_basics.py\n@@ -834,6 +834,17 @@ def test_dump_mixed(shell):\n     result = test.run()\n     result.check_stdout('CREATE TABLE a(d DATE, k FLOAT, t TIMESTAMP);')\n \n+def test_dump_blobs(shell):\n+    test = (\n+        ShellTest(shell)\n+        .statement(\"create table test(t VARCHAR, b BLOB);\")\n+        .statement(\".changes off\")\n+        .statement(\"insert into test values('literal blob', '\\\\x07\\\\x08\\\\x09');\")\n+        .statement(\".dump\")\n+    )\n+    result = test.run()\n+    result.check_stdout(\"'\\\\x07\\\\x08\\\\x09'\")\n+\n def test_invalid_csv(shell, tmp_path):\n     file = tmp_path / 'nonsencsv.csv'\n     with open(file, 'wb+') as f:\n@@ -869,18 +880,6 @@ def test_mode_trash(shell):\n     result = test.run()\n     result.check_stdout('')\n \n-@pytest.mark.skip(reason=\"Broken test, ported directly, was commented out\")\n-def test_dump_blobs(shell):\n-    test = (\n-        ShellTest(shell)\n-        .statement(\"CREATE TABLE a (b BLOB);\")\n-        .statement(\".changes off\")\n-        .statement(\"INSERT INTO a VALUES (DATE '1992-01-01', 0.3, NOW());\")\n-        .statement(\".dump\")\n-    )\n-    result = test.run()\n-    result.check_stdout('COMMIT')\n-\n def test_sqlite_comments(shell):\n     # Using /* <comment> */\n     test = (\n", "problem_statement": "[CLI] Empty strings for BLOB values in .mode insert / .dump\n### What happens?\n\nFor tables (or queries) with BLOB columns, `.dump` (or `.mode insert`) only produce empty strings instead of some kind \"literal BLOB value\".\n\nIn duckdb-cli 1.2.0 and 1.2.1.  \nAlso checked with 1.1.3, there the BLOBs are emitted as sqlite style BLOB literal ( `X'01F32B'` ) which is just wrong (as it is somewhat strangly interpreded as string with a prefixed X `'x01F32B'` - parser glitch ?)\n\nIt would make sense to emit these as eg `'\\x01\\xF3\\x2B'::BLOB`.\n\n### To Reproduce\n\n#### code\n```\ncreate table test(t VARCHAR, b BLOB);\ninsert into test values('literal blob', '\\x07\\x08\\x09');\ninsert into test values('text-as-blob', 'ABC'::BLOB);\ninsert into test values('unhex', unhex('040506'));\n\nselect * from test;\n\n.mode insert TEST\nselect * from test;\n\n.dump\n```\n\n#### results on 1.2.0/1.2.1 / BLOBs missing\n```\n-- select * from test;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      t       \u2502      b       \u2502\n\u2502   varchar    \u2502     blob     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 literal blob \u2502 \\x07\\x08\\x09 \u2502\n\u2502 text-as-blob \u2502 ABC          \u2502\n\u2502 unhex        \u2502 \\x04\\x05\\x06 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- .mode insert TEST\n-- select * from test;\nINSERT INTO TEST(t,b) VALUES('literal blob','');\nINSERT INTO TEST(t,b) VALUES('text-as-blob','');\nINSERT INTO TEST(t,b) VALUES('unhex','');\n\n-- .dump\nBEGIN TRANSACTION;\nCREATE TABLE test(t VARCHAR, b BLOB);;\nINSERT INTO test VALUES('literal blob','');\nINSERT INTO test VALUES('text-as-blob','');\nINSERT INTO test VALUES('unhex','');\nCOMMIT;\n```\n\n#### results on 1.1.3 / BLOBs as invalid (sqlite-style) literals\n```\n-- select * from test;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      t       \u2502      b       \u2502\n\u2502   varchar    \u2502     blob     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 literal blob \u2502 \\x07\\x08\\x09 \u2502\n\u2502 text-as-blob \u2502 ABC          \u2502\n\u2502 unhex        \u2502 \\x04\\x05\\x06 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- .mode insert TEST\n-- select * from test;\nINSERT INTO TEST(t,b) VALUES('literal blob',X'070809');\nINSERT INTO TEST(t,b) VALUES('text-as-blob',X'414243');\nINSERT INTO TEST(t,b) VALUES('unhex',X'040506');\n\n-- .dump\nPRAGMA foreign_keys=OFF;\nBEGIN TRANSACTION;\nCREATE TABLE test(t VARCHAR, b BLOB);;\nINSERT INTO test VALUES('literal blob',X'070809');\nINSERT INTO test VALUES('text-as-blob',X'414243');\nINSERT INTO test VALUES('unhex',X'040506');\nCOMMIT;\n```\n\n### OS:\n\nLinux (Ubuntu 24.04), x86_x64\n\n### DuckDB Version:\n\n1.2.1\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nMarc Gerber\n\n### Affiliation:\n\nprivate\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [ ] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n[CLI] Empty strings for BLOB values in .mode insert / .dump\n### What happens?\n\nFor tables (or queries) with BLOB columns, `.dump` (or `.mode insert`) only produce empty strings instead of some kind \"literal BLOB value\".\n\nIn duckdb-cli 1.2.0 and 1.2.1.  \nAlso checked with 1.1.3, there the BLOBs are emitted as sqlite style BLOB literal ( `X'01F32B'` ) which is just wrong (as it is somewhat strangly interpreded as string with a prefixed X `'x01F32B'` - parser glitch ?)\n\nIt would make sense to emit these as eg `'\\x01\\xF3\\x2B'::BLOB`.\n\n### To Reproduce\n\n#### code\n```\ncreate table test(t VARCHAR, b BLOB);\ninsert into test values('literal blob', '\\x07\\x08\\x09');\ninsert into test values('text-as-blob', 'ABC'::BLOB);\ninsert into test values('unhex', unhex('040506'));\n\nselect * from test;\n\n.mode insert TEST\nselect * from test;\n\n.dump\n```\n\n#### results on 1.2.0/1.2.1 / BLOBs missing\n```\n-- select * from test;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      t       \u2502      b       \u2502\n\u2502   varchar    \u2502     blob     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 literal blob \u2502 \\x07\\x08\\x09 \u2502\n\u2502 text-as-blob \u2502 ABC          \u2502\n\u2502 unhex        \u2502 \\x04\\x05\\x06 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- .mode insert TEST\n-- select * from test;\nINSERT INTO TEST(t,b) VALUES('literal blob','');\nINSERT INTO TEST(t,b) VALUES('text-as-blob','');\nINSERT INTO TEST(t,b) VALUES('unhex','');\n\n-- .dump\nBEGIN TRANSACTION;\nCREATE TABLE test(t VARCHAR, b BLOB);;\nINSERT INTO test VALUES('literal blob','');\nINSERT INTO test VALUES('text-as-blob','');\nINSERT INTO test VALUES('unhex','');\nCOMMIT;\n```\n\n#### results on 1.1.3 / BLOBs as invalid (sqlite-style) literals\n```\n-- select * from test;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      t       \u2502      b       \u2502\n\u2502   varchar    \u2502     blob     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 literal blob \u2502 \\x07\\x08\\x09 \u2502\n\u2502 text-as-blob \u2502 ABC          \u2502\n\u2502 unhex        \u2502 \\x04\\x05\\x06 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- .mode insert TEST\n-- select * from test;\nINSERT INTO TEST(t,b) VALUES('literal blob',X'070809');\nINSERT INTO TEST(t,b) VALUES('text-as-blob',X'414243');\nINSERT INTO TEST(t,b) VALUES('unhex',X'040506');\n\n-- .dump\nPRAGMA foreign_keys=OFF;\nBEGIN TRANSACTION;\nCREATE TABLE test(t VARCHAR, b BLOB);;\nINSERT INTO test VALUES('literal blob',X'070809');\nINSERT INTO test VALUES('text-as-blob',X'414243');\nINSERT INTO test VALUES('unhex',X'040506');\nCOMMIT;\n```\n\n### OS:\n\nLinux (Ubuntu 24.04), x86_x64\n\n### DuckDB Version:\n\n1.2.1\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nMarc Gerber\n\n### Affiliation:\n\nprivate\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [ ] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "\n", "created_at": "2025-03-17T13:50:32Z"}
{"repo": "duckdb/duckdb", "pull_number": 16691, "instance_id": "duckdb__duckdb-16691", "issue_numbers": ["16627", "16627"], "base_commit": "8758084398b63837a9a6cbdc418a3ec6ab9e033f", "patch": "diff --git a/src/storage/statistics/numeric_stats.cpp b/src/storage/statistics/numeric_stats.cpp\nindex a9379812292e..4283ea78988e 100644\n--- a/src/storage/statistics/numeric_stats.cpp\n+++ b/src/storage/statistics/numeric_stats.cpp\n@@ -147,6 +147,7 @@ FilterPropagateResult CheckZonemapTemplated(const BaseStatistics &stats, Express\n                                             T max_value, T constant) {\n \tswitch (comparison_type) {\n \tcase ExpressionType::COMPARE_EQUAL:\n+\tcase ExpressionType::COMPARE_NOT_DISTINCT_FROM:\n \t\tif (ConstantExactRange(min_value, max_value, constant)) {\n \t\t\treturn FilterPropagateResult::FILTER_ALWAYS_TRUE;\n \t\t}\n@@ -155,6 +156,7 @@ FilterPropagateResult CheckZonemapTemplated(const BaseStatistics &stats, Express\n \t\t}\n \t\treturn FilterPropagateResult::FILTER_ALWAYS_FALSE;\n \tcase ExpressionType::COMPARE_NOTEQUAL:\n+\tcase ExpressionType::COMPARE_DISTINCT_FROM:\n \t\tif (!ConstantValueInRange(min_value, max_value, constant)) {\n \t\t\treturn FilterPropagateResult::FILTER_ALWAYS_TRUE;\n \t\t} else if (ConstantExactRange(min_value, max_value, constant)) {\ndiff --git a/src/storage/statistics/string_stats.cpp b/src/storage/statistics/string_stats.cpp\nindex 691bae090520..ae6a1e5fe57e 100644\n--- a/src/storage/statistics/string_stats.cpp\n+++ b/src/storage/statistics/string_stats.cpp\n@@ -210,12 +210,14 @@ FilterPropagateResult StringStats::CheckZonemap(const_data_ptr_t min_data, idx_t\n \tint max_comp = StringValueComparison(data, MinValue(max_len, size), max_data);\n \tswitch (comparison_type) {\n \tcase ExpressionType::COMPARE_EQUAL:\n+\tcase ExpressionType::COMPARE_NOT_DISTINCT_FROM:\n \t\tif (min_comp >= 0 && max_comp <= 0) {\n \t\t\treturn FilterPropagateResult::NO_PRUNING_POSSIBLE;\n \t\t} else {\n \t\t\treturn FilterPropagateResult::FILTER_ALWAYS_FALSE;\n \t\t}\n \tcase ExpressionType::COMPARE_NOTEQUAL:\n+\tcase ExpressionType::COMPARE_DISTINCT_FROM:\n \t\tif (min_comp < 0 || max_comp > 0) {\n \t\t\treturn FilterPropagateResult::FILTER_ALWAYS_TRUE;\n \t\t}\n", "test_patch": "diff --git a/test/optimizer/pushdown/distinct_from_pushdown.test b/test/optimizer/pushdown/distinct_from_pushdown.test\nnew file mode 100644\nindex 000000000000..fa50f3094948\n--- /dev/null\n+++ b/test/optimizer/pushdown/distinct_from_pushdown.test\n@@ -0,0 +1,27 @@\n+# name: test/optimizer/pushdown/distinct_from_pushdown.test\n+# description: Test DISTINCT FROM pushed down into scans\n+# group: [pushdown]\n+\n+statement ok\n+create table test as select 'tst' as tst;\n+\n+query I\n+select * from test where tst is not distinct from 'a' or tst is not distinct from 'b';\n+----\n+\n+query I\n+select * from test where tst is distinct from 'a' or tst is distinct from 'b';\n+----\n+tst\n+\n+statement ok\n+create table test2 as select 42 as tst;\n+\n+query I\n+select * from test2 where tst is not distinct from 12 or tst is not distinct from 13;\n+----\n+\n+query I\n+select * from test2 where tst is distinct from 12 or tst is distinct from 13\n+----\n+42\n", "problem_statement": "Internal error, Expression type not implemented for string statistics zone map\n### What happens?\n\nDuckDB internal error happens when \"is not distinct from\" is combined with or. This seems to be a regression in 1.2, still present in 1.2.1.  Error does not happen in 1.1.3.\n\nCan be reproduced in cli, or in client APIs, or in shell.duckdb.org.\n\nOutput from cli:\n\n```text\nv1.2.1 8e52ec4395\nEnter \".help\" for usage hints.\nConnected to a transient in-memory database.\nUse \".open FILENAME\" to reopen on a persistent database.\n```\n```sql\ncreate table test as select 'tst' as tst;\nselect * from test where tst is not distinct from 'a' or tst is not distinct from 'b';\n```\n```console\nINTERNAL Error:\nExpression type not implemented for string statistics zone map\nThis error signals an assertion failure within DuckDB. This usually occurs due to unexpected conditions or errors in the program's logic.\nFor more information, see https://duckdb.org/docs/dev/internal_errors\n```\n\n### To Reproduce\n\n```\ncreate table test as select 'tst' as tst; \nselect * from test where tst is not distinct from 'a' or tst is not distinct from 'b';\n```\n\n### OS:\n\nWin10 x86_64\n\n### DuckDB Version:\n\n1.2.1 and v1.3.0-dev1204\n\n### DuckDB Client:\n\nall\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nHeikki Innanen\n\n### Affiliation:\n\nMetabees Oy\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release (1.2.1) and v1.3.0-dev1204\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nInternal error, Expression type not implemented for string statistics zone map\n### What happens?\n\nDuckDB internal error happens when \"is not distinct from\" is combined with or. This seems to be a regression in 1.2, still present in 1.2.1.  Error does not happen in 1.1.3.\n\nCan be reproduced in cli, or in client APIs, or in shell.duckdb.org.\n\nOutput from cli:\n\n```text\nv1.2.1 8e52ec4395\nEnter \".help\" for usage hints.\nConnected to a transient in-memory database.\nUse \".open FILENAME\" to reopen on a persistent database.\n```\n```sql\ncreate table test as select 'tst' as tst;\nselect * from test where tst is not distinct from 'a' or tst is not distinct from 'b';\n```\n```console\nINTERNAL Error:\nExpression type not implemented for string statistics zone map\nThis error signals an assertion failure within DuckDB. This usually occurs due to unexpected conditions or errors in the program's logic.\nFor more information, see https://duckdb.org/docs/dev/internal_errors\n```\n\n### To Reproduce\n\n```\ncreate table test as select 'tst' as tst; \nselect * from test where tst is not distinct from 'a' or tst is not distinct from 'b';\n```\n\n### OS:\n\nWin10 x86_64\n\n### DuckDB Version:\n\n1.2.1 and v1.3.0-dev1204\n\n### DuckDB Client:\n\nall\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nHeikki Innanen\n\n### Affiliation:\n\nMetabees Oy\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release (1.2.1) and v1.3.0-dev1204\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "\n", "created_at": "2025-03-17T13:25:21Z"}
{"repo": "duckdb/duckdb", "pull_number": 16687, "instance_id": "duckdb__duckdb-16687", "issue_numbers": ["16551"], "base_commit": "005bdde63c008ab518b0030b35cc29986d1d6827", "patch": "diff --git a/.github/actions/build_extensions/action.yml b/.github/actions/build_extensions/action.yml\nindex db05fd4c9dfb..4b581851954b 100644\n--- a/.github/actions/build_extensions/action.yml\n+++ b/.github/actions/build_extensions/action.yml\n@@ -11,7 +11,7 @@ inputs:\n \n   # Deploy config\n   deploy_as:\n-    description: 'Binary architecture name for deploy step'\n+    description: 'Binary architecture name for deploy step - DEPRECATED'\n     default: ''\n   deploy_version:\n     description: 'Version tag or commit short hash for deploy step'\n@@ -217,35 +217,5 @@ runs:\n     - name: Deploy\n       if: ${{ inputs.deploy_as != '' }}\n       shell: bash\n-      env:\n-        AWS_ACCESS_KEY_ID: ${{ inputs.s3_id }}\n-        AWS_SECRET_ACCESS_KEY: ${{ inputs.s3_key }}\n-        DUCKDB_EXTENSION_SIGNING_PK: ${{ inputs.signing_pk }}\n-        AWS_DEFAULT_REGION: us-east-1\n-        DUCKDB_DEPLOY_SCRIPT_MODE: for_real\n       run: |\n-        cd  ${{ inputs.build_dir}}\n-        if [[ \"$GITHUB_REPOSITORY\" = \"duckdb/duckdb\" ]] ; then\n-          if [[ ! -z \"${{ inputs.deploy_version }}\" ]] ; then\n-            ./scripts/extension-upload-all.sh ${{ inputs.deploy_as }} ${{ inputs.deploy_version }}\n-          elif [[ \"$GITHUB_REF\" =~ ^(refs/tags/v.+)$ ]] ; then\n-            ./scripts/extension-upload-all.sh ${{ inputs.deploy_as }} ${{ github.ref_name }}\n-          elif [[ \"$GITHUB_REF\" =~ ^(refs/heads/main)$ ]] ; then\n-            ./scripts/extension-upload-all.sh ${{ inputs.deploy_as }} `git log -1 --format=%h`\n-          fi\n-        fi\n-\n-    # Run the unittests (excluding the out-of-tree tests) with the extensions that we deployed to S3\n-    - name: Test deployed extensions\n-      if: ${{ inputs.deploy_as != '' && inputs.run_tests == 1 }}\n-      shell: bash\n-      env:\n-        AWS_ACCESS_KEY_ID: ${{ inputs.s3_id }}\n-        AWS_SECRET_ACCESS_KEY: ${{ inputs.s3_key }}\n-        AWS_DEFAULT_REGION: us-east-1\n-      run: |\n-        rm -rf ~/.duckdb\n-        cd  ${{ inputs.build_dir}}\n-        if [[ \"$GITHUB_REF\" =~ ^(refs/heads/main|refs/tags/v.+)$ && \"$GITHUB_REPOSITORY\" = \"duckdb/duckdb\" ]] ; then\n-          ./scripts/extension-upload-test.sh\n-        fi\n+        exit 1\ndiff --git a/.github/actions/build_extensions_dockerized/action.yml b/.github/actions/build_extensions_dockerized/action.yml\nindex 651c0b6d72b1..0e0eb7fd54e4 100644\n--- a/.github/actions/build_extensions_dockerized/action.yml\n+++ b/.github/actions/build_extensions_dockerized/action.yml\n@@ -11,6 +11,9 @@ inputs:\n   vcpkg_target_triplet:\n     description: 'Target triplet for installing vcpkg dependencies'\n     default: ''\n+  override_git_describe:\n+    description: 'Override git describe'\n+    default: ''\n \n runs:\n   using: \"composite\"\n@@ -56,7 +59,7 @@ runs:\n           echo \"OPENSSL_DIR=/duckdb_build_dir/build/release/vcpkg_installed/${{ inputs.vcpkg_target_triplet }}\" >> docker_env.txt\n           echo \"OPENSSL_USE_STATIC_LIBS=true\" >> docker_env.txt\n           echo \"DUCKDB_PLATFORM=${{ inputs.duckdb_arch }}\" >> docker_env.txt\n-          echo \"DUCKDB_GIT_VERSION=${{ inputs.override_git_describe }}\" >> docker_env.txt\n+          echo \"OVERRIDE_GIT_DESCRIBE=${{ inputs.override_git_describe }}\" >> docker_env.txt\n           echo \"LINUX_CI_IN_DOCKER=1\" >> docker_env.txt\n           echo \"TOOLCHAIN_FLAGS=${{ inputs.duckdb_arch == 'linux_arm64' && '-DCMAKE_C_COMPILER=aarch64-linux-gnu-gcc -DCMAKE_CXX_COMPILER=aarch64-linux-gnu-g++ -DCMAKE_Fortran_COMPILER=aarch64-linux-gnu-gfortran' || '' }}\" >> docker_env.txt\n           echo \"CC=${{ inputs.duckdb_arch == 'linux_arm64' && 'aarch64-linux-gnu-gcc' || '' }}\" >> docker_env.txt\ndiff --git a/.github/config/out_of_tree_extensions.cmake b/.github/config/out_of_tree_extensions.cmake\nindex 0fb1762f3fa0..3f1a426101de 100644\n--- a/.github/config/out_of_tree_extensions.cmake\n+++ b/.github/config/out_of_tree_extensions.cmake\n@@ -111,7 +111,7 @@ if (NOT MINGW)\n duckdb_extension_load(spatial\n     DONT_LINK LOAD_TESTS\n     GIT_URL https://github.com/duckdb/duckdb-spatial\n-    GIT_TAG 919c69fe47443b4eafbd883e2fcac0b2ec448725\n+    GIT_TAG 2905968a85703e5ca3698976daafd759554e1744\n     INCLUDE_DIR spatial/include\n     TEST_DIR test/sql\n     APPLY_PATCHES\ndiff --git a/.github/workflows/InvokeCI.yml b/.github/workflows/InvokeCI.yml\nindex 8bbba55f2677..dd22bee5f529 100644\n--- a/.github/workflows/InvokeCI.yml\n+++ b/.github/workflows/InvokeCI.yml\n@@ -26,6 +26,7 @@ jobs:\n       override_git_describe: ${{ inputs.override_git_describe }}\n       git_ref: ${{ inputs.git_ref }}\n       skip_tests: ${{ inputs.skip_tests }}\n+      run_all: ${{ inputs.run_all }}\n \n   linux-release:\n     uses: ./.github/workflows/LinuxRelease.yml\n@@ -42,6 +43,7 @@ jobs:\n       override_git_describe: ${{ inputs.override_git_describe }}\n       git_ref: ${{ inputs.git_ref }}\n       skip_tests: ${{ inputs.skip_tests }}\n+      run_all: ${{ inputs.run_all }}\n \n   python:\n     uses: ./.github/workflows/Python.yml\ndiff --git a/.github/workflows/LinuxRelease.yml b/.github/workflows/LinuxRelease.yml\nindex 15d0cfd1970b..b11dbe916d0d 100644\n--- a/.github/workflows/LinuxRelease.yml\n+++ b/.github/workflows/LinuxRelease.yml\n@@ -150,6 +150,7 @@ jobs:\n           vcpkg_target_triplet: ${{ matrix.vcpkg_triplet }}\n           duckdb_arch: ${{ matrix.duckdb_arch }}\n           run_tests: ${{ inputs.skip_tests != 'true' }}\n+          override_git_describe: ${{ inputs.override_git_describe }}\n \n       - uses: actions/upload-artifact@v4\n         with:\n@@ -192,6 +193,7 @@ jobs:\n           vcpkg_target_triplet: ${{ matrix.vcpkg_triplet }}\n           duckdb_arch: ${{ matrix.duckdb_arch }}\n           run_tests: ${{ inputs.skip_tests != 'true' }}\n+          override_git_describe: ${{ inputs.override_git_describe }}\n \n       - uses: actions/upload-artifact@v4\n         with:\n@@ -233,6 +235,7 @@ jobs:\n           vcpkg_target_triplet: ${{ matrix.vcpkg_triplet }}\n           duckdb_arch: ${{ matrix.duckdb_arch }}\n           run_tests: ${{ inputs.skip_tests != 'true' }}\n+          override_git_describe: ${{ inputs.override_git_describe }}\n \n       - uses: actions/upload-artifact@v4\n         with:\ndiff --git a/.github/workflows/OSX.yml b/.github/workflows/OSX.yml\nindex 498d9c04f049..6d2dc09a7ee5 100644\n--- a/.github/workflows/OSX.yml\n+++ b/.github/workflows/OSX.yml\n@@ -8,6 +8,8 @@ on:\n         type: string\n       skip_tests:\n         type: string\n+      run_all:\n+        type: string\n   workflow_dispatch:\n     inputs:\n       override_git_describe:\n@@ -16,6 +18,9 @@ on:\n         type: string\n       skip_tests:\n         type: string\n+      run_all:\n+        type: string\n+  repository_dispatch:\n   push:\n     branches-ignore:\n       - 'main'\n@@ -311,12 +316,11 @@ jobs:\n         python-version: '3.12'\n \n     - name: Execute test\n+      if: (( inputs.skip_tests != 'true' )) && (( startsWith(github.ref, 'refs/tags/v') || github.ref == 'refs/heads/main' || inputs.run_all == 'true' )) && (( github.repository == 'duckdb/duckdb' ))\n       shell: bash\n       env:\n           AWS_ACCESS_KEY_ID: ${{secrets.S3_ID}}\n           AWS_SECRET_ACCESS_KEY: ${{secrets.S3_KEY}}\n           AWS_DEFAULT_REGION: us-east-1\n       run: |\n-          if [[ \"$GITHUB_REF\" =~ ^(refs/heads/main|refs/tags/v.+)$ && \"$GITHUB_REPOSITORY\" = \"duckdb/duckdb\" ]] ; then\n-            ./scripts/extension-upload-test.sh\n-          fi\n+          ./scripts/extension-upload-test.sh\ndiff --git a/.github/workflows/Python.yml b/.github/workflows/Python.yml\nindex b3608dc25498..05eaacd082c6 100644\n--- a/.github/workflows/Python.yml\n+++ b/.github/workflows/Python.yml\n@@ -150,6 +150,7 @@ jobs:\n           vcpkg_target_triplet: x64-linux\n           duckdb_arch: linux_amd64_gcc4\n           run_tests: ${{ inputs.skip_tests != 'true' }}\n+          override_git_describe: ${{ inputs.override_git_describe }}\n \n       - uses: actions/upload-artifact@v4\n         with:\n@@ -158,7 +159,6 @@ jobs:\n             build/release/extension/*/*.duckdb_extension\n \n   upload-linux-extensions-gcc4:\n-    ## TODO: Add a if: github.ref == main, for now this is explicitly missing to be able to test on PR, expected is this should fail due to missing secrets\n     name: Upload Linux Extensions (gcc4)\n     needs: manylinux-extensions-x64\n     strategy:\ndiff --git a/.github/workflows/Windows.yml b/.github/workflows/Windows.yml\nindex 7d71dedafa03..3584c880f90a 100644\n--- a/.github/workflows/Windows.yml\n+++ b/.github/workflows/Windows.yml\n@@ -8,6 +8,8 @@ on:\n         type: string\n       skip_tests:\n         type: string\n+      run_all:\n+        type: string\n   workflow_dispatch:\n     inputs:\n       override_git_describe:\n@@ -16,6 +18,9 @@ on:\n         type: string\n       skip_tests:\n         type: string\n+      run_all:\n+        type: string\n+  repository_dispatch:\n   push:\n     branches-ignore:\n       - 'main'\n@@ -144,7 +149,7 @@ jobs:\n \n  win-release-32:\n     name: Windows (32 Bit)\n-    if: github.ref == 'refs/heads/main' || github.repository != 'duckdb/duckdb'\n+    if: github.ref == 'refs/heads/main' || github.repository != 'duckdb/duckdb' || inputs.run_all == 'true'\n     runs-on: windows-2019\n     needs: win-release-64\n \n@@ -184,7 +189,7 @@ jobs:\n \n  win-release-arm64:\n    name: Windows (ARM64)\n-   if: github.ref == 'refs/heads/main' || github.repository != 'duckdb/duckdb'\n+   if: github.ref == 'refs/heads/main' || github.repository != 'duckdb/duckdb' || inputs.run_all == 'true'\n    runs-on: windows-2019\n    needs: win-release-64\n \ndiff --git a/benchmark/benchmark_runner.cpp b/benchmark/benchmark_runner.cpp\nindex 7ba981285517..d30b3e5a4a93 100644\n--- a/benchmark/benchmark_runner.cpp\n+++ b/benchmark/benchmark_runner.cpp\n@@ -123,6 +123,7 @@ void BenchmarkRunner::RunBenchmark(Benchmark *benchmark) {\n \tduckdb::unique_ptr<BenchmarkState> state;\n \ttry {\n \t\tstate = benchmark->Initialize(configuration);\n+\t\tbenchmark->Assert(state.get());\n \t} catch (std::exception &ex) {\n \t\tLog(StringUtil::Format(\"%s\\t1\\t\", benchmark->name));\n \t\tLogResult(\"ERROR\");\ndiff --git a/benchmark/include/benchmark.hpp b/benchmark/include/benchmark.hpp\nindex ece2dda3d3de..1fe4b7df79f6 100644\n--- a/benchmark/include/benchmark.hpp\n+++ b/benchmark/include/benchmark.hpp\n@@ -43,6 +43,8 @@ class Benchmark {\n \tvirtual duckdb::unique_ptr<BenchmarkState> Initialize(BenchmarkConfiguration &config) {\n \t\treturn nullptr;\n \t}\n+\t//! Assert correctness after load, before run\n+\tvirtual void Assert(BenchmarkState *state) {};\n \t//! Run the benchmark\n \tvirtual void Run(BenchmarkState *state) = 0;\n \t//! Cleanup the benchmark, called after each Run\ndiff --git a/benchmark/include/interpreted_benchmark.hpp b/benchmark/include/interpreted_benchmark.hpp\nindex ecb8a47b833e..9cd4c19db80d 100644\n--- a/benchmark/include/interpreted_benchmark.hpp\n+++ b/benchmark/include/interpreted_benchmark.hpp\n@@ -19,6 +19,17 @@ struct InterpretedBenchmarkState;\n \n const string DEFAULT_DB_PATH = \"duckdb_benchmark_db.db\";\n \n+struct BenchmarkQuery {\n+public:\n+\tBenchmarkQuery() {\n+\t}\n+\n+public:\n+\tstring query;\n+\tidx_t column_count = 0;\n+\tvector<vector<string>> expected_result;\n+};\n+\n //! Interpreted benchmarks read the benchmark from a file\n class InterpretedBenchmark : public Benchmark {\n public:\n@@ -27,6 +38,8 @@ class InterpretedBenchmark : public Benchmark {\n \tvoid LoadBenchmark();\n \t//! Initialize the benchmark state\n \tduckdb::unique_ptr<BenchmarkState> Initialize(BenchmarkConfiguration &config) override;\n+\t//! Assert correct/expected state of the db, before Run\n+\tvoid Assert(BenchmarkState *state) override;\n \t//! Run the benchmark\n \tvoid Run(BenchmarkState *state) override;\n \t//! Cleanup the benchmark, called after each Run\n@@ -63,10 +76,10 @@ class InterpretedBenchmark : public Benchmark {\n \t}\n \n private:\n-\tstring VerifyInternal(BenchmarkState *state_p, MaterializedQueryResult &result);\n+\tstring VerifyInternal(BenchmarkState *state_p, const BenchmarkQuery &query, MaterializedQueryResult &result);\n \n-\tvoid ReadResultFromFile(BenchmarkFileReader &reader, const string &file);\n-\tvoid ReadResultFromReader(BenchmarkFileReader &reader, const string &file);\n+\tBenchmarkQuery ReadQueryFromFile(BenchmarkFileReader &reader, const string &file);\n+\tBenchmarkQuery ReadQueryFromReader(BenchmarkFileReader &reader, const string &sql, const string &header);\n \n \tunique_ptr<QueryResult> RunLoadQuery(InterpretedBenchmarkState &state, const string &load_query);\n \n@@ -84,9 +97,10 @@ class InterpretedBenchmark : public Benchmark {\n \t// can be used to test accessing data from a different db in a non-persistent connection\n \tbool cache_no_connect = false;\n \tstd::unordered_set<string> extensions;\n-\tint64_t result_column_count = 0;\n-\tvector<vector<string>> result_values;\n-\tstring result_query;\n+\n+\t//! Queries used to assert a given state of the data\n+\tvector<BenchmarkQuery> assert_queries;\n+\tvector<BenchmarkQuery> result_queries;\n \t//! How many times to retry the load, if any\n \tidx_t retry_load = 0;\n \n@@ -95,6 +109,7 @@ class InterpretedBenchmark : public Benchmark {\n \tstring subgroup;\n \n \tbool in_memory = true;\n+\tstring storage_version;\n \tQueryResultType result_type = QueryResultType::MATERIALIZED_RESULT;\n \tidx_t arrow_batch_size = STANDARD_VECTOR_SIZE;\n \tbool require_reinit = false;\ndiff --git a/benchmark/interpreted_benchmark.cpp b/benchmark/interpreted_benchmark.cpp\nindex 7225100b7da6..e91d65dabcda 100644\n--- a/benchmark/interpreted_benchmark.cpp\n+++ b/benchmark/interpreted_benchmark.cpp\n@@ -43,16 +43,19 @@ struct InterpretedBenchmarkState : public BenchmarkState {\n \tConnection con;\n \tduckdb::unique_ptr<MaterializedQueryResult> result;\n \n-\texplicit InterpretedBenchmarkState(string path)\n-\t    : benchmark_config(GetBenchmarkConfig()), db(path.empty() ? nullptr : path.c_str(), benchmark_config.get()),\n-\t      con(db) {\n+\texplicit InterpretedBenchmarkState(string path, const string &version)\n+\t    : benchmark_config(GetBenchmarkConfig(version)),\n+\t      db(path.empty() ? nullptr : path.c_str(), benchmark_config.get()), con(db) {\n \t\tauto &instance = BenchmarkRunner::GetInstance();\n \t\tauto res = con.Query(\"PRAGMA threads=\" + to_string(instance.threads));\n \t\tD_ASSERT(!res->HasError());\n \t}\n \n-\tduckdb::unique_ptr<DBConfig> GetBenchmarkConfig() {\n+\tduckdb::unique_ptr<DBConfig> GetBenchmarkConfig(const string &version = \"\") {\n \t\tauto result = make_uniq<DBConfig>();\n+\t\tif (!version.empty()) {\n+\t\t\tresult->options.serialization_compatibility = SerializationCompatibility::FromString(version);\n+\t\t}\n \t\tresult->options.load_extensions = false;\n \t\treturn result;\n \t}\n@@ -96,24 +99,31 @@ InterpretedBenchmark::InterpretedBenchmark(string full_path)\n \treplacement_mapping[\"BENCHMARK_DIR\"] = BenchmarkRunner::DUCKDB_BENCHMARK_DIRECTORY;\n }\n \n-void InterpretedBenchmark::ReadResultFromFile(BenchmarkFileReader &reader, const string &file) {\n+BenchmarkQuery InterpretedBenchmark::ReadQueryFromFile(BenchmarkFileReader &reader, const string &file) {\n \t// read the results from the file\n+\tBenchmarkQuery query;\n+\tquery.query = \"\";\n+\n \tDuckDB db;\n \tConnection con(db);\n \tauto result = con.Query(\"FROM read_csv('\" + file +\n \t                        \"', delim='|', header=1, nullstr='NULL', all_varchar=1, quote ='\\\"', escape ='\\\"')\");\n-\tresult_column_count = result->ColumnCount();\n+\tquery.column_count = result->ColumnCount();\n \tfor (auto &row : *result) {\n \t\tvector<string> row_values;\n \t\tfor (idx_t col_idx = 0; col_idx < result->ColumnCount(); col_idx++) {\n \t\t\trow_values.push_back(row.GetValue<string>(col_idx));\n \t\t}\n-\t\tresult_values.push_back(std::move(row_values));\n+\t\tquery.expected_result.push_back(std::move(row_values));\n \t}\n+\treturn query;\n }\n \n-void InterpretedBenchmark::ReadResultFromReader(BenchmarkFileReader &reader, const string &header) {\n-\tresult_column_count = header.size();\n+BenchmarkQuery InterpretedBenchmark::ReadQueryFromReader(BenchmarkFileReader &reader, const string &sql,\n+                                                         const string &header) {\n+\tBenchmarkQuery query;\n+\tquery.query = sql;\n+\tquery.column_count = header.size();\n \t// keep reading results until eof\n \tstring line;\n \twhile (reader.ReadLine(line)) {\n@@ -121,12 +131,13 @@ void InterpretedBenchmark::ReadResultFromReader(BenchmarkFileReader &reader, con\n \t\t\tbreak;\n \t\t}\n \t\tauto result_splits = StringUtil::Split(line, \"\\t\");\n-\t\tif ((int64_t)result_splits.size() != result_column_count) {\n+\t\tif ((int64_t)result_splits.size() != query.column_count) {\n \t\t\tthrow std::runtime_error(reader.FormatException(\"expected \" + std::to_string(result_splits.size()) +\n-\t\t\t                                                \" values but got \" + std::to_string(result_column_count)));\n+\t\t\t                                                \" values but got \" + std::to_string(query.column_count)));\n \t\t}\n-\t\tresult_values.push_back(std::move(result_splits));\n+\t\tquery.expected_result.push_back(std::move(result_splits));\n \t}\n+\treturn query;\n }\n \n static void ThrowResultModeError(BenchmarkFileReader &reader) {\n@@ -153,6 +164,7 @@ void InterpretedBenchmark::LoadBenchmark() {\n \t\t\tif (queries.find(splits[0]) != queries.end()) {\n \t\t\t\tthrow std::runtime_error(\"Multiple calls to \" + splits[0] + \" in the same benchmark file\");\n \t\t\t}\n+\n \t\t\t// load command: keep reading until we find a blank line or EOF\n \t\t\tstring query;\n \t\t\twhile (reader.ReadLine(line)) {\n@@ -233,8 +245,8 @@ void InterpretedBenchmark::LoadBenchmark() {\n \t\t\t\tcache_db = string();\n \t\t\t}\n \t\t} else if (splits[0] == \"storage\") {\n-\t\t\tif (splits.size() != 2) {\n-\t\t\t\tthrow std::runtime_error(reader.FormatException(\"storage requires a single parameter\"));\n+\t\t\tif (splits.size() < 2) {\n+\t\t\t\tthrow std::runtime_error(reader.FormatException(\"storage requires at least one parameter\"));\n \t\t\t}\n \t\t\tif (splits[1] == \"transient\") {\n \t\t\t\tin_memory = true;\n@@ -243,6 +255,10 @@ void InterpretedBenchmark::LoadBenchmark() {\n \t\t\t} else {\n \t\t\t\tthrow std::runtime_error(reader.FormatException(\"Invalid argument for storage\"));\n \t\t\t}\n+\n+\t\t\tif (splits.size() == 3) {\n+\t\t\t\tstorage_version = splits[2];\n+\t\t\t}\n \t\t} else if (splits[0] == \"require_reinit\") {\n \t\t\tif (splits.size() != 1) {\n \t\t\t\tthrow std::runtime_error(reader.FormatException(\"require_reinit does not take any parameters\"));\n@@ -261,25 +277,13 @@ void InterpretedBenchmark::LoadBenchmark() {\n \t\t\t} else {\n \t\t\t\tsubgroup = result;\n \t\t\t}\n-\t\t} else if (splits[0] == \"result_query\") {\n-\t\t\tif (result_column_count > 0) {\n-\t\t\t\tthrow std::runtime_error(reader.FormatException(\"multiple results found\"));\n-\t\t\t}\n+\t\t} else if (splits[0] == \"assert\") {\n \t\t\t// count the amount of columns\n \t\t\tif (splits.size() <= 1 || splits[1].size() == 0) {\n \t\t\t\tthrow std::runtime_error(\n-\t\t\t\t    reader.FormatException(\"result_query must be followed by a column count (e.g. result III)\"));\n-\t\t\t}\n-\t\t\tbool is_file = false;\n-\t\t\tfor (idx_t i = 0; i < splits[1].size(); i++) {\n-\t\t\t\tif (splits[1][i] != 'i') {\n-\t\t\t\t\tis_file = true;\n-\t\t\t\t\tbreak;\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tif (is_file) {\n-\t\t\t\tReadResultFromFile(reader, splits[1]);\n+\t\t\t\t    reader.FormatException(\"assert must be followed by a column count (e.g. result III)\"));\n \t\t\t}\n+\n \t\t\t// read the actual query\n \t\t\tbool found_end = false;\n \t\t\tstring sql;\n@@ -290,23 +294,20 @@ void InterpretedBenchmark::LoadBenchmark() {\n \t\t\t\t}\n \t\t\t\tsql += \"\\n\" + line;\n \t\t\t}\n-\t\t\tresult_query = sql;\n \t\t\tif (!found_end) {\n \t\t\t\tthrow std::runtime_error(reader.FormatException(\n \t\t\t\t    \"result_query must be followed by a query and a result (separated by ----)\"));\n \t\t\t}\n-\t\t\tif (!is_file) {\n-\t\t\t\tReadResultFromReader(reader, splits[1]);\n-\t\t\t}\n-\t\t} else if (splits[0] == \"result\") {\n-\t\t\tif (result_column_count > 0) {\n+\n+\t\t\tassert_queries.push_back(ReadQueryFromReader(reader, sql, splits[1]));\n+\t\t} else if (splits[0] == \"result_query\" || splits[0] == \"result\") {\n+\t\t\tif (!result_queries.empty()) {\n \t\t\t\tthrow std::runtime_error(reader.FormatException(\"multiple results found\"));\n \t\t\t}\n \t\t\t// count the amount of columns\n \t\t\tif (splits.size() <= 1 || splits[1].size() == 0) {\n \t\t\t\tthrow std::runtime_error(\n-\t\t\t\t    reader.FormatException(\"result must be followed by a column count (e.g. result III) or a file \"\n-\t\t\t\t                           \"(e.g. result /path/to/file.csv)\"));\n+\t\t\t\t    reader.FormatException(\"result_query must be followed by a column count (e.g. result III)\"));\n \t\t\t}\n \t\t\tbool is_file = false;\n \t\t\tfor (idx_t i = 0; i < splits[1].size(); i++) {\n@@ -316,17 +317,30 @@ void InterpretedBenchmark::LoadBenchmark() {\n \t\t\t\t}\n \t\t\t}\n \t\t\tif (is_file) {\n-\t\t\t\tReadResultFromFile(reader, splits[1]);\n-\n-\t\t\t\t// read the main file until we encounter an empty line\n-\t\t\t\tstring line;\n-\t\t\t\twhile (reader.ReadLine(line)) {\n-\t\t\t\t\tif (line.empty()) {\n-\t\t\t\t\t\tbreak;\n+\t\t\t\tresult_queries.push_back(ReadQueryFromFile(reader, splits[1]));\n+\t\t\t} else {\n+\t\t\t\tstring result_query;\n+\t\t\t\tif (splits[0] == \"result_query\") {\n+\t\t\t\t\t// read the actual query\n+\t\t\t\t\tbool found_end = false;\n+\t\t\t\t\tstring sql;\n+\t\t\t\t\twhile (reader.ReadLine(line)) {\n+\t\t\t\t\t\tif (line == \"----\") {\n+\t\t\t\t\t\t\tfound_end = true;\n+\t\t\t\t\t\t\tbreak;\n+\t\t\t\t\t\t}\n+\t\t\t\t\t\tsql += \"\\n\" + line;\n \t\t\t\t\t}\n+\t\t\t\t\tif (!found_end) {\n+\t\t\t\t\t\tthrow std::runtime_error(reader.FormatException(\n+\t\t\t\t\t\t    \"result_query must be followed by a query and a result (separated by ----)\"));\n+\t\t\t\t\t}\n+\t\t\t\t\tresult_query = sql;\n+\t\t\t\t} else {\n+\t\t\t\t\t//! Read directly from the answer\n+\t\t\t\t\tresult_query = \"select * from __answer\";\n \t\t\t\t}\n-\t\t\t} else {\n-\t\t\t\tReadResultFromReader(reader, splits[1]);\n+\t\t\t\tresult_queries.push_back(ReadQueryFromReader(reader, result_query, splits[1]));\n \t\t\t}\n \t\t} else if (splits[0] == \"retry\") {\n \t\t\tif (splits.size() != 3) {\n@@ -383,12 +397,12 @@ unique_ptr<BenchmarkState> InterpretedBenchmark::Initialize(BenchmarkConfigurati\n \tduckdb::unique_ptr<InterpretedBenchmarkState> state;\n \tauto full_db_path = GetDatabasePath();\n \ttry {\n-\t\tstate = make_uniq<InterpretedBenchmarkState>(full_db_path);\n+\t\tstate = make_uniq<InterpretedBenchmarkState>(full_db_path, storage_version);\n \t} catch (Exception &e) {\n \t\t// if the connection throws an error, chances are it's a storage format error.\n \t\t// In this case delete the file and connect again.\n \t\tDeleteDatabase(full_db_path);\n-\t\tstate = make_uniq<InterpretedBenchmarkState>(full_db_path);\n+\t\tstate = make_uniq<InterpretedBenchmarkState>(full_db_path, storage_version);\n \t}\n \textensions.insert(\"core_functions\");\n \textensions.insert(\"parquet\");\n@@ -494,6 +508,22 @@ ScopedConfigSetting PrepareResultCollector(ClientConfig &config, InterpretedBenc\n \treturn ScopedConfigSetting(config);\n }\n \n+void InterpretedBenchmark::Assert(BenchmarkState *state_p) {\n+\tauto &state = (InterpretedBenchmarkState &)*state_p;\n+\n+\tfor (auto &assert_query : assert_queries) {\n+\t\tauto &query = assert_query.query;\n+\t\tauto result = state.con.Query(query);\n+\t\tif (result->HasError()) {\n+\t\t\tresult->ThrowError();\n+\t\t}\n+\t\tauto verify_result = VerifyInternal(state_p, assert_query, *result);\n+\t\tif (!verify_result.empty()) {\n+\t\t\tthrow InvalidInputException(\"Assertion query failed:\\n%s\", verify_result);\n+\t\t}\n+\t}\n+}\n+\n void InterpretedBenchmark::Run(BenchmarkState *state_p) {\n \tauto &state = (InterpretedBenchmarkState &)*state_p;\n \tauto &context = state.con.context;\n@@ -545,21 +575,25 @@ string InterpretedBenchmark::GetDatabasePath() {\n \treturn db_path;\n }\n \n-string InterpretedBenchmark::VerifyInternal(BenchmarkState *state_p, MaterializedQueryResult &result) {\n+string InterpretedBenchmark::VerifyInternal(BenchmarkState *state_p, const BenchmarkQuery &query,\n+                                            MaterializedQueryResult &result) {\n \tauto &state = (InterpretedBenchmarkState &)*state_p;\n-\t// compare the column count\n-\tif (result_column_count >= 0 && (int64_t)result.ColumnCount() != result_column_count) {\n+\n+\tauto &result_values = query.expected_result;\n+\tD_ASSERT(query.column_count >= 1);\n+\tif (query.column_count != (int64_t)result.ColumnCount()) {\n \t\treturn StringUtil::Format(\"Error in result: expected %lld columns but got %lld\\nObtained result: %s\",\n-\t\t                          (int64_t)result_column_count, (int64_t)result.ColumnCount(), result.ToString());\n+\t\t                          (int64_t)query.column_count, (int64_t)result.ColumnCount(), result.ToString());\n \t}\n+\n \t// compare row count\n-\tif (result.RowCount() != result_values.size()) {\n+\tif (result.RowCount() != query.expected_result.size()) {\n \t\treturn StringUtil::Format(\"Error in result: expected %lld rows but got %lld\\nObtained result: %s\",\n \t\t                          (int64_t)result_values.size(), (int64_t)result.RowCount(), result.ToString());\n \t}\n \t// compare values\n \tfor (int64_t r = 0; r < (int64_t)result_values.size(); r++) {\n-\t\tfor (int64_t c = 0; c < result_column_count; c++) {\n+\t\tfor (int64_t c = 0; c < query.column_count; c++) {\n \t\t\tauto value = result.GetValue(c, r);\n \t\t\tif (result_values[r][c] == \"NULL\" && value.IsNull()) {\n \t\t\t\tcontinue;\n@@ -597,47 +631,49 @@ string InterpretedBenchmark::Verify(BenchmarkState *state_p) {\n \tif (state.result->HasError()) {\n \t\treturn state.result->GetError();\n \t}\n-\tif (result_column_count == 0) {\n+\tif (result_queries.empty()) {\n \t\t// no result specified\n \t\treturn string();\n \t}\n-\tif (!result_query.empty()) {\n-\t\t// we are running a result query\n-\t\t// store the current result in a table called \"__answer\"\n-\t\tauto &collection = state.result->Collection();\n-\t\tauto &names = state.result->names;\n-\t\tauto &types = state.result->types;\n-\t\t// first create the (empty) table\n-\t\tstring create_tbl = \"CREATE OR REPLACE TEMP TABLE __answer(\";\n-\t\tfor (idx_t i = 0; i < names.size(); i++) {\n-\t\t\tif (i > 0) {\n-\t\t\t\tcreate_tbl += \", \";\n-\t\t\t}\n-\t\t\tcreate_tbl += KeywordHelper::WriteOptionallyQuoted(names[i]);\n-\t\t\tcreate_tbl += \" \";\n-\t\t\tcreate_tbl += types[i].ToString();\n-\t\t}\n-\t\tcreate_tbl += \")\";\n-\t\tauto new_result = state.con.Query(create_tbl);\n-\t\tif (new_result->HasError()) {\n-\t\t\treturn new_result->GetError();\n-\t\t}\n-\t\t// now append the result to the answer table\n-\t\tauto table_info = state.con.TableInfo(\"__answer\");\n-\t\tif (table_info == nullptr) {\n-\t\t\tthrow std::runtime_error(\"Received a nullptr when querying table info of __answer\");\n-\t\t}\n-\t\tstate.con.Append(*table_info, collection);\n+\tD_ASSERT(result_queries.size() == 1);\n+\tauto &query = result_queries[0];\n+\tif (query.query.empty()) {\n+\t\treturn string();\n+\t}\n \n-\t\t// finally run the result query and verify the result of that query\n-\t\tnew_result = state.con.Query(result_query);\n-\t\tif (new_result->HasError()) {\n-\t\t\treturn new_result->GetError();\n+\t// we are running a result query\n+\t// store the current result in a table called \"__answer\"\n+\tauto &collection = state.result->Collection();\n+\tauto &names = state.result->names;\n+\tauto &types = state.result->types;\n+\t// first create the (empty) table\n+\tstring create_tbl = \"CREATE OR REPLACE TEMP TABLE __answer(\";\n+\tfor (idx_t i = 0; i < names.size(); i++) {\n+\t\tif (i > 0) {\n+\t\t\tcreate_tbl += \", \";\n \t\t}\n-\t\treturn VerifyInternal(state_p, *new_result);\n-\t} else {\n-\t\treturn VerifyInternal(state_p, *state.result);\n+\t\tcreate_tbl += KeywordHelper::WriteOptionallyQuoted(names[i]);\n+\t\tcreate_tbl += \" \";\n+\t\tcreate_tbl += types[i].ToString();\n+\t}\n+\tcreate_tbl += \")\";\n+\tauto new_result = state.con.Query(create_tbl);\n+\tif (new_result->HasError()) {\n+\t\treturn new_result->GetError();\n+\t}\n+\t// now append the result to the answer table\n+\tauto table_info = state.con.TableInfo(\"__answer\");\n+\tif (table_info == nullptr) {\n+\t\tthrow std::runtime_error(\"Received a nullptr when querying table info of __answer\");\n+\t}\n+\tstate.con.Append(*table_info, collection);\n+\n+\t// finally run the result query and verify the result of that query\n+\tnew_result = state.con.Query(query.query);\n+\tif (new_result->HasError()) {\n+\t\treturn new_result->GetError();\n \t}\n+\treturn VerifyInternal(state_p, query, *new_result);\n }\n \n void InterpretedBenchmark::Interrupt(BenchmarkState *state_p) {\ndiff --git a/benchmark/micro/compression/roaring/roaring_array_read.benchmark b/benchmark/micro/compression/roaring/roaring_array_read.benchmark\nindex fb954f6d0025..64f9a6cc6fc4 100644\n--- a/benchmark/micro/compression/roaring/roaring_array_read.benchmark\n+++ b/benchmark/micro/compression/roaring/roaring_array_read.benchmark\n@@ -4,7 +4,7 @@\n \n name Roaring Scan Array Container\n group roaring\n-storage persistent\n+storage persistent v1.2.0\n \n load\n DROP TABLE IF EXISTS tbl;\n@@ -12,6 +12,11 @@ PRAGMA force_compression='Roaring';\n CREATE TABLE tbl AS SELECT case when i%25=0 then 1337 else null end as a FROM range(0, 250_000_000) tbl(i);\n checkpoint;\n \n+assert I\n+select DISTINCT compression from pragma_storage_info('tbl') where segment_type in ('VALIDITY')\n+----\n+Roaring\n+\n run\n select count(*) from tbl WHERE a IS NOT NULL;\n \ndiff --git a/benchmark/micro/compression/roaring/roaring_array_store.benchmark b/benchmark/micro/compression/roaring/roaring_array_store.benchmark\nindex 8d331e49cab7..dd53dd1d2ab5 100644\n--- a/benchmark/micro/compression/roaring/roaring_array_store.benchmark\n+++ b/benchmark/micro/compression/roaring/roaring_array_store.benchmark\n@@ -4,12 +4,19 @@\n \n name Roaring Write Array Container\n group roaring\n-storage persistent\n+storage persistent v1.2.0\n \n load\n+CREATE TABLE data_source AS SELECT case when i%25=0 then 1337 else null end as a FROM range(0, 250_000_000) tbl(i);\n PRAGMA force_compression='Roaring';\n SET checkpoint_threshold = '10.0 GB';\n-CREATE TABLE data_source AS SELECT case when i%25=0 then 1337 else null end as a FROM range(0, 250_000_000) tbl(i);\n+CREATE TABLE test_compression as FROM data_source;\n+checkpoint;\n+\n+assert I\n+select DISTINCT compression from pragma_storage_info('test_compression') where segment_type in ('VALIDITY')\n+----\n+Roaring\n \n run\n CREATE TABLE tbl AS FROM data_source;\ndiff --git a/benchmark/micro/compression/roaring/roaring_bitset_read.benchmark b/benchmark/micro/compression/roaring/roaring_bitset_read.benchmark\nindex 93951f911d3f..af135b0a4ff3 100644\n--- a/benchmark/micro/compression/roaring/roaring_bitset_read.benchmark\n+++ b/benchmark/micro/compression/roaring/roaring_bitset_read.benchmark\n@@ -4,7 +4,7 @@\n \n name Roaring Scan Run Container Inverted\n group roaring\n-storage persistent\n+storage persistent v1.2.0\n \n load\n DROP TABLE IF EXISTS tbl;\n@@ -12,6 +12,11 @@ PRAGMA force_compression='Roaring';\n CREATE TABLE tbl AS SELECT case when i%3=0 then 1337 else null end as a FROM range(0, 250_000_000) tbl(i);\n checkpoint;\n \n+assert I\n+select DISTINCT compression from pragma_storage_info('tbl') where segment_type in ('VALIDITY')\n+----\n+Roaring\n+\n run\n select count(*) from tbl WHERE a IS NOT NULL;\n \ndiff --git a/benchmark/micro/compression/roaring/roaring_bitset_store.benchmark b/benchmark/micro/compression/roaring/roaring_bitset_store.benchmark\nindex ea9ce54d5c09..e8f7671f50be 100644\n--- a/benchmark/micro/compression/roaring/roaring_bitset_store.benchmark\n+++ b/benchmark/micro/compression/roaring/roaring_bitset_store.benchmark\n@@ -4,12 +4,19 @@\n \n name Roaring Write Run Container Inverted\n group roaring\n-storage persistent\n+storage persistent v1.2.0\n \n load\n+CREATE TABLE data_source AS SELECT case when i%3=0 then 1337 else null end as a FROM range(0, 250_000_000) tbl(i);\n PRAGMA force_compression='roaring';\n SET checkpoint_threshold = '10.0 GB';\n-CREATE TABLE data_source AS SELECT case when i%3=0 then 1337 else null end as a FROM range(0, 250_000_000) tbl(i);\n+CREATE TABLE test_compression as FROM data_source;\n+checkpoint;\n+\n+assert I\n+select DISTINCT compression from pragma_storage_info('test_compression') where segment_type in ('VALIDITY')\n+----\n+Roaring\n \n run\n CREATE TABLE tbl AS FROM data_source;\ndiff --git a/benchmark/micro/compression/roaring/roaring_inverted_array_read.benchmark b/benchmark/micro/compression/roaring/roaring_inverted_array_read.benchmark\nindex 0fb691fa5125..fc9e93eced1e 100644\n--- a/benchmark/micro/compression/roaring/roaring_inverted_array_read.benchmark\n+++ b/benchmark/micro/compression/roaring/roaring_inverted_array_read.benchmark\n@@ -4,7 +4,7 @@\n \n name Roaring Scan Array Container Inverted\n group roaring\n-storage persistent\n+storage persistent v1.2.0\n \n load\n DROP TABLE IF EXISTS tbl;\n@@ -12,6 +12,11 @@ PRAGMA force_compression='Roaring';\n CREATE TABLE tbl AS SELECT case when i%25=0 then null else 1337 end as a FROM range(0, 250_000_000) tbl(i);\n checkpoint;\n \n+assert I\n+select DISTINCT compression from pragma_storage_info('tbl') where segment_type in ('VALIDITY')\n+----\n+Roaring\n+\n run\n select count(*) from tbl WHERE a IS NOT NULL;\n \ndiff --git a/benchmark/micro/compression/roaring/roaring_inverted_array_store.benchmark b/benchmark/micro/compression/roaring/roaring_inverted_array_store.benchmark\nindex ac4868b2ab68..41673dddb5dd 100644\n--- a/benchmark/micro/compression/roaring/roaring_inverted_array_store.benchmark\n+++ b/benchmark/micro/compression/roaring/roaring_inverted_array_store.benchmark\n@@ -4,12 +4,19 @@\n \n name Roaring Scan Array Container Inverted\n group roaring\n-storage persistent\n+storage persistent v1.2.0\n \n load\n+CREATE TABLE data_source AS SELECT case when i%25=0 then null else 1337 end as a FROM range(0, 250_000_000) tbl(i);\n PRAGMA force_compression='roaring';\n SET checkpoint_threshold = '10.0 GB';\n-CREATE TABLE data_source AS SELECT case when i%25=0 then null else 1337 end as a FROM range(0, 250_000_000) tbl(i);\n+CREATE TABLE test_compression as FROM data_source;\n+checkpoint;\n+\n+assert I\n+select DISTINCT compression from pragma_storage_info('test_compression') where segment_type in ('VALIDITY')\n+----\n+Roaring\n \n run\n CREATE TABLE tbl AS FROM data_source;\ndiff --git a/benchmark/micro/compression/roaring/roaring_inverted_run_read.benchmark b/benchmark/micro/compression/roaring/roaring_inverted_run_read.benchmark\nindex c7244d679fb3..5c6e9ab865e7 100644\n--- a/benchmark/micro/compression/roaring/roaring_inverted_run_read.benchmark\n+++ b/benchmark/micro/compression/roaring/roaring_inverted_run_read.benchmark\n@@ -4,7 +4,7 @@\n \n name Roaring Scan Run Container Inverted\n group roaring\n-storage persistent\n+storage persistent v1.2.0\n \n load\n DROP TABLE IF EXISTS tbl;\n@@ -12,6 +12,11 @@ PRAGMA force_compression='Roaring';\n CREATE TABLE tbl AS SELECT case when i = 0 or (i % 512 != 0 and (i % 512) < 350 or (i % 512) > 450) then 1337 else null end as a FROM range(0, 250_000_000) tbl(i);\n checkpoint;\n \n+assert I\n+select DISTINCT compression from pragma_storage_info('tbl') where segment_type in ('VALIDITY')\n+----\n+Roaring\n+\n run\n select count(*) from tbl WHERE a IS NOT NULL;\n \ndiff --git a/benchmark/micro/compression/roaring/roaring_inverted_run_store.benchmark b/benchmark/micro/compression/roaring/roaring_inverted_run_store.benchmark\nindex e876c838f6c9..e1c27414f2ed 100644\n--- a/benchmark/micro/compression/roaring/roaring_inverted_run_store.benchmark\n+++ b/benchmark/micro/compression/roaring/roaring_inverted_run_store.benchmark\n@@ -4,12 +4,19 @@\n \n name Roaring Write Run Container Inverted\n group roaring\n-storage persistent\n+storage persistent v1.2.0\n \n load\n+CREATE TABLE data_source AS SELECT case when i = 0 or (i % 512 != 0 and (i % 512) < 350 or (i % 512) > 450) then 1337 else null end as a FROM range(0, 250_000_000) tbl(i);\n PRAGMA force_compression='Roaring';\n SET checkpoint_threshold = '10.0 GB';\n-CREATE TABLE data_source AS SELECT case when i = 0 or (i % 512 != 0 and (i % 512) < 350 or (i % 512) > 450) then 1337 else null end as a FROM range(0, 250_000_000) tbl(i);\n+CREATE TABLE test_compression as FROM data_source;\n+checkpoint;\n+\n+assert I\n+select DISTINCT compression from pragma_storage_info('test_compression') where segment_type in ('VALIDITY')\n+----\n+Roaring\n \n run\n CREATE TABLE tbl AS FROM data_source;\ndiff --git a/benchmark/micro/compression/roaring/roaring_run_read.benchmark b/benchmark/micro/compression/roaring/roaring_run_read.benchmark\nindex 8164940f17bf..a14684354181 100644\n--- a/benchmark/micro/compression/roaring/roaring_run_read.benchmark\n+++ b/benchmark/micro/compression/roaring/roaring_run_read.benchmark\n@@ -4,7 +4,7 @@\n \n name Roaring Scan Run Container Inverted\n group roaring\n-storage persistent\n+storage persistent v1.2.0\n \n load\n DROP TABLE IF EXISTS tbl;\n@@ -12,6 +12,11 @@ PRAGMA force_compression='Roaring';\n CREATE TABLE tbl AS SELECT case when i = 0 or (i % 512 != 0 and (i % 512) < 350 or (i % 512) > 450) then null else 1337 end as a FROM range(0, 250_000_000) tbl(i);\n checkpoint;\n \n+assert I\n+select DISTINCT compression from pragma_storage_info('tbl') where segment_type in ('VALIDITY')\n+----\n+Roaring\n+\n run\n select count(*) from tbl WHERE a IS NOT NULL;\n \ndiff --git a/benchmark/micro/compression/roaring/roaring_run_store.benchmark b/benchmark/micro/compression/roaring/roaring_run_store.benchmark\nindex 8a13c8404d9f..d5af79ec4a44 100644\n--- a/benchmark/micro/compression/roaring/roaring_run_store.benchmark\n+++ b/benchmark/micro/compression/roaring/roaring_run_store.benchmark\n@@ -4,13 +4,20 @@\n \n name Roaring Write Run Container\n group roaring\n-storage persistent\n+storage persistent v1.2.0\n \n # Roughly 8 runs per Vector\n load\n+CREATE TABLE data_source AS SELECT case when i = 0 or (i % 512 != 0 and (i % 512) < 350 or (i % 512) > 450) then null else 1337 end as a FROM range(0, 250_000_000) tbl(i);\n PRAGMA force_compression='Roaring';\n SET checkpoint_threshold = '10.0 GB';\n-CREATE TABLE data_source AS SELECT case when i = 0 or (i % 512 != 0 and (i % 512) < 350 or (i % 512) > 450) then null else 1337 end as a FROM range(0, 250_000_000) tbl(i);\n+CREATE TABLE test_compression as FROM data_source;\n+checkpoint;\n+\n+assert I\n+select DISTINCT compression from pragma_storage_info('test_compression') where segment_type in ('VALIDITY')\n+----\n+Roaring\n \n run\n CREATE TABLE tbl AS FROM data_source;\ndiff --git a/benchmark/micro/compression/zstd/zstd_read.benchmark b/benchmark/micro/compression/zstd/zstd_read.benchmark\nindex 4684249e67fe..4472b1a80666 100644\n--- a/benchmark/micro/compression/zstd/zstd_read.benchmark\n+++ b/benchmark/micro/compression/zstd/zstd_read.benchmark\n@@ -4,7 +4,7 @@\n \n name ZSTD Scan\n group zstd\n-storage persistent\n+storage persistent v1.2.0\n \n load\n DROP TABLE IF EXISTS zstd_strings;\n@@ -13,5 +13,10 @@ set variable my_string = (list_reduce([chr(((i % 26) + ord('a'))::INTEGER) for i\n create table zstd_strings as select getvariable('my_string') as data from range(2_500_000) tbl(i);\n checkpoint;\n \n+assert I\n+select DISTINCT compression from pragma_storage_info('zstd_strings') where segment_type in ('VARCHAR')\n+----\n+ZSTD\n+\n run\n select avg(strlen(data)) from zstd_strings;\ndiff --git a/benchmark/micro/compression/zstd/zstd_store.benchmark b/benchmark/micro/compression/zstd/zstd_store.benchmark\nindex bab765e2f89a..b8511a974be3 100644\n--- a/benchmark/micro/compression/zstd/zstd_store.benchmark\n+++ b/benchmark/micro/compression/zstd/zstd_store.benchmark\n@@ -4,13 +4,20 @@\n \n name ZSTD Compression Write\n group zstd\n-storage persistent\n+storage persistent v1.2.0\n require_reinit\n \n load\n DROP TABLE IF EXISTS zstd_strings;\n PRAGMA force_compression='zstd';\n set variable my_string = (list_reduce([chr(((i % 26) + ord('a'))::INTEGER) for i in range(4096)], (x, y) -> concat(x, y)));\n+create table test_compression as select getvariable('my_string') as data from range(2_500_000) tbl(i);\n+checkpoint;\n+\n+assert I\n+select DISTINCT compression from pragma_storage_info('test_compression') where segment_type in ('VARCHAR')\n+----\n+ZSTD\n \n run\n create table zstd_strings as select getvariable('my_string') as data from range(2_500_000) tbl(i);\ndiff --git a/data/storage/artupdates.db.gz b/data/storage/artupdates.db.gz\nnew file mode 100644\nindex 000000000000..de8c920afcac\nBinary files /dev/null and b/data/storage/artupdates.db.gz differ\ndiff --git a/src/execution/index/art/art.cpp b/src/execution/index/art/art.cpp\nindex c47f7740b976..68aad532ce7a 100644\n--- a/src/execution/index/art/art.cpp\n+++ b/src/execution/index/art/art.cpp\n@@ -45,7 +45,7 @@ ART::ART(const string &name, const IndexConstraintType index_constraint_type, co\n          const shared_ptr<array<unsafe_unique_ptr<FixedSizeAllocator>, ALLOCATOR_COUNT>> &allocators_ptr,\n          const IndexStorageInfo &info)\n     : BoundIndex(name, ART::TYPE_NAME, index_constraint_type, column_ids, table_io_manager, unbound_expressions, db),\n-      allocators(allocators_ptr), owns_data(false) {\n+      allocators(allocators_ptr), owns_data(false), verify_max_key_len(false) {\n \n \t// FIXME: Use the new byte representation function to support nested types.\n \tfor (idx_t i = 0; i < types.size(); i++) {\n@@ -70,6 +70,12 @@ ART::ART(const string &name, const IndexConstraintType index_constraint_type, co\n \t\t}\n \t}\n \n+\tif (types.size() > 1) {\n+\t\tverify_max_key_len = true;\n+\t} else if (types[0] == PhysicalType::VARCHAR) {\n+\t\tverify_max_key_len = true;\n+\t}\n+\n \t// Initialize the allocators.\n \tSetPrefixCount(info);\n \tif (!allocators) {\n@@ -380,11 +386,25 @@ void GenerateKeysInternal(ArenaAllocator &allocator, DataChunk &input, unsafe_ve\n template <>\n void ART::GenerateKeys<>(ArenaAllocator &allocator, DataChunk &input, unsafe_vector<ARTKey> &keys) {\n \tGenerateKeysInternal<false>(allocator, input, keys);\n+\tif (!verify_max_key_len) {\n+\t\treturn;\n+\t}\n+\tauto max_len = MAX_KEY_LEN * idx_t(prefix_count);\n+\tfor (idx_t i = 0; i < input.size(); i++) {\n+\t\tkeys[i].VerifyKeyLength(max_len);\n+\t}\n }\n \n template <>\n void ART::GenerateKeys<true>(ArenaAllocator &allocator, DataChunk &input, unsafe_vector<ARTKey> &keys) {\n \tGenerateKeysInternal<true>(allocator, input, keys);\n+\tif (!verify_max_key_len) {\n+\t\treturn;\n+\t}\n+\tauto max_len = MAX_KEY_LEN * idx_t(prefix_count);\n+\tfor (idx_t i = 0; i < input.size(); i++) {\n+\t\tkeys[i].VerifyKeyLength(max_len);\n+\t}\n }\n \n void ART::GenerateKeyVectors(ArenaAllocator &allocator, DataChunk &input, Vector &row_ids, unsafe_vector<ARTKey> &keys,\n@@ -976,6 +996,8 @@ bool ART::Scan(IndexScanState &state, const idx_t max_count, unsafe_vector<row_t\n \tD_ASSERT(scan_state.values[0].type().InternalType() == types[0]);\n \tArenaAllocator arena_allocator(Allocator::Get(db));\n \tauto key = ARTKey::CreateKey(arena_allocator, types[0], scan_state.values[0]);\n+\tauto max_len = MAX_KEY_LEN * prefix_count;\n+\tkey.VerifyKeyLength(max_len);\n \n \tif (scan_state.values[1].IsNull()) {\n \t\t// Single predicate.\n@@ -1000,6 +1022,8 @@ bool ART::Scan(IndexScanState &state, const idx_t max_count, unsafe_vector<row_t\n \tlock_guard<mutex> l(lock);\n \tD_ASSERT(scan_state.values[1].type().InternalType() == types[0]);\n \tauto upper_bound = ARTKey::CreateKey(arena_allocator, types[0], scan_state.values[1]);\n+\tupper_bound.VerifyKeyLength(max_len);\n+\n \tbool left_equal = scan_state.expressions[0] == ExpressionType ::COMPARE_GREATERTHANOREQUALTO;\n \tbool right_equal = scan_state.expressions[1] == ExpressionType ::COMPARE_LESSTHANOREQUALTO;\n \treturn SearchCloseRange(key, upper_bound, left_equal, right_equal, max_count, row_ids);\n@@ -1305,11 +1329,6 @@ void ART::SetPrefixCount(const IndexStorageInfo &info) {\n \t\treturn;\n \t}\n \n-\tif (!IsUnique()) {\n-\t\tprefix_count = Prefix::ROW_ID_COUNT;\n-\t\treturn;\n-\t}\n-\n \tidx_t compound_size = 0;\n \tfor (const auto &type : types) {\n \t\tcompound_size += GetTypeIdSize(type);\ndiff --git a/src/execution/index/art/art_key.cpp b/src/execution/index/art/art_key.cpp\nindex d5769f0f5810..bcc949434956 100644\n--- a/src/execution/index/art/art_key.cpp\n+++ b/src/execution/index/art/art_key.cpp\n@@ -16,6 +16,13 @@ ARTKey::ARTKey(ArenaAllocator &allocator, idx_t len) : len(len) {\n \tdata = allocator.Allocate(len);\n }\n \n+void ARTKey::VerifyKeyLength(const idx_t max_len) const {\n+\tif (len > max_len) {\n+\t\tthrow InvalidInputException(\"key size of %d bytes exceeds the maximum size of %d bytes for this ART\", len,\n+\t\t                            max_len);\n+\t}\n+}\n+\n template <>\n ARTKey ARTKey::CreateARTKey(ArenaAllocator &allocator, string_t value) {\n \tauto string_data = const_data_ptr_cast(value.GetData());\n@@ -29,22 +36,22 @@ ARTKey ARTKey::CreateARTKey(ArenaAllocator &allocator, string_t value) {\n \t\t}\n \t}\n \n-\tidx_t len = string_len + escape_count + 1;\n-\tauto data = allocator.Allocate(len);\n+\tidx_t key_len = string_len + escape_count + 1;\n+\tauto key_data = allocator.Allocate(key_len);\n \n \t// Copy over the data and add escapes.\n \tidx_t pos = 0;\n \tfor (idx_t i = 0; i < string_len; i++) {\n \t\tif (string_data[i] <= 1) {\n \t\t\t// Add escape.\n-\t\t\tdata[pos++] = '\\01';\n+\t\t\tkey_data[pos++] = '\\01';\n \t\t}\n-\t\tdata[pos++] = string_data[i];\n+\t\tkey_data[pos++] = string_data[i];\n \t}\n \n \t// End with a null-terminator.\n-\tdata[pos] = '\\0';\n-\treturn ARTKey(data, len);\n+\tkey_data[pos] = '\\0';\n+\treturn ARTKey(key_data, key_len);\n }\n \n template <>\ndiff --git a/src/execution/operator/csv_scanner/sniffer/dialect_detection.cpp b/src/execution/operator/csv_scanner/sniffer/dialect_detection.cpp\nindex 74c928b332c6..ef7c3c101248 100644\n--- a/src/execution/operator/csv_scanner/sniffer/dialect_detection.cpp\n+++ b/src/execution/operator/csv_scanner/sniffer/dialect_detection.cpp\n@@ -525,6 +525,15 @@ void CSVSniffer::RefineCandidates() {\n \t\t\tunique_ptr<ColumnCountScanner> cc_best_candidate = std::move(successful_candidates[i]);\n \t\t\tif (cc_best_candidate->state_machine->state_machine_options.quote != '\\0' &&\n \t\t\t    cc_best_candidate->ever_quoted) {\n+\t\t\t\t// If we have multiple candidates with the same quote, but different escapes\n+\t\t\t\tfor (idx_t j = i + 1; j < successful_candidates.size(); j++) {\n+\t\t\t\t\t// we give preference if it has the same character between escape and quote\n+\t\t\t\t\tif (successful_candidates[j]->state_machine->state_machine_options.escape ==\n+\t\t\t\t\t    successful_candidates[j]->state_machine->state_machine_options.quote) {\n+\t\t\t\t\t\tcc_best_candidate = std::move(successful_candidates[j]);\n+\t\t\t\t\t\tbreak;\n+\t\t\t\t\t}\n+\t\t\t\t}\n \t\t\t\tcandidates.clear();\n \t\t\t\tcandidates.push_back(std::move(cc_best_candidate));\n \t\t\t\treturn;\ndiff --git a/src/execution/operator/persistent/physical_batch_insert.cpp b/src/execution/operator/persistent/physical_batch_insert.cpp\nindex 3caaff78914d..5090588848fe 100644\n--- a/src/execution/operator/persistent/physical_batch_insert.cpp\n+++ b/src/execution/operator/persistent/physical_batch_insert.cpp\n@@ -542,8 +542,12 @@ SinkResultType PhysicalBatchInsert::Sink(ExecutionContext &context, DataChunk &c\n \tif (!lstate.constraint_state) {\n \t\tlstate.constraint_state = table.GetStorage().InitializeConstraintState(table, bound_constraints);\n \t}\n+\n \tauto &storage = table.GetStorage();\n-\tstorage.VerifyAppendConstraints(*lstate.constraint_state, context.client, lstate.insert_chunk, nullptr, nullptr);\n+\tauto &local_storage = LocalStorage::Get(context.client, storage.db);\n+\tauto local_table_storage = local_storage.GetStorage(table.GetStorage());\n+\tstorage.VerifyAppendConstraints(*lstate.constraint_state, context.client, lstate.insert_chunk, local_table_storage,\n+\t                                nullptr);\n \n \tauto &collection = table.GetStorage().GetOptimisticCollection(context.client, lstate.collection_index);\n \tauto new_row_group = collection.Append(lstate.insert_chunk, lstate.current_append_state);\ndiff --git a/src/execution/operator/persistent/physical_insert.cpp b/src/execution/operator/persistent/physical_insert.cpp\nindex 8d5572be200c..ca99242717dd 100644\n--- a/src/execution/operator/persistent/physical_insert.cpp\n+++ b/src/execution/operator/persistent/physical_insert.cpp\n@@ -479,13 +479,12 @@ static idx_t HandleInsertConflicts(TableCatalogEntry &table, ExecutionContext &c\n \n \tConflictInfo conflict_info(conflict_target);\n \tConflictManager conflict_manager(VerifyExistenceType::APPEND, tuples.size(), &conflict_info);\n+\tauto storage = local_storage.GetStorage(data_table);\n \tif (GLOBAL) {\n \t\tauto &constraint_state = lstate.GetConstraintState(data_table, table);\n-\t\tauto storage = local_storage.GetStorage(data_table);\n \t\tdata_table.VerifyAppendConstraints(constraint_state, context.client, tuples, storage, &conflict_manager);\n \t} else {\n \t\tauto &indexes = local_storage.GetIndexes(data_table);\n-\t\tauto storage = local_storage.GetStorage(data_table);\n \t\tDataTable::VerifyUniqueIndexes(indexes, storage, tuples, &conflict_manager);\n \t}\n \ndiff --git a/src/execution/operator/schema/physical_create_art_index.cpp b/src/execution/operator/schema/physical_create_art_index.cpp\nindex 11d05fd8cce0..c5f51fb12ef5 100644\n--- a/src/execution/operator/schema/physical_create_art_index.cpp\n+++ b/src/execution/operator/schema/physical_create_art_index.cpp\n@@ -142,8 +142,8 @@ SinkResultType PhysicalCreateARTIndex::Sink(ExecutionContext &context, DataChunk\n \t\t}\n \t}\n \n-\tART::GenerateKeyVectors(l_state.arena_allocator, l_state.key_chunk, chunk.data[chunk.ColumnCount() - 1],\n-\t                        l_state.keys, l_state.row_ids);\n+\tl_state.local_index->Cast<ART>().GenerateKeyVectors(\n+\t    l_state.arena_allocator, l_state.key_chunk, chunk.data[chunk.ColumnCount() - 1], l_state.keys, l_state.row_ids);\n \n \tif (sorted) {\n \t\treturn SinkSorted(input);\ndiff --git a/src/function/table/table_scan.cpp b/src/function/table/table_scan.cpp\nindex 361bc718f112..58cb9274ee14 100644\n--- a/src/function/table/table_scan.cpp\n+++ b/src/function/table/table_scan.cpp\n@@ -42,8 +42,12 @@ struct IndexScanLocalState : public LocalTableFunctionState {\n \t//! The DataChunk containing all read columns.\n \t//! This includes filter columns, which are immediately removed.\n \tDataChunk all_columns;\n-\t//! Fetch state\n+\t//! The row fetch state.\n \tColumnFetchState fetch_state;\n+\t//! The current position in the local storage scan.\n+\tTableScanState scan_state;\n+\t//! The column IDs of the local storage scan.\n+\tvector<StorageIndex> column_ids;\n };\n \n static StorageIndex TransformStorageIndex(const ColumnIndex &column_id) {\n@@ -118,8 +122,6 @@ class DuckIndexScanState : public TableScanGlobalState {\n \t//! Synchronize changes to the global index scan state.\n \tmutex index_scan_lock;\n \n-\tTableScanState table_scan_state;\n-\n public:\n \tunique_ptr<LocalTableFunctionState> InitLocalState(ExecutionContext &context,\n \t                                                   TableFunctionInitInput &input) override {\n@@ -127,6 +129,19 @@ class DuckIndexScanState : public TableScanGlobalState {\n \t\tif (input.CanRemoveFilterColumns()) {\n \t\t\tl_state->all_columns.Initialize(context.client, scanned_types);\n \t\t}\n+\t\tl_state->scan_state.options.force_fetch_row = ClientConfig::GetConfig(context.client).force_fetch_row;\n+\n+\t\t// Initialize the local storage scan.\n+\t\tauto &bind_data = input.bind_data->Cast<TableScanBindData>();\n+\t\tauto &duck_table = bind_data.table.Cast<DuckTableEntry>();\n+\t\tauto &storage = duck_table.GetStorage();\n+\t\tauto &local_storage = LocalStorage::Get(context.client, duck_table.catalog);\n+\n+\t\tfor (const auto &col_idx : input.column_indexes) {\n+\t\t\tl_state->column_ids.push_back(GetStorageIndex(bind_data.table, col_idx));\n+\t\t}\n+\t\tl_state->scan_state.Initialize(l_state->column_ids, context.client, input.filters.get());\n+\t\tlocal_storage.InitializeScan(storage, l_state->scan_state.local_state, input.filters);\n \t\treturn std::move(l_state);\n \t}\n \n@@ -172,10 +187,10 @@ class DuckIndexScanState : public TableScanGlobalState {\n \t\t\tauto &local_storage = LocalStorage::Get(tx);\n \t\t\tif (CanRemoveFilterColumns()) {\n \t\t\t\tl_state.all_columns.Reset();\n-\t\t\t\tlocal_storage.Scan(table_scan_state.local_state, column_ids, l_state.all_columns);\n+\t\t\t\tlocal_storage.Scan(l_state.scan_state.local_state, column_ids, l_state.all_columns);\n \t\t\t\toutput.ReferenceColumns(l_state.all_columns, projection_ids);\n \t\t\t} else {\n-\t\t\t\tlocal_storage.Scan(table_scan_state.local_state, column_ids, output);\n+\t\t\t\tlocal_storage.Scan(l_state.scan_state.local_state, column_ids, output);\n \t\t\t}\n \t\t}\n \t}\n@@ -325,7 +340,7 @@ unique_ptr<GlobalTableFunctionState> DuckTableScanInitGlobal(ClientContext &cont\n }\n \n unique_ptr<GlobalTableFunctionState> DuckIndexScanInitGlobal(ClientContext &context, TableFunctionInitInput &input,\n-                                                             DataTable &storage, const TableScanBindData &bind_data,\n+                                                             const TableScanBindData &bind_data,\n                                                              unsafe_vector<row_t> &row_ids) {\n \tauto g_state = make_uniq<DuckIndexScanState>(context, input.bind_data.get());\n \tif (!row_ids.empty()) {\n@@ -335,9 +350,6 @@ unique_ptr<GlobalTableFunctionState> DuckIndexScanInitGlobal(ClientContext &cont\n \tg_state->finished = g_state->row_ids.empty() ? true : false;\n \n \tauto &duck_table = bind_data.table.Cast<DuckTableEntry>();\n-\tauto &local_storage = LocalStorage::Get(context, duck_table.catalog);\n-\tg_state->table_scan_state.options.force_fetch_row = ClientConfig::GetConfig(context).force_fetch_row;\n-\n \tif (input.CanRemoveFilterColumns()) {\n \t\tg_state->projection_ids = input.projection_ids;\n \t}\n@@ -352,9 +364,6 @@ unique_ptr<GlobalTableFunctionState> DuckIndexScanInitGlobal(ClientContext &cont\n \t\tg_state->scanned_types.push_back(columns.GetColumn(col_idx.ToLogical()).Type());\n \t}\n \n-\tg_state->table_scan_state.Initialize(g_state->column_ids, context, input.filters);\n-\tlocal_storage.InitializeScan(storage, g_state->table_scan_state.local_state, input.filters);\n-\n \t// Const-cast to indicate an index scan.\n \t// We need this information in the bind data so that we can access it during ANALYZE.\n \tauto &no_const_bind_data = bind_data.CastNoConst<TableScanBindData>();\n@@ -604,7 +613,7 @@ unique_ptr<GlobalTableFunctionState> TableScanInitGlobal(ClientContext &context,\n \tif (!index_scan) {\n \t\treturn DuckTableScanInitGlobal(context, input, storage, bind_data);\n \t}\n-\treturn DuckIndexScanInitGlobal(context, input, storage, bind_data, row_ids);\n+\treturn DuckIndexScanInitGlobal(context, input, bind_data, row_ids);\n }\n \n static unique_ptr<BaseStatistics> TableScanStatistics(ClientContext &context, const FunctionData *bind_data_p,\ndiff --git a/src/function/window/window_constant_aggregator.cpp b/src/function/window/window_constant_aggregator.cpp\nindex 312161223903..7ae1784b133e 100644\n--- a/src/function/window/window_constant_aggregator.cpp\n+++ b/src/function/window/window_constant_aggregator.cpp\n@@ -308,7 +308,9 @@ void WindowConstantAggregator::Finalize(WindowAggregatorState &gstate, WindowAgg\n \tlastate.statef.Combine(gastate.statef);\n \tlastate.statef.Destroy();\n \n-\tgastate.statef.Finalize(*gastate.results);\n+\tif (!--gastate.locals) {\n+\t\tgastate.statef.Finalize(*gastate.results);\n+\t}\n }\n \n unique_ptr<WindowAggregatorState> WindowConstantAggregator::GetLocalState(const WindowAggregatorState &gstate) const {\ndiff --git a/src/include/duckdb/execution/index/art/art.hpp b/src/include/duckdb/execution/index/art/art.hpp\nindex d6f41c1c4d92..ea638abf6bd2 100644\n--- a/src/include/duckdb/execution/index/art/art.hpp\n+++ b/src/include/duckdb/execution/index/art/art.hpp\n@@ -35,6 +35,8 @@ class ART : public BoundIndex {\n \tstatic constexpr uint8_t ALLOCATOR_COUNT = 9;\n \t//! FixedSizeAllocator count of deprecated ARTs.\n \tstatic constexpr uint8_t DEPRECATED_ALLOCATOR_COUNT = ALLOCATOR_COUNT - 3;\n+\t//! Keys must not exceed MAX_KEY_LEN * prefix_count.\n+\tstatic constexpr idx_t MAX_KEY_LEN = 8192;\n \n public:\n \tART(const string &name, const IndexConstraintType index_constraint_type, const vector<column_t> &column_ids,\n@@ -59,6 +61,8 @@ class ART : public BoundIndex {\n \tshared_ptr<array<unsafe_unique_ptr<FixedSizeAllocator>, ALLOCATOR_COUNT>> allocators;\n \t//! True, if the ART owns its data.\n \tbool owns_data;\n+\t//! True, if keys need a key length verification pass.\n+\tbool verify_max_key_len;\n \t//! The number of bytes fitting in the prefix.\n \tuint8_t prefix_count;\n \n@@ -106,9 +110,9 @@ class ART : public BoundIndex {\n \n \t//! ART key generation.\n \ttemplate <bool IS_NOT_NULL = false>\n-\tstatic void GenerateKeys(ArenaAllocator &allocator, DataChunk &input, unsafe_vector<ARTKey> &keys);\n-\tstatic void GenerateKeyVectors(ArenaAllocator &allocator, DataChunk &input, Vector &row_ids,\n-\t                               unsafe_vector<ARTKey> &keys, unsafe_vector<ARTKey> &row_id_keys);\n+\tvoid GenerateKeys(ArenaAllocator &allocator, DataChunk &input, unsafe_vector<ARTKey> &keys);\n+\tvoid GenerateKeyVectors(ArenaAllocator &allocator, DataChunk &input, Vector &row_ids, unsafe_vector<ARTKey> &keys,\n+\t                        unsafe_vector<ARTKey> &row_id_keys);\n \n \t//! Verifies the nodes and optionally returns a string of the ART.\n \tstring VerifyAndToString(IndexLock &state, const bool only_verify) override;\ndiff --git a/src/include/duckdb/execution/index/art/art_key.hpp b/src/include/duckdb/execution/index/art/art_key.hpp\nindex e19e3cbb9d6f..dabb414ad798 100644\n--- a/src/include/duckdb/execution/index/art/art_key.hpp\n+++ b/src/include/duckdb/execution/index/art/art_key.hpp\n@@ -73,6 +73,7 @@ class ARTKey {\n \tvoid Concat(ArenaAllocator &allocator, const ARTKey &other);\n \trow_t GetRowId() const;\n \tidx_t GetMismatchPos(const ARTKey &other, const idx_t start) const;\n+\tvoid VerifyKeyLength(const idx_t max_len) const;\n \n private:\n \ttemplate <class T>\ndiff --git a/src/main/extension/extension_helper.cpp b/src/main/extension/extension_helper.cpp\nindex 1088f0f135dd..cbf2cae8b160 100644\n--- a/src/main/extension/extension_helper.cpp\n+++ b/src/main/extension/extension_helper.cpp\n@@ -224,6 +224,14 @@ bool ExtensionHelper::TryAutoLoadExtension(ClientContext &context, const string\n \t}\n }\n \n+static string GetAutoInstallExtensionsRepository(const DBConfigOptions &options) {\n+\tstring repository_url = options.autoinstall_extension_repo;\n+\tif (repository_url.empty()) {\n+\t\trepository_url = options.custom_extension_repo;\n+\t}\n+\treturn repository_url;\n+}\n+\n bool ExtensionHelper::TryAutoLoadExtension(DatabaseInstance &instance, const string &extension_name) noexcept {\n \tif (instance.ExtensionIsLoaded(extension_name)) {\n \t\treturn true;\n@@ -232,8 +240,8 @@ bool ExtensionHelper::TryAutoLoadExtension(DatabaseInstance &instance, const str\n \ttry {\n \t\tauto &fs = FileSystem::GetFileSystem(instance);\n \t\tif (dbconfig.options.autoinstall_known_extensions) {\n-\t\t\tauto autoinstall_repo =\n-\t\t\t    ExtensionRepository::GetRepositoryByUrl(dbconfig.options.autoinstall_extension_repo);\n+\t\t\tauto repository_url = GetAutoInstallExtensionsRepository(dbconfig.options);\n+\t\t\tauto autoinstall_repo = ExtensionRepository::GetRepositoryByUrl(repository_url);\n \t\t\tExtensionInstallOptions options;\n \t\t\toptions.repository = autoinstall_repo;\n \t\t\tExtensionHelper::InstallExtension(instance, fs, extension_name, options);\n@@ -382,10 +390,10 @@ void ExtensionHelper::AutoLoadExtension(DatabaseInstance &db, const string &exte\n \t\tauto fs = FileSystem::CreateLocal();\n #ifndef DUCKDB_WASM\n \t\tif (dbconfig.options.autoinstall_known_extensions) {\n-\t\t\t//! Get the autoloading repository\n-\t\t\tauto repository = ExtensionRepository::GetRepositoryByUrl(dbconfig.options.autoinstall_extension_repo);\n+\t\t\tauto repository_url = GetAutoInstallExtensionsRepository(dbconfig.options);\n+\t\t\tauto autoinstall_repo = ExtensionRepository::GetRepositoryByUrl(repository_url);\n \t\t\tExtensionInstallOptions options;\n-\t\t\toptions.repository = repository;\n+\t\t\toptions.repository = autoinstall_repo;\n \t\t\tExtensionHelper::InstallExtension(db, *fs, extension_name, options);\n \t\t}\n #endif\ndiff --git a/src/main/extension/extension_install.cpp b/src/main/extension/extension_install.cpp\nindex 6cb8ad24e185..711bbca19cf9 100644\n--- a/src/main/extension/extension_install.cpp\n+++ b/src/main/extension/extension_install.cpp\n@@ -220,11 +220,10 @@ string ExtensionHelper::ExtensionUrlTemplate(optional_ptr<const DatabaseInstance\n \t} else {\n \t\tversioned_path = \"/${REVISION}/${PLATFORM}/${NAME}.duckdb_extension\";\n \t}\n+\tstring default_endpoint = ExtensionRepository::DEFAULT_REPOSITORY_URL;\n #ifdef WASM_LOADABLE_EXTENSIONS\n-\tstring default_endpoint = DEFAULT_REPOSITORY;\n \tversioned_path = versioned_path + \".wasm\";\n #else\n-\tstring default_endpoint = ExtensionRepository::DEFAULT_REPOSITORY_URL;\n \tversioned_path = versioned_path + CompressionExtensionFromType(FileCompressionType::GZIP);\n #endif\n \tstring url_template = repository.path + versioned_path;\ndiff --git a/src/optimizer/column_lifetime_analyzer.cpp b/src/optimizer/column_lifetime_analyzer.cpp\nindex 90d0d60237c1..cc34d2d53378 100644\n--- a/src/optimizer/column_lifetime_analyzer.cpp\n+++ b/src/optimizer/column_lifetime_analyzer.cpp\n@@ -223,6 +223,9 @@ void ColumnLifetimeAnalyzer::AddVerificationProjection(unique_ptr<LogicalOperato\n \n \t// Create a projection and swap the operators accordingly\n \tauto projection = make_uniq<LogicalProjection>(table_index, std::move(expressions));\n+\tif (child->has_estimated_cardinality) {\n+\t\tprojection->SetEstimatedCardinality(child->estimated_cardinality);\n+\t}\n \tprojection->children.emplace_back(std::move(child));\n \tchild = std::move(projection);\n \ndiff --git a/src/optimizer/late_materialization.cpp b/src/optimizer/late_materialization.cpp\nindex 5c2f19231a93..acbcd5bbcf85 100644\n--- a/src/optimizer/late_materialization.cpp\n+++ b/src/optimizer/late_materialization.cpp\n@@ -331,12 +331,18 @@ bool LateMaterialization::TryLateMaterialization(unique_ptr<LogicalOperator> &op\n \tif (root_type == LogicalOperatorType::LOGICAL_TOP_N) {\n \t\t// for top-n we need to order on expressions, so we need to order AFTER the final projection\n \t\tauto proj = make_uniq<LogicalProjection>(proj_index, std::move(final_proj_list));\n+\t\tif (join->has_estimated_cardinality) {\n+\t\t\tproj->SetEstimatedCardinality(join->estimated_cardinality);\n+\t\t}\n \t\tproj->children.push_back(std::move(join));\n \n \t\tfor (auto &order : final_orders) {\n \t\t\tReplaceTableReferences(*order.expression, proj_index);\n \t\t}\n \t\tauto order = make_uniq<LogicalOrder>(std::move(final_orders));\n+\t\tif (proj->has_estimated_cardinality) {\n+\t\t\torder->SetEstimatedCardinality(proj->estimated_cardinality);\n+\t\t}\n \t\torder->children.push_back(std::move(proj));\n \n \t\top = std::move(order);\n@@ -344,9 +350,15 @@ bool LateMaterialization::TryLateMaterialization(unique_ptr<LogicalOperator> &op\n \t\t// for limit/sample we order on row-id, so we need to order BEFORE the final projection\n \t\t// because the final projection removes row-ids\n \t\tauto order = make_uniq<LogicalOrder>(std::move(final_orders));\n+\t\tif (join->has_estimated_cardinality) {\n+\t\t\torder->SetEstimatedCardinality(join->estimated_cardinality);\n+\t\t}\n \t\torder->children.push_back(std::move(join));\n \n \t\tauto proj = make_uniq<LogicalProjection>(proj_index, std::move(final_proj_list));\n+\t\tif (order->has_estimated_cardinality) {\n+\t\t\tproj->SetEstimatedCardinality(order->estimated_cardinality);\n+\t\t}\n \t\tproj->children.push_back(std::move(order));\n \n \t\top = std::move(proj);\ndiff --git a/src/optimizer/sum_rewriter.cpp b/src/optimizer/sum_rewriter.cpp\nindex 587144110e6b..a08d9ef4c12c 100644\n--- a/src/optimizer/sum_rewriter.cpp\n+++ b/src/optimizer/sum_rewriter.cpp\n@@ -167,6 +167,9 @@ void SumRewriterOptimizer::RewriteSums(unique_ptr<LogicalOperator> &op) {\n \n \t// push the projection to replace the aggregate\n \tauto proj = make_uniq<LogicalProjection>(proj_index, std::move(projection_expressions));\n+\tif (op->has_estimated_cardinality) {\n+\t\tproj->SetEstimatedCardinality(op->estimated_cardinality);\n+\t}\n \tproj->children.push_back(std::move(op));\n \top = std::move(proj);\n }\ndiff --git a/tools/pythonpkg/README.md b/tools/pythonpkg/README.md\nindex 722a4df6695e..0cb65c7e413b 100644\n--- a/tools/pythonpkg/README.md\n+++ b/tools/pythonpkg/README.md\n@@ -77,50 +77,18 @@ pip install --prefix $DUCKDB_PREFIX -e $DUCKDB_PREFIX/src/duckdb-pythonpkg/duckd\n \n ## Development and Stubs\n \n-`*.pyi` stubs are generated with [Mypy's `stubgen`](https://mypy.readthedocs.io/en/stable/stubgen.html) and tweaked. These are important for autocomplete in many IDEs, as static-analysis based language servers can't introspect `duckdb`'s binary module.\n-\n-The stubs from stubgen are pretty good, but not perfect. In some cases, you can help stubgen out: for example, function annotation types that it can't figure out should be specified in the cpp where necessary, as in the example.\n-\n-```cpp\n-// without this change, the generated stub is\n-// def query_df(self, df: object, virtual_table_name: str, sql_query: str) -> DuckDBPyRelation: ...\n-pybind_opts.disable_function_signatures();\n-m.def(\"query_df\", &DuckDBPyRelation::QueryDF,\n-      \"query_df(self, df: pandas.DataFrame, virtual_table_name: str, sql_query: str) -> DuckDBPyRelation \\n\"\n-      \"Run the given SQL query in sql_query on the view named virtual_table_name that contains the content of \"\n-      \"Data.Frame df\",\n-      py::arg(\"df\"), py::arg(\"virtual_table_name\"), py::arg(\"sql_query\"));\n-pybind_opts.enable_function_signatures();\n-// now the generated stub is\n-// def query_df(self, df: pandas.DataFrame, virtual_table_name: str, sql_query: str) -> DuckDBPyRelation: ...\n-```\n-\n-If you want to regenerate the stubs, there is a bit of a chicken and egg situation - the stubs should go in the package, but\n-`stubgen` needs to look at the package to generate the stubs!\n-\n-There is a test that you can run to check the stubs match the real duckdb package - this runs in CI (sorry in advance...). If you add a method to the duckdb py library and forget to add it to the stub, this test will helpfully fail. The test is a run of [mypy.stubtest](https://github.com/python/mypy/issues/5028#issuecomment-740101546).\n+`*.pyi` stubs in `duckdb-stubs` are manually maintained. The connection-related stubs are generated using dedicated scripts in `tools/pythonpkg/scripts/`:\n+- `generate_connection_stubs.py`\n+- `generate_connection_wrapper_stubs.py`\n \n-The workflow for getting the stubs right will look something like\n+These stubs are important for autocomplete in many IDEs, as static-analysis based language servers can't introspect `duckdb`'s binary module.\n \n+To verify the stubs match the actual implementation:\n ```bash\n-# Edit python package...\n-vim tools/pythonpkg/duckdb_python.cpp # or whatever\n-\n-# Install duckdb python package to\n-#  - compile it so stubgen can read it\n-#  - put the stubs in editable mode so you can tweak them easily\n-(cd tools/pythonpkg; pip install -e .)\n-# regerate stub once your changes have been installed.\n-scripts/regenerate_python_stubs.sh\n-# (re-apply our fixes on top of generate stubs,\n-# hint: git add -p; git checkout HEAD tools/pythonpkg/duckdb-stubs)\n-\n-# check tests\n-pytest tests/stubs\n-# edit and re-test stubs until you're happy\n+python3 -m pytest tests/stubs\n ```\n \n-All the above should be done in a virtualenv.\n+If you add new methods to the DuckDB Python API, you'll need to manually add corresponding type hints to the stub files.\n \n ## Frequently encountered issue with extensions\n \ndiff --git a/tools/pythonpkg/duckdb-stubs/__init__.pyi b/tools/pythonpkg/duckdb-stubs/__init__.pyi\nindex 507af1141a71..5aecae1f6eef 100644\n--- a/tools/pythonpkg/duckdb-stubs/__init__.pyi\n+++ b/tools/pythonpkg/duckdb-stubs/__init__.pyi\n@@ -243,7 +243,7 @@ class Expression:\n     def __lt__(self, expr: \"Expression\") -> \"Expression\": ...\n     def __le__(self, expr: \"Expression\") -> \"Expression\": ...\n \n-    def show(self, max_width: Optional[int] = None, max_rows: Optional[int] = None, max_col_width: Optional[int] = None, null_value: Optional[str] = None, render_mode: Optional[RenderMode] = None) -> None: ...\n+    def show(self) -> None: ...\n     def __repr__(self) -> str: ...\n     def get_name(self) -> str: ...\n     def alias(self, alias: str) -> \"Expression\": ...\n@@ -268,7 +268,7 @@ def ConstantExpression(val: Any) -> Expression: ...\n def CaseExpression(condition: Expression, value: Expression) -> Expression: ...\n def FunctionExpression(function: str, *cols: Expression) -> Expression: ...\n def CoalesceOperator(*cols: Expression) -> Expression: ...\n-def LambdaExpression(lhs: Union[Tuple[\"Expression\", ...], str]) -> Expression: ...\n+def LambdaExpression(lhs: Union[Tuple[\"Expression\", ...], str], rhs: Expression) -> Expression: ...\n def SQLExpression(expr: str) -> Expression: ...\n \n class DuckDBPyConnection:\n@@ -449,7 +449,7 @@ class DuckDBPyRelation:\n     def select_types(self, types: List[Union[str, DuckDBPyType]]) -> DuckDBPyRelation: ...\n     def select_dtypes(self, types: List[Union[str, DuckDBPyType]]) -> DuckDBPyRelation: ...\n     def set_alias(self, alias: str) -> DuckDBPyRelation: ...\n-    def show(self) -> None: ...\n+    def show(self, max_width: Optional[int] = None, max_rows: Optional[int] = None, max_col_width: Optional[int] = None, null_value: Optional[str] = None, render_mode: Optional[RenderMode] = None) -> None: ...\n     def sql_query(self) -> str: ...\n     def to_arrow_table(self, batch_size: int = ...) -> pyarrow.lib.Table: ...\n     def to_csv(\ndiff --git a/tools/pythonpkg/scripts/cache_data.json b/tools/pythonpkg/scripts/cache_data.json\nindex 685499fbf636..6de027f9a464 100644\n--- a/tools/pythonpkg/scripts/cache_data.json\n+++ b/tools/pythonpkg/scripts/cache_data.json\n@@ -315,7 +315,6 @@\n         \"full_path\": \"numpy\",\n         \"name\": \"numpy\",\n         \"children\": [\n-            \"numpy.core\",\n             \"numpy.ma\",\n             \"numpy.ndarray\",\n             \"numpy.datetime64\",\n@@ -342,20 +341,6 @@\n         ],\n         \"required\": false\n     },\n-    \"numpy.core\": {\n-        \"type\": \"attribute\",\n-        \"full_path\": \"numpy.core\",\n-        \"name\": \"core\",\n-        \"children\": [\n-            \"numpy.core.multiarray\"\n-        ]\n-    },\n-    \"numpy.core.multiarray\": {\n-        \"type\": \"attribute\",\n-        \"full_path\": \"numpy.core.multiarray\",\n-        \"name\": \"multiarray\",\n-        \"children\": []\n-    },\n     \"numpy.ma\": {\n         \"type\": \"attribute\",\n         \"full_path\": \"numpy.ma\",\ndiff --git a/tools/pythonpkg/scripts/imports.py b/tools/pythonpkg/scripts/imports.py\nindex d23200daf7b2..b25f37290729 100644\n--- a/tools/pythonpkg/scripts/imports.py\n+++ b/tools/pythonpkg/scripts/imports.py\n@@ -58,7 +58,6 @@\n \n import numpy\n \n-numpy.core.multiarray\n numpy.ma.masked\n numpy.ma.masked_array\n numpy.ndarray\ndiff --git a/tools/pythonpkg/src/arrow/arrow_array_stream.cpp b/tools/pythonpkg/src/arrow/arrow_array_stream.cpp\nindex 13140d85c043..69cc0a3e87b1 100644\n--- a/tools/pythonpkg/src/arrow/arrow_array_stream.cpp\n+++ b/tools/pythonpkg/src/arrow/arrow_array_stream.cpp\n@@ -52,23 +52,21 @@ py::object PythonTableArrowArrayStreamFactory::ProduceScanner(DBConfig &config,\n \tpy::list projection_list = py::cast(column_list);\n \n \tbool has_filter = filters && !filters->filters.empty();\n+\tpy::dict kwargs;\n+\tif (!column_list.empty()) {\n+\t\tkwargs[\"columns\"] = projection_list;\n+\t}\n \n \tif (has_filter) {\n \t\tauto filter = TransformFilter(*filters, parameters.projected_columns.projection_map, filter_to_col,\n \t\t                              client_properties, arrow_table);\n-\t\tif (column_list.empty()) {\n-\t\t\treturn arrow_scanner(arrow_obj_handle, py::arg(\"filter\") = filter);\n-\t\t} else {\n-\t\t\treturn arrow_scanner(arrow_obj_handle, py::arg(\"columns\") = projection_list, py::arg(\"filter\") = filter);\n-\t\t}\n-\t} else {\n-\t\tif (column_list.empty()) {\n-\t\t\treturn arrow_scanner(arrow_obj_handle);\n-\t\t} else {\n-\t\t\treturn arrow_scanner(arrow_obj_handle, py::arg(\"columns\") = projection_list);\n+\t\tif (!filter.is(py::none())) {\n+\t\t\tkwargs[\"filter\"] = filter;\n \t\t}\n \t}\n+\treturn arrow_scanner(arrow_obj_handle, **kwargs);\n }\n+\n unique_ptr<ArrowArrayStreamWrapper> PythonTableArrowArrayStreamFactory::Produce(uintptr_t factory_ptr,\n                                                                                 ArrowStreamParameters &parameters) {\n \tpy::gil_scoped_acquire acquire;\n@@ -342,6 +340,9 @@ py::object TransformFilterRecursive(TableFilter &filter, vector<string> column_r\n \t\tfor (idx_t i = 0; i < or_filter.child_filters.size(); i++) {\n \t\t\tauto &child_filter = *or_filter.child_filters[i];\n \t\t\tpy::object child_expression = TransformFilterRecursive(child_filter, column_ref, timezone_config, type);\n+\t\t\tif (child_expression.is(py::none())) {\n+\t\t\t\tcontinue;\n+\t\t\t}\n \t\t\tif (expression.is(py::none())) {\n \t\t\t\texpression = std::move(child_expression);\n \t\t\t} else {\n@@ -356,6 +357,9 @@ py::object TransformFilterRecursive(TableFilter &filter, vector<string> column_r\n \t\tfor (idx_t i = 0; i < and_filter.child_filters.size(); i++) {\n \t\t\tauto &child_filter = *and_filter.child_filters[i];\n \t\t\tpy::object child_expression = TransformFilterRecursive(child_filter, column_ref, timezone_config, type);\n+\t\t\tif (child_expression.is(py::none())) {\n+\t\t\t\tcontinue;\n+\t\t\t}\n \t\t\tif (expression.is(py::none())) {\n \t\t\t\texpression = std::move(child_expression);\n \t\t\t} else {\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/import_cache/modules/numpy_module.hpp b/tools/pythonpkg/src/include/duckdb_python/import_cache/modules/numpy_module.hpp\nindex 7ec78a883842..d6abf1cb3b38 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/import_cache/modules/numpy_module.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/import_cache/modules/numpy_module.hpp\n@@ -26,18 +26,6 @@ struct NumpyMaCacheItem : public PythonImportCacheItem {\n \tPythonImportCacheItem masked_array;\n };\n \n-struct NumpyCoreCacheItem : public PythonImportCacheItem {\n-\n-public:\n-\tNumpyCoreCacheItem(optional_ptr<PythonImportCacheItem> parent)\n-\t    : PythonImportCacheItem(\"core\", parent), multiarray(\"multiarray\", this) {\n-\t}\n-\t~NumpyCoreCacheItem() override {\n-\t}\n-\n-\tPythonImportCacheItem multiarray;\n-};\n-\n struct NumpyCacheItem : public PythonImportCacheItem {\n \n public:\n@@ -45,9 +33,9 @@ struct NumpyCacheItem : public PythonImportCacheItem {\n \n public:\n \tNumpyCacheItem()\n-\t    : PythonImportCacheItem(\"numpy\"), core(this), ma(this), ndarray(\"ndarray\", this),\n-\t      datetime64(\"datetime64\", this), generic(\"generic\", this), int64(\"int64\", this), bool_(\"bool_\", this),\n-\t      byte(\"byte\", this), ubyte(\"ubyte\", this), short_(\"short\", this), ushort_(\"ushort\", this), intc(\"intc\", this),\n+\t    : PythonImportCacheItem(\"numpy\"), ma(this), ndarray(\"ndarray\", this), datetime64(\"datetime64\", this),\n+\t      generic(\"generic\", this), int64(\"int64\", this), bool_(\"bool_\", this), byte(\"byte\", this),\n+\t      ubyte(\"ubyte\", this), short_(\"short\", this), ushort_(\"ushort\", this), intc(\"intc\", this),\n \t      uintc(\"uintc\", this), int_(\"int_\", this), uint(\"uint\", this), longlong(\"longlong\", this),\n \t      ulonglong(\"ulonglong\", this), half(\"half\", this), float16(\"float16\", this), single(\"single\", this),\n \t      longdouble(\"longdouble\", this), csingle(\"csingle\", this), cdouble(\"cdouble\", this),\n@@ -56,7 +44,6 @@ struct NumpyCacheItem : public PythonImportCacheItem {\n \t~NumpyCacheItem() override {\n \t}\n \n-\tNumpyCoreCacheItem core;\n \tNumpyMaCacheItem ma;\n \tPythonImportCacheItem ndarray;\n \tPythonImportCacheItem datetime64;\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/pybind11/pybind_wrapper.hpp b/tools/pythonpkg/src/include/duckdb_python/pybind11/pybind_wrapper.hpp\nindex 6717648d0b03..a492db9aaa6b 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/pybind11/pybind_wrapper.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/pybind11/pybind_wrapper.hpp\n@@ -32,6 +32,8 @@ void gil_assert();\n bool is_list_like(handle obj);\n bool is_dict_like(handle obj);\n \n+std::string to_string(const object &obj);\n+\n } // namespace pybind11\n \n namespace duckdb {\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/pyconnection/pyconnection.hpp b/tools/pythonpkg/src/include/duckdb_python/pyconnection/pyconnection.hpp\nindex 36d1b29cdf93..f9fdc18eac37 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/pyconnection/pyconnection.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/pyconnection/pyconnection.hpp\n@@ -270,11 +270,14 @@ struct DuckDBPyConnection : public enable_shared_from_this<DuckDBPyConnection> {\n \tunique_ptr<DuckDBPyRelation> FromParquet(const string &file_glob, bool binary_as_string, bool file_row_number,\n \t                                         bool filename, bool hive_partitioning, bool union_by_name,\n \t                                         const py::object &compression = py::none());\n-\n \tunique_ptr<DuckDBPyRelation> FromParquets(const vector<string> &file_globs, bool binary_as_string,\n \t                                          bool file_row_number, bool filename, bool hive_partitioning,\n \t                                          bool union_by_name, const py::object &compression = py::none());\n \n+\tunique_ptr<DuckDBPyRelation> FromParquetInternal(Value &&file_param, bool binary_as_string, bool file_row_number,\n+\t                                                 bool filename, bool hive_partitioning, bool union_by_name,\n+\t                                                 const py::object &compression = py::none());\n+\n \tunique_ptr<DuckDBPyRelation> FromArrow(py::object &arrow_object);\n \n \tunordered_set<string> GetTableNames(const string &query);\ndiff --git a/tools/pythonpkg/src/pybind11/pybind_wrapper.cpp b/tools/pythonpkg/src/pybind11/pybind_wrapper.cpp\nindex 23bf80354a16..ce3122a0fc9c 100644\n--- a/tools/pythonpkg/src/pybind11/pybind_wrapper.cpp\n+++ b/tools/pythonpkg/src/pybind11/pybind_wrapper.cpp\n@@ -36,4 +36,9 @@ bool is_dict_like(handle obj) {\n \treturn isinstance(obj, mapping);\n }\n \n+// NOLINTNEXTLINE(readability-identifier-naming)\n+std::string to_string(const object &obj) {\n+\treturn std::string(py::str(obj));\n+}\n+\n } // namespace pybind11\ndiff --git a/tools/pythonpkg/src/pyconnection.cpp b/tools/pythonpkg/src/pyconnection.cpp\nindex 9163e2747289..8fb32c9872ae 100644\n--- a/tools/pythonpkg/src/pyconnection.cpp\n+++ b/tools/pythonpkg/src/pyconnection.cpp\n@@ -1679,14 +1679,14 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromDF(const PandasDataFrame &v\n \treturn make_uniq<DuckDBPyRelation>(std::move(rel));\n }\n \n-unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromParquet(const string &file_glob, bool binary_as_string,\n-                                                             bool file_row_number, bool filename,\n-                                                             bool hive_partitioning, bool union_by_name,\n-                                                             const py::object &compression) {\n+unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromParquetInternal(Value &&file_param, bool binary_as_string,\n+                                                                     bool file_row_number, bool filename,\n+                                                                     bool hive_partitioning, bool union_by_name,\n+                                                                     const py::object &compression) {\n \tauto &connection = con.GetConnection();\n \tstring name = \"parquet_\" + StringUtil::GenerateRandomName();\n \tvector<Value> params;\n-\tparams.emplace_back(file_glob);\n+\tparams.emplace_back(std::move(file_param));\n \tnamed_parameter_map_t named_parameters({{\"binary_as_string\", Value::BOOLEAN(binary_as_string)},\n \t                                        {\"file_row_number\", Value::BOOLEAN(file_row_number)},\n \t                                        {\"filename\", Value::BOOLEAN(filename)},\n@@ -1704,32 +1704,27 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromParquet(const string &file_\n \treturn make_uniq<DuckDBPyRelation>(connection.TableFunction(\"parquet_scan\", params, named_parameters)->Alias(name));\n }\n \n+unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromParquet(const string &file_glob, bool binary_as_string,\n+                                                             bool file_row_number, bool filename,\n+                                                             bool hive_partitioning, bool union_by_name,\n+                                                             const py::object &compression) {\n+\tauto file_param = Value(file_glob);\n+\treturn FromParquetInternal(std::move(file_param), binary_as_string, file_row_number, filename, hive_partitioning,\n+\t                           union_by_name, compression);\n+}\n+\n unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromParquets(const vector<string> &file_globs, bool binary_as_string,\n                                                               bool file_row_number, bool filename,\n                                                               bool hive_partitioning, bool union_by_name,\n                                                               const py::object &compression) {\n-\tauto &connection = con.GetConnection();\n-\tstring name = \"parquet_\" + StringUtil::GenerateRandomName();\n \tvector<Value> params;\n \tauto file_globs_as_value = vector<Value>();\n \tfor (const auto &file : file_globs) {\n \t\tfile_globs_as_value.emplace_back(file);\n \t}\n-\tparams.emplace_back(Value::LIST(file_globs_as_value));\n-\tnamed_parameter_map_t named_parameters({{\"binary_as_string\", Value::BOOLEAN(binary_as_string)},\n-\t                                        {\"file_row_number\", Value::BOOLEAN(file_row_number)},\n-\t                                        {\"filename\", Value::BOOLEAN(filename)},\n-\t                                        {\"hive_partitioning\", Value::BOOLEAN(hive_partitioning)},\n-\t                                        {\"union_by_name\", Value::BOOLEAN(union_by_name)}});\n-\n-\tif (!py::none().is(compression)) {\n-\t\tif (!py::isinstance<py::str>(compression)) {\n-\t\t\tthrow InvalidInputException(\"from_parquet only accepts 'compression' as a string\");\n-\t\t}\n-\t\tnamed_parameters[\"compression\"] = Value(py::str(compression));\n-\t}\n-\n-\treturn make_uniq<DuckDBPyRelation>(connection.TableFunction(\"parquet_scan\", params, named_parameters)->Alias(name));\n+\tauto file_param = Value::LIST(file_globs_as_value);\n+\treturn FromParquetInternal(std::move(file_param), binary_as_string, file_row_number, filename, hive_partitioning,\n+\t                           union_by_name, compression);\n }\n \n unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromArrow(py::object &arrow_object) {\ndiff --git a/tools/pythonpkg/src/python_udf.cpp b/tools/pythonpkg/src/python_udf.cpp\nindex b615f64cc936..41daf4e2461c 100644\n--- a/tools/pythonpkg/src/python_udf.cpp\n+++ b/tools/pythonpkg/src/python_udf.cpp\n@@ -373,6 +373,17 @@ struct ParameterKind {\n \t}\n };\n \n+static bool NumpyDeprecatesAccessToCore(const py::tuple &numpy_version) {\n+\tif (numpy_version.empty()) {\n+\t\treturn false;\n+\t}\n+\tif (string(py::str(numpy_version[0])) == string(\"2\")) {\n+\t\t//! Starting with numpy version 2.0.0 the use of 'core' is deprecated.\n+\t\treturn true;\n+\t}\n+\treturn false;\n+}\n+\n struct PythonUDFData {\n public:\n \tPythonUDFData(const string &name, bool vectorized, FunctionNullHandling null_handling)\n@@ -475,9 +486,21 @@ struct PythonUDFData {\n \tScalarFunction GetFunction(const py::function &udf, PythonExceptionHandling exception_handling, bool side_effects,\n \t                           const ClientProperties &client_properties) {\n \n-\t\tauto &import_cache = *DuckDBPyConnection::ImportCache();\n \t\t// Import this module, because importing this from a non-main thread causes a segfault\n-\t\t(void)import_cache.numpy.core.multiarray();\n+\n+\t\tauto &import_cache = *DuckDBPyConnection::ImportCache();\n+\t\tpy::handle core;\n+\t\tauto numpy = import_cache.numpy();\n+\t\tif (!numpy) {\n+\t\t\tthrow InvalidInputException(\"'numpy' is required for this operation, but it wasn't installed\");\n+\t\t}\n+\t\tauto numpy_version = py::cast<py::tuple>(numpy.attr(\"__version__\"));\n+\t\tif (NumpyDeprecatesAccessToCore(numpy_version)) {\n+\t\t\tcore = numpy.attr(\"_core\");\n+\t\t} else {\n+\t\t\tcore = numpy.attr(\"core\");\n+\t\t}\n+\t\t(void)core.attr(\"multiarray\");\n \n \t\tscalar_function_t func;\n \t\tif (vectorized) {\n", "test_patch": "diff --git a/test/extension/duckdb_extension_settings.test b/test/extension/duckdb_extension_settings.test\nnew file mode 100644\nindex 000000000000..34ca19445e02\n--- /dev/null\n+++ b/test/extension/duckdb_extension_settings.test\n@@ -0,0 +1,28 @@\n+# name: test/extension/duckdb_extension_settings.test\n+# description: settings for extensions\n+# group: [extension]\n+\n+statement ok\n+SET autoinstall_known_extensions = true;\n+\n+statement ok\n+SET autoload_known_extensions = true;\n+\n+statement ok\n+SET extension_directory = '__TEST_DIR__/custom_extension_directory';\n+\n+statement ok\n+SET custom_extension_repository = '__TEST_DIR__/not_existing_folder'\n+\n+statement error\n+FROM read_csv('https://some.org/file.csv');\n+----\n+not_existing_folder\n+\n+statement ok\n+SET autoinstall_extension_repository = '__TEST_DIR__/other_folder';\n+\n+statement error\n+FROM read_csv('https://some.org/file.csv');\n+----\n+other_folder\ndiff --git a/test/sql/copy/csv/test_quoted_later_escaped.test b/test/sql/copy/csv/test_quoted_later_escaped.test\nnew file mode 100644\nindex 000000000000..d723b663890f\n--- /dev/null\n+++ b/test/sql/copy/csv/test_quoted_later_escaped.test\n@@ -0,0 +1,35 @@\n+# name: test/sql/copy/csv/test_quoted_later_escaped.test\n+# description: Test quoted file, with escapes only happening much later.\n+# group: [csv]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+CREATE TABLE T as select '1, \"Oogie Boogie\"' from range (100000)\n+\n+statement ok\n+insert into T values ('2, \"\"\"sir\"\" Oogie Boogie\"')\n+\n+statement ok\n+COPY T to '__TEST_DIR__/out.csv' (FORMAT CSV, HEADER 0, QUOTE '');\n+\n+query II\n+SELECT quote, escape FROM sniff_csv('__TEST_DIR__/out.csv');\n+----\n+\"\t\"\n+\n+# Test we always give preference to escaped options\n+statement ok\n+CREATE TABLE T_2 as select '1, \"Oogie Boogie\"' from range (5000)\n+\n+statement ok\n+insert into T_2 values ('2, \"\\\"sir\\\" Oogie Boogie\"')\n+\n+statement ok\n+COPY T_2 to '__TEST_DIR__/out_2.csv' (FORMAT CSV, HEADER 0, QUOTE '');\n+\n+query II\n+SELECT quote, escape FROM sniff_csv('__TEST_DIR__/out_2.csv');\n+----\n+\"\t\\\n\\ No newline at end of file\ndiff --git a/test/sql/index/art/create_drop/test_art_long_keys.test_slow b/test/sql/index/art/create_drop/test_art_long_keys.test_slow\nnew file mode 100644\nindex 000000000000..09ce66b816b9\n--- /dev/null\n+++ b/test/sql/index/art/create_drop/test_art_long_keys.test_slow\n@@ -0,0 +1,49 @@\n+# name: test/sql/index/art/create_drop/test_art_long_keys.test_slow\n+# description: Test ART creation very long BLOBs.\n+# group: [create_drop]\n+\n+# Try creating an index with identical long keys.\n+statement ok\n+CREATE TABLE long_strings (id BLOB);\n+\n+statement ok\n+INSERT INTO long_strings SELECT repeat('k', 1000000);\n+\n+statement ok\n+INSERT INTO long_strings SELECT range::VARCHAR::BLOB FROM range(100000);\n+\n+statement ok\n+INSERT INTO long_strings SELECT repeat('k', 1000000);\n+\n+statement ok\n+INSERT INTO long_strings SELECT range::VARCHAR::BLOB || 'other' FROM range(100000);\n+\n+statement ok\n+INSERT INTO long_strings SELECT repeat('k', 1000000);\n+\n+statement error\n+CREATE INDEX idx ON long_strings(id);\n+----\n+<REGEX>:Invalid Input Error.*exceeds the maximum size.*\n+\n+# Now we try medium-sized keys.\n+statement ok\n+CREATE TABLE medium_strings (id BLOB);\n+\n+statement ok\n+INSERT INTO medium_strings SELECT repeat('k', 122879);\n+\n+statement ok\n+INSERT INTO medium_strings SELECT range::VARCHAR::BLOB FROM range(100000);\n+\n+statement ok\n+INSERT INTO medium_strings SELECT repeat('k', 122879);\n+\n+statement ok\n+INSERT INTO medium_strings SELECT range::VARCHAR::BLOB || 'other' FROM range(100000);\n+\n+statement ok\n+INSERT INTO medium_strings SELECT repeat('k', 122879);\n+\n+statement ok\n+CREATE INDEX idx ON medium_strings(id);\n\\ No newline at end of file\ndiff --git a/test/sql/index/art/insert_update_delete/test_art_parallel_updates.test_slow b/test/sql/index/art/insert_update_delete/test_art_parallel_updates.test_slow\nnew file mode 100644\nindex 000000000000..494b7634f5cc\n--- /dev/null\n+++ b/test/sql/index/art/insert_update_delete/test_art_parallel_updates.test_slow\n@@ -0,0 +1,36 @@\n+# name: test/sql/index/art/insert_update_delete/test_art_parallel_updates.test_slow\n+# description: Test concurrent updates causing index scans.\n+# group: [insert_update_delete]\n+\n+unzip data/storage/artupdates.db.gz __TEST_DIR__/artupdates.db\n+\n+statement ok\n+ATTACH '__TEST_DIR__/artupdates.db' AS db;\n+\n+statement ok\n+USE db;\n+\n+statement ok\n+BEGIN TRANSACTION;\n+\n+loop i 0 100\n+\n+statement ok\n+UPDATE test SET importId = 725 WHERE id = 34165;\n+\n+statement ok\n+UPDATE test SET importId = 663 WHERE id = 42638;\n+\n+statement ok\n+UPDATE test SET importId = 210 WHERE id = 11288;\n+\n+statement ok\n+UPDATE test SET importId = 805 WHERE id = 764;\n+\n+statement ok\n+UPDATE test SET importId = 782 WHERE id = 10151;\n+\n+statement ok\n+UPDATE test SET importId = 53 WHERE id = 3229;\n+\n+endloop\n\\ No newline at end of file\ndiff --git a/test/sql/index/test_art_keys.cpp b/test/sql/index/test_art_keys.cpp\nindex dd92377feab8..07ccc8c9685c 100644\n--- a/test/sql/index/test_art_keys.cpp\n+++ b/test/sql/index/test_art_keys.cpp\n@@ -45,7 +45,7 @@ static void TestKeys(duckdb::vector<ARTKey> &keys) {\n \t}\n }\n \n-static ARTKey CreateCompoundKey(ArenaAllocator &arena_allocator, string str_val, int32_t int_val) {\n+static ARTKey CreateCompoundKey(ArenaAllocator &arena_allocator, const string &str_val, int32_t int_val) {\n \n \tauto key_left = ARTKey::CreateARTKey<string_t>(arena_allocator, string_t(str_val.c_str(), str_val.size()));\n \tauto key_right = ARTKey::CreateARTKey<int32_t>(arena_allocator, int_val);\ndiff --git a/test/sql/window/test_window_constant_aggregate.test b/test/sql/window/test_window_constant_aggregate.test\nindex 89525d65e8a5..6aafb23d0742 100644\n--- a/test/sql/window/test_window_constant_aggregate.test\n+++ b/test/sql/window/test_window_constant_aggregate.test\n@@ -1,5 +1,5 @@\n # name: test/sql/window/test_window_constant_aggregate.test\n-# description: Most basic window function\n+# description: Test \"constant\" aggregation (single result for each partition)\n # group: [window]\n \n statement ok\n@@ -200,3 +200,88 @@ ORDER BY ALL\n 1\t17\t19,18,17,16,15,14,13,12,11,10\n 1\t18\t19,18,17,16,15,14,13,12,11,10\n 1\t19\t19,18,17,16,15,14,13,12,11,10\n+\n+# Test hash group with two partitions and blocks\n+statement ok\n+pragma threads=2\n+\n+loop i 0 100\n+\n+query III\n+with table_1 AS (\n+    SELECT\n+        'fb30cf47-6f6b-42ef-dec2-3f984479a2aa'::uuid    AS id,\n+        unnest(generate_series(\n+            '2024-04-01'::date,\n+            '2025-03-01'::date,\n+            interval '1 month'\n+        ))                                              AS date\n+    UNION ALL BY NAME\n+    SELECT\n+        '7d1cc557-2d45-6900-a1ed-b2c64f5d9200'::uuid    AS id,\n+        unnest(generate_series(\n+            '2024-02-01'::date,\n+            '2025-01-01'::date,\n+            interval '1 month'\n+        ))                                              AS date\n+), table_2 AS (\n+    SELECT\n+        'fb30cf47-6f6b-42ef-dec2-3f984479a2aa'::uuid    AS id,\n+        unnest(generate_series(\n+            '2024-04-01'::date,\n+            '2025-03-01'::date,\n+            interval '1 month'\n+        ))                                              AS date,\n+        1                                               AS value\n+    UNION ALL BY NAME\n+    SELECT\n+        '7d1cc557-2d45-6900-a1ed-b2c64f5d9200'::uuid    AS id,\n+        unnest(generate_series(\n+            '2022-12-01'::date,\n+            '2023-12-01'::date,\n+            interval '1 month'\n+        ))                                              AS date,\n+        1                                               AS value\n+), output AS (\n+    SELECT\n+        table_1.id,\n+        table_1.date,\n+        sum(table_2.value) over (\n+            PARTITION BY table_1.id\n+            ORDER BY table_1.date ASC\n+            ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n+        ) AS test_sum,\n+    FROM table_1\n+    LEFT JOIN table_2\n+        ON table_1.id = table_2.id\n+        AND table_1.date = table_2.date\n+)\n+SELECT * FROM output\n+ORDER BY id DESC, date DESC;\n+----\n+fb30cf47-6f6b-42ef-dec2-3f984479a2aa\t2025-03-01 00:00:00\t12\n+fb30cf47-6f6b-42ef-dec2-3f984479a2aa\t2025-02-01 00:00:00\t12\n+fb30cf47-6f6b-42ef-dec2-3f984479a2aa\t2025-01-01 00:00:00\t12\n+fb30cf47-6f6b-42ef-dec2-3f984479a2aa\t2024-12-01 00:00:00\t12\n+fb30cf47-6f6b-42ef-dec2-3f984479a2aa\t2024-11-01 00:00:00\t12\n+fb30cf47-6f6b-42ef-dec2-3f984479a2aa\t2024-10-01 00:00:00\t12\n+fb30cf47-6f6b-42ef-dec2-3f984479a2aa\t2024-09-01 00:00:00\t12\n+fb30cf47-6f6b-42ef-dec2-3f984479a2aa\t2024-08-01 00:00:00\t12\n+fb30cf47-6f6b-42ef-dec2-3f984479a2aa\t2024-07-01 00:00:00\t12\n+fb30cf47-6f6b-42ef-dec2-3f984479a2aa\t2024-06-01 00:00:00\t12\n+fb30cf47-6f6b-42ef-dec2-3f984479a2aa\t2024-05-01 00:00:00\t12\n+fb30cf47-6f6b-42ef-dec2-3f984479a2aa\t2024-04-01 00:00:00\t12\n+7d1cc557-2d45-6900-a1ed-b2c64f5d9200\t2025-01-01 00:00:00\tNULL\n+7d1cc557-2d45-6900-a1ed-b2c64f5d9200\t2024-12-01 00:00:00\tNULL\n+7d1cc557-2d45-6900-a1ed-b2c64f5d9200\t2024-11-01 00:00:00\tNULL\n+7d1cc557-2d45-6900-a1ed-b2c64f5d9200\t2024-10-01 00:00:00\tNULL\n+7d1cc557-2d45-6900-a1ed-b2c64f5d9200\t2024-09-01 00:00:00\tNULL\n+7d1cc557-2d45-6900-a1ed-b2c64f5d9200\t2024-08-01 00:00:00\tNULL\n+7d1cc557-2d45-6900-a1ed-b2c64f5d9200\t2024-07-01 00:00:00\tNULL\n+7d1cc557-2d45-6900-a1ed-b2c64f5d9200\t2024-06-01 00:00:00\tNULL\n+7d1cc557-2d45-6900-a1ed-b2c64f5d9200\t2024-05-01 00:00:00\tNULL\n+7d1cc557-2d45-6900-a1ed-b2c64f5d9200\t2024-04-01 00:00:00\tNULL\n+7d1cc557-2d45-6900-a1ed-b2c64f5d9200\t2024-03-01 00:00:00\tNULL\n+7d1cc557-2d45-6900-a1ed-b2c64f5d9200\t2024-02-01 00:00:00\tNULL\n+\n+endloop\ndiff --git a/tools/pythonpkg/tests/fast/api/test_fsspec.py b/tools/pythonpkg/tests/fast/api/test_fsspec.py\nnew file mode 100644\nindex 000000000000..34a254e1caf1\n--- /dev/null\n+++ b/tools/pythonpkg/tests/fast/api/test_fsspec.py\n@@ -0,0 +1,51 @@\n+import pytest\n+import duckdb\n+import io\n+\n+fsspec = pytest.importorskip(\"fsspec\")\n+\n+\n+class TestReadParquet(object):\n+    def test_fsspec_deadlock(self, duckdb_cursor, tmp_path):\n+        # Create test parquet data\n+        file_path = tmp_path / \"data.parquet\"\n+        duckdb_cursor.sql(\"COPY (FROM range(50_000)) TO '{}' (FORMAT parquet)\".format(str(file_path)))\n+        with open(file_path, \"rb\") as f:\n+            parquet_data = f.read()\n+\n+        class TestFileSystem(fsspec.AbstractFileSystem):\n+            protocol = \"deadlock\"\n+\n+            @property\n+            def fsid(self):\n+                return \"deadlock\"\n+\n+            def ls(self, path, detail=True, **kwargs):\n+                vals = [k for k in self._data.keys() if k.startswith(path)]\n+                if detail:\n+                    return [\n+                        {\n+                            \"name\": path,\n+                            \"size\": len(self._data[path]),\n+                            \"type\": \"file\",\n+                            \"created\": 0,\n+                            \"islink\": False,\n+                        }\n+                        for path in vals\n+                    ]\n+                else:\n+                    return vals\n+\n+            def _open(self, path, **kwargs):\n+                return io.BytesIO(self._data[path])\n+\n+            def __init__(self):\n+                super().__init__()\n+                self._data = {\"a\": parquet_data, \"b\": parquet_data}\n+\n+        fsspec.register_implementation(\"deadlock\", TestFileSystem, clobber=True)\n+        fs = fsspec.filesystem('deadlock')\n+        duckdb_cursor.register_filesystem(fs)\n+\n+        result = duckdb_cursor.read_parquet(file_globs=[\"deadlock://a\", \"deadlock://b\"], union_by_name=True)\n+        assert len(result.fetchall()) == 100_000\ndiff --git a/tools/pythonpkg/tests/fast/arrow/test_filter_pushdown.py b/tools/pythonpkg/tests/fast/arrow/test_filter_pushdown.py\nindex aa8da22eb1f4..9a8cc743f96d 100644\n--- a/tools/pythonpkg/tests/fast/arrow/test_filter_pushdown.py\n+++ b/tools/pythonpkg/tests/fast/arrow/test_filter_pushdown.py\n@@ -946,5 +946,43 @@ def test_in_filter_pushdown(self, duckdb_cursor):\n         duck_probe = duckdb_conn.table(\"probe\")\n         duck_probe_arrow = duck_probe.arrow()\n         duckdb_conn.register(\"duck_probe_arrow\", duck_probe_arrow)\n-        assert duckdb_conn.execute(\"SELECT * from duck_probe_arrow where a in (1, 999)\").fetchall() == [(1,), (999,)]\n         assert duckdb_conn.execute(\"SELECT * from duck_probe_arrow where a = any([1,999])\").fetchall() == [(1,), (999,)]\n+\n+    def test_pushdown_of_optional_filter(self, duckdb_cursor):\n+        cardinality_table = pa.Table.from_pydict(\n+            {\n+                'column_name': [\n+                    'id',\n+                    'product_code',\n+                    'price',\n+                    'quantity',\n+                    'category',\n+                    'is_available',\n+                    'rating',\n+                    'discount',\n+                    'color',\n+                ],\n+                'cardinality': [100, 100, 100, 45, 5, 3, 6, 39, 5],\n+            }\n+        )\n+\n+        result = duckdb.query(\n+            \"\"\"\n+            SELECT *\n+            FROM cardinality_table\n+            WHERE cardinality > 1\n+            ORDER BY cardinality ASC\n+        \"\"\"\n+        )\n+        res = result.fetchall()\n+        assert res == [\n+            ('is_available', 3),\n+            ('category', 5),\n+            ('color', 5),\n+            ('rating', 6),\n+            ('discount', 39),\n+            ('quantity', 45),\n+            ('id', 100),\n+            ('product_code', 100),\n+            ('price', 100),\n+        ]\n", "problem_statement": "ArrowNotImplementedError: 'and_kleene' error when querying Polars DataFrame in DuckDB\n### What happens?\n\nDuckDB query fails with \"ArrowNotImplementedError: Function 'and_kleene' has no kernel matching input types (bool, null)\" when querying a Polars DataFrame containing nullable boolean values.\n\n### To Reproduce\n\n## Code\n```python\nimport numpy as np\nimport random\nimport polars as pl\nimport duckdb\n\nnp.random.seed(42)\nrandom.seed(42)\nn_rows = 100\n\ndata = {\n    \"id\": list(range(1, n_rows + 1)),\n    \"product_code\": [f\"P{i:04d}\" for i in range(n_rows)],\n    \"price\": np.random.uniform(10, 1000, n_rows).tolist(),\n    \"quantity\": [random.randint(1, 50) if random.random() > 0.1 else None for _ in range(n_rows)],\n    \"category\": np.random.choice([\"A\", \"B\", \"C\", \"D\", None], n_rows, p=[0.3, 0.3, 0.2, 0.1, 0.1]).tolist(),\n    \"is_available\": np.random.choice([True, False, None], n_rows, p=[0.6, 0.3, 0.1]).tolist(),\n    \"rating\": [random.randint(1, 5) if random.random() > 0.2 else None for _ in range(n_rows)],\n    \"discount\": [round(random.uniform(0, 0.5), 2) if random.random() > 0.3 else None for _ in range(n_rows)],\n    \"color\": np.random.choice([\"red\", \"blue\", \"green\", \"black\", None], n_rows).tolist()\n}\n\ndf = pl.DataFrame(data)\ncardinality_df = pl.DataFrame({\n    \"column_name\": df.columns,\n    \"cardinality\": [df[col].n_unique() for col in df.columns]\n})\n\n# This successfully creates the cardinality dataframe\nprint(cardinality_df)\n\n# This query fails\nresult = duckdb.query(\"\"\"\nSELECT *\nFROM cardinality_df\nWHERE cardinality > 1\nORDER BY cardinality ASC\n\"\"\")\n\nprint(result)\n```\n\n## Output\nFirst, the Polars DataFrame is successfully created and displays correctly:\n```\nshape: (9, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 column_name  \u2506 cardinality \u2502\n\u2502 ---          \u2506 ---         \u2502\n\u2502 str          \u2506 i64         \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 id           \u2506 100         \u2502\n\u2502 product_code \u2506 100         \u2502\n\u2502 price        \u2506 100         \u2502\n\u2502 quantity     \u2506 45          \u2502\n\u2502 category     \u2506 5           \u2502\n\u2502 is_available \u2506 3           \u2502\n\u2502 rating       \u2506 6           \u2502\n\u2502 discount     \u2506 39          \u2502\n\u2502 color        \u2506 5           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nThen, when trying to run the DuckDB query, it fails with this error:\n```\nArrowNotImplementedError: Function 'and_kleene' has no kernel matching input types (bool, null)\nAt:\n  pyarrow/error.pxi(92): pyarrow.lib.check_status\n```\n\n## Expected behavior\nThe DuckDB query should successfully filter and sort the Polars DataFrame based on the cardinality column.\n\n## Additional info\nConverting the polars dataframe to pandas via `cardinality_df = cardinality_df.to_pandas()` avoids the error.\n\n### OS:\n\nLinux\n\n### DuckDB Version:\n\n1.2.0\n\n### DuckDB Client:\n\nPython\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nPavel Khokhlov\n\n### Affiliation:\n\npersonal\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "", "created_at": "2025-03-17T11:51:46Z"}
{"repo": "duckdb/duckdb", "pull_number": 16686, "instance_id": "duckdb__duckdb-16686", "issue_numbers": ["16671"], "base_commit": "2b273c839e3782d417d49d0101503b0151b3b9fd", "patch": "diff --git a/src/optimizer/pushdown/pushdown_projection.cpp b/src/optimizer/pushdown/pushdown_projection.cpp\nindex b10b60ae4c0b..4646b894e12a 100644\n--- a/src/optimizer/pushdown/pushdown_projection.cpp\n+++ b/src/optimizer/pushdown/pushdown_projection.cpp\n@@ -32,7 +32,11 @@ static unique_ptr<Expression> ReplaceProjectionBindings(LogicalProjection &proj,\n \t\tD_ASSERT(colref.binding.column_index < proj.expressions.size());\n \t\tD_ASSERT(colref.depth == 0);\n \t\t// replace the binding with a copy to the expression at the referenced index\n-\t\treturn proj.expressions[colref.binding.column_index]->Copy();\n+\t\tauto copy = proj.expressions[colref.binding.column_index]->Copy();\n+\t\tif (!colref.alias.empty()) {\n+\t\t\tcopy->alias = colref.alias;\n+\t\t}\n+\t\treturn copy;\n \t}\n \tExpressionIterator::EnumerateChildren(\n \t    *expr, [&](unique_ptr<Expression> &child) { child = ReplaceProjectionBindings(proj, std::move(child)); });\n", "test_patch": "diff --git a/test/optimizer/pushdown/issue_16671.test b/test/optimizer/pushdown/issue_16671.test\nnew file mode 100644\nindex 000000000000..1fc8c0d37bbb\n--- /dev/null\n+++ b/test/optimizer/pushdown/issue_16671.test\n@@ -0,0 +1,18 @@\n+# name: test/optimizer/pushdown/issue_16671.test\n+# description: Test keeping alias in filter pushdown\n+# group: [pushdown]\n+\n+require json\n+\n+statement ok\n+set variable W to '{\"a\":[1,2], \"b\":[2,4]}';\n+\n+query II\n+from (values (1,2),(2,3),(3,1),(1,2),(2,3),(2,4), (3,2))  test (a,b)\n+select *\n+where (getvariable('W') -> '/'||alias(columns(getvariable('W').json_keys())))\n+    .json_contains(columns(getvariable('W').json_keys()));\n+----\n+1\t2\n+1\t2\n+2\t4\n", "problem_statement": "Empty Table with Filter pushdown and columns(*)\n### What happens?\n\nthanks,\nI was trying to achieve some dynamic filtering and wrote the following.\nIt compute the expression correctly if it is not in where clause (you can see it by replacing the `where` with `,`) . \nAs soon as you put it in the where clause, it return an empty table. \nThe table is empty even if you put a `not` before the expression. \nIt works if I set  `SET disabled_optimizers = 'filter_pushdown';`\n\n### To Reproduce\n\n\n```\nset variable W to '{\"a\":[1,2], \"b\":[2,4]}';\nfrom (values (1,2),(2,3),(3,1),(1,2),(2,3),(2,4), (3,2))  test (a,b)\nselect *\nwhere (getvariable('W') -> '/'||alias(columns(getvariable('W').json_keys())))\n    .json_contains(columns(getvariable('W').json_keys()));\n```\n\nexpected result:\n| a | b |\n|--:|--:|\n| 1 | 2 |\n| 1 | 2 |\n| 2 | 4 |\n\nactual result: 0 row\n\nI hope I wrote the issue correctly, have a nice day!\n\n### OS:\n\nWindows\n\n### DuckDB Version:\n\nv1.2.1 8e52ec4395\n\n### DuckDB Client:\n\ncommand line\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nGiorgio Serravalle\n\n### Affiliation:\n\nhawkers\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "", "created_at": "2025-03-17T10:29:16Z"}
{"repo": "duckdb/duckdb", "pull_number": 16677, "instance_id": "duckdb__duckdb-16677", "issue_numbers": ["16665", "16665"], "base_commit": "84c87b12fa9554a8775dc243b4d0afd5b407321a", "patch": "diff --git a/extension/parquet/parquet_metadata.cpp b/extension/parquet/parquet_metadata.cpp\nindex e08e2cb35e03..1f997781753d 100644\n--- a/extension/parquet/parquet_metadata.cpp\n+++ b/extension/parquet/parquet_metadata.cpp\n@@ -771,7 +771,7 @@ void ParquetMetaDataImplementation(ClientContext &context, TableFunctionInput &d\n \t\t\t\tbreak;\n \t\t\tcase ParquetMetadataOperatorType::BLOOM_PROBE: {\n \t\t\t\tauto &bloom_probe_bind_data = data_p.bind_data->Cast<ParquetBloomProbeBindData>();\n-\t\t\t\tdata.ExecuteBloomProbe(context, bind_data.return_types, bind_data.file_list->GetFirstFile(),\n+\t\t\t\tdata.ExecuteBloomProbe(context, bind_data.return_types, data.current_file,\n \t\t\t\t                       bloom_probe_bind_data.probe_column_name, bloom_probe_bind_data.probe_constant);\n \t\t\t\tbreak;\n \t\t\t}\ndiff --git a/src/common/multi_file_reader.cpp b/src/common/multi_file_reader.cpp\nindex 3801df183888..e6fd5720b92e 100644\n--- a/src/common/multi_file_reader.cpp\n+++ b/src/common/multi_file_reader.cpp\n@@ -83,8 +83,6 @@ vector<string> MultiFileReader::ParsePaths(const Value &input) {\n \n shared_ptr<MultiFileList> MultiFileReader::CreateFileList(ClientContext &context, const vector<string> &paths,\n                                                           FileGlobOptions options) {\n-\tvector<string> result_files;\n-\n \tauto res = make_uniq<GlobMultiFileList>(context, paths, options);\n \tif (res->GetExpandResult() == FileExpandResult::NO_FILES && options == FileGlobOptions::DISALLOW_EMPTY) {\n \t\tthrow IOException(\"%s needs at least one file to read\", function_name);\n", "test_patch": "diff --git a/data/parquet-testing/multi_bloom_a.parquet b/data/parquet-testing/multi_bloom_a.parquet\nnew file mode 100644\nindex 000000000000..7cf25bf54f9e\nBinary files /dev/null and b/data/parquet-testing/multi_bloom_a.parquet differ\ndiff --git a/data/parquet-testing/multi_bloom_b.parquet b/data/parquet-testing/multi_bloom_b.parquet\nnew file mode 100644\nindex 000000000000..8860e3323535\nBinary files /dev/null and b/data/parquet-testing/multi_bloom_b.parquet differ\ndiff --git a/data/parquet-testing/multi_bloom_c.parquet b/data/parquet-testing/multi_bloom_c.parquet\nnew file mode 100644\nindex 000000000000..bd039e0321e1\nBinary files /dev/null and b/data/parquet-testing/multi_bloom_c.parquet differ\ndiff --git a/test/parquet/test_filename_column.test b/test/parquet/test_filename_column.test\nindex 593f46c13454..99dfb93def84 100644\n--- a/test/parquet/test_filename_column.test\n+++ b/test/parquet/test_filename_column.test\n@@ -56,3 +56,10 @@ query I\n SELECT my_cool_filename FROM read_parquet('data/parquet-testing/enum.parquet', filename=my_cool_filename) LIMIT 1\n ----\n data/parquet-testing/enum.parquet\n+\n+query III\n+select file_name[22:], row_group_id, bloom_filter_excludes from parquet_bloom_probe('data/parquet-testing/multi_bloom_*.parquet', 'a', 1)\n+----\n+multi_bloom_a.parquet\t0\tfalse\n+multi_bloom_b.parquet\t0\ttrue\n+multi_bloom_c.parquet\t0\ttrue\n\\ No newline at end of file\n", "problem_statement": "parquet_bloom_probe() outputs wrong files in file_name column if used on multiple files\n### What happens?\n\nIf I use `parquet_bloom_probe()` on multiple files (via a wildcard pattern), the resulting table will print the name of the first (matched) file in the `file_name` column for all rows even though the `row_group_id` starts over, indicating later lines are actually for other files.\n\n### To Reproduce\n\n```sql\ncopy (select a: 1) to 'a.parquet';\ncopy (select a: 2) to 'b.parquet';\ncopy (select a: 3) to 'c.parquet';\nfrom parquet_bloom_probe('?.parquet', 'a', 1);\n```\n```text\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 file_name \u2502 row_group_id \u2502 bloom_filter_excludes \u2502\n\u2502  varchar  \u2502    int64     \u2502        boolean        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a.parquet \u2502            0 \u2502 false                 \u2502\n\u2502 a.parquet \u2502            0 \u2502 false                 \u2502\n\u2502 a.parquet \u2502            0 \u2502 false                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nObserve `a.parquet` being printed for all rows even though those entries should be the three files.\n\n### OS:\n\nGentoo Linux/amd64 (DuckDB platform `linux_amd64`)\n\n### DuckDB Version:\n\n1.2.1\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nMarco G\u00f6tze\n\n### Affiliation:\n\n(none)\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have not tested with any build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nparquet_bloom_probe() outputs wrong files in file_name column if used on multiple files\n### What happens?\n\nIf I use `parquet_bloom_probe()` on multiple files (via a wildcard pattern), the resulting table will print the name of the first (matched) file in the `file_name` column for all rows even though the `row_group_id` starts over, indicating later lines are actually for other files.\n\n### To Reproduce\n\n```sql\ncopy (select a: 1) to 'a.parquet';\ncopy (select a: 2) to 'b.parquet';\ncopy (select a: 3) to 'c.parquet';\nfrom parquet_bloom_probe('?.parquet', 'a', 1);\n```\n```text\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 file_name \u2502 row_group_id \u2502 bloom_filter_excludes \u2502\n\u2502  varchar  \u2502    int64     \u2502        boolean        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 a.parquet \u2502            0 \u2502 false                 \u2502\n\u2502 a.parquet \u2502            0 \u2502 false                 \u2502\n\u2502 a.parquet \u2502            0 \u2502 false                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nObserve `a.parquet` being printed for all rows even though those entries should be the three files.\n\n### OS:\n\nGentoo Linux/amd64 (DuckDB platform `linux_amd64`)\n\n### DuckDB Version:\n\n1.2.1\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nMarco G\u00f6tze\n\n### Affiliation:\n\n(none)\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have not tested with any build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "\n", "created_at": "2025-03-16T09:45:12Z"}
{"repo": "duckdb/duckdb", "pull_number": 16657, "instance_id": "duckdb__duckdb-16657", "issue_numbers": ["16551"], "base_commit": "65061f58d439cc021db4c1a74218f118886a2fd4", "patch": "diff --git a/tools/pythonpkg/src/arrow/arrow_array_stream.cpp b/tools/pythonpkg/src/arrow/arrow_array_stream.cpp\nindex 9546de74bdd8..2b13ddfc2451 100644\n--- a/tools/pythonpkg/src/arrow/arrow_array_stream.cpp\n+++ b/tools/pythonpkg/src/arrow/arrow_array_stream.cpp\n@@ -48,23 +48,21 @@ py::object PythonTableArrowArrayStreamFactory::ProduceScanner(DBConfig &config,\n \tpy::list projection_list = py::cast(column_list);\n \n \tbool has_filter = filters && !filters->filters.empty();\n+\tpy::dict kwargs;\n+\tif (!column_list.empty()) {\n+\t\tkwargs[\"columns\"] = projection_list;\n+\t}\n \n \tif (has_filter) {\n \t\tauto filter = TransformFilter(*filters, parameters.projected_columns.projection_map, filter_to_col,\n \t\t                              client_properties, arrow_table);\n-\t\tif (column_list.empty()) {\n-\t\t\treturn arrow_scanner(arrow_obj_handle, py::arg(\"filter\") = filter);\n-\t\t} else {\n-\t\t\treturn arrow_scanner(arrow_obj_handle, py::arg(\"columns\") = projection_list, py::arg(\"filter\") = filter);\n-\t\t}\n-\t} else {\n-\t\tif (column_list.empty()) {\n-\t\t\treturn arrow_scanner(arrow_obj_handle);\n-\t\t} else {\n-\t\t\treturn arrow_scanner(arrow_obj_handle, py::arg(\"columns\") = projection_list);\n+\t\tif (!filter.is(py::none())) {\n+\t\t\tkwargs[\"filter\"] = filter;\n \t\t}\n \t}\n+\treturn arrow_scanner(arrow_obj_handle, **kwargs);\n }\n+\n unique_ptr<ArrowArrayStreamWrapper> PythonTableArrowArrayStreamFactory::Produce(uintptr_t factory_ptr,\n                                                                                 ArrowStreamParameters &parameters) {\n \tpy::gil_scoped_acquire acquire;\n@@ -337,6 +335,9 @@ py::object TransformFilterRecursive(TableFilter &filter, vector<string> column_r\n \t\tfor (idx_t i = 0; i < or_filter.child_filters.size(); i++) {\n \t\t\tauto &child_filter = *or_filter.child_filters[i];\n \t\t\tpy::object child_expression = TransformFilterRecursive(child_filter, column_ref, timezone_config, type);\n+\t\t\tif (child_expression.is(py::none())) {\n+\t\t\t\tcontinue;\n+\t\t\t}\n \t\t\tif (expression.is(py::none())) {\n \t\t\t\texpression = std::move(child_expression);\n \t\t\t} else {\n@@ -351,6 +352,9 @@ py::object TransformFilterRecursive(TableFilter &filter, vector<string> column_r\n \t\tfor (idx_t i = 0; i < and_filter.child_filters.size(); i++) {\n \t\t\tauto &child_filter = *and_filter.child_filters[i];\n \t\t\tpy::object child_expression = TransformFilterRecursive(child_filter, column_ref, timezone_config, type);\n+\t\t\tif (child_expression.is(py::none())) {\n+\t\t\t\tcontinue;\n+\t\t\t}\n \t\t\tif (expression.is(py::none())) {\n \t\t\t\texpression = std::move(child_expression);\n \t\t\t} else {\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/pybind11/pybind_wrapper.hpp b/tools/pythonpkg/src/include/duckdb_python/pybind11/pybind_wrapper.hpp\nindex 6717648d0b03..a492db9aaa6b 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/pybind11/pybind_wrapper.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/pybind11/pybind_wrapper.hpp\n@@ -32,6 +32,8 @@ void gil_assert();\n bool is_list_like(handle obj);\n bool is_dict_like(handle obj);\n \n+std::string to_string(const object &obj);\n+\n } // namespace pybind11\n \n namespace duckdb {\ndiff --git a/tools/pythonpkg/src/pybind11/pybind_wrapper.cpp b/tools/pythonpkg/src/pybind11/pybind_wrapper.cpp\nindex 23bf80354a16..ce3122a0fc9c 100644\n--- a/tools/pythonpkg/src/pybind11/pybind_wrapper.cpp\n+++ b/tools/pythonpkg/src/pybind11/pybind_wrapper.cpp\n@@ -36,4 +36,9 @@ bool is_dict_like(handle obj) {\n \treturn isinstance(obj, mapping);\n }\n \n+// NOLINTNEXTLINE(readability-identifier-naming)\n+std::string to_string(const object &obj) {\n+\treturn std::string(py::str(obj));\n+}\n+\n } // namespace pybind11\n", "test_patch": "diff --git a/tools/pythonpkg/tests/fast/arrow/test_filter_pushdown.py b/tools/pythonpkg/tests/fast/arrow/test_filter_pushdown.py\nindex 6ee575198f6b..142d1dace103 100644\n--- a/tools/pythonpkg/tests/fast/arrow/test_filter_pushdown.py\n+++ b/tools/pythonpkg/tests/fast/arrow/test_filter_pushdown.py\n@@ -947,3 +947,42 @@ def test_in_filter_pushdown(self, duckdb_cursor):\n         duck_probe_arrow = duck_probe.arrow()\n         duckdb_conn.register(\"duck_probe_arrow\", duck_probe_arrow)\n         assert duckdb_conn.execute(\"SELECT * from duck_probe_arrow where a in (1, 999)\").fetchall() == [(1,), (999,)]\n+\n+    def test_pushdown_of_optional_filter(self, duckdb_cursor):\n+        cardinality_table = pa.Table.from_pydict(\n+            {\n+                'column_name': [\n+                    'id',\n+                    'product_code',\n+                    'price',\n+                    'quantity',\n+                    'category',\n+                    'is_available',\n+                    'rating',\n+                    'discount',\n+                    'color',\n+                ],\n+                'cardinality': [100, 100, 100, 45, 5, 3, 6, 39, 5],\n+            }\n+        )\n+\n+        result = duckdb.query(\n+            \"\"\"\n+            SELECT *\n+            FROM cardinality_table\n+            WHERE cardinality > 1\n+            ORDER BY cardinality ASC\n+        \"\"\"\n+        )\n+        res = result.fetchall()\n+        assert res == [\n+            ('is_available', 3),\n+            ('category', 5),\n+            ('color', 5),\n+            ('rating', 6),\n+            ('discount', 39),\n+            ('quantity', 45),\n+            ('id', 100),\n+            ('product_code', 100),\n+            ('price', 100),\n+        ]\n", "problem_statement": "ArrowNotImplementedError: 'and_kleene' error when querying Polars DataFrame in DuckDB\n### What happens?\n\nDuckDB query fails with \"ArrowNotImplementedError: Function 'and_kleene' has no kernel matching input types (bool, null)\" when querying a Polars DataFrame containing nullable boolean values.\n\n### To Reproduce\n\n## Code\n```python\nimport numpy as np\nimport random\nimport polars as pl\nimport duckdb\n\nnp.random.seed(42)\nrandom.seed(42)\nn_rows = 100\n\ndata = {\n    \"id\": list(range(1, n_rows + 1)),\n    \"product_code\": [f\"P{i:04d}\" for i in range(n_rows)],\n    \"price\": np.random.uniform(10, 1000, n_rows).tolist(),\n    \"quantity\": [random.randint(1, 50) if random.random() > 0.1 else None for _ in range(n_rows)],\n    \"category\": np.random.choice([\"A\", \"B\", \"C\", \"D\", None], n_rows, p=[0.3, 0.3, 0.2, 0.1, 0.1]).tolist(),\n    \"is_available\": np.random.choice([True, False, None], n_rows, p=[0.6, 0.3, 0.1]).tolist(),\n    \"rating\": [random.randint(1, 5) if random.random() > 0.2 else None for _ in range(n_rows)],\n    \"discount\": [round(random.uniform(0, 0.5), 2) if random.random() > 0.3 else None for _ in range(n_rows)],\n    \"color\": np.random.choice([\"red\", \"blue\", \"green\", \"black\", None], n_rows).tolist()\n}\n\ndf = pl.DataFrame(data)\ncardinality_df = pl.DataFrame({\n    \"column_name\": df.columns,\n    \"cardinality\": [df[col].n_unique() for col in df.columns]\n})\n\n# This successfully creates the cardinality dataframe\nprint(cardinality_df)\n\n# This query fails\nresult = duckdb.query(\"\"\"\nSELECT *\nFROM cardinality_df\nWHERE cardinality > 1\nORDER BY cardinality ASC\n\"\"\")\n\nprint(result)\n```\n\n## Output\nFirst, the Polars DataFrame is successfully created and displays correctly:\n```\nshape: (9, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 column_name  \u2506 cardinality \u2502\n\u2502 ---          \u2506 ---         \u2502\n\u2502 str          \u2506 i64         \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 id           \u2506 100         \u2502\n\u2502 product_code \u2506 100         \u2502\n\u2502 price        \u2506 100         \u2502\n\u2502 quantity     \u2506 45          \u2502\n\u2502 category     \u2506 5           \u2502\n\u2502 is_available \u2506 3           \u2502\n\u2502 rating       \u2506 6           \u2502\n\u2502 discount     \u2506 39          \u2502\n\u2502 color        \u2506 5           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nThen, when trying to run the DuckDB query, it fails with this error:\n```\nArrowNotImplementedError: Function 'and_kleene' has no kernel matching input types (bool, null)\nAt:\n  pyarrow/error.pxi(92): pyarrow.lib.check_status\n```\n\n## Expected behavior\nThe DuckDB query should successfully filter and sort the Polars DataFrame based on the cardinality column.\n\n## Additional info\nConverting the polars dataframe to pandas via `cardinality_df = cardinality_df.to_pandas()` avoids the error.\n\n### OS:\n\nLinux\n\n### DuckDB Version:\n\n1.2.0\n\n### DuckDB Client:\n\nPython\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nPavel Khokhlov\n\n### Affiliation:\n\npersonal\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "Hi @pkhokhlov thanks for reporting this! I added a print statement to trigger the error in a script and I could reproduce it.\nIt would be helpful to know the polars and pyarrow version you are using, as this doesn't reproduce on versions we have tested", "created_at": "2025-03-14T13:59:36Z"}
{"repo": "duckdb/duckdb", "pull_number": 16537, "instance_id": "duckdb__duckdb-16537", "issue_numbers": ["16524", "16524"], "base_commit": "352088979a6d89ab15366bf98294c4488e563b19", "patch": "diff --git a/src/planner/binder/query_node/plan_subquery.cpp b/src/planner/binder/query_node/plan_subquery.cpp\nindex b938f1f65417..f4c98bcfcebe 100644\n--- a/src/planner/binder/query_node/plan_subquery.cpp\n+++ b/src/planner/binder/query_node/plan_subquery.cpp\n@@ -393,17 +393,20 @@ void RecursiveDependentJoinPlanner::VisitOperator(LogicalOperator &op) {\n \t\t\tauto &rec_cte = op.Cast<LogicalRecursiveCTE>();\n \t\t\tbinder.recursive_ctes[rec_cte.table_index] = &op;\n \t\t}\n-\t\troot = std::move(op.children[0]);\n-\t\tD_ASSERT(root);\n-\t\tif (root->type == LogicalOperatorType::LOGICAL_DEPENDENT_JOIN) {\n-\t\t\t// Found a dependent join, flatten it\n-\t\t\tauto &new_root = root->Cast<LogicalDependentJoin>();\n-\t\t\troot = binder.PlanLateralJoin(std::move(new_root.children[0]), std::move(new_root.children[1]),\n-\t\t\t                              new_root.correlated_columns, new_root.join_type,\n-\t\t\t                              std::move(new_root.join_condition));\n+\t\tfor (idx_t i = 0; i < op.children.size(); i++) {\n+\t\t\troot = std::move(op.children[i]);\n+\t\t\tD_ASSERT(root);\n+\t\t\tif (root->type == LogicalOperatorType::LOGICAL_DEPENDENT_JOIN) {\n+\t\t\t\t// Found a dependent join, flatten it\n+\t\t\t\tauto &new_root = root->Cast<LogicalDependentJoin>();\n+\t\t\t\troot = binder.PlanLateralJoin(std::move(new_root.children[0]), std::move(new_root.children[1]),\n+\t\t\t\t                              new_root.correlated_columns, new_root.join_type,\n+\t\t\t\t                              std::move(new_root.join_condition));\n+\t\t\t}\n+\t\t\tVisitOperatorExpressions(op);\n+\t\t\top.children[i] = std::move(root);\n \t\t}\n-\t\tVisitOperatorExpressions(op);\n-\t\top.children[0] = std::move(root);\n+\n \t\tfor (idx_t i = 0; i < op.children.size(); i++) {\n \t\t\tD_ASSERT(op.children[i]);\n \t\t\tVisitOperator(*op.children[i]);\n", "test_patch": "diff --git a/test/issues/general/test_16524.test b/test/issues/general/test_16524.test\nnew file mode 100644\nindex 000000000000..019f09e49995\n--- /dev/null\n+++ b/test/issues/general/test_16524.test\n@@ -0,0 +1,24 @@\n+# name: test/issues/general/test_16524.test\n+# description: Issue 16524 - DuckDB internal error with a relatively complex JOIN involving lateral subqueries\n+# group: [general]\n+\n+statement ok\n+CREATE TABLE INT8_TBL(q1 int8, q2 int8);\n+\n+statement ok\n+INSERT INTO INT8_TBL VALUES\n+  ('  123   ','  456'),\n+  ('123   ','4567890123456789'),\n+  ('4567890123456789','123'),\n+  (+4567890123456789,'4567890123456789'),\n+  ('+4567890123456789','-4567890123456789');\n+\n+statement ok\n+select * from\n+  int8_tbl c left join (\n+    int8_tbl a left join (select q1, coalesce(q2,42) as x from int8_tbl b) ss1\n+      on a.q2 = ss1.q1\n+    cross join\n+    lateral (select q1, coalesce(ss1.x,q2) as y from int8_tbl d) ss2\n+  ) on c.q2 = ss2.q1,\n+  lateral (select ss2.y offset 0) ss3\n", "problem_statement": "DuckDB internal error with a relatively complex JOIN involving lateral subqueries\n### What happens?\n\nDuckDB throws `INTERNAL Error` with a relatively complex JOIN involving lateral subqueries\n\n### To Reproduce\n\n```sql\n\nCREATE TABLE INT8_TBL(q1 int8, q2 int8);\n\nINSERT INTO INT8_TBL VALUES\n  ('  123   ','  456'),\n  ('123   ','4567890123456789'),\n  ('4567890123456789','123'),\n  (+4567890123456789,'4567890123456789'),\n  ('+4567890123456789','-4567890123456789');\n\n\nselect * from\n  int8_tbl c left join (\n    int8_tbl a left join (select q1, coalesce(q2,42) as x from int8_tbl b) ss1\n      on a.q2 = ss1.q1\n    cross join\n    lateral (select q1, coalesce(ss1.x,q2) as y from int8_tbl d) ss2\n  ) on c.q2 = ss2.q1,\n  lateral (select ss2.y offset 0) ss3;\n```\n```console\nERROR:  Unknown Error\n\nINTERNAL Error: Failed to bind column reference \"x\" [3.1] (bindings: {#[9.0], #[9.1]})\nThis error signals an assertion failure within DuckDB. This usually occurs due to unexpected conditions or errors in the program's logic.\nFor more information, see https://duckdb.org/docs/dev/internal_errors\n```\n\nRemoving the last `lateral` subquery avoids the crash:\n```sql\n\nselect * from\n  int8_tbl c left join (\n    int8_tbl a left join (select q1, coalesce(q2,42) as x from int8_tbl b) ss1\n      on a.q2 = ss1.q1\n    cross join\n    lateral (select q1, coalesce(ss1.x,q2) as y from int8_tbl d) ss2\n  ) on c.q2 = ss2.q1\n```\n\n### OS:\n\nMacOS\n\n### DuckDB Version:\n\n1.1.3 and 1.2.0\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nOnder KALACI\n\n### Affiliation:\n\nCrunchy Data\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have not tested with any build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nDuckDB internal error with a relatively complex JOIN involving lateral subqueries\n### What happens?\n\nDuckDB throws `INTERNAL Error` with a relatively complex JOIN involving lateral subqueries\n\n### To Reproduce\n\n```sql\n\nCREATE TABLE INT8_TBL(q1 int8, q2 int8);\n\nINSERT INTO INT8_TBL VALUES\n  ('  123   ','  456'),\n  ('123   ','4567890123456789'),\n  ('4567890123456789','123'),\n  (+4567890123456789,'4567890123456789'),\n  ('+4567890123456789','-4567890123456789');\n\n\nselect * from\n  int8_tbl c left join (\n    int8_tbl a left join (select q1, coalesce(q2,42) as x from int8_tbl b) ss1\n      on a.q2 = ss1.q1\n    cross join\n    lateral (select q1, coalesce(ss1.x,q2) as y from int8_tbl d) ss2\n  ) on c.q2 = ss2.q1,\n  lateral (select ss2.y offset 0) ss3;\n```\n```console\nERROR:  Unknown Error\n\nINTERNAL Error: Failed to bind column reference \"x\" [3.1] (bindings: {#[9.0], #[9.1]})\nThis error signals an assertion failure within DuckDB. This usually occurs due to unexpected conditions or errors in the program's logic.\nFor more information, see https://duckdb.org/docs/dev/internal_errors\n```\n\nRemoving the last `lateral` subquery avoids the crash:\n```sql\n\nselect * from\n  int8_tbl c left join (\n    int8_tbl a left join (select q1, coalesce(q2,42) as x from int8_tbl b) ss1\n      on a.q2 = ss1.q1\n    cross join\n    lateral (select q1, coalesce(ss1.x,q2) as y from int8_tbl d) ss2\n  ) on c.q2 = ss2.q1\n```\n\n### OS:\n\nMacOS\n\n### DuckDB Version:\n\n1.1.3 and 1.2.0\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nOnder KALACI\n\n### Affiliation:\n\nCrunchy Data\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have not tested with any build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "\n", "created_at": "2025-03-06T12:36:06Z"}
{"repo": "duckdb/duckdb", "pull_number": 16522, "instance_id": "duckdb__duckdb-16522", "issue_numbers": ["16501"], "base_commit": "8e52ec43959ab363643d63cb78ee214577111da4", "patch": "diff --git a/tools/pythonpkg/src/include/duckdb_python/pyconnection/pyconnection.hpp b/tools/pythonpkg/src/include/duckdb_python/pyconnection/pyconnection.hpp\nindex 2d20e7344adb..f10a4dae05f9 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/pyconnection/pyconnection.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/pyconnection/pyconnection.hpp\n@@ -265,11 +265,14 @@ struct DuckDBPyConnection : public enable_shared_from_this<DuckDBPyConnection> {\n \tunique_ptr<DuckDBPyRelation> FromParquet(const string &file_glob, bool binary_as_string, bool file_row_number,\n \t                                         bool filename, bool hive_partitioning, bool union_by_name,\n \t                                         const py::object &compression = py::none());\n-\n \tunique_ptr<DuckDBPyRelation> FromParquets(const vector<string> &file_globs, bool binary_as_string,\n \t                                          bool file_row_number, bool filename, bool hive_partitioning,\n \t                                          bool union_by_name, const py::object &compression = py::none());\n \n+\tunique_ptr<DuckDBPyRelation> FromParquetInternal(Value &&file_param, bool binary_as_string, bool file_row_number,\n+\t                                                 bool filename, bool hive_partitioning, bool union_by_name,\n+\t                                                 const py::object &compression = py::none());\n+\n \tunique_ptr<DuckDBPyRelation> FromArrow(py::object &arrow_object);\n \n \tunordered_set<string> GetTableNames(const string &query);\ndiff --git a/tools/pythonpkg/src/pyconnection.cpp b/tools/pythonpkg/src/pyconnection.cpp\nindex 80fc21ba5ec3..ace9d1237335 100644\n--- a/tools/pythonpkg/src/pyconnection.cpp\n+++ b/tools/pythonpkg/src/pyconnection.cpp\n@@ -1676,14 +1676,14 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromDF(const PandasDataFrame &v\n \treturn make_uniq<DuckDBPyRelation>(std::move(rel));\n }\n \n-unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromParquet(const string &file_glob, bool binary_as_string,\n-                                                             bool file_row_number, bool filename,\n-                                                             bool hive_partitioning, bool union_by_name,\n-                                                             const py::object &compression) {\n+unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromParquetInternal(Value &&file_param, bool binary_as_string,\n+                                                                     bool file_row_number, bool filename,\n+                                                                     bool hive_partitioning, bool union_by_name,\n+                                                                     const py::object &compression) {\n \tauto &connection = con.GetConnection();\n \tstring name = \"parquet_\" + StringUtil::GenerateRandomName();\n \tvector<Value> params;\n-\tparams.emplace_back(file_glob);\n+\tparams.emplace_back(std::move(file_param));\n \tnamed_parameter_map_t named_parameters({{\"binary_as_string\", Value::BOOLEAN(binary_as_string)},\n \t                                        {\"file_row_number\", Value::BOOLEAN(file_row_number)},\n \t                                        {\"filename\", Value::BOOLEAN(filename)},\n@@ -1701,32 +1701,27 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromParquet(const string &file_\n \treturn make_uniq<DuckDBPyRelation>(connection.TableFunction(\"parquet_scan\", params, named_parameters)->Alias(name));\n }\n \n+unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromParquet(const string &file_glob, bool binary_as_string,\n+                                                             bool file_row_number, bool filename,\n+                                                             bool hive_partitioning, bool union_by_name,\n+                                                             const py::object &compression) {\n+\tauto file_param = Value(file_glob);\n+\treturn FromParquetInternal(std::move(file_param), binary_as_string, file_row_number, filename, hive_partitioning,\n+\t                           union_by_name, compression);\n+}\n+\n unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromParquets(const vector<string> &file_globs, bool binary_as_string,\n                                                               bool file_row_number, bool filename,\n                                                               bool hive_partitioning, bool union_by_name,\n                                                               const py::object &compression) {\n-\tauto &connection = con.GetConnection();\n-\tstring name = \"parquet_\" + StringUtil::GenerateRandomName();\n \tvector<Value> params;\n \tauto file_globs_as_value = vector<Value>();\n \tfor (const auto &file : file_globs) {\n \t\tfile_globs_as_value.emplace_back(file);\n \t}\n-\tparams.emplace_back(Value::LIST(file_globs_as_value));\n-\tnamed_parameter_map_t named_parameters({{\"binary_as_string\", Value::BOOLEAN(binary_as_string)},\n-\t                                        {\"file_row_number\", Value::BOOLEAN(file_row_number)},\n-\t                                        {\"filename\", Value::BOOLEAN(filename)},\n-\t                                        {\"hive_partitioning\", Value::BOOLEAN(hive_partitioning)},\n-\t                                        {\"union_by_name\", Value::BOOLEAN(union_by_name)}});\n-\n-\tif (!py::none().is(compression)) {\n-\t\tif (!py::isinstance<py::str>(compression)) {\n-\t\t\tthrow InvalidInputException(\"from_parquet only accepts 'compression' as a string\");\n-\t\t}\n-\t\tnamed_parameters[\"compression\"] = Value(py::str(compression));\n-\t}\n-\n-\treturn make_uniq<DuckDBPyRelation>(connection.TableFunction(\"parquet_scan\", params, named_parameters)->Alias(name));\n+\tauto file_param = Value::LIST(file_globs_as_value);\n+\treturn FromParquetInternal(std::move(file_param), binary_as_string, file_row_number, filename, hive_partitioning,\n+\t                           union_by_name, compression);\n }\n \n unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromArrow(py::object &arrow_object) {\n", "test_patch": "diff --git a/tools/pythonpkg/tests/fast/api/test_fsspec.py b/tools/pythonpkg/tests/fast/api/test_fsspec.py\nnew file mode 100644\nindex 000000000000..34a254e1caf1\n--- /dev/null\n+++ b/tools/pythonpkg/tests/fast/api/test_fsspec.py\n@@ -0,0 +1,51 @@\n+import pytest\n+import duckdb\n+import io\n+\n+fsspec = pytest.importorskip(\"fsspec\")\n+\n+\n+class TestReadParquet(object):\n+    def test_fsspec_deadlock(self, duckdb_cursor, tmp_path):\n+        # Create test parquet data\n+        file_path = tmp_path / \"data.parquet\"\n+        duckdb_cursor.sql(\"COPY (FROM range(50_000)) TO '{}' (FORMAT parquet)\".format(str(file_path)))\n+        with open(file_path, \"rb\") as f:\n+            parquet_data = f.read()\n+\n+        class TestFileSystem(fsspec.AbstractFileSystem):\n+            protocol = \"deadlock\"\n+\n+            @property\n+            def fsid(self):\n+                return \"deadlock\"\n+\n+            def ls(self, path, detail=True, **kwargs):\n+                vals = [k for k in self._data.keys() if k.startswith(path)]\n+                if detail:\n+                    return [\n+                        {\n+                            \"name\": path,\n+                            \"size\": len(self._data[path]),\n+                            \"type\": \"file\",\n+                            \"created\": 0,\n+                            \"islink\": False,\n+                        }\n+                        for path in vals\n+                    ]\n+                else:\n+                    return vals\n+\n+            def _open(self, path, **kwargs):\n+                return io.BytesIO(self._data[path])\n+\n+            def __init__(self):\n+                super().__init__()\n+                self._data = {\"a\": parquet_data, \"b\": parquet_data}\n+\n+        fsspec.register_implementation(\"deadlock\", TestFileSystem, clobber=True)\n+        fs = fsspec.filesystem('deadlock')\n+        duckdb_cursor.register_filesystem(fs)\n+\n+        result = duckdb_cursor.read_parquet(file_globs=[\"deadlock://a\", \"deadlock://b\"], union_by_name=True)\n+        assert len(result.fetchall()) == 100_000\n", "problem_statement": "fsspec read deadlock\n### What happens?\n\nIt seems that from at least duckdb 1.2.0 there is a deadlock when using fsspec from read_parquet.\nNote I am using python 3.10\n\nFrom a quick gdb inspection it looks like read_parquet does not release the GIL, but a background thread tries to take it when calling back into fsspec -> deadlock.\n\nThe main thread then just spins: https://github.com/duckdb/duckdb/blob/ab451db4720e5d82e92503bcb28a527fb9348d4b/src/parallel/task_executor.cpp#L46 \n\n\n\n### To Reproduce\n\nyou should be able to stick this in a py file and run it\n\n```\nimport duckdb\nimport io\nimport threading\nimport tempfile\nimport fsspec\n\nwith tempfile.TemporaryFile() as fp1:\n    duckdb.sql(\"COPY (FROM generate_series(50_000)) TO '{}' (FORMAT parquet)\".format(fp1))\n    with open(str(fp1), \"rb\") as f:\n        _parquet_data = f.read()\n\nclass TestFileSystem(fsspec.AbstractFileSystem):\n    protocol = \"deadlock\"\n\n    @property\n    def fsid(self):\n        return \"deadlock\"\n\n    def ls(self, path, detail=True, **kwargs):\n        vals = [k for k in self._data.keys() if k.startswith(path)]\n        if detail:\n            return [\n                {\n                    \"name\": path,\n                    \"size\": len(self._data[path]),\n                    \"type\": \"file\",\n                    \"created\": 0,\n                    \"islink\": False,\n                } for path in vals\n            ]\n        else:\n            return vals\n\n    def _open(\n        self,\n        path,\n        **kwargs,\n    ):\n        return io.BytesIO(self._data[path])\n\n    def __init__(self):\n        super().__init__()\n        self._data = {\"a\": _parquet_data, \"b\": _parquet_data}\n\nfsspec.register_implementation(\"deadlock\", TestFileSystem, clobber=True)\nduckdb.register_filesystem(fsspec.filesystem('deadlock'))\nduckdb.read_parquet(file_globs=[\"deadlock://a\", \"deadlock://b\"], union_by_name=True)\n```\n\n### OS:\n\nLinux\n\n### DuckDB Version:\n\n1.2.0\n\n### DuckDB Client:\n\nPython\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nDylan Yudaken\n\n### Affiliation:\n\nQubos\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a nightly build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "Thanks we'll take a look!", "created_at": "2025-03-05T10:07:49Z"}
{"repo": "duckdb/duckdb", "pull_number": 16517, "instance_id": "duckdb__duckdb-16517", "issue_numbers": ["16339"], "base_commit": "d0c7224b40408132d221f3424c4dc9c4dfc8b366", "patch": "diff --git a/.github/config/out_of_tree_extensions.cmake b/.github/config/out_of_tree_extensions.cmake\nindex 938bbe5f3f83..461442a9d3ba 100644\n--- a/.github/config/out_of_tree_extensions.cmake\n+++ b/.github/config/out_of_tree_extensions.cmake\n@@ -100,7 +100,7 @@ if (NOT MINGW AND NOT ${WASM_ENABLED})\n     duckdb_extension_load(postgres_scanner\n             DONT_LINK\n             GIT_URL https://github.com/duckdb/duckdb-postgres\n-            GIT_TAG 79fcce4a7478d245189d851ce289def2b42f4f93\n+            GIT_TAG 8461ed8b6f726564934e9c831cdc88d431e3148f\n             )\n endif()\n \n@@ -134,7 +134,7 @@ duckdb_extension_load(sqlite_scanner\n duckdb_extension_load(sqlsmith\n         DONT_LINK LOAD_TESTS\n         GIT_URL https://github.com/duckdb/duckdb-sqlsmith\n-        GIT_TAG b13723fe701f1e38d2cd65b3b6eb587c6553a251\n+        GIT_TAG e1eb0ae02a258f176d6e06b84c0d6c7a09c6b4da\n         )\n \n ################# VSS\n@@ -162,6 +162,6 @@ duckdb_extension_load(fts\n         LOAD_TESTS\n         DONT_LINK\n         GIT_URL https://github.com/duckdb/duckdb-fts\n-        GIT_TAG 0477abaf2484aa7b9aabf8ace9dc0bde80a15554\n+        GIT_TAG 3aa6a180b9c101d78070f5f7214c27552bb091c8\n         TEST_DIR test/sql\n )\ndiff --git a/.github/workflows/CodeQuality.yml b/.github/workflows/CodeQuality.yml\nindex 7094970312d0..7a54054e02f7 100644\n--- a/.github/workflows/CodeQuality.yml\n+++ b/.github/workflows/CodeQuality.yml\n@@ -36,7 +36,7 @@ env:\n jobs:\n   format-check:\n     name: Format Check\n-    runs-on: ubuntu-20.04\n+    runs-on: ubuntu-22.04\n \n     env:\n       CC: gcc-10\n@@ -50,7 +50,7 @@ jobs:\n \n       - name: Install\n         shell: bash\n-        run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build clang-format-11 && sudo pip3 install cmake-format black cxxheaderparser pcpp\n+        run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build clang-format-11 && sudo pip3 install cmake-format 'black==24.*' cxxheaderparser pcpp 'clang_format==11.0.1'\n \n       - name: List Installed Packages\n         shell: bash\n@@ -73,7 +73,7 @@ jobs:\n   enum-check:\n     name: C Enum Integrity Check\n     needs: format-check\n-    runs-on: ubuntu-20.04\n+    runs-on: ubuntu-22.04\n \n     env:\n       CC: gcc-10\ndiff --git a/.github/workflows/ExtraTests.yml b/.github/workflows/ExtraTests.yml\nindex d91653df9e73..7d1818e1f2ee 100644\n--- a/.github/workflows/ExtraTests.yml\n+++ b/.github/workflows/ExtraTests.yml\n@@ -12,7 +12,7 @@ env:\n jobs:\n  regression-test-all:\n   name: All Regression Tests\n-  runs-on: ubuntu-20.04\n+  runs-on: ubuntu-22.04\n   env:\n     CC: gcc-10\n     CXX: g++-10\ndiff --git a/.github/workflows/LinuxRelease.yml b/.github/workflows/LinuxRelease.yml\nindex 9cd5a448fc8d..15d0cfd1970b 100644\n--- a/.github/workflows/LinuxRelease.yml\n+++ b/.github/workflows/LinuxRelease.yml\n@@ -51,7 +51,6 @@ env:\n jobs:\n  linux-release-cli:\n     needs: linux-extensions-64\n-    if: ${{ github.ref == 'refs/heads/main' || github.ref == 'refs/heads/feature' }}\n \n     strategy:\n       fail-fast: false\n@@ -128,7 +127,6 @@ jobs:\n         build/release/benchmark/benchmark_runner benchmark/micro/update/update_with_join.benchmark\n         build/release/duckdb -c \"COPY (SELECT 42) TO '/dev/stdout' (FORMAT PARQUET)\" | cat\n \n-\n  # Linux extensions for builds that use C++11 ABI, currently these are all linux builds based on ubuntu >= 18 (e.g. NodeJS)\n  # note that the linux-release-64 is based on the manylinux-based extensions, which are built in .github/workflows/Python.yml\n  linux-extensions-64:\n@@ -258,7 +256,7 @@ jobs:\n  check-load-install-extensions:\n     name: Checks extension entries\n     if: ${{ inputs.skip_tests != 'true' }}\n-    runs-on: ubuntu-20.04\n+    runs-on: ubuntu-22.04\n     needs: linux-extensions-64\n     env:\n       CC: gcc-10\n@@ -307,6 +305,7 @@ jobs:\n         python scripts/generate_extensions_function.py\n         pip install \"black>=24\"\n         pip install cmake-format\n+        pip install \"clang_format==11.0.1\"\n         make format-fix\n \n     - uses: actions/upload-artifact@v4\n@@ -328,7 +327,7 @@ jobs:\n  symbol-leakage:\n     name: Symbol Leakage\n     if: ${{ inputs.skip_tests != 'true' }}\n-    runs-on: ubuntu-20.04\n+    runs-on: ubuntu-22.04\n     needs: linux-extensions-64\n \n     steps:\n@@ -359,7 +358,7 @@ jobs:\n     name: Amalgamation Tests\n     if: ${{ inputs.skip_tests != 'true' }}\n     needs: linux-extensions-64\n-    runs-on: ubuntu-20.04\n+    runs-on: ubuntu-22.04\n     env:\n       CC: clang\n       CXX: clang++\n@@ -377,7 +376,7 @@ jobs:\n     - name: Install LLVM and Clang\n       uses: KyleMayes/install-llvm-action@v1\n       with:\n-        version: \"10.0\"\n+        version: \"14.0\"\n \n     - name: Generate Amalgamation\n       shell: bash\ndiff --git a/.github/workflows/Main.yml b/.github/workflows/Main.yml\nindex 2f78f4743e76..f12270172436 100644\n--- a/.github/workflows/Main.yml\n+++ b/.github/workflows/Main.yml\n@@ -37,7 +37,7 @@ jobs:\n  linux-debug:\n     name: Linux Debug (${{ matrix.tag }})\n     if: ${{ !startsWith(github.ref, 'refs/tags/v') }}\n-    runs-on: ubuntu-20.04\n+    runs-on: ubuntu-22.04\n     strategy:\n       fail-fast: false\n       matrix:\n@@ -124,7 +124,7 @@ jobs:\n  force-storage:\n     name: Force Storage\n     if: ${{ !startsWith(github.ref, 'refs/tags/v') }}\n-    runs-on: ubuntu-20.04\n+    runs-on: ubuntu-22.04\n     env:\n       CC: gcc-10\n       CXX: g++-10\n@@ -161,7 +161,7 @@ jobs:\n  force-restart:\n     name: Force Restart\n     if: ${{ !startsWith(github.ref, 'refs/tags/v') }}\n-    runs-on: ubuntu-20.04\n+    runs-on: ubuntu-22.04\n     needs: force-storage\n     env:\n       CC: gcc-10\n@@ -198,7 +198,7 @@ jobs:\n  valgrind:\n     name: Valgrind\n     if: ${{ !startsWith(github.ref, 'refs/tags/v') }}\n-    runs-on: ubuntu-20.04\n+    runs-on: ubuntu-22.04\n     needs: force-storage\n     env:\n       CC: gcc-10\ndiff --git a/.github/workflows/NightlyTests.yml b/.github/workflows/NightlyTests.yml\nindex 8bdb4c96c0f7..ed8d9ee3a2e5 100644\n--- a/.github/workflows/NightlyTests.yml\n+++ b/.github/workflows/NightlyTests.yml\n@@ -65,7 +65,7 @@ jobs:\n \n   release-assert:\n     name: Release Assertions\n-    runs-on: ubuntu-20.04\n+    runs-on: ubuntu-22.04\n     needs: linux-memory-leaks\n     env:\n       CC: gcc-10\n@@ -140,7 +140,7 @@ jobs:\n \n   linux-clang:\n     name: Clang 14\n-    runs-on: ubuntu-20.04\n+    runs-on: ubuntu-22.04\n     needs: linux-memory-leaks\n     env:\n       CC: /home/runner/work/llvm/bin/clang\n@@ -235,7 +235,7 @@ jobs:\n \n   linux-tarball:\n      name: Python 3 Tarball\n-     runs-on: ubuntu-20.04\n+     runs-on: ubuntu-22.04\n      needs: linux-memory-leaks\n      steps:\n      - uses: actions/checkout@v3\n@@ -274,7 +274,7 @@ jobs:\n \n   python-sqllogic:\n      name: Python SQLLogicTest Library (Linux)\n-     runs-on: ubuntu-20.04\n+     runs-on: ubuntu-22.04\n      env:\n         GEN: ninja\n         DUCKDEBUG: 1\n@@ -333,7 +333,7 @@ jobs:\n \n   storage-initialization:\n      name: Storage Initialization Verification\n-     runs-on: ubuntu-20.04\n+     runs-on: ubuntu-22.04\n      needs: linux-memory-leaks\n      env:\n        CC: gcc-10\n@@ -365,7 +365,7 @@ jobs:\n \n   extension-updating:\n     name: Extension updating test\n-    runs-on: ubuntu-20.04\n+    runs-on: ubuntu-22.04\n     needs: linux-memory-leaks\n     env:\n       CC: gcc-10\n@@ -451,7 +451,7 @@ jobs:\n \n   latest-storage:\n     name: Latest Storage\n-    runs-on: ubuntu-20.04\n+    runs-on: ubuntu-22.04\n     needs: linux-memory-leaks\n     env:\n       CC: gcc-10\n@@ -488,7 +488,7 @@ jobs:\n \n   vector-verification:\n     name: Vector Verification Tests (${{ matrix.vector_type }})\n-    runs-on: ubuntu-20.04\n+    runs-on: ubuntu-22.04\n     needs: linux-memory-leaks\n     strategy:\n       fail-fast: false\n@@ -568,7 +568,7 @@ jobs:\n \n   regression-test-memory-safety:\n    name: Regression Tests between safe and unsafe builds\n-   runs-on: ubuntu-20.04\n+   runs-on: ubuntu-22.04\n    needs: linux-memory-leaks\n    env:\n      CC: gcc-10\n@@ -693,7 +693,7 @@ jobs:\n \n   vector-sizes:\n     name: Vector Sizes\n-    runs-on: ubuntu-20.04\n+    runs-on: ubuntu-22.04\n     needs: linux-memory-leaks\n     env:\n       CC: gcc-10\n@@ -845,7 +845,7 @@ jobs:\n \n   codecov:\n     name: Code Coverage\n-    runs-on: ubuntu-20.04\n+    runs-on: ubuntu-22.04\n     needs: linux-memory-leaks\n     strategy:\n       fail-fast: false\n@@ -893,7 +893,7 @@ jobs:\n \n   linux-httpfs:\n     name: Linux HTTPFS\n-    runs-on: ubuntu-20.04\n+    runs-on: ubuntu-22.04\n     env:\n       CORE_EXTENSIONS: \"json;parquet;tpch;tpcds;httpfs\"\n       S3_TEST_SERVER_AVAILABLE: 1\ndiff --git a/.github/workflows/Python.yml b/.github/workflows/Python.yml\nindex b63b0b82caf7..b3608dc25498 100644\n--- a/.github/workflows/Python.yml\n+++ b/.github/workflows/Python.yml\n@@ -65,7 +65,7 @@ jobs:\n # This is just a sanity check of Python 3.10 running with Arrow\n   linux-python3-10:\n     name: Python 3.10 Linux\n-    runs-on: ubuntu-20.04\n+    runs-on: ubuntu-22.04\n \n     env:\n       CIBW_BUILD: 'cp39-manylinux_x86_64'\n@@ -435,7 +435,7 @@ jobs:\n      if: startsWith(github.ref, 'refs/tags/v') || github.ref == 'refs/heads/main'\n      name: PyPi Release Cleanup\n      needs: twine-upload\n-     runs-on: ubuntu-20.04\n+     runs-on: ubuntu-22.04\n      env:\n        PYPI_CLEANUP_USERNAME: 'mytherin'\n        PYPI_CLEANUP_PASSWORD: ${{secrets.PYPI_CLEANUP_PASSWORD}}\ndiff --git a/.github/workflows/Regression.yml b/.github/workflows/Regression.yml\nindex 9d840701299e..39b475d21d1e 100644\n--- a/.github/workflows/Regression.yml\n+++ b/.github/workflows/Regression.yml\n@@ -45,7 +45,7 @@ env:\n jobs:\n   regression-test-benchmark-runner:\n     name: Regression Tests\n-    runs-on: ubuntu-20.04\n+    runs-on: ubuntu-22.04\n     env:\n       CC: gcc-10\n       CXX: g++-10\n@@ -182,7 +182,7 @@ jobs:\n \n   regression-test-storage:\n     name: Storage Size Regression Test\n-    runs-on: ubuntu-20.04\n+    runs-on: ubuntu-22.04\n     env:\n       CC: gcc-10\n       CXX: g++-10\n@@ -262,7 +262,7 @@ jobs:\n \n   regression-test-binary-size:\n     name: Regression test binary size\n-    runs-on: ubuntu-20.04\n+    runs-on: ubuntu-22.04\n     env:\n       CC: gcc-10\n       CXX: g++-10\n@@ -304,7 +304,7 @@ jobs:\n \n   regression-test-plan-cost:\n     name: Regression Test Join Order Plan Cost\n-    runs-on: ubuntu-20.04\n+    runs-on: ubuntu-22.04\n     env:\n       CC: gcc-10\n       CXX: g++-10\ndiff --git a/extension/json/json_multi_file_info.cpp b/extension/json/json_multi_file_info.cpp\nindex 01da28d18a61..ca91fc941b55 100644\n--- a/extension/json/json_multi_file_info.cpp\n+++ b/extension/json/json_multi_file_info.cpp\n@@ -316,8 +316,32 @@ void JSONMultiFileInfo::BindReader(ClientContext &context, vector<LogicalType> &\n \t\t\tname_collision_count[col_name] = 0;\n \t\t}\n \t}\n-\t// FIXME: re-use readers created during auto-detection instead of clearing here\n-\tbind_data.union_readers.clear();\n+\tbool reuse_readers = true;\n+\tfor (auto &union_reader : bind_data.union_readers) {\n+\t\tif (!union_reader || !union_reader->reader) {\n+\t\t\t// not all readers have been initialized - don't re-use any\n+\t\t\treuse_readers = false;\n+\t\t\tbreak;\n+\t\t}\n+\t\tauto &json_reader = union_reader->reader->Cast<JSONReader>();\n+\t\tif (!json_reader.IsOpen()) {\n+\t\t\t// no open file-handle - close\n+\t\t\treuse_readers = false;\n+\t\t}\n+\t}\n+\tif (!reuse_readers) {\n+\t\tbind_data.union_readers.clear();\n+\t} else {\n+\t\t// re-use readers\n+\t\tfor (auto &union_reader : bind_data.union_readers) {\n+\t\t\tauto &json_reader = union_reader->reader->Cast<JSONReader>();\n+\t\t\tunion_reader->names = names;\n+\t\t\tunion_reader->types = return_types;\n+\t\t\tunion_reader->reader->columns =\n+\t\t\t    MultiFileReaderColumnDefinition::ColumnsFromNamesAndTypes(names, return_types);\n+\t\t\tjson_reader.Reset();\n+\t\t}\n+\t}\n }\n \n void JSONMultiFileInfo::FinalizeBindData(MultiFileBindData &multi_file_data) {\n@@ -427,8 +451,10 @@ bool JSONMultiFileInfo::TryInitializeScan(ClientContext &context, shared_ptr<Bas\n                                           GlobalTableFunctionState &gstate_p, LocalTableFunctionState &lstate_p) {\n \tauto &gstate = gstate_p.Cast<JSONGlobalTableFunctionState>().state;\n \tauto &lstate = lstate_p.Cast<JSONLocalTableFunctionState>().state;\n+\tauto &json_reader = reader->Cast<JSONReader>();\n+\n \tlstate.GetScanState().ResetForNextBuffer();\n-\treturn lstate.TryInitializeScan(gstate, reader->Cast<JSONReader>());\n+\treturn lstate.TryInitializeScan(gstate, json_reader);\n }\n \n void ReadJSONFunction(ClientContext &context, JSONReader &json_reader, JSONScanGlobalState &gstate,\ndiff --git a/extension/json/json_reader.cpp b/extension/json/json_reader.cpp\nindex bf3f705de769..dc63a7a3d641 100644\n--- a/extension/json/json_reader.cpp\n+++ b/extension/json/json_reader.cpp\n@@ -37,7 +37,7 @@ void JSONFileHandle::Reset() {\n \trequested_reads = 0;\n \tactual_reads = 0;\n \tlast_read_requested = false;\n-\tif (IsOpen() && !file_handle->IsPipe()) {\n+\tif (IsOpen() && !IsPipe()) {\n \t\tfile_handle->Reset();\n \t}\n }\n@@ -90,25 +90,12 @@ bool JSONFileHandle::GetPositionAndSize(idx_t &position, idx_t &size, idx_t requ\n \n void JSONFileHandle::ReadAtPosition(char *pointer, idx_t size, idx_t position,\n                                     optional_ptr<FileHandle> override_handle) {\n+\tif (IsPipe()) {\n+\t\tthrow InternalException(\"ReadAtPosition is not supported for pipes\");\n+\t}\n \tif (size != 0) {\n \t\tauto &handle = override_handle ? *override_handle.get() : *file_handle.get();\n-\t\tif (can_seek) {\n-\t\t\thandle.Read(pointer, size, position);\n-\t\t} else if (file_handle->IsPipe()) { // Cache the buffer\n-\t\t\thandle.Read(pointer, size, position);\n-\n-\t\t\tcached_buffers.emplace_back(allocator.Allocate(size));\n-\t\t\tmemcpy(cached_buffers.back().get(), pointer, size);\n-\t\t\tcached_size += size;\n-\t\t} else {\n-\t\t\tif (!cached_buffers.empty() || position < cached_size) {\n-\t\t\t\tReadFromCache(pointer, size, position);\n-\t\t\t}\n-\n-\t\t\tif (size != 0) {\n-\t\t\t\thandle.Read(pointer, size, position);\n-\t\t\t}\n-\t\t}\n+\t\thandle.Read(pointer, size, position);\n \t}\n \n \tconst auto incremented_actual_reads = ++actual_reads;\n@@ -127,26 +114,19 @@ bool JSONFileHandle::Read(char *pointer, idx_t &read_size, idx_t requested_size)\n \t\treturn false;\n \t}\n \n-\tif (can_seek) {\n-\t\tread_size = ReadInternal(pointer, requested_size);\n-\t\tread_position += read_size;\n-\t} else if (file_handle->IsPipe()) { // Cache the buffer\n-\t\tread_size = ReadInternal(pointer, requested_size);\n-\t\tif (read_size > 0) {\n-\t\t\tcached_buffers.emplace_back(allocator.Allocate(read_size));\n-\t\t\tmemcpy(cached_buffers.back().get(), pointer, read_size);\n-\t\t}\n-\t\tcached_size += read_size;\n-\t\tread_position += read_size;\n-\t} else {\n-\t\tread_size = 0;\n-\t\tif (!cached_buffers.empty() || read_position < cached_size) {\n-\t\t\tread_size += ReadFromCache(pointer, requested_size, read_position);\n-\t\t}\n-\t\tif (requested_size != 0) {\n-\t\t\tread_size += ReadInternal(pointer, requested_size);\n-\t\t}\n+\tread_size = 0;\n+\tif (!cached_buffers.empty() || read_position < cached_size) {\n+\t\tread_size += ReadFromCache(pointer, requested_size, read_position);\n+\t}\n+\n+\tauto temp_read_size = ReadInternal(pointer, requested_size);\n+\tif (IsPipe() && temp_read_size != 0) { // Cache the buffer\n+\t\tcached_buffers.emplace_back(allocator.Allocate(temp_read_size));\n+\t\tmemcpy(cached_buffers.back().get(), pointer, temp_read_size);\n+\t\tcached_size += temp_read_size;\n \t}\n+\tread_position += temp_read_size;\n+\tread_size += temp_read_size;\n \n \tif (read_size == 0) {\n \t\tlast_read_requested = true;\n@@ -724,8 +704,12 @@ void JSONReader::AutoDetect(Allocator &allocator, idx_t buffer_capacity) {\n \t\t    \"JSON auto-detection error in file \\\"%s\\\": Expected records, detected non-record JSON instead\", file_name);\n \t}\n \t// store the buffer in the file so it can be re-used by the first reader of the file\n-\tauto_detect_data = std::move(read_buffer);\n-\tauto_detect_data_size = read_size;\n+\tif (!file_handle->IsPipe()) {\n+\t\tauto_detect_data = std::move(read_buffer);\n+\t\tauto_detect_data_size = read_size;\n+\t} else {\n+\t\tfile_handle->Reset();\n+\t}\n }\n \n void JSONReader::ThrowObjectSizeError(const idx_t object_size) {\ndiff --git a/scripts/exported_symbols_check.py b/scripts/exported_symbols_check.py\nindex 984662e12b9e..ede58c3bf4e9 100644\n--- a/scripts/exported_symbols_check.py\n+++ b/scripts/exported_symbols_check.py\n@@ -13,8 +13,8 @@\n culprits = []\n \n whitelist = [\n-    '@@GLIBC',\n-    '@@CXXABI',\n+    '@GLIBC',\n+    '@CXXABI',\n     '__gnu_cxx::',\n     'std::',\n     'N6duckdb',\ndiff --git a/src/execution/operator/csv_scanner/buffer_manager/csv_buffer.cpp b/src/execution/operator/csv_scanner/buffer_manager/csv_buffer.cpp\nindex 8fcfad10340e..575d69d7d9bf 100644\n--- a/src/execution/operator/csv_scanner/buffer_manager/csv_buffer.cpp\n+++ b/src/execution/operator/csv_scanner/buffer_manager/csv_buffer.cpp\n@@ -4,7 +4,7 @@\n namespace duckdb {\n \n CSVBuffer::CSVBuffer(ClientContext &context, idx_t buffer_size_p, CSVFileHandle &file_handle,\n-                     idx_t &global_csv_current_position)\n+                     const idx_t &global_csv_current_position)\n     : context(context), requested_size(buffer_size_p), can_seek(file_handle.CanSeek()), is_pipe(file_handle.IsPipe()) {\n \tAllocateBuffer(buffer_size_p);\n \tauto buffer = Ptr();\n@@ -31,7 +31,7 @@ CSVBuffer::CSVBuffer(CSVFileHandle &file_handle, ClientContext &context, idx_t b\n \tlast_buffer = file_handle.FinishedReading();\n }\n \n-shared_ptr<CSVBuffer> CSVBuffer::Next(CSVFileHandle &file_handle, idx_t buffer_size, bool &has_seaked) {\n+shared_ptr<CSVBuffer> CSVBuffer::Next(CSVFileHandle &file_handle, idx_t buffer_size, bool &has_seaked) const {\n \tif (has_seaked) {\n \t\t// This means that at some point a reload was done, and we are currently on the incorrect position in our file\n \t\t// handle\ndiff --git a/src/execution/operator/csv_scanner/encode/csv_encoder.cpp b/src/execution/operator/csv_scanner/encode/csv_encoder.cpp\nindex 8a6c08032597..d57e95732467 100644\n--- a/src/execution/operator/csv_scanner/encode/csv_encoder.cpp\n+++ b/src/execution/operator/csv_scanner/encode/csv_encoder.cpp\n@@ -36,7 +36,7 @@ void CSVEncoderBuffer::Reset() {\n \tactual_encoded_buffer_size = 0;\n }\n \n-CSVEncoder::CSVEncoder(DBConfig &config, const string &encoding_name_to_find, idx_t buffer_size) {\n+CSVEncoder::CSVEncoder(const DBConfig &config, const string &encoding_name_to_find, idx_t buffer_size) {\n \tencoding_name = StringUtil::Lower(encoding_name_to_find);\n \tauto function = config.GetEncodeFunction(encoding_name_to_find);\n \tif (!function) {\ndiff --git a/src/execution/operator/csv_scanner/scanner/base_scanner.cpp b/src/execution/operator/csv_scanner/scanner/base_scanner.cpp\nindex 757598e140ee..41f5d50cfa4c 100644\n--- a/src/execution/operator/csv_scanner/scanner/base_scanner.cpp\n+++ b/src/execution/operator/csv_scanner/scanner/base_scanner.cpp\n@@ -11,9 +11,10 @@ ScannerResult::ScannerResult(CSVStates &states_p, CSVStateMachine &state_machine\n \n BaseScanner::BaseScanner(shared_ptr<CSVBufferManager> buffer_manager_p, shared_ptr<CSVStateMachine> state_machine_p,\n                          shared_ptr<CSVErrorHandler> error_handler_p, bool sniffing_p,\n-                         shared_ptr<CSVFileScan> csv_file_scan_p, CSVIterator iterator_p)\n+                         shared_ptr<CSVFileScan> csv_file_scan_p, const CSVIterator &iterator_p)\n     : csv_file_scan(std::move(csv_file_scan_p)), sniffing(sniffing_p), error_handler(std::move(error_handler_p)),\n-      state_machine(std::move(state_machine_p)), buffer_manager(std::move(buffer_manager_p)), iterator(iterator_p) {\n+      state_machine(std::move(state_machine_p)), states(), buffer_manager(std::move(buffer_manager_p)),\n+      iterator(iterator_p) {\n \tD_ASSERT(buffer_manager);\n \tD_ASSERT(state_machine);\n \t// Initialize current buffer handle\ndiff --git a/src/execution/operator/csv_scanner/scanner/csv_schema.cpp b/src/execution/operator/csv_scanner/scanner/csv_schema.cpp\nindex f99e46a9a614..866c9c1fdffa 100644\n--- a/src/execution/operator/csv_scanner/scanner/csv_schema.cpp\n+++ b/src/execution/operator/csv_scanner/scanner/csv_schema.cpp\n@@ -76,8 +76,8 @@ void CSVSchema::MergeSchemas(CSVSchema &other, bool null_padding) {\n \t}\n }\n \n-CSVSchema::CSVSchema(vector<string> &names, vector<LogicalType> &types, const string &file_path, idx_t rows_read_p,\n-                     const bool empty_p)\n+CSVSchema::CSVSchema(const vector<string> &names, const vector<LogicalType> &types, const string &file_path,\n+                     idx_t rows_read_p, const bool empty_p)\n     : rows_read(rows_read_p), empty(empty_p) {\n \tInitialize(names, types, file_path);\n }\ndiff --git a/src/execution/operator/csv_scanner/scanner/scanner_boundary.cpp b/src/execution/operator/csv_scanner/scanner/scanner_boundary.cpp\nindex b0511bec64ab..bdb324d61057 100644\n--- a/src/execution/operator/csv_scanner/scanner/scanner_boundary.cpp\n+++ b/src/execution/operator/csv_scanner/scanner/scanner_boundary.cpp\n@@ -13,7 +13,7 @@ CSVBoundary::CSVBoundary(idx_t buffer_idx_p, idx_t buffer_pos_p, idx_t boundary_\n CSVBoundary::CSVBoundary() : buffer_idx(0), buffer_pos(0), boundary_idx(0), end_pos(NumericLimits<idx_t>::Maximum()) {\n }\n \n-CSVIterator::CSVIterator() : is_set(false) {\n+CSVIterator::CSVIterator() : buffer_size(0), is_set(false) {\n }\n \n void CSVBoundary::Print() const {\ndiff --git a/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp b/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\nindex 770afa62ed20..0d6e2c9eb3f0 100644\n--- a/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\n+++ b/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\n@@ -970,7 +970,8 @@ StringValueScanner::StringValueScanner(idx_t scanner_idx_p, const shared_ptr<CSV\n       result(states, *state_machine, cur_buffer_handle, BufferAllocator::Get(buffer_manager->context), result_size,\n              iterator.pos.buffer_pos, *error_handler, iterator,\n              buffer_manager->context.client_data->debug_set_max_line_length, csv_file_scan, lines_read, sniffing,\n-             buffer_manager->GetFilePath(), scanner_idx_p) {\n+             buffer_manager->GetFilePath(), scanner_idx_p),\n+      start_pos(0) {\n \titerator.buffer_size = state_machine->options.buffer_size_option.GetValue();\n }\n \n@@ -982,7 +983,8 @@ StringValueScanner::StringValueScanner(const shared_ptr<CSVBufferManager> &buffe\n       result(states, *state_machine, cur_buffer_handle, Allocator::DefaultAllocator(), result_size,\n              iterator.pos.buffer_pos, *error_handler, iterator,\n              buffer_manager->context.client_data->debug_set_max_line_length, csv_file_scan, lines_read, sniffing,\n-             buffer_manager->GetFilePath(), 0) {\n+             buffer_manager->GetFilePath(), 0),\n+      start_pos(0) {\n \titerator.buffer_size = state_machine->options.buffer_size_option.GetValue();\n }\n \ndiff --git a/src/execution/operator/csv_scanner/sniffer/type_refinement.cpp b/src/execution/operator/csv_scanner/sniffer/type_refinement.cpp\nindex 8d3e268450c4..98d668661dc7 100644\n--- a/src/execution/operator/csv_scanner/sniffer/type_refinement.cpp\n+++ b/src/execution/operator/csv_scanner/sniffer/type_refinement.cpp\n@@ -2,7 +2,7 @@\n #include \"duckdb/execution/operator/csv_scanner/csv_casting.hpp\"\n \n namespace duckdb {\n-bool CSVSniffer::TryCastVector(Vector &parse_chunk_col, idx_t size, const LogicalType &sql_type) {\n+bool CSVSniffer::TryCastVector(Vector &parse_chunk_col, idx_t size, const LogicalType &sql_type) const {\n \tauto &sniffing_state_machine = best_candidate->GetStateMachine();\n \t// try vector-cast from string to sql_type\n \tVector dummy_result(sql_type, size);\ndiff --git a/src/include/duckdb/execution/operator/csv_scanner/base_scanner.hpp b/src/include/duckdb/execution/operator/csv_scanner/base_scanner.hpp\nindex b2d9dae68a39..85c37db87b66 100644\n--- a/src/include/duckdb/execution/operator/csv_scanner/base_scanner.hpp\n+++ b/src/include/duckdb/execution/operator/csv_scanner/base_scanner.hpp\n@@ -116,7 +116,7 @@ class BaseScanner {\n public:\n \texplicit BaseScanner(shared_ptr<CSVBufferManager> buffer_manager, shared_ptr<CSVStateMachine> state_machine,\n \t                     shared_ptr<CSVErrorHandler> error_handler, bool sniffing = false,\n-\t                     shared_ptr<CSVFileScan> csv_file_scan = nullptr, CSVIterator iterator = {});\n+\t                     shared_ptr<CSVFileScan> csv_file_scan = nullptr, const CSVIterator &iterator = {});\n \n \tvirtual ~BaseScanner() = default;\n \ndiff --git a/src/include/duckdb/execution/operator/csv_scanner/csv_buffer.hpp b/src/include/duckdb/execution/operator/csv_scanner/csv_buffer.hpp\nindex 586867043291..7ee7d60a3202 100644\n--- a/src/include/duckdb/execution/operator/csv_scanner/csv_buffer.hpp\n+++ b/src/include/duckdb/execution/operator/csv_scanner/csv_buffer.hpp\n@@ -44,14 +44,14 @@ class CSVBuffer {\n public:\n \t//! Constructor for Initial Buffer\n \tCSVBuffer(ClientContext &context, idx_t buffer_size_p, CSVFileHandle &file_handle,\n-\t          idx_t &global_csv_current_position);\n+\t          const idx_t &global_csv_current_position);\n \n \t//! Constructor for `Next()` Buffers\n \tCSVBuffer(CSVFileHandle &file_handle, ClientContext &context, idx_t buffer_size, idx_t global_csv_current_position,\n \t          idx_t buffer_idx);\n \n \t//! Creates a new buffer with the next part of the CSV File\n-\tshared_ptr<CSVBuffer> Next(CSVFileHandle &file_handle, idx_t buffer_size, bool &has_seeked);\n+\tshared_ptr<CSVBuffer> Next(CSVFileHandle &file_handle, idx_t buffer_size, bool &has_seeked) const;\n \n \t//! Gets the buffer actual size\n \tidx_t GetBufferSize() const;\n@@ -66,7 +66,7 @@ class CSVBuffer {\n \t//! Wrapper for the Pin Function, if it can seek, it means that the buffer might have been destroyed, hence we must\n \t//! Scan it from the disk file again.\n \tshared_ptr<CSVBufferHandle> Pin(CSVFileHandle &file_handle, bool &has_seeked);\n-\t//! Wrapper for the unpin\n+\t//! Wrapper for unpin\n \tvoid Unpin();\n \tchar *Ptr() {\n \t\treturn char_ptr_cast(handle.Ptr());\ndiff --git a/src/include/duckdb/execution/operator/csv_scanner/csv_schema.hpp b/src/include/duckdb/execution/operator/csv_scanner/csv_schema.hpp\nindex 3e7a90c99116..6048185c1b24 100644\n--- a/src/include/duckdb/execution/operator/csv_scanner/csv_schema.hpp\n+++ b/src/include/duckdb/execution/operator/csv_scanner/csv_schema.hpp\n@@ -14,7 +14,7 @@\n namespace duckdb {\n //! Basic CSV Column Info\n struct CSVColumnInfo {\n-\tCSVColumnInfo(string &name_p, LogicalType &type_p) : name(name_p), type(type_p) {\n+\tCSVColumnInfo(const string &name_p, const LogicalType &type_p) : name(name_p), type(type_p) {\n \t}\n \tstring name;\n \tLogicalType type;\n@@ -25,7 +25,7 @@ struct CSVSchema {\n \texplicit CSVSchema(const bool empty = false) : empty(empty) {\n \t}\n \n-\tCSVSchema(vector<string> &names, vector<LogicalType> &types, const string &file_path, idx_t rows_read,\n+\tCSVSchema(const vector<string> &names, const vector<LogicalType> &types, const string &file_path, idx_t rows_read,\n \t          const bool empty = false);\n \n \t//! Initializes the schema based on names and types\ndiff --git a/src/include/duckdb/execution/operator/csv_scanner/encode/csv_encoder.hpp b/src/include/duckdb/execution/operator/csv_scanner/encode/csv_encoder.hpp\nindex 764d9694dc64..1ced26fca470 100644\n--- a/src/include/duckdb/execution/operator/csv_scanner/encode/csv_encoder.hpp\n+++ b/src/include/duckdb/execution/operator/csv_scanner/encode/csv_encoder.hpp\n@@ -46,7 +46,7 @@ struct CSVEncoderBuffer {\n class CSVEncoder {\n public:\n \t//! Constructor, basically takes an encoding and the output buffer size\n-\tCSVEncoder(DBConfig &config, const string &encoding_name, idx_t buffer_size);\n+\tCSVEncoder(const DBConfig &config, const string &encoding_name, idx_t buffer_size);\n \t//! Main encode function, it reads the file into an encoded buffer and converts it to the output buffer\n \tidx_t Encode(FileHandle &file_handle_input, char *output_buffer, const idx_t decoded_buffer_size);\n \tstring encoding_name;\ndiff --git a/src/include/duckdb/execution/operator/csv_scanner/sniffer/csv_sniffer.hpp b/src/include/duckdb/execution/operator/csv_scanner/sniffer/csv_sniffer.hpp\nindex b1f9df8332e8..8b42cdeab924 100644\n--- a/src/include/duckdb/execution/operator/csv_scanner/sniffer/csv_sniffer.hpp\n+++ b/src/include/duckdb/execution/operator/csv_scanner/sniffer/csv_sniffer.hpp\n@@ -225,7 +225,7 @@ class CSVSniffer {\n \t//! ------------------ Type Refinement ------------------ //\n \t//! ------------------------------------------------------//\n \tvoid RefineTypes();\n-\tbool TryCastVector(Vector &parse_chunk_col, idx_t size, const LogicalType &sql_type);\n+\tbool TryCastVector(Vector &parse_chunk_col, idx_t size, const LogicalType &sql_type) const;\n \tvector<LogicalType> detected_types;\n \t//! If when finding a SQLNULL type in type detection we default it to varchar\n \tconst bool default_null_to_varchar;\ndiff --git a/src/include/duckdb/execution/operator/csv_scanner/string_value_scanner.hpp b/src/include/duckdb/execution/operator/csv_scanner/string_value_scanner.hpp\nindex 6d196fc666bd..a18a0eb5f0bd 100644\n--- a/src/include/duckdb/execution/operator/csv_scanner/string_value_scanner.hpp\n+++ b/src/include/duckdb/execution/operator/csv_scanner/string_value_scanner.hpp\n@@ -121,8 +121,8 @@ class LineError {\n };\n \n struct ParseTypeInfo {\n-\tParseTypeInfo() {};\n-\tParseTypeInfo(const LogicalType &type, bool validate_utf_8_p) : validate_utf8(validate_utf_8_p) {\n+\tParseTypeInfo() : validate_utf8(false), type_id(), internal_type(), scale(0), width(0) {};\n+\tParseTypeInfo(const LogicalType &type, const bool validate_utf_8_p) : validate_utf8(validate_utf_8_p) {\n \t\ttype_id = type.id();\n \t\tinternal_type = type.InternalType();\n \t\tif (type.id() == LogicalTypeId::DECIMAL) {\ndiff --git a/src/include/duckdb/main/client_context_state.hpp b/src/include/duckdb/main/client_context_state.hpp\nindex e7a10593f3e2..80cdc8b8f33c 100644\n--- a/src/include/duckdb/main/client_context_state.hpp\n+++ b/src/include/duckdb/main/client_context_state.hpp\n@@ -80,6 +80,10 @@ class ClientContextState {\n \t}\n \tvirtual void WriteProfilingInformation(std::ostream &ss) {\n \t}\n+\tvirtual void OnTaskStart(ClientContext &context) {\n+\t}\n+\tvirtual void OnTaskStop(ClientContext &context) {\n+\t}\n \n public:\n \ttemplate <class TARGET>\ndiff --git a/src/include/duckdb/parallel/executor_task.hpp b/src/include/duckdb/parallel/executor_task.hpp\nindex d4d483b88b3f..1790b5014cb5 100644\n--- a/src/include/duckdb/parallel/executor_task.hpp\n+++ b/src/include/duckdb/parallel/executor_task.hpp\n@@ -9,10 +9,10 @@\n #pragma once\n \n #include \"duckdb/parallel/task.hpp\"\n-#include \"duckdb/parallel/event.hpp\"\n #include \"duckdb/common/optional_ptr.hpp\"\n \n namespace duckdb {\n+class Event;\n class PhysicalOperator;\n class ThreadContext;\n \n@@ -34,6 +34,9 @@ class ExecutorTask : public Task {\n \tunique_ptr<ThreadContext> thread_context;\n \toptional_ptr<const PhysicalOperator> op;\n \n+private:\n+\tClientContext &context;\n+\n public:\n \tvirtual TaskExecutionResult ExecuteTask(TaskExecutionMode mode) = 0;\n \tTaskExecutionResult Execute(TaskExecutionMode mode) override;\ndiff --git a/src/include/duckdb/parallel/pipeline.hpp b/src/include/duckdb/parallel/pipeline.hpp\nindex 34dcdd4474b3..dd1614145e18 100644\n--- a/src/include/duckdb/parallel/pipeline.hpp\n+++ b/src/include/duckdb/parallel/pipeline.hpp\n@@ -20,7 +20,6 @@\n namespace duckdb {\n \n class Executor;\n-class Event;\n class MetaPipeline;\n class PipelineExecutor;\n class Pipeline;\ndiff --git a/src/include/duckdb/parallel/task_executor.hpp b/src/include/duckdb/parallel/task_executor.hpp\nindex 191b6df9d3e6..912ad80b3f6f 100644\n--- a/src/include/duckdb/parallel/task_executor.hpp\n+++ b/src/include/duckdb/parallel/task_executor.hpp\n@@ -10,6 +10,7 @@\n \n #include \"duckdb/common/common.hpp\"\n #include \"duckdb/common/atomic.hpp\"\n+#include \"duckdb/common/optional_ptr.hpp\"\n #include \"duckdb/parallel/task.hpp\"\n #include \"duckdb/execution/task_error_manager.hpp\"\n \n@@ -47,6 +48,8 @@ class TaskExecutor {\n \tunique_ptr<ProducerToken> token;\n \tatomic<idx_t> completed_tasks;\n \tatomic<idx_t> total_tasks;\n+\tfriend class BaseExecutorTask;\n+\toptional_ptr<ClientContext> context;\n };\n \n class BaseExecutorTask : public Task {\ndiff --git a/src/include/duckdb/parallel/task_notifier.hpp b/src/include/duckdb/parallel/task_notifier.hpp\nnew file mode 100644\nindex 000000000000..6bf34b3c043f\n--- /dev/null\n+++ b/src/include/duckdb/parallel/task_notifier.hpp\n@@ -0,0 +1,27 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/parallel/task_notifier.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#pragma once\n+\n+#include \"duckdb/common/optional_ptr.hpp\"\n+\n+namespace duckdb {\n+class ClientContext;\n+\n+//! The TaskNotifier notifies ClientContextState listener about started / stopped tasks\n+class TaskNotifier {\n+public:\n+\texplicit TaskNotifier(optional_ptr<ClientContext> context_p);\n+\n+\t~TaskNotifier();\n+\n+private:\n+\toptional_ptr<ClientContext> context;\n+};\n+\n+} // namespace duckdb\ndiff --git a/src/include/duckdb/parallel/task_scheduler.hpp b/src/include/duckdb/parallel/task_scheduler.hpp\nindex c40e8e10d34d..ae1b52a956e7 100644\n--- a/src/include/duckdb/parallel/task_scheduler.hpp\n+++ b/src/include/duckdb/parallel/task_scheduler.hpp\n@@ -68,6 +68,10 @@ class TaskScheduler {\n \t//! Returns the number of threads\n \tDUCKDB_API int32_t NumberOfThreads();\n \n+\tidx_t GetNumberOfTasks() const;\n+\tidx_t GetProducerCount() const;\n+\tidx_t GetTaskCountForProducer(ProducerToken &token) const;\n+\n \t//! Send signals to n threads, signalling for them to wake up and attempt to execute a task\n \tvoid Signal(idx_t n);\n \ndiff --git a/src/include/duckdb/storage/checkpoint/table_data_writer.hpp b/src/include/duckdb/storage/checkpoint/table_data_writer.hpp\nindex a606b5615197..90b5e753261d 100644\n--- a/src/include/duckdb/storage/checkpoint/table_data_writer.hpp\n+++ b/src/include/duckdb/storage/checkpoint/table_data_writer.hpp\n@@ -23,7 +23,7 @@ class TableStatistics;\n //! Abstraction will support, for example: tiering, versioning, or splitting into multiple block managers.\n class TableDataWriter {\n public:\n-\texplicit TableDataWriter(TableCatalogEntry &table);\n+\texplicit TableDataWriter(TableCatalogEntry &table, optional_ptr<ClientContext> client_context);\n \tvirtual ~TableDataWriter();\n \n public:\n@@ -39,9 +39,11 @@ class TableDataWriter {\n \n \tTaskScheduler &GetScheduler();\n \tDatabaseInstance &GetDatabase();\n+\toptional_ptr<ClientContext> GetClientContext();\n \n protected:\n \tDuckTableEntry &table;\n+\toptional_ptr<ClientContext> client_context;\n \t//! Pointers to the start of each row group.\n \tvector<RowGroupPointer> row_group_pointers;\n };\ndiff --git a/src/include/duckdb/storage/checkpoint_manager.hpp b/src/include/duckdb/storage/checkpoint_manager.hpp\nindex cb0455deb258..3bb11912854b 100644\n--- a/src/include/duckdb/storage/checkpoint_manager.hpp\n+++ b/src/include/duckdb/storage/checkpoint_manager.hpp\n@@ -97,7 +97,8 @@ class SingleFileCheckpointWriter final : public CheckpointWriter {\n \tfriend class SingleFileTableDataWriter;\n \n public:\n-\tSingleFileCheckpointWriter(AttachedDatabase &db, BlockManager &block_manager, CheckpointType checkpoint_type);\n+\tSingleFileCheckpointWriter(optional_ptr<ClientContext> client_context, AttachedDatabase &db,\n+\t                           BlockManager &block_manager, CheckpointType checkpoint_type);\n \n \t//! Checkpoint the current state of the WAL and flush it to the main storage. This should be called BEFORE any\n \t//! connection is available because right now the checkpointing cannot be done online. (TODO)\n@@ -112,10 +113,15 @@ class SingleFileCheckpointWriter final : public CheckpointWriter {\n \t\treturn checkpoint_type;\n \t}\n \n+\toptional_ptr<ClientContext> GetClientContext() const {\n+\t\treturn client_context;\n+\t}\n+\n public:\n \tvoid WriteTable(TableCatalogEntry &table, Serializer &serializer) override;\n \n private:\n+\toptional_ptr<ClientContext> client_context;\n \t//! The metadata writer is responsible for writing schema information\n \tunique_ptr<MetadataWriter> metadata_writer;\n \t//! The table data writer is responsible for writing the DataPointers used by the table chunks\ndiff --git a/src/include/duckdb/storage/storage_manager.hpp b/src/include/duckdb/storage/storage_manager.hpp\nindex de820437c395..e209ca95a7c4 100644\n--- a/src/include/duckdb/storage/storage_manager.hpp\n+++ b/src/include/duckdb/storage/storage_manager.hpp\n@@ -100,7 +100,8 @@ class StorageManager {\n \tvirtual bool AutomaticCheckpoint(idx_t estimated_wal_bytes) = 0;\n \tvirtual unique_ptr<StorageCommitState> GenStorageCommitState(WriteAheadLog &wal) = 0;\n \tvirtual bool IsCheckpointClean(MetaBlockPointer checkpoint_id) = 0;\n-\tvirtual void CreateCheckpoint(CheckpointOptions options = CheckpointOptions()) = 0;\n+\tvirtual void CreateCheckpoint(optional_ptr<ClientContext> client_context,\n+\t                              CheckpointOptions options = CheckpointOptions()) = 0;\n \tvirtual DatabaseSize GetDatabaseSize() = 0;\n \tvirtual vector<MetadataBlockInfo> GetMetadataInfo() = 0;\n \tvirtual shared_ptr<TableIOManager> GetTableIOManager(BoundCreateTableInfo *info) = 0;\n@@ -159,7 +160,7 @@ class SingleFileStorageManager : public StorageManager {\n \tbool AutomaticCheckpoint(idx_t estimated_wal_bytes) override;\n \tunique_ptr<StorageCommitState> GenStorageCommitState(WriteAheadLog &wal) override;\n \tbool IsCheckpointClean(MetaBlockPointer checkpoint_id) override;\n-\tvoid CreateCheckpoint(CheckpointOptions options) override;\n+\tvoid CreateCheckpoint(optional_ptr<ClientContext> client_context, CheckpointOptions options) override;\n \tDatabaseSize GetDatabaseSize() override;\n \tvector<MetadataBlockInfo> GetMetadataInfo() override;\n \tshared_ptr<TableIOManager> GetTableIOManager(BoundCreateTableInfo *info) override;\ndiff --git a/src/main/attached_database.cpp b/src/main/attached_database.cpp\nindex 5fb160e842f2..64c80df560e2 100644\n--- a/src/main/attached_database.cpp\n+++ b/src/main/attached_database.cpp\n@@ -247,7 +247,7 @@ void AttachedDatabase::Close() {\n \t\t\t}\n \t\t\tCheckpointOptions options;\n \t\t\toptions.wal_action = CheckpointWALAction::DELETE_WAL;\n-\t\t\tstorage->CreateCheckpoint(options);\n+\t\t\tstorage->CreateCheckpoint(nullptr, options);\n \t\t}\n \t} catch (...) { // NOLINT\n \t}\ndiff --git a/src/main/capi/duckdb-c.cpp b/src/main/capi/duckdb-c.cpp\nindex ad47d7448faa..f8718913a363 100644\n--- a/src/main/capi/duckdb-c.cpp\n+++ b/src/main/capi/duckdb-c.cpp\n@@ -35,7 +35,11 @@ duckdb_state duckdb_open_internal(DBInstanceCacheWrapper *cache, const char *pat\n \t\t}\n \n \t\tif (cache) {\n-\t\t\twrapper->database = cache->instance_cache->GetOrCreateInstance(path, *db_config, true);\n+\t\t\tduckdb::string path_str;\n+\t\t\tif (path) {\n+\t\t\t\tpath_str = path;\n+\t\t\t}\n+\t\t\twrapper->database = cache->instance_cache->GetOrCreateInstance(path_str, *db_config, true);\n \t\t} else {\n \t\t\twrapper->database = duckdb::make_shared_ptr<DuckDB>(path, db_config);\n \t\t}\ndiff --git a/src/optimizer/join_order/query_graph_manager.cpp b/src/optimizer/join_order/query_graph_manager.cpp\nindex 6850508a6997..9b3568245ab7 100644\n--- a/src/optimizer/join_order/query_graph_manager.cpp\n+++ b/src/optimizer/join_order/query_graph_manager.cpp\n@@ -265,7 +265,6 @@ GenerateJoinRelation QueryGraphManager::GenerateJoins(vector<unique_ptr<LogicalO\n \t\t\t\t\tbreak;\n \t\t\t\t}\n \t\t\t}\n-\n \t\t\tauto join = make_uniq<LogicalComparisonJoin>(chosen_filter->join_type);\n \t\t\t// Here we optimize build side probe side. Our build side is the right side\n \t\t\t// So the right plans should have lower cardinalities.\n@@ -288,8 +287,9 @@ GenerateJoinRelation QueryGraphManager::GenerateJoins(vector<unique_ptr<LogicalO\n \t\t\t\tbool invert = !JoinRelationSet::IsSubset(*left.set, *f->left_set);\n \t\t\t\t// If the left and right set are inverted AND it is a semi or anti join\n \t\t\t\t// swap left and right children back.\n+\n \t\t\t\tif (invert && (f->join_type == JoinType::SEMI || f->join_type == JoinType::ANTI)) {\n-\t\t\t\t\tstd::swap(left, right);\n+\t\t\t\t\tstd::swap(join->children[0], join->children[1]);\n \t\t\t\t\tinvert = false;\n \t\t\t\t}\n \ndiff --git a/src/parallel/CMakeLists.txt b/src/parallel/CMakeLists.txt\nindex 61e84816eec6..ee4d7f865324 100644\n--- a/src/parallel/CMakeLists.txt\n+++ b/src/parallel/CMakeLists.txt\n@@ -15,6 +15,7 @@ add_library_unity(\n   pipeline_initialize_event.cpp\n   pipeline_prepare_finish_event.cpp\n   task_executor.cpp\n+  task_notifier.cpp\n   task_scheduler.cpp\n   thread_context.cpp)\n set(ALL_OBJECT_FILES\ndiff --git a/src/parallel/executor_task.cpp b/src/parallel/executor_task.cpp\nindex ebd462f93dd2..9c0db7609143 100644\n--- a/src/parallel/executor_task.cpp\n+++ b/src/parallel/executor_task.cpp\n@@ -1,4 +1,5 @@\n-#include \"duckdb/parallel/task.hpp\"\n+#include \"duckdb/parallel/executor_task.hpp\"\n+#include \"duckdb/parallel/task_notifier.hpp\"\n #include \"duckdb/execution/executor.hpp\"\n #include \"duckdb/main/client_context.hpp\"\n #include \"duckdb/parallel/thread_context.hpp\"\n@@ -6,13 +7,13 @@\n namespace duckdb {\n \n ExecutorTask::ExecutorTask(Executor &executor_p, shared_ptr<Event> event_p)\n-    : executor(executor_p), event(std::move(event_p)) {\n+    : executor(executor_p), event(std::move(event_p)), context(executor_p.context) {\n \texecutor.RegisterTask();\n }\n \n-ExecutorTask::ExecutorTask(ClientContext &context, shared_ptr<Event> event_p, const PhysicalOperator &op_p)\n-    : executor(Executor::Get(context)), event(std::move(event_p)), op(&op_p) {\n-\tthread_context = make_uniq<ThreadContext>(context);\n+ExecutorTask::ExecutorTask(ClientContext &context_p, shared_ptr<Event> event_p, const PhysicalOperator &op_p)\n+    : executor(Executor::Get(context_p)), event(std::move(event_p)), op(&op_p), context(context_p) {\n+\tthread_context = make_uniq<ThreadContext>(context_p);\n \texecutor.RegisterTask();\n }\n \n@@ -38,6 +39,7 @@ TaskExecutionResult ExecutorTask::Execute(TaskExecutionMode mode) {\n \t\tif (thread_context) {\n \t\t\tTaskExecutionResult result;\n \t\t\tdo {\n+\t\t\t\tTaskNotifier task_notifier {context};\n \t\t\t\tthread_context->profiler.StartOperator(op);\n \t\t\t\t// to allow continuous profiling, always execute in small steps\n \t\t\t\tresult = ExecuteTask(TaskExecutionMode::PROCESS_PARTIAL);\n@@ -46,7 +48,9 @@ TaskExecutionResult ExecutorTask::Execute(TaskExecutionMode mode) {\n \t\t\t} while (mode == TaskExecutionMode::PROCESS_ALL && result == TaskExecutionResult::TASK_NOT_FINISHED);\n \t\t\treturn result;\n \t\t} else {\n-\t\t\treturn ExecuteTask(mode);\n+\t\t\tTaskNotifier task_notifier {context};\n+\t\t\tauto result = ExecuteTask(mode);\n+\t\t\treturn result;\n \t\t}\n \t} catch (std::exception &ex) {\n \t\texecutor.PushError(ErrorData(ex));\ndiff --git a/src/parallel/task_executor.cpp b/src/parallel/task_executor.cpp\nindex eef4d28ab142..10c4a9e9240d 100644\n--- a/src/parallel/task_executor.cpp\n+++ b/src/parallel/task_executor.cpp\n@@ -1,4 +1,5 @@\n #include \"duckdb/parallel/task_executor.hpp\"\n+#include \"duckdb/parallel/task_notifier.hpp\"\n #include \"duckdb/parallel/task_scheduler.hpp\"\n \n namespace duckdb {\n@@ -7,7 +8,8 @@ TaskExecutor::TaskExecutor(TaskScheduler &scheduler)\n     : scheduler(scheduler), token(scheduler.CreateProducer()), completed_tasks(0), total_tasks(0) {\n }\n \n-TaskExecutor::TaskExecutor(ClientContext &context) : TaskExecutor(TaskScheduler::GetScheduler(context)) {\n+TaskExecutor::TaskExecutor(ClientContext &context_p) : TaskExecutor(TaskScheduler::GetScheduler(context_p)) {\n+\tcontext = context_p;\n }\n \n TaskExecutor::~TaskExecutor() {\n@@ -69,6 +71,7 @@ TaskExecutionResult BaseExecutorTask::Execute(TaskExecutionMode mode) {\n \t\treturn TaskExecutionResult::TASK_FINISHED;\n \t}\n \ttry {\n+\t\tTaskNotifier task_notifier {executor.context};\n \t\tExecuteTask();\n \t\texecutor.FinishTask();\n \t\treturn TaskExecutionResult::TASK_FINISHED;\ndiff --git a/src/parallel/task_notifier.cpp b/src/parallel/task_notifier.cpp\nnew file mode 100644\nindex 000000000000..012afb548c41\n--- /dev/null\n+++ b/src/parallel/task_notifier.cpp\n@@ -0,0 +1,23 @@\n+#include \"duckdb/parallel/task_notifier.hpp\"\n+#include \"duckdb/main/client_context.hpp\"\n+#include \"duckdb/main/client_context_state.hpp\"\n+\n+namespace duckdb {\n+\n+TaskNotifier::TaskNotifier(optional_ptr<ClientContext> context_p) : context(context_p) {\n+\tif (context) {\n+\t\tfor (auto &state : context->registered_state->States()) {\n+\t\t\tstate->OnTaskStart(*context);\n+\t\t}\n+\t}\n+}\n+\n+TaskNotifier::~TaskNotifier() {\n+\tif (context) {\n+\t\tfor (auto &state : context->registered_state->States()) {\n+\t\t\tstate->OnTaskStop(*context);\n+\t\t}\n+\t}\n+}\n+\n+} // namespace duckdb\ndiff --git a/src/parallel/task_scheduler.cpp b/src/parallel/task_scheduler.cpp\nindex fd6671a3e161..22bba36a08d4 100644\n--- a/src/parallel/task_scheduler.cpp\n+++ b/src/parallel/task_scheduler.cpp\n@@ -284,6 +284,39 @@ int32_t TaskScheduler::NumberOfThreads() {\n \treturn current_thread_count.load();\n }\n \n+idx_t TaskScheduler::GetNumberOfTasks() const {\n+#ifndef DUCKDB_NO_THREADS\n+\treturn queue->q.size_approx();\n+#else\n+\tidx_t task_count = 0;\n+\tfor (auto &producer : queue->q) {\n+\t\ttask_count += producer.second.size();\n+\t}\n+\treturn task_count;\n+#endif\n+}\n+\n+idx_t TaskScheduler::GetProducerCount() const {\n+#ifndef DUCKDB_NO_THREADS\n+\treturn queue->q.size_producers_approx();\n+#else\n+\treturn queue->q.size();\n+#endif\n+}\n+\n+idx_t TaskScheduler::GetTaskCountForProducer(ProducerToken &token) const {\n+#ifndef DUCKDB_NO_THREADS\n+\tlock_guard<mutex> producer_lock(token.producer_lock);\n+\treturn queue->q.size_producer_approx(token.token->queue_token);\n+#else\n+\tconst auto it = queue->q.find(std::ref(*token.token));\n+\tif (it == queue->q.end()) {\n+\t\treturn 0;\n+\t}\n+\treturn it->second.size();\n+#endif\n+}\n+\n void TaskScheduler::SetThreads(idx_t total_threads, idx_t external_threads) {\n \tif (total_threads == 0) {\n \t\tthrow SyntaxException(\"Number of threads must be positive!\");\ndiff --git a/src/storage/checkpoint/table_data_writer.cpp b/src/storage/checkpoint/table_data_writer.cpp\nindex 07bf9781ad07..d60ac7fa11a9 100644\n--- a/src/storage/checkpoint/table_data_writer.cpp\n+++ b/src/storage/checkpoint/table_data_writer.cpp\n@@ -10,7 +10,8 @@\n \n namespace duckdb {\n \n-TableDataWriter::TableDataWriter(TableCatalogEntry &table_p) : table(table_p.Cast<DuckTableEntry>()) {\n+TableDataWriter::TableDataWriter(TableCatalogEntry &table_p, optional_ptr<ClientContext> client_context_p)\n+    : table(table_p.Cast<DuckTableEntry>()), client_context(client_context_p) {\n \tD_ASSERT(table_p.IsDuckTable());\n }\n \n@@ -40,7 +41,8 @@ DatabaseInstance &TableDataWriter::GetDatabase() {\n \n SingleFileTableDataWriter::SingleFileTableDataWriter(SingleFileCheckpointWriter &checkpoint_manager,\n                                                      TableCatalogEntry &table, MetadataWriter &table_data_writer)\n-    : TableDataWriter(table), checkpoint_manager(checkpoint_manager), table_data_writer(table_data_writer) {\n+    : TableDataWriter(table, checkpoint_manager.GetClientContext()), checkpoint_manager(checkpoint_manager),\n+      table_data_writer(table_data_writer) {\n }\n \n unique_ptr<RowGroupWriter> SingleFileTableDataWriter::GetRowGroupWriter(RowGroup &row_group) {\ndiff --git a/src/storage/checkpoint_manager.cpp b/src/storage/checkpoint_manager.cpp\nindex ab2da7e51128..4dee9e0e8597 100644\n--- a/src/storage/checkpoint_manager.cpp\n+++ b/src/storage/checkpoint_manager.cpp\n@@ -36,10 +36,11 @@ namespace duckdb {\n \n void ReorderTableEntries(catalog_entry_vector_t &tables);\n \n-SingleFileCheckpointWriter::SingleFileCheckpointWriter(AttachedDatabase &db, BlockManager &block_manager,\n+SingleFileCheckpointWriter::SingleFileCheckpointWriter(optional_ptr<ClientContext> client_context_p,\n+                                                       AttachedDatabase &db, BlockManager &block_manager,\n                                                        CheckpointType checkpoint_type)\n-    : CheckpointWriter(db), partial_block_manager(block_manager, PartialBlockType::FULL_CHECKPOINT),\n-      checkpoint_type(checkpoint_type) {\n+    : CheckpointWriter(db), client_context(client_context_p),\n+      partial_block_manager(block_manager, PartialBlockType::FULL_CHECKPOINT), checkpoint_type(checkpoint_type) {\n }\n \n BlockManager &SingleFileCheckpointWriter::GetBlockManager() {\ndiff --git a/src/storage/storage_manager.cpp b/src/storage/storage_manager.cpp\nindex cb6c654e5fe2..a4109987c50b 100644\n--- a/src/storage/storage_manager.cpp\n+++ b/src/storage/storage_manager.cpp\n@@ -355,7 +355,7 @@ bool SingleFileStorageManager::IsCheckpointClean(MetaBlockPointer checkpoint_id)\n \treturn block_manager->IsRootBlock(checkpoint_id);\n }\n \n-void SingleFileStorageManager::CreateCheckpoint(CheckpointOptions options) {\n+void SingleFileStorageManager::CreateCheckpoint(optional_ptr<ClientContext> client_context, CheckpointOptions options) {\n \tif (InMemory() || read_only || !load_complete) {\n \t\treturn;\n \t}\n@@ -366,7 +366,7 @@ void SingleFileStorageManager::CreateCheckpoint(CheckpointOptions options) {\n \tif (GetWALSize() > 0 || config.options.force_checkpoint || options.action == CheckpointAction::ALWAYS_CHECKPOINT) {\n \t\t// we only need to checkpoint if there is anything in the WAL\n \t\ttry {\n-\t\t\tSingleFileCheckpointWriter checkpointer(db, *block_manager, options.type);\n+\t\t\tSingleFileCheckpointWriter checkpointer(client_context, db, *block_manager, options.type);\n \t\t\tcheckpointer.CreateCheckpoint();\n \t\t} catch (std::exception &ex) {\n \t\t\tErrorData error(ex);\ndiff --git a/src/transaction/duck_transaction_manager.cpp b/src/transaction/duck_transaction_manager.cpp\nindex 15248dabd776..68b2ff4e18b5 100644\n--- a/src/transaction/duck_transaction_manager.cpp\n+++ b/src/transaction/duck_transaction_manager.cpp\n@@ -194,7 +194,7 @@ void DuckTransactionManager::Checkpoint(ClientContext &context, bool force) {\n \t\t// we cannot do a full checkpoint if any transaction needs to read old data\n \t\toptions.type = CheckpointType::CONCURRENT_CHECKPOINT;\n \t}\n-\tstorage_manager.CreateCheckpoint(options);\n+\tstorage_manager.CreateCheckpoint(context, options);\n }\n \n unique_ptr<StorageLockKey> DuckTransactionManager::SharedCheckpointLock() {\n@@ -295,7 +295,7 @@ ErrorData DuckTransactionManager::CommitTransaction(ClientContext &context, Tran\n \t\toptions.action = CheckpointAction::ALWAYS_CHECKPOINT;\n \t\toptions.type = checkpoint_decision.type;\n \t\tauto &storage_manager = db.GetStorageManager();\n-\t\tstorage_manager.CreateCheckpoint(options);\n+\t\tstorage_manager.CreateCheckpoint(context, options);\n \t}\n \treturn error;\n }\ndiff --git a/third_party/concurrentqueue/concurrentqueue.h b/third_party/concurrentqueue/concurrentqueue.h\nindex 0f5ad0a4d625..b62b637bfb1d 100644\n--- a/third_party/concurrentqueue/concurrentqueue.h\n+++ b/third_party/concurrentqueue/concurrentqueue.h\n@@ -1254,6 +1254,23 @@ class ConcurrentQueue\n \t\treturn size;\n \t}\n \t\n+\n+\t// Returns the number of producers currently associated with the queue.\n+\tsize_t size_producers_approx() const\n+\t{\n+\t\tsize_t size = 0;\n+\t\tfor (auto ptr = producerListTail.load(std::memory_order_acquire); ptr != nullptr; ptr = ptr->next_prod()) {\n+\t\t\tsize += 1;\n+\t\t}\n+\t\treturn size;\n+\t}\n+\n+\t// Returns the number of elements currently in the queue for a specific producer.\n+\tsize_t size_producer_approx(producer_token_t const& producer) const\n+\t{\n+\t\treturn static_cast<ExplicitProducer*>(producer.producer)->size_approx();\n+\t}\n+\n \t\n \t// Returns true if the underlying atomic variables used by\n \t// the queue are lock-free (they should be on most platforms).\ndiff --git a/tools/pythonpkg/pyproject.toml b/tools/pythonpkg/pyproject.toml\nindex 076c0fa167ce..67acc3107f39 100644\n--- a/tools/pythonpkg/pyproject.toml\n+++ b/tools/pythonpkg/pyproject.toml\n@@ -15,7 +15,7 @@ local_scheme = \"no-local-version\"\n # Default config runs all tests and requires at least one extension to be tested against\n [tool.cibuildwheel]\n dependency-versions = \"latest\"\n-before-build = 'pip install oldest-supported-numpy'\n+before-build = 'pip install numpy>=2.0'\n before-test = 'python scripts/optional_requirements.py'\n test-requires = 'pytest'\n test-command = 'DUCKDB_PYTHON_TEST_EXTENSION_PATH={project} DUCKDB_PYTHON_TEST_EXTENSION_REQUIRED=1 python -m pytest {project}/tests --verbose'\ndiff --git a/tools/pythonpkg/scripts/cache_data.json b/tools/pythonpkg/scripts/cache_data.json\nindex 44408d142a75..685499fbf636 100644\n--- a/tools/pythonpkg/scripts/cache_data.json\n+++ b/tools/pythonpkg/scripts/cache_data.json\n@@ -48,10 +48,13 @@\n         \"name\": \"pandas\",\n         \"children\": [\n             \"pandas.DataFrame\",\n-            \"pandas.isnull\",\n-            \"pandas.ArrowDtype\",\n+            \"pandas.Categorical\",\n+            \"pandas.CategoricalDtype\",\n+            \"pandas.Series\",\n             \"pandas.NaT\",\n             \"pandas.NA\",\n+            \"pandas.isnull\",\n+            \"pandas.ArrowDtype\",\n             \"pandas.BooleanDtype\",\n             \"pandas.UInt8Dtype\",\n             \"pandas.UInt16Dtype\",\n@@ -170,8 +173,8 @@\n             \"datetime.date\",\n             \"datetime.time\",\n             \"datetime.timedelta\",\n-            \"datetime.timezone\",\n-            \"datetime.datetime\"\n+            \"datetime.datetime\",\n+            \"datetime.timezone\"\n         ]\n     },\n     \"datetime.date\": {\n@@ -671,5 +674,23 @@\n         \"full_path\": \"collections.abc.Mapping\",\n         \"name\": \"Mapping\",\n         \"children\": []\n+    },\n+    \"pandas.Categorical\": {\n+        \"type\": \"attribute\",\n+        \"full_path\": \"pandas.Categorical\",\n+        \"name\": \"Categorical\",\n+        \"children\": []\n+    },\n+    \"pandas.CategoricalDtype\": {\n+        \"type\": \"attribute\",\n+        \"full_path\": \"pandas.CategoricalDtype\",\n+        \"name\": \"CategoricalDtype\",\n+        \"children\": []\n+    },\n+    \"pandas.Series\": {\n+        \"type\": \"attribute\",\n+        \"full_path\": \"pandas.Series\",\n+        \"name\": \"Series\",\n+        \"children\": []\n     }\n }\n\\ No newline at end of file\ndiff --git a/tools/pythonpkg/scripts/generate_import_cache_json.py b/tools/pythonpkg/scripts/generate_import_cache_json.py\nindex 54426943d861..7a59e6b76093 100644\n--- a/tools/pythonpkg/scripts/generate_import_cache_json.py\n+++ b/tools/pythonpkg/scripts/generate_import_cache_json.py\n@@ -162,19 +162,26 @@ def to_json(self):\n     pass\n \n \n-def update_json(existing: dict, new: dict):\n-    for item in new:\n-        if item not in existing:\n-            continue\n-        object = new[item]\n-        if isinstance(object, dict):\n-            object.update(existing[item])\n-            update_json(object, existing[item])\n+def update_json(existing: dict, new: dict) -> dict:\n+    # Iterate over keys in the new dictionary.\n+    for key in new:\n+        new_value = new[key]\n+        old_value = existing[key] if key in existing else None\n+\n+        # If both values are dictionaries, update recursively.\n+        if isinstance(new_value, dict) and isinstance(old_value, dict):\n+            print(key)\n+            updated = update_json(old_value, new_value)\n+            existing[key] = updated\n+        else:\n+            # Otherwise, overwrite the existing value.\n+            existing[key] = new_value\n+    return existing\n \n \n # Merge the existing JSON data with the new data\n json_data = generator.to_json()\n-update_json(existing_json_data, json_data)\n+json_data = update_json(existing_json_data, json_data)\n \n # Save the merged JSON data back to the file\n with open(json_cache_path, \"w\") as file:\ndiff --git a/tools/pythonpkg/scripts/imports.py b/tools/pythonpkg/scripts/imports.py\nindex cfa45d65a13c..d23200daf7b2 100644\n--- a/tools/pythonpkg/scripts/imports.py\n+++ b/tools/pythonpkg/scripts/imports.py\n@@ -9,6 +9,9 @@\n import pandas\n \n pandas.DataFrame\n+pandas.Categorical\n+pandas.CategoricalDtype\n+pandas.Series\n pandas.NaT\n pandas.NA\n pandas.isnull\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/import_cache/modules/datetime_module.hpp b/tools/pythonpkg/src/include/duckdb_python/import_cache/modules/datetime_module.hpp\nindex bda586be15b5..898262d537b5 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/import_cache/modules/datetime_module.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/import_cache/modules/datetime_module.hpp\n@@ -48,7 +48,7 @@ struct DatetimeCacheItem : public PythonImportCacheItem {\n public:\n \tDatetimeCacheItem()\n \t    : PythonImportCacheItem(\"datetime\"), date(this), time(\"time\", this), timedelta(\"timedelta\", this),\n-\t      timezone(\"timezone\", this), datetime(this) {\n+\t      datetime(this), timezone(\"timezone\", this) {\n \t}\n \t~DatetimeCacheItem() override {\n \t}\n@@ -56,8 +56,8 @@ struct DatetimeCacheItem : public PythonImportCacheItem {\n \tDatetimeDateCacheItem date;\n \tPythonImportCacheItem time;\n \tPythonImportCacheItem timedelta;\n-\tPythonImportCacheItem timezone;\n \tDatetimeDatetimeCacheItem datetime;\n+\tPythonImportCacheItem timezone;\n };\n \n } // namespace duckdb\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/import_cache/modules/pandas_module.hpp b/tools/pythonpkg/src/include/duckdb_python/import_cache/modules/pandas_module.hpp\nindex dc13c129a2d9..117604221c25 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/import_cache/modules/pandas_module.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/import_cache/modules/pandas_module.hpp\n@@ -20,8 +20,9 @@ struct PandasCacheItem : public PythonImportCacheItem {\n \n public:\n \tPandasCacheItem()\n-\t    : PythonImportCacheItem(\"pandas\"), DataFrame(\"DataFrame\", this), isnull(\"isnull\", this),\n-\t      ArrowDtype(\"ArrowDtype\", this), NaT(\"NaT\", this), NA(\"NA\", this), BooleanDtype(\"BooleanDtype\", this),\n+\t    : PythonImportCacheItem(\"pandas\"), DataFrame(\"DataFrame\", this), Categorical(\"Categorical\", this),\n+\t      CategoricalDtype(\"CategoricalDtype\", this), Series(\"Series\", this), NaT(\"NaT\", this), NA(\"NA\", this),\n+\t      isnull(\"isnull\", this), ArrowDtype(\"ArrowDtype\", this), BooleanDtype(\"BooleanDtype\", this),\n \t      UInt8Dtype(\"UInt8Dtype\", this), UInt16Dtype(\"UInt16Dtype\", this), UInt32Dtype(\"UInt32Dtype\", this),\n \t      UInt64Dtype(\"UInt64Dtype\", this), Int8Dtype(\"Int8Dtype\", this), Int16Dtype(\"Int16Dtype\", this),\n \t      Int32Dtype(\"Int32Dtype\", this), Int64Dtype(\"Int64Dtype\", this), Float32Dtype(\"Float32Dtype\", this),\n@@ -31,10 +32,13 @@ struct PandasCacheItem : public PythonImportCacheItem {\n \t}\n \n \tPythonImportCacheItem DataFrame;\n-\tPythonImportCacheItem isnull;\n-\tPythonImportCacheItem ArrowDtype;\n+\tPythonImportCacheItem Categorical;\n+\tPythonImportCacheItem CategoricalDtype;\n+\tPythonImportCacheItem Series;\n \tPythonImportCacheItem NaT;\n \tPythonImportCacheItem NA;\n+\tPythonImportCacheItem isnull;\n+\tPythonImportCacheItem ArrowDtype;\n \tPythonImportCacheItem BooleanDtype;\n \tPythonImportCacheItem UInt8Dtype;\n \tPythonImportCacheItem UInt16Dtype;\ndiff --git a/tools/pythonpkg/src/map.cpp b/tools/pythonpkg/src/map.cpp\nindex cd724779a3d7..9864f2de3e36 100644\n--- a/tools/pythonpkg/src/map.cpp\n+++ b/tools/pythonpkg/src/map.cpp\n@@ -8,6 +8,7 @@\n #include \"duckdb_python/pybind11/dataframe.hpp\"\n #include \"duckdb_python/pytype.hpp\"\n #include \"duckdb_python/pybind11/dataframe.hpp\"\n+#include \"duckdb_python/pyconnection/pyconnection.hpp\"\n \n namespace duckdb {\n \n@@ -30,7 +31,10 @@ static py::object FunctionCall(NumpyResultConversion &conversion, const vector<s\n \tfor (idx_t col_idx = 0; col_idx < names.size(); col_idx++) {\n \t\tin_numpy_dict[names[col_idx].c_str()] = conversion.ToArray(col_idx);\n \t}\n-\tauto in_df = py::module::import(\"pandas\").attr(\"DataFrame\").attr(\"from_dict\")(in_numpy_dict);\n+\n+\tauto &import_cache = *DuckDBPyConnection::ImportCache();\n+\tauto pandas_df = import_cache.pandas.DataFrame();\n+\tauto in_df = pandas_df(in_numpy_dict);\n \tD_ASSERT(in_df.ptr());\n \n \tD_ASSERT(function);\ndiff --git a/tools/pythonpkg/src/numpy/numpy_bind.cpp b/tools/pythonpkg/src/numpy/numpy_bind.cpp\nindex 0ffef850312f..e2a4a83fae14 100644\n--- a/tools/pythonpkg/src/numpy/numpy_bind.cpp\n+++ b/tools/pythonpkg/src/numpy/numpy_bind.cpp\n@@ -4,6 +4,7 @@\n #include \"duckdb_python/pandas/column/pandas_numpy_column.hpp\"\n #include \"duckdb_python/pandas/pandas_bind.hpp\"\n #include \"duckdb_python/numpy/numpy_type.hpp\"\n+#include \"duckdb_python/pyconnection/pyconnection.hpp\"\n \n namespace duckdb {\n \ndiff --git a/tools/pythonpkg/src/pandas/analyzer.cpp b/tools/pythonpkg/src/pandas/analyzer.cpp\nindex 8c16e99becba..98fa25cc634c 100644\n--- a/tools/pythonpkg/src/pandas/analyzer.cpp\n+++ b/tools/pythonpkg/src/pandas/analyzer.cpp\n@@ -467,12 +467,11 @@ LogicalType PandasAnalyzer::InnerAnalyze(py::object column, bool &can_convert, i\n \tif (rows == 0) {\n \t\treturn LogicalType::SQLNULL;\n \t}\n+\tauto &import_cache = *DuckDBPyConnection::ImportCache();\n+\tauto pandas_series = import_cache.pandas.Series();\n \n \t// Keys are not guaranteed to start at 0 for Series, use the internal __array__ instead\n-\tauto pandas_module = py::module::import(\"pandas\");\n-\tauto pandas_series = pandas_module.attr(\"core\").attr(\"series\").attr(\"Series\");\n-\n-\tif (py::isinstance(column, pandas_series)) {\n+\tif (pandas_series && py::isinstance(column, pandas_series)) {\n \t\t// TODO: check if '_values' is more portable, and behaves the same as '__array__()'\n \t\tcolumn = column.attr(\"__array__\")();\n \t}\n@@ -503,6 +502,13 @@ bool PandasAnalyzer::Analyze(py::object column) {\n \tif (sample_size == 0) {\n \t\treturn false;\n \t}\n+\tauto &import_cache = *DuckDBPyConnection::ImportCache();\n+\tauto pandas = import_cache.pandas();\n+\tif (!pandas) {\n+\t\t//! Pandas is not installed, no need to analyze\n+\t\treturn false;\n+\t}\n+\n \tbool can_convert = true;\n \tidx_t increment = GetSampleIncrement(py::len(column));\n \tLogicalType type = InnerAnalyze(column, can_convert, increment);\ndiff --git a/tools/pythonpkg/src/pyresult.cpp b/tools/pythonpkg/src/pyresult.cpp\nindex 8444421dcf1f..aa84cee57d7f 100644\n--- a/tools/pythonpkg/src/pyresult.cpp\n+++ b/tools/pythonpkg/src/pyresult.cpp\n@@ -171,15 +171,21 @@ py::dict DuckDBPyResult::FetchNumpy() {\n \n void DuckDBPyResult::FillNumpy(py::dict &res, idx_t col_idx, NumpyResultConversion &conversion, const char *name) {\n \tif (result->types[col_idx].id() == LogicalTypeId::ENUM) {\n+\t\tauto &import_cache = *DuckDBPyConnection::ImportCache();\n+\t\tauto pandas_categorical = import_cache.pandas.Categorical();\n+\t\tauto categorical_dtype = import_cache.pandas.CategoricalDtype();\n+\t\tif (!pandas_categorical || !categorical_dtype) {\n+\t\t\tthrow InvalidInputException(\"'pandas' is required for this operation but it was not installed\");\n+\t\t}\n+\n \t\t// first we (might) need to create the categorical type\n \t\tif (categories_type.find(col_idx) == categories_type.end()) {\n \t\t\t// Equivalent to: pandas.CategoricalDtype(['a', 'b'], ordered=True)\n-\t\t\tcategories_type[col_idx] = py::module::import(\"pandas\").attr(\"CategoricalDtype\")(categories[col_idx], true);\n+\t\t\tcategories_type[col_idx] = categorical_dtype(categories[col_idx], true);\n \t\t}\n \t\t// Equivalent to: pandas.Categorical.from_codes(codes=[0, 1, 0, 1], dtype=dtype)\n-\t\tres[name] = py::module::import(\"pandas\")\n-\t\t                .attr(\"Categorical\")\n-\t\t                .attr(\"from_codes\")(conversion.ToArray(col_idx), py::arg(\"dtype\") = categories_type[col_idx]);\n+\t\tres[name] = pandas_categorical.attr(\"from_codes\")(conversion.ToArray(col_idx),\n+\t\t                                                  py::arg(\"dtype\") = categories_type[col_idx]);\n \t\tif (!conversion.ToPandas()) {\n \t\t\tres[name] = res[name].attr(\"to_numpy\")();\n \t\t}\n@@ -339,6 +345,9 @@ PandasDataFrame DuckDBPyResult::FrameFromNumpy(bool date_as_object, const py::ha\n \tD_ASSERT(py::gil_check());\n \tauto &import_cache = *DuckDBPyConnection::ImportCache();\n \tauto pandas = import_cache.pandas();\n+\tif (!pandas) {\n+\t\tthrow InvalidInputException(\"'pandas' is required for this operation but it was not installed\");\n+\t}\n \n \tpy::object items = o.attr(\"items\")();\n \tfor (const py::handle &item : items) {\n", "test_patch": "diff --git a/scripts/sqllogictest/result.py b/scripts/sqllogictest/result.py\nindex 1893389b1d1a..a03319493e26 100644\n--- a/scripts/sqllogictest/result.py\n+++ b/scripts/sqllogictest/result.py\n@@ -1092,6 +1092,15 @@ def check_require(self, statement: Require) -> RequireResult:\n                 return RequireResult.MISSING\n             return RequireResult.PRESENT\n \n+        allow_unsigned_extensions = connection.execute(\n+            \"select value::BOOLEAN from duckdb_settings() where name == 'allow_unsigned_extensions'\"\n+        ).fetchone()[0]\n+        if param == \"allow_unsigned_extensions\":\n+            if allow_unsigned_extensions == False:\n+                # If extension validation is turned on (that is allow_unsigned_extensions=False), skip test\n+                return RequireResult.MISSING\n+            return RequireResult.PRESENT\n+\n         excluded_from_autoloading = True\n         for ext in self.runner.AUTOLOADABLE_EXTENSIONS:\n             if ext == param:\ndiff --git a/test/api/capi/test_capi_instance_cache.cpp b/test/api/capi/test_capi_instance_cache.cpp\nindex 7d07225a3b18..dd3b40df17b8 100644\n--- a/test/api/capi/test_capi_instance_cache.cpp\n+++ b/test/api/capi/test_capi_instance_cache.cpp\n@@ -38,3 +38,30 @@ TEST_CASE(\"Test the database instance cache in the C API\", \"[api][.]\") {\n \n \tduckdb_destroy_instance_cache(&instance_cache);\n }\n+\n+TEST_CASE(\"Test the database instance cache in the C API with a null path\", \"[capi]\") {\n+\tauto instance_cache = duckdb_create_instance_cache();\n+\tduckdb_database db;\n+\tauto state = duckdb_get_or_create_from_cache(instance_cache, nullptr, &db, nullptr, nullptr);\n+\tREQUIRE(state == DuckDBSuccess);\n+\tduckdb_close(&db);\n+\tduckdb_destroy_instance_cache(&instance_cache);\n+}\n+\n+TEST_CASE(\"Test the database instance cache in the C API with an empty path\", \"[capi]\") {\n+\tauto instance_cache = duckdb_create_instance_cache();\n+\tduckdb_database db;\n+\tauto state = duckdb_get_or_create_from_cache(instance_cache, \"\", &db, nullptr, nullptr);\n+\tREQUIRE(state == DuckDBSuccess);\n+\tduckdb_close(&db);\n+\tduckdb_destroy_instance_cache(&instance_cache);\n+}\n+\n+TEST_CASE(\"Test the database instance cache in the C API with a memory path\", \"[capi]\") {\n+\tauto instance_cache = duckdb_create_instance_cache();\n+\tduckdb_database db;\n+\tauto state = duckdb_get_or_create_from_cache(instance_cache, \":memory:\", &db, nullptr, nullptr);\n+\tREQUIRE(state == DuckDBSuccess);\n+\tduckdb_close(&db);\n+\tduckdb_destroy_instance_cache(&instance_cache);\n+}\ndiff --git a/test/extension/load_extension.test b/test/extension/load_extension.test\nindex c40b06f929e8..420f80e6256c 100644\n--- a/test/extension/load_extension.test\n+++ b/test/extension/load_extension.test\n@@ -6,6 +6,8 @@ require notmingw\n \n require skip_reload\n \n+require allow_unsigned_extensions\n+\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/extension/load_test_alias.test b/test/extension/load_test_alias.test\nindex 51b9ad54fcd0..ae885789fa85 100644\n--- a/test/extension/load_test_alias.test\n+++ b/test/extension/load_test_alias.test\n@@ -6,6 +6,8 @@ require skip_reload\n \n require notmingw\n \n+require allow_unsigned_extensions\n+\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/extension/test_alias_point.test b/test/extension/test_alias_point.test\nindex 1b95a9360b43..75e02c81808e 100644\n--- a/test/extension/test_alias_point.test\n+++ b/test/extension/test_alias_point.test\n@@ -6,6 +6,8 @@ require skip_reload\n \n require notmingw\n \n+require allow_unsigned_extensions\n+\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/extension/test_custom_type_modifier_cast.test b/test/extension/test_custom_type_modifier_cast.test\nindex 8a19071a84d0..1d4c886d8e14 100644\n--- a/test/extension/test_custom_type_modifier_cast.test\n+++ b/test/extension/test_custom_type_modifier_cast.test\n@@ -6,6 +6,8 @@ require skip_reload\n \n require notmingw\n \n+require allow_unsigned_extensions\n+\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/extension/test_tags.test b/test/extension/test_tags.test\nindex f61e35acc4c2..a98f686142ef 100644\n--- a/test/extension/test_tags.test\n+++ b/test/extension/test_tags.test\n@@ -6,6 +6,8 @@ require skip_reload\n \n require notmingw\n \n+require allow_unsigned_extensions\n+\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/optimizer/column_binding_error.test b/test/optimizer/column_binding_error.test\nnew file mode 100644\nindex 000000000000..534aa213f962\n--- /dev/null\n+++ b/test/optimizer/column_binding_error.test\n@@ -0,0 +1,28 @@\n+# name: test/optimizer/column_binding_error.test\n+# description: column binding error test inspired by #16426,\n+# group: [optimizer]\n+\n+require tpch\n+\n+statement ok\n+CREATE TABLE stats(num_docs) AS SELECT 1;\n+\n+statement ok\n+CREATE TABLE postings(docid, termid, tf) AS SELECT range, range, 1 FROM range(30);\n+\n+statement ok\n+CREATE TABLE docs(docid) AS FROM range(2);\n+\n+statement ok\n+WITH termids(termid) AS (SELECT 1)\n+SELECT\n+  (SELECT num_docs FROM stats),\n+  (SELECT num_docs FROM stats),\n+  (SELECT num_docs FROM stats),\n+  (SELECT num_docs FROM stats),\n+  (SELECT num_docs FROM stats),\n+  (SELECT num_docs FROM stats)\n+FROM postings\n+JOIN docs USING (docid)\n+JOIN termids USING (termid)\n+WHERE termid IN (SELECT termid FROM termids);\n\\ No newline at end of file\ndiff --git a/test/sql/copy/csv/test_copy.test b/test/sql/copy/csv/test_copy.test\nindex 8ae494956b5a..dee00e0f13d3 100644\n--- a/test/sql/copy/csv/test_copy.test\n+++ b/test/sql/copy/csv/test_copy.test\n@@ -121,11 +121,17 @@ COPY test4 (a,c) FROM '__TEST_DIR__/test4.csv' (SEP 1);\n ----\n \"sep\" expects a string argument!\n \n-# multiple format options\n+# multiple format options/1, last one wins\n statement error\n-COPY test4 (a,c) FROM '__TEST_DIR__/test4.csv' (FORMAT 'csv', FORMAT 'json');\n+COPY test4 (a,c) FROM '__TEST_DIR__/test4.csv' (FORMAT 'csv', FORMAT 'some_other_copy_function');\n ----\n-Copy Function with name \"json\" is not in the catalog, but it exists in the json extension.\n+Catalog Error: Copy Function with name some_other_copy_function does not exist\n+\n+# multiple format options/2, last one wins\n+query I\n+COPY test4 (a,c) FROM '__TEST_DIR__/test4.csv' (FORMAT 'some_other_copy_function', FORMAT 'csv');\n+----\n+5000\n \n # number as escape string\n statement error\ndiff --git a/test/sql/sample/bernoulli_sampling.test b/test/sql/sample/bernoulli_sampling.test\nindex 95b3e3796c8f..ce6cdf302e38 100644\n--- a/test/sql/sample/bernoulli_sampling.test\n+++ b/test/sql/sample/bernoulli_sampling.test\n@@ -2,6 +2,9 @@\n # description: Test reservoir sample crash on large data sets\n # group: [sample]\n \n+# seed does not persist across restarts\n+require skip_reload\n+\n statement ok\n create table output (num_rows INT);\n \ndiff --git a/test/sqlite/sqllogic_test_runner.cpp b/test/sqlite/sqllogic_test_runner.cpp\nindex 346dc72524db..18a1a5a03306 100644\n--- a/test/sqlite/sqllogic_test_runner.cpp\n+++ b/test/sqlite/sqllogic_test_runner.cpp\n@@ -524,6 +524,12 @@ RequireResult SQLLogicTestRunner::CheckRequire(SQLLogicParser &parser, const vec\n \t\t}\n \t\treturn RequireResult::PRESENT;\n \t}\n+\tif (param == \"allow_unsigned_extensions\") {\n+\t\tif (config->options.allow_unsigned_extensions) {\n+\t\t\treturn RequireResult::PRESENT;\n+\t\t}\n+\t\treturn RequireResult::MISSING;\n+\t}\n \n \tbool excluded_from_autoloading = true;\n \tfor (const auto &ext : AUTOLOADABLE_EXTENSIONS) {\ndiff --git a/tools/shell/tests/test_read_from_stdin.py b/tools/shell/tests/test_read_from_stdin.py\nindex 31f0629f7603..2cd570a44698 100644\n--- a/tools/shell/tests/test_read_from_stdin.py\n+++ b/tools/shell/tests/test_read_from_stdin.py\n@@ -179,6 +179,8 @@ def test_read_stdin_json_array(self, shell, json_extension):\n         ])\n \n     def test_read_stdin_json_auto_recursive_cte(self, shell, json_extension):\n+        # FIXME: disabled for now\n+        return\n         test = (\n             ShellTest(shell)\n             .input_file('data/json/filter_keystage.ndjson')\n", "problem_statement": "Python API: .to_df() segfaults when NumPy is installed but Pandas is missing\n### What happens?\n\nCalling `.to_df()` in the Python API causes a segmentation fault if NumPy is installed but Pandas is not. Ideally, the function should raise a clear error indicating that Pandas is required.\n\n### To Reproduce\n\n```\n% uv venv venv\nUsing CPython 3.13.2 interpreter at: /usr/bin/python3\nCreating virtual environment at: venv\nActivate with: source venv/bin/activate\n% . venv/bin/activate\n% uv pip install duckdb numpy\nUsing Python 3.13.2 environment at: venv\nResolved 2 packages in 24ms\nInstalled 2 packages in 16ms\n + duckdb==1.2.0\n + numpy==2.2.3\n% python3\nPython 3.13.2 (main, Feb  5 2025, 01:23:35) [GCC 14.2.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import duckdb\n>>> r = duckdb.read_csv('/etc/hostname')\n>>> r.to_df()\nzsh: segmentation fault  python3\n```\n\n```\n% python3\nPython 3.12.8 (main, Dec  3 2024, 18:42:41) [Clang 16.0.0 (clang-1600.0.26.4)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import duckdb\n>>> r = duckdb.read_csv('/etc/xtab')\n>>> r.to_df()\nzsh: segmentation fault  python3\n```\n\n### OS:\n\nDebian Linux testing aarch64, macOS Sonama 14.6.1 M3 Pro\n\n### DuckDB Version:\n\n1.2.0\n\n### DuckDB Client:\n\nPython\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nNODA Kai\n\n### Affiliation:\n\nIndependent\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "Hi @nodakai thanks for reporting this. Interestingly, it does not reproduce on macOS with a random dataframe I created. We'll take a closer look.\n\n<img width=\"1038\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/1e5c0009-9ff0-4e1a-834a-f99e51361da1\" />\nHmm??\n```\n% uv venv venv               \nUsing CPython 3.12.8 interpreter at: /opt/homebrew/opt/python@3.12/bin/python3.12\nCreating virtual environment at: venv\nActivate with: source venv/bin/activate\n% . venv/bin/activate\n% uv pip install duckdb numpy\nUsing Python 3.12.8 environment at: venv\nResolved 2 packages in 64ms\nInstalled 2 packages in 51ms\n + duckdb==1.2.0\n + numpy==2.2.3\n% python3\nPython 3.12.8 (main, Dec  3 2024, 18:42:41) [Clang 16.0.0 (clang-1600.0.26.4)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import duckdb\n>>> r = duckdb.sql('select 42 as x')\n>>> r.to_df()\nzsh: segmentation fault  python3\n```\n\nBy the way your transcript mentions two different CPython versions, 3.11.11 and 3.12.9. Not sure if that matters\nRight! I typed `python3` when I should have typed `python` :)", "created_at": "2025-03-04T19:56:38Z"}
{"repo": "duckdb/duckdb", "pull_number": 16439, "instance_id": "duckdb__duckdb-16439", "issue_numbers": ["16333", "15792"], "base_commit": "b95a2a98d9fc321872d498134869d82b70927ce8", "patch": "diff --git a/.github/config/out_of_tree_extensions.cmake b/.github/config/out_of_tree_extensions.cmake\nindex 4aee4d773f9a..b1746d23b2a8 100644\n--- a/.github/config/out_of_tree_extensions.cmake\n+++ b/.github/config/out_of_tree_extensions.cmake\n@@ -53,18 +53,18 @@ endif()\n ################# DELTA\n # MinGW build is not available, and our current manylinux ci does not have enough storage space to run the rust build\n # for Delta\n-if (NOT MINGW AND NOT \"${OS_NAME}\" STREQUAL \"linux\" AND NOT ${WASM_ENABLED})\n-    duckdb_extension_load(delta\n-            GIT_URL https://github.com/duckdb/duckdb-delta\n-            GIT_TAG 846019edcc27000721ff9c4281e85a63d1aa10de\n-    )\n-endif()\n+#if (NOT MINGW AND NOT \"${OS_NAME}\" STREQUAL \"linux\" AND NOT ${WASM_ENABLED})\n+#    duckdb_extension_load(delta\n+#            GIT_URL https://github.com/duckdb/duckdb-delta\n+#            GIT_TAG 846019edcc27000721ff9c4281e85a63d1aa10de\n+#    )\n+#endif()\n \n ################# EXCEL\n duckdb_extension_load(excel\n     LOAD_TESTS\n     GIT_URL https://github.com/duckdb/duckdb-excel\n-    GIT_TAG 67a851738ec80e1f19148a3b37a25a83a5068195\n+    GIT_TAG f14e7c3beaf379c54b47b996aa896a1d814e1be8\n     INCLUDE_DIR src/excel/include\n     )\n \ndiff --git a/.github/workflows/InvokeCI.yml b/.github/workflows/InvokeCI.yml\nindex d17182450677..8bbba55f2677 100644\n--- a/.github/workflows/InvokeCI.yml\n+++ b/.github/workflows/InvokeCI.yml\n@@ -11,6 +11,8 @@ on:\n         type: string\n       run_all:\n         type: string\n+      twine_upload:\n+        type: string\n \n concurrency:\n   group: invokeci-${{ github.workflow }}-${{ github.ref }}-${{ github.head_ref || '' }}-${{ github.base_ref || '' }}-${{ github.ref != 'refs/heads/main' || github.sha }}-${{ inputs.override_git_describe }}-${{ inputs.git_ref }}-${{ inputs.skip_tests }}\n@@ -49,6 +51,7 @@ jobs:\n       git_ref: ${{ inputs.git_ref }}\n       skip_tests: ${{ inputs.skip_tests }}\n       run_all: ${{ inputs.run_all }}\n+      override_twine_upload: ${{ inputs.twine_upload }}\n \n   pyodide:\n     uses: ./.github/workflows/Pyodide.yml\ndiff --git a/.github/workflows/OnTag.yml b/.github/workflows/OnTag.yml\nindex 4f471b7dd40b..a6ddbd38c2b4 100644\n--- a/.github/workflows/OnTag.yml\n+++ b/.github/workflows/OnTag.yml\n@@ -14,6 +14,7 @@ jobs:\n     secrets: inherit\n     with:\n       override_git_describe: ${{ inputs.override_git_describe || github.ref_name }}\n+      twine_upload: 'true'\n \n   staged_upload:\n     uses: ./.github/workflows/StagedUpload.yml\ndiff --git a/.github/workflows/Python.yml b/.github/workflows/Python.yml\nindex 1876c81d7cbb..b63b0b82caf7 100644\n--- a/.github/workflows/Python.yml\n+++ b/.github/workflows/Python.yml\n@@ -10,6 +10,8 @@ on:\n         type: string\n       run_all:\n         type: string\n+      override_twine_upload:\n+        type: string\n   workflow_dispatch:\n     inputs:\n       override_git_describe:\n@@ -20,6 +22,8 @@ on:\n         type: string\n       run_all:\n         type: string\n+      override_twine_upload:\n+        type: string\n   push:\n     branches-ignore:\n       - 'main'\n@@ -462,8 +466,10 @@ jobs:\n       - win-python3\n       - linux-python3\n     # Note that want to run this by default ONLY if no override_git_describe is provided\n-    # This means we are not staging a release\n-    if: (( startsWith(github.ref, 'refs/tags/v') || github.ref == 'refs/heads/main' )) && (( inputs.override_git_describe == '' )) && (( github.repository == 'duckdb/duckdb' ))\n+    # This means we are not staging a release, or we explicitly set `twine_upload`\n+    # Why? If present, it means we are staging releases, and we want to do the upload manually\n+    if: (( startsWith(github.ref, 'refs/tags/v') || github.ref == 'refs/heads/main' || inputs.override_twine_upload == 'true' )) && (( inputs.override_git_describe == '' )) && (( github.repository == 'duckdb/duckdb' ))\n     uses: ./.github/workflows/TwineUpload.yml\n     secrets: inherit\n-    # Why? If present, it means we are staging releases, and we want to do the upload manually\n+    with:\n+      twine_upload: 'true'\ndiff --git a/.github/workflows/TwineUpload.yml b/.github/workflows/TwineUpload.yml\nindex 7dfd4e04f9dd..434fdf785a7c 100644\n--- a/.github/workflows/TwineUpload.yml\n+++ b/.github/workflows/TwineUpload.yml\n@@ -4,10 +4,14 @@ on:\n     inputs:\n       override_git_describe:\n         type: string\n+      twine_upload:\n+        type: string\n   workflow_dispatch:\n     inputs:\n       override_git_describe:\n         type: string\n+      twine_upload:\n+        type: string\n \n env:\n   GH_TOKEN: ${{ secrets.GH_TOKEN }}\n@@ -47,12 +51,13 @@ jobs:\n           aws s3 cp --recursive \"s3://duckdb-staging/$TARGET/$GITHUB_REPOSITORY/twine_upload\" to_be_uploaded --region us-east-2\n \n       - name: Deploy\n+        if: ${{ inputs.twine_upload == 'true' }}\n         env:\n           TWINE_USERNAME: '__token__'\n           TWINE_PASSWORD: ${{ secrets.TWINE_TOKEN }}\n         shell: bash\n         run: |\n           cd tools/pythonpkg\n-          if [[ \"$GITHUB_REF\" =~ ^(refs/heads/main|refs/tags/v.+)$ && \"$GITHUB_REPOSITORY\" = \"duckdb/duckdb\" ]] ; then\n+          if [[ \"$GITHUB_REPOSITORY\" = \"duckdb/duckdb\" ]] ; then\n             twine upload --non-interactive --disable-progress-bar --skip-existing to_be_uploaded/*\n           fi\ndiff --git a/data/csv/later_quotes.csv b/data/csv/later_quotes.csv\nnew file mode 100644\nindex 000000000000..657c4f93e861\n--- /dev/null\n+++ b/data/csv/later_quotes.csv\n@@ -0,0 +1,2050 @@\n+id,value\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+1,bla\n+2048,\"\"\",\"\ndiff --git a/data/csv/multi_quote.csv b/data/csv/multi_quote.csv\nnew file mode 100644\nindex 000000000000..b3afd621b814\n--- /dev/null\n+++ b/data/csv/multi_quote.csv\n@@ -0,0 +1,8 @@\n+datecol,textcol\n+1/1/19,\"text\"\n+1/2/19,\"text\"\n+1/3/19,\"text\"\n+1/4/19,\"text\"\n+1/5/19,\"text\"\n+1/6/19,\"text, with comma\"\n+1/9/19,'text'\n\\ No newline at end of file\ndiff --git a/extension/autocomplete/include/inlined_grammar.gram b/extension/autocomplete/include/inlined_grammar.gram\nnew file mode 100644\nindex 000000000000..2bdd82d9c3f9\n--- /dev/null\n+++ b/extension/autocomplete/include/inlined_grammar.gram\n@@ -0,0 +1,740 @@\n+\n+PivotStatement <- PivotKeyword TableRef PivotOn? PivotUsing? GroupByClause?\n+\n+PivotOn <- 'ON' PivotColumnList\n+PivotUsing <- 'USING' TargetList\n+\n+PivotColumnList <- List(Expression)\n+\n+PivotKeyword <- 'PIVOT'i / 'PIVOT_WIDER'i\n+UnpivotKeyword <- 'UNPIVOT'i / 'PIVOT_LONGER'i\n+\n+UnpivotStatement <- UnpivotKeyword TableRef 'ON' TargetList IntoNameValues?\n+\n+IntoNameValues <- 'INTO' 'NAME' Identifier ValueOrValues List(Identifier)\n+\n+ValueOrValues <- 'VALUE' / 'VALUES'\n+\n+IncludeExcludeNulls <- ('INCLUDE' / 'EXCLUDE') 'NULLS'\n+UnpivotHeader <- Identifier / Parens(List(Identifier))\n+\n+ColumnReference <- CatalogQualification? SchemaQualification? TableQualification? ColumnName\n+FunctionExpression <- FunctionIdentifier Parens(DistinctOrAll? List(FunctionArgument)? OrderByClause?) WithinGroupClause? FilterClause? ExportClause? OverClause?\n+FunctionIdentifier <- CatalogQualification? SchemaQualification? FunctionName\n+DistinctOrAll <- 'DISTINCT'i / 'ALL'i\n+ExportClause <- 'EXPORT_STATE'i\n+WithinGroupClause <- 'WITHIN'i 'GROUP'i Parens(OrderByClause)\n+FilterClause <- 'FILTER' Parens('WHERE'i? Expression)\n+\n+ParenthesisExpression <- Parens(List(Expression))\n+LiteralExpression <- StringLiteral / NumberLiteral / 'NULL'i / 'TRUE'i / 'FALSE'i\n+CastExpression <- CastOrTryCast Parens(Expression 'AS'i Type)\n+CastOrTryCast <- 'CAST'i / 'TRY_CAST'i\n+\n+StarExpression <- (Identifier '.')* '*'i ExcludeList? ReplaceList? RenameList?\n+ExcludeList <- 'EXCLUDE'i (Parens(List(ColumnReference)) / ColumnReference)\n+ReplaceList <- 'REPLACE'i (Parens(List(ReplaceEntry)) / ReplaceEntry)\n+ReplaceEntry <- Expression 'AS'i ColumnReference\n+RenameList <- 'RENAME'i (Parens(List(RenameEntry)) / RenameEntry)\n+RenameEntry <- ColumnReference 'AS'i Identifier\n+SubqueryExpression <- 'NOT'i? 'EXISTS'i? SubqueryReference\n+CaseExpression <- 'CASE'i ColumnReference? CaseWhenThen CaseWhenThen* CaseElse? 'END'i\n+CaseWhenThen <- 'WHEN'i Expression 'THEN'i Expression\n+CaseElse <- 'ELSE'i Expression\n+TypeLiteral <- Identifier StringLiteral\n+IntervalLiteral <- 'INTERVAL'i IntervalParameter IntervalUnit?\n+IntervalParameter <- StringLiteral / NumberLiteral / Parens(Expression)\n+IntervalUnit <- Identifier\n+FrameClause <- Framing FrameExtent WindowExcludeClause?\n+Framing <- 'ROWS'i / 'RANGE'i / 'GROUPS'i\n+FrameExtent <- FrameBound / ('BETWEEN'i FrameBound 'AND'i FrameBound)\n+FrameBound <- ('UNBOUNDED'i 'PRECEDING'i) / ('UNBOUNDED'i 'FOLLOWING'i) / ('CURRENT'i 'ROW'i) / (Expression 'PRECEDING'i) / (Expression 'FOLLOWING'i)\n+WindowExcludeClause <- 'EXCLUDE'i WindowExcludeElement\n+WindowExcludeElement <- ('CURRENT'i 'ROW'i) / 'GROUP'i / 'TIES'i / ('NO'i 'OTHERS'i)\n+OverClause <- 'OVER'i WindowFrame\n+WindowFrame <- WindowFrameDefinition / Identifier / Parens(Identifier)\n+WindowFrameDefinition <- Parens(WindowFrameContents)\n+WindowFrameContents <- WindowPartition? OrderByClause? FrameClause?\n+WindowPartition <- 'PARTITION'i 'BY'i List(Expression)\n+PrefixExpression <- PrefixOperator Expression\n+PrefixOperator <- 'NOT'i / '-' / '+'\n+ListExpression <- 'ARRAY'i? '[' List(Expression)? ']'\n+StructExpression <- '{' List(StructField) '}'\n+StructField <- Expression ':'i Expression\n+MapExpression <- 'MAP'i StructExpression\n+GroupingExpression <- GroupingOrGroupingId Parens(List(Expression))\n+GroupingOrGroupingId <- 'GROUPING'i / 'GROUPING_ID'i\n+Parameter <- '?' / NumberedParameter\n+NumberedParameter <- '$' NumberLiteral\n+PositionalExpression <- '#' NumberLiteral\n+DefaultExpression <- 'DEFAULT'i\n+\n+ListComprehensionExpression <- '['i Expression 'FOR'i List(Expression) ListComprehensionFilter? ']'\n+ListComprehensionFilter <- 'IF'i Expression\n+\n+SingleExpression <-\n+\tParameter /\n+    SubqueryExpression /\n+    SpecialFunctionExpression /\n+    ParenthesisExpression /\n+    IntervalLiteral /\n+    TypeLiteral /\n+    CaseExpression /\n+    StarExpression /\n+    CastExpression /\n+    GroupingExpression /\n+    FunctionExpression /\n+    ColumnReference /\n+    LiteralExpression /\n+    PrefixExpression /\n+    ListComprehensionExpression /\n+    ListExpression /\n+    StructExpression /\n+    MapExpression /\n+    PositionalExpression /\n+    DefaultExpression\n+\n+\n+\n+OperatorLiteral <- <[\\+\\-\\*\\/\\%\\^\\<\\>\\=\\~\\!\\@\\&\\|\\`]+>\n+LikeOperator <- 'NOT'i? LikeOrSimilarTo\n+LikeOrSimilarTo <- 'LIKE'i / 'ILIKE'i / 'GLOB'i / ('SIMILAR'i 'TO'i)\n+InOperator <- 'NOT'i? 'IN'i\n+IsOperator <- 'IS'i 'NOT'i? DistinctFrom?\n+DistinctFrom <- 'DISTINCT'i 'FROM'i\n+ConjunctionOperator <- 'OR'i / 'AND'i\n+ComparisonOperator <-  '=' / '<=' / '>=' / '<' / '>' / '<>' / '!=' / '=='\n+BetweenOperator <- 'NOT'i? 'BETWEEN'i\n+CollateOperator <- 'COLLATE'i\n+LambdaOperator <- '->'\n+EscapeOperator <- 'ESCAPE'i\n+AtTimeZoneOperator <- 'AT'i 'TIME'i 'ZONE'i\n+PostfixOperator <- '!'\n+AnyAllOperator <- ComparisonOperator AnyOrAll\n+AnyOrAll <- 'ANY' / 'ALL'\n+\n+Operator <-\n+\tAnyAllOperator /\n+    ConjunctionOperator /\n+    LikeOperator /\n+    InOperator /\n+    IsOperator /\n+    BetweenOperator /\n+    CollateOperator /\n+    LambdaOperator /\n+    EscapeOperator /\n+    AtTimeZoneOperator /\n+    OperatorLiteral\n+\n+CastOperator <- '::' Type\n+DotOperator <- '.' (FunctionExpression / Identifier)\n+NotNull <- 'NOT'i 'NULL'i\n+Indirection <- CastOperator / DotOperator / SliceExpression / NotNull / PostfixOperator\n+\n+BaseExpression <- SingleExpression Indirection*\n+Expression <- BaseExpression RecursiveExpression*\n+RecursiveExpression <- (Operator Expression)\n+SliceExpression <- '[' SliceBound ']'\n+SliceBound <- Expression? (':' Expression?)? (':' Expression?)?\n+\n+SpecialFunctionExpression <- CoalesceExpression / ColumnsExpression / ExtractExpression / NullIfExpression / PositionExpression / RowExpression / SubstringExpression / TrimExpression\n+CoalesceExpression <- 'COALESCE'i Parens(List(Expression))\n+ColumnsExpression <- '*'? 'COLUMNS'i Parens(Expression)\n+ExtractExpression <- 'EXTRACT'i Parens(Expression 'FROM'i Expression)\n+NullIfExpression <- 'NULLIF'i Parens(Expression ',' Expression)\n+PositionExpression <- 'POSITION'i Parens(Expression)\n+RowExpression <- 'ROW'i Parens(List(Expression))\n+SubstringExpression <- 'SUBSTRING'i Parens(SubstringParameters / List(Expression))\n+SubstringParameters <- Expression 'FROM'i NumberLiteral 'FOR'i NumberLiteral\n+TrimExpression <- 'TRIM'i Parens(TrimDirection? TrimSource? List(Expression))\n+\n+TrimDirection <- 'BOTH'i / 'LEADING'i / 'TRAILING'i\n+TrimSource <- Expression? 'FROM'i\n+\n+ExecuteStatement <- 'EXECUTE'i Identifier TableFunctionArguments?\n+CreateSecretStmt <- 'SECRET'i IfNotExists? SecretName? SecretStorageSpecifier? Parens(GenericCopyOptionList)\n+\n+SecretStorageSpecifier <- 'IN'i Identifier\n+\n+CreateViewStmt <- 'VIEW'i IfNotExists? QualifiedName InsertColumnList? 'AS'i SelectStatement\n+\n+DescribeStatement <- ShowSelect / ShowAllTables / ShowQualifiedName\n+\n+ShowSelect <- ShowOrDescribeOrSummarize SelectStatement\n+ShowAllTables <- ShowOrDescribe 'ALL'i 'TABLES'\n+ShowQualifiedName <- ShowOrDescribeOrSummarize (QualifiedName / StringLiteral)?\n+\n+ShowOrDescribeOrSummarize <- ShowOrDescribe / 'SUMMARIZE'i\n+ShowOrDescribe <- 'SHOW'i / 'DESCRIBE'i / 'DESC'i\n+\n+VacuumStatement <- 'VACUUM'i 'FULL'i? QualifiedName?\n+\n+PragmaStatement <- 'PRAGMA'i (PragmaAssign / PragmaFunction)\n+\n+PragmaAssign <- SettingName '=' VariableList\n+PragmaFunction <- PragmaName PragmaParameters?\n+PragmaParameters <- List(Expression)\n+\n+DeallocateStatement <- 'DEALLOCATE'i 'PREPARE'i? Identifier\n+\n+PrepareStatement <- 'PREPARE'i Identifier TypeList? 'AS'i Statement\n+\n+TypeList <- Parens(List(Type))\n+\n+CreateStatement <- 'CREATE'i OrReplace? Temporary? (CreateTableStmt / CreateMacroStmt / CreateSequenceStmt / CreateTypeStmt / CreateSchemaStmt / CreateViewStmt / CreateIndexStmt / CreateSecretStmt)\n+OrReplace <- 'OR'i 'REPLACE'i\n+Temporary <- 'TEMP'i / 'TEMPORARY'i / 'PERSISTENT'i\n+\n+CreateTableStmt <- 'TABLE'i IfNotExists? QualifiedName (CreateColumnList / CreateTableAs) CommitAction?\n+\n+CreateTableAs <- IdentifierList? 'AS'i SelectStatement\n+IdentifierList <- Parens(List(Identifier))\n+CreateColumnList <- Parens(CreateTableColumnList)\n+IfNotExists <- 'IF'i 'NOT'i 'EXISTS'i\n+QualifiedName <- CatalogQualification? SchemaQualification? Identifier\n+CatalogQualification <- CatalogName '.'\n+SchemaQualification <- SchemaName '.'\n+TableQualification <- TableName '.'\n+\n+CreateTableColumnList <- List(CreateTableColumnElement)\n+CreateTableColumnElement <- ColumnDefinition / TopLevelConstraint\n+ColumnDefinition <- Identifier TypeOrGenerated ColumnConstraint*\n+TypeOrGenerated <- Type? GeneratedColumn?\n+ColumnConstraint <- NotNullConstraint / UniqueConstraint / PrimaryKeyConstraint / DefaultValue / CheckConstraint / ForeignKeyConstraint / ColumnCollation / ColumnCompression\n+NotNullConstraint <- 'NOT'i 'NULL'i\n+UniqueConstraint <- 'UNIQUE'i\n+PrimaryKeyConstraint <- 'PRIMARY'i 'KEY'i\n+DefaultValue <- 'DEFAULT'i Expression\n+CheckConstraint <- 'CHECK'i Parens(Expression)\n+ForeignKeyConstraint <- 'REFERENCES'i BaseTableName Parens(ColumnList)? KeyActions?\n+ColumnCollation <- 'COLLATE'i Expression\n+ColumnCompression <- 'USING'i 'COMPRESSION'i Identifier\n+\n+KeyActions <- UpdateAction? DeleteAction?\n+UpdateAction <- 'ON' 'UPDATE' KeyAction\n+DeleteAction <- 'ON' 'DELETE' KeyAction\n+KeyAction <- ('NO'i 'ACTION'i) / 'RESTRICT'i / 'CASCADE'i / ('SET'i 'NULL'i) / ('SET'i 'DEFAULT'i)\n+\n+TopLevelConstraint <- ConstraintNameClause? TopLevelConstraintList\n+TopLevelConstraintList <- TopPrimaryKeyConstraint / CheckConstraint / TopUniqueConstraint / TopForeignKeyConstraint\n+ConstraintNameClause <- 'CONSTRAINT'i Identifier\n+TopPrimaryKeyConstraint <- 'PRIMARY'i 'KEY'i ColumnIdList\n+TopUniqueConstraint <- 'UNIQUE'i ColumnIdList\n+TopForeignKeyConstraint <- 'FOREIGN'i 'KEY'i ColumnIdList ForeignKeyConstraint\n+ColumnIdList <- Parens(List(Identifier))\n+\n+PlainIdentifier <-  !ReservedKeyword <[a-z_]i[a-z0-9_]i*>\n+QuotedIdentifier <- '\"' [^\"]* '\"'\n+Identifier <- QuotedIdentifier / PlainIdentifier\n+\n+GeneratedColumn <- Generated? 'AS'i Parens(Expression) GeneratedColumnType?\n+\n+Generated <- 'GENERATED'i AlwaysOrByDefault?\n+AlwaysOrByDefault <- 'ALWAYS'i / ('BY'i 'DEFAULT'i)\n+GeneratedColumnType <- 'VIRTUAL'i / 'STORED'i\n+\n+CommitAction <- 'ON'i 'COMMIT'i 'PRESERVE'i 'ROWS'i\n+\n+CreateIndexStmt <- Unique? 'INDEX'i IfNotExists? IndexName? 'ON'i BaseTableName IndexType? Parens(List(IndexElement))\n+\n+IndexElement <- Expression DescOrAsc? NullsFirstOrLast?\n+Unique <- 'UNIQUE'i\n+IndexType <- 'USING'i Identifier\n+\n+DropStatement <- 'DROP'i DropEntries DropBehavior?\n+\n+DropEntries <-\n+\tDropTable /\n+\tDropTableFunction /\n+\tDropFunction /\n+\tDropSchema /\n+\tDropIndex /\n+\tDropSequence /\n+\tDropCollation /\n+\tDropType /\n+\tDropSecret\n+\n+DropTable <- TableOrView IfExists? List(BaseTableName)\n+DropTableFunction <- 'MACRO'i 'TABLE'i IfExists? List(TableFunctionName)\n+DropFunction <- FunctionType IfExists? List(FunctionIdentifier)\n+DropSchema <- 'SCHEMA'i IfExists? List(QualifiedSchemaName)\n+DropIndex <- 'INDEX'i IfExists? List(IndexName)\n+DropSequence <- 'SEQUENCE'i IfExists? List(QualifiedSequenceName)\n+DropCollation <- 'COLLATION'i IfExists? List(CollationName)\n+DropType <- 'TYPE'i IfExists? List(QualifiedTypeName)\n+DropSecret <- Temporary? 'SECRET'i IfExists? SecretName DropSecretStorage?\n+\n+TableOrView <- 'TABLE'i / 'VIEW'i / ('MATERIALIZED'i 'VIEW'i)\n+FunctionType <- 'MACRO'i / 'FUNCTION'i\n+\n+DropBehavior <- 'CASCADE'i / 'RESTRICT'i\n+\n+IfExists <- 'IF'i 'EXISTS'i\n+QualifiedSchemaName <- CatalogQualification? SchemaName\n+\n+DropSecretStorage <- 'FROM'i Identifier\n+\n+UpdateStatement <- WithClause? 'UPDATE'i UpdateTarget 'SET'i UpdateSetClause FromClause? WhereClause? ReturningClause?\n+\n+UpdateTarget <- BaseTableName UpdateAlias?\n+UpdateAlias <- 'AS'i Identifier\n+UpdateSetClause <- List(UpdateSetElement)\n+UpdateSetElement <- Identifier '=' Expression\n+\n+InsertStatement <- WithClause? 'INSERT'i OrAction? 'INTO'i InsertTarget ByNameOrPosition? InsertColumnList? InsertValues OnConflictClause? ReturningClause?\n+\n+OrAction <- 'OR'i 'REPLACE'i / 'IGNORE'i\n+ByNameOrPosition <- 'BY'i 'NAME'i / 'POSITION'i\n+\n+InsertTarget <- BaseTableName InsertAlias?\n+InsertAlias <- 'AS'i Identifier\n+\n+ColumnList <- List(Identifier)\n+InsertColumnList <- Parens(ColumnList)\n+\n+InsertValues <- SelectStatement / DefaultValues\n+DefaultValues <- 'DEFAULT'i 'VALUES'i\n+\n+OnConflictClause <- 'ON'i 'CONFLICT'i OnConflictTarget? OnConflictAction\n+\n+OnConflictTarget <- OnConflictExpressionTarget / OnConflictIndexTarget\n+OnConflictExpressionTarget <- Parens(List(Identifier)) WhereClause?\n+OnConflictIndexTarget <- 'ON'i 'CONSTRAINT'i ConstraintName\n+\n+\n+OnConflictAction <- OnConflictUpdate / OnConflictNothing\n+\n+OnConflictUpdate <- 'DO'i 'UPDATE'i UpdateSetClause WhereClause?\n+OnConflictNothing <- 'DO'i 'NOTHING'i\n+\n+ReturningClause <- 'RETURNING'i TargetList\n+\n+CreateSchemaStmt <- 'SCHEMA'i IfNotExists? QualifiedName\n+\n+SelectStatement <- SelectOrParens (SetopClause SelectStatement)* ResultModifiers\n+\n+SetopClause <- ('UNION'i / 'EXCEPT'i / 'INTERSECT'i) DistinctOrAll? ByName?\n+ByName <- 'BY'i 'NAME'i\n+SelectOrParens <- BaseSelect / Parens(SelectStatement)\n+\n+BaseSelect <- WithClause? (SimpleSelect / ValuesClause / DescribeStatement / TableStatement / PivotStatement / UnpivotStatement) ResultModifiers\n+ResultModifiers <- OrderByClause? LimitClause? OffsetClause?\n+TableStatement <- 'TABLE' BaseTableName\n+\n+SimpleSelect <- SelectFrom WhereClause? GroupByClause? HavingClause? WindowClause? QualifyClause? SampleClause?\n+\n+SelectFrom <- (SelectClause FromClause?) / (FromClause SelectClause?)\n+WithStatement <- Identifier InsertColumnList? 'AS'i Materialized? SubqueryReference\n+Materialized <- 'NOT'i? 'MATERIALIZED'i\n+WithClause <- 'WITH'i Recursive? List(WithStatement)\n+Recursive <- 'RECURSIVE'i\n+SelectClause <- 'SELECT'i DistinctClause? TargetList\n+TargetList <- List(AliasedExpression)\n+ColumnAliases <- Parens(List(Identifier))\n+\n+DistinctClause <- ('DISTINCT'i DistinctOn?) / 'ALL'i\n+DistinctOn <- 'ON'i Parens(List(Expression))\n+\n+InnerTableRef <- ValuesRef / TableFunction / TableSubquery / BaseTableRef / ParensTableRef\n+\n+TableRef <- InnerTableRef JoinOrPivot*\n+TableSubquery <- Lateral? SubqueryReference TableAlias?\n+BaseTableRef <- BaseTableName TableAlias?\n+ValuesRef <- ValuesClause TableAlias?\n+ParensTableRef <- Parens(TableRef)\n+\n+\n+JoinOrPivot <- JoinClause / TablePivotClause / TableUnpivotClause\n+\n+TablePivotClause <- 'PIVOT' Parens(TargetList 'FOR' PivotValueLists GroupByClause?) TableAlias?\n+TableUnpivotClause <- 'UNPIVOT' IncludeExcludeNulls? Parens(UnpivotHeader 'FOR' PivotValueLists) TableAlias?\n+\n+PivotHeader <- BaseExpression\n+PivotValueLists <- PivotValueList PivotValueList*\n+PivotValueList <- PivotHeader 'IN' PivotTargetList\n+PivotTargetList <- Identifier / Parens(TargetList)\n+\n+Lateral <- 'LATERAL'i\n+\n+BaseTableName <- CatalogQualification? SchemaQualification? TableName\n+\n+TableFunction <- Lateral? QualifiedTableFunction TableFunctionArguments TableAlias?\n+QualifiedTableFunction <- CatalogQualification? SchemaQualification? TableFunctionName\n+TableFunctionArguments <- Parens(List(FunctionArgument)?)\n+FunctionArgument <- NamedParameter / Expression\n+NamedParameter <- Identifier NamedParameterAssignment Expression\n+NamedParameterAssignment <- ':=' / '=>'\n+\n+TableAlias <- 'AS'i? Identifier ColumnAliases?\n+\n+JoinClause <- RegularJoinClause / JoinWithoutOnClause\n+RegularJoinClause <- 'ASOF'i? JoinType? 'JOIN'i InnerTableRef JoinQualifier\n+JoinWithoutOnClause <- JoinPrefix 'JOIN'i InnerTableRef\n+JoinQualifier <- OnClause / UsingClause\n+OnClause <- 'ON'i Expression\n+UsingClause <- 'USING'i Parens(List(Identifier))\n+\n+OuterJoinType <- 'FULL'i / 'LEFT'i / 'RIGHT'i\n+JoinType <- (OuterJoinType 'OUTER'i?) / 'SEMI'i / 'ANTI'i / 'INNER'i\n+JoinPrefix <- 'CROSS'i / ('NATURAL'i JoinType?) / 'POSITIONAL'i\n+\n+FromClause <- 'FROM'i List(TableRef)\n+WhereClause <- 'WHERE'i Expression\n+GroupByClause <- 'GROUP'i 'BY'i GroupByExpressions\n+HavingClause <- 'HAVING'i Expression\n+QualifyClause <- 'QUALIFY'i Expression\n+SampleClause <- 'USING'i 'SAMPLE'i SampleEntry\n+WindowClause <- 'WINDOW'i List(WindowDefinition)\n+WindowDefinition <- Identifier 'AS'i WindowFrameDefinition\n+\n+SampleEntry <- SampleEntryCount / SampleEntryFunction RepeatableSample?\n+SampleEntryCount <- SampleCount Parens(SampleProperties)?\n+SampleEntryFunction <- SampleFunction? Parens(SampleCount)\n+SampleFunction <- Identifier\n+SampleProperties <- Identifier (',' NumberLiteral)\n+RepeatableSample <- 'REPEATABLE' Parens(NumberLiteral)\n+\n+SampleCount <- Expression SampleUnit?\n+SampleUnit <- '%' / 'PERCENT'i / 'ROWS'i\n+\n+GroupByExpressions <- GroupByList / 'ALL'i\n+GroupByList <- List(GroupByExpression)\n+GroupByExpression <- EmptyGroupingItem / CubeOrRollupClause / GroupingSetsClause / Expression\n+EmptyGroupingItem <- '(' ')'\n+CubeOrRollupClause <- CubeOrRollup Parens(List(Expression))\n+CubeOrRollup <- 'CUBE'i / 'ROLLUP'i\n+GroupingSetsClause <- 'GROUPING'i 'SETS'i Parens(GroupByList)\n+\n+SubqueryReference <- Parens(SelectStatement)\n+\n+OrderByExpression <- Expression DescOrAsc? NullsFirstOrLast?\n+DescOrAsc <- 'DESC'i / 'DESCENDING'i / 'ASC'i / 'ASCENDING'i\n+NullsFirstOrLast <- 'NULLS'i 'FIRST'i / 'LAST'i\n+OrderByClause <- 'ORDER'i 'BY'i OrderByExpressions\n+OrderByExpressions <- List(OrderByExpression) / OrderByAll\n+OrderByAll <- 'ALL'i DescOrAsc? NullsFirstOrLast?\n+\n+LimitClause <- 'LIMIT'i LimitValue\n+OffsetClause <- 'OFFSET'i LimitValue\n+LimitValue <- 'ALL'i / (NumberLiteral 'PERCENT'i) / (Expression '%'?)\n+\n+AliasedExpression <- Expression ('AS'i? Identifier)?\n+\n+ValuesClause <- 'VALUES'i List(ValuesExpressions)\n+ValuesExpressions <- Parens(List(Expression))\n+\n+TransactionStatement <- BeginTransaction / RollbackTransaction / CommitTransaction\n+\n+BeginTransaction <- StartOrBegin Transaction? ReadOrWrite?\n+RollbackTransaction <- AbortOrRollback Transaction?\n+CommitTransaction <- CommitOrEnd Transaction?\n+\n+StartOrBegin <- 'START'i / 'BEGIN'i\n+Transaction <- 'WORK'i / 'TRANSACTION'i\n+ReadOrWrite <- 'READ'i ('ONLY'i / 'WRITE'i)\n+AbortOrRollback <- 'ABORT'i / 'ROLLBACK'i\n+CommitOrEnd <- 'COMMIT'i / 'END'i\n+\n+DeleteStatement <- WithClause? 'DELETE'i 'FROM'i InsertTarget DeleteUsingClause? WhereClause? ReturningClause?\n+TruncateStatement <- 'TRUNCATE'i 'TABLE'i? BaseTableName\n+\n+DeleteUsingClause <- 'USING'i List(TableRef)\n+\n+CreateTypeStmt <- 'TYPE'i IfNotExists? QualifiedName 'AS'i Type\n+\n+SetStatement <- 'SET'i (StandardAssignment / SetTimeZone)\n+\n+StandardAssignment <- (SetVariable / SetSetting) SetAssignment\n+SetTimeZone <- 'TIME'i 'ZONE'i Expression\n+SetSetting <- SettingScope? SettingName\n+SetVariable <- 'VARIABLE'i Identifier\n+\n+SettingScope <- 'LOCAL'i / 'SESSION'i / 'GLOBAL'i\n+\n+SetAssignment <- VariableAssign VariableList\n+\n+VariableAssign <- '=' / 'TO'\n+VariableList <- List(Expression)\n+\n+ResetStatement <- 'RESET'i (SetSetting / SetVariable)\n+\n+ExportStatement <- 'EXPORT'i 'DATABASE'i ExportSource? StringLiteral Parens(GenericCopyOptionList)?\n+\n+ExportSource <- CatalogName 'TO'i\n+\n+ImportStatement <- 'IMPORT'i 'DATABASE'i StringLiteral\n+\n+CheckpointStatement <- 'FORCE'i? 'CHECKPOINT'i CatalogName?\n+\n+CopyStatement <- 'COPY'i (CopyTable / CopySelect / CopyFromDatabase)\n+\n+CopyTable <- BaseTableName InsertColumnList? FromOrTo CopyFileName CopyOptions?\n+FromOrTo <- 'FROM'i / 'TO'i\n+\n+CopySelect <- Parens(SelectStatement) 'TO'i CopyFileName CopyOptions?\n+\n+CopyFileName <- StringLiteral / Identifier\n+CopyOptions <- 'WITH'i? (Parens(GenericCopyOptionList) / (SpecializedOptions*))\n+SpecializedOptions <-\n+\t'BINARY'i / 'FREEZE'i / 'OIDS'i / 'CSV'i / 'HEADER'i /\n+\tSpecializedStringOption /\n+\t('ENCODING'i StringLiteral) /\n+\t('FORCE'i 'QUOTE'i StarOrColumnList) /\n+\t('PARTITION'i 'BY'i StarOrColumnList) /\n+\t('FORCE'i 'NOT'i? 'NULL'i ColumnList)\n+\n+SpecializedStringOption <- ('DELIMITER'i / 'NULL'i / 'QUOTE'i / 'ESCAPE'i) 'AS'i? StringLiteral\n+\n+StarOrColumnList <- '*' / ColumnList\n+\n+GenericCopyOptionList <- List(GenericCopyOption)\n+GenericCopyOption <- GenericCopyOptionName Expression?\n+# FIXME: should not need to hard-code options here\n+GenericCopyOptionName <- 'ARRAY'i / 'NULL'i / 'ANALYZE'i / CopyOptionName\n+\n+CopyFromDatabase <- 'FROM'i 'DATABASE'i Identifier 'TO'i Identifier CopyDatabaseFlag?\n+\n+CopyDatabaseFlag <- Parens(SchemaOrData)\n+SchemaOrData <- 'SCHEMA'i / 'DATA'i\n+\n+AlterStatement <- 'ALTER'i AlterOptions\n+\n+\n+AlterOptions <- AlterTableStmt / AlterViewStmt / AlterSequenceStmt\n+\n+AlterTableStmt <- 'TABLE'i IfExists? BaseTableName AlterTableOptions\n+\n+AlterTableOptions <- AddColumn / DropColumn / AlterColumn / AddConstraint / ChangeNullability / RenameColumn / RenameAlter\n+\n+AddConstraint <- 'ADD'i TopLevelConstraint\n+AddColumn <- 'ADD'i 'COLUMN'i? IfNotExists? ColumnDefinition\n+DropColumn <- 'DROP'i 'COLUMN'i? IfExists? ColumnName DropBehavior?\n+AlterColumn <- 'ALTER'i 'COLUMN'i? Identifier AlterColumnEntry\n+RenameColumn <- 'RENAME'i 'COLUMN'i? ColumnName 'TO'i Identifier\n+RenameAlter <- 'RENAME'i 'TO'i Identifier\n+\n+AlterColumnEntry <- AddOrDropDefault / ChangeNullability / AlterType\n+\n+AddOrDropDefault <- AddDefault / DropDefault\n+AddDefault <- 'SET'i 'DEFAULT'i Expression\n+DropDefault <- 'DROP'i 'DEFAULT'i\n+\n+ChangeNullability <- ('DROP'i / 'SET'i) 'NOT'i 'NULL'i\n+\n+AlterType <- SetData? 'TYPE'i Type? UsingExpression?\n+SetData <- 'SET'i 'DATA'i?\n+UsingExpression <- 'USING'i Expression\n+\n+AlterViewStmt <- 'VIEW'i IfExists? BaseTableName RenameAlter\n+\n+AlterSequenceStmt <- 'SEQUENCE'i IfExists? QualifiedSequenceName AlterSequenceOptions\n+\n+QualifiedSequenceName <- CatalogQualification? SchemaQualification? SequenceName\n+\n+AlterSequenceOptions <- RenameAlter / SetSequenceOption\n+SetSequenceOption <- List(SequenceOption)\n+CreateSequenceStmt <- 'SEQUENCE'i IfNotExists? QualifiedName SequenceOption*\n+\n+SequenceOption <-\n+\tSeqSetCycle /\n+\tSeqSetIncrement /\n+\tSeqSetMinMax /\n+\tSeqNoMinMax /\n+\tSeqStartWith /\n+\tSeqOwnedBy\n+\n+SeqSetCycle <- 'NO'i? 'CYCLE'i\n+SeqSetIncrement <- 'INCREMENT'i 'BY'i? Expression\n+SeqSetMinMax <- SeqMinOrMax Expression\n+SeqNoMinMax <- 'NO'i SeqMinOrMax\n+SeqStartWith <- 'START'i 'WITH'i? Expression\n+SeqOwnedBy <- 'OWNED'i 'BY'i QualifiedName\n+\n+\n+SeqMinOrMax <- 'MINVALUE'i / 'MAXVALUE'i\n+\n+\n+Statement <-\n+\tCreateStatement /\n+\tSelectStatement /\n+\tSetStatement /\n+\tPragmaStatement /\n+\tCallStatement /\n+\tInsertStatement /\n+\tDropStatement /\n+\tCopyStatement /\n+\tExplainStatement /\n+\tUpdateStatement /\n+\tPrepareStatement /\n+\tExecuteStatement /\n+\tAlterStatement /\n+\tTransactionStatement /\n+\tDeleteStatement /\n+\tAttachStatement /\n+\tUseStatement /\n+\tDetachStatement /\n+\tCheckpointStatement /\n+\tVacuumStatement /\n+\tResetStatement /\n+\tExportStatement /\n+\tImportStatement /\n+\tCommentStatement /\n+\tDeallocateStatement /\n+\tTruncateStatement\n+\n+TypeName <- Identifier\n+CatalogName <- Identifier\n+SchemaName <- Identifier\n+TableName <- Identifier\n+ColumnName <- Identifier\n+IndexName <- Identifier\n+FunctionName <- Identifier\n+SettingName <- Identifier\n+PragmaName <- Identifier\n+TableFunctionName <- Identifier\n+ConstraintName <- Identifier\n+SequenceName <- Identifier\n+CollationName <- Identifier\n+CopyOptionName <- Identifier\n+SecretName <- Identifier\n+\n+NumberLiteral <- < [+-]?[0-9]*([.][0-9]*)? >\n+StringLiteral <- '\\'' [^\\']* '\\''\n+\n+Type <- (TimeType / RowType / MapType / UnionType / DoubleType / SimpleType) ArrayBounds*\n+SimpleType <- QualifiedTypeName TypeModifiers?\n+DoubleType <- 'DOUBLE'i 'PRECISION'\n+QualifiedTypeName <- CatalogQualification? SchemaQualification? TypeName\n+TypeModifiers <- Parens(List(Expression))\n+RowType <- RowOrStruct Parens(List(IdentifierType))\n+UnionType <- 'UNION'i Parens(List(IdentifierType))\n+MapType <- 'MAP'i Parens(List(Type))\n+IdentifierType <- Identifier Type\n+ArrayBounds <- ('[' NumberLiteral? ']') / 'ARRAY'\n+TimeType <- TimeOrTimestamp TypeModifiers? TimeZone?\n+TimeOrTimestamp <- 'TIME'i / 'TIMESTAMP'i\n+TimeZone <- WithOrWithout 'TIME'i 'ZONE'i\n+WithOrWithout <- 'WITH'i / 'WITHOUT'i\n+\n+RowOrStruct <- 'ROW'i / 'STRUCT'i\n+\n+# keywords\n+ReservedKeyword <- 'ALL'i /\n+'ANALYSE'i /\n+'ANALYZE'i /\n+'AND'i /\n+'ANY'i /\n+'ARRAY'i /\n+'AS'i /\n+'ASC_P'i /\n+'ASYMMETRIC'i /\n+'BOTH'i /\n+'CASE'i /\n+'CAST'i /\n+'CHECK_P'i /\n+'COLLATE'i /\n+'COLUMN'i /\n+'CONSTRAINT'i /\n+'CREATE_P'i /\n+'DEFAULT'i /\n+'DEFERRABLE'i /\n+'DESC_P'i /\n+'DESCRIBE'i /\n+'DISTINCT'i /\n+'DO'i /\n+'ELSE'i /\n+'END_P'i /\n+'EXCEPT'i /\n+'FALSE_P'i /\n+'FETCH'i /\n+'FOR'i /\n+'FOREIGN'i /\n+'FROM'i /\n+'GRANT'i /\n+'GROUP_P'i /\n+'HAVING'i /\n+'QUALIFY'i /\n+'IN_P'i /\n+'INITIALLY'i /\n+'INTERSECT'i /\n+'INTO'i /\n+'LATERAL_P'i /\n+'LEADING'i /\n+'LIMIT'i /\n+'NOT'i /\n+'NULL_P'i /\n+'OFFSET'i /\n+'ON'i /\n+'ONLY'i /\n+'OR'i /\n+'ORDER'i /\n+'PIVOT'i /\n+'PIVOT_WIDER'i /\n+'PIVOT_LONGER'i /\n+'PLACING'i /\n+'PRIMARY'i /\n+'REFERENCES'i /\n+'RETURNING'i /\n+'SELECT'i /\n+'SHOW'i /\n+'SOME'i /\n+'SUMMARIZE'i /\n+'SYMMETRIC'i /\n+'TABLE'i /\n+'THEN'i /\n+'TO'i /\n+'TRAILING'i /\n+'TRUE_P'i /\n+'UNION'i /\n+'UNIQUE'i /\n+'UNPIVOT'i /\n+'USING'i /\n+'VARIADIC'i /\n+'WHEN'i /\n+'WHERE'i /\n+'WINDOW'i /\n+'WITH'i\n+\n+\n+# internal definitions\n+%whitespace <- [ \\t\\n\\r]*\n+List(D) <- D (',' D)* ','?\n+Parens(D) <- '(' D ')'\n+\n+ExplainStatement <- 'EXPLAIN'i 'ANALYZE'i? ExplainOptions? Statement\n+\n+ExplainOptions <- Parens(GenericCopyOptionList)\n+\n+CreateMacroStmt <- MacroOrFunction IfNotExists? QualifiedName List(MacroDefinition)\n+\n+MacroOrFunction <- 'MACRO'i / 'FUNCTION'i\n+\n+MacroDefinition <- Parens(MacroParameters?) 'AS'i (ScalarMacroDefinition / TableMacroDefinition)\n+\n+MacroParameters <- List(MacroParameter)\n+MacroParameter <- NamedParameter / Identifier\n+\n+ScalarMacroDefinition <- Expression\n+TableMacroDefinition <- 'TABLE'i SelectStatement\n+\n+CommentStatement <- 'COMMENT'i 'ON'i CommentOnType ColumnReference 'IS'i CommentValue\n+\n+\n+CommentOnType <- 'TABLE'i / 'SEQUENCE'i / 'FUNCTION'i / ('MACRO'i 'TABLE'i?) / 'VIEW'i / 'DATABASE'i / 'INDEX'i / 'SCHEMA'i / 'TYPE'i / 'COLUMN'i\n+CommentValue <- 'NULL'i / StringLiteral\n+\n+AttachStatement <- 'ATTACH'i IfNotExists? Database? DatabasePath AttachAlias? AttachOptions?\n+\n+Database <- 'DATABASE'i\n+DatabasePath <- StringLiteral\n+AttachAlias <- 'AS'i Identifier\n+AttachOptions <- Parens(GenericCopyOptionList)\n+\n+DetachStatement <- 'DETACH'i Database? IfExists? CatalogName\n+\n+UseStatement <- 'USE'i UseTarget\n+\n+UseTarget <- (CatalogName '.' SchemaName) / SchemaName / CatalogName\n+\n+CallStatement <- 'CALL'i TableFunctionName TableFunctionArguments\n+\ndiff --git a/extension/core_functions/lambda_functions.cpp b/extension/core_functions/lambda_functions.cpp\nindex b5549914a964..29e583591ee8 100644\n--- a/extension/core_functions/lambda_functions.cpp\n+++ b/extension/core_functions/lambda_functions.cpp\n@@ -223,17 +223,6 @@ void ExecuteExpression(const idx_t elem_cnt, const LambdaFunctions::ColumnInfo &\n // ListLambdaBindData\n //===--------------------------------------------------------------------===//\n \n-unique_ptr<FunctionData> ListLambdaBindData::Copy() const {\n-\tauto lambda_expr_copy = lambda_expr ? lambda_expr->Copy() : nullptr;\n-\treturn make_uniq<ListLambdaBindData>(return_type, std::move(lambda_expr_copy), has_index);\n-}\n-\n-bool ListLambdaBindData::Equals(const FunctionData &other_p) const {\n-\tauto &other = other_p.Cast<ListLambdaBindData>();\n-\treturn Expression::Equals(lambda_expr, other.lambda_expr) && return_type == other.return_type &&\n-\t       has_index == other.has_index;\n-}\n-\n void ListLambdaBindData::Serialize(Serializer &serializer, const optional_ptr<FunctionData> bind_data_p,\n                                    const ScalarFunction &) {\n \tauto &bind_data = bind_data_p->Cast<ListLambdaBindData>();\ndiff --git a/extension/icu/icu-datefunc.cpp b/extension/icu/icu-datefunc.cpp\nindex a8092b628de9..c744b6870a49 100644\n--- a/extension/icu/icu-datefunc.cpp\n+++ b/extension/icu/icu-datefunc.cpp\n@@ -71,13 +71,20 @@ unique_ptr<FunctionData> ICUDateFunc::Bind(ClientContext &context, ScalarFunctio\n \treturn make_uniq<BindData>(context);\n }\n \n-void ICUDateFunc::SetTimeZone(icu::Calendar *calendar, const string_t &tz_id) {\n+bool ICUDateFunc::TrySetTimeZone(icu::Calendar *calendar, const string_t &tz_id) {\n \tauto tz = icu::TimeZone::createTimeZone(icu::UnicodeString::fromUTF8(icu::StringPiece(tz_id.GetString())));\n \tif (*tz == icu::TimeZone::getUnknown()) {\n \t\tdelete tz;\n-\t\tthrow NotImplementedException(\"Unknown TimeZone '%s'\", tz_id.GetString());\n+\t\treturn false;\n \t}\n \tcalendar->adoptTimeZone(tz);\n+\treturn true;\n+}\n+\n+void ICUDateFunc::SetTimeZone(icu::Calendar *calendar, const string_t &tz_id) {\n+\tif (!TrySetTimeZone(calendar, tz_id)) {\n+\t\tthrow NotImplementedException(\"Unknown TimeZone '%s'\", tz_id.GetString());\n+\t}\n }\n \n timestamp_t ICUDateFunc::GetTimeUnsafe(icu::Calendar *calendar, uint64_t micros) {\ndiff --git a/extension/icu/icu-strptime.cpp b/extension/icu/icu-strptime.cpp\nindex d4a841d49560..298b0b2e5ff2 100644\n--- a/extension/icu/icu-strptime.cpp\n+++ b/extension/icu/icu-strptime.cpp\n@@ -12,6 +12,7 @@\n #include \"duckdb/function/scalar/strftime_format.hpp\"\n #include \"duckdb/main/client_context.hpp\"\n #include \"duckdb/planner/expression/bound_function_expression.hpp\"\n+#include \"duckdb/function/cast/default_casts.hpp\"\n #include \"duckdb/main/extension_util.hpp\"\n \n namespace duckdb {\n@@ -57,14 +58,7 @@ struct ICUStrptime : public ICUDateFunc {\n \t}\n \n \tstatic uint64_t ToMicros(icu::Calendar *calendar, const ParseResult &parsed, const StrpTimeFormat &format) {\n-\t\t// Set TZ first, if any.\n-\t\t// Note that empty TZ names are not allowed,\n-\t\t// but unknown names will map to GMT.\n-\t\tif (!parsed.tz.empty()) {\n-\t\t\tSetTimeZone(calendar, parsed.tz);\n-\t\t}\n-\n-\t\t// Now get the parts in the given time zone\n+\t\t// Get the parts in the current time zone\n \t\tuint64_t micros = parsed.GetMicros();\n \t\tcalendar->set(UCAL_EXTENDED_YEAR, parsed.data[0]); // strptime doesn't understand eras\n \t\tcalendar->set(UCAL_MONTH, parsed.data[1] - 1);\n@@ -107,6 +101,11 @@ struct ICUStrptime : public ICUDateFunc {\n \t\t\t\t\t\tif (parsed.is_special) {\n \t\t\t\t\t\t\treturn parsed.ToTimestamp();\n \t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\t// Set TZ first, if any.\n+\t\t\t\t\t\t\tif (!parsed.tz.empty()) {\n+\t\t\t\t\t\t\t\tSetTimeZone(calendar, parsed.tz);\n+\t\t\t\t\t\t\t}\n+\n \t\t\t\t\t\t\treturn GetTime(calendar, ToMicros(calendar, parsed, format));\n \t\t\t\t\t\t}\n \t\t\t\t\t}\n@@ -140,7 +139,7 @@ struct ICUStrptime : public ICUDateFunc {\n \t\t\t\t\t    if (format.Parse(input, parsed)) {\n \t\t\t\t\t\t    if (parsed.is_special) {\n \t\t\t\t\t\t\t    return parsed.ToTimestamp();\n-\t\t\t\t\t\t    } else {\n+\t\t\t\t\t\t    } else if (parsed.tz.empty() || TrySetTimeZone(calendar, parsed.tz)) {\n \t\t\t\t\t\t\t    timestamp_t result;\n \t\t\t\t\t\t\t    if (TryGetTime(calendar, ToMicros(calendar, parsed, format), result)) {\n \t\t\t\t\t\t\t\t    return result;\ndiff --git a/extension/icu/include/icu-datefunc.hpp b/extension/icu/include/icu-datefunc.hpp\nindex 2c837f2f1ffd..cc14203242f7 100644\n--- a/extension/icu/include/icu-datefunc.hpp\n+++ b/extension/icu/include/icu-datefunc.hpp\n@@ -49,7 +49,9 @@ struct ICUDateFunc {\n \tstatic duckdb::unique_ptr<FunctionData> Bind(ClientContext &context, ScalarFunction &bound_function,\n \t                                             vector<duckdb::unique_ptr<Expression>> &arguments);\n \n-\t//! Sets the time zone for the calendar.\n+\t//! Tries to set the time zone for the calendar and returns false if it is not valid.\n+\tstatic bool TrySetTimeZone(icu::Calendar *calendar, const string_t &tz_id);\n+\t//! Sets the time zone for the calendar. Throws if it is not valid\n \tstatic void SetTimeZone(icu::Calendar *calendar, const string_t &tz_id);\n \t//! Gets the timestamp from the calendar, throwing if it is not in range.\n \tstatic bool TryGetTime(icu::Calendar *calendar, uint64_t micros, timestamp_t &result);\ndiff --git a/extension/parquet/include/writer/primitive_column_writer.hpp b/extension/parquet/include/writer/primitive_column_writer.hpp\nindex f3bea0323b1f..1093b7783e49 100644\n--- a/extension/parquet/include/writer/primitive_column_writer.hpp\n+++ b/extension/parquet/include/writer/primitive_column_writer.hpp\n@@ -20,6 +20,7 @@ struct PageInformation {\n \tidx_t row_count = 0;\n \tidx_t empty_count = 0;\n \tidx_t estimated_page_size = 0;\n+\tidx_t null_count = 0;\n };\n \n struct PageWriteInformation {\ndiff --git a/extension/parquet/include/writer/templated_column_writer.hpp b/extension/parquet/include/writer/templated_column_writer.hpp\nindex 7bf1fa205f9b..481c6881df6b 100644\n--- a/extension/parquet/include/writer/templated_column_writer.hpp\n+++ b/extension/parquet/include/writer/templated_column_writer.hpp\n@@ -131,7 +131,8 @@ class StandardColumnWriter : public PrimitiveColumnWriter {\n \t\tauto &state = state_p.Cast<StandardColumnWriterState<SRC, TGT, OP>>();\n \t\tconst auto &page_info = state_p.page_info[page_idx];\n \t\tauto result = make_uniq<StandardWriterPageState<SRC, TGT, OP>>(\n-\t\t    page_info.row_count - page_info.empty_count, state.total_string_size, state.encoding, state.dictionary);\n+\t\t    page_info.row_count - (page_info.empty_count + page_info.null_count), state.total_string_size,\n+\t\t    state.encoding, state.dictionary);\n \t\treturn std::move(result);\n \t}\n \ndiff --git a/extension/parquet/writer/primitive_column_writer.cpp b/extension/parquet/writer/primitive_column_writer.cpp\nindex d6a0a00f2cc5..c0c2367175be 100644\n--- a/extension/parquet/writer/primitive_column_writer.cpp\n+++ b/extension/parquet/writer/primitive_column_writer.cpp\n@@ -75,6 +75,8 @@ void PrimitiveColumnWriter::Prepare(ColumnWriterState &state_p, ColumnWriterStat\n \t\t\t\t\tstate.page_info.push_back(new_info);\n \t\t\t\t\tpage_info_ref = state.page_info.back();\n \t\t\t\t}\n+\t\t\t} else {\n+\t\t\t\tpage_info.null_count++;\n \t\t\t}\n \t\t\tvector_index++;\n \t\t}\ndiff --git a/scripts/generate_c_api.py b/scripts/generate_c_api.py\nindex 17fafcd6341b..b81e4c2c5a95 100644\n--- a/scripts/generate_c_api.py\n+++ b/scripts/generate_c_api.py\n@@ -296,7 +296,7 @@ def create_function_declaration(function_obj):\n     function_return_type = function_obj['return_type']\n \n     # Construct function declaration\n-    result += f'DUCKDB_API {function_return_type}'\n+    result += f'DUCKDB_C_API {function_return_type}'\n     if result[-1] != '*':\n         result += ' '\n     result += f'{function_name}('\ndiff --git a/scripts/generate_extensions_function.py b/scripts/generate_extensions_function.py\nindex eefd6dfffb06..75ec0a731798 100644\n--- a/scripts/generate_extensions_function.py\n+++ b/scripts/generate_extensions_function.py\n@@ -724,7 +724,8 @@ def write_header(data: ExtensionData):\n     \"postgres_scanner\",\n     \"tpcds\",\n     \"tpch\",\n-    \"uc_catalog\"\n+    \"uc_catalog\",\n+    \"ui\"\n }; // END_OF_AUTOLOADABLE_EXTENSIONS\n \n } // namespace duckdb\"\"\"\ndiff --git a/src/catalog/catalog.cpp b/src/catalog/catalog.cpp\nindex 7d7e52657629..6821de734f0a 100644\n--- a/src/catalog/catalog.cpp\n+++ b/src/catalog/catalog.cpp\n@@ -769,6 +769,12 @@ CatalogEntryLookup Catalog::TryLookupEntry(CatalogEntryRetriever &retriever, Cat\n \n \tif (if_not_found == OnEntryNotFound::RETURN_NULL) {\n \t\treturn {nullptr, nullptr, ErrorData()};\n+\t}\n+\t// Check if the default database is actually attached. CreateMissingEntryException will throw binder exception\n+\t// otherwise.\n+\tif (!GetCatalogEntry(context, GetDefaultCatalog(retriever))) {\n+\t\tauto except = CatalogException(\"%s with name %s does not exist!\", CatalogTypeToString(type), name);\n+\t\treturn {nullptr, nullptr, ErrorData(except)};\n \t} else {\n \t\tauto except = CreateMissingEntryException(retriever, name, type, schemas, error_context);\n \t\treturn {nullptr, nullptr, ErrorData(except)};\n@@ -805,6 +811,12 @@ CatalogEntryLookup Catalog::TryLookupEntry(CatalogEntryRetriever &retriever, vec\n \n \tif (if_not_found == OnEntryNotFound::RETURN_NULL) {\n \t\treturn {nullptr, nullptr, ErrorData()};\n+\t}\n+\t// Check if the default database is actually attached. CreateMissingEntryException will throw binder exception\n+\t// otherwise.\n+\tif (!GetCatalogEntry(context, GetDefaultCatalog(retriever))) {\n+\t\tauto except = CatalogException(\"%s with name %s does not exist!\", CatalogTypeToString(type), name);\n+\t\treturn {nullptr, nullptr, ErrorData(except)};\n \t} else {\n \t\tauto except = CreateMissingEntryException(retriever, name, type, schemas, error_context);\n \t\treturn {nullptr, nullptr, ErrorData(except)};\ndiff --git a/src/catalog/catalog_entry/duck_table_entry.cpp b/src/catalog/catalog_entry/duck_table_entry.cpp\nindex d12bc557e7aa..e2cd7110eb08 100644\n--- a/src/catalog/catalog_entry/duck_table_entry.cpp\n+++ b/src/catalog/catalog_entry/duck_table_entry.cpp\n@@ -863,7 +863,7 @@ unique_ptr<CatalogEntry> DuckTableEntry::Copy(ClientContext &context) const {\n \t}\n \n \tauto binder = Binder::CreateBinder(context);\n-\tauto bound_create_info = binder->BindCreateTableInfo(std::move(create_info), schema);\n+\tauto bound_create_info = binder->BindCreateTableCheckpoint(std::move(create_info), schema);\n \treturn make_uniq<DuckTableEntry>(catalog, schema, *bound_create_info, storage);\n }\n \ndiff --git a/src/execution/aggregate_hashtable.cpp b/src/execution/aggregate_hashtable.cpp\nindex 852e3aa4f900..2b9c5d82a7ca 100644\n--- a/src/execution/aggregate_hashtable.cpp\n+++ b/src/execution/aggregate_hashtable.cpp\n@@ -329,7 +329,7 @@ optional_idx GroupedAggregateHashTable::TryAddDictionaryGroups(DataChunk &groups\n \tif (dictionary_id.empty()) {\n \t\t// dictionary has no id, we can't cache across vectors\n \t\t// only use dictionary compression if there are fewer entries than groups\n-\t\tif (dict_size >= groups.size() * DICTIONARY_THRESHOLD) {\n+\t\tif (dict_size * DICTIONARY_THRESHOLD >= groups.size()) {\n \t\t\t// dictionary is too large - use regular aggregation\n \t\t\treturn optional_idx();\n \t\t}\ndiff --git a/src/execution/index/art/art.cpp b/src/execution/index/art/art.cpp\nindex 2d0f00301083..c47f7740b976 100644\n--- a/src/execution/index/art/art.cpp\n+++ b/src/execution/index/art/art.cpp\n@@ -1038,9 +1038,11 @@ string ART::GenerateConstraintErrorMessage(VerifyExistenceType verify_type, cons\n \t}\n \tcase VerifyExistenceType::DELETE_FK: {\n \t\t// DELETE_FK that still exists in a FK table, i.e., not a valid delete.\n-\t\treturn StringUtil::Format(\"Violates foreign key constraint because key \\\"%s\\\" is still referenced by a foreign \"\n-\t\t                          \"key in a different table\",\n-\t\t                          key_name);\n+\t\treturn StringUtil::Format(\n+\t\t    \"Violates foreign key constraint because key \\\"%s\\\" is still referenced by a foreign \"\n+\t\t    \"key in a different table. If this is an unexpected constraint violation, please refer to our \"\n+\t\t    \"foreign key limitations in the documentation\",\n+\t\t    key_name);\n \t}\n \tdefault:\n \t\tthrow NotImplementedException(\"Type not implemented for VerifyExistenceType\");\n@@ -1091,16 +1093,27 @@ void ART::VerifyLeaf(const Node &leaf, const ARTKey &key, optional_ptr<ART> dele\n \t\treturn;\n \t}\n \n+\t// Fast path for FOREIGN KEY constraints.\n+\t// Up to here, the above code paths work implicitly for FKs, as the leaf is inlined.\n \t// FIXME: proper foreign key + delete ART support.\n-\t// This implicitly works for foreign keys, as we do not have to consider the actual row IDs.\n-\t// We only need to know that there are conflicts (for now), as we still perform over-eager constraint checking.\n+\tif (index_constraint_type == IndexConstraintType::FOREIGN) {\n+\t\tD_ASSERT(!deleted_leaf);\n+\t\t// We don't handle FK conflicts in UPSERT, so the row ID should not matter.\n+\t\tif (manager.AddHit(i, MAX_ROW_ID)) {\n+\t\t\tconflict_idx = i;\n+\t\t}\n+\t\treturn;\n+\t}\n \n \t// Scan the two row IDs in the leaf.\n \tIterator it(*this);\n \tit.FindMinimum(leaf);\n \tARTKey empty_key = ARTKey();\n \tunsafe_vector<row_t> row_ids;\n-\tit.Scan(empty_key, 2, row_ids, false);\n+\tauto success = it.Scan(empty_key, 2, row_ids, false);\n+\tif (!success || row_ids.size() != 2) {\n+\t\tthrow InternalException(\"VerifyLeaf expects exactly two row IDs to be scanned\");\n+\t}\n \n \tif (!deleted_leaf) {\n \t\tif (manager.AddHit(i, row_ids[0]) || manager.AddHit(i, row_ids[1])) {\ndiff --git a/src/execution/operator/csv_scanner/sniffer/dialect_detection.cpp b/src/execution/operator/csv_scanner/sniffer/dialect_detection.cpp\nindex a6e9f915597d..7791e64b420d 100644\n--- a/src/execution/operator/csv_scanner/sniffer/dialect_detection.cpp\n+++ b/src/execution/operator/csv_scanner/sniffer/dialect_detection.cpp\n@@ -397,7 +397,13 @@ void CSVSniffer::AnalyzeDialectCandidate(unique_ptr<ColumnCountScanner> scanner,\n \t\t\t\t}\n \t\t\t}\n \t\t}\n-\t\tif (max_columns_found == num_cols && ignored_rows > min_ignored_rows) {\n+\t\tif (max_columns_found == num_cols && (ignored_rows > min_ignored_rows)) {\n+\t\t\treturn;\n+\t\t}\n+\t\tif (max_columns_found > 1 && num_cols > max_columns_found && consistent_rows < best_consistent_rows / 2 &&\n+\t\t    options.null_padding) {\n+\t\t\t// When null_padding is true, we only give preference to a max number of columns if null padding is at least\n+\t\t\t// 50% as consistent as the best case scenario\n \t\t\treturn;\n \t\t}\n \t\tif (quoted && num_cols < max_columns_found) {\n@@ -436,28 +442,19 @@ void CSVSniffer::AnalyzeDialectCandidate(unique_ptr<ColumnCountScanner> scanner,\n \t    !require_more_padding && !invalid_padding && num_cols == max_columns_found && comments_are_acceptable) {\n \t\tauto &sniffing_state_machine = scanner->GetStateMachine();\n \n-\t\tbool same_quote_is_candidate = false;\n-\t\tfor (const auto &candidate : candidates) {\n-\t\t\tif (sniffing_state_machine.dialect_options.state_machine_options.quote ==\n-\t\t\t    candidate->GetStateMachine().dialect_options.state_machine_options.quote) {\n-\t\t\t\tsame_quote_is_candidate = true;\n-\t\t\t}\n-\t\t}\n-\t\tif (!same_quote_is_candidate) {\n-\t\t\tif (options.dialect_options.skip_rows.IsSetByUser()) {\n-\t\t\t\t// If skip rows is set by user, and we found dirty notes, we only accept it if either null_padding or\n-\t\t\t\t// ignore_errors is set\n-\t\t\t\tif (dirty_notes != 0 && !options.null_padding && !options.ignore_errors.GetValue()) {\n-\t\t\t\t\treturn;\n-\t\t\t\t}\n-\t\t\t\tsniffing_state_machine.dialect_options.skip_rows = options.dialect_options.skip_rows.GetValue();\n-\t\t\t} else if (!options.null_padding) {\n-\t\t\t\tsniffing_state_machine.dialect_options.skip_rows = dirty_notes;\n+\t\tif (options.dialect_options.skip_rows.IsSetByUser()) {\n+\t\t\t// If skip rows is set by user, and we found dirty notes, we only accept it if either null_padding or\n+\t\t\t// ignore_errors is set\n+\t\t\tif (dirty_notes != 0 && !options.null_padding && !options.ignore_errors.GetValue()) {\n+\t\t\t\treturn;\n \t\t\t}\n-\t\t\tsniffing_state_machine.dialect_options.num_cols = num_cols;\n-\t\t\tlines_sniffed = sniffed_column_counts.result_position;\n-\t\t\tcandidates.emplace_back(std::move(scanner));\n+\t\t\tsniffing_state_machine.dialect_options.skip_rows = options.dialect_options.skip_rows.GetValue();\n+\t\t} else if (!options.null_padding) {\n+\t\t\tsniffing_state_machine.dialect_options.skip_rows = dirty_notes;\n \t\t}\n+\t\tsniffing_state_machine.dialect_options.num_cols = num_cols;\n+\t\tlines_sniffed = sniffed_column_counts.result_position;\n+\t\tcandidates.emplace_back(std::move(scanner));\n \t}\n }\n \ndiff --git a/src/execution/operator/csv_scanner/util/csv_error.cpp b/src/execution/operator/csv_scanner/util/csv_error.cpp\nindex 6b3d5dcb357f..330cae1468a9 100644\n--- a/src/execution/operator/csv_scanner/util/csv_error.cpp\n+++ b/src/execution/operator/csv_scanner/util/csv_error.cpp\n@@ -316,6 +316,7 @@ CSVError CSVError::CastError(const CSVReaderOptions &options, const string &colu\n \t\t       \"correctly parse this column.\"\n \t\t    << '\\n';\n \t}\n+\thow_to_fix_it << \"* Check whether the null string value is set correctly (e.g., nullstr = 'N/A')\" << '\\n';\n \n \treturn CSVError(error.str(), CAST_ERROR, column_idx, csv_row, error_info, row_byte_position, byte_position, options,\n \t                how_to_fix_it.str(), current_path);\ndiff --git a/src/execution/operator/scan/physical_table_scan.cpp b/src/execution/operator/scan/physical_table_scan.cpp\nindex 2c821526cee6..cbccf9bdc38e 100644\n--- a/src/execution/operator/scan/physical_table_scan.cpp\n+++ b/src/execution/operator/scan/physical_table_scan.cpp\n@@ -109,7 +109,17 @@ SourceResultType PhysicalTableScan::GetData(ExecutionContext &context, DataChunk\n \tif (g_state.in_out_final) {\n \t\tfunction.in_out_function_final(context, data, chunk);\n \t}\n-\tfunction.in_out_function(context, data, g_state.input_chunk, chunk);\n+\tswitch (function.in_out_function(context, data, g_state.input_chunk, chunk)) {\n+\tcase OperatorResultType::BLOCKED: {\n+\t\tauto guard = g_state.Lock();\n+\t\treturn g_state.BlockSource(guard, input.interrupt_state);\n+\t}\n+\tdefault:\n+\t\t// FIXME: Handling for other cases (such as NEED_MORE_INPUT) breaks current functionality and extensions that\n+\t\t// might be relying on current behaviour. Needs a rework that is not in scope\n+\t\tbreak;\n+\t}\n+\n \tif (chunk.size() == 0 && function.in_out_function_final) {\n \t\tfunction.in_out_function_final(context, data, chunk);\n \t\tg_state.in_out_final = true;\ndiff --git a/src/execution/radix_partitioned_hashtable.cpp b/src/execution/radix_partitioned_hashtable.cpp\nindex a18cd008712b..8ef1dd519836 100644\n--- a/src/execution/radix_partitioned_hashtable.cpp\n+++ b/src/execution/radix_partitioned_hashtable.cpp\n@@ -97,6 +97,7 @@ struct RadixHTConfig {\n \tvoid SetRadixBits(const idx_t &radix_bits_p);\n \tbool SetRadixBitsToExternal();\n \tidx_t GetRadixBits() const;\n+\tidx_t GetMaximumSinkRadixBits() const;\n \tidx_t GetExternalRadixBits() const;\n \n private:\n@@ -161,7 +162,7 @@ class RadixHTGlobalSinkState : public GlobalSinkState {\n \tClientContext &context;\n \t//! Temporary memory state for managing this hash table's memory usage\n \tunique_ptr<TemporaryMemoryState> temporary_memory_state;\n-\tidx_t minimum_reservation;\n+\tatomic<idx_t> minimum_reservation;\n \n \t//! Whether we've called Finalize\n \tbool finalized;\n@@ -211,11 +212,11 @@ RadixHTGlobalSinkState::RadixHTGlobalSinkState(ClientContext &context_p, const R\n \tauto tuples_per_block = block_alloc_size / radix_ht.GetLayout().GetRowWidth();\n \tidx_t ht_count =\n \t    LossyNumericCast<idx_t>(static_cast<double>(config.sink_capacity) / GroupedAggregateHashTable::LOAD_FACTOR);\n-\tauto num_partitions = RadixPartitioning::NumberOfPartitions(config.GetExternalRadixBits());\n+\tauto num_partitions = RadixPartitioning::NumberOfPartitions(config.GetMaximumSinkRadixBits());\n \tauto count_per_partition = ht_count / num_partitions;\n-\tauto blocks_per_partition = (count_per_partition + tuples_per_block) / tuples_per_block + 1;\n+\tauto blocks_per_partition = (count_per_partition + tuples_per_block) / tuples_per_block;\n \tif (!radix_ht.GetLayout().AllConstant()) {\n-\t\tblocks_per_partition += 2;\n+\t\tblocks_per_partition += 1;\n \t}\n \tauto ht_size = num_partitions * blocks_per_partition * block_alloc_size + config.sink_capacity * sizeof(ht_entry_t);\n \n@@ -281,6 +282,10 @@ idx_t RadixHTConfig::GetRadixBits() const {\n \treturn sink_radix_bits;\n }\n \n+idx_t RadixHTConfig::GetMaximumSinkRadixBits() const {\n+\treturn maximum_sink_radix_bits;\n+}\n+\n idx_t RadixHTConfig::GetExternalRadixBits() const {\n \treturn MAXIMUM_FINAL_SINK_RADIX_BITS;\n }\n@@ -296,8 +301,12 @@ void RadixHTConfig::SetRadixBitsInternal(const idx_t radix_bits_p, bool external\n \t}\n \n \tif (external) {\n+\t\tconst auto partition_multiplier = RadixPartitioning::NumberOfPartitions(radix_bits_p) /\n+\t\t                                  RadixPartitioning::NumberOfPartitions(sink_radix_bits);\n+\t\tsink.minimum_reservation = sink.minimum_reservation * partition_multiplier;\n \t\tsink.external = true;\n \t}\n+\n \tsink_radix_bits = radix_bits_p;\n }\n \n@@ -590,7 +599,7 @@ idx_t RadixPartitionedHashTable::MaxThreads(GlobalSinkState &sink_p) const {\n \n \t// we cannot spill aggregate state memory\n \tconst auto usable_memory = sink.temporary_memory_state->GetReservation() > sink.stored_allocators_size\n-\t                               ? sink.temporary_memory_state->GetReservation() - sink.max_partition_size\n+\t                               ? sink.temporary_memory_state->GetReservation() - sink.stored_allocators_size\n \t                               : 0;\n \t// This many partitions will fit given our reservation (at least 1))\n \tconst auto partitions_fit = MaxValue<idx_t>(usable_memory / sink.max_partition_size, 1);\ndiff --git a/src/function/window/window_aggregate_states.cpp b/src/function/window/window_aggregate_states.cpp\nindex 2a673ec5458d..7c279cf5ed47 100644\n--- a/src/function/window/window_aggregate_states.cpp\n+++ b/src/function/window/window_aggregate_states.cpp\n@@ -7,6 +7,9 @@ WindowAggregateStates::WindowAggregateStates(const AggregateObject &aggr)\n }\n \n void WindowAggregateStates::Initialize(idx_t count) {\n+\t// Don't leak - every Initialize must be matched with a Destroy\n+\tD_ASSERT(states.empty());\n+\n \tstates.resize(count * state_size);\n \tauto state_ptr = states.data();\n \ndiff --git a/src/function/window/window_distinct_aggregator.cpp b/src/function/window/window_distinct_aggregator.cpp\nindex 77e00a02ee58..1c935826fe55 100644\n--- a/src/function/window/window_distinct_aggregator.cpp\n+++ b/src/function/window/window_distinct_aggregator.cpp\n@@ -744,6 +744,9 @@ void WindowDistinctAggregatorLocalState::Evaluate(const WindowDistinctAggregator\n \n \t//\tFinalise the result aggregates and write to the result\n \tstatef.Finalize(result);\n+\n+\t//\tDestruct any non-POD state\n+\tstatef.Destroy();\n }\n \n unique_ptr<WindowAggregatorState> WindowDistinctAggregator::GetLocalState(const WindowAggregatorState &gstate) const {\ndiff --git a/src/include/duckdb.h b/src/include/duckdb.h\nindex 0a75bd5531ed..3537ac5d6028 100644\n--- a/src/include/duckdb.h\n+++ b/src/include/duckdb.h\n@@ -13,20 +13,19 @@\n \n #pragma once\n \n-//! duplicate of duckdb/main/winapi.hpp\n-#ifndef DUCKDB_API\n+#ifndef DUCKDB_C_API\n #ifdef _WIN32\n #ifdef DUCKDB_STATIC_BUILD\n-#define DUCKDB_API\n+#define DUCKDB_C_API\n #else\n #if defined(DUCKDB_BUILD_LIBRARY) && !defined(DUCKDB_BUILD_LOADABLE_EXTENSION)\n-#define DUCKDB_API __declspec(dllexport)\n+#define DUCKDB_C_API __declspec(dllexport)\n #else\n-#define DUCKDB_API __declspec(dllimport)\n+#define DUCKDB_C_API __declspec(dllimport)\n #endif\n #endif\n #else\n-#define DUCKDB_API\n+#define DUCKDB_C_API\n #endif\n #endif\n \n@@ -696,7 +695,7 @@ process. Must be destroyed with 'duckdb_destroy_instance_cache'.\n \n * @return The database instance cache.\n */\n-DUCKDB_API duckdb_instance_cache duckdb_create_instance_cache();\n+DUCKDB_C_API duckdb_instance_cache duckdb_create_instance_cache();\n \n /*!\n Creates a new database instance in the instance cache, or retrieves an existing database instance.\n@@ -710,16 +709,16 @@ Must be closed with 'duckdb_close'.\n Note that the error message must be freed using `duckdb_free`.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_get_or_create_from_cache(duckdb_instance_cache instance_cache, const char *path,\n-                                                        duckdb_database *out_database, duckdb_config config,\n-                                                        char **out_error);\n+DUCKDB_C_API duckdb_state duckdb_get_or_create_from_cache(duckdb_instance_cache instance_cache, const char *path,\n+                                                          duckdb_database *out_database, duckdb_config config,\n+                                                          char **out_error);\n \n /*!\n Destroys an existing database instance cache and de-allocates its memory.\n \n * @param instance_cache The instance cache to destroy.\n */\n-DUCKDB_API void duckdb_destroy_instance_cache(duckdb_instance_cache *instance_cache);\n+DUCKDB_C_API void duckdb_destroy_instance_cache(duckdb_instance_cache *instance_cache);\n \n /*!\n Creates a new database or opens an existing database file stored at the given path.\n@@ -730,7 +729,7 @@ The database must be closed with 'duckdb_close'.\n * @param out_database The result database object.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_open(const char *path, duckdb_database *out_database);\n+DUCKDB_C_API duckdb_state duckdb_open(const char *path, duckdb_database *out_database);\n \n /*!\n Extended version of duckdb_open. Creates a new database or opens an existing database file stored at the given path.\n@@ -743,8 +742,8 @@ The database must be closed with 'duckdb_close'.\n Note that the error message must be freed using `duckdb_free`.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_open_ext(const char *path, duckdb_database *out_database, duckdb_config config,\n-                                        char **out_error);\n+DUCKDB_C_API duckdb_state duckdb_open_ext(const char *path, duckdb_database *out_database, duckdb_config config,\n+                                          char **out_error);\n \n /*!\n Closes the specified database and de-allocates all memory allocated for that database.\n@@ -754,7 +753,7 @@ Still, it is recommended to always correctly close a database object after you a\n \n * @param database The database object to shut down.\n */\n-DUCKDB_API void duckdb_close(duckdb_database *database);\n+DUCKDB_C_API void duckdb_close(duckdb_database *database);\n \n /*!\n Opens a connection to a database. Connections are required to query the database, and store transactional state\n@@ -765,14 +764,14 @@ The instantiated connection should be closed using 'duckdb_disconnect'.\n * @param out_connection The result connection object.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_connect(duckdb_database database, duckdb_connection *out_connection);\n+DUCKDB_C_API duckdb_state duckdb_connect(duckdb_database database, duckdb_connection *out_connection);\n \n /*!\n Interrupt running query\n \n * @param connection The connection to interrupt\n */\n-DUCKDB_API void duckdb_interrupt(duckdb_connection connection);\n+DUCKDB_C_API void duckdb_interrupt(duckdb_connection connection);\n \n /*!\n Get progress of the running query\n@@ -780,21 +779,21 @@ Get progress of the running query\n * @param connection The working connection\n * @return -1 if no progress or a percentage of the progress\n */\n-DUCKDB_API duckdb_query_progress_type duckdb_query_progress(duckdb_connection connection);\n+DUCKDB_C_API duckdb_query_progress_type duckdb_query_progress(duckdb_connection connection);\n \n /*!\n Closes the specified connection and de-allocates all memory allocated for that connection.\n \n * @param connection The connection to close.\n */\n-DUCKDB_API void duckdb_disconnect(duckdb_connection *connection);\n+DUCKDB_C_API void duckdb_disconnect(duckdb_connection *connection);\n \n /*!\n Returns the version of the linked DuckDB, with a version postfix for dev versions\n \n Usually used for developing C extensions that must return this for a compatibility check.\n */\n-DUCKDB_API const char *duckdb_library_version();\n+DUCKDB_C_API const char *duckdb_library_version();\n \n //===--------------------------------------------------------------------===//\n // Configuration\n@@ -813,7 +812,7 @@ Note that `duckdb_destroy_config` should always be called on the resulting confi\n * @param out_config The result configuration object.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_create_config(duckdb_config *out_config);\n+DUCKDB_C_API duckdb_state duckdb_create_config(duckdb_config *out_config);\n \n /*!\n This returns the total amount of configuration options available for usage with `duckdb_get_config_flag`.\n@@ -822,7 +821,7 @@ This should not be called in a loop as it internally loops over all the options.\n \n * @return The amount of config options available.\n */\n-DUCKDB_API size_t duckdb_config_count();\n+DUCKDB_C_API size_t duckdb_config_count();\n \n /*!\n Obtains a human-readable name and description of a specific configuration option. This can be used to e.g.\n@@ -835,7 +834,7 @@ The result name or description MUST NOT be freed.\n * @param out_description A description of the configuration flag.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_get_config_flag(size_t index, const char **out_name, const char **out_description);\n+DUCKDB_C_API duckdb_state duckdb_get_config_flag(size_t index, const char **out_name, const char **out_description);\n \n /*!\n Sets the specified option for the specified configuration. The configuration option is indicated by name.\n@@ -850,14 +849,14 @@ This can fail if either the name is invalid, or if the value provided for the op\n * @param option The value to set the configuration flag to.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_set_config(duckdb_config config, const char *name, const char *option);\n+DUCKDB_C_API duckdb_state duckdb_set_config(duckdb_config config, const char *name, const char *option);\n \n /*!\n Destroys the specified configuration object and de-allocates all memory allocated for the object.\n \n * @param config The configuration object to destroy.\n */\n-DUCKDB_API void duckdb_destroy_config(duckdb_config *config);\n+DUCKDB_C_API void duckdb_destroy_config(duckdb_config *config);\n \n //===--------------------------------------------------------------------===//\n // Query Execution\n@@ -876,14 +875,14 @@ query fails, otherwise the error stored within the result will not be freed corr\n * @param out_result The query result.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_query(duckdb_connection connection, const char *query, duckdb_result *out_result);\n+DUCKDB_C_API duckdb_state duckdb_query(duckdb_connection connection, const char *query, duckdb_result *out_result);\n \n /*!\n Closes the result and de-allocates all memory allocated for that connection.\n \n * @param result The result to destroy.\n */\n-DUCKDB_API void duckdb_destroy_result(duckdb_result *result);\n+DUCKDB_C_API void duckdb_destroy_result(duckdb_result *result);\n \n /*!\n Returns the column name of the specified column. The result should not need to be freed; the column names will\n@@ -895,7 +894,7 @@ Returns `NULL` if the column is out of range.\n * @param col The column index.\n * @return The column name of the specified column.\n */\n-DUCKDB_API const char *duckdb_column_name(duckdb_result *result, idx_t col);\n+DUCKDB_C_API const char *duckdb_column_name(duckdb_result *result, idx_t col);\n \n /*!\n Returns the column type of the specified column.\n@@ -906,7 +905,7 @@ Returns `DUCKDB_TYPE_INVALID` if the column is out of range.\n * @param col The column index.\n * @return The column type of the specified column.\n */\n-DUCKDB_API duckdb_type duckdb_column_type(duckdb_result *result, idx_t col);\n+DUCKDB_C_API duckdb_type duckdb_column_type(duckdb_result *result, idx_t col);\n \n /*!\n Returns the statement type of the statement that was executed\n@@ -914,7 +913,7 @@ Returns the statement type of the statement that was executed\n * @param result The result object to fetch the statement type from.\n * @return duckdb_statement_type value or DUCKDB_STATEMENT_TYPE_INVALID\n */\n-DUCKDB_API duckdb_statement_type duckdb_result_statement_type(duckdb_result result);\n+DUCKDB_C_API duckdb_statement_type duckdb_result_statement_type(duckdb_result result);\n \n /*!\n Returns the logical column type of the specified column.\n@@ -927,7 +926,7 @@ Returns `NULL` if the column is out of range.\n * @param col The column index.\n * @return The logical column type of the specified column.\n */\n-DUCKDB_API duckdb_logical_type duckdb_column_logical_type(duckdb_result *result, idx_t col);\n+DUCKDB_C_API duckdb_logical_type duckdb_column_logical_type(duckdb_result *result, idx_t col);\n \n /*!\n Returns the number of columns present in a the result object.\n@@ -935,7 +934,7 @@ Returns the number of columns present in a the result object.\n * @param result The result object.\n * @return The number of columns present in the result object.\n */\n-DUCKDB_API idx_t duckdb_column_count(duckdb_result *result);\n+DUCKDB_C_API idx_t duckdb_column_count(duckdb_result *result);\n \n #ifndef DUCKDB_API_NO_DEPRECATED\n /*!\n@@ -946,7 +945,7 @@ Returns the number of rows present in the result object.\n * @param result The result object.\n * @return The number of rows present in the result object.\n */\n-DUCKDB_API idx_t duckdb_row_count(duckdb_result *result);\n+DUCKDB_C_API idx_t duckdb_row_count(duckdb_result *result);\n \n #endif\n /*!\n@@ -956,7 +955,7 @@ queries. For other queries the rows_changed will be 0.\n * @param result The result object.\n * @return The number of rows changed.\n */\n-DUCKDB_API idx_t duckdb_rows_changed(duckdb_result *result);\n+DUCKDB_C_API idx_t duckdb_rows_changed(duckdb_result *result);\n \n #ifndef DUCKDB_API_NO_DEPRECATED\n /*!\n@@ -978,7 +977,7 @@ printf(\"Data for row %d: %d\\n\", row, data[row]);\n * @param col The column index.\n * @return The column data of the specified column.\n */\n-DUCKDB_API void *duckdb_column_data(duckdb_result *result, idx_t col);\n+DUCKDB_C_API void *duckdb_column_data(duckdb_result *result, idx_t col);\n \n /*!\n **DEPRECATED**: Prefer using `duckdb_result_get_chunk` instead.\n@@ -1001,7 +1000,7 @@ if (nullmask[row]) {\n * @param col The column index.\n * @return The nullmask of the specified column.\n */\n-DUCKDB_API bool *duckdb_nullmask_data(duckdb_result *result, idx_t col);\n+DUCKDB_C_API bool *duckdb_nullmask_data(duckdb_result *result, idx_t col);\n \n #endif\n /*!\n@@ -1012,7 +1011,7 @@ The result of this function must not be freed. It will be cleaned up when `duckd\n * @param result The result object to fetch the error from.\n * @return The error of the result.\n */\n-DUCKDB_API const char *duckdb_result_error(duckdb_result *result);\n+DUCKDB_C_API const char *duckdb_result_error(duckdb_result *result);\n \n /*!\n Returns the result error type contained within the result. The error is only set if `duckdb_query` returns\n@@ -1021,7 +1020,7 @@ Returns the result error type contained within the result. The error is only set\n * @param result The result object to fetch the error from.\n * @return The error type of the result.\n */\n-DUCKDB_API duckdb_error_type duckdb_result_error_type(duckdb_result *result);\n+DUCKDB_C_API duckdb_error_type duckdb_result_error_type(duckdb_result *result);\n \n //===--------------------------------------------------------------------===//\n // Result Functions\n@@ -1047,7 +1046,7 @@ Use `duckdb_result_chunk_count` to figure out how many chunks there are in the r\n * @param chunk_index The chunk index to fetch from.\n * @return The resulting data chunk. Returns `NULL` if the chunk index is out of bounds.\n */\n-DUCKDB_API duckdb_data_chunk duckdb_result_get_chunk(duckdb_result result, idx_t chunk_index);\n+DUCKDB_C_API duckdb_data_chunk duckdb_result_get_chunk(duckdb_result result, idx_t chunk_index);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n@@ -1057,7 +1056,7 @@ Checks if the type of the internal result is StreamQueryResult.\n * @param result The result object to check.\n * @return Whether or not the result object is of the type StreamQueryResult\n */\n-DUCKDB_API bool duckdb_result_is_streaming(duckdb_result result);\n+DUCKDB_C_API bool duckdb_result_is_streaming(duckdb_result result);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n@@ -1067,7 +1066,7 @@ Returns the number of data chunks present in the result.\n * @param result The result object\n * @return Number of data chunks present in the result.\n */\n-DUCKDB_API idx_t duckdb_result_chunk_count(duckdb_result result);\n+DUCKDB_C_API idx_t duckdb_result_chunk_count(duckdb_result result);\n \n #endif\n /*!\n@@ -1076,7 +1075,7 @@ Returns the return_type of the given result, or DUCKDB_RETURN_TYPE_INVALID on er\n * @param result The result object\n * @return The return_type\n */\n-DUCKDB_API duckdb_result_type duckdb_result_return_type(duckdb_result result);\n+DUCKDB_C_API duckdb_result_type duckdb_result_return_type(duckdb_result result);\n \n //===--------------------------------------------------------------------===//\n // Safe Fetch Functions\n@@ -1092,126 +1091,126 @@ DUCKDB_API duckdb_result_type duckdb_result_return_type(duckdb_result result);\n \n * @return The boolean value at the specified location, or false if the value cannot be converted.\n */\n-DUCKDB_API bool duckdb_value_boolean(duckdb_result *result, idx_t col, idx_t row);\n+DUCKDB_C_API bool duckdb_value_boolean(duckdb_result *result, idx_t col, idx_t row);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n \n * @return The int8_t value at the specified location, or 0 if the value cannot be converted.\n */\n-DUCKDB_API int8_t duckdb_value_int8(duckdb_result *result, idx_t col, idx_t row);\n+DUCKDB_C_API int8_t duckdb_value_int8(duckdb_result *result, idx_t col, idx_t row);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n \n * @return The int16_t value at the specified location, or 0 if the value cannot be converted.\n */\n-DUCKDB_API int16_t duckdb_value_int16(duckdb_result *result, idx_t col, idx_t row);\n+DUCKDB_C_API int16_t duckdb_value_int16(duckdb_result *result, idx_t col, idx_t row);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n \n * @return The int32_t value at the specified location, or 0 if the value cannot be converted.\n */\n-DUCKDB_API int32_t duckdb_value_int32(duckdb_result *result, idx_t col, idx_t row);\n+DUCKDB_C_API int32_t duckdb_value_int32(duckdb_result *result, idx_t col, idx_t row);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n \n * @return The int64_t value at the specified location, or 0 if the value cannot be converted.\n */\n-DUCKDB_API int64_t duckdb_value_int64(duckdb_result *result, idx_t col, idx_t row);\n+DUCKDB_C_API int64_t duckdb_value_int64(duckdb_result *result, idx_t col, idx_t row);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n \n * @return The duckdb_hugeint value at the specified location, or 0 if the value cannot be converted.\n */\n-DUCKDB_API duckdb_hugeint duckdb_value_hugeint(duckdb_result *result, idx_t col, idx_t row);\n+DUCKDB_C_API duckdb_hugeint duckdb_value_hugeint(duckdb_result *result, idx_t col, idx_t row);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n \n * @return The duckdb_uhugeint value at the specified location, or 0 if the value cannot be converted.\n */\n-DUCKDB_API duckdb_uhugeint duckdb_value_uhugeint(duckdb_result *result, idx_t col, idx_t row);\n+DUCKDB_C_API duckdb_uhugeint duckdb_value_uhugeint(duckdb_result *result, idx_t col, idx_t row);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n \n * @return The duckdb_decimal value at the specified location, or 0 if the value cannot be converted.\n */\n-DUCKDB_API duckdb_decimal duckdb_value_decimal(duckdb_result *result, idx_t col, idx_t row);\n+DUCKDB_C_API duckdb_decimal duckdb_value_decimal(duckdb_result *result, idx_t col, idx_t row);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n \n * @return The uint8_t value at the specified location, or 0 if the value cannot be converted.\n */\n-DUCKDB_API uint8_t duckdb_value_uint8(duckdb_result *result, idx_t col, idx_t row);\n+DUCKDB_C_API uint8_t duckdb_value_uint8(duckdb_result *result, idx_t col, idx_t row);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n \n * @return The uint16_t value at the specified location, or 0 if the value cannot be converted.\n */\n-DUCKDB_API uint16_t duckdb_value_uint16(duckdb_result *result, idx_t col, idx_t row);\n+DUCKDB_C_API uint16_t duckdb_value_uint16(duckdb_result *result, idx_t col, idx_t row);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n \n * @return The uint32_t value at the specified location, or 0 if the value cannot be converted.\n */\n-DUCKDB_API uint32_t duckdb_value_uint32(duckdb_result *result, idx_t col, idx_t row);\n+DUCKDB_C_API uint32_t duckdb_value_uint32(duckdb_result *result, idx_t col, idx_t row);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n \n * @return The uint64_t value at the specified location, or 0 if the value cannot be converted.\n */\n-DUCKDB_API uint64_t duckdb_value_uint64(duckdb_result *result, idx_t col, idx_t row);\n+DUCKDB_C_API uint64_t duckdb_value_uint64(duckdb_result *result, idx_t col, idx_t row);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n \n * @return The float value at the specified location, or 0 if the value cannot be converted.\n */\n-DUCKDB_API float duckdb_value_float(duckdb_result *result, idx_t col, idx_t row);\n+DUCKDB_C_API float duckdb_value_float(duckdb_result *result, idx_t col, idx_t row);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n \n * @return The double value at the specified location, or 0 if the value cannot be converted.\n */\n-DUCKDB_API double duckdb_value_double(duckdb_result *result, idx_t col, idx_t row);\n+DUCKDB_C_API double duckdb_value_double(duckdb_result *result, idx_t col, idx_t row);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n \n * @return The duckdb_date value at the specified location, or 0 if the value cannot be converted.\n */\n-DUCKDB_API duckdb_date duckdb_value_date(duckdb_result *result, idx_t col, idx_t row);\n+DUCKDB_C_API duckdb_date duckdb_value_date(duckdb_result *result, idx_t col, idx_t row);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n \n * @return The duckdb_time value at the specified location, or 0 if the value cannot be converted.\n */\n-DUCKDB_API duckdb_time duckdb_value_time(duckdb_result *result, idx_t col, idx_t row);\n+DUCKDB_C_API duckdb_time duckdb_value_time(duckdb_result *result, idx_t col, idx_t row);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n \n * @return The duckdb_timestamp value at the specified location, or 0 if the value cannot be converted.\n */\n-DUCKDB_API duckdb_timestamp duckdb_value_timestamp(duckdb_result *result, idx_t col, idx_t row);\n+DUCKDB_C_API duckdb_timestamp duckdb_value_timestamp(duckdb_result *result, idx_t col, idx_t row);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n \n * @return The duckdb_interval value at the specified location, or 0 if the value cannot be converted.\n */\n-DUCKDB_API duckdb_interval duckdb_value_interval(duckdb_result *result, idx_t col, idx_t row);\n+DUCKDB_C_API duckdb_interval duckdb_value_interval(duckdb_result *result, idx_t col, idx_t row);\n \n /*!\n **DEPRECATED**: Use duckdb_value_string instead. This function does not work correctly if the string contains null\n@@ -1220,7 +1219,7 @@ bytes.\n * @return The text value at the specified location as a null-terminated string, or nullptr if the value cannot be\n converted. The result must be freed with `duckdb_free`.\n */\n-DUCKDB_API char *duckdb_value_varchar(duckdb_result *result, idx_t col, idx_t row);\n+DUCKDB_C_API char *duckdb_value_varchar(duckdb_result *result, idx_t col, idx_t row);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n@@ -1230,7 +1229,7 @@ The resulting field \"string.data\" must be freed with `duckdb_free.`\n \n * @return The string value at the specified location. Attempts to cast the result value to string.\n */\n-DUCKDB_API duckdb_string duckdb_value_string(duckdb_result *result, idx_t col, idx_t row);\n+DUCKDB_C_API duckdb_string duckdb_value_string(duckdb_result *result, idx_t col, idx_t row);\n \n /*!\n **DEPRECATED**: Use duckdb_value_string_internal instead. This function does not work correctly if the string contains\n@@ -1241,7 +1240,7 @@ If the column is NOT a VARCHAR column this function will return NULL.\n \n The result must NOT be freed.\n */\n-DUCKDB_API char *duckdb_value_varchar_internal(duckdb_result *result, idx_t col, idx_t row);\n+DUCKDB_C_API char *duckdb_value_varchar_internal(duckdb_result *result, idx_t col, idx_t row);\n \n /*!\n **DEPRECATED**: Use duckdb_value_string_internal instead. This function does not work correctly if the string contains\n@@ -1251,7 +1250,7 @@ If the column is NOT a VARCHAR column this function will return NULL.\n \n The result must NOT be freed.\n */\n-DUCKDB_API duckdb_string duckdb_value_string_internal(duckdb_result *result, idx_t col, idx_t row);\n+DUCKDB_C_API duckdb_string duckdb_value_string_internal(duckdb_result *result, idx_t col, idx_t row);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n@@ -1259,14 +1258,14 @@ DUCKDB_API duckdb_string duckdb_value_string_internal(duckdb_result *result, idx\n * @return The duckdb_blob value at the specified location. Returns a blob with blob.data set to nullptr if the\n value cannot be converted. The resulting field \"blob.data\" must be freed with `duckdb_free.`\n */\n-DUCKDB_API duckdb_blob duckdb_value_blob(duckdb_result *result, idx_t col, idx_t row);\n+DUCKDB_C_API duckdb_blob duckdb_value_blob(duckdb_result *result, idx_t col, idx_t row);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n \n * @return Returns true if the value at the specified index is NULL, and false otherwise.\n */\n-DUCKDB_API bool duckdb_value_is_null(duckdb_result *result, idx_t col, idx_t row);\n+DUCKDB_C_API bool duckdb_value_is_null(duckdb_result *result, idx_t col, idx_t row);\n \n #endif\n //===--------------------------------------------------------------------===//\n@@ -1280,7 +1279,7 @@ should be freed using `duckdb_free`.\n * @param size The number of bytes to allocate.\n * @return A pointer to the allocated memory region.\n */\n-DUCKDB_API void *duckdb_malloc(size_t size);\n+DUCKDB_C_API void *duckdb_malloc(size_t size);\n \n /*!\n Free a value returned from `duckdb_malloc`, `duckdb_value_varchar`, `duckdb_value_blob`, or\n@@ -1288,7 +1287,7 @@ Free a value returned from `duckdb_malloc`, `duckdb_value_varchar`, `duckdb_valu\n \n * @param ptr The memory region to de-allocate.\n */\n-DUCKDB_API void duckdb_free(void *ptr);\n+DUCKDB_C_API void duckdb_free(void *ptr);\n \n /*!\n The internal vector size used by DuckDB.\n@@ -1296,14 +1295,14 @@ This is the amount of tuples that will fit into a data chunk created by `duckdb_\n \n * @return The vector size.\n */\n-DUCKDB_API idx_t duckdb_vector_size();\n+DUCKDB_C_API idx_t duckdb_vector_size();\n \n /*!\n Whether or not the duckdb_string_t value is inlined.\n This means that the data of the string does not have a separate allocation.\n \n */\n-DUCKDB_API bool duckdb_string_is_inlined(duckdb_string_t string);\n+DUCKDB_C_API bool duckdb_string_is_inlined(duckdb_string_t string);\n \n /*!\n Get the string length of a string_t\n@@ -1311,7 +1310,7 @@ Get the string length of a string_t\n * @param string The string to get the length of.\n * @return The length.\n */\n-DUCKDB_API uint32_t duckdb_string_t_length(duckdb_string_t string);\n+DUCKDB_C_API uint32_t duckdb_string_t_length(duckdb_string_t string);\n \n /*!\n Get a pointer to the string data of a string_t\n@@ -1319,7 +1318,7 @@ Get a pointer to the string data of a string_t\n * @param string The string to get the pointer to.\n * @return The pointer.\n */\n-DUCKDB_API const char *duckdb_string_t_data(duckdb_string_t *string);\n+DUCKDB_C_API const char *duckdb_string_t_data(duckdb_string_t *string);\n \n //===--------------------------------------------------------------------===//\n // Date Time Timestamp Helpers\n@@ -1331,7 +1330,7 @@ Decompose a `duckdb_date` object into year, month and date (stored as `duckdb_da\n * @param date The date object, as obtained from a `DUCKDB_TYPE_DATE` column.\n * @return The `duckdb_date_struct` with the decomposed elements.\n */\n-DUCKDB_API duckdb_date_struct duckdb_from_date(duckdb_date date);\n+DUCKDB_C_API duckdb_date_struct duckdb_from_date(duckdb_date date);\n \n /*!\n Re-compose a `duckdb_date` from year, month and date (`duckdb_date_struct`).\n@@ -1339,7 +1338,7 @@ Re-compose a `duckdb_date` from year, month and date (`duckdb_date_struct`).\n * @param date The year, month and date stored in a `duckdb_date_struct`.\n * @return The `duckdb_date` element.\n */\n-DUCKDB_API duckdb_date duckdb_to_date(duckdb_date_struct date);\n+DUCKDB_C_API duckdb_date duckdb_to_date(duckdb_date_struct date);\n \n /*!\n Test a `duckdb_date` to see if it is a finite value.\n@@ -1347,7 +1346,7 @@ Test a `duckdb_date` to see if it is a finite value.\n * @param date The date object, as obtained from a `DUCKDB_TYPE_DATE` column.\n * @return True if the date is finite, false if it is \u00b1infinity.\n */\n-DUCKDB_API bool duckdb_is_finite_date(duckdb_date date);\n+DUCKDB_C_API bool duckdb_is_finite_date(duckdb_date date);\n \n /*!\n Decompose a `duckdb_time` object into hour, minute, second and microsecond (stored as `duckdb_time_struct`).\n@@ -1355,7 +1354,7 @@ Decompose a `duckdb_time` object into hour, minute, second and microsecond (stor\n * @param time The time object, as obtained from a `DUCKDB_TYPE_TIME` column.\n * @return The `duckdb_time_struct` with the decomposed elements.\n */\n-DUCKDB_API duckdb_time_struct duckdb_from_time(duckdb_time time);\n+DUCKDB_C_API duckdb_time_struct duckdb_from_time(duckdb_time time);\n \n /*!\n Create a `duckdb_time_tz` object from micros and a timezone offset.\n@@ -1364,7 +1363,7 @@ Create a `duckdb_time_tz` object from micros and a timezone offset.\n * @param offset The timezone offset component of the time.\n * @return The `duckdb_time_tz` element.\n */\n-DUCKDB_API duckdb_time_tz duckdb_create_time_tz(int64_t micros, int32_t offset);\n+DUCKDB_C_API duckdb_time_tz duckdb_create_time_tz(int64_t micros, int32_t offset);\n \n /*!\n Decompose a TIME_TZ objects into micros and a timezone offset.\n@@ -1373,7 +1372,7 @@ Use `duckdb_from_time` to further decompose the micros into hour, minute, second\n \n * @param micros The time object, as obtained from a `DUCKDB_TYPE_TIME_TZ` column.\n */\n-DUCKDB_API duckdb_time_tz_struct duckdb_from_time_tz(duckdb_time_tz micros);\n+DUCKDB_C_API duckdb_time_tz_struct duckdb_from_time_tz(duckdb_time_tz micros);\n \n /*!\n Re-compose a `duckdb_time` from hour, minute, second and microsecond (`duckdb_time_struct`).\n@@ -1381,7 +1380,7 @@ Re-compose a `duckdb_time` from hour, minute, second and microsecond (`duckdb_ti\n * @param time The hour, minute, second and microsecond in a `duckdb_time_struct`.\n * @return The `duckdb_time` element.\n */\n-DUCKDB_API duckdb_time duckdb_to_time(duckdb_time_struct time);\n+DUCKDB_C_API duckdb_time duckdb_to_time(duckdb_time_struct time);\n \n /*!\n Decompose a `duckdb_timestamp` object into a `duckdb_timestamp_struct`.\n@@ -1389,7 +1388,7 @@ Decompose a `duckdb_timestamp` object into a `duckdb_timestamp_struct`.\n * @param ts The ts object, as obtained from a `DUCKDB_TYPE_TIMESTAMP` column.\n * @return The `duckdb_timestamp_struct` with the decomposed elements.\n */\n-DUCKDB_API duckdb_timestamp_struct duckdb_from_timestamp(duckdb_timestamp ts);\n+DUCKDB_C_API duckdb_timestamp_struct duckdb_from_timestamp(duckdb_timestamp ts);\n \n /*!\n Re-compose a `duckdb_timestamp` from a duckdb_timestamp_struct.\n@@ -1397,7 +1396,7 @@ Re-compose a `duckdb_timestamp` from a duckdb_timestamp_struct.\n * @param ts The de-composed elements in a `duckdb_timestamp_struct`.\n * @return The `duckdb_timestamp` element.\n */\n-DUCKDB_API duckdb_timestamp duckdb_to_timestamp(duckdb_timestamp_struct ts);\n+DUCKDB_C_API duckdb_timestamp duckdb_to_timestamp(duckdb_timestamp_struct ts);\n \n /*!\n Test a `duckdb_timestamp` to see if it is a finite value.\n@@ -1405,7 +1404,7 @@ Test a `duckdb_timestamp` to see if it is a finite value.\n * @param ts The duckdb_timestamp object, as obtained from a `DUCKDB_TYPE_TIMESTAMP` column.\n * @return True if the timestamp is finite, false if it is \u00b1infinity.\n */\n-DUCKDB_API bool duckdb_is_finite_timestamp(duckdb_timestamp ts);\n+DUCKDB_C_API bool duckdb_is_finite_timestamp(duckdb_timestamp ts);\n \n /*!\n Test a `duckdb_timestamp_s` to see if it is a finite value.\n@@ -1413,7 +1412,7 @@ Test a `duckdb_timestamp_s` to see if it is a finite value.\n * @param ts The duckdb_timestamp_s object, as obtained from a `DUCKDB_TYPE_TIMESTAMP_S` column.\n * @return True if the timestamp is finite, false if it is \u00b1infinity.\n */\n-DUCKDB_API bool duckdb_is_finite_timestamp_s(duckdb_timestamp_s ts);\n+DUCKDB_C_API bool duckdb_is_finite_timestamp_s(duckdb_timestamp_s ts);\n \n /*!\n Test a `duckdb_timestamp_ms` to see if it is a finite value.\n@@ -1421,7 +1420,7 @@ Test a `duckdb_timestamp_ms` to see if it is a finite value.\n * @param ts The duckdb_timestamp_ms object, as obtained from a `DUCKDB_TYPE_TIMESTAMP_MS` column.\n * @return True if the timestamp is finite, false if it is \u00b1infinity.\n */\n-DUCKDB_API bool duckdb_is_finite_timestamp_ms(duckdb_timestamp_ms ts);\n+DUCKDB_C_API bool duckdb_is_finite_timestamp_ms(duckdb_timestamp_ms ts);\n \n /*!\n Test a `duckdb_timestamp_ns` to see if it is a finite value.\n@@ -1429,7 +1428,7 @@ Test a `duckdb_timestamp_ns` to see if it is a finite value.\n * @param ts The duckdb_timestamp_ns object, as obtained from a `DUCKDB_TYPE_TIMESTAMP_NS` column.\n * @return True if the timestamp is finite, false if it is \u00b1infinity.\n */\n-DUCKDB_API bool duckdb_is_finite_timestamp_ns(duckdb_timestamp_ns ts);\n+DUCKDB_C_API bool duckdb_is_finite_timestamp_ns(duckdb_timestamp_ns ts);\n \n //===--------------------------------------------------------------------===//\n // Hugeint Helpers\n@@ -1441,7 +1440,7 @@ Converts a duckdb_hugeint object (as obtained from a `DUCKDB_TYPE_HUGEINT` colum\n * @param val The hugeint value.\n * @return The converted `double` element.\n */\n-DUCKDB_API double duckdb_hugeint_to_double(duckdb_hugeint val);\n+DUCKDB_C_API double duckdb_hugeint_to_double(duckdb_hugeint val);\n \n /*!\n Converts a double value to a duckdb_hugeint object.\n@@ -1451,7 +1450,7 @@ If the conversion fails because the double value is too big the result will be 0\n * @param val The double value.\n * @return The converted `duckdb_hugeint` element.\n */\n-DUCKDB_API duckdb_hugeint duckdb_double_to_hugeint(double val);\n+DUCKDB_C_API duckdb_hugeint duckdb_double_to_hugeint(double val);\n \n //===--------------------------------------------------------------------===//\n // Unsigned Hugeint Helpers\n@@ -1463,7 +1462,7 @@ Converts a duckdb_uhugeint object (as obtained from a `DUCKDB_TYPE_UHUGEINT` col\n * @param val The uhugeint value.\n * @return The converted `double` element.\n */\n-DUCKDB_API double duckdb_uhugeint_to_double(duckdb_uhugeint val);\n+DUCKDB_C_API double duckdb_uhugeint_to_double(duckdb_uhugeint val);\n \n /*!\n Converts a double value to a duckdb_uhugeint object.\n@@ -1473,7 +1472,7 @@ If the conversion fails because the double value is too big the result will be 0\n * @param val The double value.\n * @return The converted `duckdb_uhugeint` element.\n */\n-DUCKDB_API duckdb_uhugeint duckdb_double_to_uhugeint(double val);\n+DUCKDB_C_API duckdb_uhugeint duckdb_double_to_uhugeint(double val);\n \n //===--------------------------------------------------------------------===//\n // Decimal Helpers\n@@ -1487,7 +1486,7 @@ If the conversion fails because the double value is too big, or the width/scale\n * @param val The double value.\n * @return The converted `duckdb_decimal` element.\n */\n-DUCKDB_API duckdb_decimal duckdb_double_to_decimal(double val, uint8_t width, uint8_t scale);\n+DUCKDB_C_API duckdb_decimal duckdb_double_to_decimal(double val, uint8_t width, uint8_t scale);\n \n /*!\n Converts a duckdb_decimal object (as obtained from a `DUCKDB_TYPE_DECIMAL` column) into a double.\n@@ -1495,7 +1494,7 @@ Converts a duckdb_decimal object (as obtained from a `DUCKDB_TYPE_DECIMAL` colum\n * @param val The decimal value.\n * @return The converted `double` element.\n */\n-DUCKDB_API double duckdb_decimal_to_double(duckdb_decimal val);\n+DUCKDB_C_API double duckdb_decimal_to_double(duckdb_decimal val);\n \n //===--------------------------------------------------------------------===//\n // Prepared Statements\n@@ -1523,15 +1522,15 @@ If the prepare fails, `duckdb_prepare_error` can be called to obtain the reason\n * @param out_prepared_statement The resulting prepared statement object\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_prepare(duckdb_connection connection, const char *query,\n-                                       duckdb_prepared_statement *out_prepared_statement);\n+DUCKDB_C_API duckdb_state duckdb_prepare(duckdb_connection connection, const char *query,\n+                                         duckdb_prepared_statement *out_prepared_statement);\n \n /*!\n Closes the prepared statement and de-allocates all memory allocated for the statement.\n \n * @param prepared_statement The prepared statement to destroy.\n */\n-DUCKDB_API void duckdb_destroy_prepare(duckdb_prepared_statement *prepared_statement);\n+DUCKDB_C_API void duckdb_destroy_prepare(duckdb_prepared_statement *prepared_statement);\n \n /*!\n Returns the error message associated with the given prepared statement.\n@@ -1542,7 +1541,7 @@ The error message should not be freed. It will be de-allocated when `duckdb_dest\n * @param prepared_statement The prepared statement to obtain the error from.\n * @return The error message, or `nullptr` if there is none.\n */\n-DUCKDB_API const char *duckdb_prepare_error(duckdb_prepared_statement prepared_statement);\n+DUCKDB_C_API const char *duckdb_prepare_error(duckdb_prepared_statement prepared_statement);\n \n /*!\n Returns the number of parameters that can be provided to the given prepared statement.\n@@ -1551,7 +1550,7 @@ Returns 0 if the query was not successfully prepared.\n \n * @param prepared_statement The prepared statement to obtain the number of parameters for.\n */\n-DUCKDB_API idx_t duckdb_nparams(duckdb_prepared_statement prepared_statement);\n+DUCKDB_C_API idx_t duckdb_nparams(duckdb_prepared_statement prepared_statement);\n \n /*!\n Returns the name used to identify the parameter\n@@ -1561,7 +1560,7 @@ Returns NULL if the index is out of range for the provided prepared statement.\n \n * @param prepared_statement The prepared statement for which to get the parameter name from.\n */\n-DUCKDB_API const char *duckdb_parameter_name(duckdb_prepared_statement prepared_statement, idx_t index);\n+DUCKDB_C_API const char *duckdb_parameter_name(duckdb_prepared_statement prepared_statement, idx_t index);\n \n /*!\n Returns the parameter type for the parameter at the given index.\n@@ -1572,7 +1571,7 @@ Returns `DUCKDB_TYPE_INVALID` if the parameter index is out of range or the stat\n * @param param_idx The parameter index.\n * @return The parameter type\n */\n-DUCKDB_API duckdb_type duckdb_param_type(duckdb_prepared_statement prepared_statement, idx_t param_idx);\n+DUCKDB_C_API duckdb_type duckdb_param_type(duckdb_prepared_statement prepared_statement, idx_t param_idx);\n \n /*!\n Returns the logical type for the parameter at the given index.\n@@ -1585,12 +1584,13 @@ The return type of this call should be destroyed with `duckdb_destroy_logical_ty\n * @param param_idx The parameter index.\n * @return The logical type of the parameter\n */\n-DUCKDB_API duckdb_logical_type duckdb_param_logical_type(duckdb_prepared_statement prepared_statement, idx_t param_idx);\n+DUCKDB_C_API duckdb_logical_type duckdb_param_logical_type(duckdb_prepared_statement prepared_statement,\n+                                                           idx_t param_idx);\n \n /*!\n Clear the params bind to the prepared statement.\n */\n-DUCKDB_API duckdb_state duckdb_clear_bindings(duckdb_prepared_statement prepared_statement);\n+DUCKDB_C_API duckdb_state duckdb_clear_bindings(duckdb_prepared_statement prepared_statement);\n \n /*!\n Returns the statement type of the statement to be executed\n@@ -1598,7 +1598,7 @@ Returns the statement type of the statement to be executed\n * @param statement The prepared statement.\n * @return duckdb_statement_type value or DUCKDB_STATEMENT_TYPE_INVALID\n */\n-DUCKDB_API duckdb_statement_type duckdb_prepared_statement_type(duckdb_prepared_statement statement);\n+DUCKDB_C_API duckdb_statement_type duckdb_prepared_statement_type(duckdb_prepared_statement statement);\n \n //===--------------------------------------------------------------------===//\n // Bind Values To Prepared Statements\n@@ -1607,140 +1607,143 @@ DUCKDB_API duckdb_statement_type duckdb_prepared_statement_type(duckdb_prepared_\n /*!\n Binds a value to the prepared statement at the specified index.\n */\n-DUCKDB_API duckdb_state duckdb_bind_value(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n-                                          duckdb_value val);\n+DUCKDB_C_API duckdb_state duckdb_bind_value(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n+                                            duckdb_value val);\n \n /*!\n Retrieve the index of the parameter for the prepared statement, identified by name\n */\n-DUCKDB_API duckdb_state duckdb_bind_parameter_index(duckdb_prepared_statement prepared_statement, idx_t *param_idx_out,\n-                                                    const char *name);\n+DUCKDB_C_API duckdb_state duckdb_bind_parameter_index(duckdb_prepared_statement prepared_statement,\n+                                                      idx_t *param_idx_out, const char *name);\n \n /*!\n Binds a bool value to the prepared statement at the specified index.\n */\n-DUCKDB_API duckdb_state duckdb_bind_boolean(duckdb_prepared_statement prepared_statement, idx_t param_idx, bool val);\n+DUCKDB_C_API duckdb_state duckdb_bind_boolean(duckdb_prepared_statement prepared_statement, idx_t param_idx, bool val);\n \n /*!\n Binds an int8_t value to the prepared statement at the specified index.\n */\n-DUCKDB_API duckdb_state duckdb_bind_int8(duckdb_prepared_statement prepared_statement, idx_t param_idx, int8_t val);\n+DUCKDB_C_API duckdb_state duckdb_bind_int8(duckdb_prepared_statement prepared_statement, idx_t param_idx, int8_t val);\n \n /*!\n Binds an int16_t value to the prepared statement at the specified index.\n */\n-DUCKDB_API duckdb_state duckdb_bind_int16(duckdb_prepared_statement prepared_statement, idx_t param_idx, int16_t val);\n+DUCKDB_C_API duckdb_state duckdb_bind_int16(duckdb_prepared_statement prepared_statement, idx_t param_idx, int16_t val);\n \n /*!\n Binds an int32_t value to the prepared statement at the specified index.\n */\n-DUCKDB_API duckdb_state duckdb_bind_int32(duckdb_prepared_statement prepared_statement, idx_t param_idx, int32_t val);\n+DUCKDB_C_API duckdb_state duckdb_bind_int32(duckdb_prepared_statement prepared_statement, idx_t param_idx, int32_t val);\n \n /*!\n Binds an int64_t value to the prepared statement at the specified index.\n */\n-DUCKDB_API duckdb_state duckdb_bind_int64(duckdb_prepared_statement prepared_statement, idx_t param_idx, int64_t val);\n+DUCKDB_C_API duckdb_state duckdb_bind_int64(duckdb_prepared_statement prepared_statement, idx_t param_idx, int64_t val);\n \n /*!\n Binds a duckdb_hugeint value to the prepared statement at the specified index.\n */\n-DUCKDB_API duckdb_state duckdb_bind_hugeint(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n-                                            duckdb_hugeint val);\n+DUCKDB_C_API duckdb_state duckdb_bind_hugeint(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n+                                              duckdb_hugeint val);\n \n /*!\n Binds an duckdb_uhugeint value to the prepared statement at the specified index.\n */\n-DUCKDB_API duckdb_state duckdb_bind_uhugeint(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n-                                             duckdb_uhugeint val);\n+DUCKDB_C_API duckdb_state duckdb_bind_uhugeint(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n+                                               duckdb_uhugeint val);\n \n /*!\n Binds a duckdb_decimal value to the prepared statement at the specified index.\n */\n-DUCKDB_API duckdb_state duckdb_bind_decimal(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n-                                            duckdb_decimal val);\n+DUCKDB_C_API duckdb_state duckdb_bind_decimal(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n+                                              duckdb_decimal val);\n \n /*!\n Binds an uint8_t value to the prepared statement at the specified index.\n */\n-DUCKDB_API duckdb_state duckdb_bind_uint8(duckdb_prepared_statement prepared_statement, idx_t param_idx, uint8_t val);\n+DUCKDB_C_API duckdb_state duckdb_bind_uint8(duckdb_prepared_statement prepared_statement, idx_t param_idx, uint8_t val);\n \n /*!\n Binds an uint16_t value to the prepared statement at the specified index.\n */\n-DUCKDB_API duckdb_state duckdb_bind_uint16(duckdb_prepared_statement prepared_statement, idx_t param_idx, uint16_t val);\n+DUCKDB_C_API duckdb_state duckdb_bind_uint16(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n+                                             uint16_t val);\n \n /*!\n Binds an uint32_t value to the prepared statement at the specified index.\n */\n-DUCKDB_API duckdb_state duckdb_bind_uint32(duckdb_prepared_statement prepared_statement, idx_t param_idx, uint32_t val);\n+DUCKDB_C_API duckdb_state duckdb_bind_uint32(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n+                                             uint32_t val);\n \n /*!\n Binds an uint64_t value to the prepared statement at the specified index.\n */\n-DUCKDB_API duckdb_state duckdb_bind_uint64(duckdb_prepared_statement prepared_statement, idx_t param_idx, uint64_t val);\n+DUCKDB_C_API duckdb_state duckdb_bind_uint64(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n+                                             uint64_t val);\n \n /*!\n Binds a float value to the prepared statement at the specified index.\n */\n-DUCKDB_API duckdb_state duckdb_bind_float(duckdb_prepared_statement prepared_statement, idx_t param_idx, float val);\n+DUCKDB_C_API duckdb_state duckdb_bind_float(duckdb_prepared_statement prepared_statement, idx_t param_idx, float val);\n \n /*!\n Binds a double value to the prepared statement at the specified index.\n */\n-DUCKDB_API duckdb_state duckdb_bind_double(duckdb_prepared_statement prepared_statement, idx_t param_idx, double val);\n+DUCKDB_C_API duckdb_state duckdb_bind_double(duckdb_prepared_statement prepared_statement, idx_t param_idx, double val);\n \n /*!\n Binds a duckdb_date value to the prepared statement at the specified index.\n */\n-DUCKDB_API duckdb_state duckdb_bind_date(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n-                                         duckdb_date val);\n+DUCKDB_C_API duckdb_state duckdb_bind_date(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n+                                           duckdb_date val);\n \n /*!\n Binds a duckdb_time value to the prepared statement at the specified index.\n */\n-DUCKDB_API duckdb_state duckdb_bind_time(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n-                                         duckdb_time val);\n+DUCKDB_C_API duckdb_state duckdb_bind_time(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n+                                           duckdb_time val);\n \n /*!\n Binds a duckdb_timestamp value to the prepared statement at the specified index.\n */\n-DUCKDB_API duckdb_state duckdb_bind_timestamp(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n-                                              duckdb_timestamp val);\n+DUCKDB_C_API duckdb_state duckdb_bind_timestamp(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n+                                                duckdb_timestamp val);\n \n /*!\n Binds a duckdb_timestamp value to the prepared statement at the specified index.\n */\n-DUCKDB_API duckdb_state duckdb_bind_timestamp_tz(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n-                                                 duckdb_timestamp val);\n+DUCKDB_C_API duckdb_state duckdb_bind_timestamp_tz(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n+                                                   duckdb_timestamp val);\n \n /*!\n Binds a duckdb_interval value to the prepared statement at the specified index.\n */\n-DUCKDB_API duckdb_state duckdb_bind_interval(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n-                                             duckdb_interval val);\n+DUCKDB_C_API duckdb_state duckdb_bind_interval(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n+                                               duckdb_interval val);\n \n /*!\n Binds a null-terminated varchar value to the prepared statement at the specified index.\n */\n-DUCKDB_API duckdb_state duckdb_bind_varchar(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n-                                            const char *val);\n+DUCKDB_C_API duckdb_state duckdb_bind_varchar(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n+                                              const char *val);\n \n /*!\n Binds a varchar value to the prepared statement at the specified index.\n */\n-DUCKDB_API duckdb_state duckdb_bind_varchar_length(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n-                                                   const char *val, idx_t length);\n+DUCKDB_C_API duckdb_state duckdb_bind_varchar_length(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n+                                                     const char *val, idx_t length);\n \n /*!\n Binds a blob value to the prepared statement at the specified index.\n */\n-DUCKDB_API duckdb_state duckdb_bind_blob(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n-                                         const void *data, idx_t length);\n+DUCKDB_C_API duckdb_state duckdb_bind_blob(duckdb_prepared_statement prepared_statement, idx_t param_idx,\n+                                           const void *data, idx_t length);\n \n /*!\n Binds a NULL value to the prepared statement at the specified index.\n */\n-DUCKDB_API duckdb_state duckdb_bind_null(duckdb_prepared_statement prepared_statement, idx_t param_idx);\n+DUCKDB_C_API duckdb_state duckdb_bind_null(duckdb_prepared_statement prepared_statement, idx_t param_idx);\n \n //===--------------------------------------------------------------------===//\n // Execute Prepared Statements\n@@ -1758,8 +1761,8 @@ Note that the result must be freed with `duckdb_destroy_result`.\n * @param out_result The query result.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_execute_prepared(duckdb_prepared_statement prepared_statement,\n-                                                duckdb_result *out_result);\n+DUCKDB_C_API duckdb_state duckdb_execute_prepared(duckdb_prepared_statement prepared_statement,\n+                                                  duckdb_result *out_result);\n \n #ifndef DUCKDB_API_NO_DEPRECATED\n /*!\n@@ -1777,8 +1780,8 @@ Note that the result must be freed with `duckdb_destroy_result`.\n * @param out_result The query result.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_execute_prepared_streaming(duckdb_prepared_statement prepared_statement,\n-                                                          duckdb_result *out_result);\n+DUCKDB_C_API duckdb_state duckdb_execute_prepared_streaming(duckdb_prepared_statement prepared_statement,\n+                                                            duckdb_result *out_result);\n \n #endif\n //===--------------------------------------------------------------------===//\n@@ -1798,8 +1801,8 @@ If the extract fails, `duckdb_extract_statements_error` can be called to obtain\n * @param out_extracted_statements The resulting extracted statements object\n * @return The number of extracted statements or 0 on failure.\n */\n-DUCKDB_API idx_t duckdb_extract_statements(duckdb_connection connection, const char *query,\n-                                           duckdb_extracted_statements *out_extracted_statements);\n+DUCKDB_C_API idx_t duckdb_extract_statements(duckdb_connection connection, const char *query,\n+                                             duckdb_extracted_statements *out_extracted_statements);\n \n /*!\n Prepare an extracted statement.\n@@ -1814,10 +1817,10 @@ If the prepare fails, `duckdb_prepare_error` can be called to obtain the reason\n * @param out_prepared_statement The resulting prepared statement object\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_prepare_extracted_statement(duckdb_connection connection,\n-                                                           duckdb_extracted_statements extracted_statements,\n-                                                           idx_t index,\n-                                                           duckdb_prepared_statement *out_prepared_statement);\n+DUCKDB_C_API duckdb_state duckdb_prepare_extracted_statement(duckdb_connection connection,\n+                                                             duckdb_extracted_statements extracted_statements,\n+                                                             idx_t index,\n+                                                             duckdb_prepared_statement *out_prepared_statement);\n \n /*!\n Returns the error message contained within the extracted statements.\n@@ -1826,13 +1829,13 @@ The result of this function must not be freed. It will be cleaned up when `duckd\n * @param extracted_statements The extracted statements to fetch the error from.\n * @return The error of the extracted statements.\n */\n-DUCKDB_API const char *duckdb_extract_statements_error(duckdb_extracted_statements extracted_statements);\n+DUCKDB_C_API const char *duckdb_extract_statements_error(duckdb_extracted_statements extracted_statements);\n \n /*!\n De-allocates all memory allocated for the extracted statements.\n * @param extracted_statements The extracted statements to destroy.\n */\n-DUCKDB_API void duckdb_destroy_extracted(duckdb_extracted_statements *extracted_statements);\n+DUCKDB_C_API void duckdb_destroy_extracted(duckdb_extracted_statements *extracted_statements);\n \n //===--------------------------------------------------------------------===//\n // Pending Result Interface\n@@ -1850,8 +1853,8 @@ Note that after calling `duckdb_pending_prepared`, the pending result should alw\n * @param out_result The pending query result.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_pending_prepared(duckdb_prepared_statement prepared_statement,\n-                                                duckdb_pending_result *out_result);\n+DUCKDB_C_API duckdb_state duckdb_pending_prepared(duckdb_prepared_statement prepared_statement,\n+                                                  duckdb_pending_result *out_result);\n \n #ifndef DUCKDB_API_NO_DEPRECATED\n /*!\n@@ -1868,8 +1871,8 @@ Note that after calling `duckdb_pending_prepared_streaming`, the pending result\n * @param out_result The pending query result.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_pending_prepared_streaming(duckdb_prepared_statement prepared_statement,\n-                                                          duckdb_pending_result *out_result);\n+DUCKDB_C_API duckdb_state duckdb_pending_prepared_streaming(duckdb_prepared_statement prepared_statement,\n+                                                            duckdb_pending_result *out_result);\n \n #endif\n /*!\n@@ -1877,7 +1880,7 @@ Closes the pending result and de-allocates all memory allocated for the result.\n \n * @param pending_result The pending result to destroy.\n */\n-DUCKDB_API void duckdb_destroy_pending(duckdb_pending_result *pending_result);\n+DUCKDB_C_API void duckdb_destroy_pending(duckdb_pending_result *pending_result);\n \n /*!\n Returns the error message contained within the pending result.\n@@ -1887,7 +1890,7 @@ The result of this function must not be freed. It will be cleaned up when `duckd\n * @param pending_result The pending result to fetch the error from.\n * @return The error of the pending result.\n */\n-DUCKDB_API const char *duckdb_pending_error(duckdb_pending_result pending_result);\n+DUCKDB_C_API const char *duckdb_pending_error(duckdb_pending_result pending_result);\n \n /*!\n Executes a single task within the query, returning whether or not the query is ready.\n@@ -1901,7 +1904,7 @@ The error message can be obtained by calling duckdb_pending_error on the pending\n * @param pending_result The pending result to execute a task within.\n * @return The state of the pending result after the execution.\n */\n-DUCKDB_API duckdb_pending_state duckdb_pending_execute_task(duckdb_pending_result pending_result);\n+DUCKDB_C_API duckdb_pending_state duckdb_pending_execute_task(duckdb_pending_result pending_result);\n \n /*!\n If this returns DUCKDB_PENDING_RESULT_READY, the duckdb_execute_pending function can be called to obtain the result.\n@@ -1913,7 +1916,7 @@ The error message can be obtained by calling duckdb_pending_error on the pending\n * @param pending_result The pending result.\n * @return The state of the pending result.\n */\n-DUCKDB_API duckdb_pending_state duckdb_pending_execute_check_state(duckdb_pending_result pending_result);\n+DUCKDB_C_API duckdb_pending_state duckdb_pending_execute_check_state(duckdb_pending_result pending_result);\n \n /*!\n Fully execute a pending query result, returning the final query result.\n@@ -1927,7 +1930,7 @@ Note that the result must be freed with `duckdb_destroy_result`.\n * @param out_result The result object.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_execute_pending(duckdb_pending_result pending_result, duckdb_result *out_result);\n+DUCKDB_C_API duckdb_state duckdb_execute_pending(duckdb_pending_result pending_result, duckdb_result *out_result);\n \n /*!\n Returns whether a duckdb_pending_state is finished executing. For example if `pending_state` is\n@@ -1936,7 +1939,7 @@ DUCKDB_PENDING_RESULT_READY, this function will return true.\n * @param pending_state The pending state on which to decide whether to finish execution.\n * @return Boolean indicating pending execution should be considered finished.\n */\n-DUCKDB_API bool duckdb_pending_execution_is_finished(duckdb_pending_state pending_state);\n+DUCKDB_C_API bool duckdb_pending_execution_is_finished(duckdb_pending_state pending_state);\n \n //===--------------------------------------------------------------------===//\n // Value Interface\n@@ -1947,7 +1950,7 @@ Destroys the value and de-allocates all memory allocated for that type.\n \n * @param value The value to destroy.\n */\n-DUCKDB_API void duckdb_destroy_value(duckdb_value *value);\n+DUCKDB_C_API void duckdb_destroy_value(duckdb_value *value);\n \n /*!\n Creates a value from a null-terminated string\n@@ -1955,7 +1958,7 @@ Creates a value from a null-terminated string\n * @param text The null-terminated string\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_varchar(const char *text);\n+DUCKDB_C_API duckdb_value duckdb_create_varchar(const char *text);\n \n /*!\n Creates a value from a string\n@@ -1964,7 +1967,7 @@ Creates a value from a string\n * @param length The length of the text\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_varchar_length(const char *text, idx_t length);\n+DUCKDB_C_API duckdb_value duckdb_create_varchar_length(const char *text, idx_t length);\n \n /*!\n Creates a value from a boolean\n@@ -1972,7 +1975,7 @@ Creates a value from a boolean\n * @param input The boolean value\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_bool(bool input);\n+DUCKDB_C_API duckdb_value duckdb_create_bool(bool input);\n \n /*!\n Creates a value from a int8_t (a tinyint)\n@@ -1980,7 +1983,7 @@ Creates a value from a int8_t (a tinyint)\n * @param input The tinyint value\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_int8(int8_t input);\n+DUCKDB_C_API duckdb_value duckdb_create_int8(int8_t input);\n \n /*!\n Creates a value from a uint8_t (a utinyint)\n@@ -1988,7 +1991,7 @@ Creates a value from a uint8_t (a utinyint)\n * @param input The utinyint value\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_uint8(uint8_t input);\n+DUCKDB_C_API duckdb_value duckdb_create_uint8(uint8_t input);\n \n /*!\n Creates a value from a int16_t (a smallint)\n@@ -1996,7 +1999,7 @@ Creates a value from a int16_t (a smallint)\n * @param input The smallint value\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_int16(int16_t input);\n+DUCKDB_C_API duckdb_value duckdb_create_int16(int16_t input);\n \n /*!\n Creates a value from a uint16_t (a usmallint)\n@@ -2004,7 +2007,7 @@ Creates a value from a uint16_t (a usmallint)\n * @param input The usmallint value\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_uint16(uint16_t input);\n+DUCKDB_C_API duckdb_value duckdb_create_uint16(uint16_t input);\n \n /*!\n Creates a value from a int32_t (an integer)\n@@ -2012,7 +2015,7 @@ Creates a value from a int32_t (an integer)\n * @param input The integer value\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_int32(int32_t input);\n+DUCKDB_C_API duckdb_value duckdb_create_int32(int32_t input);\n \n /*!\n Creates a value from a uint32_t (a uinteger)\n@@ -2020,7 +2023,7 @@ Creates a value from a uint32_t (a uinteger)\n * @param input The uinteger value\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_uint32(uint32_t input);\n+DUCKDB_C_API duckdb_value duckdb_create_uint32(uint32_t input);\n \n /*!\n Creates a value from a uint64_t (a ubigint)\n@@ -2028,14 +2031,14 @@ Creates a value from a uint64_t (a ubigint)\n * @param input The ubigint value\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_uint64(uint64_t input);\n+DUCKDB_C_API duckdb_value duckdb_create_uint64(uint64_t input);\n \n /*!\n Creates a value from an int64\n \n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_int64(int64_t val);\n+DUCKDB_C_API duckdb_value duckdb_create_int64(int64_t val);\n \n /*!\n Creates a value from a hugeint\n@@ -2043,7 +2046,7 @@ Creates a value from a hugeint\n * @param input The hugeint value\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_hugeint(duckdb_hugeint input);\n+DUCKDB_C_API duckdb_value duckdb_create_hugeint(duckdb_hugeint input);\n \n /*!\n Creates a value from a uhugeint\n@@ -2051,7 +2054,7 @@ Creates a value from a uhugeint\n * @param input The uhugeint value\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_uhugeint(duckdb_uhugeint input);\n+DUCKDB_C_API duckdb_value duckdb_create_uhugeint(duckdb_uhugeint input);\n \n /*!\n Creates a VARINT value from a duckdb_varint\n@@ -2059,7 +2062,7 @@ Creates a VARINT value from a duckdb_varint\n * @param input The duckdb_varint value\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_varint(duckdb_varint input);\n+DUCKDB_C_API duckdb_value duckdb_create_varint(duckdb_varint input);\n \n /*!\n Creates a DECIMAL value from a duckdb_decimal\n@@ -2067,7 +2070,7 @@ Creates a DECIMAL value from a duckdb_decimal\n * @param input The duckdb_decimal value\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_decimal(duckdb_decimal input);\n+DUCKDB_C_API duckdb_value duckdb_create_decimal(duckdb_decimal input);\n \n /*!\n Creates a value from a float\n@@ -2075,7 +2078,7 @@ Creates a value from a float\n * @param input The float value\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_float(float input);\n+DUCKDB_C_API duckdb_value duckdb_create_float(float input);\n \n /*!\n Creates a value from a double\n@@ -2083,7 +2086,7 @@ Creates a value from a double\n * @param input The double value\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_double(double input);\n+DUCKDB_C_API duckdb_value duckdb_create_double(double input);\n \n /*!\n Creates a value from a date\n@@ -2091,7 +2094,7 @@ Creates a value from a date\n * @param input The date value\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_date(duckdb_date input);\n+DUCKDB_C_API duckdb_value duckdb_create_date(duckdb_date input);\n \n /*!\n Creates a value from a time\n@@ -2099,7 +2102,7 @@ Creates a value from a time\n * @param input The time value\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_time(duckdb_time input);\n+DUCKDB_C_API duckdb_value duckdb_create_time(duckdb_time input);\n \n /*!\n Creates a value from a time_tz.\n@@ -2108,7 +2111,7 @@ Not to be confused with `duckdb_create_time_tz`, which creates a duckdb_time_tz_\n * @param value The time_tz value\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_time_tz_value(duckdb_time_tz value);\n+DUCKDB_C_API duckdb_value duckdb_create_time_tz_value(duckdb_time_tz value);\n \n /*!\n Creates a TIMESTAMP value from a duckdb_timestamp\n@@ -2116,7 +2119,7 @@ Creates a TIMESTAMP value from a duckdb_timestamp\n * @param input The duckdb_timestamp value\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_timestamp(duckdb_timestamp input);\n+DUCKDB_C_API duckdb_value duckdb_create_timestamp(duckdb_timestamp input);\n \n /*!\n Creates a TIMESTAMP_TZ value from a duckdb_timestamp\n@@ -2124,7 +2127,7 @@ Creates a TIMESTAMP_TZ value from a duckdb_timestamp\n * @param input The duckdb_timestamp value\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_timestamp_tz(duckdb_timestamp input);\n+DUCKDB_C_API duckdb_value duckdb_create_timestamp_tz(duckdb_timestamp input);\n \n /*!\n Creates a TIMESTAMP_S value from a duckdb_timestamp_s\n@@ -2132,7 +2135,7 @@ Creates a TIMESTAMP_S value from a duckdb_timestamp_s\n * @param input The duckdb_timestamp_s value\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_timestamp_s(duckdb_timestamp_s input);\n+DUCKDB_C_API duckdb_value duckdb_create_timestamp_s(duckdb_timestamp_s input);\n \n /*!\n Creates a TIMESTAMP_MS value from a duckdb_timestamp_ms\n@@ -2140,7 +2143,7 @@ Creates a TIMESTAMP_MS value from a duckdb_timestamp_ms\n * @param input The duckdb_timestamp_ms value\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_timestamp_ms(duckdb_timestamp_ms input);\n+DUCKDB_C_API duckdb_value duckdb_create_timestamp_ms(duckdb_timestamp_ms input);\n \n /*!\n Creates a TIMESTAMP_NS value from a duckdb_timestamp_ns\n@@ -2148,7 +2151,7 @@ Creates a TIMESTAMP_NS value from a duckdb_timestamp_ns\n * @param input The duckdb_timestamp_ns value\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_timestamp_ns(duckdb_timestamp_ns input);\n+DUCKDB_C_API duckdb_value duckdb_create_timestamp_ns(duckdb_timestamp_ns input);\n \n /*!\n Creates a value from an interval\n@@ -2156,7 +2159,7 @@ Creates a value from an interval\n * @param input The interval value\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_interval(duckdb_interval input);\n+DUCKDB_C_API duckdb_value duckdb_create_interval(duckdb_interval input);\n \n /*!\n Creates a value from a blob\n@@ -2165,7 +2168,7 @@ Creates a value from a blob\n * @param length The length of the blob data\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_blob(const uint8_t *data, idx_t length);\n+DUCKDB_C_API duckdb_value duckdb_create_blob(const uint8_t *data, idx_t length);\n \n /*!\n Creates a BIT value from a duckdb_bit\n@@ -2173,7 +2176,7 @@ Creates a BIT value from a duckdb_bit\n * @param input The duckdb_bit value\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_bit(duckdb_bit input);\n+DUCKDB_C_API duckdb_value duckdb_create_bit(duckdb_bit input);\n \n /*!\n Creates a UUID value from a uhugeint\n@@ -2181,7 +2184,7 @@ Creates a UUID value from a uhugeint\n * @param input The duckdb_uhugeint containing the UUID\n * @return The value. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_uuid(duckdb_uhugeint input);\n+DUCKDB_C_API duckdb_value duckdb_create_uuid(duckdb_uhugeint input);\n \n /*!\n Returns the boolean value of the given value.\n@@ -2189,7 +2192,7 @@ Returns the boolean value of the given value.\n * @param val A duckdb_value containing a boolean\n * @return A boolean, or false if the value cannot be converted\n */\n-DUCKDB_API bool duckdb_get_bool(duckdb_value val);\n+DUCKDB_C_API bool duckdb_get_bool(duckdb_value val);\n \n /*!\n Returns the int8_t value of the given value.\n@@ -2197,7 +2200,7 @@ Returns the int8_t value of the given value.\n * @param val A duckdb_value containing a tinyint\n * @return A int8_t, or MinValue<int8> if the value cannot be converted\n */\n-DUCKDB_API int8_t duckdb_get_int8(duckdb_value val);\n+DUCKDB_C_API int8_t duckdb_get_int8(duckdb_value val);\n \n /*!\n Returns the uint8_t value of the given value.\n@@ -2205,7 +2208,7 @@ Returns the uint8_t value of the given value.\n * @param val A duckdb_value containing a utinyint\n * @return A uint8_t, or MinValue<uint8> if the value cannot be converted\n */\n-DUCKDB_API uint8_t duckdb_get_uint8(duckdb_value val);\n+DUCKDB_C_API uint8_t duckdb_get_uint8(duckdb_value val);\n \n /*!\n Returns the int16_t value of the given value.\n@@ -2213,7 +2216,7 @@ Returns the int16_t value of the given value.\n * @param val A duckdb_value containing a smallint\n * @return A int16_t, or MinValue<int16> if the value cannot be converted\n */\n-DUCKDB_API int16_t duckdb_get_int16(duckdb_value val);\n+DUCKDB_C_API int16_t duckdb_get_int16(duckdb_value val);\n \n /*!\n Returns the uint16_t value of the given value.\n@@ -2221,7 +2224,7 @@ Returns the uint16_t value of the given value.\n * @param val A duckdb_value containing a usmallint\n * @return A uint16_t, or MinValue<uint16> if the value cannot be converted\n */\n-DUCKDB_API uint16_t duckdb_get_uint16(duckdb_value val);\n+DUCKDB_C_API uint16_t duckdb_get_uint16(duckdb_value val);\n \n /*!\n Returns the int32_t value of the given value.\n@@ -2229,7 +2232,7 @@ Returns the int32_t value of the given value.\n * @param val A duckdb_value containing a integer\n * @return A int32_t, or MinValue<int32> if the value cannot be converted\n */\n-DUCKDB_API int32_t duckdb_get_int32(duckdb_value val);\n+DUCKDB_C_API int32_t duckdb_get_int32(duckdb_value val);\n \n /*!\n Returns the uint32_t value of the given value.\n@@ -2237,7 +2240,7 @@ Returns the uint32_t value of the given value.\n * @param val A duckdb_value containing a uinteger\n * @return A uint32_t, or MinValue<uint32> if the value cannot be converted\n */\n-DUCKDB_API uint32_t duckdb_get_uint32(duckdb_value val);\n+DUCKDB_C_API uint32_t duckdb_get_uint32(duckdb_value val);\n \n /*!\n Returns the int64_t value of the given value.\n@@ -2245,7 +2248,7 @@ Returns the int64_t value of the given value.\n * @param val A duckdb_value containing a bigint\n * @return A int64_t, or MinValue<int64> if the value cannot be converted\n */\n-DUCKDB_API int64_t duckdb_get_int64(duckdb_value val);\n+DUCKDB_C_API int64_t duckdb_get_int64(duckdb_value val);\n \n /*!\n Returns the uint64_t value of the given value.\n@@ -2253,7 +2256,7 @@ Returns the uint64_t value of the given value.\n * @param val A duckdb_value containing a ubigint\n * @return A uint64_t, or MinValue<uint64> if the value cannot be converted\n */\n-DUCKDB_API uint64_t duckdb_get_uint64(duckdb_value val);\n+DUCKDB_C_API uint64_t duckdb_get_uint64(duckdb_value val);\n \n /*!\n Returns the hugeint value of the given value.\n@@ -2261,7 +2264,7 @@ Returns the hugeint value of the given value.\n * @param val A duckdb_value containing a hugeint\n * @return A duckdb_hugeint, or MinValue<hugeint> if the value cannot be converted\n */\n-DUCKDB_API duckdb_hugeint duckdb_get_hugeint(duckdb_value val);\n+DUCKDB_C_API duckdb_hugeint duckdb_get_hugeint(duckdb_value val);\n \n /*!\n Returns the uhugeint value of the given value.\n@@ -2269,7 +2272,7 @@ Returns the uhugeint value of the given value.\n * @param val A duckdb_value containing a uhugeint\n * @return A duckdb_uhugeint, or MinValue<uhugeint> if the value cannot be converted\n */\n-DUCKDB_API duckdb_uhugeint duckdb_get_uhugeint(duckdb_value val);\n+DUCKDB_C_API duckdb_uhugeint duckdb_get_uhugeint(duckdb_value val);\n \n /*!\n Returns the duckdb_varint value of the given value.\n@@ -2278,7 +2281,7 @@ The `data` field must be destroyed with `duckdb_free`.\n * @param val A duckdb_value containing a VARINT\n * @return A duckdb_varint. The `data` field must be destroyed with `duckdb_free`.\n */\n-DUCKDB_API duckdb_varint duckdb_get_varint(duckdb_value val);\n+DUCKDB_C_API duckdb_varint duckdb_get_varint(duckdb_value val);\n \n /*!\n Returns the duckdb_decimal value of the given value.\n@@ -2286,7 +2289,7 @@ Returns the duckdb_decimal value of the given value.\n * @param val A duckdb_value containing a DECIMAL\n * @return A duckdb_decimal, or MinValue<decimal> if the value cannot be converted\n */\n-DUCKDB_API duckdb_decimal duckdb_get_decimal(duckdb_value val);\n+DUCKDB_C_API duckdb_decimal duckdb_get_decimal(duckdb_value val);\n \n /*!\n Returns the float value of the given value.\n@@ -2294,7 +2297,7 @@ Returns the float value of the given value.\n * @param val A duckdb_value containing a float\n * @return A float, or NAN if the value cannot be converted\n */\n-DUCKDB_API float duckdb_get_float(duckdb_value val);\n+DUCKDB_C_API float duckdb_get_float(duckdb_value val);\n \n /*!\n Returns the double value of the given value.\n@@ -2302,7 +2305,7 @@ Returns the double value of the given value.\n * @param val A duckdb_value containing a double\n * @return A double, or NAN if the value cannot be converted\n */\n-DUCKDB_API double duckdb_get_double(duckdb_value val);\n+DUCKDB_C_API double duckdb_get_double(duckdb_value val);\n \n /*!\n Returns the date value of the given value.\n@@ -2310,7 +2313,7 @@ Returns the date value of the given value.\n * @param val A duckdb_value containing a date\n * @return A duckdb_date, or MinValue<date> if the value cannot be converted\n */\n-DUCKDB_API duckdb_date duckdb_get_date(duckdb_value val);\n+DUCKDB_C_API duckdb_date duckdb_get_date(duckdb_value val);\n \n /*!\n Returns the time value of the given value.\n@@ -2318,7 +2321,7 @@ Returns the time value of the given value.\n * @param val A duckdb_value containing a time\n * @return A duckdb_time, or MinValue<time> if the value cannot be converted\n */\n-DUCKDB_API duckdb_time duckdb_get_time(duckdb_value val);\n+DUCKDB_C_API duckdb_time duckdb_get_time(duckdb_value val);\n \n /*!\n Returns the time_tz value of the given value.\n@@ -2326,7 +2329,7 @@ Returns the time_tz value of the given value.\n * @param val A duckdb_value containing a time_tz\n * @return A duckdb_time_tz, or MinValue<time_tz> if the value cannot be converted\n */\n-DUCKDB_API duckdb_time_tz duckdb_get_time_tz(duckdb_value val);\n+DUCKDB_C_API duckdb_time_tz duckdb_get_time_tz(duckdb_value val);\n \n /*!\n Returns the TIMESTAMP value of the given value.\n@@ -2334,7 +2337,7 @@ Returns the TIMESTAMP value of the given value.\n * @param val A duckdb_value containing a TIMESTAMP\n * @return A duckdb_timestamp, or MinValue<timestamp> if the value cannot be converted\n */\n-DUCKDB_API duckdb_timestamp duckdb_get_timestamp(duckdb_value val);\n+DUCKDB_C_API duckdb_timestamp duckdb_get_timestamp(duckdb_value val);\n \n /*!\n Returns the TIMESTAMP_TZ value of the given value.\n@@ -2342,7 +2345,7 @@ Returns the TIMESTAMP_TZ value of the given value.\n * @param val A duckdb_value containing a TIMESTAMP_TZ\n * @return A duckdb_timestamp, or MinValue<timestamp_tz> if the value cannot be converted\n */\n-DUCKDB_API duckdb_timestamp duckdb_get_timestamp_tz(duckdb_value val);\n+DUCKDB_C_API duckdb_timestamp duckdb_get_timestamp_tz(duckdb_value val);\n \n /*!\n Returns the duckdb_timestamp_s value of the given value.\n@@ -2350,7 +2353,7 @@ Returns the duckdb_timestamp_s value of the given value.\n * @param val A duckdb_value containing a TIMESTAMP_S\n * @return A duckdb_timestamp_s, or MinValue<timestamp_s> if the value cannot be converted\n */\n-DUCKDB_API duckdb_timestamp_s duckdb_get_timestamp_s(duckdb_value val);\n+DUCKDB_C_API duckdb_timestamp_s duckdb_get_timestamp_s(duckdb_value val);\n \n /*!\n Returns the duckdb_timestamp_ms value of the given value.\n@@ -2358,7 +2361,7 @@ Returns the duckdb_timestamp_ms value of the given value.\n * @param val A duckdb_value containing a TIMESTAMP_MS\n * @return A duckdb_timestamp_ms, or MinValue<timestamp_ms> if the value cannot be converted\n */\n-DUCKDB_API duckdb_timestamp_ms duckdb_get_timestamp_ms(duckdb_value val);\n+DUCKDB_C_API duckdb_timestamp_ms duckdb_get_timestamp_ms(duckdb_value val);\n \n /*!\n Returns the duckdb_timestamp_ns value of the given value.\n@@ -2366,7 +2369,7 @@ Returns the duckdb_timestamp_ns value of the given value.\n * @param val A duckdb_value containing a TIMESTAMP_NS\n * @return A duckdb_timestamp_ns, or MinValue<timestamp_ns> if the value cannot be converted\n */\n-DUCKDB_API duckdb_timestamp_ns duckdb_get_timestamp_ns(duckdb_value val);\n+DUCKDB_C_API duckdb_timestamp_ns duckdb_get_timestamp_ns(duckdb_value val);\n \n /*!\n Returns the interval value of the given value.\n@@ -2374,7 +2377,7 @@ Returns the interval value of the given value.\n * @param val A duckdb_value containing a interval\n * @return A duckdb_interval, or MinValue<interval> if the value cannot be converted\n */\n-DUCKDB_API duckdb_interval duckdb_get_interval(duckdb_value val);\n+DUCKDB_C_API duckdb_interval duckdb_get_interval(duckdb_value val);\n \n /*!\n Returns the type of the given value. The type is valid as long as the value is not destroyed.\n@@ -2383,7 +2386,7 @@ The type itself must not be destroyed.\n * @param val A duckdb_value\n * @return A duckdb_logical_type.\n */\n-DUCKDB_API duckdb_logical_type duckdb_get_value_type(duckdb_value val);\n+DUCKDB_C_API duckdb_logical_type duckdb_get_value_type(duckdb_value val);\n \n /*!\n Returns the blob value of the given value.\n@@ -2391,7 +2394,7 @@ Returns the blob value of the given value.\n * @param val A duckdb_value containing a blob\n * @return A duckdb_blob\n */\n-DUCKDB_API duckdb_blob duckdb_get_blob(duckdb_value val);\n+DUCKDB_C_API duckdb_blob duckdb_get_blob(duckdb_value val);\n \n /*!\n Returns the duckdb_bit value of the given value.\n@@ -2400,7 +2403,7 @@ The `data` field must be destroyed with `duckdb_free`.\n * @param val A duckdb_value containing a BIT\n * @return A duckdb_bit\n */\n-DUCKDB_API duckdb_bit duckdb_get_bit(duckdb_value val);\n+DUCKDB_C_API duckdb_bit duckdb_get_bit(duckdb_value val);\n \n /*!\n Returns a duckdb_uhugeint representing the UUID value of the given value.\n@@ -2408,7 +2411,7 @@ Returns a duckdb_uhugeint representing the UUID value of the given value.\n * @param val A duckdb_value containing a UUID\n * @return A duckdb_uhugeint representing the UUID value\n */\n-DUCKDB_API duckdb_uhugeint duckdb_get_uuid(duckdb_value val);\n+DUCKDB_C_API duckdb_uhugeint duckdb_get_uuid(duckdb_value val);\n \n /*!\n Obtains a string representation of the given value.\n@@ -2417,7 +2420,7 @@ The result must be destroyed with `duckdb_free`.\n * @param value The value\n * @return The string value. This must be destroyed with `duckdb_free`.\n */\n-DUCKDB_API char *duckdb_get_varchar(duckdb_value value);\n+DUCKDB_C_API char *duckdb_get_varchar(duckdb_value value);\n \n /*!\n Creates a struct value from a type and an array of values. Must be destroyed with `duckdb_destroy_value`.\n@@ -2426,7 +2429,7 @@ Creates a struct value from a type and an array of values. Must be destroyed wit\n * @param values The values for the struct fields\n * @return The struct value, or nullptr, if any child type is `DUCKDB_TYPE_ANY` or `DUCKDB_TYPE_INVALID`.\n */\n-DUCKDB_API duckdb_value duckdb_create_struct_value(duckdb_logical_type type, duckdb_value *values);\n+DUCKDB_C_API duckdb_value duckdb_create_struct_value(duckdb_logical_type type, duckdb_value *values);\n \n /*!\n Creates a list value from a child (element) type and an array of values of length `value_count`.\n@@ -2437,7 +2440,7 @@ Must be destroyed with `duckdb_destroy_value`.\n * @param value_count The number of values in the list\n * @return The list value, or nullptr, if the child type is `DUCKDB_TYPE_ANY` or `DUCKDB_TYPE_INVALID`.\n */\n-DUCKDB_API duckdb_value duckdb_create_list_value(duckdb_logical_type type, duckdb_value *values, idx_t value_count);\n+DUCKDB_C_API duckdb_value duckdb_create_list_value(duckdb_logical_type type, duckdb_value *values, idx_t value_count);\n \n /*!\n Creates an array value from a child (element) type and an array of values of length `value_count`.\n@@ -2448,7 +2451,7 @@ Must be destroyed with `duckdb_destroy_value`.\n * @param value_count The number of values in the array\n * @return The array value, or nullptr, if the child type is `DUCKDB_TYPE_ANY` or `DUCKDB_TYPE_INVALID`.\n */\n-DUCKDB_API duckdb_value duckdb_create_array_value(duckdb_logical_type type, duckdb_value *values, idx_t value_count);\n+DUCKDB_C_API duckdb_value duckdb_create_array_value(duckdb_logical_type type, duckdb_value *values, idx_t value_count);\n \n /*!\n Returns the number of elements in a MAP value.\n@@ -2456,7 +2459,7 @@ Returns the number of elements in a MAP value.\n * @param value The MAP value.\n * @return The number of elements in the map.\n */\n-DUCKDB_API idx_t duckdb_get_map_size(duckdb_value value);\n+DUCKDB_C_API idx_t duckdb_get_map_size(duckdb_value value);\n \n /*!\n Returns the MAP key at index as a duckdb_value.\n@@ -2465,7 +2468,7 @@ Returns the MAP key at index as a duckdb_value.\n * @param index The index of the key.\n * @return The key as a duckdb_value.\n */\n-DUCKDB_API duckdb_value duckdb_get_map_key(duckdb_value value, idx_t index);\n+DUCKDB_C_API duckdb_value duckdb_get_map_key(duckdb_value value, idx_t index);\n \n /*!\n Returns the MAP value at index as a duckdb_value.\n@@ -2474,7 +2477,7 @@ Returns the MAP value at index as a duckdb_value.\n * @param index The index of the value.\n * @return The value as a duckdb_value.\n */\n-DUCKDB_API duckdb_value duckdb_get_map_value(duckdb_value value, idx_t index);\n+DUCKDB_C_API duckdb_value duckdb_get_map_value(duckdb_value value, idx_t index);\n \n /*!\n Returns whether the value's type is SQLNULL or not.\n@@ -2482,14 +2485,14 @@ Returns whether the value's type is SQLNULL or not.\n * @param value The value to check.\n * @return True, if the value's type is SQLNULL, otherwise false.\n */\n-DUCKDB_API bool duckdb_is_null_value(duckdb_value value);\n+DUCKDB_C_API bool duckdb_is_null_value(duckdb_value value);\n \n /*!\n Creates a value of type SQLNULL.\n \n * @return The duckdb_value representing SQLNULL. This must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_create_null_value();\n+DUCKDB_C_API duckdb_value duckdb_create_null_value();\n \n /*!\n Returns the number of elements in a LIST value.\n@@ -2497,7 +2500,7 @@ Returns the number of elements in a LIST value.\n * @param value The LIST value.\n * @return The number of elements in the list.\n */\n-DUCKDB_API idx_t duckdb_get_list_size(duckdb_value value);\n+DUCKDB_C_API idx_t duckdb_get_list_size(duckdb_value value);\n \n /*!\n Returns the LIST child at index as a duckdb_value.\n@@ -2506,7 +2509,7 @@ Returns the LIST child at index as a duckdb_value.\n * @param index The index of the child.\n * @return The child as a duckdb_value.\n */\n-DUCKDB_API duckdb_value duckdb_get_list_child(duckdb_value value, idx_t index);\n+DUCKDB_C_API duckdb_value duckdb_get_list_child(duckdb_value value, idx_t index);\n \n /*!\n Creates an enum value from a type and a value. Must be destroyed with `duckdb_destroy_value`.\n@@ -2515,7 +2518,7 @@ Creates an enum value from a type and a value. Must be destroyed with `duckdb_de\n * @param value The value for the enum\n * @return The enum value, or nullptr.\n */\n-DUCKDB_API duckdb_value duckdb_create_enum_value(duckdb_logical_type type, uint64_t value);\n+DUCKDB_C_API duckdb_value duckdb_create_enum_value(duckdb_logical_type type, uint64_t value);\n \n /*!\n Returns the enum value of the given value.\n@@ -2523,7 +2526,7 @@ Returns the enum value of the given value.\n * @param value A duckdb_value containing an enum\n * @return A uint64_t, or MinValue<uint64> if the value cannot be converted\n */\n-DUCKDB_API uint64_t duckdb_get_enum_value(duckdb_value value);\n+DUCKDB_C_API uint64_t duckdb_get_enum_value(duckdb_value value);\n \n /*!\n Returns the STRUCT child at index as a duckdb_value.\n@@ -2532,7 +2535,7 @@ Returns the STRUCT child at index as a duckdb_value.\n * @param index The index of the child.\n * @return The child as a duckdb_value.\n */\n-DUCKDB_API duckdb_value duckdb_get_struct_child(duckdb_value value, idx_t index);\n+DUCKDB_C_API duckdb_value duckdb_get_struct_child(duckdb_value value, idx_t index);\n \n //===--------------------------------------------------------------------===//\n // Logical Type Interface\n@@ -2548,7 +2551,7 @@ Returns an invalid logical type, if type is: `DUCKDB_TYPE_INVALID`, `DUCKDB_TYPE\n * @param type The primitive type to create.\n * @return The logical type.\n */\n-DUCKDB_API duckdb_logical_type duckdb_create_logical_type(duckdb_type type);\n+DUCKDB_C_API duckdb_logical_type duckdb_create_logical_type(duckdb_type type);\n \n /*!\n Returns the alias of a duckdb_logical_type, if set, else `nullptr`.\n@@ -2557,7 +2560,7 @@ The result must be destroyed with `duckdb_free`.\n * @param type The logical type\n * @return The alias or `nullptr`\n */\n-DUCKDB_API char *duckdb_logical_type_get_alias(duckdb_logical_type type);\n+DUCKDB_C_API char *duckdb_logical_type_get_alias(duckdb_logical_type type);\n \n /*!\n Sets the alias of a duckdb_logical_type.\n@@ -2565,7 +2568,7 @@ Sets the alias of a duckdb_logical_type.\n * @param type The logical type\n * @param alias The alias to set\n */\n-DUCKDB_API void duckdb_logical_type_set_alias(duckdb_logical_type type, const char *alias);\n+DUCKDB_C_API void duckdb_logical_type_set_alias(duckdb_logical_type type, const char *alias);\n \n /*!\n Creates a LIST type from its child type.\n@@ -2574,7 +2577,7 @@ The return type must be destroyed with `duckdb_destroy_logical_type`.\n * @param type The child type of the list\n * @return The logical type.\n */\n-DUCKDB_API duckdb_logical_type duckdb_create_list_type(duckdb_logical_type type);\n+DUCKDB_C_API duckdb_logical_type duckdb_create_list_type(duckdb_logical_type type);\n \n /*!\n Creates an ARRAY type from its child type.\n@@ -2584,7 +2587,7 @@ The return type must be destroyed with `duckdb_destroy_logical_type`.\n * @param array_size The number of elements in the array.\n * @return The logical type.\n */\n-DUCKDB_API duckdb_logical_type duckdb_create_array_type(duckdb_logical_type type, idx_t array_size);\n+DUCKDB_C_API duckdb_logical_type duckdb_create_array_type(duckdb_logical_type type, idx_t array_size);\n \n /*!\n Creates a MAP type from its key type and value type.\n@@ -2594,7 +2597,7 @@ The return type must be destroyed with `duckdb_destroy_logical_type`.\n * @param value_type The map's value type.\n * @return The logical type.\n */\n-DUCKDB_API duckdb_logical_type duckdb_create_map_type(duckdb_logical_type key_type, duckdb_logical_type value_type);\n+DUCKDB_C_API duckdb_logical_type duckdb_create_map_type(duckdb_logical_type key_type, duckdb_logical_type value_type);\n \n /*!\n Creates a UNION type from the passed arrays.\n@@ -2605,8 +2608,8 @@ The return type must be destroyed with `duckdb_destroy_logical_type`.\n * @param member_count The number of union members.\n * @return The logical type.\n */\n-DUCKDB_API duckdb_logical_type duckdb_create_union_type(duckdb_logical_type *member_types, const char **member_names,\n-                                                        idx_t member_count);\n+DUCKDB_C_API duckdb_logical_type duckdb_create_union_type(duckdb_logical_type *member_types, const char **member_names,\n+                                                          idx_t member_count);\n \n /*!\n Creates a STRUCT type based on the member types and names.\n@@ -2617,8 +2620,8 @@ The resulting type must be destroyed with `duckdb_destroy_logical_type`.\n * @param member_count The number of members of the struct.\n * @return The logical type.\n */\n-DUCKDB_API duckdb_logical_type duckdb_create_struct_type(duckdb_logical_type *member_types, const char **member_names,\n-                                                         idx_t member_count);\n+DUCKDB_C_API duckdb_logical_type duckdb_create_struct_type(duckdb_logical_type *member_types, const char **member_names,\n+                                                           idx_t member_count);\n \n /*!\n Creates an ENUM type from the passed member name array.\n@@ -2628,7 +2631,7 @@ The resulting type should be destroyed with `duckdb_destroy_logical_type`.\n * @param member_count The number of elements that were specified in the array.\n * @return The logical type.\n */\n-DUCKDB_API duckdb_logical_type duckdb_create_enum_type(const char **member_names, idx_t member_count);\n+DUCKDB_C_API duckdb_logical_type duckdb_create_enum_type(const char **member_names, idx_t member_count);\n \n /*!\n Creates a DECIMAL type with the specified width and scale.\n@@ -2638,7 +2641,7 @@ The resulting type should be destroyed with `duckdb_destroy_logical_type`.\n * @param scale The scale of the decimal type\n * @return The logical type.\n */\n-DUCKDB_API duckdb_logical_type duckdb_create_decimal_type(uint8_t width, uint8_t scale);\n+DUCKDB_C_API duckdb_logical_type duckdb_create_decimal_type(uint8_t width, uint8_t scale);\n \n /*!\n Retrieves the enum `duckdb_type` of a `duckdb_logical_type`.\n@@ -2646,7 +2649,7 @@ Retrieves the enum `duckdb_type` of a `duckdb_logical_type`.\n * @param type The logical type.\n * @return The `duckdb_type` id.\n */\n-DUCKDB_API duckdb_type duckdb_get_type_id(duckdb_logical_type type);\n+DUCKDB_C_API duckdb_type duckdb_get_type_id(duckdb_logical_type type);\n \n /*!\n Retrieves the width of a decimal type.\n@@ -2654,7 +2657,7 @@ Retrieves the width of a decimal type.\n * @param type The logical type object\n * @return The width of the decimal type\n */\n-DUCKDB_API uint8_t duckdb_decimal_width(duckdb_logical_type type);\n+DUCKDB_C_API uint8_t duckdb_decimal_width(duckdb_logical_type type);\n \n /*!\n Retrieves the scale of a decimal type.\n@@ -2662,7 +2665,7 @@ Retrieves the scale of a decimal type.\n * @param type The logical type object\n * @return The scale of the decimal type\n */\n-DUCKDB_API uint8_t duckdb_decimal_scale(duckdb_logical_type type);\n+DUCKDB_C_API uint8_t duckdb_decimal_scale(duckdb_logical_type type);\n \n /*!\n Retrieves the internal storage type of a decimal type.\n@@ -2670,7 +2673,7 @@ Retrieves the internal storage type of a decimal type.\n * @param type The logical type object\n * @return The internal type of the decimal type\n */\n-DUCKDB_API duckdb_type duckdb_decimal_internal_type(duckdb_logical_type type);\n+DUCKDB_C_API duckdb_type duckdb_decimal_internal_type(duckdb_logical_type type);\n \n /*!\n Retrieves the internal storage type of an enum type.\n@@ -2678,7 +2681,7 @@ Retrieves the internal storage type of an enum type.\n * @param type The logical type object\n * @return The internal type of the enum type\n */\n-DUCKDB_API duckdb_type duckdb_enum_internal_type(duckdb_logical_type type);\n+DUCKDB_C_API duckdb_type duckdb_enum_internal_type(duckdb_logical_type type);\n \n /*!\n Retrieves the dictionary size of the enum type.\n@@ -2686,7 +2689,7 @@ Retrieves the dictionary size of the enum type.\n * @param type The logical type object\n * @return The dictionary size of the enum type\n */\n-DUCKDB_API uint32_t duckdb_enum_dictionary_size(duckdb_logical_type type);\n+DUCKDB_C_API uint32_t duckdb_enum_dictionary_size(duckdb_logical_type type);\n \n /*!\n Retrieves the dictionary value at the specified position from the enum.\n@@ -2697,7 +2700,7 @@ The result must be freed with `duckdb_free`.\n * @param index The index in the dictionary\n * @return The string value of the enum type. Must be freed with `duckdb_free`.\n */\n-DUCKDB_API char *duckdb_enum_dictionary_value(duckdb_logical_type type, idx_t index);\n+DUCKDB_C_API char *duckdb_enum_dictionary_value(duckdb_logical_type type, idx_t index);\n \n /*!\n Retrieves the child type of the given LIST type. Also accepts MAP types.\n@@ -2706,7 +2709,7 @@ The result must be freed with `duckdb_destroy_logical_type`.\n * @param type The logical type, either LIST or MAP.\n * @return The child type of the LIST or MAP type.\n */\n-DUCKDB_API duckdb_logical_type duckdb_list_type_child_type(duckdb_logical_type type);\n+DUCKDB_C_API duckdb_logical_type duckdb_list_type_child_type(duckdb_logical_type type);\n \n /*!\n Retrieves the child type of the given ARRAY type.\n@@ -2716,7 +2719,7 @@ The result must be freed with `duckdb_destroy_logical_type`.\n * @param type The logical type. Must be ARRAY.\n * @return The child type of the ARRAY type.\n */\n-DUCKDB_API duckdb_logical_type duckdb_array_type_child_type(duckdb_logical_type type);\n+DUCKDB_C_API duckdb_logical_type duckdb_array_type_child_type(duckdb_logical_type type);\n \n /*!\n Retrieves the array size of the given array type.\n@@ -2724,7 +2727,7 @@ Retrieves the array size of the given array type.\n * @param type The logical type object\n * @return The fixed number of elements the values of this array type can store.\n */\n-DUCKDB_API idx_t duckdb_array_type_array_size(duckdb_logical_type type);\n+DUCKDB_C_API idx_t duckdb_array_type_array_size(duckdb_logical_type type);\n \n /*!\n Retrieves the key type of the given map type.\n@@ -2734,7 +2737,7 @@ The result must be freed with `duckdb_destroy_logical_type`.\n * @param type The logical type object\n * @return The key type of the map type. Must be destroyed with `duckdb_destroy_logical_type`.\n */\n-DUCKDB_API duckdb_logical_type duckdb_map_type_key_type(duckdb_logical_type type);\n+DUCKDB_C_API duckdb_logical_type duckdb_map_type_key_type(duckdb_logical_type type);\n \n /*!\n Retrieves the value type of the given map type.\n@@ -2744,7 +2747,7 @@ The result must be freed with `duckdb_destroy_logical_type`.\n * @param type The logical type object\n * @return The value type of the map type. Must be destroyed with `duckdb_destroy_logical_type`.\n */\n-DUCKDB_API duckdb_logical_type duckdb_map_type_value_type(duckdb_logical_type type);\n+DUCKDB_C_API duckdb_logical_type duckdb_map_type_value_type(duckdb_logical_type type);\n \n /*!\n Returns the number of children of a struct type.\n@@ -2752,7 +2755,7 @@ Returns the number of children of a struct type.\n * @param type The logical type object\n * @return The number of children of a struct type.\n */\n-DUCKDB_API idx_t duckdb_struct_type_child_count(duckdb_logical_type type);\n+DUCKDB_C_API idx_t duckdb_struct_type_child_count(duckdb_logical_type type);\n \n /*!\n Retrieves the name of the struct child.\n@@ -2763,7 +2766,7 @@ The result must be freed with `duckdb_free`.\n * @param index The child index\n * @return The name of the struct type. Must be freed with `duckdb_free`.\n */\n-DUCKDB_API char *duckdb_struct_type_child_name(duckdb_logical_type type, idx_t index);\n+DUCKDB_C_API char *duckdb_struct_type_child_name(duckdb_logical_type type, idx_t index);\n \n /*!\n Retrieves the child type of the given struct type at the specified index.\n@@ -2774,7 +2777,7 @@ The result must be freed with `duckdb_destroy_logical_type`.\n * @param index The child index\n * @return The child type of the struct type. Must be destroyed with `duckdb_destroy_logical_type`.\n */\n-DUCKDB_API duckdb_logical_type duckdb_struct_type_child_type(duckdb_logical_type type, idx_t index);\n+DUCKDB_C_API duckdb_logical_type duckdb_struct_type_child_type(duckdb_logical_type type, idx_t index);\n \n /*!\n Returns the number of members that the union type has.\n@@ -2782,7 +2785,7 @@ Returns the number of members that the union type has.\n * @param type The logical type (union) object\n * @return The number of members of a union type.\n */\n-DUCKDB_API idx_t duckdb_union_type_member_count(duckdb_logical_type type);\n+DUCKDB_C_API idx_t duckdb_union_type_member_count(duckdb_logical_type type);\n \n /*!\n Retrieves the name of the union member.\n@@ -2793,7 +2796,7 @@ The result must be freed with `duckdb_free`.\n * @param index The child index\n * @return The name of the union member. Must be freed with `duckdb_free`.\n */\n-DUCKDB_API char *duckdb_union_type_member_name(duckdb_logical_type type, idx_t index);\n+DUCKDB_C_API char *duckdb_union_type_member_name(duckdb_logical_type type, idx_t index);\n \n /*!\n Retrieves the child type of the given union member at the specified index.\n@@ -2804,14 +2807,14 @@ The result must be freed with `duckdb_destroy_logical_type`.\n * @param index The child index\n * @return The child type of the union member. Must be destroyed with `duckdb_destroy_logical_type`.\n */\n-DUCKDB_API duckdb_logical_type duckdb_union_type_member_type(duckdb_logical_type type, idx_t index);\n+DUCKDB_C_API duckdb_logical_type duckdb_union_type_member_type(duckdb_logical_type type, idx_t index);\n \n /*!\n Destroys the logical type and de-allocates all memory allocated for that type.\n \n * @param type The logical type to destroy.\n */\n-DUCKDB_API void duckdb_destroy_logical_type(duckdb_logical_type *type);\n+DUCKDB_C_API void duckdb_destroy_logical_type(duckdb_logical_type *type);\n \n /*!\n Registers a custom type within the given connection.\n@@ -2821,8 +2824,8 @@ The type must have an alias\n * @param type The custom type to register\n * @return Whether or not the registration was successful.\n */\n-DUCKDB_API duckdb_state duckdb_register_logical_type(duckdb_connection con, duckdb_logical_type type,\n-                                                     duckdb_create_type_info info);\n+DUCKDB_C_API duckdb_state duckdb_register_logical_type(duckdb_connection con, duckdb_logical_type type,\n+                                                       duckdb_create_type_info info);\n \n //===--------------------------------------------------------------------===//\n // Data Chunk Interface\n@@ -2836,14 +2839,14 @@ The result must be destroyed with `duckdb_destroy_data_chunk`.\n * @param column_count The number of columns.\n * @return The data chunk.\n */\n-DUCKDB_API duckdb_data_chunk duckdb_create_data_chunk(duckdb_logical_type *types, idx_t column_count);\n+DUCKDB_C_API duckdb_data_chunk duckdb_create_data_chunk(duckdb_logical_type *types, idx_t column_count);\n \n /*!\n Destroys the data chunk and de-allocates all memory allocated for that chunk.\n \n * @param chunk The data chunk to destroy.\n */\n-DUCKDB_API void duckdb_destroy_data_chunk(duckdb_data_chunk *chunk);\n+DUCKDB_C_API void duckdb_destroy_data_chunk(duckdb_data_chunk *chunk);\n \n /*!\n Resets a data chunk, clearing the validity masks and setting the cardinality of the data chunk to 0.\n@@ -2852,7 +2855,7 @@ data and validity pointers\n \n * @param chunk The data chunk to reset.\n */\n-DUCKDB_API void duckdb_data_chunk_reset(duckdb_data_chunk chunk);\n+DUCKDB_C_API void duckdb_data_chunk_reset(duckdb_data_chunk chunk);\n \n /*!\n Retrieves the number of columns in a data chunk.\n@@ -2860,7 +2863,7 @@ Retrieves the number of columns in a data chunk.\n * @param chunk The data chunk to get the data from\n * @return The number of columns in the data chunk\n */\n-DUCKDB_API idx_t duckdb_data_chunk_get_column_count(duckdb_data_chunk chunk);\n+DUCKDB_C_API idx_t duckdb_data_chunk_get_column_count(duckdb_data_chunk chunk);\n \n /*!\n Retrieves the vector at the specified column index in the data chunk.\n@@ -2871,7 +2874,7 @@ It does NOT need to be destroyed.\n * @param chunk The data chunk to get the data from\n * @return The vector\n */\n-DUCKDB_API duckdb_vector duckdb_data_chunk_get_vector(duckdb_data_chunk chunk, idx_t col_idx);\n+DUCKDB_C_API duckdb_vector duckdb_data_chunk_get_vector(duckdb_data_chunk chunk, idx_t col_idx);\n \n /*!\n Retrieves the current number of tuples in a data chunk.\n@@ -2879,7 +2882,7 @@ Retrieves the current number of tuples in a data chunk.\n * @param chunk The data chunk to get the data from\n * @return The number of tuples in the data chunk\n */\n-DUCKDB_API idx_t duckdb_data_chunk_get_size(duckdb_data_chunk chunk);\n+DUCKDB_C_API idx_t duckdb_data_chunk_get_size(duckdb_data_chunk chunk);\n \n /*!\n Sets the current number of tuples in a data chunk.\n@@ -2887,7 +2890,7 @@ Sets the current number of tuples in a data chunk.\n * @param chunk The data chunk to set the size in\n * @param size The number of tuples in the data chunk\n */\n-DUCKDB_API void duckdb_data_chunk_set_size(duckdb_data_chunk chunk, idx_t size);\n+DUCKDB_C_API void duckdb_data_chunk_set_size(duckdb_data_chunk chunk, idx_t size);\n \n //===--------------------------------------------------------------------===//\n // Vector Interface\n@@ -2901,7 +2904,7 @@ The result must be destroyed with `duckdb_destroy_logical_type`.\n * @param vector The vector get the data from\n * @return The type of the vector\n */\n-DUCKDB_API duckdb_logical_type duckdb_vector_get_column_type(duckdb_vector vector);\n+DUCKDB_C_API duckdb_logical_type duckdb_vector_get_column_type(duckdb_vector vector);\n \n /*!\n Retrieves the data pointer of the vector.\n@@ -2912,7 +2915,7 @@ How to read or write values depends on the type of the vector.\n * @param vector The vector to get the data from\n * @return The data pointer\n */\n-DUCKDB_API void *duckdb_vector_get_data(duckdb_vector vector);\n+DUCKDB_C_API void *duckdb_vector_get_data(duckdb_vector vector);\n \n /*!\n Retrieves the validity mask pointer of the specified vector.\n@@ -2934,7 +2937,7 @@ Alternatively, the (slower) duckdb_validity_row_is_valid function can be used.\n * @param vector The vector to get the data from\n * @return The pointer to the validity mask, or NULL if no validity mask is present\n */\n-DUCKDB_API uint64_t *duckdb_vector_get_validity(duckdb_vector vector);\n+DUCKDB_C_API uint64_t *duckdb_vector_get_validity(duckdb_vector vector);\n \n /*!\n Ensures the validity mask is writable by allocating it.\n@@ -2944,7 +2947,7 @@ This allows NULL values to be written to the vector, regardless of whether a val\n \n * @param vector The vector to alter\n */\n-DUCKDB_API void duckdb_vector_ensure_validity_writable(duckdb_vector vector);\n+DUCKDB_C_API void duckdb_vector_ensure_validity_writable(duckdb_vector vector);\n \n /*!\n Assigns a string element in the vector at the specified location.\n@@ -2953,7 +2956,7 @@ Assigns a string element in the vector at the specified location.\n * @param index The row position in the vector to assign the string to\n * @param str The null-terminated string\n */\n-DUCKDB_API void duckdb_vector_assign_string_element(duckdb_vector vector, idx_t index, const char *str);\n+DUCKDB_C_API void duckdb_vector_assign_string_element(duckdb_vector vector, idx_t index, const char *str);\n \n /*!\n Assigns a string element in the vector at the specified location. You may also use this function to assign BLOBs.\n@@ -2963,8 +2966,8 @@ Assigns a string element in the vector at the specified location. You may also u\n * @param str The string\n * @param str_len The length of the string (in bytes)\n */\n-DUCKDB_API void duckdb_vector_assign_string_element_len(duckdb_vector vector, idx_t index, const char *str,\n-                                                        idx_t str_len);\n+DUCKDB_C_API void duckdb_vector_assign_string_element_len(duckdb_vector vector, idx_t index, const char *str,\n+                                                          idx_t str_len);\n \n /*!\n Retrieves the child vector of a list vector.\n@@ -2974,7 +2977,7 @@ The resulting vector is valid as long as the parent vector is valid.\n * @param vector The vector\n * @return The child vector\n */\n-DUCKDB_API duckdb_vector duckdb_list_vector_get_child(duckdb_vector vector);\n+DUCKDB_C_API duckdb_vector duckdb_list_vector_get_child(duckdb_vector vector);\n \n /*!\n Returns the size of the child vector of the list.\n@@ -2982,7 +2985,7 @@ Returns the size of the child vector of the list.\n * @param vector The vector\n * @return The size of the child list\n */\n-DUCKDB_API idx_t duckdb_list_vector_get_size(duckdb_vector vector);\n+DUCKDB_C_API idx_t duckdb_list_vector_get_size(duckdb_vector vector);\n \n /*!\n Sets the total size of the underlying child-vector of a list vector.\n@@ -2991,7 +2994,7 @@ Sets the total size of the underlying child-vector of a list vector.\n * @param size The size of the child list.\n * @return The duckdb state. Returns DuckDBError if the vector is nullptr.\n */\n-DUCKDB_API duckdb_state duckdb_list_vector_set_size(duckdb_vector vector, idx_t size);\n+DUCKDB_C_API duckdb_state duckdb_list_vector_set_size(duckdb_vector vector, idx_t size);\n \n /*!\n Sets the total capacity of the underlying child-vector of a list.\n@@ -3003,7 +3006,7 @@ data and validity pointers\n * @param required_capacity the total capacity to reserve.\n * @return The duckdb state. Returns DuckDBError if the vector is nullptr.\n */\n-DUCKDB_API duckdb_state duckdb_list_vector_reserve(duckdb_vector vector, idx_t required_capacity);\n+DUCKDB_C_API duckdb_state duckdb_list_vector_reserve(duckdb_vector vector, idx_t required_capacity);\n \n /*!\n Retrieves the child vector of a struct vector.\n@@ -3014,7 +3017,7 @@ The resulting vector is valid as long as the parent vector is valid.\n * @param index The child index\n * @return The child vector\n */\n-DUCKDB_API duckdb_vector duckdb_struct_vector_get_child(duckdb_vector vector, idx_t index);\n+DUCKDB_C_API duckdb_vector duckdb_struct_vector_get_child(duckdb_vector vector, idx_t index);\n \n /*!\n Retrieves the child vector of a array vector.\n@@ -3025,7 +3028,7 @@ The resulting vector has the size of the parent vector multiplied by the array s\n * @param vector The vector\n * @return The child vector\n */\n-DUCKDB_API duckdb_vector duckdb_array_vector_get_child(duckdb_vector vector);\n+DUCKDB_C_API duckdb_vector duckdb_array_vector_get_child(duckdb_vector vector);\n \n //===--------------------------------------------------------------------===//\n // Validity Mask Functions\n@@ -3038,7 +3041,7 @@ Returns whether or not a row is valid (i.e. not NULL) in the given validity mask\n * @param row The row index\n * @return true if the row is valid, false otherwise\n */\n-DUCKDB_API bool duckdb_validity_row_is_valid(uint64_t *validity, idx_t row);\n+DUCKDB_C_API bool duckdb_validity_row_is_valid(uint64_t *validity, idx_t row);\n \n /*!\n In a validity mask, sets a specific row to either valid or invalid.\n@@ -3050,7 +3053,7 @@ to ensure that there is a validity mask to write to.\n * @param row The row index\n * @param valid Whether or not to set the row to valid, or invalid\n */\n-DUCKDB_API void duckdb_validity_set_row_validity(uint64_t *validity, idx_t row, bool valid);\n+DUCKDB_C_API void duckdb_validity_set_row_validity(uint64_t *validity, idx_t row, bool valid);\n \n /*!\n In a validity mask, sets a specific row to invalid.\n@@ -3060,7 +3063,7 @@ Equivalent to `duckdb_validity_set_row_validity` with valid set to false.\n * @param validity The validity mask\n * @param row The row index\n */\n-DUCKDB_API void duckdb_validity_set_row_invalid(uint64_t *validity, idx_t row);\n+DUCKDB_C_API void duckdb_validity_set_row_invalid(uint64_t *validity, idx_t row);\n \n /*!\n In a validity mask, sets a specific row to valid.\n@@ -3070,7 +3073,7 @@ Equivalent to `duckdb_validity_set_row_validity` with valid set to true.\n * @param validity The validity mask\n * @param row The row index\n */\n-DUCKDB_API void duckdb_validity_set_row_valid(uint64_t *validity, idx_t row);\n+DUCKDB_C_API void duckdb_validity_set_row_valid(uint64_t *validity, idx_t row);\n \n //===--------------------------------------------------------------------===//\n // Scalar Functions\n@@ -3083,14 +3086,14 @@ The return value should be destroyed with `duckdb_destroy_scalar_function`.\n \n * @return The scalar function object.\n */\n-DUCKDB_API duckdb_scalar_function duckdb_create_scalar_function();\n+DUCKDB_C_API duckdb_scalar_function duckdb_create_scalar_function();\n \n /*!\n Destroys the given scalar function object.\n \n * @param scalar_function The scalar function to destroy\n */\n-DUCKDB_API void duckdb_destroy_scalar_function(duckdb_scalar_function *scalar_function);\n+DUCKDB_C_API void duckdb_destroy_scalar_function(duckdb_scalar_function *scalar_function);\n \n /*!\n Sets the name of the given scalar function.\n@@ -3098,7 +3101,7 @@ Sets the name of the given scalar function.\n * @param scalar_function The scalar function\n * @param name The name of the scalar function\n */\n-DUCKDB_API void duckdb_scalar_function_set_name(duckdb_scalar_function scalar_function, const char *name);\n+DUCKDB_C_API void duckdb_scalar_function_set_name(duckdb_scalar_function scalar_function, const char *name);\n \n /*!\n Sets the parameters of the given scalar function to varargs. Does not require adding parameters with\n@@ -3108,7 +3111,7 @@ duckdb_scalar_function_add_parameter.\n * @param type The type of the arguments.\n * @return The parameter type. Cannot contain INVALID.\n */\n-DUCKDB_API void duckdb_scalar_function_set_varargs(duckdb_scalar_function scalar_function, duckdb_logical_type type);\n+DUCKDB_C_API void duckdb_scalar_function_set_varargs(duckdb_scalar_function scalar_function, duckdb_logical_type type);\n \n /*!\n Sets the parameters of the given scalar function to varargs. Does not require adding parameters with\n@@ -3116,7 +3119,7 @@ duckdb_scalar_function_add_parameter.\n \n * @param scalar_function The scalar function.\n */\n-DUCKDB_API void duckdb_scalar_function_set_special_handling(duckdb_scalar_function scalar_function);\n+DUCKDB_C_API void duckdb_scalar_function_set_special_handling(duckdb_scalar_function scalar_function);\n \n /*!\n Sets the Function Stability of the scalar function to VOLATILE, indicating the function should be re-run for every row.\n@@ -3124,7 +3127,7 @@ This limits optimization that can be performed for the function.\n \n * @param scalar_function The scalar function.\n */\n-DUCKDB_API void duckdb_scalar_function_set_volatile(duckdb_scalar_function scalar_function);\n+DUCKDB_C_API void duckdb_scalar_function_set_volatile(duckdb_scalar_function scalar_function);\n \n /*!\n Adds a parameter to the scalar function.\n@@ -3132,7 +3135,8 @@ Adds a parameter to the scalar function.\n * @param scalar_function The scalar function.\n * @param type The parameter type. Cannot contain INVALID.\n */\n-DUCKDB_API void duckdb_scalar_function_add_parameter(duckdb_scalar_function scalar_function, duckdb_logical_type type);\n+DUCKDB_C_API void duckdb_scalar_function_add_parameter(duckdb_scalar_function scalar_function,\n+                                                       duckdb_logical_type type);\n \n /*!\n Sets the return type of the scalar function.\n@@ -3140,8 +3144,8 @@ Sets the return type of the scalar function.\n * @param scalar_function The scalar function\n * @param type Cannot contain INVALID or ANY.\n */\n-DUCKDB_API void duckdb_scalar_function_set_return_type(duckdb_scalar_function scalar_function,\n-                                                       duckdb_logical_type type);\n+DUCKDB_C_API void duckdb_scalar_function_set_return_type(duckdb_scalar_function scalar_function,\n+                                                         duckdb_logical_type type);\n \n /*!\n Assigns extra information to the scalar function that can be fetched during binding, etc.\n@@ -3150,8 +3154,8 @@ Assigns extra information to the scalar function that can be fetched during bind\n * @param extra_info The extra information\n * @param destroy The callback that will be called to destroy the bind data (if any)\n */\n-DUCKDB_API void duckdb_scalar_function_set_extra_info(duckdb_scalar_function scalar_function, void *extra_info,\n-                                                      duckdb_delete_callback_t destroy);\n+DUCKDB_C_API void duckdb_scalar_function_set_extra_info(duckdb_scalar_function scalar_function, void *extra_info,\n+                                                        duckdb_delete_callback_t destroy);\n \n /*!\n Sets the main function of the scalar function.\n@@ -3159,8 +3163,8 @@ Sets the main function of the scalar function.\n * @param scalar_function The scalar function\n * @param function The function\n */\n-DUCKDB_API void duckdb_scalar_function_set_function(duckdb_scalar_function scalar_function,\n-                                                    duckdb_scalar_function_t function);\n+DUCKDB_C_API void duckdb_scalar_function_set_function(duckdb_scalar_function scalar_function,\n+                                                      duckdb_scalar_function_t function);\n \n /*!\n Register the scalar function object within the given connection.\n@@ -3173,7 +3177,8 @@ If the function is incomplete or a function with this name already exists DuckDB\n * @param scalar_function The function pointer\n * @return Whether or not the registration was successful.\n */\n-DUCKDB_API duckdb_state duckdb_register_scalar_function(duckdb_connection con, duckdb_scalar_function scalar_function);\n+DUCKDB_C_API duckdb_state duckdb_register_scalar_function(duckdb_connection con,\n+                                                          duckdb_scalar_function scalar_function);\n \n /*!\n Retrieves the extra info of the function as set in `duckdb_scalar_function_set_extra_info`.\n@@ -3181,7 +3186,7 @@ Retrieves the extra info of the function as set in `duckdb_scalar_function_set_e\n * @param info The info object.\n * @return The extra info.\n */\n-DUCKDB_API void *duckdb_scalar_function_get_extra_info(duckdb_function_info info);\n+DUCKDB_C_API void *duckdb_scalar_function_get_extra_info(duckdb_function_info info);\n \n /*!\n Report that an error has occurred while executing the scalar function.\n@@ -3189,7 +3194,7 @@ Report that an error has occurred while executing the scalar function.\n * @param info The info object.\n * @param error The error message\n */\n-DUCKDB_API void duckdb_scalar_function_set_error(duckdb_function_info info, const char *error);\n+DUCKDB_C_API void duckdb_scalar_function_set_error(duckdb_function_info info, const char *error);\n \n /*!\n Creates a new empty scalar function set.\n@@ -3198,13 +3203,13 @@ The return value should be destroyed with `duckdb_destroy_scalar_function_set`.\n \n * @return The scalar function set object.\n */\n-DUCKDB_API duckdb_scalar_function_set duckdb_create_scalar_function_set(const char *name);\n+DUCKDB_C_API duckdb_scalar_function_set duckdb_create_scalar_function_set(const char *name);\n \n /*!\n Destroys the given scalar function set object.\n \n */\n-DUCKDB_API void duckdb_destroy_scalar_function_set(duckdb_scalar_function_set *scalar_function_set);\n+DUCKDB_C_API void duckdb_destroy_scalar_function_set(duckdb_scalar_function_set *scalar_function_set);\n \n /*!\n Adds the scalar function as a new overload to the scalar function set.\n@@ -3214,8 +3219,8 @@ Returns DuckDBError if the function could not be added, for example if the overl\n * @param set The scalar function set\n * @param function The function to add\n */\n-DUCKDB_API duckdb_state duckdb_add_scalar_function_to_set(duckdb_scalar_function_set set,\n-                                                          duckdb_scalar_function function);\n+DUCKDB_C_API duckdb_state duckdb_add_scalar_function_to_set(duckdb_scalar_function_set set,\n+                                                            duckdb_scalar_function function);\n \n /*!\n Register the scalar function set within the given connection.\n@@ -3228,7 +3233,7 @@ If the set is incomplete or a function with this name already exists DuckDBError\n * @param set The function set to register\n * @return Whether or not the registration was successful.\n */\n-DUCKDB_API duckdb_state duckdb_register_scalar_function_set(duckdb_connection con, duckdb_scalar_function_set set);\n+DUCKDB_C_API duckdb_state duckdb_register_scalar_function_set(duckdb_connection con, duckdb_scalar_function_set set);\n \n //===--------------------------------------------------------------------===//\n // Aggregate Functions\n@@ -3241,13 +3246,13 @@ The return value should be destroyed with `duckdb_destroy_aggregate_function`.\n \n * @return The aggregate function object.\n */\n-DUCKDB_API duckdb_aggregate_function duckdb_create_aggregate_function();\n+DUCKDB_C_API duckdb_aggregate_function duckdb_create_aggregate_function();\n \n /*!\n Destroys the given aggregate function object.\n \n */\n-DUCKDB_API void duckdb_destroy_aggregate_function(duckdb_aggregate_function *aggregate_function);\n+DUCKDB_C_API void duckdb_destroy_aggregate_function(duckdb_aggregate_function *aggregate_function);\n \n /*!\n Sets the name of the given aggregate function.\n@@ -3255,7 +3260,7 @@ Sets the name of the given aggregate function.\n * @param aggregate_function The aggregate function\n * @param name The name of the aggregate function\n */\n-DUCKDB_API void duckdb_aggregate_function_set_name(duckdb_aggregate_function aggregate_function, const char *name);\n+DUCKDB_C_API void duckdb_aggregate_function_set_name(duckdb_aggregate_function aggregate_function, const char *name);\n \n /*!\n Adds a parameter to the aggregate function.\n@@ -3263,8 +3268,8 @@ Adds a parameter to the aggregate function.\n * @param aggregate_function The aggregate function.\n * @param type The parameter type. Cannot contain INVALID.\n */\n-DUCKDB_API void duckdb_aggregate_function_add_parameter(duckdb_aggregate_function aggregate_function,\n-                                                        duckdb_logical_type type);\n+DUCKDB_C_API void duckdb_aggregate_function_add_parameter(duckdb_aggregate_function aggregate_function,\n+                                                          duckdb_logical_type type);\n \n /*!\n Sets the return type of the aggregate function.\n@@ -3272,8 +3277,8 @@ Sets the return type of the aggregate function.\n * @param aggregate_function The aggregate function.\n * @param type The return type. Cannot contain INVALID or ANY.\n */\n-DUCKDB_API void duckdb_aggregate_function_set_return_type(duckdb_aggregate_function aggregate_function,\n-                                                          duckdb_logical_type type);\n+DUCKDB_C_API void duckdb_aggregate_function_set_return_type(duckdb_aggregate_function aggregate_function,\n+                                                            duckdb_logical_type type);\n \n /*!\n Sets the main functions of the aggregate function.\n@@ -3285,12 +3290,12 @@ Sets the main functions of the aggregate function.\n * @param combine combine states\n * @param finalize finalize states\n */\n-DUCKDB_API void duckdb_aggregate_function_set_functions(duckdb_aggregate_function aggregate_function,\n-                                                        duckdb_aggregate_state_size state_size,\n-                                                        duckdb_aggregate_init_t state_init,\n-                                                        duckdb_aggregate_update_t update,\n-                                                        duckdb_aggregate_combine_t combine,\n-                                                        duckdb_aggregate_finalize_t finalize);\n+DUCKDB_C_API void duckdb_aggregate_function_set_functions(duckdb_aggregate_function aggregate_function,\n+                                                          duckdb_aggregate_state_size state_size,\n+                                                          duckdb_aggregate_init_t state_init,\n+                                                          duckdb_aggregate_update_t update,\n+                                                          duckdb_aggregate_combine_t combine,\n+                                                          duckdb_aggregate_finalize_t finalize);\n \n /*!\n Sets the state destructor callback of the aggregate function (optional)\n@@ -3298,8 +3303,8 @@ Sets the state destructor callback of the aggregate function (optional)\n * @param aggregate_function The aggregate function\n * @param destroy state destroy callback\n */\n-DUCKDB_API void duckdb_aggregate_function_set_destructor(duckdb_aggregate_function aggregate_function,\n-                                                         duckdb_aggregate_destroy_t destroy);\n+DUCKDB_C_API void duckdb_aggregate_function_set_destructor(duckdb_aggregate_function aggregate_function,\n+                                                           duckdb_aggregate_destroy_t destroy);\n \n /*!\n Register the aggregate function object within the given connection.\n@@ -3311,15 +3316,15 @@ If the function is incomplete or a function with this name already exists DuckDB\n * @param con The connection to register it in.\n * @return Whether or not the registration was successful.\n */\n-DUCKDB_API duckdb_state duckdb_register_aggregate_function(duckdb_connection con,\n-                                                           duckdb_aggregate_function aggregate_function);\n+DUCKDB_C_API duckdb_state duckdb_register_aggregate_function(duckdb_connection con,\n+                                                             duckdb_aggregate_function aggregate_function);\n \n /*!\n Sets the NULL handling of the aggregate function to SPECIAL_HANDLING.\n \n * @param aggregate_function The aggregate function\n */\n-DUCKDB_API void duckdb_aggregate_function_set_special_handling(duckdb_aggregate_function aggregate_function);\n+DUCKDB_C_API void duckdb_aggregate_function_set_special_handling(duckdb_aggregate_function aggregate_function);\n \n /*!\n Assigns extra information to the scalar function that can be fetched during binding, etc.\n@@ -3328,8 +3333,8 @@ Assigns extra information to the scalar function that can be fetched during bind\n * @param extra_info The extra information\n * @param destroy The callback that will be called to destroy the bind data (if any)\n */\n-DUCKDB_API void duckdb_aggregate_function_set_extra_info(duckdb_aggregate_function aggregate_function, void *extra_info,\n-                                                         duckdb_delete_callback_t destroy);\n+DUCKDB_C_API void duckdb_aggregate_function_set_extra_info(duckdb_aggregate_function aggregate_function,\n+                                                           void *extra_info, duckdb_delete_callback_t destroy);\n \n /*!\n Retrieves the extra info of the function as set in `duckdb_aggregate_function_set_extra_info`.\n@@ -3337,7 +3342,7 @@ Retrieves the extra info of the function as set in `duckdb_aggregate_function_se\n * @param info The info object\n * @return The extra info\n */\n-DUCKDB_API void *duckdb_aggregate_function_get_extra_info(duckdb_function_info info);\n+DUCKDB_C_API void *duckdb_aggregate_function_get_extra_info(duckdb_function_info info);\n \n /*!\n Report that an error has occurred while executing the aggregate function.\n@@ -3345,7 +3350,7 @@ Report that an error has occurred while executing the aggregate function.\n * @param info The info object\n * @param error The error message\n */\n-DUCKDB_API void duckdb_aggregate_function_set_error(duckdb_function_info info, const char *error);\n+DUCKDB_C_API void duckdb_aggregate_function_set_error(duckdb_function_info info, const char *error);\n \n /*!\n Creates a new empty aggregate function set.\n@@ -3354,13 +3359,13 @@ The return value should be destroyed with `duckdb_destroy_aggregate_function_set\n \n * @return The aggregate function set object.\n */\n-DUCKDB_API duckdb_aggregate_function_set duckdb_create_aggregate_function_set(const char *name);\n+DUCKDB_C_API duckdb_aggregate_function_set duckdb_create_aggregate_function_set(const char *name);\n \n /*!\n Destroys the given aggregate function set object.\n \n */\n-DUCKDB_API void duckdb_destroy_aggregate_function_set(duckdb_aggregate_function_set *aggregate_function_set);\n+DUCKDB_C_API void duckdb_destroy_aggregate_function_set(duckdb_aggregate_function_set *aggregate_function_set);\n \n /*!\n Adds the aggregate function as a new overload to the aggregate function set.\n@@ -3370,8 +3375,8 @@ Returns DuckDBError if the function could not be added, for example if the overl\n * @param set The aggregate function set\n * @param function The function to add\n */\n-DUCKDB_API duckdb_state duckdb_add_aggregate_function_to_set(duckdb_aggregate_function_set set,\n-                                                             duckdb_aggregate_function function);\n+DUCKDB_C_API duckdb_state duckdb_add_aggregate_function_to_set(duckdb_aggregate_function_set set,\n+                                                               duckdb_aggregate_function function);\n \n /*!\n Register the aggregate function set within the given connection.\n@@ -3384,8 +3389,8 @@ If the set is incomplete or a function with this name already exists DuckDBError\n * @param set The function set to register\n * @return Whether or not the registration was successful.\n */\n-DUCKDB_API duckdb_state duckdb_register_aggregate_function_set(duckdb_connection con,\n-                                                               duckdb_aggregate_function_set set);\n+DUCKDB_C_API duckdb_state duckdb_register_aggregate_function_set(duckdb_connection con,\n+                                                                 duckdb_aggregate_function_set set);\n \n //===--------------------------------------------------------------------===//\n // Table Functions\n@@ -3398,14 +3403,14 @@ The return value should be destroyed with `duckdb_destroy_table_function`.\n \n * @return The table function object.\n */\n-DUCKDB_API duckdb_table_function duckdb_create_table_function();\n+DUCKDB_C_API duckdb_table_function duckdb_create_table_function();\n \n /*!\n Destroys the given table function object.\n \n * @param table_function The table function to destroy\n */\n-DUCKDB_API void duckdb_destroy_table_function(duckdb_table_function *table_function);\n+DUCKDB_C_API void duckdb_destroy_table_function(duckdb_table_function *table_function);\n \n /*!\n Sets the name of the given table function.\n@@ -3413,7 +3418,7 @@ Sets the name of the given table function.\n * @param table_function The table function\n * @param name The name of the table function\n */\n-DUCKDB_API void duckdb_table_function_set_name(duckdb_table_function table_function, const char *name);\n+DUCKDB_C_API void duckdb_table_function_set_name(duckdb_table_function table_function, const char *name);\n \n /*!\n Adds a parameter to the table function.\n@@ -3421,7 +3426,7 @@ Adds a parameter to the table function.\n * @param table_function The table function.\n * @param type The parameter type. Cannot contain INVALID.\n */\n-DUCKDB_API void duckdb_table_function_add_parameter(duckdb_table_function table_function, duckdb_logical_type type);\n+DUCKDB_C_API void duckdb_table_function_add_parameter(duckdb_table_function table_function, duckdb_logical_type type);\n \n /*!\n Adds a named parameter to the table function.\n@@ -3430,8 +3435,8 @@ Adds a named parameter to the table function.\n * @param name The parameter name.\n * @param type The parameter type. Cannot contain INVALID.\n */\n-DUCKDB_API void duckdb_table_function_add_named_parameter(duckdb_table_function table_function, const char *name,\n-                                                          duckdb_logical_type type);\n+DUCKDB_C_API void duckdb_table_function_add_named_parameter(duckdb_table_function table_function, const char *name,\n+                                                            duckdb_logical_type type);\n \n /*!\n Assigns extra information to the table function that can be fetched during binding, etc.\n@@ -3440,8 +3445,8 @@ Assigns extra information to the table function that can be fetched during bindi\n * @param extra_info The extra information\n * @param destroy The callback that will be called to destroy the bind data (if any)\n */\n-DUCKDB_API void duckdb_table_function_set_extra_info(duckdb_table_function table_function, void *extra_info,\n-                                                     duckdb_delete_callback_t destroy);\n+DUCKDB_C_API void duckdb_table_function_set_extra_info(duckdb_table_function table_function, void *extra_info,\n+                                                       duckdb_delete_callback_t destroy);\n \n /*!\n Sets the bind function of the table function.\n@@ -3449,7 +3454,8 @@ Sets the bind function of the table function.\n * @param table_function The table function\n * @param bind The bind function\n */\n-DUCKDB_API void duckdb_table_function_set_bind(duckdb_table_function table_function, duckdb_table_function_bind_t bind);\n+DUCKDB_C_API void duckdb_table_function_set_bind(duckdb_table_function table_function,\n+                                                 duckdb_table_function_bind_t bind);\n \n /*!\n Sets the init function of the table function.\n@@ -3457,7 +3463,8 @@ Sets the init function of the table function.\n * @param table_function The table function\n * @param init The init function\n */\n-DUCKDB_API void duckdb_table_function_set_init(duckdb_table_function table_function, duckdb_table_function_init_t init);\n+DUCKDB_C_API void duckdb_table_function_set_init(duckdb_table_function table_function,\n+                                                 duckdb_table_function_init_t init);\n \n /*!\n Sets the thread-local init function of the table function.\n@@ -3465,8 +3472,8 @@ Sets the thread-local init function of the table function.\n * @param table_function The table function\n * @param init The init function\n */\n-DUCKDB_API void duckdb_table_function_set_local_init(duckdb_table_function table_function,\n-                                                     duckdb_table_function_init_t init);\n+DUCKDB_C_API void duckdb_table_function_set_local_init(duckdb_table_function table_function,\n+                                                       duckdb_table_function_init_t init);\n \n /*!\n Sets the main function of the table function.\n@@ -3474,8 +3481,8 @@ Sets the main function of the table function.\n * @param table_function The table function\n * @param function The function\n */\n-DUCKDB_API void duckdb_table_function_set_function(duckdb_table_function table_function,\n-                                                   duckdb_table_function_t function);\n+DUCKDB_C_API void duckdb_table_function_set_function(duckdb_table_function table_function,\n+                                                     duckdb_table_function_t function);\n \n /*!\n Sets whether or not the given table function supports projection pushdown.\n@@ -3487,7 +3494,8 @@ If this is set to false (the default), the system will expect all columns to be\n * @param table_function The table function\n * @param pushdown True if the table function supports projection pushdown, false otherwise.\n */\n-DUCKDB_API void duckdb_table_function_supports_projection_pushdown(duckdb_table_function table_function, bool pushdown);\n+DUCKDB_C_API void duckdb_table_function_supports_projection_pushdown(duckdb_table_function table_function,\n+                                                                     bool pushdown);\n \n /*!\n Register the table function object within the given connection.\n@@ -3500,7 +3508,7 @@ If the function is incomplete or a function with this name already exists DuckDB\n * @param function The function pointer\n * @return Whether or not the registration was successful.\n */\n-DUCKDB_API duckdb_state duckdb_register_table_function(duckdb_connection con, duckdb_table_function function);\n+DUCKDB_C_API duckdb_state duckdb_register_table_function(duckdb_connection con, duckdb_table_function function);\n \n //===--------------------------------------------------------------------===//\n // Table Function Bind\n@@ -3512,7 +3520,7 @@ Retrieves the extra info of the function as set in `duckdb_table_function_set_ex\n * @param info The info object\n * @return The extra info\n */\n-DUCKDB_API void *duckdb_bind_get_extra_info(duckdb_bind_info info);\n+DUCKDB_C_API void *duckdb_bind_get_extra_info(duckdb_bind_info info);\n \n /*!\n Adds a result column to the output of the table function.\n@@ -3521,7 +3529,7 @@ Adds a result column to the output of the table function.\n * @param name The column name.\n * @param type The logical column type.\n */\n-DUCKDB_API void duckdb_bind_add_result_column(duckdb_bind_info info, const char *name, duckdb_logical_type type);\n+DUCKDB_C_API void duckdb_bind_add_result_column(duckdb_bind_info info, const char *name, duckdb_logical_type type);\n \n /*!\n Retrieves the number of regular (non-named) parameters to the function.\n@@ -3529,7 +3537,7 @@ Retrieves the number of regular (non-named) parameters to the function.\n * @param info The info object\n * @return The number of parameters\n */\n-DUCKDB_API idx_t duckdb_bind_get_parameter_count(duckdb_bind_info info);\n+DUCKDB_C_API idx_t duckdb_bind_get_parameter_count(duckdb_bind_info info);\n \n /*!\n Retrieves the parameter at the given index.\n@@ -3540,7 +3548,7 @@ The result must be destroyed with `duckdb_destroy_value`.\n * @param index The index of the parameter to get\n * @return The value of the parameter. Must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_bind_get_parameter(duckdb_bind_info info, idx_t index);\n+DUCKDB_C_API duckdb_value duckdb_bind_get_parameter(duckdb_bind_info info, idx_t index);\n \n /*!\n Retrieves a named parameter with the given name.\n@@ -3551,7 +3559,7 @@ The result must be destroyed with `duckdb_destroy_value`.\n * @param name The name of the parameter\n * @return The value of the parameter. Must be destroyed with `duckdb_destroy_value`.\n */\n-DUCKDB_API duckdb_value duckdb_bind_get_named_parameter(duckdb_bind_info info, const char *name);\n+DUCKDB_C_API duckdb_value duckdb_bind_get_named_parameter(duckdb_bind_info info, const char *name);\n \n /*!\n Sets the user-provided bind data in the bind object. This object can be retrieved again during execution.\n@@ -3560,7 +3568,7 @@ Sets the user-provided bind data in the bind object. This object can be retrieve\n * @param bind_data The bind data object.\n * @param destroy The callback that will be called to destroy the bind data (if any)\n */\n-DUCKDB_API void duckdb_bind_set_bind_data(duckdb_bind_info info, void *bind_data, duckdb_delete_callback_t destroy);\n+DUCKDB_C_API void duckdb_bind_set_bind_data(duckdb_bind_info info, void *bind_data, duckdb_delete_callback_t destroy);\n \n /*!\n Sets the cardinality estimate for the table function, used for optimization.\n@@ -3568,7 +3576,7 @@ Sets the cardinality estimate for the table function, used for optimization.\n * @param info The bind data object.\n * @param is_exact Whether or not the cardinality estimate is exact, or an approximation\n */\n-DUCKDB_API void duckdb_bind_set_cardinality(duckdb_bind_info info, idx_t cardinality, bool is_exact);\n+DUCKDB_C_API void duckdb_bind_set_cardinality(duckdb_bind_info info, idx_t cardinality, bool is_exact);\n \n /*!\n Report that an error has occurred while calling bind.\n@@ -3576,7 +3584,7 @@ Report that an error has occurred while calling bind.\n * @param info The info object\n * @param error The error message\n */\n-DUCKDB_API void duckdb_bind_set_error(duckdb_bind_info info, const char *error);\n+DUCKDB_C_API void duckdb_bind_set_error(duckdb_bind_info info, const char *error);\n \n //===--------------------------------------------------------------------===//\n // Table Function Init\n@@ -3588,7 +3596,7 @@ Retrieves the extra info of the function as set in `duckdb_table_function_set_ex\n * @param info The info object\n * @return The extra info\n */\n-DUCKDB_API void *duckdb_init_get_extra_info(duckdb_init_info info);\n+DUCKDB_C_API void *duckdb_init_get_extra_info(duckdb_init_info info);\n \n /*!\n Gets the bind data set by `duckdb_bind_set_bind_data` during the bind.\n@@ -3599,7 +3607,7 @@ For tracking state, use the init data instead.\n * @param info The info object\n * @return The bind data object\n */\n-DUCKDB_API void *duckdb_init_get_bind_data(duckdb_init_info info);\n+DUCKDB_C_API void *duckdb_init_get_bind_data(duckdb_init_info info);\n \n /*!\n Sets the user-provided init data in the init object. This object can be retrieved again during execution.\n@@ -3608,7 +3616,7 @@ Sets the user-provided init data in the init object. This object can be retrieve\n * @param init_data The init data object.\n * @param destroy The callback that will be called to destroy the init data (if any)\n */\n-DUCKDB_API void duckdb_init_set_init_data(duckdb_init_info info, void *init_data, duckdb_delete_callback_t destroy);\n+DUCKDB_C_API void duckdb_init_set_init_data(duckdb_init_info info, void *init_data, duckdb_delete_callback_t destroy);\n \n /*!\n Returns the number of projected columns.\n@@ -3618,7 +3626,7 @@ This function must be used if projection pushdown is enabled to figure out which\n * @param info The info object\n * @return The number of projected columns.\n */\n-DUCKDB_API idx_t duckdb_init_get_column_count(duckdb_init_info info);\n+DUCKDB_C_API idx_t duckdb_init_get_column_count(duckdb_init_info info);\n \n /*!\n Returns the column index of the projected column at the specified position.\n@@ -3629,7 +3637,7 @@ This function must be used if projection pushdown is enabled to figure out which\n * @param column_index The index at which to get the projected column index, from 0..duckdb_init_get_column_count(info)\n * @return The column index of the projected column.\n */\n-DUCKDB_API idx_t duckdb_init_get_column_index(duckdb_init_info info, idx_t column_index);\n+DUCKDB_C_API idx_t duckdb_init_get_column_index(duckdb_init_info info, idx_t column_index);\n \n /*!\n Sets how many threads can process this table function in parallel (default: 1)\n@@ -3637,7 +3645,7 @@ Sets how many threads can process this table function in parallel (default: 1)\n * @param info The info object\n * @param max_threads The maximum amount of threads that can process this table function\n */\n-DUCKDB_API void duckdb_init_set_max_threads(duckdb_init_info info, idx_t max_threads);\n+DUCKDB_C_API void duckdb_init_set_max_threads(duckdb_init_info info, idx_t max_threads);\n \n /*!\n Report that an error has occurred while calling init.\n@@ -3645,7 +3653,7 @@ Report that an error has occurred while calling init.\n * @param info The info object\n * @param error The error message\n */\n-DUCKDB_API void duckdb_init_set_error(duckdb_init_info info, const char *error);\n+DUCKDB_C_API void duckdb_init_set_error(duckdb_init_info info, const char *error);\n \n //===--------------------------------------------------------------------===//\n // Table Function\n@@ -3657,7 +3665,7 @@ Retrieves the extra info of the function as set in `duckdb_table_function_set_ex\n * @param info The info object\n * @return The extra info\n */\n-DUCKDB_API void *duckdb_function_get_extra_info(duckdb_function_info info);\n+DUCKDB_C_API void *duckdb_function_get_extra_info(duckdb_function_info info);\n \n /*!\n Gets the bind data set by `duckdb_bind_set_bind_data` during the bind.\n@@ -3668,7 +3676,7 @@ For tracking state, use the init data instead.\n * @param info The info object\n * @return The bind data object\n */\n-DUCKDB_API void *duckdb_function_get_bind_data(duckdb_function_info info);\n+DUCKDB_C_API void *duckdb_function_get_bind_data(duckdb_function_info info);\n \n /*!\n Gets the init data set by `duckdb_init_set_init_data` during the init.\n@@ -3676,7 +3684,7 @@ Gets the init data set by `duckdb_init_set_init_data` during the init.\n * @param info The info object\n * @return The init data object\n */\n-DUCKDB_API void *duckdb_function_get_init_data(duckdb_function_info info);\n+DUCKDB_C_API void *duckdb_function_get_init_data(duckdb_function_info info);\n \n /*!\n Gets the thread-local init data set by `duckdb_init_set_init_data` during the local_init.\n@@ -3684,7 +3692,7 @@ Gets the thread-local init data set by `duckdb_init_set_init_data` during the lo\n * @param info The info object\n * @return The init data object\n */\n-DUCKDB_API void *duckdb_function_get_local_init_data(duckdb_function_info info);\n+DUCKDB_C_API void *duckdb_function_get_local_init_data(duckdb_function_info info);\n \n /*!\n Report that an error has occurred while executing the function.\n@@ -3692,7 +3700,7 @@ Report that an error has occurred while executing the function.\n * @param info The info object\n * @param error The error message\n */\n-DUCKDB_API void duckdb_function_set_error(duckdb_function_info info, const char *error);\n+DUCKDB_C_API void duckdb_function_set_error(duckdb_function_info info, const char *error);\n \n //===--------------------------------------------------------------------===//\n // Replacement Scans\n@@ -3706,8 +3714,8 @@ Add a replacement scan definition to the specified database.\n * @param extra_data Extra data that is passed back into the specified callback\n * @param delete_callback The delete callback to call on the extra data, if any\n */\n-DUCKDB_API void duckdb_add_replacement_scan(duckdb_database db, duckdb_replacement_callback_t replacement,\n-                                            void *extra_data, duckdb_delete_callback_t delete_callback);\n+DUCKDB_C_API void duckdb_add_replacement_scan(duckdb_database db, duckdb_replacement_callback_t replacement,\n+                                              void *extra_data, duckdb_delete_callback_t delete_callback);\n \n /*!\n Sets the replacement function name. If this function is called in the replacement callback,\n@@ -3716,7 +3724,8 @@ the replacement scan is performed. If it is not called, the replacement callback\n * @param info The info object\n * @param function_name The function name to substitute.\n */\n-DUCKDB_API void duckdb_replacement_scan_set_function_name(duckdb_replacement_scan_info info, const char *function_name);\n+DUCKDB_C_API void duckdb_replacement_scan_set_function_name(duckdb_replacement_scan_info info,\n+                                                            const char *function_name);\n \n /*!\n Adds a parameter to the replacement scan function.\n@@ -3724,7 +3733,7 @@ Adds a parameter to the replacement scan function.\n * @param info The info object\n * @param parameter The parameter to add.\n */\n-DUCKDB_API void duckdb_replacement_scan_add_parameter(duckdb_replacement_scan_info info, duckdb_value parameter);\n+DUCKDB_C_API void duckdb_replacement_scan_add_parameter(duckdb_replacement_scan_info info, duckdb_value parameter);\n \n /*!\n Report that an error has occurred while executing the replacement scan.\n@@ -3732,7 +3741,7 @@ Report that an error has occurred while executing the replacement scan.\n * @param info The info object\n * @param error The error message\n */\n-DUCKDB_API void duckdb_replacement_scan_set_error(duckdb_replacement_scan_info info, const char *error);\n+DUCKDB_C_API void duckdb_replacement_scan_set_error(duckdb_replacement_scan_info info, const char *error);\n \n //===--------------------------------------------------------------------===//\n // Profiling Info\n@@ -3744,7 +3753,7 @@ Returns the root node of the profiling information. Returns nullptr, if profilin\n * @param connection A connection object.\n * @return A profiling information object.\n */\n-DUCKDB_API duckdb_profiling_info duckdb_get_profiling_info(duckdb_connection connection);\n+DUCKDB_C_API duckdb_profiling_info duckdb_get_profiling_info(duckdb_connection connection);\n \n /*!\n Returns the value of the metric of the current profiling info node. Returns nullptr, if the metric does\n@@ -3755,7 +3764,7 @@ Returns the value of the metric of the current profiling info node. Returns null\n * @param key The name of the requested metric.\n * @return The value of the metric. Must be freed with `duckdb_destroy_value`\n */\n-DUCKDB_API duckdb_value duckdb_profiling_info_get_value(duckdb_profiling_info info, const char *key);\n+DUCKDB_C_API duckdb_value duckdb_profiling_info_get_value(duckdb_profiling_info info, const char *key);\n \n /*!\n Returns the key-value metric map of this profiling node as a MAP duckdb_value.\n@@ -3764,7 +3773,7 @@ The individual elements are accessible via the duckdb_value MAP functions.\n * @param info A profiling information object.\n * @return The key-value metric map as a MAP duckdb_value.\n */\n-DUCKDB_API duckdb_value duckdb_profiling_info_get_metrics(duckdb_profiling_info info);\n+DUCKDB_C_API duckdb_value duckdb_profiling_info_get_metrics(duckdb_profiling_info info);\n \n /*!\n Returns the number of children in the current profiling info node.\n@@ -3772,7 +3781,7 @@ Returns the number of children in the current profiling info node.\n * @param info A profiling information object.\n * @return The number of children in the current node.\n */\n-DUCKDB_API idx_t duckdb_profiling_info_get_child_count(duckdb_profiling_info info);\n+DUCKDB_C_API idx_t duckdb_profiling_info_get_child_count(duckdb_profiling_info info);\n \n /*!\n Returns the child node at the specified index.\n@@ -3781,7 +3790,7 @@ Returns the child node at the specified index.\n * @param index The index of the child node.\n * @return The child node at the specified index.\n */\n-DUCKDB_API duckdb_profiling_info duckdb_profiling_info_get_child(duckdb_profiling_info info, idx_t index);\n+DUCKDB_C_API duckdb_profiling_info duckdb_profiling_info_get_child(duckdb_profiling_info info, idx_t index);\n \n //===--------------------------------------------------------------------===//\n // Appender\n@@ -3812,8 +3821,8 @@ Note that the object must be destroyed with `duckdb_appender_destroy`.\n * @param out_appender The resulting appender object.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_appender_create(duckdb_connection connection, const char *schema, const char *table,\n-                                               duckdb_appender *out_appender);\n+DUCKDB_C_API duckdb_state duckdb_appender_create(duckdb_connection connection, const char *schema, const char *table,\n+                                                 duckdb_appender *out_appender);\n \n /*!\n Creates an appender object.\n@@ -3827,9 +3836,9 @@ Note that the object must be destroyed with `duckdb_appender_destroy`.\n * @param out_appender The resulting appender object.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_appender_create_ext(duckdb_connection connection, const char *catalog,\n-                                                   const char *schema, const char *table,\n-                                                   duckdb_appender *out_appender);\n+DUCKDB_C_API duckdb_state duckdb_appender_create_ext(duckdb_connection connection, const char *catalog,\n+                                                     const char *schema, const char *table,\n+                                                     duckdb_appender *out_appender);\n \n /*!\n Returns the number of columns that belong to the appender.\n@@ -3838,7 +3847,7 @@ If there is no active column list, then this equals the table's physical columns\n * @param appender The appender to get the column count from.\n * @return The number of columns in the data chunks.\n */\n-DUCKDB_API idx_t duckdb_appender_column_count(duckdb_appender appender);\n+DUCKDB_C_API idx_t duckdb_appender_column_count(duckdb_appender appender);\n \n /*!\n Returns the type of the column at the specified index. This is either a type in the active column list, or the same type\n@@ -3850,7 +3859,7 @@ Note: The resulting type must be destroyed with `duckdb_destroy_logical_type`.\n * @param col_idx The index of the column to get the type of.\n * @return The `duckdb_logical_type` of the column.\n */\n-DUCKDB_API duckdb_logical_type duckdb_appender_column_type(duckdb_appender appender, idx_t col_idx);\n+DUCKDB_C_API duckdb_logical_type duckdb_appender_column_type(duckdb_appender appender, idx_t col_idx);\n \n /*!\n Returns the error message associated with the given appender.\n@@ -3861,7 +3870,7 @@ The error message should not be freed. It will be de-allocated when `duckdb_appe\n * @param appender The appender to get the error from.\n * @return The error message, or `nullptr` if there is none.\n */\n-DUCKDB_API const char *duckdb_appender_error(duckdb_appender appender);\n+DUCKDB_C_API const char *duckdb_appender_error(duckdb_appender appender);\n \n /*!\n Flush the appender to the table, forcing the cache of the appender to be cleared. If flushing the data triggers a\n@@ -3872,7 +3881,7 @@ duckdb_appender_destroy to destroy the invalidated appender.\n * @param appender The appender to flush.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_appender_flush(duckdb_appender appender);\n+DUCKDB_C_API duckdb_state duckdb_appender_flush(duckdb_appender appender);\n \n /*!\n Closes the appender by flushing all intermediate states and closing it for further appends. If flushing the data\n@@ -3883,7 +3892,7 @@ appender.\n * @param appender The appender to flush and close.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_appender_close(duckdb_appender appender);\n+DUCKDB_C_API duckdb_state duckdb_appender_close(duckdb_appender appender);\n \n /*!\n Closes the appender by flushing all intermediate states to the table and destroying it. By destroying it, this function\n@@ -3895,7 +3904,7 @@ before destroying the appender, if you need insights into the specific error.\n * @param appender The appender to flush, close and destroy.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_appender_destroy(duckdb_appender *appender);\n+DUCKDB_C_API duckdb_state duckdb_appender_destroy(duckdb_appender *appender);\n \n /*!\n Appends a column to the active column list of the appender. Immediately flushes all previous data.\n@@ -3906,7 +3915,7 @@ with their default values, or NULL.\n * @param appender The appender to add the column to.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_appender_add_column(duckdb_appender appender, const char *name);\n+DUCKDB_C_API duckdb_state duckdb_appender_add_column(duckdb_appender appender, const char *name);\n \n /*!\n Removes all columns from the active column list of the appender, resetting the appender to treat all columns as active.\n@@ -3915,12 +3924,12 @@ Immediately flushes all previous data.\n * @param appender The appender to clear the columns from.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_appender_clear_columns(duckdb_appender appender);\n+DUCKDB_C_API duckdb_state duckdb_appender_clear_columns(duckdb_appender appender);\n \n /*!\n A nop function, provided for backwards compatibility reasons. Does nothing. Only `duckdb_appender_end_row` is required.\n */\n-DUCKDB_API duckdb_state duckdb_appender_begin_row(duckdb_appender appender);\n+DUCKDB_C_API duckdb_state duckdb_appender_begin_row(duckdb_appender appender);\n \n /*!\n Finish the current row of appends. After end_row is called, the next row can be appended.\n@@ -3928,12 +3937,12 @@ Finish the current row of appends. After end_row is called, the next row can be\n * @param appender The appender.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_appender_end_row(duckdb_appender appender);\n+DUCKDB_C_API duckdb_state duckdb_appender_end_row(duckdb_appender appender);\n \n /*!\n Append a DEFAULT value (NULL if DEFAULT not available for column) to the appender.\n */\n-DUCKDB_API duckdb_state duckdb_append_default(duckdb_appender appender);\n+DUCKDB_C_API duckdb_state duckdb_append_default(duckdb_appender appender);\n \n /*!\n Append a DEFAULT value, at the specified row and column, (NULL if DEFAULT not available for column) to the chunk created\n@@ -3946,118 +3955,118 @@ like nextval('seq') or random() are not supported.\n * @param row The chunk row index to append the default value to.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_append_default_to_chunk(duckdb_appender appender, duckdb_data_chunk chunk, idx_t col,\n-                                                       idx_t row);\n+DUCKDB_C_API duckdb_state duckdb_append_default_to_chunk(duckdb_appender appender, duckdb_data_chunk chunk, idx_t col,\n+                                                         idx_t row);\n \n /*!\n Append a bool value to the appender.\n */\n-DUCKDB_API duckdb_state duckdb_append_bool(duckdb_appender appender, bool value);\n+DUCKDB_C_API duckdb_state duckdb_append_bool(duckdb_appender appender, bool value);\n \n /*!\n Append an int8_t value to the appender.\n */\n-DUCKDB_API duckdb_state duckdb_append_int8(duckdb_appender appender, int8_t value);\n+DUCKDB_C_API duckdb_state duckdb_append_int8(duckdb_appender appender, int8_t value);\n \n /*!\n Append an int16_t value to the appender.\n */\n-DUCKDB_API duckdb_state duckdb_append_int16(duckdb_appender appender, int16_t value);\n+DUCKDB_C_API duckdb_state duckdb_append_int16(duckdb_appender appender, int16_t value);\n \n /*!\n Append an int32_t value to the appender.\n */\n-DUCKDB_API duckdb_state duckdb_append_int32(duckdb_appender appender, int32_t value);\n+DUCKDB_C_API duckdb_state duckdb_append_int32(duckdb_appender appender, int32_t value);\n \n /*!\n Append an int64_t value to the appender.\n */\n-DUCKDB_API duckdb_state duckdb_append_int64(duckdb_appender appender, int64_t value);\n+DUCKDB_C_API duckdb_state duckdb_append_int64(duckdb_appender appender, int64_t value);\n \n /*!\n Append a duckdb_hugeint value to the appender.\n */\n-DUCKDB_API duckdb_state duckdb_append_hugeint(duckdb_appender appender, duckdb_hugeint value);\n+DUCKDB_C_API duckdb_state duckdb_append_hugeint(duckdb_appender appender, duckdb_hugeint value);\n \n /*!\n Append a uint8_t value to the appender.\n */\n-DUCKDB_API duckdb_state duckdb_append_uint8(duckdb_appender appender, uint8_t value);\n+DUCKDB_C_API duckdb_state duckdb_append_uint8(duckdb_appender appender, uint8_t value);\n \n /*!\n Append a uint16_t value to the appender.\n */\n-DUCKDB_API duckdb_state duckdb_append_uint16(duckdb_appender appender, uint16_t value);\n+DUCKDB_C_API duckdb_state duckdb_append_uint16(duckdb_appender appender, uint16_t value);\n \n /*!\n Append a uint32_t value to the appender.\n */\n-DUCKDB_API duckdb_state duckdb_append_uint32(duckdb_appender appender, uint32_t value);\n+DUCKDB_C_API duckdb_state duckdb_append_uint32(duckdb_appender appender, uint32_t value);\n \n /*!\n Append a uint64_t value to the appender.\n */\n-DUCKDB_API duckdb_state duckdb_append_uint64(duckdb_appender appender, uint64_t value);\n+DUCKDB_C_API duckdb_state duckdb_append_uint64(duckdb_appender appender, uint64_t value);\n \n /*!\n Append a duckdb_uhugeint value to the appender.\n */\n-DUCKDB_API duckdb_state duckdb_append_uhugeint(duckdb_appender appender, duckdb_uhugeint value);\n+DUCKDB_C_API duckdb_state duckdb_append_uhugeint(duckdb_appender appender, duckdb_uhugeint value);\n \n /*!\n Append a float value to the appender.\n */\n-DUCKDB_API duckdb_state duckdb_append_float(duckdb_appender appender, float value);\n+DUCKDB_C_API duckdb_state duckdb_append_float(duckdb_appender appender, float value);\n \n /*!\n Append a double value to the appender.\n */\n-DUCKDB_API duckdb_state duckdb_append_double(duckdb_appender appender, double value);\n+DUCKDB_C_API duckdb_state duckdb_append_double(duckdb_appender appender, double value);\n \n /*!\n Append a duckdb_date value to the appender.\n */\n-DUCKDB_API duckdb_state duckdb_append_date(duckdb_appender appender, duckdb_date value);\n+DUCKDB_C_API duckdb_state duckdb_append_date(duckdb_appender appender, duckdb_date value);\n \n /*!\n Append a duckdb_time value to the appender.\n */\n-DUCKDB_API duckdb_state duckdb_append_time(duckdb_appender appender, duckdb_time value);\n+DUCKDB_C_API duckdb_state duckdb_append_time(duckdb_appender appender, duckdb_time value);\n \n /*!\n Append a duckdb_timestamp value to the appender.\n */\n-DUCKDB_API duckdb_state duckdb_append_timestamp(duckdb_appender appender, duckdb_timestamp value);\n+DUCKDB_C_API duckdb_state duckdb_append_timestamp(duckdb_appender appender, duckdb_timestamp value);\n \n /*!\n Append a duckdb_interval value to the appender.\n */\n-DUCKDB_API duckdb_state duckdb_append_interval(duckdb_appender appender, duckdb_interval value);\n+DUCKDB_C_API duckdb_state duckdb_append_interval(duckdb_appender appender, duckdb_interval value);\n \n /*!\n Append a varchar value to the appender.\n */\n-DUCKDB_API duckdb_state duckdb_append_varchar(duckdb_appender appender, const char *val);\n+DUCKDB_C_API duckdb_state duckdb_append_varchar(duckdb_appender appender, const char *val);\n \n /*!\n Append a varchar value to the appender.\n */\n-DUCKDB_API duckdb_state duckdb_append_varchar_length(duckdb_appender appender, const char *val, idx_t length);\n+DUCKDB_C_API duckdb_state duckdb_append_varchar_length(duckdb_appender appender, const char *val, idx_t length);\n \n /*!\n Append a blob value to the appender.\n */\n-DUCKDB_API duckdb_state duckdb_append_blob(duckdb_appender appender, const void *data, idx_t length);\n+DUCKDB_C_API duckdb_state duckdb_append_blob(duckdb_appender appender, const void *data, idx_t length);\n \n /*!\n Append a NULL value to the appender (of any type).\n */\n-DUCKDB_API duckdb_state duckdb_append_null(duckdb_appender appender);\n+DUCKDB_C_API duckdb_state duckdb_append_null(duckdb_appender appender);\n \n /*!\n Append a duckdb_value to the appender.\n */\n-DUCKDB_API duckdb_state duckdb_append_value(duckdb_appender appender, duckdb_value value);\n+DUCKDB_C_API duckdb_state duckdb_append_value(duckdb_appender appender, duckdb_value value);\n \n /*!\n Appends a pre-filled data chunk to the specified appender.\n@@ -4067,7 +4076,7 @@ Appends a pre-filled data chunk to the specified appender.\n * @param chunk The data chunk to append.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_append_data_chunk(duckdb_appender appender, duckdb_data_chunk chunk);\n+DUCKDB_C_API duckdb_state duckdb_append_data_chunk(duckdb_appender appender, duckdb_data_chunk chunk);\n \n //===--------------------------------------------------------------------===//\n // Table Description\n@@ -4083,8 +4092,8 @@ resulting table_description, even if the function returns `DuckDBError`.\n * @param out The resulting table description object.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_table_description_create(duckdb_connection connection, const char *schema,\n-                                                        const char *table, duckdb_table_description *out);\n+DUCKDB_C_API duckdb_state duckdb_table_description_create(duckdb_connection connection, const char *schema,\n+                                                          const char *table, duckdb_table_description *out);\n \n /*!\n Creates a table description object. Note that `duckdb_table_description_destroy` must be called on the resulting\n@@ -4097,16 +4106,16 @@ table_description, even if the function returns `DuckDBError`.\n * @param out The resulting table description object.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_table_description_create_ext(duckdb_connection connection, const char *catalog,\n-                                                            const char *schema, const char *table,\n-                                                            duckdb_table_description *out);\n+DUCKDB_C_API duckdb_state duckdb_table_description_create_ext(duckdb_connection connection, const char *catalog,\n+                                                              const char *schema, const char *table,\n+                                                              duckdb_table_description *out);\n \n /*!\n Destroy the TableDescription object.\n \n * @param table_description The table_description to destroy.\n */\n-DUCKDB_API void duckdb_table_description_destroy(duckdb_table_description *table_description);\n+DUCKDB_C_API void duckdb_table_description_destroy(duckdb_table_description *table_description);\n \n /*!\n Returns the error message associated with the given table_description.\n@@ -4116,7 +4125,7 @@ The error message should not be freed. It will be de-allocated when `duckdb_tabl\n * @param table_description The table_description to get the error from.\n * @return The error message, or `nullptr` if there is none.\n */\n-DUCKDB_API const char *duckdb_table_description_error(duckdb_table_description table_description);\n+DUCKDB_C_API const char *duckdb_table_description_error(duckdb_table_description table_description);\n \n /*!\n Check if the column at 'index' index of the table has a DEFAULT expression.\n@@ -4126,7 +4135,7 @@ Check if the column at 'index' index of the table has a DEFAULT expression.\n * @param out The out-parameter used to store the result.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_column_has_default(duckdb_table_description table_description, idx_t index, bool *out);\n+DUCKDB_C_API duckdb_state duckdb_column_has_default(duckdb_table_description table_description, idx_t index, bool *out);\n \n /*!\n Obtain the column name at 'index'.\n@@ -4136,7 +4145,7 @@ The out result must be destroyed with `duckdb_free`.\n * @param index The index of the column to query.\n * @return The column name.\n */\n-DUCKDB_API char *duckdb_table_description_get_column_name(duckdb_table_description table_description, idx_t index);\n+DUCKDB_C_API char *duckdb_table_description_get_column_name(duckdb_table_description table_description, idx_t index);\n \n //===--------------------------------------------------------------------===//\n // Arrow Interface\n@@ -4158,7 +4167,7 @@ query fails, otherwise the error stored within the result will not be freed corr\n * @param out_result The query result.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_query_arrow(duckdb_connection connection, const char *query, duckdb_arrow *out_result);\n+DUCKDB_C_API duckdb_state duckdb_query_arrow(duckdb_connection connection, const char *query, duckdb_arrow *out_result);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n@@ -4170,7 +4179,7 @@ ArrowSchema object.\n * @param out_schema The output schema.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_query_arrow_schema(duckdb_arrow result, duckdb_arrow_schema *out_schema);\n+DUCKDB_C_API duckdb_state duckdb_query_arrow_schema(duckdb_arrow result, duckdb_arrow_schema *out_schema);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n@@ -4182,8 +4191,8 @@ ArrowSchema object.\n * @param out_schema The output schema.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_prepared_arrow_schema(duckdb_prepared_statement prepared,\n-                                                     duckdb_arrow_schema *out_schema);\n+DUCKDB_C_API duckdb_state duckdb_prepared_arrow_schema(duckdb_prepared_statement prepared,\n+                                                       duckdb_arrow_schema *out_schema);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n@@ -4195,7 +4204,8 @@ ArrowArray object.\n * @param chunk The data chunk to convert.\n * @param out_array The output array.\n */\n-DUCKDB_API void duckdb_result_arrow_array(duckdb_result result, duckdb_data_chunk chunk, duckdb_arrow_array *out_array);\n+DUCKDB_C_API void duckdb_result_arrow_array(duckdb_result result, duckdb_data_chunk chunk,\n+                                            duckdb_arrow_array *out_array);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n@@ -4210,7 +4220,7 @@ So consume the out_array before calling this function again.\n * @param out_array The output array.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_query_arrow_array(duckdb_arrow result, duckdb_arrow_array *out_array);\n+DUCKDB_C_API duckdb_state duckdb_query_arrow_array(duckdb_arrow result, duckdb_arrow_array *out_array);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n@@ -4220,7 +4230,7 @@ Returns the number of columns present in the arrow result object.\n * @param result The result object.\n * @return The number of columns present in the result object.\n */\n-DUCKDB_API idx_t duckdb_arrow_column_count(duckdb_arrow result);\n+DUCKDB_C_API idx_t duckdb_arrow_column_count(duckdb_arrow result);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n@@ -4230,7 +4240,7 @@ Returns the number of rows present in the arrow result object.\n * @param result The result object.\n * @return The number of rows present in the result object.\n */\n-DUCKDB_API idx_t duckdb_arrow_row_count(duckdb_arrow result);\n+DUCKDB_C_API idx_t duckdb_arrow_row_count(duckdb_arrow result);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n@@ -4241,7 +4251,7 @@ INSERT/UPDATE/DELETE queries. For other queries the rows_changed will be 0.\n * @param result The result object.\n * @return The number of rows changed.\n */\n-DUCKDB_API idx_t duckdb_arrow_rows_changed(duckdb_arrow result);\n+DUCKDB_C_API idx_t duckdb_arrow_rows_changed(duckdb_arrow result);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n@@ -4254,7 +4264,7 @@ The error message should not be freed. It will be de-allocated when `duckdb_dest\n * @param result The result object to fetch the error from.\n * @return The error of the result.\n */\n-DUCKDB_API const char *duckdb_query_arrow_error(duckdb_arrow result);\n+DUCKDB_C_API const char *duckdb_query_arrow_error(duckdb_arrow result);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n@@ -4263,7 +4273,7 @@ Closes the result and de-allocates all memory allocated for the arrow result.\n \n * @param result The result to destroy.\n */\n-DUCKDB_API void duckdb_destroy_arrow(duckdb_arrow *result);\n+DUCKDB_C_API void duckdb_destroy_arrow(duckdb_arrow *result);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n@@ -4272,7 +4282,7 @@ Releases the arrow array stream and de-allocates its memory.\n \n * @param stream_p The arrow array stream to destroy.\n */\n-DUCKDB_API void duckdb_destroy_arrow_stream(duckdb_arrow_stream *stream_p);\n+DUCKDB_C_API void duckdb_destroy_arrow_stream(duckdb_arrow_stream *stream_p);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n@@ -4284,8 +4294,8 @@ Note that after running `duckdb_execute_prepared_arrow`, `duckdb_destroy_arrow`\n * @param out_result The query result.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_execute_prepared_arrow(duckdb_prepared_statement prepared_statement,\n-                                                      duckdb_arrow *out_result);\n+DUCKDB_C_API duckdb_state duckdb_execute_prepared_arrow(duckdb_prepared_statement prepared_statement,\n+                                                        duckdb_arrow *out_result);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n@@ -4297,8 +4307,8 @@ Scans the Arrow stream and creates a view with the given name.\n * @param arrow Arrow stream wrapper.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_arrow_scan(duckdb_connection connection, const char *table_name,\n-                                          duckdb_arrow_stream arrow);\n+DUCKDB_C_API duckdb_state duckdb_arrow_scan(duckdb_connection connection, const char *table_name,\n+                                            duckdb_arrow_stream arrow);\n \n /*!\n **DEPRECATION NOTICE**: This method is scheduled for removal in a future release.\n@@ -4313,9 +4323,9 @@ Note that after running `duckdb_arrow_array_scan`, `duckdb_destroy_arrow_stream`\n * @param out_stream Output array stream that wraps around the passed schema, for releasing/deleting once done.\n * @return `DuckDBSuccess` on success or `DuckDBError` on failure.\n */\n-DUCKDB_API duckdb_state duckdb_arrow_array_scan(duckdb_connection connection, const char *table_name,\n-                                                duckdb_arrow_schema arrow_schema, duckdb_arrow_array arrow_array,\n-                                                duckdb_arrow_stream *out_stream);\n+DUCKDB_C_API duckdb_state duckdb_arrow_array_scan(duckdb_connection connection, const char *table_name,\n+                                                  duckdb_arrow_schema arrow_schema, duckdb_arrow_array arrow_array,\n+                                                  duckdb_arrow_stream *out_stream);\n \n #endif\n //===--------------------------------------------------------------------===//\n@@ -4330,7 +4340,7 @@ Will return after `max_tasks` have been executed, or if there are no more tasks\n * @param database The database object to execute tasks for\n * @param max_tasks The maximum amount of tasks to execute\n */\n-DUCKDB_API void duckdb_execute_tasks(duckdb_database database, idx_t max_tasks);\n+DUCKDB_C_API void duckdb_execute_tasks(duckdb_database database, idx_t max_tasks);\n \n /*!\n Creates a task state that can be used with duckdb_execute_tasks_state to execute tasks until\n@@ -4341,7 +4351,7 @@ Creates a task state that can be used with duckdb_execute_tasks_state to execute\n * @param database The database object to create the task state for\n * @return The task state that can be used with duckdb_execute_tasks_state.\n */\n-DUCKDB_API duckdb_task_state duckdb_create_task_state(duckdb_database database);\n+DUCKDB_C_API duckdb_task_state duckdb_create_task_state(duckdb_database database);\n \n /*!\n Execute DuckDB tasks on this thread.\n@@ -4351,7 +4361,7 @@ Multiple threads can share the same duckdb_task_state.\n \n * @param state The task state of the executor\n */\n-DUCKDB_API void duckdb_execute_tasks_state(duckdb_task_state state);\n+DUCKDB_C_API void duckdb_execute_tasks_state(duckdb_task_state state);\n \n /*!\n Execute DuckDB tasks on this thread.\n@@ -4365,14 +4375,14 @@ Multiple threads can share the same duckdb_task_state.\n * @param max_tasks The maximum amount of tasks to execute\n * @return The amount of tasks that have actually been executed\n */\n-DUCKDB_API idx_t duckdb_execute_n_tasks_state(duckdb_task_state state, idx_t max_tasks);\n+DUCKDB_C_API idx_t duckdb_execute_n_tasks_state(duckdb_task_state state, idx_t max_tasks);\n \n /*!\n Finish execution on a specific task.\n \n * @param state The task state to finish execution\n */\n-DUCKDB_API void duckdb_finish_execution(duckdb_task_state state);\n+DUCKDB_C_API void duckdb_finish_execution(duckdb_task_state state);\n \n /*!\n Check if the provided duckdb_task_state has finished execution\n@@ -4380,7 +4390,7 @@ Check if the provided duckdb_task_state has finished execution\n * @param state The task state to inspect\n * @return Whether or not duckdb_finish_execution has been called on the task state\n */\n-DUCKDB_API bool duckdb_task_state_is_finished(duckdb_task_state state);\n+DUCKDB_C_API bool duckdb_task_state_is_finished(duckdb_task_state state);\n \n /*!\n Destroys the task state returned from duckdb_create_task_state.\n@@ -4390,14 +4400,14 @@ on the task state.\n \n * @param state The task state to clean up\n */\n-DUCKDB_API void duckdb_destroy_task_state(duckdb_task_state state);\n+DUCKDB_C_API void duckdb_destroy_task_state(duckdb_task_state state);\n \n /*!\n Returns true if the execution of the current query is finished.\n \n * @param con The connection on which to check\n */\n-DUCKDB_API bool duckdb_execution_is_finished(duckdb_connection con);\n+DUCKDB_C_API bool duckdb_execution_is_finished(duckdb_connection con);\n \n //===--------------------------------------------------------------------===//\n // Streaming Result Interface\n@@ -4422,7 +4432,7 @@ It is not known beforehand how many chunks will be returned by this result.\n * @param result The result object to fetch the data chunk from.\n * @return The resulting data chunk. Returns `NULL` if the result has an error.\n */\n-DUCKDB_API duckdb_data_chunk duckdb_stream_fetch_chunk(duckdb_result result);\n+DUCKDB_C_API duckdb_data_chunk duckdb_stream_fetch_chunk(duckdb_result result);\n \n #endif\n /*!\n@@ -4435,7 +4445,7 @@ It is not known beforehand how many chunks will be returned by this result.\n * @param result The result object to fetch the data chunk from.\n * @return The resulting data chunk. Returns `NULL` if the result has an error.\n */\n-DUCKDB_API duckdb_data_chunk duckdb_fetch_chunk(duckdb_result result);\n+DUCKDB_C_API duckdb_data_chunk duckdb_fetch_chunk(duckdb_result result);\n \n //===--------------------------------------------------------------------===//\n // Cast Functions\n@@ -4446,7 +4456,7 @@ Creates a new cast function object.\n \n * @return The cast function object.\n */\n-DUCKDB_API duckdb_cast_function duckdb_create_cast_function();\n+DUCKDB_C_API duckdb_cast_function duckdb_create_cast_function();\n \n /*!\n Sets the source type of the cast function.\n@@ -4454,8 +4464,8 @@ Sets the source type of the cast function.\n * @param cast_function The cast function object.\n * @param source_type The source type to set.\n */\n-DUCKDB_API void duckdb_cast_function_set_source_type(duckdb_cast_function cast_function,\n-                                                     duckdb_logical_type source_type);\n+DUCKDB_C_API void duckdb_cast_function_set_source_type(duckdb_cast_function cast_function,\n+                                                       duckdb_logical_type source_type);\n \n /*!\n Sets the target type of the cast function.\n@@ -4463,8 +4473,8 @@ Sets the target type of the cast function.\n * @param cast_function The cast function object.\n * @param target_type The target type to set.\n */\n-DUCKDB_API void duckdb_cast_function_set_target_type(duckdb_cast_function cast_function,\n-                                                     duckdb_logical_type target_type);\n+DUCKDB_C_API void duckdb_cast_function_set_target_type(duckdb_cast_function cast_function,\n+                                                       duckdb_logical_type target_type);\n \n /*!\n Sets the \"cost\" of implicitly casting the source type to the target type using this function.\n@@ -4472,7 +4482,7 @@ Sets the \"cost\" of implicitly casting the source type to the target type using t\n * @param cast_function The cast function object.\n * @param cost The cost to set.\n */\n-DUCKDB_API void duckdb_cast_function_set_implicit_cast_cost(duckdb_cast_function cast_function, int64_t cost);\n+DUCKDB_C_API void duckdb_cast_function_set_implicit_cast_cost(duckdb_cast_function cast_function, int64_t cost);\n \n /*!\n Sets the actual cast function to use.\n@@ -4480,7 +4490,8 @@ Sets the actual cast function to use.\n * @param cast_function The cast function object.\n * @param function The function to set.\n */\n-DUCKDB_API void duckdb_cast_function_set_function(duckdb_cast_function cast_function, duckdb_cast_function_t function);\n+DUCKDB_C_API void duckdb_cast_function_set_function(duckdb_cast_function cast_function,\n+                                                    duckdb_cast_function_t function);\n \n /*!\n Assigns extra information to the cast function that can be fetched during execution, etc.\n@@ -4488,8 +4499,8 @@ Assigns extra information to the cast function that can be fetched during execut\n * @param extra_info The extra information\n * @param destroy The callback that will be called to destroy the extra information (if any)\n */\n-DUCKDB_API void duckdb_cast_function_set_extra_info(duckdb_cast_function cast_function, void *extra_info,\n-                                                    duckdb_delete_callback_t destroy);\n+DUCKDB_C_API void duckdb_cast_function_set_extra_info(duckdb_cast_function cast_function, void *extra_info,\n+                                                      duckdb_delete_callback_t destroy);\n \n /*!\n Retrieves the extra info of the function as set in `duckdb_cast_function_set_extra_info`.\n@@ -4497,7 +4508,7 @@ Retrieves the extra info of the function as set in `duckdb_cast_function_set_ext\n * @param info The info object.\n * @return The extra info.\n */\n-DUCKDB_API void *duckdb_cast_function_get_extra_info(duckdb_function_info info);\n+DUCKDB_C_API void *duckdb_cast_function_get_extra_info(duckdb_function_info info);\n \n /*!\n Get the cast execution mode from the given function info.\n@@ -4505,7 +4516,7 @@ Get the cast execution mode from the given function info.\n * @param info The info object.\n * @return The cast mode.\n */\n-DUCKDB_API duckdb_cast_mode duckdb_cast_function_get_cast_mode(duckdb_function_info info);\n+DUCKDB_C_API duckdb_cast_mode duckdb_cast_function_get_cast_mode(duckdb_function_info info);\n \n /*!\n Report that an error has occurred while executing the cast function.\n@@ -4513,7 +4524,7 @@ Report that an error has occurred while executing the cast function.\n * @param info The info object.\n * @param error The error message.\n */\n-DUCKDB_API void duckdb_cast_function_set_error(duckdb_function_info info, const char *error);\n+DUCKDB_C_API void duckdb_cast_function_set_error(duckdb_function_info info, const char *error);\n \n /*!\n Report that an error has occurred while executing the cast function, setting the corresponding output row to NULL.\n@@ -4523,8 +4534,8 @@ Report that an error has occurred while executing the cast function, setting the\n * @param row The index of the row within the output vector to set to NULL.\n * @param output The output vector.\n */\n-DUCKDB_API void duckdb_cast_function_set_row_error(duckdb_function_info info, const char *error, idx_t row,\n-                                                   duckdb_vector output);\n+DUCKDB_C_API void duckdb_cast_function_set_row_error(duckdb_function_info info, const char *error, idx_t row,\n+                                                     duckdb_vector output);\n \n /*!\n Registers a cast function within the given connection.\n@@ -4533,14 +4544,14 @@ Registers a cast function within the given connection.\n * @param cast_function The cast function to register.\n * @return Whether or not the registration was successful.\n */\n-DUCKDB_API duckdb_state duckdb_register_cast_function(duckdb_connection con, duckdb_cast_function cast_function);\n+DUCKDB_C_API duckdb_state duckdb_register_cast_function(duckdb_connection con, duckdb_cast_function cast_function);\n \n /*!\n Destroys the cast function object.\n \n * @param cast_function The cast function object.\n */\n-DUCKDB_API void duckdb_destroy_cast_function(duckdb_cast_function *cast_function);\n+DUCKDB_C_API void duckdb_destroy_cast_function(duckdb_cast_function *cast_function);\n \n #endif\n \ndiff --git a/src/include/duckdb/common/adbc/adbc-init.hpp b/src/include/duckdb/common/adbc/adbc-init.hpp\nindex 8a5ce110a827..c5c3a127cda2 100644\n--- a/src/include/duckdb/common/adbc/adbc-init.hpp\n+++ b/src/include/duckdb/common/adbc/adbc-init.hpp\n@@ -30,7 +30,7 @@ extern \"C\" {\n typedef uint8_t AdbcStatusCode;\n \n //! We gotta leak the symbols of the init function\n-DUCKDB_API AdbcStatusCode duckdb_adbc_init(int version, void *driver, struct AdbcError *error);\n+DUCKDB_C_API AdbcStatusCode duckdb_adbc_init(int version, void *driver, struct AdbcError *error);\n \n #ifdef __cplusplus\n }\ndiff --git a/src/include/duckdb/function/lambda_functions.hpp b/src/include/duckdb/function/lambda_functions.hpp\nindex a47894a39a55..802d96c5e03b 100644\n--- a/src/include/duckdb/function/lambda_functions.hpp\n+++ b/src/include/duckdb/function/lambda_functions.hpp\n@@ -17,7 +17,7 @@\n \n namespace duckdb {\n \n-struct ListLambdaBindData : public FunctionData {\n+struct ListLambdaBindData final : public FunctionData {\n public:\n \tListLambdaBindData(const LogicalType &return_type, unique_ptr<Expression> lambda_expr, const bool has_index = false)\n \t    : return_type(return_type), lambda_expr(std::move(lambda_expr)), has_index(has_index) {};\n@@ -30,8 +30,16 @@ struct ListLambdaBindData : public FunctionData {\n \tbool has_index;\n \n public:\n-\tbool Equals(const FunctionData &other_p) const override;\n-\tunique_ptr<FunctionData> Copy() const override;\n+\tunique_ptr<FunctionData> Copy() const override {\n+\t\tauto lambda_expr_copy = lambda_expr ? lambda_expr->Copy() : nullptr;\n+\t\treturn make_uniq<ListLambdaBindData>(return_type, std::move(lambda_expr_copy), has_index);\n+\t}\n+\n+\tbool Equals(const FunctionData &other_p) const override {\n+\t\tauto &other = other_p.Cast<ListLambdaBindData>();\n+\t\treturn Expression::Equals(lambda_expr, other.lambda_expr) && return_type == other.return_type &&\n+\t\t       has_index == other.has_index;\n+\t}\n \n \t//! Serializes a lambda function's bind data\n \tstatic void Serialize(Serializer &serializer, const optional_ptr<FunctionData> bind_data_p,\ndiff --git a/src/include/duckdb/main/capi/header_generation/header_base.hpp.template b/src/include/duckdb/main/capi/header_generation/header_base.hpp.template\nindex 042a0d2357b9..d9879eaa1fbe 100644\n--- a/src/include/duckdb/main/capi/header_generation/header_base.hpp.template\n+++ b/src/include/duckdb/main/capi/header_generation/header_base.hpp.template\n@@ -7,20 +7,19 @@\n \n #pragma once\n \n-//! duplicate of duckdb/main/winapi.hpp\n-#ifndef DUCKDB_API\n+#ifndef DUCKDB_C_API\n #ifdef _WIN32\n #ifdef DUCKDB_STATIC_BUILD\n-#define DUCKDB_API\n+#define DUCKDB_C_API\n #else\n #if defined(DUCKDB_BUILD_LIBRARY) && !defined(DUCKDB_BUILD_LOADABLE_EXTENSION)\n-#define DUCKDB_API __declspec(dllexport)\n+#define DUCKDB_C_API __declspec(dllexport)\n #else\n-#define DUCKDB_API __declspec(dllimport)\n+#define DUCKDB_C_API __declspec(dllimport)\n #endif\n #endif\n #else\n-#define DUCKDB_API\n+#define DUCKDB_C_API\n #endif\n #endif\n \ndiff --git a/src/include/duckdb/main/extension_entries.hpp b/src/include/duckdb/main/extension_entries.hpp\nindex 40d3429c529b..1e6ab3f90acb 100644\n--- a/src/include/duckdb/main/extension_entries.hpp\n+++ b/src/include/duckdb/main/extension_entries.hpp\n@@ -651,13 +651,15 @@ static constexpr ExtensionFunctionEntry EXTENSION_FUNCTIONS[] = {\n     {\"st_zmax\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_zmflag\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_zmin\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n-    {\"start_ui\", \"motherduck\", CatalogType::TABLE_FUNCTION_ENTRY},\n+    {\"start_ui\", \"ui\", CatalogType::TABLE_FUNCTION_ENTRY},\n+    {\"start_ui_server\", \"ui\", CatalogType::TABLE_FUNCTION_ENTRY},\n     {\"starts_with\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"stats\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"stddev\", \"core_functions\", CatalogType::AGGREGATE_FUNCTION_ENTRY},\n     {\"stddev_pop\", \"core_functions\", CatalogType::AGGREGATE_FUNCTION_ENTRY},\n     {\"stddev_samp\", \"core_functions\", CatalogType::AGGREGATE_FUNCTION_ENTRY},\n     {\"stem\", \"fts\", CatalogType::SCALAR_FUNCTION_ENTRY},\n+    {\"stop_ui_server\", \"ui\", CatalogType::TABLE_FUNCTION_ENTRY},\n     {\"string_agg\", \"core_functions\", CatalogType::AGGREGATE_FUNCTION_ENTRY},\n     {\"strpos\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"struct_insert\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n@@ -701,6 +703,7 @@ static constexpr ExtensionFunctionEntry EXTENSION_FUNCTIONS[] = {\n     {\"trunc\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"txid_current\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"typeof\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n+    {\"ui_is_started\", \"ui\", CatalogType::TABLE_FUNCTION_ENTRY},\n     {\"unbin\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"unhex\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"unicode\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n@@ -989,6 +992,9 @@ static constexpr ExtensionEntry EXTENSION_SETTINGS[] = {\n     {\"sqlite_all_varchar\", \"sqlite_scanner\"},\n     {\"sqlite_debug_show_queries\", \"sqlite_scanner\"},\n     {\"timezone\", \"icu\"},\n+    {\"ui_local_port\", \"ui\"},\n+    {\"ui_polling_interval\", \"ui\"},\n+    {\"ui_remote_url\", \"ui\"},\n     {\"unsafe_enable_version_guessing\", \"iceberg\"},\n }; // END_OF_EXTENSION_SETTINGS\n \n@@ -1076,10 +1082,16 @@ static constexpr ExtensionEntry EXTENSION_SECRET_PROVIDERS[] = {\n     {\"mysql/config\", \"mysql_scanner\"},\n     {\"postgres/config\", \"postgres_scanner\"}}; // EXTENSION_SECRET_PROVIDERS\n \n-static constexpr const char *AUTOLOADABLE_EXTENSIONS[] = {\n-    \"aws\",        \"azure\",         \"autocomplete\", \"core_functions\", \"delta\",    \"excel\",\n-    \"fts\",        \"httpfs\",        \"iceberg\",      \"inet\",           \"icu\",      \"json\",\n-    \"motherduck\", \"mysql_scanner\", \"parquet\",      \"sqlite_scanner\", \"sqlsmith\", \"postgres_scanner\",\n-    \"tpcds\",      \"tpch\",          \"uc_catalog\"}; // END_OF_AUTOLOADABLE_EXTENSIONS\n+static constexpr const char *AUTOLOADABLE_EXTENSIONS[] = {\"aws\",          \"azure\",\n+                                                          \"autocomplete\", \"core_functions\",\n+                                                          \"delta\",        \"excel\",\n+                                                          \"fts\",          \"httpfs\",\n+                                                          \"iceberg\",      \"inet\",\n+                                                          \"icu\",          \"json\",\n+                                                          \"motherduck\",   \"mysql_scanner\",\n+                                                          \"parquet\",      \"sqlite_scanner\",\n+                                                          \"sqlsmith\",     \"postgres_scanner\",\n+                                                          \"tpcds\",        \"tpch\",\n+                                                          \"uc_catalog\",   \"ui\"}; // END_OF_AUTOLOADABLE_EXTENSIONS\n \n } // namespace duckdb\ndiff --git a/src/include/duckdb/planner/expression/bound_subquery_expression.hpp b/src/include/duckdb/planner/expression/bound_subquery_expression.hpp\nindex 31501dd8cfd0..aa07a67b9305 100644\n--- a/src/include/duckdb/planner/expression/bound_subquery_expression.hpp\n+++ b/src/include/duckdb/planner/expression/bound_subquery_expression.hpp\n@@ -40,7 +40,7 @@ class BoundSubqueryExpression : public Expression {\n \tvector<LogicalType> child_types;\n \t//! The target LogicalType of the subquery result (i.e. to which type it should be casted, if child_type <>\n \t//! child_target). Only used for ANY expressions.\n-\tLogicalType child_target;\n+\tvector<LogicalType> child_targets;\n \n public:\n \tbool HasSubquery() const override {\ndiff --git a/src/main/extension/extension_helper.cpp b/src/main/extension/extension_helper.cpp\nindex f42d43aa8571..1088f0f135dd 100644\n--- a/src/main/extension/extension_helper.cpp\n+++ b/src/main/extension/extension_helper.cpp\n@@ -121,6 +121,7 @@ static const DefaultExtension internal_extensions[] = {\n     {\"vss\", \"Adds indexing support to accelerate Vector Similarity Search\", false},\n     {\"delta\", \"Adds support for Delta Lake\", false},\n     {\"fts\", \"Adds support for Full-Text Search Indexes\", false},\n+    {\"ui\", \"Adds local UI for DuckDB\", false},\n     {nullptr, nullptr, false}};\n \n idx_t ExtensionHelper::DefaultExtensionCount() {\n@@ -139,7 +140,8 @@ DefaultExtension ExtensionHelper::GetDefaultExtension(idx_t index) {\n // Allow Auto-Install Extensions\n //===--------------------------------------------------------------------===//\n static const char *const auto_install[] = {\"motherduck\", \"postgres_scanner\", \"mysql_scanner\", \"sqlite_scanner\",\n-                                           \"delta\",      \"iceberg\",          \"uc_catalog\",    nullptr};\n+                                           \"delta\",      \"iceberg\",          \"uc_catalog\",    \"ui\",\n+                                           nullptr};\n \n // TODO: unify with new autoload mechanism\n bool ExtensionHelper::AllowAutoInstall(const string &extension) {\ndiff --git a/src/main/extension/extension_load.cpp b/src/main/extension/extension_load.cpp\nindex 5499665f1a27..6e4bb1879685 100644\n--- a/src/main/extension/extension_load.cpp\n+++ b/src/main/extension/extension_load.cpp\n@@ -123,8 +123,9 @@ struct ExtensionAccess {\n \t\t\tload_state.has_error = true;\n \t\t\tload_state.error_data =\n \t\t\t    ErrorData(ExceptionType::UNKNOWN_TYPE,\n-\t\t\t              StringUtil::Format(\"Unknown ABI Type '%s' found when loading extension '%s'\",\n-\t\t\t                                 load_state.init_result.abi_type, load_state.init_result.filename));\n+\t\t\t              StringUtil::Format(\"Unknown ABI Type of value '%d' found when loading extension '%s'\",\n+\t\t\t                                 static_cast<uint8_t>(load_state.init_result.abi_type),\n+\t\t\t                                 load_state.init_result.filename));\n \t\t\treturn nullptr;\n \t\t}\n \n@@ -588,7 +589,8 @@ void ExtensionHelper::LoadExternalExtension(DatabaseInstance &db, FileSystem &fs\n \t\treturn;\n \t}\n \n-\tthrow IOException(\"Unknown ABI type '%s' for extension '%s'\", extension_init_result.abi_type, extension);\n+\tthrow IOException(\"Unknown ABI type of value '%s' for extension '%s'\",\n+\t                  static_cast<uint8_t>(extension_init_result.abi_type), extension);\n #endif\n }\n \ndiff --git a/src/planner/binder/expression/bind_subquery_expression.cpp b/src/planner/binder/expression/bind_subquery_expression.cpp\nindex 45dc31a3326e..d413c88ed9e8 100644\n--- a/src/planner/binder/expression/bind_subquery_expression.cpp\n+++ b/src/planner/binder/expression/bind_subquery_expression.cpp\n@@ -153,7 +153,7 @@ BindResult ExpressionBinder::BindExpression(SubqueryExpression &expr, idx_t dept\n \t\t\t}\n \t\t\tchild = BoundCastExpression::AddCastToType(context, std::move(child), compare_type);\n \t\t\tresult->child_types.push_back(subquery_type);\n-\t\t\tresult->child_target = compare_type;\n+\t\t\tresult->child_targets.push_back(compare_type);\n \t\t\tresult->children.push_back(std::move(child));\n \t\t}\n \t}\ndiff --git a/src/planner/binder/query_node/plan_subquery.cpp b/src/planner/binder/query_node/plan_subquery.cpp\nindex 1e1c06c1e22e..b938f1f65417 100644\n--- a/src/planner/binder/query_node/plan_subquery.cpp\n+++ b/src/planner/binder/query_node/plan_subquery.cpp\n@@ -168,7 +168,8 @@ static unique_ptr<Expression> PlanUncorrelatedSubquery(Binder &binder, BoundSubq\n \t\t\tcond.left = std::move(expr.children[child_idx]);\n \t\t\tauto &child_type = expr.child_types[child_idx];\n \t\t\tcond.right = BoundCastExpression::AddDefaultCastToType(\n-\t\t\t    make_uniq<BoundColumnRefExpression>(child_type, plan_columns[child_idx]), expr.child_target);\n+\t\t\t    make_uniq<BoundColumnRefExpression>(child_type, plan_columns[child_idx]),\n+\t\t\t    expr.child_targets[child_idx]);\n \t\t\tcond.comparison = expr.comparison_type;\n \t\t\tjoin->conditions.push_back(std::move(cond));\n \t\t}\n@@ -371,7 +372,8 @@ static unique_ptr<Expression> PlanCorrelatedSubquery(Binder &binder, BoundSubque\n \t\t\tcompare_cond.left = std::move(expr.children[child_idx]);\n \t\t\tauto &child_type = expr.child_types[child_idx];\n \t\t\tcompare_cond.right = BoundCastExpression::AddDefaultCastToType(\n-\t\t\t    make_uniq<BoundColumnRefExpression>(child_type, plan_columns[child_idx]), expr.child_target);\n+\t\t\t    make_uniq<BoundColumnRefExpression>(child_type, plan_columns[child_idx]),\n+\t\t\t    expr.child_targets[child_idx]);\n \t\t\tcompare_cond.comparison = expr.comparison_type;\n \t\t\tdelim_join->conditions.push_back(std::move(compare_cond));\n \t\t}\ndiff --git a/src/planner/binder/statement/bind_create.cpp b/src/planner/binder/statement/bind_create.cpp\nindex 9f91922cca5d..67408ca91fc4 100644\n--- a/src/planner/binder/statement/bind_create.cpp\n+++ b/src/planner/binder/statement/bind_create.cpp\n@@ -46,6 +46,7 @@\n namespace duckdb {\n \n void Binder::BindSchemaOrCatalog(ClientContext &context, string &catalog, string &schema) {\n+\tCatalogEntryRetriever retriever(context);\n \tif (catalog.empty() && !schema.empty()) {\n \t\t// schema is specified - but catalog is not\n \t\t// try searching for the catalog instead\n@@ -60,8 +61,12 @@ void Binder::BindSchemaOrCatalog(ClientContext &context, string &catalog, string\n \t\t\t\tcatalog_names.push_back(DatabaseManager::GetDefaultDatabase(context));\n \t\t\t}\n \t\t\tfor (auto &catalog_name : catalog_names) {\n-\t\t\t\tauto &catalog = Catalog::GetCatalog(context, catalog_name);\n-\t\t\t\tif (catalog.CheckAmbiguousCatalogOrSchema(context, schema)) {\n+\t\t\t\tauto catalog = Catalog::GetCatalogEntry(retriever, catalog_name);\n+\t\t\t\tif (!catalog) {\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tif (catalog->CheckAmbiguousCatalogOrSchema(context, schema)) {\n+\n \t\t\t\t\tthrow BinderException(\n \t\t\t\t\t    \"Ambiguous reference to catalog or schema \\\"%s\\\" - use a fully qualified path like \\\"%s.%s\\\"\",\n \t\t\t\t\t    schema, catalog_name, schema);\ndiff --git a/src/storage/storage_info.cpp b/src/storage/storage_info.cpp\nindex 7083f66aec65..66c609a7073c 100644\n--- a/src/storage/storage_info.cpp\n+++ b/src/storage/storage_info.cpp\n@@ -77,6 +77,7 @@ static const StorageVersionInfo storage_version_info[] = {\n \t{\"v1.1.2\", 64},\n \t{\"v1.1.3\", 64},\n \t{\"v1.2.0\", 65},\n+\t{\"v1.2.1\", 65},\n \t{nullptr, 0}\n };\n // END OF STORAGE VERSION INFO\n@@ -96,6 +97,7 @@ static const SerializationVersionInfo serialization_version_info[] = {\n \t{\"v1.1.2\", 3},\n \t{\"v1.1.3\", 3},\n \t{\"v1.2.0\", 4},\n+\t{\"v1.2.1\", 4},\n \t{\"latest\", 4},\n \t{nullptr, 0}\n };\ndiff --git a/src/storage/version_map.json b/src/storage/version_map.json\nindex e6a73162da40..4a77e7187067 100644\n--- a/src/storage/version_map.json\n+++ b/src/storage/version_map.json\n@@ -49,7 +49,8 @@\n \t\t\"v1.1.1\": 64,\n \t\t\"v1.1.2\": 64,\n \t\t\"v1.1.3\": 64,\n-\t\t\"v1.2.0\": 65\n+\t\t\"v1.2.0\": 65,\n+\t\t\"v1.2.1\": 65\n \t},\n \t\"default\": 64\n },\n@@ -65,6 +66,7 @@\n \t\t\"v1.1.2\": 3,\n \t\t\"v1.1.3\": 3,\n \t\t\"v1.2.0\": 4,\n+\t\t\"v1.2.1\": 4,\n \t\t\"latest\": 4\n \t},\n \t\"default\": 1\ndiff --git a/tools/shell/shell.cpp b/tools/shell/shell.cpp\nindex 7fd3092bbea9..dd782ea65e9c 100644\n--- a/tools/shell/shell.cpp\n+++ b/tools/shell/shell.cpp\n@@ -3234,7 +3234,7 @@ MetadataResult SetColumnRendering(ShellState &state, const char **azArg, idx_t n\n }\n \n MetadataResult SetRowRendering(ShellState &state, const char **azArg, idx_t nArg) {\n-\tstate.columns = 1;\n+\tstate.columns = 0;\n \treturn MetadataResult::SUCCESS;\n }\n \n", "test_patch": "diff --git a/test/issues/general/test_16257.test_slow b/test/issues/general/test_16257.test_slow\nindex 6b3faf9a7ba4..df2a3ed75f9c 100644\n--- a/test/issues/general/test_16257.test_slow\n+++ b/test/issues/general/test_16257.test_slow\n@@ -21,5 +21,6 @@ CREATE OR REPLACE MACRO lorem_sentence(rand, words) AS lorem_sentence_util(list_\n statement ok\n SET preserve_insertion_order=false;\n \n+# added NULLs for issue #16306\n statement ok\n-COPY (SELECT lorem_sentence(random(), 20) FROM range(1_000_000)) TO '__TEST_DIR__/16257.parquet' (PARQUET_VERSION V2, ROW_GROUP_SIZE 2_000_000);\n+COPY (SELECT CASE WHEN random() < 0.01 THEN NULL ELSE lorem_sentence(random(), 20) END FROM range(1_000_000)) TO '__TEST_DIR__/16257.parquet' (PARQUET_VERSION V2, ROW_GROUP_SIZE 2_000_000);\ndiff --git a/test/sql/attach/attach_storage_version.test b/test/sql/attach/attach_storage_version.test\nindex 5115a597869d..7dcd4c338c8c 100644\n--- a/test/sql/attach/attach_storage_version.test\n+++ b/test/sql/attach/attach_storage_version.test\n@@ -14,7 +14,7 @@ ATTACH '__TEST_DIR__/version_1_2_0.db' (STORAGE_VERSION 'v1.2.0');\n query I\n SELECT tags['storage_version'] FROM duckdb_databases() WHERE database_name='version_1_2_0'\n ----\n-v1.2.0\n+v1.2.0 - v1.2.1\n \n statement ok\n DETACH version_1_2_0\n@@ -38,7 +38,7 @@ ATTACH '__TEST_DIR__/version_1_2_0.db' (STORAGE_VERSION 'v1.2.0');\n query I\n SELECT tags['storage_version'] FROM duckdb_databases() WHERE database_name='version_1_2_0'\n ----\n-v1.2.0\n+v1.2.0 - v1.2.1\n \n statement ok\n DETACH version_1_2_0\n@@ -51,7 +51,7 @@ ATTACH '__TEST_DIR__/version_1_2_0.db';\n query I\n SELECT tags['storage_version'] FROM duckdb_databases() WHERE database_name='version_1_2_0'\n ----\n-v1.2.0\n+v1.2.0 - v1.2.1\n \n statement ok\n DETACH version_1_2_0\n@@ -83,7 +83,7 @@ ATTACH '__TEST_DIR__/default_version.db' (STORAGE_VERSION 'v1.2.0');\n query I\n SELECT tags['storage_version'] FROM duckdb_databases() WHERE database_name='default_version'\n ----\n-v1.2.0\n+v1.2.0 - v1.2.1\n \n statement ok\n SET force_compression = 'zstd';\n@@ -105,7 +105,7 @@ ATTACH '__TEST_DIR__/default_version.db'\n query I\n SELECT tags['storage_version'] FROM duckdb_databases() WHERE database_name='default_version'\n ----\n-v1.2.0\n+v1.2.0 - v1.2.1\n \n query I\n FROM default_version.tbl\n@@ -151,4 +151,4 @@ ATTACH '__TEST_DIR__/modified_default_setting.db';\n query I\n SELECT tags['storage_version'] FROM duckdb_databases() WHERE database_name='modified_default_setting'\n ----\n-v1.2.0\n+v1.2.0 - v1.2.1\ndiff --git a/test/sql/attach/attach_wal_alter_sequence.test b/test/sql/attach/attach_wal_alter_sequence.test\nnew file mode 100644\nindex 000000000000..eb65f613b8c1\n--- /dev/null\n+++ b/test/sql/attach/attach_wal_alter_sequence.test\n@@ -0,0 +1,52 @@\n+# name: test/sql/attach/attach_wal_alter_sequence.test\n+# description: Test binding of a WAL with a sequence entry in it\n+# group: [attach]\n+\n+require skip_reload\n+\n+statement ok\n+PRAGMA disable_checkpoint_on_shutdown\n+\n+statement ok\n+PRAGMA wal_autocheckpoint='1TB';\n+\n+# create a table with hugeints\n+statement ok\n+attach '__TEST_DIR__/attach_wal_with_sequence.db' as db1;\n+\n+statement ok\n+CREATE SEQUENCE db1.seq;\n+\n+statement ok\n+CREATE TABLE db1.test (a INTEGER DEFAULT nextval('seq'), b INTEGER, c INTEGER DEFAULT currval('seq'));\n+\n+statement ok\n+INSERT INTO db1.test (b) VALUES (1);\n+\n+statement ok\n+alter table db1.test RENAME TO blubb;\n+\n+statement ok\n+INSERT INTO db1.blubb (b) VALUES (10);\n+\n+query III\n+SELECT * FROM db1.blubb\n+----\n+1\t1\t1\n+2\t10\t2\n+\n+statement ok\n+DETACH db1\n+\n+statement ok\n+attach '__TEST_DIR__/attach_wal_with_sequence.db' as db2;\n+\n+statement ok\n+INSERT INTO db2.blubb (b) VALUES (100);\n+\n+query III\n+SELECT * FROM db2.blubb\n+----\n+1\t1\t1\n+2\t10\t2\n+3\t100\t3\ndiff --git a/test/sql/catalog/test_querying_from_detached_catalog.test b/test/sql/catalog/test_querying_from_detached_catalog.test\nnew file mode 100644\nindex 000000000000..57e500291470\n--- /dev/null\n+++ b/test/sql/catalog/test_querying_from_detached_catalog.test\n@@ -0,0 +1,72 @@\n+# name: test/sql/catalog/test_querying_from_detached_catalog.test\n+# description: Test switching from detached catalog to another catalog\n+# group: [catalog]\n+\n+require skip_reload\n+\n+statement ok con1\n+ATTACH ':memory:' AS db1;\n+\n+statement ok con1\n+ATTACH ':memory:' AS db2;\n+\n+statement ok con1\n+CREATE TABLE db2.tbl (i INTEGER, j INTEGER);\n+\n+statement ok con1\n+INSERT INTO db2.tbl VALUES (1, 2), (3,4);\n+\n+statement ok con1\n+USE db1;\n+\n+query I con1\n+SELECT CURRENT_SETTING('search_path');\n+----\n+db1.main\n+\n+statement ok con2\n+USE db2;\n+\n+# drop catalog db1, which con1 is using\n+statement ok con2\n+DETACH db1;\n+\n+# querying to an attached catalog should work (with non-fully qualified name)\n+query II con1\n+FROM db2.tbl;\n+----\n+1\t2\n+3\t4\n+\n+# querying to an attached catalog should work (with fully qualified name)\n+query II con1\n+FROM db2.main.tbl;\n+----\n+1\t2\n+3\t4\n+\n+# creating a new table in db2 works\n+statement ok con1\n+CREATE TABLE db2.tbl2 AS SELECT 42;\n+\n+# error message should say that the table does not exist\n+statement error con1\n+FROM db2.non_existent_table;\n+----\n+Catalog Error: Table with name non_existent_table does not exist!\n+\n+# querying within the detached catalog fails\n+statement error con1\n+SHOW TABLES;\n+----\n+Binder Error: Catalog \"db1\" does not exist!\n+\n+# swithcing to another catalog should work\n+statement ok con1\n+USE db2;\n+\n+query I con1\n+SELECT CURRENT_SETTING('search_path');\n+----\n+db2.main\n+\ndiff --git a/test/sql/catalog/test_switching_from_detached_catalog.test b/test/sql/catalog/test_switching_from_detached_catalog.test\ndeleted file mode 100644\nindex 89111a05bda7..000000000000\n--- a/test/sql/catalog/test_switching_from_detached_catalog.test\n+++ /dev/null\n@@ -1,42 +0,0 @@\n-# name: test/sql/catalog/test_switching_from_detached_catalog.test\n-# description: Test switching from detached catalog to another catalog\n-# group: [catalog]\n-\n-require skip_reload\n-\n-statement ok con1\n-ATTACH ':memory:' AS db1;\n-\n-statement ok con1\n-ATTACH ':memory:' AS db2;\n-\n-statement ok con1\n-USE db1;\n-\n-query I con1\n-SELECT CURRENT_SETTING('search_path');\n-----\n-db1.main\n-\n-statement ok con2\n-USE db2;\n-\n-# drop catalog db1, which con1 is using\n-statement ok con2\n-DETACH db1;\n-\n-# querying within the detached catalog fails\n-statement error con1\n-SHOW TABLES;\n-----\n-Binder Error: Catalog \"db1\" does not exist!\n-\n-# swithcing to another catalog should work\n-statement ok con1\n-USE db2;\n-\n-query I con1\n-SELECT CURRENT_SETTING('search_path');\n-----\n-db2.main\n-\ndiff --git a/test/sql/constraints/foreignkey/test_fk_eager_constraint_checking.test b/test/sql/constraints/foreignkey/test_fk_eager_constraint_checking.test\nnew file mode 100644\nindex 000000000000..4b0b230a27be\n--- /dev/null\n+++ b/test/sql/constraints/foreignkey/test_fk_eager_constraint_checking.test\n@@ -0,0 +1,56 @@\n+# name: test/sql/constraints/foreignkey/test_fk_eager_constraint_checking.test\n+# description: Test over-eager constraint checking for foreign keys.\n+# group: [foreignkey]\n+\n+require noforcestorage\n+\n+require skip_reload\n+\n+statement ok\n+PRAGMA enable_verification;\n+\n+statement ok\n+SET storage_compatibility_version = 'v0.10.3';\n+\n+statement ok\n+ATTACH '__TEST_DIR__/test_fk_eager.db' AS fk_db;\n+\n+statement ok\n+USE fk_db;\n+\n+# We need a PK table with a column not supporting in-place updates.\n+statement ok\n+CREATE TABLE tbl_pk (i INT PRIMARY KEY, payload STRUCT(v VARCHAR, i INTEGER[]));\n+\n+# Let's insert two rows.\n+statement ok\n+INSERT INTO tbl_pk VALUES (1, {'v': 'hello', 'i': [42]}), (2, {'v': 'world', 'i': [43]});\n+\n+# Now, we need a FK table.\n+statement ok\n+CREATE TABLE tbl_fk (i INT REFERENCES tbl_pk(i));\n+\n+# Let's insert rows so that has the FK table has a nested leaf with more than two row IDs.\n+statement ok\n+INSERT INTO tbl_fk VALUES (1), (1), (1);\n+\n+statement ok\n+USE memory;\n+\n+# We also want the old LEAF representation serialized.\n+statement ok\n+CHECKPOINT fk_db;\n+\n+statement ok\n+DETACH fk_db;\n+\n+statement ok\n+ATTACH '__TEST_DIR__/test_fk_eager.db' AS fk_db;\n+\n+# Now, we try to update the PK table.\n+# The over-eager constraint checking fix is not yet supported for FKs, thus, we throw a constraint violation.\n+statement error\n+UPDATE fk_db.tbl_pk SET payload = {'v': 'new hello', 'i': [7]} WHERE i = 1;\n+----\n+<REGEX>:Constraint Error.*Violates foreign key constraint because.*\n+\ndiff --git a/test/sql/copy/csv/test_read_csv.test b/test/sql/copy/csv/test_read_csv.test\nindex 7f28bdec02cc..e54ecbd33efb 100644\n--- a/test/sql/copy/csv/test_read_csv.test\n+++ b/test/sql/copy/csv/test_read_csv.test\n@@ -5,6 +5,17 @@\n statement ok\n PRAGMA enable_verification\n \n+query II\n+FROM read_csv('data/csv/multi_quote.csv', null_padding = true)\n+----\n+2019-01-01\ttext\n+2019-02-01\ttext\n+2019-03-01\ttext\n+2019-04-01\ttext\n+2019-05-01\ttext\n+2019-06-01\ttext, with comma\n+2019-09-01\t'text'\n+\n query II\n FROM read_csv('data/csv/bad_escape.csv')\n ----\ndiff --git a/test/sql/copy/csv/test_sniff_csv.test b/test/sql/copy/csv/test_sniff_csv.test\nindex d94967405e8d..9bdb7a19ac8f 100644\n--- a/test/sql/copy/csv/test_sniff_csv.test\n+++ b/test/sql/copy/csv/test_sniff_csv.test\n@@ -8,6 +8,11 @@ PRAGMA enable_verification\n # requires notwindows because tests will return \\r\\n to be used in the parameters\n require notwindows\n \n+query III\n+SELECT escape,quote, delimiter from sniff_csv('data/csv/later_quotes.csv');\n+----\n+\"\t\"\t,\n+\n query I\n SELECT Prompt FROM sniff_csv('data/csv/real/lineitem_sample.csv');\n ----\ndiff --git a/test/sql/copy/return_files.test b/test/sql/copy/return_files.test\nindex 8c815bc4e9db..984c0652394d 100644\n--- a/test/sql/copy/return_files.test\n+++ b/test/sql/copy/return_files.test\n@@ -26,10 +26,12 @@ COPY integers TO '__TEST_DIR__/test_batch_copy_to_file.parquet' (RETURN_FILES TR\n statement ok\n SET threads=2;\n \n+# as mentioned in per_thread_output.test, the number of files do not necessarily match the number of threads\n+# here, we check if the number of rows are correct and at least one file has been written.\n query II\n COPY integers TO '__TEST_DIR__/test_per_thread_output' (RETURN_FILES, PER_THREAD_OUTPUT);\n ----\n-200000\t<REGEX>:.*data_0.csv.*data_1.csv.*\n+200000\t<REGEX>:.*data_0.csv.*\n \n require notwindows\n \ndiff --git a/test/sql/function/timestamp/test_icu_strptime.test b/test/sql/function/timestamp/test_icu_strptime.test\nindex d54eaa58594d..4b0902763032 100644\n--- a/test/sql/function/timestamp/test_icu_strptime.test\n+++ b/test/sql/function/timestamp/test_icu_strptime.test\n@@ -589,3 +589,9 @@ statement error\n SELECT TIMESTAMPTZ '294247-01-10 04:00:54.7758';\n ----\n Conversion Error: ICU date overflows timestamp range\n+\n+# Invalid time zones should produce NULL, not an error\n+query I\n+select try_strptime('2015-01-05 00:00:00 FNORD', '%Y-%m-%d %H:%M:%S %Z');\n+----\n+NULL\ndiff --git a/test/sql/storage/storage_version_65.test b/test/sql/storage/storage_version_65.test\nindex 3e9323ce8672..fcded07a9ce5 100644\n--- a/test/sql/storage/storage_version_65.test\n+++ b/test/sql/storage/storage_version_65.test\n@@ -17,7 +17,7 @@ ATTACH '__TEST_DIR__/storage_versions65.db'\n query I\n SELECT tags FROM duckdb_databases() WHERE database_name = 'storage_versions65';\n ----\n-{storage_version=v1.2.0}\n+{storage_version=v1.2.0 - v1.2.1}\n \n statement ok\n set storage_compatibility_version='v0.10.2'\ndiff --git a/test/sql/storage/storage_versions.test b/test/sql/storage/storage_versions.test\nindex 63be1b8b7623..113e61302493 100644\n--- a/test/sql/storage/storage_versions.test\n+++ b/test/sql/storage/storage_versions.test\n@@ -24,4 +24,4 @@ query I\n SELECT tags FROM duckdb_databases() WHERE database_name LIKE 'empty%' ORDER BY database_name;\n ----\n {storage_version=v1.0.0 - v1.1.3}\n-{storage_version=v1.2.0}\n+{storage_version=v1.2.0 - v1.2.1}\ndiff --git a/test/sql/subquery/scalar/subquery_row_in_any.test b/test/sql/subquery/scalar/subquery_row_in_any.test\nindex f0f700097beb..096f783fc9aa 100644\n--- a/test/sql/subquery/scalar/subquery_row_in_any.test\n+++ b/test/sql/subquery/scalar/subquery_row_in_any.test\n@@ -13,6 +13,12 @@ SELECT (1, 2) IN (SELECT i, i + 1 FROM integers)\n ----\n true\n \n+# mixed types\n+query I\n+SELECT (date '1992-01-02', 2) IN (SELECT date '1992-01-01' + interval (i) days, i + 1 FROM integers)\n+----\n+true\n+\n # it still works with the row inside the subquery\n query I\n SELECT (1, 2) IN (SELECT (i, i + 1) FROM integers)\ndiff --git a/test/sql/window/test_custom_spooling.test_slow b/test/sql/window/test_custom_spooling.test_slow\nindex f6d2fd9e0fd9..c8c64cfb6a74 100644\n--- a/test/sql/window/test_custom_spooling.test_slow\n+++ b/test/sql/window/test_custom_spooling.test_slow\n@@ -14,6 +14,10 @@ PRAGMA temp_directory='__TEST_DIR__/window_spooling'\n statement ok\n PRAGMA memory_limit='50MB'\n \n+# Limit threads to improve stability\n+statement ok\n+PRAGMA threads=4;\n+\n statement ok\n PRAGMA enable_verification\n \n@@ -25,13 +29,13 @@ FROM (\n \t\tSUM(l_extendedprice) OVER w AS s,\n \t\tQUANTILE(l_extendedprice, 0.5) OVER w AS q,\n \t\tMAD(l_extendedprice) OVER w AS m,\n-\t\tMODE(l_quantity) OVER w AS d,\n+\t\tMODE(l_linenumber) OVER w AS d,\n \tFROM lineitem\n \tWINDOW w AS (\n-\t\tPARTITION BY (l_linenumber = 1) \n-\t\tORDER BY l_orderkey, l_linenumber \n+\t\tPARTITION BY l_suppkey \n+\t\tORDER BY l_shipdate, l_orderkey, l_linenumber\n \t\tROWS BETWEEN 20 PRECEDING AND 20 FOLLOWING\n \t)\n ) t;\n ----\n-886221884732.62\t20709502135.61\t9898471727.97\t15330000\n+871183083803.67\t20718441622.70\t9873496927.55\t1050000.0\n", "problem_statement": "CLI \".rows\" switches to columns view (same as \".columns\")\n### What happens?\n\nUsing `.rows` in the CLI switches to columns mode (the same behavior as `.columns`) instead of switching to the default, expected behavior.\n\n### To Reproduce\n\nMinimal reproducer (Using a new DuckDB CLI session):\n```\n.rows\nFROM VALUES (1,2,3), (4,5,6) AS t(a,b,c);\n```\n\nA bit more explanatory of a typical use-case (Using a new DuckDB CLI session):\n```\n-- Default behavior (row-wise)\nFROM VALUES (1,2,3), (4,5,6) AS t(a,b,c);\n-- Observe bug: explicitly set to row-wise (this fails by going to columns instead)\n.rows\nFROM VALUES (1,2,3), (4,5,6) AS t(a,b,c);\n-- Switch to columns (nothing changes) then try to switch back (also doesn't work)\n.columns\nFROM VALUES (1,2,3), (4,5,6) AS t(a,b,c);\n.rows\nFROM VALUES (1,2,3), (4,5,6) AS t(a,b,c);\n```\n\n\n### OS:\n\nOSX 15.3 aarch64 and Ubuntu 22.04 x86_64\n\n### DuckDB Version:\n\n1.2.0\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nTeague Sterling\n\n### Affiliation:\n\n23andMe\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNot applicable - the reproduction does not require a data set\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nwrong format specifier used when loading extension with bad header\n### What happens?\n\nWrong format specifier for unknown extension ABI, is `%s` should be `%d` (or have the enum be formatted manually)\n\n### To Reproduce\n\nI have not added any reproducing code, since I do not think it is important\n\n### OS:\n\nlinux\n\n### DuckDB Version:\n\nsource\n\n### DuckDB Client:\n\ncli\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nJA\n\n### Affiliation:\n\nnone\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a source build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNo - Other reason (please specify in the issue body)\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "\nhttps://github.com/duckdb/duckdb/blob/9c133491ada57fcc588d867d66ec815814f69c8c/src/main/extension/extension_load.cpp#L125-L130\nNice catch, I didn't think there would be multiple, but I was originally referring to https://github.com/duckdb/duckdb/blob/9c133491ada57fcc588d867d66ec815814f69c8c/src/main/extension/extension_load.cpp#L594", "created_at": "2025-02-27T06:56:54Z"}
{"repo": "duckdb/duckdb", "pull_number": 16380, "instance_id": "duckdb__duckdb-16380", "issue_numbers": ["16340"], "base_commit": "7c5028689dc1f5ed033445c6e5875c3b7b878f47", "patch": "diff --git a/src/function/scalar/string/regexp.cpp b/src/function/scalar/string/regexp.cpp\nindex 2383e3b578a0..f91121a075ea 100644\n--- a/src/function/scalar/string/regexp.cpp\n+++ b/src/function/scalar/string/regexp.cpp\n@@ -186,6 +186,9 @@ static void RegexReplaceFunction(DataChunk &args, ExpressionState &state, Vector\n \t\tTernaryExecutor::Execute<string_t, string_t, string_t, string_t>(\n \t\t    strings, patterns, replaces, result, args.size(), [&](string_t input, string_t pattern, string_t replace) {\n \t\t\t    RE2 re(CreateStringPiece(pattern), info.options);\n+\t\t\t    if (!re.ok()) {\n+\t\t\t\t    throw InvalidInputException(re.error());\n+\t\t\t    }\n \t\t\t    std::string sstring = input.GetString();\n \t\t\t    if (info.global_replace) {\n \t\t\t\t    RE2::GlobalReplace(&sstring, re, CreateStringPiece(replace));\ndiff --git a/src/include/duckdb/function/scalar/regexp.hpp b/src/include/duckdb/function/scalar/regexp.hpp\nindex fa6a3e91f81a..5ac80ab089af 100644\n--- a/src/include/duckdb/function/scalar/regexp.hpp\n+++ b/src/include/duckdb/function/scalar/regexp.hpp\n@@ -140,6 +140,9 @@ struct RegexLocalState : public FunctionLocalState {\n \texplicit RegexLocalState(RegexpBaseBindData &info, bool extract_all = false)\n \t    : constant_pattern(duckdb_re2::StringPiece(info.constant_string.c_str(), info.constant_string.size()),\n \t                       info.options) {\n+\t\tif (!constant_pattern.ok()) {\n+\t\t\tthrow InvalidInputException(constant_pattern.error());\n+\t\t}\n \t\tif (extract_all) {\n \t\t\tauto group_count_p = constant_pattern.NumberOfCapturingGroups();\n \t\t\tif (group_count_p != -1) {\n", "test_patch": "diff --git a/test/sql/function/string/regex_extract_all.test b/test/sql/function/string/regex_extract_all.test\nindex 207ccf14e28c..f6102e448cde 100644\n--- a/test/sql/function/string/regex_extract_all.test\n+++ b/test/sql/function/string/regex_extract_all.test\n@@ -280,7 +280,7 @@ select regexp_extract_all('abc', '(a)(b)')\n statement error\n select regexp_extract_all('', '(')\n ----\n-Invalid Input Error: Pattern failed to parse, error: 'missing ): ('\n+Invalid Input Error: missing )\n \n query I\n select regexp_extract_all('abcdef', 'ac.*e.')\n@@ -546,7 +546,7 @@ FROM (\n   VALUES ('acd'), ('abcd'), ('abbcd'), ('abbbcd')\n ) AS t(str)\n ----\n-Invalid Input Error: Pattern failed to parse, error: 'bad repetition operator: ++'\n+Invalid Input Error: bad repetition operator: ++\n \n query IIIIIII\n SELECT\ndiff --git a/test/sql/function/string/regex_replace.test b/test/sql/function/string/regex_replace.test\nindex 1d8047c8bb53..b3474d27c3b9 100644\n--- a/test/sql/function/string/regex_replace.test\n+++ b/test/sql/function/string/regex_replace.test\n@@ -90,3 +90,32 @@ statement error\n SELECT regexp_replace('asdf', '.*SD.*', 'a', 'q')\n ----\n \n+# this used to fail as it should but lets make sure it still fails\n+statement error\n+select regexp_matches('abc', '*');\n+----\n+no argument for repetition operator: *\n+\n+# this used to silently swallow the error from the invalid regex\n+statement error\n+select regexp_replace('abc', '*', 'X');\n+----\n+no argument for repetition operator: *\n+\n+# make sure this also holds for non-constant case\n+statement ok\n+create table regex (s string, r string);\n+\n+statement ok\n+insert into regex values ('abc', '*');\n+\n+statement error\n+select regexp_matches(s, r) from regex;\n+----\n+no argument for repetition operator: *\n+\n+statement error\n+select regexp_replace(s, r, 'X') from regex;\n+----\n+no argument for repetition operator: *\n+\n", "problem_statement": "regexp_replace silently ignores errors in the regexp pattern\n### What happens?\n\n`regexp_replace` silently returns the original string if the regexp pattern contains errors.\nThis is not the case for ` regexp_matches`.\n\n### To Reproduce\n\n`regexp_replace` seems to ignore errors:\n```\nselect regexp_replace('abc', '*', 'X');\n```\nPostgres throws an error: \"invalid regular expression\"\nDuckDB returns `abc`\n\nBut `regexp_matches` properly throws errors:\n```\nselect regexp_matches('abc', '*');\n```\nDuckDB and Postgres both complain about the invalid regular expression.\n\n### OS:\n\nUbuntu\n\n### DuckDB Version:\n\nv1.2.1-dev629 d9ee15f45e\n\n### DuckDB Client:\n\nshell\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nAltan Birler\n\n### Affiliation:\n\nTUM\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a source build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "@szarnyasg could this be a good bug for a first contribute? I'd like to take a stab at it.", "created_at": "2025-02-24T13:43:45Z"}
{"repo": "duckdb/duckdb", "pull_number": 16324, "instance_id": "duckdb__duckdb-16324", "issue_numbers": ["16118", "16278", "16277", "16104"], "base_commit": "20009a22372f9f5e89057af1b07931f27341c260", "patch": "diff --git a/.github/actions/build_extensions/action.yml b/.github/actions/build_extensions/action.yml\nindex c98528ff6a6c..db05fd4c9dfb 100644\n--- a/.github/actions/build_extensions/action.yml\n+++ b/.github/actions/build_extensions/action.yml\n@@ -60,6 +60,9 @@ inputs:\n   build_out_of_tree_extensions:\n     description: 'Build out-of-tree extensions'\n     default: 1\n+  bundle_static_lib_mode:\n+    description: 'Build the default bundled extensions to publish the static libs'\n+    default: 0\n   osx_universal:\n     description: 'Build Universal Binary for OSX'\n     default: 0\n@@ -91,6 +94,7 @@ runs:\n     - name: Setup DuckDB extension build config\n       shell: bash\n       run: |\n+        export EXTENSION_CONFIGS=\"$EXTENSION_CONFIGS;${{ inputs.bundle_static_lib_mode == 1 && '.github/config/bundled_extensions.cmake' || ''}}\"\n         export EXTENSION_CONFIGS=\"$EXTENSION_CONFIGS;${{ inputs.build_in_tree_extensions == 1 && '.github/config/in_tree_extensions.cmake' || ''}}\"\n         export EXTENSION_CONFIGS=\"$EXTENSION_CONFIGS;${{ inputs.build_out_of_tree_extensions == 1 && '.github/config/out_of_tree_extensions.cmake' || '' }}\"\n         echo \"EXTENSION_CONFIGS=$EXTENSION_CONFIGS\" >> $GITHUB_ENV\ndiff --git a/.github/config/out_of_tree_extensions.cmake b/.github/config/out_of_tree_extensions.cmake\nindex e195db85681b..4aee4d773f9a 100644\n--- a/.github/config/out_of_tree_extensions.cmake\n+++ b/.github/config/out_of_tree_extensions.cmake\n@@ -64,7 +64,7 @@ endif()\n duckdb_extension_load(excel\n     LOAD_TESTS\n     GIT_URL https://github.com/duckdb/duckdb-excel\n-    GIT_TAG e243577956f36a898d5485189e5288839c2c4b73\n+    GIT_TAG 67a851738ec80e1f19148a3b37a25a83a5068195\n     INCLUDE_DIR src/excel/include\n     )\n \n@@ -110,7 +110,7 @@ if (NOT MINGW)\n duckdb_extension_load(spatial\n     DONT_LINK LOAD_TESTS\n     GIT_URL https://github.com/duckdb/duckdb-spatial\n-    GIT_TAG 79bf2b6f55db3bf7201f375662616663b4b0954a\n+    GIT_TAG 919c69fe47443b4eafbd883e2fcac0b2ec448725\n     INCLUDE_DIR spatial/include\n     TEST_DIR test/sql\n     )\ndiff --git a/.github/workflows/BundleStaticLibs.yml b/.github/workflows/BundleStaticLibs.yml\nindex 97acc0efebe9..87c878a6e90c 100644\n--- a/.github/workflows/BundleStaticLibs.yml\n+++ b/.github/workflows/BundleStaticLibs.yml\n@@ -106,6 +106,9 @@ jobs:\n   bundle-mingw-static-lib:\n     name: Windows MingW static libs\n     runs-on: windows-2019\n+    env:\n+      ENABLE_EXTENSION_AUTOLOADING: 1\n+      ENABLE_EXTENSION_AUTOINSTALL: 1\n     steps:\n       - uses: actions/checkout@v4\n         with:\n@@ -130,9 +133,12 @@ jobs:\n           override_cc: gcc\n           override_cxx: g++\n           vcpkg_build: 1\n-          no_static_linking: 1\n+          no_static_linking: 0\n           run_tests: 0\n           run_autoload_tests: 0\n+          build_in_tree_extensions: 0\n+          build_out_of_tree_extensions: 0\n+          bundle_static_lib_mode: 1\n \n       - name: Bundle static library\n         shell: bash\ndiff --git a/data/csv/bad_csv_file_2047.csv b/data/csv/bad_csv_file_2047.csv\nnew file mode 100644\nindex 000000000000..3e404b44ec43\n--- /dev/null\n+++ b/data/csv/bad_csv_file_2047.csv\n@@ -0,0 +1,2054 @@\n+\"Action\",\"column name 1\",\"column name 2\",\"column name 3\",\"column name 4\",\"column name 5\",\"column name 6\",\"column name 7\",\"column name 8\",\"column name 9\",\"column name 10\",\"column name 11\",\"column name 12\",\"column name 13\",\"column name 15\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"\"Unescaped quote and embedded, seperator\"\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n+\"U\",\"001\",\"ID00000001\",\"4211000\",\"HOME\",\"HOME\",\"1 address address\",\"address1\",\"address2\",\"address3\",\"\",\"SOMEVALUE\",\"ABC 0DE\",\"ZZ\",\"Country Name\"\n\\ No newline at end of file\ndiff --git a/extension/core_functions/aggregate/distributive/string_agg.cpp b/extension/core_functions/aggregate/distributive/string_agg.cpp\nindex b694a23656fa..cdbd9e003aa5 100644\n--- a/extension/core_functions/aggregate/distributive/string_agg.cpp\n+++ b/extension/core_functions/aggregate/distributive/string_agg.cpp\n@@ -44,14 +44,7 @@ struct StringAggFunction {\n \t\tif (!state.dataptr) {\n \t\t\tfinalize_data.ReturnNull();\n \t\t} else {\n-\t\t\ttarget = StringVector::AddString(finalize_data.result, state.dataptr, state.size);\n-\t\t}\n-\t}\n-\n-\ttemplate <class STATE>\n-\tstatic void Destroy(STATE &state, AggregateInputData &aggr_input_data) {\n-\t\tif (state.dataptr) {\n-\t\t\tdelete[] state.dataptr;\n+\t\t\ttarget = string_t(state.dataptr, state.size);\n \t\t}\n \t}\n \n@@ -59,12 +52,12 @@ struct StringAggFunction {\n \t\treturn true;\n \t}\n \n-\tstatic inline void PerformOperation(StringAggState &state, const char *str, const char *sep, idx_t str_size,\n-\t                                    idx_t sep_size) {\n+\tstatic inline void PerformOperation(StringAggState &state, ArenaAllocator &allocator, const char *str,\n+\t                                    const char *sep, idx_t str_size, idx_t sep_size) {\n \t\tif (!state.dataptr) {\n \t\t\t// first iteration: allocate space for the string and copy it into the state\n \t\t\tstate.alloc_size = MaxValue<idx_t>(8, NextPowerOfTwo(str_size));\n-\t\t\tstate.dataptr = new char[state.alloc_size];\n+\t\t\tstate.dataptr = char_ptr_cast(allocator.Allocate(state.alloc_size));\n \t\t\tstate.size = str_size;\n \t\t\tmemcpy(state.dataptr, str, str_size);\n \t\t} else {\n@@ -72,13 +65,12 @@ struct StringAggFunction {\n \t\t\tidx_t required_size = state.size + str_size + sep_size;\n \t\t\tif (required_size > state.alloc_size) {\n \t\t\t\t// no space! allocate extra space\n+\t\t\t\tconst auto old_size = state.alloc_size;\n \t\t\t\twhile (state.alloc_size < required_size) {\n \t\t\t\t\tstate.alloc_size *= 2;\n \t\t\t\t}\n-\t\t\t\tauto new_data = new char[state.alloc_size];\n-\t\t\t\tmemcpy(new_data, state.dataptr, state.size);\n-\t\t\t\tdelete[] state.dataptr;\n-\t\t\t\tstate.dataptr = new_data;\n+\t\t\t\tstate.dataptr =\n+\t\t\t\t    char_ptr_cast(allocator.Reallocate(data_ptr_cast(state.dataptr), old_size, state.alloc_size));\n \t\t\t}\n \t\t\t// copy the separator\n \t\t\tmemcpy(state.dataptr + state.size, sep, sep_size);\n@@ -89,14 +81,15 @@ struct StringAggFunction {\n \t\t}\n \t}\n \n-\tstatic inline void PerformOperation(StringAggState &state, string_t str, optional_ptr<FunctionData> data_p) {\n+\tstatic inline void PerformOperation(StringAggState &state, ArenaAllocator &allocator, string_t str,\n+\t                                    optional_ptr<FunctionData> data_p) {\n \t\tauto &data = data_p->Cast<StringAggBindData>();\n-\t\tPerformOperation(state, str.GetData(), data.sep.c_str(), str.GetSize(), data.sep.size());\n+\t\tPerformOperation(state, allocator, str.GetData(), data.sep.c_str(), str.GetSize(), data.sep.size());\n \t}\n \n \ttemplate <class INPUT_TYPE, class STATE, class OP>\n \tstatic void Operation(STATE &state, const INPUT_TYPE &input, AggregateUnaryInput &unary_input) {\n-\t\tPerformOperation(state, input, unary_input.input.bind_data);\n+\t\tPerformOperation(state, unary_input.input.allocator, input, unary_input.input.bind_data);\n \t}\n \n \ttemplate <class INPUT_TYPE, class STATE, class OP>\n@@ -113,8 +106,8 @@ struct StringAggFunction {\n \t\t\t// source is not set: skip combining\n \t\t\treturn;\n \t\t}\n-\t\tPerformOperation(target, string_t(source.dataptr, UnsafeNumericCast<uint32_t>(source.size)),\n-\t\t                 aggr_input_data.bind_data);\n+\t\tPerformOperation(target, aggr_input_data.allocator,\n+\t\t                 string_t(source.dataptr, UnsafeNumericCast<uint32_t>(source.size)), aggr_input_data.bind_data);\n \t}\n };\n \n@@ -162,8 +155,7 @@ AggregateFunctionSet StringAggFun::GetFunctions() {\n \t    AggregateFunction::UnaryScatterUpdate<StringAggState, string_t, StringAggFunction>,\n \t    AggregateFunction::StateCombine<StringAggState, StringAggFunction>,\n \t    AggregateFunction::StateFinalize<StringAggState, string_t, StringAggFunction>,\n-\t    AggregateFunction::UnaryUpdate<StringAggState, string_t, StringAggFunction>, StringAggBind,\n-\t    AggregateFunction::StateDestroy<StringAggState, StringAggFunction>);\n+\t    AggregateFunction::UnaryUpdate<StringAggState, string_t, StringAggFunction>, StringAggBind);\n \tstring_agg_param.serialize = StringAggSerialize;\n \tstring_agg_param.deserialize = StringAggDeserialize;\n \tstring_agg.AddFunction(string_agg_param);\ndiff --git a/extension/core_functions/aggregate/nested/list.cpp b/extension/core_functions/aggregate/nested/list.cpp\nindex 7b23987d6875..40a917eff7e8 100644\n--- a/extension/core_functions/aggregate/nested/list.cpp\n+++ b/extension/core_functions/aggregate/nested/list.cpp\n@@ -116,7 +116,6 @@ static void ListFinalize(Vector &states_vector, AggregateInputData &aggr_input_d\n \n \t// first iterate over all entries and set up the list entries, and get the newly required total length\n \tfor (idx_t i = 0; i < count; i++) {\n-\n \t\tauto &state = *states[states_data.sel->get_index(i)];\n \t\tconst auto rid = i + offset;\n \t\tresult_data[rid].offset = total_len;\ndiff --git a/extension/core_functions/scalar/list/list_aggregates.cpp b/extension/core_functions/scalar/list/list_aggregates.cpp\nindex 1b2aab71dca7..a5ce49eed759 100644\n--- a/extension/core_functions/scalar/list/list_aggregates.cpp\n+++ b/extension/core_functions/scalar/list/list_aggregates.cpp\n@@ -15,7 +15,17 @@\n \n namespace duckdb {\n \n-// FIXME: use a local state for each thread to increase performance?\n+struct ListAggregatesLocalState : public FunctionLocalState {\n+\texplicit ListAggregatesLocalState(Allocator &allocator) : arena_allocator(allocator) {\n+\t}\n+\n+\tArenaAllocator arena_allocator;\n+};\n+\n+unique_ptr<FunctionLocalState> ListAggregatesInitLocalState(ExpressionState &state, const BoundFunctionExpression &expr,\n+                                                            FunctionData *bind_data) {\n+\treturn make_uniq<ListAggregatesLocalState>(BufferAllocator::Get(state.GetContext()));\n+}\n // FIXME: benchmark the use of simple_update against using update (if applicable)\n \n static unique_ptr<FunctionData> ListAggregatesBindFailure(ScalarFunction &bound_function) {\n@@ -207,7 +217,8 @@ static void ListAggregatesFunction(DataChunk &args, ExpressionState &state, Vect\n \tauto &func_expr = state.expr.Cast<BoundFunctionExpression>();\n \tauto &info = func_expr.bind_info->Cast<ListAggregatesBindData>();\n \tauto &aggr = info.aggr_expr->Cast<BoundAggregateExpression>();\n-\tArenaAllocator allocator(Allocator::DefaultAllocator());\n+\tauto &allocator = ExecuteFunctionState::GetFunctionState(state)->Cast<ListAggregatesLocalState>().arena_allocator;\n+\tallocator.Reset();\n \tAggregateInputData aggr_input_data(aggr.bind_info.get(), allocator);\n \n \tD_ASSERT(aggr.function.update);\n@@ -511,8 +522,9 @@ static unique_ptr<FunctionData> ListUniqueBind(ClientContext &context, ScalarFun\n }\n \n ScalarFunction ListAggregateFun::GetFunction() {\n-\tauto result = ScalarFunction({LogicalType::LIST(LogicalType::ANY), LogicalType::VARCHAR}, LogicalType::ANY,\n-\t                             ListAggregateFunction, ListAggregateBind);\n+\tauto result =\n+\t    ScalarFunction({LogicalType::LIST(LogicalType::ANY), LogicalType::VARCHAR}, LogicalType::ANY,\n+\t                   ListAggregateFunction, ListAggregateBind, nullptr, nullptr, ListAggregatesInitLocalState);\n \tBaseScalarFunction::SetReturnsError(result);\n \tresult.null_handling = FunctionNullHandling::SPECIAL_HANDLING;\n \tresult.varargs = LogicalType::ANY;\n@@ -523,12 +535,12 @@ ScalarFunction ListAggregateFun::GetFunction() {\n \n ScalarFunction ListDistinctFun::GetFunction() {\n \treturn ScalarFunction({LogicalType::LIST(LogicalType::ANY)}, LogicalType::LIST(LogicalType::ANY),\n-\t                      ListDistinctFunction, ListDistinctBind);\n+\t                      ListDistinctFunction, ListDistinctBind, nullptr, nullptr, ListAggregatesInitLocalState);\n }\n \n ScalarFunction ListUniqueFun::GetFunction() {\n \treturn ScalarFunction({LogicalType::LIST(LogicalType::ANY)}, LogicalType::UBIGINT, ListUniqueFunction,\n-\t                      ListUniqueBind);\n+\t                      ListUniqueBind, nullptr, nullptr, ListAggregatesInitLocalState);\n }\n \n } // namespace duckdb\ndiff --git a/extension/json/buffered_json_reader.cpp b/extension/json/buffered_json_reader.cpp\nindex 68a830c7fd12..a57d375771c2 100644\n--- a/extension/json/buffered_json_reader.cpp\n+++ b/extension/json/buffered_json_reader.cpp\n@@ -92,7 +92,7 @@ void JSONFileHandle::ReadAtPosition(char *pointer, idx_t size, idx_t position, b\n \t\tauto &handle = override_handle ? *override_handle.get() : *file_handle.get();\n \t\tif (can_seek) {\n \t\t\thandle.Read(pointer, size, position);\n-\t\t} else if (sample_run) { // Cache the buffer\n+\t\t} else if (file_handle->IsPipe()) { // Cache the buffer\n \t\t\thandle.Read(pointer, size, position);\n \n \t\t\tcached_buffers.emplace_back(allocator.Allocate(size));\n@@ -128,7 +128,7 @@ bool JSONFileHandle::Read(char *pointer, idx_t &read_size, idx_t requested_size,\n \tif (can_seek) {\n \t\tread_size = ReadInternal(pointer, requested_size);\n \t\tread_position += read_size;\n-\t} else if (sample_run) { // Cache the buffer\n+\t} else if (file_handle->IsPipe()) { // Cache the buffer\n \t\tread_size = ReadInternal(pointer, requested_size);\n \t\tif (read_size > 0) {\n \t\t\tcached_buffers.emplace_back(allocator.Allocate(read_size));\ndiff --git a/extension/json/json_extension.cpp b/extension/json/json_extension.cpp\nindex e0665260a5bf..d609fd82ef68 100644\n--- a/extension/json/json_extension.cpp\n+++ b/extension/json/json_extension.cpp\n@@ -17,12 +17,17 @@\n namespace duckdb {\n \n static DefaultMacro json_macros[] = {\n-    {DEFAULT_SCHEMA, \"json_group_array\", {\"x\", nullptr}, {{nullptr, nullptr}}, \"to_json(list(x))\"},\n+    {DEFAULT_SCHEMA,\n+     \"json_group_array\",\n+     {\"x\", nullptr},\n+     {{nullptr, nullptr}},\n+     \"CAST('[' || string_agg(CASE WHEN x IS NULL THEN 'null'::JSON ELSE to_json(x) END, ',') || ']' AS JSON)\"},\n     {DEFAULT_SCHEMA,\n      \"json_group_object\",\n-     {\"name\", \"value\", nullptr},\n+     {\"n\", \"v\", nullptr},\n      {{nullptr, nullptr}},\n-     \"to_json(map(list(name), list(value)))\"},\n+     \"CAST('{' || string_agg(to_json(n::VARCHAR) || ':' || CASE WHEN v IS NULL THEN 'null'::JSON ELSE to_json(v) END, \"\n+     \"',') || '}' AS JSON)\"},\n     {DEFAULT_SCHEMA,\n      \"json_group_structure\",\n      {\"x\", nullptr},\ndiff --git a/src/common/compressed_file_system.cpp b/src/common/compressed_file_system.cpp\nindex b8f032a656e3..d222bf13de12 100644\n--- a/src/common/compressed_file_system.cpp\n+++ b/src/common/compressed_file_system.cpp\n@@ -31,6 +31,8 @@ void CompressedFile::Initialize(bool write) {\n \tstream_data.out_buff_start = stream_data.out_buff.get();\n \tstream_data.out_buff_end = stream_data.out_buff.get();\n \n+\tcurrent_position = 0;\n+\n \tstream_wrapper = compressed_fs.CreateStream();\n \tstream_wrapper->Initialize(*this, write);\n }\ndiff --git a/src/execution/operator/aggregate/physical_window.cpp b/src/execution/operator/aggregate/physical_window.cpp\nindex 8b8b2a162b32..956c50ee18ad 100644\n--- a/src/execution/operator/aggregate/physical_window.cpp\n+++ b/src/execution/operator/aggregate/physical_window.cpp\n@@ -575,6 +575,11 @@ class WindowLocalSourceState : public LocalSourceState {\n \n \texplicit WindowLocalSourceState(WindowGlobalSourceState &gsource);\n \n+\tvoid ReleaseLocalStates() {\n+\t\tauto &local_states = window_hash_group->thread_states.at(task->thread_idx);\n+\t\tlocal_states.clear();\n+\t}\n+\n \t//! Does the task have more work to do?\n \tbool TaskFinished() const {\n \t\treturn !task || task->begin_idx == task->end_idx;\n@@ -792,6 +797,12 @@ void WindowGlobalSourceState::FinishTask(TaskPtr task) {\n }\n \n bool WindowLocalSourceState::TryAssignTask() {\n+\tD_ASSERT(TaskFinished());\n+\tif (task && task->stage == WindowGroupStage::GETDATA) {\n+\t\t// If this state completed the last block in the previous iteration,\n+\t\t// release out local state memory.\n+\t\tReleaseLocalStates();\n+\t}\n \t// Because downstream operators may be using our internal buffers,\n \t// we can't \"finish\" a task until we are about to get the next one.\n \n@@ -888,10 +899,6 @@ void WindowLocalSourceState::GetData(DataChunk &result) {\n \t\t++task->begin_idx;\n \t}\n \n-\t// If that was the last block, release out local state memory.\n-\tif (TaskFinished()) {\n-\t\tlocal_states.clear();\n-\t}\n \tresult.Verify();\n }\n \ndiff --git a/src/execution/operator/csv_scanner/sniffer/dialect_detection.cpp b/src/execution/operator/csv_scanner/sniffer/dialect_detection.cpp\nindex 37d8e5835b3f..a6e9f915597d 100644\n--- a/src/execution/operator/csv_scanner/sniffer/dialect_detection.cpp\n+++ b/src/execution/operator/csv_scanner/sniffer/dialect_detection.cpp\n@@ -491,7 +491,7 @@ void CSVSniffer::RefineCandidates() {\n \n \tfor (idx_t i = 1; i <= options.sample_size_chunks; i++) {\n \t\tvector<unique_ptr<ColumnCountScanner>> successful_candidates;\n-\t\tbool done = false;\n+\t\tbool done = candidates.empty();\n \t\tfor (auto &cur_candidate : candidates) {\n \t\t\tconst bool finished_file = cur_candidate->FinishedFile();\n \t\t\tif (successful_candidates.empty()) {\ndiff --git a/src/execution/operator/helper/physical_reservoir_sample.cpp b/src/execution/operator/helper/physical_reservoir_sample.cpp\nindex 32785a7abd6d..7b89c7a14fe0 100644\n--- a/src/execution/operator/helper/physical_reservoir_sample.cpp\n+++ b/src/execution/operator/helper/physical_reservoir_sample.cpp\n@@ -86,6 +86,7 @@ SourceResultType PhysicalReservoirSample::GetData(ExecutionContext &context, Dat\n \t\treturn SourceResultType::FINISHED;\n \t}\n \tauto sample_chunk = sink.sample->GetChunk();\n+\n \tif (!sample_chunk) {\n \t\treturn SourceResultType::FINISHED;\n \t}\ndiff --git a/src/execution/operator/schema/physical_create_art_index.cpp b/src/execution/operator/schema/physical_create_art_index.cpp\nindex 8f9b2657e0a8..11d05fd8cce0 100644\n--- a/src/execution/operator/schema/physical_create_art_index.cpp\n+++ b/src/execution/operator/schema/physical_create_art_index.cpp\n@@ -34,6 +34,7 @@ PhysicalCreateARTIndex::PhysicalCreateARTIndex(LogicalOperator &op, TableCatalog\n \n class CreateARTIndexGlobalSinkState : public GlobalSinkState {\n public:\n+\t//! We merge the local indexes into one global index.\n \tunique_ptr<BoundIndex> global_index;\n };\n \n@@ -53,8 +54,10 @@ class CreateARTIndexLocalSinkState : public LocalSinkState {\n };\n \n unique_ptr<GlobalSinkState> PhysicalCreateARTIndex::GetGlobalSinkState(ClientContext &context) const {\n-\t// Create the global sink state and add the global index.\n+\t// Create the global sink state.\n \tauto state = make_uniq<CreateARTIndexGlobalSinkState>();\n+\n+\t// Create the global index.\n \tauto &storage = table.GetStorage();\n \tstate->global_index = make_uniq<ART>(info->index_name, info->constraint_type, storage_ids,\n \t                                     TableIOManager::Get(storage), unbound_expressions, storage.db);\n@@ -123,7 +126,6 @@ SinkResultType PhysicalCreateARTIndex::SinkSorted(OperatorSinkInput &input) cons\n \n SinkResultType PhysicalCreateARTIndex::Sink(ExecutionContext &context, DataChunk &chunk,\n                                             OperatorSinkInput &input) const {\n-\n \tD_ASSERT(chunk.ColumnCount() >= 2);\n \tauto &l_state = input.local_state.Cast<CreateARTIndexLocalSinkState>();\n \tl_state.arena_allocator.Reset();\n@@ -151,11 +153,10 @@ SinkResultType PhysicalCreateARTIndex::Sink(ExecutionContext &context, DataChunk\n \n SinkCombineResultType PhysicalCreateARTIndex::Combine(ExecutionContext &context,\n                                                       OperatorSinkCombineInput &input) const {\n-\n \tauto &g_state = input.global_state.Cast<CreateARTIndexGlobalSinkState>();\n-\tauto &l_state = input.local_state.Cast<CreateARTIndexLocalSinkState>();\n \n \t// Merge the local index into the global index.\n+\tauto &l_state = input.local_state.Cast<CreateARTIndexLocalSinkState>();\n \tif (!g_state.global_index->MergeIndexes(*l_state.local_index)) {\n \t\tthrow ConstraintException(\"Data contains duplicates on indexed column(s)\");\n \t}\n@@ -165,8 +166,6 @@ SinkCombineResultType PhysicalCreateARTIndex::Combine(ExecutionContext &context,\n \n SinkFinalizeType PhysicalCreateARTIndex::Finalize(Pipeline &pipeline, Event &event, ClientContext &context,\n                                                   OperatorSinkFinalizeInput &input) const {\n-\n-\t// Here, we set the resulting global index as the newly created index of the table.\n \tauto &state = input.global_state.Cast<CreateARTIndexGlobalSinkState>();\n \n \t// Vacuum excess memory and verify.\n@@ -182,7 +181,6 @@ SinkFinalizeType PhysicalCreateARTIndex::Finalize(Pipeline &pipeline, Event &eve\n \tauto &schema = table.schema;\n \tinfo->column_ids = storage_ids;\n \n-\t// FIXME: We should check for catalog exceptions prior to index creation, and later double-check.\n \tif (!alter_table_info) {\n \t\t// Ensure that the index does not yet exist in the catalog.\n \t\tauto entry = schema.GetEntry(schema.GetCatalogTransaction(context), CatalogType::INDEX_ENTRY, info->index_name);\ndiff --git a/src/execution/physical_plan/plan_create_index.cpp b/src/execution/physical_plan/plan_create_index.cpp\nindex e2017c233e8f..ef38c6971f63 100644\n--- a/src/execution/physical_plan/plan_create_index.cpp\n+++ b/src/execution/physical_plan/plan_create_index.cpp\n@@ -6,10 +6,21 @@\n #include \"duckdb/planner/expression/bound_reference_expression.hpp\"\n #include \"duckdb/planner/operator/logical_create_index.hpp\"\n #include \"duckdb/planner/operator/logical_get.hpp\"\n+#include \"duckdb/execution/operator/scan/physical_dummy_scan.hpp\"\n \n namespace duckdb {\n \n unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalCreateIndex &op) {\n+\t// Early-out, if the index already exists.\n+\tauto &schema = op.table.schema;\n+\tauto entry = schema.GetEntry(schema.GetCatalogTransaction(context), CatalogType::INDEX_ENTRY, op.info->index_name);\n+\tif (entry) {\n+\t\tif (op.info->on_conflict != OnCreateConflict::IGNORE_ON_CONFLICT) {\n+\t\t\tthrow CatalogException(\"Index with name \\\"%s\\\" already exists!\", op.info->index_name);\n+\t\t}\n+\t\treturn make_uniq<PhysicalDummyScan>(op.types, op.estimated_cardinality);\n+\t}\n+\n \t// Ensure that all expressions contain valid scalar functions.\n \t// E.g., get_current_timestamp(), random(), and sequence values cannot be index keys.\n \tfor (idx_t i = 0; i < op.unbound_expressions.size(); i++) {\ndiff --git a/src/execution/sample/reservoir_sample.cpp b/src/execution/sample/reservoir_sample.cpp\nindex b28bed81b0e9..cb52f3f2b4b0 100644\n--- a/src/execution/sample/reservoir_sample.cpp\n+++ b/src/execution/sample/reservoir_sample.cpp\n@@ -166,8 +166,15 @@ unique_ptr<ReservoirChunk> ReservoirSample::CreateNewSampleChunk(vector<LogicalT\n \n void ReservoirSample::Vacuum() {\n \tVerify();\n-\tif (NumSamplesCollected() <= FIXED_SAMPLE_SIZE || !reservoir_chunk || destroyed) {\n+\tbool do_vacuum = false;\n+\t// when it's not a stats sample, sometimes we neverr collect more than FIXED_SAMPLE_SIZE tuples\n+\t// but we still need to vacuum, so the rules are a little bit different.\n+\tif (!stats_sample && GetActiveSampleCount() <= static_cast<idx_t>(GetReservoirChunkCapacity<double>() * 0.8)) {\n+\t\tdo_vacuum = true;\n+\t}\n+\tif (!do_vacuum && (NumSamplesCollected() <= FIXED_SAMPLE_SIZE || !reservoir_chunk || destroyed)) {\n \t\t// sample is destroyed or too small to shrink\n+\t\t// sample does not need to be vacuumed.\n \t\treturn;\n \t}\n \n@@ -201,7 +208,7 @@ unique_ptr<BlockingSample> ReservoirSample::Copy() const {\n \t// how many values should be copied\n \tidx_t values_to_copy = MinValue<idx_t>(GetActiveSampleCount(), sample_count);\n \n-\tauto new_sample_chunk = CreateNewSampleChunk(types, GetReservoirChunkCapacity());\n+\tauto new_sample_chunk = CreateNewSampleChunk(types, GetReservoirChunkCapacity<idx_t>());\n \n \tSelectionVector sel_copy(sel);\n \n@@ -295,7 +302,7 @@ void ReservoirSample::SimpleMerge(ReservoirSample &other) {\n \tidx_t size_after_merge = MinValue<idx_t>(keep_from_other + keep_from_this, FIXED_SAMPLE_SIZE);\n \n \t// Check if appending the other samples to this will go over the sample chunk size\n-\tif (reservoir_chunk->chunk.size() + keep_from_other > GetReservoirChunkCapacity()) {\n+\tif (reservoir_chunk->chunk.size() + keep_from_other > GetReservoirChunkCapacity<idx_t>()) {\n \t\tVacuum();\n \t}\n \n@@ -542,7 +549,7 @@ void ReservoirSample::ExpandSerializedSample() {\n \t}\n \n \tauto types = reservoir_chunk->chunk.GetTypes();\n-\tauto new_res_chunk = CreateNewSampleChunk(types, GetReservoirChunkCapacity());\n+\tauto new_res_chunk = CreateNewSampleChunk(types, GetReservoirChunkCapacity<idx_t>());\n \tauto copy_count = reservoir_chunk->chunk.size();\n \tSelectionVector tmp_sel = SelectionVector(0, copy_count);\n \tUpdateSampleAppend(new_res_chunk->chunk, reservoir_chunk->chunk, tmp_sel, copy_count);\n@@ -550,8 +557,10 @@ void ReservoirSample::ExpandSerializedSample() {\n \tstd::swap(reservoir_chunk, new_res_chunk);\n }\n \n-idx_t ReservoirSample::GetReservoirChunkCapacity() const {\n-\treturn sample_count + (FIXED_SAMPLE_SIZE_MULTIPLIER * MinValue<idx_t>(sample_count, FIXED_SAMPLE_SIZE));\n+template <typename T>\n+T ReservoirSample::GetReservoirChunkCapacity() const {\n+\treturn static_cast<T>(sample_count +\n+\t                      (FIXED_SAMPLE_SIZE_MULTIPLIER * MinValue<idx_t>(sample_count, FIXED_SAMPLE_SIZE)));\n }\n \n idx_t ReservoirSample::FillReservoir(DataChunk &chunk) {\n@@ -563,7 +572,7 @@ idx_t ReservoirSample::FillReservoir(DataChunk &chunk) {\n \t\t}\n \t\tauto types = chunk.GetTypes();\n \t\t// create a new sample chunk to store new samples\n-\t\treservoir_chunk = CreateNewSampleChunk(types, GetReservoirChunkCapacity());\n+\t\treservoir_chunk = CreateNewSampleChunk(types, GetReservoirChunkCapacity<idx_t>());\n \t}\n \n \tidx_t actual_sample_index_start = GetActiveSampleCount();\n@@ -694,9 +703,6 @@ void ReservoirSample::UpdateSampleAppend(DataChunk &this_, DataChunk &other, Sel\n \t\treturn;\n \t}\n \tD_ASSERT(this_.GetTypes() == other.GetTypes());\n-\n-\t// UpdateSampleAppend(this_, other, other_sel, append_count);\n-\tD_ASSERT(this_.GetTypes() == other.GetTypes());\n \tauto types = reservoir_chunk->chunk.GetTypes();\n \n \tfor (idx_t i = 0; i < reservoir_chunk->chunk.ColumnCount(); i++) {\n@@ -714,6 +720,9 @@ void ReservoirSample::AddToReservoir(DataChunk &chunk) {\n \t\treturn;\n \t}\n \n+\tif (!reservoir_chunk && GetReservoirChunkCapacity<idx_t>() == 0) {\n+\t\treturn;\n+\t}\n \tidx_t tuples_consumed = FillReservoir(chunk);\n \tbase_reservoir_sample->num_entries_seen_total += tuples_consumed;\n \tD_ASSERT(sample_count == 0 || reservoir_chunk->chunk.size() >= 1);\n@@ -752,8 +761,10 @@ void ReservoirSample::AddToReservoir(DataChunk &chunk) {\n \t\tbase_reservoir_sample->num_entries_seen_total += chunk.size();\n \t\treturn;\n \t}\n+\n \tidx_t size = chunk_sel.size;\n \tD_ASSERT(size <= chunk.size());\n+\tD_ASSERT(reservoir_chunk->chunk.size() < GetReservoirChunkCapacity<idx_t>());\n \n \tUpdateSampleAppend(reservoir_chunk->chunk, chunk, chunk_sel.sel, size);\n \n@@ -763,11 +774,12 @@ void ReservoirSample::AddToReservoir(DataChunk &chunk) {\n \n \tVerify();\n \n-\t// if we are over the threshold, we ned to swith to slow sampling.\n+\t// if we are over the threshold, we ned to switch to slow sampling.\n \tif (GetSamplingState() == SamplingState::RANDOM && GetTuplesSeen() >= FIXED_SAMPLE_SIZE * FAST_TO_SLOW_THRESHOLD) {\n \t\tConvertToReservoirSample();\n \t}\n-\tif (reservoir_chunk->chunk.size() >= (GetReservoirChunkCapacity() - (static_cast<idx_t>(FIXED_SAMPLE_SIZE) * 3))) {\n+\tif (static_cast<int64_t>(reservoir_chunk->chunk.size()) >=\n+\t    GetReservoirChunkCapacity<int64_t>() - (static_cast<int64_t>(FIXED_SAMPLE_SIZE) * 3)) {\n \t\tVacuum();\n \t}\n }\ndiff --git a/src/function/window/window_constant_aggregator.cpp b/src/function/window/window_constant_aggregator.cpp\nindex 0e09c6f99996..312161223903 100644\n--- a/src/function/window/window_constant_aggregator.cpp\n+++ b/src/function/window/window_constant_aggregator.cpp\n@@ -18,6 +18,10 @@ class WindowConstantAggregatorGlobalState : public WindowAggregatorGlobalState {\n \n \tvoid Finalize(const FrameStats &stats);\n \n+\t~WindowConstantAggregatorGlobalState() override {\n+\t\tstatef.Destroy();\n+\t}\n+\n \t//! Partition starts\n \tvector<idx_t> partition_offsets;\n \t//! Reused result state container for the window functions\n@@ -304,11 +308,7 @@ void WindowConstantAggregator::Finalize(WindowAggregatorState &gstate, WindowAgg\n \tlastate.statef.Combine(gastate.statef);\n \tlastate.statef.Destroy();\n \n-\t//\tLast one out turns off the lights!\n-\tif (++gastate.finalized == gastate.locals) {\n-\t\tgastate.statef.Finalize(*gastate.results);\n-\t\tgastate.statef.Destroy();\n-\t}\n+\tgastate.statef.Finalize(*gastate.results);\n }\n \n unique_ptr<WindowAggregatorState> WindowConstantAggregator::GetLocalState(const WindowAggregatorState &gstate) const {\ndiff --git a/src/function/window/window_distinct_aggregator.cpp b/src/function/window/window_distinct_aggregator.cpp\nindex 1dc940f9533d..77e00a02ee58 100644\n--- a/src/function/window/window_distinct_aggregator.cpp\n+++ b/src/function/window/window_distinct_aggregator.cpp\n@@ -190,6 +190,10 @@ class WindowDistinctAggregatorLocalState : public WindowAggregatorLocalState {\n public:\n \texplicit WindowDistinctAggregatorLocalState(const WindowDistinctAggregatorGlobalState &aggregator);\n \n+\t~WindowDistinctAggregatorLocalState() override {\n+\t\tstatef.Destroy();\n+\t}\n+\n \tvoid Sink(DataChunk &sink_chunk, DataChunk &coll_chunk, idx_t input_idx, optional_ptr<SelectionVector> filter_sel,\n \t          idx_t filtered);\n \tvoid Finalize(WindowAggregatorGlobalState &gastate, CollectionPtr collection) override;\n@@ -740,7 +744,6 @@ void WindowDistinctAggregatorLocalState::Evaluate(const WindowDistinctAggregator\n \n \t//\tFinalise the result aggregates and write to the result\n \tstatef.Finalize(result);\n-\tstatef.Destroy();\n }\n \n unique_ptr<WindowAggregatorState> WindowDistinctAggregator::GetLocalState(const WindowAggregatorState &gstate) const {\ndiff --git a/src/include/duckdb.h b/src/include/duckdb.h\nindex ae52abd33747..0a75bd5531ed 100644\n--- a/src/include/duckdb.h\n+++ b/src/include/duckdb.h\n@@ -135,6 +135,10 @@ typedef enum DUCKDB_TYPE {\n \tDUCKDB_TYPE_VARINT = 35,\n \t// SQLNULL type\n \tDUCKDB_TYPE_SQLNULL = 36,\n+\t// STRING_LITERAL type\n+\tDUCKDB_TYPE_STRING_LITERAL = 37,\n+\t// INTEGER_LITERAL type\n+\tDUCKDB_TYPE_INTEGER_LITERAL = 38,\n } duckdb_type;\n //! An enum over the returned state of different functions.\n typedef enum duckdb_state { DuckDBSuccess = 0, DuckDBError = 1 } duckdb_state;\ndiff --git a/src/include/duckdb/execution/reservoir_sample.hpp b/src/include/duckdb/execution/reservoir_sample.hpp\nindex bc815b11f9de..811c3faca333 100644\n--- a/src/include/duckdb/execution/reservoir_sample.hpp\n+++ b/src/include/duckdb/execution/reservoir_sample.hpp\n@@ -201,7 +201,8 @@ class ReservoirSample : public BlockingSample {\n \tvoid ConvertToReservoirSample();\n \n \t//! Get the capactiy of the data chunk reserved for storing samples\n-\tidx_t GetReservoirChunkCapacity() const;\n+\ttemplate <typename T>\n+\tT GetReservoirChunkCapacity() const;\n \n \t//! If for_serialization=true then the sample_chunk is not padded with extra spaces for\n \t//! future sampling values\ndiff --git a/src/include/duckdb/main/capi/header_generation/header_base.hpp.template b/src/include/duckdb/main/capi/header_generation/header_base.hpp.template\nindex ca0b4a777e9d..042a0d2357b9 100644\n--- a/src/include/duckdb/main/capi/header_generation/header_base.hpp.template\n+++ b/src/include/duckdb/main/capi/header_generation/header_base.hpp.template\n@@ -129,6 +129,10 @@ typedef enum DUCKDB_TYPE {\n \tDUCKDB_TYPE_VARINT = 35,\n \t// SQLNULL type\n \tDUCKDB_TYPE_SQLNULL = 36,\n+\t// STRING_LITERAL type\n+\tDUCKDB_TYPE_STRING_LITERAL = 37,\n+\t// INTEGER_LITERAL type\n+\tDUCKDB_TYPE_INTEGER_LITERAL = 38,\n } duckdb_type;\n //! An enum over the returned state of different functions.\n typedef enum duckdb_state { DuckDBSuccess = 0, DuckDBError = 1 } duckdb_state;\ndiff --git a/src/include/duckdb/main/extension_entries.hpp b/src/include/duckdb/main/extension_entries.hpp\nindex 554aac9eb102..40d3429c529b 100644\n--- a/src/include/duckdb/main/extension_entries.hpp\n+++ b/src/include/duckdb/main/extension_entries.hpp\n@@ -489,6 +489,7 @@ static constexpr ExtensionFunctionEntry EXTENSION_FUNCTIONS[] = {\n     {\"read_xlsx\", \"excel\", CatalogType::TABLE_FUNCTION_ENTRY},\n     {\"reduce\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"reduce_sql_statement\", \"sqlsmith\", CatalogType::TABLE_FUNCTION_ENTRY},\n+    {\"register_geoarrow_extensions\", \"spatial\", CatalogType::TABLE_FUNCTION_ENTRY},\n     {\"regr_avgx\", \"core_functions\", CatalogType::AGGREGATE_FUNCTION_ENTRY},\n     {\"regr_avgy\", \"core_functions\", CatalogType::AGGREGATE_FUNCTION_ENTRY},\n     {\"regr_count\", \"core_functions\", CatalogType::AGGREGATE_FUNCTION_ENTRY},\n@@ -538,6 +539,7 @@ static constexpr ExtensionFunctionEntry EXTENSION_FUNCTIONS[] = {\n     {\"st_centroid\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_collect\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_collectionextract\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n+    {\"st_concavehull\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_contains\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_containsproperly\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_convexhull\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n@@ -588,14 +590,17 @@ static constexpr ExtensionFunctionEntry EXTENSION_FUNCTIONS[] = {\n     {\"st_isvalid\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_length\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_length_spheroid\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n+    {\"st_lineinterpolatepoint\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n+    {\"st_lineinterpolatepoints\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_linemerge\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_linestring2dfromwkb\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n-    {\"st_list_proj_crs\", \"spatial\", CatalogType::TABLE_FUNCTION_ENTRY},\n+    {\"st_linesubstring\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_m\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_makeenvelope\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_makeline\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_makepolygon\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_makevalid\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n+    {\"st_minimumrotatedrectangle\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_mmax\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_mmin\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_multi\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n@@ -634,6 +639,7 @@ static constexpr ExtensionFunctionEntry EXTENSION_FUNCTIONS[] = {\n     {\"st_transform\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_union\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_union_agg\", \"spatial\", CatalogType::AGGREGATE_FUNCTION_ENTRY},\n+    {\"st_voronoidiagram\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_within\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_x\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"st_xmax\", \"spatial\", CatalogType::SCALAR_FUNCTION_ENTRY},\ndiff --git a/src/include/duckdb/main/query_profiler.hpp b/src/include/duckdb/main/query_profiler.hpp\nindex 1de54e9a121d..7ac69cd33386 100644\n--- a/src/include/duckdb/main/query_profiler.hpp\n+++ b/src/include/duckdb/main/query_profiler.hpp\n@@ -166,6 +166,13 @@ class QueryProfiler {\n \t\treturn root.get();\n \t}\n \n+\t//! Provides access to the root of the query tree, but ensures there are no concurrent modifications\n+\t//! This can be useful when implementing continuous profiling or making customizations\n+\tDUCKDB_API void GetRootUnderLock(const std::function<void(optional_ptr<ProfilingNode>)> &callback) {\n+\t\tlock_guard<std::mutex> guard(lock);\n+\t\tcallback(GetRoot());\n+\t}\n+\n private:\n \tClientContext &context;\n \ndiff --git a/src/include/duckdb/optimizer/filter_combiner.hpp b/src/include/duckdb/optimizer/filter_combiner.hpp\nindex 68e22573aae5..979c886930a9 100644\n--- a/src/include/duckdb/optimizer/filter_combiner.hpp\n+++ b/src/include/duckdb/optimizer/filter_combiner.hpp\n@@ -103,8 +103,8 @@ class FilterCombiner {\n \n \texpression_map_t<unique_ptr<Expression>> stored_expressions;\n \texpression_map_t<idx_t> equivalence_set_map;\n-\tunordered_map<idx_t, vector<ExpressionValueInformation>> constant_values;\n-\tunordered_map<idx_t, vector<reference<Expression>>> equivalence_map;\n+\tmap<idx_t, vector<ExpressionValueInformation>> constant_values;\n+\tmap<idx_t, vector<reference<Expression>>> equivalence_map;\n \tidx_t set_index = 0;\n \t//\n \t//\t//! Structures used for OR Filters\ndiff --git a/src/include/duckdb/optimizer/late_materialization.hpp b/src/include/duckdb/optimizer/late_materialization.hpp\nindex 76f4f05e86cc..7d720e13da93 100644\n--- a/src/include/duckdb/optimizer/late_materialization.hpp\n+++ b/src/include/duckdb/optimizer/late_materialization.hpp\n@@ -14,6 +14,7 @@\n namespace duckdb {\n class LogicalOperator;\n class LogicalGet;\n+class LogicalLimit;\n class Optimizer;\n \n //! Transform\n@@ -34,7 +35,7 @@ class LateMaterialization : public BaseColumnPruner {\n \tvoid ReplaceTableReferences(Expression &expr, idx_t new_table_index);\n \tunique_ptr<Expression> GetExpression(LogicalOperator &op, idx_t column_index);\n \tvoid ReplaceExpressionReferences(LogicalOperator &next_op, unique_ptr<Expression> &expr);\n-\tbool OptimizeLargeLimit(LogicalOperator &child);\n+\tbool OptimizeLargeLimit(LogicalLimit &limit, idx_t limit_val, bool has_offset);\n \n private:\n \tOptimizer &optimizer;\ndiff --git a/src/main/capi/helper-c.cpp b/src/main/capi/helper-c.cpp\nindex 310ddc0d0e0d..fe3f5c02e45b 100644\n--- a/src/main/capi/helper-c.cpp\n+++ b/src/main/capi/helper-c.cpp\n@@ -78,6 +78,10 @@ LogicalTypeId ConvertCTypeToCPP(duckdb_type c_type) {\n \t\treturn LogicalTypeId::VARINT;\n \tcase DUCKDB_TYPE_SQLNULL:\n \t\treturn LogicalTypeId::SQLNULL;\n+\tcase DUCKDB_TYPE_STRING_LITERAL:\n+\t\treturn LogicalTypeId::STRING_LITERAL;\n+\tcase DUCKDB_TYPE_INTEGER_LITERAL:\n+\t\treturn LogicalTypeId::INTEGER_LITERAL;\n \tdefault: // LCOV_EXCL_START\n \t\tD_ASSERT(0);\n \t\treturn LogicalTypeId::INVALID;\n@@ -160,6 +164,10 @@ duckdb_type ConvertCPPTypeToC(const LogicalType &sql_type) {\n \t\treturn DUCKDB_TYPE_ANY;\n \tcase LogicalTypeId::SQLNULL:\n \t\treturn DUCKDB_TYPE_SQLNULL;\n+\tcase LogicalTypeId::STRING_LITERAL:\n+\t\treturn DUCKDB_TYPE_STRING_LITERAL;\n+\tcase LogicalTypeId::INTEGER_LITERAL:\n+\t\treturn DUCKDB_TYPE_INTEGER_LITERAL;\n \tdefault: // LCOV_EXCL_START\n \t\tD_ASSERT(0);\n \t\treturn DUCKDB_TYPE_INVALID;\ndiff --git a/src/optimizer/column_lifetime_analyzer.cpp b/src/optimizer/column_lifetime_analyzer.cpp\nindex 8b6f1152bf8c..233617b4ced1 100644\n--- a/src/optimizer/column_lifetime_analyzer.cpp\n+++ b/src/optimizer/column_lifetime_analyzer.cpp\n@@ -108,6 +108,7 @@ void ColumnLifetimeAnalyzer::VisitOperator(LogicalOperator &op) {\n \t\t//! When RETURNING is used, a PROJECTION is the top level operator for INSERTS, UPDATES, and DELETES\n \t\t//! We still need to project all values from these operators so the projection\n \t\t//! on top of them can select from only the table values being inserted.\n+\tcase LogicalOperatorType::LOGICAL_GET:\n \tcase LogicalOperatorType::LOGICAL_UNION:\n \tcase LogicalOperatorType::LOGICAL_EXCEPT:\n \tcase LogicalOperatorType::LOGICAL_INTERSECT:\ndiff --git a/src/optimizer/late_materialization.cpp b/src/optimizer/late_materialization.cpp\nindex aa4e5c4c1fe4..c88e1d753f49 100644\n--- a/src/optimizer/late_materialization.cpp\n+++ b/src/optimizer/late_materialization.cpp\n@@ -13,6 +13,7 @@\n #include \"duckdb/planner/expression_iterator.hpp\"\n #include \"duckdb/catalog/catalog_entry/table_catalog_entry.hpp\"\n #include \"duckdb/main/client_config.hpp\"\n+#include \"duckdb/main/config.hpp\"\n \n namespace duckdb {\n \n@@ -357,9 +358,22 @@ bool LateMaterialization::TryLateMaterialization(unique_ptr<LogicalOperator> &op\n \treturn true;\n }\n \n-bool LateMaterialization::OptimizeLargeLimit(LogicalOperator &child) {\n-\t// we only support large limits if the only\n-\treference<LogicalOperator> current_op = child;\n+bool LateMaterialization::OptimizeLargeLimit(LogicalLimit &limit, idx_t limit_val, bool has_offset) {\n+\tauto &config = DBConfig::GetConfig(optimizer.context);\n+\tif (!has_offset && !config.options.preserve_insertion_order) {\n+\t\t// we avoid optimizing large limits if preserve insertion order is false\n+\t\t// since the limit is executed in parallel anyway\n+\t\treturn false;\n+\t}\n+\t// we only perform this optimization until a certain amount of maximum values to reduce memory constraints\n+\t// since we still materialize the set of row-ids in the hash table this optimization can increase memory pressure\n+\t// FIXME: make this configurable as well\n+\tstatic constexpr const idx_t LIMIT_MAX_VAL = 1000000;\n+\tif (limit_val > LIMIT_MAX_VAL) {\n+\t\treturn false;\n+\t}\n+\t// we only support large limits if they are directly below the source\n+\treference<LogicalOperator> current_op = *limit.children[0];\n \twhile (current_op.get().type != LogicalOperatorType::LOGICAL_GET) {\n \t\tif (current_op.get().type != LogicalOperatorType::LOGICAL_PROJECTION) {\n \t\t\treturn false;\n@@ -376,11 +390,18 @@ unique_ptr<LogicalOperator> LateMaterialization::Optimize(unique_ptr<LogicalOper\n \t\tif (limit.limit_val.Type() != LimitNodeType::CONSTANT_VALUE) {\n \t\t\tbreak;\n \t\t}\n-\t\tif (limit.limit_val.GetConstantValue() > max_row_count) {\n+\t\tauto limit_val = limit.limit_val.GetConstantValue();\n+\t\tbool has_offset = limit.offset_val.Type() != LimitNodeType::UNSET;\n+\t\tif (limit_val > max_row_count) {\n \t\t\t// for large limits - we may still want to do this optimization if the limit is consecutive\n \t\t\t// this is the case if there are only projections/get below the limit\n \t\t\t// if the row-ids are not consecutive doing the join can worsen performance\n-\t\t\tif (!OptimizeLargeLimit(*limit.children[0])) {\n+\t\t\tif (!OptimizeLargeLimit(limit, limit_val, has_offset)) {\n+\t\t\t\tbreak;\n+\t\t\t}\n+\t\t} else {\n+\t\t\t// optimizing small limits really only makes sense if we have an offset\n+\t\t\tif (!has_offset) {\n \t\t\t\tbreak;\n \t\t\t}\n \t\t}\ndiff --git a/src/storage/compression/string_uncompressed.cpp b/src/storage/compression/string_uncompressed.cpp\nindex fe9cf7035957..9e013f835c4f 100644\n--- a/src/storage/compression/string_uncompressed.cpp\n+++ b/src/storage/compression/string_uncompressed.cpp\n@@ -385,12 +385,19 @@ string_t UncompressedStringStorage::ReadOverflowString(ColumnSegment &segment, V\n \t\tuint32_t remaining = length;\n \t\toffset += sizeof(uint32_t);\n \n-\t\t// allocate a buffer to store the string\n-\t\tauto alloc_size = MaxValue<idx_t>(block_manager.GetBlockSize(), length);\n-\t\t// allocate a buffer to store the compressed string\n-\t\t// TODO: profile this to check if we need to reuse buffer\n-\t\tauto target_handle = buffer_manager.Allocate(MemoryTag::OVERFLOW_STRINGS, alloc_size);\n-\t\tauto target_ptr = target_handle.Ptr();\n+\t\tBufferHandle target_handle;\n+\t\tstring_t overflow_string;\n+\t\tdata_ptr_t target_ptr;\n+\t\tbool allocate_block = length >= block_manager.GetBlockSize();\n+\t\tif (allocate_block) {\n+\t\t\t// overflow string is bigger than a block - allocate a temporary buffer for it\n+\t\t\ttarget_handle = buffer_manager.Allocate(MemoryTag::OVERFLOW_STRINGS, length);\n+\t\t\ttarget_ptr = target_handle.Ptr();\n+\t\t} else {\n+\t\t\t// overflow string is smaller than a block - add it to the vector directly\n+\t\t\toverflow_string = StringVector::EmptyString(result, length);\n+\t\t\ttarget_ptr = data_ptr_cast(overflow_string.GetDataWriteable());\n+\t\t}\n \n \t\t// now append the string to the single buffer\n \t\twhile (remaining > 0) {\n@@ -408,10 +415,14 @@ string_t UncompressedStringStorage::ReadOverflowString(ColumnSegment &segment, V\n \t\t\t\toffset = 0;\n \t\t\t}\n \t\t}\n-\n-\t\tauto final_buffer = target_handle.Ptr();\n-\t\tStringVector::AddHandle(result, std::move(target_handle));\n-\t\treturn ReadString(final_buffer, 0, length);\n+\t\tif (allocate_block) {\n+\t\t\tauto final_buffer = target_handle.Ptr();\n+\t\t\tStringVector::AddHandle(result, std::move(target_handle));\n+\t\t\treturn ReadString(final_buffer, 0, length);\n+\t\t} else {\n+\t\t\toverflow_string.Finalize();\n+\t\t\treturn overflow_string;\n+\t\t}\n \t}\n \n \t// read the overflow string from memory\ndiff --git a/tools/pythonpkg/duckdb-stubs/__init__.pyi b/tools/pythonpkg/duckdb-stubs/__init__.pyi\nindex 8c57cce2aa8f..7cd5989a810c 100644\n--- a/tools/pythonpkg/duckdb-stubs/__init__.pyi\n+++ b/tools/pythonpkg/duckdb-stubs/__init__.pyi\n@@ -284,7 +284,7 @@ class DuckDBPyConnection:\n \n     # START OF CONNECTION METHODS\n     def cursor(self) -> DuckDBPyConnection: ...\n-    def register_filesystem(self, filesystem: str) -> None: ...\n+    def register_filesystem(self, filesystem: fsspec.AbstractFileSystem) -> None: ...\n     def unregister_filesystem(self, name: str) -> None: ...\n     def list_filesystems(self) -> list: ...\n     def filesystem_is_registered(self, name: str) -> bool: ...\n@@ -631,7 +631,7 @@ def tokenize(query: str) -> List[Any]: ...\n \n # START OF CONNECTION WRAPPER\n def cursor(*, connection: DuckDBPyConnection = ...) -> DuckDBPyConnection: ...\n-def register_filesystem(filesystem: str, *, connection: DuckDBPyConnection = ...) -> None: ...\n+def register_filesystem(filesystem: fsspec.AbstractFileSystem, *, connection: DuckDBPyConnection = ...) -> None: ...\n def unregister_filesystem(name: str, *, connection: DuckDBPyConnection = ...) -> None: ...\n def list_filesystems(*, connection: DuckDBPyConnection = ...) -> list: ...\n def filesystem_is_registered(name: str, *, connection: DuckDBPyConnection = ...) -> bool: ...\ndiff --git a/tools/pythonpkg/scripts/connection_methods.json b/tools/pythonpkg/scripts/connection_methods.json\nindex 19f06c760309..a6b6b2e75681 100644\n--- a/tools/pythonpkg/scripts/connection_methods.json\n+++ b/tools/pythonpkg/scripts/connection_methods.json\n@@ -12,7 +12,7 @@\n \t\t\"args\": [\n \t\t\t{\n \t\t\t\t\"name\": \"filesystem\",\n-\t\t\t\t\"type\": \"str\"\n+\t\t\t\t\"type\": \"fsspec.AbstractFileSystem\"\n \t\t\t}\n \t\t],\n \t\t\"return\": \"None\"\n@@ -108,7 +108,11 @@\n \t\t\"return\": \"DuckDBPyConnection\"\n \t},\n \t{\n-\t\t\"name\": [\"sqltype\", \"dtype\", \"type\"],\n+\t\t\"name\": [\n+\t\t\t\"sqltype\",\n+\t\t\t\"dtype\",\n+\t\t\t\"type\"\n+\t\t],\n \t\t\"function\": \"Type\",\n \t\t\"docs\": \"Create a type object by parsing the 'type_str' string\",\n \t\t\"args\": [\n@@ -212,7 +216,10 @@\n \t\t\"return\": \"DuckDBPyType\"\n \t},\n \t{\n-\t\t\"name\": [\"struct_type\", \"row_type\"],\n+\t\t\"name\": [\n+\t\t\t\"struct_type\",\n+\t\t\t\"row_type\"\n+\t\t],\n \t\t\"function\": \"StructType\",\n \t\t\"docs\": \"Create a struct type object from 'fields'\",\n \t\t\"args\": [\n@@ -325,7 +332,11 @@\n \t\t\"return\": \"dict\"\n \t},\n \t{\n-\t\t\"name\": [\"fetchdf\", \"fetch_df\", \"df\"],\n+\t\t\"name\": [\n+\t\t\t\"fetchdf\",\n+\t\t\t\"fetch_df\",\n+\t\t\t\"df\"\n+\t\t],\n \t\t\"function\": \"FetchDF\",\n \t\t\"docs\": \"Fetch a result as DataFrame following execute()\",\n \t\t\"kwargs\": [\n@@ -371,7 +382,10 @@\n \t\t\"return\": \"polars.DataFrame\"\n \t},\n \t{\n-\t\t\"name\": [\"fetch_arrow_table\", \"arrow\"],\n+\t\t\"name\": [\n+\t\t\t\"fetch_arrow_table\",\n+\t\t\t\"arrow\"\n+\t\t],\n \t\t\"function\": \"FetchArrow\",\n \t\t\"docs\": \"Fetch a result as Arrow table following execute()\",\n \t\t\"args\": [\n@@ -658,7 +672,11 @@\n \t\t\"return\": \"List[Statement]\"\n \t},\n \t{\n-\t\t\"name\": [\"sql\", \"query\", \"from_query\"],\n+\t\t\"name\": [\n+\t\t\t\"sql\",\n+\t\t\t\"query\",\n+\t\t\t\"from_query\"\n+\t\t],\n \t\t\"function\": \"RunQuery\",\n \t\t\"docs\": \"Run a SQL query. If it is a SELECT statement, create a relation object from the given SQL query, otherwise run the query as-is.\",\n \t\t\"args\": [\n@@ -682,7 +700,10 @@\n \t\t\"return\": \"DuckDBPyRelation\"\n \t},\n \t{\n-\t\t\"name\": [\"read_csv\", \"from_csv_auto\"],\n+\t\t\"name\": [\n+\t\t\t\"read_csv\",\n+\t\t\t\"from_csv_auto\"\n+\t\t],\n \t\t\"function\": \"ReadCSV\",\n \t\t\"docs\": \"Create a relation object from the CSV file in 'name'\",\n \t\t\"args\": [\n@@ -901,7 +922,10 @@\n \t\t\"return\": \"DuckDBPyRelation\"\n \t},\n \t{\n-\t\t\"name\": [\"from_parquet\", \"read_parquet\"],\n+\t\t\"name\": [\n+\t\t\t\"from_parquet\",\n+\t\t\t\"read_parquet\"\n+\t\t],\n \t\t\"function\": \"FromParquet\",\n \t\t\"docs\": \"Create a relation object from the Parquet files in file_glob\",\n \t\t\"args\": [\n@@ -945,7 +969,10 @@\n \t\t\"return\": \"DuckDBPyRelation\"\n \t},\n \t{\n-\t\t\"name\": [\"from_parquet\", \"read_parquet\"],\n+\t\t\"name\": [\n+\t\t\t\"from_parquet\",\n+\t\t\t\"read_parquet\"\n+\t\t],\n \t\t\"function\": \"FromParquets\",\n \t\t\"docs\": \"Create a relation object from the Parquet files in file_globs\",\n \t\t\"args\": [\n@@ -1046,4 +1073,4 @@\n \t\t],\n \t\t\"return\": \"None\"\n \t}\n-]\n+]\n\\ No newline at end of file\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/expression/pyexpression.hpp b/tools/pythonpkg/src/include/duckdb_python/expression/pyexpression.hpp\nindex b89578af25bc..0c0d3d53fbf7 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/expression/pyexpression.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/expression/pyexpression.hpp\n@@ -40,14 +40,14 @@ struct DuckDBPyExpression : public enable_shared_from_this<DuckDBPyExpression> {\n \tstring ToString() const;\n \tstring GetName() const;\n \tvoid Print() const;\n-\tshared_ptr<DuckDBPyExpression> Add(const DuckDBPyExpression &other);\n+\tshared_ptr<DuckDBPyExpression> Add(const DuckDBPyExpression &other) const;\n+\tshared_ptr<DuckDBPyExpression> Subtract(const DuckDBPyExpression &other) const;\n+\tshared_ptr<DuckDBPyExpression> Multiply(const DuckDBPyExpression &other) const;\n+\tshared_ptr<DuckDBPyExpression> Division(const DuckDBPyExpression &other) const;\n+\tshared_ptr<DuckDBPyExpression> FloorDivision(const DuckDBPyExpression &other) const;\n+\tshared_ptr<DuckDBPyExpression> Modulo(const DuckDBPyExpression &other) const;\n+\tshared_ptr<DuckDBPyExpression> Power(const DuckDBPyExpression &other) const;\n \tshared_ptr<DuckDBPyExpression> Negate();\n-\tshared_ptr<DuckDBPyExpression> Subtract(const DuckDBPyExpression &other);\n-\tshared_ptr<DuckDBPyExpression> Multiply(const DuckDBPyExpression &other);\n-\tshared_ptr<DuckDBPyExpression> Division(const DuckDBPyExpression &other);\n-\tshared_ptr<DuckDBPyExpression> FloorDivision(const DuckDBPyExpression &other);\n-\tshared_ptr<DuckDBPyExpression> Modulo(const DuckDBPyExpression &other);\n-\tshared_ptr<DuckDBPyExpression> Power(const DuckDBPyExpression &other);\n \n \t// Equality operations\n \n@@ -69,8 +69,8 @@ struct DuckDBPyExpression : public enable_shared_from_this<DuckDBPyExpression> {\n \t// AND, OR and NOT\n \n \tshared_ptr<DuckDBPyExpression> Not();\n-\tshared_ptr<DuckDBPyExpression> And(const DuckDBPyExpression &other);\n-\tshared_ptr<DuckDBPyExpression> Or(const DuckDBPyExpression &other);\n+\tshared_ptr<DuckDBPyExpression> And(const DuckDBPyExpression &other) const;\n+\tshared_ptr<DuckDBPyExpression> Or(const DuckDBPyExpression &other) const;\n \n \t// IS NULL / IS NOT NULL\n \n@@ -79,6 +79,7 @@ struct DuckDBPyExpression : public enable_shared_from_this<DuckDBPyExpression> {\n \n \t// IN / NOT IN\n \n+\tshared_ptr<DuckDBPyExpression> CreateCompareExpression(ExpressionType compare_type, const py::args &args);\n \tshared_ptr<DuckDBPyExpression> In(const py::args &args);\n \tshared_ptr<DuckDBPyExpression> NotIn(const py::args &args);\n \ndiff --git a/tools/pythonpkg/src/pyexpression.cpp b/tools/pythonpkg/src/pyexpression.cpp\nindex 318ccc2d6e45..faaa6919cae7 100644\n--- a/tools/pythonpkg/src/pyexpression.cpp\n+++ b/tools/pythonpkg/src/pyexpression.cpp\n@@ -109,31 +109,31 @@ shared_ptr<DuckDBPyExpression> DuckDBPyExpression::Else(const DuckDBPyExpression\n \n // Binary operators\n \n-shared_ptr<DuckDBPyExpression> DuckDBPyExpression::Add(const DuckDBPyExpression &other) {\n+shared_ptr<DuckDBPyExpression> DuckDBPyExpression::Add(const DuckDBPyExpression &other) const {\n \treturn DuckDBPyExpression::BinaryOperator(\"+\", *this, other);\n }\n \n-shared_ptr<DuckDBPyExpression> DuckDBPyExpression::Subtract(const DuckDBPyExpression &other) {\n+shared_ptr<DuckDBPyExpression> DuckDBPyExpression::Subtract(const DuckDBPyExpression &other) const {\n \treturn DuckDBPyExpression::BinaryOperator(\"-\", *this, other);\n }\n \n-shared_ptr<DuckDBPyExpression> DuckDBPyExpression::Multiply(const DuckDBPyExpression &other) {\n+shared_ptr<DuckDBPyExpression> DuckDBPyExpression::Multiply(const DuckDBPyExpression &other) const {\n \treturn DuckDBPyExpression::BinaryOperator(\"*\", *this, other);\n }\n \n-shared_ptr<DuckDBPyExpression> DuckDBPyExpression::Division(const DuckDBPyExpression &other) {\n+shared_ptr<DuckDBPyExpression> DuckDBPyExpression::Division(const DuckDBPyExpression &other) const {\n \treturn DuckDBPyExpression::BinaryOperator(\"/\", *this, other);\n }\n \n-shared_ptr<DuckDBPyExpression> DuckDBPyExpression::FloorDivision(const DuckDBPyExpression &other) {\n+shared_ptr<DuckDBPyExpression> DuckDBPyExpression::FloorDivision(const DuckDBPyExpression &other) const {\n \treturn DuckDBPyExpression::BinaryOperator(\"//\", *this, other);\n }\n \n-shared_ptr<DuckDBPyExpression> DuckDBPyExpression::Modulo(const DuckDBPyExpression &other) {\n+shared_ptr<DuckDBPyExpression> DuckDBPyExpression::Modulo(const DuckDBPyExpression &other) const {\n \treturn DuckDBPyExpression::BinaryOperator(\"%\", *this, other);\n }\n \n-shared_ptr<DuckDBPyExpression> DuckDBPyExpression::Power(const DuckDBPyExpression &other) {\n+shared_ptr<DuckDBPyExpression> DuckDBPyExpression::Power(const DuckDBPyExpression &other) const {\n \treturn DuckDBPyExpression::BinaryOperator(\"**\", *this, other);\n }\n \n@@ -169,11 +169,11 @@ shared_ptr<DuckDBPyExpression> DuckDBPyExpression::Not() {\n \treturn DuckDBPyExpression::InternalUnaryOperator(ExpressionType::OPERATOR_NOT, *this);\n }\n \n-shared_ptr<DuckDBPyExpression> DuckDBPyExpression::And(const DuckDBPyExpression &other) {\n+shared_ptr<DuckDBPyExpression> DuckDBPyExpression::And(const DuckDBPyExpression &other) const {\n \treturn DuckDBPyExpression::InternalConjunction(ExpressionType::CONJUNCTION_AND, *this, other);\n }\n \n-shared_ptr<DuckDBPyExpression> DuckDBPyExpression::Or(const DuckDBPyExpression &other) {\n+shared_ptr<DuckDBPyExpression> DuckDBPyExpression::Or(const DuckDBPyExpression &other) const {\n \treturn DuckDBPyExpression::InternalConjunction(ExpressionType::CONJUNCTION_OR, *this, other);\n }\n \n@@ -187,9 +187,12 @@ shared_ptr<DuckDBPyExpression> DuckDBPyExpression::IsNotNull() {\n \treturn DuckDBPyExpression::InternalUnaryOperator(ExpressionType::OPERATOR_IS_NOT_NULL, *this);\n }\n \n-// IN\n+// IN / NOT IN\n+\n+shared_ptr<DuckDBPyExpression> DuckDBPyExpression::CreateCompareExpression(ExpressionType compare_type,\n+                                                                           const py::args &args) {\n+\tD_ASSERT(args.size() >= 1);\n \n-shared_ptr<DuckDBPyExpression> DuckDBPyExpression::In(const py::args &args) {\n \tvector<unique_ptr<ParsedExpression>> expressions;\n \texpressions.reserve(args.size() + 1);\n \texpressions.push_back(GetExpression().Copy());\n@@ -202,10 +205,24 @@ shared_ptr<DuckDBPyExpression> DuckDBPyExpression::In(const py::args &args) {\n \t\tauto expr = py_expr->GetExpression().Copy();\n \t\texpressions.push_back(std::move(expr));\n \t}\n-\tauto operator_expr = make_uniq<OperatorExpression>(ExpressionType::COMPARE_IN, std::move(expressions));\n+\tauto operator_expr = make_uniq<OperatorExpression>(compare_type, std::move(expressions));\n \treturn make_shared_ptr<DuckDBPyExpression>(std::move(operator_expr));\n }\n \n+shared_ptr<DuckDBPyExpression> DuckDBPyExpression::In(const py::args &args) {\n+\tif (args.size() == 0) {\n+\t\tthrow InvalidInputException(\"Incorrect amount of parameters to 'isin', needs at least 1 parameter\");\n+\t}\n+\treturn CreateCompareExpression(ExpressionType::COMPARE_IN, args);\n+}\n+\n+shared_ptr<DuckDBPyExpression> DuckDBPyExpression::NotIn(const py::args &args) {\n+\tif (args.size() == 0) {\n+\t\tthrow InvalidInputException(\"Incorrect amount of parameters to 'isnotin', needs at least 1 parameter\");\n+\t}\n+\treturn CreateCompareExpression(ExpressionType::COMPARE_NOT_IN, args);\n+}\n+\n // COALESCE\n \n shared_ptr<DuckDBPyExpression> DuckDBPyExpression::Coalesce(const py::args &args) {\n@@ -227,11 +244,6 @@ shared_ptr<DuckDBPyExpression> DuckDBPyExpression::Coalesce(const py::args &args\n \treturn make_shared_ptr<DuckDBPyExpression>(std::move(operator_expr));\n }\n \n-shared_ptr<DuckDBPyExpression> DuckDBPyExpression::NotIn(const py::args &args) {\n-\tauto in_expr = In(args);\n-\treturn in_expr->Not();\n-}\n-\n // Order modifiers\n \n shared_ptr<DuckDBPyExpression> DuckDBPyExpression::Ascending() {\ndiff --git a/tools/pythonpkg/src/pyexpression/initialize.cpp b/tools/pythonpkg/src/pyexpression/initialize.cpp\nindex 916d51695c86..c1a8a3a198c9 100644\n--- a/tools/pythonpkg/src/pyexpression/initialize.cpp\n+++ b/tools/pythonpkg/src/pyexpression/initialize.cpp\n@@ -58,7 +58,8 @@ static void InitializeDunderMethods(py::class_<DuckDBPyExpression, shared_ptr<Du\n \t)\";\n \n \tm.def(\"__add__\", &DuckDBPyExpression::Add, py::arg(\"expr\"), docs);\n-\tm.def(\"__radd__\", &DuckDBPyExpression::Add, py::arg(\"expr\"), docs);\n+\tm.def(\n+\t    \"__radd__\", [](const DuckDBPyExpression &a, const DuckDBPyExpression &b) { return b.Add(a); }, docs);\n \n \tdocs = R\"(\n \t\tNegate the expression.\n@@ -78,7 +79,8 @@ static void InitializeDunderMethods(py::class_<DuckDBPyExpression, shared_ptr<Du\n \t\t\tFunctionExpression: self '-' expr\n \t)\";\n \tm.def(\"__sub__\", &DuckDBPyExpression::Subtract, docs);\n-\tm.def(\"__rsub__\", &DuckDBPyExpression::Subtract, docs);\n+\tm.def(\n+\t    \"__rsub__\", [](const DuckDBPyExpression &a, const DuckDBPyExpression &b) { return b.Subtract(a); }, docs);\n \n \tdocs = R\"(\n \t\tMultiply self by expr\n@@ -90,7 +92,8 @@ static void InitializeDunderMethods(py::class_<DuckDBPyExpression, shared_ptr<Du\n \t\t\tFunctionExpression: self '*' expr\n \t)\";\n \tm.def(\"__mul__\", &DuckDBPyExpression::Multiply, docs);\n-\tm.def(\"__rmul__\", &DuckDBPyExpression::Multiply, docs);\n+\tm.def(\n+\t    \"__rmul__\", [](const DuckDBPyExpression &a, const DuckDBPyExpression &b) { return b.Multiply(a); }, docs);\n \n \tdocs = R\"(\n \t\tDivide self by expr\n@@ -102,10 +105,12 @@ static void InitializeDunderMethods(py::class_<DuckDBPyExpression, shared_ptr<Du\n \t\t\tFunctionExpression: self '/' expr\n \t)\";\n \tm.def(\"__div__\", &DuckDBPyExpression::Division, docs);\n-\tm.def(\"__rdiv__\", &DuckDBPyExpression::Division, docs);\n+\tm.def(\n+\t    \"__rdiv__\", [](const DuckDBPyExpression &a, const DuckDBPyExpression &b) { return b.Division(a); }, docs);\n \n \tm.def(\"__truediv__\", &DuckDBPyExpression::Division, docs);\n-\tm.def(\"__rtruediv__\", &DuckDBPyExpression::Division, docs);\n+\tm.def(\n+\t    \"__rtruediv__\", [](const DuckDBPyExpression &a, const DuckDBPyExpression &b) { return b.Division(a); }, docs);\n \n \tdocs = R\"(\n \t\t(Floor) Divide self by expr\n@@ -117,7 +122,9 @@ static void InitializeDunderMethods(py::class_<DuckDBPyExpression, shared_ptr<Du\n \t\t\tFunctionExpression: self '//' expr\n \t)\";\n \tm.def(\"__floordiv__\", &DuckDBPyExpression::FloorDivision, docs);\n-\tm.def(\"__rfloordiv__\", &DuckDBPyExpression::FloorDivision, docs);\n+\tm.def(\n+\t    \"__rfloordiv__\", [](const DuckDBPyExpression &a, const DuckDBPyExpression &b) { return b.FloorDivision(a); },\n+\t    docs);\n \n \tdocs = R\"(\n \t\tModulo self by expr\n@@ -129,7 +136,8 @@ static void InitializeDunderMethods(py::class_<DuckDBPyExpression, shared_ptr<Du\n \t\t\tFunctionExpression: self '%' expr\n \t)\";\n \tm.def(\"__mod__\", &DuckDBPyExpression::Modulo, docs);\n-\tm.def(\"__rmod__\", &DuckDBPyExpression::Modulo, docs);\n+\tm.def(\n+\t    \"__rmod__\", [](const DuckDBPyExpression &a, const DuckDBPyExpression &b) { return b.Modulo(a); }, docs);\n \n \tdocs = R\"(\n \t\tPower self by expr\n@@ -141,7 +149,8 @@ static void InitializeDunderMethods(py::class_<DuckDBPyExpression, shared_ptr<Du\n \t\t\tFunctionExpression: self '**' expr\n \t)\";\n \tm.def(\"__pow__\", &DuckDBPyExpression::Power, docs);\n-\tm.def(\"__rpow__\", &DuckDBPyExpression::Power, docs);\n+\tm.def(\n+\t    \"__rpow__\", [](const DuckDBPyExpression &a, const DuckDBPyExpression &b) { return b.Power(a); }, docs);\n \n \tdocs = R\"(\n \t\tCreate an equality expression between two expressions\n@@ -250,7 +259,8 @@ static void InitializeDunderMethods(py::class_<DuckDBPyExpression, shared_ptr<Du\n \t\tReturns:\n \t\t\tFunctionExpression: expr '&' self\n \t)\";\n-\tm.def(\"__rand__\", &DuckDBPyExpression::And, docs);\n+\tm.def(\n+\t    \"__rand__\", [](const DuckDBPyExpression &a, const DuckDBPyExpression &b) { return b.And(a); }, docs);\n \n \tdocs = R\"(\n \t\tBinary-or self together with expr\n@@ -261,7 +271,8 @@ static void InitializeDunderMethods(py::class_<DuckDBPyExpression, shared_ptr<Du\n \t\tReturns:\n \t\t\tFunctionExpression: expr '|' self\n \t)\";\n-\tm.def(\"__ror__\", &DuckDBPyExpression::Or, docs);\n+\tm.def(\n+\t    \"__ror__\", [](const DuckDBPyExpression &a, const DuckDBPyExpression &b) { return b.Or(a); }, docs);\n }\n \n static void InitializeImplicitConversion(py::class_<DuckDBPyExpression, shared_ptr<DuckDBPyExpression>> &m) {\n", "test_patch": "diff --git a/test/api/capi/test_capi_prepared.cpp b/test/api/capi/test_capi_prepared.cpp\nindex bddc23f9d919..414845108b5a 100644\n--- a/test/api/capi/test_capi_prepared.cpp\n+++ b/test/api/capi/test_capi_prepared.cpp\n@@ -520,3 +520,20 @@ TEST_CASE(\"Prepared streaming result\", \"[capi]\") {\n \t\tduckdb_destroy_extracted(&stmts);\n \t}\n }\n+\n+TEST_CASE(\"Test STRING LITERAL parameter type\", \"[capi]\") {\n+\tduckdb_database db;\n+\tduckdb_connection conn;\n+\tduckdb_prepared_statement stmt;\n+\n+\tREQUIRE(duckdb_open(\"\", &db) == DuckDBSuccess);\n+\tREQUIRE(duckdb_connect(db, &conn) == DuckDBSuccess);\n+\n+\tREQUIRE(duckdb_prepare(conn, \"SELECT ?\", &stmt) == DuckDBSuccess);\n+\tREQUIRE(duckdb_bind_varchar(stmt, 1, \"a\") == DuckDBSuccess);\n+\tREQUIRE(duckdb_param_type(stmt, 1) == DUCKDB_TYPE_STRING_LITERAL);\n+\tduckdb_destroy_prepare(&stmt);\n+\n+\tduckdb_disconnect(&conn);\n+\tduckdb_close(&db);\n+}\ndiff --git a/test/optimizer/column_lifetime_analyzer/summary_column_lifetime.test b/test/optimizer/column_lifetime_analyzer/summary_column_lifetime.test\nnew file mode 100644\nindex 000000000000..2bb177aca0df\n--- /dev/null\n+++ b/test/optimizer/column_lifetime_analyzer/summary_column_lifetime.test\n@@ -0,0 +1,9 @@\n+# name: test/optimizer/column_lifetime_analyzer/summary_column_lifetime.test\n+# description: Test column lifetime analyzer with SUMMARY (internal issue #4138)\n+# group: [column_lifetime_analyzer]\n+\n+statement ok\n+create table data as select * from range(0,4000) tbl(col);\n+\n+statement ok\n+SELECT * FROM summary((SELECT col FROM data ORDER BY col));\ndiff --git a/test/optimizer/pushdown/issue_16104.test b/test/optimizer/pushdown/issue_16104.test\nnew file mode 100644\nindex 000000000000..2a73b1daba42\n--- /dev/null\n+++ b/test/optimizer/pushdown/issue_16104.test\n@@ -0,0 +1,15 @@\n+# name: test/optimizer/pushdown/issue_16104.test\n+# description: Test expressions in filter preserve the order in Push Down\n+# group: [pushdown]\n+\n+statement ok\n+PRAGMA explain_output = OPTIMIZED_ONLY;\n+\n+statement ok\n+WITH random_data AS (\n+    SELECT random() * 2 AS col_double\n+    FROM generate_series(1, 100)\n+)\n+SELECT *\n+FROM random_data\n+WHERE abs(col_double) < 1 AND acos(col_double) > 0;\n\\ No newline at end of file\ndiff --git a/test/sql/alter/add_pk/test_add_pk_naming_conflict.test b/test/sql/alter/add_pk/test_add_pk_naming_conflict.test\nindex 1f74e6b01156..0abc0beaa49a 100644\n--- a/test/sql/alter/add_pk/test_add_pk_naming_conflict.test\n+++ b/test/sql/alter/add_pk/test_add_pk_naming_conflict.test\n@@ -22,7 +22,7 @@ CREATE INDEX PRIMARY_tbl_i ON tbl(i);\n statement error\n ALTER TABLE tbl ADD PRIMARY KEY (i);\n ----\n-<REGEX>:Catalog Error.*an index with that name already exists for this table: PRIMARY_tbl_i.*\n+<REGEX>:Catalog Error.*already exists.*\n \n restart\n \n@@ -32,7 +32,7 @@ PRAGMA enable_verification;\n statement error\n ALTER TABLE tbl ADD PRIMARY KEY (i);\n ----\n-<REGEX>:Catalog Error.*an index with that name already exists for this table: PRIMARY_tbl_i.*\n+<REGEX>:Catalog Error.*already exists.*\n \n # Let's do it the other way around now.\n \ndiff --git a/test/sql/copy/csv/test_sniffer_hang.test b/test/sql/copy/csv/test_sniffer_hang.test\nnew file mode 100644\nindex 000000000000..cc4e171c62d8\n--- /dev/null\n+++ b/test/sql/copy/csv/test_sniffer_hang.test\n@@ -0,0 +1,11 @@\n+# name: test/sql/copy/csv/test_sniffer_hang.test\n+# description: Test csv files with hanging behavior\n+# group: [csv]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement error\n+FROM read_csv('data/csv/bad_csv_file_2047.csv', sample_size = -1)\n+----\n+Error when sniffing file\n\\ No newline at end of file\ndiff --git a/test/sql/index/art/create_drop/test_art_create_if_exists.test b/test/sql/index/art/create_drop/test_art_create_if_exists.test\nnew file mode 100644\nindex 000000000000..01595a888dec\n--- /dev/null\n+++ b/test/sql/index/art/create_drop/test_art_create_if_exists.test\n@@ -0,0 +1,63 @@\n+# name: test/sql/index/art/create_drop/test_art_create_if_exists.test\n+# description: Test ART creation with the same index already existing\n+# group: [create_drop]\n+\n+statement ok\n+PRAGMA enable_verification;\n+\n+statement ok\n+PRAGMA immediate_transaction_mode = True;\n+\n+statement ok\n+CREATE TABLE tbl AS SELECT range AS i FROM range(100);\n+\n+# Trigger write-write conflict.\n+\n+statement ok con1\n+BEGIN;\n+\n+statement ok con1\n+CREATE INDEX IF NOT EXISTS my_idx ON tbl(i);\n+\n+statement ok con2\n+BEGIN;\n+\n+statement error con2\n+CREATE INDEX IF NOT EXISTS my_idx ON tbl(i);\n+----\n+<REGEX>:TransactionContext Error.*write-write.*\n+\n+statement ok con1\n+COMMIT;\n+\n+statement ok con2\n+COMMIT;\n+\n+query I\n+SELECT COUNT(*) FROM duckdb_indexes;\n+----\n+1\n+\n+statement ok\n+DROP INDEX my_idx;\n+\n+# Trigger early-out.\n+\n+statement ok\n+CREATE INDEX IF NOT EXISTS my_idx ON tbl(i);\n+\n+statement ok\n+CREATE INDEX IF NOT EXISTS my_idx ON tbl(i);\n+\n+statement error\n+CREATE INDEX my_idx ON tbl(i);\n+----\n+<REGEX>:Catalog Error.*already exists.*\n+\n+query I\n+SELECT COUNT(*) FROM duckdb_indexes;\n+----\n+1\n+\n+statement ok\n+DROP INDEX my_idx;\ndiff --git a/test/sql/json/test_json_copy.test_slow b/test/sql/json/test_json_copy.test_slow\nindex 9041e5d4d6ec..56c2c6a36803 100644\n--- a/test/sql/json/test_json_copy.test_slow\n+++ b/test/sql/json/test_json_copy.test_slow\n@@ -1,5 +1,5 @@\n # name: test/sql/json/test_json_copy.test_slow\n-# description: Test JSON COPY using TPC-H\n+# description: Test JSON COPY\n # group: [json]\n \n require json\ndiff --git a/test/sql/json/test_json_copy_tpch.test_slow b/test/sql/json/test_json_copy_tpch.test_slow\nindex ab614e4b7d11..41db483ad968 100644\n--- a/test/sql/json/test_json_copy_tpch.test_slow\n+++ b/test/sql/json/test_json_copy_tpch.test_slow\n@@ -38,7 +38,7 @@ statement ok\n set memory_limit='100mb'\n \n statement ok\n-COPY lineitem from '__TEST_DIR__/lineitem.json' (ARRAY)\n+COPY lineitem FROM '__TEST_DIR__/lineitem.json' (ARRAY)\n \n # 500mb should be enough for the rest\n statement ok\n@@ -49,6 +49,13 @@ PRAGMA tpch(1)\n ----\n <FILE>:extension/tpch/dbgen/answers/sf0.1/q01.csv\n \n+# also test gzipped\n+statement ok\n+COPY lineitem TO '__TEST_DIR__/lineitem.json.gz'\n+\n+statement ok\n+FROM '__TEST_DIR__/lineitem.json.gz'\n+\n statement ok\n rollback\n \ndiff --git a/test/sql/sample/get_multiple_samples_small.test_slow b/test/sql/sample/get_multiple_samples_small.test_slow\nnew file mode 100644\nindex 000000000000..31bbf57ec2c0\n--- /dev/null\n+++ b/test/sql/sample/get_multiple_samples_small.test_slow\n@@ -0,0 +1,21 @@\n+# name: test/sql/sample/get_multiple_samples_small.test_slow\n+# description: Run a sample multiple times (internal#4236)\n+# group: [sample]\n+\n+statement ok\n+pragma memory_limit='10G';\n+\n+\n+statement ok\n+CREATE OR REPLACE TABLE blah as (\n+        SELECT *\n+        FROM range(10_000_000)\n+    );\n+\n+\n+loop i 0 500\n+\n+statement ok\n+SELECT * FROM blah TABLESAMPLE 100 ROWS;\n+\n+endloop\n\\ No newline at end of file\ndiff --git a/tools/pythonpkg/tests/fast/test_expression.py b/tools/pythonpkg/tests/fast/test_expression.py\nindex 0309c22538ea..0cb923d771a2 100644\n--- a/tools/pythonpkg/tests/fast/test_expression.py\n+++ b/tools/pythonpkg/tests/fast/test_expression.py\n@@ -320,10 +320,13 @@ def test_subtract_expression(self):\n         col1 = ColumnExpression('a')\n         col2 = ColumnExpression('b')\n         expr = col1 - col2\n-        rel = rel.select(expr)\n-        res = rel.fetchall()\n+        rel2 = rel.select(expr)\n+        res = rel2.fetchall()\n         assert res == [(2,)]\n \n+        res = rel.select(1 - col1).fetchall()\n+        assert res == [(-2,)]\n+\n     def test_multiply_expression(self):\n         con = duckdb.connect()\n \n@@ -860,6 +863,20 @@ def test_filter_mixed(self, filter_rel):\n         assert len(res) == 2\n         assert res == [(1, 'a'), (4, 'a')]\n \n+    def test_empty_in(self, filter_rel):\n+        expr = ColumnExpression(\"a\")\n+        with pytest.raises(\n+            duckdb.InvalidInputException, match=\"Incorrect amount of parameters to 'isin', needs at least 1 parameter\"\n+        ):\n+            expr = expr.isin()\n+\n+        expr = ColumnExpression(\"a\")\n+        with pytest.raises(\n+            duckdb.InvalidInputException,\n+            match=\"Incorrect amount of parameters to 'isnotin', needs at least 1 parameter\",\n+        ):\n+            expr = expr.isnotin()\n+\n     def test_filter_in(self, filter_rel):\n         # IN expression\n         expr = ColumnExpression(\"a\")\n", "problem_statement": "v1.2 broke select from gzipped json\n### What happens?\n\nAfter upgrading to v1.2, reading a gzipped json file demanded a large increase in maximum object size and subsequently failed with invalid character. The same json without gzip compression reads fine in both v1.x and v1.2.\n\n### To Reproduce\n\n```\nSELECT * FROM 'fundos_list.json.gz';\n```\n[fundos_list.json.gz](https://github.com/user-attachments/files/18707966/fundos_list.json.gz)\n\n### OS:\n\nWindows 11\n\n### DuckDB Version:\n\n1.2\n\n### DuckDB Client:\n\npython\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nLeonardo Horta\n\n### Affiliation:\n\nSparta Fundos de Investimento\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nLarge limits are much slower in v1.2.0\n### What happens?\n\nAfter upgrading to duckdb 1.2.0 certain parquet export operations are taking much longer than in 1.1.3, especially for large(?) tables. On an example table with ~150M rows and 20 cols We see performance like:\n\n```\n./duckdb-1.1.3 test_parquet_writes.db -c \"set preserve_insertion_order=false; copy (from t1 limit 100_000_000) to '/dev/null' (format parquet)\"\n```\ntakes 9s on v1.1.3 whereas\n\n```\n./duckdb-nightly test_parquet_writes.db -c \"set preserve_insertion_order=false; copy (from t1 limit 100_000_000) to '/dev/null' (format parquet)\"\n```\ntakes 26s on nightly, a 3x slowdown. On wider tables the difference can be much worse.\n\n### To Reproduce\n\nhere is a dropbox link to a database that demonstrates the issue https://www.dropbox.com/scl/fi/jd0y5cjdabwfgriuwhick/test_parquet_writes.db.gz?rlkey=tfhu5mxtsm9ng4yv0bhzcwtok&st=l8blewpt&dl=1\n\nafter downloading/unzipping run:\n\n```time duckdb test_parquet_writes.db -c \"set preserve_insertion_order=false; copy (from t1 limit 100_000_000) to '/dev/null' (format parquet)\"```\n\non 1.2.0 vs 1.1.3\n\n### OS:\n\nmacos arm / apple silicon\n\n### DuckDB Version:\n\n1.2.0\n\n### DuckDB Client:\n\ncli\n\n### Hardware:\n\nrepros with 16core / 128 GB and 8 core / 8 GB\n\n### Full Name:\n\nMatt Hanlon\n\n### Affiliation:\n\nPwC\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a nightly build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nOut of Memory Error When Unnesting Large Array Field\n### What happens?\n\nI have large dataset that contains a deeply nested json field I am attempting to unnest. It is the ingredients column that is part of this dataset:\nhttps://huggingface.co/datasets/openfoodfacts/product-database\n\nI have loaded this parquet file into my database and I am attempting to unnest it with the following query:\n```sql\nwith\n    parsed_ingredients as (\n        select code, ingredients::json[] as json_array\n        from \"mydb\".\"main_raw\".\"raw__open_food_facts\"\n    ),\n    ingredient_hierarchy as (\n        select\n            code,\n            unnest(json_array, max_depth := 2) as ingredient_name,\n            generate_subscripts(json_array, 1) as ingredient_order,\n        from parsed_ingredients\n    )\n\nselect *\nfrom ingredient_hierarchy\norder by code, ingredient_order\n```\n\nWhen running it results in the following error (note I am limiting my duckdb instance to only use 8gb to run on my hardware):\n`Out of Memory Error: could not allocate block of size 256.0 KiB (7.4 GiB/7.4 GiB used)`\n\nI have also tried converting the field to a struct first but this causes it run out of memory before I even begin unnesting. How can i properly process this field without running OOM?\n\n### To Reproduce\n\nDownload the parquet data and run the code above to reporoduce.\n\n### OS:\n\nWindows\n\n### DuckDB Version:\n\n1.7.0\n\n### DuckDB Client:\n\nDuckDB-DBT\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nKyle Burke\n\n### Affiliation:\n\nNone\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nFilter with an error-throwing function getting incorrectly reordered\n### What happens?\n\nSimple `where abs(col_double) < 1 and acos(col_double) > 0` expressions can throw an error as of 1.2.0 because the filters might get reordered with `acos` being executed first while the `abs` expression is guarding against `acos` errors.\n\n### To Reproduce\n\n```sql\ncopy (select random() * 2 col_double from generate_series(1,100)) to '/tmp/r.parquet';\nselect * from (select * from  '/tmp/r.parquet') where abs(col_double) < 1 and acos(col_double) > 0;\n```\n\nOn 1.1.3:\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      col_double      \u2502\n\u2502        double        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  0.19490873625576743 \u2502\n\u2502   0.9895238863469309 \u2502  \n...\n```\n\nOn 1.2.0:\n```\nInvalid Input Error:\nACOS is undefined outside [-1,1]\n```\n\n### OS:\n\nUbuntu 22.04\n\n### DuckDB Version:\n\n1.2.0\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nMarco Slot\n\n### Affiliation:\n\nCrunchy Data\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "\n\n\n", "created_at": "2025-02-20T07:20:22Z"}
{"repo": "duckdb/duckdb", "pull_number": 16317, "instance_id": "duckdb__duckdb-16317", "issue_numbers": ["16306"], "base_commit": "ef50246314b2f80dcf6a8132db45a80dab7dd162", "patch": "diff --git a/extension/parquet/column_writer.cpp b/extension/parquet/column_writer.cpp\nindex 8791bc596c08..b4c33ef41f52 100644\n--- a/extension/parquet/column_writer.cpp\n+++ b/extension/parquet/column_writer.cpp\n@@ -309,6 +309,7 @@ struct PageInformation {\n \tidx_t offset = 0;\n \tidx_t row_count = 0;\n \tidx_t empty_count = 0;\n+\tidx_t null_count = 0;\n \tidx_t estimated_page_size = 0;\n };\n \n@@ -464,6 +465,8 @@ void BasicColumnWriter::Prepare(ColumnWriterState &state_p, ColumnWriterState *p\n \t\t\t\tstate.page_info.push_back(new_info);\n \t\t\t\tpage_info_ref = state.page_info.back();\n \t\t\t}\n+\t\t} else {\n+\t\t\tpage_info.null_count++;\n \t\t}\n \t\tvector_index++;\n \t}\n@@ -1237,7 +1240,8 @@ class StandardColumnWriter : public BasicColumnWriter {\n \t\tauto &state = state_p.Cast<StandardColumnWriterState<SRC>>();\n \t\tconst auto &page_info = state_p.page_info[page_idx];\n \t\tauto result = make_uniq<StandardWriterPageState<SRC, TGT>>(\n-\t\t    page_info.row_count - page_info.empty_count, state.total_string_size, state.encoding, state.dictionary);\n+\t\t    page_info.row_count - (page_info.empty_count + page_info.null_count), state.total_string_size,\n+\t\t    state.encoding, state.dictionary);\n \t\treturn std::move(result);\n \t}\n \n", "test_patch": "diff --git a/test/issues/general/test_16257.test_slow b/test/issues/general/test_16257.test_slow\nindex 6b3faf9a7ba4..df2a3ed75f9c 100644\n--- a/test/issues/general/test_16257.test_slow\n+++ b/test/issues/general/test_16257.test_slow\n@@ -21,5 +21,6 @@ CREATE OR REPLACE MACRO lorem_sentence(rand, words) AS lorem_sentence_util(list_\n statement ok\n SET preserve_insertion_order=false;\n \n+# added NULLs for issue #16306\n statement ok\n-COPY (SELECT lorem_sentence(random(), 20) FROM range(1_000_000)) TO '__TEST_DIR__/16257.parquet' (PARQUET_VERSION V2, ROW_GROUP_SIZE 2_000_000);\n+COPY (SELECT CASE WHEN random() < 0.01 THEN NULL ELSE lorem_sentence(random(), 20) END FROM range(1_000_000)) TO '__TEST_DIR__/16257.parquet' (PARQUET_VERSION V2, ROW_GROUP_SIZE 2_000_000);\n", "problem_statement": "Parquet Write value count mismatch when writing DELTA_BINARY_PACKED\n### What happens?\n\nWriting out a Parquet file using COPY hits an assertion failure. Works in DuckDB 1.2, but not in main HEAD compiled 2025/02/18.\n\nData source: https://noaa-ghcn-pds.s3.amazonaws.com/index.html#parquet/by_year/\n\n### To Reproduce\n\n```sql\nCOPY (\n    SELECT * FROM read_parquet('**/*.parquet', union_by_name = true)\n    WHERE year\n    BETWEEN 2010 AND 2015 ORDER BY element, obs_time\n)\nTO 'weather_v2_zstd_2025_02_18_HEAD.parquet'\n(PARQUET_VERSION V2, COMPRESSION 'zstd');\n```\n\n```\nINTERNAL Error:\nvalue count mismatch when writing DELTA_BINARY_PACKED\n\nStack Trace:\n\n0        duckdb::Exception::Exception(duckdb::ExceptionType, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&) + 64\n1        duckdb::InternalException::InternalException(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&) + 20\n2        duckdb::DbpEncoder::FinishWrite(duckdb::WriteStream&) + 128\n3        duckdb::StandardColumnWriter<duckdb::string_t, duckdb::string_t, duckdb::ParquetStringOperator>::FlushPageState(duckdb::WriteStream&, duckdb::ColumnWriterPageState*) + 268\n4        duckdb::PrimitiveColumnWriter::FlushPage(duckdb::PrimitiveColumnWriterState&) + 124\n5        duckdb::PrimitiveColumnWriter::NextPage(duckdb::PrimitiveColumnWriterState&) + 52\n6        duckdb::PrimitiveColumnWriter::Write(duckdb::ColumnWriterState&, duckdb::Vector&, unsigned long long) + 204\n7        duckdb::ParquetWriter::PrepareRowGroup(duckdb::ColumnDataCollection&, duckdb::PreparedRowGroup&) + 6036\n8        duckdb::ParquetWritePrepareBatch(duckdb::ClientContext&, duckdb::FunctionData&, duckdb::GlobalFunctionData&, duckdb::unique_ptr<duckdb::ColumnDataCollection, std::__1::default_delete<duckdb::ColumnDataCollection>, true>) + 144\n9        duckdb::PrepareBatchTask::Execute(duckdb::PhysicalBatchCopyToFile const&, duckdb::ClientContext&, duckdb::GlobalSinkState&) + 132\n10       duckdb::PhysicalBatchCopyToFile::ExecuteTask(duckdb::ClientContext&, duckdb::GlobalSinkState&) const + 232\n11       duckdb::ProcessRemainingBatchesTask::ExecuteTask(duckdb::TaskExecutionMode) + 32\n12       duckdb::ExecutorTask::Execute(duckdb::TaskExecutionMode) + 236\n13       duckdb::TaskScheduler::ExecuteForever(std::__1::atomic<bool>*) + 612\n14       void* std::__1::__thread_proxy[abi:ne180100]<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void (*)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*, std::__1::atomic<bool>*>>(void*) + 56\n15       _pthread_start + 136\n16       thread_start + 8\n\nThis error signals an assertion failure within DuckDB. This usually occurs due to unexpected conditions or errors in the program's logic.\nFor more information, see https://duckdb.org/docs/dev/internal_errors\n```\n\n### OS:\n\nmacOS Sequoia 15.3.1\n\n### DuckDB Version:\n\nmain/HEAD e249a40c8be4709c6aae693bc8bf2c012cc3d6b2\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nAlejandro Wainzinger\n\n### Affiliation:\n\nN/A\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a source build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNo - I cannot easily share my data sets due to their large size\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "Thanks \u2013 this runs into a spinlock on the nightly (release build). We'll take a look into what's causing it and also run it in a debug (relassert) build.", "created_at": "2025-02-19T15:05:35Z"}
{"repo": "duckdb/duckdb", "pull_number": 16284, "instance_id": "duckdb__duckdb-16284", "issue_numbers": ["16257", "16257", "16260"], "base_commit": "8605f802de38c8a6e63dfe3e757ccc6845c36784", "patch": "diff --git a/data/csv/afl/20250211_csv_fuzz_crash/case_53.csv b/data/csv/afl/20250211_csv_fuzz_crash/case_53.csv\nnew file mode 100644\nindex 000000000000..869b03087ab2\nBinary files /dev/null and b/data/csv/afl/20250211_csv_fuzz_crash/case_53.csv differ\ndiff --git a/data/csv/afl/4172/case_4.csv b/data/csv/afl/4172/case_4.csv\nnew file mode 100644\nindex 000000000000..c3c65cce9923\nBinary files /dev/null and b/data/csv/afl/4172/case_4.csv differ\ndiff --git a/extension/parquet/column_reader.cpp b/extension/parquet/column_reader.cpp\nindex 9e135e8b43ef..06f3b7a827a8 100644\n--- a/extension/parquet/column_reader.cpp\n+++ b/extension/parquet/column_reader.cpp\n@@ -304,7 +304,8 @@ void ColumnReader::PreparePageV2(PageHeader &page_hdr) {\n \n \tauto compressed_bytes = page_hdr.compressed_page_size - uncompressed_bytes;\n \n-\tAllocateCompressed(compressed_bytes);\n+\tResizeableBuffer compressed_buffer;\n+\tcompressed_buffer.resize(GetAllocator(), compressed_bytes);\n \treader.ReadData(*protocol, compressed_buffer.ptr, compressed_bytes);\n \n \tDecompressInternal(chunk->meta_data.codec, compressed_buffer.ptr, compressed_bytes, block->ptr + uncompressed_bytes,\n@@ -319,10 +320,6 @@ void ColumnReader::AllocateBlock(idx_t size) {\n \t}\n }\n \n-void ColumnReader::AllocateCompressed(idx_t size) {\n-\tcompressed_buffer.resize(GetAllocator(), size);\n-}\n-\n void ColumnReader::PreparePage(PageHeader &page_hdr) {\n \tAllocateBlock(page_hdr.uncompressed_page_size + 1);\n \tif (chunk->meta_data.codec == CompressionCodec::UNCOMPRESSED) {\n@@ -333,7 +330,8 @@ void ColumnReader::PreparePage(PageHeader &page_hdr) {\n \t\treturn;\n \t}\n \n-\tAllocateCompressed(page_hdr.compressed_page_size + 1);\n+\tResizeableBuffer compressed_buffer;\n+\tcompressed_buffer.resize(GetAllocator(), page_hdr.compressed_page_size + 1);\n \treader.ReadData(*protocol, compressed_buffer.ptr, page_hdr.compressed_page_size);\n \n \tDecompressInternal(chunk->meta_data.codec, compressed_buffer.ptr, page_hdr.compressed_page_size, block->ptr,\ndiff --git a/extension/parquet/include/column_reader.hpp b/extension/parquet/include/column_reader.hpp\nindex 0e77e2a51a84..35544de8e900 100644\n--- a/extension/parquet/include/column_reader.hpp\n+++ b/extension/parquet/include/column_reader.hpp\n@@ -289,7 +289,6 @@ class ColumnReader {\n \n private:\n \tvoid AllocateBlock(idx_t size);\n-\tvoid AllocateCompressed(idx_t size);\n \tvoid PrepareRead(optional_ptr<const TableFilter> filter);\n \tvoid PreparePage(PageHeader &page_hdr);\n \tvoid PrepareDataPage(PageHeader &page_hdr);\n@@ -305,8 +304,6 @@ class ColumnReader {\n \n \tshared_ptr<ResizeableBuffer> block;\n \n-\tResizeableBuffer compressed_buffer;\n-\n \tColumnEncoding encoding = ColumnEncoding::INVALID;\n \tunique_ptr<RleBpDecoder> defined_decoder;\n \tunique_ptr<RleBpDecoder> repeated_decoder;\ndiff --git a/extension/parquet/include/parquet_bss_encoder.hpp b/extension/parquet/include/parquet_bss_encoder.hpp\nindex 49b1ab05b4ae..78f75a0c7572 100644\n--- a/extension/parquet/include/parquet_bss_encoder.hpp\n+++ b/extension/parquet/include/parquet_bss_encoder.hpp\n@@ -30,7 +30,6 @@ class BssEncoder {\n \t}\n \n \tvoid FinishWrite(WriteStream &writer) {\n-\t\tD_ASSERT(count == total_value_count);\n \t\twriter.WriteData(buffer.get(), total_value_count * bit_width);\n \t}\n \ndiff --git a/extension/parquet/include/parquet_dlba_encoder.hpp b/extension/parquet/include/parquet_dlba_encoder.hpp\nindex ef7d19f0cfcb..897dc9c5fead 100644\n--- a/extension/parquet/include/parquet_dlba_encoder.hpp\n+++ b/extension/parquet/include/parquet_dlba_encoder.hpp\n@@ -33,9 +33,8 @@ class DlbaEncoder {\n \t}\n \n \tvoid FinishWrite(WriteStream &writer) {\n-\t\tD_ASSERT(stream->GetPosition() == total_string_size);\n \t\tdbp_encoder.FinishWrite(writer);\n-\t\twriter.WriteData(buffer.get(), total_string_size);\n+\t\twriter.WriteData(buffer.get(), stream->GetPosition());\n \t}\n \n private:\ndiff --git a/extension/parquet/include/writer/boolean_column_writer.hpp b/extension/parquet/include/writer/boolean_column_writer.hpp\nindex f513f15a578f..6c650cb0308f 100644\n--- a/extension/parquet/include/writer/boolean_column_writer.hpp\n+++ b/extension/parquet/include/writer/boolean_column_writer.hpp\n@@ -24,7 +24,7 @@ class BooleanColumnWriter : public PrimitiveColumnWriter {\n \tvoid WriteVector(WriteStream &temp_writer, ColumnWriterStatistics *stats_p, ColumnWriterPageState *state_p,\n \t                 Vector &input_column, idx_t chunk_start, idx_t chunk_end) override;\n \n-\tunique_ptr<ColumnWriterPageState> InitializePageState(PrimitiveColumnWriterState &state) override;\n+\tunique_ptr<ColumnWriterPageState> InitializePageState(PrimitiveColumnWriterState &state, idx_t page_idx) override;\n \tvoid FlushPageState(WriteStream &temp_writer, ColumnWriterPageState *state_p) override;\n \n \tidx_t GetRowSize(const Vector &vector, const idx_t index, const PrimitiveColumnWriterState &state) const override;\ndiff --git a/extension/parquet/include/writer/enum_column_writer.hpp b/extension/parquet/include/writer/enum_column_writer.hpp\nindex 724bfab6def6..ab4772eb23a1 100644\n--- a/extension/parquet/include/writer/enum_column_writer.hpp\n+++ b/extension/parquet/include/writer/enum_column_writer.hpp\n@@ -28,7 +28,7 @@ class EnumColumnWriter : public PrimitiveColumnWriter {\n \tvoid WriteVector(WriteStream &temp_writer, ColumnWriterStatistics *stats_p, ColumnWriterPageState *page_state_p,\n \t                 Vector &input_column, idx_t chunk_start, idx_t chunk_end) override;\n \n-\tunique_ptr<ColumnWriterPageState> InitializePageState(PrimitiveColumnWriterState &state) override;\n+\tunique_ptr<ColumnWriterPageState> InitializePageState(PrimitiveColumnWriterState &state, idx_t page_idx) override;\n \n \tvoid FlushPageState(WriteStream &temp_writer, ColumnWriterPageState *state_p) override;\n \ndiff --git a/extension/parquet/include/writer/primitive_column_writer.hpp b/extension/parquet/include/writer/primitive_column_writer.hpp\nindex 6315efbd7452..f3bea0323b1f 100644\n--- a/extension/parquet/include/writer/primitive_column_writer.hpp\n+++ b/extension/parquet/include/writer/primitive_column_writer.hpp\n@@ -93,7 +93,7 @@ class PrimitiveColumnWriter : public ColumnWriter {\n \tvirtual unique_ptr<ColumnWriterStatistics> InitializeStatsState();\n \n \t//! Initialize the writer for a specific page. Only used for scalar types.\n-\tvirtual unique_ptr<ColumnWriterPageState> InitializePageState(PrimitiveColumnWriterState &state);\n+\tvirtual unique_ptr<ColumnWriterPageState> InitializePageState(PrimitiveColumnWriterState &state, idx_t page_idx);\n \n \t//! Flushes the writer for a specific page. Only used for scalar types.\n \tvirtual void FlushPageState(WriteStream &temp_writer, ColumnWriterPageState *state);\ndiff --git a/extension/parquet/include/writer/templated_column_writer.hpp b/extension/parquet/include/writer/templated_column_writer.hpp\nindex 027af57fe6c5..c5aae83bc502 100644\n--- a/extension/parquet/include/writer/templated_column_writer.hpp\n+++ b/extension/parquet/include/writer/templated_column_writer.hpp\n@@ -126,11 +126,12 @@ class StandardColumnWriter : public PrimitiveColumnWriter {\n \t\treturn std::move(result);\n \t}\n \n-\tunique_ptr<ColumnWriterPageState> InitializePageState(PrimitiveColumnWriterState &state_p) override {\n+\tunique_ptr<ColumnWriterPageState> InitializePageState(PrimitiveColumnWriterState &state_p,\n+\t                                                      idx_t page_idx) override {\n \t\tauto &state = state_p.Cast<StandardColumnWriterState<SRC, TGT, OP>>();\n-\n-\t\tauto result = make_uniq<StandardWriterPageState<SRC, TGT, OP>>(state.total_value_count, state.total_string_size,\n-\t\t                                                               state.encoding, state.dictionary);\n+\t\tconst auto &page_info = state_p.page_info[page_idx];\n+\t\tauto result = make_uniq<StandardWriterPageState<SRC, TGT, OP>>(\n+\t\t    page_info.row_count - page_info.empty_count, state.total_string_size, state.encoding, state.dictionary);\n \t\treturn std::move(result);\n \t}\n \ndiff --git a/extension/parquet/writer/boolean_column_writer.cpp b/extension/parquet/writer/boolean_column_writer.cpp\nindex a8b2f9add185..c9b0e96618a9 100644\n--- a/extension/parquet/writer/boolean_column_writer.cpp\n+++ b/extension/parquet/writer/boolean_column_writer.cpp\n@@ -83,7 +83,8 @@ void BooleanColumnWriter::WriteVector(WriteStream &temp_writer, ColumnWriterStat\n \t}\n }\n \n-unique_ptr<ColumnWriterPageState> BooleanColumnWriter::InitializePageState(PrimitiveColumnWriterState &state) {\n+unique_ptr<ColumnWriterPageState> BooleanColumnWriter::InitializePageState(PrimitiveColumnWriterState &state,\n+                                                                           idx_t page_idx) {\n \treturn make_uniq<BooleanWriterPageState>();\n }\n \ndiff --git a/extension/parquet/writer/enum_column_writer.cpp b/extension/parquet/writer/enum_column_writer.cpp\nindex 8518019efedd..c6ae42827ada 100644\n--- a/extension/parquet/writer/enum_column_writer.cpp\n+++ b/extension/parquet/writer/enum_column_writer.cpp\n@@ -65,7 +65,8 @@ void EnumColumnWriter::WriteVector(WriteStream &temp_writer, ColumnWriterStatist\n \t}\n }\n \n-unique_ptr<ColumnWriterPageState> EnumColumnWriter::InitializePageState(PrimitiveColumnWriterState &state) {\n+unique_ptr<ColumnWriterPageState> EnumColumnWriter::InitializePageState(PrimitiveColumnWriterState &state,\n+                                                                        idx_t page_idx) {\n \treturn make_uniq<EnumWriterPageState>(bit_width);\n }\n \ndiff --git a/extension/parquet/writer/primitive_column_writer.cpp b/extension/parquet/writer/primitive_column_writer.cpp\nindex 9e3515de9d78..e1f54ca88002 100644\n--- a/extension/parquet/writer/primitive_column_writer.cpp\n+++ b/extension/parquet/writer/primitive_column_writer.cpp\n@@ -28,7 +28,8 @@ void PrimitiveColumnWriter::RegisterToRowGroup(duckdb_parquet::RowGroup &row_gro\n \trow_group.columns.push_back(std::move(column_chunk));\n }\n \n-unique_ptr<ColumnWriterPageState> PrimitiveColumnWriter::InitializePageState(PrimitiveColumnWriterState &state) {\n+unique_ptr<ColumnWriterPageState> PrimitiveColumnWriter::InitializePageState(PrimitiveColumnWriterState &state,\n+                                                                             idx_t page_idx) {\n \treturn nullptr;\n }\n \n@@ -114,7 +115,7 @@ void PrimitiveColumnWriter::BeginWrite(ColumnWriterState &state_p) {\n \t\t    MaxValue<idx_t>(NextPowerOfTwo(page_info.estimated_page_size), MemoryStream::DEFAULT_INITIAL_CAPACITY));\n \t\twrite_info.write_count = page_info.empty_count;\n \t\twrite_info.max_write_count = page_info.row_count;\n-\t\twrite_info.page_state = InitializePageState(state);\n+\t\twrite_info.page_state = InitializePageState(state, page_idx);\n \n \t\twrite_info.compressed_size = 0;\n \t\twrite_info.compressed_data = nullptr;\ndiff --git a/src/execution/index/art/iterator.cpp b/src/execution/index/art/iterator.cpp\nindex 689029a02e40..1c138e1d3e34 100644\n--- a/src/execution/index/art/iterator.cpp\n+++ b/src/execution/index/art/iterator.cpp\n@@ -46,9 +46,11 @@ bool Iterator::Scan(const ARTKey &upper_bound, const idx_t max_count, unsafe_vec\n \tbool has_next;\n \tdo {\n \t\t// An empty upper bound indicates that no upper bound exists.\n-\t\tif (!upper_bound.Empty() && status == GateStatus::GATE_NOT_SET) {\n-\t\t\tif (current_key.GreaterThan(upper_bound, equal, nested_depth)) {\n-\t\t\t\treturn true;\n+\t\tif (!upper_bound.Empty()) {\n+\t\t\tif (status == GateStatus::GATE_NOT_SET || entered_nested_leaf) {\n+\t\t\t\tif (current_key.GreaterThan(upper_bound, equal, nested_depth)) {\n+\t\t\t\t\treturn true;\n+\t\t\t\t}\n \t\t\t}\n \t\t}\n \n@@ -86,6 +88,7 @@ bool Iterator::Scan(const ARTKey &upper_bound, const idx_t max_count, unsafe_vec\n \t\t\tthrow InternalException(\"Invalid leaf type for index scan.\");\n \t\t}\n \n+\t\tentered_nested_leaf = false;\n \t\thas_next = Next();\n \t} while (has_next);\n \treturn true;\n@@ -104,6 +107,7 @@ void Iterator::FindMinimum(const Node &node) {\n \tif (node.GetGateStatus() == GateStatus::GATE_SET) {\n \t\tD_ASSERT(status == GateStatus::GATE_NOT_SET);\n \t\tstatus = GateStatus::GATE_SET;\n+\t\tentered_nested_leaf = true;\n \t\tnested_depth = 0;\n \t}\n \ndiff --git a/src/execution/operator/csv_scanner/encode/csv_encoder.cpp b/src/execution/operator/csv_scanner/encode/csv_encoder.cpp\nindex 89fc5df040bd..8a6c08032597 100644\n--- a/src/execution/operator/csv_scanner/encode/csv_encoder.cpp\n+++ b/src/execution/operator/csv_scanner/encode/csv_encoder.cpp\n@@ -51,6 +51,10 @@ CSVEncoder::CSVEncoder(DBConfig &config, const string &encoding_name_to_find, id\n \t}\n \t// We ensure that the encoded buffer size is an even number to make the two byte lookup on utf-16 work\n \tidx_t encoded_buffer_size = buffer_size % 2 != 0 ? buffer_size - 1 : buffer_size;\n+\tif (encoded_buffer_size == 0) {\n+\t\t// This might happen if buffer size = 1\n+\t\tencoded_buffer_size = 2;\n+\t}\n \tD_ASSERT(encoded_buffer_size > 0);\n \tencoded_buffer.Initialize(encoded_buffer_size);\n \tremaining_bytes_buffer.Initialize(function->GetBytesPerIteration());\ndiff --git a/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp b/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\nindex 94ef37399510..266f35196af5 100644\n--- a/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\n+++ b/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\n@@ -688,23 +688,29 @@ bool LineError::HandleErrors(StringValueResult &result) {\n \t\t\t\t    line_pos.GetGlobalPosition(result.requested_size), result.path);\n \t\t\t}\n \t\t\tbreak;\n-\t\tcase CAST_ERROR:\n+\t\tcase CAST_ERROR: {\n+\t\t\tstring column_name;\n+\t\t\tLogicalTypeId type_id;\n+\t\t\tif (cur_error.col_idx < result.names.size()) {\n+\t\t\t\tcolumn_name = result.names[cur_error.col_idx];\n+\t\t\t}\n+\t\t\tif (cur_error.col_idx < result.number_of_columns) {\n+\t\t\t\ttype_id = result.parse_types[cur_error.chunk_idx].type_id;\n+\t\t\t}\n \t\t\tif (result.current_line_position.begin == line_pos) {\n \t\t\t\tcsv_error = CSVError::CastError(\n-\t\t\t\t    result.state_machine.options, result.names[cur_error.col_idx], cur_error.error_message,\n-\t\t\t\t    cur_error.col_idx, borked_line, lines_per_batch,\n+\t\t\t\t    result.state_machine.options, column_name, cur_error.error_message, cur_error.col_idx, borked_line,\n+\t\t\t\t    lines_per_batch,\n \t\t\t\t    result.current_line_position.begin.GetGlobalPosition(result.requested_size, first_nl),\n-\t\t\t\t    line_pos.GetGlobalPosition(result.requested_size, first_nl),\n-\t\t\t\t    result.parse_types[cur_error.chunk_idx].type_id, result.path);\n+\t\t\t\t    line_pos.GetGlobalPosition(result.requested_size, first_nl), type_id, result.path);\n \t\t\t} else {\n \t\t\t\tcsv_error = CSVError::CastError(\n-\t\t\t\t    result.state_machine.options, result.names[cur_error.col_idx], cur_error.error_message,\n-\t\t\t\t    cur_error.col_idx, borked_line, lines_per_batch,\n+\t\t\t\t    result.state_machine.options, column_name, cur_error.error_message, cur_error.col_idx, borked_line,\n+\t\t\t\t    lines_per_batch,\n \t\t\t\t    result.current_line_position.begin.GetGlobalPosition(result.requested_size, first_nl),\n-\t\t\t\t    line_pos.GetGlobalPosition(result.requested_size), result.parse_types[cur_error.chunk_idx].type_id,\n-\t\t\t\t    result.path);\n+\t\t\t\t    line_pos.GetGlobalPosition(result.requested_size), type_id, result.path);\n \t\t\t}\n-\t\t\tbreak;\n+\t\t} break;\n \t\tcase MAXIMUM_LINE_SIZE:\n \t\t\tcsv_error = CSVError::LineSizeError(\n \t\t\t    result.state_machine.options, lines_per_batch, borked_line,\ndiff --git a/src/execution/operator/csv_scanner/util/csv_reader_options.cpp b/src/execution/operator/csv_scanner/util/csv_reader_options.cpp\nindex 9f7391eaa7a8..a4e0c82440cc 100644\n--- a/src/execution/operator/csv_scanner/util/csv_reader_options.cpp\n+++ b/src/execution/operator/csv_scanner/util/csv_reader_options.cpp\n@@ -254,6 +254,10 @@ void CSVReaderOptions::SetReadOption(const string &loption, const Value &value,\n \t\t\tthrow BinderException(\"Invalid value for MAX_LINE_SIZE parameter: it cannot be smaller than 0\");\n \t\t}\n \t\tmaximum_line_size.Set(NumericCast<idx_t>(line_size));\n+\t\tif (buffer_size_option.IsSetByUser() && maximum_line_size.GetValue() > buffer_size_option.GetValue()) {\n+\t\t\tthrow InvalidInputException(\"Buffer Size of %d must be a higher value than the maximum line size %d\",\n+\t\t\t                            buffer_size_option.GetValue(), maximum_line_size.GetValue());\n+\t\t}\n \t} else if (loption == \"date_format\" || loption == \"dateformat\") {\n \t\tstring format = ParseString(value, loption);\n \t\tSetDateFormat(LogicalTypeId::DATE, format, true);\n@@ -267,6 +271,12 @@ void CSVReaderOptions::SetReadOption(const string &loption, const Value &value,\n \t\tif (buffer_size_option == 0) {\n \t\t\tthrow InvalidInputException(\"Buffer Size option must be higher than 0\");\n \t\t}\n+\t\tif (maximum_line_size.IsSetByUser() && maximum_line_size.GetValue() > buffer_size_option.GetValue()) {\n+\t\t\tthrow InvalidInputException(\"Buffer Size of %d must be a higher value than the maximum line size %d\",\n+\t\t\t                            buffer_size_option.GetValue(), maximum_line_size.GetValue());\n+\t\t} else {\n+\t\t\tmaximum_line_size.Set(buffer_size_option.GetValue(), false);\n+\t\t}\n \t} else if (loption == \"decimal_separator\") {\n \t\tdecimal_separator = ParseString(value, loption);\n \t\tif (decimal_separator != \".\" && decimal_separator != \",\") {\n@@ -301,6 +311,9 @@ void CSVReaderOptions::SetReadOption(const string &loption, const Value &value,\n \t\tif (table_name.empty()) {\n \t\t\tthrow BinderException(\"REJECTS_TABLE option cannot be empty\");\n \t\t}\n+\t\tif (KeywordHelper::RequiresQuotes(table_name)) {\n+\t\t\tthrow BinderException(\"rejects_scan option: %s requires quotes to be used as an identifier\", table_name);\n+\t\t}\n \t\trejects_table_name.Set(table_name);\n \t} else if (loption == \"rejects_scan\") {\n \t\t// skip, handled in SetRejectsOptions\n@@ -308,6 +321,9 @@ void CSVReaderOptions::SetReadOption(const string &loption, const Value &value,\n \t\tif (table_name.empty()) {\n \t\t\tthrow BinderException(\"rejects_scan option cannot be empty\");\n \t\t}\n+\t\tif (KeywordHelper::RequiresQuotes(table_name)) {\n+\t\t\tthrow BinderException(\"rejects_scan option: %s requires quotes to be used as an identifier\", table_name);\n+\t\t}\n \t\trejects_scan_name.Set(table_name);\n \t} else if (loption == \"rejects_limit\") {\n \t\tauto limit = ParseInteger(value, loption);\ndiff --git a/src/execution/operator/helper/physical_streaming_sample.cpp b/src/execution/operator/helper/physical_streaming_sample.cpp\nindex 309256244927..ed9e21f35195 100644\n--- a/src/execution/operator/helper/physical_streaming_sample.cpp\n+++ b/src/execution/operator/helper/physical_streaming_sample.cpp\n@@ -5,10 +5,11 @@\n \n namespace duckdb {\n \n-PhysicalStreamingSample::PhysicalStreamingSample(vector<LogicalType> types, SampleMethod method, double percentage,\n-                                                 int64_t seed, idx_t estimated_cardinality)\n-    : PhysicalOperator(PhysicalOperatorType::STREAMING_SAMPLE, std::move(types), estimated_cardinality), method(method),\n-      percentage(percentage / 100), seed(seed) {\n+PhysicalStreamingSample::PhysicalStreamingSample(vector<LogicalType> types, unique_ptr<SampleOptions> options,\n+                                                 idx_t estimated_cardinality)\n+    : PhysicalOperator(PhysicalOperatorType::STREAMING_SAMPLE, std::move(types), estimated_cardinality),\n+      sample_options(std::move(options)) {\n+\tpercentage = sample_options->sample_size.GetValue<double>() / 100;\n }\n \n //===--------------------------------------------------------------------===//\n@@ -49,13 +50,21 @@ void PhysicalStreamingSample::BernoulliSample(DataChunk &input, DataChunk &resul\n \t}\n }\n \n+bool PhysicalStreamingSample::ParallelOperator() const {\n+\treturn !(sample_options->repeatable || sample_options->seed.IsValid());\n+}\n+\n unique_ptr<OperatorState> PhysicalStreamingSample::GetOperatorState(ExecutionContext &context) const {\n-\treturn make_uniq<StreamingSampleOperatorState>(seed);\n+\tif (!ParallelOperator()) {\n+\t\treturn make_uniq<StreamingSampleOperatorState>(static_cast<int64_t>(sample_options->seed.GetIndex()));\n+\t}\n+\tRandomEngine random;\n+\treturn make_uniq<StreamingSampleOperatorState>(static_cast<int64_t>(random.NextRandomInteger64()));\n }\n \n OperatorResultType PhysicalStreamingSample::Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n                                                     GlobalOperatorState &gstate, OperatorState &state) const {\n-\tswitch (method) {\n+\tswitch (sample_options->method) {\n \tcase SampleMethod::BERNOULLI_SAMPLE:\n \t\tBernoulliSample(input, chunk, state);\n \t\tbreak;\n@@ -70,7 +79,7 @@ OperatorResultType PhysicalStreamingSample::Execute(ExecutionContext &context, D\n \n InsertionOrderPreservingMap<string> PhysicalStreamingSample::ParamsToString() const {\n \tInsertionOrderPreservingMap<string> result;\n-\tresult[\"Sample Method\"] = EnumUtil::ToString(method) + \": \" + to_string(100 * percentage) + \"%\";\n+\tresult[\"Sample Method\"] = EnumUtil::ToString(sample_options->method) + \": \" + to_string(100 * percentage) + \"%\";\n \treturn result;\n }\n \ndiff --git a/src/execution/operator/persistent/physical_batch_insert.cpp b/src/execution/operator/persistent/physical_batch_insert.cpp\nindex 2e546c477282..f898af2c7014 100644\n--- a/src/execution/operator/persistent/physical_batch_insert.cpp\n+++ b/src/execution/operator/persistent/physical_batch_insert.cpp\n@@ -215,7 +215,9 @@ class MergeCollectionTask : public BatchInsertTask {\n \t\tauto &gstate = gstate_p.Cast<BatchInsertGlobalState>();\n \t\tauto &lstate = lstate_p.Cast<BatchInsertLocalState>();\n \t\t// merge together the collections\n-\t\tD_ASSERT(lstate.writer);\n+\t\tif (!lstate.writer) {\n+\t\t\tlstate.writer = &gstate.table.GetStorage().CreateOptimisticWriter(context);\n+\t\t}\n \t\tauto final_collection = gstate.MergeCollections(context, std::move(merge_collections), *lstate.writer);\n \t\t// add the merged-together collection to the set of batch indexes\n \t\tlock_guard<mutex> l(gstate.lock);\ndiff --git a/src/execution/physical_plan/plan_sample.cpp b/src/execution/physical_plan/plan_sample.cpp\nindex be55784779fb..883c7055d46f 100644\n--- a/src/execution/physical_plan/plan_sample.cpp\n+++ b/src/execution/physical_plan/plan_sample.cpp\n@@ -28,9 +28,7 @@ unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalSample &op\n \t\t\t                      \"reservoir sampling or use a sample_size\",\n \t\t\t                      EnumUtil::ToString(op.sample_options->method));\n \t\t}\n-\t\tsample = make_uniq<PhysicalStreamingSample>(\n-\t\t    op.types, op.sample_options->method, op.sample_options->sample_size.GetValue<double>(),\n-\t\t    static_cast<int64_t>(op.sample_options->seed.GetIndex()), op.estimated_cardinality);\n+\t\tsample = make_uniq<PhysicalStreamingSample>(op.types, std::move(op.sample_options), op.estimated_cardinality);\n \t\tbreak;\n \tdefault:\n \t\tthrow InternalException(\"Unimplemented sample method\");\ndiff --git a/src/function/scalar/generic/getvariable.cpp b/src/function/scalar/generic/getvariable.cpp\nindex 14d32954d1cf..0181c07523bc 100644\n--- a/src/function/scalar/generic/getvariable.cpp\n+++ b/src/function/scalar/generic/getvariable.cpp\n@@ -24,12 +24,12 @@ struct GetVariableBindData : FunctionData {\n \n static unique_ptr<FunctionData> GetVariableBind(ClientContext &context, ScalarFunction &function,\n                                                 vector<unique_ptr<Expression>> &arguments) {\n+\tif (arguments[0]->HasParameter() || arguments[0]->return_type.id() == LogicalTypeId::UNKNOWN) {\n+\t\tthrow ParameterNotResolvedException();\n+\t}\n \tif (!arguments[0]->IsFoldable()) {\n \t\tthrow NotImplementedException(\"getvariable requires a constant input\");\n \t}\n-\tif (arguments[0]->HasParameter()) {\n-\t\tthrow ParameterNotResolvedException();\n-\t}\n \tValue value;\n \tauto variable_name = ExpressionExecutor::EvaluateScalar(context, *arguments[0]);\n \tif (!variable_name.IsNull()) {\ndiff --git a/src/function/window/window_boundaries_state.cpp b/src/function/window/window_boundaries_state.cpp\nindex ce3ba3bbeb85..a4b034441d38 100644\n--- a/src/function/window/window_boundaries_state.cpp\n+++ b/src/function/window/window_boundaries_state.cpp\n@@ -180,9 +180,9 @@ struct OperationCompare : public std::function<bool(T, T)> {\n };\n \n template <typename T, typename OP, bool FROM>\n-static idx_t FindTypedRangeBound(WindowCursor &over, const idx_t order_begin, const idx_t order_end,\n-                                 const WindowBoundary range, WindowInputExpression &boundary, const idx_t chunk_idx,\n-                                 const FrameBounds &prev) {\n+static idx_t FindTypedRangeBound(WindowCursor &range_lo, WindowCursor &range_hi, const idx_t order_begin,\n+                                 const idx_t order_end, const WindowBoundary range, WindowInputExpression &boundary,\n+                                 const idx_t chunk_idx, const FrameBounds &prev) {\n \tD_ASSERT(!boundary.CellIsNull(chunk_idx));\n \tconst auto val = boundary.GetCell<T>(chunk_idx);\n \n@@ -191,14 +191,14 @@ static idx_t FindTypedRangeBound(WindowCursor &over, const idx_t order_begin, co\n \t// Check that the value we are searching for is in range.\n \tif (range == WindowBoundary::EXPR_PRECEDING_RANGE) {\n \t\t//\tPreceding but value past the current value\n-\t\tconst auto cur_val = over.GetCell<T>(0, order_end - 1);\n+\t\tconst auto cur_val = range_hi.GetCell<T>(0, order_end - 1);\n \t\tif (comp(cur_val, val)) {\n \t\t\tthrow OutOfRangeException(\"Invalid RANGE PRECEDING value\");\n \t\t}\n \t} else {\n \t\t//\tFollowing but value before the current value\n \t\tD_ASSERT(range == WindowBoundary::EXPR_FOLLOWING_RANGE);\n-\t\tconst auto cur_val = over.GetCell<T>(0, order_begin);\n+\t\tconst auto cur_val = range_lo.GetCell<T>(0, order_begin);\n \t\tif (comp(val, cur_val)) {\n \t\t\tthrow OutOfRangeException(\"Invalid RANGE FOLLOWING value\");\n \t\t}\n@@ -206,20 +206,28 @@ static idx_t FindTypedRangeBound(WindowCursor &over, const idx_t order_begin, co\n \t//\tTry to reuse the previous bounds to restrict the search.\n \t//\tThis is only valid if the previous bounds were non-empty\n \t//\tOnly inject the comparisons if the previous bounds are a strict subset.\n-\tWindowColumnIterator<T> begin(over, order_begin);\n-\tWindowColumnIterator<T> end(over, order_end);\n+\tWindowColumnIterator<T> begin(range_lo, order_begin);\n+\tWindowColumnIterator<T> end(range_hi, order_end);\n \tif (prev.start < prev.end) {\n \t\tif (order_begin < prev.start && prev.start < order_end) {\n-\t\t\tconst auto first = over.GetCell<T>(0, prev.start);\n-\t\t\tif (!comp(val, first)) {\n-\t\t\t\t//\tprev.first <= val, so we can start further forward\n+\t\t\tconst auto first = range_lo.GetCell<T>(0, prev.start);\n+\t\t\tif (FROM && !comp(val, first)) {\n+\t\t\t\t// If prev.start == val and we are looking for a lower bound, then we are done\n+\t\t\t\tif (!comp(first, val)) {\n+\t\t\t\t\treturn prev.start;\n+\t\t\t\t}\n+\t\t\t\t//\tprev.start <= val, so we can start further forward\n \t\t\t\tbegin += UnsafeNumericCast<int64_t>(prev.start - order_begin);\n \t\t\t}\n \t\t}\n \t\tif (order_begin < prev.end && prev.end < order_end) {\n-\t\t\tconst auto second = over.GetCell<T>(0, prev.end - 1);\n+\t\t\tconst auto second = range_hi.GetCell<T>(0, prev.end - 1);\n \t\t\tif (!comp(second, val)) {\n-\t\t\t\t//\tval <= prev.second, so we can end further back\n+\t\t\t\t//  If val == prev.end and we are looking for an upper bound, then we are done\n+\t\t\t\tif (!FROM && !comp(val, second)) {\n+\t\t\t\t\treturn prev.end;\n+\t\t\t\t}\n+\t\t\t\t//\tval <= prev.end, so we can end further back\n \t\t\t\t// (prev.second is the largest peer)\n \t\t\t\tend -= UnsafeNumericCast<int64_t>(order_end - prev.end - 1);\n \t\t\t}\n@@ -234,52 +242,65 @@ static idx_t FindTypedRangeBound(WindowCursor &over, const idx_t order_begin, co\n }\n \n template <typename OP, bool FROM>\n-static idx_t FindRangeBound(WindowCursor &over, const idx_t order_begin, const idx_t order_end,\n-                            const WindowBoundary range, WindowInputExpression &boundary, const idx_t chunk_idx,\n-                            const FrameBounds &prev) {\n+static idx_t FindRangeBound(WindowCursor &range_lo, WindowCursor &range_hi, const idx_t order_begin,\n+                            const idx_t order_end, const WindowBoundary range, WindowInputExpression &boundary,\n+                            const idx_t chunk_idx, const FrameBounds &prev) {\n \tswitch (boundary.InternalType()) {\n \tcase PhysicalType::INT8:\n-\t\treturn FindTypedRangeBound<int8_t, OP, FROM>(over, order_begin, order_end, range, boundary, chunk_idx, prev);\n+\t\treturn FindTypedRangeBound<int8_t, OP, FROM>(range_lo, range_hi, order_begin, order_end, range, boundary,\n+\t\t                                             chunk_idx, prev);\n \tcase PhysicalType::INT16:\n-\t\treturn FindTypedRangeBound<int16_t, OP, FROM>(over, order_begin, order_end, range, boundary, chunk_idx, prev);\n+\t\treturn FindTypedRangeBound<int16_t, OP, FROM>(range_lo, range_hi, order_begin, order_end, range, boundary,\n+\t\t                                              chunk_idx, prev);\n \tcase PhysicalType::INT32:\n-\t\treturn FindTypedRangeBound<int32_t, OP, FROM>(over, order_begin, order_end, range, boundary, chunk_idx, prev);\n+\t\treturn FindTypedRangeBound<int32_t, OP, FROM>(range_lo, range_hi, order_begin, order_end, range, boundary,\n+\t\t                                              chunk_idx, prev);\n \tcase PhysicalType::INT64:\n-\t\treturn FindTypedRangeBound<int64_t, OP, FROM>(over, order_begin, order_end, range, boundary, chunk_idx, prev);\n+\t\treturn FindTypedRangeBound<int64_t, OP, FROM>(range_lo, range_hi, order_begin, order_end, range, boundary,\n+\t\t                                              chunk_idx, prev);\n \tcase PhysicalType::UINT8:\n-\t\treturn FindTypedRangeBound<uint8_t, OP, FROM>(over, order_begin, order_end, range, boundary, chunk_idx, prev);\n+\t\treturn FindTypedRangeBound<uint8_t, OP, FROM>(range_lo, range_hi, order_begin, order_end, range, boundary,\n+\t\t                                              chunk_idx, prev);\n \tcase PhysicalType::UINT16:\n-\t\treturn FindTypedRangeBound<uint16_t, OP, FROM>(over, order_begin, order_end, range, boundary, chunk_idx, prev);\n+\t\treturn FindTypedRangeBound<uint16_t, OP, FROM>(range_lo, range_hi, order_begin, order_end, range, boundary,\n+\t\t                                               chunk_idx, prev);\n \tcase PhysicalType::UINT32:\n-\t\treturn FindTypedRangeBound<uint32_t, OP, FROM>(over, order_begin, order_end, range, boundary, chunk_idx, prev);\n+\t\treturn FindTypedRangeBound<uint32_t, OP, FROM>(range_lo, range_hi, order_begin, order_end, range, boundary,\n+\t\t                                               chunk_idx, prev);\n \tcase PhysicalType::UINT64:\n-\t\treturn FindTypedRangeBound<uint64_t, OP, FROM>(over, order_begin, order_end, range, boundary, chunk_idx, prev);\n+\t\treturn FindTypedRangeBound<uint64_t, OP, FROM>(range_lo, range_hi, order_begin, order_end, range, boundary,\n+\t\t                                               chunk_idx, prev);\n \tcase PhysicalType::INT128:\n-\t\treturn FindTypedRangeBound<hugeint_t, OP, FROM>(over, order_begin, order_end, range, boundary, chunk_idx, prev);\n+\t\treturn FindTypedRangeBound<hugeint_t, OP, FROM>(range_lo, range_hi, order_begin, order_end, range, boundary,\n+\t\t                                                chunk_idx, prev);\n \tcase PhysicalType::UINT128:\n-\t\treturn FindTypedRangeBound<uhugeint_t, OP, FROM>(over, order_begin, order_end, range, boundary, chunk_idx,\n-\t\t                                                 prev);\n+\t\treturn FindTypedRangeBound<uhugeint_t, OP, FROM>(range_lo, range_hi, order_begin, order_end, range, boundary,\n+\t\t                                                 chunk_idx, prev);\n \tcase PhysicalType::FLOAT:\n-\t\treturn FindTypedRangeBound<float, OP, FROM>(over, order_begin, order_end, range, boundary, chunk_idx, prev);\n+\t\treturn FindTypedRangeBound<float, OP, FROM>(range_lo, range_hi, order_begin, order_end, range, boundary,\n+\t\t                                            chunk_idx, prev);\n \tcase PhysicalType::DOUBLE:\n-\t\treturn FindTypedRangeBound<double, OP, FROM>(over, order_begin, order_end, range, boundary, chunk_idx, prev);\n+\t\treturn FindTypedRangeBound<double, OP, FROM>(range_lo, range_hi, order_begin, order_end, range, boundary,\n+\t\t                                             chunk_idx, prev);\n \tcase PhysicalType::INTERVAL:\n-\t\treturn FindTypedRangeBound<interval_t, OP, FROM>(over, order_begin, order_end, range, boundary, chunk_idx,\n-\t\t                                                 prev);\n+\t\treturn FindTypedRangeBound<interval_t, OP, FROM>(range_lo, range_hi, order_begin, order_end, range, boundary,\n+\t\t                                                 chunk_idx, prev);\n \tdefault:\n \t\tthrow InternalException(\"Unsupported column type for RANGE\");\n \t}\n }\n \n template <bool FROM>\n-static idx_t FindOrderedRangeBound(WindowCursor &over, const OrderType range_sense, const idx_t order_begin,\n-                                   const idx_t order_end, const WindowBoundary range, WindowInputExpression &boundary,\n-                                   const idx_t chunk_idx, const FrameBounds &prev) {\n+static idx_t FindOrderedRangeBound(WindowCursor &range_lo, WindowCursor &range_hi, const OrderType range_sense,\n+                                   const idx_t order_begin, const idx_t order_end, const WindowBoundary range,\n+                                   WindowInputExpression &boundary, const idx_t chunk_idx, const FrameBounds &prev) {\n \tswitch (range_sense) {\n \tcase OrderType::ASCENDING:\n-\t\treturn FindRangeBound<LessThan, FROM>(over, order_begin, order_end, range, boundary, chunk_idx, prev);\n+\t\treturn FindRangeBound<LessThan, FROM>(range_lo, range_hi, order_begin, order_end, range, boundary, chunk_idx,\n+\t\t                                      prev);\n \tcase OrderType::DESCENDING:\n-\t\treturn FindRangeBound<GreaterThan, FROM>(over, order_begin, order_end, range, boundary, chunk_idx, prev);\n+\t\treturn FindRangeBound<GreaterThan, FROM>(range_lo, range_hi, order_begin, order_end, range, boundary, chunk_idx,\n+\t\t                                         prev);\n \tdefault:\n \t\tthrow InternalException(\"Unsupported ORDER BY sense for RANGE\");\n \t}\n@@ -718,6 +739,13 @@ void WindowBoundariesState::FrameBegin(DataChunk &bounds, idx_t row_idx, const i\n \tprev.start = valid_begin_data[0];\n \tprev.end = valid_end_data[0];\n \n+\tif (has_preceding_range || has_following_range) {\n+\t\tif (range_lo.get() != range.get()) {\n+\t\t\trange_lo = range.get();\n+\t\t\trange_hi = range_lo->Copy();\n+\t\t}\n+\t}\n+\n \tswitch (start_boundary) {\n \tcase WindowBoundary::UNBOUNDED_PRECEDING:\n \t\tbounds.data[FRAME_BEGIN].Reference(bounds.data[PARTITION_BEGIN]);\n@@ -766,7 +794,12 @@ void WindowBoundariesState::FrameBegin(DataChunk &bounds, idx_t row_idx, const i\n \t\t\t} else {\n \t\t\t\tconst auto valid_start = valid_begin_data[chunk_idx];\n \t\t\t\tprev.end = valid_end_data[chunk_idx];\n-\t\t\t\twindow_start = FindOrderedRangeBound<true>(*range, range_sense, valid_start, row_idx + 1,\n+\t\t\t\tconst auto cur_partition = partition_begin_data[chunk_idx];\n+\t\t\t\tif (cur_partition != prev_partition) {\n+\t\t\t\t\tprev.start = valid_start;\n+\t\t\t\t\tprev_partition = cur_partition;\n+\t\t\t\t}\n+\t\t\t\twindow_start = FindOrderedRangeBound<true>(*range_lo, *range_hi, range_sense, valid_start, row_idx + 1,\n \t\t\t\t                                           start_boundary, boundary_begin, chunk_idx, prev);\n \t\t\t\tprev.start = window_start;\n \t\t\t}\n@@ -785,8 +818,8 @@ void WindowBoundariesState::FrameBegin(DataChunk &bounds, idx_t row_idx, const i\n \t\t\t\t\tprev.start = valid_begin_data[chunk_idx];\n \t\t\t\t\tprev_partition = cur_partition;\n \t\t\t\t}\n-\t\t\t\twindow_start = FindOrderedRangeBound<true>(*range, range_sense, row_idx, valid_end, start_boundary,\n-\t\t\t\t                                           boundary_begin, chunk_idx, prev);\n+\t\t\t\twindow_start = FindOrderedRangeBound<true>(*range_lo, *range_hi, range_sense, row_idx, valid_end,\n+\t\t\t\t                                           start_boundary, boundary_begin, chunk_idx, prev);\n \t\t\t\tprev.start = window_start;\n \t\t\t}\n \t\t\tframe_begin_data[chunk_idx] = window_start;\n@@ -862,6 +895,13 @@ void WindowBoundariesState::FrameEnd(DataChunk &bounds, idx_t row_idx, const idx\n \tprev.start = valid_begin_data[0];\n \tprev.end = valid_end_data[0];\n \n+\tif (has_preceding_range || has_following_range) {\n+\t\tif (range_lo.get() != range.get()) {\n+\t\t\trange_lo = range.get();\n+\t\t\trange_hi = range_lo->Copy();\n+\t\t}\n+\t}\n+\n \tswitch (end_boundary) {\n \tcase WindowBoundary::CURRENT_ROW_ROWS:\n \t\tfor (idx_t chunk_idx = 0; chunk_idx < count; ++chunk_idx, ++row_idx) {\n@@ -911,8 +951,13 @@ void WindowBoundariesState::FrameEnd(DataChunk &bounds, idx_t row_idx, const idx\n \t\t\t} else {\n \t\t\t\tconst auto valid_start = valid_begin_data[chunk_idx];\n \t\t\t\tprev.start = valid_start;\n-\t\t\t\twindow_end = FindOrderedRangeBound<false>(*range, range_sense, valid_start, row_idx + 1, end_boundary,\n-\t\t\t\t                                          boundary_end, chunk_idx, prev);\n+\t\t\t\tconst auto cur_partition = partition_begin_data[chunk_idx];\n+\t\t\t\tif (cur_partition != prev_partition) {\n+\t\t\t\t\tprev.end = valid_end;\n+\t\t\t\t\tprev_partition = cur_partition;\n+\t\t\t\t}\n+\t\t\t\twindow_end = FindOrderedRangeBound<false>(*range_lo, *range_hi, range_sense, valid_start, row_idx + 1,\n+\t\t\t\t                                          end_boundary, boundary_end, chunk_idx, prev);\n \t\t\t\tprev.end = window_end;\n \t\t\t}\n \t\t\tframe_end_data[chunk_idx] = window_end;\n@@ -930,8 +975,8 @@ void WindowBoundariesState::FrameEnd(DataChunk &bounds, idx_t row_idx, const idx\n \t\t\t\t\tprev.end = valid_end;\n \t\t\t\t\tprev_partition = cur_partition;\n \t\t\t\t}\n-\t\t\t\twindow_end = FindOrderedRangeBound<false>(*range, range_sense, row_idx, valid_end, end_boundary,\n-\t\t\t\t                                          boundary_end, chunk_idx, prev);\n+\t\t\t\twindow_end = FindOrderedRangeBound<false>(*range_lo, *range_hi, range_sense, row_idx, valid_end,\n+\t\t\t\t                                          end_boundary, boundary_end, chunk_idx, prev);\n \t\t\t\tprev.end = window_end;\n \t\t\t}\n \t\t\tframe_end_data[chunk_idx] = window_end;\ndiff --git a/src/include/duckdb/execution/index/art/iterator.hpp b/src/include/duckdb/execution/index/art/iterator.hpp\nindex 58a0f106d54d..977cc7791081 100644\n--- a/src/include/duckdb/execution/index/art/iterator.hpp\n+++ b/src/include/duckdb/execution/index/art/iterator.hpp\n@@ -90,6 +90,8 @@ class Iterator {\n \tGateStatus status;\n \t//! Depth in a nested leaf.\n \tuint8_t nested_depth = 0;\n+\t//! True, if we entered a nested leaf to retrieve the next node.\n+\tbool entered_nested_leaf = false;\n \n private:\n \t//! Goes to the next leaf in the ART and sets it as last_leaf,\ndiff --git a/src/include/duckdb/execution/operator/helper/physical_streaming_sample.hpp b/src/include/duckdb/execution/operator/helper/physical_streaming_sample.hpp\nindex dafaf849f556..6f75b2cf1964 100644\n--- a/src/include/duckdb/execution/operator/helper/physical_streaming_sample.hpp\n+++ b/src/include/duckdb/execution/operator/helper/physical_streaming_sample.hpp\n@@ -19,12 +19,10 @@ class PhysicalStreamingSample : public PhysicalOperator {\n \tstatic constexpr const PhysicalOperatorType TYPE = PhysicalOperatorType::STREAMING_SAMPLE;\n \n public:\n-\tPhysicalStreamingSample(vector<LogicalType> types, SampleMethod method, double percentage, int64_t seed,\n-\t                        idx_t estimated_cardinality);\n+\tPhysicalStreamingSample(vector<LogicalType> types, unique_ptr<SampleOptions> options, idx_t estimated_cardinality);\n \n-\tSampleMethod method;\n+\tunique_ptr<SampleOptions> sample_options;\n \tdouble percentage;\n-\tint64_t seed;\n \n public:\n \t// Operator interface\n@@ -32,9 +30,7 @@ class PhysicalStreamingSample : public PhysicalOperator {\n \tOperatorResultType Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n \t                           GlobalOperatorState &gstate, OperatorState &state) const override;\n \n-\tbool ParallelOperator() const override {\n-\t\treturn true;\n-\t}\n+\tbool ParallelOperator() const override;\n \n \tInsertionOrderPreservingMap<string> ParamsToString() const override;\n \ndiff --git a/src/include/duckdb/function/window/window_boundaries_state.hpp b/src/include/duckdb/function/window/window_boundaries_state.hpp\nindex 2748bc7a0600..11c724d9b638 100644\n--- a/src/include/duckdb/function/window/window_boundaries_state.hpp\n+++ b/src/include/duckdb/function/window/window_boundaries_state.hpp\n@@ -148,6 +148,10 @@ struct WindowBoundariesState {\n \tidx_t valid_end = 0;\n \n \tFrameBounds prev;\n+\n+\t// Extra range cursor\n+\toptional_ptr<WindowCursor> range_lo;\n+\tunique_ptr<WindowCursor> range_hi;\n };\n \n } // namespace duckdb\ndiff --git a/src/include/duckdb/main/pending_query_result.hpp b/src/include/duckdb/main/pending_query_result.hpp\nindex 72fe9405fef8..cf0268712cba 100644\n--- a/src/include/duckdb/main/pending_query_result.hpp\n+++ b/src/include/duckdb/main/pending_query_result.hpp\n@@ -29,6 +29,8 @@ class PendingQueryResult : public BaseQueryResult {\n \tDUCKDB_API explicit PendingQueryResult(ErrorData error_message);\n \tDUCKDB_API ~PendingQueryResult() override;\n \tDUCKDB_API bool AllowStreamResult() const;\n+\tPendingQueryResult(const PendingQueryResult &) = delete;\n+\tPendingQueryResult &operator=(const PendingQueryResult &) = delete;\n \n public:\n \t//! Executes a single task within the query, returning whether or not the query is ready.\ndiff --git a/src/main/extension/extension_load.cpp b/src/main/extension/extension_load.cpp\nindex 4be4588371cf..5499665f1a27 100644\n--- a/src/main/extension/extension_load.cpp\n+++ b/src/main/extension/extension_load.cpp\n@@ -71,15 +71,11 @@ struct ExtensionAccess {\n \tstatic void SetError(duckdb_extension_info info, const char *error) {\n \t\tauto &load_state = DuckDBExtensionLoadState::Get(info);\n \n-\t\tif (error) {\n-\t\t\tload_state.has_error = true;\n-\t\t\tload_state.error_data = ErrorData(error);\n-\t\t} else {\n-\t\t\tload_state.has_error = true;\n-\t\t\tload_state.error_data = ErrorData(\n-\t\t\t    ExceptionType::UNKNOWN_TYPE,\n-\t\t\t    \"Extension has indicated an error occured during initialization, but did not set an error message.\");\n-\t\t}\n+\t\tload_state.has_error = true;\n+\t\tload_state.error_data =\n+\t\t    error ? ErrorData(error)\n+\t\t          : ErrorData(ExceptionType::UNKNOWN_TYPE, \"Extension has indicated an error occured during \"\n+\t\t                                                   \"initialization, but did not set an error message.\");\n \t}\n \n \t//! Called by the extension get a pointer to the database that is loading it\n@@ -92,9 +88,11 @@ struct ExtensionAccess {\n \t\t\tload_state.database_data->database = make_shared_ptr<DuckDB>(load_state.db);\n \t\t\treturn reinterpret_cast<duckdb_database *>(load_state.database_data.get());\n \t\t} catch (std::exception &ex) {\n+\t\t\tload_state.has_error = true;\n \t\t\tload_state.error_data = ErrorData(ex);\n \t\t\treturn nullptr;\n \t\t} catch (...) {\n+\t\t\tload_state.has_error = true;\n \t\t\tload_state.error_data =\n \t\t\t    ErrorData(ExceptionType::UNKNOWN_TYPE, \"Unknown error in GetDatabase when trying to load extension!\");\n \t\t\treturn nullptr;\ndiff --git a/src/parser/transform/expression/transform_subquery.cpp b/src/parser/transform/expression/transform_subquery.cpp\nindex 6f6d742073ba..0403d24bc5dc 100644\n--- a/src/parser/transform/expression/transform_subquery.cpp\n+++ b/src/parser/transform/expression/transform_subquery.cpp\n@@ -107,6 +107,7 @@ unique_ptr<ParsedExpression> Transformer::TransformSubquery(duckdb_libpgquery::P\n \t\t\t}\n \t\t}\n \t\t// transform constants (e.g. ORDER BY 1) into positional references (ORDER BY #1)\n+\t\tidx_t array_idx = 0;\n \t\tif (aggr->order_bys) {\n \t\t\tfor (auto &order : aggr->order_bys->orders) {\n \t\t\t\tif (order.expression->GetExpressionType() == ExpressionType::VALUE_CONSTANT) {\n@@ -120,8 +121,10 @@ unique_ptr<ParsedExpression> Transformer::TransformSubquery(duckdb_libpgquery::P\n \t\t\t\t\t}\n \t\t\t\t} else if (sub_select) {\n \t\t\t\t\t// if we have a SELECT we can push the ORDER BY clause into the SELECT list and reference it\n+\t\t\t\t\tauto alias = \"__array_internal_idx_\" + to_string(++array_idx);\n+\t\t\t\t\torder.expression->alias = alias;\n \t\t\t\t\tsub_select->select_list.push_back(std::move(order.expression));\n-\t\t\t\t\torder.expression = make_uniq<PositionalReferenceExpression>(sub_select->select_list.size() - 1);\n+\t\t\t\t\torder.expression = make_uniq<ColumnRefExpression>(alias);\n \t\t\t\t} else {\n \t\t\t\t\t// otherwise we remove order qualifications\n \t\t\t\t\tRemoveOrderQualificationRecursive(order.expression);\ndiff --git a/src/storage/table/row_group.cpp b/src/storage/table/row_group.cpp\nindex d5250387362b..55c6e064f4e5 100644\n--- a/src/storage/table/row_group.cpp\n+++ b/src/storage/table/row_group.cpp\n@@ -430,14 +430,13 @@ bool RowGroup::CheckZonemap(ScanFilterInfo &filters) {\n \t\tif (prune_result == FilterPropagateResult::FILTER_ALWAYS_FALSE) {\n \t\t\treturn false;\n \t\t}\n-\t\tif (prune_result == FilterPropagateResult::FILTER_ALWAYS_TRUE) {\n-\t\t\t// filter is always true - no need to check it\n-\t\t\t// label the filter as always true so we don't need to check it anymore\n-\t\t\tfilters.SetFilterAlwaysTrue(i);\n-\t\t}\n \t\tif (filter.filter_type == TableFilterType::OPTIONAL_FILTER) {\n \t\t\t// these are only for row group checking, set as always true so we don't check it\n \t\t\tfilters.SetFilterAlwaysTrue(i);\n+\t\t} else if (prune_result == FilterPropagateResult::FILTER_ALWAYS_TRUE) {\n+\t\t\t// filter is always true - no need to check it\n+\t\t\t// label the filter as always true so we don't need to check it anymore\n+\t\t\tfilters.SetFilterAlwaysTrue(i);\n \t\t}\n \t}\n \treturn true;\n@@ -619,7 +618,7 @@ void RowGroup::TemplatedScan(TransactionData transaction, CollectionScanState &s\n \t\t\t\t\t\tif (prune_result == FilterPropagateResult::FILTER_ALWAYS_FALSE) {\n \t\t\t\t\t\t\t// We can just break out of the loop here.\n \t\t\t\t\t\t\tapproved_tuple_count = 0;\n-\t\t\t\t\t\t\tbreak;\n+\t\t\t\t\t\t\tcontinue;\n \t\t\t\t\t\t}\n \n \t\t\t\t\t\t// Generate row ids\ndiff --git a/src/storage/table/scan_state.cpp b/src/storage/table/scan_state.cpp\nindex adeccde91b03..fdfa76433059 100644\n--- a/src/storage/table/scan_state.cpp\n+++ b/src/storage/table/scan_state.cpp\n@@ -96,6 +96,9 @@ void ScanFilterInfo::CheckAllFilters() {\n \n void ScanFilterInfo::SetFilterAlwaysTrue(idx_t filter_idx) {\n \tauto &filter = filter_list[filter_idx];\n+\tif (filter.always_true) {\n+\t\treturn;\n+\t}\n \tfilter.always_true = true;\n \tcolumn_has_filter[filter.scan_column_index] = false;\n \talways_true_filters++;\n", "test_patch": "diff --git a/test/issues/general/test_16257.test_slow b/test/issues/general/test_16257.test_slow\nnew file mode 100644\nindex 000000000000..6b3faf9a7ba4\n--- /dev/null\n+++ b/test/issues/general/test_16257.test_slow\n@@ -0,0 +1,25 @@\n+# name: test/issues/general/test_16257.test_slow\n+# description: Issue 16257 - value count mismatch when writing DELTA_BINARY_PACKED\n+# group: [general]\n+\n+require parquet\n+\n+# Some macros to generate lorem ipsum\n+statement ok\n+CREATE OR REPLACE MACRO deterministic_random(rand) AS hash(rand) / 18446744073709551615;\n+\n+statement ok\n+CREATE OR REPLACE MACRO lorem_word(rand) AS ['voluptatem', 'quaerat', 'quiquia', 'non', 'dolore', 'dolorem', 'labore', 'consectetur', 'porro', 'sed', 'numquam', 'aliquam', 'sit', 'eius', 'modi', 'est', 'amet', 'magnam', 'dolor', 'etincidunt', 'velit', 'neque', 'ipsum', 'adipisci', 'quisquam', 'ut', 'tempora'][1 + floor(rand * 27 % 27)::BIGINT];\n+\n+statement ok\n+CREATE OR REPLACE MACRO lorem_sentence_util(s) AS upper(s[1]) || s[2:] || '.';\n+\n+statement ok\n+CREATE OR REPLACE MACRO lorem_sentence(rand, words) AS lorem_sentence_util(list_aggr([lorem_word(deterministic_random(rand + i)) for i in range(words)], 'string_agg', ' '));\n+\n+\n+statement ok\n+SET preserve_insertion_order=false;\n+\n+statement ok\n+COPY (SELECT lorem_sentence(random(), 20) FROM range(1_000_000)) TO '__TEST_DIR__/16257.parquet' (PARQUET_VERSION V2, ROW_GROUP_SIZE 2_000_000);\ndiff --git a/test/sql/copy/csv/afl/fuzz_20250211_crash.test b/test/sql/copy/csv/afl/fuzz_20250211_crash.test\nnew file mode 100644\nindex 000000000000..7a10d16a002d\n--- /dev/null\n+++ b/test/sql/copy/csv/afl/fuzz_20250211_crash.test\n@@ -0,0 +1,10 @@\n+# name: test/sql/copy/csv/afl/fuzz_20250211_crash.test\n+# description: fuzzer generated csv files - should not raise internal exception (by failed assertion).\n+# group: [afl]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/20250211_csv_fuzz_crash/case_53.csv', buffer_size=42);\n+----\ndiff --git a/test/sql/copy/csv/afl/test_fuzz_4172.test b/test/sql/copy/csv/afl/test_fuzz_4172.test\nnew file mode 100644\nindex 000000000000..e22e66604e57\n--- /dev/null\n+++ b/test/sql/copy/csv/afl/test_fuzz_4172.test\n@@ -0,0 +1,10 @@\n+# name: test/sql/copy/csv/afl/test_fuzz_4172.test\n+# description: fuzzer generated csv files - should not raise internal exception (by failed assertion).\n+# group: [afl]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/4172/case_4.csv', ignore_errors=true, buffer_size=1, store_rejects=false);\n+----\ndiff --git a/test/sql/copy/csv/maximum_line_size.test_slow b/test/sql/copy/csv/maximum_line_size.test_slow\nindex db5672073fbf..1ea62d7e6513 100644\n--- a/test/sql/copy/csv/maximum_line_size.test_slow\n+++ b/test/sql/copy/csv/maximum_line_size.test_slow\n@@ -39,4 +39,4 @@ Be sure that the maximum line size is set to an appropriate value\n statement error\n select * from read_csv_auto('data/csv/issue_8320_3.csv.gz', max_line_size = 2097152, buffer_size = 10);\n ----\n-BUFFER_SIZE option was set to 10, while MAX_LINE_SIZE was set to 2097152. BUFFER_SIZE must have always be set to value bigger than MAX_LINE_SIZE\n\\ No newline at end of file\n+Buffer Size of 10 must be a higher value than the maximum line size 2097152\n\\ No newline at end of file\ndiff --git a/test/sql/copy/csv/parallel/csv_parallel_buffer_size.test b/test/sql/copy/csv/parallel/csv_parallel_buffer_size.test\nindex 466758becc6f..04f78983c3cb 100644\n--- a/test/sql/copy/csv/parallel/csv_parallel_buffer_size.test\n+++ b/test/sql/copy/csv/parallel/csv_parallel_buffer_size.test\n@@ -22,7 +22,7 @@ SELECT sum(a) FROM read_csv('data/csv/test/multi_column_integer_rn.csv',  COLUMN\n 111111111\n \n query IIII\n-select * from read_csv('data/csv/test/multi_column_string.csv',  COLUMNS=STRUCT_PACK(a := 'INTEGER', b := 'INTEGER', c := 'INTEGER', d := 'VARCHAR'), auto_detect='true', delim = '|', buffer_size=25)\n+select * from read_csv('data/csv/test/multi_column_string.csv',  COLUMNS=STRUCT_PACK(a := 'INTEGER', b := 'INTEGER', c := 'INTEGER', d := 'VARCHAR'), auto_detect='true', delim = '|', buffer_size=30)\n ----\n 1\t6370\t371\tp1\n 10\t214\t465\tp2\n@@ -35,7 +35,7 @@ select * from read_csv('data/csv/test/multi_column_string.csv',  COLUMNS=STRUCT_\n 100000000\t15519\t785\tp9\n \n query IIII\n-select * from read_csv('data/csv/test/multi_column_string_rn.csv',  COLUMNS=STRUCT_PACK(a := 'INTEGER', b := 'INTEGER', c := 'INTEGER', d := 'VARCHAR'), auto_detect='true', delim = '|', buffer_size=25)\n+select * from read_csv('data/csv/test/multi_column_string_rn.csv',  COLUMNS=STRUCT_PACK(a := 'INTEGER', b := 'INTEGER', c := 'INTEGER', d := 'VARCHAR'), auto_detect='true', delim = '|', buffer_size=27)\n ----\n 1\t6370\t371\tp1\n 10\t214\t465\tp2\n@@ -53,7 +53,7 @@ SELECT sum(a) FROM read_csv('data/csv/test/new_line_string_rn.csv',  COLUMNS=STR\n 111\n \n query I\n-SELECT sum(a) FROM read_csv('data/csv/test/new_line_string_rn.csv',  COLUMNS=STRUCT_PACK(a := 'INTEGER', b := 'INTEGER', c := 'INTEGER', d := 'VARCHAR'), auto_detect='true', delim = '|', buffer_size=80)\n+SELECT sum(a) FROM read_csv('data/csv/test/new_line_string_rn.csv',  COLUMNS=STRUCT_PACK(a := 'INTEGER', b := 'INTEGER', c := 'INTEGER', d := 'VARCHAR'), auto_detect='true', delim = '|', buffer_size=100)\n ----\n 111\n \n@@ -64,7 +64,7 @@ SELECT sum(a) FROM read_csv('data/csv/test/new_line_string_rn_exc.csv',  COLUMNS\n 111\n \n query I\n-SELECT sum(a) FROM read_csv('data/csv/test/new_line_string_rn_exc.csv',  COLUMNS=STRUCT_PACK(a := 'INTEGER', b := 'INTEGER', c := 'INTEGER', d := 'VARCHAR'), auto_detect='true', delim = '|', buffer_size=60)\n+SELECT sum(a) FROM read_csv('data/csv/test/new_line_string_rn_exc.csv',  COLUMNS=STRUCT_PACK(a := 'INTEGER', b := 'INTEGER', c := 'INTEGER', d := 'VARCHAR'), auto_detect='true', delim = '|', buffer_size=80)\n ----\n 111\n \n@@ -75,6 +75,6 @@ SELECT sum(a) FROM read_csv('data/csv/test/new_line_string.csv',  COLUMNS=STRUCT\n 111\n \n query I\n-SELECT sum(a) FROM read_csv('data/csv/test/new_line_string.csv',  COLUMNS=STRUCT_PACK(a := 'INTEGER', b := 'INTEGER', c := 'INTEGER', d := 'VARCHAR'), auto_detect='true', delim = '|', buffer_size=60)\n+SELECT sum(a) FROM read_csv('data/csv/test/new_line_string.csv',  COLUMNS=STRUCT_PACK(a := 'INTEGER', b := 'INTEGER', c := 'INTEGER', d := 'VARCHAR'), quote ='\"', escape ='\"', comment = '', auto_detect='true', delim = '|', buffer_size=100, new_line = '\\r\\n')\n ----\n 111\ndiff --git a/test/sql/copy/csv/parallel/csv_parallel_new_line.test_slow b/test/sql/copy/csv/parallel/csv_parallel_new_line.test_slow\nindex b9654da5d729..f9fb5c45385f 100644\n--- a/test/sql/copy/csv/parallel/csv_parallel_new_line.test_slow\n+++ b/test/sql/copy/csv/parallel/csv_parallel_new_line.test_slow\n@@ -9,7 +9,7 @@ PRAGMA verify_parallelism\n statement ok\n PRAGMA enable_verification\n \n-loop i 25 100\n+loop i 27 100\n \n \n # Test read_csv auto with \\n\ndiff --git a/test/sql/copy/csv/relaxed_quotes.test b/test/sql/copy/csv/relaxed_quotes.test\nindex f8c6e8012c88..6bdfa8ede56b 100644\n--- a/test/sql/copy/csv/relaxed_quotes.test\n+++ b/test/sql/copy/csv/relaxed_quotes.test\n@@ -78,12 +78,7 @@ statement ok\n drop table t;\n \n statement error\n-create table t as from read_csv('data/csv/unescaped_quotes/unescaped_quote_new_line_rn.csv', strict_mode=false, buffer_size = 20, header = 0)\n-----\n-\n-\n-statement error\n-create table t as from read_csv('data/csv/unescaped_quotes/unescaped_quote_new_line_rn.csv', strict_mode=false, buffer_size = 20, header = 0)\n+create table t as from read_csv('data/csv/unescaped_quotes/unescaped_quote_new_line_rn.csv', strict_mode=false, buffer_size = 20, header = 0, delim = ';')\n ----\n \n statement ok\ndiff --git a/test/sql/copy/csv/test_validator.test b/test/sql/copy/csv/test_validator.test\nindex 66a444809520..e44d97b23014 100644\n--- a/test/sql/copy/csv/test_validator.test\n+++ b/test/sql/copy/csv/test_validator.test\n@@ -52,7 +52,7 @@ statement ok\n FROM read_csv('data/csv/validator/quoted_new_value.csv', columns = {'band': 'varchar', 'album': 'varchar', 'release': 'varchar'}, quote = '''', delim = ';', header = 0)\n \n statement ok\n-FROM read_csv('data/csv/validator/quoted_new_value.csv', columns = {'band': 'varchar', 'album': 'varchar', 'release': 'varchar'}, quote = '''', delim = ';', header = 0, buffer_size = 46)\n+FROM read_csv('data/csv/validator/quoted_new_value.csv', columns = {'band': 'varchar', 'album': 'varchar', 'release': 'varchar'}, quote = '''', delim = ';', header = 0, buffer_size = 48)\n \n statement ok\n FROM read_csv('data/csv/validator/single_column_quoted_newline.csv', columns = {'Raffaella Carr\u00e0': 'varchar'}, quote = '\"',  buffer_size = 24)\ndiff --git a/test/sql/index/art/scan/test_art_scan_normal_to_nested.test b/test/sql/index/art/scan/test_art_scan_normal_to_nested.test\nnew file mode 100644\nindex 000000000000..0cd8cf886fe5\n--- /dev/null\n+++ b/test/sql/index/art/scan/test_art_scan_normal_to_nested.test\n@@ -0,0 +1,38 @@\n+# name: test/sql/index/art/scan/test_art_scan_normal_to_nested.test\n+# description: Test range scanning with an iterator moving from a normal leaf to a nested leaf.\n+# group: [scan]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+CREATE TABLE integers (i BIGINT);\n+\n+statement ok\n+CREATE INDEX idx_integers ON integers (i);\n+\n+statement ok\n+INSERT INTO integers (i) VALUES ('1'), ('-1'), ('1');\n+\n+# The border is exactly when moving from a non-nested leaf to a nested leaf.\n+\n+query I\n+SELECT i FROM integers WHERE i <= 0;\n+----\n+-1\n+\n+# Issue 16074.\n+\n+statement ok\n+CREATE TABLE t0(c1 TIMESTAMP);\n+\n+statement ok\n+INSERT INTO t0(c1) VALUES ('2020-02-29 12:00:00'), ('1969-12-09 09:26:38'), ('2020-02-29 12:00:00');\n+\n+statement ok\n+CREATE INDEX i0 ON t0(c1);\n+\n+query I\n+SELECT c1 FROM t0 WHERE c1 <= '2007-07-07 07:07:07';\n+----\n+1969-12-09 09:26:38\n\\ No newline at end of file\ndiff --git a/test/sql/sample/bernoulli_sampling.test b/test/sql/sample/bernoulli_sampling.test\nnew file mode 100644\nindex 000000000000..95b3e3796c8f\n--- /dev/null\n+++ b/test/sql/sample/bernoulli_sampling.test\n@@ -0,0 +1,54 @@\n+# name: test/sql/sample/bernoulli_sampling.test\n+# description: Test reservoir sample crash on large data sets\n+# group: [sample]\n+\n+statement ok\n+create table output (num_rows INT);\n+\n+statement ok\n+select setseed(0.3);\n+\n+loop i 0 500\n+\n+statement ok\n+WITH some_tab AS (\n+    SELECT UNNEST(range(1000)) AS id\n+),\n+some_tab_unq AS (\n+    SELECT distinct(id) AS id FROM some_tab\n+),\n+sampled AS (\n+    select id from some_tab_unq\n+    USING SAMPLE 1% (bernoulli)\n+)\n+INSERT INTO output select count(*) as n_rows FROM sampled;\n+\n+endloop\n+\n+\n+query II\n+select min(num_rows) > 0, count(*) FILTER (num_rows = 0) = 0 from output;\n+----\n+true\ttrue\n+\n+query III\n+select avg(rowid), min(rowid), max(rowid) from output where num_rows = 0;\n+----\n+NULL\tNULL\tNULL\n+\n+statement ok\n+create table t1 as select range id from range(1000);\n+\n+statement ok\n+select setseed(0.6);\n+\n+query I nosort result_1\n+select id from t1 USING SAMPLE 1% (bernoulli, 5);\n+----\n+\n+query I nosort result_1\n+select id from t1 USING SAMPLE 1% (bernoulli, 5);\n+----\n+\n+\n+\ndiff --git a/test/sql/subquery/scalar/array_order_subquery.test b/test/sql/subquery/scalar/array_order_subquery.test\nindex a0ca2fb4c7d0..94abd308009a 100644\n--- a/test/sql/subquery/scalar/array_order_subquery.test\n+++ b/test/sql/subquery/scalar/array_order_subquery.test\n@@ -86,6 +86,16 @@ SELECT ARRAY\n ----\n [3, 2, 1]\n \n+query I\n+select array(select * from unnest(['a', 'b']) as _t(u) order by if(u='a',100, 1)) as out;\n+----\n+[b, a]\n+\n+query I\n+select array(select * from unnest(['a', 'b']) as _t(u) order by if(u='a',100, 1) desc) as out;\n+----\n+[a, b]\n+\n statement error\n SELECT ARRAY\n   (SELECT 1 UNION ALL\ndiff --git a/test/sql/variables/test_variables.test b/test/sql/variables/test_variables.test\nindex ad3c15d43f57..b67d81686222 100644\n--- a/test/sql/variables/test_variables.test\n+++ b/test/sql/variables/test_variables.test\n@@ -13,6 +13,22 @@ SELECT GETVARIABLE('animal')\n ----\n duck\n \n+statement ok\n+PREPARE v1 AS SELECT GETVARIABLE($1);\n+\n+query I\n+EXECUTE v1('animal');\n+----\n+duck\n+\n+statement ok\n+CREATE MACRO _(x) AS getvariable(x);\n+\n+query I\n+SELECT _('animal')\n+----\n+duck\n+\n # overwriting\n statement ok\n SET VARIABLE animal='bird'\n", "problem_statement": "InternalException: INTERNAL Error: value count mismatch when writing DELTA_BINARY_PACKED\n### What happens?\n\nwriting parquet file crash duckdb, notice, it works fine for sf =1 , but crash with 5 and above\n\n### To Reproduce\n\n```python\nimport duckdb\ncon=duckdb.connect()\ncon.sql(f\"\"\" ATTACH './db.duckdb' AS db (STORAGE_VERSION 'v1.2.0') \"\"\")\ncon.sql(f\" use db\")\ncon.sql(f\"CALL dbgen(sf=5)\")\ncon.sql(f\"\"\" COPY (SELECT * FROM partsupp) TO './partsupp' (FORMAT PARQUET,PARQUET_VERSION V2,PER_THREAD_OUTPUT TRUE,ROW_GROUP_SIZE 2_000_000 , APPEND) \"\"\")\ncon.close()\n```\n\n### OS:\n\nlinux\n\n### DuckDB Version:\n\nduckdb-1.2.1.dev321\n\n### DuckDB Client:\n\npython\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nmim\n\n### Affiliation:\n\npersonal\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a nightly build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nInternalException: INTERNAL Error: value count mismatch when writing DELTA_BINARY_PACKED\n### What happens?\n\nwriting parquet file crash duckdb, notice, it works fine for sf =1 , but crash with 5 and above\n\n### To Reproduce\n\n```python\nimport duckdb\ncon=duckdb.connect()\ncon.sql(f\"\"\" ATTACH './db.duckdb' AS db (STORAGE_VERSION 'v1.2.0') \"\"\")\ncon.sql(f\" use db\")\ncon.sql(f\"CALL dbgen(sf=5)\")\ncon.sql(f\"\"\" COPY (SELECT * FROM partsupp) TO './partsupp' (FORMAT PARQUET,PARQUET_VERSION V2,PER_THREAD_OUTPUT TRUE,ROW_GROUP_SIZE 2_000_000 , APPEND) \"\"\")\ncon.close()\n```\n\n### OS:\n\nlinux\n\n### DuckDB Version:\n\nduckdb-1.2.1.dev321\n\n### DuckDB Client:\n\npython\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nmim\n\n### Affiliation:\n\npersonal\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a nightly build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nChanged behaviour of getvariable\n### What happens?\n\nwith duckdb versions prior to version 1.1.3, i would run this command for ease of use:\n`CREATE MACRO _(x) AS getvariable(x);`\nso that i didn't have to write it each time,\nbut now on duckdb 1.2.0 i get back this error:\n`Not implemented Error: getvariable requires a constant input`\n\n1. is this expected?\n2. is there a way to rename it, and in general, to rename functions such as `getvariable` ?\n\n\n\n### To Reproduce\n\nfor reproducing, try this command on duckdb 1.1.3 and duckdb 1.2.0:\n`CREATE MACRO _(x) AS getvariable(x);`\n\n### OS:\n\nany\n\n### DuckDB Version:\n\n1.2.0\n\n### DuckDB Client:\n\nany \n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nMassimiliano Pizzotti\n\n### Affiliation:\n\nEssilorLuxottica\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "\n\n", "created_at": "2025-02-18T10:34:40Z"}
{"repo": "duckdb/duckdb", "pull_number": 16275, "instance_id": "duckdb__duckdb-16275", "issue_numbers": ["16257", "16257"], "base_commit": "52811a9d197d8c4e98d291b4144a0d1724cefbda", "patch": "diff --git a/extension/parquet/column_writer.cpp b/extension/parquet/column_writer.cpp\nindex ba42a9b2f20a..8791bc596c08 100644\n--- a/extension/parquet/column_writer.cpp\n+++ b/extension/parquet/column_writer.cpp\n@@ -388,7 +388,7 @@ class BasicColumnWriter : public ColumnWriter {\n \tvirtual unique_ptr<ColumnWriterStatistics> InitializeStatsState();\n \n \t//! Initialize the writer for a specific page. Only used for scalar types.\n-\tvirtual unique_ptr<ColumnWriterPageState> InitializePageState(BasicColumnWriterState &state);\n+\tvirtual unique_ptr<ColumnWriterPageState> InitializePageState(BasicColumnWriterState &state, idx_t page_idx);\n \n \t//! Flushes the writer for a specific page. Only used for scalar types.\n \tvirtual void FlushPageState(WriteStream &temp_writer, ColumnWriterPageState *state);\n@@ -427,7 +427,8 @@ void BasicColumnWriter::RegisterToRowGroup(duckdb_parquet::RowGroup &row_group)\n \trow_group.columns.push_back(std::move(column_chunk));\n }\n \n-unique_ptr<ColumnWriterPageState> BasicColumnWriter::InitializePageState(BasicColumnWriterState &state) {\n+unique_ptr<ColumnWriterPageState> BasicColumnWriter::InitializePageState(BasicColumnWriterState &state,\n+                                                                         idx_t page_idx) {\n \treturn nullptr;\n }\n \n@@ -502,7 +503,7 @@ void BasicColumnWriter::BeginWrite(ColumnWriterState &state_p) {\n \t\t    MaxValue<idx_t>(NextPowerOfTwo(page_info.estimated_page_size), MemoryStream::DEFAULT_INITIAL_CAPACITY));\n \t\twrite_info.write_count = page_info.empty_count;\n \t\twrite_info.max_write_count = page_info.row_count;\n-\t\twrite_info.page_state = InitializePageState(state);\n+\t\twrite_info.page_state = InitializePageState(state, page_idx);\n \n \t\twrite_info.compressed_size = 0;\n \t\twrite_info.compressed_data = nullptr;\n@@ -1232,11 +1233,11 @@ class StandardColumnWriter : public BasicColumnWriter {\n \t\treturn std::move(result);\n \t}\n \n-\tunique_ptr<ColumnWriterPageState> InitializePageState(BasicColumnWriterState &state_p) override {\n+\tunique_ptr<ColumnWriterPageState> InitializePageState(BasicColumnWriterState &state_p, idx_t page_idx) override {\n \t\tauto &state = state_p.Cast<StandardColumnWriterState<SRC>>();\n-\n-\t\tauto result = make_uniq<StandardWriterPageState<SRC, TGT>>(state.total_value_count, state.total_string_size,\n-\t\t                                                           state.encoding, state.dictionary);\n+\t\tconst auto &page_info = state_p.page_info[page_idx];\n+\t\tauto result = make_uniq<StandardWriterPageState<SRC, TGT>>(\n+\t\t    page_info.row_count - page_info.empty_count, state.total_string_size, state.encoding, state.dictionary);\n \t\treturn std::move(result);\n \t}\n \n@@ -1586,7 +1587,7 @@ class BooleanColumnWriter : public BasicColumnWriter {\n \t\t}\n \t}\n \n-\tunique_ptr<ColumnWriterPageState> InitializePageState(BasicColumnWriterState &state) override {\n+\tunique_ptr<ColumnWriterPageState> InitializePageState(BasicColumnWriterState &state, idx_t page_idx) override {\n \t\treturn make_uniq<BooleanWriterPageState>();\n \t}\n \n@@ -1828,7 +1829,7 @@ class EnumColumnWriter : public BasicColumnWriter {\n \t\t}\n \t}\n \n-\tunique_ptr<ColumnWriterPageState> InitializePageState(BasicColumnWriterState &state) override {\n+\tunique_ptr<ColumnWriterPageState> InitializePageState(BasicColumnWriterState &state, idx_t page_idx) override {\n \t\treturn make_uniq<EnumWriterPageState>(bit_width);\n \t}\n \ndiff --git a/extension/parquet/include/parquet_bss_encoder.hpp b/extension/parquet/include/parquet_bss_encoder.hpp\nindex 80da1726de92..65561eb2573a 100644\n--- a/extension/parquet/include/parquet_bss_encoder.hpp\n+++ b/extension/parquet/include/parquet_bss_encoder.hpp\n@@ -30,7 +30,6 @@ class BssEncoder {\n \t}\n \n \tvoid FinishWrite(WriteStream &writer) {\n-\t\tD_ASSERT(count == total_value_count);\n \t\twriter.WriteData(buffer.get(), total_value_count * bit_width);\n \t}\n \ndiff --git a/extension/parquet/include/parquet_dlba_encoder.hpp b/extension/parquet/include/parquet_dlba_encoder.hpp\nindex b3cd1aa96076..89702fc12e41 100644\n--- a/extension/parquet/include/parquet_dlba_encoder.hpp\n+++ b/extension/parquet/include/parquet_dlba_encoder.hpp\n@@ -33,9 +33,8 @@ class DlbaEncoder {\n \t}\n \n \tvoid FinishWrite(WriteStream &writer) {\n-\t\tD_ASSERT(stream->GetPosition() == total_string_size);\n \t\tdbp_encoder.FinishWrite(writer);\n-\t\twriter.WriteData(buffer.get(), total_string_size);\n+\t\twriter.WriteData(buffer.get(), stream->GetPosition());\n \t}\n \n private:\n", "test_patch": "diff --git a/test/issues/general/test_16257.test_slow b/test/issues/general/test_16257.test_slow\nnew file mode 100644\nindex 000000000000..6b3faf9a7ba4\n--- /dev/null\n+++ b/test/issues/general/test_16257.test_slow\n@@ -0,0 +1,25 @@\n+# name: test/issues/general/test_16257.test_slow\n+# description: Issue 16257 - value count mismatch when writing DELTA_BINARY_PACKED\n+# group: [general]\n+\n+require parquet\n+\n+# Some macros to generate lorem ipsum\n+statement ok\n+CREATE OR REPLACE MACRO deterministic_random(rand) AS hash(rand) / 18446744073709551615;\n+\n+statement ok\n+CREATE OR REPLACE MACRO lorem_word(rand) AS ['voluptatem', 'quaerat', 'quiquia', 'non', 'dolore', 'dolorem', 'labore', 'consectetur', 'porro', 'sed', 'numquam', 'aliquam', 'sit', 'eius', 'modi', 'est', 'amet', 'magnam', 'dolor', 'etincidunt', 'velit', 'neque', 'ipsum', 'adipisci', 'quisquam', 'ut', 'tempora'][1 + floor(rand * 27 % 27)::BIGINT];\n+\n+statement ok\n+CREATE OR REPLACE MACRO lorem_sentence_util(s) AS upper(s[1]) || s[2:] || '.';\n+\n+statement ok\n+CREATE OR REPLACE MACRO lorem_sentence(rand, words) AS lorem_sentence_util(list_aggr([lorem_word(deterministic_random(rand + i)) for i in range(words)], 'string_agg', ' '));\n+\n+\n+statement ok\n+SET preserve_insertion_order=false;\n+\n+statement ok\n+COPY (SELECT lorem_sentence(random(), 20) FROM range(1_000_000)) TO '__TEST_DIR__/16257.parquet' (PARQUET_VERSION V2, ROW_GROUP_SIZE 2_000_000);\n", "problem_statement": "InternalException: INTERNAL Error: value count mismatch when writing DELTA_BINARY_PACKED\n### What happens?\n\nwriting parquet file crash duckdb, notice, it works fine for sf =1 , but crash with 5 and above\n\n### To Reproduce\n\n```python\nimport duckdb\ncon=duckdb.connect()\ncon.sql(f\"\"\" ATTACH './db.duckdb' AS db (STORAGE_VERSION 'v1.2.0') \"\"\")\ncon.sql(f\" use db\")\ncon.sql(f\"CALL dbgen(sf=5)\")\ncon.sql(f\"\"\" COPY (SELECT * FROM partsupp) TO './partsupp' (FORMAT PARQUET,PARQUET_VERSION V2,PER_THREAD_OUTPUT TRUE,ROW_GROUP_SIZE 2_000_000 , APPEND) \"\"\")\ncon.close()\n```\n\n### OS:\n\nlinux\n\n### DuckDB Version:\n\nduckdb-1.2.1.dev321\n\n### DuckDB Client:\n\npython\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nmim\n\n### Affiliation:\n\npersonal\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a nightly build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nInternalException: INTERNAL Error: value count mismatch when writing DELTA_BINARY_PACKED\n### What happens?\n\nwriting parquet file crash duckdb, notice, it works fine for sf =1 , but crash with 5 and above\n\n### To Reproduce\n\n```python\nimport duckdb\ncon=duckdb.connect()\ncon.sql(f\"\"\" ATTACH './db.duckdb' AS db (STORAGE_VERSION 'v1.2.0') \"\"\")\ncon.sql(f\" use db\")\ncon.sql(f\"CALL dbgen(sf=5)\")\ncon.sql(f\"\"\" COPY (SELECT * FROM partsupp) TO './partsupp' (FORMAT PARQUET,PARQUET_VERSION V2,PER_THREAD_OUTPUT TRUE,ROW_GROUP_SIZE 2_000_000 , APPEND) \"\"\")\ncon.close()\n```\n\n### OS:\n\nlinux\n\n### DuckDB Version:\n\nduckdb-1.2.1.dev321\n\n### DuckDB Client:\n\npython\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nmim\n\n### Affiliation:\n\npersonal\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a nightly build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "i had the same issue this week. After reducing the ROW_GROUP_SIZE the issue resolved.\nanother reproduction just with a sequence:\n```SQL\nCOPY (SELECT * from range(100_000_000)) TO 'partsupp.parquet' (FORMAT PARQUET,PARQUET_VERSION V2,ROW_GROUP_SIZE 20_000_000 , overwrite);\n```\ni had the same issue this week. After reducing the ROW_GROUP_SIZE the issue resolved.\nanother reproduction just with a sequence:\n```SQL\nCOPY (SELECT * from range(100_000_000)) TO 'partsupp.parquet' (FORMAT PARQUET,PARQUET_VERSION V2,ROW_GROUP_SIZE 20_000_000 , overwrite);\n```", "created_at": "2025-02-17T15:18:55Z"}
{"repo": "duckdb/duckdb", "pull_number": 16272, "instance_id": "duckdb__duckdb-16272", "issue_numbers": ["16231"], "base_commit": "52811a9d197d8c4e98d291b4144a0d1724cefbda", "patch": "diff --git a/src/parser/transform/expression/transform_subquery.cpp b/src/parser/transform/expression/transform_subquery.cpp\nindex 6f6d742073ba..0403d24bc5dc 100644\n--- a/src/parser/transform/expression/transform_subquery.cpp\n+++ b/src/parser/transform/expression/transform_subquery.cpp\n@@ -107,6 +107,7 @@ unique_ptr<ParsedExpression> Transformer::TransformSubquery(duckdb_libpgquery::P\n \t\t\t}\n \t\t}\n \t\t// transform constants (e.g. ORDER BY 1) into positional references (ORDER BY #1)\n+\t\tidx_t array_idx = 0;\n \t\tif (aggr->order_bys) {\n \t\t\tfor (auto &order : aggr->order_bys->orders) {\n \t\t\t\tif (order.expression->GetExpressionType() == ExpressionType::VALUE_CONSTANT) {\n@@ -120,8 +121,10 @@ unique_ptr<ParsedExpression> Transformer::TransformSubquery(duckdb_libpgquery::P\n \t\t\t\t\t}\n \t\t\t\t} else if (sub_select) {\n \t\t\t\t\t// if we have a SELECT we can push the ORDER BY clause into the SELECT list and reference it\n+\t\t\t\t\tauto alias = \"__array_internal_idx_\" + to_string(++array_idx);\n+\t\t\t\t\torder.expression->alias = alias;\n \t\t\t\t\tsub_select->select_list.push_back(std::move(order.expression));\n-\t\t\t\t\torder.expression = make_uniq<PositionalReferenceExpression>(sub_select->select_list.size() - 1);\n+\t\t\t\t\torder.expression = make_uniq<ColumnRefExpression>(alias);\n \t\t\t\t} else {\n \t\t\t\t\t// otherwise we remove order qualifications\n \t\t\t\t\tRemoveOrderQualificationRecursive(order.expression);\n", "test_patch": "diff --git a/test/sql/subquery/scalar/array_order_subquery.test b/test/sql/subquery/scalar/array_order_subquery.test\nindex a0ca2fb4c7d0..94abd308009a 100644\n--- a/test/sql/subquery/scalar/array_order_subquery.test\n+++ b/test/sql/subquery/scalar/array_order_subquery.test\n@@ -86,6 +86,16 @@ SELECT ARRAY\n ----\n [3, 2, 1]\n \n+query I\n+select array(select * from unnest(['a', 'b']) as _t(u) order by if(u='a',100, 1)) as out;\n+----\n+[b, a]\n+\n+query I\n+select array(select * from unnest(['a', 'b']) as _t(u) order by if(u='a',100, 1) desc) as out;\n+----\n+[a, b]\n+\n statement error\n SELECT ARRAY\n   (SELECT 1 UNION ALL\n", "problem_statement": "Array ordering regression in release 1.2.0\n### What happens?\n\nDuckdb 1.2.0 seems to sort arrays by value, ignoring order by expressions. This was not happening in duckdb 1.1.3 ( i.e. the order was consistent with the expression) \n\n\n### To Reproduce\n\n```sql\nselect array(select * from unnest(['a', 'b']) as _t(u) order by if(u='a',100, 1)) as out;\nselect array(select * from unnest(['a', 'b']) as _t(u) order by if(u='a',100, 1) desc) as out;\n```\n\nin duckdb 1.1.3 it returns \n```\nselect array(select * from unnest(['a', 'b']) as _t(u) order by if(u='a',100, 1)) as out;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    out    \u2502\n\u2502 varchar[] \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 [b, a]    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n```\nselect array(select * from unnest(['a', 'b']) as _t(u) order by if(u='a',100, 1) desc) as out;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    out    \u2502\n\u2502 varchar[] \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 [a, b]    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nwhereas in duckdb 1.2.0 I get \n```\nselect array(select * from unnest(['a', 'b']) as _t(u) order by if(u='a',100, 1)) as out;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    out    \u2502\n\u2502 varchar[] \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 [a, b]    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n```\nselect array(select * from unnest(['a', 'b']) as _t(u) order by if(u='a',100, 1) desc) as out;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    out    \u2502\n\u2502 varchar[] \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 [b, a]    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n### OS:\n\nMacOS 15 (aarch64) Python 3.11.6 . Also fails on linux ubuntu 22.04, x86 Python 3.11.6\n\n### DuckDB Version:\n\n1.2.0\n\n### DuckDB Client:\n\nPython\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nChinmoy Mandayam\n\n### Affiliation:\n\nActively\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "It seems related to https://github.com/duckdb/duckdb/issues/15052, but that was buggy in 1.1.0, and 1.1.3 gives the right result for me\nThanks, this reproduces in the CLI client as well.", "created_at": "2025-02-17T15:02:38Z"}
{"repo": "duckdb/duckdb", "pull_number": 16264, "instance_id": "duckdb__duckdb-16264", "issue_numbers": ["16260", "16260"], "base_commit": "2b873268957ce115b6314ca72ca31e0f4ebf6fa6", "patch": "diff --git a/src/function/scalar/generic/getvariable.cpp b/src/function/scalar/generic/getvariable.cpp\nindex 14d32954d1cf..0181c07523bc 100644\n--- a/src/function/scalar/generic/getvariable.cpp\n+++ b/src/function/scalar/generic/getvariable.cpp\n@@ -24,12 +24,12 @@ struct GetVariableBindData : FunctionData {\n \n static unique_ptr<FunctionData> GetVariableBind(ClientContext &context, ScalarFunction &function,\n                                                 vector<unique_ptr<Expression>> &arguments) {\n+\tif (arguments[0]->HasParameter() || arguments[0]->return_type.id() == LogicalTypeId::UNKNOWN) {\n+\t\tthrow ParameterNotResolvedException();\n+\t}\n \tif (!arguments[0]->IsFoldable()) {\n \t\tthrow NotImplementedException(\"getvariable requires a constant input\");\n \t}\n-\tif (arguments[0]->HasParameter()) {\n-\t\tthrow ParameterNotResolvedException();\n-\t}\n \tValue value;\n \tauto variable_name = ExpressionExecutor::EvaluateScalar(context, *arguments[0]);\n \tif (!variable_name.IsNull()) {\n", "test_patch": "diff --git a/test/sql/variables/test_variables.test b/test/sql/variables/test_variables.test\nindex ad3c15d43f57..b67d81686222 100644\n--- a/test/sql/variables/test_variables.test\n+++ b/test/sql/variables/test_variables.test\n@@ -13,6 +13,22 @@ SELECT GETVARIABLE('animal')\n ----\n duck\n \n+statement ok\n+PREPARE v1 AS SELECT GETVARIABLE($1);\n+\n+query I\n+EXECUTE v1('animal');\n+----\n+duck\n+\n+statement ok\n+CREATE MACRO _(x) AS getvariable(x);\n+\n+query I\n+SELECT _('animal')\n+----\n+duck\n+\n # overwriting\n statement ok\n SET VARIABLE animal='bird'\n", "problem_statement": "Changed behaviour of getvariable\n### What happens?\n\nwith duckdb versions prior to version 1.1.3, i would run this command for ease of use:\n`CREATE MACRO _(x) AS getvariable(x);`\nso that i didn't have to write it each time,\nbut now on duckdb 1.2.0 i get back this error:\n`Not implemented Error: getvariable requires a constant input`\n\n1. is this expected?\n2. is there a way to rename it, and in general, to rename functions such as `getvariable` ?\n\n\n\n### To Reproduce\n\nfor reproducing, try this command on duckdb 1.1.3 and duckdb 1.2.0:\n`CREATE MACRO _(x) AS getvariable(x);`\n\n### OS:\n\nany\n\n### DuckDB Version:\n\n1.2.0\n\n### DuckDB Client:\n\nany \n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nMassimiliano Pizzotti\n\n### Affiliation:\n\nEssilorLuxottica\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nChanged behaviour of getvariable\n### What happens?\n\nwith duckdb versions prior to version 1.1.3, i would run this command for ease of use:\n`CREATE MACRO _(x) AS getvariable(x);`\nso that i didn't have to write it each time,\nbut now on duckdb 1.2.0 i get back this error:\n`Not implemented Error: getvariable requires a constant input`\n\n1. is this expected?\n2. is there a way to rename it, and in general, to rename functions such as `getvariable` ?\n\n\n\n### To Reproduce\n\nfor reproducing, try this command on duckdb 1.1.3 and duckdb 1.2.0:\n`CREATE MACRO _(x) AS getvariable(x);`\n\n### OS:\n\nany\n\n### DuckDB Version:\n\n1.2.0\n\n### DuckDB Client:\n\nany \n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nMassimiliano Pizzotti\n\n### Affiliation:\n\nEssilorLuxottica\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "That's interesting, that requirement has been on `getvariable` since its inception (<https://github.com/duckdb/duckdb/pull/13084>)\n\nI assume there has been a behavior change in macros causing this to not be a constant parameter anymore?\nThat's interesting, that requirement has been on `getvariable` since its inception (<https://github.com/duckdb/duckdb/pull/13084>)\n\nI assume there has been a behavior change in macros causing this to not be a constant parameter anymore?", "created_at": "2025-02-17T13:12:59Z"}
{"repo": "duckdb/duckdb", "pull_number": 16244, "instance_id": "duckdb__duckdb-16244", "issue_numbers": ["16118"], "base_commit": "6415640753e28d21ca5fb340d28a2bf435bab313", "patch": "diff --git a/extension/core_functions/aggregate/distributive/string_agg.cpp b/extension/core_functions/aggregate/distributive/string_agg.cpp\nindex b694a23656fa..cdbd9e003aa5 100644\n--- a/extension/core_functions/aggregate/distributive/string_agg.cpp\n+++ b/extension/core_functions/aggregate/distributive/string_agg.cpp\n@@ -44,14 +44,7 @@ struct StringAggFunction {\n \t\tif (!state.dataptr) {\n \t\t\tfinalize_data.ReturnNull();\n \t\t} else {\n-\t\t\ttarget = StringVector::AddString(finalize_data.result, state.dataptr, state.size);\n-\t\t}\n-\t}\n-\n-\ttemplate <class STATE>\n-\tstatic void Destroy(STATE &state, AggregateInputData &aggr_input_data) {\n-\t\tif (state.dataptr) {\n-\t\t\tdelete[] state.dataptr;\n+\t\t\ttarget = string_t(state.dataptr, state.size);\n \t\t}\n \t}\n \n@@ -59,12 +52,12 @@ struct StringAggFunction {\n \t\treturn true;\n \t}\n \n-\tstatic inline void PerformOperation(StringAggState &state, const char *str, const char *sep, idx_t str_size,\n-\t                                    idx_t sep_size) {\n+\tstatic inline void PerformOperation(StringAggState &state, ArenaAllocator &allocator, const char *str,\n+\t                                    const char *sep, idx_t str_size, idx_t sep_size) {\n \t\tif (!state.dataptr) {\n \t\t\t// first iteration: allocate space for the string and copy it into the state\n \t\t\tstate.alloc_size = MaxValue<idx_t>(8, NextPowerOfTwo(str_size));\n-\t\t\tstate.dataptr = new char[state.alloc_size];\n+\t\t\tstate.dataptr = char_ptr_cast(allocator.Allocate(state.alloc_size));\n \t\t\tstate.size = str_size;\n \t\t\tmemcpy(state.dataptr, str, str_size);\n \t\t} else {\n@@ -72,13 +65,12 @@ struct StringAggFunction {\n \t\t\tidx_t required_size = state.size + str_size + sep_size;\n \t\t\tif (required_size > state.alloc_size) {\n \t\t\t\t// no space! allocate extra space\n+\t\t\t\tconst auto old_size = state.alloc_size;\n \t\t\t\twhile (state.alloc_size < required_size) {\n \t\t\t\t\tstate.alloc_size *= 2;\n \t\t\t\t}\n-\t\t\t\tauto new_data = new char[state.alloc_size];\n-\t\t\t\tmemcpy(new_data, state.dataptr, state.size);\n-\t\t\t\tdelete[] state.dataptr;\n-\t\t\t\tstate.dataptr = new_data;\n+\t\t\t\tstate.dataptr =\n+\t\t\t\t    char_ptr_cast(allocator.Reallocate(data_ptr_cast(state.dataptr), old_size, state.alloc_size));\n \t\t\t}\n \t\t\t// copy the separator\n \t\t\tmemcpy(state.dataptr + state.size, sep, sep_size);\n@@ -89,14 +81,15 @@ struct StringAggFunction {\n \t\t}\n \t}\n \n-\tstatic inline void PerformOperation(StringAggState &state, string_t str, optional_ptr<FunctionData> data_p) {\n+\tstatic inline void PerformOperation(StringAggState &state, ArenaAllocator &allocator, string_t str,\n+\t                                    optional_ptr<FunctionData> data_p) {\n \t\tauto &data = data_p->Cast<StringAggBindData>();\n-\t\tPerformOperation(state, str.GetData(), data.sep.c_str(), str.GetSize(), data.sep.size());\n+\t\tPerformOperation(state, allocator, str.GetData(), data.sep.c_str(), str.GetSize(), data.sep.size());\n \t}\n \n \ttemplate <class INPUT_TYPE, class STATE, class OP>\n \tstatic void Operation(STATE &state, const INPUT_TYPE &input, AggregateUnaryInput &unary_input) {\n-\t\tPerformOperation(state, input, unary_input.input.bind_data);\n+\t\tPerformOperation(state, unary_input.input.allocator, input, unary_input.input.bind_data);\n \t}\n \n \ttemplate <class INPUT_TYPE, class STATE, class OP>\n@@ -113,8 +106,8 @@ struct StringAggFunction {\n \t\t\t// source is not set: skip combining\n \t\t\treturn;\n \t\t}\n-\t\tPerformOperation(target, string_t(source.dataptr, UnsafeNumericCast<uint32_t>(source.size)),\n-\t\t                 aggr_input_data.bind_data);\n+\t\tPerformOperation(target, aggr_input_data.allocator,\n+\t\t                 string_t(source.dataptr, UnsafeNumericCast<uint32_t>(source.size)), aggr_input_data.bind_data);\n \t}\n };\n \n@@ -162,8 +155,7 @@ AggregateFunctionSet StringAggFun::GetFunctions() {\n \t    AggregateFunction::UnaryScatterUpdate<StringAggState, string_t, StringAggFunction>,\n \t    AggregateFunction::StateCombine<StringAggState, StringAggFunction>,\n \t    AggregateFunction::StateFinalize<StringAggState, string_t, StringAggFunction>,\n-\t    AggregateFunction::UnaryUpdate<StringAggState, string_t, StringAggFunction>, StringAggBind,\n-\t    AggregateFunction::StateDestroy<StringAggState, StringAggFunction>);\n+\t    AggregateFunction::UnaryUpdate<StringAggState, string_t, StringAggFunction>, StringAggBind);\n \tstring_agg_param.serialize = StringAggSerialize;\n \tstring_agg_param.deserialize = StringAggDeserialize;\n \tstring_agg.AddFunction(string_agg_param);\ndiff --git a/extension/core_functions/aggregate/nested/list.cpp b/extension/core_functions/aggregate/nested/list.cpp\nindex 7b23987d6875..40a917eff7e8 100644\n--- a/extension/core_functions/aggregate/nested/list.cpp\n+++ b/extension/core_functions/aggregate/nested/list.cpp\n@@ -116,7 +116,6 @@ static void ListFinalize(Vector &states_vector, AggregateInputData &aggr_input_d\n \n \t// first iterate over all entries and set up the list entries, and get the newly required total length\n \tfor (idx_t i = 0; i < count; i++) {\n-\n \t\tauto &state = *states[states_data.sel->get_index(i)];\n \t\tconst auto rid = i + offset;\n \t\tresult_data[rid].offset = total_len;\ndiff --git a/extension/core_functions/scalar/list/list_aggregates.cpp b/extension/core_functions/scalar/list/list_aggregates.cpp\nindex 1b2aab71dca7..a5ce49eed759 100644\n--- a/extension/core_functions/scalar/list/list_aggregates.cpp\n+++ b/extension/core_functions/scalar/list/list_aggregates.cpp\n@@ -15,7 +15,17 @@\n \n namespace duckdb {\n \n-// FIXME: use a local state for each thread to increase performance?\n+struct ListAggregatesLocalState : public FunctionLocalState {\n+\texplicit ListAggregatesLocalState(Allocator &allocator) : arena_allocator(allocator) {\n+\t}\n+\n+\tArenaAllocator arena_allocator;\n+};\n+\n+unique_ptr<FunctionLocalState> ListAggregatesInitLocalState(ExpressionState &state, const BoundFunctionExpression &expr,\n+                                                            FunctionData *bind_data) {\n+\treturn make_uniq<ListAggregatesLocalState>(BufferAllocator::Get(state.GetContext()));\n+}\n // FIXME: benchmark the use of simple_update against using update (if applicable)\n \n static unique_ptr<FunctionData> ListAggregatesBindFailure(ScalarFunction &bound_function) {\n@@ -207,7 +217,8 @@ static void ListAggregatesFunction(DataChunk &args, ExpressionState &state, Vect\n \tauto &func_expr = state.expr.Cast<BoundFunctionExpression>();\n \tauto &info = func_expr.bind_info->Cast<ListAggregatesBindData>();\n \tauto &aggr = info.aggr_expr->Cast<BoundAggregateExpression>();\n-\tArenaAllocator allocator(Allocator::DefaultAllocator());\n+\tauto &allocator = ExecuteFunctionState::GetFunctionState(state)->Cast<ListAggregatesLocalState>().arena_allocator;\n+\tallocator.Reset();\n \tAggregateInputData aggr_input_data(aggr.bind_info.get(), allocator);\n \n \tD_ASSERT(aggr.function.update);\n@@ -511,8 +522,9 @@ static unique_ptr<FunctionData> ListUniqueBind(ClientContext &context, ScalarFun\n }\n \n ScalarFunction ListAggregateFun::GetFunction() {\n-\tauto result = ScalarFunction({LogicalType::LIST(LogicalType::ANY), LogicalType::VARCHAR}, LogicalType::ANY,\n-\t                             ListAggregateFunction, ListAggregateBind);\n+\tauto result =\n+\t    ScalarFunction({LogicalType::LIST(LogicalType::ANY), LogicalType::VARCHAR}, LogicalType::ANY,\n+\t                   ListAggregateFunction, ListAggregateBind, nullptr, nullptr, ListAggregatesInitLocalState);\n \tBaseScalarFunction::SetReturnsError(result);\n \tresult.null_handling = FunctionNullHandling::SPECIAL_HANDLING;\n \tresult.varargs = LogicalType::ANY;\n@@ -523,12 +535,12 @@ ScalarFunction ListAggregateFun::GetFunction() {\n \n ScalarFunction ListDistinctFun::GetFunction() {\n \treturn ScalarFunction({LogicalType::LIST(LogicalType::ANY)}, LogicalType::LIST(LogicalType::ANY),\n-\t                      ListDistinctFunction, ListDistinctBind);\n+\t                      ListDistinctFunction, ListDistinctBind, nullptr, nullptr, ListAggregatesInitLocalState);\n }\n \n ScalarFunction ListUniqueFun::GetFunction() {\n \treturn ScalarFunction({LogicalType::LIST(LogicalType::ANY)}, LogicalType::UBIGINT, ListUniqueFunction,\n-\t                      ListUniqueBind);\n+\t                      ListUniqueBind, nullptr, nullptr, ListAggregatesInitLocalState);\n }\n \n } // namespace duckdb\ndiff --git a/extension/json/buffered_json_reader.cpp b/extension/json/buffered_json_reader.cpp\nindex 68a830c7fd12..a57d375771c2 100644\n--- a/extension/json/buffered_json_reader.cpp\n+++ b/extension/json/buffered_json_reader.cpp\n@@ -92,7 +92,7 @@ void JSONFileHandle::ReadAtPosition(char *pointer, idx_t size, idx_t position, b\n \t\tauto &handle = override_handle ? *override_handle.get() : *file_handle.get();\n \t\tif (can_seek) {\n \t\t\thandle.Read(pointer, size, position);\n-\t\t} else if (sample_run) { // Cache the buffer\n+\t\t} else if (file_handle->IsPipe()) { // Cache the buffer\n \t\t\thandle.Read(pointer, size, position);\n \n \t\t\tcached_buffers.emplace_back(allocator.Allocate(size));\n@@ -128,7 +128,7 @@ bool JSONFileHandle::Read(char *pointer, idx_t &read_size, idx_t requested_size,\n \tif (can_seek) {\n \t\tread_size = ReadInternal(pointer, requested_size);\n \t\tread_position += read_size;\n-\t} else if (sample_run) { // Cache the buffer\n+\t} else if (file_handle->IsPipe()) { // Cache the buffer\n \t\tread_size = ReadInternal(pointer, requested_size);\n \t\tif (read_size > 0) {\n \t\t\tcached_buffers.emplace_back(allocator.Allocate(read_size));\ndiff --git a/extension/json/json_extension.cpp b/extension/json/json_extension.cpp\nindex e0665260a5bf..d609fd82ef68 100644\n--- a/extension/json/json_extension.cpp\n+++ b/extension/json/json_extension.cpp\n@@ -17,12 +17,17 @@\n namespace duckdb {\n \n static DefaultMacro json_macros[] = {\n-    {DEFAULT_SCHEMA, \"json_group_array\", {\"x\", nullptr}, {{nullptr, nullptr}}, \"to_json(list(x))\"},\n+    {DEFAULT_SCHEMA,\n+     \"json_group_array\",\n+     {\"x\", nullptr},\n+     {{nullptr, nullptr}},\n+     \"CAST('[' || string_agg(CASE WHEN x IS NULL THEN 'null'::JSON ELSE to_json(x) END, ',') || ']' AS JSON)\"},\n     {DEFAULT_SCHEMA,\n      \"json_group_object\",\n-     {\"name\", \"value\", nullptr},\n+     {\"n\", \"v\", nullptr},\n      {{nullptr, nullptr}},\n-     \"to_json(map(list(name), list(value)))\"},\n+     \"CAST('{' || string_agg(to_json(n::VARCHAR) || ':' || CASE WHEN v IS NULL THEN 'null'::JSON ELSE to_json(v) END, \"\n+     \"',') || '}' AS JSON)\"},\n     {DEFAULT_SCHEMA,\n      \"json_group_structure\",\n      {\"x\", nullptr},\ndiff --git a/src/common/compressed_file_system.cpp b/src/common/compressed_file_system.cpp\nindex b8f032a656e3..d222bf13de12 100644\n--- a/src/common/compressed_file_system.cpp\n+++ b/src/common/compressed_file_system.cpp\n@@ -31,6 +31,8 @@ void CompressedFile::Initialize(bool write) {\n \tstream_data.out_buff_start = stream_data.out_buff.get();\n \tstream_data.out_buff_end = stream_data.out_buff.get();\n \n+\tcurrent_position = 0;\n+\n \tstream_wrapper = compressed_fs.CreateStream();\n \tstream_wrapper->Initialize(*this, write);\n }\ndiff --git a/src/execution/operator/aggregate/physical_window.cpp b/src/execution/operator/aggregate/physical_window.cpp\nindex 8b8b2a162b32..956c50ee18ad 100644\n--- a/src/execution/operator/aggregate/physical_window.cpp\n+++ b/src/execution/operator/aggregate/physical_window.cpp\n@@ -575,6 +575,11 @@ class WindowLocalSourceState : public LocalSourceState {\n \n \texplicit WindowLocalSourceState(WindowGlobalSourceState &gsource);\n \n+\tvoid ReleaseLocalStates() {\n+\t\tauto &local_states = window_hash_group->thread_states.at(task->thread_idx);\n+\t\tlocal_states.clear();\n+\t}\n+\n \t//! Does the task have more work to do?\n \tbool TaskFinished() const {\n \t\treturn !task || task->begin_idx == task->end_idx;\n@@ -792,6 +797,12 @@ void WindowGlobalSourceState::FinishTask(TaskPtr task) {\n }\n \n bool WindowLocalSourceState::TryAssignTask() {\n+\tD_ASSERT(TaskFinished());\n+\tif (task && task->stage == WindowGroupStage::GETDATA) {\n+\t\t// If this state completed the last block in the previous iteration,\n+\t\t// release out local state memory.\n+\t\tReleaseLocalStates();\n+\t}\n \t// Because downstream operators may be using our internal buffers,\n \t// we can't \"finish\" a task until we are about to get the next one.\n \n@@ -888,10 +899,6 @@ void WindowLocalSourceState::GetData(DataChunk &result) {\n \t\t++task->begin_idx;\n \t}\n \n-\t// If that was the last block, release out local state memory.\n-\tif (TaskFinished()) {\n-\t\tlocal_states.clear();\n-\t}\n \tresult.Verify();\n }\n \ndiff --git a/src/function/window/window_constant_aggregator.cpp b/src/function/window/window_constant_aggregator.cpp\nindex 0e09c6f99996..312161223903 100644\n--- a/src/function/window/window_constant_aggregator.cpp\n+++ b/src/function/window/window_constant_aggregator.cpp\n@@ -18,6 +18,10 @@ class WindowConstantAggregatorGlobalState : public WindowAggregatorGlobalState {\n \n \tvoid Finalize(const FrameStats &stats);\n \n+\t~WindowConstantAggregatorGlobalState() override {\n+\t\tstatef.Destroy();\n+\t}\n+\n \t//! Partition starts\n \tvector<idx_t> partition_offsets;\n \t//! Reused result state container for the window functions\n@@ -304,11 +308,7 @@ void WindowConstantAggregator::Finalize(WindowAggregatorState &gstate, WindowAgg\n \tlastate.statef.Combine(gastate.statef);\n \tlastate.statef.Destroy();\n \n-\t//\tLast one out turns off the lights!\n-\tif (++gastate.finalized == gastate.locals) {\n-\t\tgastate.statef.Finalize(*gastate.results);\n-\t\tgastate.statef.Destroy();\n-\t}\n+\tgastate.statef.Finalize(*gastate.results);\n }\n \n unique_ptr<WindowAggregatorState> WindowConstantAggregator::GetLocalState(const WindowAggregatorState &gstate) const {\ndiff --git a/src/function/window/window_distinct_aggregator.cpp b/src/function/window/window_distinct_aggregator.cpp\nindex 1dc940f9533d..77e00a02ee58 100644\n--- a/src/function/window/window_distinct_aggregator.cpp\n+++ b/src/function/window/window_distinct_aggregator.cpp\n@@ -190,6 +190,10 @@ class WindowDistinctAggregatorLocalState : public WindowAggregatorLocalState {\n public:\n \texplicit WindowDistinctAggregatorLocalState(const WindowDistinctAggregatorGlobalState &aggregator);\n \n+\t~WindowDistinctAggregatorLocalState() override {\n+\t\tstatef.Destroy();\n+\t}\n+\n \tvoid Sink(DataChunk &sink_chunk, DataChunk &coll_chunk, idx_t input_idx, optional_ptr<SelectionVector> filter_sel,\n \t          idx_t filtered);\n \tvoid Finalize(WindowAggregatorGlobalState &gastate, CollectionPtr collection) override;\n@@ -740,7 +744,6 @@ void WindowDistinctAggregatorLocalState::Evaluate(const WindowDistinctAggregator\n \n \t//\tFinalise the result aggregates and write to the result\n \tstatef.Finalize(result);\n-\tstatef.Destroy();\n }\n \n unique_ptr<WindowAggregatorState> WindowDistinctAggregator::GetLocalState(const WindowAggregatorState &gstate) const {\ndiff --git a/src/optimizer/column_lifetime_analyzer.cpp b/src/optimizer/column_lifetime_analyzer.cpp\nindex 8b6f1152bf8c..233617b4ced1 100644\n--- a/src/optimizer/column_lifetime_analyzer.cpp\n+++ b/src/optimizer/column_lifetime_analyzer.cpp\n@@ -108,6 +108,7 @@ void ColumnLifetimeAnalyzer::VisitOperator(LogicalOperator &op) {\n \t\t//! When RETURNING is used, a PROJECTION is the top level operator for INSERTS, UPDATES, and DELETES\n \t\t//! We still need to project all values from these operators so the projection\n \t\t//! on top of them can select from only the table values being inserted.\n+\tcase LogicalOperatorType::LOGICAL_GET:\n \tcase LogicalOperatorType::LOGICAL_UNION:\n \tcase LogicalOperatorType::LOGICAL_EXCEPT:\n \tcase LogicalOperatorType::LOGICAL_INTERSECT:\n", "test_patch": "diff --git a/test/optimizer/column_lifetime_analyzer/summary_column_lifetime.test b/test/optimizer/column_lifetime_analyzer/summary_column_lifetime.test\nnew file mode 100644\nindex 000000000000..2bb177aca0df\n--- /dev/null\n+++ b/test/optimizer/column_lifetime_analyzer/summary_column_lifetime.test\n@@ -0,0 +1,9 @@\n+# name: test/optimizer/column_lifetime_analyzer/summary_column_lifetime.test\n+# description: Test column lifetime analyzer with SUMMARY (internal issue #4138)\n+# group: [column_lifetime_analyzer]\n+\n+statement ok\n+create table data as select * from range(0,4000) tbl(col);\n+\n+statement ok\n+SELECT * FROM summary((SELECT col FROM data ORDER BY col));\ndiff --git a/test/sql/json/test_json_copy.test_slow b/test/sql/json/test_json_copy.test_slow\nindex 9041e5d4d6ec..56c2c6a36803 100644\n--- a/test/sql/json/test_json_copy.test_slow\n+++ b/test/sql/json/test_json_copy.test_slow\n@@ -1,5 +1,5 @@\n # name: test/sql/json/test_json_copy.test_slow\n-# description: Test JSON COPY using TPC-H\n+# description: Test JSON COPY\n # group: [json]\n \n require json\ndiff --git a/test/sql/json/test_json_copy_tpch.test_slow b/test/sql/json/test_json_copy_tpch.test_slow\nindex ab614e4b7d11..41db483ad968 100644\n--- a/test/sql/json/test_json_copy_tpch.test_slow\n+++ b/test/sql/json/test_json_copy_tpch.test_slow\n@@ -38,7 +38,7 @@ statement ok\n set memory_limit='100mb'\n \n statement ok\n-COPY lineitem from '__TEST_DIR__/lineitem.json' (ARRAY)\n+COPY lineitem FROM '__TEST_DIR__/lineitem.json' (ARRAY)\n \n # 500mb should be enough for the rest\n statement ok\n@@ -49,6 +49,13 @@ PRAGMA tpch(1)\n ----\n <FILE>:extension/tpch/dbgen/answers/sf0.1/q01.csv\n \n+# also test gzipped\n+statement ok\n+COPY lineitem TO '__TEST_DIR__/lineitem.json.gz'\n+\n+statement ok\n+FROM '__TEST_DIR__/lineitem.json.gz'\n+\n statement ok\n rollback\n \n", "problem_statement": "v1.2 broke select from gzipped json\n### What happens?\n\nAfter upgrading to v1.2, reading a gzipped json file demanded a large increase in maximum object size and subsequently failed with invalid character. The same json without gzip compression reads fine in both v1.x and v1.2.\n\n### To Reproduce\n\n```\nSELECT * FROM 'fundos_list.json.gz';\n```\n[fundos_list.json.gz](https://github.com/user-attachments/files/18707966/fundos_list.json.gz)\n\n### OS:\n\nWindows 11\n\n### DuckDB Version:\n\n1.2\n\n### DuckDB Client:\n\npython\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nLeonardo Horta\n\n### Affiliation:\n\nSparta Fundos de Investimento\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "", "created_at": "2025-02-14T13:57:42Z"}
{"repo": "duckdb/duckdb", "pull_number": 16221, "instance_id": "duckdb__duckdb-16221", "issue_numbers": ["13552", "13552"], "base_commit": "8234e7175cb50b35eecb537320d7f3eeef849c86", "patch": "diff --git a/src/planner/binder/tableref/bind_pivot.cpp b/src/planner/binder/tableref/bind_pivot.cpp\nindex 3899ecdd6ce1..c2891e9c54d9 100644\n--- a/src/planner/binder/tableref/bind_pivot.cpp\n+++ b/src/planner/binder/tableref/bind_pivot.cpp\n@@ -606,6 +606,7 @@ unique_ptr<SelectNode> Binder::BindUnpivot(Binder &child_binder, PivotRef &ref,\n \t\t}\n \t}\n \n+\tvector<string> select_names;\n \tfor (auto &col_expr : all_columns) {\n \t\tif (col_expr->GetExpressionType() != ExpressionType::COLUMN_REF) {\n \t\t\tthrow InternalException(\"Unexpected child of pivot source - not a ColumnRef\");\n@@ -615,6 +616,7 @@ unique_ptr<SelectNode> Binder::BindUnpivot(Binder &child_binder, PivotRef &ref,\n \t\tauto entry = handled_columns.find(column_name);\n \t\tif (entry == handled_columns.end()) {\n \t\t\t// not handled - add to the set of regularly selected columns\n+\t\t\tselect_names.push_back(col_expr->GetName());\n \t\t\tselect_node->select_list.push_back(std::move(col_expr));\n \t\t} else {\n \t\t\tname_map[column_name] = column_name;\n@@ -662,28 +664,70 @@ unique_ptr<SelectNode> Binder::BindUnpivot(Binder &child_binder, PivotRef &ref,\n \t\tunpivot_expressions.push_back(std::move(expressions));\n \t}\n \n+\tidx_t column_count = select_names.size();\n+\tidx_t unnest_count = unpivot_expressions.size();\n+\t// add the names for the generated unpivot lists\n+\tselect_names.push_back(\"unpivot_names\");\n+\tfor (idx_t i = 0; i < unpivot_expressions.size(); i++) {\n+\t\tif (i > 0) {\n+\t\t\tselect_names.push_back(\"unpivot_list_\" + std::to_string(i + 1));\n+\t\t} else {\n+\t\t\tselect_names.push_back(\"unpivot_list\");\n+\t\t}\n+\t}\n+\n+\t// now de-duplicate the names\n+\tQueryResult::DeduplicateColumns(select_names);\n+\n \t// construct the UNNEST expression for the set of names (constant)\n \tauto unpivot_list = Value::LIST(LogicalType::VARCHAR, std::move(unpivot_names));\n \tauto unpivot_name_expr = make_uniq<ConstantExpression>(std::move(unpivot_list));\n-\tvector<unique_ptr<ParsedExpression>> unnest_name_children;\n-\tunnest_name_children.push_back(std::move(unpivot_name_expr));\n-\tauto unnest_name_expr = make_uniq<FunctionExpression>(\"unnest\", std::move(unnest_name_children));\n-\tunnest_name_expr->SetAlias(unpivot.unpivot_names[0]);\n-\tselect_node->select_list.push_back(std::move(unnest_name_expr));\n+\tunpivot_name_expr->alias = select_names[column_count];\n+\tselect_node->select_list.push_back(std::move(unpivot_name_expr));\n \n-\t// construct the UNNEST expression for the set of unpivoted columns\n+\t// construct the unpivot lists for the set of unpivoted columns\n \tif (ref.unpivot_names.size() != unpivot_expressions.size()) {\n \t\tthrow BinderException(ref, \"UNPIVOT name count mismatch - got %d names but %d expressions\",\n \t\t                      ref.unpivot_names.size(), unpivot_expressions.size());\n \t}\n \tfor (idx_t i = 0; i < unpivot_expressions.size(); i++) {\n \t\tauto list_expr = make_uniq<FunctionExpression>(\"unpivot_list\", std::move(unpivot_expressions[i]));\n+\t\tlist_expr->alias = select_names[column_count + 1 + i];\n+\t\tselect_node->select_list.push_back(std::move(list_expr));\n+\t}\n+\n+\t// move the unpivot lists into a subquery\n+\tauto result_node = make_uniq<SelectNode>();\n+\tauto sub_select = make_uniq<SelectStatement>();\n+\tsub_select->node = std::move(select_node);\n+\tauto subquery = make_uniq<SubqueryRef>(std::move(sub_select));\n+\tsubquery->alias = \"unpivot\";\n+\n+\tresult_node->from_table = std::move(subquery);\n+\n+\t// construct the final UNNEST calls which generate the final unpivot result\n+\tfor (idx_t i = 0; i < column_count; i++) {\n+\t\tauto select_col = make_uniq<ColumnRefExpression>(std::move(select_names[i]));\n+\t\tresult_node->select_list.push_back(std::move(select_col));\n+\t}\n+\n+\tauto unpivot_name_list = make_uniq<ColumnRefExpression>(std::move(select_names[column_count]));\n+\tvector<unique_ptr<ParsedExpression>> unnest_name_children;\n+\tunnest_name_children.push_back(std::move(unpivot_name_list));\n+\tauto unnest_name_expr = make_uniq<FunctionExpression>(\"unnest\", std::move(unnest_name_children));\n+\tunnest_name_expr->SetAlias(unpivot.unpivot_names[0]);\n+\tresult_node->select_list.push_back(std::move(unnest_name_expr));\n+\n+\tfor (idx_t i = 0; i < unnest_count; i++) {\n+\t\tauto unpivot_internal_name = std::move(select_names[column_count + 1 + i]);\n+\n+\t\tauto unpivot_list_ref = make_uniq<ColumnRefExpression>(std::move(unpivot_internal_name));\n \t\tvector<unique_ptr<ParsedExpression>> unnest_val_children;\n-\t\tunnest_val_children.push_back(std::move(list_expr));\n+\t\tunnest_val_children.push_back(std::move(unpivot_list_ref));\n \t\tauto unnest_val_expr = make_uniq<FunctionExpression>(\"unnest\", std::move(unnest_val_children));\n \t\tauto unnest_name = i < ref.column_name_alias.size() ? ref.column_name_alias[i] : ref.unpivot_names[i];\n \t\tunnest_val_expr->SetAlias(unnest_name);\n-\t\tselect_node->select_list.push_back(std::move(unnest_val_expr));\n+\t\tresult_node->select_list.push_back(std::move(unnest_val_expr));\n \t\tif (!ref.include_nulls) {\n \t\t\t// if we are running with EXCLUDE NULLS we need to add an IS NOT NULL filter\n \t\t\tauto colref = make_uniq<ColumnRefExpression>(unnest_name);\n@@ -696,7 +740,7 @@ unique_ptr<SelectNode> Binder::BindUnpivot(Binder &child_binder, PivotRef &ref,\n \t\t\t}\n \t\t}\n \t}\n-\treturn select_node;\n+\treturn result_node;\n }\n \n unique_ptr<BoundTableRef> Binder::Bind(PivotRef &ref) {\n", "test_patch": "diff --git a/test/sql/pivot/unpivot_internal_names.test b/test/sql/pivot/unpivot_internal_names.test\nnew file mode 100644\nindex 000000000000..50c5c7ea3ce6\n--- /dev/null\n+++ b/test/sql/pivot/unpivot_internal_names.test\n@@ -0,0 +1,19 @@\n+# name: test/sql/pivot/unpivot_internal_names.test\n+# description: Test unpivoting on a table with names used internally by the unpivot operator\n+# group: [pivot]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+CREATE TABLE unpivot_names(unpivot_names VARCHAR, unpivot_list VARCHAR, unpivot_list_2 VARCHAR, col1 INT, col2 INT, col3 INT);\n+\n+statement ok\n+INSERT INTO unpivot_names VALUES ('unpivot_names', 'unpivot_list', 'unpivot_list_2', 1, 2, 3);\n+\n+query IIIII\n+UNPIVOT unpivot_names ON COLUMNS('col*')\n+----\n+unpivot_names\tunpivot_list\tunpivot_list_2\tcol1\t1\n+unpivot_names\tunpivot_list\tunpivot_list_2\tcol2\t2\n+unpivot_names\tunpivot_list\tunpivot_list_2\tcol3\t3\n", "problem_statement": "UNPIVOT statement is extremely slow when working with many columns\n### What happens?\r\n\r\nI'm trying to unpivot table with 30k+ columns. It is extremely slow on DuckDB. \r\nIn comparision similar operation in Pandas takes few seconds.\r\n\r\nFor 10k columns it takes 117 seconds on DuckDB vs 2,7 sec on Pandas\r\n\r\n\r\n### To Reproduce\r\n\r\nFor reporting purposes please find this example:\r\n\r\nData generation\r\n```sql\r\ncreate table r as select id, concat('column_', id) as column_name, concat('value_', id) as  column_value from (select unnest(generate_series(1,10000)) as id);\r\ncreate table pivoted as pivot r on column_name using first(id) group by id;\r\n```\r\n\r\nBenchmark:\r\n```sql\r\nselect count(*) from (unpivot pivoted on columns(* exclude id) into name 'column_name' value 'column_value');\r\n```\r\n```\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 count_star() \u2502\r\n\u2502    int64     \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502        10000 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\nRun Time (s): real 117.393 user 215.706619 sys 18.343984\r\n```\r\n\r\nPandas for comparison\r\n```\r\nimport pandas as pd\r\nimport time\r\n\r\n# Step 1: Create the DataFrame\r\ndata = {\r\n    'id': range(10000),\r\n    'column_name': ['column_' + str(i) for i in range(10000)],\r\n    'column_value': range(10000)\r\n}\r\n\r\ndf = pd.DataFrame(data)\r\n\r\n# Step 2: Pivot the DataFrame\r\npivot_df = df.pivot(index='id', columns='column_name', values='column_value')\r\n\r\n# Step 3: Melt the DataFrame back\r\nstart = time.time()\r\nmelted_df = pivot_df.reset_index().melt(id_vars='id', var_name='column_name', value_name='column_value')\r\nprint(time.time() - start)\r\n# 2.771090269088745\r\n```\r\n\r\n### OS:\r\n\r\nMacOS\r\n\r\n### DuckDB Version:\r\n\r\n1.0.0\r\n\r\n### DuckDB Client:\r\n\r\nCLI\r\n\r\n### Full Name:\r\n\r\nMaciej Bry\u0144ski\r\n\r\n### Affiliation:\r\n\r\nCledar\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\nUNPIVOT statement is extremely slow when working with many columns\n### What happens?\r\n\r\nI'm trying to unpivot table with 30k+ columns. It is extremely slow on DuckDB. \r\nIn comparision similar operation in Pandas takes few seconds.\r\n\r\nFor 10k columns it takes 117 seconds on DuckDB vs 2,7 sec on Pandas\r\n\r\n\r\n### To Reproduce\r\n\r\nFor reporting purposes please find this example:\r\n\r\nData generation\r\n```sql\r\ncreate table r as select id, concat('column_', id) as column_name, concat('value_', id) as  column_value from (select unnest(generate_series(1,10000)) as id);\r\ncreate table pivoted as pivot r on column_name using first(id) group by id;\r\n```\r\n\r\nBenchmark:\r\n```sql\r\nselect count(*) from (unpivot pivoted on columns(* exclude id) into name 'column_name' value 'column_value');\r\n```\r\n```\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 count_star() \u2502\r\n\u2502    int64     \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502        10000 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\nRun Time (s): real 117.393 user 215.706619 sys 18.343984\r\n```\r\n\r\nPandas for comparison\r\n```\r\nimport pandas as pd\r\nimport time\r\n\r\n# Step 1: Create the DataFrame\r\ndata = {\r\n    'id': range(10000),\r\n    'column_name': ['column_' + str(i) for i in range(10000)],\r\n    'column_value': range(10000)\r\n}\r\n\r\ndf = pd.DataFrame(data)\r\n\r\n# Step 2: Pivot the DataFrame\r\npivot_df = df.pivot(index='id', columns='column_name', values='column_value')\r\n\r\n# Step 3: Melt the DataFrame back\r\nstart = time.time()\r\nmelted_df = pivot_df.reset_index().melt(id_vars='id', var_name='column_name', value_name='column_value')\r\nprint(time.time() - start)\r\n# 2.771090269088745\r\n```\r\n\r\n### OS:\r\n\r\nMacOS\r\n\r\n### DuckDB Version:\r\n\r\n1.0.0\r\n\r\n### DuckDB Client:\r\n\r\nCLI\r\n\r\n### Full Name:\r\n\r\nMaciej Bry\u0144ski\r\n\r\n### Affiliation:\r\n\r\nCledar\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\n", "hints_text": "DuckDB 1.1.0 - no changes\r\n``` \r\nD select count(*) from (unpivot pivoted on columns(* exclude id) into name 'column_name' value 'column_value');\r\n100% \u2595\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 count_star() \u2502\r\n\u2502    int64     \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502        10000 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\nRun Time (s): real 109.126 user 90.234428 sys 16.978885\r\n```\nDuckDB 1.1.0 - no changes\r\n``` \r\nD select count(*) from (unpivot pivoted on columns(* exclude id) into name 'column_name' value 'column_value');\r\n100% \u2595\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 count_star() \u2502\r\n\u2502    int64     \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502        10000 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\nRun Time (s): real 109.126 user 90.234428 sys 16.978885\r\n```", "created_at": "2025-02-13T09:39:22Z"}
{"repo": "duckdb/duckdb", "pull_number": 16193, "instance_id": "duckdb__duckdb-16193", "issue_numbers": ["16163", "16163"], "base_commit": "d76982157f9e3f72426dcf52458a26c1c8741ef3", "patch": "diff --git a/src/planner/expression_binder/table_function_binder.cpp b/src/planner/expression_binder/table_function_binder.cpp\nindex fca04a10b87a..71ccdefe4dd2 100644\n--- a/src/planner/expression_binder/table_function_binder.cpp\n+++ b/src/planner/expression_binder/table_function_binder.cpp\n@@ -49,6 +49,11 @@ BindResult TableFunctionBinder::BindColumnReference(unique_ptr<ParsedExpression>\n \tif (value_function) {\n \t\treturn BindExpression(value_function, depth, root_expression);\n \t}\n+\tif (table_function_name.empty()) {\n+\t\tthrow BinderException(query_location,\n+\t\t                      \"Failed to bind \\\"%s\\\" - COLUMNS expression can only contain lambda parameters\",\n+\t\t                      result_name);\n+\t}\n \n \treturn BindResult(make_uniq<BoundConstantExpression>(Value(result_name)));\n }\n", "test_patch": "diff --git a/test/fuzzer/duckfuzz/strptime_const_arg.test b/test/fuzzer/duckfuzz/strptime_const_arg.test\nindex 1bacd7544e08..2fd862937ea5 100644\n--- a/test/fuzzer/duckfuzz/strptime_const_arg.test\n+++ b/test/fuzzer/duckfuzz/strptime_const_arg.test\n@@ -6,6 +6,6 @@ statement ok\n create table all_types as select * exclude(small_enum, medium_enum, large_enum) from test_all_types() limit 0;\n \n statement error\n-SELECT COLUMNS(list_filter(*, (c43 -> try_strptime(c29, c24)))) FROM all_types AS t42(c1, c2, c3, c4, c5, c6, c7, c8, c9, c10, c11, c12, c13, c14, c15, c16, c17, c18, c19, c20, c21, c22, c23, c24, c25, c26, c27, c28, c29, c30, c31, c32, c33, c34, c35, c36, c37, c38, c39, c40, c41)\n+SELECT COLUMNS(list_filter(*, (c43 -> try_strptime('c29', 'c24')))) FROM all_types AS t42(c1, c2, c3, c4, c5, c6, c7, c8, c9, c10, c11, c12, c13, c14, c15, c16, c17, c18, c19, c20, c21, c22, c23, c24, c25, c26, c27, c28, c29, c30, c31, c32, c33, c34, c35, c36, c37, c38, c39, c40, c41)\n ----\n Binder Error: Star expression\ndiff --git a/test/sql/parser/test_columns.test b/test/sql/parser/test_columns.test\nindex 88dc0800d5f9..a6519bce9e7d 100644\n--- a/test/sql/parser/test_columns.test\n+++ b/test/sql/parser/test_columns.test\n@@ -85,7 +85,7 @@ SELECT (SELECT COLUMNS(*)) FROM integers\n ----\n \n statement error\n-SELECT columns([a, null]) FROM values (42) t(a);\n+SELECT columns(['a', null]) FROM values (42) t(a);\n ----\n does not support NULL input parameters\n \ndiff --git a/test/sql/parser/test_columns_lists.test b/test/sql/parser/test_columns_lists.test\nindex 39621709750a..344f1a29f6db 100644\n--- a/test/sql/parser/test_columns_lists.test\n+++ b/test/sql/parser/test_columns_lists.test\n@@ -59,12 +59,11 @@ SELECT COLUMNS(['i']) + COLUMNS(['i']) FROM integers\n 84\n 26\n \n-# columns are turned into strings\n-query II\n+# columns must be returned as strings\n+statement error\n SELECT COLUMNS([i, j]) FROM integers\n ----\n-42\t84\n-13\t14\n+COLUMNS expression can only contain lambda parameters\n \n # nested columns\n statement error\n", "problem_statement": "`COLUMNS(x -> <anything>) ` treats tokens in `<anything>` as string literals even when not in quotes\n### What happens?\n\n`COLUMNS(x -> <anything>)` treats tokens in `<anything>` as string literals even when not in quotes.\n\n\n### To Reproduce\n\n```sql\nSELECT COLUMNS(x -> x.type[3] = 't') FROM range(1); -- e.g., user wants to filter for integers, but gets all columns\n```\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 range \u2502\n\u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n```sql\nSELECT COLUMNS(x -> asdf >= asdf) FROM range(1); \n```\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 range \u2502\n\u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n### OS:\n\nLinux\n\n### DuckDB Version:\n\n1.2\n\n### DuckDB Client:\n\nPython\n\n### Hardware:\n\n.\n\n### Full Name:\n\nSoeren Wolfers\n\n### Affiliation:\n\nG-Research\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a nightly build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNot applicable - the reproduction does not require a data set\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n`COLUMNS(x -> <anything>) ` treats tokens in `<anything>` as string literals even when not in quotes\n### What happens?\n\n`COLUMNS(x -> <anything>)` treats tokens in `<anything>` as string literals even when not in quotes.\n\n\n### To Reproduce\n\n```sql\nSELECT COLUMNS(x -> x.type[3] = 't') FROM range(1); -- e.g., user wants to filter for integers, but gets all columns\n```\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 range \u2502\n\u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n```sql\nSELECT COLUMNS(x -> asdf >= asdf) FROM range(1); \n```\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 range \u2502\n\u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n### OS:\n\nLinux\n\n### DuckDB Version:\n\n1.2\n\n### DuckDB Client:\n\nPython\n\n### Hardware:\n\n.\n\n### Full Name:\n\nSoeren Wolfers\n\n### Affiliation:\n\nG-Research\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a nightly build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNot applicable - the reproduction does not require a data set\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "+1.\n\nAnother version of this that I was recently fighting with. In this case, I was trying to pass a list into the columns expression: \n\n```sql\nwith q1 as (select ['somerange'] as selected_cols)\n    select \n        columns(c->c in selected_cols) from q1, range(10) t(somerange)\n```\n\n> selected_cols \n> [somerange]\n> ...\n\nYet this had the expected result: \n```sql\n  select \n      columns(c->c in ['somerange'])\n      from range(10) t(somerange)\n```\n+1.\n\nAnother version of this that I was recently fighting with. In this case, I was trying to pass a list into the columns expression: \n\n```sql\nwith q1 as (select ['somerange'] as selected_cols)\n    select \n        columns(c->c in selected_cols) from q1, range(10) t(somerange)\n```\n\n> selected_cols \n> [somerange]\n> ...\n\nYet this had the expected result: \n```sql\n  select \n      columns(c->c in ['somerange'])\n      from range(10) t(somerange)\n```", "created_at": "2025-02-11T19:22:41Z"}
{"repo": "duckdb/duckdb", "pull_number": 16191, "instance_id": "duckdb__duckdb-16191", "issue_numbers": ["16134", "16134"], "base_commit": "d76982157f9e3f72426dcf52458a26c1c8741ef3", "patch": "diff --git a/data/csv/issue_16098.csv b/data/csv/issue_16098.csv\nnew file mode 100644\nindex 000000000000..71b98b039411\n--- /dev/null\n+++ b/data/csv/issue_16098.csv\n@@ -0,0 +1,3001 @@\n+,sale_customer__id,year_total,next_year,sale_date__year\r\n+0,AAAAAAAAAFFLAAAA,136411.51,,2002.0\r\n+1,AAAAAAAAAFFLAAAA,5595.20,5595.20,\r\n+2,AAAAAAAAAFFLBBAA,114584.86,27357.00,1998.0\r\n+3,AAAAAAAAAFFLBBAA,27357.00,147391.13,1999.0\r\n+4,AAAAAAAAAFFLBBAA,147391.13,79192.07,2000.0\r\n+5,AAAAAAAAAFFLBBAA,79192.07,67902.17,2001.0\r\n+6,AAAAAAAAAFFLBBAA,67902.17,,2002.0\r\n+7,AAAAAAAAAFFLBBAA,10658.04,10658.04,\r\n+8,AAAAAAAAAFFLJAAA,21936.79,102894.25,1998.0\r\n+9,AAAAAAAAAFFLJAAA,102894.25,88538.07,1999.0\r\n+10,AAAAAAAAAFFLJAAA,88538.07,211298.46,2000.0\r\n+11,AAAAAAAAAFFLJAAA,211298.46,83998.76,2001.0\r\n+12,AAAAAAAAAFFLJAAA,83998.76,,2002.0\r\n+13,AAAAAAAAAFFMMBAA,101483.16,27455.35,1998.0\r\n+14,AAAAAAAAAFFMMBAA,27455.35,130915.66,1999.0\r\n+15,AAAAAAAAAFFMMBAA,130915.66,189846.99,2000.0\r\n+16,AAAAAAAAAFFMMBAA,189846.99,38180.06,2001.0\r\n+17,AAAAAAAAAFFMMBAA,38180.06,,2002.0\r\n+18,AAAAAAAAAFFMMBAA,,,\r\n+19,AAAAAAAAAFFNMAAA,68011.25,49703.03,1998.0\r\n+20,AAAAAAAAAFFNMAAA,49703.03,138296.25,1999.0\r\n+21,AAAAAAAAAFFNMAAA,138296.25,186511.01,2000.0\r\n+22,AAAAAAAAAFFNMAAA,186511.01,17514.22,2001.0\r\n+23,AAAAAAAAAFFNMAAA,17514.22,,2002.0\r\n+24,AAAAAAAAAFFNMAAA,,,\r\n+25,AAAAAAAAAFFOIBAA,67781.09,,1998.0\r\n+26,AAAAAAAAAFFOIBAA,135789.77,203876.79,2000.0\r\n+27,AAAAAAAAAFFOIBAA,203876.79,79670.15,2001.0\r\n+28,AAAAAAAAAFFOIBAA,79670.15,,2002.0\r\n+29,AAAAAAAAAFFOIBAA,,,\r\n+30,AAAAAAAAAFFPNAAA,15721.86,40311.97,1998.0\r\n+31,AAAAAAAAAFFPNAAA,40311.97,148120.02,1999.0\r\n+32,AAAAAAAAAFFPNAAA,148120.02,114514.09,2000.0\r\n+33,AAAAAAAAAFFPNAAA,114514.09,75358.91,2001.0\r\n+34,AAAAAAAAAFFPNAAA,75358.91,,2002.0\r\n+35,AAAAAAAAAFFPNAAA,,,\r\n+36,AAAAAAAAAFGBDAAA,35532.03,142459.61,1998.0\r\n+37,AAAAAAAAAFGBDAAA,142459.61,28055.83,1999.0\r\n+38,AAAAAAAAAFGBDAAA,28055.83,,2000.0\r\n+39,AAAAAAAAAFGBDAAA,41687.33,,2002.0\r\n+40,AAAAAAAAAFGBDAAA,2010.19,2010.19,\r\n+41,AAAAAAAAAFGCCAAA,18426.50,95345.75,1998.0\r\n+42,AAAAAAAAAFGCCAAA,95345.75,50950.54,1999.0\r\n+43,AAAAAAAAAFGCCAAA,50950.54,82982.62,2000.0\r\n+44,AAAAAAAAAFGCCAAA,82982.62,197959.12,2001.0\r\n+45,AAAAAAAAAFGCCAAA,197959.12,,2002.0\r\n+46,AAAAAAAAAFGCCAAA,,,\r\n+47,AAAAAAAAAFGCCBAA,113100.63,35468.71,1998.0\r\n+48,AAAAAAAAAFGCCBAA,35468.71,10143.23,1999.0\r\n+49,AAAAAAAAAFGCCBAA,10143.23,107828.54,2000.0\r\n+50,AAAAAAAAAFGCCBAA,107828.54,151638.74,2001.0\r\n+51,AAAAAAAAAFGCCBAA,151638.74,,2002.0\r\n+52,AAAAAAAAAFGCIAAA,129102.62,154668.30,1998.0\r\n+53,AAAAAAAAAFGCIAAA,154668.30,147484.64,1999.0\r\n+54,AAAAAAAAAFGCIAAA,147484.64,226087.16,2000.0\r\n+55,AAAAAAAAAFGCIAAA,226087.16,82799.97,2001.0\r\n+56,AAAAAAAAAFGCIAAA,82799.97,,2002.0\r\n+57,AAAAAAAAAFGCIAAA,2690.77,2690.77,\r\n+58,AAAAAAAAAFGDCAAA,57745.35,53431.36,1998.0\r\n+59,AAAAAAAAAFGDCAAA,53431.36,31191.09,1999.0\r\n+60,AAAAAAAAAFGDCAAA,31191.09,91701.51,2000.0\r\n+61,AAAAAAAAAFGDCAAA,91701.51,106687.97,2001.0\r\n+62,AAAAAAAAAFGDCAAA,106687.97,,2002.0\r\n+63,AAAAAAAAAFGDCAAA,,,\r\n+64,AAAAAAAAAFGDGAAA,36785.43,117121.48,1998.0\r\n+65,AAAAAAAAAFGDGAAA,117121.48,334604.15,1999.0\r\n+66,AAAAAAAAAFGDGAAA,334604.15,53569.99,2000.0\r\n+67,AAAAAAAAAFGDGAAA,53569.99,100271.85,2001.0\r\n+68,AAAAAAAAAFGDGAAA,100271.85,,2002.0\r\n+69,AAAAAAAAAFGDGAAA,,,\r\n+70,AAAAAAAAAFGDHAAA,127557.03,178689.13,1998.0\r\n+71,AAAAAAAAAFGDHAAA,178689.13,18021.37,1999.0\r\n+72,AAAAAAAAAFGDHAAA,18021.37,79867.80,2000.0\r\n+73,AAAAAAAAAFGDHAAA,79867.80,50773.15,2001.0\r\n+74,AAAAAAAAAFGDHAAA,50773.15,,2002.0\r\n+75,AAAAAAAAAFGDHAAA,6799.35,6799.35,\r\n+76,AAAAAAAAAFGECAAA,137587.98,50630.43,1998.0\r\n+77,AAAAAAAAAFGECAAA,50630.43,98073.17,1999.0\r\n+78,AAAAAAAAAFGECAAA,98073.17,152762.88,2000.0\r\n+79,AAAAAAAAAFGECAAA,152762.88,65864.22,2001.0\r\n+80,AAAAAAAAAFGECAAA,65864.22,,2002.0\r\n+81,AAAAAAAAAFGECAAA,54.28,54.28,\r\n+82,AAAAAAAAAFGFOBAA,127286.07,113895.97,1998.0\r\n+83,AAAAAAAAAFGFOBAA,113895.97,131168.02,1999.0\r\n+84,AAAAAAAAAFGFOBAA,131168.02,117642.50,2000.0\r\n+85,AAAAAAAAAFGFOBAA,117642.50,83665.18,2001.0\r\n+86,AAAAAAAAAFGFOBAA,83665.18,,2002.0\r\n+87,AAAAAAAAAFGFOBAA,5962.32,5962.32,\r\n+88,AAAAAAAAAFGGBBAA,154847.23,186072.14,1998.0\r\n+89,AAAAAAAAAFGGBBAA,186072.14,75388.02,1999.0\r\n+90,AAAAAAAAAFGGBBAA,75388.02,71350.92,2000.0\r\n+91,AAAAAAAAAFGGBBAA,71350.92,107710.58,2001.0\r\n+92,AAAAAAAAAFGGBBAA,107710.58,,2002.0\r\n+93,AAAAAAAAAFGGBBAA,,,\r\n+94,AAAAAAAAAFGGGBAA,106164.66,237269.35,1999.0\r\n+95,AAAAAAAAAFGGGBAA,237269.35,,2000.0\r\n+96,AAAAAAAAAFGGGBAA,160043.27,,2002.0\r\n+97,AAAAAAAAAFGGGBAA,,,\r\n+98,AAAAAAAAAFGGMAAA,180350.20,62357.18,1998.0\r\n+99,AAAAAAAAAFGGMAAA,62357.18,55954.35,1999.0\r\n+100,AAAAAAAAAFGGMAAA,55954.35,193136.06,2000.0\r\n+101,AAAAAAAAAFGGMAAA,193136.06,159598.28,2001.0\r\n+102,AAAAAAAAAFGGMAAA,159598.28,,2002.0\r\n+103,AAAAAAAAAFGGMAAA,,,\r\n+104,AAAAAAAAAFGHABAA,70385.23,57470.19,1998.0\r\n+105,AAAAAAAAAFGHABAA,57470.19,43585.50,1999.0\r\n+106,AAAAAAAAAFGHABAA,43585.50,59101.11,2000.0\r\n+107,AAAAAAAAAFGHABAA,59101.11,56728.33,2001.0\r\n+108,AAAAAAAAAFGHABAA,56728.33,,2002.0\r\n+109,AAAAAAAAAFGHABAA,,,\r\n+110,AAAAAAAAAFGHHAAA,37170.95,57981.86,1998.0\r\n+111,AAAAAAAAAFGHHAAA,57981.86,134815.41,1999.0\r\n+112,AAAAAAAAAFGHHAAA,134815.41,23112.33,2000.0\r\n+113,AAAAAAAAAFGHHAAA,23112.33,255027.62,2001.0\r\n+114,AAAAAAAAAFGHHAAA,255027.62,,2002.0\r\n+115,AAAAAAAAAFGHHAAA,179.82,179.82,\r\n+116,AAAAAAAAAFGIBBAA,174031.03,,1998.0\r\n+117,AAAAAAAAAFGIBBAA,19703.38,27292.27,2000.0\r\n+118,AAAAAAAAAFGIBBAA,27292.27,39132.92,2001.0\r\n+119,AAAAAAAAAFGIBBAA,39132.92,,2002.0\r\n+120,AAAAAAAAAFGIBBAA,,,\r\n+121,AAAAAAAAAFGIEAAA,75567.64,38187.50,1998.0\r\n+122,AAAAAAAAAFGIEAAA,38187.50,115966.70,1999.0\r\n+123,AAAAAAAAAFGIEAAA,115966.70,75526.82,2000.0\r\n+124,AAAAAAAAAFGIEAAA,75526.82,57785.33,2001.0\r\n+125,AAAAAAAAAFGIEAAA,57785.33,,2002.0\r\n+126,AAAAAAAAAFGIEAAA,,,\r\n+127,AAAAAAAAAFGIEBAA,146993.41,75592.43,1998.0\r\n+128,AAAAAAAAAFGIEBAA,75592.43,147683.46,1999.0\r\n+129,AAAAAAAAAFGIEBAA,147683.46,138587.40,2000.0\r\n+130,AAAAAAAAAFGIEBAA,138587.40,73788.15,2001.0\r\n+131,AAAAAAAAAFGIEBAA,73788.15,,2002.0\r\n+132,AAAAAAAAAFGIEBAA,5108.99,5108.99,\r\n+133,AAAAAAAAAFGJCBAA,121553.64,56410.55,1998.0\r\n+134,AAAAAAAAAFGJCBAA,56410.55,125829.00,1999.0\r\n+135,AAAAAAAAAFGJCBAA,125829.00,143896.57,2000.0\r\n+136,AAAAAAAAAFGJCBAA,143896.57,204957.40,2001.0\r\n+137,AAAAAAAAAFGJCBAA,204957.40,32151.96,2002.0\r\n+138,AAAAAAAAAFGJCBAA,32151.96,,2003.0\r\n+139,AAAAAAAAAFGJCBAA,27622.29,27622.29,\r\n+140,AAAAAAAAAFGJDBAA,46821.17,55808.27,1998.0\r\n+141,AAAAAAAAAFGJDBAA,55808.27,183002.78,1999.0\r\n+142,AAAAAAAAAFGJDBAA,183002.78,,2000.0\r\n+143,AAAAAAAAAFGJDBAA,109565.35,,2002.0\r\n+144,AAAAAAAAAFGJDBAA,9626.40,9626.40,\r\n+145,AAAAAAAAAFGJLAAA,135079.34,75232.14,1998.0\r\n+146,AAAAAAAAAFGJLAAA,75232.14,77692.53,1999.0\r\n+147,AAAAAAAAAFGJLAAA,77692.53,116134.25,2000.0\r\n+148,AAAAAAAAAFGJLAAA,116134.25,28932.49,2001.0\r\n+149,AAAAAAAAAFGJLAAA,28932.49,,2002.0\r\n+150,AAAAAAAAAFGJLAAA,,,\r\n+151,AAAAAAAAAFGKCBAA,99973.11,389038.16,1998.0\r\n+152,AAAAAAAAAFGKCBAA,389038.16,,1999.0\r\n+153,AAAAAAAAAFGKCBAA,31724.92,52590.55,2001.0\r\n+154,AAAAAAAAAFGKCBAA,52590.55,,2002.0\r\n+155,AAAAAAAAAFGKCBAA,,,\r\n+156,AAAAAAAAAFGLBAAA,29615.29,170834.95,1998.0\r\n+157,AAAAAAAAAFGLBAAA,170834.95,82797.99,1999.0\r\n+158,AAAAAAAAAFGLBAAA,82797.99,107099.65,2000.0\r\n+159,AAAAAAAAAFGLBAAA,107099.65,97374.85,2001.0\r\n+160,AAAAAAAAAFGLBAAA,97374.85,13908.70,2002.0\r\n+161,AAAAAAAAAFGLBAAA,13908.70,,2003.0\r\n+162,AAAAAAAAAFGLBAAA,5060.62,5060.62,\r\n+163,AAAAAAAAAFGLDAAA,178964.91,77317.71,1998.0\r\n+164,AAAAAAAAAFGLDAAA,77317.71,,1999.0\r\n+165,AAAAAAAAAFGLDAAA,56766.33,56376.64,2001.0\r\n+166,AAAAAAAAAFGLDAAA,56376.64,,2002.0\r\n+167,AAAAAAAAAFGLDAAA,,,\r\n+168,AAAAAAAAAFGLGAAA,315954.37,183440.90,1999.0\r\n+169,AAAAAAAAAFGLGAAA,183440.90,66398.16,2000.0\r\n+170,AAAAAAAAAFGLGAAA,66398.16,219786.98,2001.0\r\n+171,AAAAAAAAAFGLGAAA,219786.98,,2002.0\r\n+172,AAAAAAAAAFGLGAAA,10076.28,10076.28,\r\n+173,AAAAAAAAAFGLGBAA,21918.81,,1998.0\r\n+174,AAAAAAAAAFGLGBAA,81368.27,97717.18,2000.0\r\n+175,AAAAAAAAAFGLGBAA,97717.18,55734.26,2001.0\r\n+176,AAAAAAAAAFGLGBAA,55734.26,,2002.0\r\n+177,AAAAAAAAAFGLNAAA,191886.60,67540.86,1998.0\r\n+178,AAAAAAAAAFGLNAAA,67540.86,77095.88,1999.0\r\n+179,AAAAAAAAAFGLNAAA,77095.88,,2000.0\r\n+180,AAAAAAAAAFGLNAAA,104625.77,,2002.0\r\n+181,AAAAAAAAAFGLNAAA,8173.75,8173.75,\r\n+182,AAAAAAAAAFGOAAAA,342153.09,175247.24,1998.0\r\n+183,AAAAAAAAAFGOAAAA,175247.24,25915.83,1999.0\r\n+184,AAAAAAAAAFGOAAAA,25915.83,44256.03,2000.0\r\n+185,AAAAAAAAAFGOAAAA,44256.03,82311.37,2001.0\r\n+186,AAAAAAAAAFGOAAAA,82311.37,,2002.0\r\n+187,AAAAAAAAAFGOAAAA,8347.50,8347.50,\r\n+188,AAAAAAAAAFGOCBAA,24343.07,134677.92,1999.0\r\n+189,AAAAAAAAAFGOCBAA,134677.92,47302.08,2000.0\r\n+190,AAAAAAAAAFGOCBAA,47302.08,91832.30,2001.0\r\n+191,AAAAAAAAAFGOCBAA,91832.30,,2002.0\r\n+192,AAAAAAAAAFGOCBAA,,,\r\n+193,AAAAAAAAAFGPDAAA,216496.30,49693.29,1998.0\r\n+194,AAAAAAAAAFGPDAAA,49693.29,98436.80,1999.0\r\n+195,AAAAAAAAAFGPDAAA,98436.80,98933.74,2000.0\r\n+196,AAAAAAAAAFGPDAAA,98933.74,134404.91,2001.0\r\n+197,AAAAAAAAAFGPDAAA,134404.91,,2002.0\r\n+198,AAAAAAAAAFGPDAAA,9312.52,9312.52,\r\n+199,AAAAAAAAAFGPEAAA,134830.46,31546.61,1998.0\r\n+200,AAAAAAAAAFGPEAAA,31546.61,182717.95,1999.0\r\n+201,AAAAAAAAAFGPEAAA,182717.95,94830.61,2000.0\r\n+202,AAAAAAAAAFGPEAAA,94830.61,181276.25,2001.0\r\n+203,AAAAAAAAAFGPEAAA,181276.25,,2002.0\r\n+204,AAAAAAAAAFGPEAAA,4012.14,4012.14,\r\n+205,AAAAAAAAAFHAABAA,212306.62,109445.72,1998.0\r\n+206,AAAAAAAAAFHAABAA,109445.72,27538.92,1999.0\r\n+207,AAAAAAAAAFHAABAA,27538.92,25743.18,2000.0\r\n+208,AAAAAAAAAFHAABAA,25743.18,46445.80,2001.0\r\n+209,AAAAAAAAAFHAABAA,46445.80,,2002.0\r\n+210,AAAAAAAAAFHAABAA,1554.02,1554.02,\r\n+211,AAAAAAAAAFHAHAAA,50703.11,78732.65,1998.0\r\n+212,AAAAAAAAAFHAHAAA,78732.65,149451.88,1999.0\r\n+213,AAAAAAAAAFHAHAAA,149451.88,48642.12,2000.0\r\n+214,AAAAAAAAAFHAHAAA,48642.12,29446.90,2001.0\r\n+215,AAAAAAAAAFHAHAAA,29446.90,,2002.0\r\n+216,AAAAAAAAAFHAHAAA,7579.88,7579.88,\r\n+217,AAAAAAAAAFHAJBAA,88086.23,173944.70,1998.0\r\n+218,AAAAAAAAAFHAJBAA,173944.70,74279.94,1999.0\r\n+219,AAAAAAAAAFHAJBAA,74279.94,121981.23,2000.0\r\n+220,AAAAAAAAAFHAJBAA,121981.23,88770.27,2001.0\r\n+221,AAAAAAAAAFHAJBAA,88770.27,,2002.0\r\n+222,AAAAAAAAAFHAJBAA,3294.98,3294.98,\r\n+223,AAAAAAAAAFHBIAAA,160306.52,79530.22,1998.0\r\n+224,AAAAAAAAAFHBIAAA,79530.22,139379.81,1999.0\r\n+225,AAAAAAAAAFHBIAAA,139379.81,,2000.0\r\n+226,AAAAAAAAAFHBIAAA,38369.76,,2002.0\r\n+227,AAAAAAAAAFHBIAAA,1859.14,1859.14,\r\n+228,AAAAAAAAAFHCKAAA,122636.18,146230.75,1998.0\r\n+229,AAAAAAAAAFHCKAAA,146230.75,93126.91,1999.0\r\n+230,AAAAAAAAAFHCKAAA,93126.91,26294.82,2000.0\r\n+231,AAAAAAAAAFHCKAAA,26294.82,110324.77,2001.0\r\n+232,AAAAAAAAAFHCKAAA,110324.77,,2002.0\r\n+233,AAAAAAAAAFHCKAAA,1897.36,1897.36,\r\n+234,AAAAAAAAAFHCMAAA,159008.81,,1998.0\r\n+235,AAAAAAAAAFHCMAAA,155625.65,151343.16,2000.0\r\n+236,AAAAAAAAAFHCMAAA,151343.16,185243.85,2001.0\r\n+237,AAAAAAAAAFHCMAAA,185243.85,,2002.0\r\n+238,AAAAAAAAAFHCMAAA,4137.01,4137.01,\r\n+239,AAAAAAAAAFHDLAAA,66461.94,69843.76,1998.0\r\n+240,AAAAAAAAAFHDLAAA,69843.76,44143.98,1999.0\r\n+241,AAAAAAAAAFHDLAAA,44143.98,189413.51,2000.0\r\n+242,AAAAAAAAAFHDLAAA,189413.51,41197.36,2001.0\r\n+243,AAAAAAAAAFHDLAAA,41197.36,,2002.0\r\n+244,AAAAAAAAAFHDLAAA,15523.49,15523.49,\r\n+245,AAAAAAAAAFHFEAAA,108859.32,38167.30,1998.0\r\n+246,AAAAAAAAAFHFEAAA,38167.30,56658.00,1999.0\r\n+247,AAAAAAAAAFHFEAAA,56658.00,63570.16,2000.0\r\n+248,AAAAAAAAAFHFEAAA,63570.16,126514.39,2001.0\r\n+249,AAAAAAAAAFHFEAAA,126514.39,,2002.0\r\n+250,AAAAAAAAAFHFEAAA,4361.26,4361.26,\r\n+251,AAAAAAAAAFHFHBAA,14909.00,95607.35,1998.0\r\n+252,AAAAAAAAAFHFHBAA,95607.35,30696.61,1999.0\r\n+253,AAAAAAAAAFHFHBAA,30696.61,,2000.0\r\n+254,AAAAAAAAAFHGOAAA,85129.37,94362.22,1999.0\r\n+255,AAAAAAAAAFHGOAAA,94362.22,104701.44,2000.0\r\n+256,AAAAAAAAAFHGOAAA,104701.44,70028.28,2001.0\r\n+257,AAAAAAAAAFHGOAAA,70028.28,,2002.0\r\n+258,AAAAAAAAAFHGOAAA,9324.66,9324.66,\r\n+259,AAAAAAAAAFHHFBAA,46282.87,38686.57,1998.0\r\n+260,AAAAAAAAAFHHFBAA,38686.57,106496.49,1999.0\r\n+261,AAAAAAAAAFHHFBAA,106496.49,107253.90,2000.0\r\n+262,AAAAAAAAAFHHFBAA,107253.90,69849.87,2001.0\r\n+263,AAAAAAAAAFHHFBAA,69849.87,,2002.0\r\n+264,AAAAAAAAAFHHFBAA,,,\r\n+265,AAAAAAAAAFHHIBAA,134815.31,108015.71,1998.0\r\n+266,AAAAAAAAAFHHIBAA,108015.71,66060.03,1999.0\r\n+267,AAAAAAAAAFHHIBAA,66060.03,98405.97,2000.0\r\n+268,AAAAAAAAAFHHIBAA,98405.97,,2001.0\r\n+269,AAAAAAAAAFHHIBAA,,,\r\n+270,AAAAAAAAAFHHMBAA,85756.12,139343.63,1998.0\r\n+271,AAAAAAAAAFHHMBAA,139343.63,108837.87,1999.0\r\n+272,AAAAAAAAAFHHMBAA,108837.87,74498.25,2000.0\r\n+273,AAAAAAAAAFHHMBAA,74498.25,115728.71,2001.0\r\n+274,AAAAAAAAAFHHMBAA,115728.71,,2002.0\r\n+275,AAAAAAAAAFHHMBAA,,,\r\n+276,AAAAAAAAAFHJJAAA,64644.06,80674.04,1998.0\r\n+277,AAAAAAAAAFHJJAAA,80674.04,112662.80,1999.0\r\n+278,AAAAAAAAAFHJJAAA,112662.80,192606.27,2000.0\r\n+279,AAAAAAAAAFHJJAAA,192606.27,122730.12,2001.0\r\n+280,AAAAAAAAAFHJJAAA,122730.12,,2002.0\r\n+281,AAAAAAAAAFHJJAAA,8109.72,8109.72,\r\n+282,AAAAAAAAAFHJOAAA,66813.73,164960.50,1998.0\r\n+283,AAAAAAAAAFHJOAAA,164960.50,,1999.0\r\n+284,AAAAAAAAAFHJOAAA,33970.96,47119.63,2001.0\r\n+285,AAAAAAAAAFHJOAAA,47119.63,,2002.0\r\n+286,AAAAAAAAAFHJOAAA,3865.40,3865.40,\r\n+287,AAAAAAAAAFHKCAAA,45672.48,85276.78,1998.0\r\n+288,AAAAAAAAAFHKCAAA,85276.78,98771.43,1999.0\r\n+289,AAAAAAAAAFHKCAAA,98771.43,36792.38,2000.0\r\n+290,AAAAAAAAAFHKCAAA,36792.38,180002.24,2001.0\r\n+291,AAAAAAAAAFHKCAAA,180002.24,,2002.0\r\n+292,AAAAAAAAAFHKCAAA,2076.80,2076.80,\r\n+293,AAAAAAAAAFHKHBAA,126717.87,55341.71,1998.0\r\n+294,AAAAAAAAAFHKHBAA,55341.71,81324.68,1999.0\r\n+295,AAAAAAAAAFHKHBAA,81324.68,67810.77,2000.0\r\n+296,AAAAAAAAAFHKHBAA,67810.77,152970.25,2001.0\r\n+297,AAAAAAAAAFHKHBAA,152970.25,,2002.0\r\n+298,AAAAAAAAAFHKHBAA,10387.91,10387.91,\r\n+299,AAAAAAAAAFHKMAAA,28771.32,193991.56,1998.0\r\n+300,AAAAAAAAAFHKMAAA,193991.56,154222.00,1999.0\r\n+301,AAAAAAAAAFHKMAAA,154222.00,102025.81,2000.0\r\n+302,AAAAAAAAAFHKMAAA,102025.81,40751.76,2001.0\r\n+303,AAAAAAAAAFHKMAAA,40751.76,,2002.0\r\n+304,AAAAAAAAAFHKMAAA,1043.85,1043.85,\r\n+305,AAAAAAAAAFHLDAAA,37882.32,,1998.0\r\n+306,AAAAAAAAAFHLDAAA,49670.79,100254.30,2000.0\r\n+307,AAAAAAAAAFHLDAAA,100254.30,316438.97,2001.0\r\n+308,AAAAAAAAAFHLDAAA,316438.97,,2002.0\r\n+309,AAAAAAAAAFHLDAAA,,,\r\n+310,AAAAAAAAAFHLEAAA,138914.88,27325.69,1998.0\r\n+311,AAAAAAAAAFHLEAAA,27325.69,51469.37,1999.0\r\n+312,AAAAAAAAAFHLEAAA,51469.37,49731.56,2000.0\r\n+313,AAAAAAAAAFHLEAAA,49731.56,116083.41,2001.0\r\n+314,AAAAAAAAAFHLEAAA,116083.41,,2002.0\r\n+315,AAAAAAAAAFHLEAAA,,,\r\n+316,AAAAAAAAAFHMBBAA,36424.91,231141.02,1998.0\r\n+317,AAAAAAAAAFHMBBAA,231141.02,143077.26,1999.0\r\n+318,AAAAAAAAAFHMBBAA,143077.26,113414.84,2000.0\r\n+319,AAAAAAAAAFHMBBAA,113414.84,112050.23,2001.0\r\n+320,AAAAAAAAAFHMBBAA,112050.23,,2002.0\r\n+321,AAAAAAAAAFHMBBAA,,,\r\n+322,AAAAAAAAAFHMDAAA,102290.19,,1998.0\r\n+323,AAAAAAAAAFHMDAAA,79592.33,,2000.0\r\n+324,AAAAAAAAAFHMDAAA,167849.01,,2002.0\r\n+325,AAAAAAAAAFHMDAAA,,,\r\n+326,AAAAAAAAAFHNCBAA,103857.72,172530.76,1998.0\r\n+327,AAAAAAAAAFHNCBAA,172530.76,158735.86,1999.0\r\n+328,AAAAAAAAAFHNCBAA,158735.86,110247.23,2000.0\r\n+329,AAAAAAAAAFHNCBAA,110247.23,,2001.0\r\n+330,AAAAAAAAAFHNCBAA,,,\r\n+331,AAAAAAAAAFHOBBAA,21931.64,47107.40,1998.0\r\n+332,AAAAAAAAAFHOBBAA,47107.40,38436.43,1999.0\r\n+333,AAAAAAAAAFHOBBAA,38436.43,24180.80,2000.0\r\n+334,AAAAAAAAAFHOBBAA,24180.80,211409.39,2001.0\r\n+335,AAAAAAAAAFHOBBAA,211409.39,,2002.0\r\n+336,AAAAAAAAAFHOBBAA,,,\r\n+337,AAAAAAAAAFHOEBAA,123448.00,,1998.0\r\n+338,AAAAAAAAAFHOEBAA,167176.37,120957.29,2000.0\r\n+339,AAAAAAAAAFHOEBAA,120957.29,22607.38,2001.0\r\n+340,AAAAAAAAAFHOEBAA,22607.38,,2002.0\r\n+341,AAAAAAAAAFHOEBAA,,,\r\n+342,AAAAAAAAAFHPDAAA,86179.45,37676.89,1998.0\r\n+343,AAAAAAAAAFHPDAAA,37676.89,181855.06,1999.0\r\n+344,AAAAAAAAAFHPDAAA,181855.06,160938.10,2000.0\r\n+345,AAAAAAAAAFHPDAAA,160938.10,120402.16,2001.0\r\n+346,AAAAAAAAAFHPDAAA,120402.16,,2002.0\r\n+347,AAAAAAAAAFHPDAAA,1129.20,1129.20,\r\n+348,AAAAAAAAAFHPMAAA,148616.63,229460.37,1998.0\r\n+349,AAAAAAAAAFHPMAAA,229460.37,59782.57,1999.0\r\n+350,AAAAAAAAAFHPMAAA,59782.57,116215.34,2000.0\r\n+351,AAAAAAAAAFHPMAAA,116215.34,122732.92,2001.0\r\n+352,AAAAAAAAAFHPMAAA,122732.92,,2002.0\r\n+353,AAAAAAAAAFHPMAAA,12635.38,12635.38,\r\n+354,AAAAAAAAAFIALAAA,136852.04,120839.39,1998.0\r\n+355,AAAAAAAAAFIALAAA,120839.39,,1999.0\r\n+356,AAAAAAAAAFIALAAA,33699.58,142335.41,2001.0\r\n+357,AAAAAAAAAFIALAAA,142335.41,,2002.0\r\n+358,AAAAAAAAAFIALAAA,,,\r\n+359,AAAAAAAAAFIAPAAA,174236.57,35871.33,1998.0\r\n+360,AAAAAAAAAFIAPAAA,35871.33,66776.08,1999.0\r\n+361,AAAAAAAAAFIAPAAA,66776.08,99012.71,2000.0\r\n+362,AAAAAAAAAFIAPAAA,99012.71,,2001.0\r\n+363,AAAAAAAAAFIAPAAA,11095.11,11095.11,\r\n+364,AAAAAAAAAFIBHBAA,110790.33,38313.06,1998.0\r\n+365,AAAAAAAAAFIBHBAA,38313.06,137595.48,1999.0\r\n+366,AAAAAAAAAFIBHBAA,137595.48,62942.60,2000.0\r\n+367,AAAAAAAAAFIBHBAA,62942.60,31255.35,2001.0\r\n+368,AAAAAAAAAFIBHBAA,31255.35,,2002.0\r\n+369,AAAAAAAAAFIBHBAA,,,\r\n+370,AAAAAAAAAFIBLBAA,102916.55,95615.08,1998.0\r\n+371,AAAAAAAAAFIBLBAA,95615.08,56855.03,1999.0\r\n+372,AAAAAAAAAFIBLBAA,56855.03,,2000.0\r\n+373,AAAAAAAAAFIBLBAA,49034.88,,2002.0\r\n+374,AAAAAAAAAFIBOBAA,89313.30,270226.65,1998.0\r\n+375,AAAAAAAAAFIBOBAA,270226.65,199424.89,1999.0\r\n+376,AAAAAAAAAFIBOBAA,199424.89,148750.56,2000.0\r\n+377,AAAAAAAAAFIBOBAA,148750.56,7196.87,2001.0\r\n+378,AAAAAAAAAFIBOBAA,7196.87,,2002.0\r\n+379,AAAAAAAAAFIBOBAA,,,\r\n+380,AAAAAAAAAFIBPAAA,67704.07,59688.04,1998.0\r\n+381,AAAAAAAAAFIBPAAA,59688.04,235489.70,1999.0\r\n+382,AAAAAAAAAFIBPAAA,235489.70,106048.85,2000.0\r\n+383,AAAAAAAAAFIBPAAA,106048.85,158257.78,2001.0\r\n+384,AAAAAAAAAFIBPAAA,158257.78,,2002.0\r\n+385,AAAAAAAAAFIBPAAA,4431.48,4431.48,\r\n+386,AAAAAAAAAFICKAAA,108648.16,136414.37,1998.0\r\n+387,AAAAAAAAAFICKAAA,136414.37,53850.13,1999.0\r\n+388,AAAAAAAAAFICKAAA,53850.13,78412.60,2000.0\r\n+389,AAAAAAAAAFICKAAA,78412.60,65266.14,2001.0\r\n+390,AAAAAAAAAFICKAAA,65266.14,,2002.0\r\n+391,AAAAAAAAAFICKAAA,8729.84,8729.84,\r\n+392,AAAAAAAAAFIDDAAA,59166.83,95873.43,1998.0\r\n+393,AAAAAAAAAFIDDAAA,95873.43,55019.19,1999.0\r\n+394,AAAAAAAAAFIDDAAA,55019.19,27449.13,2000.0\r\n+395,AAAAAAAAAFIDDAAA,27449.13,159392.74,2001.0\r\n+396,AAAAAAAAAFIDDAAA,159392.74,,2002.0\r\n+397,AAAAAAAAAFIDDAAA,11631.55,11631.55,\r\n+398,AAAAAAAAAFIDFBAA,18474.48,78409.06,1998.0\r\n+399,AAAAAAAAAFIDFBAA,78409.06,116578.47,1999.0\r\n+400,AAAAAAAAAFIDFBAA,116578.47,59600.56,2000.0\r\n+401,AAAAAAAAAFIDFBAA,59600.56,89929.53,2001.0\r\n+402,AAAAAAAAAFIDFBAA,89929.53,,2002.0\r\n+403,AAAAAAAAAFIDFBAA,,,\r\n+404,AAAAAAAAAFIEDBAA,64015.58,115364.51,1998.0\r\n+405,AAAAAAAAAFIEDBAA,115364.51,,1999.0\r\n+406,AAAAAAAAAFIEDBAA,47431.93,85298.69,2001.0\r\n+407,AAAAAAAAAFIEDBAA,85298.69,,2002.0\r\n+408,AAAAAAAAAFIEDBAA,3981.46,3981.46,\r\n+409,AAAAAAAAAFIEHAAA,164160.26,31555.22,1998.0\r\n+410,AAAAAAAAAFIEHAAA,31555.22,70690.25,1999.0\r\n+411,AAAAAAAAAFIEHAAA,70690.25,134173.30,2000.0\r\n+412,AAAAAAAAAFIEHAAA,134173.30,126092.08,2001.0\r\n+413,AAAAAAAAAFIEHAAA,126092.08,,2002.0\r\n+414,AAAAAAAAAFIEHAAA,17345.60,17345.60,\r\n+415,AAAAAAAAAFIEOAAA,23412.65,47405.09,1998.0\r\n+416,AAAAAAAAAFIEOAAA,47405.09,73852.40,1999.0\r\n+417,AAAAAAAAAFIEOAAA,73852.40,195146.97,2000.0\r\n+418,AAAAAAAAAFIEOAAA,195146.97,124672.39,2001.0\r\n+419,AAAAAAAAAFIEOAAA,124672.39,,2002.0\r\n+420,AAAAAAAAAFIEOAAA,,,\r\n+421,AAAAAAAAAFIFEBAA,96476.01,76392.44,1998.0\r\n+422,AAAAAAAAAFIFEBAA,76392.44,,1999.0\r\n+423,AAAAAAAAAFIFEBAA,62962.74,,2002.0\r\n+424,AAAAAAAAAFIFIBAA,113720.06,56016.20,1998.0\r\n+425,AAAAAAAAAFIFIBAA,56016.20,,1999.0\r\n+426,AAAAAAAAAFIFIBAA,107833.33,,2002.0\r\n+427,AAAAAAAAAFIFIBAA,,,\r\n+428,AAAAAAAAAFIFLAAA,182678.34,104055.10,1998.0\r\n+429,AAAAAAAAAFIFLAAA,104055.10,84138.30,1999.0\r\n+430,AAAAAAAAAFIFLAAA,84138.30,39327.04,2000.0\r\n+431,AAAAAAAAAFIFLAAA,39327.04,136063.14,2001.0\r\n+432,AAAAAAAAAFIFLAAA,136063.14,,2002.0\r\n+433,AAAAAAAAAFIFLAAA,14416.38,14416.38,\r\n+434,AAAAAAAAAFIGKAAA,34131.06,118855.33,1999.0\r\n+435,AAAAAAAAAFIGKAAA,118855.33,95475.73,2000.0\r\n+436,AAAAAAAAAFIGKAAA,95475.73,49965.49,2001.0\r\n+437,AAAAAAAAAFIGKAAA,49965.49,,2002.0\r\n+438,AAAAAAAAAFIGLBAA,95422.96,49496.14,1998.0\r\n+439,AAAAAAAAAFIGLBAA,49496.14,75463.77,1999.0\r\n+440,AAAAAAAAAFIGLBAA,75463.77,42544.76,2000.0\r\n+441,AAAAAAAAAFIGLBAA,42544.76,162791.54,2001.0\r\n+442,AAAAAAAAAFIGLBAA,162791.54,,2002.0\r\n+443,AAAAAAAAAFIGLBAA,2411.60,2411.60,\r\n+444,AAAAAAAAAFIHCBAA,129192.68,33783.45,1998.0\r\n+445,AAAAAAAAAFIHCBAA,33783.45,169969.37,1999.0\r\n+446,AAAAAAAAAFIHCBAA,169969.37,,2000.0\r\n+447,AAAAAAAAAFIHCBAA,90949.26,,2002.0\r\n+448,AAAAAAAAAFIHCBAA,,,\r\n+449,AAAAAAAAAFIHOAAA,196397.36,33977.64,1998.0\r\n+450,AAAAAAAAAFIHOAAA,33977.64,,1999.0\r\n+451,AAAAAAAAAFIHOAAA,143133.01,38893.05,2001.0\r\n+452,AAAAAAAAAFIHOAAA,38893.05,,2002.0\r\n+453,AAAAAAAAAFIHOAAA,1293.09,1293.09,\r\n+454,AAAAAAAAAFIICAAA,141209.47,64193.34,1998.0\r\n+455,AAAAAAAAAFIICAAA,64193.34,134758.12,1999.0\r\n+456,AAAAAAAAAFIICAAA,134758.12,35161.40,2000.0\r\n+457,AAAAAAAAAFIICAAA,35161.40,106119.30,2001.0\r\n+458,AAAAAAAAAFIICAAA,106119.30,,2002.0\r\n+459,AAAAAAAAAFIICAAA,5834.88,5834.88,\r\n+460,AAAAAAAAAFIJBBAA,212846.83,53748.10,1998.0\r\n+461,AAAAAAAAAFIJBBAA,53748.10,109215.73,1999.0\r\n+462,AAAAAAAAAFIJBBAA,109215.73,63576.68,2000.0\r\n+463,AAAAAAAAAFIJBBAA,63576.68,213847.17,2001.0\r\n+464,AAAAAAAAAFIJBBAA,213847.17,,2002.0\r\n+465,AAAAAAAAAFIJBBAA,517.98,517.98,\r\n+466,AAAAAAAAAFIJIAAA,49288.93,187326.92,1998.0\r\n+467,AAAAAAAAAFIJIAAA,187326.92,50754.54,1999.0\r\n+468,AAAAAAAAAFIJIAAA,50754.54,44549.27,2000.0\r\n+469,AAAAAAAAAFIJIAAA,44549.27,132998.20,2001.0\r\n+470,AAAAAAAAAFIJIAAA,132998.20,,2002.0\r\n+471,AAAAAAAAAFIJIAAA,10359.00,10359.00,\r\n+472,AAAAAAAAAFIKPAAA,34673.75,44472.41,1999.0\r\n+473,AAAAAAAAAFIKPAAA,44472.41,37416.67,2000.0\r\n+474,AAAAAAAAAFIKPAAA,37416.67,74930.00,2001.0\r\n+475,AAAAAAAAAFIKPAAA,74930.00,,2002.0\r\n+476,AAAAAAAAAFIKPAAA,2395.53,2395.53,\r\n+477,AAAAAAAAAFILCBAA,249510.35,93371.44,1998.0\r\n+478,AAAAAAAAAFILCBAA,93371.44,73810.93,1999.0\r\n+479,AAAAAAAAAFILCBAA,73810.93,160992.29,2000.0\r\n+480,AAAAAAAAAFILCBAA,160992.29,,2001.0\r\n+481,AAAAAAAAAFILCBAA,2468.64,2468.64,\r\n+482,AAAAAAAAAFIMBBAA,125058.78,198666.57,1998.0\r\n+483,AAAAAAAAAFIMBBAA,198666.57,12930.93,1999.0\r\n+484,AAAAAAAAAFIMBBAA,12930.93,,2000.0\r\n+485,AAAAAAAAAFIMBBAA,22552.13,,2002.0\r\n+486,AAAAAAAAAFIMBBAA,6380.22,6380.22,\r\n+487,AAAAAAAAAFIODBAA,30637.19,57499.08,1998.0\r\n+488,AAAAAAAAAFIODBAA,57499.08,111992.08,1999.0\r\n+489,AAAAAAAAAFIODBAA,111992.08,77552.22,2000.0\r\n+490,AAAAAAAAAFIODBAA,77552.22,,2001.0\r\n+491,AAAAAAAAAFIODBAA,8855.28,8855.28,\r\n+492,AAAAAAAAAFIOHAAA,77896.47,211189.93,1998.0\r\n+493,AAAAAAAAAFIOHAAA,211189.93,151270.88,1999.0\r\n+494,AAAAAAAAAFIOHAAA,151270.88,291624.73,2000.0\r\n+495,AAAAAAAAAFIOHAAA,291624.73,110626.36,2001.0\r\n+496,AAAAAAAAAFIOHAAA,110626.36,,2002.0\r\n+497,AAAAAAAAAFIOHAAA,4550.65,4550.65,\r\n+498,AAAAAAAAAFIOKBAA,48896.97,121503.84,1998.0\r\n+499,AAAAAAAAAFIOKBAA,121503.84,65043.86,1999.0\r\n+500,AAAAAAAAAFIOKBAA,65043.86,96900.04,2000.0\r\n+501,AAAAAAAAAFIOKBAA,96900.04,196661.64,2001.0\r\n+502,AAAAAAAAAFIOKBAA,196661.64,,2002.0\r\n+503,AAAAAAAAAFIOKBAA,137.28,137.28,\r\n+504,AAAAAAAAAFIPCBAA,49006.64,,1998.0\r\n+505,AAAAAAAAAFIPCBAA,52358.82,55902.35,2000.0\r\n+506,AAAAAAAAAFIPCBAA,55902.35,61874.75,2001.0\r\n+507,AAAAAAAAAFIPCBAA,61874.75,,2002.0\r\n+508,AAAAAAAAAFIPCBAA,219.50,219.50,\r\n+509,AAAAAAAAAFIPDAAA,190330.20,107576.79,1998.0\r\n+510,AAAAAAAAAFIPDAAA,107576.79,120675.92,1999.0\r\n+511,AAAAAAAAAFIPDAAA,120675.92,156572.51,2000.0\r\n+512,AAAAAAAAAFIPDAAA,156572.51,138636.38,2001.0\r\n+513,AAAAAAAAAFIPDAAA,138636.38,,2002.0\r\n+514,AAAAAAAAAFIPDAAA,4036.56,4036.56,\r\n+515,AAAAAAAAAFIPJBAA,33695.29,229587.85,1998.0\r\n+516,AAAAAAAAAFIPJBAA,229587.85,163515.10,1999.0\r\n+517,AAAAAAAAAFIPJBAA,163515.10,45344.48,2000.0\r\n+518,AAAAAAAAAFIPJBAA,45344.48,47162.71,2001.0\r\n+519,AAAAAAAAAFIPJBAA,47162.71,,2002.0\r\n+520,AAAAAAAAAFIPJBAA,7305.00,7305.00,\r\n+521,AAAAAAAAAFJADAAA,151111.35,143541.14,1998.0\r\n+522,AAAAAAAAAFJADAAA,143541.14,91273.95,1999.0\r\n+523,AAAAAAAAAFJADAAA,91273.95,83220.61,2000.0\r\n+524,AAAAAAAAAFJADAAA,83220.61,37350.03,2001.0\r\n+525,AAAAAAAAAFJADAAA,37350.03,,2002.0\r\n+526,AAAAAAAAAFJADAAA,,,\r\n+527,AAAAAAAAAFJADBAA,62798.17,79954.62,1998.0\r\n+528,AAAAAAAAAFJADBAA,79954.62,161967.89,1999.0\r\n+529,AAAAAAAAAFJADBAA,161967.89,136248.74,2000.0\r\n+530,AAAAAAAAAFJADBAA,136248.74,25249.36,2001.0\r\n+531,AAAAAAAAAFJADBAA,25249.36,,2002.0\r\n+532,AAAAAAAAAFJADBAA,,,\r\n+533,AAAAAAAAAFJBFBAA,36950.26,114920.35,1998.0\r\n+534,AAAAAAAAAFJBFBAA,114920.35,46088.20,1999.0\r\n+535,AAAAAAAAAFJBFBAA,46088.20,65639.82,2000.0\r\n+536,AAAAAAAAAFJBFBAA,65639.82,155444.43,2001.0\r\n+537,AAAAAAAAAFJBFBAA,155444.43,,2002.0\r\n+538,AAAAAAAAAFJBFBAA,,,\r\n+539,AAAAAAAAAFJBPAAA,81005.48,54403.53,1998.0\r\n+540,AAAAAAAAAFJBPAAA,54403.53,101134.14,1999.0\r\n+541,AAAAAAAAAFJBPAAA,101134.14,187444.98,2000.0\r\n+542,AAAAAAAAAFJBPAAA,187444.98,23791.86,2001.0\r\n+543,AAAAAAAAAFJBPAAA,23791.86,,2002.0\r\n+544,AAAAAAAAAFJBPAAA,,,\r\n+545,AAAAAAAAAFJCFBAA,34245.30,152856.63,1998.0\r\n+546,AAAAAAAAAFJCFBAA,152856.63,97045.38,1999.0\r\n+547,AAAAAAAAAFJCFBAA,97045.38,64670.97,2000.0\r\n+548,AAAAAAAAAFJCFBAA,64670.97,46006.39,2001.0\r\n+549,AAAAAAAAAFJCFBAA,46006.39,,2002.0\r\n+550,AAAAAAAAAFJCFBAA,6461.70,6461.70,\r\n+551,AAAAAAAAAFJCPAAA,85480.17,52056.03,1998.0\r\n+552,AAAAAAAAAFJCPAAA,52056.03,125855.37,1999.0\r\n+553,AAAAAAAAAFJCPAAA,125855.37,88464.85,2000.0\r\n+554,AAAAAAAAAFJCPAAA,88464.85,27727.68,2001.0\r\n+555,AAAAAAAAAFJCPAAA,27727.68,,2002.0\r\n+556,AAAAAAAAAFJDABAA,100830.19,62696.27,1998.0\r\n+557,AAAAAAAAAFJDABAA,62696.27,63283.58,1999.0\r\n+558,AAAAAAAAAFJDABAA,63283.58,43439.33,2000.0\r\n+559,AAAAAAAAAFJDABAA,43439.33,139005.31,2001.0\r\n+560,AAAAAAAAAFJDABAA,139005.31,,2002.0\r\n+561,AAAAAAAAAFJDABAA,4836.00,4836.00,\r\n+562,AAAAAAAAAFJDBAAA,46536.37,109135.12,1998.0\r\n+563,AAAAAAAAAFJDBAAA,109135.12,216887.55,1999.0\r\n+564,AAAAAAAAAFJDBAAA,216887.55,86093.54,2000.0\r\n+565,AAAAAAAAAFJDBAAA,86093.54,43110.31,2001.0\r\n+566,AAAAAAAAAFJDBAAA,43110.31,,2002.0\r\n+567,AAAAAAAAAFJDBAAA,692.25,692.25,\r\n+568,AAAAAAAAAFJDDAAA,149637.97,134102.90,1998.0\r\n+569,AAAAAAAAAFJDDAAA,134102.90,146085.93,1999.0\r\n+570,AAAAAAAAAFJDDAAA,146085.93,25213.91,2000.0\r\n+571,AAAAAAAAAFJDDAAA,25213.91,26781.84,2001.0\r\n+572,AAAAAAAAAFJDDAAA,26781.84,,2002.0\r\n+573,AAAAAAAAAFJDDAAA,,,\r\n+574,AAAAAAAAAFJEKBAA,39857.45,85641.55,1998.0\r\n+575,AAAAAAAAAFJEKBAA,85641.55,115716.28,1999.0\r\n+576,AAAAAAAAAFJEKBAA,115716.28,98410.88,2000.0\r\n+577,AAAAAAAAAFJEKBAA,98410.88,276147.55,2001.0\r\n+578,AAAAAAAAAFJEKBAA,276147.55,,2002.0\r\n+579,AAAAAAAAAFJEKBAA,6784.70,6784.70,\r\n+580,AAAAAAAAAFJFEAAA,174498.08,40516.10,1998.0\r\n+581,AAAAAAAAAFJFEAAA,40516.10,18897.03,1999.0\r\n+582,AAAAAAAAAFJFEAAA,18897.03,136626.00,2000.0\r\n+583,AAAAAAAAAFJFEAAA,136626.00,40377.49,2001.0\r\n+584,AAAAAAAAAFJFEAAA,40377.49,,2002.0\r\n+585,AAAAAAAAAFJFEAAA,1557.76,1557.76,\r\n+586,AAAAAAAAAFJFEBAA,201825.86,148041.66,1998.0\r\n+587,AAAAAAAAAFJFEBAA,148041.66,71483.21,1999.0\r\n+588,AAAAAAAAAFJFEBAA,71483.21,271772.60,2000.0\r\n+589,AAAAAAAAAFJFEBAA,271772.60,32772.41,2001.0\r\n+590,AAAAAAAAAFJFEBAA,32772.41,,2002.0\r\n+591,AAAAAAAAAFJFEBAA,3453.32,3453.32,\r\n+592,AAAAAAAAAFJFHBAA,120501.60,42140.12,1998.0\r\n+593,AAAAAAAAAFJFHBAA,42140.12,166125.25,1999.0\r\n+594,AAAAAAAAAFJFHBAA,166125.25,72156.08,2000.0\r\n+595,AAAAAAAAAFJFHBAA,72156.08,37162.38,2001.0\r\n+596,AAAAAAAAAFJFHBAA,37162.38,,2002.0\r\n+597,AAAAAAAAAFJFHBAA,6964.62,6964.62,\r\n+598,AAAAAAAAAFJHMBAA,123747.64,65076.11,1998.0\r\n+599,AAAAAAAAAFJHMBAA,65076.11,23999.82,1999.0\r\n+600,AAAAAAAAAFJHMBAA,23999.82,128232.37,2000.0\r\n+601,AAAAAAAAAFJHMBAA,128232.37,,2001.0\r\n+602,AAAAAAAAAFJHMBAA,8788.99,8788.99,\r\n+603,AAAAAAAAAFJIEBAA,120436.15,165031.75,1998.0\r\n+604,AAAAAAAAAFJIEBAA,165031.75,70583.78,1999.0\r\n+605,AAAAAAAAAFJIEBAA,70583.78,147841.78,2000.0\r\n+606,AAAAAAAAAFJIEBAA,147841.78,,2001.0\r\n+607,AAAAAAAAAFJIEBAA,8963.42,8963.42,\r\n+608,AAAAAAAAAFJIIBAA,72798.47,,1999.0\r\n+609,AAAAAAAAAFJIIBAA,48841.40,129914.75,2001.0\r\n+610,AAAAAAAAAFJIIBAA,129914.75,,2002.0\r\n+611,AAAAAAAAAFJIIBAA,,,\r\n+612,AAAAAAAAAFJIKBAA,214626.75,40494.42,1998.0\r\n+613,AAAAAAAAAFJIKBAA,40494.42,107651.22,1999.0\r\n+614,AAAAAAAAAFJIKBAA,107651.22,132584.54,2000.0\r\n+615,AAAAAAAAAFJIKBAA,132584.54,39661.43,2001.0\r\n+616,AAAAAAAAAFJIKBAA,39661.43,,2002.0\r\n+617,AAAAAAAAAFJIKBAA,,,\r\n+618,AAAAAAAAAFJJIBAA,164210.55,15955.17,1998.0\r\n+619,AAAAAAAAAFJJIBAA,15955.17,71742.35,1999.0\r\n+620,AAAAAAAAAFJJIBAA,71742.35,68543.38,2000.0\r\n+621,AAAAAAAAAFJJIBAA,68543.38,116989.57,2001.0\r\n+622,AAAAAAAAAFJJIBAA,116989.57,,2002.0\r\n+623,AAAAAAAAAFJJIBAA,,,\r\n+624,AAAAAAAAAFJJMAAA,102911.03,33098.26,1998.0\r\n+625,AAAAAAAAAFJJMAAA,33098.26,96625.70,1999.0\r\n+626,AAAAAAAAAFJJMAAA,96625.70,222772.59,2000.0\r\n+627,AAAAAAAAAFJJMAAA,222772.59,303219.70,2001.0\r\n+628,AAAAAAAAAFJJMAAA,303219.70,45704.85,2002.0\r\n+629,AAAAAAAAAFJJMAAA,45704.85,,2003.0\r\n+630,AAAAAAAAAFJJMAAA,3729.24,3729.24,\r\n+631,AAAAAAAAAFJJPAAA,76633.43,,1998.0\r\n+632,AAAAAAAAAFJJPAAA,144907.15,51814.30,2000.0\r\n+633,AAAAAAAAAFJJPAAA,51814.30,93212.44,2001.0\r\n+634,AAAAAAAAAFJJPAAA,93212.44,,2002.0\r\n+635,AAAAAAAAAFJJPAAA,2434.20,2434.20,\r\n+636,AAAAAAAAAFJKBAAA,78958.84,52411.07,1998.0\r\n+637,AAAAAAAAAFJKBAAA,52411.07,88922.37,1999.0\r\n+638,AAAAAAAAAFJKBAAA,88922.37,30065.42,2000.0\r\n+639,AAAAAAAAAFJKBAAA,30065.42,59476.92,2001.0\r\n+640,AAAAAAAAAFJKBAAA,59476.92,,2002.0\r\n+641,AAAAAAAAAFJKBAAA,1142.64,1142.64,\r\n+642,AAAAAAAAAFJKDAAA,76991.23,18825.40,1998.0\r\n+643,AAAAAAAAAFJKDAAA,18825.40,120471.97,1999.0\r\n+644,AAAAAAAAAFJKDAAA,120471.97,88914.89,2000.0\r\n+645,AAAAAAAAAFJKDAAA,88914.89,,2001.0\r\n+646,AAAAAAAAAFJKDAAA,,,\r\n+647,AAAAAAAAAFJKLAAA,89554.76,51378.25,1998.0\r\n+648,AAAAAAAAAFJKLAAA,51378.25,63145.68,1999.0\r\n+649,AAAAAAAAAFJKLAAA,63145.68,63460.62,2000.0\r\n+650,AAAAAAAAAFJKLAAA,63460.62,83008.54,2001.0\r\n+651,AAAAAAAAAFJKLAAA,83008.54,,2002.0\r\n+652,AAAAAAAAAFJKLAAA,10723.18,10723.18,\r\n+653,AAAAAAAAAFJKPAAA,148754.85,,1998.0\r\n+654,AAAAAAAAAFJKPAAA,157464.50,25157.82,2000.0\r\n+655,AAAAAAAAAFJKPAAA,25157.82,125091.01,2001.0\r\n+656,AAAAAAAAAFJKPAAA,125091.01,,2002.0\r\n+657,AAAAAAAAAFJKPAAA,,,\r\n+658,AAAAAAAAAFJLLAAA,153931.45,194522.51,1998.0\r\n+659,AAAAAAAAAFJLLAAA,194522.51,23429.19,1999.0\r\n+660,AAAAAAAAAFJLLAAA,23429.19,97431.27,2000.0\r\n+661,AAAAAAAAAFJLLAAA,97431.27,47253.52,2001.0\r\n+662,AAAAAAAAAFJLLAAA,47253.52,,2002.0\r\n+663,AAAAAAAAAFJLLAAA,591.33,591.33,\r\n+664,AAAAAAAAAFJLMBAA,94789.24,77687.28,1998.0\r\n+665,AAAAAAAAAFJLMBAA,77687.28,92756.18,1999.0\r\n+666,AAAAAAAAAFJLMBAA,92756.18,33788.13,2000.0\r\n+667,AAAAAAAAAFJLMBAA,33788.13,202091.60,2001.0\r\n+668,AAAAAAAAAFJLMBAA,202091.60,,2002.0\r\n+669,AAAAAAAAAFJLMBAA,,,\r\n+670,AAAAAAAAAFJMAAAA,46596.12,60264.59,1998.0\r\n+671,AAAAAAAAAFJMAAAA,60264.59,,1999.0\r\n+672,AAAAAAAAAFJMAAAA,45648.90,133162.09,2001.0\r\n+673,AAAAAAAAAFJMAAAA,133162.09,,2002.0\r\n+674,AAAAAAAAAFJMAAAA,6408.60,6408.60,\r\n+675,AAAAAAAAAFJMLBAA,29795.15,150172.26,1998.0\r\n+676,AAAAAAAAAFJMLBAA,150172.26,179060.95,1999.0\r\n+677,AAAAAAAAAFJMLBAA,179060.95,48331.02,2000.0\r\n+678,AAAAAAAAAFJMLBAA,48331.02,108023.35,2001.0\r\n+679,AAAAAAAAAFJMLBAA,108023.35,,2002.0\r\n+680,AAAAAAAAAFJMLBAA,,,\r\n+681,AAAAAAAAAFJNCAAA,60534.26,,1998.0\r\n+682,AAAAAAAAAFJNCAAA,109599.65,111473.52,2000.0\r\n+683,AAAAAAAAAFJNCAAA,111473.52,165539.78,2001.0\r\n+684,AAAAAAAAAFJNCAAA,165539.78,,2002.0\r\n+685,AAAAAAAAAFJNCAAA,,,\r\n+686,AAAAAAAAAFJNIAAA,39541.50,178533.37,1998.0\r\n+687,AAAAAAAAAFJNIAAA,178533.37,176222.64,1999.0\r\n+688,AAAAAAAAAFJNIAAA,176222.64,159532.86,2000.0\r\n+689,AAAAAAAAAFJNIAAA,159532.86,,2001.0\r\n+690,AAAAAAAAAFJNIAAA,,,\r\n+691,AAAAAAAAAFJOKBAA,147760.05,152864.94,1998.0\r\n+692,AAAAAAAAAFJOKBAA,152864.94,169675.46,1999.0\r\n+693,AAAAAAAAAFJOKBAA,169675.46,60329.48,2000.0\r\n+694,AAAAAAAAAFJOKBAA,60329.48,78910.74,2001.0\r\n+695,AAAAAAAAAFJOKBAA,78910.74,,2002.0\r\n+696,AAAAAAAAAFJOKBAA,5188.02,5188.02,\r\n+697,AAAAAAAAAFJPBBAA,37666.28,44221.41,1998.0\r\n+698,AAAAAAAAAFJPBBAA,44221.41,70244.05,1999.0\r\n+699,AAAAAAAAAFJPBBAA,70244.05,50124.51,2000.0\r\n+700,AAAAAAAAAFJPBBAA,50124.51,51429.34,2001.0\r\n+701,AAAAAAAAAFJPBBAA,51429.34,,2002.0\r\n+702,AAAAAAAAAFJPBBAA,,,\r\n+703,AAAAAAAAAFJPCBAA,93149.25,148961.66,1998.0\r\n+704,AAAAAAAAAFJPCBAA,148961.66,75464.96,1999.0\r\n+705,AAAAAAAAAFJPCBAA,75464.96,,2000.0\r\n+706,AAAAAAAAAFJPCBAA,102585.83,47353.39,2002.0\r\n+707,AAAAAAAAAFJPCBAA,47353.39,,2003.0\r\n+708,AAAAAAAAAFJPCBAA,4096.86,4096.86,\r\n+709,AAAAAAAAAFKBBBAA,55137.33,,1998.0\r\n+710,AAAAAAAAAFKBBBAA,139514.46,180128.83,2000.0\r\n+711,AAAAAAAAAFKBBBAA,180128.83,34053.91,2001.0\r\n+712,AAAAAAAAAFKBBBAA,34053.91,,2002.0\r\n+713,AAAAAAAAAFKBBBAA,1937.45,1937.45,\r\n+714,AAAAAAAAAFKCDBAA,138125.72,149689.74,1998.0\r\n+715,AAAAAAAAAFKCDBAA,149689.74,24123.51,1999.0\r\n+716,AAAAAAAAAFKCDBAA,24123.51,34078.59,2000.0\r\n+717,AAAAAAAAAFKCDBAA,34078.59,131699.43,2001.0\r\n+718,AAAAAAAAAFKCDBAA,131699.43,,2002.0\r\n+719,AAAAAAAAAFKCDBAA,3827.95,3827.95,\r\n+720,AAAAAAAAAFKDDAAA,18508.52,59446.80,1998.0\r\n+721,AAAAAAAAAFKDDAAA,59446.80,145787.90,1999.0\r\n+722,AAAAAAAAAFKDDAAA,145787.90,135280.38,2000.0\r\n+723,AAAAAAAAAFKDDAAA,135280.38,15200.22,2001.0\r\n+724,AAAAAAAAAFKDDAAA,15200.22,,2002.0\r\n+725,AAAAAAAAAFKDDAAA,8191.92,8191.92,\r\n+726,AAAAAAAAAFKDHAAA,89290.23,191620.35,1998.0\r\n+727,AAAAAAAAAFKDHAAA,191620.35,,1999.0\r\n+728,AAAAAAAAAFKDHAAA,95542.28,22347.09,2001.0\r\n+729,AAAAAAAAAFKDHAAA,22347.09,,2002.0\r\n+730,AAAAAAAAAFKDHAAA,,,\r\n+731,AAAAAAAAAFKEIAAA,42205.08,,1998.0\r\n+732,AAAAAAAAAFKEIAAA,173353.63,120577.70,2000.0\r\n+733,AAAAAAAAAFKEIAAA,120577.70,21853.98,2001.0\r\n+734,AAAAAAAAAFKEIAAA,21853.98,,2002.0\r\n+735,AAAAAAAAAFKEIAAA,973.10,973.10,\r\n+736,AAAAAAAAAFKEKAAA,319232.38,,1998.0\r\n+737,AAAAAAAAAFKEKAAA,167597.33,163223.48,2000.0\r\n+738,AAAAAAAAAFKEKAAA,163223.48,49231.51,2001.0\r\n+739,AAAAAAAAAFKEKAAA,49231.51,,2002.0\r\n+740,AAAAAAAAAFKEKAAA,3065.30,3065.30,\r\n+741,AAAAAAAAAFKFEAAA,79764.43,,1998.0\r\n+742,AAAAAAAAAFKFEAAA,22123.34,148256.62,2000.0\r\n+743,AAAAAAAAAFKFEAAA,148256.62,50980.48,2001.0\r\n+744,AAAAAAAAAFKFEAAA,50980.48,33156.59,2002.0\r\n+745,AAAAAAAAAFKFEAAA,33156.59,,2003.0\r\n+746,AAAAAAAAAFKFEAAA,25766.50,25766.50,\r\n+747,AAAAAAAAAFKFNAAA,59520.81,,1998.0\r\n+748,AAAAAAAAAFKFNAAA,219157.68,81026.29,2000.0\r\n+749,AAAAAAAAAFKFNAAA,81026.29,16984.80,2001.0\r\n+750,AAAAAAAAAFKFNAAA,16984.80,,2002.0\r\n+751,AAAAAAAAAFKFNAAA,,,\r\n+752,AAAAAAAAAFKGEAAA,240567.49,176809.16,1998.0\r\n+753,AAAAAAAAAFKGEAAA,176809.16,77530.66,1999.0\r\n+754,AAAAAAAAAFKGEAAA,77530.66,98115.79,2000.0\r\n+755,AAAAAAAAAFKGEAAA,98115.79,145243.46,2001.0\r\n+756,AAAAAAAAAFKGEAAA,145243.46,,2002.0\r\n+757,AAAAAAAAAFKGEAAA,,,\r\n+758,AAAAAAAAAFKGIAAA,69781.39,,1999.0\r\n+759,AAAAAAAAAFKGIAAA,126811.46,217726.86,2001.0\r\n+760,AAAAAAAAAFKGIAAA,217726.86,,2002.0\r\n+761,AAAAAAAAAFKGIAAA,1366.54,1366.54,\r\n+762,AAAAAAAAAFKHLBAA,14285.85,27099.99,1998.0\r\n+763,AAAAAAAAAFKHLBAA,27099.99,127941.24,1999.0\r\n+764,AAAAAAAAAFKHLBAA,127941.24,116231.51,2000.0\r\n+765,AAAAAAAAAFKHLBAA,116231.51,107404.82,2001.0\r\n+766,AAAAAAAAAFKHLBAA,107404.82,,2002.0\r\n+767,AAAAAAAAAFKHLBAA,,,\r\n+768,AAAAAAAAAFKHNAAA,138786.37,124584.51,1998.0\r\n+769,AAAAAAAAAFKHNAAA,124584.51,,1999.0\r\n+770,AAAAAAAAAFKHNAAA,90319.27,28139.17,2001.0\r\n+771,AAAAAAAAAFKHNAAA,28139.17,,2002.0\r\n+772,AAAAAAAAAFKHNAAA,224.46,224.46,\r\n+773,AAAAAAAAAFKIFAAA,186019.53,119826.83,1998.0\r\n+774,AAAAAAAAAFKIFAAA,119826.83,,1999.0\r\n+775,AAAAAAAAAFKIFAAA,86366.92,99301.90,2001.0\r\n+776,AAAAAAAAAFKIFAAA,99301.90,,2002.0\r\n+777,AAAAAAAAAFKIFAAA,2516.66,2516.66,\r\n+778,AAAAAAAAAFKIIBAA,118107.89,92414.39,1998.0\r\n+779,AAAAAAAAAFKIIBAA,92414.39,36231.77,1999.0\r\n+780,AAAAAAAAAFKIIBAA,36231.77,148935.06,2000.0\r\n+781,AAAAAAAAAFKIIBAA,148935.06,172890.24,2001.0\r\n+782,AAAAAAAAAFKIIBAA,172890.24,,2002.0\r\n+783,AAAAAAAAAFKIIBAA,17478.75,17478.75,\r\n+784,AAAAAAAAAFKIKAAA,141818.05,108431.67,1999.0\r\n+785,AAAAAAAAAFKIKAAA,108431.67,202305.52,2000.0\r\n+786,AAAAAAAAAFKIKAAA,202305.52,238882.30,2001.0\r\n+787,AAAAAAAAAFKIKAAA,238882.30,,2002.0\r\n+788,AAAAAAAAAFKIKAAA,,,\r\n+789,AAAAAAAAAFKIOAAA,57342.41,85872.10,1998.0\r\n+790,AAAAAAAAAFKIOAAA,85872.10,69654.69,1999.0\r\n+791,AAAAAAAAAFKIOAAA,69654.69,189108.34,2000.0\r\n+792,AAAAAAAAAFKIOAAA,189108.34,94457.49,2001.0\r\n+793,AAAAAAAAAFKIOAAA,94457.49,,2002.0\r\n+794,AAAAAAAAAFKIOAAA,,,\r\n+795,AAAAAAAAAFKJNBAA,55492.01,97602.14,1998.0\r\n+796,AAAAAAAAAFKJNBAA,97602.14,120137.16,1999.0\r\n+797,AAAAAAAAAFKJNBAA,120137.16,66640.74,2000.0\r\n+798,AAAAAAAAAFKJNBAA,66640.74,62743.87,2001.0\r\n+799,AAAAAAAAAFKJNBAA,62743.87,,2002.0\r\n+800,AAAAAAAAAFKJNBAA,,,\r\n+801,AAAAAAAAAFKJPAAA,61491.67,64707.06,1998.0\r\n+802,AAAAAAAAAFKJPAAA,64707.06,70889.93,1999.0\r\n+803,AAAAAAAAAFKJPAAA,70889.93,151357.16,2000.0\r\n+804,AAAAAAAAAFKJPAAA,151357.16,122180.73,2001.0\r\n+805,AAAAAAAAAFKJPAAA,122180.73,27132.81,2002.0\r\n+806,AAAAAAAAAFKJPAAA,27132.81,,2003.0\r\n+807,AAAAAAAAAFKJPAAA,14699.92,14699.92,\r\n+808,AAAAAAAAAFKKBBAA,373168.21,40618.00,1998.0\r\n+809,AAAAAAAAAFKKBBAA,40618.00,52523.90,1999.0\r\n+810,AAAAAAAAAFKKBBAA,52523.90,138546.89,2000.0\r\n+811,AAAAAAAAAFKKBBAA,138546.89,68442.13,2001.0\r\n+812,AAAAAAAAAFKKBBAA,68442.13,,2002.0\r\n+813,AAAAAAAAAFKKBBAA,1738.75,1738.75,\r\n+814,AAAAAAAAAFKKDAAA,110352.61,68317.57,1998.0\r\n+815,AAAAAAAAAFKKDAAA,68317.57,,1999.0\r\n+816,AAAAAAAAAFKKDAAA,130350.81,154587.63,2001.0\r\n+817,AAAAAAAAAFKKDAAA,154587.63,,2002.0\r\n+818,AAAAAAAAAFKKDAAA,1570.56,1570.56,\r\n+819,AAAAAAAAAFKKMAAA,123086.72,100680.99,1998.0\r\n+820,AAAAAAAAAFKKMAAA,100680.99,140298.55,1999.0\r\n+821,AAAAAAAAAFKKMAAA,140298.55,139966.26,2000.0\r\n+822,AAAAAAAAAFKKMAAA,139966.26,68693.67,2001.0\r\n+823,AAAAAAAAAFKKMAAA,68693.67,,2002.0\r\n+824,AAAAAAAAAFKKMAAA,5946.72,5946.72,\r\n+825,AAAAAAAAAFKKNBAA,89552.39,39894.21,1998.0\r\n+826,AAAAAAAAAFKKNBAA,39894.21,,1999.0\r\n+827,AAAAAAAAAFKKNBAA,165295.51,122356.48,2001.0\r\n+828,AAAAAAAAAFKKNBAA,122356.48,,2002.0\r\n+829,AAAAAAAAAFKKNBAA,,,\r\n+830,AAAAAAAAAFKLEBAA,68920.19,178288.89,1998.0\r\n+831,AAAAAAAAAFKLEBAA,178288.89,60666.31,1999.0\r\n+832,AAAAAAAAAFKLEBAA,60666.31,116411.54,2000.0\r\n+833,AAAAAAAAAFKLEBAA,116411.54,64956.81,2001.0\r\n+834,AAAAAAAAAFKLEBAA,64956.81,,2002.0\r\n+835,AAAAAAAAAFKLEBAA,,,\r\n+836,AAAAAAAAAFKLPAAA,80602.86,89556.16,1998.0\r\n+837,AAAAAAAAAFKLPAAA,89556.16,69115.95,1999.0\r\n+838,AAAAAAAAAFKLPAAA,69115.95,,2000.0\r\n+839,AAAAAAAAAFKLPAAA,42805.62,,2002.0\r\n+840,AAAAAAAAAFKLPAAA,1801.05,1801.05,\r\n+841,AAAAAAAAAFKMKBAA,39280.60,36326.01,1998.0\r\n+842,AAAAAAAAAFKMKBAA,36326.01,114161.04,1999.0\r\n+843,AAAAAAAAAFKMKBAA,114161.04,140596.41,2000.0\r\n+844,AAAAAAAAAFKMKBAA,140596.41,192527.47,2001.0\r\n+845,AAAAAAAAAFKMKBAA,192527.47,,2002.0\r\n+846,AAAAAAAAAFKMKBAA,,,\r\n+847,AAAAAAAAAFKNBAAA,34327.66,158183.54,1998.0\r\n+848,AAAAAAAAAFKNBAAA,158183.54,42757.88,1999.0\r\n+849,AAAAAAAAAFKNBAAA,42757.88,154260.36,2000.0\r\n+850,AAAAAAAAAFKNBAAA,154260.36,,2001.0\r\n+851,AAAAAAAAAFKNBAAA,10990.80,10990.80,\r\n+852,AAAAAAAAAFKODBAA,207666.65,59266.80,1998.0\r\n+853,AAAAAAAAAFKODBAA,59266.80,34348.42,1999.0\r\n+854,AAAAAAAAAFKODBAA,34348.42,64891.88,2000.0\r\n+855,AAAAAAAAAFKODBAA,64891.88,145090.96,2001.0\r\n+856,AAAAAAAAAFKODBAA,145090.96,,2002.0\r\n+857,AAAAAAAAAFKODBAA,,,\r\n+858,AAAAAAAAAFKOIBAA,178428.38,42697.03,1998.0\r\n+859,AAAAAAAAAFKOIBAA,42697.03,143921.81,1999.0\r\n+860,AAAAAAAAAFKOIBAA,143921.81,164078.52,2000.0\r\n+861,AAAAAAAAAFKOIBAA,164078.52,43673.70,2001.0\r\n+862,AAAAAAAAAFKOIBAA,43673.70,,2002.0\r\n+863,AAAAAAAAAFKOIBAA,8996.32,8996.32,\r\n+864,AAAAAAAAAFKOMBAA,42912.56,116956.32,1998.0\r\n+865,AAAAAAAAAFKOMBAA,116956.32,27297.58,1999.0\r\n+866,AAAAAAAAAFKOMBAA,27297.58,100249.36,2000.0\r\n+867,AAAAAAAAAFKOMBAA,100249.36,181977.22,2001.0\r\n+868,AAAAAAAAAFKOMBAA,181977.22,,2002.0\r\n+869,AAAAAAAAAFKOMBAA,32.83,32.83,\r\n+870,AAAAAAAAAFKPHAAA,140708.54,23979.10,1998.0\r\n+871,AAAAAAAAAFKPHAAA,23979.10,,1999.0\r\n+872,AAAAAAAAAFKPHAAA,166435.11,30155.24,2002.0\r\n+873,AAAAAAAAAFKPHAAA,30155.24,,2003.0\r\n+874,AAAAAAAAAFKPHAAA,2977.86,2977.86,\r\n+875,AAAAAAAAAFLANAAA,122295.90,25208.55,1998.0\r\n+876,AAAAAAAAAFLANAAA,25208.55,77321.97,1999.0\r\n+877,AAAAAAAAAFLANAAA,77321.97,101662.11,2000.0\r\n+878,AAAAAAAAAFLANAAA,101662.11,77204.79,2001.0\r\n+879,AAAAAAAAAFLANAAA,77204.79,,2002.0\r\n+880,AAAAAAAAAFLBBBAA,111363.63,35207.96,1998.0\r\n+881,AAAAAAAAAFLBBBAA,35207.96,68896.95,1999.0\r\n+882,AAAAAAAAAFLBBBAA,68896.95,186940.54,2000.0\r\n+883,AAAAAAAAAFLBBBAA,186940.54,116212.33,2001.0\r\n+884,AAAAAAAAAFLBBBAA,116212.33,,2002.0\r\n+885,AAAAAAAAAFLBBBAA,,,\r\n+886,AAAAAAAAAFLBFAAA,193354.14,88614.21,1998.0\r\n+887,AAAAAAAAAFLBFAAA,88614.21,32191.84,1999.0\r\n+888,AAAAAAAAAFLBFAAA,32191.84,,2000.0\r\n+889,AAAAAAAAAFLBFAAA,105567.78,,2002.0\r\n+890,AAAAAAAAAFLBFAAA,1675.80,1675.80,\r\n+891,AAAAAAAAAFLBGBAA,136257.05,31854.87,1998.0\r\n+892,AAAAAAAAAFLBGBAA,31854.87,127242.23,1999.0\r\n+893,AAAAAAAAAFLBGBAA,127242.23,111702.69,2000.0\r\n+894,AAAAAAAAAFLBGBAA,111702.69,254140.76,2001.0\r\n+895,AAAAAAAAAFLBGBAA,254140.76,,2002.0\r\n+896,AAAAAAAAAFLBGBAA,6531.25,6531.25,\r\n+897,AAAAAAAAAFLBMBAA,32729.53,16859.19,1998.0\r\n+898,AAAAAAAAAFLBMBAA,16859.19,95793.93,1999.0\r\n+899,AAAAAAAAAFLBMBAA,95793.93,19824.46,2000.0\r\n+900,AAAAAAAAAFLBMBAA,19824.46,75511.01,2001.0\r\n+901,AAAAAAAAAFLBMBAA,75511.01,,2002.0\r\n+902,AAAAAAAAAFLBMBAA,,,\r\n+903,AAAAAAAAAFLBOBAA,110393.05,191496.33,1998.0\r\n+904,AAAAAAAAAFLBOBAA,191496.33,98678.80,1999.0\r\n+905,AAAAAAAAAFLBOBAA,98678.80,242637.13,2000.0\r\n+906,AAAAAAAAAFLBOBAA,242637.13,207733.27,2001.0\r\n+907,AAAAAAAAAFLBOBAA,207733.27,,2002.0\r\n+908,AAAAAAAAAFLBOBAA,32.20,32.20,\r\n+909,AAAAAAAAAFLCKBAA,126749.95,106201.77,1999.0\r\n+910,AAAAAAAAAFLCKBAA,106201.77,92425.99,2000.0\r\n+911,AAAAAAAAAFLCKBAA,92425.99,157882.32,2001.0\r\n+912,AAAAAAAAAFLCKBAA,157882.32,,2002.0\r\n+913,AAAAAAAAAFLCKBAA,,,\r\n+914,AAAAAAAAAFLDKAAA,37940.14,77928.65,1999.0\r\n+915,AAAAAAAAAFLDKAAA,77928.65,155013.83,2000.0\r\n+916,AAAAAAAAAFLDKAAA,155013.83,66512.36,2001.0\r\n+917,AAAAAAAAAFLDKAAA,66512.36,,2002.0\r\n+918,AAAAAAAAAFLEEAAA,38338.10,116333.54,1998.0\r\n+919,AAAAAAAAAFLEEAAA,116333.54,223071.85,1999.0\r\n+920,AAAAAAAAAFLEEAAA,223071.85,113856.31,2000.0\r\n+921,AAAAAAAAAFLEEAAA,113856.31,56200.02,2001.0\r\n+922,AAAAAAAAAFLEEAAA,56200.02,,2002.0\r\n+923,AAAAAAAAAFLEEAAA,9183.80,9183.80,\r\n+924,AAAAAAAAAFLFKBAA,39592.69,96957.31,1998.0\r\n+925,AAAAAAAAAFLFKBAA,96957.31,,1999.0\r\n+926,AAAAAAAAAFLFKBAA,30419.72,160190.76,2001.0\r\n+927,AAAAAAAAAFLFKBAA,160190.76,51909.13,2002.0\r\n+928,AAAAAAAAAFLFKBAA,51909.13,,2003.0\r\n+929,AAAAAAAAAFLFKBAA,7585.33,7585.33,\r\n+930,AAAAAAAAAFLGIBAA,52260.33,39304.59,1998.0\r\n+931,AAAAAAAAAFLGIBAA,39304.59,85824.44,1999.0\r\n+932,AAAAAAAAAFLGIBAA,85824.44,101874.09,2000.0\r\n+933,AAAAAAAAAFLGIBAA,101874.09,,2001.0\r\n+934,AAAAAAAAAFLGIBAA,26098.24,,2003.0\r\n+935,AAAAAAAAAFLGIBAA,548.55,548.55,\r\n+936,AAAAAAAAAFLGJAAA,69867.00,163032.37,1998.0\r\n+937,AAAAAAAAAFLGJAAA,163032.37,33717.58,1999.0\r\n+938,AAAAAAAAAFLGJAAA,33717.58,83728.59,2000.0\r\n+939,AAAAAAAAAFLGJAAA,83728.59,100084.49,2001.0\r\n+940,AAAAAAAAAFLGJAAA,100084.49,,2002.0\r\n+941,AAAAAAAAAFLGJAAA,2209.60,2209.60,\r\n+942,AAAAAAAAAFLHAAAA,91767.78,80232.59,1998.0\r\n+943,AAAAAAAAAFLHAAAA,80232.59,34382.64,1999.0\r\n+944,AAAAAAAAAFLHAAAA,34382.64,,2000.0\r\n+945,AAAAAAAAAFLHAAAA,128896.28,28340.57,2002.0\r\n+946,AAAAAAAAAFLHAAAA,28340.57,,2003.0\r\n+947,AAAAAAAAAFLHAAAA,,,\r\n+948,AAAAAAAAAFLHCAAA,181558.12,152046.70,1998.0\r\n+949,AAAAAAAAAFLHCAAA,152046.70,,1999.0\r\n+950,AAAAAAAAAFLHCAAA,252512.58,115314.29,2001.0\r\n+951,AAAAAAAAAFLHCAAA,115314.29,,2002.0\r\n+952,AAAAAAAAAFLHCAAA,,,\r\n+953,AAAAAAAAAFLHEAAA,32912.29,118894.18,1998.0\r\n+954,AAAAAAAAAFLHEAAA,118894.18,142063.01,1999.0\r\n+955,AAAAAAAAAFLHEAAA,142063.01,36968.79,2000.0\r\n+956,AAAAAAAAAFLHEAAA,36968.79,142390.24,2001.0\r\n+957,AAAAAAAAAFLHEAAA,142390.24,,2002.0\r\n+958,AAAAAAAAAFLIBBAA,64976.21,,1998.0\r\n+959,AAAAAAAAAFLIBBAA,90559.43,209181.93,2000.0\r\n+960,AAAAAAAAAFLIBBAA,209181.93,95856.16,2001.0\r\n+961,AAAAAAAAAFLIBBAA,95856.16,,2002.0\r\n+962,AAAAAAAAAFLIBBAA,,,\r\n+963,AAAAAAAAAFLICAAA,92992.79,,1998.0\r\n+964,AAAAAAAAAFLICAAA,76002.63,168732.47,2000.0\r\n+965,AAAAAAAAAFLICAAA,168732.47,99633.33,2001.0\r\n+966,AAAAAAAAAFLICAAA,99633.33,,2002.0\r\n+967,AAAAAAAAAFLICAAA,,,\r\n+968,AAAAAAAAAFLIGAAA,117294.41,154722.49,1998.0\r\n+969,AAAAAAAAAFLIGAAA,154722.49,123969.76,1999.0\r\n+970,AAAAAAAAAFLIGAAA,123969.76,18617.96,2000.0\r\n+971,AAAAAAAAAFLIGAAA,18617.96,66529.66,2001.0\r\n+972,AAAAAAAAAFLIGAAA,66529.66,,2002.0\r\n+973,AAAAAAAAAFLIGAAA,,,\r\n+974,AAAAAAAAAFLJBBAA,85247.99,125254.10,1998.0\r\n+975,AAAAAAAAAFLJBBAA,125254.10,45612.61,1999.0\r\n+976,AAAAAAAAAFLJBBAA,45612.61,68919.48,2000.0\r\n+977,AAAAAAAAAFLJBBAA,68919.48,34414.65,2001.0\r\n+978,AAAAAAAAAFLJBBAA,34414.65,,2002.0\r\n+979,AAAAAAAAAFLJBBAA,393.82,393.82,\r\n+980,AAAAAAAAAFLKEAAA,136032.93,199148.21,1998.0\r\n+981,AAAAAAAAAFLKEAAA,199148.21,36980.54,1999.0\r\n+982,AAAAAAAAAFLKEAAA,36980.54,63259.58,2000.0\r\n+983,AAAAAAAAAFLKEAAA,63259.58,50161.89,2001.0\r\n+984,AAAAAAAAAFLKEAAA,50161.89,,2002.0\r\n+985,AAAAAAAAAFLKEAAA,,,\r\n+986,AAAAAAAAAFLLABAA,39011.46,55069.36,1998.0\r\n+987,AAAAAAAAAFLLABAA,55069.36,92370.54,1999.0\r\n+988,AAAAAAAAAFLLABAA,92370.54,21984.18,2000.0\r\n+989,AAAAAAAAAFLLABAA,21984.18,43417.65,2001.0\r\n+990,AAAAAAAAAFLLABAA,43417.65,,2002.0\r\n+991,AAAAAAAAAFLLABAA,913.50,913.50,\r\n+992,AAAAAAAAAFLLGAAA,104988.79,140490.83,1998.0\r\n+993,AAAAAAAAAFLLGAAA,140490.83,136196.38,1999.0\r\n+994,AAAAAAAAAFLLGAAA,136196.38,165039.96,2000.0\r\n+995,AAAAAAAAAFLLGAAA,165039.96,72363.71,2001.0\r\n+996,AAAAAAAAAFLLGAAA,72363.71,,2002.0\r\n+997,AAAAAAAAAFLLGAAA,,,\r\n+998,AAAAAAAAAFLLGBAA,141083.06,124413.09,1998.0\r\n+999,AAAAAAAAAFLLGBAA,124413.09,136337.55,1999.0\r\n+1000,AAAAAAAAAFLLGBAA,136337.55,82337.47,2000.0\r\n+1001,AAAAAAAAAFLLGBAA,82337.47,82721.60,2001.0\r\n+1002,AAAAAAAAAFLLGBAA,82721.60,,2002.0\r\n+1003,AAAAAAAAAFLLGBAA,,,\r\n+1004,AAAAAAAAAFLLMBAA,89499.10,152130.55,1998.0\r\n+1005,AAAAAAAAAFLLMBAA,152130.55,157719.08,1999.0\r\n+1006,AAAAAAAAAFLLMBAA,157719.08,,2000.0\r\n+1007,AAAAAAAAAFLLMBAA,83119.94,,2002.0\r\n+1008,AAAAAAAAAFLLMBAA,1821.56,1821.56,\r\n+1009,AAAAAAAAAFLMKAAA,374668.31,19953.27,1998.0\r\n+1010,AAAAAAAAAFLMKAAA,19953.27,163252.14,1999.0\r\n+1011,AAAAAAAAAFLMKAAA,163252.14,50171.90,2000.0\r\n+1012,AAAAAAAAAFLMKAAA,50171.90,88440.34,2001.0\r\n+1013,AAAAAAAAAFLMKAAA,88440.34,,2002.0\r\n+1014,AAAAAAAAAFLMKAAA,12568.88,12568.88,\r\n+1015,AAAAAAAAAFLNHBAA,50647.14,182815.06,1998.0\r\n+1016,AAAAAAAAAFLNHBAA,182815.06,75376.28,1999.0\r\n+1017,AAAAAAAAAFLNHBAA,75376.28,,2000.0\r\n+1018,AAAAAAAAAFLNHBAA,84864.71,,2002.0\r\n+1019,AAAAAAAAAFLNHBAA,,,\r\n+1020,AAAAAAAAAFLOCBAA,102405.23,115357.92,1998.0\r\n+1021,AAAAAAAAAFLOCBAA,115357.92,81826.13,1999.0\r\n+1022,AAAAAAAAAFLOCBAA,81826.13,43028.75,2000.0\r\n+1023,AAAAAAAAAFLOCBAA,43028.75,62324.12,2001.0\r\n+1024,AAAAAAAAAFLOCBAA,62324.12,,2002.0\r\n+1025,AAAAAAAAAFLOCBAA,,,\r\n+1026,AAAAAAAAAFLOJAAA,76434.19,99788.44,1998.0\r\n+1027,AAAAAAAAAFLOJAAA,99788.44,71203.48,1999.0\r\n+1028,AAAAAAAAAFLOJAAA,71203.48,51050.69,2000.0\r\n+1029,AAAAAAAAAFLOJAAA,51050.69,179237.45,2001.0\r\n+1030,AAAAAAAAAFLOJAAA,179237.45,,2002.0\r\n+1031,AAAAAAAAAFLPFAAA,37910.76,44287.32,1998.0\r\n+1032,AAAAAAAAAFLPFAAA,44287.32,28249.16,1999.0\r\n+1033,AAAAAAAAAFLPFAAA,28249.16,89881.49,2000.0\r\n+1034,AAAAAAAAAFLPFAAA,89881.49,25305.96,2001.0\r\n+1035,AAAAAAAAAFLPFAAA,25305.96,,2002.0\r\n+1036,AAAAAAAAAFLPFAAA,,,\r\n+1037,AAAAAAAAAFLPNBAA,31193.55,48810.28,1998.0\r\n+1038,AAAAAAAAAFLPNBAA,48810.28,,1999.0\r\n+1039,AAAAAAAAAFLPNBAA,48957.72,317896.62,2001.0\r\n+1040,AAAAAAAAAFLPNBAA,317896.62,,2002.0\r\n+1041,AAAAAAAAAFLPNBAA,4352.82,4352.82,\r\n+1042,AAAAAAAAAFMBJAAA,96743.12,24236.19,1998.0\r\n+1043,AAAAAAAAAFMBJAAA,24236.19,46130.60,1999.0\r\n+1044,AAAAAAAAAFMBJAAA,46130.60,72841.67,2000.0\r\n+1045,AAAAAAAAAFMBJAAA,72841.67,73877.00,2001.0\r\n+1046,AAAAAAAAAFMBJAAA,73877.00,,2002.0\r\n+1047,AAAAAAAAAFMBJAAA,3512.09,3512.09,\r\n+1048,AAAAAAAAAFMCAAAA,177162.09,100201.34,1998.0\r\n+1049,AAAAAAAAAFMCAAAA,100201.34,101994.02,1999.0\r\n+1050,AAAAAAAAAFMCAAAA,101994.02,,2000.0\r\n+1051,AAAAAAAAAFMCAAAA,194284.76,,2002.0\r\n+1052,AAAAAAAAAFMCAAAA,845.28,845.28,\r\n+1053,AAAAAAAAAFMCGAAA,62196.43,,1998.0\r\n+1054,AAAAAAAAAFMCGAAA,57228.10,90640.48,2000.0\r\n+1055,AAAAAAAAAFMCGAAA,90640.48,67469.72,2001.0\r\n+1056,AAAAAAAAAFMCGAAA,67469.72,,2002.0\r\n+1057,AAAAAAAAAFMCGAAA,,,\r\n+1058,AAAAAAAAAFMDHBAA,136961.39,138314.54,1998.0\r\n+1059,AAAAAAAAAFMDHBAA,138314.54,70491.25,1999.0\r\n+1060,AAAAAAAAAFMDHBAA,70491.25,,2000.0\r\n+1061,AAAAAAAAAFMDHBAA,189541.46,,2002.0\r\n+1062,AAAAAAAAAFMDHBAA,,,\r\n+1063,AAAAAAAAAFMDIAAA,27410.38,,1998.0\r\n+1064,AAAAAAAAAFMDIAAA,125302.87,40640.29,2000.0\r\n+1065,AAAAAAAAAFMDIAAA,40640.29,,2001.0\r\n+1066,AAAAAAAAAFMDIAAA,,,\r\n+1067,AAAAAAAAAFMDPAAA,48660.53,40575.63,1999.0\r\n+1068,AAAAAAAAAFMDPAAA,40575.63,,2000.0\r\n+1069,AAAAAAAAAFMDPAAA,168169.81,,2002.0\r\n+1070,AAAAAAAAAFMDPAAA,1708.00,1708.00,\r\n+1071,AAAAAAAAAFMEAAAA,28256.79,176833.09,1998.0\r\n+1072,AAAAAAAAAFMEAAAA,176833.09,124766.32,1999.0\r\n+1073,AAAAAAAAAFMEAAAA,124766.32,64177.44,2000.0\r\n+1074,AAAAAAAAAFMEAAAA,64177.44,182749.41,2001.0\r\n+1075,AAAAAAAAAFMEAAAA,182749.41,,2002.0\r\n+1076,AAAAAAAAAFMEAAAA,15673.53,15673.53,\r\n+1077,AAAAAAAAAFMECBAA,86908.02,53173.29,1998.0\r\n+1078,AAAAAAAAAFMECBAA,53173.29,,1999.0\r\n+1079,AAAAAAAAAFMECBAA,48271.28,31226.91,2001.0\r\n+1080,AAAAAAAAAFMECBAA,31226.91,,2002.0\r\n+1081,AAAAAAAAAFMECBAA,2298.27,2298.27,\r\n+1082,AAAAAAAAAFMFFBAA,131833.09,25883.35,1998.0\r\n+1083,AAAAAAAAAFMFFBAA,25883.35,,1999.0\r\n+1084,AAAAAAAAAFMFFBAA,121284.39,,2001.0\r\n+1085,AAAAAAAAAFMFFBAA,3505.85,3505.85,\r\n+1086,AAAAAAAAAFMFHBAA,104777.15,,1998.0\r\n+1087,AAAAAAAAAFMFHBAA,39850.10,91379.33,2000.0\r\n+1088,AAAAAAAAAFMFHBAA,91379.33,328488.05,2001.0\r\n+1089,AAAAAAAAAFMFHBAA,328488.05,,2002.0\r\n+1090,AAAAAAAAAFMFHBAA,756.59,756.59,\r\n+1091,AAAAAAAAAFMFKBAA,86395.89,54423.84,1998.0\r\n+1092,AAAAAAAAAFMFKBAA,54423.84,17230.58,1999.0\r\n+1093,AAAAAAAAAFMFKBAA,17230.58,139920.56,2000.0\r\n+1094,AAAAAAAAAFMFKBAA,139920.56,31963.90,2001.0\r\n+1095,AAAAAAAAAFMFKBAA,31963.90,,2002.0\r\n+1096,AAAAAAAAAFMFKBAA,1456.77,1456.77,\r\n+1097,AAAAAAAAAFMHEAAA,46617.28,110399.63,1998.0\r\n+1098,AAAAAAAAAFMHEAAA,110399.63,61928.15,1999.0\r\n+1099,AAAAAAAAAFMHEAAA,61928.15,115130.73,2000.0\r\n+1100,AAAAAAAAAFMHEAAA,115130.73,116624.53,2001.0\r\n+1101,AAAAAAAAAFMHEAAA,116624.53,,2002.0\r\n+1102,AAAAAAAAAFMHEAAA,,,\r\n+1103,AAAAAAAAAFMHNBAA,71872.70,298198.10,1998.0\r\n+1104,AAAAAAAAAFMHNBAA,298198.10,86587.28,1999.0\r\n+1105,AAAAAAAAAFMHNBAA,86587.28,,2000.0\r\n+1106,AAAAAAAAAFMHNBAA,167554.90,,2002.0\r\n+1107,AAAAAAAAAFMHNBAA,,,\r\n+1108,AAAAAAAAAFMIMAAA,62324.51,31183.60,1998.0\r\n+1109,AAAAAAAAAFMIMAAA,31183.60,25899.93,1999.0\r\n+1110,AAAAAAAAAFMIMAAA,25899.93,,2000.0\r\n+1111,AAAAAAAAAFMIMAAA,167213.47,,2002.0\r\n+1112,AAAAAAAAAFMIMAAA,178.76,178.76,\r\n+1113,AAAAAAAAAFMJGBAA,242945.04,144844.92,1998.0\r\n+1114,AAAAAAAAAFMJGBAA,144844.92,61721.51,1999.0\r\n+1115,AAAAAAAAAFMJGBAA,61721.51,146239.66,2000.0\r\n+1116,AAAAAAAAAFMJGBAA,146239.66,180996.23,2001.0\r\n+1117,AAAAAAAAAFMJGBAA,180996.23,,2002.0\r\n+1118,AAAAAAAAAFMJGBAA,8782.76,8782.76,\r\n+1119,AAAAAAAAAFMKBAAA,45032.10,161270.15,1998.0\r\n+1120,AAAAAAAAAFMKBAAA,161270.15,,1999.0\r\n+1121,AAAAAAAAAFMKBAAA,90200.90,,2002.0\r\n+1122,AAAAAAAAAFMKBAAA,524.29,524.29,\r\n+1123,AAAAAAAAAFMKIBAA,52149.20,97123.98,1998.0\r\n+1124,AAAAAAAAAFMKIBAA,97123.98,127813.86,1999.0\r\n+1125,AAAAAAAAAFMKIBAA,127813.86,105952.39,2000.0\r\n+1126,AAAAAAAAAFMKIBAA,105952.39,82953.33,2001.0\r\n+1127,AAAAAAAAAFMKIBAA,82953.33,,2002.0\r\n+1128,AAAAAAAAAFMKIBAA,,,\r\n+1129,AAAAAAAAAFMLDBAA,76758.52,,1998.0\r\n+1130,AAAAAAAAAFMLDBAA,179582.97,60509.36,2000.0\r\n+1131,AAAAAAAAAFMLDBAA,60509.36,152068.45,2001.0\r\n+1132,AAAAAAAAAFMLDBAA,152068.45,,2002.0\r\n+1133,AAAAAAAAAFMLGAAA,79958.01,72596.67,1998.0\r\n+1134,AAAAAAAAAFMLGAAA,72596.67,254993.39,1999.0\r\n+1135,AAAAAAAAAFMLGAAA,254993.39,85142.20,2000.0\r\n+1136,AAAAAAAAAFMLGAAA,85142.20,37670.29,2001.0\r\n+1137,AAAAAAAAAFMLGAAA,37670.29,,2002.0\r\n+1138,AAAAAAAAAFMLKAAA,129424.86,35336.25,1998.0\r\n+1139,AAAAAAAAAFMLKAAA,35336.25,60552.08,1999.0\r\n+1140,AAAAAAAAAFMLKAAA,60552.08,83354.15,2000.0\r\n+1141,AAAAAAAAAFMLKAAA,83354.15,,2001.0\r\n+1142,AAAAAAAAAFMLKAAA,,,\r\n+1143,AAAAAAAAAFMMJBAA,44023.71,29472.06,1998.0\r\n+1144,AAAAAAAAAFMMJBAA,29472.06,253972.07,1999.0\r\n+1145,AAAAAAAAAFMMJBAA,253972.07,55519.65,2000.0\r\n+1146,AAAAAAAAAFMMJBAA,55519.65,137877.39,2001.0\r\n+1147,AAAAAAAAAFMMJBAA,137877.39,,2002.0\r\n+1148,AAAAAAAAAFMMJBAA,9033.29,9033.29,\r\n+1149,AAAAAAAAAFMNEBAA,23184.70,265720.16,1998.0\r\n+1150,AAAAAAAAAFMNEBAA,265720.16,,1999.0\r\n+1151,AAAAAAAAAFMNEBAA,77224.93,105326.49,2001.0\r\n+1152,AAAAAAAAAFMNEBAA,105326.49,,2002.0\r\n+1153,AAAAAAAAAFMNEBAA,,,\r\n+1154,AAAAAAAAAFMNIBAA,22661.42,38257.92,1998.0\r\n+1155,AAAAAAAAAFMNIBAA,38257.92,141961.19,1999.0\r\n+1156,AAAAAAAAAFMNIBAA,141961.19,,2000.0\r\n+1157,AAAAAAAAAFMNIBAA,160049.67,,2002.0\r\n+1158,AAAAAAAAAFMNIBAA,,,\r\n+1159,AAAAAAAAAFMNLBAA,58901.62,195676.13,1998.0\r\n+1160,AAAAAAAAAFMNLBAA,195676.13,146035.55,1999.0\r\n+1161,AAAAAAAAAFMNLBAA,146035.55,151549.36,2000.0\r\n+1162,AAAAAAAAAFMNLBAA,151549.36,95662.23,2001.0\r\n+1163,AAAAAAAAAFMNLBAA,95662.23,,2002.0\r\n+1164,AAAAAAAAAFMNLBAA,,,\r\n+1165,AAAAAAAAAFMNNAAA,104079.05,77032.03,1998.0\r\n+1166,AAAAAAAAAFMNNAAA,77032.03,149887.42,1999.0\r\n+1167,AAAAAAAAAFMNNAAA,149887.42,89980.26,2000.0\r\n+1168,AAAAAAAAAFMNNAAA,89980.26,113535.87,2001.0\r\n+1169,AAAAAAAAAFMNNAAA,113535.87,,2002.0\r\n+1170,AAAAAAAAAFMNNAAA,6872.17,6872.17,\r\n+1171,AAAAAAAAAFMOEBAA,22302.25,311047.11,1998.0\r\n+1172,AAAAAAAAAFMOEBAA,311047.11,130119.27,1999.0\r\n+1173,AAAAAAAAAFMOEBAA,130119.27,116168.34,2000.0\r\n+1174,AAAAAAAAAFMOEBAA,116168.34,,2001.0\r\n+1175,AAAAAAAAAFMOEBAA,,,\r\n+1176,AAAAAAAAAFMONBAA,163739.02,57632.12,1998.0\r\n+1177,AAAAAAAAAFMONBAA,57632.12,24917.58,1999.0\r\n+1178,AAAAAAAAAFMONBAA,24917.58,176536.23,2000.0\r\n+1179,AAAAAAAAAFMONBAA,176536.23,,2001.0\r\n+1180,AAAAAAAAAFMONBAA,,,\r\n+1181,AAAAAAAAAFMPAAAA,104475.20,54997.08,1998.0\r\n+1182,AAAAAAAAAFMPAAAA,54997.08,88208.00,1999.0\r\n+1183,AAAAAAAAAFMPAAAA,88208.00,114911.88,2000.0\r\n+1184,AAAAAAAAAFMPAAAA,114911.88,278838.71,2001.0\r\n+1185,AAAAAAAAAFMPAAAA,278838.71,,2002.0\r\n+1186,AAAAAAAAAFMPAAAA,3339.60,3339.60,\r\n+1187,AAAAAAAAAFMPEBAA,135206.16,107697.12,1998.0\r\n+1188,AAAAAAAAAFMPEBAA,107697.12,216577.53,1999.0\r\n+1189,AAAAAAAAAFMPEBAA,216577.53,26223.95,2000.0\r\n+1190,AAAAAAAAAFMPEBAA,26223.95,135731.42,2001.0\r\n+1191,AAAAAAAAAFMPEBAA,135731.42,,2002.0\r\n+1192,AAAAAAAAAFMPEBAA,5071.00,5071.00,\r\n+1193,AAAAAAAAAFNABBAA,160157.67,156340.38,1998.0\r\n+1194,AAAAAAAAAFNABBAA,156340.38,167461.10,1999.0\r\n+1195,AAAAAAAAAFNABBAA,167461.10,211406.40,2000.0\r\n+1196,AAAAAAAAAFNABBAA,211406.40,21065.79,2001.0\r\n+1197,AAAAAAAAAFNABBAA,21065.79,,2002.0\r\n+1198,AAAAAAAAAFNABBAA,,,\r\n+1199,AAAAAAAAAFNALBAA,75639.21,91858.77,1998.0\r\n+1200,AAAAAAAAAFNALBAA,91858.77,158610.12,1999.0\r\n+1201,AAAAAAAAAFNALBAA,158610.12,189137.35,2000.0\r\n+1202,AAAAAAAAAFNALBAA,189137.35,178418.65,2001.0\r\n+1203,AAAAAAAAAFNALBAA,178418.65,,2002.0\r\n+1204,AAAAAAAAAFNALBAA,,,\r\n+1205,AAAAAAAAAFNBCBAA,38088.81,144517.87,1998.0\r\n+1206,AAAAAAAAAFNBCBAA,144517.87,58865.30,1999.0\r\n+1207,AAAAAAAAAFNBCBAA,58865.30,6836.23,2000.0\r\n+1208,AAAAAAAAAFNBCBAA,6836.23,89649.98,2001.0\r\n+1209,AAAAAAAAAFNBCBAA,89649.98,,2002.0\r\n+1210,AAAAAAAAAFNBCBAA,,,\r\n+1211,AAAAAAAAAFNBEAAA,36804.59,38293.59,1998.0\r\n+1212,AAAAAAAAAFNBEAAA,38293.59,76636.61,1999.0\r\n+1213,AAAAAAAAAFNBEAAA,76636.61,57986.53,2000.0\r\n+1214,AAAAAAAAAFNBEAAA,57986.53,157358.45,2001.0\r\n+1215,AAAAAAAAAFNBEAAA,157358.45,,2002.0\r\n+1216,AAAAAAAAAFNBEAAA,4260.31,4260.31,\r\n+1217,AAAAAAAAAFNCMAAA,62130.11,56025.82,1998.0\r\n+1218,AAAAAAAAAFNCMAAA,56025.82,83318.95,1999.0\r\n+1219,AAAAAAAAAFNCMAAA,83318.95,86110.16,2000.0\r\n+1220,AAAAAAAAAFNCMAAA,86110.16,174325.98,2001.0\r\n+1221,AAAAAAAAAFNCMAAA,174325.98,,2002.0\r\n+1222,AAAAAAAAAFNCMAAA,382.60,382.60,\r\n+1223,AAAAAAAAAFNCMBAA,53235.45,32800.97,1998.0\r\n+1224,AAAAAAAAAFNCMBAA,32800.97,92468.31,1999.0\r\n+1225,AAAAAAAAAFNCMBAA,92468.31,129412.66,2000.0\r\n+1226,AAAAAAAAAFNCMBAA,129412.66,68230.26,2001.0\r\n+1227,AAAAAAAAAFNCMBAA,68230.26,,2002.0\r\n+1228,AAAAAAAAAFNCMBAA,1174.60,1174.60,\r\n+1229,AAAAAAAAAFNDFBAA,36319.88,95944.42,1998.0\r\n+1230,AAAAAAAAAFNDFBAA,95944.42,179160.84,1999.0\r\n+1231,AAAAAAAAAFNDFBAA,179160.84,79677.25,2000.0\r\n+1232,AAAAAAAAAFNDFBAA,79677.25,56680.18,2001.0\r\n+1233,AAAAAAAAAFNDFBAA,56680.18,,2002.0\r\n+1234,AAAAAAAAAFNDFBAA,4276.00,4276.00,\r\n+1235,AAAAAAAAAFNDHAAA,49277.94,261320.15,1998.0\r\n+1236,AAAAAAAAAFNDHAAA,261320.15,102707.77,1999.0\r\n+1237,AAAAAAAAAFNDHAAA,102707.77,99064.35,2000.0\r\n+1238,AAAAAAAAAFNDHAAA,99064.35,84090.60,2001.0\r\n+1239,AAAAAAAAAFNDHAAA,84090.60,,2002.0\r\n+1240,AAAAAAAAAFNDHAAA,7489.18,7489.18,\r\n+1241,AAAAAAAAAFNDOAAA,80938.56,,1998.0\r\n+1242,AAAAAAAAAFNDOAAA,68983.75,113655.80,2000.0\r\n+1243,AAAAAAAAAFNDOAAA,113655.80,98618.72,2001.0\r\n+1244,AAAAAAAAAFNDOAAA,98618.72,,2002.0\r\n+1245,AAAAAAAAAFNDOAAA,,,\r\n+1246,AAAAAAAAAFNEGBAA,95732.42,126735.13,1998.0\r\n+1247,AAAAAAAAAFNEGBAA,126735.13,33047.28,1999.0\r\n+1248,AAAAAAAAAFNEGBAA,33047.28,183956.72,2000.0\r\n+1249,AAAAAAAAAFNEGBAA,183956.72,271255.90,2001.0\r\n+1250,AAAAAAAAAFNEGBAA,271255.90,,2002.0\r\n+1251,AAAAAAAAAFNEGBAA,2404.74,2404.74,\r\n+1252,AAAAAAAAAFNFABAA,240990.68,151077.09,1998.0\r\n+1253,AAAAAAAAAFNFABAA,151077.09,86647.41,1999.0\r\n+1254,AAAAAAAAAFNFABAA,86647.41,159656.50,2000.0\r\n+1255,AAAAAAAAAFNFABAA,159656.50,167111.55,2001.0\r\n+1256,AAAAAAAAAFNFABAA,167111.55,,2002.0\r\n+1257,AAAAAAAAAFNFABAA,17206.80,17206.80,\r\n+1258,AAAAAAAAAFNFHBAA,79626.08,214859.39,1998.0\r\n+1259,AAAAAAAAAFNFHBAA,214859.39,64397.62,1999.0\r\n+1260,AAAAAAAAAFNFHBAA,64397.62,,2000.0\r\n+1261,AAAAAAAAAFNFHBAA,75726.46,,2002.0\r\n+1262,AAAAAAAAAFNFHBAA,,,\r\n+1263,AAAAAAAAAFNFMBAA,142665.00,163551.04,1998.0\r\n+1264,AAAAAAAAAFNFMBAA,163551.04,112106.97,1999.0\r\n+1265,AAAAAAAAAFNFMBAA,112106.97,173119.48,2000.0\r\n+1266,AAAAAAAAAFNFMBAA,173119.48,252991.49,2001.0\r\n+1267,AAAAAAAAAFNFMBAA,252991.49,,2002.0\r\n+1268,AAAAAAAAAFNFMBAA,,,\r\n+1269,AAAAAAAAAFNFPAAA,131745.27,159492.06,1998.0\r\n+1270,AAAAAAAAAFNFPAAA,159492.06,65655.93,1999.0\r\n+1271,AAAAAAAAAFNFPAAA,65655.93,287249.55,2000.0\r\n+1272,AAAAAAAAAFNFPAAA,287249.55,145734.92,2001.0\r\n+1273,AAAAAAAAAFNFPAAA,145734.92,,2002.0\r\n+1274,AAAAAAAAAFNFPAAA,2029.58,2029.58,\r\n+1275,AAAAAAAAAFNGCAAA,38799.23,169833.21,1998.0\r\n+1276,AAAAAAAAAFNGCAAA,169833.21,63545.51,1999.0\r\n+1277,AAAAAAAAAFNGCAAA,63545.51,110852.96,2000.0\r\n+1278,AAAAAAAAAFNGCAAA,110852.96,,2001.0\r\n+1279,AAAAAAAAAFNGCAAA,9526.98,9526.98,\r\n+1280,AAAAAAAAAFNGKBAA,71226.04,107597.22,1998.0\r\n+1281,AAAAAAAAAFNGKBAA,107597.22,135272.93,1999.0\r\n+1282,AAAAAAAAAFNGKBAA,135272.93,23834.49,2000.0\r\n+1283,AAAAAAAAAFNGKBAA,23834.49,76747.72,2001.0\r\n+1284,AAAAAAAAAFNGKBAA,76747.72,,2002.0\r\n+1285,AAAAAAAAAFNGKBAA,8389.55,8389.55,\r\n+1286,AAAAAAAAAFNGOAAA,17500.42,35582.79,1999.0\r\n+1287,AAAAAAAAAFNGOAAA,35582.79,,2000.0\r\n+1288,AAAAAAAAAFNGOAAA,196030.96,,2002.0\r\n+1289,AAAAAAAAAFNGOAAA,,,\r\n+1290,AAAAAAAAAFNHHAAA,57164.92,,1998.0\r\n+1291,AAAAAAAAAFNHHAAA,243534.79,37461.33,2001.0\r\n+1292,AAAAAAAAAFNHHAAA,37461.33,,2002.0\r\n+1293,AAAAAAAAAFNHHAAA,5696.04,5696.04,\r\n+1294,AAAAAAAAAFNHHBAA,198777.13,77855.01,1998.0\r\n+1295,AAAAAAAAAFNHHBAA,77855.01,92664.08,1999.0\r\n+1296,AAAAAAAAAFNHHBAA,92664.08,143176.25,2000.0\r\n+1297,AAAAAAAAAFNHHBAA,143176.25,28523.59,2001.0\r\n+1298,AAAAAAAAAFNHHBAA,28523.59,,2002.0\r\n+1299,AAAAAAAAAFNHHBAA,14693.95,14693.95,\r\n+1300,AAAAAAAAAFNICBAA,197510.84,40589.01,1999.0\r\n+1301,AAAAAAAAAFNICBAA,40589.01,276178.19,2000.0\r\n+1302,AAAAAAAAAFNICBAA,276178.19,65735.38,2001.0\r\n+1303,AAAAAAAAAFNICBAA,65735.38,,2002.0\r\n+1304,AAAAAAAAAFNICBAA,,,\r\n+1305,AAAAAAAAAFNJGBAA,92846.32,201653.14,1998.0\r\n+1306,AAAAAAAAAFNJGBAA,201653.14,,1999.0\r\n+1307,AAAAAAAAAFNJGBAA,65182.77,97423.41,2001.0\r\n+1308,AAAAAAAAAFNJGBAA,97423.41,,2002.0\r\n+1309,AAAAAAAAAFNJGBAA,,,\r\n+1310,AAAAAAAAAFNJKBAA,214666.49,204110.25,1998.0\r\n+1311,AAAAAAAAAFNJKBAA,204110.25,140414.45,1999.0\r\n+1312,AAAAAAAAAFNJKBAA,140414.45,181768.23,2000.0\r\n+1313,AAAAAAAAAFNJKBAA,181768.23,143899.46,2001.0\r\n+1314,AAAAAAAAAFNJKBAA,143899.46,,2002.0\r\n+1315,AAAAAAAAAFNJKBAA,10605.92,10605.92,\r\n+1316,AAAAAAAAAFNJOAAA,127797.72,,1998.0\r\n+1317,AAAAAAAAAFNJOAAA,149775.93,187529.67,2000.0\r\n+1318,AAAAAAAAAFNJOAAA,187529.67,98566.39,2001.0\r\n+1319,AAAAAAAAAFNJOAAA,98566.39,,2002.0\r\n+1320,AAAAAAAAAFNJOAAA,603.24,603.24,\r\n+1321,AAAAAAAAAFNJPAAA,87683.84,55470.36,1999.0\r\n+1322,AAAAAAAAAFNJPAAA,55470.36,75800.85,2000.0\r\n+1323,AAAAAAAAAFNJPAAA,75800.85,145220.58,2001.0\r\n+1324,AAAAAAAAAFNJPAAA,145220.58,,2002.0\r\n+1325,AAAAAAAAAFNJPAAA,,,\r\n+1326,AAAAAAAAAFNKFBAA,94359.09,84048.23,1998.0\r\n+1327,AAAAAAAAAFNKFBAA,84048.23,87813.18,1999.0\r\n+1328,AAAAAAAAAFNKFBAA,87813.18,135959.26,2000.0\r\n+1329,AAAAAAAAAFNKFBAA,135959.26,219472.67,2001.0\r\n+1330,AAAAAAAAAFNKFBAA,219472.67,,2002.0\r\n+1331,AAAAAAAAAFNKFBAA,5433.31,5433.31,\r\n+1332,AAAAAAAAAFNKIBAA,118972.08,24044.62,1998.0\r\n+1333,AAAAAAAAAFNKIBAA,24044.62,107690.97,1999.0\r\n+1334,AAAAAAAAAFNKIBAA,107690.97,18133.62,2000.0\r\n+1335,AAAAAAAAAFNKIBAA,18133.62,162745.53,2001.0\r\n+1336,AAAAAAAAAFNKIBAA,162745.53,,2002.0\r\n+1337,AAAAAAAAAFNKIBAA,2487.30,2487.30,\r\n+1338,AAAAAAAAAFNMIBAA,33124.86,158886.54,1999.0\r\n+1339,AAAAAAAAAFNMIBAA,158886.54,161025.26,2000.0\r\n+1340,AAAAAAAAAFNMIBAA,161025.26,106385.88,2001.0\r\n+1341,AAAAAAAAAFNMIBAA,106385.88,,2002.0\r\n+1342,AAAAAAAAAFNMIBAA,,,\r\n+1343,AAAAAAAAAFNNGAAA,115419.30,62316.40,1998.0\r\n+1344,AAAAAAAAAFNNGAAA,62316.40,243478.82,1999.0\r\n+1345,AAAAAAAAAFNNGAAA,243478.82,,2000.0\r\n+1346,AAAAAAAAAFNNGAAA,140135.21,,2002.0\r\n+1347,AAAAAAAAAFNNGAAA,3944.40,3944.40,\r\n+1348,AAAAAAAAAFNNJAAA,25938.95,169843.39,1998.0\r\n+1349,AAAAAAAAAFNNJAAA,169843.39,183295.97,1999.0\r\n+1350,AAAAAAAAAFNNJAAA,183295.97,55644.75,2000.0\r\n+1351,AAAAAAAAAFNNJAAA,55644.75,125019.98,2001.0\r\n+1352,AAAAAAAAAFNNJAAA,125019.98,,2002.0\r\n+1353,AAAAAAAAAFNNJAAA,3745.59,3745.59,\r\n+1354,AAAAAAAAAFNPHAAA,28206.53,49654.83,1998.0\r\n+1355,AAAAAAAAAFNPHAAA,49654.83,103607.43,1999.0\r\n+1356,AAAAAAAAAFNPHAAA,103607.43,128278.67,2000.0\r\n+1357,AAAAAAAAAFNPHAAA,128278.67,106639.71,2001.0\r\n+1358,AAAAAAAAAFNPHAAA,106639.71,,2002.0\r\n+1359,AAAAAAAAAFNPHAAA,,,\r\n+1360,AAAAAAAAAFNPMAAA,90854.91,72605.95,1998.0\r\n+1361,AAAAAAAAAFNPMAAA,72605.95,146733.47,1999.0\r\n+1362,AAAAAAAAAFNPMAAA,146733.47,156311.14,2000.0\r\n+1363,AAAAAAAAAFNPMAAA,156311.14,67270.38,2001.0\r\n+1364,AAAAAAAAAFNPMAAA,67270.38,,2002.0\r\n+1365,AAAAAAAAAFNPMAAA,,,\r\n+1366,AAAAAAAAAFOAGBAA,54851.93,45019.83,1998.0\r\n+1367,AAAAAAAAAFOAGBAA,45019.83,102845.35,1999.0\r\n+1368,AAAAAAAAAFOAGBAA,102845.35,52463.98,2000.0\r\n+1369,AAAAAAAAAFOAGBAA,52463.98,153981.14,2001.0\r\n+1370,AAAAAAAAAFOAGBAA,153981.14,,2002.0\r\n+1371,AAAAAAAAAFOAGBAA,2515.50,2515.50,\r\n+1372,AAAAAAAAAFOBEBAA,65661.72,34913.58,1998.0\r\n+1373,AAAAAAAAAFOBEBAA,34913.58,39571.71,1999.0\r\n+1374,AAAAAAAAAFOBEBAA,39571.71,87191.83,2000.0\r\n+1375,AAAAAAAAAFOBEBAA,87191.83,25314.71,2001.0\r\n+1376,AAAAAAAAAFOBEBAA,25314.71,,2002.0\r\n+1377,AAAAAAAAAFOBIBAA,59879.11,148903.29,1998.0\r\n+1378,AAAAAAAAAFOBIBAA,148903.29,62865.70,1999.0\r\n+1379,AAAAAAAAAFOBIBAA,62865.70,12653.11,2000.0\r\n+1380,AAAAAAAAAFOBIBAA,12653.11,36793.59,2001.0\r\n+1381,AAAAAAAAAFOBIBAA,36793.59,,2002.0\r\n+1382,AAAAAAAAAFOBIBAA,,,\r\n+1383,AAAAAAAAAFOCABAA,258251.17,112125.11,1998.0\r\n+1384,AAAAAAAAAFOCABAA,112125.11,87947.82,1999.0\r\n+1385,AAAAAAAAAFOCABAA,87947.82,145934.36,2000.0\r\n+1386,AAAAAAAAAFOCABAA,145934.36,220022.26,2001.0\r\n+1387,AAAAAAAAAFOCABAA,220022.26,,2002.0\r\n+1388,AAAAAAAAAFOCABAA,5354.07,5354.07,\r\n+1389,AAAAAAAAAFOCHAAA,71638.23,189946.20,1998.0\r\n+1390,AAAAAAAAAFOCHAAA,189946.20,,1999.0\r\n+1391,AAAAAAAAAFOCHAAA,213248.47,98461.49,2001.0\r\n+1392,AAAAAAAAAFOCHAAA,98461.49,,2002.0\r\n+1393,AAAAAAAAAFOCHAAA,4714.60,4714.60,\r\n+1394,AAAAAAAAAFOENAAA,60603.04,83410.84,1998.0\r\n+1395,AAAAAAAAAFOENAAA,83410.84,142454.53,1999.0\r\n+1396,AAAAAAAAAFOENAAA,142454.53,167397.09,2000.0\r\n+1397,AAAAAAAAAFOENAAA,167397.09,86021.87,2001.0\r\n+1398,AAAAAAAAAFOENAAA,86021.87,,2002.0\r\n+1399,AAAAAAAAAFOENAAA,6411.64,6411.64,\r\n+1400,AAAAAAAAAFOFKAAA,23389.16,197529.49,1998.0\r\n+1401,AAAAAAAAAFOFKAAA,197529.49,61665.05,1999.0\r\n+1402,AAAAAAAAAFOFKAAA,61665.05,72462.77,2000.0\r\n+1403,AAAAAAAAAFOFKAAA,72462.77,129701.25,2001.0\r\n+1404,AAAAAAAAAFOFKAAA,129701.25,,2002.0\r\n+1405,AAAAAAAAAFOFKAAA,7995.34,7995.34,\r\n+1406,AAAAAAAAAFOGOBAA,71841.61,93290.02,1998.0\r\n+1407,AAAAAAAAAFOGOBAA,93290.02,27960.97,1999.0\r\n+1408,AAAAAAAAAFOGOBAA,27960.97,68779.09,2000.0\r\n+1409,AAAAAAAAAFOGOBAA,68779.09,44937.11,2001.0\r\n+1410,AAAAAAAAAFOGOBAA,44937.11,,2002.0\r\n+1411,AAAAAAAAAFOGOBAA,,,\r\n+1412,AAAAAAAAAFOHBAAA,118917.06,33359.67,1998.0\r\n+1413,AAAAAAAAAFOHBAAA,33359.67,131304.69,1999.0\r\n+1414,AAAAAAAAAFOHBAAA,131304.69,95895.09,2000.0\r\n+1415,AAAAAAAAAFOHBAAA,95895.09,54372.45,2001.0\r\n+1416,AAAAAAAAAFOHBAAA,54372.45,,2002.0\r\n+1417,AAAAAAAAAFOHBAAA,,,\r\n+1418,AAAAAAAAAFOHMBAA,102406.39,239875.68,1998.0\r\n+1419,AAAAAAAAAFOHMBAA,239875.68,189806.70,1999.0\r\n+1420,AAAAAAAAAFOHMBAA,189806.70,50561.84,2000.0\r\n+1421,AAAAAAAAAFOHMBAA,50561.84,66074.56,2001.0\r\n+1422,AAAAAAAAAFOHMBAA,66074.56,,2002.0\r\n+1423,AAAAAAAAAFOHMBAA,2240.26,2240.26,\r\n+1424,AAAAAAAAAFOIBAAA,74799.10,128239.33,1998.0\r\n+1425,AAAAAAAAAFOIBAAA,128239.33,134285.21,1999.0\r\n+1426,AAAAAAAAAFOIBAAA,134285.21,,2000.0\r\n+1427,AAAAAAAAAFOIBAAA,77236.20,,2002.0\r\n+1428,AAAAAAAAAFOIBAAA,16238.31,16238.31,\r\n+1429,AAAAAAAAAFOIIAAA,90924.55,191259.07,1999.0\r\n+1430,AAAAAAAAAFOIIAAA,191259.07,134003.22,2000.0\r\n+1431,AAAAAAAAAFOIIAAA,134003.22,38834.06,2001.0\r\n+1432,AAAAAAAAAFOIIAAA,38834.06,,2002.0\r\n+1433,AAAAAAAAAFOIIAAA,5978.05,5978.05,\r\n+1434,AAAAAAAAAFOJBAAA,209692.69,61472.58,1998.0\r\n+1435,AAAAAAAAAFOJBAAA,61472.58,29171.83,1999.0\r\n+1436,AAAAAAAAAFOJBAAA,29171.83,124946.56,2000.0\r\n+1437,AAAAAAAAAFOJBAAA,124946.56,78500.56,2001.0\r\n+1438,AAAAAAAAAFOJBAAA,78500.56,,2002.0\r\n+1439,AAAAAAAAAFOJBAAA,,,\r\n+1440,AAAAAAAAAFOJLBAA,64250.51,133718.07,1999.0\r\n+1441,AAAAAAAAAFOJLBAA,133718.07,103835.62,2000.0\r\n+1442,AAAAAAAAAFOJLBAA,103835.62,45678.26,2001.0\r\n+1443,AAAAAAAAAFOJLBAA,45678.26,,2002.0\r\n+1444,AAAAAAAAAFOKFAAA,92185.16,119346.16,1998.0\r\n+1445,AAAAAAAAAFOKFAAA,119346.16,79140.23,1999.0\r\n+1446,AAAAAAAAAFOKFAAA,79140.23,36414.39,2000.0\r\n+1447,AAAAAAAAAFOKFAAA,36414.39,105346.49,2001.0\r\n+1448,AAAAAAAAAFOKFAAA,105346.49,,2002.0\r\n+1449,AAAAAAAAAFOKFAAA,431.83,431.83,\r\n+1450,AAAAAAAAAFOLKBAA,70131.97,38166.03,1998.0\r\n+1451,AAAAAAAAAFOLKBAA,38166.03,,1999.0\r\n+1452,AAAAAAAAAFOLKBAA,106622.98,151068.99,2001.0\r\n+1453,AAAAAAAAAFOLKBAA,151068.99,,2002.0\r\n+1454,AAAAAAAAAFOLKBAA,,,\r\n+1455,AAAAAAAAAFOMAAAA,215211.70,140113.48,1999.0\r\n+1456,AAAAAAAAAFOMAAAA,140113.48,45881.60,2000.0\r\n+1457,AAAAAAAAAFOMAAAA,45881.60,312558.46,2001.0\r\n+1458,AAAAAAAAAFOMAAAA,312558.46,,2002.0\r\n+1459,AAAAAAAAAFOMAAAA,,,\r\n+1460,AAAAAAAAAFOMDAAA,55833.67,325130.66,1998.0\r\n+1461,AAAAAAAAAFOMDAAA,325130.66,,1999.0\r\n+1462,AAAAAAAAAFOMDAAA,69783.93,,2002.0\r\n+1463,AAAAAAAAAFOMDAAA,447.65,447.65,\r\n+1464,AAAAAAAAAFOMFAAA,123781.10,192783.73,1998.0\r\n+1465,AAAAAAAAAFOMFAAA,192783.73,388236.84,1999.0\r\n+1466,AAAAAAAAAFOMFAAA,388236.84,128377.47,2000.0\r\n+1467,AAAAAAAAAFOMFAAA,128377.47,87973.08,2001.0\r\n+1468,AAAAAAAAAFOMFAAA,87973.08,,2002.0\r\n+1469,AAAAAAAAAFOMFAAA,13916.63,13916.63,\r\n+1470,AAAAAAAAAFOMLBAA,81445.72,33433.16,1998.0\r\n+1471,AAAAAAAAAFOMLBAA,33433.16,46312.49,1999.0\r\n+1472,AAAAAAAAAFOMLBAA,46312.49,40553.95,2000.0\r\n+1473,AAAAAAAAAFOMLBAA,40553.95,96722.02,2001.0\r\n+1474,AAAAAAAAAFOMLBAA,96722.02,,2002.0\r\n+1475,AAAAAAAAAFONEBAA,106811.27,173644.50,1998.0\r\n+1476,AAAAAAAAAFONEBAA,173644.50,148949.74,1999.0\r\n+1477,AAAAAAAAAFONEBAA,148949.74,45448.46,2000.0\r\n+1478,AAAAAAAAAFONEBAA,45448.46,89011.74,2001.0\r\n+1479,AAAAAAAAAFONEBAA,89011.74,,2002.0\r\n+1480,AAAAAAAAAFONEBAA,4996.58,4996.58,\r\n+1481,AAAAAAAAAFONNAAA,141991.60,164086.46,1998.0\r\n+1482,AAAAAAAAAFONNAAA,164086.46,129765.27,1999.0\r\n+1483,AAAAAAAAAFONNAAA,129765.27,73960.57,2000.0\r\n+1484,AAAAAAAAAFONNAAA,73960.57,74920.91,2001.0\r\n+1485,AAAAAAAAAFONNAAA,74920.91,,2002.0\r\n+1486,AAAAAAAAAFONNAAA,,,\r\n+1487,AAAAAAAAAFOOJAAA,105226.25,82511.21,1998.0\r\n+1488,AAAAAAAAAFOOJAAA,82511.21,82041.17,1999.0\r\n+1489,AAAAAAAAAFOOJAAA,82041.17,113045.25,2000.0\r\n+1490,AAAAAAAAAFOOJAAA,113045.25,60900.58,2001.0\r\n+1491,AAAAAAAAAFOOJAAA,60900.58,,2002.0\r\n+1492,AAAAAAAAAFOOJAAA,,,\r\n+1493,AAAAAAAAAFOOPAAA,49735.44,,1999.0\r\n+1494,AAAAAAAAAFOOPAAA,62835.19,62667.67,2001.0\r\n+1495,AAAAAAAAAFOOPAAA,62667.67,26784.57,2002.0\r\n+1496,AAAAAAAAAFOOPAAA,26784.57,,2003.0\r\n+1497,AAAAAAAAAFOPHAAA,77392.83,,1998.0\r\n+1498,AAAAAAAAAFOPHAAA,128943.36,99393.31,2000.0\r\n+1499,AAAAAAAAAFOPHAAA,99393.31,132117.41,2001.0\r\n+1500,AAAAAAAAAFOPHAAA,132117.41,,2002.0\r\n+1501,AAAAAAAAAFOPHAAA,4899.70,4899.70,\r\n+1502,AAAAAAAAAFPAHAAA,64915.04,242448.25,1999.0\r\n+1503,AAAAAAAAAFPAHAAA,242448.25,76829.63,2000.0\r\n+1504,AAAAAAAAAFPAHAAA,76829.63,146314.81,2001.0\r\n+1505,AAAAAAAAAFPAHAAA,146314.81,,2002.0\r\n+1506,AAAAAAAAAFPAHAAA,4263.29,4263.29,\r\n+1507,AAAAAAAAAFPANBAA,100689.25,197844.94,1998.0\r\n+1508,AAAAAAAAAFPANBAA,197844.94,167332.80,1999.0\r\n+1509,AAAAAAAAAFPANBAA,167332.80,72248.50,2000.0\r\n+1510,AAAAAAAAAFPANBAA,72248.50,125361.07,2001.0\r\n+1511,AAAAAAAAAFPANBAA,125361.07,36413.73,2002.0\r\n+1512,AAAAAAAAAFPANBAA,36413.73,,2003.0\r\n+1513,AAAAAAAAAFPANBAA,345.11,345.11,\r\n+1514,AAAAAAAAAFPAPAAA,107897.50,37721.40,1998.0\r\n+1515,AAAAAAAAAFPAPAAA,37721.40,88274.68,1999.0\r\n+1516,AAAAAAAAAFPAPAAA,88274.68,70267.77,2000.0\r\n+1517,AAAAAAAAAFPAPAAA,70267.77,32456.63,2001.0\r\n+1518,AAAAAAAAAFPAPAAA,32456.63,,2002.0\r\n+1519,AAAAAAAAAFPAPAAA,,,\r\n+1520,AAAAAAAAAFPBFAAA,49547.56,107719.61,1998.0\r\n+1521,AAAAAAAAAFPBFAAA,107719.61,106776.39,1999.0\r\n+1522,AAAAAAAAAFPBFAAA,106776.39,111971.91,2000.0\r\n+1523,AAAAAAAAAFPBFAAA,111971.91,139080.31,2001.0\r\n+1524,AAAAAAAAAFPBFAAA,139080.31,,2002.0\r\n+1525,AAAAAAAAAFPBFAAA,1887.00,1887.00,\r\n+1526,AAAAAAAAAFPBFBAA,25751.71,137812.01,1998.0\r\n+1527,AAAAAAAAAFPBFBAA,137812.01,129256.47,1999.0\r\n+1528,AAAAAAAAAFPBFBAA,129256.47,126028.51,2000.0\r\n+1529,AAAAAAAAAFPBFBAA,126028.51,110568.44,2001.0\r\n+1530,AAAAAAAAAFPBFBAA,110568.44,,2002.0\r\n+1531,AAAAAAAAAFPBFBAA,,,\r\n+1532,AAAAAAAAAFPDEBAA,185521.68,115816.64,1998.0\r\n+1533,AAAAAAAAAFPDEBAA,115816.64,73760.09,1999.0\r\n+1534,AAAAAAAAAFPDEBAA,73760.09,142074.53,2000.0\r\n+1535,AAAAAAAAAFPDEBAA,142074.53,31086.50,2001.0\r\n+1536,AAAAAAAAAFPDEBAA,31086.50,,2002.0\r\n+1537,AAAAAAAAAFPDEBAA,9611.72,9611.72,\r\n+1538,AAAAAAAAAFPDHAAA,21598.47,,1998.0\r\n+1539,AAAAAAAAAFPDHAAA,33854.24,94553.71,2000.0\r\n+1540,AAAAAAAAAFPDHAAA,94553.71,226728.68,2001.0\r\n+1541,AAAAAAAAAFPDHAAA,226728.68,,2002.0\r\n+1542,AAAAAAAAAFPDHAAA,9850.71,9850.71,\r\n+1543,AAAAAAAAAFPECBAA,82602.91,137687.98,1998.0\r\n+1544,AAAAAAAAAFPECBAA,137687.98,,1999.0\r\n+1545,AAAAAAAAAFPECBAA,85759.29,83067.54,2001.0\r\n+1546,AAAAAAAAAFPECBAA,83067.54,,2002.0\r\n+1547,AAAAAAAAAFPECBAA,,,\r\n+1548,AAAAAAAAAFPELAAA,107236.69,183819.60,1998.0\r\n+1549,AAAAAAAAAFPELAAA,183819.60,146120.76,1999.0\r\n+1550,AAAAAAAAAFPELAAA,146120.76,63929.29,2000.0\r\n+1551,AAAAAAAAAFPELAAA,63929.29,79308.52,2001.0\r\n+1552,AAAAAAAAAFPELAAA,79308.52,,2002.0\r\n+1553,AAAAAAAAAFPELAAA,2321.28,2321.28,\r\n+1554,AAAAAAAAAFPFCBAA,124647.26,358353.46,1998.0\r\n+1555,AAAAAAAAAFPFCBAA,358353.46,234654.98,1999.0\r\n+1556,AAAAAAAAAFPFCBAA,234654.98,168784.52,2000.0\r\n+1557,AAAAAAAAAFPFCBAA,168784.52,92421.51,2001.0\r\n+1558,AAAAAAAAAFPFCBAA,92421.51,,2002.0\r\n+1559,AAAAAAAAAFPFCBAA,5387.32,5387.32,\r\n+1560,AAAAAAAAAFPFEBAA,163389.55,163239.85,1998.0\r\n+1561,AAAAAAAAAFPFEBAA,163239.85,95028.67,1999.0\r\n+1562,AAAAAAAAAFPFEBAA,95028.67,119342.76,2000.0\r\n+1563,AAAAAAAAAFPFEBAA,119342.76,37106.69,2001.0\r\n+1564,AAAAAAAAAFPFEBAA,37106.69,,2002.0\r\n+1565,AAAAAAAAAFPFEBAA,4270.45,4270.45,\r\n+1566,AAAAAAAAAFPFFBAA,25688.80,144544.31,1998.0\r\n+1567,AAAAAAAAAFPFFBAA,144544.31,324776.72,1999.0\r\n+1568,AAAAAAAAAFPFFBAA,324776.72,127721.18,2000.0\r\n+1569,AAAAAAAAAFPFFBAA,127721.18,40321.83,2001.0\r\n+1570,AAAAAAAAAFPFFBAA,40321.83,,2002.0\r\n+1571,AAAAAAAAAFPFFBAA,,,\r\n+1572,AAAAAAAAAFPFLAAA,46380.67,73876.78,1998.0\r\n+1573,AAAAAAAAAFPFLAAA,73876.78,100749.90,1999.0\r\n+1574,AAAAAAAAAFPFLAAA,100749.90,,2000.0\r\n+1575,AAAAAAAAAFPFLAAA,26866.45,,2002.0\r\n+1576,AAAAAAAAAFPGEBAA,117462.13,61537.50,1998.0\r\n+1577,AAAAAAAAAFPGEBAA,61537.50,123650.51,1999.0\r\n+1578,AAAAAAAAAFPGEBAA,123650.51,115612.10,2000.0\r\n+1579,AAAAAAAAAFPGEBAA,115612.10,44791.29,2001.0\r\n+1580,AAAAAAAAAFPGEBAA,44791.29,,2002.0\r\n+1581,AAAAAAAAAFPGEBAA,2679.68,2679.68,\r\n+1582,AAAAAAAAAFPGKBAA,82773.17,57709.78,1998.0\r\n+1583,AAAAAAAAAFPGKBAA,57709.78,74299.86,1999.0\r\n+1584,AAAAAAAAAFPGKBAA,74299.86,197606.65,2000.0\r\n+1585,AAAAAAAAAFPGKBAA,197606.65,,2001.0\r\n+1586,AAAAAAAAAFPGKBAA,924.30,924.30,\r\n+1587,AAAAAAAAAFPHKBAA,84932.56,201102.75,1998.0\r\n+1588,AAAAAAAAAFPHKBAA,201102.75,64085.13,1999.0\r\n+1589,AAAAAAAAAFPHKBAA,64085.13,272491.60,2000.0\r\n+1590,AAAAAAAAAFPHKBAA,272491.60,130202.57,2001.0\r\n+1591,AAAAAAAAAFPHKBAA,130202.57,,2002.0\r\n+1592,AAAAAAAAAFPHKBAA,13386.94,13386.94,\r\n+1593,AAAAAAAAAFPIBAAA,109509.79,138265.89,1998.0\r\n+1594,AAAAAAAAAFPIBAAA,138265.89,113072.30,1999.0\r\n+1595,AAAAAAAAAFPIBAAA,113072.30,13924.46,2000.0\r\n+1596,AAAAAAAAAFPIBAAA,13924.46,69080.67,2001.0\r\n+1597,AAAAAAAAAFPIBAAA,69080.67,,2002.0\r\n+1598,AAAAAAAAAFPIBAAA,,,\r\n+1599,AAAAAAAAAFPKBBAA,71280.13,247051.73,1998.0\r\n+1600,AAAAAAAAAFPKBBAA,247051.73,15920.22,1999.0\r\n+1601,AAAAAAAAAFPKBBAA,15920.22,109709.06,2000.0\r\n+1602,AAAAAAAAAFPKBBAA,109709.06,127571.52,2001.0\r\n+1603,AAAAAAAAAFPKBBAA,127571.52,,2002.0\r\n+1604,AAAAAAAAAFPKBBAA,,,\r\n+1605,AAAAAAAAAFPKCAAA,35567.92,25438.45,1998.0\r\n+1606,AAAAAAAAAFPKCAAA,25438.45,,1999.0\r\n+1607,AAAAAAAAAFPKCAAA,150943.90,139202.75,2001.0\r\n+1608,AAAAAAAAAFPKCAAA,139202.75,,2002.0\r\n+1609,AAAAAAAAAFPKCAAA,7777.50,7777.50,\r\n+1610,AAAAAAAAAFPKMBAA,131713.11,204776.38,1998.0\r\n+1611,AAAAAAAAAFPKMBAA,204776.38,53124.33,1999.0\r\n+1612,AAAAAAAAAFPKMBAA,53124.33,81081.25,2000.0\r\n+1613,AAAAAAAAAFPKMBAA,81081.25,90748.37,2001.0\r\n+1614,AAAAAAAAAFPKMBAA,90748.37,,2002.0\r\n+1615,AAAAAAAAAFPLKBAA,69597.53,106238.82,1998.0\r\n+1616,AAAAAAAAAFPLKBAA,106238.82,59448.58,1999.0\r\n+1617,AAAAAAAAAFPLKBAA,59448.58,35388.88,2000.0\r\n+1618,AAAAAAAAAFPLKBAA,35388.88,84818.86,2001.0\r\n+1619,AAAAAAAAAFPLKBAA,84818.86,,2002.0\r\n+1620,AAAAAAAAAFPMABAA,38217.83,,1998.0\r\n+1621,AAAAAAAAAFPMABAA,298907.02,90804.18,2000.0\r\n+1622,AAAAAAAAAFPMABAA,90804.18,18577.45,2001.0\r\n+1623,AAAAAAAAAFPMABAA,18577.45,,2002.0\r\n+1624,AAAAAAAAAFPMABAA,1460.70,1460.70,\r\n+1625,AAAAAAAAAFPMKAAA,31437.51,101368.34,1999.0\r\n+1626,AAAAAAAAAFPMKAAA,101368.34,102663.08,2000.0\r\n+1627,AAAAAAAAAFPMKAAA,102663.08,52465.02,2001.0\r\n+1628,AAAAAAAAAFPMKAAA,52465.02,,2002.0\r\n+1629,AAAAAAAAAFPMKAAA,651.69,651.69,\r\n+1630,AAAAAAAAAFPNAAAA,144908.39,88005.54,1998.0\r\n+1631,AAAAAAAAAFPNAAAA,88005.54,14669.23,1999.0\r\n+1632,AAAAAAAAAFPNAAAA,14669.23,136825.84,2000.0\r\n+1633,AAAAAAAAAFPNAAAA,136825.84,70430.68,2001.0\r\n+1634,AAAAAAAAAFPNAAAA,70430.68,,2002.0\r\n+1635,AAAAAAAAAFPNAAAA,,,\r\n+1636,AAAAAAAAAFPNABAA,86010.01,96961.46,1998.0\r\n+1637,AAAAAAAAAFPNABAA,96961.46,74427.04,1999.0\r\n+1638,AAAAAAAAAFPNABAA,74427.04,61356.93,2000.0\r\n+1639,AAAAAAAAAFPNABAA,61356.93,44361.40,2001.0\r\n+1640,AAAAAAAAAFPNABAA,44361.40,,2002.0\r\n+1641,AAAAAAAAAFPNABAA,,,\r\n+1642,AAAAAAAAAFPNCBAA,115726.60,294913.75,1998.0\r\n+1643,AAAAAAAAAFPNCBAA,294913.75,,1999.0\r\n+1644,AAAAAAAAAFPNCBAA,207963.49,166418.93,2001.0\r\n+1645,AAAAAAAAAFPNCBAA,166418.93,,2002.0\r\n+1646,AAAAAAAAAFPNCBAA,1151.96,1151.96,\r\n+1647,AAAAAAAAAFPNIBAA,157150.77,26784.29,1998.0\r\n+1648,AAAAAAAAAFPNIBAA,26784.29,34067.43,1999.0\r\n+1649,AAAAAAAAAFPNIBAA,34067.43,,2000.0\r\n+1650,AAAAAAAAAFPNIBAA,57297.20,,2002.0\r\n+1651,AAAAAAAAAFPNIBAA,,,\r\n+1652,AAAAAAAAAFPNLBAA,172680.04,186595.51,1998.0\r\n+1653,AAAAAAAAAFPNLBAA,186595.51,84129.55,1999.0\r\n+1654,AAAAAAAAAFPNLBAA,84129.55,131769.51,2000.0\r\n+1655,AAAAAAAAAFPNLBAA,131769.51,93480.21,2001.0\r\n+1656,AAAAAAAAAFPNLBAA,93480.21,,2002.0\r\n+1657,AAAAAAAAAFPNLBAA,7629.68,7629.68,\r\n+1658,AAAAAAAAAFPNPAAA,114919.49,82251.69,1998.0\r\n+1659,AAAAAAAAAFPNPAAA,82251.69,75233.02,1999.0\r\n+1660,AAAAAAAAAFPNPAAA,75233.02,57577.54,2000.0\r\n+1661,AAAAAAAAAFPNPAAA,57577.54,,2001.0\r\n+1662,AAAAAAAAAFPNPAAA,,,\r\n+1663,AAAAAAAAAFPPHAAA,116697.07,125808.90,1998.0\r\n+1664,AAAAAAAAAFPPHAAA,125808.90,31639.81,1999.0\r\n+1665,AAAAAAAAAFPPHAAA,31639.81,,2000.0\r\n+1666,AAAAAAAAAFPPHAAA,2604.48,2604.48,\r\n+1667,AAAAAAAAAGAAIAAA,82409.02,43523.71,1998.0\r\n+1668,AAAAAAAAAGAAIAAA,43523.71,32318.33,1999.0\r\n+1669,AAAAAAAAAGAAIAAA,32318.33,209407.54,2000.0\r\n+1670,AAAAAAAAAGAAIAAA,209407.54,30861.25,2001.0\r\n+1671,AAAAAAAAAGAAIAAA,30861.25,,2002.0\r\n+1672,AAAAAAAAAGAAIAAA,865.17,865.17,\r\n+1673,AAAAAAAAAGAAMBAA,120516.34,154674.30,1998.0\r\n+1674,AAAAAAAAAGAAMBAA,154674.30,,1999.0\r\n+1675,AAAAAAAAAGAAMBAA,72520.91,96377.79,2001.0\r\n+1676,AAAAAAAAAGAAMBAA,96377.79,,2002.0\r\n+1677,AAAAAAAAAGAAMBAA,,,\r\n+1678,AAAAAAAAAGAAPAAA,133671.99,84385.15,1998.0\r\n+1679,AAAAAAAAAGAAPAAA,84385.15,163613.85,1999.0\r\n+1680,AAAAAAAAAGAAPAAA,163613.85,71760.64,2000.0\r\n+1681,AAAAAAAAAGAAPAAA,71760.64,113303.32,2001.0\r\n+1682,AAAAAAAAAGAAPAAA,113303.32,,2002.0\r\n+1683,AAAAAAAAAGAAPAAA,,,\r\n+1684,AAAAAAAAAGABAAAA,153160.25,187278.62,1998.0\r\n+1685,AAAAAAAAAGABAAAA,187278.62,104776.91,1999.0\r\n+1686,AAAAAAAAAGABAAAA,104776.91,170697.73,2000.0\r\n+1687,AAAAAAAAAGABAAAA,170697.73,114188.63,2001.0\r\n+1688,AAAAAAAAAGABAAAA,114188.63,,2002.0\r\n+1689,AAAAAAAAAGABAAAA,,,\r\n+1690,AAAAAAAAAGABABAA,98157.70,48730.71,1998.0\r\n+1691,AAAAAAAAAGABABAA,48730.71,190573.18,1999.0\r\n+1692,AAAAAAAAAGABABAA,190573.18,93275.54,2000.0\r\n+1693,AAAAAAAAAGABABAA,93275.54,106391.90,2001.0\r\n+1694,AAAAAAAAAGABABAA,106391.90,,2002.0\r\n+1695,AAAAAAAAAGABABAA,,,\r\n+1696,AAAAAAAAAGABHBAA,31435.45,,1998.0\r\n+1697,AAAAAAAAAGABHBAA,143576.88,32855.55,2000.0\r\n+1698,AAAAAAAAAGABHBAA,32855.55,125967.18,2001.0\r\n+1699,AAAAAAAAAGABHBAA,125967.18,,2002.0\r\n+1700,AAAAAAAAAGABHBAA,,,\r\n+1701,AAAAAAAAAGADAAAA,156801.69,191278.77,1998.0\r\n+1702,AAAAAAAAAGADAAAA,191278.77,,1999.0\r\n+1703,AAAAAAAAAGADAAAA,49248.65,137651.25,2001.0\r\n+1704,AAAAAAAAAGADAAAA,137651.25,,2002.0\r\n+1705,AAAAAAAAAGADJAAA,94232.87,,1999.0\r\n+1706,AAAAAAAAAGADJAAA,97792.62,221834.97,2001.0\r\n+1707,AAAAAAAAAGADJAAA,221834.97,,2002.0\r\n+1708,AAAAAAAAAGADJAAA,,,\r\n+1709,AAAAAAAAAGADMAAA,45913.17,61900.30,1998.0\r\n+1710,AAAAAAAAAGADMAAA,61900.30,42558.83,1999.0\r\n+1711,AAAAAAAAAGADMAAA,42558.83,102238.24,2000.0\r\n+1712,AAAAAAAAAGADMAAA,102238.24,89624.37,2001.0\r\n+1713,AAAAAAAAAGADMAAA,89624.37,,2002.0\r\n+1714,AAAAAAAAAGADMAAA,11542.68,11542.68,\r\n+1715,AAAAAAAAAGAFDAAA,28915.95,66675.83,1998.0\r\n+1716,AAAAAAAAAGAFDAAA,66675.83,61296.87,1999.0\r\n+1717,AAAAAAAAAGAFDAAA,61296.87,33106.07,2000.0\r\n+1718,AAAAAAAAAGAFDAAA,33106.07,232394.87,2001.0\r\n+1719,AAAAAAAAAGAFDAAA,232394.87,,2002.0\r\n+1720,AAAAAAAAAGAFDAAA,,,\r\n+1721,AAAAAAAAAGAFFAAA,195572.39,75078.77,1998.0\r\n+1722,AAAAAAAAAGAFFAAA,75078.77,102651.86,1999.0\r\n+1723,AAAAAAAAAGAFFAAA,102651.86,,2000.0\r\n+1724,AAAAAAAAAGAFFAAA,218942.68,,2002.0\r\n+1725,AAAAAAAAAGAFFAAA,11028.52,11028.52,\r\n+1726,AAAAAAAAAGAGKBAA,124672.62,155496.54,1998.0\r\n+1727,AAAAAAAAAGAGKBAA,155496.54,39406.28,1999.0\r\n+1728,AAAAAAAAAGAGKBAA,39406.28,81859.74,2000.0\r\n+1729,AAAAAAAAAGAGKBAA,81859.74,126369.09,2001.0\r\n+1730,AAAAAAAAAGAGKBAA,126369.09,,2002.0\r\n+1731,AAAAAAAAAGAGKBAA,12159.28,12159.28,\r\n+1732,AAAAAAAAAGAHABAA,69670.92,41397.81,1998.0\r\n+1733,AAAAAAAAAGAHABAA,41397.81,28614.80,1999.0\r\n+1734,AAAAAAAAAGAHABAA,28614.80,182123.72,2000.0\r\n+1735,AAAAAAAAAGAHABAA,182123.72,125297.37,2001.0\r\n+1736,AAAAAAAAAGAHABAA,125297.37,,2002.0\r\n+1737,AAAAAAAAAGAHABAA,848.50,848.50,\r\n+1738,AAAAAAAAAGAHCBAA,150400.95,63685.31,1998.0\r\n+1739,AAAAAAAAAGAHCBAA,63685.31,167778.79,1999.0\r\n+1740,AAAAAAAAAGAHCBAA,167778.79,,2000.0\r\n+1741,AAAAAAAAAGAHCBAA,223174.63,,2002.0\r\n+1742,AAAAAAAAAGAHCBAA,3988.62,3988.62,\r\n+1743,AAAAAAAAAGAIDBAA,25753.59,129819.42,1998.0\r\n+1744,AAAAAAAAAGAIDBAA,129819.42,206986.56,1999.0\r\n+1745,AAAAAAAAAGAIDBAA,206986.56,92495.12,2000.0\r\n+1746,AAAAAAAAAGAIDBAA,92495.12,115923.94,2001.0\r\n+1747,AAAAAAAAAGAIDBAA,115923.94,,2002.0\r\n+1748,AAAAAAAAAGAIDBAA,,,\r\n+1749,AAAAAAAAAGAINBAA,182009.89,218433.78,1998.0\r\n+1750,AAAAAAAAAGAINBAA,218433.78,228175.87,1999.0\r\n+1751,AAAAAAAAAGAINBAA,228175.87,,2000.0\r\n+1752,AAAAAAAAAGAINBAA,146724.86,,2002.0\r\n+1753,AAAAAAAAAGAINBAA,1548.99,1548.99,\r\n+1754,AAAAAAAAAGAJCAAA,36700.35,254941.11,1998.0\r\n+1755,AAAAAAAAAGAJCAAA,254941.11,,1999.0\r\n+1756,AAAAAAAAAGAJCAAA,108269.83,,2001.0\r\n+1757,AAAAAAAAAGAJCAAA,7578.61,7578.61,\r\n+1758,AAAAAAAAAGAKMAAA,257540.23,46746.91,1998.0\r\n+1759,AAAAAAAAAGAKMAAA,46746.91,98772.70,1999.0\r\n+1760,AAAAAAAAAGAKMAAA,98772.70,130886.55,2000.0\r\n+1761,AAAAAAAAAGAKMAAA,130886.55,97987.60,2001.0\r\n+1762,AAAAAAAAAGAKMAAA,97987.60,,2002.0\r\n+1763,AAAAAAAAAGAKMAAA,,,\r\n+1764,AAAAAAAAAGALDAAA,63242.45,199455.51,1998.0\r\n+1765,AAAAAAAAAGALDAAA,199455.51,,1999.0\r\n+1766,AAAAAAAAAGALDAAA,116610.32,77149.53,2001.0\r\n+1767,AAAAAAAAAGALDAAA,77149.53,,2002.0\r\n+1768,AAAAAAAAAGALDAAA,,,\r\n+1769,AAAAAAAAAGALKAAA,115105.63,,1998.0\r\n+1770,AAAAAAAAAGALKAAA,134602.33,115221.34,2000.0\r\n+1771,AAAAAAAAAGALKAAA,115221.34,,2001.0\r\n+1772,AAAAAAAAAGALKAAA,,,\r\n+1773,AAAAAAAAAGALOAAA,31035.43,108356.60,1998.0\r\n+1774,AAAAAAAAAGALOAAA,108356.60,,1999.0\r\n+1775,AAAAAAAAAGALOAAA,290238.22,124037.55,2001.0\r\n+1776,AAAAAAAAAGALOAAA,124037.55,,2002.0\r\n+1777,AAAAAAAAAGALOAAA,,,\r\n+1778,AAAAAAAAAGAMGAAA,114734.76,48437.92,1999.0\r\n+1779,AAAAAAAAAGAMGAAA,48437.92,34648.84,2000.0\r\n+1780,AAAAAAAAAGAMGAAA,34648.84,29199.09,2001.0\r\n+1781,AAAAAAAAAGAMGAAA,29199.09,,2002.0\r\n+1782,AAAAAAAAAGAMGAAA,13034.30,13034.30,\r\n+1783,AAAAAAAAAGAMGBAA,183599.35,155561.49,1998.0\r\n+1784,AAAAAAAAAGAMGBAA,155561.49,150034.15,1999.0\r\n+1785,AAAAAAAAAGAMGBAA,150034.15,36801.77,2000.0\r\n+1786,AAAAAAAAAGAMGBAA,36801.77,120644.53,2001.0\r\n+1787,AAAAAAAAAGAMGBAA,120644.53,,2002.0\r\n+1788,AAAAAAAAAGAMGBAA,,,\r\n+1789,AAAAAAAAAGAMLAAA,125141.81,80545.64,1998.0\r\n+1790,AAAAAAAAAGAMLAAA,80545.64,100891.84,1999.0\r\n+1791,AAAAAAAAAGAMLAAA,100891.84,95684.89,2000.0\r\n+1792,AAAAAAAAAGAMLAAA,95684.89,160003.70,2001.0\r\n+1793,AAAAAAAAAGAMLAAA,160003.70,,2002.0\r\n+1794,AAAAAAAAAGAMLAAA,9712.59,9712.59,\r\n+1795,AAAAAAAAAGAMMAAA,85485.53,96447.46,1998.0\r\n+1796,AAAAAAAAAGAMMAAA,96447.46,79720.11,1999.0\r\n+1797,AAAAAAAAAGAMMAAA,79720.11,,2000.0\r\n+1798,AAAAAAAAAGAMMAAA,,,\r\n+1799,AAAAAAAAAGANLAAA,70818.81,110051.71,1998.0\r\n+1800,AAAAAAAAAGANLAAA,110051.71,169670.57,1999.0\r\n+1801,AAAAAAAAAGANLAAA,169670.57,214162.69,2000.0\r\n+1802,AAAAAAAAAGANLAAA,214162.69,65268.24,2001.0\r\n+1803,AAAAAAAAAGANLAAA,65268.24,,2002.0\r\n+1804,AAAAAAAAAGANLAAA,,,\r\n+1805,AAAAAAAAAGAOHBAA,72363.67,42499.05,1998.0\r\n+1806,AAAAAAAAAGAOHBAA,42499.05,152341.92,1999.0\r\n+1807,AAAAAAAAAGAOHBAA,152341.92,164427.98,2000.0\r\n+1808,AAAAAAAAAGAOHBAA,164427.98,55919.12,2001.0\r\n+1809,AAAAAAAAAGAOHBAA,55919.12,,2002.0\r\n+1810,AAAAAAAAAGAONBAA,94442.13,93698.48,1998.0\r\n+1811,AAAAAAAAAGAONBAA,93698.48,71452.74,1999.0\r\n+1812,AAAAAAAAAGAONBAA,71452.74,57948.69,2000.0\r\n+1813,AAAAAAAAAGAONBAA,57948.69,37829.17,2001.0\r\n+1814,AAAAAAAAAGAONBAA,37829.17,,2002.0\r\n+1815,AAAAAAAAAGAONBAA,,,\r\n+1816,AAAAAAAAAGAPCAAA,136060.40,,1998.0\r\n+1817,AAAAAAAAAGAPCAAA,43786.92,66487.51,2000.0\r\n+1818,AAAAAAAAAGAPCAAA,66487.51,103135.00,2001.0\r\n+1819,AAAAAAAAAGAPCAAA,103135.00,,2002.0\r\n+1820,AAAAAAAAAGBACBAA,35557.25,126559.32,1998.0\r\n+1821,AAAAAAAAAGBACBAA,126559.32,36508.13,1999.0\r\n+1822,AAAAAAAAAGBACBAA,36508.13,95230.43,2000.0\r\n+1823,AAAAAAAAAGBACBAA,95230.43,79337.02,2001.0\r\n+1824,AAAAAAAAAGBACBAA,79337.02,,2002.0\r\n+1825,AAAAAAAAAGBACBAA,476.24,476.24,\r\n+1826,AAAAAAAAAGBBABAA,32292.08,112161.46,1998.0\r\n+1827,AAAAAAAAAGBBABAA,112161.46,61539.22,1999.0\r\n+1828,AAAAAAAAAGBBABAA,61539.22,119534.61,2000.0\r\n+1829,AAAAAAAAAGBBABAA,119534.61,29721.49,2001.0\r\n+1830,AAAAAAAAAGBBABAA,29721.49,,2002.0\r\n+1831,AAAAAAAAAGBBABAA,,,\r\n+1832,AAAAAAAAAGBCAAAA,175929.62,68728.23,1999.0\r\n+1833,AAAAAAAAAGBCAAAA,68728.23,143014.48,2000.0\r\n+1834,AAAAAAAAAGBCAAAA,143014.48,17648.09,2001.0\r\n+1835,AAAAAAAAAGBCAAAA,17648.09,,2002.0\r\n+1836,AAAAAAAAAGBDABAA,239572.81,67800.78,1998.0\r\n+1837,AAAAAAAAAGBDABAA,67800.78,93766.28,1999.0\r\n+1838,AAAAAAAAAGBDABAA,93766.28,141255.61,2000.0\r\n+1839,AAAAAAAAAGBDABAA,141255.61,155432.56,2001.0\r\n+1840,AAAAAAAAAGBDABAA,155432.56,,2002.0\r\n+1841,AAAAAAAAAGBDABAA,8825.60,8825.60,\r\n+1842,AAAAAAAAAGBEDBAA,134934.36,101475.64,1998.0\r\n+1843,AAAAAAAAAGBEDBAA,101475.64,57179.17,1999.0\r\n+1844,AAAAAAAAAGBEDBAA,57179.17,26545.37,2000.0\r\n+1845,AAAAAAAAAGBEDBAA,26545.37,86868.22,2001.0\r\n+1846,AAAAAAAAAGBEDBAA,86868.22,,2002.0\r\n+1847,AAAAAAAAAGBEDBAA,,,\r\n+1848,AAAAAAAAAGBEEAAA,18333.34,211202.70,1998.0\r\n+1849,AAAAAAAAAGBEEAAA,211202.70,104556.95,1999.0\r\n+1850,AAAAAAAAAGBEEAAA,104556.95,30659.08,2000.0\r\n+1851,AAAAAAAAAGBEEAAA,30659.08,202473.11,2001.0\r\n+1852,AAAAAAAAAGBEEAAA,202473.11,,2002.0\r\n+1853,AAAAAAAAAGBEEAAA,13954.72,13954.72,\r\n+1854,AAAAAAAAAGBEKBAA,110326.61,78316.54,1998.0\r\n+1855,AAAAAAAAAGBEKBAA,78316.54,33794.80,1999.0\r\n+1856,AAAAAAAAAGBEKBAA,33794.80,134646.03,2000.0\r\n+1857,AAAAAAAAAGBEKBAA,134646.03,184201.16,2001.0\r\n+1858,AAAAAAAAAGBEKBAA,184201.16,,2002.0\r\n+1859,AAAAAAAAAGBEKBAA,2815.89,2815.89,\r\n+1860,AAAAAAAAAGBEMAAA,53537.11,155831.28,1998.0\r\n+1861,AAAAAAAAAGBEMAAA,155831.28,129303.01,1999.0\r\n+1862,AAAAAAAAAGBEMAAA,129303.01,57067.32,2000.0\r\n+1863,AAAAAAAAAGBEMAAA,57067.32,215626.75,2001.0\r\n+1864,AAAAAAAAAGBEMAAA,215626.75,,2002.0\r\n+1865,AAAAAAAAAGBEMAAA,3428.96,3428.96,\r\n+1866,AAAAAAAAAGBFDAAA,34919.28,63114.25,1998.0\r\n+1867,AAAAAAAAAGBFDAAA,63114.25,92421.01,1999.0\r\n+1868,AAAAAAAAAGBFDAAA,92421.01,12870.53,2000.0\r\n+1869,AAAAAAAAAGBFDAAA,12870.53,60488.36,2001.0\r\n+1870,AAAAAAAAAGBFDAAA,60488.36,,2002.0\r\n+1871,AAAAAAAAAGBFDAAA,75.11,75.11,\r\n+1872,AAAAAAAAAGBGJAAA,203681.64,182432.63,1998.0\r\n+1873,AAAAAAAAAGBGJAAA,182432.63,106702.21,1999.0\r\n+1874,AAAAAAAAAGBGJAAA,106702.21,101563.90,2000.0\r\n+1875,AAAAAAAAAGBGJAAA,101563.90,76182.98,2001.0\r\n+1876,AAAAAAAAAGBGJAAA,76182.98,,2002.0\r\n+1877,AAAAAAAAAGBGJAAA,,,\r\n+1878,AAAAAAAAAGBGOBAA,147262.29,92335.28,1999.0\r\n+1879,AAAAAAAAAGBGOBAA,92335.28,71412.68,2000.0\r\n+1880,AAAAAAAAAGBGOBAA,71412.68,44759.68,2001.0\r\n+1881,AAAAAAAAAGBGOBAA,44759.68,,2002.0\r\n+1882,AAAAAAAAAGBGOBAA,,,\r\n+1883,AAAAAAAAAGBHHAAA,42418.08,198737.91,1998.0\r\n+1884,AAAAAAAAAGBHHAAA,198737.91,19754.43,1999.0\r\n+1885,AAAAAAAAAGBHHAAA,19754.43,100561.84,2000.0\r\n+1886,AAAAAAAAAGBHHAAA,100561.84,,2001.0\r\n+1887,AAAAAAAAAGBHHAAA,,,\r\n+1888,AAAAAAAAAGBIBAAA,108468.98,87560.76,1998.0\r\n+1889,AAAAAAAAAGBIBAAA,87560.76,85784.76,1999.0\r\n+1890,AAAAAAAAAGBIBAAA,85784.76,50127.58,2000.0\r\n+1891,AAAAAAAAAGBIBAAA,50127.58,81258.58,2001.0\r\n+1892,AAAAAAAAAGBIBAAA,81258.58,,2002.0\r\n+1893,AAAAAAAAAGBIGBAA,137848.36,,1998.0\r\n+1894,AAAAAAAAAGBIGBAA,103658.40,36436.44,2000.0\r\n+1895,AAAAAAAAAGBIGBAA,36436.44,118995.74,2001.0\r\n+1896,AAAAAAAAAGBIGBAA,118995.74,,2002.0\r\n+1897,AAAAAAAAAGBIGBAA,,,\r\n+1898,AAAAAAAAAGBIOAAA,86760.27,33361.79,1998.0\r\n+1899,AAAAAAAAAGBIOAAA,33361.79,24274.87,1999.0\r\n+1900,AAAAAAAAAGBIOAAA,24274.87,,2000.0\r\n+1901,AAAAAAAAAGBIOAAA,24863.14,,2002.0\r\n+1902,AAAAAAAAAGBIOAAA,2340.27,2340.27,\r\n+1903,AAAAAAAAAGBJDAAA,22847.30,98624.83,1998.0\r\n+1904,AAAAAAAAAGBJDAAA,98624.83,145227.00,1999.0\r\n+1905,AAAAAAAAAGBJDAAA,145227.00,64052.75,2000.0\r\n+1906,AAAAAAAAAGBJDAAA,64052.75,234954.51,2001.0\r\n+1907,AAAAAAAAAGBJDAAA,234954.51,,2002.0\r\n+1908,AAAAAAAAAGBJDAAA,718.96,718.96,\r\n+1909,AAAAAAAAAGBJIBAA,55297.72,45540.96,1998.0\r\n+1910,AAAAAAAAAGBJIBAA,45540.96,31366.90,1999.0\r\n+1911,AAAAAAAAAGBJIBAA,31366.90,76749.96,2000.0\r\n+1912,AAAAAAAAAGBJIBAA,76749.96,56239.35,2001.0\r\n+1913,AAAAAAAAAGBJIBAA,56239.35,42029.60,2002.0\r\n+1914,AAAAAAAAAGBJIBAA,42029.60,,2003.0\r\n+1915,AAAAAAAAAGBJIBAA,,,\r\n+1916,AAAAAAAAAGBKKBAA,86301.88,,1998.0\r\n+1917,AAAAAAAAAGBKKBAA,48742.01,49103.98,2000.0\r\n+1918,AAAAAAAAAGBKKBAA,49103.98,44612.38,2001.0\r\n+1919,AAAAAAAAAGBKKBAA,44612.38,,2002.0\r\n+1920,AAAAAAAAAGBKKBAA,5146.72,5146.72,\r\n+1921,AAAAAAAAAGBLKBAA,196165.40,97399.51,1998.0\r\n+1922,AAAAAAAAAGBLKBAA,97399.51,115063.06,1999.0\r\n+1923,AAAAAAAAAGBLKBAA,115063.06,97025.70,2000.0\r\n+1924,AAAAAAAAAGBLKBAA,97025.70,214868.26,2001.0\r\n+1925,AAAAAAAAAGBLKBAA,214868.26,,2002.0\r\n+1926,AAAAAAAAAGBLKBAA,,,\r\n+1927,AAAAAAAAAGBLPAAA,84861.60,58932.59,1998.0\r\n+1928,AAAAAAAAAGBLPAAA,58932.59,38041.88,1999.0\r\n+1929,AAAAAAAAAGBLPAAA,38041.88,50612.74,2000.0\r\n+1930,AAAAAAAAAGBLPAAA,50612.74,79622.85,2001.0\r\n+1931,AAAAAAAAAGBLPAAA,79622.85,,2002.0\r\n+1932,AAAAAAAAAGBLPAAA,,,\r\n+1933,AAAAAAAAAGBMBAAA,119180.65,94689.32,1998.0\r\n+1934,AAAAAAAAAGBMBAAA,94689.32,204046.78,1999.0\r\n+1935,AAAAAAAAAGBMBAAA,204046.78,116069.35,2000.0\r\n+1936,AAAAAAAAAGBMBAAA,116069.35,41002.57,2001.0\r\n+1937,AAAAAAAAAGBMBAAA,41002.57,,2002.0\r\n+1938,AAAAAAAAAGBMBAAA,4132.12,4132.12,\r\n+1939,AAAAAAAAAGBMJBAA,88993.21,251410.11,1998.0\r\n+1940,AAAAAAAAAGBMJBAA,251410.11,22108.91,1999.0\r\n+1941,AAAAAAAAAGBMJBAA,22108.91,118723.43,2000.0\r\n+1942,AAAAAAAAAGBMJBAA,118723.43,193165.63,2001.0\r\n+1943,AAAAAAAAAGBMJBAA,193165.63,,2002.0\r\n+1944,AAAAAAAAAGBMJBAA,10236.16,10236.16,\r\n+1945,AAAAAAAAAGBMKAAA,35307.14,196981.71,1998.0\r\n+1946,AAAAAAAAAGBMKAAA,196981.71,13710.99,1999.0\r\n+1947,AAAAAAAAAGBMKAAA,13710.99,46132.93,2000.0\r\n+1948,AAAAAAAAAGBMKAAA,46132.93,77451.94,2001.0\r\n+1949,AAAAAAAAAGBMKAAA,77451.94,,2002.0\r\n+1950,AAAAAAAAAGBMKAAA,7025.04,7025.04,\r\n+1951,AAAAAAAAAGBOJBAA,202107.31,55655.30,1998.0\r\n+1952,AAAAAAAAAGBOJBAA,55655.30,79056.25,1999.0\r\n+1953,AAAAAAAAAGBOJBAA,79056.25,,2000.0\r\n+1954,AAAAAAAAAGBOJBAA,123050.17,,2002.0\r\n+1955,AAAAAAAAAGBONAAA,21090.26,181437.66,1999.0\r\n+1956,AAAAAAAAAGBONAAA,181437.66,196330.24,2000.0\r\n+1957,AAAAAAAAAGBONAAA,196330.24,32930.63,2001.0\r\n+1958,AAAAAAAAAGBONAAA,32930.63,,2002.0\r\n+1959,AAAAAAAAAGBONAAA,685.98,685.98,\r\n+1960,AAAAAAAAAGBOPAAA,68479.07,25554.25,1998.0\r\n+1961,AAAAAAAAAGBOPAAA,25554.25,,1999.0\r\n+1962,AAAAAAAAAGBOPAAA,148200.35,69612.07,2001.0\r\n+1963,AAAAAAAAAGBOPAAA,69612.07,,2002.0\r\n+1964,AAAAAAAAAGBOPAAA,5735.82,5735.82,\r\n+1965,AAAAAAAAAGBPABAA,84624.27,95770.75,1998.0\r\n+1966,AAAAAAAAAGBPABAA,95770.75,,1999.0\r\n+1967,AAAAAAAAAGBPABAA,54875.48,14876.10,2001.0\r\n+1968,AAAAAAAAAGBPABAA,14876.10,,2002.0\r\n+1969,AAAAAAAAAGBPFBAA,180298.05,57370.90,1998.0\r\n+1970,AAAAAAAAAGBPFBAA,57370.90,70679.41,1999.0\r\n+1971,AAAAAAAAAGBPFBAA,70679.41,176064.07,2000.0\r\n+1972,AAAAAAAAAGBPFBAA,176064.07,62638.93,2001.0\r\n+1973,AAAAAAAAAGBPFBAA,62638.93,,2002.0\r\n+1974,AAAAAAAAAGBPFBAA,903.42,903.42,\r\n+1975,AAAAAAAAAGBPIBAA,82826.95,352573.18,1998.0\r\n+1976,AAAAAAAAAGBPIBAA,352573.18,,1999.0\r\n+1977,AAAAAAAAAGBPIBAA,133655.18,,2002.0\r\n+1978,AAAAAAAAAGBPIBAA,8622.64,8622.64,\r\n+1979,AAAAAAAAAGBPMAAA,98327.40,74348.05,1998.0\r\n+1980,AAAAAAAAAGBPMAAA,74348.05,95596.06,1999.0\r\n+1981,AAAAAAAAAGBPMAAA,95596.06,91158.21,2000.0\r\n+1982,AAAAAAAAAGBPMAAA,91158.21,76446.72,2001.0\r\n+1983,AAAAAAAAAGBPMAAA,76446.72,,2002.0\r\n+1984,AAAAAAAAAGBPMAAA,712.99,712.99,\r\n+1985,AAAAAAAAAGCABAAA,29644.08,112834.15,1998.0\r\n+1986,AAAAAAAAAGCABAAA,112834.15,105454.22,1999.0\r\n+1987,AAAAAAAAAGCABAAA,105454.22,189983.19,2000.0\r\n+1988,AAAAAAAAAGCABAAA,189983.19,70439.95,2001.0\r\n+1989,AAAAAAAAAGCABAAA,70439.95,,2002.0\r\n+1990,AAAAAAAAAGCABAAA,2124.32,2124.32,\r\n+1991,AAAAAAAAAGCABBAA,28247.44,190984.16,1998.0\r\n+1992,AAAAAAAAAGCABBAA,190984.16,134337.26,1999.0\r\n+1993,AAAAAAAAAGCABBAA,134337.26,76267.42,2000.0\r\n+1994,AAAAAAAAAGCABBAA,76267.42,198732.60,2001.0\r\n+1995,AAAAAAAAAGCABBAA,198732.60,,2002.0\r\n+1996,AAAAAAAAAGCABBAA,3258.18,3258.18,\r\n+1997,AAAAAAAAAGCALBAA,102229.55,,1998.0\r\n+1998,AAAAAAAAAGCALBAA,54922.39,91559.54,2000.0\r\n+1999,AAAAAAAAAGCALBAA,91559.54,93678.91,2001.0\r\n+2000,AAAAAAAAAGCALBAA,93678.91,,2002.0\r\n+2001,AAAAAAAAAGCALBAA,,,\r\n+2002,AAAAAAAAAGCAMAAA,197920.62,44569.98,1998.0\r\n+2003,AAAAAAAAAGCAMAAA,44569.98,84191.19,1999.0\r\n+2004,AAAAAAAAAGCAMAAA,84191.19,73490.14,2000.0\r\n+2005,AAAAAAAAAGCAMAAA,73490.14,83424.64,2001.0\r\n+2006,AAAAAAAAAGCAMAAA,83424.64,,2002.0\r\n+2007,AAAAAAAAAGCAMAAA,4642.10,4642.10,\r\n+2008,AAAAAAAAAGCBAAAA,70816.92,113793.77,1998.0\r\n+2009,AAAAAAAAAGCBAAAA,113793.77,115623.43,1999.0\r\n+2010,AAAAAAAAAGCBAAAA,115623.43,124553.14,2000.0\r\n+2011,AAAAAAAAAGCBAAAA,124553.14,109757.69,2001.0\r\n+2012,AAAAAAAAAGCBAAAA,109757.69,,2002.0\r\n+2013,AAAAAAAAAGCBAAAA,9804.48,9804.48,\r\n+2014,AAAAAAAAAGCBMAAA,45151.97,206268.46,1998.0\r\n+2015,AAAAAAAAAGCBMAAA,206268.46,55950.34,1999.0\r\n+2016,AAAAAAAAAGCBMAAA,55950.34,51945.99,2000.0\r\n+2017,AAAAAAAAAGCBMAAA,51945.99,116255.19,2001.0\r\n+2018,AAAAAAAAAGCBMAAA,116255.19,,2002.0\r\n+2019,AAAAAAAAAGCBMAAA,,,\r\n+2020,AAAAAAAAAGCCBBAA,49844.98,173062.36,1998.0\r\n+2021,AAAAAAAAAGCCBBAA,173062.36,145059.75,1999.0\r\n+2022,AAAAAAAAAGCCBBAA,145059.75,219977.91,2000.0\r\n+2023,AAAAAAAAAGCCBBAA,219977.91,97532.12,2001.0\r\n+2024,AAAAAAAAAGCCBBAA,97532.12,,2002.0\r\n+2025,AAAAAAAAAGCCBBAA,,,\r\n+2026,AAAAAAAAAGCCCAAA,121697.24,39814.77,1998.0\r\n+2027,AAAAAAAAAGCCCAAA,39814.77,,1999.0\r\n+2028,AAAAAAAAAGCCCAAA,162135.21,27430.57,2001.0\r\n+2029,AAAAAAAAAGCCCAAA,27430.57,,2002.0\r\n+2030,AAAAAAAAAGCCCAAA,,,\r\n+2031,AAAAAAAAAGCCHBAA,180822.23,105224.46,1998.0\r\n+2032,AAAAAAAAAGCCHBAA,105224.46,,1999.0\r\n+2033,AAAAAAAAAGCCHBAA,26861.28,115490.70,2001.0\r\n+2034,AAAAAAAAAGCCHBAA,115490.70,,2002.0\r\n+2035,AAAAAAAAAGCCHBAA,1445.58,1445.58,\r\n+2036,AAAAAAAAAGCDAAAA,107787.38,21215.71,1998.0\r\n+2037,AAAAAAAAAGCDAAAA,21215.71,30181.28,1999.0\r\n+2038,AAAAAAAAAGCDAAAA,30181.28,,2000.0\r\n+2039,AAAAAAAAAGCDAAAA,117.63,117.63,\r\n+2040,AAAAAAAAAGCDCBAA,230479.02,226177.94,1998.0\r\n+2041,AAAAAAAAAGCDCBAA,226177.94,37014.66,1999.0\r\n+2042,AAAAAAAAAGCDCBAA,37014.66,63477.00,2000.0\r\n+2043,AAAAAAAAAGCDCBAA,63477.00,119634.98,2001.0\r\n+2044,AAAAAAAAAGCDCBAA,119634.98,,2002.0\r\n+2045,AAAAAAAAAGCDCBAA,6600.80,6600.80,\r\n+2046,AAAAAAAAAGCEFBAA,102834.74,159774.72,1998.0\r\n+2047,AAAAAAAAAGCEFBAA,159774.72,39484.23,1999.0\r\n+2048,AAAAAAAAAGCEFBAA,39484.23,,2000.0\r\n+2049,AAAAAAAAAGCEFBAA,65468.03,,2002.0\r\n+2050,AAAAAAAAAGCEFBAA,,,\r\n+2051,AAAAAAAAAGCEKAAA,45309.56,249868.00,1998.0\r\n+2052,AAAAAAAAAGCEKAAA,249868.00,76631.91,1999.0\r\n+2053,AAAAAAAAAGCEKAAA,76631.91,220957.60,2000.0\r\n+2054,AAAAAAAAAGCEKAAA,220957.60,161828.78,2001.0\r\n+2055,AAAAAAAAAGCEKAAA,161828.78,,2002.0\r\n+2056,AAAAAAAAAGCEKAAA,10471.73,10471.73,\r\n+2057,AAAAAAAAAGCELBAA,99865.06,73017.47,1998.0\r\n+2058,AAAAAAAAAGCELBAA,73017.47,98211.88,1999.0\r\n+2059,AAAAAAAAAGCELBAA,98211.88,148003.26,2000.0\r\n+2060,AAAAAAAAAGCELBAA,148003.26,,2001.0\r\n+2061,AAAAAAAAAGCELBAA,10559.34,10559.34,\r\n+2062,AAAAAAAAAGCFFAAA,217475.79,53940.34,1998.0\r\n+2063,AAAAAAAAAGCFFAAA,53940.34,166566.94,1999.0\r\n+2064,AAAAAAAAAGCFFAAA,166566.94,133363.17,2000.0\r\n+2065,AAAAAAAAAGCFFAAA,133363.17,81722.77,2001.0\r\n+2066,AAAAAAAAAGCFFAAA,81722.77,,2002.0\r\n+2067,AAAAAAAAAGCFFAAA,,,\r\n+2068,AAAAAAAAAGCHCBAA,88124.19,103552.65,1998.0\r\n+2069,AAAAAAAAAGCHCBAA,103552.65,150367.53,1999.0\r\n+2070,AAAAAAAAAGCHCBAA,150367.53,166600.09,2000.0\r\n+2071,AAAAAAAAAGCHCBAA,166600.09,57931.82,2001.0\r\n+2072,AAAAAAAAAGCHCBAA,57931.82,,2002.0\r\n+2073,AAAAAAAAAGCHCBAA,,,\r\n+2074,AAAAAAAAAGCHMAAA,116391.33,142161.69,1998.0\r\n+2075,AAAAAAAAAGCHMAAA,142161.69,45089.14,1999.0\r\n+2076,AAAAAAAAAGCHMAAA,45089.14,30878.71,2000.0\r\n+2077,AAAAAAAAAGCHMAAA,30878.71,72715.90,2001.0\r\n+2078,AAAAAAAAAGCHMAAA,72715.90,,2002.0\r\n+2079,AAAAAAAAAGCHMAAA,364.84,364.84,\r\n+2080,AAAAAAAAAGCIKAAA,108265.45,216311.73,1998.0\r\n+2081,AAAAAAAAAGCIKAAA,216311.73,168265.34,1999.0\r\n+2082,AAAAAAAAAGCIKAAA,168265.34,80125.02,2000.0\r\n+2083,AAAAAAAAAGCIKAAA,80125.02,25667.75,2001.0\r\n+2084,AAAAAAAAAGCIKAAA,25667.75,,2002.0\r\n+2085,AAAAAAAAAGCIKAAA,4404.94,4404.94,\r\n+2086,AAAAAAAAAGCJAAAA,73636.37,140372.92,1998.0\r\n+2087,AAAAAAAAAGCJAAAA,140372.92,105510.92,1999.0\r\n+2088,AAAAAAAAAGCJAAAA,105510.92,74711.94,2000.0\r\n+2089,AAAAAAAAAGCJAAAA,74711.94,124243.05,2001.0\r\n+2090,AAAAAAAAAGCJAAAA,124243.05,,2002.0\r\n+2091,AAAAAAAAAGCJAAAA,17869.18,17869.18,\r\n+2092,AAAAAAAAAGCJBBAA,22056.25,124994.72,1998.0\r\n+2093,AAAAAAAAAGCJBBAA,124994.72,236373.38,1999.0\r\n+2094,AAAAAAAAAGCJBBAA,236373.38,88282.46,2000.0\r\n+2095,AAAAAAAAAGCJBBAA,88282.46,27874.78,2001.0\r\n+2096,AAAAAAAAAGCJBBAA,27874.78,,2002.0\r\n+2097,AAAAAAAAAGCJBBAA,9382.02,9382.02,\r\n+2098,AAAAAAAAAGCJPAAA,220496.48,88884.45,1998.0\r\n+2099,AAAAAAAAAGCJPAAA,88884.45,132974.17,1999.0\r\n+2100,AAAAAAAAAGCJPAAA,132974.17,43792.33,2000.0\r\n+2101,AAAAAAAAAGCJPAAA,43792.33,133866.61,2001.0\r\n+2102,AAAAAAAAAGCJPAAA,133866.61,,2002.0\r\n+2103,AAAAAAAAAGCJPAAA,10835.81,10835.81,\r\n+2104,AAAAAAAAAGCKBBAA,99740.54,251954.58,1998.0\r\n+2105,AAAAAAAAAGCKBBAA,251954.58,108954.08,1999.0\r\n+2106,AAAAAAAAAGCKBBAA,108954.08,92686.69,2000.0\r\n+2107,AAAAAAAAAGCKBBAA,92686.69,121277.87,2001.0\r\n+2108,AAAAAAAAAGCKBBAA,121277.87,,2002.0\r\n+2109,AAAAAAAAAGCKBBAA,3143.33,3143.33,\r\n+2110,AAAAAAAAAGCKEBAA,127414.34,104413.26,1998.0\r\n+2111,AAAAAAAAAGCKEBAA,104413.26,50850.40,1999.0\r\n+2112,AAAAAAAAAGCKEBAA,50850.40,101782.82,2000.0\r\n+2113,AAAAAAAAAGCKEBAA,101782.82,149717.51,2001.0\r\n+2114,AAAAAAAAAGCKEBAA,149717.51,,2002.0\r\n+2115,AAAAAAAAAGCKEBAA,,,\r\n+2116,AAAAAAAAAGCKGBAA,103394.98,145263.53,1999.0\r\n+2117,AAAAAAAAAGCKGBAA,145263.53,88681.96,2000.0\r\n+2118,AAAAAAAAAGCKGBAA,88681.96,214647.69,2001.0\r\n+2119,AAAAAAAAAGCKGBAA,214647.69,,2002.0\r\n+2120,AAAAAAAAAGCKGBAA,,,\r\n+2121,AAAAAAAAAGCKHAAA,36106.56,87988.73,1999.0\r\n+2122,AAAAAAAAAGCKHAAA,87988.73,,2000.0\r\n+2123,AAAAAAAAAGCKKBAA,102040.96,159072.31,1999.0\r\n+2124,AAAAAAAAAGCKKBAA,159072.31,109888.47,2000.0\r\n+2125,AAAAAAAAAGCKKBAA,109888.47,325882.01,2001.0\r\n+2126,AAAAAAAAAGCKKBAA,325882.01,,2002.0\r\n+2127,AAAAAAAAAGCKKBAA,9641.82,9641.82,\r\n+2128,AAAAAAAAAGCLLAAA,181077.64,,1998.0\r\n+2129,AAAAAAAAAGCLLAAA,96669.44,154303.03,2000.0\r\n+2130,AAAAAAAAAGCLLAAA,154303.03,153360.17,2001.0\r\n+2131,AAAAAAAAAGCLLAAA,153360.17,,2002.0\r\n+2132,AAAAAAAAAGCLLAAA,5080.28,5080.28,\r\n+2133,AAAAAAAAAGCMCAAA,135093.64,117931.37,1998.0\r\n+2134,AAAAAAAAAGCMCAAA,117931.37,186719.04,1999.0\r\n+2135,AAAAAAAAAGCMCAAA,186719.04,,2000.0\r\n+2136,AAAAAAAAAGCMCAAA,219991.97,,2002.0\r\n+2137,AAAAAAAAAGCMCAAA,10884.19,10884.19,\r\n+2138,AAAAAAAAAGCNEAAA,61030.02,39732.71,1998.0\r\n+2139,AAAAAAAAAGCNEAAA,39732.71,124576.97,1999.0\r\n+2140,AAAAAAAAAGCNEAAA,124576.97,46170.01,2000.0\r\n+2141,AAAAAAAAAGCNEAAA,46170.01,45941.13,2001.0\r\n+2142,AAAAAAAAAGCNEAAA,45941.13,23028.22,2002.0\r\n+2143,AAAAAAAAAGCNEAAA,23028.22,,2003.0\r\n+2144,AAAAAAAAAGCNEAAA,132.46,132.46,\r\n+2145,AAAAAAAAAGCOGAAA,34950.51,,1998.0\r\n+2146,AAAAAAAAAGCOGAAA,72014.87,120492.02,2000.0\r\n+2147,AAAAAAAAAGCOGAAA,120492.02,106590.98,2001.0\r\n+2148,AAAAAAAAAGCOGAAA,106590.98,,2002.0\r\n+2149,AAAAAAAAAGCOGAAA,1513.80,1513.80,\r\n+2150,AAAAAAAAAGCOHBAA,128217.29,,1998.0\r\n+2151,AAAAAAAAAGCOHBAA,116184.13,,2000.0\r\n+2152,AAAAAAAAAGCOHBAA,227666.65,,2002.0\r\n+2153,AAAAAAAAAGCOHBAA,,,\r\n+2154,AAAAAAAAAGCOPAAA,79899.49,94449.13,1998.0\r\n+2155,AAAAAAAAAGCOPAAA,94449.13,34165.05,1999.0\r\n+2156,AAAAAAAAAGCOPAAA,34165.05,110782.74,2000.0\r\n+2157,AAAAAAAAAGCOPAAA,110782.74,58945.26,2001.0\r\n+2158,AAAAAAAAAGCOPAAA,58945.26,,2002.0\r\n+2159,AAAAAAAAAGCOPAAA,,,\r\n+2160,AAAAAAAAAGCPBAAA,56997.97,94636.88,1998.0\r\n+2161,AAAAAAAAAGCPBAAA,94636.88,111588.59,1999.0\r\n+2162,AAAAAAAAAGCPBAAA,111588.59,172167.46,2000.0\r\n+2163,AAAAAAAAAGCPBAAA,172167.46,147132.37,2001.0\r\n+2164,AAAAAAAAAGCPBAAA,147132.37,,2002.0\r\n+2165,AAAAAAAAAGCPBAAA,,,\r\n+2166,AAAAAAAAAGCPCBAA,122995.00,29130.46,1998.0\r\n+2167,AAAAAAAAAGCPCBAA,29130.46,56384.07,1999.0\r\n+2168,AAAAAAAAAGCPCBAA,56384.07,99981.88,2000.0\r\n+2169,AAAAAAAAAGCPCBAA,99981.88,239168.64,2001.0\r\n+2170,AAAAAAAAAGCPCBAA,239168.64,,2002.0\r\n+2171,AAAAAAAAAGCPCBAA,5488.26,5488.26,\r\n+2172,AAAAAAAAAGCPEBAA,121175.06,40511.46,1999.0\r\n+2173,AAAAAAAAAGCPEBAA,40511.46,77200.11,2000.0\r\n+2174,AAAAAAAAAGCPEBAA,77200.11,181022.80,2001.0\r\n+2175,AAAAAAAAAGCPEBAA,181022.80,,2002.0\r\n+2176,AAAAAAAAAGDBCBAA,180097.21,128996.67,1998.0\r\n+2177,AAAAAAAAAGDBCBAA,128996.67,203453.00,1999.0\r\n+2178,AAAAAAAAAGDBCBAA,203453.00,73283.06,2000.0\r\n+2179,AAAAAAAAAGDBCBAA,73283.06,85120.93,2001.0\r\n+2180,AAAAAAAAAGDBCBAA,85120.93,,2002.0\r\n+2181,AAAAAAAAAGDBCBAA,,,\r\n+2182,AAAAAAAAAGDBJAAA,174571.35,85911.15,1998.0\r\n+2183,AAAAAAAAAGDBJAAA,85911.15,169833.72,1999.0\r\n+2184,AAAAAAAAAGDBJAAA,169833.72,46935.20,2000.0\r\n+2185,AAAAAAAAAGDBJAAA,46935.20,71528.53,2001.0\r\n+2186,AAAAAAAAAGDBJAAA,71528.53,,2002.0\r\n+2187,AAAAAAAAAGDBJAAA,,,\r\n+2188,AAAAAAAAAGDCABAA,46530.99,64451.20,1998.0\r\n+2189,AAAAAAAAAGDCABAA,64451.20,,1999.0\r\n+2190,AAAAAAAAAGDCABAA,109935.35,67785.33,2001.0\r\n+2191,AAAAAAAAAGDCABAA,67785.33,,2002.0\r\n+2192,AAAAAAAAAGDCABAA,5981.94,5981.94,\r\n+2193,AAAAAAAAAGDCHAAA,52915.52,141915.64,1998.0\r\n+2194,AAAAAAAAAGDCHAAA,141915.64,67184.81,1999.0\r\n+2195,AAAAAAAAAGDCHAAA,67184.81,143672.82,2000.0\r\n+2196,AAAAAAAAAGDCHAAA,143672.82,106840.27,2001.0\r\n+2197,AAAAAAAAAGDCHAAA,106840.27,,2002.0\r\n+2198,AAAAAAAAAGDCHAAA,5937.90,5937.90,\r\n+2199,AAAAAAAAAGDDABAA,69449.66,155344.06,1998.0\r\n+2200,AAAAAAAAAGDDABAA,155344.06,184258.72,1999.0\r\n+2201,AAAAAAAAAGDDABAA,184258.72,141436.44,2000.0\r\n+2202,AAAAAAAAAGDDABAA,141436.44,,2001.0\r\n+2203,AAAAAAAAAGDDABAA,23770.68,23770.68,\r\n+2204,AAAAAAAAAGDDGAAA,381265.80,23212.47,1998.0\r\n+2205,AAAAAAAAAGDDGAAA,23212.47,,1999.0\r\n+2206,AAAAAAAAAGDDGAAA,88992.07,87948.02,2001.0\r\n+2207,AAAAAAAAAGDDGAAA,87948.02,,2002.0\r\n+2208,AAAAAAAAAGDDGAAA,1970.43,1970.43,\r\n+2209,AAAAAAAAAGDEFAAA,77660.78,36447.07,1998.0\r\n+2210,AAAAAAAAAGDEFAAA,36447.07,122622.96,1999.0\r\n+2211,AAAAAAAAAGDEFAAA,122622.96,47515.88,2000.0\r\n+2212,AAAAAAAAAGDEFAAA,47515.88,19419.42,2001.0\r\n+2213,AAAAAAAAAGDEFAAA,19419.42,,2002.0\r\n+2214,AAAAAAAAAGDEFAAA,581.58,581.58,\r\n+2215,AAAAAAAAAGDEKBAA,121435.92,,1998.0\r\n+2216,AAAAAAAAAGDEKBAA,76388.15,99206.06,2000.0\r\n+2217,AAAAAAAAAGDEKBAA,99206.06,260142.44,2001.0\r\n+2218,AAAAAAAAAGDEKBAA,260142.44,,2002.0\r\n+2219,AAAAAAAAAGDEKBAA,4672.50,4672.50,\r\n+2220,AAAAAAAAAGDFGAAA,200815.81,42815.09,1998.0\r\n+2221,AAAAAAAAAGDFGAAA,42815.09,186159.77,1999.0\r\n+2222,AAAAAAAAAGDFGAAA,186159.77,31035.23,2000.0\r\n+2223,AAAAAAAAAGDFGAAA,31035.23,40747.58,2001.0\r\n+2224,AAAAAAAAAGDFGAAA,40747.58,,2002.0\r\n+2225,AAAAAAAAAGDFGAAA,4528.68,4528.68,\r\n+2226,AAAAAAAAAGDGFBAA,97038.10,,1998.0\r\n+2227,AAAAAAAAAGDGFBAA,26946.51,80459.04,2000.0\r\n+2228,AAAAAAAAAGDGFBAA,80459.04,146963.59,2001.0\r\n+2229,AAAAAAAAAGDGFBAA,146963.59,,2002.0\r\n+2230,AAAAAAAAAGDGFBAA,,,\r\n+2231,AAAAAAAAAGDHABAA,87930.78,215569.56,1998.0\r\n+2232,AAAAAAAAAGDHABAA,215569.56,85884.20,1999.0\r\n+2233,AAAAAAAAAGDHABAA,85884.20,123874.28,2000.0\r\n+2234,AAAAAAAAAGDHABAA,123874.28,137355.52,2001.0\r\n+2235,AAAAAAAAAGDHABAA,137355.52,,2002.0\r\n+2236,AAAAAAAAAGDHABAA,9277.06,9277.06,\r\n+2237,AAAAAAAAAGDHFBAA,110418.27,109059.38,1998.0\r\n+2238,AAAAAAAAAGDHFBAA,109059.38,120085.77,1999.0\r\n+2239,AAAAAAAAAGDHFBAA,120085.77,113137.32,2000.0\r\n+2240,AAAAAAAAAGDHFBAA,113137.32,185035.83,2001.0\r\n+2241,AAAAAAAAAGDHFBAA,185035.83,,2002.0\r\n+2242,AAAAAAAAAGDHFBAA,900.55,900.55,\r\n+2243,AAAAAAAAAGDIIAAA,63549.69,32940.37,1999.0\r\n+2244,AAAAAAAAAGDIIAAA,32940.37,33680.57,2000.0\r\n+2245,AAAAAAAAAGDIIAAA,33680.57,118517.33,2001.0\r\n+2246,AAAAAAAAAGDIIAAA,118517.33,,2002.0\r\n+2247,AAAAAAAAAGDIIAAA,,,\r\n+2248,AAAAAAAAAGDILAAA,91220.59,37478.39,1998.0\r\n+2249,AAAAAAAAAGDILAAA,37478.39,98850.03,1999.0\r\n+2250,AAAAAAAAAGDILAAA,98850.03,107737.31,2000.0\r\n+2251,AAAAAAAAAGDILAAA,107737.31,188701.72,2001.0\r\n+2252,AAAAAAAAAGDILAAA,188701.72,,2002.0\r\n+2253,AAAAAAAAAGDILAAA,,,\r\n+2254,AAAAAAAAAGDJABAA,55920.95,61372.15,1998.0\r\n+2255,AAAAAAAAAGDJABAA,61372.15,145177.89,1999.0\r\n+2256,AAAAAAAAAGDJABAA,145177.89,86416.67,2000.0\r\n+2257,AAAAAAAAAGDJABAA,86416.67,54814.49,2001.0\r\n+2258,AAAAAAAAAGDJABAA,54814.49,,2002.0\r\n+2259,AAAAAAAAAGDJABAA,7650.22,7650.22,\r\n+2260,AAAAAAAAAGDJBAAA,71639.60,11422.27,1998.0\r\n+2261,AAAAAAAAAGDJBAAA,11422.27,64267.69,1999.0\r\n+2262,AAAAAAAAAGDJBAAA,64267.69,205840.93,2000.0\r\n+2263,AAAAAAAAAGDJBAAA,205840.93,181529.97,2001.0\r\n+2264,AAAAAAAAAGDJBAAA,181529.97,,2002.0\r\n+2265,AAAAAAAAAGDJBAAA,17827.52,17827.52,\r\n+2266,AAAAAAAAAGDKCBAA,158713.69,343362.10,1998.0\r\n+2267,AAAAAAAAAGDKCBAA,343362.10,154967.62,1999.0\r\n+2268,AAAAAAAAAGDKCBAA,154967.62,96176.14,2000.0\r\n+2269,AAAAAAAAAGDKCBAA,96176.14,94569.69,2001.0\r\n+2270,AAAAAAAAAGDKCBAA,94569.69,,2002.0\r\n+2271,AAAAAAAAAGDKCBAA,14169.99,14169.99,\r\n+2272,AAAAAAAAAGDKLAAA,213079.66,85196.46,1998.0\r\n+2273,AAAAAAAAAGDKLAAA,85196.46,,1999.0\r\n+2274,AAAAAAAAAGDKLAAA,232530.31,162568.68,2001.0\r\n+2275,AAAAAAAAAGDKLAAA,162568.68,,2002.0\r\n+2276,AAAAAAAAAGDKLAAA,782.46,782.46,\r\n+2277,AAAAAAAAAGDLNBAA,61953.70,18160.40,1998.0\r\n+2278,AAAAAAAAAGDLNBAA,18160.40,143068.35,1999.0\r\n+2279,AAAAAAAAAGDLNBAA,143068.35,154554.16,2000.0\r\n+2280,AAAAAAAAAGDLNBAA,154554.16,80234.31,2001.0\r\n+2281,AAAAAAAAAGDLNBAA,80234.31,,2002.0\r\n+2282,AAAAAAAAAGDLNBAA,,,\r\n+2283,AAAAAAAAAGDMCAAA,184307.96,,1999.0\r\n+2284,AAAAAAAAAGDMCAAA,31014.41,45527.60,2001.0\r\n+2285,AAAAAAAAAGDMCAAA,45527.60,,2002.0\r\n+2286,AAAAAAAAAGDMCAAA,2611.20,2611.20,\r\n+2287,AAAAAAAAAGDMFAAA,80425.48,50053.11,1998.0\r\n+2288,AAAAAAAAAGDMFAAA,50053.11,32351.85,1999.0\r\n+2289,AAAAAAAAAGDMFAAA,32351.85,50174.22,2000.0\r\n+2290,AAAAAAAAAGDMFAAA,50174.22,71435.32,2001.0\r\n+2291,AAAAAAAAAGDMFAAA,71435.32,,2002.0\r\n+2292,AAAAAAAAAGDMFAAA,54.14,54.14,\r\n+2293,AAAAAAAAAGDNMAAA,78888.80,42447.96,1998.0\r\n+2294,AAAAAAAAAGDNMAAA,42447.96,94746.66,1999.0\r\n+2295,AAAAAAAAAGDNMAAA,94746.66,22017.32,2000.0\r\n+2296,AAAAAAAAAGDNMAAA,22017.32,137672.33,2001.0\r\n+2297,AAAAAAAAAGDNMAAA,137672.33,,2002.0\r\n+2298,AAAAAAAAAGDNMAAA,,,\r\n+2299,AAAAAAAAAGDOCAAA,100590.74,129011.51,1998.0\r\n+2300,AAAAAAAAAGDOCAAA,129011.51,207547.09,1999.0\r\n+2301,AAAAAAAAAGDOCAAA,207547.09,121526.63,2000.0\r\n+2302,AAAAAAAAAGDOCAAA,121526.63,88149.58,2001.0\r\n+2303,AAAAAAAAAGDOCAAA,88149.58,,2002.0\r\n+2304,AAAAAAAAAGDOCAAA,8191.85,8191.85,\r\n+2305,AAAAAAAAAGDONBAA,98348.40,116248.87,1998.0\r\n+2306,AAAAAAAAAGDONBAA,116248.87,38491.20,1999.0\r\n+2307,AAAAAAAAAGDONBAA,38491.20,93173.97,2000.0\r\n+2308,AAAAAAAAAGDONBAA,93173.97,78811.28,2001.0\r\n+2309,AAAAAAAAAGDONBAA,78811.28,,2002.0\r\n+2310,AAAAAAAAAGDONBAA,,,\r\n+2311,AAAAAAAAAGDPCAAA,157828.09,82829.52,1998.0\r\n+2312,AAAAAAAAAGDPCAAA,82829.52,79335.53,1999.0\r\n+2313,AAAAAAAAAGDPCAAA,79335.53,,2000.0\r\n+2314,AAAAAAAAAGDPCAAA,84298.17,,2002.0\r\n+2315,AAAAAAAAAGDPCAAA,,,\r\n+2316,AAAAAAAAAGDPHAAA,100744.90,66705.33,1998.0\r\n+2317,AAAAAAAAAGDPHAAA,66705.33,120183.89,1999.0\r\n+2318,AAAAAAAAAGDPHAAA,120183.89,42176.78,2000.0\r\n+2319,AAAAAAAAAGDPHAAA,42176.78,76310.07,2001.0\r\n+2320,AAAAAAAAAGDPHAAA,76310.07,,2002.0\r\n+2321,AAAAAAAAAGDPHAAA,870.29,870.29,\r\n+2322,AAAAAAAAAGEACAAA,81187.91,85933.23,1998.0\r\n+2323,AAAAAAAAAGEACAAA,85933.23,54919.23,1999.0\r\n+2324,AAAAAAAAAGEACAAA,54919.23,256684.83,2000.0\r\n+2325,AAAAAAAAAGEACAAA,256684.83,55899.81,2001.0\r\n+2326,AAAAAAAAAGEACAAA,55899.81,,2002.0\r\n+2327,AAAAAAAAAGEACAAA,,,\r\n+2328,AAAAAAAAAGEAIAAA,20645.70,110210.80,1998.0\r\n+2329,AAAAAAAAAGEAIAAA,110210.80,97028.73,1999.0\r\n+2330,AAAAAAAAAGEAIAAA,97028.73,35374.68,2000.0\r\n+2331,AAAAAAAAAGEAIAAA,35374.68,133154.16,2001.0\r\n+2332,AAAAAAAAAGEAIAAA,133154.16,,2002.0\r\n+2333,AAAAAAAAAGEAIAAA,9163.13,9163.13,\r\n+2334,AAAAAAAAAGEAOBAA,79271.85,52794.57,1998.0\r\n+2335,AAAAAAAAAGEAOBAA,52794.57,104673.60,1999.0\r\n+2336,AAAAAAAAAGEAOBAA,104673.60,191514.54,2000.0\r\n+2337,AAAAAAAAAGEAOBAA,191514.54,75298.56,2001.0\r\n+2338,AAAAAAAAAGEAOBAA,75298.56,,2002.0\r\n+2339,AAAAAAAAAGEAOBAA,10956.40,10956.40,\r\n+2340,AAAAAAAAAGEBEAAA,28737.51,217270.45,1998.0\r\n+2341,AAAAAAAAAGEBEAAA,217270.45,70805.60,1999.0\r\n+2342,AAAAAAAAAGEBEAAA,70805.60,102291.05,2000.0\r\n+2343,AAAAAAAAAGEBEAAA,102291.05,,2001.0\r\n+2344,AAAAAAAAAGEBEAAA,11165.14,11165.14,\r\n+2345,AAAAAAAAAGEBHBAA,156310.66,117189.06,1998.0\r\n+2346,AAAAAAAAAGEBHBAA,117189.06,153110.03,1999.0\r\n+2347,AAAAAAAAAGEBHBAA,153110.03,26688.99,2000.0\r\n+2348,AAAAAAAAAGEBHBAA,26688.99,68807.36,2001.0\r\n+2349,AAAAAAAAAGEBHBAA,68807.36,,2002.0\r\n+2350,AAAAAAAAAGEBHBAA,6668.80,6668.80,\r\n+2351,AAAAAAAAAGECHBAA,86210.56,43371.26,1998.0\r\n+2352,AAAAAAAAAGECHBAA,43371.26,,1999.0\r\n+2353,AAAAAAAAAGECHBAA,172629.21,77519.65,2001.0\r\n+2354,AAAAAAAAAGECHBAA,77519.65,,2002.0\r\n+2355,AAAAAAAAAGECHBAA,,,\r\n+2356,AAAAAAAAAGECLBAA,122059.65,34756.34,1998.0\r\n+2357,AAAAAAAAAGECLBAA,34756.34,138456.04,1999.0\r\n+2358,AAAAAAAAAGECLBAA,138456.04,179495.42,2000.0\r\n+2359,AAAAAAAAAGECLBAA,179495.42,259821.81,2001.0\r\n+2360,AAAAAAAAAGECLBAA,259821.81,,2002.0\r\n+2361,AAAAAAAAAGECLBAA,15084.65,15084.65,\r\n+2362,AAAAAAAAAGEDEAAA,94256.92,,1998.0\r\n+2363,AAAAAAAAAGEDEAAA,98677.58,144116.38,2000.0\r\n+2364,AAAAAAAAAGEDEAAA,144116.38,47060.64,2001.0\r\n+2365,AAAAAAAAAGEDEAAA,47060.64,,2002.0\r\n+2366,AAAAAAAAAGEDEAAA,5109.00,5109.00,\r\n+2367,AAAAAAAAAGEDJBAA,30139.39,30608.10,1998.0\r\n+2368,AAAAAAAAAGEDJBAA,30608.10,91157.01,1999.0\r\n+2369,AAAAAAAAAGEDJBAA,91157.01,21344.97,2000.0\r\n+2370,AAAAAAAAAGEDJBAA,21344.97,171427.92,2001.0\r\n+2371,AAAAAAAAAGEDJBAA,171427.92,,2002.0\r\n+2372,AAAAAAAAAGEDJBAA,12895.88,12895.88,\r\n+2373,AAAAAAAAAGEDOBAA,73961.14,67794.12,1998.0\r\n+2374,AAAAAAAAAGEDOBAA,67794.12,110757.01,1999.0\r\n+2375,AAAAAAAAAGEDOBAA,110757.01,170328.80,2000.0\r\n+2376,AAAAAAAAAGEDOBAA,170328.80,66117.65,2001.0\r\n+2377,AAAAAAAAAGEDOBAA,66117.65,,2002.0\r\n+2378,AAAAAAAAAGEDOBAA,,,\r\n+2379,AAAAAAAAAGEEFAAA,166649.69,80191.33,1998.0\r\n+2380,AAAAAAAAAGEEFAAA,80191.33,,1999.0\r\n+2381,AAAAAAAAAGEEFAAA,29927.78,23607.92,2001.0\r\n+2382,AAAAAAAAAGEEFAAA,23607.92,,2002.0\r\n+2383,AAAAAAAAAGEEFAAA,,,\r\n+2384,AAAAAAAAAGEEHBAA,165182.78,112640.90,1998.0\r\n+2385,AAAAAAAAAGEEHBAA,112640.90,158722.96,1999.0\r\n+2386,AAAAAAAAAGEEHBAA,158722.96,52757.86,2000.0\r\n+2387,AAAAAAAAAGEEHBAA,52757.86,120828.68,2001.0\r\n+2388,AAAAAAAAAGEEHBAA,120828.68,,2002.0\r\n+2389,AAAAAAAAAGEEHBAA,5463.12,5463.12,\r\n+2390,AAAAAAAAAGEEKBAA,109889.26,122854.59,1998.0\r\n+2391,AAAAAAAAAGEEKBAA,122854.59,,1999.0\r\n+2392,AAAAAAAAAGEEKBAA,95207.48,,2002.0\r\n+2393,AAAAAAAAAGEEKBAA,4883.10,4883.10,\r\n+2394,AAAAAAAAAGEFEBAA,51157.62,38735.14,1998.0\r\n+2395,AAAAAAAAAGEFEBAA,38735.14,113493.04,1999.0\r\n+2396,AAAAAAAAAGEFEBAA,113493.04,,2000.0\r\n+2397,AAAAAAAAAGEFEBAA,183417.33,,2002.0\r\n+2398,AAAAAAAAAGEFEBAA,37.61,37.61,\r\n+2399,AAAAAAAAAGEHBAAA,111324.13,260062.03,1998.0\r\n+2400,AAAAAAAAAGEHBAAA,260062.03,35939.65,1999.0\r\n+2401,AAAAAAAAAGEHBAAA,35939.65,49822.13,2000.0\r\n+2402,AAAAAAAAAGEHBAAA,49822.13,84503.34,2001.0\r\n+2403,AAAAAAAAAGEHBAAA,84503.34,,2002.0\r\n+2404,AAAAAAAAAGEHBAAA,9334.01,9334.01,\r\n+2405,AAAAAAAAAGEHKAAA,233018.73,159579.15,1998.0\r\n+2406,AAAAAAAAAGEHKAAA,159579.15,130897.20,1999.0\r\n+2407,AAAAAAAAAGEHKAAA,130897.20,109498.46,2000.0\r\n+2408,AAAAAAAAAGEHKAAA,109498.46,55717.36,2001.0\r\n+2409,AAAAAAAAAGEHKAAA,55717.36,,2002.0\r\n+2410,AAAAAAAAAGEHKAAA,224.30,224.30,\r\n+2411,AAAAAAAAAGEIEAAA,165814.09,49414.61,1998.0\r\n+2412,AAAAAAAAAGEIEAAA,49414.61,145933.47,1999.0\r\n+2413,AAAAAAAAAGEIEAAA,145933.47,156952.07,2000.0\r\n+2414,AAAAAAAAAGEIEAAA,156952.07,170665.14,2001.0\r\n+2415,AAAAAAAAAGEIEAAA,170665.14,,2002.0\r\n+2416,AAAAAAAAAGEIEAAA,,,\r\n+2417,AAAAAAAAAGEIIBAA,215307.24,100818.89,1998.0\r\n+2418,AAAAAAAAAGEIIBAA,100818.89,,1999.0\r\n+2419,AAAAAAAAAGEIIBAA,37440.94,136716.98,2001.0\r\n+2420,AAAAAAAAAGEIIBAA,136716.98,,2002.0\r\n+2421,AAAAAAAAAGEIIBAA,,,\r\n+2422,AAAAAAAAAGEJCBAA,30632.40,,1998.0\r\n+2423,AAAAAAAAAGEJCBAA,140892.98,139093.87,2000.0\r\n+2424,AAAAAAAAAGEJCBAA,139093.87,79600.70,2001.0\r\n+2425,AAAAAAAAAGEJCBAA,79600.70,,2002.0\r\n+2426,AAAAAAAAAGEJCBAA,3724.53,3724.53,\r\n+2427,AAAAAAAAAGEKEBAA,98429.47,44432.92,1998.0\r\n+2428,AAAAAAAAAGEKEBAA,44432.92,60723.82,1999.0\r\n+2429,AAAAAAAAAGEKEBAA,60723.82,78340.58,2000.0\r\n+2430,AAAAAAAAAGEKEBAA,78340.58,129129.27,2001.0\r\n+2431,AAAAAAAAAGEKEBAA,129129.27,,2002.0\r\n+2432,AAAAAAAAAGEKEBAA,,,\r\n+2433,AAAAAAAAAGELABAA,232330.01,182403.05,1998.0\r\n+2434,AAAAAAAAAGELABAA,182403.05,102371.20,1999.0\r\n+2435,AAAAAAAAAGELABAA,102371.20,94565.26,2000.0\r\n+2436,AAAAAAAAAGELABAA,94565.26,107100.78,2001.0\r\n+2437,AAAAAAAAAGELABAA,107100.78,,2002.0\r\n+2438,AAAAAAAAAGELABAA,1068.18,1068.18,\r\n+2439,AAAAAAAAAGELBAAA,342542.21,122172.96,1998.0\r\n+2440,AAAAAAAAAGELBAAA,122172.96,40831.40,1999.0\r\n+2441,AAAAAAAAAGELBAAA,40831.40,106123.93,2000.0\r\n+2442,AAAAAAAAAGELBAAA,106123.93,,2001.0\r\n+2443,AAAAAAAAAGELBAAA,,,\r\n+2444,AAAAAAAAAGELHAAA,170141.89,131200.12,1999.0\r\n+2445,AAAAAAAAAGELHAAA,131200.12,131908.85,2000.0\r\n+2446,AAAAAAAAAGELHAAA,131908.85,131587.07,2001.0\r\n+2447,AAAAAAAAAGELHAAA,131587.07,,2002.0\r\n+2448,AAAAAAAAAGELHAAA,6243.00,6243.00,\r\n+2449,AAAAAAAAAGENOAAA,189098.37,41226.24,1999.0\r\n+2450,AAAAAAAAAGENOAAA,41226.24,145831.47,2000.0\r\n+2451,AAAAAAAAAGENOAAA,145831.47,96631.29,2001.0\r\n+2452,AAAAAAAAAGENOAAA,96631.29,,2002.0\r\n+2453,AAAAAAAAAGENOAAA,,,\r\n+2454,AAAAAAAAAGEOKAAA,143892.41,56378.11,1998.0\r\n+2455,AAAAAAAAAGEOKAAA,56378.11,34671.89,1999.0\r\n+2456,AAAAAAAAAGEOKAAA,34671.89,154619.05,2000.0\r\n+2457,AAAAAAAAAGEOKAAA,154619.05,,2001.0\r\n+2458,AAAAAAAAAGEOKAAA,14224.49,14224.49,\r\n+2459,AAAAAAAAAGEPABAA,112359.92,40879.45,1998.0\r\n+2460,AAAAAAAAAGEPABAA,40879.45,118359.03,1999.0\r\n+2461,AAAAAAAAAGEPABAA,118359.03,111831.89,2000.0\r\n+2462,AAAAAAAAAGEPABAA,111831.89,175413.47,2001.0\r\n+2463,AAAAAAAAAGEPABAA,175413.47,,2002.0\r\n+2464,AAAAAAAAAGEPABAA,1048.42,1048.42,\r\n+2465,AAAAAAAAAGEPGAAA,44084.29,54525.20,1998.0\r\n+2466,AAAAAAAAAGEPGAAA,54525.20,59206.31,1999.0\r\n+2467,AAAAAAAAAGEPGAAA,59206.31,30627.87,2000.0\r\n+2468,AAAAAAAAAGEPGAAA,30627.87,156741.47,2001.0\r\n+2469,AAAAAAAAAGEPGAAA,156741.47,,2002.0\r\n+2470,AAAAAAAAAGEPMAAA,140005.51,100389.38,1999.0\r\n+2471,AAAAAAAAAGEPMAAA,100389.38,56662.53,2000.0\r\n+2472,AAAAAAAAAGEPMAAA,56662.53,34245.32,2001.0\r\n+2473,AAAAAAAAAGEPMAAA,34245.32,,2002.0\r\n+2474,AAAAAAAAAGEPMAAA,598.11,598.11,\r\n+2475,AAAAAAAAAGEPNBAA,28070.70,78157.20,1998.0\r\n+2476,AAAAAAAAAGEPNBAA,78157.20,75095.94,1999.0\r\n+2477,AAAAAAAAAGEPNBAA,75095.94,127766.78,2000.0\r\n+2478,AAAAAAAAAGEPNBAA,127766.78,220875.90,2001.0\r\n+2479,AAAAAAAAAGEPNBAA,220875.90,,2002.0\r\n+2480,AAAAAAAAAGEPNBAA,5958.72,5958.72,\r\n+2481,AAAAAAAAAGFAHAAA,40001.43,21018.77,1998.0\r\n+2482,AAAAAAAAAGFAHAAA,21018.77,90765.43,1999.0\r\n+2483,AAAAAAAAAGFAHAAA,90765.43,52579.40,2000.0\r\n+2484,AAAAAAAAAGFAHAAA,52579.40,22772.13,2001.0\r\n+2485,AAAAAAAAAGFAHAAA,22772.13,28678.18,2002.0\r\n+2486,AAAAAAAAAGFAHAAA,28678.18,,2003.0\r\n+2487,AAAAAAAAAGFAHAAA,,,\r\n+2488,AAAAAAAAAGFAIAAA,44460.80,129609.05,1998.0\r\n+2489,AAAAAAAAAGFAIAAA,129609.05,153053.31,1999.0\r\n+2490,AAAAAAAAAGFAIAAA,153053.31,,2000.0\r\n+2491,AAAAAAAAAGFAIAAA,80852.08,,2002.0\r\n+2492,AAAAAAAAAGFALBAA,22789.48,48596.17,1998.0\r\n+2493,AAAAAAAAAGFALBAA,48596.17,163610.28,1999.0\r\n+2494,AAAAAAAAAGFALBAA,163610.28,140967.71,2000.0\r\n+2495,AAAAAAAAAGFALBAA,140967.71,96592.31,2001.0\r\n+2496,AAAAAAAAAGFALBAA,96592.31,37047.98,2002.0\r\n+2497,AAAAAAAAAGFALBAA,37047.98,,2003.0\r\n+2498,AAAAAAAAAGFALBAA,9005.22,9005.22,\r\n+2499,AAAAAAAAAGFBKBAA,207271.21,32190.26,1998.0\r\n+2500,AAAAAAAAAGFBKBAA,32190.26,26404.92,1999.0\r\n+2501,AAAAAAAAAGFBKBAA,26404.92,125349.05,2000.0\r\n+2502,AAAAAAAAAGFBKBAA,125349.05,,2001.0\r\n+2503,AAAAAAAAAGFBKBAA,12134.45,12134.45,\r\n+2504,AAAAAAAAAGFCJBAA,268485.91,82397.76,1998.0\r\n+2505,AAAAAAAAAGFCJBAA,82397.76,33833.07,1999.0\r\n+2506,AAAAAAAAAGFCJBAA,33833.07,126748.33,2000.0\r\n+2507,AAAAAAAAAGFCJBAA,126748.33,,2001.0\r\n+2508,AAAAAAAAAGFCJBAA,,,\r\n+2509,AAAAAAAAAGFDFAAA,32206.31,24020.05,1998.0\r\n+2510,AAAAAAAAAGFDFAAA,24020.05,35151.70,1999.0\r\n+2511,AAAAAAAAAGFDFAAA,35151.70,38923.25,2000.0\r\n+2512,AAAAAAAAAGFDFAAA,38923.25,70314.35,2001.0\r\n+2513,AAAAAAAAAGFDFAAA,70314.35,,2002.0\r\n+2514,AAAAAAAAAGFDIBAA,100700.25,36425.56,1998.0\r\n+2515,AAAAAAAAAGFDIBAA,36425.56,90719.09,1999.0\r\n+2516,AAAAAAAAAGFDIBAA,90719.09,86843.46,2000.0\r\n+2517,AAAAAAAAAGFDIBAA,86843.46,112798.06,2001.0\r\n+2518,AAAAAAAAAGFDIBAA,112798.06,17375.20,2002.0\r\n+2519,AAAAAAAAAGFDIBAA,17375.20,,2003.0\r\n+2520,AAAAAAAAAGFDIBAA,3098.00,3098.00,\r\n+2521,AAAAAAAAAGFFGAAA,65028.90,101388.62,1998.0\r\n+2522,AAAAAAAAAGFFGAAA,101388.62,89892.23,1999.0\r\n+2523,AAAAAAAAAGFFGAAA,89892.23,127943.32,2000.0\r\n+2524,AAAAAAAAAGFFGAAA,127943.32,20951.92,2001.0\r\n+2525,AAAAAAAAAGFFGAAA,20951.92,,2002.0\r\n+2526,AAAAAAAAAGFFGAAA,7200.96,7200.96,\r\n+2527,AAAAAAAAAGFFLBAA,25379.17,183972.63,1998.0\r\n+2528,AAAAAAAAAGFFLBAA,183972.63,110681.72,1999.0\r\n+2529,AAAAAAAAAGFFLBAA,110681.72,159748.09,2000.0\r\n+2530,AAAAAAAAAGFFLBAA,159748.09,174387.70,2001.0\r\n+2531,AAAAAAAAAGFFLBAA,174387.70,,2002.0\r\n+2532,AAAAAAAAAGFFLBAA,10634.83,10634.83,\r\n+2533,AAAAAAAAAGFFMAAA,80229.13,103394.70,1998.0\r\n+2534,AAAAAAAAAGFFMAAA,103394.70,134160.66,1999.0\r\n+2535,AAAAAAAAAGFFMAAA,134160.66,,2000.0\r\n+2536,AAAAAAAAAGFFMAAA,89703.06,,2002.0\r\n+2537,AAAAAAAAAGFFMAAA,,,\r\n+2538,AAAAAAAAAGFGGAAA,191364.73,,1998.0\r\n+2539,AAAAAAAAAGFGGAAA,83204.16,112690.58,2000.0\r\n+2540,AAAAAAAAAGFGGAAA,112690.58,89764.98,2001.0\r\n+2541,AAAAAAAAAGFGGAAA,89764.98,,2002.0\r\n+2542,AAAAAAAAAGFGGAAA,6760.50,6760.50,\r\n+2543,AAAAAAAAAGFGPAAA,218983.41,134482.92,1998.0\r\n+2544,AAAAAAAAAGFGPAAA,134482.92,91970.72,1999.0\r\n+2545,AAAAAAAAAGFGPAAA,91970.72,45161.55,2000.0\r\n+2546,AAAAAAAAAGFGPAAA,45161.55,41849.25,2001.0\r\n+2547,AAAAAAAAAGFGPAAA,41849.25,,2002.0\r\n+2548,AAAAAAAAAGFGPAAA,9927.34,9927.34,\r\n+2549,AAAAAAAAAGFHDBAA,43939.25,95848.38,1998.0\r\n+2550,AAAAAAAAAGFHDBAA,95848.38,145531.20,1999.0\r\n+2551,AAAAAAAAAGFHDBAA,145531.20,82722.00,2000.0\r\n+2552,AAAAAAAAAGFHDBAA,82722.00,88712.56,2001.0\r\n+2553,AAAAAAAAAGFHDBAA,88712.56,,2002.0\r\n+2554,AAAAAAAAAGFHPAAA,63021.02,29061.85,1999.0\r\n+2555,AAAAAAAAAGFHPAAA,29061.85,98828.36,2000.0\r\n+2556,AAAAAAAAAGFHPAAA,98828.36,129507.53,2001.0\r\n+2557,AAAAAAAAAGFHPAAA,129507.53,,2002.0\r\n+2558,AAAAAAAAAGFHPAAA,,,\r\n+2559,AAAAAAAAAGFIPAAA,43048.66,,1998.0\r\n+2560,AAAAAAAAAGFIPAAA,128924.79,50031.25,2000.0\r\n+2561,AAAAAAAAAGFIPAAA,50031.25,128349.64,2001.0\r\n+2562,AAAAAAAAAGFIPAAA,128349.64,,2002.0\r\n+2563,AAAAAAAAAGFIPAAA,,,\r\n+2564,AAAAAAAAAGFJFAAA,122448.41,144186.07,1998.0\r\n+2565,AAAAAAAAAGFJFAAA,144186.07,72087.62,1999.0\r\n+2566,AAAAAAAAAGFJFAAA,72087.62,104795.70,2000.0\r\n+2567,AAAAAAAAAGFJFAAA,104795.70,50321.04,2001.0\r\n+2568,AAAAAAAAAGFJFAAA,50321.04,,2002.0\r\n+2569,AAAAAAAAAGFJFAAA,624.41,624.41,\r\n+2570,AAAAAAAAAGFKDBAA,64370.74,40343.70,1998.0\r\n+2571,AAAAAAAAAGFKDBAA,40343.70,38955.79,1999.0\r\n+2572,AAAAAAAAAGFKDBAA,38955.79,156438.52,2000.0\r\n+2573,AAAAAAAAAGFKDBAA,156438.52,115524.20,2001.0\r\n+2574,AAAAAAAAAGFKDBAA,115524.20,,2002.0\r\n+2575,AAAAAAAAAGFLBAAA,81057.93,225513.80,1998.0\r\n+2576,AAAAAAAAAGFLBAAA,225513.80,79376.14,1999.0\r\n+2577,AAAAAAAAAGFLBAAA,79376.14,57402.61,2000.0\r\n+2578,AAAAAAAAAGFLBAAA,57402.61,195949.98,2001.0\r\n+2579,AAAAAAAAAGFLBAAA,195949.98,,2002.0\r\n+2580,AAAAAAAAAGFLBAAA,42.64,42.64,\r\n+2581,AAAAAAAAAGFMFAAA,47548.58,206781.57,1998.0\r\n+2582,AAAAAAAAAGFMFAAA,206781.57,149287.03,1999.0\r\n+2583,AAAAAAAAAGFMFAAA,149287.03,95817.77,2000.0\r\n+2584,AAAAAAAAAGFMFAAA,95817.77,117200.08,2001.0\r\n+2585,AAAAAAAAAGFMFAAA,117200.08,,2002.0\r\n+2586,AAAAAAAAAGFMFAAA,257.55,257.55,\r\n+2587,AAAAAAAAAGFNMAAA,135015.33,200818.03,1998.0\r\n+2588,AAAAAAAAAGFNMAAA,200818.03,44247.79,1999.0\r\n+2589,AAAAAAAAAGFNMAAA,44247.79,251651.03,2000.0\r\n+2590,AAAAAAAAAGFNMAAA,251651.03,48365.49,2001.0\r\n+2591,AAAAAAAAAGFNMAAA,48365.49,,2002.0\r\n+2592,AAAAAAAAAGFNMAAA,10934.19,10934.19,\r\n+2593,AAAAAAAAAGFOGAAA,66592.93,76005.97,1998.0\r\n+2594,AAAAAAAAAGFOGAAA,76005.97,250591.82,1999.0\r\n+2595,AAAAAAAAAGFOGAAA,250591.82,143678.96,2000.0\r\n+2596,AAAAAAAAAGFOGAAA,143678.96,141298.96,2001.0\r\n+2597,AAAAAAAAAGFOGAAA,141298.96,,2002.0\r\n+2598,AAAAAAAAAGFOGAAA,16624.55,16624.55,\r\n+2599,AAAAAAAAAGFOHBAA,67164.97,36741.72,1998.0\r\n+2600,AAAAAAAAAGFOHBAA,36741.72,208774.26,1999.0\r\n+2601,AAAAAAAAAGFOHBAA,208774.26,115062.97,2000.0\r\n+2602,AAAAAAAAAGFOHBAA,115062.97,24057.05,2001.0\r\n+2603,AAAAAAAAAGFOHBAA,24057.05,,2002.0\r\n+2604,AAAAAAAAAGFOHBAA,4094.99,4094.99,\r\n+2605,AAAAAAAAAGFPDAAA,73230.12,121386.18,1999.0\r\n+2606,AAAAAAAAAGFPDAAA,121386.18,55113.92,2000.0\r\n+2607,AAAAAAAAAGFPDAAA,55113.92,136370.16,2001.0\r\n+2608,AAAAAAAAAGFPDAAA,136370.16,,2002.0\r\n+2609,AAAAAAAAAGFPDAAA,9970.96,9970.96,\r\n+2610,AAAAAAAAAGFPGAAA,130577.63,171784.88,1998.0\r\n+2611,AAAAAAAAAGFPGAAA,171784.88,42744.42,1999.0\r\n+2612,AAAAAAAAAGFPGAAA,42744.42,112064.17,2000.0\r\n+2613,AAAAAAAAAGFPGAAA,112064.17,168793.77,2001.0\r\n+2614,AAAAAAAAAGFPGAAA,168793.77,,2002.0\r\n+2615,AAAAAAAAAGFPGAAA,1209.12,1209.12,\r\n+2616,AAAAAAAAAGFPHBAA,83681.41,72046.49,1998.0\r\n+2617,AAAAAAAAAGFPHBAA,72046.49,72838.83,1999.0\r\n+2618,AAAAAAAAAGFPHBAA,72838.83,21543.07,2000.0\r\n+2619,AAAAAAAAAGFPHBAA,21543.07,115260.10,2001.0\r\n+2620,AAAAAAAAAGFPHBAA,115260.10,54462.54,2002.0\r\n+2621,AAAAAAAAAGFPHBAA,54462.54,,2003.0\r\n+2622,AAAAAAAAAGFPHBAA,2052.61,2052.61,\r\n+2623,AAAAAAAAAGGAAAAA,79541.92,56914.85,1998.0\r\n+2624,AAAAAAAAAGGAAAAA,56914.85,134454.54,1999.0\r\n+2625,AAAAAAAAAGGAAAAA,134454.54,42983.83,2000.0\r\n+2626,AAAAAAAAAGGAAAAA,42983.83,37807.80,2001.0\r\n+2627,AAAAAAAAAGGAAAAA,37807.80,,2002.0\r\n+2628,AAAAAAAAAGGAAAAA,,,\r\n+2629,AAAAAAAAAGGAABAA,59763.82,101593.33,1998.0\r\n+2630,AAAAAAAAAGGAABAA,101593.33,255762.64,1999.0\r\n+2631,AAAAAAAAAGGAABAA,255762.64,87588.90,2000.0\r\n+2632,AAAAAAAAAGGAABAA,87588.90,40302.15,2001.0\r\n+2633,AAAAAAAAAGGAABAA,40302.15,,2002.0\r\n+2634,AAAAAAAAAGGAABAA,10058.78,10058.78,\r\n+2635,AAAAAAAAAGGAMBAA,78253.11,,1998.0\r\n+2636,AAAAAAAAAGGAMBAA,75460.22,98009.79,2000.0\r\n+2637,AAAAAAAAAGGAMBAA,98009.79,101182.62,2001.0\r\n+2638,AAAAAAAAAGGAMBAA,101182.62,,2002.0\r\n+2639,AAAAAAAAAGGBGAAA,162208.36,172977.61,1998.0\r\n+2640,AAAAAAAAAGGBGAAA,172977.61,31053.18,1999.0\r\n+2641,AAAAAAAAAGGBGAAA,31053.18,,2000.0\r\n+2642,AAAAAAAAAGGBGAAA,127926.51,,2002.0\r\n+2643,AAAAAAAAAGGBGAAA,,,\r\n+2644,AAAAAAAAAGGBJAAA,28243.51,36892.76,1999.0\r\n+2645,AAAAAAAAAGGBJAAA,36892.76,78359.06,2000.0\r\n+2646,AAAAAAAAAGGBJAAA,78359.06,39517.43,2001.0\r\n+2647,AAAAAAAAAGGBJAAA,39517.43,,2002.0\r\n+2648,AAAAAAAAAGGBJAAA,,,\r\n+2649,AAAAAAAAAGGCDBAA,171524.22,,1998.0\r\n+2650,AAAAAAAAAGGCDBAA,116861.74,,2000.0\r\n+2651,AAAAAAAAAGGCDBAA,86463.88,,2002.0\r\n+2652,AAAAAAAAAGGCDBAA,,,\r\n+2653,AAAAAAAAAGGCJAAA,33013.61,115697.87,1998.0\r\n+2654,AAAAAAAAAGGCJAAA,115697.87,52509.10,1999.0\r\n+2655,AAAAAAAAAGGCJAAA,52509.10,133542.45,2000.0\r\n+2656,AAAAAAAAAGGCJAAA,133542.45,87407.34,2001.0\r\n+2657,AAAAAAAAAGGCJAAA,87407.34,,2002.0\r\n+2658,AAAAAAAAAGGCJAAA,,,\r\n+2659,AAAAAAAAAGGCOAAA,31190.35,174703.12,1998.0\r\n+2660,AAAAAAAAAGGCOAAA,174703.12,131878.12,1999.0\r\n+2661,AAAAAAAAAGGCOAAA,131878.12,83807.59,2000.0\r\n+2662,AAAAAAAAAGGCOAAA,83807.59,,2001.0\r\n+2663,AAAAAAAAAGGCOAAA,13680.05,13680.05,\r\n+2664,AAAAAAAAAGGCPAAA,102571.26,51576.28,1998.0\r\n+2665,AAAAAAAAAGGCPAAA,51576.28,95571.33,1999.0\r\n+2666,AAAAAAAAAGGCPAAA,95571.33,87363.22,2000.0\r\n+2667,AAAAAAAAAGGCPAAA,87363.22,103419.37,2001.0\r\n+2668,AAAAAAAAAGGCPAAA,103419.37,,2002.0\r\n+2669,AAAAAAAAAGGCPAAA,,,\r\n+2670,AAAAAAAAAGGDNBAA,59350.17,102179.76,1998.0\r\n+2671,AAAAAAAAAGGDNBAA,102179.76,47170.89,1999.0\r\n+2672,AAAAAAAAAGGDNBAA,47170.89,,2000.0\r\n+2673,AAAAAAAAAGGDNBAA,94898.48,,2002.0\r\n+2674,AAAAAAAAAGGDNBAA,708.02,708.02,\r\n+2675,AAAAAAAAAGGEDBAA,82114.23,25601.69,1998.0\r\n+2676,AAAAAAAAAGGEDBAA,25601.69,196959.48,1999.0\r\n+2677,AAAAAAAAAGGEDBAA,196959.48,324253.96,2000.0\r\n+2678,AAAAAAAAAGGEDBAA,324253.96,215447.43,2001.0\r\n+2679,AAAAAAAAAGGEDBAA,215447.43,,2002.0\r\n+2680,AAAAAAAAAGGEDBAA,621.18,621.18,\r\n+2681,AAAAAAAAAGGFCBAA,76139.10,49206.33,1998.0\r\n+2682,AAAAAAAAAGGFCBAA,49206.33,142946.60,1999.0\r\n+2683,AAAAAAAAAGGFCBAA,142946.60,34080.89,2000.0\r\n+2684,AAAAAAAAAGGFCBAA,34080.89,43195.41,2001.0\r\n+2685,AAAAAAAAAGGFCBAA,43195.41,,2002.0\r\n+2686,AAAAAAAAAGGFCBAA,5080.80,5080.80,\r\n+2687,AAAAAAAAAGGFEAAA,100685.92,,1998.0\r\n+2688,AAAAAAAAAGGFEAAA,141830.15,45131.05,2000.0\r\n+2689,AAAAAAAAAGGFEAAA,45131.05,182604.01,2001.0\r\n+2690,AAAAAAAAAGGFEAAA,182604.01,,2002.0\r\n+2691,AAAAAAAAAGGFEAAA,4275.04,4275.04,\r\n+2692,AAAAAAAAAGGFGAAA,83382.60,,1998.0\r\n+2693,AAAAAAAAAGGFGAAA,132716.89,105119.29,2000.0\r\n+2694,AAAAAAAAAGGFGAAA,105119.29,96043.44,2001.0\r\n+2695,AAAAAAAAAGGFGAAA,96043.44,,2002.0\r\n+2696,AAAAAAAAAGGFGAAA,396.31,396.31,\r\n+2697,AAAAAAAAAGGGFAAA,124265.93,56883.05,1998.0\r\n+2698,AAAAAAAAAGGGFAAA,56883.05,181113.66,1999.0\r\n+2699,AAAAAAAAAGGGFAAA,181113.66,64305.10,2000.0\r\n+2700,AAAAAAAAAGGGFAAA,64305.10,,2001.0\r\n+2701,AAAAAAAAAGGGFAAA,4336.75,4336.75,\r\n+2702,AAAAAAAAAGGHDAAA,104997.19,103190.46,1998.0\r\n+2703,AAAAAAAAAGGHDAAA,103190.46,,1999.0\r\n+2704,AAAAAAAAAGGHDAAA,81213.78,,2002.0\r\n+2705,AAAAAAAAAGGHDAAA,,,\r\n+2706,AAAAAAAAAGGHGBAA,91750.50,165762.18,1998.0\r\n+2707,AAAAAAAAAGGHGBAA,165762.18,,1999.0\r\n+2708,AAAAAAAAAGGHGBAA,119385.28,27694.79,2001.0\r\n+2709,AAAAAAAAAGGHGBAA,27694.79,,2002.0\r\n+2710,AAAAAAAAAGGHGBAA,51.35,51.35,\r\n+2711,AAAAAAAAAGGIBBAA,233032.08,143977.03,1998.0\r\n+2712,AAAAAAAAAGGIBBAA,143977.03,125426.25,1999.0\r\n+2713,AAAAAAAAAGGIBBAA,125426.25,43850.86,2000.0\r\n+2714,AAAAAAAAAGGIBBAA,43850.86,103123.20,2001.0\r\n+2715,AAAAAAAAAGGIBBAA,103123.20,,2002.0\r\n+2716,AAAAAAAAAGGIBBAA,2693.68,2693.68,\r\n+2717,AAAAAAAAAGGIDAAA,128852.71,,1998.0\r\n+2718,AAAAAAAAAGGIDAAA,29022.26,,2000.0\r\n+2719,AAAAAAAAAGGIDAAA,29523.89,46677.85,2002.0\r\n+2720,AAAAAAAAAGGIDAAA,46677.85,,2003.0\r\n+2721,AAAAAAAAAGGIDAAA,3007.13,3007.13,\r\n+2722,AAAAAAAAAGGIEAAA,116458.63,53570.29,1998.0\r\n+2723,AAAAAAAAAGGIEAAA,53570.29,35480.09,1999.0\r\n+2724,AAAAAAAAAGGIEAAA,35480.09,151768.40,2000.0\r\n+2725,AAAAAAAAAGGIEAAA,151768.40,96733.66,2001.0\r\n+2726,AAAAAAAAAGGIEAAA,96733.66,,2002.0\r\n+2727,AAAAAAAAAGGIEAAA,2636.75,2636.75,\r\n+2728,AAAAAAAAAGGIMAAA,153983.45,42559.77,1998.0\r\n+2729,AAAAAAAAAGGIMAAA,42559.77,93640.34,1999.0\r\n+2730,AAAAAAAAAGGIMAAA,93640.34,44641.90,2000.0\r\n+2731,AAAAAAAAAGGIMAAA,44641.90,167854.84,2001.0\r\n+2732,AAAAAAAAAGGIMAAA,167854.84,,2002.0\r\n+2733,AAAAAAAAAGGIMAAA,,,\r\n+2734,AAAAAAAAAGGJHBAA,134558.19,140604.11,1998.0\r\n+2735,AAAAAAAAAGGJHBAA,140604.11,77949.86,1999.0\r\n+2736,AAAAAAAAAGGJHBAA,77949.86,,2000.0\r\n+2737,AAAAAAAAAGGJHBAA,92385.85,,2002.0\r\n+2738,AAAAAAAAAGGJHBAA,4524.76,4524.76,\r\n+2739,AAAAAAAAAGGJJBAA,40142.51,71198.43,1998.0\r\n+2740,AAAAAAAAAGGJJBAA,71198.43,57935.24,1999.0\r\n+2741,AAAAAAAAAGGJJBAA,57935.24,98587.41,2000.0\r\n+2742,AAAAAAAAAGGJJBAA,98587.41,174923.18,2001.0\r\n+2743,AAAAAAAAAGGJJBAA,174923.18,,2002.0\r\n+2744,AAAAAAAAAGGJJBAA,,,\r\n+2745,AAAAAAAAAGGJMBAA,28069.29,97280.79,1998.0\r\n+2746,AAAAAAAAAGGJMBAA,97280.79,88323.46,1999.0\r\n+2747,AAAAAAAAAGGJMBAA,88323.46,165845.31,2000.0\r\n+2748,AAAAAAAAAGGJMBAA,165845.31,,2001.0\r\n+2749,AAAAAAAAAGGJMBAA,1174.38,1174.38,\r\n+2750,AAAAAAAAAGGLDAAA,70449.06,36550.55,1998.0\r\n+2751,AAAAAAAAAGGLDAAA,36550.55,262752.37,1999.0\r\n+2752,AAAAAAAAAGGLDAAA,262752.37,94216.53,2000.0\r\n+2753,AAAAAAAAAGGLDAAA,94216.53,107098.11,2001.0\r\n+2754,AAAAAAAAAGGLDAAA,107098.11,,2002.0\r\n+2755,AAAAAAAAAGGLDAAA,1641.78,1641.78,\r\n+2756,AAAAAAAAAGGLHBAA,63183.63,16053.88,1998.0\r\n+2757,AAAAAAAAAGGLHBAA,16053.88,203903.49,1999.0\r\n+2758,AAAAAAAAAGGLHBAA,203903.49,100017.95,2000.0\r\n+2759,AAAAAAAAAGGLHBAA,100017.95,80870.17,2001.0\r\n+2760,AAAAAAAAAGGLHBAA,80870.17,,2002.0\r\n+2761,AAAAAAAAAGGLHBAA,362.88,362.88,\r\n+2762,AAAAAAAAAGGMGAAA,62555.14,98974.37,1998.0\r\n+2763,AAAAAAAAAGGMGAAA,98974.37,81391.64,1999.0\r\n+2764,AAAAAAAAAGGMGAAA,81391.64,258649.79,2000.0\r\n+2765,AAAAAAAAAGGMGAAA,258649.79,86617.36,2001.0\r\n+2766,AAAAAAAAAGGMGAAA,86617.36,,2002.0\r\n+2767,AAAAAAAAAGGMGAAA,952.80,952.80,\r\n+2768,AAAAAAAAAGGMLBAA,95976.67,67963.62,1998.0\r\n+2769,AAAAAAAAAGGMLBAA,67963.62,92303.55,1999.0\r\n+2770,AAAAAAAAAGGMLBAA,92303.55,71764.99,2000.0\r\n+2771,AAAAAAAAAGGMLBAA,71764.99,116055.98,2001.0\r\n+2772,AAAAAAAAAGGMLBAA,116055.98,,2002.0\r\n+2773,AAAAAAAAAGGMLBAA,10239.10,10239.10,\r\n+2774,AAAAAAAAAGGMNBAA,79304.84,141456.75,1998.0\r\n+2775,AAAAAAAAAGGMNBAA,141456.75,104185.75,1999.0\r\n+2776,AAAAAAAAAGGMNBAA,104185.75,148171.04,2000.0\r\n+2777,AAAAAAAAAGGMNBAA,148171.04,69141.89,2001.0\r\n+2778,AAAAAAAAAGGMNBAA,69141.89,,2002.0\r\n+2779,AAAAAAAAAGGMNBAA,,,\r\n+2780,AAAAAAAAAGGNEAAA,115420.71,37118.21,1998.0\r\n+2781,AAAAAAAAAGGNEAAA,37118.21,80649.24,1999.0\r\n+2782,AAAAAAAAAGGNEAAA,80649.24,99643.33,2000.0\r\n+2783,AAAAAAAAAGGNEAAA,99643.33,144818.94,2001.0\r\n+2784,AAAAAAAAAGGNEAAA,144818.94,,2002.0\r\n+2785,AAAAAAAAAGGNEAAA,10436.07,10436.07,\r\n+2786,AAAAAAAAAGGNHAAA,35633.32,45498.02,1998.0\r\n+2787,AAAAAAAAAGGNHAAA,45498.02,67331.01,1999.0\r\n+2788,AAAAAAAAAGGNHAAA,67331.01,51693.55,2000.0\r\n+2789,AAAAAAAAAGGNHAAA,51693.55,144934.42,2001.0\r\n+2790,AAAAAAAAAGGNHAAA,144934.42,,2002.0\r\n+2791,AAAAAAAAAGGNHAAA,,,\r\n+2792,AAAAAAAAAGGPHBAA,159088.49,164170.45,1998.0\r\n+2793,AAAAAAAAAGGPHBAA,164170.45,225173.44,1999.0\r\n+2794,AAAAAAAAAGGPHBAA,225173.44,95347.35,2000.0\r\n+2795,AAAAAAAAAGGPHBAA,95347.35,64357.22,2001.0\r\n+2796,AAAAAAAAAGGPHBAA,64357.22,,2002.0\r\n+2797,AAAAAAAAAGGPHBAA,7591.50,7591.50,\r\n+2798,AAAAAAAAAGHBIAAA,70444.48,96276.87,1998.0\r\n+2799,AAAAAAAAAGHBIAAA,96276.87,76155.67,1999.0\r\n+2800,AAAAAAAAAGHBIAAA,76155.67,42690.11,2000.0\r\n+2801,AAAAAAAAAGHBIAAA,42690.11,39709.15,2001.0\r\n+2802,AAAAAAAAAGHBIAAA,39709.15,,2002.0\r\n+2803,AAAAAAAAAGHBIAAA,10168.05,10168.05,\r\n+2804,AAAAAAAAAGHCIBAA,79621.01,123891.66,1998.0\r\n+2805,AAAAAAAAAGHCIBAA,123891.66,117779.24,1999.0\r\n+2806,AAAAAAAAAGHCIBAA,117779.24,39818.70,2000.0\r\n+2807,AAAAAAAAAGHCIBAA,39818.70,38618.15,2001.0\r\n+2808,AAAAAAAAAGHCIBAA,38618.15,,2002.0\r\n+2809,AAAAAAAAAGHCIBAA,,,\r\n+2810,AAAAAAAAAGHDKBAA,38415.84,95582.24,1998.0\r\n+2811,AAAAAAAAAGHDKBAA,95582.24,29174.95,1999.0\r\n+2812,AAAAAAAAAGHDKBAA,29174.95,116709.96,2000.0\r\n+2813,AAAAAAAAAGHDKBAA,116709.96,100799.34,2001.0\r\n+2814,AAAAAAAAAGHDKBAA,100799.34,20491.69,2002.0\r\n+2815,AAAAAAAAAGHDKBAA,20491.69,,2003.0\r\n+2816,AAAAAAAAAGHDKBAA,,,\r\n+2817,AAAAAAAAAGHEJAAA,110458.63,78075.16,1998.0\r\n+2818,AAAAAAAAAGHEJAAA,78075.16,144022.53,1999.0\r\n+2819,AAAAAAAAAGHEJAAA,144022.53,105608.57,2000.0\r\n+2820,AAAAAAAAAGHEJAAA,105608.57,,2001.0\r\n+2821,AAAAAAAAAGHEJAAA,134.98,134.98,\r\n+2822,AAAAAAAAAGHFABAA,166402.65,95724.00,1998.0\r\n+2823,AAAAAAAAAGHFABAA,95724.00,61029.80,1999.0\r\n+2824,AAAAAAAAAGHFABAA,61029.80,206565.56,2000.0\r\n+2825,AAAAAAAAAGHFABAA,206565.56,225304.18,2001.0\r\n+2826,AAAAAAAAAGHFABAA,225304.18,,2002.0\r\n+2827,AAAAAAAAAGHFABAA,5021.17,5021.17,\r\n+2828,AAAAAAAAAGHFKBAA,138419.59,76046.21,1998.0\r\n+2829,AAAAAAAAAGHFKBAA,76046.21,20848.73,1999.0\r\n+2830,AAAAAAAAAGHFKBAA,20848.73,,2000.0\r\n+2831,AAAAAAAAAGHFKBAA,42831.28,,2002.0\r\n+2832,AAAAAAAAAGHFKBAA,5432.00,5432.00,\r\n+2833,AAAAAAAAAGHFOBAA,108632.58,46914.14,1998.0\r\n+2834,AAAAAAAAAGHFOBAA,46914.14,25576.13,1999.0\r\n+2835,AAAAAAAAAGHFOBAA,25576.13,141600.29,2000.0\r\n+2836,AAAAAAAAAGHFOBAA,141600.29,49193.72,2001.0\r\n+2837,AAAAAAAAAGHFOBAA,49193.72,,2002.0\r\n+2838,AAAAAAAAAGHFOBAA,,,\r\n+2839,AAAAAAAAAGHGABAA,79649.66,168727.89,1998.0\r\n+2840,AAAAAAAAAGHGABAA,168727.89,39467.25,1999.0\r\n+2841,AAAAAAAAAGHGABAA,39467.25,70836.46,2000.0\r\n+2842,AAAAAAAAAGHGABAA,70836.46,116440.39,2001.0\r\n+2843,AAAAAAAAAGHGABAA,116440.39,,2002.0\r\n+2844,AAAAAAAAAGHGABAA,,,\r\n+2845,AAAAAAAAAGHGBBAA,56499.09,134923.11,1998.0\r\n+2846,AAAAAAAAAGHGBBAA,134923.11,99563.62,1999.0\r\n+2847,AAAAAAAAAGHGBBAA,99563.62,37380.05,2000.0\r\n+2848,AAAAAAAAAGHGBBAA,37380.05,140017.42,2001.0\r\n+2849,AAAAAAAAAGHGBBAA,140017.42,,2002.0\r\n+2850,AAAAAAAAAGHGBBAA,23943.32,23943.32,\r\n+2851,AAAAAAAAAGHGGAAA,43713.52,88619.69,1998.0\r\n+2852,AAAAAAAAAGHGGAAA,88619.69,39859.99,1999.0\r\n+2853,AAAAAAAAAGHGGAAA,39859.99,142983.20,2000.0\r\n+2854,AAAAAAAAAGHGGAAA,142983.20,246597.34,2001.0\r\n+2855,AAAAAAAAAGHGGAAA,246597.34,,2002.0\r\n+2856,AAAAAAAAAGHGGAAA,,,\r\n+2857,AAAAAAAAAGHGLBAA,256714.92,62661.87,1998.0\r\n+2858,AAAAAAAAAGHGLBAA,62661.87,102309.09,1999.0\r\n+2859,AAAAAAAAAGHGLBAA,102309.09,66752.20,2000.0\r\n+2860,AAAAAAAAAGHGLBAA,66752.20,46635.40,2001.0\r\n+2861,AAAAAAAAAGHGLBAA,46635.40,,2002.0\r\n+2862,AAAAAAAAAGHGLBAA,280.76,280.76,\r\n+2863,AAAAAAAAAGHGMAAA,97994.25,24460.77,1998.0\r\n+2864,AAAAAAAAAGHGMAAA,24460.77,63197.34,1999.0\r\n+2865,AAAAAAAAAGHGMAAA,63197.34,84382.57,2000.0\r\n+2866,AAAAAAAAAGHGMAAA,84382.57,123045.80,2001.0\r\n+2867,AAAAAAAAAGHGMAAA,123045.80,,2002.0\r\n+2868,AAAAAAAAAGHGMAAA,1088.64,1088.64,\r\n+2869,AAAAAAAAAGHGNAAA,110108.81,55390.83,1998.0\r\n+2870,AAAAAAAAAGHGNAAA,55390.83,52002.42,1999.0\r\n+2871,AAAAAAAAAGHGNAAA,52002.42,137666.38,2000.0\r\n+2872,AAAAAAAAAGHGNAAA,137666.38,63255.69,2001.0\r\n+2873,AAAAAAAAAGHGNAAA,63255.69,,2002.0\r\n+2874,AAAAAAAAAGHGNAAA,5481.82,5481.82,\r\n+2875,AAAAAAAAAGHGNBAA,126935.33,,1998.0\r\n+2876,AAAAAAAAAGHGNBAA,97953.23,47113.88,2000.0\r\n+2877,AAAAAAAAAGHGNBAA,47113.88,146049.48,2001.0\r\n+2878,AAAAAAAAAGHGNBAA,146049.48,,2002.0\r\n+2879,AAAAAAAAAGHGNBAA,,,\r\n+2880,AAAAAAAAAGHHOAAA,33586.67,158616.74,1999.0\r\n+2881,AAAAAAAAAGHHOAAA,158616.74,116926.88,2000.0\r\n+2882,AAAAAAAAAGHHOAAA,116926.88,,2001.0\r\n+2883,AAAAAAAAAGHHOAAA,4269.72,4269.72,\r\n+2884,AAAAAAAAAGHIIBAA,256404.69,188708.95,1999.0\r\n+2885,AAAAAAAAAGHIIBAA,188708.95,92052.88,2000.0\r\n+2886,AAAAAAAAAGHIIBAA,92052.88,46101.98,2001.0\r\n+2887,AAAAAAAAAGHIIBAA,46101.98,,2002.0\r\n+2888,AAAAAAAAAGHIIBAA,2583.02,2583.02,\r\n+2889,AAAAAAAAAGHIJBAA,157930.77,40714.85,1998.0\r\n+2890,AAAAAAAAAGHIJBAA,40714.85,224966.80,1999.0\r\n+2891,AAAAAAAAAGHIJBAA,224966.80,,2000.0\r\n+2892,AAAAAAAAAGHIJBAA,12174.29,,2002.0\r\n+2893,AAAAAAAAAGHIJBAA,,,\r\n+2894,AAAAAAAAAGHJABAA,124685.63,,1998.0\r\n+2895,AAAAAAAAAGHJABAA,80404.53,147557.13,2000.0\r\n+2896,AAAAAAAAAGHJABAA,147557.13,23057.67,2001.0\r\n+2897,AAAAAAAAAGHJABAA,23057.67,,2002.0\r\n+2898,AAAAAAAAAGHJABAA,4138.65,4138.65,\r\n+2899,AAAAAAAAAGHJCBAA,87132.13,43516.08,1998.0\r\n+2900,AAAAAAAAAGHJCBAA,43516.08,126206.11,1999.0\r\n+2901,AAAAAAAAAGHJCBAA,126206.11,149680.61,2000.0\r\n+2902,AAAAAAAAAGHJCBAA,149680.61,,2001.0\r\n+2903,AAAAAAAAAGHJCBAA,,,\r\n+2904,AAAAAAAAAGHJDAAA,80924.96,107816.13,1998.0\r\n+2905,AAAAAAAAAGHJDAAA,107816.13,85681.68,1999.0\r\n+2906,AAAAAAAAAGHJDAAA,85681.68,95215.74,2000.0\r\n+2907,AAAAAAAAAGHJDAAA,95215.74,239617.26,2001.0\r\n+2908,AAAAAAAAAGHJDAAA,239617.26,,2002.0\r\n+2909,AAAAAAAAAGHJDAAA,327.08,327.08,\r\n+2910,AAAAAAAAAGHJEBAA,67215.28,142699.71,1999.0\r\n+2911,AAAAAAAAAGHJEBAA,142699.71,76370.49,2000.0\r\n+2912,AAAAAAAAAGHJEBAA,76370.49,105889.22,2001.0\r\n+2913,AAAAAAAAAGHJEBAA,105889.22,,2002.0\r\n+2914,AAAAAAAAAGHJEBAA,,,\r\n+2915,AAAAAAAAAGHJLBAA,13442.16,23607.94,1998.0\r\n+2916,AAAAAAAAAGHJLBAA,23607.94,174751.44,1999.0\r\n+2917,AAAAAAAAAGHJLBAA,174751.44,107007.74,2000.0\r\n+2918,AAAAAAAAAGHJLBAA,107007.74,47153.57,2001.0\r\n+2919,AAAAAAAAAGHJLBAA,47153.57,,2002.0\r\n+2920,AAAAAAAAAGHJLBAA,,,\r\n+2921,AAAAAAAAAGHKBBAA,155847.78,69330.45,1998.0\r\n+2922,AAAAAAAAAGHKBBAA,69330.45,,1999.0\r\n+2923,AAAAAAAAAGHKBBAA,57928.42,150882.33,2001.0\r\n+2924,AAAAAAAAAGHKBBAA,150882.33,,2002.0\r\n+2925,AAAAAAAAAGHKBBAA,184.50,184.50,\r\n+2926,AAAAAAAAAGHLFBAA,164040.86,83797.47,1998.0\r\n+2927,AAAAAAAAAGHLFBAA,83797.47,84149.28,1999.0\r\n+2928,AAAAAAAAAGHLFBAA,84149.28,136968.12,2000.0\r\n+2929,AAAAAAAAAGHLFBAA,136968.12,40251.55,2001.0\r\n+2930,AAAAAAAAAGHLFBAA,40251.55,,2002.0\r\n+2931,AAAAAAAAAGHLFBAA,,,\r\n+2932,AAAAAAAAAGHMBAAA,87873.92,76702.68,1998.0\r\n+2933,AAAAAAAAAGHMBAAA,76702.68,258176.44,1999.0\r\n+2934,AAAAAAAAAGHMBAAA,258176.44,42039.38,2000.0\r\n+2935,AAAAAAAAAGHMBAAA,42039.38,,2001.0\r\n+2936,AAAAAAAAAGHMBAAA,1901.85,1901.85,\r\n+2937,AAAAAAAAAGHMHBAA,34155.35,62064.09,1999.0\r\n+2938,AAAAAAAAAGHMHBAA,62064.09,52596.70,2000.0\r\n+2939,AAAAAAAAAGHMHBAA,52596.70,,2001.0\r\n+2940,AAAAAAAAAGHNBBAA,162808.66,60331.33,1998.0\r\n+2941,AAAAAAAAAGHNBBAA,60331.33,124540.15,1999.0\r\n+2942,AAAAAAAAAGHNBBAA,124540.15,,2000.0\r\n+2943,AAAAAAAAAGHNBBAA,91948.74,,2002.0\r\n+2944,AAAAAAAAAGHNBBAA,3298.24,3298.24,\r\n+2945,AAAAAAAAAGHOBBAA,57269.74,190199.51,1998.0\r\n+2946,AAAAAAAAAGHOBBAA,190199.51,258727.07,1999.0\r\n+2947,AAAAAAAAAGHOBBAA,258727.07,20577.01,2000.0\r\n+2948,AAAAAAAAAGHOBBAA,20577.01,127860.69,2001.0\r\n+2949,AAAAAAAAAGHOBBAA,127860.69,,2002.0\r\n+2950,AAAAAAAAAGHOBBAA,9596.31,9596.31,\r\n+2951,AAAAAAAAAGHOGAAA,46806.16,104368.75,1998.0\r\n+2952,AAAAAAAAAGHOGAAA,104368.75,188126.30,1999.0\r\n+2953,AAAAAAAAAGHOGAAA,188126.30,141356.73,2000.0\r\n+2954,AAAAAAAAAGHOGAAA,141356.73,87997.11,2001.0\r\n+2955,AAAAAAAAAGHOGAAA,87997.11,,2002.0\r\n+2956,AAAAAAAAAGHOGAAA,3123.90,3123.90,\r\n+2957,AAAAAAAAAGHOJBAA,63904.27,78189.46,1998.0\r\n+2958,AAAAAAAAAGHOJBAA,78189.46,244356.22,1999.0\r\n+2959,AAAAAAAAAGHOJBAA,244356.22,65146.95,2000.0\r\n+2960,AAAAAAAAAGHOJBAA,65146.95,84062.41,2001.0\r\n+2961,AAAAAAAAAGHOJBAA,84062.41,,2002.0\r\n+2962,AAAAAAAAAGHOJBAA,8294.00,8294.00,\r\n+2963,AAAAAAAAAGHOPAAA,84196.23,152221.25,1998.0\r\n+2964,AAAAAAAAAGHOPAAA,152221.25,79399.52,1999.0\r\n+2965,AAAAAAAAAGHOPAAA,79399.52,98883.69,2000.0\r\n+2966,AAAAAAAAAGHOPAAA,98883.69,29302.33,2001.0\r\n+2967,AAAAAAAAAGHOPAAA,29302.33,,2002.0\r\n+2968,AAAAAAAAAGHOPAAA,671.84,671.84,\r\n+2969,AAAAAAAAAGHPPAAA,59873.07,153985.98,1998.0\r\n+2970,AAAAAAAAAGHPPAAA,153985.98,23243.57,1999.0\r\n+2971,AAAAAAAAAGHPPAAA,23243.57,,2000.0\r\n+2972,AAAAAAAAAGHPPAAA,82202.03,,2002.0\r\n+2973,AAAAAAAAAGHPPAAA,2940.60,2940.60,\r\n+2974,AAAAAAAAAGIAJAAA,50581.47,43808.76,1998.0\r\n+2975,AAAAAAAAAGIAJAAA,43808.76,163545.53,1999.0\r\n+2976,AAAAAAAAAGIAJAAA,163545.53,177674.06,2000.0\r\n+2977,AAAAAAAAAGIAJAAA,177674.06,,2001.0\r\n+2978,AAAAAAAAAGIAJAAA,,,\r\n+2979,AAAAAAAAAGIBCBAA,31104.07,57999.93,1998.0\r\n+2980,AAAAAAAAAGIBCBAA,57999.93,125386.06,1999.0\r\n+2981,AAAAAAAAAGIBCBAA,125386.06,13408.05,2000.0\r\n+2982,AAAAAAAAAGIBCBAA,13408.05,19829.99,2001.0\r\n+2983,AAAAAAAAAGIBCBAA,19829.99,,2002.0\r\n+2984,AAAAAAAAAGIBCBAA,5814.65,5814.65,\r\n+2985,AAAAAAAAAGIBEAAA,97804.95,198576.60,1998.0\r\n+2986,AAAAAAAAAGIBEAAA,198576.60,39282.38,1999.0\r\n+2987,AAAAAAAAAGIBEAAA,39282.38,108326.90,2000.0\r\n+2988,AAAAAAAAAGIBEAAA,108326.90,54315.44,2001.0\r\n+2989,AAAAAAAAAGIBEAAA,54315.44,,2002.0\r\n+2990,AAAAAAAAAGIBEAAA,266.05,266.05,\r\n+2991,AAAAAAAAAGIBHAAA,43518.09,155879.87,1998.0\r\n+2992,AAAAAAAAAGIBHAAA,155879.87,66128.56,1999.0\r\n+2993,AAAAAAAAAGIBHAAA,66128.56,100268.11,2000.0\r\n+2994,AAAAAAAAAGIBHAAA,100268.11,42153.62,2001.0\r\n+2995,AAAAAAAAAGIBHAAA,42153.62,,2002.0\r\n+2996,AAAAAAAAAGIBHAAA,2975.58,2975.58,\r\n+2997,AAAAAAAAAGIBMAAA,75603.52,117802.74,1998.0\r\n+2998,AAAAAAAAAGIBMAAA,117802.74,40745.20,1999.0\r\n+2999,AAAAAAAAAGIBMAAA,40745.20,,2000.0\r\ndiff --git a/extension/autocomplete/autocomplete_extension.cpp b/extension/autocomplete/autocomplete_extension.cpp\nindex 62db1f89ae63..609ecbffe834 100644\n--- a/extension/autocomplete/autocomplete_extension.cpp\n+++ b/extension/autocomplete/autocomplete_extension.cpp\n@@ -47,7 +47,10 @@ static vector<AutoCompleteSuggestion> ComputeSuggestions(vector<AutoCompleteCand\n \tfor (idx_t i = 0; i < available_suggestions.size(); i++) {\n \t\tauto &suggestion = available_suggestions[i];\n \t\tconst int32_t BASE_SCORE = 10;\n-\t\tauto &str = suggestion.candidate;\n+\t\tauto str = suggestion.candidate;\n+\t\tif (suggestion.extra_char != '\\0') {\n+\t\t\tstr += suggestion.extra_char;\n+\t\t}\n \t\tauto bonus = suggestion.score_bonus;\n \t\tif (matches.find(str) != matches.end()) {\n \t\t\t// entry already exists\n@@ -73,6 +76,9 @@ static vector<AutoCompleteSuggestion> ComputeSuggestions(vector<AutoCompleteCand\n \t\t\tthrow InternalException(\"Auto-complete match not found\");\n \t\t}\n \t\tauto &suggestion = available_suggestions[entry->second];\n+\t\tif (suggestion.extra_char != '\\0') {\n+\t\t\tresult.pop_back();\n+\t\t}\n \t\tif (suggestion.candidate_type == CandidateType::KEYWORD) {\n \t\t\tif (prefix_is_lower) {\n \t\t\t\tresult = StringUtil::Lower(result);\ndiff --git a/extension/parquet/column_writer.cpp b/extension/parquet/column_writer.cpp\nindex 0eba64b4f104..ba42a9b2f20a 100644\n--- a/extension/parquet/column_writer.cpp\n+++ b/extension/parquet/column_writer.cpp\n@@ -796,7 +796,6 @@ class NumericStatisticsState : public ColumnWriterStatistics {\n };\n \n struct BaseParquetOperator {\n-\n \ttemplate <class SRC, class TGT>\n \tstatic void WriteToStream(const TGT &input, WriteStream &ser) {\n \t\tser.WriteData(const_data_ptr_cast(&input), sizeof(TGT));\n@@ -815,6 +814,11 @@ struct BaseParquetOperator {\n \ttemplate <class SRC, class TGT>\n \tstatic void HandleStats(ColumnWriterStatistics *stats, TGT target_value) {\n \t}\n+\n+\ttemplate <class SRC, class TGT>\n+\tstatic idx_t GetRowSize(const Vector &, idx_t) {\n+\t\treturn sizeof(TGT);\n+\t}\n };\n \n struct ParquetCastOperator : public BaseParquetOperator {\n@@ -936,6 +940,11 @@ struct ParquetStringOperator : public BaseParquetOperator {\n \tstatic uint64_t XXHash64(const TGT &target_value) {\n \t\treturn duckdb_zstd::XXH64(target_value.GetData(), target_value.GetSize(), 0);\n \t}\n+\n+\ttemplate <class SRC, class TGT>\n+\tstatic idx_t GetRowSize(const Vector &vector, idx_t index) {\n+\t\treturn FlatVector::GetData<string_t>(vector)[index].GetSize();\n+\t}\n };\n \n struct ParquetIntervalTargetType {\n@@ -1066,6 +1075,7 @@ class StandardColumnWriterState : public BasicColumnWriterState {\n \t// analysis state for integer values for DELTA_BINARY_PACKED/DELTA_LENGTH_BYTE_ARRAY\n \tidx_t total_value_count = 0;\n \tidx_t total_string_size = 0;\n+\tuint32_t key_bit_width = 0;\n \n \tunordered_map<T, uint32_t> dictionary;\n \tduckdb_parquet::Encoding::type encoding;\n@@ -1335,6 +1345,8 @@ class StandardColumnWriter : public BasicColumnWriter {\n \t\t\t\t}\n \t\t\t}\n \t\t\tstate.dictionary.clear();\n+\t\t} else {\n+\t\t\tstate.key_bit_width = RleBpDecoder::ComputeBitWidth(state.dictionary.size());\n \t\t}\n \t}\n \n@@ -1488,9 +1500,13 @@ class StandardColumnWriter : public BasicColumnWriter {\n \t\t// bloom filter will be queued for writing in ParquetWriter::BufferBloomFilter one level up\n \t}\n \n-\t// TODO this now vastly over-estimates the page size\n \tidx_t GetRowSize(const Vector &vector, const idx_t index, const BasicColumnWriterState &state_p) const override {\n-\t\treturn sizeof(TGT);\n+\t\tauto &state = state_p.Cast<StandardColumnWriterState<SRC>>();\n+\t\tif (state.encoding == Encoding::RLE_DICTIONARY) {\n+\t\t\treturn (state.key_bit_width + 7) / 8;\n+\t\t} else {\n+\t\t\treturn OP::template GetRowSize<SRC, TGT>(vector, index);\n+\t\t}\n \t}\n };\n \ndiff --git a/src/catalog/catalog_entry_retriever.cpp b/src/catalog/catalog_entry_retriever.cpp\nindex c37562d72144..eb283de5b4b7 100644\n--- a/src/catalog/catalog_entry_retriever.cpp\n+++ b/src/catalog/catalog_entry_retriever.cpp\n@@ -76,7 +76,7 @@ void CatalogEntryRetriever::Inherit(const CatalogEntryRetriever &parent) {\n \tthis->search_path = parent.search_path;\n }\n \n-CatalogSearchPath &CatalogEntryRetriever::GetSearchPath() {\n+const CatalogSearchPath &CatalogEntryRetriever::GetSearchPath() const {\n \tif (search_path) {\n \t\treturn *search_path;\n \t}\ndiff --git a/src/catalog/catalog_search_path.cpp b/src/catalog/catalog_search_path.cpp\nindex 793de909b9f6..9ce71f283cfe 100644\n--- a/src/catalog/catalog_search_path.cpp\n+++ b/src/catalog/catalog_search_path.cpp\n@@ -189,11 +189,11 @@ void CatalogSearchPath::Set(CatalogSearchEntry new_value, CatalogSetPathType set\n \tSet(std::move(new_paths), set_type);\n }\n \n-const vector<CatalogSearchEntry> &CatalogSearchPath::Get() {\n+const vector<CatalogSearchEntry> &CatalogSearchPath::Get() const {\n \treturn paths;\n }\n \n-string CatalogSearchPath::GetDefaultSchema(const string &catalog) {\n+string CatalogSearchPath::GetDefaultSchema(const string &catalog) const {\n \tfor (auto &path : paths) {\n \t\tif (path.catalog == TEMP_CATALOG) {\n \t\t\tcontinue;\n@@ -205,7 +205,7 @@ string CatalogSearchPath::GetDefaultSchema(const string &catalog) {\n \treturn DEFAULT_SCHEMA;\n }\n \n-string CatalogSearchPath::GetDefaultSchema(ClientContext &context, const string &catalog) {\n+string CatalogSearchPath::GetDefaultSchema(ClientContext &context, const string &catalog) const {\n \tfor (auto &path : paths) {\n \t\tif (path.catalog == TEMP_CATALOG) {\n \t\t\tcontinue;\n@@ -221,7 +221,7 @@ string CatalogSearchPath::GetDefaultSchema(ClientContext &context, const string\n \treturn DEFAULT_SCHEMA;\n }\n \n-string CatalogSearchPath::GetDefaultCatalog(const string &schema) {\n+string CatalogSearchPath::GetDefaultCatalog(const string &schema) const {\n \tif (DefaultSchemaGenerator::IsDefaultSchema(schema)) {\n \t\treturn SYSTEM_CATALOG;\n \t}\n@@ -236,7 +236,7 @@ string CatalogSearchPath::GetDefaultCatalog(const string &schema) {\n \treturn INVALID_CATALOG;\n }\n \n-vector<string> CatalogSearchPath::GetCatalogsForSchema(const string &schema) {\n+vector<string> CatalogSearchPath::GetCatalogsForSchema(const string &schema) const {\n \tvector<string> catalogs;\n \tif (DefaultSchemaGenerator::IsDefaultSchema(schema)) {\n \t\tcatalogs.push_back(SYSTEM_CATALOG);\n@@ -250,7 +250,7 @@ vector<string> CatalogSearchPath::GetCatalogsForSchema(const string &schema) {\n \treturn catalogs;\n }\n \n-vector<string> CatalogSearchPath::GetSchemasForCatalog(const string &catalog) {\n+vector<string> CatalogSearchPath::GetSchemasForCatalog(const string &catalog) const {\n \tvector<string> schemas;\n \tfor (auto &path : paths) {\n \t\tif (StringUtil::CIEquals(path.catalog, catalog)) {\n@@ -260,7 +260,7 @@ vector<string> CatalogSearchPath::GetSchemasForCatalog(const string &catalog) {\n \treturn schemas;\n }\n \n-const CatalogSearchEntry &CatalogSearchPath::GetDefault() {\n+const CatalogSearchEntry &CatalogSearchPath::GetDefault() const {\n \tconst auto &paths = Get();\n \tD_ASSERT(paths.size() >= 2);\n \treturn paths[1];\n@@ -281,7 +281,7 @@ void CatalogSearchPath::SetPathsInternal(vector<CatalogSearchEntry> new_paths) {\n }\n \n bool CatalogSearchPath::SchemaInSearchPath(ClientContext &context, const string &catalog_name,\n-                                           const string &schema_name) {\n+                                           const string &schema_name) const {\n \tfor (auto &path : paths) {\n \t\tif (!StringUtil::CIEquals(path.schema, schema_name)) {\n \t\t\tcontinue;\ndiff --git a/src/common/hive_partitioning.cpp b/src/common/hive_partitioning.cpp\nindex c84d0505d032..dc13c8724b9a 100644\n--- a/src/common/hive_partitioning.cpp\n+++ b/src/common/hive_partitioning.cpp\n@@ -245,7 +245,7 @@ static void TemplatedGetHivePartitionValues(Vector &input, vector<HivePartitionK\n \n \tconst auto &type = input.GetType();\n \n-\tconst auto reinterpret = Value::CreateValue<T>(data[0]).GetTypeMutable() != type;\n+\tconst auto reinterpret = Value::CreateValue<T>(data[sel.get_index(0)]).GetTypeMutable() != type;\n \tif (reinterpret) {\n \t\tfor (idx_t i = 0; i < count; i++) {\n \t\t\tauto &key = keys[i];\ndiff --git a/src/common/multi_file_reader.cpp b/src/common/multi_file_reader.cpp\nindex e03f667f3c02..be17aaf9516b 100644\n--- a/src/common/multi_file_reader.cpp\n+++ b/src/common/multi_file_reader.cpp\n@@ -508,14 +508,14 @@ void MultiFileReader::CreateMapping(const string &file_name,\n \t// copy global columns and inject any different defaults\n \tCreateColumnMapping(file_name, local_columns, global_columns, global_column_ids, reader_data, bind_data,\n \t                    initial_file, global_state);\n-\tCreateFilterMap(global_columns, filters, reader_data, global_state);\n+\tCreateFilterMap(global_column_ids, filters, reader_data, global_state);\n }\n \n-void MultiFileReader::CreateFilterMap(const vector<MultiFileReaderColumnDefinition> &global_columns,\n+void MultiFileReader::CreateFilterMap(const vector<ColumnIndex> &global_column_ids,\n                                       optional_ptr<TableFilterSet> filters, MultiFileReaderData &reader_data,\n                                       optional_ptr<MultiFileReaderGlobalState> global_state) {\n \tif (filters) {\n-\t\tauto filter_map_size = global_columns.size();\n+\t\tauto filter_map_size = global_column_ids.size();\n \t\tif (global_state) {\n \t\t\tfilter_map_size += global_state->extra_columns.size();\n \t\t}\ndiff --git a/src/function/window/window_boundaries_state.cpp b/src/function/window/window_boundaries_state.cpp\nindex 60b59caceaf1..ce3ba3bbeb85 100644\n--- a/src/function/window/window_boundaries_state.cpp\n+++ b/src/function/window/window_boundaries_state.cpp\n@@ -203,7 +203,6 @@ static idx_t FindTypedRangeBound(WindowCursor &over, const idx_t order_begin, co\n \t\t\tthrow OutOfRangeException(\"Invalid RANGE FOLLOWING value\");\n \t\t}\n \t}\n-\n \t//\tTry to reuse the previous bounds to restrict the search.\n \t//\tThis is only valid if the previous bounds were non-empty\n \t//\tOnly inject the comparisons if the previous bounds are a strict subset.\n@@ -686,19 +685,15 @@ void WindowBoundariesState::ValidEnd(DataChunk &bounds, idx_t row_idx, const idx\n \t\tif (!is_same_partition || is_jump) {\n \t\t\t// Find valid ordering values for the new partition\n \t\t\t// so we can exclude NULLs from RANGE expression computations\n+\t\t\tconst auto valid_start = valid_begin_data[chunk_idx];\n \t\t\tvalid_end = partition_end_data[chunk_idx];\n \n \t\t\tif ((valid_start < valid_end) && has_following_range) {\n \t\t\t\t// Exclude any trailing NULLs\n-\t\t\t\tconst auto valid_start = valid_begin_data[chunk_idx];\n \t\t\t\tif (range->CellIsNull(0, valid_end - 1)) {\n \t\t\t\t\tidx_t n = 1;\n \t\t\t\t\tvalid_end = FindPrevStart(order_mask, valid_start, valid_end, n);\n \t\t\t\t}\n-\n-\t\t\t\t//\tReset range hints\n-\t\t\t\tprev.start = valid_start;\n-\t\t\t\tprev.end = valid_end;\n \t\t\t}\n \t\t}\n \n@@ -718,6 +713,11 @@ void WindowBoundariesState::FrameBegin(DataChunk &bounds, idx_t row_idx, const i\n \n \tidx_t window_start = NumericLimits<idx_t>::Maximum();\n \n+\t//\tReset previous range hints\n+\tidx_t prev_partition = partition_begin_data[0];\n+\tprev.start = valid_begin_data[0];\n+\tprev.end = valid_end_data[0];\n+\n \tswitch (start_boundary) {\n \tcase WindowBoundary::UNBOUNDED_PRECEDING:\n \t\tbounds.data[FRAME_BEGIN].Reference(bounds.data[PARTITION_BEGIN]);\n@@ -780,6 +780,11 @@ void WindowBoundariesState::FrameBegin(DataChunk &bounds, idx_t row_idx, const i\n \t\t\t} else {\n \t\t\t\tconst auto valid_end = valid_end_data[chunk_idx];\n \t\t\t\tprev.end = valid_end;\n+\t\t\t\tconst auto cur_partition = partition_begin_data[chunk_idx];\n+\t\t\t\tif (cur_partition != prev_partition) {\n+\t\t\t\t\tprev.start = valid_begin_data[chunk_idx];\n+\t\t\t\t\tprev_partition = cur_partition;\n+\t\t\t\t}\n \t\t\t\twindow_start = FindOrderedRangeBound<true>(*range, range_sense, row_idx, valid_end, start_boundary,\n \t\t\t\t                                           boundary_begin, chunk_idx, prev);\n \t\t\t\tprev.start = window_start;\n@@ -852,6 +857,11 @@ void WindowBoundariesState::FrameEnd(DataChunk &bounds, idx_t row_idx, const idx\n \n \tidx_t window_end = NumericLimits<idx_t>::Maximum();\n \n+\t//\tReset previous range hints\n+\tidx_t prev_partition = partition_begin_data[0];\n+\tprev.start = valid_begin_data[0];\n+\tprev.end = valid_end_data[0];\n+\n \tswitch (end_boundary) {\n \tcase WindowBoundary::CURRENT_ROW_ROWS:\n \t\tfor (idx_t chunk_idx = 0; chunk_idx < count; ++chunk_idx, ++row_idx) {\n@@ -915,6 +925,11 @@ void WindowBoundariesState::FrameEnd(DataChunk &bounds, idx_t row_idx, const idx\n \t\t\t} else {\n \t\t\t\tconst auto valid_end = valid_end_data[chunk_idx];\n \t\t\t\tprev.start = valid_begin_data[chunk_idx];\n+\t\t\t\tconst auto cur_partition = partition_begin_data[chunk_idx];\n+\t\t\t\tif (cur_partition != prev_partition) {\n+\t\t\t\t\tprev.end = valid_end;\n+\t\t\t\t\tprev_partition = cur_partition;\n+\t\t\t\t}\n \t\t\t\twindow_end = FindOrderedRangeBound<false>(*range, range_sense, row_idx, valid_end, end_boundary,\n \t\t\t\t                                          boundary_end, chunk_idx, prev);\n \t\t\t\tprev.end = window_end;\ndiff --git a/src/include/duckdb/catalog/catalog_entry_retriever.hpp b/src/include/duckdb/catalog/catalog_entry_retriever.hpp\nindex 4e771cdc589e..08425f00ad87 100644\n--- a/src/include/duckdb/catalog/catalog_entry_retriever.hpp\n+++ b/src/include/duckdb/catalog/catalog_entry_retriever.hpp\n@@ -56,7 +56,7 @@ class CatalogEntryRetriever {\n \t                                           OnEntryNotFound on_entry_not_found = OnEntryNotFound::THROW_EXCEPTION,\n \t                                           QueryErrorContext error_context = QueryErrorContext());\n \n-\tCatalogSearchPath &GetSearchPath();\n+\tconst CatalogSearchPath &GetSearchPath() const;\n \tvoid SetSearchPath(vector<CatalogSearchEntry> entries);\n \n \tvoid SetCallback(catalog_entry_callback_t callback);\ndiff --git a/src/include/duckdb/catalog/catalog_search_path.hpp b/src/include/duckdb/catalog/catalog_search_path.hpp\nindex f128a4962e75..e5b6cd254962 100644\n--- a/src/include/duckdb/catalog/catalog_search_path.hpp\n+++ b/src/include/duckdb/catalog/catalog_search_path.hpp\n@@ -48,20 +48,21 @@ class CatalogSearchPath {\n \tDUCKDB_API void Set(vector<CatalogSearchEntry> new_paths, CatalogSetPathType set_type);\n \tDUCKDB_API void Reset();\n \n-\tDUCKDB_API const vector<CatalogSearchEntry> &Get();\n-\tconst vector<CatalogSearchEntry> &GetSetPaths() {\n+\tDUCKDB_API const vector<CatalogSearchEntry> &Get() const;\n+\tconst vector<CatalogSearchEntry> &GetSetPaths() const {\n \t\treturn set_paths;\n \t}\n-\tDUCKDB_API const CatalogSearchEntry &GetDefault();\n+\tDUCKDB_API const CatalogSearchEntry &GetDefault() const;\n \t//! FIXME: this method is deprecated\n-\tDUCKDB_API string GetDefaultSchema(const string &catalog);\n-\tDUCKDB_API string GetDefaultSchema(ClientContext &context, const string &catalog);\n-\tDUCKDB_API string GetDefaultCatalog(const string &schema);\n+\tDUCKDB_API string GetDefaultSchema(const string &catalog) const;\n+\tDUCKDB_API string GetDefaultSchema(ClientContext &context, const string &catalog) const;\n+\tDUCKDB_API string GetDefaultCatalog(const string &schema) const;\n \n-\tDUCKDB_API vector<string> GetSchemasForCatalog(const string &catalog);\n-\tDUCKDB_API vector<string> GetCatalogsForSchema(const string &schema);\n+\tDUCKDB_API vector<string> GetSchemasForCatalog(const string &catalog) const;\n+\tDUCKDB_API vector<string> GetCatalogsForSchema(const string &schema) const;\n \n-\tDUCKDB_API bool SchemaInSearchPath(ClientContext &context, const string &catalog_name, const string &schema_name);\n+\tDUCKDB_API bool SchemaInSearchPath(ClientContext &context, const string &catalog_name,\n+\t                                   const string &schema_name) const;\n \n private:\n \t//! Set paths without checking if they exist\ndiff --git a/src/include/duckdb/common/multi_file_reader.hpp b/src/include/duckdb/common/multi_file_reader.hpp\nindex 1c73b855c8d7..942f72c1e277 100644\n--- a/src/include/duckdb/common/multi_file_reader.hpp\n+++ b/src/include/duckdb/common/multi_file_reader.hpp\n@@ -168,7 +168,7 @@ struct MultiFileFilterEntry {\n struct MultiFileConstantEntry {\n \tMultiFileConstantEntry(idx_t column_id, Value value_p) : column_id(column_id), value(std::move(value_p)) {\n \t}\n-\t//! The column id to apply the constant value to\n+\t//! The (global) column id to apply the constant value to\n \tidx_t column_id;\n \t//! The constant value\n \tValue value;\n@@ -273,7 +273,7 @@ struct MultiFileReader {\n \t                                      const string &initial_file, const MultiFileReaderBindData &options,\n \t                                      optional_ptr<MultiFileReaderGlobalState> global_state);\n \t//! Populated the filter_map\n-\tDUCKDB_API virtual void CreateFilterMap(const vector<MultiFileReaderColumnDefinition> &global_columns,\n+\tDUCKDB_API virtual void CreateFilterMap(const vector<ColumnIndex> &global_column_ids,\n \t                                        optional_ptr<TableFilterSet> filters, MultiFileReaderData &reader_data,\n \t                                        optional_ptr<MultiFileReaderGlobalState> global_state);\n \ndiff --git a/src/main/config.cpp b/src/main/config.cpp\nindex a69075c6d65a..d48181cd57a6 100644\n--- a/src/main/config.cpp\n+++ b/src/main/config.cpp\n@@ -380,7 +380,13 @@ void DBConfig::AddExtensionOption(const string &name, string description, Logica\n                                   const Value &default_value, set_option_callback_t function) {\n \textension_parameters.insert(\n \t    make_pair(name, ExtensionOption(std::move(description), std::move(parameter), function, default_value)));\n-\tif (!default_value.IsNull()) {\n+\t// copy over unrecognized options, if they match the new extension option\n+\tauto iter = options.unrecognized_options.find(name);\n+\tif (iter != options.unrecognized_options.end()) {\n+\t\toptions.set_variables[name] = iter->second;\n+\t\toptions.unrecognized_options.erase(iter);\n+\t}\n+\tif (!default_value.IsNull() && options.set_variables.find(name) == options.set_variables.end()) {\n \t\t// Default value is set, insert it into the 'set_variables' list\n \t\toptions.set_variables[name] = default_value;\n \t}\ndiff --git a/src/main/database.cpp b/src/main/database.cpp\nindex 084dab6f30c0..f51caaaee6a3 100644\n--- a/src/main/database.cpp\n+++ b/src/main/database.cpp\n@@ -225,10 +225,11 @@ static void ThrowExtensionSetUnrecognizedOptions(const case_insensitive_map_t<Va\n }\n \n void DatabaseInstance::LoadExtensionSettings() {\n-\tauto &unrecognized_options = config.options.unrecognized_options;\n+\t// copy the map, to protect against modifications during\n+\tauto unrecognized_options_copy = config.options.unrecognized_options;\n \n \tif (config.options.autoload_known_extensions) {\n-\t\tif (unrecognized_options.empty()) {\n+\t\tif (unrecognized_options_copy.empty()) {\n \t\t\t// Nothing to do\n \t\t\treturn;\n \t\t}\n@@ -237,7 +238,7 @@ void DatabaseInstance::LoadExtensionSettings() {\n \t\tcon.BeginTransaction();\n \n \t\tvector<string> extension_options;\n-\t\tfor (auto &option : unrecognized_options) {\n+\t\tfor (auto &option : unrecognized_options_copy) {\n \t\t\tauto &name = option.first;\n \t\t\tauto &value = option.second;\n \n@@ -254,18 +255,17 @@ void DatabaseInstance::LoadExtensionSettings() {\n \t\t\tif (it == config.extension_parameters.end()) {\n \t\t\t\tthrow InternalException(\"Extension %s did not provide the '%s' config setting\", extension_name, name);\n \t\t\t}\n+\t\t\t// if the extension provided the option, it should no longer be unrecognized.\n+\t\t\tD_ASSERT(config.options.unrecognized_options.find(name) == config.options.unrecognized_options.end());\n \t\t\tauto &context = *con.context;\n \t\t\tPhysicalSet::SetExtensionVariable(context, it->second, name, SetScope::GLOBAL, value);\n \t\t\textension_options.push_back(name);\n \t\t}\n \n-\t\tfor (auto &option : extension_options) {\n-\t\t\tunrecognized_options.erase(option);\n-\t\t}\n \t\tcon.Commit();\n \t}\n-\tif (!unrecognized_options.empty()) {\n-\t\tThrowExtensionSetUnrecognizedOptions(unrecognized_options);\n+\tif (!config.options.unrecognized_options.empty()) {\n+\t\tThrowExtensionSetUnrecognizedOptions(config.options.unrecognized_options);\n \t}\n }\n \ndiff --git a/src/planner/binder/statement/bind_create_table.cpp b/src/planner/binder/statement/bind_create_table.cpp\nindex 80d50d074e00..15a553b81605 100644\n--- a/src/planner/binder/statement/bind_create_table.cpp\n+++ b/src/planner/binder/statement/bind_create_table.cpp\n@@ -271,13 +271,14 @@ void Binder::BindDefaultValues(const ColumnList &columns, vector<unique_ptr<Expr\n \t\tschema_name = DEFAULT_SCHEMA;\n \t}\n \n-\t// FIXME: We might want to save the existing search path of the binder\n \tvector<CatalogSearchEntry> defaults_search_path;\n \tdefaults_search_path.emplace_back(catalog_name, schema_name);\n \tif (schema_name != DEFAULT_SCHEMA) {\n \t\tdefaults_search_path.emplace_back(catalog_name, DEFAULT_SCHEMA);\n \t}\n-\tentry_retriever.SetSearchPath(std::move(defaults_search_path));\n+\n+\tauto default_binder = Binder::CreateBinder(context, *this);\n+\tdefault_binder->entry_retriever.SetSearchPath(std::move(defaults_search_path));\n \n \tfor (auto &column : columns.Physical()) {\n \t\tunique_ptr<Expression> bound_default;\n@@ -288,9 +289,9 @@ void Binder::BindDefaultValues(const ColumnList &columns, vector<unique_ptr<Expr\n \t\t\tif (default_copy->HasParameter()) {\n \t\t\t\tthrow BinderException(\"DEFAULT values cannot contain parameters\");\n \t\t\t}\n-\t\t\tConstantBinder default_binder(*this, context, \"DEFAULT value\");\n-\t\t\tdefault_binder.target_type = column.Type();\n-\t\t\tbound_default = default_binder.Bind(default_copy);\n+\t\t\tConstantBinder default_value_binder(*default_binder, context, \"DEFAULT value\");\n+\t\t\tdefault_value_binder.target_type = column.Type();\n+\t\t\tbound_default = default_value_binder.Bind(default_copy);\n \t\t} else {\n \t\t\t// no default value specified: push a default value of constant null\n \t\t\tbound_default = make_uniq<BoundConstantExpression>(Value(column.Type()));\ndiff --git a/src/transaction/duck_transaction.cpp b/src/transaction/duck_transaction.cpp\nindex 273f256b6a65..1aa62c20cacc 100644\n--- a/src/transaction/duck_transaction.cpp\n+++ b/src/transaction/duck_transaction.cpp\n@@ -192,6 +192,7 @@ bool DuckTransaction::ShouldWriteToWAL(AttachedDatabase &db) {\n }\n \n ErrorData DuckTransaction::WriteToWAL(AttachedDatabase &db, unique_ptr<StorageCommitState> &commit_state) noexcept {\n+\tErrorData error_data;\n \ttry {\n \t\tD_ASSERT(ShouldWriteToWAL(db));\n \t\tauto &storage_manager = db.GetStorageManager();\n@@ -206,13 +207,20 @@ ErrorData DuckTransaction::WriteToWAL(AttachedDatabase &db, unique_ptr<StorageCo\n \t\t\tstorage_manager.GetBlockManager().FileSync();\n \t\t}\n \t} catch (std::exception &ex) {\n-\t\tif (commit_state) {\n+\t\t// Call RevertCommit() outside this try-catch as it itself may throw\n+\t\terror_data = ErrorData(ex);\n+\t}\n+\n+\tif (commit_state && error_data.HasError()) {\n+\t\ttry {\n \t\t\tcommit_state->RevertCommit();\n \t\t\tcommit_state.reset();\n+\t\t} catch (std::exception &) {\n+\t\t\t// Ignore this error. If we fail to RevertCommit(), just return the original exception\n \t\t}\n-\t\treturn ErrorData(ex);\n \t}\n-\treturn ErrorData();\n+\n+\treturn error_data;\n }\n \n ErrorData DuckTransaction::Commit(AttachedDatabase &db, transaction_t new_commit_id,\n", "test_patch": "diff --git a/test/parquet/test_parquet_schema.test b/test/parquet/test_parquet_schema.test\nindex 1639ae8370fb..77a9dbc5b0f7 100644\n--- a/test/parquet/test_parquet_schema.test\n+++ b/test/parquet/test_parquet_schema.test\n@@ -323,3 +323,26 @@ query III\n SELECT * FROM read_parquet('__TEST_DIR__/15504.parquet', schema=map { 0: { name: 'id', type: 'int32', default_value: NULL }, 1: { name: 'arr', type: 'varchar[]', default_value: NULL }, 2: { name: 's', type: 'STRUCT(key INT, v1 TEXT, v2 TEXT)', default_value: NULL } });\n ----\n 1\t[a, b, c]\t{'key': 1, 'v1': a, 'v2': b}\n+\n+# issue 16094\n+statement ok\n+copy (\n+\tselect\n+\t\tx\n+\tfrom generate_series(1,100) as g(x)\n+) to '__TEST_DIR__/16094.parquet'\n+with (\n+\tfield_ids {x: 1}\n+);\n+\n+statement ok\n+select\n+\tx,\n+\tfilename\n+from read_parquet(\n+\t'__TEST_DIR__/16094.parquet',\n+\tschema=map {\n+\t\t1: {name: 'x', type: 'int', default_value: NULL}\n+\t},\n+\tfilename=True\n+) where x = 1;\ndiff --git a/test/sql/attach/attach_issue16122.test b/test/sql/attach/attach_issue16122.test\nnew file mode 100644\nindex 000000000000..b47365bf20e2\n--- /dev/null\n+++ b/test/sql/attach/attach_issue16122.test\n@@ -0,0 +1,30 @@\n+# name: test/sql/attach/attach_issue16122.test\n+# description: Issue #16122 - Attach binding to incorrect table\n+# group: [attach]\n+\n+require noforcestorage\n+\n+load __TEST_DIR__/issue16122.db\n+\n+\n+statement ok\n+create table mytable (C1 VARCHAR(10));\n+\n+statement ok\n+insert into mytable values ('a');\n+\n+statement ok\n+attach '__TEST_DIR__/issue16122_new.db' as TOMERGE;\n+\n+statement ok\n+create table TOMERGE.mytable (C1 VARCHAR(10));\n+\n+query I\n+insert into TOMERGE.mytable SELECT * FROM mytable;\n+----\n+1\n+\n+query I\n+select * from TOMERGE.mytable;\n+----\n+a\ndiff --git a/test/sql/function/autocomplete/identical_schema_table.test b/test/sql/function/autocomplete/identical_schema_table.test\nnew file mode 100644\nindex 000000000000..9d44a567dc54\n--- /dev/null\n+++ b/test/sql/function/autocomplete/identical_schema_table.test\n@@ -0,0 +1,16 @@\n+# name: test/sql/function/autocomplete/identical_schema_table.test\n+# description: Test sql_auto_complete\n+# group: [autocomplete]\n+\n+require autocomplete\n+\n+statement ok\n+CREATE SCHEMA my_catalog_entry;\n+\n+statement ok\n+CREATE TABLE my_catalog_entry(i INT);\n+\n+query II\n+FROM sql_auto_complete('FROM my_c') LIMIT 1;\n+----\n+my_catalog_entry\t5\ndiff --git a/test/sql/window/window_valid_end.test_slow b/test/sql/window/window_valid_end.test_slow\nnew file mode 100644\nindex 000000000000..276d8220ab24\n--- /dev/null\n+++ b/test/sql/window/window_valid_end.test_slow\n@@ -0,0 +1,35 @@\n+# name: test/sql/window/window_valid_end.test_slow\n+# description: Nasty user test that stresses ValidEnd vectorisation.\n+# group: [window]\n+\n+# This only reproduced in release because debug wrote garbage instead of 0s...\n+statement ok\n+pragma threads=2;\n+\n+loop i 1 100\n+\n+query IIIIII\n+select * from\n+(\n+  select\n+\tcolumn0,\n+\tsale_customer__id,\n+\tyear_total,\n+\tnext_year,\n+\tsale_date__year,\n+    (\n+      first (year_total) over (\n+        partition by\n+          sale_customer__id\n+        order by\n+          sale_date__year\n+        range between 1 following and 1 following\n+      ) \n+    ) as recompute_next_year,\n+  from 'data/csv/issue_16098.csv'\t\n+)\n+where next_year is distinct from recompute_next_year\n+order by all;\n+----\n+\n+endloop\n", "problem_statement": "Auto completion in v1.2.0 is adding a '.' to table names\n### What happens?\n\nWhen using tab completion on a table name without a qualifying schema name, an extra '.' is being appended to the completed name\n\ne.g.\n\n\ud83e\udd86\ud83e\udd86\ud83e\udd86 > .tables\nRussian_tax   reject_scans  rejects\n\ud83e\udd86\ud83e\udd86\ud83e\udd86 > from russ\n\nhitting tab now gives\n\n\ud83e\udd86\ud83e\udd86\ud83e\udd86 > from russian_tax.  <-- extra '.' character\n\nwhereas\n\n\ud83e\udd86\ud83e\udd86\ud83e\udd86 > from main.Russi\n\nhitting tab now gives the correct\n\n\ud83e\udd86\ud83e\udd86\ud83e\udd86 > from main.Russian_tax\n\n\n\n### To Reproduce\n\nSee above CLI examples\n\n### OS:\n\niOS and Debian\n\n### DuckDB Version:\n\n1.2.0\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\nMacbook Pro M3 \n\n### Full Name:\n\nMaurice Hickey\n\n### Affiliation:\n\nNisos\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNo - Other reason (please specify in the issue body)\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nAuto completion in v1.2.0 is adding a '.' to table names\n### What happens?\n\nWhen using tab completion on a table name without a qualifying schema name, an extra '.' is being appended to the completed name\n\ne.g.\n\n\ud83e\udd86\ud83e\udd86\ud83e\udd86 > .tables\nRussian_tax   reject_scans  rejects\n\ud83e\udd86\ud83e\udd86\ud83e\udd86 > from russ\n\nhitting tab now gives\n\n\ud83e\udd86\ud83e\udd86\ud83e\udd86 > from russian_tax.  <-- extra '.' character\n\nwhereas\n\n\ud83e\udd86\ud83e\udd86\ud83e\udd86 > from main.Russi\n\nhitting tab now gives the correct\n\n\ud83e\udd86\ud83e\udd86\ud83e\udd86 > from main.Russian_tax\n\n\n\n### To Reproduce\n\nSee above CLI examples\n\n### OS:\n\niOS and Debian\n\n### DuckDB Version:\n\n1.2.0\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\nMacbook Pro M3 \n\n### Full Name:\n\nMaurice Hickey\n\n### Affiliation:\n\nNisos\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNo - Other reason (please specify in the issue body)\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "\n", "created_at": "2025-02-11T18:37:29Z"}
{"repo": "duckdb/duckdb", "pull_number": 16189, "instance_id": "duckdb__duckdb-16189", "issue_numbers": ["16134", "16134"], "base_commit": "5b8f3542dd62ec1c9f18a96f64088367d770f4bc", "patch": "diff --git a/extension/autocomplete/autocomplete_extension.cpp b/extension/autocomplete/autocomplete_extension.cpp\nindex 62db1f89ae63..609ecbffe834 100644\n--- a/extension/autocomplete/autocomplete_extension.cpp\n+++ b/extension/autocomplete/autocomplete_extension.cpp\n@@ -47,7 +47,10 @@ static vector<AutoCompleteSuggestion> ComputeSuggestions(vector<AutoCompleteCand\n \tfor (idx_t i = 0; i < available_suggestions.size(); i++) {\n \t\tauto &suggestion = available_suggestions[i];\n \t\tconst int32_t BASE_SCORE = 10;\n-\t\tauto &str = suggestion.candidate;\n+\t\tauto str = suggestion.candidate;\n+\t\tif (suggestion.extra_char != '\\0') {\n+\t\t\tstr += suggestion.extra_char;\n+\t\t}\n \t\tauto bonus = suggestion.score_bonus;\n \t\tif (matches.find(str) != matches.end()) {\n \t\t\t// entry already exists\n@@ -73,6 +76,9 @@ static vector<AutoCompleteSuggestion> ComputeSuggestions(vector<AutoCompleteCand\n \t\t\tthrow InternalException(\"Auto-complete match not found\");\n \t\t}\n \t\tauto &suggestion = available_suggestions[entry->second];\n+\t\tif (suggestion.extra_char != '\\0') {\n+\t\t\tresult.pop_back();\n+\t\t}\n \t\tif (suggestion.candidate_type == CandidateType::KEYWORD) {\n \t\t\tif (prefix_is_lower) {\n \t\t\t\tresult = StringUtil::Lower(result);\n", "test_patch": "diff --git a/test/sql/function/autocomplete/identical_schema_table.test b/test/sql/function/autocomplete/identical_schema_table.test\nnew file mode 100644\nindex 000000000000..9d44a567dc54\n--- /dev/null\n+++ b/test/sql/function/autocomplete/identical_schema_table.test\n@@ -0,0 +1,16 @@\n+# name: test/sql/function/autocomplete/identical_schema_table.test\n+# description: Test sql_auto_complete\n+# group: [autocomplete]\n+\n+require autocomplete\n+\n+statement ok\n+CREATE SCHEMA my_catalog_entry;\n+\n+statement ok\n+CREATE TABLE my_catalog_entry(i INT);\n+\n+query II\n+FROM sql_auto_complete('FROM my_c') LIMIT 1;\n+----\n+my_catalog_entry\t5\n", "problem_statement": "Auto completion in v1.2.0 is adding a '.' to table names\n### What happens?\n\nWhen using tab completion on a table name without a qualifying schema name, an extra '.' is being appended to the completed name\n\ne.g.\n\n\ud83e\udd86\ud83e\udd86\ud83e\udd86 > .tables\nRussian_tax   reject_scans  rejects\n\ud83e\udd86\ud83e\udd86\ud83e\udd86 > from russ\n\nhitting tab now gives\n\n\ud83e\udd86\ud83e\udd86\ud83e\udd86 > from russian_tax.  <-- extra '.' character\n\nwhereas\n\n\ud83e\udd86\ud83e\udd86\ud83e\udd86 > from main.Russi\n\nhitting tab now gives the correct\n\n\ud83e\udd86\ud83e\udd86\ud83e\udd86 > from main.Russian_tax\n\n\n\n### To Reproduce\n\nSee above CLI examples\n\n### OS:\n\niOS and Debian\n\n### DuckDB Version:\n\n1.2.0\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\nMacbook Pro M3 \n\n### Full Name:\n\nMaurice Hickey\n\n### Affiliation:\n\nNisos\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNo - Other reason (please specify in the issue body)\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nAuto completion in v1.2.0 is adding a '.' to table names\n### What happens?\n\nWhen using tab completion on a table name without a qualifying schema name, an extra '.' is being appended to the completed name\n\ne.g.\n\n\ud83e\udd86\ud83e\udd86\ud83e\udd86 > .tables\nRussian_tax   reject_scans  rejects\n\ud83e\udd86\ud83e\udd86\ud83e\udd86 > from russ\n\nhitting tab now gives\n\n\ud83e\udd86\ud83e\udd86\ud83e\udd86 > from russian_tax.  <-- extra '.' character\n\nwhereas\n\n\ud83e\udd86\ud83e\udd86\ud83e\udd86 > from main.Russi\n\nhitting tab now gives the correct\n\n\ud83e\udd86\ud83e\udd86\ud83e\udd86 > from main.Russian_tax\n\n\n\n### To Reproduce\n\nSee above CLI examples\n\n### OS:\n\niOS and Debian\n\n### DuckDB Version:\n\n1.2.0\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\nMacbook Pro M3 \n\n### Full Name:\n\nMaurice Hickey\n\n### Affiliation:\n\nNisos\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNo - Other reason (please specify in the issue body)\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "Thanks for opening this issue! Based on our automated check, it seems that your post contains some code but it does not use [code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) to format it.\n          \nPlease double-check your post and revise it if necessary. To employ syntax highlighting, it's recommended to use code blocks with triple backticks, e.g.:\n````\n```sql\nSELECT ...\n```\n````\nIf this is a false positive, feel free to disregard this comment.\n\nThanks for the report!\n\nI cannot reproduce this with only a table - this seems to work correctly for me:\n\n```sql\ncreate table Russian_tax(i int);\nD from sql_auto_complete('from russ') limit 1;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 suggestion  \u2502 suggestion_start \u2502\n\u2502   varchar   \u2502      int32       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Russian_tax \u2502        5         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nOnly when I create a schema with the same name do I get this completion:\n\n```sql\nD create schema Russian_tax;\nD from sql_auto_complete('from russ') limit 1;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  suggestion  \u2502 suggestion_start \u2502\n\u2502   varchar    \u2502      int32       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Russian_tax. \u2502        5         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nDo you perhaps have a schema with this name as well?\n\nIf not, could you provide a full reproducible example including the schema/table definitions.\nThanks for opening this issue in the DuckDB issue tracker! To resolve this issue, our team needs a reproducible example. This includes:\n\n* A source code snippet which reproduces the issue.\n* The snippet should be self-contained, i.e., it should contain all imports and should use relative paths instead of hard coded paths (please avoid `/Users/JohnDoe/...`).\n* A lot of issues can be reproduced with plain SQL code executed in the [DuckDB command line client](https://duckdb.org/docs/api/cli/overview). If you can provide such an example, it greatly simplifies the reproduction process and likely results in a faster fix.\n* If the script needs additional data, please share the data as a CSV, JSON, or Parquet file. Unfortunately, we cannot fix issues that can only be reproduced with a confidential data set. [Support contracts](https://duckdblabs.com/#support) allow sharing confidential data with the core DuckDB team under NDA.\n\nFor more detailed guidelines on how to create reproducible examples, please visit Stack Overflow's [\u201cMinimal, Reproducible Example\u201d](https://stackoverflow.com/help/minimal-reproducible-example) page.\n\nI had a further look ... The \"issue\", if it can be called an \"issue\", occurs when the filename (and I therefore presume the database name) is the same as the table name. e.g file \"russian_tax.duckdb\" and table name \"russian_tax\",  I assume that the CLI tab completion is completing what it thinks is the database or schema  name?\nYes, it seems that if there are duplicates it prefers to suggest database/schema names over tables. We could flip that around - it makes sense to prefer tables imo.\nThanks for opening this issue! Based on our automated check, it seems that your post contains some code but it does not use [code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) to format it.\n          \nPlease double-check your post and revise it if necessary. To employ syntax highlighting, it's recommended to use code blocks with triple backticks, e.g.:\n````\n```sql\nSELECT ...\n```\n````\nIf this is a false positive, feel free to disregard this comment.\n\nThanks for the report!\n\nI cannot reproduce this with only a table - this seems to work correctly for me:\n\n```sql\ncreate table Russian_tax(i int);\nD from sql_auto_complete('from russ') limit 1;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 suggestion  \u2502 suggestion_start \u2502\n\u2502   varchar   \u2502      int32       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Russian_tax \u2502        5         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nOnly when I create a schema with the same name do I get this completion:\n\n```sql\nD create schema Russian_tax;\nD from sql_auto_complete('from russ') limit 1;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  suggestion  \u2502 suggestion_start \u2502\n\u2502   varchar    \u2502      int32       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Russian_tax. \u2502        5         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nDo you perhaps have a schema with this name as well?\n\nIf not, could you provide a full reproducible example including the schema/table definitions.\nThanks for opening this issue in the DuckDB issue tracker! To resolve this issue, our team needs a reproducible example. This includes:\n\n* A source code snippet which reproduces the issue.\n* The snippet should be self-contained, i.e., it should contain all imports and should use relative paths instead of hard coded paths (please avoid `/Users/JohnDoe/...`).\n* A lot of issues can be reproduced with plain SQL code executed in the [DuckDB command line client](https://duckdb.org/docs/api/cli/overview). If you can provide such an example, it greatly simplifies the reproduction process and likely results in a faster fix.\n* If the script needs additional data, please share the data as a CSV, JSON, or Parquet file. Unfortunately, we cannot fix issues that can only be reproduced with a confidential data set. [Support contracts](https://duckdblabs.com/#support) allow sharing confidential data with the core DuckDB team under NDA.\n\nFor more detailed guidelines on how to create reproducible examples, please visit Stack Overflow's [\u201cMinimal, Reproducible Example\u201d](https://stackoverflow.com/help/minimal-reproducible-example) page.\n\nI had a further look ... The \"issue\", if it can be called an \"issue\", occurs when the filename (and I therefore presume the database name) is the same as the table name. e.g file \"russian_tax.duckdb\" and table name \"russian_tax\",  I assume that the CLI tab completion is completing what it thinks is the database or schema  name?\nYes, it seems that if there are duplicates it prefers to suggest database/schema names over tables. We could flip that around - it makes sense to prefer tables imo.", "created_at": "2025-02-11T16:51:09Z"}
{"repo": "duckdb/duckdb", "pull_number": 16181, "instance_id": "duckdb__duckdb-16181", "issue_numbers": ["16122", "16122"], "base_commit": "8b582bcabd995a9bd657c3740737af9f4c833f4c", "patch": "diff --git a/src/catalog/catalog_entry_retriever.cpp b/src/catalog/catalog_entry_retriever.cpp\nindex c37562d72144..eb283de5b4b7 100644\n--- a/src/catalog/catalog_entry_retriever.cpp\n+++ b/src/catalog/catalog_entry_retriever.cpp\n@@ -76,7 +76,7 @@ void CatalogEntryRetriever::Inherit(const CatalogEntryRetriever &parent) {\n \tthis->search_path = parent.search_path;\n }\n \n-CatalogSearchPath &CatalogEntryRetriever::GetSearchPath() {\n+const CatalogSearchPath &CatalogEntryRetriever::GetSearchPath() const {\n \tif (search_path) {\n \t\treturn *search_path;\n \t}\ndiff --git a/src/catalog/catalog_search_path.cpp b/src/catalog/catalog_search_path.cpp\nindex 793de909b9f6..9ce71f283cfe 100644\n--- a/src/catalog/catalog_search_path.cpp\n+++ b/src/catalog/catalog_search_path.cpp\n@@ -189,11 +189,11 @@ void CatalogSearchPath::Set(CatalogSearchEntry new_value, CatalogSetPathType set\n \tSet(std::move(new_paths), set_type);\n }\n \n-const vector<CatalogSearchEntry> &CatalogSearchPath::Get() {\n+const vector<CatalogSearchEntry> &CatalogSearchPath::Get() const {\n \treturn paths;\n }\n \n-string CatalogSearchPath::GetDefaultSchema(const string &catalog) {\n+string CatalogSearchPath::GetDefaultSchema(const string &catalog) const {\n \tfor (auto &path : paths) {\n \t\tif (path.catalog == TEMP_CATALOG) {\n \t\t\tcontinue;\n@@ -205,7 +205,7 @@ string CatalogSearchPath::GetDefaultSchema(const string &catalog) {\n \treturn DEFAULT_SCHEMA;\n }\n \n-string CatalogSearchPath::GetDefaultSchema(ClientContext &context, const string &catalog) {\n+string CatalogSearchPath::GetDefaultSchema(ClientContext &context, const string &catalog) const {\n \tfor (auto &path : paths) {\n \t\tif (path.catalog == TEMP_CATALOG) {\n \t\t\tcontinue;\n@@ -221,7 +221,7 @@ string CatalogSearchPath::GetDefaultSchema(ClientContext &context, const string\n \treturn DEFAULT_SCHEMA;\n }\n \n-string CatalogSearchPath::GetDefaultCatalog(const string &schema) {\n+string CatalogSearchPath::GetDefaultCatalog(const string &schema) const {\n \tif (DefaultSchemaGenerator::IsDefaultSchema(schema)) {\n \t\treturn SYSTEM_CATALOG;\n \t}\n@@ -236,7 +236,7 @@ string CatalogSearchPath::GetDefaultCatalog(const string &schema) {\n \treturn INVALID_CATALOG;\n }\n \n-vector<string> CatalogSearchPath::GetCatalogsForSchema(const string &schema) {\n+vector<string> CatalogSearchPath::GetCatalogsForSchema(const string &schema) const {\n \tvector<string> catalogs;\n \tif (DefaultSchemaGenerator::IsDefaultSchema(schema)) {\n \t\tcatalogs.push_back(SYSTEM_CATALOG);\n@@ -250,7 +250,7 @@ vector<string> CatalogSearchPath::GetCatalogsForSchema(const string &schema) {\n \treturn catalogs;\n }\n \n-vector<string> CatalogSearchPath::GetSchemasForCatalog(const string &catalog) {\n+vector<string> CatalogSearchPath::GetSchemasForCatalog(const string &catalog) const {\n \tvector<string> schemas;\n \tfor (auto &path : paths) {\n \t\tif (StringUtil::CIEquals(path.catalog, catalog)) {\n@@ -260,7 +260,7 @@ vector<string> CatalogSearchPath::GetSchemasForCatalog(const string &catalog) {\n \treturn schemas;\n }\n \n-const CatalogSearchEntry &CatalogSearchPath::GetDefault() {\n+const CatalogSearchEntry &CatalogSearchPath::GetDefault() const {\n \tconst auto &paths = Get();\n \tD_ASSERT(paths.size() >= 2);\n \treturn paths[1];\n@@ -281,7 +281,7 @@ void CatalogSearchPath::SetPathsInternal(vector<CatalogSearchEntry> new_paths) {\n }\n \n bool CatalogSearchPath::SchemaInSearchPath(ClientContext &context, const string &catalog_name,\n-                                           const string &schema_name) {\n+                                           const string &schema_name) const {\n \tfor (auto &path : paths) {\n \t\tif (!StringUtil::CIEquals(path.schema, schema_name)) {\n \t\t\tcontinue;\ndiff --git a/src/include/duckdb/catalog/catalog_entry_retriever.hpp b/src/include/duckdb/catalog/catalog_entry_retriever.hpp\nindex 4e771cdc589e..08425f00ad87 100644\n--- a/src/include/duckdb/catalog/catalog_entry_retriever.hpp\n+++ b/src/include/duckdb/catalog/catalog_entry_retriever.hpp\n@@ -56,7 +56,7 @@ class CatalogEntryRetriever {\n \t                                           OnEntryNotFound on_entry_not_found = OnEntryNotFound::THROW_EXCEPTION,\n \t                                           QueryErrorContext error_context = QueryErrorContext());\n \n-\tCatalogSearchPath &GetSearchPath();\n+\tconst CatalogSearchPath &GetSearchPath() const;\n \tvoid SetSearchPath(vector<CatalogSearchEntry> entries);\n \n \tvoid SetCallback(catalog_entry_callback_t callback);\ndiff --git a/src/include/duckdb/catalog/catalog_search_path.hpp b/src/include/duckdb/catalog/catalog_search_path.hpp\nindex f128a4962e75..e5b6cd254962 100644\n--- a/src/include/duckdb/catalog/catalog_search_path.hpp\n+++ b/src/include/duckdb/catalog/catalog_search_path.hpp\n@@ -48,20 +48,21 @@ class CatalogSearchPath {\n \tDUCKDB_API void Set(vector<CatalogSearchEntry> new_paths, CatalogSetPathType set_type);\n \tDUCKDB_API void Reset();\n \n-\tDUCKDB_API const vector<CatalogSearchEntry> &Get();\n-\tconst vector<CatalogSearchEntry> &GetSetPaths() {\n+\tDUCKDB_API const vector<CatalogSearchEntry> &Get() const;\n+\tconst vector<CatalogSearchEntry> &GetSetPaths() const {\n \t\treturn set_paths;\n \t}\n-\tDUCKDB_API const CatalogSearchEntry &GetDefault();\n+\tDUCKDB_API const CatalogSearchEntry &GetDefault() const;\n \t//! FIXME: this method is deprecated\n-\tDUCKDB_API string GetDefaultSchema(const string &catalog);\n-\tDUCKDB_API string GetDefaultSchema(ClientContext &context, const string &catalog);\n-\tDUCKDB_API string GetDefaultCatalog(const string &schema);\n+\tDUCKDB_API string GetDefaultSchema(const string &catalog) const;\n+\tDUCKDB_API string GetDefaultSchema(ClientContext &context, const string &catalog) const;\n+\tDUCKDB_API string GetDefaultCatalog(const string &schema) const;\n \n-\tDUCKDB_API vector<string> GetSchemasForCatalog(const string &catalog);\n-\tDUCKDB_API vector<string> GetCatalogsForSchema(const string &schema);\n+\tDUCKDB_API vector<string> GetSchemasForCatalog(const string &catalog) const;\n+\tDUCKDB_API vector<string> GetCatalogsForSchema(const string &schema) const;\n \n-\tDUCKDB_API bool SchemaInSearchPath(ClientContext &context, const string &catalog_name, const string &schema_name);\n+\tDUCKDB_API bool SchemaInSearchPath(ClientContext &context, const string &catalog_name,\n+\t                                   const string &schema_name) const;\n \n private:\n \t//! Set paths without checking if they exist\ndiff --git a/src/planner/binder/statement/bind_create_table.cpp b/src/planner/binder/statement/bind_create_table.cpp\nindex 80d50d074e00..15a553b81605 100644\n--- a/src/planner/binder/statement/bind_create_table.cpp\n+++ b/src/planner/binder/statement/bind_create_table.cpp\n@@ -271,13 +271,14 @@ void Binder::BindDefaultValues(const ColumnList &columns, vector<unique_ptr<Expr\n \t\tschema_name = DEFAULT_SCHEMA;\n \t}\n \n-\t// FIXME: We might want to save the existing search path of the binder\n \tvector<CatalogSearchEntry> defaults_search_path;\n \tdefaults_search_path.emplace_back(catalog_name, schema_name);\n \tif (schema_name != DEFAULT_SCHEMA) {\n \t\tdefaults_search_path.emplace_back(catalog_name, DEFAULT_SCHEMA);\n \t}\n-\tentry_retriever.SetSearchPath(std::move(defaults_search_path));\n+\n+\tauto default_binder = Binder::CreateBinder(context, *this);\n+\tdefault_binder->entry_retriever.SetSearchPath(std::move(defaults_search_path));\n \n \tfor (auto &column : columns.Physical()) {\n \t\tunique_ptr<Expression> bound_default;\n@@ -288,9 +289,9 @@ void Binder::BindDefaultValues(const ColumnList &columns, vector<unique_ptr<Expr\n \t\t\tif (default_copy->HasParameter()) {\n \t\t\t\tthrow BinderException(\"DEFAULT values cannot contain parameters\");\n \t\t\t}\n-\t\t\tConstantBinder default_binder(*this, context, \"DEFAULT value\");\n-\t\t\tdefault_binder.target_type = column.Type();\n-\t\t\tbound_default = default_binder.Bind(default_copy);\n+\t\t\tConstantBinder default_value_binder(*default_binder, context, \"DEFAULT value\");\n+\t\t\tdefault_value_binder.target_type = column.Type();\n+\t\t\tbound_default = default_value_binder.Bind(default_copy);\n \t\t} else {\n \t\t\t// no default value specified: push a default value of constant null\n \t\t\tbound_default = make_uniq<BoundConstantExpression>(Value(column.Type()));\n", "test_patch": "diff --git a/test/sql/attach/attach_issue16122.test b/test/sql/attach/attach_issue16122.test\nnew file mode 100644\nindex 000000000000..b47365bf20e2\n--- /dev/null\n+++ b/test/sql/attach/attach_issue16122.test\n@@ -0,0 +1,30 @@\n+# name: test/sql/attach/attach_issue16122.test\n+# description: Issue #16122 - Attach binding to incorrect table\n+# group: [attach]\n+\n+require noforcestorage\n+\n+load __TEST_DIR__/issue16122.db\n+\n+\n+statement ok\n+create table mytable (C1 VARCHAR(10));\n+\n+statement ok\n+insert into mytable values ('a');\n+\n+statement ok\n+attach '__TEST_DIR__/issue16122_new.db' as TOMERGE;\n+\n+statement ok\n+create table TOMERGE.mytable (C1 VARCHAR(10));\n+\n+query I\n+insert into TOMERGE.mytable SELECT * FROM mytable;\n+----\n+1\n+\n+query I\n+select * from TOMERGE.mytable;\n+----\n+a\n", "problem_statement": "v1.2 ATTACH DATABASE not working?\n### What happens?\n\nIs there any difference in attach syntax in version 1.2?\n\n```sql\n.open \"mydb.db\";\ncreate table mytable (C1 VARCHAR(10));\ninsert into mytable values ('a');\nselect * from mytable; -- 1 row\nattach 'mynewdb.db' as TOMERGE;\ncreate table TOMERGE.mytable (C1 VARCHAR(10));\ninsert into TOMERGE.mytable SELECT * FROM mytable;\nselect * from TOMERGE.mytable; -- no rows: error!\nDETACH TOMERGE;\n```\n\n### To Reproduce\n\nPrevious stable version was working\n\n### OS:\n\nWindows 10\n\n### DuckDB Version:\n\n1.2\n\n### DuckDB Client:\n\ncommand line\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nL. Brasio\n\n### Affiliation:\n\nnone\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nv1.2 ATTACH DATABASE not working?\n### What happens?\n\nIs there any difference in attach syntax in version 1.2?\n\n```sql\n.open \"mydb.db\";\ncreate table mytable (C1 VARCHAR(10));\ninsert into mytable values ('a');\nselect * from mytable; -- 1 row\nattach 'mynewdb.db' as TOMERGE;\ncreate table TOMERGE.mytable (C1 VARCHAR(10));\ninsert into TOMERGE.mytable SELECT * FROM mytable;\nselect * from TOMERGE.mytable; -- no rows: error!\nDETACH TOMERGE;\n```\n\n### To Reproduce\n\nPrevious stable version was working\n\n### OS:\n\nWindows 10\n\n### DuckDB Version:\n\n1.2\n\n### DuckDB Client:\n\ncommand line\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nL. Brasio\n\n### Affiliation:\n\nnone\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "\n", "created_at": "2025-02-11T12:53:38Z"}
{"repo": "duckdb/duckdb", "pull_number": 16111, "instance_id": "duckdb__duckdb-16111", "issue_numbers": ["16104"], "base_commit": "cfafb10bb2863b6f8706af66c8cd6d19c167de51", "patch": "diff --git a/src/include/duckdb/optimizer/filter_combiner.hpp b/src/include/duckdb/optimizer/filter_combiner.hpp\nindex 68e22573aae5..979c886930a9 100644\n--- a/src/include/duckdb/optimizer/filter_combiner.hpp\n+++ b/src/include/duckdb/optimizer/filter_combiner.hpp\n@@ -103,8 +103,8 @@ class FilterCombiner {\n \n \texpression_map_t<unique_ptr<Expression>> stored_expressions;\n \texpression_map_t<idx_t> equivalence_set_map;\n-\tunordered_map<idx_t, vector<ExpressionValueInformation>> constant_values;\n-\tunordered_map<idx_t, vector<reference<Expression>>> equivalence_map;\n+\tmap<idx_t, vector<ExpressionValueInformation>> constant_values;\n+\tmap<idx_t, vector<reference<Expression>>> equivalence_map;\n \tidx_t set_index = 0;\n \t//\n \t//\t//! Structures used for OR Filters\n", "test_patch": "diff --git a/test/optimizer/pushdown/issue_16104.test b/test/optimizer/pushdown/issue_16104.test\nnew file mode 100644\nindex 000000000000..2a73b1daba42\n--- /dev/null\n+++ b/test/optimizer/pushdown/issue_16104.test\n@@ -0,0 +1,15 @@\n+# name: test/optimizer/pushdown/issue_16104.test\n+# description: Test expressions in filter preserve the order in Push Down\n+# group: [pushdown]\n+\n+statement ok\n+PRAGMA explain_output = OPTIMIZED_ONLY;\n+\n+statement ok\n+WITH random_data AS (\n+    SELECT random() * 2 AS col_double\n+    FROM generate_series(1, 100)\n+)\n+SELECT *\n+FROM random_data\n+WHERE abs(col_double) < 1 AND acos(col_double) > 0;\n\\ No newline at end of file\n", "problem_statement": "Filter with an error-throwing function getting incorrectly reordered\n### What happens?\n\nSimple `where abs(col_double) < 1 and acos(col_double) > 0` expressions can throw an error as of 1.2.0 because the filters might get reordered with `acos` being executed first while the `abs` expression is guarding against `acos` errors.\n\n### To Reproduce\n\n```sql\ncopy (select random() * 2 col_double from generate_series(1,100)) to '/tmp/r.parquet';\nselect * from (select * from  '/tmp/r.parquet') where abs(col_double) < 1 and acos(col_double) > 0;\n```\n\nOn 1.1.3:\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      col_double      \u2502\n\u2502        double        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  0.19490873625576743 \u2502\n\u2502   0.9895238863469309 \u2502  \n...\n```\n\nOn 1.2.0:\n```\nInvalid Input Error:\nACOS is undefined outside [-1,1]\n```\n\n### OS:\n\nUbuntu 22.04\n\n### DuckDB Version:\n\n1.2.0\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nMarco Slot\n\n### Affiliation:\n\nCrunchy Data\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "", "created_at": "2025-02-07T09:13:57Z"}
{"repo": "duckdb/duckdb", "pull_number": 16070, "instance_id": "duckdb__duckdb-16070", "issue_numbers": ["16052", "16052", "15791"], "base_commit": "3240832cddb955d4240cf2d3adcc053b77c88717", "patch": "diff --git a/.github/actions/build_extensions/action.yml b/.github/actions/build_extensions/action.yml\nindex 3163dff31ff2..c98528ff6a6c 100644\n--- a/.github/actions/build_extensions/action.yml\n+++ b/.github/actions/build_extensions/action.yml\n@@ -233,7 +233,7 @@ runs:\n \n     # Run the unittests (excluding the out-of-tree tests) with the extensions that we deployed to S3\n     - name: Test deployed extensions\n-      if: ${{ inputs.run_tests == 1 }}\n+      if: ${{ inputs.deploy_as != '' && inputs.run_tests == 1 }}\n       shell: bash\n       env:\n         AWS_ACCESS_KEY_ID: ${{ inputs.s3_id }}\ndiff --git a/.github/workflows/BundleStaticLibs.yml b/.github/workflows/BundleStaticLibs.yml\nindex 4757eec2e163..97acc0efebe9 100644\n--- a/.github/workflows/BundleStaticLibs.yml\n+++ b/.github/workflows/BundleStaticLibs.yml\n@@ -93,7 +93,7 @@ jobs:\n           AWS_ACCESS_KEY_ID: ${{ secrets.S3_DUCKDB_STAGING_ID }}\n           AWS_SECRET_ACCESS_KEY: ${{ secrets.S3_DUCKDB_STAGING_KEY }}\n         run: |\n-          python scripts/amalgamation.py\n+          python3 scripts/amalgamation.py\n           zip -j static-lib-osx-${{ matrix.architecture }}.zip src/include/duckdb.h build/release/libduckdb_bundle.a\n           ./scripts/upload-assets-to-staging.sh github_release static-lib-osx-${{ matrix.architecture }}.zip\n \n@@ -124,7 +124,6 @@ jobs:\n \n       - uses: ./.github/actions/build_extensions\n         with:\n-          deploy_as: windows_amd64_mingw\n           duckdb_arch: windows_amd64_mingw\n           vcpkg_target_triplet: x64-mingw-static\n           treat_warn_as_error: 0\n@@ -153,4 +152,91 @@ jobs:\n         with:\n           name: duckdb-static-lib-windows-mingw\n           path: |\n-            static-lib-windows-mingw.zip\n\\ No newline at end of file\n+            static-lib-windows-mingw.zip\n+  bundle-linux-arm64-static-libs:\n+    name: Linux arm64 static libs\n+    runs-on: ubuntu-latest\n+\n+    steps:\n+      - uses: actions/checkout@v4\n+        with:\n+          fetch-depth: 0\n+          ref: ${{ inputs.git_ref }}\n+\n+      - name: Build\n+        shell: bash\n+        run: |\n+          docker run                                                             \\\n+          -v.:/duckdb                                                            \\\n+          -e CC=aarch64-linux-gnu-gcc                                            \\\n+          -e CXX=aarch64-linux-gnu-g++                                           \\\n+          -e CMAKE_BUILD_PARALLEL_LEVEL=2                                        \\\n+          -e OVERRIDE_GIT_DESCRIBE=$OVERRIDE_GIT_DESCRIBE                        \\\n+          -e EXTENSION_CONFIGS='/duckdb/.github/config/bundled_extensions.cmake' \\\n+          -e ENABLE_EXTENSION_AUTOLOADING=1                                      \\\n+          -e ENABLE_EXTENSION_AUTOINSTALL=1                                      \\\n+          -e FORCE_WARN_UNUSED=1                                                 \\\n+          -e DUCKDB_PLATFORM=linux_arm64                                         \\\n+          ubuntu:18.04                                                           \\\n+          bash -c \"/duckdb/scripts/setup_ubuntu1804.sh && git config --global --add safe.directory /duckdb && make bundle-library -C /duckdb\"\n+      - name: Deploy\n+        shell: bash\n+        env:\n+          AWS_ACCESS_KEY_ID: ${{ secrets.S3_DUCKDB_STAGING_ID }}\n+          AWS_SECRET_ACCESS_KEY: ${{ secrets.S3_DUCKDB_STAGING_KEY }}\n+        run: |\n+          python3 scripts/amalgamation.py\n+          zip -j static-lib-linux-arm64.zip src/include/duckdb.h build/release/libduckdb_bundle.a\n+          ./scripts/upload-assets-to-staging.sh github_release static-lib-linux-arm64.zip\n+      - uses: actions/upload-artifact@v4\n+        with:\n+          name: duckdb-static-lib-linux-arm64\n+          path: |\n+            static-lib-linux-arm64.zip\n+  bundle-linux-amd64-static-libs:\n+    name: Linux amd64 static libs\n+    runs-on: ubuntu-latest\n+\n+    steps:\n+      - uses: actions/checkout@v4\n+        with:\n+          fetch-depth: 0\n+          ref: ${{ inputs.git_ref }}\n+\n+      - name: Install pytest\n+        run: |\n+          python3 -m pip install pytest\n+      - name: Build\n+        shell: bash\n+        run: |\n+          export PWD=`pwd`\n+          docker run                                                             \\\n+          -v$PWD:$PWD                                                            \\\n+          -e CMAKE_BUILD_PARALLEL_LEVEL=2                                        \\\n+          -e OVERRIDE_GIT_DESCRIBE=$OVERRIDE_GIT_DESCRIBE                        \\\n+          -e EXTENSION_CONFIGS=\"$PWD/.github/config/bundled_extensions.cmake\"    \\\n+          -e ENABLE_EXTENSION_AUTOLOADING=1                                      \\\n+          -e ENABLE_EXTENSION_AUTOINSTALL=1                                      \\\n+          -e BUILD_BENCHMARK=1                                                   \\\n+          -e FORCE_WARN_UNUSED=1                                                 \\\n+          -e DUCKDB_RUN_PARALLEL_CSV_TESTS=1                                     \\\n+          quay.io/pypa/manylinux2014_x86_64                                      \\\n+          bash -c \"yum install -y perl-IPC-Cmd && git config --global --add safe.directory $PWD && make bundle-library -C $PWD\"\n+      - name: Print platform\n+        shell: bash\n+        run: ./build/release/duckdb -c \"PRAGMA platform;\"\n+\n+      - name: Deploy\n+        shell: bash\n+        env:\n+          AWS_ACCESS_KEY_ID: ${{ secrets.S3_DUCKDB_STAGING_ID }}\n+          AWS_SECRET_ACCESS_KEY: ${{ secrets.S3_DUCKDB_STAGING_KEY }}\n+        run: |\n+          python3 scripts/amalgamation.py\n+          zip -j static-lib-linux-amd64.zip src/include/duckdb.h build/release/libduckdb_bundle.a\n+          ./scripts/upload-assets-to-staging.sh github_release static-lib-linux-amd64.zip\n+      - uses: actions/upload-artifact@v4\n+        with:\n+          name: duckdb-static-lib-linux-amd64\n+          path: |\n+            static-lib-linux-amd64.zip\n\\ No newline at end of file\ndiff --git a/.github/workflows/LinuxRelease.yml b/.github/workflows/LinuxRelease.yml\nindex 7facfe26c94a..2b5f7a7d3769 100644\n--- a/.github/workflows/LinuxRelease.yml\n+++ b/.github/workflows/LinuxRelease.yml\n@@ -123,7 +123,7 @@ jobs:\n       shell: bash\n       if: ${{ inputs.skip_tests != 'true' }}\n       run: |\n-        build/release/benchmark/benchmark_runner benchmark/tpch/sf1/q01.benchmark\n+        build/release/benchmark/benchmark_runner benchmark/micro/update/update_with_join.benchmark\n         build/release/duckdb -c \"COPY (SELECT 42) TO '/dev/stdout' (FORMAT PARQUET)\" | cat\n \n  linux-release-aarch64:\ndiff --git a/.github/workflows/R.yml b/.github/workflows/R.yml\nindex 36400179a812..21afdd29009b 100644\n--- a/.github/workflows/R.yml\n+++ b/.github/workflows/R.yml\n@@ -62,7 +62,6 @@ jobs:\n \n       - uses: ./.github/actions/build_extensions\n         with:\n-          deploy_as: windows_amd64_mingw\n           duckdb_arch: windows_amd64_mingw\n           vcpkg_target_triplet: x64-mingw-static\n           treat_warn_as_error: 0\ndiff --git a/.github/workflows/SwiftRelease.yml b/.github/workflows/SwiftRelease.yml\nindex 9708ae55faf2..0d0d3c4bf875 100644\n--- a/.github/workflows/SwiftRelease.yml\n+++ b/.github/workflows/SwiftRelease.yml\n@@ -61,5 +61,9 @@ jobs:\n           cd source-repo\n           export TAG_NAME=`python3 -c \"import sys, os; sys.path.append(os.path.join('scripts')); import package_build; print(package_build.git_dev_version())\"`\n           cd ..\n-          git -C updated-repo tag -a $TAG_NAME -m \"Release $TAG_NAME\"\n-          git -C updated-repo push origin $TAG_NAME\n+          if [[ $(git -C updated-repo tag -l $TAG_NAME) ]]; then\n+            echo 'Tag '$TAG_NAME' already exists - skipping'\n+          else\n+            git -C updated-repo tag -a $TAG_NAME -m \"Release $TAG_NAME\"\n+            git -C updated-repo push origin $TAG_NAME\n+          fi\ndiff --git a/.github/workflows/Windows.yml b/.github/workflows/Windows.yml\nindex 57b9b41ded0b..c1db5b18b8d3 100644\n--- a/.github/workflows/Windows.yml\n+++ b/.github/workflows/Windows.yml\n@@ -280,7 +280,6 @@ jobs:\n      - uses: ./.github/actions/build_extensions\n        with:\n          vcpkg_target_triplet: x64-windows-static-md\n-         deploy_as: windows_amd64\n          treat_warn_as_error: 0\n          run_tests: ${{ inputs.skip_tests != 'true' && 1 || 0 }}\n          run_autoload_tests: ${{ inputs.skip_tests != 'true' && 1 || 0 }}\ndiff --git a/extension/jemalloc/jemalloc/README.md b/extension/jemalloc/jemalloc/README.md\nindex 81b6669327e9..49bb632e4685 100644\n--- a/extension/jemalloc/jemalloc/README.md\n+++ b/extension/jemalloc/jemalloc/README.md\n@@ -79,6 +79,10 @@ jemalloc_constructor(void) {\n \tif (cpu_count == 0) {\n \t\tcpu_count = duckdb_malloc_ncpus();\n \t}\n+\tunsigned long long narenas = cpu_count / 2;\n+\tif (narenas == 0) {\n+\t    narenas = 1;\n+\t}\n \tunsigned long long bgt_count = cpu_count / 16;\n \tif (bgt_count == 0) {\n \t\tbgt_count = 1;\n@@ -86,9 +90,9 @@ jemalloc_constructor(void) {\n \t// decay is in ms\n \tunsigned long long decay = DUCKDB_JEMALLOC_DECAY * 1000;\n #ifdef DEBUG\n-\tsnprintf(JE_MALLOC_CONF_BUFFER, JE_MALLOC_CONF_BUFFER_SIZE, \"junk:true,oversize_threshold:268435456,dirty_decay_ms:%llu,muzzy_decay_ms:%llu,narenas:%llu,max_background_threads:%llu\", decay, decay, cpu_count / 2, bgt_count);\n+\tsnprintf(JE_MALLOC_CONF_BUFFER, JE_MALLOC_CONF_BUFFER_SIZE, \"junk:true,oversize_threshold:268435456,dirty_decay_ms:%llu,muzzy_decay_ms:%llu,narenas:%llu,max_background_threads:%llu\", decay, decay, narenas, bgt_count);\n #else\n-\tsnprintf(JE_MALLOC_CONF_BUFFER, JE_MALLOC_CONF_BUFFER_SIZE, \"oversize_threshold:268435456,dirty_decay_ms:%llu,muzzy_decay_ms:%llu,narenas:%llu,max_background_threads:%llu\", decay, decay, cpu_count / 2, bgt_count);\n+\tsnprintf(JE_MALLOC_CONF_BUFFER, JE_MALLOC_CONF_BUFFER_SIZE, \"oversize_threshold:268435456,dirty_decay_ms:%llu,muzzy_decay_ms:%llu,narenas:%llu,max_background_threads:%llu\", decay, decay, narenas, bgt_count);\n #endif\n \tje_malloc_conf = JE_MALLOC_CONF_BUFFER;\n \tmalloc_init();\ndiff --git a/extension/jemalloc/jemalloc/src/jemalloc.c b/extension/jemalloc/jemalloc/src/jemalloc.c\nindex 292d553aa360..64dca839ecad 100644\n--- a/extension/jemalloc/jemalloc/src/jemalloc.c\n+++ b/extension/jemalloc/jemalloc/src/jemalloc.c\n@@ -4275,6 +4275,10 @@ jemalloc_constructor(void) {\n \tif (cpu_count == 0) {\n \t\tcpu_count = duckdb_malloc_ncpus();\n \t}\n+\tunsigned long long narenas = cpu_count / 2;\n+\tif (narenas == 0) {\n+\t    narenas = 1;\n+\t}\n \tunsigned long long bgt_count = cpu_count / 16;\n \tif (bgt_count == 0) {\n \t\tbgt_count = 1;\n@@ -4282,9 +4286,9 @@ jemalloc_constructor(void) {\n \t// decay is in ms\n \tunsigned long long decay = DUCKDB_JEMALLOC_DECAY * 1000;\n #ifdef DEBUG\n-\tsnprintf(JE_MALLOC_CONF_BUFFER, JE_MALLOC_CONF_BUFFER_SIZE, \"junk:true,oversize_threshold:268435456,dirty_decay_ms:%llu,muzzy_decay_ms:%llu,narenas:%llu,max_background_threads:%llu\", decay, decay, cpu_count / 2, bgt_count);\n+\tsnprintf(JE_MALLOC_CONF_BUFFER, JE_MALLOC_CONF_BUFFER_SIZE, \"junk:true,oversize_threshold:268435456,dirty_decay_ms:%llu,muzzy_decay_ms:%llu,narenas:%llu,max_background_threads:%llu\", decay, decay, narenas, bgt_count);\n #else\n-\tsnprintf(JE_MALLOC_CONF_BUFFER, JE_MALLOC_CONF_BUFFER_SIZE, \"oversize_threshold:268435456,dirty_decay_ms:%llu,muzzy_decay_ms:%llu,narenas:%llu,max_background_threads:%llu\", decay, decay, cpu_count / 2, bgt_count);\n+\tsnprintf(JE_MALLOC_CONF_BUFFER, JE_MALLOC_CONF_BUFFER_SIZE, \"oversize_threshold:268435456,dirty_decay_ms:%llu,muzzy_decay_ms:%llu,narenas:%llu,max_background_threads:%llu\", decay, decay, narenas, bgt_count);\n #endif\n \tje_malloc_conf = JE_MALLOC_CONF_BUFFER;\n \tmalloc_init();\ndiff --git a/extension/parquet/include/parquet_reader.hpp b/extension/parquet/include/parquet_reader.hpp\nindex df537ea04b32..0061ede2dd14 100644\n--- a/extension/parquet/include/parquet_reader.hpp\n+++ b/extension/parquet/include/parquet_reader.hpp\n@@ -216,12 +216,6 @@ class ParquetReader {\n \tvoid PrepareRowGroupBuffer(ParquetReaderScanState &state, idx_t out_col_idx);\n \tLogicalType DeriveLogicalType(const SchemaElement &s_ele);\n \n-\ttemplate <typename... Args>\n-\tstd::runtime_error FormatException(const string fmt_str, Args... params) {\n-\t\treturn std::runtime_error(\"Failed to read Parquet file \\\"\" + file_name +\n-\t\t                          \"\\\": \" + StringUtil::Format(fmt_str, params...));\n-\t}\n-\n private:\n \tunique_ptr<FileHandle> file_handle;\n };\ndiff --git a/extension/parquet/parquet_reader.cpp b/extension/parquet/parquet_reader.cpp\nindex 6c5fd8f714c6..c16c3b183a9c 100644\n--- a/extension/parquet/parquet_reader.cpp\n+++ b/extension/parquet/parquet_reader.cpp\n@@ -492,7 +492,8 @@ void ParquetReader::InitializeSchema(ClientContext &context) {\n \t}\n \t// check if we like this schema\n \tif (file_meta_data->schema.size() < 2) {\n-\t\tthrow FormatException(\"Need at least one non-root column in the file\");\n+\t\tthrow InvalidInputException(\"Failed to read Parquet file '%s': Need at least one non-root column in the file\",\n+\t\t                            file_name);\n \t}\n \troot_reader = CreateReader(context);\n \tauto &root_type = root_reader->Type();\ndiff --git a/src/common/types/column/column_data_collection.cpp b/src/common/types/column/column_data_collection.cpp\nindex d6e01e5a663d..17be6722389b 100644\n--- a/src/common/types/column/column_data_collection.cpp\n+++ b/src/common/types/column/column_data_collection.cpp\n@@ -799,7 +799,10 @@ static bool IsComplexType(const LogicalType &type) {\n \n void ColumnDataCollection::Append(ColumnDataAppendState &state, DataChunk &input) {\n \tD_ASSERT(!finished_append);\n-\tD_ASSERT(types == input.GetTypes());\n+\t{\n+\t\tauto input_types = input.GetTypes();\n+\t\tD_ASSERT(types == input_types);\n+\t}\n \n \tauto &segment = *segments.back();\n \tfor (idx_t vector_idx = 0; vector_idx < types.size(); vector_idx++) {\ndiff --git a/src/execution/index/fixed_size_allocator.cpp b/src/execution/index/fixed_size_allocator.cpp\nindex 860e45d46ff5..7da8b547899d 100644\n--- a/src/execution/index/fixed_size_allocator.cpp\n+++ b/src/execution/index/fixed_size_allocator.cpp\n@@ -253,6 +253,12 @@ FixedSizeAllocatorInfo FixedSizeAllocator::GetInfo() const {\n \n \tfor (const auto &buffer : buffers) {\n \t\tinfo.buffer_ids.push_back(buffer.first);\n+\n+\t\t// Memory safety check.\n+\t\tif (buffer.first > idx_t(MAX_ROW_ID)) {\n+\t\t\tthrow InternalException(\"Initializing invalid buffer ID in FixedSizeAllocator::GetInfo\");\n+\t\t}\n+\n \t\tinfo.block_pointers.push_back(buffer.second->block_pointer);\n \t\tinfo.segment_counts.push_back(buffer.second->segment_count);\n \t\tinfo.allocation_sizes.push_back(buffer.second->allocation_size);\n@@ -289,6 +295,12 @@ void FixedSizeAllocator::Init(const FixedSizeAllocatorInfo &info) {\n \n \t\t// read all FixedSizeBuffer data\n \t\tauto buffer_id = info.buffer_ids[i];\n+\n+\t\t// Memory safety check.\n+\t\tif (buffer_id > idx_t(MAX_ROW_ID)) {\n+\t\t\tthrow InternalException(\"Initializing invalid buffer ID in FixedSizeAllocator::Init\");\n+\t\t}\n+\n \t\tauto buffer_block_pointer = info.block_pointers[i];\n \t\tauto segment_count = info.segment_counts[i];\n \t\tauto allocation_size = info.allocation_sizes[i];\ndiff --git a/src/execution/index/unbound_index.cpp b/src/execution/index/unbound_index.cpp\nindex b8173d751243..86f224feede4 100644\n--- a/src/execution/index/unbound_index.cpp\n+++ b/src/execution/index/unbound_index.cpp\n@@ -14,6 +14,16 @@ UnboundIndex::UnboundIndex(unique_ptr<CreateInfo> create_info, IndexStorageInfo\n                            TableIOManager &table_io_manager, AttachedDatabase &db)\n     : Index(create_info->Cast<CreateIndexInfo>().column_ids, table_io_manager, db), create_info(std::move(create_info)),\n       storage_info(std::move(storage_info_p)) {\n+\n+\t// Memory safety check.\n+\tfor (idx_t info_idx = 0; info_idx < storage_info.allocator_infos.size(); info_idx++) {\n+\t\tauto &info = storage_info.allocator_infos[info_idx];\n+\t\tfor (idx_t buffer_idx = 0; buffer_idx < info.buffer_ids.size(); buffer_idx++) {\n+\t\t\tif (info.buffer_ids[buffer_idx] > idx_t(MAX_ROW_ID)) {\n+\t\t\t\tthrow InternalException(\"Found invalid buffer ID in UnboundIndex constructor\");\n+\t\t\t}\n+\t\t}\n+\t}\n }\n \n void UnboundIndex::CommitDrop() {\ndiff --git a/src/execution/operator/persistent/physical_insert.cpp b/src/execution/operator/persistent/physical_insert.cpp\nindex a3c6619ed5e9..161fa8f58a20 100644\n--- a/src/execution/operator/persistent/physical_insert.cpp\n+++ b/src/execution/operator/persistent/physical_insert.cpp\n@@ -253,6 +253,7 @@ static void CreateUpdateChunk(ExecutionContext &context, DataChunk &chunk, Table\n \t\t\tchunk.SetCardinality(selection.Count());\n \t\t\t// Also apply this Slice to the to-update row_ids\n \t\t\trow_ids.Slice(selection.Selection(), selection.Count());\n+\t\t\trow_ids.Flatten(selection.Count());\n \t\t}\n \t}\n \n@@ -271,8 +272,9 @@ static void CreateUpdateChunk(ExecutionContext &context, DataChunk &chunk, Table\n }\n \n template <bool GLOBAL>\n-static idx_t PerformOnConflictAction(InsertLocalState &lstate, ExecutionContext &context, DataChunk &chunk,\n-                                     TableCatalogEntry &table, Vector &row_ids, const PhysicalInsert &op) {\n+static idx_t PerformOnConflictAction(InsertLocalState &lstate, InsertGlobalState &gstate, ExecutionContext &context,\n+                                     DataChunk &chunk, TableCatalogEntry &table, Vector &row_ids,\n+                                     const PhysicalInsert &op) {\n \t// Early-out, if we do nothing on conflicting rows.\n \tif (op.action_type == OnConflictAction::NOTHING) {\n \t\treturn 0;\n@@ -283,15 +285,8 @@ static idx_t PerformOnConflictAction(InsertLocalState &lstate, ExecutionContext\n \tCreateUpdateChunk(context, chunk, table, row_ids, update_chunk, op);\n \tauto &data_table = table.GetStorage();\n \n-\t// Perform the UPDATE on the (global) storage.\n-\tif (!op.update_is_del_and_insert) {\n-\t\tif (GLOBAL) {\n-\t\t\tauto update_state = data_table.InitializeUpdate(table, context.client, op.bound_constraints);\n-\t\t\tdata_table.Update(*update_state, context.client, row_ids, set_columns, update_chunk);\n-\t\t\treturn update_chunk.size();\n-\t\t}\n-\t\tauto &local_storage = LocalStorage::Get(context.client, data_table.db);\n-\t\tlocal_storage.Update(data_table, row_ids, set_columns, update_chunk);\n+\tif (update_chunk.size() == 0) {\n+\t\t// Nothing to do\n \t\treturn update_chunk.size();\n \t}\n \n@@ -305,6 +300,27 @@ static idx_t PerformOnConflictAction(InsertLocalState &lstate, ExecutionContext\n \t\tappend_chunk.data[set_columns[i].index].Reference(update_chunk.data[i]);\n \t}\n \n+\t// Perform the UPDATE on the (global) storage.\n+\tif (!op.update_is_del_and_insert) {\n+\t\tif (!op.parallel && op.return_chunk) {\n+\t\t\tgstate.return_collection.Append(append_chunk);\n+\t\t}\n+\n+\t\tif (GLOBAL) {\n+\t\t\tauto update_state = data_table.InitializeUpdate(table, context.client, op.bound_constraints);\n+\t\t\tdata_table.Update(*update_state, context.client, row_ids, set_columns, update_chunk);\n+\t\t\treturn update_chunk.size();\n+\t\t}\n+\t\tauto &local_storage = LocalStorage::Get(context.client, data_table.db);\n+\t\tif (gstate.initialized) {\n+\t\t\t// Flush the data first, it might be referenced by the Update\n+\t\t\tdata_table.FinalizeLocalAppend(gstate.append_state);\n+\t\t\tgstate.initialized = false;\n+\t\t}\n+\t\tlocal_storage.Update(data_table, row_ids, set_columns, update_chunk);\n+\t\treturn update_chunk.size();\n+\t}\n+\n \tif (GLOBAL) {\n \t\tauto &delete_state = lstate.GetDeleteState(data_table, table, context.client);\n \t\tdata_table.Delete(delete_state, context.client, row_ids, update_chunk.size());\n@@ -313,6 +329,9 @@ static idx_t PerformOnConflictAction(InsertLocalState &lstate, ExecutionContext\n \t\tlocal_storage.Delete(data_table, row_ids, update_chunk.size());\n \t}\n \n+\tif (!op.parallel && op.return_chunk) {\n+\t\tgstate.return_collection.Append(append_chunk);\n+\t}\n \tdata_table.LocalAppend(table, context.client, append_chunk, op.bound_constraints, row_ids, append_chunk);\n \treturn update_chunk.size();\n }\n@@ -365,8 +384,8 @@ static void CheckDistinctnessInternal(ValidityMask &valid, vector<reference<Vect\n \t}\n }\n \n-void PrepareSortKeys(DataChunk &input, unordered_map<column_t, unique_ptr<Vector>> &sort_keys,\n-                     const unordered_set<column_t> &column_ids) {\n+static void PrepareSortKeys(DataChunk &input, unordered_map<column_t, unique_ptr<Vector>> &sort_keys,\n+                            const unordered_set<column_t> &column_ids) {\n \tOrderModifiers order_modifiers(OrderType::ASCENDING, OrderByNullType::NULLS_LAST);\n \tfor (auto &it : column_ids) {\n \t\tauto &sort_key = sort_keys[it];\n@@ -448,7 +467,7 @@ static void VerifyOnConflictCondition(ExecutionContext &context, DataChunk &comb\n \n template <bool GLOBAL>\n static idx_t HandleInsertConflicts(TableCatalogEntry &table, ExecutionContext &context, InsertLocalState &lstate,\n-                                   DataChunk &tuples, const PhysicalInsert &op) {\n+                                   InsertGlobalState &gstate, DataChunk &tuples, const PhysicalInsert &op) {\n \tauto &types_to_fetch = op.types_to_fetch;\n \tauto &on_conflict_condition = op.on_conflict_condition;\n \tauto &conflict_target = op.conflict_target;\n@@ -518,7 +537,7 @@ static idx_t HandleInsertConflicts(TableCatalogEntry &table, ExecutionContext &c\n \t\tRegisterUpdatedRows(lstate, row_ids, combined_chunk.size());\n \t}\n \n-\taffected_tuples += PerformOnConflictAction<GLOBAL>(lstate, context, combined_chunk, table, row_ids, op);\n+\taffected_tuples += PerformOnConflictAction<GLOBAL>(lstate, gstate, context, combined_chunk, table, row_ids, op);\n \n \t// Remove the conflicting tuples from the insert chunk\n \tSelectionVector sel_vec(tuples.size());\n@@ -598,6 +617,11 @@ idx_t PhysicalInsert::OnConflictHandling(TableCatalogEntry &table, ExecutionCont\n \t\t\t}\n \t\t}\n \t\tif (action_type == OnConflictAction::UPDATE) {\n+\t\t\tif (do_update_condition) {\n+\t\t\t\t//! See https://github.com/duckdblabs/duckdb-internal/issues/4090 for context\n+\t\t\t\tthrow NotImplementedException(\"Inner conflicts detected with a conditional DO UPDATE on-conflict \"\n+\t\t\t\t                              \"action, not fully implemented yet\");\n+\t\t\t}\n \t\t\tManagedSelection last_occurrences(last_occurrences_of_conflict.size());\n \t\t\tfor (auto &idx : last_occurrences_of_conflict) {\n \t\t\t\tlast_occurrences.Append(idx);\n@@ -615,9 +639,9 @@ idx_t PhysicalInsert::OnConflictHandling(TableCatalogEntry &table, ExecutionCont\n \t// Check whether any conflicts arise, and if they all meet the conflict_target + condition\n \t// If that's not the case - We throw the first error\n \tidx_t updated_tuples = 0;\n-\tupdated_tuples += HandleInsertConflicts<true>(table, context, lstate, lstate.insert_chunk, *this);\n+\tupdated_tuples += HandleInsertConflicts<true>(table, context, lstate, gstate, lstate.insert_chunk, *this);\n \t// Also check the transaction-local storage+ART so we can detect conflicts within this transaction\n-\tupdated_tuples += HandleInsertConflicts<false>(table, context, lstate, lstate.insert_chunk, *this);\n+\tupdated_tuples += HandleInsertConflicts<false>(table, context, lstate, gstate, lstate.insert_chunk, *this);\n \n \treturn updated_tuples;\n }\n@@ -636,31 +660,22 @@ SinkResultType PhysicalInsert::Sink(ExecutionContext &context, DataChunk &chunk,\n \t\t\tgstate.initialized = true;\n \t\t}\n \n-\t\tif (action_type != OnConflictAction::NOTHING && return_chunk) {\n-\t\t\t// If the action is UPDATE or REPLACE, we will always create either an APPEND or an INSERT\n-\t\t\t// for NOTHING we don't create either an APPEND or an INSERT for the tuple\n-\t\t\t// so it should not be added to the RETURNING chunk\n-\t\t\tgstate.return_collection.Append(lstate.insert_chunk);\n-\t\t}\n \t\tidx_t updated_tuples = OnConflictHandling(table, context, gstate, lstate);\n-\t\tif (action_type == OnConflictAction::NOTHING && return_chunk) {\n-\t\t\t// Because we didn't add to the RETURNING chunk yet\n-\t\t\t// we add the tuples that did not get filtered out now\n-\t\t\tgstate.return_collection.Append(lstate.insert_chunk);\n-\t\t}\n+\n \t\tgstate.insert_count += lstate.insert_chunk.size();\n \t\tgstate.insert_count += updated_tuples;\n+\t\tif (!parallel && return_chunk) {\n+\t\t\tgstate.return_collection.Append(lstate.insert_chunk);\n+\t\t}\n \t\tstorage.LocalAppend(gstate.append_state, context.client, lstate.insert_chunk, true);\n \t\tif (action_type == OnConflictAction::UPDATE && lstate.update_chunk.size() != 0) {\n-\t\t\t// Flush the append so we can target the data we just appended with the update\n-\t\t\tstorage.FinalizeLocalAppend(gstate.append_state);\n-\t\t\tgstate.initialized = false;\n-\t\t\t(void)HandleInsertConflicts<true>(table, context, lstate, lstate.update_chunk, *this);\n-\t\t\t(void)HandleInsertConflicts<false>(table, context, lstate, lstate.update_chunk, *this);\n+\t\t\t(void)HandleInsertConflicts<true>(table, context, lstate, gstate, lstate.update_chunk, *this);\n+\t\t\t(void)HandleInsertConflicts<false>(table, context, lstate, gstate, lstate.update_chunk, *this);\n \t\t\t// All of the tuples should have been turned into an update, leaving the chunk empty afterwards\n \t\t\tD_ASSERT(lstate.update_chunk.size() == 0);\n \t\t}\n \t} else {\n+\t\t//! FIXME: can't we enable this by using a BatchedDataCollection ?\n \t\tD_ASSERT(!return_chunk);\n \t\t// parallel append\n \t\tif (!lstate.local_collection) {\ndiff --git a/src/execution/operator/schema/physical_attach.cpp b/src/execution/operator/schema/physical_attach.cpp\nindex 3d3d7b187d44..523f0d57ea32 100644\n--- a/src/execution/operator/schema/physical_attach.cpp\n+++ b/src/execution/operator/schema/physical_attach.cpp\n@@ -25,9 +25,6 @@ SourceResultType PhysicalAttach::GetData(ExecutionContext &context, DataChunk &c\n \tif (options.db_type.empty()) {\n \t\tDBPathAndType::ExtractExtensionPrefix(path, options.db_type);\n \t}\n-\tif (!config.options.enable_external_access && !options.db_type.empty()) {\n-\t\tthrow PermissionException(\"Attaching external databases is disabled through configuration\");\n-\t}\n \tif (name.empty()) {\n \t\tauto &fs = FileSystem::GetFileSystem(context.client);\n \t\tname = AttachedDatabase::ExtractDatabaseName(path, fs);\ndiff --git a/src/execution/sample/reservoir_sample.cpp b/src/execution/sample/reservoir_sample.cpp\nindex 58056920eaf8..b28bed81b0e9 100644\n--- a/src/execution/sample/reservoir_sample.cpp\n+++ b/src/execution/sample/reservoir_sample.cpp\n@@ -551,7 +551,7 @@ void ReservoirSample::ExpandSerializedSample() {\n }\n \n idx_t ReservoirSample::GetReservoirChunkCapacity() const {\n-\treturn sample_count + (FIXED_SAMPLE_SIZE_MULTIPLIER * FIXED_SAMPLE_SIZE);\n+\treturn sample_count + (FIXED_SAMPLE_SIZE_MULTIPLIER * MinValue<idx_t>(sample_count, FIXED_SAMPLE_SIZE));\n }\n \n idx_t ReservoirSample::FillReservoir(DataChunk &chunk) {\ndiff --git a/src/function/table/table_scan.cpp b/src/function/table/table_scan.cpp\nindex 5317f49ffa52..0cf85d64a2b9 100644\n--- a/src/function/table/table_scan.cpp\n+++ b/src/function/table/table_scan.cpp\n@@ -576,7 +576,8 @@ unique_ptr<GlobalTableFunctionState> TableScanInitGlobal(ClientContext &context,\n \t}\n \n \t// The checkpoint lock ensures that we do not checkpoint while scanning this table.\n-\tauto checkpoint_lock = storage.GetSharedCheckpointLock();\n+\tauto &transaction = DuckTransaction::Get(context, storage.db);\n+\tauto checkpoint_lock = transaction.SharedLockTable(*storage.GetDataTableInfo());\n \tauto &info = storage.GetDataTableInfo();\n \tauto &indexes = info->GetIndexes();\n \tif (indexes.Empty()) {\ndiff --git a/src/include/duckdb/execution/index/fixed_size_allocator.hpp b/src/include/duckdb/execution/index/fixed_size_allocator.hpp\nindex d4a1b708def8..3b2e4c28781c 100644\n--- a/src/include/duckdb/execution/index/fixed_size_allocator.hpp\n+++ b/src/include/duckdb/execution/index/fixed_size_allocator.hpp\n@@ -54,8 +54,9 @@ class FixedSizeAllocator {\n \t\tD_ASSERT(ptr.GetOffset() < available_segments_per_buffer);\n \t\tD_ASSERT(buffers.find(ptr.GetBufferId()) != buffers.end());\n \n-\t\tauto &buffer = buffers.find(ptr.GetBufferId())->second;\n-\t\tauto buffer_ptr = buffer->Get(dirty);\n+\t\tauto buffer_it = buffers.find(ptr.GetBufferId());\n+\t\tD_ASSERT(buffer_it != buffers.end());\n+\t\tauto buffer_ptr = buffer_it->second->Get(dirty);\n \t\treturn buffer_ptr + ptr.GetOffset() * segment_size + bitmask_offset;\n \t}\n \ndiff --git a/src/include/duckdb/main/extension_helper.hpp b/src/include/duckdb/main/extension_helper.hpp\nindex 7a7c3ed9e9cf..3c5e04cbe4f8 100644\n--- a/src/include/duckdb/main/extension_helper.hpp\n+++ b/src/include/duckdb/main/extension_helper.hpp\n@@ -236,6 +236,7 @@ class ExtensionHelper {\n \n \tstatic bool IsRelease(const string &version_tag);\n \tstatic bool CreateSuggestions(const string &extension_name, string &message);\n+\tstatic string ExtensionInstallDocumentationLink(const string &extension_name);\n \n private:\n \tstatic unique_ptr<ExtensionInstallInfo> InstallExtensionInternal(DatabaseInstance &db, FileSystem &fs,\ndiff --git a/src/include/duckdb/planner/table_filter.hpp b/src/include/duckdb/planner/table_filter.hpp\nindex b39d529b0873..290f789da1b8 100644\n--- a/src/include/duckdb/planner/table_filter.hpp\n+++ b/src/include/duckdb/planner/table_filter.hpp\n@@ -52,7 +52,7 @@ class TableFilter {\n \tstring DebugToString();\n \tvirtual unique_ptr<TableFilter> Copy() const = 0;\n \tvirtual bool Equals(const TableFilter &other) const {\n-\t\treturn filter_type != other.filter_type;\n+\t\treturn filter_type == other.filter_type;\n \t}\n \tvirtual unique_ptr<Expression> ToExpression(const Expression &column) const = 0;\n \ndiff --git a/src/main/extension/extension_install.cpp b/src/main/extension/extension_install.cpp\nindex e8ab595ab0b7..b36e1b46f9f2 100644\n--- a/src/main/extension/extension_install.cpp\n+++ b/src/main/extension/extension_install.cpp\n@@ -56,6 +56,18 @@ const vector<string> ExtensionHelper::PathComponents() {\n \treturn vector<string> {GetVersionDirectoryName(), DuckDB::Platform()};\n }\n \n+string ExtensionHelper::ExtensionInstallDocumentationLink(const string &extension_name) {\n+\tauto components = PathComponents();\n+\n+\tstring link = \"https://duckdb.org/docs/extensions/troubleshooting\";\n+\n+\tif (components.size() >= 2) {\n+\t\tlink += \"/?version=\" + components[0] + \"&platform=\" + components[1] + \"&extension=\" + extension_name;\n+\t}\n+\n+\treturn link;\n+}\n+\n duckdb::string ExtensionHelper::DefaultExtensionFolder(FileSystem &fs) {\n \tstring home_directory = fs.GetHomeDirectory();\n \t// exception if the home directory does not exist, don't create whatever we think is home\n@@ -444,9 +456,11 @@ static unique_ptr<ExtensionInstallInfo> InstallFromHttpUrl(DatabaseInstance &db,\n \t\tif (!should_retry || retry_count >= MAX_RETRY_COUNT) {\n \t\t\t// if we should not retry or exceeded the number of retries - bubble up the error\n \t\t\tstring message;\n-\t\t\tauto exact_match = ExtensionHelper::CreateSuggestions(extension_name, message);\n-\t\t\tif (exact_match && !ExtensionHelper::IsRelease(DuckDB::LibraryVersion())) {\n-\t\t\t\tmessage += \"\\nAre you using a development build? In this case, extensions might not (yet) be uploaded.\";\n+\t\t\tExtensionHelper::CreateSuggestions(extension_name, message);\n+\n+\t\t\tauto documentation_link = ExtensionHelper::ExtensionInstallDocumentationLink(extension_name);\n+\t\t\tif (!documentation_link.empty()) {\n+\t\t\t\tmessage += \"\\nFor more info, visit \" + documentation_link;\n \t\t\t}\n \t\t\tif (res.error() == duckdb_httplib::Error::Success) {\n \t\t\t\tthrow HTTPException(res.value(), \"Failed to download extension \\\"%s\\\" at URL \\\"%s%s\\\" (HTTP %n)\\n%s\",\ndiff --git a/src/optimizer/remove_unused_columns.cpp b/src/optimizer/remove_unused_columns.cpp\nindex b197a4f5f986..48ea7cbffe83 100644\n--- a/src/optimizer/remove_unused_columns.cpp\n+++ b/src/optimizer/remove_unused_columns.cpp\n@@ -261,9 +261,6 @@ void RemoveUnusedColumns::VisitOperator(LogicalOperator &op) {\n \t\t\t\tif (entry == column_references.end()) {\n \t\t\t\t\tthrow InternalException(\"RemoveUnusedColumns - could not find referenced column\");\n \t\t\t\t}\n-\t\t\t\tif (final_column_ids[col_sel_idx].HasChildren()) {\n-\t\t\t\t\tthrow InternalException(\"RemoveUnusedColumns - LogicalGet::column_ids already has children\");\n-\t\t\t\t}\n \t\t\t\tColumnIndex new_index(final_column_ids[col_sel_idx].GetPrimaryIndex(), entry->second.child_columns);\n \t\t\t\tcolumn_ids.emplace_back(new_index);\n \t\t\t}\ndiff --git a/src/planner/binder/expression/bind_star_expression.cpp b/src/planner/binder/expression/bind_star_expression.cpp\nindex 179fad7da38a..fa9f004ee53d 100644\n--- a/src/planner/binder/expression/bind_star_expression.cpp\n+++ b/src/planner/binder/expression/bind_star_expression.cpp\n@@ -145,7 +145,7 @@ void TryTransformStarLike(unique_ptr<ParsedExpression> &root) {\n \t\treturn;\n \t}\n \tauto &function = root->Cast<FunctionExpression>();\n-\tif (function.children.size() != 2) {\n+\tif (function.children.size() < 2 || function.children.size() > 3) {\n \t\treturn;\n \t}\n \tauto &left = function.children[0];\n@@ -158,7 +158,17 @@ void TryTransformStarLike(unique_ptr<ParsedExpression> &root) {\n \t\t// COLUMNS(*) has different semantics\n \t\treturn;\n \t}\n-\tunordered_set<string> supported_ops {\"~~\", \"!~~\", \"~~~\", \"!~~~\", \"~~*\", \"!~~*\", \"regexp_full_match\"};\n+\tunordered_set<string> supported_ops {\"~~\",\n+\t                                     \"!~~\",\n+\t                                     \"~~~\",\n+\t                                     \"!~~~\",\n+\t                                     \"~~*\",\n+\t                                     \"!~~*\",\n+\t                                     \"regexp_full_match\",\n+\t                                     \"not_like_escape\",\n+\t                                     \"ilike_escape\",\n+\t                                     \"not_ilike_escape\",\n+\t                                     \"like_escape\"};\n \tif (supported_ops.count(function.function_name) == 0) {\n \t\t// unsupported op for * expression\n \t\tthrow BinderException(*root, \"Function \\\"%s\\\" cannot be applied to a star expression\", function.function_name);\ndiff --git a/src/planner/binder/tableref/bind_table_function.cpp b/src/planner/binder/tableref/bind_table_function.cpp\nindex 29d68f3fc3ab..ace96207bf98 100644\n--- a/src/planner/binder/tableref/bind_table_function.cpp\n+++ b/src/planner/binder/tableref/bind_table_function.cpp\n@@ -203,8 +203,12 @@ unique_ptr<LogicalOperator> Binder::BindTableFunctionInternal(TableFunction &tab\n \t\tif (table_function.bind_replace) {\n \t\t\tauto new_plan = table_function.bind_replace(context, bind_input);\n \t\t\tif (new_plan) {\n-\t\t\t\tnew_plan->alias = ref.alias;\n-\t\t\t\tnew_plan->column_name_alias = ref.column_name_alias;\n+\t\t\t\tif (!ref.alias.empty()) {\n+\t\t\t\t\tnew_plan->alias = ref.alias;\n+\t\t\t\t}\n+\t\t\t\tif (!ref.column_name_alias.empty()) {\n+\t\t\t\t\tnew_plan->column_name_alias = ref.column_name_alias;\n+\t\t\t\t}\n \t\t\t\treturn CreatePlan(*Bind(*new_plan));\n \t\t\t} else if (!table_function.bind) {\n \t\t\t\tthrow BinderException(\"Failed to bind \\\"%s\\\": nullptr returned from bind_replace without bind function\",\ndiff --git a/src/storage/local_storage.cpp b/src/storage/local_storage.cpp\nindex cbbf64df28f8..93dccfcba763 100644\n--- a/src/storage/local_storage.cpp\n+++ b/src/storage/local_storage.cpp\n@@ -474,6 +474,7 @@ idx_t LocalStorage::Delete(DataTable &table, Vector &row_ids, idx_t count) {\n \n void LocalStorage::Update(DataTable &table, Vector &row_ids, const vector<PhysicalIndex> &column_ids,\n                           DataChunk &updates) {\n+\tD_ASSERT(updates.size() >= 1);\n \tauto storage = table_manager.GetStorage(table);\n \tD_ASSERT(storage);\n \ndiff --git a/src/storage/table/row_group_collection.cpp b/src/storage/table/row_group_collection.cpp\nindex 2629800a4be8..dc0a7eb47eb7 100644\n--- a/src/storage/table/row_group_collection.cpp\n+++ b/src/storage/table/row_group_collection.cpp\n@@ -593,6 +593,7 @@ idx_t RowGroupCollection::Delete(TransactionData transaction, DataTable &table,\n //===--------------------------------------------------------------------===//\n void RowGroupCollection::Update(TransactionData transaction, row_t *ids, const vector<PhysicalIndex> &column_ids,\n                                 DataChunk &updates) {\n+\tD_ASSERT(updates.size() >= 1);\n \tidx_t pos = 0;\n \tdo {\n \t\tidx_t start = pos;\ndiff --git a/third_party/fmt/include/fmt/format.h b/third_party/fmt/include/fmt/format.h\nindex e92437a2ed8e..ad4fe83ab438 100644\n--- a/third_party/fmt/include/fmt/format.h\n+++ b/third_party/fmt/include/fmt/format.h\n@@ -548,7 +548,7 @@ class u8string_view : public basic_string_view<fmt_char8_t> {\n \n #if FMT_USE_USER_DEFINED_LITERALS\n inline namespace literals {\n-inline u8string_view operator\"\"_u(const char* s, std::size_t n) {\n+inline u8string_view operator\"\" _u(const char* s, std::size_t n) {\n   return {s, n};\n }\n }  // namespace literals\n@@ -3342,11 +3342,11 @@ FMT_CONSTEXPR internal::udl_formatter<Char, CHARS...> operator\"\"_format() {\n     std::string message = \"The answer is {}\"_format(42);\n   \\endrst\n  */\n-FMT_CONSTEXPR internal::udl_formatter<char> operator\"\"_format(const char* s,\n+FMT_CONSTEXPR internal::udl_formatter<char> operator\"\" _format(const char* s,\n                                                                std::size_t n) {\n   return {{s, n}};\n }\n-FMT_CONSTEXPR internal::udl_formatter<wchar_t> operator\"\"_format(\n+FMT_CONSTEXPR internal::udl_formatter<wchar_t> operator\"\" _format(\n     const wchar_t* s, std::size_t n) {\n   return {{s, n}};\n }\n@@ -3362,11 +3362,11 @@ FMT_CONSTEXPR internal::udl_formatter<wchar_t> operator\"\"_format(\n     fmt::print(\"Elapsed time: {s:.2f} seconds\", \"s\"_a=1.23);\n   \\endrst\n  */\n-FMT_CONSTEXPR internal::udl_arg<char> operator\"\"_a(const char* s,\n+FMT_CONSTEXPR internal::udl_arg<char> operator\"\" _a(const char* s,\n                                                     std::size_t n) {\n   return {{s, n}};\n }\n-FMT_CONSTEXPR internal::udl_arg<wchar_t> operator\"\"_a(const wchar_t* s,\n+FMT_CONSTEXPR internal::udl_arg<wchar_t> operator\"\" _a(const wchar_t* s,\n                                                        std::size_t n) {\n   return {{s, n}};\n }\ndiff --git a/tools/juliapkg/src/result.jl b/tools/juliapkg/src/result.jl\nindex 59bf6953a78a..f3ce9a8ee225 100644\n--- a/tools/juliapkg/src/result.jl\n+++ b/tools/juliapkg/src/result.jl\n@@ -870,7 +870,14 @@ The resultset iterator supports the [Tables.jl](https://github.com/JuliaData/Tab\n like `DataFrame(results)`, `CSV.write(\"results.csv\", results)`, etc.\n \"\"\"\n DBInterface.execute(stmt::Stmt, params::DBInterface.StatementParams) = execute(stmt, params)\n-DBInterface.execute(con::Connection, sql::AbstractString, result_type::Type) = execute(Stmt(con, sql, result_type))\n+function DBInterface.execute(con::Connection, sql::AbstractString, result_type::Type)\n+    stmt = Stmt(con, sql, result_type)\n+    try\n+        return execute(stmt)\n+    finally\n+        _close_stmt(stmt) # immediately close, don't wait for GC\n+    end\n+end\n DBInterface.execute(con::Connection, sql::AbstractString) = DBInterface.execute(con, sql, MaterializedResult)\n DBInterface.execute(db::DB, sql::AbstractString, result_type::Type) =\n     DBInterface.execute(db.main_connection, sql, result_type)\n", "test_patch": "diff --git a/test/extension/install_extension.test b/test/extension/install_extension.test\nindex 1c20345e374b..35acda8ef6a9 100644\n--- a/test/extension/install_extension.test\n+++ b/test/extension/install_extension.test\n@@ -37,3 +37,9 @@ statement error\n INSTALL will_never_exist FROM 'core';\n ----\n IO Error: Failed to copy local extension \"will_never_exist\" at PATH \n+\n+# Error message should point to extensions troubleshooting page\n+statement error\n+INSTALL will_never_exist FROM core;\n+----\n+For more info, visit https://duckdb.org/docs/extensions/troubleshooting\ndiff --git a/test/sql/constraints/primarykey/test_pk_updel_multi_column.test b/test/sql/constraints/primarykey/test_pk_updel_multi_column.test\nindex 077fa824f38c..083a10ca9011 100644\n--- a/test/sql/constraints/primarykey/test_pk_updel_multi_column.test\n+++ b/test/sql/constraints/primarykey/test_pk_updel_multi_column.test\n@@ -2,9 +2,6 @@\n # description: PRIMARY KEY and update/delete on multiple columns\n # group: [primarykey]\n \n-# See test/sql/index/art/constraints/test_art_tx_returning.test.\n-require vector_size 2048\n-\n statement ok\n PRAGMA enable_verification;\n \n@@ -25,17 +22,17 @@ SELECT * FROM test ORDER BY ALL;\n 13\tpandas\n \n statement ok\n-UPDATE test SET a = a + 1;\n+UPDATE test SET a = a + 3;\n \n query IT\n SELECT * FROM test ORDER BY ALL;\n ----\n-12\tpandas\n-13\tpandas\n 14\tpandas\n+15\tpandas\n+16\tpandas\n \n statement error\n-UPDATE test SET a = 13 WHERE a = 12;\n+UPDATE test SET a = 15 WHERE a = 14;\n ----\n <REGEX>:Constraint Error.*violates primary key constraint.*\n \n@@ -47,12 +44,12 @@ UPDATE test SET a = 4;\n query IT\n SELECT * FROM test ORDER BY a;\n ----\n-12\tpandas\n-13\tpandas\n 14\tpandas\n+15\tpandas\n+16\tpandas\n \n statement ok\n-UPDATE test SET a = a - 1;\n+UPDATE test SET a = a - 3;\n \n query IT\n SELECT * FROM test ORDER BY ALL;\ndiff --git a/test/sql/index/art/constraints/test_art_tx_returning.test b/test/sql/index/art/constraints/test_art_tx_returning.test\nindex de9e8963f04c..f414b71cbb15 100644\n--- a/test/sql/index/art/constraints/test_art_tx_returning.test\n+++ b/test/sql/index/art/constraints/test_art_tx_returning.test\n@@ -2,13 +2,6 @@\n # description: Test updates on the primary key containing RETURNING.\n # group: [constraints]\n \n-# For each incoming chunk, we add the row IDs to the delete index.\n-# For standard_vector_size = 2, we delete [0, 1], and then try to insert value [1, 2].\n-# This is expected to throw a constraint violation.\n-# The value 2 is not yet in the delete index, as the chunk that would add that value hasn't been processed, yet.\n-# This scenario is a known limitation (also in postgres).\n-require vector_size 2048\n-\n statement ok\n PRAGMA enable_verification\n \n@@ -22,10 +15,24 @@ statement ok\n INSERT INTO tbl_list SELECT range, [range || ' payload'] FROM range(5);\n \n query II\n+UPDATE tbl_list SET id = id + 5 RETURNING id, payload;\n+----\n+5\t[0 payload]\n+6\t[1 payload]\n+7\t[2 payload]\n+8\t[3 payload]\n+9\t[4 payload]\n+\n+statement ok\n+INSERT INTO tbl_list SELECT range + 10, [(range + 10) || ' payload'] FROM range(3000);\n+\n+# For each incoming chunk, we add the row IDs to the delete index.\n+# For standard_vector_size = 2048, we delete the first chunk, and then try to insert the incremented values.\n+# This is expected to throw a constraint violation.\n+# The value going into the next chunk is not yet in the delete index, as the chunk that would add that value hasn't been processed, yet.\n+# This scenario is a known limitation (also in postgres).\n+\n+statement error\n UPDATE tbl_list SET id = id + 1 RETURNING id, payload;\n ----\n-1\t[0 payload]\n-2\t[1 payload]\n-3\t[2 payload]\n-4\t[3 payload]\n-5\t[4 payload]\n+<REGEX>:Constraint Error.*violates primary key constraint.*\ndiff --git a/test/sql/projection/select_star_like.test b/test/sql/projection/select_star_like.test\nindex 40969744dfa1..f31e68f9df80 100644\n--- a/test/sql/projection/select_star_like.test\n+++ b/test/sql/projection/select_star_like.test\n@@ -61,6 +61,27 @@ SELECT * NOT LIKE '%number%' AS val FROM (SELECT 1 AS number1, 2 AS number2, 3 A\n ----\n 3\n \n+# ESCAPE\n+query I\n+SELECT * LIKE '\\_%' ESCAPE '\\' AS val FROM (SELECT 1 AS number1, 2 AS _number2)\n+----\n+2\n+\n+query I\n+SELECT * NOT LIKE '\\_%' ESCAPE '\\' AS val FROM (SELECT 1 AS number1, 2 AS _number2)\n+----\n+1\n+\n+query I\n+SELECT * ILIKE '\\_NUM%' ESCAPE '\\' AS val FROM (SELECT 1 AS number1, 2 AS _number2)\n+----\n+2\n+\n+query I\n+SELECT * NOT ILIKE '\\_NUM%' ESCAPE '\\' AS val FROM (SELECT 1 AS number1, 2 AS _number2)\n+----\n+1\n+\n # non-constant pattern\n statement error\n SELECT * SIMILAR TO pattern FROM integers, (SELECT '.*col.*') t(pattern)\ndiff --git a/test/sql/topn/test_top_n_nested_struct.test b/test/sql/topn/test_top_n_nested_struct.test\nnew file mode 100644\nindex 000000000000..beaad014bf82\n--- /dev/null\n+++ b/test/sql/topn/test_top_n_nested_struct.test\n@@ -0,0 +1,28 @@\n+# name: test/sql/topn/test_top_n_nested_struct.test\n+# description: Test Top-N on nested structs\n+# group: [topn]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+CREATE TABLE nested_struct(cik BIGINT, entityName VARCHAR, a STRUCT(b STRUCT(c INT, d INT), c STRUCT(e INT, f INT)));\n+\n+statement ok\n+INSERT INTO nested_struct VALUES (42, 'entity', {'b': {'c': 42, 'd': 43}, 'c': {'e': 44, 'f': 45}}),\n+                                 (142, 'entity2', {'b': {'c': 142, 'd': 143}, 'c': {'e': 144, 'f': 145}});\n+\n+query IIII\n+select unnest(a, recursive:=true) from nested_struct limit 1\n+----\n+42\t43\t44\t45\n+\n+query IIII\n+SELECT unnest(a, recursive := true) FROM nested_struct ORDER BY a.b.c LIMIT 1\n+----\n+42\t43\t44\t45\n+\n+query IIII\n+SELECT unnest(a, recursive := true) FROM nested_struct ORDER BY a.b.c DESC LIMIT 1\n+----\n+142\t143\t144\t145\ndiff --git a/test/sql/types/nested/struct/lineitem_struct.test_slow b/test/sql/types/nested/struct/lineitem_struct.test_slow\nindex 14b515071c10..9dd375bc3df8 100644\n--- a/test/sql/types/nested/struct/lineitem_struct.test_slow\n+++ b/test/sql/types/nested/struct/lineitem_struct.test_slow\n@@ -36,3 +36,22 @@ query I\n PRAGMA tpch(1)\n ----\n <FILE>:extension/tpch/dbgen/answers/sf0.01/q01.csv\n+\n+# top-n\n+query IIIIIIIIIIIIIII\n+SELECT l_orderkey, l_partkey, l_suppkey, l_linenumber, l_quantity, l_extendedprice, l_discount, l_tax, l_returnflag, l_linestatus, l_shipdate, l_commitdate, l_receiptdate, l_shipinstruct, l_shipmode FROM lineitem ORDER BY l_shipdate, l_orderkey LIMIT 5;\n+----\n+27137\t1673\t56\t3\t24.00\t37792.08\t0.06\t0.03\tR\tF\t1992-01-04\t1992-02-18\t1992-01-22\tDELIVER IN PERSON\tRAIL\n+27137\t590\t51\t5\t37.00\t55151.83\t0.03\t0.03\tA\tF\t1992-01-06\t1992-02-24\t1992-01-13\tDELIVER IN PERSON\tMAIL\n+47591\t676\t39\t1\t38.00\t59913.46\t0.05\t0.04\tA\tF\t1992-01-06\t1992-03-19\t1992-01-11\tCOLLECT COD\tREG AIR\n+5601\t723\t24\t3\t38.00\t61701.36\t0.07\t0.00\tA\tF\t1992-01-08\t1992-03-01\t1992-01-09\tTAKE BACK RETURN\tREG AIR\n+9379\t556\t57\t4\t13.00\t18935.15\t0.00\t0.01\tA\tF\t1992-01-09\t1992-03-20\t1992-01-12\tCOLLECT COD\tTRUCK\n+\n+query IIIIIIIIIIIIIII\n+SELECT l_orderkey,l_partkey,l_suppkey,l_linenumber,l_quantity,l_extendedprice,l_discount,l_tax,l_returnflag,l_linestatus,l_shipdate,l_commitdate,l_receiptdate,l_shipinstruct,l_shipmode FROM lineitem ORDER BY l_orderkey DESC, l_shipdate DESC LIMIT 5;\n+----\n+60000\t1843\t44\t2\t23.00\t40131.32\t0.05\t0.03\tN\tO\t1995-08-09\t1995-06-08\t1995-08-23\tCOLLECT COD\tFOB\n+60000\t585\t16\t5\t31.00\t46052.98\t0.00\t0.05\tN\tO\t1995-08-06\t1995-07-18\t1995-08-19\tTAKE BACK RETURN\tTRUCK\n+60000\t271\t53\t4\t29.00\t33966.83\t0.02\t0.01\tN\tO\t1995-07-25\t1995-06-07\t1995-08-17\tCOLLECT COD\tSHIP\n+60000\t836\t3\t6\t45.00\t78157.35\t0.04\t0.08\tN\tO\t1995-07-23\t1995-07-17\t1995-07-24\tDELIVER IN PERSON\tTRUCK\n+60000\t292\t93\t1\t45.00\t53653.05\t0.05\t0.06\tN\tO\t1995-07-13\t1995-05-29\t1995-08-10\tTAKE BACK RETURN\tMAIL\ndiff --git a/test/sql/upsert/test_big_insert.test b/test/sql/upsert/test_big_insert.test\nindex 1bba1ba5fd17..eaf476447f57 100644\n--- a/test/sql/upsert/test_big_insert.test\n+++ b/test/sql/upsert/test_big_insert.test\n@@ -3,53 +3,45 @@\n # group: [upsert]\n \n statement ok\n-pragma enable_verification;\n+PRAGMA enable_verification;\n \n statement ok\n-SET preserve_insertion_order=false;\n+SET preserve_insertion_order = false;\n \n-# big insert\n statement ok\n CREATE TABLE integers(\n-\ti INTEGER unique,\n-\tj INTEGER DEFAULT 0,\n-\tk INTEGER DEFAULT 0\n+\ti INT UNIQUE,\n+\tj INT DEFAULT 0,\n+\tk INT DEFAULT 0\n );\n \n statement ok\n-INSERT INTO integers(i) SELECT i from range(5000) tbl(i);\n+INSERT INTO integers(i) SELECT i FROM range(5000) tbl(i);\n \n query I\n SELECT COUNT(*) FROM integers\n ----\n 5000\n \n-# All tuples hit a conflict - Do nothing\n+# All tuples hit a conflict - DO NOTHING.\n statement ok\n-INSERT INTO integers SELECT * FROM integers on conflict do nothing;\n+INSERT INTO integers SELECT * FROM integers ON CONFLICT DO NOTHING;\n \n-# All tuples hit a conflict - Do Update\n+# All tuples hit a conflict - DO UPDATE.\n statement ok\n-INSERT INTO integers SELECT * FROM integers on conflict do update set j = 10;\n+INSERT INTO integers SELECT * FROM integers ON CONFLICT DO UPDATE SET j = 10;\n \n-# All 'j' entries are changed to 10\n+# All 'j' entries are changed to 10.\n query I\n SELECT COUNT(*) FILTER (WHERE j = 10) FROM integers\n ----\n 5000\n \n-# All insert tuples cause a conflict on the same row\n-statement error\n-INSERT INTO integers(i,j) select i%5,i from range(5000) tbl(i) on conflict do update set j = excluded.j, k = excluded.i;\n-----\n-Invalid Input Error: ON CONFLICT DO UPDATE can not update the same row twice in the same command. Ensure that no rows proposed for insertion within the same command have duplicate constrained values\n-\n statement ok\n-INSERT INTO integers(i,j) select i%5,i from range(4995, 5000) tbl(i) on conflict do update set j = excluded.j, k = excluded.i;\n+INSERT INTO integers(i, j) SELECT i % 5, i FROM range(4995, 5000) tbl(i) ON CONFLICT DO UPDATE SET j = excluded.j, k = excluded.i;\n \n-# This is what we might expect the previous result to look like as well\n query I\n-select j from integers limit 5;\n+SELECT j FROM integers LIMIT 5;\n ----\n 4995\n 4996\n@@ -57,25 +49,21 @@ select j from integers limit 5;\n 4998\n 4999\n \n-# This is the worst conflicting rowid pattern we could have\n-# Every odd-indexed insert tuple conflicts with a row at the start of the existing tuples\n-# And every even-indexed insert tuple conflicts with a row at the end of the existing tuples\n+# This is the worst conflicting rowid pattern we could have.\n+# Every odd-indexed insert tuple conflicts with a row at the start of the existing tuples.\n+# And every even-indexed insert tuple conflicts with a row at the end of the existing tuples.\n statement ok\n-insert into integers(i,j)\n-\tselect\n-\t\tCASE WHEN i % 2 = 0\n-\t\t\tTHEN\n-\t\t\t\t4999 - (i//2)\n-\t\t\tELSE\n-\t\t\t\ti - ((i//2)+1)\n-\t\tEND,\n-\t\ti\n-\tfrom range(5000) tbl(i)\n-on conflict do update set j = excluded.j;\n-\n-# This shows that the odd-indexed insert tuples conflicted with the first rows\n+INSERT INTO integers(i, j)\n+\tSELECT CASE WHEN i % 2 = 0\n+\t\tTHEN 4999 - (i // 2)\n+\t\tELSE i - ((i // 2) + 1)\n+\t\tEND, i\n+\tFROM range(5000) tbl(i)\n+ON CONFLICT DO UPDATE SET j = excluded.j;\n+\n+# This shows that the odd-indexed insert tuples conflicted with the first rows.\n query I\n-select j from integers limit 5;\n+SELECT j FROM integers LIMIT 5;\n ----\n 1\n 3\n@@ -83,9 +71,9 @@ select j from integers limit 5;\n 7\n 9\n \n-# This shows that the even-indexed insert tuples conflicted with the last rows\n+# This shows that the even-indexed insert tuples conflicted with the last rows.\n query I\n-select j from integers limit 5 offset 4995;\n+SELECT j FROM integers LIMIT 5 OFFSET 4995;\n ----\n 8\n 6\n@@ -93,26 +81,23 @@ select j from integers limit 5 offset 4995;\n 2\n 0\n \n-# Reset j\n+# Reset j.\n statement ok\n-update integers set j = 0;\n+UPDATE integers SET j = 0;\n \n-# Only set j if both the existing tuple and the insert tuple are even\n+# Only set j if both the existing tuple and the insert tuple are even.\n statement ok\n-insert into integers(i,j)\n-\tselect\n-\t\tCASE WHEN i % 2 = 0\n-\t\t\tTHEN\n-\t\t\t\t4999 - (i//2)\n-\t\t\tELSE\n-\t\t\t\ti - ((i//2)+1)\n-\t\tEND,\n-\t\ti\n-\tfrom range(5000) tbl(i)\n-on conflict do update set j = excluded.j where i % 2 = 0 AND excluded.j % 2 = 0;\n-\n-# The DO UPDATE where clause is only true for a quarter of the cases\n+INSERT INTO integers(i, j)\n+\tSELECT CASE WHEN i % 2 = 0\n+\t\tTHEN 4999 - (i // 2)\n+\t\tELSE i - ((i // 2) + 1)\n+\t\tEND, i\n+\tFROM range(5000) tbl(i)\n+ON CONFLICT DO UPDATE SET j = excluded.j\n+WHERE i % 2 = 0 AND excluded.j % 2 = 0;\n+\n+# The DO UPDATE WHERE clause is only true for a quarter of the cases.\n query I\n-select COUNT(j) filter (where j != 0) from integers;\n+SELECT COUNT(j) FILTER (WHERE j != 0) FROM integers;\n ----\n 1250\ndiff --git a/test/sql/upsert/test_big_insert_no_vector_verification.test b/test/sql/upsert/test_big_insert_no_vector_verification.test\nnew file mode 100644\nindex 000000000000..3f4b849d9774\n--- /dev/null\n+++ b/test/sql/upsert/test_big_insert_no_vector_verification.test\n@@ -0,0 +1,32 @@\n+# name: test/sql/upsert/test_big_insert_no_vector_verification.test\n+# description: Test ON CONFLICT statement on the same conflicting row.\n+# group: [upsert]\n+\n+# The constant operator verification ensures that we have only one row per data chunk.\n+# Thus, the below insert succeeds, as we no longer see the same row within a chunk.\n+require no_vector_verification\n+\n+statement ok\n+PRAGMA enable_verification;\n+\n+statement ok\n+SET preserve_insertion_order = false;\n+\n+statement ok\n+CREATE TABLE integers(\n+\ti INT UNIQUE,\n+\tj INT DEFAULT 0,\n+\tk INT DEFAULT 0\n+);\n+\n+statement ok\n+INSERT INTO integers(i) SELECT i FROM range(5000) tbl(i);\n+\n+statement error\n+INSERT INTO integers(i, j)\n+SELECT i % 5, i\n+FROM range(5000) tbl(i) ON CONFLICT DO UPDATE SET\n+\tj = excluded.j,\n+\tk = excluded.i;\n+----\n+<REGEX>:Invalid Input Error:.*ON CONFLICT DO UPDATE can not update the same row twice in the same command.*\ndiff --git a/test/sql/upsert/test_problematic_conditional_do_update.test b/test/sql/upsert/test_problematic_conditional_do_update.test\nnew file mode 100644\nindex 000000000000..ade3cd1bde07\n--- /dev/null\n+++ b/test/sql/upsert/test_problematic_conditional_do_update.test\n@@ -0,0 +1,40 @@\n+# name: test/sql/upsert/test_problematic_conditional_do_update.test\n+# group: [upsert]\n+\n+statement ok\n+CREATE TABLE users (\n+\tid BIGINT PRIMARY KEY,\n+\tusername TEXT UNIQUE,\n+\temail TEXT\n+);\n+\n+# FIXME: not consistent\n+mode skip\n+\n+# The condition skips the last tuple\n+statement error\n+INSERT INTO users (id, username, email)\n+VALUES\n+\t(3, 'inner_conflict', 'test'),\n+\t(3, 'inner_conflict2', 'other_test'),\n+\t(3, 'inner_conflict3', 'filtered_out')\n+ON CONFLICT (id) DO\n+    UPDATE SET email = EXCLUDED.email\n+    WHERE EXCLUDED.email != 'filtered_out'\n+----\n+Not implemented Error: Inner conflicts detected with a conditional DO UPDATE on-conflict action, not fully implemented yet\n+\n+# The result of the condition can also be influenced based on previous updates\n+statement error\n+INSERT INTO users (id, username, email)\n+VALUES\n+\t(3, 'inner_conflict', 'test'),\n+\t(3, 'inner_conflict2', 'other_test'),\n+\t(3, 'inner_conflict3', 'yet_another_test'),\n+\t(3, 'inner_conflict4', 'dont_skip_me')\n+ON CONFLICT (id) DO\n+    UPDATE SET email = EXCLUDED.email\n+    WHERE email != 'other_test' OR EXCLUDED.email == 'dont_skip_me'\n+RETURNING *;\n+----\n+Not implemented Error: Inner conflicts detected with a conditional DO UPDATE on-conflict action, not fully implemented yet\ndiff --git a/test/sql/upsert/upsert_returning.test b/test/sql/upsert/upsert_returning.test\nnew file mode 100644\nindex 000000000000..cbb3c90126d9\n--- /dev/null\n+++ b/test/sql/upsert/upsert_returning.test\n@@ -0,0 +1,83 @@\n+# name: test/sql/upsert/upsert_returning.test\n+# group: [upsert]\n+\n+require vector_size 2048\n+\n+statement ok\n+CREATE TABLE users (\n+    id BIGINT PRIMARY KEY,\n+    username TEXT UNIQUE,\n+    email TEXT\n+);\n+\n+query III\n+INSERT INTO users (id, username, email) VALUES\n+\t(1, 'john_doe', 'john@example.com')\n+ON CONFLICT (username) DO NOTHING\n+RETURNING *;\n+----\n+1\tjohn_doe\tjohn@example.com\n+\n+query III\n+INSERT INTO users (id, username, email) VALUES\n+\t(1, 'john_doe', 'john@example.com')\n+ON CONFLICT (username) DO NOTHING\n+RETURNING *;\n+----\n+\n+# We create a conflict, with a where clause that filters out this conflict\n+# Because the where clause filters it out, the DO UPDATE becomes a DO NOTHING for this row instead\n+# So it does not get added to the returning clause.\n+query III\n+INSERT INTO users (id, username, email)\n+VALUES (1, 'john_doe', 'john_new@example.com')\n+ON CONFLICT (id) DO\n+    UPDATE SET email = EXCLUDED.email\n+    WHERE EXCLUDED.email != 'john_new@example.com'\n+RETURNING *;\n+----\n+\n+# Verify that the *other* tuple does get added to the returning clause\n+query III\n+INSERT INTO users (id, username, email)\n+VALUES\n+\t(1, 'john_doe', 'john_new@example.com'),\n+\t(2, 'not_john_doe', 'not_john_new@example.com')\n+ON CONFLICT (id) DO\n+    UPDATE SET email = EXCLUDED.email\n+    WHERE EXCLUDED.email != 'john_new@example.com'\n+RETURNING *;\n+----\n+2\tnot_john_doe\tnot_john_new@example.com\n+\n+\n+# FIXME: not consistent\n+mode skip\n+\n+# Here we have conflicts within the inserted data\n+# Only the last occurrence of this conflict should be present in the returning clause.\n+query III\n+INSERT INTO users (id, username, email)\n+VALUES\n+\t(3, 'inner_conflict', 'test'),\n+\t(4, 'a', ''),\n+\t(5, 'b', ''),\n+\t(6, 'c', ''),\n+\t(3, 'inner_conflict2', 'other_test'),\n+\t(7, 'd', ''),\n+\t(8, 'e', ''),\n+\t(9, 'f', ''),\n+\t(3, 'inner_conflict3', 'yet_another_test')\n+ON CONFLICT (id) DO\n+    UPDATE SET email = EXCLUDED.email\n+    WHERE EXCLUDED.email != 'test'\n+RETURNING *;\n+----\n+3\tinner_conflict\ttest\n+4\ta\t(empty)\n+5\tb\t(empty)\n+6\tc\t(empty)\n+7\td\t(empty)\n+8\te\t(empty)\n+9\tf\t(empty)\n+3\tinner_conflict3\tyet_another_test\ndiff --git a/tools/juliapkg/test/test_connection.jl b/tools/juliapkg/test/test_connection.jl\nindex c09848b27450..0258788a6dfe 100644\n--- a/tools/juliapkg/test/test_connection.jl\n+++ b/tools/juliapkg/test/test_connection.jl\n@@ -17,3 +17,39 @@ end\n @testset \"Test opening a bogus directory\" begin\n     @test_throws DuckDB.ConnectionException DBInterface.connect(DuckDB.DB, \"/path/to/bogus/directory\")\n end\n+\n+\n+@testset \"Test opening and closing an on-disk database\" begin\n+    # This checks for an issue where the DB and the connection are \n+    # closed but the actual db is not (and subsequently cannot be opened\n+    # in a different process). To check this, we create a DB, write some\n+    # data to it, close the connection and check if the WAL file exists.\n+    #\n+    # Ideally, the WAL file should not exist, but Garbage Collection of Julia\n+    # may not have run yet, so open database handles may still exist, preventing\n+    # the database from being closed properly.\n+\n+    db_path = joinpath(mktempdir(), \"duckdata.db\")\n+    db_path_wal = db_path * \".wal\"\n+\n+    function write_data(dbfile::String)\n+        db = DuckDB.DB(dbfile)\n+        conn = DBInterface.connect(db)\n+        DBInterface.execute(conn, \"CREATE OR REPLACE TABLE test (a INTEGER, b INTEGER);\")\n+        DBInterface.execute(conn, \"INSERT INTO test VALUES (1, 2);\")\n+        DBInterface.close!(conn)\n+        DuckDB.close_database(db)\n+        return true\n+    end\n+    write_data(db_path) # call the function\n+    @test isfile(db_path_wal) === false # WAL file should not exist\n+\n+    @test isfile(db_path) # check if the database file exists\n+\n+    # check if the database can be opened\n+    if haskey(ENV, \"JULIA_DUCKDB_LIBRARY\")\n+        duckdb_binary = joinpath(dirname(ENV[\"JULIA_DUCKDB_LIBRARY\"]), \"..\", \"duckdb\")\n+        result = run(`$duckdb_binary $db_path -c \"SELECT * FROM test LIMIT 1\"`) # check if the database can be opened\n+        @test success(result)\n+    end\n+end\ndiff --git a/tools/pythonpkg/scripts/sqllogictest_python.py b/tools/pythonpkg/scripts/sqllogictest_python.py\nindex c3821f581c75..554e3a5a489e 100644\n--- a/tools/pythonpkg/scripts/sqllogictest_python.py\n+++ b/tools/pythonpkg/scripts/sqllogictest_python.py\n@@ -38,6 +38,9 @@ def __init__(self, build_directory: Optional[str] = None):\n                 'test/sql/json/table/read_json_objects.test',  # <-- Python client is always loaded with JSON available\n                 'test/sql/copy/csv/zstd_crash.test',  # <-- Python client is always loaded with Parquet available\n                 'test/sql/error/extension_function_error.test',  # <-- Python client is always loaded with TPCH available\n+                'test/optimizer/joins/tpcds_nofail.test',  # <-- Python client is always loaded with TPCDS available\n+                'test/sql/settings/errors_as_json.test',  # <-- errors_as_json not currently supported in Python\n+                'test/sql/parallelism/intraquery/depth_first_evaluation_union_and_join.test',  # <-- Python client is always loaded with TPCDS available\n                 'test/sql/types/timestamp/test_timestamp_tz.test',  # <-- Python client is always loaded wih ICU available - making the TIMESTAMPTZ::DATE cast pass\n                 'test/sql/parser/invisible_spaces.test',  # <-- Parser is getting tripped up on the invisible spaces\n                 'test/sql/copy/csv/code_cov/csv_state_machine_invalid_utf.test',  # <-- ConversionException is empty, see Python Mega Issue (duckdb-internal #1488)\n", "problem_statement": "Aliases being set inside bind_replace are overwritten\n### What happens?\n\nWhen setting the alias of a TableRef inside a bind_replace function, it is overwritten by the `ref.alias` even if this `ref.alias` is empty. \nSpecifically here: \nhttps://github.com/duckdb/duckdb/blob/6264c5c95b9a77d333d04fa9a268e04c52015766/src/planner/binder/tableref/bind_table_function.cpp#L204-L209\nI can set the `ref.alias` earlier like this: https://github.com/cwida/duckpgq-extension/blob/8de232b5ba4df00afdaf7e1f3c0870dfee21c54f/src/core/parser/duckpgq_parser.cpp#L50, but that means I need to check for every possible bind_replace function I have during the initial bind phase, which feels quite hacky. I think the ability to set the alias during the bind_replace and it not being overwritten is a better solution.\n\nPerhaps I am missing something regarding the `ref.alias`, if that's the case please let me know :) \n\n### To Reproduce\n\nTo reproduce: \n\n`git clone --recurse-submodules git@github.com:cwida/duckpgq-extension.git`\n`make GEN=ninja`\n\n```sql\nCREATE TABLE Student(id BIGINT, name VARCHAR);INSERT INTO Student VALUES (0, 'Daniel'), (1, 'Tavneet'), (2, 'Gabor'), (3, 'Peter'), (4, 'David');\nCREATE TABLE know(src BIGINT, dst BIGINT, createDate BIGINT);INSERT INTO know VALUES (0,1, 10), (0,2, 11), (0,3, 12), (3,0, 13), (1,2, 14), (1,3, 15), (2,3, 16), (4,3, 17);\n-CREATE PROPERTY GRAPH pg\nVERTEX TABLES (\n    Student,\n    Foo\n    )\nEDGE TABLES (\n    know    SOURCE KEY ( src ) REFERENCES Student ( id )\n            DESTINATION KEY ( dst ) REFERENCES Student ( id )\n    );\n\nselect a.id, a.name, local_clustering_coefficient from local_clustering_coefficient(pg, student, know), student a where a.id = lcc.id;\n```\n```\nBinder Error: Referenced table \"lcc\" not found!\nCandidate tables: \"a\"\n```\n\n### OS:\n\nmacOS\n\n### DuckDB Version:\n\nv1.2-histrionicus\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nDaniel ten Wolde\n\n### Affiliation:\n\nCentrum Wiskunde & Informatica\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a source build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nAliases being set inside bind_replace are overwritten\n### What happens?\n\nWhen setting the alias of a TableRef inside a bind_replace function, it is overwritten by the `ref.alias` even if this `ref.alias` is empty. \nSpecifically here: \nhttps://github.com/duckdb/duckdb/blob/6264c5c95b9a77d333d04fa9a268e04c52015766/src/planner/binder/tableref/bind_table_function.cpp#L204-L209\nI can set the `ref.alias` earlier like this: https://github.com/cwida/duckpgq-extension/blob/8de232b5ba4df00afdaf7e1f3c0870dfee21c54f/src/core/parser/duckpgq_parser.cpp#L50, but that means I need to check for every possible bind_replace function I have during the initial bind phase, which feels quite hacky. I think the ability to set the alias during the bind_replace and it not being overwritten is a better solution.\n\nPerhaps I am missing something regarding the `ref.alias`, if that's the case please let me know :) \n\n### To Reproduce\n\nTo reproduce: \n\n`git clone --recurse-submodules git@github.com:cwida/duckpgq-extension.git`\n`make GEN=ninja`\n\n```sql\nCREATE TABLE Student(id BIGINT, name VARCHAR);INSERT INTO Student VALUES (0, 'Daniel'), (1, 'Tavneet'), (2, 'Gabor'), (3, 'Peter'), (4, 'David');\nCREATE TABLE know(src BIGINT, dst BIGINT, createDate BIGINT);INSERT INTO know VALUES (0,1, 10), (0,2, 11), (0,3, 12), (3,0, 13), (1,2, 14), (1,3, 15), (2,3, 16), (4,3, 17);\n-CREATE PROPERTY GRAPH pg\nVERTEX TABLES (\n    Student,\n    Foo\n    )\nEDGE TABLES (\n    know    SOURCE KEY ( src ) REFERENCES Student ( id )\n            DESTINATION KEY ( dst ) REFERENCES Student ( id )\n    );\n\nselect a.id, a.name, local_clustering_coefficient from local_clustering_coefficient(pg, student, know), student a where a.id = lcc.id;\n```\n```\nBinder Error: Referenced table \"lcc\" not found!\nCandidate tables: \"a\"\n```\n\n### OS:\n\nmacOS\n\n### DuckDB Version:\n\nv1.2-histrionicus\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nDaniel ten Wolde\n\n### Affiliation:\n\nCentrum Wiskunde & Informatica\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a source build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nSurprising upsert with returning and where condition result\n### What happens?\n\nGiven I have a table with a primary key and I perform an upsert with a where condition in the update I would expect rows that don't match the condition not be present in the returned rows, this is not the case.\n\n### To Reproduce\n\n```sql\ncreate table foo(id int primary key, bar text);\ninsert into foo select 1, 'zoo';\ninsert into foo select 1, 'zoo' returning *;\n```\n```\nConstraint Error: Duplicate key \"id: 1\" violates primary key constraint. If this is an unexpected constraint violation please double check with the known index limitations section in our documentation (https://duckdb.org/docs/sql/indexes).\n```\n```sql\ninsert into foo select 1, 'zoo'\non conflict (id) do\n    update set bar = excluded.bar\n    where excluded.bar != 'zoo'\nreturning *;\n```\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  id   \u2502   bar   \u2502\n\u2502 int32 \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502 zoo     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n```sql\ninsert into foo select 1, 'zoom'\non conflict (id) do\n    update set bar = excluded.bar\n    where excluded.bar != 'zoom'\nreturning *;\n```\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  id   \u2502   bar   \u2502\n\u2502 int32 \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502 zoom    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n```sql\ninsert into foo select 1, 'zoom'\non conflict (id) do\n    update set bar = excluded.bar\n    where id != 1\nreturning *;\n```\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  id   \u2502   bar   \u2502\n\u2502 int32 \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502 zoom    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n```sql\nselect * from foo;\n```\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  id   \u2502   bar   \u2502\n\u2502 int32 \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502 zoo     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nSee in the upserts the where condition prevents the update and I would expect it to prevent anything from being returned, the stored data was never changed.\n\nThe documentation only states\n> The RETURNING clause may be used to return the contents of the rows that were inserted\n\nI think it would be fair in an upsert scenario to assume it would \"return the contents of the rows that were upserted\"\n\n### OS:\n\nMacOs 13.6.7 (aarch64)\n\n### DuckDB Version:\n\nv1.1.3\n\n### DuckDB Client:\n\nCLI (mac via homebrew)\n\n### Hardware:\n\nM1, 16Gb ram\n\n### Full Name:\n\nStephen Flavin\n\n### Affiliation:\n\nN/A\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "\n\n", "created_at": "2025-02-04T23:02:22Z"}
{"repo": "duckdb/duckdb", "pull_number": 16040, "instance_id": "duckdb__duckdb-16040", "issue_numbers": ["16026", "16026"], "base_commit": "e235e48e6dfe9242deb11b882ac5548a6abc627b", "patch": "diff --git a/src/optimizer/remove_unused_columns.cpp b/src/optimizer/remove_unused_columns.cpp\nindex b197a4f5f986..48ea7cbffe83 100644\n--- a/src/optimizer/remove_unused_columns.cpp\n+++ b/src/optimizer/remove_unused_columns.cpp\n@@ -261,9 +261,6 @@ void RemoveUnusedColumns::VisitOperator(LogicalOperator &op) {\n \t\t\t\tif (entry == column_references.end()) {\n \t\t\t\t\tthrow InternalException(\"RemoveUnusedColumns - could not find referenced column\");\n \t\t\t\t}\n-\t\t\t\tif (final_column_ids[col_sel_idx].HasChildren()) {\n-\t\t\t\t\tthrow InternalException(\"RemoveUnusedColumns - LogicalGet::column_ids already has children\");\n-\t\t\t\t}\n \t\t\t\tColumnIndex new_index(final_column_ids[col_sel_idx].GetPrimaryIndex(), entry->second.child_columns);\n \t\t\t\tcolumn_ids.emplace_back(new_index);\n \t\t\t}\n", "test_patch": "diff --git a/test/sql/topn/test_top_n_nested_struct.test b/test/sql/topn/test_top_n_nested_struct.test\nnew file mode 100644\nindex 000000000000..beaad014bf82\n--- /dev/null\n+++ b/test/sql/topn/test_top_n_nested_struct.test\n@@ -0,0 +1,28 @@\n+# name: test/sql/topn/test_top_n_nested_struct.test\n+# description: Test Top-N on nested structs\n+# group: [topn]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+CREATE TABLE nested_struct(cik BIGINT, entityName VARCHAR, a STRUCT(b STRUCT(c INT, d INT), c STRUCT(e INT, f INT)));\n+\n+statement ok\n+INSERT INTO nested_struct VALUES (42, 'entity', {'b': {'c': 42, 'd': 43}, 'c': {'e': 44, 'f': 45}}),\n+                                 (142, 'entity2', {'b': {'c': 142, 'd': 143}, 'c': {'e': 144, 'f': 145}});\n+\n+query IIII\n+select unnest(a, recursive:=true) from nested_struct limit 1\n+----\n+42\t43\t44\t45\n+\n+query IIII\n+SELECT unnest(a, recursive := true) FROM nested_struct ORDER BY a.b.c LIMIT 1\n+----\n+42\t43\t44\t45\n+\n+query IIII\n+SELECT unnest(a, recursive := true) FROM nested_struct ORDER BY a.b.c DESC LIMIT 1\n+----\n+142\t143\t144\t145\ndiff --git a/test/sql/types/nested/struct/lineitem_struct.test_slow b/test/sql/types/nested/struct/lineitem_struct.test_slow\nindex 14b515071c10..9dd375bc3df8 100644\n--- a/test/sql/types/nested/struct/lineitem_struct.test_slow\n+++ b/test/sql/types/nested/struct/lineitem_struct.test_slow\n@@ -36,3 +36,22 @@ query I\n PRAGMA tpch(1)\n ----\n <FILE>:extension/tpch/dbgen/answers/sf0.01/q01.csv\n+\n+# top-n\n+query IIIIIIIIIIIIIII\n+SELECT l_orderkey, l_partkey, l_suppkey, l_linenumber, l_quantity, l_extendedprice, l_discount, l_tax, l_returnflag, l_linestatus, l_shipdate, l_commitdate, l_receiptdate, l_shipinstruct, l_shipmode FROM lineitem ORDER BY l_shipdate, l_orderkey LIMIT 5;\n+----\n+27137\t1673\t56\t3\t24.00\t37792.08\t0.06\t0.03\tR\tF\t1992-01-04\t1992-02-18\t1992-01-22\tDELIVER IN PERSON\tRAIL\n+27137\t590\t51\t5\t37.00\t55151.83\t0.03\t0.03\tA\tF\t1992-01-06\t1992-02-24\t1992-01-13\tDELIVER IN PERSON\tMAIL\n+47591\t676\t39\t1\t38.00\t59913.46\t0.05\t0.04\tA\tF\t1992-01-06\t1992-03-19\t1992-01-11\tCOLLECT COD\tREG AIR\n+5601\t723\t24\t3\t38.00\t61701.36\t0.07\t0.00\tA\tF\t1992-01-08\t1992-03-01\t1992-01-09\tTAKE BACK RETURN\tREG AIR\n+9379\t556\t57\t4\t13.00\t18935.15\t0.00\t0.01\tA\tF\t1992-01-09\t1992-03-20\t1992-01-12\tCOLLECT COD\tTRUCK\n+\n+query IIIIIIIIIIIIIII\n+SELECT l_orderkey,l_partkey,l_suppkey,l_linenumber,l_quantity,l_extendedprice,l_discount,l_tax,l_returnflag,l_linestatus,l_shipdate,l_commitdate,l_receiptdate,l_shipinstruct,l_shipmode FROM lineitem ORDER BY l_orderkey DESC, l_shipdate DESC LIMIT 5;\n+----\n+60000\t1843\t44\t2\t23.00\t40131.32\t0.05\t0.03\tN\tO\t1995-08-09\t1995-06-08\t1995-08-23\tCOLLECT COD\tFOB\n+60000\t585\t16\t5\t31.00\t46052.98\t0.00\t0.05\tN\tO\t1995-08-06\t1995-07-18\t1995-08-19\tTAKE BACK RETURN\tTRUCK\n+60000\t271\t53\t4\t29.00\t33966.83\t0.02\t0.01\tN\tO\t1995-07-25\t1995-06-07\t1995-08-17\tCOLLECT COD\tSHIP\n+60000\t836\t3\t6\t45.00\t78157.35\t0.04\t0.08\tN\tO\t1995-07-23\t1995-07-17\t1995-07-24\tDELIVER IN PERSON\tTRUCK\n+60000\t292\t93\t1\t45.00\t53653.05\t0.05\t0.06\tN\tO\t1995-07-13\t1995-05-29\t1995-08-10\tTAKE BACK RETURN\tMAIL\n", "problem_statement": "INTERNAL error on 1.1.4.dev5147 (regression)\n### What happens?\n\nThe following code works fine on 1.1.3 (release), but fails on duckdb-1.1.4.dev5147. Also works if you remove \"limit 1\". \n\nInput File attached.\n[CIK0000001750scratch.json](https://github.com/user-attachments/files/18632812/CIK0000001750scratch.json)\n\n**Error**:\n> InternalException: INTERNAL Error: RemoveUnusedColumns - LogicalGet::column_ids already has children\n> This error signals an assertion failure within DuckDB. This usually occurs due to unexpected conditions or errors in the program's logic.\n> For more information, see https://duckdb.org/docs/dev/internal_errors\n\n### To Reproduce\n\n```py\nimport duckdb\n\nwith duckdb.connect() as con: \n    con.execute(\"\"\"\n    CREATE or replace TABLE jsondata AS\n        SELECT *\n        FROM 'CIK0000001750scratch.json';\n    \"\"\")\n\n    con.execute(\"select unnest(facts, recursive:=true) from jsondata limit 1\").df()\n\n```\n\n### OS:\n\nWindows\n\n### DuckDB Version:\n\nduckdb-1.1.4.dev5147\n\n### DuckDB Client:\n\nPython - Windows - VScode Notebook\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nPaul T\n\n### Affiliation:\n\nIqmo\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a nightly build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nINTERNAL error on 1.1.4.dev5147 (regression)\n### What happens?\n\nThe following code works fine on 1.1.3 (release), but fails on duckdb-1.1.4.dev5147. Also works if you remove \"limit 1\". \n\nInput File attached.\n[CIK0000001750scratch.json](https://github.com/user-attachments/files/18632812/CIK0000001750scratch.json)\n\n**Error**:\n> InternalException: INTERNAL Error: RemoveUnusedColumns - LogicalGet::column_ids already has children\n> This error signals an assertion failure within DuckDB. This usually occurs due to unexpected conditions or errors in the program's logic.\n> For more information, see https://duckdb.org/docs/dev/internal_errors\n\n### To Reproduce\n\n```py\nimport duckdb\n\nwith duckdb.connect() as con: \n    con.execute(\"\"\"\n    CREATE or replace TABLE jsondata AS\n        SELECT *\n        FROM 'CIK0000001750scratch.json';\n    \"\"\")\n\n    con.execute(\"select unnest(facts, recursive:=true) from jsondata limit 1\").df()\n\n```\n\n### OS:\n\nWindows\n\n### DuckDB Version:\n\nduckdb-1.1.4.dev5147\n\n### DuckDB Client:\n\nPython - Windows - VScode Notebook\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nPaul T\n\n### Affiliation:\n\nIqmo\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a nightly build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "\n", "created_at": "2025-02-03T12:56:52Z"}
{"repo": "duckdb/duckdb", "pull_number": 15991, "instance_id": "duckdb__duckdb-15991", "issue_numbers": ["15921", "15443", "15443"], "base_commit": "0959644c1d57409e78d2fae0262f792921a54c55", "patch": "diff --git a/.github/config/out_of_tree_extensions.cmake b/.github/config/out_of_tree_extensions.cmake\nindex f3c49daae57f..2d628facb839 100644\n--- a/.github/config/out_of_tree_extensions.cmake\n+++ b/.github/config/out_of_tree_extensions.cmake\n@@ -28,8 +28,7 @@ if (NOT MINGW AND NOT ${WASM_ENABLED} AND NOT ${MUSL_ENABLED})\n     duckdb_extension_load(arrow\n             LOAD_TESTS DONT_LINK\n             GIT_URL https://github.com/duckdb/arrow\n-            GIT_TAG c50862c82c065096722745631f4230832a3a04e8\n-            APPLY_PATCHES\n+            GIT_TAG cff2f0e21b1608e38640e15b4cf0693dd52dd0eb\n             )\n endif()\n \ndiff --git a/.github/patches/extensions/arrow/arrow_extension_types.patch b/.github/patches/extensions/arrow/arrow_extension_types.patch\ndeleted file mode 100644\nindex f99754806186..000000000000\n--- a/.github/patches/extensions/arrow/arrow_extension_types.patch\n+++ /dev/null\n@@ -1,57 +0,0 @@\n-diff --git a/src/arrow_scan_ipc.cpp b/src/arrow_scan_ipc.cpp\n-index a60d255..37e0e81 100644\n---- a/src/arrow_scan_ipc.cpp\n-+++ b/src/arrow_scan_ipc.cpp\n-@@ -15,7 +15,6 @@ TableFunction ArrowIPCTableFunction::GetFunction() {\n-       ArrowTableFunction::ArrowScanInitLocal);\n-\n-   scan_arrow_ipc_func.cardinality = ArrowTableFunction::ArrowScanCardinality;\n--  scan_arrow_ipc_func.get_batch_index = nullptr; // TODO implement\n-   scan_arrow_ipc_func.projection_pushdown = true;\n-   scan_arrow_ipc_func.filter_pushdown = false;\n-\n-@@ -71,9 +70,12 @@ unique_ptr<FunctionData> ArrowIPCTableFunction::ArrowScanBind(\n-     if (!schema.release) {\n-       throw InvalidInputException(\"arrow_scan: released schema passed\");\n-     }\n--    auto arrow_type = GetArrowLogicalType(schema);\n-+    auto arrow_type =\n-+       ArrowType::GetArrowLogicalType(DBConfig::GetConfig(context), schema);\n-+\n-     if (schema.dictionary) {\n--      auto dictionary_type = GetArrowLogicalType(*schema.dictionary);\n-+      auto dictionary_type = ArrowType::GetArrowLogicalType(\n-+          DBConfig::GetConfig(context), *schema.dictionary);\n-       return_types.emplace_back(dictionary_type->GetDuckType());\n-       arrow_type->SetDictionary(std::move(dictionary_type));\n-     } else {\n-diff --git a/src/arrow_to_ipc.cpp b/src/arrow_to_ipc.cpp\n-index c316d85..905df2b 100644\n---- a/src/arrow_to_ipc.cpp\n-+++ b/src/arrow_to_ipc.cpp\n-@@ -76,9 +76,9 @@ ToArrowIPCFunction::Bind(ClientContext &context, TableFunctionBindInput &input,\n-\n-   // Create the Arrow schema\n-   ArrowSchema schema;\n-+  auto properties = context.GetClientProperties();\n-   ArrowConverter::ToArrowSchema(&schema, input.input_table_types,\n--                                input.input_table_names,\n--                                context.GetClientProperties());\n-+                                input.input_table_names, properties);\n-   result->schema = arrow::ImportSchema(&schema).ValueOrDie();\n-\n-   return std::move(result);\n-@@ -116,9 +116,10 @@ OperatorResultType ToArrowIPCFunction::Function(ExecutionContext &context,\n-     output.data[1].SetValue(0, Value::BOOLEAN(1));\n-   } else {\n-     if (!local_state.appender) {\n--      local_state.appender =\n--          make_uniq<ArrowAppender>(input.GetTypes(), data.chunk_size,\n--                                   context.client.GetClientProperties());\n-+      local_state.appender = make_uniq<ArrowAppender>(input.GetTypes(), data.chunk_size,\n-+                                   context.client.GetClientProperties(),\n-+                                   ArrowTypeExtensionData::GetExtensionTypes(\n-+                                       context.client, input.GetTypes()));\n-     }\n-\n-     // Append input chunk\ndiff --git a/.github/workflows/Pyodide.yml b/.github/workflows/Pyodide.yml\nindex 0b6950ce89a5..32e14802065c 100644\n--- a/.github/workflows/Pyodide.yml\n+++ b/.github/workflows/Pyodide.yml\n@@ -108,7 +108,7 @@ jobs:\n       - name: install deps into environment\n         run: |\n           source .venv-pyodide/bin/activate\n-          pip install pytest numpy pandas mypy\n+          pip install pytest numpy pandas 'mypy<=1.13'\n \n       - name: install duckdb wasm wheel into environment\n         run: |\ndiff --git a/benchmark/tpch/startup.cpp b/benchmark/tpch/startup.cpp\nindex 88f678d22fdf..a468545476f2 100644\n--- a/benchmark/tpch/startup.cpp\n+++ b/benchmark/tpch/startup.cpp\n@@ -1,6 +1,5 @@\n #include \"benchmark_runner.hpp\"\n #include \"compare_result.hpp\"\n-#include \"tpch_extension.hpp\"\n #include \"duckdb_benchmark_macro.hpp\"\n \n using namespace duckdb;\n@@ -70,6 +69,6 @@ TPCHStartup(\"PRAGMA tpch(1)\") NormalConfig() string VerifyResult(QueryResult *re\n \tif (result->HasError()) {\n \t\treturn result->GetError();\n \t}\n-\treturn compare_csv(*result, TpchExtension::GetAnswer(SF, 1), true);\n+\treturn string();\n }\n FINISH_BENCHMARK(TPCHQ1)\ndiff --git a/extension/core_functions/scalar/list/flatten.cpp b/extension/core_functions/scalar/list/flatten.cpp\nindex 849c20d16c05..5f4361cdbb1a 100644\n--- a/extension/core_functions/scalar/list/flatten.cpp\n+++ b/extension/core_functions/scalar/list/flatten.cpp\n@@ -7,44 +7,41 @@\n \n namespace duckdb {\n \n-void ListFlattenFunction(DataChunk &args, ExpressionState &state, Vector &result) {\n-\tD_ASSERT(args.ColumnCount() == 1);\n+static void ListFlattenFunction(DataChunk &args, ExpressionState &, Vector &result) {\n \n-\tVector &input = args.data[0];\n-\tif (input.GetType().id() == LogicalTypeId::SQLNULL) {\n-\t\tresult.Reference(input);\n+\tconst auto flat_list_data = FlatVector::GetData<list_entry_t>(result);\n+\tauto &flat_list_mask = FlatVector::Validity(result);\n+\n+\tUnifiedVectorFormat outer_format;\n+\tUnifiedVectorFormat inner_format;\n+\tUnifiedVectorFormat items_format;\n+\n+\t// Setup outer vec;\n+\tauto &outer_vec = args.data[0];\n+\tconst auto outer_count = args.size();\n+\touter_vec.ToUnifiedFormat(outer_count, outer_format);\n+\n+\t// Special case: outer list is all-null\n+\tif (outer_vec.GetType().id() == LogicalTypeId::SQLNULL) {\n+\t\tresult.Reference(outer_vec);\n \t\treturn;\n \t}\n \n-\tidx_t count = args.size();\n-\n-\t// Prepare the result vector\n-\tresult.SetVectorType(VectorType::FLAT_VECTOR);\n-\t// This holds the new offsets and lengths\n-\tauto result_entries = FlatVector::GetData<list_entry_t>(result);\n-\tauto &result_validity = FlatVector::Validity(result);\n-\n-\t// The outermost list in each row\n-\tUnifiedVectorFormat row_data;\n-\tinput.ToUnifiedFormat(count, row_data);\n-\tauto row_entries = UnifiedVectorFormat::GetData<list_entry_t>(row_data);\n-\n-\t// The list elements in each row: [HERE, ...]\n-\tauto &row_lists = ListVector::GetEntry(input);\n-\tUnifiedVectorFormat row_lists_data;\n-\tidx_t total_row_lists = ListVector::GetListSize(input);\n-\trow_lists.ToUnifiedFormat(total_row_lists, row_lists_data);\n-\tauto row_lists_entries = UnifiedVectorFormat::GetData<list_entry_t>(row_lists_data);\n-\n-\tif (row_lists.GetType().id() == LogicalTypeId::SQLNULL) {\n-\t\tfor (idx_t row_cnt = 0; row_cnt < count; row_cnt++) {\n-\t\t\tauto row_idx = row_data.sel->get_index(row_cnt);\n-\t\t\tif (!row_data.validity.RowIsValid(row_idx)) {\n-\t\t\t\tresult_validity.SetInvalid(row_cnt);\n+\t// Setup inner vec\n+\tauto &inner_vec = ListVector::GetEntry(outer_vec);\n+\tconst auto inner_count = ListVector::GetListSize(outer_vec);\n+\tinner_vec.ToUnifiedFormat(inner_count, inner_format);\n+\n+\t// Special case: inner list is all-null\n+\tif (inner_vec.GetType().id() == LogicalTypeId::SQLNULL) {\n+\t\tfor (idx_t outer_raw_idx = 0; outer_raw_idx < outer_count; outer_raw_idx++) {\n+\t\t\tconst auto outer_idx = outer_format.sel->get_index(outer_raw_idx);\n+\t\t\tif (!outer_format.validity.RowIsValid(outer_idx)) {\n+\t\t\t\tflat_list_mask.SetInvalid(outer_raw_idx);\n \t\t\t\tcontinue;\n \t\t\t}\n-\t\t\tresult_entries[row_cnt].offset = 0;\n-\t\t\tresult_entries[row_cnt].length = 0;\n+\t\t\tflat_list_data[outer_raw_idx].offset = 0;\n+\t\t\tflat_list_data[outer_raw_idx].length = 0;\n \t\t}\n \t\tif (args.AllConstant()) {\n \t\t\tresult.SetVectorType(VectorType::CONSTANT_VECTOR);\n@@ -52,57 +49,90 @@ void ListFlattenFunction(DataChunk &args, ExpressionState &state, Vector &result\n \t\treturn;\n \t}\n \n-\t// The actual elements inside each row list: [[HERE, ...], []]\n-\t// This one becomes the child vector of the result.\n-\tauto &elem_vector = ListVector::GetEntry(row_lists);\n+\t// Setup items vec\n+\tauto &items_vec = ListVector::GetEntry(inner_vec);\n+\tconst auto items_count = ListVector::GetListSize(inner_vec);\n+\titems_vec.ToUnifiedFormat(items_count, items_format);\n+\n+\t// First pass: Figure out the total amount of items.\n+\t// This can be more than items_count if the inner list reference the same item(s) multiple times.\n+\n+\tidx_t total_items = 0;\n+\n+\tconst auto outer_data = UnifiedVectorFormat::GetData<list_entry_t>(outer_format);\n+\tconst auto inner_data = UnifiedVectorFormat::GetData<list_entry_t>(inner_format);\n+\n+\tfor (idx_t outer_raw_idx = 0; outer_raw_idx < outer_count; outer_raw_idx++) {\n+\t\tconst auto outer_idx = outer_format.sel->get_index(outer_raw_idx);\n+\n+\t\tif (!outer_format.validity.RowIsValid(outer_idx)) {\n+\t\t\tcontinue;\n+\t\t}\n+\n+\t\tconst auto &outer_entry = outer_data[outer_idx];\n+\n+\t\tfor (idx_t inner_raw_idx = outer_entry.offset; inner_raw_idx < outer_entry.offset + outer_entry.length;\n+\t\t     inner_raw_idx++) {\n+\t\t\tconst auto inner_idx = inner_format.sel->get_index(inner_raw_idx);\n \n-\t// We'll use this selection vector to slice the elem_vector.\n-\tidx_t child_elem_cnt = ListVector::GetListSize(row_lists);\n-\tSelectionVector sel(child_elem_cnt);\n+\t\t\tif (!inner_format.validity.RowIsValid(inner_idx)) {\n+\t\t\t\tcontinue;\n+\t\t\t}\n+\n+\t\t\tconst auto &inner_entry = inner_data[inner_idx];\n+\n+\t\t\ttotal_items += inner_entry.length;\n+\t\t}\n+\t}\n+\n+\t// Now we know the total amount of items, we can create our selection vector.\n+\tSelectionVector sel(total_items);\n \tidx_t sel_idx = 0;\n \n-\t// HERE, [[]], ...\n-\tfor (idx_t row_cnt = 0; row_cnt < count; row_cnt++) {\n-\t\tauto row_idx = row_data.sel->get_index(row_cnt);\n+\t// Second pass: Fill the selection vector (and the result list entries)\n+\n+\tfor (idx_t outer_raw_idx = 0; outer_raw_idx < outer_count; outer_raw_idx++) {\n+\t\tconst auto outer_idx = outer_format.sel->get_index(outer_raw_idx);\n \n-\t\tif (!row_data.validity.RowIsValid(row_idx)) {\n-\t\t\tresult_validity.SetInvalid(row_cnt);\n+\t\tif (!outer_format.validity.RowIsValid(outer_idx)) {\n+\t\t\tflat_list_mask.SetInvalid(outer_raw_idx);\n \t\t\tcontinue;\n \t\t}\n \n-\t\tidx_t list_offset = sel_idx;\n-\t\tidx_t list_length = 0;\n+\t\tconst auto &outer_entry = outer_data[outer_idx];\n+\n+\t\tlist_entry_t list_entry = {sel_idx, 0};\n \n-\t\t// [HERE, [...], ...]\n-\t\tauto row_entry = row_entries[row_idx];\n-\t\tfor (idx_t row_lists_cnt = 0; row_lists_cnt < row_entry.length; row_lists_cnt++) {\n-\t\t\tauto row_lists_idx = row_lists_data.sel->get_index(row_entry.offset + row_lists_cnt);\n+\t\tfor (idx_t inner_raw_idx = outer_entry.offset; inner_raw_idx < outer_entry.offset + outer_entry.length;\n+\t\t     inner_raw_idx++) {\n+\t\t\tconst auto inner_idx = inner_format.sel->get_index(inner_raw_idx);\n \n-\t\t\t// Skip invalid lists\n-\t\t\tif (!row_lists_data.validity.RowIsValid(row_lists_idx)) {\n+\t\t\tif (!inner_format.validity.RowIsValid(inner_idx)) {\n \t\t\t\tcontinue;\n \t\t\t}\n \n-\t\t\t// [[HERE, ...], [.., ...]]\n-\t\t\tauto list_entry = row_lists_entries[row_lists_idx];\n-\t\t\tlist_length += list_entry.length;\n+\t\t\tconst auto &inner_entry = inner_data[inner_idx];\n+\n+\t\t\tlist_entry.length += inner_entry.length;\n+\n+\t\t\tfor (idx_t elem_raw_idx = inner_entry.offset; elem_raw_idx < inner_entry.offset + inner_entry.length;\n+\t\t\t     elem_raw_idx++) {\n+\t\t\t\tconst auto elem_idx = items_format.sel->get_index(elem_raw_idx);\n \n-\t\t\tfor (idx_t elem_cnt = 0; elem_cnt < list_entry.length; elem_cnt++) {\n-\t\t\t\t// offset of the element in the elem_vector.\n-\t\t\t\tidx_t offset = list_entry.offset + elem_cnt;\n-\t\t\t\tsel.set_index(sel_idx, offset);\n+\t\t\t\tsel.set_index(sel_idx, elem_idx);\n \t\t\t\tsel_idx++;\n \t\t\t}\n \t\t}\n \n-\t\tresult_entries[row_cnt].offset = list_offset;\n-\t\tresult_entries[row_cnt].length = list_length;\n+\t\t// Assign the result list entry\n+\t\tflat_list_data[outer_raw_idx] = list_entry;\n \t}\n \n+\t// Now assing the result\n \tListVector::SetListSize(result, sel_idx);\n \n \tauto &result_child_vector = ListVector::GetEntry(result);\n-\tresult_child_vector.Slice(elem_vector, sel, sel_idx);\n+\tresult_child_vector.Slice(items_vec, sel, sel_idx);\n \tresult_child_vector.Flatten(sel_idx);\n \n \tif (args.AllConstant()) {\ndiff --git a/extension/parquet/column_writer.cpp b/extension/parquet/column_writer.cpp\nindex 2502484b50e8..5735036e6102 100644\n--- a/extension/parquet/column_writer.cpp\n+++ b/extension/parquet/column_writer.cpp\n@@ -717,6 +717,7 @@ void BasicColumnWriter::FinalizeWrite(ColumnWriterState &state_p) {\n \tcolumn_chunk.meta_data.total_compressed_size =\n \t    UnsafeNumericCast<int64_t>(column_writer.GetTotalWritten() - start_offset);\n \tcolumn_chunk.meta_data.total_uncompressed_size = UnsafeNumericCast<int64_t>(total_uncompressed_size);\n+\tstate.row_group.total_byte_size += column_chunk.meta_data.total_uncompressed_size;\n \n \tif (state.bloom_filter) {\n \t\twriter.BufferBloomFilter(state.col_idx, std::move(state.bloom_filter));\ndiff --git a/extension/parquet/parquet_writer.cpp b/extension/parquet/parquet_writer.cpp\nindex f7e3651ececa..f236362780b2 100644\n--- a/extension/parquet/parquet_writer.cpp\n+++ b/extension/parquet/parquet_writer.cpp\n@@ -395,7 +395,6 @@ void ParquetWriter::PrepareRowGroup(ColumnDataCollection &buffer, PreparedRowGro\n \t// set up a new row group for this chunk collection\n \tauto &row_group = result.row_group;\n \trow_group.num_rows = NumericCast<int64_t>(buffer.Count());\n-\trow_group.total_byte_size = NumericCast<int64_t>(buffer.SizeInBytes());\n \trow_group.__isset.file_offset = true;\n \n \tauto &states = result.states;\ndiff --git a/src/catalog/catalog.cpp b/src/catalog/catalog.cpp\nindex 0382b24a8b1d..cb2ea83bbbc4 100644\n--- a/src/catalog/catalog.cpp\n+++ b/src/catalog/catalog.cpp\n@@ -426,7 +426,12 @@ vector<CatalogSearchEntry> GetCatalogEntries(CatalogEntryRetriever &retriever, c\n \t\t\tentries.emplace_back(catalog, schema_name);\n \t\t}\n \t\tif (entries.empty()) {\n-\t\t\tentries.emplace_back(catalog, DEFAULT_SCHEMA);\n+\t\t\tauto catalog_entry = Catalog::GetCatalogEntry(context, catalog);\n+\t\t\tif (catalog_entry) {\n+\t\t\t\tentries.emplace_back(catalog, catalog_entry->GetDefaultSchema());\n+\t\t\t} else {\n+\t\t\t\tentries.emplace_back(catalog, DEFAULT_SCHEMA);\n+\t\t\t}\n \t\t}\n \t} else {\n \t\t// specific catalog and schema provided\n@@ -968,12 +973,16 @@ optional_ptr<SchemaCatalogEntry> Catalog::GetSchema(CatalogEntryRetriever &retri\n \t\t\t// skip if it is not an attached database\n \t\t\tcontinue;\n \t\t}\n-\t\tauto on_not_found = i + 1 == entries.size() ? if_not_found : OnEntryNotFound::RETURN_NULL;\n+\t\tconst auto on_not_found = i + 1 == entries.size() ? if_not_found : OnEntryNotFound::RETURN_NULL;\n \t\tauto result = catalog->GetSchema(retriever.GetContext(), schema_name, on_not_found, error_context);\n \t\tif (result) {\n \t\t\treturn result;\n \t\t}\n \t}\n+\t// Catalog has not been found.\n+\tif (if_not_found == OnEntryNotFound::THROW_EXCEPTION) {\n+\t\tthrow CatalogException(error_context, \"Catalog with name %s does not exist!\", catalog_name);\n+\t}\n \treturn nullptr;\n }\n \n@@ -1073,6 +1082,10 @@ optional_ptr<DependencyManager> Catalog::GetDependencyManager() {\n \treturn nullptr;\n }\n \n+string Catalog::GetDefaultSchema() const {\n+\treturn DEFAULT_SCHEMA;\n+}\n+\n //! Whether this catalog has a default table. Catalogs with a default table can be queries by their catalog name\n bool Catalog::HasDefaultTable() const {\n \treturn !default_table.empty();\ndiff --git a/src/catalog/catalog_search_path.cpp b/src/catalog/catalog_search_path.cpp\nindex 2f2a987519df..793de909b9f6 100644\n--- a/src/catalog/catalog_search_path.cpp\n+++ b/src/catalog/catalog_search_path.cpp\n@@ -165,7 +165,7 @@ void CatalogSearchPath::Set(vector<CatalogSearchEntry> new_paths, CatalogSetPath\n \t\tif (path.catalog.empty()) {\n \t\t\tauto catalog = Catalog::GetCatalogEntry(context, path.schema);\n \t\t\tif (catalog) {\n-\t\t\t\tauto schema = catalog->GetSchema(context, DEFAULT_SCHEMA, OnEntryNotFound::RETURN_NULL);\n+\t\t\t\tauto schema = catalog->GetSchema(context, catalog->GetDefaultSchema(), OnEntryNotFound::RETURN_NULL);\n \t\t\t\tif (schema) {\n \t\t\t\t\tpath.catalog = std::move(path.schema);\n \t\t\t\t\tpath.schema = schema->name;\n@@ -205,6 +205,22 @@ string CatalogSearchPath::GetDefaultSchema(const string &catalog) {\n \treturn DEFAULT_SCHEMA;\n }\n \n+string CatalogSearchPath::GetDefaultSchema(ClientContext &context, const string &catalog) {\n+\tfor (auto &path : paths) {\n+\t\tif (path.catalog == TEMP_CATALOG) {\n+\t\t\tcontinue;\n+\t\t}\n+\t\tif (StringUtil::CIEquals(path.catalog, catalog)) {\n+\t\t\treturn path.schema;\n+\t\t}\n+\t}\n+\tauto catalog_entry = Catalog::GetCatalogEntry(context, catalog);\n+\tif (catalog_entry) {\n+\t\treturn catalog_entry->GetDefaultSchema();\n+\t}\n+\treturn DEFAULT_SCHEMA;\n+}\n+\n string CatalogSearchPath::GetDefaultCatalog(const string &schema) {\n \tif (DefaultSchemaGenerator::IsDefaultSchema(schema)) {\n \t\treturn SYSTEM_CATALOG;\ndiff --git a/src/common/enum_util.cpp b/src/common/enum_util.cpp\nindex 0ac5bb0c4e7f..49e7bb2b9b77 100644\n--- a/src/common/enum_util.cpp\n+++ b/src/common/enum_util.cpp\n@@ -83,6 +83,7 @@\n #include \"duckdb/common/types/vector_buffer.hpp\"\n #include \"duckdb/execution/index/art/art.hpp\"\n #include \"duckdb/execution/index/art/node.hpp\"\n+#include \"duckdb/execution/index/bound_index.hpp\"\n #include \"duckdb/execution/operator/csv_scanner/csv_option.hpp\"\n #include \"duckdb/execution/operator/csv_scanner/csv_state.hpp\"\n #include \"duckdb/execution/operator/csv_scanner/quote_rules.hpp\"\n@@ -150,25 +151,6 @@\n \n namespace duckdb {\n \n-const StringUtil::EnumStringLiteral *GetARTAppendModeValues() {\n-\tstatic constexpr StringUtil::EnumStringLiteral values[] {\n-\t\t{ static_cast<uint32_t>(ARTAppendMode::DEFAULT), \"DEFAULT\" },\n-\t\t{ static_cast<uint32_t>(ARTAppendMode::IGNORE_DUPLICATES), \"IGNORE_DUPLICATES\" },\n-\t\t{ static_cast<uint32_t>(ARTAppendMode::INSERT_DUPLICATES), \"INSERT_DUPLICATES\" }\n-\t};\n-\treturn values;\n-}\n-\n-template<>\n-const char* EnumUtil::ToChars<ARTAppendMode>(ARTAppendMode value) {\n-\treturn StringUtil::EnumToString(GetARTAppendModeValues(), 3, \"ARTAppendMode\", static_cast<uint32_t>(value));\n-}\n-\n-template<>\n-ARTAppendMode EnumUtil::FromString<ARTAppendMode>(const char *value) {\n-\treturn static_cast<ARTAppendMode>(StringUtil::StringToEnum(GetARTAppendModeValues(), 3, \"ARTAppendMode\", value));\n-}\n-\n const StringUtil::EnumStringLiteral *GetARTConflictTypeValues() {\n \tstatic constexpr StringUtil::EnumStringLiteral values[] {\n \t\t{ static_cast<uint32_t>(ARTConflictType::NO_CONFLICT), \"NO_CONFLICT\" },\n@@ -1878,6 +1860,25 @@ HLLStorageType EnumUtil::FromString<HLLStorageType>(const char *value) {\n \treturn static_cast<HLLStorageType>(StringUtil::StringToEnum(GetHLLStorageTypeValues(), 2, \"HLLStorageType\", value));\n }\n \n+const StringUtil::EnumStringLiteral *GetIndexAppendModeValues() {\n+\tstatic constexpr StringUtil::EnumStringLiteral values[] {\n+\t\t{ static_cast<uint32_t>(IndexAppendMode::DEFAULT), \"DEFAULT\" },\n+\t\t{ static_cast<uint32_t>(IndexAppendMode::IGNORE_DUPLICATES), \"IGNORE_DUPLICATES\" },\n+\t\t{ static_cast<uint32_t>(IndexAppendMode::INSERT_DUPLICATES), \"INSERT_DUPLICATES\" }\n+\t};\n+\treturn values;\n+}\n+\n+template<>\n+const char* EnumUtil::ToChars<IndexAppendMode>(IndexAppendMode value) {\n+\treturn StringUtil::EnumToString(GetIndexAppendModeValues(), 3, \"IndexAppendMode\", static_cast<uint32_t>(value));\n+}\n+\n+template<>\n+IndexAppendMode EnumUtil::FromString<IndexAppendMode>(const char *value) {\n+\treturn static_cast<IndexAppendMode>(StringUtil::StringToEnum(GetIndexAppendModeValues(), 3, \"IndexAppendMode\", value));\n+}\n+\n const StringUtil::EnumStringLiteral *GetIndexConstraintTypeValues() {\n \tstatic constexpr StringUtil::EnumStringLiteral values[] {\n \t\t{ static_cast<uint32_t>(IndexConstraintType::NONE), \"NONE\" },\ndiff --git a/src/common/random_engine.cpp b/src/common/random_engine.cpp\nindex cf558ea7ad87..78403e0301af 100644\n--- a/src/common/random_engine.cpp\n+++ b/src/common/random_engine.cpp\n@@ -21,7 +21,10 @@ RandomEngine::RandomEngine(int64_t seed) : random_state(make_uniq<RandomState>()\n \tif (seed < 0) {\n #ifdef __linux__\n \t\tidx_t random_seed = 0;\n-\t\tauto result = syscall(SYS_getrandom, &random_seed, sizeof(random_seed), 0);\n+\t\tint result = -1;\n+#if defined(SYS_getrandom)\n+\t\tresult = static_cast<int>(syscall(SYS_getrandom, &random_seed, sizeof(random_seed), 0));\n+#endif\n \t\tif (result == -1) {\n \t\t\t// Something went wrong with the syscall, we use chrono\n \t\t\tconst auto now = std::chrono::high_resolution_clock::now();\ndiff --git a/src/common/serializer/memory_stream.cpp b/src/common/serializer/memory_stream.cpp\nindex e5f0455e3ee4..2b3d0bb1bf4e 100644\n--- a/src/common/serializer/memory_stream.cpp\n+++ b/src/common/serializer/memory_stream.cpp\n@@ -1,14 +1,12 @@\n #include \"duckdb/common/serializer/memory_stream.hpp\"\n \n+#include \"duckdb/common/allocator.hpp\"\n+\n namespace duckdb {\n \n MemoryStream::MemoryStream(idx_t capacity) : position(0), capacity(capacity), owns_data(true) {\n \tD_ASSERT(capacity != 0 && IsPowerOfTwo(capacity));\n-\tauto data_malloc_result = malloc(capacity);\n-\tif (!data_malloc_result) {\n-\t\tthrow std::bad_alloc();\n-\t}\n-\tdata = static_cast<data_ptr_t>(data_malloc_result);\n+\tdata = Allocator::DefaultAllocatorReference()->AllocateData(capacity);\n }\n \n MemoryStream::MemoryStream(data_ptr_t buffer, idx_t capacity)\n@@ -17,7 +15,7 @@ MemoryStream::MemoryStream(data_ptr_t buffer, idx_t capacity)\n \n MemoryStream::~MemoryStream() {\n \tif (owns_data) {\n-\t\tfree(data);\n+\t\tAllocator::DefaultAllocatorReference()->FreeData(data, capacity);\n \t}\n }\n \n@@ -39,7 +37,7 @@ MemoryStream &MemoryStream::operator=(MemoryStream &&other) noexcept {\n \tif (this != &other) {\n \t\t// Free the current data\n \t\tif (owns_data) {\n-\t\t\tfree(data);\n+\t\t\tAllocator::DefaultAllocatorReference()->FreeData(data, capacity);\n \t\t}\n \n \t\t// Move the data from the other stream into this stream\n@@ -58,14 +56,17 @@ MemoryStream &MemoryStream::operator=(MemoryStream &&other) noexcept {\n }\n \n void MemoryStream::WriteData(const_data_ptr_t source, idx_t write_size) {\n+\tconst auto old_capacity = capacity;\n \twhile (position + write_size > capacity) {\n \t\tif (owns_data) {\n \t\t\tcapacity *= 2;\n-\t\t\tdata = static_cast<data_ptr_t>(realloc(data, capacity));\n \t\t} else {\n \t\t\tthrow SerializationException(\"Failed to serialize: not enough space in buffer to fulfill write request\");\n \t\t}\n \t}\n+\tif (capacity != old_capacity) {\n+\t\tdata = Allocator::DefaultAllocatorReference()->ReallocateData(data, old_capacity, capacity);\n+\t}\n \tmemcpy(data + position, source, write_size);\n \tposition += write_size;\n }\ndiff --git a/src/execution/index/art/art.cpp b/src/execution/index/art/art.cpp\nindex 137cc98811a4..1317fb08edd2 100644\n--- a/src/execution/index/art/art.cpp\n+++ b/src/execution/index/art/art.cpp\n@@ -45,7 +45,7 @@ ART::ART(const string &name, const IndexConstraintType index_constraint_type, co\n          const shared_ptr<array<unsafe_unique_ptr<FixedSizeAllocator>, ALLOCATOR_COUNT>> &allocators_ptr,\n          const IndexStorageInfo &info)\n     : BoundIndex(name, ART::TYPE_NAME, index_constraint_type, column_ids, table_io_manager, unbound_expressions, db),\n-      allocators(allocators_ptr), owns_data(false), append_mode(ARTAppendMode::DEFAULT) {\n+      allocators(allocators_ptr), owns_data(false) {\n \n \t// FIXME: Use the new byte representation function to support nested types.\n \tfor (idx_t i = 0; i < types.size(); i++) {\n@@ -480,10 +480,11 @@ bool ART::Construct(unsafe_vector<ARTKey> &keys, unsafe_vector<ARTKey> &row_ids,\n //===--------------------------------------------------------------------===//\n \n ErrorData ART::Insert(IndexLock &l, DataChunk &chunk, Vector &row_ids) {\n-\treturn Insert(l, chunk, row_ids, nullptr);\n+\tIndexAppendInfo info;\n+\treturn Insert(l, chunk, row_ids, info);\n }\n \n-ErrorData ART::Insert(IndexLock &l, DataChunk &chunk, Vector &row_ids, optional_ptr<BoundIndex> delete_index) {\n+ErrorData ART::Insert(IndexLock &l, DataChunk &chunk, Vector &row_ids, IndexAppendInfo &info) {\n \tD_ASSERT(row_ids.GetType().InternalType() == ROW_TYPE);\n \tauto row_count = chunk.size();\n \n@@ -493,8 +494,8 @@ ErrorData ART::Insert(IndexLock &l, DataChunk &chunk, Vector &row_ids, optional_\n \tGenerateKeyVectors(allocator, chunk, row_ids, keys, row_id_keys);\n \n \toptional_ptr<ART> delete_art;\n-\tif (delete_index) {\n-\t\tdelete_art = delete_index->Cast<ART>();\n+\tif (info.delete_index) {\n+\t\tdelete_art = info.delete_index->Cast<ART>();\n \t}\n \n \tauto conflict_type = ARTConflictType::NO_CONFLICT;\n@@ -506,7 +507,7 @@ ErrorData ART::Insert(IndexLock &l, DataChunk &chunk, Vector &row_ids, optional_\n \t\tif (keys[i].Empty()) {\n \t\t\tcontinue;\n \t\t}\n-\t\tconflict_type = Insert(tree, keys[i], 0, row_id_keys[i], tree.GetGateStatus(), delete_art);\n+\t\tconflict_type = Insert(tree, keys[i], 0, row_id_keys[i], tree.GetGateStatus(), delete_art, info.append_mode);\n \t\tif (conflict_type != ARTConflictType::NO_CONFLICT) {\n \t\t\tconflict_idx = i;\n \t\t\tbreak;\n@@ -557,27 +558,27 @@ ErrorData ART::Append(IndexLock &l, DataChunk &chunk, Vector &row_ids) {\n \tExecuteExpressions(chunk, expr_chunk);\n \n \t// Now insert the data chunk.\n-\treturn Insert(l, expr_chunk, row_ids, nullptr);\n+\tIndexAppendInfo info;\n+\treturn Insert(l, expr_chunk, row_ids, info);\n }\n \n-ErrorData ART::AppendWithDeleteIndex(IndexLock &l, DataChunk &chunk, Vector &row_ids,\n-                                     optional_ptr<BoundIndex> delete_index) {\n+ErrorData ART::Append(IndexLock &l, DataChunk &chunk, Vector &row_ids, IndexAppendInfo &info) {\n \t// Execute all column expressions before inserting the data chunk.\n \tDataChunk expr_chunk;\n \texpr_chunk.Initialize(Allocator::DefaultAllocator(), logical_types);\n \tExecuteExpressions(chunk, expr_chunk);\n \n \t// Now insert the data chunk.\n-\treturn Insert(l, expr_chunk, row_ids, delete_index);\n+\treturn Insert(l, expr_chunk, row_ids, info);\n }\n \n-void ART::VerifyAppend(DataChunk &chunk, optional_ptr<BoundIndex> delete_index, optional_ptr<ConflictManager> manager) {\n+void ART::VerifyAppend(DataChunk &chunk, IndexAppendInfo &info, optional_ptr<ConflictManager> manager) {\n \tif (manager) {\n \t\tD_ASSERT(manager->LookupType() == VerifyExistenceType::APPEND);\n-\t\treturn VerifyConstraint(chunk, delete_index, *manager);\n+\t\treturn VerifyConstraint(chunk, info, *manager);\n \t}\n \tConflictManager local_manager(VerifyExistenceType::APPEND, chunk.size());\n-\tVerifyConstraint(chunk, delete_index, local_manager);\n+\tVerifyConstraint(chunk, info, local_manager);\n }\n \n void ART::InsertIntoEmpty(Node &node, const ARTKey &key, const idx_t depth, const ARTKey &row_id,\n@@ -598,15 +599,16 @@ void ART::InsertIntoEmpty(Node &node, const ARTKey &key, const idx_t depth, cons\n }\n \n ARTConflictType ART::InsertIntoInlined(Node &node, const ARTKey &key, const idx_t depth, const ARTKey &row_id,\n-                                       const GateStatus status, optional_ptr<ART> delete_art) {\n+                                       const GateStatus status, optional_ptr<ART> delete_art,\n+                                       const IndexAppendMode append_mode) {\n \n-\tif (!IsUnique() || append_mode == ARTAppendMode::INSERT_DUPLICATES) {\n+\tif (!IsUnique() || append_mode == IndexAppendMode::INSERT_DUPLICATES) {\n \t\tLeaf::InsertIntoInlined(*this, node, row_id, depth, status);\n \t\treturn ARTConflictType::NO_CONFLICT;\n \t}\n \n \tif (!delete_art) {\n-\t\tif (append_mode == ARTAppendMode::IGNORE_DUPLICATES) {\n+\t\tif (append_mode == IndexAppendMode::IGNORE_DUPLICATES) {\n \t\t\treturn ARTConflictType::NO_CONFLICT;\n \t\t}\n \t\treturn ARTConflictType::CONSTRAINT;\n@@ -633,14 +635,15 @@ ARTConflictType ART::InsertIntoInlined(Node &node, const ARTKey &key, const idx_\n }\n \n ARTConflictType ART::InsertIntoNode(Node &node, const ARTKey &key, const idx_t depth, const ARTKey &row_id,\n-                                    const GateStatus status, optional_ptr<ART> delete_art) {\n+                                    const GateStatus status, optional_ptr<ART> delete_art,\n+                                    const IndexAppendMode append_mode) {\n \tD_ASSERT(depth < key.len);\n \tauto child = node.GetChildMutable(*this, key[depth]);\n \n \t// Recurse, if a child exists at key[depth].\n \tif (child) {\n \t\tD_ASSERT(child->HasMetadata());\n-\t\tauto conflict_type = Insert(*child, key, depth + 1, row_id, status, delete_art);\n+\t\tauto conflict_type = Insert(*child, key, depth + 1, row_id, status, delete_art, append_mode);\n \t\tnode.ReplaceChild(*this, key[depth], *child);\n \t\treturn conflict_type;\n \t}\n@@ -649,7 +652,7 @@ ARTConflictType ART::InsertIntoNode(Node &node, const ARTKey &key, const idx_t d\n \tif (status == GateStatus::GATE_SET) {\n \t\tNode remainder;\n \t\tauto byte = key[depth];\n-\t\tauto conflict_type = Insert(remainder, key, depth + 1, row_id, status, delete_art);\n+\t\tauto conflict_type = Insert(remainder, key, depth + 1, row_id, status, delete_art, append_mode);\n \t\tNode::InsertChild(*this, node, byte, remainder);\n \t\treturn conflict_type;\n \t}\n@@ -671,7 +674,7 @@ ARTConflictType ART::InsertIntoNode(Node &node, const ARTKey &key, const idx_t d\n }\n \n ARTConflictType ART::Insert(Node &node, const ARTKey &key, idx_t depth, const ARTKey &row_id, const GateStatus status,\n-                            optional_ptr<ART> delete_art) {\n+                            optional_ptr<ART> delete_art, const IndexAppendMode append_mode) {\n \tif (!node.HasMetadata()) {\n \t\tInsertIntoEmpty(node, key, depth, row_id, status);\n \t\treturn ARTConflictType::NO_CONFLICT;\n@@ -688,17 +691,17 @@ ARTConflictType ART::Insert(Node &node, const ARTKey &key, idx_t depth, const AR\n \t\t\t// incoming transaction must fail here.\n \t\t\treturn ARTConflictType::TRANSACTION;\n \t\t}\n-\t\treturn Insert(node, row_id, 0, row_id, GateStatus::GATE_SET, delete_art);\n+\t\treturn Insert(node, row_id, 0, row_id, GateStatus::GATE_SET, delete_art, append_mode);\n \t}\n \n \tauto type = node.GetType();\n \tswitch (type) {\n \tcase NType::LEAF_INLINED: {\n-\t\treturn InsertIntoInlined(node, key, depth, row_id, status, delete_art);\n+\t\treturn InsertIntoInlined(node, key, depth, row_id, status, delete_art, append_mode);\n \t}\n \tcase NType::LEAF: {\n \t\tLeaf::TransformToNested(*this, node);\n-\t\treturn Insert(node, key, depth, row_id, status, delete_art);\n+\t\treturn Insert(node, key, depth, row_id, status, delete_art, append_mode);\n \t}\n \tcase NType::NODE_7_LEAF:\n \tcase NType::NODE_15_LEAF:\n@@ -712,9 +715,9 @@ ARTConflictType ART::Insert(Node &node, const ARTKey &key, idx_t depth, const AR\n \tcase NType::NODE_16:\n \tcase NType::NODE_48:\n \tcase NType::NODE_256:\n-\t\treturn InsertIntoNode(node, key, depth, row_id, status, delete_art);\n+\t\treturn InsertIntoNode(node, key, depth, row_id, status, delete_art, append_mode);\n \tcase NType::PREFIX:\n-\t\treturn Prefix::Insert(*this, node, key, depth, row_id, status, delete_art);\n+\t\treturn Prefix::Insert(*this, node, key, depth, row_id, status, delete_art, append_mode);\n \tdefault:\n \t\tthrow InternalException(\"Invalid node type for ART::Insert.\");\n \t}\n@@ -1119,7 +1122,7 @@ void ART::VerifyLeaf(const Node &leaf, const ARTKey &key, optional_ptr<ART> dele\n \t}\n }\n \n-void ART::VerifyConstraint(DataChunk &chunk, optional_ptr<BoundIndex> delete_index, ConflictManager &manager) {\n+void ART::VerifyConstraint(DataChunk &chunk, IndexAppendInfo &info, ConflictManager &manager) {\n \t// Lock the index during constraint checking.\n \tlock_guard<mutex> l(lock);\n \n@@ -1132,8 +1135,8 @@ void ART::VerifyConstraint(DataChunk &chunk, optional_ptr<BoundIndex> delete_ind\n \tGenerateKeys<>(arena_allocator, expr_chunk, keys);\n \n \toptional_ptr<ART> delete_art;\n-\tif (delete_index) {\n-\t\tdelete_art = delete_index->Cast<ART>();\n+\tif (info.delete_index) {\n+\t\tdelete_art = info.delete_index->Cast<ART>();\n \t}\n \n \toptional_idx conflict_idx;\ndiff --git a/src/execution/index/art/leaf.cpp b/src/execution/index/art/leaf.cpp\nindex 5cde0d5d042a..f5eadf178e9c 100644\n--- a/src/execution/index/art/leaf.cpp\n+++ b/src/execution/index/art/leaf.cpp\n@@ -26,7 +26,7 @@ void Leaf::New(ART &art, reference<Node> &node, const unsafe_vector<ARTKey> &row\n \t// We cannot recurse into the leaf during Construct(...) because row IDs are not sorted.\n \tfor (idx_t i = 0; i < count; i++) {\n \t\tidx_t offset = start + i;\n-\t\tart.Insert(node, row_ids[offset], 0, row_ids[offset], GateStatus::GATE_SET, nullptr);\n+\t\tart.Insert(node, row_ids[offset], 0, row_ids[offset], GateStatus::GATE_SET, nullptr, IndexAppendMode::DEFAULT);\n \t}\n \tnode.get().SetGateStatus(GateStatus::GATE_SET);\n }\n@@ -36,7 +36,7 @@ void Leaf::MergeInlined(ART &art, Node &l_node, Node &r_node) {\n \n \tArenaAllocator arena_allocator(Allocator::Get(art.db));\n \tauto key = ARTKey::CreateARTKey<row_t>(arena_allocator, r_node.GetRowId());\n-\tart.Insert(l_node, key, 0, key, l_node.GetGateStatus(), nullptr);\n+\tart.Insert(l_node, key, 0, key, l_node.GetGateStatus(), nullptr, IndexAppendMode::DEFAULT);\n \tr_node.Clear();\n }\n \n@@ -96,18 +96,14 @@ void Leaf::TransformToNested(ART &art, Node &node) {\n \tArenaAllocator allocator(Allocator::Get(art.db));\n \tNode root = Node();\n \n-\t// Temporarily disable constraint checking.\n-\tif (art.IsUnique() && art.append_mode == ARTAppendMode::DEFAULT) {\n-\t\tart.append_mode = ARTAppendMode::INSERT_DUPLICATES;\n-\t}\n-\n \t// Move all row IDs into the nested leaf.\n \treference<const Node> leaf_ref(node);\n \twhile (leaf_ref.get().HasMetadata()) {\n \t\tauto &leaf = Node::Ref<const Leaf>(art, leaf_ref, LEAF);\n \t\tfor (uint8_t i = 0; i < leaf.count; i++) {\n \t\t\tauto row_id = ARTKey::CreateARTKey<row_t>(allocator, leaf.row_ids[i]);\n-\t\t\tauto conflict_type = art.Insert(root, row_id, 0, row_id, GateStatus::GATE_SET, nullptr);\n+\t\t\tauto conflict_type =\n+\t\t\t    art.Insert(root, row_id, 0, row_id, GateStatus::GATE_SET, nullptr, IndexAppendMode::INSERT_DUPLICATES);\n \t\t\tif (conflict_type != ARTConflictType::NO_CONFLICT) {\n \t\t\t\tthrow InternalException(\"invalid conflict type in Leaf::TransformToNested\");\n \t\t\t}\n@@ -115,7 +111,6 @@ void Leaf::TransformToNested(ART &art, Node &node) {\n \t\tleaf_ref = leaf.ptr;\n \t}\n \n-\tart.append_mode = ARTAppendMode::DEFAULT;\n \troot.SetGateStatus(GateStatus::GATE_SET);\n \tNode::Free(art, node);\n \tnode = root;\ndiff --git a/src/execution/index/art/node.cpp b/src/execution/index/art/node.cpp\nindex 25c1dd5ff6da..1a85ad921fd5 100644\n--- a/src/execution/index/art/node.cpp\n+++ b/src/execution/index/art/node.cpp\n@@ -572,7 +572,7 @@ bool Node::MergeInternal(ART &art, Node &other, const GateStatus status) {\n \t\tArenaAllocator allocator(Allocator::Get(art.db));\n \t\tfor (idx_t i = 0; i < row_ids.size(); i++) {\n \t\t\tauto row_id = ARTKey::CreateARTKey<row_t>(allocator, row_ids[i]);\n-\t\t\tart.Insert(*this, row_id, 0, row_id, GateStatus::GATE_SET, nullptr);\n+\t\t\tart.Insert(*this, row_id, 0, row_id, GateStatus::GATE_SET, nullptr, IndexAppendMode::DEFAULT);\n \t\t}\n \t\treturn true;\n \t}\ndiff --git a/src/execution/index/art/prefix.cpp b/src/execution/index/art/prefix.cpp\nindex f0821be040c3..551171819d16 100644\n--- a/src/execution/index/art/prefix.cpp\n+++ b/src/execution/index/art/prefix.cpp\n@@ -292,7 +292,8 @@ GateStatus Prefix::Split(ART &art, reference<Node> &node, Node &child, const uin\n }\n \n ARTConflictType Prefix::Insert(ART &art, Node &node, const ARTKey &key, idx_t depth, const ARTKey &row_id,\n-                               const GateStatus status, optional_ptr<ART> delete_art) {\n+                               const GateStatus status, optional_ptr<ART> delete_art,\n+                               const IndexAppendMode append_mode) {\n \treference<Node> next(node);\n \tauto pos = TraverseMutable(art, next, key, depth);\n \n@@ -301,7 +302,7 @@ ARTConflictType Prefix::Insert(ART &art, Node &node, const ARTKey &key, idx_t de\n \t// (2) we reach a gate.\n \tif (pos == DConstants::INVALID_INDEX) {\n \t\tif (next.get().GetType() != NType::PREFIX || next.get().GetGateStatus() == GateStatus::GATE_SET) {\n-\t\t\treturn art.Insert(next, key, depth, row_id, status, delete_art);\n+\t\t\treturn art.Insert(next, key, depth, row_id, status, delete_art, append_mode);\n \t\t}\n \t}\n \ndiff --git a/src/execution/index/bound_index.cpp b/src/execution/index/bound_index.cpp\nindex 199cc4bddb49..26933680adc3 100644\n--- a/src/execution/index/bound_index.cpp\n+++ b/src/execution/index/bound_index.cpp\n@@ -38,24 +38,22 @@ ErrorData BoundIndex::Append(DataChunk &chunk, Vector &row_ids) {\n \treturn Append(l, chunk, row_ids);\n }\n \n-ErrorData BoundIndex::AppendWithDeleteIndex(IndexLock &l, DataChunk &chunk, Vector &row_ids,\n-                                            optional_ptr<BoundIndex> delete_index) {\n+ErrorData BoundIndex::Append(IndexLock &l, DataChunk &chunk, Vector &row_ids, IndexAppendInfo &info) {\n \t// Fallback to the old Append.\n \treturn Append(l, chunk, row_ids);\n }\n \n-ErrorData BoundIndex::AppendWithDeleteIndex(DataChunk &chunk, Vector &row_ids, optional_ptr<BoundIndex> delete_index) {\n+ErrorData BoundIndex::Append(DataChunk &chunk, Vector &row_ids, IndexAppendInfo &info) {\n \tIndexLock l;\n \tInitializeLock(l);\n-\treturn AppendWithDeleteIndex(l, chunk, row_ids, delete_index);\n+\treturn Append(l, chunk, row_ids, info);\n }\n \n-void BoundIndex::VerifyAppend(DataChunk &chunk, optional_ptr<BoundIndex> delete_index,\n-                              optional_ptr<ConflictManager> manager) {\n+void BoundIndex::VerifyAppend(DataChunk &chunk, IndexAppendInfo &info, optional_ptr<ConflictManager> manager) {\n \tthrow NotImplementedException(\"this implementation of VerifyAppend does not exist.\");\n }\n \n-void BoundIndex::VerifyConstraint(DataChunk &chunk, optional_ptr<BoundIndex> delete_index, ConflictManager &manager) {\n+void BoundIndex::VerifyConstraint(DataChunk &chunk, IndexAppendInfo &info, ConflictManager &manager) {\n \tthrow NotImplementedException(\"this implementation of VerifyConstraint does not exist.\");\n }\n \n@@ -71,7 +69,7 @@ void BoundIndex::Delete(DataChunk &entries, Vector &row_identifiers) {\n \tDelete(state, entries, row_identifiers);\n }\n \n-ErrorData BoundIndex::Insert(IndexLock &l, DataChunk &chunk, Vector &row_ids, optional_ptr<BoundIndex> delete_index) {\n+ErrorData BoundIndex::Insert(IndexLock &l, DataChunk &chunk, Vector &row_ids, IndexAppendInfo &info) {\n \tthrow NotImplementedException(\"this implementation of Insert does not exist.\");\n }\n \ndiff --git a/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp b/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\nindex c922f7294b2a..94ef37399510 100644\n--- a/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\n+++ b/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\n@@ -126,6 +126,10 @@ StringValueResult::StringValueResult(CSVStates &states, CSVStateMachine &state_m\n \t\t\tSkipBOM();\n \t\t}\n \t}\n+\tignore_empty_values = state_machine.dialect_options.state_machine_options.delimiter.GetValue()[0] != ' ' &&\n+\t                      state_machine.dialect_options.state_machine_options.quote != ' ' &&\n+\t                      state_machine.dialect_options.state_machine_options.escape != ' ' &&\n+\t                      state_machine.dialect_options.state_machine_options.comment != ' ';\n }\n \n StringValueResult::~StringValueResult() {\n@@ -503,8 +507,15 @@ void StringValueResult::AddQuotedValue(StringValueResult &result, const idx_t bu\n \tif (!result.unquoted) {\n \t\tresult.current_errors.Insert(UNTERMINATED_QUOTES, result.cur_col_id, result.chunk_col_id, result.last_position);\n \t}\n-\tAddPossiblyEscapedValue(result, buffer_pos, result.buffer_ptr + result.quoted_position + 1,\n-\t                        buffer_pos - result.quoted_position - 2, buffer_pos < result.last_position.buffer_pos + 2);\n+\t// remove potential empty values\n+\tidx_t length = buffer_pos - result.quoted_position - 1;\n+\twhile (length > 0 && result.ignore_empty_values &&\n+\t       result.buffer_ptr[result.quoted_position + 1 + length - 1] == ' ') {\n+\t\tlength--;\n+\t}\n+\tlength--;\n+\tAddPossiblyEscapedValue(result, buffer_pos, result.buffer_ptr + result.quoted_position + 1, length,\n+\t                        buffer_pos < result.last_position.buffer_pos + 2);\n \tresult.quoted = false;\n }\n \n@@ -1365,8 +1376,12 @@ void StringValueScanner::ProcessOverBufferValue() {\n \tif (!skip_value) {\n \t\tstring_t value;\n \t\tif (result.quoted && !result.comment) {\n-\t\t\tvalue = string_t(over_buffer_string.c_str() + result.quoted_position,\n-\t\t\t                 UnsafeNumericCast<uint32_t>(over_buffer_string.size() - 1 - result.quoted_position));\n+\t\t\tidx_t length = over_buffer_string.size() - 1 - result.quoted_position;\n+\t\t\twhile (length > 0 && result.ignore_empty_values &&\n+\t\t\t       over_buffer_string.c_str()[result.quoted_position + length] == ' ') {\n+\t\t\t\tlength--;\n+\t\t\t}\n+\t\t\tvalue = string_t(over_buffer_string.c_str() + result.quoted_position, UnsafeNumericCast<uint32_t>(length));\n \t\t\tif (result.escaped) {\n \t\t\t\tif (!result.HandleTooManyColumnsError(over_buffer_string.c_str(), over_buffer_string.size())) {\n \t\t\t\t\tconst auto str_ptr = over_buffer_string.c_str() + result.quoted_position;\ndiff --git a/src/execution/operator/persistent/physical_copy_database.cpp b/src/execution/operator/persistent/physical_copy_database.cpp\nindex 6ad354ea2edc..3479f7887ce5 100644\n--- a/src/execution/operator/persistent/physical_copy_database.cpp\n+++ b/src/execution/operator/persistent/physical_copy_database.cpp\n@@ -1,6 +1,8 @@\n #include \"duckdb/execution/operator/persistent/physical_copy_database.hpp\"\n+\n #include \"duckdb/catalog/catalog.hpp\"\n #include \"duckdb/catalog/catalog_entry/schema_catalog_entry.hpp\"\n+#include \"duckdb/catalog/catalog_entry/table_catalog_entry.hpp\"\n #include \"duckdb/planner/binder.hpp\"\n #include \"duckdb/planner/parsed_data/bound_create_table_info.hpp\"\n #include \"duckdb/parser/parsed_data/create_schema_info.hpp\"\n@@ -9,6 +11,8 @@\n #include \"duckdb/parser/parsed_data/create_type_info.hpp\"\n #include \"duckdb/parser/parsed_data/create_view_info.hpp\"\n #include \"duckdb/parser/parsed_data/create_index_info.hpp\"\n+#include \"duckdb/execution/index/unbound_index.hpp\"\n+#include \"duckdb/storage/data_table.hpp\"\n \n namespace duckdb {\n \n@@ -52,7 +56,7 @@ SourceResultType PhysicalCopyDatabase::GetData(ExecutionContext &context, DataCh\n \t\t\tbreak;\n \t\t}\n \t\tcase CatalogType::INDEX_ENTRY: {\n-\t\t\tcatalog.CreateIndex(context.client, create_info->Cast<CreateIndexInfo>());\n+\t\t\t// Skip for now.\n \t\t\tbreak;\n \t\t}\n \t\tdefault:\n@@ -60,6 +64,27 @@ SourceResultType PhysicalCopyDatabase::GetData(ExecutionContext &context, DataCh\n \t\t\t                              CatalogTypeToString(create_info->type));\n \t\t}\n \t}\n+\n+\t// Create the indexes after table creation.\n+\tfor (auto &create_info : info->entries) {\n+\t\tif (!create_info || create_info->type != CatalogType::INDEX_ENTRY) {\n+\t\t\tcontinue;\n+\t\t}\n+\t\tcatalog.CreateIndex(context.client, create_info->Cast<CreateIndexInfo>());\n+\n+\t\tauto &create_index_info = create_info->Cast<CreateIndexInfo>();\n+\t\tauto &catalog_table = catalog.GetEntry(context.client, CatalogType::TABLE_ENTRY, create_index_info.schema,\n+\t\t                                       create_index_info.table);\n+\t\tauto &table_entry = catalog_table.Cast<TableCatalogEntry>();\n+\t\tauto &data_table = table_entry.GetStorage();\n+\n+\t\tIndexStorageInfo storage_info(create_index_info.index_name);\n+\t\tstorage_info.options.emplace(\"v1_0_0_storage\", false);\n+\t\tauto unbound_index = make_uniq<UnboundIndex>(create_index_info.Copy(), storage_info,\n+\t\t                                             data_table.GetTableIOManager(), catalog.GetAttached());\n+\t\tdata_table.AddIndex(std::move(unbound_index));\n+\t}\n+\n \treturn SourceResultType::FINISHED;\n }\n \ndiff --git a/src/execution/operator/persistent/physical_delete.cpp b/src/execution/operator/persistent/physical_delete.cpp\nindex 7d494ac0c18f..abb705aa01be 100644\n--- a/src/execution/operator/persistent/physical_delete.cpp\n+++ b/src/execution/operator/persistent/physical_delete.cpp\n@@ -133,12 +133,13 @@ SinkResultType PhysicalDelete::Sink(ExecutionContext &context, DataChunk &chunk,\n \tif (g_state.has_unique_indexes && l_state.delete_chunk.size() != 0) {\n \t\tauto &local_storage = LocalStorage::Get(context.client, table.db);\n \t\tauto storage = local_storage.GetStorage(table);\n+\t\tIndexAppendInfo index_append_info(IndexAppendMode::IGNORE_DUPLICATES, nullptr);\n \t\tstorage->delete_indexes.Scan([&](Index &index) {\n \t\t\tif (!index.IsBound() || !index.IsUnique()) {\n \t\t\t\treturn false;\n \t\t\t}\n \t\t\tauto &bound_index = index.Cast<BoundIndex>();\n-\t\t\tauto error = bound_index.Append(l_state.delete_chunk, row_ids);\n+\t\t\tauto error = bound_index.Append(l_state.delete_chunk, row_ids, index_append_info);\n \t\t\tif (error.HasError()) {\n \t\t\t\tthrow InternalException(\"failed to update delete ART in physical delete: \", error.Message());\n \t\t\t}\ndiff --git a/src/execution/operator/persistent/physical_insert.cpp b/src/execution/operator/persistent/physical_insert.cpp\nindex cb21cc26b91c..a3c6619ed5e9 100644\n--- a/src/execution/operator/persistent/physical_insert.cpp\n+++ b/src/execution/operator/persistent/physical_insert.cpp\n@@ -80,17 +80,15 @@ InsertGlobalState::InsertGlobalState(ClientContext &context, const vector<Logica\n     : table(table), insert_count(0), initialized(false), return_collection(context, return_types) {\n }\n \n-InsertLocalState::InsertLocalState(ClientContext &context, const vector<LogicalType> &types_p,\n+InsertLocalState::InsertLocalState(ClientContext &context, const vector<LogicalType> &types,\n                                    const vector<unique_ptr<Expression>> &bound_defaults,\n                                    const vector<unique_ptr<BoundConstraint>> &bound_constraints)\n     : default_executor(context, bound_defaults), bound_constraints(bound_constraints) {\n \n \tauto &allocator = Allocator::Get(context);\n-\n-\ttypes = types_p;\n-\tauto initialize = vector<bool>(types.size(), false);\n-\tupdate_chunk.Initialize(allocator, types, initialize);\n-\tappend_chunk.Initialize(allocator, types, initialize);\n+\tinsert_chunk.Initialize(allocator, types);\n+\tupdate_chunk.Initialize(allocator, types);\n+\tappend_chunk.Initialize(allocator, types);\n }\n \n ConstraintState &InsertLocalState::GetConstraintState(DataTable &table, TableCatalogEntry &table_ref) {\n@@ -187,10 +185,8 @@ static void CombineExistingAndInsertTuples(DataChunk &result, DataChunk &scan_ch\n \tauto &insert_types = op.insert_types;\n \n \tif (types_to_fetch.empty()) {\n-\t\t// We have not scanned the initial table, so we duplicate the initial chunk.\n-\t\tconst auto &types = input_chunk.GetTypes();\n-\t\tauto initialize = vector<bool>(types.size(), false);\n-\t\tresult.Initialize(client, types, initialize, input_chunk.size());\n+\t\t// We have not scanned the initial table, so we can just duplicate the initial chunk\n+\t\tresult.Initialize(client, input_chunk.GetTypes());\n \t\tresult.Reference(input_chunk);\n \t\tresult.SetCardinality(input_chunk);\n \t\treturn;\n@@ -200,7 +196,7 @@ static void CombineExistingAndInsertTuples(DataChunk &result, DataChunk &scan_ch\n \tcombined_types.insert(combined_types.end(), insert_types.begin(), insert_types.end());\n \tcombined_types.insert(combined_types.end(), types_to_fetch.begin(), types_to_fetch.end());\n \n-\tresult.Initialize(client, combined_types, input_chunk.size());\n+\tresult.Initialize(client, combined_types);\n \tresult.Reset();\n \t// Add the VALUES list\n \tfor (idx_t i = 0; i < insert_types.size(); i++) {\n@@ -227,8 +223,8 @@ static void CombineExistingAndInsertTuples(DataChunk &result, DataChunk &scan_ch\n \tresult.SetCardinality(input_chunk.size());\n }\n \n-static void CreateUpdateChunk(ExecutionContext &context, DataChunk &chunk, Vector &row_ids, DataChunk &update_chunk,\n-                              const PhysicalInsert &op) {\n+static void CreateUpdateChunk(ExecutionContext &context, DataChunk &chunk, TableCatalogEntry &table, Vector &row_ids,\n+                              DataChunk &update_chunk, const PhysicalInsert &op) {\n \n \tauto &do_update_condition = op.do_update_condition;\n \tauto &set_types = op.set_types;\n@@ -284,7 +280,7 @@ static idx_t PerformOnConflictAction(InsertLocalState &lstate, ExecutionContext\n \n \tauto &set_columns = op.set_columns;\n \tDataChunk update_chunk;\n-\tCreateUpdateChunk(context, chunk, row_ids, update_chunk, op);\n+\tCreateUpdateChunk(context, chunk, table, row_ids, update_chunk, op);\n \tauto &data_table = table.GetStorage();\n \n \t// Perform the UPDATE on the (global) storage.\n@@ -488,9 +484,7 @@ static idx_t HandleInsertConflicts(TableCatalogEntry &table, ExecutionContext &c\n \tDataChunk combined_chunk; // contains conflict_chunk + scan_chunk (wide)\n \n \t// Filter out everything but the conflicting rows\n-\tconst auto &types = tuples.GetTypes();\n-\tauto initialize = vector<bool>(types.size(), false);\n-\tconflict_chunk.Initialize(context.client, types, initialize, tuples.size());\n+\tconflict_chunk.Initialize(context.client, tuples.GetTypes());\n \tconflict_chunk.Reference(tuples);\n \tconflict_chunk.Slice(conflicts.Selection(), conflicts.Count());\n \tconflict_chunk.SetCardinality(conflicts.Count());\n@@ -501,7 +495,7 @@ static idx_t HandleInsertConflicts(TableCatalogEntry &table, ExecutionContext &c\n \t\tD_ASSERT(scan_chunk.size() == 0);\n \t\t// When these values are required for the conditions or the SET expressions,\n \t\t// then we scan the existing table for the conflicting tuples, using the rowids\n-\t\tscan_chunk.Initialize(context.client, types_to_fetch, conflicts.Count());\n+\t\tscan_chunk.Initialize(context.client, types_to_fetch);\n \t\tfetch_state = make_uniq<ColumnFetchState>();\n \t\tif (GLOBAL) {\n \t\t\tauto &transaction = DuckTransaction::Get(context.client, table.catalog);\n@@ -534,7 +528,7 @@ static idx_t HandleInsertConflicts(TableCatalogEntry &table, ExecutionContext &c\n \treturn affected_tuples;\n }\n \n-idx_t PhysicalInsert::OnConflictHandling(TableCatalogEntry &table, ExecutionContext &context,\n+idx_t PhysicalInsert::OnConflictHandling(TableCatalogEntry &table, ExecutionContext &context, InsertGlobalState &gstate,\n                                          InsertLocalState &lstate) const {\n \tauto &data_table = table.GetStorage();\n \tauto &local_storage = LocalStorage::Get(context.client, data_table.db);\n@@ -634,21 +628,6 @@ SinkResultType PhysicalInsert::Sink(ExecutionContext &context, DataChunk &chunk,\n \n \tauto &table = gstate.table;\n \tauto &storage = table.GetStorage();\n-\tif (lstate.init_insert_chunk) {\n-\t\tauto initialize = vector<bool>(lstate.types.size(), false);\n-\t\tif (!column_index_map.empty()) {\n-\t\t\tfor (auto &col : table.GetColumns().Physical()) {\n-\t\t\t\tauto storage_idx = col.StorageOid();\n-\t\t\t\tauto mapped_index = column_index_map[col.Physical()];\n-\t\t\t\tif (mapped_index == DConstants::INVALID_INDEX) {\n-\t\t\t\t\tinitialize[storage_idx] = true;\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n-\t\tauto &allocator = Allocator::Get(context.client);\n-\t\tlstate.insert_chunk.Initialize(allocator, lstate.types, initialize, chunk.size());\n-\t\tlstate.init_insert_chunk = false;\n-\t}\n \tPhysicalInsert::ResolveDefaults(table, chunk, column_index_map, lstate.default_executor, lstate.insert_chunk);\n \n \tif (!parallel) {\n@@ -663,7 +642,7 @@ SinkResultType PhysicalInsert::Sink(ExecutionContext &context, DataChunk &chunk,\n \t\t\t// so it should not be added to the RETURNING chunk\n \t\t\tgstate.return_collection.Append(lstate.insert_chunk);\n \t\t}\n-\t\tidx_t updated_tuples = OnConflictHandling(table, context, lstate);\n+\t\tidx_t updated_tuples = OnConflictHandling(table, context, gstate, lstate);\n \t\tif (action_type == OnConflictAction::NOTHING && return_chunk) {\n \t\t\t// Because we didn't add to the RETURNING chunk yet\n \t\t\t// we add the tuples that did not get filtered out now\n@@ -694,7 +673,7 @@ SinkResultType PhysicalInsert::Sink(ExecutionContext &context, DataChunk &chunk,\n \t\t\tlstate.local_collection->InitializeAppend(lstate.local_append_state);\n \t\t\tlstate.writer = &gstate.table.GetStorage().CreateOptimisticWriter(context.client);\n \t\t}\n-\t\tOnConflictHandling(table, context, lstate);\n+\t\tOnConflictHandling(table, context, gstate, lstate);\n \t\tD_ASSERT(action_type != OnConflictAction::UPDATE);\n \n \t\tauto new_row_group = lstate.local_collection->Append(lstate.insert_chunk, lstate.local_append_state);\ndiff --git a/src/execution/operator/schema/physical_create_art_index.cpp b/src/execution/operator/schema/physical_create_art_index.cpp\nindex e34e49de475e..8f9b2657e0a8 100644\n--- a/src/execution/operator/schema/physical_create_art_index.cpp\n+++ b/src/execution/operator/schema/physical_create_art_index.cpp\n@@ -88,7 +88,8 @@ SinkResultType PhysicalCreateARTIndex::SinkUnsorted(OperatorSinkInput &input) co\n \t// Insert each key and its corresponding row ID.\n \tfor (idx_t i = 0; i < row_count; i++) {\n \t\tauto status = art.tree.GetGateStatus();\n-\t\tauto conflict_type = art.Insert(art.tree, l_state.keys[i], 0, l_state.row_ids[i], status, nullptr);\n+\t\tauto conflict_type =\n+\t\t    art.Insert(art.tree, l_state.keys[i], 0, l_state.row_ids[i], status, nullptr, IndexAppendMode::DEFAULT);\n \t\tD_ASSERT(conflict_type != ARTConflictType::TRANSACTION);\n \t\tif (conflict_type == ARTConflictType::CONSTRAINT) {\n \t\t\tthrow ConstraintException(\"Data contains duplicates on indexed column(s)\");\ndiff --git a/src/execution/sample/reservoir_sample.cpp b/src/execution/sample/reservoir_sample.cpp\nindex 334b613d1d0a..58056920eaf8 100644\n--- a/src/execution/sample/reservoir_sample.cpp\n+++ b/src/execution/sample/reservoir_sample.cpp\n@@ -749,6 +749,7 @@ void ReservoirSample::AddToReservoir(DataChunk &chunk) {\n \n \tif (chunk_sel.size == 0) {\n \t\t// not adding any samples\n+\t\tbase_reservoir_sample->num_entries_seen_total += chunk.size();\n \t\treturn;\n \t}\n \tidx_t size = chunk_sel.size;\ndiff --git a/src/include/duckdb/catalog/catalog.hpp b/src/include/duckdb/catalog/catalog.hpp\nindex 121b047cb781..96679f2a9153 100644\n--- a/src/include/duckdb/catalog/catalog.hpp\n+++ b/src/include/duckdb/catalog/catalog.hpp\n@@ -315,7 +315,11 @@ class Catalog {\n \t\treturn CatalogLookupBehavior::STANDARD;\n \t}\n \n+\t//! Returns the default schema of the catalog\n+\tvirtual string GetDefaultSchema() const;\n+\n \t//! The default table is used for `SELECT * FROM <catalog_name>;`\n+\t//! FIXME: these should be virtual methods\n \tDUCKDB_API bool HasDefaultTable() const;\n \tDUCKDB_API void SetDefaultTable(const string &schema, const string &name);\n \tDUCKDB_API string GetDefaultTable() const;\ndiff --git a/src/include/duckdb/catalog/catalog_search_path.hpp b/src/include/duckdb/catalog/catalog_search_path.hpp\nindex ff0def0fcd30..f128a4962e75 100644\n--- a/src/include/duckdb/catalog/catalog_search_path.hpp\n+++ b/src/include/duckdb/catalog/catalog_search_path.hpp\n@@ -53,7 +53,9 @@ class CatalogSearchPath {\n \t\treturn set_paths;\n \t}\n \tDUCKDB_API const CatalogSearchEntry &GetDefault();\n+\t//! FIXME: this method is deprecated\n \tDUCKDB_API string GetDefaultSchema(const string &catalog);\n+\tDUCKDB_API string GetDefaultSchema(ClientContext &context, const string &catalog);\n \tDUCKDB_API string GetDefaultCatalog(const string &schema);\n \n \tDUCKDB_API vector<string> GetSchemasForCatalog(const string &catalog);\ndiff --git a/src/include/duckdb/common/enum_util.hpp b/src/include/duckdb/common/enum_util.hpp\nindex accdea5d42eb..379a23969c55 100644\n--- a/src/include/duckdb/common/enum_util.hpp\n+++ b/src/include/duckdb/common/enum_util.hpp\n@@ -32,8 +32,6 @@ struct EnumUtil {\n     static string ToString(T value) { return string(ToChars<T>(value)); }\n };\n \n-enum class ARTAppendMode : uint8_t;\n-\n enum class ARTConflictType : uint8_t;\n \n enum class AccessMode : uint8_t;\n@@ -188,6 +186,8 @@ enum class GateStatus : uint8_t;\n \n enum class HLLStorageType : uint8_t;\n \n+enum class IndexAppendMode : uint8_t;\n+\n enum class IndexConstraintType : uint8_t;\n \n enum class InsertColumnOrder : uint8_t;\n@@ -391,9 +391,6 @@ enum class WindowBoundary : uint8_t;\n enum class WindowExcludeMode : uint8_t;\n \n \n-template<>\n-const char* EnumUtil::ToChars<ARTAppendMode>(ARTAppendMode value);\n-\n template<>\n const char* EnumUtil::ToChars<ARTConflictType>(ARTConflictType value);\n \n@@ -625,6 +622,9 @@ const char* EnumUtil::ToChars<GateStatus>(GateStatus value);\n template<>\n const char* EnumUtil::ToChars<HLLStorageType>(HLLStorageType value);\n \n+template<>\n+const char* EnumUtil::ToChars<IndexAppendMode>(IndexAppendMode value);\n+\n template<>\n const char* EnumUtil::ToChars<IndexConstraintType>(IndexConstraintType value);\n \n@@ -929,9 +929,6 @@ template<>\n const char* EnumUtil::ToChars<WindowExcludeMode>(WindowExcludeMode value);\n \n \n-template<>\n-ARTAppendMode EnumUtil::FromString<ARTAppendMode>(const char *value);\n-\n template<>\n ARTConflictType EnumUtil::FromString<ARTConflictType>(const char *value);\n \n@@ -1163,6 +1160,9 @@ GateStatus EnumUtil::FromString<GateStatus>(const char *value);\n template<>\n HLLStorageType EnumUtil::FromString<HLLStorageType>(const char *value);\n \n+template<>\n+IndexAppendMode EnumUtil::FromString<IndexAppendMode>(const char *value);\n+\n template<>\n IndexConstraintType EnumUtil::FromString<IndexConstraintType>(const char *value);\n \ndiff --git a/src/include/duckdb/execution/index/art/art.hpp b/src/include/duckdb/execution/index/art/art.hpp\nindex 31a560ad5842..d6f41c1c4d92 100644\n--- a/src/include/duckdb/execution/index/art/art.hpp\n+++ b/src/include/duckdb/execution/index/art/art.hpp\n@@ -16,7 +16,6 @@ namespace duckdb {\n \n enum class VerifyExistenceType : uint8_t { APPEND = 0, APPEND_FK = 1, DELETE_FK = 2 };\n enum class ARTConflictType : uint8_t { NO_CONFLICT = 0, CONSTRAINT = 1, TRANSACTION = 2 };\n-enum class ARTAppendMode : uint8_t { DEFAULT = 0, IGNORE_DUPLICATES = 1, INSERT_DUPLICATES = 2 };\n \n class ConflictManager;\n class ARTKey;\n@@ -62,8 +61,6 @@ class ART : public BoundIndex {\n \tbool owns_data;\n \t//! The number of bytes fitting in the prefix.\n \tuint8_t prefix_count;\n-\t//! The append mode.\n-\tARTAppendMode append_mode;\n \n public:\n \t//! Try to initialize a scan on the ART with the given expression and filter.\n@@ -74,21 +71,19 @@ class ART : public BoundIndex {\n \n \t//! Appends data to the locked index.\n \tErrorData Append(IndexLock &l, DataChunk &chunk, Vector &row_ids) override;\n-\t//! Appends data to the locked index and verifies constraint violations against a delete index.\n-\tErrorData AppendWithDeleteIndex(IndexLock &l, DataChunk &chunk, Vector &row_ids,\n-\t                                optional_ptr<BoundIndex> delete_index) override;\n+\t//! Appends data to the locked index and verifies constraint violations.\n+\tErrorData Append(IndexLock &l, DataChunk &chunk, Vector &row_ids, IndexAppendInfo &info) override;\n \n \t//! Internally inserts a chunk.\n \tARTConflictType Insert(Node &node, const ARTKey &key, idx_t depth, const ARTKey &row_id, const GateStatus status,\n-\t                       optional_ptr<ART> delete_art);\n+\t                       optional_ptr<ART> delete_art, const IndexAppendMode append_mode);\n \t//! Insert a chunk.\n \tErrorData Insert(IndexLock &l, DataChunk &chunk, Vector &row_ids) override;\n-\t//! Insert a chunk and verifies constraint violations against a delete index.\n-\tErrorData Insert(IndexLock &l, DataChunk &data, Vector &row_ids, optional_ptr<BoundIndex> delete_index) override;\n+\t//! Insert a chunk and verifies constraint violations.\n+\tErrorData Insert(IndexLock &l, DataChunk &data, Vector &row_ids, IndexAppendInfo &info) override;\n \n \t//! Verify that data can be appended to the index without a constraint violation.\n-\tvoid VerifyAppend(DataChunk &chunk, optional_ptr<BoundIndex> delete_index,\n-\t                  optional_ptr<ConflictManager> manager) override;\n+\tvoid VerifyAppend(DataChunk &chunk, IndexAppendInfo &info, optional_ptr<ConflictManager> manager) override;\n \n \t//! Delete a chunk from the ART.\n \tvoid Delete(IndexLock &lock, DataChunk &entries, Vector &row_ids) override;\n@@ -131,15 +126,17 @@ class ART : public BoundIndex {\n \tvoid InsertIntoEmpty(Node &node, const ARTKey &key, const idx_t depth, const ARTKey &row_id,\n \t                     const GateStatus status);\n \tARTConflictType InsertIntoInlined(Node &node, const ARTKey &key, const idx_t depth, const ARTKey &row_id,\n-\t                                  const GateStatus status, optional_ptr<ART> delete_art);\n+\t                                  const GateStatus status, optional_ptr<ART> delete_art,\n+\t                                  const IndexAppendMode append_mode);\n \tARTConflictType InsertIntoNode(Node &node, const ARTKey &key, const idx_t depth, const ARTKey &row_id,\n-\t                               const GateStatus status, optional_ptr<ART> delete_art);\n+\t                               const GateStatus status, optional_ptr<ART> delete_art,\n+\t                               const IndexAppendMode append_mode);\n \n \tstring GenerateErrorKeyName(DataChunk &input, idx_t row);\n \tstring GenerateConstraintErrorMessage(VerifyExistenceType verify_type, const string &key_name);\n \tvoid VerifyLeaf(const Node &leaf, const ARTKey &key, optional_ptr<ART> delete_art, ConflictManager &manager,\n \t                optional_idx &conflict_idx, idx_t i);\n-\tvoid VerifyConstraint(DataChunk &chunk, optional_ptr<BoundIndex> delete_index, ConflictManager &manager) override;\n+\tvoid VerifyConstraint(DataChunk &chunk, IndexAppendInfo &info, ConflictManager &manager) override;\n \tstring GetConstraintViolationMessage(VerifyExistenceType verify_type, idx_t failed_index,\n \t                                     DataChunk &input) override;\n \ndiff --git a/src/include/duckdb/execution/index/art/prefix.hpp b/src/include/duckdb/execution/index/art/prefix.hpp\nindex 5d656c742e8e..38b57514c862 100644\n--- a/src/include/duckdb/execution/index/art/prefix.hpp\n+++ b/src/include/duckdb/execution/index/art/prefix.hpp\n@@ -85,7 +85,8 @@ class Prefix {\n \n \t//! Insert a key into a prefix.\n \tstatic ARTConflictType Insert(ART &art, Node &node, const ARTKey &key, idx_t depth, const ARTKey &row_id,\n-\t                              const GateStatus status, optional_ptr<ART> delete_art);\n+\t                              const GateStatus status, optional_ptr<ART> delete_art,\n+\t                              const IndexAppendMode append_mode);\n \n \t//! Returns the string representation of the node, or only traverses and verifies the node and its subtree\n \tstatic string VerifyAndToString(ART &art, const Node &node, const bool only_verify);\ndiff --git a/src/include/duckdb/execution/index/bound_index.hpp b/src/include/duckdb/execution/index/bound_index.hpp\nindex 522c7c78e4e7..4ac5d4b25a0c 100644\n--- a/src/include/duckdb/execution/index/bound_index.hpp\n+++ b/src/include/duckdb/execution/index/bound_index.hpp\n@@ -28,6 +28,19 @@ class ConflictManager;\n struct IndexLock;\n struct IndexScanState;\n \n+enum class IndexAppendMode : uint8_t { DEFAULT = 0, IGNORE_DUPLICATES = 1, INSERT_DUPLICATES = 2 };\n+\n+class IndexAppendInfo {\n+public:\n+\tIndexAppendInfo() : append_mode(IndexAppendMode::DEFAULT), delete_index(nullptr) {};\n+\tIndexAppendInfo(const IndexAppendMode append_mode, const optional_ptr<BoundIndex> delete_index)\n+\t    : append_mode(append_mode), delete_index(delete_index) {};\n+\n+public:\n+\tIndexAppendMode append_mode;\n+\toptional_ptr<BoundIndex> delete_index;\n+};\n+\n //! The index is an abstract base class that serves as the basis for indexes\n class BoundIndex : public Index {\n public:\n@@ -71,17 +84,15 @@ class BoundIndex : public Index {\n \tvirtual ErrorData Append(IndexLock &l, DataChunk &chunk, Vector &row_ids) = 0;\n \t//! Obtains a lock and calls Append while holding that lock.\n \tErrorData Append(DataChunk &chunk, Vector &row_ids);\n-\t//! Appends data to the locked index and verifies constraint violations against a delete index.\n-\tvirtual ErrorData AppendWithDeleteIndex(IndexLock &l, DataChunk &chunk, Vector &row_ids,\n-\t                                        optional_ptr<BoundIndex> delete_index);\n-\t//! Obtains a lock and calls Append with an delete_index while holding that lock.\n-\tErrorData AppendWithDeleteIndex(DataChunk &chunk, Vector &row_ids, optional_ptr<BoundIndex> delete_index);\n+\t//! Appends data to the locked index and verifies constraint violations.\n+\tvirtual ErrorData Append(IndexLock &l, DataChunk &chunk, Vector &row_ids, IndexAppendInfo &info);\n+\t//! Obtains a lock and calls Append while holding that lock.\n+\tErrorData Append(DataChunk &chunk, Vector &row_ids, IndexAppendInfo &info);\n \n \t//! Verify that data can be appended to the index without a constraint violation.\n-\tvirtual void VerifyAppend(DataChunk &chunk, optional_ptr<BoundIndex> delete_index,\n-\t                          optional_ptr<ConflictManager> manager);\n+\tvirtual void VerifyAppend(DataChunk &chunk, IndexAppendInfo &info, optional_ptr<ConflictManager> manager);\n \t//! Verifies the constraint for a chunk of data.\n-\tvirtual void VerifyConstraint(DataChunk &chunk, optional_ptr<BoundIndex> delete_index, ConflictManager &manager);\n+\tvirtual void VerifyConstraint(DataChunk &chunk, IndexAppendInfo &info, ConflictManager &manager);\n \n \t//! Deletes all data from the index. The lock obtained from InitializeLock must be held\n \tvirtual void CommitDrop(IndexLock &index_lock) = 0;\n@@ -94,8 +105,8 @@ class BoundIndex : public Index {\n \n \t//! Insert a chunk.\n \tvirtual ErrorData Insert(IndexLock &l, DataChunk &chunk, Vector &row_ids) = 0;\n-\t//! Insert a chunk and verifies constraint violations against a delete index.\n-\tvirtual ErrorData Insert(IndexLock &l, DataChunk &chunk, Vector &row_ids, optional_ptr<BoundIndex> delete_index);\n+\t//! Insert a chunk and verifies constraint violations.\n+\tvirtual ErrorData Insert(IndexLock &l, DataChunk &chunk, Vector &row_ids, IndexAppendInfo &info);\n \n \t//! Merge another index into this index. The lock obtained from InitializeLock must be held, and the other\n \t//! index must also be locked during the merge\ndiff --git a/src/include/duckdb/execution/operator/csv_scanner/string_value_scanner.hpp b/src/include/duckdb/execution/operator/csv_scanner/string_value_scanner.hpp\nindex 7ce7ab5776b4..6bddd944f2a5 100644\n--- a/src/include/duckdb/execution/operator/csv_scanner/string_value_scanner.hpp\n+++ b/src/include/duckdb/execution/operator/csv_scanner/string_value_scanner.hpp\n@@ -217,6 +217,8 @@ class StringValueResult : public ScannerResult {\n \t//! (i.e., non-comment) line.\n \tbool first_line_is_comment = false;\n \n+\tbool ignore_empty_values = true;\n+\n \t//! Specialized code for quoted values, makes sure to remove quotes and escapes\n \tstatic inline void AddQuotedValue(StringValueResult &result, const idx_t buffer_pos);\n \t//! Specialized code for possibly escaped values, makes sure to remove escapes\ndiff --git a/src/include/duckdb/execution/operator/persistent/physical_insert.hpp b/src/include/duckdb/execution/operator/persistent/physical_insert.hpp\nindex 04d202af24d9..ccb113c4f939 100644\n--- a/src/include/duckdb/execution/operator/persistent/physical_insert.hpp\n+++ b/src/include/duckdb/execution/operator/persistent/physical_insert.hpp\n@@ -38,7 +38,7 @@ class InsertGlobalState : public GlobalSinkState {\n class InsertLocalState : public LocalSinkState {\n public:\n public:\n-\tInsertLocalState(ClientContext &context, const vector<LogicalType> &types_p,\n+\tInsertLocalState(ClientContext &context, const vector<LogicalType> &types,\n \t                 const vector<unique_ptr<Expression>> &bound_defaults,\n \t                 const vector<unique_ptr<BoundConstraint>> &bound_constraints);\n \n@@ -47,12 +47,8 @@ class InsertLocalState : public LocalSinkState {\n \tTableDeleteState &GetDeleteState(DataTable &table, TableCatalogEntry &table_ref, ClientContext &context);\n \n public:\n-\t//! The to-be-inserted chunk.\n-\t//! We initialize it lazily, as we need to know which columns will be references and which will be set to their\n-\t//! default values.\n+\t//! The chunk that ends up getting inserted\n \tDataChunk insert_chunk;\n-\tbool init_insert_chunk = true;\n-\tvector<LogicalType> types;\n \t//! The chunk containing the tuples that become an update (if DO UPDATE)\n \tDataChunk update_chunk;\n \tExpressionExecutor default_executor;\n@@ -174,7 +170,8 @@ class PhysicalInsert : public PhysicalOperator {\n \t//! Returns the amount of updated tuples\n \tvoid CreateUpdateChunk(ExecutionContext &context, DataChunk &chunk, TableCatalogEntry &table, Vector &row_ids,\n \t                       DataChunk &result) const;\n-\tidx_t OnConflictHandling(TableCatalogEntry &table, ExecutionContext &context, InsertLocalState &lstate) const;\n+\tidx_t OnConflictHandling(TableCatalogEntry &table, ExecutionContext &context, InsertGlobalState &gstate,\n+\t                         InsertLocalState &lstate) const;\n };\n \n } // namespace duckdb\ndiff --git a/src/include/duckdb/execution/reservoir_sample.hpp b/src/include/duckdb/execution/reservoir_sample.hpp\nindex b794328bb0fb..bc815b11f9de 100644\n--- a/src/include/duckdb/execution/reservoir_sample.hpp\n+++ b/src/include/duckdb/execution/reservoir_sample.hpp\n@@ -172,7 +172,13 @@ class ReservoirSample : public BlockingSample {\n \tstatic constexpr const SampleType TYPE = SampleType::RESERVOIR_SAMPLE;\n \n \tconstexpr static idx_t FIXED_SAMPLE_SIZE_MULTIPLIER = 10;\n-\tconstexpr static idx_t FAST_TO_SLOW_THRESHOLD = 60;\n+\t// size is small enough, then the threshold to switch\n+\t// MinValue between std vec size and fixed sample size.\n+\t// During 'fast' sampling, we want every new vector to have the potential\n+\t// to add to the sample. If the threshold is too far below the standard vector size, then\n+\t// samples in the sample have a higher weight than new samples coming in.\n+\t// i.e during vector_size=2, 2 new samples will not be significant compared 2048 samples from 204800 tuples.\n+\tconstexpr static idx_t FAST_TO_SLOW_THRESHOLD = MinValue<idx_t>(STANDARD_VECTOR_SIZE, 60);\n \n \t// If the table has less than 204800 rows, this is the percentage\n \t// of values we save when serializing/returning a sample.\ndiff --git a/src/include/duckdb/storage/data_table.hpp b/src/include/duckdb/storage/data_table.hpp\nindex 32418d911da0..6a0b97727384 100644\n--- a/src/include/duckdb/storage/data_table.hpp\n+++ b/src/include/duckdb/storage/data_table.hpp\n@@ -107,8 +107,8 @@ class DataTable {\n \t                 const vector<unique_ptr<BoundConstraint>> &bound_constraints, Vector &row_ids,\n \t                 DataChunk &delete_chunk);\n \t//! Append a chunk to the transaction-local storage of this table.\n-\tvoid LocalAppend(TableCatalogEntry &table, ClientContext &context, DataChunk &chunk,\n-\t                 const vector<unique_ptr<BoundConstraint>> &bound_constraints);\n+\tvoid LocalWALAppend(TableCatalogEntry &table, ClientContext &context, DataChunk &chunk,\n+\t                    const vector<unique_ptr<BoundConstraint>> &bound_constraints);\n \t//! Append a column data collection with default values to the transaction-local storage of this table.\n \tvoid LocalAppend(TableCatalogEntry &table, ClientContext &context, ColumnDataCollection &collection,\n \t                 const vector<unique_ptr<BoundConstraint>> &bound_constraints,\n@@ -167,9 +167,10 @@ class DataTable {\n \n \t//! Append a chunk with the row ids [row_start, ..., row_start + chunk.size()] to all indexes of the table.\n \t//! Returns empty ErrorData, if the append was successful.\n-\tErrorData AppendToIndexes(optional_ptr<TableIndexList> delete_indexes, DataChunk &chunk, row_t row_start);\n+\tErrorData AppendToIndexes(optional_ptr<TableIndexList> delete_indexes, DataChunk &chunk, row_t row_start,\n+\t                          const IndexAppendMode index_append_mode);\n \tstatic ErrorData AppendToIndexes(TableIndexList &indexes, optional_ptr<TableIndexList> delete_indexes,\n-\t                                 DataChunk &chunk, row_t row_start);\n+\t                                 DataChunk &chunk, row_t row_start, const IndexAppendMode index_append_mode);\n \t//! Remove a chunk with the row ids [row_start, ..., row_start + chunk.size()] from all indexes of the table\n \tvoid RemoveFromIndexes(TableAppendState &state, DataChunk &chunk, row_t row_start);\n \t//! Remove the chunk with the specified set of row identifiers from all indexes of the table\ndiff --git a/src/include/duckdb/storage/index_storage_info.hpp b/src/include/duckdb/storage/index_storage_info.hpp\nindex d5e71ae48183..27312c8244c1 100644\n--- a/src/include/duckdb/storage/index_storage_info.hpp\n+++ b/src/include/duckdb/storage/index_storage_info.hpp\n@@ -62,6 +62,10 @@ struct IndexStorageInfo {\n \tBlockPointer root_block_ptr;\n \n \t//! Returns true, if IndexStorageInfo holds information to deserialize an index.\n+\t//! Note that the name can be misleading - any index that is empty (no nodes, etc.) might\n+\t//! also have neither a root_block_ptr nor allocator_infos.\n+\t//! Ensure that your index constructor initializes an empty index correctly without the\n+\t//! need for these fields.\n \tbool IsValid() const {\n \t\treturn root_block_ptr.IsValid() || !allocator_infos.empty();\n \t}\ndiff --git a/src/include/duckdb/transaction/local_storage.hpp b/src/include/duckdb/transaction/local_storage.hpp\nindex 453a7ce440ab..4213fa0fadce 100644\n--- a/src/include/duckdb/transaction/local_storage.hpp\n+++ b/src/include/duckdb/transaction/local_storage.hpp\n@@ -48,6 +48,8 @@ class LocalTableStorage : public enable_shared_from_this<LocalTableStorage> {\n \tTableIndexList append_indexes;\n \t//! The set of delete indexes.\n \tTableIndexList delete_indexes;\n+\t//! Set to INSERT_DUPLICATES, if we are skipping constraint checking during, e.g., WAL replay.\n+\tIndexAppendMode index_append_mode = IndexAppendMode::DEFAULT;\n \t//! The number of deleted rows\n \tidx_t deleted_rows;\n \t//! The main optimistic data writer\ndiff --git a/src/main/extension/extension_helper.cpp b/src/main/extension/extension_helper.cpp\nindex c7b613226a10..f42d43aa8571 100644\n--- a/src/main/extension/extension_helper.cpp\n+++ b/src/main/extension/extension_helper.cpp\n@@ -143,9 +143,9 @@ static const char *const auto_install[] = {\"motherduck\", \"postgres_scanner\", \"my\n \n // TODO: unify with new autoload mechanism\n bool ExtensionHelper::AllowAutoInstall(const string &extension) {\n-\tauto lcase = StringUtil::Lower(extension);\n+\tauto extension_name = ApplyExtensionAlias(extension);\n \tfor (idx_t i = 0; auto_install[i]; i++) {\n-\t\tif (lcase == auto_install[i]) {\n+\t\tif (extension_name == auto_install[i]) {\n \t\t\treturn true;\n \t\t}\n \t}\ndiff --git a/src/optimizer/column_lifetime_analyzer.cpp b/src/optimizer/column_lifetime_analyzer.cpp\nindex efb3e684d473..8b6f1152bf8c 100644\n--- a/src/optimizer/column_lifetime_analyzer.cpp\n+++ b/src/optimizer/column_lifetime_analyzer.cpp\n@@ -102,6 +102,12 @@ void ColumnLifetimeAnalyzer::VisitOperator(LogicalOperator &op) {\n \t\tGenerateProjectionMap(op.children[1]->GetColumnBindings(), rhs_unused, comp_join.right_projection_map);\n \t\treturn;\n \t}\n+\tcase LogicalOperatorType::LOGICAL_INSERT:\n+\tcase LogicalOperatorType::LOGICAL_UPDATE:\n+\tcase LogicalOperatorType::LOGICAL_DELETE:\n+\t\t//! When RETURNING is used, a PROJECTION is the top level operator for INSERTS, UPDATES, and DELETES\n+\t\t//! We still need to project all values from these operators so the projection\n+\t\t//! on top of them can select from only the table values being inserted.\n \tcase LogicalOperatorType::LOGICAL_UNION:\n \tcase LogicalOperatorType::LOGICAL_EXCEPT:\n \tcase LogicalOperatorType::LOGICAL_INTERSECT:\ndiff --git a/src/optimizer/filter_combiner.cpp b/src/optimizer/filter_combiner.cpp\nindex a72354d7df91..45d7c06a06f2 100644\n--- a/src/optimizer/filter_combiner.cpp\n+++ b/src/optimizer/filter_combiner.cpp\n@@ -78,6 +78,7 @@ FilterResult FilterCombiner::AddConstantComparison(vector<ExpressionValueInforma\n \t\t\treturn FilterResult::SUCCESS;\n \t\tcase ValueComparisonResult::UNSATISFIABLE_CONDITION:\n \t\t\t// combination of filters is unsatisfiable: prune the entire branch\n+\t\t\tinfo_list.push_back(info);\n \t\t\treturn FilterResult::UNSATISFIABLE;\n \t\tdefault:\n \t\t\t// prune nothing, move to the next condition\n@@ -792,11 +793,15 @@ FilterResult FilterCombiner::AddBoundComparisonFilter(Expression &expr) {\n \t\tauto transitive_filter = FindTransitiveFilter(non_scalar);\n \t\tif (transitive_filter != nullptr) {\n \t\t\t// try to add transitive filters\n-\t\t\tif (AddTransitiveFilters(transitive_filter->Cast<BoundComparisonExpression>()) ==\n-\t\t\t    FilterResult::UNSUPPORTED) {\n+\t\t\tauto transitive_result = AddTransitiveFilters(transitive_filter->Cast<BoundComparisonExpression>());\n+\t\t\tif (transitive_result == FilterResult::UNSUPPORTED) {\n \t\t\t\t// in case of unsuccessful re-add filter into remaining ones\n \t\t\t\tremaining_filters.push_back(std::move(transitive_filter));\n \t\t\t}\n+\t\t\tif (transitive_result == FilterResult::UNSATISFIABLE) {\n+\t\t\t\t// in case transitive filter is unsatisfiable - abort filter pushdown\n+\t\t\t\treturn FilterResult::UNSATISFIABLE;\n+\t\t\t}\n \t\t}\n \t\treturn ret;\n \t} else {\n@@ -1067,10 +1072,15 @@ FilterResult FilterCombiner::AddTransitiveFilters(BoundComparisonExpression &com\n \t\t\tif (transitive_filter != nullptr) {\n \t\t\t\t// try to add transitive filters\n \t\t\t\tauto &transitive_cast = transitive_filter->Cast<BoundComparisonExpression>();\n-\t\t\t\tif (AddTransitiveFilters(transitive_cast, false) == FilterResult::UNSUPPORTED) {\n+\t\t\t\tauto transitive_result = AddTransitiveFilters(transitive_cast, false);\n+\t\t\t\tif (transitive_result == FilterResult::UNSUPPORTED) {\n \t\t\t\t\t// in case of unsuccessful re-add filter into remaining ones\n \t\t\t\t\tremaining_filters.push_back(std::move(transitive_filter));\n \t\t\t\t}\n+\t\t\t\tif (transitive_result == FilterResult::UNSATISFIABLE) {\n+\t\t\t\t\t// while adding transitive filters we discovered the filter is unsatisfisable - we can prune\n+\t\t\t\t\treturn FilterResult::UNSATISFIABLE;\n+\t\t\t\t}\n \t\t\t}\n \t\t}\n \t\treturn FilterResult::SUCCESS;\ndiff --git a/src/optimizer/late_materialization.cpp b/src/optimizer/late_materialization.cpp\nindex 81d4881cd754..aa4e5c4c1fe4 100644\n--- a/src/optimizer/late_materialization.cpp\n+++ b/src/optimizer/late_materialization.cpp\n@@ -1,5 +1,6 @@\n #include \"duckdb/optimizer/late_materialization.hpp\"\n #include \"duckdb/planner/operator/logical_comparison_join.hpp\"\n+#include \"duckdb/planner/operator/logical_filter.hpp\"\n #include \"duckdb/planner/operator/logical_get.hpp\"\n #include \"duckdb/planner/operator/logical_limit.hpp\"\n #include \"duckdb/planner/operator/logical_order.hpp\"\n@@ -61,6 +62,8 @@ ColumnBinding LateMaterialization::ConstructRHS(unique_ptr<LogicalOperator> &op)\n \t// we have reached the logical get - now we need to push the row-id column (if it is not yet projected out)\n \tauto &get = child.get().Cast<LogicalGet>();\n \tauto row_id_idx = GetOrInsertRowId(get);\n+\tidx_t column_count = get.projection_ids.empty() ? get.GetColumnIds().size() : get.projection_ids.size();\n+\tD_ASSERT(column_count == get.GetColumnBindings().size());\n \n \t// the row id has been projected - now project it up the stack\n \tColumnBinding row_id_binding(get.table_index, row_id_idx);\n@@ -74,11 +77,18 @@ ColumnBinding LateMaterialization::ConstructRHS(unique_ptr<LogicalOperator> &op)\n \t\t\t    make_uniq<BoundColumnRefExpression>(\"rowid\", get.GetRowIdType(), row_id_binding));\n \t\t\t// modify the row-id-binding to push to the new projection\n \t\t\trow_id_binding = ColumnBinding(proj.table_index, proj.expressions.size() - 1);\n+\t\t\tcolumn_count = proj.expressions.size();\n \t\t\tbreak;\n \t\t}\n-\t\tcase LogicalOperatorType::LOGICAL_FILTER:\n-\t\t\t// column bindings pass-through this operator as-is\n+\t\tcase LogicalOperatorType::LOGICAL_FILTER: {\n+\t\t\tauto &filter = op.Cast<LogicalFilter>();\n+\t\t\t// column bindings pass-through this operator as-is UNLESS the filter has a projection map\n+\t\t\tif (filter.HasProjectionMap()) {\n+\t\t\t\t// if the filter has a projection map, we need to project the new column\n+\t\t\t\tfilter.projection_map.push_back(column_count - 1);\n+\t\t\t}\n \t\t\tbreak;\n+\t\t}\n \t\tdefault:\n \t\t\tthrow InternalException(\"Unsupported logical operator in LateMaterialization::ConstructRHS\");\n \t\t}\n@@ -212,12 +222,13 @@ bool LateMaterialization::TryLateMaterialization(unique_ptr<LogicalOperator> &op\n \t\t\tchild = *child.get().children[0];\n \t\t\tbreak;\n \t\t}\n-\t\tcase LogicalOperatorType::LOGICAL_FILTER:\n+\t\tcase LogicalOperatorType::LOGICAL_FILTER: {\n \t\t\t// visit filter expressions - we need these columns\n \t\t\tVisitOperatorExpressions(child.get());\n \t\t\t// continue into child\n \t\t\tchild = *child.get().children[0];\n \t\t\tbreak;\n+\t\t}\n \t\tdefault:\n \t\t\t// unsupported operator for late materialization\n \t\t\treturn false;\ndiff --git a/src/parser/transform/expression/transform_columnref.cpp b/src/parser/transform/expression/transform_columnref.cpp\nindex a232219fa14c..dfbbc6f121fc 100644\n--- a/src/parser/transform/expression/transform_columnref.cpp\n+++ b/src/parser/transform/expression/transform_columnref.cpp\n@@ -96,6 +96,7 @@ unique_ptr<ParsedExpression> Transformer::TransformStarExpression(duckdb_libpgqu\n \t\t\tresult->relation_name = child_star.relation_name;\n \t\t\tresult->exclude_list = std::move(child_star.exclude_list);\n \t\t\tresult->replace_list = std::move(child_star.replace_list);\n+\t\t\tresult->rename_list = std::move(child_star.rename_list);\n \t\t\tresult->expr.reset();\n \t\t} else if (result->expr->GetExpressionType() == ExpressionType::LAMBDA) {\n \t\t\tvector<unique_ptr<ParsedExpression>> children;\ndiff --git a/src/planner/binder/statement/bind_copy_database.cpp b/src/planner/binder/statement/bind_copy_database.cpp\nindex f05445e906e4..d2c0a03fb8c7 100644\n--- a/src/planner/binder/statement/bind_copy_database.cpp\n+++ b/src/planner/binder/statement/bind_copy_database.cpp\n@@ -43,7 +43,6 @@ unique_ptr<LogicalOperator> Binder::BindCopyDatabaseSchema(Catalog &from_databas\n \t\tinfo->entries.push_back(std::move(create_info));\n \t}\n \n-\t// FIXME: copy indexes\n \treturn make_uniq<LogicalCopyDatabase>(std::move(info));\n }\n \ndiff --git a/src/planner/binder/statement/bind_create.cpp b/src/planner/binder/statement/bind_create.cpp\nindex 4f1a43a308ba..053ceaef4f56 100644\n--- a/src/planner/binder/statement/bind_create.cpp\n+++ b/src/planner/binder/statement/bind_create.cpp\n@@ -98,7 +98,7 @@ SchemaCatalogEntry &Binder::BindSchema(CreateInfo &info) {\n \t\tinfo.catalog = default_entry.catalog;\n \t\tinfo.schema = default_entry.schema;\n \t} else if (IsInvalidSchema(info.schema)) {\n-\t\tinfo.schema = search_path->GetDefaultSchema(info.catalog);\n+\t\tinfo.schema = search_path->GetDefaultSchema(context, info.catalog);\n \t} else if (IsInvalidCatalog(info.catalog)) {\n \t\tinfo.catalog = search_path->GetDefaultCatalog(info.schema);\n \t}\ndiff --git a/src/planner/binder/tableref/bind_table_function.cpp b/src/planner/binder/tableref/bind_table_function.cpp\nindex 26dd86c9dfd1..29d68f3fc3ab 100644\n--- a/src/planner/binder/tableref/bind_table_function.cpp\n+++ b/src/planner/binder/tableref/bind_table_function.cpp\n@@ -126,8 +126,7 @@ bool Binder::BindTableFunctionParameters(TableFunctionCatalogEntry &table_functi\n \t\t    child->GetExpressionType() == ExpressionType::SUBQUERY) {\n \t\t\tD_ASSERT(table_function.functions.Size() == 1);\n \t\t\tauto fun = table_function.functions.GetFunctionByOffset(0);\n-\t\t\tif (table_function.functions.Size() != 1 || fun.arguments.empty() ||\n-\t\t\t    fun.arguments[0].id() != LogicalTypeId::TABLE) {\n+\t\t\tif (table_function.functions.Size() != 1 || fun.arguments.empty()) {\n \t\t\t\tthrow BinderException(\n \t\t\t\t    \"Only table-in-out functions can have subquery parameters - %s only accepts constant parameters\",\n \t\t\t\t    fun.name);\ndiff --git a/src/planner/subquery/flatten_dependent_join.cpp b/src/planner/subquery/flatten_dependent_join.cpp\nindex a297a7855dae..bb5db60a98bd 100644\n--- a/src/planner/subquery/flatten_dependent_join.cpp\n+++ b/src/planner/subquery/flatten_dependent_join.cpp\n@@ -401,6 +401,7 @@ unique_ptr<LogicalOperator> FlattenDependentJoins::PushDownDependentJoinInternal\n \t\t\t\t// only right has correlation: push into right\n \t\t\t\tplan->children[1] = PushDownDependentJoinInternal(std::move(plan->children[1]),\n \t\t\t\t                                                  parent_propagate_null_values, lateral_depth);\n+\t\t\t\tdelim_offset += plan->children[0]->GetColumnBindings().size();\n \t\t\t\t// Remove the correlated columns coming from outside for current join node\n \t\t\t\treturn plan;\n \t\t\t}\n@@ -419,6 +420,7 @@ unique_ptr<LogicalOperator> FlattenDependentJoins::PushDownDependentJoinInternal\n \t\t\t\t// only right has correlation: push into right\n \t\t\t\tplan->children[1] = PushDownDependentJoinInternal(std::move(plan->children[1]),\n \t\t\t\t                                                  parent_propagate_null_values, lateral_depth);\n+\t\t\t\tdelim_offset += plan->children[0]->GetColumnBindings().size();\n \t\t\t\treturn plan;\n \t\t\t}\n \t\t} else if (join.join_type == JoinType::MARK) {\ndiff --git a/src/storage/data_table.cpp b/src/storage/data_table.cpp\nindex cf35519cca82..168ee3009b64 100644\n--- a/src/storage/data_table.cpp\n+++ b/src/storage/data_table.cpp\n@@ -679,9 +679,11 @@ void DataTable::VerifyUniqueIndexes(TableIndexList &indexes, optional_ptr<LocalT\n \n \t\t\tif (storage) {\n \t\t\t\tauto delete_index = storage->delete_indexes.Find(art.GetIndexName());\n-\t\t\t\tart.VerifyAppend(chunk, delete_index, nullptr);\n+\t\t\t\tIndexAppendInfo index_append_info(IndexAppendMode::DEFAULT, delete_index);\n+\t\t\t\tart.VerifyAppend(chunk, index_append_info, nullptr);\n \t\t\t} else {\n-\t\t\t\tart.VerifyAppend(chunk, nullptr, nullptr);\n+\t\t\t\tIndexAppendInfo index_append_info;\n+\t\t\t\tart.VerifyAppend(chunk, index_append_info, nullptr);\n \t\t\t}\n \t\t\treturn false;\n \t\t});\n@@ -712,8 +714,10 @@ void DataTable::VerifyUniqueIndexes(TableIndexList &indexes, optional_ptr<LocalT\n \tmanager->SetMode(ConflictManagerMode::SCAN);\n \tauto &matched_indexes = manager->MatchedIndexes();\n \tauto &matched_delete_indexes = manager->MatchedDeleteIndexes();\n+\tIndexAppendInfo index_append_info(IndexAppendMode::DEFAULT, nullptr);\n \tfor (idx_t i = 0; i < matched_indexes.size(); i++) {\n-\t\tmatched_indexes[i].get().VerifyAppend(chunk, matched_delete_indexes[i], *manager);\n+\t\tindex_append_info.delete_index = matched_delete_indexes[i];\n+\t\tmatched_indexes[i].get().VerifyAppend(chunk, index_append_info, *manager);\n \t}\n \n \t// Scan the other indexes and throw, if there are any conflicts.\n@@ -728,9 +732,11 @@ void DataTable::VerifyUniqueIndexes(TableIndexList &indexes, optional_ptr<LocalT\n \n \t\tif (storage) {\n \t\t\tauto delete_index = storage->delete_indexes.Find(art.GetIndexName());\n-\t\t\tart.VerifyAppend(chunk, delete_index, *manager);\n+\t\t\tIndexAppendInfo index_append_info(IndexAppendMode::DEFAULT, delete_index);\n+\t\t\tart.VerifyAppend(chunk, index_append_info, *manager);\n \t\t} else {\n-\t\t\tart.VerifyAppend(chunk, nullptr, *manager);\n+\t\t\tIndexAppendInfo index_append_info;\n+\t\t\tart.VerifyAppend(chunk, index_append_info, *manager);\n \t\t}\n \t\treturn false;\n \t});\n@@ -863,13 +869,14 @@ void DataTable::LocalMerge(ClientContext &context, RowGroupCollection &collectio\n \tlocal_storage.LocalMerge(*this, collection);\n }\n \n-void DataTable::LocalAppend(TableCatalogEntry &table, ClientContext &context, DataChunk &chunk,\n-                            const vector<unique_ptr<BoundConstraint>> &bound_constraints) {\n+void DataTable::LocalWALAppend(TableCatalogEntry &table, ClientContext &context, DataChunk &chunk,\n+                               const vector<unique_ptr<BoundConstraint>> &bound_constraints) {\n \tLocalAppendState append_state;\n \tauto &storage = table.GetStorage();\n \tstorage.InitializeLocalAppend(append_state, table, context, bound_constraints);\n \n-\tstorage.LocalAppend(append_state, context, chunk, false);\n+\tstorage.LocalAppend(append_state, context, chunk, true);\n+\tappend_state.storage->index_append_mode = IndexAppendMode::INSERT_DUPLICATES;\n \tstorage.FinalizeLocalAppend(append_state);\n }\n \n@@ -1109,7 +1116,7 @@ void DataTable::RevertAppend(DuckTransaction &transaction, idx_t start_row, idx_\n // Indexes\n //===--------------------------------------------------------------------===//\n ErrorData DataTable::AppendToIndexes(TableIndexList &indexes, optional_ptr<TableIndexList> delete_indexes,\n-                                     DataChunk &chunk, row_t row_start) {\n+                                     DataChunk &chunk, row_t row_start, const IndexAppendMode index_append_mode) {\n \tErrorData error;\n \tif (indexes.Empty()) {\n \t\treturn error;\n@@ -1137,7 +1144,8 @@ ErrorData DataTable::AppendToIndexes(TableIndexList &indexes, optional_ptr<Table\n \t\t}\n \n \t\ttry {\n-\t\t\terror = index.AppendWithDeleteIndex(chunk, row_ids, delete_index);\n+\t\t\tIndexAppendInfo index_append_info(index_append_mode, delete_index);\n+\t\t\terror = index.Append(chunk, row_ids, index_append_info);\n \t\t} catch (std::exception &ex) {\n \t\t\terror = ErrorData(ex);\n \t\t}\n@@ -1160,9 +1168,10 @@ ErrorData DataTable::AppendToIndexes(TableIndexList &indexes, optional_ptr<Table\n \treturn error;\n }\n \n-ErrorData DataTable::AppendToIndexes(optional_ptr<TableIndexList> delete_indexes, DataChunk &chunk, row_t row_start) {\n+ErrorData DataTable::AppendToIndexes(optional_ptr<TableIndexList> delete_indexes, DataChunk &chunk, row_t row_start,\n+                                     const IndexAppendMode index_append_mode) {\n \tD_ASSERT(is_root);\n-\treturn AppendToIndexes(info->indexes, delete_indexes, chunk, row_start);\n+\treturn AppendToIndexes(info->indexes, delete_indexes, chunk, row_start, index_append_mode);\n }\n \n void DataTable::RemoveFromIndexes(TableAppendState &state, DataChunk &chunk, row_t row_start) {\ndiff --git a/src/storage/local_storage.cpp b/src/storage/local_storage.cpp\nindex 71b20bd10059..93326ed6726f 100644\n--- a/src/storage/local_storage.cpp\n+++ b/src/storage/local_storage.cpp\n@@ -41,7 +41,6 @@ LocalTableStorage::LocalTableStorage(ClientContext &context, DataTable &table)\n \t\t// Create a delete index and a local index.\n \t\tauto delete_index = make_uniq<ART>(art.GetIndexName(), constraint_type, art.GetColumnIds(),\n \t\t                                   art.table_io_manager, std::move(delete_expressions), art.db);\n-\t\tdelete_index->append_mode = ARTAppendMode::IGNORE_DUPLICATES;\n \t\tdelete_indexes.AddIndex(std::move(delete_index));\n \n \t\tauto index = make_uniq<ART>(art.GetIndexName(), constraint_type, art.GetColumnIds(), art.table_io_manager,\n@@ -152,7 +151,7 @@ ErrorData LocalTableStorage::AppendToIndexes(DuckTransaction &transaction, RowGr\n \t\t}\n \t\tmock_chunk.SetCardinality(chunk);\n \t\t// append this chunk to the indexes of the table\n-\t\terror = DataTable::AppendToIndexes(index_list, nullptr, mock_chunk, start_row);\n+\t\terror = DataTable::AppendToIndexes(index_list, nullptr, mock_chunk, start_row, index_append_mode);\n \t\tif (error.HasError()) {\n \t\t\treturn false;\n \t\t}\n@@ -173,7 +172,7 @@ void LocalTableStorage::AppendToIndexes(DuckTransaction &transaction, TableAppen\n \t\t// appending: need to scan entire\n \t\trow_groups->Scan(transaction, [&](DataChunk &chunk) -> bool {\n \t\t\t// append this chunk to the indexes of the table\n-\t\t\terror = table.AppendToIndexes(delete_indexes, chunk, append_state.current_row);\n+\t\t\terror = table.AppendToIndexes(delete_indexes, chunk, append_state.current_row, index_append_mode);\n \t\t\tif (error.HasError()) {\n \t\t\t\treturn false;\n \t\t\t}\n@@ -186,6 +185,7 @@ void LocalTableStorage::AppendToIndexes(DuckTransaction &transaction, TableAppen\n \t\tauto &index_list = data_table_info->GetIndexes();\n \t\terror = AppendToIndexes(transaction, *row_groups, index_list, table.GetTypes(), append_state.current_row);\n \t}\n+\n \tif (error.HasError()) {\n \t\t// need to revert all appended row ids\n \t\trow_t current_row = append_state.row_start;\n@@ -386,7 +386,8 @@ void LocalTableStorage::AppendToDeleteIndexes(Vector &row_ids, DataChunk &delete\n \t\tif (!art.IsUnique()) {\n \t\t\treturn false;\n \t\t}\n-\t\tauto result = art.Cast<BoundIndex>().Append(delete_chunk, row_ids);\n+\t\tIndexAppendInfo index_append_info(IndexAppendMode::IGNORE_DUPLICATES, nullptr);\n+\t\tauto result = art.Cast<BoundIndex>().Append(delete_chunk, row_ids, index_append_info);\n \t\tif (result.HasError()) {\n \t\t\tthrow InternalException(\"unexpected constraint violation on delete ART: \", result.Message());\n \t\t}\n@@ -401,7 +402,7 @@ void LocalStorage::Append(LocalAppendState &state, DataChunk &chunk) {\n \tidx_t base_id = offset + state.append_state.total_append_count;\n \n \tauto error = DataTable::AppendToIndexes(storage->append_indexes, storage->delete_indexes, chunk,\n-\t                                        NumericCast<row_t>(base_id));\n+\t                                        NumericCast<row_t>(base_id), storage->index_append_mode);\n \tif (error.HasError()) {\n \t\terror.Throw();\n \t}\ndiff --git a/src/storage/table_index_list.cpp b/src/storage/table_index_list.cpp\nindex b46ddaf1989e..abcb9a7d144a 100644\n--- a/src/storage/table_index_list.cpp\n+++ b/src/storage/table_index_list.cpp\n@@ -173,9 +173,11 @@ void TableIndexList::VerifyForeignKey(optional_ptr<LocalTableStorage> storage, c\n \tD_ASSERT(index && index->IsBound());\n \tif (storage) {\n \t\tauto delete_index = storage->delete_indexes.Find(index->GetIndexName());\n-\t\tindex->Cast<BoundIndex>().VerifyConstraint(chunk, delete_index, conflict_manager);\n+\t\tIndexAppendInfo index_append_info(IndexAppendMode::DEFAULT, delete_index);\n+\t\tindex->Cast<BoundIndex>().VerifyConstraint(chunk, index_append_info, conflict_manager);\n \t} else {\n-\t\tindex->Cast<BoundIndex>().VerifyConstraint(chunk, nullptr, conflict_manager);\n+\t\tIndexAppendInfo index_append_info;\n+\t\tindex->Cast<BoundIndex>().VerifyConstraint(chunk, index_append_info, conflict_manager);\n \t}\n }\n \n@@ -201,10 +203,9 @@ vector<IndexStorageInfo> TableIndexList::GetStorageInfos(const case_insensitive_\n \t\t}\n \n \t\tauto info = index->Cast<UnboundIndex>().GetStorageInfo();\n-\t\tD_ASSERT(info.IsValid() && !info.name.empty());\n+\t\tD_ASSERT(!info.name.empty());\n \t\tinfos.push_back(info);\n \t}\n-\n \treturn infos;\n }\n \ndiff --git a/src/storage/wal_replay.cpp b/src/storage/wal_replay.cpp\nindex 0b6894854ea2..ac2a1bb57fed 100644\n--- a/src/storage/wal_replay.cpp\n+++ b/src/storage/wal_replay.cpp\n@@ -740,7 +740,7 @@ void WriteAheadLogDeserializer::ReplayInsert() {\n \t// Append to the current table without constraint verification.\n \tvector<unique_ptr<BoundConstraint>> bound_constraints;\n \tauto &storage = state.current_table->GetStorage();\n-\tstorage.LocalAppend(*state.current_table, context, chunk, bound_constraints);\n+\tstorage.LocalWALAppend(*state.current_table, context, chunk, bound_constraints);\n }\n \n static void MarkBlocksAsUsed(BlockManager &manager, const PersistentColumnData &col_data) {\ndiff --git a/tools/pythonpkg/duckdb/experimental/spark/sql/functions.py b/tools/pythonpkg/duckdb/experimental/spark/sql/functions.py\nindex 4d01c69e5993..f0cbf1dbfc12 100644\n--- a/tools/pythonpkg/duckdb/experimental/spark/sql/functions.py\n+++ b/tools/pythonpkg/duckdb/experimental/spark/sql/functions.py\n@@ -5617,7 +5617,7 @@ def to_timestamp(col: \"ColumnOrName\", format: Optional[str] = None) -> Column:\n     >>> df.select(to_timestamp(df.t, 'yyyy-MM-dd HH:mm:ss').alias('dt')).collect()\n     [Row(dt=datetime.datetime(1997, 2, 28, 10, 30))]\n     \"\"\"\n-    return _to_date_or_timestamp(col, _types.TimestampType(), format)\n+    return _to_date_or_timestamp(col, _types.TimestampNTZType(), format)\n \n \n def to_timestamp_ltz(\n@@ -5649,7 +5649,7 @@ def to_timestamp_ltz(\n     ... # doctest: +SKIP\n     [Row(r=datetime.datetime(2016, 12, 31, 0, 0))]\n     \"\"\"\n-    return _to_date_or_timestamp(timestamp, _types.TimestampType(), format)\n+    return _to_date_or_timestamp(timestamp, _types.TimestampNTZType(), format)\n \n \n def to_timestamp_ntz(\n@@ -5731,7 +5731,7 @@ def substr(\n \n \n def _unix_diff(col: \"ColumnOrName\", part: str) -> Column:\n-    return _invoke_function_over_columns(\"date_diff\", lit(part), lit(\"1970-01-01 00:00:00+00:00\").cast(\"timestamptz\"), col)\n+    return _invoke_function_over_columns(\"date_diff\", lit(part), lit(\"1970-01-01 00:00:00+00:00\").cast(\"timestamp\"), col)\n \n def unix_date(col: \"ColumnOrName\") -> Column:\n     \"\"\"Returns the number of days since 1970-01-01.\ndiff --git a/tools/shell/shell.cpp b/tools/shell/shell.cpp\nindex 53880de8a55d..45252c86e95b 100644\n--- a/tools/shell/shell.cpp\n+++ b/tools/shell/shell.cpp\n@@ -4004,7 +4004,7 @@ MetadataResult ToggleTimer(ShellState &state, const char **azArg, idx_t nArg) {\n }\n \n MetadataResult ShowVersion(ShellState &state, const char **azArg, idx_t nArg) {\n-\tutf8_printf(state.out, \"SQLite %s %s\\n\" /*extra-version-info*/, sqlite3_libversion(), sqlite3_sourceid());\n+\tutf8_printf(state.out, \"DuckDB %s %s\\n\" /*extra-version-info*/, sqlite3_libversion(), sqlite3_sourceid());\n #define CTIMEOPT_VAL_(opt) #opt\n #define CTIMEOPT_VAL(opt)  CTIMEOPT_VAL_(opt)\n #if defined(__clang__) && defined(__clang_major__)\n", "test_patch": "diff --git a/scripts/sqllogictest/__init__.py b/scripts/sqllogictest/__init__.py\nindex 02ae67a6f99c..6053ce836ec1 100644\n--- a/scripts/sqllogictest/__init__.py\n+++ b/scripts/sqllogictest/__init__.py\n@@ -20,6 +20,7 @@\n     Sleep,\n     SleepUnit,\n     Skip,\n+    Unzip,\n     Unskip,\n )\n from .decorator import SkipIf, OnlyIf\n@@ -50,6 +51,7 @@\n     Sleep,\n     SleepUnit,\n     Skip,\n+    Unzip,\n     Unskip,\n     SkipIf,\n     OnlyIf,\ndiff --git a/scripts/sqllogictest/parser/parser.py b/scripts/sqllogictest/parser/parser.py\nindex 349d63cb1e34..37049dc6a1fe 100644\n--- a/scripts/sqllogictest/parser/parser.py\n+++ b/scripts/sqllogictest/parser/parser.py\n@@ -23,6 +23,7 @@\n     Reconnect,\n     Sleep,\n     Skip,\n+    Unzip,\n     Unskip,\n     SortStyle,\n )\n@@ -86,6 +87,7 @@ def __init__(self):\n             TokenType.SQLLOGIC_RESTART: self.statement_restart,\n             TokenType.SQLLOGIC_RECONNECT: self.statement_reconnect,\n             TokenType.SQLLOGIC_SLEEP: self.statement_sleep,\n+            TokenType.SQLLOGIC_UNZIP: self.statement_unzip,\n             TokenType.SQLLOGIC_INVALID: None,\n         }\n         self.DECORATORS = {\n@@ -405,6 +407,29 @@ def statement_sleep(self, header: Token) -> Optional[BaseStatement]:\n             raise self.fail(f\"Unrecognized sleep mode - expected {create_formatted_list(options)}\")\n         return Sleep(header, self.current_line + 1, sleep_duration, sleep_unit)\n \n+    def statement_unzip(self, header: Token) -> Optional[BaseStatement]:\n+        params = header.parameters\n+        if len(params) != 1 and len(params) != 2:\n+            docs = \"\"\"\n+                unzip requires 1 parameter, the path to a (g)zipped file.\n+                Optionally a destination location can be provided, defaulting to '__TEST_DIR__/<base_name>'\n+            \"\"\"\n+            self.fail(docs)\n+\n+        source = params[0]\n+\n+        accepted_filetypes = {'.gz'}\n+\n+        basename = os.path.basename(source)\n+        stem, extension = os.path.splitext(basename)\n+        if extension not in accepted_filetypes:\n+            accepted_options = \", \".join(list(accepted_filetypes))\n+            self.fail(\n+                f\"unzip: input does not end in a valid file extension ({extension}), accepted options are: {accepted_options}\"\n+            )\n+        destination = params[1] if len(params) == 2 else f'__TEST_DIR__/{stem}'\n+        return Unzip(header, self.current_line + 1, source, destination)\n+\n     # Decorators\n \n     def decorator_skipif(self, token: Token) -> Optional[BaseDecorator]:\n@@ -531,6 +556,7 @@ def is_single_line_statement(self, token):\n             TokenType.SQLLOGIC_RESTART,\n             TokenType.SQLLOGIC_RECONNECT,\n             TokenType.SQLLOGIC_SLEEP,\n+            TokenType.SQLLOGIC_UNZIP,\n         ]\n \n         if token.type in single_line_statements:\n@@ -566,6 +592,7 @@ def command_to_token(self, token):\n             \"load\": TokenType.SQLLOGIC_LOAD,\n             \"restart\": TokenType.SQLLOGIC_RESTART,\n             \"reconnect\": TokenType.SQLLOGIC_RECONNECT,\n+            \"unzip\": TokenType.SQLLOGIC_UNZIP,\n             \"sleep\": TokenType.SQLLOGIC_SLEEP,\n         }\n \ndiff --git a/scripts/sqllogictest/result.py b/scripts/sqllogictest/result.py\nindex aa4e8158bd47..1893389b1d1a 100644\n--- a/scripts/sqllogictest/result.py\n+++ b/scripts/sqllogictest/result.py\n@@ -21,6 +21,7 @@\n     Sleep,\n     SleepUnit,\n     Skip,\n+    Unzip,\n     SortStyle,\n     Unskip,\n )\n@@ -764,6 +765,7 @@ def __init__(\n             Restart: self.execute_restart,\n             HashThreshold: self.execute_hash_threshold,\n             Set: self.execute_set,\n+            Unzip: self.execute_unzip,\n             Loop: self.execute_loop,\n             Foreach: self.execute_foreach,\n             Endloop: None,  # <-- should never be encountered outside of Loop/Foreach\n@@ -900,6 +902,18 @@ def is_query_result(sql_query, statement) -> bool:\n     def execute_skip(self, statement: Skip):\n         self.runner.skip()\n \n+    def execute_unzip(self, statement: Unzip):\n+        import gzip\n+        import shutil\n+\n+        source = self.replace_keywords(statement.source)\n+        destination = self.replace_keywords(statement.destination)\n+\n+        with gzip.open(source, 'rb') as f_in:\n+            with open(destination, 'wb') as f_out:\n+                shutil.copyfileobj(f_in, f_out)\n+        print(f\"Extracted to '{destination}'\")\n+\n     def execute_unskip(self, statement: Unskip):\n         self.runner.unskip()\n \ndiff --git a/scripts/sqllogictest/statement/__init__.py b/scripts/sqllogictest/statement/__init__.py\nindex daeeee0a1d52..2600fe110963 100644\n--- a/scripts/sqllogictest/statement/__init__.py\n+++ b/scripts/sqllogictest/statement/__init__.py\n@@ -14,6 +14,7 @@\n from .restart import Restart\n from .reconnect import Reconnect\n from .sleep import Sleep, SleepUnit\n+from .unzip import Unzip\n \n from .skip import Skip, Unskip\n \n@@ -35,6 +36,7 @@\n     Sleep,\n     SleepUnit,\n     Skip,\n+    Unzip,\n     Unskip,\n     SortStyle,\n ]\ndiff --git a/scripts/sqllogictest/statement/unzip.py b/scripts/sqllogictest/statement/unzip.py\nnew file mode 100644\nindex 000000000000..030e1b7b4e70\n--- /dev/null\n+++ b/scripts/sqllogictest/statement/unzip.py\n@@ -0,0 +1,9 @@\n+from sqllogictest.base_statement import BaseStatement\n+from sqllogictest.token import Token\n+\n+\n+class Unzip(BaseStatement):\n+    def __init__(self, header: Token, line: int, source: str, destination: str):\n+        super().__init__(header, line)\n+        self.source = source\n+        self.destination = destination\ndiff --git a/scripts/sqllogictest/token.py b/scripts/sqllogictest/token.py\nindex 20928735d950..88d42d156d38 100644\n--- a/scripts/sqllogictest/token.py\n+++ b/scripts/sqllogictest/token.py\n@@ -22,6 +22,7 @@ class TokenType(Enum):\n     SQLLOGIC_RESTART = auto()\n     SQLLOGIC_RECONNECT = auto()\n     SQLLOGIC_SLEEP = auto()\n+    SQLLOGIC_UNZIP = auto()\n \n \n class Token:\ndiff --git a/test/fuzzer/duckfuzz/late_materialization_filter.test b/test/fuzzer/duckfuzz/late_materialization_filter.test\nnew file mode 100644\nindex 000000000000..30bdea187cca\n--- /dev/null\n+++ b/test/fuzzer/duckfuzz/late_materialization_filter.test\n@@ -0,0 +1,17 @@\n+# name: test/fuzzer/duckfuzz/late_materialization_filter.test\n+# description: NULL input to json_extract_string - found by fuzzer\n+# group: [duckfuzz]\n+\n+statement ok\n+create table tbl(z int, i bool, j bool, k uhugeint);\n+\n+statement ok\n+insert into tbl (i, j, k) values (true, 'true', 3), (NULL, NULL, NULL), (false, 'false', 1);\n+\n+query I\n+select k\n+from tbl\n+where i and j\n+limit 30;\n+----\n+3\ndiff --git a/test/fuzzer/public/insert_returning.test b/test/fuzzer/public/insert_returning.test\nnew file mode 100644\nindex 000000000000..4f4cfb9acea5\n--- /dev/null\n+++ b/test/fuzzer/public/insert_returning.test\n@@ -0,0 +1,17 @@\n+# name: test/fuzzer/public/insert_returning.test\n+# description: Test INSERT OR REPLACE with DEFAULT VALUES\n+# group: [public]\n+\n+statement ok\n+pragma enable_verification\n+\n+statement ok\n+CREATE TABLE v00 (c01 INT, c02 STRING);\n+\n+statement ok\n+INSERT INTO v00 (c01, c02) VALUES (0, 'abc');\n+\n+query I\n+INSERT INTO v00 FROM v00 ORDER BY ALL DESC RETURNING 'abc';\n+----\n+abc\ndiff --git a/test/fuzzer/public/lateral_in_right_side_of_join.test b/test/fuzzer/public/lateral_in_right_side_of_join.test\nnew file mode 100644\nindex 000000000000..aab7706bef98\n--- /dev/null\n+++ b/test/fuzzer/public/lateral_in_right_side_of_join.test\n@@ -0,0 +1,28 @@\n+# name: test/fuzzer/public/lateral_in_right_side_of_join.test\n+# description: Lateral correlation in right side of join\n+# group: [public]\n+\n+statement ok\n+pragma enable_verification\n+\n+statement ok\n+CREATE TABLE t0(c0 INT , c1 VARCHAR);\n+\n+statement ok\n+CREATE TABLE t1( c1 INT);\n+\n+statement ok\n+INSERT INTO t0 VALUES(4, 3);\n+\n+statement ok\n+INSERT INTO t1 VALUES(2);\n+\n+query IIII\n+SELECT * FROM t1, t0 JOIN LATERAL (SELECT t1.c1 AS col0) _subq ON true;\n+----\n+2\t4\t3\t2\n+\n+query IIII\n+SELECT * FROM t1, t0 INNER JOIN (SELECT t1.c1 AS col0) ON true;\n+----\n+2\t4\t3\t2\ndiff --git a/test/fuzzer/public/unsatisfiable_filter_prune.test b/test/fuzzer/public/unsatisfiable_filter_prune.test\nnew file mode 100644\nindex 000000000000..b1f3e1a67f3e\n--- /dev/null\n+++ b/test/fuzzer/public/unsatisfiable_filter_prune.test\n@@ -0,0 +1,20 @@\n+# name: test/fuzzer/public/unsatisfiable_filter_prune.test\n+# description: Test SEMI JOIN with USING clause\n+# group: [public]\n+\n+statement ok\n+pragma enable_verification\n+\n+statement ok\n+CREATE TABLE  t0(c0 INT, c1 INT);\n+\n+statement ok\n+INSERT INTO t0( c0, c1) VALUES ( -1, -1);\n+\n+query I\n+SELECT c0 FROM t0 WHERE (((CASE t0.c0 WHEN t0.c0 THEN t0.c0 END ) BETWEEN 1 AND t0.c0)AND(t0.c0 <= 0)) ;\n+----\n+\n+query II\n+SELECT * FROM t0 WHERE c0 >= 1 AND c0 <= t0.c1 AND t0.c1 <= 0;\n+----\ndiff --git a/test/sql/catalog/sequence/test_sequence_google_fuzz.test b/test/sql/catalog/sequence/test_sequence_google_fuzz.test\nnew file mode 100644\nindex 000000000000..a439abbf30e3\n--- /dev/null\n+++ b/test/sql/catalog/sequence/test_sequence_google_fuzz.test\n@@ -0,0 +1,16 @@\n+# name: test/sql/catalog/sequence/test_sequence_google_fuzz.test\n+# description: Test Sequence on results produce by the google fuzzer\n+# group: [sequence]\n+\n+statement error\n+;creAte\n+sequence\n+uGe\u00f5\u00f3\u00b1\u00f5\u00f5\u00f5\u00f5.\u00f5\u00f5\u00f5.\u00f5;creAte\n+sequence\n+uGe\u00f5\u00f5\u00f5\u00f5\u00f5.\u0081.\u00f5;creAte\n+sequence\n+uGe\u00f5\u00f5\u00f5\u00f5\u00f5.\u0081.\u00f5;creAte\n+sequence\n+uGe\u00f5\u00f5\u00f5\u00f5\n+----\n+Catalog with name uGe\u00f5\u00f3\u00b1\u00f5\u00f5\u00f5\u00f5 does not exist!\n\\ No newline at end of file\ndiff --git a/test/sql/constraints/primarykey/test_pk_updel_multi_column.test b/test/sql/constraints/primarykey/test_pk_updel_multi_column.test\nindex 5357eaa69d46..077fa824f38c 100644\n--- a/test/sql/constraints/primarykey/test_pk_updel_multi_column.test\n+++ b/test/sql/constraints/primarykey/test_pk_updel_multi_column.test\n@@ -2,6 +2,9 @@\n # description: PRIMARY KEY and update/delete on multiple columns\n # group: [primarykey]\n \n+# See test/sql/index/art/constraints/test_art_tx_returning.test.\n+require vector_size 2048\n+\n statement ok\n PRAGMA enable_verification;\n \ndiff --git a/test/sql/copy/csv/14512.test b/test/sql/copy/csv/14512.test\nindex 97df786ccb28..79af7b8399c0 100644\n--- a/test/sql/copy/csv/14512.test\n+++ b/test/sql/copy/csv/14512.test\n@@ -8,7 +8,7 @@ PRAGMA enable_verification\n query II\n FROM read_csv('data/csv/14512.csv', strict_mode=TRUE);\n ----\n-onions \t,\n+onions\t,\n \n query I\n select columns FROM sniff_csv('data/csv/14512.csv')\n@@ -20,7 +20,7 @@ FROM 'data/csv/14512_og.csv';\n ----\n 00000579000098\t13.99\tEA\tPINE RIDGE CHENIN VOIGNIER\t750.0\tML\t1\t13\tNULL\t1\tNULL\tNULL\tNULL\tNULL\tNULL\tNULL\tDEFAULT BRAND\tNULL\tNULL\tNULL\tNULL\tBEER & WINE\tNULL\tNULL\t7.25\t{\"sales_tax\":{ \"tax_type\": \"rate_percent\", \"value\" :0.0725}}\n 00000609082001\t3.99\tEA\tMADELAINE MINI MILK CHOCOLATE TURKEY\t1.0\tOZ\t1\t13\tNULL\tNULL\tNULL\tNULL\tNULL\tNULL\tNULL\tNULL\tMADELEINE\tNULL\tNULL\tNULL\tNULL\tCANDY\tNULL\tNULL\t7.25\t{\"sales_tax\":{ \"tax_type\": \"rate_percent\", \"value\" :0.0725}}\n-00817566020096\t9.99\tEA\tCOTSWOLD EW\t5.3\tOZ\t1\t13\tNULL\tNULL\tNULL\tNULL\tNULL\tNULL\tNULL\tNULL\tLONG CLAWSON\tNULL\tNULL\tNULL\tNULL\tDELI\tINGREDIENTS: DOUBLE GLOUCESTER CHEESE (PASTEURIZED MILK  SALT  ENZYMES  DAIRY CULTURES  ANNATTO  EXTRACT AS A COLOR)  RECONSTITUTED MINCED ONIONS (2%)  DRIED CHIVES. CONTAINS: MILK     THIS PRODUCT WAS PRODUCED IN AN ENVIRONMENT THAT ALSO USES PEANUTS  TREE NUTS  EGGS  MILK  WHEAT  SOY  FISH  SHELLFISH  AND SESAME. \tNULL\t2.0\t{\"sales_tax\":{ \"tax_type\": \"rate_percent\", \"value\" :0.02}}\n+00817566020096\t9.99\tEA\tCOTSWOLD EW\t5.3\tOZ\t1\t13\tNULL\tNULL\tNULL\tNULL\tNULL\tNULL\tNULL\tNULL\tLONG CLAWSON\tNULL\tNULL\tNULL\tNULL\tDELI\tINGREDIENTS: DOUBLE GLOUCESTER CHEESE (PASTEURIZED MILK  SALT  ENZYMES  DAIRY CULTURES  ANNATTO  EXTRACT AS A COLOR)  RECONSTITUTED MINCED ONIONS (2%)  DRIED CHIVES. CONTAINS: MILK     THIS PRODUCT WAS PRODUCED IN AN ENVIRONMENT THAT ALSO USES PEANUTS  TREE NUTS  EGGS  MILK  WHEAT  SOY  FISH  SHELLFISH  AND SESAME.\tNULL\t2.0\t{\"sales_tax\":{ \"tax_type\": \"rate_percent\", \"value\" :0.02}}\n \n query I\n select columns FROM sniff_csv('data/csv/14512_og.csv')\ndiff --git a/test/sql/copy/csv/parallel/test_parallel_csv.test b/test/sql/copy/csv/parallel/test_parallel_csv.test\nindex b903844ccf41..ce3cfefede61 100644\n--- a/test/sql/copy/csv/parallel/test_parallel_csv.test\n+++ b/test/sql/copy/csv/parallel/test_parallel_csv.test\n@@ -5,6 +5,13 @@\n statement ok\n PRAGMA enable_verification\n \n+query IIIIIIIIIIIIIIIIIIIIIIIIII\n+FROM read_csv('data/csv/14512_og.csv', buffer_size = 473)\n+----\n+00000579000098\t13.99\tEA\tPINE RIDGE CHENIN VOIGNIER\t750.0\tML\t1\t13\tNULL\t1\tNULL\tNULL\tNULL\tNULL\tNULL\tNULL\tDEFAULT BRAND\tNULL\tNULL\tNULL\tNULL\tBEER & WINE\tNULL\tNULL\t7.25\t{\"sales_tax\":{ \"tax_type\": \"rate_percent\", \"value\" :0.0725}}\n+00000609082001\t3.99\tEA\tMADELAINE MINI MILK CHOCOLATE TURKEY\t1.0\tOZ\t1\t13\tNULL\tNULL\tNULL\tNULL\tNULL\tNULL\tNULL\tNULL\tMADELEINE\tNULL\tNULL\tNULL\tNULL\tCANDY\tNULL\tNULL\t7.25\t{\"sales_tax\":{ \"tax_type\": \"rate_percent\", \"value\" :0.0725}}\n+00817566020096\t9.99\tEA\tCOTSWOLD EW\t5.3\tOZ\t1\t13\tNULL\tNULL\tNULL\tNULL\tNULL\tNULL\tNULL\tNULL\tLONG CLAWSON\tNULL\tNULL\tNULL\tNULL\tDELI\tINGREDIENTS: DOUBLE GLOUCESTER CHEESE (PASTEURIZED MILK  SALT  ENZYMES  DAIRY CULTURES  ANNATTO  EXTRACT AS A COLOR)  RECONSTITUTED MINCED ONIONS (2%)  DRIED CHIVES. CONTAINS: MILK     THIS PRODUCT WAS PRODUCED IN AN ENVIRONMENT THAT ALSO USES PEANUTS  TREE NUTS  EGGS  MILK  WHEAT  SOY  FISH  SHELLFISH  AND SESAME.\tNULL\t2.0\t{\"sales_tax\":{ \"tax_type\": \"rate_percent\", \"value\" :0.02}}\n+\n \n query III\n select * from read_csv_auto('data/csv/dirty_line.csv',  skip = 1)\ndiff --git a/test/sql/copy/csv/test_thijs_unquoted_file.test b/test/sql/copy/csv/test_thijs_unquoted_file.test\nindex b40e9af98897..64a2fc222192 100644\n--- a/test/sql/copy/csv/test_thijs_unquoted_file.test\n+++ b/test/sql/copy/csv/test_thijs_unquoted_file.test\n@@ -14,7 +14,7 @@ from read_csv('data/csv/thijs_unquoted.csv', quote='\"', sep='|', escape='\"', col\n query III\n from read_csv('data/csv/thijs_unquoted.csv', quote='\"', sep='|', escape='\"', columns={'a':'varchar', 'b': 'varchar', 'c': 'integer'}, auto_detect=false, strict_mode = False);\n ----\n-HYDRONIC GESELLSCHAFT F\u00dcR WASSERTECHNIK MBH                                                     \t \t2011\n+HYDRONIC GESELLSCHAFT F\u00dcR WASSERTECHNIK MBH\t \t2011\n ANTON SONNENSCHUTZSYSTEME GESELLSCHAFT MIT BESCHR\u00c4NKTER HAFTUN\t \t2012\n ENERGYS MAINTENANCE S\t \t2015\n SYSTEMAT BELGIUM  S\t \t2013\ndiff --git a/test/sql/copy_database/copy_database_index.test b/test/sql/copy_database/copy_database_index.test\nindex 0c7db26eafe9..e8f7351b7d60 100644\n--- a/test/sql/copy_database/copy_database_index.test\n+++ b/test/sql/copy_database/copy_database_index.test\n@@ -43,13 +43,10 @@ SELECT * FROM test WHERE a = 42;\n ----\n 42\t88\thello\n \n-# FIXME: We do not yet copy indexes.\n-# See issue 14909.\n-\n query II\n EXPLAIN ANALYZE SELECT * FROM test WHERE a = 42;\n ----\n-analyzed_plan\t<REGEX>:.*Type: Sequential Scan.*\n+analyzed_plan\t<REGEX>:.*Type: Index Scan.*\n \n statement ok\n DROP INDEX i_index;\ndiff --git a/test/sql/copy_database/copy_database_with_index.test b/test/sql/copy_database/copy_database_with_index.test\nnew file mode 100644\nindex 000000000000..b4daa7003bc3\n--- /dev/null\n+++ b/test/sql/copy_database/copy_database_with_index.test\n@@ -0,0 +1,42 @@\n+# name: test/sql/copy_database/copy_database_with_index.test\n+# description: Test the COPY DATABASE statement with an index.\n+# group: [copy_database]\n+\n+require noforcestorage\n+\n+statement ok\n+PRAGMA enable_verification;\n+\n+statement ok\n+ATTACH ':memory:' AS db1;\n+\n+statement ok\n+USE db1;\n+\n+statement ok\n+CREATE TABLE data AS\n+SELECT i, hash(i)::VARCHAR AS value FROM generate_series(1, 10000) s(i);\n+\n+statement ok\n+ALTER TABLE data ALTER COLUMN value SET NOT NULL;\n+\n+statement ok\n+CREATE INDEX data_value ON data(value);\n+\n+statement ok\n+ATTACH ':memory:' AS db2;\n+\n+statement ok\n+COPY FROM DATABASE db1 TO db2;\n+\n+query III\n+SELECT database_name, table_name, index_name FROM duckdb_indexes ORDER BY ALL;\n+----\n+db1\tdata\tdata_value\n+db2\tdata\tdata_value\n+\n+query III\n+SELECT database_name, table_name, index_count FROM duckdb_tables ORDER BY ALL;\n+----\n+db1\tdata\t1\n+db2\tdata\t1\n\\ No newline at end of file\ndiff --git a/test/sql/copy_database/copy_database_with_unique_index.test b/test/sql/copy_database/copy_database_with_unique_index.test\nnew file mode 100644\nindex 000000000000..9c0e00123cf8\n--- /dev/null\n+++ b/test/sql/copy_database/copy_database_with_unique_index.test\n@@ -0,0 +1,62 @@\n+# name: test/sql/copy_database/copy_database_with_unique_index.test\n+# description: Test the COPY DATABASE statement with unique indexes.\n+# group: [copy_database]\n+\n+require noforcestorage\n+\n+statement ok\n+PRAGMA enable_verification;\n+\n+statement ok\n+ATTACH '__TEST_DIR__/copy_db_old.db' AS old;\n+\n+statement ok\n+CREATE TABLE old.items (id INT, uniq INT UNIQUE);\n+\n+statement ok\n+INSERT INTO old.items VALUES (1, 1), (2, 2), (3, 3);\n+\n+statement ok\n+CREATE UNIQUE INDEX idx_id ON old.items(id);\n+\n+statement ok\n+ATTACH '__TEST_DIR__/copy_db_new1.db' AS new1;\n+\n+statement ok\n+COPY FROM DATABASE old TO new1 (SCHEMA);\n+\n+statement ok\n+COPY FROM DATABASE old TO new1 (DATA);\n+\n+query II\n+SELECT id, uniq FROM new1.items ORDER BY ALL;\n+----\n+1\t1\n+2\t2\n+3\t3\n+\n+statement error\n+INSERT INTO new1.items VALUES (1, 4);\n+----\n+<REGEX>:Constraint Error.*violates unique constraint.*\n+\n+statement error\n+INSERT INTO new1.items VALUES (4, 1);\n+----\n+<REGEX>:Constraint Error.*violates unique constraint.*\n+\n+statement ok\n+DETACH new1;\n+\n+statement ok\n+ATTACH '__TEST_DIR__/copy_db_new1.db' AS new1;\n+\n+statement error\n+INSERT INTO new1.items VALUES (1, 4);\n+----\n+<REGEX>:Constraint Error.*violates unique constraint.*\n+\n+statement error\n+INSERT INTO new1.items VALUES (4, 1);\n+----\n+<REGEX>:Constraint Error.*violates unique constraint.*\ndiff --git a/test/sql/function/list/flatten.test b/test/sql/function/list/flatten.test\nindex e0c894b802ae..4869cb2233ce 100644\n--- a/test/sql/function/list/flatten.test\n+++ b/test/sql/function/list/flatten.test\n@@ -150,3 +150,13 @@ query I\n select flatten(NULL);\n ----\n NULL\n+\n+query IIII rowsort\n+with v_data (col, list) as ( select * FROM (VALUES ('a', [1,2,3]), ('b', [4,5]), ('a', [2,6])) ),\n+        v_list_of_lists ( col, list, list_of_lists ) as ( select v.*, array_agg(v.list) over (partition by v.col) from v_data v )\n+select v.*, flatten(v.list_of_lists) from v_list_of_lists v;\n+----\n+a\t[1, 2, 3]\t[[1, 2, 3], [2, 6]]\t[1, 2, 3, 2, 6]\n+a\t[2, 6]\t[[1, 2, 3], [2, 6]]\t[1, 2, 3, 2, 6]\n+b\t[4, 5]\t[[4, 5]]\t[4, 5]\n+\ndiff --git a/test/sql/index/art/constraints/test_art_eager_with_wal.test b/test/sql/index/art/constraints/test_art_eager_with_wal.test\nnew file mode 100644\nindex 000000000000..4d211adf7734\n--- /dev/null\n+++ b/test/sql/index/art/constraints/test_art_eager_with_wal.test\n@@ -0,0 +1,39 @@\n+# name: test/sql/index/art/constraints/test_art_eager_with_wal.test\n+# description: Test eager constraint checking with WAL replay.\n+# group: [constraints]\n+\n+load __TEST_DIR__/pk_duplicate_key_wal.db\n+\n+statement ok\n+PRAGMA enable_verification;\n+\n+statement ok\n+SET checkpoint_threshold = '10.0 GB';\n+\n+statement ok\n+PRAGMA disable_checkpoint_on_shutdown;\n+\n+statement ok\n+CREATE TABLE tbl (id INT PRIMARY KEY);\n+\n+statement ok\n+INSERT INTO tbl VALUES (1);\n+\n+statement ok\n+BEGIN;\n+\n+statement ok\n+DELETE FROM tbl WHERE id = 1;\n+\n+statement ok\n+INSERT INTO tbl VALUES (1);\n+\n+statement ok\n+COMMIT;\n+\n+restart\n+\n+statement error\n+INSERT INTO tbl VALUES (1);\n+----\n+<REGEX>:Constraint Error.*violates primary key constraint.*\n\\ No newline at end of file\ndiff --git a/test/sql/index/art/constraints/test_art_tx_returning.test b/test/sql/index/art/constraints/test_art_tx_returning.test\nindex 318d68b08844..de9e8963f04c 100644\n--- a/test/sql/index/art/constraints/test_art_tx_returning.test\n+++ b/test/sql/index/art/constraints/test_art_tx_returning.test\n@@ -2,6 +2,13 @@\n # description: Test updates on the primary key containing RETURNING.\n # group: [constraints]\n \n+# For each incoming chunk, we add the row IDs to the delete index.\n+# For standard_vector_size = 2, we delete [0, 1], and then try to insert value [1, 2].\n+# This is expected to throw a constraint violation.\n+# The value 2 is not yet in the delete index, as the chunk that would add that value hasn't been processed, yet.\n+# This scenario is a known limitation (also in postgres).\n+require vector_size 2048\n+\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/projection/select_star_rename.test b/test/sql/projection/select_star_rename.test\nindex f52f4a9e7b2a..7f3be601c2e0 100644\n--- a/test/sql/projection/select_star_rename.test\n+++ b/test/sql/projection/select_star_rename.test\n@@ -17,6 +17,12 @@ SELECT renamed_col FROM (SELECT * RENAME i AS renamed_col FROM integers)\n ----\n 1\n \n+# rename with COLUMNS\n+query I\n+SELECT renamed_col FROM (SELECT COLUMNS(* RENAME i AS renamed_col) FROM integers)\n+----\n+1\n+\n # qualified\n query I\n SELECT renamed_col FROM (SELECT * RENAME integers.i AS renamed_col FROM integers)\ndiff --git a/test/sql/sample/table_samples/basic_sample_tests.test b/test/sql/sample/table_samples/basic_sample_tests.test\nindex 1bb07364c9c3..733b14b6827a 100644\n--- a/test/sql/sample/table_samples/basic_sample_tests.test\n+++ b/test/sql/sample/table_samples/basic_sample_tests.test\n@@ -1,6 +1,11 @@\n # name: test/sql/sample/table_samples/basic_sample_tests.test\n # group: [table_samples]\n \n+# currently require fixed vector size since the \"randomness\" of the sample depends on\n+# the vector size. If the vector size decreases, the randomness of the sample decreases\n+# This is especially noticeable for small tables and their samples\n+require vector_size 2048\n+\n statement ok\n PRAGMA enable_verification\n \ndiff --git a/test/sql/sample/table_samples/sample_stores_rows_from_later_on.test_slow b/test/sql/sample/table_samples/sample_stores_rows_from_later_on.test_slow\nindex c88b9cd74a67..7f883d9fa19b 100644\n--- a/test/sql/sample/table_samples/sample_stores_rows_from_later_on.test_slow\n+++ b/test/sql/sample/table_samples/sample_stores_rows_from_later_on.test_slow\n@@ -2,6 +2,7 @@\n # description: Test sampling of larger relations\n # group: [table_samples]\n \n+# required when testing table samples. See basic_sample_test.test\n require vector_size 2048\n \n require noforcestorage\ndiff --git a/test/sql/sample/table_samples/table_sample_converts_to_block_sample.test b/test/sql/sample/table_samples/table_sample_converts_to_block_sample.test\nindex 0ffca61f31ef..3e810c325a3b 100644\n--- a/test/sql/sample/table_samples/table_sample_converts_to_block_sample.test\n+++ b/test/sql/sample/table_samples/table_sample_converts_to_block_sample.test\n@@ -2,6 +2,7 @@\n # description: Test sampling of larger relations\n # group: [table_samples]\n \n+# required when testing table samples. See basic_sample_test.test\n require vector_size 2048\n \n require noforcestorage\ndiff --git a/test/sql/sample/table_samples/table_sample_is_stored.test_slow b/test/sql/sample/table_samples/table_sample_is_stored.test_slow\nindex f8370557d2a5..aef613355f64 100644\n--- a/test/sql/sample/table_samples/table_sample_is_stored.test_slow\n+++ b/test/sql/sample/table_samples/table_sample_is_stored.test_slow\n@@ -2,6 +2,7 @@\n # description: Test sampling of larger relations\n # group: [table_samples]\n \n+# required when testing table samples. See basic_sample_test.test\n require vector_size 2048\n \n require noforcestorage\ndiff --git a/test/sql/sample/table_samples/test_sample_is_destroyed_on_updates.test b/test/sql/sample/table_samples/test_sample_is_destroyed_on_updates.test\nindex 410d9004e87c..5041df626617 100644\n--- a/test/sql/sample/table_samples/test_sample_is_destroyed_on_updates.test\n+++ b/test/sql/sample/table_samples/test_sample_is_destroyed_on_updates.test\n@@ -2,6 +2,7 @@\n # description: Test sampling of larger relations\n # group: [table_samples]\n \n+# required when testing table samples. See basic_sample_test.test\n require vector_size 2048\n \n load __TEST_DIR__/test_sample_is_destroyed_on_update.db\ndiff --git a/tools/pythonpkg/tests/fast/spark/test_spark_functions_date.py b/tools/pythonpkg/tests/fast/spark/test_spark_functions_date.py\nindex fda95752a714..8a03fd68169c 100644\n--- a/tools/pythonpkg/tests/fast/spark/test_spark_functions_date.py\n+++ b/tools/pythonpkg/tests/fast/spark/test_spark_functions_date.py\n@@ -177,20 +177,13 @@ def test_to_date(self, spark):\n     def test_to_timestamp(self, spark):\n         df = spark.createDataFrame([('1997-02-28 10:30:00',)], ['t'])\n         res = df.select(F.to_timestamp(df.t).alias('dt')).collect()\n-        # FIXME: Fix difference between DuckDB and Spark\n-        if USE_ACTUAL_SPARK:\n-            assert res == [Row(dt=datetime(1997, 2, 28, 10, 30))]\n-        else:\n-            assert res == [Row(dt=datetime(1997, 2, 28, 10, 30, tzinfo=timezone.utc))]\n+        assert res == [Row(dt=datetime(1997, 2, 28, 10, 30))]\n \n     def test_to_timestamp_ltz(self, spark):\n         df = spark.createDataFrame([(\"2016-12-31\",)], [\"e\"])\n         res = df.select(F.to_timestamp_ltz(df.e).alias('r')).collect()\n-        # FIXME: Fix difference between DuckDB and Spark\n-        if USE_ACTUAL_SPARK:\n-            assert res == [Row(r=datetime(2016, 12, 31, 0, 0))]\n-        else:\n-            assert res == [Row(r=datetime(2016, 12, 31, 0, 0, tzinfo=timezone.utc))]\n+\n+        assert res == [Row(r=datetime(2016, 12, 31, 0, 0))]\n \n     def test_to_timestamp_ntz(self, spark):\n         df = spark.createDataFrame([(\"2016-04-08\",)], [\"e\"])\n", "problem_statement": "DuckDB Trigger Assertion Failure: result.data[storage_idx].GetType() == chunk.data[mapped_index].GetType()\n### What happens?\r\n\r\nThe latest version of the DuckDB (latest main: v1.1.4-dev3741 ab8c909857) triggers Internal Error when running the following SQL statement: \r\n\r\n```sql\r\nCREATE TABLE v00 (c01 INT, c02 STRING);\r\nINSERT INTO v00 BY POSITION ( c02 ) OVERRIDING USER VALUE FROM LATERAL ( SELECT 'simple_string' ) AS ta507400 GROUP BY ALL WINDOW EVENT AS ( GROUPS BETWEEN 'abc' IS NOT UNKNOWN IN CASE WHEN 'abc' THEN 0 ELSE 'abc' END FOLLOWING AND UNBOUNDED FOLLOWING ) ORDER BY ALL RETURNING 'anything';\r\n```\r\n\r\nThe code is working fine from the latest release: v1.1.3 19864453f7. Maybe just a faulty assertion? \r\n\r\nHere is the stack from ab8c909857:\r\n\r\n```\r\nAssertion triggered in file \"/home/duckdb/duckdb/src/execution/operator/persistent/physical_insert.cpp\" on line 150: result.data[storage_idx].GetType() == chunk.data[mapped_index].GetType()\r\n\r\n#0  duckdb::InternalException::InternalException (this=0x60d000018ba0, Python Exception <class 'gdb.error'> There is no member named _M_dataplus.:\r\nmsg=) at /home/duckdb/duckdb/src/common/exception.cpp:320\r\n#1  0x00000000020c1089 in duckdb::InternalException::InternalException<char const*, int, char const*> (this=0x60d000018ba0, msg=...,\r\n    params=<optimized out>, params=<optimized out>, params=<optimized out>) at ../../src/include/duckdb/common/exception.hpp:313\r\n#2  0x0000000001e672b1 in duckdb::DuckDBAssertInternal (condition=<optimized out>, condition_name=<optimized out>, file=<optimized out>,\r\n    linenr=<optimized out>) at /home/duckdb/duckdb/src/common/assert.cpp:13\r\n#3  0x000000000a69cf33 in duckdb::PhysicalInsert::ResolveDefaults (table=..., chunk=..., column_index_map=..., default_executor=..., result=...)\r\n    at /home/duckdb/duckdb/src/execution/operator/persistent/physical_insert.cpp:150\r\n#4  0x000000000a6f5aaa in duckdb::PhysicalInsert::Sink (this=0x6150000e4a00, context=..., chunk=..., input=...)\r\n    at /home/duckdb/duckdb/src/execution/operator/persistent/physical_insert.cpp:623\r\n#5  0x0000000003cf87a8 in duckdb::PipelineExecutor::ExecutePushInternal (this=<optimized out>, input=..., chunk_budget=..., initial_idx=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:332\r\n#6  0x0000000003cdbda6 in duckdb::PipelineExecutor::Execute (this=0x615000083980, max_chunks=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:250\r\n#7  0x0000000003cdd7e0 in duckdb::PipelineExecutor::Execute (this=<optimized out>) at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:278\r\n#8  0x0000000003cd8c05 in duckdb::PipelineTask::ExecuteTask (this=0x60700008ace0, mode=<optimized out>) at /home/duckdb/duckdb/src/parallel/pipeline.cpp:51\r\n#9  0x0000000003ca595c in duckdb::ExecutorTask::Execute (this=0x60700008ace0, mode=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/executor_task.cpp:49\r\n#10 0x0000000003d0f68f in duckdb::TaskScheduler::ExecuteForever (this=<optimized out>, marker=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/task_scheduler.cpp:189\r\n#11 0x000079e0d73d5df4 in ?? () from /lib/x86_64-linux-gnu/libstdc++.so.6\r\n#12 0x000079e0d7195609 in start_thread (arg=<optimized out>) at pthread_create.c:477\r\n#13 0x000079e0d7093353 in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95\r\n```\r\n\r\n### To Reproduce\r\n\r\n1. Clone the DuckDB Git from the official repo.\r\n2. Checkout to the latest main (v1.1.4-dev3741 ab8c909857).\r\n3. Compile the DuckDB binary by using `make relassert` or `make debug`.\r\n4. Run the compiled DuckDB and input the following SQL:\r\n\r\n```sql\r\nCREATE TABLE v00 (c01 INT, c02 STRING);\r\nINSERT INTO v00 BY POSITION ( c02 ) OVERRIDING USER VALUE FROM LATERAL ( SELECT 'simple_string' ) AS ta507400 GROUP BY ALL WINDOW EVENT AS ( GROUPS BETWEEN 'abc' IS NOT UNKNOWN IN CASE WHEN 'abc' THEN 0 ELSE 'abc' END FOLLOWING AND UNBOUNDED FOLLOWING ) ORDER BY ALL RETURNING 'anything';\r\n```\r\n\r\n### OS:\r\n\r\nUbuntu 24.04 LTS\r\n\r\n### DuckDB Version:\r\n\r\nv1.1.4-dev3741 ab8c909857\r\n\r\n### DuckDB Client:\r\n\r\ncli\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\nYu Liang\r\n\r\n### Affiliation:\r\n\r\nPennsylvania State University\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a source build\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\nDuckDB Trigger Assertion Failure: result.data[storage_idx].GetType() == chunk.data[mapped_index].GetType()\n### What happens?\r\n\r\nThe latest version of the DuckDB (latest main: v1.1.4-dev3741 ab8c909857) triggers Internal Error when running the following SQL statement: \r\n\r\n```sql\r\nCREATE TABLE v00 (c01 INT, c02 STRING);\r\nINSERT INTO v00 BY POSITION ( c02 ) OVERRIDING USER VALUE FROM LATERAL ( SELECT 'simple_string' ) AS ta507400 GROUP BY ALL WINDOW EVENT AS ( GROUPS BETWEEN 'abc' IS NOT UNKNOWN IN CASE WHEN 'abc' THEN 0 ELSE 'abc' END FOLLOWING AND UNBOUNDED FOLLOWING ) ORDER BY ALL RETURNING 'anything';\r\n```\r\n\r\nThe code is working fine from the latest release: v1.1.3 19864453f7. Maybe just a faulty assertion? \r\n\r\nHere is the stack from ab8c909857:\r\n\r\n```\r\nAssertion triggered in file \"/home/duckdb/duckdb/src/execution/operator/persistent/physical_insert.cpp\" on line 150: result.data[storage_idx].GetType() == chunk.data[mapped_index].GetType()\r\n\r\n#0  duckdb::InternalException::InternalException (this=0x60d000018ba0, Python Exception <class 'gdb.error'> There is no member named _M_dataplus.:\r\nmsg=) at /home/duckdb/duckdb/src/common/exception.cpp:320\r\n#1  0x00000000020c1089 in duckdb::InternalException::InternalException<char const*, int, char const*> (this=0x60d000018ba0, msg=...,\r\n    params=<optimized out>, params=<optimized out>, params=<optimized out>) at ../../src/include/duckdb/common/exception.hpp:313\r\n#2  0x0000000001e672b1 in duckdb::DuckDBAssertInternal (condition=<optimized out>, condition_name=<optimized out>, file=<optimized out>,\r\n    linenr=<optimized out>) at /home/duckdb/duckdb/src/common/assert.cpp:13\r\n#3  0x000000000a69cf33 in duckdb::PhysicalInsert::ResolveDefaults (table=..., chunk=..., column_index_map=..., default_executor=..., result=...)\r\n    at /home/duckdb/duckdb/src/execution/operator/persistent/physical_insert.cpp:150\r\n#4  0x000000000a6f5aaa in duckdb::PhysicalInsert::Sink (this=0x6150000e4a00, context=..., chunk=..., input=...)\r\n    at /home/duckdb/duckdb/src/execution/operator/persistent/physical_insert.cpp:623\r\n#5  0x0000000003cf87a8 in duckdb::PipelineExecutor::ExecutePushInternal (this=<optimized out>, input=..., chunk_budget=..., initial_idx=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:332\r\n#6  0x0000000003cdbda6 in duckdb::PipelineExecutor::Execute (this=0x615000083980, max_chunks=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:250\r\n#7  0x0000000003cdd7e0 in duckdb::PipelineExecutor::Execute (this=<optimized out>) at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:278\r\n#8  0x0000000003cd8c05 in duckdb::PipelineTask::ExecuteTask (this=0x60700008ace0, mode=<optimized out>) at /home/duckdb/duckdb/src/parallel/pipeline.cpp:51\r\n#9  0x0000000003ca595c in duckdb::ExecutorTask::Execute (this=0x60700008ace0, mode=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/executor_task.cpp:49\r\n#10 0x0000000003d0f68f in duckdb::TaskScheduler::ExecuteForever (this=<optimized out>, marker=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/task_scheduler.cpp:189\r\n#11 0x000079e0d73d5df4 in ?? () from /lib/x86_64-linux-gnu/libstdc++.so.6\r\n#12 0x000079e0d7195609 in start_thread (arg=<optimized out>) at pthread_create.c:477\r\n#13 0x000079e0d7093353 in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95\r\n```\r\n\r\n### To Reproduce\r\n\r\n1. Clone the DuckDB Git from the official repo.\r\n2. Checkout to the latest main (v1.1.4-dev3741 ab8c909857).\r\n3. Compile the DuckDB binary by using `make relassert` or `make debug`.\r\n4. Run the compiled DuckDB and input the following SQL:\r\n\r\n```sql\r\nCREATE TABLE v00 (c01 INT, c02 STRING);\r\nINSERT INTO v00 BY POSITION ( c02 ) OVERRIDING USER VALUE FROM LATERAL ( SELECT 'simple_string' ) AS ta507400 GROUP BY ALL WINDOW EVENT AS ( GROUPS BETWEEN 'abc' IS NOT UNKNOWN IN CASE WHEN 'abc' THEN 0 ELSE 'abc' END FOLLOWING AND UNBOUNDED FOLLOWING ) ORDER BY ALL RETURNING 'anything';\r\n```\r\n\r\n### OS:\r\n\r\nUbuntu 24.04 LTS\r\n\r\n### DuckDB Version:\r\n\r\nv1.1.4-dev3741 ab8c909857\r\n\r\n### DuckDB Client:\r\n\r\ncli\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\nYu Liang\r\n\r\n### Affiliation:\r\n\r\nPennsylvania State University\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a source build\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\n", "hints_text": "\n", "created_at": "2025-01-29T21:40:50Z"}
{"repo": "duckdb/duckdb", "pull_number": 15987, "instance_id": "duckdb__duckdb-15987", "issue_numbers": ["15443", "15443"], "base_commit": "cf03ec882f1db588da5b432c1e9e26ace76a7c0f", "patch": "diff --git a/src/optimizer/column_lifetime_analyzer.cpp b/src/optimizer/column_lifetime_analyzer.cpp\nindex efb3e684d473..8b6f1152bf8c 100644\n--- a/src/optimizer/column_lifetime_analyzer.cpp\n+++ b/src/optimizer/column_lifetime_analyzer.cpp\n@@ -102,6 +102,12 @@ void ColumnLifetimeAnalyzer::VisitOperator(LogicalOperator &op) {\n \t\tGenerateProjectionMap(op.children[1]->GetColumnBindings(), rhs_unused, comp_join.right_projection_map);\n \t\treturn;\n \t}\n+\tcase LogicalOperatorType::LOGICAL_INSERT:\n+\tcase LogicalOperatorType::LOGICAL_UPDATE:\n+\tcase LogicalOperatorType::LOGICAL_DELETE:\n+\t\t//! When RETURNING is used, a PROJECTION is the top level operator for INSERTS, UPDATES, and DELETES\n+\t\t//! We still need to project all values from these operators so the projection\n+\t\t//! on top of them can select from only the table values being inserted.\n \tcase LogicalOperatorType::LOGICAL_UNION:\n \tcase LogicalOperatorType::LOGICAL_EXCEPT:\n \tcase LogicalOperatorType::LOGICAL_INTERSECT:\n", "test_patch": "diff --git a/test/fuzzer/public/insert_returning.test b/test/fuzzer/public/insert_returning.test\nnew file mode 100644\nindex 000000000000..4f4cfb9acea5\n--- /dev/null\n+++ b/test/fuzzer/public/insert_returning.test\n@@ -0,0 +1,17 @@\n+# name: test/fuzzer/public/insert_returning.test\n+# description: Test INSERT OR REPLACE with DEFAULT VALUES\n+# group: [public]\n+\n+statement ok\n+pragma enable_verification\n+\n+statement ok\n+CREATE TABLE v00 (c01 INT, c02 STRING);\n+\n+statement ok\n+INSERT INTO v00 (c01, c02) VALUES (0, 'abc');\n+\n+query I\n+INSERT INTO v00 FROM v00 ORDER BY ALL DESC RETURNING 'abc';\n+----\n+abc\n", "problem_statement": "DuckDB Trigger Assertion Failure: result.data[storage_idx].GetType() == chunk.data[mapped_index].GetType()\n### What happens?\r\n\r\nThe latest version of the DuckDB (latest main: v1.1.4-dev3741 ab8c909857) triggers Internal Error when running the following SQL statement: \r\n\r\n```sql\r\nCREATE TABLE v00 (c01 INT, c02 STRING);\r\nINSERT INTO v00 BY POSITION ( c02 ) OVERRIDING USER VALUE FROM LATERAL ( SELECT 'simple_string' ) AS ta507400 GROUP BY ALL WINDOW EVENT AS ( GROUPS BETWEEN 'abc' IS NOT UNKNOWN IN CASE WHEN 'abc' THEN 0 ELSE 'abc' END FOLLOWING AND UNBOUNDED FOLLOWING ) ORDER BY ALL RETURNING 'anything';\r\n```\r\n\r\nThe code is working fine from the latest release: v1.1.3 19864453f7. Maybe just a faulty assertion? \r\n\r\nHere is the stack from ab8c909857:\r\n\r\n```\r\nAssertion triggered in file \"/home/duckdb/duckdb/src/execution/operator/persistent/physical_insert.cpp\" on line 150: result.data[storage_idx].GetType() == chunk.data[mapped_index].GetType()\r\n\r\n#0  duckdb::InternalException::InternalException (this=0x60d000018ba0, Python Exception <class 'gdb.error'> There is no member named _M_dataplus.:\r\nmsg=) at /home/duckdb/duckdb/src/common/exception.cpp:320\r\n#1  0x00000000020c1089 in duckdb::InternalException::InternalException<char const*, int, char const*> (this=0x60d000018ba0, msg=...,\r\n    params=<optimized out>, params=<optimized out>, params=<optimized out>) at ../../src/include/duckdb/common/exception.hpp:313\r\n#2  0x0000000001e672b1 in duckdb::DuckDBAssertInternal (condition=<optimized out>, condition_name=<optimized out>, file=<optimized out>,\r\n    linenr=<optimized out>) at /home/duckdb/duckdb/src/common/assert.cpp:13\r\n#3  0x000000000a69cf33 in duckdb::PhysicalInsert::ResolveDefaults (table=..., chunk=..., column_index_map=..., default_executor=..., result=...)\r\n    at /home/duckdb/duckdb/src/execution/operator/persistent/physical_insert.cpp:150\r\n#4  0x000000000a6f5aaa in duckdb::PhysicalInsert::Sink (this=0x6150000e4a00, context=..., chunk=..., input=...)\r\n    at /home/duckdb/duckdb/src/execution/operator/persistent/physical_insert.cpp:623\r\n#5  0x0000000003cf87a8 in duckdb::PipelineExecutor::ExecutePushInternal (this=<optimized out>, input=..., chunk_budget=..., initial_idx=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:332\r\n#6  0x0000000003cdbda6 in duckdb::PipelineExecutor::Execute (this=0x615000083980, max_chunks=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:250\r\n#7  0x0000000003cdd7e0 in duckdb::PipelineExecutor::Execute (this=<optimized out>) at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:278\r\n#8  0x0000000003cd8c05 in duckdb::PipelineTask::ExecuteTask (this=0x60700008ace0, mode=<optimized out>) at /home/duckdb/duckdb/src/parallel/pipeline.cpp:51\r\n#9  0x0000000003ca595c in duckdb::ExecutorTask::Execute (this=0x60700008ace0, mode=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/executor_task.cpp:49\r\n#10 0x0000000003d0f68f in duckdb::TaskScheduler::ExecuteForever (this=<optimized out>, marker=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/task_scheduler.cpp:189\r\n#11 0x000079e0d73d5df4 in ?? () from /lib/x86_64-linux-gnu/libstdc++.so.6\r\n#12 0x000079e0d7195609 in start_thread (arg=<optimized out>) at pthread_create.c:477\r\n#13 0x000079e0d7093353 in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95\r\n```\r\n\r\n### To Reproduce\r\n\r\n1. Clone the DuckDB Git from the official repo.\r\n2. Checkout to the latest main (v1.1.4-dev3741 ab8c909857).\r\n3. Compile the DuckDB binary by using `make relassert` or `make debug`.\r\n4. Run the compiled DuckDB and input the following SQL:\r\n\r\n```sql\r\nCREATE TABLE v00 (c01 INT, c02 STRING);\r\nINSERT INTO v00 BY POSITION ( c02 ) OVERRIDING USER VALUE FROM LATERAL ( SELECT 'simple_string' ) AS ta507400 GROUP BY ALL WINDOW EVENT AS ( GROUPS BETWEEN 'abc' IS NOT UNKNOWN IN CASE WHEN 'abc' THEN 0 ELSE 'abc' END FOLLOWING AND UNBOUNDED FOLLOWING ) ORDER BY ALL RETURNING 'anything';\r\n```\r\n\r\n### OS:\r\n\r\nUbuntu 24.04 LTS\r\n\r\n### DuckDB Version:\r\n\r\nv1.1.4-dev3741 ab8c909857\r\n\r\n### DuckDB Client:\r\n\r\ncli\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\nYu Liang\r\n\r\n### Affiliation:\r\n\r\nPennsylvania State University\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a source build\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\nDuckDB Trigger Assertion Failure: result.data[storage_idx].GetType() == chunk.data[mapped_index].GetType()\n### What happens?\r\n\r\nThe latest version of the DuckDB (latest main: v1.1.4-dev3741 ab8c909857) triggers Internal Error when running the following SQL statement: \r\n\r\n```sql\r\nCREATE TABLE v00 (c01 INT, c02 STRING);\r\nINSERT INTO v00 BY POSITION ( c02 ) OVERRIDING USER VALUE FROM LATERAL ( SELECT 'simple_string' ) AS ta507400 GROUP BY ALL WINDOW EVENT AS ( GROUPS BETWEEN 'abc' IS NOT UNKNOWN IN CASE WHEN 'abc' THEN 0 ELSE 'abc' END FOLLOWING AND UNBOUNDED FOLLOWING ) ORDER BY ALL RETURNING 'anything';\r\n```\r\n\r\nThe code is working fine from the latest release: v1.1.3 19864453f7. Maybe just a faulty assertion? \r\n\r\nHere is the stack from ab8c909857:\r\n\r\n```\r\nAssertion triggered in file \"/home/duckdb/duckdb/src/execution/operator/persistent/physical_insert.cpp\" on line 150: result.data[storage_idx].GetType() == chunk.data[mapped_index].GetType()\r\n\r\n#0  duckdb::InternalException::InternalException (this=0x60d000018ba0, Python Exception <class 'gdb.error'> There is no member named _M_dataplus.:\r\nmsg=) at /home/duckdb/duckdb/src/common/exception.cpp:320\r\n#1  0x00000000020c1089 in duckdb::InternalException::InternalException<char const*, int, char const*> (this=0x60d000018ba0, msg=...,\r\n    params=<optimized out>, params=<optimized out>, params=<optimized out>) at ../../src/include/duckdb/common/exception.hpp:313\r\n#2  0x0000000001e672b1 in duckdb::DuckDBAssertInternal (condition=<optimized out>, condition_name=<optimized out>, file=<optimized out>,\r\n    linenr=<optimized out>) at /home/duckdb/duckdb/src/common/assert.cpp:13\r\n#3  0x000000000a69cf33 in duckdb::PhysicalInsert::ResolveDefaults (table=..., chunk=..., column_index_map=..., default_executor=..., result=...)\r\n    at /home/duckdb/duckdb/src/execution/operator/persistent/physical_insert.cpp:150\r\n#4  0x000000000a6f5aaa in duckdb::PhysicalInsert::Sink (this=0x6150000e4a00, context=..., chunk=..., input=...)\r\n    at /home/duckdb/duckdb/src/execution/operator/persistent/physical_insert.cpp:623\r\n#5  0x0000000003cf87a8 in duckdb::PipelineExecutor::ExecutePushInternal (this=<optimized out>, input=..., chunk_budget=..., initial_idx=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:332\r\n#6  0x0000000003cdbda6 in duckdb::PipelineExecutor::Execute (this=0x615000083980, max_chunks=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:250\r\n#7  0x0000000003cdd7e0 in duckdb::PipelineExecutor::Execute (this=<optimized out>) at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:278\r\n#8  0x0000000003cd8c05 in duckdb::PipelineTask::ExecuteTask (this=0x60700008ace0, mode=<optimized out>) at /home/duckdb/duckdb/src/parallel/pipeline.cpp:51\r\n#9  0x0000000003ca595c in duckdb::ExecutorTask::Execute (this=0x60700008ace0, mode=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/executor_task.cpp:49\r\n#10 0x0000000003d0f68f in duckdb::TaskScheduler::ExecuteForever (this=<optimized out>, marker=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/task_scheduler.cpp:189\r\n#11 0x000079e0d73d5df4 in ?? () from /lib/x86_64-linux-gnu/libstdc++.so.6\r\n#12 0x000079e0d7195609 in start_thread (arg=<optimized out>) at pthread_create.c:477\r\n#13 0x000079e0d7093353 in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95\r\n```\r\n\r\n### To Reproduce\r\n\r\n1. Clone the DuckDB Git from the official repo.\r\n2. Checkout to the latest main (v1.1.4-dev3741 ab8c909857).\r\n3. Compile the DuckDB binary by using `make relassert` or `make debug`.\r\n4. Run the compiled DuckDB and input the following SQL:\r\n\r\n```sql\r\nCREATE TABLE v00 (c01 INT, c02 STRING);\r\nINSERT INTO v00 BY POSITION ( c02 ) OVERRIDING USER VALUE FROM LATERAL ( SELECT 'simple_string' ) AS ta507400 GROUP BY ALL WINDOW EVENT AS ( GROUPS BETWEEN 'abc' IS NOT UNKNOWN IN CASE WHEN 'abc' THEN 0 ELSE 'abc' END FOLLOWING AND UNBOUNDED FOLLOWING ) ORDER BY ALL RETURNING 'anything';\r\n```\r\n\r\n### OS:\r\n\r\nUbuntu 24.04 LTS\r\n\r\n### DuckDB Version:\r\n\r\nv1.1.4-dev3741 ab8c909857\r\n\r\n### DuckDB Client:\r\n\r\ncli\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\nYu Liang\r\n\r\n### Affiliation:\r\n\r\nPennsylvania State University\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a source build\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\n", "hints_text": "Another very possible the same bug: \r\n\r\n```sql\r\nCREATE TABLE v00 (c01 INT, c02 STRING);\r\nINSERT INTO v00 (c01, c02) VALUES (0, 'abc');\r\nINSERT INTO v00 FROM v00 ORDER BY ALL DESC RETURNING 'abc';\r\n```\r\n\r\nStack trace from v1.1.4-dev3741 ab8c909857:\r\n\r\n```\r\n#0  duckdb::InternalException::InternalException (this=0x60d000019700, Python Exception <class 'gdb.error'> There is no member named _M_dataplus.:\r\nmsg=) at /home/duckdb/duckdb/src/common/exception.cpp:320\r\n#1  0x00000000020c1089 in duckdb::InternalException::InternalException<char const*, int, char const*> (this=0x60d000019700, msg=...,\r\n    params=<optimized out>, params=<optimized out>, params=<optimized out>) at ../../src/include/duckdb/common/exception.hpp:313\r\n#2  0x0000000001e672b1 in duckdb::DuckDBAssertInternal (condition=<optimized out>, condition_name=<optimized out>, file=<optimized out>,\r\n    linenr=<optimized out>) at /home/duckdb/duckdb/src/common/assert.cpp:13\r\n#3  0x000000000a69c425 in duckdb::PhysicalInsert::ResolveDefaults (table=..., chunk=..., column_index_map=..., default_executor=..., result=...)\r\n    at /home/duckdb/duckdb/src/execution/operator/persistent/physical_insert.cpp:157\r\n#4  0x000000000a6f5aaa in duckdb::PhysicalInsert::Sink (this=0x61500012d700, context=..., chunk=..., input=...)\r\n    at /home/duckdb/duckdb/src/execution/operator/persistent/physical_insert.cpp:623\r\n#5  0x0000000003cf87a8 in duckdb::PipelineExecutor::ExecutePushInternal (this=<optimized out>, input=..., chunk_budget=..., initial_idx=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:332\r\n#6  0x0000000003cdbda6 in duckdb::PipelineExecutor::Execute (this=0x615000083980, max_chunks=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:250\r\n#7  0x0000000003cdd7e0 in duckdb::PipelineExecutor::Execute (this=<optimized out>) at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:278\r\n#8  0x0000000003cd8c05 in duckdb::PipelineTask::ExecuteTask (this=0x60700008e400, mode=<optimized out>) at /home/duckdb/duckdb/src/parallel/pipeline.cpp:51\r\n#9  0x0000000003ca595c in duckdb::ExecutorTask::Execute (this=0x60700008e400, mode=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/executor_task.cpp:49\r\n#10 0x0000000003d0f68f in duckdb::TaskScheduler::ExecuteForever (this=<optimized out>, marker=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/task_scheduler.cpp:189\r\n#11 0x00007defcc3d8df4 in ?? () from /lib/x86_64-linux-gnu/libstdc++.so.6\r\n#12 0x00007defcc198609 in start_thread (arg=<optimized out>) at pthread_create.c:477\r\n#13 0x00007defcc096353 in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95\r\n```\nHi, I'm unable to reproduce this on the latest main. That said, the assertion is likely still there, so we'll definitely take a look!\r\n\r\n```bash\r\n~/git/duckdb/build/relassert/duckdb\r\n```\r\n```console\r\nduckdb(97944,0x205188240) malloc: nano zone abandoned due to inability to reserve vm space.\r\nv1.1.3-dev3906 ab8c909857\r\nEnter \".help\" for usage hints.\r\nConnected to a transient in-memory database.\r\nUse \".open FILENAME\" to reopen on a persistent database.\r\nD CREATE TABLE v00 (c01 INT, c02 STRING);\r\nD INSERT INTO v00 BY POSITION ( c02 ) OVERRIDING USER VALUE FROM LATERAL ( SELECT 'simple_string' ) AS ta507400 GROUP BY ALL WINDOW EVENT AS ( GROUPS BETWEEN 'abc' IS NOT UNKNOWN IN CASE WHEN 'abc' THEN 0 ELSE 'abc' END FOLLOWING AND UNBOUNDED FOLLOWING ) ORDER BY ALL RETURNING 'anything';\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 'anything' \u2502\r\n\u2502  varchar   \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 anything   \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\n> Hi, I'm unable to reproduce this on the latest main. That said, the assertion is likely still there, so we'll definitely take a look!\r\n> \r\n> ```shell\r\n> ~/git/duckdb/build/relassert/duckdb\r\n> ```\r\n> \r\n>  ```\r\n> duckdb(97944,0x205188240) malloc: nano zone abandoned due to inability to reserve vm space.\r\n> v1.1.3-dev3906 ab8c909857\r\n> Enter \".help\" for usage hints.\r\n> Connected to a transient in-memory database.\r\n> Use \".open FILENAME\" to reopen on a persistent database.\r\n> D CREATE TABLE v00 (c01 INT, c02 STRING);\r\n> D INSERT INTO v00 BY POSITION ( c02 ) OVERRIDING USER VALUE FROM LATERAL ( SELECT 'simple_string' ) AS ta507400 GROUP BY ALL WINDOW EVENT AS ( GROUPS BETWEEN 'abc' IS NOT UNKNOWN IN CASE WHEN 'abc' THEN 0 ELSE 'abc' END FOLLOWING AND UNBOUNDED FOLLOWING ) ORDER BY ALL RETURNING 'anything';\r\n> \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n> \u2502 'anything' \u2502\r\n> \u2502  varchar   \u2502\r\n> \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n> \u2502 anything   \u2502\r\n> \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n> ```\r\n\r\nOh it is possible that I am using `make debug` build. Maybe the assertion is inside the debug code? \r\n\r\nMerry Christmas! \ud83c\udf84\nAnother very possible the same bug: \r\n\r\n```sql\r\nCREATE TABLE v00 (c01 INT, c02 STRING);\r\nINSERT INTO v00 (c01, c02) VALUES (0, 'abc');\r\nINSERT INTO v00 FROM v00 ORDER BY ALL DESC RETURNING 'abc';\r\n```\r\n\r\nStack trace from v1.1.4-dev3741 ab8c909857:\r\n\r\n```\r\n#0  duckdb::InternalException::InternalException (this=0x60d000019700, Python Exception <class 'gdb.error'> There is no member named _M_dataplus.:\r\nmsg=) at /home/duckdb/duckdb/src/common/exception.cpp:320\r\n#1  0x00000000020c1089 in duckdb::InternalException::InternalException<char const*, int, char const*> (this=0x60d000019700, msg=...,\r\n    params=<optimized out>, params=<optimized out>, params=<optimized out>) at ../../src/include/duckdb/common/exception.hpp:313\r\n#2  0x0000000001e672b1 in duckdb::DuckDBAssertInternal (condition=<optimized out>, condition_name=<optimized out>, file=<optimized out>,\r\n    linenr=<optimized out>) at /home/duckdb/duckdb/src/common/assert.cpp:13\r\n#3  0x000000000a69c425 in duckdb::PhysicalInsert::ResolveDefaults (table=..., chunk=..., column_index_map=..., default_executor=..., result=...)\r\n    at /home/duckdb/duckdb/src/execution/operator/persistent/physical_insert.cpp:157\r\n#4  0x000000000a6f5aaa in duckdb::PhysicalInsert::Sink (this=0x61500012d700, context=..., chunk=..., input=...)\r\n    at /home/duckdb/duckdb/src/execution/operator/persistent/physical_insert.cpp:623\r\n#5  0x0000000003cf87a8 in duckdb::PipelineExecutor::ExecutePushInternal (this=<optimized out>, input=..., chunk_budget=..., initial_idx=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:332\r\n#6  0x0000000003cdbda6 in duckdb::PipelineExecutor::Execute (this=0x615000083980, max_chunks=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:250\r\n#7  0x0000000003cdd7e0 in duckdb::PipelineExecutor::Execute (this=<optimized out>) at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:278\r\n#8  0x0000000003cd8c05 in duckdb::PipelineTask::ExecuteTask (this=0x60700008e400, mode=<optimized out>) at /home/duckdb/duckdb/src/parallel/pipeline.cpp:51\r\n#9  0x0000000003ca595c in duckdb::ExecutorTask::Execute (this=0x60700008e400, mode=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/executor_task.cpp:49\r\n#10 0x0000000003d0f68f in duckdb::TaskScheduler::ExecuteForever (this=<optimized out>, marker=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/task_scheduler.cpp:189\r\n#11 0x00007defcc3d8df4 in ?? () from /lib/x86_64-linux-gnu/libstdc++.so.6\r\n#12 0x00007defcc198609 in start_thread (arg=<optimized out>) at pthread_create.c:477\r\n#13 0x00007defcc096353 in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95\r\n```\nHi, I'm unable to reproduce this on the latest main. That said, the assertion is likely still there, so we'll definitely take a look!\r\n\r\n```bash\r\n~/git/duckdb/build/relassert/duckdb\r\n```\r\n```console\r\nduckdb(97944,0x205188240) malloc: nano zone abandoned due to inability to reserve vm space.\r\nv1.1.3-dev3906 ab8c909857\r\nEnter \".help\" for usage hints.\r\nConnected to a transient in-memory database.\r\nUse \".open FILENAME\" to reopen on a persistent database.\r\nD CREATE TABLE v00 (c01 INT, c02 STRING);\r\nD INSERT INTO v00 BY POSITION ( c02 ) OVERRIDING USER VALUE FROM LATERAL ( SELECT 'simple_string' ) AS ta507400 GROUP BY ALL WINDOW EVENT AS ( GROUPS BETWEEN 'abc' IS NOT UNKNOWN IN CASE WHEN 'abc' THEN 0 ELSE 'abc' END FOLLOWING AND UNBOUNDED FOLLOWING ) ORDER BY ALL RETURNING 'anything';\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 'anything' \u2502\r\n\u2502  varchar   \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 anything   \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\n> Hi, I'm unable to reproduce this on the latest main. That said, the assertion is likely still there, so we'll definitely take a look!\r\n> \r\n> ```shell\r\n> ~/git/duckdb/build/relassert/duckdb\r\n> ```\r\n> \r\n>  ```\r\n> duckdb(97944,0x205188240) malloc: nano zone abandoned due to inability to reserve vm space.\r\n> v1.1.3-dev3906 ab8c909857\r\n> Enter \".help\" for usage hints.\r\n> Connected to a transient in-memory database.\r\n> Use \".open FILENAME\" to reopen on a persistent database.\r\n> D CREATE TABLE v00 (c01 INT, c02 STRING);\r\n> D INSERT INTO v00 BY POSITION ( c02 ) OVERRIDING USER VALUE FROM LATERAL ( SELECT 'simple_string' ) AS ta507400 GROUP BY ALL WINDOW EVENT AS ( GROUPS BETWEEN 'abc' IS NOT UNKNOWN IN CASE WHEN 'abc' THEN 0 ELSE 'abc' END FOLLOWING AND UNBOUNDED FOLLOWING ) ORDER BY ALL RETURNING 'anything';\r\n> \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n> \u2502 'anything' \u2502\r\n> \u2502  varchar   \u2502\r\n> \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n> \u2502 anything   \u2502\r\n> \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n> ```\r\n\r\nOh it is possible that I am using `make debug` build. Maybe the assertion is inside the debug code? \r\n\r\nMerry Christmas! \ud83c\udf84", "created_at": "2025-01-29T18:38:19Z"}
{"repo": "duckdb/duckdb", "pull_number": 15977, "instance_id": "duckdb__duckdb-15977", "issue_numbers": ["15791"], "base_commit": "45ee9acbc1836a27a6ce4e4d94bf7a44a485bf4f", "patch": "diff --git a/src/common/types/column/column_data_collection.cpp b/src/common/types/column/column_data_collection.cpp\nindex d6e01e5a663d..17be6722389b 100644\n--- a/src/common/types/column/column_data_collection.cpp\n+++ b/src/common/types/column/column_data_collection.cpp\n@@ -799,7 +799,10 @@ static bool IsComplexType(const LogicalType &type) {\n \n void ColumnDataCollection::Append(ColumnDataAppendState &state, DataChunk &input) {\n \tD_ASSERT(!finished_append);\n-\tD_ASSERT(types == input.GetTypes());\n+\t{\n+\t\tauto input_types = input.GetTypes();\n+\t\tD_ASSERT(types == input_types);\n+\t}\n \n \tauto &segment = *segments.back();\n \tfor (idx_t vector_idx = 0; vector_idx < types.size(); vector_idx++) {\ndiff --git a/src/execution/operator/persistent/physical_insert.cpp b/src/execution/operator/persistent/physical_insert.cpp\nindex 3d14f365d0a3..161fa8f58a20 100644\n--- a/src/execution/operator/persistent/physical_insert.cpp\n+++ b/src/execution/operator/persistent/physical_insert.cpp\n@@ -253,6 +253,7 @@ static void CreateUpdateChunk(ExecutionContext &context, DataChunk &chunk, Table\n \t\t\tchunk.SetCardinality(selection.Count());\n \t\t\t// Also apply this Slice to the to-update row_ids\n \t\t\trow_ids.Slice(selection.Selection(), selection.Count());\n+\t\t\trow_ids.Flatten(selection.Count());\n \t\t}\n \t}\n \n@@ -284,8 +285,27 @@ static idx_t PerformOnConflictAction(InsertLocalState &lstate, InsertGlobalState\n \tCreateUpdateChunk(context, chunk, table, row_ids, update_chunk, op);\n \tauto &data_table = table.GetStorage();\n \n+\tif (update_chunk.size() == 0) {\n+\t\t// Nothing to do\n+\t\treturn update_chunk.size();\n+\t}\n+\n+\t// Arrange the columns in the standard table order.\n+\tDataChunk &append_chunk = lstate.append_chunk;\n+\tappend_chunk.SetCardinality(update_chunk);\n+\tfor (idx_t i = 0; i < append_chunk.ColumnCount(); i++) {\n+\t\tappend_chunk.data[i].Reference(chunk.data[i]);\n+\t}\n+\tfor (idx_t i = 0; i < set_columns.size(); i++) {\n+\t\tappend_chunk.data[set_columns[i].index].Reference(update_chunk.data[i]);\n+\t}\n+\n \t// Perform the UPDATE on the (global) storage.\n \tif (!op.update_is_del_and_insert) {\n+\t\tif (!op.parallel && op.return_chunk) {\n+\t\t\tgstate.return_collection.Append(append_chunk);\n+\t\t}\n+\n \t\tif (GLOBAL) {\n \t\t\tauto update_state = data_table.InitializeUpdate(table, context.client, op.bound_constraints);\n \t\t\tdata_table.Update(*update_state, context.client, row_ids, set_columns, update_chunk);\n@@ -301,16 +321,6 @@ static idx_t PerformOnConflictAction(InsertLocalState &lstate, InsertGlobalState\n \t\treturn update_chunk.size();\n \t}\n \n-\t// Arrange the columns in the standard table order.\n-\tDataChunk &append_chunk = lstate.append_chunk;\n-\tappend_chunk.SetCardinality(update_chunk);\n-\tfor (idx_t i = 0; i < append_chunk.ColumnCount(); i++) {\n-\t\tappend_chunk.data[i].Reference(chunk.data[i]);\n-\t}\n-\tfor (idx_t i = 0; i < set_columns.size(); i++) {\n-\t\tappend_chunk.data[set_columns[i].index].Reference(update_chunk.data[i]);\n-\t}\n-\n \tif (GLOBAL) {\n \t\tauto &delete_state = lstate.GetDeleteState(data_table, table, context.client);\n \t\tdata_table.Delete(delete_state, context.client, row_ids, update_chunk.size());\n@@ -319,6 +329,9 @@ static idx_t PerformOnConflictAction(InsertLocalState &lstate, InsertGlobalState\n \t\tlocal_storage.Delete(data_table, row_ids, update_chunk.size());\n \t}\n \n+\tif (!op.parallel && op.return_chunk) {\n+\t\tgstate.return_collection.Append(append_chunk);\n+\t}\n \tdata_table.LocalAppend(table, context.client, append_chunk, op.bound_constraints, row_ids, append_chunk);\n \treturn update_chunk.size();\n }\n@@ -647,23 +660,13 @@ SinkResultType PhysicalInsert::Sink(ExecutionContext &context, DataChunk &chunk,\n \t\t\tgstate.initialized = true;\n \t\t}\n \n-\t\t// FIXME: this is way too optimistic\n-\t\t// some tuples could be filtered out entirely and thus shouldn't be added to the return chunk.\n-\t\tif (action_type != OnConflictAction::NOTHING && return_chunk) {\n-\t\t\t// If the action is UPDATE or REPLACE, we will always create either an APPEND or an INSERT\n-\t\t\t// for NOTHING we don't create either an APPEND or an INSERT for the tuple\n-\t\t\t// so it should not be added to the RETURNING chunk\n-\t\t\tgstate.return_collection.Append(lstate.insert_chunk);\n-\t\t}\n \t\tidx_t updated_tuples = OnConflictHandling(table, context, gstate, lstate);\n-\t\tif (action_type == OnConflictAction::NOTHING && return_chunk) {\n-\t\t\t// Because we didn't add to the RETURNING chunk yet\n-\t\t\t// we add the tuples that did not get filtered out now\n-\t\t\tgstate.return_collection.Append(lstate.insert_chunk);\n-\t\t}\n \n \t\tgstate.insert_count += lstate.insert_chunk.size();\n \t\tgstate.insert_count += updated_tuples;\n+\t\tif (!parallel && return_chunk) {\n+\t\t\tgstate.return_collection.Append(lstate.insert_chunk);\n+\t\t}\n \t\tstorage.LocalAppend(gstate.append_state, context.client, lstate.insert_chunk, true);\n \t\tif (action_type == OnConflictAction::UPDATE && lstate.update_chunk.size() != 0) {\n \t\t\t(void)HandleInsertConflicts<true>(table, context, lstate, gstate, lstate.update_chunk, *this);\ndiff --git a/src/storage/local_storage.cpp b/src/storage/local_storage.cpp\nindex cbbf64df28f8..93dccfcba763 100644\n--- a/src/storage/local_storage.cpp\n+++ b/src/storage/local_storage.cpp\n@@ -474,6 +474,7 @@ idx_t LocalStorage::Delete(DataTable &table, Vector &row_ids, idx_t count) {\n \n void LocalStorage::Update(DataTable &table, Vector &row_ids, const vector<PhysicalIndex> &column_ids,\n                           DataChunk &updates) {\n+\tD_ASSERT(updates.size() >= 1);\n \tauto storage = table_manager.GetStorage(table);\n \tD_ASSERT(storage);\n \ndiff --git a/src/storage/table/row_group_collection.cpp b/src/storage/table/row_group_collection.cpp\nindex 2629800a4be8..dc0a7eb47eb7 100644\n--- a/src/storage/table/row_group_collection.cpp\n+++ b/src/storage/table/row_group_collection.cpp\n@@ -593,6 +593,7 @@ idx_t RowGroupCollection::Delete(TransactionData transaction, DataTable &table,\n //===--------------------------------------------------------------------===//\n void RowGroupCollection::Update(TransactionData transaction, row_t *ids, const vector<PhysicalIndex> &column_ids,\n                                 DataChunk &updates) {\n+\tD_ASSERT(updates.size() >= 1);\n \tidx_t pos = 0;\n \tdo {\n \t\tidx_t start = pos;\n", "test_patch": "diff --git a/test/sql/upsert/test_problematic_conditional_do_update.test b/test/sql/upsert/test_problematic_conditional_do_update.test\nindex 078c35321ac9..ade3cd1bde07 100644\n--- a/test/sql/upsert/test_problematic_conditional_do_update.test\n+++ b/test/sql/upsert/test_problematic_conditional_do_update.test\n@@ -8,6 +8,9 @@ CREATE TABLE users (\n \temail TEXT\n );\n \n+# FIXME: not consistent\n+mode skip\n+\n # The condition skips the last tuple\n statement error\n INSERT INTO users (id, username, email)\ndiff --git a/test/sql/upsert/upsert_returning.test b/test/sql/upsert/upsert_returning.test\nnew file mode 100644\nindex 000000000000..cbb3c90126d9\n--- /dev/null\n+++ b/test/sql/upsert/upsert_returning.test\n@@ -0,0 +1,83 @@\n+# name: test/sql/upsert/upsert_returning.test\n+# group: [upsert]\n+\n+require vector_size 2048\n+\n+statement ok\n+CREATE TABLE users (\n+    id BIGINT PRIMARY KEY,\n+    username TEXT UNIQUE,\n+    email TEXT\n+);\n+\n+query III\n+INSERT INTO users (id, username, email) VALUES\n+\t(1, 'john_doe', 'john@example.com')\n+ON CONFLICT (username) DO NOTHING\n+RETURNING *;\n+----\n+1\tjohn_doe\tjohn@example.com\n+\n+query III\n+INSERT INTO users (id, username, email) VALUES\n+\t(1, 'john_doe', 'john@example.com')\n+ON CONFLICT (username) DO NOTHING\n+RETURNING *;\n+----\n+\n+# We create a conflict, with a where clause that filters out this conflict\n+# Because the where clause filters it out, the DO UPDATE becomes a DO NOTHING for this row instead\n+# So it does not get added to the returning clause.\n+query III\n+INSERT INTO users (id, username, email)\n+VALUES (1, 'john_doe', 'john_new@example.com')\n+ON CONFLICT (id) DO\n+    UPDATE SET email = EXCLUDED.email\n+    WHERE EXCLUDED.email != 'john_new@example.com'\n+RETURNING *;\n+----\n+\n+# Verify that the *other* tuple does get added to the returning clause\n+query III\n+INSERT INTO users (id, username, email)\n+VALUES\n+\t(1, 'john_doe', 'john_new@example.com'),\n+\t(2, 'not_john_doe', 'not_john_new@example.com')\n+ON CONFLICT (id) DO\n+    UPDATE SET email = EXCLUDED.email\n+    WHERE EXCLUDED.email != 'john_new@example.com'\n+RETURNING *;\n+----\n+2\tnot_john_doe\tnot_john_new@example.com\n+\n+\n+# FIXME: not consistent\n+mode skip\n+\n+# Here we have conflicts within the inserted data\n+# Only the last occurrence of this conflict should be present in the returning clause.\n+query III\n+INSERT INTO users (id, username, email)\n+VALUES\n+\t(3, 'inner_conflict', 'test'),\n+\t(4, 'a', ''),\n+\t(5, 'b', ''),\n+\t(6, 'c', ''),\n+\t(3, 'inner_conflict2', 'other_test'),\n+\t(7, 'd', ''),\n+\t(8, 'e', ''),\n+\t(9, 'f', ''),\n+\t(3, 'inner_conflict3', 'yet_another_test')\n+ON CONFLICT (id) DO\n+    UPDATE SET email = EXCLUDED.email\n+    WHERE EXCLUDED.email != 'test'\n+RETURNING *;\n+----\n+3\tinner_conflict\ttest\n+4\ta\t(empty)\n+5\tb\t(empty)\n+6\tc\t(empty)\n+7\td\t(empty)\n+8\te\t(empty)\n+9\tf\t(empty)\n+3\tinner_conflict3\tyet_another_test\n", "problem_statement": "Surprising upsert with returning and where condition result\n### What happens?\n\nGiven I have a table with a primary key and I perform an upsert with a where condition in the update I would expect rows that don't match the condition not be present in the returned rows, this is not the case.\n\n### To Reproduce\n\n```sql\ncreate table foo(id int primary key, bar text);\ninsert into foo select 1, 'zoo';\ninsert into foo select 1, 'zoo' returning *;\n```\n```\nConstraint Error: Duplicate key \"id: 1\" violates primary key constraint. If this is an unexpected constraint violation please double check with the known index limitations section in our documentation (https://duckdb.org/docs/sql/indexes).\n```\n```sql\ninsert into foo select 1, 'zoo'\non conflict (id) do\n    update set bar = excluded.bar\n    where excluded.bar != 'zoo'\nreturning *;\n```\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  id   \u2502   bar   \u2502\n\u2502 int32 \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502 zoo     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n```sql\ninsert into foo select 1, 'zoom'\non conflict (id) do\n    update set bar = excluded.bar\n    where excluded.bar != 'zoom'\nreturning *;\n```\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  id   \u2502   bar   \u2502\n\u2502 int32 \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502 zoom    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n```sql\ninsert into foo select 1, 'zoom'\non conflict (id) do\n    update set bar = excluded.bar\n    where id != 1\nreturning *;\n```\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  id   \u2502   bar   \u2502\n\u2502 int32 \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502 zoom    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n```sql\nselect * from foo;\n```\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  id   \u2502   bar   \u2502\n\u2502 int32 \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502 zoo     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nSee in the upserts the where condition prevents the update and I would expect it to prevent anything from being returned, the stored data was never changed.\n\nThe documentation only states\n> The RETURNING clause may be used to return the contents of the rows that were inserted\n\nI think it would be fair in an upsert scenario to assume it would \"return the contents of the rows that were upserted\"\n\n### OS:\n\nMacOs 13.6.7 (aarch64)\n\n### DuckDB Version:\n\nv1.1.3\n\n### DuckDB Client:\n\nCLI (mac via homebrew)\n\n### Hardware:\n\nM1, 16Gb ram\n\n### Full Name:\n\nStephen Flavin\n\n### Affiliation:\n\nN/A\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n", "hints_text": "", "created_at": "2025-01-29T09:05:53Z"}
{"repo": "duckdb/duckdb", "pull_number": 15961, "instance_id": "duckdb__duckdb-15961", "issue_numbers": ["15584", "15584"], "base_commit": "612e8ac006668fa29df7edd8b181da6395b6a8d5", "patch": "diff --git a/src/planner/subquery/flatten_dependent_join.cpp b/src/planner/subquery/flatten_dependent_join.cpp\nindex a297a7855dae..bb5db60a98bd 100644\n--- a/src/planner/subquery/flatten_dependent_join.cpp\n+++ b/src/planner/subquery/flatten_dependent_join.cpp\n@@ -401,6 +401,7 @@ unique_ptr<LogicalOperator> FlattenDependentJoins::PushDownDependentJoinInternal\n \t\t\t\t// only right has correlation: push into right\n \t\t\t\tplan->children[1] = PushDownDependentJoinInternal(std::move(plan->children[1]),\n \t\t\t\t                                                  parent_propagate_null_values, lateral_depth);\n+\t\t\t\tdelim_offset += plan->children[0]->GetColumnBindings().size();\n \t\t\t\t// Remove the correlated columns coming from outside for current join node\n \t\t\t\treturn plan;\n \t\t\t}\n@@ -419,6 +420,7 @@ unique_ptr<LogicalOperator> FlattenDependentJoins::PushDownDependentJoinInternal\n \t\t\t\t// only right has correlation: push into right\n \t\t\t\tplan->children[1] = PushDownDependentJoinInternal(std::move(plan->children[1]),\n \t\t\t\t                                                  parent_propagate_null_values, lateral_depth);\n+\t\t\t\tdelim_offset += plan->children[0]->GetColumnBindings().size();\n \t\t\t\treturn plan;\n \t\t\t}\n \t\t} else if (join.join_type == JoinType::MARK) {\n", "test_patch": "diff --git a/test/fuzzer/public/lateral_in_right_side_of_join.test b/test/fuzzer/public/lateral_in_right_side_of_join.test\nnew file mode 100644\nindex 000000000000..aab7706bef98\n--- /dev/null\n+++ b/test/fuzzer/public/lateral_in_right_side_of_join.test\n@@ -0,0 +1,28 @@\n+# name: test/fuzzer/public/lateral_in_right_side_of_join.test\n+# description: Lateral correlation in right side of join\n+# group: [public]\n+\n+statement ok\n+pragma enable_verification\n+\n+statement ok\n+CREATE TABLE t0(c0 INT , c1 VARCHAR);\n+\n+statement ok\n+CREATE TABLE t1( c1 INT);\n+\n+statement ok\n+INSERT INTO t0 VALUES(4, 3);\n+\n+statement ok\n+INSERT INTO t1 VALUES(2);\n+\n+query IIII\n+SELECT * FROM t1, t0 JOIN LATERAL (SELECT t1.c1 AS col0) _subq ON true;\n+----\n+2\t4\t3\t2\n+\n+query IIII\n+SELECT * FROM t1, t0 INNER JOIN (SELECT t1.c1 AS col0) ON true;\n+----\n+2\t4\t3\t2\n", "problem_statement": "INTERNAL Error: Vector::Reference used on vector of different type\n### What happens?\n\nThe below test case triggered an internal error in DuckDB.\n\n### To Reproduce\n\n```sql\r\nCREATE TABLE t0(c0 INT , c1 VARCHAR);\r\nCREATE TABLE t1( c1 INT);\r\nINSERT INTO t0 VALUES(4, 3);\r\nINSERT INTO t1 VALUES(2);\r\n\r\nSELECT * FROM t1, t0 INNER JOIN (SELECT t1.c1 AS col0) ON true;\r\n-- INTERNAL Error:\r\n-- Vector::Reference used on vector of different type\r\n\r\n```\n\n### OS:\n\nUbuntu 22.04\n\n### DuckDB Version:\n\nv1.1.4-dev4060 f99785b78a\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nSuyang Zhong\n\n### Affiliation:\n\nNUS\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a source build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNot applicable - the reproduction does not require a data set\n\n### Did you include all code required to reproduce the issue?\n\n- [X] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [X] Yes, I have\nINTERNAL Error: Vector::Reference used on vector of different type\n### What happens?\n\nThe below test case triggered an internal error in DuckDB.\n\n### To Reproduce\n\n```sql\r\nCREATE TABLE t0(c0 INT , c1 VARCHAR);\r\nCREATE TABLE t1( c1 INT);\r\nINSERT INTO t0 VALUES(4, 3);\r\nINSERT INTO t1 VALUES(2);\r\n\r\nSELECT * FROM t1, t0 INNER JOIN (SELECT t1.c1 AS col0) ON true;\r\n-- INTERNAL Error:\r\n-- Vector::Reference used on vector of different type\r\n\r\n```\n\n### OS:\n\nUbuntu 22.04\n\n### DuckDB Version:\n\nv1.1.4-dev4060 f99785b78a\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nSuyang Zhong\n\n### Affiliation:\n\nNUS\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a source build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNot applicable - the reproduction does not require a data set\n\n### Did you include all code required to reproduce the issue?\n\n- [X] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [X] Yes, I have\n", "hints_text": "\n", "created_at": "2025-01-28T13:05:37Z"}
{"repo": "duckdb/duckdb", "pull_number": 15958, "instance_id": "duckdb__duckdb-15958", "issue_numbers": ["15602"], "base_commit": "837cbce93f4ac1778b26ca0bd23ed2a1d9b7eff7", "patch": "diff --git a/src/optimizer/filter_combiner.cpp b/src/optimizer/filter_combiner.cpp\nindex a72354d7df91..45d7c06a06f2 100644\n--- a/src/optimizer/filter_combiner.cpp\n+++ b/src/optimizer/filter_combiner.cpp\n@@ -78,6 +78,7 @@ FilterResult FilterCombiner::AddConstantComparison(vector<ExpressionValueInforma\n \t\t\treturn FilterResult::SUCCESS;\n \t\tcase ValueComparisonResult::UNSATISFIABLE_CONDITION:\n \t\t\t// combination of filters is unsatisfiable: prune the entire branch\n+\t\t\tinfo_list.push_back(info);\n \t\t\treturn FilterResult::UNSATISFIABLE;\n \t\tdefault:\n \t\t\t// prune nothing, move to the next condition\n@@ -792,11 +793,15 @@ FilterResult FilterCombiner::AddBoundComparisonFilter(Expression &expr) {\n \t\tauto transitive_filter = FindTransitiveFilter(non_scalar);\n \t\tif (transitive_filter != nullptr) {\n \t\t\t// try to add transitive filters\n-\t\t\tif (AddTransitiveFilters(transitive_filter->Cast<BoundComparisonExpression>()) ==\n-\t\t\t    FilterResult::UNSUPPORTED) {\n+\t\t\tauto transitive_result = AddTransitiveFilters(transitive_filter->Cast<BoundComparisonExpression>());\n+\t\t\tif (transitive_result == FilterResult::UNSUPPORTED) {\n \t\t\t\t// in case of unsuccessful re-add filter into remaining ones\n \t\t\t\tremaining_filters.push_back(std::move(transitive_filter));\n \t\t\t}\n+\t\t\tif (transitive_result == FilterResult::UNSATISFIABLE) {\n+\t\t\t\t// in case transitive filter is unsatisfiable - abort filter pushdown\n+\t\t\t\treturn FilterResult::UNSATISFIABLE;\n+\t\t\t}\n \t\t}\n \t\treturn ret;\n \t} else {\n@@ -1067,10 +1072,15 @@ FilterResult FilterCombiner::AddTransitiveFilters(BoundComparisonExpression &com\n \t\t\tif (transitive_filter != nullptr) {\n \t\t\t\t// try to add transitive filters\n \t\t\t\tauto &transitive_cast = transitive_filter->Cast<BoundComparisonExpression>();\n-\t\t\t\tif (AddTransitiveFilters(transitive_cast, false) == FilterResult::UNSUPPORTED) {\n+\t\t\t\tauto transitive_result = AddTransitiveFilters(transitive_cast, false);\n+\t\t\t\tif (transitive_result == FilterResult::UNSUPPORTED) {\n \t\t\t\t\t// in case of unsuccessful re-add filter into remaining ones\n \t\t\t\t\tremaining_filters.push_back(std::move(transitive_filter));\n \t\t\t\t}\n+\t\t\t\tif (transitive_result == FilterResult::UNSATISFIABLE) {\n+\t\t\t\t\t// while adding transitive filters we discovered the filter is unsatisfisable - we can prune\n+\t\t\t\t\treturn FilterResult::UNSATISFIABLE;\n+\t\t\t\t}\n \t\t\t}\n \t\t}\n \t\treturn FilterResult::SUCCESS;\n", "test_patch": "diff --git a/test/fuzzer/public/unsatisfiable_filter_prune.test b/test/fuzzer/public/unsatisfiable_filter_prune.test\nnew file mode 100644\nindex 000000000000..b1f3e1a67f3e\n--- /dev/null\n+++ b/test/fuzzer/public/unsatisfiable_filter_prune.test\n@@ -0,0 +1,20 @@\n+# name: test/fuzzer/public/unsatisfiable_filter_prune.test\n+# description: Test SEMI JOIN with USING clause\n+# group: [public]\n+\n+statement ok\n+pragma enable_verification\n+\n+statement ok\n+CREATE TABLE  t0(c0 INT, c1 INT);\n+\n+statement ok\n+INSERT INTO t0( c0, c1) VALUES ( -1, -1);\n+\n+query I\n+SELECT c0 FROM t0 WHERE (((CASE t0.c0 WHEN t0.c0 THEN t0.c0 END ) BETWEEN 1 AND t0.c0)AND(t0.c0 <= 0)) ;\n+----\n+\n+query II\n+SELECT * FROM t0 WHERE c0 >= 1 AND c0 <= t0.c1 AND t0.c1 <= 0;\n+----\n", "problem_statement": "Unexpected result when using `BETWEEN` and `CASE WHEN`\n### What happens?\n\nConsider the following test case. The second query returned `false`, showing that the expression `(((CASE t0.c0 WHEN t0.c0 THEN t0.c0 END ) BETWEEN 1 AND t0.c0)AND(t0.c0 <= 0))` should be evaluated to `false`; however, the third query return `-1`, which is unexpected.\n\n### To Reproduce\n\n```sql\r\nCREATE TABLE  t0(c0 INT);\r\nINSERT INTO t0( c0) VALUES ( -1);\r\n\r\nSELECT * FROM t0; -- -1\r\nSELECT (((CASE t0.c0 WHEN t0.c0 THEN t0.c0 END ) BETWEEN 1 AND t0.c0)AND(t0.c0 <= 0)) FROM t0; -- false\r\nSELECT * FROM t0 WHERE (((CASE t0.c0 WHEN t0.c0 THEN t0.c0 END ) BETWEEN 1 AND t0.c0)AND(t0.c0 <= 0)) ;\r\n-- Expected: empty table\r\n-- Actual: -1\r\n```\n\n### OS:\n\nUbuntu 22.04\n\n### DuckDB Version:\n\nv1.1.4-dev4108 acdbf60889\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nSuyang Zhong\n\n### Affiliation:\n\nNUS\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a source build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNot applicable - the reproduction does not require a data set\n\n### Did you include all code required to reproduce the issue?\n\n- [X] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [X] Yes, I have\n", "hints_text": "Thanks! Indeed, Postgres returns an empty table:\r\n\r\n```\r\npostgres=# CREATE TABLE  t0(c0 INT);\r\nCREATE TABLE\r\npostgres=# INSERT INTO t0( c0) VALUES ( -1);\r\nINSERT 0 1\r\npostgres=#\r\npostgres=# SELECT * FROM t0; -- -1\r\n c0\r\n----\r\n -1\r\n(1 row)\r\n\r\npostgres=# SELECT (((CASE t0.c0 WHEN t0.c0 THEN t0.c0 END ) BETWEEN 1 AND t0.c0)AND(t0.c0 <= 0)) FROM t0; -- false\r\n ?column?\r\n----------\r\n f\r\n(1 row)\r\n\r\npostgres=# SELECT * FROM t0 WHERE (((CASE t0.c0 WHEN t0.c0 THEN t0.c0 END ) BETWEEN 1 AND t0.c0)AND(t0.c0 <= 0)) ;\r\n c0\r\n----\r\n(0 rows)\r\n```", "created_at": "2025-01-28T11:35:12Z"}
{"repo": "duckdb/duckdb", "pull_number": 15956, "instance_id": "duckdb__duckdb-15956", "issue_numbers": ["15664", "15664"], "base_commit": "837cbce93f4ac1778b26ca0bd23ed2a1d9b7eff7", "patch": "diff --git a/src/parser/transform/expression/transform_columnref.cpp b/src/parser/transform/expression/transform_columnref.cpp\nindex a232219fa14c..dfbbc6f121fc 100644\n--- a/src/parser/transform/expression/transform_columnref.cpp\n+++ b/src/parser/transform/expression/transform_columnref.cpp\n@@ -96,6 +96,7 @@ unique_ptr<ParsedExpression> Transformer::TransformStarExpression(duckdb_libpgqu\n \t\t\tresult->relation_name = child_star.relation_name;\n \t\t\tresult->exclude_list = std::move(child_star.exclude_list);\n \t\t\tresult->replace_list = std::move(child_star.replace_list);\n+\t\t\tresult->rename_list = std::move(child_star.rename_list);\n \t\t\tresult->expr.reset();\n \t\t} else if (result->expr->GetExpressionType() == ExpressionType::LAMBDA) {\n \t\t\tvector<unique_ptr<ParsedExpression>> children;\n", "test_patch": "diff --git a/test/sql/projection/select_star_rename.test b/test/sql/projection/select_star_rename.test\nindex f52f4a9e7b2a..7f3be601c2e0 100644\n--- a/test/sql/projection/select_star_rename.test\n+++ b/test/sql/projection/select_star_rename.test\n@@ -17,6 +17,12 @@ SELECT renamed_col FROM (SELECT * RENAME i AS renamed_col FROM integers)\n ----\n 1\n \n+# rename with COLUMNS\n+query I\n+SELECT renamed_col FROM (SELECT COLUMNS(* RENAME i AS renamed_col) FROM integers)\n+----\n+1\n+\n # qualified\n query I\n SELECT renamed_col FROM (SELECT * RENAME integers.i AS renamed_col FROM integers)\n", "problem_statement": "COLUMNS(* RENAME \"x\" AS \"y\") doesn't work\n### What happens?\r\n\r\n```sql\r\nFROM range(1)\r\nSELECT COLUMNS(* RENAME \"range\" AS \"x\")\r\n```\r\n```\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 range \u2502\r\n\u2502 int64 \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502     0 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n```sql\r\nFROM range(1)\r\nSELECT * RENAME \"range\" AS \"x\"\r\n```\r\n```\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502   x   \u2502\r\n\u2502 int64 \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502     0 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\n### To Reproduce\r\n\r\n.\r\n\r\n### OS:\r\n\r\nLinux\r\n\r\n### DuckDB Version:\r\n\r\n'1.1.4-dev3961' (what `pip install --upgrade --pre` gives me )\r\n\r\n### DuckDB Client:\r\n\r\nPython\r\n\r\n### Hardware:\r\n\r\n.\r\n\r\n### Full Name:\r\n\r\nSoeren Wolfers\r\n\r\n### Affiliation:\r\n\r\nG-Research\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a nightly build\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nNot applicable - the reproduction does not require a data set\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\nCOLUMNS(* RENAME \"x\" AS \"y\") doesn't work\n### What happens?\r\n\r\n```sql\r\nFROM range(1)\r\nSELECT COLUMNS(* RENAME \"range\" AS \"x\")\r\n```\r\n```\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 range \u2502\r\n\u2502 int64 \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502     0 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n```sql\r\nFROM range(1)\r\nSELECT * RENAME \"range\" AS \"x\"\r\n```\r\n```\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502   x   \u2502\r\n\u2502 int64 \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502     0 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\n### To Reproduce\r\n\r\n.\r\n\r\n### OS:\r\n\r\nLinux\r\n\r\n### DuckDB Version:\r\n\r\n'1.1.4-dev3961' (what `pip install --upgrade --pre` gives me )\r\n\r\n### DuckDB Client:\r\n\r\nPython\r\n\r\n### Hardware:\r\n\r\n.\r\n\r\n### Full Name:\r\n\r\nSoeren Wolfers\r\n\r\n### Affiliation:\r\n\r\nG-Research\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a nightly build\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nNot applicable - the reproduction does not require a data set\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\n", "hints_text": "\n", "created_at": "2025-01-28T10:34:56Z"}
{"repo": "duckdb/duckdb", "pull_number": 15881, "instance_id": "duckdb__duckdb-15881", "issue_numbers": ["15316"], "base_commit": "ba8eaca942c94550cf999e4f44208977401f0a7f", "patch": "diff --git a/src/optimizer/pushdown/pushdown_left_join.cpp b/src/optimizer/pushdown/pushdown_left_join.cpp\nindex 814adadc040d..8ac7d3e8472c 100644\n--- a/src/optimizer/pushdown/pushdown_left_join.cpp\n+++ b/src/optimizer/pushdown/pushdown_left_join.cpp\n@@ -1,12 +1,28 @@\n+#include \"duckdb/common/assert.hpp\"\n+#include \"duckdb/common/enums/join_type.hpp\"\n+#include \"duckdb/common/helper.hpp\"\n+#include \"duckdb/common/typedefs.hpp\"\n+#include \"duckdb/common/types.hpp\"\n+#include \"duckdb/common/types/value.hpp\"\n+#include \"duckdb/common/unique_ptr.hpp\"\n+#include \"duckdb/common/unordered_map.hpp\"\n #include \"duckdb/execution/expression_executor.hpp\"\n #include \"duckdb/optimizer/filter_pushdown.hpp\"\n #include \"duckdb/optimizer/optimizer.hpp\"\n+#include \"duckdb/planner/binder.hpp\"\n+#include \"duckdb/planner/column_binding.hpp\"\n #include \"duckdb/planner/expression/bound_columnref_expression.hpp\"\n #include \"duckdb/planner/expression/bound_comparison_expression.hpp\"\n #include \"duckdb/planner/expression/bound_constant_expression.hpp\"\n #include \"duckdb/planner/expression_iterator.hpp\"\n+#include \"duckdb/planner/logical_operator.hpp\"\n+#include \"duckdb/planner/operator/logical_any_join.hpp\"\n #include \"duckdb/planner/operator/logical_comparison_join.hpp\"\n+#include \"duckdb/planner/operator/logical_cross_product.hpp\"\n+#include \"duckdb/planner/operator/logical_dummy_scan.hpp\"\n #include \"duckdb/planner/operator/logical_filter.hpp\"\n+#include \"duckdb/planner/operator/logical_projection.hpp\"\n+#include <utility>\n \n namespace duckdb {\n \n@@ -126,7 +142,49 @@ unique_ptr<LogicalOperator> FilterPushdown::PushdownLeftJoin(unique_ptr<LogicalO\n \t});\n \tright_pushdown.GenerateFilters();\n \top->children[0] = left_pushdown.Rewrite(std::move(op->children[0]));\n-\top->children[1] = right_pushdown.Rewrite(std::move(op->children[1]));\n+\n+\tbool rewrite_right = true;\n+\tif (op->type == LogicalOperatorType::LOGICAL_ANY_JOIN) {\n+\t\tauto &any_join = join.Cast<LogicalAnyJoin>();\n+\t\tif (AddFilter(any_join.condition->Copy()) == FilterResult::UNSATISFIABLE) {\n+\t\t\t// filter statically evaluates to false, turns it to the cross product join with 1 row NULLs\n+\t\t\tif (any_join.join_type == JoinType::LEFT) {\n+\t\t\t\tunordered_map<idx_t, vector<unique_ptr<Expression>>> projections_groups;\n+\t\t\t\tauto column_bindings = op->children[1]->GetColumnBindings();\n+\t\t\t\top->children[1]->ResolveOperatorTypes();\n+\t\t\t\tauto &types = op->children[1]->types;\n+\t\t\t\tfor (idx_t i = 0; i < column_bindings.size(); i++) {\n+\t\t\t\t\tprojections_groups[column_bindings[i].table_index].emplace_back(\n+\t\t\t\t\t    make_uniq<BoundConstantExpression>(Value(types[i])));\n+\t\t\t\t}\n+\n+\t\t\t\tauto create_proj_dummy_scan = [&](idx_t table_index) {\n+\t\t\t\t\tauto dummy_scan = make_uniq<LogicalDummyScan>(optimizer.binder.GenerateTableIndex());\n+\t\t\t\t\tauto proj = make_uniq<LogicalProjection>(table_index, std::move(projections_groups[table_index]));\n+\t\t\t\t\tproj->AddChild(std::move(dummy_scan));\n+\t\t\t\t\treturn proj;\n+\t\t\t\t};\n+\t\t\t\t// make cross products on the RHS first\n+\t\t\t\tauto begin = projections_groups.begin();\n+\t\t\t\tD_ASSERT(begin != projections_groups.end());\n+\t\t\t\tunique_ptr<LogicalOperator> left = create_proj_dummy_scan(begin->first);\n+\t\t\t\tprojections_groups.erase(begin);\n+\t\t\t\tfor (auto &group : projections_groups) {\n+\t\t\t\t\tauto proj = create_proj_dummy_scan(group.first);\n+\t\t\t\t\tauto op = LogicalCrossProduct::Create(std::move(left), std::move(proj));\n+\t\t\t\t\tleft = std::move(op);\n+\t\t\t\t}\n+\t\t\t\t// then make cross product with the LHS\n+\t\t\t\top = LogicalCrossProduct::Create(std::move(op->children[0]), std::move(left));\n+\t\t\t\trewrite_right = false;\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tif (rewrite_right) {\n+\t\top->children[1] = right_pushdown.Rewrite(std::move(op->children[1]));\n+\t}\n+\n \treturn PushFinalFilters(std::move(op));\n }\n \n", "test_patch": "diff --git a/test/optimizer/statistics/statistics_is_null.test b/test/optimizer/statistics/statistics_is_null.test\nindex 5fce1b6b603b..0c77dce732f4 100644\n--- a/test/optimizer/statistics/statistics_is_null.test\n+++ b/test/optimizer/statistics/statistics_is_null.test\n@@ -45,12 +45,14 @@ EXPLAIN SELECT i IS NULL FROM integers2 WHERE i>0;\n ----\n logical_opt\t<!REGEX>:.*IS NULL.*\n \n-# left/right/full outer joins can introduce nulls, even if the base tables do not contain them\n+# left/right outer joins with false condition can convert to cross product with constant NULL value, \n+# so we don't need to check IS NULL here, since it's always NULL\n query II\n EXPLAIN SELECT i2.i IS NULL FROM integers i1 LEFT JOIN integers i2 ON (false);\n ----\n-logical_opt\t<REGEX>:.*IS NULL.*\n+logical_opt\t<!REGEX>:.*IS NULL.*\n \n+# full outer joins can introduce nulls, even if the base tables do not contain them\n query II\n EXPLAIN SELECT i1.i IS NULL FROM integers i1 FULL OUTER JOIN integers i2 ON (false);\n ----\ndiff --git a/test/sql/join/left_outer/left_join_issue_15316.test b/test/sql/join/left_outer/left_join_issue_15316.test\nnew file mode 100644\nindex 000000000000..2f63a9b99b9a\n--- /dev/null\n+++ b/test/sql/join/left_outer/left_join_issue_15316.test\n@@ -0,0 +1,53 @@\n+# name: test/sql/join/left_outer/left_join_issue_15316.test\n+# description: Issue #15316: Left join should strip tree if filter statically evaluates to false\n+# group: [left_outer]\n+\n+statement ok\n+set explain_output='optimized_only';\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+CREATE OR REPLACE TABLE big_table AS\n+SELECT i.range AS col1,\n+       CAST(random() * 1000 AS INTEGER) AS col2\n+FROM range(100) i;\n+\n+statement ok\n+CREATE OR REPLACE TABLE single_col_table AS\n+SELECT i.range AS col1\n+FROM range(50) i;\n+\n+query II\n+explain SELECT * \n+FROM big_table c\n+LEFT OUTER JOIN single_col_table hd ON hd.col1=c.col1 \n+AND (\n+    FALSE\n+);\n+----\n+logical_opt\t<REGEX>:.*CROSS_PRODUCT.*\n+\n+# RHS contains multiple tables\n+statement ok\n+CREATE TABLE integers1 AS SELECT * FROM (VALUES (1), (2), (3)) tbl(i);\n+\n+statement ok\n+CREATE TABLE integers2 AS SELECT * FROM (VALUES (1, '1'), (2, '2'), (3, '3')) tbl(i, s);\n+\n+statement ok\n+CREATE TABLE integers3 AS SELECT * FROM (VALUES (1, '4'), (2, '5'), (3, '6')) tbl(i, s);\n+\n+query III\n+SELECT\n+    i1.i AS i1_i,\n+    i2.s,\n+    i3.i AS i3_i\n+FROM\n+    integers1 i1\n+LEFT OUTER JOIN (integers2 i2 LEFT OUTER JOIN integers3 i3 ON i2.i = i3.i) on false;\n+----\n+1\tNULL\tNULL\n+2\tNULL\tNULL\n+3\tNULL\tNULL\n", "problem_statement": "Literal 'FALSE' much slower than false condition that triggers predicate pushdown\n### What happens?\r\n\r\nWhen querying against parquet files, I am using a JOIN condition that should return no rows. Joining on FALSE is far slower than joining on a FALSE-yielding statement that references a column available in the parquet files.\r\n\r\n## Example\r\nIn this example, `single_col_table.parquet` col1 is never < 0.\r\n\r\nSlow:\r\n```sql\r\nSELECT * \r\nFROM big_table.parquet c\r\nLEFT OUTER JOIN single_col_table.parquet hd ON hd.col1=c.col1 \r\nAND (\r\n    FALSE\r\n)\r\n\r\n```\r\n\r\nFast:\r\n```sql\r\nSELECT * \r\nFROM big_table.parquet c\r\nLEFT OUTER JOIN single_col_table.parquet hd ON hd.col1=c.col1 \r\nAND (\r\n    hd.col1 = -1\r\n)\r\n```\r\n\r\n### To Reproduce\r\n\r\n## Generate the tables\r\n\r\n`generate.sql`:\r\n```sql\r\n\r\n-- Create a large table with two columns\r\nCREATE OR REPLACE TABLE big_table AS\r\nSELECT i.range AS col1,\r\n       CAST(random() * 1000000 AS INTEGER) AS col2\r\nFROM range(1_000_000) i;\r\n\r\n-- Create another large table with one column\r\nCREATE OR REPLACE TABLE single_col_table AS\r\nSELECT i.range AS col1\r\nFROM range(500_000) i;\r\n\r\nCOPY big_table TO 'big_table.parquet' (FORMAT 'parquet');\r\nCOPY single_col_table TO 'single_col_table.parquet' (FORMAT 'parquet');\r\n\r\n```\r\n\r\n```sh\r\n\r\nduckdb < generate.sql\r\n\r\n```\r\n\r\n## Run the fast query\r\nIt executes quickly.\r\n\r\n`query_fast.sql`:\r\n```sql\r\nSELECT * \r\nFROM big_table.parquet c\r\nLEFT OUTER JOIN single_col_table.parquet hd ON hd.col1=c.col1 \r\nAND (\r\n    hd.col1 = -1\r\n);\r\n```\r\n\r\n```sh\r\nduckdb < query_fast.sql\r\n```\r\n\r\n## Run the slow query\r\nIt takes a long time.\r\n\r\n`query_slow.sql`:\r\n```sql\r\nSELECT * \r\nFROM big_table.parquet c\r\nLEFT OUTER JOIN single_col_table.parquet hd ON hd.col1=c.col1 \r\nAND (\r\n    FALSE\r\n);\r\n```\r\n\r\n```sh\r\nduckdb < query_slow.sql\r\n```\r\n\r\n## Notes\r\n* This has an easy workaround, documented in the \"fast\" query, so I am not requesting any support, but raising this in case it's of interest.\r\n* If the `slow` query runs too quickly for you, just increase the number of records in the `generate` step.\r\n\r\n### OS:\r\n\r\nmacOS Ventura (13.6.9)\r\n\r\n### DuckDB Version:\r\n\r\nv1.1.3\r\n\r\n### DuckDB Client:\r\n\r\nduckdb cli (it also repros with github.com/marcboeker/go-duckdb )\r\n\r\n### Hardware:\r\n\r\nrepros on mac ARM and linux x86\r\n\r\n### Full Name:\r\n\r\nJames Pirruccello\r\n\r\n### Affiliation:\r\n\r\nCarbocation Corporation\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\n", "hints_text": "This is surely very interesting, thanks. We'll take a look.\nHi, I'm external and I would like to try myself on this issue. I have read the contributing.md. Can I go ahead and try to solve it? Here are my insights so far:\r\n\"I am using a JOIN condition that should return no rows\" - actually, since you are using a left outer join, the query should return as many rows as the lhs table has. It's a common misconception that the join condition behaves like a where-clause. What really happens is that the join condition determines whether the rows match and where they don't match, the columns of the rhs table are set to null.\r\nNevertheless, the query with a constant false join condition should still trigger predicate pushdown, but it doesn't:\r\n\r\noptimized logical plan for the fast query:\r\n![fast](https://github.com/user-attachments/assets/2bcaef8f-3658-4b21-9b5b-6a4afd32271b)\r\n\r\noptimized logical plan for the slow query:\r\n![slow](https://github.com/user-attachments/assets/839fe9d1-df22-4a23-8e1c-c31537e5d271)\r\n\r\nNotice, how the slow query scans the rhs table, whereas the fast query doesn't and simply fills up the columns with null values.", "created_at": "2025-01-24T08:14:13Z"}
{"repo": "duckdb/duckdb", "pull_number": 15851, "instance_id": "duckdb__duckdb-15851", "issue_numbers": ["15570", "15760"], "base_commit": "8e68a3e34aa526a342ae91e1b14b764bb3075a12", "patch": "diff --git a/.github/config/out_of_tree_extensions.cmake b/.github/config/out_of_tree_extensions.cmake\nindex c02455026c25..2224acfd97a0 100644\n--- a/.github/config/out_of_tree_extensions.cmake\n+++ b/.github/config/out_of_tree_extensions.cmake\n@@ -56,10 +56,8 @@ endif()\n # for Delta\n if (NOT MINGW AND NOT \"${OS_NAME}\" STREQUAL \"linux\" AND NOT ${WASM_ENABLED})\n     duckdb_extension_load(delta\n-            LOAD_TESTS\n             GIT_URL https://github.com/duckdb/duckdb-delta\n-            GIT_TAG b7333c0143e101c720117d564651e693b317bb31\n-            APPLY_PATCHES\n+            GIT_TAG 846019edcc27000721ff9c4281e85a63d1aa10de\n     )\n endif()\n \n@@ -91,10 +89,9 @@ endif()\n duckdb_extension_load(inet\n     LOAD_TESTS\n     GIT_URL https://github.com/duckdb/duckdb-inet\n-    GIT_TAG 51d7ad789f34eecb36a2071bac5aef0e12747d70\n+    GIT_TAG a8b361ab5d43f6390d7cb48c9a9f0638e9581cf9\n     INCLUDE_DIR src/include\n     TEST_DIR test/sql\n-    APPLY_PATCHES\n     )\n \n ################# POSTGRES_SCANNER\ndiff --git a/.github/patches/extensions/delta/fixes.patch b/.github/patches/extensions/delta/fixes.patch\ndeleted file mode 100644\nindex 28b142ffd8b1..000000000000\n--- a/.github/patches/extensions/delta/fixes.patch\n+++ /dev/null\n@@ -1,142 +0,0 @@\n-diff --git a/src/functions/delta_scan.cpp b/src/functions/delta_scan.cpp\n-index 65eb34f..7210382 100644\n---- a/src/functions/delta_scan.cpp\n-+++ b/src/functions/delta_scan.cpp\n-@@ -464,7 +464,11 @@ unique_ptr<MultiFileList> DeltaSnapshot::ComplexFilterPushdown(ClientContext &co\n-     for (const auto &filter : filters) {\n-         combiner.AddFilter(filter->Copy());\n-     }\n--    auto filterstmp = combiner.GenerateTableScanFilters(info.column_ids);\n-+    vector<ColumnIndex> column_indexes;\n-+    for(auto column_id : info.column_ids) {\n-+    \tcolumn_indexes.emplace_back(column_id);\n-+    }\n-+    auto filterstmp = combiner.GenerateTableScanFilters(column_indexes);\n- \n-     // TODO: can/should we figure out if this filtered anything?\n-     auto filtered_list = make_uniq<DeltaSnapshot>(context, paths[0]);\n-@@ -529,7 +533,7 @@ unique_ptr<NodeStatistics> DeltaSnapshot::GetCardinality(ClientContext &context)\n-     return nullptr;\n- }\n- \n--unique_ptr<MultiFileReader> DeltaMultiFileReader::CreateInstance() {\n-+unique_ptr<MultiFileReader> DeltaMultiFileReader::CreateInstance(const TableFunction &table_function) {\n-     return std::move(make_uniq<DeltaMultiFileReader>());\n- }\n- \n-@@ -575,7 +579,7 @@ void DeltaMultiFileReader::BindOptions(MultiFileReaderOptions &options, MultiFil\n- void DeltaMultiFileReader::FinalizeBind(const MultiFileReaderOptions &file_options, const MultiFileReaderBindData &options,\n-                   const string &filename, const vector<string> &local_names,\n-                   const vector<LogicalType> &global_types, const vector<string> &global_names,\n--                  const vector<column_t> &global_column_ids, MultiFileReaderData &reader_data,\n-+                  const vector<ColumnIndex> &global_column_ids, MultiFileReaderData &reader_data,\n-                   ClientContext &context, optional_ptr<MultiFileReaderGlobalState> global_state) {\n-     MultiFileReader::FinalizeBind(file_options, options, filename, local_names, global_types, global_names, global_column_ids, reader_data, context, global_state);\n- \n-@@ -600,7 +604,7 @@ void DeltaMultiFileReader::FinalizeBind(const MultiFileReaderOptions &file_optio\n- \n-     if (!file_metadata->partition_map.empty()) {\n-         for (idx_t i = 0; i < global_column_ids.size(); i++) {\n--            column_t col_id = global_column_ids[i];\n-+            column_t col_id = global_column_ids[i].GetPrimaryIndex();\n-             if (IsRowIdColumnId(col_id)) {\n-                 continue;\n-             }\n-@@ -618,12 +622,12 @@ void DeltaMultiFileReader::FinalizeBind(const MultiFileReaderOptions &file_optio\n-     }\n- }\n- \n--unique_ptr<MultiFileList> DeltaMultiFileReader::CreateFileList(ClientContext &context, const vector<string>& paths, FileGlobOptions options) {\n-+shared_ptr<MultiFileList> DeltaMultiFileReader::CreateFileList(ClientContext &context, const vector<string>& paths, FileGlobOptions options) {\n-     if (paths.size() != 1) {\n-         throw BinderException(\"'delta_scan' only supports single path as input\");\n-     }\n- \n--    return make_uniq<DeltaSnapshot>(context, paths[0]);\n-+    return make_shared_ptr<DeltaSnapshot>(context, paths[0]);\n- }\n- \n- // Generate the correct Selection Vector Based on the Raw delta KernelBoolSlice dv and the row_id_column\n-@@ -670,14 +674,14 @@ unique_ptr<MultiFileReaderGlobalState> DeltaMultiFileReader::InitializeGlobalSta\n-                                                                                    const duckdb::MultiFileList &file_list,\n-                                                                                    const vector<duckdb::LogicalType> &global_types,\n-                                                                                    const vector<std::string> &global_names,\n--                                                                                   const vector<duckdb::column_t> &global_column_ids) {\n-+                                                                                   const vector<duckdb::ColumnIndex> &global_column_ids) {\n-     vector<LogicalType> extra_columns;\n-     vector<pair<string, idx_t>> mapped_columns;\n- \n-     // Create a map of the columns that are in the projection\n-     case_insensitive_map_t<idx_t> selected_columns;\n-     for (idx_t i = 0; i < global_column_ids.size(); i++) {\n--        auto global_id = global_column_ids[i];\n-+        auto global_id = global_column_ids[i].GetPrimaryIndex();\n-         if (IsRowIdColumnId(global_id)) {\n-             continue;\n-         }\n-@@ -736,7 +740,7 @@ unique_ptr<MultiFileReaderGlobalState> DeltaMultiFileReader::InitializeGlobalSta\n- // in the parquet files, we just add null constant columns\n- static void CustomMulfiFileNameMapping(const string &file_name, const vector<LogicalType> &local_types,\n-                                         const vector<string> &local_names, const vector<LogicalType> &global_types,\n--                                        const vector<string> &global_names, const vector<column_t> &global_column_ids,\n-+                                        const vector<string> &global_names, const vector<ColumnIndex> &global_column_ids,\n-                                         MultiFileReaderData &reader_data, const string &initial_file,\n-                                         optional_ptr<MultiFileReaderGlobalState> global_state) {\n-     D_ASSERT(global_types.size() == global_names.size());\n-@@ -760,7 +764,7 @@ static void CustomMulfiFileNameMapping(const string &file_name, const vector<Log\n- \t\t\tcontinue;\n- \t\t}\n- \t\t// not constant - look up the column in the name map\n--\t\tauto global_id = global_column_ids[i];\n-+\t\tauto global_id = global_column_ids[i].GetPrimaryIndex();\n- \t\tif (global_id >= global_types.size()) {\n- \t\t\tthrow InternalException(\n- \t\t\t    \"MultiFileReader::CreatePositionalMapping - global_id is out of range in global_types for this file\");\n-@@ -800,7 +804,7 @@ static void CustomMulfiFileNameMapping(const string &file_name, const vector<Log\n- \n- void DeltaMultiFileReader::CreateNameMapping(const string &file_name, const vector<LogicalType> &local_types,\n-                                         const vector<string> &local_names, const vector<LogicalType> &global_types,\n--                                        const vector<string> &global_names, const vector<column_t> &global_column_ids,\n-+                                        const vector<string> &global_names, const vector<ColumnIndex> &global_column_ids,\n-                                         MultiFileReaderData &reader_data, const string &initial_file,\n-                                         optional_ptr<MultiFileReaderGlobalState> global_state) {\n-     // First call the base implementation to do most mapping\n-diff --git a/src/include/functions/delta_scan.hpp b/src/include/functions/delta_scan.hpp\n-index aac35cc..d90968b 100644\n---- a/src/include/functions/delta_scan.hpp\n-+++ b/src/include/functions/delta_scan.hpp\n-@@ -103,9 +103,9 @@ struct DeltaMultiFileReaderGlobalState : public MultiFileReaderGlobalState {\n- };\n- \n- struct DeltaMultiFileReader : public MultiFileReader {\n--    static unique_ptr<MultiFileReader> CreateInstance();\n-+    static unique_ptr<MultiFileReader> CreateInstance(const TableFunction &table_function);\n-     //! Return a DeltaSnapshot\n--    unique_ptr<MultiFileList> CreateFileList(ClientContext &context, const vector<string> &paths,\n-+    shared_ptr<MultiFileList> CreateFileList(ClientContext &context, const vector<string> &paths,\n-                    FileGlobOptions options) override;\n- \n-     //! Override the regular parquet bind using the MultiFileReader Bind. The bind from these are what DuckDB's file\n-@@ -119,19 +119,19 @@ struct DeltaMultiFileReader : public MultiFileReader {\n- \n-     void CreateNameMapping(const string &file_name, const vector<LogicalType> &local_types,\n-                       const vector<string> &local_names, const vector<LogicalType> &global_types,\n--                      const vector<string> &global_names, const vector<column_t> &global_column_ids,\n-+                      const vector<string> &global_names, const vector<ColumnIndex> &global_column_ids,\n-                       MultiFileReaderData &reader_data, const string &initial_file,\n-                       optional_ptr<MultiFileReaderGlobalState> global_state) override;\n- \n-     unique_ptr<MultiFileReaderGlobalState> InitializeGlobalState(ClientContext &context, const MultiFileReaderOptions &file_options,\n-                           const MultiFileReaderBindData &bind_data, const MultiFileList &file_list,\n-                           const vector<LogicalType> &global_types, const vector<string> &global_names,\n--                          const vector<column_t> &global_column_ids) override;\n-+                          const vector<ColumnIndex> &global_column_ids) override;\n- \n-     void FinalizeBind(const MultiFileReaderOptions &file_options, const MultiFileReaderBindData &options,\n-                                        const string &filename, const vector<string> &local_names,\n-                                        const vector<LogicalType> &global_types, const vector<string> &global_names,\n--                                       const vector<column_t> &global_column_ids, MultiFileReaderData &reader_data,\n-+                                       const vector<ColumnIndex> &global_column_ids, MultiFileReaderData &reader_data,\n-                                        ClientContext &context, optional_ptr<MultiFileReaderGlobalState> global_state) override;\n- \n-     //! Override the FinalizeChunk method\ndiff --git a/.github/patches/extensions/delta/multi_file_reader_column_definition.patch b/.github/patches/extensions/delta/multi_file_reader_column_definition.patch\ndeleted file mode 100644\nindex 81855d22e231..000000000000\n--- a/.github/patches/extensions/delta/multi_file_reader_column_definition.patch\n+++ /dev/null\n@@ -1,207 +0,0 @@\n-diff --git a/src/functions/delta_scan.cpp b/src/functions/delta_scan.cpp\n-index 7210382..6eaf0b9 100644\n---- a/src/functions/delta_scan.cpp\n-+++ b/src/functions/delta_scan.cpp\n-@@ -576,12 +576,13 @@ void DeltaMultiFileReader::BindOptions(MultiFileReaderOptions &options, MultiFil\n-     }\n- }\n- \n--void DeltaMultiFileReader::FinalizeBind(const MultiFileReaderOptions &file_options, const MultiFileReaderBindData &options,\n--                  const string &filename, const vector<string> &local_names,\n--                  const vector<LogicalType> &global_types, const vector<string> &global_names,\n--                  const vector<ColumnIndex> &global_column_ids, MultiFileReaderData &reader_data,\n--                  ClientContext &context, optional_ptr<MultiFileReaderGlobalState> global_state) {\n--    MultiFileReader::FinalizeBind(file_options, options, filename, local_names, global_types, global_names, global_column_ids, reader_data, context, global_state);\n-+void DeltaMultiFileReader::FinalizeBind(const MultiFileReaderOptions &file_options,\n-+\t                                     const MultiFileReaderBindData &options, const string &filename,\n-+\t                                     const vector<MultiFileReaderColumnDefinition> &local_columns,\n-+\t                                     const vector<MultiFileReaderColumnDefinition> &global_columns,\n-+\t                                     const vector<ColumnIndex> &global_column_ids, MultiFileReaderData &reader_data,\n-+\t                                     ClientContext &context, optional_ptr<MultiFileReaderGlobalState> global_state) {\n-+    MultiFileReader::FinalizeBind(file_options, options, filename, local_columns, global_columns, global_column_ids, reader_data, context, global_state);\n- \n-     // Handle custom delta option set in MultiFileReaderOptions::custom_options\n-     auto file_number_opt = file_options.custom_options.find(\"delta_file_number\");\n-@@ -608,9 +609,9 @@ void DeltaMultiFileReader::FinalizeBind(const MultiFileReaderOptions &file_optio\n-             if (IsRowIdColumnId(col_id)) {\n-                 continue;\n-             }\n--            auto col_partition_entry = file_metadata->partition_map.find(global_names[col_id]);\n-+            auto col_partition_entry = file_metadata->partition_map.find(global_columns[col_id].name);\n-             if (col_partition_entry != file_metadata->partition_map.end()) {\n--                auto &current_type = global_types[col_id];\n-+                auto &current_type = global_columns[col_id].type;\n-                 if (current_type == LogicalType::BLOB) {\n-                     reader_data.constant_map.emplace_back(i, Value::BLOB_RAW(col_partition_entry->second));\n-                 } else {\n-@@ -668,13 +669,10 @@ void DeltaMultiFileReaderGlobalState::SetColumnIdx(const string &column, idx_t i\n-     throw IOException(\"Unknown column '%s' found as required by the DeltaMultiFileReader\");\n- }\n- \n--unique_ptr<MultiFileReaderGlobalState> DeltaMultiFileReader::InitializeGlobalState(duckdb::ClientContext &context,\n--                                                                                   const duckdb::MultiFileReaderOptions &file_options,\n--                                                                                   const duckdb::MultiFileReaderBindData &bind_data,\n--                                                                                   const duckdb::MultiFileList &file_list,\n--                                                                                   const vector<duckdb::LogicalType> &global_types,\n--                                                                                   const vector<std::string> &global_names,\n--                                                                                   const vector<duckdb::ColumnIndex> &global_column_ids) {\n-+unique_ptr<MultiFileReaderGlobalState> DeltaMultiFileReader::InitializeGlobalState(ClientContext &context, const MultiFileReaderOptions &file_options,\n-+\t                      const MultiFileReaderBindData &bind_data, const MultiFileList &file_list,\n-+\t                      const vector<MultiFileReaderColumnDefinition> &global_columns,\n-+\t                      const vector<ColumnIndex> &global_column_ids) {\n-     vector<LogicalType> extra_columns;\n-     vector<pair<string, idx_t>> mapped_columns;\n- \n-@@ -686,7 +684,7 @@ unique_ptr<MultiFileReaderGlobalState> DeltaMultiFileReader::InitializeGlobalSta\n-             continue;\n-         }\n- \n--        auto &global_name = global_names[global_id];\n-+        auto &global_name = global_columns[global_id].name;\n-         selected_columns.insert({global_name, i});\n-     }\n- \n-@@ -738,17 +736,16 @@ unique_ptr<MultiFileReaderGlobalState> DeltaMultiFileReader::InitializeGlobalSta\n- \n- // This code is duplicated from MultiFileReader::CreateNameMapping the difference is that for columns that are not found\n- // in the parquet files, we just add null constant columns\n--static void CustomMulfiFileNameMapping(const string &file_name, const vector<LogicalType> &local_types,\n--                                        const vector<string> &local_names, const vector<LogicalType> &global_types,\n--                                        const vector<string> &global_names, const vector<ColumnIndex> &global_column_ids,\n--                                        MultiFileReaderData &reader_data, const string &initial_file,\n--                                        optional_ptr<MultiFileReaderGlobalState> global_state) {\n--    D_ASSERT(global_types.size() == global_names.size());\n--\tD_ASSERT(local_types.size() == local_names.size());\n-+static void CustomMulfiFileNameMapping(const string &file_name,\n-+\t                                 const vector<MultiFileReaderColumnDefinition> &local_columns,\n-+\t                                 const vector<MultiFileReaderColumnDefinition> &global_columns,\n-+\t                                 const vector<ColumnIndex> &global_column_ids, MultiFileReaderData &reader_data,\n-+\t                                 const string &initial_file,\n-+\t                                 optional_ptr<MultiFileReaderGlobalState> global_state) {\n- \t// we have expected types: create a map of name -> column index\n- \tcase_insensitive_map_t<idx_t> name_map;\n--\tfor (idx_t col_idx = 0; col_idx < local_names.size(); col_idx++) {\n--\t\tname_map[local_names[col_idx]] = col_idx;\n-+\tfor (idx_t col_idx = 0; col_idx < local_columns.size(); col_idx++) {\n-+\t\tname_map[local_columns[col_idx].name] = col_idx;\n- \t}\n- \tfor (idx_t i = 0; i < global_column_ids.size(); i++) {\n- \t\t// check if this is a constant column\n-@@ -765,32 +762,32 @@ static void CustomMulfiFileNameMapping(const string &file_name, const vector<Log\n- \t\t}\n- \t\t// not constant - look up the column in the name map\n- \t\tauto global_id = global_column_ids[i].GetPrimaryIndex();\n--\t\tif (global_id >= global_types.size()) {\n-+\t\tif (global_id >= global_columns.size()) {\n- \t\t\tthrow InternalException(\n--\t\t\t    \"MultiFileReader::CreatePositionalMapping - global_id is out of range in global_types for this file\");\n-+\t\t\t    \"MultiFileReader::CreatePositionalMapping - global_id is out of range in global_columns for this file\");\n- \t\t}\n--\t\tauto &global_name = global_names[global_id];\n-+\t\tauto &global_name = global_columns[global_id].name;\n- \t\tauto entry = name_map.find(global_name);\n- \t\tif (entry == name_map.end()) {\n- \t\t\tstring candidate_names;\n--\t\t\tfor (auto &local_name : local_names) {\n-+\t\t\tfor (auto &column : local_columns) {\n- \t\t\t\tif (!candidate_names.empty()) {\n- \t\t\t\t\tcandidate_names += \", \";\n- \t\t\t\t}\n--\t\t\t\tcandidate_names += local_name;\n-+\t\t\t\tcandidate_names += column.name;\n- \t\t\t}\n- \t\t\t// FIXME: this override is pretty hacky: for missing columns we just insert NULL constants\n--\t\t    auto &global_type = global_types[global_id];\n-+\t\t    auto &global_type = global_columns[global_id].type;\n- \t\t    Value val (global_type);\n- \t\t    reader_data.constant_map.push_back({i, val});\n- \t\t    continue;\n- \t\t}\n- \t\t// we found the column in the local file - check if the types are the same\n- \t\tauto local_id = entry->second;\n--\t\tD_ASSERT(global_id < global_types.size());\n--\t\tD_ASSERT(local_id < local_types.size());\n--\t\tauto &global_type = global_types[global_id];\n--\t\tauto &local_type = local_types[local_id];\n-+\t\tD_ASSERT(global_id < global_columns.size());\n-+\t\tD_ASSERT(local_id < local_columns.size());\n-+\t\tauto &global_type = global_columns[global_id].type;\n-+\t\tauto &local_type = local_columns[local_id].type;\n- \t\tif (global_type != local_type) {\n- \t\t\treader_data.cast_map[local_id] = global_type;\n- \t\t}\n-@@ -802,13 +799,14 @@ static void CustomMulfiFileNameMapping(const string &file_name, const vector<Log\n- \treader_data.empty_columns = reader_data.column_ids.empty();\n- }\n- \n--void DeltaMultiFileReader::CreateNameMapping(const string &file_name, const vector<LogicalType> &local_types,\n--                                        const vector<string> &local_names, const vector<LogicalType> &global_types,\n--                                        const vector<string> &global_names, const vector<ColumnIndex> &global_column_ids,\n--                                        MultiFileReaderData &reader_data, const string &initial_file,\n--                                        optional_ptr<MultiFileReaderGlobalState> global_state) {\n-+void DeltaMultiFileReader::CreateColumnMapping(const string &file_name,\n-+\t                                 const vector<MultiFileReaderColumnDefinition> &local_columns,\n-+\t                                 const vector<MultiFileReaderColumnDefinition> &global_columns,\n-+\t                                 const vector<ColumnIndex> &global_column_ids, MultiFileReaderData &reader_data,\n-+\t                                 const MultiFileReaderBindData &bind_data, const string &initial_file,\n-+\t                                 optional_ptr<MultiFileReaderGlobalState> global_state) {\n-     // First call the base implementation to do most mapping\n--    CustomMulfiFileNameMapping(file_name, local_types, local_names, global_types, global_names, global_column_ids, reader_data, initial_file, global_state);\n-+    CustomMulfiFileNameMapping(file_name, local_columns, global_columns, global_column_ids, reader_data, initial_file, global_state);\n- \n-     // Then we handle delta specific mapping\n-     D_ASSERT(global_state);\n-@@ -820,8 +818,8 @@ void DeltaMultiFileReader::CreateNameMapping(const string &file_name, const vect\n- \n-         // Build the name map\n-         case_insensitive_map_t<idx_t> name_map;\n--        for (idx_t col_idx = 0; col_idx < local_names.size(); col_idx++) {\n--            name_map[local_names[col_idx]] = col_idx;\n-+        for (idx_t col_idx = 0; col_idx < local_columns.size(); col_idx++) {\n-+            name_map[local_columns[col_idx].name] = col_idx;\n-         }\n- \n-         // Lookup the required column in the local map\n-diff --git a/src/include/functions/delta_scan.hpp b/src/include/functions/delta_scan.hpp\n-index d90968b..c3e71f2 100644\n---- a/src/include/functions/delta_scan.hpp\n-+++ b/src/include/functions/delta_scan.hpp\n-@@ -117,22 +117,24 @@ struct DeltaMultiFileReader : public MultiFileReader {\n-     void BindOptions(MultiFileReaderOptions &options, MultiFileList &files,\n-                                         vector<LogicalType> &return_types, vector<string> &names, MultiFileReaderBindData& bind_data) override;\n- \n--    void CreateNameMapping(const string &file_name, const vector<LogicalType> &local_types,\n--                      const vector<string> &local_names, const vector<LogicalType> &global_types,\n--                      const vector<string> &global_names, const vector<ColumnIndex> &global_column_ids,\n--                      MultiFileReaderData &reader_data, const string &initial_file,\n--                      optional_ptr<MultiFileReaderGlobalState> global_state) override;\n-+    void CreateColumnMapping(const string &file_name,\n-+\t                                 const vector<MultiFileReaderColumnDefinition> &local_columns,\n-+\t                                 const vector<MultiFileReaderColumnDefinition> &global_columns,\n-+\t                                 const vector<ColumnIndex> &global_column_ids, MultiFileReaderData &reader_data,\n-+\t                                 const MultiFileReaderBindData &bind_data, const string &initial_file,\n-+\t                                 optional_ptr<MultiFileReaderGlobalState> global_state) override;\n- \n-     unique_ptr<MultiFileReaderGlobalState> InitializeGlobalState(ClientContext &context, const MultiFileReaderOptions &file_options,\n--                          const MultiFileReaderBindData &bind_data, const MultiFileList &file_list,\n--                          const vector<LogicalType> &global_types, const vector<string> &global_names,\n--                          const vector<ColumnIndex> &global_column_ids) override;\n--\n--    void FinalizeBind(const MultiFileReaderOptions &file_options, const MultiFileReaderBindData &options,\n--                                       const string &filename, const vector<string> &local_names,\n--                                       const vector<LogicalType> &global_types, const vector<string> &global_names,\n--                                       const vector<ColumnIndex> &global_column_ids, MultiFileReaderData &reader_data,\n--                                       ClientContext &context, optional_ptr<MultiFileReaderGlobalState> global_state) override;\n-+\t                      const MultiFileReaderBindData &bind_data, const MultiFileList &file_list,\n-+\t                      const vector<MultiFileReaderColumnDefinition> &global_columns,\n-+\t                      const vector<ColumnIndex> &global_column_ids) override;\n-+\n-+    void FinalizeBind(const MultiFileReaderOptions &file_options,\n-+\t                                     const MultiFileReaderBindData &options, const string &filename,\n-+\t                                     const vector<MultiFileReaderColumnDefinition> &local_columns,\n-+\t                                     const vector<MultiFileReaderColumnDefinition> &global_columns,\n-+\t                                     const vector<ColumnIndex> &global_column_ids, MultiFileReaderData &reader_data,\n-+\t                                     ClientContext &context, optional_ptr<MultiFileReaderGlobalState> global_state) override;\n- \n-     //! Override the FinalizeChunk method\n-     void FinalizeChunk(ClientContext &context, const MultiFileReaderBindData &bind_data,\ndiff --git a/.github/patches/extensions/inet/require_autoloading.patch b/.github/patches/extensions/inet/require_autoloading.patch\ndeleted file mode 100644\nindex 4611e2f6a893..000000000000\n--- a/.github/patches/extensions/inet/require_autoloading.patch\n+++ /dev/null\n@@ -1,26 +0,0 @@\n-diff --git a/test/sql/test_inet_storage.test b/test/sql/test_inet_storage.test\n-index 6679439..7de7620 100644\n---- a/test/sql/test_inet_storage.test\n-+++ b/test/sql/test_inet_storage.test\n-@@ -5,7 +5,7 @@\n- require inet\n- \n- # FIXME: Make inet properly autoloadable\n--require no_extension_autoloading\n-+require no_extension_autoloading \"FIXME: to be reviewed whether this can be lifted\"\n- \n- # load the DB from disk\n- load __TEST_DIR__/store_inet.db\n-diff --git a/test/sql/test_ipv6_inet_storage.test b/test/sql/test_ipv6_inet_storage.test\n-index 5be1ff2..7dc1930 100644\n---- a/test/sql/test_ipv6_inet_storage.test\n-+++ b/test/sql/test_ipv6_inet_storage.test\n-@@ -25,7 +25,7 @@ CREATE VIEW iview AS SELECT INET '::1'\n- restart\n- \n- #FIXME: INET needs to be explicitly autoloaded on restart\n--require no_extension_autoloading\n-+require no_extension_autoloading \"FIXME: INET needs to be explicitly autoloaded on restart\"\n- \n- query IIIIII\n- DESCRIBE tbl\ndiff --git a/.github/patches/extensions/substrait/or_filter_pushdown.patch b/.github/patches/extensions/substrait/or_filter_pushdown.patch\ndeleted file mode 100644\nindex c971d4f7fcda..000000000000\n--- a/.github/patches/extensions/substrait/or_filter_pushdown.patch\n+++ /dev/null\n@@ -1,31 +0,0 @@\n-diff --git a/src/to_substrait.cpp b/src/to_substrait.cpp\n-index a466fb2..0dd0766 100644\n---- a/src/to_substrait.cpp\n-+++ b/src/to_substrait.cpp\n-@@ -1296,6 +1296,17 @@ substrait::Rel *DuckDBToSubstrait::TransformGet(LogicalOperator &dop) {\n- \tauto bind_info = dget.function.get_bind_info(dget.bind_data.get());\n- \tauto sget = get_rel->mutable_read();\n- \n-+\tif (!dget.table_filters.filters.empty()) {\n-+\n-+\t\tfor (auto it = dget.table_filters.filters.begin(); it != dget.table_filters.filters.end();) {\n-+\t\t\tif (it->second->filter_type == TableFilterType::OPTIONAL_FILTER) {\n-+\t\t\t\tit = dget.table_filters.filters.erase(it);\n-+\t\t\t} else {\n-+\t\t\t\t++it;\n-+\t\t\t}\n-+\t\t}\n-+\t}\n-+\n- \tif (!dget.table_filters.filters.empty()) {\n- \t\t// Pushdown filter\n- \t\tauto filter = CreateConjunction(dget.table_filters.filters,\n-@@ -1317,7 +1328,7 @@ substrait::Rel *DuckDBToSubstrait::TransformGet(LogicalOperator &dop) {\n- \t\tauto &column_ids = dget.GetColumnIds();\n- \t\tfor (auto col_idx : dget.projection_ids) {\n- \t\t\tauto struct_item = select->add_struct_items();\n--\t\t\tstruct_item->set_field(static_cast<int32_t>(column_ids[col_idx]));\n-+\t\t\tstruct_item->set_field(static_cast<int32_t>(column_ids[col_idx].GetPrimaryIndex()));\n- \t\t\t// FIXME do we need to set the child? if yes, to what?\n- \t\t}\n- \t\tprojection->set_allocated_select(select);\ndiff --git a/.github/workflows/ExtensionTrigger.yml b/.github/workflows/ExtensionTrigger.yml\ndeleted file mode 100644\nindex c858fb5768fc..000000000000\n--- a/.github/workflows/ExtensionTrigger.yml\n+++ /dev/null\n@@ -1,15 +0,0 @@\n-name: Extension Trigger\n-on:\n-  workflow_dispatch:\n-  repository_dispatch:\n-\n-jobs:\n-  build-linux:\n-    runs-on: ubuntu-latest\n-\n-    steps:\n-    - uses: actions/checkout@v4\n-\n-    - name: Trigger Substrait Extension\n-      run: |\n-        curl -XPOST -u \"${{secrets.PAT_USERNAME}}:${{secrets.PAT_TOKEN}}\" -H \"Accept: application/vnd.github.everest-preview+json\" -H \"Content-Type: application/json\" https://api.github.com/repos/duckdb/substrait/dispatches --data '{\"event_type\": \"build_application\"}'\n\\ No newline at end of file\ndiff --git a/.github/workflows/LinuxRelease.yml b/.github/workflows/LinuxRelease.yml\nindex ab8a4cd44a34..3cb87603fd80 100644\n--- a/.github/workflows/LinuxRelease.yml\n+++ b/.github/workflows/LinuxRelease.yml\n@@ -88,6 +88,25 @@ jobs:\n       shell: bash\n       run: ./build/release/duckdb -c \"PRAGMA platform;\"\n \n+    - name: Deploy\n+      shell: bash\n+      env:\n+        AWS_ACCESS_KEY_ID: ${{ secrets.S3_DUCKDB_STAGING_ID }}\n+        AWS_SECRET_ACCESS_KEY: ${{ secrets.S3_DUCKDB_STAGING_KEY }}\n+      run: |\n+        python3 scripts/amalgamation.py\n+        zip -j duckdb_cli-linux-amd64.zip build/release/duckdb\n+        zip -j libduckdb-linux-amd64.zip build/release/src/libduckdb*.* src/amalgamation/duckdb.hpp src/include/duckdb.h\n+        zip -j libduckdb-src.zip src/amalgamation/duckdb.hpp src/amalgamation/duckdb.cpp src/include/duckdb.h src/include/duckdb_extension.h\n+        ./scripts/upload-assets-to-staging.sh github_release libduckdb-src.zip libduckdb-linux-amd64.zip duckdb_cli-linux-amd64.zip\n+\n+    - uses: actions/upload-artifact@v4\n+      with:\n+        name: duckdb-binaries-linux\n+        path: |\n+          libduckdb-linux-amd64.zip\n+          duckdb_cli-linux-amd64.zip\n+\n     - name: Test\n       shell: bash\n       if: ${{ inputs.skip_tests != 'true' }}\n@@ -109,26 +128,6 @@ jobs:\n         build/release/benchmark/benchmark_runner benchmark/tpch/sf1/q01.benchmark\n         build/release/duckdb -c \"COPY (SELECT 42) TO '/dev/stdout' (FORMAT PARQUET)\" | cat\n \n-    - name: Deploy\n-      shell: bash\n-      env:\n-        AWS_ACCESS_KEY_ID: ${{ secrets.S3_DUCKDB_STAGING_ID }}\n-        AWS_SECRET_ACCESS_KEY: ${{ secrets.S3_DUCKDB_STAGING_KEY }}\n-      run: |\n-        python3 scripts/amalgamation.py\n-        zip -j duckdb_cli-linux-amd64.zip build/release/duckdb\n-        zip -j libduckdb-linux-amd64.zip build/release/src/libduckdb*.* src/amalgamation/duckdb.hpp src/include/duckdb.h\n-        zip -j libduckdb-src.zip src/amalgamation/duckdb.hpp src/amalgamation/duckdb.cpp src/include/duckdb.h src/include/duckdb_extension.h\n-        ./scripts/upload-assets-to-staging.sh github_release libduckdb-src.zip libduckdb-linux-amd64.zip duckdb_cli-linux-amd64.zip\n-\n-    - uses: actions/upload-artifact@v4\n-      with:\n-        name: duckdb-binaries-linux\n-        path: |\n-          libduckdb-linux-amd64.zip\n-          duckdb_cli-linux-amd64.zip\n-\n-\n  linux-release-aarch64:\n    # Builds binaries for linux_arm64\n    name: Linux (aarch64)\ndiff --git a/Makefile b/Makefile\nindex 5f3a37ec4c97..227d582e0e98 100644\n--- a/Makefile\n+++ b/Makefile\n@@ -316,7 +316,6 @@ clean-python:\n debug: ${EXTENSION_CONFIG_STEP}\n \tmkdir -p ./build/debug && \\\n \tcd build/debug && \\\n-\techo ${DUCKDB_EXTENSION_SUBSTRAIT_PATH} && \\\n \tcmake $(GENERATOR) $(FORCE_COLOR) ${WARNINGS_AS_ERRORS} ${FORCE_32_BIT_FLAG} ${DISABLE_UNITY_FLAG} ${DISABLE_SANITIZER_FLAG} ${STATIC_LIBCPP} ${CMAKE_VARS} ${CMAKE_VARS_BUILD} -DDEBUG_MOVE=1 -DCMAKE_BUILD_TYPE=Debug ../.. && \\\n \tcmake --build . --config Debug\n \ndiff --git a/benchmark/micro/index/insert/insert_pk_fk.benchmark b/benchmark/micro/index/insert/insert_pk_fk.benchmark\nindex fcb4709f781e..0f70944c4603 100644\n--- a/benchmark/micro/index/insert/insert_pk_fk.benchmark\n+++ b/benchmark/micro/index/insert/insert_pk_fk.benchmark\n@@ -25,7 +25,11 @@ COPY warehouse FROM '${BENCHMARK_DIR}/sf1data/warehouse.csv' (FORMAT 'csv', head\n COPY inventory FROM '${BENCHMARK_DIR}/sf1data/inventory.csv' (FORMAT 'csv', header 1, delimiter ',', quote '\"');\n \n cleanup\n-CREATE OR REPLACE TABLE date_dim (d_date_sk Integer Not Null PRIMARY KEY, d_date_id String Not Null, d_date Date Not Null, d_month_seq Integer, d_week_seq Integer, d_quarter_seq Integer, d_year Integer, d_dow Integer, d_moy Integer, d_dom Integer, d_qoy Integer, d_fy_year Integer, d_fy_quarter_seq Integer, d_fy_week_seq Integer, d_day_name String, d_quarter_name String, d_holiday String, d_weekend String, d_following_holiday String, d_first_dom Integer, d_last_dom Integer, d_same_day_ly Integer, d_same_day_lq Integer, d_current_day String, d_current_week String, d_current_month String, d_current_quarter String, d_current_year String);\n-CREATE OR REPLACE TABLE warehouse (w_warehouse_sk Integer Not Null PRIMARY KEY, w_warehouse_id String Not Null, w_warehouse_name String, w_warehouse_sq_ft Integer, w_street_number String, w_street_name String, w_street_type String, w_suite_number String, w_city String, w_county String, w_state String, w_zip String, w_country String, w_gmt_offset Decimal(5,2));\n-CREATE OR REPLACE TABLE item (i_item_sk Integer Not Null PRIMARY KEY, i_item_id String Not Null, i_rec_start_date Date, i_rec_end_date Date, i_item_desc String, i_current_price Decimal(7,2), i_wholesale_cost Decimal(7,2), i_brand_id Integer, i_brand String, i_class_id Integer, i_class String, i_category_id Integer, i_category String, i_manufact_id Integer, i_manufact String, i_size String, i_formulation String, i_color String, i_units String, i_container String, i_manager_id Integer, i_product_name String);\n-CREATE OR REPLACE TABLE inventory (inv_date_sk Integer Not Null REFERENCES date_dim (d_date_sk), inv_item_sk Integer Not Null REFERENCES item (i_item_sk), inv_warehouse_sk Integer Not Null REFERENCES warehouse (w_warehouse_sk), inv_quantity_on_hand Integer);\n\\ No newline at end of file\n+DROP TABLE inventory;\n+DROP TABLE item;\n+DROP TABLE warehouse;\n+DROP TABLE date_dim;\n+CREATE TABLE date_dim (d_date_sk Integer Not Null PRIMARY KEY, d_date_id String Not Null, d_date Date Not Null, d_month_seq Integer, d_week_seq Integer, d_quarter_seq Integer, d_year Integer, d_dow Integer, d_moy Integer, d_dom Integer, d_qoy Integer, d_fy_year Integer, d_fy_quarter_seq Integer, d_fy_week_seq Integer, d_day_name String, d_quarter_name String, d_holiday String, d_weekend String, d_following_holiday String, d_first_dom Integer, d_last_dom Integer, d_same_day_ly Integer, d_same_day_lq Integer, d_current_day String, d_current_week String, d_current_month String, d_current_quarter String, d_current_year String);\n+CREATE TABLE warehouse (w_warehouse_sk Integer Not Null PRIMARY KEY, w_warehouse_id String Not Null, w_warehouse_name String, w_warehouse_sq_ft Integer, w_street_number String, w_street_name String, w_street_type String, w_suite_number String, w_city String, w_county String, w_state String, w_zip String, w_country String, w_gmt_offset Decimal(5,2));\n+CREATE TABLE item (i_item_sk Integer Not Null PRIMARY KEY, i_item_id String Not Null, i_rec_start_date Date, i_rec_end_date Date, i_item_desc String, i_current_price Decimal(7,2), i_wholesale_cost Decimal(7,2), i_brand_id Integer, i_brand String, i_class_id Integer, i_class String, i_category_id Integer, i_category String, i_manufact_id Integer, i_manufact String, i_size String, i_formulation String, i_color String, i_units String, i_container String, i_manager_id Integer, i_product_name String);\n+CREATE TABLE inventory (inv_date_sk Integer Not Null REFERENCES date_dim (d_date_sk), inv_item_sk Integer Not Null REFERENCES item (i_item_sk), inv_warehouse_sk Integer Not Null REFERENCES warehouse (w_warehouse_sk), inv_quantity_on_hand Integer);\n\\ No newline at end of file\ndiff --git a/data/csv/afl/3977/case_1.csv b/data/csv/afl/3977/case_1.csv\nnew file mode 100644\nindex 000000000000..e69b13d4d99e\nBinary files /dev/null and b/data/csv/afl/3977/case_1.csv differ\ndiff --git a/data/csv/afl/3977/case_10.csv b/data/csv/afl/3977/case_10.csv\nnew file mode 100644\nindex 000000000000..3e3072b344af\nBinary files /dev/null and b/data/csv/afl/3977/case_10.csv differ\ndiff --git a/data/csv/afl/3977/case_11.csv b/data/csv/afl/3977/case_11.csv\nnew file mode 100644\nindex 000000000000..2bbbf9e3e979\nBinary files /dev/null and b/data/csv/afl/3977/case_11.csv differ\ndiff --git a/data/csv/afl/3977/case_12.csv b/data/csv/afl/3977/case_12.csv\nnew file mode 100644\nindex 000000000000..cb565bfdaec3\nBinary files /dev/null and b/data/csv/afl/3977/case_12.csv differ\ndiff --git a/data/csv/afl/3977/case_13.csv b/data/csv/afl/3977/case_13.csv\nnew file mode 100644\nindex 000000000000..5a7f3751c723\nBinary files /dev/null and b/data/csv/afl/3977/case_13.csv differ\ndiff --git a/data/csv/afl/3977/case_14.csv b/data/csv/afl/3977/case_14.csv\nnew file mode 100644\nindex 000000000000..929e48820fa1\nBinary files /dev/null and b/data/csv/afl/3977/case_14.csv differ\ndiff --git a/data/csv/afl/3977/case_15.csv b/data/csv/afl/3977/case_15.csv\nnew file mode 100644\nindex 000000000000..7d3129840c30\nBinary files /dev/null and b/data/csv/afl/3977/case_15.csv differ\ndiff --git a/data/csv/afl/3977/case_16.csv b/data/csv/afl/3977/case_16.csv\nnew file mode 100644\nindex 000000000000..8798828e1063\nBinary files /dev/null and b/data/csv/afl/3977/case_16.csv differ\ndiff --git a/data/csv/afl/3977/case_17.csv b/data/csv/afl/3977/case_17.csv\nnew file mode 100644\nindex 000000000000..34d5e21f3462\nBinary files /dev/null and b/data/csv/afl/3977/case_17.csv differ\ndiff --git a/data/csv/afl/3977/case_18.csv b/data/csv/afl/3977/case_18.csv\nnew file mode 100644\nindex 000000000000..e522f4b29436\nBinary files /dev/null and b/data/csv/afl/3977/case_18.csv differ\ndiff --git a/data/csv/afl/3977/case_19.csv b/data/csv/afl/3977/case_19.csv\nnew file mode 100644\nindex 000000000000..30ebb2778d25\nBinary files /dev/null and b/data/csv/afl/3977/case_19.csv differ\ndiff --git a/data/csv/afl/3977/case_2.csv b/data/csv/afl/3977/case_2.csv\nnew file mode 100644\nindex 000000000000..c9619da772c4\n--- /dev/null\n+++ b/data/csv/afl/3977/case_2.csv\n@@ -0,0 +1,3 @@\n+line1;line1_2;line1_3\n+line2;line2_2;line2_3\n+line3;line3_2;Rine3_3\n\\ No newline at end of file\ndiff --git a/data/csv/afl/3977/case_20.csv b/data/csv/afl/3977/case_20.csv\nnew file mode 100644\nindex 000000000000..f2204791ecb6\nBinary files /dev/null and b/data/csv/afl/3977/case_20.csv differ\ndiff --git a/data/csv/afl/3977/case_21.csv b/data/csv/afl/3977/case_21.csv\nnew file mode 100644\nindex 000000000000..65bb610e83ac\nBinary files /dev/null and b/data/csv/afl/3977/case_21.csv differ\ndiff --git a/data/csv/afl/3977/case_22.csv b/data/csv/afl/3977/case_22.csv\nnew file mode 100644\nindex 000000000000..37b7add295ec\nBinary files /dev/null and b/data/csv/afl/3977/case_22.csv differ\ndiff --git a/data/csv/afl/3977/case_23.csv b/data/csv/afl/3977/case_23.csv\nnew file mode 100644\nindex 000000000000..9b430d53e975\nBinary files /dev/null and b/data/csv/afl/3977/case_23.csv differ\ndiff --git a/data/csv/afl/3977/case_24.csv b/data/csv/afl/3977/case_24.csv\nnew file mode 100644\nindex 000000000000..babff5de5745\nBinary files /dev/null and b/data/csv/afl/3977/case_24.csv differ\ndiff --git a/data/csv/afl/3977/case_25.csv b/data/csv/afl/3977/case_25.csv\nnew file mode 100644\nindex 000000000000..82de320acb61\nBinary files /dev/null and b/data/csv/afl/3977/case_25.csv differ\ndiff --git a/data/csv/afl/3977/case_26.csv b/data/csv/afl/3977/case_26.csv\nnew file mode 100644\nindex 000000000000..1cc82568e70f\nBinary files /dev/null and b/data/csv/afl/3977/case_26.csv differ\ndiff --git a/data/csv/afl/3977/case_27.csv b/data/csv/afl/3977/case_27.csv\nnew file mode 100644\nindex 000000000000..1378f74ba85a\nBinary files /dev/null and b/data/csv/afl/3977/case_27.csv differ\ndiff --git a/data/csv/afl/3977/case_28.csv b/data/csv/afl/3977/case_28.csv\nnew file mode 100644\nindex 000000000000..43efeafc5e0c\nBinary files /dev/null and b/data/csv/afl/3977/case_28.csv differ\ndiff --git a/data/csv/afl/3977/case_29.csv b/data/csv/afl/3977/case_29.csv\nnew file mode 100644\nindex 000000000000..d1f60b6d942d\nBinary files /dev/null and b/data/csv/afl/3977/case_29.csv differ\ndiff --git a/data/csv/afl/3977/case_3.csv b/data/csv/afl/3977/case_3.csv\nnew file mode 100644\nindex 000000000000..861d472b9048\n--- /dev/null\n+++ b/data/csv/afl/3977/case_3.csv\n@@ -0,0 +1,1 @@\n+3;line3_2;line3_3\n\\ No newline at end of file\ndiff --git a/data/csv/afl/3977/case_30.csv b/data/csv/afl/3977/case_30.csv\nnew file mode 100644\nindex 000000000000..2adc417728fe\nBinary files /dev/null and b/data/csv/afl/3977/case_30.csv differ\ndiff --git a/data/csv/afl/3977/case_31.csv b/data/csv/afl/3977/case_31.csv\nnew file mode 100644\nindex 000000000000..c4ea43561ad8\nBinary files /dev/null and b/data/csv/afl/3977/case_31.csv differ\ndiff --git a/data/csv/afl/3977/case_32.csv b/data/csv/afl/3977/case_32.csv\nnew file mode 100644\nindex 000000000000..49f5a28bb267\nBinary files /dev/null and b/data/csv/afl/3977/case_32.csv differ\ndiff --git a/data/csv/afl/3977/case_33.csv b/data/csv/afl/3977/case_33.csv\nnew file mode 100644\nindex 000000000000..0322ccc54c03\nBinary files /dev/null and b/data/csv/afl/3977/case_33.csv differ\ndiff --git a/data/csv/afl/3977/case_34.csv b/data/csv/afl/3977/case_34.csv\nnew file mode 100644\nindex 000000000000..51ad255bac34\nBinary files /dev/null and b/data/csv/afl/3977/case_34.csv differ\ndiff --git a/data/csv/afl/3977/case_35.csv b/data/csv/afl/3977/case_35.csv\nnew file mode 100644\nindex 000000000000..954fc2e5a2c6\nBinary files /dev/null and b/data/csv/afl/3977/case_35.csv differ\ndiff --git a/data/csv/afl/3977/case_36.csv b/data/csv/afl/3977/case_36.csv\nnew file mode 100644\nindex 000000000000..3ad931bfcbf5\nBinary files /dev/null and b/data/csv/afl/3977/case_36.csv differ\ndiff --git a/data/csv/afl/3977/case_37.csv b/data/csv/afl/3977/case_37.csv\nnew file mode 100644\nindex 000000000000..8161bace41ba\nBinary files /dev/null and b/data/csv/afl/3977/case_37.csv differ\ndiff --git a/data/csv/afl/3977/case_38.csv b/data/csv/afl/3977/case_38.csv\nnew file mode 100644\nindex 000000000000..974367b0402c\nBinary files /dev/null and b/data/csv/afl/3977/case_38.csv differ\ndiff --git a/data/csv/afl/3977/case_39.csv b/data/csv/afl/3977/case_39.csv\nnew file mode 100644\nindex 000000000000..e26b19f89d5e\nBinary files /dev/null and b/data/csv/afl/3977/case_39.csv differ\ndiff --git a/data/csv/afl/3977/case_4.csv b/data/csv/afl/3977/case_4.csv\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/data/csv/afl/3977/case_40.csv b/data/csv/afl/3977/case_40.csv\nnew file mode 100644\nindex 000000000000..c9f9ac5880ea\nBinary files /dev/null and b/data/csv/afl/3977/case_40.csv differ\ndiff --git a/data/csv/afl/3977/case_41.csv b/data/csv/afl/3977/case_41.csv\nnew file mode 100644\nindex 000000000000..41deeed6880f\nBinary files /dev/null and b/data/csv/afl/3977/case_41.csv differ\ndiff --git a/data/csv/afl/3977/case_42.csv b/data/csv/afl/3977/case_42.csv\nnew file mode 100644\nindex 000000000000..4b96cce041b1\nBinary files /dev/null and b/data/csv/afl/3977/case_42.csv differ\ndiff --git a/data/csv/afl/3977/case_43.csv b/data/csv/afl/3977/case_43.csv\nnew file mode 100644\nindex 000000000000..7dfe369df9f3\nBinary files /dev/null and b/data/csv/afl/3977/case_43.csv differ\ndiff --git a/data/csv/afl/3977/case_44.csv b/data/csv/afl/3977/case_44.csv\nnew file mode 100644\nindex 000000000000..921253950cd9\nBinary files /dev/null and b/data/csv/afl/3977/case_44.csv differ\ndiff --git a/data/csv/afl/3977/case_45.csv b/data/csv/afl/3977/case_45.csv\nnew file mode 100644\nindex 000000000000..cb19a6e72abe\nBinary files /dev/null and b/data/csv/afl/3977/case_45.csv differ\ndiff --git a/data/csv/afl/3977/case_46.csv b/data/csv/afl/3977/case_46.csv\nnew file mode 100644\nindex 000000000000..600fbba9ed59\nBinary files /dev/null and b/data/csv/afl/3977/case_46.csv differ\ndiff --git a/data/csv/afl/3977/case_47.csv b/data/csv/afl/3977/case_47.csv\nnew file mode 100644\nindex 000000000000..c0f1b5e52264\nBinary files /dev/null and b/data/csv/afl/3977/case_47.csv differ\ndiff --git a/data/csv/afl/3977/case_48.csv b/data/csv/afl/3977/case_48.csv\nnew file mode 100644\nindex 000000000000..271b06559604\nBinary files /dev/null and b/data/csv/afl/3977/case_48.csv differ\ndiff --git a/data/csv/afl/3977/case_49.csv b/data/csv/afl/3977/case_49.csv\nnew file mode 100644\nindex 000000000000..c5e4b4ad79e7\nBinary files /dev/null and b/data/csv/afl/3977/case_49.csv differ\ndiff --git a/data/csv/afl/3977/case_5.csv b/data/csv/afl/3977/case_5.csv\nnew file mode 100644\nindex 000000000000..20491b527321\n--- /dev/null\n+++ b/data/csv/afl/3977/case_5.csv\n@@ -0,0 +1,6 @@\n+\"blaaaaaaaaaaaaaa\"\n+\"bla\"SON'}\u0010\u00011{\"col{\"co\u0010\u00011{\"co {\"col_a\":1,\"col_b\"n\n+l_a\":1,\"col_b\"n\n+\"bla\"\n+\"bla\"\n+\"bla\n\\ No newline at end of file\ndiff --git a/data/csv/afl/3977/case_50.csv b/data/csv/afl/3977/case_50.csv\nnew file mode 100644\nindex 000000000000..d6f76352fb15\nBinary files /dev/null and b/data/csv/afl/3977/case_50.csv differ\ndiff --git a/data/csv/afl/3977/case_51.csv b/data/csv/afl/3977/case_51.csv\nnew file mode 100644\nindex 000000000000..26381fb96cd5\nBinary files /dev/null and b/data/csv/afl/3977/case_51.csv differ\ndiff --git a/data/csv/afl/3977/case_52.csv b/data/csv/afl/3977/case_52.csv\nnew file mode 100644\nindex 000000000000..3a23e7f3e6f9\nBinary files /dev/null and b/data/csv/afl/3977/case_52.csv differ\ndiff --git a/data/csv/afl/3977/case_53.csv b/data/csv/afl/3977/case_53.csv\nnew file mode 100644\nindex 000000000000..6e4ff8649f92\nBinary files /dev/null and b/data/csv/afl/3977/case_53.csv differ\ndiff --git a/data/csv/afl/3977/case_54.csv b/data/csv/afl/3977/case_54.csv\nnew file mode 100644\nindex 000000000000..31fc262001e9\nBinary files /dev/null and b/data/csv/afl/3977/case_54.csv differ\ndiff --git a/data/csv/afl/3977/case_55.csv b/data/csv/afl/3977/case_55.csv\nnew file mode 100644\nindex 000000000000..6f1fc5e7267b\nBinary files /dev/null and b/data/csv/afl/3977/case_55.csv differ\ndiff --git a/data/csv/afl/3977/case_56.csv b/data/csv/afl/3977/case_56.csv\nnew file mode 100644\nindex 000000000000..204024993a21\nBinary files /dev/null and b/data/csv/afl/3977/case_56.csv differ\ndiff --git a/data/csv/afl/3977/case_57.csv b/data/csv/afl/3977/case_57.csv\nnew file mode 100644\nindex 000000000000..018368c81520\nBinary files /dev/null and b/data/csv/afl/3977/case_57.csv differ\ndiff --git a/data/csv/afl/3977/case_58.csv b/data/csv/afl/3977/case_58.csv\nnew file mode 100644\nindex 000000000000..16a841938d93\nBinary files /dev/null and b/data/csv/afl/3977/case_58.csv differ\ndiff --git a/data/csv/afl/3977/case_59.csv b/data/csv/afl/3977/case_59.csv\nnew file mode 100644\nindex 000000000000..13c07cf93aab\nBinary files /dev/null and b/data/csv/afl/3977/case_59.csv differ\ndiff --git a/data/csv/afl/3977/case_6.csv b/data/csv/afl/3977/case_6.csv\nnew file mode 100644\nindex 000000000000..6288a88f9bbb\nBinary files /dev/null and b/data/csv/afl/3977/case_6.csv differ\ndiff --git a/data/csv/afl/3977/case_60.csv b/data/csv/afl/3977/case_60.csv\nnew file mode 100644\nindex 000000000000..d6553426568f\nBinary files /dev/null and b/data/csv/afl/3977/case_60.csv differ\ndiff --git a/data/csv/afl/3977/case_61.csv b/data/csv/afl/3977/case_61.csv\nnew file mode 100644\nindex 000000000000..7b05567042f8\nBinary files /dev/null and b/data/csv/afl/3977/case_61.csv differ\ndiff --git a/data/csv/afl/3977/case_62.csv b/data/csv/afl/3977/case_62.csv\nnew file mode 100644\nindex 000000000000..10279dfd189a\nBinary files /dev/null and b/data/csv/afl/3977/case_62.csv differ\ndiff --git a/data/csv/afl/3977/case_63.csv b/data/csv/afl/3977/case_63.csv\nnew file mode 100644\nindex 000000000000..b0ccb52ea284\nBinary files /dev/null and b/data/csv/afl/3977/case_63.csv differ\ndiff --git a/data/csv/afl/3977/case_64.csv b/data/csv/afl/3977/case_64.csv\nnew file mode 100644\nindex 000000000000..e86846eff9ab\nBinary files /dev/null and b/data/csv/afl/3977/case_64.csv differ\ndiff --git a/data/csv/afl/3977/case_65.csv b/data/csv/afl/3977/case_65.csv\nnew file mode 100644\nindex 000000000000..079b9f20503e\nBinary files /dev/null and b/data/csv/afl/3977/case_65.csv differ\ndiff --git a/data/csv/afl/3977/case_66.csv b/data/csv/afl/3977/case_66.csv\nnew file mode 100644\nindex 000000000000..f9d6ea9cbdbc\nBinary files /dev/null and b/data/csv/afl/3977/case_66.csv differ\ndiff --git a/data/csv/afl/3977/case_67.csv b/data/csv/afl/3977/case_67.csv\nnew file mode 100644\nindex 000000000000..3ab64528302b\nBinary files /dev/null and b/data/csv/afl/3977/case_67.csv differ\ndiff --git a/data/csv/afl/3977/case_68.csv b/data/csv/afl/3977/case_68.csv\nnew file mode 100644\nindex 000000000000..5a6226db2fe7\nBinary files /dev/null and b/data/csv/afl/3977/case_68.csv differ\ndiff --git a/data/csv/afl/3977/case_69.csv b/data/csv/afl/3977/case_69.csv\nnew file mode 100644\nindex 000000000000..5bee9991494c\nBinary files /dev/null and b/data/csv/afl/3977/case_69.csv differ\ndiff --git a/data/csv/afl/3977/case_7.csv b/data/csv/afl/3977/case_7.csv\nnew file mode 100644\nindex 000000000000..d50d8eb80470\nBinary files /dev/null and b/data/csv/afl/3977/case_7.csv differ\ndiff --git a/data/csv/afl/3977/case_70.csv b/data/csv/afl/3977/case_70.csv\nnew file mode 100644\nindex 000000000000..fa6d9c61c758\nBinary files /dev/null and b/data/csv/afl/3977/case_70.csv differ\ndiff --git a/data/csv/afl/3977/case_71.csv b/data/csv/afl/3977/case_71.csv\nnew file mode 100644\nindex 000000000000..060bfb01e9d7\nBinary files /dev/null and b/data/csv/afl/3977/case_71.csv differ\ndiff --git a/data/csv/afl/3977/case_72.csv b/data/csv/afl/3977/case_72.csv\nnew file mode 100644\nindex 000000000000..30de195449fd\nBinary files /dev/null and b/data/csv/afl/3977/case_72.csv differ\ndiff --git a/data/csv/afl/3977/case_73.csv b/data/csv/afl/3977/case_73.csv\nnew file mode 100644\nindex 000000000000..8497c94c4fb7\nBinary files /dev/null and b/data/csv/afl/3977/case_73.csv differ\ndiff --git a/data/csv/afl/3977/case_74.csv b/data/csv/afl/3977/case_74.csv\nnew file mode 100644\nindex 000000000000..821523693e88\nBinary files /dev/null and b/data/csv/afl/3977/case_74.csv differ\ndiff --git a/data/csv/afl/3977/case_75.csv b/data/csv/afl/3977/case_75.csv\nnew file mode 100644\nindex 000000000000..85a82566e50b\nBinary files /dev/null and b/data/csv/afl/3977/case_75.csv differ\ndiff --git a/data/csv/afl/3977/case_76.csv b/data/csv/afl/3977/case_76.csv\nnew file mode 100644\nindex 000000000000..5003b82705ea\nBinary files /dev/null and b/data/csv/afl/3977/case_76.csv differ\ndiff --git a/data/csv/afl/3977/case_77.csv b/data/csv/afl/3977/case_77.csv\nnew file mode 100644\nindex 000000000000..5500c5157c37\nBinary files /dev/null and b/data/csv/afl/3977/case_77.csv differ\ndiff --git a/data/csv/afl/3977/case_78.csv b/data/csv/afl/3977/case_78.csv\nnew file mode 100644\nindex 000000000000..79d4b5866755\nBinary files /dev/null and b/data/csv/afl/3977/case_78.csv differ\ndiff --git a/data/csv/afl/3977/case_79.csv b/data/csv/afl/3977/case_79.csv\nnew file mode 100644\nindex 000000000000..662127e59e1d\nBinary files /dev/null and b/data/csv/afl/3977/case_79.csv differ\ndiff --git a/data/csv/afl/3977/case_8.csv b/data/csv/afl/3977/case_8.csv\nnew file mode 100644\nindex 000000000000..f7c7b1399007\nBinary files /dev/null and b/data/csv/afl/3977/case_8.csv differ\ndiff --git a/data/csv/afl/3977/case_80.csv b/data/csv/afl/3977/case_80.csv\nnew file mode 100644\nindex 000000000000..114ad5fa8fec\nBinary files /dev/null and b/data/csv/afl/3977/case_80.csv differ\ndiff --git a/data/csv/afl/3977/case_81.csv b/data/csv/afl/3977/case_81.csv\nnew file mode 100644\nindex 000000000000..f99002c5263d\nBinary files /dev/null and b/data/csv/afl/3977/case_81.csv differ\ndiff --git a/data/csv/afl/3977/case_82.csv b/data/csv/afl/3977/case_82.csv\nnew file mode 100644\nindex 000000000000..e4e1da27c222\nBinary files /dev/null and b/data/csv/afl/3977/case_82.csv differ\ndiff --git a/data/csv/afl/3977/case_83.csv b/data/csv/afl/3977/case_83.csv\nnew file mode 100644\nindex 000000000000..96e6ee3273ea\nBinary files /dev/null and b/data/csv/afl/3977/case_83.csv differ\ndiff --git a/data/csv/afl/3977/case_84.csv b/data/csv/afl/3977/case_84.csv\nnew file mode 100644\nindex 000000000000..bc8e6a8b6ce8\nBinary files /dev/null and b/data/csv/afl/3977/case_84.csv differ\ndiff --git a/data/csv/afl/3977/case_85.csv b/data/csv/afl/3977/case_85.csv\nnew file mode 100644\nindex 000000000000..4b37abac1b10\nBinary files /dev/null and b/data/csv/afl/3977/case_85.csv differ\ndiff --git a/data/csv/afl/3977/case_86.csv b/data/csv/afl/3977/case_86.csv\nnew file mode 100644\nindex 000000000000..631178cb3f47\nBinary files /dev/null and b/data/csv/afl/3977/case_86.csv differ\ndiff --git a/data/csv/afl/3977/case_87.csv b/data/csv/afl/3977/case_87.csv\nnew file mode 100644\nindex 000000000000..6c582bc4e474\nBinary files /dev/null and b/data/csv/afl/3977/case_87.csv differ\ndiff --git a/data/csv/afl/3977/case_88.csv b/data/csv/afl/3977/case_88.csv\nnew file mode 100644\nindex 000000000000..ede26b592233\nBinary files /dev/null and b/data/csv/afl/3977/case_88.csv differ\ndiff --git a/data/csv/afl/3977/case_9.csv b/data/csv/afl/3977/case_9.csv\nnew file mode 100644\nindex 000000000000..dcee2aab7c28\nBinary files /dev/null and b/data/csv/afl/3977/case_9.csv differ\ndiff --git a/data/csv/afl/3981/case_0.csv b/data/csv/afl/3981/case_0.csv\nnew file mode 100644\nindex 000000000000..59390ec49901\nBinary files /dev/null and b/data/csv/afl/3981/case_0.csv differ\ndiff --git a/data/csv/afl/3981/case_1.csv b/data/csv/afl/3981/case_1.csv\nnew file mode 100644\nindex 000000000000..a8919290cb72\nBinary files /dev/null and b/data/csv/afl/3981/case_1.csv differ\ndiff --git a/data/csv/afl/3981/case_2.csv b/data/csv/afl/3981/case_2.csv\nnew file mode 100644\nindex 000000000000..2154533db63a\nBinary files /dev/null and b/data/csv/afl/3981/case_2.csv differ\ndiff --git a/data/csv/afl/3981/case_3.csv b/data/csv/afl/3981/case_3.csv\nnew file mode 100644\nindex 000000000000..7fb006c47f72\nBinary files /dev/null and b/data/csv/afl/3981/case_3.csv differ\ndiff --git a/data/csv/afl/3981/case_4.csv b/data/csv/afl/3981/case_4.csv\nnew file mode 100644\nindex 000000000000..d73484ecd2ed\nBinary files /dev/null and b/data/csv/afl/3981/case_4.csv differ\ndiff --git a/data/csv/afl/3981/case_5.csv b/data/csv/afl/3981/case_5.csv\nnew file mode 100644\nindex 000000000000..7e5b80b63bdd\nBinary files /dev/null and b/data/csv/afl/3981/case_5.csv differ\ndiff --git a/data/csv/afl/3981/case_6.csv b/data/csv/afl/3981/case_6.csv\nnew file mode 100644\nindex 000000000000..3a200bab6ab5\nBinary files /dev/null and b/data/csv/afl/3981/case_6.csv differ\ndiff --git a/data/csv/extra_delimiters.csv b/data/csv/extra_delimiters.csv\nnew file mode 100644\nindex 000000000000..df5e498074c6\n--- /dev/null\n+++ b/data/csv/extra_delimiters.csv\n@@ -0,0 +1,5 @@\n+a,b,c\n+1,2,3\n+1,2,3\n+1,2,3,4,5\n+1,2,3\n\\ No newline at end of file\ndiff --git a/data/csv/pollock/file_field_delimiter_0x20.csv b/data/csv/pollock/file_field_delimiter_0x20.csv\nnew file mode 100644\nindex 000000000000..464e76bb632f\n--- /dev/null\n+++ b/data/csv/pollock/file_field_delimiter_0x20.csv\n@@ -0,0 +1,84 @@\n+DATE TIME Qty PRODUCTID Price ProductType \"ProductDescription\" \"URL\" Comments\n+28/01/2018 00:00 2 MG-8769 $74.69 Men's Waterproof Hiking Boots \"These waterproof hiking boots for men are rugged enough for peak performance yet light and quick enough to keep feet from feeling weighed down.\" \"https://www.example.com/product/MG_8769.html\"\n+29/01/2018 00:15 0 RI-3895 $29.81 Light-Up Running Jacket \"The next level of weather protection. This light-up jacket resists the elements and keeps you visible in low-light conditions. From running, biking or walking the dog, the durable construction and innovative safety features won't let you down.\" \"https://www.example.com/product/RI_3895.html\"\n+30/01/2018 00:30 1 RI-8070 $80.08 Men's Ventilated Trail Shoes \"Great grip and super extra breathability make these amazing ventilated hikers ideal for warm, dry conditions.\" \"https://www.example.com/product/RI_8070.html\"\n+31/01/2018 00:45 1 RI-9546 $25.55 Switch Fly Rods \"This lightweight fly rod delivers outstanding performance and can be used as either a traditional one-handed rod or as a two-handed spey rod. Two-handed technique is ideal for larger rivers and situations where there isn't space for a backcast.\" \"https://www.example.com/product/RI_9546.html\"\n+13/02/2018 01:00 9 CC-9259 $48.00 \"Throw Pillow, Wooden Paddles\" \"Add a pop of paddling fun to your bed, chair or sofa with this whimsical throw pillow, handhooked on front for a timeless style.\" \"https://www.example.com/product/CC_9259.html\"\n+14/02/2018 01:15 1 CC-1697 $34.22 Men's Heavy-Duty Suspenders \"These tough Men's Heavy-Duty Suspenders are made to hold up heavy wool pants without stretching in any way, shape or form.\" \"https://www.example.com/product/CC_1697.html\"\n+15/02/2018 01:30 2 RI-6052 $89.34 Organic Textured Cotton Towel \"All the softness and absorbency you've come to expect from our towels, in certified organic cotton for natural, ecofriendly comfort.\" \"https://www.example.com/product/RI_6052.html\"\n+16/02/2018 01:45 2 YY-3522 $19.34 \"Cycling Jersey, Short-Sleeve\" \"Designed with lots of performance features, plus a semi-form-fitting profile, this cycling jersey delivers all-day comfort and serious style.\" \"https://www.example.com/product/YY_3522.html\"\n+17/02/2018 02:00 0 YY-5315 $45.39 \"Men's Silk Underwear, Crewneck\" \"For strong, lightweight comfort without bulk, our men's silk crewneck makes for an ideal first layer against the cold from slope to lodge to shoveling snow.\" \"https://www.example.com/product/YY_5315.html\"\n+18/02/2018 02:15 2 BH-9827 $78.07 \"All-Weather Dining Table, Round 48\"\"\" \"Made in the USA to our exacting standards, this round patio table is durable enough to weather the elements year-round.\" \"https://www.example.com/product/BH_9827.html\"\n+19/02/2018 02:30 1 BH-7885 $52.45 Women's No-Show Socks \"The warmth and comfort of wool, these socks are designed in a minimal, no-show style that is of pure elegance and design.\" \"https://www.example.com/product/BH_7885.html\"\n+20/02/2018 02:45 1 BH-7531 $48.08 Women's  Fly Rod 8 Wt. \"Amazingly crisp action and a remarkably light feel in our 8\\'9\"\" length fly rod, impeccably designed for her.\" \"https://www.example.com/product/BH_7531.html\"\n+21/02/2018 03:00 3 BH-3190 $65.38 Men's Down Vest \"Our best-value down vest is packed with ultralight 650-fill for warmth and protection, even when wet.\" \"https://www.example.com/product/BH_3190.html\"\n+22/02/2018 03:15 3 HK-3372 $6.45 Tropic Cap \"Made with the same tropical fabric as our bestselling shirts, this wonderful cap provides UPF 50+ sun protection.\" \"https://www.example.com/product/HK_3372.html\"\n+23/02/2018 03:30 1 HK-5716 $46.01 Women's 3-in-1 Jacket \"Our women's 3-in-1 jacket offers three times the value and versatility for the solution to year-round weather conditions.\" \"https://www.example.com/product/HK_5716.html\"\n+24/02/2018 03:45 1 AN-5096 $33.83 \"Organic Cotton Oxford Shirt, Plaid\" \"Introducing our most easygoing oxford ever. This plaid oxford shirt is made from the purest cotton organically sourced and 100% certified and washed for a super laid-back look and feel.\" \"https://www.example.com/product/AN_5096.html\"\n+25/02/2018 04:00 3 AN-8641 $65.18 Kids' Good Mocs \"Just like Mom and Dad our shearling slippers wrap completely around little feet for soft, cozy comfort.\" \"https://www.example.com/product/AN_8641.html\"\n+26/02/2018 04:15 2 ZN-4777 $34.14 \"Kids' Sweater Fleece, Hooded\" \"With its fleece warmth, sweatshirt styling, and fun colorblocking, our updated kids' Sweater Fleece is the perfect layer for the classroom and the world outside of it.\" \"https://www.example.com/product/ZN_4777.html\"\n+27/02/2018 04:30 0 ZN-2049 $83.32 \"Women's Hikers, Low Ventilated\" \"Youll be light on your feet with these ultralightweight, breathable hikers. But dont let the comfortable, airy construction fool you: they deliver all the protection and stability you expect from a trail shoe.\" \"https://www.example.com/product/ZN_2049.html\"\n+28/02/2018 04:45 3 GN-5043 $69.07 \"Women's Comfort Cycling Jersey, Short-Sleeve\" \"This women's quarter-zip cycling shirt is our most popular cycling jersey, thanks in part to sun protection that's built right in. With a more relaxed look and fit than most cycling apparel.\" \"https://www.example.com/product/GN_5043.html\"\n+13/03/2018 05:00 0 GN-9860 $24.86 \"Men's Boxer, 5\"\" Inseam\" \"Perfect for a day on the bonefish flats, these boxers are breathable, quick drying and just may become your everyday underwear.\" \"https://www.example.com/product/GN_9860.html\"\n+14/03/2018 05:15 1 YY-2600 $90.99 \"Kids' Mountain Bike, 24\"\"\" \"An easy-to-ride mountain bike that not only proves to be great fun for all the kids, but also offers great durability and stability.\" \"https://www.example.com/product/YY_2600.html\"\n+15/03/2018 05:30 1 YY-4017 $69.52 Leather Sofa \"Our American-made leather sofa exhibits quality craftsmanship in every detail and delivers lasting comfort through and through.\" \"https://www.example.com/product/YY_4017.html\"\n+16/03/2018 05:45 1 RI-9156 $53.62 Girls' Waterproof 3-in-1 Jacket \"This 3-in-1 girls' jacket offers three great options for one great price, so she'll stay warm, dry and comfortable whatever the weather.\" \"https://www.example.com/product/RI_9156.html\"\n+17/03/2018 06:00 1 RI-9121 $9.81 Women's No-Show Socks \"These ankle socks provide all-day comfort and no-show style. In a naturally breathable merino-wool blend that wicks moisture and dries quickly.\" \"https://www.example.com/product/RI_9121.html\"\n+18/03/2018 06:15 1 RI-7338 $43.53 Kids' Hat \"Let your kids show their spirit for adventure with our fun trucker-style hat, ready to go from trailhead to bus stop and back.\" \"https://www.example.com/product/RI_7338.html\"\n+19/03/2018 06:30 0 ZN-6172 $30.79 Men's Snowshoes Set \"Take your favorite hikes all winter long with these easy-to-use snowshoes. Best of all, this boxed set helps you save money and includes everything you need to get started: snowshoes, hiking poles and a tough snowshoe storage bag.\" \"https://www.example.com/product/ZN_6172.html\"\n+20/03/2018 06:45 0 YY-2057 $43.4 \"Tippet Material, Pro Freshwater\" \"This tippet is field tested in a variety of situations, from spring creeks to tidal rips, and is guaranteed to perform under the worst weather conditions.\" \"https://www.example.com/product/YY_2057.html\"\n+21/03/2018 07:00 1 BH-5486 $0.91 Women's Wet Suit \"Ideal for kayaking, paddle boarding and surfing, this wetsuit covers your core in 3 mm neoprene for maximum warmth, while 2 mm thickness on your arms and legs ensures your range of motion is at its best.\" \"https://www.example.com/product/BH_5486.html\"\n+22/03/2018 07:15 3 BH-1732 $65.46 \"Waterproof Boots, Tall\" \"Industry-leading insulation and innovative construction allow us to make these super-warm winter boots 50% lighter than traditional boots.\" \"https://www.example.com/product/BH_1732.html\"\n+24/03/2018 07:45 0 BH-4480 $51.42 \"Heated Insoles\" \"This pair of water-resistant, remote-controlled heated insoles features thermal technology engineered to keep your feet warm, not hot, to avoid sweating and freezing.\" \"https://www.example.com/product/BH_4480.html\"\n+25/03/2018 08:00 0 BH-1061 $62.55 \"Base Layer, Pants\" \"Our exclusive wool performance fabric makes these pants an ideal base layer for cool-weather sports.\" \"https://www.example.com/product/BH_1061.html\"\n+26/03/2018 08:15 2 ON-7017 $0.9 \"Quarter-Zip Hoodie, Camo\" \"This camo quarter-zip hoodie is an extremely versatile mid layer thats great for all hunting seasons. Its made from warm, breathable fleece and features an innovative lightweight hood with a built-in face mask.\" \"https://www.example.com/product/ON_7017.html\"\n+27/03/2018 08:30 3 ON-1026 $20.65 \"Tee, Traditional Fit, Short-Sleeve\" \"Made of soft cotton that resists wrinkles, stains, shrinking, fading and pilling, our resilient tee keeps its shape wash after wash.\" \"https://www.example.com/product/ON_1026.html\"\n+28/03/2018 08:45 4 AN-6109 $18.58 Kids' Pullover \"Just as good today as it was back then, our kids' retro fleece pullover combines our soft, warm, stretchy fleece with cool colorblock designs and our logo.\" \"https://www.example.com/product/AN_6109.html\"\n+29/03/2018 09:00 3 AN-9272 $57.75 Women's Essential Running Vest \"This lightweight fitness vest allows excellent freedom of movement while resisting wind and light rain, making it perfect for running, hiking, cycling or walks around town.\" \"https://www.example.com/product/AN_9272.html\"\n+30/03/2018 09:15 0 AN-1646 $78.74 \"Rolling Duffle, Extra-Large\" \"We kept the heritage-inspired design of our spacious rolling duffle, then added thoughtful details like easy-rolling spinner wheels.\" \"https://www.example.com/product/AN_1646.html\"\n+31/03/2018 09:30 0 AN-9388 $64.02 \"Linen Shirt, Slightly Fitted Short-Sleeve Stripe\" \"Lightweight and breathable, this colorful shirt will be a warm-weather mainstay year after year. Light and comfortable, perfect for summer.\" \"https://www.example.com/product/AN_9388.html\"\n+13/04/2018 11:00 4 YY-9611 $3.79 \"Women's Hunting Shoes, 10\"\"\" \"The original boot, made since 1912. Now with even more protection from cold, wet weather, with the addition of a waterproof liner and warm insulation.\" \"https://www.example.com/product/YY_9611.html\"\n+14/04/2018 11:15 12 RI-1639 $25.14 \"Men's Loafers, Leather/Nubuck\" \"Our finest leather Men's slip-on penny loafers are handstitched from supple, fine-grain nubuck leather that molds to your foot for a custom-like feel.\" \"https://www.example.com/product/RI_1639.html\"\n+16/04/2018 11:45 15 RI-3655 $45.12 Kids' Sneaker \"Designed with FAST fun in mind, these super cool kids' sneakers feature a sleek, engineered mesh upper and award-winning cushioning for all-day, action-packed comfort.\" \"https://www.example.com/product/RI_3655.html\"\n+17/04/2018 12:00 16 CC-5271 $38.81 \"Kids' Shirt, Short Sleeve, Graphic\" \"With its great coverage and UPF 50+ sun protection, this quick-drying kids' rashguard blocks the sun, but not the summer fun.\" \"https://www.example.com/product/CC_5271.html\"\n+18/04/2018 12:15 9 CC-9916 $75.06 Men's Biking Shorts \"Designed specifically for mountain biking, the cycling shorts are built with performance features such as breathable, moisture-wicking fabric and chamois padding, with a casual, relaxed fit for comfort on and off the bike.\" \"https://www.example.com/product/CC_9916.html\"\n+19/04/2018 12:30 9 YY-7121 $67.64 Backpacking Stove Kit \"Our lightest, most compact 2-person cookset nests together to save space. Includes a stove, a two-liter hard anodized aluminum pot with clear strainer lid, 2 bowls, 2-12.5 oz. double-wall insulated mugs and 2 folding sporks.\" \"https://www.example.com/product/YY_7121.html\"\n+20/04/2018 12:45 15 YY-8954 $64.19 \"Travel Lock, Combination Cable\" \"This luggage lock helps keep your belongings secure while traveling. Allows your luggage to go through airport security and arrive at your destination fully locked.\" \"https://www.example.com/product/YY_8954.html\"\n+21/04/2018 13:00 8 YY-8239 $72 Men's Boots \"Here, when we call something good we mean it: just one touch of these soft men's boot slippers and you'll understand why.\" \"https://www.example.com/product/YY_8239.html\"\n+23/04/2018 13:30 26 BH-2268 $43.61 Men's Shorts \"We used performance-packed swim fabric to create board shorts that keep up during the most rigorous adventures, with enough style for heading into town afterward.\" \"https://www.example.com/product/BH_2268.html\"\n+25/04/2018 14:00 16 BH-4482 $53.95 Portable Game Center \"This portable game center will provide hours of fun at your barbecue, tailgate, beach trip and more. With easy set-up and take-down, you can take it anywhere.\" \"https://www.example.com/product/BH_4482.html\"\n+26/04/2018 14:15 22 HK-4191 $3.35 \"Women's Waterproof Hiking Boots, Leather Mesh\" \"The classic alpine hiker is back, with retro style and all-day comfort you'll want to wear beyond the trail.\" \"https://www.example.com/product/HK_4191.html\"\n+29/04/2018 15:00 30 AN-5829 $2.86 Women's Booties \"Inspired by the legendary comfort of our slippers, we designed these warm slipper booties to be so cozy you'll never want to take them off. The durable knit lambswool upper is lined with toasty fleece that wraps your feet in luxury.\" \"https://www.example.com/product/AN_5829.html\"\n+13/05/2018 18:45 24 BH-7941 $64.17 Cotton/Linen Ragg Sweater \"An ultracozy take on the classic ragg sweater. We created this swing sweater from beautifully marled cotton with linen for amazing texture.\" \"https://www.example.com/product/BH_7941.html\"\n+15/05/2018 19:15 18 HK-8027 $26.62 Camp Stove Bundle with Coffee Press \"This unique bundle includes the wood-burning camp Stove, Portable Grill, Kettle Pot with Coffee Press and a USB Lantern.\" \"https://www.example.com/product/HK_8027.html\"\n+18/05/2018 20:00 30 AN-2099 $64.14 Sandals \"An exclusive, these colorblocked sandals are an absolutely beautiful and incredibly comfortable addition to your warm-weather wardrobe.\" \"https://www.example.com/product/AN_2099.html\"\n+19/05/2018 20:15 33 AN-5746 $83.75 \"Flannel Tunic, Plaid\" \"Our most rugged flannel shirt is also one of the softest - double brushed for an exceptional feel. Made from heavyweight organic cotton in a flattering longer length.\" \"https://www.example.com/product/AN_5746.html\"\n+20/05/2018 20:30 16 AN-5136 $39.41 Ragg Wool Hat \"Our traditional ragg wool hat is thickly knit from soft lambswool yarns and keeps on insulating, even when wet.\" \"https://www.example.com/product/AN_5136.html\"\n+21/05/2018 20:45 21 ZN-5503 $88.45 Coffee Table \"Spend more time relaxing outside with our low-maintenance coffee table. Like all of our furniture, it won't chip, peel, warp or crack.\" \"https://www.example.com/product/ZN_5503.html\"\n+22/05/2018 21:00 19 ZN-4103 $68.74 Baseball Hat \"This sun-blocking baseball hat features a rear flap for extra coverage. It provides UPF 50+ rated sun protection, the highest possible.\" \"https://www.example.com/product/ZN_4103.html\"\n+23/05/2018 21:15 2 GN-1741 $48.05 \"Beach Chair, Print\" \"With four reclining positions and backpack straps for easy carrying, this is the most comfortable and convenient folding beach chair we've ever offered.\" \"https://www.example.com/product/GN_1741.html\"\n+24/05/2018 21:30 1 GN-5567 $26.87 Men's Reversible Jacket \"Designed to be the ultimate reversible jacket with two great options. We took the cozy comfort of plush fleece and combined it with the ultralight warmth of our insulation.\" \"https://www.example.com/product/GN_5567.html\"\n+25/05/2018 21:45 0 GN-3028 $12.98 \"Swimwear, Print\" \"With flattering coverage, amazing stay-put shape and quick-dry comfort, our best-value one-piece bathing suit is designed for sun and surf. Made from premium Italian swim fabric in fun wave print.\" \"https://www.example.com/product/GN_3028.html\"\n+26/05/2018 22:00 2 YY-4147 $11.06 Women's Sandals \"You wont find a sandal with better control or support than this. Its loaded with features like secure double-strap webbing, a podiatrist-certified footbed and a toe loop for extra forefoot stability.\" \"https://www.example.com/product/YY_4147.html\"\n+27/05/2018 22:15 0 WH-3118 $31.06 Men's Ear Warmer \"Designed to resist wind and water, these click-to-fit ear warmers are made with insulation for even more warmth during outdoor activities.\" \"https://www.example.com/product/WH_3118.html\"\n+28/05/2018 22:30 1 WH-2859 $72.91 \"Tee, Traditional Fit, Long-Sleeve\" \"Made of soft cotton that resists wrinkles, stains, shrinking, fading and pilling, our resilient tee keeps its shape wash after wash.\" \"https://www.example.com/product/WH_2859.html\"\n+30/05/2018 23:00 1 CC-2828 $79.36 \"Camp Light, Two-Pack\" \"Collapsed or extended, our lightweight camp lights take up minimal space, making them handy to bring on hikes and camping trips, and easy to keep on hand in case of a power outage.\" \"https://www.example.com/product/CC_2828.html\"\n+31/05/2018 15:30 3 HK-9973 $39.49 Women's Ventilated Hiking Shoes \"This lightweight, ventilated version of the best-selling trail hiker features less volume in the forefoot for a more athletic fit. It's also equipped with a grippier outsole that excels in both wet and dry conditions.\" \"https://www.example.com/product/HK_9973.html\"\n+21/06/2018 23:15 1 CC-5815 $13.57 Field Watch \"Inspired by watches worn by World War II infantrymen, this updated design makes it easy to tell time at a glance. New smaller size is perfect for men and women who want a classic field watch that's perfect for all occasions, both indoor and outdoor.\" \"https://www.example.com/product/CC_5815.html\"\n+22/06/2018 23:30 1 YY-2632 $27.84 Women's Capris \"These great cargo capris pants for women are designed for performance, with built-in UPF 50+ to keep you cool, dry, and protected from the sun while you're out enjoying it.\" \"https://www.example.com/product/YY_2632.html\"\n+23/06/2018 23:45 0 YY-1196 $90.15 Girls' Tee \"This girls' fitness tee controls moisture and odor: all at a great price, perfect for camp, sports and play.\" \"https://www.example.com/product/YY_1196.html\"\n+24/06/2018 00:00 0 YY-1894 $13.52 \"Men's Socks, Two-Pack\" \"Made of moisture-wicking merino wool with nylon for durability and spandex for shape-retaining stretch, these soft, form-fitting men's chino socks offer all-day comfort at home or work.\" \"https://www.example.com/product/YY_1894.html\"\n+26/06/2018 00:30 0 BH-1861 $82.12 Women's Socks \"These ankle socks provide all-day comfort and no-show style. In a naturally breathable merino-wool blend that wicks moisture and dries quickly.\" \"https://www.example.com/product/BH_1861.html\"\n+27/06/2018 17:15 1 RI-7731 $65.13 \"Ceramic Lamp, Stripe\" \"Bring light, texture and classic style to any space with this coast-inspired striped ceramic table lamp.\" \"https://www.example.com/product/RI_7731.html\"\n+29/06/2018 10:00 1 ZN-7072 $88.21 Kids' High Handles Boots \"Parents and little ones alike swear by this warm weatherproofing. Just pull these kids' handle boots on and seal the cold, wet weather out.\" \"https://www.example.com/product/ZN_7072.html\"\n+30/06/2018 10:15 2 GN-1306 $78.95 National Park Patch \"Were proud to offer the National Park collectible patch, featuring an embroidered scene of a breathtaking, rugged coastline.\" \"https://www.example.com/product/GN_1306.html\"\n+13/07/2018 10:30 1 GN-7767 $25.88 Men's Versatile Tote \"We combined details with your everyday needs to create this: an exceptional quality tote with a laptop compartment and enough room for all your other essentials.\" \"https://www.example.com/product/GN_7767.html\"\n+14/07/2018 10:45 0 GN-4624 $24.52 Summer Slip-On Sneakers \"Run a 5K, rock hop at the shore, window shop in town - these summer slip-on sneakers do it all. They're breathable, quick drying and comfortably cushioned for whatever your day has in store.\" \"https://www.example.com/product/GN_4624.html\"\n+15/07/2018 16:45 20 RI-7676 $7.49 Kids' Hydration Pack \"Designed after the most popular adult hydration pack, this hydration pack measures up to your kids' trail hydration needs and your highest expectations.\" \"https://www.example.com/product/RI_7676.html\"\n+16/07/2018 17:00 3 RI-5314 $76.26 Fishing Sunglasses \"These sunglasses are made for fishermen with large faces. The taller lens shape and thicker temples provide additional sun protection, great for fishermen who spend a lot of time on the water.\" \"https://www.example.com/product/RI_5314.html\"\n+17/07/2018 16:30 0 YY-7734 $73.42 Havana Hat \"The perfect complement to any summertime style: this fedora hat offers UPF 50+ protection and won't crunch or bend during your travels.\" \"https://www.example.com/product/YY_7734.html\"\n+18/07/2018 17:30 1 BH-7744 $56.76 Headlamp \"With proprietary construction, a front profile of only 9mm and weighing only 2.4 oz., this bright headlamp sits comfortably on your forehead without bouncing or slipping.\" \"https://www.example.com/product/BH_7744.html\"\n+19/07/2018 17:45 1 YY-8580 $6.31 \"Underwear, Print\" \"Our built-in fabric technology traps your body heat and keeps you up to 7 degrees warmer: for comfort as the days and months get colder.\" \"https://www.example.com/product/YY_8580.html\"\n+20/07/2018 18:00 1 BH-7918 $63.7 Kids' Jumper Hat \"With ski-inspired style and a toasty, fleece-lined earband, staying warm on the slopes has never looked cooler.\" \"https://www.example.com/product/BH_7918.html\"\n+22/07/2018 18:30 1 BH-1085 $85.07 Heated Insoles \"This pair of water-resistant, remote-controlled heated insoles features thermal technology engineered to keep your feet warm, not hot, to avoid sweating and freezing.\" \"https://www.example.com/product/BH_1085.html\"\n+24/07/2018 16:00 6 GN-2043 $23.25 \"Men's Boots, 10\"\" Shearling-Lined\" \"With waterproof leather outside and soft, plush shearling inside, our lined Boots are very possibly the coolest, warmest boots ever. Handcrafted right here.\" \"https://www.example.com/product/GN_2043.html\"\ndiff --git a/data/csv/pollock/file_quotation_char_0x27.csv b/data/csv/pollock/file_quotation_char_0x27.csv\nnew file mode 100644\nindex 000000000000..d8461eb582b4\n--- /dev/null\n+++ b/data/csv/pollock/file_quotation_char_0x27.csv\n@@ -0,0 +1,1 @@\n+31/05/2018,15:30,3,HK-9973,$39.49,Women's Ventilated Hiking Shoes,'This lightweight, ventilated version of the best-selling trail hiker features less volume in the forefoot for a more athletic fit. It's also equipped with a grippier outsole that excels in both wet and dry conditions.','https://www.example.com/product/HK_9973.html',\ndiff --git a/data/json/internal_4014.json b/data/json/internal_4014.json\nnew file mode 100644\nindex 000000000000..ad8744628ff8\n--- /dev/null\n+++ b/data/json/internal_4014.json\n@@ -0,0 +1,15 @@\n+{\n+   \"s4\": {\"1\": [1]},\n+ \"a\": {\n+    \"s1\": {\"1\": null},\n+    \"s2\": {\"1\": {}},\n+    \"s3\": {\"1\": \"1\"},\n+    \"s4\": {\"1\": [1]},\n+    \"s5\": {\"1\": 1},\n+    \"s6\": {\"1\": \"1\"},\n+    \"s7\": {\"1\": [1]},\n+    \"s8\": {\"1\": 1},\n+    \"s9\": {\"1\": \"1\"},\n+    \"s10\": {\"1\": [1]}\n+  }\n+}\n\\ No newline at end of file\ndiff --git a/extension/autocomplete/autocomplete_extension.cpp b/extension/autocomplete/autocomplete_extension.cpp\nindex 99087fe6a2f9..62db1f89ae63 100644\n--- a/extension/autocomplete/autocomplete_extension.cpp\n+++ b/extension/autocomplete/autocomplete_extension.cpp\n@@ -481,11 +481,7 @@ std::string AutocompleteExtension::Name() {\n }\n \n std::string AutocompleteExtension::Version() const {\n-#ifdef EXT_VERSION_AUTOCOMPLETE\n-\treturn EXT_VERSION_AUTOCOMPLETE;\n-#else\n-\treturn \"\";\n-#endif\n+\treturn DefaultVersion();\n }\n \n } // namespace duckdb\n@@ -496,7 +492,7 @@ DUCKDB_EXTENSION_API void autocomplete_init(duckdb::DatabaseInstance &db) {\n }\n \n DUCKDB_EXTENSION_API const char *autocomplete_version() {\n-\treturn duckdb::DuckDB::LibraryVersion();\n+\treturn duckdb::AutocompleteExtension::DefaultVersion();\n }\n }\n \ndiff --git a/extension/core_functions/function_list.cpp b/extension/core_functions/function_list.cpp\nindex fb8550c677ba..9051c60047c0 100644\n--- a/extension/core_functions/function_list.cpp\n+++ b/extension/core_functions/function_list.cpp\n@@ -136,6 +136,7 @@ static const StaticFunctionDefinition core_functions[] = {\n \tDUCKDB_AGGREGATE_FUNCTION(CovarPopFun),\n \tDUCKDB_AGGREGATE_FUNCTION(CovarSampFun),\n \tDUCKDB_SCALAR_FUNCTION(CurrentDatabaseFun),\n+\tDUCKDB_SCALAR_FUNCTION(CurrentDateFun),\n \tDUCKDB_SCALAR_FUNCTION(CurrentQueryFun),\n \tDUCKDB_SCALAR_FUNCTION(CurrentSchemaFun),\n \tDUCKDB_SCALAR_FUNCTION(CurrentSchemasFun),\n@@ -192,6 +193,7 @@ static const StaticFunctionDefinition core_functions[] = {\n \tDUCKDB_SCALAR_FUNCTION_ALIAS(GenRandomUuidFun),\n \tDUCKDB_SCALAR_FUNCTION_SET(GenerateSeriesFun),\n \tDUCKDB_SCALAR_FUNCTION(GetBitFun),\n+\tDUCKDB_SCALAR_FUNCTION(CurrentTimeFun),\n \tDUCKDB_SCALAR_FUNCTION(GetCurrentTimestampFun),\n \tDUCKDB_SCALAR_FUNCTION_SET_ALIAS(GradeUpFun),\n \tDUCKDB_SCALAR_FUNCTION_SET(GreatestFun),\n@@ -369,6 +371,7 @@ static const StaticFunctionDefinition core_functions[] = {\n \tDUCKDB_SCALAR_FUNCTION(ToTimestampFun),\n \tDUCKDB_SCALAR_FUNCTION(ToWeeksFun),\n \tDUCKDB_SCALAR_FUNCTION(ToYearsFun),\n+\tDUCKDB_SCALAR_FUNCTION_ALIAS(TodayFun),\n \tDUCKDB_SCALAR_FUNCTION_ALIAS(TransactionTimestampFun),\n \tDUCKDB_SCALAR_FUNCTION(TranslateFun),\n \tDUCKDB_SCALAR_FUNCTION_SET(TrimFun),\ndiff --git a/extension/core_functions/include/core_functions/scalar/date_functions.hpp b/extension/core_functions/include/core_functions/scalar/date_functions.hpp\nindex 7256502a9c50..efa9821d1d36 100644\n--- a/extension/core_functions/include/core_functions/scalar/date_functions.hpp\n+++ b/extension/core_functions/include/core_functions/scalar/date_functions.hpp\n@@ -33,6 +33,21 @@ struct CenturyFun {\n \tstatic ScalarFunctionSet GetFunctions();\n };\n \n+struct CurrentDateFun {\n+\tstatic constexpr const char *Name = \"current_date\";\n+\tstatic constexpr const char *Parameters = \"\";\n+\tstatic constexpr const char *Description = \"Returns the current date\";\n+\tstatic constexpr const char *Example = \"current_date()\";\n+\n+\tstatic ScalarFunction GetFunction();\n+};\n+\n+struct TodayFun {\n+\tusing ALIAS = CurrentDateFun;\n+\n+\tstatic constexpr const char *Name = \"today\";\n+};\n+\n struct DateDiffFun {\n \tstatic constexpr const char *Name = \"date_diff\";\n \tstatic constexpr const char *Parameters = \"part,startdate,enddate\";\n@@ -183,6 +198,15 @@ struct EpochNsFun {\n \tstatic ScalarFunctionSet GetFunctions();\n };\n \n+struct CurrentTimeFun {\n+\tstatic constexpr const char *Name = \"get_current_time\";\n+\tstatic constexpr const char *Parameters = \"\";\n+\tstatic constexpr const char *Description = \"Returns the current time\";\n+\tstatic constexpr const char *Example = \"get_current_time()\";\n+\n+\tstatic ScalarFunction GetFunction();\n+};\n+\n struct EraFun {\n \tstatic constexpr const char *Name = \"era\";\n \tstatic constexpr const char *Parameters = \"ts\";\ndiff --git a/extension/core_functions/scalar/date/current.cpp b/extension/core_functions/scalar/date/current.cpp\nindex 3d25ee80a0e3..61867f271d60 100644\n--- a/extension/core_functions/scalar/date/current.cpp\n+++ b/extension/core_functions/scalar/date/current.cpp\n@@ -6,6 +6,7 @@\n #include \"duckdb/main/client_context.hpp\"\n #include \"duckdb/planner/expression/bound_function_expression.hpp\"\n #include \"duckdb/transaction/meta_transaction.hpp\"\n+#include \"duckdb/planner/expression/bound_cast_expression.hpp\"\n \n namespace duckdb {\n \n@@ -26,4 +27,41 @@ ScalarFunction GetCurrentTimestampFun::GetFunction() {\n \treturn current_timestamp;\n }\n \n+static unique_ptr<Expression> CurrentTimeExpr(FunctionBindExpressionInput &input) {\n+\tauto timestamp = GetCurrentTimestampFun::GetFunction();\n+\ttimestamp.name = GetCurrentTimestampFun::Name;\n+\n+\tvector<unique_ptr<Expression>> args;\n+\n+\tauto func = make_uniq_base<Expression, BoundFunctionExpression>(LogicalType::TIMESTAMP_TZ, timestamp,\n+\t                                                                std::move(args), nullptr);\n+\n+\treturn BoundCastExpression::AddCastToType(input.context, std::move(func), LogicalType::TIME_TZ);\n+}\n+\n+static unique_ptr<Expression> CurrentDateExpr(FunctionBindExpressionInput &input) {\n+\tauto timestamp = GetCurrentTimestampFun::GetFunction();\n+\ttimestamp.name = GetCurrentTimestampFun::Name;\n+\n+\tvector<unique_ptr<Expression>> args;\n+\n+\tauto func = make_uniq_base<Expression, BoundFunctionExpression>(LogicalType::TIMESTAMP_TZ, timestamp,\n+\t                                                                std::move(args), nullptr);\n+\treturn BoundCastExpression::AddCastToType(input.context, std::move(func), LogicalType::DATE);\n+}\n+\n+ScalarFunction CurrentTimeFun::GetFunction() {\n+\tScalarFunction current_time({}, LogicalType::TIME_TZ, nullptr);\n+\tcurrent_time.bind_expression = CurrentTimeExpr;\n+\tcurrent_time.stability = FunctionStability::CONSISTENT_WITHIN_QUERY;\n+\treturn current_time;\n+}\n+\n+ScalarFunction CurrentDateFun::GetFunction() {\n+\tScalarFunction current_date({}, LogicalType::DATE, nullptr);\n+\tcurrent_date.bind_expression = CurrentDateExpr;\n+\tcurrent_date.stability = FunctionStability::CONSISTENT_WITHIN_QUERY;\n+\treturn current_date;\n+}\n+\n } // namespace duckdb\ndiff --git a/extension/core_functions/scalar/date/functions.json b/extension/core_functions/scalar/date/functions.json\nindex 6cc719b38651..4a1a36e8d2a3 100644\n--- a/extension/core_functions/scalar/date/functions.json\n+++ b/extension/core_functions/scalar/date/functions.json\n@@ -13,6 +13,13 @@\n         \"example\": \"century(timestamp '2021-08-03 11:59:44.123456')\",\n         \"type\": \"scalar_function_set\"\n     },\n+    {\n+        \"name\": \"current_date\",\n+        \"description\": \"Returns the current date\",\n+        \"example\": \"current_date()\",\n+        \"type\": \"scalar_function\",\n+        \"aliases\": [\"today\"]\n+    },\n     {\n         \"name\": \"date_diff\",\n         \"parameters\": \"part,startdate,enddate\",\n@@ -119,6 +126,13 @@\n         \"example\": \"epoch_ns(timestamp '2021-08-03 11:59:44.123456')\",\n         \"type\": \"scalar_function_set\"\n     },\n+    {\n+        \"struct\": \"CurrentTimeFun\",\n+        \"name\": \"get_current_time\",\n+        \"description\": \"Returns the current time\",\n+        \"example\": \"get_current_time()\",\n+        \"type\": \"scalar_function\"\n+    },\n     {\n         \"name\": \"era\",\n         \"parameters\": \"ts\",\ndiff --git a/extension/core_functions/scalar/generic/can_implicitly_cast.cpp b/extension/core_functions/scalar/generic/can_implicitly_cast.cpp\nindex 5db38d601905..5949dcc37c70 100644\n--- a/extension/core_functions/scalar/generic/can_implicitly_cast.cpp\n+++ b/extension/core_functions/scalar/generic/can_implicitly_cast.cpp\n@@ -18,8 +18,8 @@ static void CanCastImplicitlyFunction(DataChunk &args, ExpressionState &state, V\n }\n \n unique_ptr<Expression> BindCanCastImplicitlyExpression(FunctionBindExpressionInput &input) {\n-\tauto &source_type = input.function.children[0]->return_type;\n-\tauto &target_type = input.function.children[1]->return_type;\n+\tauto &source_type = input.children[0]->return_type;\n+\tauto &target_type = input.children[1]->return_type;\n \tif (source_type.id() == LogicalTypeId::UNKNOWN || source_type.id() == LogicalTypeId::SQLNULL ||\n \t    target_type.id() == LogicalTypeId::UNKNOWN || target_type.id() == LogicalTypeId::SQLNULL) {\n \t\t// parameter - unknown return type\ndiff --git a/extension/core_functions/scalar/generic/typeof.cpp b/extension/core_functions/scalar/generic/typeof.cpp\nindex 1f7caef848ce..895d474f429d 100644\n--- a/extension/core_functions/scalar/generic/typeof.cpp\n+++ b/extension/core_functions/scalar/generic/typeof.cpp\n@@ -10,7 +10,7 @@ static void TypeOfFunction(DataChunk &args, ExpressionState &state, Vector &resu\n }\n \n unique_ptr<Expression> BindTypeOfFunctionExpression(FunctionBindExpressionInput &input) {\n-\tauto &return_type = input.function.children[0]->return_type;\n+\tauto &return_type = input.children[0]->return_type;\n \tif (return_type.id() == LogicalTypeId::UNKNOWN || return_type.id() == LogicalTypeId::SQLNULL) {\n \t\t// parameter - unknown return type\n \t\treturn nullptr;\ndiff --git a/extension/json/json_functions/json_structure.cpp b/extension/json/json_functions/json_structure.cpp\nindex fbc71366ef92..260f7984a671 100644\n--- a/extension/json/json_functions/json_structure.cpp\n+++ b/extension/json/json_functions/json_structure.cpp\n@@ -662,7 +662,9 @@ static double CalculateTypeSimilarity(const LogicalType &merged, const LogicalTy\n \t\t}\n \n \t\t// Only maps and structs can be merged into a map\n-\t\tD_ASSERT(type.id() == LogicalTypeId::STRUCT);\n+\t\tif (type.id() != LogicalTypeId::STRUCT) {\n+\t\t\treturn -1;\n+\t\t}\n \t\treturn CalculateMapAndStructSimilarity(merged, type, false, max_depth, depth);\n \t}\n \tcase LogicalTypeId::LIST: {\ndiff --git a/extension/parquet/include/resizable_buffer.hpp b/extension/parquet/include/resizable_buffer.hpp\nindex 14658ecee85b..1e225d510320 100644\n--- a/extension/parquet/include/resizable_buffer.hpp\n+++ b/extension/parquet/include/resizable_buffer.hpp\n@@ -98,6 +98,7 @@ class ResizeableBuffer : public ByteBuffer {\n \t\t}\n \t\tif (new_size > alloc_len) {\n \t\t\talloc_len = NextPowerOfTwo(new_size);\n+\t\t\tallocated_data.Reset(); // Have to reset before allocating new buffer (otherwise we use ~2x the memory)\n \t\t\tallocated_data = allocator.Allocate(alloc_len);\n \t\t\tptr = allocated_data.get();\n \t\t}\ndiff --git a/extension/parquet/parquet_extension.cpp b/extension/parquet/parquet_extension.cpp\nindex 8ec9924a67bf..a9e8b20e4830 100644\n--- a/extension/parquet/parquet_extension.cpp\n+++ b/extension/parquet/parquet_extension.cpp\n@@ -1497,18 +1497,19 @@ static void ParquetCopySerialize(Serializer &serializer, const FunctionData &bin\n \t// We have to std::move them, otherwise MSVC will complain that it's not a \"const T &&\"\n \tconst auto compression_level = SerializeCompressionLevel(bind_data.compression_level);\n \tD_ASSERT(DeserializeCompressionLevel(compression_level) == bind_data.compression_level);\n+\tParquetWriteBindData default_value;\n \tserializer.WritePropertyWithDefault(109, \"compression_level\", compression_level);\n \tserializer.WritePropertyWithDefault(110, \"row_groups_per_file\", bind_data.row_groups_per_file,\n-\t                                    std::move(ParquetWriteBindData().row_groups_per_file));\n+\t                                    std::move(default_value.row_groups_per_file));\n \tserializer.WritePropertyWithDefault(111, \"debug_use_openssl\", bind_data.debug_use_openssl,\n-\t                                    std::move(ParquetWriteBindData().debug_use_openssl));\n+\t                                    std::move(default_value.debug_use_openssl));\n \tserializer.WritePropertyWithDefault(112, \"dictionary_size_limit\", bind_data.dictionary_size_limit,\n-\t                                    std::move(ParquetWriteBindData().dictionary_size_limit));\n+\t                                    std::move(default_value.dictionary_size_limit));\n \tserializer.WritePropertyWithDefault(113, \"bloom_filter_false_positive_ratio\",\n \t                                    bind_data.bloom_filter_false_positive_ratio,\n-\t                                    std::move(ParquetWriteBindData().bloom_filter_false_positive_ratio));\n+\t                                    std::move(default_value.bloom_filter_false_positive_ratio));\n \tserializer.WritePropertyWithDefault(114, \"parquet_version\", bind_data.parquet_version,\n-\t                                    std::move(ParquetWriteBindData().parquet_version));\n+\t                                    std::move(default_value.parquet_version));\n }\n \n static unique_ptr<FunctionData> ParquetCopyDeserialize(Deserializer &deserializer, CopyFunction &function) {\n@@ -1528,16 +1529,17 @@ static unique_ptr<FunctionData> ParquetCopyDeserialize(Deserializer &deserialize\n \tdeserializer.ReadPropertyWithDefault<optional_idx>(109, \"compression_level\", compression_level);\n \tdata->compression_level = DeserializeCompressionLevel(compression_level);\n \tD_ASSERT(SerializeCompressionLevel(data->compression_level) == compression_level);\n+\tParquetWriteBindData default_value;\n \tdata->row_groups_per_file = deserializer.ReadPropertyWithExplicitDefault<optional_idx>(\n-\t    110, \"row_groups_per_file\", std::move(ParquetWriteBindData().row_groups_per_file));\n+\t    110, \"row_groups_per_file\", std::move(default_value.row_groups_per_file));\n \tdata->debug_use_openssl = deserializer.ReadPropertyWithExplicitDefault<bool>(\n-\t    111, \"debug_use_openssl\", std::move(ParquetWriteBindData().debug_use_openssl));\n+\t    111, \"debug_use_openssl\", std::move(default_value.debug_use_openssl));\n \tdata->dictionary_size_limit = deserializer.ReadPropertyWithExplicitDefault<idx_t>(\n-\t    112, \"dictionary_size_limit\", std::move(ParquetWriteBindData().dictionary_size_limit));\n+\t    112, \"dictionary_size_limit\", std::move(default_value.dictionary_size_limit));\n \tdata->bloom_filter_false_positive_ratio = deserializer.ReadPropertyWithExplicitDefault<double>(\n-\t    113, \"bloom_filter_false_positive_ratio\", std::move(ParquetWriteBindData().bloom_filter_false_positive_ratio));\n-\tdata->parquet_version = deserializer.ReadPropertyWithExplicitDefault(\n-\t    114, \"parquet_version\", std::move(ParquetWriteBindData().parquet_version));\n+\t    113, \"bloom_filter_false_positive_ratio\", std::move(default_value.bloom_filter_false_positive_ratio));\n+\tdata->parquet_version =\n+\t    deserializer.ReadPropertyWithExplicitDefault(114, \"parquet_version\", std::move(default_value.parquet_version));\n \n \treturn std::move(data);\n }\ndiff --git a/extension/tpch/dbgen/dbgen.cpp b/extension/tpch/dbgen/dbgen.cpp\nindex 09a1aaac71e2..093b255a422b 100644\n--- a/extension/tpch/dbgen/dbgen.cpp\n+++ b/extension/tpch/dbgen/dbgen.cpp\n@@ -659,16 +659,24 @@ void DBGenWrapper::LoadTPCHData(ClientContext &context, double flt_scale, string\n \t\t\t\tthreads.emplace_back(ParallelTPCHAppend, &new_appenders[thr_idx], child_count, step);\n \t\t\t\tstep++;\n \t\t\t}\n-\t\t\t// flush the previous batch of appenders while waiting (if any are there)\n-\t\t\t// now flush the appenders in-order\n-\t\t\tfor(auto &appender : finished_appenders) {\n-\t\t\t\tappender.Flush();\n+\t\t\tErrorData error;\n+\t\t\ttry {\n+\t\t\t\t// flush the previous batch of appenders while waiting (if any are there)\n+\t\t\t\t// now flush the appenders in-order\n+\t\t\t\tfor(auto &appender : finished_appenders) {\n+\t\t\t\t\tappender.Flush();\n+\t\t\t\t}\n+\t\t\t} catch(std::exception &ex) {\n+\t\t\t\terror = ErrorData(ex);\n \t\t\t}\n \t\t\tfinished_appenders.clear();\n \t\t\t// wait for all threads to finish\n \t\t\tfor(auto &thread : threads) {\n \t\t\t\tthread.join();\n \t\t\t}\n+\t\t\tif (error.HasError()) {\n+\t\t\t\terror.Throw();\n+\t\t\t}\n \t\t\tfinished_appenders = std::move(new_appenders);\n \t\t}\n \t\t// flush the final batch of appenders\ndiff --git a/scripts/generate_benchmarks.py b/scripts/generate_benchmarks.py\ndeleted file mode 100644\nindex 089bd0adef03..000000000000\n--- a/scripts/generate_benchmarks.py\n+++ /dev/null\n@@ -1,37 +0,0 @@\n-import os\n-from python_helpers import open_utf8\n-\n-\n-def format_tpch_queries(target_dir, tpch_in, comment):\n-    with open_utf8(tpch_in, 'r') as f:\n-        text = f.read()\n-\n-    for i in range(1, 23):\n-        qnr = '%02d' % (i,)\n-        target_file = os.path.join(target_dir, 'q' + qnr + '.benchmark')\n-        new_text = '''# name: %s\n-# description: Run query %02d from the TPC-H benchmark (%s)\n-# group: [sf1]\n-\n-template %s\n-QUERY_NUMBER=%d\n-QUERY_NUMBER_PADDED=%02d''' % (\n-            target_file,\n-            i,\n-            comment,\n-            tpch_in,\n-            i,\n-            i,\n-        )\n-        with open_utf8(target_file, 'w+') as f:\n-            f.write(new_text)\n-\n-\n-# generate the TPC-H benchmark files\n-single_threaded_dir = os.path.join('benchmark', 'tpch', 'sf1')\n-single_threaded_in = os.path.join(single_threaded_dir, 'tpch_sf1.benchmark.in')\n-format_tpch_queries(single_threaded_dir, single_threaded_in, 'single-threaded')\n-\n-parallel_threaded_dir = os.path.join('benchmark', 'tpch', 'sf1-parallel')\n-parallel_threaded_in = os.path.join(parallel_threaded_dir, 'tpch_sf1_parallel.benchmark.in')\n-format_tpch_queries(parallel_threaded_dir, parallel_threaded_in, '4 threads')\ndiff --git a/scripts/generate_extensions_function.py b/scripts/generate_extensions_function.py\nindex 15417eb76c0a..eefd6dfffb06 100644\n--- a/scripts/generate_extensions_function.py\n+++ b/scripts/generate_extensions_function.py\n@@ -363,16 +363,10 @@ def __init__(self):\n         self.extensions: Dict[str, str] = get_extension_path_map()\n \n         self.stored_functions: Dict[str, List[Function]] = {\n-            'substrait': [\n-                Function(\"from_substrait\", CatalogType.TABLE),\n-                Function(\"get_substrait\", CatalogType.TABLE),\n-                Function(\"get_substrait_json\", CatalogType.TABLE),\n-                Function(\"from_substrait_json\", CatalogType.TABLE),\n-            ],\n             'arrow': [Function(\"scan_arrow_ipc\", CatalogType.TABLE), Function(\"to_arrow_ipc\", CatalogType.TABLE)],\n             'spatial': [],\n         }\n-        self.stored_settings: Dict[str, List[str]] = {'substrait': [], 'arrow': [], 'spatial': []}\n+        self.stored_settings: Dict[str, List[str]] = {'arrow': [], 'spatial': []}\n \n     def set_base(self):\n         (functions, function_overloads) = get_functions()\n@@ -718,6 +712,7 @@ def write_header(data: ExtensionData):\n     \"excel\",\n     \"fts\",\n     \"httpfs\",\n+    \"iceberg\",\n     \"inet\",\n     \"icu\",\n     \"json\",\n@@ -728,7 +723,8 @@ def write_header(data: ExtensionData):\n     \"sqlsmith\",\n     \"postgres_scanner\",\n     \"tpcds\",\n-    \"tpch\"\n+    \"tpch\",\n+    \"uc_catalog\"\n }; // END_OF_AUTOLOADABLE_EXTENSIONS\n \n } // namespace duckdb\"\"\"\ndiff --git a/src/catalog/default/default_functions.cpp b/src/catalog/default/default_functions.cpp\nindex 7702bc4e0fdf..480e05f81081 100644\n--- a/src/catalog/default/default_functions.cpp\n+++ b/src/catalog/default/default_functions.cpp\n@@ -163,9 +163,6 @@ static const DefaultMacro internal_macros[] = {\n \n \t// date functions\n \t{DEFAULT_SCHEMA, \"date_add\", {\"date\", \"interval\", nullptr}, {{nullptr, nullptr}}, \"date + interval\"},\n-\t{DEFAULT_SCHEMA, \"current_date\", {nullptr}, {{nullptr, nullptr}}, \"current_timestamp::DATE\"},\n-\t{DEFAULT_SCHEMA, \"today\", {nullptr}, {{nullptr, nullptr}}, \"current_timestamp::DATE\"},\n-\t{DEFAULT_SCHEMA, \"get_current_time\", {nullptr}, {{nullptr, nullptr}}, \"current_timestamp::TIMETZ\"},\n \n \t// regexp functions\n \t{DEFAULT_SCHEMA, \"regexp_split_to_table\", {\"text\", \"pattern\", nullptr}, {{nullptr, nullptr}}, \"unnest(string_split_regex(text, pattern))\"},\ndiff --git a/src/common/adbc/adbc.cpp b/src/common/adbc/adbc.cpp\nindex 7323f3b1f337..35ceb2f3406f 100644\n--- a/src/common/adbc/adbc.cpp\n+++ b/src/common/adbc/adbc.cpp\n@@ -53,7 +53,6 @@ AdbcStatusCode duckdb_adbc_init(int version, void *driver, struct AdbcError *err\n \tadbc_driver->ConnectionGetInfo = duckdb_adbc::ConnectionGetInfo;\n \tadbc_driver->StatementGetParameterSchema = duckdb_adbc::StatementGetParameterSchema;\n \tadbc_driver->ConnectionGetTableSchema = duckdb_adbc::ConnectionGetTableSchema;\n-\tadbc_driver->StatementSetSubstraitPlan = duckdb_adbc::StatementSetSubstraitPlan;\n \treturn ADBC_STATUS_OK;\n }\n \n@@ -70,7 +69,6 @@ struct DuckDBAdbcStatementWrapper {\n \tArrowArrayStream ingestion_stream;\n \tIngestionMode ingestion_mode = IngestionMode::CREATE;\n \tbool temporary_table = false;\n-\tuint8_t *substrait_plan;\n \tuint64_t plan_length;\n };\n \n@@ -157,36 +155,6 @@ AdbcStatusCode DatabaseNew(struct AdbcDatabase *database, struct AdbcError *erro\n \treturn CheckResult(res, error, \"Failed to allocate\");\n }\n \n-AdbcStatusCode StatementSetSubstraitPlan(struct AdbcStatement *statement, const uint8_t *plan, size_t length,\n-                                         struct AdbcError *error) {\n-\tif (!statement) {\n-\t\tSetError(error, \"Statement is not set\");\n-\t\treturn ADBC_STATUS_INVALID_ARGUMENT;\n-\t}\n-\tif (!plan) {\n-\t\tSetError(error, \"Substrait Plan is not set\");\n-\t\treturn ADBC_STATUS_INVALID_ARGUMENT;\n-\t}\n-\tif (length == 0) {\n-\t\tSetError(error, \"Can't execute plan with size = 0\");\n-\t\treturn ADBC_STATUS_INVALID_ARGUMENT;\n-\t}\n-\tauto wrapper = static_cast<DuckDBAdbcStatementWrapper *>(statement->private_data);\n-\tif (wrapper->ingestion_stream.release) {\n-\t\t// Release any resources currently held by the ingestion stream before we overwrite it\n-\t\twrapper->ingestion_stream.release(&wrapper->ingestion_stream);\n-\t\twrapper->ingestion_stream.release = nullptr;\n-\t}\n-\tif (wrapper->statement) {\n-\t\tduckdb_destroy_prepare(&wrapper->statement);\n-\t\twrapper->statement = nullptr;\n-\t}\n-\twrapper->substrait_plan = static_cast<uint8_t *>(malloc(sizeof(uint8_t) * length));\n-\twrapper->plan_length = length;\n-\tmemcpy(wrapper->substrait_plan, plan, length);\n-\treturn ADBC_STATUS_OK;\n-}\n-\n AdbcStatusCode DatabaseSetOption(struct AdbcDatabase *database, const char *key, const char *value,\n                                  struct AdbcError *error) {\n \tif (!database) {\n@@ -677,7 +645,6 @@ AdbcStatusCode StatementNew(struct AdbcConnection *connection, struct AdbcStatem\n \tstatement_wrapper->ingestion_stream.release = nullptr;\n \tstatement_wrapper->ingestion_table_name = nullptr;\n \tstatement_wrapper->db_schema = nullptr;\n-\tstatement_wrapper->substrait_plan = nullptr;\n \tstatement_wrapper->temporary_table = false;\n \n \tstatement_wrapper->ingestion_mode = IngestionMode::CREATE;\n@@ -709,10 +676,6 @@ AdbcStatusCode StatementRelease(struct AdbcStatement *statement, struct AdbcErro\n \t\tfree(wrapper->db_schema);\n \t\twrapper->db_schema = nullptr;\n \t}\n-\tif (wrapper->substrait_plan) {\n-\t\tfree(wrapper->substrait_plan);\n-\t\twrapper->substrait_plan = nullptr;\n-\t}\n \tfree(statement->private_data);\n \tstatement->private_data = nullptr;\n \treturn ADBC_STATUS_OK;\n@@ -805,25 +768,7 @@ AdbcStatusCode StatementExecuteQuery(struct AdbcStatement *statement, struct Arr\n \tif (has_stream && to_table) {\n \t\treturn IngestToTableFromBoundStream(wrapper, error);\n \t}\n-\tif (wrapper->substrait_plan != nullptr) {\n-\t\tauto plan_str = std::string(reinterpret_cast<const char *>(wrapper->substrait_plan), wrapper->plan_length);\n-\t\tduckdb::vector<duckdb::Value> params;\n-\t\tparams.emplace_back(duckdb::Value::BLOB_RAW(plan_str));\n-\t\tduckdb::unique_ptr<duckdb::QueryResult> query_result;\n-\t\ttry {\n-\t\t\tquery_result = reinterpret_cast<duckdb::Connection *>(wrapper->connection)\n-\t\t\t                   ->TableFunction(\"from_substrait\", params)\n-\t\t\t                   ->Execute();\n-\t\t} catch (duckdb::Exception &e) {\n-\t\t\tstd::string error_msg = \"It was not possible to execute substrait query. \" + std::string(e.what());\n-\t\t\tSetError(error, error_msg);\n-\t\t\treturn ADBC_STATUS_INVALID_ARGUMENT;\n-\t\t}\n-\t\tauto arrow_wrapper = new duckdb::ArrowResultWrapper();\n-\t\tarrow_wrapper->result =\n-\t\t    duckdb::unique_ptr_cast<duckdb::QueryResult, duckdb::MaterializedQueryResult>(std::move(query_result));\n-\t\twrapper->result = reinterpret_cast<duckdb_arrow>(arrow_wrapper);\n-\t} else if (has_stream) {\n+\tif (has_stream) {\n \t\t// A stream was bound to the statement, use that to bind parameters\n \t\tduckdb::unique_ptr<duckdb::QueryResult> result;\n \t\tArrowArrayStream stream = wrapper->ingestion_stream;\ndiff --git a/src/common/compressed_file_system.cpp b/src/common/compressed_file_system.cpp\nindex ddc325cf1156..7d2e2cfde82b 100644\n--- a/src/common/compressed_file_system.cpp\n+++ b/src/common/compressed_file_system.cpp\n@@ -44,7 +44,7 @@ int64_t CompressedFile::ReadData(void *buffer, int64_t remaining) {\n \t\t\tauto available =\n \t\t\t    MinValue<idx_t>(UnsafeNumericCast<idx_t>(remaining),\n \t\t\t                    UnsafeNumericCast<idx_t>(stream_data.out_buff_end - stream_data.out_buff_start));\n-\t\t\tmemcpy(data_ptr_t(buffer) + total_read, stream_data.out_buff_start, available);\n+\t\t\tmemcpy(static_cast<data_ptr_t>(buffer) + total_read, stream_data.out_buff_start, available);\n \n \t\t\t// increment the total read variables as required\n \t\t\tstream_data.out_buff_start += available;\ndiff --git a/src/common/gzip_file_system.cpp b/src/common/gzip_file_system.cpp\nindex ee0a215805ca..edb72bf911cd 100644\n--- a/src/common/gzip_file_system.cpp\n+++ b/src/common/gzip_file_system.cpp\n@@ -82,7 +82,7 @@ struct MiniZStreamWrapper : public StreamWrapper {\n \n \tvoid Close() override;\n \n-\tvoid FlushStream();\n+\tvoid FlushStream() const;\n };\n \n MiniZStreamWrapper::~MiniZStreamWrapper() {\n@@ -146,7 +146,7 @@ void MiniZStreamWrapper::Initialize(CompressedFile &file, bool write) {\n bool MiniZStreamWrapper::Read(StreamData &sd) {\n \t// Handling for the concatenated files\n \tif (sd.refresh) {\n-\t\tauto available = (uint32_t)(sd.in_buff_end - sd.in_buff_start);\n+\t\tauto available = static_cast<uint32_t>(sd.in_buff_end - sd.in_buff_start);\n \t\tif (available <= GZIP_FOOTER_SIZE) {\n \t\t\t// Only footer is available so we just close and return finished\n \t\t\tClose();\n@@ -173,7 +173,7 @@ bool MiniZStreamWrapper::Read(StreamData &sd) {\n \t\t\t\tc = UnsafeNumericCast<char>(*body_ptr);\n \t\t\t\tbody_ptr++;\n \t\t\t} while (c != '\\0' && body_ptr < sd.in_buff_end);\n-\t\t\tif ((idx_t)(body_ptr - sd.in_buff_start) >= GZIP_HEADER_MAXSIZE) {\n+\t\t\tif (static_cast<idx_t>(body_ptr - sd.in_buff_start) >= GZIP_HEADER_MAXSIZE) {\n \t\t\t\tthrow InternalException(\"Filename resulting in GZIP header larger than defined maximum (%d)\",\n \t\t\t\t                        GZIP_HEADER_MAXSIZE);\n \t\t\t}\n@@ -193,9 +193,9 @@ bool MiniZStreamWrapper::Read(StreamData &sd) {\n \t// actually decompress\n \tmz_stream_ptr->next_in = sd.in_buff_start;\n \tD_ASSERT(sd.in_buff_end - sd.in_buff_start < NumericLimits<int32_t>::Maximum());\n-\tmz_stream_ptr->avail_in = (uint32_t)(sd.in_buff_end - sd.in_buff_start);\n+\tmz_stream_ptr->avail_in = static_cast<uint32_t>(sd.in_buff_end - sd.in_buff_start);\n \tmz_stream_ptr->next_out = data_ptr_cast(sd.out_buff_end);\n-\tmz_stream_ptr->avail_out = (uint32_t)((sd.out_buff.get() + sd.out_buf_size) - sd.out_buff_end);\n+\tmz_stream_ptr->avail_out = static_cast<uint32_t>((sd.out_buff.get() + sd.out_buf_size) - sd.out_buff_end);\n \tauto ret = duckdb_miniz::mz_inflate(mz_stream_ptr.get(), duckdb_miniz::MZ_NO_FLUSH);\n \tif (ret != duckdb_miniz::MZ_OK && ret != duckdb_miniz::MZ_STREAM_END) {\n \t\tthrow IOException(\"Failed to decode gzip stream: %s\", duckdb_miniz::mz_error(ret));\n@@ -248,7 +248,7 @@ void MiniZStreamWrapper::Write(CompressedFile &file, StreamData &sd, data_ptr_t\n \t}\n }\n \n-void MiniZStreamWrapper::FlushStream() {\n+void MiniZStreamWrapper::FlushStream() const {\n \tauto &sd = file->stream_data;\n \tmz_stream_ptr->next_in = nullptr;\n \tmz_stream_ptr->avail_in = 0;\n@@ -371,7 +371,7 @@ string GZipFileSystem::UncompressGZIPString(const char *data, idx_t size) {\n \t\tdo {\n \t\t\tc = *body_ptr;\n \t\t\tbody_ptr++;\n-\t\t} while (c != '\\0' && (idx_t)(body_ptr - data) < size);\n+\t\t} while (c != '\\0' && static_cast<idx_t>(body_ptr - data) < size);\n \t}\n \n \t// stream is now set to beginning of payload data\n@@ -384,10 +384,10 @@ string GZipFileSystem::UncompressGZIPString(const char *data, idx_t size) {\n \tmz_stream_ptr->next_in = const_uchar_ptr_cast(body_ptr);\n \tmz_stream_ptr->avail_in = NumericCast<unsigned int>(bytes_remaining);\n \n-\tunsigned char decompress_buffer[BUFSIZ];\n \tstring decompressed;\n \n \twhile (status == duckdb_miniz::MZ_OK) {\n+\t\tunsigned char decompress_buffer[BUFSIZ];\n \t\tmz_stream_ptr->next_out = decompress_buffer;\n \t\tmz_stream_ptr->avail_out = sizeof(decompress_buffer);\n \t\tstatus = mz_inflate(mz_stream_ptr.get(), duckdb_miniz::MZ_NO_FLUSH);\ndiff --git a/src/execution/operator/aggregate/physical_streaming_window.cpp b/src/execution/operator/aggregate/physical_streaming_window.cpp\nindex 8d78e6653296..aa165678b133 100644\n--- a/src/execution/operator/aggregate/physical_streaming_window.cpp\n+++ b/src/execution/operator/aggregate/physical_streaming_window.cpp\n@@ -153,8 +153,6 @@ class StreamingWindowState : public OperatorState {\n \t\t\tComputeOffset(context, wexpr, offset);\n \t\t\tComputeDefault(context, wexpr, dflt);\n \n-\t\t\tcurr_chunk.Initialize(context, {wexpr.return_type});\n-\n \t\t\tbuffered = idx_t(std::abs(offset));\n \t\t\tprev.Reference(dflt);\n \t\t\tprev.Flatten(buffered);\n@@ -162,6 +160,10 @@ class StreamingWindowState : public OperatorState {\n \t\t}\n \n \t\tvoid Execute(ExecutionContext &context, DataChunk &input, DataChunk &delayed, Vector &result) {\n+\t\t\tif (!curr_chunk.ColumnCount()) {\n+\t\t\t\tcurr_chunk.Initialize(context.client, {result.GetType()}, delayed.GetCapacity());\n+\t\t\t}\n+\n \t\t\tif (offset >= 0) {\n \t\t\t\tExecuteLag(context, input, result);\n \t\t\t} else {\n@@ -212,7 +214,7 @@ class StreamingWindowState : public OperatorState {\n \t\t\tidx_t pos = 0;\n \t\t\tidx_t unified_offset = buffered;\n \t\t\tif (unified_offset < count) {\n-\t\t\t\tcurr_chunk.Reset();\n+\t\t\t\tReset(curr_chunk);\n \t\t\t\texecutor.Execute(input, curr_chunk);\n \t\t\t\tVectorOperations::Copy(curr, result, count, unified_offset, pos);\n \t\t\t\tpos += count - unified_offset;\n@@ -221,7 +223,7 @@ class StreamingWindowState : public OperatorState {\n \t\t\t// Copy unified[unified_offset:] => result[pos:]\n \t\t\tidx_t unified_count = count + delayed.size();\n \t\t\tif (unified_offset < unified_count) {\n-\t\t\t\tcurr_chunk.Reset();\n+\t\t\t\tReset(curr_chunk);\n \t\t\t\texecutor.Execute(delayed, curr_chunk);\n \t\t\t\tidx_t delayed_offset = unified_offset - count;\n \t\t\t\t// Only copy as many values as we need\n@@ -312,6 +314,13 @@ class StreamingWindowState : public OperatorState {\n \t\tinitialized = true;\n \t}\n \n+\tstatic inline void Reset(DataChunk &chunk) {\n+\t\t//\tReset trashes the capacity...\n+\t\tconst auto capacity = chunk.GetCapacity();\n+\t\tchunk.Reset();\n+\t\tchunk.SetCapacity(capacity);\n+\t}\n+\n public:\n \t//! We can't initialise until we have an input chunk\n \tbool initialized;\n@@ -470,34 +479,34 @@ void StreamingWindowState::AggregateState::Execute(ExecutionContext &context, Da\n \t}\n }\n \n-void PhysicalStreamingWindow::ExecuteFunctions(ExecutionContext &context, DataChunk &chunk, DataChunk &delayed,\n+void PhysicalStreamingWindow::ExecuteFunctions(ExecutionContext &context, DataChunk &output, DataChunk &delayed,\n                                                GlobalOperatorState &gstate_p, OperatorState &state_p) const {\n \tauto &gstate = gstate_p.Cast<StreamingWindowGlobalState>();\n \tauto &state = state_p.Cast<StreamingWindowState>();\n \n \t// Compute window functions\n-\tconst idx_t count = chunk.size();\n+\tconst idx_t count = output.size();\n \tconst column_t input_width = children[0]->GetTypes().size();\n \tfor (column_t expr_idx = 0; expr_idx < select_list.size(); expr_idx++) {\n \t\tcolumn_t col_idx = input_width + expr_idx;\n \t\tauto &expr = *select_list[expr_idx];\n-\t\tauto &result = chunk.data[col_idx];\n+\t\tauto &result = output.data[col_idx];\n \t\tswitch (expr.GetExpressionType()) {\n \t\tcase ExpressionType::WINDOW_AGGREGATE:\n-\t\t\tstate.aggregate_states[expr_idx]->Execute(context, chunk, result);\n+\t\t\tstate.aggregate_states[expr_idx]->Execute(context, output, result);\n \t\t\tbreak;\n \t\tcase ExpressionType::WINDOW_FIRST_VALUE:\n \t\tcase ExpressionType::WINDOW_PERCENT_RANK:\n \t\tcase ExpressionType::WINDOW_RANK:\n \t\tcase ExpressionType::WINDOW_RANK_DENSE: {\n \t\t\t// Reference constant vector\n-\t\t\tchunk.data[col_idx].Reference(*state.const_vectors[expr_idx]);\n+\t\t\toutput.data[col_idx].Reference(*state.const_vectors[expr_idx]);\n \t\t\tbreak;\n \t\t}\n \t\tcase ExpressionType::WINDOW_ROW_NUMBER: {\n \t\t\t// Set row numbers\n \t\t\tint64_t start_row = gstate.row_number;\n-\t\t\tauto rdata = FlatVector::GetData<int64_t>(chunk.data[col_idx]);\n+\t\t\tauto rdata = FlatVector::GetData<int64_t>(output.data[col_idx]);\n \t\t\tfor (idx_t i = 0; i < count; i++) {\n \t\t\t\trdata[i] = NumericCast<int64_t>(start_row + NumericCast<int64_t>(i));\n \t\t\t}\n@@ -505,7 +514,7 @@ void PhysicalStreamingWindow::ExecuteFunctions(ExecutionContext &context, DataCh\n \t\t}\n \t\tcase ExpressionType::WINDOW_LAG:\n \t\tcase ExpressionType::WINDOW_LEAD:\n-\t\t\tstate.lead_lag_states[expr_idx]->Execute(context, chunk, delayed, result);\n+\t\t\tstate.lead_lag_states[expr_idx]->Execute(context, output, delayed, result);\n \t\t\tbreak;\n \t\tdefault:\n \t\t\tthrow NotImplementedException(\"%s for StreamingWindow\", ExpressionTypeToString(expr.GetExpressionType()));\n@@ -515,13 +524,13 @@ void PhysicalStreamingWindow::ExecuteFunctions(ExecutionContext &context, DataCh\n }\n \n void PhysicalStreamingWindow::ExecuteInput(ExecutionContext &context, DataChunk &delayed, DataChunk &input,\n-                                           DataChunk &chunk, GlobalOperatorState &gstate_p,\n+                                           DataChunk &output, GlobalOperatorState &gstate_p,\n                                            OperatorState &state_p) const {\n \tauto &state = state_p.Cast<StreamingWindowState>();\n \n \t// Put payload columns in place\n \tfor (idx_t col_idx = 0; col_idx < input.data.size(); col_idx++) {\n-\t\tchunk.data[col_idx].Reference(input.data[col_idx]);\n+\t\toutput.data[col_idx].Reference(input.data[col_idx]);\n \t}\n \tidx_t count = input.size();\n \n@@ -531,51 +540,53 @@ void PhysicalStreamingWindow::ExecuteInput(ExecutionContext &context, DataChunk\n \t\tcount -= state.lead_count;\n \t\tinput.Copy(delayed, count);\n \t}\n-\tchunk.SetCardinality(count);\n+\toutput.SetCardinality(count);\n \n-\tExecuteFunctions(context, chunk, state.delayed, gstate_p, state_p);\n+\tExecuteFunctions(context, output, state.delayed, gstate_p, state_p);\n }\n \n void PhysicalStreamingWindow::ExecuteShifted(ExecutionContext &context, DataChunk &delayed, DataChunk &input,\n-                                             DataChunk &chunk, GlobalOperatorState &gstate_p,\n+                                             DataChunk &output, GlobalOperatorState &gstate_p,\n                                              OperatorState &state_p) const {\n \tauto &state = state_p.Cast<StreamingWindowState>();\n \tauto &shifted = state.shifted;\n \n-\tidx_t i = input.size();\n-\tidx_t d = delayed.size();\n-\tshifted.Reset();\n+\tidx_t out = output.size();\n+\tidx_t in = input.size();\n+\tidx_t delay = delayed.size();\n+\tD_ASSERT(out <= delay);\n+\n+\tstate.Reset(shifted);\n \t// shifted = delayed\n \tdelayed.Copy(shifted);\n-\tdelayed.Reset();\n+\tstate.Reset(delayed);\n \tfor (idx_t col_idx = 0; col_idx < delayed.data.size(); ++col_idx) {\n-\t\t// chunk[0:i] = shifted[0:i]\n-\t\tchunk.data[col_idx].Reference(shifted.data[col_idx]);\n-\t\t// delayed[0:i] = chunk[i:d-i]\n-\t\tVectorOperations::Copy(shifted.data[col_idx], delayed.data[col_idx], d, i, 0);\n-\t\t// delayed[d-i:d] = input[0:i]\n-\t\tVectorOperations::Copy(input.data[col_idx], delayed.data[col_idx], i, 0, d - i);\n+\t\t// output[0:out] = delayed[0:out]\n+\t\toutput.data[col_idx].Reference(shifted.data[col_idx]);\n+\t\t// delayed[0:out] = delayed[out:delay-out]\n+\t\tVectorOperations::Copy(shifted.data[col_idx], delayed.data[col_idx], delay, out, 0);\n+\t\t// delayed[delay-out:delay-out+in] = input[0:in]\n+\t\tVectorOperations::Copy(input.data[col_idx], delayed.data[col_idx], in, 0, delay - out);\n \t}\n-\tchunk.SetCardinality(i);\n-\tdelayed.SetCardinality(d);\n+\tdelayed.SetCardinality(delay - out + in);\n \n-\tExecuteFunctions(context, chunk, delayed, gstate_p, state_p);\n+\tExecuteFunctions(context, output, delayed, gstate_p, state_p);\n }\n \n void PhysicalStreamingWindow::ExecuteDelayed(ExecutionContext &context, DataChunk &delayed, DataChunk &input,\n-                                             DataChunk &chunk, GlobalOperatorState &gstate_p,\n+                                             DataChunk &output, GlobalOperatorState &gstate_p,\n                                              OperatorState &state_p) const {\n \t// Put payload columns in place\n \tfor (idx_t col_idx = 0; col_idx < delayed.data.size(); col_idx++) {\n-\t\tchunk.data[col_idx].Reference(delayed.data[col_idx]);\n+\t\toutput.data[col_idx].Reference(delayed.data[col_idx]);\n \t}\n \tidx_t count = delayed.size();\n-\tchunk.SetCardinality(count);\n+\toutput.SetCardinality(count);\n \n-\tExecuteFunctions(context, chunk, input, gstate_p, state_p);\n+\tExecuteFunctions(context, output, input, gstate_p, state_p);\n }\n \n-OperatorResultType PhysicalStreamingWindow::Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n+OperatorResultType PhysicalStreamingWindow::Execute(ExecutionContext &context, DataChunk &input, DataChunk &output,\n                                                     GlobalOperatorState &gstate_p, OperatorState &state_p) const {\n \tauto &state = state_p.Cast<StreamingWindowState>();\n \tif (!state.initialized) {\n@@ -585,37 +596,37 @@ OperatorResultType PhysicalStreamingWindow::Execute(ExecutionContext &context, D\n \tauto &delayed = state.delayed;\n \t// We can Reset delayed now that no one can be referencing it.\n \tif (!delayed.size()) {\n-\t\tdelayed.Reset();\n+\t\tstate.Reset(delayed);\n \t}\n-\tconst idx_t available = delayed.size() + input.size();\n-\tif (available <= state.lead_count) {\n+\tif (delayed.size() < state.lead_count) {\n \t\t//\tIf we don't have enough to produce a single row,\n \t\t//\tthen just delay more rows, return nothing\n \t\t//\tand ask for more data.\n \t\tdelayed.Append(input);\n-\t\tchunk.SetCardinality(0);\n+\t\toutput.SetCardinality(0);\n \t\treturn OperatorResultType::NEED_MORE_INPUT;\n \t} else if (input.size() < delayed.size()) {\n \t\t// If we can't consume all of the delayed values,\n \t\t// we need to split them instead of referencing them all\n-\t\tExecuteShifted(context, delayed, input, chunk, gstate_p, state_p);\n+\t\toutput.SetCardinality(input.size());\n+\t\tExecuteShifted(context, delayed, input, output, gstate_p, state_p);\n \t\t// We delayed the unused input so ask for more\n \t\treturn OperatorResultType::NEED_MORE_INPUT;\n \t} else if (delayed.size()) {\n \t\t//\tWe have enough delayed rows so flush them\n-\t\tExecuteDelayed(context, delayed, input, chunk, gstate_p, state_p);\n+\t\tExecuteDelayed(context, delayed, input, output, gstate_p, state_p);\n \t\t// Defer resetting delayed as it may be referenced.\n \t\tdelayed.SetCardinality(0);\n \t\t// Come back to process the input\n \t\treturn OperatorResultType::HAVE_MORE_OUTPUT;\n \t} else {\n \t\t//\tNo delayed rows, so emit what we can and delay the rest.\n-\t\tExecuteInput(context, delayed, input, chunk, gstate_p, state_p);\n+\t\tExecuteInput(context, delayed, input, output, gstate_p, state_p);\n \t\treturn OperatorResultType::NEED_MORE_INPUT;\n \t}\n }\n \n-OperatorFinalizeResultType PhysicalStreamingWindow::FinalExecute(ExecutionContext &context, DataChunk &chunk,\n+OperatorFinalizeResultType PhysicalStreamingWindow::FinalExecute(ExecutionContext &context, DataChunk &output,\n                                                                  GlobalOperatorState &gstate_p,\n                                                                  OperatorState &state_p) const {\n \tauto &state = state_p.Cast<StreamingWindowState>();\n@@ -624,8 +635,15 @@ OperatorFinalizeResultType PhysicalStreamingWindow::FinalExecute(ExecutionContex\n \t\tauto &delayed = state.delayed;\n \t\t//\tThere are no more input rows\n \t\tauto &input = state.shifted;\n-\t\tinput.Reset();\n-\t\tExecuteDelayed(context, delayed, input, chunk, gstate_p, state_p);\n+\t\tstate.Reset(input);\n+\n+\t\tif (output.GetCapacity() < delayed.size()) {\n+\t\t\t//\tMore than one output buffer was delayed, so shift in what we can\n+\t\t\toutput.SetCardinality(output.GetCapacity());\n+\t\t\tExecuteShifted(context, delayed, input, output, gstate_p, state_p);\n+\t\t\treturn OperatorFinalizeResultType::HAVE_MORE_OUTPUT;\n+\t\t}\n+\t\tExecuteDelayed(context, delayed, input, output, gstate_p, state_p);\n \t}\n \n \treturn OperatorFinalizeResultType::FINISHED;\ndiff --git a/src/execution/operator/csv_scanner/scanner/column_count_scanner.cpp b/src/execution/operator/csv_scanner/scanner/column_count_scanner.cpp\nindex 906ace12b1e7..2b3361533267 100644\n--- a/src/execution/operator/csv_scanner/scanner/column_count_scanner.cpp\n+++ b/src/execution/operator/csv_scanner/scanner/column_count_scanner.cpp\n@@ -39,7 +39,13 @@ idx_t ColumnCountResult::GetMostFrequentColumnCount() const {\n }\n \n bool ColumnCountResult::AddRow(ColumnCountResult &result, idx_t buffer_pos) {\n+\tconst LinePosition cur_position(result.cur_buffer_idx, buffer_pos + 1, result.current_buffer_size);\n+\tif (cur_position - result.last_position > result.state_machine.options.maximum_line_size.GetValue() &&\n+\t    buffer_pos != NumericLimits<idx_t>::Maximum()) {\n+\t\tresult.error = true;\n+\t}\n \tresult.InternalAddRow();\n+\tresult.last_position = cur_position;\n \tif (!result.states.EmptyLastValue()) {\n \t\tidx_t col_count_idx = result.result_position;\n \t\tfor (idx_t i = 0; i < result.result_position + 1; i++) {\n@@ -99,6 +105,7 @@ ColumnCountScanner::ColumnCountScanner(shared_ptr<CSVBufferManager> buffer_manag\n     : BaseScanner(std::move(buffer_manager), state_machine, std::move(error_handler), true, nullptr, iterator),\n       result(states, *state_machine, result_size_p), column_count(1), result_size(result_size_p) {\n \tsniffing = true;\n+\tresult.last_position = {0, 0, cur_buffer_handle->actual_size};\n }\n \n unique_ptr<StringValueScanner> ColumnCountScanner::UpgradeToStringValueScanner() {\n@@ -117,6 +124,7 @@ unique_ptr<StringValueScanner> ColumnCountScanner::UpgradeToStringValueScanner()\n ColumnCountResult &ColumnCountScanner::ParseChunk() {\n \tresult.result_position = 0;\n \tcolumn_count = 1;\n+\tresult.current_buffer_size = cur_buffer_handle->actual_size;\n \tParseChunkInternal(result);\n \treturn result;\n }\n@@ -139,6 +147,7 @@ void ColumnCountScanner::FinalizeChunkProcess() {\n \t\tif (iterator.pos.buffer_pos == cur_buffer_handle->actual_size) {\n \t\t\t// Move to next buffer\n \t\t\tcur_buffer_handle = buffer_manager->GetBuffer(++iterator.pos.buffer_idx);\n+\n \t\t\tif (!cur_buffer_handle) {\n \t\t\t\tbuffer_handle_ptr = nullptr;\n \t\t\t\tif (states.IsQuotedCurrent() && !states.IsUnquoted()) {\n@@ -158,6 +167,15 @@ void ColumnCountScanner::FinalizeChunkProcess() {\n \t\t\t\t\tresult.AddRow(result, NumericLimits<idx_t>::Maximum());\n \t\t\t\t}\n \t\t\t\treturn;\n+\t\t\t} else {\n+\t\t\t\tresult.cur_buffer_idx = iterator.pos.buffer_idx;\n+\t\t\t\tresult.current_buffer_size = cur_buffer_handle->actual_size;\n+\t\t\t\t// Do a quick check that the line is still sane\n+\t\t\t\tconst LinePosition cur_position(result.cur_buffer_idx, 0, result.current_buffer_size);\n+\t\t\t\tif (cur_position - result.last_position > result.state_machine.options.maximum_line_size.GetValue()) {\n+\t\t\t\t\tresult.error = true;\n+\t\t\t\t\treturn;\n+\t\t\t\t}\n \t\t\t}\n \t\t\titerator.pos.buffer_pos = 0;\n \t\t\tbuffer_handle_ptr = cur_buffer_handle->Ptr();\ndiff --git a/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp b/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\nindex 29838280ecf5..f48339a029aa 100644\n--- a/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\n+++ b/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\n@@ -148,7 +148,7 @@ inline bool IsValueNull(const char *null_str_ptr, const char *value_ptr, const i\n }\n \n bool StringValueResult::HandleTooManyColumnsError(const char *value_ptr, const idx_t size) {\n-\tif (cur_col_id >= number_of_columns) {\n+\tif (cur_col_id >= number_of_columns && state_machine.state_machine_options.rfc_4180.GetValue()) {\n \t\tbool error = true;\n \t\tif (cur_col_id == number_of_columns && ((quoted && state_machine.options.allow_quoted_nulls) || !quoted)) {\n \t\t\t// we make an exception if the first over-value is null\n@@ -220,6 +220,9 @@ void StringValueResult::AddValueToVector(const char *value_ptr, const idx_t size\n \t\treturn;\n \t}\n \tif (cur_col_id >= number_of_columns) {\n+\t\tif (!state_machine.state_machine_options.rfc_4180.GetValue()) {\n+\t\t\treturn;\n+\t\t}\n \t\tbool error = true;\n \t\tif (cur_col_id == number_of_columns && ((quoted && state_machine.options.allow_quoted_nulls) || !quoted)) {\n \t\t\t// we make an exception if the first over-value is null\n@@ -511,6 +514,10 @@ void StringValueResult::AddPossiblyEscapedValue(StringValueResult &result, const\n \t\t\t\treturn;\n \t\t\t}\n \t\t}\n+\t\tif (result.cur_col_id >= result.number_of_columns &&\n+\t\t    !result.state_machine.state_machine_options.rfc_4180.GetValue()) {\n+\t\t\treturn;\n+\t\t}\n \t\tif (!result.HandleTooManyColumnsError(value_ptr, length)) {\n \t\t\t// If it's an escaped value we have to remove all the escapes, this is not really great\n \t\t\t// If we are going to escape, this vector must be a varchar vector\n@@ -520,7 +527,6 @@ void StringValueResult::AddPossiblyEscapedValue(StringValueResult &result, const\n \t\t\t\t\t// We have to write the cast error message.\n \t\t\t\t\tstd::ostringstream error;\n \t\t\t\t\t// Casting Error Message\n-\n \t\t\t\t\terror << \"Could not convert string \\\"\" << std::string(value_ptr, length) << \"\\\" to \\'\"\n \t\t\t\t\t      << LogicalTypeIdToString(result.parse_types[result.chunk_col_id].type_id) << \"\\'\";\n \t\t\t\t\tauto error_string = error.str();\n@@ -533,6 +539,7 @@ void StringValueResult::AddPossiblyEscapedValue(StringValueResult &result, const\n \t\t\t\tauto value = StringValueScanner::RemoveEscape(\n \t\t\t\t    value_ptr, length, result.state_machine.dialect_options.state_machine_options.escape.GetValue(),\n \t\t\t\t    result.state_machine.dialect_options.state_machine_options.quote.GetValue(),\n+\t\t\t\t    result.state_machine.dialect_options.state_machine_options.rfc_4180.GetValue(),\n \t\t\t\t    result.parse_chunk.data[result.chunk_col_id]);\n \t\t\t\tresult.AddValueToVector(value.GetData(), value.GetSize());\n \t\t\t}\n@@ -806,7 +813,7 @@ bool StringValueResult::AddRowInternal() {\n \tquoted_new_line = false;\n \t// We need to check if we are getting the correct number of columns here.\n \t// If columns are correct, we add it, and that's it.\n-\tif (cur_col_id != number_of_columns) {\n+\tif (cur_col_id < number_of_columns) {\n \t\t// We have too few columns:\n \t\tif (null_padding) {\n \t\t\twhile (cur_col_id < number_of_columns) {\n@@ -1231,7 +1238,8 @@ void StringValueScanner::ProcessExtraRow() {\n \t}\n }\n \n-string_t StringValueScanner::RemoveEscape(const char *str_ptr, idx_t end, char escape, char quote, Vector &vector) {\n+string_t StringValueScanner::RemoveEscape(const char *str_ptr, idx_t end, char escape, char quote, bool rfc_4180,\n+                                          Vector &vector) {\n \t// Figure out the exact size\n \tidx_t str_pos = 0;\n \tbool just_escaped = false;\n@@ -1239,7 +1247,7 @@ string_t StringValueScanner::RemoveEscape(const char *str_ptr, idx_t end, char e\n \t\tif (str_ptr[cur_pos] == escape && !just_escaped) {\n \t\t\tjust_escaped = true;\n \t\t} else if (str_ptr[cur_pos] == quote) {\n-\t\t\tif (just_escaped) {\n+\t\t\tif (just_escaped || !rfc_4180) {\n \t\t\t\tstr_pos++;\n \t\t\t}\n \t\t\tjust_escaped = false;\n@@ -1259,7 +1267,7 @@ string_t StringValueScanner::RemoveEscape(const char *str_ptr, idx_t end, char e\n \t\tif (c == escape && !just_escaped) {\n \t\t\tjust_escaped = true;\n \t\t} else if (str_ptr[cur_pos] == quote) {\n-\t\t\tif (just_escaped) {\n+\t\t\tif (just_escaped || !rfc_4180) {\n \t\t\t\tremoved_escapes_ptr[str_pos++] = c;\n \t\t\t}\n \t\t\tjust_escaped = false;\n@@ -1289,10 +1297,8 @@ void StringValueScanner::ProcessOverBufferValue() {\n \t\t}\n \t\tif (states.NewRow() || states.NewValue()) {\n \t\t\tbreak;\n-\t\t} else {\n-\t\t\tif (!result.comment) {\n-\t\t\t\tover_buffer_string += previous_buffer[i];\n-\t\t\t}\n+\t\t} else if (!result.comment) {\n+\t\t\tover_buffer_string += previous_buffer[i];\n \t\t}\n \t\tif (states.IsQuoted()) {\n \t\t\tresult.SetQuoted(result, j);\n@@ -1323,16 +1329,13 @@ void StringValueScanner::ProcessOverBufferValue() {\n \t\tif (states.EmptyLine()) {\n \t\t\tif (state_machine->dialect_options.num_cols == 1) {\n \t\t\t\tbreak;\n-\t\t\t} else {\n-\t\t\t\tcontinue;\n \t\t\t}\n+\t\t\tcontinue;\n \t\t}\n \t\tif (states.NewRow() || states.NewValue()) {\n \t\t\tbreak;\n-\t\t} else {\n-\t\t\tif (!result.comment && !states.IsComment()) {\n-\t\t\t\tover_buffer_string += buffer_handle_ptr[iterator.pos.buffer_pos];\n-\t\t\t}\n+\t\t} else if (!result.comment && !states.IsComment()) {\n+\t\t\tover_buffer_string += buffer_handle_ptr[iterator.pos.buffer_pos];\n \t\t}\n \t\tif (states.IsQuoted()) {\n \t\t\tresult.SetQuoted(result, j);\n@@ -1357,7 +1360,7 @@ void StringValueScanner::ProcessOverBufferValue() {\n \t}\n \tif (!skip_value) {\n \t\tstring_t value;\n-\t\tif (result.quoted) {\n+\t\tif (result.quoted && !result.comment) {\n \t\t\tvalue = string_t(over_buffer_string.c_str() + result.quoted_position,\n \t\t\t                 UnsafeNumericCast<uint32_t>(over_buffer_string.size() - 1 - result.quoted_position));\n \t\t\tif (result.escaped) {\n@@ -1366,6 +1369,7 @@ void StringValueScanner::ProcessOverBufferValue() {\n \t\t\t\t\tvalue = RemoveEscape(str_ptr, over_buffer_string.size() - 2,\n \t\t\t\t\t                     state_machine->dialect_options.state_machine_options.escape.GetValue(),\n \t\t\t\t\t                     state_machine->dialect_options.state_machine_options.quote.GetValue(),\n+\t\t\t\t\t                     result.state_machine.dialect_options.state_machine_options.rfc_4180.GetValue(),\n \t\t\t\t\t                     result.parse_chunk.data[result.chunk_col_id]);\n \t\t\t\t}\n \t\t\t}\n@@ -1376,6 +1380,7 @@ void StringValueScanner::ProcessOverBufferValue() {\n \t\t\t\t\tvalue = RemoveEscape(over_buffer_string.c_str(), over_buffer_string.size(),\n \t\t\t\t\t                     state_machine->dialect_options.state_machine_options.escape.GetValue(),\n \t\t\t\t\t                     state_machine->dialect_options.state_machine_options.quote.GetValue(),\n+\t\t\t\t\t                     result.state_machine.dialect_options.state_machine_options.rfc_4180.GetValue(),\n \t\t\t\t\t                     result.parse_chunk.data[result.chunk_col_id]);\n \t\t\t\t}\n \t\t\t}\n@@ -1436,7 +1441,7 @@ bool StringValueScanner::MoveToNextBuffer() {\n \t\t\t// This means we reached the end of the file, we must add a last line if there is any to be added\n \t\t\tif (states.EmptyLine() || states.NewRow() || result.added_last_line || states.IsCurrentNewRow() ||\n \t\t\t    states.IsNotSet()) {\n-\t\t\t\tif (result.cur_col_id == result.number_of_columns) {\n+\t\t\t\tif (result.cur_col_id == result.number_of_columns && !result.IsStateCurrent(CSVState::INVALID)) {\n \t\t\t\t\tresult.number_of_rows++;\n \t\t\t\t}\n \t\t\t\tresult.cur_col_id = 0;\ndiff --git a/src/execution/operator/csv_scanner/sniffer/header_detection.cpp b/src/execution/operator/csv_scanner/sniffer/header_detection.cpp\nindex f973e8784850..fa48e5ef1758 100644\n--- a/src/execution/operator/csv_scanner/sniffer/header_detection.cpp\n+++ b/src/execution/operator/csv_scanner/sniffer/header_detection.cpp\n@@ -117,9 +117,7 @@ static void ReplaceNames(vector<string> &detected_names, CSVStateMachine &state_\n \t\t\t\t\tdetected_names.push_back(GenerateColumnName(options.name_list.size(), col++));\n \t\t\t\t\tbest_sql_types_candidates_per_column_idx[i] = {LogicalType::VARCHAR};\n \t\t\t\t}\n-\n \t\t\t\tdialect_options.num_cols = options.name_list.size();\n-\n \t\t\t} else {\n \t\t\t\t// we throw an error\n \t\t\t\tconst auto error = CSVError::HeaderSniffingError(\n@@ -128,8 +126,16 @@ static void ReplaceNames(vector<string> &detected_names, CSVStateMachine &state_\n \t\t\t\terror_handler.Error(error);\n \t\t\t}\n \t\t}\n-\t\tfor (idx_t i = 0; i < options.name_list.size(); i++) {\n-\t\t\tdetected_names[i] = options.name_list[i];\n+\t\tif (options.name_list.size() > detected_names.size()) {\n+\t\t\t// we throw an error\n+\t\t\tconst auto error =\n+\t\t\t    CSVError::HeaderSniffingError(options, best_header_row, options.name_list.size(),\n+\t\t\t                                  state_machine.dialect_options.state_machine_options.delimiter.GetValue());\n+\t\t\terror_handler.Error(error);\n+\t\t} else {\n+\t\t\tfor (idx_t i = 0; i < options.name_list.size(); i++) {\n+\t\t\t\tdetected_names[i] = options.name_list[i];\n+\t\t\t}\n \t\t}\n \t}\n }\ndiff --git a/src/execution/sample/reservoir_sample.cpp b/src/execution/sample/reservoir_sample.cpp\nindex ba777b609f02..402d84a80466 100644\n--- a/src/execution/sample/reservoir_sample.cpp\n+++ b/src/execution/sample/reservoir_sample.cpp\n@@ -225,10 +225,6 @@ vector<uint32_t> ReservoirSample::GetRandomizedVector(uint32_t range, uint32_t s\n \tfor (uint32_t i = 0; i < range; i++) {\n \t\tret.push_back(i);\n \t}\n-\tif (size == FIXED_SAMPLE_SIZE) {\n-\t\tstd::shuffle(ret.begin(), ret.end(), base_reservoir_sample->random);\n-\t\treturn ret;\n-\t}\n \tfor (uint32_t i = 0; i < size; i++) {\n \t\tuint32_t random_shuffle = base_reservoir_sample->random.NextRandomInteger32(i, range);\n \t\tif (random_shuffle == i) {\ndiff --git a/src/function/function_binder.cpp b/src/function/function_binder.cpp\nindex 67144182522e..b0e3bbc732e6 100644\n--- a/src/function/function_binder.cpp\n+++ b/src/function/function_binder.cpp\n@@ -457,7 +457,7 @@ unique_ptr<Expression> FunctionBinder::BindScalarFunction(ScalarFunction bound_f\n \t                                                      std::move(children), std::move(bind_info), is_operator);\n \tif (result_func->function.bind_expression) {\n \t\t// if a bind_expression callback is registered - call it and emit the resulting expression\n-\t\tFunctionBindExpressionInput input(context, result_func->bind_info.get(), *result_func);\n+\t\tFunctionBindExpressionInput input(context, result_func->bind_info.get(), result_func->children);\n \t\tresult = result_func->function.bind_expression(input);\n \t}\n \tif (!result) {\ndiff --git a/src/function/table/read_csv.cpp b/src/function/table/read_csv.cpp\nindex 706712f8193d..517c7a266cb0 100644\n--- a/src/function/table/read_csv.cpp\n+++ b/src/function/table/read_csv.cpp\n@@ -124,7 +124,7 @@ void SchemaDiscovery(ClientContext &context, ReadCSVData &result, CSVReaderOptio\n \t\tnames = best_schema.GetNames();\n \t\treturn_types = best_schema.GetTypes();\n \t}\n-\tif (only_header_or_empty_files == current_file) {\n+\tif (only_header_or_empty_files == current_file && !options.columns_set) {\n \t\tfor (auto &type : return_types) {\n \t\t\tD_ASSERT(type.id() == LogicalTypeId::BOOLEAN);\n \t\t\t// we default to varchar if all files are empty or only have a header after all the sniffing\ndiff --git a/src/function/table/system/duckdb_extensions.cpp b/src/function/table/system/duckdb_extensions.cpp\nindex 64d26dea9fb8..0edc2c2ff929 100644\n--- a/src/function/table/system/duckdb_extensions.cpp\n+++ b/src/function/table/system/duckdb_extensions.cpp\n@@ -149,11 +149,15 @@ unique_ptr<GlobalTableFunctionState> DuckDBExtensionsInit(ClientContext &context\n \t\t\tauto entry = installed_extensions.find(ext_name);\n \t\t\tif (entry == installed_extensions.end() || !entry->second.installed) {\n \t\t\t\tExtensionInformation &info = installed_extensions[ext_name];\n+\n \t\t\t\tinfo.name = ext_name;\n \t\t\t\tinfo.loaded = true;\n \t\t\t\tinfo.extension_version = ext_install_info->version;\n \t\t\t\tinfo.installed = ext_install_info->mode == ExtensionInstallMode::STATICALLY_LINKED;\n \t\t\t\tinfo.install_mode = ext_install_info->mode;\n+\t\t\t\tif (ext_data.install_info->mode == ExtensionInstallMode::STATICALLY_LINKED && info.file_path.empty()) {\n+\t\t\t\t\tinfo.file_path = \"(BUILT-IN)\";\n+\t\t\t\t}\n \t\t\t} else {\n \t\t\t\tentry->second.loaded = true;\n \t\t\t\tentry->second.extension_version = ext_install_info->version;\ndiff --git a/src/include/duckdb/execution/operator/csv_scanner/base_scanner.hpp b/src/include/duckdb/execution/operator/csv_scanner/base_scanner.hpp\nindex 93b8bf9ac1f3..b2d9dae68a39 100644\n--- a/src/include/duckdb/execution/operator/csv_scanner/base_scanner.hpp\n+++ b/src/include/duckdb/execution/operator/csv_scanner/base_scanner.hpp\n@@ -17,6 +17,35 @@\n namespace duckdb {\n \n class CSVFileScan;\n+\n+//! Class that keeps track of line starts, used for line size verification\n+class LinePosition {\n+public:\n+\tLinePosition() {\n+\t}\n+\tLinePosition(idx_t buffer_idx_p, idx_t buffer_pos_p, idx_t buffer_size_p)\n+\t    : buffer_pos(buffer_pos_p), buffer_size(buffer_size_p), buffer_idx(buffer_idx_p) {\n+\t}\n+\n+\tidx_t operator-(const LinePosition &other) const {\n+\t\tif (other.buffer_idx == buffer_idx) {\n+\t\t\treturn buffer_pos - other.buffer_pos;\n+\t\t}\n+\t\treturn other.buffer_size - other.buffer_pos + buffer_pos;\n+\t}\n+\n+\tbool operator==(const LinePosition &other) const {\n+\t\treturn buffer_pos == other.buffer_pos && buffer_idx == other.buffer_idx && buffer_size == other.buffer_size;\n+\t}\n+\n+\tidx_t GetGlobalPosition(idx_t requested_buffer_size, bool first_char_nl = false) const {\n+\t\treturn requested_buffer_size * buffer_idx + buffer_pos + first_char_nl;\n+\t}\n+\tidx_t buffer_pos = 0;\n+\tidx_t buffer_size = 0;\n+\tidx_t buffer_idx = 0;\n+};\n+\n class ScannerResult {\n public:\n \tScannerResult(CSVStates &states, CSVStateMachine &state_machine, idx_t result_size);\n@@ -52,6 +81,10 @@ class ScannerResult {\n \t\treturn result.comment == true;\n \t}\n \n+\tinline bool IsStateCurrent(CSVState state) const {\n+\t\treturn states.states[1] == state;\n+\t}\n+\n \t//! Variable to keep information regarding quoted and escaped values\n \tbool quoted = false;\n \t//! If the current quoted value is unquoted\n@@ -62,6 +95,8 @@ class ScannerResult {\n \tbool comment = false;\n \tidx_t quoted_position = 0;\n \n+\tLinePosition last_position;\n+\n \t//! Size of the result\n \tconst idx_t result_size;\n \n@@ -88,7 +123,7 @@ class BaseScanner {\n \t//! Returns true if the scanner is finished\n \tbool FinishedFile() const;\n \n-\t//! Parses data into a output_chunk\n+\t//! Parses data into an output_chunk\n \tvirtual ScannerResult &ParseChunk();\n \n \t//! Returns the result from the last Parse call. Shouts at you if you call it wrong\ndiff --git a/src/include/duckdb/execution/operator/csv_scanner/column_count_scanner.hpp b/src/include/duckdb/execution/operator/csv_scanner/column_count_scanner.hpp\nindex 8cecfe500d15..5da4d30376e7 100644\n--- a/src/include/duckdb/execution/operator/csv_scanner/column_count_scanner.hpp\n+++ b/src/include/duckdb/execution/operator/csv_scanner/column_count_scanner.hpp\n@@ -41,6 +41,9 @@ class ColumnCountResult : public ScannerResult {\n \tbool error = false;\n \tidx_t result_position = 0;\n \tbool cur_line_starts_as_comment = false;\n+\n+\tidx_t cur_buffer_idx = 0;\n+\tidx_t current_buffer_size = 0;\n \t//! How many rows fit a given column count\n \tmap<idx_t, idx_t> rows_per_column_count;\n \t//! Adds a Value to the result\ndiff --git a/src/include/duckdb/execution/operator/csv_scanner/string_value_scanner.hpp b/src/include/duckdb/execution/operator/csv_scanner/string_value_scanner.hpp\nindex a2a3d5372fe5..12fd0f42759d 100644\n--- a/src/include/duckdb/execution/operator/csv_scanner/string_value_scanner.hpp\n+++ b/src/include/duckdb/execution/operator/csv_scanner/string_value_scanner.hpp\n@@ -27,34 +27,6 @@ struct CSVBufferUsage {\n \tidx_t buffer_idx;\n };\n \n-//! Class that keeps track of line starts, used for line size verification\n-class LinePosition {\n-public:\n-\tLinePosition() {\n-\t}\n-\tLinePosition(idx_t buffer_idx_p, idx_t buffer_pos_p, idx_t buffer_size_p)\n-\t    : buffer_pos(buffer_pos_p), buffer_size(buffer_size_p), buffer_idx(buffer_idx_p) {\n-\t}\n-\n-\tidx_t operator-(const LinePosition &other) const {\n-\t\tif (other.buffer_idx == buffer_idx) {\n-\t\t\treturn buffer_pos - other.buffer_pos;\n-\t\t}\n-\t\treturn other.buffer_size - other.buffer_pos + buffer_pos;\n-\t}\n-\n-\tbool operator==(const LinePosition &other) const {\n-\t\treturn buffer_pos == other.buffer_pos && buffer_idx == other.buffer_idx && buffer_size == other.buffer_size;\n-\t}\n-\n-\tidx_t GetGlobalPosition(idx_t requested_buffer_size, bool first_char_nl = false) const {\n-\t\treturn requested_buffer_size * buffer_idx + buffer_pos + first_char_nl;\n-\t}\n-\tidx_t buffer_pos = 0;\n-\tidx_t buffer_size = 0;\n-\tidx_t buffer_idx = 0;\n-};\n-\n //! Keeps track of start and end of line positions in regard to the CSV file\n class FullLinePosition {\n public:\n@@ -181,7 +153,7 @@ class StringValueResult : public ScannerResult {\n \tunsafe_vector<ValidityMask *> validity_mask;\n \n \t//! Variables to iterate over the CSV buffers\n-\tLinePosition last_position;\n+\n \tchar *buffer_ptr;\n \tidx_t buffer_size;\n \tidx_t position_before_comment;\n@@ -322,7 +294,8 @@ class StringValueScanner : public BaseScanner {\n \tbool FinishedIterator() const;\n \n \t//! Creates a new string with all escaped values removed\n-\tstatic string_t RemoveEscape(const char *str_ptr, idx_t end, char escape, char quote, Vector &vector);\n+\tstatic string_t RemoveEscape(const char *str_ptr, idx_t end, char escape, char quote, bool rfc_4180,\n+\t                             Vector &vector);\n \n \t//! If we can directly cast the type when consuming the CSV file, or we have to do it later\n \tstatic bool CanDirectlyCast(const LogicalType &type, bool icu_loaded);\ndiff --git a/src/include/duckdb/function/scalar_function.hpp b/src/include/duckdb/function/scalar_function.hpp\nindex 236356b9af8e..f46bb60427df 100644\n--- a/src/include/duckdb/function/scalar_function.hpp\n+++ b/src/include/duckdb/function/scalar_function.hpp\n@@ -78,13 +78,13 @@ struct FunctionModifiedDatabasesInput {\n \n struct FunctionBindExpressionInput {\n \tFunctionBindExpressionInput(ClientContext &context_p, optional_ptr<FunctionData> bind_data_p,\n-\t                            BoundFunctionExpression &function_p)\n-\t    : context(context_p), bind_data(bind_data_p), function(function_p) {\n+\t                            vector<unique_ptr<Expression>> &children_p)\n+\t    : context(context_p), bind_data(bind_data_p), children(children_p) {\n \t}\n \n \tClientContext &context;\n \toptional_ptr<FunctionData> bind_data;\n-\tBoundFunctionExpression &function;\n+\tvector<unique_ptr<Expression>> &children;\n };\n \n struct ScalarFunctionBindInput {\ndiff --git a/src/include/duckdb/main/connection.hpp b/src/include/duckdb/main/connection.hpp\nindex d0935ca8e084..f5b46717c667 100644\n--- a/src/include/duckdb/main/connection.hpp\n+++ b/src/include/duckdb/main/connection.hpp\n@@ -166,14 +166,6 @@ class Connection {\n \tDUCKDB_API shared_ptr<Relation> RelationFromQuery(unique_ptr<SelectStatement> select_stmt,\n \t                                                  const string &alias = \"queryrelation\", const string &query = \"\");\n \n-\t//! Returns a substrait BLOB from a valid query\n-\tDUCKDB_API string GetSubstrait(const string &query);\n-\t//! Returns a Query Result from a substrait blob\n-\tDUCKDB_API unique_ptr<QueryResult> FromSubstrait(const string &proto);\n-\t//! Returns a substrait BLOB from a valid query\n-\tDUCKDB_API string GetSubstraitJSON(const string &query);\n-\t//! Returns a Query Result from a substrait JSON\n-\tDUCKDB_API unique_ptr<QueryResult> FromSubstraitJSON(const string &json);\n \tDUCKDB_API void BeginTransaction();\n \tDUCKDB_API void Commit();\n \tDUCKDB_API void Rollback();\ndiff --git a/src/include/duckdb/main/extension.hpp b/src/include/duckdb/main/extension.hpp\nindex 53de1481d946..b623daeff989 100644\n--- a/src/include/duckdb/main/extension.hpp\n+++ b/src/include/duckdb/main/extension.hpp\n@@ -24,6 +24,7 @@ class Extension {\n \tDUCKDB_API virtual std::string Version() const {\n \t\treturn \"\";\n \t}\n+\tDUCKDB_API static const char *DefaultVersion();\n };\n \n enum class ExtensionABIType : uint8_t {\ndiff --git a/src/include/duckdb/main/extension_entries.hpp b/src/include/duckdb/main/extension_entries.hpp\nindex c8ce3db3a533..530f388b2d57 100644\n--- a/src/include/duckdb/main/extension_entries.hpp\n+++ b/src/include/duckdb/main/extension_entries.hpp\n@@ -135,6 +135,7 @@ static constexpr ExtensionFunctionEntry EXTENSION_FUNCTIONS[] = {\n     {\"covar_samp\", \"core_functions\", CatalogType::AGGREGATE_FUNCTION_ENTRY},\n     {\"create_fts_index\", \"fts\", CatalogType::PRAGMA_FUNCTION_ENTRY},\n     {\"current_database\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n+    {\"current_date\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"current_localtime\", \"icu\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"current_localtimestamp\", \"icu\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"current_query\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n@@ -179,8 +180,6 @@ static constexpr ExtensionFunctionEntry EXTENSION_FUNCTIONS[] = {\n     {\"from_hex\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"from_json\", \"json\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"from_json_strict\", \"json\", CatalogType::SCALAR_FUNCTION_ENTRY},\n-    {\"from_substrait\", \"substrait\", CatalogType::TABLE_FUNCTION_ENTRY},\n-    {\"from_substrait_json\", \"substrait\", CatalogType::TABLE_FUNCTION_ENTRY},\n     {\"fsum\", \"core_functions\", CatalogType::AGGREGATE_FUNCTION_ENTRY},\n     {\"fuzz_all_functions\", \"sqlsmith\", CatalogType::TABLE_FUNCTION_ENTRY},\n     {\"fuzzyduck\", \"sqlsmith\", CatalogType::TABLE_FUNCTION_ENTRY},\n@@ -188,9 +187,8 @@ static constexpr ExtensionFunctionEntry EXTENSION_FUNCTIONS[] = {\n     {\"gcd\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"gen_random_uuid\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"get_bit\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n+    {\"get_current_time\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"get_current_timestamp\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n-    {\"get_substrait\", \"substrait\", CatalogType::TABLE_FUNCTION_ENTRY},\n-    {\"get_substrait_json\", \"substrait\", CatalogType::TABLE_FUNCTION_ENTRY},\n     {\"grade_up\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"greatest\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"greatest_common_divisor\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n@@ -683,6 +681,7 @@ static constexpr ExtensionFunctionEntry EXTENSION_FUNCTIONS[] = {\n     {\"to_timestamp\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"to_weeks\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"to_years\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n+    {\"today\", \"core_functions\", CatalogType::SCALAR_FUNCTION_ENTRY},\n     {\"tpcds\", \"tpcds\", CatalogType::PRAGMA_FUNCTION_ENTRY},\n     {\"tpcds_answers\", \"tpcds\", CatalogType::TABLE_FUNCTION_ENTRY},\n     {\"tpcds_queries\", \"tpcds\", CatalogType::TABLE_FUNCTION_ENTRY},\n@@ -1069,24 +1068,10 @@ static constexpr ExtensionEntry EXTENSION_SECRET_PROVIDERS[] = {\n     {\"mysql/config\", \"mysql_scanner\"},\n     {\"postgres/config\", \"postgres_scanner\"}}; // EXTENSION_SECRET_PROVIDERS\n \n-static constexpr const char *AUTOLOADABLE_EXTENSIONS[] = {\"aws\",\n-                                                          \"azure\",\n-                                                          \"autocomplete\",\n-                                                          \"core_functions\",\n-                                                          \"delta\",\n-                                                          \"excel\",\n-                                                          \"fts\",\n-                                                          \"httpfs\",\n-                                                          \"inet\",\n-                                                          \"icu\",\n-                                                          \"json\",\n-                                                          \"motherduck\",\n-                                                          \"mysql_scanner\",\n-                                                          \"parquet\",\n-                                                          \"sqlite_scanner\",\n-                                                          \"sqlsmith\",\n-                                                          \"postgres_scanner\",\n-                                                          \"tpcds\",\n-                                                          \"tpch\"}; // END_OF_AUTOLOADABLE_EXTENSIONS\n+static constexpr const char *AUTOLOADABLE_EXTENSIONS[] = {\n+    \"aws\",        \"azure\",         \"autocomplete\", \"core_functions\", \"delta\",    \"excel\",\n+    \"fts\",        \"httpfs\",        \"iceberg\",      \"inet\",           \"icu\",      \"json\",\n+    \"motherduck\", \"mysql_scanner\", \"parquet\",      \"sqlite_scanner\", \"sqlsmith\", \"postgres_scanner\",\n+    \"tpcds\",      \"tpch\",          \"uc_catalog\"}; // END_OF_AUTOLOADABLE_EXTENSIONS\n \n } // namespace duckdb\ndiff --git a/src/main/connection.cpp b/src/main/connection.cpp\nindex 119b39c892ad..a5742dbfdbfa 100644\n--- a/src/main/connection.cpp\n+++ b/src/main/connection.cpp\n@@ -28,9 +28,10 @@ Connection::Connection(DatabaseInstance &database)\n }\n \n Connection::Connection(DuckDB &database) : Connection(*database.instance) {\n+\t// Initialization of warning_cb happens in the other constructor\n }\n \n-Connection::Connection(Connection &&other) noexcept {\n+Connection::Connection(Connection &&other) noexcept : warning_cb(nullptr) {\n \tstd::swap(context, other.context);\n \tstd::swap(warning_cb, other.warning_cb);\n }\n@@ -98,34 +99,6 @@ unique_ptr<MaterializedQueryResult> Connection::Query(const string &query) {\n \treturn unique_ptr_cast<QueryResult, MaterializedQueryResult>(std::move(result));\n }\n \n-DUCKDB_API string Connection::GetSubstrait(const string &query) {\n-\tvector<Value> params;\n-\tparams.emplace_back(query);\n-\tauto result = TableFunction(\"get_substrait\", params)->Execute();\n-\tauto protobuf = result->FetchRaw()->GetValue(0, 0);\n-\treturn protobuf.GetValueUnsafe<string_t>().GetString();\n-}\n-\n-DUCKDB_API unique_ptr<QueryResult> Connection::FromSubstrait(const string &proto) {\n-\tvector<Value> params;\n-\tparams.emplace_back(Value::BLOB_RAW(proto));\n-\treturn TableFunction(\"from_substrait\", params)->Execute();\n-}\n-\n-DUCKDB_API string Connection::GetSubstraitJSON(const string &query) {\n-\tvector<Value> params;\n-\tparams.emplace_back(query);\n-\tauto result = TableFunction(\"get_substrait_json\", params)->Execute();\n-\tauto protobuf = result->FetchRaw()->GetValue(0, 0);\n-\treturn protobuf.GetValueUnsafe<string_t>().GetString();\n-}\n-\n-DUCKDB_API unique_ptr<QueryResult> Connection::FromSubstraitJSON(const string &json) {\n-\tvector<Value> params;\n-\tparams.emplace_back(json);\n-\treturn TableFunction(\"from_substrait_json\", params)->Execute();\n-}\n-\n unique_ptr<MaterializedQueryResult> Connection::Query(unique_ptr<SQLStatement> statement) {\n \tauto result = context->Query(std::move(statement), false);\n \tD_ASSERT(result->type == QueryResultType::MATERIALIZED_RESULT);\ndiff --git a/src/main/extension.cpp b/src/main/extension.cpp\nindex c13971b0c2ba..e07ce4c53a64 100644\n--- a/src/main/extension.cpp\n+++ b/src/main/extension.cpp\n@@ -50,18 +50,29 @@ string ParsedExtensionMetaData::GetInvalidMetadataError() {\n \t\tconst string engine_version = string(ExtensionHelper::GetVersionDirectoryName());\n \n \t\tif (engine_version != duckdb_version) {\n-\t\t\tresult += StringUtil::Format(\"The file was built for DuckDB version '%s', but we can only load extensions \"\n-\t\t\t                             \"built for DuckDB version '%s'.\",\n+\t\t\tresult += StringUtil::Format(\"The file was built specifically for DuckDB version '%s' and can only be \"\n+\t\t\t                             \"loaded with that version of DuckDB. (this version of DuckDB is '%s')\",\n \t\t\t                             PrettyPrintString(duckdb_version), engine_version);\n \t\t}\n-\t\t// C_STRUCT ABI versioning works when current duckdb version >= required version\n+\t\t// C_STRUCT ABI versioning\n \t} else if (abi_type == ExtensionABIType::C_STRUCT) {\n-\n-\t\tif (!VersioningUtils::IsSupportedCAPIVersion(duckdb_capi_version)) {\n-\t\t\tresult += StringUtil::Format(\"The file was built for DuckDB version '%s', but we can only load extensions \"\n-\t\t\t                             \"built for DuckDB C API 'v%lld.%lld.%lld' and lower.\",\n-\t\t\t                             duckdb_capi_version, DUCKDB_EXTENSION_API_VERSION_MAJOR,\n-\t\t\t                             DUCKDB_EXTENSION_API_VERSION_MINOR, DUCKDB_EXTENSION_API_VERSION_PATCH);\n+\t\tidx_t major, minor, patch;\n+\t\tif (!VersioningUtils::ParseSemver(duckdb_capi_version, major, minor, patch)) {\n+\t\t\tresult += StringUtil::Format(\"The file was built for DuckDB C API version '%s', which failed to parse as a \"\n+\t\t\t                             \"recognized version string\",\n+\t\t\t                             duckdb_capi_version, DUCKDB_EXTENSION_API_VERSION_MAJOR);\n+\t\t} else if (major != DUCKDB_EXTENSION_API_VERSION_MAJOR) {\n+\t\t\t// Special case where the extension is built for a completely unsupported API\n+\t\t\tresult +=\n+\t\t\t    StringUtil::Format(\"The file was built for DuckDB C API version '%s', but we can only load extensions \"\n+\t\t\t                       \"built for DuckDB C API 'v%lld.x.y'.\",\n+\t\t\t                       duckdb_capi_version, DUCKDB_EXTENSION_API_VERSION_MAJOR);\n+\t\t} else if (!VersioningUtils::IsSupportedCAPIVersion(major, minor, patch)) {\n+\t\t\tresult +=\n+\t\t\t    StringUtil::Format(\"The file was built for DuckDB C API version '%s', but we can only load extensions \"\n+\t\t\t                       \"built for DuckDB C API 'v%lld.%lld.%lld' and lower.\",\n+\t\t\t                       duckdb_capi_version, DUCKDB_EXTENSION_API_VERSION_MAJOR,\n+\t\t\t                       DUCKDB_EXTENSION_API_VERSION_MINOR, DUCKDB_EXTENSION_API_VERSION_PATCH);\n \t\t}\n \t} else {\n \t\tthrow InternalException(\"Unknown ABI type for extension: \" + extension_abi_metadata);\n@@ -137,4 +148,11 @@ bool VersioningUtils::ParseSemver(string &semver, idx_t &major_out, idx_t &minor\n \treturn true;\n }\n \n+const char *Extension::DefaultVersion() {\n+\tif (ExtensionHelper::IsRelease(DuckDB::LibraryVersion())) {\n+\t\treturn DuckDB::LibraryVersion();\n+\t}\n+\treturn DuckDB::SourceID();\n+}\n+\n } // namespace duckdb\ndiff --git a/src/main/extension/extension_helper.cpp b/src/main/extension/extension_helper.cpp\nindex 015d758820ac..c7b613226a10 100644\n--- a/src/main/extension/extension_helper.cpp\n+++ b/src/main/extension/extension_helper.cpp\n@@ -114,7 +114,6 @@ static const DefaultExtension internal_extensions[] = {\n     {\"postgres_scanner\", \"Adds support for connecting to a Postgres database\", false},\n     {\"inet\", \"Adds support for IP-related data types and functions\", false},\n     {\"spatial\", \"Geospatial extension that adds support for working with spatial data and functions\", false},\n-    {\"substrait\", \"Adds support for the Substrait integration\", false},\n     {\"aws\", \"Provides features that depend on the AWS SDK\", false},\n     {\"arrow\", \"A zero-copy data integration between Apache Arrow and DuckDB\", false},\n     {\"azure\", \"Adds a filesystem abstraction for Azure blob storage to DuckDB\", false},\n@@ -140,7 +139,7 @@ DefaultExtension ExtensionHelper::GetDefaultExtension(idx_t index) {\n // Allow Auto-Install Extensions\n //===--------------------------------------------------------------------===//\n static const char *const auto_install[] = {\"motherduck\", \"postgres_scanner\", \"mysql_scanner\", \"sqlite_scanner\",\n-                                           nullptr};\n+                                           \"delta\",      \"iceberg\",          \"uc_catalog\",    nullptr};\n \n // TODO: unify with new autoload mechanism\n bool ExtensionHelper::AllowAutoInstall(const string &extension) {\ndiff --git a/src/main/extension/extension_load.cpp b/src/main/extension/extension_load.cpp\nindex 23101f722f3d..84b28fef0939 100644\n--- a/src/main/extension/extension_load.cpp\n+++ b/src/main/extension/extension_load.cpp\n@@ -399,15 +399,13 @@ bool ExtensionHelper::TryInitialLoad(DatabaseInstance &db, FileSystem &fs, const\n \t\t\tsignature_valid = false;\n \t\t}\n \n-\t\tif (!signature_valid) {\n-\t\t\tthrow IOException(db.config.error_manager->FormatException(ErrorType::UNSIGNED_EXTENSION, filename) +\n-\t\t\t                  metadata_mismatch_error);\n-\t\t}\n-\n \t\tif (!metadata_mismatch_error.empty()) {\n-\t\t\t// Signed extensions perform the full check\n \t\t\tthrow InvalidInputException(metadata_mismatch_error);\n \t\t}\n+\n+\t\tif (!signature_valid) {\n+\t\t\tthrow IOException(db.config.error_manager->FormatException(ErrorType::UNSIGNED_EXTENSION, filename));\n+\t\t}\n \t} else if (!db.config.options.allow_extensions_metadata_mismatch) {\n \t\tif (!metadata_mismatch_error.empty()) {\n \t\t\t// Unsigned extensions AND configuration allowing n, loading allowed, mainly for\ndiff --git a/src/planner/binder/expression/bind_columnref_expression.cpp b/src/planner/binder/expression/bind_columnref_expression.cpp\nindex 1c9bc238ba8a..e5995d2915b9 100644\n--- a/src/planner/binder/expression/bind_columnref_expression.cpp\n+++ b/src/planner/binder/expression/bind_columnref_expression.cpp\n@@ -436,11 +436,13 @@ BindResult ExpressionBinder::BindExpression(ColumnRefExpression &col_ref_p, idx_\n \t\t\tif (found_alias) {\n \t\t\t\treturn alias_result;\n \t\t\t}\n-\n-\t\t\t// column was not found - check if it is a SQL value function\n-\t\t\tauto value_function = GetSQLValueFunction(col_ref_p.GetColumnName());\n-\t\t\tif (value_function) {\n-\t\t\t\treturn BindExpression(value_function, depth);\n+\t\t\tfound_alias = QualifyColumnAlias(col_ref_p);\n+\t\t\tif (!found_alias) {\n+\t\t\t\t// column was not found - check if it is a SQL value function\n+\t\t\t\tauto value_function = GetSQLValueFunction(col_ref_p.GetColumnName());\n+\t\t\t\tif (value_function) {\n+\t\t\t\t\treturn BindExpression(value_function, depth);\n+\t\t\t\t}\n \t\t\t}\n \t\t}\n \t\terror.AddQueryLocation(col_ref_p);\ndiff --git a/src/planner/binder/tableref/bind_table_function.cpp b/src/planner/binder/tableref/bind_table_function.cpp\nindex 3f4c249bda23..26dd86c9dfd1 100644\n--- a/src/planner/binder/tableref/bind_table_function.cpp\n+++ b/src/planner/binder/tableref/bind_table_function.cpp\n@@ -203,7 +203,9 @@ unique_ptr<LogicalOperator> Binder::BindTableFunctionInternal(TableFunction &tab\n \t\t                                  table_function.function_info.get(), this, table_function, ref);\n \t\tif (table_function.bind_replace) {\n \t\t\tauto new_plan = table_function.bind_replace(context, bind_input);\n-\t\t\tif (new_plan != nullptr) {\n+\t\t\tif (new_plan) {\n+\t\t\t\tnew_plan->alias = ref.alias;\n+\t\t\t\tnew_plan->column_name_alias = ref.column_name_alias;\n \t\t\t\treturn CreatePlan(*Bind(*new_plan));\n \t\t\t} else if (!table_function.bind) {\n \t\t\t\tthrow BinderException(\"Failed to bind \\\"%s\\\": nullptr returned from bind_replace without bind function\",\ndiff --git a/src/planner/expression/bound_function_expression.cpp b/src/planner/expression/bound_function_expression.cpp\nindex 1be27254099b..be146bd5090f 100644\n--- a/src/planner/expression/bound_function_expression.cpp\n+++ b/src/planner/expression/bound_function_expression.cpp\n@@ -109,12 +109,28 @@ void BoundFunctionExpression::Serialize(Serializer &serializer) const {\n unique_ptr<Expression> BoundFunctionExpression::Deserialize(Deserializer &deserializer) {\n \tauto return_type = deserializer.ReadProperty<LogicalType>(200, \"return_type\");\n \tauto children = deserializer.ReadProperty<vector<unique_ptr<Expression>>>(201, \"children\");\n+\n \tauto entry = FunctionSerializer::Deserialize<ScalarFunction, ScalarFunctionCatalogEntry>(\n \t    deserializer, CatalogType::SCALAR_FUNCTION_ENTRY, children, return_type);\n \tauto function_return_type = entry.first.return_type;\n+\n+\tauto is_operator = deserializer.ReadProperty<bool>(202, \"is_operator\");\n+\n+\tif (entry.first.bind_expression) {\n+\t\t// bind the function expression\n+\t\tauto &context = deserializer.Get<ClientContext &>();\n+\t\tauto bind_input = FunctionBindExpressionInput(context, entry.second, children);\n+\t\t// replace the function expression with the bound expression\n+\t\tauto bound_expression = entry.first.bind_expression(bind_input);\n+\t\tif (bound_expression) {\n+\t\t\treturn bound_expression;\n+\t\t}\n+\t\t// Otherwise, fall thorugh and continue on normally\n+\t}\n+\n \tauto result = make_uniq<BoundFunctionExpression>(std::move(function_return_type), std::move(entry.first),\n \t                                                 std::move(children), std::move(entry.second));\n-\tdeserializer.ReadProperty(202, \"is_operator\", result->is_operator);\n+\tresult->is_operator = is_operator;\n \tif (result->return_type != return_type) {\n \t\t// return type mismatch - push a cast\n \t\tauto &context = deserializer.Get<ClientContext &>();\ndiff --git a/tools/pythonpkg/duckdb-stubs/__init__.pyi b/tools/pythonpkg/duckdb-stubs/__init__.pyi\nindex b98763f7d3d9..8c57cce2aa8f 100644\n--- a/tools/pythonpkg/duckdb-stubs/__init__.pyi\n+++ b/tools/pythonpkg/duckdb-stubs/__init__.pyi\n@@ -343,10 +343,6 @@ class DuckDBPyConnection:\n     def from_arrow(self, arrow_object: object) -> DuckDBPyRelation: ...\n     def from_parquet(self, file_glob: str, binary_as_string: bool = False, *, file_row_number: bool = False, filename: bool = False, hive_partitioning: bool = False, union_by_name: bool = False, compression: Optional[str] = None) -> DuckDBPyRelation: ...\n     def read_parquet(self, file_glob: str, binary_as_string: bool = False, *, file_row_number: bool = False, filename: bool = False, hive_partitioning: bool = False, union_by_name: bool = False, compression: Optional[str] = None) -> DuckDBPyRelation: ...\n-    def from_substrait(self, proto: bytes) -> DuckDBPyRelation: ...\n-    def get_substrait(self, query: str, *, enable_optimizer: bool = True) -> str: ...\n-    def get_substrait_json(self, query: str, *, enable_optimizer: bool = True) -> str: ...\n-    def from_substrait_json(self, json: str) -> DuckDBPyRelation: ...\n     def get_table_names(self, query: str) -> Set[str]: ...\n     def install_extension(self, extension: str, *, force_install: bool = False, repository: Optional[str] = None, repository_url: Optional[str] = None, version: Optional[str] = None) -> None: ...\n     def load_extension(self, extension: str) -> None: ...\n@@ -694,10 +690,6 @@ def from_df(df: pandas.DataFrame, *, connection: DuckDBPyConnection = ...) -> Du\n def from_arrow(arrow_object: object, *, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...\n def from_parquet(file_glob: str, binary_as_string: bool = False, *, file_row_number: bool = False, filename: bool = False, hive_partitioning: bool = False, union_by_name: bool = False, compression: Optional[str] = None, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...\n def read_parquet(file_glob: str, binary_as_string: bool = False, *, file_row_number: bool = False, filename: bool = False, hive_partitioning: bool = False, union_by_name: bool = False, compression: Optional[str] = None, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...\n-def from_substrait(proto: bytes, *, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...\n-def get_substrait(query: str, *, enable_optimizer: bool = True, connection: DuckDBPyConnection = ...) -> str: ...\n-def get_substrait_json(query: str, *, enable_optimizer: bool = True, connection: DuckDBPyConnection = ...) -> str: ...\n-def from_substrait_json(json: str, *, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...\n def get_table_names(query: str, *, connection: DuckDBPyConnection = ...) -> Set[str]: ...\n def install_extension(extension: str, *, force_install: bool = False, repository: Optional[str] = None, repository_url: Optional[str] = None, version: Optional[str] = None, connection: DuckDBPyConnection = ...) -> None: ...\n def load_extension(extension: str, *, connection: DuckDBPyConnection = ...) -> None: ...\ndiff --git a/tools/pythonpkg/duckdb/__init__.py b/tools/pythonpkg/duckdb/__init__.py\nindex 04dfb7640dd2..4799270c3e31 100644\n--- a/tools/pythonpkg/duckdb/__init__.py\n+++ b/tools/pythonpkg/duckdb/__init__.py\n@@ -125,10 +125,6 @@\n \tread_parquet,\n \tfrom_parquet,\n \tread_parquet,\n-\tfrom_substrait,\n-\tget_substrait,\n-\tget_substrait_json,\n-\tfrom_substrait_json,\n \tget_table_names,\n \tinstall_extension,\n \tload_extension,\n@@ -208,10 +204,6 @@\n \t'read_parquet',\n \t'from_parquet',\n \t'read_parquet',\n-\t'from_substrait',\n-\t'get_substrait',\n-\t'get_substrait_json',\n-\t'from_substrait_json',\n \t'get_table_names',\n \t'install_extension',\n \t'load_extension',\ndiff --git a/tools/pythonpkg/duckdb_python.cpp b/tools/pythonpkg/duckdb_python.cpp\nindex 784269f4bd35..dcffa2bb6c7e 100644\n--- a/tools/pythonpkg/duckdb_python.cpp\n+++ b/tools/pythonpkg/duckdb_python.cpp\n@@ -754,46 +754,6 @@ static void InitializeConnectionMethods(py::module_ &m) {\n \t    py::arg(\"binary_as_string\") = false, py::kw_only(), py::arg(\"file_row_number\") = false,\n \t    py::arg(\"filename\") = false, py::arg(\"hive_partitioning\") = false, py::arg(\"union_by_name\") = false,\n \t    py::arg(\"compression\") = py::none(), py::arg(\"connection\") = py::none());\n-\tm.def(\n-\t    \"from_substrait\",\n-\t    [](py::bytes &proto, shared_ptr<DuckDBPyConnection> conn = nullptr) {\n-\t\t    if (!conn) {\n-\t\t\t    conn = DuckDBPyConnection::DefaultConnection();\n-\t\t    }\n-\t\t    return conn->FromSubstrait(proto);\n-\t    },\n-\t    \"Create a query object from protobuf plan\", py::arg(\"proto\"), py::kw_only(),\n-\t    py::arg(\"connection\") = py::none());\n-\tm.def(\n-\t    \"get_substrait\",\n-\t    [](const string &query, bool enable_optimizer = true, shared_ptr<DuckDBPyConnection> conn = nullptr) {\n-\t\t    if (!conn) {\n-\t\t\t    conn = DuckDBPyConnection::DefaultConnection();\n-\t\t    }\n-\t\t    return conn->GetSubstrait(query, enable_optimizer);\n-\t    },\n-\t    \"Serialize a query to protobuf\", py::arg(\"query\"), py::kw_only(), py::arg(\"enable_optimizer\") = true,\n-\t    py::arg(\"connection\") = py::none());\n-\tm.def(\n-\t    \"get_substrait_json\",\n-\t    [](const string &query, bool enable_optimizer = true, shared_ptr<DuckDBPyConnection> conn = nullptr) {\n-\t\t    if (!conn) {\n-\t\t\t    conn = DuckDBPyConnection::DefaultConnection();\n-\t\t    }\n-\t\t    return conn->GetSubstraitJSON(query, enable_optimizer);\n-\t    },\n-\t    \"Serialize a query to protobuf on the JSON format\", py::arg(\"query\"), py::kw_only(),\n-\t    py::arg(\"enable_optimizer\") = true, py::arg(\"connection\") = py::none());\n-\tm.def(\n-\t    \"from_substrait_json\",\n-\t    [](const string &json, shared_ptr<DuckDBPyConnection> conn = nullptr) {\n-\t\t    if (!conn) {\n-\t\t\t    conn = DuckDBPyConnection::DefaultConnection();\n-\t\t    }\n-\t\t    return conn->FromSubstraitJSON(json);\n-\t    },\n-\t    \"Create a query object from a JSON protobuf plan\", py::arg(\"json\"), py::kw_only(),\n-\t    py::arg(\"connection\") = py::none());\n \tm.def(\n \t    \"get_table_names\",\n \t    [](const string &query, shared_ptr<DuckDBPyConnection> conn = nullptr) {\ndiff --git a/tools/pythonpkg/scripts/connection_methods.json b/tools/pythonpkg/scripts/connection_methods.json\nindex e64d60f772fc..19f06c760309 100644\n--- a/tools/pythonpkg/scripts/connection_methods.json\n+++ b/tools/pythonpkg/scripts/connection_methods.json\n@@ -988,68 +988,6 @@\n \t\t],\n \t\t\"return\": \"DuckDBPyRelation\"\n \t},\n-\t{\n-\t\t\"name\": \"from_substrait\",\n-\t\t\"function\": \"FromSubstrait\",\n-\t\t\"docs\": \"Create a query object from protobuf plan\",\n-\t\t\"args\": [\n-\t\t\t{\n-\t\t\t\t\"name\": \"proto\",\n-\t\t\t\t\"type\": \"bytes\"\n-\t\t\t}\n-\t\t],\n-\t\t\"return\": \"DuckDBPyRelation\"\n-\t},\n-\t{\n-\t\t\"name\": \"get_substrait\",\n-\t\t\"function\": \"GetSubstrait\",\n-\t\t\"docs\": \"Serialize a query to protobuf\",\n-\t\t\"args\": [\n-\t\t\t{\n-\t\t\t\t\"name\": \"query\",\n-\t\t\t\t\"type\": \"str\"\n-\t\t\t}\n-\t\t],\n-\t\t\"kwargs\": [\n-\t\t\t{\n-\t\t\t\t\"name\": \"enable_optimizer\",\n-\t\t\t\t\"default\": \"True\",\n-\t\t\t\t\"type\": \"bool\"\n-\t\t\t}\n-\t\t],\n-\t\t\"return\": \"str\"\n-\t},\n-\t{\n-\t\t\"name\": \"get_substrait_json\",\n-\t\t\"function\": \"GetSubstraitJSON\",\n-\t\t\"docs\": \"Serialize a query to protobuf on the JSON format\",\n-\t\t\"args\": [\n-\t\t\t{\n-\t\t\t\t\"name\": \"query\",\n-\t\t\t\t\"type\": \"str\"\n-\t\t\t}\n-\t\t],\n-\t\t\"kwargs\": [\n-\t\t\t{\n-\t\t\t\t\"name\": \"enable_optimizer\",\n-\t\t\t\t\"default\": \"True\",\n-\t\t\t\t\"type\": \"bool\"\n-\t\t\t}\n-\t\t],\n-\t\t\"return\": \"str\"\n-\t},\n-\t{\n-\t\t\"name\": \"from_substrait_json\",\n-\t\t\"function\": \"FromSubstraitJSON\",\n-\t\t\"docs\": \"Create a query object from a JSON protobuf plan\",\n-\t\t\"args\": [\n-\t\t\t{\n-\t\t\t\t\"name\": \"json\",\n-\t\t\t\t\"type\": \"str\"\n-\t\t\t}\n-\t\t],\n-\t\t\"return\": \"DuckDBPyRelation\"\n-\t},\n \t{\n \t\t\"name\": \"get_table_names\",\n \t\t\"function\": \"GetTableNames\",\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/pyconnection/pyconnection.hpp b/tools/pythonpkg/src/include/duckdb_python/pyconnection/pyconnection.hpp\nindex aad8c44bc3ca..e108cbe5ff59 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/pyconnection/pyconnection.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/pyconnection/pyconnection.hpp\n@@ -271,14 +271,6 @@ struct DuckDBPyConnection : public enable_shared_from_this<DuckDBPyConnection> {\n \n \tunique_ptr<DuckDBPyRelation> FromArrow(py::object &arrow_object);\n \n-\tunique_ptr<DuckDBPyRelation> FromSubstrait(py::bytes &proto);\n-\n-\tunique_ptr<DuckDBPyRelation> GetSubstrait(const string &query, bool enable_optimizer = true);\n-\n-\tunique_ptr<DuckDBPyRelation> GetSubstraitJSON(const string &query, bool enable_optimizer = true);\n-\n-\tunique_ptr<DuckDBPyRelation> FromSubstraitJSON(const string &json);\n-\n \tunordered_set<string> GetTableNames(const string &query);\n \n \tshared_ptr<DuckDBPyConnection> UnregisterPythonObject(const string &name);\ndiff --git a/tools/pythonpkg/src/pyconnection.cpp b/tools/pythonpkg/src/pyconnection.cpp\nindex 13cd5e1512ba..b1131801ead7 100644\n--- a/tools/pythonpkg/src/pyconnection.cpp\n+++ b/tools/pythonpkg/src/pyconnection.cpp\n@@ -266,15 +266,6 @@ static void InitializeConnectionMethods(py::class_<DuckDBPyConnection, shared_pt\n \t      py::arg(\"binary_as_string\") = false, py::kw_only(), py::arg(\"file_row_number\") = false,\n \t      py::arg(\"filename\") = false, py::arg(\"hive_partitioning\") = false, py::arg(\"union_by_name\") = false,\n \t      py::arg(\"compression\") = py::none());\n-\tm.def(\"from_substrait\", &DuckDBPyConnection::FromSubstrait, \"Create a query object from protobuf plan\",\n-\t      py::arg(\"proto\"));\n-\tm.def(\"get_substrait\", &DuckDBPyConnection::GetSubstrait, \"Serialize a query to protobuf\", py::arg(\"query\"),\n-\t      py::kw_only(), py::arg(\"enable_optimizer\") = true);\n-\tm.def(\"get_substrait_json\", &DuckDBPyConnection::GetSubstraitJSON,\n-\t      \"Serialize a query to protobuf on the JSON format\", py::arg(\"query\"), py::kw_only(),\n-\t      py::arg(\"enable_optimizer\") = true);\n-\tm.def(\"from_substrait_json\", &DuckDBPyConnection::FromSubstraitJSON,\n-\t      \"Create a query object from a JSON protobuf plan\", py::arg(\"json\"));\n \tm.def(\"get_table_names\", &DuckDBPyConnection::GetTableNames, \"Extract the required table names from a query\",\n \t      py::arg(\"query\"));\n \tm.def(\"install_extension\", &DuckDBPyConnection::InstallExtension,\n@@ -1731,40 +1722,6 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromArrow(py::object &arrow_obj\n \treturn make_uniq<DuckDBPyRelation>(std::move(rel));\n }\n \n-unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromSubstrait(py::bytes &proto) {\n-\tauto &connection = con.GetConnection();\n-\tstring name = \"substrait_\" + StringUtil::GenerateRandomName();\n-\tvector<Value> params;\n-\tparams.emplace_back(Value::BLOB_RAW(proto));\n-\treturn make_uniq<DuckDBPyRelation>(connection.TableFunction(\"from_substrait\", params)->Alias(name));\n-}\n-\n-unique_ptr<DuckDBPyRelation> DuckDBPyConnection::GetSubstrait(const string &query, bool enable_optimizer) {\n-\tauto &connection = con.GetConnection();\n-\tvector<Value> params;\n-\tparams.emplace_back(query);\n-\tnamed_parameter_map_t named_parameters({{\"enable_optimizer\", Value::BOOLEAN(enable_optimizer)}});\n-\treturn make_uniq<DuckDBPyRelation>(\n-\t    connection.TableFunction(\"get_substrait\", params, named_parameters)->Alias(query));\n-}\n-\n-unique_ptr<DuckDBPyRelation> DuckDBPyConnection::GetSubstraitJSON(const string &query, bool enable_optimizer) {\n-\tauto &connection = con.GetConnection();\n-\tvector<Value> params;\n-\tparams.emplace_back(query);\n-\tnamed_parameter_map_t named_parameters({{\"enable_optimizer\", Value::BOOLEAN(enable_optimizer)}});\n-\treturn make_uniq<DuckDBPyRelation>(\n-\t    connection.TableFunction(\"get_substrait_json\", params, named_parameters)->Alias(query));\n-}\n-\n-unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromSubstraitJSON(const string &json) {\n-\tauto &connection = con.GetConnection();\n-\tstring name = \"from_substrait_\" + StringUtil::GenerateRandomName();\n-\tvector<Value> params;\n-\tparams.emplace_back(json);\n-\treturn make_uniq<DuckDBPyRelation>(connection.TableFunction(\"from_substrait_json\", params)->Alias(name));\n-}\n-\n unordered_set<string> DuckDBPyConnection::GetTableNames(const string &query) {\n \tauto &connection = con.GetConnection();\n \treturn connection.GetTableNames(query);\ndiff --git a/tools/sqlite3_api_wrapper/include/shell_extension.hpp b/tools/sqlite3_api_wrapper/include/shell_extension.hpp\nindex 429adbfd5279..090d99cb44ec 100644\n--- a/tools/sqlite3_api_wrapper/include/shell_extension.hpp\n+++ b/tools/sqlite3_api_wrapper/include/shell_extension.hpp\n@@ -16,6 +16,7 @@ class ShellExtension : public Extension {\n public:\n \tvoid Load(DuckDB &db) override;\n \tstd::string Name() override;\n+\tstd::string Version() const override;\n };\n \n } // namespace duckdb\ndiff --git a/tools/sqlite3_api_wrapper/shell_extension.cpp b/tools/sqlite3_api_wrapper/shell_extension.cpp\nindex e2c074060d40..b553635ff534 100644\n--- a/tools/sqlite3_api_wrapper/shell_extension.cpp\n+++ b/tools/sqlite3_api_wrapper/shell_extension.cpp\n@@ -38,4 +38,8 @@ std::string ShellExtension::Name() {\n \treturn \"shell\";\n }\n \n+std::string ShellExtension::Version() const {\n+\treturn DefaultVersion();\n+}\n+\n } // namespace duckdb\n", "test_patch": "diff --git a/test/api/adbc/test_adbc.cpp b/test/api/adbc/test_adbc.cpp\nindex c61d2696fa68..afcbb596d073 100644\n--- a/test/api/adbc/test_adbc.cpp\n+++ b/test/api/adbc/test_adbc.cpp\n@@ -1017,96 +1017,6 @@ TEST_CASE(\"Test ADBC ConnectionGetTableSchema\", \"[adbc]\") {\n \tadbc_error.release(&adbc_error);\n }\n \n-TEST_CASE(\"Test ADBC Substrait\", \"[adbc]\") {\n-\tif (!duckdb_lib) {\n-\t\treturn;\n-\t}\n-\tAdbcDatabase adbc_database;\n-\tAdbcConnection adbc_connection;\n-\n-\tAdbcError adbc_error;\n-\tAdbcStatement adbc_statement;\n-\tInitializeADBCError(&adbc_error);\n-\n-\tArrowArrayStream arrow_stream;\n-\tArrowArray arrow_array;\n-\n-\tREQUIRE(SUCCESS(AdbcDatabaseNew(&adbc_database, &adbc_error)));\n-\tREQUIRE(SUCCESS(AdbcDatabaseSetOption(&adbc_database, \"driver\", duckdb_lib, &adbc_error)));\n-\tREQUIRE(SUCCESS(AdbcDatabaseSetOption(&adbc_database, \"entrypoint\", \"duckdb_adbc_init\", &adbc_error)));\n-\tREQUIRE(SUCCESS(AdbcDatabaseSetOption(&adbc_database, \"path\", \":memory:\", &adbc_error)));\n-\n-\tREQUIRE(SUCCESS(AdbcDatabaseInit(&adbc_database, &adbc_error)));\n-\n-\tREQUIRE(SUCCESS(AdbcConnectionNew(&adbc_connection, &adbc_error)));\n-\tREQUIRE(SUCCESS(AdbcConnectionInit(&adbc_connection, &adbc_database, &adbc_error)));\n-\n-\tauto conn = static_cast<Connection *>(adbc_connection.private_data);\n-\tif (!conn->context->db->ExtensionIsLoaded(\"substrait\")) {\n-\t\t// We need substrait to run this test\n-\t\tREQUIRE(SUCCESS(AdbcConnectionRelease(&adbc_connection, &adbc_error)));\n-\t\tREQUIRE(SUCCESS(AdbcDatabaseRelease(&adbc_database, &adbc_error)));\n-\t\treturn;\n-\t}\n-\t// Insert Data\n-\tADBCTestDatabase db;\n-\tauto &input_data = db.QueryArrow(\"SELECT 'Push Ups' as exercise, 3 as difficulty_level;\");\n-\tstring table_name = \"crossfit\";\n-\tREQUIRE(SUCCESS(AdbcStatementNew(&adbc_connection, &adbc_statement, &adbc_error)));\n-\n-\tREQUIRE(\n-\t    SUCCESS(StatementSetOption(&adbc_statement, ADBC_INGEST_OPTION_TARGET_TABLE, table_name.c_str(), &adbc_error)));\n-\n-\tREQUIRE(SUCCESS(StatementBindStream(&adbc_statement, &input_data, &adbc_error)));\n-\n-\tREQUIRE(SUCCESS(StatementExecuteQuery(&adbc_statement, nullptr, nullptr, &adbc_error)));\n-\n-\t// SELECT COUNT(*) FROM CROSSFIT\n-\tauto str_plan =\n-\t    \"\\\\x12\\\\x09\\\\x1A\\\\x07\\\\x10\\\\x01\\\\x1A\\\\x03lte\\\\x12\\\\x11\\\\x1A\\\\x0F\\\\x10\\\\x02\\\\x1A\\\\x0Bis_not_\"\n-\t    \"null\\\\x12\\\\x09\\\\x1A\\\\x07\\\\x10\\\\x03\\\\x1A\\\\x03and\\\\x12\\\\x0B\\\\x1A\\\\x09\\\\x10\\\\x04\\\\x1A\\\\x05count\\\\x1A\\\\xC7\\\\x01\\\\x\"\n-\t    \"12\\\\xC4\\\\x01\\\\x0A\\\\xB7\\\\x01:\\\\xB4\\\\x01\\\\x12\\\\xA7\\\\x01\\\\x22\\\\xA4\\\\x01\\\\x12\\\\x93\\\\x01\\\\x0A\\\\x90\\\\x01\\\\x12.\"\n-\t    \"\\\\x0A\\\\x08exercise\\\\x0A\\\\x0Fdificulty_level\\\\x12\\\\x11\\\\x0A\\\\x07\\\\xB2\\\\x01\\\\x04\\\\x08\\\\x0D\\\\x18\\\\x01\\\\x0A\\\\x04*\"\n-\t    \"\\\\x02\\\\x10\\\\x01\\\\x18\\\\x02\\\\x1AJ\\\\x1AH\\\\x08\\\\x03\\\\x1A\\\\x04\\\\x0A\\\\x02\\\\x10\\\\x01\\\\x22\\\\x22\\\\x1A \"\n-\t    \"\\\\x1A\\\\x1E\\\\x08\\\\x01\\\\x1A\\\\x04*\"\n-\t    \"\\\\x02\\\\x10\\\\x01\\\\x22\\\\x0C\\\\x1A\\\\x0A\\\\x12\\\\x08\\\\x0A\\\\x04\\\\x12\\\\x02\\\\x08\\\\x01\\\\x22\\\\x00\\\\x22\\\\x06\\\\x1A\\\\x04\\\\x0A\"\n-\t    \"\\\\x02(\\\\x05\\\\x22\\\\x1A\\\\x1A\\\\x18\\\\x1A\\\\x16\\\\x08\\\\x02\\\\x1A\\\\x04*\"\n-\t    \"\\\\x02\\\\x10\\\\x01\\\\x22\\\\x0C\\\\x1A\\\\x0A\\\\x12\\\\x08\\\\x0A\\\\x04\\\\x12\\\\x02\\\\x08\\\\x01\\\\x22\\\\x00\\\\x22\\\\x06\\\\x0A\\\\x02\\\\x0A\"\n-\t    \"\\\\x00\\\\x10\\\\x01:\\\\x0A\\\\x0A\\\\x08crossfit\\\\x1A\\\\x00\\\\x22\\\\x0A\\\\x0A\\\\x08\\\\x08\\\\x04*\\\\x04:\"\n-\t    \"\\\\x02\\\\x10\\\\x01\\\\x1A\\\\x08\\\\x12\\\\x06\\\\x0A\\\\x02\\\\x12\\\\x00\\\\x22\\\\x00\\\\x12\\\\x08exercise2\\\\x0A\\\\x10\\\\x18*\"\n-\t    \"\\\\x06DuckDB\";\n-\tauto plan = reinterpret_cast<const uint8_t *>(str_plan);\n-\tsize_t length = strlen(str_plan);\n-\tREQUIRE(SUCCESS(AdbcStatementRelease(&adbc_statement, &adbc_error)));\n-\n-\tREQUIRE(SUCCESS(AdbcStatementNew(&adbc_connection, &adbc_statement, &adbc_error)));\n-\tREQUIRE(SUCCESS(AdbcStatementSetSubstraitPlan(&adbc_statement, plan, length, &adbc_error)));\n-\tint64_t rows_affected;\n-\tREQUIRE(SUCCESS(AdbcStatementExecuteQuery(&adbc_statement, &arrow_stream, &rows_affected, &adbc_error)));\n-\tarrow_stream.get_next(&arrow_stream, &arrow_array);\n-\tREQUIRE(((reinterpret_cast<const int64_t *>(arrow_array.children[0]->buffers[1])[0] == 1)));\n-\tarrow_array.release(&arrow_array);\n-\tarrow_stream.release(&arrow_stream);\n-\n-\t// Try some errors\n-\tREQUIRE(!SUCCESS(AdbcStatementSetSubstraitPlan(&adbc_statement, nullptr, length, &adbc_error)));\n-\tREQUIRE((std::strcmp(adbc_error.message, \"Substrait Plan is not set\") == 0));\n-\tadbc_error.release(&adbc_error);\n-\n-\tREQUIRE(!SUCCESS(AdbcStatementSetSubstraitPlan(&adbc_statement, plan, 0, &adbc_error)));\n-\tREQUIRE((std::strcmp(adbc_error.message, \"Can't execute plan with size = 0\") == 0));\n-\tadbc_error.release(&adbc_error);\n-\n-\t// Broken Plan\n-\tREQUIRE(!SUCCESS(AdbcStatementSetSubstraitPlan(&adbc_statement, plan, 5, &adbc_error)));\n-\tREQUIRE(StringUtil::Contains(adbc_error.message, \"unterminated escape code at end of blob\"));\n-\n-\tREQUIRE(SUCCESS(AdbcStatementRelease(&adbc_statement, &adbc_error)));\n-\tREQUIRE(SUCCESS(AdbcConnectionRelease(&adbc_connection, &adbc_error)));\n-\tREQUIRE(SUCCESS(AdbcDatabaseRelease(&adbc_database, &adbc_error)));\n-\tadbc_error.release(&adbc_error);\n-}\n-\n TEST_CASE(\"Test ADBC Prepared Statement - Prepare nop\", \"[adbc]\") {\n \tif (!duckdb_lib) {\n \t\treturn;\ndiff --git a/test/api/capi/test_capi_data_chunk.cpp b/test/api/capi/test_capi_data_chunk.cpp\nindex 79012f375c39..fb8a6692374e 100644\n--- a/test/api/capi/test_capi_data_chunk.cpp\n+++ b/test/api/capi/test_capi_data_chunk.cpp\n@@ -513,12 +513,13 @@ TEST_CASE(\"Test DataChunk write BLOB\", \"[capi]\") {\n \tduckdb_destroy_logical_type(&column_type);\n \tuint8_t bytes[] = {0x80, 0x00, 0x01, 0x2a};\n \tduckdb_vector_assign_string_element_len(vector, 0, (const char *)bytes, 4);\n-\tauto string_data = (duckdb_string_t *)duckdb_vector_get_data(vector);\n-\tREQUIRE(string_data[0].value.inlined.length == 4);\n-\tREQUIRE(string_data[0].value.inlined.inlined[0] == (char)0x80);\n-\tREQUIRE(string_data[0].value.inlined.inlined[1] == (char)0x00);\n-\tREQUIRE(string_data[0].value.inlined.inlined[2] == (char)0x01);\n-\tREQUIRE(string_data[0].value.inlined.inlined[3] == (char)0x2a);\n+\tauto string_data = static_cast<duckdb_string_t *>(duckdb_vector_get_data(vector));\n+\tauto string_value = duckdb_string_t_data(string_data);\n+\tREQUIRE(duckdb_string_t_length(*string_data) == 4);\n+\tREQUIRE(string_value[0] == (char)0x80);\n+\tREQUIRE(string_value[1] == (char)0x00);\n+\tREQUIRE(string_value[2] == (char)0x01);\n+\tREQUIRE(string_value[3] == (char)0x2a);\n \tduckdb_destroy_data_chunk(&chunk);\n \tduckdb_destroy_logical_type(&type);\n }\n@@ -536,12 +537,13 @@ TEST_CASE(\"Test DataChunk write VARINT\", \"[capi]\") {\n \tduckdb_destroy_logical_type(&column_type);\n \tuint8_t bytes[] = {0x80, 0x00, 0x01, 0x2a}; // VARINT 42\n \tduckdb_vector_assign_string_element_len(vector, 0, (const char *)bytes, 4);\n-\tauto string_data = (duckdb_string_t *)duckdb_vector_get_data(vector);\n-\tREQUIRE(string_data[0].value.inlined.length == 4);\n-\tREQUIRE(string_data[0].value.inlined.inlined[0] == (char)0x80);\n-\tREQUIRE(string_data[0].value.inlined.inlined[1] == (char)0x00);\n-\tREQUIRE(string_data[0].value.inlined.inlined[2] == (char)0x01);\n-\tREQUIRE(string_data[0].value.inlined.inlined[3] == (char)0x2a);\n+\tauto string_data = static_cast<duckdb_string_t *>(duckdb_vector_get_data(vector));\n+\tauto string_value = duckdb_string_t_data(string_data);\n+\tREQUIRE(duckdb_string_t_length(*string_data) == 4);\n+\tREQUIRE(string_value[0] == (char)0x80);\n+\tREQUIRE(string_value[1] == (char)0x00);\n+\tREQUIRE(string_value[2] == (char)0x01);\n+\tREQUIRE(string_value[3] == (char)0x2a);\n \tduckdb_destroy_data_chunk(&chunk);\n \tduckdb_destroy_logical_type(&type);\n }\ndiff --git a/test/extension/update_extensions_ci.test b/test/extension/update_extensions_ci.test\nindex a8aceb8dae98..3171f0fe2be4 100644\n--- a/test/extension/update_extensions_ci.test\n+++ b/test/extension/update_extensions_ci.test\n@@ -202,13 +202,13 @@ statement error\n FORCE INSTALL '${DIRECT_INSTALL_DIR}/json_incorrect_version.duckdb_extension';\n ----\n Failed to install './build/extension_metadata_test_data/direct_install/json_incorrect_version.duckdb_extension'\n-The file was built for DuckDB version 'v1337', but we can only load extensions built for DuckDB version\n+The file was built specifically for DuckDB version 'v1337' and can only be loaded with that version of DuckDB. (this version of DuckDB is\n \n statement error\n FORCE INSTALL json_incorrect_version FROM '${LOCAL_EXTENSION_REPO_INCORRECT_DUCKDB_VERSION}';\n ----\n Failed to install 'json_incorrect_version'\n-The file was built for DuckDB version 'v1337', but we can only load extensions built for DuckDB version\n+The file was built specifically for DuckDB version 'v1337' and can only be loaded with that version of DuckDB. (this version of DuckDB is\n \n # These should print both errors\n statement error\n@@ -235,7 +235,7 @@ The file was built for the platform 'test_platform', but we can only load extens\n statement error\n LOAD '${DIRECT_INSTALL_DIR}/json_incorrect_version.duckdb_extension';\n ----\n-The file was built for DuckDB version 'v1337', but we can only load extensions built for DuckDB version\n+The file was built specifically for DuckDB version 'v1337' and can only be loaded with that version of DuckDB. (this version of DuckDB is\n \n # Note that this is the json extension with incorrect platform and version\n statement error\ndiff --git a/test/sql/aggregate/external/simple_external_aggregate.test_slow b/test/sql/aggregate/external/simple_external_aggregate.test_slow\nindex c0525f0b0fa2..317974e3f044 100644\n--- a/test/sql/aggregate/external/simple_external_aggregate.test_slow\n+++ b/test/sql/aggregate/external/simple_external_aggregate.test_slow\n@@ -27,7 +27,7 @@ statement ok\n set disabled_optimizers to 'compressed_materialization'\n \n statement ok\n-pragma memory_limit='600MB'\n+pragma memory_limit='800MB'\n \n query I\n select count(*) from (select distinct * from t1)\ndiff --git a/test/sql/catalog/function/query_function.test b/test/sql/catalog/function/query_function.test\nindex 0d65fa65b4ac..1ef00218e192 100644\n--- a/test/sql/catalog/function/query_function.test\n+++ b/test/sql/catalog/function/query_function.test\n@@ -249,6 +249,16 @@ FROM query_table('SELECT 4 + 2');\n ----\n Catalog Error: Table with name SELECT 4 + 2 does not exist!\n \n+query I\n+SELECT f.* FROM query_table('tbl_int') as f;\n+----\n+42\n+\n+query I\n+SELECT f.x FROM query_table('tbl_int') as f(x);\n+----\n+42\n+\n # test by_name argument\n query I\n FROM query_table(['tbl_int', 'tbl_varchar', 'tbl_empty', 'tbl2_varchar'], false);\ndiff --git a/test/sql/catalog/test_extension_suggestion.test b/test/sql/catalog/test_extension_suggestion.test\nindex 94f2307e15d0..9d88900f2680 100644\n--- a/test/sql/catalog/test_extension_suggestion.test\n+++ b/test/sql/catalog/test_extension_suggestion.test\n@@ -7,6 +7,6 @@ require skip_reload\n require no_extension_autoloading \"EXPECTED: This tests what happens when extension is not there\"\n \n statement error\n-SELECT get_substrait(\"select 1\");\n+SELECT from_json('data/json/array_of_empty_arrays.json');\n ----\n-Catalog Error: Scalar Function with name \"get_substrait\" is not in the catalog, a function by this name exists in the substrait extension, but it's of a different type, namely Table Function\n+Catalog Error: Scalar Function with name \"from_json\" is not in the catalog, but it exists in the json extension.\n\\ No newline at end of file\ndiff --git a/test/sql/copy/csv/14512.test b/test/sql/copy/csv/14512.test\nindex c970e05a47ca..c85603500d48 100644\n--- a/test/sql/copy/csv/14512.test\n+++ b/test/sql/copy/csv/14512.test\n@@ -6,7 +6,7 @@ statement ok\n PRAGMA enable_verification\n \n query II\n-FROM 'data/csv/14512.csv';\n+FROM read_csv('data/csv/14512.csv', RFC_4180=TRUE);\n ----\n onions \t,\n \ndiff --git a/test/sql/copy/csv/afl/test_fuzz_3977.test b/test/sql/copy/csv/afl/test_fuzz_3977.test\nnew file mode 100644\nindex 000000000000..16620e82a637\n--- /dev/null\n+++ b/test/sql/copy/csv/afl/test_fuzz_3977.test\n@@ -0,0 +1,363 @@\n+# name: test/sql/copy/csv/afl/test_fuzz_3977.test\n+# description: fuzzer generated csv files - should not raise internal exception (by failed assertion).\n+# group: [afl]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+query I\n+select count(file) from glob('./data/csv/afl/3977/*');\n+----\n+88\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_1.csv', rejects_scan=0, buffer_size=655371, all_varchar=false, rejects_scan=0, buffer_size=42);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_2.csv', names=['a','b','c','d'], store_rejects=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_3.csv', names=['a','b','c','d'], store_rejects=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_4.csv', names=['a','b','c','d'], store_rejects=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_5.csv', auto_detect=false, columns={'a': 'VARCHAR'}, escape='\"', header=false, quote='\"', rfc_4180=true, store_rejects=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_6.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_7.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_8.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_9.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=false);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_10.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_11.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_12.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_13.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_14.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_15.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_16.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_17.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_18.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_19.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_20.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_21.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_22.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_23.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_24.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_25.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_26.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_27.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_28.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_29.csv', auto_detect=false, buffer_size=65536, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_30.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_31.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_32.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_33.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_34.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_35.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_36.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_37.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_38.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_39.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_40.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, comment=';', rejects_table='\"', rfc_4180=false);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_41.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_42.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_43.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_44.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_45.csv', auto_detect=false, buffer_size=810, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_46.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_47.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_48.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_49.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_50.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','\u0010':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_51.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', '|':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_52.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_53.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_54.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAr'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_55.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_56.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_57.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_58.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_59.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','\"':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_60.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_61.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_62.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_63.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_64.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_65.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_66.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_67.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_68.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_69.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_70.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_71.csv', auto_detect=false, buffer_size=16711722, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_72.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','F':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_73.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_74.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_75.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_76.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_77.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_78.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_79.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_80.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_81.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_82.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_83.csv', auto_detect=false, parallel=false, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_84.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_85.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_86.csv', auto_detect=false, buffer_size=720938, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_87.csv', auto_detect=false, buffer_size=42, columns={'a2.0-22222222222222222.0222->>':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3977/case_88.csv', auto_detect=false, buffer_size=42, columns={'a':'INTEGER','b':'INTEGER', 'c':'VARCHAR'}, delim=';', rejects_table='\"', rfc_4180=true);\n+----\ndiff --git a/test/sql/copy/csv/afl/test_fuzz_3981.test_slow b/test/sql/copy/csv/afl/test_fuzz_3981.test_slow\nnew file mode 100644\nindex 000000000000..19ad0bbcd0fe\n--- /dev/null\n+++ b/test/sql/copy/csv/afl/test_fuzz_3981.test_slow\n@@ -0,0 +1,40 @@\n+# name: test/sql/copy/csv/afl/test_fuzz_3981.test_slow\n+# description: fuzzer generated csv files - should not raise internal exception (by failed assertion).\n+# group: [afl]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+query I\n+select count(file) from glob('data/csv/afl/3981/*');\n+----\n+7\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3981/case_0.csv', compression='gzip');\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3981/case_1.csv', compression='gzip');\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3981/case_2.csv', compression='gzip');\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3981/case_3.csv', compression='gzip');\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3981/case_4.csv', compression='gzip');\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3981/case_5.csv', compression='gzip');\n+----\n+\n+statement maybe\n+FROM read_csv('data/csv/afl/3981/case_6.csv', compression='gzip');\n+----\n+\ndiff --git a/test/sql/copy/csv/auto/test_csv_auto.test b/test/sql/copy/csv/auto/test_csv_auto.test\nindex 54ad76526a46..9d689d0dd316 100644\n--- a/test/sql/copy/csv/auto/test_csv_auto.test\n+++ b/test/sql/copy/csv/auto/test_csv_auto.test\n@@ -19,7 +19,8 @@ FROM read_csv('data/csv/repromarket.csv',\n    header=false,\n    skip=0,\n    null_padding=true,\n-   ignore_errors=true\n+   ignore_errors=true,\n+   RFC_4180=true\n );\n ----\n nemanja.krpovic@gmail.com\tkrlleta\n@@ -53,7 +54,8 @@ select columns FROM sniff_csv('data/csv/auto/mock_duckdb_test_data.csv', ignore_\n [{'name': id, 'type': BIGINT}, {'name': name, 'type': VARCHAR}, {'name': age, 'type': BIGINT}, {'name': sex, 'type': VARCHAR}, {'name': state, 'type': VARCHAR}]\n \n query IIIII\n-FROM read_csv('data/csv/auto/mock_duckdb_test_data.csv', ignore_errors = true)\n+FROM read_csv('data/csv/auto/mock_duckdb_test_data.csv', ignore_errors = true,\n+   RFC_4180=true)\n ----\n 1\tJames\t30\tM\tAL\n 2\tJill\t32\tF\tCO\n@@ -64,7 +66,8 @@ FROM read_csv('data/csv/auto/mock_duckdb_test_data.csv', ignore_errors = true)\n 9\tTitus\t38\tM\tWY\n \n statement error\n-select * from read_csv_auto('data/csv/dates.csv', auto_detect=false, delim=',', quote='\"', columns={'a': 'VARCHAR'})\n+select * from read_csv_auto('data/csv/dates.csv', auto_detect=false, delim=',', quote='\"', columns={'a': 'VARCHAR'},\n+   RFC_4180=true)\n ----\n Expected Number of Columns: 1 Found: 2\n \ndiff --git a/test/sql/copy/csv/csv_line_too_long.test b/test/sql/copy/csv/csv_line_too_long.test\nindex 6563b660e6b9..e1a91d760da8 100644\n--- a/test/sql/copy/csv/csv_line_too_long.test\n+++ b/test/sql/copy/csv/csv_line_too_long.test\n@@ -8,17 +8,21 @@ PRAGMA enable_verification\n statement ok\n CREATE TABLE T1 (name VARCHAR);\n \n-\n-foreach path data/csv/line_too_long.csv.gz data/csv/line_too_long_with_newline.csv.gz data/csv/multiple_line_too_long.csv.gz\n-\n foreach header true false\n \n-\n statement error\n-COPY T1(name) from '${path}' (DELIMITER ',', HEADER ${header} , COMPRESSION gzip, ALLOW_QUOTED_NULLS false);\n+COPY T1(name) from 'data/csv/line_too_long.csv.gz' (DELIMITER ',', HEADER ${header} , COMPRESSION gzip, ALLOW_QUOTED_NULLS false);\n ----\n Maximum line size of 2000000 bytes exceeded\n \n-endloop\n+statement error\n+COPY T1(name) from 'data/csv/line_too_long_with_newline.csv.gz' (DELIMITER ',', HEADER ${header} , COMPRESSION gzip, ALLOW_QUOTED_NULLS false);\n+----\n+Be sure that the maximum line size is set to an appropriate value\n+\n+statement error\n+COPY T1(name) from 'data/csv/multiple_line_too_long.csv.gz' (DELIMITER ',', HEADER ${header} , COMPRESSION gzip, ALLOW_QUOTED_NULLS false);\n+----\n+Be sure that the maximum line size is set to an appropriate value\n \n endloop\ndiff --git a/test/sql/copy/csv/pollock/test_field_delimiter.test b/test/sql/copy/csv/pollock/test_field_delimiter.test\nnew file mode 100644\nindex 000000000000..b2b4304245f2\n--- /dev/null\n+++ b/test/sql/copy/csv/pollock/test_field_delimiter.test\n@@ -0,0 +1,11 @@\n+# name: test/sql/copy/csv/pollock/test_field_delimiter.test\n+# description: Test field delimiter from Pollock\n+# group: [pollock]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+FROM read_csv('data/csv/pollock/file_field_delimiter_0x20.csv', delim = ' ', escape = '\"', quote='\"', header = false, skip=1,\n+columns = {'Date':'VARCHAR','TIME':'VARCHAR','Qty':'VARCHAR','PRODUCTID':'VARCHAR','Price':'VARCHAR'\n+,'ProductType':'VARCHAR','ProductDescription':'VARCHAR','URL':'VARCHAR','Comments':'VARCHAR'}, auto_detect = false, RFC_4180=FALSE, null_padding = true)\ndiff --git a/test/sql/copy/csv/pollock/test_quotation_char.test b/test/sql/copy/csv/pollock/test_quotation_char.test\nnew file mode 100644\nindex 000000000000..1d259a2c6459\n--- /dev/null\n+++ b/test/sql/copy/csv/pollock/test_quotation_char.test\n@@ -0,0 +1,11 @@\n+# name: test/sql/copy/csv/pollock/test_quotation_char.test\n+# description: Test quotation from Pollock\n+# group: [pollock]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+FROM read_csv('data/csv/pollock/file_quotation_char_0x27.csv', delim = ',', escape = '\"', quote='''',\n+columns = {'Date':'VARCHAR','TIME':'VARCHAR','Qty':'VARCHAR','PRODUCTID':'VARCHAR','Price':'VARCHAR'\n+,'ProductType':'VARCHAR','ProductDescription':'VARCHAR','URL':'VARCHAR','Comments':'VARCHAR'}, auto_detect = false, RFC_4180=FALSE, null_padding = true)\ndiff --git a/test/sql/copy/csv/rejects/csv_incorrect_columns_amount_rejects.test b/test/sql/copy/csv/rejects/csv_incorrect_columns_amount_rejects.test\nindex 6fc829c263b9..ff418f8f8eb1 100644\n--- a/test/sql/copy/csv/rejects/csv_incorrect_columns_amount_rejects.test\n+++ b/test/sql/copy/csv/rejects/csv_incorrect_columns_amount_rejects.test\n@@ -36,7 +36,7 @@ statement ok\n SELECT * FROM read_csv(\n     'data/csv/rejects/incorrect_columns/many_columns.csv',\n     columns = {'a': 'INTEGER', 'b': 'INTEGER', 'c': 'INTEGER', 'd': 'INTEGER'},\n-    store_rejects=true, auto_detect=false, header = 1);\n+    store_rejects=true, auto_detect=false, header = 1, RFC_4180=True);\n \n query IIIIIIIII rowsort\n SELECT * EXCLUDE (scan_id) FROM reject_errors order by all;\n@@ -58,7 +58,7 @@ statement ok\n SELECT * FROM read_csv(\n     'data/csv/rejects/incorrect_columns/mix_columns.csv',\n     columns = {'a': 'INTEGER', 'b': 'INTEGER', 'c': 'INTEGER', 'd': 'INTEGER'},\n-    store_rejects=true, auto_detect=false, header = 1);\n+    store_rejects=true, auto_detect=false, header = 1, RFC_4180=True);\n \n query IIIIIIIII rowsort\n SELECT * EXCLUDE (scan_id) FROM reject_errors order by all;\n@@ -87,7 +87,7 @@ statement ok\n SELECT * FROM read_csv(\n     'data/csv/rejects/incorrect_columns/small_mix.csv',\n     columns = {'a': 'INTEGER', 'b': 'INTEGER', 'c': 'INTEGER', 'd': 'INTEGER'},\n-    store_rejects=true, auto_detect=false, header = 1);\n+    store_rejects=true, auto_detect=false, header = 1, RFC_4180=True);\n \n query IIIIIIIII rowsort\n SELECT * EXCLUDE (scan_id) FROM reject_errors order by all\n@@ -108,7 +108,7 @@ statement ok\n SELECT * FROM read_csv(\n     'data/csv/rejects/incorrect_columns/*.csv',\n     columns = {'a': 'INTEGER', 'b': 'INTEGER', 'c': 'INTEGER', 'd': 'INTEGER'},\n-   store_rejects=true, auto_detect=false, header = 1);\n+   store_rejects=true, auto_detect=false, header = 1, RFC_4180=True);\n \n query IIIIIIIII rowsort\n SELECT * EXCLUDE (scan_id) FROM reject_errors order by all\ndiff --git a/test/sql/copy/csv/rejects/csv_rejects_read.test b/test/sql/copy/csv/rejects/csv_rejects_read.test\nindex 2a33a2e779b4..bc0d8dda524c 100644\n--- a/test/sql/copy/csv/rejects/csv_rejects_read.test\n+++ b/test/sql/copy/csv/rejects/csv_rejects_read.test\n@@ -271,7 +271,7 @@ statement ok\n DROP TABLE reject_scans;\n \n query II\n-FROM read_csv('data/csv/error.csv', store_rejects=1);\n+FROM read_csv('data/csv/error.csv', store_rejects=1, RFC_4180=True);\n ----\n true\tfalse\n \ndiff --git a/test/sql/copy/csv/rejects/test_multiple_errors_same_line.test b/test/sql/copy/csv/rejects/test_multiple_errors_same_line.test\nindex e89a3bf13f97..fa63fffe9124 100644\n--- a/test/sql/copy/csv/rejects/test_multiple_errors_same_line.test\n+++ b/test/sql/copy/csv/rejects/test_multiple_errors_same_line.test\n@@ -10,7 +10,7 @@ require notwindows\n query IIII\n FROM read_csv('data/csv/rejects/multiple_errors/cast_and_more_col.csv',\n     columns = {'name': 'VARCHAR', 'age': 'INTEGER', 'current_day': 'DATE', 'barks': 'INTEGER'},\n-    store_rejects = true, auto_detect=false, header = 1);\n+    store_rejects = true, auto_detect=false, header = 1, RFC_4180=True);\n ----\n oogie boogie\t3\t2023-01-01\t2\n oogie boogie\t3\t2023-01-02\t5\n@@ -33,7 +33,7 @@ DROP TABLE reject_scans;\n query IIII\n FROM read_csv('data/csv/rejects/multiple_errors/multiple_cast_implicit.csv',\n     columns = {'name': 'VARCHAR', 'age': 'INTEGER', 'current_day': 'DATE', 'barks': 'INTEGER'},\n-    store_rejects = true, auto_detect=false, header = 1);\n+    store_rejects = true, auto_detect=false, header = 1, RFC_4180=True);\n ----\n oogie boogie\t3\t2023-01-01\t2\n oogie boogie\t3\t2023-01-02\t5\n@@ -158,7 +158,7 @@ DROP TABLE reject_scans;\n query IIII\n FROM read_csv('data/csv/rejects/multiple_errors/more_col_and_max_line.csv',\n     columns = {'name': 'VARCHAR', 'age': 'INTEGER', 'current_day': 'DATE', 'barks': 'INTEGER'},\n-    store_rejects = true, auto_detect=false, header = 1, max_line_size=40);\n+    store_rejects = true, auto_detect=false, header = 1, max_line_size=40, RFC_4180=True);\n ----\n oogie boogie\t3\t2023-01-01\t2\n oogie boogie\t3\t2023-01-02\t5\n@@ -300,7 +300,7 @@ DROP TABLE reject_scans;\n query IIII\n FROM read_csv('data/csv/rejects/multiple_errors/invalid_utf_max_line.csv',\n     columns = {'name': 'VARCHAR', 'age': 'INTEGER', 'current_day': 'DATE', 'barks': 'INTEGER'},\n-    store_rejects = true, auto_detect=false, header = 1, max_line_size=40);\n+    store_rejects = true, auto_detect=false, header = 1, max_line_size=40, RFC_4180=True);\n ----\n oogie boogie\t3\t2023-01-01\t2\n \n@@ -321,7 +321,7 @@ DROP TABLE reject_scans;\n query IIII\n FROM read_csv('data/csv/rejects/multiple_errors/invalid_utf_more.csv',\n     columns = {'name': 'VARCHAR', 'age': 'INTEGER', 'current_day': 'DATE', 'barks': 'INTEGER'},\n-    store_rejects = true, auto_detect=false, header = 1, max_line_size=40);\n+    store_rejects = true, auto_detect=false, header = 1, max_line_size=40, RFC_4180=True);\n ----\n oogie boogie\t3\t2023-01-01\t2\n \ndiff --git a/test/sql/copy/csv/relaxed_quotes.test b/test/sql/copy/csv/relaxed_quotes.test\nindex caaea768486b..ef3cd5bae806 100644\n--- a/test/sql/copy/csv/relaxed_quotes.test\n+++ b/test/sql/copy/csv/relaxed_quotes.test\n@@ -28,8 +28,8 @@ de:08115:4574:0:2\tWeil der Stadt Stadtgarten\t48.7523774577301\t8.869444093766\n de:08115:4575:0:1\tWeil der Stadt Merklinger Stra\u00dfe\t48.7554808692434\t8.86798882300553\n de:08115:4575:0:2\tWeil der Stadt Merklinger Stra\u00dfe\t48.7554808692434\t8.86798882300553\n de:08115:4577:0:1\tM\u00fcnklingen Neuhauser Str.\t48.7769389105929\t8.81035291436839\n-de:08317:12007:2:1\tLahr Schl\u00fcssel Vis-\u00e0-Vis Bus more text\t48.3411985847104\t7.87932997062448\n-de:08317:12007:2:1\tLahr Schl\u00fcssel Vis-\u00e0-Vis Bus\t48.3411985847104\t7.87932997062448\n+de:08317:12007:2:1\tLahr Schl\u00fcssel \"Vis-\u00e0-Vis Bus\" more text\t48.3411985847104\t7.87932997062448\n+de:08317:12007:2:1\tLahr Schl\u00fcssel \"Vis-\u00e0-Vis Bus\"\t48.3411985847104\t7.87932997062448\n \n query II\n from read_csv('data/csv/unescaped_quotes/unescaped_quote.csv', escape = '\"', rfc_4180=false);\ndiff --git a/test/sql/copy/csv/test_comment_midline.test b/test/sql/copy/csv/test_comment_midline.test\nindex 55cc29b35997..6d1ef940ef51 100644\n--- a/test/sql/copy/csv/test_comment_midline.test\n+++ b/test/sql/copy/csv/test_comment_midline.test\n@@ -102,7 +102,7 @@ FROM 'data/csv/comments/midline_empty_space.csv';\n 6\t7\n \n query II\n-FROM read_csv('data/csv/comments/mid_line_invalid.csv', ignore_errors = true, delim = ';', comment = '#', auto_detect = false, columns= {'a':'integer', 'b':'integer'});\n+FROM read_csv('data/csv/comments/mid_line_invalid.csv', ignore_errors = true, delim = ';', comment = '#', auto_detect = false, columns= {'a':'integer', 'b':'integer'}, RFC_4180=True);\n ----\n 1\t3\n 6\t7\ndiff --git a/test/sql/copy/csv/test_extra_delimiters_rfc.test b/test/sql/copy/csv/test_extra_delimiters_rfc.test\nnew file mode 100644\nindex 000000000000..eab1009f2175\n--- /dev/null\n+++ b/test/sql/copy/csv/test_extra_delimiters_rfc.test\n@@ -0,0 +1,14 @@\n+# name: test/sql/copy/csv/test_extra_delimiters_rfc.test\n+# description: Test Export function that is not null\n+# group: [csv]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+query III\n+FROM read_csv('data/csv/extra_delimiters.csv', RFC_4180 = false, columns={'a':'VARCHAR','b':'VARCHAR','c':'VARCHAR'}, auto_detect = false, delim = ',', header = true)\n+----\n+1\t2\t3\n+1\t2\t3\n+1\t2\t3\n+1\t2\t3\n\\ No newline at end of file\ndiff --git a/test/sql/copy/csv/test_ignore_errors.test b/test/sql/copy/csv/test_ignore_errors.test\nindex a6c36c9e38f0..93c673f4a1ab 100644\n--- a/test/sql/copy/csv/test_ignore_errors.test\n+++ b/test/sql/copy/csv/test_ignore_errors.test\n@@ -68,7 +68,7 @@ statement ok\n DELETE FROM integers;\n \n statement ok\n-COPY integers FROM 'data/csv/test/error_too_many.csv' (HEADER, IGNORE_ERRORS, SAMPLE_SIZE -1)\n+COPY integers FROM 'data/csv/test/error_too_many.csv' (HEADER, IGNORE_ERRORS, SAMPLE_SIZE -1, RFC_4180 TRUE)\n \n statement error\n COPY integers FROM 'data/csv/test/error_too_many.csv' (HEADER)\ndiff --git a/test/sql/copy/csv/test_ignore_mid_null_line.test b/test/sql/copy/csv/test_ignore_mid_null_line.test\nindex 7ed5a1cbd0fe..6278dcc0bc9f 100644\n--- a/test/sql/copy/csv/test_ignore_mid_null_line.test\n+++ b/test/sql/copy/csv/test_ignore_mid_null_line.test\n@@ -7,7 +7,7 @@ PRAGMA enable_verification\n \n query III\n FROM read_csv('data/csv/error/mid_null.csv', delim = ';',\n-     columns = {'a':'integer','b':'integer','c':'integer'}, auto_detect = false, header = true, ignore_errors = true)\n+     columns = {'a':'integer','b':'integer','c':'integer'}, auto_detect = false, header = true, ignore_errors = true, RFC_4180=True)\n ----\n 1\t2\t3\n 1\t2\t3\n\\ No newline at end of file\ndiff --git a/test/sql/copy/csv/test_null_padding_projection.test b/test/sql/copy/csv/test_null_padding_projection.test\nindex 33ed335cf78e..3f1fd020162d 100644\n--- a/test/sql/copy/csv/test_null_padding_projection.test\n+++ b/test/sql/copy/csv/test_null_padding_projection.test\n@@ -8,14 +8,14 @@ PRAGMA enable_verification\n # Test simple null_padding, this will fail because we have a row with more columns that defined\n statement error\n from read_csv('data/csv/nullpadding.csv',null_padding=true, columns={\n-'a': 'INTEGER','b': 'INTEGER','c': 'INTEGER','d': 'INTEGER'}, auto_detect = false)\n+'a': 'INTEGER','b': 'INTEGER','c': 'INTEGER','d': 'INTEGER'}, auto_detect = false, rfc_4180=True)\n ----\n Expected Number of Columns: 4 Found: 5\n \n # Create a view\n statement ok\n CREATE VIEW np AS  from read_csv('data/csv/nullpadding.csv',null_padding=true, columns={\n-'a': 'INTEGER','b': 'INTEGER','c': 'INTEGER','d': 'INTEGER'}, auto_detect = false, ignore_errors = true);\n+'a': 'INTEGER','b': 'INTEGER','c': 'INTEGER','d': 'INTEGER'}, auto_detect = false, ignore_errors = true, rfc_4180=True);\n \n # With ignore errors this should work, with last row being ignored\n query IIII\n@@ -46,7 +46,7 @@ NULL\tNULL\n # Now let's try with options that give a const value\n query IIIII\n from read_csv('data/csv/nullpadding.csv',null_padding=true, columns={\n-'a': 'INTEGER','b': 'INTEGER','c': 'INTEGER','d': 'INTEGER'}, auto_detect => false, ignore_errors => true, filename => true);\n+'a': 'INTEGER','b': 'INTEGER','c': 'INTEGER','d': 'INTEGER'}, auto_detect => false, ignore_errors => true, filename => true, rfc_4180=True);\n ----\n 10\t100\t1000\tNULL\tdata/csv/nullpadding.csv\n 10\t100\t1000\t10000\tdata/csv/nullpadding.csv\n@@ -55,7 +55,7 @@ from read_csv('data/csv/nullpadding.csv',null_padding=true, columns={\n \n query II\n select a, filename from read_csv('data/csv/nullpadding.csv',null_padding=true, columns={\n-'a': 'INTEGER','b': 'INTEGER','c': 'INTEGER','d': 'INTEGER'}, auto_detect => false, ignore_errors => true, filename => true);\n+'a': 'INTEGER','b': 'INTEGER','c': 'INTEGER','d': 'INTEGER'}, auto_detect => false, ignore_errors => true, filename => true, rfc_4180=True);\n ----\n 10\tdata/csv/nullpadding.csv\n 10\tdata/csv/nullpadding.csv\n@@ -64,7 +64,7 @@ select a, filename from read_csv('data/csv/nullpadding.csv',null_padding=true, c\n \n query I\n select filename from read_csv('data/csv/nullpadding.csv',null_padding=true, columns={\n-'a': 'INTEGER','b': 'INTEGER','c': 'INTEGER','d': 'INTEGER'}, auto_detect => false, ignore_errors => true, filename => true);\n+'a': 'INTEGER','b': 'INTEGER','c': 'INTEGER','d': 'INTEGER'}, auto_detect => false, ignore_errors => true, filename => true, rfc_4180=True);\n ----\n data/csv/nullpadding.csv\n data/csv/nullpadding.csv\n@@ -73,7 +73,7 @@ data/csv/nullpadding.csv\n \n query I\n select a from read_csv('data/csv/nullpadding.csv',null_padding=true, columns={\n-'a': 'INTEGER','b': 'INTEGER','c': 'INTEGER','d': 'INTEGER'}, auto_detect = false, ignore_errors => true, filename => true);\n+'a': 'INTEGER','b': 'INTEGER','c': 'INTEGER','d': 'INTEGER'}, auto_detect = false, ignore_errors => true, filename => true, rfc_4180=True);\n ----\n 10\n 10\n@@ -84,7 +84,7 @@ select a from read_csv('data/csv/nullpadding.csv',null_padding=true, columns={\n \n query IIII\n select * from read_csv('data/csv/nullpadding.csv',null_padding=true, columns={\n-'a': 'INTEGER','b': 'INTEGER','c': 'INTEGER','d': 'INTEGER'}, auto_detect := false, ignore_errors := true)\n+'a': 'INTEGER','b': 'INTEGER','c': 'INTEGER','d': 'INTEGER'}, auto_detect := false, ignore_errors := true, rfc_4180=True)\n where  b = 100;\n ----\n 10\t100\t1000\tNULL\n@@ -94,7 +94,7 @@ where  b = 100;\n \n query IIIII\n select * from read_csv('data/csv/nullpadding.csv',null_padding=true, columns={\n-'a': 'INTEGER','b': 'INTEGER','c': 'INTEGER','d': 'INTEGER'}, auto_detect = false, ignore_errors = true, filename = true)\n+'a': 'INTEGER','b': 'INTEGER','c': 'INTEGER','d': 'INTEGER'}, auto_detect = false, ignore_errors = true, filename = true, rfc_4180=True)\n where a = 10 and d = 10000;\n ----\n 10\t100\t1000\t10000\tdata/csv/nullpadding.csv\ndiff --git a/test/sql/copy/csv/test_skip.test_slow b/test/sql/copy/csv/test_skip.test_slow\nindex b0fe6dd30cba..e6f71c6d7b4e 100644\n--- a/test/sql/copy/csv/test_skip.test_slow\n+++ b/test/sql/copy/csv/test_skip.test_slow\n@@ -5,8 +5,6 @@\n statement ok\n PRAGMA enable_verification\n \n-mode skip\n-\n statement ok\n copy (from range(10000)) to '__TEST_DIR__/skip.csv' (HEADER 0);\n \n@@ -67,10 +65,11 @@ SELECT * EXCLUDE (prompt) from sniff_csv('__TEST_DIR__/skip.csv',skip=3000)\n ----\n ,\t\\0\t\\0\t\\n\t\\0\t3000\t0\t[{'name': column0, 'type': BIGINT}]\tNULL\tNULL\tskip=3000\n \n+# If we don't encounter a value, we use skip\n query IIIIIIIIIII\n SELECT * EXCLUDE (prompt) from sniff_csv('__TEST_DIR__/skip.csv',skip=11000)\n ----\n-,\t\\0\t\\0\t\\n\t\\0\t11000\t0\t[{'name': column0, 'type': BIGINT}]\tNULL\tNULL\tskip=11000\n+,\t\\0\t\\0\t\\n\t\\0\t11000\t0\t[{'name': column0, 'type': VARCHAR}]\tNULL\tNULL\tskip=11000\n \n # Test with different buffer sizes\n \ndiff --git a/test/sql/json/issues/internal_issue4014.test b/test/sql/json/issues/internal_issue4014.test\nnew file mode 100644\nindex 000000000000..5e14739dc015\n--- /dev/null\n+++ b/test/sql/json/issues/internal_issue4014.test\n@@ -0,0 +1,8 @@\n+# name: test/sql/json/issues/internal_issue4014.test\n+# description: Test internal issue 4014 - AFL++ issue: segfault in json reader\n+# group: [issues]\n+\n+require json\n+\n+statement ok\n+FROM read_json('data/json/internal_4014.json', map_inference_threshold=0);\ndiff --git a/test/sql/parser/test_value_functions.test b/test/sql/parser/test_value_functions.test\nindex 32d6dd39fd41..ee507d265133 100644\n--- a/test/sql/parser/test_value_functions.test\n+++ b/test/sql/parser/test_value_functions.test\n@@ -71,3 +71,9 @@ select a as \"CURRENT_TIMESTAMP\" from (VALUES (84), (42)) t(a) order by \"CURRENT_\n ----\n 42\n 84\n+\n+# value function conflict in WHERE\n+query I\n+select a as localtime from (VALUES ('2018-01-01'), ('2022-01-01')) t(a) where localtime >= '2020-01-01'\n+----\n+2022-01-01\ndiff --git a/test/sql/sample/table_samples/basic_sample_tests.test b/test/sql/sample/table_samples/basic_sample_tests.test\nindex 2107062f32c3..1bb07364c9c3 100644\n--- a/test/sql/sample/table_samples/basic_sample_tests.test\n+++ b/test/sql/sample/table_samples/basic_sample_tests.test\n@@ -46,14 +46,14 @@ true\ttrue\n \n # about half the samples are below 102400 and half above\n query I\n-select count(*) < 1060 from duckdb_table_sample('t1') where a < 102400;\n+select count(*) from duckdb_table_sample('t1') where a < 102400;\n ----\n-true\n+1069\n \n query I\n-select count(*) < 1060 from duckdb_table_sample('t1') where a > 102400;\n+select count(*) from duckdb_table_sample('t1') where a > 102400;\n ----\n-true\n+979\n \n query I\n select count(*) from t1 using sample (200000);\ndiff --git a/test/sql/sample/table_samples/table_sample_is_stored.test_slow b/test/sql/sample/table_samples/table_sample_is_stored.test_slow\nindex aed4fbc8aae4..f8370557d2a5 100644\n--- a/test/sql/sample/table_samples/table_sample_is_stored.test_slow\n+++ b/test/sql/sample/table_samples/table_sample_is_stored.test_slow\n@@ -61,13 +61,13 @@ select count(*) from duckdb_table_sample('integers_2');\n \n \n query II\n-select floor(b / 1000000) as interval, count(*) > 350 as frequency from duckdb_table_sample('integers_1') group by interval order by all;\n+select floor(b / 1000000) as interval, count(*) as frequency from duckdb_table_sample('integers_1') group by interval order by all;\n ----\n-0.0\ttrue\n-1.0\ttrue\n-2.0\ttrue\n-3.0\ttrue\n-4.0\ttrue\n+0.0\t453\n+1.0\t408\n+2.0\t406\n+3.0\t404\n+4.0\t377\n \n \n # adding another interval should subtract an equal number from the rest of the intervals\n@@ -75,14 +75,14 @@ statement ok\n insert into integers_1 (select (range + 5) a, range b from range(5000000,6000000));\n \n query II\n-select floor(b / 1000000) as interval, count(*) > 300 as frequency from duckdb_table_sample('integers_1') group by interval order by all;\n+select floor(b / 1000000) as interval, count(*) as frequency from duckdb_table_sample('integers_1') group by interval order by all;\n ----\n-0.0\ttrue\n-1.0\ttrue\n-2.0\ttrue\n-3.0\ttrue\n-4.0\ttrue\n-5.0\ttrue\n+0.0\t374\n+1.0\t334\n+2.0\t332\n+3.0\t334\n+4.0\t311\n+5.0\t363\n \n # If double the table count is appended, around half the sample should account for the new values.\n statement ok\n@@ -97,17 +97,17 @@ select count(*) from integers_1;\n ## about half of the samples should have the pair '-1', 1.\n # on latest storage test its something like 997\n query I\n-select count(*) > 924 and count(*) < 1124 from duckdb_table_sample('integers_1') where a = -1 and b = -1;\n+select count(*) from duckdb_table_sample('integers_1') where a = -1 and b = -1;\n ----\n-true\n+914\n \n restart\n \n # updated sample is also newly serialized\n query I\n-select count(*) > 924 and count(*) < 1124 from duckdb_table_sample('integers_1') where a = -1 and b = -1;\n+select count(*) from duckdb_table_sample('integers_1') where a = -1 and b = -1;\n ----\n-true\n+914\n \n # create a view on top of the sample\n statement ok\n@@ -118,27 +118,18 @@ statement ok\n insert into integers_1 (select -2, -2 from range(6000000));\n \n \n-# 2048 / 3 = 682 (706 is good)\n-# on latest storage is 670\n+# 2048 / 3 = 682 (639 is good)\n query I\n-select count(*) > 600 and count(*) < 750 from sample_view where a = -2 and b = -2;\n+select count(*) from sample_view where a = -2 and b = -2;\n ----\n-true\n-\n-#query I nosort result_2\n-#select count(*) from sample_view where a = -2 and b = -2;\n-#----\n+639\n \n restart\n \n query I\n-select count(*) > 600 and count(*) < 750 from sample_view where a = -2 and b = -2;\n-----\n-true\n-\n-query I nosort result_2\n-select count(*) from sample_view where a = -2 and b = -2;\n+select count(*)  from sample_view where a = -2 and b = -2;\n ----\n+639\n \n # currently have 18_000_000 values in the table.\n # to try and get 1 value in the sample, we should add\ndiff --git a/test/sql/storage/parallel/insert_many_compressible_batches.test_slow b/test/sql/storage/parallel/insert_many_compressible_batches.test_slow\nindex 224460ef2dab..483e3e1b5626 100644\n--- a/test/sql/storage/parallel/insert_many_compressible_batches.test_slow\n+++ b/test/sql/storage/parallel/insert_many_compressible_batches.test_slow\n@@ -106,8 +106,10 @@ COMMIT\n # NULLs are RLE compressed (with Roaring)\n # So even with nulls we reach a similar compression ratio\n \n+mode skip\n+\n query I\n-SELECT COUNT(DISTINCT block_id) < 5 FROM pragma_storage_info('integers_batched_load_nulls');\n+SELECT COUNT(DISTINCT block_id) < 8 FROM pragma_storage_info('integers_batched_load_nulls');\n ----\n true\n \ndiff --git a/test/sql/tpch/dbgen_error.test b/test/sql/tpch/dbgen_error.test\nnew file mode 100644\nindex 000000000000..94600c66aa4f\n--- /dev/null\n+++ b/test/sql/tpch/dbgen_error.test\n@@ -0,0 +1,18 @@\n+# name: test/sql/tpch/dbgen_error.test\n+# description: Test error thrown during dbgen\n+# group: [tpch]\n+\n+require tpch\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+SET memory_limit = '100MB';\n+\n+statement ok\n+SET temp_directory = '.unrecognized_folder/folder2'\n+\n+statement error\n+CALL dbgen(sf=1);\n+----\ndiff --git a/test/sql/types/test_typeof.test b/test/sql/types/test_typeof.test\nnew file mode 100644\nindex 000000000000..1a2bd0231d80\n--- /dev/null\n+++ b/test/sql/types/test_typeof.test\n@@ -0,0 +1,10 @@\n+# name: test/sql/types/test_typeof.test\n+# group: [types]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+query I\n+SELECT typeof(1)\n+----\n+INTEGER\n\\ No newline at end of file\ndiff --git a/test/sql/window/test_streaming_lead_lag.test b/test/sql/window/test_streaming_lead_lag.test\nindex 143813a6d8b9..de7be94f09e8 100644\n--- a/test/sql/window/test_streaming_lead_lag.test\n+++ b/test/sql/window/test_streaming_lead_lag.test\n@@ -222,3 +222,30 @@ FROM range(10) tbl(i)\n 7\t8\t9\n 8\t9\tNULL\n 9\tNULL\tNULL\n+\n+# Test incomplete buffering\n+query II\n+select * from (\n+\tselect \n+\t\tid, \n+\t\tlead(id, 2047, -1) over() l \n+\tfrom range(6144) tbl(id)\n+\twhere id != 1 \n+\t  and id != 2 \n+\t  and id != 2500 \n+\t  and id != 2501 \n+\t  and id != 2502\n+) \n+where id >= 2040 and id <= 2050;\n+----\n+2040\t4090\n+2041\t4091\n+2042\t4092\n+2043\t4093\n+2044\t4094\n+2045\t4095\n+2046\t4096\n+2047\t4097\n+2048\t4098\n+2049\t4099\n+2050\t4100\ndiff --git a/tools/pythonpkg/tests/fast/api/test_duckdb_connection.py b/tools/pythonpkg/tests/fast/api/test_duckdb_connection.py\nindex 560c8b320444..bd53c985fee4 100644\n--- a/tools/pythonpkg/tests/fast/api/test_duckdb_connection.py\n+++ b/tools/pythonpkg/tests/fast/api/test_duckdb_connection.py\n@@ -270,15 +270,6 @@ def test_from_parquet(self):\n     def test_from_query(self):\n         assert None != duckdb.from_query\n \n-    def test_from_substrait(self):\n-        assert None != duckdb.from_substrait\n-\n-    def test_get_substrait(self):\n-        assert None != duckdb.get_substrait\n-\n-    def test_get_substrait_json(self):\n-        assert None != duckdb.get_substrait_json\n-\n     def test_get_table_names(self):\n         assert None != duckdb.get_table_names\n \n", "problem_statement": "Binder error when using query_table with an alias\n### What happens?\n\nGiving `query_table` an alias and referencing columns via that throws a `BinderError`, e.g.:\r\n```\r\nBinder Error: Referenced table \"f\" not found!\r\nCandidate tables: \"unnamed_subquery\"\r\nLINE 1: SELECT bar, f.baz FROM query_table('foo') as f;\r\n                    ^\r\n```\r\nReferencing `baz` without the alias works as expected. My guess would be that the alias is either dropped or pulled into a subquery (like `SELECT bar, f.baz FROM (FROM foo as f)`) when `query_table` is transformed.\n\n### To Reproduce\n\nRun with DuckDB CLI client:\r\n```sql\r\nCREATE TABLE foo AS SELECT 1 as bar, 2 as baz;\r\nSELECT bar, f.baz FROM query_table('foo') as f;\r\n```\r\n\r\nOutput:\r\n```\r\nBinder Error: Referenced table \"f\" not found!\r\nCandidate tables: \"unnamed_subquery\"\r\nLINE 1: SELECT bar, f.baz FROM query_table('foo') as f;\r\n                    ^\r\n```\n\n### OS:\n\n6.6.10-1-MANJARO, x86_64 GNU/Linux\n\n### DuckDB Version:\n\nv1.1.3 19864453f7\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nLennart Hensler\n\n### Affiliation:\n\nPrivate usage\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNot applicable - the reproduction does not require a data set\n\n### Did you include all code required to reproduce the issue?\n\n- [X] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [X] Yes, I have\n", "hints_text": "", "created_at": "2025-01-22T21:35:59Z"}
{"repo": "duckdb/duckdb", "pull_number": 15843, "instance_id": "duckdb__duckdb-15843", "issue_numbers": ["15570"], "base_commit": "3b3e9683f927d2e02f86af5a20bed9328bef6f71", "patch": "diff --git a/src/planner/binder/tableref/bind_table_function.cpp b/src/planner/binder/tableref/bind_table_function.cpp\nindex 3f4c249bda23..26dd86c9dfd1 100644\n--- a/src/planner/binder/tableref/bind_table_function.cpp\n+++ b/src/planner/binder/tableref/bind_table_function.cpp\n@@ -203,7 +203,9 @@ unique_ptr<LogicalOperator> Binder::BindTableFunctionInternal(TableFunction &tab\n \t\t                                  table_function.function_info.get(), this, table_function, ref);\n \t\tif (table_function.bind_replace) {\n \t\t\tauto new_plan = table_function.bind_replace(context, bind_input);\n-\t\t\tif (new_plan != nullptr) {\n+\t\t\tif (new_plan) {\n+\t\t\t\tnew_plan->alias = ref.alias;\n+\t\t\t\tnew_plan->column_name_alias = ref.column_name_alias;\n \t\t\t\treturn CreatePlan(*Bind(*new_plan));\n \t\t\t} else if (!table_function.bind) {\n \t\t\t\tthrow BinderException(\"Failed to bind \\\"%s\\\": nullptr returned from bind_replace without bind function\",\n", "test_patch": "diff --git a/test/sql/catalog/function/query_function.test b/test/sql/catalog/function/query_function.test\nindex 0d65fa65b4ac..1ef00218e192 100644\n--- a/test/sql/catalog/function/query_function.test\n+++ b/test/sql/catalog/function/query_function.test\n@@ -249,6 +249,16 @@ FROM query_table('SELECT 4 + 2');\n ----\n Catalog Error: Table with name SELECT 4 + 2 does not exist!\n \n+query I\n+SELECT f.* FROM query_table('tbl_int') as f;\n+----\n+42\n+\n+query I\n+SELECT f.x FROM query_table('tbl_int') as f(x);\n+----\n+42\n+\n # test by_name argument\n query I\n FROM query_table(['tbl_int', 'tbl_varchar', 'tbl_empty', 'tbl2_varchar'], false);\n", "problem_statement": "Binder error when using query_table with an alias\n### What happens?\n\nGiving `query_table` an alias and referencing columns via that throws a `BinderError`, e.g.:\r\n```\r\nBinder Error: Referenced table \"f\" not found!\r\nCandidate tables: \"unnamed_subquery\"\r\nLINE 1: SELECT bar, f.baz FROM query_table('foo') as f;\r\n                    ^\r\n```\r\nReferencing `baz` without the alias works as expected. My guess would be that the alias is either dropped or pulled into a subquery (like `SELECT bar, f.baz FROM (FROM foo as f)`) when `query_table` is transformed.\n\n### To Reproduce\n\nRun with DuckDB CLI client:\r\n```sql\r\nCREATE TABLE foo AS SELECT 1 as bar, 2 as baz;\r\nSELECT bar, f.baz FROM query_table('foo') as f;\r\n```\r\n\r\nOutput:\r\n```\r\nBinder Error: Referenced table \"f\" not found!\r\nCandidate tables: \"unnamed_subquery\"\r\nLINE 1: SELECT bar, f.baz FROM query_table('foo') as f;\r\n                    ^\r\n```\n\n### OS:\n\n6.6.10-1-MANJARO, x86_64 GNU/Linux\n\n### DuckDB Version:\n\nv1.1.3 19864453f7\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nLennart Hensler\n\n### Affiliation:\n\nPrivate usage\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNot applicable - the reproduction does not require a data set\n\n### Did you include all code required to reproduce the issue?\n\n- [X] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [X] Yes, I have\n", "hints_text": "The same is true for the `query` function:\n```sql\nSELECT q.a from query($$ SELECT 1 a $$) q;\n```\n```\nBinder Error: Referenced table \"q\" not found!\nCandidate tables: \"unnamed_subquery\"\nLINE 1: SELECT q.a from query($$ SELECT 1 a $$) q;\n               ^\n```", "created_at": "2025-01-22T13:37:01Z"}
{"repo": "duckdb/duckdb", "pull_number": 15724, "instance_id": "duckdb__duckdb-15724", "issue_numbers": ["15659", "15659"], "base_commit": "677a8e7cd679f89748f8e05b668c7496255d5430", "patch": "diff --git a/src/include/duckdb/planner/expression/bound_parameter_data.hpp b/src/include/duckdb/planner/expression/bound_parameter_data.hpp\nindex 181751c1e58a..0467e37c54de 100644\n--- a/src/include/duckdb/planner/expression/bound_parameter_data.hpp\n+++ b/src/include/duckdb/planner/expression/bound_parameter_data.hpp\n@@ -17,7 +17,7 @@ struct BoundParameterData {\n public:\n \tBoundParameterData() {\n \t}\n-\texplicit BoundParameterData(Value val) : value(std::move(val)), return_type(value.type()) {\n+\texplicit BoundParameterData(Value val) : value(std::move(val)), return_type(GetDefaultType(value.type())) {\n \t}\n \tBoundParameterData(Value val, LogicalType type_p) : value(std::move(val)), return_type(std::move(type_p)) {\n \t}\n@@ -39,6 +39,14 @@ struct BoundParameterData {\n \n \tvoid Serialize(Serializer &serializer) const;\n \tstatic shared_ptr<BoundParameterData> Deserialize(Deserializer &deserializer);\n+\n+private:\n+\tLogicalType GetDefaultType(const LogicalType &type) {\n+\t\tif (value.type().id() == LogicalTypeId::VARCHAR && StringType::GetCollation(type).empty()) {\n+\t\t\treturn LogicalTypeId::STRING_LITERAL;\n+\t\t}\n+\t\treturn value.type();\n+\t}\n };\n \n } // namespace duckdb\ndiff --git a/src/planner/binder/expression/bind_comparison_expression.cpp b/src/planner/binder/expression/bind_comparison_expression.cpp\nindex cd490f4333c0..525dd3c620f1 100644\n--- a/src/planner/binder/expression/bind_comparison_expression.cpp\n+++ b/src/planner/binder/expression/bind_comparison_expression.cpp\n@@ -28,6 +28,7 @@ void ExpressionBinder::TestCollation(ClientContext &context, const string &colla\n \n static bool SwitchVarcharComparison(const LogicalType &type) {\n \tswitch (type.id()) {\n+\tcase LogicalTypeId::BOOLEAN:\n \tcase LogicalTypeId::TINYINT:\n \tcase LogicalTypeId::SMALLINT:\n \tcase LogicalTypeId::INTEGER:\ndiff --git a/src/planner/binder/statement/bind_execute.cpp b/src/planner/binder/statement/bind_execute.cpp\nindex 3e3af4d6ab76..86799dc9514c 100644\n--- a/src/planner/binder/statement/bind_execute.cpp\n+++ b/src/planner/binder/statement/bind_execute.cpp\n@@ -54,7 +54,8 @@ BoundStatement Binder::Bind(ExecuteStatement &stmt) {\n \t\t\tparameter_data = BoundParameterData(std::move(constant.value), std::move(return_type));\n \t\t} else {\n \t\t\tauto value = ExpressionExecutor::EvaluateScalar(context, *bound_expr, true);\n-\t\t\tparameter_data = BoundParameterData(std::move(value));\n+\t\t\tauto value_type = value.type();\n+\t\t\tparameter_data = BoundParameterData(std::move(value), std::move(value_type));\n \t\t}\n \t\tbind_values[pair.first] = std::move(parameter_data);\n \t}\n", "test_patch": "diff --git a/test/sql/cast/boolean_autocast.test b/test/sql/cast/boolean_autocast.test\nindex e26c1c1f1523..ac18988e325b 100644\n--- a/test/sql/cast/boolean_autocast.test\n+++ b/test/sql/cast/boolean_autocast.test\n@@ -52,6 +52,11 @@ SELECT true='1';\n ----\n true\n \n+query T\n+SELECT true='1'::VARCHAR;\n+----\n+true\n+\n query T\n SELECT true='0';\n ----\ndiff --git a/test/sql/collate/collate_filter_pushdown.test b/test/sql/collate/collate_filter_pushdown.test\nindex 19a4e599a701..732915a7b865 100644\n--- a/test/sql/collate/collate_filter_pushdown.test\n+++ b/test/sql/collate/collate_filter_pushdown.test\n@@ -20,4 +20,4 @@ insert into t63(c0) values ('1');\n query I\n SELECT t63.c0 FROM t0 NATURAL LEFT JOIN t63;\n ----\n-NULL\n+1\ndiff --git a/tools/pythonpkg/tests/fast/test_parameter_list.py b/tools/pythonpkg/tests/fast/test_parameter_list.py\nindex 6db0325c42be..032b1b9c875a 100644\n--- a/tools/pythonpkg/tests/fast/test_parameter_list.py\n+++ b/tools/pythonpkg/tests/fast/test_parameter_list.py\n@@ -28,3 +28,18 @@ def test_explicit_nan_param(self):\n         con = duckdb.default_connection()\n         res = con.execute('select isnan(cast(? as double))', (float(\"nan\"),))\n         assert res.fetchone()[0] == True\n+\n+    def test_string_parameter(self, duckdb_cursor):\n+        conn = duckdb.connect()\n+        conn.execute(\"create table orders (o_orderdate date)\")\n+        conn.execute(\"insert into orders values (date '1992-01-01'), (date '1994-01-01')\")\n+        conn.execute(\n+            \"\"\"\n+            SELECT COUNT(*)\n+            FROM ORDERS\n+            WHERE O_ORDERDATE BETWEEN ? AND ?\n+            \"\"\",\n+            [\"1994-01-01\", \"1996-01-01\"],\n+        )\n+        res = conn.fetchall()\n+        assert res == [(1,)]\n", "problem_statement": "Regression in parameterized BETWEEN clause in 1.1\n### What happens?\n\nIt appears that duckdb 1.1 requires explicitly casting parameters to a BETWEEN clause when it did not previously, and which it does not require if the parameters are specified (still as strings) withinin the query instead of as parameters. I could not find any mention of this change in the \"Breaking SQL Changes\" section of the [1.1 release post](https://duckdb.org/2024/09/09/announcing-duckdb-110.html#breaking-sql-changes) or elsewhere.\n\n### To Reproduce\n\n```python\r\nimport duckdb\r\n\r\nwith duckdb.connect() as conn:\r\n    conn.execute(\"CALL dbgen(sf = 0.1);\")\r\n    print(\r\n        conn.execute(\r\n            \"\"\"\r\n            SELECT COUNT(*)\r\n            FROM ORDERS\r\n            WHERE O_ORDERDATE BETWEEN ? AND ?\r\n            \"\"\",\r\n            [\"1994-01-01\", \"1996-01-01\"],\r\n        ).fetchone()\r\n    )\r\n```\r\n\r\nOn duckdb 1.0 the query executes correctly, but on 1.1 it raises\r\n\r\n```\r\nBinderException: Binder Error: Cannot mix values of type DATE and VARCHAR in BETWEEN clause - an explicit cast is required\r\nLINE 4:             WHERE O_ORDERDATE BETWEEN ? AND ?\r\n```\r\n\r\nAnd strangely the query works on 1.1 if you inline the parameters but still specify them as strings, i.e.\r\n\r\n```\r\nSELECT COUNT(*)\r\nFROM ORDERS\r\nWHERE O_ORDERDATE BETWEEN '1994-01-01' AND '1996-01-01'\r\n```\n\n### OS:\n\nmacOS, Linux\n\n### DuckDB Version:\n\n1.1.3\n\n### DuckDB Client:\n\nPython, Java\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nDylan Scott\n\n### Affiliation:\n\nHex Technologies\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [X] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [X] Yes, I have\nRegression in parameterized BETWEEN clause in 1.1\n### What happens?\n\nIt appears that duckdb 1.1 requires explicitly casting parameters to a BETWEEN clause when it did not previously, and which it does not require if the parameters are specified (still as strings) withinin the query instead of as parameters. I could not find any mention of this change in the \"Breaking SQL Changes\" section of the [1.1 release post](https://duckdb.org/2024/09/09/announcing-duckdb-110.html#breaking-sql-changes) or elsewhere.\n\n### To Reproduce\n\n```python\r\nimport duckdb\r\n\r\nwith duckdb.connect() as conn:\r\n    conn.execute(\"CALL dbgen(sf = 0.1);\")\r\n    print(\r\n        conn.execute(\r\n            \"\"\"\r\n            SELECT COUNT(*)\r\n            FROM ORDERS\r\n            WHERE O_ORDERDATE BETWEEN ? AND ?\r\n            \"\"\",\r\n            [\"1994-01-01\", \"1996-01-01\"],\r\n        ).fetchone()\r\n    )\r\n```\r\n\r\nOn duckdb 1.0 the query executes correctly, but on 1.1 it raises\r\n\r\n```\r\nBinderException: Binder Error: Cannot mix values of type DATE and VARCHAR in BETWEEN clause - an explicit cast is required\r\nLINE 4:             WHERE O_ORDERDATE BETWEEN ? AND ?\r\n```\r\n\r\nAnd strangely the query works on 1.1 if you inline the parameters but still specify them as strings, i.e.\r\n\r\n```\r\nSELECT COUNT(*)\r\nFROM ORDERS\r\nWHERE O_ORDERDATE BETWEEN '1994-01-01' AND '1996-01-01'\r\n```\n\n### OS:\n\nmacOS, Linux\n\n### DuckDB Version:\n\n1.1.3\n\n### DuckDB Client:\n\nPython, Java\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nDylan Scott\n\n### Affiliation:\n\nHex Technologies\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [X] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [X] Yes, I have\n", "hints_text": "\n", "created_at": "2025-01-15T11:55:48Z"}
{"repo": "duckdb/duckdb", "pull_number": 15708, "instance_id": "duckdb__duckdb-15708", "issue_numbers": ["15180"], "base_commit": "945a96cd3fffc49b1522342f710b9b133f77107b", "patch": "diff --git a/extension/autocomplete/grammar/describe.gram b/extension/autocomplete/grammar/describe.gram\nindex d6960a8c2193..84bc6f5bc381 100644\n--- a/extension/autocomplete/grammar/describe.gram\n+++ b/extension/autocomplete/grammar/describe.gram\n@@ -2,7 +2,7 @@ DescribeStatement <- ShowSelect / ShowAllTables / ShowQualifiedName\n \n ShowSelect <- ShowOrDescribeOrSummarize SelectStatement\n ShowAllTables <- ShowOrDescribe 'ALL'i 'TABLES'\n-ShowQualifiedName <- ShowOrDescribeOrSummarize (QualifiedName / StringLiteral)?\n+ShowQualifiedName <- ShowOrDescribeOrSummarize (BaseTableName / StringLiteral)?\n \n ShowOrDescribeOrSummarize <- ShowOrDescribe / 'SUMMARIZE'i\n ShowOrDescribe <- 'SHOW'i / 'DESCRIBE'i / 'DESC'i\ndiff --git a/extension/autocomplete/include/inlined_grammar.hpp b/extension/autocomplete/include/inlined_grammar.hpp\nindex b38d3866ece1..4d0dc96a96a9 100644\n--- a/extension/autocomplete/include/inlined_grammar.hpp\n+++ b/extension/autocomplete/include/inlined_grammar.hpp\n@@ -141,7 +141,7 @@ const char INLINED_PEG_GRAMMAR[] = {\n \t\"DescribeStatement <- ShowSelect / ShowAllTables / ShowQualifiedName\\n\"\n \t\"ShowSelect <- ShowOrDescribeOrSummarize SelectStatement\\n\"\n \t\"ShowAllTables <- ShowOrDescribe 'ALL'i 'TABLES'\\n\"\n-\t\"ShowQualifiedName <- ShowOrDescribeOrSummarize (QualifiedName / StringLiteral)?\\n\"\n+\t\"ShowQualifiedName <- ShowOrDescribeOrSummarize (BaseTableName / StringLiteral)?\\n\"\n \t\"ShowOrDescribeOrSummarize <- ShowOrDescribe / 'SUMMARIZE'i\\n\"\n \t\"ShowOrDescribe <- 'SHOW'i / 'DESCRIBE'i / 'DESC'i\\n\"\n \t\"VacuumStatement <- 'VACUUM'i 'FULL'i? QualifiedName?\\n\"\ndiff --git a/tools/shell/linenoise/linenoise.cpp b/tools/shell/linenoise/linenoise.cpp\nindex ad01d3ffb34a..87cfe49d3911 100644\n--- a/tools/shell/linenoise/linenoise.cpp\n+++ b/tools/shell/linenoise/linenoise.cpp\n@@ -141,10 +141,7 @@ int Linenoise::CompleteLine(EscapeSequence &current_sequence) {\n \t\t\tLinenoise::Log(\"\\nComplete Character %d\\n\", (int)c);\n \t\t\tswitch (c) {\n \t\t\tcase TAB: /* tab */\n-\t\t\t\ti = (i + 1) % (completions.size() + 1);\n-\t\t\t\tif (i == completions.size()) {\n-\t\t\t\t\tTerminal::Beep();\n-\t\t\t\t}\n+\t\t\t\ti = (i + 1) % completions.size();\n \t\t\t\tbreak;\n \t\t\tcase ESC: { /* escape */\n \t\t\t\tauto escape = Terminal::ReadEscapeSequence(ifd);\n@@ -152,16 +149,17 @@ int Linenoise::CompleteLine(EscapeSequence &current_sequence) {\n \t\t\t\tcase EscapeSequence::SHIFT_TAB:\n \t\t\t\t\t// shift-tab: move backwards\n \t\t\t\t\tif (i == 0) {\n-\t\t\t\t\t\tTerminal::Beep();\n+\t\t\t\t\t\t// pressing shift-tab at the first completion cancels completion\n+\t\t\t\t\t\tRefreshLine();\n+\t\t\t\t\t\tcurrent_sequence = escape;\n+\t\t\t\t\t\tstop = true;\n \t\t\t\t\t} else {\n \t\t\t\t\t\ti--;\n \t\t\t\t\t}\n \t\t\t\t\tbreak;\n \t\t\t\tcase EscapeSequence::ESCAPE:\n \t\t\t\t\t/* Re-show original buffer */\n-\t\t\t\t\tif (i < completions.size()) {\n-\t\t\t\t\t\tRefreshLine();\n-\t\t\t\t\t}\n+\t\t\t\t\tRefreshLine();\n \t\t\t\t\tcurrent_sequence = escape;\n \t\t\t\t\tstop = true;\n \t\t\t\t\tbreak;\n", "test_patch": "diff --git a/test/sql/function/autocomplete/copy.test b/test/sql/function/autocomplete/copy.test\nindex 40cfccbcf6a4..32641f68b4b4 100644\n--- a/test/sql/function/autocomplete/copy.test\n+++ b/test/sql/function/autocomplete/copy.test\n@@ -18,3 +18,11 @@ query II\n FROM sql_auto_complete('COPY tbl FROM ''file.csv'' HEAD') LIMIT 1;\n ----\n HEADER \t25\n+\n+statement ok\n+CREATE TABLE my_table(my_column INTEGER);\n+\n+query II\n+FROM sql_auto_complete('COPY my_') LIMIT 1;\n+----\n+my_table\t5\ndiff --git a/test/sql/function/autocomplete/drop.test b/test/sql/function/autocomplete/drop.test\nindex e44bcb2f7615..9cbc839331f0 100644\n--- a/test/sql/function/autocomplete/drop.test\n+++ b/test/sql/function/autocomplete/drop.test\n@@ -28,3 +28,27 @@ query II\n FROM sql_auto_complete('DROP TABLE tbl CAS') LIMIT 1;\n ----\n CASCADE \t15\n+\n+statement ok\n+CREATE TABLE my_table(my_column INTEGER);\n+\n+query II\n+FROM sql_auto_complete('DROP TABLE my_') LIMIT 1;\n+----\n+my_table\t11\n+\n+statement ok\n+CREATE SCHEMA my_schema;\n+\n+statement ok\n+CREATE TABLE my_schema.table_in_schema(my_column INTEGER)\n+\n+query II\n+FROM sql_auto_complete('DROP TABLE my_s') LIMIT 1;\n+----\n+my_schema.\t11\n+\n+query II\n+FROM sql_auto_complete('DROP TABLE my_schema.t') LIMIT 1;\n+----\n+table_in_schema\t21\ndiff --git a/test/sql/function/autocomplete/show.test b/test/sql/function/autocomplete/show.test\nnew file mode 100644\nindex 000000000000..c17f241b25d7\n--- /dev/null\n+++ b/test/sql/function/autocomplete/show.test\n@@ -0,0 +1,34 @@\n+# name: test/sql/function/autocomplete/show.test\n+# description: Test sql_auto_complete\n+# group: [autocomplete]\n+\n+require autocomplete\n+\n+query II\n+FROM sql_auto_complete('DESCR') LIMIT 1;\n+----\n+DESCRIBE \t0\n+\n+statement ok\n+CREATE TABLE my_table(my_column INTEGER);\n+\n+query II\n+FROM sql_auto_complete('SHOW my_') LIMIT 1;\n+----\n+my_table\t5\n+\n+statement ok\n+CREATE SCHEMA my_schema;\n+\n+statement ok\n+CREATE TABLE my_schema.table_in_schema(my_column INTEGER)\n+\n+query II\n+FROM sql_auto_complete('SHOW my_s') LIMIT 1;\n+----\n+my_schema.\t5\n+\n+query II\n+FROM sql_auto_complete('DESCRIBE my_schema.t') LIMIT 1;\n+----\n+table_in_schema\t19\n", "problem_statement": "CLI tab completion not working on some common commands\n### What happens?\n\nCLI tab completion (which is great) doe not seem to work on a table name in the COPY, SHOW or SUMMARIZE statements\n\n### To Reproduce\n\nSimply try `SHOW a<tab>' where you have a table name that starts with 'a' and <tab> usually gives \"ALTER\"\n\n### OS:\n\nmacOS Sanoma 14.7.1 and Debian bullseye\n\n### DuckDB Version:\n\n1.1.3\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nMaurice Hickey\n\n### Affiliation:\n\nNisos\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNo - Other reason (please specify in the issue body)\n\n### Did you include all code required to reproduce the issue?\n\n- [X] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [X] Yes, I have\n", "hints_text": "", "created_at": "2025-01-14T14:50:12Z"}
{"repo": "duckdb/duckdb", "pull_number": 15704, "instance_id": "duckdb__duckdb-15704", "issue_numbers": ["15641"], "base_commit": "2a1d5e2ab8882b27474e733f8703ef05ebcb0524", "patch": "diff --git a/.github/patches/extensions/httpfs/last_modified.patch b/.github/patches/extensions/httpfs/last_modified.patch\nnew file mode 100644\nindex 000000000000..6b0f3e17852b\n--- /dev/null\n+++ b/.github/patches/extensions/httpfs/last_modified.patch\n@@ -0,0 +1,33 @@\n+diff --git a/extension/httpfs/httpfs.cpp b/extension/httpfs/httpfs.cpp\n+index e6b28e5..5847eb4 100644\n+--- a/extension/httpfs/httpfs.cpp\n++++ b/extension/httpfs/httpfs.cpp\n+@@ -772,16 +772,18 @@ void HTTPFileHandle::Initialize(optional_ptr<FileOpener> opener) {\n+ \t\tFullDownload(hfs, should_write_cache);\n+ \t}\n+ \tif (!res->headers[\"Last-Modified\"].empty()) {\n+-\t\tauto result = StrpTimeFormat::Parse(\"%a, %d %h %Y %T %Z\", res->headers[\"Last-Modified\"]);\n+-\t\tstruct tm tm {};\n+-\t\ttm.tm_year = result.data[0] - 1900;\n+-\t\ttm.tm_mon = result.data[1] - 1;\n+-\t\ttm.tm_mday = result.data[2];\n+-\t\ttm.tm_hour = result.data[3];\n+-\t\ttm.tm_min = result.data[4];\n+-\t\ttm.tm_sec = result.data[5];\n+-\t\ttm.tm_isdst = 0;\n+-\t\tlast_modified = mktime(&tm);\n++\t\tStrpTimeFormat::ParseResult result;\n++\t\tif (StrpTimeFormat::TryParse(\"%a, %d %h %Y %T %Z\", res->headers[\"Last-Modified\"], result)) {\n++\t\t\tstruct tm tm {};\n++\t\t\ttm.tm_year = result.data[0] - 1900;\n++\t\t\ttm.tm_mon = result.data[1] - 1;\n++\t\t\ttm.tm_mday = result.data[2];\n++\t\t\ttm.tm_hour = result.data[3];\n++\t\t\ttm.tm_min = result.data[4];\n++\t\t\ttm.tm_sec = result.data[5];\n++\t\t\ttm.tm_isdst = 0;\n++\t\t\tlast_modified = mktime(&tm);\n++\t\t}\n+ \t}\n+ \n+ \tif (should_write_cache) {\ndiff --git a/extension/json/buffered_json_reader.cpp b/extension/json/buffered_json_reader.cpp\nindex f99fe0321327..68a830c7fd12 100644\n--- a/extension/json/buffered_json_reader.cpp\n+++ b/extension/json/buffered_json_reader.cpp\n@@ -35,7 +35,7 @@ void JSONFileHandle::Reset() {\n \trequested_reads = 0;\n \tactual_reads = 0;\n \tlast_read_requested = false;\n-\tif (IsOpen() && CanSeek()) {\n+\tif (IsOpen() && !file_handle->IsPipe()) {\n \t\tfile_handle->Reset();\n \t}\n }\ndiff --git a/extension/json/json_functions/read_json_objects.cpp b/extension/json/json_functions/read_json_objects.cpp\nindex a0e6e6b8f4f8..c58b85fd7ea6 100644\n--- a/extension/json/json_functions/read_json_objects.cpp\n+++ b/extension/json/json_functions/read_json_objects.cpp\n@@ -64,8 +64,8 @@ TableFunction GetReadJSONObjectsTableFunction(bool list_parameter, shared_ptr<JS\n \n TableFunctionSet JSONFunctions::GetReadJSONObjectsFunction() {\n \tTableFunctionSet function_set(\"read_json_objects\");\n-\tauto function_info =\n-\t    make_shared_ptr<JSONScanInfo>(JSONScanType::READ_JSON_OBJECTS, JSONFormat::ARRAY, JSONRecordType::RECORDS);\n+\tauto function_info = make_shared_ptr<JSONScanInfo>(JSONScanType::READ_JSON_OBJECTS, JSONFormat::AUTO_DETECT,\n+\t                                                   JSONRecordType::RECORDS);\n \tfunction_set.AddFunction(GetReadJSONObjectsTableFunction(false, function_info));\n \tfunction_set.AddFunction(GetReadJSONObjectsTableFunction(true, function_info));\n \treturn function_set;\ndiff --git a/src/common/local_file_system.cpp b/src/common/local_file_system.cpp\nindex 7136dc715cc2..89990c767e36 100644\n--- a/src/common/local_file_system.cpp\n+++ b/src/common/local_file_system.cpp\n@@ -853,16 +853,27 @@ unique_ptr<FileHandle> LocalFileSystem::OpenFile(const string &path_p, FileOpenF\n \tbool open_write = flags.OpenForWriting();\n \tif (open_read && open_write) {\n \t\tdesired_access = GENERIC_READ | GENERIC_WRITE;\n-\t\tshare_mode = 0;\n \t} else if (open_read) {\n \t\tdesired_access = GENERIC_READ;\n-\t\tshare_mode = FILE_SHARE_READ;\n \t} else if (open_write) {\n \t\tdesired_access = GENERIC_WRITE;\n-\t\tshare_mode = 0;\n \t} else {\n \t\tthrow InternalException(\"READ, WRITE or both should be specified when opening a file\");\n \t}\n+\tswitch (flags.Lock()) {\n+\tcase FileLockType::NO_LOCK:\n+\t\tshare_mode = FILE_SHARE_READ | FILE_SHARE_WRITE;\n+\t\tbreak;\n+\tcase FileLockType::READ_LOCK:\n+\t\tshare_mode = FILE_SHARE_READ;\n+\t\tbreak;\n+\tcase FileLockType::WRITE_LOCK:\n+\t\tshare_mode = 0;\n+\t\tbreak;\n+\tdefault:\n+\t\tthrow InternalException(\"Unknown FileLockType\");\n+\t}\n+\n \tif (open_write) {\n \t\tif (flags.CreateFileIfNotExists()) {\n \t\t\tcreation_disposition = OPEN_ALWAYS;\ndiff --git a/src/function/scalar/strftime_format.cpp b/src/function/scalar/strftime_format.cpp\nindex 8ab46ace7058..58ccd9959e25 100644\n--- a/src/function/scalar/strftime_format.cpp\n+++ b/src/function/scalar/strftime_format.cpp\n@@ -1412,6 +1412,16 @@ StrpTimeFormat::ParseResult StrpTimeFormat::Parse(const string &format_string, c\n \treturn result;\n }\n \n+bool StrpTimeFormat::TryParse(const string &format_string, const string &text, ParseResult &result) {\n+\tStrpTimeFormat format;\n+\tformat.format_specifier = format_string;\n+\tstring error = StrTimeFormat::ParseFormatSpecifier(format_string, format);\n+\tif (!error.empty()) {\n+\t\tthrow InvalidInputException(\"Failed to parse format specifier %s: %s\", format_string, error);\n+\t}\n+\treturn format.Parse(text, result);\n+}\n+\n bool StrTimeFormat::Empty() const {\n \treturn format_specifier.empty();\n }\ndiff --git a/src/include/duckdb/function/scalar/strftime_format.hpp b/src/include/duckdb/function/scalar/strftime_format.hpp\nindex 7392be2541a1..8353ee9a64d8 100644\n--- a/src/include/duckdb/function/scalar/strftime_format.hpp\n+++ b/src/include/duckdb/function/scalar/strftime_format.hpp\n@@ -169,6 +169,7 @@ struct StrpTimeFormat : public StrTimeFormat { // NOLINT: work-around bug in cla\n \t\treturn format_specifier != other.format_specifier;\n \t}\n \tDUCKDB_API static ParseResult Parse(const string &format, const string &text);\n+\tDUCKDB_API static bool TryParse(const string &format, const string &text, ParseResult &result);\n \n \tDUCKDB_API bool Parse(string_t str, ParseResult &result, bool strict = false) const;\n \n", "test_patch": "diff --git a/test/sql/json/table/read_json_objects.test b/test/sql/json/table/read_json_objects.test\nindex e9c0018b897a..ecf73b6214e5 100644\n--- a/test/sql/json/table/read_json_objects.test\n+++ b/test/sql/json/table/read_json_objects.test\n@@ -9,7 +9,7 @@ require json\n statement error\n select * from read_json_objects('data/json/unterminated_quotes.ndjson')\n ----\n-Invalid Input Error: Expected top-level JSON array\n+Invalid Input Error: Malformed JSON\n \n # now it should work!\n query I\n@@ -213,7 +213,7 @@ Invalid Input Error: Malformed JSON in file \"data/json/multiple_objects_per_line\n statement error\n select * from read_json_objects('data/csv/tpcds_14.csv')\n ----\n-Invalid Input Error: Expected top-level JSON array\n+Invalid Input Error: Malformed JSON\n \n statement error\n select * from read_ndjson_objects('data/csv/tpcds_14.csv')\n@@ -224,7 +224,7 @@ Invalid Input Error: Malformed JSON in file \"data/csv/tpcds_14.csv\"\n statement error\n select * from read_json_objects('data/parquet-testing/blob.parquet')\n ----\n-Invalid Input Error: Expected top-level JSON array\n+Invalid Input Error: Malformed JSON\n \n statement error\n select * from read_ndjson_objects('data/parquet-testing/blob.parquet')\n", "problem_statement": "Duckdb fails to load json files in windows that are open in another app\n### What happens?\n\nUsing the duckdb command line of JDBC driver you can't load files that are open (locked) by another application. This is mainly a problem on Windows as it likes to lock files.\r\n\r\nIO Error: Cannot open file \"P:\\2025-01-09_Log.json\": The process cannot access the file because it is being used by another process.\r\n\r\nIs it possible so the code tries to open the file without gaining a lock on it, so that it can be read. I'm happy to accept that the data could change while it's being read, but with the ignore_errors=true\n\n### To Reproduce\n\nThis powershell creates a file, opens it for writing, then tries to read it.\r\n\r\n```powershell\r\n$path = \"$($ENV:HOMEPATH)\\Downloads\\t.json\"\r\nWrite-Output '{}' > $path\r\n$file = [System.IO.File]::Open($path, \"Open\", \"Write\", \"None\")\r\nduckdb -c \"select count(*) from read_json('${path}')\";\r\n$file.close()\r\n ;\r\n\r\n````\n\n### OS:\n\nWindows\n\n### DuckDB Version:\n\nv1.1.0 \n\n### DuckDB Client:\n\ncli, JDBC\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nPaul Austin\n\n### Affiliation:\n\nAutomutatio\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [X] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [X] Yes, I have\n", "hints_text": "Hi @paulaustin-automutatio thanks for reporting this. We'll discuss it in our weekly meeting but to be honest I don't think there's a lot we can do here. The `ignore_errors` is supposed to ignore errors related to the file's content, not its access. So reading locked files would require the introduction of another configuration flag.\nOne question: what happens if you open the file in read mode with the Powershell script?\n@szarnyasg The actual file is being opened by the logback library in Java on a completely different machine. The example I gave was one I made up so that you can replicate the issue.\r\n\r\nIs there not a way you can read the file without a lock. I am able to read that file in Java. So my temporary work around is to copy the files from the active log directory to another directory so that I can then read them using duckdb.\nWe already open JSON files (and CSV/Parquet files, for that matter) with just a read flag without any locks. I'm assuming that the lock that the other process grabs is exclusive? If not, we might not be interpreting the other process' logs as exclusive wrongly\nI've looked into this a bit and I think this is an issue with Windows that we cannot solve:\r\n```powershell\r\nWrite-Output '{}' > my.json\r\n$file = [System.IO.File]::Open(\"C:\\Users\\duckdb\\duckdb-laurens\\my.json\", \"Open\", \"Write\", \"None\")\r\ncat my.json\r\n```\r\nErrors with:\r\n```\r\ncat: The process cannot access the file 'C:\\Users\\duckdb\\duckdb-laurens\\my.json' because it is being used by another process.\r\n```\r\nIf even `cat`, which definitely opens files in read-only mode, cannot read files that are already opened like that, I don't think DuckDB can either.\n@lnkuiper I can read the file on the same machine in Java, so it is possible\n@lnkuiper When you open the file for reading what specific base API do you use and what open mode parameters do you specify?\n@lnkuiper I think my example using the System.Io.File Open is locking more than logback in java is locking.\r\n", "created_at": "2025-01-14T13:03:42Z"}
{"repo": "duckdb/duckdb", "pull_number": 15632, "instance_id": "duckdb__duckdb-15632", "issue_numbers": ["15626"], "base_commit": "f850786ddef96177354ca8183280bc0de62a66c0", "patch": "diff --git a/src/function/cast/struct_cast.cpp b/src/function/cast/struct_cast.cpp\nindex e5902b7522e2..051581c54231 100644\n--- a/src/function/cast/struct_cast.cpp\n+++ b/src/function/cast/struct_cast.cpp\n@@ -128,6 +128,7 @@ static bool StructToStructCast(Vector &source, Vector &result, idx_t count, Cast\n \tsource.Flatten(count);\n \tauto &result_validity = FlatVector::Validity(result);\n \tresult_validity = FlatVector::Validity(source);\n+\tresult.Verify(count);\n \treturn all_converted;\n }\n \ndiff --git a/src/function/table/arrow_conversion.cpp b/src/function/table/arrow_conversion.cpp\nindex 18daff2b9209..e09f81aac640 100644\n--- a/src/function/table/arrow_conversion.cpp\n+++ b/src/function/table/arrow_conversion.cpp\n@@ -725,6 +725,9 @@ static void ColumnArrowToDuckDBRunEndEncoded(Vector &vector, const ArrowArray &a\n \tD_ASSERT(vector.GetType() == values_type.GetDuckType());\n \n \tauto &scan_state = array_state.state;\n+\tif (vector.GetBuffer()) {\n+\t\tvector.GetBuffer()->SetAuxiliaryData(make_uniq<ArrowAuxiliaryData>(array_state.owned_data));\n+\t}\n \n \tD_ASSERT(run_ends_array.length == values_array.length);\n \tauto compressed_size = NumericCast<idx_t>(run_ends_array.length);\n@@ -766,6 +769,9 @@ static void ColumnArrowToDuckDB(Vector &vector, ArrowArray &array, ArrowArraySca\n \tauto &scan_state = array_state.state;\n \tD_ASSERT(!array.dictionary);\n \n+\tif (vector.GetBuffer()) {\n+\t\tvector.GetBuffer()->SetAuxiliaryData(make_uniq<ArrowAuxiliaryData>(array_state.owned_data));\n+\t}\n \tswitch (vector.GetType().id()) {\n \tcase LogicalTypeId::SQLNULL:\n \t\tvector.Reference(Value());\n@@ -1284,6 +1290,9 @@ static bool CanContainNull(const ArrowArray &array, const ValidityMask *parent_m\n static void ColumnArrowToDuckDBDictionary(Vector &vector, ArrowArray &array, ArrowArrayScanState &array_state,\n                                           idx_t size, const ArrowType &arrow_type, int64_t nested_offset,\n                                           const ValidityMask *parent_mask, uint64_t parent_offset) {\n+\tif (vector.GetBuffer()) {\n+\t\tvector.GetBuffer()->SetAuxiliaryData(make_uniq<ArrowAuxiliaryData>(array_state.owned_data));\n+\t}\n \tD_ASSERT(arrow_type.HasDictionary());\n \tauto &scan_state = array_state.state;\n \tconst bool has_nulls = CanContainNull(array, parent_mask);\n@@ -1384,7 +1393,6 @@ void ArrowTableFunction::ArrowToDuckDB(ArrowScanLocalState &scan_state, const ar\n \t\tif (!array_state.owned_data) {\n \t\t\tarray_state.owned_data = scan_state.chunk;\n \t\t}\n-\t\toutput.data[idx].GetBuffer()->SetAuxiliaryData(make_uniq<ArrowAuxiliaryData>(array_state.owned_data));\n \n \t\tauto array_physical_type = GetArrowArrayPhysicalType(arrow_type);\n \ndiff --git a/tools/pythonpkg/src/python_udf.cpp b/tools/pythonpkg/src/python_udf.cpp\nindex 7667c3ba21e4..dd55c8ffa8c6 100644\n--- a/tools/pythonpkg/src/python_udf.cpp\n+++ b/tools/pythonpkg/src/python_udf.cpp\n@@ -126,6 +126,7 @@ static void ConvertArrowTableToVector(const py::object &table, Vector &out, Clie\n \n \tVectorOperations::Cast(context, result.data[0], out, count);\n \tout.Flatten(count);\n+\tout.Verify(count);\n }\n \n static string NullHandlingError() {\n", "test_patch": "diff --git a/tools/pythonpkg/tests/fast/udf/test_scalar_arrow.py b/tools/pythonpkg/tests/fast/udf/test_scalar_arrow.py\nindex 85fec00c8bfc..fd7f00f72e5b 100644\n--- a/tools/pythonpkg/tests/fast/udf/test_scalar_arrow.py\n+++ b/tools/pythonpkg/tests/fast/udf/test_scalar_arrow.py\n@@ -209,3 +209,14 @@ def return_five(x):\n         res = con.sql('select return_five(NULL) from range(10)').fetchall()\n         # Because we didn't specify 'special' null handling, these are all NULL\n         assert res == [(None,), (None,), (None,), (None,), (None,), (None,), (None,), (None,), (None,), (None,)]\n+\n+    def test_struct_with_non_inlined_string(self, duckdb_cursor):\n+        def func(data):\n+            return pa.array([{'x': 1, 'y': 'this is not an inlined string'}] * data.length())\n+\n+        duckdb_cursor.create_function(\n+            name=\"func\", function=func, return_type=\"STRUCT(x integer, y varchar)\", type=\"arrow\", side_effects=False\n+        )\n+\n+        res = duckdb_cursor.sql(\"select func(1).y\").fetchone()\n+        assert res == ('this is not an inlined string',)\n", "problem_statement": "Corrupt data in Python UDF using PyArrow\n### What happens?\n\nCalling a UDF in \"arrow\" mode with certain python return values reliably causes corrupt return in duckdb table.\r\n\r\nThis maybe should be in the 'arrow' repo but I'm not sure.\n\n### To Reproduce\n\nThis is with a build 1.1.4-dev3393 just now but also with release 1.1.3 ...\r\n\r\n```\r\nimport duckdb\r\nimport pyarrow\r\n\r\nprint(f\"VERSION: {duckdb.__version__}\")\r\n\r\ndef func(data):\r\n    return pyarrow.array([ { 'x': 1, 'y': 'g.[4T>A;9del]' } ] * data.length())\r\n\r\nddbc = duckdb.connect()\r\n\r\nddbc.create_function(\r\n    name=\"fnord\",\r\n    function=func,\r\n    return_type=\"STRUCT(x integer, y varchar)\",\r\n    type=\"arrow\",\r\n    side_effects=False\r\n)\r\n\r\nprint(ddbc.sql(\"select fnord(1).y\"))\r\n```\r\n\r\noutput from running the same code several times:\r\n\r\n```$ python test_duckdb_3.py \r\nVERSION: 1.1.4-dev3393\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502    (fnord(1)).y     \u2502\r\n\u2502       varchar       \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 ????INVALID VALUE\u2026  \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n$ python test_duckdb_3.py \r\nVERSION: 1.1.4-dev3393\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502    (fnord(1)).y    \u2502\r\n\u2502      varchar       \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 ????INVALID VALU\u2026  \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n$ python test_duckdb_3.py \r\nVERSION: 1.1.4-dev3393\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502   (fnord(1)).y   \u2502\r\n\u2502     varchar      \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 @\\a\\2\u030e\\5\\0\\09del] \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n$ python test_duckdb_3.py \r\nVERSION: 1.1.4-dev3393\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502   (fnord(1)).y    \u2502\r\n\u2502      varchar      \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 ????INVALID VAL\u2026  \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n$ python test_duckdb_3.py \r\nVERSION: 1.1.4-dev3393\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502    (fnord(1)).y     \u2502\r\n\u2502       varchar       \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 @\\a\\2X\\3\\3\\0\\09del] \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n```\r\n\r\nnote that the \"invalid\" value varies a little, and it is sometimes a mess of ascii characters.\r\nThe value of that string seems to matter but I don't know why.\n\n### OS:\n\nLinux x86_64\n\n### DuckDB Version:\n\n1.1.3, 1.1.4-dev3393\n\n### DuckDB Client:\n\nPython\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nNick Moore\n\n### Affiliation:\n\nMnemote Pty Ltd\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a source build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [X] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [X] Yes, I have\n", "hints_text": "Seems to be any 13 or more character string, eg: 'helloworldab' is fine but 'helloworldabc' results in corruption.\r\nSometimes the corrupt string has the last few characters of the original string on the end, eg: \r\n```\r\n$ python test_duckdb_3.py \r\nVERSION: 1.1.4-dev3393\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502    (fnord(1)).y     \u2502\r\n\u2502       varchar       \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 @\\a\\2\\20\\4\\0\\0ldabc \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n$ python test_duckdb_3.py \r\nVERSION: 1.1.4-dev3393\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502     (fnord(1)).y     \u2502\r\n\u2502       varchar        \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 @\\a\\2\\28I\\4\\0\\0ldabc \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\n* the exact corrupt value varies, but it is always wrong.\r\n* only seems to do it if 'x' is numeric, eg: `{ 'x': '1', 'y': 'helloworldabcde' }` is fine\r\n* doesn't seem to matter what the names of the fields are or what order they're in so long as there's at least one numeric one in addition to the varchar.\r\n* if you run it on more than one row, eg: `select fnord(1).y from (values (1), (2), (3))` only the first row is corrupted:\r\n```\r\n$ python test_duckdb_3.py \r\nVERSION: 1.1.4-dev3393\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502     (fnord(1)).y      \u2502\r\n\u2502        varchar        \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 ????INVALID VALUE -\u2026  \u2502\r\n\u2502 helloworldabcde       \u2502\r\n\u2502 helloworldabcde       \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\nThanks for the report, here is great. The duckdb_arrow repo is for Arrow IPC mainly", "created_at": "2025-01-09T11:49:22Z"}
{"repo": "duckdb/duckdb", "pull_number": 15615, "instance_id": "duckdb__duckdb-15615", "issue_numbers": ["15601", "15601"], "base_commit": "ce33de966a521d1a6e86ec9579e133ff2b2534f4", "patch": "diff --git a/data/json/15601/bunch_of_key_collisions.json b/data/json/15601/bunch_of_key_collisions.json\nnew file mode 100644\nindex 000000000000..5be180543052\n--- /dev/null\n+++ b/data/json/15601/bunch_of_key_collisions.json\n@@ -0,0 +1,1 @@\n+{\"duck_1_1\": 42, \"duck\": 43, \"Duck\": 44, \"duck_1\": 45, \"Duck_1\": 46, \"Duck_1_1\": 47}\ndiff --git a/data/json/15601/fragment1.json b/data/json/15601/fragment1.json\nnew file mode 100644\nindex 000000000000..c745c4e33c7c\n--- /dev/null\n+++ b/data/json/15601/fragment1.json\n@@ -0,0 +1,2 @@\n+{\"id\":\"19276\",\"Consignee\":\"zz af9\",\"Time\":\"30-04-2024 10:06:21\",\"DocketNumber\":\"6364174\",\"Image\":[\"abc\"],\"Time_1\":\"30-04-2024 09:32:13\"}\n+{\"id\":\"19281\",\"Consignee\":\"zz af9\",\"Time\":\"30-04-2024 11:38:13\",\"DocketNumber\":\"6364181\",\"Image\":[\"def\"],\"Time_1\":\"30-04-2024 11:01:27\"}\ndiff --git a/data/json/15601/fragment2.json b/data/json/15601/fragment2.json\nnew file mode 100644\nindex 000000000000..c2744a30d1db\n--- /dev/null\n+++ b/data/json/15601/fragment2.json\n@@ -0,0 +1,3 @@\n+{\"id\":\"19421\",\"Comments\":null,\"Consignee\":\"zz zz\",\"Driver\":null,\"Time\":\"30-04-2024 17:04:01\",\"image\":[\"zz\"],\"DocketNumber\":\"11\",\"Image_1\":[\"zzz\"],\"Time_1\":\"30-04-2024 17:00:59\"}\n+{\"id\":\"19426\",\"Comments\":\"delivered\",\"Consignee\":null,\"Driver\":\"zz zz\",\"Time\":\"01-05-2024 08:31:27\",\"image\":[\"zz\"],\"DocketNumber\":\"zxc\",\"Image_1\":[\"zzz\"],\"Time_1\":\"01-05-2024 08:31:01\"}\n+{\"id\":\"8182\",\"Comments\":null,\"Consignee\":\"\",\"Driver\":null,\"Time\":\"26-03-2024 18:03:33\",\"image\":null,\"signature\":[\"xx\"],\"DocketNumber\":\"x D xc\",\"Image_1\":null,\"Time_1\":\"26-03-2024 18:03:33\"}\ndiff --git a/extension/json/json_functions/read_json.cpp b/extension/json/json_functions/read_json.cpp\nindex 78c1b43795db..0dfe0039198b 100644\n--- a/extension/json/json_functions/read_json.cpp\n+++ b/extension/json/json_functions/read_json.cpp\n@@ -306,14 +306,14 @@ unique_ptr<FunctionData> ReadJSONBind(ClientContext &context, TableFunctionBindI\n \t\t// JSON may contain columns such as \"id\" and \"Id\", which are duplicates for us due to case-insensitivity\n \t\t// We rename them so we can parse the file anyway. Note that we can't change bind_data->names,\n \t\t// because the JSON reader gets columns by exact name, not position\n-\t\tcase_insensitive_map_t<idx_t> name_count_map;\n-\t\tfor (auto &name : names) {\n-\t\t\tauto it = name_count_map.find(name);\n-\t\t\tif (it == name_count_map.end()) {\n-\t\t\t\tname_count_map[name] = 1;\n-\t\t\t} else {\n-\t\t\t\tname = StringUtil::Format(\"%s_%llu\", name, it->second++);\n+\t\tcase_insensitive_map_t<idx_t> name_collision_count;\n+\t\tfor (auto &col_name : names) {\n+\t\t\t// Taken from CSV header_detection.cpp\n+\t\t\twhile (name_collision_count.find(col_name) != name_collision_count.end()) {\n+\t\t\t\tname_collision_count[col_name] += 1;\n+\t\t\t\tcol_name = col_name + \"_\" + to_string(name_collision_count[col_name]);\n \t\t\t}\n+\t\t\tname_collision_count[col_name] = 0;\n \t\t}\n \t}\n \n", "test_patch": "diff --git a/test/sql/json/issues/issue15601.test b/test/sql/json/issues/issue15601.test\nnew file mode 100644\nindex 000000000000..106db3bdd82b\n--- /dev/null\n+++ b/test/sql/json/issues/issue15601.test\n@@ -0,0 +1,16 @@\n+# name: test/sql/json/issues/issue15601.test\n+# description: Test issue 15601 - JSON reader fails with duplicate column name when reading multiple JSON files of slightly different casing\n+# group: [issues]\n+\n+require json\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+# original from the issue\n+statement ok\n+FROM 'data/json/15601/fragment*.json'\n+\n+# created an even worse example\n+statement ok\n+FROM 'data/json/15601/bunch_of_key_collisions.json'\n", "problem_statement": "JSON reader fails with duplicate column name when reading multiple JSON files of slightly different casing\n### What happens?\r\n\r\nWhen reading multiple JSON files using a single FROM \"fragment*.json\" query, DuckDB throws a duplicate column name \"Image_1\" error. It appears that columns (JSON object keys) with differing case\u2014e.g., \"Image\" vs. \"image\"\u2014may trigger this collision.\r\n\r\n### To Reproduce\r\n\r\n\r\nI have two JSON files with partially overlapping schemas. One file uses a key `\"Image\"`, and the other uses `\"image\"`, plus there is a key named `\"Image_1\"` in the second file. When I attempt to query all JSON files at once using a wildcard pattern, DuckDB complains about a duplicate column name.\r\n\r\n**File: `fragment1.json`**\r\n```json\r\n{\"id\":\"19276\",\"Consignee\":\"zz af9\",\"Time\":\"30-04-2024 10:06:21\",\"DocketNumber\":\"6364174\",\"Image\":[\"abc\"],\"Time_1\":\"30-04-2024 09:32:13\"}\r\n{\"id\":\"19281\",\"Consignee\":\"zz af9\",\"Time\":\"30-04-2024 11:38:13\",\"DocketNumber\":\"6364181\",\"Image\":[\"def\"],\"Time_1\":\"30-04-2024 11:01:27\"}\r\n```\r\n\r\n**File: `fragment2.json`**\r\n```json\r\n{\"id\":\"19421\",\"Comments\":null,\"Consignee\":\"zz zz\",\"Driver\":null,\"Time\":\"30-04-2024 17:04:01\",\"image\":[\"zz\"],\"DocketNumber\":\"11\",\"Image_1\":[\"zzz\"],\"Time_1\":\"30-04-2024 17:00:59\"}\r\n{\"id\":\"19426\",\"Comments\":\"delivered\",\"Consignee\":null,\"Driver\":\"zz zz\",\"Time\":\"01-05-2024 08:31:27\",\"image\":[\"zz\"],\"DocketNumber\":\"zxc\",\"Image_1\":[\"zzz\"],\"Time_1\":\"01-05-2024 08:31:01\"}\r\n{\"id\":\"8182\",\"Comments\":null,\"Consignee\":\"\",\"Driver\":null,\"Time\":\"26-03-2024 18:03:33\",\"image\":null,\"signature\":[\"xx\"],\"DocketNumber\":\"x D xc\",\"Image_1\":null,\"Time_1\":\"26-03-2024 18:03:33\"}\r\n```\r\n\r\n### Python script to reproduce\r\n\r\n```python\r\nimport duckdb\r\nimport os\r\n\r\ndef main():\r\n    # Create two JSON files with the sample data\r\n    with open('fragment1.json', 'w') as f:\r\n        f.write('''\\\r\n{\"id\":\"19276\",\"Consignee\":\"zz af9\",\"Time\":\"30-04-2024 10:06:21\",\"DocketNumber\":\"6364174\",\"Image\":[\"abc\"],\"Time_1\":\"30-04-2024 09:32:13\"}\r\n{\"id\":\"19281\",\"Consignee\":\"zz af9\",\"Time\":\"30-04-2024 11:38:13\",\"DocketNumber\":\"6364181\",\"Image\":[\"def\"],\"Time_1\":\"30-04-2024 11:01:27\"}\r\n''')\r\n\r\n    with open('fragment2.json', 'w') as f:\r\n        f.write('''\\\r\n{\"id\":\"19421\",\"Comments\":null,\"Consignee\":\"zz zz\",\"Driver\":null,\"Time\":\"30-04-2024 17:04:01\",\"image\":[\"zz\"],\"DocketNumber\":\"11\",\"Image_1\":[\"zzz\"],\"Time_1\":\"30-04-2024 17:00:59\"}\r\n{\"id\":\"19426\",\"Comments\":\"delivered\",\"Consignee\":null,\"Driver\":\"zz zz\",\"Time\":\"01-05-2024 08:31:27\",\"image\":[\"zz\"],\"DocketNumber\":\"zxc\",\"Image_1\":[\"zzz\"],\"Time_1\":\"01-05-2024 08:31:01\"}\r\n{\"id\":\"8182\",\"Comments\":null,\"Consignee\":\"\",\"Driver\":null,\"Time\":\"26-03-2024 18:03:33\",\"image\":null,\"signature\":[\"xx\"],\"DocketNumber\":\"x D xc\",\"Image_1\":null,\"Time_1\":\"26-03-2024 18:03:33\"}\r\n''')\r\n\r\n    con = duckdb.connect()\r\n    try:\r\n        # This query should fail due to a duplicate column name\r\n        con.execute(\"SELECT * FROM 'fragment*.json';\")\r\n        results = con.fetchall()\r\n        print(\"Query succeeded (unexpectedly). Results:\", results)\r\n    except Exception as e:\r\n        print(\"Query failed as expected with error:\")\r\n        print(e)\r\n\r\n    # Cleanup test files\r\n    os.remove('fragment1.json')\r\n    os.remove('fragment2.json')\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\n### Expected vs. Actual Behavior\r\n\r\n- **Expected**: DuckDB should read all rows from both JSON files, merging columns appropriately (with `NULL` where columns are missing).\r\n- **Actual**: A `duplicate column name \"Image_1\"` error appears:\r\n  ```Binder Error: table \"fragment*.json\" has duplicate column name \"Image_1\"```\r\n\r\n### OS:\r\n\r\nWindows 11 amd64\r\n\r\n### DuckDB Version:\r\n\r\n1.1.3\r\n\r\n### DuckDB Client:\r\n\r\nPython\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\nMaitland Marshall\r\n\r\n### Affiliation:\r\n\r\nMAIT DEV\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\nJSON reader fails with duplicate column name when reading multiple JSON files of slightly different casing\n### What happens?\r\n\r\nWhen reading multiple JSON files using a single FROM \"fragment*.json\" query, DuckDB throws a duplicate column name \"Image_1\" error. It appears that columns (JSON object keys) with differing case\u2014e.g., \"Image\" vs. \"image\"\u2014may trigger this collision.\r\n\r\n### To Reproduce\r\n\r\n\r\nI have two JSON files with partially overlapping schemas. One file uses a key `\"Image\"`, and the other uses `\"image\"`, plus there is a key named `\"Image_1\"` in the second file. When I attempt to query all JSON files at once using a wildcard pattern, DuckDB complains about a duplicate column name.\r\n\r\n**File: `fragment1.json`**\r\n```json\r\n{\"id\":\"19276\",\"Consignee\":\"zz af9\",\"Time\":\"30-04-2024 10:06:21\",\"DocketNumber\":\"6364174\",\"Image\":[\"abc\"],\"Time_1\":\"30-04-2024 09:32:13\"}\r\n{\"id\":\"19281\",\"Consignee\":\"zz af9\",\"Time\":\"30-04-2024 11:38:13\",\"DocketNumber\":\"6364181\",\"Image\":[\"def\"],\"Time_1\":\"30-04-2024 11:01:27\"}\r\n```\r\n\r\n**File: `fragment2.json`**\r\n```json\r\n{\"id\":\"19421\",\"Comments\":null,\"Consignee\":\"zz zz\",\"Driver\":null,\"Time\":\"30-04-2024 17:04:01\",\"image\":[\"zz\"],\"DocketNumber\":\"11\",\"Image_1\":[\"zzz\"],\"Time_1\":\"30-04-2024 17:00:59\"}\r\n{\"id\":\"19426\",\"Comments\":\"delivered\",\"Consignee\":null,\"Driver\":\"zz zz\",\"Time\":\"01-05-2024 08:31:27\",\"image\":[\"zz\"],\"DocketNumber\":\"zxc\",\"Image_1\":[\"zzz\"],\"Time_1\":\"01-05-2024 08:31:01\"}\r\n{\"id\":\"8182\",\"Comments\":null,\"Consignee\":\"\",\"Driver\":null,\"Time\":\"26-03-2024 18:03:33\",\"image\":null,\"signature\":[\"xx\"],\"DocketNumber\":\"x D xc\",\"Image_1\":null,\"Time_1\":\"26-03-2024 18:03:33\"}\r\n```\r\n\r\n### Python script to reproduce\r\n\r\n```python\r\nimport duckdb\r\nimport os\r\n\r\ndef main():\r\n    # Create two JSON files with the sample data\r\n    with open('fragment1.json', 'w') as f:\r\n        f.write('''\\\r\n{\"id\":\"19276\",\"Consignee\":\"zz af9\",\"Time\":\"30-04-2024 10:06:21\",\"DocketNumber\":\"6364174\",\"Image\":[\"abc\"],\"Time_1\":\"30-04-2024 09:32:13\"}\r\n{\"id\":\"19281\",\"Consignee\":\"zz af9\",\"Time\":\"30-04-2024 11:38:13\",\"DocketNumber\":\"6364181\",\"Image\":[\"def\"],\"Time_1\":\"30-04-2024 11:01:27\"}\r\n''')\r\n\r\n    with open('fragment2.json', 'w') as f:\r\n        f.write('''\\\r\n{\"id\":\"19421\",\"Comments\":null,\"Consignee\":\"zz zz\",\"Driver\":null,\"Time\":\"30-04-2024 17:04:01\",\"image\":[\"zz\"],\"DocketNumber\":\"11\",\"Image_1\":[\"zzz\"],\"Time_1\":\"30-04-2024 17:00:59\"}\r\n{\"id\":\"19426\",\"Comments\":\"delivered\",\"Consignee\":null,\"Driver\":\"zz zz\",\"Time\":\"01-05-2024 08:31:27\",\"image\":[\"zz\"],\"DocketNumber\":\"zxc\",\"Image_1\":[\"zzz\"],\"Time_1\":\"01-05-2024 08:31:01\"}\r\n{\"id\":\"8182\",\"Comments\":null,\"Consignee\":\"\",\"Driver\":null,\"Time\":\"26-03-2024 18:03:33\",\"image\":null,\"signature\":[\"xx\"],\"DocketNumber\":\"x D xc\",\"Image_1\":null,\"Time_1\":\"26-03-2024 18:03:33\"}\r\n''')\r\n\r\n    con = duckdb.connect()\r\n    try:\r\n        # This query should fail due to a duplicate column name\r\n        con.execute(\"SELECT * FROM 'fragment*.json';\")\r\n        results = con.fetchall()\r\n        print(\"Query succeeded (unexpectedly). Results:\", results)\r\n    except Exception as e:\r\n        print(\"Query failed as expected with error:\")\r\n        print(e)\r\n\r\n    # Cleanup test files\r\n    os.remove('fragment1.json')\r\n    os.remove('fragment2.json')\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\n### Expected vs. Actual Behavior\r\n\r\n- **Expected**: DuckDB should read all rows from both JSON files, merging columns appropriately (with `NULL` where columns are missing).\r\n- **Actual**: A `duplicate column name \"Image_1\"` error appears:\r\n  ```Binder Error: table \"fragment*.json\" has duplicate column name \"Image_1\"```\r\n\r\n### OS:\r\n\r\nWindows 11 amd64\r\n\r\n### DuckDB Version:\r\n\r\n1.1.3\r\n\r\n### DuckDB Client:\r\n\r\nPython\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\nMaitland Marshall\r\n\r\n### Affiliation:\r\n\r\nMAIT DEV\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\n", "hints_text": "\n", "created_at": "2025-01-08T13:46:12Z"}
{"repo": "duckdb/duckdb", "pull_number": 15614, "instance_id": "duckdb__duckdb-15614", "issue_numbers": ["15062", "14619"], "base_commit": "ce33de966a521d1a6e86ec9579e133ff2b2534f4", "patch": "diff --git a/extension/core_functions/scalar/list/list_reduce.cpp b/extension/core_functions/scalar/list/list_reduce.cpp\nindex f8758515f8bd..173b52699bbe 100644\n--- a/extension/core_functions/scalar/list/list_reduce.cpp\n+++ b/extension/core_functions/scalar/list/list_reduce.cpp\n@@ -101,7 +101,7 @@ static bool ExecuteReduce(idx_t loops, ReduceExecuteInfo &execute_info, LambdaFu\n \t}\n \n \t// create the index vector\n-\tVector index_vector(Value::BIGINT(UnsafeNumericCast<int64_t>(loops + 1)));\n+\tVector index_vector(Value::BIGINT(UnsafeNumericCast<int64_t>(loops + 2)));\n \n \t// slice the left and right slice\n \texecute_info.left_slice->Slice(*execute_info.left_slice, execute_info.left_sel, reduced_row_idx);\n", "test_patch": "diff --git a/test/sql/function/list/lambdas/reduce.test b/test/sql/function/list/lambdas/reduce.test\nindex 943da335c6e0..3b107ee61999 100644\n--- a/test/sql/function/list/lambdas/reduce.test\n+++ b/test/sql/function/list/lambdas/reduce.test\n@@ -18,7 +18,7 @@ SELECT list_reduce([1, 2, 3], (x, y) -> x * y);\n query I\n SELECT list_reduce([100, 10, 1], (x, y, i) -> x - y - i);\n ----\n-86\n+84\n \n query I\n SELECT list_reduce([1, 2, 3], (x, y) -> y - x);\n@@ -33,7 +33,7 @@ SELECT list_reduce([1, 2, 3], (x, y) -> x - y);\n query I\n SELECT list_reduce([1, 2, 3], (x, y, i) -> x + y + i);\n ----\n-9\n+11\n \n query I\n SELECT list_reduce([NULL], (x, y, i) -> x + y + i);\n@@ -109,10 +109,10 @@ NULL\n query I\n SELECT list_reduce(a, (x, y, i) -> x + y + i) FROM t1;\n ----\n-9\n+11\n 666\n NULL\n-100\n+101\n NULL\n \n statement ok\n@@ -181,7 +181,7 @@ Cannot perform list_reduce on an empty input list\n query I\n SELECT list_reduce([1, 2, 3], (x, y, x_i) -> list_reduce([4, 5, 6], (a, b, a_i) -> x + y + a + b + x_i + a_i));\n ----\n-80\n+92\n \n statement error\n SELECT list_reduce([1, 2, 3], (x, y, x_i) -> list_reduce([], (a, b, a_i) -> x + y + a + b + x_i + a_i));\n@@ -234,7 +234,7 @@ NULL\n query I\n SELECT list_reduce(n, (x, y, x_i) -> list_reduce(l, (a, b, a_i) -> x + y + a + b + x_i + a_i)) FROM nested;\n ----\n-80\n+92\n NULL\n NULL\n NULL\n@@ -312,7 +312,7 @@ SELECT list_reduce([1, 2, 3], (x, y) -> list_reduce([4, 5, 6], (a, b) -> list_re\n query I\n SELECT list_reduce([1, 2, 3], (x, y, x_i) -> list_reduce([4, 5, 6], (a, b, a_i) -> list_reduce([7, 8, 9], (c, d, c_i) -> x + y + a + b + c + d + x_i + a_i + c_i)));\n ----\n-1133\n+1259\n \n query I\n SELECT list_reduce([[[10, 20], [100, 200]], [[30, 40], [300, 400]], [[50, 60], [500, 600]]], (x, y) -> list_pack(list_reduce(x, (l, m) -> list_pack(list_reduce(l, (a, b) -> a + b) + list_reduce(m, (c, d) -> c + d))) + list_reduce(y, (n, o) -> list_pack(list_reduce(n, (a, b) -> a + b) + list_reduce(o, (c, d) -> c + d)))));\n", "problem_statement": "Zero-based index in `list_reduce`\n### What happens?\n\n```sql\r\nSELECT list_reduce(['a', 'b'], (x, y, i) -> x || y || i)\r\n```\r\n```\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 list_reduce(main.list_value('a', 'b'), (main.\"row\"(x, y, i) -> ((x || y) || i))) \u2502\r\n\u2502                                     varchar                                      \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 ab1                                                                              \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\nbut according to https://duckdb.org/docs/sql/functions/lambda.html \r\n\r\n> All lambda functions accept an optional extra parameter that represents the index of the current element. This is always the last parameter of the lambda function, and is 1-based (i.e., the first element has index 1).\r\n\r\nwhich strongly suggests that `y = 'b'` should be accompanied with `i = 2`, since `2` is the correct index of `b` in the list `['a', 'b']`.\n\n### To Reproduce\n\n.\n\n### OS:\n\nLinux\n\n### DuckDB Version:\n\n1.1.0\n\n### DuckDB Client:\n\nPython\n\n### Hardware:\n\ni5, AMD64\n\n### Full Name:\n\nSoeren Wolfers\n\n### Affiliation:\n\nG-Research\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNot applicable - the reproduction does not require a data set\n\n### Did you include all code required to reproduce the issue?\n\n- [X] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [X] Yes, I have\nInconsistent Index Origin in list_transform() and list_reduce() \n### What happens?\n\nIn a nutshell, list_transform() uses 1 as its index-origin (IO=1)\r\nwhereas list_reduce() uses 0 instead:\r\n```\r\nD select list_transform([10,20,30], (x,ix) -> ix) as ix;\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502    ix     \u2502\r\n\u2502  int64[]  \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 [1, 2, 3] \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\nD select list_reduce([10,20,30], (acc,x,ix) -> ix) as ix;\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502  ix   \u2502\r\n\u2502 int32 \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502     2 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\n\n### To Reproduce\n\n```\r\nselect list_transform([10,20,30], (x,ix) -> ix) as ix;\r\nselect list_reduce([10,20,30], (acc,x,ix) -> ix) as ix;\r\n```\n\n### OS:\n\nMacOS\n\n### DuckDB Version:\n\nv1.1.3-dev75 c73cfca650 et al\n\n### DuckDB Client:\n\nCLI\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nPeter Koppstein\n\n### Affiliation:\n\nPrinceton University\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a source build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNot applicable - the reproduction does not require a data set\n\n### Did you include all code required to reproduce the issue?\n\n- [X] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [X] Yes, I have\n", "hints_text": "Seems consistent behaviour?\r\n\r\nIn the first iteration of list_reduce the values 'a' and 'b' are taken (hence i = 1).\r\nThe result is this query: SELECT list_reduce(['a', 'b','c'], (x, y, i) -> x || y || i);\r\n\r\nab1c2.\r\n\r\nSo in fact \"i\" is not the index in the list but the iterator count of list reduce.\nThe docs say \"extra parameter that represents the index of the current element\", not \"extra parameter that represents the iterator count\".\r\n\r\n`list_reduce` should eventually take an initial state argument. Once that's available, I think it'd be incompatible with any phrasing/interpretation of \"extra parameter ... index in the list\" if without that initial state `(a, b, 1)` were the first inputs to the lambda function while with the initial state`(init, a, 1)` are the first inputs. \r\n\r\nThen again, documentation can be changed and I'm happy to do that if I get confirmation that the current behavior is preferred. \nI agree with the initial state argument and then index is indeed the current element.\nDuplicate of https://github.com/duckdb/duckdb/issues/14619\nNice find, thanks! This should be consistent indeed.\nI think `list_reduce` is still 1-based. The below is converting loops (0-based) to 1-based.\r\n\r\nhttps://github.com/duckdb/duckdb/blob/2d1b7d796d0e49e7a73ede14fd7d3033c1782626/extension/core_functions/scalar/list/list_reduce.cpp#L104\r\n\r\nHowever, `list_reduce([10,20,30], (acc,x,ix) -> ix) as ix;` is calling the function only twice. The first is `(acc=10, x=20, ix=1)` and the second is `(acc=1, x=30, ix=2)`. That's why the result is 2.\n@kzys The docs say \"extra parameter that represents the index of the current element\", not \"extra parameter that represents the loop iterator count\". \r\n\r\nThat unambiguously requires that the arguments should be `(acc=10, x=20, ix=2)` and `(acc=30, x=30, ix=3)`.\r\n\r\nYou might say that the docs should therefore be changed; however, that wouldn't be future-proof: `list_reduce` will almost surely eventually take an initial state argument. Once that's available, I believe everybody agrees that the arguments have to be `(acc=init, x=10, ix=1), ..., (acc=init+30, x=30, ix=3)` so the only way to square that with the status quo would be to make _different_ `(x, ix)` pairs depending on whether an initial state is passed in, which would be awful.", "created_at": "2025-01-08T13:08:52Z"}
{"repo": "duckdb/duckdb", "pull_number": 15605, "instance_id": "duckdb__duckdb-15605", "issue_numbers": ["15504"], "base_commit": "acdbf60889033d2701a5fef360a19963cafea471", "patch": "diff --git a/extension/parquet/column_reader.cpp b/extension/parquet/column_reader.cpp\nindex cf1f5ba504c4..8a2112c356dd 100644\n--- a/extension/parquet/column_reader.cpp\n+++ b/extension/parquet/column_reader.cpp\n@@ -135,6 +135,14 @@ const SchemaElement &ColumnReader::Schema() const {\n \treturn schema;\n }\n \n+optional_ptr<const SchemaElement> ColumnReader::GetParentSchema() const {\n+\treturn parent_schema;\n+}\n+\n+void ColumnReader::SetParentSchema(const SchemaElement &parent_schema_p) {\n+\tparent_schema = &parent_schema_p;\n+}\n+\n idx_t ColumnReader::FileIdx() const {\n \treturn file_idx;\n }\ndiff --git a/extension/parquet/include/column_reader.hpp b/extension/parquet/include/column_reader.hpp\nindex dd89cadd5cd8..23d4fc3d4b6b 100644\n--- a/extension/parquet/include/column_reader.hpp\n+++ b/extension/parquet/include/column_reader.hpp\n@@ -57,6 +57,9 @@ class ColumnReader {\n \tParquetReader &Reader();\n \tconst LogicalType &Type() const;\n \tconst SchemaElement &Schema() const;\n+\toptional_ptr<const SchemaElement> GetParentSchema() const;\n+\tvoid SetParentSchema(const SchemaElement &parent_schema);\n+\n \tidx_t FileIdx() const;\n \tidx_t MaxDefine() const;\n \tidx_t MaxRepeat() const;\n@@ -140,6 +143,7 @@ class ColumnReader {\n \n protected:\n \tconst SchemaElement &schema;\n+\toptional_ptr<const SchemaElement> parent_schema;\n \n \tidx_t file_idx;\n \tidx_t max_define;\ndiff --git a/extension/parquet/parquet_extension.cpp b/extension/parquet/parquet_extension.cpp\nindex 8cbea80909d4..500b899198d7 100644\n--- a/extension/parquet/parquet_extension.cpp\n+++ b/extension/parquet/parquet_extension.cpp\n@@ -313,9 +313,15 @@ static void InitializeParquetReader(ParquetReader &reader, const ParquetReadBind\n \tunordered_map<uint32_t, idx_t> field_id_to_column_index;\n \tauto &column_readers = reader.root_reader->Cast<StructColumnReader>().child_readers;\n \tfor (idx_t column_index = 0; column_index < column_readers.size(); column_index++) {\n-\t\tauto &column_schema = column_readers[column_index]->Schema();\n+\t\tauto &column_reader = *column_readers[column_index];\n+\t\tauto &column_schema = column_reader.Schema();\n \t\tif (column_schema.__isset.field_id) {\n \t\t\tfield_id_to_column_index[column_schema.field_id] = column_index;\n+\t\t} else if (column_reader.GetParentSchema()) {\n+\t\t\tauto &parent_column_schema = *column_reader.GetParentSchema();\n+\t\t\tif (parent_column_schema.__isset.field_id) {\n+\t\t\t\tfield_id_to_column_index[parent_column_schema.field_id] = column_index;\n+\t\t\t}\n \t\t}\n \t}\n \ndiff --git a/extension/parquet/parquet_reader.cpp b/extension/parquet/parquet_reader.cpp\nindex e6ce7aa92d51..1d2565a2dea9 100644\n--- a/extension/parquet/parquet_reader.cpp\n+++ b/extension/parquet/parquet_reader.cpp\n@@ -418,9 +418,10 @@ unique_ptr<ColumnReader> ParquetReader::CreateReaderRecursive(ClientContext &con\n \t\t}\n \t\tif (is_repeated) {\n \t\t\tresult_type = LogicalType::LIST(result_type);\n-\t\t\treturn make_uniq<ListColumnReader>(*this, result_type, s_ele, this_idx, max_define, max_repeat,\n-\t\t\t                                   std::move(result));\n+\t\t\tresult = make_uniq<ListColumnReader>(*this, result_type, s_ele, this_idx, max_define, max_repeat,\n+\t\t\t                                     std::move(result));\n \t\t}\n+\t\tresult->SetParentSchema(s_ele);\n \t\treturn result;\n \t} else { // leaf node\n \t\tif (!s_ele.__isset.type) {\ndiff --git a/src/execution/aggregate_hashtable.cpp b/src/execution/aggregate_hashtable.cpp\nindex 8a2dd448ce78..198b77facfc0 100644\n--- a/src/execution/aggregate_hashtable.cpp\n+++ b/src/execution/aggregate_hashtable.cpp\n@@ -131,6 +131,9 @@ void GroupedAggregateHashTable::Abandon() {\n \t// Start over\n \tClearPointerTable();\n \tcount = 0;\n+\n+\t// Resetting the id ensures the dict state is reset properly when needed\n+\tstate.dict_state.dictionary_id = string();\n }\n \n void GroupedAggregateHashTable::Repartition() {\ndiff --git a/src/function/scalar/sequence/nextval.cpp b/src/function/scalar/sequence/nextval.cpp\nindex 7e19dae7d6bf..6738383dc50f 100644\n--- a/src/function/scalar/sequence/nextval.cpp\n+++ b/src/function/scalar/sequence/nextval.cpp\n@@ -91,6 +91,9 @@ static void NextValFunction(DataChunk &args, ExpressionState &state, Vector &res\n \n static unique_ptr<FunctionData> NextValBind(ScalarFunctionBindInput &bind_input, ScalarFunction &,\n                                             vector<unique_ptr<Expression>> &arguments) {\n+\tif (arguments[0]->HasParameter() || arguments[0]->return_type.id() == LogicalTypeId::UNKNOWN) {\n+\t\tthrow ParameterNotResolvedException();\n+\t}\n \tif (!arguments[0]->IsFoldable()) {\n \t\tthrow NotImplementedException(\n \t\t    \"currval/nextval requires a constant sequence - non-constant sequences are no longer supported\");\ndiff --git a/src/function/scalar/string/length.cpp b/src/function/scalar/string/length.cpp\nindex f2ec8bae1ff0..5386464199d3 100644\n--- a/src/function/scalar/string/length.cpp\n+++ b/src/function/scalar/string/length.cpp\n@@ -110,12 +110,14 @@ static void ArrayLengthFunction(DataChunk &args, ExpressionState &state, Vector\n \n static unique_ptr<FunctionData> ArrayOrListLengthBind(ClientContext &context, ScalarFunction &bound_function,\n                                                       vector<unique_ptr<Expression>> &arguments) {\n-\tif (arguments[0]->HasParameter()) {\n+\tif (arguments[0]->HasParameter() || arguments[0]->return_type.id() == LogicalTypeId::UNKNOWN) {\n \t\tthrow ParameterNotResolvedException();\n \t}\n-\tif (arguments[0]->return_type.id() == LogicalTypeId::ARRAY) {\n+\n+\tconst auto &arg_type = arguments[0]->return_type.id();\n+\tif (arg_type == LogicalTypeId::ARRAY) {\n \t\tbound_function.function = ArrayLengthFunction;\n-\t} else if (arguments[0]->return_type.id() == LogicalTypeId::LIST) {\n+\t} else if (arg_type == LogicalTypeId::LIST) {\n \t\tbound_function.function = ListLengthFunction;\n \t} else {\n \t\t// Unreachable\n@@ -183,7 +185,7 @@ static void ArrayLengthBinaryFunction(DataChunk &args, ExpressionState &state, V\n \n static unique_ptr<FunctionData> ArrayOrListLengthBinaryBind(ClientContext &context, ScalarFunction &bound_function,\n                                                             vector<unique_ptr<Expression>> &arguments) {\n-\tif (arguments[0]->HasParameter()) {\n+\tif (arguments[0]->HasParameter() || arguments[0]->return_type.id() == LogicalTypeId::UNKNOWN) {\n \t\tthrow ParameterNotResolvedException();\n \t}\n \tauto type = arguments[0]->return_type;\ndiff --git a/src/planner/binder/expression/bind_operator_expression.cpp b/src/planner/binder/expression/bind_operator_expression.cpp\nindex 81addd4069ef..9326c8849622 100644\n--- a/src/planner/binder/expression/bind_operator_expression.cpp\n+++ b/src/planner/binder/expression/bind_operator_expression.cpp\n@@ -134,6 +134,9 @@ BindResult ExpressionBinder::BindExpression(OperatorExpression &op, idx_t depth)\n \t\tD_ASSERT(op.children[0]->GetExpressionClass() == ExpressionClass::BOUND_EXPRESSION);\n \t\tD_ASSERT(op.children[1]->GetExpressionClass() == ExpressionClass::BOUND_EXPRESSION);\n \t\tauto &extract_exp = BoundExpression::GetExpression(*op.children[0]);\n+\t\tif (extract_exp->HasParameter() || extract_exp->return_type.id() == LogicalTypeId::UNKNOWN) {\n+\t\t\tthrow ParameterNotResolvedException();\n+\t\t}\n \t\tauto &name_exp = BoundExpression::GetExpression(*op.children[1]);\n \t\tconst auto &extract_expr_type = extract_exp->return_type;\n \t\tif (extract_expr_type.id() != LogicalTypeId::STRUCT && extract_expr_type.id() != LogicalTypeId::UNION &&\ndiff --git a/src/planner/binder/statement/bind_create.cpp b/src/planner/binder/statement/bind_create.cpp\nindex 495a687e67f6..8d53446fc625 100644\n--- a/src/planner/binder/statement/bind_create.cpp\n+++ b/src/planner/binder/statement/bind_create.cpp\n@@ -196,7 +196,7 @@ SchemaCatalogEntry &Binder::BindCreateFunctionInfo(CreateInfo &info) {\n \t\t\tif (param.IsQualified()) {\n \t\t\t\tthrow BinderException(\"Invalid parameter name '%s': must be unqualified\", param.ToString());\n \t\t\t}\n-\t\t\tdummy_types.emplace_back(LogicalType::SQLNULL);\n+\t\t\tdummy_types.emplace_back(LogicalType::UNKNOWN);\n \t\t\tdummy_names.push_back(param.GetColumnName());\n \t\t}\n \t\t// default parameters\ndiff --git a/src/storage/arena_allocator.cpp b/src/storage/arena_allocator.cpp\nindex a67eeb2869cd..000444f755f6 100644\n--- a/src/storage/arena_allocator.cpp\n+++ b/src/storage/arena_allocator.cpp\n@@ -107,12 +107,13 @@ data_ptr_t ArenaAllocator::Reallocate(data_ptr_t pointer, idx_t old_size, idx_t\n \t\treturn pointer;\n \t}\n \n-\tauto head_ptr = head->data.get() + head->current_position;\n+\tconst auto head_ptr = head->data.get() + head->current_position - old_size;\n+\tint64_t current_position = NumericCast<int64_t>(head->current_position);\n \tint64_t diff = NumericCast<int64_t>(size) - NumericCast<int64_t>(old_size);\n-\tif (pointer == head_ptr && (size < old_size || NumericCast<int64_t>(head->current_position) + diff <=\n-\t                                                   NumericCast<int64_t>(head->maximum_size))) {\n+\tif (pointer == head_ptr &&\n+\t    (size < old_size || current_position + diff <= NumericCast<int64_t>(head->maximum_size))) {\n \t\t// passed pointer is the head pointer, and the diff fits on the current chunk\n-\t\thead->current_position += NumericCast<idx_t>(diff);\n+\t\thead->current_position = NumericCast<idx_t>(current_position + diff);\n \t\treturn pointer;\n \t} else {\n \t\t// allocate new memory\n", "test_patch": "diff --git a/test/issues/general/test_15432.test b/test/issues/general/test_15432.test\nnew file mode 100644\nindex 000000000000..521bbcd84ce6\n--- /dev/null\n+++ b/test/issues/general/test_15432.test\n@@ -0,0 +1,34 @@\n+# name: test/issues/general/test_15432.test\n+# description: Issue 15432 - Regression bug (V1.1.4 vs V1.0 and V1.0): binder error references non-existent call to sum()\n+# group: [general]\n+\n+statement ok\n+pragma enable_verification;\n+\n+statement ok\n+create or replace function transpose(lst) as (\n+\tselect list_transform(\n+\t\trange(1, 1+length(lst[1])),\n+\t\tj -> list_transform(\n+\t\t\trange(1, length(lst)+1),\n+\t\t\ti -> lst[i][j]\n+\t\t)\n+\t)\n+);\n+\n+statement ok\n+create or replace function centroid(points) as (\n+\tlist_transform(\n+\t\ttranspose(points),\n+\t\tx -> list_sum(x) / length(points)\n+\t)\n+);\n+\n+query II\n+select\n+\tpoints,\n+\tcentroid(points)\n+from\n+\tunnest([[[1], [2], [3]]]) t(points);\n+----\n+[[1], [2], [3]]\t[2.0]\ndiff --git a/test/parquet/test_parquet_schema.test b/test/parquet/test_parquet_schema.test\nindex b7f41cb6ac19..3df1a2736fd7 100644\n--- a/test/parquet/test_parquet_schema.test\n+++ b/test/parquet/test_parquet_schema.test\n@@ -268,3 +268,12 @@ ORDER BY filename\n ----\n 5\t3\t2\t1\tmultifile1.parquet\n 1\t4\t5\tNULL\tmultifile2.parquet\n+\n+# issue 15504\n+statement ok\n+COPY (select 1 as id, list_value('a', 'b', 'c') as arr, { key: 1, v1: 'a', v2: 'b' } as s) TO '__TEST_DIR__/15504.parquet' (field_ids { 'id': 0, 'arr': 1, 's': 2 });\n+\n+query III\n+SELECT * FROM read_parquet('__TEST_DIR__/15504.parquet', schema=map { 0: { name: 'id', type: 'int32', default_value: NULL }, 1: { name: 'arr', type: 'varchar[]', default_value: NULL }, 2: { name: 's', type: 'STRUCT(key INT, v1 TEXT, v2 TEXT)', default_value: NULL } });\n+----\n+1\t[a, b, c]\t{'key': 1, 'v1': a, 'v2': b}\ndiff --git a/test/sql/catalog/function/test_complex_macro.test b/test/sql/catalog/function/test_complex_macro.test\nindex 7211801e9c26..1bbe101d000c 100644\n--- a/test/sql/catalog/function/test_complex_macro.test\n+++ b/test/sql/catalog/function/test_complex_macro.test\n@@ -62,10 +62,13 @@ statement error\n SELECT IFELSE(1,IFELSE(1,b,1),a) FROM integers\n ----\n \n-# conflicting bindings\n-statement error\n+statement ok\n CREATE MACRO f1(x) AS (SELECT MIN(a) + x FROM integers)\n+\n+query I\n+select f1(42) from integers;\n ----\n+43\n \n # macro in GROUP BY\n statement ok\n", "problem_statement": "ARRAY or LIST return null when read_parquet with schema parameter\n### What happens?\r\n\r\nI am using duck db to test the analysis of nested fields, When using read_parquet with schema parameters to read a Parquet file, the array / list type returns null.\r\nI'm not sure if this is a bug or if there's a problem with my usage.\r\n\r\n### To Reproduce\r\n\r\n```\r\nCOPY (select 1 as id, list_value('a', 'b', 'c') as arr, { key: 1, v1: 'a', v2: 'b' } as s) TO './test.parquet' (field_ids { 'id': 0, 'arr': 1, 's': 2 });\r\nSELECT * FROM read_parquet('./test.parquet', schema=map { 0: { name: 'id', type: 'int32', default_value: NULL }, 1: { name: 'arr', type: 'varchar[]', default_value: NULL }, 2: { name: 's', type: 'STRUCT(key INT, v1 TEXT, v2 TEXT)', default_value: NULL } });\r\n```\r\nThe Output:\r\n```\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502  id   \u2502    arr    \u2502                       s                       \u2502\r\n\u2502 int32 \u2502 varchar[] \u2502 struct(\"key\" integer, v1 varchar, v2 varchar) \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502     1 \u2502           \u2502 {'key': 1, 'v1': a, 'v2': b}                  \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\nif read_parquet without schema\uff0cthe result is normal\r\n```\r\nSELECT * FROM read_parquet('./test.parquet');\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502  id   \u2502    arr    \u2502                       s                       \u2502\r\n\u2502 int32 \u2502 varchar[] \u2502 struct(\"key\" integer, v1 varchar, v2 varchar) \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502     1 \u2502 [a, b, c] \u2502 {'key': 1, 'v1': a, 'v2': b}                  \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\nfull case:\r\n<img width=\"1870\" alt=\"image\" src=\"https://github.com/user-attachments/assets/2ddf246b-ff08-42ae-8507-3ee643407e0a\" />\r\n\r\n\r\n### OS:\r\n\r\nosx aarch64\r\n\r\n### DuckDB Version:\r\n\r\n1.3.0, 1.0.0\r\n\r\n### DuckDB Client:\r\n\r\ncli\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\njun\r\n\r\n### Affiliation:\r\n\r\njdy\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have not tested with any build\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [ ] Yes, I have\n", "hints_text": "The reason for this problem may be as follows\r\n\r\nThe parquet schema was:\r\n```\r\nSchema:\r\nmessage duckdb_schema {\r\n  optional int32 id (INTEGER(32,true)) = 0;\r\n  optional group arr (LIST) = 1 {\r\n    repeated group list {\r\n      optional binary element (STRING);\r\n    }\r\n  }\r\n  optional group s = 2 {\r\n    optional int32 key (INTEGER(32,true));\r\n    optional binary v1 (STRING);\r\n    optional binary v2 (STRING);\r\n  }\r\n}\r\n```\r\n\r\nIn the [ParquetReader::CreateReaderRecursive](https://github.com/duckdb/duckdb/blob/e1db888231f0cbe856d75ee8db6e677a2e19dd4a/extension/parquet/parquet_reader.cpp#L298) method, it will be rollup when there only one child reader\r\n\r\nhttps://github.com/duckdb/duckdb/blob/e1db888231f0cbe856d75ee8db6e677a2e19dd4a/extension/parquet/parquet_reader.cpp#L410-L418\r\n\r\nSo the child reader of root will be like this in the end\r\n```\r\nStruct:\r\n  - name: id, field_id: 0\r\n  - name: list, field_id: (not set)\r\n  - name: s, field_id: 2\r\n```\r\n\r\nIn the [InitializeParquetReader](https://github.com/duckdb/duckdb/blob/e1db888231f0cbe856d75ee8db6e677a2e19dd4a/extension/parquet/parquet_extension.cpp#L287) method, the column will be checked for existence based on the root reader, and if not, the default value will be returned.\r\n\r\nThe relevant code is as follows:\r\nhttps://github.com/duckdb/duckdb/blob/e1db888231f0cbe856d75ee8db6e677a2e19dd4a/extension/parquet/parquet_extension.cpp#L314-L320\r\n\r\nhttps://github.com/duckdb/duckdb/blob/e1db888231f0cbe856d75ee8db6e677a2e19dd4a/extension/parquet/parquet_extension.cpp#L349-L354\r\n\r\nMy C++ is poor, and I\u2019m not sure if the reason is correct.", "created_at": "2025-01-08T08:30:37Z"}
{"repo": "duckdb/duckdb", "pull_number": 15575, "instance_id": "duckdb__duckdb-15575", "issue_numbers": ["15526", "15526"], "base_commit": "adc6f607a71b87da2d0a7550e90db623e9bea637", "patch": "diff --git a/src/execution/physical_plan/plan_cte.cpp b/src/execution/physical_plan/plan_cte.cpp\nindex 190cb9319bc7..9c6596279ca5 100644\n--- a/src/execution/physical_plan/plan_cte.cpp\n+++ b/src/execution/physical_plan/plan_cte.cpp\n@@ -24,7 +24,7 @@ unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalMaterializ\n \tauto right = CreatePlan(*op.children[1]);\n \n \tunique_ptr<PhysicalCTE> cte;\n-\tcte = make_uniq<PhysicalCTE>(op.ctename, op.table_index, op.children[1]->types, std::move(left), std::move(right),\n+\tcte = make_uniq<PhysicalCTE>(op.ctename, op.table_index, right->types, std::move(left), std::move(right),\n \t                             op.estimated_cardinality);\n \tcte->working_table = working_table;\n \tcte->cte_scans = materialized_ctes[op.table_index];\n", "test_patch": "diff --git a/test/fuzzer/public/lateral_join_subquery.test b/test/fuzzer/public/lateral_join_subquery.test\nindex 30a2ce2f3acc..0c47325298d8 100644\n--- a/test/fuzzer/public/lateral_join_subquery.test\n+++ b/test/fuzzer/public/lateral_join_subquery.test\n@@ -12,3 +12,6 @@ statement error\n FROM t1 INNER JOIN (SELECT t1.c1) ON (SELECT 42);\n ----\n Subqueries are not supported in LATERAL join conditions\n+\n+statement ok\n+SELECT  c01 from values('string') as _(c01), LATERAL ( WITH ta02 AS MATERIALIZED ( SELECT 'string' ) ( SELECT 'string' ) INTERSECT ALL ( SELECT 'string' ) );\n", "problem_statement": "DuckDB Internal Error: types == input.GetTypes()\n### What happens?\r\n\r\nThe latest version of the DuckDB (latest main: v1.1.4-dev3916 13ff921d7c and released version v1.1.3 19864453f7) triggers Internal Error when running the following SQL statement: \r\n\r\n```sql\r\nCREATE TABLE v00 AS ( SELECT 'string' ); \r\nSELECT DISTINCT 'string' AS c01 FROM v00, LATERAL ( WITH ta02 AS MATERIALIZED ( SELECT 'string' ) ( SELECT 'string' ) INTERSECT ALL ( SELECT 'string' ) );\r\n```\r\n\r\nHere is the stack trace from (v1.1.4-dev3916 13ff921d7c)\r\n\r\n```\r\nINTERNAL Error: Assertion triggered in file \"/home/duckdb/duckdb/src/common/types/column/column_data_collection.cpp\" on line 794: types == input.GetTypes()\r\n\r\n#0  duckdb::InternalException::InternalException (this=0xffff80002b80, Python Exception <class 'gdb.error'> There is no member named _M_dataplus.:\r\nmsg=) at /home/duckdb/duckdb/src/common/exception.cpp:320\r\n#1  0x00000000004f0950 in duckdb::InternalException::InternalException<unsigned long, unsigned long> (this=0xffff80002b80, Python Exception <class 'gdb.error'> There is no member named _M_dataplus.:\r\nmsg=, params=1, params=1)\r\n    at ../../src/include/duckdb/common/exception.hpp:313\r\n#2  duckdb::vector<duckdb::Vector, true>::AssertIndexInBounds (index=1, size=1) at ../../src/include/duckdb/common/vector.hpp:35\r\n#3  0x0000000000a02f60 in duckdb::vector<duckdb::Vector, true>::get<true> (this=0xffff80000f88, __n=1) at ../../src/include/duckdb/common/vector.hpp:62\r\n#4  duckdb::vector<duckdb::Vector, true>::operator[] (this=0xffff80000f88, __n=1) at ../../src/include/duckdb/common/vector.hpp:76\r\n#5  duckdb::ColumnDataCollection::Append (this=0xffff78000c50, state=..., input=...)\r\n    at /home/duckdb/duckdb/src/common/types/column/column_data_collection.cpp:806\r\n#6  0x000000000454df74 in duckdb::PhysicalCrossProduct::Sink (this=<optimized out>, context=..., chunk=..., input=...)\r\n    at /home/duckdb/duckdb/src/execution/operator/join/physical_cross_product.cpp:38\r\n#7  0x0000000001ac48c8 in duckdb::PipelineExecutor::Sink (this=0xffff80000e60, chunk=..., input=...)\r\n    at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:521\r\n#8  duckdb::PipelineExecutor::ExecutePushInternal (this=0xffff80000e60, input=..., chunk_budget=..., initial_idx=1)\r\n    at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:332\r\n#9  0x0000000001ac3858 in duckdb::PipelineExecutor::TryFlushCachingOperators (this=0xffff80000e60, chunk_budget=...)\r\n    at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:94\r\n#10 0x0000000001ab4710 in duckdb::PipelineExecutor::Execute (this=0xffff80000e60, max_chunks=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:211\r\n#11 0x0000000001ab2994 in duckdb::PipelineExecutor::Execute (this=0xffff80000e60) at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:278\r\n#12 duckdb::PipelineTask::ExecuteTask (this=0xffff7c000d90, mode=duckdb::TaskExecutionMode::PROCESS_ALL)\r\n    at /home/duckdb/duckdb/src/parallel/pipeline.cpp:51\r\n#13 0x0000000001a9680c in duckdb::ExecutorTask::Execute (this=0xffff7c000d90, mode=duckdb::TaskExecutionMode::PROCESS_ALL)\r\n    at /home/duckdb/duckdb/src/parallel/executor_task.cpp:49\r\n#14 0x0000000001ad2fd0 in duckdb::TaskScheduler::ExecuteForever (this=0x3a174910, marker=0x3a207060)\r\n    at /home/duckdb/duckdb/src/parallel/task_scheduler.cpp:189\r\n#15 0x0000ffff9b760f9c in ?? () from /lib/aarch64-linux-gnu/libstdc++.so.6\r\n#16 0x0000ffff9b880624 in start_thread (arg=0xffff9b760f80) at pthread_create.c:477\r\n#17 0x0000ffff9b52362c in thread_start () at ../sysdeps/unix/sysv/linux/aarch64/clone.S:78\r\n```\r\n\r\n### To Reproduce\r\n\r\n1. Clone the DuckDB Git from the official repo.\r\n2. Checkout to the latest main (v1.1.4-dev3916 13ff921d7c).\r\n3. Compile the DuckDB binary by using `make debug`.\r\n4. Run the compiled DuckDB and input the following SQL: \r\n\r\n```sql\r\nCREATE TABLE v00 AS ( SELECT 'string' ); \r\nSELECT DISTINCT 'string' AS c01 FROM v00, LATERAL ( WITH ta02 AS MATERIALIZED ( SELECT 'string' ) ( SELECT 'string' ) INTERSECT ALL ( SELECT 'string' ) );\r\n```\r\n\r\n### OS:\r\n\r\nUbuntu 24.04 LTS\r\n\r\n### DuckDB Version:\r\n\r\nv1.1.4-dev3916 13ff921d7c\r\n\r\n### DuckDB Client:\r\n\r\ncli\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\nYu Liang\r\n\r\n### Affiliation:\r\n\r\nThe Pennsylvania State University\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\nDuckDB Internal Error: types == input.GetTypes()\n### What happens?\r\n\r\nThe latest version of the DuckDB (latest main: v1.1.4-dev3916 13ff921d7c and released version v1.1.3 19864453f7) triggers Internal Error when running the following SQL statement: \r\n\r\n```sql\r\nCREATE TABLE v00 AS ( SELECT 'string' ); \r\nSELECT DISTINCT 'string' AS c01 FROM v00, LATERAL ( WITH ta02 AS MATERIALIZED ( SELECT 'string' ) ( SELECT 'string' ) INTERSECT ALL ( SELECT 'string' ) );\r\n```\r\n\r\nHere is the stack trace from (v1.1.4-dev3916 13ff921d7c)\r\n\r\n```\r\nINTERNAL Error: Assertion triggered in file \"/home/duckdb/duckdb/src/common/types/column/column_data_collection.cpp\" on line 794: types == input.GetTypes()\r\n\r\n#0  duckdb::InternalException::InternalException (this=0xffff80002b80, Python Exception <class 'gdb.error'> There is no member named _M_dataplus.:\r\nmsg=) at /home/duckdb/duckdb/src/common/exception.cpp:320\r\n#1  0x00000000004f0950 in duckdb::InternalException::InternalException<unsigned long, unsigned long> (this=0xffff80002b80, Python Exception <class 'gdb.error'> There is no member named _M_dataplus.:\r\nmsg=, params=1, params=1)\r\n    at ../../src/include/duckdb/common/exception.hpp:313\r\n#2  duckdb::vector<duckdb::Vector, true>::AssertIndexInBounds (index=1, size=1) at ../../src/include/duckdb/common/vector.hpp:35\r\n#3  0x0000000000a02f60 in duckdb::vector<duckdb::Vector, true>::get<true> (this=0xffff80000f88, __n=1) at ../../src/include/duckdb/common/vector.hpp:62\r\n#4  duckdb::vector<duckdb::Vector, true>::operator[] (this=0xffff80000f88, __n=1) at ../../src/include/duckdb/common/vector.hpp:76\r\n#5  duckdb::ColumnDataCollection::Append (this=0xffff78000c50, state=..., input=...)\r\n    at /home/duckdb/duckdb/src/common/types/column/column_data_collection.cpp:806\r\n#6  0x000000000454df74 in duckdb::PhysicalCrossProduct::Sink (this=<optimized out>, context=..., chunk=..., input=...)\r\n    at /home/duckdb/duckdb/src/execution/operator/join/physical_cross_product.cpp:38\r\n#7  0x0000000001ac48c8 in duckdb::PipelineExecutor::Sink (this=0xffff80000e60, chunk=..., input=...)\r\n    at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:521\r\n#8  duckdb::PipelineExecutor::ExecutePushInternal (this=0xffff80000e60, input=..., chunk_budget=..., initial_idx=1)\r\n    at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:332\r\n#9  0x0000000001ac3858 in duckdb::PipelineExecutor::TryFlushCachingOperators (this=0xffff80000e60, chunk_budget=...)\r\n    at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:94\r\n#10 0x0000000001ab4710 in duckdb::PipelineExecutor::Execute (this=0xffff80000e60, max_chunks=<optimized out>)\r\n    at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:211\r\n#11 0x0000000001ab2994 in duckdb::PipelineExecutor::Execute (this=0xffff80000e60) at /home/duckdb/duckdb/src/parallel/pipeline_executor.cpp:278\r\n#12 duckdb::PipelineTask::ExecuteTask (this=0xffff7c000d90, mode=duckdb::TaskExecutionMode::PROCESS_ALL)\r\n    at /home/duckdb/duckdb/src/parallel/pipeline.cpp:51\r\n#13 0x0000000001a9680c in duckdb::ExecutorTask::Execute (this=0xffff7c000d90, mode=duckdb::TaskExecutionMode::PROCESS_ALL)\r\n    at /home/duckdb/duckdb/src/parallel/executor_task.cpp:49\r\n#14 0x0000000001ad2fd0 in duckdb::TaskScheduler::ExecuteForever (this=0x3a174910, marker=0x3a207060)\r\n    at /home/duckdb/duckdb/src/parallel/task_scheduler.cpp:189\r\n#15 0x0000ffff9b760f9c in ?? () from /lib/aarch64-linux-gnu/libstdc++.so.6\r\n#16 0x0000ffff9b880624 in start_thread (arg=0xffff9b760f80) at pthread_create.c:477\r\n#17 0x0000ffff9b52362c in thread_start () at ../sysdeps/unix/sysv/linux/aarch64/clone.S:78\r\n```\r\n\r\n### To Reproduce\r\n\r\n1. Clone the DuckDB Git from the official repo.\r\n2. Checkout to the latest main (v1.1.4-dev3916 13ff921d7c).\r\n3. Compile the DuckDB binary by using `make debug`.\r\n4. Run the compiled DuckDB and input the following SQL: \r\n\r\n```sql\r\nCREATE TABLE v00 AS ( SELECT 'string' ); \r\nSELECT DISTINCT 'string' AS c01 FROM v00, LATERAL ( WITH ta02 AS MATERIALIZED ( SELECT 'string' ) ( SELECT 'string' ) INTERSECT ALL ( SELECT 'string' ) );\r\n```\r\n\r\n### OS:\r\n\r\nUbuntu 24.04 LTS\r\n\r\n### DuckDB Version:\r\n\r\nv1.1.4-dev3916 13ff921d7c\r\n\r\n### DuckDB Client:\r\n\r\ncli\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\nYu Liang\r\n\r\n### Affiliation:\r\n\r\nThe Pennsylvania State University\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\n", "hints_text": "\n", "created_at": "2025-01-07T08:09:18Z"}
{"repo": "duckdb/duckdb", "pull_number": 15537, "instance_id": "duckdb__duckdb-15537", "issue_numbers": ["15528"], "base_commit": "1342bdbf2d809a4194f2767c3020181ce5199df7", "patch": "diff --git a/tools/pythonpkg/src/pyconnection.cpp b/tools/pythonpkg/src/pyconnection.cpp\nindex 9fb078e9f0a9..13cd5e1512ba 100644\n--- a/tools/pythonpkg/src/pyconnection.cpp\n+++ b/tools/pythonpkg/src/pyconnection.cpp\n@@ -2022,8 +2022,11 @@ py::dict DuckDBPyConnection::FetchTF() {\n }\n \n PolarsDataFrame DuckDBPyConnection::FetchPolars(idx_t rows_per_batch) {\n-\tauto arrow = FetchArrow(rows_per_batch);\n-\treturn py::cast<PolarsDataFrame>(py::module::import(\"polars\").attr(\"DataFrame\")(arrow));\n+\tif (!con.HasResult()) {\n+\t\tthrow InvalidInputException(\"No open result set\");\n+\t}\n+\tauto &result = con.GetResult();\n+\treturn result.ToPolars(rows_per_batch);\n }\n \n duckdb::pyarrow::RecordBatchReader DuckDBPyConnection::FetchRecordBatchReader(const idx_t rows_per_batch) {\n", "test_patch": "diff --git a/tools/pythonpkg/tests/fast/arrow/test_polars.py b/tools/pythonpkg/tests/fast/arrow/test_polars.py\nindex 1238bd3ec10e..df1a683a917e 100644\n--- a/tools/pythonpkg/tests/fast/arrow/test_polars.py\n+++ b/tools/pythonpkg/tests/fast/arrow/test_polars.py\n@@ -30,6 +30,10 @@ def test_polars(self, duckdb_cursor):\n         con_result = con.execute('SELECT * FROM df').pl()\n         pl_testing.assert_frame_equal(df, con_result)\n \n+    def test_execute_polars(self, duckdb_cursor):\n+        res1 = duckdb_cursor.execute(\"SELECT 1 AS a, 2 AS a\").pl()\n+        assert res1.columns == ['a', 'a_1']\n+\n     def test_register_polars(self, duckdb_cursor):\n         con = duckdb.connect()\n         df = pl.DataFrame(\n", "problem_statement": "Pandas (.df()) and fetchall() but not Polars (.pl()) rename column name conflicts \n### What happens?\r\n\r\nIf two tables with identical column names are joined, and the identical column names are selected from each table and retrieved using the Python API via .pl(), this fails with the error \"polars.exceptions.ShapeError: M column names provided for a DataFrame of width N\" (where M is the number of columns participating in the conflict, and N is the number of unique names. Pandas and fetchall() assign a unique suffix (i.e. _1). I'm not sure if this is a bug or intended behavior, but my vote would be to have the behavior be consistent across all manners of fetching rows. Thank you!\r\n\r\n### To Reproduce\r\n\r\n```\r\nimport duckdb as dd\r\n\r\nconn = dd.connect()\r\nconn.execute(\"CREATE TABLE one (a INTEGER); CREATE TABLE two (a INTEGER); SELECT one.a, two.a FROM one JOIN two ON one.a = two.a\").pl()\r\n```\r\n\r\n### OS:\r\n\r\nUbuntu Jammy Jellyfish\r\n\r\n### DuckDB Version:\r\n\r\n1.1.3\r\n\r\n### DuckDB Client:\r\n\r\nPython\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\nBen Skubi\r\n\r\n### Affiliation:\r\n\r\nOHSU\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nNot applicable - the reproduction does not require a data set\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\n", "hints_text": "Thanks for opening this issue! Based on our automated check, it seems that your post contains some code but it does not use [code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) to format it.\n          \nPlease double-check your post and revise it if necessary. To employ syntax highlighting, it's recommended to use code blocks with triple backticks, e.g.:\n````\n```sql\nSELECT ...\n```\n````\nIf this is a false positive, feel free to disregard this comment.\n\nMWE:\r\n\r\n```python\r\nimport duckdb as dd\r\ndd.execute(\"SELECT 1 AS a, 2 AS a\").pl()\r\n```\r\n\r\nConfusingly, \r\n\r\n```python\r\nimport duckdb as dd\r\ndd.query(\"SELECT 1 AS a, 2 AS a\").pl()\r\ndd.query(\"SELECT 1 AS a, 2 AS a\").execute().pl()\r\n```\r\nwork as expected. See https://github.com/duckdb/duckdb/issues/11085 for similar problems with / differences between `execute` and query. ", "created_at": "2025-01-03T11:10:57Z"}
{"repo": "duckdb/duckdb", "pull_number": 15534, "instance_id": "duckdb__duckdb-15534", "issue_numbers": ["15290"], "base_commit": "0959644c1d57409e78d2fae0262f792921a54c55", "patch": "diff --git a/src/planner/binder/expression/bind_unpacked_star_expression.cpp b/src/planner/binder/expression/bind_unpacked_star_expression.cpp\nindex 24e708129528..b255542180dd 100644\n--- a/src/planner/binder/expression/bind_unpacked_star_expression.cpp\n+++ b/src/planner/binder/expression/bind_unpacked_star_expression.cpp\n@@ -50,6 +50,23 @@ static void ReplaceInFunction(unique_ptr<ParsedExpression> &expr, expression_lis\n static void ReplaceInOperator(unique_ptr<ParsedExpression> &expr, expression_list_t &star_list) {\n \tauto &operator_expr = expr->Cast<OperatorExpression>();\n \n+\tvector<ExpressionType> allowed_types({\n+\t    ExpressionType::OPERATOR_COALESCE,\n+\t    ExpressionType::COMPARE_IN,\n+\t    ExpressionType::COMPARE_NOT_IN,\n+\t});\n+\tbool allowed = false;\n+\tfor (idx_t i = 0; i < allowed_types.size() && !allowed; i++) {\n+\t\tauto &type = allowed_types[i];\n+\t\tif (operator_expr.type == type) {\n+\t\t\tallowed = true;\n+\t\t}\n+\t}\n+\tif (!allowed) {\n+\t\tthrow BinderException(\"*COLUMNS() can not be used together with the '%s' operator\",\n+\t\t                      EnumUtil::ToString(operator_expr.type));\n+\t}\n+\n \t// Replace children\n \texpression_list_t new_children;\n \tfor (auto &child : operator_expr.children) {\n", "test_patch": "diff --git a/test/fuzzer/fuzz_not_unpacked_columns.test b/test/fuzzer/fuzz_not_unpacked_columns.test\nnew file mode 100644\nindex 000000000000..29e3206c8d58\n--- /dev/null\n+++ b/test/fuzzer/fuzz_not_unpacked_columns.test\n@@ -0,0 +1,40 @@\n+# name: test/fuzzer/fuzz_not_unpacked_columns.test\n+# group: [fuzzer]\n+\n+statement ok\n+CREATE TABLE v00 (c01 INT, c02 STRING);\n+\n+statement error\n+SELECT NOT (*COLUMNS(*)) FROM v00;\n+----\n+Binder Error: *COLUMNS() can not be used together with the 'OPERATOR_NOT' operator\n+\n+statement error\n+SELECT (*COLUMNS(*) IS NOT NULL) FROM v00;\n+----\n+Binder Error: *COLUMNS() can not be used together with the 'OPERATOR_IS_NOT_NULL' operator\n+\n+statement error\n+SELECT (*COLUMNS(*) IS NULL) FROM v00;\n+----\n+Binder Error: *COLUMNS() can not be used together with the 'OPERATOR_IS_NULL' operator\n+\n+statement error\n+SELECT (*COLUMNS(*))[2] FROM v00;\n+----\n+Binder Error: *COLUMNS() can not be used together with the 'ARRAY_EXTRACT' operator\n+\n+statement error\n+SELECT (*COLUMNS(*))[2:1:0] FROM v00;\n+----\n+Binder Error: *COLUMNS() can not be used together with the 'ARRAY_SLICE' operator\n+\n+statement error\n+SELECT (*COLUMNS(*)).a FROM v00;\n+----\n+Binder Error: *COLUMNS() can not be used together with the 'STRUCT_EXTRACT' operator\n+\n+statement error\n+SELECT construct_array(*COLUMNS(*)) FROM v00;\n+----\n+Binder Error: *COLUMNS() can not be used together with the 'ARRAY_CONSTRUCTOR' operator\n", "problem_statement": "DuckDB triggers Assertion Failure: children.size() == 1\n### What happens?\n\nThe latest version of the DuckDB (latest main: v1.1.4-dev3139 07780a0d22) triggers Assertion Failure when running the following SQL statement: \r\n\r\n```sql\r\nCREATE TABLE v00 (c01 INT, c02 STRING); -- Both columns are required. \r\nPIVOT any_name : ( v00 AS ta5200 NATURAL JOIN v00 AS ta10801 ) ON CASE 'string' WHEN 'string' % c01 THEN NOT * COLUMNS ( * RENAME ( XMLPARSE AS any_name ) ) ->> 'string' END;\r\n```\r\n\r\nThis error is only reproducible when compiling DuckDB with assertions turned on, e.g., compiled with `make relassert`. The code seems to work properly with released builds and non-assert builds. Just a faulty assertion?\r\n\r\nThe stack trace for the assertion failure (v1.1.4-dev3139 07780a0d22) is: \r\n\r\n```\r\n#0  duckdb::InternalException::InternalException (this=0x60d0000074f0, Python Exception <class 'gdb.error'> There is no member named _M_dataplus.: \r\nmsg=) at /home/duckdb/duckdb/src/common/exception.cpp:333\r\n#1  0x000000000202e0ea in duckdb::InternalException::InternalException<char const*, int, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > (this=0x60d0000074f0, msg=..., params=<incomplete type>, params=<incomplete type>, params=<incomplete type>, \r\n    params=<incomplete type>) at ../../src/include/duckdb/common/exception.hpp:313\r\n#2  0x0000000001de7c50 in duckdb::DuckDBAssertInternal (condition=<optimized out>, condition_name=<optimized out>, file=<optimized out>, \r\n    linenr=<optimized out>) at /home/duckdb/duckdb/src/common/assert.cpp:13\r\n#3  0x00000000059f15b6 in duckdb::ExpressionBinder::ResolveNotType (this=0x7fff041ccc50, op=..., children=...)\r\n    at /home/duckdb/duckdb/src/planner/binder/expression/bind_operator_expression.cpp:16\r\n#4  0x00000000059f5806 in duckdb::ExpressionBinder::ResolveOperatorType (this=<optimized out>, op=..., children=...)\r\n    at /home/duckdb/duckdb/src/planner/binder/expression/bind_operator_expression.cpp:77\r\n#5  0x00000000059df531 in duckdb::ExpressionBinder::BindExpression (this=0x7fff041ccc50, op=..., depth=<optimized out>)\r\n    at /home/duckdb/duckdb/src/planner/binder/expression/bind_operator_expression.cpp:183\r\n#6  0x0000000005f8efd8 in duckdb::ExpressionBinder::BindExpression (this=0x7fff041ccc50, expr=..., depth=<optimized out>, root_expression=<optimized out>)\r\n    at /home/duckdb/duckdb/src/planner/expression_binder.cpp:94\r\n#7  0x0000000005e4d929 in duckdb::WhereBinder::BindExpression (this=0x7fff041ccc50, expr_ptr=..., depth=<optimized out>, root_expression=<optimized out>)\r\n    at /home/duckdb/duckdb/src/planner/expression_binder/where_binder.cpp:38\r\n#8  0x0000000005f94308 in duckdb::ExpressionBinder::Bind (this=0x7fff041ccc50, expr=..., depth=<optimized out>, root_expression=<optimized out>)\r\n    at /home/duckdb/duckdb/src/planner/expression_binder.cpp:365\r\n#9  0x0000000005f95f5f in duckdb::ExpressionBinder::BindChild (this=0x7fff041ccc50, expr=..., depth=<optimized out>, error=...)\r\n    at /home/duckdb/duckdb/src/planner/expression_binder.cpp:223\r\n#10 0x00000000059c3967 in duckdb::ExpressionBinder::BindFunction (this=0x7fff041ccc50, function=..., func=..., depth=<optimized out>)\r\n    at /home/duckdb/duckdb/src/planner/binder/expression/bind_function_expression.cpp:110\r\n#11 0x00000000059c11fb in duckdb::ExpressionBinder::BindExpression (this=0x7fff041ccc50, function=..., depth=<optimized out>, expr_ptr=...)\r\n    at /home/duckdb/duckdb/src/planner/binder/expression/bind_function_expression.cpp:93\r\n#12 0x0000000005f90847 in duckdb::ExpressionBinder::BindExpression (this=0x7fff041ccc50, expr=..., depth=<optimized out>, root_expression=<optimized out>)\r\n    at /home/duckdb/duckdb/src/planner/expression_binder.cpp:89\r\n#13 0x0000000005e4d929 in duckdb::WhereBinder::BindExpression (this=0x7fff041ccc50, expr_ptr=..., depth=<optimized out>, root_expression=<optimized out>)\r\n    at /home/duckdb/duckdb/src/planner/expression_binder/where_binder.cpp:38\r\n#14 0x0000000005f94308 in duckdb::ExpressionBinder::Bind (this=0x7fff041ccc50, expr=..., depth=<optimized out>, root_expression=<optimized out>)\r\n    at /home/duckdb/duckdb/src/planner/expression_binder.cpp:365\r\n#15 0x0000000005f95f5f in duckdb::ExpressionBinder::BindChild (this=0x7fff041ccc50, expr=..., depth=<optimized out>, error=...)\r\n    at /home/duckdb/duckdb/src/planner/expression_binder.cpp:223\r\n#16 0x0000000005990d00 in duckdb::ExpressionBinder::BindExpression (this=0x7fff041ccc50, expr=..., depth=<optimized out>)\r\n    at /home/duckdb/duckdb/src/planner/binder/expression/bind_case_expression.cpp:14\r\n#17 0x0000000005f8e6d3 in duckdb::ExpressionBinder::BindExpression (this=0x7fff041ccc50, expr=..., depth=<optimized out>, root_expression=<optimized out>)\r\n    at /home/duckdb/duckdb/src/planner/expression_binder.cpp:67\r\n#18 0x0000000005e4d929 in duckdb::WhereBinder::BindExpression (this=0x7fff041ccc50, expr_ptr=..., depth=<optimized out>, root_expression=<optimized out>)\r\n    at /home/duckdb/duckdb/src/planner/expression_binder/where_binder.cpp:38\r\n#19 0x0000000005f94308 in duckdb::ExpressionBinder::Bind (this=0x7fff041ccc50, expr=..., depth=<optimized out>, root_expression=<optimized out>)\r\n    at /home/duckdb/duckdb/src/planner/expression_binder.cpp:365\r\n#20 0x0000000005f95f5f in duckdb::ExpressionBinder::BindChild (this=0x7fff041ccc50, expr=..., depth=<optimized out>, error=...)\r\n    at /home/duckdb/duckdb/src/planner/expression_binder.cpp:223\r\n#21 0x00000000059dba66 in duckdb::ExpressionBinder::BindExpression (this=0x7fff041ccc50, op=..., depth=<optimized out>)\r\n    at /home/duckdb/duckdb/src/planner/binder/expression/bind_operator_expression.cpp:96\r\n#22 0x0000000005f8efd8 in duckdb::ExpressionBinder::BindExpression (this=0x7fff041ccc50, expr=..., depth=<optimized out>, root_expression=<optimized out>)\r\n    at /home/duckdb/duckdb/src/planner/expression_binder.cpp:94\r\n#23 0x0000000005e4d929 in duckdb::WhereBinder::BindExpression (this=0x7fff041ccc50, expr_ptr=..., depth=<optimized out>, root_expression=<optimized out>)\r\n    at /home/duckdb/duckdb/src/planner/expression_binder/where_binder.cpp:38\r\n#24 0x0000000005f94308 in duckdb::ExpressionBinder::Bind (this=0x7fff041ccc50, expr=..., depth=<optimized out>, root_expression=<optimized out>)\r\n    at /home/duckdb/duckdb/src/planner/expression_binder.cpp:365\r\n#25 0x0000000005f9ab7e in duckdb::ExpressionBinder::Bind (this=<optimized out>, expr=..., result_type=..., root_expression=<optimized out>)\r\n    at /home/duckdb/duckdb/src/planner/expression_binder.cpp:317\r\n#26 0x000000000ad369cd in duckdb::Binder::BindSelectNode (this=0x61900000a580, statement=..., from_table=...)\r\n    at /home/duckdb/duckdb/src/planner/binder/query_node/bind_select_node.cpp:456\r\n#27 0x000000000ad32f35 in duckdb::Binder::BindNode (this=<optimized out>, statement=...)\r\n    at /home/duckdb/duckdb/src/planner/binder/query_node/bind_select_node.cpp:373\r\n#28 0x0000000005fc0f1d in duckdb::Binder::BindNode (this=0x61900000a580, node=...) at /home/duckdb/duckdb/src/planner/binder.cpp:328\r\n#29 0x0000000005fc2483 in duckdb::Binder::Bind (this=0x61900000a580, node=...) at /home/duckdb/duckdb/src/planner/binder.cpp:365\r\n#30 0x0000000005ac79f8 in duckdb::Binder::Bind (this=0x61900000a580, stmt=...) at /home/duckdb/duckdb/src/planner/binder/statement/bind_select.cpp:11\r\n#31 0x0000000005fb5d0a in duckdb::Binder::Bind (this=<optimized out>, statement=...) at /home/duckdb/duckdb/src/planner/binder.cpp:150\r\n#32 0x0000000005b1f60a in duckdb::Binder::Bind (this=0x61900000a580, stmt=...) at /home/duckdb/duckdb/src/planner/binder/statement/bind_create.cpp:737\r\n#33 0x0000000005fb7867 in duckdb::Binder::Bind (this=<optimized out>, statement=...) at /home/duckdb/duckdb/src/planner/binder.cpp:162\r\n#34 0x000000000600a2cc in duckdb::Planner::CreatePlan (this=0x7fff041d03b0, statement=...) at /home/duckdb/duckdb/src/planner/planner.cpp:43\r\n#35 0x0000000006013453 in duckdb::Planner::CreatePlan (this=0x60d0000074f0, statement=...) at /home/duckdb/duckdb/src/planner/planner.cpp:142\r\n#36 0x00000000033b510c in duckdb::ClientContext::CreatePreparedStatementInternal (this=0x616000074790, lock=..., query=..., statement=..., values=...)\r\n    at /home/duckdb/duckdb/src/main/client_context.cpp:340\r\n#37 0x00000000033bb6d4 in duckdb::ClientContext::CreatePreparedStatement (this=0x616000074790, lock=..., query=..., statement=..., values=..., \r\n    mode=<optimized out>) at /home/duckdb/duckdb/src/main/client_context.cpp:426\r\n#38 0x00000000033dd73a in duckdb::ClientContext::PendingStatementInternal (this=0x616000074790, lock=..., query=..., statement=..., parameters=...)\r\n    at /home/duckdb/duckdb/src/main/client_context.cpp:745\r\n#39 0x00000000033ea364 in duckdb::ClientContext::PendingStatementOrPreparedStatement (this=0x616000074790, lock=..., query=..., statement=..., \r\n    prepared=..., parameters=...) at /home/duckdb/duckdb/src/main/client_context.cpp:863\r\n#40 0x00000000033d8e48 in duckdb::ClientContext::PendingStatementOrPreparedStatementInternal (this=0x616000074790, lock=..., query=..., statement=..., \r\n    prepared=..., parameters=...) at /home/duckdb/duckdb/src/main/client_context.cpp:837\r\n#41 0x00000000033e0b9b in duckdb::ClientContext::PendingQueryInternal (this=0x616000074790, lock=..., statement=..., parameters=..., verify=<optimized out>)\r\n    at /home/duckdb/duckdb/src/main/client_context.cpp:1054\r\n#42 0x00000000033f6c5e in duckdb::ClientContext::PendingQuery (this=0x616000074790, statement=..., values=..., allow_stream_result=<optimized out>)\r\n    at /home/duckdb/duckdb/src/main/client_context.cpp:1041\r\n#43 0x00000000033ee170 in duckdb::ClientContext::PendingQuery (this=0x616000074790, statement=..., allow_stream_result=<optimized out>)\r\n    at /home/duckdb/duckdb/src/main/client_context.cpp:1001\r\n#44 0x00000000033ed1d4 in duckdb::ClientContext::Query (this=0x7fff041c84e0, statement=..., allow_stream_result=<optimized out>)\r\n    at /home/duckdb/duckdb/src/main/client_context.cpp:914\r\n#45 0x000000000343c45d in duckdb::Connection::Query (this=<optimized out>, statement=...) at /home/duckdb/duckdb/src/main/connection.cpp:130\r\n#46 0x000000000070493f in duckdb_shell_sqlite3_prepare_v2 (db=0x60f000000a90, zSql=<optimized out>, nByte=<optimized out>, ppStmt=<optimized out>, \r\n    pzTail=<optimized out>) at ../../tools/sqlite3_api_wrapper/sqlite3_api_wrapper.cpp:201\r\n#47 0x000000000066d9e6 in duckdb_shell::ShellState::ExecuteSQL (this=0x7fff041d2cc0, \r\n    zSql=0x6120000a4ec0 \"PIVOT any_name : ( v00 AS ta5200 NATURAL JOIN v00 AS ta10801 ) ON CASE 'string' WHEN 'string' % c01 THEN NOT * COLUMNS ( * RENAME ( XMLPARSE AS any_name ) ) ->> 'string' END;\", pzErrMsg=<optimized out>) at ../../tools/shell/shell.cpp:3524\r\n#48 0x0000000000698f43 in duckdb_shell::ShellState::RunOneSqlLine (this=<optimized out>, zSql=<optimized out>) at ../../tools/shell/shell.cpp:8706\r\n#49 0x000000000068e530 in duckdb_shell::ShellState::ProcessInput (this=0x7fff041d2cc0) at ../../tools/shell/shell.cpp:8936\r\n#50 0x000000000069f1ad in main (argc=<optimized out>, argv=<optimized out>) at ../../tools/shell/shell.cpp:10152\r\n```\n\n### To Reproduce\n\n1. Clone the DuckDB Git from the official repo.\r\n2. Checkout to the latest main (v1.1.4-dev3139 07780a0d22).\r\n3. Compile the DuckDB binary by using `make relassert`. The assertion must be turned on. \r\n4. Run the compiled DuckDB and input the following SQL:\r\n\r\n```sql\r\nCREATE TABLE v00 (c01 INT, c02 STRING); -- Both columns are required. \r\nPIVOT any_name : ( v00 AS ta5200 NATURAL JOIN v00 AS ta10801 ) ON CASE 'string' WHEN 'string' % c01 THEN NOT * COLUMNS ( * RENAME ( XMLPARSE AS any_name ) ) ->> 'string' END;\r\n```\n\n### OS:\n\nUbuntu 24.04 LTS\n\n### DuckDB Version:\n\nv1.1.4-dev3139 07780a0d22\n\n### DuckDB Client:\n\ncli\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nYu Liang\n\n### Affiliation:\n\nThe Pennsylvania State Univeristy\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a source build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [X] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [X] Yes, I have\n", "hints_text": "", "created_at": "2025-01-03T09:43:59Z"}
{"repo": "duckdb/duckdb", "pull_number": 15531, "instance_id": "duckdb__duckdb-15531", "issue_numbers": ["15465"], "base_commit": "6c4d2a394ff166af23cfd9be499d96f2b1bfb0de", "patch": "diff --git a/src/common/vector_operations/comparison_operators.cpp b/src/common/vector_operations/comparison_operators.cpp\nindex 8a56cdfc3b59..9c5c3d662d09 100644\n--- a/src/common/vector_operations/comparison_operators.cpp\n+++ b/src/common/vector_operations/comparison_operators.cpp\n@@ -223,7 +223,8 @@ struct ComparisonExecutor {\n public:\n \ttemplate <class OP>\n \tstatic inline void Execute(Vector &left, Vector &right, Vector &result, idx_t count) {\n-\t\tD_ASSERT(left.GetType() == right.GetType() && result.GetType() == LogicalType::BOOLEAN);\n+\t\tD_ASSERT(left.GetType().InternalType() == right.GetType().InternalType() &&\n+\t\t         result.GetType() == LogicalType::BOOLEAN);\n \t\t// the inplace loops take the result as the last parameter\n \t\tswitch (left.GetType().InternalType()) {\n \t\tcase PhysicalType::BOOL:\ndiff --git a/src/parser/transform/tableref/transform_pivot.cpp b/src/parser/transform/tableref/transform_pivot.cpp\nindex 3a51ba0f7bcd..d042d881d3c1 100644\n--- a/src/parser/transform/tableref/transform_pivot.cpp\n+++ b/src/parser/transform/tableref/transform_pivot.cpp\n@@ -73,6 +73,7 @@ PivotColumn Transformer::TransformPivotColumn(duckdb_libpgquery::PGPivot &pivot,\n \t\t\t\t\t                      \"PIVOT IN list must contain columns or lists of columns\");\n \t\t\t\t} else {\n \t\t\t\t\t// for unpivot - we can forward the expression immediately\n+\t\t\t\t\tentry.values.clear();\n \t\t\t\t\tentry.expr = std::move(expr);\n \t\t\t\t}\n \t\t\t}\ndiff --git a/src/planner/bind_context.cpp b/src/planner/bind_context.cpp\nindex 58ddbaac63d9..d135ed2ae604 100644\n--- a/src/planner/bind_context.cpp\n+++ b/src/planner/bind_context.cpp\n@@ -695,14 +695,6 @@ void BindContext::AddContext(BindContext other) {\n \t}\n \tfor (auto &entry : other.using_columns) {\n \t\tfor (auto &alias : entry.second) {\n-#ifdef DEBUG\n-\t\t\tfor (auto &other_alias : using_columns[entry.first]) {\n-\t\t\t\tfor (auto &col : alias.get().bindings) {\n-\t\t\t\t\tD_ASSERT(std::find(other_alias.get().bindings.begin(), other_alias.get().bindings.end(), col) ==\n-\t\t\t\t\t         other_alias.get().bindings.end());\n-\t\t\t\t}\n-\t\t\t}\n-#endif\n \t\t\tusing_columns[entry.first].insert(alias);\n \t\t}\n \t}\n@@ -719,22 +711,22 @@ vector<BindingAlias> BindContext::GetBindingAliases() {\n void BindContext::RemoveContext(const vector<BindingAlias> &aliases) {\n \tfor (auto &alias : aliases) {\n \t\t// remove the binding from any USING columns\n+\t\tvector<string> removed_using_columns;\n \t\tfor (auto &using_sets : using_columns) {\n \t\t\tfor (auto &using_set_ref : using_sets.second) {\n \t\t\t\tauto &using_set = using_set_ref.get();\n \t\t\t\tauto it = std::remove_if(using_set.bindings.begin(), using_set.bindings.end(),\n \t\t\t\t                         [&](const BindingAlias &using_alias) { return using_alias == alias; });\n \t\t\t\tusing_set.bindings.erase(it, using_set.bindings.end());\n-\t\t\t\tif (using_set.bindings.empty()) {\n-\t\t\t\t\tthrow InternalException(\n-\t\t\t\t\t    \"BindContext::RemoveContext - no more tables that refer to this using binding\");\n-\t\t\t\t}\n-\t\t\t\tif (using_set.primary_binding == alias) {\n-\t\t\t\t\tthrow InternalException(\n-\t\t\t\t\t    \"BindContext::RemoveContext - cannot remove primary binding from using binding\");\n+\t\t\t\tif (using_set.bindings.empty() || using_set.primary_binding == alias) {\n+\t\t\t\t\t// if the using column is no longer referred to - remove it entirely\n+\t\t\t\t\tremoved_using_columns.push_back(using_sets.first);\n \t\t\t\t}\n \t\t\t}\n \t\t}\n+\t\tfor (auto &removed_col : removed_using_columns) {\n+\t\t\tusing_columns.erase(removed_col);\n+\t\t}\n \n \t\t// remove the binding from the list of bindings\n \t\tauto it = std::remove_if(bindings_list.begin(), bindings_list.end(),\ndiff --git a/src/planner/binder/expression/bind_window_expression.cpp b/src/planner/binder/expression/bind_window_expression.cpp\nindex 7fcf96e69ade..72a6c4be2c32 100644\n--- a/src/planner/binder/expression/bind_window_expression.cpp\n+++ b/src/planner/binder/expression/bind_window_expression.cpp\n@@ -155,7 +155,7 @@ BindResult BaseSelectBinder::BindWindow(WindowExpression &window, idx_t depth) {\n \t\treturn BindMacro(*macro, entry->Cast<ScalarMacroCatalogEntry>(), depth, macro_expr);\n \t}\n \n-\tauto name = window.GetName();\n+\tauto name = window.alias;\n \n \tif (inside_window) {\n \t\tthrow BinderException(error_context, \"window function calls cannot be nested\");\ndiff --git a/src/planner/binder/statement/bind_vacuum.cpp b/src/planner/binder/statement/bind_vacuum.cpp\nindex 34b0ec56eb79..93e70fe5b8be 100644\n--- a/src/planner/binder/statement/bind_vacuum.cpp\n+++ b/src/planner/binder/statement/bind_vacuum.cpp\n@@ -27,8 +27,9 @@ void Binder::BindVacuumTable(LogicalVacuum &vacuum, unique_ptr<LogicalOperator>\n \tauto &columns = info.columns;\n \tif (columns.empty()) {\n \t\t// Empty means ALL columns should be vacuumed/analyzed\n-\t\tauto &get = ref->get->Cast<LogicalGet>();\n-\t\tcolumns.insert(columns.end(), get.names.begin(), get.names.end());\n+\t\tfor (auto &col : table.GetColumns().Physical()) {\n+\t\t\tcolumns.push_back(col.GetName());\n+\t\t}\n \t}\n \n \tcase_insensitive_set_t column_name_set;\n@@ -45,7 +46,9 @@ void Binder::BindVacuumTable(LogicalVacuum &vacuum, unique_ptr<LogicalOperator>\n \t\tauto &col = table.GetColumn(col_name);\n \t\t// ignore generated column\n \t\tif (col.Generated()) {\n-\t\t\tcontinue;\n+\t\t\tthrow BinderException(\n+\t\t\t    \"cannot vacuum or analyze generated column \\\"%s\\\" - specify non-generated columns to vacuum or analyze\",\n+\t\t\t    col.GetName());\n \t\t}\n \t\tnon_generated_column_names.push_back(col_name);\n \t\tColumnRefExpression colref(col_name, table.name);\n@@ -56,8 +59,6 @@ void Binder::BindVacuumTable(LogicalVacuum &vacuum, unique_ptr<LogicalOperator>\n \t\tselect_list.push_back(std::move(result.expression));\n \t}\n \tinfo.columns = std::move(non_generated_column_names);\n-\t// Creating a table without any physical columns is not supported\n-\tD_ASSERT(!select_list.empty());\n \n \tauto table_scan = CreatePlan(*ref);\n \tD_ASSERT(table_scan->type == LogicalOperatorType::LOGICAL_GET);\ndiff --git a/src/planner/subquery/flatten_dependent_join.cpp b/src/planner/subquery/flatten_dependent_join.cpp\nindex af79baa83e8b..a297a7855dae 100644\n--- a/src/planner/subquery/flatten_dependent_join.cpp\n+++ b/src/planner/subquery/flatten_dependent_join.cpp\n@@ -414,7 +414,7 @@ unique_ptr<LogicalOperator> FlattenDependentJoins::PushDownDependentJoinInternal\n \t\t\t\treturn plan;\n \t\t\t}\n \t\t} else if (join.join_type == JoinType::RIGHT) {\n-\t\t\t// left outer join\n+\t\t\t// right outer join\n \t\t\tif (!left_has_correlation) {\n \t\t\t\t// only right has correlation: push into right\n \t\t\t\tplan->children[1] = PushDownDependentJoinInternal(std::move(plan->children[1]),\n@@ -450,6 +450,7 @@ unique_ptr<LogicalOperator> FlattenDependentJoins::PushDownDependentJoinInternal\n \t\t\tthis->base_binding = left_binding;\n \t\t} else if (join.join_type == JoinType::RIGHT) {\n \t\t\tthis->base_binding = right_binding;\n+\t\t\tdelim_offset += plan->children[0]->GetColumnBindings().size();\n \t\t}\n \t\t// add the correlated columns to the join conditions\n \t\tfor (idx_t i = 0; i < correlated_columns.size(); i++) {\ndiff --git a/tools/shell/shell.cpp b/tools/shell/shell.cpp\nindex 911d8efebdb1..024db0db922c 100644\n--- a/tools/shell/shell.cpp\n+++ b/tools/shell/shell.cpp\n@@ -1772,6 +1772,17 @@ int ShellState::ExecuteSQL(const char *zSql, /* SQL to be evaluated */\n \t\t\t\t\tzSql++;\n \t\t\t\tcontinue;\n \t\t\t}\n+\t\t\tif (sqlite3_bind_parameter_count(pStmt) != 0) {\n+\t\t\t\tzSql = zLeftover;\n+\t\t\t\twhile (IsSpace(zSql[0]))\n+\t\t\t\t\tzSql++;\n+\t\t\t\tif (pzErrMsg) {\n+\t\t\t\t\t*pzErrMsg = strdup(\"Prepared statement parameters cannot be used directly\\nTo use prepared \"\n+\t\t\t\t\t                   \"statement parameters, use PREPARE to prepare a statement, followed by EXECUTE\");\n+\t\t\t\t}\n+\t\t\t\tsqlite3_finalize(pStmt);\n+\t\t\t\tcontinue;\n+\t\t\t}\n \t\t\tzStmtSql = sqlite3_sql(pStmt);\n \t\t\tif (zStmtSql == 0)\n \t\t\t\tzStmtSql = \"\";\ndiff --git a/tools/sqlite3_api_wrapper/sqlite3_api_wrapper.cpp b/tools/sqlite3_api_wrapper/sqlite3_api_wrapper.cpp\nindex b9b7529249a9..8e8fee65e70a 100644\n--- a/tools/sqlite3_api_wrapper/sqlite3_api_wrapper.cpp\n+++ b/tools/sqlite3_api_wrapper/sqlite3_api_wrapper.cpp\n@@ -264,7 +264,6 @@ void sqlite3_print_duckbox(sqlite3_stmt *pStmt, size_t max_rows, size_t max_widt\n \t\t\tpStmt->db->last_error = ErrorData(\"Statement has already been executed\");\n \t\t\treturn;\n \t\t}\n-\n \t\tif (pStmt->prepared) {\n \t\t\tpStmt->result = pStmt->prepared->Execute(pStmt->bound_values, false);\n \t\t} else if (pStmt->pending) {\n", "test_patch": "diff --git a/test/fuzzer/pedro/vacuum_table_with_generated_column.test b/test/fuzzer/pedro/vacuum_table_with_generated_column.test\nindex 98f1a09224cf..10959d2bd79f 100644\n--- a/test/fuzzer/pedro/vacuum_table_with_generated_column.test\n+++ b/test/fuzzer/pedro/vacuum_table_with_generated_column.test\n@@ -18,8 +18,15 @@ ANALYZE test(x, x);\n ----\n <REGEX>:Binder Error.*cannot vacuum.*the same column twice.*\n \n-statement ok\n+statement error\n+ANALYZE test(y);\n+----\n+cannot vacuum or analyze generated column \"y\"\n+\n+statement error\n ANALYZE test(y, x);\n+----\n+cannot vacuum or analyze generated column \"y\"\n \n statement ok\n INSERT INTO test SELECT range % 5000 FROM range(10000);\n@@ -38,6 +45,9 @@ SELECT stats(y) FROM test LIMIT 1;\n statement ok\n PRAGMA verify_parallelism;\n \n+statement ok\n+ANALYZE test\n+\n statement ok\n ANALYZE test(x);\n \ndiff --git a/test/fuzzer/public/duplicate_alias_using.test b/test/fuzzer/public/duplicate_alias_using.test\nnew file mode 100644\nindex 000000000000..4d1c3c22a79e\n--- /dev/null\n+++ b/test/fuzzer/public/duplicate_alias_using.test\n@@ -0,0 +1,16 @@\n+# name: test/fuzzer/public/duplicate_alias_using.test\n+# description: Duplicate alias in USING\n+# group: [public]\n+\n+statement ok\n+pragma enable_verification\n+\n+statement ok\n+CREATE TABLE t1 (c1 INT);\n+\n+statement error\n+SELECT c1\n+FROM t1 AS same_alias JOIN t1 AS same_alias2 USING (c1),\n+     t1 AS same_alias JOIN t1 AS same_alias2 USING (c1);\n+----\n+Ambiguous\ndiff --git a/test/fuzzer/public/lateral_right_join.test b/test/fuzzer/public/lateral_right_join.test\nnew file mode 100644\nindex 000000000000..3b86215899c9\n--- /dev/null\n+++ b/test/fuzzer/public/lateral_right_join.test\n@@ -0,0 +1,22 @@\n+# name: test/fuzzer/public/lateral_right_join.test\n+# description: Lateral join followed by a right join\n+# group: [public]\n+\n+statement ok\n+pragma enable_verification\n+\n+statement ok\n+CREATE TABLE tbl (c01 INT, c02 VARCHAR);\n+\n+statement ok\n+INSERT INTO tbl (c01, c02) VALUES (0, 'abc');\n+\n+query IIIIII\n+SELECT * FROM tbl, LATERAL (SELECT tbl.c01 AS lat_c01) AS subq CROSS JOIN tbl AS t1 RIGHT JOIN tbl AS t2 USING (c02);\n+----\n+0\tabc\t0\t0\tabc\t0\n+\n+query IIIII\n+SELECT * FROM tbl, LATERAL (SELECT tbl.c01 AS lat_c01) AS subq CROSS JOIN tbl AS t1 RIGHT JOIN tbl AS t2 USING (c02, c01);\n+----\n+0\tabc\t0\t0\tabc\ndiff --git a/test/fuzzer/public/regex_range_filter_mismatch.test b/test/fuzzer/public/regex_range_filter_mismatch.test\nnew file mode 100644\nindex 000000000000..d7203f62f9b8\n--- /dev/null\n+++ b/test/fuzzer/public/regex_range_filter_mismatch.test\n@@ -0,0 +1,13 @@\n+# name: test/fuzzer/public/regex_range_filter_mismatch.test\n+# description: Type mismatch in regex range filter optimizer\n+# group: [public]\n+\n+statement ok\n+pragma enable_verification\n+\n+statement ok\n+CREATE TABLE v00 ( c01 INTEGER ) ;\n+\n+query I\n+SELECT * FROM v00 WHERE concat(c01 IS NOT NULL, 'string') SIMILAR TO 'string';\n+----\ndiff --git a/test/fuzzer/public/semi_anti_join_using.test b/test/fuzzer/public/semi_anti_join_using.test\nnew file mode 100644\nindex 000000000000..d925080f7a02\n--- /dev/null\n+++ b/test/fuzzer/public/semi_anti_join_using.test\n@@ -0,0 +1,21 @@\n+# name: test/fuzzer/public/semi_anti_join_using.test\n+# description: Test semi/anti join in combination with USING columns\n+# group: [public]\n+\n+statement ok\n+pragma enable_verification\n+\n+statement ok\n+CREATE TABLE v00 (c01 INT);\n+\n+statement ok\n+INSERT INTO v00 VALUES (42);\n+\n+query I\n+SELECT c01 FROM ( v00 AS ta03 SEMI JOIN ( v00 AS ta04 JOIN v00 AS ta05 USING ( c01 ) ) ON 42 ) ;\n+----\n+42\n+\n+query I\n+SELECT c01 FROM ( v00 AS ta03 ANTI JOIN ( v00 AS ta04 JOIN v00 AS ta05 USING ( c01 ) ) ON 42 ) ;\n+----\ndiff --git a/test/fuzzer/public/unpivot_partial_values.test b/test/fuzzer/public/unpivot_partial_values.test\nnew file mode 100644\nindex 000000000000..1937f2bea8f9\n--- /dev/null\n+++ b/test/fuzzer/public/unpivot_partial_values.test\n@@ -0,0 +1,9 @@\n+# name: test/fuzzer/public/unpivot_partial_values.test\n+# description: Test UNPIVOT on a row that contains a mix of expressions and values\n+# group: [public]\n+\n+statement ok\n+pragma enable_verification\n+\n+statement ok\n+FROM (SELECT 42 c1) AS ta06 UNPIVOT (c1 FOR 'v' IN ( ( c1, 'a' || 'b' ) ) ) ;\ndiff --git a/test/fuzzer/public/window_subquery_error.test b/test/fuzzer/public/window_subquery_error.test\nnew file mode 100644\nindex 000000000000..12dc78c59c62\n--- /dev/null\n+++ b/test/fuzzer/public/window_subquery_error.test\n@@ -0,0 +1,14 @@\n+# name: test/fuzzer/public/window_subquery_error.test\n+# description: Test window function with a subquery that generates an error message\n+# group: [public]\n+\n+statement ok\n+pragma enable_verification\n+\n+statement ok\n+CREATE TABLE v00 (c01 INT, c02 STRING);\n+\n+statement error\n+SELECT 'string' IN ( SELECT string_agg ('str') OVER ( PARTITION BY c02 + 'string' IN ( SELECT 'string' )) );\n+----\n+correlated columns in window functions not supported\ndiff --git a/test/sql/vacuum/vacuum_nested_types.test b/test/sql/vacuum/vacuum_nested_types.test\nindex 5c8627983855..955fe69f47ea 100644\n--- a/test/sql/vacuum/vacuum_nested_types.test\n+++ b/test/sql/vacuum/vacuum_nested_types.test\n@@ -6,7 +6,7 @@ statement ok\n CREATE TABLE test (x INT[], y AS (x || [100]));\n \n statement ok\n-ANALYZE test(y, x);\n+ANALYZE test(x);\n \n statement ok\n INSERT INTO test SELECT [range % 5000] FROM range(10000);\ndiff --git a/tools/shell/tests/test_shell_basics.py b/tools/shell/tests/test_shell_basics.py\nindex 7cd0984e9407..f888d752ad64 100644\n--- a/tools/shell/tests/test_shell_basics.py\n+++ b/tools/shell/tests/test_shell_basics.py\n@@ -1035,4 +1035,10 @@ def test_decimal_sep(shell):\n     result.check_stdout(\"10.5\")\n     result.check_stdout(\"current decimal separator\")\n \n+def test_prepared_statement(shell):\n+    test = ShellTest(shell).statement(\"select ?\")\n+    result = test.run()\n+    result.check_stderr(\"Prepared statement parameters cannot be used directly\")\n+\n+\n # fmt: on\n", "problem_statement": "DuckDB Assertion Failure: comparison_operators.cpp on line 226: left.GetType() == right.GetType() && result.GetType() == LogicalType::BOOLEAN\n### What happens?\r\n\r\nThe latest version of the DuckDB (latest main: v1.1.4-dev3741 ab8c909857) triggers Assertion Failure when running the following SQL statement: \r\n\r\n```sql\r\nCREATE TABLE v00 ( c01 INT ) ;\r\nSELECT * FROM v00 WHERE c01 IS NOT NULL ->> 'string' SIMILAR TO 'string';\r\n```\r\n\r\nHere is the stack trace: \r\n\r\n```\r\ncomparison_operators.cpp on line 226: left.GetType() == right.GetType() && result.GetType() == LogicalType::BOOLEAN\r\n\r\n#0  duckdb::InternalException::InternalException (this=0x60d0000251e0, Python Exception <class 'gdb.error'> There is no member named _M_dataplus.:\r\nmsg=) at /home/duckdb/duckdb/src/common/exception.cpp:320\r\n#1  0x00000000020c1089 in duckdb::InternalException::InternalException<char const*, int, char const*> (this=0x60d0000251e0, msg=...,\r\n    params=<optimized out>, params=<optimized out>, params=<optimized out>) at ../../src/include/duckdb/common/exception.hpp:313\r\n#2  0x0000000001e672b1 in duckdb::DuckDBAssertInternal (condition=<optimized out>, condition_name=<optimized out>, file=<optimized out>,\r\n    linenr=<optimized out>) at /home/duckdb/duckdb/src/common/assert.cpp:13\r\n#3  0x0000000001b6ef0a in duckdb::ComparisonExecutor::Execute<duckdb::GreaterThanEquals> (left=..., right=..., result=..., count=<optimized out>)\r\n    at ../../src/common/vector_operations/comparison_operators.cpp:226\r\n#4  0x0000000002734cad in duckdb::ExpressionExecutor::Execute (this=0x7ffd491d6c00, expr=..., state=<optimized out>, sel=<optimized out>,\r\n    count=<optimized out>, result=...) at /home/duckdb/duckdb/src/execution/expression_executor/execute_comparison.cpp:49\r\n#5  0x00000000030afb5a in duckdb::ExpressionExecutor::Execute (this=0x7ffd491d6c00, expr=..., state=<optimized out>, sel=<optimized out>,\r\n    count=<optimized out>, result=...) at /home/duckdb/duckdb/src/execution/expression_executor.cpp:208\r\n#6  0x00000000030ace07 in duckdb::ExpressionExecutor::ExecuteExpression (this=<optimized out>, expr_idx=<optimized out>, result=...)\r\n    at /home/duckdb/duckdb/src/execution/expression_executor.cpp:102\r\n#7  0x00000000030ad61d in duckdb::ExpressionExecutor::ExecuteExpression (this=<optimized out>, result=...)\r\n    at /home/duckdb/duckdb/src/execution/expression_executor.cpp:96\r\n#8  0x00000000030b233e in duckdb::ExpressionExecutor::EvaluateScalar (context=..., expr=..., allow_unfoldable=<optimized out>)\r\n    at /home/duckdb/duckdb/src/execution/expression_executor.cpp:112\r\n#9  0x000000000b127756 in duckdb::StatisticsPropagator::PropagateExpression (this=0x7ffd491d8760, expr=..., expr_ptr=...)\r\n    at /home/duckdb/duckdb/src/optimizer/statistics/expression/propagate_conjunction.cpp:22\r\n#10 0x0000000005859520 in duckdb::StatisticsPropagator::PropagateExpression (this=0x7ffd491d8760, expr=..., expr_ptr=...)\r\n    at /home/duckdb/duckdb/src/optimizer/statistics_propagator.cpp:107\r\n#11 0x000000000585b415 in duckdb::StatisticsPropagator::PropagateExpression (this=0x7ffd491d8760, expr=...)\r\n    at /home/duckdb/duckdb/src/optimizer/statistics_propagator.cpp:128\r\n#12 0x000000000b148a40 in duckdb::StatisticsPropagator::PropagateStatistics (this=0x7ffd491d8760, filter=..., node_ptr=...)\r\n    at /home/duckdb/duckdb/src/optimizer/statistics/operator/propagate_filter.cpp:239\r\n#13 0x00000000058573b7 in duckdb::StatisticsPropagator::PropagateStatistics (this=0x7ffd491d8760, node=..., node_ptr=...)\r\n    at /home/duckdb/duckdb/src/optimizer/statistics_propagator.cpp:51\r\n#14 0x0000000005855e58 in duckdb::StatisticsPropagator::PropagateStatistics (this=0x7ffd491d8760, node_ptr=...)\r\n    at /home/duckdb/duckdb/src/optimizer/statistics_propagator.cpp:94\r\n#15 0x000000000b161e28 in duckdb::StatisticsPropagator::PropagateStatistics (this=0x7ffd491d8760, proj=..., node_ptr=...)\r\n    at /home/duckdb/duckdb/src/optimizer/statistics/operator/propagate_projection.cpp:9\r\n#16 0x000000000585716c in duckdb::StatisticsPropagator::PropagateStatistics (this=0x7ffd491d8760, node=..., node_ptr=...)\r\n    at /home/duckdb/duckdb/src/optimizer/statistics_propagator.cpp:57\r\n#17 0x0000000005855e58 in duckdb::StatisticsPropagator::PropagateStatistics (this=0x7ffd491d8760, node_ptr=...)\r\n    at /home/duckdb/duckdb/src/optimizer/statistics_propagator.cpp:94\r\n#18 0x000000000b1481f1 in duckdb::StatisticsPropagator::PropagateStatistics (this=0x7ffd491d8760, filter=..., node_ptr=...)\r\n    at /home/duckdb/duckdb/src/optimizer/statistics/operator/propagate_filter.cpp:230\r\n#19 0x00000000058573b7 in duckdb::StatisticsPropagator::PropagateStatistics (this=0x7ffd491d8760, node=..., node_ptr=...)\r\n    at /home/duckdb/duckdb/src/optimizer/statistics_propagator.cpp:51\r\n#20 0x0000000005855e58 in duckdb::StatisticsPropagator::PropagateStatistics (this=0x7ffd491d8760, node_ptr=...)\r\n    at /home/duckdb/duckdb/src/optimizer/statistics_propagator.cpp:94\r\n#21 0x000000000b161e28 in duckdb::StatisticsPropagator::PropagateStatistics (this=0x7ffd491d8760, proj=..., node_ptr=...)\r\n    at /home/duckdb/duckdb/src/optimizer/statistics/operator/propagate_projection.cpp:9\r\n#22 0x000000000585716c in duckdb::StatisticsPropagator::PropagateStatistics (this=0x7ffd491d8760, node=..., node_ptr=...)\r\n    at /home/duckdb/duckdb/src/optimizer/statistics_propagator.cpp:57\r\n#23 0x0000000005855e58 in duckdb::StatisticsPropagator::PropagateStatistics (this=0x7ffd491d8760, node_ptr=...)\r\n    at /home/duckdb/duckdb/src/optimizer/statistics_propagator.cpp:94\r\n#24 0x00000000058ceb31 in duckdb::Optimizer::RunBuiltInOptimizers()::$_31::operator()() const (this=0x7ffd491d91a0)\r\n    at /home/duckdb/duckdb/src/optimizer/optimizer.cpp:234\r\n#25 std::_Function_handler<void (), duckdb::Optimizer::RunBuiltInOptimizers()::$_31>::_M_invoke(std::_Any_data const&) (__functor=...) at /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/std_function.h:300\r\n#26 0x00000000058248e6 in duckdb::Optimizer::RunOptimizer(duckdb::OptimizerType, std::function<void ()> const&) (this=0x7ffd491d9840, type=<optimized out>, callback=...) at /home/duckdb/duckdb/src/optimizer/optimizer.cpp:89\r\n#27 0x0000000005829ee2 in duckdb::Optimizer::RunBuiltInOptimizers (this=<optimized out>) at /home/duckdb/duckdb/src/optimizer/optimizer.cpp:232\r\n#28 0x000000000582c57f in duckdb::Optimizer::Optimize (this=0x7ffd491d9840, plan_p=...) at /home/duckdb/duckdb/src/optimizer/optimizer.cpp:268\r\n#29 0x00000000035f3604 in duckdb::ClientContext::CreatePreparedStatementInternal (this=0x616000080190, lock=..., query=..., statement=..., values=...) at /home/duckdb/duckdb/src/main/client_context.cpp:363\r\n#30 0x00000000035f9584 in duckdb::ClientContext::CreatePreparedStatement (this=0x616000080190, lock=..., query=..., statement=..., values=..., mode=<optimized out>) at /home/duckdb/duckdb/src/main/client_context.cpp:430\r\n#31 0x000000000361b5ea in duckdb::ClientContext::PendingStatementInternal (this=0x616000080190, lock=..., query=..., statement=..., parameters=...) at /home/duckdb/duckdb/src/main/client_context.cpp:749\r\n#32 0x0000000003628214 in duckdb::ClientContext::PendingStatementOrPreparedStatement (this=0x616000080190, lock=..., query=..., statement=..., prepared=..., parameters=...) at /home/duckdb/duckdb/src/main/client_context.cpp:867\r\n#33 0x0000000003616cf8 in duckdb::ClientContext::PendingStatementOrPreparedStatementInternal (this=0x616000080190, lock=..., query=..., statement=..., prepared=..., parameters=...) at /home/duckdb/duckdb/src/main/client_context.cpp:841\r\n#34 0x000000000361ea4b in duckdb::ClientContext::PendingQueryInternal (this=0x616000080190, lock=..., statement=..., parameters=..., verify=<optimized out>) at /home/duckdb/duckdb/src/main/client_context.cpp:1058\r\n#35 0x0000000003634b0e in duckdb::ClientContext::PendingQuery (this=0x616000080190, statement=..., values=..., allow_stream_result=<optimized out>) at /home/duckdb/duckdb/src/main/client_context.cpp:1045\r\n#36 0x000000000362c020 in duckdb::ClientContext::PendingQuery (this=0x616000080190, statement=..., allow_stream_result=<optimized out>) at /home/duckdb/duckdb/src/main/client_context.cpp:1005\r\n#37 0x000000000367b5a8 in duckdb::Connection::PendingQuery (this=<optimized out>, statement=..., allow_stream_result=<optimized out>) at /home/duckdb/duckdb/src/main/connection.cpp:140\r\n#38 0x000000000071a344 in duckdb_shell_sqlite3_prepare_v2 (db=0x60f0000006d0, zSql=<optimized out>, nByte=<optimized out>, ppStmt=<optimized out>, pzTail=<optimized out>) at ../../tools/sqlite3_api_wrapper/sqlite3_api_wrapper.cpp:224\r\n#39 0x00000000006720f6 in duckdb_shell::ShellState::ExecuteSQL (this=0x7ffd491dbcc0, zSql=0x60d0000005f0 \"SELECT * FROM v00 WHERE c01 IS NOT NULL ->> 'string' SIMILAR TO 'string';\", pzErrMsg=<optimized out>) at ../../tools/shell/shell.cpp:3524\r\n#40 0x000000000069d6b3 in duckdb_shell::ShellState::RunOneSqlLine (this=<optimized out>, zSql=<optimized out>) at ../../tools/shell/shell.cpp:8706\r\n#41 0x0000000000692c74 in duckdb_shell::ShellState::ProcessInput (this=0x7ffd491dbcc0) at ../../tools/shell/shell.cpp:8936\r\n#42 0x00000000006a396d in main (argc=<optimized out>, argv=<optimized out>) at ../../tools/shell/shell.cpp:10152\r\n```\r\n\r\n### To Reproduce\r\n\r\n1. Clone the DuckDB Git from the official repo.\r\n2. Checkout to the latest main (v1.1.4-dev3741 ab8c909857).\r\n3. Compile the DuckDB binary by using `make debug`.\r\n4. Run the compiled DuckDB and input the following SQL: \r\n\r\n```sql\r\nCREATE TABLE v00 ( c01 INT ) ;\r\nSELECT * FROM v00 WHERE c01 IS NOT NULL ->> 'string' SIMILAR TO 'string';\r\n```\r\n\r\n### OS:\r\n\r\nUbuntu 24.04 LTS\r\n\r\n### DuckDB Version:\r\n\r\nv1.1.4-dev3741 ab8c909857\r\n\r\n### DuckDB Client:\r\n\r\ncli\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\nYu Liang\r\n\r\n### Affiliation:\r\n\r\nThe Pennsylvania State University\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a source build\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\n", "hints_text": "", "created_at": "2025-01-02T22:03:23Z"}
{"repo": "duckdb/duckdb", "pull_number": 15517, "instance_id": "duckdb__duckdb-15517", "issue_numbers": ["15428"], "base_commit": "30c80bb3111b2ac8db37d31d71e971d47768987c", "patch": "diff --git a/src/planner/binder/statement/bind_create.cpp b/src/planner/binder/statement/bind_create.cpp\nindex 5ebd56819ba1..156be1e5ddcf 100644\n--- a/src/planner/binder/statement/bind_create.cpp\n+++ b/src/planner/binder/statement/bind_create.cpp\n@@ -389,184 +389,6 @@ void Binder::BindLogicalType(LogicalType &type, optional_ptr<Catalog> catalog, c\n \t}\n }\n \n-static void FindMatchingPrimaryKeyColumns(const ColumnList &columns, const vector<unique_ptr<Constraint>> &constraints,\n-                                          ForeignKeyConstraint &fk) {\n-\t// find the matching primary key constraint\n-\tbool found_constraint = false;\n-\t// if no columns are defined, we will automatically try to bind to the primary key\n-\tbool find_primary_key = fk.pk_columns.empty();\n-\tfor (auto &constr : constraints) {\n-\t\tif (constr->type != ConstraintType::UNIQUE) {\n-\t\t\tcontinue;\n-\t\t}\n-\t\tauto &unique = constr->Cast<UniqueConstraint>();\n-\t\tif (find_primary_key && !unique.IsPrimaryKey()) {\n-\t\t\tcontinue;\n-\t\t}\n-\t\tfound_constraint = true;\n-\n-\t\tvector<string> pk_names;\n-\t\tif (unique.HasIndex()) {\n-\t\t\tpk_names.push_back(columns.GetColumn(LogicalIndex(unique.GetIndex())).Name());\n-\t\t} else {\n-\t\t\tpk_names = unique.GetColumnNames();\n-\t\t}\n-\t\tif (find_primary_key) {\n-\t\t\t// found matching primary key\n-\t\t\tif (pk_names.size() != fk.fk_columns.size()) {\n-\t\t\t\tauto pk_name_str = StringUtil::Join(pk_names, \",\");\n-\t\t\t\tauto fk_name_str = StringUtil::Join(fk.fk_columns, \",\");\n-\t\t\t\tthrow BinderException(\n-\t\t\t\t    \"Failed to create foreign key: number of referencing (%s) and referenced columns (%s) differ\",\n-\t\t\t\t    fk_name_str, pk_name_str);\n-\t\t\t}\n-\t\t\tfk.pk_columns = pk_names;\n-\t\t\treturn;\n-\t\t}\n-\t\tif (pk_names.size() != fk.fk_columns.size()) {\n-\t\t\t// the number of referencing and referenced columns for foreign keys must be the same\n-\t\t\tcontinue;\n-\t\t}\n-\t\tbool equals = true;\n-\t\tfor (idx_t i = 0; i < fk.pk_columns.size(); i++) {\n-\t\t\tif (!StringUtil::CIEquals(fk.pk_columns[i], pk_names[i])) {\n-\t\t\t\tequals = false;\n-\t\t\t\tbreak;\n-\t\t\t}\n-\t\t}\n-\t\tif (!equals) {\n-\t\t\tcontinue;\n-\t\t}\n-\t\t// found match\n-\t\treturn;\n-\t}\n-\t// no match found! examine why\n-\tif (!found_constraint) {\n-\t\t// no unique constraint or primary key\n-\t\tstring search_term = find_primary_key ? \"primary key\" : \"primary key or unique constraint\";\n-\t\tthrow BinderException(\"Failed to create foreign key: there is no %s for referenced table \\\"%s\\\"\", search_term,\n-\t\t                      fk.info.table);\n-\t}\n-\t// check if all the columns exist\n-\tfor (auto &name : fk.pk_columns) {\n-\t\tbool found = columns.ColumnExists(name);\n-\t\tif (!found) {\n-\t\t\tthrow BinderException(\n-\t\t\t    \"Failed to create foreign key: referenced table \\\"%s\\\" does not have a column named \\\"%s\\\"\",\n-\t\t\t    fk.info.table, name);\n-\t\t}\n-\t}\n-\tauto fk_names = StringUtil::Join(fk.pk_columns, \",\");\n-\tthrow BinderException(\"Failed to create foreign key: referenced table \\\"%s\\\" does not have a primary key or unique \"\n-\t                      \"constraint on the columns %s\",\n-\t                      fk.info.table, fk_names);\n-}\n-\n-static void FindForeignKeyIndexes(const ColumnList &columns, const vector<string> &names,\n-                                  vector<PhysicalIndex> &indexes) {\n-\tD_ASSERT(indexes.empty());\n-\tD_ASSERT(!names.empty());\n-\tfor (auto &name : names) {\n-\t\tif (!columns.ColumnExists(name)) {\n-\t\t\tthrow BinderException(\"column \\\"%s\\\" named in key does not exist\", name);\n-\t\t}\n-\t\tauto &column = columns.GetColumn(name);\n-\t\tif (column.Generated()) {\n-\t\t\tthrow BinderException(\"Failed to create foreign key: referenced column \\\"%s\\\" is a generated column\",\n-\t\t\t                      column.Name());\n-\t\t}\n-\t\tindexes.push_back(column.Physical());\n-\t}\n-}\n-\n-static void CheckForeignKeyTypes(const ColumnList &pk_columns, const ColumnList &fk_columns, ForeignKeyConstraint &fk) {\n-\tD_ASSERT(fk.info.pk_keys.size() == fk.info.fk_keys.size());\n-\tfor (idx_t c_idx = 0; c_idx < fk.info.pk_keys.size(); c_idx++) {\n-\t\tauto &pk_col = pk_columns.GetColumn(fk.info.pk_keys[c_idx]);\n-\t\tauto &fk_col = fk_columns.GetColumn(fk.info.fk_keys[c_idx]);\n-\t\tif (pk_col.Type() != fk_col.Type()) {\n-\t\t\tthrow BinderException(\"Failed to create foreign key: incompatible types between column \\\"%s\\\" (\\\"%s\\\") and \"\n-\t\t\t                      \"column \\\"%s\\\" (\\\"%s\\\")\",\n-\t\t\t                      pk_col.Name(), pk_col.Type().ToString(), fk_col.Name(), fk_col.Type().ToString());\n-\t\t}\n-\t}\n-}\n-\n-void ExpressionContainsGeneratedColumn(const ParsedExpression &expr, const unordered_set<string> &gcols,\n-                                       bool &contains_gcol) {\n-\tif (contains_gcol) {\n-\t\treturn;\n-\t}\n-\tif (expr.GetExpressionType() == ExpressionType::COLUMN_REF) {\n-\t\tauto &column_ref = expr.Cast<ColumnRefExpression>();\n-\t\tauto &name = column_ref.GetColumnName();\n-\t\tif (gcols.count(name)) {\n-\t\t\tcontains_gcol = true;\n-\t\t\treturn;\n-\t\t}\n-\t}\n-\tParsedExpressionIterator::EnumerateChildren(\n-\t    expr, [&](const ParsedExpression &child) { ExpressionContainsGeneratedColumn(child, gcols, contains_gcol); });\n-}\n-\n-static bool AnyConstraintReferencesGeneratedColumn(CreateTableInfo &table_info) {\n-\tunordered_set<string> generated_columns;\n-\tfor (auto &col : table_info.columns.Logical()) {\n-\t\tif (!col.Generated()) {\n-\t\t\tcontinue;\n-\t\t}\n-\t\tgenerated_columns.insert(col.Name());\n-\t}\n-\tif (generated_columns.empty()) {\n-\t\treturn false;\n-\t}\n-\n-\tfor (auto &constr : table_info.constraints) {\n-\t\tswitch (constr->type) {\n-\t\tcase ConstraintType::CHECK: {\n-\t\t\tauto &constraint = constr->Cast<CheckConstraint>();\n-\t\t\tauto &expr = constraint.expression;\n-\t\t\tbool contains_generated_column = false;\n-\t\t\tExpressionContainsGeneratedColumn(*expr, generated_columns, contains_generated_column);\n-\t\t\tif (contains_generated_column) {\n-\t\t\t\treturn true;\n-\t\t\t}\n-\t\t\tbreak;\n-\t\t}\n-\t\tcase ConstraintType::NOT_NULL: {\n-\t\t\tauto &constraint = constr->Cast<NotNullConstraint>();\n-\t\t\tif (table_info.columns.GetColumn(constraint.index).Generated()) {\n-\t\t\t\treturn true;\n-\t\t\t}\n-\t\t\tbreak;\n-\t\t}\n-\t\tcase ConstraintType::UNIQUE: {\n-\t\t\tauto &constraint = constr->Cast<UniqueConstraint>();\n-\t\t\tif (!constraint.HasIndex()) {\n-\t\t\t\tfor (auto &col : constraint.GetColumnNames()) {\n-\t\t\t\t\tif (generated_columns.count(col)) {\n-\t\t\t\t\t\treturn true;\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t} else {\n-\t\t\t\tif (table_info.columns.GetColumn(constraint.GetIndex()).Generated()) {\n-\t\t\t\t\treturn true;\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tbreak;\n-\t\t}\n-\t\tcase ConstraintType::FOREIGN_KEY: {\n-\t\t\t// If it contained a generated column, an exception would have been thrown inside AddDataTableIndex earlier\n-\t\t\tbreak;\n-\t\t}\n-\t\tdefault: {\n-\t\t\tthrow NotImplementedException(\"ConstraintType not implemented\");\n-\t\t}\n-\t\t}\n-\t}\n-\treturn false;\n-}\n-\n unique_ptr<LogicalOperator> DuckCatalog::BindCreateIndex(Binder &binder, CreateStatement &stmt,\n                                                          TableCatalogEntry &table, unique_ptr<LogicalOperator> plan) {\n \tD_ASSERT(plan->type == LogicalOperatorType::LOGICAL_GET);\n@@ -646,66 +468,8 @@ BoundStatement Binder::Bind(CreateStatement &stmt) {\n \t\tbreak;\n \t}\n \tcase CatalogType::TABLE_ENTRY: {\n-\t\tauto &create_info = stmt.info->Cast<CreateTableInfo>();\n-\t\t// If there is a foreign key constraint, resolve primary key column's index from primary key column's name\n-\t\treference_set_t<SchemaCatalogEntry> fk_schemas;\n-\t\tfor (idx_t i = 0; i < create_info.constraints.size(); i++) {\n-\t\t\tauto &cond = create_info.constraints[i];\n-\t\t\tif (cond->type != ConstraintType::FOREIGN_KEY) {\n-\t\t\t\tcontinue;\n-\t\t\t}\n-\t\t\tauto &fk = cond->Cast<ForeignKeyConstraint>();\n-\t\t\tif (fk.info.type != ForeignKeyType::FK_TYPE_FOREIGN_KEY_TABLE) {\n-\t\t\t\tcontinue;\n-\t\t\t}\n-\t\t\tD_ASSERT(fk.info.pk_keys.empty());\n-\t\t\tD_ASSERT(fk.info.fk_keys.empty());\n-\t\t\tFindForeignKeyIndexes(create_info.columns, fk.fk_columns, fk.info.fk_keys);\n-\n-\t\t\t// Resolve the self-reference.\n-\t\t\tif (StringUtil::CIEquals(create_info.table, fk.info.table)) {\n-\t\t\t\tfk.info.type = ForeignKeyType::FK_TYPE_SELF_REFERENCE_TABLE;\n-\t\t\t\tFindMatchingPrimaryKeyColumns(create_info.columns, create_info.constraints, fk);\n-\t\t\t\tFindForeignKeyIndexes(create_info.columns, fk.pk_columns, fk.info.pk_keys);\n-\t\t\t\tCheckForeignKeyTypes(create_info.columns, create_info.columns, fk);\n-\t\t\t\tcontinue;\n-\t\t\t}\n-\n-\t\t\t// Resolve the table reference.\n-\t\t\tauto table_entry =\n-\t\t\t    entry_retriever.GetEntry(CatalogType::TABLE_ENTRY, INVALID_CATALOG, fk.info.schema, fk.info.table);\n-\t\t\tif (table_entry->type == CatalogType::VIEW_ENTRY) {\n-\t\t\t\tthrow BinderException(\"cannot reference a VIEW with a FOREIGN KEY\");\n-\t\t\t}\n-\n-\t\t\tauto &pk_table_entry_ptr = table_entry->Cast<TableCatalogEntry>();\n-\t\t\tfk_schemas.insert(pk_table_entry_ptr.schema);\n-\t\t\tFindMatchingPrimaryKeyColumns(pk_table_entry_ptr.GetColumns(), pk_table_entry_ptr.GetConstraints(), fk);\n-\t\t\tFindForeignKeyIndexes(pk_table_entry_ptr.GetColumns(), fk.pk_columns, fk.info.pk_keys);\n-\t\t\tCheckForeignKeyTypes(pk_table_entry_ptr.GetColumns(), create_info.columns, fk);\n-\t\t\tauto &storage = pk_table_entry_ptr.GetStorage();\n-\n-\t\t\tif (!storage.HasForeignKeyIndex(fk.info.pk_keys, ForeignKeyType::FK_TYPE_PRIMARY_KEY_TABLE)) {\n-\t\t\t\tauto fk_column_names = StringUtil::Join(fk.pk_columns, \",\");\n-\t\t\t\tthrow BinderException(\"Failed to create foreign key on %s(%s): no UNIQUE or PRIMARY KEY constraint \"\n-\t\t\t\t                      \"present on these columns\",\n-\t\t\t\t                      pk_table_entry_ptr.name, fk_column_names);\n-\t\t\t}\n-\n-\t\t\tD_ASSERT(fk.info.pk_keys.size() == fk.info.fk_keys.size());\n-\t\t\tD_ASSERT(fk.info.pk_keys.size() == fk.pk_columns.size());\n-\t\t\tD_ASSERT(fk.info.fk_keys.size() == fk.fk_columns.size());\n-\t\t}\n-\t\tif (AnyConstraintReferencesGeneratedColumn(create_info)) {\n-\t\t\tthrow BinderException(\"Constraints on generated columns are not supported yet\");\n-\t\t}\n \t\tauto bound_info = BindCreateTableInfo(std::move(stmt.info));\n \t\tauto root = std::move(bound_info->query);\n-\t\tfor (auto &fk_schema : fk_schemas) {\n-\t\t\tif (&fk_schema.get() != &bound_info->schema) {\n-\t\t\t\tthrow BinderException(\"Creating foreign keys across different schemas or catalogs is not supported\");\n-\t\t\t}\n-\t\t}\n \n \t\t// create the logical operator\n \t\tauto &schema = bound_info->schema;\ndiff --git a/src/planner/binder/statement/bind_create_table.cpp b/src/planner/binder/statement/bind_create_table.cpp\nindex 6a6bd564da23..80d50d074e00 100644\n--- a/src/planner/binder/statement/bind_create_table.cpp\n+++ b/src/planner/binder/statement/bind_create_table.cpp\n@@ -19,6 +19,8 @@\n #include \"duckdb/planner/expression_binder/index_binder.hpp\"\n #include \"duckdb/parser/parsed_data/create_index_info.hpp\"\n #include \"duckdb/catalog/catalog_entry/schema_catalog_entry.hpp\"\n+#include \"duckdb/parser/parsed_expression_iterator.hpp\"\n+#include \"duckdb/storage/data_table.hpp\"\n \n namespace duckdb {\n \n@@ -309,6 +311,242 @@ unique_ptr<BoundCreateTableInfo> Binder::BindCreateTableCheckpoint(unique_ptr<Cr\n \treturn result;\n }\n \n+void ExpressionContainsGeneratedColumn(const ParsedExpression &expr, const unordered_set<string> &gcols,\n+                                       bool &contains_gcol) {\n+\tif (contains_gcol) {\n+\t\treturn;\n+\t}\n+\tif (expr.GetExpressionType() == ExpressionType::COLUMN_REF) {\n+\t\tauto &column_ref = expr.Cast<ColumnRefExpression>();\n+\t\tauto &name = column_ref.GetColumnName();\n+\t\tif (gcols.count(name)) {\n+\t\t\tcontains_gcol = true;\n+\t\t\treturn;\n+\t\t}\n+\t}\n+\tParsedExpressionIterator::EnumerateChildren(\n+\t    expr, [&](const ParsedExpression &child) { ExpressionContainsGeneratedColumn(child, gcols, contains_gcol); });\n+}\n+\n+static bool AnyConstraintReferencesGeneratedColumn(CreateTableInfo &table_info) {\n+\tunordered_set<string> generated_columns;\n+\tfor (auto &col : table_info.columns.Logical()) {\n+\t\tif (!col.Generated()) {\n+\t\t\tcontinue;\n+\t\t}\n+\t\tgenerated_columns.insert(col.Name());\n+\t}\n+\tif (generated_columns.empty()) {\n+\t\treturn false;\n+\t}\n+\n+\tfor (auto &constr : table_info.constraints) {\n+\t\tswitch (constr->type) {\n+\t\tcase ConstraintType::CHECK: {\n+\t\t\tauto &constraint = constr->Cast<CheckConstraint>();\n+\t\t\tauto &expr = constraint.expression;\n+\t\t\tbool contains_generated_column = false;\n+\t\t\tExpressionContainsGeneratedColumn(*expr, generated_columns, contains_generated_column);\n+\t\t\tif (contains_generated_column) {\n+\t\t\t\treturn true;\n+\t\t\t}\n+\t\t\tbreak;\n+\t\t}\n+\t\tcase ConstraintType::NOT_NULL: {\n+\t\t\tauto &constraint = constr->Cast<NotNullConstraint>();\n+\t\t\tif (table_info.columns.GetColumn(constraint.index).Generated()) {\n+\t\t\t\treturn true;\n+\t\t\t}\n+\t\t\tbreak;\n+\t\t}\n+\t\tcase ConstraintType::UNIQUE: {\n+\t\t\tauto &constraint = constr->Cast<UniqueConstraint>();\n+\t\t\tif (!constraint.HasIndex()) {\n+\t\t\t\tfor (auto &col : constraint.GetColumnNames()) {\n+\t\t\t\t\tif (generated_columns.count(col)) {\n+\t\t\t\t\t\treturn true;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t} else {\n+\t\t\t\tif (table_info.columns.GetColumn(constraint.GetIndex()).Generated()) {\n+\t\t\t\t\treturn true;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\tbreak;\n+\t\t}\n+\t\tcase ConstraintType::FOREIGN_KEY: {\n+\t\t\t// If it contained a generated column, an exception would have been thrown inside AddDataTableIndex earlier\n+\t\t\tbreak;\n+\t\t}\n+\t\tdefault: {\n+\t\t\tthrow NotImplementedException(\"ConstraintType not implemented\");\n+\t\t}\n+\t\t}\n+\t}\n+\treturn false;\n+}\n+\n+static void FindForeignKeyIndexes(const ColumnList &columns, const vector<string> &names,\n+                                  vector<PhysicalIndex> &indexes) {\n+\tD_ASSERT(indexes.empty());\n+\tD_ASSERT(!names.empty());\n+\tfor (auto &name : names) {\n+\t\tif (!columns.ColumnExists(name)) {\n+\t\t\tthrow BinderException(\"column \\\"%s\\\" named in key does not exist\", name);\n+\t\t}\n+\t\tauto &column = columns.GetColumn(name);\n+\t\tif (column.Generated()) {\n+\t\t\tthrow BinderException(\"Failed to create foreign key: referenced column \\\"%s\\\" is a generated column\",\n+\t\t\t                      column.Name());\n+\t\t}\n+\t\tindexes.push_back(column.Physical());\n+\t}\n+}\n+\n+static void FindMatchingPrimaryKeyColumns(const ColumnList &columns, const vector<unique_ptr<Constraint>> &constraints,\n+                                          ForeignKeyConstraint &fk) {\n+\t// find the matching primary key constraint\n+\tbool found_constraint = false;\n+\t// if no columns are defined, we will automatically try to bind to the primary key\n+\tbool find_primary_key = fk.pk_columns.empty();\n+\tfor (auto &constr : constraints) {\n+\t\tif (constr->type != ConstraintType::UNIQUE) {\n+\t\t\tcontinue;\n+\t\t}\n+\t\tauto &unique = constr->Cast<UniqueConstraint>();\n+\t\tif (find_primary_key && !unique.IsPrimaryKey()) {\n+\t\t\tcontinue;\n+\t\t}\n+\t\tfound_constraint = true;\n+\n+\t\tvector<string> pk_names;\n+\t\tif (unique.HasIndex()) {\n+\t\t\tpk_names.push_back(columns.GetColumn(LogicalIndex(unique.GetIndex())).Name());\n+\t\t} else {\n+\t\t\tpk_names = unique.GetColumnNames();\n+\t\t}\n+\t\tif (find_primary_key) {\n+\t\t\t// found matching primary key\n+\t\t\tif (pk_names.size() != fk.fk_columns.size()) {\n+\t\t\t\tauto pk_name_str = StringUtil::Join(pk_names, \",\");\n+\t\t\t\tauto fk_name_str = StringUtil::Join(fk.fk_columns, \",\");\n+\t\t\t\tthrow BinderException(\n+\t\t\t\t    \"Failed to create foreign key: number of referencing (%s) and referenced columns (%s) differ\",\n+\t\t\t\t    fk_name_str, pk_name_str);\n+\t\t\t}\n+\t\t\tfk.pk_columns = pk_names;\n+\t\t\treturn;\n+\t\t}\n+\t\tif (pk_names.size() != fk.fk_columns.size()) {\n+\t\t\t// the number of referencing and referenced columns for foreign keys must be the same\n+\t\t\tcontinue;\n+\t\t}\n+\t\tbool equals = true;\n+\t\tfor (idx_t i = 0; i < fk.pk_columns.size(); i++) {\n+\t\t\tif (!StringUtil::CIEquals(fk.pk_columns[i], pk_names[i])) {\n+\t\t\t\tequals = false;\n+\t\t\t\tbreak;\n+\t\t\t}\n+\t\t}\n+\t\tif (!equals) {\n+\t\t\tcontinue;\n+\t\t}\n+\t\t// found match\n+\t\treturn;\n+\t}\n+\t// no match found! examine why\n+\tif (!found_constraint) {\n+\t\t// no unique constraint or primary key\n+\t\tstring search_term = find_primary_key ? \"primary key\" : \"primary key or unique constraint\";\n+\t\tthrow BinderException(\"Failed to create foreign key: there is no %s for referenced table \\\"%s\\\"\", search_term,\n+\t\t                      fk.info.table);\n+\t}\n+\t// check if all the columns exist\n+\tfor (auto &name : fk.pk_columns) {\n+\t\tbool found = columns.ColumnExists(name);\n+\t\tif (!found) {\n+\t\t\tthrow BinderException(\n+\t\t\t    \"Failed to create foreign key: referenced table \\\"%s\\\" does not have a column named \\\"%s\\\"\",\n+\t\t\t    fk.info.table, name);\n+\t\t}\n+\t}\n+\tauto fk_names = StringUtil::Join(fk.pk_columns, \",\");\n+\tthrow BinderException(\"Failed to create foreign key: referenced table \\\"%s\\\" does not have a primary key or unique \"\n+\t                      \"constraint on the columns %s\",\n+\t                      fk.info.table, fk_names);\n+}\n+\n+static void CheckForeignKeyTypes(const ColumnList &pk_columns, const ColumnList &fk_columns, ForeignKeyConstraint &fk) {\n+\tD_ASSERT(fk.info.pk_keys.size() == fk.info.fk_keys.size());\n+\tfor (idx_t c_idx = 0; c_idx < fk.info.pk_keys.size(); c_idx++) {\n+\t\tauto &pk_col = pk_columns.GetColumn(fk.info.pk_keys[c_idx]);\n+\t\tauto &fk_col = fk_columns.GetColumn(fk.info.fk_keys[c_idx]);\n+\t\tif (pk_col.Type() != fk_col.Type()) {\n+\t\t\tthrow BinderException(\"Failed to create foreign key: incompatible types between column \\\"%s\\\" (\\\"%s\\\") and \"\n+\t\t\t                      \"column \\\"%s\\\" (\\\"%s\\\")\",\n+\t\t\t                      pk_col.Name(), pk_col.Type().ToString(), fk_col.Name(), fk_col.Type().ToString());\n+\t\t}\n+\t}\n+}\n+\n+static void BindCreateTableConstraints(CreateTableInfo &create_info, CatalogEntryRetriever &entry_retriever,\n+                                       SchemaCatalogEntry &schema) {\n+\t// If there is a foreign key constraint, resolve primary key column's index from primary key column's name\n+\treference_set_t<SchemaCatalogEntry> fk_schemas;\n+\tfor (idx_t i = 0; i < create_info.constraints.size(); i++) {\n+\t\tauto &cond = create_info.constraints[i];\n+\t\tif (cond->type != ConstraintType::FOREIGN_KEY) {\n+\t\t\tcontinue;\n+\t\t}\n+\t\tauto &fk = cond->Cast<ForeignKeyConstraint>();\n+\t\tif (fk.info.type != ForeignKeyType::FK_TYPE_FOREIGN_KEY_TABLE) {\n+\t\t\tcontinue;\n+\t\t}\n+\t\tif (!fk.info.pk_keys.empty() && !fk.info.fk_keys.empty()) {\n+\t\t\treturn;\n+\t\t}\n+\t\tD_ASSERT(fk.info.pk_keys.empty());\n+\t\tD_ASSERT(fk.info.fk_keys.empty());\n+\t\tFindForeignKeyIndexes(create_info.columns, fk.fk_columns, fk.info.fk_keys);\n+\n+\t\t// Resolve the self-reference.\n+\t\tif (StringUtil::CIEquals(create_info.table, fk.info.table)) {\n+\t\t\tfk.info.type = ForeignKeyType::FK_TYPE_SELF_REFERENCE_TABLE;\n+\t\t\tFindMatchingPrimaryKeyColumns(create_info.columns, create_info.constraints, fk);\n+\t\t\tFindForeignKeyIndexes(create_info.columns, fk.pk_columns, fk.info.pk_keys);\n+\t\t\tCheckForeignKeyTypes(create_info.columns, create_info.columns, fk);\n+\t\t\tcontinue;\n+\t\t}\n+\n+\t\t// Resolve the table reference.\n+\t\tauto table_entry =\n+\t\t    entry_retriever.GetEntry(CatalogType::TABLE_ENTRY, INVALID_CATALOG, fk.info.schema, fk.info.table);\n+\t\tif (table_entry->type == CatalogType::VIEW_ENTRY) {\n+\t\t\tthrow BinderException(\"cannot reference a VIEW with a FOREIGN KEY\");\n+\t\t}\n+\n+\t\tauto &pk_table_entry_ptr = table_entry->Cast<TableCatalogEntry>();\n+\t\tif (&pk_table_entry_ptr.schema != &schema) {\n+\t\t\tthrow BinderException(\"Creating foreign keys across different schemas or catalogs is not supported\");\n+\t\t}\n+\t\tFindMatchingPrimaryKeyColumns(pk_table_entry_ptr.GetColumns(), pk_table_entry_ptr.GetConstraints(), fk);\n+\t\tFindForeignKeyIndexes(pk_table_entry_ptr.GetColumns(), fk.pk_columns, fk.info.pk_keys);\n+\t\tCheckForeignKeyTypes(pk_table_entry_ptr.GetColumns(), create_info.columns, fk);\n+\t\tauto &storage = pk_table_entry_ptr.GetStorage();\n+\n+\t\tif (!storage.HasForeignKeyIndex(fk.info.pk_keys, ForeignKeyType::FK_TYPE_PRIMARY_KEY_TABLE)) {\n+\t\t\tauto fk_column_names = StringUtil::Join(fk.pk_columns, \",\");\n+\t\t\tthrow BinderException(\"Failed to create foreign key on %s(%s): no UNIQUE or PRIMARY KEY constraint \"\n+\t\t\t                      \"present on these columns\",\n+\t\t\t                      pk_table_entry_ptr.name, fk_column_names);\n+\t\t}\n+\n+\t\tD_ASSERT(fk.info.pk_keys.size() == fk.info.fk_keys.size());\n+\t\tD_ASSERT(fk.info.pk_keys.size() == fk.pk_columns.size());\n+\t\tD_ASSERT(fk.info.fk_keys.size() == fk.fk_columns.size());\n+\t}\n+}\n+\n unique_ptr<BoundCreateTableInfo> Binder::BindCreateTableInfo(unique_ptr<CreateInfo> info, SchemaCatalogEntry &schema,\n                                                              vector<unique_ptr<Expression>> &bound_defaults) {\n \tauto &base = info->Cast<CreateTableInfo>();\n@@ -350,6 +588,14 @@ unique_ptr<BoundCreateTableInfo> Binder::BindCreateTableInfo(unique_ptr<CreateIn\n \t\t\t\tbase.columns.AddColumn(ColumnDefinition(names[i], sql_types[i]));\n \t\t\t}\n \t\t}\n+\t\t// bind collations to detect any unsupported collation errors\n+\t\tfor (idx_t i = 0; i < base.columns.PhysicalColumnCount(); i++) {\n+\t\t\tauto &column = base.columns.GetColumnMutable(PhysicalIndex(i));\n+\t\t\tif (column.Type().id() == LogicalTypeId::VARCHAR) {\n+\t\t\t\tExpressionBinder::TestCollation(context, StringType::GetCollation(column.Type()));\n+\t\t\t}\n+\t\t\tBindLogicalType(column.TypeMutable(), &result->schema.catalog, result->schema.name);\n+\t\t}\n \t} else {\n \t\tSetCatalogLookupCallback([&dependencies, &schema](CatalogEntry &entry) {\n \t\t\tif (&schema.ParentCatalog() != &entry.ParentCatalog()) {\n@@ -362,6 +608,20 @@ unique_ptr<BoundCreateTableInfo> Binder::BindCreateTableInfo(unique_ptr<CreateIn\n \t\t// bind the generated column expressions\n \t\tBindGeneratedColumns(*result);\n \t\t// bind any constraints\n+\n+\t\t// bind collations to detect any unsupported collation errors\n+\t\tfor (idx_t i = 0; i < base.columns.PhysicalColumnCount(); i++) {\n+\t\t\tauto &column = base.columns.GetColumnMutable(PhysicalIndex(i));\n+\t\t\tif (column.Type().id() == LogicalTypeId::VARCHAR) {\n+\t\t\t\tExpressionBinder::TestCollation(context, StringType::GetCollation(column.Type()));\n+\t\t\t}\n+\t\t\tBindLogicalType(column.TypeMutable(), &result->schema.catalog, result->schema.name);\n+\t\t}\n+\t\tBindCreateTableConstraints(base, entry_retriever, schema);\n+\n+\t\tif (AnyConstraintReferencesGeneratedColumn(base)) {\n+\t\t\tthrow BinderException(\"Constraints on generated columns are not supported yet\");\n+\t\t}\n \t\tbound_constraints = BindNewConstraints(base.constraints, base.table, base.columns);\n \t\t// bind the default values\n \t\tauto &catalog_name = schema.ParentCatalog().GetName();\n@@ -372,14 +632,7 @@ unique_ptr<BoundCreateTableInfo> Binder::BindCreateTableInfo(unique_ptr<CreateIn\n \tif (base.columns.PhysicalColumnCount() == 0) {\n \t\tthrow BinderException(\"Creating a table without physical (non-generated) columns is not supported\");\n \t}\n-\t// bind collations to detect any unsupported collation errors\n-\tfor (idx_t i = 0; i < base.columns.PhysicalColumnCount(); i++) {\n-\t\tauto &column = base.columns.GetColumnMutable(PhysicalIndex(i));\n-\t\tif (column.Type().id() == LogicalTypeId::VARCHAR) {\n-\t\t\tExpressionBinder::TestCollation(context, StringType::GetCollation(column.Type()));\n-\t\t}\n-\t\tBindLogicalType(column.TypeMutable(), &result->schema.catalog, result->schema.name);\n-\t}\n+\n \tresult->dependencies.VerifyDependencies(schema.catalog, result->Base().table);\n \n \tauto &properties = GetStatementProperties();\n", "test_patch": "diff --git a/test/sql/collate/test_unsupported_collations.test b/test/sql/collate/test_unsupported_collations.test\nindex 8c7b7063f80c..9c79632783f7 100644\n--- a/test/sql/collate/test_unsupported_collations.test\n+++ b/test/sql/collate/test_unsupported_collations.test\n@@ -6,11 +6,13 @@\n statement error\n CREATE TABLE collate_test(s VARCHAR COLLATE blabla)\n ----\n+Catalog Error: Collation with name blabla does not exist!\n \n # non-varchar columns cannot have collations\n statement error\n CREATE TABLE collate_test(s INTEGER COLLATE blabla)\n ----\n+Parser Error: Only VARCHAR columns can have collations!\n \n # we can combine multiple of the same collation\n statement ok\n@@ -19,11 +21,14 @@ CREATE TABLE collate_test(s VARCHAR COLLATE NOACCENT.NOACCENT)\n statement error\n CREATE TABLE collate_test(s VARCHAR COLLATE 1)\n ----\n+Parser Error: syntax error at or near \"1\"\n \n statement error\n CREATE TABLE collate_test(s VARCHAR COLLATE 'hello')\n ----\n+Parser Error: syntax error at or near \"'hello'\"\n \n statement error\n PRAGMA default_collation='blabla'\n ----\n+Catalog Error: Collation with name blabla does not exist!\ndiff --git a/test/sql/constraints/foreignkey/test_fk_create_type.test b/test/sql/constraints/foreignkey/test_fk_create_type.test\nnew file mode 100644\nindex 000000000000..ed7499c7f7f4\n--- /dev/null\n+++ b/test/sql/constraints/foreignkey/test_fk_create_type.test\n@@ -0,0 +1,42 @@\n+# name: test/sql/constraints/foreignkey/test_fk_create_type.test\n+# group: [foreignkey]\n+\n+# Create a custom type\n+\n+statement ok\n+create type custom_type as integer;\n+\n+statement ok\n+create table parent (\n+\tid custom_type primary key\n+);\n+\n+# Use the type alias in both the primary key table and the foreign key table\n+\n+statement ok\n+create table child (\n+\tparent custom_type references parent\n+);\n+\n+statement ok\n+drop table child;\n+\n+# Also works with just 'integer'\n+\n+statement ok\n+create table child (\n+\tparent integer references parent\n+);\n+\n+statement ok\n+drop table child;\n+\n+statement ok\n+create type another_custom_type as integer;\n+\n+# And even with a different type alias that also resolves to 'integer'\n+\n+statement ok\n+create table child (\n+\tparent another_custom_type references parent\n+);\n", "problem_statement": "Foreign keys using user defined types fail to be defined\n### What happens?\r\n\r\nIf one uses `create type ...` to define a custom type, and then uses that as a primary key in some table, and it then references it as a foreign key, DuckDB (v1.1.3) fails with `Failed to create foreign key: incompatible types between column [...]`.\r\n\r\n(It seems to be related to issue #9234, which was however closed due to \"inactivity\".)\r\n\r\n\r\n### To Reproduce\r\n\r\nRunning the following simple SQL defining schema:\r\n\r\n```sql\r\ncreate type idtype as integer;\r\n\r\ncreate table parent (id idtype primary key);\r\ncreate table child (parent idtype references parent);\r\n```\r\n\r\nFails with:\r\n\r\n```console\r\nBinder Error: Failed to create foreign key: incompatible types between column \"id\" (\"INTEGER\") and column \"parent\" (\"idtype\")\r\n```\r\n\r\n### OS:\r\n\r\nLinux\r\n\r\n### DuckDB Version:\r\n\r\n1.1.3\r\n\r\n### DuckDB Client:\r\n\r\nCLI\r\n\r\n### Hardware:\r\n\r\nx86_64\r\n\r\n### Full Name:\r\n\r\n(see Github account submitting this issue)\r\n\r\n### Affiliation:\r\n\r\n(see Github account submitting this issue)\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\n", "hints_text": "", "created_at": "2025-01-02T10:16:13Z"}
{"repo": "duckdb/duckdb", "pull_number": 15484, "instance_id": "duckdb__duckdb-15484", "issue_numbers": ["15466", "15466"], "base_commit": "0959644c1d57409e78d2fae0262f792921a54c55", "patch": "diff --git a/src/parser/transform/statement/transform_select_node.cpp b/src/parser/transform/statement/transform_select_node.cpp\nindex ab206fdb860d..56ef6c71c744 100644\n--- a/src/parser/transform/statement/transform_select_node.cpp\n+++ b/src/parser/transform/statement/transform_select_node.cpp\n@@ -31,11 +31,20 @@ void Transformer::TransformModifiers(duckdb_libpgquery::PGSelectStmt &stmt, Quer\n \t\t\tnode.modifiers.push_back(std::move(limit_percent_modifier));\n \t\t} else {\n \t\t\tauto limit_modifier = make_uniq<LimitModifier>();\n-\t\t\tif (stmt.limitCount) {\n-\t\t\t\tlimit_modifier->limit = TransformExpression(stmt.limitCount);\n-\t\t\t}\n-\t\t\tif (stmt.limitOffset) {\n-\t\t\t\tlimit_modifier->offset = TransformExpression(stmt.limitOffset);\n+\t\t\tif (stmt.offset_first) {\n+\t\t\t\tif (stmt.limitOffset) {\n+\t\t\t\t\tlimit_modifier->offset = TransformExpression(stmt.limitOffset);\n+\t\t\t\t}\n+\t\t\t\tif (stmt.limitCount) {\n+\t\t\t\t\tlimit_modifier->limit = TransformExpression(stmt.limitCount);\n+\t\t\t\t}\n+\t\t\t} else {\n+\t\t\t\tif (stmt.limitCount) {\n+\t\t\t\t\tlimit_modifier->limit = TransformExpression(stmt.limitCount);\n+\t\t\t\t}\n+\t\t\t\tif (stmt.limitOffset) {\n+\t\t\t\t\tlimit_modifier->offset = TransformExpression(stmt.limitOffset);\n+\t\t\t\t}\n \t\t\t}\n \t\t\tnode.modifiers.push_back(std::move(limit_modifier));\n \t\t}\ndiff --git a/third_party/libpg_query/grammar/grammar.cpp b/third_party/libpg_query/grammar/grammar.cpp\nindex 39f849278640..6774ce90ae53 100644\n--- a/third_party/libpg_query/grammar/grammar.cpp\n+++ b/third_party/libpg_query/grammar/grammar.cpp\n@@ -366,7 +366,7 @@ static PGNode* makeNamedParamRef(char *name, int location)\n static void\n insertSelectOptions(PGSelectStmt *stmt,\n \t\t\t\t\tPGList *sortClause, PGList *lockingClause,\n-\t\t\t\t\tPGNode *limitOffset, PGNode *limitCount,\n+\t\t\t\t\tPGNode *limitOffset, PGNode *limitCount, PGNode *isLimitOffsetFirst,\n \t\t\t\t\tPGWithClause *withClause,\n \t\t\t\t\tcore_yyscan_t yyscanner)\n {\n@@ -411,6 +411,9 @@ insertSelectOptions(PGSelectStmt *stmt,\n \t\t\t\t\t parser_errposition(exprLocation(limitCount))));\n \t\tstmt->limitCount = limitCount;\n \t}\n+\tif (limitOffset == isLimitOffsetFirst) {\n+\t\tstmt->offset_first = true;\n+\t}\n \tif (withClause)\n \t{\n \t\tif (stmt->withClause)\ndiff --git a/third_party/libpg_query/grammar/grammar.hpp b/third_party/libpg_query/grammar/grammar.hpp\nindex f442bd3edbd1..c50538d683c0 100644\n--- a/third_party/libpg_query/grammar/grammar.hpp\n+++ b/third_party/libpg_query/grammar/grammar.hpp\n@@ -197,7 +197,7 @@ static PGList *check_func_name(PGList *names, core_yyscan_t yyscanner);\n static PGList *check_indirection(PGList *indirection, core_yyscan_t yyscanner);\n static void insertSelectOptions(PGSelectStmt *stmt,\n \t\t\t\t\t\t\t\tPGList *sortClause, PGList *lockingClause,\n-\t\t\t\t\t\t\t\tPGNode *limitOffset, PGNode *limitCount,\n+\t\t\t\t\t\t\t\tPGNode *limitOffset, PGNode *limitCount, PGNode *isLimitOffsetFirst,\n \t\t\t\t\t\t\t\tPGWithClause *withClause,\n \t\t\t\t\t\t\t\tcore_yyscan_t yyscanner);\n static PGNode *makeSetOp(PGSetOperation op, bool all, PGNode *larg, PGNode *rarg);\ndiff --git a/third_party/libpg_query/grammar/statements/select.y b/third_party/libpg_query/grammar/statements/select.y\nindex f1b2200323e1..e6bb118cf6d6 100644\n--- a/third_party/libpg_query/grammar/statements/select.y\n+++ b/third_party/libpg_query/grammar/statements/select.y\n@@ -73,14 +73,14 @@ select_no_parens:\n \t\t\t| select_clause sort_clause\n \t\t\t\t{\n \t\t\t\t\tinsertSelectOptions((PGSelectStmt *) $1, $2, NIL,\n-\t\t\t\t\t\t\t\t\t\tNULL, NULL, NULL,\n+\t\t\t\t\t\t\t\t\t\tNULL, NULL, NULL, NULL,\n \t\t\t\t\t\t\t\t\t\tyyscanner);\n \t\t\t\t\t$$ = $1;\n \t\t\t\t}\n \t\t\t| select_clause opt_sort_clause for_locking_clause opt_select_limit\n \t\t\t\t{\n \t\t\t\t\tinsertSelectOptions((PGSelectStmt *) $1, $2, $3,\n-\t\t\t\t\t\t\t\t\t\t(PGNode*) list_nth($4, 0), (PGNode*) list_nth($4, 1),\n+\t\t\t\t\t\t\t\t\t\t(PGNode*) list_nth($4, 0), (PGNode*) list_nth($4, 1), (PGNode*) list_nth($4, 2),\n \t\t\t\t\t\t\t\t\t\tNULL,\n \t\t\t\t\t\t\t\t\t\tyyscanner);\n \t\t\t\t\t$$ = $1;\n@@ -88,7 +88,7 @@ select_no_parens:\n \t\t\t| select_clause opt_sort_clause select_limit opt_for_locking_clause\n \t\t\t\t{\n \t\t\t\t\tinsertSelectOptions((PGSelectStmt *) $1, $2, $4,\n-\t\t\t\t\t\t\t\t\t\t(PGNode*) list_nth($3, 0), (PGNode*) list_nth($3, 1),\n+\t\t\t\t\t\t\t\t\t\t(PGNode*) list_nth($3, 0), (PGNode*) list_nth($3, 1), (PGNode*) list_nth($3, 2),\n \t\t\t\t\t\t\t\t\t\tNULL,\n \t\t\t\t\t\t\t\t\t\tyyscanner);\n \t\t\t\t\t$$ = $1;\n@@ -96,7 +96,7 @@ select_no_parens:\n \t\t\t| with_clause select_clause\n \t\t\t\t{\n \t\t\t\t\tinsertSelectOptions((PGSelectStmt *) $2, NULL, NIL,\n-\t\t\t\t\t\t\t\t\t\tNULL, NULL,\n+\t\t\t\t\t\t\t\t\t\tNULL, NULL, NULL,\n \t\t\t\t\t\t\t\t\t\t$1,\n \t\t\t\t\t\t\t\t\t\tyyscanner);\n \t\t\t\t\t$$ = $2;\n@@ -104,7 +104,7 @@ select_no_parens:\n \t\t\t| with_clause select_clause sort_clause\n \t\t\t\t{\n \t\t\t\t\tinsertSelectOptions((PGSelectStmt *) $2, $3, NIL,\n-\t\t\t\t\t\t\t\t\t\tNULL, NULL,\n+\t\t\t\t\t\t\t\t\t\tNULL, NULL, NULL,\n \t\t\t\t\t\t\t\t\t\t$1,\n \t\t\t\t\t\t\t\t\t\tyyscanner);\n \t\t\t\t\t$$ = $2;\n@@ -112,7 +112,7 @@ select_no_parens:\n \t\t\t| with_clause select_clause opt_sort_clause for_locking_clause opt_select_limit\n \t\t\t\t{\n \t\t\t\t\tinsertSelectOptions((PGSelectStmt *) $2, $3, $4,\n-\t\t\t\t\t\t\t\t\t\t(PGNode*) list_nth($5, 0), (PGNode*) list_nth($5, 1),\n+\t\t\t\t\t\t\t\t\t\t(PGNode*) list_nth($5, 0), (PGNode*) list_nth($5, 1), (PGNode*) list_nth($5, 2),\n \t\t\t\t\t\t\t\t\t\t$1,\n \t\t\t\t\t\t\t\t\t\tyyscanner);\n \t\t\t\t\t$$ = $2;\n@@ -120,7 +120,7 @@ select_no_parens:\n \t\t\t| with_clause select_clause opt_sort_clause select_limit opt_for_locking_clause\n \t\t\t\t{\n \t\t\t\t\tinsertSelectOptions((PGSelectStmt *) $2, $3, $5,\n-\t\t\t\t\t\t\t\t\t\t(PGNode*) list_nth($4, 0), (PGNode*) list_nth($4, 1),\n+\t\t\t\t\t\t\t\t\t\t(PGNode*) list_nth($4, 0), (PGNode*) list_nth($4, 1), (PGNode*) list_nth($4, 2),\n \t\t\t\t\t\t\t\t\t\t$1,\n \t\t\t\t\t\t\t\t\t\tyyscanner);\n \t\t\t\t\t$$ = $2;\n@@ -640,15 +640,15 @@ opt_nulls_order: NULLS_LA FIRST_P\t\t\t{ $$ = PG_SORTBY_NULLS_FIRST; }\n \t\t;\n \n select_limit:\n-\t\t\tlimit_clause offset_clause\t\t\t{ $$ = list_make2($2, $1); }\n-\t\t\t| offset_clause limit_clause\t\t{ $$ = list_make2($1, $2); }\n-\t\t\t| limit_clause\t\t\t\t\t\t{ $$ = list_make2(NULL, $1); }\n-\t\t\t| offset_clause\t\t\t\t\t\t{ $$ = list_make2($1, NULL); }\n+\t\t\tlimit_clause offset_clause\t\t\t{ $$ = list_make3($2, $1, NULL); }\n+\t\t\t| offset_clause limit_clause\t\t{ $$ = list_make3($1, $2, $1); }\n+\t\t\t| limit_clause\t\t\t\t\t\t{ $$ = list_make3(NULL, $1, NULL); }\n+\t\t\t| offset_clause\t\t\t\t\t\t{ $$ = list_make3($1, NULL, $1); }\n \t\t;\n \n opt_select_limit:\n \t\t\tselect_limit\t\t\t\t\t\t{ $$ = $1; }\n-\t\t\t| /* EMPTY */\t\t\t\t\t\t{ $$ = list_make2(NULL,NULL); }\n+\t\t\t| /* EMPTY */\t\t\t\t\t\t{ $$ = list_make3(NULL,NULL,NULL); }\n \t\t;\n \n limit_clause:\ndiff --git a/third_party/libpg_query/include/nodes/parsenodes.hpp b/third_party/libpg_query/include/nodes/parsenodes.hpp\nindex 2fbf2cf75245..4789b88661c6 100755\n--- a/third_party/libpg_query/include/nodes/parsenodes.hpp\n+++ b/third_party/libpg_query/include/nodes/parsenodes.hpp\n@@ -1289,6 +1289,7 @@ typedef struct PGSelectStmt {\n \tPGSetOperation op;         /* type of set op */\n \tbool all;                  /* ALL specified? */\n \tbool from_first;           /* FROM first or SELECT first */\n+\tbool offset_first;         /* OFFSET first or LIMIT first */\n \tstruct PGNode *larg; /* left child */\n \tstruct PGNode *rarg; /* right child */\n \t                           /* Eventually add fields for CORRESPONDING spec here */\ndiff --git a/third_party/libpg_query/src_backend_parser_gram.cpp b/third_party/libpg_query/src_backend_parser_gram.cpp\nindex 71ed8b023f32..e8bf4eb50e38 100644\n--- a/third_party/libpg_query/src_backend_parser_gram.cpp\n+++ b/third_party/libpg_query/src_backend_parser_gram.cpp\n@@ -1292,7 +1292,7 @@ static PGList *check_func_name(PGList *names, core_yyscan_t yyscanner);\n static PGList *check_indirection(PGList *indirection, core_yyscan_t yyscanner);\n static void insertSelectOptions(PGSelectStmt *stmt,\n \t\t\t\t\t\t\t\tPGList *sortClause, PGList *lockingClause,\n-\t\t\t\t\t\t\t\tPGNode *limitOffset, PGNode *limitCount,\n+\t\t\t\t\t\t\t\tPGNode *limitOffset, PGNode *limitCount, PGNode *isLimitOffsetFirst,\n \t\t\t\t\t\t\t\tPGWithClause *withClause,\n \t\t\t\t\t\t\t\tcore_yyscan_t yyscanner);\n static PGNode *makeSetOp(PGSetOperation op, bool all, PGNode *larg, PGNode *rarg);\n@@ -24378,7 +24378,7 @@ YYLTYPE yylloc;\n #line 74 \"third_party/libpg_query/grammar/statements/select.y\"\n     {\n \t\t\t\t\tinsertSelectOptions((PGSelectStmt *) (yyvsp[(1) - (2)].node), (yyvsp[(2) - (2)].list), NIL,\n-\t\t\t\t\t\t\t\t\t\tNULL, NULL, NULL,\n+\t\t\t\t\t\t\t\t\t\tNULL, NULL, NULL, NULL,\n \t\t\t\t\t\t\t\t\t\tyyscanner);\n \t\t\t\t\t(yyval.node) = (yyvsp[(1) - (2)].node);\n \t\t\t\t;}\n@@ -24388,7 +24388,7 @@ YYLTYPE yylloc;\n #line 81 \"third_party/libpg_query/grammar/statements/select.y\"\n     {\n \t\t\t\t\tinsertSelectOptions((PGSelectStmt *) (yyvsp[(1) - (4)].node), (yyvsp[(2) - (4)].list), (yyvsp[(3) - (4)].list),\n-\t\t\t\t\t\t\t\t\t\t(PGNode*) list_nth((yyvsp[(4) - (4)].list), 0), (PGNode*) list_nth((yyvsp[(4) - (4)].list), 1),\n+\t\t\t\t\t\t\t\t\t\t(PGNode*) list_nth((yyvsp[(4) - (4)].list), 0), (PGNode*) list_nth((yyvsp[(4) - (4)].list), 1), (PGNode*) list_nth((yyvsp[(4) - (4)].list), 2),\n \t\t\t\t\t\t\t\t\t\tNULL,\n \t\t\t\t\t\t\t\t\t\tyyscanner);\n \t\t\t\t\t(yyval.node) = (yyvsp[(1) - (4)].node);\n@@ -24399,7 +24399,7 @@ YYLTYPE yylloc;\n #line 89 \"third_party/libpg_query/grammar/statements/select.y\"\n     {\n \t\t\t\t\tinsertSelectOptions((PGSelectStmt *) (yyvsp[(1) - (4)].node), (yyvsp[(2) - (4)].list), (yyvsp[(4) - (4)].list),\n-\t\t\t\t\t\t\t\t\t\t(PGNode*) list_nth((yyvsp[(3) - (4)].list), 0), (PGNode*) list_nth((yyvsp[(3) - (4)].list), 1),\n+\t\t\t\t\t\t\t\t\t\t(PGNode*) list_nth((yyvsp[(3) - (4)].list), 0), (PGNode*) list_nth((yyvsp[(3) - (4)].list), 1), (PGNode*) list_nth((yyvsp[(3) - (4)].list), 2),\n \t\t\t\t\t\t\t\t\t\tNULL,\n \t\t\t\t\t\t\t\t\t\tyyscanner);\n \t\t\t\t\t(yyval.node) = (yyvsp[(1) - (4)].node);\n@@ -24410,7 +24410,7 @@ YYLTYPE yylloc;\n #line 97 \"third_party/libpg_query/grammar/statements/select.y\"\n     {\n \t\t\t\t\tinsertSelectOptions((PGSelectStmt *) (yyvsp[(2) - (2)].node), NULL, NIL,\n-\t\t\t\t\t\t\t\t\t\tNULL, NULL,\n+\t\t\t\t\t\t\t\t\t\tNULL, NULL, NULL,\n \t\t\t\t\t\t\t\t\t\t(yyvsp[(1) - (2)].with),\n \t\t\t\t\t\t\t\t\t\tyyscanner);\n \t\t\t\t\t(yyval.node) = (yyvsp[(2) - (2)].node);\n@@ -24421,7 +24421,7 @@ YYLTYPE yylloc;\n #line 105 \"third_party/libpg_query/grammar/statements/select.y\"\n     {\n \t\t\t\t\tinsertSelectOptions((PGSelectStmt *) (yyvsp[(2) - (3)].node), (yyvsp[(3) - (3)].list), NIL,\n-\t\t\t\t\t\t\t\t\t\tNULL, NULL,\n+\t\t\t\t\t\t\t\t\t\tNULL, NULL, NULL,\n \t\t\t\t\t\t\t\t\t\t(yyvsp[(1) - (3)].with),\n \t\t\t\t\t\t\t\t\t\tyyscanner);\n \t\t\t\t\t(yyval.node) = (yyvsp[(2) - (3)].node);\n@@ -24432,7 +24432,7 @@ YYLTYPE yylloc;\n #line 113 \"third_party/libpg_query/grammar/statements/select.y\"\n     {\n \t\t\t\t\tinsertSelectOptions((PGSelectStmt *) (yyvsp[(2) - (5)].node), (yyvsp[(3) - (5)].list), (yyvsp[(4) - (5)].list),\n-\t\t\t\t\t\t\t\t\t\t(PGNode*) list_nth((yyvsp[(5) - (5)].list), 0), (PGNode*) list_nth((yyvsp[(5) - (5)].list), 1),\n+\t\t\t\t\t\t\t\t\t\t(PGNode*) list_nth((yyvsp[(5) - (5)].list), 0), (PGNode*) list_nth((yyvsp[(5) - (5)].list), 1), (PGNode*) list_nth((yyvsp[(5) - (5)].list), 2),\n \t\t\t\t\t\t\t\t\t\t(yyvsp[(1) - (5)].with),\n \t\t\t\t\t\t\t\t\t\tyyscanner);\n \t\t\t\t\t(yyval.node) = (yyvsp[(2) - (5)].node);\n@@ -24443,7 +24443,7 @@ YYLTYPE yylloc;\n #line 121 \"third_party/libpg_query/grammar/statements/select.y\"\n     {\n \t\t\t\t\tinsertSelectOptions((PGSelectStmt *) (yyvsp[(2) - (5)].node), (yyvsp[(3) - (5)].list), (yyvsp[(5) - (5)].list),\n-\t\t\t\t\t\t\t\t\t\t(PGNode*) list_nth((yyvsp[(4) - (5)].list), 0), (PGNode*) list_nth((yyvsp[(4) - (5)].list), 1),\n+\t\t\t\t\t\t\t\t\t\t(PGNode*) list_nth((yyvsp[(4) - (5)].list), 0), (PGNode*) list_nth((yyvsp[(4) - (5)].list), 1), (PGNode*) list_nth((yyvsp[(4) - (5)].list), 2),\n \t\t\t\t\t\t\t\t\t\t(yyvsp[(1) - (5)].with),\n \t\t\t\t\t\t\t\t\t\tyyscanner);\n \t\t\t\t\t(yyval.node) = (yyvsp[(2) - (5)].node);\n@@ -25103,22 +25103,22 @@ YYLTYPE yylloc;\n \n   case 622:\n #line 643 \"third_party/libpg_query/grammar/statements/select.y\"\n-    { (yyval.list) = list_make2((yyvsp[(2) - (2)].node), (yyvsp[(1) - (2)].node)); ;}\n+    { (yyval.list) = list_make3((yyvsp[(2) - (2)].node), (yyvsp[(1) - (2)].node), NULL); ;}\n     break;\n \n   case 623:\n #line 644 \"third_party/libpg_query/grammar/statements/select.y\"\n-    { (yyval.list) = list_make2((yyvsp[(1) - (2)].node), (yyvsp[(2) - (2)].node)); ;}\n+    { (yyval.list) = list_make3((yyvsp[(1) - (2)].node), (yyvsp[(2) - (2)].node), (yyvsp[(1) - (2)].node)); ;}\n     break;\n \n   case 624:\n #line 645 \"third_party/libpg_query/grammar/statements/select.y\"\n-    { (yyval.list) = list_make2(NULL, (yyvsp[(1) - (1)].node)); ;}\n+    { (yyval.list) = list_make3(NULL, (yyvsp[(1) - (1)].node), NULL); ;}\n     break;\n \n   case 625:\n #line 646 \"third_party/libpg_query/grammar/statements/select.y\"\n-    { (yyval.list) = list_make2((yyvsp[(1) - (1)].node), NULL); ;}\n+    { (yyval.list) = list_make3((yyvsp[(1) - (1)].node), NULL, (yyvsp[(1) - (1)].node)); ;}\n     break;\n \n   case 626:\n@@ -25128,7 +25128,7 @@ YYLTYPE yylloc;\n \n   case 627:\n #line 651 \"third_party/libpg_query/grammar/statements/select.y\"\n-    { (yyval.list) = list_make2(NULL,NULL); ;}\n+    { (yyval.list) = list_make3(NULL,NULL,NULL); ;}\n     break;\n \n   case 628:\n@@ -32114,7 +32114,7 @@ static PGNode* makeNamedParamRef(char *name, int location)\n static void\n insertSelectOptions(PGSelectStmt *stmt,\n \t\t\t\t\tPGList *sortClause, PGList *lockingClause,\n-\t\t\t\t\tPGNode *limitOffset, PGNode *limitCount,\n+\t\t\t\t\tPGNode *limitOffset, PGNode *limitCount, PGNode *isLimitOffsetFirst,\n \t\t\t\t\tPGWithClause *withClause,\n \t\t\t\t\tcore_yyscan_t yyscanner)\n {\n@@ -32159,6 +32159,9 @@ insertSelectOptions(PGSelectStmt *stmt,\n \t\t\t\t\t parser_errposition(exprLocation(limitCount))));\n \t\tstmt->limitCount = limitCount;\n \t}\n+  if (limitOffset == isLimitOffsetFirst) {\n+    stmt->offset_first = true;\n+  }\n \tif (withClause)\n \t{\n \t\tif (stmt->withClause)\n", "test_patch": "diff --git a/test/sql/prepared/prepare_offset_first.test b/test/sql/prepared/prepare_offset_first.test\nnew file mode 100644\nindex 000000000000..d7fb5b43c5cc\n--- /dev/null\n+++ b/test/sql/prepared/prepare_offset_first.test\n@@ -0,0 +1,30 @@\n+# name: test/sql/prepared/prepare_offset_first.test\n+# description: Test OFFSET and LIMIT with prepared statements\n+# group: [prepared]\n+\n+statement ok\n+pragma enable_verification\n+\n+# Prepare a query with OFFSET and LIMIT as parameters with OFFSET written first in the query\n+statement ok\n+PREPARE q AS SELECT x FROM generate_series(1, 10) t(x) OFFSET ? LIMIT ?;\n+\n+# Execute the prepared query with OFFSET = 3 and LIMIT = 5\n+query I\n+EXECUTE q(3, 5);\n+----\n+4\n+5\n+6\n+7\n+8\n+\n+# Verify the result matches the direct query\n+query I\n+SELECT x FROM generate_series(1, 10) t(x) OFFSET 3 LIMIT 5;\n+----\n+4\n+5\n+6\n+7\n+8\n", "problem_statement": "Parameters for OFFSET and LIMIT in a prepared statement get swapped\nI am experiencing a strange effect with DuckDB and Java when passing in OFFSET and LIMIT as parameters in a prepared statement. \r\n\r\nTo make it work I have to swap the assignment of the parameters compared to the expected i.e. set the desired limit as first parameter and the desired offset as second even though the order is the oposite in the prepared statement....\r\nIf I do not switch the order I get zero records in the result (because the limit seems to become zero).\r\n\r\nWhat am I doing wrong here or are there some known quirks/problems with DuckDB (1.1.3) parameter mapping?\r\n\r\nMy program (somewhat simplified) looks like this:\r\nimport java.sql.*;\r\n\r\n```\r\npublic class DuckDBParameterBindingTest {\r\n\r\n    private static final String JDBC_URL = \"jdbc:duckdb:demo.db\";\r\n    private static final String QUERY = \"SELECT a, b, c, d, e FROM table ORDER BY a, b, c, d, e OFFSET ? LIMIT ?\";\r\n\r\n    public static void main(String[] args) {\r\n        try (Connection connection = DriverManager.getConnection(JDBC_URL);\r\n             PreparedStatement preparedStatement = connection.prepareStatement(QUERY)) {\r\n\r\n            System.out.println(\"Test 1: Standard parameter binding (OFFSET=0, LIMIT=5)\");\r\n            preparedStatement.setInt(1, 0); // OFFSET\r\n            preparedStatement.setInt(2, 5); // LIMIT\r\n            runQuery(preparedStatement); // Incorrect result: No rows printed\r\n\r\n            System.out.println(\"Test 2: Swapped parameter binding (LIMIT=5, OFFSET=0)\");\r\n            preparedStatement.setInt(1, 5); // LIMIT\r\n            preparedStatement.setInt(2, 0); // OFFSET\r\n            runQuery(preparedStatement); // Correct result: 5 rows printed\r\n\r\n        } catch (SQLException e) {\r\n            e.printStackTrace();\r\n        }\r\n    }\r\n\r\n    private static void runQuery(PreparedStatement preparedStatement) throws SQLException {\r\n        try (ResultSet resultSet = preparedStatement.executeQuery()) {\r\n            while (resultSet.next()) {\r\n                System.out.printf(\"%s, %s, %d, %d, %d%n\",\r\n                        resultSet.getString(1),\r\n                        resultSet.getString(2),\r\n                        resultSet.getLong(3),\r\n                        resultSet.getLong(4),\r\n                        resultSet.getLong(5));\r\n            }\r\n            System.out.println(\"-------------------------\");\r\n        }\r\n    }\r\n}\r\n\r\n```\r\n\r\n_Originally posted by @javafanboy in https://github.com/duckdb/duckdb/discussions/14907_\nParameters for OFFSET and LIMIT in a prepared statement get swapped\nI am experiencing a strange effect with DuckDB and Java when passing in OFFSET and LIMIT as parameters in a prepared statement. \r\n\r\nTo make it work I have to swap the assignment of the parameters compared to the expected i.e. set the desired limit as first parameter and the desired offset as second even though the order is the oposite in the prepared statement....\r\nIf I do not switch the order I get zero records in the result (because the limit seems to become zero).\r\n\r\nWhat am I doing wrong here or are there some known quirks/problems with DuckDB (1.1.3) parameter mapping?\r\n\r\nMy program (somewhat simplified) looks like this:\r\nimport java.sql.*;\r\n\r\n```\r\npublic class DuckDBParameterBindingTest {\r\n\r\n    private static final String JDBC_URL = \"jdbc:duckdb:demo.db\";\r\n    private static final String QUERY = \"SELECT a, b, c, d, e FROM table ORDER BY a, b, c, d, e OFFSET ? LIMIT ?\";\r\n\r\n    public static void main(String[] args) {\r\n        try (Connection connection = DriverManager.getConnection(JDBC_URL);\r\n             PreparedStatement preparedStatement = connection.prepareStatement(QUERY)) {\r\n\r\n            System.out.println(\"Test 1: Standard parameter binding (OFFSET=0, LIMIT=5)\");\r\n            preparedStatement.setInt(1, 0); // OFFSET\r\n            preparedStatement.setInt(2, 5); // LIMIT\r\n            runQuery(preparedStatement); // Incorrect result: No rows printed\r\n\r\n            System.out.println(\"Test 2: Swapped parameter binding (LIMIT=5, OFFSET=0)\");\r\n            preparedStatement.setInt(1, 5); // LIMIT\r\n            preparedStatement.setInt(2, 0); // OFFSET\r\n            runQuery(preparedStatement); // Correct result: 5 rows printed\r\n\r\n        } catch (SQLException e) {\r\n            e.printStackTrace();\r\n        }\r\n    }\r\n\r\n    private static void runQuery(PreparedStatement preparedStatement) throws SQLException {\r\n        try (ResultSet resultSet = preparedStatement.executeQuery()) {\r\n            while (resultSet.next()) {\r\n                System.out.printf(\"%s, %s, %d, %d, %d%n\",\r\n                        resultSet.getString(1),\r\n                        resultSet.getString(2),\r\n                        resultSet.getLong(3),\r\n                        resultSet.getLong(4),\r\n                        resultSet.getLong(5));\r\n            }\r\n            System.out.println(\"-------------------------\");\r\n        }\r\n    }\r\n}\r\n\r\n```\r\n\r\n_Originally posted by @javafanboy in https://github.com/duckdb/duckdb/discussions/14907_\n", "hints_text": "Hi @javafanboy, thanks for reporting this! The issue can be reproduced in the DuckDB CLI client:\r\n\r\n```sql\r\nPREPARE q AS SELECT x FROM generate_series(1, 10) t(x) OFFSET ? LIMIT ?;\r\nEXECUTE q(3, 5);\r\n```\r\n```text\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502   x   \u2502\r\n\u2502 int64 \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502     6 \u2502\r\n\u2502     7 \u2502\r\n\u2502     8 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\nThe reason you're experiencing this issue is that the default order of these clauses is [`LIMIT` followed by `OFFSET`](https://duckdb.org/docs/sql/statements/select#order-by-limit-and-offset-clauses) and while DuckDB allows you to swap them, switching them up is not tracked by prepared statements, causing a mixup. This is similar to issue #13585, where switching up the `SELECT` and `FROM` clauses caused prepared statements to evaluate incorrectly.\r\n\r\nFor now, a workaround is to use `LIMIT ... OFFSET`. As this is a bug that can lead to uncorrect results, we'll fix it for the next release.\r\n\nThanks for the quick reply - will switch to the \"preferred order\" to avoid my code stop working once the problem is fixed!\n@javafanboy no need to close issues before they are actually fixed - that only increases the chance they'll slip through unfixed. \nhi @szarnyasg, I would like to work on this issue. I have identified the potential fix for this.\r\nPlease assign this issue to me.\n@ashwaniYDV thanks for offering your contribution! I assigned you. Please tag me in the PR of the proposed fix once it's ready to review.\nHi @javafanboy, thanks for reporting this! The issue can be reproduced in the DuckDB CLI client:\r\n\r\n```sql\r\nPREPARE q AS SELECT x FROM generate_series(1, 10) t(x) OFFSET ? LIMIT ?;\r\nEXECUTE q(3, 5);\r\n```\r\n```text\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502   x   \u2502\r\n\u2502 int64 \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502     6 \u2502\r\n\u2502     7 \u2502\r\n\u2502     8 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\nThe reason you're experiencing this issue is that the default order of these clauses is [`LIMIT` followed by `OFFSET`](https://duckdb.org/docs/sql/statements/select#order-by-limit-and-offset-clauses) and while DuckDB allows you to swap them, switching them up is not tracked by prepared statements, causing a mixup. This is similar to issue #13585, where switching up the `SELECT` and `FROM` clauses caused prepared statements to evaluate incorrectly.\r\n\r\nFor now, a workaround is to use `LIMIT ... OFFSET`. As this is a bug that can lead to uncorrect results, we'll fix it for the next release.\r\n\nThanks for the quick reply - will switch to the \"preferred order\" to avoid my code stop working once the problem is fixed!\n@javafanboy no need to close issues before they are actually fixed - that only increases the chance they'll slip through unfixed. \nhi @szarnyasg, I would like to work on this issue. I have identified the potential fix for this.\r\nPlease assign this issue to me.\n@ashwaniYDV thanks for offering your contribution! I assigned you. Please tag me in the PR of the proposed fix once it's ready to review.", "created_at": "2024-12-28T17:05:31Z"}
{"repo": "duckdb/duckdb", "pull_number": 15297, "instance_id": "duckdb__duckdb-15297", "issue_numbers": ["14938", "14938"], "base_commit": "4ca094fa6370d5bc7893ca156db422082b9a5528", "patch": "diff --git a/src/catalog/catalog.cpp b/src/catalog/catalog.cpp\nindex 6168967d764d..53a31ac389b5 100644\n--- a/src/catalog/catalog.cpp\n+++ b/src/catalog/catalog.cpp\n@@ -862,7 +862,7 @@ CatalogEntryLookup Catalog::TryLookupEntry(CatalogEntryRetriever &retriever, Cat\n \t// lookup\n \tif (type == CatalogType::TABLE_ENTRY) {\n \t\tauto lookup_result_default_table =\n-\t\t    TryLookupDefaultTable(retriever, type, catalog, schema, name, if_not_found, error_context);\n+\t\t    TryLookupDefaultTable(retriever, type, catalog, schema, name, OnEntryNotFound::RETURN_NULL, error_context);\n \n \t\tif (lookup_result_default_table.Found() && lookup_result.Found()) {\n \t\t\tThrowDefaultTableAmbiguityException(lookup_result, lookup_result_default_table, name);\ndiff --git a/src/common/types.cpp b/src/common/types.cpp\nindex 7ec718928038..474fc2848cbe 100644\n--- a/src/common/types.cpp\n+++ b/src/common/types.cpp\n@@ -887,14 +887,8 @@ LogicalType LogicalType::NormalizeType(const LogicalType &type) {\n template <class OP>\n static bool CombineUnequalTypes(const LogicalType &left, const LogicalType &right, LogicalType &result) {\n \t// left and right are not equal\n-\t// for enums, match the varchar rules\n-\tif (left.id() == LogicalTypeId::ENUM) {\n-\t\treturn OP::Operation(LogicalType::VARCHAR, right, result);\n-\t} else if (right.id() == LogicalTypeId::ENUM) {\n-\t\treturn OP::Operation(left, LogicalType::VARCHAR, result);\n-\t}\n-\t// NULL/string literals/unknown (parameter) types always take the other type\n-\tLogicalTypeId other_types[] = {LogicalTypeId::SQLNULL, LogicalTypeId::UNKNOWN, LogicalTypeId::STRING_LITERAL};\n+\t// NULL/unknown (parameter) types always take the other type\n+\tLogicalTypeId other_types[] = {LogicalTypeId::SQLNULL, LogicalTypeId::UNKNOWN};\n \tfor (auto &other_type : other_types) {\n \t\tif (left.id() == other_type) {\n \t\t\tresult = LogicalType::NormalizeType(right);\n@@ -905,6 +899,22 @@ static bool CombineUnequalTypes(const LogicalType &left, const LogicalType &righ\n \t\t}\n \t}\n \n+\t// for enums, match the varchar rules\n+\tif (left.id() == LogicalTypeId::ENUM) {\n+\t\treturn OP::Operation(LogicalType::VARCHAR, right, result);\n+\t} else if (right.id() == LogicalTypeId::ENUM) {\n+\t\treturn OP::Operation(left, LogicalType::VARCHAR, result);\n+\t}\n+\n+\t// for everything but enums - string literals also take the other type\n+\tif (left.id() == LogicalTypeId::STRING_LITERAL) {\n+\t\tresult = LogicalType::NormalizeType(right);\n+\t\treturn true;\n+\t} else if (right.id() == LogicalTypeId::STRING_LITERAL) {\n+\t\tresult = LogicalType::NormalizeType(left);\n+\t\treturn true;\n+\t}\n+\n \t// for other types - use implicit cast rules to check if we can combine the types\n \tauto left_to_right_cost = CastRules::ImplicitCast(left, right);\n \tauto right_to_left_cost = CastRules::ImplicitCast(right, left);\n", "test_patch": "diff --git a/test/sql/types/enum/test_enum_case.test b/test/sql/types/enum/test_enum_case.test\nnew file mode 100644\nindex 000000000000..8c2da50c08a1\n--- /dev/null\n+++ b/test/sql/types/enum/test_enum_case.test\n@@ -0,0 +1,20 @@\n+# name: test/sql/types/enum/test_enum_case.test\n+# description: Test enum in CASE expressions\n+# group: [enum]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+CREATE TYPE E1 AS ENUM ('v1', 'v2');\n+\n+statement ok\n+CREATE TABLE t1 (v E1);\n+\n+statement ok\n+INSERT INTO t1 VALUES ('v1');\n+\n+query I\n+SELECT typeof(CASE WHEN 1 THEN v END) FROM t1;\n+----\n+ENUM('v1', 'v2')\n", "problem_statement": "Unexpected implicit cast when using CASE WHEN\n### What happens?\r\n\r\nI am observing some unexpected type casting when using CASE WHEN in a query.\r\n\r\nWhen using an ENUM-typed variable inside a CASE WHEN check, the resulting value will be of type VARCHAR instead of ENUM,  which is unnecessary and wrong in my opinion.\r\n\r\n### To Reproduce\r\n\r\n```sql\r\nCREATE TYPE E1 AS ENUM ('v1', 'v2');\r\nCREATE TABLE t1 (v E1);\r\nINSERT INTO t1 VALUES ('v1');\r\nINSERT INTO t1 VALUES ('v1');\r\nINSERT INTO t1 VALUES ('v1');\r\n\r\n-- This returns a result only if all elements in a column are equal (namely this value), otherwise it should return NULL.\r\nDESCRIBE (SELECT CASE WHEN COUNT(DISTINCT v) == 1 THEN FIRST(v) END AS r FROM t1);\r\n```\r\nOutput:\r\n```\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 column_name \u2506 column_type \u2506 null \u2506 key \u2506 default \u2506 extra \u2502\r\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\r\n\u2502 r           \u2506 VARCHAR     \u2506 YES  \u2506     \u2506         \u2506       \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\nI expect the column type to be of ENUM E1 type, not VARCHAR.\r\n\r\n### OS:\r\n\r\nMS Windows 10, x64\r\n\r\n### DuckDB Version:\r\n\r\n1.1.3\r\n\r\n### DuckDB Client:\r\n\r\nR, WASM\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\nLukas Schneiderbauer\r\n\r\n### Affiliation:\r\n\r\nNone\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\nUnexpected implicit cast when using CASE WHEN\n### What happens?\r\n\r\nI am observing some unexpected type casting when using CASE WHEN in a query.\r\n\r\nWhen using an ENUM-typed variable inside a CASE WHEN check, the resulting value will be of type VARCHAR instead of ENUM,  which is unnecessary and wrong in my opinion.\r\n\r\n### To Reproduce\r\n\r\n```sql\r\nCREATE TYPE E1 AS ENUM ('v1', 'v2');\r\nCREATE TABLE t1 (v E1);\r\nINSERT INTO t1 VALUES ('v1');\r\nINSERT INTO t1 VALUES ('v1');\r\nINSERT INTO t1 VALUES ('v1');\r\n\r\n-- This returns a result only if all elements in a column are equal (namely this value), otherwise it should return NULL.\r\nDESCRIBE (SELECT CASE WHEN COUNT(DISTINCT v) == 1 THEN FIRST(v) END AS r FROM t1);\r\n```\r\nOutput:\r\n```\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 column_name \u2506 column_type \u2506 null \u2506 key \u2506 default \u2506 extra \u2502\r\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\r\n\u2502 r           \u2506 VARCHAR     \u2506 YES  \u2506     \u2506         \u2506       \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\nI expect the column type to be of ENUM E1 type, not VARCHAR.\r\n\r\n### OS:\r\n\r\nMS Windows 10, x64\r\n\r\n### DuckDB Version:\r\n\r\n1.1.3\r\n\r\n### DuckDB Client:\r\n\r\nR, WASM\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\nLukas Schneiderbauer\r\n\r\n### Affiliation:\r\n\r\nNone\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\n", "hints_text": "duplicate of https://github.com/duckdb/duckdb/issues/14935\nduplicate of https://github.com/duckdb/duckdb/issues/14935", "created_at": "2024-12-12T10:48:24Z"}
{"repo": "duckdb/duckdb", "pull_number": 15287, "instance_id": "duckdb__duckdb-15287", "issue_numbers": ["15183", "15183"], "base_commit": "4a8188effcf664085eedf723996a90dc870a7d7e", "patch": "diff --git a/extension/core_functions/scalar/generic/least.cpp b/extension/core_functions/scalar/generic/least.cpp\nindex 8dcb64344f5e..e9df9872829c 100644\n--- a/extension/core_functions/scalar/generic/least.cpp\n+++ b/extension/core_functions/scalar/generic/least.cpp\n@@ -5,6 +5,22 @@\n \n namespace duckdb {\n \n+struct LeastOp {\n+\tusing OP = LessThan;\n+\n+\tstatic OrderByNullType NullOrdering() {\n+\t\treturn OrderByNullType::NULLS_LAST;\n+\t}\n+};\n+\n+struct GreaterOp {\n+\tusing OP = GreaterThan;\n+\n+\tstatic OrderByNullType NullOrdering() {\n+\t\treturn OrderByNullType::NULLS_FIRST;\n+\t}\n+};\n+\n template <class OP>\n struct LeastOperator {\n \ttemplate <class T>\n@@ -14,8 +30,8 @@ struct LeastOperator {\n };\n \n struct LeastGreatestSortKeyState : public FunctionLocalState {\n-\texplicit LeastGreatestSortKeyState(idx_t column_count)\n-\t    : intermediate(LogicalType::BLOB), modifiers(OrderType::ASCENDING, OrderByNullType::NULLS_LAST) {\n+\texplicit LeastGreatestSortKeyState(idx_t column_count, OrderByNullType null_ordering)\n+\t    : intermediate(LogicalType::BLOB), modifiers(OrderType::ASCENDING, null_ordering) {\n \t\tvector<LogicalType> types;\n \t\t// initialize sort key chunk\n \t\tfor (idx_t i = 0; i < column_count; i++) {\n@@ -29,9 +45,10 @@ struct LeastGreatestSortKeyState : public FunctionLocalState {\n \tOrderModifiers modifiers;\n };\n \n+template <class OP>\n unique_ptr<FunctionLocalState> LeastGreatestSortKeyInit(ExpressionState &state, const BoundFunctionExpression &expr,\n                                                         FunctionData *bind_data) {\n-\treturn make_uniq<LeastGreatestSortKeyState>(expr.children.size());\n+\treturn make_uniq<LeastGreatestSortKeyState>(expr.children.size(), OP::NullOrdering());\n }\n \n template <bool STRING>\n@@ -155,7 +172,7 @@ static void LeastGreatestFunction(DataChunk &args, ExpressionState &state, Vecto\n \tresult.SetVectorType(result_type);\n }\n \n-template <class OP>\n+template <class LEAST_GREATER_OP>\n unique_ptr<FunctionData> BindLeastGreatest(ClientContext &context, ScalarFunction &bound_function,\n                                            vector<unique_ptr<Expression>> &arguments) {\n \tLogicalType child_type = ExpressionBinder::GetExpressionReturnType(*arguments[0]);\n@@ -179,7 +196,9 @@ unique_ptr<FunctionData> BindLeastGreatest(ClientContext &context, ScalarFunctio\n \tdefault:\n \t\tbreak;\n \t}\n+\tusing OP = typename LEAST_GREATER_OP::OP;\n \tswitch (child_type.InternalType()) {\n+#ifndef DUCKDB_SMALLER_BINARY\n \tcase PhysicalType::BOOL:\n \tcase PhysicalType::INT8:\n \t\tbound_function.function = LeastGreatestFunction<int8_t, OP>;\n@@ -202,10 +221,11 @@ unique_ptr<FunctionData> BindLeastGreatest(ClientContext &context, ScalarFunctio\n \tcase PhysicalType::VARCHAR:\n \t\tbound_function.function = LeastGreatestFunction<string_t, OP, StandardLeastGreatest<true>>;\n \t\tbreak;\n+#endif\n \tdefault:\n \t\t// fallback with sort keys\n \t\tbound_function.function = LeastGreatestFunction<string_t, OP, SortKeyLeastGreatest>;\n-\t\tbound_function.init_local_state = LeastGreatestSortKeyInit;\n+\t\tbound_function.init_local_state = LeastGreatestSortKeyInit<LEAST_GREATER_OP>;\n \t\tbreak;\n \t}\n \tbound_function.arguments[0] = child_type;\n@@ -229,11 +249,11 @@ static ScalarFunctionSet GetLeastGreatestFunctions() {\n }\n \n ScalarFunctionSet LeastFun::GetFunctions() {\n-\treturn GetLeastGreatestFunctions<LessThan>();\n+\treturn GetLeastGreatestFunctions<LeastOp>();\n }\n \n ScalarFunctionSet GreatestFun::GetFunctions() {\n-\treturn GetLeastGreatestFunctions<GreaterThan>();\n+\treturn GetLeastGreatestFunctions<GreaterOp>();\n }\n \n } // namespace duckdb\ndiff --git a/src/common/types/column/column_data_collection_segment.cpp b/src/common/types/column/column_data_collection_segment.cpp\nindex f8b0c1583dd9..1ec0f6f45900 100644\n--- a/src/common/types/column/column_data_collection_segment.cpp\n+++ b/src/common/types/column/column_data_collection_segment.cpp\n@@ -216,7 +216,6 @@ idx_t ColumnDataCollectionSegment::ReadVector(ChunkManagementState &state, Vecto\n \t\tauto &child_vector = ListVector::GetEntry(result);\n \t\tauto child_count = ReadVector(state, GetChildIndex(vdata.child_index), child_vector);\n \t\tListVector::SetListSize(result, child_count);\n-\n \t} else if (internal_type == PhysicalType::ARRAY) {\n \t\tauto &child_vector = ArrayVector::GetEntry(result);\n \t\tauto child_count = ReadVector(state, GetChildIndex(vdata.child_index), child_vector);\n", "test_patch": "diff --git a/test/sql/function/generic/test_least_greatest.test b/test/sql/function/generic/test_least_greatest.test\nindex e743f1888f81..22edc46a8e7c 100644\n--- a/test/sql/function/generic/test_least_greatest.test\n+++ b/test/sql/function/generic/test_least_greatest.test\n@@ -41,6 +41,11 @@ SELECT LEAST(NULL, 3, 0, 2, 7, 8, 10, 11, -100, 30, 1)\n ----\n -100\n \n+query I\n+SELECT GREATEST(NULL, 1.0::FLOAT)\n+----\n+1\n+\n # double\n query R\n SELECT LEAST(1.0, 10.0)\n", "problem_statement": "PostgreSQL incompatibility and inconsistency: Floating point version of `greatest` doesn't ignore `NULL`s\n### What happens?\r\n\r\nIn PostgreSQL, `greatest(var1, ..., varn)` and `least(var1, ..., varn)` return the greatest and least non-`NULL` arguments, respectively, for all data-types.\r\n\r\nIn DuckDB, this is true with the exception of only the `greatest` function on floating point datatypes, which returns `NULL` when any argument is `NULL`. \r\n\r\n(FWIW, [the recent SQL standards](https://modern-sql.com/caniuse/greatest-least#null) specify that `greatest` and `least` should always propagate `NULL`s, but I think this can be safely ignored since they did this after a lot of dialects already had made their choices, it doesn't seem like any other system changed in response to this, and certainly DuckDB doesn't seem to adhere to this anywhere else except for the floating point version of `greatest`.) \r\n\r\nPS: This is part two - report bug - of my dissection of https://github.com/duckdb/duckdb/issues/14239, which I closed for being too chaotic.\r\n\r\n### To Reproduce\r\n\r\n```sql\r\nSELECT \r\ngreatest(0::FLOAT, NULL), -- DuckDB returns NULL; PostgreSQL returns 0 \r\nleast(0::FLOAT, NULL), -- both DuckDB and PostgreSQL return 0\r\ngreatest(0::INT, NULL), -- both DuckDB and PostgreSQL return 0\r\nleast(0::INT, NULL) -- both DuckDB and PostgreSQL return 0\r\n```\r\n\r\n### OS:\r\n\r\nUbuntu 20.04, x86_64\r\n\r\n### DuckDB Version:\r\n\r\n1.1.3\r\n\r\n### DuckDB Client:\r\n\r\nPython\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\nSoeren Wolfers\r\n\r\n### Affiliation:\r\n\r\nG-Research\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nNot applicable - the reproduction does not require a data set\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\nPostgreSQL incompatibility and inconsistency: Floating point version of `greatest` doesn't ignore `NULL`s\n### What happens?\r\n\r\nIn PostgreSQL, `greatest(var1, ..., varn)` and `least(var1, ..., varn)` return the greatest and least non-`NULL` arguments, respectively, for all data-types.\r\n\r\nIn DuckDB, this is true with the exception of only the `greatest` function on floating point datatypes, which returns `NULL` when any argument is `NULL`. \r\n\r\n(FWIW, [the recent SQL standards](https://modern-sql.com/caniuse/greatest-least#null) specify that `greatest` and `least` should always propagate `NULL`s, but I think this can be safely ignored since they did this after a lot of dialects already had made their choices, it doesn't seem like any other system changed in response to this, and certainly DuckDB doesn't seem to adhere to this anywhere else except for the floating point version of `greatest`.) \r\n\r\nPS: This is part two - report bug - of my dissection of https://github.com/duckdb/duckdb/issues/14239, which I closed for being too chaotic.\r\n\r\n### To Reproduce\r\n\r\n```sql\r\nSELECT \r\ngreatest(0::FLOAT, NULL), -- DuckDB returns NULL; PostgreSQL returns 0 \r\nleast(0::FLOAT, NULL), -- both DuckDB and PostgreSQL return 0\r\ngreatest(0::INT, NULL), -- both DuckDB and PostgreSQL return 0\r\nleast(0::INT, NULL) -- both DuckDB and PostgreSQL return 0\r\n```\r\n\r\n### OS:\r\n\r\nUbuntu 20.04, x86_64\r\n\r\n### DuckDB Version:\r\n\r\n1.1.3\r\n\r\n### DuckDB Client:\r\n\r\nPython\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\nSoeren Wolfers\r\n\r\n### Affiliation:\r\n\r\nG-Research\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nNot applicable - the reproduction does not require a data set\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\n", "hints_text": "\n", "created_at": "2024-12-11T15:09:29Z"}
{"repo": "duckdb/duckdb", "pull_number": 15277, "instance_id": "duckdb__duckdb-15277", "issue_numbers": ["15267"], "base_commit": "9489881191eba8af452b94120d542c09b3ffd0c1", "patch": "diff --git a/tools/pythonpkg/src/include/duckdb_python/expression/pyexpression.hpp b/tools/pythonpkg/src/include/duckdb_python/expression/pyexpression.hpp\nindex c7b9387e96a8..b89578af25bc 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/expression/pyexpression.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/expression/pyexpression.hpp\n@@ -1,7 +1,7 @@\n //===----------------------------------------------------------------------===//\n //                         DuckDB\n //\n-// duckdb_python/pyrelation.hpp\n+// duckdb_python/expression/pyexpression.hpp\n //\n //\n //===----------------------------------------------------------------------===//\ndiff --git a/tools/pythonpkg/src/pyrelation.cpp b/tools/pythonpkg/src/pyrelation.cpp\nindex 723d6a9274ae..cb4b8032e02d 100644\n--- a/tools/pythonpkg/src/pyrelation.cpp\n+++ b/tools/pythonpkg/src/pyrelation.cpp\n@@ -1023,13 +1023,27 @@ unique_ptr<DuckDBPyRelation> DuckDBPyRelation::GetAttribute(const string &name)\n \t\tthrow py::attribute_error(\n \t\t    StringUtil::Format(\"This relation does not contain a column by the name of '%s'\", name));\n \t}\n+\tvector<string> column_names;\n \tif (names.size() == 1 && ContainsStructFieldByName(types[0], name)) {\n-\t\treturn make_uniq<DuckDBPyRelation>(rel->Project({StringUtil::Format(\"%s.%s\", names[0], name)}));\n+\t\t// e.g 'rel['my_struct']['my_field']:\n+\t\t// first 'my_struct' is selected by the bottom condition\n+\t\t// then 'my_field' is accessed on the result of this\n+\t\tcolumn_names.push_back(names[0]);\n+\t\tcolumn_names.push_back(name);\n+\t} else if (ContainsColumnByName(name)) {\n+\t\tcolumn_names.push_back(name);\n \t}\n-\tif (ContainsColumnByName(name)) {\n-\t\treturn make_uniq<DuckDBPyRelation>(rel->Project({StringUtil::Format(\"\\\"%s\\\"\", name)}));\n+\n+\tif (column_names.empty()) {\n+\t\tthrow py::attribute_error(\n+\t\t    StringUtil::Format(\"This relation does not contain a column by the name of '%s'\", name));\n \t}\n-\tthrow py::attribute_error(StringUtil::Format(\"This relation does not contain a column by the name of '%s'\", name));\n+\n+\tvector<unique_ptr<ParsedExpression>> expressions;\n+\texpressions.push_back(std::move(make_uniq<ColumnRefExpression>(column_names)));\n+\tvector<string> aliases;\n+\taliases.push_back(name);\n+\treturn make_uniq<DuckDBPyRelation>(rel->Project(std::move(expressions), aliases));\n }\n \n unique_ptr<DuckDBPyRelation> DuckDBPyRelation::Union(DuckDBPyRelation *other) {\n", "test_patch": "diff --git a/tools/pythonpkg/tests/fast/api/test_attribute_getter.py b/tools/pythonpkg/tests/fast/api/test_attribute_getter.py\nindex 795e26e9c834..958e8892c512 100644\n--- a/tools/pythonpkg/tests/fast/api/test_attribute_getter.py\n+++ b/tools/pythonpkg/tests/fast/api/test_attribute_getter.py\n@@ -57,3 +57,7 @@ def test_getattr_struct(self, duckdb_cursor):\n     def test_getattr_spaces(self, duckdb_cursor):\n         rel = duckdb_cursor.sql('select 42 as \"hello world\"')\n         assert rel['hello world'].fetchall()[0][0] == 42\n+\n+    def test_getattr_doublequotes(self, duckdb_cursor):\n+        rel = duckdb_cursor.sql('select 1 as \"tricky\"\", \"\"quotes\", 2 as tricky, 3 as quotes')\n+        assert rel[rel.columns[0]].fetchone() == (1,)\n", "problem_statement": "unescaped double-quote in column lookup in Python relational API\n### What happens?\r\n\r\nWhen using the python relational API, column names with `\"` in them don't seem to be escaped properly.\r\n\r\n### To Reproduce\r\n\r\npython code:\r\n\r\n```\r\nimport duckdb\r\nc = duckdb.connect()\r\nt = c.sql('select 1 as \"tricky\"\", \"\"quotes\", 2 as tricky, 3 as quotes')\r\n\r\nprint(\"t:\")\r\nprint(t)\r\n\r\nprint(\"t[t.columns[0]]:\")\r\nprint(t[t.columns[0]])\r\n```\r\n\r\noutput:\r\n\r\n```\r\nt:\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 tricky\", \"quotes \u2502 tricky \u2502 quotes \u2502\r\n\u2502      int32       \u2502 int32  \u2502 int32  \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502                1 \u2502      2 \u2502      3 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\nt[t.columns[0]]:\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 tricky \u2502 quotes \u2502\r\n\u2502 int32  \u2502 int32  \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502      2 \u2502      3 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\nIt looks like internally it's translating that lookup to `SELECT \"tricky\", \"quotes\"` instead of the correct `SELECT \"tricky\"\", \"\"quotes\"`\r\n\r\n### OS:\r\n\r\nLinux 6.8.0-49-generic x86_64\r\n\r\n### DuckDB Version:\r\n\r\n1.1.3 \r\n\r\nUPDATE: Also 1.1.4-dev3247\r\n\r\n### DuckDB Client:\r\n\r\nPython, on Python 3.12.3\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\nNick Moore\r\n\r\n### Affiliation:\r\n\r\nMnemote Pty Ltd\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\nUPDATE: Also 1.1.4-dev3247\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [x] Yes, I have\n", "hints_text": "The python client is not doing anything special here, this is the same result you'd get with the CLI for this query.\r\n\r\nAs seen by your result, every quote you intend to escape should be doubled\nYep, and in SQL / the CLI that makes sense.  But the within the Python API, the `[]` operator should be doing the quoting for you, and `t[t.columns[0]]` should always get the first column!\r\n\r\nAs it is, it does do *some* quoting when constructing the query, it seems to be inserting `\"` before and after the identifier, just not escaping `\"` to `\"\"` within the identifier.\r\n\r\n```\r\n>>> t['\"foo\"']\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nduckdb.duckdb.ParserException: Parser Error: zero-length delimited identifier at or near \"\"\"\"\r\n```\r\n\nHi @nickzoic thanks for opening this. I could reproduce it as follows:\r\n\r\n```python\r\nimport duckdb\r\nt=  duckdb.sql('select 1 as \"hello \"\"quoted\"\" world\", 2 as asd, 3 as qwe;')\r\nprint(t[t.columns[0]])\r\n```\r\n\r\n```console\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nduckdb.duckdb.ParserException: Parser Error: syntax error at or near \"\" world\"\"\r\n```", "created_at": "2024-12-11T09:52:18Z"}
