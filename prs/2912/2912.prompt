You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
Tests for dataset roundtrip with Arrow
We've been working on enabling true streaming with DuckDB <-> Arrow in R and haven't been able to get it quite right (you can see some of the stuff we're running into at https://github.com/apache/arrow/pull/11730).

As part of that process I tried to write some python tests to see if I can confirm it's an (Arrow or DuckDB) R package issue, or if it is something more widespread. 

I've seen the two following two errors in alternation on this test when running it locally. The IOError: Query Stream is closed is something we've seen on the R side as well.

Any thoughts on what might be causing this?

<details>
```
tests/fast/arrow/test_dataset.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
pyarrow/ipc.pxi:524: in pyarrow.lib._ReadPandasMixin.read_pandas
    ???
pyarrow/ipc.pxi:587: in pyarrow.lib.RecordBatchReader.read_all
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   OSError: Query Stream is closed

pyarrow/error.pxi:114: OSError
```


```
tests/fast/arrow/test_dataset.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
pyarrow/ipc.pxi:525: in pyarrow.lib._ReadPandasMixin.read_pandas
    ???
pyarrow/array.pxi:766: in pyarrow.lib._PandasConvertible.to_pandas
    ???
pyarrow/table.pxi:1815: in pyarrow.lib.Table._to_pandas
    ???
../../../../envs/duckdb/lib/python3.9/site-packages/pyarrow/pandas_compat.py:789: in table_to_blockmanager
    blocks = _table_to_blocks(options, table, categories, ext_columns_dtypes)
../../../../envs/duckdb/lib/python3.9/site-packages/pyarrow/pandas_compat.py:1128: in _table_to_blocks
    result = pa.lib.table_to_blocks(options, block_table, categories,
pyarrow/table.pxi:1225: in pyarrow.lib.table_to_blocks
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   pyarrow.lib.ArrowException: Unknown error: Wrapping Pï¿½id@com.com failed

pyarrow/error.pxi:137: ArrowException
```
</details>

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
3: </div>
4: <p>&nbsp;</p>
5: 
6: <p align="center">
7:   <a href="https://github.com/duckdb/duckdb/actions">
8:     <img src="https://github.com/cwida/duckdb/workflows/.github/workflows/main.yml/badge.svg?branch=master" alt=".github/workflows/main.yml">
9:   </a>
10:   <a href="https://www.codefactor.io/repository/github/cwida/duckdb">
11:     <img src="https://www.codefactor.io/repository/github/cwida/duckdb/badge" alt="CodeFactor"/>
12:   </a>
13:   <a href="https://app.codecov.io/gh/duckdb/duckdb">
14:     <img src="https://codecov.io/gh/duckdb/duckdb/branch/master/graph/badge.svg?token=FaxjcfFghN" alt="codecov"/>
15:   </a>
16:   <a href="https://discord.gg/tcvwpjfnZx">
17:     <img src="https://shields.io/discord/909674491309850675" alt="discord" />
18:   </a>
19: </p>
20: 
21: ## DuckDB
22: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on the goals of DuckDB, please refer to [the Why DuckDB page on our website](https://duckdb.org/docs/why_duckdb.html).
23: 
24: ## Installation
25: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
26: 
27: ## Data Import
28: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
29: 
30: ```sql
31: SELECT * FROM 'myfile.csv';
32: SELECT * FROM 'myfile.parquet';
33: ```
34: 
35: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
36: 
37: ## SQL Reference
38: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
39: 
40: ## Development
41: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`.
42: 
43: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
44: 
45: 
[end of README.md]
[start of src/common/arrow_wrapper.cpp]
1: #include "duckdb/common/arrow_wrapper.hpp"
2: 
3: #include "duckdb/common/assert.hpp"
4: #include "duckdb/common/exception.hpp"
5: 
6: #include "duckdb/main/stream_query_result.hpp"
7: namespace duckdb {
8: 
9: ArrowSchemaWrapper::~ArrowSchemaWrapper() {
10: 	if (arrow_schema.release) {
11: 		for (int64_t child_idx = 0; child_idx < arrow_schema.n_children; child_idx++) {
12: 			auto &child = *arrow_schema.children[child_idx];
13: 			if (child.release) {
14: 				child.release(&child);
15: 			}
16: 		}
17: 		arrow_schema.release(&arrow_schema);
18: 		arrow_schema.release = nullptr;
19: 	}
20: }
21: 
22: ArrowArrayWrapper::~ArrowArrayWrapper() {
23: 	if (arrow_array.release) {
24: 		for (int64_t child_idx = 0; child_idx < arrow_array.n_children; child_idx++) {
25: 			auto &child = *arrow_array.children[child_idx];
26: 			if (child.release) {
27: 				child.release(&child);
28: 			}
29: 		}
30: 		arrow_array.release(&arrow_array);
31: 		arrow_array.release = nullptr;
32: 	}
33: }
34: 
35: ArrowArrayStreamWrapper::~ArrowArrayStreamWrapper() {
36: 	if (arrow_array_stream.release) {
37: 		arrow_array_stream.release(&arrow_array_stream);
38: 		arrow_array_stream.release = nullptr;
39: 	}
40: }
41: 
42: void ArrowArrayStreamWrapper::GetSchema(ArrowSchemaWrapper &schema) {
43: 	D_ASSERT(arrow_array_stream.get_schema);
44: 	// LCOV_EXCL_START
45: 	if (arrow_array_stream.get_schema(&arrow_array_stream, &schema.arrow_schema)) {
46: 		throw InvalidInputException("arrow_scan: get_schema failed(): %s", string(GetError()));
47: 	}
48: 	if (!schema.arrow_schema.release) {
49: 		throw InvalidInputException("arrow_scan: released schema passed");
50: 	}
51: 	if (schema.arrow_schema.n_children < 1) {
52: 		throw InvalidInputException("arrow_scan: empty schema passed");
53: 	}
54: 	// LCOV_EXCL_STOP
55: }
56: 
57: unique_ptr<ArrowArrayWrapper> ArrowArrayStreamWrapper::GetNextChunk() {
58: 	auto current_chunk = make_unique<ArrowArrayWrapper>();
59: 	if (arrow_array_stream.get_next(&arrow_array_stream, &current_chunk->arrow_array)) { // LCOV_EXCL_START
60: 		throw InvalidInputException("arrow_scan: get_next failed(): %s", string(GetError()));
61: 	} // LCOV_EXCL_STOP
62: 
63: 	return current_chunk;
64: }
65: 
66: const char *ArrowArrayStreamWrapper::GetError() { // LCOV_EXCL_START
67: 	return arrow_array_stream.get_last_error(&arrow_array_stream);
68: } // LCOV_EXCL_STOP
69: 
70: int ResultArrowArrayStreamWrapper::MyStreamGetSchema(struct ArrowArrayStream *stream, struct ArrowSchema *out) {
71: 	if (!stream->release) {
72: 		return -1;
73: 	}
74: 	auto my_stream = (ResultArrowArrayStreamWrapper *)stream->private_data;
75: 	auto &result = *my_stream->result;
76: 	if (!result.success) {
77: 		my_stream->last_error = "Query Failed";
78: 		return -1;
79: 	}
80: 	if (result.type == QueryResultType::STREAM_RESULT) {
81: 		auto &stream_result = (StreamQueryResult &)result;
82: 		if (!stream_result.IsOpen()) {
83: 			my_stream->last_error = "Query Stream is closed";
84: 			return -1;
85: 		}
86: 	}
87: 	result.ToArrowSchema(out);
88: 	return 0;
89: }
90: 
91: int ResultArrowArrayStreamWrapper::MyStreamGetNext(struct ArrowArrayStream *stream, struct ArrowArray *out) {
92: 	if (!stream->release) {
93: 		return -1;
94: 	}
95: 	auto my_stream = (ResultArrowArrayStreamWrapper *)stream->private_data;
96: 	auto &result = *my_stream->result;
97: 	if (!result.success) {
98: 		my_stream->last_error = "Query Failed";
99: 		return -1;
100: 	}
101: 	if (result.type == QueryResultType::STREAM_RESULT) {
102: 		auto &stream_result = (StreamQueryResult &)result;
103: 		if (!stream_result.IsOpen()) {
104: 			my_stream->last_error = "Query Stream is closed";
105: 			return -1;
106: 		}
107: 	}
108: 	unique_ptr<DataChunk> chunk_result = result.Fetch();
109: 	if (!chunk_result) {
110: 		// Nothing to output
111: 		out->release = nullptr;
112: 		return 0;
113: 	}
114: 	for (idx_t i = 1; i < my_stream->vectors_per_chunk; i++) {
115: 		auto new_chunk = result.Fetch();
116: 		if (!new_chunk) {
117: 			break;
118: 		} else {
119: 			chunk_result->Append(*new_chunk, true);
120: 		}
121: 	}
122: 	chunk_result->ToArrowArray(out);
123: 	return 0;
124: }
125: 
126: void ResultArrowArrayStreamWrapper::MyStreamRelease(struct ArrowArrayStream *stream) {
127: 	if (!stream->release) {
128: 		return;
129: 	}
130: 	stream->release = nullptr;
131: 	delete (ResultArrowArrayStreamWrapper *)stream->private_data;
132: }
133: 
134: const char *ResultArrowArrayStreamWrapper::MyStreamGetLastError(struct ArrowArrayStream *stream) {
135: 	if (!stream->release) {
136: 		return "stream was released";
137: 	}
138: 	D_ASSERT(stream->private_data);
139: 	auto my_stream = (ResultArrowArrayStreamWrapper *)stream->private_data;
140: 	return my_stream->last_error.c_str();
141: }
142: ResultArrowArrayStreamWrapper::ResultArrowArrayStreamWrapper(unique_ptr<QueryResult> result_p, idx_t approx_batch_size)
143:     : result(move(result_p)) {
144: 	//! We first initialize the private data of the stream
145: 	stream.private_data = this;
146: 	//! Ceil Approx_Batch_Size/STANDARD_VECTOR_SIZE
147: 	if (approx_batch_size == 0) {
148: 		throw std::runtime_error("Approximate Batch Size of Record Batch MUST be higher than 0");
149: 	}
150: 	vectors_per_chunk = (approx_batch_size + STANDARD_VECTOR_SIZE - 1) / STANDARD_VECTOR_SIZE;
151: 	//! We initialize the stream functions
152: 	stream.get_schema = ResultArrowArrayStreamWrapper::MyStreamGetSchema;
153: 	stream.get_next = ResultArrowArrayStreamWrapper::MyStreamGetNext;
154: 	stream.release = ResultArrowArrayStreamWrapper::MyStreamRelease;
155: 	stream.get_last_error = ResultArrowArrayStreamWrapper::MyStreamGetLastError;
156: }
157: 
158: } // namespace duckdb
[end of src/common/arrow_wrapper.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: