You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
Auto DataFrame scans give too much access to server data
**What does happen?**
When DuckDB is used in a server environment, the automatic Pandas DataFrame, csv, and parquet scan capabilities grant too much authority on the server to users and is a security risk. The read_csv and read_csv_auto, as well as the parquet reader also have the same issue.
There is a related issue here: [#823](https://github.com/duckdb/duckdb/pull/823) 

**What should happen?**
We would love a configuration option that is accessible from the Python API to disable these features. Our code should need to register a table or a file prior to DuckDB querying it so that we can appropriately control permission to files and DataFrames on the server. 

**To Reproduce**
Access a Pandas DataFrame without registering it.

**Environment (please complete the following information):**
 - OS: Windows
 - DuckDB Version 0.2.6

**Before submitting**
- [X] Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?
- [X] Have you tried this on the latest `master` branch? In case you cannot compile, you may find some binaries here: https://github.com/duckdb/duckdb/releases/tag/master-builds


</issue>
<code>
[start of README.md]
1: <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
2: 
3: ![.github/workflows/main.yml](https://github.com/cwida/duckdb/workflows/.github/workflows/main.yml/badge.svg?branch=master)
4: [![CodeFactor](https://www.codefactor.io/repository/github/cwida/duckdb/badge)](https://www.codefactor.io/repository/github/cwida/duckdb)
5: [![Coverage Status](https://coveralls.io/repos/github/cwida/duckdb/badge.svg?branch=master)](https://coveralls.io/github/cwida/duckdb?branch=master)
6: 
7: 
8: ## Installation
9: If you just want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
10: 
11: ## Development
12: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`.
13: 
14: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
15: 
16: 
[end of README.md]
[start of src/function/pragma/pragma_functions.cpp]
1: #include "duckdb/function/pragma/pragma_functions.hpp"
2: #include "duckdb/main/query_profiler.hpp"
3: #include "duckdb/common/operator/cast_operators.hpp"
4: #include "duckdb/main/client_context.hpp"
5: #include "duckdb/main/database.hpp"
6: #include "duckdb/parallel/task_scheduler.hpp"
7: #include "duckdb/planner/expression_binder.hpp"
8: #include "duckdb/storage/buffer_manager.hpp"
9: #include "duckdb/storage/storage_manager.hpp"
10: #include "duckdb/common/enums/output_type.hpp"
11: #include <cctype>
12: 
13: namespace duckdb {
14: 
15: static void PragmaEnableProfilingStatement(ClientContext &context, const FunctionParameters &parameters) {
16: 	context.profiler->automatic_print_format = ProfilerPrintFormat::QUERY_TREE;
17: 	context.profiler->Enable();
18: }
19: 
20: static void PragmaSetProfilingModeStatement(ClientContext &context, const FunctionParameters &parameters) {
21: 	// this is either profiling_mode = standard, or profiling_mode = detailed
22: 	string mode = StringUtil::Lower(parameters.values[0].ToString());
23: 	if (mode == "standard") {
24: 		context.profiler->Enable();
25: 	} else if (mode == "detailed") {
26: 		context.profiler->DetailedEnable();
27: 	} else {
28: 		throw ParserException("Unrecognized print format %s, supported formats: [standard, detailed]", mode);
29: 	}
30: }
31: 
32: static void PragmaSetProfilerHistorySize(ClientContext &context, const FunctionParameters &parameters) {
33: 	auto size = parameters.values[0].GetValue<int64_t>();
34: 	if (size <= 0) {
35: 		throw ParserException("Size should be larger than 0");
36: 	}
37: 	context.query_profiler_history->SetProfilerHistorySize(size);
38: }
39: 
40: static void PragmaEnableProfilingAssignment(ClientContext &context, const FunctionParameters &parameters) {
41: 	// this is either enable_profiling = json, or enable_profiling = query_tree
42: 	string assignment = parameters.values[0].ToString();
43: 	if (assignment == "json") {
44: 		context.profiler->automatic_print_format = ProfilerPrintFormat::JSON;
45: 	} else if (assignment == "query_tree") {
46: 		context.profiler->automatic_print_format = ProfilerPrintFormat::QUERY_TREE;
47: 	} else if (assignment == "query_tree_optimizer") {
48: 		context.profiler->automatic_print_format = ProfilerPrintFormat::QUERY_TREE_OPTIMIZER;
49: 	} else {
50: 		throw ParserException(
51: 		    "Unrecognized print format %s, supported formats: [json, query_tree, query_tree_optimizer]", assignment);
52: 	}
53: 	context.profiler->Enable();
54: }
55: 
56: void RegisterEnableProfiling(BuiltinFunctions &set) {
57: 	vector<PragmaFunction> functions;
58: 	functions.push_back(PragmaFunction::PragmaStatement(string(), PragmaEnableProfilingStatement));
59: 	functions.push_back(
60: 	    PragmaFunction::PragmaAssignment(string(), PragmaEnableProfilingAssignment, LogicalType::VARCHAR));
61: 
62: 	set.AddFunction("enable_profile", functions);
63: 	set.AddFunction("enable_profiling", functions);
64: }
65: 
66: static void PragmaDisableProfiling(ClientContext &context, const FunctionParameters &parameters) {
67: 	context.profiler->Disable();
68: 	context.profiler->automatic_print_format = ProfilerPrintFormat::NONE;
69: }
70: 
71: static void PragmaProfileOutput(ClientContext &context, const FunctionParameters &parameters) {
72: 	context.profiler->save_location = parameters.values[0].ToString();
73: }
74: 
75: static idx_t ParseMemoryLimit(string arg);
76: 
77: static void PragmaMemoryLimit(ClientContext &context, const FunctionParameters &parameters) {
78: 	idx_t new_limit = ParseMemoryLimit(parameters.values[0].ToString());
79: 	// set the new limit in the buffer manager
80: 	BufferManager::GetBufferManager(context).SetLimit(new_limit);
81: }
82: 
83: static void PragmaCollation(ClientContext &context, const FunctionParameters &parameters) {
84: 	auto collation_param = StringUtil::Lower(parameters.values[0].ToString());
85: 	// bind the collation to verify that it exists
86: 	ExpressionBinder::TestCollation(context, collation_param);
87: 	auto &config = DBConfig::GetConfig(context);
88: 	config.collation = collation_param;
89: }
90: 
91: static void PragmaNullOrder(ClientContext &context, const FunctionParameters &parameters) {
92: 	auto &config = DBConfig::GetConfig(context);
93: 	string new_null_order = StringUtil::Lower(parameters.values[0].ToString());
94: 	if (new_null_order == "nulls first" || new_null_order == "null first" || new_null_order == "first") {
95: 		config.default_null_order = OrderByNullType::NULLS_FIRST;
96: 	} else if (new_null_order == "nulls last" || new_null_order == "null last" || new_null_order == "last") {
97: 		config.default_null_order = OrderByNullType::NULLS_LAST;
98: 	} else {
99: 		throw ParserException("Unrecognized null order '%s', expected either NULLS FIRST or NULLS LAST",
100: 		                      new_null_order);
101: 	}
102: }
103: 
104: static void PragmaDefaultOrder(ClientContext &context, const FunctionParameters &parameters) {
105: 	auto &config = DBConfig::GetConfig(context);
106: 	string new_order = StringUtil::Lower(parameters.values[0].ToString());
107: 	if (new_order == "ascending" || new_order == "asc") {
108: 		config.default_order_type = OrderType::ASCENDING;
109: 	} else if (new_order == "descending" || new_order == "desc") {
110: 		config.default_order_type = OrderType::DESCENDING;
111: 	} else {
112: 		throw ParserException("Unrecognized order order '%s', expected either ASCENDING or DESCENDING", new_order);
113: 	}
114: }
115: 
116: static void PragmaSetThreads(ClientContext &context, const FunctionParameters &parameters) {
117: 	auto nr_threads = parameters.values[0].GetValue<int64_t>();
118: 	TaskScheduler::GetScheduler(context).SetThreads(nr_threads);
119: }
120: 
121: static void PragmaEnableProgressBar(ClientContext &context, const FunctionParameters &parameters) {
122: 	context.enable_progress_bar = true;
123: }
124: static void PragmaSetProgressBarWaitTime(ClientContext &context, const FunctionParameters &parameters) {
125: 	context.wait_time = parameters.values[0].GetValue<int>();
126: 	context.enable_progress_bar = true;
127: }
128: 
129: static void PragmaDisableProgressBar(ClientContext &context, const FunctionParameters &parameters) {
130: 	context.enable_progress_bar = false;
131: }
132: 
133: static void PragmaEnablePrintProgressBar(ClientContext &context, const FunctionParameters &parameters) {
134: 	context.print_progress_bar = true;
135: }
136: 
137: static void PragmaDisablePrintProgressBar(ClientContext &context, const FunctionParameters &parameters) {
138: 	context.print_progress_bar = false;
139: }
140: 
141: static void PragmaEnableVerification(ClientContext &context, const FunctionParameters &parameters) {
142: 	context.query_verification_enabled = true;
143: }
144: 
145: static void PragmaDisableVerification(ClientContext &context, const FunctionParameters &parameters) {
146: 	context.query_verification_enabled = false;
147: }
148: 
149: static void PragmaEnableForceParallelism(ClientContext &context, const FunctionParameters &parameters) {
150: 	context.force_parallelism = true;
151: }
152: 
153: static void PragmaEnableForceIndexJoin(ClientContext &context, const FunctionParameters &parameters) {
154: 	context.force_index_join = true;
155: }
156: 
157: static void PragmaForceCheckpoint(ClientContext &context, const FunctionParameters &parameters) {
158: 	DBConfig::GetConfig(context).force_checkpoint = true;
159: }
160: 
161: static void PragmaDisableForceParallelism(ClientContext &context, const FunctionParameters &parameters) {
162: 	context.force_parallelism = false;
163: }
164: 
165: static void PragmaEnableObjectCache(ClientContext &context, const FunctionParameters &parameters) {
166: 	DBConfig::GetConfig(context).object_cache_enable = true;
167: }
168: 
169: static void PragmaDisableObjectCache(ClientContext &context, const FunctionParameters &parameters) {
170: 	DBConfig::GetConfig(context).object_cache_enable = false;
171: }
172: 
173: static void PragmaEnableCheckpointOnShutdown(ClientContext &context, const FunctionParameters &parameters) {
174: 	DBConfig::GetConfig(context).checkpoint_on_shutdown = true;
175: }
176: 
177: static void PragmaDisableCheckpointOnShutdown(ClientContext &context, const FunctionParameters &parameters) {
178: 	DBConfig::GetConfig(context).checkpoint_on_shutdown = false;
179: }
180: 
181: static void PragmaLogQueryPath(ClientContext &context, const FunctionParameters &parameters) {
182: 	auto str_val = parameters.values[0].ToString();
183: 	if (str_val.empty()) {
184: 		// empty path: clean up query writer
185: 		context.log_query_writer = nullptr;
186: 	} else {
187: 		context.log_query_writer = make_unique<BufferedFileWriter>(FileSystem::GetFileSystem(context), str_val);
188: 	}
189: }
190: 
191: static void PragmaExplainOutput(ClientContext &context, const FunctionParameters &parameters) {
192: 	string val = StringUtil::Lower(parameters.values[0].ToString());
193: 	if (val == "all") {
194: 		context.explain_output_type = ExplainOutputType::ALL;
195: 	} else if (val == "optimized_only") {
196: 		context.explain_output_type = ExplainOutputType::OPTIMIZED_ONLY;
197: 	} else if (val == "physical_only") {
198: 		context.explain_output_type = ExplainOutputType::PHYSICAL_ONLY;
199: 	} else {
200: 		throw ParserException("Unrecognized output type '%s', expected either ALL, OPTIMIZED_ONLY or PHYSICAL_ONLY",
201: 		                      val);
202: 	}
203: }
204: 
205: static void PragmaEnableOptimizer(ClientContext &context, const FunctionParameters &parameters) {
206: 	context.enable_optimizer = true;
207: }
208: 
209: static void PragmaDisableOptimizer(ClientContext &context, const FunctionParameters &parameters) {
210: 	context.enable_optimizer = false;
211: }
212: 
213: static void PragmaPerfectHashThreshold(ClientContext &context, const FunctionParameters &parameters) {
214: 	auto bits = parameters.values[0].GetValue<int32_t>();
215: 	;
216: 	if (bits < 0 || bits > 32) {
217: 		throw ParserException("Perfect HT threshold out of range: should be within range 0 - 32");
218: 	}
219: 	context.perfect_ht_threshold = bits;
220: }
221: 
222: static void PragmaAutoCheckpointThreshold(ClientContext &context, const FunctionParameters &parameters) {
223: 	idx_t new_limit = ParseMemoryLimit(parameters.values[0].ToString());
224: 	DBConfig::GetConfig(context).checkpoint_wal_size = new_limit;
225: }
226: 
227: static void PragmaDebugCheckpointAbort(ClientContext &context, const FunctionParameters &parameters) {
228: 	auto checkpoint_abort = StringUtil::Lower(parameters.values[0].ToString());
229: 	auto &config = DBConfig::GetConfig(context);
230: 	if (checkpoint_abort == "none") {
231: 		config.checkpoint_abort = CheckpointAbort::NO_ABORT;
232: 	} else if (checkpoint_abort == "before_truncate") {
233: 		config.checkpoint_abort = CheckpointAbort::DEBUG_ABORT_BEFORE_TRUNCATE;
234: 	} else if (checkpoint_abort == "before_header") {
235: 		config.checkpoint_abort = CheckpointAbort::DEBUG_ABORT_BEFORE_HEADER;
236: 	} else {
237: 		throw ParserException(
238: 		    "Unrecognized option for PRAGMA debug_checkpoint_abort, expected none, before_truncate or before_header");
239: 	}
240: }
241: 
242: void PragmaFunctions::RegisterFunction(BuiltinFunctions &set) {
243: 	RegisterEnableProfiling(set);
244: 
245: 	set.AddFunction(
246: 	    PragmaFunction::PragmaAssignment("profiling_mode", PragmaSetProfilingModeStatement, LogicalType::VARCHAR));
247: 	set.AddFunction(PragmaFunction::PragmaAssignment("set_profiler_history_size", PragmaSetProfilerHistorySize,
248: 	                                                 LogicalType::BIGINT));
249: 
250: 	set.AddFunction(PragmaFunction::PragmaStatement("disable_profile", PragmaDisableProfiling));
251: 	set.AddFunction(PragmaFunction::PragmaStatement("disable_profiling", PragmaDisableProfiling));
252: 
253: 	set.AddFunction(PragmaFunction::PragmaAssignment("profile_output", PragmaProfileOutput, LogicalType::VARCHAR));
254: 	set.AddFunction(PragmaFunction::PragmaAssignment("profiling_output", PragmaProfileOutput, LogicalType::VARCHAR));
255: 
256: 	set.AddFunction(PragmaFunction::PragmaAssignment("memory_limit", PragmaMemoryLimit, LogicalType::VARCHAR));
257: 
258: 	set.AddFunction(PragmaFunction::PragmaAssignment("collation", PragmaCollation, LogicalType::VARCHAR));
259: 	set.AddFunction(PragmaFunction::PragmaAssignment("default_collation", PragmaCollation, LogicalType::VARCHAR));
260: 
261: 	set.AddFunction(PragmaFunction::PragmaAssignment("null_order", PragmaNullOrder, LogicalType::VARCHAR));
262: 	set.AddFunction(PragmaFunction::PragmaAssignment("default_null_order", PragmaNullOrder, LogicalType::VARCHAR));
263: 
264: 	set.AddFunction(PragmaFunction::PragmaAssignment("order", PragmaDefaultOrder, LogicalType::VARCHAR));
265: 	set.AddFunction(PragmaFunction::PragmaAssignment("default_order", PragmaDefaultOrder, LogicalType::VARCHAR));
266: 
267: 	set.AddFunction(PragmaFunction::PragmaAssignment("threads", PragmaSetThreads, LogicalType::BIGINT));
268: 	set.AddFunction(PragmaFunction::PragmaAssignment("worker_threads", PragmaSetThreads, LogicalType::BIGINT));
269: 
270: 	set.AddFunction(PragmaFunction::PragmaStatement("enable_verification", PragmaEnableVerification));
271: 	set.AddFunction(PragmaFunction::PragmaStatement("disable_verification", PragmaDisableVerification));
272: 
273: 	set.AddFunction(PragmaFunction::PragmaStatement("force_parallelism", PragmaEnableForceParallelism));
274: 	set.AddFunction(PragmaFunction::PragmaStatement("disable_force_parallelism", PragmaDisableForceParallelism));
275: 
276: 	set.AddFunction(PragmaFunction::PragmaStatement("enable_object_cache", PragmaEnableObjectCache));
277: 	set.AddFunction(PragmaFunction::PragmaStatement("disable_object_cache", PragmaDisableObjectCache));
278: 
279: 	set.AddFunction(PragmaFunction::PragmaStatement("enable_optimizer", PragmaEnableOptimizer));
280: 	set.AddFunction(PragmaFunction::PragmaStatement("disable_optimizer", PragmaDisableOptimizer));
281: 
282: 	set.AddFunction(PragmaFunction::PragmaAssignment("log_query_path", PragmaLogQueryPath, LogicalType::VARCHAR));
283: 	set.AddFunction(PragmaFunction::PragmaAssignment("explain_output", PragmaExplainOutput, LogicalType::VARCHAR));
284: 
285: 	set.AddFunction(PragmaFunction::PragmaStatement("force_index_join", PragmaEnableForceIndexJoin));
286: 	set.AddFunction(PragmaFunction::PragmaStatement("force_checkpoint", PragmaForceCheckpoint));
287: 
288: 	set.AddFunction(PragmaFunction::PragmaStatement("enable_progress_bar", PragmaEnableProgressBar));
289: 	set.AddFunction(PragmaFunction::PragmaStatement("disable_progress_bar", PragmaDisableProgressBar));
290: 
291: 	set.AddFunction(PragmaFunction::PragmaStatement("enable_print_progress_bar", PragmaEnablePrintProgressBar));
292: 	set.AddFunction(PragmaFunction::PragmaStatement("disable_print_progress_bar", PragmaDisablePrintProgressBar));
293: 
294: 	set.AddFunction(
295: 	    PragmaFunction::PragmaAssignment("set_progress_bar_time", PragmaSetProgressBarWaitTime, LogicalType::INTEGER));
296: 
297: 	set.AddFunction(PragmaFunction::PragmaStatement("enable_checkpoint_on_shutdown", PragmaEnableCheckpointOnShutdown));
298: 	set.AddFunction(
299: 	    PragmaFunction::PragmaStatement("disable_checkpoint_on_shutdown", PragmaDisableCheckpointOnShutdown));
300: 
301: 	set.AddFunction(
302: 	    PragmaFunction::PragmaAssignment("perfect_ht_threshold", PragmaPerfectHashThreshold, LogicalType::INTEGER));
303: 
304: 	set.AddFunction(
305: 	    PragmaFunction::PragmaAssignment("wal_autocheckpoint", PragmaAutoCheckpointThreshold, LogicalType::VARCHAR));
306: 	set.AddFunction(
307: 	    PragmaFunction::PragmaAssignment("checkpoint_threshold", PragmaAutoCheckpointThreshold, LogicalType::VARCHAR));
308: 
309: 	set.AddFunction(
310: 	    PragmaFunction::PragmaAssignment("debug_checkpoint_abort", PragmaDebugCheckpointAbort, LogicalType::VARCHAR));
311: }
312: 
313: idx_t ParseMemoryLimit(string arg) {
314: 	if (arg[0] == '-' || arg == "null" || arg == "none") {
315: 		return INVALID_INDEX;
316: 	}
317: 	// split based on the number/non-number
318: 	idx_t idx = 0;
319: 	while (StringUtil::CharacterIsSpace(arg[idx])) {
320: 		idx++;
321: 	}
322: 	idx_t num_start = idx;
323: 	while ((arg[idx] >= '0' && arg[idx] <= '9') || arg[idx] == '.' || arg[idx] == 'e' || arg[idx] == 'E' ||
324: 	       arg[idx] == '-') {
325: 		idx++;
326: 	}
327: 	if (idx == num_start) {
328: 		throw ParserException("Memory limit must have a number (e.g. PRAGMA memory_limit=1GB");
329: 	}
330: 	string number = arg.substr(num_start, idx - num_start);
331: 
332: 	// try to parse the number
333: 	double limit = Cast::Operation<string_t, double>(string_t(number));
334: 
335: 	// now parse the memory limit unit (e.g. bytes, gb, etc)
336: 	while (StringUtil::CharacterIsSpace(arg[idx])) {
337: 		idx++;
338: 	}
339: 	idx_t start = idx;
340: 	while (idx < arg.size() && !StringUtil::CharacterIsSpace(arg[idx])) {
341: 		idx++;
342: 	}
343: 	if (limit < 0) {
344: 		// limit < 0, set limit to infinite
345: 		return (idx_t)-1;
346: 	}
347: 	string unit = StringUtil::Lower(arg.substr(start, idx - start));
348: 	idx_t multiplier;
349: 	if (unit == "byte" || unit == "bytes" || unit == "b") {
350: 		multiplier = 1;
351: 	} else if (unit == "kilobyte" || unit == "kilobytes" || unit == "kb" || unit == "k") {
352: 		multiplier = 1000LL;
353: 	} else if (unit == "megabyte" || unit == "megabytes" || unit == "mb" || unit == "m") {
354: 		multiplier = 1000LL * 1000LL;
355: 	} else if (unit == "gigabyte" || unit == "gigabytes" || unit == "gb" || unit == "g") {
356: 		multiplier = 1000LL * 1000LL * 1000LL;
357: 	} else if (unit == "terabyte" || unit == "terabytes" || unit == "tb" || unit == "t") {
358: 		multiplier = 1000LL * 1000LL * 1000LL * 1000LL;
359: 	} else {
360: 		throw ParserException("Unknown unit for memory_limit: %s (expected: b, mb, gb or tb)", unit);
361: 	}
362: 	return (idx_t)multiplier * limit;
363: }
364: 
365: } // namespace duckdb
[end of src/function/pragma/pragma_functions.cpp]
[start of src/include/duckdb/main/config.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/main/config.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/allocator.hpp"
12: #include "duckdb/common/common.hpp"
13: #include "duckdb/common/enums/order_type.hpp"
14: #include "duckdb/common/file_system.hpp"
15: #include "duckdb/common/winapi.hpp"
16: #include "duckdb/common/types/value.hpp"
17: #include "duckdb/common/vector.hpp"
18: #include "duckdb/function/replacement_scan.hpp"
19: 
20: namespace duckdb {
21: class ClientContext;
22: class TableFunctionRef;
23: 
24: enum class AccessMode : uint8_t { UNDEFINED = 0, AUTOMATIC = 1, READ_ONLY = 2, READ_WRITE = 3 };
25: enum class CheckpointAbort : uint8_t { NO_ABORT = 0, DEBUG_ABORT_BEFORE_TRUNCATE = 1, DEBUG_ABORT_BEFORE_HEADER = 2 };
26: 
27: // this is optional and only used in tests at the moment
28: struct DBConfig {
29: 	friend class DatabaseInstance;
30: 	friend class StorageManager;
31: 
32: public:
33: 	DUCKDB_API ~DBConfig();
34: 
35: 	//! Access mode of the database (AUTOMATIC, READ_ONLY or READ_WRITE)
36: 	AccessMode access_mode = AccessMode::AUTOMATIC;
37: 	//! The allocator used by the system
38: 	Allocator allocator;
39: 	// Checkpoint when WAL reaches this size (default: 16MB)
40: 	idx_t checkpoint_wal_size = 1 << 24;
41: 	//! Whether or not to use Direct IO, bypassing operating system buffers
42: 	bool use_direct_io = false;
43: 	//! The FileSystem to use, can be overwritten to allow for injecting custom file systems for testing purposes (e.g.
44: 	//! RamFS or something similar)
45: 	unique_ptr<FileSystem> file_system;
46: 	//! The maximum memory used by the database system (in bytes). Default: 80% of System available memory
47: 	idx_t maximum_memory = (idx_t)-1;
48: 	//! The maximum amount of CPU threads used by the database system. Default: all available.
49: 	idx_t maximum_threads = (idx_t)-1;
50: 	//! Whether or not to create and use a temporary directory to store intermediates that do not fit in memory
51: 	bool use_temporary_directory = true;
52: 	//! Directory to store temporary structures that do not fit in memory
53: 	string temporary_directory;
54: 	//! The collation type of the database
55: 	string collation = string();
56: 	//! The order type used when none is specified (default: ASC)
57: 	OrderType default_order_type = OrderType::ASCENDING;
58: 	//! Null ordering used when none is specified (default: NULLS FIRST)
59: 	OrderByNullType default_null_order = OrderByNullType::NULLS_FIRST;
60: 	//! enable COPY and related commands
61: 	bool enable_copy = true;
62: 	//! Whether or not object cache is used
63: 	bool object_cache_enable = false;
64: 	//! Database configuration variables as controlled by SET
65: 	unordered_map<std::string, Value> set_variables;
66: 	//! Force checkpoint when CHECKPOINT is called or on shutdown, even if no changes have been made
67: 	bool force_checkpoint = false;
68: 	//! Run a checkpoint on successful shutdown and delete the WAL, to leave only a single database file behind
69: 	bool checkpoint_on_shutdown = true;
70: 	//! Debug flag that decides when a checkpoing should be aborted. Only used for testing purposes.
71: 	CheckpointAbort checkpoint_abort = CheckpointAbort::NO_ABORT;
72: 	//! Replacement table scans are automatically attempted when a table name cannot be found in the schema
73: 	vector<ReplacementScan> replacement_scans;
74: 
75: public:
76: 	DUCKDB_API static DBConfig &GetConfig(ClientContext &context);
77: 	DUCKDB_API static DBConfig &GetConfig(DatabaseInstance &db);
78: };
79: 
80: } // namespace duckdb
[end of src/include/duckdb/main/config.hpp]
[start of src/main/CMakeLists.txt]
1: add_subdirectory(relation)
2: 
3: set(DUCKDB_MAIN_FILES
4:     appender.cpp
5:     client_context.cpp
6:     connection.cpp
7:     database.cpp
8:     materialized_query_result.cpp
9:     prepared_statement.cpp
10:     prepared_statement_data.cpp
11:     relation.cpp
12:     query_profiler.cpp
13:     query_result.cpp
14:     stream_query_result.cpp)
15: 
16: if(NOT CLANG_TIDY)
17:   set(DUCKDB_MAIN_FILES ${DUCKDB_MAIN_FILES} duckdb-c.cpp)
18: endif()
19: 
20: add_library_unity(duckdb_main OBJECT ${DUCKDB_MAIN_FILES})
21: set(ALL_OBJECT_FILES
22:     ${ALL_OBJECT_FILES} $<TARGET_OBJECTS:duckdb_main>
23:     PARENT_SCOPE)
[end of src/main/CMakeLists.txt]
[start of src/main/database.cpp]
1: #include "duckdb/main/database.hpp"
2: 
3: #include "duckdb/catalog/catalog.hpp"
4: #include "duckdb/common/file_system.hpp"
5: #include "duckdb/main/client_context.hpp"
6: #include "duckdb/parallel/task_scheduler.hpp"
7: #include "duckdb/storage/storage_manager.hpp"
8: #include "duckdb/storage/object_cache.hpp"
9: #include "duckdb/transaction/transaction_manager.hpp"
10: #include "duckdb/main/connection_manager.hpp"
11: 
12: #ifndef DUCKDB_NO_THREADS
13: #include "duckdb/common/thread.hpp"
14: #endif
15: 
16: namespace duckdb {
17: 
18: DBConfig::~DBConfig() {
19: }
20: 
21: DatabaseInstance::DatabaseInstance() {
22: }
23: 
24: DatabaseInstance::~DatabaseInstance() {
25: 	// shutting down: attempt to checkpoint the database
26: 	try {
27: 		auto &storage = StorageManager::GetStorageManager(*this);
28: 		if (!storage.InMemory()) {
29: 			auto &config = storage.db.config;
30: 			if (!config.checkpoint_on_shutdown) {
31: 				return;
32: 			}
33: 			storage.CreateCheckpoint(true);
34: 		}
35: 	} catch (...) {
36: 	}
37: }
38: 
39: BufferManager &BufferManager::GetBufferManager(DatabaseInstance &db) {
40: 	return *db.GetStorageManager().buffer_manager;
41: }
42: 
43: BlockManager &BlockManager::GetBlockManager(DatabaseInstance &db) {
44: 	return *db.GetStorageManager().block_manager;
45: }
46: 
47: BlockManager &BlockManager::GetBlockManager(ClientContext &context) {
48: 	return BlockManager::GetBlockManager(DatabaseInstance::GetDatabase(context));
49: }
50: 
51: DatabaseInstance &DatabaseInstance::GetDatabase(ClientContext &context) {
52: 	return *context.db;
53: }
54: 
55: StorageManager &StorageManager::GetStorageManager(DatabaseInstance &db) {
56: 	return db.GetStorageManager();
57: }
58: 
59: Catalog &Catalog::GetCatalog(DatabaseInstance &db) {
60: 	return db.GetCatalog();
61: }
62: 
63: FileSystem &FileSystem::GetFileSystem(DatabaseInstance &db) {
64: 	return db.GetFileSystem();
65: }
66: 
67: DBConfig &DBConfig::GetConfig(DatabaseInstance &db) {
68: 	return db.config;
69: }
70: 
71: TransactionManager &TransactionManager::Get(ClientContext &context) {
72: 	return TransactionManager::Get(DatabaseInstance::GetDatabase(context));
73: }
74: 
75: TransactionManager &TransactionManager::Get(DatabaseInstance &db) {
76: 	return db.GetTransactionManager();
77: }
78: 
79: ConnectionManager &ConnectionManager::Get(DatabaseInstance &db) {
80: 	return db.GetConnectionManager();
81: }
82: 
83: ConnectionManager &ConnectionManager::Get(ClientContext &context) {
84: 	return ConnectionManager::Get(DatabaseInstance::GetDatabase(context));
85: }
86: 
87: void DatabaseInstance::Initialize(const char *path, DBConfig *new_config) {
88: 	if (new_config) {
89: 		// user-supplied configuration
90: 		Configure(*new_config);
91: 	} else {
92: 		// default configuration
93: 		DBConfig config;
94: 		Configure(config);
95: 	}
96: 	if (config.temporary_directory.empty() && path) {
97: 		// no directory specified: use default temp path
98: 		config.temporary_directory = string(path) + ".tmp";
99: 
100: 		// special treatment for in-memory mode
101: 		if (strcmp(path, ":memory:") == 0) {
102: 			config.temporary_directory = ".tmp";
103: 		}
104: 	}
105: 	if (new_config && !new_config->use_temporary_directory) {
106: 		// temporary directories explicitly disabled
107: 		config.temporary_directory = string();
108: 	}
109: 
110: 	storage =
111: 	    make_unique<StorageManager>(*this, path ? string(path) : string(), config.access_mode == AccessMode::READ_ONLY);
112: 	catalog = make_unique<Catalog>(*this);
113: 	transaction_manager = make_unique<TransactionManager>(*this);
114: 	scheduler = make_unique<TaskScheduler>();
115: 	object_cache = make_unique<ObjectCache>();
116: 	connection_manager = make_unique<ConnectionManager>();
117: 
118: 	// initialize the database
119: 	storage->Initialize();
120: 
121: 	// only increase thread count after storage init because we get races on catalog otherwise
122: 	scheduler->SetThreads(config.maximum_threads);
123: }
124: 
125: DuckDB::DuckDB(const char *path, DBConfig *new_config) : instance(make_shared<DatabaseInstance>()) {
126: 	instance->Initialize(path, new_config);
127: }
128: 
129: DuckDB::DuckDB(const string &path, DBConfig *config) : DuckDB(path.c_str(), config) {
130: }
131: 
132: DuckDB::~DuckDB() {
133: }
134: 
135: StorageManager &DatabaseInstance::GetStorageManager() {
136: 	return *storage;
137: }
138: 
139: Catalog &DatabaseInstance::GetCatalog() {
140: 	return *catalog;
141: }
142: 
143: TransactionManager &DatabaseInstance::GetTransactionManager() {
144: 	return *transaction_manager;
145: }
146: 
147: TaskScheduler &DatabaseInstance::GetScheduler() {
148: 	return *scheduler;
149: }
150: 
151: ObjectCache &DatabaseInstance::GetObjectCache() {
152: 	return *object_cache;
153: }
154: 
155: FileSystem &DatabaseInstance::GetFileSystem() {
156: 	return *config.file_system;
157: }
158: 
159: ConnectionManager &DatabaseInstance::GetConnectionManager() {
160: 	return *connection_manager;
161: }
162: 
163: FileSystem &DuckDB::GetFileSystem() {
164: 	return instance->GetFileSystem();
165: }
166: 
167: Allocator &Allocator::Get(ClientContext &context) {
168: 	return Allocator::Get(*context.db);
169: }
170: 
171: Allocator &Allocator::Get(DatabaseInstance &db) {
172: 	return db.config.allocator;
173: }
174: 
175: void DatabaseInstance::Configure(DBConfig &new_config) {
176: 	if (new_config.access_mode != AccessMode::UNDEFINED) {
177: 		config.access_mode = new_config.access_mode;
178: 	} else {
179: 		config.access_mode = AccessMode::READ_WRITE;
180: 	}
181: 	if (new_config.file_system) {
182: 		config.file_system = move(new_config.file_system);
183: 	} else {
184: 		config.file_system = make_unique<VirtualFileSystem>();
185: 	}
186: 	if (new_config.maximum_memory == (idx_t)-1) {
187: 		config.maximum_memory = config.file_system->GetAvailableMemory() * 8 / 10;
188: 	} else {
189: 		config.maximum_memory = new_config.maximum_memory;
190: 	}
191: 	if (new_config.maximum_threads == (idx_t)-1) {
192: #ifndef DUCKDB_NO_THREADS
193: 		config.maximum_threads = 1;
194: 		// FIXME: next release
195: 		// config.maximum_threads = std::thread::hardware_concurrency();
196: #else
197: 		config.maximum_threads = 1;
198: #endif
199: 	} else {
200: 		config.maximum_threads = new_config.maximum_threads;
201: 	}
202: 	config.allocator = move(new_config.allocator);
203: 	config.checkpoint_wal_size = new_config.checkpoint_wal_size;
204: 	config.use_direct_io = new_config.use_direct_io;
205: 	config.temporary_directory = new_config.temporary_directory;
206: 	config.collation = new_config.collation;
207: 	config.default_order_type = new_config.default_order_type;
208: 	config.default_null_order = new_config.default_null_order;
209: 	config.enable_copy = new_config.enable_copy;
210: 	config.replacement_scans = move(new_config.replacement_scans);
211: }
212: 
213: DBConfig &DBConfig::GetConfig(ClientContext &context) {
214: 	return context.db->config;
215: }
216: 
217: idx_t DatabaseInstance::NumberOfThreads() {
218: 	return scheduler->NumberOfThreads();
219: }
220: 
221: idx_t DuckDB::NumberOfThreads() {
222: 	return instance->NumberOfThreads();
223: }
224: 
225: } // namespace duckdb
[end of src/main/database.cpp]
[start of src/planner/binder/statement/bind_copy.cpp]
1: #include "duckdb/catalog/catalog.hpp"
2: #include "duckdb/parser/statement/copy_statement.hpp"
3: #include "duckdb/planner/binder.hpp"
4: #include "duckdb/parser/statement/insert_statement.hpp"
5: #include "duckdb/planner/operator/logical_copy_to_file.hpp"
6: #include "duckdb/planner/operator/logical_get.hpp"
7: #include "duckdb/planner/operator/logical_insert.hpp"
8: #include "duckdb/catalog/catalog_entry/copy_function_catalog_entry.hpp"
9: #include "duckdb/main/client_context.hpp"
10: #include "duckdb/main/database.hpp"
11: 
12: #include "duckdb/parser/expression/columnref_expression.hpp"
13: #include "duckdb/parser/expression/star_expression.hpp"
14: #include "duckdb/parser/tableref/basetableref.hpp"
15: #include "duckdb/parser/query_node/select_node.hpp"
16: 
17: #include <algorithm>
18: 
19: namespace duckdb {
20: 
21: BoundStatement Binder::BindCopyTo(CopyStatement &stmt) {
22: 	// COPY TO a file
23: 	auto &config = DBConfig::GetConfig(context);
24: 	if (!config.enable_copy) {
25: 		throw Exception("COPY TO is disabled by configuration");
26: 	}
27: 	BoundStatement result;
28: 	result.types = {LogicalType::BIGINT};
29: 	result.names = {"Count"};
30: 
31: 	// bind the select statement
32: 	auto select_node = Bind(*stmt.select_statement);
33: 
34: 	// lookup the format in the catalog
35: 	auto &catalog = Catalog::GetCatalog(context);
36: 	auto copy_function = catalog.GetEntry<CopyFunctionCatalogEntry>(context, DEFAULT_SCHEMA, stmt.info->format);
37: 	if (!copy_function->function.copy_to_bind) {
38: 		throw NotImplementedException("COPY TO is not supported for FORMAT \"%s\"", stmt.info->format);
39: 	}
40: 
41: 	auto function_data =
42: 	    copy_function->function.copy_to_bind(context, *stmt.info, select_node.names, select_node.types);
43: 	// now create the copy information
44: 	auto copy = make_unique<LogicalCopyToFile>(copy_function->function, move(function_data));
45: 	copy->AddChild(move(select_node.plan));
46: 
47: 	result.plan = move(copy);
48: 
49: 	return result;
50: }
51: 
52: BoundStatement Binder::BindCopyFrom(CopyStatement &stmt) {
53: 	auto &config = DBConfig::GetConfig(context);
54: 	if (!config.enable_copy) {
55: 		throw Exception("COPY FROM is disabled by configuration");
56: 	}
57: 	BoundStatement result;
58: 	result.types = {LogicalType::BIGINT};
59: 	result.names = {"Count"};
60: 
61: 	D_ASSERT(!stmt.info->table.empty());
62: 	// COPY FROM a file
63: 	// generate an insert statement for the the to-be-inserted table
64: 	InsertStatement insert;
65: 	insert.table = stmt.info->table;
66: 	insert.schema = stmt.info->schema;
67: 	insert.columns = stmt.info->select_list;
68: 
69: 	// bind the insert statement to the base table
70: 	auto insert_statement = Bind(insert);
71: 	D_ASSERT(insert_statement.plan->type == LogicalOperatorType::LOGICAL_INSERT);
72: 
73: 	auto &bound_insert = (LogicalInsert &)*insert_statement.plan;
74: 
75: 	// lookup the format in the catalog
76: 	auto &catalog = Catalog::GetCatalog(context);
77: 	auto copy_function = catalog.GetEntry<CopyFunctionCatalogEntry>(context, DEFAULT_SCHEMA, stmt.info->format);
78: 	if (!copy_function->function.copy_from_bind) {
79: 		throw NotImplementedException("COPY FROM is not supported for FORMAT \"%s\"", stmt.info->format);
80: 	}
81: 	// lookup the table to copy into
82: 	auto table = Catalog::GetCatalog(context).GetEntry<TableCatalogEntry>(context, stmt.info->schema, stmt.info->table);
83: 	vector<string> expected_names;
84: 	if (!bound_insert.column_index_map.empty()) {
85: 		expected_names.resize(bound_insert.expected_types.size());
86: 		for (idx_t i = 0; i < table->columns.size(); i++) {
87: 			if (bound_insert.column_index_map[i] != INVALID_INDEX) {
88: 				expected_names[bound_insert.column_index_map[i]] = table->columns[i].name;
89: 			}
90: 		}
91: 	} else {
92: 		expected_names.reserve(bound_insert.expected_types.size());
93: 		for (idx_t i = 0; i < table->columns.size(); i++) {
94: 			expected_names.push_back(table->columns[i].name);
95: 		}
96: 	}
97: 
98: 	auto function_data =
99: 	    copy_function->function.copy_from_bind(context, *stmt.info, expected_names, bound_insert.expected_types);
100: 	auto get = make_unique<LogicalGet>(0, copy_function->function.copy_from_function, move(function_data),
101: 	                                   bound_insert.expected_types, expected_names);
102: 	for (idx_t i = 0; i < bound_insert.expected_types.size(); i++) {
103: 		get->column_ids.push_back(i);
104: 	}
105: 	insert_statement.plan->children.push_back(move(get));
106: 	result.plan = move(insert_statement.plan);
107: 	return result;
108: }
109: 
110: BoundStatement Binder::Bind(CopyStatement &stmt) {
111: 	if (!stmt.info->is_from && !stmt.select_statement) {
112: 		// copy table into file without a query
113: 		// generate SELECT * FROM table;
114: 		auto ref = make_unique<BaseTableRef>();
115: 		ref->schema_name = stmt.info->schema;
116: 		ref->table_name = stmt.info->table;
117: 
118: 		auto statement = make_unique<SelectNode>();
119: 		statement->from_table = move(ref);
120: 		if (!stmt.info->select_list.empty()) {
121: 			for (auto &name : stmt.info->select_list) {
122: 				statement->select_list.push_back(make_unique<ColumnRefExpression>(name));
123: 			}
124: 		} else {
125: 			statement->select_list.push_back(make_unique<StarExpression>());
126: 		}
127: 		stmt.select_statement = move(statement);
128: 	}
129: 	if (stmt.info->is_from) {
130: 		return BindCopyFrom(stmt);
131: 	} else {
132: 		return BindCopyTo(stmt);
133: 	}
134: }
135: 
136: } // namespace duckdb
[end of src/planner/binder/statement/bind_copy.cpp]
[start of src/planner/binder/statement/bind_export.cpp]
1: #include "duckdb/catalog/catalog.hpp"
2: #include "duckdb/parser/statement/export_statement.hpp"
3: #include "duckdb/planner/binder.hpp"
4: #include "duckdb/planner/operator/logical_export.hpp"
5: #include "duckdb/catalog/catalog_entry/copy_function_catalog_entry.hpp"
6: #include "duckdb/parser/statement/copy_statement.hpp"
7: #include "duckdb/main/client_context.hpp"
8: #include "duckdb/main/database.hpp"
9: #include "duckdb/common/file_system.hpp"
10: #include "duckdb/planner/operator/logical_set_operation.hpp"
11: #include "duckdb/common/string_util.hpp"
12: #include <algorithm>
13: 
14: namespace duckdb {
15: 
16: BoundStatement Binder::Bind(ExportStatement &stmt) {
17: 	// COPY TO a file
18: 	auto &config = DBConfig::GetConfig(context);
19: 	if (!config.enable_copy) {
20: 		throw Exception("COPY TO is disabled by configuration");
21: 	}
22: 	BoundStatement result;
23: 	result.types = {LogicalType::BOOLEAN};
24: 	result.names = {"Success"};
25: 
26: 	// lookup the format in the catalog
27: 	auto &catalog = Catalog::GetCatalog(context);
28: 	auto copy_function = catalog.GetEntry<CopyFunctionCatalogEntry>(context, DEFAULT_SCHEMA, stmt.info->format);
29: 	if (!copy_function->function.copy_to_bind) {
30: 		throw NotImplementedException("COPY TO is not supported for FORMAT \"%s\"", stmt.info->format);
31: 	}
32: 
33: 	// gather a list of all the tables
34: 	vector<TableCatalogEntry *> tables;
35: 	Catalog::GetCatalog(context).schemas->Scan(context, [&](CatalogEntry *entry) {
36: 		auto schema = (SchemaCatalogEntry *)entry;
37: 		schema->Scan(context, CatalogType::TABLE_ENTRY, [&](CatalogEntry *entry) {
38: 			if (entry->type == CatalogType::TABLE_ENTRY) {
39: 				tables.push_back((TableCatalogEntry *)entry);
40: 			}
41: 		});
42: 	});
43: 
44: 	// now generate the COPY statements for each of the tables
45: 	auto &fs = FileSystem::GetFileSystem(context);
46: 	unique_ptr<LogicalOperator> child_operator;
47: 	for (auto &table : tables) {
48: 		auto info = make_unique<CopyInfo>();
49: 		// we copy the options supplied to the EXPORT
50: 		info->format = stmt.info->format;
51: 		info->options = stmt.info->options;
52: 		// set up the file name for the COPY TO
53: 		if (table->schema->name == DEFAULT_SCHEMA) {
54: 			info->file_path = fs.JoinPath(stmt.info->file_path,
55: 			                              StringUtil::Format("%s.%s", table->name, copy_function->function.extension));
56: 		} else {
57: 			info->file_path =
58: 			    fs.JoinPath(stmt.info->file_path, StringUtil::Format("%s.%s.%s", table->schema->name, table->name,
59: 			                                                         copy_function->function.extension));
60: 		}
61: 		info->is_from = false;
62: 		info->schema = table->schema->name;
63: 		info->table = table->name;
64: 
65: 		// generate the copy statement and bind it
66: 		CopyStatement copy_stmt;
67: 		copy_stmt.info = move(info);
68: 
69: 		auto copy_binder = Binder::CreateBinder(context);
70: 		auto bound_statement = copy_binder->Bind(copy_stmt);
71: 		if (child_operator) {
72: 			// use UNION ALL to combine the individual copy statements into a single node
73: 			auto copy_union =
74: 			    make_unique<LogicalSetOperation>(GenerateTableIndex(), 1, move(child_operator),
75: 			                                     move(bound_statement.plan), LogicalOperatorType::LOGICAL_UNION);
76: 			child_operator = move(copy_union);
77: 		} else {
78: 			child_operator = move(bound_statement.plan);
79: 		}
80: 	}
81: 
82: 	// try to create the directory, if it doesn't exist yet
83: 	// a bit hacky to do it here, but we need to create the directory BEFORE the copy statements run
84: 	if (!fs.DirectoryExists(stmt.info->file_path)) {
85: 		fs.CreateDirectory(stmt.info->file_path);
86: 	}
87: 
88: 	// create the export node
89: 	auto export_node = make_unique<LogicalExport>(copy_function->function, move(stmt.info));
90: 
91: 	if (child_operator) {
92: 		export_node->children.push_back(move(child_operator));
93: 	}
94: 
95: 	result.plan = move(export_node);
96: 	return result;
97: }
98: 
99: } // namespace duckdb
[end of src/planner/binder/statement/bind_export.cpp]
[start of tools/pythonpkg/duckdb_python.cpp]
1: #include "duckdb_python/pybind_wrapper.hpp"
2: 
3: #include "duckdb/common/atomic.hpp"
4: #include "duckdb/common/unordered_map.hpp"
5: #include "duckdb/common/vector.hpp"
6: 
7: #include "duckdb_python/array_wrapper.hpp"
8: #include "duckdb_python/pandas_scan.hpp"
9: #include "duckdb_python/pyconnection.hpp"
10: #include "duckdb_python/pyrelation.hpp"
11: #include "duckdb_python/pyresult.hpp"
12: #include "duckdb/parser/parser.hpp"
13: 
14: #include "datetime.h" // from Python
15: 
16: #include "duckdb.hpp"
17: #include <random>
18: #include <stdlib.h>
19: 
20: namespace py = pybind11;
21: 
22: namespace duckdb {
23: 
24: enum PySQLTokenType {
25: 	PY_SQL_TOKEN_IDENTIFIER = 0,
26: 	PY_SQL_TOKEN_NUMERIC_CONSTANT,
27: 	PY_SQL_TOKEN_STRING_CONSTANT,
28: 	PY_SQL_TOKEN_OPERATOR,
29: 	PY_SQL_TOKEN_KEYWORD,
30: 	PY_SQL_TOKEN_COMMENT
31: };
32: 
33: static py::object PyTokenize(const string &query) {
34: 	auto tokens = Parser::Tokenize(query);
35: 	py::list result;
36: 	for (auto &token : tokens) {
37: 		auto tuple = py::tuple(2);
38: 		tuple[0] = token.start;
39: 		switch (token.type) {
40: 		case SimplifiedTokenType::SIMPLIFIED_TOKEN_IDENTIFIER:
41: 			tuple[1] = PY_SQL_TOKEN_IDENTIFIER;
42: 			break;
43: 		case SimplifiedTokenType::SIMPLIFIED_TOKEN_NUMERIC_CONSTANT:
44: 			tuple[1] = PY_SQL_TOKEN_NUMERIC_CONSTANT;
45: 			break;
46: 		case SimplifiedTokenType::SIMPLIFIED_TOKEN_STRING_CONSTANT:
47: 			tuple[1] = PY_SQL_TOKEN_STRING_CONSTANT;
48: 			break;
49: 		case SimplifiedTokenType::SIMPLIFIED_TOKEN_OPERATOR:
50: 			tuple[1] = PY_SQL_TOKEN_OPERATOR;
51: 			break;
52: 		case SimplifiedTokenType::SIMPLIFIED_TOKEN_KEYWORD:
53: 			tuple[1] = PY_SQL_TOKEN_KEYWORD;
54: 			break;
55: 		case SimplifiedTokenType::SIMPLIFIED_TOKEN_COMMENT:
56: 			tuple[1] = PY_SQL_TOKEN_COMMENT;
57: 			break;
58: 		}
59: 		result.append(tuple);
60: 	}
61: 	return move(result);
62: }
63: 
64: PYBIND11_MODULE(duckdb, m) {
65: 	DuckDBPyRelation::Initialize(m);
66: 	DuckDBPyResult::Initialize(m);
67: 	DuckDBPyConnection::Initialize(m);
68: 
69: 	m.doc() = "DuckDB is an embeddable SQL OLAP Database Management System";
70: 	m.attr("__package__") = "duckdb";
71: 	m.attr("__version__") = DuckDB::LibraryVersion();
72: 	m.attr("__git_revision__") = DuckDB::SourceID();
73: 
74: 	m.def("connect", &DuckDBPyConnection::Connect,
75: 	      "Create a DuckDB database instance. Can take a database file name to read/write persistent data and a "
76: 	      "read_only flag if no changes are desired",
77: 	      py::arg("database") = ":memory:", py::arg("read_only") = false);
78: 	m.def("tokenize", PyTokenize,
79: 	      "Tokenizes a SQL string, returning a list of (position, type) tuples that can be "
80: 	      "used for e.g. syntax highlighting",
81: 	      py::arg("query"));
82: 	py::enum_<PySQLTokenType>(m, "token_type")
83: 	    .value("identifier", PySQLTokenType::PY_SQL_TOKEN_IDENTIFIER)
84: 	    .value("numeric_const", PySQLTokenType::PY_SQL_TOKEN_NUMERIC_CONSTANT)
85: 	    .value("string_const", PySQLTokenType::PY_SQL_TOKEN_STRING_CONSTANT)
86: 	    .value("operator", PySQLTokenType::PY_SQL_TOKEN_OPERATOR)
87: 	    .value("keyword", PySQLTokenType::PY_SQL_TOKEN_KEYWORD)
88: 	    .value("comment", PySQLTokenType::PY_SQL_TOKEN_COMMENT)
89: 	    .export_values();
90: 
91: 	m.def("values", &DuckDBPyRelation::Values, "Create a relation object from the passed values", py::arg("values"));
92: 	m.def("from_query", &DuckDBPyRelation::FromQuery, "Create a relation object from the given SQL query",
93: 	      py::arg("query"), py::arg("alias") = "query_relation");
94: 	m.def("query", &DuckDBPyRelation::FromQuery, "Create a relation object from the given SQL query", py::arg("query"),
95: 	      py::arg("alias") = "query_relation");
96: 	m.def("from_csv_auto", &DuckDBPyRelation::FromCsvAuto, "Creates a relation object from the CSV file in file_name",
97: 	      py::arg("file_name"));
98: 	m.def("from_parquet", &DuckDBPyRelation::FromParquet,
99: 	      "Creates a relation object from the Parquet file in file_name", py::arg("file_name"));
100: 	m.def("df", &DuckDBPyRelation::FromDf, "Create a relation object from the Data.Frame df", py::arg("df"));
101: 	m.def("from_df", &DuckDBPyRelation::FromDf, "Create a relation object from the Data.Frame df", py::arg("df"));
102: 	m.def("from_arrow_table", &DuckDBPyRelation::FromArrowTable, "Create a relation object from an Arrow table",
103: 	      py::arg("table"));
104: 	m.def("arrow", &DuckDBPyRelation::FromArrowTable, "Create a relation object from an Arrow table", py::arg("table"));
105: 	m.def("filter", &DuckDBPyRelation::FilterDf, "Filter the Data.Frame df by the filter in filter_expr", py::arg("df"),
106: 	      py::arg("filter_expr"));
107: 	m.def("project", &DuckDBPyRelation::ProjectDf, "Project the Data.Frame df by the projection in project_expr",
108: 	      py::arg("df"), py::arg("project_expr"));
109: 	m.def("alias", &DuckDBPyRelation::AliasDF, "Create a relation from Data.Frame df with the passed alias",
110: 	      py::arg("df"), py::arg("alias"));
111: 	m.def("order", &DuckDBPyRelation::OrderDf, "Reorder the Data.Frame df by order_expr", py::arg("df"),
112: 	      py::arg("order_expr"));
113: 	m.def("aggregate", &DuckDBPyRelation::AggregateDF,
114: 	      "Compute the aggregate aggr_expr by the optional groups group_expr on Data.frame df", py::arg("df"),
115: 	      py::arg("aggr_expr"), py::arg("group_expr") = "");
116: 	m.def("distinct", &DuckDBPyRelation::DistinctDF, "Compute the distinct rows from Data.Frame df ", py::arg("df"));
117: 	m.def("limit", &DuckDBPyRelation::LimitDF, "Retrieve the first n rows from the Data.Frame df", py::arg("df"),
118: 	      py::arg("n"));
119: 	m.def("query_df", &DuckDBPyRelation::QueryDF,
120: 	      "Run the given SQL query in sql_query on the view named virtual_table_name that contains the content of "
121: 	      "Data.Frame df",
122: 	      py::arg("df"), py::arg("virtual_table_name"), py::arg("sql_query"));
123: 	m.def("write_csv", &DuckDBPyRelation::WriteCsvDF, "Write the Data.Frame df to a CSV file in file_name",
124: 	      py::arg("df"), py::arg("file_name"));
125: 
126: 	// we need this because otherwise we try to remove registered_dfs on shutdown when python is already dead
127: 	auto clean_default_connection = []() {
128: 		DuckDBPyConnection::Cleanup();
129: 	};
130: 	m.add_object("_clean_default_connection", py::capsule(clean_default_connection));
131: 
132: 	PyDateTime_IMPORT;
133: }
134: 
135: } // namespace duckdb
[end of tools/pythonpkg/duckdb_python.cpp]
[start of tools/pythonpkg/src/include/duckdb_python/pyconnection.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb_python/pyconnection.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include <utility>
12: 
13: #include "arrow_array_stream.hpp"
14: #include "duckdb.hpp"
15: #include "duckdb_python/pybind_wrapper.hpp"
16: 
17: namespace duckdb {
18: 
19: struct DuckDBPyRelation;
20: struct DuckDBPyResult;
21: 
22: class RegisteredObject {
23: public:
24: 	explicit RegisteredObject(py::object obj_p) : obj(move(obj_p)) {
25: 	}
26: 	virtual ~RegisteredObject() {
27: 		obj = py::none();
28: 	}
29: 
30: 	py::object obj;
31: };
32: 
33: class RegisteredArrow : public RegisteredObject {
34: 
35: public:
36: 	RegisteredArrow(unique_ptr<PythonTableArrowArrayStreamFactory> arrow_factory_p, py::object obj_p)
37: 	    : RegisteredObject(std::move(obj_p)), arrow_factory(move(arrow_factory_p)) {};
38: 	unique_ptr<PythonTableArrowArrayStreamFactory> arrow_factory;
39: };
40: 
41: struct DuckDBPyConnection {
42: public:
43: 	shared_ptr<DuckDB> database;
44: 	unique_ptr<Connection> connection;
45: 	unordered_map<string, unique_ptr<RegisteredObject>> registered_objects;
46: 	unique_ptr<DuckDBPyResult> result;
47: 	vector<shared_ptr<DuckDBPyConnection>> cursors;
48: 
49: public:
50: 	static void Initialize(py::handle &m);
51: 	static void Cleanup();
52: 
53: 	static DuckDBPyConnection *DefaultConnection();
54: 
55: 	DuckDBPyConnection *ExecuteMany(const string &query, py::object params = py::list());
56: 
57: 	DuckDBPyConnection *Execute(const string &query, py::object params = py::list(), bool many = false);
58: 
59: 	DuckDBPyConnection *Append(const string &name, py::object value);
60: 
61: 	DuckDBPyConnection *RegisterDF(const string &name, py::object value);
62: 
63: 	unique_ptr<DuckDBPyRelation> FromQuery(const string &query, const string &alias = "query_relation");
64: 	DuckDBPyConnection *RegisterArrow(const string &name, py::object value);
65: 
66: 	unique_ptr<DuckDBPyRelation> Table(const string &tname);
67: 
68: 	unique_ptr<DuckDBPyRelation> Values(py::object params = py::list());
69: 
70: 	unique_ptr<DuckDBPyRelation> View(const string &vname);
71: 
72: 	unique_ptr<DuckDBPyRelation> TableFunction(const string &fname, py::object params = py::list());
73: 
74: 	unique_ptr<DuckDBPyRelation> FromDF(py::object value);
75: 
76: 	unique_ptr<DuckDBPyRelation> FromCsvAuto(const string &filename);
77: 
78: 	unique_ptr<DuckDBPyRelation> FromParquet(const string &filename);
79: 
80: 	unique_ptr<DuckDBPyRelation> FromArrowTable(py::object &table);
81: 
82: 	DuckDBPyConnection *UnregisterPythonObject(const string &name);
83: 
84: 	DuckDBPyConnection *Begin();
85: 
86: 	DuckDBPyConnection *Commit();
87: 
88: 	DuckDBPyConnection *Rollback();
89: 
90: 	py::object GetAttr(const py::str &key);
91: 
92: 	void Close();
93: 
94: 	// cursor() is stupid
95: 	shared_ptr<DuckDBPyConnection> Cursor();
96: 
97: 	// these should be functions on the result but well
98: 	py::object FetchOne();
99: 
100: 	py::list FetchAll();
101: 
102: 	py::dict FetchNumpy();
103: 	py::object FetchDF();
104: 
105: 	py::object FetchDFChunk() const;
106: 
107: 	py::object FetchArrow();
108: 
109: 	static shared_ptr<DuckDBPyConnection> Connect(const string &database, bool read_only);
110: 
111: 	static vector<Value> TransformPythonParamList(py::handle params);
112: 
113: private:
114: 	//! Default connection to an in-memory database
115: 	static shared_ptr<DuckDBPyConnection> default_connection;
116: };
117: 
118: } // namespace duckdb
[end of tools/pythonpkg/src/include/duckdb_python/pyconnection.hpp]
[start of tools/pythonpkg/src/pyconnection.cpp]
1: #include "duckdb_python/pyconnection.hpp"
2: #include "duckdb_python/pyresult.hpp"
3: #include "duckdb_python/pyrelation.hpp"
4: #include "duckdb_python/pandas_scan.hpp"
5: #include "duckdb_python/map.hpp"
6: 
7: #include "duckdb/common/arrow.hpp"
8: #include "duckdb_python/arrow_array_stream.hpp"
9: #include "duckdb/parser/parsed_data/create_table_function_info.hpp"
10: #include "duckdb/main/client_context.hpp"
11: #include "duckdb/parser/parsed_data/create_table_function_info.hpp"
12: #include "duckdb/common/types/vector.hpp"
13: #include "duckdb/common/printer.hpp"
14: #include "duckdb/main/config.hpp"
15: #include "duckdb/parser/expression/constant_expression.hpp"
16: #include "duckdb/parser/expression/function_expression.hpp"
17: #include "duckdb/parser/tableref/table_function_ref.hpp"
18: 
19: #include "extension/extension_helper.hpp"
20: 
21: #include "datetime.h" // from Python
22: 
23: #include <random>
24: 
25: namespace duckdb {
26: 
27: shared_ptr<DuckDBPyConnection> DuckDBPyConnection::default_connection = nullptr;
28: 
29: void DuckDBPyConnection::Initialize(py::handle &m) {
30: 	py::class_<DuckDBPyConnection, shared_ptr<DuckDBPyConnection>>(m, "DuckDBPyConnection")
31: 	    .def("cursor", &DuckDBPyConnection::Cursor, "Create a duplicate of the current connection")
32: 	    .def("duplicate", &DuckDBPyConnection::Cursor, "Create a duplicate of the current connection")
33: 	    .def("execute", &DuckDBPyConnection::Execute,
34: 	         "Execute the given SQL query, optionally using prepared statements with parameters set", py::arg("query"),
35: 	         py::arg("parameters") = py::list(), py::arg("multiple_parameter_sets") = false)
36: 	    .def("executemany", &DuckDBPyConnection::ExecuteMany,
37: 	         "Execute the given prepared statement multiple times using the list of parameter sets in parameters",
38: 	         py::arg("query"), py::arg("parameters") = py::list())
39: 	    .def("close", &DuckDBPyConnection::Close, "Close the connection")
40: 	    .def("fetchone", &DuckDBPyConnection::FetchOne, "Fetch a single row from a result following execute")
41: 	    .def("fetchall", &DuckDBPyConnection::FetchAll, "Fetch all rows from a result following execute")
42: 	    .def("fetchnumpy", &DuckDBPyConnection::FetchNumpy, "Fetch a result as list of NumPy arrays following execute")
43: 	    .def("fetchdf", &DuckDBPyConnection::FetchDF, "Fetch a result as Data.Frame following execute()")
44: 	    .def("fetch_df", &DuckDBPyConnection::FetchDF, "Fetch a result as Data.Frame following execute()")
45: 	    .def("fetch_df_chunk", &DuckDBPyConnection::FetchDFChunk,
46: 	         "Fetch a chunk of the result as Data.Frame following execute()")
47: 	    .def("df", &DuckDBPyConnection::FetchDF, "Fetch a result as Data.Frame following execute()")
48: 	    .def("fetch_arrow_table", &DuckDBPyConnection::FetchArrow, "Fetch a result as Arrow table following execute()")
49: 	    .def("arrow", &DuckDBPyConnection::FetchArrow, "Fetch a result as Arrow table following execute()")
50: 	    .def("begin", &DuckDBPyConnection::Begin, "Start a new transaction")
51: 	    .def("commit", &DuckDBPyConnection::Commit, "Commit changes performed within a transaction")
52: 	    .def("rollback", &DuckDBPyConnection::Rollback, "Roll back changes performed within a transaction")
53: 	    .def("append", &DuckDBPyConnection::Append, "Append the passed Data.Frame to the named table",
54: 	         py::arg("table_name"), py::arg("df"))
55: 	    .def("register", &DuckDBPyConnection::RegisterDF,
56: 	         "Register the passed Data.Frame value for querying with a view", py::arg("view_name"), py::arg("df"))
57: 	    .def("unregister", &DuckDBPyConnection::UnregisterPythonObject, "Unregister the view name",
58: 	         py::arg("view_name"))
59: 	    .def("register_arrow", &DuckDBPyConnection::RegisterArrow,
60: 	         "Register the passed Arrow Table for querying with a view", py::arg("view_name"), py::arg("arrow_table"))
61: 	    .def("table", &DuckDBPyConnection::Table, "Create a relation object for the name'd table",
62: 	         py::arg("table_name"))
63: 	    .def("view", &DuckDBPyConnection::View, "Create a relation object for the name'd view", py::arg("view_name"))
64: 	    .def("values", &DuckDBPyConnection::Values, "Create a relation object from the passed values",
65: 	         py::arg("values"))
66: 	    .def("table_function", &DuckDBPyConnection::TableFunction,
67: 	         "Create a relation object from the name'd table function with given parameters", py::arg("name"),
68: 	         py::arg("parameters") = py::list())
69: 	    .def("from_query", &DuckDBPyConnection::FromQuery, "Create a relation object from the given SQL query",
70: 	         py::arg("query"), py::arg("alias") = "query_relation")
71: 	    .def("query", &DuckDBPyConnection::FromQuery, "Create a relation object from the given SQL query",
72: 	         py::arg("query"), py::arg("alias") = "query_relation")
73: 	    .def("from_df", &DuckDBPyConnection::FromDF, "Create a relation object from the Data.Frame in df",
74: 	         py::arg("df") = py::none())
75: 	    .def("from_arrow_table", &DuckDBPyConnection::FromArrowTable, "Create a relation object from an Arrow table",
76: 	         py::arg("table"))
77: 	    .def("df", &DuckDBPyConnection::FromDF, "Create a relation object from the Data.Frame in df (alias of from_df)",
78: 	         py::arg("df"))
79: 	    .def("from_csv_auto", &DuckDBPyConnection::FromCsvAuto,
80: 	         "Create a relation object from the CSV file in file_name", py::arg("file_name"))
81: 	    .def("from_parquet", &DuckDBPyConnection::FromParquet,
82: 	         "Create a relation object from the Parquet file in file_name", py::arg("file_name"))
83: 	    .def("__getattr__", &DuckDBPyConnection::GetAttr, "Get result set attributes, mainly column names");
84: 
85: 	PyDateTime_IMPORT;
86: }
87: 
88: DuckDBPyConnection *DuckDBPyConnection::ExecuteMany(const string &query, py::object params) {
89: 	Execute(query, std::move(params), true);
90: 	return this;
91: }
92: 
93: DuckDBPyConnection *DuckDBPyConnection::Execute(const string &query, py::object params, bool many) {
94: 	if (!connection) {
95: 		throw std::runtime_error("connection closed");
96: 	}
97: 	result = nullptr;
98: 
99: 	auto statements = connection->ExtractStatements(query);
100: 	if (statements.empty()) {
101: 		// no statements to execute
102: 		return this;
103: 	}
104: 	// if there are multiple statements, we directly execute the statements besides the last one
105: 	// we only return the result of the last statement to the user, unless one of the previous statements fails
106: 	for (idx_t i = 0; i + 1 < statements.size(); i++) {
107: 		auto res = connection->Query(move(statements[i]));
108: 		if (!res->success) {
109: 			throw std::runtime_error(res->error);
110: 		}
111: 	}
112: 
113: 	auto prep = connection->Prepare(move(statements.back()));
114: 	if (!prep->success) {
115: 		throw std::runtime_error(prep->error);
116: 	}
117: 
118: 	// this is a list of a list of parameters in executemany
119: 	py::list params_set;
120: 	if (!many) {
121: 		params_set = py::list(1);
122: 		params_set[0] = params;
123: 	} else {
124: 		params_set = params;
125: 	}
126: 
127: 	for (pybind11::handle single_query_params : params_set) {
128: 		if (prep->n_param != py::len(single_query_params)) {
129: 			throw std::runtime_error("Prepared statement needs " + to_string(prep->n_param) + " parameters, " +
130: 			                         to_string(py::len(single_query_params)) + " given");
131: 		}
132: 		auto args = DuckDBPyConnection::TransformPythonParamList(single_query_params);
133: 		auto res = make_unique<DuckDBPyResult>();
134: 		{
135: 			py::gil_scoped_release release;
136: 			res->result = prep->Execute(args);
137: 		}
138: 		if (!res->result->success) {
139: 			throw std::runtime_error(res->result->error);
140: 		}
141: 		if (!many) {
142: 			result = move(res);
143: 		}
144: 	}
145: 	return this;
146: }
147: 
148: DuckDBPyConnection *DuckDBPyConnection::Append(const string &name, py::object value) {
149: 	RegisterDF("__append_df", std::move(value));
150: 	return Execute("INSERT INTO \"" + name + "\" SELECT * FROM __append_df");
151: }
152: 
153: DuckDBPyConnection *DuckDBPyConnection::RegisterDF(const string &name, py::object value) {
154: 	if (!connection) {
155: 		throw std::runtime_error("connection closed");
156: 	}
157: 	connection->TableFunction("pandas_scan", {Value::POINTER((uintptr_t)value.ptr())})->CreateView(name, true, true);
158: 	// keep a reference
159: 	auto object = make_unique<RegisteredObject>(value);
160: 	registered_objects[name] = move(object);
161: 	return this;
162: }
163: 
164: DuckDBPyConnection *DuckDBPyConnection::RegisterArrow(const string &name, py::object table) {
165: 	if (!connection) {
166: 		throw std::runtime_error("connection closed");
167: 	}
168: 	if (table.is_none() || string(py::str(table.get_type().attr("__name__"))) != "Table") {
169: 		throw std::runtime_error("Only arrow tables supported");
170: 	}
171: 	auto stream_factory = make_unique<PythonTableArrowArrayStreamFactory>(table.ptr());
172: 
173: 	auto stream_factory_produce = PythonTableArrowArrayStreamFactory::Produce;
174: 	connection
175: 	    ->TableFunction("arrow_scan", {Value::POINTER((uintptr_t)stream_factory.get()),
176: 	                                   Value::POINTER((uintptr_t)stream_factory_produce)})
177: 	    ->CreateView(name, true, true);
178: 	auto object = make_unique<RegisteredArrow>(move(stream_factory), table);
179: 	registered_objects[name] = move(object);
180: 	return this;
181: }
182: 
183: unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromQuery(const string &query, const string &alias) {
184: 	if (!connection) {
185: 		throw std::runtime_error("connection closed");
186: 	}
187: 	return make_unique<DuckDBPyRelation>(connection->RelationFromQuery(query, alias));
188: }
189: 
190: unique_ptr<DuckDBPyRelation> DuckDBPyConnection::Table(const string &tname) {
191: 	if (!connection) {
192: 		throw std::runtime_error("connection closed");
193: 	}
194: 	return make_unique<DuckDBPyRelation>(connection->Table(tname));
195: }
196: 
197: unique_ptr<DuckDBPyRelation> DuckDBPyConnection::Values(py::object params) {
198: 	if (!connection) {
199: 		throw std::runtime_error("connection closed");
200: 	}
201: 	vector<vector<Value>> values {DuckDBPyConnection::TransformPythonParamList(std::move(params))};
202: 	return make_unique<DuckDBPyRelation>(connection->Values(values));
203: }
204: 
205: unique_ptr<DuckDBPyRelation> DuckDBPyConnection::View(const string &vname) {
206: 	if (!connection) {
207: 		throw std::runtime_error("connection closed");
208: 	}
209: 	return make_unique<DuckDBPyRelation>(connection->View(vname));
210: }
211: 
212: unique_ptr<DuckDBPyRelation> DuckDBPyConnection::TableFunction(const string &fname, py::object params) {
213: 	if (!connection) {
214: 		throw std::runtime_error("connection closed");
215: 	}
216: 
217: 	return make_unique<DuckDBPyRelation>(
218: 	    connection->TableFunction(fname, DuckDBPyConnection::TransformPythonParamList(std::move(params))));
219: }
220: 
221: static std::string GenerateRandomName() {
222: 	std::random_device rd;
223: 	std::mt19937 gen(rd());
224: 	std::uniform_int_distribution<> dis(0, 15);
225: 
226: 	std::stringstream ss;
227: 	int i;
228: 	ss << std::hex;
229: 	for (i = 0; i < 16; i++) {
230: 		ss << dis(gen);
231: 	}
232: 	return ss.str();
233: }
234: 
235: unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromDF(py::object value) {
236: 	if (!connection) {
237: 		throw std::runtime_error("connection closed");
238: 	}
239: 	string name = "df_" + GenerateRandomName();
240: 	registered_objects[name] = make_unique<RegisteredObject>(value);
241: 	vector<Value> params;
242: 	params.emplace_back(Value::POINTER((uintptr_t)value.ptr()));
243: 	return make_unique<DuckDBPyRelation>(connection->TableFunction("pandas_scan", params)->Alias(name));
244: }
245: 
246: unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromCsvAuto(const string &filename) {
247: 	if (!connection) {
248: 		throw std::runtime_error("connection closed");
249: 	}
250: 	vector<Value> params;
251: 	params.emplace_back(filename);
252: 	return make_unique<DuckDBPyRelation>(connection->TableFunction("read_csv_auto", params)->Alias(filename));
253: }
254: 
255: unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromParquet(const string &filename) {
256: 	if (!connection) {
257: 		throw std::runtime_error("connection closed");
258: 	}
259: 	vector<Value> params;
260: 	params.emplace_back(filename);
261: 	return make_unique<DuckDBPyRelation>(connection->TableFunction("parquet_scan", params)->Alias(filename));
262: }
263: 
264: unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromArrowTable(py::object &table) {
265: 	if (!connection) {
266: 		throw std::runtime_error("connection closed");
267: 	}
268: 	py::gil_scoped_acquire acquire;
269: 
270: 	// the following is a careful dance around having to depend on pyarrow
271: 	if (table.is_none() || string(py::str(table.get_type().attr("__name__"))) != "Table") {
272: 		throw std::runtime_error("Only arrow tables supported");
273: 	}
274: 	string name = "arrow_table_" + GenerateRandomName();
275: 
276: 	//	registered_arrow[name] = table;
277: 	auto stream_factory = make_unique<PythonTableArrowArrayStreamFactory>(table.ptr());
278: 
279: 	unique_ptr<ArrowArrayStreamWrapper> (*stream_factory_produce)(uintptr_t factory) =
280: 	    PythonTableArrowArrayStreamFactory::Produce;
281: 	auto rel = make_unique<DuckDBPyRelation>(
282: 	    connection
283: 	        ->TableFunction("arrow_scan", {Value::POINTER((uintptr_t)stream_factory.get()),
284: 	                                       Value::POINTER((uintptr_t)stream_factory_produce)})
285: 	        ->Alias(name));
286: 	registered_objects[name] = make_unique<RegisteredArrow>(move(stream_factory), table);
287: 	return rel;
288: }
289: 
290: DuckDBPyConnection *DuckDBPyConnection::UnregisterPythonObject(const string &name) {
291: 	registered_objects.erase(name);
292: 
293: 	if (connection) {
294: 		connection->Query("DROP VIEW \"" + name + "\"");
295: 	}
296: 	return this;
297: }
298: 
299: DuckDBPyConnection *DuckDBPyConnection::Begin() {
300: 	Execute("BEGIN TRANSACTION");
301: 	return this;
302: }
303: 
304: DuckDBPyConnection *DuckDBPyConnection::Commit() {
305: 	if (connection->context->transaction.IsAutoCommit()) {
306: 		return this;
307: 	}
308: 	Execute("COMMIT");
309: 	return this;
310: }
311: 
312: DuckDBPyConnection *DuckDBPyConnection::Rollback() {
313: 	Execute("ROLLBACK");
314: 	return this;
315: }
316: 
317: py::object DuckDBPyConnection::GetAttr(const py::str &key) {
318: 	if (key.cast<string>() == "description") {
319: 		if (!result) {
320: 			throw std::runtime_error("no open result set");
321: 		}
322: 		return result->Description();
323: 	}
324: 	return py::none();
325: }
326: 
327: void DuckDBPyConnection::Close() {
328: 	result = nullptr;
329: 	connection = nullptr;
330: 	database = nullptr;
331: 	for (auto &cur : cursors) {
332: 		cur->Close();
333: 	}
334: 	cursors.clear();
335: }
336: 
337: // cursor() is stupid
338: shared_ptr<DuckDBPyConnection> DuckDBPyConnection::Cursor() {
339: 	auto res = make_shared<DuckDBPyConnection>();
340: 	res->database = database;
341: 	res->connection = make_unique<Connection>(*res->database);
342: 	cursors.push_back(res);
343: 	return res;
344: }
345: 
346: // these should be functions on the result but well
347: py::object DuckDBPyConnection::FetchOne() {
348: 	if (!result) {
349: 		throw std::runtime_error("no open result set");
350: 	}
351: 	return result->Fetchone();
352: }
353: 
354: py::list DuckDBPyConnection::FetchAll() {
355: 	if (!result) {
356: 		throw std::runtime_error("no open result set");
357: 	}
358: 	return result->Fetchall();
359: }
360: 
361: py::dict DuckDBPyConnection::FetchNumpy() {
362: 	if (!result) {
363: 		throw std::runtime_error("no open result set");
364: 	}
365: 	return result->FetchNumpy();
366: }
367: py::object DuckDBPyConnection::FetchDF() {
368: 	if (!result) {
369: 		throw std::runtime_error("no open result set");
370: 	}
371: 	return result->FetchDF();
372: }
373: 
374: py::object DuckDBPyConnection::FetchDFChunk() const {
375: 	if (!result) {
376: 		throw std::runtime_error("no open result set");
377: 	}
378: 	return result->FetchDFChunk();
379: }
380: 
381: py::object DuckDBPyConnection::FetchArrow() {
382: 	if (!result) {
383: 		throw std::runtime_error("no open result set");
384: 	}
385: 	return result->FetchArrowTable();
386: }
387: 
388: static unique_ptr<TableFunctionRef> TryPandasReplacement(py::dict &dict, py::str &table_name) {
389: 	if (!dict.contains(table_name)) {
390: 		// not present in the globals
391: 		return nullptr;
392: 	}
393: 	auto entry = dict[table_name];
394: 
395: 	// check if there is a local or global variable
396: 	auto table_function = make_unique<TableFunctionRef>();
397: 	vector<unique_ptr<ParsedExpression>> children;
398: 	children.push_back(make_unique<ConstantExpression>(Value::POINTER((uintptr_t)entry.ptr())));
399: 	table_function->function = make_unique<FunctionExpression>("pandas_scan", children);
400: 	return table_function;
401: }
402: 
403: static unique_ptr<TableFunctionRef> PandasScanReplacement(const string &table_name, void *data) {
404: 	py::gil_scoped_acquire acquire;
405: 	// look in the locals first
406: 	PyObject *p = PyEval_GetLocals();
407: 	auto py_table_name = py::str(table_name);
408: 	if (p) {
409: 		auto local_dict = py::reinterpret_borrow<py::dict>(p);
410: 		auto result = TryPandasReplacement(local_dict, py_table_name);
411: 		if (result) {
412: 			return result;
413: 		}
414: 	}
415: 	// otherwise look in the globals
416: 	auto global_dict = py::globals();
417: 	return TryPandasReplacement(global_dict, py_table_name);
418: }
419: 
420: shared_ptr<DuckDBPyConnection> DuckDBPyConnection::Connect(const string &database, bool read_only) {
421: 	auto res = make_shared<DuckDBPyConnection>();
422: 	DBConfig config;
423: 	if (read_only) {
424: 		config.access_mode = AccessMode::READ_ONLY;
425: 	}
426: 	config.replacement_scans.emplace_back(PandasScanReplacement);
427: 
428: 	res->database = make_unique<DuckDB>(database, &config);
429: 	ExtensionHelper::LoadAllExtensions(*res->database);
430: 	res->connection = make_unique<Connection>(*res->database);
431: 
432: 	PandasScanFunction scan_fun;
433: 	CreateTableFunctionInfo scan_info(scan_fun);
434: 
435: 	MapFunction map_fun;
436: 	CreateTableFunctionInfo map_info(map_fun);
437: 
438: 	auto &context = *res->connection->context;
439: 	auto &catalog = Catalog::GetCatalog(context);
440: 	context.transaction.BeginTransaction();
441: 	catalog.CreateTableFunction(context, &scan_info);
442: 	catalog.CreateTableFunction(context, &map_info);
443: 
444: 	context.transaction.Commit();
445: 
446: 	return res;
447: }
448: 
449: vector<Value> DuckDBPyConnection::TransformPythonParamList(py::handle params) {
450: 	vector<Value> args;
451: 
452: 	auto datetime_mod = py::module::import("datetime");
453: 	auto datetime_date = datetime_mod.attr("date");
454: 	auto datetime_datetime = datetime_mod.attr("datetime");
455: 	auto datetime_time = datetime_mod.attr("time");
456: 	auto decimal_mod = py::module::import("decimal");
457: 	auto decimal_decimal = decimal_mod.attr("Decimal");
458: 
459: 	for (pybind11::handle ele : params) {
460: 		if (ele.is_none()) {
461: 			args.emplace_back();
462: 		} else if (py::isinstance<py::bool_>(ele)) {
463: 			args.push_back(Value::BOOLEAN(ele.cast<bool>()));
464: 		} else if (py::isinstance<py::int_>(ele)) {
465: 			args.push_back(Value::BIGINT(ele.cast<int64_t>()));
466: 		} else if (py::isinstance<py::float_>(ele)) {
467: 			args.push_back(Value::DOUBLE(ele.cast<double>()));
468: 		} else if (py::isinstance<py::str>(ele)) {
469: 			args.emplace_back(ele.cast<string>());
470: 		} else if (py::isinstance(ele, decimal_decimal)) {
471: 			args.emplace_back(py::str(ele).cast<string>());
472: 		} else if (py::isinstance(ele, datetime_datetime)) {
473: 			auto year = PyDateTime_GET_YEAR(ele.ptr());
474: 			auto month = PyDateTime_GET_MONTH(ele.ptr());
475: 			auto day = PyDateTime_GET_DAY(ele.ptr());
476: 			auto hour = PyDateTime_DATE_GET_HOUR(ele.ptr());
477: 			auto minute = PyDateTime_DATE_GET_MINUTE(ele.ptr());
478: 			auto second = PyDateTime_DATE_GET_SECOND(ele.ptr());
479: 			auto micros = PyDateTime_DATE_GET_MICROSECOND(ele.ptr());
480: 			args.push_back(Value::TIMESTAMP(year, month, day, hour, minute, second, micros));
481: 		} else if (py::isinstance(ele, datetime_time)) {
482: 			auto hour = PyDateTime_TIME_GET_HOUR(ele.ptr());
483: 			auto minute = PyDateTime_TIME_GET_MINUTE(ele.ptr());
484: 			auto second = PyDateTime_TIME_GET_SECOND(ele.ptr());
485: 			auto micros = PyDateTime_TIME_GET_MICROSECOND(ele.ptr());
486: 			args.push_back(Value::TIME(hour, minute, second, micros));
487: 		} else if (py::isinstance(ele, datetime_date)) {
488: 			auto year = PyDateTime_GET_YEAR(ele.ptr());
489: 			auto month = PyDateTime_GET_MONTH(ele.ptr());
490: 			auto day = PyDateTime_GET_DAY(ele.ptr());
491: 			args.push_back(Value::DATE(year, month, day));
492: 		} else {
493: 			throw std::runtime_error("unknown param type " + py::str(ele.get_type()).cast<string>());
494: 		}
495: 	}
496: 	return args;
497: }
498: 
499: DuckDBPyConnection *DuckDBPyConnection::DefaultConnection() {
500: 	if (!default_connection) {
501: 		default_connection = DuckDBPyConnection::Connect(":memory:", false);
502: 	}
503: 	return default_connection.get();
504: }
505: 
506: void DuckDBPyConnection::Cleanup() {
507: 	default_connection.reset();
508: }
509: 
510: } // namespace duckdb
[end of tools/pythonpkg/src/pyconnection.cpp]
[start of tools/rest/server.cpp]
1: #include <chrono>
2: #include <cstdio>
3: #include <thread>
4: #include <iostream>
5: 
6: #include "duckdb.hpp"
7: #include "duckdb/common/types/data_chunk.hpp"
8: #include "duckdb/common/vector_operations/vector_operations.hpp"
9: #include "duckdb/common/string_util.hpp"
10: #include "duckdb/main/client_context.hpp"
11: 
12: #include "extension_helper.hpp"
13: 
14: // you can set this to enable compression. You will need to link zlib as well.
15: // #define CPPHTTPLIB_ZLIB_SUPPORT 1
16: #define CPPHTTPLIB_KEEPALIVE_TIMEOUT_USECOND 10000
17: #define CPPHTTPLIB_KEEPALIVE_TIMEOUT_SECOND  0
18: #define CPPHTTPLIB_THREAD_POOL_COUNT         16
19: 
20: #include "httplib.hpp"
21: #include "json.hpp"
22: 
23: #include <unordered_map>
24: 
25: using namespace httplib;
26: using namespace duckdb;
27: using namespace nlohmann;
28: 
29: void print_help() {
30: 	fprintf(stderr, "🦆 Usage: duckdb_rest_server\n");
31: 	fprintf(stderr, "          --listen=[address]    listening address\n");
32: 	fprintf(stderr, "          --port=[no]           listening port\n");
33: 	fprintf(stderr, "          --database=[file]     use given database file\n");
34: 	fprintf(stderr, "          --read_only           open database in read-only mode\n");
35: 	fprintf(stderr, "          --disable_copy        disallow file import/export, e.g. in COPY\n");
36: 	fprintf(stderr, "          --query_timeout=[sec] query timeout in seconds\n");
37: 	fprintf(stderr, "          --fetch_timeout=[sec] result set timeout in seconds\n");
38: 	fprintf(stderr, "          --static=[folder]     static resource folder to serve\n");
39: 	fprintf(stderr, "          --log=[file]          log queries to file\n\n");
40: 	fprintf(stderr, "Version: %s\n", DuckDB::SourceID());
41: }
42: 
43: // https://stackoverflow.com/a/12468109/2652376
44: std::string random_string(size_t length) {
45: 	auto randchar = []() -> char {
46: 		const char charset[] = "0123456789"
47: 		                       "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
48: 		                       "abcdefghijklmnopqrstuvwxyz";
49: 		const size_t max_index = (sizeof(charset) - 1);
50: 		return charset[rand() % max_index];
51: 	};
52: 	std::string str(length, 0);
53: 	std::generate_n(str.begin(), length, randchar);
54: 	return str;
55: }
56: 
57: struct RestClientState {
58: 	unique_ptr<duckdb::QueryResult> res;
59: 	unique_ptr<duckdb::Connection> con;
60: 	time_t touched;
61: };
62: 
63: enum ReturnContentType { JSON, BSON, CBOR, MESSAGE_PACK, UBJSON };
64: 
65: template <class T, class TARGET>
66: static void assign_json_loop(Vector &v, idx_t col_idx, idx_t count, json &j) {
67: 	v.Normalify(count);
68: 	auto data_ptr = FlatVector::GetData<T>(v);
69: 	auto &mask = FlatVector::Validity(v);
70: 	for (idx_t i = 0; i < count; i++) {
71: 		if (mask.RowIsValid(i)) {
72: 			j["data"][col_idx] += (TARGET)data_ptr[i];
73: 		} else {
74: 			j["data"][col_idx] += nullptr;
75: 		}
76: 	}
77: }
78: 
79: static void assign_json_string_loop(Vector &v, idx_t col_idx, idx_t count, json &j) {
80: 	Vector cast_vector(LogicalType::VARCHAR);
81: 	Vector *result_vector;
82: 	if (v.GetType().id() != LogicalTypeId::VARCHAR) {
83: 		VectorOperations::Cast(v, cast_vector, count);
84: 		result_vector = &cast_vector;
85: 	} else {
86: 		result_vector = &v;
87: 	}
88: 	result_vector->Normalify(count);
89: 	auto data_ptr = FlatVector::GetData<string_t>(*result_vector);
90: 	auto &mask = FlatVector::Validity(*result_vector);
91: 	for (idx_t i = 0; i < count; i++) {
92: 		if (mask.RowIsValid(i)) {
93: 			j["data"][col_idx] += data_ptr[i].GetString();
94: 
95: 		} else {
96: 			j["data"][col_idx] += nullptr;
97: 		}
98: 	}
99: }
100: 
101: void serialize_chunk(QueryResult *res, DataChunk *chunk, json &j) {
102: 	D_ASSERT(res);
103: 	for (size_t col_idx = 0; col_idx < chunk->ColumnCount(); col_idx++) {
104: 		Vector &v = chunk->data[col_idx];
105: 		switch (v.GetType().id()) {
106: 		case LogicalTypeId::BOOLEAN:
107: 			assign_json_loop<bool, int64_t>(v, col_idx, chunk->size(), j);
108: 			break;
109: 		case LogicalTypeId::TINYINT:
110: 			assign_json_loop<int8_t, int64_t>(v, col_idx, chunk->size(), j);
111: 			break;
112: 		case LogicalTypeId::SMALLINT:
113: 			assign_json_loop<int16_t, int64_t>(v, col_idx, chunk->size(), j);
114: 			break;
115: 		case LogicalTypeId::INTEGER:
116: 			assign_json_loop<int32_t, int64_t>(v, col_idx, chunk->size(), j);
117: 			break;
118: 		case LogicalTypeId::BIGINT:
119: 			assign_json_loop<int64_t, int64_t>(v, col_idx, chunk->size(), j);
120: 			break;
121: 		case LogicalTypeId::FLOAT:
122: 			assign_json_loop<float, double>(v, col_idx, chunk->size(), j);
123: 			break;
124: 		case LogicalTypeId::DOUBLE:
125: 			assign_json_loop<double, double>(v, col_idx, chunk->size(), j);
126: 			break;
127: 		case LogicalTypeId::DATE:
128: 		case LogicalTypeId::TIME:
129: 		case LogicalTypeId::TIMESTAMP:
130: 		case LogicalTypeId::DECIMAL:
131: 		case LogicalTypeId::INTERVAL:
132: 		case LogicalTypeId::HUGEINT:
133: 		case LogicalTypeId::BLOB:
134: 		case LogicalTypeId::VARCHAR:
135: 		default:
136: 			assign_json_string_loop(v, col_idx, chunk->size(), j);
137: 			break;
138: 		}
139: 	}
140: }
141: 
142: void serialize_json(const Request &req, Response &resp, json &j) {
143: 	auto return_type = ReturnContentType::JSON;
144: 	j["duckdb_version"] = DuckDB::SourceID();
145: 
146: 	if (req.has_header("Accept")) {
147: 		auto accept = req.get_header_value("Accept");
148: 		if (accept.rfind("application/bson", 0) == 0 || accept.rfind("application/x-bson", 0) == 0) {
149: 			return_type = ReturnContentType::BSON;
150: 		} else if (accept.rfind("application/cbor", 0) == 0) {
151: 			return_type = ReturnContentType::CBOR;
152: 		} else if (accept.rfind("application/msgpack", 0) == 0 || accept.rfind("application/x-msgpack", 0) == 0 ||
153: 		           accept.rfind("application/vnd.msgpack", 0) == 0) {
154: 			return_type = ReturnContentType::MESSAGE_PACK;
155: 		} else if (accept.rfind("application/ubjson", 0) == 0) {
156: 			return_type = ReturnContentType::UBJSON;
157: 		}
158: 	}
159: 
160: 	switch (return_type) {
161: 	case ReturnContentType::JSON: {
162: 		if (req.has_param("callback")) {
163: 			auto jsonp_callback = req.get_param_value("callback");
164: 			resp.set_content(jsonp_callback + "(" + j.dump() + ");", "application/javascript");
165: 
166: 		} else {
167: 			resp.set_content(j.dump(), "application/json");
168: 		}
169: 		break;
170: 	}
171: 	case ReturnContentType::BSON: {
172: 		auto bson = json::to_bson(j);
173: 		resp.set_content((const char *)bson.data(), bson.size(), "application/bson");
174: 		break;
175: 	}
176: 	case ReturnContentType::CBOR: {
177: 		auto cbor = json::to_cbor(j);
178: 		resp.set_content((const char *)cbor.data(), cbor.size(), "application/cbor");
179: 		break;
180: 	}
181: 	case ReturnContentType::MESSAGE_PACK: {
182: 		auto msgpack = json::to_msgpack(j);
183: 		resp.set_content((const char *)msgpack.data(), msgpack.size(), "application/msgpack");
184: 		break;
185: 	}
186: 	case ReturnContentType::UBJSON: {
187: 		auto ubjson = json::to_ubjson(j);
188: 		resp.set_content((const char *)ubjson.data(), ubjson.size(), "application/ubjson");
189: 		break;
190: 	}
191: 	}
192: }
193: 
194: void sleep_thread(duckdb::Connection *conn, bool *is_active, int timeout_duration) {
195: 	// timeout is given in seconds
196: 	// we wait 10ms per iteration, so timeout * 100 gives us the amount of
197: 	// iterations
198: 	D_ASSERT(conn);
199: 	D_ASSERT(is_active);
200: 
201: 	if (timeout_duration < 0) {
202: 		return;
203: 	}
204: 	for (size_t i = 0; i < (size_t)(timeout_duration * 100) && *is_active; i++) {
205: 		std::this_thread::sleep_for(std::chrono::milliseconds(10));
206: 	}
207: 	if (*is_active) {
208: 		conn->Interrupt();
209: 	}
210: }
211: 
212: void client_state_cleanup(unordered_map<string, RestClientState> *map, std::mutex *mutex, int timeout_duration) {
213: 	// timeout is given in seconds
214: 	while (true) {
215: 		// sleep for half the timeout duration
216: 		std::this_thread::sleep_for(std::chrono::milliseconds((timeout_duration * 1000) / 2));
217: 		{
218: 			std::lock_guard<std::mutex> guard(*mutex);
219: 			auto now = std::time(nullptr);
220: 			for (auto it = map->cbegin(); it != map->cend();) {
221: 				if (now - it->second.touched > timeout_duration) {
222: 					it = map->erase(it);
223: 				} else {
224: 					++it;
225: 				}
226: 			}
227: 		}
228: 	}
229: }
230: 
231: int main(int argc, char **argv) {
232: 	Server svr;
233: 	if (!svr.is_valid()) {
234: 		printf("server has an error...\n");
235: 		return -1;
236: 	}
237: 
238: 	std::mutex out_mutex;
239: 	srand(time(nullptr));
240: 
241: 	DBConfig config;
242: 	string dbfile = "";
243: 	string logfile_name;
244: 
245: 	string listen = "localhost";
246: 	string static_files;
247: 	int port = 1294;
248: 	std::ofstream logfile;
249: 
250: 	int query_timeout = 60;
251: 	int fetch_timeout = 60 * 5;
252: 
253: 	// parse config
254: 	for (int arg_index = 1; arg_index < argc; ++arg_index) {
255: 		string arg = argv[arg_index];
256: 		if (arg == "--help") {
257: 			print_help();
258: 			exit(0);
259: 		} else if (arg == "--read_only") {
260: 			config.access_mode = AccessMode::READ_ONLY;
261: 		} else if (arg == "--disable_copy") {
262: 			config.enable_copy = false;
263: 		} else if (StringUtil::StartsWith(arg, "--database=")) {
264: 			auto splits = StringUtil::Split(arg, '=');
265: 			if (splits.size() != 2) {
266: 				print_help();
267: 				exit(1);
268: 			}
269: 			dbfile = string(splits[1]);
270: 		} else if (StringUtil::StartsWith(arg, "--log=")) {
271: 			auto splits = StringUtil::Split(arg, '=');
272: 			if (splits.size() != 2) {
273: 				print_help();
274: 				exit(1);
275: 			}
276: 			logfile_name = string(splits[1]);
277: 		} else if (StringUtil::StartsWith(arg, "--static=")) {
278: 			auto splits = StringUtil::Split(arg, '=');
279: 			if (splits.size() != 2) {
280: 				print_help();
281: 				exit(1);
282: 			}
283: 			static_files = string(splits[1]);
284: 		} else if (StringUtil::StartsWith(arg, "--listen=")) {
285: 			auto splits = StringUtil::Split(arg, '=');
286: 			if (splits.size() != 2) {
287: 				print_help();
288: 				exit(1);
289: 			}
290: 			listen = string(splits[1]);
291: 		} else if (StringUtil::StartsWith(arg, "--port=")) {
292: 			auto splits = StringUtil::Split(arg, '=');
293: 			if (splits.size() != 2) {
294: 				print_help();
295: 				exit(1);
296: 			}
297: 			port = std::stoi(splits[1]);
298: 
299: 		} else if (StringUtil::StartsWith(arg, "--query_timeout=")) {
300: 			auto splits = StringUtil::Split(arg, '=');
301: 			if (splits.size() != 2) {
302: 				print_help();
303: 				exit(1);
304: 			}
305: 			query_timeout = std::stoi(splits[1]);
306: 
307: 		} else if (StringUtil::StartsWith(arg, "--fetch_timeout=")) {
308: 			auto splits = StringUtil::Split(arg, '=');
309: 			if (splits.size() != 2) {
310: 				print_help();
311: 				exit(1);
312: 			}
313: 			fetch_timeout = std::stoi(splits[1]);
314: 
315: 		} else {
316: 			fprintf(stderr, "Error: unknown argument %s\n", arg.c_str());
317: 			print_help();
318: 			exit(1);
319: 		}
320: 	}
321: 
322: 	unordered_map<string, RestClientState> client_state_map;
323: 	std::mutex client_state_map_mutex;
324: 	std::thread client_state_cleanup_thread(client_state_cleanup, &client_state_map, &client_state_map_mutex,
325: 	                                        fetch_timeout);
326: 
327: 	if (!logfile_name.empty()) {
328: 		logfile.open(logfile_name, std::ios_base::app);
329: 	}
330: 
331: 	config.maximum_memory = 10737418240;
332: 
333: 	DuckDB duckdb(dbfile.empty() ? nullptr : dbfile.c_str(), &config);
334: 	ExtensionHelper::LoadAllExtensions(duckdb);
335: 
336: 	svr.Get("/query", [&](const Request &req, Response &resp) {
337: 		auto q = req.get_param_value("q");
338: 		{
339: 			std::lock_guard<std::mutex> guard(out_mutex);
340: 			logfile << q << " ; -- DFgoEnx9UIRgHFsVYW8K" << std::endl
341: 			        << std::flush; // using a terminator that will **never** occur in queries
342: 		}
343: 
344: 		json j;
345: 
346: 		RestClientState state;
347: 		state.con = make_unique<duckdb::Connection>(duckdb);
348: 		state.con->EnableProfiling();
349: 		state.touched = std::time(nullptr);
350: 		bool is_active = true;
351: 
352: 		std::thread interrupt_thread(sleep_thread, state.con.get(), &is_active, query_timeout);
353: 		auto res = state.con->context->Query(q, true);
354: 
355: 		is_active = false;
356: 		interrupt_thread.join();
357: 
358: 		state.res = move(res);
359: 
360: 		if (state.res->success) {
361: 			j = {{"query", q},
362: 			     {"success", state.res->success},
363: 			     {"column_count", state.res->types.size()},
364: 
365: 			     {"statement_type", StatementTypeToString(state.res->statement_type)},
366: 			     {"names", json(state.res->names)},
367: 			     {"name_index_map", json::object()},
368: 			     {"types", json::array()},
369: 			     {"sql_types", json::array()},
370: 			     {"data", json::array()}};
371: 
372: 			for (auto &sql_type : state.res->types) {
373: 				j["sql_types"] += sql_type.ToString();
374: 			}
375: 			for (auto &type : state.res->types) {
376: 				j["types"] += TypeIdToString(type.InternalType());
377: 			}
378: 
379: 			// make it easier to get col data by name
380: 			size_t col_idx = 0;
381: 			for (auto &name : state.res->names) {
382: 				j["name_index_map"][name] = col_idx;
383: 				col_idx++;
384: 			}
385: 
386: 			// only do this if query was successful
387: 			string query_ref = random_string(10);
388: 			j["ref"] = query_ref;
389: 			auto chunk = state.res->Fetch();
390: 			if (chunk != nullptr) {
391: 				serialize_chunk(state.res.get(), chunk.get(), j);
392: 			}
393: 			{
394: 				std::lock_guard<std::mutex> guard(client_state_map_mutex);
395: 				client_state_map[query_ref] = move(state);
396: 			}
397: 
398: 		} else {
399: 			j = {{"query", q}, {"success", state.res->success}, {"error", state.res->error}};
400: 		}
401: 
402: 		serialize_json(req, resp, j);
403: 	});
404: 
405: 	svr.Get("/fetch", [&](const Request &req, Response &resp) {
406: 		auto ref = req.get_param_value("ref");
407: 		json j;
408: 		RestClientState state;
409: 		bool found_state = false;
410: 		{
411: 			std::lock_guard<std::mutex> guard(client_state_map_mutex);
412: 			auto it = client_state_map.find(ref);
413: 			if (it != client_state_map.end()) {
414: 				state = move(it->second);
415: 				client_state_map.erase(it);
416: 				found_state = true;
417: 			}
418: 		}
419: 
420: 		if (found_state) {
421: 			bool is_active = true;
422: 			std::thread interrupt_thread(sleep_thread, state.con.get(), &is_active, query_timeout);
423: 			auto chunk = state.res->Fetch();
424: 			is_active = false;
425: 			interrupt_thread.join();
426: 
427: 			j = {{"success", true}, {"ref", ref}, {"count", chunk->size()}, {"data", json::array()}};
428: 			serialize_chunk(state.res.get(), chunk.get(), j);
429: 			if (chunk->size() != 0) {
430: 				std::lock_guard<std::mutex> guard(client_state_map_mutex);
431: 				state.touched = std::time(nullptr);
432: 				client_state_map[ref] = move(state);
433: 			}
434: 		} else {
435: 			j = {{"success", false}, {"error", "Unable to find ref."}};
436: 		}
437: 
438: 		serialize_json(req, resp, j);
439: 	});
440: 
441: 	svr.Get("/close", [&](const Request &req, Response &resp) {
442: 		auto ref = req.get_param_value("ref");
443: 		duckdb::Connection conn(duckdb);
444: 		json j;
445: 		std::lock_guard<std::mutex> guard(client_state_map_mutex);
446: 		if (client_state_map.find(ref) != client_state_map.end()) {
447: 			client_state_map.erase(client_state_map.find(ref));
448: 			j = {{"success", true}, {"ref", ref}};
449: 		} else {
450: 			j = {{"success", false}, {"error", "Unable to find ref."}};
451: 		}
452: 
453: 		serialize_json(req, resp, j);
454: 	});
455: 
456: 	svr.Get("/", [&](const Request &req, Response &resp) {
457: 		resp.status = 302;
458: 
459: 		resp.set_header("Location", "/select.html");
460: 		resp.set_content("<a href='/select.html'>select.html</a>", "text/html");
461: 	});
462: 
463: 	if (!static_files.empty()) {
464: 		svr.set_base_dir(static_files.c_str());
465: 	}
466: 
467: 	std::cout << "🦆 serving " + dbfile + " on http://" + listen + ":" + std::to_string(port) + "\n";
468: 
469: 	svr.listen(listen.c_str(), port);
470: 	return 0;
471: }
[end of tools/rest/server.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: