{
  "repo": "duckdb/duckdb",
  "pull_number": 9848,
  "instance_id": "duckdb__duckdb-9848",
  "issue_numbers": [
    "9520"
  ],
  "base_commit": "9c91b3a329073ea1767b0aaff94b51da98dd03e2",
  "patch": "diff --git a/tools/pythonpkg/scripts/cache_data.json b/tools/pythonpkg/scripts/cache_data.json\nindex 8b377efa0c39..ca9c7a88c4ab 100644\n--- a/tools/pythonpkg/scripts/cache_data.json\n+++ b/tools/pythonpkg/scripts/cache_data.json\n@@ -48,9 +48,10 @@\n         \"name\": \"pandas\",\n         \"children\": [\n             \"pandas.DataFrame\",\n-            \"pandas._libs\",\n             \"pandas.isnull\",\n-            \"pandas.ArrowDtype\"\n+            \"pandas.ArrowDtype\",\n+            \"pandas.NaT\",\n+            \"pandas.NA\"\n         ],\n         \"required\": false\n     },\n@@ -60,27 +61,16 @@\n         \"name\": \"DataFrame\",\n         \"children\": []\n     },\n-    \"pandas._libs\": {\n+    \"pandas.NaT\": {\n         \"type\": \"attribute\",\n-        \"full_path\": \"pandas._libs\",\n-        \"name\": \"_libs\",\n-        \"children\": [\n-            \"pandas._libs.missing\"\n-        ],\n-        \"required\": false\n-    },\n-    \"pandas._libs.missing\": {\n-        \"type\": \"attribute\",\n-        \"full_path\": \"pandas._libs.missing\",\n-        \"name\": \"missing\",\n-        \"children\": [\n-            \"pandas._libs.missing.NAType\"\n-        ]\n+        \"full_path\": \"pandas.NaT\",\n+        \"name\": \"NaT\",\n+        \"children\": []\n     },\n-    \"pandas._libs.missing.NAType\": {\n+    \"pandas.NA\": {\n         \"type\": \"attribute\",\n-        \"full_path\": \"pandas._libs.missing.NAType\",\n-        \"name\": \"NAType\",\n+        \"full_path\": \"pandas.NA\",\n+        \"name\": \"NA\",\n         \"children\": []\n     },\n     \"pandas.isnull\": {\n@@ -433,7 +423,7 @@\n         \"children\": [\n             \"duckdb.filesystem.ModifiedMemoryFileSystem\"\n         ],\n-\t\t\"required\": false\n+        \"required\": false\n     },\n     \"duckdb.filesystem.ModifiedMemoryFileSystem\": {\n         \"type\": \"attribute\",\ndiff --git a/tools/pythonpkg/scripts/imports.py b/tools/pythonpkg/scripts/imports.py\nindex a09fbf7734ce..8d868cb94295 100644\n--- a/tools/pythonpkg/scripts/imports.py\n+++ b/tools/pythonpkg/scripts/imports.py\n@@ -9,7 +9,8 @@\n import pandas\n \n pandas.DataFrame\n-pandas._libs.missing.NAType\n+pandas.NaT\n+pandas.NA\n pandas.isnull\n pandas.ArrowDtype\n \ndiff --git a/tools/pythonpkg/src/include/duckdb_python/import_cache/modules/pandas_module.hpp b/tools/pythonpkg/src/include/duckdb_python/import_cache/modules/pandas_module.hpp\nindex 6ea660689128..30c36f691233 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/import_cache/modules/pandas_module.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/import_cache/modules/pandas_module.hpp\n@@ -13,35 +13,6 @@\n \n namespace duckdb {\n \n-struct PandasLibsMissingCacheItem : public PythonImportCacheItem {\n-\n-public:\n-\tPandasLibsMissingCacheItem(optional_ptr<PythonImportCacheItem> parent)\n-\t    : PythonImportCacheItem(\"missing\", parent), NAType(\"NAType\", this) {\n-\t}\n-\t~PandasLibsMissingCacheItem() override {\n-\t}\n-\n-\tPythonImportCacheItem NAType;\n-};\n-\n-struct PandasLibsCacheItem : public PythonImportCacheItem {\n-\n-public:\n-\tPandasLibsCacheItem(optional_ptr<PythonImportCacheItem> parent)\n-\t    : PythonImportCacheItem(\"_libs\", parent), missing(this) {\n-\t}\n-\t~PandasLibsCacheItem() override {\n-\t}\n-\n-\tPandasLibsMissingCacheItem missing;\n-\n-protected:\n-\tbool IsRequired() const override final {\n-\t\treturn false;\n-\t}\n-};\n-\n struct PandasCacheItem : public PythonImportCacheItem {\n \n public:\n@@ -49,16 +20,17 @@ struct PandasCacheItem : public PythonImportCacheItem {\n \n public:\n \tPandasCacheItem()\n-\t    : PythonImportCacheItem(\"pandas\"), DataFrame(\"DataFrame\", this), _libs(this), isnull(\"isnull\", this),\n-\t      ArrowDtype(\"ArrowDtype\", this) {\n+\t    : PythonImportCacheItem(\"pandas\"), DataFrame(\"DataFrame\", this), isnull(\"isnull\", this),\n+\t      ArrowDtype(\"ArrowDtype\", this), NaT(\"NaT\", this), NA(\"NA\", this) {\n \t}\n \t~PandasCacheItem() override {\n \t}\n \n \tPythonImportCacheItem DataFrame;\n-\tPandasLibsCacheItem _libs;\n \tPythonImportCacheItem isnull;\n \tPythonImportCacheItem ArrowDtype;\n+\tPythonImportCacheItem NaT;\n+\tPythonImportCacheItem NA;\n \n protected:\n \tbool IsRequired() const override final {\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/python_objects.hpp b/tools/pythonpkg/src/include/duckdb_python/python_objects.hpp\nindex cda87259789c..5ef4a4bb4cb7 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/python_objects.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/python_objects.hpp\n@@ -163,8 +163,6 @@ struct PyDateTime {\n \tdate_t ToDate();\n \tdtime_t ToDuckTime();\n \tValue ToDuckValue(const LogicalType &target_type);\n-\tbool IsPositiveInfinity() const;\n-\tbool IsNegativeInfinity() const;\n \n public:\n \tstatic int32_t GetYears(py::handle &obj);\n@@ -186,8 +184,6 @@ struct PyDate {\n \n public:\n \tValue ToDuckValue();\n-\tbool IsPositiveInfinity() const;\n-\tbool IsNegativeInfinity() const;\n };\n \n struct PyTimezone {\ndiff --git a/tools/pythonpkg/src/native/python_conversion.cpp b/tools/pythonpkg/src/native/python_conversion.cpp\nindex 9caa68451333..faa0692c9bc3 100644\n--- a/tools/pythonpkg/src/native/python_conversion.cpp\n+++ b/tools/pythonpkg/src/native/python_conversion.cpp\n@@ -363,7 +363,9 @@ PythonObjectType GetPythonObjectType(py::handle &ele) {\n \n \tif (ele.is_none()) {\n \t\treturn PythonObjectType::None;\n-\t} else if (py::isinstance(ele, import_cache.pandas._libs.missing.NAType())) {\n+\t} else if (ele.is(import_cache.pandas.NaT())) {\n+\t\treturn PythonObjectType::None;\n+\t} else if (ele.is(import_cache.pandas.NA())) {\n \t\treturn PythonObjectType::None;\n \t} else if (py::isinstance<py::bool_>(ele)) {\n \t\treturn PythonObjectType::Bool;\ndiff --git a/tools/pythonpkg/src/native/python_objects.cpp b/tools/pythonpkg/src/native/python_objects.cpp\nindex eda3dcc46c79..f7f7da466c32 100644\n--- a/tools/pythonpkg/src/native/python_objects.cpp\n+++ b/tools/pythonpkg/src/native/python_objects.cpp\n@@ -274,23 +274,7 @@ timestamp_t PyDateTime::ToTimestamp() {\n \treturn Timestamp::FromDatetime(date, time);\n }\n \n-bool PyDateTime::IsPositiveInfinity() const {\n-\treturn year == 9999 && month == 12 && day == 31 && hour == 23 && minute == 59 && second == 59 && micros == 999999;\n-}\n-\n-bool PyDateTime::IsNegativeInfinity() const {\n-\treturn year == 1 && month == 1 && day == 1 && hour == 0 && minute == 0 && second == 0 && micros == 0;\n-}\n-\n Value PyDateTime::ToDuckValue(const LogicalType &target_type) {\n-\tif (IsPositiveInfinity()) {\n-\t\t// FIXME: respect the target_type ?\n-\t\treturn Value::TIMESTAMP(timestamp_t::infinity());\n-\t}\n-\tif (IsNegativeInfinity()) {\n-\t\t// FIXME: respect the target_type ?\n-\t\treturn Value::TIMESTAMP(timestamp_t::ninfinity());\n-\t}\n \tauto timestamp = ToTimestamp();\n \tif (!py::none().is(tzone_obj)) {\n \t\tauto utc_offset = PyTimezone::GetUTCOffset(tzone_obj);\n@@ -363,21 +347,8 @@ PyDate::PyDate(py::handle &ele) {\n }\n \n Value PyDate::ToDuckValue() {\n-\tif (IsPositiveInfinity()) {\n-\t\treturn Value::DATE(date_t::infinity());\n-\t}\n-\tif (IsNegativeInfinity()) {\n-\t\treturn Value::DATE(date_t::ninfinity());\n-\t}\n-\treturn Value::DATE(year, month, day);\n-}\n-\n-bool PyDate::IsPositiveInfinity() const {\n-\treturn year == 9999 && month == 12 && day == 31;\n-}\n-\n-bool PyDate::IsNegativeInfinity() const {\n-\treturn year == 1 && month == 1 && day == 1;\n+\tauto value = Value::DATE(year, month, day);\n+\treturn value;\n }\n \n void PythonObject::Initialize() {\ndiff --git a/tools/pythonpkg/src/numpy/numpy_scan.cpp b/tools/pythonpkg/src/numpy/numpy_scan.cpp\nindex 281b7737730f..c5e822514538 100644\n--- a/tools/pythonpkg/src/numpy/numpy_scan.cpp\n+++ b/tools/pythonpkg/src/numpy/numpy_scan.cpp\n@@ -340,11 +340,18 @@ void NumpyScan::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset,\n \t\t\t\t\tout_mask.SetInvalid(row);\n \t\t\t\t\tcontinue;\n \t\t\t\t}\n-\t\t\t\tif (import_cache.pandas._libs.missing.NAType(false)) {\n-\t\t\t\t\t// If pandas is imported, check if the type is NAType\n-\t\t\t\t\tauto val_type = Py_TYPE(val);\n-\t\t\t\t\tauto na_type = reinterpret_cast<PyTypeObject *>(import_cache.pandas._libs.missing.NAType().ptr());\n-\t\t\t\t\tif (val_type == na_type) {\n+\t\t\t\tif (import_cache.pandas.NaT(false)) {\n+\t\t\t\t\t// If pandas is imported, check if this is pandas.NaT\n+\t\t\t\t\tpy::handle value(val);\n+\t\t\t\t\tif (value.is(import_cache.pandas.NaT())) {\n+\t\t\t\t\t\tout_mask.SetInvalid(row);\n+\t\t\t\t\t\tcontinue;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t\tif (import_cache.pandas.NA(false)) {\n+\t\t\t\t\t// If pandas is imported, check if this is pandas.NA\n+\t\t\t\t\tpy::handle value(val);\n+\t\t\t\t\tif (value.is(import_cache.pandas.NA())) {\n \t\t\t\t\t\tout_mask.SetInvalid(row);\n \t\t\t\t\t\tcontinue;\n \t\t\t\t\t}\n",
  "test_patch": "diff --git a/tools/pythonpkg/tests/fast/pandas/test_df_object_resolution.py b/tools/pythonpkg/tests/fast/pandas/test_df_object_resolution.py\nindex 79c8b1f7dacb..e6592b07f726 100644\n--- a/tools/pythonpkg/tests/fast/pandas/test_df_object_resolution.py\n+++ b/tools/pythonpkg/tests/fast/pandas/test_df_object_resolution.py\n@@ -548,42 +548,67 @@ def test_multiple_chunks(self, pandas):\n         assert len(res['dates'].__array__()) == 4\n \n     @pytest.mark.parametrize('pandas', [NumpyPandas(), ArrowPandas()])\n-    def test_multiple_chunks_aggregate(self, pandas):\n-        conn = duckdb.connect()\n-        conn.execute(\n-            \"create table dates as select '2022-09-14'::DATE + INTERVAL (i::INTEGER) DAY as i from range(0, 4096) tbl(i);\"\n+    def test_multiple_chunks_aggregate(self, pandas, duckdb_cursor):\n+        duckdb_cursor.execute(f\"SET GLOBAL pandas_analyze_sample=4096\")\n+        duckdb_cursor.execute(\n+            \"create table dates as select '2022-09-14'::DATE + INTERVAL (i::INTEGER) DAY as i from range(4096) tbl(i);\"\n         )\n-        res = duckdb.query(\"select * from dates\", connection=conn).df()\n+        rel = duckdb_cursor.query(\"select * from dates\")\n+        res = rel.df()\n         date_df = res.copy()\n-        # Convert the values to `datetime.date` values, and the dtype of the column to 'object'\n+\n+        # Convert the dataframe to datetime\n         date_df['i'] = pandas.to_datetime(res['i']).dt.date\n         assert str(date_df['i'].dtype) == 'object'\n-        expected_res = duckdb.query(\n-            'select avg(epoch(i)), min(epoch(i)), max(epoch(i)) from dates;', connection=conn\n-        ).fetchall()\n-        actual_res = duckdb.query_df(\n-            date_df, 'x', 'select avg(epoch(i)), min(epoch(i)), max(epoch(i)) from x'\n-        ).fetchall()\n+\n+        expected_res = [\n+            (\n+                1840017600.0,  # Saturday, April 22, 2028 12:00:00 PM (avg)\n+                1663113600.0,  # Wednesday, September 14, 2022 12:00:00 AM (min)\n+                2016921600.0,  # Wednesday, November 30, 2033 12:00:00 AM (max)\n+            )\n+        ]\n+\n+        rel = duckdb_cursor.query(\n+            \"\"\"\n+            select\n+                avg(epoch(i)),\n+                min(epoch(i)),\n+                max(epoch(i))\n+            from date_df\n+        \"\"\"\n+        )\n+        actual_res = rel.fetchall()\n         assert expected_res == actual_res\n \n-        conn.execute('drop table dates')\n-        # Now with nulls interleaved\n+        # Now interleave nulls into the dataframe\n+        duckdb_cursor.execute('drop table dates')\n         for i in range(0, len(res['i']), 2):\n             res['i'][i] = None\n+        duckdb_cursor.execute('create table dates as select * from res')\n \n-        date_view = conn.register(\"date_view\", res)\n-        date_view.execute('create table dates as select * from date_view')\n-        expected_res = duckdb.query(\n-            \"select avg(epoch(i)), min(epoch(i)), max(epoch(i)) from dates\", connection=conn\n-        ).fetchall()\n-\n+        expected_res = [\n+            (\n+                1840060800.0,  # Sunday, April 23, 2028 12:00:00 AM\n+                1663200000.0,  # Thursday, September 15, 2022 12:00:00 AM\n+                2016921600.0,  # Wednesday, November 30, 2033 12:00:00 AM\n+            )\n+        ]\n+        # Convert the dataframe to datetime\n         date_df = res.copy()\n-        # Convert the values to `datetime.date` values, and the dtype of the column to 'object'\n         date_df['i'] = pandas.to_datetime(res['i']).dt.date\n         assert str(date_df['i'].dtype) == 'object'\n-        actual_res = duckdb.query_df(\n-            date_df, 'x', 'select avg(epoch(i)), min(epoch(i)), max(epoch(i)) from x'\n+\n+        actual_res = duckdb_cursor.query(\n+            \"\"\"\n+            select\n+                avg(epoch(i)),\n+                min(epoch(i)),\n+                max(epoch(i))\n+            from date_df\n+        \"\"\"\n         ).fetchall()\n+\n         assert expected_res == actual_res\n \n     @pytest.mark.parametrize('pandas', [NumpyPandas(), ArrowPandas()])\ndiff --git a/tools/pythonpkg/tests/fast/pandas/test_pandas_na.py b/tools/pythonpkg/tests/fast/pandas/test_pandas_na.py\nindex f76fd98077dd..fb102f9bd1a0 100644\n--- a/tools/pythonpkg/tests/fast/pandas/test_pandas_na.py\n+++ b/tools/pythonpkg/tests/fast/pandas/test_pandas_na.py\n@@ -18,15 +18,13 @@ def test_pandas_na(self, duckdb_cursor):\n         # DataFrame containing a single pd.NA\n         df = pd.DataFrame(pd.Series([pd.NA]))\n \n-        conn = duckdb.connect()\n-\n-        res = conn.execute(\"select * from df\").fetchall()\n+        res = duckdb_cursor.execute(\"select * from df\").fetchall()\n         assert res[0][0] == None\n \n         # DataFrame containing multiple values, with a pd.NA mixed in\n         null_index = 3\n         df = pd.DataFrame(pd.Series([3, 1, 2, pd.NA, 8, 6]))\n-        res = conn.execute(\"select * from df\").fetchall()\n+        res = duckdb_cursor.execute(\"select * from df\").fetchall()\n         items = [x[0] for x in [y for y in res]]\n         assert_nullness(items, [null_index])\n \n@@ -62,13 +60,13 @@ def test_pandas_na(self, duckdb_cursor):\n         assert str(nan_df['a'].dtype) == 'float64'\n         assert str(na_df['a'].dtype) == 'object'  # pd.NA values turn the column into 'object'\n \n-        nan_result = conn.execute(\"select * from nan_df\").df()\n-        na_result = conn.execute(\"select * from na_df\").df()\n+        nan_result = duckdb_cursor.execute(\"select * from nan_df\").df()\n+        na_result = duckdb_cursor.execute(\"select * from na_df\").df()\n         pd.testing.assert_frame_equal(nan_result, na_result)\n \n         # Mixed with stringified pd.NA values\n         na_string_df = pd.DataFrame({'a': [str(pd.NA), str(pd.NA), pd.NA, str(pd.NA), pd.NA, pd.NA, pd.NA, str(pd.NA)]})\n         null_indices = [2, 4, 5, 6]\n-        res = conn.execute(\"select * from na_string_df\").fetchall()\n+        res = duckdb_cursor.execute(\"select * from na_string_df\").fetchall()\n         items = [x[0] for x in [y for y in res]]\n         assert_nullness(items, null_indices)\ndiff --git a/tools/pythonpkg/tests/fast/types/test_datetime_date.py b/tools/pythonpkg/tests/fast/types/test_datetime_date.py\nindex 83973be40224..9efb6bd1ee8f 100644\n--- a/tools/pythonpkg/tests/fast/types/test_datetime_date.py\n+++ b/tools/pythonpkg/tests/fast/types/test_datetime_date.py\n@@ -22,9 +22,9 @@ def test_date_infinity_roundtrip(self):\n         # positive infinity\n         con.execute(\"select $1, $1 = 'infinity'::DATE\", [datetime.date.max])\n         res = con.fetchall()\n-        assert res == [(datetime.date.max, True)]\n+        assert res == [(datetime.date.max, False)]\n \n         # negative infinity\n         con.execute(\"select $1, $1 = '-infinity'::DATE\", [datetime.date.min])\n         res = con.fetchall()\n-        assert res == [(datetime.date.min, True)]\n+        assert res == [(datetime.date.min, False)]\ndiff --git a/tools/pythonpkg/tests/fast/types/test_datetime_datetime.py b/tools/pythonpkg/tests/fast/types/test_datetime_datetime.py\nindex 45aff1fca0fe..cfd307cb9f73 100644\n--- a/tools/pythonpkg/tests/fast/types/test_datetime_datetime.py\n+++ b/tools/pythonpkg/tests/fast/types/test_datetime_datetime.py\n@@ -41,9 +41,9 @@ def test_timestamp_infinity_roundtrip(self):\n         # positive infinity\n         con.execute(\"select $1, $1 = 'infinity'::TIMESTAMP\", [datetime.datetime.max])\n         res = con.fetchall()\n-        assert res == [(datetime.datetime.max, True)]\n+        assert res == [(datetime.datetime.max, False)]\n \n         # negative infinity\n         con.execute(\"select $1, $1 = '-infinity'::TIMESTAMP\", [datetime.datetime.min])\n         res = con.fetchall()\n-        assert res == [(datetime.datetime.min, True)]\n+        assert res == [(datetime.datetime.min, False)]\n",
  "problem_statement": "Overflow when exporting far-future dates to Arrow (IFF registered with pandas)\n### What happens?\r\n\r\nIf I create a table with a Pandas DataFrame that contains a date value of `9999-12-31`, when those values are retrieved in an Arrow table the conversion isn't handled correctly.\r\n\r\nThis appears to be a relatively recent regression (doesn't happen in 0.8.1).  I also tested this dropping the Pandas version down to 1.5.1 and the issue is still there with DuckDB 0.9.1 (I thought it might be related to some of the dtype changes in Pandas 2, but apparently not)\r\n\r\nIf I first convert the DataFrame to a PyArrow table, then everything works fine.\r\n\r\n```python\r\n[ins] In [1]: import pandas as pd\r\n\r\n[ins] In [2]: from datetime import date\r\n\r\n[ins] In [3]: import duckdb\r\n\r\n[ins] In [4]: pd.__version__\r\nOut[4]: '2.1.0'\r\n\r\n[ins] In [5]: duckdb.__version__\r\nOut[5]: '0.9.1'\r\n\r\n[ins] In [6]: df = pd.DataFrame({\"val\": [date(9999, 12, 30), date(9999, 12, 31)]})\r\n\r\n[ins] In [7]: con = duckdb.connect()\r\n\r\n[ins] In [8]: con.execute(\"CREATE TABLE t as SELECT * FROM df\");\r\n\r\n[ins] In [9]: con.execute(\"SELECT * FROM t\").fetchall()\r\nOut[9]: [(datetime.date(9999, 12, 30),), (datetime.date(9999, 12, 31),)]\r\n\r\n[ins] In [10]: con.execute(\"SELECT * FROM t\").arrow()\r\nOut[10]:\r\npyarrow.Table\r\nval: date32[day]\r\n----\r\nval: [[9999-12-30,<value out of range: 2147483647>]]\r\n\r\n[ins] In [11]: import pyarrow as pa\r\n\r\n[ins] In [12]: pat = pa.Table.from_pandas(df)\r\n\r\n[ins] In [13]: pat\r\nOut[13]:\r\npyarrow.Table\r\nval: date32[day]\r\n----\r\nval: [[9999-12-30,9999-12-31]]\r\n\r\n[ins] In [14]: con.execute(\"CREATE TABLE t2 as SELECT * FROM pat\")\r\nOut[14]: <duckdb.duckdb.DuckDBPyConnection at 0x7fa934c79530>\r\n\r\n[ins] In [15]: con.execute(\"SELECT * FROM t2\").fetchall()\r\nOut[15]: [(datetime.date(9999, 12, 30),), (datetime.date(9999, 12, 31),)]\r\n\r\n[ins] In [16]: con.execute(\"SELECT * FROM t2\").arrow()\r\nOut[16]:\r\npyarrow.Table\r\nval: date32[day]\r\n----\r\nval: [[9999-12-30,9999-12-31]]\r\n\r\n```\r\n\r\n### To Reproduce\r\n\r\n```python\r\nimport pandas as pd\r\nfrom datetime import date\r\nimport duckdb\r\n\r\ndf = pd.DataFrame({\"val\": [date(9999, 12, 30), date(9999, 12, 31)]})\r\n\r\ncon = duckdb.connect()\r\n\r\ncon.execute(\"CREATE TABLE t as SELECT * FROM df\");\r\ncon.execute(\"SELECT * FROM t\").fetchall()  # works\r\ncon.execute(\"SELECT * FROM t\").arrow()  # doesn't work\r\n```\r\n\r\n\r\n### OS:\r\n\r\nUbuntu 22.04 x64\r\n\r\n### DuckDB Version:\r\n\r\n0.9.1 and dev\r\n\r\n### DuckDB Client:\r\n\r\nPython\r\n\r\n### Full Name:\r\n\r\nGil Forsyth\r\n\r\n### Affiliation:\r\n\r\nVoltron Data\r\n\r\n### Have you tried this on the latest `main` branch?\r\n\r\nI have tested with a main build\r\n\r\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\r\n\r\n- [X] Yes, I have\n",
  "hints_text": "Thanks for the report!\r\n\r\nWhen we scan the pandas data we convert to infinity if the value is too big, looks like we're not checking for this special case in the arrow appender code.\r\n\r\nI assume arrow can't represent infinity in a date array, so we should set it to NULL instead?\r\n\r\nWe do this by checking for the `max` and `min` values of `datetime.date`:\r\n```py\r\n>>> import datetime\r\n>>> datetime.date.max \r\ndatetime.date(9999, 12, 31)\r\n>>> datetime.date.min \r\ndatetime.date(1, 1, 1)\r\n```\r\n\r\nThis is done so we can roundtrip infinity\r\n```c++\r\n\t\tif (!duckdb::Date::IsFinite(date)) {\r\n\t\t\tif (date == date_t::infinity()) {\r\n\t\t\t\treturn py::reinterpret_borrow<py::object>(import_cache.datetime().date.max());\r\n\t\t\t}\r\n\t\t\treturn py::reinterpret_borrow<py::object>(import_cache.datetime().date.min());\r\n\t\t}\r\n```\nHey @Tishj , thanks for the explanation -- these are helpful boundaries to have documented. \n\nAs for the above error, shouldn't it allow for `9999-12-31` as that's the max date supported? Is there a `<` somewhere that should be a `<=`?",
  "created_at": "2023-11-29T13:46:40Z"
}