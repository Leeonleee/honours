{
  "repo": "duckdb/duckdb",
  "pull_number": 7658,
  "instance_id": "duckdb__duckdb-7658",
  "issue_numbers": [
    "7652",
    "7652"
  ],
  "base_commit": "a81a31a0af24a6ecbfd402c88cd1fb671f8cd3c8",
  "patch": "diff --git a/extension/parquet/column_reader.cpp b/extension/parquet/column_reader.cpp\nindex c0787cf3c005..5c81f7593dbe 100644\n--- a/extension/parquet/column_reader.cpp\n+++ b/extension/parquet/column_reader.cpp\n@@ -95,7 +95,11 @@ const uint64_t ParquetDecodeUtils::BITPACK_MASKS[] = {0,\n                                                       576460752303423487,\n                                                       1152921504606846975,\n                                                       2305843009213693951,\n-                                                      4611686018427387903};\n+                                                      4611686018427387903,\n+                                                      9223372036854775807,\n+                                                      18446744073709551615ULL};\n+\n+const uint64_t ParquetDecodeUtils::BITPACK_MASKS_SIZE = sizeof(ParquetDecodeUtils::BITPACK_MASKS) / sizeof(uint64_t);\n \n const uint8_t ParquetDecodeUtils::BITPACK_DLEN = 8;\n \ndiff --git a/extension/parquet/include/decode_utils.hpp b/extension/parquet/include/decode_utils.hpp\nindex 75a967327b4b..1fb6bbc2222a 100644\n--- a/extension/parquet/include/decode_utils.hpp\n+++ b/extension/parquet/include/decode_utils.hpp\n@@ -12,10 +12,16 @@ class ParquetDecodeUtils {\n \t}\n \n \tstatic const uint64_t BITPACK_MASKS[];\n+\tstatic const uint64_t BITPACK_MASKS_SIZE;\n \tstatic const uint8_t BITPACK_DLEN;\n \n \ttemplate <typename T>\n \tstatic uint32_t BitUnpack(ByteBuffer &buffer, uint8_t &bitpack_pos, T *dest, uint32_t count, uint8_t width) {\n+\t\tif (width >= ParquetDecodeUtils::BITPACK_MASKS_SIZE) {\n+\t\t\tthrow InvalidInputException(\"The width (%d) of the bitpacked data exceeds the supported max width (%d), \"\n+\t\t\t                            \"the file might be corrupted.\",\n+\t\t\t                            width, ParquetDecodeUtils::BITPACK_MASKS_SIZE);\n+\t\t}\n \t\tauto mask = BITPACK_MASKS[width];\n \n \t\tfor (uint32_t i = 0; i < count; i++) {\n",
  "test_patch": "diff --git a/tools/pythonpkg/tests/fast/arrow/test_7652.py b/tools/pythonpkg/tests/fast/arrow/test_7652.py\nnew file mode 100644\nindex 000000000000..dfcae55e99bf\n--- /dev/null\n+++ b/tools/pythonpkg/tests/fast/arrow/test_7652.py\n@@ -0,0 +1,44 @@\n+import duckdb\n+import os\n+import pytest\n+import tempfile\n+\n+pa = pytest.importorskip(\"pyarrow\")\n+pq = pytest.importorskip(\"pyarrow.parquet\")\n+\n+class Test7652(object):\n+    def test_7652(self):\n+        temp_file_name = tempfile.NamedTemporaryFile(suffix='.parquet').name\n+        # Generate a list of values that aren't uniform in changes.\n+        generated_list = [1, 0, 2]\n+\n+        print(\"Generated values:\", generated_list)\n+        print(f\"Min value: {min(generated_list)} max value: {max(generated_list)}\")\n+\n+        # Convert list of values to a PyArrow table with a single column.\n+        fake_table = pa.Table.from_arrays([pa.array(generated_list, pa.int64())], names=['n0'])\n+\n+        # Write that column with DELTA_BINARY_PACKED encoding\n+        with pq.ParquetWriter(temp_file_name,\n+            fake_table.schema,\n+            column_encoding={\"n0\": \"DELTA_BINARY_PACKED\"},\n+            use_dictionary=False) as writer:\n+            writer.write_table(fake_table)\n+\n+        # Check to make sure that PyArrow can read the file and retrieve the expected values.\n+        # Assert the values read from PyArrow are the same\n+        read_table = pq.read_table(temp_file_name, use_threads=False)\n+\n+        read_list = read_table[\"n0\"].to_pylist()\n+        assert min(read_list) == min(generated_list)\n+        assert max(read_list) == max(generated_list)\n+        assert read_list == generated_list\n+\n+        # Attempt to perform the same thing with duckdb.\n+        print(\"Retrieving from duckdb\")\n+        duckdb_result = list(map(lambda v: v[0], duckdb.query(f\"select * from '{temp_file_name}'\").fetchall()))\n+\n+        print(\"DuckDB result:\", duckdb_result)\n+        assert min(duckdb_result) == min(generated_list)\n+        assert max(duckdb_result) == max(generated_list)\n+        assert duckdb_result == generated_list\n",
  "problem_statement": "Parquet: DELTA_BINARY_PACKED encoded int64 column leads to global-buffer-overflow when decoding\n### What happens?\r\n\r\nWhen decoding a Parquet file that has a int64 column using DELTA_BINARY_PACKED parquet encoding the values are corrupted and there is a global-buffer-overflow assertion thrown.  When using a int32 column with DELTA_BINARY_PACKED the assertion isn't thrown.\r\n\r\nIf the int64 array is ordered the exception isn't thrown, but it the delta isn't static between elements the exception is thrown.\r\n\r\nHere is an python program that reproduces the failure:\r\n\r\n```python\r\n\r\nimport pyarrow as pa\r\nimport pyarrow.parquet as pq\r\nimport duckdb\r\nimport random\r\n\r\ntest_parquet_file = \"dbp.parquet\"\r\n\r\n# Generate a list of values that aren't uniform in changes.\r\ngenerated_list = [1, 0, 2]\r\n\r\nprint(\"Generated values:\", generated_list)\r\nprint(f\"Min value: {min(generated_list)} max value: {max(generated_list)}\")\r\n\r\n# Convert list of values to a PyArrow table with a single column.\r\nfake_table = pa.Table.from_arrays([pa.array(generated_list, pa.int64())], names=['n0'])\r\n\r\n# Write that column with DELTA_BINARY_PACKED encoding\r\nwith pq.ParquetWriter(test_parquet_file,\r\n    fake_table.schema,\r\n    column_encoding={\"n0\": \"DELTA_BINARY_PACKED\"},\r\n    use_dictionary=False) as writer:\r\n  writer.write_table(fake_table)\r\n\r\n# Check to make sure that PyArrow can read the file and retrieve the expected values.\r\n# Assert the values read from PyArrow are the same\r\nread_table = pq.read_table(test_parquet_file, use_threads=False)\r\n\r\nread_list = read_table[\"n0\"].to_pylist()\r\nassert min(read_list) == min(generated_list)\r\nassert max(read_list) == max(generated_list)\r\nassert read_list == generated_list\r\n\r\n# Attempt to perform the same thing with duckdb.\r\nprint(\"Retrieving from duckdb\")\r\nduckdb_result = list(map(lambda v: v[0], duckdb.query(f\"select * from '{test_parquet_file}'\").fetchall()))\r\n\r\nprint(\"DuckDB result:\", duckdb_result)\r\nassert min(duckdb_result) == min(generated_list)\r\nassert max(duckdb_result) == max(generated_list)\r\nassert duckdb_result == generated_list\r\n```\r\n\r\nHere is a crash against the current head DuckDB from git.\r\n\r\n```\r\nselect * from '/Users/rusty/Development/test-duckdb/dbp.parquet';\r\n=================================================================\r\n==29727==ERROR: AddressSanitizer: global-buffer-overflow on address 0x00010d95ac00 at pc 0x00010b0a6495 bp 0x700006a2f090 sp 0x700006a2f088\r\nREAD of size 8 at 0x00010d95ac00 thread T6\r\n    #0 0x10b0a6494 in unsigned int duckdb::ParquetDecodeUtils::BitUnpack<long long>(duckdb::ByteBuffer&, unsigned char&, long long*, unsigned int, unsigned char) decode_utils.hpp:19\r\n    #1 0x10b0587b4 in void duckdb::DbpDecoder::GetBatch<long long>(char*, unsigned int) parquet_dbp_decoder.hpp:80\r\n    #2 0x10b0536af in duckdb::ColumnReader::Read(unsigned long long, std::__1::bitset<2048ul>&, unsigned char*, unsigned char*, duckdb::Vector&) column_reader.cpp:517\r\n    #3 0x10af3b1bf in duckdb::ParquetReader::ScanInternal(duckdb::ParquetReaderScanState&, duckdb::DataChunk&) parquet_reader.cpp:986\r\n    #4 0x10af35d85 in duckdb::ParquetReader::Scan(duckdb::ParquetReaderScanState&, duckdb::DataChunk&) parquet_reader.cpp:816\r\n    #5 0x10aeb455c in duckdb::ParquetScanFunction::ParquetScanImplementation(duckdb::ClientContext&, duckdb::TableFunctionInput&, duckdb::DataChunk&) parquet-extension.cpp:440\r\n    #6 0x108b52e9b in duckdb::PhysicalTableScan::GetData(duckdb::ExecutionContext&, duckdb::DataChunk&, duckdb::OperatorSourceInput&) const physical_table_scan.cpp:83\r\n    #7 0x10974af1c in duckdb::PipelineExecutor::GetData(duckdb::DataChunk&, duckdb::OperatorSourceInput&) pipeline_executor.cpp:442\r\n    #8 0x109746313 in duckdb::PipelineExecutor::FetchFromSource(duckdb::DataChunk&) pipeline_executor.cpp:468\r\n    #9 0x1097457dd in duckdb::PipelineExecutor::Execute(unsigned long long) pipeline_executor.cpp:142\r\n    #10 0x109748480 in duckdb::PipelineExecutor::Execute() pipeline_executor.cpp:180\r\n    #11 0x109823cf3 in duckdb::PipelineTask::ExecuteTask(duckdb::TaskExecutionMode) pipeline.cpp:50\r\n    #12 0x10970c79b in duckdb::ExecutorTask::Execute(duckdb::TaskExecutionMode) executor_task.cpp:28\r\n    #13 0x10974f735 in duckdb::TaskScheduler::ExecuteForever(std::__1::atomic<bool>*) task_scheduler.cpp:135\r\n    #14 0x109752208 in duckdb::ThreadExecuteTasks(duckdb::TaskScheduler*, std::__1::atomic<bool>*) task_scheduler.cpp:220\r\n    #15 0x109860e97 in decltype(std::declval<void (*)(duckdb::TaskScheduler*, std::__1::atomic<bool>*)>()(std::declval<duckdb::TaskScheduler*>(), std::declval<std::__1::atomic<bool>*>())) std::__1::__invoke[abi:v15006]<void (*)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*, std::__1::atomic<bool>*>(void (*&&)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*&&, std::__1::atomic<bool>*&&) invoke.h:394\r\n    #16 0x109860d44 in void std::__1::__thread_execute[abi:v15006]<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void (*)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*, std::__1::atomic<bool>*, 2ul, 3ul>(std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void (*)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*, std::__1::atomic<bool>*>&, std::__1::__tuple_indices<2ul, 3ul>) thread:290\r\n    #17 0x10985fcb6 in void* std::__1::__thread_proxy[abi:v15006]<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void (*)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*, std::__1::atomic<bool>*>>(void*) thread:301\r\n    #18 0x7ff8006011d2 in _pthread_start+0x7c (libsystem_pthread.dylib:x86_64+0x61d2) (BuildId: 8cb0b396011f31f2891594cde1abae84240000001000000000040d0000040d00)\r\n    #19 0x7ff8005fcbd2 in thread_start+0xe (libsystem_pthread.dylib:x86_64+0x1bd2) (BuildId: 8cb0b396011f31f2891594cde1abae84240000001000000000040d0000040d00)\r\n\r\n0x00010d95ac00 is located 8 bytes to the right of global variable 'duckdb::ParquetDecodeUtils::BITPACK_MASKS' defined in '/Users/rusty/Development/duckdb/extension/parquet/column_reader.cpp:36:36' (0x10d95aa00) of size 504\r\nSUMMARY: AddressSanitizer: global-buffer-overflow decode_utils.hpp:19 in unsigned int duckdb::ParquetDecodeUtils::BitUnpack<long long>(duckdb::ByteBuffer&, unsigned char&, long long*, unsigned int, unsigned char)\r\nShadow bytes around the buggy address:\r\n  0x100021b2b530: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\r\n  0x100021b2b540: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\r\n  0x100021b2b550: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\r\n  0x100021b2b560: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\r\n  0x100021b2b570: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 f9\r\n=>0x100021b2b580:[f9]f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 01 f9 f9 f9\r\n  0x100021b2b590: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\r\n  0x100021b2b5a0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\r\n  0x100021b2b5b0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\r\n  0x100021b2b5c0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\r\n  0x100021b2b5d0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\r\nShadow byte legend (one shadow byte represents 8 application bytes):\r\n  Addressable:           00\r\n  Partially addressable: 01 02 03 04 05 06 07 \r\n  Heap left redzone:       fa\r\n  Freed heap region:       fd\r\n  Stack left redzone:      f1\r\n  Stack mid redzone:       f2\r\n  Stack right redzone:     f3\r\n  Stack after return:      f5\r\n  Stack use after scope:   f8\r\n  Global redzone:          f9\r\n  Global init order:       f6\r\n  Poisoned by user:        f7\r\n  Container overflow:      fc\r\n  Array cookie:            ac\r\n  Intra object redzone:    bb\r\n  ASan internal:           fe\r\n  Left alloca redzone:     ca\r\n  Right alloca redzone:    cb\r\nThread T6 created by T0 here:\r\n    #0 0x11aaa383c in wrap_pthread_create+0x5c (libclang_rt.asan_osx_dynamic.dylib:x86_64h+0x4283c) (BuildId: 756bb7515781379f84412f22c4274ffd2400000010000000000a0a0000030d00)\r\n    #1 0x1091a03d0 in std::__1::__libcpp_thread_create[abi:v15006](_opaque_pthread_t**, void* (*)(void*), void*) __threading_support:376\r\n    #2 0x10985f7fc in std::__1::thread::thread<void (&)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*, std::__1::atomic<bool>*, void>(void (&)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*&&, std::__1::atomic<bool>*&&) thread:317\r\n    #3 0x10985f4f0 in std::__1::thread::thread<void (&)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*, std::__1::atomic<bool>*, void>(void (&)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*&&, std::__1::atomic<bool>*&&) thread:309\r\n    #4 0x10975213c in duckdb::__unique_if<std::__1::thread, true>::__unique_single duckdb::make_uniq<std::__1::thread, void (&)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*, std::__1::atomic<bool>*>(void (&)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*&&, std::__1::atomic<bool>*&&) helper.hpp:63\r\n    #5 0x10974e899 in duckdb::TaskScheduler::SetThreadsInternal(int) task_scheduler.cpp:276\r\n    #6 0x1097519b7 in duckdb::TaskScheduler::SetThreads(int) task_scheduler.cpp:236\r\n    #7 0x1092c2af6 in duckdb::DatabaseInstance::Initialize(char const*, duckdb::DBConfig*) database.cpp:248\r\n    #8 0x1092c592d in duckdb::DuckDB::DuckDB(char const*, duckdb::DBConfig*) database.cpp:252\r\n    #9 0x1092c5ce8 in duckdb::DuckDB::DuckDB(char const*, duckdb::DBConfig*) database.cpp:251\r\n    #10 0x102f93f6c in duckdb::__unique_if<duckdb::DuckDB, true>::__unique_single duckdb::make_uniq<duckdb::DuckDB, char const*&, duckdb::DBConfig*>(char const*&, duckdb::DBConfig*&&) helper.hpp:63\r\n    #11 0x102f932a1 in duckdb_shell_sqlite3_open_v2 sqlite3_api_wrapper.cpp:118\r\n    #12 0x102e8f39c in open_db shell.c:14241\r\n    #13 0x102f3c46c in runOneSqlLine shell.c:19890\r\n    #14 0x102ec6794 in process_input shell.c:20015\r\n    #15 0x102e8ca61 in main shell.c:20828\r\n    #16 0x7ff8002a741e in start+0x76e (dyld:x86_64+0xfffffffffff6e41e) (BuildId: 9e98a840a3ac31c1ab97829af9bd686432000000200000000100000000040d00)\r\n\r\n==29727==ABORTING\r\n[1]    29727 abort      ./build/debug/duckdb\r\n```\r\n\r\n### To Reproduce\r\n\r\nSee the attached script\r\n\r\n### OS:\r\n\r\nMacOS X\r\n\r\n### DuckDB Version:\r\n\r\nv0.8.1-dev65 a81a31a0af\r\n\r\n### DuckDB Client:\r\n\r\nPython\r\n\r\n### Full Name:\r\n\r\nRusty Conover\r\n\r\n### Affiliation:\r\n\r\nn/a\r\n\r\n### Have you tried this on the latest `master` branch?\r\n\r\n- [X] I agree\r\n\r\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\r\n\r\n- [X] I agree\nParquet: DELTA_BINARY_PACKED encoded int64 column leads to global-buffer-overflow when decoding\n### What happens?\r\n\r\nWhen decoding a Parquet file that has a int64 column using DELTA_BINARY_PACKED parquet encoding the values are corrupted and there is a global-buffer-overflow assertion thrown.  When using a int32 column with DELTA_BINARY_PACKED the assertion isn't thrown.\r\n\r\nIf the int64 array is ordered the exception isn't thrown, but it the delta isn't static between elements the exception is thrown.\r\n\r\nHere is an python program that reproduces the failure:\r\n\r\n```python\r\n\r\nimport pyarrow as pa\r\nimport pyarrow.parquet as pq\r\nimport duckdb\r\nimport random\r\n\r\ntest_parquet_file = \"dbp.parquet\"\r\n\r\n# Generate a list of values that aren't uniform in changes.\r\ngenerated_list = [1, 0, 2]\r\n\r\nprint(\"Generated values:\", generated_list)\r\nprint(f\"Min value: {min(generated_list)} max value: {max(generated_list)}\")\r\n\r\n# Convert list of values to a PyArrow table with a single column.\r\nfake_table = pa.Table.from_arrays([pa.array(generated_list, pa.int64())], names=['n0'])\r\n\r\n# Write that column with DELTA_BINARY_PACKED encoding\r\nwith pq.ParquetWriter(test_parquet_file,\r\n    fake_table.schema,\r\n    column_encoding={\"n0\": \"DELTA_BINARY_PACKED\"},\r\n    use_dictionary=False) as writer:\r\n  writer.write_table(fake_table)\r\n\r\n# Check to make sure that PyArrow can read the file and retrieve the expected values.\r\n# Assert the values read from PyArrow are the same\r\nread_table = pq.read_table(test_parquet_file, use_threads=False)\r\n\r\nread_list = read_table[\"n0\"].to_pylist()\r\nassert min(read_list) == min(generated_list)\r\nassert max(read_list) == max(generated_list)\r\nassert read_list == generated_list\r\n\r\n# Attempt to perform the same thing with duckdb.\r\nprint(\"Retrieving from duckdb\")\r\nduckdb_result = list(map(lambda v: v[0], duckdb.query(f\"select * from '{test_parquet_file}'\").fetchall()))\r\n\r\nprint(\"DuckDB result:\", duckdb_result)\r\nassert min(duckdb_result) == min(generated_list)\r\nassert max(duckdb_result) == max(generated_list)\r\nassert duckdb_result == generated_list\r\n```\r\n\r\nHere is a crash against the current head DuckDB from git.\r\n\r\n```\r\nselect * from '/Users/rusty/Development/test-duckdb/dbp.parquet';\r\n=================================================================\r\n==29727==ERROR: AddressSanitizer: global-buffer-overflow on address 0x00010d95ac00 at pc 0x00010b0a6495 bp 0x700006a2f090 sp 0x700006a2f088\r\nREAD of size 8 at 0x00010d95ac00 thread T6\r\n    #0 0x10b0a6494 in unsigned int duckdb::ParquetDecodeUtils::BitUnpack<long long>(duckdb::ByteBuffer&, unsigned char&, long long*, unsigned int, unsigned char) decode_utils.hpp:19\r\n    #1 0x10b0587b4 in void duckdb::DbpDecoder::GetBatch<long long>(char*, unsigned int) parquet_dbp_decoder.hpp:80\r\n    #2 0x10b0536af in duckdb::ColumnReader::Read(unsigned long long, std::__1::bitset<2048ul>&, unsigned char*, unsigned char*, duckdb::Vector&) column_reader.cpp:517\r\n    #3 0x10af3b1bf in duckdb::ParquetReader::ScanInternal(duckdb::ParquetReaderScanState&, duckdb::DataChunk&) parquet_reader.cpp:986\r\n    #4 0x10af35d85 in duckdb::ParquetReader::Scan(duckdb::ParquetReaderScanState&, duckdb::DataChunk&) parquet_reader.cpp:816\r\n    #5 0x10aeb455c in duckdb::ParquetScanFunction::ParquetScanImplementation(duckdb::ClientContext&, duckdb::TableFunctionInput&, duckdb::DataChunk&) parquet-extension.cpp:440\r\n    #6 0x108b52e9b in duckdb::PhysicalTableScan::GetData(duckdb::ExecutionContext&, duckdb::DataChunk&, duckdb::OperatorSourceInput&) const physical_table_scan.cpp:83\r\n    #7 0x10974af1c in duckdb::PipelineExecutor::GetData(duckdb::DataChunk&, duckdb::OperatorSourceInput&) pipeline_executor.cpp:442\r\n    #8 0x109746313 in duckdb::PipelineExecutor::FetchFromSource(duckdb::DataChunk&) pipeline_executor.cpp:468\r\n    #9 0x1097457dd in duckdb::PipelineExecutor::Execute(unsigned long long) pipeline_executor.cpp:142\r\n    #10 0x109748480 in duckdb::PipelineExecutor::Execute() pipeline_executor.cpp:180\r\n    #11 0x109823cf3 in duckdb::PipelineTask::ExecuteTask(duckdb::TaskExecutionMode) pipeline.cpp:50\r\n    #12 0x10970c79b in duckdb::ExecutorTask::Execute(duckdb::TaskExecutionMode) executor_task.cpp:28\r\n    #13 0x10974f735 in duckdb::TaskScheduler::ExecuteForever(std::__1::atomic<bool>*) task_scheduler.cpp:135\r\n    #14 0x109752208 in duckdb::ThreadExecuteTasks(duckdb::TaskScheduler*, std::__1::atomic<bool>*) task_scheduler.cpp:220\r\n    #15 0x109860e97 in decltype(std::declval<void (*)(duckdb::TaskScheduler*, std::__1::atomic<bool>*)>()(std::declval<duckdb::TaskScheduler*>(), std::declval<std::__1::atomic<bool>*>())) std::__1::__invoke[abi:v15006]<void (*)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*, std::__1::atomic<bool>*>(void (*&&)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*&&, std::__1::atomic<bool>*&&) invoke.h:394\r\n    #16 0x109860d44 in void std::__1::__thread_execute[abi:v15006]<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void (*)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*, std::__1::atomic<bool>*, 2ul, 3ul>(std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void (*)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*, std::__1::atomic<bool>*>&, std::__1::__tuple_indices<2ul, 3ul>) thread:290\r\n    #17 0x10985fcb6 in void* std::__1::__thread_proxy[abi:v15006]<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void (*)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*, std::__1::atomic<bool>*>>(void*) thread:301\r\n    #18 0x7ff8006011d2 in _pthread_start+0x7c (libsystem_pthread.dylib:x86_64+0x61d2) (BuildId: 8cb0b396011f31f2891594cde1abae84240000001000000000040d0000040d00)\r\n    #19 0x7ff8005fcbd2 in thread_start+0xe (libsystem_pthread.dylib:x86_64+0x1bd2) (BuildId: 8cb0b396011f31f2891594cde1abae84240000001000000000040d0000040d00)\r\n\r\n0x00010d95ac00 is located 8 bytes to the right of global variable 'duckdb::ParquetDecodeUtils::BITPACK_MASKS' defined in '/Users/rusty/Development/duckdb/extension/parquet/column_reader.cpp:36:36' (0x10d95aa00) of size 504\r\nSUMMARY: AddressSanitizer: global-buffer-overflow decode_utils.hpp:19 in unsigned int duckdb::ParquetDecodeUtils::BitUnpack<long long>(duckdb::ByteBuffer&, unsigned char&, long long*, unsigned int, unsigned char)\r\nShadow bytes around the buggy address:\r\n  0x100021b2b530: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\r\n  0x100021b2b540: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\r\n  0x100021b2b550: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\r\n  0x100021b2b560: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\r\n  0x100021b2b570: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 f9\r\n=>0x100021b2b580:[f9]f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 01 f9 f9 f9\r\n  0x100021b2b590: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\r\n  0x100021b2b5a0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\r\n  0x100021b2b5b0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\r\n  0x100021b2b5c0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\r\n  0x100021b2b5d0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\r\nShadow byte legend (one shadow byte represents 8 application bytes):\r\n  Addressable:           00\r\n  Partially addressable: 01 02 03 04 05 06 07 \r\n  Heap left redzone:       fa\r\n  Freed heap region:       fd\r\n  Stack left redzone:      f1\r\n  Stack mid redzone:       f2\r\n  Stack right redzone:     f3\r\n  Stack after return:      f5\r\n  Stack use after scope:   f8\r\n  Global redzone:          f9\r\n  Global init order:       f6\r\n  Poisoned by user:        f7\r\n  Container overflow:      fc\r\n  Array cookie:            ac\r\n  Intra object redzone:    bb\r\n  ASan internal:           fe\r\n  Left alloca redzone:     ca\r\n  Right alloca redzone:    cb\r\nThread T6 created by T0 here:\r\n    #0 0x11aaa383c in wrap_pthread_create+0x5c (libclang_rt.asan_osx_dynamic.dylib:x86_64h+0x4283c) (BuildId: 756bb7515781379f84412f22c4274ffd2400000010000000000a0a0000030d00)\r\n    #1 0x1091a03d0 in std::__1::__libcpp_thread_create[abi:v15006](_opaque_pthread_t**, void* (*)(void*), void*) __threading_support:376\r\n    #2 0x10985f7fc in std::__1::thread::thread<void (&)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*, std::__1::atomic<bool>*, void>(void (&)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*&&, std::__1::atomic<bool>*&&) thread:317\r\n    #3 0x10985f4f0 in std::__1::thread::thread<void (&)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*, std::__1::atomic<bool>*, void>(void (&)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*&&, std::__1::atomic<bool>*&&) thread:309\r\n    #4 0x10975213c in duckdb::__unique_if<std::__1::thread, true>::__unique_single duckdb::make_uniq<std::__1::thread, void (&)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*, std::__1::atomic<bool>*>(void (&)(duckdb::TaskScheduler*, std::__1::atomic<bool>*), duckdb::TaskScheduler*&&, std::__1::atomic<bool>*&&) helper.hpp:63\r\n    #5 0x10974e899 in duckdb::TaskScheduler::SetThreadsInternal(int) task_scheduler.cpp:276\r\n    #6 0x1097519b7 in duckdb::TaskScheduler::SetThreads(int) task_scheduler.cpp:236\r\n    #7 0x1092c2af6 in duckdb::DatabaseInstance::Initialize(char const*, duckdb::DBConfig*) database.cpp:248\r\n    #8 0x1092c592d in duckdb::DuckDB::DuckDB(char const*, duckdb::DBConfig*) database.cpp:252\r\n    #9 0x1092c5ce8 in duckdb::DuckDB::DuckDB(char const*, duckdb::DBConfig*) database.cpp:251\r\n    #10 0x102f93f6c in duckdb::__unique_if<duckdb::DuckDB, true>::__unique_single duckdb::make_uniq<duckdb::DuckDB, char const*&, duckdb::DBConfig*>(char const*&, duckdb::DBConfig*&&) helper.hpp:63\r\n    #11 0x102f932a1 in duckdb_shell_sqlite3_open_v2 sqlite3_api_wrapper.cpp:118\r\n    #12 0x102e8f39c in open_db shell.c:14241\r\n    #13 0x102f3c46c in runOneSqlLine shell.c:19890\r\n    #14 0x102ec6794 in process_input shell.c:20015\r\n    #15 0x102e8ca61 in main shell.c:20828\r\n    #16 0x7ff8002a741e in start+0x76e (dyld:x86_64+0xfffffffffff6e41e) (BuildId: 9e98a840a3ac31c1ab97829af9bd686432000000200000000100000000040d00)\r\n\r\n==29727==ABORTING\r\n[1]    29727 abort      ./build/debug/duckdb\r\n```\r\n\r\n### To Reproduce\r\n\r\nSee the attached script\r\n\r\n### OS:\r\n\r\nMacOS X\r\n\r\n### DuckDB Version:\r\n\r\nv0.8.1-dev65 a81a31a0af\r\n\r\n### DuckDB Client:\r\n\r\nPython\r\n\r\n### Full Name:\r\n\r\nRusty Conover\r\n\r\n### Affiliation:\r\n\r\nn/a\r\n\r\n### Have you tried this on the latest `master` branch?\r\n\r\n- [X] I agree\r\n\r\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\r\n\r\n- [X] I agree\n",
  "hints_text": "```\r\n\u279c  duckdb git:(master) \u2717 python3 tmp/delta_binary_decode_bug.py \r\nGenerated values: [1, 0, 2]\r\nMin value: 0 max value: 2\r\nRetrieving from duckdb\r\nDuckDB result: [1, 7813537761367057516, 7813537761367057518]\r\nTraceback (most recent call last):\r\n  File \"/Users/thijs/DuckDBLabs/duckdb/tmp/delta_binary_decode_bug.py\", line 38, in <module>\r\n    assert min(duckdb_result) == min(generated_list)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nAssertionError\r\n```\nYep thats the failure, duckdb result doesn't match the generated list.\nHmm yea I see\r\n```c++\r\nauto mask = BITPACK_MASKS[width];\r\n```\r\nThis is causing the overflow, as width is `64` and we only have 63 entries inside the BITPACK_MASKS array.\n```\r\n\u279c  duckdb git:(master) \u2717 python3 tmp/delta_binary_decode_bug.py \r\nGenerated values: [1, 0, 2]\r\nMin value: 0 max value: 2\r\nRetrieving from duckdb\r\nDuckDB result: [1, 7813537761367057516, 7813537761367057518]\r\nTraceback (most recent call last):\r\n  File \"/Users/thijs/DuckDBLabs/duckdb/tmp/delta_binary_decode_bug.py\", line 38, in <module>\r\n    assert min(duckdb_result) == min(generated_list)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nAssertionError\r\n```\nYep thats the failure, duckdb result doesn't match the generated list.\nHmm yea I see\r\n```c++\r\nauto mask = BITPACK_MASKS[width];\r\n```\r\nThis is causing the overflow, as width is `64` and we only have 63 entries inside the BITPACK_MASKS array.",
  "created_at": "2023-05-24T06:42:55Z"
}