{
  "repo": "duckdb/duckdb",
  "pull_number": 7417,
  "instance_id": "duckdb__duckdb-7417",
  "issue_numbers": [
    "7356",
    "7356",
    "7504"
  ],
  "base_commit": "a1497beda4284bc9fadfa92f08586e44c5b1a07f",
  "patch": "diff --git a/.github/regression/micro.csv b/.github/regression/micro.csv\nindex 0c7ad9c66d56..a10f0a75233d 100644\n--- a/.github/regression/micro.csv\n+++ b/.github/regression/micro.csv\n@@ -1,5 +1,3 @@\n-Append100KIntegersINSERT\n-Append100KIntegersPREPARED\n benchmark/micro/cast/cast_date_string.benchmark\n benchmark/micro/cast/cast_int_string.benchmark\n benchmark/micro/cast/cast_double_string.benchmark\ndiff --git a/benchmark/micro/list/string_split.benchmark b/benchmark/micro/list/string_split.benchmark\nindex b7c4b6d01360..89a7d0bbfee6 100644\n--- a/benchmark/micro/list/string_split.benchmark\n+++ b/benchmark/micro/list/string_split.benchmark\n@@ -17,4 +17,4 @@ run\n SELECT SUM(LENGTH(str_split(l_comment, ' '))) FROM lineitem\n \n result I\n-27124176\n+27116609\ndiff --git a/benchmark/micro/list/string_split_regexp.benchmark b/benchmark/micro/list/string_split_regexp.benchmark\nindex 1504064a19ff..2cf5b1eb66df 100644\n--- a/benchmark/micro/list/string_split_regexp.benchmark\n+++ b/benchmark/micro/list/string_split_regexp.benchmark\n@@ -17,4 +17,4 @@ run\n SELECT SUM(LENGTH(str_split_regex(l_comment, '[z ]'))) FROM lineitem\n \n result I\n-27186473\n+27179168\ndiff --git a/src/function/table/table_scan.cpp b/src/function/table/table_scan.cpp\nindex 3bfbe5a17828..8b449ca3db5f 100644\n--- a/src/function/table/table_scan.cpp\n+++ b/src/function/table/table_scan.cpp\n@@ -207,7 +207,7 @@ struct IndexScanGlobalState : public GlobalTableFunctionState {\n \tVector row_ids;\n \tColumnFetchState fetch_state;\n \tTableScanState local_storage_state;\n-\tvector<column_t> column_ids;\n+\tvector<storage_t> column_ids;\n \tbool finished;\n };\n \n@@ -219,8 +219,12 @@ static unique_ptr<GlobalTableFunctionState> IndexScanInitGlobal(ClientContext &c\n \t}\n \tauto result = make_uniq<IndexScanGlobalState>(row_id_data);\n \tauto &local_storage = LocalStorage::Get(context, bind_data.table.catalog);\n-\tresult->column_ids = input.column_ids;\n-\tresult->local_storage_state.Initialize(input.column_ids, input.filters.get());\n+\n+\tresult->column_ids.reserve(input.column_ids.size());\n+\tfor (auto &id : input.column_ids) {\n+\t\tresult->column_ids.push_back(GetStorageIndex(bind_data.table, id));\n+\t}\n+\tresult->local_storage_state.Initialize(result->column_ids, input.filters.get());\n \tlocal_storage.InitializeScan(bind_data.table.GetStorage(), result->local_storage_state.local_state, input.filters);\n \n \tresult->finished = false;\ndiff --git a/src/include/duckdb/storage/table/row_group.hpp b/src/include/duckdb/storage/table/row_group.hpp\nindex ba0dbe0b8486..aadb9ca5389e 100644\n--- a/src/include/duckdb/storage/table/row_group.hpp\n+++ b/src/include/duckdb/storage/table/row_group.hpp\n@@ -149,7 +149,7 @@ class RowGroup : public SegmentBase<RowGroup> {\n \n private:\n \tChunkInfo *GetChunkInfo(idx_t vector_idx);\n-\tColumnData &GetColumn(idx_t c);\n+\tColumnData &GetColumn(storage_t c);\n \tidx_t GetColumnCount() const;\n \tvector<shared_ptr<ColumnData>> &GetColumns();\n \ndiff --git a/src/include/duckdb/storage/table/scan_state.hpp b/src/include/duckdb/storage/table/scan_state.hpp\nindex ca4350d7122b..00c5cf168797 100644\n--- a/src/include/duckdb/storage/table/scan_state.hpp\n+++ b/src/include/duckdb/storage/table/scan_state.hpp\n@@ -109,7 +109,7 @@ class CollectionScanState {\n \n public:\n \tvoid Initialize(const vector<LogicalType> &types);\n-\tconst vector<column_t> &GetColumnIds();\n+\tconst vector<storage_t> &GetColumnIds();\n \tTableFilterSet *GetFilters();\n \tAdaptiveFilter *GetAdaptiveFilter();\n \tbool Scan(DuckTransaction &transaction, DataChunk &result);\n@@ -130,15 +130,15 @@ class TableScanState {\n \tCollectionScanState local_state;\n \n public:\n-\tvoid Initialize(vector<column_t> column_ids, TableFilterSet *table_filters = nullptr);\n+\tvoid Initialize(vector<storage_t> column_ids, TableFilterSet *table_filters = nullptr);\n \n-\tconst vector<column_t> &GetColumnIds();\n+\tconst vector<storage_t> &GetColumnIds();\n \tTableFilterSet *GetFilters();\n \tAdaptiveFilter *GetAdaptiveFilter();\n \n private:\n \t//! The column identifiers of the scan\n-\tvector<column_t> column_ids;\n+\tvector<storage_t> column_ids;\n \t//! The table filters (if any)\n \tTableFilterSet *table_filters;\n \t//! Adaptive filter info (if any)\ndiff --git a/src/include/duckdb/transaction/local_storage.hpp b/src/include/duckdb/transaction/local_storage.hpp\nindex 56b9e53117cb..5d91ac566686 100644\n--- a/src/include/duckdb/transaction/local_storage.hpp\n+++ b/src/include/duckdb/transaction/local_storage.hpp\n@@ -108,7 +108,7 @@ class LocalStorage {\n \t//! Initialize a scan of the local storage\n \tvoid InitializeScan(DataTable &table, CollectionScanState &state, optional_ptr<TableFilterSet> table_filters);\n \t//! Scan\n-\tvoid Scan(CollectionScanState &state, const vector<column_t> &column_ids, DataChunk &result);\n+\tvoid Scan(CollectionScanState &state, const vector<storage_t> &column_ids, DataChunk &result);\n \n \tvoid InitializeParallelScan(DataTable &table, ParallelCollectionScanState &state);\n \tbool NextParallelScan(ClientContext &context, DataTable &table, ParallelCollectionScanState &state,\ndiff --git a/src/storage/local_storage.cpp b/src/storage/local_storage.cpp\nindex 969c143471e9..c8e1592d70fb 100644\n--- a/src/storage/local_storage.cpp\n+++ b/src/storage/local_storage.cpp\n@@ -310,7 +310,7 @@ void LocalStorage::InitializeScan(DataTable &table, CollectionScanState &state,\n \tstorage->InitializeScan(state, table_filters);\n }\n \n-void LocalStorage::Scan(CollectionScanState &state, const vector<column_t> &column_ids, DataChunk &result) {\n+void LocalStorage::Scan(CollectionScanState &state, const vector<storage_t> &column_ids, DataChunk &result) {\n \tstate.Scan(transaction, result);\n }\n \ndiff --git a/src/storage/table/row_group.cpp b/src/storage/table/row_group.cpp\nindex a1adb9b11bd4..306536ed8550 100644\n--- a/src/storage/table/row_group.cpp\n+++ b/src/storage/table/row_group.cpp\n@@ -81,7 +81,7 @@ idx_t RowGroup::GetColumnCount() const {\n \treturn columns.size();\n }\n \n-ColumnData &RowGroup::GetColumn(idx_t c) {\n+ColumnData &RowGroup::GetColumn(storage_t c) {\n \tD_ASSERT(c < columns.size());\n \tif (!is_loaded) {\n \t\t// not being lazy loaded\n@@ -179,7 +179,7 @@ bool RowGroup::InitializeScanWithOffset(CollectionScanState &state, idx_t vector\n \t    this->start > state.max_row ? 0 : MinValue<idx_t>(this->count, state.max_row - this->start);\n \tD_ASSERT(state.column_scans);\n \tfor (idx_t i = 0; i < column_ids.size(); i++) {\n-\t\tauto column = column_ids[i];\n+\t\tconst auto &column = column_ids[i];\n \t\tif (column != COLUMN_IDENTIFIER_ROW_ID) {\n \t\t\tauto &column_data = GetColumn(column);\n \t\t\tcolumn_data.InitializeScanWithOffset(state.column_scans[i], start + vector_offset * STANDARD_VECTOR_SIZE);\n@@ -334,9 +334,9 @@ void RowGroup::CommitDropColumn(idx_t column_idx) {\n \n void RowGroup::NextVector(CollectionScanState &state) {\n \tstate.vector_index++;\n-\tauto &column_ids = state.GetColumnIds();\n+\tconst auto &column_ids = state.GetColumnIds();\n \tfor (idx_t i = 0; i < column_ids.size(); i++) {\n-\t\tauto column = column_ids[i];\n+\t\tconst auto &column = column_ids[i];\n \t\tif (column == COLUMN_IDENTIFIER_ROW_ID) {\n \t\t\tcontinue;\n \t\t}\n@@ -345,11 +345,11 @@ void RowGroup::NextVector(CollectionScanState &state) {\n \t}\n }\n \n-bool RowGroup::CheckZonemap(TableFilterSet &filters, const vector<column_t> &column_ids) {\n+bool RowGroup::CheckZonemap(TableFilterSet &filters, const vector<storage_t> &column_ids) {\n \tfor (auto &entry : filters.filters) {\n \t\tauto column_index = entry.first;\n \t\tauto &filter = entry.second;\n-\t\tauto base_column_index = column_ids[column_index];\n+\t\tconst auto &base_column_index = column_ids[column_index];\n \t\tif (!GetColumn(base_column_index).CheckZonemap(*filter)) {\n \t\t\treturn false;\n \t\t}\n@@ -366,7 +366,7 @@ bool RowGroup::CheckZonemapSegments(CollectionScanState &state) {\n \tfor (auto &entry : filters->filters) {\n \t\tD_ASSERT(entry.first < column_ids.size());\n \t\tauto column_idx = entry.first;\n-\t\tauto base_column_idx = column_ids[column_idx];\n+\t\tconst auto &base_column_idx = column_ids[column_idx];\n \t\tbool read_segment = GetColumn(base_column_idx).CheckZonemap(state.column_scans[column_idx], *entry.second);\n \t\tif (!read_segment) {\n \t\t\tidx_t target_row =\n@@ -398,7 +398,7 @@ void RowGroup::TemplatedScan(TransactionData transaction, CollectionScanState &s\n \tconst bool ALLOW_UPDATES = TYPE != TableScanType::TABLE_SCAN_COMMITTED_ROWS_DISALLOW_UPDATES &&\n \t                           TYPE != TableScanType::TABLE_SCAN_COMMITTED_ROWS_OMIT_PERMANENTLY_DELETED;\n \tauto table_filters = state.GetFilters();\n-\tauto &column_ids = state.GetColumnIds();\n+\tconst auto &column_ids = state.GetColumnIds();\n \tauto adaptive_filter = state.GetAdaptiveFilter();\n \twhile (true) {\n \t\tif (state.vector_index * STANDARD_VECTOR_SIZE >= state.max_row_group_row) {\n@@ -436,7 +436,7 @@ void RowGroup::TemplatedScan(TransactionData transaction, CollectionScanState &s\n \t\tif (count == max_count && !table_filters) {\n \t\t\t// scan all vectors completely: full scan without deletions or table filters\n \t\t\tfor (idx_t i = 0; i < column_ids.size(); i++) {\n-\t\t\t\tauto column = column_ids[i];\n+\t\t\t\tconst auto &column = column_ids[i];\n \t\t\t\tif (column == COLUMN_IDENTIFIER_ROW_ID) {\n \t\t\t\t\t// scan row id\n \t\t\t\t\tD_ASSERT(result.data[i].GetType().InternalType() == ROW_TYPE);\ndiff --git a/src/storage/table/scan_state.cpp b/src/storage/table/scan_state.cpp\nindex e4ef305f5470..a40a9b1f30d0 100644\n--- a/src/storage/table/scan_state.cpp\n+++ b/src/storage/table/scan_state.cpp\n@@ -55,7 +55,7 @@ void ColumnScanState::Next(idx_t count) {\n \t}\n }\n \n-const vector<column_t> &CollectionScanState::GetColumnIds() {\n+const vector<storage_t> &CollectionScanState::GetColumnIds() {\n \treturn parent.GetColumnIds();\n }\n \n",
  "test_patch": "diff --git a/test/sql/function/list/list_concat.test b/test/sql/function/list/list_concat.test\nindex 680ec052c067..fa84873b110c 100644\n--- a/test/sql/function/list/list_concat.test\n+++ b/test/sql/function/list/list_concat.test\n@@ -144,7 +144,7 @@ SELECT list_append(NULL, 3)\n ----\n [3]\n \n-query II\n+query II rowsort\n SELECT i, list_append(list_concat(j, k), i) FROM lists\n ----\n 0\t[0, 4, 8, 12, 0, 4, 8, 12, 0]\ndiff --git a/test/sql/generated_columns/virtual/row_group_fetch.test b/test/sql/generated_columns/virtual/row_group_fetch.test\nnew file mode 100644\nindex 000000000000..79a1db9eaf26\n--- /dev/null\n+++ b/test/sql/generated_columns/virtual/row_group_fetch.test\n@@ -0,0 +1,22 @@\n+# name: test/sql/generated_columns/virtual/row_group_fetch.test\n+# group: [virtual]\n+\n+statement ok\n+pragma enable_verification;\n+\n+statement ok\n+CREATE TABLE t1 (\n+\ttr INTEGER,\n+\ttd INTEGER GENERATED ALWAYS AS (tr),\n+\ttz INTEGER\n+);\n+\n+statement ok\n+CREATE INDEX id ON t1(tr);\n+\n+statement ok\n+INSERT INTO t1(tr) VALUES (2);\n+\n+# Because of the generated column, the logical and physical index of 'tz' do not align.\n+statement ok\n+SELECT tz from t1 WHERE tr < 5;\n",
  "problem_statement": "DuckDB INTERNAL Error: Assertion triggered in file \"src/storage/table/row_group.cpp\" on line 86: c < columns.size()\n### What happens?\n\nThe DuckDB binary (`/usr/local/bin/duckdb`) throws `INTERNAL Error: Assertion triggered in file \"src/storage/table/row_group.cpp\" on line 86: c < columns.size()`.\n\n### To Reproduce\n\n```sql\r\nCREATE INDEX id ON t1(td);\r\nINSERT INTO t1(tr) VALUES (2);\r\nSELECT * FROM (SELECT *, ROW_NUMBER() OVER (ORDER BY td) AS row_num FROM t1 WHERE td < 5) AS temp WHERE row_num = 1;\r\n```\n\n### OS:\n\nUbuntu 20.04 64bit\n\n### DuckDB Version:\n\nv0.7.2-dev2867 aa20f17\n\n### DuckDB Client:\n\nBinary (/usr/local/bin/duckdb)\n\n### Full Name:\n\nJingzhou Fu\n\n### Affiliation:\n\nWingtecher Lab of Tsinghua University\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\nDuckDB INTERNAL Error: Assertion triggered in file \"src/storage/table/row_group.cpp\" on line 86: c < columns.size()\n### What happens?\n\nThe DuckDB binary (`/usr/local/bin/duckdb`) throws `INTERNAL Error: Assertion triggered in file \"src/storage/table/row_group.cpp\" on line 86: c < columns.size()`.\n\n### To Reproduce\n\n```sql\r\nCREATE INDEX id ON t1(td);\r\nINSERT INTO t1(tr) VALUES (2);\r\nSELECT * FROM (SELECT *, ROW_NUMBER() OVER (ORDER BY td) AS row_num FROM t1 WHERE td < 5) AS temp WHERE row_num = 1;\r\n```\n\n### OS:\n\nUbuntu 20.04 64bit\n\n### DuckDB Version:\n\nv0.7.2-dev2867 aa20f17\n\n### DuckDB Client:\n\nBinary (/usr/local/bin/duckdb)\n\n### Full Name:\n\nJingzhou Fu\n\n### Affiliation:\n\nWingtecher Lab of Tsinghua University\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\nString split benchmark wrong result\n### What happens?\n\nIn the latest commit, string split benchmark result is incorrect, including `benchmark/micro/list/string_split.benchmark`,  `benchmark/micro/list/string_split_regexp.benchmark`, `benchmark/micro/list/string_split_unicode.benchmark`\n\n### To Reproduce\n\n```\r\n./benchmark/benchmark_runner benchmark/micro/list/string_split.benchmark\r\nname    run     timing\r\nbenchmark/micro/list/string_split.benchmark     1       INCORRECT\r\nINCORRECT RESULT: Error in result on row 1 column 1: expected value \"27124176\" but got value \"27116609\"\r\nObtained result:\r\nsum(length(str_split(l_comment, ' ')))\r\nHUGEINT\r\n[ Rows: 1]\r\n27116609\r\n```\n\n### OS:\n\nubuntu 20.04\n\n### DuckDB Version:\n\nv0.7.2-dev3561\n\n### DuckDB Client:\n\nbinary\n\n### Full Name:\n\nKe Xu\n\n### Affiliation:\n\nSoutheast University\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\n",
  "hints_text": "how do you create t1?\nLike xuke-hat said, this is currently not reproducable, please provide the full steps\nSorry for the incomplete PoC. The full steps is:\r\n\r\n```sql\r\nCREATE TABLE t1 (tr INTEGER, td INTEGER GENERATED ALWAYS AS (tr), c1 VARCHAR(10), t VARCHAR(20), a VARCHAR(10) GENERATED ALWAYS AS (c1), tz INTEGER);\r\nCREATE INDEX id ON t1(td);\r\nINSERT INTO t1(tr) VALUES (2);\r\nSELECT * FROM (SELECT *, ROW_NUMBER() OVER (ORDER BY td) AS row_num FROM t1 WHERE td < 5) AS temp WHERE row_num = 1;\r\n```\nThe issue is that you shouldn't be able to create a index on `td` because it's a generated column.\r\nWe explicitly disallow this when it's done as part of table creation, it must have slipped through undetected for the `CREATE INDEX` variant.\r\n\r\nWhat happens here is that `td` binds to `tr`, so the Index has a LogicalGet on `tr`.\r\nI think the assertion triggers because `tr` is not part of the projection list.\r\n\r\nActually..\r\nThat's a different issue, even when we create the index on a different column it still breaks \ud83e\udd14 \r\n\r\n```sql\r\nstatement ok\r\nCREATE TABLE t1 (\r\n\ttr INTEGER,\r\n\ttd INTEGER GENERATED ALWAYS AS (tr),\r\n\tc1 VARCHAR,\r\n\tt VARCHAR,\r\n\ta VARCHAR,\r\n\ttz INTEGER\r\n);\r\n\r\nstatement ok\r\nCREATE INDEX id ON t1(tr);\r\n\r\nstatement ok\r\nINSERT INTO t1(tr) VALUES (2);\r\n\r\nstatement ok\r\nSELECT * FROM (\r\n\tSELECT *,\r\n\tROW_NUMBER() OVER (\r\n\t\tORDER BY tr\r\n\t) AS row_num FROM t1 WHERE tr < 5\r\n) AS temp\r\n\tWHERE row_num = 1;\r\n```\r\ntriggers the same assertion\r\n\r\nThe root cause is the difference between `SELECT tz` and `SELECT a`\r\nBecause of the generated column there is a mismatch between logical column index and physical column index, which is not handled properly here \ud83d\udc4d \r\nBecause of this we try to access the array of physical columns with the logical index, which overflows because we only have 4 physical columns but 5 logical ones\r\n\r\nMinimal reproduction:\r\n```sql\r\nstatement ok\r\nCREATE TABLE t1 (\r\n\ttr INTEGER,\r\n\ttd INTEGER GENERATED ALWAYS AS (tr),\r\n\ttz INTEGER\r\n);\r\n\r\nstatement ok\r\nCREATE INDEX id ON t1(tr);\r\n\r\nstatement ok\r\nINSERT INTO t1(tr) VALUES (2);\r\n\r\nstatement ok\r\nSELECT tz from t1 WHERE tr < 5;\r\n```\nhow do you create t1?\nLike xuke-hat said, this is currently not reproducable, please provide the full steps\nSorry for the incomplete PoC. The full steps is:\r\n\r\n```sql\r\nCREATE TABLE t1 (tr INTEGER, td INTEGER GENERATED ALWAYS AS (tr), c1 VARCHAR(10), t VARCHAR(20), a VARCHAR(10) GENERATED ALWAYS AS (c1), tz INTEGER);\r\nCREATE INDEX id ON t1(td);\r\nINSERT INTO t1(tr) VALUES (2);\r\nSELECT * FROM (SELECT *, ROW_NUMBER() OVER (ORDER BY td) AS row_num FROM t1 WHERE td < 5) AS temp WHERE row_num = 1;\r\n```\nThe issue is that you shouldn't be able to create a index on `td` because it's a generated column.\r\nWe explicitly disallow this when it's done as part of table creation, it must have slipped through undetected for the `CREATE INDEX` variant.\r\n\r\nWhat happens here is that `td` binds to `tr`, so the Index has a LogicalGet on `tr`.\r\nI think the assertion triggers because `tr` is not part of the projection list.\r\n\r\nActually..\r\nThat's a different issue, even when we create the index on a different column it still breaks \ud83e\udd14 \r\n\r\n```sql\r\nstatement ok\r\nCREATE TABLE t1 (\r\n\ttr INTEGER,\r\n\ttd INTEGER GENERATED ALWAYS AS (tr),\r\n\tc1 VARCHAR,\r\n\tt VARCHAR,\r\n\ta VARCHAR,\r\n\ttz INTEGER\r\n);\r\n\r\nstatement ok\r\nCREATE INDEX id ON t1(tr);\r\n\r\nstatement ok\r\nINSERT INTO t1(tr) VALUES (2);\r\n\r\nstatement ok\r\nSELECT * FROM (\r\n\tSELECT *,\r\n\tROW_NUMBER() OVER (\r\n\t\tORDER BY tr\r\n\t) AS row_num FROM t1 WHERE tr < 5\r\n) AS temp\r\n\tWHERE row_num = 1;\r\n```\r\ntriggers the same assertion\r\n\r\nThe root cause is the difference between `SELECT tz` and `SELECT a`\r\nBecause of the generated column there is a mismatch between logical column index and physical column index, which is not handled properly here \ud83d\udc4d \r\nBecause of this we try to access the array of physical columns with the logical index, which overflows because we only have 4 physical columns but 5 logical ones\r\n\r\nMinimal reproduction:\r\n```sql\r\nstatement ok\r\nCREATE TABLE t1 (\r\n\ttr INTEGER,\r\n\ttd INTEGER GENERATED ALWAYS AS (tr),\r\n\ttz INTEGER\r\n);\r\n\r\nstatement ok\r\nCREATE INDEX id ON t1(tr);\r\n\r\nstatement ok\r\nINSERT INTO t1(tr) VALUES (2);\r\n\r\nstatement ok\r\nSELECT tz from t1 WHERE tr < 5;\r\n```\n",
  "created_at": "2023-05-09T08:18:56Z"
}