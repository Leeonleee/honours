You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes.
In the patch file, please make sure to include the line numbers and a blank line at the end so it can be applied using git apply.

<issue>
Wrong number of results when calling a MACRO that calls a scalar function
### What happens?

```sql
create or replace function rnv(a,b) as (select a + b * pi());
select rnv(0, 1) from unnest( range(0,2) );
```
```
┌───────────────────┐
│     rnv(0, 1)     │
│      double       │
├───────────────────┤
│ 3.141592653589793 │
│ 3.141592653589793 │
│ 3.141592653589793 │
│ 3.141592653589793 │
│ 3.141592653589793 │
│ 3.141592653589793 │
│ 3.141592653589793 │
│ 3.141592653589793 │
└───────────────────┘
```

Note: this is similar to one of the problems reported at #13639, but here random() is not called at all.

### To Reproduce

```
create or replace function rnv(a,b) as (select a + b * pi());

select rnv(0, 1) from unnest( range(0,2) );
```

### OS:

macOS

### DuckDB Version:

v1.0.1-dev5058 (August 30)

### DuckDB Client:

CLI

### Full Name:

Peter Koppstein

### Affiliation:

Princeton University

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a source build

### Did you include all relevant data sets for reproducing the issue?

Not applicable - the reproduction does not require a data set

### Did you include all code required to reproduce the issue?

- [X] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [X] Yes, I have
Using random() in an uncorrelated subquery replicates the result
### What happens?

For the sake of clarity, first consider the case where a MACRO only invokes random() once. (*)
```
D create or replace function r() as random();

D select r() from unnest(range(0,4));
┌─────────────────────┐
│         r()         │
│       double        │
├─────────────────────┤
│ 0.38555585057474673 │
│  0.7014810184482485 │
│  0.6464361036196351 │
│ 0.05984393716789782 │
└─────────────────────┘
D
```
All as expected.

But now consider:
```
D create or replace function rnv(mean, sd) as 
  (select (( sqrt(-2 * ln(random())) * cos(2 * pi() * random())) * sd) + mean);

D select rnv(0,1) from unnest(range(0,4));
┌────────────────────┐
│     rnv(0, 1)      │
│       double       │
├────────────────────┤
│ 1.0384863850924373 │
│ 1.0384863850924373 │
│ 1.0384863850924373 │
│ 1.0384863850924373 │
│ 1.0384863850924373 │
│ 1.0384863850924373 │
│ 1.0384863850924373 │
│ 1.0384863850924373 │
│ 1.0384863850924373 │
│ 1.0384863850924373 │
│ 1.0384863850924373 │
│ 1.0384863850924373 │
│ 1.0384863850924373 │
│ 1.0384863850924373 │
│ 1.0384863850924373 │
│ 1.0384863850924373 │
├────────────────────┤
│      16 rows       │
└────────────────────┘
D
```

This is bizarre for two separate reasons:

(1) Why are all the values the same?

(2) Shouldn't there be just 4 rows as in the case of r()?

Note that calling rnv() in isolation produces results in accordance with expectations:
```
D select rnv(0,1);
┌──────────────────────┐
│      rnv(0, 1)       │
│        double        │
├──────────────────────┤
│ 0.006052431330421223 │
└──────────────────────┘

D select rnv(0,1);
┌────────────────────┐
│     rnv(0, 1)      │
│       double       │
├────────────────────┤
│ 0.7537127145896633 │
└────────────────────┘
D
```

p.s. Shouldn't it be possible to set the "has_side_effects" field in the table shown duckdb_functions() 
For reference:
```
D select has_side_effects is null from duckdb_functions() where function_name = 'r';
┌────────────────────────────┐
│ (has_side_effects IS NULL) │
│          boolean           │
├────────────────────────────┤
│ true                       │
└────────────────────────────┘
```
(*) All results shown are based on v1.0.1-dev4911 b41679dfd2

### To Reproduce

```
create or replace function rnv(mean, sd) as 
  (select (( sqrt(-2 * ln(random())) * cos(2 * pi() * random())) * sd) + mean);

select rnv(0,1) from unnest(range(0,4));
```

### OS:

MacOS

### DuckDB Version:

v1.0.1-dev4911 b41679dfd2

### DuckDB Client:

CLI

### Full Name:

Peter Koppstein

### Affiliation:

Princeton University

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a source build

### Did you include all relevant data sets for reproducing the issue?

Not applicable - the reproduction does not require a data set

### Did you include all code required to reproduce the issue?

- [X] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [X] Yes, I have

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <picture>
3:     <source media="(prefers-color-scheme: light)" srcset="logo/DuckDB_Logo-horizontal.svg">
4:     <source media="(prefers-color-scheme: dark)" srcset="logo/DuckDB_Logo-horizontal-dark-mode.svg">
5:     <img alt="DuckDB logo" src="logo/DuckDB_Logo-horizontal.svg" height="100">
6:   </picture>
7: </div>
8: <br>
9: 
10: <p align="center">
11:   <a href="https://github.com/duckdb/duckdb/actions"><img src="https://github.com/duckdb/duckdb/actions/workflows/Main.yml/badge.svg?branch=main" alt="Github Actions Badge"></a>
12:   <a href="https://discord.gg/tcvwpjfnZx"><img src="https://shields.io/discord/909674491309850675" alt="discord" /></a>
13:   <a href="https://github.com/duckdb/duckdb/releases/"><img src="https://img.shields.io/github/v/release/duckdb/duckdb?color=brightgreen&display_name=tag&logo=duckdb&logoColor=white" alt="Latest Release"></a>
14: </p>
15: 
16: ## DuckDB
17: 
18: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable, portable, and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs, maps), and [several extensions designed to make SQL easier to use](https://duckdb.org/docs/guides/sql_features/friendly_sql).
19: 
20: DuckDB is available as a [standalone CLI application](https://duckdb.org/docs/api/cli/overview) and has clients for [Python](https://duckdb.org/docs/api/python/overview), [R](https://duckdb.org/docs/api/r), [Java](https://duckdb.org/docs/api/java), [Wasm](https://duckdb.org/docs/api/wasm/overview), etc., with deep integrations with packages such as [pandas](https://duckdb.org/docs/guides/python/sql_on_pandas) and [dplyr](https://duckdblabs.github.io/duckplyr/).
21: 
22: For more information on using DuckDB, please refer to the [DuckDB documentation](https://duckdb.org/docs/).
23: 
24: ## Installation
25: 
26: If you want to install DuckDB, please see [our installation page](https://duckdb.org/docs/installation) for instructions.
27: 
28: ## Data Import
29: 
30: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
31: 
32: ```sql
33: SELECT * FROM 'myfile.csv';
34: SELECT * FROM 'myfile.parquet';
35: ```
36: 
37: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
38: 
39: ## SQL Reference
40: 
41: The documentation contains a [SQL introduction and reference](https://duckdb.org/docs/sql/introduction).
42: 
43: ## Development
44: 
45: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run `BUILD_BENCHMARK=1 BUILD_TPCH=1 make` and then perform several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`. The details of benchmarks are in our [Benchmark Guide](benchmark/README.md).
46: 
47: Please also refer to our [Build Guide](https://duckdb.org/dev/building) and [Contribution Guide](CONTRIBUTING.md).
48: 
49: ## Support
50: 
51: See the [Support Options](https://duckdblabs.com/support/) page.
[end of README.md]
[start of src/execution/operator/scan/physical_table_scan.cpp]
1: #include "duckdb/execution/operator/scan/physical_table_scan.hpp"
2: 
3: #include "duckdb/catalog/catalog_entry/table_catalog_entry.hpp"
4: #include "duckdb/common/string_util.hpp"
5: #include "duckdb/planner/expression/bound_conjunction_expression.hpp"
6: #include "duckdb/transaction/transaction.hpp"
7: 
8: #include <utility>
9: 
10: namespace duckdb {
11: 
12: PhysicalTableScan::PhysicalTableScan(vector<LogicalType> types, TableFunction function_p,
13:                                      unique_ptr<FunctionData> bind_data_p, vector<LogicalType> returned_types_p,
14:                                      vector<column_t> column_ids_p, vector<idx_t> projection_ids_p,
15:                                      vector<string> names_p, unique_ptr<TableFilterSet> table_filters_p,
16:                                      idx_t estimated_cardinality, ExtraOperatorInfo extra_info,
17:                                      vector<Value> parameters_p)
18:     : PhysicalOperator(PhysicalOperatorType::TABLE_SCAN, std::move(types), estimated_cardinality),
19:       function(std::move(function_p)), bind_data(std::move(bind_data_p)), returned_types(std::move(returned_types_p)),
20:       column_ids(std::move(column_ids_p)), projection_ids(std::move(projection_ids_p)), names(std::move(names_p)),
21:       table_filters(std::move(table_filters_p)), extra_info(extra_info), parameters(std::move(parameters_p)) {
22: }
23: 
24: class TableScanGlobalSourceState : public GlobalSourceState {
25: public:
26: 	TableScanGlobalSourceState(ClientContext &context, const PhysicalTableScan &op) {
27: 		if (op.dynamic_filters && op.dynamic_filters->HasFilters()) {
28: 			table_filters = op.dynamic_filters->GetFinalTableFilters(op, op.table_filters.get());
29: 		}
30: 		if (op.function.init_global) {
31: 			TableFunctionInitInput input(op.bind_data.get(), op.column_ids, op.projection_ids, GetTableFilters(op));
32: 			global_state = op.function.init_global(context, input);
33: 			if (global_state) {
34: 				max_threads = global_state->MaxThreads();
35: 			}
36: 		} else {
37: 			max_threads = 1;
38: 		}
39: 		if (op.function.in_out_function) {
40: 			// this is an in-out function, we need to setup the input chunk
41: 			vector<LogicalType> input_types;
42: 			for (auto &param : op.parameters) {
43: 				input_types.push_back(param.type());
44: 			}
45: 			input_chunk.Initialize(context, input_types);
46: 			for (idx_t c = 0; c < op.parameters.size(); c++) {
47: 				input_chunk.data[c].SetValue(0, op.parameters[c]);
48: 			}
49: 			input_chunk.SetCardinality(1);
50: 		}
51: 	}
52: 
53: 	idx_t max_threads = 0;
54: 	unique_ptr<GlobalTableFunctionState> global_state;
55: 	bool in_out_final = false;
56: 	DataChunk input_chunk;
57: 	//! Combined table filters, if we have dynamic filters
58: 	unique_ptr<TableFilterSet> table_filters;
59: 
60: 	optional_ptr<TableFilterSet> GetTableFilters(const PhysicalTableScan &op) const {
61: 		return table_filters ? table_filters.get() : op.table_filters.get();
62: 	}
63: 	idx_t MaxThreads() override {
64: 		return max_threads;
65: 	}
66: };
67: 
68: class TableScanLocalSourceState : public LocalSourceState {
69: public:
70: 	TableScanLocalSourceState(ExecutionContext &context, TableScanGlobalSourceState &gstate,
71: 	                          const PhysicalTableScan &op) {
72: 		if (op.function.init_local) {
73: 			TableFunctionInitInput input(op.bind_data.get(), op.column_ids, op.projection_ids,
74: 			                             gstate.GetTableFilters(op));
75: 			local_state = op.function.init_local(context, input, gstate.global_state.get());
76: 		}
77: 	}
78: 
79: 	unique_ptr<LocalTableFunctionState> local_state;
80: };
81: 
82: unique_ptr<LocalSourceState> PhysicalTableScan::GetLocalSourceState(ExecutionContext &context,
83:                                                                     GlobalSourceState &gstate) const {
84: 	return make_uniq<TableScanLocalSourceState>(context, gstate.Cast<TableScanGlobalSourceState>(), *this);
85: }
86: 
87: unique_ptr<GlobalSourceState> PhysicalTableScan::GetGlobalSourceState(ClientContext &context) const {
88: 	return make_uniq<TableScanGlobalSourceState>(context, *this);
89: }
90: 
91: SourceResultType PhysicalTableScan::GetData(ExecutionContext &context, DataChunk &chunk,
92:                                             OperatorSourceInput &input) const {
93: 	D_ASSERT(!column_ids.empty());
94: 	auto &gstate = input.global_state.Cast<TableScanGlobalSourceState>();
95: 	auto &state = input.local_state.Cast<TableScanLocalSourceState>();
96: 
97: 	TableFunctionInput data(bind_data.get(), state.local_state.get(), gstate.global_state.get());
98: 	if (function.function) {
99: 		function.function(context.client, data, chunk);
100: 	} else {
101: 		if (gstate.in_out_final) {
102: 			function.in_out_function_final(context, data, chunk);
103: 		}
104: 		function.in_out_function(context, data, gstate.input_chunk, chunk);
105: 		if (chunk.size() == 0 && function.in_out_function_final) {
106: 			function.in_out_function_final(context, data, chunk);
107: 			gstate.in_out_final = true;
108: 		}
109: 	}
110: 
111: 	return chunk.size() == 0 ? SourceResultType::FINISHED : SourceResultType::HAVE_MORE_OUTPUT;
112: }
113: 
114: double PhysicalTableScan::GetProgress(ClientContext &context, GlobalSourceState &gstate_p) const {
115: 	auto &gstate = gstate_p.Cast<TableScanGlobalSourceState>();
116: 	if (function.table_scan_progress) {
117: 		return function.table_scan_progress(context, bind_data.get(), gstate.global_state.get());
118: 	}
119: 	// if table_scan_progress is not implemented we don't support this function yet in the progress bar
120: 	return -1;
121: }
122: 
123: idx_t PhysicalTableScan::GetBatchIndex(ExecutionContext &context, DataChunk &chunk, GlobalSourceState &gstate_p,
124:                                        LocalSourceState &lstate) const {
125: 	D_ASSERT(SupportsBatchIndex());
126: 	D_ASSERT(function.get_batch_index);
127: 	auto &gstate = gstate_p.Cast<TableScanGlobalSourceState>();
128: 	auto &state = lstate.Cast<TableScanLocalSourceState>();
129: 	return function.get_batch_index(context.client, bind_data.get(), state.local_state.get(),
130: 	                                gstate.global_state.get());
131: }
132: 
133: string PhysicalTableScan::GetName() const {
134: 	return StringUtil::Upper(function.name + " " + function.extra_info);
135: }
136: 
137: InsertionOrderPreservingMap<string> PhysicalTableScan::ParamsToString() const {
138: 	InsertionOrderPreservingMap<string> result;
139: 	if (function.to_string) {
140: 		result["__text__"] = function.to_string(bind_data.get());
141: 	} else {
142: 		result["Function"] = StringUtil::Upper(function.name);
143: 	}
144: 	if (function.projection_pushdown) {
145: 		if (function.filter_prune) {
146: 			string projections;
147: 			for (idx_t i = 0; i < projection_ids.size(); i++) {
148: 				const auto &column_id = column_ids[projection_ids[i]];
149: 				if (column_id < names.size()) {
150: 					if (i > 0) {
151: 						projections += "\n";
152: 					}
153: 					projections += names[column_id];
154: 				}
155: 			}
156: 			result["Projections"] = projections;
157: 		} else {
158: 			string projections;
159: 			for (idx_t i = 0; i < column_ids.size(); i++) {
160: 				const auto &column_id = column_ids[i];
161: 				if (column_id < names.size()) {
162: 					if (i > 0) {
163: 						projections += "\n";
164: 					}
165: 					projections += names[column_id];
166: 				}
167: 			}
168: 			result["Projections"] = projections;
169: 		}
170: 	}
171: 	if (function.filter_pushdown && table_filters) {
172: 		string filters_info;
173: 		bool first_item = true;
174: 		for (auto &f : table_filters->filters) {
175: 			auto &column_index = f.first;
176: 			auto &filter = f.second;
177: 			if (column_index < names.size()) {
178: 				if (!first_item) {
179: 					filters_info += "\n";
180: 				}
181: 				first_item = false;
182: 				filters_info += filter->ToString(names[column_ids[column_index]]);
183: 			}
184: 		}
185: 		result["Filters"] = filters_info;
186: 	}
187: 	if (!extra_info.file_filters.empty()) {
188: 		result["File Filters"] = extra_info.file_filters;
189: 		if (extra_info.filtered_files.IsValid() && extra_info.total_files.IsValid()) {
190: 			result["Scanning Files"] = StringUtil::Format("%llu/%llu", extra_info.filtered_files.GetIndex(),
191: 			                                              extra_info.total_files.GetIndex());
192: 		}
193: 	}
194: 
195: 	SetEstimatedCardinality(result, estimated_cardinality);
196: 	return result;
197: }
198: 
199: bool PhysicalTableScan::Equals(const PhysicalOperator &other_p) const {
200: 	if (type != other_p.type) {
201: 		return false;
202: 	}
203: 	auto &other = other_p.Cast<PhysicalTableScan>();
204: 	if (function.function != other.function.function) {
205: 		return false;
206: 	}
207: 	if (column_ids != other.column_ids) {
208: 		return false;
209: 	}
210: 	if (!FunctionData::Equals(bind_data.get(), other.bind_data.get())) {
211: 		return false;
212: 	}
213: 	return true;
214: }
215: 
216: } // namespace duckdb
[end of src/execution/operator/scan/physical_table_scan.cpp]
[start of src/include/duckdb/execution/operator/scan/physical_table_scan.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/execution/operator/scan/physical_table_scan.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/execution/physical_operator.hpp"
12: #include "duckdb/function/table_function.hpp"
13: #include "duckdb/planner/table_filter.hpp"
14: #include "duckdb/storage/data_table.hpp"
15: #include "duckdb/common/extra_operator_info.hpp"
16: 
17: namespace duckdb {
18: 
19: //! Represents a scan of a base table
20: class PhysicalTableScan : public PhysicalOperator {
21: public:
22: 	static constexpr const PhysicalOperatorType TYPE = PhysicalOperatorType::TABLE_SCAN;
23: 
24: public:
25: 	//! Table scan that immediately projects out filter columns that are unused in the remainder of the query plan
26: 	PhysicalTableScan(vector<LogicalType> types, TableFunction function, unique_ptr<FunctionData> bind_data,
27: 	                  vector<LogicalType> returned_types, vector<column_t> column_ids, vector<idx_t> projection_ids,
28: 	                  vector<string> names, unique_ptr<TableFilterSet> table_filters, idx_t estimated_cardinality,
29: 	                  ExtraOperatorInfo extra_info, vector<Value> parameters);
30: 
31: 	//! The table function
32: 	TableFunction function;
33: 	//! Bind data of the function
34: 	unique_ptr<FunctionData> bind_data;
35: 	//! The types of ALL columns that can be returned by the table function
36: 	vector<LogicalType> returned_types;
37: 	//! The column ids used within the table function
38: 	vector<column_t> column_ids;
39: 	//! The projected-out column ids
40: 	vector<idx_t> projection_ids;
41: 	//! The names of the columns
42: 	vector<string> names;
43: 	//! The table filters
44: 	unique_ptr<TableFilterSet> table_filters;
45: 	//! Currently stores info related to filters pushed down into MultiFileLists
46: 	ExtraOperatorInfo extra_info;
47: 	//! Parameters
48: 	vector<Value> parameters;
49: 	//! Contains a reference to dynamically generated table filters (through e.g. a join up in the tree)
50: 	shared_ptr<DynamicTableFilterSet> dynamic_filters;
51: 
52: public:
53: 	string GetName() const override;
54: 	InsertionOrderPreservingMap<string> ParamsToString() const override;
55: 
56: 	bool Equals(const PhysicalOperator &other) const override;
57: 
58: public:
59: 	unique_ptr<LocalSourceState> GetLocalSourceState(ExecutionContext &context,
60: 	                                                 GlobalSourceState &gstate) const override;
61: 	unique_ptr<GlobalSourceState> GetGlobalSourceState(ClientContext &context) const override;
62: 	SourceResultType GetData(ExecutionContext &context, DataChunk &chunk, OperatorSourceInput &input) const override;
63: 	idx_t GetBatchIndex(ExecutionContext &context, DataChunk &chunk, GlobalSourceState &gstate,
64: 	                    LocalSourceState &lstate) const override;
65: 
66: 	bool IsSource() const override {
67: 		return true;
68: 	}
69: 	bool ParallelSource() const override {
70: 		return true;
71: 	}
72: 
73: 	bool SupportsBatchIndex() const override {
74: 		return function.get_batch_index != nullptr;
75: 	}
76: 
77: 	double GetProgress(ClientContext &context, GlobalSourceState &gstate) const override;
78: };
79: 
80: } // namespace duckdb
[end of src/include/duckdb/execution/operator/scan/physical_table_scan.hpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: