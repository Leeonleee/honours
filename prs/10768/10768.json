{
  "repo": "duckdb/duckdb",
  "pull_number": 10768,
  "instance_id": "duckdb__duckdb-10768",
  "issue_numbers": [
    "10693"
  ],
  "base_commit": "1a400858ba65554260e9cae6c52c500d27d01b00",
  "patch": "diff --git a/tools/pythonpkg/src/pandas/analyzer.cpp b/tools/pythonpkg/src/pandas/analyzer.cpp\nindex 6f5b4416cb18..df1ddb6be080 100644\n--- a/tools/pythonpkg/src/pandas/analyzer.cpp\n+++ b/tools/pythonpkg/src/pandas/analyzer.cpp\n@@ -4,6 +4,7 @@\n #include \"duckdb_python/pandas/pandas_analyzer.hpp\"\n #include \"duckdb_python/python_conversion.hpp\"\n #include \"duckdb/common/types/decimal.hpp\"\n+#include \"duckdb/common/helper.hpp\"\n \n namespace duckdb {\n \n@@ -396,7 +397,8 @@ LogicalType PandasAnalyzer::InnerAnalyze(py::object column, bool &can_convert, b\n \tLogicalType item_type = LogicalType::SQLNULL;\n \tvector<LogicalType> types;\n \tfor (idx_t i = 0; i < rows; i += increment) {\n-\t\tauto obj = FindFirstNonNull(row, i, increment);\n+\t\tauto range = MinValue(increment, rows - i);\n+\t\tauto obj = FindFirstNonNull(row, i, range);\n \t\tauto next_item_type = GetItemType(obj, can_convert);\n \t\ttypes.push_back(next_item_type);\n \n",
  "test_patch": "diff --git a/tools/pythonpkg/tests/fast/pandas/test_df_analyze.py b/tools/pythonpkg/tests/fast/pandas/test_df_analyze.py\nindex 19fb6ec182e3..578cb2fee720 100644\n--- a/tools/pythonpkg/tests/fast/pandas/test_df_analyze.py\n+++ b/tools/pythonpkg/tests/fast/pandas/test_df_analyze.py\n@@ -56,3 +56,14 @@ def test_sample_low_incorrect_undetected(self, duckdb_cursor, pandas):\n         # Sample size is too low to detect the mismatch, exception is raised when trying to convert\n         with pytest.raises(duckdb.InvalidInputException, match=\"Failed to cast value: Unimplemented type for cast\"):\n             roundtripped_df = duckdb.query_df(df, \"x\", \"select * from x\", connection=duckdb_conn).df()\n+\n+    @pytest.mark.parametrize('pandas', [NumpyPandas(), ArrowPandas()])\n+    def test_10750(self, duckdb_cursor, pandas):\n+        max_row_number = 2000\n+        data = {'id': [i for i in range(max_row_number + 1)], 'content': [None for _ in range(max_row_number + 1)]}\n+\n+        pdf = pandas.DataFrame(data=data)\n+        duckdb_cursor.register(\"content\", pdf)\n+        res = duckdb_cursor.query(\"select id from content\").fetchall()\n+        expected = [(i,) for i in range(2001)]\n+        assert res == expected\n",
  "problem_statement": "Queries to a long df that worked in pip duckdb==0.9.2 does not work in duckdb==0.10.0\n### What happens?\n\nI get the error `IndexError: index 2015628 is out of bounds for axis 0 with size 2015628` when running the same code that ran fine in pip duckdb==0.9.2. The code was a simple `select * from df where column is not null`. Tried to roll back and everything worked. Made a synthetic dataframe to test in new version, but still did not work. The synthetic example worked with few rows, but failed when i added as many rows as i had in my real scenario. \n\n### To Reproduce\n\n```python\r\nimport pandas as pd\r\nimport duckdb\r\n\r\n# Create a DataFrame with 5 rows\r\ndf = pd.DataFrame({'A': range(2015628),\r\n                   'B': range(2015628),\r\n                   'C': None})\r\n# Doing stuff to it in duckdb\r\nsql =  \"\"\"\r\n        select * from df\r\n        where A is not null\r\n        \"\"\"\r\nnew_df = duckdb.sql(sql).to_df()\r\nnew_df\r\n```\n\n### OS:\n\niOS M2\n\n### DuckDB Version:\n\n0.10.0\n\n### DuckDB Client:\n\nPython\n\n### Full Name:\n\nEirik Duesund Helland\n\n### Affiliation:\n\nNAV IKT\n\n### Have you tried this on the latest [nightly build](https://duckdb.org/docs/installation/?version=main)?\n\nI have tested with a nightly build\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] Yes, I have\n",
  "hints_text": "Had the same issue here\r\n```python\r\nselect * from df\r\n```\r\nThis also raises the same error.\r\n\r\nReplacing `None` with `np.nan` works\nEncountered the same issue when reading a parquet file (containing around 3m records) from s3 storage that worked previously on 0.9.2 using the python api on linux.\r\n",
  "created_at": "2024-02-20T13:55:41Z"
}