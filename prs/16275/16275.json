{
  "repo": "duckdb/duckdb",
  "pull_number": 16275,
  "instance_id": "duckdb__duckdb-16275",
  "issue_numbers": [
    "16257",
    "16257"
  ],
  "base_commit": "52811a9d197d8c4e98d291b4144a0d1724cefbda",
  "patch": "diff --git a/extension/parquet/column_writer.cpp b/extension/parquet/column_writer.cpp\nindex ba42a9b2f20a..8791bc596c08 100644\n--- a/extension/parquet/column_writer.cpp\n+++ b/extension/parquet/column_writer.cpp\n@@ -388,7 +388,7 @@ class BasicColumnWriter : public ColumnWriter {\n \tvirtual unique_ptr<ColumnWriterStatistics> InitializeStatsState();\n \n \t//! Initialize the writer for a specific page. Only used for scalar types.\n-\tvirtual unique_ptr<ColumnWriterPageState> InitializePageState(BasicColumnWriterState &state);\n+\tvirtual unique_ptr<ColumnWriterPageState> InitializePageState(BasicColumnWriterState &state, idx_t page_idx);\n \n \t//! Flushes the writer for a specific page. Only used for scalar types.\n \tvirtual void FlushPageState(WriteStream &temp_writer, ColumnWriterPageState *state);\n@@ -427,7 +427,8 @@ void BasicColumnWriter::RegisterToRowGroup(duckdb_parquet::RowGroup &row_group)\n \trow_group.columns.push_back(std::move(column_chunk));\n }\n \n-unique_ptr<ColumnWriterPageState> BasicColumnWriter::InitializePageState(BasicColumnWriterState &state) {\n+unique_ptr<ColumnWriterPageState> BasicColumnWriter::InitializePageState(BasicColumnWriterState &state,\n+                                                                         idx_t page_idx) {\n \treturn nullptr;\n }\n \n@@ -502,7 +503,7 @@ void BasicColumnWriter::BeginWrite(ColumnWriterState &state_p) {\n \t\t    MaxValue<idx_t>(NextPowerOfTwo(page_info.estimated_page_size), MemoryStream::DEFAULT_INITIAL_CAPACITY));\n \t\twrite_info.write_count = page_info.empty_count;\n \t\twrite_info.max_write_count = page_info.row_count;\n-\t\twrite_info.page_state = InitializePageState(state);\n+\t\twrite_info.page_state = InitializePageState(state, page_idx);\n \n \t\twrite_info.compressed_size = 0;\n \t\twrite_info.compressed_data = nullptr;\n@@ -1232,11 +1233,11 @@ class StandardColumnWriter : public BasicColumnWriter {\n \t\treturn std::move(result);\n \t}\n \n-\tunique_ptr<ColumnWriterPageState> InitializePageState(BasicColumnWriterState &state_p) override {\n+\tunique_ptr<ColumnWriterPageState> InitializePageState(BasicColumnWriterState &state_p, idx_t page_idx) override {\n \t\tauto &state = state_p.Cast<StandardColumnWriterState<SRC>>();\n-\n-\t\tauto result = make_uniq<StandardWriterPageState<SRC, TGT>>(state.total_value_count, state.total_string_size,\n-\t\t                                                           state.encoding, state.dictionary);\n+\t\tconst auto &page_info = state_p.page_info[page_idx];\n+\t\tauto result = make_uniq<StandardWriterPageState<SRC, TGT>>(\n+\t\t    page_info.row_count - page_info.empty_count, state.total_string_size, state.encoding, state.dictionary);\n \t\treturn std::move(result);\n \t}\n \n@@ -1586,7 +1587,7 @@ class BooleanColumnWriter : public BasicColumnWriter {\n \t\t}\n \t}\n \n-\tunique_ptr<ColumnWriterPageState> InitializePageState(BasicColumnWriterState &state) override {\n+\tunique_ptr<ColumnWriterPageState> InitializePageState(BasicColumnWriterState &state, idx_t page_idx) override {\n \t\treturn make_uniq<BooleanWriterPageState>();\n \t}\n \n@@ -1828,7 +1829,7 @@ class EnumColumnWriter : public BasicColumnWriter {\n \t\t}\n \t}\n \n-\tunique_ptr<ColumnWriterPageState> InitializePageState(BasicColumnWriterState &state) override {\n+\tunique_ptr<ColumnWriterPageState> InitializePageState(BasicColumnWriterState &state, idx_t page_idx) override {\n \t\treturn make_uniq<EnumWriterPageState>(bit_width);\n \t}\n \ndiff --git a/extension/parquet/include/parquet_bss_encoder.hpp b/extension/parquet/include/parquet_bss_encoder.hpp\nindex 80da1726de92..65561eb2573a 100644\n--- a/extension/parquet/include/parquet_bss_encoder.hpp\n+++ b/extension/parquet/include/parquet_bss_encoder.hpp\n@@ -30,7 +30,6 @@ class BssEncoder {\n \t}\n \n \tvoid FinishWrite(WriteStream &writer) {\n-\t\tD_ASSERT(count == total_value_count);\n \t\twriter.WriteData(buffer.get(), total_value_count * bit_width);\n \t}\n \ndiff --git a/extension/parquet/include/parquet_dlba_encoder.hpp b/extension/parquet/include/parquet_dlba_encoder.hpp\nindex b3cd1aa96076..89702fc12e41 100644\n--- a/extension/parquet/include/parquet_dlba_encoder.hpp\n+++ b/extension/parquet/include/parquet_dlba_encoder.hpp\n@@ -33,9 +33,8 @@ class DlbaEncoder {\n \t}\n \n \tvoid FinishWrite(WriteStream &writer) {\n-\t\tD_ASSERT(stream->GetPosition() == total_string_size);\n \t\tdbp_encoder.FinishWrite(writer);\n-\t\twriter.WriteData(buffer.get(), total_string_size);\n+\t\twriter.WriteData(buffer.get(), stream->GetPosition());\n \t}\n \n private:\n",
  "test_patch": "diff --git a/test/issues/general/test_16257.test_slow b/test/issues/general/test_16257.test_slow\nnew file mode 100644\nindex 000000000000..6b3faf9a7ba4\n--- /dev/null\n+++ b/test/issues/general/test_16257.test_slow\n@@ -0,0 +1,25 @@\n+# name: test/issues/general/test_16257.test_slow\n+# description: Issue 16257 - value count mismatch when writing DELTA_BINARY_PACKED\n+# group: [general]\n+\n+require parquet\n+\n+# Some macros to generate lorem ipsum\n+statement ok\n+CREATE OR REPLACE MACRO deterministic_random(rand) AS hash(rand) / 18446744073709551615;\n+\n+statement ok\n+CREATE OR REPLACE MACRO lorem_word(rand) AS ['voluptatem', 'quaerat', 'quiquia', 'non', 'dolore', 'dolorem', 'labore', 'consectetur', 'porro', 'sed', 'numquam', 'aliquam', 'sit', 'eius', 'modi', 'est', 'amet', 'magnam', 'dolor', 'etincidunt', 'velit', 'neque', 'ipsum', 'adipisci', 'quisquam', 'ut', 'tempora'][1 + floor(rand * 27 % 27)::BIGINT];\n+\n+statement ok\n+CREATE OR REPLACE MACRO lorem_sentence_util(s) AS upper(s[1]) || s[2:] || '.';\n+\n+statement ok\n+CREATE OR REPLACE MACRO lorem_sentence(rand, words) AS lorem_sentence_util(list_aggr([lorem_word(deterministic_random(rand + i)) for i in range(words)], 'string_agg', ' '));\n+\n+\n+statement ok\n+SET preserve_insertion_order=false;\n+\n+statement ok\n+COPY (SELECT lorem_sentence(random(), 20) FROM range(1_000_000)) TO '__TEST_DIR__/16257.parquet' (PARQUET_VERSION V2, ROW_GROUP_SIZE 2_000_000);\n",
  "problem_statement": "InternalException: INTERNAL Error: value count mismatch when writing DELTA_BINARY_PACKED\n### What happens?\n\nwriting parquet file crash duckdb, notice, it works fine for sf =1 , but crash with 5 and above\n\n### To Reproduce\n\n```python\nimport duckdb\ncon=duckdb.connect()\ncon.sql(f\"\"\" ATTACH './db.duckdb' AS db (STORAGE_VERSION 'v1.2.0') \"\"\")\ncon.sql(f\" use db\")\ncon.sql(f\"CALL dbgen(sf=5)\")\ncon.sql(f\"\"\" COPY (SELECT * FROM partsupp) TO './partsupp' (FORMAT PARQUET,PARQUET_VERSION V2,PER_THREAD_OUTPUT TRUE,ROW_GROUP_SIZE 2_000_000 , APPEND) \"\"\")\ncon.close()\n```\n\n### OS:\n\nlinux\n\n### DuckDB Version:\n\nduckdb-1.2.1.dev321\n\n### DuckDB Client:\n\npython\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nmim\n\n### Affiliation:\n\npersonal\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a nightly build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\nInternalException: INTERNAL Error: value count mismatch when writing DELTA_BINARY_PACKED\n### What happens?\n\nwriting parquet file crash duckdb, notice, it works fine for sf =1 , but crash with 5 and above\n\n### To Reproduce\n\n```python\nimport duckdb\ncon=duckdb.connect()\ncon.sql(f\"\"\" ATTACH './db.duckdb' AS db (STORAGE_VERSION 'v1.2.0') \"\"\")\ncon.sql(f\" use db\")\ncon.sql(f\"CALL dbgen(sf=5)\")\ncon.sql(f\"\"\" COPY (SELECT * FROM partsupp) TO './partsupp' (FORMAT PARQUET,PARQUET_VERSION V2,PER_THREAD_OUTPUT TRUE,ROW_GROUP_SIZE 2_000_000 , APPEND) \"\"\")\ncon.close()\n```\n\n### OS:\n\nlinux\n\n### DuckDB Version:\n\nduckdb-1.2.1.dev321\n\n### DuckDB Client:\n\npython\n\n### Hardware:\n\n_No response_\n\n### Full Name:\n\nmim\n\n### Affiliation:\n\npersonal\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a nightly build\n\n### Did you include all relevant data sets for reproducing the issue?\n\nYes\n\n### Did you include all code required to reproduce the issue?\n\n- [x] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [x] Yes, I have\n",
  "hints_text": "i had the same issue this week. After reducing the ROW_GROUP_SIZE the issue resolved.\nanother reproduction just with a sequence:\n```SQL\nCOPY (SELECT * from range(100_000_000)) TO 'partsupp.parquet' (FORMAT PARQUET,PARQUET_VERSION V2,ROW_GROUP_SIZE 20_000_000 , overwrite);\n```\ni had the same issue this week. After reducing the ROW_GROUP_SIZE the issue resolved.\nanother reproduction just with a sequence:\n```SQL\nCOPY (SELECT * from range(100_000_000)) TO 'partsupp.parquet' (FORMAT PARQUET,PARQUET_VERSION V2,ROW_GROUP_SIZE 20_000_000 , overwrite);\n```",
  "created_at": "2025-02-17T15:18:55Z"
}