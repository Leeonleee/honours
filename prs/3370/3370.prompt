You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
Undefined behavior : -nan outside the range at pipeline.cpp:87:23 (maybe not a bug)
#### What happens?
```
/root/duckdb/src/parallel/pipeline.cpp:87:23: runtime error: -nan is outside the range of representable values of type 'unsigned long'
SUMMARY: UndefinedBehaviorSanitizer: undefined-behavior /root/duckdb/src/parallel/pipeline.cpp:87:23 in
```

#### To Reproduce
```sql
SET enable_progress_bar=true;
WITH RECURSIVE t AS
(
	SELECT 1 AS x
UNION
	SELECT t1.x + t2.x + t3.x AS x
	FROM t t1, t t2, t t3
	WHERE t1.x < 100
)
SELECT * FROM t ORDER BY 1;
```

#### Environment (please complete the following information):
 - OS: linux
 - DuckDB Version: v0.3.3-dev1399 7c5ba6c0e
 - DuckDB Client: /usr/local/bin/duckdb

#### Before Submitting

- [x] **Have you tried this on the latest `master` branch?**
* **Python**: `pip install duckdb --upgrade --pre`
* **R**: `install.packages("https://github.com/duckdb/duckdb/releases/download/master-builds/duckdb_r_src.tar.gz", repos = NULL)`
* **Other Platforms**: You can find binaries [here](https://github.com/duckdb/duckdb/releases/tag/master-builds) or compile from source.

- [x] **Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?**

Undefined behavior : -nan outside the range at pipeline.cpp:87:23 (maybe not a bug)
#### What happens?
```
/root/duckdb/src/parallel/pipeline.cpp:87:23: runtime error: -nan is outside the range of representable values of type 'unsigned long'
SUMMARY: UndefinedBehaviorSanitizer: undefined-behavior /root/duckdb/src/parallel/pipeline.cpp:87:23 in
```

#### To Reproduce
```sql
SET enable_progress_bar=true;
WITH RECURSIVE t AS
(
	SELECT 1 AS x
UNION
	SELECT t1.x + t2.x + t3.x AS x
	FROM t t1, t t2, t t3
	WHERE t1.x < 100
)
SELECT * FROM t ORDER BY 1;
```

#### Environment (please complete the following information):
 - OS: linux
 - DuckDB Version: v0.3.3-dev1399 7c5ba6c0e
 - DuckDB Client: /usr/local/bin/duckdb

#### Before Submitting

- [x] **Have you tried this on the latest `master` branch?**
* **Python**: `pip install duckdb --upgrade --pre`
* **R**: `install.packages("https://github.com/duckdb/duckdb/releases/download/master-builds/duckdb_r_src.tar.gz", repos = NULL)`
* **Other Platforms**: You can find binaries [here](https://github.com/duckdb/duckdb/releases/tag/master-builds) or compile from source.

- [x] **Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?**


</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
3: </div>
4: <p>&nbsp;</p>
5: 
6: <p align="center">
7:   <a href="https://github.com/duckdb/duckdb/actions">
8:     <img src="https://github.com/cwida/duckdb/workflows/.github/workflows/main.yml/badge.svg?branch=master" alt=".github/workflows/main.yml">
9:   </a>
10:   <a href="https://www.codefactor.io/repository/github/cwida/duckdb">
11:     <img src="https://www.codefactor.io/repository/github/cwida/duckdb/badge" alt="CodeFactor"/>
12:   </a>
13:   <a href="https://app.codecov.io/gh/duckdb/duckdb">
14:     <img src="https://codecov.io/gh/duckdb/duckdb/branch/master/graph/badge.svg?token=FaxjcfFghN" alt="codecov"/>
15:   </a>
16:   <a href="https://discord.gg/tcvwpjfnZx">
17:     <img src="https://shields.io/discord/909674491309850675" alt="discord" />
18:   </a>
19: </p>
20: 
21: ## DuckDB
22: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on the goals of DuckDB, please refer to [the Why DuckDB page on our website](https://duckdb.org/why_duckdb).
23: 
24: ## Installation
25: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
26: 
27: ## Data Import
28: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
29: 
30: ```sql
31: SELECT * FROM 'myfile.csv';
32: SELECT * FROM 'myfile.parquet';
33: ```
34: 
35: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
36: 
37: ## SQL Reference
38: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
39: 
40: ## Development
41: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`.
42: 
43: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
44: 
45: 
[end of README.md]
[start of src/parallel/pipeline.cpp]
1: #include "duckdb/parallel/pipeline.hpp"
2: 
3: #include "duckdb/common/printer.hpp"
4: #include "duckdb/execution/executor.hpp"
5: #include "duckdb/main/client_context.hpp"
6: #include "duckdb/parallel/thread_context.hpp"
7: #include "duckdb/parallel/task_scheduler.hpp"
8: #include "duckdb/main/database.hpp"
9: 
10: #include "duckdb/execution/operator/aggregate/physical_simple_aggregate.hpp"
11: #include "duckdb/execution/operator/aggregate/physical_window.hpp"
12: #include "duckdb/execution/operator/scan/physical_table_scan.hpp"
13: #include "duckdb/execution/operator/order/physical_order.hpp"
14: #include "duckdb/execution/operator/aggregate/physical_hash_aggregate.hpp"
15: #include "duckdb/execution/operator/join/physical_hash_join.hpp"
16: #include "duckdb/parallel/pipeline_executor.hpp"
17: #include "duckdb/parallel/pipeline_event.hpp"
18: 
19: #include "duckdb/common/algorithm.hpp"
20: #include "duckdb/common/tree_renderer.hpp"
21: 
22: namespace duckdb {
23: 
24: class PipelineTask : public ExecutorTask {
25: 	static constexpr const idx_t PARTIAL_CHUNK_COUNT = 50;
26: 
27: public:
28: 	explicit PipelineTask(Pipeline &pipeline_p, shared_ptr<Event> event_p)
29: 	    : ExecutorTask(pipeline_p.executor), pipeline(pipeline_p), event(move(event_p)) {
30: 	}
31: 
32: 	Pipeline &pipeline;
33: 	shared_ptr<Event> event;
34: 	unique_ptr<PipelineExecutor> pipeline_executor;
35: 
36: public:
37: 	TaskExecutionResult ExecuteTask(TaskExecutionMode mode) override {
38: 		if (!pipeline_executor) {
39: 			pipeline_executor = make_unique<PipelineExecutor>(pipeline.GetClientContext(), pipeline);
40: 		}
41: 		if (mode == TaskExecutionMode::PROCESS_PARTIAL) {
42: 			bool finished = pipeline_executor->Execute(PARTIAL_CHUNK_COUNT);
43: 			if (!finished) {
44: 				return TaskExecutionResult::TASK_NOT_FINISHED;
45: 			}
46: 		} else {
47: 			pipeline_executor->Execute();
48: 		}
49: 		event->FinishTask();
50: 		pipeline_executor.reset();
51: 		return TaskExecutionResult::TASK_FINISHED;
52: 	}
53: };
54: 
55: Pipeline::Pipeline(Executor &executor_p) : executor(executor_p), ready(false), source(nullptr), sink(nullptr) {
56: }
57: 
58: ClientContext &Pipeline::GetClientContext() {
59: 	return executor.context;
60: }
61: 
62: // LCOV_EXCL_START
63: bool Pipeline::GetProgressInternal(ClientContext &context, PhysicalOperator *op, double &current_percentage) {
64: 	current_percentage = -1;
65: 	switch (op->type) {
66: 	case PhysicalOperatorType::TABLE_SCAN: {
67: 		auto &get = (PhysicalTableScan &)*op;
68: 		if (get.function.table_scan_progress) {
69: 			current_percentage = get.function.table_scan_progress(context, get.bind_data.get());
70: 			return true;
71: 		}
72: 		// If the table_scan_progress is not implemented it means we don't support this function yet in the progress
73: 		// bar
74: 		return false;
75: 	}
76: 		// If it is not a table scan we go down on all children until we reach the leaf operators
77: 	default: {
78: 		vector<idx_t> progress;
79: 		vector<idx_t> cardinality;
80: 		double total_cardinality = 0;
81: 		current_percentage = 0;
82: 		for (auto &op_child : op->children) {
83: 			double child_percentage = 0;
84: 			if (!GetProgressInternal(context, op_child.get(), child_percentage)) {
85: 				return false;
86: 			}
87: 			progress.push_back(child_percentage);
88: 			cardinality.push_back(op_child->estimated_cardinality);
89: 			total_cardinality += op_child->estimated_cardinality;
90: 		}
91: 		for (size_t i = 0; i < progress.size(); i++) {
92: 			current_percentage += progress[i] * cardinality[i] / total_cardinality;
93: 		}
94: 		return true;
95: 	}
96: 	}
97: }
98: // LCOV_EXCL_STOP
99: 
100: bool Pipeline::GetProgress(double &current_percentage) {
101: 	auto &client = executor.context;
102: 	return GetProgressInternal(client, source, current_percentage);
103: }
104: 
105: void Pipeline::ScheduleSequentialTask(shared_ptr<Event> &event) {
106: 	vector<unique_ptr<Task>> tasks;
107: 	tasks.push_back(make_unique<PipelineTask>(*this, event));
108: 	event->SetTasks(move(tasks));
109: }
110: 
111: bool Pipeline::ScheduleParallel(shared_ptr<Event> &event) {
112: 	if (!sink->ParallelSink()) {
113: 		return false;
114: 	}
115: 	if (!source->ParallelSource()) {
116: 		return false;
117: 	}
118: 	for (auto &op : operators) {
119: 		if (!op->ParallelOperator()) {
120: 			return false;
121: 		}
122: 	}
123: 	idx_t max_threads = source_state->MaxThreads();
124: 	return LaunchScanTasks(event, max_threads);
125: }
126: 
127: void Pipeline::Schedule(shared_ptr<Event> &event) {
128: 	D_ASSERT(ready);
129: 	D_ASSERT(sink);
130: 	if (!ScheduleParallel(event)) {
131: 		// could not parallelize this pipeline: push a sequential task instead
132: 		ScheduleSequentialTask(event);
133: 	}
134: }
135: 
136: bool Pipeline::LaunchScanTasks(shared_ptr<Event> &event, idx_t max_threads) {
137: 	// split the scan up into parts and schedule the parts
138: 	auto &scheduler = TaskScheduler::GetScheduler(executor.context);
139: 	idx_t active_threads = scheduler.NumberOfThreads();
140: 	if (max_threads > active_threads) {
141: 		max_threads = active_threads;
142: 	}
143: 	if (max_threads <= 1) {
144: 		// too small to parallelize
145: 		return false;
146: 	}
147: 
148: 	// launch a task for every thread
149: 	vector<unique_ptr<Task>> tasks;
150: 	for (idx_t i = 0; i < max_threads; i++) {
151: 		tasks.push_back(make_unique<PipelineTask>(*this, event));
152: 	}
153: 	event->SetTasks(move(tasks));
154: 	return true;
155: }
156: 
157: void Pipeline::Reset() {
158: 	if (sink && !sink->sink_state) {
159: 		sink->sink_state = sink->GetGlobalSinkState(GetClientContext());
160: 	}
161: 
162: 	for (auto &op : operators) {
163: 		if (op && !op->op_state) {
164: 			op->op_state = op->GetGlobalOperatorState(GetClientContext());
165: 		}
166: 	}
167: 
168: 	ResetSource();
169: }
170: 
171: void Pipeline::ResetSource() {
172: 	source_state = source->GetGlobalSourceState(GetClientContext());
173: }
174: 
175: void Pipeline::Ready() {
176: 	if (ready) {
177: 		return;
178: 	}
179: 	ready = true;
180: 	std::reverse(operators.begin(), operators.end());
181: 	Reset();
182: }
183: 
184: void Pipeline::Finalize(Event &event) {
185: 	D_ASSERT(ready);
186: 	try {
187: 		auto sink_state = sink->Finalize(*this, event, executor.context, *sink->sink_state);
188: 		sink->sink_state->state = sink_state;
189: 	} catch (Exception &ex) { // LCOV_EXCL_START
190: 		executor.PushError(ex.type, ex.what());
191: 	} catch (std::exception &ex) {
192: 		executor.PushError(ExceptionType::UNKNOWN_TYPE, ex.what());
193: 	} catch (...) {
194: 		executor.PushError(ExceptionType::UNKNOWN_TYPE, "Unknown exception in Finalize!");
195: 	} // LCOV_EXCL_STOP
196: }
197: 
198: void Pipeline::AddDependency(shared_ptr<Pipeline> &pipeline) {
199: 	D_ASSERT(pipeline);
200: 	dependencies.push_back(weak_ptr<Pipeline>(pipeline));
201: 	pipeline->parents.push_back(weak_ptr<Pipeline>(shared_from_this()));
202: }
203: 
204: string Pipeline::ToString() const {
205: 	TreeRenderer renderer;
206: 	return renderer.ToString(*this);
207: }
208: 
209: void Pipeline::Print() const {
210: 	Printer::Print(ToString());
211: }
212: 
213: vector<PhysicalOperator *> Pipeline::GetOperators() const {
214: 	vector<PhysicalOperator *> result;
215: 	D_ASSERT(source);
216: 	result.push_back(source);
217: 	result.insert(result.end(), operators.begin(), operators.end());
218: 	if (sink) {
219: 		result.push_back(sink);
220: 	}
221: 	return result;
222: }
223: 
224: } // namespace duckdb
[end of src/parallel/pipeline.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: