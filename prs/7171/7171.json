{
  "repo": "duckdb/duckdb",
  "pull_number": 7171,
  "instance_id": "duckdb__duckdb-7171",
  "issue_numbers": [
    "6862"
  ],
  "base_commit": "c7fa248e14074c754394dbd848de7b507d69278d",
  "patch": "diff --git a/src/common/arrow/arrow_converter.cpp b/src/common/arrow/arrow_converter.cpp\nindex 5f5ac9d2fbe1..9b1789d50211 100644\n--- a/src/common/arrow/arrow_converter.cpp\n+++ b/src/common/arrow/arrow_converter.cpp\n@@ -59,10 +59,10 @@ void InitializeChild(ArrowSchema &child, const string &name = \"\") {\n \tchild.dictionary = nullptr;\n }\n void SetArrowFormat(DuckDBArrowSchemaHolder &root_holder, ArrowSchema &child, const LogicalType &type,\n-                    string &config_timezone);\n+                    const string &config_timezone);\n \n void SetArrowMapFormat(DuckDBArrowSchemaHolder &root_holder, ArrowSchema &child, const LogicalType &type,\n-                       string &config_timezone) {\n+                       const string &config_timezone) {\n \tchild.format = \"+m\";\n \t//! Map has one child which is a struct\n \tchild.n_children = 1;\n@@ -77,7 +77,7 @@ void SetArrowMapFormat(DuckDBArrowSchemaHolder &root_holder, ArrowSchema &child,\n }\n \n void SetArrowFormat(DuckDBArrowSchemaHolder &root_holder, ArrowSchema &child, const LogicalType &type,\n-                    string &config_timezone) {\n+                    const string &config_timezone) {\n \tswitch (type.id()) {\n \tcase LogicalTypeId::BOOLEAN:\n \t\tchild.format = \"b\";\n@@ -249,8 +249,8 @@ void SetArrowFormat(DuckDBArrowSchemaHolder &root_holder, ArrowSchema &child, co\n \t}\n }\n \n-void ArrowConverter::ToArrowSchema(ArrowSchema *out_schema, vector<LogicalType> &types, vector<string> &names,\n-                                   string &config_timezone) {\n+void ArrowConverter::ToArrowSchema(ArrowSchema *out_schema, const vector<LogicalType> &types,\n+                                   const vector<string> &names, const string &config_timezone) {\n \tD_ASSERT(out_schema);\n \tD_ASSERT(types.size() == names.size());\n \tidx_t column_count = types.size();\ndiff --git a/src/common/types/vector.cpp b/src/common/types/vector.cpp\nindex 7d6681f3d5f3..86ae13fded66 100644\n--- a/src/common/types/vector.cpp\n+++ b/src/common/types/vector.cpp\n@@ -732,6 +732,11 @@ void Vector::Flatten(idx_t count) {\n \t\tauto old_buffer = std::move(buffer);\n \t\tauto old_data = data;\n \t\tbuffer = VectorBuffer::CreateStandardVector(type, MaxValue<idx_t>(STANDARD_VECTOR_SIZE, count));\n+\t\tif (old_buffer) {\n+\t\t\tD_ASSERT(buffer->GetAuxiliaryData() == nullptr);\n+\t\t\t// The old buffer might be relying on the auxiliary data, keep it alive\n+\t\t\tbuffer->MoveAuxiliaryData(*old_buffer);\n+\t\t}\n \t\tdata = buffer->GetData();\n \t\tvector_type = VectorType::FLAT_VECTOR;\n \t\tif (is_null) {\ndiff --git a/src/function/table/arrow.cpp b/src/function/table/arrow.cpp\nindex 9c15891774fb..122bb216126d 100644\n--- a/src/function/table/arrow.cpp\n+++ b/src/function/table/arrow.cpp\n@@ -286,9 +286,9 @@ unique_ptr<GlobalTableFunctionState> ArrowTableFunction::ArrowScanInitGlobal(Cli\n \treturn std::move(result);\n }\n \n-unique_ptr<LocalTableFunctionState> ArrowTableFunction::ArrowScanInitLocal(ExecutionContext &context,\n-                                                                           TableFunctionInitInput &input,\n-                                                                           GlobalTableFunctionState *global_state_p) {\n+unique_ptr<LocalTableFunctionState>\n+ArrowTableFunction::ArrowScanInitLocalInternal(ClientContext &context, TableFunctionInitInput &input,\n+                                               GlobalTableFunctionState *global_state_p) {\n \tauto &global_state = global_state_p->Cast<ArrowScanGlobalState>();\n \tauto current_chunk = make_uniq<ArrowArrayWrapper>();\n \tauto result = make_uniq<ArrowScanLocalState>(std::move(current_chunk));\n@@ -296,14 +296,20 @@ unique_ptr<LocalTableFunctionState> ArrowTableFunction::ArrowScanInitLocal(Execu\n \tresult->filters = input.filters.get();\n \tif (input.CanRemoveFilterColumns()) {\n \t\tauto &asgs = global_state_p->Cast<ArrowScanGlobalState>();\n-\t\tresult->all_columns.Initialize(context.client, asgs.scanned_types);\n+\t\tresult->all_columns.Initialize(context, asgs.scanned_types);\n \t}\n-\tif (!ArrowScanParallelStateNext(context.client, input.bind_data.get(), *result, global_state)) {\n+\tif (!ArrowScanParallelStateNext(context, input.bind_data.get(), *result, global_state)) {\n \t\treturn nullptr;\n \t}\n \treturn std::move(result);\n }\n \n+unique_ptr<LocalTableFunctionState> ArrowTableFunction::ArrowScanInitLocal(ExecutionContext &context,\n+                                                                           TableFunctionInitInput &input,\n+                                                                           GlobalTableFunctionState *global_state_p) {\n+\treturn ArrowScanInitLocalInternal(context.client, input, global_state_p);\n+}\n+\n void ArrowTableFunction::ArrowScanFunction(ClientContext &context, TableFunctionInput &data_p, DataChunk &output) {\n \tif (!data_p.local_state) {\n \t\treturn;\ndiff --git a/src/include/duckdb/common/arrow/arrow_converter.hpp b/src/include/duckdb/common/arrow/arrow_converter.hpp\nindex 390add889352..a24c36adad40 100644\n--- a/src/include/duckdb/common/arrow/arrow_converter.hpp\n+++ b/src/include/duckdb/common/arrow/arrow_converter.hpp\n@@ -16,8 +16,8 @@ struct ArrowSchema;\n namespace duckdb {\n \n struct ArrowConverter {\n-\tDUCKDB_API static void ToArrowSchema(ArrowSchema *out_schema, vector<LogicalType> &types, vector<string> &names,\n-\t                                     string &config_timezone);\n+\tDUCKDB_API static void ToArrowSchema(ArrowSchema *out_schema, const vector<LogicalType> &types,\n+\t                                     const vector<string> &names, const string &config_timezone);\n \tDUCKDB_API static void ToArrowArray(DataChunk &input, ArrowArray *out_array);\n };\n \ndiff --git a/src/include/duckdb/common/types/arrow_aux_data.hpp b/src/include/duckdb/common/types/arrow_aux_data.hpp\nindex 44edbe2119d1..cf6c176fe3d3 100644\n--- a/src/include/duckdb/common/types/arrow_aux_data.hpp\n+++ b/src/include/duckdb/common/types/arrow_aux_data.hpp\n@@ -13,7 +13,8 @@\n \n namespace duckdb {\n \n-struct ArrowAuxiliaryData : VectorAuxiliaryData {\n+struct ArrowAuxiliaryData : public VectorAuxiliaryData {\n+\tstatic constexpr const VectorAuxiliaryDataType TYPE = VectorAuxiliaryDataType::ARROW_AUXILIARY;\n \texplicit ArrowAuxiliaryData(shared_ptr<ArrowArrayWrapper> arrow_array_p)\n \t    : VectorAuxiliaryData(VectorAuxiliaryDataType::ARROW_AUXILIARY), arrow_array(std::move(arrow_array_p)) {\n \t}\ndiff --git a/src/include/duckdb/common/types/vector_buffer.hpp b/src/include/duckdb/common/types/vector_buffer.hpp\nindex 3d6849206c7b..d2171fcfc8f2 100644\n--- a/src/include/duckdb/common/types/vector_buffer.hpp\n+++ b/src/include/duckdb/common/types/vector_buffer.hpp\n@@ -45,6 +45,23 @@ struct VectorAuxiliaryData {\n \n \tvirtual ~VectorAuxiliaryData() {\n \t}\n+\n+public:\n+\ttemplate <class TARGET>\n+\tTARGET &Cast() {\n+\t\tif (type != TARGET::TYPE) {\n+\t\t\tthrow InternalException(\"Failed to cast vector auxiliary data to type - type mismatch\");\n+\t\t}\n+\t\treturn (TARGET &)*this;\n+\t}\n+\n+\ttemplate <class TARGET>\n+\tconst TARGET &Cast() const {\n+\t\tif (type != TARGET::TYPE) {\n+\t\t\tthrow InternalException(\"Failed to cast vector auxiliary data to type - type mismatch\");\n+\t\t}\n+\t\treturn (const TARGET &)*this;\n+\t}\n };\n \n //! The VectorBuffer is a class used by the vector to hold its data\n@@ -82,6 +99,10 @@ class VectorBuffer {\n \t\taux_data = std::move(aux_data_p);\n \t}\n \n+\tvoid MoveAuxiliaryData(VectorBuffer &source_buffer) {\n+\t\tSetAuxiliaryData(std::move(source_buffer.aux_data));\n+\t}\n+\n \tstatic buffer_ptr<VectorBuffer> CreateStandardVector(PhysicalType type, idx_t capacity = STANDARD_VECTOR_SIZE);\n \tstatic buffer_ptr<VectorBuffer> CreateConstantVector(PhysicalType type);\n \tstatic buffer_ptr<VectorBuffer> CreateConstantVector(const LogicalType &logical_type);\ndiff --git a/src/include/duckdb/core_functions/scalar/string_functions.hpp b/src/include/duckdb/core_functions/scalar/string_functions.hpp\nindex 9ce71c154d2b..55ff6eb5d9fa 100644\n--- a/src/include/duckdb/core_functions/scalar/string_functions.hpp\n+++ b/src/include/duckdb/core_functions/scalar/string_functions.hpp\n@@ -31,7 +31,8 @@ struct StartsWithFun {\n struct ASCIIFun {\n \tstatic constexpr const char *Name = \"ascii\";\n \tstatic constexpr const char *Parameters = \"string\";\n-\tstatic constexpr const char *Description = \"Returns an integer that represents the Unicode code point of the first character of the string.\";\n+\tstatic constexpr const char *Description =\n+\t    \"Returns an integer that represents the Unicode code point of the first character of the string.\";\n \tstatic constexpr const char *Example = \"ascii('\u03a9')\";\n \n \tstatic ScalarFunction GetFunction();\n@@ -40,7 +41,8 @@ struct ASCIIFun {\n struct BarFun {\n \tstatic constexpr const char *Name = \"bar\";\n \tstatic constexpr const char *Parameters = \"x,min,max,width\";\n-\tstatic constexpr const char *Description = \"Draw a band whose width is proportional to (x - min) and equal to width characters when x = max. width defaults to 80.\";\n+\tstatic constexpr const char *Description = \"Draw a band whose width is proportional to (x - min) and equal to \"\n+\t                                           \"width characters when x = max. width defaults to 80.\";\n \tstatic constexpr const char *Example = \"bar(5, 0, 20, 10)\";\n \n \tstatic ScalarFunctionSet GetFunctions();\n@@ -64,7 +66,8 @@ struct ToBinaryFun {\n struct ChrFun {\n \tstatic constexpr const char *Name = \"chr\";\n \tstatic constexpr const char *Parameters = \"code_point\";\n-\tstatic constexpr const char *Description = \"returns a character which is corresponding the ASCII code value or Unicode code point\";\n+\tstatic constexpr const char *Description =\n+\t    \"returns a character which is corresponding the ASCII code value or Unicode code point\";\n \tstatic constexpr const char *Example = \"chr(65)\";\n \n \tstatic ScalarFunction GetFunction();\n@@ -73,7 +76,10 @@ struct ChrFun {\n struct DamerauLevenshteinFun {\n \tstatic constexpr const char *Name = \"damerau_levenshtein\";\n \tstatic constexpr const char *Parameters = \"str1,str2\";\n-\tstatic constexpr const char *Description = \"Extension of Levenshtein distance to also include transposition of adjacent characters as an allowed edit operation. In other words, the minimum number of edit operations (insertions, deletions, substitutions or transpositions) required to change one string to another. Different case is considered different.\";\n+\tstatic constexpr const char *Description =\n+\t    \"Extension of Levenshtein distance to also include transposition of adjacent characters as an allowed edit \"\n+\t    \"operation. In other words, the minimum number of edit operations (insertions, deletions, substitutions or \"\n+\t    \"transpositions) required to change one string to another. Different case is considered different.\";\n \tstatic constexpr const char *Example = \"damerau_levenshtein('hello', 'world')\";\n \n \tstatic ScalarFunction GetFunction();\n@@ -91,7 +97,8 @@ struct FormatFun {\n struct HammingFun {\n \tstatic constexpr const char *Name = \"hamming\";\n \tstatic constexpr const char *Parameters = \"str1,str2\";\n-\tstatic constexpr const char *Description = \"The number of positions with different characters for 2 strings of equal length. Different case is considered different.\";\n+\tstatic constexpr const char *Description = \"The number of positions with different characters for 2 strings of \"\n+\t                                           \"equal length. Different case is considered different.\";\n \tstatic constexpr const char *Example = \"hamming('duck','luck')\";\n \n \tstatic ScalarFunction GetFunction();\n@@ -121,7 +128,8 @@ struct ToHexFun {\n struct InstrFun {\n \tstatic constexpr const char *Name = \"instr\";\n \tstatic constexpr const char *Parameters = \"haystack,needle\";\n-\tstatic constexpr const char *Description = \"Return location of first occurrence of needle in haystack, counting from 1. Returns 0 if no match found.\";\n+\tstatic constexpr const char *Description =\n+\t    \"Return location of first occurrence of needle in haystack, counting from 1. Returns 0 if no match found.\";\n \tstatic constexpr const char *Example = \"instr('test test','es')\";\n \n \tstatic ScalarFunction GetFunction();\n@@ -142,7 +150,8 @@ struct PositionFun {\n struct JaccardFun {\n \tstatic constexpr const char *Name = \"jaccard\";\n \tstatic constexpr const char *Parameters = \"str1,str2\";\n-\tstatic constexpr const char *Description = \"The Jaccard similarity between two strings. Different case is considered different. Returns a number between 0 and 1.\";\n+\tstatic constexpr const char *Description = \"The Jaccard similarity between two strings. Different case is \"\n+\t                                           \"considered different. Returns a number between 0 and 1.\";\n \tstatic constexpr const char *Example = \"jaccard('duck','luck')\";\n \n \tstatic ScalarFunction GetFunction();\n@@ -151,7 +160,8 @@ struct JaccardFun {\n struct JaroSimilarityFun {\n \tstatic constexpr const char *Name = \"jaro_similarity\";\n \tstatic constexpr const char *Parameters = \"str1,str2\";\n-\tstatic constexpr const char *Description = \"The Jaro similarity between two strings. Different case is considered different. Returns a number between 0 and 1.\";\n+\tstatic constexpr const char *Description = \"The Jaro similarity between two strings. Different case is considered \"\n+\t                                           \"different. Returns a number between 0 and 1.\";\n \tstatic constexpr const char *Example = \"jaro_similarity('duck','duckdb')\";\n \n \tstatic ScalarFunction GetFunction();\n@@ -160,7 +170,8 @@ struct JaroSimilarityFun {\n struct JaroWinklerSimilarityFun {\n \tstatic constexpr const char *Name = \"jaro_winkler_similarity\";\n \tstatic constexpr const char *Parameters = \"str1,str2\";\n-\tstatic constexpr const char *Description = \"The Jaro-Winkler similarity between two strings. Different case is considered different. Returns a number between 0 and 1.\";\n+\tstatic constexpr const char *Description = \"The Jaro-Winkler similarity between two strings. Different case is \"\n+\t                                           \"considered different. Returns a number between 0 and 1.\";\n \tstatic constexpr const char *Example = \"jaro_winkler_similarity('duck','duckdb')\";\n \n \tstatic ScalarFunction GetFunction();\n@@ -187,7 +198,9 @@ struct LeftGraphemeFun {\n struct LevenshteinFun {\n \tstatic constexpr const char *Name = \"levenshtein\";\n \tstatic constexpr const char *Parameters = \"str1,str2\";\n-\tstatic constexpr const char *Description = \"The minimum number of single-character edits (insertions, deletions or substitutions) required to change one string to the other. Different case is considered different.\";\n+\tstatic constexpr const char *Description =\n+\t    \"The minimum number of single-character edits (insertions, deletions or substitutions) required to change one \"\n+\t    \"string to the other. Different case is considered different.\";\n \tstatic constexpr const char *Example = \"levenshtein('duck','db')\";\n \n \tstatic ScalarFunction GetFunction();\n@@ -202,7 +215,8 @@ struct Editdist3Fun {\n struct LpadFun {\n \tstatic constexpr const char *Name = \"lpad\";\n \tstatic constexpr const char *Parameters = \"string,count,character\";\n-\tstatic constexpr const char *Description = \"Pads the string with the character from the left until it has count characters\";\n+\tstatic constexpr const char *Description =\n+\t    \"Pads the string with the character from the left until it has count characters\";\n \tstatic constexpr const char *Example = \"lpad('hello', 10, '>')\";\n \n \tstatic ScalarFunction GetFunction();\n@@ -211,7 +225,8 @@ struct LpadFun {\n struct LtrimFun {\n \tstatic constexpr const char *Name = \"ltrim\";\n \tstatic constexpr const char *Parameters = \"string,characters\";\n-\tstatic constexpr const char *Description = \"Removes any occurrences of any of the characters from the left side of the string\";\n+\tstatic constexpr const char *Description =\n+\t    \"Removes any occurrences of any of the characters from the left side of the string\";\n \tstatic constexpr const char *Example = \"ltrim('>>>>test<<', '><')\";\n \n \tstatic ScalarFunctionSet GetFunctions();\n@@ -310,7 +325,8 @@ struct RightGraphemeFun {\n struct RpadFun {\n \tstatic constexpr const char *Name = \"rpad\";\n \tstatic constexpr const char *Parameters = \"string,count,character\";\n-\tstatic constexpr const char *Description = \"Pads the string with the character from the right until it has count characters\";\n+\tstatic constexpr const char *Description =\n+\t    \"Pads the string with the character from the right until it has count characters\";\n \tstatic constexpr const char *Example = \"rpad('hello', 10, '<')\";\n \n \tstatic ScalarFunction GetFunction();\n@@ -319,7 +335,8 @@ struct RpadFun {\n struct RtrimFun {\n \tstatic constexpr const char *Name = \"rtrim\";\n \tstatic constexpr const char *Parameters = \"string,characters\";\n-\tstatic constexpr const char *Description = \"Removes any occurrences of any of the characters from the right side of the string\";\n+\tstatic constexpr const char *Description =\n+\t    \"Removes any occurrences of any of the characters from the right side of the string\";\n \tstatic constexpr const char *Example = \"rtrim('>>>>test<<', '><')\";\n \n \tstatic ScalarFunctionSet GetFunctions();\n@@ -376,7 +393,9 @@ struct RegexpSplitToArrayFun {\n struct TranslateFun {\n \tstatic constexpr const char *Name = \"translate\";\n \tstatic constexpr const char *Parameters = \"string,from,to\";\n-\tstatic constexpr const char *Description = \"Replaces each character in string that matches a character in the from set with the corresponding character in the to set. If from is longer than to, occurrences of the extra characters in from are deleted.\";\n+\tstatic constexpr const char *Description =\n+\t    \"Replaces each character in string that matches a character in the from set with the corresponding character \"\n+\t    \"in the to set. If from is longer than to, occurrences of the extra characters in from are deleted.\";\n \tstatic constexpr const char *Example = \"translate('12345', '143', 'ax')\";\n \n \tstatic ScalarFunction GetFunction();\n@@ -385,7 +404,8 @@ struct TranslateFun {\n struct TrimFun {\n \tstatic constexpr const char *Name = \"trim\";\n \tstatic constexpr const char *Parameters = \"string,characters\";\n-\tstatic constexpr const char *Description = \"Removes any occurrences of any of the characters from either side of the string\";\n+\tstatic constexpr const char *Description =\n+\t    \"Removes any occurrences of any of the characters from either side of the string\";\n \tstatic constexpr const char *Example = \"trim('>>>>test<<', '><')\";\n \n \tstatic ScalarFunctionSet GetFunctions();\ndiff --git a/src/include/duckdb/function/table/arrow.hpp b/src/include/duckdb/function/table/arrow.hpp\nindex 2a9c2229ee78..9e0f9865e054 100644\n--- a/src/include/duckdb/function/table/arrow.hpp\n+++ b/src/include/duckdb/function/table/arrow.hpp\n@@ -127,7 +127,7 @@ struct ArrowTableFunction {\n public:\n \tstatic void RegisterFunction(BuiltinFunctions &set);\n \n-protected:\n+public:\n \t//! Binds an arrow table\n \tstatic unique_ptr<FunctionData> ArrowScanBind(ClientContext &context, TableFunctionBindInput &input,\n \t                                              vector<LogicalType> &return_types, vector<string> &names);\n@@ -145,6 +145,9 @@ struct ArrowTableFunction {\n \t                                                                TableFunctionInitInput &input);\n \n \t//! Initialize Local State\n+\tstatic unique_ptr<LocalTableFunctionState> ArrowScanInitLocalInternal(ClientContext &context,\n+\t                                                                      TableFunctionInitInput &input,\n+\t                                                                      GlobalTableFunctionState *global_state);\n \tstatic unique_ptr<LocalTableFunctionState> ArrowScanInitLocal(ExecutionContext &context,\n \t                                                              TableFunctionInitInput &input,\n \t                                                              GlobalTableFunctionState *global_state);\n@@ -152,6 +155,7 @@ struct ArrowTableFunction {\n \t//! Scan Function\n \tstatic void ArrowScanFunction(ClientContext &context, TableFunctionInput &data, DataChunk &output);\n \n+protected:\n \t//! Defines Maximum Number of Threads\n \tstatic idx_t ArrowScanMaxThreads(ClientContext &context, const FunctionData *bind_data);\n \ndiff --git a/tools/pythonpkg/duckdb-stubs/__init__.pyi b/tools/pythonpkg/duckdb-stubs/__init__.pyi\nindex 2b9140cd28a3..cfc51c151145 100644\n--- a/tools/pythonpkg/duckdb-stubs/__init__.pyi\n+++ b/tools/pythonpkg/duckdb-stubs/__init__.pyi\n@@ -5,12 +5,13 @@\n # to help the sanity of maintainers.\n \n from .typing import DuckDBPyType\n+from .functional import FunctionNullHandling, PythonUDFType\n \n # We also run this in python3.7, where this is needed\n from typing_extensions import Literal\n import typing\n # stubgen override - missing import of Set\n-from typing import Any, ClassVar, Set, Optional\n+from typing import Any, ClassVar, Set, Optional, Callable\n from io import StringIO, TextIOBase\n \n from typing import overload, Dict, List, Union\n@@ -35,6 +36,8 @@ threadsafety: int\n __standard_vector_size__: int\n STANDARD: ExplainType\n ANALYZE: ExplainType\n+DEFAULT: PythonExceptionHandling\n+RETURN_NULL: PythonExceptionHandling\n \n __interactive__: bool\n __jupyter__: bool\n@@ -65,6 +68,18 @@ class ExplainType:\n     @property\n     def value(self) -> int: ...\n \n+class PythonExceptionHandling:\n+    DEFAULT: PythonExceptionHandling\n+    RETURN_NULL: PythonExceptionHandling\n+    def __int__(self) -> int: ...\n+    def __index__(self) -> int: ...\n+    @property\n+    def __members__(self) -> Dict[str, PythonExceptionHandling]: ...\n+    @property\n+    def name(self) -> str: ...\n+    @property\n+    def value(self) -> int: ...\n+\n class DuckDBPyConnection:\n     def __init__(self, *args, **kwargs) -> None: ...\n     def append(self, table_name: str, df: pandas.DataFrame) -> DuckDBPyConnection: ...\n@@ -160,6 +175,16 @@ class DuckDBPyConnection:\n     def tf(self, connection: DuckDBPyConnection = ...) -> dict: ...\n     def query(self, query: str, alias: str = ...) -> DuckDBPyRelation: ...\n     def register(self, view_name: str, python_object: object) -> DuckDBPyConnection: ...\n+    def remove_function(self, name: str) -> DuckDBPyConnection: ...\n+    def create_function(\n+        self,\n+        name: str,\n+        func: Callable,\n+        args: Optional[List[DuckDBPyType]],\n+        return_type: Optional[DuckDBPyType],\n+        vectorized: Optional[bool] = False,\n+        null_handling: Optional[FunctionNullHandling] = FunctionNullHandling.DEFAULT,\n+        exception_handling: Optional[PythonExceptionHandling] = PythonExceptionHandling.DEFAULT) -> DuckDBPyConnection: ...\n     def register_filesystem(self, filesystem: fsspec.AbstractFileSystem) -> None: ...\n     def rollback(self) -> DuckDBPyConnection: ...\n     def sql(self, query: str, alias: str = ...) -> DuckDBPyRelation: ...\n@@ -498,6 +523,16 @@ def torch(connection: DuckDBPyConnection = ...) -> dict: ...\n def tf(self, connection: DuckDBPyConnection = ...) -> dict: ...\n def query(query: str, alias: str = 'query_relation', connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...\n def register(view_name: str, python_object: object, connection: DuckDBPyConnection = ...) -> DuckDBPyConnection: ...\n+def remove_function(name: str, connection : DuckDBPyConnection = ...) -> DuckDBPyConnection: ...\n+def create_function(\n+    name: str,\n+    func: Callable,\n+    args: Optional[List[DuckDBPyType]],\n+    return_type: Optional[DuckDBPyType],\n+    vectorized: Optional[bool] = False,\n+    null_handling: Optional[FunctionNullHandling] = FunctionNullHandling.DEFAULT,\n+    exception_handling: Optional[PythonExceptionHandling] = PythonExceptionHandling.DEFAULT,\n+    connection: DuckDBPyConnection = ...) -> DuckDBPyConnection: ...\n def register_filesystem(filesystem: fsspec.AbstractFileSystem, connection: DuckDBPyConnection = ...) -> None: ...\n def rollback(connection: DuckDBPyConnection = ...) -> DuckDBPyConnection: ...\n def sql(query: str, alias: str = ..., connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...\ndiff --git a/tools/pythonpkg/duckdb-stubs/functional/__init__.pyi b/tools/pythonpkg/duckdb-stubs/functional/__init__.pyi\nnew file mode 100644\nindex 000000000000..63116386c3ea\n--- /dev/null\n+++ b/tools/pythonpkg/duckdb-stubs/functional/__init__.pyi\n@@ -0,0 +1,33 @@\n+from .. import DuckDBPyConnection\n+\n+from typing import Dict\n+\n+SPECIAL: FunctionNullHandling\n+DEFAULT: FunctionNullHandling\n+\n+NATIVE: PythonUDFType\n+ARROW: PythonUDFType\n+\n+class FunctionNullHandling:\n+    DEFAULT: FunctionNullHandling\n+    SPECIAL: FunctionNullHandling\n+    def __int__(self) -> int: ...\n+    def __index__(self) -> int: ...\n+    @property\n+    def __members__(self) -> Dict[str, FunctionNullHandling]: ...\n+    @property\n+    def name(self) -> str: ...\n+    @property\n+    def value(self) -> int: ...\n+\n+class PythonUDFType:\n+    NATIVE: PythonUDFType\n+    ARROW: PythonUDFType\n+    def __int__(self) -> int: ...\n+    def __index__(self) -> int: ...\n+    @property\n+    def __members__(self) -> Dict[str, PythonUDFType]: ...\n+    @property\n+    def name(self) -> str: ...\n+    @property\n+    def value(self) -> int: ...\ndiff --git a/tools/pythonpkg/duckdb_python.cpp b/tools/pythonpkg/duckdb_python.cpp\nindex 32f26b45975f..93fdf7f7f870 100644\n--- a/tools/pythonpkg/duckdb_python.cpp\n+++ b/tools/pythonpkg/duckdb_python.cpp\n@@ -10,8 +10,12 @@\n #include \"duckdb_python/pyresult.hpp\"\n #include \"duckdb_python/pybind11/exceptions.hpp\"\n #include \"duckdb_python/typing.hpp\"\n+#include \"duckdb_python/functional.hpp\"\n #include \"duckdb_python/connection_wrapper.hpp\"\n #include \"duckdb_python/pybind11/conversions/pyconnection_default.hpp\"\n+#include \"duckdb/function/function.hpp\"\n+#include \"duckdb_python/pybind11/conversions/exception_handling_enum.hpp\"\n+#include \"duckdb_python/pybind11/conversions/python_udf_type_enum.hpp\"\n \n #include \"duckdb.hpp\"\n \n@@ -68,6 +72,15 @@ static void InitializeConnectionMethods(py::module_ &m) {\n \t      py::arg(\"connection\") = py::none())\n \t    .def(\"duplicate\", &PyConnectionWrapper::Cursor, \"Create a duplicate of the current connection\",\n \t         py::arg(\"connection\") = py::none());\n+\tm.def(\"create_function\", &PyConnectionWrapper::RegisterScalarUDF,\n+\t      \"Create a DuckDB function out of the passing in python function so it can be used in queries\",\n+\t      py::arg(\"name\"), py::arg(\"function\"), py::arg(\"return_type\") = py::none(), py::arg(\"parameters\") = py::none(),\n+\t      py::kw_only(), py::arg(\"type\") = PythonUDFType::NATIVE, py::arg(\"null_handling\") = 0,\n+\t      py::arg(\"exception_handling\") = 0, py::arg(\"connection\") = py::none());\n+\n+\tm.def(\"remove_function\", &PyConnectionWrapper::UnregisterUDF, \"Remove a previously created function\",\n+\t      py::arg(\"name\"), py::arg(\"connection\") = py::none());\n+\n \tDefineMethod({\"sqltype\", \"dtype\", \"type\"}, m, &PyConnectionWrapper::Type, \"Create a type object from 'type_str'\",\n \t             py::arg(\"type_str\"), py::arg(\"connection\") = py::none());\n \tDefineMethod({\"struct_type\", \"row_type\"}, m, &PyConnectionWrapper::StructType,\n@@ -255,13 +268,23 @@ static void InitializeConnectionMethods(py::module_ &m) {\n }\n \n PYBIND11_MODULE(DUCKDB_PYTHON_LIB_NAME, m) {\n+\n+\tpy::enum_<duckdb::ExplainType>(m, \"ExplainType\")\n+\t    .value(\"STANDARD\", duckdb::ExplainType::EXPLAIN_STANDARD)\n+\t    .value(\"ANALYZE\", duckdb::ExplainType::EXPLAIN_ANALYZE)\n+\t    .export_values();\n+\n+\tpy::enum_<duckdb::PythonExceptionHandling>(m, \"PythonExceptionHandling\")\n+\t    .value(\"DEFAULT\", duckdb::PythonExceptionHandling::FORWARD_ERROR)\n+\t    .value(\"RETURN_NULL\", duckdb::PythonExceptionHandling::RETURN_NULL)\n+\t    .export_values();\n+\n+\tDuckDBPyTyping::Initialize(m);\n+\tDuckDBPyFunctional::Initialize(m);\n \tDuckDBPyRelation::Initialize(m);\n \tDuckDBPyConnection::Initialize(m);\n-\tDuckDBPyTyping::Initialize(m);\n \tPythonObject::Initialize();\n \n-\tInitializeConnectionMethods(m);\n-\n \tpy::options pybind_opts;\n \n \tm.doc() = \"DuckDB is an embeddable SQL OLAP Database Management System\";\n@@ -276,10 +299,7 @@ PYBIND11_MODULE(DUCKDB_PYTHON_LIB_NAME, m) {\n \tm.attr(\"threadsafety\") = 1;\n \tm.attr(\"paramstyle\") = \"qmark\";\n \n-\tpy::enum_<duckdb::ExplainType>(m, \"ExplainType\")\n-\t    .value(\"STANDARD\", duckdb::ExplainType::EXPLAIN_STANDARD)\n-\t    .value(\"ANALYZE\", duckdb::ExplainType::EXPLAIN_ANALYZE)\n-\t    .export_values();\n+\tInitializeConnectionMethods(m);\n \n \tRegisterExceptions(m);\n \ndiff --git a/tools/pythonpkg/pyduckdb/udf.py b/tools/pythonpkg/pyduckdb/udf.py\nnew file mode 100644\nindex 000000000000..073db1576ee6\n--- /dev/null\n+++ b/tools/pythonpkg/pyduckdb/udf.py\n@@ -0,0 +1,24 @@\n+def vectorized(func):\n+\t\"\"\"\n+\tDecorate a function with annotated function parameters, so DuckDB can infer that the function should be provided with pyarrow arrays and should expect pyarrow array(s) as output\n+\t\"\"\"\n+\tfrom inspect import signature\n+\timport types\n+\tnew_func = types.FunctionType(\n+\t\tfunc.__code__,\n+\t\tfunc.__globals__,\n+\t\tfunc.__name__,\n+\t\tfunc.__defaults__,\n+\t\tfunc.__closure__\n+\t)\n+\t# Construct the annotations:\n+\timport pyarrow as pa\n+\n+\tnew_annotations = {}\n+\tsig = signature(func)\n+\tsig.parameters\n+\tfor param in sig.parameters:\n+\t\tnew_annotations[param] = pa.lib.ChunkedArray\n+\n+\tnew_func.__annotations__ = new_annotations\n+\treturn new_func\ndiff --git a/tools/pythonpkg/src/CMakeLists.txt b/tools/pythonpkg/src/CMakeLists.txt\nindex 09b431b88640..e41eea6ba863 100644\n--- a/tools/pythonpkg/src/CMakeLists.txt\n+++ b/tools/pythonpkg/src/CMakeLists.txt\n@@ -11,6 +11,7 @@ add_subdirectory(numpy)\n add_subdirectory(native)\n add_subdirectory(jupyter)\n add_subdirectory(typing)\n+add_subdirectory(functional)\n add_subdirectory(pyconnection)\n add_subdirectory(common)\n add_subdirectory(pandas)\n@@ -18,6 +19,7 @@ add_subdirectory(pandas)\n add_library(\n   python_src OBJECT\n   path_like.cpp\n+  python_udf.cpp\n   pyconnection.cpp\n   python_import_cache.cpp\n   pyrelation.cpp\ndiff --git a/tools/pythonpkg/src/arrow/CMakeLists.txt b/tools/pythonpkg/src/arrow/CMakeLists.txt\nindex e115f97019d1..ff9bf298c0dd 100644\n--- a/tools/pythonpkg/src/arrow/CMakeLists.txt\n+++ b/tools/pythonpkg/src/arrow/CMakeLists.txt\n@@ -3,7 +3,7 @@ include_directories(${pybind11_INCLUDE_DIR})\n include_directories(${PYTHON_INCLUDE_DIRS})\n find_package(pybind11 REQUIRED)\n \n-add_library(python_arrow OBJECT arrow_array_stream.cpp)\n+add_library(python_arrow OBJECT arrow_array_stream.cpp arrow_export_utils.cpp)\n \n set(ALL_OBJECT_FILES\n     ${ALL_OBJECT_FILES} $<TARGET_OBJECTS:python_arrow>\ndiff --git a/tools/pythonpkg/src/arrow/arrow_array_stream.cpp b/tools/pythonpkg/src/arrow/arrow_array_stream.cpp\nindex ce0ab987924b..5e074134527b 100644\n--- a/tools/pythonpkg/src/arrow/arrow_array_stream.cpp\n+++ b/tools/pythonpkg/src/arrow/arrow_array_stream.cpp\n@@ -14,6 +14,13 @@\n \n namespace duckdb {\n \n+void TransformDuckToArrowChunk(ArrowSchema &arrow_schema, ArrowArray &data, py::list &batches) {\n+\tpy::gil_assert();\n+\tauto pyarrow_lib_module = py::module::import(\"pyarrow\").attr(\"lib\");\n+\tauto batch_import_func = pyarrow_lib_module.attr(\"RecordBatch\").attr(\"_import_from_c\");\n+\tbatches.append(batch_import_func((uint64_t)&data, (uint64_t)&arrow_schema));\n+}\n+\n void VerifyArrowDatasetLoaded() {\n \tauto &import_cache = *DuckDBPyConnection::ImportCache();\n \tif (!import_cache.arrow_dataset().IsLoaded()) {\ndiff --git a/tools/pythonpkg/src/arrow/arrow_export_utils.cpp b/tools/pythonpkg/src/arrow/arrow_export_utils.cpp\nnew file mode 100644\nindex 000000000000..6f67119b2d41\n--- /dev/null\n+++ b/tools/pythonpkg/src/arrow/arrow_export_utils.cpp\n@@ -0,0 +1,37 @@\n+#include \"duckdb_python/arrow/arrow_array_stream.hpp\"\n+\n+#include \"duckdb/common/assert.hpp\"\n+#include \"duckdb/common/common.hpp\"\n+#include \"duckdb/common/limits.hpp\"\n+#include \"duckdb/main/client_config.hpp\"\n+#include \"duckdb/planner/filter/conjunction_filter.hpp\"\n+#include \"duckdb/planner/filter/constant_filter.hpp\"\n+#include \"duckdb/planner/table_filter.hpp\"\n+#include \"duckdb/common/arrow/arrow_converter.hpp\"\n+\n+#include \"duckdb_python/pyconnection/pyconnection.hpp\"\n+#include \"duckdb_python/pyrelation.hpp\"\n+#include \"duckdb_python/pyresult.hpp\"\n+\n+namespace duckdb {\n+\n+namespace pyarrow {\n+\n+py::object ToArrowTable(const vector<LogicalType> &types, const vector<string> &names, const string &timezone_config,\n+                        py::list batches) {\n+\tpy::gil_scoped_acquire acquire;\n+\n+\tauto pyarrow_lib_module = py::module::import(\"pyarrow\").attr(\"lib\");\n+\tauto from_batches_func = pyarrow_lib_module.attr(\"Table\").attr(\"from_batches\");\n+\tauto schema_import_func = pyarrow_lib_module.attr(\"Schema\").attr(\"_import_from_c\");\n+\tArrowSchema schema;\n+\n+\tArrowConverter::ToArrowSchema(&schema, types, names, timezone_config);\n+\tauto schema_obj = schema_import_func((uint64_t)&schema);\n+\n+\treturn py::cast<duckdb::pyarrow::Table>(from_batches_func(batches, schema_obj));\n+}\n+\n+} // namespace pyarrow\n+\n+} // namespace duckdb\ndiff --git a/tools/pythonpkg/src/functional/CMakeLists.txt b/tools/pythonpkg/src/functional/CMakeLists.txt\nnew file mode 100644\nindex 000000000000..72025f4a9223\n--- /dev/null\n+++ b/tools/pythonpkg/src/functional/CMakeLists.txt\n@@ -0,0 +1,10 @@\n+# this is used for clang-tidy checks\n+include_directories(${pybind11_INCLUDE_DIR})\n+include_directories(${PYTHON_INCLUDE_DIRS})\n+find_package(pybind11 REQUIRED)\n+\n+add_library(python_functional OBJECT functional.cpp)\n+\n+set(ALL_OBJECT_FILES\n+    ${ALL_OBJECT_FILES} $<TARGET_OBJECTS:python_functional>\n+    PARENT_SCOPE)\ndiff --git a/tools/pythonpkg/src/functional/functional.cpp b/tools/pythonpkg/src/functional/functional.cpp\nnew file mode 100644\nindex 000000000000..6761a2641365\n--- /dev/null\n+++ b/tools/pythonpkg/src/functional/functional.cpp\n@@ -0,0 +1,20 @@\n+#include \"duckdb_python/functional.hpp\"\n+\n+namespace duckdb {\n+\n+void DuckDBPyFunctional::Initialize(py::module_ &parent) {\n+\tauto m =\n+\t    parent.def_submodule(\"functional\", \"This module contains classes and methods related to functions and udf\");\n+\n+\tpy::enum_<duckdb::PythonUDFType>(m, \"PythonUDFType\")\n+\t    .value(\"NATIVE\", duckdb::PythonUDFType::NATIVE)\n+\t    .value(\"ARROW\", duckdb::PythonUDFType::ARROW)\n+\t    .export_values();\n+\n+\tpy::enum_<duckdb::FunctionNullHandling>(m, \"FunctionNullHandling\")\n+\t    .value(\"DEFAULT\", duckdb::FunctionNullHandling::DEFAULT_NULL_HANDLING)\n+\t    .value(\"SPECIAL\", duckdb::FunctionNullHandling::SPECIAL_HANDLING)\n+\t    .export_values();\n+}\n+\n+} // namespace duckdb\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/arrow/arrow_array_stream.hpp b/tools/pythonpkg/src/include/duckdb_python/arrow/arrow_array_stream.hpp\nindex 365bd58f6dc5..cab7e03f92ed 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/arrow/arrow_array_stream.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/arrow/arrow_array_stream.hpp\n@@ -46,10 +46,13 @@ class Table : public py::object {\n \t\treturn !py::none().is(object);\n \t}\n };\n+\n } // namespace pyarrow\n \n enum class PyArrowObjectType { Invalid, Table, RecordBatchReader, Scanner, Dataset };\n \n+void TransformDuckToArrowChunk(ArrowSchema &arrow_schema, ArrowArray &data, py::list &batches);\n+\n PyArrowObjectType GetArrowType(const py::handle &obj);\n \n class PythonTableArrowArrayStreamFactory {\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/arrow/arrow_export_utils.hpp b/tools/pythonpkg/src/include/duckdb_python/arrow/arrow_export_utils.hpp\nnew file mode 100644\nindex 000000000000..2ef03c98bd61\n--- /dev/null\n+++ b/tools/pythonpkg/src/include/duckdb_python/arrow/arrow_export_utils.hpp\n@@ -0,0 +1,14 @@\n+#pragma once\n+\n+#include \"duckdb_python/pybind11/pybind_wrapper.hpp\"\n+\n+namespace duckdb {\n+\n+namespace pyarrow {\n+\n+py::object ToArrowTable(const vector<LogicalType> &types, const vector<string> &names, const string &timezone_config,\n+                        py::list batches);\n+\n+} // namespace pyarrow\n+\n+} // namespace duckdb\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/connection_wrapper.hpp b/tools/pythonpkg/src/include/duckdb_python/connection_wrapper.hpp\nindex c7ae8af4db55..262d40bc9926 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/connection_wrapper.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/connection_wrapper.hpp\n@@ -30,6 +30,16 @@ class PyConnectionWrapper {\n \tstatic shared_ptr<DuckDBPyConnection> Execute(const string &query, py::object params = py::list(),\n \t                                              bool many = false, shared_ptr<DuckDBPyConnection> conn = nullptr);\n \n+\tstatic shared_ptr<DuckDBPyConnection>\n+\tRegisterScalarUDF(const string &name, const py::function &udf, const py::object &arguments = py::none(),\n+\t                  const shared_ptr<DuckDBPyType> &return_type = nullptr, PythonUDFType type = PythonUDFType::NATIVE,\n+\t                  FunctionNullHandling null_handling = FunctionNullHandling::DEFAULT_NULL_HANDLING,\n+\t                  PythonExceptionHandling exception_handling = PythonExceptionHandling::FORWARD_ERROR,\n+\t                  shared_ptr<DuckDBPyConnection> conn = nullptr);\n+\n+\tstatic shared_ptr<DuckDBPyConnection> UnregisterUDF(const string &name,\n+\t                                                    shared_ptr<DuckDBPyConnection> conn = nullptr);\n+\n \tstatic shared_ptr<DuckDBPyType> ArrayType(const shared_ptr<DuckDBPyType> &type,\n \t                                          shared_ptr<DuckDBPyConnection> conn = nullptr);\n \tstatic shared_ptr<DuckDBPyType> MapType(const shared_ptr<DuckDBPyType> &key, const shared_ptr<DuckDBPyType> &value,\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/conversions/optional_wrapper.hpp b/tools/pythonpkg/src/include/duckdb_python/conversions/optional_wrapper.hpp\nnew file mode 100644\nindex 000000000000..7ac0dcb01db7\n--- /dev/null\n+++ b/tools/pythonpkg/src/include/duckdb_python/conversions/optional_wrapper.hpp\n@@ -0,0 +1,35 @@\n+#pragma once\n+\n+#include \"duckdb_python/pyconnection.hpp\"\n+#include \"duckdb/common/helper.hpp\"\n+\n+using duckdb::Optional;\n+\n+namespace py = pybind11;\n+\n+namespace PYBIND11_NAMESPACE {\n+namespace detail {\n+\n+template <class T>\n+struct type_caster<Optional<T>> : public type_caster_base<Optional<T>> {\n+\tusing base = type_caster_base<Optional<T>>;\n+\tusing child = type_caster_base<T>;\n+\tOptional<T> tmp;\n+\n+public:\n+\tbool load(handle src, bool convert) {\n+\t\tif (base::load(src, convert)) {\n+\t\t\treturn true;\n+\t\t} else if (child::load(src, convert)) {\n+\t\t\treturn true;\n+\t\t}\n+\t\treturn false;\n+\t}\n+\n+\tstatic handle cast(Optional<T> src, return_value_policy policy, handle parent) {\n+\t\treturn base::cast(src, policy, parent);\n+\t}\n+};\n+\n+} // namespace detail\n+} // namespace PYBIND11_NAMESPACE\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/functional.hpp b/tools/pythonpkg/src/include/duckdb_python/functional.hpp\nnew file mode 100644\nindex 000000000000..8d7b091d561f\n--- /dev/null\n+++ b/tools/pythonpkg/src/include/duckdb_python/functional.hpp\n@@ -0,0 +1,17 @@\n+#pragma once\n+\n+#include \"duckdb_python/pybind11/pybind_wrapper.hpp\"\n+#include \"duckdb_python/pytype.hpp\"\n+#include \"duckdb_python/pyconnection/pyconnection.hpp\"\n+\n+namespace duckdb {\n+\n+class DuckDBPyFunctional {\n+public:\n+\tDuckDBPyFunctional() = delete;\n+\n+public:\n+\tstatic void Initialize(py::module_ &m);\n+};\n+\n+} // namespace duckdb\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/numpy/numpy_scan.hpp b/tools/pythonpkg/src/include/duckdb_python/numpy/numpy_scan.hpp\nindex 4661bf7051bb..5424cc15efc2 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/numpy/numpy_scan.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/numpy/numpy_scan.hpp\n@@ -9,6 +9,7 @@ struct PandasColumnBindData;\n \n struct NumpyScan {\n \tstatic void Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out);\n+\tstatic void ScanObjectColumn(PyObject **col, idx_t count, idx_t offset, Vector &out);\n };\n \n } // namespace duckdb\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/pybind11/conversions/exception_handling_enum.hpp b/tools/pythonpkg/src/include/duckdb_python/pybind11/conversions/exception_handling_enum.hpp\nnew file mode 100644\nindex 000000000000..acf407fedcaf\n--- /dev/null\n+++ b/tools/pythonpkg/src/include/duckdb_python/pybind11/conversions/exception_handling_enum.hpp\n@@ -0,0 +1,72 @@\n+#pragma once\n+\n+#include \"duckdb/common/common.hpp\"\n+#include \"duckdb/common/exception.hpp\"\n+#include \"duckdb/common/string_util.hpp\"\n+\n+using duckdb::InvalidInputException;\n+using duckdb::string;\n+using duckdb::StringUtil;\n+\n+namespace duckdb {\n+\n+enum class PythonExceptionHandling : uint8_t { FORWARD_ERROR, RETURN_NULL };\n+\n+} // namespace duckdb\n+\n+using duckdb::PythonExceptionHandling;\n+\n+namespace py = pybind11;\n+\n+static PythonExceptionHandling PythonExceptionHandlingFromString(const string &type) {\n+\tauto ltype = StringUtil::Lower(type);\n+\tif (ltype.empty() || ltype == \"default\") {\n+\t\treturn PythonExceptionHandling::FORWARD_ERROR;\n+\t} else if (ltype == \"return_null\") {\n+\t\treturn PythonExceptionHandling::RETURN_NULL;\n+\t} else {\n+\t\tthrow InvalidInputException(\"'%s' is not a recognized type for 'exception_handling'\", type);\n+\t}\n+}\n+\n+static PythonExceptionHandling PythonExceptionHandlingFromInteger(int64_t value) {\n+\tif (value == 0) {\n+\t\treturn PythonExceptionHandling::FORWARD_ERROR;\n+\t} else if (value == 1) {\n+\t\treturn PythonExceptionHandling::RETURN_NULL;\n+\t} else {\n+\t\tthrow InvalidInputException(\"'%d' is not a recognized type for 'exception_handling'\", value);\n+\t}\n+}\n+\n+namespace PYBIND11_NAMESPACE {\n+namespace detail {\n+\n+template <>\n+struct type_caster<PythonExceptionHandling> : public type_caster_base<PythonExceptionHandling> {\n+\tusing base = type_caster_base<PythonExceptionHandling>;\n+\tPythonExceptionHandling tmp;\n+\n+public:\n+\tbool load(handle src, bool convert) {\n+\t\tif (base::load(src, convert)) {\n+\t\t\treturn true;\n+\t\t} else if (py::isinstance<py::str>(src)) {\n+\t\t\ttmp = PythonExceptionHandlingFromString(py::str(src));\n+\t\t\tvalue = &tmp;\n+\t\t\treturn true;\n+\t\t} else if (py::isinstance<py::int_>(src)) {\n+\t\t\ttmp = PythonExceptionHandlingFromInteger(src.cast<int64_t>());\n+\t\t\tvalue = &tmp;\n+\t\t\treturn true;\n+\t\t}\n+\t\treturn false;\n+\t}\n+\n+\tstatic handle cast(PythonExceptionHandling src, return_value_policy policy, handle parent) {\n+\t\treturn base::cast(src, policy, parent);\n+\t}\n+};\n+\n+} // namespace detail\n+} // namespace PYBIND11_NAMESPACE\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/pybind11/conversions/null_handling_enum.hpp b/tools/pythonpkg/src/include/duckdb_python/pybind11/conversions/null_handling_enum.hpp\nnew file mode 100644\nindex 000000000000..b9bbcf908aff\n--- /dev/null\n+++ b/tools/pythonpkg/src/include/duckdb_python/pybind11/conversions/null_handling_enum.hpp\n@@ -0,0 +1,66 @@\n+#pragma once\n+\n+#include \"duckdb/function/function.hpp\"\n+#include \"duckdb/common/common.hpp\"\n+#include \"duckdb/common/exception.hpp\"\n+#include \"duckdb/common/string_util.hpp\"\n+\n+using duckdb::FunctionNullHandling;\n+using duckdb::InvalidInputException;\n+using duckdb::string;\n+using duckdb::StringUtil;\n+\n+namespace py = pybind11;\n+\n+static FunctionNullHandling FunctionNullHandlingFromString(const string &type) {\n+\tauto ltype = StringUtil::Lower(type);\n+\tif (ltype.empty() || ltype == \"default\") {\n+\t\treturn FunctionNullHandling::DEFAULT_NULL_HANDLING;\n+\t} else if (ltype == \"special\") {\n+\t\treturn FunctionNullHandling::SPECIAL_HANDLING;\n+\t} else {\n+\t\tthrow InvalidInputException(\"'%s' is not a recognized type for 'null_handling'\", type);\n+\t}\n+}\n+\n+static FunctionNullHandling FunctionNullHandlingFromInteger(int64_t value) {\n+\tif (value == 0) {\n+\t\treturn FunctionNullHandling::DEFAULT_NULL_HANDLING;\n+\t} else if (value == 1) {\n+\t\treturn FunctionNullHandling::SPECIAL_HANDLING;\n+\t} else {\n+\t\tthrow InvalidInputException(\"'%d' is not a recognized type for 'null_handling'\", value);\n+\t}\n+}\n+\n+namespace PYBIND11_NAMESPACE {\n+namespace detail {\n+\n+template <>\n+struct type_caster<FunctionNullHandling> : public type_caster_base<FunctionNullHandling> {\n+\tusing base = type_caster_base<FunctionNullHandling>;\n+\tFunctionNullHandling tmp;\n+\n+public:\n+\tbool load(handle src, bool convert) {\n+\t\tif (base::load(src, convert)) {\n+\t\t\treturn true;\n+\t\t} else if (py::isinstance<py::str>(src)) {\n+\t\t\ttmp = FunctionNullHandlingFromString(py::str(src));\n+\t\t\tvalue = &tmp;\n+\t\t\treturn true;\n+\t\t} else if (py::isinstance<py::int_>(src)) {\n+\t\t\ttmp = FunctionNullHandlingFromInteger(src.cast<int64_t>());\n+\t\t\tvalue = &tmp;\n+\t\t\treturn true;\n+\t\t}\n+\t\treturn false;\n+\t}\n+\n+\tstatic handle cast(FunctionNullHandling src, return_value_policy policy, handle parent) {\n+\t\treturn base::cast(src, policy, parent);\n+\t}\n+};\n+\n+} // namespace detail\n+} // namespace PYBIND11_NAMESPACE\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/pybind11/conversions/python_udf_type_enum.hpp b/tools/pythonpkg/src/include/duckdb_python/pybind11/conversions/python_udf_type_enum.hpp\nnew file mode 100644\nindex 000000000000..6a224090357b\n--- /dev/null\n+++ b/tools/pythonpkg/src/include/duckdb_python/pybind11/conversions/python_udf_type_enum.hpp\n@@ -0,0 +1,72 @@\n+#pragma once\n+\n+#include \"duckdb/common/common.hpp\"\n+#include \"duckdb/common/exception.hpp\"\n+#include \"duckdb/common/string_util.hpp\"\n+\n+using duckdb::InvalidInputException;\n+using duckdb::string;\n+using duckdb::StringUtil;\n+\n+namespace duckdb {\n+\n+enum class PythonUDFType : uint8_t { NATIVE, ARROW };\n+\n+} // namespace duckdb\n+\n+using duckdb::PythonUDFType;\n+\n+namespace py = pybind11;\n+\n+static PythonUDFType PythonUDFTypeFromString(const string &type) {\n+\tauto ltype = StringUtil::Lower(type);\n+\tif (ltype.empty() || ltype == \"default\" || ltype == \"native\") {\n+\t\treturn PythonUDFType::NATIVE;\n+\t} else if (ltype == \"arrow\") {\n+\t\treturn PythonUDFType::ARROW;\n+\t} else {\n+\t\tthrow InvalidInputException(\"'%s' is not a recognized type for 'udf_type'\", type);\n+\t}\n+}\n+\n+static PythonUDFType PythonUDFTypeFromInteger(int64_t value) {\n+\tif (value == 0) {\n+\t\treturn PythonUDFType::NATIVE;\n+\t} else if (value == 1) {\n+\t\treturn PythonUDFType::ARROW;\n+\t} else {\n+\t\tthrow InvalidInputException(\"'%d' is not a recognized type for 'udf_type'\", value);\n+\t}\n+}\n+\n+namespace PYBIND11_NAMESPACE {\n+namespace detail {\n+\n+template <>\n+struct type_caster<PythonUDFType> : public type_caster_base<PythonUDFType> {\n+\tusing base = type_caster_base<PythonUDFType>;\n+\tPythonUDFType tmp;\n+\n+public:\n+\tbool load(handle src, bool convert) {\n+\t\tif (base::load(src, convert)) {\n+\t\t\treturn true;\n+\t\t} else if (py::isinstance<py::str>(src)) {\n+\t\t\ttmp = PythonUDFTypeFromString(py::str(src));\n+\t\t\tvalue = &tmp;\n+\t\t\treturn true;\n+\t\t} else if (py::isinstance<py::int_>(src)) {\n+\t\t\ttmp = PythonUDFTypeFromInteger(src.cast<int64_t>());\n+\t\t\tvalue = &tmp;\n+\t\t\treturn true;\n+\t\t}\n+\t\treturn false;\n+\t}\n+\n+\tstatic handle cast(PythonUDFType src, return_value_policy policy, handle parent) {\n+\t\treturn base::cast(src, policy, parent);\n+\t}\n+};\n+\n+} // namespace detail\n+} // namespace PYBIND11_NAMESPACE\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/pybind11/pybind_wrapper.hpp b/tools/pythonpkg/src/include/duckdb_python/pybind11/pybind_wrapper.hpp\nindex 27eeb6508fd8..84739068197d 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/pybind11/pybind_wrapper.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/pybind11/pybind_wrapper.hpp\n@@ -70,6 +70,16 @@ inline bool isinstance(handle obj, handle type) {\n \treturn result != 0;\n }\n \n+template <class T>\n+bool try_cast(const handle &object, T &result) {\n+\ttry {\n+\t\tresult = cast<T>(object);\n+\t} catch (cast_error &e) {\n+\t\treturn false;\n+\t}\n+\treturn true;\n+}\n+\n } // namespace py\n \n template <class T, typename... ARGS>\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/pyconnection/pyconnection.hpp b/tools/pythonpkg/src/include/duckdb_python/pyconnection/pyconnection.hpp\nindex 56e51bc3aade..a919fa7fb85c 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/pyconnection/pyconnection.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/pyconnection/pyconnection.hpp\n@@ -19,6 +19,9 @@\n #include \"duckdb/execution/operator/persistent/csv_reader_options.hpp\"\n #include \"duckdb_python/pyfilesystem.hpp\"\n #include \"duckdb_python/pybind11/registered_py_object.hpp\"\n+#include \"duckdb/function/scalar_function.hpp\"\n+#include \"duckdb_python/pybind11/conversions/exception_handling_enum.hpp\"\n+#include \"duckdb_python/pybind11/conversions/python_udf_type_enum.hpp\"\n \n namespace duckdb {\n \n@@ -44,6 +47,7 @@ struct DuckDBPyConnection : public std::enable_shared_from_this<DuckDBPyConnecti\n \tstd::mutex py_connection_lock;\n \t//! MemoryFileSystem used to temporarily store file-like objects for reading\n \tshared_ptr<ModifiedMemoryFileSystem> internal_object_filesystem;\n+\tcase_insensitive_map_t<unique_ptr<PythonDependencies>> registered_functions;\n \n public:\n \texplicit DuckDBPyConnection() {\n@@ -90,6 +94,14 @@ struct DuckDBPyConnection : public std::enable_shared_from_this<DuckDBPyConnecti\n \tshared_ptr<DuckDBPyType> StringType(const string &collation = string());\n \tshared_ptr<DuckDBPyType> Type(const string &type_str);\n \n+\tshared_ptr<DuckDBPyConnection>\n+\tRegisterScalarUDF(const string &name, const py::function &udf, const py::object &arguments = py::none(),\n+\t                  const shared_ptr<DuckDBPyType> &return_type = nullptr, PythonUDFType type = PythonUDFType::NATIVE,\n+\t                  FunctionNullHandling null_handling = FunctionNullHandling::DEFAULT_NULL_HANDLING,\n+\t                  PythonExceptionHandling exception_handling = PythonExceptionHandling::FORWARD_ERROR);\n+\n+\tshared_ptr<DuckDBPyConnection> UnregisterUDF(const string &name);\n+\n \tshared_ptr<DuckDBPyConnection> ExecuteMany(const string &query, py::object params = py::list());\n \n \tunique_ptr<QueryResult> ExecuteInternal(const string &query, py::object params = py::list(), bool many = false);\n@@ -198,6 +210,9 @@ struct DuckDBPyConnection : public std::enable_shared_from_this<DuckDBPyConnecti\n private:\n \tPathLike GetPathLike(const py::object &object);\n \tunique_lock<std::mutex> AcquireConnectionLock();\n+\tScalarFunction CreateScalarUDF(const string &name, const py::function &udf, const py::object &parameters,\n+\t                               const shared_ptr<DuckDBPyType> &return_type, bool vectorized,\n+\t                               FunctionNullHandling null_handling, PythonExceptionHandling exception_handling);\n \tvoid RegisterArrowObject(const py::object &arrow_object, const string &name);\n \n \tstatic PythonEnvironmentType environment;\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/pyrelation.hpp b/tools/pythonpkg/src/include/duckdb_python/pyrelation.hpp\nindex fc942e2c1128..5a70b4c9aba5 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/pyrelation.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/pyrelation.hpp\n@@ -17,6 +17,7 @@\n #include \"duckdb_python/pyresult.hpp\"\n #include \"duckdb/parser/statement/explain_statement.hpp\"\n #include \"duckdb_python/pybind11/conversions/explain_enum.hpp\"\n+#include \"duckdb_python/pybind11/conversions/null_handling_enum.hpp\"\n #include \"duckdb_python/pybind11/dataframe.hpp\"\n \n namespace duckdb {\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/pyresult.hpp b/tools/pythonpkg/src/include/duckdb_python/pyresult.hpp\nindex 75edcc0071dc..c76bf24c49e5 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/pyresult.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/pyresult.hpp\n@@ -55,10 +55,10 @@ struct DuckDBPyResult {\n \tconst vector<LogicalType> &GetTypes();\n \n private:\n-\tvoid FillNumpy(py::dict &res, idx_t col_idx, NumpyResultConversion &conversion, const char *name);\n-\n \tpy::list FetchAllArrowChunks(idx_t rows_per_batch);\n \n+\tvoid FillNumpy(py::dict &res, idx_t col_idx, NumpyResultConversion &conversion, const char *name);\n+\n \tbool FetchArrowChunk(QueryResult *result, py::list &batches, idx_t rows_per_batch);\n \n \tPandasDataFrame FrameFromNumpy(bool date_as_object, const py::handle &o);\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/python_conversion.hpp b/tools/pythonpkg/src/include/duckdb_python/python_conversion.hpp\nindex 5c723cf01cc6..655e3a8f1274 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/python_conversion.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/python_conversion.hpp\n@@ -43,7 +43,7 @@ enum class PythonObjectType {\n \n PythonObjectType GetPythonObjectType(py::handle &ele);\n \n-bool TryTransformPythonNumeric(Value &res, py::handle ele);\n+bool TryTransformPythonNumeric(Value &res, py::handle ele, const LogicalType &target_type = LogicalType::UNKNOWN);\n bool DictionaryHasMapFormat(const PyDictionary &dict);\n Value TransformPythonValue(py::handle ele, const LogicalType &target_type = LogicalType::UNKNOWN,\n                            bool nan_as_null = true);\ndiff --git a/tools/pythonpkg/src/native/python_conversion.cpp b/tools/pythonpkg/src/native/python_conversion.cpp\nindex 1033ed927d33..b7408c2c80fe 100644\n--- a/tools/pythonpkg/src/native/python_conversion.cpp\n+++ b/tools/pythonpkg/src/native/python_conversion.cpp\n@@ -4,6 +4,7 @@\n #include \"duckdb_python/pyrelation.hpp\"\n #include \"duckdb_python/pyconnection/pyconnection.hpp\"\n #include \"duckdb_python/pyresult.hpp\"\n+#include \"duckdb/common/types.hpp\"\n \n #include \"datetime.h\" //From Python\n \n@@ -211,15 +212,23 @@ void TransformPythonUnsigned(uint64_t value, Value &res) {\n }\n \n // TODO: add support for HUGEINT\n-bool TryTransformPythonNumeric(Value &res, py::handle ele) {\n+bool TryTransformPythonNumeric(Value &res, py::handle ele, const LogicalType &target_type) {\n \tauto ptr = ele.ptr();\n \n \tint overflow;\n \tint64_t value = PyLong_AsLongLongAndOverflow(ptr, &overflow);\n \tif (overflow == -1) {\n \t\tPyErr_Clear();\n+\t\tif (target_type.id() == LogicalTypeId::BIGINT) {\n+\t\t\tthrow InvalidInputException(StringUtil::Format(\"Failed to cast value: Python value '%s' to INT64\",\n+\t\t\t                                               std::string(pybind11::str(ele))));\n+\t\t}\n \t\treturn TryTransformPythonIntegerToDouble(res, ele);\n \t} else if (overflow == 1) {\n+\t\tif (target_type.InternalType() == PhysicalType::INT64) {\n+\t\t\tthrow InvalidInputException(StringUtil::Format(\"Failed to cast value: Python value '%s' to INT64\",\n+\t\t\t                                               std::string(pybind11::str(ele))));\n+\t\t}\n \t\tuint64_t unsigned_value = PyLong_AsUnsignedLongLong(ptr);\n \t\tif (PyErr_Occurred()) {\n \t\t\tPyErr_Clear();\n@@ -303,7 +312,7 @@ Value TransformPythonValue(py::handle ele, const LogicalType &target_type, bool\n \t\treturn Value::BOOLEAN(ele.cast<bool>());\n \tcase PythonObjectType::Integer: {\n \t\tValue integer;\n-\t\tif (!TryTransformPythonNumeric(integer, ele)) {\n+\t\tif (!TryTransformPythonNumeric(integer, ele, target_type)) {\n \t\t\tthrow InvalidInputException(\"An error occurred attempting to convert a python integer\");\n \t\t}\n \t\treturn integer;\ndiff --git a/tools/pythonpkg/src/numpy/numpy_scan.cpp b/tools/pythonpkg/src/numpy/numpy_scan.cpp\nindex 2f05c8b3f9a8..cba8c417934f 100644\n--- a/tools/pythonpkg/src/numpy/numpy_scan.cpp\n+++ b/tools/pythonpkg/src/numpy/numpy_scan.cpp\n@@ -133,7 +133,7 @@ static void SetInvalidRecursive(Vector &out, idx_t index) {\n \n //! 'count' is the amount of rows in the 'out' vector\n //! 'offset' is the current row number within this vector\n-void ScanNumpyObject(PandasColumnBindData &bind_data, PyObject *object, idx_t offset, Vector &out) {\n+void ScanNumpyObject(PyObject *object, idx_t offset, Vector &out) {\n \n \t// handle None\n \tif (object == Py_None) {\n@@ -173,14 +173,14 @@ void VerifyTypeConstraints(Vector &vec, idx_t count) {\n \t}\n }\n \n-void ScanNumpyObjectColumn(PandasColumnBindData &bind_data, PyObject **col, idx_t count, idx_t offset, Vector &out) {\n+void NumpyScan::ScanObjectColumn(PyObject **col, idx_t count, idx_t offset, Vector &out) {\n \t// numpy_col is a sequential list of objects, that make up one \"column\" (Vector)\n \tout.SetVectorType(VectorType::FLAT_VECTOR);\n \t{\n \t\tPythonGILWrapper gil; // We're creating python objects here, so we need the GIL\n \t\tfor (idx_t i = 0; i < count; i++) {\n \t\t\tidx_t source_idx = offset + i;\n-\t\t\tScanNumpyObject(bind_data, col[source_idx], i, out);\n+\t\t\tScanNumpyObject(col[source_idx], i, out);\n \t\t}\n \t}\n \tVerifyTypeConstraints(out, count);\n@@ -274,7 +274,7 @@ void NumpyScan::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset,\n \t\t// Get the source pointer of the numpy array\n \t\tauto src_ptr = (PyObject **)array.data();\n \t\tif (out.GetType().id() != LogicalTypeId::VARCHAR) {\n-\t\t\treturn ScanNumpyObjectColumn(bind_data, src_ptr, count, offset, out);\n+\t\t\treturn NumpyScan::ScanObjectColumn(src_ptr, count, offset, out);\n \t\t}\n \n \t\t// Get the data pointer and the validity mask of the result vector\ndiff --git a/tools/pythonpkg/src/pyconnection.cpp b/tools/pythonpkg/src/pyconnection.cpp\nindex f2b0ea9cf06e..169bf1827689 100644\n--- a/tools/pythonpkg/src/pyconnection.cpp\n+++ b/tools/pythonpkg/src/pyconnection.cpp\n@@ -39,6 +39,14 @@\n #include \"duckdb/catalog/default/default_types.hpp\"\n #include \"duckdb/main/relation/value_relation.hpp\"\n #include \"duckdb_python/filesystem_object.hpp\"\n+#include \"duckdb/parser/parsed_data/create_scalar_function_info.hpp\"\n+#include \"duckdb/function/scalar_function.hpp\"\n+#include \"duckdb_python/pandas/pandas_scan.hpp\"\n+#include \"duckdb_python/python_objects.hpp\"\n+#include \"duckdb/function/function.hpp\"\n+#include \"duckdb_python/pybind11/conversions/exception_handling_enum.hpp\"\n+#include \"duckdb/parser/parsed_data/drop_info.hpp\"\n+#include \"duckdb/catalog/catalog_entry/scalar_function_catalog_entry.hpp\"\n \n #include <random>\n \n@@ -110,6 +118,15 @@ static void InitializeConnectionMethods(py::class_<DuckDBPyConnection, shared_pt\n \t    .def(\"filesystem_is_registered\", &DuckDBPyConnection::FileSystemIsRegistered,\n \t         \"Check if a filesystem with the provided name is currently registered\", py::arg(\"name\"));\n \n+\tm.def(\"create_function\", &DuckDBPyConnection::RegisterScalarUDF,\n+\t      \"Create a DuckDB function out of the passing in python function so it can be used in queries\",\n+\t      py::arg(\"name\"), py::arg(\"function\"), py::arg(\"return_type\") = py::none(), py::arg(\"parameters\") = py::none(),\n+\t      py::kw_only(), py::arg(\"type\") = PythonUDFType::NATIVE, py::arg(\"null_handling\") = 0,\n+\t      py::arg(\"exception_handling\") = 0);\n+\n+\tm.def(\"remove_function\", &DuckDBPyConnection::UnregisterUDF, \"Remove a previously created function\",\n+\t      py::arg(\"name\"));\n+\n \tDefineMethod({\"sqltype\", \"dtype\", \"type\"}, m, &DuckDBPyConnection::Type,\n \t             \"Create a type object by parsing the 'type_str' string\", py::arg(\"type_str\"));\n \tDefineMethod({\"array_type\", \"list_type\"}, m, &DuckDBPyConnection::ArrayType,\n@@ -277,6 +294,60 @@ bool DuckDBPyConnection::FileSystemIsRegistered(const string &name) {\n \treturn std::find(subsystems.begin(), subsystems.end(), name) != subsystems.end();\n }\n \n+shared_ptr<DuckDBPyConnection> DuckDBPyConnection::UnregisterUDF(const string &name) {\n+\tif (!connection) {\n+\t\tthrow ConnectionException(\"Connection already closed!\");\n+\t}\n+\tauto entry = registered_functions.find(name);\n+\tif (entry == registered_functions.end()) {\n+\t\t// Not registered or already unregistered\n+\t\tthrow InvalidInputException(\"No function by the name of '%s' was found in the list of registered functions\",\n+\t\t                            name);\n+\t}\n+\n+\tauto &context = *connection->context;\n+\n+\tcontext.RunFunctionInTransaction([&]() {\n+\t\t// create function\n+\t\tauto &catalog = Catalog::GetCatalog(context, SYSTEM_CATALOG);\n+\t\tDropInfo info;\n+\t\tinfo.type = CatalogType::SCALAR_FUNCTION_ENTRY;\n+\t\tinfo.name = name;\n+\t\tinfo.allow_drop_internal = true;\n+\t\tinfo.cascade = false;\n+\t\tinfo.if_not_found = OnEntryNotFound::THROW_EXCEPTION;\n+\t\tcatalog.DropEntry(context, info);\n+\t});\n+\tregistered_functions.erase(entry);\n+\n+\treturn shared_from_this();\n+}\n+\n+shared_ptr<DuckDBPyConnection>\n+DuckDBPyConnection::RegisterScalarUDF(const string &name, const py::function &udf, const py::object &parameters_p,\n+                                      const shared_ptr<DuckDBPyType> &return_type_p, PythonUDFType type,\n+                                      FunctionNullHandling null_handling, PythonExceptionHandling exception_handling) {\n+\tif (!connection) {\n+\t\tthrow ConnectionException(\"Connection already closed!\");\n+\t}\n+\tauto &context = *connection->context;\n+\n+\tif (registered_functions.find(name) != registered_functions.end()) {\n+\t\tthrow NotImplementedException(\"A function by the name of '%s' is already created, creating multiple \"\n+\t\t                              \"functions with the same name is not supported yet, please remove it first\",\n+\t\t                              name);\n+\t}\n+\tauto scalar_function = CreateScalarUDF(name, udf, parameters_p, return_type_p, type == PythonUDFType::ARROW,\n+\t                                       null_handling, exception_handling);\n+\tCreateScalarFunctionInfo info(scalar_function);\n+\n+\tcontext.RegisterFunction(info);\n+\n+\tregistered_functions[name] = make_uniq<PythonDependencies>(udf);\n+\n+\treturn shared_from_this();\n+}\n+\n void DuckDBPyConnection::Initialize(py::handle &m) {\n \tauto connection_module =\n \t    py::class_<DuckDBPyConnection, shared_ptr<DuckDBPyConnection>>(m, \"DuckDBPyConnection\", py::module_local());\ndiff --git a/tools/pythonpkg/src/pyconnection/type_creation.cpp b/tools/pythonpkg/src/pyconnection/type_creation.cpp\nindex 75a56c705f20..f1f95c8484d4 100644\n--- a/tools/pythonpkg/src/pyconnection/type_creation.cpp\n+++ b/tools/pythonpkg/src/pyconnection/type_creation.cpp\n@@ -19,11 +19,11 @@ static child_list_t<LogicalType> GetChildList(const py::object &container) {\n \t\tconst py::list &fields = container;\n \t\tidx_t i = 1;\n \t\tfor (auto &item : fields) {\n-\t\t\tif (!py::isinstance<DuckDBPyType>(item)) {\n+\t\t\tshared_ptr<DuckDBPyType> pytype;\n+\t\t\tif (!py::try_cast<shared_ptr<DuckDBPyType>>(item, pytype)) {\n \t\t\t\tstring actual_type = py::str(item.get_type());\n \t\t\t\tthrow InvalidInputException(\"object has to be a list of DuckDBPyType's, not '%s'\", actual_type);\n \t\t\t}\n-\t\t\tauto *pytype = item.cast<DuckDBPyType *>();\n \t\t\ttypes.push_back(std::make_pair(StringUtil::Format(\"v%d\", i++), pytype->Type()));\n \t\t}\n \t\treturn types;\n@@ -33,12 +33,12 @@ static child_list_t<LogicalType> GetChildList(const py::object &container) {\n \t\t\tauto &name_p = item.first;\n \t\t\tauto &type_p = item.second;\n \t\t\tstring name = py::str(name_p);\n-\t\t\tif (!py::isinstance<DuckDBPyType>(type_p)) {\n+\t\t\tshared_ptr<DuckDBPyType> pytype;\n+\t\t\tif (!py::try_cast<shared_ptr<DuckDBPyType>>(type_p, pytype)) {\n \t\t\t\tstring actual_type = py::str(type_p.get_type());\n \t\t\t\tthrow InvalidInputException(\"object has to be a list of DuckDBPyType's, not '%s'\", actual_type);\n \t\t\t}\n-\t\t\tauto *type = type_p.cast<DuckDBPyType *>();\n-\t\t\ttypes.push_back(std::make_pair(name, type->Type()));\n+\t\t\ttypes.push_back(std::make_pair(name, pytype->Type()));\n \t\t}\n \t\treturn types;\n \t} else {\n@@ -49,7 +49,6 @@ static child_list_t<LogicalType> GetChildList(const py::object &container) {\n }\n \n shared_ptr<DuckDBPyType> DuckDBPyConnection::StructType(const py::object &fields) {\n-\tbool is_list = py::isinstance<py::list>(fields);\n \tchild_list_t<LogicalType> types = GetChildList(fields);\n \tif (types.empty()) {\n \t\tthrow InvalidInputException(\"Can not create an empty struct type!\");\ndiff --git a/tools/pythonpkg/src/pyduckdb/connection_wrapper.cpp b/tools/pythonpkg/src/pyduckdb/connection_wrapper.cpp\nindex 87604b48bb85..fe2ad5a6ac9f 100644\n--- a/tools/pythonpkg/src/pyduckdb/connection_wrapper.cpp\n+++ b/tools/pythonpkg/src/pyduckdb/connection_wrapper.cpp\n@@ -97,6 +97,19 @@ shared_ptr<DuckDBPyConnection> PyConnectionWrapper::Execute(const string &query,\n \treturn conn->Execute(query, params, many);\n }\n \n+shared_ptr<DuckDBPyConnection> PyConnectionWrapper::UnregisterUDF(const string &name,\n+                                                                  shared_ptr<DuckDBPyConnection> conn) {\n+\treturn conn->UnregisterUDF(name);\n+}\n+\n+shared_ptr<DuckDBPyConnection>\n+PyConnectionWrapper::RegisterScalarUDF(const string &name, const py::function &udf, const py::object &parameters_p,\n+                                       const shared_ptr<DuckDBPyType> &return_type_p, PythonUDFType type,\n+                                       FunctionNullHandling null_handling, PythonExceptionHandling exception_handling,\n+                                       shared_ptr<DuckDBPyConnection> conn) {\n+\treturn conn->RegisterScalarUDF(name, udf, parameters_p, return_type_p, type, null_handling, exception_handling);\n+}\n+\n shared_ptr<DuckDBPyConnection> PyConnectionWrapper::Append(const string &name, PandasDataFrame value, bool by_name,\n                                                            shared_ptr<DuckDBPyConnection> conn) {\n \treturn conn->Append(name, value, by_name);\ndiff --git a/tools/pythonpkg/src/pyresult.cpp b/tools/pythonpkg/src/pyresult.cpp\nindex 2a3bb65291b7..1f7adf2c82be 100644\n--- a/tools/pythonpkg/src/pyresult.cpp\n+++ b/tools/pythonpkg/src/pyresult.cpp\n@@ -3,6 +3,7 @@\n #include \"duckdb_python/pyresult.hpp\"\n #include \"duckdb_python/python_objects.hpp\"\n \n+#include \"duckdb_python/arrow/arrow_array_stream.hpp\"\n #include \"duckdb/common/arrow/arrow.hpp\"\n #include \"duckdb/common/arrow/arrow_converter.hpp\"\n #include \"duckdb/common/arrow/arrow_wrapper.hpp\"\n@@ -14,6 +15,7 @@\n #include \"duckdb/common/types/uuid.hpp\"\n #include \"duckdb_python/numpy/array_wrapper.hpp\"\n #include \"duckdb/common/exception.hpp\"\n+#include \"duckdb_python/arrow/arrow_export_utils.hpp\"\n \n namespace duckdb {\n \n@@ -283,12 +285,6 @@ py::dict DuckDBPyResult::FetchTF() {\n \treturn result_dict;\n }\n \n-void TransformDuckToArrowChunk(ArrowSchema &arrow_schema, ArrowArray &data, py::list &batches) {\n-\tauto pyarrow_lib_module = py::module::import(\"pyarrow\").attr(\"lib\");\n-\tauto batch_import_func = pyarrow_lib_module.attr(\"RecordBatch\").attr(\"_import_from_c\");\n-\tbatches.append(batch_import_func((uint64_t)&data, (uint64_t)&arrow_schema));\n-}\n-\n bool DuckDBPyResult::FetchArrowChunk(QueryResult *result, py::list &batches, idx_t rows_per_batch) {\n \tArrowArray data;\n \tidx_t count;\n@@ -323,23 +319,9 @@ duckdb::pyarrow::Table DuckDBPyResult::FetchArrowTable(idx_t rows_per_batch) {\n \tif (!result) {\n \t\tthrow InvalidInputException(\"There is no query result\");\n \t}\n-\tpy::gil_scoped_acquire acquire;\n-\n-\tauto pyarrow_lib_module = py::module::import(\"pyarrow\").attr(\"lib\");\n-\tauto from_batches_func = pyarrow_lib_module.attr(\"Table\").attr(\"from_batches\");\n-\n-\tauto schema_import_func = pyarrow_lib_module.attr(\"Schema\").attr(\"_import_from_c\");\n-\tArrowSchema schema;\n-\n \ttimezone_config = QueryResult::GetConfigTimezone(*result);\n-\tArrowConverter::ToArrowSchema(&schema, result->types, result->names, timezone_config);\n-\n-\tauto schema_obj = schema_import_func((uint64_t)&schema);\n-\n-\tpy::list batches = FetchAllArrowChunks(rows_per_batch);\n \n-\t// We return an Arrow Table\n-\treturn py::cast<duckdb::pyarrow::Table>(from_batches_func(batches, schema_obj));\n+\treturn pyarrow::ToArrowTable(result->types, result->names, timezone_config, FetchAllArrowChunks(rows_per_batch));\n }\n \n duckdb::pyarrow::RecordBatchReader DuckDBPyResult::FetchRecordBatchReader(idx_t rows_per_batch) {\ndiff --git a/tools/pythonpkg/src/python_udf.cpp b/tools/pythonpkg/src/python_udf.cpp\nnew file mode 100644\nindex 000000000000..b0893837cf85\n--- /dev/null\n+++ b/tools/pythonpkg/src/python_udf.cpp\n@@ -0,0 +1,345 @@\n+#include \"duckdb/main/query_result.hpp\"\n+#include \"duckdb_python/pybind11/pybind_wrapper.hpp\"\n+#include \"duckdb/function/scalar_function.hpp\"\n+#include \"duckdb_python/pytype.hpp\"\n+#include \"duckdb_python/pyconnection/pyconnection.hpp\"\n+#include \"duckdb_python/pandas/pandas_scan.hpp\"\n+#include \"duckdb/common/arrow/arrow.hpp\"\n+#include \"duckdb/common/arrow/arrow_converter.hpp\"\n+#include \"duckdb/common/arrow/arrow_wrapper.hpp\"\n+#include \"duckdb/common/arrow/arrow_appender.hpp\"\n+#include \"duckdb/common/arrow/result_arrow_wrapper.hpp\"\n+#include \"duckdb_python/arrow/arrow_array_stream.hpp\"\n+#include \"duckdb/function/table/arrow.hpp\"\n+#include \"duckdb/function/function.hpp\"\n+#include \"duckdb_python/numpy/numpy_scan.hpp\"\n+#include \"duckdb_python/arrow/arrow_export_utils.hpp\"\n+#include \"duckdb/common/types/arrow_aux_data.hpp\"\n+\n+namespace duckdb {\n+\n+static py::list ConvertToSingleBatch(const string &timezone_config, vector<LogicalType> &types, vector<string> &names,\n+                                     DataChunk &input) {\n+\tArrowSchema schema;\n+\tArrowConverter::ToArrowSchema(&schema, types, names, timezone_config);\n+\n+\tpy::list single_batch;\n+\tArrowAppender appender(types, STANDARD_VECTOR_SIZE);\n+\tappender.Append(input, 0, input.size(), input.size());\n+\tauto array = appender.Finalize();\n+\tTransformDuckToArrowChunk(schema, array, single_batch);\n+\treturn single_batch;\n+}\n+\n+static py::object ConvertDataChunkToPyArrowTable(DataChunk &input, const string &timezone_config) {\n+\tauto types = input.GetTypes();\n+\tvector<string> names;\n+\tnames.reserve(types.size());\n+\tfor (idx_t i = 0; i < types.size(); i++) {\n+\t\tnames.push_back(StringUtil::Format(\"c%d\", i));\n+\t}\n+\n+\treturn pyarrow::ToArrowTable(types, names, timezone_config,\n+\t                             ConvertToSingleBatch(timezone_config, types, names, input));\n+}\n+\n+static void ConvertPyArrowToDataChunk(const py::object &table, Vector &out, ClientContext &context, idx_t count) {\n+\n+\t// Create the stream factory from the Table object\n+\tauto stream_factory = make_uniq<PythonTableArrowArrayStreamFactory>(table.ptr(), context.config);\n+\tauto stream_factory_produce = PythonTableArrowArrayStreamFactory::Produce;\n+\tauto stream_factory_get_schema = PythonTableArrowArrayStreamFactory::GetSchema;\n+\n+\t// Get the functions we need\n+\tauto function = ArrowTableFunction::ArrowScanFunction;\n+\tauto bind = ArrowTableFunction::ArrowScanBind;\n+\tauto init_global = ArrowTableFunction::ArrowScanInitGlobal;\n+\tauto init_local = ArrowTableFunction::ArrowScanInitLocalInternal;\n+\n+\t// Prepare the inputs for the bind\n+\tvector<Value> children;\n+\tchildren.reserve(3);\n+\tchildren.push_back(Value::POINTER((uintptr_t)stream_factory.get()));\n+\tchildren.push_back(Value::POINTER((uintptr_t)stream_factory_produce));\n+\tchildren.push_back(Value::POINTER((uintptr_t)stream_factory_get_schema));\n+\tnamed_parameter_map_t named_params;\n+\tvector<LogicalType> input_types;\n+\tvector<string> input_names;\n+\n+\tauto bind_input = TableFunctionBindInput(children, named_params, input_types, input_names, nullptr);\n+\tvector<LogicalType> return_types;\n+\tvector<string> return_names;\n+\n+\tauto bind_data = bind(context, bind_input, return_types, return_names);\n+\n+\tif (return_types.size() != 1) {\n+\t\tthrow InvalidInputException(\n+\t\t    \"The returned table from a pyarrow scalar udf should only contain one column, found %d\",\n+\t\t    return_types.size());\n+\t}\n+\t// if (return_types[0] != out.GetType()) {\n+\t//\tthrow InvalidInputException(\"The type of the returned array (%s) does not match the expected type: '%s'\", )\n+\t//}\n+\n+\tDataChunk result;\n+\t// Reserve for STANDARD_VECTOR_SIZE instead of count, in case the returned table contains too many tuples\n+\tresult.Initialize(context, return_types, STANDARD_VECTOR_SIZE);\n+\n+\tvector<column_t> column_ids = {0};\n+\tTableFunctionInitInput input(bind_data.get(), column_ids, vector<idx_t>(), nullptr);\n+\tauto global_state = init_global(context, input);\n+\tauto local_state = init_local(context, input, global_state.get());\n+\n+\tTableFunctionInput function_input(bind_data.get(), local_state.get(), global_state.get());\n+\tfunction(context, function_input, result);\n+\tif (result.size() != count) {\n+\t\tthrow InvalidInputException(\"Returned pyarrow table should have %d tuples, found %d\", count, result.size());\n+\t}\n+\n+\tVectorOperations::Cast(context, result.data[0], out, count);\n+}\n+\n+static scalar_function_t CreateVectorizedFunction(PyObject *function, PythonExceptionHandling exception_handling) {\n+\t// Through the capture of the lambda, we have access to the function pointer\n+\t// We just need to make sure that it doesn't get garbage collected\n+\tscalar_function_t func = [=](DataChunk &input, ExpressionState &state, Vector &result) -> void {\n+\t\tpy::gil_scoped_acquire gil;\n+\n+\t\t// owning references\n+\t\tpy::object python_object;\n+\t\t// Convert the input datachunk to pyarrow\n+\t\tstring timezone_config = \"UTC\";\n+\t\tif (state.HasContext()) {\n+\t\t\tauto &context = state.GetContext();\n+\t\t\tauto client_properties = context.GetClientProperties();\n+\t\t\ttimezone_config = client_properties.time_zone;\n+\t\t}\n+\t\tauto pyarrow_table = ConvertDataChunkToPyArrowTable(input, timezone_config);\n+\t\tpy::tuple column_list = pyarrow_table.attr(\"columns\");\n+\n+\t\tauto count = input.size();\n+\n+\t\t// Call the function\n+\t\tPyObject *ret = nullptr;\n+\t\tret = PyObject_CallObject(function, column_list.ptr());\n+\t\tif (ret == nullptr && PyErr_Occurred()) {\n+\t\t\tif (exception_handling == PythonExceptionHandling::FORWARD_ERROR) {\n+\t\t\t\tauto exception = py::error_already_set();\n+\t\t\t\tthrow InvalidInputException(\"Python exception occurred while executing the UDF: %s\", exception.what());\n+\t\t\t} else if (exception_handling == PythonExceptionHandling::RETURN_NULL) {\n+\t\t\t\tPyErr_Clear();\n+\t\t\t\tpython_object = py::module_::import(\"pyarrow\").attr(\"nulls\")(count);\n+\t\t\t} else {\n+\t\t\t\tthrow NotImplementedException(\"Exception handling type not implemented\");\n+\t\t\t}\n+\t\t} else {\n+\t\t\tpython_object = py::reinterpret_steal<py::object>(ret);\n+\t\t}\n+\t\tif (!py::isinstance(python_object, py::module_::import(\"pyarrow\").attr(\"lib\").attr(\"Table\"))) {\n+\t\t\t// Try to convert into a table\n+\t\t\tpy::list single_array(1);\n+\t\t\tpy::list single_name(1);\n+\n+\t\t\tsingle_array[0] = python_object;\n+\t\t\tsingle_name[0] = \"c0\";\n+\t\t\tpython_object = py::module_::import(\"pyarrow\").attr(\"lib\").attr(\"Table\").attr(\"from_arrays\")(\n+\t\t\t    single_array, py::arg(\"names\") = single_name);\n+\t\t}\n+\t\t// Convert the pyarrow result back to a DuckDB datachunk\n+\t\tConvertPyArrowToDataChunk(python_object, result, state.GetContext(), count);\n+\n+\t\tif (input.AllConstant()) {\n+\t\t\tresult.SetVectorType(VectorType::CONSTANT_VECTOR);\n+\t\t}\n+\t};\n+\treturn func;\n+}\n+\n+static scalar_function_t CreateNativeFunction(PyObject *function, PythonExceptionHandling exception_handling) {\n+\t// Through the capture of the lambda, we have access to the function pointer\n+\t// We just need to make sure that it doesn't get garbage collected\n+\tscalar_function_t func = [=](DataChunk &input, ExpressionState &state, Vector &result) -> void {\n+\t\tpy::gil_scoped_acquire gil;\n+\n+\t\t// owning references\n+\t\tvector<py::handle> python_objects;\n+\t\tvector<PyObject *> python_results;\n+\t\tpython_results.reserve(input.size());\n+\t\tfor (idx_t row = 0; row < input.size(); row++) {\n+\n+\t\t\tauto bundled_parameters = py::tuple((int)input.ColumnCount());\n+\t\t\tfor (idx_t i = 0; i < input.ColumnCount(); i++) {\n+\t\t\t\t// Fill the tuple with the arguments for this row\n+\t\t\t\tauto &column = input.data[i];\n+\t\t\t\tauto value = column.GetValue(row);\n+\t\t\t\tbundled_parameters[i] = PythonObject::FromValue(value, column.GetType());\n+\t\t\t}\n+\n+\t\t\t// Call the function\n+\t\t\tPyObject *ret = nullptr;\n+\t\t\tret = PyObject_CallObject(function, bundled_parameters.ptr());\n+\t\t\tif (ret == nullptr && PyErr_Occurred()) {\n+\t\t\t\tif (exception_handling == PythonExceptionHandling::FORWARD_ERROR) {\n+\t\t\t\t\tauto exception = py::error_already_set();\n+\t\t\t\t\tthrow InvalidInputException(\"Python exception occurred while executing the UDF: %s\",\n+\t\t\t\t\t                            exception.what());\n+\t\t\t\t} else if (exception_handling == PythonExceptionHandling::RETURN_NULL) {\n+\t\t\t\t\tPyErr_Clear();\n+\t\t\t\t\tret = Py_None;\n+\t\t\t\t} else {\n+\t\t\t\t\tthrow NotImplementedException(\"Exception handling type not implemented\");\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\tpython_objects.push_back(py::handle(ret));\n+\t\t\tpython_results.push_back(ret);\n+\t\t}\n+\n+\t\t// Cast the resulting native python to DuckDB, using the return type\n+\t\t// result.Resize(input.size());\n+\t\tNumpyScan::ScanObjectColumn(python_results.data(), input.size(), 0, result);\n+\t\tif (input.AllConstant()) {\n+\t\t\tresult.SetVectorType(VectorType::CONSTANT_VECTOR);\n+\t\t}\n+\t};\n+\treturn func;\n+}\n+\n+namespace {\n+\n+struct ParameterKind {\n+\tenum class Type : uint8_t { POSITIONAL_ONLY, POSITIONAL_OR_KEYWORD, VAR_POSITIONAL, KEYWORD_ONLY, VAR_KEYWORD };\n+\tstatic ParameterKind::Type FromString(const string &type_str) {\n+\t\tif (type_str == \"POSITIONAL_ONLY\") {\n+\t\t\treturn Type::POSITIONAL_ONLY;\n+\t\t} else if (type_str == \"POSITIONAL_OR_KEYWORD\") {\n+\t\t\treturn Type::POSITIONAL_OR_KEYWORD;\n+\t\t} else if (type_str == \"VAR_POSITIONAL\") {\n+\t\t\treturn Type::VAR_POSITIONAL;\n+\t\t} else if (type_str == \"KEYWORD_ONLY\") {\n+\t\t\treturn Type::KEYWORD_ONLY;\n+\t\t} else if (type_str == \"VAR_KEYWORD\") {\n+\t\t\treturn Type::VAR_KEYWORD;\n+\t\t} else {\n+\t\t\tthrow NotImplementedException(\"ParameterKindType not implemented for '%s'\", type_str);\n+\t\t}\n+\t}\n+};\n+\n+struct PythonUDFData {\n+public:\n+\tPythonUDFData(const string &name, bool vectorized, FunctionNullHandling null_handling)\n+\t    : name(name), null_handling(null_handling), vectorized(vectorized) {\n+\t\treturn_type = LogicalType::INVALID;\n+\t\tparam_count = DConstants::INVALID_INDEX;\n+\t}\n+\n+public:\n+\tstring name;\n+\tvector<LogicalType> parameters;\n+\tLogicalType return_type;\n+\tLogicalType varargs = LogicalTypeId::INVALID;\n+\tFunctionNullHandling null_handling;\n+\tidx_t param_count;\n+\tbool vectorized;\n+\n+public:\n+\tvoid Verify() {\n+\t\tif (return_type == LogicalType::INVALID) {\n+\t\t\tthrow InvalidInputException(\"Could not infer the return type, please set it explicitly\");\n+\t\t}\n+\t}\n+\n+\tvoid OverrideReturnType(const shared_ptr<DuckDBPyType> &type) {\n+\t\tif (!type) {\n+\t\t\treturn;\n+\t\t}\n+\t\treturn_type = type->Type();\n+\t}\n+\n+\tvoid OverrideParameters(const py::object &parameters_p) {\n+\t\tif (py::none().is(parameters_p)) {\n+\t\t\treturn;\n+\t\t}\n+\t\tif (!py::isinstance<py::list>(parameters_p)) {\n+\t\t\tthrow InvalidInputException(\"Either leave 'parameters' empty, or provide a list of DuckDBPyType objects\");\n+\t\t}\n+\n+\t\tauto params = py::list(parameters_p);\n+\t\tif (params.size() != param_count) {\n+\t\t\tthrow InvalidInputException(\"%d types provided, but the provided function takes %d parameters\",\n+\t\t\t                            params.size(), param_count);\n+\t\t}\n+\t\tD_ASSERT(parameters.empty() || parameters.size() == param_count);\n+\t\tif (parameters.empty()) {\n+\t\t\tfor (idx_t i = 0; i < param_count; i++) {\n+\t\t\t\tparameters.push_back(LogicalType::ANY);\n+\t\t\t}\n+\t\t}\n+\t\tidx_t i = 0;\n+\t\tfor (auto &param : params) {\n+\t\t\tauto type = py::cast<shared_ptr<DuckDBPyType>>(param);\n+\t\t\tparameters[i++] = type->Type();\n+\t\t}\n+\t}\n+\n+\tvoid AnalyzeSignature(const py::object &udf) {\n+\t\tauto signature_func = py::module_::import(\"inspect\").attr(\"signature\");\n+\t\tauto signature = signature_func(udf);\n+\t\tauto sig_params = signature.attr(\"parameters\");\n+\t\tauto return_annotation = signature.attr(\"return_annotation\");\n+\t\tif (!py::none().is(return_annotation)) {\n+\t\t\tshared_ptr<DuckDBPyType> pytype;\n+\t\t\tif (py::try_cast<shared_ptr<DuckDBPyType>>(return_annotation, pytype)) {\n+\t\t\t\treturn_type = pytype->Type();\n+\t\t\t}\n+\t\t}\n+\t\tparam_count = py::len(sig_params);\n+\t\tparameters.reserve(param_count);\n+\t\tauto params = py::dict(sig_params);\n+\t\tfor (auto &item : params) {\n+\t\t\tauto &value = item.second;\n+\t\t\tshared_ptr<DuckDBPyType> pytype;\n+\t\t\tif (py::try_cast<shared_ptr<DuckDBPyType>>(value.attr(\"annotation\"), pytype)) {\n+\t\t\t\tparameters.push_back(pytype->Type());\n+\t\t\t} else {\n+\t\t\t\tstd::string kind = py::str(value.attr(\"kind\"));\n+\t\t\t\tauto parameter_kind = ParameterKind::FromString(kind);\n+\t\t\t\tif (parameter_kind == ParameterKind::Type::VAR_POSITIONAL) {\n+\t\t\t\t\tvarargs = LogicalType::ANY;\n+\t\t\t\t}\n+\t\t\t\tparameters.push_back(LogicalType::ANY);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tScalarFunction GetFunction(const py::function &udf, PythonExceptionHandling exception_handling) {\n+\t\tscalar_function_t func;\n+\t\tif (vectorized) {\n+\t\t\tfunc = CreateVectorizedFunction(udf.ptr(), exception_handling);\n+\t\t} else {\n+\t\t\tfunc = CreateNativeFunction(udf.ptr(), exception_handling);\n+\t\t}\n+\t\tScalarFunction scalar_function(name, std::move(parameters), return_type, func, nullptr, nullptr, nullptr,\n+\t\t                               nullptr, varargs, FunctionSideEffects::NO_SIDE_EFFECTS, null_handling);\n+\t\treturn scalar_function;\n+\t}\n+};\n+\n+} // namespace\n+\n+ScalarFunction DuckDBPyConnection::CreateScalarUDF(const string &name, const py::function &udf,\n+                                                   const py::object &parameters,\n+                                                   const shared_ptr<DuckDBPyType> &return_type, bool vectorized,\n+                                                   FunctionNullHandling null_handling,\n+                                                   PythonExceptionHandling exception_handling) {\n+\tPythonUDFData data(name, vectorized, null_handling);\n+\n+\tdata.AnalyzeSignature(udf);\n+\tdata.OverrideParameters(parameters);\n+\tdata.OverrideReturnType(return_type);\n+\tdata.Verify();\n+\n+\treturn data.GetFunction(udf, exception_handling);\n+}\n+\n+} // namespace duckdb\ndiff --git a/tools/pythonpkg/src/typing/pytype.cpp b/tools/pythonpkg/src/typing/pytype.cpp\nindex fbab04d93059..19a16f263160 100644\n--- a/tools/pythonpkg/src/typing/pytype.cpp\n+++ b/tools/pythonpkg/src/typing/pytype.cpp\n@@ -76,7 +76,8 @@ enum class PythonTypeObject : uint8_t {\n \tBASE,      // 'builtin' type objects\n \tUNION,     // typing.UnionType\n \tCOMPOSITE, // list|dict types\n-\tSTRUCT     // dictionary\n+\tSTRUCT,    // dictionary\n+\tSTRING,    // string value\n };\n }\n \n@@ -84,6 +85,9 @@ static PythonTypeObject GetTypeObjectType(const py::handle &type_object) {\n \tif (py::isinstance<py::type>(type_object)) {\n \t\treturn PythonTypeObject::BASE;\n \t}\n+\tif (py::isinstance<py::str>(type_object)) {\n+\t\treturn PythonTypeObject::STRING;\n+\t}\n \tif (py::isinstance<PyGenericAlias>(type_object)) {\n \t\treturn PythonTypeObject::COMPOSITE;\n \t}\n@@ -249,6 +253,10 @@ static LogicalType FromObject(const py::object &object) {\n \tcase PythonTypeObject::UNION: {\n \t\treturn FromUnionType(object);\n \t}\n+\tcase PythonTypeObject::STRING: {\n+\t\tauto string_value = std::string(py::str(object));\n+\t\treturn FromString(string_value, nullptr);\n+\t}\n \tdefault: {\n \t\tstring actual_type = py::str(object.get_type());\n \t\tthrow NotImplementedException(\"Could not convert from object of type '%s' to DuckDBPyType\", actual_type);\n",
  "test_patch": "diff --git a/tools/pythonpkg/tests/fast/udf/test_remove_function.py b/tools/pythonpkg/tests/fast/udf/test_remove_function.py\nnew file mode 100644\nindex 000000000000..049d29648045\n--- /dev/null\n+++ b/tools/pythonpkg/tests/fast/udf/test_remove_function.py\n@@ -0,0 +1,103 @@\n+import duckdb\n+import os\n+import pytest\n+pd = pytest.importorskip(\"pandas\")\n+pa = pytest.importorskip(\"pyarrow\")\n+from typing import Union\n+import pyarrow.compute as pc\n+import uuid\n+import datetime\n+import numpy as np\n+import cmath\n+\n+from duckdb.typing import *\n+\n+class TestRemoveFunction(object):\n+    def test_not_created(self):\n+        con = duckdb.connect()\n+        with pytest.raises(duckdb.InvalidInputException, match=\"No function by the name of 'not_a_registered_function' was found in the list of registered functions\"):\n+            con.remove_function('not_a_registered_function')\n+\n+    def test_double_remove(self):\n+        def func(x: int) -> int:\n+            return x\n+\n+        con = duckdb.connect()\n+        con.create_function('func', func)\n+        con.sql('select func(42)')\n+        con.remove_function('func')\n+        with pytest.raises(duckdb.InvalidInputException, match=\"No function by the name of 'func' was found in the list of registered functions\"):\n+            con.remove_function('func')\n+        \n+        with pytest.raises(duckdb.CatalogException, match='Scalar Function with name func does not exist!'):\n+            con.sql('select func(42)')\n+\n+    def test_use_after_remove(self):\n+        def func(x: int) -> int:\n+            return x\n+\n+        con = duckdb.connect()\n+        con.create_function('func', func)\n+        rel = con.sql('select func(42)')\n+        con.remove_function('func')\n+        \"\"\"\n+            Error: Catalog Error: Scalar Function with name func does not exist!\n+        \"\"\"\n+        with pytest.raises(duckdb.InvalidInputException, match='Attempting to execute an unsuccessful or closed pending query result'):\n+            res = rel.fetchall()\n+\n+    def test_use_after_remove_and_recreation(self):\n+        def func(x: str) -> str:\n+            return x\n+\n+        con = duckdb.connect()\n+        con.create_function('func', func)\n+        rel1 = con.sql('select func(42)')\n+        rel2 = con.sql(\"select func('test')\")\n+        con.remove_function('func')\n+\n+        def also_func(x: int) -> int:\n+            return x\n+        con.create_function('func', also_func)\n+        res = rel1.fetchall()\n+        assert res[0][0] == 42\n+        \"\"\"\n+            Error: Binder Error: No function matches the given name and argument types 'func(VARCHAR)'. You might need to add explicit type casts.\n+                Candidate functions:\n+                func(BIGINT) -> BIGINT\n+        \"\"\"\n+        with pytest.raises(duckdb.InvalidInputException, match='Attempting to execute an unsuccessful or closed pending query result'):\n+            res = rel2.fetchall()\n+\n+    def test_overwrite_name(self):\n+        def func(x):\n+            return x\n+        con = duckdb.connect()\n+        # create first version of the function\n+        con.create_function('func', func, [BIGINT], BIGINT)\n+\n+        # create relation that uses the function\n+        rel1 = con.sql('select func(3)')\n+\n+        def other_func(x):\n+            return x\n+\n+        with pytest.raises(duckdb.NotImplementedException, match=\"A function by the name of 'func' is already created, creating multiple functions with the same name is not supported yet, please remove it first\"):\n+            con.create_function('func', other_func, [VARCHAR], VARCHAR)\n+\n+        con.remove_function('func')\n+\n+        with pytest.raises(duckdb.InvalidInputException, match='Catalog Error: Scalar Function with name func does not exist!'):\n+            # Attempted to execute the relation using the 'func' function, but it was deleted\n+            rel1.fetchall()\n+\n+        con.create_function('func', other_func, [VARCHAR], VARCHAR)\n+        # create relation that uses the new version\n+        rel2 = con.sql(\"select func('test')\")\n+\n+        # execute both relations\n+        res1 = rel1.fetchall()\n+        res2 = rel2.fetchall()\n+        # This has been converted to string, because the previous version of the function no longer exists\n+        assert res1 == [('3',)]\n+        assert res2 == [('test',)]\ndiff --git a/tools/pythonpkg/tests/fast/udf/test_scalar.py b/tools/pythonpkg/tests/fast/udf/test_scalar.py\nnew file mode 100644\nindex 000000000000..504ecca9ab62\n--- /dev/null\n+++ b/tools/pythonpkg/tests/fast/udf/test_scalar.py\n@@ -0,0 +1,270 @@\n+import duckdb\n+import os\n+import pytest\n+pd = pytest.importorskip(\"pandas\")\n+pa = pytest.importorskip(\"pyarrow\")\n+from typing import Union\n+import pyarrow.compute as pc\n+import uuid\n+import datetime\n+import numpy as np\n+import cmath\n+\n+from duckdb.typing import *\n+\n+def make_annotated_function(type):\n+    # Create a function that returns its input\n+    def test_base(x):\n+        return x\n+\n+    import types\n+    test_function = types.FunctionType(\n+        test_base.__code__,\n+        test_base.__globals__,\n+        test_base.__name__,\n+        test_base.__defaults__,\n+        test_base.__closure__\n+    )\n+    # Add annotations for the return type and 'x'\n+    test_function.__annotations__ = {\n+        'return': type,\n+        'x': type\n+    }\n+    return test_function\n+\n+class TestScalarUDF(object):\n+    @pytest.mark.parametrize('function_type', [\n+        'native',\n+        'arrow'\n+    ])\n+    @pytest.mark.parametrize('test_type', [\n+        (TINYINT, -42),\n+        (SMALLINT, -512),\n+        (INTEGER, -131072),\n+        (BIGINT, -17179869184),\n+        (UTINYINT, 254),\n+        (USMALLINT, 65535),\n+        (UINTEGER, 4294967295),\n+        (UBIGINT, 18446744073709551615),\n+        (HUGEINT, 18446744073709551616),\n+        (VARCHAR, 'long_string_test'),\n+        (UUID, uuid.UUID('ffffffff-ffff-ffff-ffff-ffffffffffff')),\n+        (FLOAT, 0.12246409803628922),\n+        (DOUBLE, 123142.12312416293784721232344),\n+        (DATE, datetime.date(2005, 3, 11)),\n+        (TIMESTAMP, datetime.datetime(2009, 2, 13, 11, 5, 53)),\n+        (TIME, datetime.time(14, 1, 12)),\n+        (BLOB, b'\\xF6\\x96\\xB0\\x85'),\n+        (INTERVAL, datetime.timedelta(days=30969, seconds=999, microseconds=999999)),\n+        (BOOLEAN, True),\n+        (duckdb.struct_type(['BIGINT[]','VARCHAR[]']), {'v1': [1, 2, 3], 'v2': ['a', 'non-inlined string', 'duckdb']}),\n+        (duckdb.list_type('VARCHAR'), ['the', 'duck', 'non-inlined string'])\n+    ])\n+    def test_type_coverage(self, test_type, function_type):\n+        type = test_type[0]\n+        value = test_type[1]\n+\n+        test_function = make_annotated_function(type)\n+\n+        con = duckdb.connect()\n+        con.create_function('test', test_function, type=function_type)\n+\n+        # Single value\n+        res = con.execute(f\"select test(?::{str(type)})\", [value]).fetchall()\n+        assert res[0][0] == value\n+\n+        # NULLs\n+        res = con.execute(f\"select res from (select ?, test(NULL::{str(type)}) as res)\", [value]).fetchall()\n+        assert res[0][0] == None\n+\n+        # Multiple chunks\n+        size = duckdb.__standard_vector_size__ * 3\n+        res = con.execute(f\"select test(x) from repeat(?::{str(type)}, {size}) as tbl(x)\", [value]).fetchall()\n+        assert(len(res) == size)\n+\n+        # Mixed NULL/NON-NULL\n+        size = duckdb.__standard_vector_size__ * 3\n+        con.execute(\"select setseed(0.1337)\").fetchall()\n+        actual = con.execute(f\"\"\"\n+            select test(\n+                case when (x > 0.5) then\n+                    ?::{str(type)}\n+                else\n+                    NULL\n+                end\n+            ) from (select random() as x from range({size}))\n+        \"\"\", [value]).fetchall()\n+\n+        con.execute(\"select setseed(0.1337)\").fetchall()\n+        expected = con.execute(f\"\"\"\n+            select\n+                case when (x > 0.5) then\n+                    ?::{str(type)}\n+                else\n+                    NULL\n+                end\n+            from (select random() as x from range({size}))\n+        \"\"\", [value]).fetchall()\n+        assert expected == actual\n+\n+        # Using 'relation.project'\n+        con.execute(f\"create table tbl as select ?::{str(type)} as x\", [value])\n+        table_rel = con.table('tbl')\n+        res = table_rel.project('test(x)').fetchall()\n+        assert res[0][0] == value\n+\n+    @pytest.mark.parametrize('udf_type', [\n+        'arrow',\n+        'native'\n+    ])\n+    def test_map_coverage(self, udf_type):\n+        def no_op(x):\n+            return x\n+        \n+        con = duckdb.connect()\n+        map_type = con.map_type('VARCHAR', 'BIGINT')\n+        con.create_function('test_map', no_op, [map_type], map_type, type=udf_type)\n+        rel = con.sql(\"select test_map(map(['non-inlined string', 'test', 'duckdb'], [42, 1337, 123]))\")\n+        res = rel.fetchall()\n+        assert res == [({'key': ['non-inlined string', 'test', 'duckdb'], 'value': [42, 1337, 123]},)]\n+\n+    @pytest.mark.parametrize('udf_type', [\n+        'arrow',\n+        'native'\n+    ])\n+    def test_exceptions(self, udf_type):\n+        def raises_exception(x):\n+            raise AttributeError(\"error\")\n+        \n+        con = duckdb.connect()\n+        con.create_function('raises', raises_exception, [BIGINT], BIGINT, type=udf_type)\n+        with pytest.raises(duckdb.InvalidInputException, match=' Python exception occurred while executing the UDF: AttributeError: error'):\n+            res = con.sql('select raises(3)').fetchall()\n+        \n+        con.remove_function('raises')\n+        con.create_function('raises', raises_exception, [BIGINT], BIGINT, exception_handling='return_null', type=udf_type)\n+        res = con.sql('select raises(3) from range(5)').fetchall()\n+        assert res == [(None,), (None,), (None,), (None,), (None,)]\n+\n+    def test_non_callable(self):\n+        con = duckdb.connect()\n+        with pytest.raises(TypeError):\n+            con.create_function('func', 5, [BIGINT], BIGINT, type='arrow')\n+\n+        class MyCallable:\n+            def __init__(self):\n+                pass\n+\n+            def __call__(self, x):\n+                return x\n+\n+        my_callable = MyCallable()\n+        con.create_function('func', my_callable, [BIGINT], BIGINT, type='arrow')\n+        res = con.sql('select func(5)').fetchall()\n+        assert res == [(5,)]\n+\n+    # pyarrow does not support creating an array filled with pd.NA values\n+    @pytest.mark.parametrize('udf_type', [\n+        'native'\n+    ])\n+    @pytest.mark.parametrize('duckdb_type', [\n+        FLOAT,\n+        DOUBLE\n+    ])\n+    def test_pd_nan(self, duckdb_type, udf_type):\n+        def return_pd_nan():\n+            if udf_type == 'native':\n+                return pd.NA\n+\n+        con = duckdb.connect()\n+        con.create_function('return_pd_nan', return_pd_nan, None, duckdb_type, null_handling='SPECIAL', type=udf_type)\n+\n+        res = con.sql('select return_pd_nan()').fetchall()\n+        assert res[0][0] == None\n+\n+    @pytest.mark.parametrize('udf_type', [\n+        'arrow',\n+        'native'\n+    ])\n+    @pytest.mark.parametrize('duckdb_type', [\n+        FLOAT,\n+        DOUBLE\n+    ])\n+    def test_np_nan(self, duckdb_type, udf_type):\n+        def return_np_nan():\n+            if udf_type == 'native':\n+                return np.nan\n+            else:\n+                import pyarrow as pa\n+                return pa.chunked_array([[np.nan]], type=pa.float64())\n+\n+        con = duckdb.connect()\n+        con.create_function('return_np_nan', return_np_nan, None, duckdb_type, null_handling='SPECIAL', type=udf_type)\n+\n+        res = con.sql('select return_np_nan()').fetchall()\n+        assert pd.isnull(res[0][0])\n+\n+    @pytest.mark.parametrize('udf_type', [\n+        'arrow',\n+        'native'\n+    ])\n+    @pytest.mark.parametrize('duckdb_type', [\n+        FLOAT,\n+        DOUBLE\n+    ])\n+    def test_math_nan(self, duckdb_type, udf_type):\n+        def return_math_nan():\n+            import cmath\n+            if udf_type == 'native':\n+                return cmath.nan\n+            else:\n+                import pyarrow as pa\n+                return pa.chunked_array([[cmath.nan]], type=pa.float64())\n+\n+        con = duckdb.connect()\n+        con.create_function('return_math_nan', return_math_nan, None, duckdb_type, null_handling='SPECIAL', type=udf_type)\n+\n+        res = con.sql('select return_math_nan()').fetchall()\n+        assert pd.isnull(res[0][0])\n+\n+    @pytest.mark.parametrize('udf_type', [\n+        'arrow',\n+        'native'\n+    ])\n+    @pytest.mark.parametrize('data_type', [\n+        TINYINT,\n+        SMALLINT,\n+        INTEGER,\n+        BIGINT,\n+        UTINYINT,\n+        USMALLINT,\n+        UINTEGER,\n+        UBIGINT,\n+        HUGEINT,\n+        VARCHAR,\n+        UUID,\n+        FLOAT,\n+        DOUBLE,\n+        DATE,\n+        TIMESTAMP,\n+        TIME,\n+        BLOB,\n+        INTERVAL,\n+        BOOLEAN,\n+        duckdb.struct_type(['BIGINT[]','VARCHAR[]']),\n+        duckdb.list_type('VARCHAR')\n+    ])\n+    def test_return_null(self, data_type, udf_type):\n+        def return_null():\n+            if udf_type == 'native':\n+                return None\n+            else:\n+                import pyarrow as pa\n+                return pa.nulls(1)\n+\n+        con = duckdb.connect()\n+        con.create_function('return_null', return_null, None, data_type, null_handling='special', type=udf_type)\n+        rel = con.sql('select return_null() as x')\n+        assert rel.types[0] == data_type\n+        assert rel.fetchall()[0][0] == None\n+\ndiff --git a/tools/pythonpkg/tests/fast/udf/test_scalar_arrow.py b/tools/pythonpkg/tests/fast/udf/test_scalar_arrow.py\nnew file mode 100644\nindex 000000000000..760dfb040075\n--- /dev/null\n+++ b/tools/pythonpkg/tests/fast/udf/test_scalar_arrow.py\n@@ -0,0 +1,176 @@\n+import duckdb\n+import os\n+import pytest\n+pd = pytest.importorskip(\"pandas\")\n+pa = pytest.importorskip(\"pyarrow\")\n+from typing import Union\n+import pyarrow.compute as pc\n+import uuid\n+import datetime\n+\n+from duckdb.typing import *\n+\n+class TestPyArrowUDF(object):\n+\n+    def test_basic_use(self):\n+        def plus_one(x):\n+            table = pa.lib.Table.from_arrays([x], names=['c0'])\n+            import pandas as pd\n+            df = pd.DataFrame(x.to_pandas())\n+            df['c0'] = df['c0'] + 1\n+            return pa.lib.Table.from_pandas(df)\n+\n+        con = duckdb.connect()\n+        con.create_function('plus_one', plus_one, [BIGINT], BIGINT, type='arrow')\n+        assert [(6,)] == con.sql('select plus_one(5)').fetchall()\n+\n+        range_table = con.table_function('range', [5000])\n+        res = con.sql('select plus_one(i) from range_table tbl(i)').fetchall()\n+        assert len(res) == 5000\n+\n+        vector_size = duckdb.__standard_vector_size__\n+        res = con.sql(f'select i, plus_one(i) from test_vector_types(NULL::BIGINT, false) t(i), range({vector_size})')\n+        assert len(res) == (vector_size * 11)\n+\n+    # NOTE: This only works up to duckdb.__standard_vector_size__,\n+    # because we process up to STANDARD_VECTOR_SIZE tuples at a time\n+    def test_sort_table(self):\n+        def sort_table(x):\n+            table = pa.lib.Table.from_arrays([x], names=['c0'])\n+            sorted_table = table.sort_by([(\"c0\", \"ascending\")])\n+            return sorted_table\n+\n+        con = duckdb.connect()\n+        con.create_function('sort_table', sort_table, [BIGINT], BIGINT, type='arrow')\n+        res = con.sql(\"select 100-i as original, sort_table(original) from range(100) tbl(i)\").fetchall()\n+        assert res[0] == (100, 1)\n+\n+\n+    def test_varargs(self):\n+        def variable_args(*args):\n+            # We return a chunked array here, but internally we convert this into a Table\n+            if (len(args) == 0):\n+                raise ValueError(\"Expected at least one argument\")\n+            for item in args:\n+                return item\n+\n+        con = duckdb.connect()\n+        # This function takes any number of arguments, returning the first column\n+        con.create_function('varargs', variable_args, None, BIGINT, type='arrow')\n+        res = con.sql(\"\"\"select varargs(5, '3', '2', 1, 0.12345)\"\"\").fetchall()\n+        assert res == [(5,)]\n+    \n+        res = con.sql(\"\"\"select varargs(42, 'test', [5,4,3])\"\"\").fetchall()\n+        assert res == [(42,)]\n+\n+    def test_cast_varchar_to_int(self):\n+        def takes_string(col):\n+            return col\n+        con = duckdb.connect()\n+        # The return type of the function is set to BIGINT, but it takes a VARCHAR\n+        con.create_function('pyarrow_string_to_num', takes_string, [VARCHAR], BIGINT, type='arrow')\n+\n+        # Succesful conversion\n+        res = con.sql(\"\"\"select pyarrow_string_to_num('5')\"\"\").fetchall()\n+        assert res == [(5,)]\n+\n+        with pytest.raises(duckdb.ConversionException, match=\"\"\"Could not convert string 'test' to INT64\"\"\"):\n+            res = con.sql(\"\"\"select pyarrow_string_to_num('test')\"\"\").fetchall()\n+\n+    def test_return_multiple_columns(self):\n+        def returns_two_columns(col):\n+            import pandas as pd\n+            # Return a pyarrow table consisting of two columns\n+            return pa.lib.Table.from_pandas(pd.DataFrame({'a': [5,4,3], 'b': ['test', 'quack', 'duckdb']}))\n+\n+        con = duckdb.connect()\n+        # Scalar functions only return a single value per tuple\n+        con.create_function('two_columns', returns_two_columns, [BIGINT], BIGINT, type='arrow')\n+        with pytest.raises(duckdb.InvalidInputException, match='The returned table from a pyarrow scalar udf should only contain one column, found 2'):\n+            res = con.sql(\"\"\"select two_columns(5)\"\"\").fetchall()\n+\n+    def test_return_none(self):\n+        def returns_none(col):\n+            return None\n+\n+        con = duckdb.connect()\n+        con.create_function('will_crash', returns_none, [BIGINT], BIGINT, type='arrow')\n+        with pytest.raises(duckdb.Error, match=\"\"\"Invalid Error: TypeError: 'NoneType' object is not iterable\"\"\"):\n+            res = con.sql(\"\"\"select will_crash(5)\"\"\").fetchall()\n+\n+    def test_empty_result(self):\n+        def return_empty(col):\n+            # Always returns an empty table\n+            return pa.lib.Table.from_arrays([[]], names=['c0'])\n+\n+        con = duckdb.connect()\n+        con.create_function('empty_result', return_empty, [BIGINT], BIGINT, type='arrow')\n+        with pytest.raises(duckdb.InvalidInputException, match='Returned pyarrow table should have 1 tuples, found 0'):\n+            res = con.sql(\"\"\"select empty_result(5)\"\"\").fetchall()\n+\n+    def test_excessive_result(self):\n+        def return_too_many(col):\n+            # Always returns a table consisting of 5 tuples\n+            return pa.lib.Table.from_arrays([[5,4,3,2,1]], names=['c0'])\n+\n+        con = duckdb.connect()\n+        con.create_function('too_many_tuples', return_too_many, [BIGINT], BIGINT, type='arrow')\n+        with pytest.raises(duckdb.InvalidInputException, match='Returned pyarrow table should have 1 tuples, found 5'):\n+            res = con.sql(\"\"\"select too_many_tuples(5)\"\"\").fetchall()\n+\n+    def test_return_struct(self):\n+        def return_struct(col):\n+            con = duckdb.connect()\n+            return con.sql(\"\"\"\n+                select {'a': 5, 'b': 'test', 'c': [5,3,2]}\n+            \"\"\").arrow()\n+        \n+        con = duckdb.connect()\n+        struct_type = con.struct_type({'a': BIGINT, 'b': VARCHAR, 'c': con.list_type(BIGINT)})\n+        con.create_function('return_struct', return_struct, [BIGINT], struct_type, type='arrow')\n+        res = con.sql(\"\"\"select return_struct(5)\"\"\").fetchall()\n+        assert res == [({'a': 5, 'b': 'test', 'c': [5, 3, 2]},)]\n+\n+    def test_multiple_chunks(self):\n+        def return_unmodified(col):\n+            return col\n+        \n+        con = duckdb.connect()\n+        con.create_function('unmodified', return_unmodified, [BIGINT], BIGINT, type='arrow')\n+        res = con.sql(\"\"\"\n+            select unmodified(i) from range(5000) tbl(i)\n+        \"\"\").fetchall()\n+\n+        assert len(res) == 5000\n+        assert res == con.sql('select * from range(5000)').fetchall()\n+\n+    def test_inferred(self):\n+        def func(x: int) -> int:\n+            import pandas as pd\n+            df = pd.DataFrame({'c0': x})\n+            df['c0'] = df['c0'] ** 2\n+            return pa.lib.Table.from_pandas(df)\n+        \n+        con = duckdb.connect()\n+        con.create_function('inferred', func, type='arrow')\n+        res = con.sql('select inferred(42)').fetchall()\n+        assert res == [(1764,)]\n+\n+    def test_nulls(self):\n+        def return_five(x):\n+            import pandas as pd\n+            length = len(x)\n+            return pa.lib.Table.from_pandas(pd.DataFrame({'a': [5 for _ in range(length)]}))\n+\n+        con = duckdb.connect()\n+        con.create_function('return_five', return_five, [BIGINT], BIGINT, null_handling='special', type='arrow')\n+        res = con.sql('select return_five(NULL) from range(10)').fetchall()\n+        # without 'special' null handling these would all be NULL\n+        assert res == [(5,), (5,), (5,), (5,), (5,), (5,), (5,), (5,), (5,), (5,)]\n+\n+        con = duckdb.connect()\n+        con.create_function('return_five', return_five, [BIGINT], BIGINT, null_handling='default', type='arrow')\n+        res = con.sql('select return_five(NULL) from range(10)').fetchall()\n+        # Because we didn't specify 'special' null handling, these are all NULL\n+        assert res == [(None,), (None,), (None,), (None,), (None,), (None,), (None,), (None,), (None,), (None,)]\n+\ndiff --git a/tools/pythonpkg/tests/fast/udf/test_scalar_native.py b/tools/pythonpkg/tests/fast/udf/test_scalar_native.py\nnew file mode 100644\nindex 000000000000..0b09f273ec4d\n--- /dev/null\n+++ b/tools/pythonpkg/tests/fast/udf/test_scalar_native.py\n@@ -0,0 +1,183 @@\n+import duckdb\n+import os\n+import pandas as pd\n+import pytest\n+\n+from duckdb.typing import *\n+\n+class TestNativeUDF(object):\n+    def test_default_conn(self):\n+        def passthrough(x):\n+            return x\n+        \n+        duckdb.create_function('default_conn_passthrough', passthrough, [BIGINT], BIGINT)\n+        res = duckdb.sql('select default_conn_passthrough(5)').fetchall()\n+        assert res == [(5,)]\n+\n+    def test_basic_use(self):\n+        def plus_one(x):\n+            if x == None or x > 50:\n+                return x;\n+            return x + 1\n+\n+        con = duckdb.connect()\n+        con.create_function('plus_one', plus_one, [BIGINT], BIGINT)\n+        assert [(6,)] == con.sql('select plus_one(5)').fetchall()\n+\n+        range_table = con.table_function('range', [5000])\n+        res = con.sql('select plus_one(i) from range_table tbl(i)').fetchall()\n+        assert len(res) == 5000\n+\n+        vector_size = duckdb.__standard_vector_size__\n+        res = con.sql(f'select i, plus_one(i) from test_vector_types(NULL::BIGINT, false) t(i), range({vector_size})')\n+        assert len(res) == (vector_size * 11)\n+\n+    def test_passthrough(self):\n+        def passthrough(x):\n+            return x\n+\n+        con = duckdb.connect()\n+        con.create_function('passthrough', passthrough, [BIGINT], BIGINT)\n+        assert con.sql('select passthrough(i) from range(5000) tbl(i)').fetchall() == con.sql('select * from range(5000)').fetchall()\n+\n+    def test_execute(self):\n+        def func(x):\n+            return x % 2\n+\n+        con = duckdb.connect()\n+        con.create_function('modulo_op', func, [BIGINT], TINYINT)\n+        res = con.execute('select modulo_op(?)', [5]).fetchall()\n+        assert res == [(1,)]\n+\n+    def test_cast_output(self):\n+        def takes_string(x):\n+            return x\n+\n+        con = duckdb.connect()\n+        con.create_function('casts_from_string', takes_string, [VARCHAR], BIGINT)\n+\n+        res = con.sql(\"select casts_from_string('42')\").fetchall()\n+        assert res == [(42,)]\n+\n+        with pytest.raises(duckdb.InvalidInputException):\n+            res = con.sql(\"select casts_from_string('test')\").fetchall()\n+\n+    def test_detected_parameters(self):\n+        def concatenate(a: str, b: str):\n+            return a + b\n+\n+        con = duckdb.connect()\n+        con.create_function('py_concatenate', concatenate, None, VARCHAR)\n+        res = con.sql(\"\"\"\n+            select py_concatenate('5','3');\n+        \"\"\").fetchall()\n+        assert res[0][0] == '53'\n+\n+    def test_detected_return_type(self):\n+        def add_nums(*args) -> int:\n+            sum = 0;\n+            for arg in args:\n+                sum += arg\n+            return sum\n+\n+        con = duckdb.connect()\n+        con.create_function('add_nums', add_nums)\n+        res = con.sql(\"\"\"\n+            select add_nums(5,3,2,1);\n+        \"\"\").fetchall()\n+        assert res[0][0] == 11\n+\n+    def test_varargs(self):\n+        def variable_args(*args):\n+            amount = len(args)\n+            return amount\n+\n+        con = duckdb.connect()\n+        con.create_function('varargs', variable_args, None, BIGINT)\n+        res = con.sql(\"\"\"select varargs('5', '3', '2', 1, 0.12345)\"\"\").fetchall()\n+        assert res == [(5,)]\n+\n+    def test_return_incorrectly_typed_object(self):\n+        def returns_duckdb() -> int:\n+            return 'duckdb'\n+        \n+        con = duckdb.connect()\n+        con.create_function('fastest_database_in_the_west', returns_duckdb)\n+        with pytest.raises(duckdb.InvalidInputException, match=\"Failed to cast value: Could not convert string 'duckdb' to INT64\"):\n+            res = con.sql('select fastest_database_in_the_west()').fetchall()\n+\n+    def test_nulls(self):\n+        def five_if_null(x):\n+            if (x == None):\n+                return 5\n+            return x\n+        con = duckdb.connect()\n+        con.create_function('null_test', five_if_null, [BIGINT], BIGINT, null_handling = \"SPECIAL\")\n+        res = con.sql('select null_test(NULL)').fetchall()\n+        assert res == [(5,)]\n+\n+    @pytest.mark.parametrize('pair', [\n+        (TINYINT, -129),\n+        (TINYINT, 128),\n+        (SMALLINT, -32769),\n+        (SMALLINT, 32768),\n+        (INTEGER, -2147483649),\n+        (INTEGER, 2147483648),\n+        (BIGINT, -9223372036854775815),\n+        (BIGINT, 9223372036854775808),\n+        (UTINYINT, -1),\n+        (UTINYINT, 256),\n+        (USMALLINT, -1),\n+        (USMALLINT, 65536),\n+        (UINTEGER, -1),\n+        (UINTEGER, 4294967296),\n+        (UBIGINT, -1),\n+        (UBIGINT, 18446744073709551616),\n+        (HUGEINT, -170141183460469231731687303715884105729),\n+        (HUGEINT, 170141183460469231731687303715884105728),\n+    ])\n+    def test_return_overflow(self, pair):\n+        duckdb_type, overflowing_value = pair\n+\n+        def return_overflow():\n+            return overflowing_value\n+        \n+        con = duckdb.connect()\n+        con.create_function('return_overflow', return_overflow, None, duckdb_type)\n+        with pytest.raises(duckdb.InvalidInputException, match='Invalid Input Error: Failed to cast value:'):\n+            rel = con.sql('select return_overflow()')\n+            res = rel.fetchall()\n+            print(duckdb_type)\n+            print(res)\n+\n+    def test_structs(self):\n+        def add_extra_column(original):\n+            original['a'] = 200\n+            original['bb'] = 0\n+            return original\n+\n+        con = duckdb.connect()\n+        range_table = con.table_function('range', [5000])\n+        con.create_function(\"append_field\", add_extra_column, [duckdb.struct_type({'a': BIGINT, 'b': BIGINT})], duckdb.struct_type({'a': BIGINT, 'b': BIGINT, 'c': BIGINT}))\n+\n+        res = con.sql(\"\"\"\n+            select append_field({'a': i::BIGINT, 'b': 3::BIGINT}) from range_table tbl(i)\n+        \"\"\")\n+        # added extra column to the struct\n+        assert len(res.fetchone()[0].keys()) == 3\n+        # FIXME: this is needed, otherwise the old transaction is still active when we try to start a new transaction inside of 'create_function', which means the call would fail\n+        res.fetchall()\n+\n+        def swap_keys(dict):\n+            result = {}\n+            reversed_keys = list(dict.keys())\n+            reversed_keys.reverse()\n+            for item in reversed_keys:\n+                result[item] = dict[item]\n+            return result\n+\n+        con.create_function('swap_keys', swap_keys, [con.struct_type({'a': BIGINT, 'b': VARCHAR})], con.struct_type({'a': VARCHAR, 'b': BIGINT}))\n+        res = con.sql(\"\"\"\n+        select swap_keys({'a': 42, 'b': 'answer_to_life'})\n+        \"\"\").fetchall()\n+        assert res == [({'a': 'answer_to_life', 'b': 42},)]\n",
  "problem_statement": "[Python] Add scalar UDF\nWe want to add the ability to register UDFs in the python client.\r\n\r\nProposed syntax:\r\n```py\r\nimport duckdb\r\n\r\nfrom duckdb.typing import *\r\n\r\ndef add_one(x):\r\n    return x + 1\r\n\r\nduckdb.register_scalar(\"plus_one\", add_one, [BIGINT], BIGINT)\r\n# duckdb.register_scalar(\"plus_one\", lambda x: x + 1, [BIGINT], BIGINT)\r\n\r\nres = duckdb.sql('select plus_one(5)')\r\n```\r\n\n",
  "hints_text": "",
  "created_at": "2023-04-20T14:40:16Z"
}