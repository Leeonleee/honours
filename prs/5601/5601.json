{
  "repo": "duckdb/duckdb",
  "pull_number": 5601,
  "instance_id": "duckdb__duckdb-5601",
  "issue_numbers": [
    "5520"
  ],
  "base_commit": "8d4671cf506d559a61a4dc5f73e8a615ea2fd54f",
  "patch": "diff --git a/src/catalog/catalog_set.cpp b/src/catalog/catalog_set.cpp\nindex f0233112457a..f8c20c72cbae 100644\n--- a/src/catalog/catalog_set.cpp\n+++ b/src/catalog/catalog_set.cpp\n@@ -298,6 +298,7 @@ void CatalogSet::CleanupEntry(CatalogEntry *catalog_entry) {\n \t// destroy the backed up entry: it is no longer required\n \tD_ASSERT(catalog_entry->parent);\n \tif (catalog_entry->parent->type != CatalogType::UPDATED_ENTRY) {\n+\t\tlock_guard<mutex> write_lock(catalog.write_lock);\n \t\tlock_guard<mutex> lock(catalog_lock);\n \t\tif (!catalog_entry->deleted) {\n \t\t\t// delete the entry from the dependency manager, if it is not deleted yet\ndiff --git a/src/transaction/commit_state.cpp b/src/transaction/commit_state.cpp\nindex e31dbda0873c..06b85dfb6c0a 100644\n--- a/src/transaction/commit_state.cpp\n+++ b/src/transaction/commit_state.cpp\n@@ -217,6 +217,12 @@ void CommitState::CommitEntry(UndoFlags type, data_ptr_t data) {\n \t\t// set the commit timestamp of the catalog entry to the given id\n \t\tauto catalog_entry = Load<CatalogEntry *>(data);\n \t\tD_ASSERT(catalog_entry->parent);\n+\n+\t\tauto &catalog = catalog_entry->catalog;\n+\t\tD_ASSERT(catalog);\n+\n+\t\t// Grab a write lock on the catalog\n+\t\tlock_guard<mutex> write_lock(catalog->write_lock);\n \t\tcatalog_entry->set->UpdateTimestamp(catalog_entry->parent, commit_id);\n \t\tif (catalog_entry->name != catalog_entry->parent->name) {\n \t\t\tcatalog_entry->set->UpdateTimestamp(catalog_entry, commit_id);\n",
  "test_patch": "diff --git a/test/sql/catalog/table/test_table_drop_concurrent.test b/test/sql/catalog/table/test_table_drop_concurrent.test\nnew file mode 100644\nindex 000000000000..ab58526602c3\n--- /dev/null\n+++ b/test/sql/catalog/table/test_table_drop_concurrent.test\n@@ -0,0 +1,17 @@\n+# name: test/sql/catalog/table/test_table_drop_concurrent.test\n+# group: [table]\n+\n+require 64bit\n+\n+# Create 4000 threads that all run the contents of this loop\n+concurrentloop threadid 0 3000\n+\n+# Create a table\n+statement ok\n+CREATE OR REPLACE TABLE df${threadid} as select i,i,i from range(100) tbl(i)\n+\n+# Drop the table\n+statement ok\n+DROP TABLE df${threadid};\n+\n+endloop\ndiff --git a/test/sql/catalog/view/test_view_drop_concurrent.test b/test/sql/catalog/view/test_view_drop_concurrent.test\nnew file mode 100644\nindex 000000000000..66242dc3b4cc\n--- /dev/null\n+++ b/test/sql/catalog/view/test_view_drop_concurrent.test\n@@ -0,0 +1,17 @@\n+# name: test/sql/catalog/view/test_view_drop_concurrent.test\n+# group: [view]\n+\n+require 64bit\n+\n+# Create 4000 threads that all run the contents of this loop\n+concurrentloop threadid 0 3000\n+\n+# Create the view\n+statement ok\n+CREATE TEMPORARY VIEW df AS select 0,0,0 from range(10);\n+\n+# Drop the view\n+statement ok\n+DROP VIEW df;\n+\n+endloop\n",
  "problem_statement": "[Python] Segfault in DuckDBPyConnection.unregister() in multi-threaded program\n### What happens?\n\nCalling `conn.register()`/`conn.unregister()` from multiple threads triggers a segfault sometimes. The cause appears to be some sort of race condition where the entry being removed is already gone/invalid by the time `unregister()` calls `DependencyManager::DropObject`.\n\n### To Reproduce\n\nThe following script causes a crash about a third of the time:\r\n\r\n```python\r\nimport duckdb\r\nimport pandas as pd\r\nimport numpy as np\r\nimport time\r\nfrom threading import Thread\r\n\r\ndf = pd.DataFrame(np.zeros((10_000, 3)))\r\n\r\nconn = duckdb.connect()\r\nconn.execute(\"\"\"CREATE TABLE foo\r\n             (\r\n                x FLOAT,\r\n                y FLOAT,\r\n                z FLOAT,\r\n                );\"\"\")\r\n\r\ndef work(i):\r\n    db = conn.cursor()\r\n    db.register(\"df\", df)\r\n    #print(f\"{i} registered\")\r\n    db.execute(\"INSERT INTO foo SELECT * from df\")\r\n    #print(f\"{i} inserted\")\r\n    db.unregister(\"df\")\r\n    #print(f\"{i} done\")\r\n\r\nprint(\"Start\")\r\nthreads = []\r\nfor i in range(100_000):\r\n    threads.append(Thread(target=work, args=(i,), name=f\"thread_{i}\"))\r\n\r\nfor t in threads:\r\n    t.start()\r\n\r\nfor t in threads:\r\n    t.join()\r\nprint(\"done!\")\r\n```\r\n\r\nThe backtrace under lldb typically looks like this:\r\n```\r\n(lldb) bt\r\n* thread #41, stop reason = EXC_BAD_ACCESS (code=1, address=0xbeadd8af5d08)\r\n  * frame #0: 0x000000010373b990 duckdb.cpython-38-darwin.so`std::__1::unordered_map<duckdb::CatalogEntry*, std::__1::unordered_set<duckdb::Dependency, duckdb::DependencyHashFunction, duckdb::DependencyEquality, std::__1::allocator<duckdb::Dependency> >, std::__1::hash<duckdb::CatalogEntry*>, std::__1::equal_to<duckdb::CatalogEntry*>, std::__1::allocator<std::__1::pair<duckdb::CatalogEntry* const, std::__1::unordered_set<duckdb::Dependency, duckdb::DependencyHashFunction, duckdb::DependencyEquality, std::__1::allocator<duckdb::Dependency> > > > >::operator[](duckdb::CatalogEntry* const&) + 408\r\n    frame #1: 0x000000010373a8f4 duckdb.cpython-38-darwin.so`duckdb::DependencyManager::DropObject(duckdb::ClientContext&, duckdb::CatalogEntry*, bool) + 44\r\n    frame #2: 0x000000010373a864 duckdb.cpython-38-darwin.so`duckdb::CatalogSet::DropEntryDependencies(duckdb::ClientContext&, unsigned long long, duckdb::CatalogEntry&, bool) + 132\r\n    frame #3: 0x000000010373ab24 duckdb.cpython-38-darwin.so`duckdb::CatalogSet::DropEntryInternal(duckdb::ClientContext&, unsigned long long, duckdb::CatalogEntry&, bool) + 84\r\n    frame #4: 0x0000000103734ab4 duckdb.cpython-38-darwin.so`duckdb::CatalogSet::DropEntry(duckdb::ClientContext&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool) + 228\r\n    frame #5: 0x0000000103745100 duckdb.cpython-38-darwin.so`duckdb::SchemaCatalogEntry::DropEntry(duckdb::ClientContext&, duckdb::DropInfo*) + 124\r\n    frame #6: 0x0000000103a8b4fc duckdb.cpython-38-darwin.so`duckdb::PhysicalDrop::GetData(duckdb::ExecutionContext&, duckdb::DataChunk&, duckdb::GlobalSourceState&, duckdb::LocalSourceState&) const + 236\r\n    frame #7: 0x00000001040bf5e8 duckdb.cpython-38-darwin.so`duckdb::PipelineExecutor::FetchFromSource(duckdb::DataChunk&) + 96\r\n    frame #8: 0x00000001040bcf88 duckdb.cpython-38-darwin.so`duckdb::PipelineExecutor::ExecutePull(duckdb::DataChunk&) + 160\r\n    frame #9: 0x00000001040bce40 duckdb.cpython-38-darwin.so`duckdb::Executor::FetchChunk() + 112\r\n    frame #10: 0x0000000103ff66d0 duckdb.cpython-38-darwin.so`duckdb::ClientContext::FetchInternal(duckdb::ClientContextLock&, duckdb::Executor&, duckdb::BaseQueryResult&) + 76\r\n    frame #11: 0x0000000103ff7fd8 duckdb.cpython-38-darwin.so`duckdb::ClientContext::FetchResultInternal(duckdb::ClientContextLock&, duckdb::PendingQueryResult&) + 540\r\n    frame #12: 0x0000000103ffcb04 duckdb.cpython-38-darwin.so`duckdb::PendingQueryResult::ExecuteInternal(duckdb::ClientContextLock&) + 92\r\n    frame #13: 0x0000000103ffefac duckdb.cpython-38-darwin.so`duckdb::ClientContext::Query(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool) + 316\r\n    frame #14: 0x0000000104004a28 duckdb.cpython-38-darwin.so`duckdb::Connection::Query(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) + 36\r\n    frame #15: 0x000000010429c39c duckdb.cpython-38-darwin.so`duckdb::DuckDBPyConnection::UnregisterPythonObject(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) + 288\r\n    frame #16: 0x00000001042aa2fc duckdb.cpython-38-darwin.so`void pybind11::cpp_function::initialize<pybind11::cpp_function::cpp_function<duckdb::DuckDBPyConnection*, duckdb::DuckDBPyConnection, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, pybind11::name, pybind11::is_method, pybind11::sibling, char [25], pybind11::arg>(duckdb::DuckDBPyConnection* (duckdb::DuckDBPyConnection::*)(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&, char const (&) [25], pybind11::arg const&)::'lambda'(duckdb::DuckDBPyConnection*, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&), duckdb::DuckDBPyConnection*, duckdb::DuckDBPyConnection*, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, pybind11::name, pybind11::is_method, pybind11::sibling, char [25], pybind11::arg>(duckdb::DuckDBPyConnection*&&, duckdb::DuckDBPyConnection (*)(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&, char const (&) [25], pybind11::arg const&)::'lambda'(pybind11::detail::function_call&)::operator()(pybind11::detail::function_call&) const + 172\r\n    frame #17: 0x0000000104254818 duckdb.cpython-38-darwin.so`pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 3544\r\n    frame #18: 0x0000000100021960 python`cfunction_call_varargs + 140\r\n    frame #19: 0x0000000100021324 python`_PyObject_MakeTpCall + 372\r\n    frame #20: 0x00000001000244e0 python`method_vectorcall + 196\r\n    frame #21: 0x00000001000f6840 python`call_function + 296\r\n    frame #22: 0x00000001000f3bf0 python`_PyEval_EvalFrameDefault + 23796\r\n    frame #23: 0x0000000100021d08 python`function_code_fastcall + 120\r\n    frame #24: 0x0000000100021688 python`PyVectorcall_Call + 104\r\n    frame #25: 0x00000001000f3e48 python`_PyEval_EvalFrameDefault + 24396\r\n    frame #26: 0x0000000100021d08 python`function_code_fastcall + 120\r\n    frame #27: 0x00000001000f6840 python`call_function + 296\r\n    frame #28: 0x00000001000f3bcc python`_PyEval_EvalFrameDefault + 23760\r\n    frame #29: 0x0000000100021d08 python`function_code_fastcall + 120\r\n    frame #30: 0x00000001000f6840 python`call_function + 296\r\n    frame #31: 0x00000001000f3bcc python`_PyEval_EvalFrameDefault + 23760\r\n    frame #32: 0x0000000100021d08 python`function_code_fastcall + 120\r\n    frame #33: 0x000000010002453c python`method_vectorcall + 288\r\n    frame #34: 0x0000000100021688 python`PyVectorcall_Call + 104\r\n    frame #35: 0x000000010019247c python`t_bootstrap + 80\r\n    frame #36: 0x0000000100142b2c python`pythread_wrapper + 28\r\n    frame #37: 0x000000019e50606c libsystem_pthread.dylib`_pthread_start + 148\r\n```\n\n### OS:\n\nMacOS 13.0 - arm64\n\n### DuckDB Version:\n\n0.6.1-dev153\n\n### DuckDB Client:\n\nPython\n\n### Full Name:\n\nRonan Lamy\n\n### Affiliation:\n\niterative.ai\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\n",
  "hints_text": "Thanks for the report! We will have a look.\r\n\r\nAs a work-around could you perhaps try not using register/unregister but using the replacement scans instead?\nThank you, avoiding register/unregister seems to fix the issue.\nThis looks to be related to an issue in the `CatalogSet::CleanupEntry()` code, we obtain the `catalog_lock`, check `!catalog_entry->deleted` then clean up the dependencies and dependents map, asserting beforehand that there are entries present in these maps for this catalog entry - but then we don't set `catalog_entry->deleted` to true before releasing the lock.\r\n\r\nThis assertion gets triggered:\r\n```c++\r\n\tD_ASSERT(dependencies_map.find(object) != dependencies_map.end());\r\n```\r\n\r\nAfter setting that to true while we hold the lock, I ran into another issue, where we GetEntryInternal, and then do DropEntryInternal, which calls dependency_manager DropObject - which assumes the object has an entry in the `dependents_map`\r\nSo I added a check for that before calling DropObject, and now it seems fixed",
  "created_at": "2022-12-05T14:38:13Z"
}