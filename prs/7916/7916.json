{
  "repo": "duckdb/duckdb",
  "pull_number": 7916,
  "instance_id": "duckdb__duckdb-7916",
  "issue_numbers": [
    "7278"
  ],
  "base_commit": "da8980368176fe30ee7fcd6debc8fb300ac60224",
  "patch": "diff --git a/src/execution/operator/join/physical_iejoin.cpp b/src/execution/operator/join/physical_iejoin.cpp\nindex dae712e203a4..71f944c4de5c 100644\n--- a/src/execution/operator/join/physical_iejoin.cpp\n+++ b/src/execution/operator/join/physical_iejoin.cpp\n@@ -1016,19 +1016,16 @@ void PhysicalIEJoin::BuildPipelines(Pipeline &current, MetaPipeline &meta_pipeli\n \n \t// Create one child meta pipeline that will hold the LHS and RHS pipelines\n \tauto &child_meta_pipeline = meta_pipeline.CreateChildMetaPipeline(current, *this);\n-\tauto lhs_pipeline = child_meta_pipeline.GetBasePipeline();\n-\tauto rhs_pipeline = child_meta_pipeline.CreatePipeline();\n \n \t// Build out LHS\n+\tauto lhs_pipeline = child_meta_pipeline.GetBasePipeline();\n \tchildren[0]->BuildPipelines(*lhs_pipeline, child_meta_pipeline);\n \n-\t// RHS depends on everything in LHS\n-\tchild_meta_pipeline.AddDependenciesFrom(rhs_pipeline, lhs_pipeline.get(), true);\n-\n \t// Build out RHS\n+\tauto rhs_pipeline = child_meta_pipeline.CreatePipeline();\n \tchildren[1]->BuildPipelines(*rhs_pipeline, child_meta_pipeline);\n \n-\t// Despite having the same sink, RHS needs its own PipelineFinishEvent\n+\t// Despite having the same sink, RHS and everything created after it need their own (same) PipelineFinishEvent\n \tchild_meta_pipeline.AddFinishEvent(rhs_pipeline);\n }\n \ndiff --git a/src/include/duckdb/parallel/meta_pipeline.hpp b/src/include/duckdb/parallel/meta_pipeline.hpp\nindex eef848b65947..82b92ba5111c 100644\n--- a/src/include/duckdb/parallel/meta_pipeline.hpp\n+++ b/src/include/duckdb/parallel/meta_pipeline.hpp\n@@ -14,6 +14,13 @@ namespace duckdb {\n \n class PhysicalRecursiveCTE;\n \n+struct PipelineFinishGroup {\n+\texplicit PipelineFinishGroup(Pipeline *group_base_p) : group_base(group_base_p) {\n+\t}\n+\tPipeline *group_base;\n+\tunordered_set<Pipeline *> group_members;\n+};\n+\n //! MetaPipeline represents a set of pipelines that all have the same sink\n class MetaPipeline : public std::enable_shared_from_this<MetaPipeline> {\n \t//! We follow these rules when building:\n@@ -57,7 +64,9 @@ class MetaPipeline : public std::enable_shared_from_this<MetaPipeline> {\n \t//! Make sure that the given pipeline has its own PipelineFinishEvent (e.g., for IEJoin - double Finalize)\n \tvoid AddFinishEvent(Pipeline *pipeline);\n \t//! Whether the pipeline needs its own PipelineFinishEvent\n-\tbool HasFinishEvent(Pipeline *pipeline);\n+\tbool HasFinishEvent(Pipeline *pipeline) const;\n+\t//! Whether this pipeline is part of a PipelineFinishEvent\n+\toptional_ptr<Pipeline> GetFinishGroup(Pipeline *pipeline) const;\n \n public:\n \t//! Build the MetaPipeline with 'op' as the first operator (excl. the shared sink)\n@@ -86,8 +95,6 @@ class MetaPipeline : public std::enable_shared_from_this<MetaPipeline> {\n \tbool recursive_cte;\n \t//! All pipelines with a different source, but the same sink\n \tvector<shared_ptr<Pipeline>> pipelines;\n-\t//! The pipelines that must finish before the MetaPipeline is finished\n-\tvector<Pipeline *> final_pipelines;\n \t//! Dependencies within this MetaPipeline\n \tunordered_map<Pipeline *, vector<Pipeline *>> dependencies;\n \t//! Other MetaPipelines that this MetaPipeline depends on\n@@ -96,6 +103,8 @@ class MetaPipeline : public std::enable_shared_from_this<MetaPipeline> {\n \tidx_t next_batch_index;\n \t//! Pipelines (other than the base pipeline) that need their own PipelineFinishEvent (e.g., for IEJoin)\n \tunordered_set<Pipeline *> finish_pipelines;\n+\t//! Mapping from pipeline (e.g., child or union) to finish pipeline\n+\tunordered_map<Pipeline *, Pipeline *> finish_map;\n };\n \n } // namespace duckdb\ndiff --git a/src/parallel/executor.cpp b/src/parallel/executor.cpp\nindex dbde87a420b5..2a1a5cbc710c 100644\n--- a/src/parallel/executor.cpp\n+++ b/src/parallel/executor.cpp\n@@ -95,26 +95,50 @@ void Executor::SchedulePipeline(const shared_ptr<MetaPipeline> &meta_pipeline, S\n \n \t\t// create events/stack for this pipeline\n \t\tauto pipeline_event = make_shared<PipelineEvent>(pipeline);\n-\t\toptional_ptr<Event> pipeline_finish_event_ptr;\n-\t\tif (meta_pipeline->HasFinishEvent(pipeline.get())) {\n+\n+\t\tauto finish_group = meta_pipeline->GetFinishGroup(pipeline.get());\n+\t\tif (finish_group) {\n+\t\t\t// this pipeline is part of a finish group\n+\t\t\tconst auto group_entry = event_map.find(*finish_group.get());\n+\t\t\tD_ASSERT(group_entry != event_map.end());\n+\t\t\tauto &group_stack = group_entry->second;\n+\t\t\tPipelineEventStack pipeline_stack(base_stack.pipeline_initialize_event, *pipeline_event,\n+\t\t\t                                  group_stack.pipeline_finish_event, base_stack.pipeline_complete_event);\n+\n+\t\t\t// dependencies: base_finish -> pipeline_event -> group_finish\n+\t\t\tpipeline_stack.pipeline_event.AddDependency(base_stack.pipeline_event);\n+\t\t\tgroup_stack.pipeline_finish_event.AddDependency(pipeline_stack.pipeline_event);\n+\n+\t\t\t// add pipeline stack to event map\n+\t\t\tevent_map.insert(make_pair(reference<Pipeline>(*pipeline), pipeline_stack));\n+\t\t} else if (meta_pipeline->HasFinishEvent(pipeline.get())) {\n \t\t\t// this pipeline has its own finish event (despite going into the same sink - Finalize twice!)\n \t\t\tauto pipeline_finish_event = make_shared<PipelineFinishEvent>(pipeline);\n-\t\t\tpipeline_finish_event_ptr = pipeline_finish_event.get();\n+\t\t\tPipelineEventStack pipeline_stack(base_stack.pipeline_initialize_event, *pipeline_event,\n+\t\t\t                                  *pipeline_finish_event, base_stack.pipeline_complete_event);\n \t\t\tevents.push_back(std::move(pipeline_finish_event));\n-\t\t\tbase_stack.pipeline_complete_event.AddDependency(*pipeline_finish_event_ptr);\n+\n+\t\t\t// dependencies: base_finish -> pipeline_event -> pipeline_finish -> base_complete\n+\t\t\tpipeline_stack.pipeline_event.AddDependency(base_stack.pipeline_finish_event);\n+\t\t\tpipeline_stack.pipeline_finish_event.AddDependency(pipeline_stack.pipeline_event);\n+\t\t\tbase_stack.pipeline_complete_event.AddDependency(pipeline_stack.pipeline_finish_event);\n+\n+\t\t\t// add pipeline stack to event map\n+\t\t\tevent_map.insert(make_pair(reference<Pipeline>(*pipeline), pipeline_stack));\n+\n \t\t} else {\n-\t\t\tpipeline_finish_event_ptr = &base_stack.pipeline_finish_event;\n-\t\t}\n-\t\tPipelineEventStack pipeline_stack(base_stack.pipeline_initialize_event, *pipeline_event,\n-\t\t                                  *pipeline_finish_event_ptr, base_stack.pipeline_complete_event);\n-\t\tevents.push_back(std::move(pipeline_event));\n+\t\t\t// no additional finish event\n+\t\t\tPipelineEventStack pipeline_stack(base_stack.pipeline_initialize_event, *pipeline_event,\n+\t\t\t                                  base_stack.pipeline_finish_event, base_stack.pipeline_complete_event);\n \n-\t\t// dependencies: base_initialize -> pipeline_event -> base_finish\n-\t\tpipeline_stack.pipeline_event.AddDependency(base_stack.pipeline_initialize_event);\n-\t\tpipeline_stack.pipeline_finish_event.AddDependency(pipeline_stack.pipeline_event);\n+\t\t\t// dependencies: base_initialize -> pipeline_event -> base_finish\n+\t\t\tpipeline_stack.pipeline_event.AddDependency(base_stack.pipeline_initialize_event);\n+\t\t\tbase_stack.pipeline_finish_event.AddDependency(pipeline_stack.pipeline_event);\n \n-\t\t// add pipeline stack to event map\n-\t\tevent_map.insert(make_pair(reference<Pipeline>(*pipeline), pipeline_stack));\n+\t\t\t// add pipeline stack to event map\n+\t\t\tevent_map.insert(make_pair(reference<Pipeline>(*pipeline), pipeline_stack));\n+\t\t}\n+\t\tevents.push_back(std::move(pipeline_event));\n \t}\n \n \t// add base stack to the event data too\ndiff --git a/src/parallel/meta_pipeline.cpp b/src/parallel/meta_pipeline.cpp\nindex a9fda6b9b499..191f36c71ebe 100644\n--- a/src/parallel/meta_pipeline.cpp\n+++ b/src/parallel/meta_pipeline.cpp\n@@ -70,7 +70,6 @@ void MetaPipeline::AssignNextBatchIndex(Pipeline *pipeline) {\n void MetaPipeline::Build(PhysicalOperator &op) {\n \tD_ASSERT(pipelines.size() == 1);\n \tD_ASSERT(children.empty());\n-\tD_ASSERT(final_pipelines.empty());\n \top.BuildPipelines(*pipelines.back(), *this);\n }\n \n@@ -125,13 +124,28 @@ void MetaPipeline::AddDependenciesFrom(Pipeline *dependant, Pipeline *start, boo\n }\n \n void MetaPipeline::AddFinishEvent(Pipeline *pipeline) {\n+\tD_ASSERT(finish_pipelines.find(pipeline) == finish_pipelines.end());\n \tfinish_pipelines.insert(pipeline);\n+\n+\t// add all pipelines that were added since 'pipeline' was added (including 'pipeline') to the finish group\n+\tauto it = pipelines.begin();\n+\tfor (; it->get() != pipeline; it++) {\n+\t}\n+\tit++;\n+\tfor (; it != pipelines.end(); it++) {\n+\t\tfinish_map.emplace(it->get(), pipeline);\n+\t}\n }\n \n-bool MetaPipeline::HasFinishEvent(Pipeline *pipeline) {\n+bool MetaPipeline::HasFinishEvent(Pipeline *pipeline) const {\n \treturn finish_pipelines.find(pipeline) != finish_pipelines.end();\n }\n \n+optional_ptr<Pipeline> MetaPipeline::GetFinishGroup(Pipeline *pipeline) const {\n+\tauto it = finish_map.find(pipeline);\n+\treturn it == finish_map.end() ? nullptr : it->second;\n+}\n+\n Pipeline *MetaPipeline::CreateUnionPipeline(Pipeline &current, bool order_matters) {\n \t// create the union pipeline (batch index 0, should be set correctly afterwards)\n \tauto union_pipeline = CreatePipeline();\n@@ -162,7 +176,7 @@ void MetaPipeline::CreateChildPipeline(Pipeline &current, PhysicalOperator &op,\n \tauto child_pipeline = pipelines.back().get();\n \tchild_pipeline->base_batch_index = current.base_batch_index;\n \n-\t// child pipeline has a depency (within this MetaPipeline on all pipelines that were scheduled\n+\t// child pipeline has a dependency (within this MetaPipeline on all pipelines that were scheduled\n \t// between 'current' and now (including 'current') - set them up\n \tdependencies[child_pipeline].push_back(&current);\n \tAddDependenciesFrom(child_pipeline, last_pipeline, false);\n",
  "test_patch": "diff --git a/test/sql/join/iejoin/iejoin_issue_7278.test b/test/sql/join/iejoin/iejoin_issue_7278.test\nnew file mode 100644\nindex 000000000000..fbf56dbf25e7\n--- /dev/null\n+++ b/test/sql/join/iejoin/iejoin_issue_7278.test\n@@ -0,0 +1,97 @@\n+# name: test/sql/join/iejoin/iejoin_issue_7278.test\n+# description: Issue #7278: Incorrect results (child pipeline / finish event scheduling\n+# group: [iejoin]\n+\n+statement ok\n+pragma enable_verification\n+\n+statement ok\n+create table calendar as\n+\tSELECT\n+\t\tstart_ts,\n+\t\tstart_ts + interval '12 hours' as end_ts,\n+\t\tdate_part('year',start_ts)::bigint * 100 + date_part('week',start_ts)::bigint  as yyyyww\n+\tFROM generate_series(TIMESTAMP '2023-01-01 06:00:00', TIMESTAMP '2023-06-01 00:00:00', INTERVAL '12 hours') tbl(start_ts)\n+;\n+\n+statement ok\n+create table snapshot_data as\n+\tselect\n+\t\tTIMESTAMP '2023-03-01 08:00:00' as snapshot_ts,\n+\t\t1 as snapshot_value\n+\tfrom generate_series(1,1000) t(i)\n+;\n+\n+query I\n+with cal_last_13 as (\n+\tselect * from calendar where yyyyww in (SELECT yyyyww\n+\tFROM calendar)\n+)\n+select\n+\tcount(*)\n+from snapshot_data data\n+join cal_last_13 cal\n+\ton data.snapshot_ts >= cal.start_ts\n+\tand data.snapshot_ts <= cal.end_ts\n+----\n+1000\n+\n+query I\n+with cal_last_13 as (\n+\tselect * from calendar where yyyyww in (SELECT yyyyww\n+\tFROM calendar)\n+\tunion all\n+\tselect * from calendar where yyyyww in (SELECT yyyyww\n+\tFROM calendar)\n+)\n+select\n+\tcount(*)\n+from snapshot_data data\n+join cal_last_13 cal\n+\ton data.snapshot_ts >= cal.start_ts\n+\tand data.snapshot_ts <= cal.end_ts\n+----\n+2000\n+\n+query I\n+with cal_last_13 as (\n+\tselect * from calendar where yyyyww in (SELECT yyyyww\n+\tFROM calendar)\n+\tunion all\n+\tselect * from calendar where yyyyww in (SELECT yyyyww\n+\tFROM calendar)\n+\tunion all\n+\tselect * from calendar where yyyyww in (SELECT yyyyww\n+\tFROM calendar)\n+)\n+select\n+\tcount(*)\n+from snapshot_data data\n+join cal_last_13 cal\n+\ton data.snapshot_ts >= cal.start_ts\n+\tand data.snapshot_ts <= cal.end_ts\n+----\n+3000\n+\n+query I\n+with cal_last_13 as (\n+\tselect * from calendar where yyyyww in (SELECT yyyyww\n+\tFROM calendar)\n+\tunion all\n+\tselect * from calendar where yyyyww in (SELECT yyyyww\n+\tFROM calendar)\n+\tunion all\n+\tselect * from calendar where yyyyww in (SELECT yyyyww\n+\tFROM calendar)\n+)\n+select\n+\tcount(*)\n+from snapshot_data data\n+join cal_last_13 cal\n+\ton data.snapshot_ts >= cal.start_ts\n+\tand data.snapshot_ts <= cal.end_ts\n+join cal_last_13 cal2\n+\ton data.snapshot_ts >= cal2.start_ts\n+\tand data.snapshot_ts <= cal2.end_ts\n+----\n+9000\n",
  "problem_statement": "Incorrect results in 0.7.1 and 0.7.2-dev2675 vs 0.4.0 (Issue with IEJoin/CTE's/?)\n### What happens?\r\n\r\nWhen I run the below query, I receive a null value for the average computation and 0 rows for the count(*) aggregation using 0.7.1 or 0.7.2-dev2675. In 0.4.0, I receive non-zero results for both columns. \r\n\r\nThe query is an IE join that connects a shiftly calendar with data that is recorded at specific timestamps. I am using the IEJoin to filter the data and assign a shift number to the data. This query is with random data, but I encountered this in a real-world query of similar structure.\r\n\r\nPlease forgive me on the ugly IN statements... I was just hacking something together and figured that the calendar table was small enough to handle my ugly SQL... ;-)\r\n\r\n### To Reproduce\r\n\r\nI am running this query in the Python client, but it is all encapsulated in a single SQL statement:\r\n```sql\r\nSELECT SETSEED(0.8675309);\r\ncreate temp table calendar as \r\n\tSELECT \r\n\t\tstart_ts,\r\n\t\tstart_ts + interval '12 hours' - interval '1 second' as end_ts,\r\n\t\tdate_part('isodow',start_ts)::bigint as dow,\r\n\t\tdate_part('yearweek',start_ts)::bigint as yyyyww,\r\n\t\t((date_part('isodow',start_ts)/2)*2)::varchar as shift_estimate\r\n\tFROM range(TIMESTAMP '2023-01-01 06:00:00', TIMESTAMP '2023-06-01 00:00:00', INTERVAL '12 hours') tbl(start_ts)\r\n;\r\n\r\ncreate temp table snapshot_data as \r\n\tselect \r\n\t\tTIMESTAMP '2023-03-01 06:00:00' + to_seconds(((90*24*60*60)*1*random())::int) as snapshot_ts,\r\n\t\t'woot' || mod(i,3) as varchar_column,\r\n\t\t(random() * i * 10000)::bigint as snapshot_value,\r\n\t\t(random() * i * 10000)::bigint as snapshot_value2,\r\n\t\t(random() * i * 10000)::bigint as snapshot_value3,\r\n\t\t\r\n\tfrom generate_series(1000000) t(i)\r\n;\r\n\r\nwith last_13_wws as (\r\n\tSELECT distinct yyyyww\r\n\tFROM calendar\r\n\tWHERE\r\n\t\tstart_ts >= (current_timestamp - (interval 1 day * (7 * 13)))\r\n\t\tand end_ts <= current_timestamp\r\n\t\t--Not the current ww\r\n\t\tand yyyyww != (select yyyyww from calendar where start_ts <= current_timestamp and end_ts >= current_timestamp limit 1)\r\n), cal_last_13 as (\r\n\tselect * from calendar where yyyyww in (select yyyyww from last_13_wws)  \r\n)\r\n  \r\nselect \r\n\tavg(snapshot_value),\r\n\tcount(*),\r\nfrom snapshot_data data\r\njoin cal_last_13 cal\r\n\ton data.snapshot_ts >= cal.start_ts\r\n\tand data.snapshot_ts <= cal.end_ts\r\n-- where\r\n-- \tvarchar_column = 'woot1'\r\n\r\n```\r\nResults in 0.7.1 and 0.7.2dev:\r\n| avg(snapshot_value) | count_star() |\r\n|-- | -- | \r\nNULL | 0\r\n\r\n\r\nResults in 0.4.0:\r\n| avg(snapshot_value) | count_star() |\r\n|-- | -- | \r\n|2501231162.132651 | 599654.0|\r\n\r\nIf I remove the CTE's, the query does return correct results:\r\n```sql\r\nSELECT SETSEED(0.8675309);\r\ncreate temp table calendar as \r\n\tSELECT \r\n\t\tstart_ts,\r\n\t\tstart_ts + interval '12 hours' - interval '1 second' as end_ts,\r\n\t\tdate_part('isodow',start_ts)::bigint as dow,\r\n\t\tdate_part('yearweek',start_ts)::bigint as yyyyww,\r\n\t\t((date_part('isodow',start_ts)/2)*2)::varchar as shift_estimate\r\n\tFROM range(TIMESTAMP '2023-01-01 06:00:00', TIMESTAMP '2023-06-01 00:00:00', INTERVAL '12 hours') tbl(start_ts)\r\n;\r\n\r\ncreate temp table snapshot_data as \r\n\tselect \r\n\t\tTIMESTAMP '2023-03-01 06:00:00' + to_seconds(((90*24*60*60)*1*random())::int) as snapshot_ts,\r\n\t\t'woot' || mod(i,3) as varchar_column,\r\n\t\t(random() * i * 10000)::bigint as snapshot_value,\r\n\t\t(random() * i * 10000)::bigint as snapshot_value2,\r\n\t\t(random() * i * 10000)::bigint as snapshot_value3,\r\n\t\t\r\n\tfrom generate_series(1000000) t(i)\r\n;\r\n  \r\nselect \r\n\tavg(snapshot_value),\r\n\tcount(*),\r\nfrom snapshot_data data\r\njoin calendar cal\r\n\ton data.snapshot_ts >= cal.start_ts\r\n\tand data.snapshot_ts <= cal.end_ts\r\n```\r\n\r\n| avg(snapshot_value) | count_star() |\r\n|-- | -- | \r\n|2502216150.542991 | 1000001.0|\r\n\r\n### OS:\r\n\r\nWindows\r\n\r\n### DuckDB Version:\r\n\r\n0.7.1 and 0.7.2-dev2675\r\n\r\n### DuckDB Client:\r\n\r\nPython\r\n\r\n### Full Name:\r\n\r\nAlex Monahan\r\n\r\n### Affiliation:\r\n\r\nIntel and DuckDB Labs\r\n\r\n### Have you tried this on the latest `master` branch?\r\n\r\n- [X] I agree\r\n\r\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\r\n\r\n- [X] I agree\n",
  "hints_text": "```sql\r\nSELECT SETSEED(0.8675309);\r\n```\r\nWill make the random numbers deterministic. \n> ```sql\r\n> SELECT SETSEED(0.8675309);\r\n> ```\r\n> \r\n> Will make the random numbers deterministic.\r\n\r\nI'll make that change!\nUpdated to be deterministic using `SETSEED`. Thanks!\nIn case it helps, a more minimal reproduction (I've been interested in understanding duckdb's IEJoin implementation so this seemed like a good chance to try to dig in a little... didn't get far in code yet, but at least narrowed down the reproduction): \r\n\r\nAfter removing some extraneous factors, like random(), I observed that the number of elements in snapshot data + the nested subquery in the CTE are both factors\r\n\nEdit: to add a better explanation of the cases: Case 1 is a minimized reproduction of the original issue. Case 2 only differs by the sequence length (1000 vs 100). Case 3 is a modification of Case 1 that passes that differs from Case 1 by the removal of the nested subquery in the CTE.\n\n## Case 1: fails (returns 0 count) w/ generateseries(1000)\r\n```\r\ncreate temp table calendar as \r\n\tSELECT \r\n\t\tstart_ts,\r\n\t\tstart_ts + interval '12 hours' as end_ts,\r\n\t\tdate_part('yearweek',start_ts)::bigint as yyyyww\r\n\tFROM range(TIMESTAMP '2023-01-01 06:00:00', TIMESTAMP '2023-06-01 00:00:00', INTERVAL '12 hours') tbl(start_ts)\r\n;\r\n\r\ncreate temp table snapshot_data as \r\n\tselect \r\n\t\tTIMESTAMP '2023-03-01 08:00:00' as snapshot_ts,\r\n\t\t1 as snapshot_value\r\n\tfrom generate_series(1000) t(i)\r\n;\r\n \r\nwith cal_last_13 as (\r\n\tselect * from calendar where yyyyww in (SELECT yyyyww\r\n\tFROM calendar)  \r\n)\r\nselect \r\n\tcount(*),\r\nfrom snapshot_data data\r\njoin cal_last_13 cal\r\n\ton data.snapshot_ts >= cal.start_ts\r\n\tand data.snapshot_ts <= cal.end_ts\r\n```\r\n\r\n## Case 2: Passes (101 count) with `generate_series(100)`\r\n```\r\ncreate temp table calendar as \r\n\tSELECT \r\n\t\tstart_ts,\r\n\t\tstart_ts + interval '12 hours' as end_ts,\r\n\t\tdate_part('yearweek',start_ts)::bigint as yyyyww\r\n\tFROM range(TIMESTAMP '2023-01-01 06:00:00', TIMESTAMP '2023-06-01 00:00:00', INTERVAL '12 hours') tbl(start_ts)\r\n;\r\ncreate temp table snapshot_data as \r\n\tselect \r\n\t\tTIMESTAMP '2023-03-01 08:00:00' as snapshot_ts,\r\n\t\t1 as snapshot_value\r\n\tfrom generate_series(100) t(i)\r\n;\r\nwith cal_last_13 as (\r\n\tselect * from calendar where yyyyww in (SELECT yyyyww\r\n\tFROM calendar)  \r\n)\r\nselect \r\n\tcount(*),\r\nfrom snapshot_data data\r\njoin cal_last_13 cal\r\n\ton data.snapshot_ts >= cal.start_ts\r\n\tand data.snapshot_ts <= cal.end_ts\r\n```\r\n\r\n## Case 3: Passes after removing the nested query from the CTE \r\n```\r\nwith cal_last_13 as (\r\n\tselect * from calendar\r\n)\r\nselect \r\n\tcount(*),\r\nfrom snapshot_data data\r\njoin cal_last_13 cal\r\n\ton data.snapshot_ts >= cal.start_ts\r\n\tand data.snapshot_ts <= cal.end_ts\r\n```",
  "created_at": "2023-06-12T12:31:14Z"
}