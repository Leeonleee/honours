{
  "repo": "duckdb/duckdb",
  "pull_number": 14375,
  "instance_id": "duckdb__duckdb-14375",
  "issue_numbers": [
    "14132"
  ],
  "base_commit": "fb51e97b3103865f63f89f693dbb8d98adcf1a00",
  "patch": "diff --git a/extension/json/json_scan.cpp b/extension/json/json_scan.cpp\nindex 761e4a5e63b9..c5dee4b1aaa5 100644\n--- a/extension/json/json_scan.cpp\n+++ b/extension/json/json_scan.cpp\n@@ -144,8 +144,7 @@ string JSONScanData::GetTimestampFormat() const {\n }\n \n JSONScanGlobalState::JSONScanGlobalState(ClientContext &context, const JSONScanData &bind_data_p)\n-    : bind_data(bind_data_p), transform_options(bind_data.transform_options),\n-      allocator(BufferManager::GetBufferManager(context).GetBufferAllocator()),\n+    : bind_data(bind_data_p), transform_options(bind_data.transform_options), allocator(BufferAllocator::Get(context)),\n       buffer_capacity(bind_data.maximum_object_size * 2), file_index(0), batch_index(0),\n       system_threads(TaskScheduler::GetScheduler(context).NumberOfThreads()),\n       enable_parallel_scans(bind_data.files.size() < system_threads) {\ndiff --git a/src/common/radix_partitioning.cpp b/src/common/radix_partitioning.cpp\nindex 3e8dee30d59f..d62a1329a44a 100644\n--- a/src/common/radix_partitioning.cpp\n+++ b/src/common/radix_partitioning.cpp\n@@ -112,6 +112,7 @@ RadixPartitionedColumnData::RadixPartitionedColumnData(ClientContext &context_p,\n \tallocators->allocators.reserve(num_partitions);\n \tfor (idx_t i = 0; i < num_partitions; i++) {\n \t\tCreateAllocator();\n+\t\tallocators->allocators.back()->SetPartitionIndex(i);\n \t}\n \tD_ASSERT(allocators->allocators.size() == num_partitions);\n }\n@@ -174,8 +175,10 @@ RadixPartitionedTupleData::~RadixPartitionedTupleData() {\n }\n \n void RadixPartitionedTupleData::Initialize() {\n-\tfor (idx_t i = 0; i < RadixPartitioning::NumberOfPartitions(radix_bits); i++) {\n+\tconst auto num_partitions = RadixPartitioning::NumberOfPartitions(radix_bits);\n+\tfor (idx_t i = 0; i < num_partitions; i++) {\n \t\tpartitions.emplace_back(CreatePartitionCollection(i));\n+\t\tpartitions.back()->SetPartitionIndex(i);\n \t}\n }\n \ndiff --git a/src/common/types/column/column_data_allocator.cpp b/src/common/types/column/column_data_allocator.cpp\nindex bec0751e0d6c..66a1e612f2b3 100644\n--- a/src/common/types/column/column_data_allocator.cpp\n+++ b/src/common/types/column/column_data_allocator.cpp\n@@ -1,5 +1,6 @@\n #include \"duckdb/common/types/column/column_data_allocator.hpp\"\n \n+#include \"duckdb/common/radix_partitioning.hpp\"\n #include \"duckdb/common/types/column/column_data_collection_segment.hpp\"\n #include \"duckdb/storage/buffer/block_handle.hpp\"\n #include \"duckdb/storage/buffer/buffer_pool.hpp\"\n@@ -84,6 +85,9 @@ BufferHandle ColumnDataAllocator::AllocateBlock(idx_t size) {\n \tauto pin = alloc.buffer_manager->Allocate(MemoryTag::COLUMN_DATA, max_size, false);\n \tdata.handle = pin.GetBlockHandle();\n \tblocks.push_back(std::move(data));\n+\tif (partition_index.IsValid()) { // Set the eviction queue index logarithmically using RadixBits\n+\t\tblocks.back().handle->SetEvictionQueueIndex(RadixPartitioning::RadixBits(partition_index.GetIndex()));\n+\t}\n \tallocated_size += max_size;\n \treturn pin;\n }\ndiff --git a/src/common/types/column/column_data_collection.cpp b/src/common/types/column/column_data_collection.cpp\nindex 41626d470633..dd3439e5523a 100644\n--- a/src/common/types/column/column_data_collection.cpp\n+++ b/src/common/types/column/column_data_collection.cpp\n@@ -119,6 +119,13 @@ idx_t ColumnDataCollection::AllocationSize() const {\n \treturn total_size;\n }\n \n+void ColumnDataCollection::SetPartitionIndex(const idx_t index) {\n+\tD_ASSERT(!partition_index.IsValid());\n+\tD_ASSERT(Count() == 0);\n+\tpartition_index = index;\n+\tallocator->SetPartitionIndex(index);\n+}\n+\n //===--------------------------------------------------------------------===//\n // ColumnDataRow\n //===--------------------------------------------------------------------===//\ndiff --git a/src/common/types/row/partitioned_tuple_data.cpp b/src/common/types/row/partitioned_tuple_data.cpp\nindex 17cd306f4045..b77463d8cf06 100644\n--- a/src/common/types/row/partitioned_tuple_data.cpp\n+++ b/src/common/types/row/partitioned_tuple_data.cpp\n@@ -262,15 +262,8 @@ void PartitionedTupleData::Repartition(PartitionedTupleData &new_partitioned_dat\n \tPartitionedTupleDataAppendState append_state;\n \tnew_partitioned_data.InitializeAppendState(append_state);\n \n-\tconst auto reverse = RepartitionReverseOrder();\n-\tconst idx_t start_idx = reverse ? partitions.size() : 0;\n-\tconst idx_t end_idx = reverse ? 0 : partitions.size();\n-\tconst int64_t update = reverse ? -1 : 1;\n-\tconst int64_t adjustment = reverse ? -1 : 0;\n-\n-\tfor (idx_t partition_idx = start_idx; partition_idx != end_idx; partition_idx += idx_t(update)) {\n-\t\tauto actual_partition_idx = partition_idx + idx_t(adjustment);\n-\t\tauto &partition = *partitions[actual_partition_idx];\n+\tfor (idx_t partition_idx = 0; partition_idx < partitions.size(); partition_idx++) {\n+\t\tauto &partition = *partitions[partition_idx];\n \n \t\tif (partition.Count() > 0) {\n \t\t\tTupleDataChunkIterator iterator(partition, TupleDataPinProperties::DESTROY_AFTER_DONE, true);\n@@ -279,9 +272,9 @@ void PartitionedTupleData::Repartition(PartitionedTupleData &new_partitioned_dat\n \t\t\t\tnew_partitioned_data.Append(append_state, chunk_state, iterator.GetCurrentChunkCount());\n \t\t\t} while (iterator.Next());\n \n-\t\t\tRepartitionFinalizeStates(*this, new_partitioned_data, append_state, actual_partition_idx);\n+\t\t\tRepartitionFinalizeStates(*this, new_partitioned_data, append_state, partition_idx);\n \t\t}\n-\t\tpartitions[actual_partition_idx]->Reset();\n+\t\tpartitions[partition_idx]->Reset();\n \t}\n \tnew_partitioned_data.FlushAppendState(append_state);\n \ndiff --git a/src/common/types/row/tuple_data_allocator.cpp b/src/common/types/row/tuple_data_allocator.cpp\nindex 8f391c4983aa..11895e977d61 100644\n--- a/src/common/types/row/tuple_data_allocator.cpp\n+++ b/src/common/types/row/tuple_data_allocator.cpp\n@@ -1,6 +1,7 @@\n #include \"duckdb/common/types/row/tuple_data_allocator.hpp\"\n \n #include \"duckdb/common/fast_mem.hpp\"\n+#include \"duckdb/common/radix_partitioning.hpp\"\n #include \"duckdb/common/types/row/tuple_data_segment.hpp\"\n #include \"duckdb/common/types/row/tuple_data_states.hpp\"\n #include \"duckdb/storage/buffer/block_handle.hpp\"\n@@ -73,6 +74,12 @@ idx_t TupleDataAllocator::HeapBlockCount() const {\n \treturn heap_blocks.size();\n }\n \n+void TupleDataAllocator::SetPartitionIndex(const idx_t index) {\n+\tD_ASSERT(!partition_index.IsValid());\n+\tD_ASSERT(row_blocks.empty() && heap_blocks.empty());\n+\tpartition_index = index;\n+}\n+\n void TupleDataAllocator::Build(TupleDataSegment &segment, TupleDataPinState &pin_state,\n                                TupleDataChunkState &chunk_state, const idx_t append_offset, const idx_t append_count) {\n \tD_ASSERT(this == segment.allocator.get());\n@@ -142,6 +149,9 @@ TupleDataChunkPart TupleDataAllocator::BuildChunkPart(TupleDataPinState &pin_sta\n \t// Allocate row block (if needed)\n \tif (row_blocks.empty() || row_blocks.back().RemainingCapacity() < layout.GetRowWidth()) {\n \t\trow_blocks.emplace_back(buffer_manager, block_size);\n+\t\tif (partition_index.IsValid()) { // Set the eviction queue index logarithmically using RadixBits\n+\t\t\trow_blocks.back().handle->SetEvictionQueueIndex(RadixPartitioning::RadixBits(partition_index.GetIndex()));\n+\t\t}\n \t}\n \tresult.row_block_index = NumericCast<uint32_t>(row_blocks.size() - 1);\n \tauto &row_block = row_blocks[result.row_block_index];\n@@ -188,6 +198,10 @@ TupleDataChunkPart TupleDataAllocator::BuildChunkPart(TupleDataPinState &pin_sta\n \t\t\t\tif (heap_blocks.empty() || heap_blocks.back().RemainingCapacity() < heap_sizes[append_offset]) {\n \t\t\t\t\tconst auto size = MaxValue<idx_t>(block_size, heap_sizes[append_offset]);\n \t\t\t\t\theap_blocks.emplace_back(buffer_manager, size);\n+\t\t\t\t\tif (partition_index.IsValid()) { // Set the eviction queue index logarithmically using RadixBits\n+\t\t\t\t\t\theap_blocks.back().handle->SetEvictionQueueIndex(\n+\t\t\t\t\t\t    RadixPartitioning::RadixBits(partition_index.GetIndex()));\n+\t\t\t\t\t}\n \t\t\t\t}\n \t\t\t\tresult.heap_block_index = NumericCast<uint32_t>(heap_blocks.size() - 1);\n \t\t\t\tauto &heap_block = heap_blocks[result.heap_block_index];\ndiff --git a/src/common/types/row/tuple_data_collection.cpp b/src/common/types/row/tuple_data_collection.cpp\nindex a5215d0302eb..c44732847e9d 100644\n--- a/src/common/types/row/tuple_data_collection.cpp\n+++ b/src/common/types/row/tuple_data_collection.cpp\n@@ -79,6 +79,13 @@ void TupleDataCollection::Unpin() {\n \t}\n }\n \n+void TupleDataCollection::SetPartitionIndex(const idx_t index) {\n+\tD_ASSERT(!partition_index.IsValid());\n+\tD_ASSERT(Count() == 0);\n+\tpartition_index = index;\n+\tallocator->SetPartitionIndex(index);\n+}\n+\n // LCOV_EXCL_START\n void VerifyAppendColumns(const TupleDataLayout &layout, const vector<column_t> &column_ids) {\n #ifdef DEBUG\ndiff --git a/src/execution/aggregate_hashtable.cpp b/src/execution/aggregate_hashtable.cpp\nindex e09fd9b70fad..077d846cd6d9 100644\n--- a/src/execution/aggregate_hashtable.cpp\n+++ b/src/execution/aggregate_hashtable.cpp\n@@ -59,7 +59,8 @@ GroupedAggregateHashTable::GroupedAggregateHashTable(ClientContext &context, All\n }\n \n void GroupedAggregateHashTable::InitializePartitionedData() {\n-\tif (!partitioned_data || RadixPartitioning::RadixBits(partitioned_data->PartitionCount()) != radix_bits) {\n+\tif (!partitioned_data ||\n+\t    RadixPartitioning::RadixBitsOfPowerOfTwo(partitioned_data->PartitionCount()) != radix_bits) {\n \t\tD_ASSERT(!partitioned_data || partitioned_data->Count() == 0);\n \t\tpartitioned_data =\n \t\t    make_uniq<RadixPartitionedTupleData>(buffer_manager, layout, radix_bits, layout.ColumnCount() - 1);\n@@ -131,7 +132,11 @@ idx_t GroupedAggregateHashTable::Capacity() const {\n }\n \n idx_t GroupedAggregateHashTable::ResizeThreshold() const {\n-\treturn LossyNumericCast<idx_t>(static_cast<double>(Capacity()) / LOAD_FACTOR);\n+\treturn ResizeThreshold(Capacity());\n+}\n+\n+idx_t GroupedAggregateHashTable::ResizeThreshold(const idx_t capacity) {\n+\treturn LossyNumericCast<idx_t>(static_cast<double>(capacity) / LOAD_FACTOR);\n }\n \n idx_t GroupedAggregateHashTable::ApplyBitMask(hash_t hash) const {\n@@ -169,8 +174,8 @@ void GroupedAggregateHashTable::SetRadixBits(idx_t radix_bits_p) {\n void GroupedAggregateHashTable::Resize(idx_t size) {\n \tD_ASSERT(size >= STANDARD_VECTOR_SIZE);\n \tD_ASSERT(IsPowerOfTwo(size));\n-\tif (size < capacity) {\n-\t\tthrow InternalException(\"Cannot downsize a hash table!\");\n+\tif (Count() != 0 && size < capacity) {\n+\t\tthrow InternalException(\"Cannot downsize a non-empty hash table!\");\n \t}\n \n \tcapacity = size;\ndiff --git a/src/execution/operator/join/physical_hash_join.cpp b/src/execution/operator/join/physical_hash_join.cpp\nindex 0283f79945af..a5fe270f0a9b 100644\n--- a/src/execution/operator/join/physical_hash_join.cpp\n+++ b/src/execution/operator/join/physical_hash_join.cpp\n@@ -426,18 +426,11 @@ class HashJoinFinalizeEvent : public BasePipelineEvent {\n \t\t\t    make_uniq<HashJoinFinalizeTask>(shared_from_this(), context, sink, 0U, chunk_count, false, sink.op));\n \t\t} else {\n \t\t\t// Parallel finalize\n-\t\t\tauto chunks_per_thread = MaxValue<idx_t>((chunk_count + num_threads - 1) / num_threads, 1);\n-\n-\t\t\tidx_t chunk_idx = 0;\n-\t\t\tfor (idx_t thread_idx = 0; thread_idx < num_threads; thread_idx++) {\n-\t\t\t\tauto chunk_idx_from = chunk_idx;\n-\t\t\t\tauto chunk_idx_to = MinValue<idx_t>(chunk_idx_from + chunks_per_thread, chunk_count);\n-\t\t\t\tfinalize_tasks.push_back(make_uniq<HashJoinFinalizeTask>(shared_from_this(), context, sink,\n-\t\t\t\t                                                         chunk_idx_from, chunk_idx_to, true, sink.op));\n-\t\t\t\tchunk_idx = chunk_idx_to;\n-\t\t\t\tif (chunk_idx == chunk_count) {\n-\t\t\t\t\tbreak;\n-\t\t\t\t}\n+\t\t\tconst idx_t chunks_per_task = context.config.verify_parallelism ? 1 : CHUNKS_PER_TASK;\n+\t\t\tfor (idx_t chunk_idx = 0; chunk_idx < chunk_count; chunk_idx += chunks_per_task) {\n+\t\t\t\tauto chunk_idx_to = MinValue<idx_t>(chunk_idx + chunks_per_task, chunk_count);\n+\t\t\t\tfinalize_tasks.push_back(make_uniq<HashJoinFinalizeTask>(shared_from_this(), context, sink, chunk_idx,\n+\t\t\t\t                                                         chunk_idx_to, true, sink.op));\n \t\t\t}\n \t\t}\n \t\tSetTasks(std::move(finalize_tasks));\n@@ -448,7 +441,8 @@ class HashJoinFinalizeEvent : public BasePipelineEvent {\n \t\tsink.hash_table->finalized = true;\n \t}\n \n-\tstatic constexpr const idx_t PARALLEL_CONSTRUCT_THRESHOLD = 1048576;\n+\tstatic constexpr idx_t PARALLEL_CONSTRUCT_THRESHOLD = 1048576;\n+\tstatic constexpr idx_t CHUNKS_PER_TASK = 64;\n };\n \n void HashJoinGlobalSinkState::ScheduleFinalize(Pipeline &pipeline, Event &event) {\ndiff --git a/src/execution/radix_partitioned_hashtable.cpp b/src/execution/radix_partitioned_hashtable.cpp\nindex cfd968100662..179f7fd67d92 100644\n--- a/src/execution/radix_partitioned_hashtable.cpp\n+++ b/src/execution/radix_partitioned_hashtable.cpp\n@@ -119,8 +119,6 @@ struct RadixHTConfig {\n \tstatic constexpr const idx_t MAXIMUM_INITIAL_SINK_RADIX_BITS = 3;\n \t//! Maximum Sink radix bits (independent of threads)\n \tstatic constexpr const idx_t MAXIMUM_FINAL_SINK_RADIX_BITS = 7;\n-\t//! By how many radix bits to increment if we go external\n-\tstatic constexpr const idx_t EXTERNAL_RADIX_BITS_INCREMENT = 3;\n \n \t//! The global sink state\n \tRadixHTGlobalSinkState &sink;\n@@ -128,8 +126,6 @@ struct RadixHTConfig {\n \tatomic<idx_t> sink_radix_bits;\n \t//! Maximum Sink radix bits (set based on number of threads)\n \tconst idx_t maximum_sink_radix_bits;\n-\t//! Radix bits if we go external\n-\tconst idx_t external_radix_bits;\n \n public:\n \t//! Capacity of HTs during the Sink\n@@ -153,6 +149,7 @@ class RadixHTGlobalSinkState : public GlobalSinkState {\n \tClientContext &context;\n \t//! Temporary memory state for managing this hash table's memory usage\n \tunique_ptr<TemporaryMemoryState> temporary_memory_state;\n+\tidx_t minimum_reservation;\n \n \t//! The radix HT\n \tconst RadixPartitionedHashTable &radix_ht;\n@@ -174,6 +171,7 @@ class RadixHTGlobalSinkState : public GlobalSinkState {\n \tunique_ptr<PartitionedTupleData> uncombined_data;\n \t//! Allocators used during the Sink/Finalize\n \tvector<shared_ptr<ArenaAllocator>> stored_allocators;\n+\tidx_t stored_allocators_size;\n \n \t//! Partitions that are finalized during GetData\n \tvector<unique_ptr<AggregatePartition>> partitions;\n@@ -192,8 +190,9 @@ RadixHTGlobalSinkState::RadixHTGlobalSinkState(ClientContext &context_p, const R\n     : context(context_p), temporary_memory_state(TemporaryMemoryManager::Get(context).Register(context)),\n       radix_ht(radix_ht_p), config(context, *this), finalized(false), external(false), active_threads(0),\n       number_of_threads(NumericCast<idx_t>(TaskScheduler::GetScheduler(context).NumberOfThreads())),\n-      any_combined(false), finalize_done(0), scan_pin_properties(TupleDataPinProperties::DESTROY_AFTER_DONE),\n-      count_before_combining(0), max_partition_size(0) {\n+      any_combined(false), stored_allocators_size(0), finalize_done(0),\n+      scan_pin_properties(TupleDataPinProperties::DESTROY_AFTER_DONE), count_before_combining(0),\n+      max_partition_size(0) {\n \n \t// Compute minimum reservation\n \tauto block_alloc_size = BufferManager::GetBufferManager(context).GetBlockAllocSize();\n@@ -210,7 +209,7 @@ RadixHTGlobalSinkState::RadixHTGlobalSinkState(ClientContext &context_p, const R\n \n \t// This really is the minimum reservation that we can do\n \tauto num_threads = NumericCast<idx_t>(TaskScheduler::GetScheduler(context).NumberOfThreads());\n-\tauto minimum_reservation = num_threads * ht_size;\n+\tminimum_reservation = num_threads * ht_size;\n \n \ttemporary_memory_state->SetMinimumReservation(minimum_reservation);\n \ttemporary_memory_state->SetRemainingSizeAndUpdateReservation(context, minimum_reservation);\n@@ -253,8 +252,7 @@ void RadixHTGlobalSinkState::Destroy() {\n \n RadixHTConfig::RadixHTConfig(ClientContext &context, RadixHTGlobalSinkState &sink_p)\n     : sink(sink_p), sink_radix_bits(InitialSinkRadixBits(context)),\n-      maximum_sink_radix_bits(MaximumSinkRadixBits(context)),\n-      external_radix_bits(ExternalRadixBits(maximum_sink_radix_bits)), sink_capacity(SinkCapacity(context)) {\n+      maximum_sink_radix_bits(MaximumSinkRadixBits(context)), sink_capacity(SinkCapacity(context)) {\n }\n \n void RadixHTConfig::SetRadixBits(idx_t radix_bits_p) {\n@@ -262,7 +260,7 @@ void RadixHTConfig::SetRadixBits(idx_t radix_bits_p) {\n }\n \n bool RadixHTConfig::SetRadixBitsToExternal() {\n-\tSetRadixBitsInternal(external_radix_bits, true);\n+\tSetRadixBitsInternal(MAXIMUM_FINAL_SINK_RADIX_BITS, true);\n \treturn sink.external;\n }\n \n@@ -284,21 +282,18 @@ void RadixHTConfig::SetRadixBitsInternal(const idx_t radix_bits_p, bool external\n \t\tsink.external = true;\n \t}\n \tsink_radix_bits = radix_bits_p;\n-\treturn;\n }\n \n idx_t RadixHTConfig::InitialSinkRadixBits(ClientContext &context) {\n \tconst auto active_threads = NumericCast<idx_t>(TaskScheduler::GetScheduler(context).NumberOfThreads());\n-\treturn MinValue(RadixPartitioning::RadixBits(NextPowerOfTwo(active_threads)), MAXIMUM_INITIAL_SINK_RADIX_BITS);\n+\treturn MinValue(RadixPartitioning::RadixBitsOfPowerOfTwo(NextPowerOfTwo(active_threads)),\n+\t                MAXIMUM_INITIAL_SINK_RADIX_BITS);\n }\n \n idx_t RadixHTConfig::MaximumSinkRadixBits(ClientContext &context) {\n \tconst auto active_threads = NumericCast<idx_t>(TaskScheduler::GetScheduler(context).NumberOfThreads());\n-\treturn MinValue(RadixPartitioning::RadixBits(NextPowerOfTwo(active_threads)), MAXIMUM_FINAL_SINK_RADIX_BITS);\n-}\n-\n-idx_t RadixHTConfig::ExternalRadixBits(const idx_t &maximum_sink_radix_bits_p) {\n-\treturn MinValue(maximum_sink_radix_bits_p + EXTERNAL_RADIX_BITS_INCREMENT, MAXIMUM_FINAL_SINK_RADIX_BITS);\n+\treturn MinValue(RadixPartitioning::RadixBitsOfPowerOfTwo(NextPowerOfTwo(active_threads)),\n+\t                MAXIMUM_FINAL_SINK_RADIX_BITS);\n }\n \n idx_t RadixHTConfig::SinkCapacity(ClientContext &context) {\n@@ -370,7 +365,9 @@ bool MaybeRepartition(ClientContext &context, RadixHTGlobalSinkState &gstate, Ra\n \n \t// Check if we're approaching the memory limit\n \tauto &temporary_memory_state = *gstate.temporary_memory_state;\n-\tconst auto total_size = partitioned_data->SizeInBytes() + ht.Capacity() * sizeof(ht_entry_t);\n+\tconst auto aggregate_allocator_size = ht.GetAggregateAllocator()->AllocationSize();\n+\tconst auto total_size =\n+\t    aggregate_allocator_size + partitioned_data->SizeInBytes() + ht.Capacity() * sizeof(ht_entry_t);\n \tidx_t thread_limit = temporary_memory_state.GetReservation() / gstate.number_of_threads;\n \tif (total_size > thread_limit) {\n \t\t// We're over the thread memory limit\n@@ -379,7 +376,9 @@ bool MaybeRepartition(ClientContext &context, RadixHTGlobalSinkState &gstate, Ra\n \t\t\tauto guard = gstate.Lock();\n \t\t\tthread_limit = temporary_memory_state.GetReservation() / gstate.number_of_threads;\n \t\t\tif (total_size > thread_limit) {\n-\t\t\t\t// Out-of-core would be triggered below, try to increase the reservation\n+\t\t\t\t// Out-of-core would be triggered below, update minimum reservation and try to increase the reservation\n+\t\t\t\ttemporary_memory_state.SetMinimumReservation(aggregate_allocator_size * gstate.number_of_threads +\n+\t\t\t\t                                             gstate.minimum_reservation);\n \t\t\t\tauto remaining_size =\n \t\t\t\t    MaxValue<idx_t>(gstate.number_of_threads * total_size, temporary_memory_state.GetRemainingSize());\n \t\t\t\ttemporary_memory_state.SetRemainingSizeAndUpdateReservation(context, 2 * remaining_size);\n@@ -411,7 +410,7 @@ bool MaybeRepartition(ClientContext &context, RadixHTGlobalSinkState &gstate, Ra\n \t}\n \n \tconst auto partition_count = partitioned_data->PartitionCount();\n-\tconst auto current_radix_bits = RadixPartitioning::RadixBits(partition_count);\n+\tconst auto current_radix_bits = RadixPartitioning::RadixBitsOfPowerOfTwo(partition_count);\n \tD_ASSERT(current_radix_bits <= config.GetRadixBits());\n \n \tconst auto block_size = BufferManager::GetBufferManager(context).GetBlockSize();\n@@ -441,7 +440,8 @@ void RadixPartitionedHashTable::Sink(ExecutionContext &context, DataChunk &chunk\n \tauto &gstate = input.global_state.Cast<RadixHTGlobalSinkState>();\n \tauto &lstate = input.local_state.Cast<RadixHTLocalSinkState>();\n \tif (!lstate.ht) {\n-\t\tlstate.ht = CreateHT(context.client, gstate.config.sink_capacity, gstate.config.GetRadixBits());\n+\t\tlstate.ht =\n+\t\t    CreateHT(context.client, GroupedAggregateHashTable::InitialCapacity(), gstate.config.GetRadixBits());\n \t\tgstate.active_threads++;\n \t}\n \n@@ -451,11 +451,11 @@ void RadixPartitionedHashTable::Sink(ExecutionContext &context, DataChunk &chunk\n \tauto &ht = *lstate.ht;\n \tht.AddChunk(group_chunk, payload_input, filter);\n \n-\tif (ht.Count() + STANDARD_VECTOR_SIZE < ht.ResizeThreshold()) {\n+\tif (ht.Count() + STANDARD_VECTOR_SIZE < GroupedAggregateHashTable::ResizeThreshold(gstate.config.sink_capacity)) {\n \t\treturn; // We can fit another chunk\n \t}\n \n-\tif (gstate.number_of_threads > 2) {\n+\tif (gstate.number_of_threads > 2 || gstate.external) {\n \t\t// 'Reset' the HT without taking its data, we can just keep appending to the same collection\n \t\t// This only works because we never resize the HT\n \t\tht.ClearPointerTable();\n@@ -470,6 +470,9 @@ void RadixPartitionedHashTable::Sink(ExecutionContext &context, DataChunk &chunk\n \t\t// We repartitioned, but we didn't clear the pointer table / reset the count because we're on 1 or 2 threads\n \t\tht.ClearPointerTable();\n \t\tht.ResetCount();\n+\t\tif (gstate.external) {\n+\t\t\tht.Resize(gstate.config.sink_capacity);\n+\t\t}\n \t}\n \n \t// TODO: combine early and often\n@@ -507,6 +510,7 @@ void RadixPartitionedHashTable::Combine(ExecutionContext &context, GlobalSinkSta\n \t\tgstate.uncombined_data = std::move(lstate.abandoned_data);\n \t}\n \tgstate.stored_allocators.emplace_back(ht.GetAggregateAllocator());\n+\tgstate.stored_allocators_size += gstate.stored_allocators.back()->AllocationSize();\n }\n \n void RadixPartitionedHashTable::Finalize(ClientContext &context, GlobalSinkState &gstate_p) const {\n@@ -541,7 +545,7 @@ void RadixPartitionedHashTable::Finalize(ClientContext &context, GlobalSinkState\n \t}\n \n \t// Minimum of combining one partition at a time\n-\tgstate.temporary_memory_state->SetMinimumReservation(gstate.max_partition_size);\n+\tgstate.temporary_memory_state->SetMinimumReservation(gstate.stored_allocators_size + gstate.max_partition_size);\n \t// Set size to 0 until the scan actually starts\n \tgstate.temporary_memory_state->SetZero();\n \tgstate.finalized = true;\n@@ -558,12 +562,15 @@ idx_t RadixPartitionedHashTable::MaxThreads(GlobalSinkState &sink_p) const {\n \n \tconst auto max_threads = MinValue<idx_t>(\n \t    NumericCast<idx_t>(TaskScheduler::GetScheduler(sink.context).NumberOfThreads()), sink.partitions.size());\n-\tsink.temporary_memory_state->SetRemainingSizeAndUpdateReservation(sink.context,\n-\t                                                                  max_threads * sink.max_partition_size);\n+\tsink.temporary_memory_state->SetRemainingSizeAndUpdateReservation(\n+\t    sink.context, sink.stored_allocators_size + max_threads * sink.max_partition_size);\n \n+\t// we cannot spill aggregate state memory\n+\tconst auto usable_memory = sink.temporary_memory_state->GetReservation() > sink.stored_allocators_size\n+\t                               ? sink.temporary_memory_state->GetReservation() - sink.max_partition_size\n+\t                               : 0;\n \t// This many partitions will fit given our reservation (at least 1))\n-\tconst auto partitions_fit =\n-\t    MaxValue<idx_t>(sink.temporary_memory_state->GetReservation() / sink.max_partition_size, 1);\n+\tconst auto partitions_fit = MaxValue<idx_t>(usable_memory / sink.max_partition_size, 1);\n \n \t// Mininum of the two\n \treturn MinValue<idx_t>(partitions_fit, max_threads);\ndiff --git a/src/function/aggregate/distributive/first.cpp b/src/function/aggregate/distributive/first.cpp\nindex 86d3e4bcb3e9..cbd63116f677 100644\n--- a/src/function/aggregate/distributive/first.cpp\n+++ b/src/function/aggregate/distributive/first.cpp\n@@ -1,7 +1,7 @@\n #include \"duckdb/common/exception.hpp\"\n #include \"duckdb/common/vector_operations/vector_operations.hpp\"\n-#include \"duckdb/function/create_sort_key.hpp\"\n #include \"duckdb/function/aggregate/distributive_functions.hpp\"\n+#include \"duckdb/function/create_sort_key.hpp\"\n #include \"duckdb/planner/expression.hpp\"\n \n namespace duckdb {\n@@ -68,7 +68,7 @@ struct FirstFunction : public FirstFunctionBase {\n \n template <bool LAST, bool SKIP_NULLS>\n struct FirstFunctionStringBase : public FirstFunctionBase {\n-\ttemplate <class STATE>\n+\ttemplate <class STATE, bool COMBINE = false>\n \tstatic void SetValue(STATE &state, AggregateInputData &input_data, string_t value, bool is_null) {\n \t\tif (LAST && state.is_set) {\n \t\t\tDestroy(state, input_data);\n@@ -81,7 +81,9 @@ struct FirstFunctionStringBase : public FirstFunctionBase {\n \t\t} else {\n \t\t\tstate.is_set = true;\n \t\t\tstate.is_null = false;\n-\t\t\tif (value.IsInlined()) {\n+\t\t\tif ((COMBINE && !LAST) || value.IsInlined()) {\n+\t\t\t\t// We use the aggregate allocator for 'first', so the allocation is already done when combining\n+\t\t\t\t// Of course, if the value is inlined, we also don't need to allocate\n \t\t\t\tstate.value = value;\n \t\t\t} else {\n \t\t\t\t// non-inlined string, need to allocate space for it\n@@ -97,7 +99,7 @@ struct FirstFunctionStringBase : public FirstFunctionBase {\n \ttemplate <class STATE, class OP>\n \tstatic void Combine(const STATE &source, STATE &target, AggregateInputData &input_data) {\n \t\tif (source.is_set && (LAST || !target.is_set)) {\n-\t\t\tSetValue(target, input_data, source.value, source.is_null);\n+\t\t\tSetValue<STATE, true>(target, input_data, source.value, source.is_null);\n \t\t}\n \t}\n \ndiff --git a/src/include/duckdb/common/file_buffer.hpp b/src/include/duckdb/common/file_buffer.hpp\nindex 1a3e6e9cb081..f32a2c416972 100644\n--- a/src/include/duckdb/common/file_buffer.hpp\n+++ b/src/include/duckdb/common/file_buffer.hpp\n@@ -17,7 +17,7 @@ struct FileHandle;\n \n enum class FileBufferType : uint8_t { BLOCK = 1, MANAGED_BUFFER = 2, TINY_BUFFER = 3 };\n \n-static constexpr const idx_t FILE_BUFFER_TYPE_COUNT = 3;\n+static constexpr idx_t FILE_BUFFER_TYPE_COUNT = 3;\n \n //! The FileBuffer represents a buffer that can be read or written to a Direct IO FileHandle.\n class FileBuffer {\ndiff --git a/src/include/duckdb/common/radix_partitioning.hpp b/src/include/duckdb/common/radix_partitioning.hpp\nindex aa5efc2860f1..66b74ef7a4a2 100644\n--- a/src/include/duckdb/common/radix_partitioning.hpp\n+++ b/src/include/duckdb/common/radix_partitioning.hpp\n@@ -8,7 +8,7 @@\n \n #pragma once\n \n-#include \"duckdb/common/fast_mem.hpp\"\n+#include \"duckdb/common/bit_utils.hpp\"\n #include \"duckdb/common/types/column/partitioned_column_data.hpp\"\n #include \"duckdb/common/types/row/partitioned_tuple_data.hpp\"\n \n@@ -30,15 +30,15 @@ struct RadixPartitioning {\n \t\treturn idx_t(1) << radix_bits;\n \t}\n \n+\ttemplate <class T>\n+\tstatic inline idx_t RadixBits(T n) {\n+\t\treturn sizeof(T) * 8 - CountZeros<T>::Leading(n);\n+\t}\n+\n \t//! Inverse of NumberOfPartitions, given a number of partitions, get the number of radix bits\n-\tstatic inline idx_t RadixBits(idx_t n_partitions) {\n+\tstatic inline idx_t RadixBitsOfPowerOfTwo(idx_t n_partitions) {\n \t\tD_ASSERT(IsPowerOfTwo(n_partitions));\n-\t\tfor (idx_t r = 0; r < sizeof(idx_t) * 8; r++) {\n-\t\t\tif (n_partitions == NumberOfPartitions(r)) {\n-\t\t\t\treturn r;\n-\t\t\t}\n-\t\t}\n-\t\tthrow InternalException(\"RadixPartitioning::RadixBits unable to find partition count!\");\n+\t\treturn RadixBits(n_partitions) - 1;\n \t}\n \n \t//! Radix bits begin after uint16_t because these bits are used as salt in the aggregate HT\n@@ -132,9 +132,6 @@ class RadixPartitionedTupleData : public PartitionedTupleData {\n \t\treturn RadixPartitioning::NumberOfPartitions(radix_bits) - 1;\n \t}\n \n-\tbool RepartitionReverseOrder() const override {\n-\t\treturn true;\n-\t}\n \tvoid RepartitionFinalizeStates(PartitionedTupleData &old_partitioned_data,\n \t                               PartitionedTupleData &new_partitioned_data, PartitionedTupleDataAppendState &state,\n \t                               idx_t finished_partition_idx) const override;\ndiff --git a/src/include/duckdb/common/types/column/column_data_allocator.hpp b/src/include/duckdb/common/types/column/column_data_allocator.hpp\nindex 194b40ca3ea1..38a29532013d 100644\n--- a/src/include/duckdb/common/types/column/column_data_allocator.hpp\n+++ b/src/include/duckdb/common/types/column/column_data_allocator.hpp\n@@ -62,6 +62,12 @@ class ColumnDataAllocator {\n \tidx_t AllocationSize() const {\n \t\treturn allocated_size;\n \t}\n+\t//! Sets the partition index of this tuple data collection\n+\tvoid SetPartitionIndex(idx_t index) {\n+\t\tD_ASSERT(!partition_index.IsValid());\n+\t\tD_ASSERT(blocks.empty() && allocated_data.empty());\n+\t\tpartition_index = index;\n+\t}\n \n public:\n \tvoid AllocateData(idx_t size, uint32_t &block_id, uint32_t &offset, ChunkManagementState *chunk_state);\n@@ -107,6 +113,8 @@ class ColumnDataAllocator {\n \tmutex lock;\n \t//! Total allocated size\n \tidx_t allocated_size = 0;\n+\t//! Partition index (optional, if partitioned)\n+\toptional_idx partition_index;\n };\n \n } // namespace duckdb\ndiff --git a/src/include/duckdb/common/types/column/column_data_collection.hpp b/src/include/duckdb/common/types/column/column_data_collection.hpp\nindex 571826617a3d..f02d4900169a 100644\n--- a/src/include/duckdb/common/types/column/column_data_collection.hpp\n+++ b/src/include/duckdb/common/types/column/column_data_collection.hpp\n@@ -65,6 +65,8 @@ class ColumnDataCollection {\n \tidx_t SizeInBytes() const;\n \t//! The allocation size (in bytes) of this ColumnDataCollection - this property is cached\n \tidx_t AllocationSize() const;\n+\t//! Sets the partition index of this ColumnDataCollection\n+\tvoid SetPartitionIndex(idx_t index);\n \n \t//! Get the allocator\n \tDUCKDB_API Allocator &GetAllocator() const;\n@@ -185,6 +187,8 @@ class ColumnDataCollection {\n \tvector<ColumnDataCopyFunction> copy_functions;\n \t//! When the column data collection is marked as finished - new tuples can no longer be appended to it\n \tbool finished_append;\n+\t//! Partition index (optional, if partitioned)\n+\toptional_idx partition_index;\n };\n \n //! The ColumnDataRowCollection represents a set of materialized rows, as obtained from the ColumnDataCollection\ndiff --git a/src/include/duckdb/common/types/row/partitioned_tuple_data.hpp b/src/include/duckdb/common/types/row/partitioned_tuple_data.hpp\nindex 999c7218a31d..878b1bfa095d 100644\n--- a/src/include/duckdb/common/types/row/partitioned_tuple_data.hpp\n+++ b/src/include/duckdb/common/types/row/partitioned_tuple_data.hpp\n@@ -153,10 +153,6 @@ class PartitionedTupleData {\n \t\treturn DConstants::INVALID_INDEX;\n \t}\n \n-\t//! Whether or not to iterate over the original partitions in reverse order when repartitioning (optional)\n-\tvirtual bool RepartitionReverseOrder() const {\n-\t\treturn false;\n-\t}\n \t//! Finalize states while repartitioning - useful for unpinning blocks that are no longer needed (optional)\n \tvirtual void RepartitionFinalizeStates(PartitionedTupleData &old_partitioned_data,\n \t                                       PartitionedTupleData &new_partitioned_data,\ndiff --git a/src/include/duckdb/common/types/row/tuple_data_allocator.hpp b/src/include/duckdb/common/types/row/tuple_data_allocator.hpp\nindex 840d48602152..b68d3606b62c 100644\n--- a/src/include/duckdb/common/types/row/tuple_data_allocator.hpp\n+++ b/src/include/duckdb/common/types/row/tuple_data_allocator.hpp\n@@ -67,6 +67,8 @@ class TupleDataAllocator {\n \tidx_t RowBlockCount() const;\n \t//! Number of heap blocks\n \tidx_t HeapBlockCount() const;\n+\t//! Sets the partition index of this tuple data allocator\n+\tvoid SetPartitionIndex(idx_t index);\n \n public:\n \t//! Builds out the chunks for next append, given the metadata in the append state\n@@ -113,6 +115,8 @@ class TupleDataAllocator {\n \tBufferManager &buffer_manager;\n \t//! The layout of the data\n \tconst TupleDataLayout layout;\n+\t//! Partition index (optional, if partitioned)\n+\toptional_idx partition_index;\n \t//! Blocks storing the fixed-size rows\n \tunsafe_vector<TupleDataBlock> row_blocks;\n \t//! Blocks storing the variable-size data of the fixed-size rows (e.g., string, list)\ndiff --git a/src/include/duckdb/common/types/row/tuple_data_collection.hpp b/src/include/duckdb/common/types/row/tuple_data_collection.hpp\nindex b87b4002401f..71b70092231f 100644\n--- a/src/include/duckdb/common/types/row/tuple_data_collection.hpp\n+++ b/src/include/duckdb/common/types/row/tuple_data_collection.hpp\n@@ -66,6 +66,8 @@ class TupleDataCollection {\n \tidx_t SizeInBytes() const;\n \t//! Unpins all held pins\n \tvoid Unpin();\n+\t//! Sets the partition index of this tuple data collection\n+\tvoid SetPartitionIndex(idx_t index);\n \n \t//! Gets the scatter function for the given type\n \tstatic TupleDataScatterFunction GetScatterFunction(const LogicalType &type, bool within_collection = false);\n@@ -252,6 +254,8 @@ class TupleDataCollection {\n \tvector<TupleDataScatterFunction> scatter_functions;\n \t//! The set of gather functions\n \tvector<TupleDataGatherFunction> gather_functions;\n+\t//! Partition index (optional, if partitioned)\n+\toptional_idx partition_index;\n };\n \n } // namespace duckdb\ndiff --git a/src/include/duckdb/execution/aggregate_hashtable.hpp b/src/include/duckdb/execution/aggregate_hashtable.hpp\nindex 2b424152f2c1..ac3c4a00ace0 100644\n--- a/src/include/duckdb/execution/aggregate_hashtable.hpp\n+++ b/src/include/duckdb/execution/aggregate_hashtable.hpp\n@@ -57,6 +57,7 @@ class GroupedAggregateHashTable : public BaseAggregateHashTable {\n \tidx_t Capacity() const;\n \t//! Threshold at which to resize the HT\n \tidx_t ResizeThreshold() const;\n+\tstatic idx_t ResizeThreshold(idx_t capacity);\n \n \t//! Add the given data to the HT, computing the aggregates grouped by the\n \t//! data in the group chunk. When resize = true, aggregates will not be\ndiff --git a/src/include/duckdb/storage/buffer/block_handle.hpp b/src/include/duckdb/storage/buffer/block_handle.hpp\nindex be1128faebad..1b07ff0f643c 100644\n--- a/src/include/duckdb/storage/buffer/block_handle.hpp\n+++ b/src/include/duckdb/storage/buffer/block_handle.hpp\n@@ -15,6 +15,7 @@\n #include \"duckdb/common/file_buffer.hpp\"\n #include \"duckdb/common/mutex.hpp\"\n #include \"duckdb/common/numeric_utils.hpp\"\n+#include \"duckdb/common/optional_idx.hpp\"\n #include \"duckdb/storage/storage_info.hpp\"\n \n namespace duckdb {\n@@ -116,10 +117,17 @@ class BlockHandle : public enable_shared_from_this<BlockHandle> {\n \tinline const idx_t &GetMemoryUsage() const {\n \t\treturn memory_usage;\n \t}\n+\n \tbool IsUnloaded() {\n \t\treturn state == BlockState::BLOCK_UNLOADED;\n \t}\n \n+\tvoid SetEvictionQueueIndex(const idx_t index) {\n+\t\tD_ASSERT(!eviction_queue_idx.IsValid());                  // Cannot overwrite\n+\t\tD_ASSERT(buffer->type == FileBufferType::MANAGED_BUFFER); // MANAGED_BUFFER only (at least, for now)\n+\t\teviction_queue_idx = index;\n+\t}\n+\n private:\n \tBufferHandle Load(unique_ptr<FileBuffer> buffer = nullptr);\n \tBufferHandle LoadFromBuffer(data_ptr_t data, unique_ptr<FileBuffer> reusable_buffer);\n@@ -152,6 +160,8 @@ class BlockHandle : public enable_shared_from_this<BlockHandle> {\n \tBufferPoolReservation memory_charge;\n \t//! Does the block contain any memory pointers?\n \tconst char *unswizzled;\n+\t//! Index for eviction queue (FileBufferType::MANAGED_BUFFER only, for now)\n+\toptional_idx eviction_queue_idx;\n };\n \n } // namespace duckdb\ndiff --git a/src/include/duckdb/storage/buffer/buffer_pool.hpp b/src/include/duckdb/storage/buffer/buffer_pool.hpp\nindex 50166a51fa05..f4548e4305e2 100644\n--- a/src/include/duckdb/storage/buffer/buffer_pool.hpp\n+++ b/src/include/duckdb/storage/buffer/buffer_pool.hpp\n@@ -82,14 +82,21 @@ class BufferPool {\n \tidx_t PurgeAgedBlocks(uint32_t max_age_sec);\n \tidx_t PurgeAgedBlocksInternal(EvictionQueue &queue, uint32_t max_age_sec, int64_t now, int64_t limit);\n \t//! Garbage collect dead nodes in the eviction queue.\n-\tvoid PurgeQueue(FileBufferType type);\n+\tvoid PurgeQueue(const BlockHandle &handle);\n \t//! Add a buffer handle to the eviction queue. Returns true, if the queue is\n \t//! ready to be purged, and false otherwise.\n \tbool AddToEvictionQueue(shared_ptr<BlockHandle> &handle);\n \t//! Gets the eviction queue for the specified type\n-\tEvictionQueue &GetEvictionQueueForType(FileBufferType type);\n+\tEvictionQueue &GetEvictionQueueForBlockHandle(const BlockHandle &handle);\n \t//! Increments the dead nodes for the queue with specified type\n-\tvoid IncrementDeadNodes(FileBufferType type);\n+\tvoid IncrementDeadNodes(const BlockHandle &handle);\n+\n+\t//! How many eviction queues we have for the different FileBufferTypes\n+\tstatic constexpr idx_t BLOCK_QUEUE_SIZE = 1;\n+\tstatic constexpr idx_t MANAGED_BUFFER_QUEUE_SIZE = 6;\n+\tstatic constexpr idx_t TINY_BUFFER_QUEUE_SIZE = 1;\n+\t//! Mapping and priority order for the eviction queues\n+\tconst array<idx_t, FILE_BUFFER_TYPE_COUNT> eviction_queue_sizes;\n \n protected:\n \tenum class MemoryUsageCaches {\ndiff --git a/src/include/duckdb/storage/buffer_manager.hpp b/src/include/duckdb/storage/buffer_manager.hpp\nindex e2a3b95e0775..16708416e83f 100644\n--- a/src/include/duckdb/storage/buffer_manager.hpp\n+++ b/src/include/duckdb/storage/buffer_manager.hpp\n@@ -98,7 +98,7 @@ class BufferManager {\n \tvirtual TemporaryMemoryManager &GetTemporaryMemoryManager();\n \n protected:\n-\tvirtual void PurgeQueue(FileBufferType type) = 0;\n+\tvirtual void PurgeQueue(const BlockHandle &handle) = 0;\n \tvirtual void AddToEvictionQueue(shared_ptr<BlockHandle> &handle);\n \tvirtual void WriteTemporaryBuffer(MemoryTag tag, block_id_t block_id, FileBuffer &buffer);\n \tvirtual unique_ptr<FileBuffer> ReadTemporaryBuffer(MemoryTag tag, BlockHandle &block,\ndiff --git a/src/include/duckdb/storage/standard_buffer_manager.hpp b/src/include/duckdb/storage/standard_buffer_manager.hpp\nindex e4de96089b6a..ef52365fa5ea 100644\n--- a/src/include/duckdb/storage/standard_buffer_manager.hpp\n+++ b/src/include/duckdb/storage/standard_buffer_manager.hpp\n@@ -120,7 +120,7 @@ class StandardBufferManager : public BufferManager {\n \tshared_ptr<BlockHandle> RegisterMemory(MemoryTag tag, idx_t block_size, bool can_destroy);\n \n \t//! Garbage collect eviction queue\n-\tvoid PurgeQueue(FileBufferType type) final;\n+\tvoid PurgeQueue(const BlockHandle &handle) final;\n \n \tBufferPool &GetBufferPool() const final;\n \tTemporaryMemoryManager &GetTemporaryMemoryManager() final;\ndiff --git a/src/storage/buffer/block_handle.cpp b/src/storage/buffer/block_handle.cpp\nindex 9523b2962560..8a24834a808f 100644\n--- a/src/storage/buffer/block_handle.cpp\n+++ b/src/storage/buffer/block_handle.cpp\n@@ -36,7 +36,7 @@ BlockHandle::~BlockHandle() { // NOLINT: allow internal exceptions\n \tif (buffer && buffer->type != FileBufferType::TINY_BUFFER) {\n \t\t// we kill the latest version in the eviction queue\n \t\tauto &buffer_manager = block_manager.buffer_manager;\n-\t\tbuffer_manager.GetBufferPool().IncrementDeadNodes(buffer->type);\n+\t\tbuffer_manager.GetBufferPool().IncrementDeadNodes(*this);\n \t}\n \n \t// no references remain to this block: erase\ndiff --git a/src/storage/buffer/block_manager.cpp b/src/storage/buffer/block_manager.cpp\nindex 22cb54d13572..2f7839179aa4 100644\n--- a/src/storage/buffer/block_manager.cpp\n+++ b/src/storage/buffer/block_manager.cpp\n@@ -64,7 +64,7 @@ shared_ptr<BlockHandle> BlockManager::ConvertToPersistent(block_id_t block_id, s\n \t// potentially purge the queue\n \tauto purge_queue = buffer_manager.GetBufferPool().AddToEvictionQueue(new_block);\n \tif (purge_queue) {\n-\t\tbuffer_manager.GetBufferPool().PurgeQueue(new_block->buffer->type);\n+\t\tbuffer_manager.GetBufferPool().PurgeQueue(*new_block);\n \t}\n \n \treturn new_block;\ndiff --git a/src/storage/buffer/buffer_pool.cpp b/src/storage/buffer/buffer_pool.cpp\nindex 9ed31f6f3262..607ef09db464 100644\n--- a/src/storage/buffer/buffer_pool.cpp\n+++ b/src/storage/buffer/buffer_pool.cpp\n@@ -41,7 +41,8 @@ typedef duckdb_moodycamel::ConcurrentQueue<BufferEvictionNode> eviction_queue_t;\n \n struct EvictionQueue {\n public:\n-\tEvictionQueue() : evict_queue_insertions(0), total_dead_nodes(0) {\n+\texplicit EvictionQueue(const FileBufferType file_buffer_type_p)\n+\t    : file_buffer_type(file_buffer_type_p), evict_queue_insertions(0), total_dead_nodes(0) {\n \t}\n \n public:\n@@ -69,6 +70,8 @@ struct EvictionQueue {\n \tvoid PurgeIteration(const idx_t purge_size);\n \n public:\n+\t//! The type of the buffers in this queue\n+\tconst FileBufferType file_buffer_type;\n \t//! The concurrent queue\n \teviction_queue_t q;\n \n@@ -196,20 +199,24 @@ void EvictionQueue::PurgeIteration(const idx_t purge_size) {\n \n BufferPool::BufferPool(idx_t maximum_memory, bool track_eviction_timestamps,\n                        idx_t allocator_bulk_deallocation_flush_threshold)\n-    : maximum_memory(maximum_memory),\n+    : eviction_queue_sizes({BLOCK_QUEUE_SIZE, MANAGED_BUFFER_QUEUE_SIZE, TINY_BUFFER_QUEUE_SIZE}),\n+      maximum_memory(maximum_memory),\n       allocator_bulk_deallocation_flush_threshold(allocator_bulk_deallocation_flush_threshold),\n       track_eviction_timestamps(track_eviction_timestamps),\n       temporary_memory_manager(make_uniq<TemporaryMemoryManager>()) {\n-\tqueues.reserve(FILE_BUFFER_TYPE_COUNT);\n-\tfor (idx_t i = 0; i < FILE_BUFFER_TYPE_COUNT; i++) {\n-\t\tqueues.push_back(make_uniq<EvictionQueue>());\n+\tfor (uint8_t type_idx = 0; type_idx < FILE_BUFFER_TYPE_COUNT; type_idx++) {\n+\t\tconst auto type = static_cast<FileBufferType>(type_idx + 1);\n+\t\tconst auto &type_queue_size = eviction_queue_sizes[type_idx];\n+\t\tfor (idx_t queue_idx = 0; queue_idx < type_queue_size; queue_idx++) {\n+\t\t\tqueues.push_back(make_uniq<EvictionQueue>(type));\n+\t\t}\n \t}\n }\n BufferPool::~BufferPool() {\n }\n \n bool BufferPool::AddToEvictionQueue(shared_ptr<BlockHandle> &handle) {\n-\tauto &queue = GetEvictionQueueForType(handle->buffer->type);\n+\tauto &queue = GetEvictionQueueForBlockHandle(*handle);\n \n \t// The block handle is locked during this operation (Unpin),\n \t// or the block handle is still a local variable (ConvertToPersistent)\n@@ -227,16 +234,36 @@ bool BufferPool::AddToEvictionQueue(shared_ptr<BlockHandle> &handle) {\n \t\tqueue.IncrementDeadNodes();\n \t}\n \n-\t// Get the eviction queue for the buffer type and add it\n+\t// Get the eviction queue for the block and add it\n \treturn queue.AddToEvictionQueue(BufferEvictionNode(weak_ptr<BlockHandle>(handle), ts));\n }\n \n-EvictionQueue &BufferPool::GetEvictionQueueForType(FileBufferType type) {\n-\treturn *queues[uint8_t(type) - 1];\n+EvictionQueue &BufferPool::GetEvictionQueueForBlockHandle(const BlockHandle &handle) {\n+\tconst auto &handle_buffer_type = handle.buffer->type;\n+\n+\t// Get offset into eviction queues for this FileBufferType\n+\tidx_t queue_index = 0;\n+\tfor (uint8_t type_idx = 0; type_idx < FILE_BUFFER_TYPE_COUNT; type_idx++) {\n+\t\tconst auto queue_buffer_type = static_cast<FileBufferType>(type_idx + 1);\n+\t\tif (handle_buffer_type == queue_buffer_type) {\n+\t\t\tbreak;\n+\t\t}\n+\t\tconst auto &type_queue_size = eviction_queue_sizes[type_idx];\n+\t\tqueue_index += type_queue_size;\n+\t}\n+\n+\tconst auto &queue_size = eviction_queue_sizes[static_cast<uint8_t>(handle_buffer_type) - 1];\n+\t// Adjust if eviction_queue_idx is set (idx == 0 -> add at back, idx >= queue_size -> add at front)\n+\tif (handle.eviction_queue_idx.IsValid() && handle.eviction_queue_idx.GetIndex() < queue_size) {\n+\t\tqueue_index += queue_size - handle.eviction_queue_idx.GetIndex() - 1;\n+\t}\n+\n+\tD_ASSERT(queues[queue_index]->file_buffer_type == handle_buffer_type);\n+\treturn *queues[queue_index];\n }\n \n-void BufferPool::IncrementDeadNodes(FileBufferType type) {\n-\tGetEvictionQueueForType(type).IncrementDeadNodes();\n+void BufferPool::IncrementDeadNodes(const BlockHandle &handle) {\n+\tGetEvictionQueueForBlockHandle(handle).IncrementDeadNodes();\n }\n \n void BufferPool::UpdateUsedMemory(MemoryTag tag, int64_t size) {\n@@ -261,23 +288,14 @@ TemporaryMemoryManager &BufferPool::GetTemporaryMemoryManager() {\n \n BufferPool::EvictionResult BufferPool::EvictBlocks(MemoryTag tag, idx_t extra_memory, idx_t memory_limit,\n                                                    unique_ptr<FileBuffer> *buffer) {\n-\t// First, we try to evict persistent table data\n-\tauto block_result =\n-\t    EvictBlocksInternal(GetEvictionQueueForType(FileBufferType::BLOCK), tag, extra_memory, memory_limit, buffer);\n-\tif (block_result.success) {\n-\t\treturn block_result;\n-\t}\n-\n-\t// If that does not succeed, we try to evict temporary data\n-\tauto managed_buffer_result = EvictBlocksInternal(GetEvictionQueueForType(FileBufferType::MANAGED_BUFFER), tag,\n-\t                                                 extra_memory, memory_limit, buffer);\n-\tif (managed_buffer_result.success) {\n-\t\treturn managed_buffer_result;\n+\tfor (auto &queue : queues) {\n+\t\tauto block_result = EvictBlocksInternal(*queue, tag, extra_memory, memory_limit, buffer);\n+\t\tif (block_result.success || RefersToSameObject(*queue, *queues.back())) {\n+\t\t\treturn block_result; // Return upon success or upon last queue\n+\t\t}\n \t}\n-\n-\t// Finally, we try to evict tiny buffers\n-\treturn EvictBlocksInternal(GetEvictionQueueForType(FileBufferType::TINY_BUFFER), tag, extra_memory, memory_limit,\n-\t                           buffer);\n+\t// This can never happen since we always return when i == 1. Exception to silence compiler warning\n+\tthrow InternalException(\"Exited BufferPool::EvictBlocksInternal without obtaining BufferPool::EvictionResult\");\n }\n \n BufferPool::EvictionResult BufferPool::EvictBlocksInternal(EvictionQueue &queue, MemoryTag tag, idx_t extra_memory,\n@@ -381,8 +399,8 @@ void EvictionQueue::IterateUnloadableBlocks(FN fn) {\n \t}\n }\n \n-void BufferPool::PurgeQueue(FileBufferType type) {\n-\tGetEvictionQueueForType(type).Purge();\n+void BufferPool::PurgeQueue(const BlockHandle &block) {\n+\tGetEvictionQueueForBlockHandle(block).Purge();\n }\n \n void BufferPool::SetLimit(idx_t limit, const char *exception_postscript) {\ndiff --git a/src/storage/standard_buffer_manager.cpp b/src/storage/standard_buffer_manager.cpp\nindex da10afce297d..9b4c305d40a4 100644\n--- a/src/storage/standard_buffer_manager.cpp\n+++ b/src/storage/standard_buffer_manager.cpp\n@@ -356,8 +356,8 @@ BufferHandle StandardBufferManager::Pin(shared_ptr<BlockHandle> &handle) {\n \treturn buf;\n }\n \n-void StandardBufferManager::PurgeQueue(FileBufferType type) {\n-\tbuffer_pool.PurgeQueue(type);\n+void StandardBufferManager::PurgeQueue(const BlockHandle &handle) {\n+\tbuffer_pool.PurgeQueue(handle);\n }\n \n void StandardBufferManager::AddToEvictionQueue(shared_ptr<BlockHandle> &handle) {\n@@ -395,7 +395,7 @@ void StandardBufferManager::Unpin(shared_ptr<BlockHandle> &handle) {\n \n \t// We do not have to keep the handle locked while purging.\n \tif (purge) {\n-\t\tPurgeQueue(handle->buffer->type);\n+\t\tPurgeQueue(*handle);\n \t}\n }\n \n",
  "test_patch": "diff --git a/test/sql/aggregate/aggregates/first_memory_usage.test_slow b/test/sql/aggregate/aggregates/first_memory_usage.test_slow\nnew file mode 100644\nindex 000000000000..427c9f961ea5\n--- /dev/null\n+++ b/test/sql/aggregate/aggregates/first_memory_usage.test_slow\n@@ -0,0 +1,14 @@\n+# name: test/sql/aggregate/aggregates/first_memory_usage.test_slow\n+# description: Issue 14132 - Out of memory on basic hash aggregations with large values/aggregates\n+# group: [aggregates]\n+\n+load __TEST_DIR__/first_memory_usage.db\n+\n+statement ok\n+set memory_limit='400mb';\n+\n+# this query uses the first() aggregate, which used to use too much memory (it did redundant allocation in Combine)\n+# we also limit the number of threads in RadixPartitionedHashtable to limit memory usage when close to the limit\n+# we can now easily complete this query\n+statement ok\n+select distinct on (a) b from (select s a, md5(s::text) b from generate_series(1,10_000_000) as g(s)) limit 10;\n",
  "problem_statement": "Out of memory on basic hash aggregations with large values/aggregates\n### What happens?\r\n\r\nWe see persistent out of memory issues with certain hash aggregations and hash joins for slightly bigger data sets, which also reproduce on surprisingly simple queries.\r\n\r\nThe problem occurs if there are many groups and the values/aggregates, rather than the keys, are of non-trivial size (strings, geometries, etc.). The spilling to disk seems no longer effective in avoiding memory_limit.\r\n\r\nPossibly by design, but it's a very common scenario. \r\n\r\n### To Reproduce\r\n\r\nExample with 100M MD5 values, distinct on, Parquet:\r\n```sql\r\ncopy (select s a, md5(s::text) b from generate_series(1,100_000_000) as g(s)) to '/tmp/test.parquet';\r\nset memory_limit to '4GB';\r\nselect distinct on (a) b from '/tmp/test.parquet' limit 10;\r\n```\r\n```consoke\r\nOut of Memory Error: could not allocate block of size 256.0 KiB (3.7 GiB/3.7 GiB used)\r\n```\r\n\r\nExample with 1M long string values, group by, DuckDB table:\r\n```sql\r\ncreate table tbl as select s a, repeat('#', 10_000) b from generate_series(1,1_000_000) as g(s);\r\nset memory_limit to '4GB';\r\nselect a, max(b) from tbl group by a limit 10;\r\n```\r\n```console\r\nOut of Memory Error: could not allocate block of size 256.0 KiB (3.7 GiB/3.7 GiB used)\r\n```\r\n\r\nLarge key small value, e.g. `select distinct on (b) a from '/tmp/test.parquet' limit 10;` works fine.\r\n\r\nUsing a persistent database with max_temp_directory_size 400GB.\r\n\r\nAlso noted in https://news.ycombinator.com/item?id=40645100\r\n\r\n### OS:\r\n\r\nUbuntu 22.04 x86_64\r\n\r\n### DuckDB Version:\r\n\r\n1.1.1\r\n\r\n### DuckDB Client:\r\n\r\nCLI\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\nMarco Slot\r\n\r\n### Affiliation:\r\n\r\nCrunchy Data\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nNo - I cannot share the data sets because they are confidential\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\n",
  "hints_text": "",
  "created_at": "2024-10-15T12:26:20Z"
}