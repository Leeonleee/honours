You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
"Unimplemented type for LIST_EXTRACT" with column of type list<struct> 
```
select array_extract(assignedLicenses,0) from 'test.parquet';
Error: Not implemented Error: Unimplemented type for LIST_EXTRACT
```

Duckdb should return the first element of each list.
Minimal parquet file attached.
[test.parquet.zip](https://github.com/duckdb/duckdb/files/7156933/test.parquet.zip)


**Environment (please complete the following information):**
 - OS: MacOS 11.5
 - DuckDB Version: Mytherin:issue2267 (this fix needed to read the column in the first place)

**Before submitting**
- [x ] Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?
- [x] Have you tried this on the latest `master` branch? In case you cannot compile, you may find some binaries here: https://github.com/duckdb/duckdb/releases/tag/master-builds


</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
3: </div>
4: <p>&nbsp;</p>
5: 
6: <p align="center">
7:   <a href="https://github.com/duckdb/duckdb/actions">
8:     <img src="https://github.com/cwida/duckdb/workflows/.github/workflows/main.yml/badge.svg?branch=master" alt=".github/workflows/main.yml">
9:   </a>
10:   <a href="https://www.codefactor.io/repository/github/cwida/duckdb">
11:     <img src="https://www.codefactor.io/repository/github/cwida/duckdb/badge" alt="CodeFactor"/>
12:   </a>
13:   <a href="https://app.codecov.io/gh/duckdb/duckdb">
14:     <img src="https://codecov.io/gh/duckdb/duckdb/branch/master/graph/badge.svg?token=FaxjcfFghN" alt="codecov"/>
15:   </a>
16: </p>
17: 
18: ## DuckDB
19: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on the goals of DuckDB, please refer to [the Why DuckDB page on our website](https://duckdb.org/docs/why_duckdb.html).
20: 
21: ## Installation
22: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
23: 
24: ## Data Import
25: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
26: 
27: ```sql
28: SELECT * FROM 'myfile.csv';
29: SELECT * FROM 'myfile.parquet';
30: ```
31: 
32: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
33: 
34: ## SQL Reference
35: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
36: 
37: ## Development
38: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`.
39: 
40: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
41: 
42: 
[end of README.md]
[start of src/function/scalar/list/list_extract.cpp]
1: #include "duckdb/planner/expression/bound_function_expression.hpp"
2: #include "duckdb/common/string_util.hpp"
3: #include "duckdb/common/vector_operations/binary_executor.hpp"
4: #include "duckdb/parser/expression/bound_expression.hpp"
5: #include "duckdb/function/scalar/nested_functions.hpp"
6: #include "duckdb/function/scalar/string_functions.hpp"
7: #include "duckdb/common/types/chunk_collection.hpp"
8: #include "duckdb/common/types/data_chunk.hpp"
9: #include "duckdb/common/pair.hpp"
10: #include "duckdb/storage/statistics/list_statistics.hpp"
11: #include "duckdb/storage/statistics/validity_statistics.hpp"
12: 
13: namespace duckdb {
14: 
15: template <class T, bool HEAP_REF = false>
16: void ListExtractTemplate(idx_t count, Vector &list, Vector &offsets, Vector &result) {
17: 	VectorData list_data, offsets_data, child_data;
18: 
19: 	list.Orrify(count, list_data);
20: 	offsets.Orrify(count, offsets_data);
21: 
22: 	result.SetVectorType(VectorType::FLAT_VECTOR);
23: 	auto result_data = FlatVector::GetData<T>(result);
24: 	auto &result_mask = FlatVector::Validity(result);
25: 
26: 	auto &vec = ListVector::GetEntry(list);
27: 	// heap-ref once
28: 	if (HEAP_REF) {
29: 		StringVector::AddHeapReference(result, vec);
30: 	}
31: 
32: 	// this is lifted from ExecuteGenericLoop because we can't push the list child data into this otherwise
33: 	// should have gone with GetValue perhaps
34: 	for (idx_t i = 0; i < count; i++) {
35: 		auto list_index = list_data.sel->get_index(i);
36: 		auto offsets_index = offsets_data.sel->get_index(i);
37: 		if (list_data.validity.RowIsValid(list_index) && offsets_data.validity.RowIsValid(offsets_index)) {
38: 			auto list_entry = ((list_entry_t *)list_data.data)[list_index];
39: 			auto offsets_entry = ((int64_t *)offsets_data.data)[offsets_index];
40: 			idx_t child_offset;
41: 			if (offsets_entry < 0) {
42: 				if ((idx_t)-offsets_entry > list_entry.length) {
43: 					result_mask.SetInvalid(i);
44: 					continue;
45: 				}
46: 				child_offset = list_entry.offset + list_entry.length + offsets_entry;
47: 			} else {
48: 				if ((idx_t)offsets_entry >= list_entry.length) {
49: 					result_mask.SetInvalid(i);
50: 					continue;
51: 				}
52: 				child_offset = list_entry.offset + offsets_entry;
53: 			}
54: 			vec.Orrify(ListVector::GetListSize(list), child_data);
55: 			if (child_data.validity.RowIsValid(child_offset)) {
56: 				result_data[i] = ((T *)child_data.data)[child_offset];
57: 			} else {
58: 				result_mask.SetInvalid(i);
59: 			}
60: 		} else {
61: 			result_mask.SetInvalid(i);
62: 		}
63: 	}
64: 	if (count == 1) {
65: 		result.SetVectorType(VectorType::CONSTANT_VECTOR);
66: 	}
67: }
68: 
69: static void ExecuteListExtract(Vector &result, Vector &list, Vector &offsets, const idx_t count) {
70: 	D_ASSERT(list.GetType().id() == LogicalTypeId::LIST);
71: 
72: 	switch (result.GetType().id()) {
73: 	case LogicalTypeId::UTINYINT:
74: 		ListExtractTemplate<uint8_t>(count, list, offsets, result);
75: 		break;
76: 	case LogicalTypeId::TINYINT:
77: 		ListExtractTemplate<int8_t>(count, list, offsets, result);
78: 		break;
79: 	case LogicalTypeId::USMALLINT:
80: 		ListExtractTemplate<uint16_t>(count, list, offsets, result);
81: 		break;
82: 	case LogicalTypeId::SMALLINT:
83: 		ListExtractTemplate<int16_t>(count, list, offsets, result);
84: 		break;
85: 	case LogicalTypeId::UINTEGER:
86: 		ListExtractTemplate<uint32_t>(count, list, offsets, result);
87: 		break;
88: 	case LogicalTypeId::INTEGER:
89: 		ListExtractTemplate<int32_t>(count, list, offsets, result);
90: 		break;
91: 	case LogicalTypeId::UBIGINT:
92: 		ListExtractTemplate<uint64_t>(count, list, offsets, result);
93: 		break;
94: 	case LogicalTypeId::BIGINT:
95: 		ListExtractTemplate<int64_t>(count, list, offsets, result);
96: 		break;
97: 	case LogicalTypeId::HUGEINT:
98: 		ListExtractTemplate<hugeint_t>(count, list, offsets, result);
99: 		break;
100: 	case LogicalTypeId::FLOAT:
101: 		ListExtractTemplate<float>(count, list, offsets, result);
102: 		break;
103: 	case LogicalTypeId::DOUBLE:
104: 		ListExtractTemplate<double>(count, list, offsets, result);
105: 		break;
106: 	case LogicalTypeId::DATE:
107: 		ListExtractTemplate<date_t>(count, list, offsets, result);
108: 		break;
109: 	case LogicalTypeId::TIME:
110: 		ListExtractTemplate<dtime_t>(count, list, offsets, result);
111: 		break;
112: 	case LogicalTypeId::TIMESTAMP:
113: 		ListExtractTemplate<timestamp_t>(count, list, offsets, result);
114: 		break;
115: 	case LogicalTypeId::BLOB:
116: 	case LogicalTypeId::VARCHAR:
117: 		ListExtractTemplate<string_t, true>(count, list, offsets, result);
118: 		break;
119: 	case LogicalTypeId::SQLNULL:
120: 		result.Reference(Value());
121: 		break;
122: 	case LogicalTypeId::LIST: {
123: 		// nested list: we have to reference the child
124: 		auto &child_list = ListVector::GetEntry(list);
125: 		auto &child_child_list = ListVector::GetEntry(child_list);
126: 
127: 		ListVector::GetEntry(result).Reference(child_child_list);
128: 		ListVector::SetListSize(result, ListVector::GetListSize(child_list));
129: 		ListExtractTemplate<list_entry_t>(count, list, offsets, result);
130: 		break;
131: 	}
132: 	default:
133: 		throw NotImplementedException("Unimplemented type for LIST_EXTRACT");
134: 	}
135: 
136: 	result.Verify(count);
137: }
138: 
139: static void ExecuteStringExtract(Vector &result, Vector &input_vector, Vector &subscript_vector, const idx_t count) {
140: 	BinaryExecutor::Execute<string_t, int32_t, string_t>(
141: 	    input_vector, subscript_vector, result, count, [&](string_t input_string, int32_t subscript) {
142: 		    return SubstringFun::SubstringScalarFunction(result, input_string, subscript + int32_t(subscript >= 0), 1);
143: 	    });
144: }
145: 
146: static void ListExtractFunction(DataChunk &args, ExpressionState &state, Vector &result) {
147: 	D_ASSERT(args.ColumnCount() == 2);
148: 	auto count = args.size();
149: 
150: 	result.SetVectorType(VectorType::CONSTANT_VECTOR);
151: 	for (idx_t i = 0; i < args.ColumnCount(); i++) {
152: 		if (args.data[i].GetVectorType() != VectorType::CONSTANT_VECTOR) {
153: 			result.SetVectorType(VectorType::FLAT_VECTOR);
154: 		}
155: 	}
156: 
157: 	Vector &base = args.data[0];
158: 	Vector &subscript = args.data[1];
159: 
160: 	switch (base.GetType().id()) {
161: 	case LogicalTypeId::LIST:
162: 		ExecuteListExtract(result, base, subscript, count);
163: 		break;
164: 	case LogicalTypeId::VARCHAR:
165: 		ExecuteStringExtract(result, base, subscript, count);
166: 		break;
167: 	default:
168: 		throw NotImplementedException("Specifier type not implemented");
169: 	}
170: }
171: 
172: static unique_ptr<FunctionData> ListExtractBind(ClientContext &context, ScalarFunction &bound_function,
173:                                                 vector<unique_ptr<Expression>> &arguments) {
174: 	D_ASSERT(bound_function.arguments.size() == 2);
175: 	D_ASSERT(LogicalTypeId::LIST == arguments[0]->return_type.id());
176: 	// list extract returns the child type of the list as return type
177: 	bound_function.return_type = ListType::GetChildType(arguments[0]->return_type);
178: 
179: 	return make_unique<VariableReturnBindData>(bound_function.return_type);
180: }
181: 
182: static unique_ptr<BaseStatistics> ListExtractStats(ClientContext &context, BoundFunctionExpression &expr,
183:                                                    FunctionData *bind_data,
184:                                                    vector<unique_ptr<BaseStatistics>> &child_stats) {
185: 	if (!child_stats[0]) {
186: 		return nullptr;
187: 	}
188: 	auto &list_stats = (ListStatistics &)*child_stats[0];
189: 	if (!list_stats.child_stats) {
190: 		return nullptr;
191: 	}
192: 	auto child_copy = list_stats.child_stats->Copy();
193: 	// list_extract always pushes a NULL, since if the offset is out of range for a list it inserts a null
194: 	child_copy->validity_stats = make_unique<ValidityStatistics>(true);
195: 	return child_copy;
196: }
197: 
198: void ListExtractFun::RegisterFunction(BuiltinFunctions &set) {
199: 	// the arguments and return types are actually set in the binder function
200: 	ScalarFunction lfun({LogicalType::LIST(LogicalType::ANY), LogicalType::BIGINT}, LogicalType::ANY,
201: 	                    ListExtractFunction, false, ListExtractBind, nullptr, ListExtractStats);
202: 
203: 	ScalarFunction sfun({LogicalType::VARCHAR, LogicalType::INTEGER}, LogicalType::VARCHAR, ListExtractFunction, false,
204: 	                    nullptr);
205: 
206: 	ScalarFunctionSet list_extract("list_extract");
207: 	list_extract.AddFunction(lfun);
208: 	list_extract.AddFunction(sfun);
209: 	set.AddFunction(list_extract);
210: 
211: 	ScalarFunctionSet list_element("list_element");
212: 	list_element.AddFunction(lfun);
213: 	list_element.AddFunction(sfun);
214: 	set.AddFunction(list_element);
215: 
216: 	ScalarFunctionSet array_extract("array_extract");
217: 	array_extract.AddFunction(lfun);
218: 	array_extract.AddFunction(sfun);
219: 	array_extract.AddFunction(StructExtractFun::GetFunction());
220: 	set.AddFunction(array_extract);
221: }
222: 
223: } // namespace duckdb
[end of src/function/scalar/list/list_extract.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: