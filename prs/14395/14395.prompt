You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes.
In the patch file, please make sure to include the line numbers and a blank line at the end so it can be applied using git apply.

<issue>
DuckDb does not insert arrow correctly if the record batch has been sliced
### What happens?

If a record batch is created from slicing a different record batch it seems that boolean columns are not created correctly in duckdb. I have made a simple test where we upload a record batch into duck db as table "__record_batch__" then we can query 
```
"select * from __record_batch__";
```
You would expect the record batch returned to be equal to the record batch put in. However, this is not always true.  have noticed if the record batch was created by calling "slice" that the booelean columns seem to be in-accurate. If i do a deep copy of the record batch before putting into the db it is accurate.

### To Reproduce

```
#include <cstdlib>
#include <arrow/api.h>
#include <arrow/io/api.h>
#include <arrow/ipc/api.h>
#include <arrow/c/bridge.h>
#include <adbc.h>
#include <iostream>
std::string kDuckDbDriver = "/home/path_to/libduckdb.so";

#define CHECK_ARROW_FATAL(EXPR)                      \
  if (arrow::Status status = (EXPR); !status.ok()) { \
    std::cout << status.ToString() <<std::endl;       \
    exit(1);                                         \
  }

#define CHECK_ADBC_FATAL(EXPR)                                    \
  if (AdbcStatusCode status = (EXPR); status != ADBC_STATUS_OK) { \
    std::cout <<                          \
        "AdbcStatusCode " <<(int)status << " "<<(error.message ? error.message : ""); \
  }



class ReadOneBatchReader : public arrow::RecordBatchReader {
 public:
  ReadOneBatchReader(const std::shared_ptr<arrow::RecordBatch>& batch) : batch_(batch) {}
  virtual arrow::Status ReadNext(std::shared_ptr<arrow::RecordBatch>* batch) override {
    if (already_read) {
      *batch = nullptr;
      return arrow::Status::OK();
    }
    *batch = batch_;
    already_read = true;
    return arrow::Status::OK();
  }
  std::shared_ptr<arrow::Schema> schema() const override { return batch_->schema(); }

 private:
  std::shared_ptr<arrow::RecordBatch> batch_;
  bool already_read = false;
};

arrow::Result<std::shared_ptr<arrow::RecordBatchReader>> Query(std::shared_ptr<arrow::RecordBatch>& batch, AdbcConnection connection) noexcept {
  std::string query = "select * from __record_batch__";
  ArrowArrayStream array;
  auto status =
      arrow::ExportRecordBatchReader(std::make_shared<ReadOneBatchReader>(batch), &array);
  if (!status.ok()) {
    return status;
  }
  auto clean = [array_ptr = &array, &connection]() {
    AdbcStatement statement = {};
    AdbcError error = {};
    CHECK_ADBC_FATAL(AdbcStatementNew(&connection, &statement, &error));
    CHECK_ADBC_FATAL(AdbcStatementSetSqlQuery(
        &statement, "drop table __record_batch__", &error));
    CHECK_ADBC_FATAL(AdbcStatementExecuteQuery(&statement, nullptr, nullptr, &error));
    CHECK_ADBC_FATAL(AdbcStatementRelease(&statement, &error));
    if (array_ptr->release) {
      array_ptr->release(array_ptr);
    }
  };
  AdbcError error = {};
  AdbcStatement statement = {};
  CHECK_ADBC_FATAL(AdbcStatementNew(&connection, &statement, &error));
  CHECK_ADBC_FATAL(AdbcStatementSetOption(
      &statement, ADBC_INGEST_OPTION_TARGET_TABLE, "__record_batch__", &error));
  CHECK_ADBC_FATAL(AdbcStatementBindStream(&statement, &array, &error));
  CHECK_ADBC_FATAL(AdbcStatementExecuteQuery(&statement, nullptr, nullptr, &error));
  CHECK_ADBC_FATAL(AdbcStatementRelease(&statement, &error));

  statement = {};
  CHECK_ADBC_FATAL(AdbcStatementNew(&connection, &statement, &error));
  auto adbc_status = AdbcStatementSetSqlQuery(&statement, query.c_str(), &error);
  if (adbc_status != ADBC_STATUS_OK) {
    clean();
    return arrow::Status::UnknownError(error.message ? error.message : "");
  }
  ArrowArrayStream array_result;
  int64_t rows_affected;
  adbc_status =
      AdbcStatementExecuteQuery(&statement, &array_result, &rows_affected, &error);
  if (adbc_status != ADBC_STATUS_OK) {
    clean();
    AdbcStatementRelease(&statement, &error);
    return arrow::Status::UnknownError(error.message ? error.message : "");
  }
  CHECK_ADBC_FATAL(AdbcStatementRelease(&statement, &error));
  auto reader_result = arrow::ImportRecordBatchReader(&array_result);
  clean();
  return reader_result;
}

int main() {
    arrow::MemoryPool* pool = arrow::default_memory_pool();

    // Create Builders for each column
    arrow::StringBuilder date_builder(pool);
    arrow::Int64Builder time_builder(pool);
    arrow::DictionaryBuilder<arrow::StringType> source_builder(pool);
    arrow::Int32Builder channel_builder(pool);
    arrow::DictionaryBuilder<arrow::StringType> b_symbol_builder(pool);
    arrow::DictionaryBuilder<arrow::StringType> symbol_builder(pool);
    arrow::DictionaryBuilder<arrow::StringType> prime_symbol_builder(pool);
    arrow::Int64Builder event_id_builder(pool);
    arrow::BooleanBuilder bool_0_builder(pool);
    arrow::BooleanBuilder bool_1_builder(pool);
    arrow::BooleanBuilder is_string_builder(pool);
    arrow::Int64Builder id_builder(pool);
    arrow::Int32Builder qty_builder(pool);
    arrow::Int32Builder b_total_qty_builder(pool);
    arrow::DoubleBuilder price_builder(pool);
    arrow::Int32Builder qty_3_builder(pool);
    arrow::BooleanBuilder bool4_builder(pool);
    arrow::BooleanBuilder is_stop_builder(pool);

    // Populate with the example data
    std::vector<std::string> dates = {"2024-10-14", "2024-10-14", "2024-10-14", "2024-10-14", "2024-10-14", 
                                            "2024-10-14", "2024-10-14", "2024-10-14", "2024-10-14", "2024-10-14"};
    std::vector<int64_t> times = {1728856800040503141, 1728856800040503141, 1728856800040503141, 1728856800052961261, 
                                  1728856800055141669, 1728856800063910245, 1728856800074775351, 1728856800080599547, 
                                  1728856800086024633, 1728856800097860063};
    std::vector<std::string> sources = {"SOURCE", "SOURCE", "SOURCE", "SOURCE", "SOURCE", 
                                             "SOURCE", "SOURCE", "SOURCE", "SOURCE", "SOURCE"};
    std::vector<int32_t> channels = {207, 207, 207, 207, 207, 207, 207, 207, 207, 207};
    std::vector<std::string> b_symbols = {"symbol", "symbol", "symbol", "symbol", "symbol", 
                                                  "symbol", "symbol", "symbol", "symbol", "symbol"};
    std::vector<std::string> symbols = {"symbol", "symbol", "symbol", "symbol", "symbol", 
                                        "symbol", "symbol", "symbol", "symbol", "symbol"};
    std::vector<std::string> prime_symbols = {"STRING@0", "STRING@0", "STRING@0", "STRING@0", "STRING@0", 
                                              "STRING@0", "STRING@0", "STRING@0", "STRING@0", "STRING@0"};
    std::vector<int64_t> event_ids = {733, 733, 733, 755, 793, 803, 810, 815, 818, 825};
    std::vector<bool> bool_0s = {false, false, false, true, true, true, true, false, false, true};
    std::vector<bool> bool_1 = {false, false, false, false, false, false, false, false, false, false};
    std::vector<bool> is_string = {false, false, false, false, false, false, false, false, false, false};
    std::vector<int64_t> ids = {6413949158507, 6413949158507, 6413949158507, 6413949158776, 
                                      6413949158812, 6413949158817, 6413949158821, 6413949158825, 
                                      6413949158826, 6413949158833};
    std::vector<int32_t> qtys = {1, 3, 4, 1, 1, 2, 1, 1, 1, 1};
    std::vector<int32_t> qty_2 = {8, 8, 8, 1, 1, 2, 1, 1, 1, 1};
    std::vector<double> prices = {585450.0, 585475.0, 585500.0, 585425.0, 585425.0, 
                                  585425.0, 585425.0, 585450.0, 585450.0, 585425.0};
    std::vector<int32_t> qty_3s = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
    std::vector<bool> bool4 = {true, true, true, false, false, false, false, false, false, false};
    std::vector<bool> is_stop = {false, false, false, false, false, false, false, false, false, false};

    // Insert values into builders
    for (size_t i = 0; i < dates.size(); ++i) {
        (void)date_builder.Append(dates[i]);
        (void)time_builder.Append(times[i]);
        (void)source_builder.Append(sources[i]);
        (void)channel_builder.Append(channels[i]);
        (void)b_symbol_builder.Append(b_symbols[i]);
        (void)symbol_builder.Append(symbols[i]);
        (void)prime_symbol_builder.Append(prime_symbols[i]);
        (void)event_id_builder.Append(event_ids[i]);
        (void)bool_0_builder.Append(bool_0s[i]);
        (void)bool_1_builder.Append(bool_1[i]);
        (void)is_string_builder.Append(is_string[i]);
        (void)id_builder.Append(ids[i]);
        (void)qty_builder.Append(qtys[i]);
        (void)b_total_qty_builder.Append(qty_2[i]);
        (void)price_builder.Append(prices[i]);
        (void)qty_3_builder.Append(qty_3s[i]);
        (void)bool4_builder.Append(bool4[i]);
        (void)is_stop_builder.Append(is_stop[i]);
    }

    // Finish builders to create Arrays
    std::shared_ptr<arrow::Array> date_array;
    std::shared_ptr<arrow::Array> time_array;
    std::shared_ptr<arrow::Array> source_array;
    std::shared_ptr<arrow::Array> channel_array;
    std::shared_ptr<arrow::Array> b_symbol_array;
    std::shared_ptr<arrow::Array> symbol_array;
    std::shared_ptr<arrow::Array> prime_symbol_array;
    std::shared_ptr<arrow::Array> event_id_array;
    std::shared_ptr<arrow::Array> bool_0_array;
    std::shared_ptr<arrow::Array> bool_1_array;
    std::shared_ptr<arrow::Array> is_string_array;
    std::shared_ptr<arrow::Array> id_array;
    std::shared_ptr<arrow::Array> qty_array;
    std::shared_ptr<arrow::Array> b_total_qty_array;
    std::shared_ptr<arrow::Array> price_array;
    std::shared_ptr<arrow::Array> qty_3_array;
    std::shared_ptr<arrow::Array> bool4_array;
    std::shared_ptr<arrow::Array> is_stop_array;

    (void)date_builder.Finish(&date_array);
    (void)time_builder.Finish(&time_array);
    (void)source_builder.Finish(&source_array);
    (void)channel_builder.Finish(&channel_array);
    (void)b_symbol_builder.Finish(&b_symbol_array);
    (void)symbol_builder.Finish(&symbol_array);
    (void)prime_symbol_builder.Finish(&prime_symbol_array);
    (void)event_id_builder.Finish(&event_id_array);
    (void)bool_0_builder.Finish(&bool_0_array);
    (void)bool_1_builder.Finish(&bool_1_array);
    (void)is_string_builder.Finish(&is_string_array);
    (void)id_builder.Finish(&id_array);
    (void)qty_builder.Finish(&qty_array);
    (void)b_total_qty_builder.Finish(&b_total_qty_array);
    (void)price_builder.Finish(&price_array);
    (void)qty_3_builder.Finish(&qty_3_array);
    (void)bool4_builder.Finish(&bool4_array);
    (void)is_stop_builder.Finish(&is_stop_array);

    // Create Schema
    std::vector<std::shared_ptr<arrow::Field>> schema_fields = {
        arrow::field("Date", arrow::utf8()),
        arrow::field("Time", arrow::int64()),
        arrow::field("Source", arrow::dictionary(arrow::int32(), arrow::utf8())),
        arrow::field("Channel", arrow::int32()),
        arrow::field("bSymbol", arrow::dictionary(arrow::int32(), arrow::utf8())),
        arrow::field("Symbol", arrow::dictionary(arrow::int32(), arrow::utf8())),
        arrow::field("PrimeSymbol", arrow::dictionary(arrow::int32(), arrow::utf8())),
        arrow::field("EventId", arrow::int64()),
        arrow::field("bool0", arrow::boolean()),
        arrow::field("bool1", arrow::boolean()),
        arrow::field("Isstring", arrow::boolean()),
        arrow::field("aId", arrow::int64()),
        arrow::field("Qty", arrow::int32()),
        arrow::field("bTotalQty", arrow::int32()),
        arrow::field("Price", arrow::float64()),
        arrow::field("Qty3", arrow::int32()),
        arrow::field("bool4", arrow::boolean()),
        arrow::field("IsStop", arrow::boolean())
    };

    auto schema = std::make_shared<arrow::Schema>(schema_fields);

    // Create RecordBatch
    auto record_batch = arrow::RecordBatch::Make(schema, dates.size(),
                                                 {date_array, time_array, source_array, channel_array,
                                                  b_symbol_array, symbol_array, prime_symbol_array, event_id_array,
                                                  bool_0_array, bool_1_array, is_string_array, id_array,
                                                  qty_array, b_total_qty_array, price_array, qty_3_array,
                                                  bool4_array, is_stop_array});

  AdbcError error = {};
  AdbcDatabase database;
  assert(AdbcDatabaseNew(&database, &error) == 0);
  assert(AdbcDatabaseSetOption(&database, "driver", kDuckDbDriver.c_str(), &error) == 0);
  assert(AdbcDatabaseSetOption(&database, "entrypoint", "duckdb_adbc_init", &error) == 0);
  assert(AdbcDatabaseInit(&database, &error) == 0);
  AdbcConnection connection;
  assert(AdbcConnectionNew(&connection, &error) == 0);
  assert(AdbcConnectionInit(&connection, &database, &error) == 0);

  auto temp_record = record_batch->Slice(4,1);
  auto res = *(*arrow::Table::FromRecordBatchReader(((*Query(temp_record, connection)).get())))->CombineChunksToBatch();
  std::cout << "-----------------temp_record-----------------" << std::endl;
  std::cout << temp_record->ToString()<< std::endl;
  std::cout << "-----------------res-----------------" << std::endl;
  std::cout << res->ToString()<< std::endl;
  assert(res->Equals(*record_batch));
  return 0;
}

````

you will see that column `bool0` is different in `temp_record` compared to `res`

### OS:

rhel8

### DuckDB Version:

1.1.2

### DuckDB Client:

c++, libduckdb.so

### Hardware:

intel

### Full Name:

Maxwell Gomez

### Affiliation:

Trading Firm (please DM for name)

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a stable release

### Did you include all relevant data sets for reproducing the issue?

No - Other reason (please specify in the issue body)

### Did you include all code required to reproduce the issue?

- [X] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [X] Yes, I have

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <picture>
3:     <source media="(prefers-color-scheme: light)" srcset="logo/DuckDB_Logo-horizontal.svg">
4:     <source media="(prefers-color-scheme: dark)" srcset="logo/DuckDB_Logo-horizontal-dark-mode.svg">
5:     <img alt="DuckDB logo" src="logo/DuckDB_Logo-horizontal.svg" height="100">
6:   </picture>
7: </div>
8: <br>
9: 
10: <p align="center">
11:   <a href="https://github.com/duckdb/duckdb/actions"><img src="https://github.com/duckdb/duckdb/actions/workflows/Main.yml/badge.svg?branch=main" alt="Github Actions Badge"></a>
12:   <a href="https://discord.gg/tcvwpjfnZx"><img src="https://shields.io/discord/909674491309850675" alt="discord" /></a>
13:   <a href="https://github.com/duckdb/duckdb/releases/"><img src="https://img.shields.io/github/v/release/duckdb/duckdb?color=brightgreen&display_name=tag&logo=duckdb&logoColor=white" alt="Latest Release"></a>
14: </p>
15: 
16: ## DuckDB
17: 
18: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable, portable, and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs, maps), and [several extensions designed to make SQL easier to use](https://duckdb.org/docs/guides/sql_features/friendly_sql).
19: 
20: DuckDB is available as a [standalone CLI application](https://duckdb.org/docs/api/cli/overview) and has clients for [Python](https://duckdb.org/docs/api/python/overview), [R](https://duckdb.org/docs/api/r), [Java](https://duckdb.org/docs/api/java), [Wasm](https://duckdb.org/docs/api/wasm/overview), etc., with deep integrations with packages such as [pandas](https://duckdb.org/docs/guides/python/sql_on_pandas) and [dplyr](https://duckdblabs.github.io/duckplyr/).
21: 
22: For more information on using DuckDB, please refer to the [DuckDB documentation](https://duckdb.org/docs/).
23: 
24: ## Installation
25: 
26: If you want to install DuckDB, please see [our installation page](https://duckdb.org/docs/installation/) for instructions.
27: 
28: ## Data Import
29: 
30: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
31: 
32: ```sql
33: SELECT * FROM 'myfile.csv';
34: SELECT * FROM 'myfile.parquet';
35: ```
36: 
37: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
38: 
39: ## SQL Reference
40: 
41: The documentation contains a [SQL introduction and reference](https://duckdb.org/docs/sql/introduction).
42: 
43: ## Development
44: 
45: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run `BUILD_BENCHMARK=1 BUILD_TPCH=1 make` and then perform several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`. The details of benchmarks are in our [Benchmark Guide](benchmark/README.md).
46: 
47: Please also refer to our [Build Guide](https://duckdb.org/dev/building) and [Contribution Guide](CONTRIBUTING.md).
48: 
49: ## Support
50: 
51: See the [Support Options](https://duckdblabs.com/support/) page.
[end of README.md]
[start of src/function/table/arrow_conversion.cpp]
1: #include "duckdb/common/exception/conversion_exception.hpp"
2: #include "duckdb/common/limits.hpp"
3: #include "duckdb/common/operator/multiply.hpp"
4: #include "duckdb/common/types/arrow_aux_data.hpp"
5: #include "duckdb/common/types/arrow_string_view_type.hpp"
6: #include "duckdb/common/types/hugeint.hpp"
7: #include "duckdb/function/scalar/nested_functions.hpp"
8: #include "duckdb/function/table/arrow.hpp"
9: 
10: #include "duckdb/common/bswap.hpp"
11: 
12: namespace duckdb {
13: 
14: namespace {
15: 
16: enum class ArrowArrayPhysicalType : uint8_t { DICTIONARY_ENCODED, RUN_END_ENCODED, DEFAULT };
17: 
18: ArrowArrayPhysicalType GetArrowArrayPhysicalType(const ArrowType &type) {
19: 	if (type.HasDictionary()) {
20: 		return ArrowArrayPhysicalType::DICTIONARY_ENCODED;
21: 	}
22: 	if (type.RunEndEncoded()) {
23: 		return ArrowArrayPhysicalType::RUN_END_ENCODED;
24: 	}
25: 	return ArrowArrayPhysicalType::DEFAULT;
26: }
27: 
28: } // namespace
29: 
30: static void ShiftRight(unsigned char *ar, int size, int shift) {
31: 	int carry = 0;
32: 	while (shift--) {
33: 		for (int i = size - 1; i >= 0; --i) {
34: 			int next = (ar[i] & 1) ? 0x80 : 0;
35: 			ar[i] = UnsafeNumericCast<unsigned char>(carry | (ar[i] >> 1));
36: 			carry = next;
37: 		}
38: 	}
39: }
40: 
41: idx_t GetEffectiveOffset(const ArrowArray &array, int64_t parent_offset, const ArrowScanLocalState &state,
42:                          int64_t nested_offset = -1) {
43: 	if (nested_offset != -1) {
44: 		// The parent of this array is a list
45: 		// We just ignore the parent offset, it's already applied to the list
46: 		return UnsafeNumericCast<idx_t>(array.offset + nested_offset);
47: 	}
48: 	// Parent offset is set in the case of a struct, it applies to all child arrays
49: 	// 'chunk_offset' is how much of the chunk we've already scanned, in case the chunk size exceeds
50: 	// STANDARD_VECTOR_SIZE
51: 	return UnsafeNumericCast<idx_t>(array.offset + parent_offset) + state.chunk_offset;
52: }
53: 
54: template <class T>
55: T *ArrowBufferData(ArrowArray &array, idx_t buffer_idx) {
56: 	return (T *)array.buffers[buffer_idx]; // NOLINT
57: }
58: 
59: static void GetValidityMask(ValidityMask &mask, ArrowArray &array, const ArrowScanLocalState &scan_state, idx_t size,
60:                             int64_t parent_offset, int64_t nested_offset = -1, bool add_null = false) {
61: 	// In certains we don't need to or cannot copy arrow's validity mask to duckdb.
62: 	//
63: 	// The conditions where we do want to copy arrow's mask to duckdb are:
64: 	// 1. nulls exist
65: 	// 2. n_buffers > 0, meaning the array's arrow type is not `null`
66: 	// 3. the validity buffer (the first buffer) is not a nullptr
67: 	if (array.null_count != 0 && array.n_buffers > 0 && array.buffers[0]) {
68: 		auto bit_offset = GetEffectiveOffset(array, parent_offset, scan_state, nested_offset);
69: 		mask.EnsureWritable();
70: #if STANDARD_VECTOR_SIZE > 64
71: 		auto n_bitmask_bytes = (size + 8 - 1) / 8;
72: 		if (bit_offset % 8 == 0) {
73: 			//! just memcpy nullmask
74: 			memcpy((void *)mask.GetData(), ArrowBufferData<uint8_t>(array, 0) + bit_offset / 8, n_bitmask_bytes);
75: 		} else {
76: 			//! need to re-align nullmask
77: 			vector<uint8_t> temp_nullmask(n_bitmask_bytes + 1);
78: 			memcpy(temp_nullmask.data(), ArrowBufferData<uint8_t>(array, 0) + bit_offset / 8, n_bitmask_bytes + 1);
79: 			ShiftRight(temp_nullmask.data(), NumericCast<int>(n_bitmask_bytes + 1),
80: 			           NumericCast<int>(bit_offset % 8ull)); //! why this has to be a right shift is a mystery to me
81: 			memcpy((void *)mask.GetData(), data_ptr_cast(temp_nullmask.data()), n_bitmask_bytes);
82: 		}
83: #else
84: 		auto byte_offset = bit_offset / 8;
85: 		auto source_data = ArrowBufferData<uint8_t>(array, 0);
86: 		bit_offset %= 8;
87: 		for (idx_t i = 0; i < size; i++) {
88: 			mask.Set(i, source_data[byte_offset] & (1 << bit_offset));
89: 			bit_offset++;
90: 			if (bit_offset == 8) {
91: 				bit_offset = 0;
92: 				byte_offset++;
93: 			}
94: 		}
95: #endif
96: 	}
97: 	if (add_null) {
98: 		//! We are setting a validity mask of the data part of dictionary vector
99: 		//! For some reason, Nulls are allowed to be indexes, hence we need to set the last element here to be null
100: 		//! We might have to resize the mask
101: 		mask.Resize(size, size + 1);
102: 		mask.SetInvalid(size);
103: 	}
104: }
105: 
106: static void SetValidityMask(Vector &vector, ArrowArray &array, const ArrowScanLocalState &scan_state, idx_t size,
107:                             int64_t parent_offset, int64_t nested_offset, bool add_null = false) {
108: 	D_ASSERT(vector.GetVectorType() == VectorType::FLAT_VECTOR);
109: 	auto &mask = FlatVector::Validity(vector);
110: 	GetValidityMask(mask, array, scan_state, size, parent_offset, nested_offset, add_null);
111: }
112: 
113: static void ColumnArrowToDuckDBRunEndEncoded(Vector &vector, const ArrowArray &array, ArrowArrayScanState &array_state,
114:                                              idx_t size, const ArrowType &arrow_type, int64_t nested_offset = -1,
115:                                              ValidityMask *parent_mask = nullptr, uint64_t parent_offset = 0);
116: 
117: static void ColumnArrowToDuckDB(Vector &vector, ArrowArray &array, ArrowArrayScanState &array_state, idx_t size,
118:                                 const ArrowType &arrow_type, int64_t nested_offset = -1,
119:                                 ValidityMask *parent_mask = nullptr, uint64_t parent_offset = 0);
120: 
121: static void ColumnArrowToDuckDBDictionary(Vector &vector, ArrowArray &array, ArrowArrayScanState &array_state,
122:                                           idx_t size, const ArrowType &arrow_type, int64_t nested_offset = -1,
123:                                           const ValidityMask *parent_mask = nullptr, uint64_t parent_offset = 0);
124: 
125: namespace {
126: 
127: struct ArrowListOffsetData {
128: 	idx_t list_size = 0;
129: 	idx_t start_offset = 0;
130: };
131: 
132: } // namespace
133: 
134: template <class BUFFER_TYPE>
135: static ArrowListOffsetData ConvertArrowListOffsetsTemplated(Vector &vector, ArrowArray &array, idx_t size,
136:                                                             idx_t effective_offset) {
137: 	ArrowListOffsetData result;
138: 	auto &start_offset = result.start_offset;
139: 	auto &list_size = result.list_size;
140: 
141: 	idx_t cur_offset = 0;
142: 	auto offsets = ArrowBufferData<BUFFER_TYPE>(array, 1) + effective_offset;
143: 	start_offset = offsets[0];
144: 	auto list_data = FlatVector::GetData<list_entry_t>(vector);
145: 	for (idx_t i = 0; i < size; i++) {
146: 		auto &le = list_data[i];
147: 		le.offset = cur_offset;
148: 		le.length = offsets[i + 1] - offsets[i];
149: 		cur_offset += le.length;
150: 	}
151: 	list_size = offsets[size];
152: 	list_size -= start_offset;
153: 	return result;
154: }
155: 
156: template <class BUFFER_TYPE>
157: static ArrowListOffsetData ConvertArrowListViewOffsetsTemplated(Vector &vector, ArrowArray &array, idx_t size,
158:                                                                 idx_t effective_offset) {
159: 	ArrowListOffsetData result;
160: 	auto &start_offset = result.start_offset;
161: 	auto &list_size = result.list_size;
162: 
163: 	list_size = 0;
164: 	auto offsets = ArrowBufferData<BUFFER_TYPE>(array, 1) + effective_offset;
165: 	auto sizes = ArrowBufferData<BUFFER_TYPE>(array, 2) + effective_offset;
166: 
167: 	// In ListArrays the offsets have to be sequential
168: 	// ListViewArrays do not have this same constraint
169: 	// for that reason we need to keep track of the lowest offset, so we can skip all the data that comes before it
170: 	// when we scan the child data
171: 
172: 	auto lowest_offset = size ? offsets[0] : 0;
173: 	auto list_data = FlatVector::GetData<list_entry_t>(vector);
174: 	for (idx_t i = 0; i < size; i++) {
175: 		auto &le = list_data[i];
176: 		le.offset = offsets[i];
177: 		le.length = sizes[i];
178: 		list_size += le.length;
179: 		if (sizes[i] != 0) {
180: 			lowest_offset = MinValue(lowest_offset, offsets[i]);
181: 		}
182: 	}
183: 	start_offset = lowest_offset;
184: 	if (start_offset) {
185: 		// We start scanning the child data at the 'start_offset' so we need to fix up the created list entries
186: 		for (idx_t i = 0; i < size; i++) {
187: 			auto &le = list_data[i];
188: 			le.offset = le.offset <= start_offset ? 0 : le.offset - start_offset;
189: 		}
190: 	}
191: 	return result;
192: }
193: 
194: static ArrowListOffsetData ConvertArrowListOffsets(Vector &vector, ArrowArray &array, idx_t size,
195:                                                    const ArrowType &arrow_type, idx_t effective_offset) {
196: 	auto &list_info = arrow_type.GetTypeInfo<ArrowListInfo>();
197: 	auto size_type = list_info.GetSizeType();
198: 	if (list_info.IsView()) {
199: 		if (size_type == ArrowVariableSizeType::NORMAL) {
200: 			return ConvertArrowListViewOffsetsTemplated<uint32_t>(vector, array, size, effective_offset);
201: 		} else {
202: 			D_ASSERT(size_type == ArrowVariableSizeType::SUPER_SIZE);
203: 			return ConvertArrowListViewOffsetsTemplated<uint64_t>(vector, array, size, effective_offset);
204: 		}
205: 	} else {
206: 		if (size_type == ArrowVariableSizeType::NORMAL) {
207: 			return ConvertArrowListOffsetsTemplated<uint32_t>(vector, array, size, effective_offset);
208: 		} else {
209: 			D_ASSERT(size_type == ArrowVariableSizeType::SUPER_SIZE);
210: 			return ConvertArrowListOffsetsTemplated<uint64_t>(vector, array, size, effective_offset);
211: 		}
212: 	}
213: }
214: 
215: static void ArrowToDuckDBList(Vector &vector, ArrowArray &array, ArrowArrayScanState &array_state, idx_t size,
216:                               const ArrowType &arrow_type, int64_t nested_offset, const ValidityMask *parent_mask,
217:                               int64_t parent_offset) {
218: 	auto &scan_state = array_state.state;
219: 
220: 	auto &list_info = arrow_type.GetTypeInfo<ArrowListInfo>();
221: 	SetValidityMask(vector, array, scan_state, size, parent_offset, nested_offset);
222: 
223: 	auto effective_offset = GetEffectiveOffset(array, parent_offset, scan_state, nested_offset);
224: 	auto list_data = ConvertArrowListOffsets(vector, array, size, arrow_type, effective_offset);
225: 	auto &start_offset = list_data.start_offset;
226: 	auto &list_size = list_data.list_size;
227: 
228: 	ListVector::Reserve(vector, list_size);
229: 	ListVector::SetListSize(vector, list_size);
230: 	auto &child_vector = ListVector::GetEntry(vector);
231: 	SetValidityMask(child_vector, *array.children[0], scan_state, list_size, array.offset,
232: 	                NumericCast<int64_t>(start_offset));
233: 	auto &list_mask = FlatVector::Validity(vector);
234: 	if (parent_mask) {
235: 		//! Since this List is owned by a struct we must guarantee their validity map matches on Null
236: 		if (!parent_mask->AllValid()) {
237: 			for (idx_t i = 0; i < size; i++) {
238: 				if (!parent_mask->RowIsValid(i)) {
239: 					list_mask.SetInvalid(i);
240: 				}
241: 			}
242: 		}
243: 	}
244: 	auto &child_state = array_state.GetChild(0);
245: 	auto &child_array = *array.children[0];
246: 	auto &child_type = list_info.GetChild();
247: 
248: 	if (list_size == 0 && start_offset == 0) {
249: 		D_ASSERT(!child_array.dictionary);
250: 		ColumnArrowToDuckDB(child_vector, child_array, child_state, list_size, child_type, -1);
251: 		return;
252: 	}
253: 
254: 	auto array_physical_type = GetArrowArrayPhysicalType(child_type);
255: 	switch (array_physical_type) {
256: 	case ArrowArrayPhysicalType::DICTIONARY_ENCODED:
257: 		// TODO: add support for offsets
258: 		ColumnArrowToDuckDBDictionary(child_vector, child_array, child_state, list_size, child_type,
259: 		                              NumericCast<int64_t>(start_offset));
260: 		break;
261: 	case ArrowArrayPhysicalType::RUN_END_ENCODED:
262: 		ColumnArrowToDuckDBRunEndEncoded(child_vector, child_array, child_state, list_size, child_type,
263: 		                                 NumericCast<int64_t>(start_offset));
264: 		break;
265: 	case ArrowArrayPhysicalType::DEFAULT:
266: 		ColumnArrowToDuckDB(child_vector, child_array, child_state, list_size, child_type,
267: 		                    NumericCast<int64_t>(start_offset));
268: 		break;
269: 	default:
270: 		throw NotImplementedException("ArrowArrayPhysicalType not recognized");
271: 	}
272: }
273: 
274: static void ArrowToDuckDBArray(Vector &vector, ArrowArray &array, ArrowArrayScanState &array_state, idx_t size,
275:                                const ArrowType &arrow_type, int64_t nested_offset, const ValidityMask *parent_mask,
276:                                int64_t parent_offset) {
277: 
278: 	auto &array_info = arrow_type.GetTypeInfo<ArrowArrayInfo>();
279: 	auto &scan_state = array_state.state;
280: 	auto array_size = array_info.FixedSize();
281: 	auto child_count = array_size * size;
282: 	auto child_offset = GetEffectiveOffset(array, parent_offset, scan_state, nested_offset) * array_size;
283: 
284: 	SetValidityMask(vector, array, scan_state, size, parent_offset, nested_offset);
285: 
286: 	auto &child_vector = ArrayVector::GetEntry(vector);
287: 	SetValidityMask(child_vector, *array.children[0], scan_state, child_count, array.offset,
288: 	                NumericCast<int64_t>(child_offset));
289: 
290: 	auto &array_mask = FlatVector::Validity(vector);
291: 	if (parent_mask) {
292: 		//! Since this List is owned by a struct we must guarantee their validity map matches on Null
293: 		if (!parent_mask->AllValid()) {
294: 			for (idx_t i = 0; i < size; i++) {
295: 				if (!parent_mask->RowIsValid(i)) {
296: 					array_mask.SetInvalid(i);
297: 				}
298: 			}
299: 		}
300: 	}
301: 
302: 	// Broadcast the validity mask to the child vector
303: 	if (!array_mask.AllValid()) {
304: 		auto &child_validity_mask = FlatVector::Validity(child_vector);
305: 		for (idx_t i = 0; i < size; i++) {
306: 			if (!array_mask.RowIsValid(i)) {
307: 				for (idx_t j = 0; j < array_size; j++) {
308: 					child_validity_mask.SetInvalid(i * array_size + j);
309: 				}
310: 			}
311: 		}
312: 	}
313: 
314: 	auto &child_state = array_state.GetChild(0);
315: 	auto &child_array = *array.children[0];
316: 	auto &child_type = array_info.GetChild();
317: 	if (child_count == 0 && child_offset == 0) {
318: 		D_ASSERT(!child_array.dictionary);
319: 		ColumnArrowToDuckDB(child_vector, child_array, child_state, child_count, child_type, -1);
320: 	} else {
321: 		if (child_array.dictionary) {
322: 			ColumnArrowToDuckDBDictionary(child_vector, child_array, child_state, child_count, child_type,
323: 			                              NumericCast<int64_t>(child_offset));
324: 		} else {
325: 			ColumnArrowToDuckDB(child_vector, child_array, child_state, child_count, child_type,
326: 			                    NumericCast<int64_t>(child_offset));
327: 		}
328: 	}
329: }
330: 
331: static void ArrowToDuckDBBlob(Vector &vector, ArrowArray &array, const ArrowScanLocalState &scan_state, idx_t size,
332:                               const ArrowType &arrow_type, int64_t nested_offset, int64_t parent_offset) {
333: 	SetValidityMask(vector, array, scan_state, size, parent_offset, nested_offset);
334: 	auto &string_info = arrow_type.GetTypeInfo<ArrowStringInfo>();
335: 	auto size_type = string_info.GetSizeType();
336: 	if (size_type == ArrowVariableSizeType::FIXED_SIZE) {
337: 		auto fixed_size = string_info.FixedSize();
338: 		//! Have to check validity mask before setting this up
339: 		idx_t offset = GetEffectiveOffset(array, parent_offset, scan_state, nested_offset) * fixed_size;
340: 		auto cdata = ArrowBufferData<char>(array, 1);
341: 		for (idx_t row_idx = 0; row_idx < size; row_idx++) {
342: 			if (FlatVector::IsNull(vector, row_idx)) {
343: 				continue;
344: 			}
345: 			auto bptr = cdata + offset;
346: 			auto blob_len = fixed_size;
347: 			FlatVector::GetData<string_t>(vector)[row_idx] = StringVector::AddStringOrBlob(vector, bptr, blob_len);
348: 			offset += blob_len;
349: 		}
350: 	} else if (size_type == ArrowVariableSizeType::NORMAL) {
351: 		auto offsets =
352: 		    ArrowBufferData<uint32_t>(array, 1) + GetEffectiveOffset(array, parent_offset, scan_state, nested_offset);
353: 		auto cdata = ArrowBufferData<char>(array, 2);
354: 		for (idx_t row_idx = 0; row_idx < size; row_idx++) {
355: 			if (FlatVector::IsNull(vector, row_idx)) {
356: 				continue;
357: 			}
358: 			auto bptr = cdata + offsets[row_idx];
359: 			auto blob_len = offsets[row_idx + 1] - offsets[row_idx];
360: 			FlatVector::GetData<string_t>(vector)[row_idx] = StringVector::AddStringOrBlob(vector, bptr, blob_len);
361: 		}
362: 	} else {
363: 		//! Check if last offset is higher than max uint32
364: 		if (ArrowBufferData<uint64_t>(array, 1)[array.length] > NumericLimits<uint32_t>::Maximum()) { // LCOV_EXCL_START
365: 			throw ConversionException("DuckDB does not support Blobs over 4GB");
366: 		} // LCOV_EXCL_STOP
367: 		auto offsets =
368: 		    ArrowBufferData<uint64_t>(array, 1) + GetEffectiveOffset(array, parent_offset, scan_state, nested_offset);
369: 		auto cdata = ArrowBufferData<char>(array, 2);
370: 		for (idx_t row_idx = 0; row_idx < size; row_idx++) {
371: 			if (FlatVector::IsNull(vector, row_idx)) {
372: 				continue;
373: 			}
374: 			auto bptr = cdata + offsets[row_idx];
375: 			auto blob_len = offsets[row_idx + 1] - offsets[row_idx];
376: 			FlatVector::GetData<string_t>(vector)[row_idx] = StringVector::AddStringOrBlob(vector, bptr, blob_len);
377: 		}
378: 	}
379: }
380: 
381: static void ArrowToDuckDBMapVerify(Vector &vector, idx_t count) {
382: 	auto valid_check = MapVector::CheckMapValidity(vector, count);
383: 	switch (valid_check) {
384: 	case MapInvalidReason::VALID:
385: 		break;
386: 	case MapInvalidReason::DUPLICATE_KEY: {
387: 		throw InvalidInputException("Arrow map contains duplicate key, which isn't supported by DuckDB map type");
388: 	}
389: 	case MapInvalidReason::NULL_KEY: {
390: 		throw InvalidInputException("Arrow map contains NULL as map key, which isn't supported by DuckDB map type");
391: 	}
392: 	default: {
393: 		throw InternalException("MapInvalidReason not implemented");
394: 	}
395: 	}
396: }
397: 
398: template <class T>
399: static void SetVectorString(Vector &vector, idx_t size, char *cdata, T *offsets) {
400: 	auto strings = FlatVector::GetData<string_t>(vector);
401: 	for (idx_t row_idx = 0; row_idx < size; row_idx++) {
402: 		if (FlatVector::IsNull(vector, row_idx)) {
403: 			continue;
404: 		}
405: 		auto cptr = cdata + offsets[row_idx];
406: 		auto str_len = offsets[row_idx + 1] - offsets[row_idx];
407: 		if (str_len > NumericLimits<uint32_t>::Maximum()) { // LCOV_EXCL_START
408: 			throw ConversionException("DuckDB does not support Strings over 4GB");
409: 		} // LCOV_EXCL_STOP
410: 		strings[row_idx] = string_t(cptr, UnsafeNumericCast<uint32_t>(str_len));
411: 	}
412: }
413: 
414: static void SetVectorStringView(Vector &vector, idx_t size, ArrowArray &array, idx_t current_pos) {
415: 	auto strings = FlatVector::GetData<string_t>(vector);
416: 	auto arrow_string = ArrowBufferData<arrow_string_view_t>(array, 1) + current_pos;
417: 
418: 	for (idx_t row_idx = 0; row_idx < size; row_idx++) {
419: 		if (FlatVector::IsNull(vector, row_idx)) {
420: 			continue;
421: 		}
422: 		auto length = UnsafeNumericCast<uint32_t>(arrow_string[row_idx].Length());
423: 		if (arrow_string[row_idx].IsInline()) {
424: 			//	This string is inlined
425: 			//  | Bytes 0-3  | Bytes 4-15                            |
426: 			//  |------------|---------------------------------------|
427: 			//  | length     | data (padded with 0)                  |
428: 			strings[row_idx] = string_t(arrow_string[row_idx].GetInlineData(), length);
429: 		} else {
430: 			//  This string is not inlined, we have to check a different buffer and offsets
431: 			//  | Bytes 0-3  | Bytes 4-7  | Bytes 8-11 | Bytes 12-15 |
432: 			//  |------------|------------|------------|-------------|
433: 			//  | length     | prefix     | buf. index | offset      |
434: 			auto buffer_index = UnsafeNumericCast<uint32_t>(arrow_string[row_idx].GetBufferIndex());
435: 			int32_t offset = arrow_string[row_idx].GetOffset();
436: 			D_ASSERT(array.n_buffers > 2 + buffer_index);
437: 			auto c_data = ArrowBufferData<char>(array, 2 + buffer_index);
438: 			strings[row_idx] = string_t(&c_data[offset], length);
439: 		}
440: 	}
441: }
442: 
443: static void DirectConversion(Vector &vector, ArrowArray &array, const ArrowScanLocalState &scan_state,
444:                              int64_t nested_offset, uint64_t parent_offset) {
445: 	auto internal_type = GetTypeIdSize(vector.GetType().InternalType());
446: 	auto data_ptr =
447: 	    ArrowBufferData<data_t>(array, 1) +
448: 	    internal_type * GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset), scan_state, nested_offset);
449: 	FlatVector::SetData(vector, data_ptr);
450: }
451: 
452: template <class T>
453: static void TimeConversion(Vector &vector, ArrowArray &array, const ArrowScanLocalState &scan_state,
454:                            int64_t nested_offset, int64_t parent_offset, idx_t size, int64_t conversion) {
455: 	auto tgt_ptr = FlatVector::GetData<dtime_t>(vector);
456: 	auto &validity_mask = FlatVector::Validity(vector);
457: 	auto src_ptr =
458: 	    static_cast<const T *>(array.buffers[1]) + GetEffectiveOffset(array, parent_offset, scan_state, nested_offset);
459: 	for (idx_t row = 0; row < size; row++) {
460: 		if (!validity_mask.RowIsValid(row)) {
461: 			continue;
462: 		}
463: 		if (!TryMultiplyOperator::Operation(static_cast<int64_t>(src_ptr[row]), conversion, tgt_ptr[row].micros)) {
464: 			throw ConversionException("Could not convert Time to Microsecond");
465: 		}
466: 	}
467: }
468: 
469: static void UUIDConversion(Vector &vector, const ArrowArray &array, const ArrowScanLocalState &scan_state,
470:                            int64_t nested_offset, int64_t parent_offset, idx_t size) {
471: 	auto tgt_ptr = FlatVector::GetData<hugeint_t>(vector);
472: 	auto &validity_mask = FlatVector::Validity(vector);
473: 	auto src_ptr = static_cast<const hugeint_t *>(array.buffers[1]) +
474: 	               GetEffectiveOffset(array, parent_offset, scan_state, nested_offset);
475: 	for (idx_t row = 0; row < size; row++) {
476: 		if (!validity_mask.RowIsValid(row)) {
477: 			continue;
478: 		}
479: 		tgt_ptr[row].lower = static_cast<uint64_t>(BSwap(src_ptr[row].upper));
480: 		// flip Upper MSD
481: 		tgt_ptr[row].upper =
482: 		    static_cast<int64_t>(static_cast<uint64_t>(BSwap(src_ptr[row].lower)) ^ (static_cast<uint64_t>(1) << 63));
483: 	}
484: }
485: 
486: static void TimestampTZConversion(Vector &vector, ArrowArray &array, const ArrowScanLocalState &scan_state,
487:                                   int64_t nested_offset, int64_t parent_offset, idx_t size, int64_t conversion) {
488: 	auto tgt_ptr = FlatVector::GetData<timestamp_t>(vector);
489: 	auto &validity_mask = FlatVector::Validity(vector);
490: 	auto src_ptr =
491: 	    ArrowBufferData<int64_t>(array, 1) + GetEffectiveOffset(array, parent_offset, scan_state, nested_offset);
492: 	for (idx_t row = 0; row < size; row++) {
493: 		if (!validity_mask.RowIsValid(row)) {
494: 			continue;
495: 		}
496: 		if (!TryMultiplyOperator::Operation(src_ptr[row], conversion, tgt_ptr[row].value)) {
497: 			throw ConversionException("Could not convert TimestampTZ to Microsecond");
498: 		}
499: 	}
500: }
501: 
502: static void IntervalConversionUs(Vector &vector, ArrowArray &array, const ArrowScanLocalState &scan_state,
503:                                  int64_t nested_offset, int64_t parent_offset, idx_t size, int64_t conversion) {
504: 	auto tgt_ptr = FlatVector::GetData<interval_t>(vector);
505: 	auto src_ptr =
506: 	    ArrowBufferData<int64_t>(array, 1) + GetEffectiveOffset(array, parent_offset, scan_state, nested_offset);
507: 	for (idx_t row = 0; row < size; row++) {
508: 		tgt_ptr[row].days = 0;
509: 		tgt_ptr[row].months = 0;
510: 		if (!TryMultiplyOperator::Operation(src_ptr[row], conversion, tgt_ptr[row].micros)) {
511: 			throw ConversionException("Could not convert Interval to Microsecond");
512: 		}
513: 	}
514: }
515: 
516: static void IntervalConversionMonths(Vector &vector, ArrowArray &array, const ArrowScanLocalState &scan_state,
517:                                      int64_t nested_offset, int64_t parent_offset, idx_t size) {
518: 	auto tgt_ptr = FlatVector::GetData<interval_t>(vector);
519: 	auto src_ptr =
520: 	    ArrowBufferData<int32_t>(array, 1) + GetEffectiveOffset(array, parent_offset, scan_state, nested_offset);
521: 	for (idx_t row = 0; row < size; row++) {
522: 		tgt_ptr[row].days = 0;
523: 		tgt_ptr[row].micros = 0;
524: 		tgt_ptr[row].months = src_ptr[row];
525: 	}
526: }
527: 
528: static void IntervalConversionMonthDayNanos(Vector &vector, ArrowArray &array, const ArrowScanLocalState &scan_state,
529:                                             int64_t nested_offset, int64_t parent_offset, idx_t size) {
530: 	auto tgt_ptr = FlatVector::GetData<interval_t>(vector);
531: 	auto src_ptr =
532: 	    ArrowBufferData<ArrowInterval>(array, 1) + GetEffectiveOffset(array, parent_offset, scan_state, nested_offset);
533: 	for (idx_t row = 0; row < size; row++) {
534: 		tgt_ptr[row].days = src_ptr[row].days;
535: 		tgt_ptr[row].micros = src_ptr[row].nanoseconds / Interval::NANOS_PER_MICRO;
536: 		tgt_ptr[row].months = src_ptr[row].months;
537: 	}
538: }
539: 
540: // Find the index of the first run-end that is strictly greater than the offset.
541: // count is returned if no such run-end is found.
542: template <class RUN_END_TYPE>
543: static idx_t FindRunIndex(const RUN_END_TYPE *run_ends, idx_t count, idx_t offset) {
544: 	// Binary-search within the [0, count) range. For example:
545: 	// [0, 0, 0, 1, 1, 2] encoded as
546: 	// run_ends: [3, 5, 6]:
547: 	// 0, 1, 2 -> 0
548: 	//    3, 4 -> 1
549: 	//       5 -> 2
550: 	// 6, 7 .. -> 3 (3 == count [not found])
551: 	idx_t begin = 0;
552: 	idx_t end = count;
553: 	while (begin < end) {
554: 		idx_t middle = (begin + end) / 2;
555: 		// begin < end implies middle < end
556: 		if (offset >= static_cast<idx_t>(run_ends[middle])) {
557: 			// keep searching in [middle + 1, end)
558: 			begin = middle + 1;
559: 		} else {
560: 			// offset < run_ends[middle], so keep searching in [begin, middle)
561: 			end = middle;
562: 		}
563: 	}
564: 	return begin;
565: }
566: 
567: template <class RUN_END_TYPE, class VALUE_TYPE>
568: static void FlattenRunEnds(Vector &result, ArrowRunEndEncodingState &run_end_encoding, idx_t compressed_size,
569:                            idx_t scan_offset, idx_t count) {
570: 	auto &runs = *run_end_encoding.run_ends;
571: 	auto &values = *run_end_encoding.values;
572: 
573: 	UnifiedVectorFormat run_end_format;
574: 	UnifiedVectorFormat value_format;
575: 	runs.ToUnifiedFormat(compressed_size, run_end_format);
576: 	values.ToUnifiedFormat(compressed_size, value_format);
577: 	auto run_ends_data = run_end_format.GetData<RUN_END_TYPE>(run_end_format);
578: 	auto values_data = value_format.GetData<VALUE_TYPE>(value_format);
579: 	auto result_data = FlatVector::GetData<VALUE_TYPE>(result);
580: 	auto &validity = FlatVector::Validity(result);
581: 
582: 	// According to the arrow spec, the 'run_ends' array is always valid
583: 	// so we will assume this is true and not check the validity map
584: 
585: 	// Now construct the result vector from the run_ends and the values
586: 
587: 	auto run = FindRunIndex(run_ends_data, compressed_size, scan_offset);
588: 	idx_t logical_index = scan_offset;
589: 	idx_t index = 0;
590: 	if (value_format.validity.AllValid()) {
591: 		// None of the compressed values are NULL
592: 		for (; run < compressed_size; ++run) {
593: 			auto run_end_index = run_end_format.sel->get_index(run);
594: 			auto value_index = value_format.sel->get_index(run);
595: 			auto &value = values_data[value_index];
596: 			auto run_end = static_cast<idx_t>(run_ends_data[run_end_index]);
597: 
598: 			D_ASSERT(run_end > (logical_index + index));
599: 			auto to_scan = run_end - (logical_index + index);
600: 			// Cap the amount to scan so we don't go over size
601: 			to_scan = MinValue<idx_t>(to_scan, (count - index));
602: 
603: 			for (idx_t i = 0; i < to_scan; i++) {
604: 				result_data[index + i] = value;
605: 			}
606: 			index += to_scan;
607: 			if (index >= count) {
608: 				if (logical_index + index >= run_end) {
609: 					// The last run was completed, forward the run index
610: 					++run;
611: 				}
612: 				break;
613: 			}
614: 		}
615: 	} else {
616: 		for (; run < compressed_size; ++run) {
617: 			auto run_end_index = run_end_format.sel->get_index(run);
618: 			auto value_index = value_format.sel->get_index(run);
619: 			auto run_end = static_cast<idx_t>(run_ends_data[run_end_index]);
620: 
621: 			D_ASSERT(run_end > (logical_index + index));
622: 			auto to_scan = run_end - (logical_index + index);
623: 			// Cap the amount to scan so we don't go over size
624: 			to_scan = MinValue<idx_t>(to_scan, (count - index));
625: 
626: 			if (value_format.validity.RowIsValidUnsafe(value_index)) {
627: 				auto &value = values_data[value_index];
628: 				for (idx_t i = 0; i < to_scan; i++) {
629: 					result_data[index + i] = value;
630: 					validity.SetValid(index + i);
631: 				}
632: 			} else {
633: 				for (idx_t i = 0; i < to_scan; i++) {
634: 					validity.SetInvalid(index + i);
635: 				}
636: 			}
637: 			index += to_scan;
638: 			if (index >= count) {
639: 				if (logical_index + index >= run_end) {
640: 					// The last run was completed, forward the run index
641: 					++run;
642: 				}
643: 				break;
644: 			}
645: 		}
646: 	}
647: }
648: 
649: template <class RUN_END_TYPE>
650: static void FlattenRunEndsSwitch(Vector &result, ArrowRunEndEncodingState &run_end_encoding, idx_t compressed_size,
651:                                  idx_t scan_offset, idx_t size) {
652: 	auto &values = *run_end_encoding.values;
653: 	auto physical_type = values.GetType().InternalType();
654: 
655: 	switch (physical_type) {
656: 	case PhysicalType::INT8:
657: 		FlattenRunEnds<RUN_END_TYPE, int8_t>(result, run_end_encoding, compressed_size, scan_offset, size);
658: 		break;
659: 	case PhysicalType::INT16:
660: 		FlattenRunEnds<RUN_END_TYPE, int16_t>(result, run_end_encoding, compressed_size, scan_offset, size);
661: 		break;
662: 	case PhysicalType::INT32:
663: 		FlattenRunEnds<RUN_END_TYPE, int32_t>(result, run_end_encoding, compressed_size, scan_offset, size);
664: 		break;
665: 	case PhysicalType::INT64:
666: 		FlattenRunEnds<RUN_END_TYPE, int64_t>(result, run_end_encoding, compressed_size, scan_offset, size);
667: 		break;
668: 	case PhysicalType::INT128:
669: 		FlattenRunEnds<RUN_END_TYPE, hugeint_t>(result, run_end_encoding, compressed_size, scan_offset, size);
670: 		break;
671: 	case PhysicalType::UINT8:
672: 		FlattenRunEnds<RUN_END_TYPE, uint8_t>(result, run_end_encoding, compressed_size, scan_offset, size);
673: 		break;
674: 	case PhysicalType::UINT16:
675: 		FlattenRunEnds<RUN_END_TYPE, uint16_t>(result, run_end_encoding, compressed_size, scan_offset, size);
676: 		break;
677: 	case PhysicalType::UINT32:
678: 		FlattenRunEnds<RUN_END_TYPE, uint32_t>(result, run_end_encoding, compressed_size, scan_offset, size);
679: 		break;
680: 	case PhysicalType::UINT64:
681: 		FlattenRunEnds<RUN_END_TYPE, uint64_t>(result, run_end_encoding, compressed_size, scan_offset, size);
682: 		break;
683: 	case PhysicalType::BOOL:
684: 		FlattenRunEnds<RUN_END_TYPE, bool>(result, run_end_encoding, compressed_size, scan_offset, size);
685: 		break;
686: 	case PhysicalType::FLOAT:
687: 		FlattenRunEnds<RUN_END_TYPE, float>(result, run_end_encoding, compressed_size, scan_offset, size);
688: 		break;
689: 	case PhysicalType::DOUBLE:
690: 		FlattenRunEnds<RUN_END_TYPE, double>(result, run_end_encoding, compressed_size, scan_offset, size);
691: 		break;
692: 	case PhysicalType::INTERVAL:
693: 		FlattenRunEnds<RUN_END_TYPE, interval_t>(result, run_end_encoding, compressed_size, scan_offset, size);
694: 		break;
695: 	case PhysicalType::VARCHAR: {
696: 		// Share the string heap, we don't need to allocate new strings, we just reference the existing ones
697: 		result.SetAuxiliary(values.GetAuxiliary());
698: 		FlattenRunEnds<RUN_END_TYPE, string_t>(result, run_end_encoding, compressed_size, scan_offset, size);
699: 		break;
700: 	}
701: 	default:
702: 		throw NotImplementedException("RunEndEncoded value type '%s' not supported yet", TypeIdToString(physical_type));
703: 	}
704: }
705: 
706: static void ColumnArrowToDuckDBRunEndEncoded(Vector &vector, const ArrowArray &array, ArrowArrayScanState &array_state,
707:                                              idx_t size, const ArrowType &arrow_type, int64_t nested_offset,
708:                                              ValidityMask *parent_mask, uint64_t parent_offset) {
709: 	// Scan the 'run_ends' array
710: 	D_ASSERT(array.n_children == 2);
711: 	auto &run_ends_array = *array.children[0];
712: 	auto &values_array = *array.children[1];
713: 
714: 	auto &struct_info = arrow_type.GetTypeInfo<ArrowStructInfo>();
715: 	auto &run_ends_type = struct_info.GetChild(0);
716: 	auto &values_type = struct_info.GetChild(1);
717: 	D_ASSERT(vector.GetType() == values_type.GetDuckType());
718: 
719: 	auto &scan_state = array_state.state;
720: 
721: 	D_ASSERT(run_ends_array.length == values_array.length);
722: 	auto compressed_size = NumericCast<idx_t>(run_ends_array.length);
723: 	// Create a vector for the run ends and the values
724: 	auto &run_end_encoding = array_state.RunEndEncoding();
725: 	if (!run_end_encoding.run_ends) {
726: 		// The run ends and values have not been scanned yet for this array
727: 		D_ASSERT(!run_end_encoding.values);
728: 		run_end_encoding.run_ends = make_uniq<Vector>(run_ends_type.GetDuckType(), compressed_size);
729: 		run_end_encoding.values = make_uniq<Vector>(values_type.GetDuckType(), compressed_size);
730: 
731: 		ColumnArrowToDuckDB(*run_end_encoding.run_ends, run_ends_array, array_state, compressed_size, run_ends_type);
732: 		auto &values = *run_end_encoding.values;
733: 		SetValidityMask(values, values_array, scan_state, compressed_size, NumericCast<int64_t>(parent_offset),
734: 		                nested_offset);
735: 		ColumnArrowToDuckDB(values, values_array, array_state, compressed_size, values_type);
736: 	}
737: 
738: 	idx_t scan_offset = GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset), scan_state, nested_offset);
739: 	auto physical_type = run_ends_type.GetDuckType().InternalType();
740: 	switch (physical_type) {
741: 	case PhysicalType::INT16:
742: 		FlattenRunEndsSwitch<int16_t>(vector, run_end_encoding, compressed_size, scan_offset, size);
743: 		break;
744: 	case PhysicalType::INT32:
745: 		FlattenRunEndsSwitch<int32_t>(vector, run_end_encoding, compressed_size, scan_offset, size);
746: 		break;
747: 	case PhysicalType::INT64:
748: 		FlattenRunEndsSwitch<int32_t>(vector, run_end_encoding, compressed_size, scan_offset, size);
749: 		break;
750: 	default:
751: 		throw NotImplementedException("Type '%s' not implemented for RunEndEncoding", TypeIdToString(physical_type));
752: 	}
753: }
754: 
755: static void ColumnArrowToDuckDB(Vector &vector, ArrowArray &array, ArrowArrayScanState &array_state, idx_t size,
756:                                 const ArrowType &arrow_type, int64_t nested_offset, ValidityMask *parent_mask,
757:                                 uint64_t parent_offset) {
758: 	auto &scan_state = array_state.state;
759: 	D_ASSERT(!array.dictionary);
760: 
761: 	switch (vector.GetType().id()) {
762: 	case LogicalTypeId::SQLNULL:
763: 		vector.Reference(Value());
764: 		break;
765: 	case LogicalTypeId::BOOLEAN: {
766: 		//! Arrow bit-packs boolean values
767: 		//! Lets first figure out where we are in the source array
768: 		auto src_ptr = ArrowBufferData<uint8_t>(array, 1) +
769: 		               GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset), scan_state, nested_offset) / 8;
770: 		auto tgt_ptr = (uint8_t *)FlatVector::GetData(vector);
771: 		int src_pos = 0;
772: 		idx_t cur_bit = scan_state.chunk_offset % 8;
773: 		if (nested_offset != -1) {
774: 			cur_bit = NumericCast<idx_t>(nested_offset % 8);
775: 		}
776: 		for (idx_t row = 0; row < size; row++) {
777: 			if ((src_ptr[src_pos] & (1 << cur_bit)) == 0) {
778: 				tgt_ptr[row] = 0;
779: 			} else {
780: 				tgt_ptr[row] = 1;
781: 			}
782: 			cur_bit++;
783: 			if (cur_bit == 8) {
784: 				src_pos++;
785: 				cur_bit = 0;
786: 			}
787: 		}
788: 		break;
789: 	}
790: 	case LogicalTypeId::TINYINT:
791: 	case LogicalTypeId::SMALLINT:
792: 	case LogicalTypeId::INTEGER:
793: 	case LogicalTypeId::FLOAT:
794: 	case LogicalTypeId::DOUBLE:
795: 	case LogicalTypeId::UTINYINT:
796: 	case LogicalTypeId::USMALLINT:
797: 	case LogicalTypeId::UINTEGER:
798: 	case LogicalTypeId::UBIGINT:
799: 	case LogicalTypeId::BIGINT:
800: 	case LogicalTypeId::HUGEINT:
801: 	case LogicalTypeId::UHUGEINT:
802: 	case LogicalTypeId::TIMESTAMP:
803: 	case LogicalTypeId::TIMESTAMP_SEC:
804: 	case LogicalTypeId::TIMESTAMP_MS:
805: 	case LogicalTypeId::TIMESTAMP_NS:
806: 	case LogicalTypeId::TIME_TZ: {
807: 		DirectConversion(vector, array, scan_state, nested_offset, parent_offset);
808: 		break;
809: 	}
810: 	case LogicalTypeId::UUID:
811: 		UUIDConversion(vector, array, scan_state, nested_offset, NumericCast<int64_t>(parent_offset), size);
812: 		break;
813: 	case LogicalTypeId::VARCHAR: {
814: 		auto &string_info = arrow_type.GetTypeInfo<ArrowStringInfo>();
815: 		auto size_type = string_info.GetSizeType();
816: 		switch (size_type) {
817: 		case ArrowVariableSizeType::SUPER_SIZE: {
818: 			auto cdata = ArrowBufferData<char>(array, 2);
819: 			auto offsets = ArrowBufferData<uint64_t>(array, 1) +
820: 			               GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset), scan_state, nested_offset);
821: 			SetVectorString(vector, size, cdata, offsets);
822: 			break;
823: 		}
824: 		case ArrowVariableSizeType::NORMAL:
825: 		case ArrowVariableSizeType::FIXED_SIZE: {
826: 			auto cdata = ArrowBufferData<char>(array, 2);
827: 			auto offsets = ArrowBufferData<uint32_t>(array, 1) +
828: 			               GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset), scan_state, nested_offset);
829: 			SetVectorString(vector, size, cdata, offsets);
830: 			break;
831: 		}
832: 		case ArrowVariableSizeType::VIEW: {
833: 			SetVectorStringView(
834: 			    vector, size, array,
835: 			    GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset), scan_state, nested_offset));
836: 			break;
837: 		}
838: 		}
839: 		break;
840: 	}
841: 	case LogicalTypeId::DATE: {
842: 		auto &datetime_info = arrow_type.GetTypeInfo<ArrowDateTimeInfo>();
843: 		auto precision = datetime_info.GetDateTimeType();
844: 		switch (precision) {
845: 		case ArrowDateTimeType::DAYS: {
846: 			DirectConversion(vector, array, scan_state, nested_offset, parent_offset);
847: 			break;
848: 		}
849: 		case ArrowDateTimeType::MILLISECONDS: {
850: 			//! convert date from nanoseconds to days
851: 			auto src_ptr = ArrowBufferData<uint64_t>(array, 1) +
852: 			               GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset), scan_state, nested_offset);
853: 			auto tgt_ptr = FlatVector::GetData<date_t>(vector);
854: 			for (idx_t row = 0; row < size; row++) {
855: 				tgt_ptr[row] = date_t(UnsafeNumericCast<int32_t>(static_cast<int64_t>(src_ptr[row]) /
856: 				                                                 static_cast<int64_t>(1000 * 60 * 60 * 24)));
857: 			}
858: 			break;
859: 		}
860: 		default:
861: 			throw NotImplementedException("Unsupported precision for Date Type ");
862: 		}
863: 		break;
864: 	}
865: 	case LogicalTypeId::TIME: {
866: 		auto &datetime_info = arrow_type.GetTypeInfo<ArrowDateTimeInfo>();
867: 		auto precision = datetime_info.GetDateTimeType();
868: 		switch (precision) {
869: 		case ArrowDateTimeType::SECONDS: {
870: 			TimeConversion<int32_t>(vector, array, scan_state, nested_offset, NumericCast<int64_t>(parent_offset), size,
871: 			                        1000000);
872: 			break;
873: 		}
874: 		case ArrowDateTimeType::MILLISECONDS: {
875: 			TimeConversion<int32_t>(vector, array, scan_state, nested_offset, NumericCast<int64_t>(parent_offset), size,
876: 			                        1000);
877: 			break;
878: 		}
879: 		case ArrowDateTimeType::MICROSECONDS: {
880: 			TimeConversion<int64_t>(vector, array, scan_state, nested_offset, NumericCast<int64_t>(parent_offset), size,
881: 			                        1);
882: 			break;
883: 		}
884: 		case ArrowDateTimeType::NANOSECONDS: {
885: 			auto tgt_ptr = FlatVector::GetData<dtime_t>(vector);
886: 			auto src_ptr = ArrowBufferData<int64_t>(array, 1) +
887: 			               GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset), scan_state, nested_offset);
888: 			for (idx_t row = 0; row < size; row++) {
889: 				tgt_ptr[row].micros = src_ptr[row] / 1000;
890: 			}
891: 			break;
892: 		}
893: 		default:
894: 			throw NotImplementedException("Unsupported precision for Time Type ");
895: 		}
896: 		break;
897: 	}
898: 	case LogicalTypeId::TIMESTAMP_TZ: {
899: 		auto &datetime_info = arrow_type.GetTypeInfo<ArrowDateTimeInfo>();
900: 		auto precision = datetime_info.GetDateTimeType();
901: 		switch (precision) {
902: 		case ArrowDateTimeType::SECONDS: {
903: 			TimestampTZConversion(vector, array, scan_state, nested_offset, NumericCast<int64_t>(parent_offset), size,
904: 			                      1000000);
905: 			break;
906: 		}
907: 		case ArrowDateTimeType::MILLISECONDS: {
908: 			TimestampTZConversion(vector, array, scan_state, nested_offset, NumericCast<int64_t>(parent_offset), size,
909: 			                      1000);
910: 			break;
911: 		}
912: 		case ArrowDateTimeType::MICROSECONDS: {
913: 			DirectConversion(vector, array, scan_state, nested_offset, parent_offset);
914: 			break;
915: 		}
916: 		case ArrowDateTimeType::NANOSECONDS: {
917: 			auto tgt_ptr = FlatVector::GetData<timestamp_t>(vector);
918: 			auto src_ptr = ArrowBufferData<int64_t>(array, 1) +
919: 			               GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset), scan_state, nested_offset);
920: 			for (idx_t row = 0; row < size; row++) {
921: 				tgt_ptr[row].value = src_ptr[row] / 1000;
922: 			}
923: 			break;
924: 		}
925: 		default:
926: 			throw NotImplementedException("Unsupported precision for TimestampTZ Type ");
927: 		}
928: 		break;
929: 	}
930: 	case LogicalTypeId::INTERVAL: {
931: 		auto &datetime_info = arrow_type.GetTypeInfo<ArrowDateTimeInfo>();
932: 		auto precision = datetime_info.GetDateTimeType();
933: 		switch (precision) {
934: 		case ArrowDateTimeType::SECONDS: {
935: 			IntervalConversionUs(vector, array, scan_state, nested_offset, NumericCast<int64_t>(parent_offset), size,
936: 			                     1000000);
937: 			break;
938: 		}
939: 		case ArrowDateTimeType::DAYS:
940: 		case ArrowDateTimeType::MILLISECONDS: {
941: 			IntervalConversionUs(vector, array, scan_state, nested_offset, NumericCast<int64_t>(parent_offset), size,
942: 			                     1000);
943: 			break;
944: 		}
945: 		case ArrowDateTimeType::MICROSECONDS: {
946: 			IntervalConversionUs(vector, array, scan_state, nested_offset, NumericCast<int64_t>(parent_offset), size,
947: 			                     1);
948: 			break;
949: 		}
950: 		case ArrowDateTimeType::NANOSECONDS: {
951: 			auto tgt_ptr = FlatVector::GetData<interval_t>(vector);
952: 			auto src_ptr = ArrowBufferData<int64_t>(array, 1) +
953: 			               GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset), scan_state, nested_offset);
954: 			for (idx_t row = 0; row < size; row++) {
955: 				tgt_ptr[row].micros = src_ptr[row] / 1000;
956: 				tgt_ptr[row].days = 0;
957: 				tgt_ptr[row].months = 0;
958: 			}
959: 			break;
960: 		}
961: 		case ArrowDateTimeType::MONTHS: {
962: 			IntervalConversionMonths(vector, array, scan_state, nested_offset, NumericCast<int64_t>(parent_offset),
963: 			                         size);
964: 			break;
965: 		}
966: 		case ArrowDateTimeType::MONTH_DAY_NANO: {
967: 			IntervalConversionMonthDayNanos(vector, array, scan_state, nested_offset,
968: 			                                NumericCast<int64_t>(parent_offset), size);
969: 			break;
970: 		}
971: 		default:
972: 			throw NotImplementedException("Unsupported precision for Interval/Duration Type ");
973: 		}
974: 		break;
975: 	}
976: 	case LogicalTypeId::DECIMAL: {
977: 		auto val_mask = FlatVector::Validity(vector);
978: 		//! We have to convert from INT128
979: 		auto src_ptr = ArrowBufferData<hugeint_t>(array, 1) +
980: 		               GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset), scan_state, nested_offset);
981: 		switch (vector.GetType().InternalType()) {
982: 		case PhysicalType::INT16: {
983: 			auto tgt_ptr = FlatVector::GetData<int16_t>(vector);
984: 			for (idx_t row = 0; row < size; row++) {
985: 				if (val_mask.RowIsValid(row)) {
986: 					auto result = Hugeint::TryCast(src_ptr[row], tgt_ptr[row]);
987: 					D_ASSERT(result);
988: 					(void)result;
989: 				}
990: 			}
991: 			break;
992: 		}
993: 		case PhysicalType::INT32: {
994: 			auto tgt_ptr = FlatVector::GetData<int32_t>(vector);
995: 			for (idx_t row = 0; row < size; row++) {
996: 				if (val_mask.RowIsValid(row)) {
997: 					auto result = Hugeint::TryCast(src_ptr[row], tgt_ptr[row]);
998: 					D_ASSERT(result);
999: 					(void)result;
1000: 				}
1001: 			}
1002: 			break;
1003: 		}
1004: 		case PhysicalType::INT64: {
1005: 			auto tgt_ptr = FlatVector::GetData<int64_t>(vector);
1006: 			for (idx_t row = 0; row < size; row++) {
1007: 				if (val_mask.RowIsValid(row)) {
1008: 					auto result = Hugeint::TryCast(src_ptr[row], tgt_ptr[row]);
1009: 					D_ASSERT(result);
1010: 					(void)result;
1011: 				}
1012: 			}
1013: 			break;
1014: 		}
1015: 		case PhysicalType::INT128: {
1016: 			FlatVector::SetData(vector, ArrowBufferData<data_t>(array, 1) +
1017: 			                                GetTypeIdSize(vector.GetType().InternalType()) *
1018: 			                                    GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset),
1019: 			                                                       scan_state, nested_offset));
1020: 			break;
1021: 		}
1022: 		default:
1023: 			throw NotImplementedException("Unsupported physical type for Decimal: %s",
1024: 			                              TypeIdToString(vector.GetType().InternalType()));
1025: 		}
1026: 		break;
1027: 	}
1028: 	case LogicalTypeId::BLOB:
1029: 	case LogicalTypeId::BIT:
1030: 	case LogicalTypeId::VARINT: {
1031: 		ArrowToDuckDBBlob(vector, array, scan_state, size, arrow_type, nested_offset,
1032: 		                  NumericCast<int64_t>(parent_offset));
1033: 		break;
1034: 	}
1035: 	case LogicalTypeId::LIST: {
1036: 		ArrowToDuckDBList(vector, array, array_state, size, arrow_type, nested_offset, parent_mask,
1037: 		                  NumericCast<int64_t>(parent_offset));
1038: 		break;
1039: 	}
1040: 	case LogicalTypeId::ARRAY: {
1041: 		ArrowToDuckDBArray(vector, array, array_state, size, arrow_type, nested_offset, parent_mask,
1042: 		                   NumericCast<int64_t>(parent_offset));
1043: 		break;
1044: 	}
1045: 	case LogicalTypeId::MAP: {
1046: 		ArrowToDuckDBList(vector, array, array_state, size, arrow_type, nested_offset, parent_mask,
1047: 		                  NumericCast<int64_t>(parent_offset));
1048: 		ArrowToDuckDBMapVerify(vector, size);
1049: 		break;
1050: 	}
1051: 	case LogicalTypeId::STRUCT: {
1052: 		//! Fill the children
1053: 		auto &struct_info = arrow_type.GetTypeInfo<ArrowStructInfo>();
1054: 		auto &child_entries = StructVector::GetEntries(vector);
1055: 		auto &struct_validity_mask = FlatVector::Validity(vector);
1056: 		for (idx_t child_idx = 0; child_idx < NumericCast<idx_t>(array.n_children); child_idx++) {
1057: 			auto &child_entry = *child_entries[child_idx];
1058: 			auto &child_array = *array.children[child_idx];
1059: 			auto &child_type = struct_info.GetChild(child_idx);
1060: 			auto &child_state = array_state.GetChild(child_idx);
1061: 
1062: 			SetValidityMask(child_entry, child_array, scan_state, size, array.offset, nested_offset);
1063: 			if (!struct_validity_mask.AllValid()) {
1064: 				auto &child_validity_mark = FlatVector::Validity(child_entry);
1065: 				for (idx_t i = 0; i < size; i++) {
1066: 					if (!struct_validity_mask.RowIsValid(i)) {
1067: 						child_validity_mark.SetInvalid(i);
1068: 					}
1069: 				}
1070: 			}
1071: 
1072: 			auto array_physical_type = GetArrowArrayPhysicalType(child_type);
1073: 			switch (array_physical_type) {
1074: 			case ArrowArrayPhysicalType::DICTIONARY_ENCODED:
1075: 				ColumnArrowToDuckDBDictionary(child_entry, child_array, child_state, size, child_type, nested_offset,
1076: 				                              &struct_validity_mask, NumericCast<uint64_t>(array.offset));
1077: 				break;
1078: 			case ArrowArrayPhysicalType::RUN_END_ENCODED:
1079: 				ColumnArrowToDuckDBRunEndEncoded(child_entry, child_array, child_state, size, child_type, nested_offset,
1080: 				                                 &struct_validity_mask, NumericCast<uint64_t>(array.offset));
1081: 				break;
1082: 			case ArrowArrayPhysicalType::DEFAULT:
1083: 				ColumnArrowToDuckDB(child_entry, child_array, child_state, size, child_type, nested_offset,
1084: 				                    &struct_validity_mask, NumericCast<uint64_t>(array.offset));
1085: 				break;
1086: 			default:
1087: 				throw NotImplementedException("ArrowArrayPhysicalType not recognized");
1088: 			}
1089: 		}
1090: 		break;
1091: 	}
1092: 	case LogicalTypeId::UNION: {
1093: 		auto type_ids = ArrowBufferData<int8_t>(array, array.n_buffers == 1 ? 0 : 1);
1094: 		D_ASSERT(type_ids);
1095: 		auto members = UnionType::CopyMemberTypes(vector.GetType());
1096: 
1097: 		auto &validity_mask = FlatVector::Validity(vector);
1098: 		auto &union_info = arrow_type.GetTypeInfo<ArrowStructInfo>();
1099: 		duckdb::vector<Vector> children;
1100: 		for (idx_t child_idx = 0; child_idx < NumericCast<idx_t>(array.n_children); child_idx++) {
1101: 			Vector child(members[child_idx].second, size);
1102: 			auto &child_array = *array.children[child_idx];
1103: 			auto &child_state = array_state.GetChild(child_idx);
1104: 			auto &child_type = union_info.GetChild(child_idx);
1105: 
1106: 			SetValidityMask(child, child_array, scan_state, size, NumericCast<int64_t>(parent_offset), nested_offset);
1107: 			auto array_physical_type = GetArrowArrayPhysicalType(child_type);
1108: 
1109: 			switch (array_physical_type) {
1110: 			case ArrowArrayPhysicalType::DICTIONARY_ENCODED:
1111: 				ColumnArrowToDuckDBDictionary(child, child_array, child_state, size, child_type);
1112: 				break;
1113: 			case ArrowArrayPhysicalType::RUN_END_ENCODED:
1114: 				ColumnArrowToDuckDBRunEndEncoded(child, child_array, child_state, size, child_type);
1115: 				break;
1116: 			case ArrowArrayPhysicalType::DEFAULT:
1117: 				ColumnArrowToDuckDB(child, child_array, child_state, size, child_type, nested_offset, &validity_mask);
1118: 				break;
1119: 			default:
1120: 				throw NotImplementedException("ArrowArrayPhysicalType not recognized");
1121: 			}
1122: 
1123: 			children.push_back(std::move(child));
1124: 		}
1125: 
1126: 		for (idx_t row_idx = 0; row_idx < size; row_idx++) {
1127: 			auto tag = NumericCast<uint8_t>(type_ids[row_idx]);
1128: 
1129: 			auto out_of_range = tag >= array.n_children;
1130: 			if (out_of_range) {
1131: 				throw InvalidInputException("Arrow union tag out of range: %d", tag);
1132: 			}
1133: 
1134: 			const Value &value = children[tag].GetValue(row_idx);
1135: 			vector.SetValue(row_idx, value.IsNull() ? Value() : Value::UNION(members, tag, value));
1136: 		}
1137: 
1138: 		break;
1139: 	}
1140: 	default:
1141: 		throw NotImplementedException("Unsupported type for arrow conversion: %s", vector.GetType().ToString());
1142: 	}
1143: }
1144: 
1145: template <class T>
1146: static void SetSelectionVectorLoop(SelectionVector &sel, data_ptr_t indices_p, idx_t size) {
1147: 	auto indices = reinterpret_cast<T *>(indices_p);
1148: 	for (idx_t row = 0; row < size; row++) {
1149: 		sel.set_index(row, UnsafeNumericCast<idx_t>(indices[row]));
1150: 	}
1151: }
1152: 
1153: template <class T>
1154: static void SetSelectionVectorLoopWithChecks(SelectionVector &sel, data_ptr_t indices_p, idx_t size) {
1155: 
1156: 	auto indices = reinterpret_cast<T *>(indices_p);
1157: 	for (idx_t row = 0; row < size; row++) {
1158: 		if (indices[row] > NumericLimits<uint32_t>::Maximum()) {
1159: 			throw ConversionException("DuckDB only supports indices that fit on an uint32");
1160: 		}
1161: 		sel.set_index(row, NumericCast<idx_t>(indices[row]));
1162: 	}
1163: }
1164: 
1165: template <class T>
1166: static void SetMaskedSelectionVectorLoop(SelectionVector &sel, data_ptr_t indices_p, idx_t size, ValidityMask &mask,
1167:                                          idx_t last_element_pos) {
1168: 	auto indices = reinterpret_cast<T *>(indices_p);
1169: 	for (idx_t row = 0; row < size; row++) {
1170: 		if (mask.RowIsValid(row)) {
1171: 			sel.set_index(row, UnsafeNumericCast<idx_t>(indices[row]));
1172: 		} else {
1173: 			//! Need to point out to last element
1174: 			sel.set_index(row, last_element_pos);
1175: 		}
1176: 	}
1177: }
1178: 
1179: static void SetSelectionVector(SelectionVector &sel, data_ptr_t indices_p, const LogicalType &logical_type, idx_t size,
1180:                                ValidityMask *mask = nullptr, idx_t last_element_pos = 0) {
1181: 	sel.Initialize(size);
1182: 
1183: 	if (mask) {
1184: 		switch (logical_type.id()) {
1185: 		case LogicalTypeId::UTINYINT:
1186: 			SetMaskedSelectionVectorLoop<uint8_t>(sel, indices_p, size, *mask, last_element_pos);
1187: 			break;
1188: 		case LogicalTypeId::TINYINT:
1189: 			SetMaskedSelectionVectorLoop<int8_t>(sel, indices_p, size, *mask, last_element_pos);
1190: 			break;
1191: 		case LogicalTypeId::USMALLINT:
1192: 			SetMaskedSelectionVectorLoop<uint16_t>(sel, indices_p, size, *mask, last_element_pos);
1193: 			break;
1194: 		case LogicalTypeId::SMALLINT:
1195: 			SetMaskedSelectionVectorLoop<int16_t>(sel, indices_p, size, *mask, last_element_pos);
1196: 			break;
1197: 		case LogicalTypeId::UINTEGER:
1198: 			if (last_element_pos > NumericLimits<uint32_t>::Maximum()) {
1199: 				//! Its guaranteed that our indices will point to the last element, so just throw an error
1200: 				throw ConversionException("DuckDB only supports indices that fit on an uint32");
1201: 			}
1202: 			SetMaskedSelectionVectorLoop<uint32_t>(sel, indices_p, size, *mask, last_element_pos);
1203: 			break;
1204: 		case LogicalTypeId::INTEGER:
1205: 			SetMaskedSelectionVectorLoop<int32_t>(sel, indices_p, size, *mask, last_element_pos);
1206: 			break;
1207: 		case LogicalTypeId::UBIGINT:
1208: 			if (last_element_pos > NumericLimits<uint32_t>::Maximum()) {
1209: 				//! Its guaranteed that our indices will point to the last element, so just throw an error
1210: 				throw ConversionException("DuckDB only supports indices that fit on an uint32");
1211: 			}
1212: 			SetMaskedSelectionVectorLoop<uint64_t>(sel, indices_p, size, *mask, last_element_pos);
1213: 			break;
1214: 		case LogicalTypeId::BIGINT:
1215: 			if (last_element_pos > NumericLimits<uint32_t>::Maximum()) {
1216: 				//! Its guaranteed that our indices will point to the last element, so just throw an error
1217: 				throw ConversionException("DuckDB only supports indices that fit on an uint32");
1218: 			}
1219: 			SetMaskedSelectionVectorLoop<int64_t>(sel, indices_p, size, *mask, last_element_pos);
1220: 			break;
1221: 
1222: 		default:
1223: 			throw NotImplementedException("(Arrow) Unsupported type for selection vectors %s", logical_type.ToString());
1224: 		}
1225: 
1226: 	} else {
1227: 		switch (logical_type.id()) {
1228: 		case LogicalTypeId::UTINYINT:
1229: 			SetSelectionVectorLoop<uint8_t>(sel, indices_p, size);
1230: 			break;
1231: 		case LogicalTypeId::TINYINT:
1232: 			SetSelectionVectorLoop<int8_t>(sel, indices_p, size);
1233: 			break;
1234: 		case LogicalTypeId::USMALLINT:
1235: 			SetSelectionVectorLoop<uint16_t>(sel, indices_p, size);
1236: 			break;
1237: 		case LogicalTypeId::SMALLINT:
1238: 			SetSelectionVectorLoop<int16_t>(sel, indices_p, size);
1239: 			break;
1240: 		case LogicalTypeId::UINTEGER:
1241: 			SetSelectionVectorLoop<uint32_t>(sel, indices_p, size);
1242: 			break;
1243: 		case LogicalTypeId::INTEGER:
1244: 			SetSelectionVectorLoop<int32_t>(sel, indices_p, size);
1245: 			break;
1246: 		case LogicalTypeId::UBIGINT:
1247: 			if (last_element_pos > NumericLimits<uint32_t>::Maximum()) {
1248: 				//! We need to check if our indexes fit in a uint32_t
1249: 				SetSelectionVectorLoopWithChecks<uint64_t>(sel, indices_p, size);
1250: 			} else {
1251: 				SetSelectionVectorLoop<uint64_t>(sel, indices_p, size);
1252: 			}
1253: 			break;
1254: 		case LogicalTypeId::BIGINT:
1255: 			if (last_element_pos > NumericLimits<uint32_t>::Maximum()) {
1256: 				//! We need to check if our indexes fit in a uint32_t
1257: 				SetSelectionVectorLoopWithChecks<int64_t>(sel, indices_p, size);
1258: 			} else {
1259: 				SetSelectionVectorLoop<int64_t>(sel, indices_p, size);
1260: 			}
1261: 			break;
1262: 		default:
1263: 			throw ConversionException("(Arrow) Unsupported type for selection vectors %s", logical_type.ToString());
1264: 		}
1265: 	}
1266: }
1267: 
1268: static bool CanContainNull(const ArrowArray &array, const ValidityMask *parent_mask) {
1269: 	if (array.null_count > 0) {
1270: 		return true;
1271: 	}
1272: 	if (!parent_mask) {
1273: 		return false;
1274: 	}
1275: 	return !parent_mask->AllValid();
1276: }
1277: 
1278: static void ColumnArrowToDuckDBDictionary(Vector &vector, ArrowArray &array, ArrowArrayScanState &array_state,
1279:                                           idx_t size, const ArrowType &arrow_type, int64_t nested_offset,
1280:                                           const ValidityMask *parent_mask, uint64_t parent_offset) {
1281: 	D_ASSERT(arrow_type.HasDictionary());
1282: 	auto &scan_state = array_state.state;
1283: 	const bool has_nulls = CanContainNull(array, parent_mask);
1284: 	if (array_state.CacheOutdated(array.dictionary)) {
1285: 		//! We need to set the dictionary data for this column
1286: 		auto base_vector = make_uniq<Vector>(vector.GetType(), NumericCast<idx_t>(array.dictionary->length));
1287: 		SetValidityMask(*base_vector, *array.dictionary, scan_state, NumericCast<idx_t>(array.dictionary->length), 0, 0,
1288: 		                has_nulls);
1289: 		auto &dictionary_type = arrow_type.GetDictionary();
1290: 		auto arrow_physical_type = GetArrowArrayPhysicalType(dictionary_type);
1291: 		switch (arrow_physical_type) {
1292: 		case ArrowArrayPhysicalType::DICTIONARY_ENCODED:
1293: 			ColumnArrowToDuckDBDictionary(*base_vector, *array.dictionary, array_state,
1294: 			                              NumericCast<idx_t>(array.dictionary->length), dictionary_type);
1295: 			break;
1296: 		case ArrowArrayPhysicalType::RUN_END_ENCODED:
1297: 			ColumnArrowToDuckDBRunEndEncoded(*base_vector, *array.dictionary, array_state,
1298: 			                                 NumericCast<idx_t>(array.dictionary->length), dictionary_type);
1299: 			break;
1300: 		case ArrowArrayPhysicalType::DEFAULT:
1301: 			ColumnArrowToDuckDB(*base_vector, *array.dictionary, array_state,
1302: 			                    NumericCast<idx_t>(array.dictionary->length), dictionary_type);
1303: 			break;
1304: 		default:
1305: 			throw NotImplementedException("ArrowArrayPhysicalType not recognized");
1306: 		};
1307: 		array_state.AddDictionary(std::move(base_vector), array.dictionary);
1308: 	}
1309: 	auto offset_type = arrow_type.GetDuckType();
1310: 	//! Get Pointer to Indices of Dictionary
1311: 	auto indices = ArrowBufferData<data_t>(array, 1) +
1312: 	               GetTypeIdSize(offset_type.InternalType()) *
1313: 	                   GetEffectiveOffset(array, NumericCast<int64_t>(parent_offset), scan_state, nested_offset);
1314: 
1315: 	SelectionVector sel;
1316: 	if (has_nulls) {
1317: 		ValidityMask indices_validity;
1318: 		GetValidityMask(indices_validity, array, scan_state, size, NumericCast<int64_t>(parent_offset));
1319: 		if (parent_mask && !parent_mask->AllValid()) {
1320: 			auto &struct_validity_mask = *parent_mask;
1321: 			for (idx_t i = 0; i < size; i++) {
1322: 				if (!struct_validity_mask.RowIsValid(i)) {
1323: 					indices_validity.SetInvalid(i);
1324: 				}
1325: 			}
1326: 		}
1327: 		SetSelectionVector(sel, indices, offset_type, size, &indices_validity,
1328: 		                   NumericCast<idx_t>(array.dictionary->length));
1329: 	} else {
1330: 		SetSelectionVector(sel, indices, offset_type, size);
1331: 	}
1332: 	vector.Slice(array_state.GetDictionary(), sel, size);
1333: 	vector.Verify(size);
1334: }
1335: 
1336: void ArrowTableFunction::ArrowToDuckDB(ArrowScanLocalState &scan_state, const arrow_column_map_t &arrow_convert_data,
1337:                                        DataChunk &output, idx_t start, bool arrow_scan_is_projected) {
1338: 	for (idx_t idx = 0; idx < output.ColumnCount(); idx++) {
1339: 		auto col_idx = scan_state.column_ids[idx];
1340: 
1341: 		// If projection was not pushed down into the arrow scanner, but projection pushdown is enabled on the
1342: 		// table function, we need to use original column ids here.
1343: 		auto arrow_array_idx = arrow_scan_is_projected ? idx : col_idx;
1344: 
1345: 		if (col_idx == COLUMN_IDENTIFIER_ROW_ID) {
1346: 			// This column is skipped by the projection pushdown
1347: 			continue;
1348: 		}
1349: 
1350: 		auto &parent_array = scan_state.chunk->arrow_array;
1351: 		auto &array = *scan_state.chunk->arrow_array.children[arrow_array_idx];
1352: 		if (!array.release) {
1353: 			throw InvalidInputException("arrow_scan: released array passed");
1354: 		}
1355: 		if (array.length != scan_state.chunk->arrow_array.length) {
1356: 			throw InvalidInputException("arrow_scan: array length mismatch");
1357: 		}
1358: 
1359: 		D_ASSERT(arrow_convert_data.find(col_idx) != arrow_convert_data.end());
1360: 		auto &arrow_type = *arrow_convert_data.at(col_idx);
1361: 		auto &array_state = scan_state.GetState(col_idx);
1362: 
1363: 		// Make sure this Vector keeps the Arrow chunk alive in case we can zero-copy the data
1364: 		if (!array_state.owned_data) {
1365: 			array_state.owned_data = scan_state.chunk;
1366: 		}
1367: 		output.data[idx].GetBuffer()->SetAuxiliaryData(make_uniq<ArrowAuxiliaryData>(array_state.owned_data));
1368: 
1369: 		auto array_physical_type = GetArrowArrayPhysicalType(arrow_type);
1370: 
1371: 		switch (array_physical_type) {
1372: 		case ArrowArrayPhysicalType::DICTIONARY_ENCODED:
1373: 			ColumnArrowToDuckDBDictionary(output.data[idx], array, array_state, output.size(), arrow_type);
1374: 			break;
1375: 		case ArrowArrayPhysicalType::RUN_END_ENCODED:
1376: 			ColumnArrowToDuckDBRunEndEncoded(output.data[idx], array, array_state, output.size(), arrow_type);
1377: 			break;
1378: 		case ArrowArrayPhysicalType::DEFAULT:
1379: 			SetValidityMask(output.data[idx], array, scan_state, output.size(), parent_array.offset, -1);
1380: 			ColumnArrowToDuckDB(output.data[idx], array, array_state, output.size(), arrow_type);
1381: 			break;
1382: 		default:
1383: 			throw NotImplementedException("ArrowArrayPhysicalType not recognized");
1384: 		}
1385: 	}
1386: }
1387: 
1388: } // namespace duckdb
[end of src/function/table/arrow_conversion.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: