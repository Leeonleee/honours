You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes.
In the patch file, please make sure to include the line numbers and a blank line at the end so it can be applied using git apply.

<issue>
group by a timestamp column in a parquet file can cause the process to crash
### What happens?

Group by a timestamp column in a parquet file can cause the process to crash.
[demo.parquet.zip](https://github.com/user-attachments/files/17427101/demo.zip)


### To Reproduce

```sql
SELECT a FROM 'demo.parquet' GROUP BY a;
```

### OS:

windows 11, x86_64

### DuckDB Version:

1.1.2

### DuckDB Client:

CLI

### Hardware:

_No response_

### Full Name:

Jason Jia

### Affiliation:

personal

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a stable release

### Did you include all relevant data sets for reproducing the issue?

Yes

### Did you include all code required to reproduce the issue?

- [X] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [X] Yes, I have

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <picture>
3:     <source media="(prefers-color-scheme: light)" srcset="logo/DuckDB_Logo-horizontal.svg">
4:     <source media="(prefers-color-scheme: dark)" srcset="logo/DuckDB_Logo-horizontal-dark-mode.svg">
5:     <img alt="DuckDB logo" src="logo/DuckDB_Logo-horizontal.svg" height="100">
6:   </picture>
7: </div>
8: <br>
9: 
10: <p align="center">
11:   <a href="https://github.com/duckdb/duckdb/actions"><img src="https://github.com/duckdb/duckdb/actions/workflows/Main.yml/badge.svg?branch=main" alt="Github Actions Badge"></a>
12:   <a href="https://discord.gg/tcvwpjfnZx"><img src="https://shields.io/discord/909674491309850675" alt="discord" /></a>
13:   <a href="https://github.com/duckdb/duckdb/releases/"><img src="https://img.shields.io/github/v/release/duckdb/duckdb?color=brightgreen&display_name=tag&logo=duckdb&logoColor=white" alt="Latest Release"></a>
14: </p>
15: 
16: ## DuckDB
17: 
18: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable, portable, and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs, maps), and [several extensions designed to make SQL easier to use](https://duckdb.org/docs/guides/sql_features/friendly_sql).
19: 
20: DuckDB is available as a [standalone CLI application](https://duckdb.org/docs/api/cli/overview) and has clients for [Python](https://duckdb.org/docs/api/python/overview), [R](https://duckdb.org/docs/api/r), [Java](https://duckdb.org/docs/api/java), [Wasm](https://duckdb.org/docs/api/wasm/overview), etc., with deep integrations with packages such as [pandas](https://duckdb.org/docs/guides/python/sql_on_pandas) and [dplyr](https://duckdblabs.github.io/duckplyr/).
21: 
22: For more information on using DuckDB, please refer to the [DuckDB documentation](https://duckdb.org/docs/).
23: 
24: ## Installation
25: 
26: If you want to install DuckDB, please see [our installation page](https://duckdb.org/docs/installation/) for instructions.
27: 
28: ## Data Import
29: 
30: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
31: 
32: ```sql
33: SELECT * FROM 'myfile.csv';
34: SELECT * FROM 'myfile.parquet';
35: ```
36: 
37: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
38: 
39: ## SQL Reference
40: 
41: The documentation contains a [SQL introduction and reference](https://duckdb.org/docs/sql/introduction).
42: 
43: ## Development
44: 
45: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run `BUILD_BENCHMARK=1 BUILD_TPCH=1 make` and then perform several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`. The details of benchmarks are in our [Benchmark Guide](benchmark/README.md).
46: 
47: Please also refer to our [Build Guide](https://duckdb.org/dev/building) and [Contribution Guide](CONTRIBUTING.md).
48: 
49: ## Support
50: 
51: See the [Support Options](https://duckdblabs.com/support/) page.
[end of README.md]
[start of src/execution/perfect_aggregate_hashtable.cpp]
1: #include "duckdb/execution/perfect_aggregate_hashtable.hpp"
2: 
3: #include "duckdb/common/numeric_utils.hpp"
4: #include "duckdb/common/row_operations/row_operations.hpp"
5: #include "duckdb/execution/expression_executor.hpp"
6: 
7: namespace duckdb {
8: 
9: PerfectAggregateHashTable::PerfectAggregateHashTable(ClientContext &context, Allocator &allocator,
10:                                                      const vector<LogicalType> &group_types_p,
11:                                                      vector<LogicalType> payload_types_p,
12:                                                      vector<AggregateObject> aggregate_objects_p,
13:                                                      vector<Value> group_minima_p, vector<idx_t> required_bits_p)
14:     : BaseAggregateHashTable(context, allocator, aggregate_objects_p, std::move(payload_types_p)),
15:       addresses(LogicalType::POINTER), required_bits(std::move(required_bits_p)), total_required_bits(0),
16:       group_minima(std::move(group_minima_p)), sel(STANDARD_VECTOR_SIZE),
17:       aggregate_allocator(make_uniq<ArenaAllocator>(allocator)) {
18: 	for (auto &group_bits : required_bits) {
19: 		total_required_bits += group_bits;
20: 	}
21: 	// the total amount of groups we allocate space for is 2^required_bits
22: 	total_groups = (uint64_t)1 << total_required_bits;
23: 	// we don't need to store the groups in a perfect hash table, since the group keys can be deduced by their location
24: 	grouping_columns = group_types_p.size();
25: 	layout.Initialize(std::move(aggregate_objects_p));
26: 	tuple_size = layout.GetRowWidth();
27: 
28: 	// allocate and null initialize the data
29: 	owned_data = make_unsafe_uniq_array_uninitialized<data_t>(tuple_size * total_groups);
30: 	data = owned_data.get();
31: 
32: 	// set up the empty payloads for every tuple, and initialize the "occupied" flag to false
33: 	group_is_set = make_unsafe_uniq_array_uninitialized<bool>(total_groups);
34: 	memset(group_is_set.get(), 0, total_groups * sizeof(bool));
35: 
36: 	// initialize the hash table for each entry
37: 	auto address_data = FlatVector::GetData<uintptr_t>(addresses);
38: 	idx_t init_count = 0;
39: 	for (idx_t i = 0; i < total_groups; i++) {
40: 		address_data[init_count] = uintptr_t(data) + (tuple_size * i);
41: 		init_count++;
42: 		if (init_count == STANDARD_VECTOR_SIZE) {
43: 			RowOperations::InitializeStates(layout, addresses, *FlatVector::IncrementalSelectionVector(), init_count);
44: 			init_count = 0;
45: 		}
46: 	}
47: 	RowOperations::InitializeStates(layout, addresses, *FlatVector::IncrementalSelectionVector(), init_count);
48: }
49: 
50: PerfectAggregateHashTable::~PerfectAggregateHashTable() {
51: 	Destroy();
52: }
53: 
54: template <class T>
55: static void ComputeGroupLocationTemplated(UnifiedVectorFormat &group_data, Value &min, uintptr_t *address_data,
56:                                           idx_t current_shift, idx_t count) {
57: 	auto data = UnifiedVectorFormat::GetData<T>(group_data);
58: 	auto min_val = min.GetValueUnsafe<T>();
59: 	if (!group_data.validity.AllValid()) {
60: 		for (idx_t i = 0; i < count; i++) {
61: 			auto index = group_data.sel->get_index(i);
62: 			// check if the value is NULL
63: 			// NULL groups are considered as "0" in the hash table
64: 			// that is to say, they have no effect on the position of the element (because 0 << shift is 0)
65: 			// we only need to handle non-null values here
66: 			if (group_data.validity.RowIsValid(index)) {
67: 				D_ASSERT(data[index] >= min_val);
68: 				auto adjusted_value = UnsafeNumericCast<uintptr_t>((data[index] - min_val) + 1);
69: 				address_data[i] += adjusted_value << current_shift;
70: 			}
71: 		}
72: 	} else {
73: 		// no null values: we can directly compute the addresses
74: 		for (idx_t i = 0; i < count; i++) {
75: 			auto index = group_data.sel->get_index(i);
76: 			auto adjusted_value = UnsafeNumericCast<uintptr_t>((data[index] - min_val) + 1);
77: 			address_data[i] += adjusted_value << current_shift;
78: 		}
79: 	}
80: }
81: 
82: static void ComputeGroupLocation(Vector &group, Value &min, uintptr_t *address_data, idx_t current_shift, idx_t count) {
83: 	UnifiedVectorFormat vdata;
84: 	group.ToUnifiedFormat(count, vdata);
85: 
86: 	switch (group.GetType().InternalType()) {
87: 	case PhysicalType::INT8:
88: 		ComputeGroupLocationTemplated<int8_t>(vdata, min, address_data, current_shift, count);
89: 		break;
90: 	case PhysicalType::INT16:
91: 		ComputeGroupLocationTemplated<int16_t>(vdata, min, address_data, current_shift, count);
92: 		break;
93: 	case PhysicalType::INT32:
94: 		ComputeGroupLocationTemplated<int32_t>(vdata, min, address_data, current_shift, count);
95: 		break;
96: 	case PhysicalType::INT64:
97: 		ComputeGroupLocationTemplated<int64_t>(vdata, min, address_data, current_shift, count);
98: 		break;
99: 	case PhysicalType::UINT8:
100: 		ComputeGroupLocationTemplated<uint8_t>(vdata, min, address_data, current_shift, count);
101: 		break;
102: 	case PhysicalType::UINT16:
103: 		ComputeGroupLocationTemplated<uint16_t>(vdata, min, address_data, current_shift, count);
104: 		break;
105: 	case PhysicalType::UINT32:
106: 		ComputeGroupLocationTemplated<uint32_t>(vdata, min, address_data, current_shift, count);
107: 		break;
108: 	case PhysicalType::UINT64:
109: 		ComputeGroupLocationTemplated<uint64_t>(vdata, min, address_data, current_shift, count);
110: 		break;
111: 	default:
112: 		throw InternalException("Unsupported group type for perfect aggregate hash table");
113: 	}
114: }
115: 
116: void PerfectAggregateHashTable::AddChunk(DataChunk &groups, DataChunk &payload) {
117: 	// first we need to find the location in the HT of each of the groups
118: 	auto address_data = FlatVector::GetData<uintptr_t>(addresses);
119: 	// zero-initialize the address data
120: 	memset(address_data, 0, groups.size() * sizeof(uintptr_t));
121: 	D_ASSERT(groups.ColumnCount() == group_minima.size());
122: 
123: 	// then compute the actual group location by iterating over each of the groups
124: 	idx_t current_shift = total_required_bits;
125: 	for (idx_t i = 0; i < groups.ColumnCount(); i++) {
126: 		current_shift -= required_bits[i];
127: 		ComputeGroupLocation(groups.data[i], group_minima[i], address_data, current_shift, groups.size());
128: 	}
129: 	// now we have the HT entry number for every tuple
130: 	// compute the actual pointer to the data by adding it to the base HT pointer and multiplying by the tuple size
131: 	for (idx_t i = 0; i < groups.size(); i++) {
132: 		const auto group = address_data[i];
133: 		D_ASSERT(group < total_groups);
134: 		group_is_set[group] = true;
135: 		address_data[i] = uintptr_t(data) + group * tuple_size;
136: 	}
137: 
138: 	// after finding the group location we update the aggregates
139: 	idx_t payload_idx = 0;
140: 	auto &aggregates = layout.GetAggregates();
141: 	RowOperationsState row_state(*aggregate_allocator);
142: 	for (idx_t aggr_idx = 0; aggr_idx < aggregates.size(); aggr_idx++) {
143: 		auto &aggregate = aggregates[aggr_idx];
144: 		auto input_count = (idx_t)aggregate.child_count;
145: 		if (aggregate.filter) {
146: 			RowOperations::UpdateFilteredStates(row_state, filter_set.GetFilterData(aggr_idx), aggregate, addresses,
147: 			                                    payload, payload_idx);
148: 		} else {
149: 			RowOperations::UpdateStates(row_state, aggregate, addresses, payload, payload_idx, payload.size());
150: 		}
151: 		// move to the next aggregate
152: 		payload_idx += input_count;
153: 		VectorOperations::AddInPlace(addresses, UnsafeNumericCast<int64_t>(aggregate.payload_size), payload.size());
154: 	}
155: }
156: 
157: void PerfectAggregateHashTable::Combine(PerfectAggregateHashTable &other) {
158: 	D_ASSERT(total_groups == other.total_groups);
159: 	D_ASSERT(tuple_size == other.tuple_size);
160: 
161: 	Vector source_addresses(LogicalType::POINTER);
162: 	Vector target_addresses(LogicalType::POINTER);
163: 	auto source_addresses_ptr = FlatVector::GetData<data_ptr_t>(source_addresses);
164: 	auto target_addresses_ptr = FlatVector::GetData<data_ptr_t>(target_addresses);
165: 
166: 	// iterate over all entries of both hash tables and call combine for all entries that can be combined
167: 	data_ptr_t source_ptr = other.data;
168: 	data_ptr_t target_ptr = data;
169: 	idx_t combine_count = 0;
170: 	RowOperationsState row_state(*aggregate_allocator);
171: 	for (idx_t i = 0; i < total_groups; i++) {
172: 		auto has_entry_source = other.group_is_set[i];
173: 		// we only have any work to do if the source has an entry for this group
174: 		if (has_entry_source) {
175: 			group_is_set[i] = true;
176: 			source_addresses_ptr[combine_count] = source_ptr;
177: 			target_addresses_ptr[combine_count] = target_ptr;
178: 			combine_count++;
179: 			if (combine_count == STANDARD_VECTOR_SIZE) {
180: 				RowOperations::CombineStates(row_state, layout, source_addresses, target_addresses, combine_count);
181: 				combine_count = 0;
182: 			}
183: 		}
184: 		source_ptr += tuple_size;
185: 		target_ptr += tuple_size;
186: 	}
187: 	RowOperations::CombineStates(row_state, layout, source_addresses, target_addresses, combine_count);
188: 
189: 	// FIXME: after moving the arena allocator, we currently have to ensure that the pointer is not nullptr, because the
190: 	// FIXME: Destroy()-function of the hash table expects an allocator in some cases (e.g., for sorted aggregates)
191: 	stored_allocators.push_back(std::move(other.aggregate_allocator));
192: 	other.aggregate_allocator = make_uniq<ArenaAllocator>(allocator);
193: }
194: 
195: template <class T>
196: static void ReconstructGroupVectorTemplated(uint32_t group_values[], Value &min, idx_t mask, idx_t shift,
197:                                             idx_t entry_count, Vector &result) {
198: 	auto data = FlatVector::GetData<T>(result);
199: 	auto &validity_mask = FlatVector::Validity(result);
200: 	auto min_data = min.GetValueUnsafe<T>();
201: 	for (idx_t i = 0; i < entry_count; i++) {
202: 		// extract the value of this group from the total group index
203: 		auto group_index = UnsafeNumericCast<int32_t>((group_values[i] >> shift) & mask);
204: 		if (group_index == 0) {
205: 			// if it is 0, the value is NULL
206: 			validity_mask.SetInvalid(i);
207: 		} else {
208: 			// otherwise we add the value (minus 1) to the min value
209: 			data[i] = UnsafeNumericCast<T>(UnsafeNumericCast<int64_t>(min_data) +
210: 			                               UnsafeNumericCast<int64_t>(group_index) - 1);
211: 		}
212: 	}
213: }
214: 
215: static void ReconstructGroupVector(uint32_t group_values[], Value &min, idx_t required_bits, idx_t shift,
216:                                    idx_t entry_count, Vector &result) {
217: 	// construct the mask for this entry
218: 	idx_t mask = ((uint64_t)1 << required_bits) - 1;
219: 	switch (result.GetType().InternalType()) {
220: 	case PhysicalType::INT8:
221: 		ReconstructGroupVectorTemplated<int8_t>(group_values, min, mask, shift, entry_count, result);
222: 		break;
223: 	case PhysicalType::INT16:
224: 		ReconstructGroupVectorTemplated<int16_t>(group_values, min, mask, shift, entry_count, result);
225: 		break;
226: 	case PhysicalType::INT32:
227: 		ReconstructGroupVectorTemplated<int32_t>(group_values, min, mask, shift, entry_count, result);
228: 		break;
229: 	case PhysicalType::INT64:
230: 		ReconstructGroupVectorTemplated<int64_t>(group_values, min, mask, shift, entry_count, result);
231: 		break;
232: 	case PhysicalType::UINT8:
233: 		ReconstructGroupVectorTemplated<uint8_t>(group_values, min, mask, shift, entry_count, result);
234: 		break;
235: 	case PhysicalType::UINT16:
236: 		ReconstructGroupVectorTemplated<uint16_t>(group_values, min, mask, shift, entry_count, result);
237: 		break;
238: 	case PhysicalType::UINT32:
239: 		ReconstructGroupVectorTemplated<uint32_t>(group_values, min, mask, shift, entry_count, result);
240: 		break;
241: 	case PhysicalType::UINT64:
242: 		ReconstructGroupVectorTemplated<uint64_t>(group_values, min, mask, shift, entry_count, result);
243: 		break;
244: 	default:
245: 		throw InternalException("Invalid type for perfect aggregate HT group");
246: 	}
247: }
248: 
249: void PerfectAggregateHashTable::Scan(idx_t &scan_position, DataChunk &result) {
250: 	auto data_pointers = FlatVector::GetData<data_ptr_t>(addresses);
251: 	uint32_t group_values[STANDARD_VECTOR_SIZE];
252: 
253: 	// iterate over the HT until we either have exhausted the entire HT, or
254: 	idx_t entry_count = 0;
255: 	for (; scan_position < total_groups; scan_position++) {
256: 		if (group_is_set[scan_position]) {
257: 			// this group is set: add it to the set of groups to extract
258: 			data_pointers[entry_count] = data + tuple_size * scan_position;
259: 			group_values[entry_count] = NumericCast<uint32_t>(scan_position);
260: 			entry_count++;
261: 			if (entry_count == STANDARD_VECTOR_SIZE) {
262: 				scan_position++;
263: 				break;
264: 			}
265: 		}
266: 	}
267: 	if (entry_count == 0) {
268: 		// no entries found
269: 		return;
270: 	}
271: 	// first reconstruct the groups from the group index
272: 	idx_t shift = total_required_bits;
273: 	for (idx_t i = 0; i < grouping_columns; i++) {
274: 		shift -= required_bits[i];
275: 		ReconstructGroupVector(group_values, group_minima[i], required_bits[i], shift, entry_count, result.data[i]);
276: 	}
277: 	// then construct the payloads
278: 	result.SetCardinality(entry_count);
279: 	RowOperationsState row_state(*aggregate_allocator);
280: 	RowOperations::FinalizeStates(row_state, layout, addresses, result, grouping_columns);
281: }
282: 
283: void PerfectAggregateHashTable::Destroy() {
284: 	// check if there is any destructor to call
285: 	bool has_destructor = false;
286: 	for (auto &aggr : layout.GetAggregates()) {
287: 		if (aggr.function.destructor) {
288: 			has_destructor = true;
289: 		}
290: 	}
291: 	if (!has_destructor) {
292: 		return;
293: 	}
294: 	// there are aggregates with destructors: loop over the hash table
295: 	// and call the destructor method for each of the aggregates
296: 	auto data_pointers = FlatVector::GetData<data_ptr_t>(addresses);
297: 	idx_t count = 0;
298: 
299: 	// iterate over all initialised slots of the hash table
300: 	RowOperationsState row_state(*aggregate_allocator);
301: 	data_ptr_t payload_ptr = data;
302: 	for (idx_t i = 0; i < total_groups; i++) {
303: 		data_pointers[count++] = payload_ptr;
304: 		if (count == STANDARD_VECTOR_SIZE) {
305: 			RowOperations::DestroyStates(row_state, layout, addresses, count);
306: 			count = 0;
307: 		}
308: 		payload_ptr += tuple_size;
309: 	}
310: 	RowOperations::DestroyStates(row_state, layout, addresses, count);
311: }
312: 
313: } // namespace duckdb
[end of src/execution/perfect_aggregate_hashtable.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: