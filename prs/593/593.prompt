You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
DISTINCT malfunctions for BOOLEAN
Consider the following statements:
```sql
CREATE TABLE t0(c0 BOOLEAN);
INSERT INTO t0 VALUES (NULL), (false);
SELECT DISTINCT t0.c0 FROM t0; -- expected: {NULL, false}, actual: {NULL, NULL}
```
Unexpectedly, the `DISTINCT` results in two `NULL` values being fetched. I found this bug based on the latest master version (ed92e9c555299378c86d4342c94663e65ab8eef7).
Query with complex ORDER BY causes an incorrect rowid value
Consider the following statements:
```sql
CREATE TABLE t0(c0 INT);
INSERT INTO t0 VALUES (1), (0), (1);
SELECT t0.rowid FROM t0 WHERE t0.rowid ORDER BY CASE ((t0.c0) ::BOOL) WHEN 1 THEN t0.rowid END; -- expected: {0, 2}, actual: {140671047175328, 2}
```
Unexpectedly, the `rowid` for the first row is some non-deterministic, large value. I found this based on commit dc352a3729f57252a1f6bfa18077fed9c4598a54.

</issue>
<code>
[start of README.md]
1: <img align="left" src="logo/duckdb-logo.png" height="120">
2: 
3: # DuckDB, the SQLite for Analytics
4: [![Travis](https://api.travis-ci.org/cwida/duckdb.svg?branch=master)](https://travis-ci.org/cwida/duckdb)
5: [![CodeFactor](https://www.codefactor.io/repository/github/cwida/duckdb/badge)](https://www.codefactor.io/repository/github/cwida/duckdb)
6: [![Coverage Status](https://coveralls.io/repos/github/cwida/duckdb/badge.svg?branch=master)](https://coveralls.io/github/cwida/duckdb?branch=master)
7: 
8: <br>
9: 
10: 
11: # Requirements
12: DuckDB requires [CMake](https://cmake.org) to be installed and a `C++11` compliant compiler. GCC 4.9 and newer, Clang 3.9 and newer and VisualStudio 2017 are tested on each revision.
13: 
14: ## Compiling
15: Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You may run `make unit` and `make allunit` to verify that your version works properly after making changes.
16: 
17: # Usage
18: A command line utility based on `sqlite3` can be found in either `build/release/duckdb_cli` (release, the default) or `build/debug/duckdb_cli` (debug).
19: 
20: # Embedding
21: As DuckDB is an embedded database, there is no database server to launch or client to connect to a running server. However, the database server can be embedded directly into an application using the C or C++ bindings. The main build process creates the shared library `build/release/src/libduckdb.[so|dylib|dll]` that can be linked against. A static library is built as well.
22: 
23: For examples on how to embed DuckDB into your application, see the [examples](https://github.com/cwida/duckdb/tree/master/examples) folder.
24: 
25: ## Benchmarks
26: After compiling, benchmarks can be executed from the root directory by executing `./build/release/benchmark/benchmark_runner`.
27: 
28: ## Standing on the Shoulders of Giants
29: DuckDB is implemented in C++ 11, should compile with GCC and clang, uses CMake to build and [Catch2](https://github.com/catchorg/Catch2) for testing. DuckDB uses some components from various Open-Source databases and draws inspiration from scientific publications. Here is an overview:
30: 
31: * Parser: We use the PostgreSQL parser that was [repackaged as a stand-alone library](https://github.com/lfittl/libpg_query). The translation to our own parse tree is inspired by [Peloton](https://pelotondb.io).
32: * Shell: We have adapted the [SQLite shell](https://sqlite.org/cli.html) to work with DuckDB.
33: * Tests: We use the [SQL Logic Tests from SQLite](https://www.sqlite.org/sqllogictest/doc/trunk/about.wiki) to test DuckDB.
34: * Query fuzzing: We use [SQLsmith](https://github.com/anse1/sqlsmith) to generate random queries for additional testing.
35: * Date Math: We use the date math component from [MonetDB](https://www.monetdb.org).
36: * SQL Window Functions: DuckDB's window functions implementation uses Segment Tree Aggregation as described in the paper "Efficient Processing of Window Functions in Analytical SQL Queries" by Viktor Leis, Kan Kundhikanjana, Alfons Kemper and Thomas Neumann.
37: * Execution engine: The vectorized execution engine is inspired by the paper "MonetDB/X100: Hyper-Pipelining Query Execution" by Peter Boncz, Marcin Zukowski and Niels Nes.
38: * Optimizer: DuckDB's optimizer draws inspiration from the papers "Dynamic programming strikes back" by Guido Moerkotte and Thomas Neumman as well as "Unnesting Arbitrary Queries" by Thomas Neumann and Alfons Kemper.
39: * Concurrency control: Our MVCC implementation is inspired by the paper "Fast Serializable Multi-Version Concurrency Control for Main-Memory Database Systems" by Thomas Neumann, Tobias Mühlbauer and Alfons Kemper.
40: * Regular Expression: DuckDB uses Google's [RE2](https://github.com/google/re2) regular expression engine.
41: 
42: ## Other pages
43: * [Continuous Benchmarking (CB™)](https://www.duckdb.org/benchmarks/index.html), runs TPC-H, TPC-DS and some microbenchmarks on every commit
[end of README.md]
[start of src/common/operator/cast_operators.cpp]
1: #include "duckdb/common/operator/cast_operators.hpp"
2: 
3: #include "duckdb/common/exception.hpp"
4: #include "duckdb/common/limits.hpp"
5: #include "duckdb/common/types/date.hpp"
6: #include "duckdb/common/types/time.hpp"
7: #include "duckdb/common/types/timestamp.hpp"
8: #include "duckdb/common/types/vector.hpp"
9: 
10: #include "fmt/format.h"
11: 
12: #include <cstdlib>
13: #include <cctype>
14: #include <cmath>
15: 
16: using namespace std;
17: 
18: namespace duckdb {
19: 
20: template <class SRC, class DST> static bool try_cast_with_overflow_check(SRC value, DST &result) {
21: 	if (value < MinimumValue<DST>() || value > MaximumValue<DST>()) {
22: 		return false;
23: 	}
24: 	result = (DST)value;
25: 	return true;
26: }
27: 
28: template <class SRC, class DST> static DST cast_with_overflow_check(SRC value) {
29: 	DST result;
30: 	if (!try_cast_with_overflow_check<SRC, DST>(value, result)) {
31: 		throw ValueOutOfRangeException((int64_t)value, GetTypeId<SRC>(), GetTypeId<DST>());
32: 	}
33: 	return result;
34: }
35: 
36: //===--------------------------------------------------------------------===//
37: // Numeric -> int8_t casts
38: //===--------------------------------------------------------------------===//
39: template <> bool TryCast::Operation(int16_t input, int8_t &result) {
40: 	return try_cast_with_overflow_check(input, result);
41: }
42: template <> bool TryCast::Operation(int32_t input, int8_t &result) {
43: 	return try_cast_with_overflow_check(input, result);
44: }
45: template <> bool TryCast::Operation(int64_t input, int8_t &result) {
46: 	return try_cast_with_overflow_check(input, result);
47: }
48: template <> bool TryCast::Operation(float input, int8_t &result) {
49: 	return try_cast_with_overflow_check(input, result);
50: }
51: template <> bool TryCast::Operation(double input, int8_t &result) {
52: 	return try_cast_with_overflow_check(input, result);
53: }
54: 
55: template <> int8_t Cast::Operation(int16_t input) {
56: 	return cast_with_overflow_check<int16_t, int8_t>(input);
57: }
58: template <> int8_t Cast::Operation(int32_t input) {
59: 	return cast_with_overflow_check<int32_t, int8_t>(input);
60: }
61: template <> int8_t Cast::Operation(int64_t input) {
62: 	return cast_with_overflow_check<int64_t, int8_t>(input);
63: }
64: template <> int8_t Cast::Operation(float input) {
65: 	return cast_with_overflow_check<float, int8_t>(input);
66: }
67: template <> int8_t Cast::Operation(double input) {
68: 	return cast_with_overflow_check<double, int8_t>(input);
69: }
70: //===--------------------------------------------------------------------===//
71: // Numeric -> int16_t casts
72: //===--------------------------------------------------------------------===//
73: template <> bool TryCast::Operation(int32_t input, int16_t &result) {
74: 	return try_cast_with_overflow_check(input, result);
75: }
76: template <> bool TryCast::Operation(int64_t input, int16_t &result) {
77: 	return try_cast_with_overflow_check(input, result);
78: }
79: template <> bool TryCast::Operation(float input, int16_t &result) {
80: 	return try_cast_with_overflow_check(input, result);
81: }
82: template <> bool TryCast::Operation(double input, int16_t &result) {
83: 	return try_cast_with_overflow_check(input, result);
84: }
85: 
86: template <> int16_t Cast::Operation(int32_t input) {
87: 	return cast_with_overflow_check<int32_t, int16_t>(input);
88: }
89: template <> int16_t Cast::Operation(int64_t input) {
90: 	return cast_with_overflow_check<int64_t, int16_t>(input);
91: }
92: template <> int16_t Cast::Operation(float input) {
93: 	return cast_with_overflow_check<float, int16_t>(input);
94: }
95: template <> int16_t Cast::Operation(double input) {
96: 	return cast_with_overflow_check<double, int16_t>(input);
97: }
98: //===--------------------------------------------------------------------===//
99: // Numeric -> int32_t casts
100: //===--------------------------------------------------------------------===//
101: template <> bool TryCast::Operation(int64_t input, int32_t &result) {
102: 	return try_cast_with_overflow_check(input, result);
103: }
104: template <> bool TryCast::Operation(float input, int32_t &result) {
105: 	return try_cast_with_overflow_check(input, result);
106: }
107: template <> bool TryCast::Operation(double input, int32_t &result) {
108: 	return try_cast_with_overflow_check(input, result);
109: }
110: 
111: template <> int32_t Cast::Operation(int64_t input) {
112: 	return cast_with_overflow_check<int64_t, int32_t>(input);
113: }
114: template <> int32_t Cast::Operation(float input) {
115: 	return cast_with_overflow_check<float, int32_t>(input);
116: }
117: template <> int32_t Cast::Operation(double input) {
118: 	return cast_with_overflow_check<double, int32_t>(input);
119: }
120: //===--------------------------------------------------------------------===//
121: // Numeric -> int64_t casts
122: //===--------------------------------------------------------------------===//
123: template <> bool TryCast::Operation(float input, int64_t &result) {
124: 	return try_cast_with_overflow_check(input, result);
125: }
126: template <> bool TryCast::Operation(double input, int64_t &result) {
127: 	return try_cast_with_overflow_check(input, result);
128: }
129: 
130: template <> int64_t Cast::Operation(float input) {
131: 	return cast_with_overflow_check<float, int64_t>(input);
132: }
133: template <> int64_t Cast::Operation(double input) {
134: 	return cast_with_overflow_check<double, int64_t>(input);
135: }
136: 
137: //===--------------------------------------------------------------------===//
138: // Double -> float casts
139: //===--------------------------------------------------------------------===//
140: template <> bool TryCast::Operation(double input, float &result) {
141: 	auto res = (float)input;
142: 	if (std::isnan(res) || std::isinf(res)) {
143: 		return false;
144: 	}
145: 	result = res;
146: 	return true;
147: }
148: 
149: template <> float Cast::Operation(double input) {
150: 	float result;
151: 	if (!TryCast::Operation(input, result)) {
152: 		throw ValueOutOfRangeException(input, GetTypeId<double>(), GetTypeId<float>());
153: 	}
154: 	return result;
155: }
156: 
157: //===--------------------------------------------------------------------===//
158: // Cast String -> Numeric
159: //===--------------------------------------------------------------------===//
160: template <class T> static T try_cast_string(string_t input) {
161: 	T result;
162: 	if (!TryCast::Operation<string_t, T>(input, result)) {
163: 		throw ConversionException("Could not convert string '%s' to numeric", input.GetData());
164: 	}
165: 	return result;
166: }
167: 
168: template <class T, bool NEGATIVE, bool ALLOW_EXPONENT> static bool IntegerCastLoop(const char *buf, T &result) {
169: 	idx_t pos = NEGATIVE ? 1 : 0;
170: 	while (buf[pos]) {
171: 		if (!std::isdigit(buf[pos])) {
172: 			// not a digit!
173: 			if (buf[pos] == '.') {
174: 				// decimal point: we accept decimal values for integers as well
175: 				// we just truncate them
176: 				// make sure everything after the period is a number
177: 				pos++;
178: 				while (buf[pos]) {
179: 					if (!std::isdigit(buf[pos++])) {
180: 						return false;
181: 					}
182: 				}
183: 				return true;
184: 			}
185: 			if (std::isspace(buf[pos])) {
186: 				// skip any trailing spaces
187: 				while (buf[++pos]) {
188: 					if (!std::isspace(buf[pos])) {
189: 						return false;
190: 					}
191: 				}
192: 				return true;
193: 			}
194: 			if (ALLOW_EXPONENT) {
195: 				if (buf[pos] == 'e' || buf[pos] == 'E') {
196: 					pos++;
197: 					int64_t exponent = 0;
198: 					int negative = buf[pos] == '-';
199: 					if (negative) {
200: 						if (!IntegerCastLoop<int64_t, true, false>(buf + pos, exponent)) {
201: 							return false;
202: 						}
203: 					} else {
204: 						if (!IntegerCastLoop<int64_t, false, false>(buf + pos, exponent)) {
205: 							return false;
206: 						}
207: 					}
208: 					double dbl_res = result * pow(10, exponent);
209: 					if (dbl_res < MinimumValue<T>() || dbl_res > MaximumValue<T>()) {
210: 						return false;
211: 					}
212: 					result = (T)dbl_res;
213: 					return true;
214: 				}
215: 			}
216: 			return false;
217: 		}
218: 		T digit = buf[pos++] - '0';
219: 		if (NEGATIVE) {
220: 			if (result < (MinimumValue<T>() + digit) / 10) {
221: 				return false;
222: 			}
223: 			result = result * 10 - digit;
224: 		} else {
225: 			if (result > (MaximumValue<T>() - digit) / 10) {
226: 				return false;
227: 			}
228: 			result = result * 10 + digit;
229: 		}
230: 	}
231: 	return pos > (NEGATIVE ? 1 : 0);
232: }
233: 
234: template <class T, bool ALLOW_EXPONENT = true> static bool TryIntegerCast(const char *buf, T &result) {
235: 	if (!*buf) {
236: 		return false;
237: 	}
238: 	// skip any spaces at the start
239: 	while (std::isspace(*buf)) {
240: 		buf++;
241: 	}
242: 	int negative = *buf == '-';
243: 
244: 	result = 0;
245: 	if (!negative) {
246: 		return IntegerCastLoop<T, false, ALLOW_EXPONENT>(buf, result);
247: 	} else {
248: 		return IntegerCastLoop<T, true, ALLOW_EXPONENT>(buf, result);
249: 	}
250: }
251: 
252: template <> bool TryCast::Operation(string_t input, bool &result) {
253: 	auto input_data = input.GetData();
254: 	if (input_data[0] == 't' || input_data[0] == 'T') {
255: 		result = true;
256: 	} else if (input_data[0] == 'f' || input_data[0] == 'F') {
257: 		result = false;
258: 	} else {
259: 		return false;
260: 	}
261: 	return true;
262: }
263: template <> bool TryCast::Operation(string_t input, int8_t &result) {
264: 	return TryIntegerCast<int8_t>(input.GetData(), result);
265: }
266: template <> bool TryCast::Operation(string_t input, int16_t &result) {
267: 	return TryIntegerCast<int16_t>(input.GetData(), result);
268: }
269: template <> bool TryCast::Operation(string_t input, int32_t &result) {
270: 	return TryIntegerCast<int32_t>(input.GetData(), result);
271: }
272: template <> bool TryCast::Operation(string_t input, int64_t &result) {
273: 	return TryIntegerCast<int64_t>(input.GetData(), result);
274: }
275: 
276: template <class T, bool NEGATIVE> static void ComputeDoubleResult(T &result, idx_t decimal, idx_t decimal_factor) {
277: 	if (decimal_factor > 1) {
278: 		if (NEGATIVE) {
279: 			result -= (T)decimal / (T)decimal_factor;
280: 		} else {
281: 			result += (T)decimal / (T)decimal_factor;
282: 		}
283: 	}
284: }
285: 
286: template <class T, bool NEGATIVE> static bool DoubleCastLoop(const char *buf, T &result) {
287: 	idx_t pos = NEGATIVE ? 1 : 0;
288: 	idx_t decimal = 0;
289: 	idx_t decimal_factor = 0;
290: 	while (buf[pos]) {
291: 		if (!std::isdigit(buf[pos])) {
292: 			// not a digit!
293: 			if (buf[pos] == '.') {
294: 				// decimal point
295: 				if (decimal_factor != 0) {
296: 					// nested periods
297: 					return false;
298: 				}
299: 				decimal_factor = 1;
300: 				pos++;
301: 				continue;
302: 			} else if (std::isspace(buf[pos])) {
303: 				// skip any trailing spaces
304: 				while (buf[++pos]) {
305: 					if (!std::isspace(buf[pos])) {
306: 						return false;
307: 					}
308: 				}
309: 				ComputeDoubleResult<T, NEGATIVE>(result, decimal, decimal_factor);
310: 				return true;
311: 			} else if (buf[pos] == 'e' || buf[pos] == 'E') {
312: 				// E power
313: 				// parse an integer, this time not allowing another exponent
314: 				pos++;
315: 				int64_t exponent;
316: 				if (!TryIntegerCast<int64_t, false>(buf + pos, exponent)) {
317: 					return false;
318: 				}
319: 				ComputeDoubleResult<T, NEGATIVE>(result, decimal, decimal_factor);
320: 				result = result * pow(10, exponent);
321: 				return true;
322: 			} else {
323: 				return false;
324: 			}
325: 		}
326: 		T digit = buf[pos++] - '0';
327: 		if (decimal_factor == 0) {
328: 			result = result * 10 + (NEGATIVE ? -digit : digit);
329: 		} else {
330: 			if (decimal_factor >= 1000000000000000000) {
331: 				// decimal value will overflow if we parse more, ignore any subsequent numbers
332: 				continue;
333: 			}
334: 			decimal = decimal * 10 + digit;
335: 			decimal_factor *= 10;
336: 		}
337: 	}
338: 	ComputeDoubleResult<T, NEGATIVE>(result, decimal, decimal_factor);
339: 	return pos > (NEGATIVE ? 1 : 0);
340: }
341: 
342: template <class T> bool CheckDoubleValidity(T value);
343: 
344: template <> bool CheckDoubleValidity(float value) {
345: 	return Value::FloatIsValid(value);
346: }
347: 
348: template <> bool CheckDoubleValidity(double value) {
349: 	return Value::DoubleIsValid(value);
350: }
351: 
352: template <class T> static bool TryDoubleCast(const char *buf, T &result) {
353: 	if (!*buf) {
354: 		return false;
355: 	}
356: 	// skip any spaces at the start
357: 	while (std::isspace(*buf)) {
358: 		buf++;
359: 	}
360: 	int negative = *buf == '-';
361: 
362: 	result = 0;
363: 	if (!negative) {
364: 		if (!DoubleCastLoop<T, false>(buf, result)) {
365: 			return false;
366: 		}
367: 	} else {
368: 		if (!DoubleCastLoop<T, true>(buf, result)) {
369: 			return false;
370: 		}
371: 	}
372: 	if (!CheckDoubleValidity<T>(result)) {
373: 		return false;
374: 	}
375: 	return true;
376: }
377: 
378: template <> bool TryCast::Operation(string_t input, float &result) {
379: 	return TryDoubleCast<float>(input.GetData(), result);
380: }
381: template <> bool TryCast::Operation(string_t input, double &result) {
382: 	return TryDoubleCast<double>(input.GetData(), result);
383: }
384: 
385: template <> bool Cast::Operation(string_t input) {
386: 	return try_cast_string<bool>(input);
387: }
388: template <> int8_t Cast::Operation(string_t input) {
389: 	return try_cast_string<int8_t>(input);
390: }
391: template <> int16_t Cast::Operation(string_t input) {
392: 	return try_cast_string<int16_t>(input);
393: }
394: template <> int32_t Cast::Operation(string_t input) {
395: 	return try_cast_string<int32_t>(input);
396: }
397: template <> int64_t Cast::Operation(string_t input) {
398: 	return try_cast_string<int64_t>(input);
399: }
400: template <> float Cast::Operation(string_t input) {
401: 	return try_cast_string<float>(input);
402: }
403: template <> double Cast::Operation(string_t input) {
404: 	return try_cast_string<double>(input);
405: }
406: 
407: //===--------------------------------------------------------------------===//
408: // Cast Numeric -> String
409: //===--------------------------------------------------------------------===//
410: template <class T> string CastToStandardString(T input) {
411: 	Vector v(TypeId::VARCHAR);
412: 	return StringCast::Operation(input, v).GetString();
413: }
414: 
415: template <> string Cast::Operation(bool input) {
416: 	return CastToStandardString(input);
417: }
418: template <> string Cast::Operation(int8_t input) {
419: 	return CastToStandardString(input);
420: }
421: template <> string Cast::Operation(int16_t input) {
422: 	return CastToStandardString(input);
423: }
424: template <> string Cast::Operation(int32_t input) {
425: 	return CastToStandardString(input);
426: }
427: template <> string Cast::Operation(int64_t input) {
428: 	return CastToStandardString(input);
429: }
430: template <> string Cast::Operation(float input) {
431: 	return CastToStandardString(input);
432: }
433: template <> string Cast::Operation(double input) {
434: 	return CastToStandardString(input);
435: }
436: template <> string Cast::Operation(string_t input) {
437: 	return input.GetString();
438: }
439: 
440: template <> string_t StringCast::Operation(bool input, Vector &vector) {
441: 	if (input) {
442: 		return StringVector::AddString(vector, "true", 4);
443: 	} else {
444: 		return StringVector::AddString(vector, "false", 5);
445: 	}
446: }
447: 
448: struct StringToIntegerCast {
449: 	template <class T> static int UnsignedLength(T value);
450: 
451: 	// Formats value in reverse and returns a pointer to the beginning.
452: 	template <class T> static char *FormatUnsigned(T value, char *ptr) {
453: 		while (value >= 100) {
454: 			// Integer division is slow so do it for a group of two digits instead
455: 			// of for every digit. The idea comes from the talk by Alexandrescu
456: 			// "Three Optimization Tips for C++". See speed-test for a comparison.
457: 			auto index = static_cast<unsigned>((value % 100) * 2);
458: 			value /= 100;
459: 			*--ptr = fmt::internal::data::digits[index + 1];
460: 			*--ptr = fmt::internal::data::digits[index];
461: 		}
462: 		if (value < 10) {
463: 			*--ptr = static_cast<char>('0' + value);
464: 			return ptr;
465: 		}
466: 		auto index = static_cast<unsigned>(value * 2);
467: 		*--ptr = fmt::internal::data::digits[index + 1];
468: 		*--ptr = fmt::internal::data::digits[index];
469: 		return ptr;
470: 	}
471: 
472: 	template <class SIGNED, class UNSIGNED> static string_t FormatSigned(SIGNED value, Vector &vector) {
473: 		int sign = -(value < 0);
474: 		UNSIGNED unsigned_value = (value ^ sign) - sign;
475: 		int length = UnsignedLength<UNSIGNED>(unsigned_value) - sign;
476: 		string_t result = StringVector::EmptyString(vector, length);
477: 		auto dataptr = result.GetData();
478: 		auto endptr = dataptr + length;
479: 		endptr = FormatUnsigned(unsigned_value, endptr);
480: 		if (sign) {
481: 			*--endptr = '-';
482: 		}
483: 		result.Finalize();
484: 		return result;
485: 	}
486: };
487: 
488: template <> int StringToIntegerCast::UnsignedLength(uint8_t value) {
489: 	int length = 1;
490: 	length += value >= 10;
491: 	length += value >= 100;
492: 	return length;
493: }
494: 
495: template <> int StringToIntegerCast::UnsignedLength(uint16_t value) {
496: 	int length = 1;
497: 	length += value >= 10;
498: 	length += value >= 100;
499: 	length += value >= 1000;
500: 	length += value >= 10000;
501: 	return length;
502: }
503: 
504: template <> int StringToIntegerCast::UnsignedLength(uint32_t value) {
505: 	if (value >= 10000) {
506: 		int length = 5;
507: 		length += value >= 100000;
508: 		length += value >= 1000000;
509: 		length += value >= 10000000;
510: 		length += value >= 100000000;
511: 		length += value >= 1000000000;
512: 		return length;
513: 	} else {
514: 		int length = 1;
515: 		length += value >= 10;
516: 		length += value >= 100;
517: 		length += value >= 1000;
518: 		return length;
519: 	}
520: }
521: 
522: template <> int StringToIntegerCast::UnsignedLength(uint64_t value) {
523: 	if (value >= 10000000000ULL) {
524: 		if (value >= 1000000000000000ULL) {
525: 			int length = 16;
526: 			length += value >= 10000000000000000ULL;
527: 			length += value >= 100000000000000000ULL;
528: 			length += value >= 1000000000000000000ULL;
529: 			length += value >= 10000000000000000000ULL;
530: 			return length;
531: 		} else {
532: 			int length = 11;
533: 			length += value >= 100000000000ULL;
534: 			length += value >= 1000000000000ULL;
535: 			length += value >= 10000000000000ULL;
536: 			length += value >= 100000000000000ULL;
537: 			return length;
538: 		}
539: 	} else {
540: 		if (value >= 100000ULL) {
541: 			int length = 6;
542: 			length += value >= 1000000ULL;
543: 			length += value >= 10000000ULL;
544: 			length += value >= 100000000ULL;
545: 			length += value >= 1000000000ULL;
546: 			return length;
547: 		} else {
548: 			int length = 1;
549: 			length += value >= 10ULL;
550: 			length += value >= 100ULL;
551: 			length += value >= 1000ULL;
552: 			length += value >= 10000ULL;
553: 			return length;
554: 		}
555: 	}
556: }
557: 
558: template <> string_t StringCast::Operation(int8_t input, Vector &vector) {
559: 	return StringToIntegerCast::FormatSigned<int8_t, uint8_t>(input, vector);
560: }
561: 
562: template <> string_t StringCast::Operation(int16_t input, Vector &vector) {
563: 	return StringToIntegerCast::FormatSigned<int16_t, uint16_t>(input, vector);
564: }
565: template <> string_t StringCast::Operation(int32_t input, Vector &vector) {
566: 	return StringToIntegerCast::FormatSigned<int32_t, uint32_t>(input, vector);
567: }
568: 
569: template <> string_t StringCast::Operation(int64_t input, Vector &vector) {
570: 	return StringToIntegerCast::FormatSigned<int64_t, uint64_t>(input, vector);
571: }
572: 
573: template <> string_t StringCast::Operation(float input, Vector &vector) {
574: 	std::string s = fmt::format("{}", input);
575: 	return StringVector::AddString(vector, s);
576: }
577: 
578: template <> string_t StringCast::Operation(double input, Vector &vector) {
579: 	std::string s = fmt::format("{}", input);
580: 	return StringVector::AddString(vector, s);
581: }
582: 
583: //===--------------------------------------------------------------------===//
584: // Cast From Date
585: //===--------------------------------------------------------------------===//
586: struct DateToStringCast {
587: 	static idx_t Length(int32_t date[], idx_t &year_length, bool &add_bc) {
588: 		// format is YYYY-MM-DD with optional (BC) at the end
589: 		// regular length is 10
590: 		idx_t length = 6;
591: 		year_length = 4;
592: 		add_bc = false;
593: 		if (date[0] <= 0) {
594: 			// add (BC) suffix
595: 			length += 5;
596: 			date[0] = -date[0];
597: 			add_bc = true;
598: 		} else {
599: 			// potentially add extra characters depending on length of year
600: 			year_length += date[0] >= 10000;
601: 			year_length += date[0] >= 100000;
602: 			year_length += date[0] >= 1000000;
603: 			year_length += date[0] >= 10000000;
604: 		}
605: 		length += year_length;
606: 		return length;
607: 	}
608: 
609: 	static void Format(char *data, int32_t date[], idx_t year_length, bool add_bc) {
610: 		// now we write the string, first write the year
611: 		auto endptr = data + year_length;
612: 		endptr = StringToIntegerCast::FormatUnsigned(date[0], endptr);
613: 		// add optional leading zeros
614: 		while (endptr > data) {
615: 			*--endptr = '0';
616: 		}
617: 		// now write the month and day
618: 		auto ptr = data + year_length;
619: 		for (int i = 1; i <= 2; i++) {
620: 			ptr[0] = '-';
621: 			if (date[i] < 10) {
622: 				ptr[1] = '0';
623: 				ptr[2] = '0' + date[i];
624: 			} else {
625: 				auto index = static_cast<unsigned>(date[i] * 2);
626: 				ptr[1] = fmt::internal::data::digits[index];
627: 				ptr[2] = fmt::internal::data::digits[index + 1];
628: 			}
629: 			ptr += 3;
630: 		}
631: 		// optionally add BC to the end of the date
632: 		if (add_bc) {
633: 			memcpy(ptr, " (BC)", 5);
634: 		}
635: 	}
636: };
637: 
638: template <> string_t CastFromDate::Operation(date_t input, Vector &vector) {
639: 	int32_t date[3];
640: 	Date::Convert(input, date[0], date[1], date[2]);
641: 
642: 	idx_t year_length;
643: 	bool add_bc;
644: 	idx_t length = DateToStringCast::Length(date, year_length, add_bc);
645: 
646: 	string_t result = StringVector::EmptyString(vector, length);
647: 	auto data = result.GetData();
648: 
649: 	DateToStringCast::Format(data, date, year_length, add_bc);
650: 
651: 	result.Finalize();
652: 	return result;
653: }
654: 
655: //===--------------------------------------------------------------------===//
656: // Cast To Date
657: //===--------------------------------------------------------------------===//
658: template <> date_t CastToDate::Operation(string_t input) {
659: 	return Date::FromCString(input.GetData());
660: }
661: 
662: //===--------------------------------------------------------------------===//
663: // Cast From Time
664: //===--------------------------------------------------------------------===//
665: struct TimeToStringCast {
666: 	static idx_t Length(int32_t time[]) {
667: 		// format is HH:MM:DD
668: 		// regular length is 8
669: 		idx_t length = 8;
670: 		if (time[3] > 0) {
671: 			// if there are msecs, we add the miliseconds after the time with a period separator
672: 			// i.e. the format becomes HH:MM:DD.msec
673: 			length += 4;
674: 		}
675: 		return length;
676: 	}
677: 
678: 	static void Format(char *data, idx_t length, int32_t time[]) {
679: 		// first write hour, month and day
680: 		auto ptr = data;
681: 		for (int i = 0; i <= 2; i++) {
682: 			if (time[i] < 10) {
683: 				ptr[0] = '0';
684: 				ptr[1] = '0' + time[i];
685: 			} else {
686: 				auto index = static_cast<unsigned>(time[i] * 2);
687: 				ptr[0] = fmt::internal::data::digits[index];
688: 				ptr[1] = fmt::internal::data::digits[index + 1];
689: 			}
690: 			ptr[2] = ':';
691: 			ptr += 3;
692: 		}
693: 		// now optionally write ms at the end
694: 		if (time[3] > 0) {
695: 			auto start = ptr;
696: 			ptr = StringToIntegerCast::FormatUnsigned(time[3], data + length);
697: 			while (ptr > start) {
698: 				*--ptr = '0';
699: 			}
700: 			*--ptr = '.';
701: 		}
702: 	}
703: };
704: 
705: template <> string_t CastFromTime::Operation(dtime_t input, Vector &vector) {
706: 	int32_t time[4];
707: 	Time::Convert(input, time[0], time[1], time[2], time[3]);
708: 
709: 	idx_t length = TimeToStringCast::Length(time);
710: 
711: 	string_t result = StringVector::EmptyString(vector, length);
712: 	auto data = result.GetData();
713: 
714: 	TimeToStringCast::Format(data, length, time);
715: 
716: 	result.Finalize();
717: 	return result;
718: }
719: 
720: //===--------------------------------------------------------------------===//
721: // Cast To Time
722: //===--------------------------------------------------------------------===//
723: template <> dtime_t CastToTime::Operation(string_t input) {
724: 	return Time::FromCString(input.GetData());
725: }
726: 
727: template <> timestamp_t CastDateToTimestamp::Operation(date_t input) {
728: 	return Timestamp::FromDatetime(input, Time::FromTime(0, 0, 0, 0));
729: }
730: 
731: //===--------------------------------------------------------------------===//
732: // Cast From Timestamps
733: //===--------------------------------------------------------------------===//
734: template <> string_t CastFromTimestamp::Operation(timestamp_t input, Vector &vector) {
735: 	date_t date_entry;
736: 	dtime_t time_entry;
737: 	Timestamp::Convert(input, date_entry, time_entry);
738: 
739: 	int32_t date[3], time[4];
740: 	Date::Convert(date_entry, date[0], date[1], date[2]);
741: 	Time::Convert(time_entry, time[0], time[1], time[2], time[3]);
742: 
743: 	// format for timestamp is DATE TIME (separated by space)
744: 	idx_t year_length;
745: 	bool add_bc;
746: 	idx_t date_length = DateToStringCast::Length(date, year_length, add_bc);
747: 	idx_t time_length = TimeToStringCast::Length(time);
748: 	idx_t length = date_length + time_length + 1;
749: 
750: 	string_t result = StringVector::EmptyString(vector, length);
751: 	auto data = result.GetData();
752: 
753: 	DateToStringCast::Format(data, date, year_length, add_bc);
754: 	data[date_length] = ' ';
755: 	TimeToStringCast::Format(data + date_length + 1, time_length, time);
756: 
757: 	result.Finalize();
758: 	return result;
759: }
760: 
761: template <> date_t CastTimestampToDate::Operation(timestamp_t input) {
762: 	return Timestamp::GetDate(input);
763: }
764: 
765: template <> dtime_t CastTimestampToTime::Operation(timestamp_t input) {
766: 	return Timestamp::GetTime(input);
767: }
768: 
769: //===--------------------------------------------------------------------===//
770: // Cast To Timestamp
771: //===--------------------------------------------------------------------===//
772: template <> timestamp_t CastToTimestamp::Operation(string_t input) {
773: 	return Timestamp::FromString(input.GetData());
774: }
775: 
776: } // namespace duckdb
[end of src/common/operator/cast_operators.cpp]
[start of src/common/types/vector.cpp]
1: #include <cstring> // strlen() on Solaris
2: 
3: #include "duckdb/common/types/vector.hpp"
4: 
5: #include "duckdb/common/assert.hpp"
6: #include "duckdb/common/exception.hpp"
7: #include "duckdb/common/printer.hpp"
8: #include "duckdb/common/vector_operations/vector_operations.hpp"
9: #include "duckdb/common/types/chunk_collection.hpp"
10: #include "duckdb/common/serializer.hpp"
11: #include "duckdb/common/types/null_value.hpp"
12: 
13: using namespace std;
14: 
15: namespace duckdb {
16: 
17: Vector::Vector(TypeId type, bool create_data, bool zero_data)
18:     : vector_type(VectorType::FLAT_VECTOR), type(type), data(nullptr) {
19: 	if (create_data) {
20: 		Initialize(type, zero_data);
21: 	}
22: }
23: 
24: Vector::Vector(TypeId type) : Vector(type, true, false) {
25: }
26: 
27: Vector::Vector(TypeId type, data_ptr_t dataptr) : vector_type(VectorType::FLAT_VECTOR), type(type), data(dataptr) {
28: 	if (dataptr && type == TypeId::INVALID) {
29: 		throw InvalidTypeException(type, "Cannot create a vector of type INVALID!");
30: 	}
31: }
32: 
33: Vector::Vector(Value value) : vector_type(VectorType::CONSTANT_VECTOR) {
34: 	Reference(value);
35: }
36: 
37: Vector::Vector() : vector_type(VectorType::FLAT_VECTOR), type(TypeId::INVALID), data(nullptr) {
38: }
39: 
40: Vector::Vector(Vector &&other) noexcept
41:     : vector_type(other.vector_type), type(other.type), data(other.data), nullmask(other.nullmask),
42:       buffer(move(other.buffer)), auxiliary(move(other.auxiliary)) {
43: }
44: 
45: void Vector::Reference(Value &value) {
46: 	vector_type = VectorType::CONSTANT_VECTOR;
47: 	type = value.type;
48: 	buffer = VectorBuffer::CreateConstantVector(type);
49: 	auxiliary.reset();
50: 	data = buffer->GetData();
51: 	SetValue(0, value);
52: }
53: 
54: void Vector::Reference(Vector &other) {
55: 	vector_type = other.vector_type;
56: 	buffer = other.buffer;
57: 	auxiliary = other.auxiliary;
58: 	data = other.data;
59: 	type = other.type;
60: 	nullmask = other.nullmask;
61: }
62: 
63: void Vector::Slice(Vector &other, idx_t offset) {
64: 	if (other.vector_type == VectorType::CONSTANT_VECTOR) {
65: 		Reference(other);
66: 		return;
67: 	}
68: 	assert(other.vector_type == VectorType::FLAT_VECTOR);
69: 
70: 	// create a reference to the other vector
71: 	Reference(other);
72: 	if (offset > 0) {
73: 		data = data + GetTypeIdSize(type) * offset;
74: 		nullmask <<= offset;
75: 	}
76: }
77: 
78: void Vector::Slice(Vector &other, const SelectionVector &sel, idx_t count) {
79: 	Reference(other);
80: 	Slice(sel, count);
81: }
82: 
83: void Vector::Slice(const SelectionVector &sel, idx_t count) {
84: 	if (vector_type == VectorType::CONSTANT_VECTOR) {
85: 		// dictionary on a constant is just a constant
86: 		return;
87: 	}
88: 	if (vector_type == VectorType::DICTIONARY_VECTOR) {
89: 		// already a dictionary, slice the current dictionary
90: 		auto &current_sel = DictionaryVector::SelVector(*this);
91: 		auto sliced_dictionary = current_sel.Slice(sel, count);
92: 		buffer = make_unique<DictionaryBuffer>(move(sliced_dictionary));
93: 		return;
94: 	}
95: 	auto child_ref = make_buffer<VectorChildBuffer>();
96: 	child_ref->data.Reference(*this);
97: 
98: 	auto dict_buffer = make_unique<DictionaryBuffer>(sel);
99: 	buffer = move(dict_buffer);
100: 	auxiliary = move(child_ref);
101: 	vector_type = VectorType::DICTIONARY_VECTOR;
102: }
103: 
104: void Vector::Slice(const SelectionVector &sel, idx_t count, sel_cache_t &cache) {
105: 	if (vector_type == VectorType::DICTIONARY_VECTOR) {
106: 		// dictionary vector: need to merge dictionaries
107: 		// check if we have a cached entry
108: 		auto &current_sel = DictionaryVector::SelVector(*this);
109: 		auto target_data = current_sel.data();
110: 		auto entry = cache.find(target_data);
111: 		if (entry != cache.end()) {
112: 			// cached entry exists: use that
113: 			this->buffer = entry->second;
114: 		} else {
115: 			Slice(sel, count);
116: 			cache[target_data] = this->buffer;
117: 		}
118: 	} else {
119: 		Slice(sel, count);
120: 	}
121: }
122: 
123: void Vector::Initialize(TypeId new_type, bool zero_data) {
124: 	if (new_type != TypeId::INVALID) {
125: 		type = new_type;
126: 	}
127: 	vector_type = VectorType::FLAT_VECTOR;
128: 	buffer.reset();
129: 	auxiliary.reset();
130: 	nullmask.reset();
131: 	if (GetTypeIdSize(type) > 0) {
132: 		buffer = VectorBuffer::CreateStandardVector(type);
133: 		data = buffer->GetData();
134: 		if (zero_data) {
135: 			memset(data, 0, STANDARD_VECTOR_SIZE * GetTypeIdSize(type));
136: 		}
137: 	}
138: }
139: 
140: void Vector::SetValue(idx_t index, Value val) {
141: 	if (vector_type == VectorType::DICTIONARY_VECTOR) {
142: 		// dictionary: apply dictionary and forward to child
143: 		auto &sel_vector = DictionaryVector::SelVector(*this);
144: 		auto &child = DictionaryVector::Child(*this);
145: 		return child.SetValue(sel_vector.get_index(index), move(val));
146: 	}
147: 	Value newVal = val.CastAs(type);
148: 
149: 	nullmask[index] = newVal.is_null;
150: 	if (newVal.is_null) {
151: 		return;
152: 	}
153: 	switch (type) {
154: 	case TypeId::BOOL:
155: 		((bool *)data)[index] = newVal.value_.boolean;
156: 		break;
157: 	case TypeId::INT8:
158: 		((int8_t *)data)[index] = newVal.value_.tinyint;
159: 		break;
160: 	case TypeId::INT16:
161: 		((int16_t *)data)[index] = newVal.value_.smallint;
162: 		break;
163: 	case TypeId::INT32:
164: 		((int32_t *)data)[index] = newVal.value_.integer;
165: 		break;
166: 	case TypeId::INT64:
167: 		((int64_t *)data)[index] = newVal.value_.bigint;
168: 		break;
169: 	case TypeId::FLOAT:
170: 		((float *)data)[index] = newVal.value_.float_;
171: 		break;
172: 	case TypeId::DOUBLE:
173: 		((double *)data)[index] = newVal.value_.double_;
174: 		break;
175: 	case TypeId::POINTER:
176: 		((uintptr_t *)data)[index] = newVal.value_.pointer;
177: 		break;
178: 	case TypeId::VARCHAR: {
179: 		((string_t *)data)[index] = StringVector::AddString(*this, newVal.str_value);
180: 		break;
181: 	}
182: 	case TypeId::STRUCT: {
183: 		if (!auxiliary || StructVector::GetEntries(*this).size() == 0) {
184: 			for (size_t i = 0; i < val.struct_value.size(); i++) {
185: 				auto &struct_child = val.struct_value[i];
186: 				auto cv = make_unique<Vector>(struct_child.second.type);
187: 				cv->vector_type = vector_type;
188: 				StructVector::AddEntry(*this, struct_child.first, move(cv));
189: 			}
190: 		}
191: 
192: 		auto &children = StructVector::GetEntries(*this);
193: 		assert(children.size() == val.struct_value.size());
194: 
195: 		for (size_t i = 0; i < val.struct_value.size(); i++) {
196: 			auto &struct_child = val.struct_value[i];
197: 			assert(vector_type == VectorType::CONSTANT_VECTOR || vector_type == VectorType::FLAT_VECTOR);
198: 			auto &vec_child = children[i];
199: 			assert(vec_child.first == struct_child.first);
200: 			vec_child.second->SetValue(index, struct_child.second);
201: 		}
202: 	} break;
203: 
204: 	case TypeId::LIST: {
205: 		if (!auxiliary) {
206: 			auto cc = make_unique<ChunkCollection>();
207: 			ListVector::SetEntry(*this, move(cc));
208: 		}
209: 		auto &child_cc = ListVector::GetEntry(*this);
210: 		// TODO optimization: in-place update if fits
211: 		auto offset = child_cc.count;
212: 		if (val.list_value.size() > 0) {
213: 			idx_t append_idx = 0;
214: 			while (append_idx < val.list_value.size()) {
215: 				idx_t this_append_len = min((idx_t)STANDARD_VECTOR_SIZE, val.list_value.size() - append_idx);
216: 
217: 				DataChunk child_append_chunk;
218: 				child_append_chunk.SetCardinality(this_append_len);
219: 				vector<TypeId> types;
220: 				types.push_back(val.list_value[0].type);
221: 				child_append_chunk.Initialize(types);
222: 				for (idx_t i = 0; i < this_append_len; i++) {
223: 					child_append_chunk.data[0].SetValue(i, val.list_value[i + append_idx]);
224: 				}
225: 				child_cc.Append(child_append_chunk);
226: 				append_idx += this_append_len;
227: 			}
228: 		}
229: 		// now set the pointer
230: 		auto &entry = ((list_entry_t *)data)[index];
231: 		entry.length = val.list_value.size();
232: 		entry.offset = offset;
233: 	} break;
234: 	default:
235: 		throw NotImplementedException("Unimplemented type for Vector::SetValue");
236: 	}
237: }
238: 
239: Value Vector::GetValue(idx_t index) const {
240: 	if (vector_type == VectorType::CONSTANT_VECTOR) {
241: 		index = 0;
242: 	} else if (vector_type == VectorType::DICTIONARY_VECTOR) {
243: 		// dictionary: apply dictionary and forward to child
244: 		auto &sel_vector = DictionaryVector::SelVector(*this);
245: 		auto &child = DictionaryVector::Child(*this);
246: 		return child.GetValue(sel_vector.get_index(index));
247: 	} else {
248: 		assert(vector_type == VectorType::FLAT_VECTOR);
249: 	}
250: 
251: 	if (nullmask[index]) {
252: 		return Value(type);
253: 	}
254: 	switch (type) {
255: 	case TypeId::BOOL:
256: 		return Value::BOOLEAN(((bool *)data)[index]);
257: 	case TypeId::INT8:
258: 		return Value::TINYINT(((int8_t *)data)[index]);
259: 	case TypeId::INT16:
260: 		return Value::SMALLINT(((int16_t *)data)[index]);
261: 	case TypeId::INT32:
262: 		return Value::INTEGER(((int32_t *)data)[index]);
263: 	case TypeId::INT64:
264: 		return Value::BIGINT(((int64_t *)data)[index]);
265: 	case TypeId::HASH:
266: 		return Value::HASH(((hash_t *)data)[index]);
267: 	case TypeId::POINTER:
268: 		return Value::POINTER(((uintptr_t *)data)[index]);
269: 	case TypeId::FLOAT:
270: 		return Value::FLOAT(((float *)data)[index]);
271: 	case TypeId::DOUBLE:
272: 		return Value::DOUBLE(((double *)data)[index]);
273: 	case TypeId::VARCHAR: {
274: 		auto str = ((string_t *)data)[index];
275: 		return Value(str.GetString());
276: 	}
277: 	case TypeId::STRUCT: {
278: 		Value ret(TypeId::STRUCT);
279: 		ret.is_null = false;
280: 		// we can derive the value schema from the vector schema
281: 		for (auto &struct_child : StructVector::GetEntries(*this)) {
282: 			ret.struct_value.push_back(pair<string, Value>(struct_child.first, struct_child.second->GetValue(index)));
283: 		}
284: 		return ret;
285: 	}
286: 	case TypeId::LIST: {
287: 		Value ret(TypeId::LIST);
288: 		ret.is_null = false;
289: 		auto offlen = ((list_entry_t *)data)[index];
290: 		auto &child_cc = ListVector::GetEntry(*this);
291: 		for (idx_t i = offlen.offset; i < offlen.offset + offlen.length; i++) {
292: 			ret.list_value.push_back(child_cc.GetValue(0, i));
293: 		}
294: 		return ret;
295: 	}
296: 	default:
297: 		throw NotImplementedException("Unimplemented type for value access");
298: 	}
299: }
300: 
301: string VectorTypeToString(VectorType type) {
302: 	switch (type) {
303: 	case VectorType::FLAT_VECTOR:
304: 		return "FLAT";
305: 	case VectorType::SEQUENCE_VECTOR:
306: 		return "SEQUENCE";
307: 	case VectorType::DICTIONARY_VECTOR:
308: 		return "DICTIONARY";
309: 	case VectorType::CONSTANT_VECTOR:
310: 		return "CONSTANT";
311: 	default:
312: 		return "UNKNOWN";
313: 	}
314: }
315: 
316: string Vector::ToString(idx_t count) const {
317: 	string retval = VectorTypeToString(vector_type) + " " + TypeIdToString(type) + ": " + to_string(count) + " = [ ";
318: 	switch (vector_type) {
319: 	case VectorType::FLAT_VECTOR:
320: 	case VectorType::DICTIONARY_VECTOR:
321: 		for (idx_t i = 0; i < count; i++) {
322: 			retval += GetValue(i).ToString() + (i == count - 1 ? "" : ", ");
323: 		}
324: 		break;
325: 	case VectorType::CONSTANT_VECTOR:
326: 		retval += GetValue(0).ToString();
327: 		break;
328: 	case VectorType::SEQUENCE_VECTOR: {
329: 		int64_t start, increment;
330: 		SequenceVector::GetSequence(*this, start, increment);
331: 		for (idx_t i = 0; i < count; i++) {
332: 			retval += to_string(start + increment * i) + (i == count - 1 ? "" : ", ");
333: 		}
334: 		break;
335: 	}
336: 	default:
337: 		retval += "UNKNOWN VECTOR TYPE";
338: 		break;
339: 	}
340: 	retval += "]";
341: 	return retval;
342: }
343: 
344: void Vector::Print(idx_t count) {
345: 	Printer::Print(ToString(count));
346: }
347: 
348: string Vector::ToString() const {
349: 	string retval = VectorTypeToString(vector_type) + " " + TypeIdToString(type) + ": (UNKNOWN COUNT) [ ";
350: 	switch (vector_type) {
351: 	case VectorType::FLAT_VECTOR:
352: 	case VectorType::DICTIONARY_VECTOR:
353: 		break;
354: 	case VectorType::CONSTANT_VECTOR:
355: 		retval += GetValue(0).ToString();
356: 		break;
357: 	case VectorType::SEQUENCE_VECTOR: {
358: 		break;
359: 	}
360: 	default:
361: 		retval += "UNKNOWN VECTOR TYPE";
362: 		break;
363: 	}
364: 	retval += "]";
365: 	return retval;
366: }
367: 
368: void Vector::Print() {
369: 	Printer::Print(ToString());
370: }
371: 
372: template <class T> static void flatten_constant_vector_loop(data_ptr_t data, data_ptr_t old_data, idx_t count) {
373: 	auto constant = *((T *)old_data);
374: 	auto output = (T *)data;
375: 	for (idx_t i = 0; i < count; i++) {
376: 		output[i] = constant;
377: 	}
378: }
379: 
380: void Vector::Normalify(idx_t count) {
381: 	switch (vector_type) {
382: 	case VectorType::FLAT_VECTOR:
383: 		// already a flat vector
384: 		break;
385: 	case VectorType::DICTIONARY_VECTOR: {
386: 		// create a new flat vector of this type
387: 		Vector other(type);
388: 		// now copy the data of this vector to the other vector, removing the selection vector in the process
389: 		VectorOperations::Copy(*this, other, count, 0, 0);
390: 		// create a reference to the data in the other vector
391: 		this->Reference(other);
392: 		break;
393: 	}
394: 	case VectorType::CONSTANT_VECTOR: {
395: 		vector_type = VectorType::FLAT_VECTOR;
396: 		// allocate a new buffer for the vector
397: 		auto old_buffer = move(buffer);
398: 		auto old_data = data;
399: 		buffer = VectorBuffer::CreateStandardVector(type);
400: 		data = buffer->GetData();
401: 		if (nullmask[0]) {
402: 			// constant NULL, set nullmask
403: 			nullmask.set();
404: 			return;
405: 		}
406: 		// non-null constant: have to repeat the constant
407: 		switch (type) {
408: 		case TypeId::BOOL:
409: 		case TypeId::INT8:
410: 			flatten_constant_vector_loop<int8_t>(data, old_data, count);
411: 			break;
412: 		case TypeId::INT16:
413: 			flatten_constant_vector_loop<int16_t>(data, old_data, count);
414: 			break;
415: 		case TypeId::INT32:
416: 			flatten_constant_vector_loop<int32_t>(data, old_data, count);
417: 			break;
418: 		case TypeId::INT64:
419: 			flatten_constant_vector_loop<int64_t>(data, old_data, count);
420: 			break;
421: 		case TypeId::FLOAT:
422: 			flatten_constant_vector_loop<float>(data, old_data, count);
423: 			break;
424: 		case TypeId::DOUBLE:
425: 			flatten_constant_vector_loop<double>(data, old_data, count);
426: 			break;
427: 		case TypeId::HASH:
428: 			flatten_constant_vector_loop<hash_t>(data, old_data, count);
429: 			break;
430: 		case TypeId::POINTER:
431: 			flatten_constant_vector_loop<uintptr_t>(data, old_data, count);
432: 			break;
433: 		case TypeId::VARCHAR:
434: 			flatten_constant_vector_loop<string_t>(data, old_data, count);
435: 			break;
436: 		case TypeId::LIST: {
437: 			flatten_constant_vector_loop<list_entry_t>(data, old_data, count);
438: 			break;
439: 		}
440: 		case TypeId::STRUCT: {
441: 			for (auto &child : StructVector::GetEntries(*this)) {
442: 				assert(child.second->vector_type == VectorType::CONSTANT_VECTOR);
443: 				child.second->Normalify(count);
444: 			}
445: 		} break;
446: 		default:
447: 			throw NotImplementedException("Unimplemented type for VectorOperations::Normalify");
448: 		}
449: 		break;
450: 	}
451: 	case VectorType::SEQUENCE_VECTOR: {
452: 		int64_t start, increment;
453: 		SequenceVector::GetSequence(*this, start, increment);
454: 
455: 		vector_type = VectorType::FLAT_VECTOR;
456: 		buffer = VectorBuffer::CreateStandardVector(type);
457: 		data = buffer->GetData();
458: 		VectorOperations::GenerateSequence(*this, count, start, increment);
459: 		break;
460: 	}
461: 	default:
462: 		throw NotImplementedException("FIXME: unimplemented type for normalify");
463: 	}
464: }
465: 
466: void Vector::Normalify(const SelectionVector &sel, idx_t count) {
467: 	switch (vector_type) {
468: 	case VectorType::FLAT_VECTOR:
469: 		// already a flat vector
470: 		break;
471: 	case VectorType::SEQUENCE_VECTOR: {
472: 		int64_t start, increment;
473: 		SequenceVector::GetSequence(*this, start, increment);
474: 
475: 		vector_type = VectorType::FLAT_VECTOR;
476: 		buffer = VectorBuffer::CreateStandardVector(type);
477: 		data = buffer->GetData();
478: 		VectorOperations::GenerateSequence(*this, count, sel, start, increment);
479: 		break;
480: 	}
481: 	default:
482: 		throw NotImplementedException("Unimplemented type for normalify with selection vector");
483: 	}
484: }
485: 
486: void Vector::Orrify(idx_t count, VectorData &data) {
487: 	switch (vector_type) {
488: 	case VectorType::DICTIONARY_VECTOR: {
489: 		auto &sel = DictionaryVector::SelVector(*this);
490: 		auto &child = DictionaryVector::Child(*this);
491: 		child.Normalify(sel, count);
492: 
493: 		data.sel = &sel;
494: 		data.data = FlatVector::GetData(child);
495: 		data.nullmask = &FlatVector::Nullmask(child);
496: 		break;
497: 	}
498: 	case VectorType::CONSTANT_VECTOR:
499: 		data.sel = &ConstantVector::ZeroSelectionVector;
500: 		data.data = ConstantVector::GetData(*this);
501: 		data.nullmask = &nullmask;
502: 		break;
503: 	default:
504: 		Normalify(count);
505: 		data.sel = &FlatVector::IncrementalSelectionVector;
506: 		data.data = FlatVector::GetData(*this);
507: 		data.nullmask = &nullmask;
508: 		break;
509: 	}
510: }
511: 
512: void Vector::Sequence(int64_t start, int64_t increment) {
513: 	vector_type = VectorType::SEQUENCE_VECTOR;
514: 	this->buffer = make_buffer<VectorBuffer>(sizeof(int64_t) * 2);
515: 	auto data = (int64_t *)buffer->GetData();
516: 	data[0] = start;
517: 	data[1] = increment;
518: 	nullmask.reset();
519: 	auxiliary.reset();
520: }
521: 
522: void Vector::Serialize(idx_t count, Serializer &serializer) {
523: 	if (TypeIsConstantSize(type)) {
524: 		// constant size type: simple copy
525: 		idx_t write_size = GetTypeIdSize(type) * count;
526: 		auto ptr = unique_ptr<data_t[]>(new data_t[write_size]);
527: 		VectorOperations::WriteToStorage(*this, count, ptr.get());
528: 		serializer.WriteData(ptr.get(), write_size);
529: 	} else {
530: 		VectorData vdata;
531: 		Orrify(count, vdata);
532: 
533: 		switch (type) {
534: 		case TypeId::VARCHAR: {
535: 			auto strings = (string_t *)vdata.data;
536: 			for (idx_t i = 0; i < count; i++) {
537: 				auto idx = vdata.sel->get_index(i);
538: 				auto source = (*vdata.nullmask)[idx] ? NullValue<const char *>() : strings[idx].GetData();
539: 				serializer.WriteString(source);
540: 			}
541: 			break;
542: 		}
543: 		default:
544: 			throw NotImplementedException("Unimplemented type for Vector::Serialize!");
545: 		}
546: 	}
547: }
548: 
549: void Vector::Deserialize(idx_t count, Deserializer &source) {
550: 	if (TypeIsConstantSize(type)) {
551: 		// constant size type: read fixed amount of data from
552: 		auto column_size = GetTypeIdSize(type) * count;
553: 		auto ptr = unique_ptr<data_t[]>(new data_t[column_size]);
554: 		source.ReadData(ptr.get(), column_size);
555: 
556: 		VectorOperations::ReadFromStorage(ptr.get(), count, *this);
557: 	} else {
558: 		auto strings = FlatVector::GetData<string_t>(*this);
559: 		auto &nullmask = FlatVector::Nullmask(*this);
560: 		for (idx_t i = 0; i < count; i++) {
561: 			// read the strings
562: 			auto str = source.Read<string>();
563: 			// now add the string to the StringHeap of the vector
564: 			// and write the pointer into the vector
565: 			if (IsNullValue<const char *>((const char *)str.c_str())) {
566: 				nullmask[i] = true;
567: 			} else {
568: 				strings[i] = StringVector::AddString(*this, str);
569: 			}
570: 		}
571: 	}
572: }
573: 
574: void Vector::Verify(const SelectionVector &sel, idx_t count) {
575: #ifdef DEBUG
576: 	if (count == 0) {
577: 		return;
578: 	}
579: 	if (vector_type == VectorType::DICTIONARY_VECTOR) {
580: 		auto &child = DictionaryVector::Child(*this);
581: 		auto &dict_sel = DictionaryVector::SelVector(*this);
582: 		for (idx_t i = 0; i < count; i++) {
583: 			auto oidx = sel.get_index(i);
584: 			auto idx = dict_sel.get_index(oidx);
585: 			assert(idx < STANDARD_VECTOR_SIZE);
586: 		}
587: 		// merge the selection vectors and verify the child
588: 		auto new_buffer = dict_sel.Slice(sel, count);
589: 		SelectionVector new_sel(new_buffer);
590: 		child.Verify(new_sel, count);
591: 		return;
592: 	}
593: 	if (type == TypeId::VARCHAR) {
594: 		// we just touch all the strings and let the sanitizer figure out if any
595: 		// of them are deallocated/corrupt
596: 		switch (vector_type) {
597: 		case VectorType::CONSTANT_VECTOR: {
598: 			auto string = ConstantVector::GetData<string_t>(*this);
599: 			if (!ConstantVector::IsNull(*this)) {
600: 				string->Verify();
601: 			}
602: 			break;
603: 		}
604: 		case VectorType::FLAT_VECTOR: {
605: 			auto strings = FlatVector::GetData<string_t>(*this);
606: 			for (idx_t i = 0; i < count; i++) {
607: 				auto oidx = sel.get_index(i);
608: 				if (!nullmask[oidx]) {
609: 					strings[oidx].Verify();
610: 				}
611: 			}
612: 			break;
613: 		}
614: 		default:
615: 			break;
616: 		}
617: 	}
618: 	if (type == TypeId::DOUBLE) {
619: 		// verify that there are no INF or NAN values
620: 		switch (vector_type) {
621: 		case VectorType::CONSTANT_VECTOR: {
622: 			auto dbl = ConstantVector::GetData<double>(*this);
623: 			if (!ConstantVector::IsNull(*this)) {
624: 				assert(Value::DoubleIsValid(*dbl));
625: 			}
626: 			break;
627: 		}
628: 		case VectorType::FLAT_VECTOR: {
629: 			auto doubles = FlatVector::GetData<double>(*this);
630: 			for (idx_t i = 0; i < count; i++) {
631: 				auto oidx = sel.get_index(i);
632: 				if (!nullmask[oidx]) {
633: 					assert(Value::DoubleIsValid(doubles[oidx]));
634: 				}
635: 			}
636: 			break;
637: 		}
638: 		default:
639: 			break;
640: 		}
641: 	}
642: 
643: 	if (type == TypeId::STRUCT) {
644: 		if (vector_type == VectorType::FLAT_VECTOR || vector_type == VectorType::CONSTANT_VECTOR) {
645: 			auto &children = StructVector::GetEntries(*this);
646: 			assert(children.size() > 0);
647: 			for (auto &child : children) {
648: 				child.second->Verify(sel, count);
649: 			}
650: 		}
651: 	}
652: 
653: 	if (type == TypeId::LIST) {
654: 		if (vector_type == VectorType::CONSTANT_VECTOR) {
655: 			if (!ConstantVector::IsNull(*this)) {
656: 				ListVector::GetEntry(*this).Verify();
657: 				auto le = ConstantVector::GetData<list_entry_t>(*this);
658: 				assert(le->offset + le->length <= ListVector::GetEntry(*this).count);
659: 			}
660: 		} else if (vector_type == VectorType::FLAT_VECTOR) {
661: 			if (ListVector::HasEntry(*this)) {
662: 				ListVector::GetEntry(*this).Verify();
663: 			}
664: 			auto list_data = FlatVector::GetData<list_entry_t>(*this);
665: 			for (idx_t i = 0; i < count; i++) {
666: 				auto idx = sel.get_index(i);
667: 				auto &le = list_data[idx];
668: 				if (!nullmask[idx]) {
669: 					assert(le.offset + le.length <= ListVector::GetEntry(*this).count);
670: 				}
671: 			}
672: 		}
673: 	}
674: // TODO verify list and struct
675: #endif
676: }
677: 
678: void Vector::Verify(idx_t count) {
679: 	Verify(FlatVector::IncrementalSelectionVector, count);
680: }
681: 
682: string_t StringVector::AddString(Vector &vector, const char *data, idx_t len) {
683: 	return StringVector::AddString(vector, string_t(data, len));
684: }
685: 
686: string_t StringVector::AddString(Vector &vector, const char *data) {
687: 	return StringVector::AddString(vector, string_t(data, strlen(data)));
688: }
689: 
690: string_t StringVector::AddString(Vector &vector, const string &data) {
691: 	return StringVector::AddString(vector, string_t(data.c_str(), data.size()));
692: }
693: 
694: string_t StringVector::AddString(Vector &vector, string_t data) {
695: 	assert(vector.type == TypeId::VARCHAR);
696: 	if (data.IsInlined()) {
697: 		// string will be inlined: no need to store in string heap
698: 		return data;
699: 	}
700: 	if (!vector.auxiliary) {
701: 		vector.auxiliary = make_buffer<VectorStringBuffer>();
702: 	}
703: 	assert(vector.auxiliary->type == VectorBufferType::STRING_BUFFER);
704: 	auto &string_buffer = (VectorStringBuffer &)*vector.auxiliary;
705: 	return string_buffer.AddString(data);
706: }
707: 
708: string_t StringVector::EmptyString(Vector &vector, idx_t len) {
709: 	assert(vector.type == TypeId::VARCHAR);
710: 	if (len < string_t::INLINE_LENGTH) {
711: 		return string_t(len);
712: 	}
713: 	if (!vector.auxiliary) {
714: 		vector.auxiliary = make_buffer<VectorStringBuffer>();
715: 	}
716: 	assert(vector.auxiliary->type == VectorBufferType::STRING_BUFFER);
717: 	auto &string_buffer = (VectorStringBuffer &)*vector.auxiliary;
718: 	return string_buffer.EmptyString(len);
719: }
720: 
721: void StringVector::AddHeapReference(Vector &vector, Vector &other) {
722: 	assert(vector.type == TypeId::VARCHAR);
723: 	assert(other.type == TypeId::VARCHAR);
724: 
725: 	if (other.vector_type == VectorType::DICTIONARY_VECTOR) {
726: 		StringVector::AddHeapReference(vector, DictionaryVector::Child(other));
727: 		return;
728: 	}
729: 	if (!other.auxiliary) {
730: 		return;
731: 	}
732: 	if (!vector.auxiliary) {
733: 		vector.auxiliary = make_buffer<VectorStringBuffer>();
734: 	}
735: 	assert(vector.auxiliary->type == VectorBufferType::STRING_BUFFER);
736: 	assert(other.auxiliary->type == VectorBufferType::STRING_BUFFER);
737: 	auto &string_buffer = (VectorStringBuffer &)*vector.auxiliary;
738: 	string_buffer.AddHeapReference(other.auxiliary);
739: }
740: 
741: bool StructVector::HasEntries(const Vector &vector) {
742: 	assert(vector.type == TypeId::STRUCT);
743: 	assert(vector.vector_type == VectorType::FLAT_VECTOR || vector.vector_type == VectorType::CONSTANT_VECTOR);
744: 	assert(vector.auxiliary == nullptr || vector.auxiliary->type == VectorBufferType::STRUCT_BUFFER);
745: 	return vector.auxiliary != nullptr;
746: }
747: 
748: child_list_t<unique_ptr<Vector>> &StructVector::GetEntries(const Vector &vector) {
749: 	assert(vector.type == TypeId::STRUCT);
750: 	assert(vector.vector_type == VectorType::FLAT_VECTOR || vector.vector_type == VectorType::CONSTANT_VECTOR);
751: 	assert(vector.auxiliary);
752: 	assert(vector.auxiliary->type == VectorBufferType::STRUCT_BUFFER);
753: 	return ((VectorStructBuffer *)vector.auxiliary.get())->GetChildren();
754: }
755: 
756: void StructVector::AddEntry(Vector &vector, string name, unique_ptr<Vector> entry) {
757: 	// TODO asser that an entry with this name does not already exist
758: 	assert(vector.type == TypeId::STRUCT);
759: 	assert(vector.vector_type == VectorType::FLAT_VECTOR || vector.vector_type == VectorType::CONSTANT_VECTOR);
760: 	if (!vector.auxiliary) {
761: 		vector.auxiliary = make_buffer<VectorStructBuffer>();
762: 	}
763: 	assert(vector.auxiliary);
764: 	assert(vector.auxiliary->type == VectorBufferType::STRUCT_BUFFER);
765: 	((VectorStructBuffer *)vector.auxiliary.get())->AddChild(name, move(entry));
766: }
767: 
768: bool ListVector::HasEntry(const Vector &vector) {
769: 	assert(vector.type == TypeId::LIST);
770: 	if (vector.vector_type == VectorType::DICTIONARY_VECTOR) {
771: 		auto &child = DictionaryVector::Child(vector);
772: 		return ListVector::HasEntry(child);
773: 	}
774: 	assert(vector.vector_type == VectorType::FLAT_VECTOR || vector.vector_type == VectorType::CONSTANT_VECTOR);
775: 	return vector.auxiliary != nullptr;
776: }
777: 
778: ChunkCollection &ListVector::GetEntry(const Vector &vector) {
779: 	assert(vector.type == TypeId::LIST);
780: 	if (vector.vector_type == VectorType::DICTIONARY_VECTOR) {
781: 		auto &child = DictionaryVector::Child(vector);
782: 		return ListVector::GetEntry(child);
783: 	}
784: 	assert(vector.vector_type == VectorType::FLAT_VECTOR || vector.vector_type == VectorType::CONSTANT_VECTOR);
785: 	assert(vector.auxiliary);
786: 	assert(vector.auxiliary->type == VectorBufferType::LIST_BUFFER);
787: 	return ((VectorListBuffer *)vector.auxiliary.get())->GetChild();
788: }
789: 
790: void ListVector::SetEntry(Vector &vector, unique_ptr<ChunkCollection> cc) {
791: 	assert(vector.type == TypeId::LIST);
792: 	assert(vector.vector_type == VectorType::FLAT_VECTOR || vector.vector_type == VectorType::CONSTANT_VECTOR);
793: 	if (!vector.auxiliary) {
794: 		vector.auxiliary = make_buffer<VectorListBuffer>();
795: 	}
796: 	assert(vector.auxiliary);
797: 	assert(vector.auxiliary->type == VectorBufferType::LIST_BUFFER);
798: 	((VectorListBuffer *)vector.auxiliary.get())->SetChild(move(cc));
799: }
800: 
801: } // namespace duckdb
[end of src/common/types/vector.cpp]
[start of src/function/aggregate/distributive/first.cpp]
1: #include "duckdb/function/aggregate/distributive_functions.hpp"
2: #include "duckdb/common/exception.hpp"
3: #include "duckdb/common/types/null_value.hpp"
4: #include "duckdb/common/vector_operations/vector_operations.hpp"
5: 
6: using namespace std;
7: 
8: namespace duckdb {
9: 
10: template <class T> struct FirstState {
11: 	bool is_set;
12: 	T value;
13: };
14: 
15: struct FirstFunctionBase {
16: 	template <class STATE> static void Initialize(STATE *state) {
17: 		state->is_set = false;
18: 	}
19: 
20: 	template <class STATE, class OP> static void Combine(STATE source, STATE *target) {
21: 		if (!target->is_set) {
22: 			*target = source;
23: 		}
24: 	}
25: 
26: 	static bool IgnoreNull() {
27: 		return false;
28: 	}
29: };
30: 
31: struct FirstFunction : public FirstFunctionBase {
32: 	template <class INPUT_TYPE, class STATE, class OP>
33: 	static void Operation(STATE *state, INPUT_TYPE *input, nullmask_t &nullmask, idx_t idx) {
34: 		if (!state->is_set) {
35: 			state->is_set = true;
36: 			if (nullmask[idx]) {
37: 				state->value = NullValue<INPUT_TYPE>();
38: 			} else {
39: 				state->value = input[idx];
40: 			}
41: 		}
42: 	}
43: 
44: 	template <class INPUT_TYPE, class STATE, class OP>
45: 	static void ConstantOperation(STATE *state, INPUT_TYPE *input, nullmask_t &nullmask, idx_t count) {
46: 		Operation<INPUT_TYPE, STATE, OP>(state, input, nullmask, 0);
47: 	}
48: 
49: 	template <class T, class STATE>
50: 	static void Finalize(Vector &result, STATE *state, T *target, nullmask_t &nullmask, idx_t idx) {
51: 		if (!state->is_set || IsNullValue<T>(state->value)) {
52: 			nullmask[idx] = true;
53: 		} else {
54: 			target[idx] = state->value;
55: 		}
56: 	}
57: };
58: 
59: struct FirstFunctionString : public FirstFunctionBase {
60: 	template <class INPUT_TYPE, class STATE, class OP>
61: 	static void Operation(STATE *state, INPUT_TYPE *input, nullmask_t &nullmask, idx_t idx) {
62: 		if (!state->is_set) {
63: 			state->is_set = true;
64: 			if (nullmask[idx]) {
65: 				state->value = NullValue<INPUT_TYPE>();
66: 			} else {
67: 				if (input[idx].IsInlined()) {
68: 					state->value = input[idx];
69: 				} else {
70: 					// non-inlined string, need to allocate space for it
71: 					auto len = input[idx].GetSize();
72: 					auto ptr = new char[len + 1];
73: 					memcpy(ptr, input[idx].GetData(), len + 1);
74: 
75: 					state->value = string_t(ptr, len);
76: 				}
77: 			}
78: 		}
79: 	}
80: 
81: 	template <class INPUT_TYPE, class STATE, class OP>
82: 	static void ConstantOperation(STATE *state, INPUT_TYPE *input, nullmask_t &nullmask, idx_t count) {
83: 		Operation<INPUT_TYPE, STATE, OP>(state, input, nullmask, 0);
84: 	}
85: 
86: 	template <class T, class STATE>
87: 	static void Finalize(Vector &result, STATE *state, T *target, nullmask_t &nullmask, idx_t idx) {
88: 		if (!state->is_set || IsNullValue<T>(state->value)) {
89: 			nullmask[idx] = true;
90: 		} else {
91: 			target[idx] = StringVector::AddString(result, state->value);
92: 		}
93: 	}
94: 
95: 	template <class STATE> static void Destroy(STATE *state) {
96: 		if (state->is_set && !state->value.IsInlined()) {
97: 			delete[] state->value.GetData();
98: 		}
99: 	}
100: };
101: 
102: template <class T> static AggregateFunction GetFirstAggregateTemplated(SQLType type) {
103: 	return AggregateFunction::UnaryAggregate<FirstState<T>, T, T, FirstFunction>(type, type);
104: }
105: 
106: AggregateFunction FirstFun::GetFunction(SQLType type) {
107: 	switch (type.id) {
108: 	case SQLTypeId::BOOLEAN:
109: 		return GetFirstAggregateTemplated<bool>(type);
110: 	case SQLTypeId::TINYINT:
111: 		return GetFirstAggregateTemplated<int8_t>(type);
112: 	case SQLTypeId::SMALLINT:
113: 		return GetFirstAggregateTemplated<int16_t>(type);
114: 	case SQLTypeId::INTEGER:
115: 		return GetFirstAggregateTemplated<int32_t>(type);
116: 	case SQLTypeId::BIGINT:
117: 		return GetFirstAggregateTemplated<int64_t>(type);
118: 	case SQLTypeId::FLOAT:
119: 		return GetFirstAggregateTemplated<float>(type);
120: 	case SQLTypeId::DOUBLE:
121: 		return GetFirstAggregateTemplated<double>(type);
122: 	case SQLTypeId::DECIMAL:
123: 		return GetFirstAggregateTemplated<double>(type);
124: 	case SQLTypeId::DATE:
125: 		return GetFirstAggregateTemplated<date_t>(type);
126: 	case SQLTypeId::TIMESTAMP:
127: 		return GetFirstAggregateTemplated<timestamp_t>(type);
128: 	case SQLTypeId::VARCHAR:
129: 		return AggregateFunction::UnaryAggregateDestructor<FirstState<string_t>, string_t, string_t,
130: 		                                                   FirstFunctionString>(type, type);
131: 	default:
132: 		throw NotImplementedException("Unimplemented type for FIRST aggregate");
133: 	}
134: }
135: 
136: void FirstFun::RegisterFunction(BuiltinFunctions &set) {
137: 	AggregateFunctionSet first("first");
138: 	for (auto type : SQLType::ALL_TYPES) {
139: 		first.AddFunction(FirstFun::GetFunction(type));
140: 	}
141: 	set.AddFunction(first);
142: }
143: 
144: } // namespace duckdb
[end of src/function/aggregate/distributive/first.cpp]
[start of src/function/scalar/string/caseconvert.cpp]
1: #include "duckdb/function/scalar/string_functions.hpp"
2: 
3: #include "duckdb/common/exception.hpp"
4: #include "duckdb/common/vector_operations/vector_operations.hpp"
5: #include "duckdb/common/vector_operations/unary_executor.hpp"
6: #include "utf8proc.hpp"
7: 
8: #include <string.h>
9: 
10: using namespace std;
11: 
12: namespace duckdb {
13: 
14: template <bool IS_UPPER>
15: static string_t strcase_unicode(Vector &result, const char *input_data, idx_t input_length) {
16: 	// first figure out the output length
17: 	// optimization: if only ascii then input_length = output_length
18: 	idx_t output_length = 0;
19: 	for (idx_t i = 0; i < input_length;) {
20: 		if (input_data[i] & 0x80) {
21: 			// unicode
22: 			int sz = 0;
23: 			int codepoint = utf8proc_codepoint(input_data + i, sz);
24: 			int converted_codepoint = IS_UPPER ? utf8proc_toupper(codepoint) : utf8proc_tolower(codepoint);
25: 			sz = utf8proc_codepoint_length(converted_codepoint);
26: 			if (sz < 0) {
27: 				throw InternalException("Invalid UTF8 encountered!");
28: 			}
29: 			output_length += sz;
30: 			i += sz;
31: 		} else {
32: 			// ascii
33: 			output_length++;
34: 			i++;
35: 		}
36: 	}
37: 	auto result_str = StringVector::EmptyString(result, output_length);
38: 	auto result_data = result_str.GetData();
39: 
40: 	for (idx_t i = 0; i < input_length;) {
41: 		if (input_data[i] & 0x80) {
42: 			// non-ascii character
43: 			int sz = 0;
44: 			int codepoint = utf8proc_codepoint(input_data + i, sz);
45: 			int converted_codepoint = IS_UPPER ? utf8proc_toupper(codepoint) : utf8proc_tolower(codepoint);
46: 			if (!utf8proc_codepoint_to_utf8(converted_codepoint, sz, result_data)) {
47: 				throw InternalException("Invalid UTF8 encountered!");
48: 			}
49: 			result_data += sz;
50: 			i += sz;
51: 		} else {
52: 			// ascii
53: 			*result_data = IS_UPPER ? toupper(input_data[i]) : tolower(input_data[i]);
54: 			result_data++;
55: 			i++;
56: 		}
57: 	}
58: 	result_str.Finalize();
59: 	return result_str;
60: }
61: 
62: template <bool IS_UPPER> static void caseconvert_function(Vector &input, Vector &result, idx_t count) {
63: 	assert(input.type == TypeId::VARCHAR);
64: 
65: 	UnaryExecutor::Execute<string_t, string_t, true>(input, result, count, [&](string_t input) {
66: 		auto input_data = input.GetData();
67: 		auto input_length = input.GetSize();
68: 		return strcase_unicode<IS_UPPER>(result, input_data, input_length);
69: 	});
70: }
71: 
72: static void caseconvert_upper_function(DataChunk &args, ExpressionState &state, Vector &result) {
73: 	assert(args.column_count() == 1);
74: 	caseconvert_function<true>(args.data[0], result, args.size());
75: }
76: 
77: static void caseconvert_lower_function(DataChunk &args, ExpressionState &state, Vector &result) {
78: 	assert(args.column_count() == 1);
79: 	caseconvert_function<false>(args.data[0], result, args.size());
80: }
81: 
82: ScalarFunction LowerFun::GetFunction() {
83: 	return ScalarFunction({SQLType::VARCHAR}, SQLType::VARCHAR, caseconvert_lower_function);
84: }
85: 
86: void LowerFun::RegisterFunction(BuiltinFunctions &set) {
87: 	set.AddFunction({"lower", "lcase"}, LowerFun::GetFunction());
88: }
89: 
90: void UpperFun::RegisterFunction(BuiltinFunctions &set) {
91: 	set.AddFunction({"upper", "ucase"}, ScalarFunction({SQLType::VARCHAR}, SQLType::VARCHAR, caseconvert_upper_function));
92: }
93: 
94: } // namespace duckdb
[end of src/function/scalar/string/caseconvert.cpp]
[start of src/function/scalar/string/substring.cpp]
1: #include "duckdb/function/scalar/string_functions.hpp"
2: 
3: #include "duckdb/common/exception.hpp"
4: #include "duckdb/common/vector_operations/vector_operations.hpp"
5: #include "duckdb/common/vector_operations/ternary_executor.hpp"
6: #include "utf8proc.hpp"
7: 
8: using namespace std;
9: 
10: namespace duckdb {
11: 
12: static string_t substring_ascii_only(Vector &result, const char *input_data, int offset, int length) {
13: 	auto result_string = StringVector::EmptyString(result, length);
14: 	auto result_data = result_string.GetData();
15: 	memcpy(result_data, input_data + offset, length);
16: 	result_string.Finalize();
17: 	return result_string;
18: }
19: 
20: static string_t substring_scalar_function(Vector &result, string_t input, int offset, int length,
21:                                           unique_ptr<char[]> &output, idx_t &current_len) {
22: 	// reduce offset by one because SQL starts counting at 1
23: 	offset--;
24: 	if (offset < 0 || length < 0) {
25: 		throw Exception("SUBSTRING cannot handle negative offsets");
26: 	}
27: 	auto input_data = input.GetData();
28: 	auto input_size = input.GetSize();
29: 
30: 	// check if there is any non-ascii
31: 	bool ascii_only = true;
32: 	int ascii_end = std::min(offset + length + 1, (int)input_size);
33: 	for (int i = 0; i < ascii_end; i++) {
34: 		if (input_data[i] & 0x80) {
35: 			ascii_only = false;
36: 			break;
37: 		}
38: 	}
39: 	if (ascii_only) {
40: 		// ascii only
41: 		length = std::min(offset + length, (int)input_size) - offset;
42: 		return substring_ascii_only(result, input_data, offset, length);
43: 	}
44: 
45: 	// size is at most the input size: alloc it
46: 	idx_t required_len = input_size + 1;
47: 	if (required_len > current_len) {
48: 		// need a resize
49: 		current_len = required_len;
50: 		output = unique_ptr<char[]>{new char[required_len]};
51: 	}
52: 
53: 	// use grapheme iterator to iterate over the characters
54: 	int current_offset = 0;
55: 	int output_size = 0;
56: 	utf8proc_grapheme_callback(input_data, input_size, [&](size_t start, size_t end) {
57: 		if (current_offset >= offset) {
58: 			// this character belongs to the output: copy it there
59: 			memcpy(output.get() + output_size, input_data + start, end - start);
60: 			output_size += end - start;
61: 		}
62: 		current_offset++;
63: 		// stop iterating after we have exceeded the required characters
64: 		return current_offset < offset + length;
65: 	});
66: 	output[output_size] = '\0';
67: 	return StringVector::AddString(result, output.get(), output_size);
68: }
69: 
70: static void substring_function(DataChunk &args, ExpressionState &state, Vector &result) {
71: 	assert(args.column_count() == 3 && args.data[0].type == TypeId::VARCHAR && args.data[1].type == TypeId::INT32 &&
72: 	       args.data[2].type == TypeId::INT32);
73: 	auto &input_vector = args.data[0];
74: 	auto &offset_vector = args.data[1];
75: 	auto &length_vector = args.data[2];
76: 
77: 	idx_t current_len = 0;
78: 	unique_ptr<char[]> output;
79: 	TernaryExecutor::Execute<string_t, int, int, string_t>(
80: 	    input_vector, offset_vector, length_vector, result, args.size(),
81: 	    [&](string_t input_string, int offset, int length) {
82: 		    return substring_scalar_function(result, input_string, offset, length, output, current_len);
83: 	    });
84: }
85: 
86: void SubstringFun::RegisterFunction(BuiltinFunctions &set) {
87: 	set.AddFunction({"substring", "substr"}, ScalarFunction({SQLType::VARCHAR, SQLType::INTEGER, SQLType::INTEGER}, SQLType::VARCHAR, substring_function));
88: }
89: 
90: } // namespace duckdb
[end of src/function/scalar/string/substring.cpp]
[start of src/include/duckdb/planner/expression/bound_cast_expression.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/planner/expression/bound_cast_expression.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/planner/expression.hpp"
12: 
13: namespace duckdb {
14: 
15: class BoundCastExpression : public Expression {
16: public:
17: 	BoundCastExpression(TypeId target, unique_ptr<Expression> child, SQLType source_type, SQLType target_type);
18: 
19: 	//! The child type
20: 	unique_ptr<Expression> child;
21: 	//! The SQL type of the child
22: 	SQLType source_type;
23: 	//! The SQL type to cast to
24: 	SQLType target_type;
25: 
26: public:
27: 	//! Cast an expression to the specified SQL type if required
28: 	static unique_ptr<Expression> AddCastToType(unique_ptr<Expression> expr, SQLType source_type, SQLType target_type);
29: 
30: 	string ToString() const override;
31: 
32: 	bool Equals(const BaseExpression *other) const override;
33: 
34: 	unique_ptr<Expression> Copy() override;
35: };
36: } // namespace duckdb
[end of src/include/duckdb/planner/expression/bound_cast_expression.hpp]
[start of src/optimizer/rule/comparison_simplification.cpp]
1: #include "duckdb/planner/expression/list.hpp"
2: #include "duckdb/optimizer/rule/comparison_simplification.hpp"
3: 
4: #include "duckdb/execution/expression_executor.hpp"
5: #include "duckdb/planner/expression/bound_constant_expression.hpp"
6: 
7: using namespace duckdb;
8: using namespace std;
9: 
10: ComparisonSimplificationRule::ComparisonSimplificationRule(ExpressionRewriter &rewriter) : Rule(rewriter) {
11: 	// match on a ComparisonExpression that has a ConstantExpression as a check
12: 	auto op = make_unique<ComparisonExpressionMatcher>();
13: 	op->matchers.push_back(make_unique<FoldableConstantMatcher>());
14: 	op->policy = SetMatcher::Policy::SOME;
15: 	root = move(op);
16: }
17: 
18: unique_ptr<Expression> ComparisonSimplificationRule::Apply(LogicalOperator &op, vector<Expression *> &bindings,
19:                                                            bool &changes_made) {
20: 	assert(bindings[0]->expression_class == ExpressionClass::BOUND_COMPARISON);
21: 	auto expr = (BoundComparisonExpression *)bindings[0];
22: 	auto constant_expr = bindings[1];
23: 	bool column_ref_left = expr->left.get() != constant_expr;
24: 	auto column_ref_expr = !column_ref_left ? expr->right.get() : expr->left.get();
25: 	// the constant_expr is a scalar expression that we have to fold
26: 	// use an ExpressionExecutor to execute the expression
27: 	assert(constant_expr->IsFoldable());
28: 	auto constant_value = ExpressionExecutor::EvaluateScalar(*constant_expr);
29: 	if (constant_value.is_null) {
30: 		// comparison with constant NULL, return NULL
31: 		return make_unique<BoundConstantExpression>(Value(TypeId::BOOL));
32: 	}
33: 	if (column_ref_expr->expression_class == ExpressionClass::BOUND_CAST &&
34: 	    constant_expr->expression_class == ExpressionClass::BOUND_CONSTANT) {
35: 		//! Here we check if we can apply the expression on the constant side
36: 		auto cast_expression = (BoundCastExpression *)column_ref_expr;
37: 		auto bound_const_expr = (BoundConstantExpression *)constant_expr;
38: 		auto new_constant = (BoundConstantExpression *)bound_const_expr->value.TryCastAs(
39: 		    cast_expression->target_type.id, cast_expression->source_type.id);
40: 		if (new_constant) {
41: 			auto child_expression = move(cast_expression->child);
42: 			constant_expr->return_type = bound_const_expr->value.type;
43: 			//! We can cast, now we change our column_ref_expression from an operator cast to a column reference
44: 			if (column_ref_left) {
45: 				expr->left = move(child_expression);
46: 			} else {
47: 				expr->right = move(child_expression);
48: 			}
49: 		}
50: 	}
51: 	return nullptr;
52: }
[end of src/optimizer/rule/comparison_simplification.cpp]
[start of src/planner/binder/statement/bind_create.cpp]
1: #include "duckdb/parser/statement/create_statement.hpp"
2: #include "duckdb/planner/operator/logical_create.hpp"
3: #include "duckdb/planner/operator/logical_create_table.hpp"
4: #include "duckdb/planner/operator/logical_create_index.hpp"
5: #include "duckdb/planner/operator/logical_get.hpp"
6: #include "duckdb/planner/parsed_data/bound_create_table_info.hpp"
7: #include "duckdb/catalog/catalog.hpp"
8: #include "duckdb/catalog/catalog_entry/schema_catalog_entry.hpp"
9: #include "duckdb/planner/binder.hpp"
10: #include "duckdb/planner/expression_binder/index_binder.hpp"
11: #include "duckdb/parser/parsed_data/create_view_info.hpp"
12: #include "duckdb/parser/parsed_data/create_index_info.hpp"
13: #include "duckdb/planner/bound_query_node.hpp"
14: #include "duckdb/planner/tableref/bound_basetableref.hpp"
15: 
16: using namespace duckdb;
17: using namespace std;
18: 
19: SchemaCatalogEntry *Binder::BindSchema(CreateInfo &info) {
20: 	if (info.schema == INVALID_SCHEMA) {
21: 		info.schema = info.temporary ? TEMP_SCHEMA : DEFAULT_SCHEMA;
22: 	}
23: 
24: 	if (!info.temporary) {
25: 		// non-temporary create: not read only
26: 		if (info.schema == TEMP_SCHEMA) {
27: 			throw ParserException("Only TEMPORARY table names can use the \"temp\" schema");
28: 		}
29: 		this->read_only = false;
30: 	} else {
31: 		if (info.schema != TEMP_SCHEMA) {
32: 			throw ParserException("TEMPORARY table names can *only* use the \"%s\" schema", TEMP_SCHEMA);
33: 		}
34: 	}
35: 	// fetch the schema in which we want to create the object
36: 	auto schema_obj = Catalog::GetCatalog(context).GetSchema(context, info.schema);
37: 	assert(schema_obj->type == CatalogType::SCHEMA);
38: 	info.schema = schema_obj->name;
39: 	return schema_obj;
40: }
41: 
42: BoundStatement Binder::Bind(CreateStatement &stmt) {
43: 	BoundStatement result;
44: 	result.names = {"Count"};
45: 	result.types = {SQLType::BIGINT};
46: 
47: 	auto catalog_type = stmt.info->type;
48: 	switch (catalog_type) {
49: 	case CatalogType::SCHEMA:
50: 		result.plan = make_unique<LogicalCreate>(LogicalOperatorType::CREATE_SCHEMA, move(stmt.info));
51: 		break;
52: 	case CatalogType::VIEW: {
53: 		auto &base = (CreateViewInfo &)*stmt.info;
54: 		// bind the schema
55: 		auto schema = BindSchema(*stmt.info);
56: 
57: 		// bind the view as if it were a query so we can catch errors
58: 		// note that we bind a copy and don't actually use the bind result
59: 		auto copy = base.query->Copy();
60: 		auto query_node = Bind(*copy);
61: 		if (base.aliases.size() > query_node.names.size()) {
62: 			throw BinderException("More VIEW aliases than columns in query result");
63: 		}
64: 		// fill up the aliases with the remaining names of the bound query
65: 		for (idx_t i = base.aliases.size(); i < query_node.names.size(); i++) {
66: 			base.aliases.push_back(query_node.names[i]);
67: 		}
68: 		base.types = query_node.types;
69: 		result.plan = make_unique<LogicalCreate>(LogicalOperatorType::CREATE_VIEW, move(stmt.info), schema);
70: 		break;
71: 	}
72: 	case CatalogType::SEQUENCE: {
73: 		auto schema = BindSchema(*stmt.info);
74: 		result.plan = make_unique<LogicalCreate>(LogicalOperatorType::CREATE_SEQUENCE, move(stmt.info), schema);
75: 		break;
76: 	}
77: 	case CatalogType::INDEX: {
78: 		auto &base = (CreateIndexInfo &)*stmt.info;
79: 
80: 		// visit the table reference
81: 		auto bound_table = Bind(*base.table);
82: 		if (bound_table->type != TableReferenceType::BASE_TABLE) {
83: 			throw BinderException("Can only delete from base table!");
84: 		}
85: 		// bind the index expressions
86: 		vector<unique_ptr<Expression>> expressions;
87: 		IndexBinder binder(*this, context);
88: 		for (auto &expr : base.expressions) {
89: 			expressions.push_back(binder.Bind(expr));
90: 		}
91: 
92: 		auto plan = CreatePlan(*bound_table);
93: 		if (plan->type != LogicalOperatorType::GET) {
94: 			throw BinderException("Cannot create index on a view!");
95: 		}
96: 		auto &get = (LogicalGet &)*plan;
97: 		// this gives us a logical table scan
98: 		// we take the required columns from here
99: 		// create the logical operator
100: 		result.plan = make_unique<LogicalCreateIndex>(*get.table, get.column_ids, move(expressions),
101: 		                                              unique_ptr_cast<CreateInfo, CreateIndexInfo>(move(stmt.info)));
102: 		break;
103: 	}
104: 	case CatalogType::TABLE: {
105: 		auto bound_info = BindCreateTableInfo(move(stmt.info));
106: 		auto root = move(bound_info->query);
107: 
108: 		// create the logical operator
109: 		auto create_table = make_unique<LogicalCreateTable>(bound_info->schema, move(bound_info));
110: 		if (root) {
111: 			create_table->children.push_back(move(root));
112: 		}
113: 		result.plan = move(create_table);
114: 		return result;
115: 	}
116: 	default:
117: 		throw Exception("Unrecognized type!");
118: 	}
119: 	return result;
120: }
[end of src/planner/binder/statement/bind_create.cpp]
[start of src/planner/expression/bound_cast_expression.cpp]
1: #include "duckdb/planner/expression/bound_cast_expression.hpp"
2: #include "duckdb/planner/expression/bound_default_expression.hpp"
3: #include "duckdb/planner/expression/bound_parameter_expression.hpp"
4: 
5: using namespace duckdb;
6: using namespace std;
7: 
8: BoundCastExpression::BoundCastExpression(TypeId target, unique_ptr<Expression> child, SQLType source_type,
9:                                          SQLType target_type)
10:     : Expression(ExpressionType::OPERATOR_CAST, ExpressionClass::BOUND_CAST, target), child(move(child)),
11:       source_type(source_type), target_type(target_type) {
12: }
13: 
14: unique_ptr<Expression> BoundCastExpression::AddCastToType(unique_ptr<Expression> expr, SQLType source_type,
15:                                                           SQLType target_type) {
16: 	assert(expr);
17: 	if (expr->expression_class == ExpressionClass::BOUND_PARAMETER) {
18: 		auto &parameter = (BoundParameterExpression &)*expr;
19: 		parameter.sql_type = target_type;
20: 		parameter.return_type = GetInternalType(target_type);
21: 	} else if (expr->expression_class == ExpressionClass::BOUND_DEFAULT) {
22: 		auto &def = (BoundDefaultExpression &)*expr;
23: 		def.sql_type = target_type;
24: 		def.return_type = GetInternalType(target_type);
25: 	} else if (source_type != target_type) {
26: 		return make_unique<BoundCastExpression>(GetInternalType(target_type), move(expr), source_type, target_type);
27: 	}
28: 	return expr;
29: }
30: 
31: string BoundCastExpression::ToString() const {
32: 	return "CAST[" + TypeIdToString(return_type) + "](" + child->GetName() + ")";
33: }
34: 
35: bool BoundCastExpression::Equals(const BaseExpression *other_) const {
36: 	if (!BaseExpression::Equals(other_)) {
37: 		return false;
38: 	}
39: 	auto other = (BoundCastExpression *)other_;
40: 	if (!Expression::Equals(child.get(), other->child.get())) {
41: 		return false;
42: 	}
43: 	if (source_type != other->source_type || target_type != other->target_type) {
44: 		return false;
45: 	}
46: 	return true;
47: }
48: 
49: unique_ptr<Expression> BoundCastExpression::Copy() {
50: 	auto copy = make_unique<BoundCastExpression>(return_type, child->Copy(), source_type, target_type);
51: 	copy->CopyProperties(*this);
52: 	return move(copy);
53: }
[end of src/planner/expression/bound_cast_expression.cpp]
[start of src/storage/data_table.cpp]
1: #include "duckdb/storage/data_table.hpp"
2: 
3: #include "duckdb/catalog/catalog_entry/table_catalog_entry.hpp"
4: #include "duckdb/common/exception.hpp"
5: #include "duckdb/common/helper.hpp"
6: #include "duckdb/common/vector_operations/vector_operations.hpp"
7: #include "duckdb/execution/expression_executor.hpp"
8: #include "duckdb/planner/constraints/list.hpp"
9: #include "duckdb/transaction/transaction.hpp"
10: #include "duckdb/transaction/transaction_manager.hpp"
11: #include "duckdb/storage/table/transient_segment.hpp"
12: 
13: using namespace duckdb;
14: using namespace std;
15: using namespace chrono;
16: 
17: DataTable::DataTable(StorageManager &storage, string schema, string table, vector<TypeId> types_,
18:                      unique_ptr<vector<unique_ptr<PersistentSegment>>[]> data)
19:     : cardinality(0), schema(schema), table(table), types(types_), storage(storage), persistent_manager(*this),
20:       transient_manager(*this) {
21: 	// set up the segment trees for the column segments
22: 	columns = unique_ptr<ColumnData[]>(new ColumnData[types.size()]);
23: 	for (idx_t i = 0; i < types.size(); i++) {
24: 		columns[i].type = types[i];
25: 		columns[i].table = this;
26: 		columns[i].column_idx = i;
27: 	}
28: 
29: 	// initialize the table with the existing data from disk, if any
30: 	if (data && data[0].size() > 0) {
31: 		// first append all the segments to the set of column segments
32: 		for (idx_t i = 0; i < types.size(); i++) {
33: 			columns[i].Initialize(data[i]);
34: 			if (columns[i].persistent_rows != columns[0].persistent_rows) {
35: 				throw Exception("Column length mismatch in table load!");
36: 			}
37: 		}
38: 		persistent_manager.max_row = columns[0].persistent_rows;
39: 		transient_manager.base_row = persistent_manager.max_row;
40: 	}
41: }
42: 
43: //===--------------------------------------------------------------------===//
44: // Scan
45: //===--------------------------------------------------------------------===//
46: void DataTable::InitializeScan(TableScanState &state, vector<column_t> column_ids,
47:                                unordered_map<idx_t, vector<TableFilter>> *table_filters) {
48: 	// initialize a column scan state for each column
49: 	state.column_scans = unique_ptr<ColumnScanState[]>(new ColumnScanState[column_ids.size()]);
50: 	for (idx_t i = 0; i < column_ids.size(); i++) {
51: 		auto column = column_ids[i];
52: 		if (column != COLUMN_IDENTIFIER_ROW_ID) {
53: 			columns[column].InitializeScan(state.column_scans[i]);
54: 		}
55: 	}
56: 	state.column_ids = move(column_ids);
57: 	// initialize the chunk scan state
58: 	state.offset = 0;
59: 	state.current_persistent_row = 0;
60: 	state.max_persistent_row = persistent_manager.max_row;
61: 	state.current_transient_row = 0;
62: 	state.max_transient_row = transient_manager.max_row;
63: 	if (table_filters) {
64: 		state.adaptive_filter = make_unique<AdaptiveFilter>(*table_filters);
65: 	}
66: }
67: 
68: void DataTable::InitializeScan(Transaction &transaction, TableScanState &state, vector<column_t> column_ids,
69:                                unordered_map<idx_t, vector<TableFilter>> *table_filters) {
70: 	InitializeScan(state, move(column_ids), table_filters);
71: 	transaction.storage.InitializeScan(this, state.local_state);
72: }
73: 
74: void DataTable::Scan(Transaction &transaction, DataChunk &result, TableScanState &state,
75:                      unordered_map<idx_t, vector<TableFilter>> &table_filters) {
76: 	// scan the persistent segments
77: 	while (ScanBaseTable(transaction, result, state, state.current_persistent_row, state.max_persistent_row, 0,
78: 	                     persistent_manager, table_filters)) {
79: 		if (result.size() > 0) {
80: 			return;
81: 		}
82: 	}
83: 	// scan the transient segments
84: 	while (ScanBaseTable(transaction, result, state, state.current_transient_row, state.max_transient_row,
85: 	                     persistent_manager.max_row, transient_manager, table_filters)) {
86: 		if (result.size() > 0) {
87: 			return;
88: 		}
89: 	}
90: 
91: 	// scan the transaction-local segments
92: 	transaction.storage.Scan(state.local_state, state.column_ids, result, &table_filters);
93: }
94: 
95: template <class T> bool checkZonemap(TableScanState &state, TableFilter &table_filter, T constant) {
96: 	T *min = (T *)state.column_scans[table_filter.column_index].current->stats.minimum.get();
97: 	T *max = (T *)state.column_scans[table_filter.column_index].current->stats.maximum.get();
98: 	switch (table_filter.comparison_type) {
99: 	case ExpressionType::COMPARE_EQUAL:
100: 		return constant >= *min && constant <= *max;
101: 	case ExpressionType::COMPARE_GREATERTHANOREQUALTO:
102: 		return constant <= *max;
103: 	case ExpressionType::COMPARE_GREATERTHAN:
104: 		return constant < *max;
105: 	case ExpressionType::COMPARE_LESSTHANOREQUALTO:
106: 		return constant >= *min;
107: 	case ExpressionType::COMPARE_LESSTHAN:
108: 		return constant > *min;
109: 	default:
110: 		throw NotImplementedException("Operation not implemented");
111: 	}
112: }
113: 
114: bool checkZonemapString(TableScanState &state, TableFilter &table_filter, const char *constant) {
115: 	char *min = (char *)state.column_scans[table_filter.column_index].current->stats.minimum.get();
116: 	char *max = (char *)state.column_scans[table_filter.column_index].current->stats.maximum.get();
117: 	int min_comp = strcmp(min, constant);
118: 	int max_comp = strcmp(max, constant);
119: 	switch (table_filter.comparison_type) {
120: 	case ExpressionType::COMPARE_EQUAL:
121: 		return min_comp <= 0 && max_comp >= 0;
122: 	case ExpressionType::COMPARE_GREATERTHANOREQUALTO:
123: 		return max_comp >= 0;
124: 	case ExpressionType::COMPARE_GREATERTHAN:
125: 		return max_comp > 0;
126: 	case ExpressionType::COMPARE_LESSTHANOREQUALTO:
127: 		return min_comp <= 0;
128: 	case ExpressionType::COMPARE_LESSTHAN:
129: 		return min_comp < 0;
130: 	default:
131: 		throw NotImplementedException("Operation not implemented");
132: 	}
133: }
134: 
135: bool DataTable::CheckZonemap(TableScanState &state, unordered_map<idx_t, vector<TableFilter>> &table_filters,
136:                              idx_t &current_row) {
137: 	bool readSegment = true;
138: 	for (auto &table_filter : table_filters) {
139: 		for (auto &predicate_constant : table_filter.second) {
140: 			if (!state.column_scans[predicate_constant.column_index].segment_checked) {
141: 				state.column_scans[predicate_constant.column_index].segment_checked = true;
142: 				if (!state.column_scans[predicate_constant.column_index].current) {
143: 					return true;
144: 				}
145: 				switch (state.column_scans[predicate_constant.column_index].current->type) {
146: 				case TypeId::INT8: {
147: 					int8_t constant = predicate_constant.constant.value_.tinyint;
148: 					readSegment &= checkZonemap<int8_t>(state, predicate_constant, constant);
149: 					break;
150: 				}
151: 				case TypeId::INT16: {
152: 					int16_t constant = predicate_constant.constant.value_.smallint;
153: 					readSegment &= checkZonemap<int16_t>(state, predicate_constant, constant);
154: 					break;
155: 				}
156: 				case TypeId::INT32: {
157: 					int32_t constant = predicate_constant.constant.value_.integer;
158: 					readSegment &= checkZonemap<int32_t>(state, predicate_constant, constant);
159: 					break;
160: 				}
161: 				case TypeId::INT64: {
162: 					int64_t constant = predicate_constant.constant.value_.bigint;
163: 					readSegment &= checkZonemap<int64_t>(state, predicate_constant, constant);
164: 					break;
165: 				}
166: 				case TypeId::FLOAT: {
167: 					float constant = predicate_constant.constant.value_.float_;
168: 					readSegment &= checkZonemap<float>(state, predicate_constant, constant);
169: 					break;
170: 				}
171: 				case TypeId::DOUBLE: {
172: 					double constant = predicate_constant.constant.value_.double_;
173: 					readSegment &= checkZonemap<double>(state, predicate_constant, constant);
174: 					break;
175: 				}
176: 				case TypeId::VARCHAR: {
177: 					//! we can only compare the first 7 bytes
178: 					size_t value_size = predicate_constant.constant.str_value.size() > 7
179: 					                        ? 7
180: 					                        : predicate_constant.constant.str_value.size();
181: 					string constant;
182: 					for (size_t i = 0; i < value_size; i++) {
183: 						constant += predicate_constant.constant.str_value[i];
184: 					}
185: 					readSegment &= checkZonemapString(state, predicate_constant, constant.c_str());
186: 					break;
187: 				}
188: 				default:
189: 					throw NotImplementedException("Unimplemented type for uncompressed segment");
190: 				}
191: 			}
192: 			if (!readSegment) {
193: 				//! We can skip this partition
194: 				idx_t vectorsToSkip =
195: 				    ceil((double)(state.column_scans[predicate_constant.column_index].current->count +
196: 				                  state.column_scans[predicate_constant.column_index].current->start - current_row) /
197: 				         STANDARD_VECTOR_SIZE);
198: 				for (idx_t i = 0; i < vectorsToSkip; ++i) {
199: 					state.NextVector();
200: 					current_row += STANDARD_VECTOR_SIZE;
201: 				}
202: 				return false;
203: 			}
204: 		}
205: 	}
206: 
207: 	return true;
208: }
209: 
210: bool DataTable::ScanBaseTable(Transaction &transaction, DataChunk &result, TableScanState &state, idx_t &current_row,
211:                               idx_t max_row, idx_t base_row, VersionManager &manager,
212:                               unordered_map<idx_t, vector<TableFilter>> &table_filters) {
213: 	if (current_row >= max_row) {
214: 		// exceeded the amount of rows to scan
215: 		return false;
216: 	}
217: 	idx_t max_count = std::min((idx_t)STANDARD_VECTOR_SIZE, max_row - current_row);
218: 	idx_t vector_offset = current_row / STANDARD_VECTOR_SIZE;
219: 	//! first check the zonemap if we have to scan this partition
220: 	if (!CheckZonemap(state, table_filters, current_row)) {
221: 		return true;
222: 	}
223: 	// second, scan the version chunk manager to figure out which tuples to load for this transaction
224: 	SelectionVector valid_sel(STANDARD_VECTOR_SIZE);
225: 	idx_t count = manager.GetSelVector(transaction, vector_offset, valid_sel, max_count);
226: 	if (count == 0) {
227: 		// nothing to scan for this vector, skip the entire vector
228: 		state.NextVector();
229: 		current_row += STANDARD_VECTOR_SIZE;
230: 		return true;
231: 	}
232: 	idx_t approved_tuple_count = count;
233: 	if (count == max_count && table_filters.empty()) {
234: 		//! If we don't have any deleted tuples or filters we can just run a regular scan
235: 		for (idx_t i = 0; i < state.column_ids.size(); i++) {
236: 			auto column = state.column_ids[i];
237: 			if (column == COLUMN_IDENTIFIER_ROW_ID) {
238: 				// scan row id
239: 				assert(result.data[i].type == ROW_TYPE);
240: 				result.data[i].Sequence(base_row + current_row, 1);
241: 			} else {
242: 				columns[column].Scan(transaction, state.column_scans[i], result.data[i]);
243: 			}
244: 		}
245: 	} else {
246: 		SelectionVector sel;
247: 
248: 		if (count != max_count) {
249: 			sel.Initialize(valid_sel);
250: 		} else {
251: 			sel.Initialize(FlatVector::IncrementalSelectionVector);
252: 		}
253: 		//! First, we scan the columns with filters, fetch their data and generate a selection vector.
254: 		//! get runtime statistics
255: 		auto start_time = high_resolution_clock::now();
256: 		for (idx_t i = 0; i < table_filters.size(); i++) {
257: 			auto tf_idx = state.adaptive_filter->permutation[i];
258: 			columns[tf_idx].Select(transaction, state.column_scans[tf_idx], result.data[tf_idx], sel,
259: 			                       approved_tuple_count, table_filters[tf_idx]);
260: 		}
261: 		for (auto &table_filter : table_filters) {
262: 			result.data[table_filter.first].Slice(sel, approved_tuple_count);
263: 		}
264: 		//! Now we use the selection vector to fetch data for the other columns.
265: 		for (idx_t i = 0; i < state.column_ids.size(); i++) {
266: 			if (table_filters.find(i) == table_filters.end()) {
267: 				auto column = state.column_ids[i];
268: 				if (column == COLUMN_IDENTIFIER_ROW_ID) {
269: 					assert(result.data[i].type == TypeId::INT64);
270: 					result.data[i].vector_type = VectorType::FLAT_VECTOR;
271: 					auto result_data = (int64_t *)FlatVector::GetData(result.data[i]);
272: 					for (size_t sel_idx = 0; sel_idx < approved_tuple_count; sel_idx++) {
273: 						result_data[sel_idx] = base_row + current_row + sel.get_index(sel_idx);
274: 					}
275: 				} else {
276: 					columns[column].FilterScan(transaction, state.column_scans[i], result.data[i], sel,
277: 					                           approved_tuple_count);
278: 				}
279: 			}
280: 		}
281: 		auto end_time = high_resolution_clock::now();
282: 		if (state.adaptive_filter && table_filters.size() > 1) {
283: 			state.adaptive_filter->AdaptRuntimeStatistics(
284: 			    duration_cast<duration<double>>(end_time - start_time).count());
285: 		}
286: 	}
287: 
288: 	result.SetCardinality(approved_tuple_count);
289: 	current_row += STANDARD_VECTOR_SIZE;
290: 	return true;
291: }
292: 
293: //===--------------------------------------------------------------------===//
294: // Index Scan
295: //===--------------------------------------------------------------------===//
296: void DataTable::InitializeIndexScan(Transaction &transaction, TableIndexScanState &state, Index &index,
297:                                     vector<column_t> column_ids) {
298: 	state.index = &index;
299: 	state.column_ids = move(column_ids);
300: 	transaction.storage.InitializeScan(this, state.local_state);
301: }
302: 
303: void DataTable::InitializeIndexScan(Transaction &transaction, TableIndexScanState &state, Index &index, Value value,
304:                                     ExpressionType expr_type, vector<column_t> column_ids) {
305: 	InitializeIndexScan(transaction, state, index, move(column_ids));
306: 	state.index_state = index.InitializeScanSinglePredicate(transaction, state.column_ids, value, expr_type);
307: }
308: 
309: void DataTable::InitializeIndexScan(Transaction &transaction, TableIndexScanState &state, Index &index, Value low_value,
310:                                     ExpressionType low_type, Value high_value, ExpressionType high_type,
311:                                     vector<column_t> column_ids) {
312: 	InitializeIndexScan(transaction, state, index, move(column_ids));
313: 	state.index_state =
314: 	    index.InitializeScanTwoPredicates(transaction, state.column_ids, low_value, low_type, high_value, high_type);
315: }
316: 
317: void DataTable::IndexScan(Transaction &transaction, DataChunk &result, TableIndexScanState &state) {
318: 	// clear any previously pinned blocks
319: 	state.fetch_state.handles.clear();
320: 	// scan the index
321: 	state.index->Scan(transaction, state, result);
322: 	if (result.size() > 0) {
323: 		return;
324: 	}
325: 	// scan the local structure
326: 	transaction.storage.Scan(state.local_state, state.column_ids, result);
327: }
328: 
329: //===--------------------------------------------------------------------===//
330: // Fetch
331: //===--------------------------------------------------------------------===//
332: void DataTable::Fetch(Transaction &transaction, DataChunk &result, vector<column_t> &column_ids,
333:                       Vector &row_identifiers, idx_t fetch_count, TableIndexScanState &state) {
334: 	// first figure out which row identifiers we should use for this transaction by looking at the VersionManagers
335: 	row_t rows[STANDARD_VECTOR_SIZE];
336: 	idx_t count = FetchRows(transaction, row_identifiers, fetch_count, rows);
337: 
338: 	if (count == 0) {
339: 		// no rows to use
340: 		return;
341: 	}
342: 	// for each of the remaining rows, now fetch the data
343: 	result.SetCardinality(count);
344: 	for (idx_t col_idx = 0; col_idx < column_ids.size(); col_idx++) {
345: 		auto column = column_ids[col_idx];
346: 		if (column == COLUMN_IDENTIFIER_ROW_ID) {
347: 			// row id column: fill in the row ids
348: 			assert(result.data[col_idx].type == TypeId::INT64);
349: 			result.data[col_idx].vector_type = VectorType::FLAT_VECTOR;
350: 			auto data = FlatVector::GetData<row_t>(result.data[col_idx]);
351: 			for (idx_t i = 0; i < count; i++) {
352: 				data[i] = rows[i];
353: 			}
354: 		} else {
355: 			// regular column: fetch data from the base column
356: 			for (idx_t i = 0; i < count; i++) {
357: 				auto row_id = rows[i];
358: 				columns[column].FetchRow(state.fetch_state, transaction, row_id, result.data[col_idx], i);
359: 			}
360: 		}
361: 	}
362: }
363: 
364: idx_t DataTable::FetchRows(Transaction &transaction, Vector &row_identifiers, idx_t fetch_count, row_t result_rows[]) {
365: 	assert(row_identifiers.type == ROW_TYPE);
366: 
367: 	// obtain a read lock on the version managers
368: 	auto l1 = persistent_manager.lock.GetSharedLock();
369: 	auto l2 = transient_manager.lock.GetSharedLock();
370: 
371: 	// now iterate over the row ids and figure out which rows to use
372: 	idx_t count = 0;
373: 
374: 	auto row_ids = FlatVector::GetData<row_t>(row_identifiers);
375: 	for (idx_t i = 0; i < fetch_count; i++) {
376: 		auto row_id = row_ids[i];
377: 		bool use_row;
378: 		if ((idx_t)row_id < persistent_manager.max_row) {
379: 			// persistent row: use persistent manager
380: 			use_row = persistent_manager.Fetch(transaction, row_id);
381: 		} else {
382: 			// transient row: use transient manager
383: 			use_row = transient_manager.Fetch(transaction, row_id);
384: 		}
385: 		if (use_row) {
386: 			// row is not deleted; use the row
387: 			result_rows[count++] = row_id;
388: 		}
389: 	}
390: 	return count;
391: }
392: 
393: //===--------------------------------------------------------------------===//
394: // Append
395: //===--------------------------------------------------------------------===//
396: static void VerifyNotNullConstraint(TableCatalogEntry &table, Vector &vector, idx_t count, string &col_name) {
397: 	if (VectorOperations::HasNull(vector, count)) {
398: 		throw ConstraintException("NOT NULL constraint failed: %s.%s", table.name.c_str(), col_name.c_str());
399: 	}
400: }
401: 
402: static void VerifyCheckConstraint(TableCatalogEntry &table, Expression &expr, DataChunk &chunk) {
403: 	ExpressionExecutor executor(expr);
404: 	Vector result(TypeId::INT32);
405: 	try {
406: 		executor.ExecuteExpression(chunk, result);
407: 	} catch (Exception &ex) {
408: 		throw ConstraintException("CHECK constraint failed: %s (Error: %s)", table.name.c_str(), ex.what());
409: 	} catch (...) {
410: 		throw ConstraintException("CHECK constraint failed: %s (Unknown Error)", table.name.c_str());
411: 	}
412: 	VectorData vdata;
413: 	result.Orrify(chunk.size(), vdata);
414: 
415: 	auto dataptr = (int32_t *)vdata.data;
416: 	for (idx_t i = 0; i < chunk.size(); i++) {
417: 		auto idx = vdata.sel->get_index(i);
418: 		if (!(*vdata.nullmask)[idx] && dataptr[idx] == 0) {
419: 			throw ConstraintException("CHECK constraint failed: %s", table.name.c_str());
420: 		}
421: 	}
422: }
423: 
424: void DataTable::VerifyAppendConstraints(TableCatalogEntry &table, DataChunk &chunk) {
425: 	for (auto &constraint : table.bound_constraints) {
426: 		switch (constraint->type) {
427: 		case ConstraintType::NOT_NULL: {
428: 			auto &not_null = *reinterpret_cast<BoundNotNullConstraint *>(constraint.get());
429: 			VerifyNotNullConstraint(table, chunk.data[not_null.index], chunk.size(),
430: 			                        table.columns[not_null.index].name);
431: 			break;
432: 		}
433: 		case ConstraintType::CHECK: {
434: 			auto &check = *reinterpret_cast<BoundCheckConstraint *>(constraint.get());
435: 			VerifyCheckConstraint(table, *check.expression, chunk);
436: 			break;
437: 		}
438: 		case ConstraintType::UNIQUE: {
439: 			//! check whether or not the chunk can be inserted into the indexes
440: 			for (auto &index : indexes) {
441: 				index->VerifyAppend(chunk);
442: 			}
443: 			break;
444: 		}
445: 		case ConstraintType::FOREIGN_KEY:
446: 		default:
447: 			throw NotImplementedException("Constraint type not implemented!");
448: 		}
449: 	}
450: }
451: 
452: void DataTable::Append(TableCatalogEntry &table, ClientContext &context, DataChunk &chunk) {
453: 	if (chunk.size() == 0) {
454: 		return;
455: 	}
456: 	if (chunk.column_count() != table.columns.size()) {
457: 		throw CatalogException("Mismatch in column count for append");
458: 	}
459: 
460: 	chunk.Verify();
461: 
462: 	// verify any constraints on the new chunk
463: 	VerifyAppendConstraints(table, chunk);
464: 
465: 	// append to the transaction local data
466: 	auto &transaction = Transaction::GetTransaction(context);
467: 	transaction.storage.Append(this, chunk);
468: }
469: 
470: void DataTable::InitializeAppend(TableAppendState &state) {
471: 	// obtain the append lock for this table
472: 	state.append_lock = unique_lock<mutex>(append_lock);
473: 	// obtain locks on all indexes for the table
474: 	state.index_locks = unique_ptr<IndexLock[]>(new IndexLock[indexes.size()]);
475: 	for (idx_t i = 0; i < indexes.size(); i++) {
476: 		indexes[i]->InitializeLock(state.index_locks[i]);
477: 	}
478: 	// for each column, initialize the append state
479: 	state.states = unique_ptr<ColumnAppendState[]>(new ColumnAppendState[types.size()]);
480: 	for (idx_t i = 0; i < types.size(); i++) {
481: 		columns[i].InitializeAppend(state.states[i]);
482: 	}
483: 	state.row_start = transient_manager.max_row;
484: 	state.current_row = state.row_start;
485: }
486: 
487: void DataTable::Append(Transaction &transaction, transaction_t commit_id, DataChunk &chunk, TableAppendState &state) {
488: 	assert(chunk.column_count() == types.size());
489: 	chunk.Verify();
490: 
491: 	// set up the inserted info in the version manager
492: 	transient_manager.Append(transaction, state.current_row, chunk.size(), commit_id);
493: 
494: 	// append the physical data to each of the entries
495: 	for (idx_t i = 0; i < types.size(); i++) {
496: 		columns[i].Append(state.states[i], chunk.data[i], chunk.size());
497: 	}
498: 	cardinality += chunk.size();
499: 	state.current_row += chunk.size();
500: }
501: 
502: void DataTable::RevertAppend(TableAppendState &state) {
503: 	if (state.row_start == state.current_row) {
504: 		// nothing to revert!
505: 		return;
506: 	}
507: 	// revert changes in the base columns
508: 	for (idx_t i = 0; i < types.size(); i++) {
509: 		columns[i].RevertAppend(state.row_start);
510: 	}
511: 	// adjust the cardinality
512: 	cardinality -= state.current_row - state.row_start;
513: 	transient_manager.max_row = state.row_start;
514: 	// revert changes in the transient manager
515: 	transient_manager.RevertAppend(state.row_start, state.current_row);
516: }
517: 
518: //===--------------------------------------------------------------------===//
519: // Indexes
520: //===--------------------------------------------------------------------===//
521: bool DataTable::AppendToIndexes(TableAppendState &state, DataChunk &chunk, row_t row_start) {
522: 	if (indexes.size() == 0) {
523: 		return true;
524: 	}
525: 	// first generate the vector of row identifiers
526: 	Vector row_identifiers(ROW_TYPE);
527: 	VectorOperations::GenerateSequence(row_identifiers, chunk.size(), row_start, 1);
528: 
529: 	idx_t failed_index = INVALID_INDEX;
530: 	// now append the entries to the indices
531: 	for (idx_t i = 0; i < indexes.size(); i++) {
532: 		if (!indexes[i]->Append(state.index_locks[i], chunk, row_identifiers)) {
533: 			failed_index = i;
534: 			break;
535: 		}
536: 	}
537: 	if (failed_index != INVALID_INDEX) {
538: 		// constraint violation!
539: 		// remove any appended entries from previous indexes (if any)
540: 		for (idx_t i = 0; i < failed_index; i++) {
541: 			indexes[i]->Delete(state.index_locks[i], chunk, row_identifiers);
542: 		}
543: 		return false;
544: 	}
545: 	return true;
546: }
547: 
548: void DataTable::RemoveFromIndexes(TableAppendState &state, DataChunk &chunk, row_t row_start) {
549: 	if (indexes.size() == 0) {
550: 		return;
551: 	}
552: 	// first generate the vector of row identifiers
553: 	Vector row_identifiers(ROW_TYPE);
554: 	VectorOperations::GenerateSequence(row_identifiers, chunk.size(), row_start, 1);
555: 
556: 	// now remove the entries from the indices
557: 	RemoveFromIndexes(state, chunk, row_identifiers);
558: }
559: 
560: void DataTable::RemoveFromIndexes(TableAppendState &state, DataChunk &chunk, Vector &row_identifiers) {
561: 	for (idx_t i = 0; i < indexes.size(); i++) {
562: 		indexes[i]->Delete(state.index_locks[i], chunk, row_identifiers);
563: 	}
564: }
565: 
566: void DataTable::RemoveFromIndexes(Vector &row_identifiers, idx_t count) {
567: 	auto row_ids = FlatVector::GetData<row_t>(row_identifiers);
568: 	// create a selection vector from the row_ids
569: 	SelectionVector sel(STANDARD_VECTOR_SIZE);
570: 	for (idx_t i = 0; i < count; i++) {
571: 		sel.set_index(i, row_ids[i] % STANDARD_VECTOR_SIZE);
572: 	}
573: 
574: 	// fetch the data for these row identifiers
575: 	DataChunk result;
576: 	result.Initialize(types);
577: 	// FIXME: we do not need to fetch all columns, only the columns required by the indices!
578: 	auto states = unique_ptr<ColumnScanState[]>(new ColumnScanState[types.size()]);
579: 	for (idx_t i = 0; i < types.size(); i++) {
580: 		columns[i].Fetch(states[i], row_ids[0], result.data[i]);
581: 	}
582: 	result.Slice(sel, count);
583: 	for (idx_t i = 0; i < indexes.size(); i++) {
584: 		indexes[i]->Delete(result, row_identifiers);
585: 	}
586: }
587: 
588: //===--------------------------------------------------------------------===//
589: // Delete
590: //===--------------------------------------------------------------------===//
591: void DataTable::Delete(TableCatalogEntry &table, ClientContext &context, Vector &row_identifiers, idx_t count) {
592: 	assert(row_identifiers.type == ROW_TYPE);
593: 	if (count == 0) {
594: 		return;
595: 	}
596: 
597: 	auto &transaction = Transaction::GetTransaction(context);
598: 
599: 	row_identifiers.Normalify(count);
600: 	auto ids = FlatVector::GetData<row_t>(row_identifiers);
601: 	auto first_id = ids[0];
602: 
603: 	if (first_id >= MAX_ROW_ID) {
604: 		// deletion is in transaction-local storage: push delete into local chunk collection
605: 		transaction.storage.Delete(this, row_identifiers, count);
606: 	} else if ((idx_t)first_id < persistent_manager.max_row) {
607: 		// deletion is in persistent storage: delete in the persistent version manager
608: 		persistent_manager.Delete(transaction, row_identifiers, count);
609: 	} else {
610: 		// deletion is in transient storage: delete in the persistent version manager
611: 		transient_manager.Delete(transaction, row_identifiers, count);
612: 	}
613: }
614: 
615: //===--------------------------------------------------------------------===//
616: // Update
617: //===--------------------------------------------------------------------===//
618: static void CreateMockChunk(vector<TypeId> &types, vector<column_t> &column_ids, DataChunk &chunk,
619:                             DataChunk &mock_chunk) {
620: 	// construct a mock DataChunk
621: 	mock_chunk.InitializeEmpty(types);
622: 	for (column_t i = 0; i < column_ids.size(); i++) {
623: 		mock_chunk.data[column_ids[i]].Reference(chunk.data[i]);
624: 	}
625: 	mock_chunk.SetCardinality(chunk.size());
626: }
627: 
628: static bool CreateMockChunk(TableCatalogEntry &table, vector<column_t> &column_ids,
629:                             unordered_set<column_t> &desired_column_ids, DataChunk &chunk, DataChunk &mock_chunk) {
630: 	idx_t found_columns = 0;
631: 	// check whether the desired columns are present in the UPDATE clause
632: 	for (column_t i = 0; i < column_ids.size(); i++) {
633: 		if (desired_column_ids.find(column_ids[i]) != desired_column_ids.end()) {
634: 			found_columns++;
635: 		}
636: 	}
637: 	if (found_columns == 0) {
638: 		// no columns were found: no need to check the constraint again
639: 		return false;
640: 	}
641: 	if (found_columns != desired_column_ids.size()) {
642: 		// FIXME: not all columns in UPDATE clause are present!
643: 		// this should not be triggered at all as the binder should add these columns
644: 		throw NotImplementedException(
645: 		    "Not all columns required for the CHECK constraint are present in the UPDATED chunk!");
646: 	}
647: 	// construct a mock DataChunk
648: 	auto types = table.GetTypes();
649: 	CreateMockChunk(types, column_ids, chunk, mock_chunk);
650: 	return true;
651: }
652: 
653: void DataTable::VerifyUpdateConstraints(TableCatalogEntry &table, DataChunk &chunk, vector<column_t> &column_ids) {
654: 	for (auto &constraint : table.bound_constraints) {
655: 		switch (constraint->type) {
656: 		case ConstraintType::NOT_NULL: {
657: 			auto &not_null = *reinterpret_cast<BoundNotNullConstraint *>(constraint.get());
658: 			// check if the constraint is in the list of column_ids
659: 			for (idx_t i = 0; i < column_ids.size(); i++) {
660: 				if (column_ids[i] == not_null.index) {
661: 					// found the column id: check the data in
662: 					VerifyNotNullConstraint(table, chunk.data[i], chunk.size(), table.columns[not_null.index].name);
663: 					break;
664: 				}
665: 			}
666: 			break;
667: 		}
668: 		case ConstraintType::CHECK: {
669: 			auto &check = *reinterpret_cast<BoundCheckConstraint *>(constraint.get());
670: 
671: 			DataChunk mock_chunk;
672: 			if (CreateMockChunk(table, column_ids, check.bound_columns, chunk, mock_chunk)) {
673: 				VerifyCheckConstraint(table, *check.expression, mock_chunk);
674: 			}
675: 			break;
676: 		}
677: 		case ConstraintType::UNIQUE:
678: 		case ConstraintType::FOREIGN_KEY:
679: 			break;
680: 		default:
681: 			throw NotImplementedException("Constraint type not implemented!");
682: 		}
683: 	}
684: 	// update should not be called for indexed columns!
685: 	// instead update should have been rewritten to delete + update on higher layer
686: #ifdef DEBUG
687: 	for (idx_t i = 0; i < indexes.size(); i++) {
688: 		assert(!indexes[i]->IndexIsUpdated(column_ids));
689: 	}
690: #endif
691: }
692: 
693: void DataTable::Update(TableCatalogEntry &table, ClientContext &context, Vector &row_ids, vector<column_t> &column_ids,
694:                        DataChunk &updates) {
695: 	assert(row_ids.type == ROW_TYPE);
696: 
697: 	updates.Verify();
698: 	if (updates.size() == 0) {
699: 		return;
700: 	}
701: 
702: 	// first verify that no constraints are violated
703: 	VerifyUpdateConstraints(table, updates, column_ids);
704: 
705: 	// now perform the actual update
706: 	auto &transaction = Transaction::GetTransaction(context);
707: 
708: 	updates.Normalify();
709: 	row_ids.Normalify(updates.size());
710: 	auto first_id = FlatVector::GetValue<row_t>(row_ids, 0);
711: 	if (first_id >= MAX_ROW_ID) {
712: 		// update is in transaction-local storage: push update into local storage
713: 		transaction.storage.Update(this, row_ids, column_ids, updates);
714: 		return;
715: 	}
716: 
717: 	for (idx_t i = 0; i < column_ids.size(); i++) {
718: 		auto column = column_ids[i];
719: 		assert(column != COLUMN_IDENTIFIER_ROW_ID);
720: 
721: 		columns[column].Update(transaction, updates.data[i], row_ids, updates.size());
722: 	}
723: }
724: 
725: //===--------------------------------------------------------------------===//
726: // Create Index Scan
727: //===--------------------------------------------------------------------===//
728: void DataTable::InitializeCreateIndexScan(CreateIndexScanState &state, vector<column_t> column_ids) {
729: 	// we grab the append lock to make sure nothing is appended until AFTER we finish the index scan
730: 	state.append_lock = unique_lock<mutex>(append_lock);
731: 	// get a read lock on the VersionManagers to prevent any further deletions
732: 	state.locks.push_back(persistent_manager.lock.GetSharedLock());
733: 	state.locks.push_back(transient_manager.lock.GetSharedLock());
734: 
735: 	InitializeScan(state, column_ids);
736: }
737: 
738: void DataTable::CreateIndexScan(CreateIndexScanState &state, DataChunk &result) {
739: 	// scan the persistent segments
740: 	if (ScanCreateIndex(state, result, state.current_persistent_row, state.max_persistent_row, 0)) {
741: 		return;
742: 	}
743: 	// scan the transient segments
744: 	if (ScanCreateIndex(state, result, state.current_transient_row, state.max_transient_row,
745: 	                    state.max_persistent_row)) {
746: 		return;
747: 	}
748: }
749: 
750: bool DataTable::ScanCreateIndex(CreateIndexScanState &state, DataChunk &result, idx_t &current_row, idx_t max_row,
751:                                 idx_t base_row) {
752: 	if (current_row >= max_row) {
753: 		return false;
754: 	}
755: 	idx_t count = std::min((idx_t)STANDARD_VECTOR_SIZE, max_row - current_row);
756: 
757: 	// scan the base columns to fetch the actual data
758: 	// note that we insert all data into the index, even if it is marked as deleted
759: 	// FIXME: tuples that are already "cleaned up" do not need to be inserted into the index!
760: 	for (idx_t i = 0; i < state.column_ids.size(); i++) {
761: 		auto column = state.column_ids[i];
762: 		if (column == COLUMN_IDENTIFIER_ROW_ID) {
763: 			// scan row id
764: 			assert(result.data[i].type == ROW_TYPE);
765: 			result.data[i].Sequence(base_row + current_row, 1);
766: 		} else {
767: 			// scan actual base column
768: 			columns[column].IndexScan(state.column_scans[i], result.data[i]);
769: 		}
770: 	}
771: 	result.SetCardinality(count);
772: 
773: 	current_row += STANDARD_VECTOR_SIZE;
774: 	return count > 0;
775: }
776: 
777: void DataTable::AddIndex(unique_ptr<Index> index, vector<unique_ptr<Expression>> &expressions) {
778: 	DataChunk result;
779: 	result.Initialize(index->types);
780: 
781: 	DataChunk intermediate;
782: 	vector<TypeId> intermediate_types;
783: 	auto column_ids = index->column_ids;
784: 	column_ids.push_back(COLUMN_IDENTIFIER_ROW_ID);
785: 	for (auto &id : index->column_ids) {
786: 		intermediate_types.push_back(types[id]);
787: 	}
788: 	intermediate_types.push_back(ROW_TYPE);
789: 	intermediate.Initialize(intermediate_types);
790: 
791: 	// initialize an index scan
792: 	CreateIndexScanState state;
793: 	InitializeCreateIndexScan(state, column_ids);
794: 
795: 	// now start incrementally building the index
796: 	IndexLock lock;
797: 	index->InitializeLock(lock);
798: 	ExpressionExecutor executor(expressions);
799: 	while (true) {
800: 		intermediate.Reset();
801: 		// scan a new chunk from the table to index
802: 		CreateIndexScan(state, intermediate);
803: 		if (intermediate.size() == 0) {
804: 			// finished scanning for index creation
805: 			// release all locks
806: 			break;
807: 		}
808: 		// resolve the expressions for this chunk
809: 		executor.Execute(intermediate, result);
810: 
811: 		// insert into the index
812: 		if (!index->Insert(lock, result, intermediate.data[intermediate.column_count() - 1])) {
813: 			throw ConstraintException("Cant create unique index, table contains duplicate data on indexed column(s)");
814: 		}
815: 	}
816: 	indexes.push_back(move(index));
817: }
818: 
819: bool DataTable::IsTemporary() {
820: 	return schema.compare(TEMP_SCHEMA) == 0;
821: }
[end of src/storage/data_table.cpp]
[start of src/storage/string_segment.cpp]
1: #include "duckdb/storage/string_segment.hpp"
2: #include "duckdb/storage/buffer_manager.hpp"
3: #include "duckdb/storage/numeric_segment.hpp"
4: #include "duckdb/transaction/update_info.hpp"
5: #include "duckdb/common/vector_operations/vector_operations.hpp"
6: #include "duckdb/storage/data_table.hpp"
7: #include "duckdb/common/operator/comparison_operators.hpp"
8: 
9: using namespace duckdb;
10: using namespace std;
11: 
12: StringSegment::StringSegment(BufferManager &manager, idx_t row_start, block_id_t block)
13:     : UncompressedSegment(manager, TypeId::VARCHAR, row_start) {
14: 	this->max_vector_count = 0;
15: 	this->dictionary_offset = 0;
16: 	// the vector_size is given in the size of the dictionary offsets
17: 	this->vector_size = STANDARD_VECTOR_SIZE * sizeof(int32_t) + sizeof(nullmask_t);
18: 	this->string_updates = nullptr;
19: 
20: 	this->block_id = block;
21: 	if (block_id == INVALID_BLOCK) {
22: 		// start off with an empty string segment: allocate space for it
23: 		auto handle = manager.Allocate(Storage::BLOCK_ALLOC_SIZE);
24: 		this->block_id = handle->block_id;
25: 
26: 		ExpandStringSegment(handle->node->buffer);
27: 	}
28: }
29: 
30: StringSegment::~StringSegment() {
31: 	while (head) {
32: 		manager.DestroyBuffer(head->block_id);
33: 		head = move(head->next);
34: 	}
35: }
36: 
37: void StringSegment::ExpandStringSegment(data_ptr_t baseptr) {
38: 	// clear the nullmask for this vector
39: 	auto mask = (nullmask_t *)(baseptr + (max_vector_count * vector_size));
40: 	mask->reset();
41: 
42: 	max_vector_count++;
43: 	if (versions) {
44: 		auto new_versions = unique_ptr<UpdateInfo *[]>(new UpdateInfo *[max_vector_count]);
45: 		memcpy(new_versions.get(), versions.get(), (max_vector_count - 1) * sizeof(UpdateInfo *));
46: 		new_versions[max_vector_count - 1] = nullptr;
47: 		versions = move(new_versions);
48: 	}
49: 
50: 	if (string_updates) {
51: 		auto new_string_updates = unique_ptr<string_update_info_t[]>(new string_update_info_t[max_vector_count]);
52: 		for (idx_t i = 0; i < max_vector_count - 1; i++) {
53: 			new_string_updates[i] = move(string_updates[i]);
54: 		}
55: 		new_string_updates[max_vector_count - 1] = 0;
56: 		string_updates = move(new_string_updates);
57: 	}
58: }
59: 
60: //===--------------------------------------------------------------------===//
61: // Scan
62: //===--------------------------------------------------------------------===//
63: void StringSegment::InitializeScan(ColumnScanState &state) {
64: 	// pin the primary buffer
65: 	state.primary_handle = manager.Pin(block_id);
66: }
67: 
68: //===--------------------------------------------------------------------===//
69: // Filter base data
70: //===--------------------------------------------------------------------===//
71: void StringSegment::read_string(string_t *result_data, buffer_handle_set_t &handles, data_ptr_t baseptr,
72:                                 int32_t *dict_offset, idx_t src_idx, idx_t res_idx, idx_t &update_idx,
73:                                 size_t vector_index) {
74: 	if (string_updates && string_updates[vector_index]) {
75: 		auto &info = *string_updates[vector_index];
76: 		if (update_idx < info.count && info.ids[update_idx] == src_idx) {
77: 			result_data[res_idx] = ReadString(handles, info.block_ids[update_idx], info.offsets[update_idx]);
78: 			update_idx++;
79: 		} else {
80: 			result_data[res_idx] = FetchStringFromDict(handles, baseptr, dict_offset[src_idx]);
81: 		}
82: 	} else {
83: 		result_data[res_idx] = FetchStringFromDict(handles, baseptr, dict_offset[src_idx]);
84: 	}
85: }
86: 
87: void StringSegment::Select(ColumnScanState &state, Vector &result, SelectionVector &sel, idx_t &approved_tuple_count,
88:                            vector<TableFilter> &tableFilter) {
89: 	auto vector_index = state.vector_index;
90: 	assert(vector_index < max_vector_count);
91: 	assert(vector_index * STANDARD_VECTOR_SIZE <= tuple_count);
92: 
93: 	auto handle = state.primary_handle.get();
94: 	state.handles.clear();
95: 	auto baseptr = handle->node->buffer;
96: 	// fetch the data from the base segment
97: 	auto base = baseptr + state.vector_index * vector_size;
98: 	auto base_data = (int32_t *)(base + sizeof(nullmask_t));
99: 	auto base_nullmask = (nullmask_t *)base;
100: 
101: 	if (tableFilter.size() == 1) {
102: 		switch (tableFilter[0].comparison_type) {
103: 		case ExpressionType::COMPARE_EQUAL: {
104: 			Select_String<Equals>(state.handles, result, baseptr, base_data, sel, tableFilter[0].constant.str_value,
105: 			                      approved_tuple_count, base_nullmask, vector_index);
106: 			break;
107: 		}
108: 		case ExpressionType::COMPARE_LESSTHAN: {
109: 			Select_String<LessThan>(state.handles, result, baseptr, base_data, sel, tableFilter[0].constant.str_value,
110: 			                        approved_tuple_count, base_nullmask, vector_index);
111: 			break;
112: 		}
113: 		case ExpressionType::COMPARE_GREATERTHAN: {
114: 			Select_String<GreaterThan>(state.handles, result, baseptr, base_data, sel,
115: 			                           tableFilter[0].constant.str_value, approved_tuple_count, base_nullmask,
116: 			                           vector_index);
117: 			break;
118: 		}
119: 		case ExpressionType::COMPARE_LESSTHANOREQUALTO: {
120: 			Select_String<LessThanEquals>(state.handles, result, baseptr, base_data, sel,
121: 			                              tableFilter[0].constant.str_value, approved_tuple_count, base_nullmask,
122: 			                              vector_index);
123: 			break;
124: 		}
125: 		case ExpressionType::COMPARE_GREATERTHANOREQUALTO: {
126: 			Select_String<GreaterThanEquals>(state.handles, result, baseptr, base_data, sel,
127: 			                                 tableFilter[0].constant.str_value, approved_tuple_count, base_nullmask,
128: 			                                 vector_index);
129: 
130: 			break;
131: 		}
132: 		default:
133: 			throw NotImplementedException("Unknown comparison type for filter pushed down to table!");
134: 		}
135: 	} else {
136: 		assert(tableFilter[0].comparison_type == ExpressionType::COMPARE_GREATERTHAN ||
137: 		       tableFilter[0].comparison_type == ExpressionType::COMPARE_GREATERTHANOREQUALTO);
138: 		assert(tableFilter[1].comparison_type == ExpressionType::COMPARE_LESSTHAN ||
139: 		       tableFilter[1].comparison_type == ExpressionType::COMPARE_LESSTHANOREQUALTO);
140: 
141: 		if (tableFilter[0].comparison_type == ExpressionType::COMPARE_GREATERTHAN) {
142: 			if (tableFilter[1].comparison_type == ExpressionType::COMPARE_LESSTHAN) {
143: 				Select_String_Between<GreaterThan, LessThan>(
144: 				    state.handles, result, baseptr, base_data, sel, tableFilter[0].constant.str_value,
145: 				    tableFilter[1].constant.str_value, approved_tuple_count, base_nullmask, vector_index);
146: 			} else {
147: 				Select_String_Between<GreaterThan, LessThanEquals>(
148: 				    state.handles, result, baseptr, base_data, sel, tableFilter[0].constant.str_value,
149: 				    tableFilter[1].constant.str_value, approved_tuple_count, base_nullmask, vector_index);
150: 			}
151: 		} else {
152: 			if (tableFilter[1].comparison_type == ExpressionType::COMPARE_LESSTHAN) {
153: 				Select_String_Between<GreaterThanEquals, LessThan>(
154: 				    state.handles, result, baseptr, base_data, sel, tableFilter[0].constant.str_value,
155: 				    tableFilter[1].constant.str_value, approved_tuple_count, base_nullmask, vector_index);
156: 			} else {
157: 				Select_String_Between<GreaterThanEquals, LessThanEquals>(
158: 				    state.handles, result, baseptr, base_data, sel, tableFilter[0].constant.str_value,
159: 				    tableFilter[1].constant.str_value, approved_tuple_count, base_nullmask, vector_index);
160: 			}
161: 		}
162: 	}
163: }
164: 
165: //===--------------------------------------------------------------------===//
166: // Fetch base data
167: //===--------------------------------------------------------------------===//
168: void StringSegment::FetchBaseData(ColumnScanState &state, idx_t vector_index, Vector &result) {
169: 	// clear any previously locked buffers and get the primary buffer handle
170: 	auto handle = state.primary_handle.get();
171: 	state.handles.clear();
172: 
173: 	// fetch the data from the base segment
174: 	FetchBaseData(state, handle->node->buffer, vector_index, result, GetVectorCount(vector_index));
175: }
176: 
177: void StringSegment::FetchBaseData(ColumnScanState &state, data_ptr_t baseptr, idx_t vector_index, Vector &result,
178:                                   idx_t count) {
179: 	auto base = baseptr + vector_index * vector_size;
180: 
181: 	auto &base_nullmask = *((nullmask_t *)base);
182: 	auto base_data = (int32_t *)(base + sizeof(nullmask_t));
183: 	auto result_data = FlatVector::GetData<string_t>(result);
184: 
185: 	if (string_updates && string_updates[vector_index]) {
186: 		// there are updates: merge them in
187: 		auto &info = *string_updates[vector_index];
188: 		idx_t update_idx = 0;
189: 		for (idx_t i = 0; i < count; i++) {
190: 			if (update_idx < info.count && info.ids[update_idx] == i) {
191: 				// use update info
192: 				result_data[i] = ReadString(state.handles, info.block_ids[update_idx], info.offsets[update_idx]);
193: 				update_idx++;
194: 			} else {
195: 				// use base table info
196: 				result_data[i] = FetchStringFromDict(state.handles, baseptr, base_data[i]);
197: 			}
198: 		}
199: 	} else {
200: 		// no updates: fetch only from the string dictionary
201: 		for (idx_t i = 0; i < count; i++) {
202: 			result_data[i] = FetchStringFromDict(state.handles, baseptr, base_data[i]);
203: 		}
204: 	}
205: 	FlatVector::SetNullmask(result, base_nullmask);
206: }
207: 
208: void StringSegment::FilterFetchBaseData(ColumnScanState &state, Vector &result, SelectionVector &sel,
209:                                         idx_t &approved_tuple_count) {
210: 	// clear any previously locked buffers and get the primary buffer handle
211: 	auto handle = state.primary_handle.get();
212: 	state.handles.clear();
213: 	auto baseptr = handle->node->buffer;
214: 	// fetch the data from the base segment
215: 	auto base = baseptr + state.vector_index * vector_size;
216: 	auto &base_nullmask = *((nullmask_t *)base);
217: 	auto base_data = (int32_t *)(base + sizeof(nullmask_t));
218: 	result.vector_type = VectorType::FLAT_VECTOR;
219: 	auto result_data = FlatVector::GetData<string_t>(result);
220: 	nullmask_t result_nullmask;
221: 	idx_t update_idx = 0;
222: 	if (base_nullmask.any()) {
223: 		for (idx_t i = 0; i < approved_tuple_count; i++) {
224: 			idx_t src_idx = sel.get_index(i);
225: 			if (base_nullmask[src_idx]) {
226: 				result_nullmask.set(i, true);
227: 				read_string(result_data, state.handles, baseptr, base_data, src_idx, i, update_idx, state.vector_index);
228: 			} else {
229: 				read_string(result_data, state.handles, baseptr, base_data, src_idx, i, update_idx, state.vector_index);
230: 			}
231: 		}
232: 	} else {
233: 		for (idx_t i = 0; i < approved_tuple_count; i++) {
234: 			idx_t src_idx = sel.get_index(i);
235: 			read_string(result_data, state.handles, baseptr, base_data, src_idx, i, update_idx, state.vector_index);
236: 		}
237: 	}
238: 	FlatVector::SetNullmask(result, result_nullmask);
239: }
240: 
241: //===--------------------------------------------------------------------===//
242: // Fetch update data
243: //===--------------------------------------------------------------------===//
244: void StringSegment::FetchUpdateData(ColumnScanState &state, Transaction &transaction, UpdateInfo *info,
245:                                     Vector &result) {
246: 	// fetch data from updates
247: 	auto handle = state.primary_handle.get();
248: 
249: 	auto result_data = FlatVector::GetData<string_t>(result);
250: 	auto &result_mask = FlatVector::Nullmask(result);
251: 	UpdateInfo::UpdatesForTransaction(info, transaction, [&](UpdateInfo *current) {
252: 		auto info_data = (string_location_t *)current->tuple_data;
253: 		for (idx_t i = 0; i < current->N; i++) {
254: 			auto string = FetchString(state.handles, handle->node->buffer, info_data[i]);
255: 			result_data[current->tuples[i]] = string;
256: 			result_mask[current->tuples[i]] = current->nullmask[current->tuples[i]];
257: 		}
258: 	});
259: }
260: 
261: //===--------------------------------------------------------------------===//
262: // Fetch strings
263: //===--------------------------------------------------------------------===//
264: void StringSegment::FetchStringLocations(data_ptr_t baseptr, row_t *ids, idx_t vector_index, idx_t vector_offset,
265:                                          idx_t count, string_location_t result[]) {
266: 	auto base = baseptr + vector_index * vector_size;
267: 	auto base_data = (int32_t *)(base + sizeof(nullmask_t));
268: 
269: 	if (string_updates && string_updates[vector_index]) {
270: 		// there are updates: merge them in
271: 		auto &info = *string_updates[vector_index];
272: 		idx_t update_idx = 0;
273: 		for (idx_t i = 0; i < count; i++) {
274: 			auto id = ids[i] - vector_offset;
275: 			while (update_idx < info.count && info.ids[update_idx] < id) {
276: 				update_idx++;
277: 			}
278: 			if (update_idx < info.count && info.ids[update_idx] == id) {
279: 				// use update info
280: 				result[i].block_id = info.block_ids[update_idx];
281: 				result[i].offset = info.offsets[update_idx];
282: 				update_idx++;
283: 			} else {
284: 				// use base table info
285: 				result[i] = FetchStringLocation(baseptr, base_data[id]);
286: 			}
287: 		}
288: 	} else {
289: 		// no updates: fetch strings from base vector
290: 		for (idx_t i = 0; i < count; i++) {
291: 			auto id = ids[i] - vector_offset;
292: 			result[i] = FetchStringLocation(baseptr, base_data[id]);
293: 		}
294: 	}
295: }
296: 
297: string_location_t StringSegment::FetchStringLocation(data_ptr_t baseptr, int32_t dict_offset) {
298: 	if (dict_offset == 0) {
299: 		return string_location_t(INVALID_BLOCK, 0);
300: 	}
301: 	// look up result in dictionary
302: 	auto dict_end = baseptr + Storage::BLOCK_SIZE;
303: 	auto dict_pos = dict_end - dict_offset;
304: 	auto string_length = *((uint16_t *)dict_pos);
305: 	string_location_t result;
306: 	if (string_length == BIG_STRING_MARKER) {
307: 		ReadStringMarker(dict_pos, result.block_id, result.offset);
308: 	} else {
309: 		result.block_id = INVALID_BLOCK;
310: 		result.offset = dict_offset;
311: 	}
312: 	return result;
313: }
314: 
315: string_t StringSegment::FetchStringFromDict(buffer_handle_set_t &handles, data_ptr_t baseptr, int32_t dict_offset) {
316: 	// fetch base data
317: 	assert(dict_offset <= Storage::BLOCK_SIZE);
318: 	string_location_t location = FetchStringLocation(baseptr, dict_offset);
319: 	return FetchString(handles, baseptr, location);
320: }
321: 
322: string_t StringSegment::FetchString(buffer_handle_set_t &handles, data_ptr_t baseptr, string_location_t location) {
323: 	if (location.block_id != INVALID_BLOCK) {
324: 		// big string marker: read from separate block
325: 		return ReadString(handles, location.block_id, location.offset);
326: 	} else {
327: 		if (location.offset == 0) {
328: 			return string_t(nullptr, 0);
329: 		}
330: 		// normal string: read string from this block
331: 		auto dict_end = baseptr + Storage::BLOCK_SIZE;
332: 		auto dict_pos = dict_end - location.offset;
333: 		auto string_length = *((uint16_t *)dict_pos);
334: 
335: 		auto str_ptr = (char *)(dict_pos + sizeof(uint16_t));
336: 		return string_t(str_ptr, string_length);
337: 	}
338: }
339: 
340: void StringSegment::FetchRow(ColumnFetchState &state, Transaction &transaction, row_t row_id, Vector &result,
341:                              idx_t result_idx) {
342: 	auto read_lock = lock.GetSharedLock();
343: 
344: 	idx_t vector_index = row_id / STANDARD_VECTOR_SIZE;
345: 	idx_t id_in_vector = row_id - vector_index * STANDARD_VECTOR_SIZE;
346: 	assert(vector_index < max_vector_count);
347: 
348: 	data_ptr_t baseptr;
349: 
350: 	// fetch a single row from the string segment
351: 	// first pin the main buffer if it is not already pinned
352: 	auto entry = state.handles.find(block_id);
353: 	if (entry == state.handles.end()) {
354: 		// not pinned yet: pin it
355: 		auto handle = manager.Pin(block_id);
356: 		baseptr = handle->node->buffer;
357: 		state.handles[block_id] = move(handle);
358: 	} else {
359: 		// already pinned: use the pinned handle
360: 		baseptr = entry->second->node->buffer;
361: 	}
362: 
363: 	auto base = baseptr + vector_index * vector_size;
364: 	auto &base_nullmask = *((nullmask_t *)base);
365: 	auto base_data = (int32_t *)(base + sizeof(nullmask_t));
366: 	auto result_data = FlatVector::GetData<string_t>(result);
367: 	auto &result_mask = FlatVector::Nullmask(result);
368: 
369: 	bool found_data = false;
370: 	// first see if there is any updated version of this tuple we must fetch
371: 	if (versions && versions[vector_index]) {
372: 		UpdateInfo::UpdatesForTransaction(versions[vector_index], transaction, [&](UpdateInfo *current) {
373: 			auto info_data = (string_location_t *)current->tuple_data;
374: 			// loop over the tuples in this UpdateInfo
375: 			for (idx_t i = 0; i < current->N; i++) {
376: 				if (current->tuples[i] == row_id) {
377: 					// found the relevant tuple
378: 					found_data = true;
379: 					result_data[result_idx] = FetchString(state.handles, baseptr, info_data[i]);
380: 					result_mask[result_idx] = current->nullmask[current->tuples[i]];
381: 					break;
382: 				} else if (current->tuples[i] > row_id) {
383: 					// tuples are sorted: so if the current tuple is > row_id we will not find it anymore
384: 					break;
385: 				}
386: 			}
387: 		});
388: 	}
389: 	if (!found_data && string_updates && string_updates[vector_index]) {
390: 		// there are updates: check if we should use them
391: 		auto &info = *string_updates[vector_index];
392: 		for (idx_t i = 0; i < info.count; i++) {
393: 			if (info.ids[i] == id_in_vector) {
394: 				// use the update
395: 				result_data[result_idx] = ReadString(state.handles, info.block_ids[i], info.offsets[i]);
396: 				found_data = true;
397: 				break;
398: 			} else if (info.ids[i] > id_in_vector) {
399: 				break;
400: 			}
401: 		}
402: 	}
403: 	if (!found_data) {
404: 		// no version was found yet: fetch base table version
405: 		result_data[result_idx] = FetchStringFromDict(state.handles, baseptr, base_data[id_in_vector]);
406: 	}
407: 	result_mask[result_idx] = base_nullmask[id_in_vector];
408: }
409: 
410: //===--------------------------------------------------------------------===//
411: // Append
412: //===--------------------------------------------------------------------===//
413: idx_t StringSegment::Append(SegmentStatistics &stats, Vector &data, idx_t offset, idx_t count) {
414: 	assert(data.type == TypeId::VARCHAR);
415: 	auto handle = manager.Pin(block_id);
416: 	idx_t initial_count = tuple_count;
417: 	while (count > 0) {
418: 		// get the vector index of the vector to append to and see how many tuples we can append to that vector
419: 		idx_t vector_index = tuple_count / STANDARD_VECTOR_SIZE;
420: 		if (vector_index == max_vector_count) {
421: 			// we are at the maximum vector, check if there is space to increase the maximum vector count
422: 			// as a heuristic, we only allow another vector to be added if we have at least 32 bytes per string
423: 			// remaining (32KB out of a 256KB block, or around 12% empty)
424: 			if (RemainingSpace() >= STANDARD_VECTOR_SIZE * 32) {
425: 				// we have enough remaining space to add another vector
426: 				ExpandStringSegment(handle->node->buffer);
427: 			} else {
428: 				break;
429: 			}
430: 		}
431: 		idx_t current_tuple_count = tuple_count - vector_index * STANDARD_VECTOR_SIZE;
432: 		idx_t append_count = std::min(STANDARD_VECTOR_SIZE - current_tuple_count, count);
433: 
434: 		// now perform the actual append
435: 		AppendData(stats, handle->node->buffer + vector_size * vector_index, handle->node->buffer + Storage::BLOCK_SIZE,
436: 		           current_tuple_count, data, offset, append_count);
437: 
438: 		count -= append_count;
439: 		offset += append_count;
440: 		tuple_count += append_count;
441: 	}
442: 	return tuple_count - initial_count;
443: }
444: 
445: static void update_min_max(string value, char *__restrict min, char *__restrict max) {
446: 	//! we can only fit 8 bytes, so we might need to trim our string
447: 	size_t value_size = value.size() > 7 ? 7 : value.size();
448: 	if (min[0] == '\0' && max[0] == '\0') {
449: 		size_t min_end = value.copy(min, value_size);
450: 		size_t max_end = value.copy(max, value_size);
451: 		for (size_t i = min_end; i < 8; i++) {
452: 			min[i] = '\0';
453: 		}
454: 		for (size_t i = max_end; i < 8; i++) {
455: 			max[i] = '\0';
456: 		}
457: 	}
458: 	if (strcmp(value.data(), min) < 0) {
459: 		size_t min_end = value.copy(min, value_size);
460: 		for (size_t i = min_end; i < 8; i++) {
461: 			min[i] = '\0';
462: 		}
463: 	}
464: 	if (strcmp(value.data(), max) > 0) {
465: 		size_t max_end = value.copy(max, value_size);
466: 		for (size_t i = max_end; i < 8; i++) {
467: 			max[i] = '\0';
468: 		}
469: 	}
470: }
471: 
472: void StringSegment::AppendData(SegmentStatistics &stats, data_ptr_t target, data_ptr_t end, idx_t target_offset,
473:                                Vector &source, idx_t offset, idx_t count) {
474: 	VectorData adata;
475: 	source.Orrify(count, adata);
476: 
477: 	auto sdata = (string_t *)adata.data;
478: 	auto &result_nullmask = *((nullmask_t *)target);
479: 	auto result_data = (int32_t *)(target + sizeof(nullmask_t));
480: 	auto min = (char *)stats.minimum.get();
481: 	auto max = (char *)stats.maximum.get();
482: 
483: 	idx_t remaining_strings = STANDARD_VECTOR_SIZE - (this->tuple_count % STANDARD_VECTOR_SIZE);
484: 	for (idx_t i = 0; i < count; i++) {
485: 		auto source_idx = adata.sel->get_index(offset + i);
486: 		auto target_idx = target_offset + i;
487: 		if ((*adata.nullmask)[source_idx]) {
488: 			// null value is stored as -1
489: 			result_data[target_idx] = 0;
490: 			result_nullmask[target_idx] = true;
491: 			stats.has_null = true;
492: 		} else {
493: 			assert(dictionary_offset < Storage::BLOCK_SIZE);
494: 			// non-null value, check if we can fit it within the block
495: 			idx_t string_length = sdata[source_idx].GetSize();
496: 			idx_t total_length = string_length + 1 + sizeof(uint16_t);
497: 
498: 			if (string_length > stats.max_string_length) {
499: 				stats.max_string_length = string_length;
500: 			}
501: 			// determine whether or not the string needs to be stored in an overflow block
502: 			// we never place small strings in the overflow blocks: the pointer would take more space than the
503: 			// string itself we always place big strings (>= STRING_BLOCK_LIMIT) in the overflow blocks we also have
504: 			// to always leave enough room for BIG_STRING_MARKER_SIZE for each of the remaining strings
505: 			if (total_length > BIG_STRING_MARKER_BASE_SIZE &&
506: 			    (total_length >= STRING_BLOCK_LIMIT ||
507: 			     total_length + (remaining_strings * BIG_STRING_MARKER_SIZE) > RemainingSpace())) {
508: 				assert(RemainingSpace() >= BIG_STRING_MARKER_SIZE);
509: 				// string is too big for block: write to overflow blocks
510: 				block_id_t block;
511: 				int32_t offset;
512: 				//! Update min/max of column segment
513: 				update_min_max(sdata[source_idx].GetData(), min, max);
514: 				// write the string into the current string block
515: 				WriteString(sdata[source_idx], block, offset);
516: 				dictionary_offset += BIG_STRING_MARKER_SIZE;
517: 				auto dict_pos = end - dictionary_offset;
518: 
519: 				// write a big string marker into the dictionary
520: 				WriteStringMarker(dict_pos, block, offset);
521: 
522: 				stats.has_overflow_strings = true;
523: 			} else {
524: 				// string fits in block, append to dictionary and increment dictionary position
525: 				assert(string_length < std::numeric_limits<uint16_t>::max());
526: 				dictionary_offset += total_length;
527: 				auto dict_pos = end - dictionary_offset;
528: 				//! Update min/max of column segment
529: 				update_min_max(sdata[source_idx].GetData(), min, max);
530: 				// first write the length as u16
531: 				uint16_t string_length_u16 = string_length;
532: 				memcpy(dict_pos, &string_length_u16, sizeof(uint16_t));
533: 				// now write the actual string data into the dictionary
534: 				memcpy(dict_pos + sizeof(uint16_t), sdata[source_idx].GetData(), string_length + 1);
535: 			}
536: 			// place the dictionary offset into the set of vectors
537: 			assert(dictionary_offset <= Storage::BLOCK_SIZE);
538: 			result_data[target_idx] = dictionary_offset;
539: 		}
540: 		remaining_strings--;
541: 	}
542: }
543: 
544: void StringSegment::WriteString(string_t string, block_id_t &result_block, int32_t &result_offset) {
545: 	assert(strlen(string.GetData()) == string.GetSize());
546: 	if (overflow_writer) {
547: 		// overflow writer is set: write string there
548: 		overflow_writer->WriteString(string, result_block, result_offset);
549: 	} else {
550: 		// default overflow behavior: use in-memory buffer to store the overflow string
551: 		WriteStringMemory(string, result_block, result_offset);
552: 	}
553: }
554: 
555: void StringSegment::WriteStringMemory(string_t string, block_id_t &result_block, int32_t &result_offset) {
556: 	uint32_t total_length = string.GetSize() + 1 + sizeof(uint32_t);
557: 	unique_ptr<BufferHandle> handle;
558: 	// check if the string fits in the current block
559: 	if (!head || head->offset + total_length >= head->size) {
560: 		// string does not fit, allocate space for it
561: 		// create a new string block
562: 		idx_t alloc_size = std::max((idx_t)total_length, (idx_t)Storage::BLOCK_ALLOC_SIZE);
563: 		auto new_block = make_unique<StringBlock>();
564: 		new_block->offset = 0;
565: 		new_block->size = alloc_size;
566: 		// allocate an in-memory buffer for it
567: 		handle = manager.Allocate(alloc_size);
568: 		new_block->block_id = handle->block_id;
569: 		new_block->next = move(head);
570: 		head = move(new_block);
571: 	} else {
572: 		// string fits, copy it into the current block
573: 		handle = manager.Pin(head->block_id);
574: 	}
575: 
576: 	result_block = head->block_id;
577: 	result_offset = head->offset;
578: 
579: 	// copy the string and the length there
580: 	auto ptr = handle->node->buffer + head->offset;
581: 	memcpy(ptr, &string.length, sizeof(uint32_t));
582: 	ptr += sizeof(uint32_t);
583: 	memcpy(ptr, string.GetData(), string.length + 1);
584: 	head->offset += total_length;
585: }
586: 
587: string_t StringSegment::ReadString(buffer_handle_set_t &handles, block_id_t block, int32_t offset) {
588: 	assert(offset < Storage::BLOCK_SIZE);
589: 	if (block == INVALID_BLOCK) {
590: 		return string_t(nullptr, 0);
591: 	}
592: 	if (block < MAXIMUM_BLOCK) {
593: 		// read the overflow string from disk
594: 		// pin the initial handle and read the length
595: 		auto handle = manager.Pin(block);
596: 		uint32_t length = *((uint32_t *)(handle->node->buffer + offset));
597: 		uint32_t remaining = length + 1;
598: 		offset += sizeof(uint32_t);
599: 
600: 		// allocate a buffer to store the string
601: 		auto alloc_size = std::max((idx_t)Storage::BLOCK_ALLOC_SIZE, (idx_t)length + 1 + sizeof(uint32_t));
602: 		auto target_handle = manager.Allocate(alloc_size, true);
603: 		auto target_ptr = target_handle->node->buffer;
604: 		// write the length in this block as well
605: 		*((uint32_t *)target_ptr) = length;
606: 		target_ptr += sizeof(uint32_t);
607: 		// now append the string to the single buffer
608: 		while (remaining > 0) {
609: 			idx_t to_write = std::min((idx_t)remaining, (idx_t)(Storage::BLOCK_SIZE - sizeof(block_id_t) - offset));
610: 			memcpy(target_ptr, handle->node->buffer + offset, to_write);
611: 
612: 			remaining -= to_write;
613: 			offset += to_write;
614: 			target_ptr += to_write;
615: 			if (remaining > 0) {
616: 				// read the next block
617: 				block_id_t next_block = *((block_id_t *)(handle->node->buffer + offset));
618: 				handle = manager.Pin(next_block);
619: 				offset = 0;
620: 			}
621: 		}
622: 
623: 		auto final_buffer = target_handle->node->buffer;
624: 		handles.insert(make_pair(target_handle->block_id, move(target_handle)));
625: 		return ReadString(final_buffer, 0);
626: 	} else {
627: 		// read the overflow string from memory
628: 		// first pin the handle, if it is not pinned yet
629: 		BufferHandle *handle;
630: 		auto entry = handles.find(block);
631: 		if (entry == handles.end()) {
632: 			auto pinned_handle = manager.Pin(block);
633: 			handle = pinned_handle.get();
634: 
635: 			handles.insert(make_pair(block, move(pinned_handle)));
636: 		} else {
637: 			handle = entry->second.get();
638: 		}
639: 		return ReadString(handle->node->buffer, offset);
640: 	}
641: }
642: 
643: string_t StringSegment::ReadString(data_ptr_t target, int32_t offset) {
644: 	auto ptr = target + offset;
645: 	auto str_length = *((uint32_t *)ptr);
646: 	auto str_ptr = (char *)(ptr + sizeof(uint32_t));
647: 	return string_t(str_ptr, str_length);
648: }
649: 
650: void StringSegment::WriteStringMarker(data_ptr_t target, block_id_t block_id, int32_t offset) {
651: 	uint16_t length = BIG_STRING_MARKER;
652: 	memcpy(target, &length, sizeof(uint16_t));
653: 	target += sizeof(uint16_t);
654: 	memcpy(target, &block_id, sizeof(block_id_t));
655: 	target += sizeof(block_id_t);
656: 	memcpy(target, &offset, sizeof(int32_t));
657: }
658: 
659: void StringSegment::ReadStringMarker(data_ptr_t target, block_id_t &block_id, int32_t &offset) {
660: 	target += sizeof(uint16_t);
661: 	memcpy(&block_id, target, sizeof(block_id_t));
662: 	target += sizeof(block_id_t);
663: 	memcpy(&offset, target, sizeof(int32_t));
664: }
665: 
666: //===--------------------------------------------------------------------===//
667: // String Update
668: //===--------------------------------------------------------------------===//
669: string_update_info_t StringSegment::CreateStringUpdate(SegmentStatistics &stats, Vector &update, row_t *ids,
670:                                                        idx_t count, idx_t vector_offset) {
671: 	auto info = make_unique<StringUpdateInfo>();
672: 	info->count = count;
673: 	auto strings = FlatVector::GetData<string_t>(update);
674: 	auto &update_nullmask = FlatVector::Nullmask(update);
675: 	for (idx_t i = 0; i < count; i++) {
676: 		info->ids[i] = ids[i] - vector_offset;
677: 		// copy the string into the block
678: 		if (!update_nullmask[i]) {
679: 			auto min = (char *)stats.minimum.get();
680: 			auto max = (char *)stats.maximum.get();
681: 			for (idx_t i = 0; i < count; i++) {
682: 				update_min_max(strings[i].GetData(), min, max);
683: 			}
684: 			WriteString(strings[i], info->block_ids[i], info->offsets[i]);
685: 		} else {
686: 			info->block_ids[i] = INVALID_BLOCK;
687: 			info->offsets[i] = 0;
688: 		}
689: 	}
690: 	return info;
691: }
692: 
693: string_update_info_t StringSegment::MergeStringUpdate(SegmentStatistics &stats, Vector &update, row_t *ids,
694:                                                       idx_t update_count, idx_t vector_offset,
695:                                                       StringUpdateInfo &update_info) {
696: 	auto info = make_unique<StringUpdateInfo>();
697: 
698: 	// perform a merge between the new and old indexes
699: 	auto strings = FlatVector::GetData<string_t>(update);
700: 	auto &update_nullmask = FlatVector::Nullmask(update);
701: 	auto pick_new = [&](idx_t id, idx_t idx, idx_t count) {
702: 		info->ids[count] = id;
703: 		if (!update_nullmask[idx]) {
704: 			WriteString(strings[idx], info->block_ids[count], info->offsets[count]);
705: 		} else {
706: 			info->block_ids[count] = INVALID_BLOCK;
707: 			info->offsets[count] = 0;
708: 		}
709: 	};
710: 	auto merge = [&](idx_t id, idx_t aidx, idx_t bidx, idx_t count) {
711: 		// merge: only pick new entry
712: 		pick_new(id, aidx, count);
713: 	};
714: 	auto pick_old = [&](idx_t id, idx_t bidx, idx_t count) {
715: 		// pick old entry
716: 		info->ids[count] = id;
717: 		info->block_ids[count] = update_info.block_ids[bidx];
718: 		info->offsets[count] = update_info.offsets[bidx];
719: 	};
720: 
721: 	info->count =
722: 	    merge_loop(ids, update_info.ids, update_count, update_info.count, vector_offset, merge, pick_new, pick_old);
723: 	return info;
724: }
725: 
726: //===--------------------------------------------------------------------===//
727: // Update Info
728: //===--------------------------------------------------------------------===//
729: void StringSegment::MergeUpdateInfo(UpdateInfo *node, row_t *ids, idx_t update_count, idx_t vector_offset,
730:                                     string_location_t base_data[], nullmask_t base_nullmask) {
731: 	auto info_data = (string_location_t *)node->tuple_data;
732: 
733: 	// first we copy the old update info into a temporary structure
734: 	sel_t old_ids[STANDARD_VECTOR_SIZE];
735: 	string_location_t old_data[STANDARD_VECTOR_SIZE];
736: 
737: 	memcpy(old_ids, node->tuples, node->N * sizeof(sel_t));
738: 	memcpy(old_data, node->tuple_data, node->N * sizeof(string_location_t));
739: 
740: 	// now we perform a merge of the new ids with the old ids
741: 	auto merge = [&](idx_t id, idx_t aidx, idx_t bidx, idx_t count) {
742: 		// new_id and old_id are the same, insert the old data in the UpdateInfo
743: 		assert(old_data[bidx].IsValid());
744: 		info_data[count] = old_data[bidx];
745: 		node->tuples[count] = id;
746: 	};
747: 	auto pick_new = [&](idx_t id, idx_t aidx, idx_t count) {
748: 		// new_id comes before the old id, insert the base table data into the update info
749: 		assert(base_data[aidx].IsValid());
750: 		info_data[count] = base_data[aidx];
751: 		node->nullmask[id] = base_nullmask[aidx];
752: 
753: 		node->tuples[count] = id;
754: 	};
755: 	auto pick_old = [&](idx_t id, idx_t bidx, idx_t count) {
756: 		// old_id comes before new_id, insert the old data
757: 		assert(old_data[bidx].IsValid());
758: 		info_data[count] = old_data[bidx];
759: 		node->tuples[count] = id;
760: 	};
761: 	// perform the merge
762: 	node->N = merge_loop(ids, old_ids, update_count, node->N, vector_offset, merge, pick_new, pick_old);
763: }
764: 
765: //===--------------------------------------------------------------------===//
766: // Update
767: //===--------------------------------------------------------------------===//
768: void StringSegment::Update(ColumnData &column_data, SegmentStatistics &stats, Transaction &transaction, Vector &update,
769:                            row_t *ids, idx_t count, idx_t vector_index, idx_t vector_offset, UpdateInfo *node) {
770: 	if (!string_updates) {
771: 		string_updates = unique_ptr<string_update_info_t[]>(new string_update_info_t[max_vector_count]);
772: 	}
773: 
774: 	// first pin the base block
775: 	auto handle = manager.Pin(block_id);
776: 	auto baseptr = handle->node->buffer;
777: 	auto base = baseptr + vector_index * vector_size;
778: 	auto &base_nullmask = *((nullmask_t *)base);
779: 
780: 	// fetch the original string locations and copy the original nullmask
781: 	string_location_t string_locations[STANDARD_VECTOR_SIZE];
782: 	nullmask_t original_nullmask = base_nullmask;
783: 	FetchStringLocations(baseptr, ids, vector_index, vector_offset, count, string_locations);
784: 
785: 	string_update_info_t new_update_info;
786: 	// next up: create the updates
787: 	if (!string_updates[vector_index]) {
788: 		// no string updates yet, allocate a block and place the updates there
789: 		new_update_info = CreateStringUpdate(stats, update, ids, count, vector_offset);
790: 	} else {
791: 		// string updates already exist, merge the string updates together
792: 		new_update_info = MergeStringUpdate(stats, update, ids, count, vector_offset, *string_updates[vector_index]);
793: 	}
794: 
795: 	// now update the original nullmask
796: 	auto &update_nullmask = FlatVector::Nullmask(update);
797: 	for (idx_t i = 0; i < count; i++) {
798: 		base_nullmask[ids[i] - vector_offset] = update_nullmask[i];
799: 	}
800: 
801: 	// now that the original strings are placed in the undo buffer and the updated strings are placed in the base table
802: 	// create the update node
803: 	if (!node) {
804: 		// create a new node in the undo buffer for this update
805: 		node = CreateUpdateInfo(column_data, transaction, ids, count, vector_index, vector_offset,
806: 		                        sizeof(string_location_t));
807: 
808: 		// copy the string location data into the undo buffer
809: 		node->nullmask = original_nullmask;
810: 		memcpy(node->tuple_data, string_locations, sizeof(string_location_t) * count);
811: 	} else {
812: 		// node in the update info already exists, merge the new updates in
813: 		MergeUpdateInfo(node, ids, count, vector_offset, string_locations, original_nullmask);
814: 	}
815: 	// finally move the string updates in place
816: 	string_updates[vector_index] = move(new_update_info);
817: }
818: 
819: void StringSegment::RollbackUpdate(UpdateInfo *info) {
820: 	auto lock_handle = lock.GetExclusiveLock();
821: 
822: 	idx_t new_count = 0;
823: 	auto &update_info = *string_updates[info->vector_index];
824: 	auto string_locations = (string_location_t *)info->tuple_data;
825: 
826: 	// put the previous NULL values back
827: 	auto handle = manager.Pin(block_id);
828: 	auto baseptr = handle->node->buffer;
829: 	auto base = baseptr + info->vector_index * vector_size;
830: 	auto &base_nullmask = *((nullmask_t *)base);
831: 	for (idx_t i = 0; i < info->N; i++) {
832: 		base_nullmask[info->tuples[i]] = info->nullmask[info->tuples[i]];
833: 	}
834: 
835: 	// now put the original values back into the update info
836: 	idx_t old_idx = 0;
837: 	for (idx_t i = 0; i < update_info.count; i++) {
838: 		if (old_idx >= info->N || update_info.ids[i] != info->tuples[old_idx]) {
839: 			assert(old_idx >= info->N || update_info.ids[i] < info->tuples[old_idx]);
840: 			// this entry is not rolled back: insert entry directly
841: 			update_info.ids[new_count] = update_info.ids[i];
842: 			update_info.block_ids[new_count] = update_info.block_ids[i];
843: 			update_info.offsets[new_count] = update_info.offsets[i];
844: 			new_count++;
845: 		} else {
846: 			// this entry is being rolled back
847: 			auto &old_location = string_locations[old_idx];
848: 			if (old_location.block_id != INVALID_BLOCK) {
849: 				// not rolled back to base table: insert entry again
850: 				update_info.ids[new_count] = update_info.ids[i];
851: 				update_info.block_ids[new_count] = old_location.block_id;
852: 				update_info.offsets[new_count] = old_location.offset;
853: 				new_count++;
854: 			}
855: 			old_idx++;
856: 		}
857: 	}
858: 
859: 	if (new_count == 0) {
860: 		// all updates are rolled back: delete the string update vector
861: 		string_updates[info->vector_index].reset();
862: 	} else {
863: 		// set the count of the new string update vector
864: 		update_info.count = new_count;
865: 	}
866: 	CleanupUpdate(info);
867: }
[end of src/storage/string_segment.cpp]
[start of src/storage/table/column_segment.cpp]
1: #include "duckdb/storage/table/column_segment.hpp"
2: #include <cstring>
3: 
4: using namespace duckdb;
5: using namespace std;
6: 
7: ColumnSegment::ColumnSegment(TypeId type, ColumnSegmentType segment_type, idx_t start, idx_t count)
8:     : SegmentBase(start, count), type(type), type_size(GetTypeIdSize(type)), segment_type(segment_type),
9:       stats(type, type_size) {
10: }
11: 
12: ColumnSegment::ColumnSegment(TypeId type, ColumnSegmentType segment_type, idx_t start, idx_t count, data_t stats_min[],
13:                              data_t stats_max[])
14:     : SegmentBase(start, count), type(type), type_size(GetTypeIdSize(type)), segment_type(segment_type),
15:       stats(type, type_size, stats_min, stats_max) {
16: }
17: 
18: SegmentStatistics::SegmentStatistics(TypeId type, idx_t type_size) : type(type), type_size(type_size) {
19: 	Reset();
20: }
21: 
22: template <class T>
23: static void set_min_max(data_t min_value_p[], data_t max_value_p[], data_ptr_t min_p, data_ptr_t max_p) {
24: 	memcpy(min_p, min_value_p, sizeof(T));
25: 	memcpy(max_p, max_value_p, sizeof(T));
26: }
27: 
28: SegmentStatistics::SegmentStatistics(TypeId type, idx_t type_size, data_t stats_min[], data_t stats_max[])
29:     : type(type), type_size(type_size) {
30: 	Reset();
31: 	switch (type) {
32: 	case TypeId::INT8: {
33: 		set_min_max<int8_t>(stats_min, stats_max, minimum.get(), maximum.get());
34: 		break;
35: 	}
36: 	case TypeId::INT16: {
37: 		set_min_max<int16_t>(stats_min, stats_max, minimum.get(), maximum.get());
38: 		break;
39: 	}
40: 	case TypeId::INT32: {
41: 		set_min_max<int32_t>(stats_min, stats_max, minimum.get(), maximum.get());
42: 		break;
43: 	}
44: 	case TypeId::INT64: {
45: 		set_min_max<int64_t>(stats_min, stats_max, minimum.get(), maximum.get());
46: 		break;
47: 	}
48: 	case TypeId::FLOAT: {
49: 		set_min_max<float>(stats_min, stats_max, minimum.get(), maximum.get());
50: 		break;
51: 	}
52: 	case TypeId::DOUBLE: {
53: 		set_min_max<double>(stats_min, stats_max, minimum.get(), maximum.get());
54: 		break;
55: 	}
56: 	case TypeId::VARCHAR: {
57: 		set_min_max<char[8]>(stats_min, stats_max, minimum.get(), maximum.get());
58: 		break;
59: 	}
60: 
61: 	default:
62: 		break;
63: 	}
64: }
65: 
66: template <class T> void initialize_max_min(data_ptr_t min, data_ptr_t max) {
67: 	*((T *)min) = std::numeric_limits<T>::max();
68: 	*((T *)max) = std::numeric_limits<T>::min();
69: }
70: 
71: void SegmentStatistics::Reset() {
72: 	idx_t min_max_size = type_size > 8 ? 8 : type_size;
73: 	minimum = unique_ptr<data_t[]>(new data_t[min_max_size]);
74: 	maximum = unique_ptr<data_t[]>(new data_t[min_max_size]);
75: 	has_null = false;
76: 	max_string_length = 0;
77: 	has_overflow_strings = false;
78: 	char padding = '\0';
79: 	switch (type) {
80: 	case TypeId::INT8:
81: 		initialize_max_min<int8_t>(minimum.get(), maximum.get());
82: 		break;
83: 	case TypeId::INT16:
84: 		initialize_max_min<int16_t>(minimum.get(), maximum.get());
85: 		break;
86: 	case TypeId::INT32:
87: 		initialize_max_min<int32_t>(minimum.get(), maximum.get());
88: 		break;
89: 	case TypeId::INT64:
90: 		initialize_max_min<int64_t>(minimum.get(), maximum.get());
91: 		break;
92: 	case TypeId::FLOAT:
93: 		initialize_max_min<float>(minimum.get(), maximum.get());
94: 		break;
95: 	case TypeId::DOUBLE:
96: 		initialize_max_min<double>(minimum.get(), maximum.get());
97: 		break;
98: 	case TypeId::VARCHAR: {
99: 		memset(minimum.get(), padding, min_max_size);
100: 		memset(maximum.get(), padding, min_max_size);
101: 		break;
102: 	}
103: 	default:
104: 		break;
105: 	}
106: }
[end of src/storage/table/column_segment.cpp]
[start of tools/shell/linenoise.c]
1: /* linenoise.c -- guerrilla line editing library against the idea that a
2:  * line editing lib needs to be 20,000 lines of C code.
3:  *
4:  * You can find the latest source code at:
5:  *
6:  *   http://github.com/antirez/linenoise
7:  *
8:  * Does a number of crazy assumptions that happen to be true in 99.9999% of
9:  * the 2010 UNIX computers around.
10:  *
11:  * ------------------------------------------------------------------------
12:  *
13:  * Copyright (c) 2010-2016, Salvatore Sanfilippo <antirez at gmail dot com>
14:  * Copyright (c) 2010-2013, Pieter Noordhuis <pcnoordhuis at gmail dot com>
15:  *
16:  * All rights reserved.
17:  *
18:  * Redistribution and use in source and binary forms, with or without
19:  * modification, are permitted provided that the following conditions are
20:  * met:
21:  *
22:  *  *  Redistributions of source code must retain the above copyright
23:  *     notice, this list of conditions and the following disclaimer.
24:  *
25:  *  *  Redistributions in binary form must reproduce the above copyright
26:  *     notice, this list of conditions and the following disclaimer in the
27:  *     documentation and/or other materials provided with the distribution.
28:  *
29:  * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
30:  * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
31:  * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
32:  * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
33:  * HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
34:  * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
35:  * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
36:  * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
37:  * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
38:  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
39:  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
40:  *
41:  * ------------------------------------------------------------------------
42:  *
43:  * References:
44:  * - http://invisible-island.net/xterm/ctlseqs/ctlseqs.html
45:  * - http://www.3waylabs.com/nw/WWW/products/wizcon/vt220.html
46:  *
47:  * Todo list:
48:  * - Filter bogus Ctrl+<char> combinations.
49:  * - Win32 support
50:  *
51:  * Bloat:
52:  * - History search like Ctrl+r in readline?
53:  *
54:  * List of escape sequences used by this program, we do everything just
55:  * with three sequences. In order to be so cheap we may have some
56:  * flickering effect with some slow terminal, but the lesser sequences
57:  * the more compatible.
58:  *
59:  * EL (Erase Line)
60:  *    Sequence: ESC [ n K
61:  *    Effect: if n is 0 or missing, clear from cursor to end of line
62:  *    Effect: if n is 1, clear from beginning of line to cursor
63:  *    Effect: if n is 2, clear entire line
64:  *
65:  * CUF (CUrsor Forward)
66:  *    Sequence: ESC [ n C
67:  *    Effect: moves cursor forward n chars
68:  *
69:  * CUB (CUrsor Backward)
70:  *    Sequence: ESC [ n D
71:  *    Effect: moves cursor backward n chars
72:  *
73:  * The following is used to get the terminal width if getting
74:  * the width with the TIOCGWINSZ ioctl fails
75:  *
76:  * DSR (Device Status Report)
77:  *    Sequence: ESC [ 6 n
78:  *    Effect: reports the current cusor position as ESC [ n ; m R
79:  *            where n is the row and m is the column
80:  *
81:  * When multi line mode is enabled, we also use an additional escape
82:  * sequence. However multi line editing is disabled by default.
83:  *
84:  * CUU (Cursor Up)
85:  *    Sequence: ESC [ n A
86:  *    Effect: moves cursor up of n chars.
87:  *
88:  * CUD (Cursor Down)
89:  *    Sequence: ESC [ n B
90:  *    Effect: moves cursor down of n chars.
91:  *
92:  * When linenoiseClearScreen() is called, two additional escape sequences
93:  * are used in order to clear the screen and position the cursor at home
94:  * position.
95:  *
96:  * CUP (Cursor position)
97:  *    Sequence: ESC [ H
98:  *    Effect: moves the cursor to upper left corner
99:  *
100:  * ED (Erase display)
101:  *    Sequence: ESC [ 2 J
102:  *    Effect: clear the whole screen
103:  *
104:  */
105: 
106: #include <termios.h>
107: #include <unistd.h>
108: #include <stdlib.h>
109: #include <stdio.h>
110: #include <errno.h>
111: #include <string.h>
112: #include <stdlib.h>
113: #include <ctype.h>
114: #include <sys/stat.h>
115: #include <sys/types.h>
116: #include <sys/ioctl.h>
117: #include <unistd.h>
118: #include "linenoise.h"
119: #include "utf8proc_wrapper.h"
120: 
121: #define LINENOISE_DEFAULT_HISTORY_MAX_LEN 100
122: #define LINENOISE_MAX_LINE 4096
123: static char *unsupported_term[] = {"dumb", "cons25", "emacs", NULL};
124: static linenoiseCompletionCallback *completionCallback = NULL;
125: static linenoiseHintsCallback *hintsCallback = NULL;
126: static linenoiseFreeHintsCallback *freeHintsCallback = NULL;
127: 
128: static struct termios orig_termios; /* In order to restore at exit.*/
129: static int rawmode = 0;             /* For atexit() function to check if restore is needed*/
130: static int mlmode = 0;              /* Multi line mode. Default is single line. */
131: static int atexit_registered = 0;   /* Register atexit just 1 time. */
132: static int history_max_len = LINENOISE_DEFAULT_HISTORY_MAX_LEN;
133: static int history_len = 0;
134: static char **history = NULL;
135: 
136: /* The linenoiseState structure represents the state during line editing.
137:  * We pass this state to functions implementing specific editing
138:  * functionalities. */
139: struct linenoiseState {
140: 	int ifd;            /* Terminal stdin file descriptor. */
141: 	int ofd;            /* Terminal stdout file descriptor. */
142: 	char *buf;          /* Edited line buffer. */
143: 	size_t buflen;      /* Edited line buffer size. */
144: 	const char *prompt; /* Prompt to display. */
145: 	size_t plen;        /* Prompt length. */
146: 	size_t pos;         /* Current cursor position. */
147: 	size_t oldpos;      /* Previous refresh cursor position. */
148: 	size_t len;         /* Current edited line length. */
149: 	size_t cols;        /* Number of columns in terminal. */
150: 	size_t maxrows;     /* Maximum num of rows used so far (multiline mode) */
151: 	int history_index;  /* The history index we are currently editing. */
152: };
153: 
154: enum KEY_ACTION {
155: 	KEY_NULL = 0,   /* NULL */
156: 	CTRL_A = 1,     /* Ctrl+a */
157: 	CTRL_B = 2,     /* Ctrl-b */
158: 	CTRL_C = 3,     /* Ctrl-c */
159: 	CTRL_D = 4,     /* Ctrl-d */
160: 	CTRL_E = 5,     /* Ctrl-e */
161: 	CTRL_F = 6,     /* Ctrl-f */
162: 	CTRL_H = 8,     /* Ctrl-h */
163: 	TAB = 9,        /* Tab */
164: 	CTRL_K = 11,    /* Ctrl+k */
165: 	CTRL_L = 12,    /* Ctrl+l */
166: 	ENTER = 13,     /* Enter */
167: 	CTRL_N = 14,    /* Ctrl-n */
168: 	CTRL_P = 16,    /* Ctrl-p */
169: 	CTRL_T = 20,    /* Ctrl-t */
170: 	CTRL_U = 21,    /* Ctrl+u */
171: 	CTRL_W = 23,    /* Ctrl+w */
172: 	ESC = 27,       /* Escape */
173: 	BACKSPACE = 127 /* Backspace */
174: };
175: 
176: static void linenoiseAtExit(void);
177: int linenoiseHistoryAdd(const char *line);
178: static void refreshLine(struct linenoiseState *l);
179: 
180: /* Debugging macro. */
181: #if 0
182: FILE *lndebug_fp = NULL;
183: #define lndebug(...)                                                                                                   \
184: 	do {                                                                                                               \
185: 		if (lndebug_fp == NULL) {                                                                                      \
186: 			lndebug_fp = fopen("/tmp/lndebug.txt", "a");                                                               \
187: 			fprintf(lndebug_fp, "[%d %d %d] p: %d, rows: %d, rpos: %d, max: %d, oldmax: %d\n", (int)l->len,            \
188: 			        (int)l->pos, (int)l->oldpos, plen, rows, rpos, (int)l->maxrows, old_rows);                         \
189: 		}                                                                                                              \
190: 		fprintf(lndebug_fp, ", " __VA_ARGS__);                                                                         \
191: 		fflush(lndebug_fp);                                                                                            \
192: 	} while (0)
193: #else
194: #define lndebug(fmt, ...)
195: #endif
196: 
197: /* ======================= Low level terminal handling ====================== */
198: 
199: /* Set if to use or not the multi line mode. */
200: void linenoiseSetMultiLine(int ml) {
201: 	mlmode = ml;
202: }
203: 
204: /* Return true if the terminal name is in the list of terminals we know are
205:  * not able to understand basic escape sequences. */
206: static int isUnsupportedTerm(void) {
207: 	char *term = getenv("TERM");
208: 	int j;
209: 
210: 	if (term == NULL)
211: 		return 0;
212: 	for (j = 0; unsupported_term[j]; j++)
213: 		if (!strcasecmp(term, unsupported_term[j]))
214: 			return 1;
215: 	return 0;
216: }
217: 
218: /* Raw mode: 1960 magic shit. */
219: static int enableRawMode(int fd) {
220: 	struct termios raw;
221: 
222: 	if (!isatty(STDIN_FILENO))
223: 		goto fatal;
224: 	if (!atexit_registered) {
225: 		atexit(linenoiseAtExit);
226: 		atexit_registered = 1;
227: 	}
228: 	if (tcgetattr(fd, &orig_termios) == -1)
229: 		goto fatal;
230: 
231: 	raw = orig_termios; /* modify the original mode */
232: 	/* input modes: no break, no CR to NL, no parity check, no strip char,
233: 	 * no start/stop output control. */
234: 	raw.c_iflag &= ~(BRKINT | ICRNL | INPCK | ISTRIP | IXON);
235: 	/* output modes - disable post processing */
236: 	raw.c_oflag &= ~(OPOST);
237: 	/* control modes - set 8 bit chars */
238: 	raw.c_cflag |= (CS8);
239: 	/* local modes - choing off, canonical off, no extended functions,
240: 	 * no signal chars (^Z,^C) */
241: 	raw.c_lflag &= ~(ECHO | ICANON | IEXTEN | ISIG);
242: 	/* control chars - set return condition: min number of bytes and timer.
243: 	 * We want read to return every single byte, without timeout. */
244: 	raw.c_cc[VMIN] = 1;
245: 	raw.c_cc[VTIME] = 0; /* 1 byte, no timer */
246: 
247: 	/* put terminal in raw mode after flushing */
248: 	if (tcsetattr(fd, TCSADRAIN, &raw) < 0)
249: 		goto fatal;
250: 	rawmode = 1;
251: 	return 0;
252: 
253: fatal:
254: 	errno = ENOTTY;
255: 	return -1;
256: }
257: 
258: static void disableRawMode(int fd) {
259: 	/* Don't even check the return value as it's too late. */
260: 	if (rawmode && tcsetattr(fd, TCSADRAIN, &orig_termios) != -1)
261: 		rawmode = 0;
262: }
263: 
264: /* Use the ESC [6n escape sequence to query the horizontal cursor position
265:  * and return it. On error -1 is returned, on success the position of the
266:  * cursor. */
267: static int getCursorPosition(int ifd, int ofd) {
268: 	char buf[32];
269: 	int cols, rows;
270: 	unsigned int i = 0;
271: 
272: 	/* Report cursor location */
273: 	if (write(ofd, "\x1b[6n", 4) != 4)
274: 		return -1;
275: 
276: 	/* Read the response: ESC [ rows ; cols R */
277: 	while (i < sizeof(buf) - 1) {
278: 		if (read(ifd, buf + i, 1) != 1)
279: 			break;
280: 		if (buf[i] == 'R')
281: 			break;
282: 		i++;
283: 	}
284: 	buf[i] = '\0';
285: 
286: 	/* Parse it. */
287: 	if (buf[0] != ESC || buf[1] != '[')
288: 		return -1;
289: 	if (sscanf(buf + 2, "%d;%d", &rows, &cols) != 2)
290: 		return -1;
291: 	return cols;
292: }
293: 
294: /* Try to get the number of columns in the current terminal, or assume 80
295:  * if it fails. */
296: static int getColumns(int ifd, int ofd) {
297: 	struct winsize ws;
298: 
299: 	if (ioctl(1, TIOCGWINSZ, &ws) == -1 || ws.ws_col == 0) {
300: 		/* ioctl() failed. Try to query the terminal itself. */
301: 		int start, cols;
302: 
303: 		/* Get the initial position so we can restore it later. */
304: 		start = getCursorPosition(ifd, ofd);
305: 		if (start == -1)
306: 			goto failed;
307: 
308: 		/* Go to right margin and get position. */
309: 		if (write(ofd, "\x1b[999C", 6) != 6)
310: 			goto failed;
311: 		cols = getCursorPosition(ifd, ofd);
312: 		if (cols == -1)
313: 			goto failed;
314: 
315: 		/* Restore position. */
316: 		if (cols > start) {
317: 			char seq[32];
318: 			snprintf(seq, 32, "\x1b[%dD", cols - start);
319: 			if (write(ofd, seq, strlen(seq)) == -1) {
320: 				/* Can't recover... */
321: 			}
322: 		}
323: 		return cols;
324: 	} else {
325: 		return ws.ws_col;
326: 	}
327: 
328: failed:
329: 	return 80;
330: }
331: 
332: /* Clear the screen. Used to handle ctrl+l */
333: void linenoiseClearScreen(void) {
334: 	if (write(STDOUT_FILENO, "\x1b[H\x1b[2J", 7) <= 0) {
335: 		/* nothing to do, just to avoid warning. */
336: 	}
337: }
338: 
339: /* Beep, used for completion when there is nothing to complete or when all
340:  * the choices were already shown. */
341: static void linenoiseBeep(void) {
342: 	fprintf(stderr, "\x7");
343: 	fflush(stderr);
344: }
345: 
346: /* ============================== Completion ================================ */
347: 
348: /* Free a list of completion option populated by linenoiseAddCompletion(). */
349: static void freeCompletions(linenoiseCompletions *lc) {
350: 	size_t i;
351: 	for (i = 0; i < lc->len; i++)
352: 		free(lc->cvec[i]);
353: 	if (lc->cvec != NULL)
354: 		free(lc->cvec);
355: }
356: 
357: /* This is an helper function for linenoiseEdit() and is called when the
358:  * user types the <tab> key in order to complete the string currently in the
359:  * input.
360:  *
361:  * The state of the editing is encapsulated into the pointed linenoiseState
362:  * structure as described in the structure definition. */
363: static int completeLine(struct linenoiseState *ls) {
364: 	linenoiseCompletions lc = {0, NULL};
365: 	int nread, nwritten;
366: 	char c = 0;
367: 
368: 	completionCallback(ls->buf, &lc);
369: 	if (lc.len == 0) {
370: 		linenoiseBeep();
371: 	} else {
372: 		size_t stop = 0, i = 0;
373: 
374: 		while (!stop) {
375: 			/* Show completion or original buffer */
376: 			if (i < lc.len) {
377: 				struct linenoiseState saved = *ls;
378: 
379: 				ls->len = ls->pos = strlen(lc.cvec[i]);
380: 				ls->buf = lc.cvec[i];
381: 				refreshLine(ls);
382: 				ls->len = saved.len;
383: 				ls->pos = saved.pos;
384: 				ls->buf = saved.buf;
385: 			} else {
386: 				refreshLine(ls);
387: 			}
388: 
389: 			nread = read(ls->ifd, &c, 1);
390: 			if (nread <= 0) {
391: 				freeCompletions(&lc);
392: 				return -1;
393: 			}
394: 
395: 			switch (c) {
396: 			case 9: /* tab */
397: 				i = (i + 1) % (lc.len + 1);
398: 				if (i == lc.len)
399: 					linenoiseBeep();
400: 				break;
401: 			case 27: /* escape */
402: 				/* Re-show original buffer */
403: 				if (i < lc.len)
404: 					refreshLine(ls);
405: 				stop = 1;
406: 				break;
407: 			default:
408: 				/* Update buffer and return */
409: 				if (i < lc.len) {
410: 					nwritten = snprintf(ls->buf, ls->buflen, "%s", lc.cvec[i]);
411: 					ls->len = ls->pos = nwritten;
412: 				}
413: 				stop = 1;
414: 				break;
415: 			}
416: 		}
417: 	}
418: 
419: 	freeCompletions(&lc);
420: 	return c; /* Return last read character */
421: }
422: 
423: /* Register a callback function to be called for tab-completion. */
424: void linenoiseSetCompletionCallback(linenoiseCompletionCallback *fn) {
425: 	completionCallback = fn;
426: }
427: 
428: /* Register a hits function to be called to show hits to the user at the
429:  * right of the prompt. */
430: void linenoiseSetHintsCallback(linenoiseHintsCallback *fn) {
431: 	hintsCallback = fn;
432: }
433: 
434: /* Register a function to free the hints returned by the hints callback
435:  * registered with linenoiseSetHintsCallback(). */
436: void linenoiseSetFreeHintsCallback(linenoiseFreeHintsCallback *fn) {
437: 	freeHintsCallback = fn;
438: }
439: 
440: /* This function is used by the callback function registered by the user
441:  * in order to add completion options given the input string when the
442:  * user typed <tab>. See the example.c source code for a very easy to
443:  * understand example. */
444: void linenoiseAddCompletion(linenoiseCompletions *lc, const char *str) {
445: 	size_t len = strlen(str);
446: 	char *copy, **cvec;
447: 
448: 	copy = malloc(len + 1);
449: 	if (copy == NULL)
450: 		return;
451: 	memcpy(copy, str, len + 1);
452: 	cvec = realloc(lc->cvec, sizeof(char *) * (lc->len + 1));
453: 	if (cvec == NULL) {
454: 		free(copy);
455: 		return;
456: 	}
457: 	lc->cvec = cvec;
458: 	lc->cvec[lc->len++] = copy;
459: }
460: 
461: /* =========================== Line editing ================================= */
462: 
463: /* We define a very simple "append buffer" structure, that is an heap
464:  * allocated string where we can append to. This is useful in order to
465:  * write all the escape sequences in a buffer and flush them to the standard
466:  * output in a single call, to avoid flickering effects. */
467: struct abuf {
468: 	char *b;
469: 	int len;
470: };
471: 
472: static void abInit(struct abuf *ab) {
473: 	ab->b = NULL;
474: 	ab->len = 0;
475: }
476: 
477: static void abAppend(struct abuf *ab, const char *s, int len) {
478: 	char *new = realloc(ab->b, ab->len + len);
479: 
480: 	if (new == NULL)
481: 		return;
482: 	memcpy(new + ab->len, s, len);
483: 	ab->b = new;
484: 	ab->len += len;
485: }
486: 
487: static void abFree(struct abuf *ab) {
488: 	free(ab->b);
489: }
490: 
491: /* Helper of refreshSingleLine() and refreshMultiLine() to show hints
492:  * to the right of the prompt. */
493: void refreshShowHints(struct abuf *ab, struct linenoiseState *l, int plen) {
494: 	char seq[64];
495: 	if (hintsCallback && plen + l->len < l->cols) {
496: 		int color = -1, bold = 0;
497: 		char *hint = hintsCallback(l->buf, &color, &bold);
498: 		if (hint) {
499: 			int hintlen = strlen(hint);
500: 			int hintmaxlen = l->cols - (plen + l->len);
501: 			if (hintlen > hintmaxlen)
502: 				hintlen = hintmaxlen;
503: 			if (bold == 1 && color == -1)
504: 				color = 37;
505: 			if (color != -1 || bold != 0)
506: 				snprintf(seq, 64, "\033[%d;%d;49m", bold, color);
507: 			else
508: 				seq[0] = '\0';
509: 			abAppend(ab, seq, strlen(seq));
510: 			abAppend(ab, hint, hintlen);
511: 			if (color != -1 || bold != 0)
512: 				abAppend(ab, "\033[0m", 4);
513: 			/* Call the function to free the hint returned. */
514: 			if (freeHintsCallback)
515: 				freeHintsCallback(hint);
516: 		}
517: 	}
518: }
519: 
520: static size_t compute_render_width(const char *buf, size_t len) {
521: 	if (utf8proc_is_valid(buf, len)) {
522: 		// utf8 in prompt, get render width
523: 		size_t cpos = 0;
524: 		size_t render_width = 0;
525: 		while (cpos < len) {
526: 			size_t char_render_width = utf8proc_render_width(buf, len, cpos);
527: 			cpos = utf8proc_next_grapheme_cluster(buf, len, cpos);
528: 			render_width += char_render_width;
529: 		}
530: 		return render_width;
531: 	} else {
532: 		// invalid utf8 in prompt, use length in bytes
533: 		return len;
534: 	}
535: }
536: 
537: /* Single line low level line refresh.
538:  *
539:  * Rewrite the currently edited line accordingly to the buffer content,
540:  * cursor position, and number of columns of the terminal. */
541: static void refreshSingleLine(struct linenoiseState *l) {
542: 	char seq[64];
543: 	size_t plen = compute_render_width(l->prompt, strlen(l->prompt));
544: 	int fd = l->ofd;
545: 	char *buf = l->buf;
546: 	size_t len = l->len;
547: 	size_t pos = l->pos;
548: 	struct abuf ab;
549: 	size_t render_pos = 0;
550: 
551: 	if (utf8proc_is_valid(l->buf, l->len)) {
552: 		// utf8 in prompt, handle rendering
553: 		size_t remaining_render_width = l->cols - plen - 1;
554: 		size_t start_pos = 0;
555: 		size_t cpos = 0;
556: 		size_t prev_pos = 0;
557: 		size_t total_render_width = 0;
558: 		while (cpos < len) {
559: 			size_t char_render_width = utf8proc_render_width(buf, len, cpos);
560: 			prev_pos = cpos;
561: 			cpos = utf8proc_next_grapheme_cluster(buf, len, cpos);
562: 			total_render_width += cpos - prev_pos;
563: 			if (total_render_width >= remaining_render_width) {
564: 				// character does not fit anymore! we need to figure something out
565: 				if (prev_pos >= l->pos) {
566: 					// we passed the cursor: break
567: 					cpos = prev_pos;
568: 					break;
569: 				} else {
570: 					// we did not pass the cursor yet! remove characters from the start until it fits again
571: 					while(total_render_width >= remaining_render_width) {
572: 						size_t start_char_width = utf8proc_render_width(buf, len, start_pos);
573: 						size_t new_start = utf8proc_next_grapheme_cluster(buf, len, start_pos);
574: 						total_render_width -= new_start - start_pos;
575: 						start_pos = new_start;
576: 						render_pos -= start_char_width;
577: 					}
578: 				}
579: 			}
580: 			if (prev_pos < l->pos) {
581: 				render_pos += char_render_width;
582: 			}
583: 		}
584: 		buf = buf + start_pos;
585: 		len = cpos - start_pos;
586: 	} else {
587: 		// invalid UTF8: fallback
588: 		while ((plen + pos) >= l->cols) {
589: 			buf++;
590: 			len--;
591: 			pos--;
592: 		}
593: 		while (plen + len > l->cols) {
594: 			len--;
595: 		}
596: 		render_pos = pos;
597: 	}
598: 
599: 	abInit(&ab);
600: 	/* Cursor to left edge */
601: 	snprintf(seq, 64, "\r");
602: 	abAppend(&ab, seq, strlen(seq));
603: 	/* Write the prompt and the current buffer content */
604: 	abAppend(&ab, l->prompt, strlen(l->prompt));
605: 	abAppend(&ab, buf, len);
606: 	/* Show hits if any. */
607: 	refreshShowHints(&ab, l, plen);
608: 	/* Erase to right */
609: 	snprintf(seq, 64, "\x1b[0K");
610: 	abAppend(&ab, seq, strlen(seq));
611: 	/* Move cursor to original position. */
612: 	snprintf(seq, 64, "\r\x1b[%dC", (int)(render_pos + plen));
613: 	abAppend(&ab, seq, strlen(seq));
614: 	if (write(fd, ab.b, ab.len) == -1) {
615: 	} /* Can't recover from write error. */
616: 	abFree(&ab);
617: }
618: 
619: /* Multi line low level line refresh.
620:  *
621:  * Rewrite the currently edited line accordingly to the buffer content,
622:  * cursor position, and number of columns of the terminal. */
623: static void refreshMultiLine(struct linenoiseState *l) {
624: 	char seq[64];
625: 	int plen = strlen(l->prompt);
626: 	int rows = (plen + l->len + l->cols - 1) / l->cols; /* rows used by current buf. */
627: 	int rpos = (plen + l->oldpos + l->cols) / l->cols;  /* cursor relative row. */
628: 	int rpos2;                                          /* rpos after refresh. */
629: 	int col;                                            /* colum position, zero-based. */
630: 	int old_rows = l->maxrows;
631: 	int fd = l->ofd, j;
632: 	struct abuf ab;
633: 
634: 	/* Update maxrows if needed. */
635: 	if (rows > (int)l->maxrows)
636: 		l->maxrows = rows;
637: 
638: 	/* First step: clear all the lines used before. To do so start by
639: 	 * going to the last row. */
640: 	abInit(&ab);
641: 	if (old_rows - rpos > 0) {
642: 		lndebug("go down %d", old_rows - rpos);
643: 		snprintf(seq, 64, "\x1b[%dB", old_rows - rpos);
644: 		abAppend(&ab, seq, strlen(seq));
645: 	}
646: 
647: 	/* Now for every row clear it, go up. */
648: 	for (j = 0; j < old_rows - 1; j++) {
649: 		lndebug("clear+up");
650: 		snprintf(seq, 64, "\r\x1b[0K\x1b[1A");
651: 		abAppend(&ab, seq, strlen(seq));
652: 	}
653: 
654: 	/* Clean the top line. */
655: 	lndebug("clear");
656: 	snprintf(seq, 64, "\r\x1b[0K");
657: 	abAppend(&ab, seq, strlen(seq));
658: 
659: 	/* Write the prompt and the current buffer content */
660: 	abAppend(&ab, l->prompt, strlen(l->prompt));
661: 	abAppend(&ab, l->buf, l->len);
662: 
663: 	/* Show hits if any. */
664: 	refreshShowHints(&ab, l, plen);
665: 
666: 	/* If we are at the very end of the screen with our prompt, we need to
667: 	 * emit a newline and move the prompt to the first column. */
668: 	if (l->pos && l->pos == l->len && (l->pos + plen) % l->cols == 0) {
669: 		lndebug("<newline>");
670: 		abAppend(&ab, "\n", 1);
671: 		snprintf(seq, 64, "\r");
672: 		abAppend(&ab, seq, strlen(seq));
673: 		rows++;
674: 		if (rows > (int)l->maxrows)
675: 			l->maxrows = rows;
676: 	}
677: 
678: 	/* Move cursor to right position. */
679: 	rpos2 = (plen + l->pos + l->cols) / l->cols; /* current cursor relative row. */
680: 	lndebug("rpos2 %d", rpos2);
681: 
682: 	/* Go up till we reach the expected positon. */
683: 	if (rows - rpos2 > 0) {
684: 		lndebug("go-up %d", rows - rpos2);
685: 		snprintf(seq, 64, "\x1b[%dA", rows - rpos2);
686: 		abAppend(&ab, seq, strlen(seq));
687: 	}
688: 
689: 	/* Set column. */
690: 	col = (plen + (int)l->pos) % (int)l->cols;
691: 	lndebug("set col %d", 1 + col);
692: 	if (col)
693: 		snprintf(seq, 64, "\r\x1b[%dC", col);
694: 	else
695: 		snprintf(seq, 64, "\r");
696: 	abAppend(&ab, seq, strlen(seq));
697: 
698: 	lndebug("\n");
699: 	l->oldpos = l->pos;
700: 
701: 	if (write(fd, ab.b, ab.len) == -1) {
702: 	} /* Can't recover from write error. */
703: 	abFree(&ab);
704: }
705: 
706: /* Calls the two low level functions refreshSingleLine() or
707:  * refreshMultiLine() according to the selected mode. */
708: static void refreshLine(struct linenoiseState *l) {
709: 	if (mlmode)
710: 		refreshMultiLine(l);
711: 	else
712: 		refreshSingleLine(l);
713: }
714: 
715: /* Insert the character 'c' at cursor current position.
716:  *
717:  * On error writing to the terminal -1 is returned, otherwise 0. */
718: int linenoiseEditInsert(struct linenoiseState *l, char c) {
719: 	if (l->len < l->buflen) {
720: 		if (l->len == l->pos) {
721: 			l->buf[l->pos] = c;
722: 			l->pos++;
723: 			l->len++;
724: 			l->buf[l->len] = '\0';
725: 			if ((!mlmode && l->plen + l->len < l->cols && !hintsCallback)) {
726: 				/* Avoid a full update of the line in the
727: 				 * trivial case. */
728: 				if (write(l->ofd, &c, 1) == -1)
729: 					return -1;
730: 			} else {
731: 				refreshLine(l);
732: 			}
733: 		} else {
734: 			memmove(l->buf + l->pos + 1, l->buf + l->pos, l->len - l->pos);
735: 			l->buf[l->pos] = c;
736: 			l->len++;
737: 			l->pos++;
738: 			l->buf[l->len] = '\0';
739: 			refreshLine(l);
740: 		}
741: 	}
742: 	refreshLine(l);
743: 	return 0;
744: }
745: 
746: static size_t prev_char(struct linenoiseState *l) {
747: 	return utf8proc_prev_grapheme_cluster(l->buf, l->len, l->pos);
748: }
749: 
750: static size_t next_char(struct linenoiseState *l) {
751: 	return utf8proc_next_grapheme_cluster(l->buf, l->len, l->pos);
752: }
753: 
754: /* Move cursor on the left. */
755: void linenoiseEditMoveLeft(struct linenoiseState *l) {
756: 	if (l->pos > 0) {
757: 		l->pos = prev_char(l);
758: 		refreshLine(l);
759: 	}
760: }
761: 
762: /* Move cursor on the right. */
763: void linenoiseEditMoveRight(struct linenoiseState *l) {
764: 	if (l->pos != l->len) {
765: 		l->pos = next_char(l);
766: 		refreshLine(l);
767: 	}
768: }
769: 
770: /* Move cursor to the start of the line. */
771: void linenoiseEditMoveHome(struct linenoiseState *l) {
772: 	if (l->pos != 0) {
773: 		l->pos = 0;
774: 		refreshLine(l);
775: 	}
776: }
777: 
778: /* Move cursor to the end of the line. */
779: void linenoiseEditMoveEnd(struct linenoiseState *l) {
780: 	if (l->pos != l->len) {
781: 		l->pos = l->len;
782: 		refreshLine(l);
783: 	}
784: }
785: 
786: /* Substitute the currently edited line with the next or previous history
787:  * entry as specified by 'dir'. */
788: #define LINENOISE_HISTORY_NEXT 0
789: #define LINENOISE_HISTORY_PREV 1
790: void linenoiseEditHistoryNext(struct linenoiseState *l, int dir) {
791: 	if (history_len > 1) {
792: 		/* Update the current history entry before to
793: 		 * overwrite it with the next one. */
794: 		free(history[history_len - 1 - l->history_index]);
795: 		history[history_len - 1 - l->history_index] = strdup(l->buf);
796: 		/* Show the new entry */
797: 		l->history_index += (dir == LINENOISE_HISTORY_PREV) ? 1 : -1;
798: 		if (l->history_index < 0) {
799: 			l->history_index = 0;
800: 			return;
801: 		} else if (l->history_index >= history_len) {
802: 			l->history_index = history_len - 1;
803: 			return;
804: 		}
805: 		strncpy(l->buf, history[history_len - 1 - l->history_index], l->buflen);
806: 		l->buf[l->buflen - 1] = '\0';
807: 		l->len = l->pos = strlen(l->buf);
808: 		refreshLine(l);
809: 	}
810: }
811: 
812: /* Delete the character at the right of the cursor without altering the cursor
813:  * position. Basically this is what happens with the "Delete" keyboard key. */
814: void linenoiseEditDelete(struct linenoiseState *l) {
815: 	if (l->len > 0 && l->pos < l->len) {
816: 		size_t new_pos = next_char(l);
817: 		size_t char_sz = new_pos - l->pos;
818: 		memmove(l->buf + l->pos, l->buf + new_pos, l->len - new_pos);
819: 		l->len -= char_sz;
820: 		l->buf[l->len] = '\0';
821: 		refreshLine(l);
822: 	}
823: }
824: 
825: /* Backspace implementation. */
826: void linenoiseEditBackspace(struct linenoiseState *l) {
827: 	if (l->pos > 0 && l->len > 0) {
828: 		size_t new_pos = prev_char(l);
829: 		size_t char_sz = l->pos - new_pos;
830: 		memmove(l->buf + new_pos, l->buf + l->pos, l->len - l->pos);
831: 		l->len -= char_sz;
832: 		l->pos = new_pos;
833: 		l->buf[l->len] = '\0';
834: 		refreshLine(l);
835: 	}
836: }
837: 
838: /* Delete the previosu word, maintaining the cursor at the start of the
839:  * current word. */
840: void linenoiseEditDeletePrevWord(struct linenoiseState *l) {
841: 	size_t old_pos = l->pos;
842: 	size_t diff;
843: 
844: 	while (l->pos > 0 && l->buf[l->pos - 1] == ' ')
845: 		l->pos--;
846: 	while (l->pos > 0 && l->buf[l->pos - 1] != ' ')
847: 		l->pos--;
848: 	diff = old_pos - l->pos;
849: 	memmove(l->buf + l->pos, l->buf + old_pos, l->len - old_pos + 1);
850: 	l->len -= diff;
851: 	refreshLine(l);
852: }
853: 
854: /* This function is the core of the line editing capability of linenoise.
855:  * It expects 'fd' to be already in "raw mode" so that every key pressed
856:  * will be returned ASAP to read().
857:  *
858:  * The resulting string is put into 'buf' when the user type enter, or
859:  * when ctrl+d is typed.
860:  *
861:  * The function returns the length of the current buffer. */
862: static int linenoiseEdit(int stdin_fd, int stdout_fd, char *buf, size_t buflen, const char *prompt) {
863: 	struct linenoiseState l;
864: 
865: 	/* Populate the linenoise state that we pass to functions implementing
866: 	 * specific editing functionalities. */
867: 	l.ifd = stdin_fd;
868: 	l.ofd = stdout_fd;
869: 	l.buf = buf;
870: 	l.buflen = buflen;
871: 	l.prompt = prompt;
872: 	l.plen = strlen(prompt);
873: 	l.oldpos = l.pos = 0;
874: 	l.len = 0;
875: 	l.cols = getColumns(stdin_fd, stdout_fd);
876: 	l.maxrows = 0;
877: 	l.history_index = 0;
878: 
879: 	/* Buffer starts empty. */
880: 	l.buf[0] = '\0';
881: 	l.buflen--; /* Make sure there is always space for the nulterm */
882: 
883: 	/* The latest history entry is always our current buffer, that
884: 	 * initially is just an empty string. */
885: 	linenoiseHistoryAdd("");
886: 
887: 	if (write(l.ofd, prompt, l.plen) == -1)
888: 		return -1;
889: 	while (1) {
890: 		char c;
891: 		int nread;
892: 		char seq[3];
893: 
894: 		nread = read(l.ifd, &c, 1);
895: 		if (nread <= 0)
896: 			return l.len;
897: 
898: 		/* Only autocomplete when the callback is set. It returns < 0 when
899: 		 * there was an error reading from fd. Otherwise it will return the
900: 		 * character that should be handled next. */
901: 		if (c == 9 && completionCallback != NULL) {
902: 			c = completeLine(&l);
903: 			/* Return on errors */
904: 			if (c < 0)
905: 				return l.len;
906: 			/* Read next character when 0 */
907: 			if (c == 0)
908: 				continue;
909: 		}
910: 
911: 		switch (c) {
912: 		case ENTER: /* enter */
913: 			history_len--;
914: 			free(history[history_len]);
915: 			if (mlmode)
916: 				linenoiseEditMoveEnd(&l);
917: 			if (hintsCallback) {
918: 				/* Force a refresh without hints to leave the previous
919: 				 * line as the user typed it after a newline. */
920: 				linenoiseHintsCallback *hc = hintsCallback;
921: 				hintsCallback = NULL;
922: 				refreshLine(&l);
923: 				hintsCallback = hc;
924: 			}
925: 			return (int)l.len;
926: 		case CTRL_C: /* ctrl-c */
927: 			errno = EAGAIN;
928: 			return -1;
929: 		case BACKSPACE: /* backspace */
930: 		case 8:         /* ctrl-h */
931: 			linenoiseEditBackspace(&l);
932: 			break;
933: 		case CTRL_D: /* ctrl-d, remove char at right of cursor, or if the
934: 		                line is empty, act as end-of-file. */
935: 			if (l.len > 0) {
936: 				linenoiseEditDelete(&l);
937: 			} else {
938: 				history_len--;
939: 				free(history[history_len]);
940: 				return -1;
941: 			}
942: 			break;
943: 		case CTRL_T: /* ctrl-t, swaps current character with previous. */
944: 			if (l.pos > 0 && l.pos < l.len) {
945: 				char temp_buffer[128];
946: 				int prev_pos = prev_char(&l);
947: 				int next_pos = next_char(&l);
948: 				int prev_char_size = l.pos - prev_pos;
949: 				int cur_char_size = next_pos - l.pos;
950: 				memcpy(temp_buffer, l.buf + prev_pos, prev_char_size);
951: 				memmove(l.buf + prev_pos, l.buf + l.pos, cur_char_size);
952: 				memcpy(l.buf + prev_pos + cur_char_size, temp_buffer, prev_char_size);
953: 				l.pos = next_pos;
954: 				refreshLine(&l);
955: 			}
956: 			break;
957: 		case CTRL_B: /* ctrl-b */
958: 			linenoiseEditMoveLeft(&l);
959: 			break;
960: 		case CTRL_F: /* ctrl-f */
961: 			linenoiseEditMoveRight(&l);
962: 			break;
963: 		case CTRL_P: /* ctrl-p */
964: 			linenoiseEditHistoryNext(&l, LINENOISE_HISTORY_PREV);
965: 			break;
966: 		case CTRL_N: /* ctrl-n */
967: 			linenoiseEditHistoryNext(&l, LINENOISE_HISTORY_NEXT);
968: 			break;
969: 		case ESC: /* escape sequence */
970: 			/* Read the next two bytes representing the escape sequence.
971: 			 * Use two calls to handle slow terminals returning the two
972: 			 * chars at different times. */
973: 			if (read(l.ifd, seq, 1) == -1)
974: 				break;
975: 			if (read(l.ifd, seq + 1, 1) == -1)
976: 				break;
977: 
978: 			/* ESC [ sequences. */
979: 			if (seq[0] == '[') {
980: 				if (seq[1] >= '0' && seq[1] <= '9') {
981: 					/* Extended escape, read additional byte. */
982: 					if (read(l.ifd, seq + 2, 1) == -1)
983: 						break;
984: 					if (seq[2] == '~') {
985: 						switch (seq[1]) {
986: 						case '3': /* Delete key. */
987: 							linenoiseEditDelete(&l);
988: 							break;
989: 						}
990: 					}
991: 				} else {
992: 					switch (seq[1]) {
993: 					case 'A': /* Up */
994: 						linenoiseEditHistoryNext(&l, LINENOISE_HISTORY_PREV);
995: 						break;
996: 					case 'B': /* Down */
997: 						linenoiseEditHistoryNext(&l, LINENOISE_HISTORY_NEXT);
998: 						break;
999: 					case 'C': /* Right */
1000: 						linenoiseEditMoveRight(&l);
1001: 						break;
1002: 					case 'D': /* Left */
1003: 						linenoiseEditMoveLeft(&l);
1004: 						break;
1005: 					case 'H': /* Home */
1006: 						linenoiseEditMoveHome(&l);
1007: 						break;
1008: 					case 'F': /* End*/
1009: 						linenoiseEditMoveEnd(&l);
1010: 						break;
1011: 					}
1012: 				}
1013: 			}
1014: 
1015: 			/* ESC O sequences. */
1016: 			else if (seq[0] == 'O') {
1017: 				switch (seq[1]) {
1018: 				case 'H': /* Home */
1019: 					linenoiseEditMoveHome(&l);
1020: 					break;
1021: 				case 'F': /* End*/
1022: 					linenoiseEditMoveEnd(&l);
1023: 					break;
1024: 				}
1025: 			}
1026: 			break;
1027: 		default:
1028: 			if (linenoiseEditInsert(&l, c))
1029: 				return -1;
1030: 			break;
1031: 		case CTRL_U: /* Ctrl+u, delete the whole line. */
1032: 			buf[0] = '\0';
1033: 			l.pos = l.len = 0;
1034: 			refreshLine(&l);
1035: 			break;
1036: 		case CTRL_K: /* Ctrl+k, delete from current to end of line. */
1037: 			buf[l.pos] = '\0';
1038: 			l.len = l.pos;
1039: 			refreshLine(&l);
1040: 			break;
1041: 		case CTRL_A: /* Ctrl+a, go to the start of the line */
1042: 			linenoiseEditMoveHome(&l);
1043: 			break;
1044: 		case CTRL_E: /* ctrl+e, go to the end of the line */
1045: 			linenoiseEditMoveEnd(&l);
1046: 			break;
1047: 		case CTRL_L: /* ctrl+l, clear screen */
1048: 			linenoiseClearScreen();
1049: 			refreshLine(&l);
1050: 			break;
1051: 		case CTRL_W: /* ctrl+w, delete previous word */
1052: 			linenoiseEditDeletePrevWord(&l);
1053: 			break;
1054: 		}
1055: 	}
1056: 	return l.len;
1057: }
1058: 
1059: /* This special mode is used by linenoise in order to print scan codes
1060:  * on screen for debugging / development purposes. It is implemented
1061:  * by the linenoise_example program using the --keycodes option. */
1062: void linenoisePrintKeyCodes(void) {
1063: 	char quit[4];
1064: 
1065: 	printf("Linenoise key codes debugging mode.\n"
1066: 	       "Press keys to see scan codes. Type 'quit' at any time to exit.\n");
1067: 	if (enableRawMode(STDIN_FILENO) == -1)
1068: 		return;
1069: 	memset(quit, ' ', 4);
1070: 	while (1) {
1071: 		char c;
1072: 		int nread;
1073: 
1074: 		nread = read(STDIN_FILENO, &c, 1);
1075: 		if (nread <= 0)
1076: 			continue;
1077: 		memmove(quit, quit + 1, sizeof(quit) - 1); /* shift string to left. */
1078: 		quit[sizeof(quit) - 1] = c;                /* Insert current char on the right. */
1079: 		if (memcmp(quit, "quit", sizeof(quit)) == 0)
1080: 			break;
1081: 
1082: 		printf("'%c' %02x (%d) (type quit to exit)\n", isprint(c) ? c : '?', (int)c, (int)c);
1083: 		printf("\r"); /* Go left edge manually, we are in raw mode. */
1084: 		fflush(stdout);
1085: 	}
1086: 	disableRawMode(STDIN_FILENO);
1087: }
1088: 
1089: /* This function calls the line editing function linenoiseEdit() using
1090:  * the STDIN file descriptor set in raw mode. */
1091: static int linenoiseRaw(char *buf, size_t buflen, const char *prompt) {
1092: 	int count;
1093: 
1094: 	if (buflen == 0) {
1095: 		errno = EINVAL;
1096: 		return -1;
1097: 	}
1098: 
1099: 	if (enableRawMode(STDIN_FILENO) == -1)
1100: 		return -1;
1101: 	count = linenoiseEdit(STDIN_FILENO, STDOUT_FILENO, buf, buflen, prompt);
1102: 	disableRawMode(STDIN_FILENO);
1103: 	printf("\n");
1104: 	return count;
1105: }
1106: 
1107: /* This function is called when linenoise() is called with the standard
1108:  * input file descriptor not attached to a TTY. So for example when the
1109:  * program using linenoise is called in pipe or with a file redirected
1110:  * to its standard input. In this case, we want to be able to return the
1111:  * line regardless of its length (by default we are limited to 4k). */
1112: static char *linenoiseNoTTY(void) {
1113: 	char *line = NULL;
1114: 	size_t len = 0, maxlen = 0;
1115: 
1116: 	while (1) {
1117: 		if (len == maxlen) {
1118: 			if (maxlen == 0)
1119: 				maxlen = 16;
1120: 			maxlen *= 2;
1121: 			char *oldval = line;
1122: 			line = realloc(line, maxlen);
1123: 			if (line == NULL) {
1124: 				if (oldval)
1125: 					free(oldval);
1126: 				return NULL;
1127: 			}
1128: 		}
1129: 		int c = fgetc(stdin);
1130: 		if (c == EOF || c == '\n') {
1131: 			if (c == EOF && len == 0) {
1132: 				free(line);
1133: 				return NULL;
1134: 			} else {
1135: 				line[len] = '\0';
1136: 				return line;
1137: 			}
1138: 		} else {
1139: 			line[len] = c;
1140: 			len++;
1141: 		}
1142: 	}
1143: }
1144: 
1145: /* The high level function that is the main API of the linenoise library.
1146:  * This function checks if the terminal has basic capabilities, just checking
1147:  * for a blacklist of stupid terminals, and later either calls the line
1148:  * editing function or uses dummy fgets() so that you will be able to type
1149:  * something even in the most desperate of the conditions. */
1150: char *linenoise(const char *prompt) {
1151: 	char buf[LINENOISE_MAX_LINE];
1152: 	int count;
1153: 
1154: 	if (!isatty(STDIN_FILENO)) {
1155: 		/* Not a tty: read from file / pipe. In this mode we don't want any
1156: 		 * limit to the line size, so we call a function to handle that. */
1157: 		return linenoiseNoTTY();
1158: 	} else if (isUnsupportedTerm()) {
1159: 		size_t len;
1160: 
1161: 		printf("%s", prompt);
1162: 		fflush(stdout);
1163: 		if (fgets(buf, LINENOISE_MAX_LINE, stdin) == NULL)
1164: 			return NULL;
1165: 		len = strlen(buf);
1166: 		while (len && (buf[len - 1] == '\n' || buf[len - 1] == '\r')) {
1167: 			len--;
1168: 			buf[len] = '\0';
1169: 		}
1170: 		return strdup(buf);
1171: 	} else {
1172: 		count = linenoiseRaw(buf, LINENOISE_MAX_LINE, prompt);
1173: 		if (count == -1)
1174: 			return NULL;
1175: 		return strdup(buf);
1176: 	}
1177: }
1178: 
1179: /* This is just a wrapper the user may want to call in order to make sure
1180:  * the linenoise returned buffer is freed with the same allocator it was
1181:  * created with. Useful when the main program is using an alternative
1182:  * allocator. */
1183: void linenoiseFree(void *ptr) {
1184: 	free(ptr);
1185: }
1186: 
1187: /* ================================ History ================================= */
1188: 
1189: /* Free the history, but does not reset it. Only used when we have to
1190:  * exit() to avoid memory leaks are reported by valgrind & co. */
1191: static void freeHistory(void) {
1192: 	if (history) {
1193: 		int j;
1194: 
1195: 		for (j = 0; j < history_len; j++)
1196: 			free(history[j]);
1197: 		free(history);
1198: 	}
1199: }
1200: 
1201: /* At exit we'll try to fix the terminal to the initial conditions. */
1202: static void linenoiseAtExit(void) {
1203: 	disableRawMode(STDIN_FILENO);
1204: 	freeHistory();
1205: }
1206: 
1207: /* This is the API call to add a new entry in the linenoise history.
1208:  * It uses a fixed array of char pointers that are shifted (memmoved)
1209:  * when the history max length is reached in order to remove the older
1210:  * entry and make room for the new one, so it is not exactly suitable for huge
1211:  * histories, but will work well for a few hundred of entries.
1212:  *
1213:  * Using a circular buffer is smarter, but a bit more complex to handle. */
1214: int linenoiseHistoryAdd(const char *line) {
1215: 	char *linecopy;
1216: 
1217: 	if (history_max_len == 0)
1218: 		return 0;
1219: 
1220: 	/* Initialization on first call. */
1221: 	if (history == NULL) {
1222: 		history = malloc(sizeof(char *) * history_max_len);
1223: 		if (history == NULL)
1224: 			return 0;
1225: 		memset(history, 0, (sizeof(char *) * history_max_len));
1226: 	}
1227: 
1228: 	/* Don't add duplicated lines. */
1229: 	if (history_len && !strcmp(history[history_len - 1], line))
1230: 		return 0;
1231: 
1232: 	/* Add an heap allocated copy of the line in the history.
1233: 	 * If we reached the max length, remove the older line. */
1234: 	linecopy = strdup(line);
1235: 	if (!linecopy)
1236: 		return 0;
1237: 	if (history_len == history_max_len) {
1238: 		free(history[0]);
1239: 		memmove(history, history + 1, sizeof(char *) * (history_max_len - 1));
1240: 		history_len--;
1241: 	}
1242: 	history[history_len] = linecopy;
1243: 	history_len++;
1244: 	return 1;
1245: }
1246: 
1247: /* Set the maximum length for the history. This function can be called even
1248:  * if there is already some history, the function will make sure to retain
1249:  * just the latest 'len' elements if the new history length value is smaller
1250:  * than the amount of items already inside the history. */
1251: int linenoiseHistorySetMaxLen(int len) {
1252: 	char **new;
1253: 
1254: 	if (len < 1)
1255: 		return 0;
1256: 	if (history) {
1257: 		int tocopy = history_len;
1258: 
1259: 		new = malloc(sizeof(char *) * len);
1260: 		if (new == NULL)
1261: 			return 0;
1262: 
1263: 		/* If we can't copy everything, free the elements we'll not use. */
1264: 		if (len < tocopy) {
1265: 			int j;
1266: 
1267: 			for (j = 0; j < tocopy - len; j++)
1268: 				free(history[j]);
1269: 			tocopy = len;
1270: 		}
1271: 		memset(new, 0, sizeof(char *) * len);
1272: 		memcpy(new, history + (history_len - tocopy), sizeof(char *) * tocopy);
1273: 		free(history);
1274: 		history = new;
1275: 	}
1276: 	history_max_len = len;
1277: 	if (history_len > history_max_len)
1278: 		history_len = history_max_len;
1279: 	return 1;
1280: }
1281: 
1282: /* Save the history in the specified file. On success 0 is returned
1283:  * otherwise -1 is returned. */
1284: int linenoiseHistorySave(const char *filename) {
1285: 	mode_t old_umask = umask(S_IXUSR | S_IRWXG | S_IRWXO);
1286: 	FILE *fp;
1287: 	int j;
1288: 
1289: 	fp = fopen(filename, "w");
1290: 	umask(old_umask);
1291: 	if (fp == NULL)
1292: 		return -1;
1293: 	chmod(filename, S_IRUSR | S_IWUSR);
1294: 	for (j = 0; j < history_len; j++)
1295: 		fprintf(fp, "%s\n", history[j]);
1296: 	fclose(fp);
1297: 	return 0;
1298: }
1299: 
1300: /* Load the history from the specified file. If the file does not exist
1301:  * zero is returned and no operation is performed.
1302:  *
1303:  * If the file exists and the operation succeeded 0 is returned, otherwise
1304:  * on error -1 is returned. */
1305: int linenoiseHistoryLoad(const char *filename) {
1306: 	FILE *fp = fopen(filename, "r");
1307: 	char buf[LINENOISE_MAX_LINE];
1308: 
1309: 	if (fp == NULL)
1310: 		return -1;
1311: 
1312: 	while (fgets(buf, LINENOISE_MAX_LINE, fp) != NULL) {
1313: 		char *p;
1314: 
1315: 		p = strchr(buf, '\r');
1316: 		if (!p)
1317: 			p = strchr(buf, '\n');
1318: 		if (p)
1319: 			*p = '\0';
1320: 		linenoiseHistoryAdd(buf);
1321: 	}
1322: 	fclose(fp);
1323: 	return 0;
1324: }
[end of tools/shell/linenoise.c]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: