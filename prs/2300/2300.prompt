You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
JSON Profile Not Escaping Quotes Correctly
**What does happen?**
When the profiling option is enabled with JSON format, quotes in the JSON profile are not properly escaped.

**What should happen?**
Quotes should be properly escaped in JSON profile.

**To Reproduce**
See the key "extra-info" contains quotes not escaped correctly:

```
$ duckdb
v0.2.9 1776611
Enter ".help" for usage hints.
Connected to a transient in-memory database.
Use ".open FILENAME" to reopen on a persistent database.
D PRAGMA enable_profiling=json;
D CREATE TABLE "foo"("hello world" INT);
D SELECT "hello world" FROM "foo";
{
   "name":  "Query",
   "result": 0.000050,
   "timing": 0.000050,
   "cardinality": 0,
   "extra-info": "SELECT "hello world" FROM "foo";",
   "timings": [

   ],
   "children": [
    {
      "name": "SEQ_SCAN",
      "timing":0.000015,
      "cardinality":0,
      "extra_info": "foo\n[INFOSEPARATOR]\nhello world",
      "timings": [
      ],
      "children": [
      ]
    }
   ]
}
```

**Environment (please complete the following information):**
 - OS: [CentOS 7.x]
 - DuckDB Version [0.29]

**Before submitting**
- [X] Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?
- [ ] Have you tried this on the latest `master` branch? In case you cannot compile, you may find some binaries here: https://github.com/duckdb/duckdb/releases/tag/master-builds


</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
3: </div>
4: <p>&nbsp;</p>
5: 
6: <p align="center">
7:   <a href="https://github.com/duckdb/duckdb/actions">
8:     <img src="https://github.com/cwida/duckdb/workflows/.github/workflows/main.yml/badge.svg?branch=master" alt=".github/workflows/main.yml">
9:   </a>
10:   <a href="https://www.codefactor.io/repository/github/cwida/duckdb">
11:     <img src="https://www.codefactor.io/repository/github/cwida/duckdb/badge" alt="CodeFactor"/>
12:   </a>
13:   <a href="https://app.codecov.io/gh/duckdb/duckdb">
14:     <img src="https://codecov.io/gh/duckdb/duckdb/branch/master/graph/badge.svg?token=FaxjcfFghN" alt="codecov"/>
15:   </a>
16: </p>
17: 
18: ## DuckDB
19: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on the goals of DuckDB, please refer to [the Why DuckDB page on our website](https://duckdb.org/docs/why_duckdb.html).
20: 
21: ## Installation
22: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
23: 
24: ## Data Import
25: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
26: 
27: ```sql
28: SELECT * FROM 'myfile.csv';
29: SELECT * FROM 'myfile.parquet';
30: ```
31: 
32: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
33: 
34: ## SQL Reference
35: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
36: 
37: ## Development
38: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`.
39: 
40: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
41: 
42: 
[end of README.md]
[start of src/main/query_profiler.cpp]
1: #include "duckdb/main/query_profiler.hpp"
2: #include "duckdb/common/to_string.hpp"
3: #include "duckdb/common/fstream.hpp"
4: #include "duckdb/common/printer.hpp"
5: #include "duckdb/common/string_util.hpp"
6: #include "duckdb/execution/physical_operator.hpp"
7: #include "duckdb/execution/operator/join/physical_delim_join.hpp"
8: #include "duckdb/execution/operator/helper/physical_execute.hpp"
9: #include "duckdb/common/tree_renderer.hpp"
10: #include "duckdb/parser/sql_statement.hpp"
11: #include "duckdb/common/limits.hpp"
12: #include "duckdb/execution/expression_executor.hpp"
13: #include "duckdb/planner/expression/bound_function_expression.hpp"
14: #include <utility>
15: #include <algorithm>
16: 
17: namespace duckdb {
18: 
19: void QueryProfiler::StartQuery(string query) {
20: 	if (!enabled) {
21: 		return;
22: 	}
23: 	this->running = true;
24: 	this->query = move(query);
25: 	tree_map.clear();
26: 	root = nullptr;
27: 	phase_timings.clear();
28: 	phase_stack.clear();
29: 
30: 	main_query.Start();
31: }
32: 
33: bool QueryProfiler::OperatorRequiresProfiling(PhysicalOperatorType op_type) {
34: 	switch (op_type) {
35: 	case PhysicalOperatorType::ORDER_BY:
36: 	case PhysicalOperatorType::RESERVOIR_SAMPLE:
37: 	case PhysicalOperatorType::STREAMING_SAMPLE:
38: 	case PhysicalOperatorType::LIMIT:
39: 	case PhysicalOperatorType::TOP_N:
40: 	case PhysicalOperatorType::WINDOW:
41: 	case PhysicalOperatorType::UNNEST:
42: 	case PhysicalOperatorType::SIMPLE_AGGREGATE:
43: 	case PhysicalOperatorType::HASH_GROUP_BY:
44: 	case PhysicalOperatorType::FILTER:
45: 	case PhysicalOperatorType::PROJECTION:
46: 	case PhysicalOperatorType::COPY_TO_FILE:
47: 	case PhysicalOperatorType::TABLE_SCAN:
48: 	case PhysicalOperatorType::CHUNK_SCAN:
49: 	case PhysicalOperatorType::DELIM_SCAN:
50: 	case PhysicalOperatorType::EXPRESSION_SCAN:
51: 	case PhysicalOperatorType::BLOCKWISE_NL_JOIN:
52: 	case PhysicalOperatorType::NESTED_LOOP_JOIN:
53: 	case PhysicalOperatorType::HASH_JOIN:
54: 	case PhysicalOperatorType::CROSS_PRODUCT:
55: 	case PhysicalOperatorType::PIECEWISE_MERGE_JOIN:
56: 	case PhysicalOperatorType::DELIM_JOIN:
57: 	case PhysicalOperatorType::UNION:
58: 	case PhysicalOperatorType::RECURSIVE_CTE:
59: 	case PhysicalOperatorType::EMPTY_RESULT:
60: 		return true;
61: 	default:
62: 		return false;
63: 	}
64: }
65: 
66: void QueryProfiler::EndQuery() {
67: 	if (!enabled || !running) {
68: 		return;
69: 	}
70: 
71: 	main_query.End();
72: 	this->running = false;
73: 	// print or output the query profiling after termination, if this is enabled
74: 	if (automatic_print_format != ProfilerPrintFormat::NONE) {
75: 		// check if this query should be output based on the operator types
76: 		string query_info;
77: 		if (automatic_print_format == ProfilerPrintFormat::JSON) {
78: 			query_info = ToJSON();
79: 		} else if (automatic_print_format == ProfilerPrintFormat::QUERY_TREE) {
80: 			query_info = ToString();
81: 		} else if (automatic_print_format == ProfilerPrintFormat::QUERY_TREE_OPTIMIZER) {
82: 			query_info = ToString(true);
83: 		}
84: 
85: 		if (save_location.empty()) {
86: 			Printer::Print(query_info);
87: 			Printer::Print("\n");
88: 		} else {
89: 			WriteToFile(save_location.c_str(), query_info);
90: 		}
91: 	}
92: }
93: 
94: void QueryProfiler::StartPhase(string new_phase) {
95: 	if (!enabled || !running) {
96: 		return;
97: 	}
98: 
99: 	if (!phase_stack.empty()) {
100: 		// there are active phases
101: 		phase_profiler.End();
102: 		// add the timing to all phases prior to this one
103: 		string prefix = "";
104: 		for (auto &phase : phase_stack) {
105: 			phase_timings[phase] += phase_profiler.Elapsed();
106: 			prefix += phase + " > ";
107: 		}
108: 		// when there are previous phases, we prefix the current phase with those phases
109: 		new_phase = prefix + new_phase;
110: 	}
111: 
112: 	// start a new phase
113: 	phase_stack.push_back(new_phase);
114: 	// restart the timer
115: 	phase_profiler.Start();
116: }
117: 
118: void QueryProfiler::EndPhase() {
119: 	if (!enabled || !running) {
120: 		return;
121: 	}
122: 	D_ASSERT(phase_stack.size() > 0);
123: 
124: 	// end the timer
125: 	phase_profiler.End();
126: 	// add the timing to all currently active phases
127: 	for (auto &phase : phase_stack) {
128: 		phase_timings[phase] += phase_profiler.Elapsed();
129: 	}
130: 	// now remove the last added phase
131: 	phase_stack.pop_back();
132: 
133: 	if (!phase_stack.empty()) {
134: 		phase_profiler.Start();
135: 	}
136: }
137: 
138: void QueryProfiler::Initialize(PhysicalOperator *root_op) {
139: 	if (!enabled || !running) {
140: 		return;
141: 	}
142: 	this->query_requires_profiling = false;
143: 	this->root = CreateTree(root_op);
144: 	if (!query_requires_profiling) {
145: 		// query does not require profiling: disable profiling for this query
146: 		this->running = false;
147: 		tree_map.clear();
148: 		root = nullptr;
149: 		phase_timings.clear();
150: 		phase_stack.clear();
151: 	}
152: }
153: 
154: OperatorProfiler::OperatorProfiler(bool enabled_p) : enabled(enabled_p) {
155: 	execution_stack = std::stack<const PhysicalOperator *>();
156: }
157: 
158: void OperatorProfiler::StartOperator(const PhysicalOperator *phys_op) {
159: 	if (!enabled) {
160: 		return;
161: 	}
162: 
163: 	if (!execution_stack.empty()) {
164: 		// add timing for the previous element
165: 		op.End();
166: 
167: 		AddTiming(execution_stack.top(), op.Elapsed(), 0);
168: 	}
169: 
170: 	execution_stack.push(phys_op);
171: 
172: 	// start timing for current element
173: 	op.Start();
174: }
175: 
176: void OperatorProfiler::EndOperator(DataChunk *chunk) {
177: 	if (!enabled) {
178: 		return;
179: 	}
180: 
181: 	// finish timing for the current element
182: 	op.End();
183: 
184: 	AddTiming(execution_stack.top(), op.Elapsed(), chunk ? chunk->size() : 0);
185: 
186: 	D_ASSERT(!execution_stack.empty());
187: 	execution_stack.pop();
188: 
189: 	// start timing again for the previous element, if any
190: 	if (!execution_stack.empty()) {
191: 		op.Start();
192: 	}
193: }
194: 
195: void OperatorProfiler::AddTiming(const PhysicalOperator *op, double time, idx_t elements) {
196: 	if (!enabled) {
197: 		return;
198: 	}
199: 	if (!Value::DoubleIsValid(time)) {
200: 		return;
201: 	}
202: 	auto entry = timings.find(op);
203: 	if (entry == timings.end()) {
204: 		// add new entry
205: 		timings[op] = OperatorInformation(time, elements);
206: 	} else {
207: 		// add to existing entry
208: 		entry->second.time += time;
209: 		entry->second.elements += elements;
210: 	}
211: }
212: void OperatorProfiler::Flush(const PhysicalOperator *phys_op, ExpressionExecutor *expression_executor,
213:                              const string &name, int id) {
214: 	auto entry = timings.find(phys_op);
215: 	if (entry == timings.end()) {
216: 		return;
217: 	}
218: 	auto &operator_timing = timings.find(phys_op)->second;
219: 	if (int(operator_timing.executors_info.size()) <= id) {
220: 		operator_timing.executors_info.resize(id + 1);
221: 	}
222: 	operator_timing.executors_info[id] = make_unique<ExpressionExecutorInfo>(*expression_executor, name, id);
223: 	operator_timing.name = phys_op->GetName();
224: }
225: 
226: void QueryProfiler::Flush(OperatorProfiler &profiler) {
227: 	if (!enabled || !running) {
228: 		return;
229: 	}
230: 	lock_guard<mutex> guard(flush_lock);
231: 	for (auto &node : profiler.timings) {
232: 		auto entry = tree_map.find(node.first);
233: 		D_ASSERT(entry != tree_map.end());
234: 
235: 		entry->second->info.time += node.second.time;
236: 		entry->second->info.elements += node.second.elements;
237: 		if (!detailed_enabled) {
238: 			continue;
239: 		}
240: 		for (auto &info : node.second.executors_info) {
241: 			if (!info) {
242: 				continue;
243: 			}
244: 			auto info_id = info->id;
245: 			if (int(entry->second->info.executors_info.size()) <= info_id) {
246: 				entry->second->info.executors_info.resize(info_id + 1);
247: 			}
248: 			entry->second->info.executors_info[info_id] = move(info);
249: 		}
250: 	}
251: }
252: 
253: static string DrawPadded(const string &str, idx_t width) {
254: 	if (str.size() > width) {
255: 		return str.substr(0, width);
256: 	} else {
257: 		width -= str.size();
258: 		int half_spaces = width / 2;
259: 		int extra_left_space = width % 2 != 0 ? 1 : 0;
260: 		return string(half_spaces + extra_left_space, ' ') + str + string(half_spaces, ' ');
261: 	}
262: }
263: 
264: static string RenderTitleCase(string str) {
265: 	str = StringUtil::Lower(str);
266: 	str[0] = toupper(str[0]);
267: 	for (idx_t i = 0; i < str.size(); i++) {
268: 		if (str[i] == '_') {
269: 			str[i] = ' ';
270: 			if (i + 1 < str.size()) {
271: 				str[i + 1] = toupper(str[i + 1]);
272: 			}
273: 		}
274: 	}
275: 	return str;
276: }
277: 
278: static string RenderTiming(double timing) {
279: 	string timing_s;
280: 	if (timing >= 1) {
281: 		timing_s = StringUtil::Format("%.2f", timing);
282: 	} else if (timing >= 0.1) {
283: 		timing_s = StringUtil::Format("%.3f", timing);
284: 	} else {
285: 		timing_s = StringUtil::Format("%.4f", timing);
286: 	}
287: 	return timing_s + "s";
288: }
289: 
290: string QueryProfiler::ToString(bool print_optimizer_output) const {
291: 	std::stringstream str;
292: 	ToStream(str, print_optimizer_output);
293: 	return str.str();
294: }
295: 
296: void QueryProfiler::ToStream(std::ostream &ss, bool print_optimizer_output) const {
297: 	if (!enabled) {
298: 		ss << "Query profiling is disabled. Call "
299: 		      "Connection::EnableProfiling() to enable profiling!";
300: 		return;
301: 	}
302: 	ss << "┌─────────────────────────────────────┐\n";
303: 	ss << "│┌───────────────────────────────────┐│\n";
304: 	ss << "││    Query Profiling Information    ││\n";
305: 	ss << "│└───────────────────────────────────┘│\n";
306: 	ss << "└─────────────────────────────────────┘\n";
307: 	ss << StringUtil::Replace(query, "\n", " ") + "\n";
308: 	if (query.empty()) {
309: 		return;
310: 	}
311: 
312: 	constexpr idx_t TOTAL_BOX_WIDTH = 39;
313: 	ss << "┌─────────────────────────────────────┐\n";
314: 	ss << "│┌───────────────────────────────────┐│\n";
315: 	string total_time = "Total Time: " + RenderTiming(main_query.Elapsed());
316: 	ss << "││" + DrawPadded(total_time, TOTAL_BOX_WIDTH - 4) + "││\n";
317: 	ss << "│└───────────────────────────────────┘│\n";
318: 	ss << "└─────────────────────────────────────┘\n";
319: 	// print phase timings
320: 	if (print_optimizer_output) {
321: 		bool has_previous_phase = false;
322: 		for (const auto &entry : GetOrderedPhaseTimings()) {
323: 			if (!StringUtil::Contains(entry.first, " > ")) {
324: 				// primary phase!
325: 				if (has_previous_phase) {
326: 					ss << "│└───────────────────────────────────┘│\n";
327: 					ss << "└─────────────────────────────────────┘\n";
328: 				}
329: 				ss << "┌─────────────────────────────────────┐\n";
330: 				ss << "│" +
331: 				          DrawPadded(RenderTitleCase(entry.first) + ": " + RenderTiming(entry.second),
332: 				                     TOTAL_BOX_WIDTH - 2) +
333: 				          "│\n";
334: 				ss << "│┌───────────────────────────────────┐│\n";
335: 				has_previous_phase = true;
336: 			} else {
337: 				string entry_name = StringUtil::Split(entry.first, " > ")[1];
338: 				ss << "││" +
339: 				          DrawPadded(RenderTitleCase(entry_name) + ": " + RenderTiming(entry.second),
340: 				                     TOTAL_BOX_WIDTH - 4) +
341: 				          "││\n";
342: 			}
343: 		}
344: 		if (has_previous_phase) {
345: 			ss << "│└───────────────────────────────────┘│\n";
346: 			ss << "└─────────────────────────────────────┘\n";
347: 		}
348: 	}
349: 	// render the main operator tree
350: 	if (root) {
351: 		Render(*root, ss);
352: 	}
353: }
354: 
355: // Print a row
356: static void PrintRow(std::ostream &ss, const string &annotation, int id, const string &name, double time,
357:                      int sample_counter, int tuple_counter, string extra_info, int depth) {
358: 	ss << string(depth * 3, ' ') << " {\n";
359: 	ss << string(depth * 3, ' ') << "   \"annotation\": \"" + annotation + "\",\n";
360: 	ss << string(depth * 3, ' ') << "   \"id\": " + to_string(id) + ",\n";
361: 	ss << string(depth * 3, ' ') << "   \"name\": \"" + name + "\",\n";
362: #if defined(RDTSC)
363: 	ss << string(depth * 3, ' ') << "   \"timing\": \"NULL\" ,\n";
364: 	ss << string(depth * 3, ' ') << "   \"cycles_per_tuple\": " + StringUtil::Format("%.4f", time) + ",\n";
365: #else
366: 	ss << string(depth * 3, ' ') << "   \"timing\":" + to_string(time) + ",\n";
367: 	ss << string(depth * 3, ' ') << "   \"cycles_per_tuple\": \"NULL\" ,\n";
368: #endif
369: 	ss << string(depth * 3, ' ') << "   \"sample_size\": " << to_string(sample_counter) + ",\n";
370: 	ss << string(depth * 3, ' ') << "   \"input_size\": " << to_string(tuple_counter) + ",\n";
371: 	ss << string(depth * 3, ' ') << "   \"extra_info\": \""
372: 	   << StringUtil::Replace(std::move(extra_info), "\n", "\\n") + "\"\n";
373: 	ss << string(depth * 3, ' ') << " },\n";
374: }
375: 
376: static void ExtractFunctions(std::ostream &ss, ExpressionInfo &info, int &fun_id, int depth) {
377: 	if (info.hasfunction) {
378: 		D_ASSERT(info.sample_tuples_count != 0);
379: 		PrintRow(ss, "Function", fun_id++, info.function_name,
380: 		         int(info.function_time) / double(info.sample_tuples_count), info.sample_tuples_count,
381: 		         info.tuples_count, "", depth);
382: 	}
383: 	if (info.children.empty()) {
384: 		return;
385: 	}
386: 	// extract the children of this node
387: 	for (auto &child : info.children) {
388: 		ExtractFunctions(ss, *child, fun_id, depth);
389: 	}
390: }
391: 
392: static void ToJSONRecursive(QueryProfiler::TreeNode &node, std::ostream &ss, int depth = 1) {
393: 	ss << string(depth * 3, ' ') << " {\n";
394: 	ss << string(depth * 3, ' ') << "   \"name\": \"" + node.name + "\",\n";
395: 	ss << string(depth * 3, ' ') << "   \"timing\":" + to_string(node.info.time) + ",\n";
396: 	ss << string(depth * 3, ' ') << "   \"cardinality\":" + to_string(node.info.elements) + ",\n";
397: 	ss << string(depth * 3, ' ')
398: 	   << "   \"extra_info\": \"" + StringUtil::Replace(node.extra_info, "\n", "\\n") + "\",\n";
399: 	ss << string(depth * 3, ' ') << "   \"timings\": [";
400: 	int32_t function_counter = 1;
401: 	int32_t expression_counter = 1;
402: 	ss << "\n ";
403: 	for (auto &expr_executor : node.info.executors_info) {
404: 		// For each Expression tree
405: 		if (!expr_executor) {
406: 			continue;
407: 		}
408: 		for (auto &expr_timer : expr_executor->roots) {
409: 			D_ASSERT(expr_timer->sample_tuples_count != 0);
410: 			PrintRow(ss, "ExpressionRoot", expression_counter++, expr_timer->name,
411: 			         int(expr_timer->time) / double(expr_timer->sample_tuples_count), expr_timer->sample_tuples_count,
412: 			         expr_timer->tuples_count, expr_timer->extra_info, depth + 1);
413: 			// Extract all functions inside the tree
414: 			ExtractFunctions(ss, *expr_timer->root, function_counter, depth + 1);
415: 		}
416: 	}
417: 	ss.seekp(-2, ss.cur);
418: 	ss << "\n";
419: 	ss << string(depth * 3, ' ') << "   ],\n";
420: 	ss << string(depth * 3, ' ') << "   \"children\": [\n";
421: 	if (node.children.empty()) {
422: 		ss << string(depth * 3, ' ') << "   ]\n";
423: 	} else {
424: 		for (idx_t i = 0; i < node.children.size(); i++) {
425: 			if (i > 0) {
426: 				ss << ",\n";
427: 			}
428: 			ToJSONRecursive(*node.children[i], ss, depth + 1);
429: 		}
430: 		ss << string(depth * 3, ' ') << "   ]\n";
431: 	}
432: 	ss << string(depth * 3, ' ') << " }\n";
433: }
434: 
435: string QueryProfiler::ToJSON() const {
436: 	if (!enabled) {
437: 		return "{ \"result\": \"disabled\" }\n";
438: 	}
439: 	if (query.empty()) {
440: 		return "{ \"result\": \"empty\" }\n";
441: 	}
442: 	if (!root) {
443: 		return "{ \"result\": \"error\" }\n";
444: 	}
445: 	std::stringstream ss;
446: 	ss << "{\n";
447: 	ss << "   \"name\":  \"Query\", \n";
448: 	ss << "   \"result\": " + to_string(main_query.Elapsed()) + ",\n";
449: 	ss << "   \"timing\": " + to_string(main_query.Elapsed()) + ",\n";
450: 	ss << "   \"cardinality\": " + to_string(root->info.elements) + ",\n";
451: 	// JSON cannot have literal control characters in string literals
452: 	string extra_info = StringUtil::Replace(query, "\t", "\\t");
453: 	extra_info = StringUtil::Replace(extra_info, "\n", "\\n");
454: 	ss << "   \"extra-info\": \"" + extra_info + "\", \n";
455: 	// print the phase timings
456: 	ss << "   \"timings\": [\n";
457: 	const auto &ordered_phase_timings = GetOrderedPhaseTimings();
458: 	for (idx_t i = 0; i < ordered_phase_timings.size(); i++) {
459: 		if (i > 0) {
460: 			ss << ",\n";
461: 		}
462: 		ss << "   {\n";
463: 		ss << "   \"annotation\": \"" + ordered_phase_timings[i].first + "\", \n";
464: 		ss << "   \"timing\": " + to_string(ordered_phase_timings[i].second) + "\n";
465: 		ss << "   }";
466: 	}
467: 	ss << "\n";
468: 	ss << "   ],\n";
469: 	// recursively print the physical operator tree
470: 	ss << "   \"children\": [\n";
471: 	ToJSONRecursive(*root, ss);
472: 	ss << "   ]\n";
473: 	ss << "}";
474: 	return ss.str();
475: }
476: 
477: void QueryProfiler::WriteToFile(const char *path, string &info) const {
478: 	ofstream out(path);
479: 	out << info;
480: 	out.close();
481: 	// throw an IO exception if it fails to write the file
482: 	if (out.fail()) {
483: 		throw IOException(strerror(errno));
484: 	}
485: }
486: 
487: unique_ptr<QueryProfiler::TreeNode> QueryProfiler::CreateTree(PhysicalOperator *root, idx_t depth) {
488: 	if (OperatorRequiresProfiling(root->type)) {
489: 		this->query_requires_profiling = true;
490: 	}
491: 	auto node = make_unique<QueryProfiler::TreeNode>();
492: 	node->name = root->GetName();
493: 	node->extra_info = root->ParamsToString();
494: 	node->depth = depth;
495: 	tree_map[root] = node.get();
496: 	for (auto &child : root->children) {
497: 		auto child_node = CreateTree(child.get(), depth + 1);
498: 		node->children.push_back(move(child_node));
499: 	}
500: 	switch (root->type) {
501: 	case PhysicalOperatorType::DELIM_JOIN: {
502: 		auto &delim_join = (PhysicalDelimJoin &)*root;
503: 		auto child_node = CreateTree((PhysicalOperator *)delim_join.join.get(), depth + 1);
504: 		node->children.push_back(move(child_node));
505: 		child_node = CreateTree((PhysicalOperator *)delim_join.distinct.get(), depth + 1);
506: 		node->children.push_back(move(child_node));
507: 		break;
508: 	}
509: 	case PhysicalOperatorType::EXECUTE: {
510: 		auto &execute = (PhysicalExecute &)*root;
511: 		auto child_node = CreateTree((PhysicalOperator *)execute.plan, depth + 1);
512: 		node->children.push_back(move(child_node));
513: 		break;
514: 	}
515: 	default:
516: 		break;
517: 	}
518: 	return node;
519: }
520: 
521: void QueryProfiler::Render(const QueryProfiler::TreeNode &node, std::ostream &ss) const {
522: 	TreeRenderer renderer;
523: 	if (IsDetailedEnabled()) {
524: 		renderer.EnableDetailed();
525: 	} else {
526: 		renderer.EnableStandard();
527: 	}
528: 	renderer.Render(node, ss);
529: }
530: 
531: void QueryProfiler::Print() {
532: 	Printer::Print(ToString());
533: }
534: 
535: vector<QueryProfiler::PhaseTimingItem> QueryProfiler::GetOrderedPhaseTimings() const {
536: 	vector<PhaseTimingItem> result;
537: 	// first sort the phases alphabetically
538: 	vector<string> phases;
539: 	for (auto &entry : phase_timings) {
540: 		phases.push_back(entry.first);
541: 	}
542: 	std::sort(phases.begin(), phases.end());
543: 	for (const auto &phase : phases) {
544: 		auto entry = phase_timings.find(phase);
545: 		D_ASSERT(entry != phase_timings.end());
546: 		result.emplace_back(entry->first, entry->second);
547: 	}
548: 	return result;
549: }
550: void QueryProfiler::Propagate(QueryProfiler &qp) {
551: 	this->automatic_print_format = qp.automatic_print_format;
552: 	this->save_location = qp.save_location;
553: 	this->enabled = qp.enabled;
554: 	this->detailed_enabled = qp.detailed_enabled;
555: }
556: 
557: void ExpressionInfo::ExtractExpressionsRecursive(unique_ptr<ExpressionState> &state) {
558: 	if (state->child_states.empty()) {
559: 		return;
560: 	}
561: 	// extract the children of this node
562: 	for (auto &child : state->child_states) {
563: 		auto expr_info = make_unique<ExpressionInfo>();
564: 		if (child->expr.expression_class == ExpressionClass::BOUND_FUNCTION) {
565: 			expr_info->hasfunction = true;
566: 			expr_info->function_name = ((BoundFunctionExpression &)child->expr).function.ToString();
567: 			expr_info->function_time = child->profiler.time;
568: 			expr_info->sample_tuples_count = child->profiler.sample_tuples_count;
569: 			expr_info->tuples_count = child->profiler.tuples_count;
570: 		}
571: 		expr_info->ExtractExpressionsRecursive(child);
572: 		children.push_back(move(expr_info));
573: 	}
574: 	return;
575: }
576: 
577: ExpressionExecutorInfo::ExpressionExecutorInfo(ExpressionExecutor &executor, const string &name, int id) : id(id) {
578: 	// Extract Expression Root Information from ExpressionExecutorStats
579: 	for (auto &state : executor.GetStates()) {
580: 		roots.push_back(make_unique<ExpressionRootInfo>(*state, name));
581: 	}
582: }
583: 
584: ExpressionRootInfo::ExpressionRootInfo(ExpressionExecutorState &state, string name)
585:     : current_count(state.profiler.current_count), sample_count(state.profiler.sample_count),
586:       sample_tuples_count(state.profiler.sample_tuples_count), tuples_count(state.profiler.tuples_count),
587:       name(state.name), time(state.profiler.time) {
588: 	// Use the name of expression-tree as extra-info
589: 	extra_info = move(name);
590: 	auto expression_info_p = make_unique<ExpressionInfo>();
591: 	// Maybe root has a function
592: 	if (state.root_state->expr.expression_class == ExpressionClass::BOUND_FUNCTION) {
593: 		expression_info_p->hasfunction = true;
594: 		expression_info_p->function_name = ((BoundFunctionExpression &)state.root_state->expr).function.name;
595: 		expression_info_p->function_time = state.root_state->profiler.time;
596: 		expression_info_p->sample_tuples_count = state.root_state->profiler.sample_tuples_count;
597: 		expression_info_p->tuples_count = state.root_state->profiler.tuples_count;
598: 	}
599: 	expression_info_p->ExtractExpressionsRecursive(state.root_state);
600: 	root = move(expression_info_p);
601: }
602: } // namespace duckdb
[end of src/main/query_profiler.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: