{
  "repo": "duckdb/duckdb",
  "pull_number": 6118,
  "instance_id": "duckdb__duckdb-6118",
  "issue_numbers": [
    "6013"
  ],
  "base_commit": "5b9fd043c9794c8e4dcd84a0993fd302c9df54f9",
  "patch": "diff --git a/src/common/types/vector.cpp b/src/common/types/vector.cpp\nindex f4405f2a049c..d70416170622 100644\n--- a/src/common/types/vector.cpp\n+++ b/src/common/types/vector.cpp\n@@ -1322,6 +1322,7 @@ void ConstantVector::Reference(Vector &vector, Vector &source, idx_t position, i\n \t\t\tConstantVector::Reference(*target_entries[i], *source_entries[i], position, count);\n \t\t}\n \t\tvector.SetVectorType(VectorType::CONSTANT_VECTOR);\n+\t\tvector.validity.Set(0, true);\n \t\tbreak;\n \t}\n \tdefault:\ndiff --git a/src/execution/operator/projection/physical_unnest.cpp b/src/execution/operator/projection/physical_unnest.cpp\nindex 8b1bdbc135e9..951fd814a193 100644\n--- a/src/execution/operator/projection/physical_unnest.cpp\n+++ b/src/execution/operator/projection/physical_unnest.cpp\n@@ -11,7 +11,11 @@ namespace duckdb {\n class UnnestOperatorState : public OperatorState {\n public:\n \tUnnestOperatorState(ClientContext &context, const vector<unique_ptr<Expression>> &select_list)\n-\t    : parent_position(0), list_position(0), list_length(-1), first_fetch(true), executor(context) {\n+\t    : current_row(0), list_position(0), longest_list_length(DConstants::INVALID_INDEX), first_fetch(true),\n+\t      executor(context) {\n+\n+\t\t// for each UNNEST in the select_list, we add the child expression to the expression executor\n+\t\t// and set the return type in the list_data chunk, which will contain the evaluated expression results\n \t\tvector<LogicalType> list_data_types;\n \t\tfor (auto &exp : select_list) {\n \t\t\tD_ASSERT(exp->type == ExpressionType::BOUND_UNNEST);\n@@ -19,6 +23,7 @@ class UnnestOperatorState : public OperatorState {\n \t\t\tlist_data_types.push_back(bue->child->return_type);\n \t\t\texecutor.AddExpression(*bue->child.get());\n \t\t}\n+\n \t\tauto &allocator = Allocator::Get(context);\n \t\tlist_data.Initialize(allocator, list_data_types);\n \n@@ -26,18 +31,50 @@ class UnnestOperatorState : public OperatorState {\n \t\tlist_child_data.resize(list_data.ColumnCount());\n \t}\n \n-\tidx_t parent_position;\n+\tidx_t current_row;\n \tidx_t list_position;\n-\tint64_t list_length;\n+\tidx_t longest_list_length;\n \tbool first_fetch;\n \n \tExpressionExecutor executor;\n \tDataChunk list_data;\n \tvector<UnifiedVectorFormat> list_vector_data;\n \tvector<UnifiedVectorFormat> list_child_data;\n+\n+public:\n+\t//! Reset the fields of the unnest operator state\n+\tvoid Reset();\n+\t//! Set the longest list's length for the current row\n+\tvoid SetLongestListLength();\n };\n \n-// this implements a sorted window functions variant\n+void UnnestOperatorState::Reset() {\n+\tcurrent_row = 0;\n+\tlist_position = 0;\n+\tlongest_list_length = DConstants::INVALID_INDEX;\n+\tfirst_fetch = true;\n+}\n+\n+void UnnestOperatorState::SetLongestListLength() {\n+\n+\tlongest_list_length = 0;\n+\tfor (idx_t col_idx = 0; col_idx < list_data.ColumnCount(); col_idx++) {\n+\n+\t\tauto &vector_data = list_vector_data[col_idx];\n+\t\tauto current_idx = vector_data.sel->get_index(current_row);\n+\n+\t\tif (vector_data.validity.RowIsValid(current_idx)) {\n+\n+\t\t\t// check if this list is longer\n+\t\t\tauto list_data = (list_entry_t *)vector_data.data;\n+\t\t\tauto list_entry = list_data[current_idx];\n+\t\t\tif (list_entry.length > longest_list_length) {\n+\t\t\t\tlongest_list_length = list_entry.length;\n+\t\t\t}\n+\t\t}\n+\t}\n+}\n+\n PhysicalUnnest::PhysicalUnnest(vector<LogicalType> types, vector<unique_ptr<Expression>> select_list,\n                                idx_t estimated_cardinality, PhysicalOperatorType type)\n     : PhysicalOperator(type, std::move(types), estimated_cardinality), select_list(std::move(select_list)) {\n@@ -45,6 +82,8 @@ PhysicalUnnest::PhysicalUnnest(vector<LogicalType> types, vector<unique_ptr<Expr\n }\n \n static void UnnestNull(idx_t start, idx_t end, Vector &result) {\n+\n+\tD_ASSERT(result.GetVectorType() == VectorType::FLAT_VECTOR);\n \tauto &validity = FlatVector::Validity(result);\n \tfor (idx_t i = start; i < end; i++) {\n \t\tvalidity.SetInvalid(i);\n@@ -58,14 +97,17 @@ static void UnnestNull(idx_t start, idx_t end, Vector &result) {\n }\n \n template <class T>\n-static void TemplatedUnnest(UnifiedVectorFormat &vdata, idx_t start, idx_t end, Vector &result) {\n-\tauto source_data = (T *)vdata.data;\n-\tauto &source_mask = vdata.validity;\n+static void TemplatedUnnest(UnifiedVectorFormat &vector_data, idx_t start, idx_t end, Vector &result) {\n+\n+\tauto source_data = (T *)vector_data.data;\n+\tauto &source_mask = vector_data.validity;\n+\n+\tD_ASSERT(result.GetVectorType() == VectorType::FLAT_VECTOR);\n \tauto result_data = FlatVector::GetData<T>(result);\n \tauto &result_mask = FlatVector::Validity(result);\n \n \tfor (idx_t i = start; i < end; i++) {\n-\t\tauto source_idx = vdata.sel->get_index(i);\n+\t\tauto source_idx = vector_data.sel->get_index(i);\n \t\tauto target_idx = i - start;\n \t\tif (source_mask.RowIsValid(source_idx)) {\n \t\t\tresult_data[target_idx] = source_data[source_idx];\n@@ -76,84 +118,131 @@ static void TemplatedUnnest(UnifiedVectorFormat &vdata, idx_t start, idx_t end,\n \t}\n }\n \n-static void UnnestValidity(UnifiedVectorFormat &vdata, idx_t start, idx_t end, Vector &result) {\n-\tauto &source_mask = vdata.validity;\n+static void UnnestValidity(UnifiedVectorFormat &vector_data, idx_t start, idx_t end, Vector &result) {\n+\n+\tauto &source_mask = vector_data.validity;\n+\tD_ASSERT(result.GetVectorType() == VectorType::FLAT_VECTOR);\n \tauto &result_mask = FlatVector::Validity(result);\n \n \tfor (idx_t i = start; i < end; i++) {\n-\t\tauto source_idx = vdata.sel->get_index(i);\n+\t\tauto source_idx = vector_data.sel->get_index(i);\n \t\tauto target_idx = i - start;\n \t\tresult_mask.Set(target_idx, source_mask.RowIsValid(source_idx));\n \t}\n }\n \n-static void UnnestVector(UnifiedVectorFormat &vdata, Vector &source, idx_t list_size, idx_t start, idx_t end,\n-                         Vector &result) {\n-\tD_ASSERT(source.GetType() == result.GetType());\n+static void UnnestVector(UnifiedVectorFormat &child_vector_data, Vector &child_vector, idx_t list_size, idx_t start,\n+                         idx_t end, Vector &result) {\n+\n+\tD_ASSERT(child_vector.GetType() == result.GetType());\n \tswitch (result.GetType().InternalType()) {\n \tcase PhysicalType::BOOL:\n \tcase PhysicalType::INT8:\n-\t\tTemplatedUnnest<int8_t>(vdata, start, end, result);\n+\t\tTemplatedUnnest<int8_t>(child_vector_data, start, end, result);\n \t\tbreak;\n \tcase PhysicalType::INT16:\n-\t\tTemplatedUnnest<int16_t>(vdata, start, end, result);\n+\t\tTemplatedUnnest<int16_t>(child_vector_data, start, end, result);\n \t\tbreak;\n \tcase PhysicalType::INT32:\n-\t\tTemplatedUnnest<int32_t>(vdata, start, end, result);\n+\t\tTemplatedUnnest<int32_t>(child_vector_data, start, end, result);\n \t\tbreak;\n \tcase PhysicalType::INT64:\n-\t\tTemplatedUnnest<int64_t>(vdata, start, end, result);\n+\t\tTemplatedUnnest<int64_t>(child_vector_data, start, end, result);\n \t\tbreak;\n \tcase PhysicalType::INT128:\n-\t\tTemplatedUnnest<hugeint_t>(vdata, start, end, result);\n+\t\tTemplatedUnnest<hugeint_t>(child_vector_data, start, end, result);\n \t\tbreak;\n \tcase PhysicalType::UINT8:\n-\t\tTemplatedUnnest<uint8_t>(vdata, start, end, result);\n+\t\tTemplatedUnnest<uint8_t>(child_vector_data, start, end, result);\n \t\tbreak;\n \tcase PhysicalType::UINT16:\n-\t\tTemplatedUnnest<uint16_t>(vdata, start, end, result);\n+\t\tTemplatedUnnest<uint16_t>(child_vector_data, start, end, result);\n \t\tbreak;\n \tcase PhysicalType::UINT32:\n-\t\tTemplatedUnnest<uint32_t>(vdata, start, end, result);\n+\t\tTemplatedUnnest<uint32_t>(child_vector_data, start, end, result);\n \t\tbreak;\n \tcase PhysicalType::UINT64:\n-\t\tTemplatedUnnest<uint64_t>(vdata, start, end, result);\n+\t\tTemplatedUnnest<uint64_t>(child_vector_data, start, end, result);\n \t\tbreak;\n \tcase PhysicalType::FLOAT:\n-\t\tTemplatedUnnest<float>(vdata, start, end, result);\n+\t\tTemplatedUnnest<float>(child_vector_data, start, end, result);\n \t\tbreak;\n \tcase PhysicalType::DOUBLE:\n-\t\tTemplatedUnnest<double>(vdata, start, end, result);\n+\t\tTemplatedUnnest<double>(child_vector_data, start, end, result);\n \t\tbreak;\n \tcase PhysicalType::INTERVAL:\n-\t\tTemplatedUnnest<interval_t>(vdata, start, end, result);\n+\t\tTemplatedUnnest<interval_t>(child_vector_data, start, end, result);\n \t\tbreak;\n \tcase PhysicalType::VARCHAR:\n-\t\tTemplatedUnnest<string_t>(vdata, start, end, result);\n+\t\tTemplatedUnnest<string_t>(child_vector_data, start, end, result);\n \t\tbreak;\n \tcase PhysicalType::LIST: {\n+\t\t// the child vector of result now references the child vector source\n+\t\t// FIXME: only reference relevant children (start - end) instead of all\n \t\tauto &target = ListVector::GetEntry(result);\n-\t\ttarget.Reference(ListVector::GetEntry(source));\n-\t\tListVector::SetListSize(result, ListVector::GetListSize(source));\n-\t\tTemplatedUnnest<list_entry_t>(vdata, start, end, result);\n+\t\ttarget.Reference(ListVector::GetEntry(child_vector));\n+\t\tListVector::SetListSize(result, ListVector::GetListSize(child_vector));\n+\t\t// unnest\n+\t\tTemplatedUnnest<list_entry_t>(child_vector_data, start, end, result);\n \t\tbreak;\n \t}\n \tcase PhysicalType::STRUCT: {\n-\t\tauto &source_entries = StructVector::GetEntries(source);\n-\t\tauto &target_entries = StructVector::GetEntries(result);\n-\t\tUnnestValidity(vdata, start, end, result);\n-\t\tfor (idx_t i = 0; i < source_entries.size(); i++) {\n-\t\t\tUnifiedVectorFormat sdata;\n-\t\t\tsource_entries[i]->ToUnifiedFormat(list_size, sdata);\n-\t\t\tUnnestVector(sdata, *source_entries[i], list_size, start, end, *target_entries[i]);\n+\t\tauto &child_vector_entries = StructVector::GetEntries(child_vector);\n+\t\tauto &result_entries = StructVector::GetEntries(result);\n+\n+\t\t// set the validity mask for the 'outer' struct vector before unnesting its children\n+\t\tUnnestValidity(child_vector_data, start, end, result);\n+\n+\t\tfor (idx_t i = 0; i < child_vector_entries.size(); i++) {\n+\t\t\tUnifiedVectorFormat child_vector_entries_data;\n+\t\t\tchild_vector_entries[i]->ToUnifiedFormat(list_size, child_vector_entries_data);\n+\t\t\tUnnestVector(child_vector_entries_data, *child_vector_entries[i], list_size, start, end,\n+\t\t\t             *result_entries[i]);\n \t\t}\n \t\tbreak;\n \t}\n \tdefault:\n-\t\tthrow InternalException(\"Unimplemented type for UNNEST\");\n+\t\tthrow InternalException(\"Unimplemented type for UNNEST.\");\n \t}\n }\n \n+static void PrepareInput(UnnestOperatorState &state, DataChunk &input,\n+                         const vector<unique_ptr<Expression>> &select_list) {\n+\n+\tstate.list_data.Reset();\n+\t// execute the expressions inside each UNNEST in the select_list to get the list data\n+\t// execution results (lists) are kept in state.list_data chunk\n+\tstate.executor.Execute(input, state.list_data);\n+\n+\t// verify incoming lists\n+\tstate.list_data.Verify();\n+\tD_ASSERT(input.size() == state.list_data.size());\n+\tD_ASSERT(state.list_data.ColumnCount() == select_list.size());\n+\tD_ASSERT(state.list_vector_data.size() == state.list_data.ColumnCount());\n+\tD_ASSERT(state.list_child_data.size() == state.list_data.ColumnCount());\n+\n+\t// get the UnifiedVectorFormat of each list_data vector (LIST vectors for the different UNNESTs)\n+\t// both for the vector itself and its child vector\n+\tfor (idx_t col_idx = 0; col_idx < state.list_data.ColumnCount(); col_idx++) {\n+\n+\t\tauto &list_vector = state.list_data.data[col_idx];\n+\t\tlist_vector.ToUnifiedFormat(state.list_data.size(), state.list_vector_data[col_idx]);\n+\n+\t\tif (list_vector.GetType() == LogicalType::SQLNULL) {\n+\t\t\t// UNNEST(NULL): SQLNULL vectors don't have child vectors, but we need to point to the child vector of\n+\t\t\t// each vector, so we just get the UnifiedVectorFormat of the vector itself\n+\t\t\tauto &child_vector = list_vector;\n+\t\t\tchild_vector.ToUnifiedFormat(0, state.list_child_data[col_idx]);\n+\t\t} else {\n+\t\t\tauto list_size = ListVector::GetListSize(list_vector);\n+\t\t\tauto &child_vector = ListVector::GetEntry(list_vector);\n+\t\t\tchild_vector.ToUnifiedFormat(list_size, state.list_child_data[col_idx]);\n+\t\t}\n+\t}\n+\n+\tstate.first_fetch = false;\n+}\n+\n unique_ptr<OperatorState> PhysicalUnnest::GetOperatorState(ExecutionContext &context) const {\n \treturn PhysicalUnnest::GetState(context, select_list);\n }\n@@ -167,137 +256,107 @@ OperatorResultType PhysicalUnnest::ExecuteInternal(ExecutionContext &context, Da\n                                                    OperatorState &state_p,\n                                                    const vector<unique_ptr<Expression>> &select_list,\n                                                    bool include_input) {\n+\n \tauto &state = (UnnestOperatorState &)state_p;\n+\n \tdo {\n+\t\t// prepare the input data by executing any expressions and getting the\n+\t\t// UnifiedVectorFormat of each LIST vector (list_vector_data) and its child vector (list_child_data)\n \t\tif (state.first_fetch) {\n-\t\t\t// get the list data to unnest\n-\t\t\tstate.list_data.Reset();\n-\t\t\tstate.executor.Execute(input, state.list_data);\n-\n-\t\t\t// paranoia aplenty\n-\t\t\tstate.list_data.Verify();\n-\t\t\tD_ASSERT(input.size() == state.list_data.size());\n-\t\t\tD_ASSERT(state.list_data.ColumnCount() == select_list.size());\n-\t\t\tD_ASSERT(state.list_vector_data.size() == state.list_data.ColumnCount());\n-\t\t\tD_ASSERT(state.list_child_data.size() == state.list_data.ColumnCount());\n-\n-\t\t\t// initialize UnifiedVectorFormat object so the nullmask can accessed\n-\t\t\tfor (idx_t col_idx = 0; col_idx < state.list_data.ColumnCount(); col_idx++) {\n-\t\t\t\tauto &list_vector = state.list_data.data[col_idx];\n-\t\t\t\tlist_vector.ToUnifiedFormat(state.list_data.size(), state.list_vector_data[col_idx]);\n-\n-\t\t\t\tif (list_vector.GetType() == LogicalType::SQLNULL) {\n-\t\t\t\t\t// UNNEST(NULL)\n-\t\t\t\t\tauto &child_vector = list_vector;\n-\t\t\t\t\tchild_vector.ToUnifiedFormat(0, state.list_child_data[col_idx]);\n-\t\t\t\t} else {\n-\t\t\t\t\tauto list_size = ListVector::GetListSize(list_vector);\n-\t\t\t\t\tauto &child_vector = ListVector::GetEntry(list_vector);\n-\t\t\t\t\tchild_vector.ToUnifiedFormat(list_size, state.list_child_data[col_idx]);\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tstate.first_fetch = false;\n+\t\t\tPrepareInput(state, input, select_list);\n \t\t}\n-\t\tif (state.parent_position >= input.size()) {\n-\t\t\t// finished with this input chunk\n-\t\t\tstate.parent_position = 0;\n-\t\t\tstate.list_position = 0;\n-\t\t\tstate.list_length = -1;\n-\t\t\tstate.first_fetch = true;\n+\n+\t\t// finished with all rows of this input chunk, reset\n+\t\tif (state.current_row >= input.size()) {\n+\t\t\tstate.Reset();\n \t\t\treturn OperatorResultType::NEED_MORE_INPUT;\n \t\t}\n \n-\t\t// need to figure out how many times we need to repeat for current row\n-\t\tif (state.list_length < 0) {\n-\t\t\tfor (idx_t col_idx = 0; col_idx < state.list_data.ColumnCount(); col_idx++) {\n-\t\t\t\tauto &vdata = state.list_vector_data[col_idx];\n-\t\t\t\tauto current_idx = vdata.sel->get_index(state.parent_position);\n-\n-\t\t\t\tint64_t list_length;\n-\t\t\t\t// deal with NULL values\n-\t\t\t\tif (!vdata.validity.RowIsValid(current_idx)) {\n-\t\t\t\t\tlist_length = 0;\n-\t\t\t\t} else {\n-\t\t\t\t\tauto list_data = (list_entry_t *)vdata.data;\n-\t\t\t\t\tauto list_entry = list_data[current_idx];\n-\t\t\t\t\tlist_length = (int64_t)list_entry.length;\n-\t\t\t\t}\n-\n-\t\t\t\tif (list_length > state.list_length) {\n-\t\t\t\t\tstate.list_length = list_length;\n-\t\t\t\t}\n-\t\t\t}\n+\t\t// each UNNEST in the select_list contains a list (or NULL) for this row, find longest list\n+\t\t// because this length determines how many times we need to repeat for the current row\n+\t\tif (state.longest_list_length == DConstants::INVALID_INDEX) {\n+\t\t\tstate.SetLongestListLength();\n \t\t}\n+\t\tD_ASSERT(state.longest_list_length != DConstants::INVALID_INDEX);\n \n-\t\tD_ASSERT(state.list_length >= 0);\n-\n-\t\tauto this_chunk_len = MinValue<idx_t>(STANDARD_VECTOR_SIZE, state.list_length - state.list_position);\n-\n-\t\t// first cols are from child, last n cols from unnest\n+\t\t// we emit chunks of either STANDARD_VECTOR_SIZE or smaller\n+\t\tauto this_chunk_len = MinValue<idx_t>(STANDARD_VECTOR_SIZE, state.longest_list_length - state.list_position);\n \t\tchunk.SetCardinality(this_chunk_len);\n \n-\t\tidx_t output_offset = 0;\n+\t\t// if we include other projection input columns, e.g. SELECT 1, UNNEST([1, 2]);, then\n+\t\t// we need to add them as a constant vector to the resulting chunk\n+\t\t// FIXME: emit multiple unnested rows. Currently, we never emit a chunk containing multiple unnested input rows,\n+\t\t//  so setting a constant vector for the value at state.current_row is fine\n+\t\tidx_t col_offset = 0;\n \t\tif (include_input) {\n \t\t\tfor (idx_t col_idx = 0; col_idx < input.ColumnCount(); col_idx++) {\n-\t\t\t\tConstantVector::Reference(chunk.data[col_idx], input.data[col_idx], state.parent_position,\n-\t\t\t\t                          input.size());\n+\t\t\t\tConstantVector::Reference(chunk.data[col_idx], input.data[col_idx], state.current_row, input.size());\n \t\t\t}\n-\t\t\toutput_offset = input.ColumnCount();\n+\t\t\tcol_offset = input.ColumnCount();\n \t\t}\n \n+\t\t// unnest the lists\n \t\tfor (idx_t col_idx = 0; col_idx < state.list_data.ColumnCount(); col_idx++) {\n-\t\t\tauto &result_vector = chunk.data[col_idx + output_offset];\n+\n+\t\t\tauto &result_vector = chunk.data[col_idx + col_offset];\n \n \t\t\tif (state.list_data.data[col_idx].GetType() == LogicalType::SQLNULL) {\n \t\t\t\t// UNNEST(NULL)\n \t\t\t\tchunk.SetCardinality(0);\n+\t\t\t\tbreak;\n+\n \t\t\t} else {\n-\t\t\t\tauto &vdata = state.list_vector_data[col_idx];\n-\t\t\t\tauto &child_data = state.list_child_data[col_idx];\n-\t\t\t\tauto current_idx = vdata.sel->get_index(state.parent_position);\n \n-\t\t\t\tauto list_data = (list_entry_t *)vdata.data;\n-\t\t\t\tauto list_entry = list_data[current_idx];\n+\t\t\t\tauto &vector_data = state.list_vector_data[col_idx];\n+\t\t\t\tauto current_idx = vector_data.sel->get_index(state.current_row);\n+\n+\t\t\t\tif (!vector_data.validity.RowIsValid(current_idx)) {\n+\t\t\t\t\tUnnestNull(0, this_chunk_len, result_vector);\n \n-\t\t\t\tidx_t list_count;\n-\t\t\t\tif (state.list_position >= list_entry.length) {\n-\t\t\t\t\tlist_count = 0;\n \t\t\t\t} else {\n-\t\t\t\t\tlist_count = MinValue<idx_t>(this_chunk_len, list_entry.length - state.list_position);\n-\t\t\t\t}\n \n-\t\t\t\tif (list_entry.length > state.list_position) {\n-\t\t\t\t\tif (!vdata.validity.RowIsValid(current_idx)) {\n-\t\t\t\t\t\tUnnestNull(0, list_count, result_vector);\n-\t\t\t\t\t} else {\n+\t\t\t\t\tauto list_data = (list_entry_t *)vector_data.data;\n+\t\t\t\t\tauto list_entry = list_data[current_idx];\n+\n+\t\t\t\t\tidx_t list_count = 0;\n+\t\t\t\t\tif (state.list_position < list_entry.length) {\n+\t\t\t\t\t\t// there are still list_count elements to unnest\n+\t\t\t\t\t\tlist_count = MinValue<idx_t>(this_chunk_len, list_entry.length - state.list_position);\n+\n \t\t\t\t\t\tauto &list_vector = state.list_data.data[col_idx];\n \t\t\t\t\t\tauto &child_vector = ListVector::GetEntry(list_vector);\n \t\t\t\t\t\tauto list_size = ListVector::GetListSize(list_vector);\n+\t\t\t\t\t\tauto &child_vector_data = state.list_child_data[col_idx];\n \n \t\t\t\t\t\tauto base_offset = list_entry.offset + state.list_position;\n-\t\t\t\t\t\tUnnestVector(child_data, child_vector, list_size, base_offset, base_offset + list_count,\n+\t\t\t\t\t\tUnnestVector(child_vector_data, child_vector, list_size, base_offset, base_offset + list_count,\n \t\t\t\t\t\t             result_vector);\n \t\t\t\t\t}\n-\t\t\t\t}\n \n-\t\t\t\tUnnestNull(list_count, this_chunk_len, result_vector);\n+\t\t\t\t\t// fill the rest with NULLs\n+\t\t\t\t\tif (list_count != this_chunk_len) {\n+\t\t\t\t\t\tUnnestNull(list_count, this_chunk_len, result_vector);\n+\t\t\t\t\t}\n+\t\t\t\t}\n \t\t\t}\n \t\t}\n \n+\t\tchunk.Verify();\n+\n \t\tstate.list_position += this_chunk_len;\n-\t\tif ((int64_t)state.list_position == state.list_length) {\n-\t\t\tstate.parent_position++;\n-\t\t\tstate.list_length = -1;\n+\t\tif (state.list_position == state.longest_list_length) {\n+\t\t\tstate.current_row++;\n+\t\t\tstate.longest_list_length = DConstants::INVALID_INDEX;\n \t\t\tstate.list_position = 0;\n \t\t}\n \n-\t\tchunk.Verify();\n+\t\t// we only emit one unnested row (that contains data) at a time\n \t} while (chunk.size() == 0);\n \treturn OperatorResultType::HAVE_MORE_OUTPUT;\n }\n \n OperatorResultType PhysicalUnnest::Execute(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n-                                           GlobalOperatorState &gstate, OperatorState &state) const {\n+                                           GlobalOperatorState &, OperatorState &state) const {\n \treturn ExecuteInternal(context, input, chunk, state, select_list);\n }\n \ndiff --git a/src/include/duckdb/execution/operator/projection/physical_unnest.hpp b/src/include/duckdb/execution/operator/projection/physical_unnest.hpp\nindex f7ae86e0755f..9a57c3a4d036 100644\n--- a/src/include/duckdb/execution/operator/projection/physical_unnest.hpp\n+++ b/src/include/duckdb/execution/operator/projection/physical_unnest.hpp\n@@ -14,13 +14,14 @@\n \n namespace duckdb {\n \n-//! PhysicalWindow implements window functions\n+//! PhysicalUnnest implements the physical UNNEST operation\n class PhysicalUnnest : public PhysicalOperator {\n public:\n \tPhysicalUnnest(vector<LogicalType> types, vector<unique_ptr<Expression>> select_list, idx_t estimated_cardinality,\n \t               PhysicalOperatorType type = PhysicalOperatorType::UNNEST);\n \n \t//! The projection list of the UNNEST\n+\t//! E.g. SELECT 1, UNNEST([1]), UNNEST([2, 3]); has two UNNESTs in its select_list\n \tvector<unique_ptr<Expression>> select_list;\n \n public:\n@@ -35,6 +36,9 @@ class PhysicalUnnest : public PhysicalOperator {\n public:\n \tstatic unique_ptr<OperatorState> GetState(ExecutionContext &context,\n \t                                          const vector<unique_ptr<Expression>> &select_list);\n+\t//! Executes the UNNEST operator internally and emits a chunk of unnested data. If include_input is set, then\n+\t//! the resulting chunk also contains vectors for all non-UNNEST columns in the projection. If include_input is\n+\t//! not set, then the UNNEST behaves as a table function and only emits the unnested data.\n \tstatic OperatorResultType ExecuteInternal(ExecutionContext &context, DataChunk &input, DataChunk &chunk,\n \t                                          OperatorState &state, const vector<unique_ptr<Expression>> &select_list,\n \t                                          bool include_input = true);\n",
  "test_patch": "diff --git a/data/parquet-testing/issue_6013.parquet b/data/parquet-testing/issue_6013.parquet\nnew file mode 100644\nindex 000000000000..845043e17165\nBinary files /dev/null and b/data/parquet-testing/issue_6013.parquet differ\ndiff --git a/test/sql/types/list/const_struct_null_bug.test_slow b/test/sql/types/list/const_struct_null_bug.test_slow\nnew file mode 100644\nindex 000000000000..c182e7a8cd70\n--- /dev/null\n+++ b/test/sql/types/list/const_struct_null_bug.test_slow\n@@ -0,0 +1,19 @@\n+# name: test/sql/types/list/const_struct_null_bug.test_slow\n+# description: Test that the validity mask of structs within structs is set correctly when referencing constant vectors\n+# group: [list]\n+\n+require parquet\n+\n+# this issue #6013\n+# I could not reproduce the assertion with a smaller data set\n+query III\n+SELECT hits_0.access.page.\"pageTitle\" as \"pageTitle\",\n+COUNT(DISTINCT CONCAT(ga_sessions.\"__distinct_key\", 'x', hits_0.__row_id)) as \"hits_count\",\n+COUNT(DISTINCT CASE WHEN product_0.access.\"productQuantity\">0 THEN CONCAT(ga_sessions.\"__distinct_key\", 'x', hits_0.\"__row_id\") END) as \"sold_count\"\n+FROM (SELECT GEN_RANDOM_UUID() as __distinct_key, * FROM 'data/parquet-testing/issue_6013.parquet' as x) as ga_sessions,\n+(SELECT GEN_RANDOM_UUID() as __row_id, x.access FROM (SELECT UNNEST(ga_sessions.hits)) as x(access)) as hits_0,\n+(SELECT GEN_RANDOM_UUID() as __row_id, x.access FROM (SELECT UNNEST(hits_0.access.product)) as x(access)) as product_0\n+GROUP BY 1 LIMIT 2;\n+----\n+Electronics | Google Merchandise Store\t15\t0\n+Men's Outerwear | Apparel | Google Merchandise Store\t6\t0\n\\ No newline at end of file\n",
  "problem_statement": "Internal Assertion in Debug: Child of const null struct vector not null\n### What happens?\n\nInternal Assertion in Debug mode. Found this while working on the unnest rewriter. I don't have a smaller query yet. Data is a smaller subset of the data in issue #5827.\r\n\r\n```\r\nError: INTERNAL Error: Assertion triggered in file \"/Users/tania/DuckDB/duckdb/src/common/types/vector.cpp\" on line 1144: ConstantVector::IsNull(*children[child_idx])\r\n```\n\n### To Reproduce\n\n`make debug`\r\nDownload this file: [ga_sample_small.parquet.zip](https://github.com/duckdb/duckdb/files/10518562/ga_sample_small.parquet.zip)\r\n\r\n```sql\r\nSELECT hits_0.access.page.\"pageTitle\" as \"pageTitle\",\r\nCOUNT(DISTINCT CONCAT(ga_sessions.\"__distinct_key\", 'x', hits_0.__row_id)) as \"hits_count\",\r\nCOUNT(DISTINCT CASE WHEN product_0.access.\"productQuantity\">0 THEN CONCAT(ga_sessions.\"__distinct_key\", 'x', hits_0.\"__row_id\") END) as \"sold_count\"\r\nFROM (SELECT GEN_RANDOM_UUID() as __distinct_key, * FROM 'data/parquet-testing/ga_sample.parquet' as x) as ga_sessions,\r\n(SELECT GEN_RANDOM_UUID() as __row_id, x.access FROM (SELECT UNNEST(ga_sessions.hits)) as x(access)) as hits_0,\r\n(SELECT GEN_RANDOM_UUID() as __row_id, x.access FROM (SELECT UNNEST(hits_0.access.product)) as x(access)) as product_0\r\nGROUP BY 1 LIMIT 2;\r\n```\r\n\r\n\n\n### OS:\n\niOS\n\n### DuckDB Version:\n\nmaster\n\n### DuckDB Client:\n\nCLI\n\n### Full Name:\n\nTania Bogatsch\n\n### Affiliation:\n\nDuckDB Labs\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\n",
  "hints_text": "Ah somewhere the children of the struct aren't set to NULL, even though the struct entry itself is NULL",
  "created_at": "2023-02-07T09:46:31Z"
}