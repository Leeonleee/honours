diff --git a/src/execution/physical_plan/plan_delim_join.cpp b/src/execution/physical_plan/plan_delim_join.cpp
index 27a9de5e65b6..02424b0b125d 100644
--- a/src/execution/physical_plan/plan_delim_join.cpp
+++ b/src/execution/physical_plan/plan_delim_join.cpp
@@ -49,8 +49,9 @@ PhysicalOperator &PhysicalPlanGenerator::PlanDelimJoin(LogicalComparisonJoin &op
 	}
 
 	// we still have to create the DISTINCT clause that is used to generate the duplicate eliminated chunk
-	auto &distinct = Make<PhysicalHashAggregate>(context, delim_types, std::move(distinct_expressions),
-	                                             std::move(distinct_groups), op.estimated_cardinality);
+	auto &distinct =
+	    Make<PhysicalHashAggregate>(context, delim_types, std::move(distinct_expressions), std::move(distinct_groups),
+	                                delim_scans[0].get().estimated_cardinality);
 
 	// Create the duplicate eliminated join.
 	if (op.delim_flipped) {
diff --git a/src/include/duckdb/optimizer/join_order/cardinality_estimator.hpp b/src/include/duckdb/optimizer/join_order/cardinality_estimator.hpp
index 8aec1cd02c46..5390357102b2 100644
--- a/src/include/duckdb/optimizer/join_order/cardinality_estimator.hpp
+++ b/src/include/duckdb/optimizer/join_order/cardinality_estimator.hpp
@@ -88,7 +88,6 @@ class CardinalityHelper {
 class CardinalityEstimator {
 public:
 	static constexpr double DEFAULT_SEMI_ANTI_SELECTIVITY = 5;
-	static constexpr double DEFAULT_LT_GT_MULTIPLIER = 2.5;
 	explicit CardinalityEstimator() {};
 
 private:
diff --git a/src/optimizer/join_order/cardinality_estimator.cpp b/src/optimizer/join_order/cardinality_estimator.cpp
index 4b5e22adad1e..2539bf37ac39 100644
--- a/src/optimizer/join_order/cardinality_estimator.cpp
+++ b/src/optimizer/join_order/cardinality_estimator.cpp
@@ -9,6 +9,8 @@
 #include "duckdb/planner/operator/logical_comparison_join.hpp"
 #include "duckdb/storage/data_table.hpp"
 
+#include <math.h>
+
 namespace duckdb {
 
 // The filter was made on top of a logical sample or other projection,
@@ -216,16 +218,14 @@ double CardinalityEstimator::CalculateUpdatedDenom(Subgraph2Denominator left, Su
 	double new_denom = left.denom * right.denom;
 	switch (filter.filter_info->join_type) {
 	case JoinType::INNER: {
-		bool set = false;
-		ExpressionType comparison_type = ExpressionType::COMPARE_EQUAL;
+		// Collect comparison types
+		ExpressionType comparison_type = ExpressionType::INVALID;
 		ExpressionIterator::EnumerateExpression(filter.filter_info->filter, [&](Expression &expr) {
 			if (expr.GetExpressionClass() == ExpressionClass::BOUND_COMPARISON) {
 				comparison_type = expr.GetExpressionType();
-				set = true;
-				return;
 			}
 		});
-		if (!set) {
+		if (comparison_type == ExpressionType::INVALID) {
 			new_denom *=
 			    filter.has_tdom_hll ? static_cast<double>(filter.tdom_hll) : static_cast<double>(filter.tdom_no_hll);
 			// no comparison is taking place, so the denominator is just the product of the left and right
@@ -237,22 +237,20 @@ double CardinalityEstimator::CalculateUpdatedDenom(Subgraph2Denominator left, Su
 		switch (comparison_type) {
 		case ExpressionType::COMPARE_EQUAL:
 		case ExpressionType::COMPARE_NOT_DISTINCT_FROM:
-			// extra ration stays 1
-			extra_ratio = filter.has_tdom_hll ? (double)filter.tdom_hll : (double)filter.tdom_no_hll;
+			// extra ratio stays 1
+			extra_ratio =
+			    filter.has_tdom_hll ? static_cast<double>(filter.tdom_hll) : static_cast<double>(filter.tdom_no_hll);
 			break;
 		case ExpressionType::COMPARE_LESSTHANOREQUALTO:
 		case ExpressionType::COMPARE_LESSTHAN:
 		case ExpressionType::COMPARE_GREATERTHANOREQUALTO:
 		case ExpressionType::COMPARE_GREATERTHAN:
-			// start with the selectivity of equality
-			extra_ratio = filter.has_tdom_hll ? (double)filter.tdom_hll : (double)filter.tdom_no_hll;
-			// now assume every tuple will match 2.5 times (on average)
-			extra_ratio *= static_cast<double>(1) / CardinalityEstimator::DEFAULT_LT_GT_MULTIPLIER;
-			break;
 		case ExpressionType::COMPARE_NOTEQUAL:
 		case ExpressionType::COMPARE_DISTINCT_FROM:
-			// basically assume cross product.
-			extra_ratio = 1;
+			// Assume this blows up, but use the tdom to bound it a bit
+			extra_ratio =
+			    filter.has_tdom_hll ? static_cast<double>(filter.tdom_hll) : static_cast<double>(filter.tdom_no_hll);
+			extra_ratio = pow(extra_ratio, 2.0 / 3.0);
 			break;
 		default:
 			break;
diff --git a/src/optimizer/join_order/relation_manager.cpp b/src/optimizer/join_order/relation_manager.cpp
index d4f7032d676d..cfc829da7808 100644
--- a/src/optimizer/join_order/relation_manager.cpp
+++ b/src/optimizer/join_order/relation_manager.cpp
@@ -418,7 +418,9 @@ bool RelationManager::ExtractJoinRelations(JoinOrderOptimizer &optimizer, Logica
 		// create dummy aggregation for the duplicate elimination
 		auto dummy_aggr = make_uniq<LogicalAggregate>(DConstants::INVALID_INDEX - 1, DConstants::INVALID_INDEX,
 		                                              vector<unique_ptr<Expression>>());
+		dummy_aggr->grouping_sets.emplace_back();
 		for (auto &delim_col : delim_join.duplicate_eliminated_columns) {
+			dummy_aggr->grouping_sets.back().insert(dummy_aggr->groups.size());
 			dummy_aggr->groups.push_back(delim_col->Copy());
 		}
 		auto lhs_delim_stats = RelationStatisticsHelper::ExtractAggregationStats(*dummy_aggr, lhs_stats);
@@ -429,6 +431,36 @@ bool RelationManager::ExtractJoinRelations(JoinOrderOptimizer &optimizer, Logica
 		rhs_optimizer.AddDelimScanStats(lhs_delim_stats);
 		op->children[1] = rhs_optimizer.Optimize(std::move(op->children[1]), rhs_stats);
 
+		RelationStats dj_stats;
+		switch (delim_join.join_type) {
+		case JoinType::LEFT:
+		case JoinType::INNER:
+		case JoinType::OUTER:
+		case JoinType::SINGLE:
+		case JoinType::MARK:
+		case JoinType::SEMI:
+		case JoinType::ANTI:
+			dj_stats = lhs_stats;
+			break;
+		case JoinType::RIGHT:
+		case JoinType::RIGHT_SEMI:
+		case JoinType::RIGHT_ANTI:
+			dj_stats = rhs_stats;
+			break;
+		default:
+			throw NotImplementedException("Unsupported join type");
+		}
+
+		if (delim_join.join_type == JoinType::SEMI || delim_join.join_type == JoinType::ANTI ||
+		    delim_join.join_type == JoinType::RIGHT_SEMI || delim_join.join_type == JoinType::RIGHT_ANTI) {
+			dj_stats.cardinality =
+			    MaxValue<idx_t>(LossyNumericCast<idx_t>(static_cast<double>(dj_stats.cardinality) /
+			                                            CardinalityEstimator::DEFAULT_SEMI_ANTI_SELECTIVITY),
+			                    1);
+		}
+
+		AddAggregateOrWindowRelation(input_op, parent, dj_stats, op->type);
+
 		return false;
 	}
 	case LogicalOperatorType::LOGICAL_DELIM_GET: {
diff --git a/src/optimizer/join_order/relation_statistics_helper.cpp b/src/optimizer/join_order/relation_statistics_helper.cpp
index 6340d9c02cd8..33edb135e7d0 100644
--- a/src/optimizer/join_order/relation_statistics_helper.cpp
+++ b/src/optimizer/join_order/relation_statistics_helper.cpp
@@ -9,6 +9,8 @@
 #include "duckdb/storage/data_table.hpp"
 #include "duckdb/planner/filter/constant_filter.hpp"
 
+#include <math.h>
+
 namespace duckdb {
 
 static ExpressionBinding GetChildColumnBinding(Expression &expr) {
@@ -328,8 +330,9 @@ RelationStats RelationStatisticsHelper::ExtractAggregationStats(LogicalAggregate
 	// TODO: look at child distinct count to better estimate cardinality.
 	stats.cardinality = child_stats.cardinality;
 	stats.column_distinct_count = child_stats.column_distinct_count;
-	double new_card = -1;
+	vector<double> distinct_counts;
 	for (auto &g_set : aggr.grouping_sets) {
+		vector<double> set_distinct_counts;
 		for (auto &ind : g_set) {
 			if (aggr.groups[ind]->GetExpressionClass() != ExpressionClass::BOUND_COLUMN_REF) {
 				continue;
@@ -343,26 +346,59 @@ RelationStats RelationStatisticsHelper::ExtractAggregationStats(LogicalAggregate
 				// be grouped by. Hopefully this can be fixed with duckdb-internal#606
 				continue;
 			}
-			double distinct_count = double(child_stats.column_distinct_count[col_index].distinct_count);
-			if (new_card < distinct_count) {
-				new_card = distinct_count;
-			}
+			double distinct_count = static_cast<double>(child_stats.column_distinct_count[col_index].distinct_count);
+			set_distinct_counts.push_back(distinct_count == 0 ? 1 : distinct_count);
+		}
+		// We use the grouping set with the most group key columns for cardinality estimation
+		if (set_distinct_counts.size() > distinct_counts.size()) {
+			distinct_counts = std::move(set_distinct_counts);
 		}
 	}
-	if (new_card < 0 || new_card >= double(child_stats.cardinality)) {
+
+	double new_card;
+	if (distinct_counts.empty()) {
 		// We have no good statistics on distinct count.
 		// most likely we are running on parquet files. Therefore we divide by 2.
-		new_card = (double)child_stats.cardinality / 2;
+		new_card = static_cast<double>(child_stats.cardinality) / 2.0;
+	} else {
+		// Multiply distinct counts
+		double product = 1;
+		for (const auto &distinct_count : distinct_counts) {
+			product *= distinct_count;
+		}
+
+		// Assume slight correlation for each grouping column
+		const auto correction = pow(0.95, static_cast<double>(distinct_counts.size() - 1));
+		product *= correction;
+
+		// Estimate using the "Occupancy Problem",
+		// where "product" is number of bins, and "child_stats.cardinality" is number of balls
+		const auto mult = 1.0 - exp(-static_cast<double>(child_stats.cardinality) / product);
+		if (mult == 0) { // Can become 0 with very large estimates due to double imprecision
+			new_card = static_cast<double>(child_stats.cardinality);
+		} else {
+			new_card = product * mult;
+		}
+		new_card = MinValue(new_card, static_cast<double>(child_stats.cardinality));
 	}
+
 	// an ungrouped aggregate has 1 row
 	stats.cardinality = aggr.groups.empty() ? 1 : LossyNumericCast<idx_t>(new_card);
 	stats.column_names = child_stats.column_names;
 	stats.stats_initialized = true;
-	auto num_child_columns = aggr.GetColumnBindings().size();
+	const auto aggr_column_bindings = aggr.GetColumnBindings();
+	auto num_child_columns = aggr_column_bindings.size();
 
-	for (idx_t column_index = child_stats.column_distinct_count.size(); column_index < num_child_columns;
-	     column_index++) {
-		stats.column_distinct_count.push_back(DistinctCount({child_stats.cardinality, false}));
+	for (idx_t column_index = 0; column_index < num_child_columns; column_index++) {
+		const auto &binding = aggr_column_bindings[column_index];
+		if (binding.table_index == aggr.group_index && column_index < distinct_counts.size()) {
+			// Group column that we have the HLL of
+			stats.column_distinct_count.push_back(
+			    DistinctCount({LossyNumericCast<idx_t>(distinct_counts[column_index]), true}));
+		} else {
+			// Non-group column, or we don't have the HLL
+			stats.column_distinct_count.push_back(DistinctCount({child_stats.cardinality, false}));
+		}
 		stats.column_names.push_back("aggregate");
 	}
 	return stats;
