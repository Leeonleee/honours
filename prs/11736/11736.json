{
  "repo": "duckdb/duckdb",
  "pull_number": 11736,
  "instance_id": "duckdb__duckdb-11736",
  "issue_numbers": [
    "11734"
  ],
  "base_commit": "f29b2db1bbaa750b5273f1323568404830fb1f3c",
  "patch": "diff --git a/.github/regression/csv.csv b/.github/regression/csv.csv\nindex 272b7ced2a04..ddfe10bad1e8 100644\n--- a/.github/regression/csv.csv\n+++ b/.github/regression/csv.csv\n@@ -4,4 +4,5 @@ benchmark/micro/csv/small_csv.benchmark\n benchmark/micro/csv/null_padding.benchmark\n benchmark/micro/csv/projection_pushdown.benchmark\n benchmark/micro/csv/1_byte_values.benchmark\n-benchmark/micro/csv/16_byte_values.benchmark\n\\ No newline at end of file\n+benchmark/micro/csv/16_byte_values.benchmark\n+benchmark/micro/csv/time_type.benchmark\n\\ No newline at end of file\ndiff --git a/.github/regression/micro_extended.csv b/.github/regression/micro_extended.csv\nindex 6973785b4c98..365347ad3ad3 100644\n--- a/.github/regression/micro_extended.csv\n+++ b/.github/regression/micro_extended.csv\n@@ -86,6 +86,7 @@ benchmark/micro/csv/read.benchmark\n benchmark/micro/csv/small_csv.benchmark\n benchmark/micro/csv/sniffer.benchmark\n benchmark/micro/csv/sniffer_quotes.benchmark\n+benchmark/micro/csv/time_type.benchmark\n benchmark/micro/cte/cte.benchmark\n benchmark/micro/cte/materialized_cte.benchmark\n benchmark/micro/date/extract_month.benchmark\ndiff --git a/benchmark/micro/csv/time_type.benchmark b/benchmark/micro/csv/time_type.benchmark\nnew file mode 100644\nindex 000000000000..98f4a556bb06\n--- /dev/null\n+++ b/benchmark/micro/csv/time_type.benchmark\n@@ -0,0 +1,14 @@\n+# name: benchmark/micro/csv/time_type.benchmark\n+# description: Run CSV scan with timestamp and date types\n+# group: [csv]\n+\n+name CSV Read Benchmark with timestamp and date types\n+group csv\n+\n+load\n+CREATE TABLE t1 AS select '30/07/1992', '30/07/1992 17:15:30';\n+insert into t1  select '30/07/1992', '30/07/1992 17:15:30' from range(0,10000000) tbl(i);\n+COPY t1 TO '${BENCHMARK_DIR}/time_timestamp.csv' (FORMAT CSV, HEADER 0);\n+\n+run\n+SELECT * from read_csv('${BENCHMARK_DIR}/time_timestamp.csv',delim= ',',  header = 0)\ndiff --git a/data/csv/rejects/flush.csv b/data/csv/rejects/flush.csv\nnew file mode 100644\nindex 000000000000..f731737ac263\n--- /dev/null\n+++ b/data/csv/rejects/flush.csv\n@@ -0,0 +1,8 @@\n+\"number\"\n+\"not-a-number\"\n+\"-26,9568\"\n+1521000\n+\"33,4386\"\n+\"33.4386,00\"\n+33.438600\n+-21060000\n\\ No newline at end of file\ndiff --git a/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp b/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\nindex 9e6271c82818..c4d255be484a 100644\n--- a/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\n+++ b/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\n@@ -97,6 +97,8 @@ StringValueResult::StringValueResult(CSVStates &states, CSVStateMachine &state_m\n \t\tnull_str_ptr[i] = state_machine.options.null_str[i].c_str();\n \t\tnull_str_size[i] = state_machine.options.null_str[i].size();\n \t}\n+\tdate_format = state_machine.options.dialect_options.date_format.at(LogicalTypeId::DATE).GetValue();\n+\ttimestamp_format = state_machine.options.dialect_options.date_format.at(LogicalTypeId::TIMESTAMP).GetValue();\n }\n \n StringValueResult::~StringValueResult() {\n@@ -215,16 +217,26 @@ void StringValueResult::AddValueToVector(const char *value_ptr, const idx_t size\n \t\t                               false, state_machine.options.decimal_separator[0]);\n \t\tbreak;\n \tcase LogicalTypeId::DATE: {\n-\t\tidx_t pos;\n-\t\tbool special;\n-\t\tsuccess = Date::TryConvertDate(value_ptr, size, pos,\n-\t\t                               static_cast<date_t *>(vector_ptr[chunk_col_id])[number_of_rows], special, false);\n+\t\tif (!date_format.Empty()) {\n+\t\t\tsuccess = date_format.TryParseDate(value_ptr, size,\n+\t\t\t                                   static_cast<date_t *>(vector_ptr[chunk_col_id])[number_of_rows]);\n+\t\t} else {\n+\t\t\tidx_t pos;\n+\t\t\tbool special;\n+\t\t\tsuccess = Date::TryConvertDate(\n+\t\t\t    value_ptr, size, pos, static_cast<date_t *>(vector_ptr[chunk_col_id])[number_of_rows], special, false);\n+\t\t}\n \t\tbreak;\n \t}\n \tcase LogicalTypeId::TIMESTAMP: {\n-\t\tsuccess = Timestamp::TryConvertTimestamp(\n-\t\t              value_ptr, size, static_cast<timestamp_t *>(vector_ptr[chunk_col_id])[number_of_rows]) ==\n-\t\t          TimestampCastResult::SUCCESS;\n+\t\tif (!timestamp_format.Empty()) {\n+\t\t\tsuccess = timestamp_format.TryParseTimestamp(\n+\t\t\t    value_ptr, size, static_cast<timestamp_t *>(vector_ptr[chunk_col_id])[number_of_rows]);\n+\t\t} else {\n+\t\t\tsuccess = Timestamp::TryConvertTimestamp(\n+\t\t\t              value_ptr, size, static_cast<timestamp_t *>(vector_ptr[chunk_col_id])[number_of_rows]) ==\n+\t\t\t          TimestampCastResult::SUCCESS;\n+\t\t}\n \t\tbreak;\n \t}\n \tdefault: {\n@@ -730,26 +742,7 @@ void StringValueScanner::Flush(DataChunk &insert_chunk) {\n \t\t\tbool success;\n \t\t\tidx_t line_error = 0;\n \t\t\tbool line_error_set = true;\n-\n-\t\t\tif (!state_machine->options.dialect_options.date_format.at(LogicalTypeId::DATE).GetValue().Empty() &&\n-\t\t\t    type.id() == LogicalTypeId::DATE) {\n-\t\t\t\t// use the date format to cast the chunk\n-\t\t\t\tsuccess = CSVCast::TryCastDateVector(state_machine->options.dialect_options.date_format, parse_vector,\n-\t\t\t\t                                     result_vector, parse_chunk.size(), parameters, line_error, true);\n-\t\t\t} else if (!state_machine->options.dialect_options.date_format.at(LogicalTypeId::TIMESTAMP)\n-\t\t\t                .GetValue()\n-\t\t\t                .Empty() &&\n-\t\t\t           type.id() == LogicalTypeId::TIMESTAMP) {\n-\t\t\t\t// use the date format to cast the chunk\n-\t\t\t\tsuccess =\n-\t\t\t\t    CSVCast::TryCastTimestampVector(state_machine->options.dialect_options.date_format, parse_vector,\n-\t\t\t\t                                    result_vector, parse_chunk.size(), parameters, true);\n-\t\t\t} else if (state_machine->options.decimal_separator != \".\" &&\n-\t\t\t           (type.id() == LogicalTypeId::FLOAT || type.id() == LogicalTypeId::DOUBLE)) {\n-\t\t\t\tsuccess =\n-\t\t\t\t    CSVCast::TryCastFloatingVectorCommaSeparated(state_machine->options, parse_vector, result_vector,\n-\t\t\t\t                                                 parse_chunk.size(), parameters, type, line_error);\n-\t\t\t} else if (state_machine->options.decimal_separator != \".\" && type.id() == LogicalTypeId::DECIMAL) {\n+\t\t\tif (state_machine->options.decimal_separator != \".\" && type.id() == LogicalTypeId::DECIMAL) {\n \t\t\t\tsuccess =\n \t\t\t\t    CSVCast::TryCastDecimalVectorCommaSeparated(state_machine->options, parse_vector, result_vector,\n \t\t\t\t                                                parse_chunk.size(), parameters, type, line_error);\n@@ -790,8 +783,12 @@ void StringValueScanner::Flush(DataChunk &insert_chunk) {\n \t\t\t\tbool first_nl;\n \t\t\t\tauto borked_line =\n \t\t\t\t    result.line_positions_per_row[line_error].ReconstructCurrentLine(first_nl, result.buffer_handles);\n+\t\t\t\tstd::ostringstream error;\n+\t\t\t\terror << \"Could not convert string \\\"\" << parse_vector.GetValue(line_error) << \"\\\" to \\'\"\n+\t\t\t\t      << LogicalTypeIdToString(type.id()) << \"\\'\";\n+\t\t\t\tstring error_msg = error.str();\n \t\t\t\tauto csv_error = CSVError::CastError(\n-\t\t\t\t    state_machine->options, csv_file_scan->names[col_idx], error_message, col_idx, borked_line,\n+\t\t\t\t    state_machine->options, csv_file_scan->names[col_idx], error_msg, col_idx, borked_line,\n \t\t\t\t    lines_per_batch,\n \t\t\t\t    result.line_positions_per_row[line_error].begin.GetGlobalPosition(result.result_size, first_nl), -1,\n \t\t\t\t    result_vector.GetType().id());\n@@ -814,8 +811,13 @@ void StringValueScanner::Flush(DataChunk &insert_chunk) {\n \t\t\t\t\tbool first_nl;\n \t\t\t\t\tauto borked_line = result.line_positions_per_row[line_error].ReconstructCurrentLine(\n \t\t\t\t\t    first_nl, result.buffer_handles);\n+\t\t\t\t\tstd::ostringstream error;\n+\t\t\t\t\t// Casting Error Message\n+\t\t\t\t\terror << \"Could not convert string \\\"\" << parse_vector.GetValue(line_error) << \"\\\" to \\'\"\n+\t\t\t\t\t      << LogicalTypeIdToString(type.id()) << \"\\'\";\n+\t\t\t\t\tstring error_msg = error.str();\n \t\t\t\t\tauto csv_error = CSVError::CastError(\n-\t\t\t\t\t    state_machine->options, csv_file_scan->names[col_idx], error_message, col_idx, borked_line,\n+\t\t\t\t\t    state_machine->options, csv_file_scan->names[col_idx], error_msg, col_idx, borked_line,\n \t\t\t\t\t    lines_per_batch,\n \t\t\t\t\t    result.line_positions_per_row[line_error].begin.GetGlobalPosition(result.result_size, first_nl),\n \t\t\t\t\t    -1, result_vector.GetType().id());\n@@ -1185,7 +1187,6 @@ bool StringValueScanner::CanDirectlyCast(const LogicalType &type,\n                                          const map<LogicalTypeId, CSVOption<StrpTimeFormat>> &format_options) {\n \n \tswitch (type.id()) {\n-\t\t// All Integers (Except HugeInt)\n \tcase LogicalTypeId::TINYINT:\n \tcase LogicalTypeId::SMALLINT:\n \tcase LogicalTypeId::INTEGER:\n@@ -1196,20 +1197,8 @@ bool StringValueScanner::CanDirectlyCast(const LogicalType &type,\n \tcase LogicalTypeId::UBIGINT:\n \tcase LogicalTypeId::DOUBLE:\n \tcase LogicalTypeId::FLOAT:\n-\t\treturn true;\n \tcase LogicalTypeId::DATE:\n-\t\t// We can only internally cast YYYY-MM-DD\n-\t\tif (format_options.at(LogicalTypeId::DATE).GetValue().format_specifier == \"%Y-%m-%d\") {\n-\t\t\treturn true;\n-\t\t} else {\n-\t\t\treturn false;\n-\t\t}\n \tcase LogicalTypeId::TIMESTAMP:\n-\t\tif (format_options.at(LogicalTypeId::TIMESTAMP).GetValue().format_specifier == \"%Y-%m-%d %H:%M:%S\") {\n-\t\t\treturn true;\n-\t\t} else {\n-\t\t\treturn false;\n-\t\t}\n \tcase LogicalType::VARCHAR:\n \t\treturn true;\n \tdefault:\ndiff --git a/src/function/scalar/strftime_format.cpp b/src/function/scalar/strftime_format.cpp\nindex f0ec24920a59..f8ff39c37247 100644\n--- a/src/function/scalar/strftime_format.cpp\n+++ b/src/function/scalar/strftime_format.cpp\n@@ -740,8 +740,7 @@ int32_t StrpTimeFormat::TryParseCollection(const char *data, idx_t &pos, idx_t s\n \treturn -1;\n }\n \n-//! Parses a timestamp using the given specifier\n-bool StrpTimeFormat::Parse(string_t str, ParseResult &result) const {\n+bool StrpTimeFormat::Parse(const char *data, size_t size, ParseResult &result) const {\n \tauto &result_data = result.data;\n \tauto &error_message = result.error_message;\n \tauto &error_position = result.error_position;\n@@ -755,15 +754,11 @@ bool StrpTimeFormat::Parse(string_t str, ParseResult &result) const {\n \tresult_data[5] = 0;\n \tresult_data[6] = 0;\n \tresult_data[7] = 0;\n-\n-\tauto data = str.GetData();\n-\tidx_t size = str.GetSize();\n \t// skip leading spaces\n \twhile (StringUtil::CharacterIsSpace(*data)) {\n \t\tdata++;\n \t\tsize--;\n \t}\n-\n \t//\tCheck for specials\n \t//\tPrecheck for alphas for performance.\n \tidx_t pos = 0;\n@@ -1067,7 +1062,6 @@ bool StrpTimeFormat::Parse(string_t str, ParseResult &result) const {\n \t\t\t\tcase StrTimeSpecifier::YEAR_DECIMAL:\n \t\t\t\t\t// Just validate, don't use\n \t\t\t\t\tbreak;\n-\t\t\t\t\tbreak;\n \t\t\t\tcase StrTimeSpecifier::WEEKDAY_DECIMAL:\n \t\t\t\t\t// First offset specifier\n \t\t\t\t\toffset_specifier = specifiers[i];\n@@ -1324,6 +1318,13 @@ bool StrpTimeFormat::Parse(string_t str, ParseResult &result) const {\n \treturn true;\n }\n \n+//! Parses a timestamp using the given specifier\n+bool StrpTimeFormat::Parse(string_t str, ParseResult &result) const {\n+\tauto data = str.GetData();\n+\tidx_t size = str.GetSize();\n+\treturn Parse(data, size, result);\n+}\n+\n StrpTimeFormat::ParseResult StrpTimeFormat::Parse(const string &format_string, const string &text) {\n \tStrpTimeFormat format;\n \tformat.format_specifier = format_string;\n@@ -1413,6 +1414,14 @@ bool StrpTimeFormat::TryParseDate(string_t input, date_t &result, string &error_\n \treturn parse_result.TryToDate(result);\n }\n \n+bool StrpTimeFormat::TryParseDate(const char *data, size_t size, date_t &result) const {\n+\tParseResult parse_result;\n+\tif (!Parse(data, size, parse_result)) {\n+\t\treturn false;\n+\t}\n+\treturn parse_result.TryToDate(result);\n+}\n+\n bool StrpTimeFormat::TryParseTime(string_t input, dtime_t &result, string &error_message) const {\n \tParseResult parse_result;\n \tif (!Parse(input, parse_result)) {\n@@ -1431,4 +1440,12 @@ bool StrpTimeFormat::TryParseTimestamp(string_t input, timestamp_t &result, stri\n \treturn parse_result.TryToTimestamp(result);\n }\n \n+bool StrpTimeFormat::TryParseTimestamp(const char *data, size_t size, timestamp_t &result) const {\n+\tParseResult parse_result;\n+\tif (!Parse(data, size, parse_result)) {\n+\t\treturn false;\n+\t}\n+\treturn parse_result.TryToTimestamp(result);\n+}\n+\n } // namespace duckdb\ndiff --git a/src/include/duckdb/execution/operator/csv_scanner/string_value_scanner.hpp b/src/include/duckdb/execution/operator/csv_scanner/string_value_scanner.hpp\nindex 9ad42fd16635..a1fa130e4ffd 100644\n--- a/src/include/duckdb/execution/operator/csv_scanner/string_value_scanner.hpp\n+++ b/src/include/duckdb/execution/operator/csv_scanner/string_value_scanner.hpp\n@@ -145,7 +145,7 @@ class StringValueResult : public ScannerResult {\n \n \t//! Errors happening in the current line (if any)\n \tvector<CurrentError> current_errors;\n-\n+\tStrpTimeFormat date_format, timestamp_format;\n \tbool sniffing;\n \t//! Specialized code for quoted values, makes sure to remove quotes and escapes\n \tstatic inline void AddQuotedValue(StringValueResult &result, const idx_t buffer_pos);\ndiff --git a/src/include/duckdb/function/scalar/strftime_format.hpp b/src/include/duckdb/function/scalar/strftime_format.hpp\nindex a7b3addde7d2..a538db4255b3 100644\n--- a/src/include/duckdb/function/scalar/strftime_format.hpp\n+++ b/src/include/duckdb/function/scalar/strftime_format.hpp\n@@ -161,6 +161,11 @@ struct StrpTimeFormat : public StrTimeFormat { // NOLINT: work-around bug in cla\n \n \tDUCKDB_API bool Parse(string_t str, ParseResult &result) const;\n \n+\tDUCKDB_API bool Parse(const char *data, size_t size, ParseResult &result) const;\n+\n+\tDUCKDB_API bool TryParseDate(const char *data, size_t size, date_t &result) const;\n+\tDUCKDB_API bool TryParseTimestamp(const char *data, size_t size, timestamp_t &result) const;\n+\n \tDUCKDB_API bool TryParseDate(string_t str, date_t &result, string &error_message) const;\n \tDUCKDB_API bool TryParseTime(string_t str, dtime_t &result, string &error_message) const;\n \tDUCKDB_API bool TryParseTimestamp(string_t str, timestamp_t &result, string &error_message) const;\n",
  "test_patch": "diff --git a/test/sql/copy/csv/csv_hive_filename_union.test b/test/sql/copy/csv/csv_hive_filename_union.test\nindex 79f84efcdfc0..ff145d929f77 100644\n--- a/test/sql/copy/csv/csv_hive_filename_union.test\n+++ b/test/sql/copy/csv/csv_hive_filename_union.test\n@@ -56,7 +56,7 @@ xxx\t42\n statement error\n select * from read_csv_auto(['data/csv/hive-partitioning/mismatching_contents/part=1/test.csv', 'data/csv/hive-partitioning/mismatching_contents/part=2/test.csv'])  order by 1\n ----\n-date field value out of range\n+Error when converting column \"c\". Could not convert string \"world\" to 'DATE'\n \n query III\n select a, b, c from read_csv_auto('data/csv/hive-partitioning/mismatching_contents/*/*.csv', UNION_BY_NAME=1)  order by 2 NULLS LAST\ndiff --git a/test/sql/copy/csv/rejects/csv_rejects_flush_cast.test b/test/sql/copy/csv/rejects/csv_rejects_flush_cast.test\nindex ba48d9fe2a99..09daa735d6eb 100644\n--- a/test/sql/copy/csv/rejects/csv_rejects_flush_cast.test\n+++ b/test/sql/copy/csv/rejects/csv_rejects_flush_cast.test\n@@ -20,6 +20,6 @@ DATE\tVARCHAR\t2811\n query IIIIIIIII\n SELECT * EXCLUDE (scan_id) FROM reject_errors order by all;\n ----\n-0\t439\t6997\tNULL\t1\ta\tCAST\tB, bla\tError when converting column \"a\". Could not parse string \"B\" according to format specifier \"%d-%m-%Y\"\n-0\t2813\t44972\tNULL\t1\ta\tCAST\tc, bla\tError when converting column \"a\". Could not parse string \"c\" according to format specifier \"%d-%m-%Y\"\n+0\t439\t6997\t6997\t1\ta\tCAST\tB, bla\tError when converting column \"a\". Could not convert string \"B\" to 'DATE'\n+0\t2813\t44972\t44972\t1\ta\tCAST\tc, bla\tError when converting column \"a\". Could not convert string \"c\" to 'DATE'\n \ndiff --git a/test/sql/copy/csv/rejects/csv_rejects_flush_message.test b/test/sql/copy/csv/rejects/csv_rejects_flush_message.test\nnew file mode 100644\nindex 000000000000..cb409c240f23\n--- /dev/null\n+++ b/test/sql/copy/csv/rejects/csv_rejects_flush_message.test\n@@ -0,0 +1,27 @@\n+# name: test/sql/copy/csv/rejects/csv_rejects_flush_message.test\n+# description: Test that Flush Cast gives reasonable messages\n+# group: [rejects]\n+\n+require skip_reload\n+\n+# Test will fail on windows because byte_position is slightly different due to \\r\\n instead of \\n\n+require notwindows\n+\n+query I\n+SELECT * FROM read_csv(\n+    'data/csv/rejects/flush.csv',\n+    columns = {'a': 'DECIMAL'},\n+    store_rejects = true);\n+----\n+1521000.000\n+33.439\n+-21060000.000\n+\n+query IIIIIIIII\n+SELECT * EXCLUDE (scan_id) FROM reject_errors order by all;\n+----\n+0\t2\t10\tNULL\t1\ta\tCAST\t\"not-a-number\"\tError when converting column \"a\". Could not convert string \"not-a-number\" to 'DECIMAL'\n+0\t3\t25\tNULL\t1\ta\tCAST\t\"-26,9568\"\tError when converting column \"a\". Could not convert string \"-26,9568\" to 'DECIMAL'\n+0\t5\t44\tNULL\t1\ta\tCAST\t\"33,4386\"\tError when converting column \"a\". Could not convert string \"33,4386\" to 'DECIMAL'\n+0\t6\t54\tNULL\t1\ta\tCAST\t\"33.4386,00\"\tError when converting column \"a\". Could not convert string \"33.4386,00\" to 'DECIMAL'\n+\ndiff --git a/test/sql/copy/csv/rejects/test_multiple_errors_same_line.test b/test/sql/copy/csv/rejects/test_multiple_errors_same_line.test\nindex 6d9f1fcb5baa..85c3140097bc 100644\n--- a/test/sql/copy/csv/rejects/test_multiple_errors_same_line.test\n+++ b/test/sql/copy/csv/rejects/test_multiple_errors_same_line.test\n@@ -61,8 +61,8 @@ oogie boogie\t3\t2023-01-02\t2023-01-03\n query IIIIIIIII rowsort\n SElECT * EXCLUDE (scan_id) FROM reject_errors ORDER BY ALL;\n ----\n-0\t4\t110\tNULL\t3\tcurrent_day\tCAST\toogie boogie,3, bla_2, bla_1\tError when converting column \"current_day\". date field value out of range: \" bla_2\", expected format is (YYYY-MM-DD)\n-0\t4\t110\tNULL\t4\ttomorrow\tCAST\toogie boogie,3, bla_2, bla_1\tError when converting column \"tomorrow\". date field value out of range: \" bla_1\", expected format is (YYYY-MM-DD)\n+0\t4\t110\t125\t3\tcurrent_day\tCAST\toogie boogie,3, bla_2, bla_1\tError when converting column \"current_day\". Could not convert string \" bla_2\" to 'DATE'\n+0\t4\t110\t132\t4\ttomorrow\tCAST\toogie boogie,3, bla_2, bla_1\tError when converting column \"tomorrow\". Could not convert string \" bla_1\" to 'DATE'\n \n statement ok\n DROP TABLE reject_errors;\n@@ -82,6 +82,7 @@ oogie boogie\t3\t2023-01-02\t5\n query IIIIIIIII rowsort\n SElECT * EXCLUDE (scan_id) FROM reject_errors ORDER BY ALL;\n ----\n+0\t4\t89\t104\t3\tcurrent_day\tCAST\toogie boogie,3, bla_2, bla_1\tError when converting column \"current_day\". Could not convert string \" bla_2\" to 'DATE'\n 0\t4\t89\t111\t4\tbarks\tCAST\toogie boogie,3, bla_2, bla_1\tError when converting column \"barks\". Could not convert string \" bla_1\" to 'INTEGER'\n \n statement ok\n@@ -370,10 +371,13 @@ SELECT * EXCLUDE (scan_id) FROM reject_errors ORDER BY ALL;\n ----\n 0\t4\t89\t116\t4\tbarks\tCAST\toogie boogie,3, 2023-01-03, bla, 7\tError when converting column \"barks\". Could not convert string \" bla\" to 'INTEGER'\n 0\t4\t89\t120\t5\tNULL\tTOO MANY COLUMNS\toogie boogie,3, 2023-01-03, bla, 7\tExpected Number of Columns: 4 Found: 5\n+0\t5\t124\t139\t3\tcurrent_day\tCAST\toogie boogie,3, bla, bla, 7\tError when converting column \"current_day\". Could not convert string \" bla\" to 'DATE'\n 0\t5\t124\t144\t4\tbarks\tCAST\toogie boogie,3, bla, bla, 7\tError when converting column \"barks\". Could not convert string \" bla\" to 'INTEGER'\n 0\t5\t124\t148\t5\tNULL\tTOO MANY COLUMNS\toogie boogie,3, bla, bla, 7\tExpected Number of Columns: 4 Found: 5\n 0\t6\t152\t152\t1\tname\tUNQUOTED VALUE\t\"oogie boogie\"bla,3, 2023-01-04\tValue with unterminated quote found.\n 0\t6\t152\t183\t3\tbarks\tMISSING COLUMNS\t\"oogie boogie\"bla,3, 2023-01-04\tExpected Number of Columns: 4 Found: 3\n+0\t7\t184\t199\t3\tcurrent_day\tCAST\toogie boogie,3, bla\tError when converting column \"current_day\". Could not convert string \" bla\" to 'DATE'\n 0\t7\t184\t203\t3\tbarks\tMISSING COLUMNS\toogie boogie,3, bla\tExpected Number of Columns: 4 Found: 3\n 0\t8\t204\t204\tNULL\tNULL\tLINE SIZE OVER MAXIMUM\toogie boogieoogie boogieoogie boogieoogie boogieoogie boogieoogie boogieoogie boogie,3, bla\tMaximum line size of 40 bytes exceeded. Actual Size:92 bytes.\n-0\t8\t204\t295\t3\tbarks\tMISSING COLUMNS\toogie boogieoogie boogieoogie boogieoogie boogieoogie boogieoogie boogieoogie boogie,3, bla\tExpected Number of Columns: 4 Found: 3\n+0\t8\t204\t291\t3\tcurrent_day\tCAST\toogie boogieoogie boogieoogie boogieoogie boogieoogie boogieoogie boogieoogie boogie,3, bla\tError when converting column \"current_day\". Could not convert string \" bla\" to 'DATE'\n+0\t8\t204\t295\t3\tbarks\tMISSING COLUMNS\toogie boogieoogie boogieoogie boogieoogie boogieoogie boogieoogie boogieoogie boogie,3, bla\tExpected Number of Columns: 4 Found: 3\n\\ No newline at end of file\ndiff --git a/test/sql/copy/csv/timestamp_with_tz.test b/test/sql/copy/csv/timestamp_with_tz.test\nindex 9478957d222e..b8dbd3de4e74 100644\n--- a/test/sql/copy/csv/timestamp_with_tz.test\n+++ b/test/sql/copy/csv/timestamp_with_tz.test\n@@ -9,7 +9,7 @@ CREATE TABLE tbl(id int, ts timestamp);\n statement error\n COPY tbl FROM 'data/csv/timestamp_with_tz.csv' (HEADER)\n ----\n-timestamp that is not UTC\n+Error when converting column \"ts\". Could not convert string \"2021-05-25 04:55:03.382494 EST\" to 'TIMESTAMP'\n \n require icu\n \n",
  "problem_statement": "CSV rejects table error_message is the same for each line despite column having different values\n### What happens?\r\n\r\nWhen reading [faulty CSV files](https://duckdb.org/docs/data/csv/reading_faulty_csv_files.html), the `error_message` returns the same value for all lines, despite each line having a different value which cannot be read.\r\n\r\n### To Reproduce\r\n\r\nGiven the following CSV, `numbers.csv`:\r\n\r\n```csv\r\n\"number\"\r\n\"not-a-number\"\r\n\"-26,9568\"\r\n1521000\r\n\"33,4386\"\r\n\"33.4386,00\"\r\n33.438600\r\n-21060000\r\n```\r\n\r\nWhen I run the following command:\r\n\r\n```sql\r\nSELECT * FROM read_csv('numbers.csv', columns={ 'numbers': 'DECIMAL(25,3)' }, ignore_errors=true, rejects_table='rejects_table');\r\n```\r\n```text\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502    numbers    \u2502\r\n\u2502 decimal(25,3) \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502   1521000.000 \u2502\r\n\u2502        33.439 \u2502\r\n\u2502 -21060000.000 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\nThe below faulty lines are returned:\r\n\r\n```sql\r\nSELECT * FROM rejects_table;\r\n```\r\n```text\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 scan_id \u2502 file_id \u2502  line  \u2502 line_byte_position \u2502 byte_position \u2502 column_idx \u2502 column_name \u2502      error_type      \u2502    csv_line    \u2502                                error_message                                \u2502\r\n\u2502 uint64  \u2502 uint64  \u2502 uint64 \u2502       uint64       \u2502    uint64     \u2502   uint64   \u2502   varchar   \u2502 enum('cast', 'miss\u2026  \u2502    varchar     \u2502                                   varchar                                   \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502      22 \u2502       0 \u2502      2 \u2502                 10 \u2502               \u2502          1 \u2502 numbers     \u2502 CAST                 \u2502 \"not-a-number\" \u2502 Error when converting column \"numbers\". Could not convert string \"not-a-n\u2026  \u2502\r\n\u2502      22 \u2502       0 \u2502      3 \u2502                 25 \u2502               \u2502          1 \u2502 numbers     \u2502 CAST                 \u2502 \"-26,9568\"     \u2502 Error when converting column \"numbers\". Could not convert string \"not-a-n\u2026  \u2502\r\n\u2502      22 \u2502       0 \u2502      5 \u2502                 44 \u2502               \u2502          1 \u2502 numbers     \u2502 CAST                 \u2502 \"33,4386\"      \u2502 Error when converting column \"numbers\". Could not convert string \"not-a-n\u2026  \u2502\r\n\u2502      22 \u2502       0 \u2502      6 \u2502                 54 \u2502               \u2502          1 \u2502 numbers     \u2502 CAST                 \u2502 \"33.4386,00\"   \u2502 Error when converting column \"numbers\". Could not convert string \"not-a-n\u2026  \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\nReading the `error_message` column, you can see they're all the same despite the column having different values.\r\n\r\n```sql\r\nSELECT error_message FROM rejects_table;\r\n```\r\n```text\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502                                          error_message                                           \u2502\r\n\u2502                                             varchar                                              \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 Error when converting column \"numbers\". Could not convert string \"not-a-number\" to DECIMAL(25,3) \u2502\r\n\u2502 Error when converting column \"numbers\". Could not convert string \"not-a-number\" to DECIMAL(25,3) \u2502\r\n\u2502 Error when converting column \"numbers\". Could not convert string \"not-a-number\" to DECIMAL(25,3) \u2502\r\n\u2502 Error when converting column \"numbers\". Could not convert string \"not-a-number\" to DECIMAL(25,3) \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n```\r\n\r\n\r\n### OS:\r\n\r\nDISTRIB_ID=Ubuntu\r\nDISTRIB_RELEASE=23.10\r\nDISTRIB_CODENAME=mantic\r\nDISTRIB_DESCRIPTION=\"Ubuntu 23.10\"\r\n\r\n### DuckDB Version:\r\n\r\nv0.10.2 1601d94f94\r\n\r\n### DuckDB Client:\r\n\r\nCLI\r\n\r\n### Full Name:\r\n\r\nFrank Verschuren\r\n\r\n### Affiliation:\r\n\r\n1 Giant Leap Solutions BV\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\n",
  "hints_text": "",
  "created_at": "2024-04-19T14:50:43Z"
}