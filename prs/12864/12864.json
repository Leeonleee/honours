{
  "repo": "duckdb/duckdb",
  "pull_number": 12864,
  "instance_id": "duckdb__duckdb-12864",
  "issue_numbers": [
    "12818"
  ],
  "base_commit": "6b0889c968cb36caf7f6e00ffcd295d75b9b6f25",
  "patch": "diff --git a/tools/pythonpkg/src/include/duckdb_python/pyconnection/pyconnection.hpp b/tools/pythonpkg/src/include/duckdb_python/pyconnection/pyconnection.hpp\nindex 6702300a17bd..70afbffcae49 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/pyconnection/pyconnection.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/pyconnection/pyconnection.hpp\n@@ -40,11 +40,87 @@ class RegisteredArrow : public RegisteredObject {\n \tunique_ptr<PythonTableArrowArrayStreamFactory> arrow_factory;\n };\n \n-struct DuckDBPyConnection : public enable_shared_from_this<DuckDBPyConnection> {\n+struct ConnectionGuard {\n+public:\n+\tConnectionGuard() {\n+\t}\n+\t~ConnectionGuard() {\n+\t}\n+\n public:\n+\tDuckDB &GetDatabase() {\n+\t\tif (!database) {\n+\t\t\tThrowConnectionException();\n+\t\t}\n+\t\treturn *database;\n+\t}\n+\tconst DuckDB &GetDatabase() const {\n+\t\tif (!database) {\n+\t\t\tThrowConnectionException();\n+\t\t}\n+\t\treturn *database;\n+\t}\n+\tConnection &GetConnection() {\n+\t\tif (!connection) {\n+\t\t\tThrowConnectionException();\n+\t\t}\n+\t\treturn *connection;\n+\t}\n+\tconst Connection &GetConnection() const {\n+\t\tif (!connection) {\n+\t\t\tThrowConnectionException();\n+\t\t}\n+\t\treturn *connection;\n+\t}\n+\tDuckDBPyRelation &GetResult() {\n+\t\tif (!result) {\n+\t\t\tThrowConnectionException();\n+\t\t}\n+\t\treturn *result;\n+\t}\n+\tconst DuckDBPyRelation &GetResult() const {\n+\t\tif (!result) {\n+\t\t\tThrowConnectionException();\n+\t\t}\n+\t\treturn *result;\n+\t}\n+\n+public:\n+\tbool HasResult() const {\n+\t\treturn result != nullptr;\n+\t}\n+\n+public:\n+\tvoid SetDatabase(shared_ptr<DuckDB> db) {\n+\t\tdatabase = std::move(db);\n+\t}\n+\tvoid SetDatabase(ConnectionGuard &con) {\n+\t\tif (!con.database) {\n+\t\t\tThrowConnectionException();\n+\t\t}\n+\t\tdatabase = con.database;\n+\t}\n+\tvoid SetConnection(unique_ptr<Connection> con) {\n+\t\tconnection = std::move(con);\n+\t}\n+\tvoid SetResult(unique_ptr<DuckDBPyRelation> res) {\n+\t\tresult = std::move(res);\n+\t}\n+\n+private:\n+\tvoid ThrowConnectionException() const {\n+\t\tthrow ConnectionException(\"Connection already closed!\");\n+\t}\n+\n+private:\n \tshared_ptr<DuckDB> database;\n \tunique_ptr<Connection> connection;\n \tunique_ptr<DuckDBPyRelation> result;\n+};\n+\n+struct DuckDBPyConnection : public enable_shared_from_this<DuckDBPyConnection> {\n+public:\n+\tConnectionGuard con;\n \tvector<weak_ptr<DuckDBPyConnection>> cursors;\n \tunordered_map<string, shared_ptr<Relation>> temporary_views;\n \tstd::mutex py_connection_lock;\n@@ -204,7 +280,7 @@ struct DuckDBPyConnection : public enable_shared_from_this<DuckDBPyConnection> {\n \n \tpy::dict FetchNumpy();\n \tPandasDataFrame FetchDF(bool date_as_object);\n-\tPandasDataFrame FetchDFChunk(const idx_t vectors_per_chunk = 1, bool date_as_object = false) const;\n+\tPandasDataFrame FetchDFChunk(const idx_t vectors_per_chunk = 1, bool date_as_object = false);\n \n \tduckdb::pyarrow::Table FetchArrow(idx_t rows_per_batch);\n \tPolarsDataFrame FetchPolars(idx_t rows_per_batch);\n@@ -213,7 +289,7 @@ struct DuckDBPyConnection : public enable_shared_from_this<DuckDBPyConnection> {\n \n \tpy::dict FetchTF();\n \n-\tduckdb::pyarrow::RecordBatchReader FetchRecordBatchReader(const idx_t rows_per_batch) const;\n+\tduckdb::pyarrow::RecordBatchReader FetchRecordBatchReader(const idx_t rows_per_batch);\n \n \tstatic shared_ptr<DuckDBPyConnection> Connect(const py::object &database, bool read_only, const py::dict &config);\n \ndiff --git a/tools/pythonpkg/src/pyconnection.cpp b/tools/pythonpkg/src/pyconnection.cpp\nindex 19cd77a3c183..65015aeb6bc1 100644\n--- a/tools/pythonpkg/src/pyconnection.cpp\n+++ b/tools/pythonpkg/src/pyconnection.cpp\n@@ -72,8 +72,8 @@ DuckDBPyConnection::~DuckDBPyConnection() {\n \ttry {\n \t\tpy::gil_scoped_release gil;\n \t\t// Release any structures that do not need to hold the GIL here\n-\t\tdatabase.reset();\n-\t\tconnection.reset();\n+\t\tcon.SetDatabase(nullptr);\n+\t\tcon.SetConnection(nullptr);\n \t\ttemporary_views.clear();\n \t} catch (...) { // NOLINT\n \t}\n@@ -294,7 +294,8 @@ static void InitializeConnectionMethods(py::class_<DuckDBPyConnection, shared_pt\n } // END_OF_CONNECTION_METHODS\n \n void DuckDBPyConnection::UnregisterFilesystem(const py::str &name) {\n-\tauto &fs = database->GetFileSystem();\n+\tauto &database = con.GetDatabase();\n+\tauto &fs = database.GetFileSystem();\n \n \tfs.UnregisterSubSystem(name);\n }\n@@ -302,11 +303,12 @@ void DuckDBPyConnection::UnregisterFilesystem(const py::str &name) {\n void DuckDBPyConnection::RegisterFilesystem(AbstractFileSystem filesystem) {\n \tPythonGILWrapper gil_wrapper;\n \n+\tauto &database = con.GetDatabase();\n \tif (!py::isinstance<AbstractFileSystem>(filesystem)) {\n \t\tthrow InvalidInputException(\"Bad filesystem instance\");\n \t}\n \n-\tauto &fs = database->GetFileSystem();\n+\tauto &fs = database.GetFileSystem();\n \n \tauto protocol = filesystem.attr(\"protocol\");\n \tif (protocol.is_none() || py::str(\"abstract\").equal(protocol)) {\n@@ -326,7 +328,8 @@ void DuckDBPyConnection::RegisterFilesystem(AbstractFileSystem filesystem) {\n }\n \n py::list DuckDBPyConnection::ListFilesystems() {\n-\tauto subsystems = database->GetFileSystem().ListSubSystems();\n+\tauto &database = con.GetDatabase();\n+\tauto subsystems = database.GetFileSystem().ListSubSystems();\n \tpy::list names;\n \tfor (auto &name : subsystems) {\n \t\tnames.append(py::str(name));\n@@ -335,11 +338,9 @@ py::list DuckDBPyConnection::ListFilesystems() {\n }\n \n py::list DuckDBPyConnection::ExtractStatements(const string &query) {\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection already closed!\");\n-\t}\n \tpy::list result;\n-\tauto statements = connection->ExtractStatements(query);\n+\tauto &connection = con.GetConnection();\n+\tauto statements = connection.ExtractStatements(query);\n \tfor (auto &statement : statements) {\n \t\tresult.append(make_uniq<DuckDBPyStatement>(std::move(statement)));\n \t}\n@@ -347,14 +348,12 @@ py::list DuckDBPyConnection::ExtractStatements(const string &query) {\n }\n \n bool DuckDBPyConnection::FileSystemIsRegistered(const string &name) {\n-\tauto subsystems = database->GetFileSystem().ListSubSystems();\n+\tauto &database = con.GetDatabase();\n+\tauto subsystems = database.GetFileSystem().ListSubSystems();\n \treturn std::find(subsystems.begin(), subsystems.end(), name) != subsystems.end();\n }\n \n shared_ptr<DuckDBPyConnection> DuckDBPyConnection::UnregisterUDF(const string &name) {\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection already closed!\");\n-\t}\n \tauto entry = registered_functions.find(name);\n \tif (entry == registered_functions.end()) {\n \t\t// Not registered or already unregistered\n@@ -362,7 +361,8 @@ shared_ptr<DuckDBPyConnection> DuckDBPyConnection::UnregisterUDF(const string &n\n \t\t                            name);\n \t}\n \n-\tauto &context = *connection->context;\n+\tauto &connection = con.GetConnection();\n+\tauto &context = *connection.context;\n \n \tcontext.RunFunctionInTransaction([&]() {\n \t\t// create function\n@@ -385,10 +385,8 @@ DuckDBPyConnection::RegisterScalarUDF(const string &name, const py::function &ud\n                                       const shared_ptr<DuckDBPyType> &return_type_p, PythonUDFType type,\n                                       FunctionNullHandling null_handling, PythonExceptionHandling exception_handling,\n                                       bool side_effects) {\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection already closed!\");\n-\t}\n-\tauto &context = *connection->context;\n+\tauto &connection = con.GetConnection();\n+\tauto &context = *connection.context;\n \n \tif (context.transaction.HasActiveTransaction()) {\n \t\tthrow InvalidInputException(\n@@ -429,7 +427,7 @@ void DuckDBPyConnection::Initialize(py::handle &m) {\n }\n \n shared_ptr<DuckDBPyConnection> DuckDBPyConnection::ExecuteMany(const py::object &query, py::object params_p) {\n-\tresult.reset();\n+\tcon.SetResult(nullptr);\n \tif (params_p.is_none()) {\n \t\tparams_p = py::list();\n \t}\n@@ -465,7 +463,7 @@ shared_ptr<DuckDBPyConnection> DuckDBPyConnection::ExecuteMany(const py::object\n \t// Set the internal 'result' object\n \tif (query_result) {\n \t\tauto py_result = make_uniq<DuckDBPyResult>(std::move(query_result));\n-\t\tresult = make_uniq<DuckDBPyRelation>(std::move(py_result));\n+\t\tcon.SetResult(make_uniq<DuckDBPyRelation>(std::move(py_result)));\n \t}\n \n \treturn shared_from_this();\n@@ -547,12 +545,13 @@ case_insensitive_map_t<BoundParameterData> TransformPreparedParameters(PreparedS\n }\n \n unique_ptr<PreparedStatement> DuckDBPyConnection::PrepareQuery(unique_ptr<SQLStatement> statement) {\n+\tauto &connection = con.GetConnection();\n \tunique_ptr<PreparedStatement> prep;\n \t{\n \t\tpy::gil_scoped_release release;\n \t\tunique_lock<mutex> lock(py_connection_lock);\n \n-\t\tprep = connection->Prepare(std::move(statement));\n+\t\tprep = connection.Prepare(std::move(statement));\n \t\tif (prep->HasError()) {\n \t\t\tprep->error.Throw();\n \t\t}\n@@ -561,9 +560,6 @@ unique_ptr<PreparedStatement> DuckDBPyConnection::PrepareQuery(unique_ptr<SQLSta\n }\n \n unique_ptr<QueryResult> DuckDBPyConnection::ExecuteInternal(PreparedStatement &prep, py::object params) {\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection has already been closed\");\n-\t}\n \tif (params.is_none()) {\n \t\tparams = py::list();\n \t}\n@@ -587,9 +583,7 @@ unique_ptr<QueryResult> DuckDBPyConnection::ExecuteInternal(PreparedStatement &p\n \n vector<unique_ptr<SQLStatement>> DuckDBPyConnection::GetStatements(const py::object &query) {\n \tvector<unique_ptr<SQLStatement>> result;\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection has already been closed\");\n-\t}\n+\tauto &connection = con.GetConnection();\n \n \tshared_ptr<DuckDBPyStatement> statement_obj;\n \tif (py::try_cast(query, statement_obj)) {\n@@ -598,7 +592,7 @@ vector<unique_ptr<SQLStatement>> DuckDBPyConnection::GetStatements(const py::obj\n \t}\n \tif (py::isinstance<py::str>(query)) {\n \t\tauto sql_query = std::string(py::str(query));\n-\t\treturn connection->ExtractStatements(sql_query);\n+\t\treturn connection.ExtractStatements(sql_query);\n \t}\n \tthrow InvalidInputException(\"Please provide either a DuckDBPyStatement or a string representing the query\");\n }\n@@ -608,7 +602,7 @@ shared_ptr<DuckDBPyConnection> DuckDBPyConnection::ExecuteFromString(const strin\n }\n \n shared_ptr<DuckDBPyConnection> DuckDBPyConnection::Execute(const py::object &query, py::object params) {\n-\tresult.reset();\n+\tcon.SetResult(nullptr);\n \n \tauto statements = GetStatements(query);\n \tif (statements.empty()) {\n@@ -628,7 +622,7 @@ shared_ptr<DuckDBPyConnection> DuckDBPyConnection::Execute(const py::object &que\n \t// Set the internal 'result' object\n \tif (res) {\n \t\tauto py_result = make_uniq<DuckDBPyResult>(std::move(res));\n-\t\tresult = make_uniq<DuckDBPyRelation>(std::move(py_result));\n+\t\tcon.SetResult(make_uniq<DuckDBPyRelation>(std::move(py_result)));\n \t}\n \treturn shared_from_this();\n }\n@@ -659,17 +653,18 @@ shared_ptr<DuckDBPyConnection> DuckDBPyConnection::Append(const string &name, co\n }\n \n void DuckDBPyConnection::RegisterArrowObject(const py::object &arrow_object, const string &name) {\n+\tauto &connection = con.GetConnection();\n \tauto stream_factory =\n-\t    make_uniq<PythonTableArrowArrayStreamFactory>(arrow_object.ptr(), connection->context->GetClientProperties());\n+\t    make_uniq<PythonTableArrowArrayStreamFactory>(arrow_object.ptr(), connection.context->GetClientProperties());\n \tauto stream_factory_produce = PythonTableArrowArrayStreamFactory::Produce;\n \tauto stream_factory_get_schema = PythonTableArrowArrayStreamFactory::GetSchema;\n \t{\n \t\tpy::gil_scoped_release release;\n \t\ttemporary_views[name] =\n \t\t    connection\n-\t\t        ->TableFunction(\"arrow_scan\", {Value::POINTER(CastPointerToValue(stream_factory.get())),\n-\t\t                                       Value::POINTER(CastPointerToValue(stream_factory_produce)),\n-\t\t                                       Value::POINTER(CastPointerToValue(stream_factory_get_schema))})\n+\t\t        .TableFunction(\"arrow_scan\", {Value::POINTER(CastPointerToValue(stream_factory.get())),\n+\t\t                                      Value::POINTER(CastPointerToValue(stream_factory_produce)),\n+\t\t                                      Value::POINTER(CastPointerToValue(stream_factory_get_schema))})\n \t\t        ->CreateView(name, true, true);\n \t}\n \tvector<shared_ptr<ExternalDependency>> dependencies;\n@@ -678,14 +673,12 @@ void DuckDBPyConnection::RegisterArrowObject(const py::object &arrow_object, con\n \t    PythonDependencyItem::Create(make_uniq<RegisteredArrow>(std::move(stream_factory), arrow_object));\n \tdependency->AddDependency(\"object\", std::move(dependency_item));\n \tdependencies.push_back(std::move(dependency));\n-\tconnection->context->external_dependencies[name] = std::move(dependencies);\n+\tconnection.context->external_dependencies[name] = std::move(dependencies);\n }\n \n shared_ptr<DuckDBPyConnection> DuckDBPyConnection::RegisterPythonObject(const string &name,\n                                                                         const py::object &python_object) {\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection has already been closed\");\n-\t}\n+\tauto &connection = con.GetConnection();\n \n \tif (DuckDBPyConnection::IsPandasDataframe(python_object)) {\n \t\tif (PandasDataFrame::IsPyArrowBacked(python_object)) {\n@@ -696,7 +689,7 @@ shared_ptr<DuckDBPyConnection> DuckDBPyConnection::RegisterPythonObject(const st\n \t\t\t{\n \t\t\t\tpy::gil_scoped_release release;\n \t\t\t\ttemporary_views[name] =\n-\t\t\t\t    connection->TableFunction(\"pandas_scan\", {Value::POINTER(CastPointerToValue(new_df.ptr()))})\n+\t\t\t\t    connection.TableFunction(\"pandas_scan\", {Value::POINTER(CastPointerToValue(new_df.ptr()))})\n \t\t\t\t        ->CreateView(name, true, true);\n \t\t\t}\n \n@@ -706,7 +699,7 @@ shared_ptr<DuckDBPyConnection> DuckDBPyConnection::RegisterPythonObject(const st\n \n \t\t\tvector<shared_ptr<ExternalDependency>> dependencies;\n \t\t\tdependencies.push_back(std::move(dependency));\n-\t\t\tconnection->context->external_dependencies[name] = std::move(dependencies);\n+\t\t\tconnection.context->external_dependencies[name] = std::move(dependencies);\n \t\t}\n \t} else if (IsAcceptedArrowObject(python_object) || IsPolarsDataframe(python_object)) {\n \t\tpy::object arrow_object;\n@@ -725,7 +718,7 @@ shared_ptr<DuckDBPyConnection> DuckDBPyConnection::RegisterPythonObject(const st\n \t\tRegisterArrowObject(arrow_object, name);\n \t} else if (DuckDBPyRelation::IsRelation(python_object)) {\n \t\tauto pyrel = py::cast<DuckDBPyRelation *>(python_object);\n-\t\tif (!pyrel->CanBeRegisteredBy(*connection)) {\n+\t\tif (!pyrel->CanBeRegisteredBy(connection)) {\n \t\t\tthrow InvalidInputException(\n \t\t\t    \"The relation you are attempting to register was not made from this connection\");\n \t\t}\n@@ -790,12 +783,10 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::ReadJSON(\n     const Optional<py::object> &maximum_sample_files, const Optional<py::object> &filename,\n     const Optional<py::object> &hive_partitioning, const Optional<py::object> &union_by_name,\n     const Optional<py::object> &hive_types, const Optional<py::object> &hive_types_autocast) {\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection has already been closed\");\n-\t}\n \n \tnamed_parameter_map_t options;\n \n+\tauto &connection = con.GetConnection();\n \tParseMultiFileReaderOptions(options, filename, hive_partitioning, union_by_name, hive_types, hive_types_autocast);\n \n \tif (!py::none().is(columns)) {\n@@ -953,7 +944,7 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::ReadJSON(\n \t}\n \n \tauto read_json_relation =\n-\t    make_shared_ptr<ReadJSONRelation>(connection->context, name, std::move(options), auto_detect);\n+\t    make_shared_ptr<ReadJSONRelation>(connection.context, name, std::move(options), auto_detect);\n \tif (read_json_relation == nullptr) {\n \t\tthrow BinderException(\"read_json can only be used when the JSON extension is (statically) loaded\");\n \t}\n@@ -971,9 +962,8 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::ReadCSV(\n     const py::object &date_format, const py::object &timestamp_format, const py::object &sample_size,\n     const py::object &all_varchar, const py::object &normalize_names, const py::object &filename,\n     const py::object &null_padding, const py::object &names_p) {\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection has already been closed\");\n-\t}\n+\n+\tauto &connection = con.GetConnection();\n \tCSVReaderOptions options;\n \tauto path_like = GetPathLike(name_p);\n \tauto &name = path_like.files;\n@@ -1170,7 +1160,7 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::ReadCSV(\n \n \t// Create the ReadCSV Relation using the 'options'\n \n-\tauto read_csv_p = connection->ReadCSV(name, std::move(bind_parameters));\n+\tauto read_csv_p = connection.ReadCSV(name, std::move(bind_parameters));\n \tauto &read_csv = read_csv_p->Cast<ReadCSVRelation>();\n \tif (file_like_object_wrapper) {\n \t\tread_csv.AddExternalDependency(std::move(file_like_object_wrapper));\n@@ -1180,6 +1170,7 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::ReadCSV(\n }\n \n void DuckDBPyConnection::ExecuteImmediately(vector<unique_ptr<SQLStatement>> statements) {\n+\tauto &connection = con.GetConnection();\n \tif (statements.empty()) {\n \t\treturn;\n \t}\n@@ -1189,7 +1180,7 @@ void DuckDBPyConnection::ExecuteImmediately(vector<unique_ptr<SQLStatement>> sta\n \t\t\t    \"Prepared parameters are only supported for the last statement, please split your query up into \"\n \t\t\t    \"separate 'execute' calls if you want to use prepared parameters\");\n \t\t}\n-\t\tauto pending_query = connection->PendingQuery(std::move(stmt), false);\n+\t\tauto pending_query = connection.PendingQuery(std::move(stmt), false);\n \t\tauto res = CompletePendingQuery(*pending_query);\n \n \t\tif (res->HasError()) {\n@@ -1199,9 +1190,7 @@ void DuckDBPyConnection::ExecuteImmediately(vector<unique_ptr<SQLStatement>> sta\n }\n \n unique_ptr<DuckDBPyRelation> DuckDBPyConnection::RunQuery(const py::object &query, string alias, py::object params) {\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection has already been closed\");\n-\t}\n+\tauto &connection = con.GetConnection();\n \tif (alias.empty()) {\n \t\talias = \"unnamed_relation_\" + StringUtil::GenerateRandomName(16);\n \t}\n@@ -1225,7 +1214,7 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::RunQuery(const py::object &quer\n \t\tswitch (statement_type) {\n \t\tcase StatementType::SELECT_STATEMENT: {\n \t\t\tauto select_statement = unique_ptr_cast<SQLStatement, SelectStatement>(std::move(last_statement));\n-\t\t\trelation = connection->RelationFromQuery(std::move(select_statement), alias);\n+\t\t\trelation = connection.RelationFromQuery(std::move(select_statement), alias);\n \t\t\tbreak;\n \t\t}\n \t\tdefault:\n@@ -1248,22 +1237,20 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::RunQuery(const py::object &quer\n \t\t\tres = stream_result.Materialize();\n \t\t}\n \t\tauto &materialized_result = res->Cast<MaterializedQueryResult>();\n-\t\trelation = make_shared_ptr<MaterializedRelation>(connection->context, materialized_result.TakeCollection(),\n+\t\trelation = make_shared_ptr<MaterializedRelation>(connection.context, materialized_result.TakeCollection(),\n \t\t                                                 res->names, alias);\n \t}\n \treturn make_uniq<DuckDBPyRelation>(std::move(relation));\n }\n \n unique_ptr<DuckDBPyRelation> DuckDBPyConnection::Table(const string &tname) {\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection has already been closed\");\n-\t}\n+\tauto &connection = con.GetConnection();\n \tauto qualified_name = QualifiedName::Parse(tname);\n \tif (qualified_name.schema.empty()) {\n \t\tqualified_name.schema = DEFAULT_SCHEMA;\n \t}\n \ttry {\n-\t\treturn make_uniq<DuckDBPyRelation>(connection->Table(qualified_name.schema, qualified_name.name));\n+\t\treturn make_uniq<DuckDBPyRelation>(connection.Table(qualified_name.schema, qualified_name.name));\n \t} catch (const CatalogException &) {\n \t\t// CatalogException will be of the type '... is not a table'\n \t\t// Not a table in the database, make a query relation that can perform replacement scans\n@@ -1273,9 +1260,7 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::Table(const string &tname) {\n }\n \n unique_ptr<DuckDBPyRelation> DuckDBPyConnection::Values(py::object params) {\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection has already been closed\");\n-\t}\n+\tauto &connection = con.GetConnection();\n \tif (params.is_none()) {\n \t\tparams = py::list();\n \t}\n@@ -1283,39 +1268,33 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::Values(py::object params) {\n \t\tthrow InvalidInputException(\"Type of object passed to parameter 'values' must be iterable\");\n \t}\n \tvector<vector<Value>> values {DuckDBPyConnection::TransformPythonParamList(params)};\n-\treturn make_uniq<DuckDBPyRelation>(connection->Values(values));\n+\treturn make_uniq<DuckDBPyRelation>(connection.Values(values));\n }\n \n unique_ptr<DuckDBPyRelation> DuckDBPyConnection::View(const string &vname) {\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection has already been closed\");\n-\t}\n+\tauto &connection = con.GetConnection();\n \t// First check our temporary view\n \tif (temporary_views.find(vname) != temporary_views.end()) {\n \t\treturn make_uniq<DuckDBPyRelation>(temporary_views[vname]);\n \t}\n-\treturn make_uniq<DuckDBPyRelation>(connection->View(vname));\n+\treturn make_uniq<DuckDBPyRelation>(connection.View(vname));\n }\n \n unique_ptr<DuckDBPyRelation> DuckDBPyConnection::TableFunction(const string &fname, py::object params) {\n+\tauto &connection = con.GetConnection();\n \tif (params.is_none()) {\n \t\tparams = py::list();\n \t}\n \tif (!py::is_list_like(params)) {\n \t\tthrow InvalidInputException(\"'params' has to be a list of parameters\");\n \t}\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection has already been closed\");\n-\t}\n \n \treturn make_uniq<DuckDBPyRelation>(\n-\t    connection->TableFunction(fname, DuckDBPyConnection::TransformPythonParamList(params)));\n+\t    connection.TableFunction(fname, DuckDBPyConnection::TransformPythonParamList(params)));\n }\n \n unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromDF(const PandasDataFrame &value) {\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection has already been closed\");\n-\t}\n+\tauto &connection = con.GetConnection();\n \tstring name = \"df_\" + StringUtil::GenerateRandomName();\n \tif (PandasDataFrame::IsPyArrowBacked(value)) {\n \t\tauto table = PandasDataFrame::ToArrowTable(value);\n@@ -1324,7 +1303,7 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromDF(const PandasDataFrame &v\n \tauto new_df = PandasScanFunction::PandasReplaceCopiedNames(value);\n \tvector<Value> params;\n \tparams.emplace_back(Value::POINTER(CastPointerToValue(new_df.ptr())));\n-\tauto rel = connection->TableFunction(\"pandas_scan\", params)->Alias(name);\n+\tauto rel = connection.TableFunction(\"pandas_scan\", params)->Alias(name);\n \tauto dependency = make_shared_ptr<ExternalDependency>();\n \tdependency->AddDependency(\"original\", PythonDependencyItem::Create(value));\n \tdependency->AddDependency(\"copy\", PythonDependencyItem::Create(new_df));\n@@ -1336,9 +1315,7 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromParquet(const string &file_\n                                                              bool file_row_number, bool filename,\n                                                              bool hive_partitioning, bool union_by_name,\n                                                              const py::object &compression) {\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection has already been closed\");\n-\t}\n+\tauto &connection = con.GetConnection();\n \tstring name = \"parquet_\" + StringUtil::GenerateRandomName();\n \tvector<Value> params;\n \tparams.emplace_back(file_glob);\n@@ -1354,17 +1331,14 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromParquet(const string &file_\n \t\t}\n \t\tnamed_parameters[\"compression\"] = Value(py::str(compression));\n \t}\n-\treturn make_uniq<DuckDBPyRelation>(\n-\t    connection->TableFunction(\"parquet_scan\", params, named_parameters)->Alias(name));\n+\treturn make_uniq<DuckDBPyRelation>(connection.TableFunction(\"parquet_scan\", params, named_parameters)->Alias(name));\n }\n \n unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromParquets(const vector<string> &file_globs, bool binary_as_string,\n                                                               bool file_row_number, bool filename,\n                                                               bool hive_partitioning, bool union_by_name,\n                                                               const py::object &compression) {\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection has already been closed\");\n-\t}\n+\tauto &connection = con.GetConnection();\n \tstring name = \"parquet_\" + StringUtil::GenerateRandomName();\n \tvector<Value> params;\n \tauto file_globs_as_value = vector<Value>();\n@@ -1385,14 +1359,11 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromParquets(const vector<strin\n \t\tnamed_parameters[\"compression\"] = Value(py::str(compression));\n \t}\n \n-\treturn make_uniq<DuckDBPyRelation>(\n-\t    connection->TableFunction(\"parquet_scan\", params, named_parameters)->Alias(name));\n+\treturn make_uniq<DuckDBPyRelation>(connection.TableFunction(\"parquet_scan\", params, named_parameters)->Alias(name));\n }\n \n unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromArrow(py::object &arrow_object) {\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection has already been closed\");\n-\t}\n+\tauto &connection = con.GetConnection();\n \tpy::gil_scoped_acquire acquire;\n \tstring name = \"arrow_object_\" + StringUtil::GenerateRandomName();\n \tif (!IsAcceptedArrowObject(arrow_object)) {\n@@ -1400,15 +1371,15 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromArrow(py::object &arrow_obj\n \t\tthrow InvalidInputException(\"Python Object Type %s is not an accepted Arrow Object.\", py_object_type);\n \t}\n \tauto stream_factory =\n-\t    make_uniq<PythonTableArrowArrayStreamFactory>(arrow_object.ptr(), connection->context->GetClientProperties());\n+\t    make_uniq<PythonTableArrowArrayStreamFactory>(arrow_object.ptr(), connection.context->GetClientProperties());\n \n \tauto stream_factory_produce = PythonTableArrowArrayStreamFactory::Produce;\n \tauto stream_factory_get_schema = PythonTableArrowArrayStreamFactory::GetSchema;\n \n \tauto rel = connection\n-\t               ->TableFunction(\"arrow_scan\", {Value::POINTER(CastPointerToValue(stream_factory.get())),\n-\t                                              Value::POINTER(CastPointerToValue(stream_factory_produce)),\n-\t                                              Value::POINTER(CastPointerToValue(stream_factory_get_schema))})\n+\t               .TableFunction(\"arrow_scan\", {Value::POINTER(CastPointerToValue(stream_factory.get())),\n+\t                                             Value::POINTER(CastPointerToValue(stream_factory_produce)),\n+\t                                             Value::POINTER(CastPointerToValue(stream_factory_get_schema))})\n \t               ->Alias(name);\n \tauto dependency = make_shared_ptr<ExternalDependency>();\n \tauto dependency_item =\n@@ -1419,61 +1390,50 @@ unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromArrow(py::object &arrow_obj\n }\n \n unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromSubstrait(py::bytes &proto) {\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection has already been closed\");\n-\t}\n+\tauto &connection = con.GetConnection();\n \tstring name = \"substrait_\" + StringUtil::GenerateRandomName();\n \tvector<Value> params;\n \tparams.emplace_back(Value::BLOB_RAW(proto));\n-\treturn make_uniq<DuckDBPyRelation>(connection->TableFunction(\"from_substrait\", params)->Alias(name));\n+\treturn make_uniq<DuckDBPyRelation>(connection.TableFunction(\"from_substrait\", params)->Alias(name));\n }\n \n unique_ptr<DuckDBPyRelation> DuckDBPyConnection::GetSubstrait(const string &query, bool enable_optimizer) {\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection has already been closed\");\n-\t}\n+\tauto &connection = con.GetConnection();\n \tvector<Value> params;\n \tparams.emplace_back(query);\n \tnamed_parameter_map_t named_parameters({{\"enable_optimizer\", Value::BOOLEAN(enable_optimizer)}});\n \treturn make_uniq<DuckDBPyRelation>(\n-\t    connection->TableFunction(\"get_substrait\", params, named_parameters)->Alias(query));\n+\t    connection.TableFunction(\"get_substrait\", params, named_parameters)->Alias(query));\n }\n \n unique_ptr<DuckDBPyRelation> DuckDBPyConnection::GetSubstraitJSON(const string &query, bool enable_optimizer) {\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection has already been closed\");\n-\t}\n+\tauto &connection = con.GetConnection();\n \tvector<Value> params;\n \tparams.emplace_back(query);\n \tnamed_parameter_map_t named_parameters({{\"enable_optimizer\", Value::BOOLEAN(enable_optimizer)}});\n \treturn make_uniq<DuckDBPyRelation>(\n-\t    connection->TableFunction(\"get_substrait_json\", params, named_parameters)->Alias(query));\n+\t    connection.TableFunction(\"get_substrait_json\", params, named_parameters)->Alias(query));\n }\n \n unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromSubstraitJSON(const string &json) {\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection has already been closed\");\n-\t}\n+\tauto &connection = con.GetConnection();\n \tstring name = \"from_substrait_\" + StringUtil::GenerateRandomName();\n \tvector<Value> params;\n \tparams.emplace_back(json);\n-\treturn make_uniq<DuckDBPyRelation>(connection->TableFunction(\"from_substrait_json\", params)->Alias(name));\n+\treturn make_uniq<DuckDBPyRelation>(connection.TableFunction(\"from_substrait_json\", params)->Alias(name));\n }\n \n unordered_set<string> DuckDBPyConnection::GetTableNames(const string &query) {\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection has already been closed\");\n-\t}\n-\treturn connection->GetTableNames(query);\n+\tauto &connection = con.GetConnection();\n+\treturn connection.GetTableNames(query);\n }\n \n shared_ptr<DuckDBPyConnection> DuckDBPyConnection::UnregisterPythonObject(const string &name) {\n-\tconnection->context->external_dependencies.erase(name);\n+\tauto &connection = con.GetConnection();\n+\tconnection.context->external_dependencies.erase(name);\n \ttemporary_views.erase(name);\n \tpy::gil_scoped_release release;\n-\tif (connection) {\n-\t\tconnection->Query(\"DROP VIEW \\\"\" + name + \"\\\"\");\n-\t}\n+\tconnection.Query(\"DROP VIEW \\\"\" + name + \"\\\"\");\n \treturn shared_from_this();\n }\n \n@@ -1483,7 +1443,8 @@ shared_ptr<DuckDBPyConnection> DuckDBPyConnection::Begin() {\n }\n \n shared_ptr<DuckDBPyConnection> DuckDBPyConnection::Commit() {\n-\tif (connection->context->transaction.IsAutoCommit()) {\n+\tauto &connection = con.GetConnection();\n+\tif (connection.context->transaction.IsAutoCommit()) {\n \t\treturn shared_from_this();\n \t}\n \tExecuteFromString(\"COMMIT\");\n@@ -1501,10 +1462,11 @@ shared_ptr<DuckDBPyConnection> DuckDBPyConnection::Checkpoint() {\n }\n \n Optional<py::list> DuckDBPyConnection::GetDescription() {\n-\tif (!result) {\n+\tif (!con.HasResult()) {\n \t\treturn py::none();\n \t}\n-\treturn result->Description();\n+\tauto &result = con.GetResult();\n+\treturn result.Description();\n }\n \n int DuckDBPyConnection::GetRowcount() {\n@@ -1512,9 +1474,9 @@ int DuckDBPyConnection::GetRowcount() {\n }\n \n void DuckDBPyConnection::Close() {\n-\tresult = nullptr;\n-\tconnection = nullptr;\n-\tdatabase = nullptr;\n+\tcon.SetResult(nullptr);\n+\tcon.SetConnection(nullptr);\n+\tcon.SetDatabase(nullptr);\n \ttemporary_views.clear();\n \t// https://peps.python.org/pep-0249/#Connection.close\n \tfor (auto &cur : cursors) {\n@@ -1530,94 +1492,100 @@ void DuckDBPyConnection::Close() {\n }\n \n void DuckDBPyConnection::Interrupt() {\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection has already been closed\");\n-\t}\n-\tconnection->Interrupt();\n+\tauto &connection = con.GetConnection();\n+\tconnection.Interrupt();\n }\n \n void DuckDBPyConnection::InstallExtension(const string &extension, bool force_install) {\n-\tExtensionHelper::InstallExtension(*connection->context, extension, force_install);\n+\tauto &connection = con.GetConnection();\n+\tExtensionHelper::InstallExtension(*connection.context, extension, force_install);\n }\n \n void DuckDBPyConnection::LoadExtension(const string &extension) {\n-\tExtensionHelper::LoadExternalExtension(*connection->context, extension);\n+\tauto &connection = con.GetConnection();\n+\tExtensionHelper::LoadExternalExtension(*connection.context, extension);\n }\n \n // cursor() is stupid\n shared_ptr<DuckDBPyConnection> DuckDBPyConnection::Cursor() {\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection has already been closed\");\n-\t}\n \tauto res = make_shared_ptr<DuckDBPyConnection>();\n-\tres->database = database;\n-\tres->connection = make_uniq<Connection>(*res->database);\n+\tres->con.SetDatabase(con);\n+\tres->con.SetConnection(make_uniq<Connection>(res->con.GetDatabase()));\n \tcursors.push_back(res);\n \treturn res;\n }\n \n // these should be functions on the result but well\n Optional<py::tuple> DuckDBPyConnection::FetchOne() {\n-\tif (!result) {\n+\tif (!con.HasResult()) {\n \t\tthrow InvalidInputException(\"No open result set\");\n \t}\n-\treturn result->FetchOne();\n+\tauto &result = con.GetResult();\n+\treturn result.FetchOne();\n }\n \n py::list DuckDBPyConnection::FetchMany(idx_t size) {\n-\tif (!result) {\n+\tif (!con.HasResult()) {\n \t\tthrow InvalidInputException(\"No open result set\");\n \t}\n-\treturn result->FetchMany(size);\n+\tauto &result = con.GetResult();\n+\treturn result.FetchMany(size);\n }\n \n py::list DuckDBPyConnection::FetchAll() {\n-\tif (!result) {\n+\tif (!con.HasResult()) {\n \t\tthrow InvalidInputException(\"No open result set\");\n \t}\n-\treturn result->FetchAll();\n+\tauto &result = con.GetResult();\n+\treturn result.FetchAll();\n }\n \n py::dict DuckDBPyConnection::FetchNumpy() {\n-\tif (!result) {\n+\tif (!con.HasResult()) {\n \t\tthrow InvalidInputException(\"No open result set\");\n \t}\n-\treturn result->FetchNumpyInternal();\n+\tauto &result = con.GetResult();\n+\treturn result.FetchNumpyInternal();\n }\n \n PandasDataFrame DuckDBPyConnection::FetchDF(bool date_as_object) {\n-\tif (!result) {\n+\tif (!con.HasResult()) {\n \t\tthrow InvalidInputException(\"No open result set\");\n \t}\n-\treturn result->FetchDF(date_as_object);\n+\tauto &result = con.GetResult();\n+\treturn result.FetchDF(date_as_object);\n }\n \n-PandasDataFrame DuckDBPyConnection::FetchDFChunk(const idx_t vectors_per_chunk, bool date_as_object) const {\n-\tif (!result) {\n+PandasDataFrame DuckDBPyConnection::FetchDFChunk(const idx_t vectors_per_chunk, bool date_as_object) {\n+\tif (!con.HasResult()) {\n \t\tthrow InvalidInputException(\"No open result set\");\n \t}\n-\treturn result->FetchDFChunk(vectors_per_chunk, date_as_object);\n+\tauto &result = con.GetResult();\n+\treturn result.FetchDFChunk(vectors_per_chunk, date_as_object);\n }\n \n duckdb::pyarrow::Table DuckDBPyConnection::FetchArrow(idx_t rows_per_batch) {\n-\tif (!result) {\n+\tif (!con.HasResult()) {\n \t\tthrow InvalidInputException(\"No open result set\");\n \t}\n-\treturn result->ToArrowTable(rows_per_batch);\n+\tauto &result = con.GetResult();\n+\treturn result.ToArrowTable(rows_per_batch);\n }\n \n py::dict DuckDBPyConnection::FetchPyTorch() {\n-\tif (!result) {\n+\tif (!con.HasResult()) {\n \t\tthrow InvalidInputException(\"No open result set\");\n \t}\n-\treturn result->FetchPyTorch();\n+\tauto &result = con.GetResult();\n+\treturn result.FetchPyTorch();\n }\n \n py::dict DuckDBPyConnection::FetchTF() {\n-\tif (!result) {\n+\tif (!con.HasResult()) {\n \t\tthrow InvalidInputException(\"No open result set\");\n \t}\n-\treturn result->FetchTF();\n+\tauto &result = con.GetResult();\n+\treturn result.FetchTF();\n }\n \n PolarsDataFrame DuckDBPyConnection::FetchPolars(idx_t rows_per_batch) {\n@@ -1625,11 +1593,12 @@ PolarsDataFrame DuckDBPyConnection::FetchPolars(idx_t rows_per_batch) {\n \treturn py::cast<PolarsDataFrame>(py::module::import(\"polars\").attr(\"DataFrame\")(arrow));\n }\n \n-duckdb::pyarrow::RecordBatchReader DuckDBPyConnection::FetchRecordBatchReader(const idx_t rows_per_batch) const {\n-\tif (!result) {\n+duckdb::pyarrow::RecordBatchReader DuckDBPyConnection::FetchRecordBatchReader(const idx_t rows_per_batch) {\n+\tif (!con.HasResult()) {\n \t\tthrow InvalidInputException(\"No open result set\");\n \t}\n-\treturn result->FetchRecordBatchReader(rows_per_batch);\n+\tauto &result = con.GetResult();\n+\treturn result.FetchRecordBatchReader(rows_per_batch);\n }\n \n case_insensitive_map_t<Value> TransformPyConfigDict(const py::dict &py_config_dict) {\n@@ -1646,9 +1615,9 @@ void CreateNewInstance(DuckDBPyConnection &res, const string &database, DBConfig\n \t// We don't cache unnamed memory instances (i.e., :memory:)\n \tbool cache_instance = database != \":memory:\" && !database.empty();\n \tconfig.replacement_scans.emplace_back(PythonReplacementScan::Replace);\n-\tres.database = instance_cache.CreateInstance(database, config, cache_instance);\n-\tres.connection = make_uniq<Connection>(*res.database);\n-\tauto &context = *res.connection->context;\n+\tres.con.SetDatabase(instance_cache.CreateInstance(database, config, cache_instance));\n+\tres.con.SetConnection(make_uniq<Connection>(res.con.GetDatabase()));\n+\tauto &context = *res.con.GetConnection().context;\n \tPandasScanFunction scan_fun;\n \tCreateTableFunctionInfo scan_info(scan_fun);\n \tMapFunction map_fun;\n@@ -1693,15 +1662,16 @@ static void SetDefaultConfigArguments(ClientContext &context) {\n \tcontext.config.display_create_func = JupyterProgressBarDisplay::Create;\n }\n \n-static shared_ptr<DuckDBPyConnection> FetchOrCreateInstance(const string &database, DBConfig &config) {\n+static shared_ptr<DuckDBPyConnection> FetchOrCreateInstance(const string &database_path, DBConfig &config) {\n \tauto res = make_shared_ptr<DuckDBPyConnection>();\n-\tres->database = instance_cache.GetInstance(database, config);\n-\tif (!res->database) {\n+\tauto database = instance_cache.GetInstance(database_path, config);\n+\tif (!database) {\n \t\t//! No cached database, we must create a new instance\n-\t\tCreateNewInstance(*res, database, config);\n+\t\tCreateNewInstance(*res, database_path, config);\n \t\treturn res;\n \t}\n-\tres->connection = make_uniq<Connection>(*res->database);\n+\tres->con.SetDatabase(std::move(database));\n+\tres->con.SetConnection(make_uniq<Connection>(res->con.GetDatabase()));\n \treturn res;\n }\n \n@@ -1750,7 +1720,7 @@ shared_ptr<DuckDBPyConnection> DuckDBPyConnection::Connect(const py::object &dat\n \tconfig.SetOptionsByName(config_dict);\n \n \tauto res = FetchOrCreateInstance(database, config);\n-\tauto &client_context = *res->connection->context;\n+\tauto &client_context = *res->con.GetConnection().context;\n \tSetDefaultConfigArguments(client_context);\n \treturn res;\n }\ndiff --git a/tools/pythonpkg/src/pyconnection/type_creation.cpp b/tools/pythonpkg/src/pyconnection/type_creation.cpp\nindex 733d30a7979f..f1839feefadf 100644\n--- a/tools/pythonpkg/src/pyconnection/type_creation.cpp\n+++ b/tools/pythonpkg/src/pyconnection/type_creation.cpp\n@@ -93,10 +93,8 @@ shared_ptr<DuckDBPyType> DuckDBPyConnection::StringType(const string &collation)\n }\n \n shared_ptr<DuckDBPyType> DuckDBPyConnection::Type(const string &type_str) {\n-\tif (!connection) {\n-\t\tthrow ConnectionException(\"Connection already closed!\");\n-\t}\n-\tauto &context = *connection->context;\n+\tauto &connection = con.GetConnection();\n+\tauto &context = *connection.context;\n \tshared_ptr<DuckDBPyType> result;\n \tcontext.RunFunctionInTransaction([&result, &type_str, &context]() {\n \t\tresult = make_shared_ptr<DuckDBPyType>(TransformStringToLogicalType(type_str, context));\ndiff --git a/tools/pythonpkg/src/python_udf.cpp b/tools/pythonpkg/src/python_udf.cpp\nindex b24bfb05c95b..53e3eb72c6c9 100644\n--- a/tools/pythonpkg/src/python_udf.cpp\n+++ b/tools/pythonpkg/src/python_udf.cpp\n@@ -358,12 +358,13 @@ ScalarFunction DuckDBPyConnection::CreateScalarUDF(const string &name, const py:\n                                                    FunctionNullHandling null_handling,\n                                                    PythonExceptionHandling exception_handling, bool side_effects) {\n \tPythonUDFData data(name, vectorized, null_handling);\n+\tauto &connection = con.GetConnection();\n \n \tdata.AnalyzeSignature(udf);\n \tdata.OverrideParameters(parameters);\n \tdata.OverrideReturnType(return_type);\n \tdata.Verify();\n-\treturn data.GetFunction(udf, exception_handling, side_effects, connection->context->GetClientProperties());\n+\treturn data.GetFunction(udf, exception_handling, side_effects, connection.context->GetClientProperties());\n }\n \n } // namespace duckdb\ndiff --git a/tools/pythonpkg/src/typing/pytype.cpp b/tools/pythonpkg/src/typing/pytype.cpp\nindex 529c8a043683..39172a12eb4a 100644\n--- a/tools/pythonpkg/src/typing/pytype.cpp\n+++ b/tools/pythonpkg/src/typing/pytype.cpp\n@@ -114,11 +114,12 @@ static PythonTypeObject GetTypeObjectType(const py::handle &type_object) {\n \treturn PythonTypeObject::INVALID;\n }\n \n-static LogicalType FromString(const string &type_str, shared_ptr<DuckDBPyConnection> connection) {\n-\tif (!connection) {\n-\t\tconnection = DuckDBPyConnection::DefaultConnection();\n+static LogicalType FromString(const string &type_str, shared_ptr<DuckDBPyConnection> pycon) {\n+\tif (!pycon) {\n+\t\tpycon = DuckDBPyConnection::DefaultConnection();\n \t}\n-\treturn TransformStringToLogicalType(type_str, *connection->connection->context);\n+\tauto &connection = pycon->con.GetConnection();\n+\treturn TransformStringToLogicalType(type_str, *connection.context);\n }\n \n static bool FromNumpyType(const py::object &type, LogicalType &result) {\n",
  "test_patch": "diff --git a/tools/pythonpkg/tests/fast/test_get_table_names.py b/tools/pythonpkg/tests/fast/test_get_table_names.py\nindex 968a13c49a9f..00752d184358 100644\n--- a/tools/pythonpkg/tests/fast/test_get_table_names.py\n+++ b/tools/pythonpkg/tests/fast/test_get_table_names.py\n@@ -11,5 +11,5 @@ def test_table_success(self, duckdb_cursor):\n     def test_table_fail(self, duckdb_cursor):\n         conn = duckdb.connect()\n         conn.close()\n-        with pytest.raises(duckdb.ConnectionException, match=\"Connection has already been closed\"):\n+        with pytest.raises(duckdb.ConnectionException, match=\"Connection already closed\"):\n             table_names = conn.get_table_names(\"SELECT * FROM my_table1, my_table2, my_table3\")\ndiff --git a/tools/pythonpkg/tests/fast/test_runtime_error.py b/tools/pythonpkg/tests/fast/test_runtime_error.py\nindex 9f1f5378c5e4..98c5a332bda5 100644\n--- a/tools/pythonpkg/tests/fast/test_runtime_error.py\n+++ b/tools/pythonpkg/tests/fast/test_runtime_error.py\n@@ -2,7 +2,7 @@\n import pytest\n from conftest import NumpyPandas, ArrowPandas\n \n-closed = lambda: pytest.raises(duckdb.ConnectionException, match='Connection has already been closed')\n+closed = lambda: pytest.raises(duckdb.ConnectionException, match='Connection already closed')\n no_result_set = lambda: pytest.raises(duckdb.InvalidInputException, match='No open result set')\n \n \n",
  "problem_statement": "InternalException: INTERNAL Error: Attempted to dereference unique_ptr that is NULL!\n### What happens?\n\nAfter closing my connection on my Python client, connecting and writing to it causes this error. If I am understanding correctly, this shouldn't happen since I am reopening the connection and therefore it should allow a write.\n\n### To Reproduce\n\n```\r\nimport duckdb\r\nschema = {\r\n            \"doc_id\": \"VARCHAR\",\r\n            \"embeddings\": \"FLOAT[384]\",\r\n            \"properties\": \"MAP(VARCHAR, VARCHAR)\",\r\n            \"text_representation\": \"VARCHAR\",\r\n            \"bbox\": \"DOUBLE[]\",\r\n            \"shingles\": \"BIGINT[]\",\r\n            \"type\": \"VARCHAR\",\r\n        }\r\nin_memory_db = duckdb.connect(\":default:\")\r\nin_memory_db.execute(f\"\"\"CREATE TABLE in_memory_table (doc_id {schema.get('doc_id')},\r\n                      embeddings {schema.get('embeddings')}, properties {schema.get('properties')}, \r\n                      text_representation {schema.get('text_representation')}, bbox {schema.get('bbox')}, \r\n                      shingles {schema.get('shingles')}, type {schema.get('type')})\"\"\"\r\nin_memory_db.close()\r\nin_memory_db = duckdb.connect(\":default:\")\r\nin_memory_db.execute(f\"\"\"CREATE TABLE in_memory_table (doc_id {schema.get('doc_id')},\r\n                      embeddings {schema.get('embeddings')}, properties {schema.get('properties')}, \r\n                      text_representation {schema.get('text_representation')}, bbox {schema.get('bbox')}, \r\n                      shingles {schema.get('shingles')}, type {schema.get('type')})\"\"\"\r\n```\n\n### OS:\n\narm64\n\n### DuckDB Version:\n\n1.0.0\n\n### DuckDB Client:\n\nPython\n\n### Full Name:\n\nKaran Sampath\n\n### Affiliation:\n\nAryn AI\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNo - I cannot share the data sets because they are confidential\n\n### Did you include all code required to reproduce the issue?\n\n- [X] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [X] Yes, I have\n",
  "hints_text": "I can't reproduce this on `main`\r\n\r\n```\r\n\u279c  duckdb git:(main) \u2717 python3 tmp/default_connection_close.py\r\nTraceback (most recent call last):\r\n  File \"/Users/thijs/DuckDBLabs/duckdb/tmp/default_connection_close.py\", line 18, in <module>\r\n    in_memory_db.execute(f\"\"\"CREATE TABLE in_memory_table (doc_id {schema.get('doc_id')},\r\nduckdb.duckdb.ConnectionException: Connection Error: Connection has already been closed\r\n```\r\n\r\nThis is expected behavior, `:default:` allows you to connect to the default connection, the one that is started by default as part of the `duckdb` module\r\n\r\nThis connection enables the use of `duckdb.execute` `duckdb.sql` etc.. without explicitly starting a connection.\r\nWhat `:default:` is used for is to be able to use this connection string with packages like SQLAlchemy so any tables/views you created in the default connection can be used through those packages as well.\r\n\r\nFor more information, see:\r\n<https://duckdb.org/docs/api/python/dbapi#default-connection>\n@karansampath even with `pip install duckdb==1.0.0` I can not reproduce the InternalException from the script you provided.\r\nCan you please double check if the reproduction is correct?\nHi @Tishj, please find the full code below, I missed a line which should hopefully make it reproducible now. The full error is as follows:\r\n`InternalException: INTERNAL Error: Attempted to dereference unique_ptr that is NULL!\r\nThis error signals an assertion failure within DuckDB. This usually occurs due to unexpected conditions or errors in the program's logic.\r\nFor more information, see https://duckdb.org/docs/dev/internal_errors\r\n`\r\n\r\nThe code is below:\r\n```\r\nschema = {\r\n            \"doc_id\": \"VARCHAR\",\r\n            \"embeddings\": \"FLOAT[384]\",\r\n            \"properties\": \"MAP(VARCHAR, VARCHAR)\",\r\n            \"text_representation\": \"VARCHAR\",\r\n            \"bbox\": \"DOUBLE[]\",\r\n            \"shingles\": \"BIGINT[]\",\r\n            \"type\": \"VARCHAR\",\r\n        }\r\nin_memory_db = duckdb.connect(\":default:\")\r\nin_memory_db.install_extension(\"vss\")\r\nin_memory_db.load_extension(\"vss\")\r\nin_memory_db.execute(f\"\"\"CREATE TABLE in_memory_table (doc_id {schema.get('doc_id')},\r\n                      embeddings {schema.get('embeddings')}, properties {schema.get('properties')}, \r\n                      text_representation {schema.get('text_representation')}, bbox {schema.get('bbox')}, \r\n                      shingles {schema.get('shingles')}, type {schema.get('type')})\"\"\"\r\n    )\r\nin_memory_db.execute(\"\"\"INSERT INTO in_memory_table SELECT * FROM df; \r\n                      CREATE INDEX in_memory_table_index ON in_memory_table USING HNSW(embeddings)\"\"\")\r\nin_memory_db.sql(f\"ALTER TABLE in_memory_table ADD COLUMN metadata VARCHAR\")\r\nin_memory_db.close()\r\nin_memory_db = duckdb.connect(\":default:\")\r\nin_memory_db.install_extension(\"vss\")\r\n```\r\nIt fails on the last line for me.\nThanks, that makes it reproducable for me\r\nI know what the issue is, and there are likely other places that suffer from this, I have worked on a generic fix that should cover all of those \ud83d\udc4d ",
  "created_at": "2024-07-05T12:13:23Z"
}