{
  "repo": "duckdb/duckdb",
  "pull_number": 308,
  "instance_id": "duckdb__duckdb-308",
  "issue_numbers": [
    "108"
  ],
  "base_commit": "aec86f63a9882df7f10df3a4ab52607b8fd39aa1",
  "patch": "diff --git a/src/execution/operator/persistent/buffered_csv_reader.cpp b/src/execution/operator/persistent/buffered_csv_reader.cpp\nindex fd779cbf5c86..7d00e323d268 100644\n--- a/src/execution/operator/persistent/buffered_csv_reader.cpp\n+++ b/src/execution/operator/persistent/buffered_csv_reader.cpp\n@@ -9,6 +9,8 @@\n \n #include <algorithm>\n #include <fstream>\n+#include <queue>\n+#include <cstring>\n \n using namespace duckdb;\n using namespace std;\n@@ -34,14 +36,68 @@ BufferedCSVReader::BufferedCSVReader(CopyInfo &info, vector<SQLType> sql_types,\n \t}\n }\n \n+void BufferedCSVReader::MatchBufferPosition(bool &prev_pos_matches, index_t &control_str_offset, index_t &tmp_position, bool &match, string &control_str) {\n+\tif (prev_pos_matches && control_str_offset < control_str.length()) {\n+\t\tif (buffer[tmp_position] != control_str[control_str_offset]) {\n+\t\t\tprev_pos_matches = false;\n+\t\t} else {\n+\t\t\tif (control_str_offset == control_str.length() - 1) {\n+\t\t\t\tprev_pos_matches = false;\n+\t\t\t\tmatch = true;\n+\t\t\t}\n+\t\t}\n+\t}\n+}\n+\n+bool BufferedCSVReader::MatchControlString(bool &delim_match, bool &quote_match, bool &escape_match) {\n+\tindex_t tmp_position = position;\n+\tindex_t control_str_offset = 0;\n+\n+\tbool delim = true;\n+\tbool quote = true;\n+\tbool escape = true;\n+\n+\twhile (true) {\n+\t\t// check if the delimiter string matches\n+\t\tMatchBufferPosition(delim, control_str_offset, tmp_position, delim_match, info.delimiter);\n+\t\t// check if the quote string matches\n+\t\tMatchBufferPosition(quote, control_str_offset, tmp_position, quote_match, info.quote);\n+\t\t// check if the escape string matches\n+\t\tMatchBufferPosition(escape, control_str_offset, tmp_position, escape_match, info.escape);\n+\n+\t\t// return if matching is not possible any longer\n+\t\tif (!delim && !quote && !escape) {\n+\t\t\treturn false;\n+\t\t}\n+\n+\t\ttmp_position++;\n+\t\tcontrol_str_offset++;\n+\n+\t\t// make sure not to exceed buffer size, and return if there cannot be any further control strings\n+\t\tif (tmp_position >= buffer_size) {\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+}\n+\n void BufferedCSVReader::ParseCSV(DataChunk &insert_chunk) {\n \tcached_buffers.clear();\n \n-\tindex_t column = 0;\n-\tindex_t offset = 0;\n+\t// used for parsing algorithm\n \tbool in_quotes = false;\n \tbool finished_chunk = false;\n-\tbool seen_escape = true;\n+\tbool seen_escape = false;\n+\tbool reset_quotes = false;\n+\tbool quote_or_escape = false;\n+\tbool exhausted_buffer = false;\n+\tindex_t column = 0;\n+\tindex_t offset = 0;\n+\tstd::queue<index_t> escape_positions;\n+\n+\t// used for fast control sequence detection\n+\tbool delimiter = false;\n+\tbool quote = false;\n+\tbool escape = false;\n \n \tif (position >= buffer_size) {\n \t\tif (!ReadBuffer(start)) {\n@@ -54,65 +110,114 @@ void BufferedCSVReader::ParseCSV(DataChunk &insert_chunk) {\n \t\tif (finished_chunk) {\n \t\t\treturn;\n \t\t}\n-\t\tif (in_quotes) {\n-\t\t\tif (buffer[position] == info.escape) {\n-\t\t\t\tseen_escape = true;\n-\t\t\t\t// FIXME this is only part of the deal, we also need to zap the escapes below\n-\t\t\t}\n-\t\t\telse if (!seen_escape) {\n-\t\t\t\tif (buffer[position] == info.quote) {\n-\t\t\t\t\t// end quote\n-\t\t\t\t\toffset = 1;\n+\n+\t\t// detect control strings\n+\t\texhausted_buffer = MatchControlString(delimiter, quote, escape);\n+\n+\t\tif (!exhausted_buffer) {\n+\t\t\t// if QUOTE equals ESCAPE we might need to determine which one we detected in the previous loop\n+\t\t\tif (quote_or_escape) {\n+\t\t\t\tif (delimiter || is_newline(buffer[position]) || (source.eof() && position + 1 == buffer_size)) {\n+\t\t\t\t\t// found quote without escape, end quote\n+\t\t\t\t\toffset = info.quote.length();\n \t\t\t\t\tin_quotes = false;\n+\t\t\t\t} else {\n+\t\t\t\t\t// found escape\n+\t\t\t\t\tseen_escape = true;\n \t\t\t\t}\n-\t\t\t} else {\n-\t\t\t\tseen_escape = false;\n+\t\t\t\tquote_or_escape = false;\n \t\t\t}\n \n-\t\t} else {\n-\t\t\tif (buffer[position] == info.quote) {\n-\t\t\t\t// start quotes can only occur at the start of a field\n-\t\t\t\tif (position == start) {\n-\t\t\t\t\t// increment start by 1\n-\t\t\t\t\tstart++;\n-\t\t\t\t\t// read until we encounter a quote again\n-\t\t\t\t\tin_quotes = true;\n+\t\t\tif (in_quotes) {\n+\t\t\t\tif (!quote && !escape && !seen_escape) {\n+\t\t\t\t\t// plain value character\n+\t\t\t\t\tseen_escape = false;\n+\t\t\t\t} else if (!quote && !escape && seen_escape) {\n+\t\t\t\t\tthrow ParserException(\"Error on line %lld: neither QUOTE nor ESCAPE is proceeded by ESCAPE\", linenr);\n+\t\t\t\t} else if (!quote && escape && !seen_escape) {\n+\t\t\t\t\t// escape\n+\t\t\t\t\tseen_escape = true;\n+\t\t\t\t\tposition += info.escape.length() - 1;\n+\t\t\t\t} else if (!quote && escape && seen_escape) {\n+\t\t\t\t\t// escaped escape\n+\t\t\t\t\t// we store the position of the escape so we can skip it when adding the value\n+\t\t\t\t\tescape_positions.push(position);\n+\t\t\t\t\tposition += info.escape.length() - 1;\n+\t\t\t\t\tseen_escape = false;\n+\t\t\t\t} else if (quote && !escape && !seen_escape) {\n+\t\t\t\t\t// found quote without escape, end quote\n+\t\t\t\t\toffset = info.quote.length();\n+\t\t\t\t\tposition += info.quote.length() - 1;\n+\t\t\t\t\tin_quotes = false;\n+\t\t\t\t} else if (quote && !escape && seen_escape) {\n+\t\t\t\t\t// escaped quote\n+\t\t\t\t\t// we store the position of the escape so we can skip it when adding the value\n+\t\t\t\t\tescape_positions.push(position);\n+\t\t\t\t\tposition += info.quote.length() - 1;\n+\t\t\t\t\tseen_escape = false;\n+\t\t\t\t} else if (quote && escape && !seen_escape) {\n+\t\t\t\t\t// either escape or end of quote, decide depending on next character\n+\t\t\t\t\t// NOTE: QUOTE and ESCAPE cannot be subsets of each other\n+\t\t\t\t\tposition += info.escape.length() - 1;\n+\t\t\t\t\tquote_or_escape = true;\n+\t\t\t\t} else if (quote && escape && seen_escape) {\n+\t\t\t\t\t// we store the position of the escape so we can skip it when adding the value\n+\t\t\t\t\tescape_positions.push(position);\n+\t\t\t\t\tposition += info.escape.length() - 1;\n+\t\t\t\t\tseen_escape = false;\n \t\t\t\t}\n-\t\t\t} else if (buffer[position] == info.delimiter) {\n-\t\t\t\t// encountered delimiter\n-\t\t\t\tAddValue(buffer.get() + start, position - start - offset, column);\n-\t\t\t\tstart = position + 1;\n-\t\t\t\toffset = 0;\n-\t\t\t}\n-\t\t\tif (is_newline(buffer[position]) || (source.eof() && position + 1 == buffer_size)) {\n-\t\t\t\tchar newline = buffer[position];\n-\t\t\t\t// encountered a newline, add the current value and push the row\n-\t\t\t\tAddValue(buffer.get() + start, position - start - offset, column);\n-\t\t\t\tfinished_chunk = AddRow(insert_chunk, column);\n-\n-\t\t\t\t// move to the next character\n-\t\t\t\tstart = position + 1;\n-\t\t\t\toffset = 0;\n-\t\t\t\tif (newline == '\\r') {\n-\t\t\t\t\t// \\r, skip subsequent \\n\n-\t\t\t\t\tif (position + 1 >= buffer_size) {\n-\t\t\t\t\t\tif (!ReadBuffer(start)) {\n-\t\t\t\t\t\t\tbreak;\n+\t\t\t} else {\n+\t\t\t\tif (quote) {\n+\t\t\t\t\t// start quotes can only occur at the start of a field\n+\t\t\t\t\tif (position == start) {\n+\t\t\t\t\t\tin_quotes = true;\n+\t\t\t\t\t\t// increment start by quote length\n+\t\t\t\t\t\tstart += info.quote.length();\n+\t\t\t\t\t\treset_quotes = in_quotes;\n+\t\t\t\t\t\tposition += info.quote.length() - 1;\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tthrow ParserException(\"Error on line %lld: unterminated quotes\", linenr);\n+\t\t\t\t\t}\n+\t\t\t\t} else if (delimiter) {\n+\t\t\t\t\t// encountered delimiter\n+\t\t\t\t\tAddValue(buffer.get() + start, position - start - offset, column, escape_positions);\n+\t\t\t\t\tstart = position + info.delimiter.length();\n+\t\t\t\t\treset_quotes = in_quotes;\n+\t\t\t\t\tposition += info.delimiter.length() - 1;\n+\t\t\t\t\toffset = 0;\n+\t\t\t\t}\n+\n+\t\t\t\tif (is_newline(buffer[position]) || (source.eof() && position + 1 == buffer_size)) {\n+\t\t\t\t\tchar newline = buffer[position];\n+\t\t\t\t\t// encountered a newline, add the current value and push the row\n+\t\t\t\t\tAddValue(buffer.get() + start, position - start - offset, column, escape_positions);\n+\t\t\t\t\tfinished_chunk = AddRow(insert_chunk, column);\n+\n+\t\t\t\t\t// move to the next character\n+\t\t\t\t\tstart = position + 1;\n+\t\t\t\t\treset_quotes = in_quotes;\n+\t\t\t\t\toffset = 0;\n+\t\t\t\t\tif (newline == '\\r') {\n+\t\t\t\t\t\t// \\r, skip subsequent \\n\n+\t\t\t\t\t\tif (position + 1 >= buffer_size) {\n+\t\t\t\t\t\t\tif (!ReadBuffer(start)) {\n+\t\t\t\t\t\t\t\tbreak;\n+\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\tif (buffer[position] == '\\n') {\n+\t\t\t\t\t\t\t\tstart++;\n+\t\t\t\t\t\t\t\tposition++;\n+\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\tcontinue;\n \t\t\t\t\t\t}\n-\t\t\t\t\t\tif (buffer[position] == '\\n') {\n+\t\t\t\t\t\tif (buffer[position + 1] == '\\n') {\n \t\t\t\t\t\t\tstart++;\n \t\t\t\t\t\t\tposition++;\n \t\t\t\t\t\t}\n-\t\t\t\t\t\tcontinue;\n-\t\t\t\t\t}\n-\t\t\t\t\tif (buffer[position + 1] == '\\n') {\n-\t\t\t\t\t\tstart++;\n-\t\t\t\t\t\tposition++;\n \t\t\t\t\t}\n \t\t\t\t}\n-\t\t\t}\n-\t\t\tif (offset != 0) {\n-\t\t\t\tin_quotes = true;\n+\t\t\t\tif (offset != 0) {\n+\t\t\t\t\tin_quotes = true;\n+\t\t\t\t}\n \t\t\t}\n \t\t}\n \n@@ -122,8 +227,22 @@ void BufferedCSVReader::ParseCSV(DataChunk &insert_chunk) {\n \t\t\tif (!ReadBuffer(start)) {\n \t\t\t\tbreak;\n \t\t\t}\n+\t\t\t// restore the current state after reading from the buffer\n+\t\t\tin_quotes = reset_quotes;\n+\t\t\tseen_escape = false;\n+\t\t\tposition = start;\n+\t\t\tquote_or_escape = false;\n+\t\t\twhile (!escape_positions.empty()) {\n+\t\t\t\tescape_positions.pop();\n+\t\t\t}\n \t\t}\n+\n+\t\t// reset values for control string matching\n+\t\tdelimiter = false;\n+\t\tquote = false;\n+\t\tescape = false;\n \t}\n+\n \tif (in_quotes) {\n \t\tthrow ParserException(\"Error on line %lld: unterminated quotes\", linenr);\n \t}\n@@ -161,7 +280,11 @@ bool BufferedCSVReader::ReadBuffer(index_t &start) {\n \treturn read_count > 0;\n }\n \n-void BufferedCSVReader::AddValue(char *str_val, index_t length, index_t &column) {\n+void BufferedCSVReader::AddValue(char *str_val, index_t length, index_t &column, std::queue<index_t> &escape_positions) {\n+\t// used to remove escape characters\n+\tindex_t pos = start;\n+\tbool in_escape = false;\n+\n \tif (column == sql_types.size() && length == 0) {\n \t\t// skip a single trailing delimiter\n \t\tcolumn++;\n@@ -173,16 +296,40 @@ void BufferedCSVReader::AddValue(char *str_val, index_t length, index_t &column)\n \t}\n \t// insert the line number into the chunk\n \tindex_t row_entry = parse_chunk.data[column].count++;\n-\tif (length == 0) {\n+\n+\tstr_val[length] = '\\0';\n+\t// test against null string\n+\tif (info.null_str == str_val && !info.force_not_null[column]) {\n \t\tparse_chunk.data[column].nullmask[row_entry] = true;\n \t} else {\n-\t\tauto data = (const char **)parse_chunk.data[column].data;\n-\t\tdata[row_entry] = str_val;\n-\t\tstr_val[length] = '\\0';\n-\t\tif (!Value::IsUTF8String(str_val)) {\n+\t\t// optionally remove escape(s)\n+\t\tstring new_val = \"\";\n+\t\tfor (const char *val = str_val; *val; val++) {\n+\t\t\tif (!escape_positions.empty()){\n+\t\t\t\tif (escape_positions.front() == pos) {\n+\t\t\t\t\tin_escape = false;\n+\t\t\t\t\tescape_positions.pop();\n+\t\t\t\t} else if (escape_positions.front() - info.escape.length() == pos) {\n+\t\t\t\t\tin_escape = true;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\tif (!in_escape) {\n+\t\t\t\tnew_val += *val;\n+\t\t\t}\n+\t\t\tpos++;\n+\t\t}\n+\t\twhile (!escape_positions.empty()) {\n+\t\t\tescape_positions.pop();\n+\t\t}\n+\t\t// test for valid utf-8 string\n+\t\tif (!Value::IsUTF8String(new_val.c_str())) {\n \t\t\tthrow ParserException(\"Error on line %lld: file is not valid UTF8\", linenr);\n \t\t}\n+\n+\t\tauto& v = parse_chunk.data[column];\n+\t\t((const char **)v.data)[row_entry] = v.string_heap.AddString(new_val.c_str());\n \t}\n+\n \t// move to the next column\n \tcolumn++;\n }\ndiff --git a/src/execution/operator/persistent/physical_copy_to_file.cpp b/src/execution/operator/persistent/physical_copy_to_file.cpp\nindex 8ee0a6b5e9e0..a5740eb109a7 100644\n--- a/src/execution/operator/persistent/physical_copy_to_file.cpp\n+++ b/src/execution/operator/persistent/physical_copy_to_file.cpp\n@@ -54,23 +54,82 @@ class BufferedWriter {\n \tofstream to_csv;\n };\n \n-static void WriteQuotedString(BufferedWriter &writer, const char *str_value, char delimiter, char quote) {\n-\t// scan the string for the delimiter\n-\tbool write_quoted = false;\n-\tindex_t len = 0;\n-\tfor (const char *val = str_value; *val; val++) {\n-\t\tlen++;\n-\t\tif (*val == delimiter || *val == '\\n' || *val == '\\r') {\n-\t\t\t// delimiter or newline, write a quoted string\n+string AddEscapes(string &to_be_escaped, string escape, string val) {\n+\tindex_t i = 0;\n+\tstring new_val = \"\";\n+\tindex_t found = val.find(to_be_escaped);\n+\n+\twhile (found != string::npos) {\n+\t\twhile (i < found) {\n+\t\t\tnew_val += val[i];\n+\t\t\ti++;\n+\t\t}\n+\t\tnew_val += escape;\n+\t\tfound = val.find(to_be_escaped, found + escape.length());\n+\t}\n+\twhile (i < val.length()) {\n+\t\tnew_val += val[i];\n+\t\ti++;\n+\t}\n+\treturn new_val;\n+}\n+\n+static void WriteQuotedString(BufferedWriter &writer, const char *str_value, string &delimiter, string &quote, string &escape, string &null_str, bool write_quoted) {\n+\t// used for adding escapes\n+\tbool add_escapes = false;\n+\tstring new_val = str_value;\n+\n+\t// check for \\n, \\r, \\n\\r in string\n+\tif (!write_quoted) {\n+\t\tfor (const char *val = str_value; *val; val++) {\n+\t\t\tif (*val == '\\n' || *val == '\\r') {\n+\t\t\t\t// newline, write a quoted string\n+\t\t\t\twrite_quoted = true;\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t// check if value is null string\n+\tif (!write_quoted) {\n+\t\tif (new_val == null_str) {\n \t\t\twrite_quoted = true;\n \t\t}\n \t}\n+\n+\t// check for delimiter\n \tif (!write_quoted) {\n-\t\twriter.Write(str_value, len);\n+\t\tif (new_val.find(delimiter) != string::npos) {\n+\t\t\twrite_quoted = true;\n+\t\t}\n+\t}\n+\n+\t// check for quote\n+\tif (new_val.find(quote) != string::npos) {\n+\t\twrite_quoted = true;\n+\t\tadd_escapes = true;\n+\t}\n+\n+\t// check for escapes in quoted string\n+\tif (write_quoted && !add_escapes) {\n+\t\tif (new_val.find(escape) != string::npos) {\n+\t\t\tadd_escapes = true;\n+\t\t}\n+\t}\n+\n+\tif (add_escapes) {\n+\t\tnew_val = AddEscapes(escape, escape, new_val);\n+\t\t// also escape quotes\n+\t\tif (escape != quote) {\n+\t\t\tnew_val = AddEscapes(quote, escape, new_val);\n+\t\t}\n+\t}\n+\n+\tif (!write_quoted) {\n+\t\twriter.Write(new_val);\n \t} else {\n-\t\twriter.Write(&quote, 1);\n-\t\twriter.Write(str_value, len);\n-\t\twriter.Write(&quote, 1);\n+\t\twriter.Write(quote);\n+\t\twriter.Write(new_val);\n+\t\twriter.Write(quote);\n \t}\n }\n \n@@ -84,13 +143,13 @@ void PhysicalCopyToFile::GetChunkInternal(ClientContext &context, DataChunk &chu\n \t\t// write the header line\n \t\tfor (index_t i = 0; i < names.size(); i++) {\n \t\t\tif (i != 0) {\n-\t\t\t\twriter.Write(&info.delimiter, 1);\n+\t\t\t\twriter.Write(info.delimiter);\n \t\t\t}\n-\t\t\tWriteQuotedString(writer, names[i].c_str(), info.delimiter, info.quote);\n+\t\t\tWriteQuotedString(writer, names[i].c_str(), info.delimiter, info.quote, info.escape, info.null_str, false);\n \t\t}\n \t\twriter.Write(newline);\n \t}\n-\t// cerate a chunk with VARCHAR columns\n+\t// create a chunk with VARCHAR columns\n \tvector<TypeId> types;\n \tfor (index_t col_idx = 0; col_idx < state->child_chunk.column_count; col_idx++) {\n \t\ttypes.push_back(TypeId::VARCHAR);\n@@ -116,16 +175,20 @@ void PhysicalCopyToFile::GetChunkInternal(ClientContext &context, DataChunk &chu\n \t\t}\n \t\t// now loop over the vectors and output the values\n \t\tVectorOperations::Exec(cast_chunk.data[0], [&](index_t i, index_t k) {\n+\t\t\t// write values\n \t\t\tfor (index_t col_idx = 0; col_idx < state->child_chunk.column_count; col_idx++) {\n \t\t\t\tif (col_idx != 0) {\n-\t\t\t\t\twriter.Write(&info.delimiter, 1);\n+\t\t\t\t\twriter.Write(info.delimiter);\n \t\t\t\t}\n \t\t\t\tif (cast_chunk.data[col_idx].nullmask[i]) {\n+\t\t\t\t\t// write null value\n+\t\t\t\t\twriter.Write(info.null_str);\n \t\t\t\t\tcontinue;\n \t\t\t\t}\n+\n \t\t\t\t// non-null value, fetch the string value from the cast chunk\n \t\t\t\tauto str_value = ((const char **)cast_chunk.data[col_idx].data)[i];\n-\t\t\t\tWriteQuotedString(writer, str_value, info.delimiter, info.quote);\n+\t\t\t\tWriteQuotedString(writer, str_value, info.delimiter, info.quote, info.escape, info.null_str, info.force_quote[col_idx]);\n \t\t\t}\n \t\t\twriter.Write(newline);\n \t\t});\ndiff --git a/src/include/execution/operator/persistent/buffered_csv_reader.hpp b/src/include/execution/operator/persistent/buffered_csv_reader.hpp\nindex 0cd35aafc099..3b0a74057948 100644\n--- a/src/include/execution/operator/persistent/buffered_csv_reader.hpp\n+++ b/src/include/execution/operator/persistent/buffered_csv_reader.hpp\n@@ -11,6 +11,8 @@\n #include \"execution/physical_operator.hpp\"\n #include \"parser/parsed_data/copy_info.hpp\"\n \n+#include <queue>\n+\n namespace duckdb {\n struct CopyInfo;\n \n@@ -44,13 +46,17 @@ class BufferedCSVReader {\n \n private:\n \t//! Adds a value to the current row\n-\tvoid AddValue(char *str_val, index_t length, index_t &column);\n+\tvoid AddValue(char *str_val, index_t length, index_t &column, std::queue<index_t> &escape_positions);\n \t//! Adds a row to the insert_chunk, returns true if the chunk is filled as a result of this row being added\n \tbool AddRow(DataChunk &insert_chunk, index_t &column);\n \t//! Finalizes a chunk, parsing all values that have been added so far and adding them to the insert_chunk\n \tvoid Flush(DataChunk &insert_chunk);\n \t//! Reads a new buffer from the CSV file if the current one has been exhausted\n \tbool ReadBuffer(index_t &start);\n+\t//! Sets the control strings starting at the current buffer position, returns false if the buffer was exhausted\n+\tbool MatchControlString(bool &delim_str, bool &quote_str, bool &escape_str);\n+\t//! Matches one position of the buffer against a corresponding char in a control string\n+\tvoid MatchBufferPosition(bool &prev_pos_matches, index_t &control_str_offset, index_t &tmp_position, bool &match, string &control_str);\n };\n \n } // namespace duckdb\ndiff --git a/src/include/parser/parsed_data/copy_info.hpp b/src/include/parser/parsed_data/copy_info.hpp\nindex bc1fb12b8cab..2d3b7bab48a6 100644\n--- a/src/include/parser/parsed_data/copy_info.hpp\n+++ b/src/include/parser/parsed_data/copy_info.hpp\n@@ -22,26 +22,38 @@ struct CopyInfo {\n \tstring schema;\n \t//! The table name to copy to/from\n \tstring table;\n-\t//! The file path to copy to or copy from\n+\t//! List of columns to copy to/from\n+\tvector<string> select_list;\n+\t//! The file path to copy to/from\n \tstring file_path;\n-\t//! Whether or not this is a copy to file or copy from a file\n+\t//! Whether or not this is a copy to file (false) or copy from a file (true)\n \tbool is_from;\n-\t//! Delimiter to parse\n-\tchar delimiter;\n-\t//! Quote to use\n-\tchar quote;\n-\t//! Escape character to use\n-\tchar escape;\n+\t//! Delimiter to separate columns within each line\n+\tstring delimiter;\n+\t//! Quote used for columns that contain reserved characters, e.g., delimiter\n+\tstring quote;\n+\t//! Escape character to escape quote character\n+\tstring escape;\n \t//! Whether or not the file has a header line\n \tbool header;\n \t//! The file format of the external file\n \tExternalFileFormat format;\n-\t// List of Columns that will be copied from/to.\n-\tvector<string> select_list;\n+\t//! Specifies the string that represents a null value\n+\tstring null_str;\n+\t//! Determines whether all columns must be quoted\n+\tbool quote_all;\n+\t//! Forces quoting to be used for all non-NULL values in each specified column\n+\tvector<string> force_quote_list;\n+\t//! True, if column with that index must be quoted\n+\tvector<bool> force_quote;\n+\t//! Null values will be read as zero-length strings in each specified column\n+\tvector<string> force_not_null_list;\n+\t//! True, if column with that index must skip null check\n+\tvector<bool> force_not_null;\n \n \tCopyInfo()\n-\t    : schema(DEFAULT_SCHEMA), is_from(false), delimiter(','), quote('\"'), escape('\\0'), header(false),\n-\t      format(ExternalFileFormat::CSV) {\n+\t    : schema(DEFAULT_SCHEMA), is_from(false), delimiter(\",\"), quote(\"\\\"\"), escape(\"\"), header(false),\n+\t      format(ExternalFileFormat::CSV), null_str(\"\"), quote_all(false) {\n \t}\n };\n \ndiff --git a/src/include/planner/statement/bound_copy_statement.hpp b/src/include/planner/statement/bound_copy_statement.hpp\nindex b5694c4006d5..91a3433c3a0d 100644\n--- a/src/include/planner/statement/bound_copy_statement.hpp\n+++ b/src/include/planner/statement/bound_copy_statement.hpp\n@@ -23,9 +23,9 @@ class BoundCopyStatement : public BoundSQLStatement {\n \n \t//! The CopyInfo\n \tunique_ptr<CopyInfo> info;\n-\t//! The bound insert statement (only for COPY from file -> database)\n+\t//! The bound insert statement (only for COPY FROM)\n \tunique_ptr<BoundSQLStatement> bound_insert;\n-\t// The bound SQL statement (only for COPY from database -> file)\n+\t//! The bound SQL statement (only for COPY TO)\n \tunique_ptr<BoundQueryNode> select_statement;\n \n \tvector<string> names;\ndiff --git a/src/parser/transform/statement/transform_copy.cpp b/src/parser/transform/statement/transform_copy.cpp\nindex dd7faaa52d29..808a08f91d21 100644\n--- a/src/parser/transform/statement/transform_copy.cpp\n+++ b/src/parser/transform/statement/transform_copy.cpp\n@@ -14,26 +14,165 @@ using namespace std;\n \n static ExternalFileFormat StringToExternalFileFormat(const string &str) {\n \tauto upper = StringUtil::Upper(str);\n-\tif (upper == \"CSV\") {\n-\t\treturn ExternalFileFormat::CSV;\n+\treturn ExternalFileFormat::CSV;\n+}\n+\n+void SetControlString(DefElem *def_elem, string option, string option_example, string &info_str) {\n+\tauto *val = (postgres::Value *)(def_elem->arg);\n+\tif (!val || val->type != T_String) {\n+\t\tthrow ParserException(\"Unsupported parameter type for \" + option + \": expected e.g. \" + option_example);\n \t}\n-\tthrow ConversionException(\"No ExternalFileFormat for input '%s'\", upper.c_str());\n+\tinfo_str = val->val.str;\n }\n \n-unique_ptr<CopyStatement> Transformer::TransformCopy(Node *node) {\n+void SubstringDetection(string &str_1, string &str_2, string name_str_1, string name_str_2) {\n+\tif (str_1.find(str_2) != string::npos || str_2.find(str_1) != std::string::npos) {\n+\t\tthrow Exception(\"COPY \" + name_str_1 + \" must not appear in the \" + name_str_2 + \" specification and vice versa\");\n+\t}\n+}\n+\n+void HandleOptions(CopyStmt *stmt, CopyInfo &info) {\n+\t// option names\n \tconst string kDelimiterTok = \"delimiter\";\n \tconst string kFormatTok = \"format\";\n \tconst string kQuoteTok = \"quote\";\n \tconst string kEscapeTok = \"escape\";\n \tconst string kHeaderTok = \"header\";\n+\tconst string kNullTok = \"null\";\n+\tconst string kForceQuoteTok = \"force_quote\";\n+\tconst string kForceNotNullTok = \"force_not_null\";\n+\tconst string kEncodingTok = \"encoding\";\n+\n+\tListCell *cell = nullptr;\n+\n+\t// iterate over each option\n+\tfor_each_cell(cell, stmt->options->head) {\n+\t\tauto *def_elem = reinterpret_cast<DefElem *>(cell->data.ptr_value);\n+\n+\t\tif (StringUtil::StartsWith(def_elem->defname, \"delim\") || StringUtil::StartsWith(def_elem->defname, \"sep\")) {\n+\t\t\t// delimiter\n+\t\t\tSetControlString(def_elem, \"DELIMITER\", \"DELIMITER ','\", info.delimiter);\n+\n+\t\t} else if (def_elem->defname == kFormatTok) {\n+\t\t\t// format\n+\t\t\tauto *format_val = (postgres::Value *)(def_elem->arg);\n+\t\t\tif (!format_val || format_val->type != T_String) {\n+\t\t\t\tthrow ParserException(\"Unsupported parameter type for FORMAT: expected e.g. FORMAT 'csv'\");\n+\t\t\t}\n+\t\t\tif (StringUtil::Upper(format_val->val.str) != \"CSV\") {\n+\t\t\t\tthrow Exception(\"Copy is only supported for .CSV-files, FORMAT 'csv'\");\n+\t\t\t}\n+\t\t\tinfo.format = StringToExternalFileFormat(format_val->val.str);\n+\n+\t\t} else if (def_elem->defname == kQuoteTok) {\n+\t\t\t// quote\n+\t\t\tSetControlString(def_elem, \"QUOTE\", \"QUOTE '\\\"'\", info.quote);\n+\t\t\tif (info.quote.length() == 0) {\n+\t\t\t\tthrow Exception(\"QUOTE must not be empty\");\n+\t\t\t}\n+\n+\t\t} else if (def_elem->defname == kEscapeTok) {\n+\t\t\t// escape\n+\t\t\tSetControlString(def_elem, \"ESCAPE\", \"ESCAPE '\\\"'\", info.escape);\n+\t\t\tif (info.escape.length() == 0) {\n+\t\t\t\tthrow Exception(\"ESCAPE must not be empty\");\n+\t\t\t}\n+\n+\t\t} else if (def_elem->defname == kHeaderTok) {\n+\t\t\t// header\n+\t\t\tauto *header_val = (postgres::Value *)(def_elem->arg);\n+\t\t\tif (!header_val) {\n+\t\t\t\tinfo.header = true;\n+\t\t\t\tcontinue;\n+\t\t\t}\n+\t\t\tswitch (header_val->type) {\n+\t\t\tcase T_Integer:\n+\t\t\t\tinfo.header = header_val->val.ival == 1 ? true : false;\n+\t\t\t\tbreak;\n+\t\t\tcase T_String: {\n+\t\t\t\tauto val = duckdb::Value(string(header_val->val.str));\n+\t\t\t\tinfo.header = val.CastAs(TypeId::BOOLEAN).value_.boolean;\n+\t\t\t\tbreak;\n+\t\t\t}\n+\t\t\tdefault:\n+\t\t\t\tthrow ParserException(\"Unsupported parameter type for HEADER: expected e.g. HEADER 1\");\n+\t\t\t}\n+\n+\t\t} else if (def_elem->defname == kNullTok) {\n+\t\t\t// null\n+\t\t\tSetControlString(def_elem, \"NULL\", \"NULL 'null'\", info.null_str);\n+\n+\t\t} else if (def_elem->defname == kForceQuoteTok) {\n+\t\t\t// force quote\n+\t\t\t// only for COPY ... TO ...\n+\t\t\tif(info.is_from) {\n+\t\t\t\tthrow Exception(\"The FORCE_QUOTE option is only for COPY ... TO ...\");\n+\t\t\t}\n+\n+\t\t\tauto *force_quote_val = def_elem->arg;\n+\t\t\tif (!force_quote_val || (force_quote_val->type != T_A_Star && force_quote_val->type != T_List)) {\n+\t\t\t\tthrow ParserException(\"Unsupported parameter type for FORCE_QUOTE: expected e.g. FORCE_QUOTE *\");\n+\t\t\t}\n+\n+\t\t\t// * option (all columns)\n+\t\t\tif (force_quote_val->type == T_A_Star) {\n+\t\t\t\tinfo.quote_all = true;\n+\t\t\t}\n+\n+\t\t\t// list of columns\n+\t\t\tif (force_quote_val->type == T_List) {\n+\t\t\t\tauto column_list = (postgres::List*)(force_quote_val);\n+\t\t\t\tfor (ListCell *c = column_list->head; c != NULL; c = lnext(c)) {\n+\t\t\t\t\tResTarget *target = (ResTarget *)(c->data.ptr_value);\n+\t\t\t\t\tinfo.force_quote_list.push_back(string(target->name));\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t} else if (def_elem->defname == kForceNotNullTok) {\n+\t\t\t// force not null\n+\t\t\t// only for COPY ... FROM ...\n+\t\t\tif (!info.is_from) {\n+\t\t\t\tthrow Exception(\"The FORCE_NOT_NULL option is only for COPY ... FROM ...\");\n+\t\t\t}\n \n+\t\t\tauto *force_not_null_val = def_elem->arg;\n+\t\t\tif (!force_not_null_val || force_not_null_val->type != T_List) {\n+\t\t\t\tthrow ParserException(\"Unsupported parameter type for FORCE_NOT_NULL: expected e.g. FORCE_NOT_NULL *\");\n+\t\t\t}\n+\n+\t\t\tauto column_list = (postgres::List*)(force_not_null_val);\n+\t\t\tfor (ListCell *c = column_list->head; c != NULL; c = lnext(c)) {\n+\t\t\t\tResTarget *target = (ResTarget *)(c->data.ptr_value);\n+\t\t\t\tinfo.force_not_null_list.push_back(string(target->name));\n+\t\t\t}\n+\n+\t\t} else if (def_elem->defname == kEncodingTok) {\n+\t\t\t// encoding\n+\t\t\tauto *encoding_val = (postgres::Value *)(def_elem->arg);\n+\t\t\tif (!encoding_val || encoding_val->type != T_String) {\n+\t\t\t\tthrow ParserException(\"Unsupported parameter type for ENCODING: expected e.g. ENCODING 'UTF-8'\");\n+\t\t\t}\n+\t\t\tif (StringUtil::Upper(encoding_val->val.str) != \"UTF8\" && StringUtil::Upper(encoding_val->val.str) != \"UTF-8\") {\n+\t\t\t\tthrow Exception(\"Copy is only supported for UTF-8 encoded files, ENCODING 'UTF-8'\");\n+\t\t\t}\n+\n+\t\t} else {\n+\t\t\tthrow ParserException(\"Unsupported COPY option: %s\", def_elem->defname);\n+\t\t}\n+\t}\n+}\n+\n+unique_ptr<CopyStatement> Transformer::TransformCopy(Node *node) {\n \tCopyStmt *stmt = reinterpret_cast<CopyStmt *>(node);\n \tassert(stmt);\n \tauto result = make_unique<CopyStatement>();\n \tauto &info = *result->info;\n+\n+\t// get file_path and is_from\n \tinfo.file_path = stmt->filename;\n \tinfo.is_from = stmt->is_from;\n \n+\t// get select_list\n \tif (stmt->attlist) {\n \t\tfor (auto n = stmt->attlist->head; n != nullptr; n = n->next) {\n \t\t\tauto target = reinterpret_cast<ResTarget *>(n->data.ptr_value);\n@@ -66,74 +205,26 @@ unique_ptr<CopyStatement> Transformer::TransformCopy(Node *node) {\n \t\tresult->select_statement = TransformSelectNode((SelectStmt *)stmt->query);\n \t}\n \n-\t// Handle options\n+\t// handle options\n \tif (stmt->options) {\n-\t\tListCell *cell = nullptr;\n-\t\tfor_each_cell(cell, stmt->options->head) {\n-\t\t\tauto *def_elem = reinterpret_cast<DefElem *>(cell->data.ptr_value);\n-\n-\t\t\tif (StringUtil::StartsWith(def_elem->defname, \"delim\") ||\n-\t\t\t    StringUtil::StartsWith(def_elem->defname, \"sep\")) {\n-\t\t\t\t// delimiter\n-\t\t\t\tauto *delimiter_val = reinterpret_cast<postgres::Value *>(def_elem->arg);\n-\t\t\t\tif (!delimiter_val || delimiter_val->type != T_String) {\n-\t\t\t\t\tthrow ParserException(\"Unsupported parameter type for DELIMITER: expected e.g. DELIMITER ','\");\n-\t\t\t\t}\n-\t\t\t\tindex_t delim_len = strlen(delimiter_val->val.str);\n-\t\t\t\tinfo.delimiter = '\\0';\n-\t\t\t\tchar *delim_cstr = delimiter_val->val.str;\n-\t\t\t\tif (delim_len == 1) {\n-\t\t\t\t\tinfo.delimiter = delim_cstr[0];\n-\t\t\t\t}\n-\t\t\t\tif (delim_len == 2 && delim_cstr[0] == '\\\\' && delim_cstr[1] == 't') {\n-\t\t\t\t\tinfo.delimiter = '\\t';\n-\t\t\t\t}\n-\t\t\t\tif (info.delimiter == '\\0') {\n-\t\t\t\t\tthrow Exception(\"Could not interpret DELIMITER option\");\n-\t\t\t\t}\n-\t\t\t} else if (def_elem->defname == kFormatTok) {\n-\t\t\t\t// format\n-\t\t\t\tauto *format_val = reinterpret_cast<postgres::Value *>(def_elem->arg);\n-\t\t\t\tif (!format_val || format_val->type != T_String) {\n-\t\t\t\t\tthrow ParserException(\"Unsupported parameter type for FORMAT: expected e.g. FORMAT 'csv'\");\n-\t\t\t\t}\n-\t\t\t\tinfo.format = StringToExternalFileFormat(format_val->val.str);\n-\t\t\t} else if (def_elem->defname == kQuoteTok) {\n-\t\t\t\t// quote\n-\t\t\t\tauto *quote_val = reinterpret_cast<postgres::Value *>(def_elem->arg);\n-\t\t\t\tif (!quote_val || quote_val->type != T_String) {\n-\t\t\t\t\tthrow ParserException(\"Unsupported parameter type for QUOTE: expected e.g. QUOTE '\\\"'\");\n-\t\t\t\t}\n-\t\t\t\tinfo.quote = *quote_val->val.str;\n-\t\t\t} else if (def_elem->defname == kEscapeTok) {\n-\t\t\t\t// escape\n-\t\t\t\tauto *escape_val = reinterpret_cast<postgres::Value *>(def_elem->arg);\n-\t\t\t\tif (!escape_val || escape_val->type != T_String) {\n-\t\t\t\t\tthrow ParserException(\"Unsupported parameter type for ESCAPE: expected e.g. ESCAPE '\\\\'\");\n-\t\t\t\t}\n-\t\t\t\tinfo.escape = *escape_val->val.str;\n-\t\t\t} else if (def_elem->defname == kHeaderTok) {\n-\t\t\t\tauto *header_val = reinterpret_cast<postgres::Value *>(def_elem->arg);\n-\t\t\t\tif (!header_val) {\n-\t\t\t\t\tinfo.header = true;\n-\t\t\t\t\tcontinue;\n-\t\t\t\t}\n-\t\t\t\tswitch (header_val->type) {\n-\t\t\t\tcase T_Integer:\n-\t\t\t\t\tinfo.header = header_val->val.ival == 1 ? true : false;\n-\t\t\t\t\tbreak;\n-\t\t\t\tcase T_String: {\n-\t\t\t\t\tauto val = duckdb::Value(string(header_val->val.str));\n-\t\t\t\t\tinfo.header = val.CastAs(TypeId::BOOLEAN).value_.boolean;\n-\t\t\t\t\tbreak;\n-\t\t\t\t}\n-\t\t\t\tdefault:\n-\t\t\t\t\tthrow ParserException(\"Unsupported parameter type for HEADER\");\n-\t\t\t\t}\n-\t\t\t} else {\n-\t\t\t\tthrow ParserException(\"Unsupported COPY option: %s\", def_elem->defname);\n-\t\t\t}\n-\t\t}\n+\t\tHandleOptions(stmt, info);\n+\t}\n+\n+\t// the default character of the ESCAPE option is the same as the QUOTE character\n+\tif (info.escape == \"\") {\n+\t\tinfo.escape = info.quote;\n+\t}\n+\t// escape and delimiter must not be substrings of each other\n+\tSubstringDetection(info.delimiter, info.escape, \"DELIMITER\", \"ESCAPE\");\n+\t// delimiter and quote must not be substrings of each other\n+\tSubstringDetection(info.quote, info.delimiter, \"DELIMITER\", \"QUOTE\");\n+\t// escape and quote must not be substrings of each other (but can be the same)\n+\tif (info.quote != info.escape) {\n+\t\tSubstringDetection(info.quote, info.escape, \"QUOTE\", \"ESCAPE\");\n+\t}\n+\t// null string and delimiter must not be substrings of each other\n+\tif (info.null_str != \"\") {\n+\t\tSubstringDetection(info.delimiter, info.null_str, \"DELIMITER\", \"NULL\");\n \t}\n \n \treturn result;\ndiff --git a/src/planner/binder/statement/bind_copy.cpp b/src/planner/binder/statement/bind_copy.cpp\nindex 7e9acca84148..d51db095d851 100644\n--- a/src/planner/binder/statement/bind_copy.cpp\n+++ b/src/planner/binder/statement/bind_copy.cpp\n@@ -7,16 +7,40 @@\n using namespace duckdb;\n using namespace std;\n \n+//void transformColumnList(){}\n+\n unique_ptr<BoundSQLStatement> Binder::Bind(CopyStatement &stmt) {\n \tauto result = make_unique<BoundCopyStatement>();\n+\n \tif (stmt.select_statement) {\n-\t\t// COPY from a query\n+\t\t// COPY TO a file\n \t\tresult->select_statement = Bind(*stmt.select_statement);\n \t\tresult->names = {\"Count\"};\n \t\tresult->sql_types = {SQLType::BIGINT};\n+\n+\t\tauto names = result->select_statement->names;\n+\t\tauto quote_list = stmt.info->force_quote_list;\n+\n+\t\t// set all columns to false\n+\t\tfor (index_t i = 0; i < names.size(); i++) {\n+\t\t\tstmt.info->force_quote.push_back(stmt.info->quote_all);\n+\t\t}\n+\n+\t\tif (!quote_list.empty()) {\n+\t\t\t// validate force_quote_list entries\n+\t\t\tfor (const auto& column : quote_list) {\n+\t\t\t\tauto it = find(names.begin(), names.end(), column);\n+\t\t\t\tif (it != names.end()) {\n+\t\t\t\t\tstmt.info->force_quote[distance(names.begin(), it)] = true;\n+\t\t\t\t} else {\n+\t\t\t\t\tthrow BinderException(\"Column %s in FORCE_QUOTE is not used in COPY\", column.c_str());\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\n \t} else {\n \t\tassert(!stmt.info->table.empty());\n-\t\t// COPY to a table\n+\t\t// COPY FROM a file\n \t\t// generate an insert statement for the the to-be-inserted table\n \t\tInsertStatement insert;\n \t\tinsert.table = stmt.info->table;\n@@ -25,9 +49,37 @@ unique_ptr<BoundSQLStatement> Binder::Bind(CopyStatement &stmt) {\n \n \t\t// bind the insert statement to the base table\n \t\tresult->bound_insert = Bind(insert);\n+\n \t\tauto &bound_insert = (BoundInsertStatement &)*result->bound_insert;\n \t\t// get the set of expected columns from the insert statement; these types will be parsed from the CSV\n \t\tresult->sql_types = bound_insert.expected_types;\n+\n+\t\tauto table = context.catalog.GetTable(context.ActiveTransaction(), stmt.info->schema, stmt.info->table);\n+\t\t// set all columns to false\n+\t\tfor (index_t i = 0; i < table->columns.size(); i++) {\n+\t\t\tstmt.info->force_not_null.push_back(false);\n+\t\t}\n+\n+\t\t// transform column names of force_not_null_list into force_not_null booleans\n+\t\tif (!stmt.info->force_not_null_list.empty()) {\n+\t\t\t// validate force_not_null_list entries\n+\t\t\tfor (const auto& column : stmt.info->force_not_null_list) {\n+\t\t\t\tauto entry = table->name_map.find(column);\n+\t\t\t\tif (entry == table->name_map.end()) {\n+\t\t\t\t\tthrow BinderException(\"Column %s not found in table %s\", column.c_str(), table->name.c_str());\n+\t\t\t\t}\n+\t\t\t\tif (bound_insert.column_index_map.size() > 0) {\n+\t\t\t\t\tauto it = find(bound_insert.column_index_map.begin(), bound_insert.column_index_map.end(), entry->second);\n+\t\t\t\t\tif (it != bound_insert.column_index_map.end()) {\n+\t\t\t\t\t\tstmt.info->force_not_null[entry->second] = true;\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tthrow BinderException(\"Column %s in FORCE_NOT_NULL is not used in COPY\", column.c_str());\n+\t\t\t\t\t}\n+\t\t\t\t} else {\n+\t\t\t\t\tstmt.info->force_not_null[entry->second] = true;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n \t}\n \tresult->info = move(stmt.info);\n \treturn move(result);\ndiff --git a/src/planner/logical_plan/statement/plan_copy.cpp b/src/planner/logical_plan/statement/plan_copy.cpp\nindex 80dd1672e3bb..be7b515f6395 100644\n--- a/src/planner/logical_plan/statement/plan_copy.cpp\n+++ b/src/planner/logical_plan/statement/plan_copy.cpp\n@@ -8,7 +8,7 @@ using namespace std;\n \n unique_ptr<LogicalOperator> LogicalPlanGenerator::CreatePlan(BoundCopyStatement &stmt) {\n \tif (stmt.select_statement) {\n-\t\t// COPY from a query\n+\t\t// COPY TO a file\n \t\tauto names = stmt.select_statement->names;\n \t\tauto types = stmt.select_statement->types;\n \n@@ -22,7 +22,7 @@ unique_ptr<LogicalOperator> LogicalPlanGenerator::CreatePlan(BoundCopyStatement\n \n \t\treturn move(copy);\n \t} else {\n-\t\t// COPY to a table\n+\t\t// COPY FROM a file\n \t\tassert(!stmt.info->table.empty());\n \t\t// first create a plan for the insert statement\n \t\tauto insert = CreatePlan(*stmt.bound_insert);\n",
  "test_patch": "diff --git a/test/helpers/test_helpers.cpp b/test/helpers/test_helpers.cpp\nindex e1e8c74a4114..41ea6cef6aab 100644\n--- a/test/helpers/test_helpers.cpp\n+++ b/test/helpers/test_helpers.cpp\n@@ -231,9 +231,10 @@ bool compare_result(string csv, ChunkCollection &collection, vector<SQLType> sql\n \n \t// set up the CSV reader\n \tCopyInfo info;\n-\tinfo.delimiter = '|';\n+\tinfo.delimiter = \"|\";\n \tinfo.header = true;\n-\tinfo.quote = '\"';\n+\tinfo.quote = \"\\\"\";\n+\tinfo.escape = \"\\\"\";\n \n \t// convert the CSV string into a stringstream\n \tistringstream csv_stream(csv);\ndiff --git a/test/sql/copy/test_copy.cpp b/test/sql/copy/test_copy.cpp\nindex 5daf1fa31626..c889aeebc2aa 100644\n--- a/test/sql/copy/test_copy.cpp\n+++ b/test/sql/copy/test_copy.cpp\n@@ -39,15 +39,15 @@ TEST_CASE(\"Test copy statement\", \"[copy]\") {\n \n \tauto csv_path = GetCSVPath();\n \n-\t// Generate CSV file With ; as delimiter and complex strings\n+\t// generate CSV file with ',' as delimiter and complex strings\n \tofstream from_csv_file(fs.JoinPath(csv_path, \"test.csv\"));\n \tfor (int i = 0; i < 5000; i++) {\n \t\tfrom_csv_file << i << \",\" << i << \", test\" << endl;\n \t}\n \tfrom_csv_file.close();\n \n-\t// Loading CSV into a table\n-\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test (a INTEGER, b INTEGER,c VARCHAR(10));\"));\n+\t// load CSV file into a table\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test (a INTEGER, b INTEGER, c VARCHAR(10));\"));\n \tresult = con.Query(\"COPY test FROM '\" + fs.JoinPath(csv_path, \"test.csv\") + \"';\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {5000}));\n \n@@ -55,69 +55,75 @@ TEST_CASE(\"Test copy statement\", \"[copy]\") {\n \tREQUIRE(CHECK_COLUMN(result, 0, {5000}));\n \tREQUIRE(CHECK_COLUMN(result, 1, {12497500}));\n \n-\tresult = con.Query(\"SELECT * FROM test ORDER BY 1 LIMIT 3 \");\n+\tresult = con.Query(\"SELECT * FROM test ORDER BY 1 LIMIT 3;\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {0, 1, 2}));\n \tREQUIRE(CHECK_COLUMN(result, 1, {0, 1, 2}));\n \tREQUIRE(CHECK_COLUMN(result, 2, {\" test\", \" test\", \" test\"}));\n \n-\t//  Creating CSV from table\n-\tresult = con.Query(\"COPY test to '\" + fs.JoinPath(csv_path, \"test2.csv\") + \"';\");\n+\t// create CSV file from table\n+\tresult = con.Query(\"COPY test TO '\" + fs.JoinPath(csv_path, \"test2.csv\") + \"';\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {5000}));\n-\t// load the same CSV back again\n-\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test2(a INTEGER, b INTEGER, c VARCHAR(10));\"));\n+\t// load the same CSV file back again\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test2 (a INTEGER, b INTEGER, c VARCHAR(10));\"));\n \tresult = con.Query(\"COPY test2 FROM '\" + fs.JoinPath(csv_path, \"test2.csv\") + \"';\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {5000}));\n-\tresult = con.Query(\"SELECT * FROM test2 ORDER BY 1 LIMIT 3 \");\n+\tresult = con.Query(\"SELECT * FROM test2 ORDER BY 1 LIMIT 3;\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {0, 1, 2}));\n \tREQUIRE(CHECK_COLUMN(result, 1, {0, 1, 2}));\n \tREQUIRE(CHECK_COLUMN(result, 2, {\" test\", \" test\", \" test\"}));\n \n \t// test too few rows\n-\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test_too_few_rows(a INTEGER, b INTEGER, c VARCHAR, d INTEGER);\"));\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test_too_few_rows (a INTEGER, b INTEGER, c VARCHAR, d INTEGER);\"));\n \tREQUIRE_FAIL(con.Query(\"COPY test_too_few_rows FROM '\" + fs.JoinPath(csv_path, \"test2.csv\") + \"';\"));\n \n-\t//  Creating CSV from Query\n-\tresult = con.Query(\"COPY (select a,b from test where a < 4000) to '\" + fs.JoinPath(csv_path, \"test3.csv\") + \"';\");\n+\t// create CSV file from query\n+\tresult = con.Query(\"COPY (SELECT a,b FROM test WHERE a < 4000) TO '\" + fs.JoinPath(csv_path, \"test3.csv\") + \"';\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {4000}));\n-\t// load the same CSV back again\n-\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test3(a INTEGER, b INTEGER);\"));\n+\t// load the same CSV file back again\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test3 (a INTEGER, b INTEGER);\"));\n \tresult = con.Query(\"COPY test3 FROM '\" + fs.JoinPath(csv_path, \"test3.csv\") + \"';\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {4000}));\n-\tresult = con.Query(\"SELECT * FROM test3 ORDER BY 1 LIMIT 3 \");\n+\tresult = con.Query(\"SELECT * FROM test3 ORDER BY 1 LIMIT 3;\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {0, 1, 2}));\n \tREQUIRE(CHECK_COLUMN(result, 1, {0, 1, 2}));\n \n-\t// Exporting selected columns from a table to a CSV.\n-\tresult = con.Query(\"COPY test(a,c) to '\" + fs.JoinPath(csv_path, \"test4.csv\") + \"' (DELIMITER ',', HEADER false);\");\n+\t// export selected columns from a table to a CSV file\n+\tresult = con.Query(\"COPY test (a,c) TO '\" + fs.JoinPath(csv_path, \"test4.csv\") + \"' (DELIMITER ',', HEADER false);\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {5000}));\n \n-\t// Importing CSV to Selected Columns\n-\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test4 (a INTEGER, b INTEGER,c VARCHAR(10));\"));\n-\tresult = con.Query(\"COPY test4(a,c) from '\" + fs.JoinPath(csv_path, \"test4.csv\") + \"' (DELIM ',', HEADER 0);\");\n+\t// import selected columns from CSV file\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test4 (a INTEGER, b INTEGER, c VARCHAR(10));\"));\n+\tresult = con.Query(\"COPY test4 (a,c) FROM '\" + fs.JoinPath(csv_path, \"test4.csv\") + \"' (DELIM ',', HEADER 0);\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {5000}));\n-\tresult = con.Query(\"SELECT * FROM test4 ORDER BY 1 LIMIT 3 \");\n+\tresult = con.Query(\"SELECT * FROM test4 ORDER BY 1 LIMIT 3;\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {0, 1, 2}));\n \tREQUIRE(CHECK_COLUMN(result, 1, {Value(), Value(), Value()}));\n \tREQUIRE(CHECK_COLUMN(result, 2, {\" test\", \" test\", \" test\"}));\n \n \t// unsupported type for HEADER\n-\tREQUIRE_FAIL(\n-\t    con.Query(\"COPY test4(a,c) from '\" + fs.JoinPath(csv_path, \"test4.csv\") + \" ' (SEP ',', HEADER 0.2);\"));\n-\t// empty sep\n-\tREQUIRE_FAIL(con.Query(\"COPY test4(a,c) from '\" + fs.JoinPath(csv_path, \"test4.csv\") + \" ' (SEP);\"));\n-\t// number as separator\n-\tREQUIRE_FAIL(con.Query(\"COPY test4(a,c) from '\" + fs.JoinPath(csv_path, \"test4.csv\") + \" ' (SEP 1);\"));\n+\tREQUIRE_FAIL(con.Query(\"COPY test4 (a,c) FROM '\" + fs.JoinPath(csv_path, \"test4.csv\") + \"' (SEP ',', HEADER 0.2);\"));\n+\t// empty delimiter\n+\tREQUIRE_FAIL(con.Query(\"COPY test4 (a,c) FROM '\" + fs.JoinPath(csv_path, \"test4.csv\") + \"' (SEP);\"));\n+\t// number as delimiter\n+\tREQUIRE_FAIL(con.Query(\"COPY test4 (a,c) FROM '\" + fs.JoinPath(csv_path, \"test4.csv\") + \"' (SEP 1);\"));\n \t// multiple format options\n-\tREQUIRE_FAIL(\n-\t    con.Query(\"COPY test4(a,c) from '\" + fs.JoinPath(csv_path, \"test4.csv\") + \"' (FORMAT 'csv', FORMAT 'json');\"));\n-\t// number as escape character\n-\tREQUIRE_FAIL(con.Query(\"COPY test4(a,c) from '\" + fs.JoinPath(csv_path, \"test4.csv\") + \" ' (ESCAPE 1);\"));\n-\t// no escape character\n-\tREQUIRE_FAIL(con.Query(\"COPY test4(a,c) from '\" + fs.JoinPath(csv_path, \"test4.csv\") + \" ' (ESCAPE);\"));\n-\t// no quote character\n-\tREQUIRE_FAIL(con.Query(\"COPY test4(a,c) from '\" + fs.JoinPath(csv_path, \"test4.csv\") + \" ' (QUOTE);\"));\n-\t// no format character\n-\tREQUIRE_FAIL(con.Query(\"COPY test4(a,c) from '\" + fs.JoinPath(csv_path, \"test4.csv\") + \" ' (FORMAT);\"));\n+\tREQUIRE_FAIL(con.Query(\"COPY test4 (a,c) FROM '\" + fs.JoinPath(csv_path, \"test4.csv\") + \"' (FORMAT 'csv', FORMAT 'json');\"));\n+\t// number as escape string\n+\tREQUIRE_FAIL(con.Query(\"COPY test4 (a,c) FROM '\" + fs.JoinPath(csv_path, \"test4.csv\") + \"' (ESCAPE 1);\"));\n+\t// no escape string\n+\tREQUIRE_FAIL(con.Query(\"COPY test4 (a,c) FROM '\" + fs.JoinPath(csv_path, \"test4.csv\") + \"' (ESCAPE);\"));\n+\t// number as quote string\n+\tREQUIRE_FAIL(con.Query(\"COPY test4 (a,c) FROM '\" + fs.JoinPath(csv_path, \"test4.csv\") + \"' (QUOTE 1);\"));\n+\t// no quote string\n+\tREQUIRE_FAIL(con.Query(\"COPY test4 (a,c) FROM '\" + fs.JoinPath(csv_path, \"test4.csv\") + \"' (QUOTE);\"));\n+\t// no format string\n+\tREQUIRE_FAIL(con.Query(\"COPY test4 (a,c) FROM '\" + fs.JoinPath(csv_path, \"test4.csv\") + \"' (FORMAT);\"));\n+\t// encoding must not be empty and must have the correct parameter type and value\n+\tREQUIRE_FAIL(con.Query(\"COPY test4 (a,c) FROM '\" + fs.JoinPath(csv_path, \"test4.csv\") + \"' (ENCODING);\"));\n+\tREQUIRE_FAIL(con.Query(\"COPY test4 (a,c) FROM '\" + fs.JoinPath(csv_path, \"test4.csv\") + \"' (ENCODING 42);\"));\n+\tREQUIRE_FAIL(con.Query(\"COPY test4 (a,c) FROM '\" + fs.JoinPath(csv_path, \"test4.csv\") + \"' (ENCODING 'utf-42');\"));\n+\t// don't allow for non-existant copy options\n+\tREQUIRE_FAIL(con.Query(\"COPY test4 (a,c) FROM '\" + fs.JoinPath(csv_path, \"test4.csv\") + \"' (MAGIC '42');\"));\n \n \t// use a different delimiter\n \tauto pipe_csv = fs.JoinPath(csv_path, \"test_pipe.csv\");\n@@ -127,12 +133,19 @@ TEST_CASE(\"Test copy statement\", \"[copy]\") {\n \t}\n \tfrom_csv_file_pipe.close();\n \n+\t// create new table\n \tREQUIRE_NO_FAIL(con.Query(\"DROP TABLE test;\"));\n-\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test (a INTEGER, b INTEGER,c VARCHAR(10));\"));\n-\tresult = con.Query(\"COPY test FROM '\" + pipe_csv + \"' (SEPARATOR '|')\");\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test (a INTEGER, b INTEGER, c VARCHAR(10));\"));\n+\tresult = con.Query(\"COPY test FROM '\" + pipe_csv + \"' (SEPARATOR '|');\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {10}));\n \n-\t// test null\n+\t// throw exception if a line contains too many values\n+\tofstream csv_too_many_values_file(fs.JoinPath(csv_path, \"too_many_values.csv\"));\n+\tcsv_too_many_values_file << \"1,2,3,4\" << endl;\n+\tcsv_too_many_values_file.close();\n+\tREQUIRE_FAIL(con.Query(\"COPY test FROM '\" + fs.JoinPath(csv_path, \"too_many_values.csv\") + \"';\"));\n+\n+\t// test default null string\n \tauto null_csv = fs.JoinPath(csv_path, \"null.csv\");\n \tofstream from_csv_file_null(null_csv);\n \tfor (int i = 0; i < 1; i++)\n@@ -141,7 +154,7 @@ TEST_CASE(\"Test copy statement\", \"[copy]\") {\n \tresult = con.Query(\"COPY test FROM '\" + null_csv + \"' DELIMITER '|';\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {1}));\n \n-\t// test invalid UTF8\n+\t// test invalid UTF-8\n \tauto invalid_utf_csv = fs.JoinPath(csv_path, \"invalid_utf.csv\");\n \tofstream from_csv_file_utf(invalid_utf_csv);\n \tfor (int i = 0; i < 1; i++)\n@@ -153,7 +166,7 @@ TEST_CASE(\"Test copy statement\", \"[copy]\") {\n \tofstream empty_file(fs.JoinPath(csv_path, \"empty.csv\"));\n \tempty_file.close();\n \n-\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE empty_table (a INTEGER, b INTEGER,c VARCHAR(10));\"));\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE empty_table (a INTEGER, b INTEGER, c VARCHAR(10));\"));\n \tresult = con.Query(\"COPY empty_table FROM '\" + fs.JoinPath(csv_path, \"empty.csv\") + \"';\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {0}));\n \n@@ -161,23 +174,425 @@ TEST_CASE(\"Test copy statement\", \"[copy]\") {\n \tofstream unterminated_quotes_file(fs.JoinPath(csv_path, \"unterminated.csv\"));\n \tunterminated_quotes_file << \"\\\"hello\\n\\n world\\n\";\n \tunterminated_quotes_file.close();\n-\n \tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE unterminated (a VARCHAR);\"));\n \tREQUIRE_FAIL(con.Query(\"COPY unterminated FROM '\" + fs.JoinPath(csv_path, \"unterminated.csv\") + \"';\"));\n \n-\t// 1024 rows\n+\t// 1024 rows (vector size)\n \tofstream csv_vector_size(fs.JoinPath(csv_path, \"vsize.csv\"));\n \tfor (int i = 0; i < 1024; i++) {\n \t\tcsv_vector_size << i << \",\" << i << \", test\" << endl;\n \t}\n \tcsv_vector_size.close();\n \n-\t// Loading CSV into a table\n-\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE vsize (a INTEGER, b INTEGER,c VARCHAR(10));\"));\n+\t// load CSV file into a table\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE vsize (a INTEGER, b INTEGER, c VARCHAR(10));\"));\n \tresult = con.Query(\"COPY vsize FROM '\" + fs.JoinPath(csv_path, \"vsize.csv\") + \"';\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {1024}));\n }\n \n+TEST_CASE(\"Test NULL option of copy statement\", \"[copy]\") {\n+\tunique_ptr<QueryResult> result;\n+\tDuckDB db(nullptr);\n+\tConnection con(db);\n+\n+\tauto csv_path = GetCSVPath();\n+\n+\t// generate CSV file with default delimiter\n+\tofstream from_csv_file(fs.JoinPath(csv_path, \"test_null_option.csv\"));\n+\tfor (int i = 0; i < 3; i++) {\n+\t\tfrom_csv_file << i << \",,\\\"test\\\",null\" << endl;\n+\t}\n+\tfrom_csv_file.close();\n+\n+\t// create a table\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test_null_option (col_a INTEGER, col_b VARCHAR(10), col_c VARCHAR(10), col_d VARCHAR(10));\"));\n+\t\n+\t// test COPY ... FROM ... \n+\n+\t// implicitly using default NULL value\n+\tresult = con.Query(\"COPY test_null_option FROM '\" + fs.JoinPath(csv_path, \"test_null_option.csv\") + \"';\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {3}));\n+\tresult = con.Query(\"SELECT * FROM test_null_option ORDER BY 1 LIMIT 3;\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {0, 1, 2}));\n+\tREQUIRE(CHECK_COLUMN(result, 1, {Value(), Value(), Value()}));\n+\tREQUIRE(CHECK_COLUMN(result, 2, {\"test\", \"test\", \"test\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 3, {\"null\", \"null\", \"null\"}));\n+\tREQUIRE_NO_FAIL(con.Query(\"DELETE FROM test_null_option;\"));\n+\n+\t// explicitly using default NULL value\n+\tresult = con.Query(\"COPY test_null_option FROM '\" + fs.JoinPath(csv_path, \"test_null_option.csv\") + \"' (NULL '');\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {3}));\n+\tresult = con.Query(\"SELECT * FROM test_null_option ORDER BY 1 LIMIT 3;\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {0, 1, 2}));\n+\tREQUIRE(CHECK_COLUMN(result, 1, {Value(), Value(), Value()}));\n+\tREQUIRE(CHECK_COLUMN(result, 2, {\"test\", \"test\", \"test\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 3, {\"null\", \"null\", \"null\"}));\n+\tREQUIRE_NO_FAIL(con.Query(\"DELETE FROM test_null_option;\"));\n+\n+\t// make sure a quoted null string is interpreted as a null value\n+\tresult = con.Query(\"COPY test_null_option FROM '\" + fs.JoinPath(csv_path, \"test_null_option.csv\") + \"' (NULL 'test');\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {3}));\n+\tresult = con.Query(\"SELECT * FROM test_null_option ORDER BY 1 LIMIT 3;\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {0, 1, 2}));\n+\tREQUIRE(CHECK_COLUMN(result, 1, {\"\", \"\", \"\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 2, {Value(), Value(), Value()}));\n+\tREQUIRE(CHECK_COLUMN(result, 3, {\"null\", \"null\", \"null\"}));\n+\tREQUIRE_NO_FAIL(con.Query(\"DELETE FROM test_null_option;\"));\n+\n+\t// setting specific NULL value\n+\tresult = con.Query(\"COPY test_null_option FROM '\" + fs.JoinPath(csv_path, \"test_null_option.csv\") + \"' (NULL 'null');\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {3}));\n+\tresult = con.Query(\"SELECT * FROM test_null_option ORDER BY 1 LIMIT 3;\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {0, 1, 2}));\n+\tREQUIRE(CHECK_COLUMN(result, 1, {\"\", \"\", \"\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 2, {\"test\", \"test\", \"test\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 3, {Value(), Value(), Value()}));\n+\n+\t// invalid parameter type\n+\tREQUIRE_FAIL(con.Query(\"COPY test_null_option FROM '\" + fs.JoinPath(csv_path, \"test_null_option.csv\") + \"' (NULL null);\"));\n+\t\n+\t// delimiter must not appear in the NULL specification\n+\tREQUIRE_FAIL(con.Query(\"COPY test_null_option FROM '\" + fs.JoinPath(csv_path, \"test_null_option.csv\") + \"' (NULL 'null,');\"));\n+\tREQUIRE_FAIL(con.Query(\"COPY test_null_option FROM '\" + fs.JoinPath(csv_path, \"test_null_option.csv\") + \"' (DELIMITER 'null', NULL 'null');\"));\n+\tREQUIRE_FAIL(con.Query(\"COPY test_null_option FROM '\" + fs.JoinPath(csv_path, \"test_null_option.csv\") + \"' (DELIMITER 'null', NULL 'nu');\"));\n+\n+\t// no parameter type\n+\tREQUIRE_FAIL(con.Query(\"COPY test_null_option FROM '\" + fs.JoinPath(csv_path, \"test_null_option.csv\") + \"' (NULL);\"));\n+\n+\t// empty integer column with non-default NULL string\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test_null_option_2 (col_a INTEGER, col_b INTEGER, col_c VARCHAR(10), col_d VARCHAR(10));\"));\n+\tREQUIRE_FAIL(con.Query(\"COPY test_null_option_2 FROM '\" + fs.JoinPath(csv_path, \"test_null_option.csv\") + \"' (NULL 'null');\"));\n+\n+\t// test COPY ... TO ...\n+\n+\t// implicitly using default NULL value\n+\tresult = con.Query(\"COPY test_null_option TO '\" + fs.JoinPath(csv_path, \"test_null_option_2.csv\") + \"';\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {3}));\n+\tREQUIRE_NO_FAIL(con.Query(\"DELETE FROM test_null_option;\"));\n+\tresult = con.Query(\"COPY test_null_option FROM '\" + fs.JoinPath(csv_path, \"test_null_option_2.csv\") + \"';\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {3}));\n+\tresult = con.Query(\"SELECT * FROM test_null_option ORDER BY 1 LIMIT 3;\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {0, 1, 2}));\n+\tREQUIRE(CHECK_COLUMN(result, 1, {\"\", \"\", \"\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 2, {\"test\", \"test\", \"test\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 3, {Value(), Value(), Value()}));\n+\n+\t// explicitly using default NULL value\n+\tresult = con.Query(\"COPY test_null_option TO '\" + fs.JoinPath(csv_path, \"test_null_option_3.csv\") + \"' (NULL '');\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {3}));\n+\tREQUIRE_NO_FAIL(con.Query(\"DELETE FROM test_null_option;\"));\n+\tresult = con.Query(\"COPY test_null_option FROM '\" + fs.JoinPath(csv_path, \"test_null_option_3.csv\") + \"' (NULL '');\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {3}));\n+\tresult = con.Query(\"SELECT * FROM test_null_option ORDER BY 1 LIMIT 3;\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {0, 1, 2}));\n+\tREQUIRE(CHECK_COLUMN(result, 1, {\"\", \"\", \"\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 2, {\"test\", \"test\", \"test\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 3, {Value(), Value(), Value()}));\n+\n+\t// setting specific NULL value\n+\tresult = con.Query(\"COPY test_null_option TO '\" + fs.JoinPath(csv_path, \"test_null_option_4.csv\") + \"' (NULL 'null');\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {3}));\n+\tREQUIRE_NO_FAIL(con.Query(\"DELETE FROM test_null_option;\"));\n+\tresult = con.Query(\"COPY test_null_option FROM '\" + fs.JoinPath(csv_path, \"test_null_option_4.csv\") + \"' (NULL 'null');\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {3}));\n+\tresult = con.Query(\"SELECT * FROM test_null_option ORDER BY 1 LIMIT 3;\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {0, 1, 2}));\n+\tREQUIRE(CHECK_COLUMN(result, 1, {\"\", \"\", \"\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 2, {\"test\", \"test\", \"test\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 3, {Value(), Value(), Value()}));\n+}\n+\n+TEST_CASE(\"Test force_quote and force_not_null\", \"[copy]\") {\n+\tunique_ptr<QueryResult> result;\n+\tDuckDB db(nullptr);\n+\tConnection con(db);\n+\n+\tauto csv_path = GetCSVPath();\n+\n+\t// generate CSV file with default delimiter\n+\tofstream from_csv_file(fs.JoinPath(csv_path, \"test.csv\"));\n+\tfrom_csv_file << 8 << \",test,tea\" << endl;\n+\tfor (int i = 0; i < 2; i++) {\n+\t\tfrom_csv_file << i << \",,test\" << endl;\n+\t}\n+\tfrom_csv_file.close();\n+\n+\t// generate another CSV file\n+\tofstream from_csv_file_2(fs.JoinPath(csv_path, \"test_2.csv\"));\n+\tfrom_csv_file_2 << \",test,tea\" << endl;\n+\tfor (int i = 0; i < 2; i++) {\n+\t\tfrom_csv_file_2 << i << \",,test\" << endl;\n+\t}\n+\tfrom_csv_file_2.close();\n+\n+\t// create a table\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test (col_a INTEGER, col_b VARCHAR(10), col_c VARCHAR(10));\"));\n+\n+\tresult = con.Query(\"COPY test FROM '\" + fs.JoinPath(csv_path, \"test.csv\") + \"';\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {3}));\n+\n+\t// test FORCE_QUOTE *\n+\tresult = con.Query(\"COPY test TO '\" + fs.JoinPath(csv_path, \"test_star.csv\") + \"' (FORCE_QUOTE *);\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {3}));\n+\n+\tvector<string> lines;\n+\tstring line;\n+\tifstream test_star_file (fs.JoinPath(csv_path, \"test_star.csv\"));\n+\tif (test_star_file.is_open()) {\n+\t\twhile (getline(test_star_file,line)) {\n+\t\t\tlines.push_back(line);\n+\t\t}\n+\t\ttest_star_file.close();\n+\t} else {\n+\t\tthrow Exception(\"Unable to open file: \" + fs.JoinPath(csv_path, \"test_star.csv\"));\n+\t};\n+\tREQUIRE(lines[0] == \"\\\"8\\\",\\\"test\\\",\\\"tea\\\"\");\n+\tREQUIRE(lines[1] == \"\\\"0\\\",,\\\"test\\\"\");\n+\tREQUIRE(lines[2] == \"\\\"1\\\",,\\\"test\\\"\");\n+\n+\t// test FORCE_QUOTE with specific columns and non-default quote character and non-default null character\n+\tresult = con.Query(\"COPY test TO '\" + fs.JoinPath(csv_path, \"test_chosen_columns.csv\") + \"' (FORCE_QUOTE (col_a, col_c), QUOTE 't', NULL 'tea');\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {3}));\n+\n+\tifstream test_columns_file (fs.JoinPath(csv_path, \"test_chosen_columns.csv\"));\n+\tif (test_columns_file.is_open()) {\n+\t\twhile (getline(test_columns_file,line)) {\n+\t\t\tlines.push_back(line);\n+\t\t}\n+\t\ttest_columns_file.close();\n+\t} else {\n+\t\tthrow Exception(\"Unable to open file: \" + fs.JoinPath(csv_path, \"test_chosen_columns.csv\"));\n+\t};\n+\tREQUIRE(lines[3] == \"t8t,tttesttt,ttteat\");\n+\tREQUIRE(lines[4] == \"t0t,tea,tttesttt\");\n+\tREQUIRE(lines[5] == \"t1t,tea,tttesttt\");\n+\n+\t// test FORCE_QUOTE with reordered columns\n+\tresult = con.Query(\"COPY test (col_b, col_c, col_a) TO '\" + fs.JoinPath(csv_path, \"test_reorder.csv\") + \"' (FORCE_QUOTE (col_c, col_b), NULL 'test');\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {3}));\n+\n+\tifstream test_reorder_file (fs.JoinPath(csv_path, \"test_reorder.csv\"));\n+\tif (test_reorder_file.is_open()) {\n+\t\twhile (getline(test_reorder_file,line)) {\n+\t\t\tlines.push_back(line);\n+\t\t}\n+\t\ttest_reorder_file.close();\n+\t} else {\n+\t\tthrow Exception(\"Unable to open file: \" + fs.JoinPath(csv_path, \"test_reorder.csv\"));\n+\t};\n+\tREQUIRE(lines[6] == \"\\\"test\\\",\\\"tea\\\",8\");\n+\tREQUIRE(lines[7] == \"test,\\\"test\\\",0\");\n+\tREQUIRE(lines[8] == \"test,\\\"test\\\",1\");\n+\n+\t// test using a column in FORCE_QUOTE that is not set as output, but that is a column of the table\n+\tREQUIRE_FAIL(con.Query(\"COPY test (col_b, col_a) TO '\" + fs.JoinPath(csv_path, \"test_reorder.csv\") + \"' (FORCE_QUOTE (col_c, col_b));\"));\n+\t// test using a column in FORCE_QUOTE that is not a column of the table\n+\tREQUIRE_FAIL(con.Query(\"COPY test TO '\" + fs.JoinPath(csv_path, \"test_reorder.csv\") + \"' (FORCE_QUOTE (col_c, col_d));\"));\n+\t// FORCE_QUOTE is only supported in COPY ... TO ...\n+\tREQUIRE_FAIL(con.Query(\"COPY test FROM '\" + fs.JoinPath(csv_path, \"test_reorder.csv\") + \"' (FORCE_QUOTE (col_c, col_d));\"));\n+\t// FORCE_QUOTE must not be empty and must have the correct parameter type\n+\tREQUIRE_FAIL(con.Query(\"COPY test TO '\" + fs.JoinPath(csv_path, \"test_reorder.csv\") + \"' (FORCE_QUOTE);\"));\n+\tREQUIRE_FAIL(con.Query(\"COPY test TO '\" + fs.JoinPath(csv_path, \"test_reorder.csv\") + \"' (FORCE_QUOTE 42);\"));\n+\n+\tREQUIRE_NO_FAIL(con.Query(\"DELETE FROM test;\"));\n+\n+\t// test FORCE_NOT_NULL\n+\n+\t// test if null value is correctly converted into string\n+\tresult = con.Query(\"COPY test FROM '\" + fs.JoinPath(csv_path, \"test_star.csv\") + \"' (FORCE_NOT_NULL (col_b), NULL 'test');\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {3}));\n+\tresult = con.Query(\"SELECT * FROM test ORDER BY 1;\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {0, 1, 8}));\n+\tREQUIRE(CHECK_COLUMN(result, 1, {\"\", \"\", \"test\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 2, {Value(), Value(), \"tea\"}));\n+\tREQUIRE_NO_FAIL(con.Query(\"DELETE FROM test;\"));\n+\n+\t// test if null value is correctly converted into string if explicit columns are used\n+\tresult = con.Query(\"COPY test (col_a, col_b, col_c) FROM '\" + fs.JoinPath(csv_path, \"test_star.csv\") + \"' (FORCE_NOT_NULL (col_b), NULL 'test');\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {3}));\n+\tresult = con.Query(\"SELECT * FROM test ORDER BY 1;\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {0, 1, 8}));\n+\tREQUIRE(CHECK_COLUMN(result, 1, {\"\", \"\", \"test\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 2, {Value(), Value(), \"tea\"}));\n+\n+\t// FORCE_NOT_NULL is only supported in COPY ... FROM ...\n+\tREQUIRE_FAIL(result = con.Query(\"COPY test TO '\" + fs.JoinPath(csv_path, \"test_star.csv\") + \"' (FORCE_NOT_NULL (col_b), NULL 'test');\"));\n+\t// FORCE_NOT_NULL must not be empty and must have the correct parameter type\n+\tREQUIRE_FAIL(result = con.Query(\"COPY test FROM '\" + fs.JoinPath(csv_path, \"test_star.csv\") + \"' (FORCE_NOT_NULL, NULL 'test');\"));\n+\tREQUIRE_FAIL(result = con.Query(\"COPY test FROM '\" + fs.JoinPath(csv_path, \"test_star.csv\") + \"' (FORCE_NOT_NULL 42, NULL 'test');\"));\n+\t// test using a column in FORCE_NOT_NULL that is not set as output, but that is a column of the table\n+\tREQUIRE_FAIL(con.Query(\"COPY test (col_b, col_a) FROM '\" + fs.JoinPath(csv_path, \"test_reorder.csv\") + \"' (FORCE_NOT_NULL (col_c, col_b));\"));\n+\t// test using a column in FORCE_NOT_NULL that is not a column of the table\n+\tREQUIRE_FAIL(con.Query(\"COPY test FROM '\" + fs.JoinPath(csv_path, \"test_reorder.csv\") + \"' (FORCE_NOT_NULL (col_c, col_d));\"));\n+\n+\t// FORCE_NOT_NULL fails on integer columns\n+\t// FIXME: only working if test cases are run individually, not working if whole [copy] test cases are run at once\n+\tREQUIRE_FAIL(con.Query(\"COPY test FROM '\" + fs.JoinPath(csv_path, \"test_2.csv\") + \"' (FORCE_NOT_NULL (col_a));\"));\n+}\n+\n+TEST_CASE(\"Test copy statement with unicode delimiter/quote/escape\", \"[copy]\") {\n+\tunique_ptr<QueryResult> result;\n+\tDuckDB db(nullptr);\n+\tConnection con(db);\n+\n+\tauto csv_path = GetCSVPath();\n+\n+\t// generate CSV file with unicode (> one-byte) delimiter/quote/escape\n+\tofstream from_csv_file1(fs.JoinPath(csv_path, \"multi_char.csv\"));\n+\tfrom_csv_file1 << 0 << \"\ud83e\udd86\u02eedu\u02e7\u02e7\ud83e\udd86ck\u02ee\ud83e\udd86\u02eed\u02e7\u02ee\u02e7\u02eeu\ud83e\udd86ck\u02ee\ud83e\udd86duck\" << endl;\n+\tfrom_csv_file1 << 1 << \"\ud83e\udd86\u02eedou\u02e7\u02eeble\u02ee\ud83e\udd86\ud83e\udd86duck\" << endl;\n+\tfrom_csv_file1 << 2 << \"\ud83e\udd86\ud83e\udd86\ud83e\udd86\" << endl;\n+\tfrom_csv_file1 << 3 << \"\ud83e\udd86duck inv\u02e7asion\ud83e\udd86\ud83e\udd86\" << endl;\n+\tfrom_csv_file1.close();\n+\n+\t// generate CSV file with unicode (> one-byte) delimiter/quote/escape that exceeds the buffer size a few times\n+\tofstream from_csv_file2(fs.JoinPath(csv_path, \"multi_char_buffer_exhausted.csv\"));\n+\tint64_t sum = 0;\n+\tfor (int i = 0; i < 16384; i++) {\n+\t\tif (i % 2 == 0) {\n+\t\t\tfrom_csv_file2 << i << \"\ud83e\udd86\u02ee\ud83e\udd86d\u02ee\ud83e\udd86\u02eed\u02e7\u02ee\ud83e\udd86\u02ee\ud83e\udd86d\u02e7\" << endl;\n+\t\t} else {\n+\t\t\tfrom_csv_file2 << i << \"\ud83e\udd86\u02ee\u02e7\u02ee\u02e7\u02ee\u02e7\u02ee\u02ee\ud83e\udd86\u02e7\u02e7\ud83e\udd86\ttest test\t\ud83e\udd86\" << endl;\n+\t\t}\n+\t\tsum += i;\n+\t}\n+\tfrom_csv_file2.close();\n+\n+\t// generate CSV file with one-byte delimiter/quote/escape\n+\tofstream from_csv_file3(fs.JoinPath(csv_path, \"one_byte_char.csv\"));\n+\tfor (int i = 0; i < 3; i++) {\n+\t\tfrom_csv_file3 << i << \",'du''ck','''''du,ck',duck\" << endl;\n+\t}\n+\tfrom_csv_file3.close();\n+\n+\t// generate CSV file with unterminated quotes\n+\tofstream from_csv_file4(fs.JoinPath(csv_path, \"unterminated_quotes.csv\"));\n+\tfor (int i = 0; i < 3; i++) {\n+\t\tfrom_csv_file4 << i << \",duck,\\\"duck\" << endl;\n+\t}\n+\tfrom_csv_file4.close();\n+\n+\t// generate CSV file with quotes that start midway in the value\n+\tofstream from_csv_file5(fs.JoinPath(csv_path, \"unterminated_quotes_2.csv\"));\n+\tfor (int i = 0; i < 3; i++) {\n+\t\tfrom_csv_file5 << i << \",du\\\"ck,duck\" << endl;\n+\t}\n+\tfrom_csv_file5.close();\n+\n+\t// generate a CSV file with a very long string exceeding the buffer midway in an escape sequence (delimiter and escape share substrings)\n+\tofstream from_csv_file6(fs.JoinPath(csv_path, \"shared_substrings.csv\"));\n+\tstring big_string_a(16370, 'a');\n+\tfrom_csv_file6 << big_string_a << \"AAA\\\"aaaaaaaaAAB\\\"\\\"\" << endl;\n+\tfrom_csv_file6.close();\n+\n+\t// create three tables for testing\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test_unicode_1 (col_a INTEGER, col_b VARCHAR(10), col_c VARCHAR(10), col_d VARCHAR(10));\"));\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test_unicode_2 (col_a INTEGER, col_b VARCHAR(10), col_c VARCHAR(10), col_d VARCHAR(10));\"));\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test_unicode_3 (col_a INTEGER, col_b VARCHAR(10), col_c VARCHAR(10), col_d VARCHAR(10));\"));\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test_unicode_4 (col_a VARCHAR, col_b VARCHAR);\"));\n+\n+\t// throw error if unterminated quotes are detected\n+\tREQUIRE_FAIL(con.Query(\"COPY test_unicode_1 FROM '\" + fs.JoinPath(csv_path, \"unterminated_quotes.csv\") + \"';\"));\n+\tREQUIRE_FAIL(con.Query(\"COPY test_unicode_1 FROM '\" + fs.JoinPath(csv_path, \"unterminated_quotes_2.csv\") + \"';\"));\n+\n+\t// test COPY ... FROM ...\n+\n+\t// test unicode delimiter/quote/escape\n+\tresult = con.Query(\"COPY test_unicode_1 FROM '\" + fs.JoinPath(csv_path, \"multi_char.csv\") + \"' (DELIMITER '\ud83e\udd86', QUOTE '\u02ee', ESCAPE '\u02e7');\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {4}));\n+\tresult = con.Query(\"SELECT * FROM test_unicode_1 ORDER BY 1 LIMIT 4;\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {0, 1, 2, 3}));\n+\tREQUIRE(CHECK_COLUMN(result, 1, {\"du\u02e7\ud83e\udd86ck\", \"dou\u02eeble\", Value(), \"duck inv\u02e7asion\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 2, {\"d\u02ee\u02eeu\ud83e\udd86ck\", Value(), Value(), Value()}));\n+\tREQUIRE(CHECK_COLUMN(result, 3, {\"duck\", \"duck\", Value(), Value()}));\n+\n+\t// test unicode delimiter/quote/escape that exceeds the buffer size a few times\n+\tresult = con.Query(\"COPY test_unicode_2 FROM '\" + fs.JoinPath(csv_path, \"multi_char_buffer_exhausted.csv\") + \"' (DELIMITER '\ud83e\udd86', QUOTE '\u02ee', ESCAPE '\u02e7');\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {16384}));\n+\tresult = con.Query(\"SELECT * FROM test_unicode_2 ORDER BY 1 LIMIT 4;\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {0, 1, 2, 3}));\n+\tREQUIRE(CHECK_COLUMN(result, 1, {\"\ud83e\udd86d\", \"\u02ee\u02ee\u02ee\", \"\ud83e\udd86d\", \"\u02ee\u02ee\u02ee\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 2, {\"d\u02ee\ud83e\udd86\", \"\u02e7\u02e7\", \"d\u02ee\ud83e\udd86\", \"\u02e7\u02e7\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 3, {\"d\u02e7\", \"\ttest test\t\", \"d\u02e7\", \"\ttest test\t\"}));\n+\tresult = con.Query(\"SELECT SUM(col_a) FROM test_unicode_2;\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {Value::BIGINT(sum)}));\n+\n+\t// test one-byte delimiter/quote/escape\n+\tresult = con.Query(\"COPY test_unicode_3 FROM '\" + fs.JoinPath(csv_path, \"one_byte_char.csv\") + \"' (QUOTE '''');\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {3}));\n+\tresult = con.Query(\"SELECT * FROM test_unicode_3 ORDER BY 1 LIMIT 3;\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {0, 1, 2}));\n+\tREQUIRE(CHECK_COLUMN(result, 1, {\"du'ck\", \"du'ck\", \"du'ck\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 2, {\"''du,ck\", \"''du,ck\", \"''du,ck\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 3, {\"duck\", \"duck\", \"duck\"}));\n+\n+\t// test correct shared substring behavior at buffer borders\n+\tresult = con.Query(\"COPY test_unicode_4 FROM '\" + fs.JoinPath(csv_path, \"shared_substrings.csv\") + \"' (DELIMITER 'AAA', ESCAPE 'AAB');\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {1}));\n+\tresult = con.Query(\"SELECT * FROM test_unicode_4;\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {big_string_a}));\n+\tREQUIRE(CHECK_COLUMN(result, 1, {\"aaaaaaaa\\\"\"}));\n+\n+\t// quote and escape must not be empty\n+\tREQUIRE_FAIL(con.Query(\"COPY test_unicode_1 FROM '\" + fs.JoinPath(csv_path, \"one_byte_char.csv\") + \"' (DELIMITER '\ud83e\udd86', QUOTE '');\"));\n+\tREQUIRE_FAIL(con.Query(\"COPY test_unicode_1 FROM '\" + fs.JoinPath(csv_path, \"one_byte_char.csv\") + \"' (DELIMITER '\ud83e\udd86', ESCAPE '');\"));\n+\n+\t// test same string for delimiter and quote\n+\tREQUIRE_FAIL(con.Query(\"COPY test_unicode_1 FROM '\" + fs.JoinPath(csv_path, \"one_byte_char.csv\") + \"' (DELIMITER '\ud83e\udd86', QUOTE '\ud83e\udd86');\"));\n+\n+\t// escape and quote cannot be substrings of each other\n+\tREQUIRE_FAIL(con.Query(\"COPY test_unicode_1 FROM '\" + fs.JoinPath(csv_path, \"one_byte_char.csv\") + \"' (ESCAPE 'du', QUOTE 'duck');\"));\n+\tREQUIRE_FAIL(con.Query(\"COPY test_unicode_1 FROM '\" + fs.JoinPath(csv_path, \"one_byte_char.csv\") + \"' (ESCAPE 'duck', QUOTE 'du');\"));\n+\n+\t// delimiter and quote cannot be substrings of each other\n+\tREQUIRE_FAIL(con.Query(\"COPY test_unicode_1 FROM '\" + fs.JoinPath(csv_path, \"one_byte_char.csv\") + \"' (DELIMITER 'du', QUOTE 'duck');\"));\n+\tREQUIRE_FAIL(con.Query(\"COPY test_unicode_1 FROM '\" + fs.JoinPath(csv_path, \"one_byte_char.csv\") + \"' (DELIMITER 'duck', QUOTE 'du');\"));\n+\n+\t// delimiter and escape cannot be substrings of each other\n+\tREQUIRE_FAIL(con.Query(\"COPY test_unicode_1 FROM '\" + fs.JoinPath(csv_path, \"one_byte_char.csv\") + \"' (DELIMITER 'AA', ESCAPE 'AAAA');\"));\n+\tREQUIRE_FAIL(con.Query(\"COPY test_unicode_1 FROM '\" + fs.JoinPath(csv_path, \"one_byte_char.csv\") + \"' (DELIMITER 'AAAA', ESCAPE 'AA');\"));\n+\n+\t// COPY ... TO ...\n+\n+\t// test unicode delimiter/quote/escape\n+\tresult = con.Query(\"COPY test_unicode_1 TO '\" + fs.JoinPath(csv_path, \"test_unicode_1.csv\") + \"' (DELIMITER '\ud83e\udd86', QUOTE '\u02ee', ESCAPE '\u02e7');\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {4}));\n+\tREQUIRE_NO_FAIL(con.Query(\"DELETE FROM test_unicode_1;\"));\n+\tresult = con.Query(\"COPY test_unicode_1 FROM '\" + fs.JoinPath(csv_path, \"test_unicode_1.csv\") + \"' (DELIMITER '\ud83e\udd86', QUOTE '\u02ee', ESCAPE '\u02e7');\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {4}));\n+\tresult = con.Query(\"SELECT * FROM test_unicode_1 ORDER BY 1 LIMIT 4;\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {0, 1, 2, 3}));\n+\tREQUIRE(CHECK_COLUMN(result, 1, {\"du\u02e7\ud83e\udd86ck\", \"dou\u02eeble\", Value(), \"duck inv\u02e7asion\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 2, {\"d\u02ee\u02eeu\ud83e\udd86ck\", Value(), Value(), Value()}));\n+\tREQUIRE(CHECK_COLUMN(result, 3, {\"duck\", \"duck\", Value(), Value()}));\n+\n+\t// test unicode delimiter/quote/escape\n+\tresult = con.Query(\"COPY test_unicode_2 TO '\" + fs.JoinPath(csv_path, \"test_unicode_2.csv\") + \"' (DELIMITER '\ud83e\udd86', QUOTE '\u02ee', ESCAPE '\u02e7');\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {16384}));\n+\tREQUIRE_NO_FAIL(con.Query(\"DELETE FROM test_unicode_2;\"));\n+\tresult = con.Query(\"COPY test_unicode_2 FROM '\" + fs.JoinPath(csv_path, \"test_unicode_2.csv\") + \"' (DELIMITER '\ud83e\udd86', QUOTE '\u02ee', ESCAPE '\u02e7');\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {16384}));\n+\tresult = con.Query(\"SELECT * FROM test_unicode_2 ORDER BY 1 LIMIT 4;\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {0, 1, 2, 3}));\n+\tREQUIRE(CHECK_COLUMN(result, 1, {\"\ud83e\udd86d\", \"\u02ee\u02ee\u02ee\", \"\ud83e\udd86d\", \"\u02ee\u02ee\u02ee\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 2, {\"d\u02ee\ud83e\udd86\", \"\u02e7\u02e7\", \"d\u02ee\ud83e\udd86\", \"\u02e7\u02e7\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 3, {\"d\u02e7\", \"\ttest test\t\", \"d\u02e7\", \"\ttest test\t\"}));\n+\tresult = con.Query(\"SELECT SUM(col_a) FROM test_unicode_2;\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {Value::BIGINT(sum)}));\n+\n+\t// test one-byte delimiter/quote/escape\n+\tresult = con.Query(\"COPY test_unicode_3 TO '\" + fs.JoinPath(csv_path, \"test_unicode_3.csv\") + \"' (QUOTE '''');\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {3}));\n+\tREQUIRE_NO_FAIL(con.Query(\"DELETE FROM test_unicode_3;\"));\n+\tresult = con.Query(\"COPY test_unicode_3 FROM '\" + fs.JoinPath(csv_path, \"test_unicode_3.csv\") + \"' (QUOTE '''');\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {3}));\n+\tresult = con.Query(\"SELECT * FROM test_unicode_3 ORDER BY 1 LIMIT 3;\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {0, 1, 2}));\n+\tREQUIRE(CHECK_COLUMN(result, 1, {\"du'ck\", \"du'ck\", \"du'ck\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 2, {\"''du,ck\", \"''du,ck\", \"''du,ck\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 3, {\"duck\", \"duck\", \"duck\"}));\n+}\n+\n TEST_CASE(\"Test copy statement with file overwrite\", \"[copy]\") {\n \tunique_ptr<QueryResult> result;\n \tDuckDB db(nullptr);\n@@ -193,7 +608,7 @@ TEST_CASE(\"Test copy statement with file overwrite\", \"[copy]\") {\n \tREQUIRE(CHECK_COLUMN(result, 0, {1, 2, 3}));\n \tREQUIRE(CHECK_COLUMN(result, 1, {\"hello\", \"world \", \" xx\"}));\n \n-\t// copy to the file\n+\t// copy to the CSV file\n \tresult = con.Query(\"COPY test TO '\" + fs.JoinPath(csv_path, \"test.csv\") + \"';\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {3}));\n \n@@ -202,7 +617,7 @@ TEST_CASE(\"Test copy statement with file overwrite\", \"[copy]\") {\n \tREQUIRE(CHECK_COLUMN(result, 0, {3}));\n \n \t// reload the data from the file: it should only have three rows\n-\tREQUIRE_NO_FAIL(con.Query(\"DELETE FROM test\"));\n+\tREQUIRE_NO_FAIL(con.Query(\"DELETE FROM test;\"));\n \n \tresult = con.Query(\"COPY test FROM '\" + fs.JoinPath(csv_path, \"test.csv\") + \"';\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {3}));\n@@ -219,6 +634,7 @@ TEST_CASE(\"Test copy statement with default values\", \"[copy]\") {\n \n \tauto csv_path = GetCSVPath();\n \n+\t// create a file only consisting of integers\n \tofstream from_csv_file(fs.JoinPath(csv_path, \"test.csv\"));\n \tint64_t expected_sum_a = 0;\n \tint64_t expected_sum_c = 0;\n@@ -230,15 +646,14 @@ TEST_CASE(\"Test copy statement with default values\", \"[copy]\") {\n \t}\n \tfrom_csv_file.close();\n \n-\t// Loading CSV into a table\n+\t// load CSV file into a table\n \tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test (a INTEGER, b VARCHAR DEFAULT('hello'), c INTEGER DEFAULT(3+4));\"));\n \tresult = con.Query(\"COPY test (a) FROM '\" + fs.JoinPath(csv_path, \"test.csv\") + \"';\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {5000}));\n \tresult = con.Query(\"COPY test (c) FROM '\" + fs.JoinPath(csv_path, \"test.csv\") + \"';\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {5000}));\n \n-\tresult =\n-\t    con.Query(\"SELECT COUNT(a), COUNT(b), COUNT(c), MIN(LENGTH(b)), MAX(LENGTH(b)), SUM(a), SUM(c) FROM test;\");\n+\tresult = con.Query(\"SELECT COUNT(a), COUNT(b), COUNT(c), MIN(LENGTH(b)), MAX(LENGTH(b)), SUM(a), SUM(c) FROM test;\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {5000}));\n \tREQUIRE(CHECK_COLUMN(result, 1, {10000}));\n \tREQUIRE(CHECK_COLUMN(result, 2, {10000}));\n@@ -255,7 +670,7 @@ TEST_CASE(\"Test copy statement with long lines\", \"[copy]\") {\n \n \tauto csv_path = GetCSVPath();\n \n-\t// Generate CSV file with a very long string\n+\t// generate a CSV file with a very long string\n \tofstream from_csv_file(fs.JoinPath(csv_path, \"test.csv\"));\n \tstring big_string_a(100000, 'a');\n \tstring big_string_b(200000, 'b');\n@@ -263,7 +678,7 @@ TEST_CASE(\"Test copy statement with long lines\", \"[copy]\") {\n \tfrom_csv_file << 20 << \",\" << big_string_b << \",\" << 30 << endl;\n \tfrom_csv_file.close();\n \n-\t// loading CSV into a table\n+\t// load CSV file into a table\n \tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test (a INTEGER, b VARCHAR, c INTEGER);\"));\n \tresult = con.Query(\"COPY test FROM '\" + fs.JoinPath(csv_path, \"test.csv\") + \"';\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {2}));\n@@ -283,13 +698,13 @@ TEST_CASE(\"Test copy statement with quotes and newlines\", \"[copy]\") {\n \n \tauto csv_path = GetCSVPath();\n \n-\t// Generate CSV file with quotes and newlines in the quotes\n+\t// generate a CSV file with newlines enclosed by quotes\n \tofstream from_csv_file(fs.JoinPath(csv_path, \"test.csv\"));\n-\tfrom_csv_file << \"\\\"hello\\nworld\\\",\\\"5\\\"\" << endl;\n-\tfrom_csv_file << \"\\\"what,\\n brings, you here\\n, today\\\",\\\"6\\\"\" << endl;\n+\tfrom_csv_file << \"\\\"hello\\\\nworld\\\",\\\"5\\\"\" << endl;\n+\tfrom_csv_file << \"\\\"what,\\\\n brings, you here\\\\n, today\\\",\\\"6\\\"\" << endl;\n \tfrom_csv_file.close();\n \n-\t// loading CSV into a table\n+\t// load CSV file into a table\n \tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test (a VARCHAR, b INTEGER);\"));\n \tresult = con.Query(\"COPY test FROM '\" + fs.JoinPath(csv_path, \"test.csv\") + \"';\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {2}));\n@@ -298,35 +713,43 @@ TEST_CASE(\"Test copy statement with quotes and newlines\", \"[copy]\") {\n \tREQUIRE(CHECK_COLUMN(result, 0, {11}));\n \n \tresult = con.Query(\"SELECT a FROM test ORDER BY a;\");\n-\tREQUIRE(CHECK_COLUMN(result, 0, {\"hello\\nworld\", \"what,\\n brings, you here\\n, today\"}));\n-\n+\tREQUIRE(CHECK_COLUMN(result, 0, {\"hello\\\\nworld\", \"what,\\\\n brings, you here\\\\n, today\"}));\n \tREQUIRE_NO_FAIL(con.Query(\"DROP TABLE test;\"));\n \n-\t// quotes in the middle of a quoted string are ignored\n+\t// quotes in the middle of a quoted string cause an exception if they are not escaped\n \tfrom_csv_file.open(fs.JoinPath(csv_path, \"test.csv\"));\n-\tfrom_csv_file << \"\\\"hello\\n\\\"w\\\"o\\\"rld\\\",\\\"5\\\"\" << endl;\n-\tfrom_csv_file << \"\\\"what,\\n brings, you here\\n, today\\\",\\\"6\\\"\" << endl;\n+\tfrom_csv_file << \"\\\"hello\\\\n\\\"w\\\"o\\\"rld\\\",\\\"5\\\"\" << endl;\n+\tfrom_csv_file << \"\\\"what,\\\\n brings, you here\\\\n, today\\\",\\\"6\\\"\" << endl;\n \tfrom_csv_file.close();\n \n \tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test (a VARCHAR, b INTEGER);\"));\n+\tREQUIRE_FAIL(con.Query(\"COPY test FROM '\" + fs.JoinPath(csv_path, \"test.csv\") + \"';\"));\n+\n+\t// now the same quotes are escaped\n+\tfrom_csv_file.open(fs.JoinPath(csv_path, \"test.csv\"));\n+\tfrom_csv_file << \"\\\"hello\\\\n\\\"\\\"w\\\"\\\"o\\\"\\\"rld\\\",\\\"5\\\"\" << endl;\n+\tfrom_csv_file << \"\\\"what,\\\\n brings, you here\\\\n, today\\\",\\\"6\\\"\" << endl;\n+\tfrom_csv_file.close();\n+\n \tresult = con.Query(\"COPY test FROM '\" + fs.JoinPath(csv_path, \"test.csv\") + \"';\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {2}));\n \n \tresult = con.Query(\"SELECT SUM(b) FROM test;\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {11}));\n-\tresult = con.Query(\"SELECT a FROM test ORDER BY a;\");\n-\tREQUIRE(CHECK_COLUMN(result, 0, {\"hello\\n\\\"w\\\"o\\\"rld\", \"what,\\n brings, you here\\n, today\"}));\n+\tresult = con.Query(\"SELECT a,b FROM test ORDER BY b;\");\n+\tREQUIRE(CHECK_COLUMN(result, 0, {\"hello\\\\n\\\"w\\\"o\\\"rld\", \"what,\\\\n brings, you here\\\\n, today\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 1, {5, 6}));\n \n \tREQUIRE_NO_FAIL(con.Query(\"DROP TABLE test;\"));\n \n-\t// unclosed quotes results in failure\n+\t// not escaped escape string in quotes throws an exception\n \tfrom_csv_file.open(fs.JoinPath(csv_path, \"test.csv\"));\n-\tfrom_csv_file << \"\\\"hello\\nworld\\\",\\\"5\" << endl;\n-\tfrom_csv_file << \"\\\"what,\\n brings, you here\\n, today\\\",\\\"6\\\"\" << endl;\n+\tfrom_csv_file << \"\\\"\\\\\\\"escaped\\\\\\\",\\\"5\\\"\" << endl;\n+\tfrom_csv_file << \"yea,6\" << endl;\n \tfrom_csv_file.close();\n \n \tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test (a VARCHAR, b INTEGER);\"));\n-\tREQUIRE_FAIL(con.Query(\"COPY test FROM '\" + fs.JoinPath(csv_path, \"test.csv\") + \"';\"));\n+\tREQUIRE_FAIL(con.Query(\"COPY test FROM '\" + fs.JoinPath(csv_path, \"test.csv\") + \"' (ESCAPE '\\\\');\"));\n }\n \n TEST_CASE(\"Test copy statement with many empty lines\", \"[copy]\") {\n@@ -336,7 +759,7 @@ TEST_CASE(\"Test copy statement with many empty lines\", \"[copy]\") {\n \n \tauto csv_path = GetCSVPath();\n \n-\t// Generate CSV file with a very long string\n+\t// generate CSV file with a very long string\n \tofstream from_csv_file(fs.JoinPath(csv_path, \"test.csv\"));\n \tfrom_csv_file << \"1\\n\";\n \tfor (index_t i = 0; i < 19999; i++) {\n@@ -344,7 +767,7 @@ TEST_CASE(\"Test copy statement with many empty lines\", \"[copy]\") {\n \t}\n \tfrom_csv_file.close();\n \n-\t// loading CSV into a table\n+\t// load CSV file into a table\n \tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test (a INTEGER);\"));\n \tresult = con.Query(\"COPY test FROM '\" + fs.JoinPath(csv_path, \"test.csv\") + \"';\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {20000}));\n@@ -353,27 +776,21 @@ TEST_CASE(\"Test copy statement with many empty lines\", \"[copy]\") {\n \tREQUIRE(CHECK_COLUMN(result, 0, {1}));\n }\n \n-TEST_CASE(\"Test line endings\", \"[copy]\") {\n+TEST_CASE(\"Test different line endings\", \"[copy]\") {\n \tunique_ptr<QueryResult> result;\n \tDuckDB db(nullptr);\n \tConnection con(db);\n \n \tauto csv_path = GetCSVPath();\n \n-\t// Generate CSV file with different line endings\n+\t// generate CSV file with different line endings\n \tofstream from_csv_file(fs.JoinPath(csv_path, \"test.csv\"));\n-\tfrom_csv_file << 10 << \",\"\n-\t              << \"hello\"\n-\t              << \",\" << 20 << \"\\r\\n\";\n-\tfrom_csv_file << 20 << \",\"\n-\t              << \"world\"\n-\t              << \",\" << 30 << '\\n';\n-\tfrom_csv_file << 30 << \",\"\n-\t              << \"test\"\n-\t              << \",\" << 30 << '\\r';\n+\tfrom_csv_file << 10 << \",\" << \"hello\" << \",\" << 20 << \"\\r\\n\";\n+\tfrom_csv_file << 20 << \",\" << \"world\" << \",\" << 30 << '\\n';\n+\tfrom_csv_file << 30 << \",\" << \"test\" << \",\" << 30 << '\\r';\n \tfrom_csv_file.close();\n \n-\t// loading CSV into a table\n+\t// load CSV file into a table\n \tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test (a INTEGER, b VARCHAR, c INTEGER);\"));\n \tresult = con.Query(\"COPY test FROM '\" + fs.JoinPath(csv_path, \"test.csv\") + \"';\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {3}));\n@@ -395,18 +812,18 @@ TEST_CASE(\"Test Windows Newlines with a long file\", \"[copy]\") {\n \n \tindex_t line_count = 20000;\n \tint64_t sum_a = 0, sum_c = 0;\n-\t// Generate CSV file with many strings\n+\n+\t// generate a CSV file with many strings\n \tofstream from_csv_file(fs.JoinPath(csv_path, \"test.csv\"));\n \tfor (index_t i = 0; i < line_count; i++) {\n-\t\tfrom_csv_file << i << \",\"\n-\t\t              << \"hello\"\n-\t\t              << \",\" << i + 2 << \"\\r\\n\";\n+\t\tfrom_csv_file << i << \",\" << \"hello\" << \",\" << i + 2 << \"\\r\\n\";\n+\n \t\tsum_a += i;\n \t\tsum_c += i + 2;\n \t}\n \tfrom_csv_file.close();\n \n-\t// loading CSV into a table\n+\t// load CSV file into a table\n \tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test (a INTEGER, b VARCHAR, c INTEGER);\"));\n \tresult = con.Query(\"COPY test FROM '\" + fs.JoinPath(csv_path, \"test.csv\") + \"';\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {Value::BIGINT(line_count)}));\n@@ -428,7 +845,7 @@ TEST_CASE(\"Test Windows Newlines with a long file\", \"[copy]\") {\n \t}\n \tfrom_csv_file_empty.close();\n \n-\t// loading CSV into a table\n+\t// load CSV file into a table\n \tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test (a INTEGER);\"));\n \tresult = con.Query(\"COPY test FROM '\" + fs.JoinPath(csv_path, \"test2.csv\") + \"';\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {Value::BIGINT(line_count)}));\n@@ -437,26 +854,25 @@ TEST_CASE(\"Test Windows Newlines with a long file\", \"[copy]\") {\n \tREQUIRE(CHECK_COLUMN(result, 0, {Value::BIGINT(1)}));\n }\n \n-TEST_CASE(\"Test lines that exceed the maximum allowed line size\", \"[copy]\") {\n+TEST_CASE(\"Test lines that exceed the maximum line size\", \"[copy]\") {\n \tunique_ptr<QueryResult> result;\n \tDuckDB db(nullptr);\n \tConnection con(db);\n \n \tauto csv_path = GetCSVPath();\n \n-\t// Generate CSV file with many strings\n+\t// generate CSV file with 20 MB string\n \tofstream from_csv_file(fs.JoinPath(csv_path, \"test.csv\"));\n-\t// 20 MB string\n \tstring big_string(2048576, 'a');\n \tfrom_csv_file << 10 << \",\" << big_string << \",\" << 20 << endl;\n \tfrom_csv_file.close();\n \n-\t// the load fails because the value is too big\n+\t// value is too big for loading\n \tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE test (a INTEGER, b VARCHAR, c INTEGER);\"));\n \tREQUIRE_FAIL(con.Query(\"COPY test FROM '\" + fs.JoinPath(csv_path, \"test.csv\") + \"';\"));\n }\n \n-TEST_CASE(\"Test copy into from on-time dataset\", \"[copy]\") {\n+TEST_CASE(\"Test copy from/to on-time dataset\", \"[copy]\") {\n \tunique_ptr<QueryResult> result;\n \tDuckDB db(nullptr);\n \tConnection con(db);\n@@ -494,35 +910,31 @@ TEST_CASE(\"Test copy into from on-time dataset\", \"[copy]\") {\n \t    \"div5airportseqid INTEGER, div5wheelson VARCHAR(10), div5totalgtime VARCHAR(10), div5longestgtime VARCHAR(10), \"\n \t    \"div5wheelsoff VARCHAR(10), div5tailnum VARCHAR(10));\"));\n \n-\tresult = con.Query(\"COPY ontime FROM '\" + ontime_csv + \"' DELIMITER ',' HEADER\");\n+\tresult = con.Query(\"COPY ontime FROM '\" + ontime_csv + \"' DELIMITER ',' HEADER;\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {9}));\n \n-\tresult = con.Query(\"SELECT year, uniquecarrier, origin, origincityname, div5longestgtime FROM ontime\");\n+\tresult = con.Query(\"SELECT year, uniquecarrier, origin, origincityname, div5longestgtime FROM ontime;\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {1988, 1988, 1988, 1988, 1988, 1988, 1988, 1988, 1988}));\n \tREQUIRE(CHECK_COLUMN(result, 1, {\"AA\", \"AA\", \"AA\", \"AA\", \"AA\", \"AA\", \"AA\", \"AA\", \"AA\"}));\n \tREQUIRE(CHECK_COLUMN(result, 2, {\"JFK\", \"JFK\", \"JFK\", \"JFK\", \"JFK\", \"JFK\", \"JFK\", \"JFK\", \"JFK\"}));\n-\tREQUIRE(CHECK_COLUMN(result, 3,\n-\t                     {\"New York, NY\", \"New York, NY\", \"New York, NY\", \"New York, NY\", \"New York, NY\",\n-\t                      \"New York, NY\", \"New York, NY\", \"New York, NY\", \"New York, NY\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 3, {\"New York, NY\", \"New York, NY\", \"New York, NY\", \"New York, NY\", \"New York, NY\", \"New York, NY\", \"New York, NY\", \"New York, NY\", \"New York, NY\"}));\n \tREQUIRE(CHECK_COLUMN(result, 4, {Value(), Value(), Value(), Value(), Value(), Value(), Value(), Value(), Value()}));\n \n-\tresult = con.Query(\"COPY ontime TO '\" + ontime_csv + \"' DELIMITER ',' HEADER\");\n+\tresult = con.Query(\"COPY ontime TO '\" + ontime_csv + \"' DELIMITER ',' HEADER;\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {9}));\n-\tREQUIRE_NO_FAIL(con.Query(\"DELETE FROM ontime\"));\n-\tresult = con.Query(\"COPY ontime FROM '\" + ontime_csv + \"' DELIMITER ',' HEADER\");\n+\tREQUIRE_NO_FAIL(con.Query(\"DELETE FROM ontime;\"));\n+\tresult = con.Query(\"COPY ontime FROM '\" + ontime_csv + \"' DELIMITER ',' HEADER;\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {9}));\n \n-\tresult = con.Query(\"SELECT year, uniquecarrier, origin, origincityname, div5longestgtime FROM ontime\");\n+\tresult = con.Query(\"SELECT year, uniquecarrier, origin, origincityname, div5longestgtime FROM ontime;\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {1988, 1988, 1988, 1988, 1988, 1988, 1988, 1988, 1988}));\n \tREQUIRE(CHECK_COLUMN(result, 1, {\"AA\", \"AA\", \"AA\", \"AA\", \"AA\", \"AA\", \"AA\", \"AA\", \"AA\"}));\n \tREQUIRE(CHECK_COLUMN(result, 2, {\"JFK\", \"JFK\", \"JFK\", \"JFK\", \"JFK\", \"JFK\", \"JFK\", \"JFK\", \"JFK\"}));\n-\tREQUIRE(CHECK_COLUMN(result, 3,\n-\t                     {\"New York, NY\", \"New York, NY\", \"New York, NY\", \"New York, NY\", \"New York, NY\",\n-\t                      \"New York, NY\", \"New York, NY\", \"New York, NY\", \"New York, NY\"}));\n+\tREQUIRE(CHECK_COLUMN(result, 3, {\"New York, NY\", \"New York, NY\", \"New York, NY\", \"New York, NY\", \"New York, NY\", \"New York, NY\", \"New York, NY\", \"New York, NY\", \"New York, NY\"}));\n \tREQUIRE(CHECK_COLUMN(result, 4, {Value(), Value(), Value(), Value(), Value(), Value(), Value(), Value(), Value()}));\n }\n \n-TEST_CASE(\"Test copy from lineitem csv\", \"[copy]\") {\n+TEST_CASE(\"Test copy from/to lineitem csv\", \"[copy]\") {\n \tunique_ptr<QueryResult> result;\n \tDuckDB db(nullptr);\n \tConnection con(db);\n@@ -540,27 +952,27 @@ TEST_CASE(\"Test copy from lineitem csv\", \"[copy]\") {\n \tresult = con.Query(\"COPY lineitem FROM '\" + lineitem_csv + \"' DELIMITER '|'\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {10}));\n \n-\tresult = con.Query(\"SELECT l_partkey, l_comment FROM lineitem WHERE l_orderkey=1 ORDER BY l_linenumber\");\n+\tresult = con.Query(\"SELECT l_partkey, l_comment FROM lineitem WHERE l_orderkey=1 ORDER BY l_linenumber;\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {15519, 6731, 6370, 214, 2403, 1564}));\n \tREQUIRE(\n \t    CHECK_COLUMN(result, 1,\n \t                 {\"egular courts above the\", \"ly final dependencies: slyly bold \", \"riously. regular, express dep\",\n \t                  \"lites. fluffily even de\", \" pending foxes. slyly re\", \"arefully slyly ex\"}));\n \n-\t// test COPY TO with HEADER\n-\tresult = con.Query(\"COPY lineitem TO '\" + lineitem_csv + \"' (DELIMITER ' ', HEADER)\");\n+\t// test COPY ... TO ... with HEADER\n+\tresult = con.Query(\"COPY lineitem TO '\" + lineitem_csv + \"' (DELIMITER ' ', HEADER);\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {10}));\n \n-\t// clear out the table\n-\tREQUIRE_NO_FAIL(con.Query(\"DELETE FROM lineitem\"));\n-\tresult = con.Query(\"SELECT * FROM lineitem\");\n+\t// clear the table\n+\tREQUIRE_NO_FAIL(con.Query(\"DELETE FROM lineitem;\"));\n+\tresult = con.Query(\"SELECT * FROM lineitem;\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {}));\n \n \t// now copy back into the table\n-\tresult = con.Query(\"COPY lineitem FROM '\" + lineitem_csv + \"' DELIMITER ' ' HEADER\");\n+\tresult = con.Query(\"COPY lineitem FROM '\" + lineitem_csv + \"' DELIMITER ' ' HEADER;\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {10}));\n \n-\tresult = con.Query(\"SELECT l_partkey, l_comment FROM lineitem WHERE l_orderkey=1 ORDER BY l_linenumber\");\n+\tresult = con.Query(\"SELECT l_partkey, l_comment FROM lineitem WHERE l_orderkey=1 ORDER BY l_linenumber;\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {15519, 6731, 6370, 214, 2403, 1564}));\n \tREQUIRE(\n \t    CHECK_COLUMN(result, 1,\n@@ -581,12 +993,12 @@ TEST_CASE(\"Test copy from web_page csv\", \"[copy]\") {\n \t    \"CREATE TABLE web_page(wp_web_page_sk integer not null, wp_web_page_id char(16) not null, wp_rec_start_date \"\n \t    \"date, wp_rec_end_date date, wp_creation_date_sk integer, wp_access_date_sk integer, wp_autogen_flag char(1), \"\n \t    \"wp_customer_sk integer, wp_url varchar(100), wp_type char(50), wp_char_count integer, wp_link_count integer, \"\n-\t    \"wp_image_count integer, wp_max_ad_count integer, primary key (wp_web_page_sk))\"));\n+\t    \"wp_image_count integer, wp_max_ad_count integer, primary key (wp_web_page_sk));\"));\n \n-\tresult = con.Query(\"COPY web_page FROM '\" + webpage_csv + \"' DELIMITER '|'\");\n+\tresult = con.Query(\"COPY web_page FROM '\" + webpage_csv + \"' DELIMITER '|';\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {60}));\n \n-\tresult = con.Query(\"SELECT * FROM web_page ORDER BY wp_web_page_sk LIMIT 3\");\n+\tresult = con.Query(\"SELECT * FROM web_page ORDER BY wp_web_page_sk LIMIT 3;\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {1, 2, 3}));\n \tREQUIRE(CHECK_COLUMN(result, 1, {\"AAAAAAAABAAAAAAA\", \"AAAAAAAACAAAAAAA\", \"AAAAAAAACAAAAAAA\"}));\n \tREQUIRE(CHECK_COLUMN(result, 2, {Value::DATE(1997, 9, 3), Value::DATE(1997, 9, 3), Value::DATE(2000, 9, 3)}));\n@@ -612,12 +1024,12 @@ TEST_CASE(\"Test copy from greek-utf8 csv\", \"[copy]\") {\n \tauto csv_file = fs.JoinPath(csv_path, \"greek_utf8.csv\");\n \tWriteBinary(csv_file, greek_utf8, sizeof(greek_utf8));\n \n-\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE greek_utf8(i INTEGER, j VARCHAR, k INTEGER)\"));\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE greek_utf8(i INTEGER, j VARCHAR, k INTEGER);\"));\n \n-\tresult = con.Query(\"COPY greek_utf8 FROM '\" + csv_file + \"' DELIMITER '|'\");\n+\tresult = con.Query(\"COPY greek_utf8 FROM '\" + csv_file + \"' DELIMITER '|';\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {8}));\n \n-\tresult = con.Query(\"SELECT * FROM greek_utf8 ORDER BY 1\");\n+\tresult = con.Query(\"SELECT * FROM greek_utf8 ORDER BY 1;\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {1689, 1690, 41561, 45804, 51981, 171067, 182773, 607808}));\n \tREQUIRE(CHECK_COLUMN(result, 1,\n \t                     {\"\\x30\\x30\\x69\\\\047\\x6d\", \"\\x30\\x30\\x69\\\\047\\x76\", \"\\x32\\x30\\x31\\x35\\xe2\\x80\\x8e\",\n@@ -638,10 +1050,10 @@ TEST_CASE(\"Test copy from ncvoter csv\", \"[copy]\") {\n \n \tREQUIRE_NO_FAIL(con.Query(\n \t    \"CREATE TABLE IF NOT EXISTS ncvoters(county_id INTEGER, county_desc STRING, voter_reg_num STRING,status_cd STRING, voter_status_desc STRING, reason_cd STRING, voter_status_reason_desc STRING, absent_ind STRING, name_prefx_cd STRING,last_name STRING, first_name STRING, midl_name STRING, name_sufx_cd STRING, full_name_rep STRING,full_name_mail STRING, house_num STRING, half_code STRING, street_dir STRING, street_name STRING, street_type_cd STRING, street_sufx_cd STRING, unit_designator STRING, unit_num STRING, res_city_desc STRING,state_cd STRING, zip_code STRING, res_street_address STRING, res_city_state_zip STRING, mail_addr1 STRING, mail_addr2 STRING, mail_addr3 STRING, mail_addr4 STRING, mail_city STRING, mail_state STRING, mail_zipcode STRING, mail_city_state_zip STRING, area_cd STRING, phone_num STRING, full_phone_number STRING, drivers_lic STRING, race_code STRING, race_desc STRING, ethnic_code STRING, ethnic_desc STRING, party_cd STRING, party_desc STRING, sex_code STRING, sex STRING, birth_age STRING, birth_place STRING, registr_dt STRING, precinct_abbrv STRING, precinct_desc STRING,municipality_abbrv STRING, municipality_desc STRING, ward_abbrv STRING, ward_desc STRING, cong_dist_abbrv STRING, cong_dist_desc STRING, super_court_abbrv STRING, super_court_desc STRING, judic_dist_abbrv STRING, judic_dist_desc STRING, nc_senate_abbrv STRING, nc_senate_desc STRING, nc_house_abbrv STRING, nc_house_desc STRING,county_commiss_abbrv STRING, county_commiss_desc STRING, township_abbrv STRING, township_desc STRING,school_dist_abbrv STRING, school_dist_desc STRING, fire_dist_abbrv STRING, fire_dist_desc STRING, water_dist_abbrv STRING, water_dist_desc STRING, sewer_dist_abbrv STRING, sewer_dist_desc STRING, sanit_dist_abbrv STRING, sanit_dist_desc STRING, rescue_dist_abbrv STRING, rescue_dist_desc STRING, munic_dist_abbrv STRING, munic_dist_desc STRING, dist_1_abbrv STRING, dist_1_desc STRING, dist_2_abbrv STRING, dist_2_desc STRING, confidential_ind STRING, age STRING, ncid STRING, vtd_abbrv STRING, vtd_desc STRING);\"));\n-\tresult = con.Query(\"COPY ncvoters FROM '\" + ncvoter_csv + \"' DELIMITER '\\t'\");\n+\tresult = con.Query(\"COPY ncvoters FROM '\" + ncvoter_csv + \"' DELIMITER '\\t';\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {10}));\n \n-\tresult = con.Query(\"SELECT county_id, county_desc, vtd_desc, name_prefx_cd FROM ncvoters\");\n+\tresult = con.Query(\"SELECT county_id, county_desc, vtd_desc, name_prefx_cd FROM ncvoters;\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {1, 1, 1, 1, 1, 1, 1, 1, 1, 1}));\n \tREQUIRE(CHECK_COLUMN(result, 1, {\"ALAMANCE\", \"ALAMANCE\", \"ALAMANCE\", \"ALAMANCE\", \"ALAMANCE\", \"ALAMANCE\", \"ALAMANCE\", \"ALAMANCE\", \"ALAMANCE\", \"ALAMANCE\"}));\n \tREQUIRE(CHECK_COLUMN(result, 2, {\"09S\", \"09S\", \"03W\", \"09S\", \"1210\", \"035\", \"124\", \"06E\", \"035\", \"064\"}));\n@@ -653,16 +1065,16 @@ TEST_CASE(\"Test date copy\", \"[copy]\") {\n \tDuckDB db(nullptr);\n \tConnection con(db);\n \n-\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE date_test(d date)\"));\n+\tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE date_test(d date);\"));\n \n \tauto csv_path = GetCSVPath();\n \tauto date_csv = fs.JoinPath(csv_path, \"date.csv\");\n \tWriteCSV(date_csv, \"2019-06-05\\n\");\n \n-\tresult = con.Query(\"COPY date_test FROM '\" + date_csv + \"'\");\n+\tresult = con.Query(\"COPY date_test FROM '\" + date_csv + \"';\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {1}));\n \n-\tresult = con.Query(\"SELECT cast(d as string) FROM date_test\");\n+\tresult = con.Query(\"SELECT cast(d as string) FROM date_test;\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {\"2019-06-05\"}));\n }\n \n@@ -676,9 +1088,9 @@ TEST_CASE(\"Test cranlogs broken gzip copy\", \"[copy]\") {\n \tWriteBinary(cranlogs_csv, tmp2013_06_15, sizeof(tmp2013_06_15));\n \n \tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE cranlogs (date date,time string,size int,r_version string,r_arch \"\n-\t                          \"string,r_os string,package string,version string,country string,ip_id int)\"));\n+\t                          \"string,r_os string,package string,version string,country string,ip_id int);\"));\n \n-\tresult = con.Query(\"COPY cranlogs FROM '\" + cranlogs_csv + \"' DELIMITER ',' HEADER\");\n+\tresult = con.Query(\"COPY cranlogs FROM '\" + cranlogs_csv + \"' DELIMITER ',' HEADER;\");\n \tREQUIRE(CHECK_COLUMN(result, 0, {37459}));\n }\n \n@@ -692,11 +1104,12 @@ TEST_CASE(\"Test imdb escapes\", \"[copy]\") {\n \tWriteBinary(imdb_movie_info, imdb_movie_info_escaped, sizeof(imdb_movie_info_escaped));\n \n \tREQUIRE_NO_FAIL(con.Query(\"CREATE TABLE movie_info (id integer NOT NULL PRIMARY KEY, movie_id integer NOT NULL, \"\n-\t                          \"info_type_id integer NOT NULL, info text NOT NULL, note text)\"));\n+\t                          \"info_type_id integer NOT NULL, info text NOT NULL, note text);\"));\n \n-\tresult = con.Query(\"COPY movie_info FROM '\" + imdb_movie_info + \"' DELIMITER ',' ESCAPE '\\\\'\");\n+\tresult = con.Query(\"COPY movie_info FROM '\" + imdb_movie_info + \"' DELIMITER ',' ESCAPE '\\\\';\");\n \tREQUIRE(result->success);\n \tREQUIRE(CHECK_COLUMN(result, 0, {201}));\n-\t// TODO actually check results\n-\tresult = con.Query(\"SELECT * FROM movie_info\");\n+\n+\t// TODO: actually check results\n+\tresult = con.Query(\"SELECT * FROM movie_info;\");\n }\ndiff --git a/test/sqlserver/test_sqlserver.cpp b/test/sqlserver/test_sqlserver.cpp\nindex d72a6d2a9b61..66d65cbf0090 100644\n--- a/test/sqlserver/test_sqlserver.cpp\n+++ b/test/sqlserver/test_sqlserver.cpp\n@@ -78,7 +78,7 @@ TEST_CASE(\"SQL Server functions tests\", \"[sqlserver]\") {\n \t              \"string NOT NULL, Title string , FirstName string NOT NULL, MiddleName string, LastName string NOT \"\n \t              \"NULL, Suffix string, EmailPromotion int NOT NULL, AdditionalContactInfo string, Demographics \"\n \t              \"string, rowguid string, ModifiedDate datetime NOT NULL); \"));\n-\tREQUIRE_NO_FAIL(con.Query(\"COPY Person.Person FROM 'test/sqlserver/data/Person.csv.gz' DELIMITER '|';\"));\n+\tREQUIRE_NO_FAIL(con.Query(\"COPY Person.Person FROM 'test/sqlserver/data/Person.csv.gz' (DELIMITER '|', QUOTE '*');\"));\n \n \tREQUIRE_NO_FAIL(\n \t    con.Query(\"CREATE TABLE Person.BusinessEntityAddress( BusinessEntityID int NOT NULL, AddressID int NOT NULL, \"\n",
  "problem_statement": "Support all PostgreSQL CSV import options\nhttps://www.postgresql.org/docs/9.2/sql-copy.html\r\n\r\nExcept the following which don't make much sense for us:\r\n\r\nSTDIN, STDOUT, OIDS\r\n\r\nFor now we should enforce that ENCODING is UTF-8\r\n\r\nOur current parser also does not support for multi-character delimiters and newlines in quotes. Add more tests with e.g. unicode delimiter, newlines in quotes, and broken CSV files.\r\n\r\n\n",
  "hints_text": "Also see #284 ",
  "created_at": "2019-10-12T17:45:48Z"
}