{
  "repo": "duckdb/duckdb",
  "pull_number": 10390,
  "instance_id": "duckdb__duckdb-10390",
  "issue_numbers": [
    "10324"
  ],
  "base_commit": "2be5405458e0129b6edab3e9fd4ab2e8bdf94e8f",
  "patch": "diff --git a/src/common/operator/cast_operators.cpp b/src/common/operator/cast_operators.cpp\nindex fb737e0e6da3..69ed385b0fa6 100644\n--- a/src/common/operator/cast_operators.cpp\n+++ b/src/common/operator/cast_operators.cpp\n@@ -24,6 +24,8 @@\n #include \"fast_float/fast_float.h\"\n #include \"fmt/format.h\"\n #include \"duckdb/common/types/bit.hpp\"\n+#include \"duckdb/common/operator/integer_cast_operator.hpp\"\n+#include \"duckdb/common/operator/double_cast_operator.hpp\"\n \n #include <cctype>\n #include <cmath>\n@@ -918,447 +920,6 @@ bool TryCast::Operation(double input, double &result, bool strict) {\n //===--------------------------------------------------------------------===//\n // Cast String -> Numeric\n //===--------------------------------------------------------------------===//\n-\n-template <typename T>\n-struct IntegerCastData {\n-\tusing ResultType = T;\n-\tusing StoreType = T;\n-\tResultType result;\n-};\n-\n-struct IntegerCastOperation {\n-\ttemplate <class T, bool NEGATIVE>\n-\tstatic bool HandleDigit(T &state, uint8_t digit) {\n-\t\tusing store_t = typename T::StoreType;\n-\t\tif (NEGATIVE) {\n-\t\t\tif (DUCKDB_UNLIKELY(state.result < (NumericLimits<store_t>::Minimum() + digit) / 10)) {\n-\t\t\t\treturn false;\n-\t\t\t}\n-\t\t\tstate.result = state.result * 10 - digit;\n-\t\t} else {\n-\t\t\tif (DUCKDB_UNLIKELY(state.result > (NumericLimits<store_t>::Maximum() - digit) / 10)) {\n-\t\t\t\treturn false;\n-\t\t\t}\n-\t\t\tstate.result = state.result * 10 + digit;\n-\t\t}\n-\t\treturn true;\n-\t}\n-\n-\ttemplate <class T, bool NEGATIVE>\n-\tstatic bool HandleHexDigit(T &state, uint8_t digit) {\n-\t\tusing store_t = typename T::StoreType;\n-\t\tif (DUCKDB_UNLIKELY(state.result > (NumericLimits<store_t>::Maximum() - digit) / 16)) {\n-\t\t\treturn false;\n-\t\t}\n-\t\tstate.result = state.result * 16 + digit;\n-\t\treturn true;\n-\t}\n-\n-\ttemplate <class T, bool NEGATIVE>\n-\tstatic bool HandleBinaryDigit(T &state, uint8_t digit) {\n-\t\tusing store_t = typename T::StoreType;\n-\t\tif (DUCKDB_UNLIKELY(state.result > (NumericLimits<store_t>::Maximum() - digit) / 2)) {\n-\t\t\treturn false;\n-\t\t}\n-\t\tstate.result = state.result * 2 + digit;\n-\t\treturn true;\n-\t}\n-\n-\ttemplate <class T, bool NEGATIVE>\n-\tstatic bool HandleExponent(T &state, int16_t exponent) {\n-\t\t// Simple integers don't deal with Exponents\n-\t\treturn false;\n-\t}\n-\n-\ttemplate <class T, bool NEGATIVE, bool ALLOW_EXPONENT>\n-\tstatic bool HandleDecimal(T &state, uint8_t digit) {\n-\t\t// Simple integers don't deal with Decimals\n-\t\treturn false;\n-\t}\n-\n-\ttemplate <class T, bool NEGATIVE>\n-\tstatic bool Finalize(T &state) {\n-\t\treturn true;\n-\t}\n-};\n-\n-template <typename T>\n-struct IntegerDecimalCastData {\n-\tusing ResultType = T;\n-\tusing StoreType = int64_t;\n-\tStoreType result;\n-\tStoreType decimal;\n-\tuint16_t decimal_digits;\n-};\n-\n-template <>\n-struct IntegerDecimalCastData<uint64_t> {\n-\tusing ResultType = uint64_t;\n-\tusing StoreType = uint64_t;\n-\tStoreType result;\n-\tStoreType decimal;\n-\tuint16_t decimal_digits;\n-};\n-\n-struct IntegerDecimalCastOperation : IntegerCastOperation {\n-\ttemplate <class T, bool NEGATIVE>\n-\tstatic bool HandleExponent(T &state, int16_t exponent) {\n-\t\tusing store_t = typename T::StoreType;\n-\n-\t\tint16_t e = exponent;\n-\t\t// Negative Exponent\n-\t\tif (e < 0) {\n-\t\t\twhile (state.result != 0 && e++ < 0) {\n-\t\t\t\tstate.decimal = state.result % 10;\n-\t\t\t\tstate.result /= 10;\n-\t\t\t}\n-\t\t\tif (state.decimal < 0) {\n-\t\t\t\tstate.decimal = -state.decimal;\n-\t\t\t}\n-\t\t\tstate.decimal_digits = 1;\n-\t\t\treturn Finalize<T, NEGATIVE>(state);\n-\t\t}\n-\n-\t\t// Positive Exponent\n-\t\twhile (state.result != 0 && e-- > 0) {\n-\t\t\tif (!TryMultiplyOperator::Operation(state.result, (store_t)10, state.result)) {\n-\t\t\t\treturn false;\n-\t\t\t}\n-\t\t}\n-\n-\t\tif (state.decimal == 0) {\n-\t\t\treturn Finalize<T, NEGATIVE>(state);\n-\t\t}\n-\n-\t\t// Handle decimals\n-\t\te = exponent - state.decimal_digits;\n-\t\tstore_t remainder = 0;\n-\t\tif (e < 0) {\n-\t\t\tif (static_cast<uint16_t>(-e) <= NumericLimits<store_t>::Digits()) {\n-\t\t\t\tstore_t power = 1;\n-\t\t\t\twhile (e++ < 0) {\n-\t\t\t\t\tpower *= 10;\n-\t\t\t\t}\n-\t\t\t\tremainder = state.decimal % power;\n-\t\t\t\tstate.decimal /= power;\n-\t\t\t} else {\n-\t\t\t\tstate.decimal = 0;\n-\t\t\t}\n-\t\t} else {\n-\t\t\twhile (e-- > 0) {\n-\t\t\t\tif (!TryMultiplyOperator::Operation(state.decimal, (store_t)10, state.decimal)) {\n-\t\t\t\t\treturn false;\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n-\n-\t\tstate.decimal_digits -= exponent;\n-\n-\t\tif (NEGATIVE) {\n-\t\t\tif (!TrySubtractOperator::Operation(state.result, state.decimal, state.result)) {\n-\t\t\t\treturn false;\n-\t\t\t}\n-\t\t} else if (!TryAddOperator::Operation(state.result, state.decimal, state.result)) {\n-\t\t\treturn false;\n-\t\t}\n-\t\tstate.decimal = remainder;\n-\t\treturn Finalize<T, NEGATIVE>(state);\n-\t}\n-\n-\ttemplate <class T, bool NEGATIVE, bool ALLOW_EXPONENT>\n-\tstatic bool HandleDecimal(T &state, uint8_t digit) {\n-\t\tusing store_t = typename T::StoreType;\n-\t\tif (DUCKDB_UNLIKELY(state.decimal > (NumericLimits<store_t>::Maximum() - digit) / 10)) {\n-\t\t\t// Simply ignore any more decimals\n-\t\t\treturn true;\n-\t\t}\n-\t\tstate.decimal_digits++;\n-\t\tstate.decimal = state.decimal * 10 + digit;\n-\t\treturn true;\n-\t}\n-\n-\ttemplate <class T, bool NEGATIVE>\n-\tstatic bool Finalize(T &state) {\n-\t\tusing result_t = typename T::ResultType;\n-\t\tusing store_t = typename T::StoreType;\n-\n-\t\tresult_t tmp;\n-\t\tif (!TryCast::Operation<store_t, result_t>(state.result, tmp)) {\n-\t\t\treturn false;\n-\t\t}\n-\n-\t\twhile (state.decimal > 10) {\n-\t\t\tstate.decimal /= 10;\n-\t\t\tstate.decimal_digits--;\n-\t\t}\n-\n-\t\tbool success = true;\n-\t\tif (state.decimal_digits == 1 && state.decimal >= 5) {\n-\t\t\tif (NEGATIVE) {\n-\t\t\t\tsuccess = TrySubtractOperator::Operation(tmp, (result_t)1, tmp);\n-\t\t\t} else {\n-\t\t\t\tsuccess = TryAddOperator::Operation(tmp, (result_t)1, tmp);\n-\t\t\t}\n-\t\t}\n-\t\tstate.result = tmp;\n-\t\treturn success;\n-\t}\n-};\n-\n-template <class T, bool NEGATIVE, bool ALLOW_EXPONENT, class OP = IntegerCastOperation, char decimal_separator = '.'>\n-static bool IntegerCastLoop(const char *buf, idx_t len, T &result, bool strict) {\n-\tidx_t start_pos;\n-\tif (NEGATIVE) {\n-\t\tstart_pos = 1;\n-\t} else {\n-\t\tif (*buf == '+') {\n-\t\t\tif (strict) {\n-\t\t\t\t// leading plus is not allowed in strict mode\n-\t\t\t\treturn false;\n-\t\t\t}\n-\t\t\tstart_pos = 1;\n-\t\t} else {\n-\t\t\tstart_pos = 0;\n-\t\t}\n-\t}\n-\tidx_t pos = start_pos;\n-\twhile (pos < len) {\n-\t\tif (!StringUtil::CharacterIsDigit(buf[pos])) {\n-\t\t\t// not a digit!\n-\t\t\tif (buf[pos] == decimal_separator) {\n-\t\t\t\tif (strict) {\n-\t\t\t\t\treturn false;\n-\t\t\t\t}\n-\t\t\t\tbool number_before_period = pos > start_pos;\n-\t\t\t\t// decimal point: we accept decimal values for integers as well\n-\t\t\t\t// we just truncate them\n-\t\t\t\t// make sure everything after the period is a number\n-\t\t\t\tpos++;\n-\t\t\t\tidx_t start_digit = pos;\n-\t\t\t\twhile (pos < len) {\n-\t\t\t\t\tif (!StringUtil::CharacterIsDigit(buf[pos])) {\n-\t\t\t\t\t\tbreak;\n-\t\t\t\t\t}\n-\t\t\t\t\tif (!OP::template HandleDecimal<T, NEGATIVE, ALLOW_EXPONENT>(result, buf[pos] - '0')) {\n-\t\t\t\t\t\treturn false;\n-\t\t\t\t\t}\n-\t\t\t\t\tpos++;\n-\n-\t\t\t\t\tif (pos != len && buf[pos] == '_') {\n-\t\t\t\t\t\t// Skip one underscore if it is not the last character and followed by a digit\n-\t\t\t\t\t\tpos++;\n-\t\t\t\t\t\tif (pos == len || !StringUtil::CharacterIsDigit(buf[pos])) {\n-\t\t\t\t\t\t\treturn false;\n-\t\t\t\t\t\t}\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t\t// make sure there is either (1) one number after the period, or (2) one number before the period\n-\t\t\t\t// i.e. we accept \"1.\" and \".1\" as valid numbers, but not \".\"\n-\t\t\t\tif (!(number_before_period || pos > start_digit)) {\n-\t\t\t\t\treturn false;\n-\t\t\t\t}\n-\t\t\t\tif (pos >= len) {\n-\t\t\t\t\tbreak;\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tif (StringUtil::CharacterIsSpace(buf[pos])) {\n-\t\t\t\t// skip any trailing spaces\n-\t\t\t\twhile (++pos < len) {\n-\t\t\t\t\tif (!StringUtil::CharacterIsSpace(buf[pos])) {\n-\t\t\t\t\t\treturn false;\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t\tbreak;\n-\t\t\t}\n-\t\t\tif (ALLOW_EXPONENT) {\n-\t\t\t\tif (buf[pos] == 'e' || buf[pos] == 'E') {\n-\t\t\t\t\tif (pos == start_pos) {\n-\t\t\t\t\t\treturn false;\n-\t\t\t\t\t}\n-\t\t\t\t\tpos++;\n-\t\t\t\t\tif (pos >= len) {\n-\t\t\t\t\t\treturn false;\n-\t\t\t\t\t}\n-\t\t\t\t\tusing ExponentData = IntegerCastData<int16_t>;\n-\t\t\t\t\tExponentData exponent {};\n-\t\t\t\t\tint negative = buf[pos] == '-';\n-\t\t\t\t\tif (negative) {\n-\t\t\t\t\t\tif (!IntegerCastLoop<ExponentData, true, false, IntegerCastOperation, decimal_separator>(\n-\t\t\t\t\t\t        buf + pos, len - pos, exponent, strict)) {\n-\t\t\t\t\t\t\treturn false;\n-\t\t\t\t\t\t}\n-\t\t\t\t\t} else {\n-\t\t\t\t\t\tif (!IntegerCastLoop<ExponentData, false, false, IntegerCastOperation, decimal_separator>(\n-\t\t\t\t\t\t        buf + pos, len - pos, exponent, strict)) {\n-\t\t\t\t\t\t\treturn false;\n-\t\t\t\t\t\t}\n-\t\t\t\t\t}\n-\t\t\t\t\treturn OP::template HandleExponent<T, NEGATIVE>(result, exponent.result);\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\treturn false;\n-\t\t}\n-\t\tuint8_t digit = buf[pos++] - '0';\n-\t\tif (!OP::template HandleDigit<T, NEGATIVE>(result, digit)) {\n-\t\t\treturn false;\n-\t\t}\n-\n-\t\tif (pos != len && buf[pos] == '_') {\n-\t\t\t// Skip one underscore if it is not the last character and followed by a digit\n-\t\t\tpos++;\n-\t\t\tif (pos == len || !StringUtil::CharacterIsDigit(buf[pos])) {\n-\t\t\t\treturn false;\n-\t\t\t}\n-\t\t}\n-\t}\n-\tif (!OP::template Finalize<T, NEGATIVE>(result)) {\n-\t\treturn false;\n-\t}\n-\treturn pos > start_pos;\n-}\n-\n-template <class T, bool NEGATIVE, bool ALLOW_EXPONENT, class OP = IntegerCastOperation>\n-static bool IntegerHexCastLoop(const char *buf, idx_t len, T &result, bool strict) {\n-\tif (ALLOW_EXPONENT || NEGATIVE) {\n-\t\treturn false;\n-\t}\n-\tidx_t start_pos = 1;\n-\tidx_t pos = start_pos;\n-\tchar current_char;\n-\twhile (pos < len) {\n-\t\tcurrent_char = StringUtil::CharacterToLower(buf[pos]);\n-\t\tif (!StringUtil::CharacterIsHex(current_char)) {\n-\t\t\treturn false;\n-\t\t}\n-\t\tuint8_t digit;\n-\t\tif (current_char >= 'a') {\n-\t\t\tdigit = current_char - 'a' + 10;\n-\t\t} else {\n-\t\t\tdigit = current_char - '0';\n-\t\t}\n-\t\tpos++;\n-\n-\t\tif (pos != len && buf[pos] == '_') {\n-\t\t\t// Skip one underscore if it is not the last character and followed by a hex\n-\t\t\tpos++;\n-\t\t\tif (pos == len || !StringUtil::CharacterIsHex(buf[pos])) {\n-\t\t\t\treturn false;\n-\t\t\t}\n-\t\t}\n-\n-\t\tif (!OP::template HandleHexDigit<T, NEGATIVE>(result, digit)) {\n-\t\t\treturn false;\n-\t\t}\n-\t}\n-\tif (!OP::template Finalize<T, NEGATIVE>(result)) {\n-\t\treturn false;\n-\t}\n-\treturn pos > start_pos;\n-}\n-\n-template <class T, bool NEGATIVE, bool ALLOW_EXPONENT, class OP = IntegerCastOperation>\n-static bool IntegerBinaryCastLoop(const char *buf, idx_t len, T &result, bool strict) {\n-\tif (ALLOW_EXPONENT || NEGATIVE) {\n-\t\treturn false;\n-\t}\n-\tidx_t start_pos = 1;\n-\tidx_t pos = start_pos;\n-\tuint8_t digit;\n-\tchar current_char;\n-\twhile (pos < len) {\n-\t\tcurrent_char = buf[pos];\n-\t\tif (current_char == '0') {\n-\t\t\tdigit = 0;\n-\t\t} else if (current_char == '1') {\n-\t\t\tdigit = 1;\n-\t\t} else {\n-\t\t\treturn false;\n-\t\t}\n-\t\tpos++;\n-\t\tif (pos != len && buf[pos] == '_') {\n-\t\t\t// Skip one underscore if it is not the last character and followed by a digit\n-\t\t\tpos++;\n-\t\t\tif (pos == len || (buf[pos] != '0' && buf[pos] != '1')) {\n-\t\t\t\treturn false;\n-\t\t\t}\n-\t\t}\n-\n-\t\tif (!OP::template HandleBinaryDigit<T, NEGATIVE>(result, digit)) {\n-\t\t\treturn false;\n-\t\t}\n-\t}\n-\tif (!OP::template Finalize<T, NEGATIVE>(result)) {\n-\t\treturn false;\n-\t}\n-\treturn pos > start_pos;\n-}\n-\n-template <class T, bool IS_SIGNED = true, bool ALLOW_EXPONENT = true, class OP = IntegerCastOperation,\n-          bool ZERO_INITIALIZE = true, char decimal_separator = '.'>\n-static bool TryIntegerCast(const char *buf, idx_t len, T &result, bool strict) {\n-\t// skip any spaces at the start\n-\twhile (len > 0 && StringUtil::CharacterIsSpace(*buf)) {\n-\t\tbuf++;\n-\t\tlen--;\n-\t}\n-\tif (len == 0) {\n-\t\treturn false;\n-\t}\n-\tif (ZERO_INITIALIZE) {\n-\t\tmemset(&result, 0, sizeof(T));\n-\t}\n-\t// if the number is negative, we set the negative flag and skip the negative sign\n-\tif (*buf == '-') {\n-\t\tif (!IS_SIGNED) {\n-\t\t\t// Need to check if its not -0\n-\t\t\tidx_t pos = 1;\n-\t\t\twhile (pos < len) {\n-\t\t\t\tif (buf[pos++] != '0') {\n-\t\t\t\t\treturn false;\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n-\t\treturn IntegerCastLoop<T, true, ALLOW_EXPONENT, OP, decimal_separator>(buf, len, result, strict);\n-\t}\n-\tif (len > 1 && *buf == '0') {\n-\t\tif (buf[1] == 'x' || buf[1] == 'X') {\n-\t\t\t// If it starts with 0x or 0X, we parse it as a hex value\n-\t\t\tbuf++;\n-\t\t\tlen--;\n-\t\t\treturn IntegerHexCastLoop<T, false, false, OP>(buf, len, result, strict);\n-\t\t} else if (buf[1] == 'b' || buf[1] == 'B') {\n-\t\t\t// If it starts with 0b or 0B, we parse it as a binary value\n-\t\t\tbuf++;\n-\t\t\tlen--;\n-\t\t\treturn IntegerBinaryCastLoop<T, false, false, OP>(buf, len, result, strict);\n-\t\t} else if (strict && StringUtil::CharacterIsDigit(buf[1])) {\n-\t\t\t// leading zeros are not allowed in strict mode\n-\t\t\treturn false;\n-\t\t}\n-\t}\n-\treturn IntegerCastLoop<T, false, ALLOW_EXPONENT, OP, decimal_separator>(buf, len, result, strict);\n-}\n-\n-template <typename T, bool IS_SIGNED = true>\n-static inline bool TrySimpleIntegerCast(const char *buf, idx_t len, T &result, bool strict) {\n-\tIntegerCastData<T> simple_data;\n-\tif (TryIntegerCast<IntegerCastData<T>, IS_SIGNED, false, IntegerCastOperation>(buf, len, simple_data, strict)) {\n-\t\tresult = (T)simple_data.result;\n-\t\treturn true;\n-\t}\n-\n-\t// Simple integer cast failed, try again with decimals/exponents included\n-\t// FIXME: This could definitely be improved as some extra work is being done here. It is more important that\n-\t//  \"normal\" integers (without exponent/decimals) are still being parsed quickly.\n-\tIntegerDecimalCastData<T> cast_data;\n-\tif (TryIntegerCast<IntegerDecimalCastData<T>, IS_SIGNED, true, IntegerDecimalCastOperation>(buf, len, cast_data,\n-\t                                                                                            strict)) {\n-\t\tresult = (T)cast_data.result;\n-\t\treturn true;\n-\t}\n-\treturn false;\n-}\n-\n template <>\n bool TryCast::Operation(string_t input, bool &result, bool strict) {\n \tauto input_data = input.GetData();\n@@ -1437,44 +998,6 @@ bool TryCast::Operation(string_t input, uint64_t &result, bool strict) {\n \treturn TrySimpleIntegerCast<uint64_t, false>(input.GetData(), input.GetSize(), result, strict);\n }\n \n-template <class T, char decimal_separator = '.'>\n-static bool TryDoubleCast(const char *buf, idx_t len, T &result, bool strict) {\n-\t// skip any spaces at the start\n-\twhile (len > 0 && StringUtil::CharacterIsSpace(*buf)) {\n-\t\tbuf++;\n-\t\tlen--;\n-\t}\n-\tif (len == 0) {\n-\t\treturn false;\n-\t}\n-\tif (*buf == '+') {\n-\t\tif (strict) {\n-\t\t\t// plus is not allowed in strict mode\n-\t\t\treturn false;\n-\t\t}\n-\t\tbuf++;\n-\t\tlen--;\n-\t}\n-\tif (strict && len >= 2) {\n-\t\tif (buf[0] == '0' && StringUtil::CharacterIsDigit(buf[1])) {\n-\t\t\t// leading zeros are not allowed in strict mode\n-\t\t\treturn false;\n-\t\t}\n-\t}\n-\tauto endptr = buf + len;\n-\tauto parse_result = duckdb_fast_float::from_chars(buf, buf + len, result, decimal_separator);\n-\tif (parse_result.ec != std::errc()) {\n-\t\treturn false;\n-\t}\n-\tauto current_end = parse_result.ptr;\n-\tif (!strict) {\n-\t\twhile (current_end < endptr && StringUtil::CharacterIsSpace(*current_end)) {\n-\t\t\tcurrent_end++;\n-\t\t}\n-\t}\n-\treturn current_end == endptr;\n-}\n-\n template <>\n bool TryCast::Operation(string_t input, float &result, bool strict) {\n \treturn TryDoubleCast<float>(input.GetData(), input.GetSize(), result, strict);\n@@ -1487,7 +1010,7 @@ bool TryCast::Operation(string_t input, double &result, bool strict) {\n \n template <>\n bool TryCastErrorMessageCommaSeparated::Operation(string_t input, float &result, string *error_message, bool strict) {\n-\tif (!TryDoubleCast<float, ','>(input.GetData(), input.GetSize(), result, strict)) {\n+\tif (!TryDoubleCast<float>(input.GetData(), input.GetSize(), result, strict, ',')) {\n \t\tHandleCastError::AssignError(StringUtil::Format(\"Could not cast string to float: \\\"%s\\\"\", input.GetString()),\n \t\t                             error_message);\n \t\treturn false;\n@@ -1497,7 +1020,7 @@ bool TryCastErrorMessageCommaSeparated::Operation(string_t input, float &result,\n \n template <>\n bool TryCastErrorMessageCommaSeparated::Operation(string_t input, double &result, string *error_message, bool strict) {\n-\tif (!TryDoubleCast<double, ','>(input.GetData(), input.GetSize(), result, strict)) {\n+\tif (!TryDoubleCast<double>(input.GetData(), input.GetSize(), result, strict, ',')) {\n \t\tHandleCastError::AssignError(StringUtil::Format(\"Could not cast string to double: \\\"%s\\\"\", input.GetString()),\n \t\t                             error_message);\n \t\treturn false;\ndiff --git a/src/execution/operator/csv_scanner/scanner/base_scanner.cpp b/src/execution/operator/csv_scanner/scanner/base_scanner.cpp\nindex a1e72552eea7..9ba2e6d54177 100644\n--- a/src/execution/operator/csv_scanner/scanner/base_scanner.cpp\n+++ b/src/execution/operator/csv_scanner/scanner/base_scanner.cpp\n@@ -7,18 +7,11 @@ ScannerResult::ScannerResult(CSVStates &states_p, CSVStateMachine &state_machine\n     : states(states_p), state_machine(state_machine_p) {\n }\n \n-idx_t ScannerResult::Size() {\n-\treturn result_position;\n-}\n-\n-bool ScannerResult::Empty() {\n-\treturn result_position == 0;\n-}\n-\n BaseScanner::BaseScanner(shared_ptr<CSVBufferManager> buffer_manager_p, shared_ptr<CSVStateMachine> state_machine_p,\n-                         shared_ptr<CSVErrorHandler> error_handler_p, CSVIterator iterator_p)\n-    : error_handler(std::move(error_handler_p)), state_machine(std::move(state_machine_p)), iterator(iterator_p),\n-      buffer_manager(std::move(buffer_manager_p)) {\n+                         shared_ptr<CSVErrorHandler> error_handler_p, shared_ptr<CSVFileScan> csv_file_scan_p,\n+                         CSVIterator iterator_p)\n+    : csv_file_scan(std::move(csv_file_scan_p)), error_handler(std::move(error_handler_p)),\n+      state_machine(std::move(state_machine_p)), iterator(iterator_p), buffer_manager(std::move(buffer_manager_p)) {\n \tD_ASSERT(buffer_manager);\n \tD_ASSERT(state_machine);\n \t// Initialize current buffer handle\ndiff --git a/src/execution/operator/csv_scanner/scanner/column_count_scanner.cpp b/src/execution/operator/csv_scanner/scanner/column_count_scanner.cpp\nindex 7b2195b0925e..d07087478580 100644\n--- a/src/execution/operator/csv_scanner/scanner/column_count_scanner.cpp\n+++ b/src/execution/operator/csv_scanner/scanner/column_count_scanner.cpp\n@@ -50,7 +50,7 @@ ColumnCountScanner::ColumnCountScanner(shared_ptr<CSVBufferManager> buffer_manag\n }\n \n unique_ptr<StringValueScanner> ColumnCountScanner::UpgradeToStringValueScanner() {\n-\tauto scanner = make_uniq<StringValueScanner>(0, buffer_manager, state_machine, error_handler);\n+\tauto scanner = make_uniq<StringValueScanner>(0, buffer_manager, state_machine, error_handler, nullptr);\n \tscanner->sniffing = true;\n \treturn scanner;\n }\ndiff --git a/src/execution/operator/csv_scanner/scanner/skip_scanner.cpp b/src/execution/operator/csv_scanner/scanner/skip_scanner.cpp\nindex 0c5bf6041d7a..b3d526a91a0a 100644\n--- a/src/execution/operator/csv_scanner/scanner/skip_scanner.cpp\n+++ b/src/execution/operator/csv_scanner/scanner/skip_scanner.cpp\n@@ -58,9 +58,6 @@ void SkipScanner::Initialize() {\n }\n \n void SkipScanner::FinalizeChunkProcess() {\n-\tif (result.rows_to_skip == result.row_count) {\n-\t\t// We are done\n-\t\treturn;\n-\t}\n+\t// nop\n }\n } // namespace duckdb\ndiff --git a/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp b/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\nindex bb0e9819d2ee..c3ba21afbf66 100644\n--- a/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\n+++ b/src/execution/operator/csv_scanner/scanner/string_value_scanner.cpp\n@@ -3,24 +3,23 @@\n #include \"duckdb/execution/operator/csv_scanner/scanner/skip_scanner.hpp\"\n #include \"duckdb/execution/operator/csv_scanner/table_function/csv_file_scanner.hpp\"\n #include \"duckdb/main/client_data.hpp\"\n-\n+#include \"duckdb/common/operator/integer_cast_operator.hpp\"\n+#include \"duckdb/common/operator/double_cast_operator.hpp\"\n #include <algorithm>\n \n namespace duckdb {\n \n StringValueResult::StringValueResult(CSVStates &states, CSVStateMachine &state_machine, CSVBufferHandle &buffer_handle,\n                                      Allocator &buffer_allocator, idx_t result_size_p, idx_t buffer_position,\n-                                     CSVErrorHandler &error_hander_p, CSVIterator &iterator_p, bool store_line_size_p)\n+                                     CSVErrorHandler &error_hander_p, CSVIterator &iterator_p, bool store_line_size_p,\n+                                     shared_ptr<CSVFileScan> csv_file_scan_p, idx_t &lines_read_p)\n     : ScannerResult(states, state_machine), number_of_columns(state_machine.dialect_options.num_cols),\n       null_padding(state_machine.options.null_padding), ignore_errors(state_machine.options.ignore_errors),\n-      null_str(state_machine.options.null_str), result_size(result_size_p), error_handler(error_hander_p),\n-      iterator(iterator_p), store_line_size(store_line_size_p) {\n+      null_str_ptr(state_machine.options.null_str.c_str()), null_str_size(state_machine.options.null_str.size()),\n+      result_size(result_size_p), error_handler(error_hander_p), iterator(iterator_p),\n+      store_line_size(store_line_size_p), csv_file_scan(std::move(csv_file_scan_p)), lines_read(lines_read_p) {\n \t// Vector information\n \tD_ASSERT(number_of_columns > 0);\n-\tvector_size = number_of_columns * result_size;\n-\tvector = make_uniq<Vector>(LogicalType::VARCHAR, vector_size);\n-\tvector_ptr = FlatVector::GetData<string_t>(*vector);\n-\tvalidity_mask = &FlatVector::Validity(*vector);\n \n \t// Buffer Information\n \tbuffer_ptr = buffer_handle.Ptr();\n@@ -28,52 +27,234 @@ StringValueResult::StringValueResult(CSVStates &states, CSVStateMachine &state_m\n \tlast_position = buffer_position;\n \n \t// Current Result information\n-\tresult_position = 0;\n \tprevious_line_start = {iterator.pos.buffer_idx, iterator.pos.buffer_pos, buffer_handle.actual_size};\n \tpre_previous_line_start = previous_line_start;\n+\t// Fill out Parse Types\n+\tvector<LogicalType> logical_types;\n+\tparse_types = make_unsafe_uniq_array<LogicalTypeId>(number_of_columns);\n+\tif (!csv_file_scan) {\n+\t\tfor (idx_t i = 0; i < number_of_columns; i++) {\n+\t\t\tparse_types[i] = LogicalTypeId::VARCHAR;\n+\t\t\tlogical_types.emplace_back(LogicalType::VARCHAR);\n+\t\t}\n+\t} else {\n+\t\tif (csv_file_scan->file_types.size() > number_of_columns) {\n+\t\t\tthrow InvalidInputException(\n+\t\t\t    \"Mismatch between the number of columns (%d) in the CSV file and what is expected in the scanner (%d).\",\n+\t\t\t    number_of_columns, csv_file_scan->file_types.size());\n+\t\t}\n+\t\tfor (idx_t i = 0; i < csv_file_scan->file_types.size(); i++) {\n+\t\t\tauto &type = csv_file_scan->file_types[i];\n+\t\t\tif (StringValueScanner::CanDirectlyCast(type, state_machine.options.dialect_options.date_format)) {\n+\t\t\t\tparse_types[i] = type.id();\n+\t\t\t\tlogical_types.emplace_back(type);\n+\t\t\t} else {\n+\t\t\t\tparse_types[i] = LogicalTypeId::VARCHAR;\n+\t\t\t\tlogical_types.emplace_back(LogicalType::VARCHAR);\n+\t\t\t}\n+\t\t}\n+\t}\n+\t// Fill out Names\n+\tif (!csv_file_scan) {\n+\t\tfor (idx_t i = 0; i < number_of_columns; i++) {\n+\t\t\tstring name = \"Column_\" + to_string(i);\n+\t\t\tnames.emplace_back(name);\n+\t\t}\n+\t} else {\n+\t\tnames = csv_file_scan->file_names;\n+\t\tbool projecting_columns = false;\n+\t\tidx_t i = 0;\n+\t\tfor (auto &col_idx : csv_file_scan->projected_columns) {\n+\t\t\tprojected_columns[col_idx] = i;\n+\t\t\tif (col_idx != i) {\n+\t\t\t\tprojecting_columns = true;\n+\t\t\t}\n+\t\t\ti++;\n+\t\t}\n+\t\tif (!projecting_columns && projected_columns.size() == number_of_columns) {\n+\t\t\tprojected_columns.clear();\n+\t\t\tfor (idx_t j = logical_types.size(); j < number_of_columns; j++) {\n+\t\t\t\t// This can happen if we have sneaky null columns at the end that we wish to ignore\n+\t\t\t\tparse_types[j] = LogicalTypeId::VARCHAR;\n+\t\t\t\tlogical_types.emplace_back(LogicalType::VARCHAR);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n \t// Initialize Parse Chunk\n-\tparse_chunk.Initialize(buffer_allocator, {number_of_columns, LogicalType::VARCHAR}, result_size);\n+\tparse_chunk.Initialize(buffer_allocator, logical_types, result_size);\n+\tfor (auto &col : parse_chunk.data) {\n+\t\tvector_ptr.push_back(FlatVector::GetData<string_t>(col));\n+\t\tvalidity_mask.push_back(&FlatVector::Validity(col));\n+\t}\n+}\n+\n+void StringValueResult::AddValueToVector(const char *value_ptr, const idx_t size, bool allocate) {\n+\tidx_t chunk_col_id = cur_col_id;\n+\tif (!projected_columns.empty()) {\n+\t\tif (projected_columns.find(cur_col_id) == projected_columns.end()) {\n+\t\t\tcur_col_id++;\n+\t\t\treturn;\n+\t\t}\n+\t\tchunk_col_id = projected_columns[cur_col_id];\n+\t}\n+\tif (size == null_str_size) {\n+\t\tif (((quoted && state_machine.options.allow_quoted_nulls) || !quoted)) {\n+\t\t\tbool is_null = true;\n+\t\t\tfor (idx_t i = 0; i < size; i++) {\n+\t\t\t\tif (null_str_ptr[i] != value_ptr[i]) {\n+\t\t\t\t\tis_null = false;\n+\t\t\t\t\tbreak;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\tif (is_null) {\n+\t\t\t\tbool empty = false;\n+\t\t\t\tif (chunk_col_id < state_machine.options.force_not_null.size()) {\n+\t\t\t\t\tempty = state_machine.options.force_not_null[chunk_col_id];\n+\t\t\t\t}\n+\t\t\t\tif (empty) {\n+\t\t\t\t\tif (chunk_col_id >= number_of_columns) {\n+\t\t\t\t\t\tHandleOverLimitRows();\n+\t\t\t\t\t}\n+\t\t\t\t\tif (parse_types[chunk_col_id] != LogicalTypeId::VARCHAR) {\n+\t\t\t\t\t\t// If it is not a varchar, empty values are not accepted, we must error.\n+\t\t\t\t\t\tcast_errors[chunk_col_id] = std::string(\"\");\n+\t\t\t\t\t}\n+\t\t\t\t\tstatic_cast<string_t *>(vector_ptr[chunk_col_id])[number_of_rows] = string_t();\n+\t\t\t\t} else {\n+\t\t\t\t\tif (chunk_col_id == number_of_columns) {\n+\t\t\t\t\t\t// We check for a weird case, where we ignore an extra value, if it is a null value\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t\tvalidity_mask[chunk_col_id]->SetInvalid(number_of_rows);\n+\t\t\t\t}\n+\t\t\t\tcur_col_id++;\n+\t\t\t\treturn;\n+\t\t\t}\n+\t\t}\n+\t}\n+\tif (chunk_col_id >= number_of_columns) {\n+\t\tHandleOverLimitRows();\n+\t\tchunk_col_id = cur_col_id;\n+\t\tif (!projected_columns.empty()) {\n+\t\t\tif (projected_columns.find(cur_col_id) == projected_columns.end()) {\n+\t\t\t\tcur_col_id++;\n+\t\t\t\treturn;\n+\t\t\t}\n+\t\t\tchunk_col_id = projected_columns[cur_col_id];\n+\t\t}\n+\t}\n+\tbool success = true;\n+\tswitch (parse_types[chunk_col_id]) {\n+\tcase LogicalTypeId::TINYINT:\n+\t\tsuccess = TrySimpleIntegerCast(value_ptr, size, static_cast<int8_t *>(vector_ptr[chunk_col_id])[number_of_rows],\n+\t\t                               false);\n+\t\tbreak;\n+\tcase LogicalTypeId::SMALLINT:\n+\t\tsuccess = TrySimpleIntegerCast(value_ptr, size,\n+\t\t                               static_cast<int16_t *>(vector_ptr[chunk_col_id])[number_of_rows], false);\n+\t\tbreak;\n+\tcase LogicalTypeId::INTEGER:\n+\t\tsuccess = TrySimpleIntegerCast(value_ptr, size,\n+\t\t                               static_cast<int32_t *>(vector_ptr[chunk_col_id])[number_of_rows], false);\n+\t\tbreak;\n+\tcase LogicalTypeId::BIGINT:\n+\t\tsuccess = TrySimpleIntegerCast(value_ptr, size,\n+\t\t                               static_cast<int64_t *>(vector_ptr[chunk_col_id])[number_of_rows], false);\n+\t\tbreak;\n+\tcase LogicalTypeId::UTINYINT:\n+\t\tsuccess = TrySimpleIntegerCast<uint8_t, false>(\n+\t\t    value_ptr, size, static_cast<uint8_t *>(vector_ptr[chunk_col_id])[number_of_rows], false);\n+\t\tbreak;\n+\tcase LogicalTypeId::USMALLINT:\n+\t\tsuccess = TrySimpleIntegerCast<uint16_t, false>(\n+\t\t    value_ptr, size, static_cast<uint16_t *>(vector_ptr[chunk_col_id])[number_of_rows], false);\n+\t\tbreak;\n+\tcase LogicalTypeId::UINTEGER:\n+\t\tsuccess = TrySimpleIntegerCast<uint32_t, false>(\n+\t\t    value_ptr, size, static_cast<uint32_t *>(vector_ptr[chunk_col_id])[number_of_rows], false);\n+\t\tbreak;\n+\tcase LogicalTypeId::UBIGINT:\n+\t\tsuccess = TrySimpleIntegerCast<uint64_t, false>(\n+\t\t    value_ptr, size, static_cast<uint64_t *>(vector_ptr[chunk_col_id])[number_of_rows], false);\n+\t\tbreak;\n+\tcase LogicalTypeId::DOUBLE:\n+\t\tsuccess =\n+\t\t    TryDoubleCast<double>(value_ptr, size, static_cast<double *>(vector_ptr[chunk_col_id])[number_of_rows],\n+\t\t                          false, state_machine.options.decimal_separator[0]);\n+\t\tbreak;\n+\tcase LogicalTypeId::FLOAT:\n+\t\tsuccess = TryDoubleCast<float>(value_ptr, size, static_cast<float *>(vector_ptr[chunk_col_id])[number_of_rows],\n+\t\t                               false, state_machine.options.decimal_separator[0]);\n+\t\tbreak;\n+\tcase LogicalTypeId::DATE: {\n+\t\tidx_t pos;\n+\t\tbool special;\n+\t\tsuccess = Date::TryConvertDate(value_ptr, size, pos,\n+\t\t                               static_cast<date_t *>(vector_ptr[chunk_col_id])[number_of_rows], special, false);\n+\t\tbreak;\n+\t}\n+\tcase LogicalTypeId::TIMESTAMP: {\n+\t\tsuccess = Timestamp::TryConvertTimestamp(\n+\t\t              value_ptr, size, static_cast<timestamp_t *>(vector_ptr[chunk_col_id])[number_of_rows]) ==\n+\t\t          TimestampCastResult::SUCCESS;\n+\t\tbreak;\n+\t}\n+\tdefault:\n+\t\tif (allocate) {\n+\t\t\tstatic_cast<string_t *>(vector_ptr[chunk_col_id])[number_of_rows] =\n+\t\t\t    StringVector::AddStringOrBlob(parse_chunk.data[chunk_col_id], string_t(value_ptr, size));\n+\t\t} else {\n+\t\t\tstatic_cast<string_t *>(vector_ptr[chunk_col_id])[number_of_rows] = string_t(value_ptr, size);\n+\t\t}\n+\t\tbreak;\n+\t}\n+\tif (!success) {\n+\t\t// We had a casting error, we push it here because we can only error when finishing the line read.\n+\t\tcast_errors[chunk_col_id] = std::string(value_ptr, size);\n+\t}\n+\tcur_col_id++;\n }\n \n Value StringValueResult::GetValue(idx_t row_idx, idx_t col_idx) {\n-\tidx_t vector_idx = row_idx * number_of_columns + col_idx;\n-\tif (validity_mask->AllValid()) {\n-\t\treturn Value(vector_ptr[vector_idx]);\n+\tif (validity_mask[col_idx]->AllValid()) {\n+\t\treturn Value(static_cast<string_t *>(vector_ptr[col_idx])[row_idx]);\n \t} else {\n-\t\tif (validity_mask->RowIsValid(vector_idx)) {\n-\t\t\treturn Value(vector_ptr[vector_idx]);\n+\t\tif (validity_mask[col_idx]->RowIsValid(row_idx)) {\n+\t\t\treturn Value(static_cast<string_t *>(vector_ptr[col_idx])[row_idx]);\n \t\t} else {\n \t\t\treturn Value();\n \t\t}\n \t}\n }\n DataChunk &StringValueResult::ToChunk() {\n-\tidx_t number_of_rows = NumberOfRows();\n-\tparse_chunk.Reset();\n-\tconst auto &selection_vectors = state_machine.GetSelectionVector();\n-\tfor (idx_t col_idx = 0; col_idx < parse_chunk.ColumnCount(); col_idx++) {\n-\t\tparse_chunk.data[col_idx].Slice(*vector, selection_vectors[col_idx], number_of_rows);\n-\t}\n \tparse_chunk.SetCardinality(number_of_rows);\n \treturn parse_chunk;\n }\n \n void StringValueResult::AddQuotedValue(StringValueResult &result, const idx_t buffer_pos) {\n \tif (result.escaped) {\n+\t\tidx_t chunk_col_id = result.cur_col_id;\n+\t\tif (!result.projected_columns.empty()) {\n+\t\t\tif (result.projected_columns.find(result.cur_col_id) == result.projected_columns.end()) {\n+\t\t\t\tresult.cur_col_id++;\n+\t\t\t\treturn;\n+\t\t\t}\n+\t\t\tchunk_col_id = result.projected_columns[result.cur_col_id];\n+\t\t}\n \t\t// If it's an escaped value we have to remove all the escapes, this is not really great\n-\t\tauto value = StringValueScanner::RemoveEscape(result.buffer_ptr + result.last_position + 1,\n-\t\t                                              buffer_pos - result.last_position - 2,\n-\t\t                                              result.state_machine.options.GetEscape()[0], *result.vector);\n-\n-\t\tresult.AddValueToVector(value);\n+\t\tauto value = StringValueScanner::RemoveEscape(\n+\t\t    result.buffer_ptr + result.last_position + 1, buffer_pos - result.last_position - 2,\n+\t\t    result.state_machine.options.GetEscape()[0], result.parse_chunk.data[chunk_col_id]);\n+\t\tresult.AddValueToVector(value.GetData(), value.GetSize());\n \t} else {\n \t\tif (buffer_pos < result.last_position + 2) {\n \t\t\t// empty value\n \t\t\tauto value = string_t();\n-\t\t\tresult.AddValueToVector(value);\n+\t\t\tresult.AddValueToVector(value.GetData(), value.GetSize());\n \t\t} else {\n-\t\t\tauto value = string_t(result.buffer_ptr + result.last_position + 1, buffer_pos - result.last_position - 2);\n-\t\t\tresult.AddValueToVector(value);\n+\t\t\tresult.AddValueToVector(result.buffer_ptr + result.last_position + 1,\n+\t\t\t                        buffer_pos - result.last_position - 2);\n \t\t}\n \t}\n \tresult.quoted = false;\n@@ -84,48 +265,23 @@ void StringValueResult::AddValue(StringValueResult &result, const idx_t buffer_p\n \tif (result.last_position > buffer_pos) {\n \t\treturn;\n \t}\n-\n-\tD_ASSERT(result.result_position < result.vector_size);\n-\tif (result.result_position == result.vector_size) {\n-\t\tresult.HandleOverLimitRows();\n-\t}\n \tif (result.quoted) {\n \t\tStringValueResult::AddQuotedValue(result, buffer_pos);\n \t} else {\n-\t\tauto value = string_t(result.buffer_ptr + result.last_position, buffer_pos - result.last_position);\n-\t\tresult.AddValueToVector(value);\n+\t\tresult.AddValueToVector(result.buffer_ptr + result.last_position, buffer_pos - result.last_position);\n \t}\n \tresult.last_position = buffer_pos + 1;\n }\n \n void StringValueResult::HandleOverLimitRows() {\n-\tauto csv_error = CSVError::IncorrectColumnAmountError(state_machine.options, vector_ptr, number_of_columns,\n-\t                                                      result_position - last_row_pos);\n-\tLinesPerBoundary lines_per_batch(iterator.GetBoundaryIdx(), result_position / number_of_columns + 1);\n+\tauto csv_error =\n+\t    CSVError::IncorrectColumnAmountError(state_machine.options, nullptr, number_of_columns, cur_col_id + 1);\n+\tLinesPerBoundary lines_per_batch(iterator.GetBoundaryIdx(), number_of_rows + 1);\n \terror_handler.Error(lines_per_batch, csv_error);\n-\tresult_position -= result_position % number_of_columns + number_of_columns;\n+\t// If we get here we need to remove the last line\n+\tcur_col_id = 0;\n }\n \n-void StringValueResult::AddValueToVector(string_t &value, bool allocate) {\n-\tif (((quoted && state_machine.options.allow_quoted_nulls) || !quoted) && value == null_str) {\n-\t\tbool empty = false;\n-\t\tidx_t cur_pos = result_position % number_of_columns;\n-\t\tif (cur_pos < state_machine.options.force_not_null.size()) {\n-\t\t\tempty = state_machine.options.force_not_null[cur_pos];\n-\t\t}\n-\t\tif (empty) {\n-\t\t\tvector_ptr[result_position++] = string_t();\n-\t\t} else {\n-\t\t\tvalidity_mask->SetInvalid(result_position++);\n-\t\t}\n-\t} else {\n-\t\tif (allocate) {\n-\t\t\tvector_ptr[result_position++] = StringVector::AddStringOrBlob(*vector, value);\n-\t\t} else {\n-\t\t\tvector_ptr[result_position++] = value;\n-\t\t}\n-\t}\n-}\n void StringValueResult::QuotedNewLine(StringValueResult &result) {\n \tresult.quoted_new_line = true;\n }\n@@ -136,72 +292,81 @@ void StringValueResult::NullPaddingQuotedNewlineCheck() {\n \t\t// If we have null_padding set, we found a quoted new line, we are scanning the file in parallel and it's the\n \t\t// last row of this thread.\n \t\tauto csv_error = CSVError::NullPaddingFail(state_machine.options);\n-\t\tLinesPerBoundary lines_per_batch(iterator.GetBoundaryIdx(), result_position / number_of_columns + 1);\n+\t\tLinesPerBoundary lines_per_batch(iterator.GetBoundaryIdx(), number_of_rows + 1);\n \t\terror_handler.Error(lines_per_batch, csv_error, true);\n \t}\n }\n \n bool StringValueResult::AddRowInternal() {\n+\tif (!cast_errors.empty()) {\n+\t\t// A wild casting error appears\n+\t\t// Recreate row for rejects-table\n+\t\tvector<Value> row;\n+\t\tif (!state_machine.options.rejects_table_name.empty()) {\n+\t\t\tfor (idx_t col = 0; col < parse_chunk.ColumnCount(); col++) {\n+\t\t\t\tif (cast_errors.find(col) != cast_errors.end()) {\n+\t\t\t\t\trow.push_back(cast_errors[col]);\n+\t\t\t\t} else {\n+\t\t\t\t\trow.push_back(parse_chunk.data[col].GetValue(number_of_rows));\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\tfor (auto &cast_error : cast_errors) {\n+\t\t\tstd::ostringstream error;\n+\t\t\t// Casting Error Message\n+\t\t\terror << \"Could not convert string \\\"\" << cast_error.second << \"\\\" to \\'\"\n+\t\t\t      << LogicalTypeIdToString(parse_types[cast_error.first]) << \"\\'\";\n+\t\t\tauto error_string = error.str();\n+\t\t\tauto csv_error = CSVError::CastError(state_machine.options, names[cast_error.first], error_string,\n+\t\t\t                                     cast_error.first, row);\n+\t\t\tLinesPerBoundary lines_per_batch(iterator.GetBoundaryIdx(), lines_read - 1);\n+\t\t\terror_handler.Error(lines_per_batch, csv_error);\n+\t\t}\n+\t\t// If we got here it means we are ignoring errors, hence we need to signify to our result scanner to ignore this\n+\t\t// row\n+\t\t// Cleanup this line and continue\n+\t\tcast_errors.clear();\n+\t\tcur_col_id = 0;\n+\t\treturn false;\n+\t}\n \tNullPaddingQuotedNewlineCheck();\n \tquoted_new_line = false;\n \t// We need to check if we are getting the correct number of columns here.\n \t// If columns are correct, we add it, and that's it.\n-\tidx_t total_columns_in_row = result_position - last_row_pos;\n-\tif (total_columns_in_row > number_of_columns) {\n-\t\t// If the columns are incorrect:\n-\t\t// Maybe we have too many columns:\n-\t\tif (total_columns_in_row == number_of_columns + 1 && !validity_mask->RowIsValid(result_position - 1)) {\n-\t\t\t// This is a weird case, where we ignore an extra value, if it is a null value\n-\t\t\tresult_position--;\n-\t\t\tvalidity_mask->SetValid(result_position);\n-\t\t} else {\n-\t\t\tHandleOverLimitRows();\n-\t\t}\n-\t}\n-\tif (result_position % number_of_columns != 0) {\n-\t\t// Maybe we have too few columns:\n-\t\t// 1) if null_padding is on we null pad it\n+\tif (cur_col_id != number_of_columns) {\n+\t\t// We have too few columns:\n \t\tif (null_padding) {\n-\t\t\twhile (result_position % number_of_columns != 0) {\n+\t\t\twhile (cur_col_id < number_of_columns) {\n \t\t\t\tbool empty = false;\n-\t\t\t\tidx_t cur_pos = result_position % number_of_columns;\n-\t\t\t\tif (cur_pos < state_machine.options.force_not_null.size()) {\n-\t\t\t\t\tempty = state_machine.options.force_not_null[cur_pos];\n+\t\t\t\tif (cur_col_id < state_machine.options.force_not_null.size()) {\n+\t\t\t\t\tempty = state_machine.options.force_not_null[cur_col_id];\n \t\t\t\t}\n \t\t\t\tif (empty) {\n-\t\t\t\t\tvector_ptr[result_position++] = string_t();\n+\t\t\t\t\tstatic_cast<string_t *>(vector_ptr[cur_col_id])[number_of_rows] = string_t();\n \t\t\t\t} else {\n-\t\t\t\t\tvalidity_mask->SetInvalid(result_position++);\n+\t\t\t\t\tvalidity_mask[cur_col_id]->SetInvalid(number_of_rows);\n \t\t\t\t}\n+\t\t\t\tcur_col_id++;\n \t\t\t}\n \t\t} else {\n-\t\t\tauto csv_error = CSVError::IncorrectColumnAmountError(state_machine.options, vector_ptr, number_of_columns,\n-\t\t\t                                                      result_position % number_of_columns);\n-\t\t\tLinesPerBoundary lines_per_batch(iterator.GetBoundaryIdx(), result_position / number_of_columns + 1);\n+\t\t\t// If we are not nullpadding this is an error\n+\t\t\tauto csv_error =\n+\t\t\t    CSVError::IncorrectColumnAmountError(state_machine.options, nullptr, number_of_columns, cur_col_id);\n+\t\t\tLinesPerBoundary lines_per_batch(iterator.GetBoundaryIdx(), number_of_rows + 1);\n \t\t\terror_handler.Error(lines_per_batch, csv_error);\n-\t\t\tresult_position -= result_position % number_of_columns;\n-\t\t\tD_ASSERT(result_position % number_of_columns == 0);\n+\t\t\t// If we are here we ignore_errors, so we delete this line\n+\t\t\tnumber_of_rows--;\n \t\t}\n \t}\n-\tlast_row_pos = result_position;\n-\tif (result_position / number_of_columns >= result_size) {\n+\tcur_col_id = 0;\n+\tnumber_of_rows++;\n+\tif (number_of_rows >= result_size) {\n \t\t// We have a full chunk\n \t\treturn true;\n \t}\n \treturn false;\n }\n \n-void StringValueResult::Print() {\n-\tfor (idx_t i = 0; i < result_position; i++) {\n-\t\tstd::cout << vector_ptr[i].GetString();\n-\t\tif ((i + 1) % number_of_columns == 0) {\n-\t\t\tstd::cout << std::endl;\n-\t\t} else {\n-\t\t\tstd::cout << \",\";\n-\t\t}\n-\t}\n-}\n-\n bool StringValueResult::AddRow(StringValueResult &result, const idx_t buffer_pos) {\n \tif (result.last_position <= buffer_pos) {\n \t\tLinePosition current_line_start = {result.iterator.pos.buffer_idx, result.iterator.pos.buffer_pos,\n@@ -212,21 +377,16 @@ bool StringValueResult::AddRow(StringValueResult &result, const idx_t buffer_pos\n \t\t}\n \t\tif (current_line_size > result.state_machine.options.maximum_line_size) {\n \t\t\tauto csv_error = CSVError::LineSizeError(result.state_machine.options, current_line_size);\n-\t\t\tLinesPerBoundary lines_per_batch(result.iterator.GetBoundaryIdx(),\n-\t\t\t                                 result.result_position / result.number_of_columns);\n+\t\t\tLinesPerBoundary lines_per_batch(result.iterator.GetBoundaryIdx(), result.number_of_rows + 1);\n \t\t\tresult.error_handler.Error(lines_per_batch, csv_error);\n \t\t}\n \t\tresult.pre_previous_line_start = result.previous_line_start;\n \t\tresult.previous_line_start = current_line_start;\n-\t\tif (result.result_position == result.vector_size) {\n-\t\t\tresult.HandleOverLimitRows();\n-\t\t}\n \t\t// We add the value\n \t\tif (result.quoted) {\n \t\t\tStringValueResult::AddQuotedValue(result, buffer_pos);\n \t\t} else {\n-\t\t\tauto value = string_t(result.buffer_ptr + result.last_position, buffer_pos - result.last_position);\n-\t\t\tresult.AddValueToVector(value);\n+\t\t\tresult.AddValueToVector(result.buffer_ptr + result.last_position, buffer_pos - result.last_position);\n \t\t}\n \t\tif (result.state_machine.dialect_options.state_machine_options.new_line == NewLineIdentifier::CARRY_ON) {\n \t\t\tif (result.states.states[1] == CSVState::RECORD_SEPARATOR) {\n@@ -246,11 +406,10 @@ bool StringValueResult::AddRow(StringValueResult &result, const idx_t buffer_pos\n \n void StringValueResult::InvalidState(StringValueResult &result) {\n \t// FIXME: How do we recover from an invalid state? Can we restart the state machine and jump to the next row?\n-\tauto csv_error =\n-\t    CSVError::UnterminatedQuotesError(result.state_machine.options, result.vector_ptr, result.result_position,\n-\t                                      result.result_position % result.number_of_columns);\n-\tLinesPerBoundary lines_per_batch(result.iterator.GetBoundaryIdx(),\n-\t                                 result.result_position / result.number_of_columns);\n+\tauto csv_error = CSVError::UnterminatedQuotesError(result.state_machine.options,\n+\t                                                   static_cast<string_t *>(result.vector_ptr[result.cur_col_id]),\n+\t                                                   result.number_of_rows, result.cur_col_id);\n+\tLinesPerBoundary lines_per_batch(result.iterator.GetBoundaryIdx(), result.number_of_rows);\n \tresult.error_handler.Error(lines_per_batch, csv_error);\n }\n \n@@ -261,64 +420,45 @@ bool StringValueResult::EmptyLine(StringValueResult &result, const idx_t buffer_\n \t    result.state_machine.dialect_options.state_machine_options.new_line == NewLineIdentifier::CARRY_ON) {\n \t\tresult.last_position++;\n \t}\n-\tif (result.parse_chunk.ColumnCount() == 1) {\n-\t\tif (result.null_str.Empty()) {\n+\tif (result.number_of_columns == 1) {\n+\t\tif (result.null_str_size == 0) {\n \t\t\tbool empty = false;\n \t\t\tif (!result.state_machine.options.force_not_null.empty()) {\n-\t\t\t\tempty = result.state_machine.options.force_not_null[result.result_position % result.number_of_columns];\n+\t\t\t\tempty = result.state_machine.options.force_not_null[0];\n \t\t\t}\n \t\t\tif (empty) {\n-\t\t\t\tresult.vector_ptr[result.result_position++] = string_t();\n+\t\t\t\tstatic_cast<string_t *>(result.vector_ptr[0])[result.number_of_rows] = string_t();\n \t\t\t} else {\n-\t\t\t\tresult.validity_mask->SetInvalid(result.result_position++);\n+\t\t\t\tresult.validity_mask[0]->SetInvalid(result.number_of_rows);\n \t\t\t}\n+\t\t\tresult.number_of_rows++;\n \t\t}\n-\t\tif (result.result_position / result.number_of_columns >= result.result_size) {\n+\t\tif (result.number_of_rows >= result.result_size) {\n \t\t\t// We have a full chunk\n \t\t\treturn true;\n \t\t}\n-\t\tresult.last_row_pos = result.result_position;\n \t}\n \treturn false;\n }\n \n-idx_t StringValueResult::NumberOfRows() {\n-\tif (result_position % number_of_columns != 0) {\n-\t\t// Maybe we have too few columns:\n-\t\t// 1) if null_padding is on we null pad it\n-\t\tif (null_padding) {\n-\t\t\twhile (result_position % number_of_columns != 0) {\n-\t\t\t\tbool empty = false;\n-\t\t\t\tidx_t cur_pos = result_position % number_of_columns;\n-\t\t\t\tif (cur_pos < state_machine.options.force_not_null.size()) {\n-\t\t\t\t\tempty = state_machine.options.force_not_null[cur_pos];\n-\t\t\t\t}\n-\t\t\t\tif (empty) {\n-\t\t\t\t\tvector_ptr[result_position++] = string_t();\n-\t\t\t\t} else {\n-\t\t\t\t\tvalidity_mask->SetInvalid(result_position++);\n-\t\t\t\t}\n-\t\t\t}\n-\t\t} else {\n-\t\t\tauto csv_error = CSVError::IncorrectColumnAmountError(state_machine.options, vector_ptr, number_of_columns,\n-\t\t\t                                                      result_position % number_of_columns);\n-\t\t\tLinesPerBoundary lines_per_batch(iterator.GetBoundaryIdx(), result_position / number_of_columns + 1);\n-\t\t\terror_handler.Error(lines_per_batch, csv_error);\n-\t\t\tresult_position -= result_position % number_of_columns;\n-\t\t\tD_ASSERT(result_position % number_of_columns == 0);\n-\t\t}\n-\t}\n-\treturn result_position / number_of_columns;\n-}\n-\n StringValueScanner::StringValueScanner(idx_t scanner_idx_p, const shared_ptr<CSVBufferManager> &buffer_manager,\n                                        const shared_ptr<CSVStateMachine> &state_machine,\n-                                       const shared_ptr<CSVErrorHandler> &error_handler, CSVIterator boundary,\n+                                       const shared_ptr<CSVErrorHandler> &error_handler,\n+                                       const shared_ptr<CSVFileScan> &csv_file_scan, CSVIterator boundary,\n                                        idx_t result_size)\n-    : BaseScanner(buffer_manager, state_machine, error_handler, boundary), scanner_idx(scanner_idx_p),\n+    : BaseScanner(buffer_manager, state_machine, error_handler, csv_file_scan, boundary), scanner_idx(scanner_idx_p),\n       result(states, *state_machine, *cur_buffer_handle, BufferAllocator::Get(buffer_manager->context), result_size,\n              iterator.pos.buffer_pos, *error_handler, iterator,\n-             buffer_manager->context.client_data->debug_set_max_line_length) {\n+             buffer_manager->context.client_data->debug_set_max_line_length, csv_file_scan, lines_read) {\n+}\n+\n+StringValueScanner::StringValueScanner(const shared_ptr<CSVBufferManager> &buffer_manager,\n+                                       const shared_ptr<CSVStateMachine> &state_machine,\n+                                       const shared_ptr<CSVErrorHandler> &error_handler)\n+    : BaseScanner(buffer_manager, state_machine, error_handler, nullptr, {}), scanner_idx(0),\n+      result(states, *state_machine, *cur_buffer_handle, Allocator::DefaultAllocator(), STANDARD_VECTOR_SIZE,\n+             iterator.pos.buffer_pos, *error_handler, iterator,\n+             buffer_manager->context.client_data->debug_set_max_line_length, csv_file_scan, lines_read) {\n }\n \n unique_ptr<StringValueScanner> StringValueScanner::GetCSVScanner(ClientContext &context, CSVReaderOptions &options) {\n@@ -328,7 +468,7 @@ unique_ptr<StringValueScanner> StringValueScanner::GetCSVScanner(ClientContext &\n \tstate_machine->dialect_options.num_cols = options.dialect_options.num_cols;\n \tstate_machine->dialect_options.header = options.dialect_options.header;\n \tauto buffer_manager = make_shared<CSVBufferManager>(context, options, options.file_path, 0);\n-\tauto scanner = make_uniq<StringValueScanner>(0, buffer_manager, state_machine, make_shared<CSVErrorHandler>());\n+\tauto scanner = make_uniq<StringValueScanner>(buffer_manager, state_machine, make_shared<CSVErrorHandler>());\n \tscanner->csv_file_scan = make_shared<CSVFileScan>(context, options.file_path, options);\n \tscanner->csv_file_scan->InitializeProjection();\n \treturn scanner;\n@@ -339,9 +479,11 @@ bool StringValueScanner::FinishedIterator() {\n }\n \n StringValueResult &StringValueScanner::ParseChunk() {\n-\tresult.result_position = 0;\n-\tresult.last_row_pos = 0;\n-\tresult.validity_mask->SetAllValid(result.vector_size);\n+\tresult.number_of_rows = 0;\n+\tresult.cur_col_id = 0;\n+\tfor (auto &v : result.validity_mask) {\n+\t\tv->SetAllValid(result.result_size);\n+\t}\n \tParseChunkInternal(result);\n \treturn result;\n }\n@@ -364,7 +506,7 @@ void StringValueScanner::Flush(DataChunk &insert_chunk) {\n \tauto &reader_data = csv_file_scan->reader_data;\n \t// Now Do the cast-aroo\n \tfor (idx_t c = 0; c < reader_data.column_ids.size(); c++) {\n-\t\tauto col_idx = reader_data.column_ids[c];\n+\t\tauto col_idx = c;\n \t\tauto result_idx = reader_data.column_mapping[c];\n \t\tif (col_idx >= parse_chunk.ColumnCount()) {\n \t\t\tthrow InvalidInputException(\"Mismatch between the schema of different files\");\n@@ -372,9 +514,9 @@ void StringValueScanner::Flush(DataChunk &insert_chunk) {\n \t\tauto &parse_vector = parse_chunk.data[col_idx];\n \t\tauto &result_vector = insert_chunk.data[result_idx];\n \t\tauto &type = result_vector.GetType();\n-\t\tif (type.id() == LogicalTypeId::VARCHAR) {\n-\t\t\t// target type is varchar: no need to convert\n-\t\t\t// reinterpret rather than reference, so we can deal with user-defined types\n+\t\tauto &parse_type = parse_vector.GetType();\n+\t\tif (type == LogicalType::VARCHAR || (type != LogicalType::VARCHAR && parse_type != LogicalType::VARCHAR)) {\n+\t\t\t// reinterpret rather than reference\n \t\t\tresult_vector.Reinterpret(parse_vector);\n \t\t} else {\n \t\t\tstring error_message;\n@@ -430,8 +572,8 @@ void StringValueScanner::Flush(DataChunk &insert_chunk) {\n \t\t\t\tfor (idx_t col = 0; col < parse_chunk.ColumnCount(); col++) {\n \t\t\t\t\trow.push_back(parse_chunk.GetValue(col, line_error));\n \t\t\t\t}\n-\t\t\t\tauto csv_error = CSVError::CastError(state_machine->options, parse_chunk, line_error,\n-\t\t\t\t                                     csv_file_scan->names[col_idx], error_message, col_idx, row);\n+\t\t\t\tauto csv_error = CSVError::CastError(state_machine->options, csv_file_scan->names[col_idx],\n+\t\t\t\t                                     error_message, col_idx, row);\n \t\t\t\tLinesPerBoundary lines_per_batch(iterator.GetBoundaryIdx(),\n \t\t\t\t                                 lines_read - parse_chunk.size() + line_error);\n \t\t\t\terror_handler->Error(lines_per_batch, csv_error);\n@@ -447,8 +589,8 @@ void StringValueScanner::Flush(DataChunk &insert_chunk) {\n \t\t\t\t\tfor (idx_t col = 0; col < parse_chunk.ColumnCount(); col++) {\n \t\t\t\t\t\trow.push_back(parse_chunk.GetValue(col, line_error));\n \t\t\t\t\t}\n-\t\t\t\t\tauto csv_error = CSVError::CastError(state_machine->options, parse_chunk, line_error,\n-\t\t\t\t\t                                     csv_file_scan->names[col_idx], error_message, col_idx, row);\n+\t\t\t\t\tauto csv_error = CSVError::CastError(state_machine->options, csv_file_scan->names[col_idx],\n+\t\t\t\t\t                                     error_message, col_idx, row);\n \t\t\t\t\tLinesPerBoundary lines_per_batch(iterator.GetBoundaryIdx(),\n \t\t\t\t\t                                 lines_read - parse_chunk.size() + line_error);\n \t\t\t\t\terror_handler->Error(lines_per_batch, csv_error);\n@@ -492,7 +634,7 @@ void StringValueScanner::ProcessExtraRow() {\n \t\tcase CSVState::INVALID:\n \t\t\tresult.InvalidState(result);\n \t\t\titerator.pos.buffer_pos++;\n-\t\t\tbreak;\n+\t\t\treturn;\n \t\tcase CSVState::RECORD_SEPARATOR:\n \t\t\tif (states.states[0] == CSVState::RECORD_SEPARATOR) {\n \t\t\t\tlines_read++;\n@@ -647,23 +789,26 @@ void StringValueScanner::ProcessOverbufferValue() {\n \t\tvalue = string_t(overbuffer_string.c_str() + result.quoted, overbuffer_string.size() - 2);\n \t\tif (result.escaped) {\n \t\t\tconst auto str_ptr = static_cast<const char *>(overbuffer_string.c_str() + result.quoted);\n-\t\t\tvalue = StringValueScanner::RemoveEscape(\n-\t\t\t    str_ptr, overbuffer_string.size() - 2,\n-\t\t\t    state_machine->dialect_options.state_machine_options.escape.GetValue(), *result.vector);\n+\t\t\tvalue =\n+\t\t\t    StringValueScanner::RemoveEscape(str_ptr, overbuffer_string.size() - 2,\n+\t\t\t                                     state_machine->dialect_options.state_machine_options.escape.GetValue(),\n+\t\t\t                                     result.parse_chunk.data[result.cur_col_id]);\n \t\t}\n \t} else {\n \t\tvalue = string_t(overbuffer_string.c_str(), overbuffer_string.size());\n \t}\n-\tif (!states.IsNotSet()) {\n-\t\tresult.AddValueToVector(value, true);\n+\n+\tif (states.EmptyLine() && state_machine->dialect_options.num_cols == 1) {\n+\t\tresult.EmptyLine(result, iterator.pos.buffer_pos);\n+\t} else if (!states.IsNotSet()) {\n+\t\tresult.AddValueToVector(value.GetData(), value.GetSize(), true);\n \t}\n+\n \tif (states.NewRow() && !states.IsNotSet()) {\n \t\tresult.AddRowInternal();\n \t\tlines_read++;\n \t}\n-\tif (states.EmptyLine() && state_machine->dialect_options.num_cols == 1) {\n-\t\tresult.last_row_pos = result.result_position;\n-\t}\n+\n \tif (iterator.pos.buffer_pos >= cur_buffer_handle->actual_size && cur_buffer_handle->is_last_buffer) {\n \t\tresult.added_last_line = true;\n \t}\n@@ -690,9 +835,10 @@ bool StringValueScanner::MoveToNextBuffer() {\n \t\t\t// This means we reached the end of the file, we must add a last line if there is any to be added\n \t\t\tif (states.EmptyLine() || states.NewRow() || result.added_last_line || states.IsCurrentNewRow() ||\n \t\t\t    states.IsNotSet()) {\n-\t\t\t\twhile (result.result_position % result.number_of_columns != 0) {\n-\t\t\t\t\tresult.result_position--;\n+\t\t\t\tif (result.cur_col_id == result.number_of_columns) {\n+\t\t\t\t\tresult.number_of_rows++;\n \t\t\t\t}\n+\t\t\t\tresult.cur_col_id = 0;\n \t\t\t\treturn false;\n \t\t\t} else if (states.NewValue()) {\n \t\t\t\tlines_read++;\n@@ -774,6 +920,42 @@ void StringValueScanner::SkipUntilNewLine() {\n \t}\n }\n \n+bool StringValueScanner::CanDirectlyCast(const LogicalType &type,\n+                                         const map<LogicalTypeId, CSVOption<StrpTimeFormat>> &format_options) {\n+\n+\tswitch (type.id()) {\n+\t\t// All Integers (Except HugeInt)\n+\tcase LogicalTypeId::TINYINT:\n+\tcase LogicalTypeId::SMALLINT:\n+\tcase LogicalTypeId::INTEGER:\n+\tcase LogicalTypeId::BIGINT:\n+\tcase LogicalTypeId::UTINYINT:\n+\tcase LogicalTypeId::USMALLINT:\n+\tcase LogicalTypeId::UINTEGER:\n+\tcase LogicalTypeId::UBIGINT:\n+\tcase LogicalTypeId::DOUBLE:\n+\tcase LogicalTypeId::FLOAT:\n+\t\treturn true;\n+\tcase LogicalTypeId::DATE:\n+\t\t// We can only internally cast YYYY-MM-DD\n+\t\tif (format_options.at(LogicalTypeId::DATE).GetValue().format_specifier == \"%Y-%m-%d\") {\n+\t\t\treturn true;\n+\t\t} else {\n+\t\t\treturn false;\n+\t\t}\n+\tcase LogicalTypeId::TIMESTAMP:\n+\t\tif (format_options.at(LogicalTypeId::TIMESTAMP).GetValue().format_specifier == \"%Y-%m-%d %H:%M:%S\") {\n+\t\t\treturn true;\n+\t\t} else {\n+\t\t\treturn false;\n+\t\t}\n+\tcase LogicalType::VARCHAR:\n+\t\treturn true;\n+\tdefault:\n+\t\treturn false;\n+\t}\n+}\n+\n void StringValueScanner::SetStart() {\n \tif (iterator.pos.buffer_idx == 0 && iterator.pos.buffer_pos == 0) {\n \t\t// This means this is the very first buffer\n@@ -785,32 +967,48 @@ void StringValueScanner::SetStart() {\n \t}\n \t// We have to look for a new line that fits our schema\n \t// 1. We walk until the next new line\n-\tSkipUntilNewLine();\n-\tif (state_machine->options.null_padding) {\n-\t\t// When Null Padding, we assume we start from the correct new-line\n-\t\treturn;\n-\t}\n-\tStringValueScanner scan_finder(0, buffer_manager, state_machine, make_shared<CSVErrorHandler>(true), iterator, 1);\n-\tauto &tuples = scan_finder.ParseChunk();\n-\tif (tuples.Empty() || tuples.Size() != state_machine->options.dialect_options.num_cols) {\n-\t\t// If no tuples were parsed, this is not the correct start, we need to skip until the next new line\n-\t\t// Or if columns don't match, this is not the correct start, we need to skip until the next new line\n-\t\tif (scan_finder.iterator.pos.buffer_pos >= cur_buffer_handle->actual_size &&\n-\t\t    cur_buffer_handle->is_last_buffer) {\n-\t\t\titerator.pos.buffer_idx = scan_finder.iterator.pos.buffer_idx;\n-\t\t\titerator.pos.buffer_pos = scan_finder.iterator.pos.buffer_pos;\n-\t\t\tresult.last_position = iterator.pos.buffer_pos;\n+\tbool line_found;\n+\tunique_ptr<StringValueScanner> scan_finder;\n+\tdo {\n+\t\tSkipUntilNewLine();\n+\t\tif (state_machine->options.null_padding) {\n+\t\t\t// When Null Padding, we assume we start from the correct new-line\n \t\t\treturn;\n \t\t}\n-\t}\n-\titerator.pos.buffer_idx = scan_finder.result.pre_previous_line_start.buffer_idx;\n-\titerator.pos.buffer_pos = scan_finder.result.pre_previous_line_start.buffer_pos;\n+\t\tscan_finder = make_uniq<StringValueScanner>(0, buffer_manager, state_machine,\n+\t\t                                            make_shared<CSVErrorHandler>(true), csv_file_scan, iterator, 1);\n+\t\tauto &tuples = scan_finder->ParseChunk();\n+\t\tline_found = true;\n+\t\tif (tuples.number_of_rows != 1) {\n+\t\t\tline_found = false;\n+\t\t\t// If no tuples were parsed, this is not the correct start, we need to skip until the next new line\n+\t\t\t// Or if columns don't match, this is not the correct start, we need to skip until the next new line\n+\t\t\tif (scan_finder->previous_buffer_handle) {\n+\t\t\t\tif (scan_finder->iterator.pos.buffer_pos >= scan_finder->previous_buffer_handle->actual_size &&\n+\t\t\t\t    scan_finder->previous_buffer_handle->is_last_buffer) {\n+\t\t\t\t\titerator.pos.buffer_idx = scan_finder->iterator.pos.buffer_idx;\n+\t\t\t\t\titerator.pos.buffer_pos = scan_finder->iterator.pos.buffer_pos;\n+\t\t\t\t\tresult.last_position = iterator.pos.buffer_pos;\n+\t\t\t\t\titerator.done = scan_finder->iterator.done;\n+\t\t\t\t\treturn;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t} while (!line_found);\n+\titerator.pos.buffer_idx = scan_finder->result.pre_previous_line_start.buffer_idx;\n+\titerator.pos.buffer_pos = scan_finder->result.pre_previous_line_start.buffer_pos;\n \tresult.last_position = iterator.pos.buffer_pos;\n }\n \n void StringValueScanner::FinalizeChunkProcess() {\n-\tif (result.result_position >= result.vector_size || iterator.done) {\n+\tif (result.number_of_rows >= result.result_size || iterator.done) {\n \t\t// We are done\n+\t\tif (!sniffing) {\n+\t\t\tif (csv_file_scan) {\n+\t\t\t\tcsv_file_scan->bytes_read += bytes_read;\n+\t\t\t\tbytes_read = 0;\n+\t\t\t}\n+\t\t}\n \t\treturn;\n \t}\n \t// If we are not done we have two options.\n@@ -824,7 +1022,7 @@ void StringValueScanner::FinalizeChunkProcess() {\n \t\t}\n \t\tbool moved = MoveToNextBuffer();\n \t\tif (cur_buffer_handle) {\n-\t\t\tif (moved && result.result_position % result.number_of_columns != 0) {\n+\t\t\tif (moved && result.cur_col_id < result.number_of_columns && result.cur_col_id > 0) {\n \t\t\t\tProcessExtraRow();\n \t\t\t} else if (!moved) {\n \t\t\t\tProcessExtraRow();\n@@ -836,9 +1034,9 @@ void StringValueScanner::FinalizeChunkProcess() {\n \t} else {\n \t\t// 2) If a boundary is not set\n \t\t// We read until the chunk is complete, or we have nothing else to read.\n-\t\twhile (!FinishedFile() && result.result_position < result.vector_size) {\n+\t\twhile (!FinishedFile() && result.number_of_rows < result.result_size) {\n \t\t\tMoveToNextBuffer();\n-\t\t\tif (result.result_position >= result.vector_size) {\n+\t\t\tif (result.number_of_rows >= result.result_size) {\n \t\t\t\treturn;\n \t\t\t}\n \t\t\tif (cur_buffer_handle) {\n@@ -847,9 +1045,10 @@ void StringValueScanner::FinalizeChunkProcess() {\n \t\t}\n \t\titerator.done = FinishedFile();\n \t\tif (result.null_padding) {\n-\t\t\twhile (result.result_position % result.number_of_columns != 0) {\n-\t\t\t\tresult.validity_mask->SetInvalid(result.result_position++);\n+\t\t\twhile (result.cur_col_id < result.number_of_columns) {\n+\t\t\t\tresult.validity_mask[result.cur_col_id++]->SetInvalid(result.number_of_rows);\n \t\t\t}\n+\t\t\tresult.number_of_rows++;\n \t\t}\n \t}\n }\ndiff --git a/src/execution/operator/csv_scanner/sniffer/csv_sniffer.cpp b/src/execution/operator/csv_scanner/sniffer/csv_sniffer.cpp\nindex f3369f11ce5c..2778adfc8768 100644\n--- a/src/execution/operator/csv_scanner/sniffer/csv_sniffer.cpp\n+++ b/src/execution/operator/csv_scanner/sniffer/csv_sniffer.cpp\n@@ -44,7 +44,8 @@ void MatchAndReplace(CSVOption<T> &original, CSVOption<T> &sniffed, const string\n \t\toriginal.Set(sniffed.GetValue(), false);\n \t}\n }\n-void MatchAndRepaceUserSetVariables(DialectOptions &original, DialectOptions &sniffed, string &error) {\n+void MatchAndRepaceUserSetVariables(DialectOptions &original, DialectOptions &sniffed, string &error, bool found_date,\n+                                    bool found_timestamp) {\n \tMatchAndReplace(original.header, sniffed.header, \"Header\", error);\n \tif (sniffed.state_machine_options.new_line.GetValue() != NewLineIdentifier::NOT_SET) {\n \t\t// Is sniffed line is not set (e.g., single-line file) , we don't try to replace and match.\n@@ -56,15 +57,28 @@ void MatchAndRepaceUserSetVariables(DialectOptions &original, DialectOptions &sn\n \t                error);\n \tMatchAndReplace(original.state_machine_options.quote, sniffed.state_machine_options.quote, \"Quote\", error);\n \tMatchAndReplace(original.state_machine_options.escape, sniffed.state_machine_options.escape, \"Escape\", error);\n-\tMatchAndReplace(original.date_format[LogicalTypeId::DATE], sniffed.date_format[LogicalTypeId::DATE], \"Date Format\",\n-\t                error);\n-\tMatchAndReplace(original.date_format[LogicalTypeId::TIMESTAMP], sniffed.date_format[LogicalTypeId::TIMESTAMP],\n-\t                \"Timestamp Format\", error);\n+\tif (found_date) {\n+\t\tMatchAndReplace(original.date_format[LogicalTypeId::DATE], sniffed.date_format[LogicalTypeId::DATE],\n+\t\t                \"Date Format\", error);\n+\t}\n+\tif (found_timestamp) {\n+\t\tMatchAndReplace(original.date_format[LogicalTypeId::TIMESTAMP], sniffed.date_format[LogicalTypeId::TIMESTAMP],\n+\t\t                \"Timestamp Format\", error);\n+\t}\n }\n // Set the CSV Options in the reference\n void CSVSniffer::SetResultOptions() {\n+\tbool found_date = false;\n+\tbool found_timestamp = false;\n+\tfor (auto &type : detected_types) {\n+\t\tif (type == LogicalType::DATE) {\n+\t\t\tfound_date = true;\n+\t\t} else if (type == LogicalType::TIMESTAMP) {\n+\t\t\tfound_timestamp = true;\n+\t\t}\n+\t}\n \tMatchAndRepaceUserSetVariables(options.dialect_options, best_candidate->GetStateMachine().dialect_options,\n-\t                               options.sniffer_user_mismatch_error);\n+\t                               options.sniffer_user_mismatch_error, found_date, found_timestamp);\n \toptions.dialect_options.num_cols = best_candidate->GetStateMachine().dialect_options.num_cols;\n }\n \ndiff --git a/src/execution/operator/csv_scanner/sniffer/dialect_detection.cpp b/src/execution/operator/csv_scanner/sniffer/dialect_detection.cpp\nindex f404403cb41e..d0ba53d9a411 100644\n--- a/src/execution/operator/csv_scanner/sniffer/dialect_detection.cpp\n+++ b/src/execution/operator/csv_scanner/sniffer/dialect_detection.cpp\n@@ -91,18 +91,18 @@ void CSVSniffer::AnalyzeDialectCandidate(unique_ptr<ColumnCountScanner> scanner,\n \tauto &sniffed_column_counts = scanner->ParseChunk();\n \tidx_t start_row = options.dialect_options.skip_rows.GetValue();\n \tidx_t consistent_rows = 0;\n-\tidx_t num_cols = sniffed_column_counts.Empty() ? 1 : sniffed_column_counts[start_row];\n+\tidx_t num_cols = sniffed_column_counts.result_position == 0 ? 1 : sniffed_column_counts[start_row];\n \tidx_t padding_count = 0;\n \tbool allow_padding = options.null_padding;\n-\tif (sniffed_column_counts.Size() > rows_read) {\n-\t\trows_read = sniffed_column_counts.Size();\n+\tif (sniffed_column_counts.result_position > rows_read) {\n+\t\trows_read = sniffed_column_counts.result_position;\n \t}\n \tif (set_columns.IsCandidateUnacceptable(num_cols, options.null_padding, options.ignore_errors,\n \t                                        sniffed_column_counts.last_value_always_empty)) {\n \t\t// Not acceptable\n \t\treturn;\n \t}\n-\tfor (idx_t row = start_row; row < sniffed_column_counts.Size(); row++) {\n+\tfor (idx_t row = start_row; row < sniffed_column_counts.result_position; row++) {\n \t\tif (set_columns.IsCandidateUnacceptable(sniffed_column_counts[row], options.null_padding, options.ignore_errors,\n \t\t                                        sniffed_column_counts.last_value_always_empty)) {\n \t\t\t// Not acceptable\n@@ -143,7 +143,7 @@ void CSVSniffer::AnalyzeDialectCandidate(unique_ptr<ColumnCountScanner> scanner,\n \t// If the number of rows is consistent with the calculated value after accounting for skipped rows and the\n \t// start row.\n \tbool rows_consistent = consistent_rows + (start_row - options.dialect_options.skip_rows.GetValue()) ==\n-\t                       sniffed_column_counts.Size() - options.dialect_options.skip_rows.GetValue();\n+\t                       sniffed_column_counts.result_position - options.dialect_options.skip_rows.GetValue();\n \t// If there are more than one consistent row.\n \tbool more_than_one_row = (consistent_rows > 1);\n \n@@ -205,7 +205,7 @@ void CSVSniffer::AnalyzeDialectCandidate(unique_ptr<ColumnCountScanner> scanner,\n \n bool CSVSniffer::RefineCandidateNextChunk(ColumnCountScanner &candidate) {\n \tauto &sniffed_column_counts = candidate.ParseChunk();\n-\tfor (idx_t i = 0; i < sniffed_column_counts.Size(); i++) {\n+\tfor (idx_t i = 0; i < sniffed_column_counts.result_position; i++) {\n \t\tif (set_columns.IsSet()) {\n \t\t\treturn !set_columns.IsCandidateUnacceptable(sniffed_column_counts[i], options.null_padding,\n \t\t\t                                            options.ignore_errors,\ndiff --git a/src/execution/operator/csv_scanner/sniffer/header_detection.cpp b/src/execution/operator/csv_scanner/sniffer/header_detection.cpp\nindex 24965e6a2449..a20980876813 100644\n--- a/src/execution/operator/csv_scanner/sniffer/header_detection.cpp\n+++ b/src/execution/operator/csv_scanner/sniffer/header_detection.cpp\n@@ -94,11 +94,23 @@ static string NormalizeColumnName(const string &col_name) {\n \treturn col_name_cleaned;\n }\n void CSVSniffer::DetectHeader() {\n+\tauto &sniffer_state_machine = best_candidate->GetStateMachine();\n+\n+\tif (best_header_row.empty()) {\n+\t\tsniffer_state_machine.dialect_options.header = false;\n+\t\tfor (idx_t col = 0; col < sniffer_state_machine.dialect_options.num_cols; col++) {\n+\t\t\tnames.push_back(GenerateColumnName(sniffer_state_machine.dialect_options.num_cols, col));\n+\t\t}\n+\t\t// If the user provided names, we must replace our header with the user provided names\n+\t\tfor (idx_t i = 0; i < MinValue<idx_t>(names.size(), sniffer_state_machine.options.name_list.size()); i++) {\n+\t\t\tnames[i] = sniffer_state_machine.options.name_list[i];\n+\t\t}\n+\t\treturn;\n+\t}\n \t// information for header detection\n \tbool first_row_consistent = true;\n \t// check if header row is all null and/or consistent with detected column data types\n \tbool first_row_nulls = true;\n-\tauto &sniffer_state_machine = best_candidate->GetStateMachine();\n \t// If null-padding is not allowed and there is a mismatch between our header candidate and the number of columns\n \t// We can't detect the dialect/type options properly\n \tif (!sniffer_state_machine.options.null_padding &&\ndiff --git a/src/execution/operator/csv_scanner/sniffer/type_detection.cpp b/src/execution/operator/csv_scanner/sniffer/type_detection.cpp\nindex 8e723088cd68..d78c702e7227 100644\n--- a/src/execution/operator/csv_scanner/sniffer/type_detection.cpp\n+++ b/src/execution/operator/csv_scanner/sniffer/type_detection.cpp\n@@ -204,7 +204,7 @@ void CSVSniffer::DetectTypes() {\n \t\t// Parse chunk and read csv with info candidate\n \t\tauto &tuples = candidate->ParseChunk();\n \t\tidx_t row_idx = 0;\n-\t\tif (tuples.NumberOfRows() > 1 &&\n+\t\tif (tuples.number_of_rows > 1 &&\n \t\t    (!options.dialect_options.header.IsSetByUser() ||\n \t\t     (options.dialect_options.header.IsSetByUser() && options.dialect_options.header.GetValue()))) {\n \t\t\t// This means we have more than one row, hence we can use the first row to detect if we have a header\n@@ -212,7 +212,7 @@ void CSVSniffer::DetectTypes() {\n \t\t}\n \t\t// First line where we start our type detection\n \t\tconst idx_t start_idx_detection = row_idx;\n-\t\tfor (; row_idx < tuples.NumberOfRows(); row_idx++) {\n+\t\tfor (; row_idx < tuples.number_of_rows; row_idx++) {\n \t\t\tfor (idx_t col_idx = 0; col_idx < tuples.number_of_columns; col_idx++) {\n \t\t\t\tauto &col_type_candidates = info_sql_types_candidates[col_idx];\n \t\t\t\t// col_type_candidates can't be empty since anything in a CSV file should at least be a string\n@@ -277,8 +277,10 @@ void CSVSniffer::DetectTypes() {\n \t\t\tfor (auto &format_candidate : format_candidates) {\n \t\t\t\tbest_format_candidates[format_candidate.first] = format_candidate.second.format;\n \t\t\t}\n-\t\t\tfor (idx_t col_idx = 0; col_idx < tuples.number_of_columns; col_idx++) {\n-\t\t\t\tbest_header_row.emplace_back(tuples.GetValue(0, col_idx));\n+\t\t\tif (tuples.number_of_rows > 0) {\n+\t\t\t\tfor (idx_t col_idx = 0; col_idx < tuples.number_of_columns; col_idx++) {\n+\t\t\t\t\tbest_header_row.emplace_back(tuples.GetValue(0, col_idx));\n+\t\t\t\t}\n \t\t\t}\n \t\t}\n \t}\n@@ -287,7 +289,7 @@ void CSVSniffer::DetectTypes() {\n \t\terror_handler->Error(error);\n \t}\n \t// Assert that it's all good at this point.\n-\tD_ASSERT(best_candidate && !best_format_candidates.empty() && !best_header_row.empty());\n+\tD_ASSERT(best_candidate && !best_format_candidates.empty());\n }\n \n } // namespace duckdb\ndiff --git a/src/execution/operator/csv_scanner/sniffer/type_refinement.cpp b/src/execution/operator/csv_scanner/sniffer/type_refinement.cpp\nindex f649ac6274d8..615fd5562a03 100644\n--- a/src/execution/operator/csv_scanner/sniffer/type_refinement.cpp\n+++ b/src/execution/operator/csv_scanner/sniffer/type_refinement.cpp\n@@ -58,31 +58,6 @@ void CSVSniffer::RefineTypes() {\n \t\t\tbool is_bool_type = col_type_candidates.back() == LogicalType::BOOLEAN;\n \t\t\twhile (col_type_candidates.size() > 1) {\n \t\t\t\tconst auto &sql_type = col_type_candidates.back();\n-\t\t\t\t//\tnarrow down the date formats\n-\t\t\t\tif (best_format_candidates.count(sql_type.id())) {\n-\t\t\t\t\tauto &best_type_format_candidates = best_format_candidates[sql_type.id()];\n-\t\t\t\t\tauto save_format_candidates = best_type_format_candidates;\n-\t\t\t\t\twhile (!best_type_format_candidates.empty()) {\n-\t\t\t\t\t\tif (TryCastVector(parse_chunk.data[col], parse_chunk.size(), sql_type)) {\n-\t\t\t\t\t\t\tbreak;\n-\t\t\t\t\t\t}\n-\t\t\t\t\t\t//\tdoesn't work - move to the next one\n-\t\t\t\t\t\tbest_type_format_candidates.pop_back();\n-\t\t\t\t\t\tif (!best_type_format_candidates.empty()) {\n-\t\t\t\t\t\t\tSetDateFormat(best_candidate->GetStateMachine(), best_type_format_candidates.back(),\n-\t\t\t\t\t\t\t              sql_type.id());\n-\t\t\t\t\t\t}\n-\t\t\t\t\t}\n-\t\t\t\t\t//\tif none match, then this is not a column of type sql_type,\n-\t\t\t\t\tif (best_type_format_candidates.empty()) {\n-\t\t\t\t\t\t//\tso restore the candidates that did work.\n-\t\t\t\t\t\tbest_type_format_candidates.swap(save_format_candidates);\n-\t\t\t\t\t\tif (!best_type_format_candidates.empty()) {\n-\t\t\t\t\t\t\tSetDateFormat(best_candidate->GetStateMachine(), best_type_format_candidates.back(),\n-\t\t\t\t\t\t\t              sql_type.id());\n-\t\t\t\t\t\t}\n-\t\t\t\t\t}\n-\t\t\t\t}\n \t\t\t\tif (TryCastVector(parse_chunk.data[col], parse_chunk.size(), sql_type)) {\n \t\t\t\t\tbreak;\n \t\t\t\t} else {\ndiff --git a/src/execution/operator/csv_scanner/state_machine/csv_state_machine.cpp b/src/execution/operator/csv_scanner/state_machine/csv_state_machine.cpp\nindex 01b23098d9a4..c643b3348b03 100644\n--- a/src/execution/operator/csv_scanner/state_machine/csv_state_machine.cpp\n+++ b/src/execution/operator/csv_scanner/state_machine/csv_state_machine.cpp\n@@ -19,22 +19,4 @@ CSVStateMachine::CSVStateMachine(const StateMachine &transition_array_p, const C\n \tdialect_options.state_machine_options = state_machine_options;\n }\n \n-void CSVStateMachine::InitializeSelectionVector(vector<SelectionVector> &selection_vector, idx_t num_cols) {\n-\tif (selection_vector.empty()) {\n-\t\tselection_vector.resize(num_cols);\n-\t\t// precompute these selection vectors\n-\t\tfor (idx_t i = 0; i < selection_vector.size(); i++) {\n-\t\t\tselection_vector[i].Initialize();\n-\t\t\tfor (idx_t j = 0; j < STANDARD_VECTOR_SIZE; j++) {\n-\t\t\t\tselection_vector[i][j] = i + (num_cols * j);\n-\t\t\t}\n-\t\t}\n-\t}\n-}\n-\n-const vector<SelectionVector> &CSVStateMachine::GetSelectionVector() {\n-\tstd::call_once(call_once_flag, this->InitializeSelectionVector, selection_vector, dialect_options.num_cols);\n-\treturn selection_vector;\n-}\n-\n } // namespace duckdb\ndiff --git a/src/execution/operator/csv_scanner/table_function/csv_file_scanner.cpp b/src/execution/operator/csv_scanner/table_function/csv_file_scanner.cpp\nindex a53d31f97752..b6a6bbd98187 100644\n--- a/src/execution/operator/csv_scanner/table_function/csv_file_scanner.cpp\n+++ b/src/execution/operator/csv_scanner/table_function/csv_file_scanner.cpp\n@@ -19,6 +19,7 @@ CSVFileScan::CSVFileScan(ClientContext &context, shared_ptr<CSVBufferManager> bu\n \t\ttypes = union_reader.GetTypes();\n \t\tMultiFileReader::InitializeReader(*this, options.file_options, bind_data.reader_bind, bind_data.return_types,\n \t\t                                  bind_data.return_names, column_ids, nullptr, file_path, context);\n+\t\tInitializeFileNamesTypes(bind_data);\n \t\treturn;\n \t} else if (!bind_data.column_info.empty()) {\n \t\t// Serialized Union By name\n@@ -26,6 +27,7 @@ CSVFileScan::CSVFileScan(ClientContext &context, shared_ptr<CSVBufferManager> bu\n \t\ttypes = bind_data.column_info[0].types;\n \t\tMultiFileReader::InitializeReader(*this, options.file_options, bind_data.reader_bind, bind_data.return_types,\n \t\t                                  bind_data.return_names, column_ids, nullptr, file_path, context);\n+\t\tInitializeFileNamesTypes(bind_data);\n \t\treturn;\n \t}\n \tnames = bind_data.return_names;\n@@ -33,6 +35,8 @@ CSVFileScan::CSVFileScan(ClientContext &context, shared_ptr<CSVBufferManager> bu\n \tfile_schema = bind_data.return_types;\n \tMultiFileReader::InitializeReader(*this, options.file_options, bind_data.reader_bind, bind_data.return_types,\n \t                                  bind_data.return_names, column_ids, nullptr, file_path, context);\n+\n+\tInitializeFileNamesTypes(bind_data);\n }\n \n CSVFileScan::CSVFileScan(ClientContext &context, const string &file_path_p, const CSVReaderOptions &options_p,\n@@ -62,6 +66,8 @@ CSVFileScan::CSVFileScan(ClientContext &context, const string &file_path_p, cons\n \t\t\tMultiFileReader::InitializeReader(*this, options.file_options, bind_data.reader_bind,\n \t\t\t                                  bind_data.return_types, bind_data.return_names, column_ids, nullptr,\n \t\t\t                                  file_path, context);\n+\n+\t\t\tInitializeFileNamesTypes(bind_data);\n \t\t\treturn;\n \t\t}\n \t}\n@@ -84,6 +90,7 @@ CSVFileScan::CSVFileScan(ClientContext &context, const string &file_path_p, cons\n \n \t\tMultiFileReader::InitializeReader(*this, options.file_options, bind_data.reader_bind, bind_data.return_types,\n \t\t                                  bind_data.return_names, column_ids, nullptr, file_path, context);\n+\t\tInitializeFileNamesTypes(bind_data);\n \t\treturn;\n \t}\n \t// Sniff it (We only really care about dialect detection, if types or number of columns are different this will\n@@ -114,6 +121,7 @@ CSVFileScan::CSVFileScan(ClientContext &context, const string &file_path_p, cons\n \n \tMultiFileReader::InitializeReader(*this, options.file_options, bind_data.reader_bind, bind_data.return_types,\n \t                                  bind_data.return_names, column_ids, nullptr, file_path, context);\n+\tInitializeFileNamesTypes(bind_data);\n }\n \n CSVFileScan::CSVFileScan(ClientContext &context, const string &file_name, CSVReaderOptions &options_p)\n@@ -143,6 +151,57 @@ CSVFileScan::CSVFileScan(ClientContext &context, const string &file_name, CSVRea\n \t    make_shared<CSVStateMachine>(state_machine_cache.Get(options.dialect_options.state_machine_options), options);\n }\n \n+void CSVFileScan::InitializeFileNamesTypes(const ReadCSVData &bind_data) {\n+\tif (options.null_padding) {\n+\t\t// If we are null padding we do not yet support projection pushdown\n+\t\tfile_names = names;\n+\t\tfile_types = types;\n+\t\treturn;\n+\t}\n+\tif (reader_data.empty_columns && reader_data.column_ids.empty()) {\n+\t\t// This means that the columns from this file are irrelevant.\n+\t\t// just read the first column\n+\t\tfile_names.emplace_back(\"c_1\");\n+\t\tfile_types.emplace_back(LogicalType::VARCHAR);\n+\t\tprojected_columns.emplace_back(0);\n+\t\treturn;\n+\t}\n+\tstd::set<idx_t> column_ids;\n+\tfor (idx_t i = 0; i < reader_data.column_ids.size(); i++) {\n+\t\tidx_t result_idx = reader_data.column_ids[i];\n+\t\tfile_names.emplace_back(names[result_idx]);\n+\t\tfile_types.emplace_back(types[result_idx]);\n+\t\tprojected_columns.emplace_back(reader_data.column_ids[i]);\n+\t\tcolumn_ids.insert(reader_data.column_ids[i]);\n+\t}\n+\n+\tif (!column_ids.empty()) {\n+\t\t// We might have to add recovery rejects column ids\n+\t\tfor (idx_t i = 0; i < options.rejects_recovery_column_ids.size(); i++) {\n+\t\t\tidx_t col_id = options.rejects_recovery_column_ids[i];\n+\t\t\tif (column_ids.find(col_id) == column_ids.end()) {\n+\t\t\t\t// We have to insert this column in our projection\n+\t\t\t\tcolumn_ids.insert(col_id);\n+\t\t\t\tfile_names.emplace_back(options.rejects_recovery_columns[i]);\n+\t\t\t\tfile_types.emplace_back(LogicalType::VARCHAR);\n+\t\t\t\tprojected_columns.emplace_back(col_id);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tif (reader_data.column_ids.empty()) {\n+\t\tfile_names = names;\n+\t\tfile_types = types;\n+\t}\n+\n+\t// We need to be sure that our types are also following the cast_map\n+\tfor (idx_t i = 0; i < reader_data.column_ids.size(); i++) {\n+\t\tif (reader_data.cast_map.find(reader_data.column_ids[i]) != reader_data.cast_map.end()) {\n+\t\t\tfile_types[i] = reader_data.cast_map[reader_data.column_ids[i]];\n+\t\t}\n+\t}\n+}\n+\n const string &CSVFileScan::GetFileName() {\n \treturn file_path;\n }\ndiff --git a/src/execution/operator/csv_scanner/table_function/global_csv_state.cpp b/src/execution/operator/csv_scanner/table_function/global_csv_state.cpp\nindex e0dd7c6d22e3..ed08e629a38e 100644\n--- a/src/execution/operator/csv_scanner/table_function/global_csv_state.cpp\n+++ b/src/execution/operator/csv_scanner/table_function/global_csv_state.cpp\n@@ -70,8 +70,7 @@ unique_ptr<StringValueScanner> CSVGlobalState::Next() {\n \t\t}\n \t\tauto csv_scanner =\n \t\t    make_uniq<StringValueScanner>(scanner_idx++, current_file->buffer_manager, current_file->state_machine,\n-\t\t                                  current_file->error_handler, current_boundary);\n-\t\tcsv_scanner->csv_file_scan = current_file;\n+\t\t                                  current_file->error_handler, current_file, current_boundary);\n \t\treturn csv_scanner;\n \t}\n \tlock_guard<mutex> parallel_lock(main_mutex);\n@@ -83,8 +82,7 @@ unique_ptr<StringValueScanner> CSVGlobalState::Next() {\n \tauto &current_file = *file_scans.back();\n \tauto csv_scanner =\n \t    make_uniq<StringValueScanner>(scanner_idx++, current_file.buffer_manager, current_file.state_machine,\n-\t                                  current_file.error_handler, current_boundary);\n-\tcsv_scanner->csv_file_scan = file_scans.back();\n+\t                                  current_file.error_handler, file_scans.back(), current_boundary);\n \t// We then produce the next boundary\n \tif (!current_boundary.Next(*current_file.buffer_manager)) {\n \t\t// This means we are done scanning the current file\ndiff --git a/src/execution/operator/csv_scanner/util/csv_error.cpp b/src/execution/operator/csv_scanner/util/csv_error.cpp\nindex 35395cbc7519..e674066721c5 100644\n--- a/src/execution/operator/csv_scanner/util/csv_error.cpp\n+++ b/src/execution/operator/csv_scanner/util/csv_error.cpp\n@@ -17,16 +17,21 @@ void CSVErrorHandler::Error(CSVError &csv_error) {\n \tError(mock, csv_error, true);\n }\n void CSVErrorHandler::Error(LinesPerBoundary &error_info, CSVError &csv_error, bool force_error) {\n-\tlock_guard<mutex> parallel_lock(main_mutex);\n \tif (ignore_errors && !force_error) {\n+\t\tlock_guard<mutex> parallel_lock(main_mutex);\n \t\t// We store this error\n \t\terrors.push_back({error_info, csv_error});\n \t\treturn;\n \t}\n+\n \tstd::ostringstream error;\n \tif (PrintLineNumber(csv_error)) {\n \t\terror << \"CSV Error on Line: \" << GetLine(error_info) << std::endl;\n \t}\n+\t{\n+\t\tlock_guard<mutex> parallel_lock(main_mutex);\n+\t\tgot_borked = true;\n+\t}\n \terror << csv_error.error_message;\n \tswitch (csv_error.type) {\n \tcase CSVErrorType::CAST_ERROR:\n@@ -82,22 +87,13 @@ CSVError CSVError::ColumnTypesError(case_insensitive_map_t<idx_t> sql_types_per_\n \treturn CSVError(exception, CSVErrorType::COLUMN_NAME_TYPE_MISMATCH);\n }\n \n-CSVError CSVError::CastError(const CSVReaderOptions &options, DataChunk &parse_chunk, idx_t chunk_row,\n-                             string &column_name, string &cast_error, idx_t &column_idx, vector<Value> &row) {\n+CSVError CSVError::CastError(const CSVReaderOptions &options, string &column_name, string &cast_error, idx_t column_idx,\n+                             vector<Value> &row) {\n \tstd::ostringstream error;\n \t// Which column\n \terror << \"Error when converting column \\\"\" << column_name << \"\\\".\" << std::endl;\n \t// What was the cast error\n \terror << cast_error << std::endl;\n-\t// What is the problematic CSV Line\n-\terror << \"Problematic CSV Line:\" << std::endl;\n-\tfor (idx_t col = 0; col < parse_chunk.ColumnCount(); col++) {\n-\t\t// error << parse_chunk.GetValue(column_idx, chunk_row).ToString();\n-\t\tif (col < parse_chunk.ColumnCount() - 1) {\n-\t\t\t// we are not in the last line, add the delimiter\n-\t\t\terror << options.dialect_options.state_machine_options.delimiter.GetValue();\n-\t\t}\n-\t}\n \terror << std::endl;\n \t// What were the options\n \terror << options.ToString();\n@@ -133,16 +129,7 @@ CSVError CSVError::NullPaddingFail(const CSVReaderOptions &options) {\n CSVError CSVError::UnterminatedQuotesError(const CSVReaderOptions &options, string_t *vector_ptr,\n                                            idx_t vector_line_start, idx_t current_column) {\n \tstd::ostringstream error;\n-\t// What is the problematic CSV Line\n \terror << \"Value with unterminated quote found.\" << std::endl;\n-\terror << \"Problematic CSV Line (Up to unquoted value):\" << std::endl;\n-\tfor (; vector_line_start < current_column; vector_line_start++) {\n-\t\terror << vector_ptr[vector_line_start].GetString();\n-\t\tif (vector_line_start < current_column - 1) {\n-\t\t\t// we are not in the last line, add the delimiter\n-\t\t\terror << options.dialect_options.state_machine_options.delimiter.GetValue();\n-\t\t}\n-\t}\n \terror << std::endl;\n \t// What were the options\n \terror << options.ToString();\n@@ -155,17 +142,6 @@ CSVError CSVError::IncorrectColumnAmountError(const CSVReaderOptions &options, s\n \t// How many columns were expected and how many were found\n \terror << \"Expected Number of Columns: \" << options.dialect_options.num_cols << \" Found: \" << actual_columns\n \t      << std::endl;\n-\t// What is the problematic CSV Line\n-\terror << \"Problematic CSV Line:\" << std::endl;\n-\terror << \"Consider using the \\'null_padding\\' or \\'ignore_errors\\' options.\" << std::endl;\n-\tfor (; vector_line_start < actual_columns; vector_line_start++) {\n-\t\t//\t\terror << vector_ptr[vector_line_start].GetString();\n-\t\tif (vector_line_start < actual_columns - 1) {\n-\t\t\t// we are not in the last line, add the delimiter\n-\t\t\terror << options.dialect_options.state_machine_options.delimiter.GetValue();\n-\t\t}\n-\t}\n-\terror << std::endl;\n \t// What were the options\n \terror << options.ToString();\n \treturn CSVError(error.str(), CSVErrorType::INCORRECT_COLUMN_AMOUNT);\n@@ -189,10 +165,17 @@ idx_t CSVErrorHandler::GetLine(LinesPerBoundary &error_info) {\n \tfor (idx_t boundary_idx = 0; boundary_idx < error_info.boundary_idx; boundary_idx++) {\n \t\tbool batch_done = false;\n \t\twhile (!batch_done) {\n+\t\t\tif (boundary_idx == 0) {\n+\t\t\t\t// if it's the first boundary, we just return\n+\t\t\t\tbreak;\n+\t\t\t}\n \t\t\tif (lines_per_batch_map.find(boundary_idx) != lines_per_batch_map.end()) {\n \t\t\t\tbatch_done = true;\n \t\t\t\tcurrent_line += lines_per_batch_map[boundary_idx].lines_in_batch;\n \t\t\t}\n+\t\t\tif (got_borked) {\n+\t\t\t\treturn current_line;\n+\t\t\t}\n \t\t}\n \t}\n \treturn current_line;\ndiff --git a/src/include/duckdb/common/operator/double_cast_operator.hpp b/src/include/duckdb/common/operator/double_cast_operator.hpp\nnew file mode 100644\nindex 000000000000..af87eaafa3b2\n--- /dev/null\n+++ b/src/include/duckdb/common/operator/double_cast_operator.hpp\n@@ -0,0 +1,52 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/common/operator/double_cast_operator.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#pragma once\n+\n+#include \"duckdb.h\"\n+#include \"fast_float/fast_float.h\"\n+\n+namespace duckdb {\n+template <class T>\n+static bool TryDoubleCast(const char *buf, idx_t len, T &result, bool strict, char decimal_separator = '.') {\n+\t// skip any spaces at the start\n+\twhile (len > 0 && StringUtil::CharacterIsSpace(*buf)) {\n+\t\tbuf++;\n+\t\tlen--;\n+\t}\n+\tif (len == 0) {\n+\t\treturn false;\n+\t}\n+\tif (*buf == '+') {\n+\t\tif (strict) {\n+\t\t\t// plus is not allowed in strict mode\n+\t\t\treturn false;\n+\t\t}\n+\t\tbuf++;\n+\t\tlen--;\n+\t}\n+\tif (strict && len >= 2) {\n+\t\tif (buf[0] == '0' && StringUtil::CharacterIsDigit(buf[1])) {\n+\t\t\t// leading zeros are not allowed in strict mode\n+\t\t\treturn false;\n+\t\t}\n+\t}\n+\tauto endptr = buf + len;\n+\tauto parse_result = duckdb_fast_float::from_chars(buf, buf + len, result, decimal_separator);\n+\tif (parse_result.ec != std::errc()) {\n+\t\treturn false;\n+\t}\n+\tauto current_end = parse_result.ptr;\n+\tif (!strict) {\n+\t\twhile (current_end < endptr && StringUtil::CharacterIsSpace(*current_end)) {\n+\t\t\tcurrent_end++;\n+\t\t}\n+\t}\n+\treturn current_end == endptr;\n+}\n+} // namespace duckdb\ndiff --git a/src/include/duckdb/common/operator/integer_cast_operator.hpp b/src/include/duckdb/common/operator/integer_cast_operator.hpp\nnew file mode 100644\nindex 000000000000..10953fe2099b\n--- /dev/null\n+++ b/src/include/duckdb/common/operator/integer_cast_operator.hpp\n@@ -0,0 +1,456 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/common/operator/integer_cast_operator.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#pragma once\n+\n+#include \"duckdb/common/operator/add.hpp\"\n+#include \"duckdb/common/operator/multiply.hpp\"\n+#include \"duckdb/common/operator/subtract.hpp\"\n+#include \"duckdb/common/operator/cast_operators.hpp\"\n+\n+namespace duckdb {\n+template <typename T>\n+struct IntegerCastData {\n+\tusing ResultType = T;\n+\tusing StoreType = T;\n+\tResultType result;\n+};\n+\n+struct IntegerCastOperation {\n+\ttemplate <class T, bool NEGATIVE>\n+\tstatic bool HandleDigit(T &state, uint8_t digit) {\n+\t\tusing store_t = typename T::StoreType;\n+\t\tif (NEGATIVE) {\n+\t\t\tif (DUCKDB_UNLIKELY(state.result < (NumericLimits<store_t>::Minimum() + digit) / 10)) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t\tstate.result = state.result * 10 - digit;\n+\t\t} else {\n+\t\t\tif (DUCKDB_UNLIKELY(state.result > (NumericLimits<store_t>::Maximum() - digit) / 10)) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t\tstate.result = state.result * 10 + digit;\n+\t\t}\n+\t\treturn true;\n+\t}\n+\n+\ttemplate <class T, bool NEGATIVE>\n+\tstatic bool HandleHexDigit(T &state, uint8_t digit) {\n+\t\tusing store_t = typename T::StoreType;\n+\t\tif (DUCKDB_UNLIKELY(state.result > (NumericLimits<store_t>::Maximum() - digit) / 16)) {\n+\t\t\treturn false;\n+\t\t}\n+\t\tstate.result = state.result * 16 + digit;\n+\t\treturn true;\n+\t}\n+\n+\ttemplate <class T, bool NEGATIVE>\n+\tstatic bool HandleBinaryDigit(T &state, uint8_t digit) {\n+\t\tusing store_t = typename T::StoreType;\n+\t\tif (DUCKDB_UNLIKELY(state.result > (NumericLimits<store_t>::Maximum() - digit) / 2)) {\n+\t\t\treturn false;\n+\t\t}\n+\t\tstate.result = state.result * 2 + digit;\n+\t\treturn true;\n+\t}\n+\n+\ttemplate <class T, bool NEGATIVE>\n+\tstatic bool HandleExponent(T &state, int16_t exponent) {\n+\t\t// Simple integers don't deal with Exponents\n+\t\treturn false;\n+\t}\n+\n+\ttemplate <class T, bool NEGATIVE, bool ALLOW_EXPONENT>\n+\tstatic bool HandleDecimal(T &state, uint8_t digit) {\n+\t\t// Simple integers don't deal with Decimals\n+\t\treturn false;\n+\t}\n+\n+\ttemplate <class T, bool NEGATIVE>\n+\tstatic bool Finalize(T &state) {\n+\t\treturn true;\n+\t}\n+};\n+\n+template <typename T>\n+struct IntegerDecimalCastData {\n+\tusing ResultType = T;\n+\tusing StoreType = int64_t;\n+\tStoreType result;\n+\tStoreType decimal;\n+\tuint16_t decimal_digits;\n+};\n+\n+template <>\n+struct IntegerDecimalCastData<uint64_t> {\n+\tusing ResultType = uint64_t;\n+\tusing StoreType = uint64_t;\n+\tStoreType result;\n+\tStoreType decimal;\n+\tuint16_t decimal_digits;\n+};\n+\n+struct IntegerDecimalCastOperation : IntegerCastOperation {\n+\ttemplate <class T, bool NEGATIVE>\n+\tstatic bool HandleExponent(T &state, int16_t exponent) {\n+\t\tusing store_t = typename T::StoreType;\n+\n+\t\tint16_t e = exponent;\n+\t\t// Negative Exponent\n+\t\tif (e < 0) {\n+\t\t\twhile (state.result != 0 && e++ < 0) {\n+\t\t\t\tstate.decimal = state.result % 10;\n+\t\t\t\tstate.result /= 10;\n+\t\t\t}\n+\t\t\tif (state.decimal < 0) {\n+\t\t\t\tstate.decimal = -state.decimal;\n+\t\t\t}\n+\t\t\tstate.decimal_digits = 1;\n+\t\t\treturn Finalize<T, NEGATIVE>(state);\n+\t\t}\n+\n+\t\t// Positive Exponent\n+\t\twhile (state.result != 0 && e-- > 0) {\n+\t\t\tif (!TryMultiplyOperator::Operation(state.result, (store_t)10, state.result)) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t}\n+\n+\t\tif (state.decimal == 0) {\n+\t\t\treturn Finalize<T, NEGATIVE>(state);\n+\t\t}\n+\n+\t\t// Handle decimals\n+\t\te = exponent - state.decimal_digits;\n+\t\tstore_t remainder = 0;\n+\t\tif (e < 0) {\n+\t\t\tif (static_cast<uint16_t>(-e) <= NumericLimits<store_t>::Digits()) {\n+\t\t\t\tstore_t power = 1;\n+\t\t\t\twhile (e++ < 0) {\n+\t\t\t\t\tpower *= 10;\n+\t\t\t\t}\n+\t\t\t\tremainder = state.decimal % power;\n+\t\t\t\tstate.decimal /= power;\n+\t\t\t} else {\n+\t\t\t\tstate.decimal = 0;\n+\t\t\t}\n+\t\t} else {\n+\t\t\twhile (e-- > 0) {\n+\t\t\t\tif (!TryMultiplyOperator::Operation(state.decimal, (store_t)10, state.decimal)) {\n+\t\t\t\t\treturn false;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\n+\t\tstate.decimal_digits -= exponent;\n+\n+\t\tif (NEGATIVE) {\n+\t\t\tif (!TrySubtractOperator::Operation(state.result, state.decimal, state.result)) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t} else if (!TryAddOperator::Operation(state.result, state.decimal, state.result)) {\n+\t\t\treturn false;\n+\t\t}\n+\t\tstate.decimal = remainder;\n+\t\treturn Finalize<T, NEGATIVE>(state);\n+\t}\n+\n+\ttemplate <class T, bool NEGATIVE, bool ALLOW_EXPONENT>\n+\tstatic bool HandleDecimal(T &state, uint8_t digit) {\n+\t\tusing store_t = typename T::StoreType;\n+\t\tif (DUCKDB_UNLIKELY(state.decimal > (NumericLimits<store_t>::Maximum() - digit) / 10)) {\n+\t\t\t// Simply ignore any more decimals\n+\t\t\treturn true;\n+\t\t}\n+\t\tstate.decimal_digits++;\n+\t\tstate.decimal = state.decimal * 10 + digit;\n+\t\treturn true;\n+\t}\n+\n+\ttemplate <class T, bool NEGATIVE>\n+\tstatic bool Finalize(T &state) {\n+\t\tusing result_t = typename T::ResultType;\n+\t\tusing store_t = typename T::StoreType;\n+\n+\t\tresult_t tmp;\n+\t\tif (!TryCast::Operation<store_t, result_t>(state.result, tmp)) {\n+\t\t\treturn false;\n+\t\t}\n+\n+\t\twhile (state.decimal > 10) {\n+\t\t\tstate.decimal /= 10;\n+\t\t\tstate.decimal_digits--;\n+\t\t}\n+\n+\t\tbool success = true;\n+\t\tif (state.decimal_digits == 1 && state.decimal >= 5) {\n+\t\t\tif (NEGATIVE) {\n+\t\t\t\tsuccess = TrySubtractOperator::Operation(tmp, (result_t)1, tmp);\n+\t\t\t} else {\n+\t\t\t\tsuccess = TryAddOperator::Operation(tmp, (result_t)1, tmp);\n+\t\t\t}\n+\t\t}\n+\t\tstate.result = tmp;\n+\t\treturn success;\n+\t}\n+};\n+\n+template <class T, bool NEGATIVE, bool ALLOW_EXPONENT, class OP = IntegerCastOperation, char decimal_separator = '.'>\n+static bool IntegerCastLoop(const char *buf, idx_t len, T &result, bool strict) {\n+\tidx_t start_pos;\n+\tif (NEGATIVE) {\n+\t\tstart_pos = 1;\n+\t} else {\n+\t\tif (*buf == '+') {\n+\t\t\tif (strict) {\n+\t\t\t\t// leading plus is not allowed in strict mode\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t\tstart_pos = 1;\n+\t\t} else {\n+\t\t\tstart_pos = 0;\n+\t\t}\n+\t}\n+\tidx_t pos = start_pos;\n+\twhile (pos < len) {\n+\t\tif (!StringUtil::CharacterIsDigit(buf[pos])) {\n+\t\t\t// not a digit!\n+\t\t\tif (buf[pos] == decimal_separator) {\n+\t\t\t\tif (strict) {\n+\t\t\t\t\treturn false;\n+\t\t\t\t}\n+\t\t\t\tbool number_before_period = pos > start_pos;\n+\t\t\t\t// decimal point: we accept decimal values for integers as well\n+\t\t\t\t// we just truncate them\n+\t\t\t\t// make sure everything after the period is a number\n+\t\t\t\tpos++;\n+\t\t\t\tidx_t start_digit = pos;\n+\t\t\t\twhile (pos < len) {\n+\t\t\t\t\tif (!StringUtil::CharacterIsDigit(buf[pos])) {\n+\t\t\t\t\t\tbreak;\n+\t\t\t\t\t}\n+\t\t\t\t\tif (!OP::template HandleDecimal<T, NEGATIVE, ALLOW_EXPONENT>(result, buf[pos] - '0')) {\n+\t\t\t\t\t\treturn false;\n+\t\t\t\t\t}\n+\t\t\t\t\tpos++;\n+\n+\t\t\t\t\tif (pos != len && buf[pos] == '_') {\n+\t\t\t\t\t\t// Skip one underscore if it is not the last character and followed by a digit\n+\t\t\t\t\t\tpos++;\n+\t\t\t\t\t\tif (pos == len || !StringUtil::CharacterIsDigit(buf[pos])) {\n+\t\t\t\t\t\t\treturn false;\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t\t// make sure there is either (1) one number after the period, or (2) one number before the period\n+\t\t\t\t// i.e. we accept \"1.\" and \".1\" as valid numbers, but not \".\"\n+\t\t\t\tif (!(number_before_period || pos > start_digit)) {\n+\t\t\t\t\treturn false;\n+\t\t\t\t}\n+\t\t\t\tif (pos >= len) {\n+\t\t\t\t\tbreak;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\tif (StringUtil::CharacterIsSpace(buf[pos])) {\n+\t\t\t\t// skip any trailing spaces\n+\t\t\t\twhile (++pos < len) {\n+\t\t\t\t\tif (!StringUtil::CharacterIsSpace(buf[pos])) {\n+\t\t\t\t\t\treturn false;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t\tbreak;\n+\t\t\t}\n+\t\t\tif (ALLOW_EXPONENT) {\n+\t\t\t\tif (buf[pos] == 'e' || buf[pos] == 'E') {\n+\t\t\t\t\tif (pos == start_pos) {\n+\t\t\t\t\t\treturn false;\n+\t\t\t\t\t}\n+\t\t\t\t\tpos++;\n+\t\t\t\t\tif (pos >= len) {\n+\t\t\t\t\t\treturn false;\n+\t\t\t\t\t}\n+\t\t\t\t\tusing ExponentData = IntegerCastData<int16_t>;\n+\t\t\t\t\tExponentData exponent {};\n+\t\t\t\t\tint negative = buf[pos] == '-';\n+\t\t\t\t\tif (negative) {\n+\t\t\t\t\t\tif (!IntegerCastLoop<ExponentData, true, false, IntegerCastOperation, decimal_separator>(\n+\t\t\t\t\t\t        buf + pos, len - pos, exponent, strict)) {\n+\t\t\t\t\t\t\treturn false;\n+\t\t\t\t\t\t}\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tif (!IntegerCastLoop<ExponentData, false, false, IntegerCastOperation, decimal_separator>(\n+\t\t\t\t\t\t        buf + pos, len - pos, exponent, strict)) {\n+\t\t\t\t\t\t\treturn false;\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t\treturn OP::template HandleExponent<T, NEGATIVE>(result, exponent.result);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\treturn false;\n+\t\t}\n+\t\tuint8_t digit = buf[pos++] - '0';\n+\t\tif (!OP::template HandleDigit<T, NEGATIVE>(result, digit)) {\n+\t\t\treturn false;\n+\t\t}\n+\n+\t\tif (pos != len && buf[pos] == '_') {\n+\t\t\t// Skip one underscore if it is not the last character and followed by a digit\n+\t\t\tpos++;\n+\t\t\tif (pos == len || !StringUtil::CharacterIsDigit(buf[pos])) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t}\n+\t}\n+\tif (!OP::template Finalize<T, NEGATIVE>(result)) {\n+\t\treturn false;\n+\t}\n+\treturn pos > start_pos;\n+}\n+\n+template <class T, bool NEGATIVE, bool ALLOW_EXPONENT, class OP = IntegerCastOperation>\n+static bool IntegerHexCastLoop(const char *buf, idx_t len, T &result, bool strict) {\n+\tif (ALLOW_EXPONENT || NEGATIVE) {\n+\t\treturn false;\n+\t}\n+\tidx_t start_pos = 1;\n+\tidx_t pos = start_pos;\n+\tchar current_char;\n+\twhile (pos < len) {\n+\t\tcurrent_char = StringUtil::CharacterToLower(buf[pos]);\n+\t\tif (!StringUtil::CharacterIsHex(current_char)) {\n+\t\t\treturn false;\n+\t\t}\n+\t\tuint8_t digit;\n+\t\tif (current_char >= 'a') {\n+\t\t\tdigit = current_char - 'a' + 10;\n+\t\t} else {\n+\t\t\tdigit = current_char - '0';\n+\t\t}\n+\t\tpos++;\n+\n+\t\tif (pos != len && buf[pos] == '_') {\n+\t\t\t// Skip one underscore if it is not the last character and followed by a hex\n+\t\t\tpos++;\n+\t\t\tif (pos == len || !StringUtil::CharacterIsHex(buf[pos])) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t}\n+\n+\t\tif (!OP::template HandleHexDigit<T, NEGATIVE>(result, digit)) {\n+\t\t\treturn false;\n+\t\t}\n+\t}\n+\tif (!OP::template Finalize<T, NEGATIVE>(result)) {\n+\t\treturn false;\n+\t}\n+\treturn pos > start_pos;\n+}\n+\n+template <class T, bool NEGATIVE, bool ALLOW_EXPONENT, class OP = IntegerCastOperation>\n+static bool IntegerBinaryCastLoop(const char *buf, idx_t len, T &result, bool strict) {\n+\tif (ALLOW_EXPONENT || NEGATIVE) {\n+\t\treturn false;\n+\t}\n+\tidx_t start_pos = 1;\n+\tidx_t pos = start_pos;\n+\tuint8_t digit;\n+\tchar current_char;\n+\twhile (pos < len) {\n+\t\tcurrent_char = buf[pos];\n+\t\tif (current_char == '0') {\n+\t\t\tdigit = 0;\n+\t\t} else if (current_char == '1') {\n+\t\t\tdigit = 1;\n+\t\t} else {\n+\t\t\treturn false;\n+\t\t}\n+\t\tpos++;\n+\t\tif (pos != len && buf[pos] == '_') {\n+\t\t\t// Skip one underscore if it is not the last character and followed by a digit\n+\t\t\tpos++;\n+\t\t\tif (pos == len || (buf[pos] != '0' && buf[pos] != '1')) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t}\n+\n+\t\tif (!OP::template HandleBinaryDigit<T, NEGATIVE>(result, digit)) {\n+\t\t\treturn false;\n+\t\t}\n+\t}\n+\tif (!OP::template Finalize<T, NEGATIVE>(result)) {\n+\t\treturn false;\n+\t}\n+\treturn pos > start_pos;\n+}\n+\n+template <class T, bool IS_SIGNED = true, bool ALLOW_EXPONENT = true, class OP = IntegerCastOperation,\n+          bool ZERO_INITIALIZE = true, char decimal_separator = '.'>\n+static bool TryIntegerCast(const char *buf, idx_t len, T &result, bool strict) {\n+\t// skip any spaces at the start\n+\twhile (len > 0 && StringUtil::CharacterIsSpace(*buf)) {\n+\t\tbuf++;\n+\t\tlen--;\n+\t}\n+\tif (len == 0) {\n+\t\treturn false;\n+\t}\n+\tif (ZERO_INITIALIZE) {\n+\t\tmemset(&result, 0, sizeof(T));\n+\t}\n+\t// if the number is negative, we set the negative flag and skip the negative sign\n+\tif (*buf == '-') {\n+\t\tif (!IS_SIGNED) {\n+\t\t\t// Need to check if its not -0\n+\t\t\tidx_t pos = 1;\n+\t\t\twhile (pos < len) {\n+\t\t\t\tif (buf[pos++] != '0') {\n+\t\t\t\t\treturn false;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn IntegerCastLoop<T, true, ALLOW_EXPONENT, OP, decimal_separator>(buf, len, result, strict);\n+\t}\n+\tif (len > 1 && *buf == '0') {\n+\t\tif (buf[1] == 'x' || buf[1] == 'X') {\n+\t\t\t// If it starts with 0x or 0X, we parse it as a hex value\n+\t\t\tbuf++;\n+\t\t\tlen--;\n+\t\t\treturn IntegerHexCastLoop<T, false, false, OP>(buf, len, result, strict);\n+\t\t} else if (buf[1] == 'b' || buf[1] == 'B') {\n+\t\t\t// If it starts with 0b or 0B, we parse it as a binary value\n+\t\t\tbuf++;\n+\t\t\tlen--;\n+\t\t\treturn IntegerBinaryCastLoop<T, false, false, OP>(buf, len, result, strict);\n+\t\t} else if (strict && StringUtil::CharacterIsDigit(buf[1])) {\n+\t\t\t// leading zeros are not allowed in strict mode\n+\t\t\treturn false;\n+\t\t}\n+\t}\n+\treturn IntegerCastLoop<T, false, ALLOW_EXPONENT, OP, decimal_separator>(buf, len, result, strict);\n+}\n+\n+template <typename T, bool IS_SIGNED = true>\n+static inline bool TrySimpleIntegerCast(const char *buf, idx_t len, T &result, bool strict) {\n+\tIntegerCastData<T> simple_data;\n+\tif (TryIntegerCast<IntegerCastData<T>, IS_SIGNED, false, IntegerCastOperation>(buf, len, simple_data, strict)) {\n+\t\tresult = (T)simple_data.result;\n+\t\treturn true;\n+\t}\n+\n+\t// Simple integer cast failed, try again with decimals/exponents included\n+\t// FIXME: This could definitely be improved as some extra work is being done here. It is more important that\n+\t//  \"normal\" integers (without exponent/decimals) are still being parsed quickly.\n+\tIntegerDecimalCastData<T> cast_data;\n+\tif (TryIntegerCast<IntegerDecimalCastData<T>, IS_SIGNED, true, IntegerDecimalCastOperation>(buf, len, cast_data,\n+\t                                                                                            strict)) {\n+\t\tresult = (T)cast_data.result;\n+\t\treturn true;\n+\t}\n+\treturn false;\n+}\n+} // namespace duckdb\ndiff --git a/src/include/duckdb/execution/operator/csv_scanner/scanner/base_scanner.hpp b/src/include/duckdb/execution/operator/csv_scanner/scanner/base_scanner.hpp\nindex 3f13d2ed3bbb..cfba096dd468 100644\n--- a/src/include/duckdb/execution/operator/csv_scanner/scanner/base_scanner.hpp\n+++ b/src/include/duckdb/execution/operator/csv_scanner/scanner/base_scanner.hpp\n@@ -20,10 +20,6 @@ class ScannerResult {\n public:\n \tScannerResult(CSVStates &states, CSVStateMachine &state_machine);\n \n-\tidx_t Size();\n-\tbool Empty();\n-\tidx_t result_position = 0;\n-\n \t//! Adds a Value to the result\n \tstatic inline void SetQuoted(ScannerResult &result) {\n \t\tresult.quoted = true;\n@@ -46,7 +42,8 @@ class ScannerResult {\n class BaseScanner {\n public:\n \texplicit BaseScanner(shared_ptr<CSVBufferManager> buffer_manager, shared_ptr<CSVStateMachine> state_machine,\n-\t                     shared_ptr<CSVErrorHandler> error_handler, CSVIterator iterator = {});\n+\t                     shared_ptr<CSVErrorHandler> error_handler, shared_ptr<CSVFileScan> csv_file_scan = nullptr,\n+\t                     CSVIterator iterator = {});\n \n \tvirtual ~BaseScanner() = default;\n \t//! Returns true if the scanner is finished\n@@ -106,7 +103,7 @@ class BaseScanner {\n \tbool initialized = false;\n \t//! How many lines were read by this scanner\n \tidx_t lines_read = 0;\n-\n+\tidx_t bytes_read = 0;\n \t//! Internal Functions used to perform the parsing\n \t//! Initializes the scanner\n \tvirtual void Initialize();\n@@ -115,6 +112,7 @@ class BaseScanner {\n \ttemplate <class T>\n \tvoid Process(T &result) {\n \t\tidx_t to_pos;\n+\t\tconst idx_t start_pos = iterator.pos.buffer_pos;\n \t\tif (iterator.IsBoundarySet()) {\n \t\t\tto_pos = iterator.GetEndPos();\n \t\t\tif (to_pos > cur_buffer_handle->actual_size) {\n@@ -129,18 +127,21 @@ class BaseScanner {\n \t\t\tcase CSVState::INVALID:\n \t\t\t\tT::InvalidState(result);\n \t\t\t\titerator.pos.buffer_pos++;\n+\t\t\t\tbytes_read = iterator.pos.buffer_pos - start_pos;\n \t\t\t\treturn;\n \t\t\tcase CSVState::RECORD_SEPARATOR:\n \t\t\t\tif (states.states[0] == CSVState::RECORD_SEPARATOR || states.states[0] == CSVState::NOT_SET) {\n \t\t\t\t\tlines_read++;\n \t\t\t\t\tif (T::EmptyLine(result, iterator.pos.buffer_pos)) {\n \t\t\t\t\t\titerator.pos.buffer_pos++;\n+\t\t\t\t\t\tbytes_read = iterator.pos.buffer_pos - start_pos;\n \t\t\t\t\t\treturn;\n \t\t\t\t\t}\n \t\t\t\t} else if (states.states[0] != CSVState::CARRIAGE_RETURN) {\n \t\t\t\t\tlines_read++;\n \t\t\t\t\tif (T::AddRow(result, iterator.pos.buffer_pos)) {\n \t\t\t\t\t\titerator.pos.buffer_pos++;\n+\t\t\t\t\t\tbytes_read = iterator.pos.buffer_pos - start_pos;\n \t\t\t\t\t\treturn;\n \t\t\t\t\t}\n \t\t\t\t}\n@@ -151,11 +152,13 @@ class BaseScanner {\n \t\t\t\tif (states.states[0] == CSVState::RECORD_SEPARATOR || states.states[0] == CSVState::NOT_SET) {\n \t\t\t\t\tif (T::EmptyLine(result, iterator.pos.buffer_pos)) {\n \t\t\t\t\t\titerator.pos.buffer_pos++;\n+\t\t\t\t\t\tbytes_read = iterator.pos.buffer_pos - start_pos;\n \t\t\t\t\t\treturn;\n \t\t\t\t\t}\n \t\t\t\t} else if (states.states[0] != CSVState::CARRIAGE_RETURN) {\n \t\t\t\t\tif (T::AddRow(result, iterator.pos.buffer_pos)) {\n \t\t\t\t\t\titerator.pos.buffer_pos++;\n+\t\t\t\t\t\tbytes_read = iterator.pos.buffer_pos - start_pos;\n \t\t\t\t\t\treturn;\n \t\t\t\t\t}\n \t\t\t\t}\n@@ -198,6 +201,7 @@ class BaseScanner {\n \t\t\t\tbreak;\n \t\t\t}\n \t\t}\n+\t\tbytes_read = iterator.pos.buffer_pos - start_pos;\n \t}\n \n \t//! Finalizes the process of the chunk\n@@ -210,7 +214,9 @@ class BaseScanner {\n \t\t\tInitialize();\n \t\t\tinitialized = true;\n \t\t}\n-\t\tProcess(result);\n+\t\tif (!iterator.done) {\n+\t\t\tProcess(result);\n+\t\t}\n \t\tFinalizeChunkProcess();\n \t}\n };\ndiff --git a/src/include/duckdb/execution/operator/csv_scanner/scanner/column_count_scanner.hpp b/src/include/duckdb/execution/operator/csv_scanner/scanner/column_count_scanner.hpp\nindex 8645677796ac..87cd04058c73 100644\n--- a/src/include/duckdb/execution/operator/csv_scanner/scanner/column_count_scanner.hpp\n+++ b/src/include/duckdb/execution/operator/csv_scanner/scanner/column_count_scanner.hpp\n@@ -27,6 +27,7 @@ class ColumnCountResult : public ScannerResult {\n \tidx_t current_column_count = 0;\n \tbool error = false;\n \tbool last_value_always_empty = true;\n+\tidx_t result_position = 0;\n \n \t//! Adds a Value to the result\n \tstatic inline void AddValue(ColumnCountResult &result, const idx_t buffer_pos);\ndiff --git a/src/include/duckdb/execution/operator/csv_scanner/scanner/string_value_scanner.hpp b/src/include/duckdb/execution/operator/csv_scanner/scanner/string_value_scanner.hpp\nindex 69cf9c210d0b..cc79916587db 100644\n--- a/src/include/duckdb/execution/operator/csv_scanner/scanner/string_value_scanner.hpp\n+++ b/src/include/duckdb/execution/operator/csv_scanner/scanner/string_value_scanner.hpp\n@@ -39,13 +39,12 @@ class StringValueResult : public ScannerResult {\n public:\n \tStringValueResult(CSVStates &states, CSVStateMachine &state_machine, CSVBufferHandle &buffer_handle,\n \t                  Allocator &buffer_allocator, idx_t result_size, idx_t buffer_position,\n-\t                  CSVErrorHandler &error_hander, CSVIterator &iterator, bool store_line_size);\n+\t                  CSVErrorHandler &error_hander, CSVIterator &iterator, bool store_line_size,\n+\t                  shared_ptr<CSVFileScan> csv_file_scan, idx_t &lines_read);\n \n \t//! Information on the vector\n-\tunique_ptr<Vector> vector;\n-\tstring_t *vector_ptr;\n-\tValidityMask *validity_mask;\n-\tidx_t vector_size;\n+\tunsafe_vector<void *> vector_ptr;\n+\tunsafe_vector<ValidityMask *> validity_mask;\n \n \t//! Variables to iterate over the CSV buffers\n \tidx_t last_position;\n@@ -56,13 +55,14 @@ class StringValueResult : public ScannerResult {\n \tconst uint32_t number_of_columns;\n \tconst bool null_padding;\n \tconst bool ignore_errors;\n-\tconst string_t null_str;\n+\tconst char *null_str_ptr;\n+\tconst idx_t null_str_size;\n \n \t//! Internal Data Chunk used for flushing\n \tDataChunk parse_chunk;\n-\n+\tidx_t number_of_rows = 0;\n+\tidx_t cur_col_id = 0;\n \tidx_t result_size;\n-\n \t//! Information to properly handle errors\n \tCSVErrorHandler &error_handler;\n \tCSVIterator &iterator;\n@@ -72,8 +72,16 @@ class StringValueResult : public ScannerResult {\n \tbool store_line_size = false;\n \tbool added_last_line = false;\n \tbool quoted_new_line = false;\n-\t//! Last result position where a new row started\n-\tidx_t last_row_pos = 0;\n+\n+\tunsafe_unique_array<LogicalTypeId> parse_types;\n+\tvector<string> names;\n+\tunordered_map<idx_t, string> cast_errors;\n+\n+\tshared_ptr<CSVFileScan> csv_file_scan;\n+\tidx_t &lines_read;\n+\n+\tunordered_map<idx_t, idx_t> projected_columns;\n+\n \t//! Specialized code for quoted values, makes sure to remove quotes and escapes\n \tstatic inline void AddQuotedValue(StringValueResult &result, const idx_t buffer_pos);\n \t//! Adds a Value to the result\n@@ -90,15 +98,12 @@ class StringValueResult : public ScannerResult {\n \tinline bool AddRowInternal();\n \n \tvoid HandleOverLimitRows();\n-\tvoid AddValueToVector(string_t &value, bool allocate = false);\n+\n+\tinline void AddValueToVector(const char *value_ptr, const idx_t size, bool allocate = false);\n \n \tValue GetValue(idx_t row_idx, idx_t col_idx);\n \n \tDataChunk &ToChunk();\n-\n-\tidx_t NumberOfRows();\n-\n-\tvoid Print();\n };\n \n //! Our dialect scanner basically goes over the CSV and actually parses the values to a DuckDB vector of string_t\n@@ -106,8 +111,12 @@ class StringValueScanner : public BaseScanner {\n public:\n \tStringValueScanner(idx_t scanner_idx, const shared_ptr<CSVBufferManager> &buffer_manager,\n \t                   const shared_ptr<CSVStateMachine> &state_machine,\n-\t                   const shared_ptr<CSVErrorHandler> &error_handler, CSVIterator boundary = {},\n-\t                   idx_t result_size = STANDARD_VECTOR_SIZE);\n+\t                   const shared_ptr<CSVErrorHandler> &error_handler, const shared_ptr<CSVFileScan> &csv_file_scan,\n+\t                   CSVIterator boundary = {}, idx_t result_size = STANDARD_VECTOR_SIZE);\n+\n+\tStringValueScanner(const shared_ptr<CSVBufferManager> &buffer_manager,\n+\t                   const shared_ptr<CSVStateMachine> &state_machine,\n+\t                   const shared_ptr<CSVErrorHandler> &error_handler);\n \n \t~StringValueScanner() {\n \t}\n@@ -125,6 +134,10 @@ class StringValueScanner : public BaseScanner {\n \t//! Creates a new string with all escaped values removed\n \tstatic string_t RemoveEscape(const char *str_ptr, idx_t end, char escape, Vector &vector);\n \n+\t//! If we can directly cast the type when consuming the CSV file, or we have to do it later\n+\tstatic bool CanDirectlyCast(const LogicalType &type,\n+\t                            const map<LogicalTypeId, CSVOption<StrpTimeFormat>> &format_options);\n+\n \tconst idx_t scanner_idx;\n \n private:\n@@ -150,6 +163,7 @@ class StringValueScanner : public BaseScanner {\n \tvoid SetStart();\n \n \tStringValueResult result;\n+\tvector<LogicalType> types;\n \n \t//! Pointer to the previous buffer handle, necessary for overbuffer values\n \tunique_ptr<CSVBufferHandle> previous_buffer_handle;\ndiff --git a/src/include/duckdb/execution/operator/csv_scanner/state_machine/csv_state_machine.hpp b/src/include/duckdb/execution/operator/csv_scanner/state_machine/csv_state_machine.hpp\nindex 2a5337a16ee4..3c661b1e3788 100644\n--- a/src/include/duckdb/execution/operator/csv_scanner/state_machine/csv_state_machine.hpp\n+++ b/src/include/duckdb/execution/operator/csv_scanner/state_machine/csv_state_machine.hpp\n@@ -87,7 +87,6 @@ class CSVStateMachine {\n \t\tstates.states[1] = transition_array[static_cast<uint8_t>(current_char)][static_cast<uint8_t>(states.states[1])];\n \t}\n \n-\tconst vector<SelectionVector> &GetSelectionVector();\n \t//! The Transition Array is a Finite State Machine\n \t//! It holds the transitions of all states, on all 256 possible different characters\n \tconst StateMachine &transition_array;\n@@ -97,10 +96,6 @@ class CSVStateMachine {\n \tconst CSVReaderOptions &options;\n \t//! Dialect options resulting from sniffing\n \tDialectOptions dialect_options;\n-\n-private:\n-\tstatic void InitializeSelectionVector(vector<SelectionVector> &selection_vector, idx_t num_cols);\n-\tvector<SelectionVector> selection_vector;\n };\n \n } // namespace duckdb\ndiff --git a/src/include/duckdb/execution/operator/csv_scanner/table_function/csv_file_scanner.hpp b/src/include/duckdb/execution/operator/csv_scanner/table_function/csv_file_scanner.hpp\nindex f0f74bcf26b9..fcd4cd17a07c 100644\n--- a/src/include/duckdb/execution/operator/csv_scanner/table_function/csv_file_scanner.hpp\n+++ b/src/include/duckdb/execution/operator/csv_scanner/table_function/csv_file_scanner.hpp\n@@ -35,6 +35,9 @@ class CSVFileScan {\n \tconst vector<string> &GetNames();\n \tconst vector<LogicalType> &GetTypes();\n \tvoid InitializeProjection();\n+\n+\t//! Initialize the actual names and types to be scanned from the file\n+\tvoid InitializeFileNamesTypes(const ReadCSVData &bind_data);\n \tconst string file_path;\n \t//! File Index\n \tidx_t file_idx;\n@@ -55,6 +58,10 @@ class CSVFileScan {\n \tvector<LogicalType> types;\n \tMultiFileReaderData reader_data;\n \n+\tvector<string> file_names;\n+\tvector<LogicalType> file_types;\n+\tvector<idx_t> projected_columns;\n+\n \t//! Options for this CSV Reader\n \tCSVReaderOptions options;\n };\ndiff --git a/src/include/duckdb/execution/operator/csv_scanner/table_function/global_csv_state.hpp b/src/include/duckdb/execution/operator/csv_scanner/table_function/global_csv_state.hpp\nindex 4ca760a0cffa..cabc87461187 100644\n--- a/src/include/duckdb/execution/operator/csv_scanner/table_function/global_csv_state.hpp\n+++ b/src/include/duckdb/execution/operator/csv_scanner/table_function/global_csv_state.hpp\n@@ -45,7 +45,7 @@ struct CSVGlobalState : public GlobalTableFunctionState {\n \tCSVIterator current_boundary;\n \n private:\n-\t//! Reference to the cient context that created this scan\n+\t//! Reference to the client context that created this scan\n \tClientContext &context;\n \n \tvector<shared_ptr<CSVFileScan>> file_scans;\ndiff --git a/src/include/duckdb/execution/operator/csv_scanner/util/csv_casting.hpp b/src/include/duckdb/execution/operator/csv_scanner/util/csv_casting.hpp\nindex b34abe02f2ef..7a21264d09c8 100644\n--- a/src/include/duckdb/execution/operator/csv_scanner/util/csv_casting.hpp\n+++ b/src/include/duckdb/execution/operator/csv_scanner/util/csv_casting.hpp\n@@ -75,7 +75,6 @@ class CSVCast {\n \t\tUnaryExecutor::Execute<string_t, T>(input_vector, result_vector, count, [&](string_t input) {\n \t\t\tT result;\n \t\t\tif (!OP::Operation(options, input, result, error_message)) {\n-\t\t\t\tFlatVector::SetNull(result_vector, cur_line, true);\n \t\t\t\tline_error = cur_line;\n \t\t\t\tall_converted = false;\n \t\t\t}\ndiff --git a/src/include/duckdb/execution/operator/csv_scanner/util/csv_error.hpp b/src/include/duckdb/execution/operator/csv_scanner/util/csv_error.hpp\nindex 6060d79e2afe..f166f86abe50 100644\n--- a/src/include/duckdb/execution/operator/csv_scanner/util/csv_error.hpp\n+++ b/src/include/duckdb/execution/operator/csv_scanner/util/csv_error.hpp\n@@ -47,8 +47,8 @@ class CSVError {\n \t//! Produces error messages for column name -> type mismatch.\n \tstatic CSVError ColumnTypesError(case_insensitive_map_t<idx_t> sql_types_per_column, const vector<string> &names);\n \t//! Produces error messages for casting errors\n-\tstatic CSVError CastError(const CSVReaderOptions &options, DataChunk &parse_chunk, idx_t chunk_row,\n-\t                          string &column_name, string &cast_error, idx_t &column_idx, vector<Value> &row);\n+\tstatic CSVError CastError(const CSVReaderOptions &options, string &column_name, string &cast_error,\n+\t                          idx_t column_idx, vector<Value> &row);\n \t//! Produces error for when the line size exceeds the maximum line size option\n \tstatic CSVError LineSizeError(const CSVReaderOptions &options, idx_t actual_size);\n \t//! Produces error for when the sniffer couldn't find viable options\n@@ -97,6 +97,8 @@ class CSVErrorHandler {\n \tunordered_map<idx_t, LinesPerBoundary> lines_per_batch_map;\n \tidx_t max_line_length = 0;\n \tbool ignore_errors = false;\n+\n+\tbool got_borked = false;\n };\n \n } // namespace duckdb\n",
  "test_patch": "diff --git a/test/parallel_csv/test_parallel_csv.cpp b/test/parallel_csv/test_parallel_csv.cpp\nindex f45dfc3dc7e0..3a681a0ce76c 100644\n--- a/test/parallel_csv/test_parallel_csv.cpp\n+++ b/test/parallel_csv/test_parallel_csv.cpp\n@@ -98,6 +98,9 @@ bool RunFull(std::string &path, std::set<std::string> *skip = nullptr, const str\n \tif (!full_buffer_res->HasError()) {\n \t\tground_truth = &full_buffer_res->Collection();\n \t}\n+\tif (!ground_truth) {\n+\t\treturn true;\n+\t}\n \t// For parallel CSV Reading the buffer must be at least the size of the biggest line in the File.\n \tidx_t min_buffer_size = conn.context->client_data->debug_max_line_length + 3;\n \t// So our tests don't take infinite time, we will go till a max buffer size of 5 positions higher than the minimum.\ndiff --git a/test/sql/copy/csv/7702.test b/test/sql/copy/csv/7702.test\nindex 524c3a596f45..81be3147b557 100644\n--- a/test/sql/copy/csv/7702.test\n+++ b/test/sql/copy/csv/7702.test\n@@ -13,14 +13,4 @@ SELECT count(*) FROM read_csv_auto( ['test/sql/copy/csv/data/error/mismatch/half\n query I\n SELECT count(*) FROM read_csv_auto( ['test/sql/copy/csv/data/error/mismatch/half2.csv', 'test/sql/copy/csv/data/error/mismatch/half1.csv'], ignore_errors=true, sample_size=1);\n ----\n-9102\n-\n-query I\n-SELECT count(*) FROM read_csv_auto(['test/sql/copy/csv/data/error/mismatch/half1.csv', 'test/sql/copy/csv/data/error/mismatch/half2.csv'], ignore_errors=true, sample_size=1);\n-----\n-9102\n-\n-query I\n-SELECT count(*) FROM read_csv_auto( ['test/sql/copy/csv/data/error/mismatch/half2.csv', 'test/sql/copy/csv/data/error/mismatch/half1.csv'], ignore_errors=true, sample_size=1);\n-----\n-9102\n+9102\n\\ No newline at end of file\ndiff --git a/test/sql/copy/csv/code_cov/csv_type_refinement.test b/test/sql/copy/csv/code_cov/csv_type_refinement.test\nindex 4972aadaff17..978f2704ed89 100644\n--- a/test/sql/copy/csv/code_cov/csv_type_refinement.test\n+++ b/test/sql/copy/csv/code_cov/csv_type_refinement.test\n@@ -6,7 +6,7 @@ statement ok\n PRAGMA enable_verification\n \n query I\n-select count(*) from read_csv_auto('data/csv/borked_date.csv')\n+select count(*) from read_csv_auto('data/csv/borked_date.csv', header = 0)\n ----\n 2070\n \ndiff --git a/test/sql/copy/csv/parallel/csv_parallel_clickbench.test_slow b/test/sql/copy/csv/parallel/csv_parallel_clickbench.test_slow\nindex 7be19d033602..529a24ae5c5b 100644\n--- a/test/sql/copy/csv/parallel/csv_parallel_clickbench.test_slow\n+++ b/test/sql/copy/csv/parallel/csv_parallel_clickbench.test_slow\n@@ -2,6 +2,8 @@\n # description: Test parallel read CSV function on Clickbench\n # group: [parallel]\n \n+mode skip\n+\n require parquet\n \n require httpfs\n@@ -9,9 +11,6 @@ require httpfs\n statement ok\n pragma threads=4\n \n-#FIXME\n-mode skip\n-\n statement ok\n CREATE TABLE hits_og\n (\n@@ -125,7 +124,7 @@ CREATE TABLE hits_og\n \n \n statement ok\n-INSERT INTO hits_og SELECT * FROM read_parquet('./hits.parquet');\n+INSERT INTO hits_og SELECT * FROM read_parquet('https://github.com/duckdb/duckdb-data/releases/download/v1.0/hits.parquet');\n \n statement ok\n COPY hits_og TO '__TEST_DIR__/hits.csv';\n@@ -134,7 +133,7 @@ statement ok\n create table hits as select * from hits_og limit 0;\n \n statement ok\n-copy hits from '__TEST_DIR__/hits.csv' (HEADER 1);\n+copy hits from '__TEST_DIR__/hits.csv' (nullstr 'null');\n \n #Q 01\n query I\ndiff --git a/test/sql/copy/csv/test_force_not_null.test b/test/sql/copy/csv/test_force_not_null.test\nindex c890f46c8d26..9de2bdd023b2 100644\n--- a/test/sql/copy/csv/test_force_not_null.test\n+++ b/test/sql/copy/csv/test_force_not_null.test\n@@ -67,4 +67,4 @@ COPY test FROM 'test/sql/copy/csv/data/test/force_not_null.csv' (FORCE_NOT_NULL\n statement error\n COPY test FROM 'test/sql/copy/csv/data/test/force_not_null_inull.csv' (FORCE_NOT_NULL (col_a), HEADER 0);\n ----\n-\n+Error when converting column \"col_a\".\ndiff --git a/test/sql/copy/csv/test_union_by_name.test b/test/sql/copy/csv/test_union_by_name.test\nindex 2a659b6494ae..a59ccc21129c 100644\n--- a/test/sql/copy/csv/test_union_by_name.test\n+++ b/test/sql/copy/csv/test_union_by_name.test\n@@ -189,6 +189,7 @@ NULL\t300\tFriday\tdata/csv/union-by-name/ubn4.csv\n statement error\n SELECT * FROM read_csv_auto('data/csv/union-by-name/part=[ab]/*',HIVE_PARTITIONING=TRUE, null_padding=0)\n ----\n+Mismatch between the number of columns (2) in the CSV file and what is expected in the scanner (3).\n \n query IIII\n SELECT id, value, a, part\ndiff --git a/test/unittest.cpp b/test/unittest.cpp\nindex ae30c47287bb..a09d9f11dc15 100644\n--- a/test/unittest.cpp\n+++ b/test/unittest.cpp\n@@ -51,7 +51,6 @@ int main(int argc, char *argv[]) {\n \t\t\t\treturn 1;\n \t\t\t}\n \t\t\tSetTestDirectory(test_dir);\n-\t\t\tdelete_test_path = false;\n \t\t} else if (string(argv[i]) == \"--zero-initialize\") {\n \t\t\tSetDebugInitialize(0);\n \t\t} else if (string(argv[i]) == \"--one-initialize\") {\n",
  "problem_statement": "[CSV Parser] Bug FIxes - Progress Bar - Error Handling - Clickbench Test Back\nThis PR fixes issues with:\r\n1) The Progress Bar. We were not correctly taking `bytes_read` into account.\r\n2) Error Handling. A deadlock could happen when trying to handle errors from different threads. This PR loses the locks a bit and adds a sync variable to terminate hanging threads.\r\n3) Adds the `test/sql/copy/csv/parallel/csv_parallel_clickbench.test_slow back`. At some point, this test was removed from the CI. I guess was just forgotten. I've fixed it up and made sure it runs again.\n",
  "hints_text": "",
  "created_at": "2024-01-30T14:11:04Z"
}