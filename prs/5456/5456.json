{
  "repo": "duckdb/duckdb",
  "pull_number": 5456,
  "instance_id": "duckdb__duckdb-5456",
  "issue_numbers": [
    "5277"
  ],
  "base_commit": "28bf538ecb87a905d5d6902d2b0fd3d67962f29b",
  "patch": "diff --git a/benchmark/micro/aggregate/quantile/quantile_many.benchmark b/benchmark/micro/aggregate/quantile/quantile_many.benchmark\nnew file mode 100644\nindex 000000000000..a6be7d80817c\n--- /dev/null\n+++ b/benchmark/micro/aggregate/quantile/quantile_many.benchmark\n@@ -0,0 +1,13 @@\n+# name: benchmark/micro/aggregate/quantile/quantile_many.benchmark\n+# description: Quantile Function\n+# group: [quantile]\n+\n+name Quantile Many Groups\n+group quantile\n+\n+load\n+create table quantile as select range r, random() from range(10000000) union all values (NULL, 0.1), (NULL, 0.5), (NULL, 0.9) order by 2;\n+\n+run\n+SELECT quantile(r, 0.5) FROM quantile GROUP BY r % 100000\n+\ndiff --git a/src/common/types/chunk_collection.cpp b/src/common/types/chunk_collection.cpp\nindex 65d41623f63e..545b4a80f9c4 100644\n--- a/src/common/types/chunk_collection.cpp\n+++ b/src/common/types/chunk_collection.cpp\n@@ -163,267 +163,6 @@ void ChunkCollection::Fuse(ChunkCollection &other) {\n \ttypes.insert(types.end(), other.types.begin(), other.types.end());\n }\n \n-// returns an int similar to a C comparator:\n-// -1 if left < right\n-// 0 if left == right\n-// 1 if left > right\n-\n-template <class TYPE>\n-static int8_t TemplatedCompareValue(Vector &left_vec, Vector &right_vec, idx_t left_idx, idx_t right_idx) {\n-\tD_ASSERT(left_vec.GetType() == right_vec.GetType());\n-\tauto left_val = FlatVector::GetData<TYPE>(left_vec)[left_idx];\n-\tauto right_val = FlatVector::GetData<TYPE>(right_vec)[right_idx];\n-\tif (Equals::Operation<TYPE>(left_val, right_val)) {\n-\t\treturn 0;\n-\t}\n-\tif (LessThan::Operation<TYPE>(left_val, right_val)) {\n-\t\treturn -1;\n-\t}\n-\treturn 1;\n-}\n-\n-template <>\n-int8_t TemplatedCompareValue<Value>(Vector &left_vec, Vector &right_vec, idx_t left_idx, idx_t right_idx) {\n-\tauto left_val = left_vec.GetValue(left_idx);\n-\tauto right_val = right_vec.GetValue(right_idx);\n-\tif (ValueOperations::Equals(left_val, right_val)) {\n-\t\treturn 0;\n-\t}\n-\tif (ValueOperations::LessThan(left_val, right_val)) {\n-\t\treturn -1;\n-\t}\n-\treturn 1;\n-}\n-\n-// return type here is int32 because strcmp() on some platforms returns rather large values\n-static int32_t CompareValue(Vector &left_vec, Vector &right_vec, idx_t vector_idx_left, idx_t vector_idx_right,\n-                            OrderByNullType null_order) {\n-\tauto left_null = FlatVector::IsNull(left_vec, vector_idx_left);\n-\tauto right_null = FlatVector::IsNull(right_vec, vector_idx_right);\n-\n-\tif (left_null && right_null) {\n-\t\treturn 0;\n-\t} else if (right_null) {\n-\t\treturn null_order == OrderByNullType::NULLS_FIRST ? 1 : -1;\n-\t} else if (left_null) {\n-\t\treturn null_order == OrderByNullType::NULLS_FIRST ? -1 : 1;\n-\t}\n-\n-\tswitch (left_vec.GetType().InternalType()) {\n-\tcase PhysicalType::BOOL:\n-\tcase PhysicalType::INT8:\n-\t\treturn TemplatedCompareValue<int8_t>(left_vec, right_vec, vector_idx_left, vector_idx_right);\n-\tcase PhysicalType::INT16:\n-\t\treturn TemplatedCompareValue<int16_t>(left_vec, right_vec, vector_idx_left, vector_idx_right);\n-\tcase PhysicalType::INT32:\n-\t\treturn TemplatedCompareValue<int32_t>(left_vec, right_vec, vector_idx_left, vector_idx_right);\n-\tcase PhysicalType::INT64:\n-\t\treturn TemplatedCompareValue<int64_t>(left_vec, right_vec, vector_idx_left, vector_idx_right);\n-\tcase PhysicalType::UINT8:\n-\t\treturn TemplatedCompareValue<uint8_t>(left_vec, right_vec, vector_idx_left, vector_idx_right);\n-\tcase PhysicalType::UINT16:\n-\t\treturn TemplatedCompareValue<uint16_t>(left_vec, right_vec, vector_idx_left, vector_idx_right);\n-\tcase PhysicalType::UINT32:\n-\t\treturn TemplatedCompareValue<uint32_t>(left_vec, right_vec, vector_idx_left, vector_idx_right);\n-\tcase PhysicalType::UINT64:\n-\t\treturn TemplatedCompareValue<uint64_t>(left_vec, right_vec, vector_idx_left, vector_idx_right);\n-\tcase PhysicalType::INT128:\n-\t\treturn TemplatedCompareValue<hugeint_t>(left_vec, right_vec, vector_idx_left, vector_idx_right);\n-\tcase PhysicalType::FLOAT:\n-\t\treturn TemplatedCompareValue<float>(left_vec, right_vec, vector_idx_left, vector_idx_right);\n-\tcase PhysicalType::DOUBLE:\n-\t\treturn TemplatedCompareValue<double>(left_vec, right_vec, vector_idx_left, vector_idx_right);\n-\tcase PhysicalType::VARCHAR:\n-\t\treturn TemplatedCompareValue<string_t>(left_vec, right_vec, vector_idx_left, vector_idx_right);\n-\tcase PhysicalType::INTERVAL:\n-\t\treturn TemplatedCompareValue<interval_t>(left_vec, right_vec, vector_idx_left, vector_idx_right);\n-\tdefault:\n-\t\treturn TemplatedCompareValue<Value>(left_vec, right_vec, vector_idx_left, vector_idx_right);\n-\t}\n-}\n-\n-static int CompareTuple(ChunkCollection *sort_by, vector<OrderType> &desc, vector<OrderByNullType> &null_order,\n-                        idx_t left, idx_t right) {\n-\tD_ASSERT(sort_by);\n-\n-\tidx_t chunk_idx_left = left / STANDARD_VECTOR_SIZE;\n-\tidx_t chunk_idx_right = right / STANDARD_VECTOR_SIZE;\n-\tidx_t vector_idx_left = left % STANDARD_VECTOR_SIZE;\n-\tidx_t vector_idx_right = right % STANDARD_VECTOR_SIZE;\n-\n-\tauto &left_chunk = sort_by->GetChunk(chunk_idx_left);\n-\tauto &right_chunk = sort_by->GetChunk(chunk_idx_right);\n-\n-\tfor (idx_t col_idx = 0; col_idx < desc.size(); col_idx++) {\n-\t\tauto order_type = desc[col_idx];\n-\n-\t\tauto &left_vec = left_chunk.data[col_idx];\n-\t\tauto &right_vec = right_chunk.data[col_idx];\n-\n-\t\tD_ASSERT(left_vec.GetVectorType() == VectorType::FLAT_VECTOR);\n-\t\tD_ASSERT(right_vec.GetVectorType() == VectorType::FLAT_VECTOR);\n-\t\tD_ASSERT(left_vec.GetType() == right_vec.GetType());\n-\n-\t\tauto comp_res = CompareValue(left_vec, right_vec, vector_idx_left, vector_idx_right, null_order[col_idx]);\n-\n-\t\tif (comp_res == 0) {\n-\t\t\tcontinue;\n-\t\t}\n-\t\treturn comp_res < 0 ? (order_type == OrderType::ASCENDING ? -1 : 1)\n-\t\t                    : (order_type == OrderType::ASCENDING ? 1 : -1);\n-\t}\n-\treturn 0;\n-}\n-\n-static int64_t QuicksortInitial(ChunkCollection *sort_by, vector<OrderType> &desc, vector<OrderByNullType> &null_order,\n-                                idx_t *result) {\n-\t// select pivot\n-\tint64_t pivot = 0;\n-\tint64_t low = 0, high = sort_by->Count() - 1;\n-\t// now insert elements\n-\tfor (idx_t i = 1; i < sort_by->Count(); i++) {\n-\t\tif (CompareTuple(sort_by, desc, null_order, i, pivot) <= 0) {\n-\t\t\tresult[low++] = i;\n-\t\t} else {\n-\t\t\tresult[high--] = i;\n-\t\t}\n-\t}\n-\tD_ASSERT(low == high);\n-\tresult[low] = pivot;\n-\treturn low;\n-}\n-\n-struct QuicksortInfo {\n-\tQuicksortInfo(int64_t left_p, int64_t right_p) : left(left_p), right(right_p) {\n-\t}\n-\n-\tint64_t left;\n-\tint64_t right;\n-};\n-\n-struct QuicksortStack {\n-\tstd::queue<QuicksortInfo> info_queue;\n-\n-\tQuicksortInfo Pop() {\n-\t\tauto element = info_queue.front();\n-\t\tinfo_queue.pop();\n-\t\treturn element;\n-\t}\n-\n-\tbool IsEmpty() {\n-\t\treturn info_queue.empty();\n-\t}\n-\n-\tvoid Enqueue(int64_t left, int64_t right) {\n-\t\tif (left >= right) {\n-\t\t\treturn;\n-\t\t}\n-\t\tinfo_queue.emplace(left, right);\n-\t}\n-};\n-\n-static void QuicksortInPlace(ChunkCollection *sort_by, vector<OrderType> &desc, vector<OrderByNullType> &null_order,\n-                             idx_t *result, QuicksortInfo info, QuicksortStack &stack) {\n-\tauto left = info.left;\n-\tauto right = info.right;\n-\n-\tD_ASSERT(left < right);\n-\n-\tint64_t middle = left + (right - left) / 2;\n-\tint64_t pivot = result[middle];\n-\t// move the mid point value to the front.\n-\tint64_t i = left + 1;\n-\tint64_t j = right;\n-\n-\tstd::swap(result[middle], result[left]);\n-\tbool all_equal = true;\n-\twhile (i <= j) {\n-\t\tif (result) {\n-\t\t\twhile (i <= j) {\n-\t\t\t\tint cmp = CompareTuple(sort_by, desc, null_order, result[i], pivot);\n-\t\t\t\tif (cmp < 0) {\n-\t\t\t\t\tall_equal = false;\n-\t\t\t\t} else if (cmp > 0) {\n-\t\t\t\t\tall_equal = false;\n-\t\t\t\t\tbreak;\n-\t\t\t\t}\n-\t\t\t\ti++;\n-\t\t\t}\n-\t\t}\n-\n-\t\twhile (i <= j && CompareTuple(sort_by, desc, null_order, result[j], pivot) > 0) {\n-\t\t\tj--;\n-\t\t}\n-\n-\t\tif (i < j) {\n-\t\t\tstd::swap(result[i], result[j]);\n-\t\t}\n-\t}\n-\tstd::swap(result[i - 1], result[left]);\n-\tint64_t part = i - 1;\n-\n-\tif (all_equal) {\n-\t\treturn;\n-\t}\n-\n-\tstack.Enqueue(left, part - 1);\n-\tstack.Enqueue(part + 1, right);\n-}\n-\n-void ChunkCollection::Sort(vector<OrderType> &desc, vector<OrderByNullType> &null_order, idx_t result[]) {\n-\tif (count == 0) {\n-\t\treturn;\n-\t}\n-\tD_ASSERT(result);\n-\n-\t// start off with an initial quicksort\n-\tint64_t part = QuicksortInitial(this, desc, null_order, result);\n-\n-\t// now continuously perform\n-\tQuicksortStack stack;\n-\tstack.Enqueue(0, part);\n-\tstack.Enqueue(part + 1, count - 1);\n-\twhile (!stack.IsEmpty()) {\n-\t\tauto element = stack.Pop();\n-\t\tQuicksortInPlace(this, desc, null_order, result, element, stack);\n-\t}\n-}\n-\n-// FIXME make this more efficient by not using the Value API\n-// just use memcpy in the vectors\n-// assert that there is no selection list\n-void ChunkCollection::Reorder(idx_t order_org[]) {\n-\tauto order = unique_ptr<idx_t[]>(new idx_t[count]);\n-\tmemcpy(order.get(), order_org, sizeof(idx_t) * count);\n-\n-\t// adapted from https://stackoverflow.com/a/7366196/2652376\n-\n-\tauto val_buf = vector<Value>();\n-\tval_buf.resize(ColumnCount());\n-\n-\tidx_t j, k;\n-\tfor (idx_t i = 0; i < count; i++) {\n-\t\tfor (idx_t col_idx = 0; col_idx < ColumnCount(); col_idx++) {\n-\t\t\tval_buf[col_idx] = GetValue(col_idx, i);\n-\t\t}\n-\t\tj = i;\n-\t\twhile (true) {\n-\t\t\tk = order[j];\n-\t\t\torder[j] = j;\n-\t\t\tif (k == i) {\n-\t\t\t\tbreak;\n-\t\t\t}\n-\t\t\tfor (idx_t col_idx = 0; col_idx < ColumnCount(); col_idx++) {\n-\t\t\t\tSetValue(col_idx, j, GetValue(col_idx, k));\n-\t\t\t}\n-\t\t\tj = k;\n-\t\t}\n-\t\tfor (idx_t col_idx = 0; col_idx < ColumnCount(); col_idx++) {\n-\t\t\tSetValue(col_idx, j, val_buf[col_idx]);\n-\t\t}\n-\t}\n-}\n-\n Value ChunkCollection::GetValue(idx_t column, idx_t index) {\n \treturn chunks[LocateChunk(index)]->GetValue(column, index % STANDARD_VECTOR_SIZE);\n }\n@@ -448,58 +187,4 @@ void ChunkCollection::Print() const {\n \tPrinter::Print(ToString());\n }\n \n-bool ChunkCollection::Equals(ChunkCollection &other) {\n-\tif (count != other.count) {\n-\t\treturn false;\n-\t}\n-\tif (ColumnCount() != other.ColumnCount()) {\n-\t\treturn false;\n-\t}\n-\t// first try to compare the results as-is\n-\tbool compare_equals = true;\n-\tfor (idx_t row_idx = 0; row_idx < count; row_idx++) {\n-\t\tfor (idx_t col_idx = 0; col_idx < ColumnCount(); col_idx++) {\n-\t\t\tauto lvalue = GetValue(col_idx, row_idx);\n-\t\t\tauto rvalue = other.GetValue(col_idx, row_idx);\n-\t\t\tif (!Value::DefaultValuesAreEqual(lvalue, rvalue)) {\n-\t\t\t\tcompare_equals = false;\n-\t\t\t\tbreak;\n-\t\t\t}\n-\t\t}\n-\t\tif (!compare_equals) {\n-\t\t\tbreak;\n-\t\t}\n-\t}\n-\tif (compare_equals) {\n-\t\treturn true;\n-\t}\n-\tfor (auto &type : types) {\n-\t\t// sort not supported\n-\t\tif (type.InternalType() == PhysicalType::LIST || type.InternalType() == PhysicalType::STRUCT) {\n-\t\t\treturn false;\n-\t\t}\n-\t}\n-\t// if the results are not equal,\n-\t// sort both chunk collections to ensure the comparison is not order insensitive\n-\tvector<OrderType> desc(ColumnCount(), OrderType::DESCENDING);\n-\tvector<OrderByNullType> null_order(ColumnCount(), OrderByNullType::NULLS_FIRST);\n-\tauto this_order = unique_ptr<idx_t[]>(new idx_t[count]);\n-\tauto other_order = unique_ptr<idx_t[]>(new idx_t[count]);\n-\tSort(desc, null_order, this_order.get());\n-\tother.Sort(desc, null_order, other_order.get());\n-\n-\tfor (idx_t row_idx = 0; row_idx < count; row_idx++) {\n-\t\tauto lrow = this_order[row_idx];\n-\t\tauto rrow = other_order[row_idx];\n-\t\tfor (idx_t col_idx = 0; col_idx < ColumnCount(); col_idx++) {\n-\t\t\tauto lvalue = GetValue(col_idx, lrow);\n-\t\t\tauto rvalue = other.GetValue(col_idx, rrow);\n-\t\t\tif (!Value::DefaultValuesAreEqual(lvalue, rvalue)) {\n-\t\t\t\treturn false;\n-\t\t\t}\n-\t\t}\n-\t}\n-\treturn true;\n-}\n-\n } // namespace duckdb\ndiff --git a/src/function/aggregate/sorted_aggregate_function.cpp b/src/function/aggregate/sorted_aggregate_function.cpp\nindex 36ff0a674cb9..ad788ba60419 100644\n--- a/src/function/aggregate/sorted_aggregate_function.cpp\n+++ b/src/function/aggregate/sorted_aggregate_function.cpp\n@@ -1,48 +1,36 @@\n #include \"duckdb/function/aggregate_function.hpp\"\n-#include \"duckdb/common/types/chunk_collection.hpp\"\n+#include \"duckdb/common/sort/sort.hpp\"\n+#include \"duckdb/common/types/column_data_collection.hpp\"\n #include \"duckdb/function/function_binder.hpp\"\n+#include \"duckdb/storage/buffer_manager.hpp\"\n \n namespace duckdb {\n \n struct SortedAggregateBindData : public FunctionData {\n-\n-\t// TODO: Collection sorting does not handle OrderByNullType correctly\n-\t// so this is the third hack around it...\n-\tstatic OrderByNullType NormaliseNullOrder(OrderType sense, OrderByNullType null_order) {\n-\t\tif (sense != OrderType::DESCENDING) {\n-\t\t\treturn null_order;\n-\t\t}\n-\n-\t\tswitch (null_order) {\n-\t\tcase OrderByNullType::NULLS_FIRST:\n-\t\t\treturn OrderByNullType::NULLS_LAST;\n-\t\tcase OrderByNullType::NULLS_LAST:\n-\t\t\treturn OrderByNullType::NULLS_FIRST;\n-\t\tdefault:\n-\t\t\tthrow InternalException(\"Unknown NULL order sense\");\n-\t\t}\n-\t}\n-\n-\tSortedAggregateBindData(const AggregateFunction &function_p, vector<unique_ptr<Expression>> &children,\n-\t                        unique_ptr<FunctionData> bind_info_p, const BoundOrderModifier &order_bys)\n-\t    : function(function_p), bind_info(move(bind_info_p)) {\n+\tSortedAggregateBindData(ClientContext &context, const AggregateFunction &function_p,\n+\t                        vector<unique_ptr<Expression>> &children, unique_ptr<FunctionData> bind_info_p,\n+\t                        const BoundOrderModifier &order_bys)\n+\t    : buffer_manager(BufferManager::GetBufferManager(context)), function(function_p), bind_info(move(bind_info_p)) {\n \t\targ_types.reserve(children.size());\n \t\tfor (const auto &child : children) {\n \t\t\targ_types.emplace_back(child->return_type);\n \t\t}\n+\t\tsort_types.reserve(order_bys.orders.size());\n \t\tfor (auto &order : order_bys.orders) {\n-\t\t\torder_sense.emplace_back(order.type);\n-\t\t\tnull_order.emplace_back(NormaliseNullOrder(order.type, order.null_order));\n+\t\t\torders.emplace_back(order.Copy());\n \t\t\tsort_types.emplace_back(order.expression->return_type);\n \t\t}\n \t}\n \n \tSortedAggregateBindData(const SortedAggregateBindData &other)\n-\t    : function(other.function), arg_types(other.arg_types), order_sense(other.order_sense),\n-\t      null_order(other.null_order), sort_types(other.sort_types) {\n+\t    : buffer_manager(other.buffer_manager), function(other.function), arg_types(other.arg_types),\n+\t      sort_types(other.sort_types) {\n \t\tif (other.bind_info) {\n \t\t\tbind_info = other.bind_info->Copy();\n \t\t}\n+\t\tfor (auto &order : other.orders) {\n+\t\t\torders.emplace_back(order.Copy());\n+\t\t}\n \t}\n \n \tunique_ptr<FunctionData> Copy() const override {\n@@ -58,26 +46,130 @@ struct SortedAggregateBindData : public FunctionData {\n \t\t} else if (bind_info || other.bind_info) {\n \t\t\treturn false;\n \t\t}\n-\t\treturn function == other.function && order_sense == other.order_sense && null_order == other.null_order &&\n-\t\t       sort_types == other.sort_types;\n+\t\tif (function != other.function) {\n+\t\t\treturn false;\n+\t\t}\n+\t\tif (orders.size() != other.orders.size()) {\n+\t\t\treturn false;\n+\t\t}\n+\t\tfor (size_t i = 0; i < orders.size(); ++i) {\n+\t\t\tif (!orders[i].Equals(other.orders[i])) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t}\n+\t\treturn true;\n \t}\n \n+\tBufferManager &buffer_manager;\n \tAggregateFunction function;\n \tvector<LogicalType> arg_types;\n \tunique_ptr<FunctionData> bind_info;\n \n-\tvector<OrderType> order_sense;\n-\tvector<OrderByNullType> null_order;\n+\tvector<BoundOrderByNode> orders;\n \tvector<LogicalType> sort_types;\n };\n \n struct SortedAggregateState {\n-\tSortedAggregateState()\n-\t    : arguments(Allocator::DefaultAllocator()), ordering(Allocator::DefaultAllocator()), nsel(0) {\n+\tstatic const idx_t BUFFER_CAPACITY = STANDARD_VECTOR_SIZE;\n+\n+\tSortedAggregateState() : nsel(0) {\n \t}\n \n-\tChunkCollection arguments;\n-\tChunkCollection ordering;\n+\tstatic inline void InitializeBuffer(DataChunk &chunk, const vector<LogicalType> &types) {\n+\t\tif (!chunk.ColumnCount() && !types.empty()) {\n+\t\t\tchunk.Initialize(Allocator::DefaultAllocator(), types);\n+\t\t}\n+\t}\n+\n+\tvoid Flush(SortedAggregateBindData &order_bind) {\n+\t\tif (ordering) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tordering = make_unique<ColumnDataCollection>(order_bind.buffer_manager, order_bind.sort_types);\n+\t\tInitializeBuffer(sort_buffer, order_bind.sort_types);\n+\t\tordering->Append(sort_buffer);\n+\n+\t\targuments = make_unique<ColumnDataCollection>(order_bind.buffer_manager, order_bind.arg_types);\n+\t\tInitializeBuffer(arg_buffer, order_bind.arg_types);\n+\t\targuments->Append(arg_buffer);\n+\t}\n+\n+\tvoid Update(SortedAggregateBindData &order_bind, DataChunk &sort_chunk, DataChunk &arg_chunk) {\n+\t\t// Lazy instantiation of the buffer chunks\n+\t\tInitializeBuffer(sort_buffer, order_bind.sort_types);\n+\t\tInitializeBuffer(arg_buffer, order_bind.arg_types);\n+\n+\t\tif (sort_chunk.size() + sort_buffer.size() > BUFFER_CAPACITY) {\n+\t\t\tFlush(order_bind);\n+\t\t}\n+\t\tif (ordering) {\n+\t\t\tordering->Append(sort_chunk);\n+\t\t\targuments->Append(arg_chunk);\n+\t\t} else {\n+\t\t\tsort_buffer.Append(sort_chunk, true);\n+\t\t\targ_buffer.Append(arg_chunk, true);\n+\t\t}\n+\t}\n+\n+\tvoid UpdateSlice(SortedAggregateBindData &order_bind, DataChunk &sort_inputs, DataChunk &arg_inputs) {\n+\t\t// Lazy instantiation of the buffer chunks\n+\t\tInitializeBuffer(sort_buffer, order_bind.sort_types);\n+\t\tInitializeBuffer(arg_buffer, order_bind.arg_types);\n+\n+\t\tif (nsel + sort_buffer.size() > BUFFER_CAPACITY) {\n+\t\t\tFlush(order_bind);\n+\t\t}\n+\t\tif (ordering) {\n+\t\t\tsort_buffer.Reset();\n+\t\t\tsort_buffer.Slice(sort_inputs, sel, nsel);\n+\t\t\tordering->Append(sort_buffer);\n+\n+\t\t\targ_buffer.Reset();\n+\t\t\targ_buffer.Slice(arg_inputs, sel, nsel);\n+\t\t\targuments->Append(arg_buffer);\n+\t\t} else {\n+\t\t\tsort_buffer.Append(sort_inputs, true, &sel, nsel);\n+\t\t\targ_buffer.Append(arg_inputs, true, &sel, nsel);\n+\t\t}\n+\n+\t\tnsel = 0;\n+\t}\n+\n+\tvoid Combine(SortedAggregateBindData &order_bind, SortedAggregateState &other) {\n+\t\tif (other.ordering) {\n+\t\t\t// Force CDC if the other hash it\n+\t\t\tFlush(order_bind);\n+\t\t\tordering->Combine(*other.ordering);\n+\t\t\targuments->Combine(*other.arguments);\n+\t\t} else if (other.sort_buffer.size()) {\n+\t\t\tUpdate(order_bind, other.sort_buffer, other.arg_buffer);\n+\t\t}\n+\t}\n+\n+\tvoid Finalize(LocalSortState &local_sort) {\n+\t\tif (ordering) {\n+\t\t\tColumnDataScanState sort_state;\n+\t\t\tordering->InitializeScan(sort_state);\n+\t\t\tColumnDataScanState arg_state;\n+\t\t\targuments->InitializeScan(arg_state);\n+\t\t\tfor (sort_buffer.Reset(); ordering->Scan(sort_state, sort_buffer); sort_buffer.Reset()) {\n+\t\t\t\targ_buffer.Reset();\n+\t\t\t\targuments->Scan(arg_state, arg_buffer);\n+\t\t\t\tlocal_sort.SinkChunk(sort_buffer, arg_buffer);\n+\t\t\t}\n+\t\t\tordering->Reset();\n+\t\t\targuments->Reset();\n+\t\t} else {\n+\t\t\tlocal_sort.SinkChunk(sort_buffer, arg_buffer);\n+\t\t}\n+\t}\n+\n+\tunique_ptr<ColumnDataCollection> arguments;\n+\tunique_ptr<ColumnDataCollection> ordering;\n+\n+\tDataChunk sort_buffer;\n+\tDataChunk arg_buffer;\n \n \t// Selection for scattering\n \tSelectionVector sel;\n@@ -120,8 +212,7 @@ struct SortedAggregateFunction {\n \t\tProjectInputs(inputs, order_bind, input_count, count, arg_chunk, sort_chunk);\n \n \t\tconst auto order_state = (SortedAggregateState *)state;\n-\t\torder_state->arguments.Append(arg_chunk);\n-\t\torder_state->ordering.Append(sort_chunk);\n+\t\torder_state->Update(*order_bind, sort_chunk, arg_chunk);\n \t}\n \n \tstatic void ScatterUpdate(Vector inputs[], AggregateInputData &aggr_input_data, idx_t input_count, Vector &states,\n@@ -160,41 +251,29 @@ struct SortedAggregateFunction {\n \t\t\t\tcontinue;\n \t\t\t}\n \n-\t\t\tDataChunk arg_chunk;\n-\t\t\targ_chunk.InitializeEmpty(arg_inputs.GetTypes());\n-\t\t\targ_chunk.Slice(arg_inputs, order_state->sel, order_state->nsel);\n-\t\t\torder_state->arguments.Append(arg_chunk);\n-\n-\t\t\tDataChunk sort_chunk;\n-\t\t\tsort_chunk.InitializeEmpty(sort_inputs.GetTypes());\n-\t\t\tsort_chunk.Slice(sort_inputs, order_state->sel, order_state->nsel);\n-\t\t\torder_state->ordering.Append(sort_chunk);\n-\n-\t\t\t// Mark the slice as empty now we have consumed it.\n-\t\t\torder_state->nsel = 0;\n+\t\t\torder_state->UpdateSlice(*order_bind, sort_inputs, arg_inputs);\n \t\t}\n \t}\n \n \ttemplate <class STATE, class OP>\n-\tstatic void Combine(const STATE &source, STATE *target, AggregateInputData &) {\n-\t\tif (source.arguments.Count() == 0) {\n-\t\t\treturn;\n-\t\t}\n-\t\ttarget->arguments.Append(const_cast<ChunkCollection &>(source.arguments));\n-\t\ttarget->ordering.Append(const_cast<ChunkCollection &>(source.ordering));\n+\tstatic void Combine(const STATE &source, STATE *target, AggregateInputData &aggr_input_data) {\n+\t\tconst auto order_bind = (SortedAggregateBindData *)aggr_input_data.bind_data;\n+\t\tauto &other = const_cast<STATE &>(source);\n+\t\ttarget->Combine(*order_bind, other);\n \t}\n \n \tstatic void Finalize(Vector &states, AggregateInputData &aggr_input_data, Vector &result, idx_t count,\n \t                     idx_t offset) {\n \t\tconst auto order_bind = (SortedAggregateBindData *)aggr_input_data.bind_data;\n+\t\tauto &buffer_manager = order_bind->buffer_manager;\n+\t\tauto &orders = order_bind->orders;\n+\t\tRowLayout payload_layout;\n+\t\tpayload_layout.Initialize(order_bind->arg_types);\n \n \t\t//\t Reusable inner state\n \t\tvector<data_t> agg_state(order_bind->function.state_size());\n \t\tVector agg_state_vec(Value::POINTER((idx_t)agg_state.data()));\n \n-\t\t// Sorting buffer\n-\t\tvector<idx_t> reordering;\n-\n \t\t// State variables\n \t\tconst auto input_count = order_bind->function.arguments.size();\n \t\tauto bind_info = order_bind->bind_info.get();\n@@ -213,21 +292,37 @@ struct SortedAggregateFunction {\n \t\t\tauto state = sdata[i];\n \n \t\t\t// Apply the sort before delegating the chunks\n-\t\t\tconst auto agg_count = state->ordering.Count();\n-\t\t\tif (agg_count > 0) {\n-\t\t\t\treordering.resize(agg_count);\n-\t\t\t\tstate->ordering.Sort(order_bind->order_sense, order_bind->null_order, reordering.data());\n-\t\t\t\tstate->arguments.Reorder(reordering.data());\n-\t\t\t}\n+\t\t\tauto global_sort = make_unique<GlobalSortState>(buffer_manager, orders, payload_layout);\n+\t\t\tLocalSortState local_sort;\n+\t\t\tlocal_sort.Initialize(*global_sort, global_sort->buffer_manager);\n+\t\t\tstate->Finalize(local_sort);\n+\t\t\tglobal_sort->AddLocalState(local_sort);\n+\n+\t\t\tif (!global_sort->sorted_blocks.empty()) {\n+\t\t\t\tglobal_sort->PrepareMergePhase();\n+\t\t\t\twhile (global_sort->sorted_blocks.size() > 1) {\n+\t\t\t\t\tglobal_sort->InitializeMergeRound();\n+\t\t\t\t\tMergeSorter merge_sorter(*global_sort, global_sort->buffer_manager);\n+\t\t\t\t\tmerge_sorter.PerformInMergeRound();\n+\t\t\t\t\tglobal_sort->CompleteMergeRound(false);\n+\t\t\t\t}\n \n-\t\t\tfor (auto &chunk : state->arguments.Chunks()) {\n-\t\t\t\t// These are all simple updates, so use it if available\n-\t\t\t\tif (simple_update) {\n-\t\t\t\t\tsimple_update(chunk->data.data(), aggr_bind_info, input_count, agg_state.data(), chunk->size());\n-\t\t\t\t} else {\n-\t\t\t\t\t// We are only updating a constant state\n-\t\t\t\t\tagg_state_vec.SetVectorType(VectorType::CONSTANT_VECTOR);\n-\t\t\t\t\tupdate(chunk->data.data(), aggr_bind_info, input_count, agg_state_vec, chunk->size());\n+\t\t\t\tauto &chunk = state->arg_buffer;\n+\t\t\t\tPayloadScanner scanner(*global_sort);\n+\t\t\t\tfor (;;) {\n+\t\t\t\t\tchunk.Reset();\n+\t\t\t\t\tscanner.Scan(chunk);\n+\t\t\t\t\tif (chunk.size() == 0) {\n+\t\t\t\t\t\tbreak;\n+\t\t\t\t\t}\n+\t\t\t\t\t// These are all simple updates, so use it if available\n+\t\t\t\t\tif (simple_update) {\n+\t\t\t\t\t\tsimple_update(chunk.data.data(), aggr_bind_info, input_count, agg_state.data(), chunk.size());\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\t// We are only updating a constant state\n+\t\t\t\t\t\tagg_state_vec.SetVectorType(VectorType::CONSTANT_VECTOR);\n+\t\t\t\t\t\tupdate(chunk.data.data(), aggr_bind_info, input_count, agg_state_vec, chunk.size());\n+\t\t\t\t\t}\n \t\t\t\t}\n \t\t\t}\n \n@@ -255,7 +350,8 @@ unique_ptr<FunctionData> FunctionBinder::BindSortedAggregate(AggregateFunction &\n                                                              unique_ptr<FunctionData> bind_info,\n                                                              unique_ptr<BoundOrderModifier> order_bys) {\n \n-\tauto sorted_bind = make_unique<SortedAggregateBindData>(bound_function, children, move(bind_info), *order_bys);\n+\tauto sorted_bind =\n+\t    make_unique<SortedAggregateBindData>(context, bound_function, children, move(bind_info), *order_bys);\n \n \t// The arguments are the children plus the sort columns.\n \tfor (auto &order : order_bys->orders) {\ndiff --git a/src/include/duckdb/common/types/chunk_collection.hpp b/src/include/duckdb/common/types/chunk_collection.hpp\nindex ce73dc236106..321aa6a8364e 100644\n--- a/src/include/duckdb/common/types/chunk_collection.hpp\n+++ b/src/include/duckdb/common/types/chunk_collection.hpp\n@@ -26,8 +26,8 @@ class ClientContext;\n */\n class ChunkCollection {\n public:\n-\tChunkCollection(Allocator &allocator);\n-\tChunkCollection(ClientContext &context);\n+\texplicit ChunkCollection(Allocator &allocator);\n+\texplicit ChunkCollection(ClientContext &context);\n \n \t//! The types of columns in the ChunkCollection\n \tDUCKDB_API vector<LogicalType> &Types() {\n@@ -114,13 +114,6 @@ class ChunkCollection {\n \t\treturn res;\n \t}\n \n-\tDUCKDB_API void Sort(vector<OrderType> &desc, vector<OrderByNullType> &null_order, idx_t result[]);\n-\t//! Reorders the rows in the collection according to the given indices.\n-\tDUCKDB_API void Reorder(idx_t order[]);\n-\n-\t//! Returns true if the ChunkCollections are equivalent\n-\tDUCKDB_API bool Equals(ChunkCollection &other);\n-\n \t//! Locates the chunk that belongs to the specific index\n \tDUCKDB_API idx_t LocateChunk(idx_t index) {\n \t\tidx_t result = index / STANDARD_VECTOR_SIZE;\ndiff --git a/src/include/duckdb/planner/bound_result_modifier.hpp b/src/include/duckdb/planner/bound_result_modifier.hpp\nindex 088848c4a9ea..37903ee13a37 100644\n--- a/src/include/duckdb/planner/bound_result_modifier.hpp\n+++ b/src/include/duckdb/planner/bound_result_modifier.hpp\n@@ -38,6 +38,7 @@ struct BoundOrderByNode {\n \n public:\n \tBoundOrderByNode Copy() const;\n+\tbool Equals(const BoundOrderByNode &other) const;\n \tstring ToString() const;\n \n \tvoid Serialize(Serializer &serializer) const;\ndiff --git a/src/parser/transform/helpers/transform_orderby.cpp b/src/parser/transform/helpers/transform_orderby.cpp\nindex 37c64b8ca182..ecba4d340119 100644\n--- a/src/parser/transform/helpers/transform_orderby.cpp\n+++ b/src/parser/transform/helpers/transform_orderby.cpp\n@@ -1,6 +1,7 @@\n #include \"duckdb/parser/expression/constant_expression.hpp\"\n #include \"duckdb/parser/statement/select_statement.hpp\"\n #include \"duckdb/parser/transformer.hpp\"\n+#include \"duckdb/parser/expression/star_expression.hpp\"\n \n namespace duckdb {\n \n@@ -35,6 +36,13 @@ bool Transformer::TransformOrderBy(duckdb_libpgquery::PGList *order, vector<Orde\n \t\t\t\tthrow NotImplementedException(\"Unimplemented order by type\");\n \t\t\t}\n \t\t\tauto order_expression = TransformExpression(target);\n+\t\t\tif (order_expression->GetExpressionClass() == ExpressionClass::STAR) {\n+\t\t\t\tauto &star_expr = (StarExpression &)*order_expression;\n+\t\t\t\tD_ASSERT(star_expr.relation_name.empty());\n+\t\t\t\tif (star_expr.columns) {\n+\t\t\t\t\tthrow ParserException(\"COLUMNS expr is not supported in ORDER BY\");\n+\t\t\t\t}\n+\t\t\t}\n \t\t\tresult.emplace_back(type, null_order, move(order_expression));\n \t\t} else {\n \t\t\tthrow NotImplementedException(\"ORDER BY list member type %d\\n\", temp->type);\ndiff --git a/src/planner/bound_result_modifier.cpp b/src/planner/bound_result_modifier.cpp\nindex 5e65f7c51ef9..ddf31f15dda5 100644\n--- a/src/planner/bound_result_modifier.cpp\n+++ b/src/planner/bound_result_modifier.cpp\n@@ -25,6 +25,17 @@ BoundOrderByNode BoundOrderByNode::Copy() const {\n \t}\n }\n \n+bool BoundOrderByNode::Equals(const BoundOrderByNode &other) const {\n+\tif (type != other.type || null_order != other.null_order) {\n+\t\treturn false;\n+\t}\n+\tif (!expression->Equals(other.expression.get())) {\n+\t\treturn false;\n+\t}\n+\n+\treturn true;\n+}\n+\n string BoundOrderByNode::ToString() const {\n \tauto str = expression->ToString();\n \tswitch (type) {\n",
  "test_patch": "diff --git a/test/sql/parser/test_columns.test b/test/sql/parser/test_columns.test\nindex efe31699e33b..f6821172d9b3 100644\n--- a/test/sql/parser/test_columns.test\n+++ b/test/sql/parser/test_columns.test\n@@ -78,3 +78,10 @@ SELECT COLUMNS(*) + COLUMNS(* EXCLUDE(j)) FROM integers\n # COLUMNS in subquery without FROM clause\n statement error\n SELECT (SELECT COLUMNS(*)) FROM integers\n+\n+# COLUMNS in order by cluase\n+statement error\n+SELECT * FROM integers ORDER BY COLUMNS('index[0-9]');\n+\n+statement error\n+SELECT * FROM integers ORDER BY COLUMNS(*);\n",
  "problem_statement": "Remove ChunkCollection::Sort from ordered aggregation\nUgh this is still using `ChunkCollection::Sort`...  And the error is triggered because that code doesn't support comparing `STRUCT`s. It needs to be rewritten to use the new sorting code (which sorts anything).\r\n\r\n_Originally posted by @hawkfish in https://github.com/duckdb/duckdb/issues/5259#issuecomment-1309452742_\r\n      \n",
  "hints_text": "While I think we have to bite the bullet here and simplify, @Mytherin and I were debating the trade-offs here with small vs large partitions. I think in the short term just replacing the sort code in `Finalize` would be a good first step. We can work on scaling later, which might involve pushing the sort data structures into the state so that data can be spooled for very large groups.",
  "created_at": "2022-11-22T16:44:55Z"
}