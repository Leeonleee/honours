diff --git a/test/sql/copy/format_uuid.test b/test/sql/copy/format_uuid.test
index 1f773cdef835..ff09c264fc70 100644
--- a/test/sql/copy/format_uuid.test
+++ b/test/sql/copy/format_uuid.test
@@ -61,6 +61,7 @@ SELECT * FROM '__TEST_DIR__/part/a=9/leading_????????-????-4???-????-???????????
 query III sort
 SELECT * FROM '__TEST_DIR__/part/a=9/leading_????????-????-4???-????-????????????*.parquet';
 ----
+9	18	81
 9	27	729
 
 # Test without a specified format name for the outputfile.
@@ -77,6 +78,8 @@ SELECT * FROM '__TEST_DIR__/part/a=9/data_[0-9]*.parquet';
 query III sort
 SELECT * FROM '__TEST_DIR__/part/a=9/*.parquet';
 ----
+9	18	81
+9	27	729
 9	36	6561
 
 # Test where the FILENAME_PATTERN does not contain "{i}" or "{uuid}". 
@@ -93,6 +96,9 @@ SELECT * FROM '__TEST_DIR__/part/a=9/basename[0-9]*.parquet';
 query III sort
 SELECT * FROM '__TEST_DIR__/part/a=9/*.parquet';
 ----
+9	18	81
+9	27	729
+9	36	6561
 9	45	59049
 
 # Test without the overwrite_or_ignore param, that tries to add a file to an existing directory
diff --git a/test/sql/copy/partitioned/hive_partitioning_overwrite.test b/test/sql/copy/partitioned/hive_partitioning_overwrite.test
index 1b458a47a372..eb002273aa40 100644
--- a/test/sql/copy/partitioned/hive_partitioning_overwrite.test
+++ b/test/sql/copy/partitioned/hive_partitioning_overwrite.test
@@ -12,11 +12,11 @@ COPY (SELECT 42 AS part_col) TO '__TEST_DIR__/overwrite_test' (FORMAT PARQUET, P
 statement error
 COPY (SELECT 84 AS part_col) TO '__TEST_DIR__/overwrite_test' (FORMAT PARQUET, PARTITION_BY (part_col));
 ----
-Enable OVERWRITE_OR_IGNORE option to force writing
+Enable OVERWRITE option to overwrite files
 
 # test the overwrite setting
 statement ok
-COPY (SELECT 84 AS part_col) TO '__TEST_DIR__/overwrite_test' (FORMAT PARQUET, PARTITION_BY (part_col), OVERWRITE_OR_IGNORE 1);
+COPY (SELECT 84 AS part_col) TO '__TEST_DIR__/overwrite_test' (FORMAT PARQUET, PARTITION_BY (part_col), OVERWRITE 1);
 
 # the old file (with part_col=42) should now be removed
 query I
@@ -34,9 +34,14 @@ COPY (SELECT 84 AS part_col) TO '__TEST_DIR__/overwrite_test2' (FORMAT PARQUET,
 it exists and is a file
 
 statement ok
-COPY (SELECT 84 AS part_col) TO '__TEST_DIR__/overwrite_test2' (FORMAT PARQUET, PARTITION_BY (part_col), OVERWRITE_OR_IGNORE 1);
+COPY (SELECT 84 AS part_col) TO '__TEST_DIR__/overwrite_test2' (FORMAT PARQUET, PARTITION_BY (part_col), OVERWRITE 1);
 
 query I
 SELECT * FROM '__TEST_DIR__/overwrite_test2/**/*.parquet'
 ----
 84
+
+statement error
+COPY (SELECT 84 AS part_col) TO '__TEST_DIR__/overwrite_test' (FORMAT PARQUET, PARTITION_BY (part_col), OVERWRITE 1, OVERWRITE_OR_IGNORE 1);
+----
+Can only set one of OVERWRITE_OR_IGNORE or OVERWRITE
diff --git a/test/sql/copy/s3/s3_hive_partition.test b/test/sql/copy/s3/s3_hive_partition.test
index 47b3c028b169..efa534738ac2 100644
--- a/test/sql/copy/s3/s3_hive_partition.test
+++ b/test/sql/copy/s3/s3_hive_partition.test
@@ -98,3 +98,7 @@ EXPLAIN select a from read_csv_auto('s3://test-bucket/hive-partitioning/filter-t
 ----
 physical_plan	<REGEX>:.*FILTER.*(a < 4).*READ_CSV_AUTO.*File Filters: \(CAST\(c AS.*INTEGER\) = 500\).*
 
+statement error
+COPY (SELECT * FROM t1) TO 's3://test-bucket/hive-partitioning/filter-test-parquet' (FORMAT PARQUET, PARTITION_BY c, OVERWRITE);
+----
+OVERWRITE is not supported for remote file systems
diff --git a/tools/pythonpkg/tests/fast/api/test_to_csv.py b/tools/pythonpkg/tests/fast/api/test_to_csv.py
index b52dcde35db6..0b137327710d 100644
--- a/tools/pythonpkg/tests/fast/api/test_to_csv.py
+++ b/tools/pythonpkg/tests/fast/api/test_to_csv.py
@@ -218,7 +218,7 @@ def test_to_csv_overwrite_not_enabled(self, pandas):
         )
         rel = duckdb.from_df(df)
         rel.to_csv(temp_file_name, header=True, partition_by=["c_category_1"])
-        with pytest.raises(duckdb.IOException, match="Enable OVERWRITE_OR_IGNORE option to force writing"):
+        with pytest.raises(duckdb.IOException, match="OVERWRITE"):
             rel.to_csv(temp_file_name, header=True, partition_by=["c_category_1"])
 
     @pytest.mark.parametrize('pandas', [NumpyPandas(), ArrowPandas()])
