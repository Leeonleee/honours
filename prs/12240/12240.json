{
  "repo": "duckdb/duckdb",
  "pull_number": 12240,
  "instance_id": "duckdb__duckdb-12240",
  "issue_numbers": [
    "12225",
    "12225"
  ],
  "base_commit": "e658bf62dc3cae0c0637aa7c80ec5cad2b7538af",
  "patch": "diff --git a/src/common/enum_util.cpp b/src/common/enum_util.cpp\nindex 6ee1ec51afbf..33b644694996 100644\n--- a/src/common/enum_util.cpp\n+++ b/src/common/enum_util.cpp\n@@ -18,6 +18,7 @@\n #include \"duckdb/common/enums/catalog_lookup_behavior.hpp\"\n #include \"duckdb/common/enums/catalog_type.hpp\"\n #include \"duckdb/common/enums/compression_type.hpp\"\n+#include \"duckdb/common/enums/copy_overwrite_mode.hpp\"\n #include \"duckdb/common/enums/cte_materialize.hpp\"\n #include \"duckdb/common/enums/date_part_specifier.hpp\"\n #include \"duckdb/common/enums/debug_initialize.hpp\"\n@@ -1306,6 +1307,34 @@ ConstraintType EnumUtil::FromString<ConstraintType>(const char *value) {\n \tthrow NotImplementedException(StringUtil::Format(\"Enum value: '%s' not implemented\", value));\n }\n \n+template<>\n+const char* EnumUtil::ToChars<CopyOverwriteMode>(CopyOverwriteMode value) {\n+\tswitch(value) {\n+\tcase CopyOverwriteMode::COPY_ERROR_ON_CONFLICT:\n+\t\treturn \"COPY_ERROR_ON_CONFLICT\";\n+\tcase CopyOverwriteMode::COPY_OVERWRITE:\n+\t\treturn \"COPY_OVERWRITE\";\n+\tcase CopyOverwriteMode::COPY_OVERWRITE_OR_IGNORE:\n+\t\treturn \"COPY_OVERWRITE_OR_IGNORE\";\n+\tdefault:\n+\t\tthrow NotImplementedException(StringUtil::Format(\"Enum value: '%d' not implemented\", value));\n+\t}\n+}\n+\n+template<>\n+CopyOverwriteMode EnumUtil::FromString<CopyOverwriteMode>(const char *value) {\n+\tif (StringUtil::Equals(value, \"COPY_ERROR_ON_CONFLICT\")) {\n+\t\treturn CopyOverwriteMode::COPY_ERROR_ON_CONFLICT;\n+\t}\n+\tif (StringUtil::Equals(value, \"COPY_OVERWRITE\")) {\n+\t\treturn CopyOverwriteMode::COPY_OVERWRITE;\n+\t}\n+\tif (StringUtil::Equals(value, \"COPY_OVERWRITE_OR_IGNORE\")) {\n+\t\treturn CopyOverwriteMode::COPY_OVERWRITE_OR_IGNORE;\n+\t}\n+\tthrow NotImplementedException(StringUtil::Format(\"Enum value: '%s' not implemented\", value));\n+}\n+\n template<>\n const char* EnumUtil::ToChars<DataFileType>(DataFileType value) {\n \tswitch(value) {\ndiff --git a/src/execution/operator/persistent/physical_copy_to_file.cpp b/src/execution/operator/persistent/physical_copy_to_file.cpp\nindex 9205067b3c10..2280b7707ae0 100644\n--- a/src/execution/operator/persistent/physical_copy_to_file.cpp\n+++ b/src/execution/operator/persistent/physical_copy_to_file.cpp\n@@ -228,12 +228,16 @@ unique_ptr<LocalSinkState> PhysicalCopyToFile::GetLocalSinkState(ExecutionContex\n \treturn std::move(res);\n }\n \n-void CheckDirectory(FileSystem &fs, const string &file_path, bool overwrite) {\n-\tif (fs.IsRemoteFile(file_path) && overwrite) {\n-\t\t// we only remove files for local file systems\n-\t\t// as remote file systems (e.g. S3) do not support RemoveFile\n+void CheckDirectory(FileSystem &fs, const string &file_path, CopyOverwriteMode overwrite_mode) {\n+\tif (overwrite_mode == CopyOverwriteMode::COPY_OVERWRITE_OR_IGNORE) {\n+\t\t// with overwrite or ignore we fully ignore the presence of any files instead of erasing them\n \t\treturn;\n \t}\n+\tif (fs.IsRemoteFile(file_path) && overwrite_mode == CopyOverwriteMode::COPY_OVERWRITE) {\n+\t\t// we can only remove files for local file systems currently\n+\t\t// as remote file systems (e.g. S3) do not support RemoveFile\n+\t\tthrow NotImplementedException(\"OVERWRITE is not supported for remote file systems\");\n+\t}\n \tvector<string> file_list;\n \tvector<string> directory_list;\n \tdirectory_list.push_back(file_path);\n@@ -251,13 +255,12 @@ void CheckDirectory(FileSystem &fs, const string &file_path, bool overwrite) {\n \tif (file_list.empty()) {\n \t\treturn;\n \t}\n-\tif (overwrite) {\n+\tif (overwrite_mode == CopyOverwriteMode::COPY_OVERWRITE) {\n \t\tfor (auto &file : file_list) {\n \t\t\tfs.RemoveFile(file);\n \t\t}\n \t} else {\n-\t\tthrow IOException(\"Directory \\\"%s\\\" is not empty! Enable OVERWRITE_OR_IGNORE option to force writing\",\n-\t\t                  file_path);\n+\t\tthrow IOException(\"Directory \\\"%s\\\" is not empty! Enable OVERWRITE option to overwrite files\", file_path);\n \t}\n }\n \n@@ -272,11 +275,11 @@ unique_ptr<GlobalSinkState> PhysicalCopyToFile::GetGlobalSinkState(ClientContext\n \t\t\t\tthrow IOException(\"Cannot write to \\\"%s\\\" - it exists and is a file, not a directory!\", file_path);\n \t\t\t} else {\n \t\t\t\t// for local files we can remove the file if OVERWRITE_OR_IGNORE is enabled\n-\t\t\t\tif (overwrite_or_ignore) {\n+\t\t\t\tif (overwrite_mode == CopyOverwriteMode::COPY_OVERWRITE) {\n \t\t\t\t\tfs.RemoveFile(file_path);\n \t\t\t\t} else {\n \t\t\t\t\tthrow IOException(\"Cannot write to \\\"%s\\\" - it exists and is a file, not a directory! Enable \"\n-\t\t\t\t\t                  \"OVERWRITE_OR_IGNORE option to force writing\",\n+\t\t\t\t\t                  \"OVERWRITE option to overwrite the file\",\n \t\t\t\t\t                  file_path);\n \t\t\t\t}\n \t\t\t}\n@@ -285,7 +288,7 @@ unique_ptr<GlobalSinkState> PhysicalCopyToFile::GetGlobalSinkState(ClientContext\n \t\tif (!fs.DirectoryExists(file_path)) {\n \t\t\tfs.CreateDirectory(file_path);\n \t\t} else {\n-\t\t\tCheckDirectory(fs, file_path, overwrite_or_ignore);\n+\t\t\tCheckDirectory(fs, file_path, overwrite_mode);\n \t\t}\n \n \t\tauto state = make_uniq<CopyToFunctionGlobalState>(nullptr);\ndiff --git a/src/execution/physical_plan/plan_copy_to_file.cpp b/src/execution/physical_plan/plan_copy_to_file.cpp\nindex cd7f19cdbca8..c3194e253f67 100644\n--- a/src/execution/physical_plan/plan_copy_to_file.cpp\n+++ b/src/execution/physical_plan/plan_copy_to_file.cpp\n@@ -17,7 +17,7 @@ unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalCopyToFile\n \t\top.file_path = fs.JoinPath(path, \"tmp_\" + base);\n \t}\n \tif (op.per_thread_output || op.file_size_bytes.IsValid() || op.partition_output || !op.partition_columns.empty() ||\n-\t    op.overwrite_or_ignore) {\n+\t    op.overwrite_mode != CopyOverwriteMode::COPY_ERROR_ON_CONFLICT) {\n \t\t// hive-partitioning/per-thread output does not care about insertion order, and does not support batch indexes\n \t\tpreserve_insertion_order = false;\n \t\tsupports_batch_index = false;\n@@ -42,7 +42,7 @@ unique_ptr<PhysicalOperator> PhysicalPlanGenerator::CreatePlan(LogicalCopyToFile\n \tauto copy = make_uniq<PhysicalCopyToFile>(op.types, op.function, std::move(op.bind_data), op.estimated_cardinality);\n \tcopy->file_path = op.file_path;\n \tcopy->use_tmp_file = op.use_tmp_file;\n-\tcopy->overwrite_or_ignore = op.overwrite_or_ignore;\n+\tcopy->overwrite_mode = op.overwrite_mode;\n \tcopy->filename_pattern = op.filename_pattern;\n \tcopy->file_extension = op.file_extension;\n \tcopy->per_thread_output = op.per_thread_output;\ndiff --git a/src/include/duckdb/common/enum_util.hpp b/src/include/duckdb/common/enum_util.hpp\nindex fea983108a43..6ca097982489 100644\n--- a/src/include/duckdb/common/enum_util.hpp\n+++ b/src/include/duckdb/common/enum_util.hpp\n@@ -98,6 +98,8 @@ enum class ConflictManagerMode : uint8_t;\n \n enum class ConstraintType : uint8_t;\n \n+enum class CopyOverwriteMode : uint8_t;\n+\n enum class DataFileType : uint8_t;\n \n enum class DatePartSpecifier : uint8_t;\n@@ -434,6 +436,9 @@ const char* EnumUtil::ToChars<ConflictManagerMode>(ConflictManagerMode value);\n template<>\n const char* EnumUtil::ToChars<ConstraintType>(ConstraintType value);\n \n+template<>\n+const char* EnumUtil::ToChars<CopyOverwriteMode>(CopyOverwriteMode value);\n+\n template<>\n const char* EnumUtil::ToChars<DataFileType>(DataFileType value);\n \n@@ -888,6 +893,9 @@ ConflictManagerMode EnumUtil::FromString<ConflictManagerMode>(const char *value)\n template<>\n ConstraintType EnumUtil::FromString<ConstraintType>(const char *value);\n \n+template<>\n+CopyOverwriteMode EnumUtil::FromString<CopyOverwriteMode>(const char *value);\n+\n template<>\n DataFileType EnumUtil::FromString<DataFileType>(const char *value);\n \ndiff --git a/src/include/duckdb/common/enums/copy_overwrite_mode.hpp b/src/include/duckdb/common/enums/copy_overwrite_mode.hpp\nnew file mode 100644\nindex 000000000000..595a867e9a32\n--- /dev/null\n+++ b/src/include/duckdb/common/enums/copy_overwrite_mode.hpp\n@@ -0,0 +1,18 @@\n+//===----------------------------------------------------------------------===//\n+//                         DuckDB\n+//\n+// duckdb/common/enums/copy_overwrite_mode.hpp\n+//\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#pragma once\n+\n+#include \"duckdb/common/constants.hpp\"\n+#include \"duckdb/common/vector.hpp\"\n+\n+namespace duckdb {\n+\n+enum class CopyOverwriteMode : uint8_t { COPY_ERROR_ON_CONFLICT = 0, COPY_OVERWRITE = 1, COPY_OVERWRITE_OR_IGNORE = 2 };\n+\n+} // namespace duckdb\ndiff --git a/src/include/duckdb/execution/operator/persistent/physical_copy_to_file.hpp b/src/include/duckdb/execution/operator/persistent/physical_copy_to_file.hpp\nindex a405ee5cb683..980d5dc979f8 100644\n--- a/src/include/duckdb/execution/operator/persistent/physical_copy_to_file.hpp\n+++ b/src/include/duckdb/execution/operator/persistent/physical_copy_to_file.hpp\n@@ -13,6 +13,7 @@\n #include \"duckdb/execution/physical_operator.hpp\"\n #include \"duckdb/function/copy_function.hpp\"\n #include \"duckdb/parser/parsed_data/copy_info.hpp\"\n+#include \"duckdb/common/enums/copy_overwrite_mode.hpp\"\n \n namespace duckdb {\n \n@@ -31,7 +32,7 @@ class PhysicalCopyToFile : public PhysicalOperator {\n \tbool use_tmp_file;\n \tFilenamePattern filename_pattern;\n \tstring file_extension;\n-\tbool overwrite_or_ignore;\n+\tCopyOverwriteMode overwrite_mode;\n \tbool parallel;\n \tbool per_thread_output;\n \toptional_idx file_size_bytes;\ndiff --git a/src/include/duckdb/planner/operator/logical_copy_to_file.hpp b/src/include/duckdb/planner/operator/logical_copy_to_file.hpp\nindex ea79b9407651..bc95ae5ad150 100644\n--- a/src/include/duckdb/planner/operator/logical_copy_to_file.hpp\n+++ b/src/include/duckdb/planner/operator/logical_copy_to_file.hpp\n@@ -13,6 +13,7 @@\n #include \"duckdb/common/optional_idx.hpp\"\n #include \"duckdb/function/copy_function.hpp\"\n #include \"duckdb/planner/logical_operator.hpp\"\n+#include \"duckdb/common/enums/copy_overwrite_mode.hpp\"\n \n namespace duckdb {\n \n@@ -33,7 +34,7 @@ class LogicalCopyToFile : public LogicalOperator {\n \tbool use_tmp_file;\n \tFilenamePattern filename_pattern;\n \tstring file_extension;\n-\tbool overwrite_or_ignore;\n+\tCopyOverwriteMode overwrite_mode;\n \tbool per_thread_output;\n \toptional_idx file_size_bytes;\n \ndiff --git a/src/planner/binder/statement/bind_copy.cpp b/src/planner/binder/statement/bind_copy.cpp\nindex 1e3928f0bb79..7db1db812dec 100644\n--- a/src/planner/binder/statement/bind_copy.cpp\n+++ b/src/planner/binder/statement/bind_copy.cpp\n@@ -55,12 +55,13 @@ BoundStatement Binder::BindCopyTo(CopyStatement &stmt) {\n \t}\n \n \tbool use_tmp_file = true;\n-\tbool overwrite_or_ignore = false;\n+\tCopyOverwriteMode overwrite_mode = CopyOverwriteMode::COPY_ERROR_ON_CONFLICT;\n \tFilenamePattern filename_pattern;\n \tbool user_set_use_tmp_file = false;\n \tbool per_thread_output = false;\n \toptional_idx file_size_bytes;\n \tvector<idx_t> partition_cols;\n+\tbool seen_overwrite_mode = false;\n \n \tCopyFunctionBindInput bind_input(*stmt.info);\n \n@@ -74,8 +75,20 @@ BoundStatement Binder::BindCopyTo(CopyStatement &stmt) {\n \t\tif (loption == \"use_tmp_file\") {\n \t\t\tuse_tmp_file = GetBooleanArg(context, option.second);\n \t\t\tuser_set_use_tmp_file = true;\n-\t\t} else if (loption == \"overwrite_or_ignore\") {\n-\t\t\toverwrite_or_ignore = GetBooleanArg(context, option.second);\n+\t\t} else if (loption == \"overwrite_or_ignore\" || loption == \"overwrite\") {\n+\t\t\tif (seen_overwrite_mode) {\n+\t\t\t\tthrow BinderException(\"Can only set one of OVERWRITE_OR_IGNORE or OVERWRITE\");\n+\t\t\t}\n+\t\t\tseen_overwrite_mode = true;\n+\n+\t\t\tauto boolean = GetBooleanArg(context, option.second);\n+\t\t\tif (boolean) {\n+\t\t\t\tif (loption == \"overwrite_or_ignore\") {\n+\t\t\t\t\toverwrite_mode = CopyOverwriteMode::COPY_OVERWRITE_OR_IGNORE;\n+\t\t\t\t} else if (loption == \"overwrite\") {\n+\t\t\t\t\toverwrite_mode = CopyOverwriteMode::COPY_OVERWRITE;\n+\t\t\t\t}\n+\t\t\t}\n \t\t} else if (loption == \"filename_pattern\") {\n \t\t\tif (option.second.empty()) {\n \t\t\t\tthrow IOException(\"FILENAME_PATTERN cannot be empty\");\n@@ -146,7 +159,7 @@ BoundStatement Binder::BindCopyTo(CopyStatement &stmt) {\n \tauto copy = make_uniq<LogicalCopyToFile>(copy_function.function, std::move(function_data), std::move(stmt.info));\n \tcopy->file_path = file_path;\n \tcopy->use_tmp_file = use_tmp_file;\n-\tcopy->overwrite_or_ignore = overwrite_or_ignore;\n+\tcopy->overwrite_mode = overwrite_mode;\n \tcopy->filename_pattern = filename_pattern;\n \tcopy->file_extension = bind_input.file_extension;\n \tcopy->per_thread_output = per_thread_output;\ndiff --git a/src/planner/operator/logical_copy_to_file.cpp b/src/planner/operator/logical_copy_to_file.cpp\nindex 67f684d84614..6ed72e799e8b 100644\n--- a/src/planner/operator/logical_copy_to_file.cpp\n+++ b/src/planner/operator/logical_copy_to_file.cpp\n@@ -13,7 +13,7 @@ void LogicalCopyToFile::Serialize(Serializer &serializer) const {\n \tserializer.WriteProperty(200, \"file_path\", file_path);\n \tserializer.WriteProperty(201, \"use_tmp_file\", use_tmp_file);\n \tserializer.WriteProperty(202, \"filename_pattern\", filename_pattern);\n-\tserializer.WriteProperty(203, \"overwrite_or_ignore\", overwrite_or_ignore);\n+\tserializer.WriteProperty(203, \"overwrite_or_ignore\", overwrite_mode);\n \tserializer.WriteProperty(204, \"per_thread_output\", per_thread_output);\n \tserializer.WriteProperty(205, \"partition_output\", partition_output);\n \tserializer.WriteProperty(206, \"partition_columns\", partition_columns);\n@@ -39,7 +39,7 @@ unique_ptr<LogicalOperator> LogicalCopyToFile::Deserialize(Deserializer &deseria\n \tauto file_path = deserializer.ReadProperty<string>(200, \"file_path\");\n \tauto use_tmp_file = deserializer.ReadProperty<bool>(201, \"use_tmp_file\");\n \tauto filename_pattern = deserializer.ReadProperty<FilenamePattern>(202, \"filename_pattern\");\n-\tauto overwrite_or_ignore = deserializer.ReadProperty<bool>(203, \"overwrite_or_ignore\");\n+\tauto overwrite_mode = deserializer.ReadProperty<CopyOverwriteMode>(203, \"overwrite_mode\");\n \tauto per_thread_output = deserializer.ReadProperty<bool>(204, \"per_thread_output\");\n \tauto partition_output = deserializer.ReadProperty<bool>(205, \"partition_output\");\n \tauto partition_columns = deserializer.ReadProperty<vector<idx_t>>(206, \"partition_columns\");\n@@ -86,7 +86,7 @@ unique_ptr<LogicalOperator> LogicalCopyToFile::Deserialize(Deserializer &deseria\n \tresult->use_tmp_file = use_tmp_file;\n \tresult->filename_pattern = filename_pattern;\n \tresult->file_extension = file_extension;\n-\tresult->overwrite_or_ignore = overwrite_or_ignore;\n+\tresult->overwrite_mode = overwrite_mode;\n \tresult->per_thread_output = per_thread_output;\n \tresult->partition_output = partition_output;\n \tresult->partition_columns = partition_columns;\n",
  "test_patch": "diff --git a/test/sql/copy/format_uuid.test b/test/sql/copy/format_uuid.test\nindex 1f773cdef835..ff09c264fc70 100644\n--- a/test/sql/copy/format_uuid.test\n+++ b/test/sql/copy/format_uuid.test\n@@ -61,6 +61,7 @@ SELECT * FROM '__TEST_DIR__/part/a=9/leading_????????-????-4???-????-???????????\n query III sort\n SELECT * FROM '__TEST_DIR__/part/a=9/leading_????????-????-4???-????-????????????*.parquet';\n ----\n+9\t18\t81\n 9\t27\t729\n \n # Test without a specified format name for the outputfile.\n@@ -77,6 +78,8 @@ SELECT * FROM '__TEST_DIR__/part/a=9/data_[0-9]*.parquet';\n query III sort\n SELECT * FROM '__TEST_DIR__/part/a=9/*.parquet';\n ----\n+9\t18\t81\n+9\t27\t729\n 9\t36\t6561\n \n # Test where the FILENAME_PATTERN does not contain \"{i}\" or \"{uuid}\". \n@@ -93,6 +96,9 @@ SELECT * FROM '__TEST_DIR__/part/a=9/basename[0-9]*.parquet';\n query III sort\n SELECT * FROM '__TEST_DIR__/part/a=9/*.parquet';\n ----\n+9\t18\t81\n+9\t27\t729\n+9\t36\t6561\n 9\t45\t59049\n \n # Test without the overwrite_or_ignore param, that tries to add a file to an existing directory\ndiff --git a/test/sql/copy/partitioned/hive_partitioning_overwrite.test b/test/sql/copy/partitioned/hive_partitioning_overwrite.test\nindex 1b458a47a372..eb002273aa40 100644\n--- a/test/sql/copy/partitioned/hive_partitioning_overwrite.test\n+++ b/test/sql/copy/partitioned/hive_partitioning_overwrite.test\n@@ -12,11 +12,11 @@ COPY (SELECT 42 AS part_col) TO '__TEST_DIR__/overwrite_test' (FORMAT PARQUET, P\n statement error\n COPY (SELECT 84 AS part_col) TO '__TEST_DIR__/overwrite_test' (FORMAT PARQUET, PARTITION_BY (part_col));\n ----\n-Enable OVERWRITE_OR_IGNORE option to force writing\n+Enable OVERWRITE option to overwrite files\n \n # test the overwrite setting\n statement ok\n-COPY (SELECT 84 AS part_col) TO '__TEST_DIR__/overwrite_test' (FORMAT PARQUET, PARTITION_BY (part_col), OVERWRITE_OR_IGNORE 1);\n+COPY (SELECT 84 AS part_col) TO '__TEST_DIR__/overwrite_test' (FORMAT PARQUET, PARTITION_BY (part_col), OVERWRITE 1);\n \n # the old file (with part_col=42) should now be removed\n query I\n@@ -34,9 +34,14 @@ COPY (SELECT 84 AS part_col) TO '__TEST_DIR__/overwrite_test2' (FORMAT PARQUET,\n it exists and is a file\n \n statement ok\n-COPY (SELECT 84 AS part_col) TO '__TEST_DIR__/overwrite_test2' (FORMAT PARQUET, PARTITION_BY (part_col), OVERWRITE_OR_IGNORE 1);\n+COPY (SELECT 84 AS part_col) TO '__TEST_DIR__/overwrite_test2' (FORMAT PARQUET, PARTITION_BY (part_col), OVERWRITE 1);\n \n query I\n SELECT * FROM '__TEST_DIR__/overwrite_test2/**/*.parquet'\n ----\n 84\n+\n+statement error\n+COPY (SELECT 84 AS part_col) TO '__TEST_DIR__/overwrite_test' (FORMAT PARQUET, PARTITION_BY (part_col), OVERWRITE 1, OVERWRITE_OR_IGNORE 1);\n+----\n+Can only set one of OVERWRITE_OR_IGNORE or OVERWRITE\ndiff --git a/test/sql/copy/s3/s3_hive_partition.test b/test/sql/copy/s3/s3_hive_partition.test\nindex 47b3c028b169..efa534738ac2 100644\n--- a/test/sql/copy/s3/s3_hive_partition.test\n+++ b/test/sql/copy/s3/s3_hive_partition.test\n@@ -98,3 +98,7 @@ EXPLAIN select a from read_csv_auto('s3://test-bucket/hive-partitioning/filter-t\n ----\n physical_plan\t<REGEX>:.*FILTER.*(a < 4).*READ_CSV_AUTO.*File Filters: \\(CAST\\(c AS.*INTEGER\\) = 500\\).*\n \n+statement error\n+COPY (SELECT * FROM t1) TO 's3://test-bucket/hive-partitioning/filter-test-parquet' (FORMAT PARQUET, PARTITION_BY c, OVERWRITE);\n+----\n+OVERWRITE is not supported for remote file systems\ndiff --git a/tools/pythonpkg/tests/fast/api/test_to_csv.py b/tools/pythonpkg/tests/fast/api/test_to_csv.py\nindex b52dcde35db6..0b137327710d 100644\n--- a/tools/pythonpkg/tests/fast/api/test_to_csv.py\n+++ b/tools/pythonpkg/tests/fast/api/test_to_csv.py\n@@ -218,7 +218,7 @@ def test_to_csv_overwrite_not_enabled(self, pandas):\n         )\n         rel = duckdb.from_df(df)\n         rel.to_csv(temp_file_name, header=True, partition_by=[\"c_category_1\"])\n-        with pytest.raises(duckdb.IOException, match=\"Enable OVERWRITE_OR_IGNORE option to force writing\"):\n+        with pytest.raises(duckdb.IOException, match=\"OVERWRITE\"):\n             rel.to_csv(temp_file_name, header=True, partition_by=[\"c_category_1\"])\n \n     @pytest.mark.parametrize('pandas', [NumpyPandas(), ArrowPandas()])\n",
  "problem_statement": "Hive partitioned append/write 0.10.3 \n### What happens?\n\nBefore version 0.10.3, you could enforce partitioned append to a Hive partitioned table by specifying the FILENAME_PATTERN \r\nproperty and setting OVERWRITE_OR_IGNORE to true. \r\nHowever, since the recent changes (as documented in this GitHub pull request https://github.com/duckdb/duckdb/pull/11787),\r\n the behavior has been modified. Now I am experiencing breaking changes in my applications.  Is there any alternative approach for partitioned append? The code below  illustrates the problem.\n\n### To Reproduce\n\n```sql\r\ncreate or replace temp view t_val_v  as \r\nselect *\r\nfrom ( \r\n    values \r\n    ('p_1', 'key_1', 'val_1'),\r\n    ('p_2', 'key_1', 'val_1'),\r\n    ('p_3', 'key_1', 'val_1')\r\n) as t_val(p_key, key, val);\r\ncopy (\r\n    select *\r\n    from  t_val_v\r\n) to '/home/da/output_tmp/t_val' (\r\nformat parquet,\r\nPARTITION_BY (p_key),\r\nFILENAME_PATTERN \"pv1_{i}\",\r\nOVERWRITE_OR_IGNORE false\r\n);\r\ncopy (\r\n    select *\r\n    from  t_val_v\r\n) to '/home/da/output_tmp/t_val' (\r\nformat parquet,\r\nPARTITION_BY (p_key),\r\nFILENAME_PATTERN \"pv2_{i}\",\r\nOVERWRITE_OR_IGNORE false\r\n);\r\n```\r\n\r\noutput before. changes (version 0.10.2):\r\n\r\n```bash\r\nbefore 0.10.3 \r\n~/output_tmp/t_val/p_key=p_1$ ls -la\r\ntotal 16\r\ndrwxr-xr-x 2 da da 4096 May 24 10:46 .\r\ndrwxr-xr-x 5 da da 4096 May 24 10:44 ..\r\n-rw-r--r-- 1 da da  367 May 24 11:49 pv1_0.parquet\r\n-rw-r--r-- 1 da da  367 May 24 11:49 pv2_0.parquet\r\n```\r\noutput with version 0.10.3 (removes all old files)\r\n\r\n```bash\r\n~/output_tmp/t_val/p_key=p_1$ ls -la\r\ntotal 12\r\ndrwxr-xr-x 2 da da 4096 May 24 11:51 .\r\ndrwxr-xr-x 5 da da 4096 May 24 10:44 ..\r\n-rw-r--r-- 1 da da  367 May 24 11:51 pv2_0.parquet\r\n```\r\n\r\n\n\n### OS:\n\nwindows, ubuntu\n\n### DuckDB Version:\n\n0.10.3\n\n### DuckDB Client:\n\npython\n\n### Full Name:\n\nDaniar Achakeev\n\n### Affiliation:\n\nHMS Analytical Software GmbH\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNot applicable - the reproduction does not require a data set\n\n### Did you include all code required to reproduce the issue?\n\n- [X] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [X] Yes, I have\nHive partitioned append/write 0.10.3 \n### What happens?\n\nBefore version 0.10.3, you could enforce partitioned append to a Hive partitioned table by specifying the FILENAME_PATTERN \r\nproperty and setting OVERWRITE_OR_IGNORE to true. \r\nHowever, since the recent changes (as documented in this GitHub pull request https://github.com/duckdb/duckdb/pull/11787),\r\n the behavior has been modified. Now I am experiencing breaking changes in my applications.  Is there any alternative approach for partitioned append? The code below  illustrates the problem.\n\n### To Reproduce\n\n```sql\r\ncreate or replace temp view t_val_v  as \r\nselect *\r\nfrom ( \r\n    values \r\n    ('p_1', 'key_1', 'val_1'),\r\n    ('p_2', 'key_1', 'val_1'),\r\n    ('p_3', 'key_1', 'val_1')\r\n) as t_val(p_key, key, val);\r\ncopy (\r\n    select *\r\n    from  t_val_v\r\n) to '/home/da/output_tmp/t_val' (\r\nformat parquet,\r\nPARTITION_BY (p_key),\r\nFILENAME_PATTERN \"pv1_{i}\",\r\nOVERWRITE_OR_IGNORE false\r\n);\r\ncopy (\r\n    select *\r\n    from  t_val_v\r\n) to '/home/da/output_tmp/t_val' (\r\nformat parquet,\r\nPARTITION_BY (p_key),\r\nFILENAME_PATTERN \"pv2_{i}\",\r\nOVERWRITE_OR_IGNORE false\r\n);\r\n```\r\n\r\noutput before. changes (version 0.10.2):\r\n\r\n```bash\r\nbefore 0.10.3 \r\n~/output_tmp/t_val/p_key=p_1$ ls -la\r\ntotal 16\r\ndrwxr-xr-x 2 da da 4096 May 24 10:46 .\r\ndrwxr-xr-x 5 da da 4096 May 24 10:44 ..\r\n-rw-r--r-- 1 da da  367 May 24 11:49 pv1_0.parquet\r\n-rw-r--r-- 1 da da  367 May 24 11:49 pv2_0.parquet\r\n```\r\noutput with version 0.10.3 (removes all old files)\r\n\r\n```bash\r\n~/output_tmp/t_val/p_key=p_1$ ls -la\r\ntotal 12\r\ndrwxr-xr-x 2 da da 4096 May 24 11:51 .\r\ndrwxr-xr-x 5 da da 4096 May 24 10:44 ..\r\n-rw-r--r-- 1 da da  367 May 24 11:51 pv2_0.parquet\r\n```\r\n\r\n\n\n### OS:\n\nwindows, ubuntu\n\n### DuckDB Version:\n\n0.10.3\n\n### DuckDB Client:\n\npython\n\n### Full Name:\n\nDaniar Achakeev\n\n### Affiliation:\n\nHMS Analytical Software GmbH\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNot applicable - the reproduction does not require a data set\n\n### Did you include all code required to reproduce the issue?\n\n- [X] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [X] Yes, I have\n",
  "hints_text": "yes, I reported the issue in discussion 3 weeks ago, current workaround is not to upgrade\r\n\r\nhttps://github.com/duckdb/duckdb/discussions/11928\nyes, I reported the issue in discussion 3 weeks ago, current workaround is not to upgrade\r\n\r\nhttps://github.com/duckdb/duckdb/discussions/11928",
  "created_at": "2024-05-25T11:21:47Z"
}