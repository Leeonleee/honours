{
  "repo": "duckdb/duckdb",
  "pull_number": 14030,
  "instance_id": "duckdb__duckdb-14030",
  "issue_numbers": [
    "14020",
    "14020"
  ],
  "base_commit": "58e511c59b621d019fc189216cdd08b9debb0993",
  "patch": "diff --git a/src/storage/compression/rle.cpp b/src/storage/compression/rle.cpp\nindex f845baad323a..61524cda8ac1 100644\n--- a/src/storage/compression/rle.cpp\n+++ b/src/storage/compression/rle.cpp\n@@ -57,11 +57,14 @@ struct RLEState {\n \t\t\t} else {\n \t\t\t\t// the values are different\n \t\t\t\t// issue the callback on the last value\n-\t\t\t\tFlush<OP>();\n+\t\t\t\t// edge case: if a value has exactly 2^16 repeated values, we can end up here with last_seen_count = 0\n+\t\t\t\tif (last_seen_count > 0) {\n+\t\t\t\t\tFlush<OP>();\n+\t\t\t\t\tseen_count++;\n+\t\t\t\t}\n \n \t\t\t\t// increment the seen_count and put the new value into the RLE slot\n \t\t\t\tlast_value = data[idx];\n-\t\t\t\tseen_count++;\n \t\t\t\tlast_seen_count = 1;\n \t\t\t}\n \t\t} else {\n",
  "test_patch": "diff --git a/test/sql/storage/compression/rle/rle_many_repeated.test_slow b/test/sql/storage/compression/rle/rle_many_repeated.test_slow\nnew file mode 100644\nindex 000000000000..dca8635d215d\n--- /dev/null\n+++ b/test/sql/storage/compression/rle/rle_many_repeated.test_slow\n@@ -0,0 +1,25 @@\n+# name: test/sql/storage/compression/rle/rle_many_repeated.test_slow\n+# description: Test forcing RLE as the compression scheme\n+# group: [rle]\n+\n+require vector_size 2048\n+\n+load __TEST_DIR__/rle_many_repeated.db\n+\n+statement ok\n+PRAGMA force_compression = 'rle'\n+\n+statement ok\n+CREATE TABLE test_rle (a BIGINT);\n+\n+statement ok\n+INSERT INTO test_rle SELECT 3::BIGINT FROM range(0, 65535) UNION ALL SELECT 4::BIGINT FROM range(100000);\n+\n+statement ok\n+CHECKPOINT\n+\n+query II\n+SELECT a, COUNT(*) FROM test_rle GROUP BY ALL\n+----\n+3\t65535\n+4\t100000\n",
  "problem_statement": "Seeing a single value changed after inserting ~1.5million row polars df to duckdb and then querying back out\n### What happens?\r\n\r\nWhen I write these 9 polars dataframes (saved as parquet files here: https://drive.google.com/drive/folders/18-xFUBLvPyux-erwETaATOV_fUpkLp4B?usp=sharing) to a duckdb table, I find that one single value from one single column is changed when I read the data back out.\r\n\r\n### To Reproduce\r\n\r\nFirst, download these 9 parquet files to your local machine: https://drive.google.com/drive/folders/18-xFUBLvPyux-erwETaATOV_fUpkLp4B?usp=sharing\r\n\r\nThen, run the following code:\r\n```\r\nimport duckdb\r\nimport polars as pl\r\nimport os\r\nfrom datetime import date\r\nfrom zipfile import ZipFile\r\n\r\n### Constants\r\nFILESDIR = \"path_you_saved_downloaded_parquet_files_to\" \r\nDAYS = range(1,10)\r\nDUCKDB_FILE = os.path.join(\"path_you_saved_downloaded_parquet_files_to\", \"so_test.ddb\")\r\n\r\n### Read data from disk and write to duckdb\r\nfor day in DAYS:\r\n    pldf = pl.read_parquet(os.path.join(FILESDIR, f\"f{day}_masked.parquet\"))\r\n    with duckdb.connect(database=DUCKDB_FILE, read_only=False) as conn:\r\n        if day == 1:\r\n            conn.execute(f\"CREATE OR REPLACE TABLE so_test AS SELECT * FROM pldf\")\r\n        else:\r\n            conn.execute(f\"INSERT INTO so_test SELECT * FROM pldf\")        \r\n\r\n### Verify that the data has changed by comparing a specific row from last df to its record in duckdb\r\nPROBLEM_ROW = 1108956\r\n\r\nprint(pldf.slice(PROBLEM_ROW,1))  # hour=4.0\r\nwith duckdb.connect(database=DUCKDB_FILE, read_only=False) as conn:\r\n    print(conn.execute(f\"SELECT * from so_test WHERE (DAILY_FILE_ROW_ORDER = {PROBLEM_ROW}) and (DAILY_FILE_DATE = '2021-01-09')\").pl())  # hour=3.0 now\r\n```\r\n\r\nBelow is a screenshot of what I see when I run the code above. Note the rows are identical except `hour` has been changed from `4.0` to `3.0` (Also, I see `hour` for that row has been changed to `3.0` even if I read the result as a pandas `.df()`). \r\n<img width=\"834\" alt=\"screenshot for duckdb issue\" src=\"https://github.com/user-attachments/assets/ee217594-528c-49d3-861e-016758a19c02\">\r\n\r\n\r\n### OS:\r\n\r\nWindows Server 2019 Datacenter, Version 10.0.17763 Build 17763 x64\r\n\r\n### DuckDB Version:\r\n\r\n1.1.0\r\n\r\n### DuckDB Client:\r\n\r\npython (python version 3.9.6)\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\nMax Epstein\r\n\r\n### Affiliation:\r\n\r\nMax Power Consulting, LLC\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\nSeeing a single value changed after inserting ~1.5million row polars df to duckdb and then querying back out\n### What happens?\r\n\r\nWhen I write these 9 polars dataframes (saved as parquet files here: https://drive.google.com/drive/folders/18-xFUBLvPyux-erwETaATOV_fUpkLp4B?usp=sharing) to a duckdb table, I find that one single value from one single column is changed when I read the data back out.\r\n\r\n### To Reproduce\r\n\r\nFirst, download these 9 parquet files to your local machine: https://drive.google.com/drive/folders/18-xFUBLvPyux-erwETaATOV_fUpkLp4B?usp=sharing\r\n\r\nThen, run the following code:\r\n```\r\nimport duckdb\r\nimport polars as pl\r\nimport os\r\nfrom datetime import date\r\nfrom zipfile import ZipFile\r\n\r\n### Constants\r\nFILESDIR = \"path_you_saved_downloaded_parquet_files_to\" \r\nDAYS = range(1,10)\r\nDUCKDB_FILE = os.path.join(\"path_you_saved_downloaded_parquet_files_to\", \"so_test.ddb\")\r\n\r\n### Read data from disk and write to duckdb\r\nfor day in DAYS:\r\n    pldf = pl.read_parquet(os.path.join(FILESDIR, f\"f{day}_masked.parquet\"))\r\n    with duckdb.connect(database=DUCKDB_FILE, read_only=False) as conn:\r\n        if day == 1:\r\n            conn.execute(f\"CREATE OR REPLACE TABLE so_test AS SELECT * FROM pldf\")\r\n        else:\r\n            conn.execute(f\"INSERT INTO so_test SELECT * FROM pldf\")        \r\n\r\n### Verify that the data has changed by comparing a specific row from last df to its record in duckdb\r\nPROBLEM_ROW = 1108956\r\n\r\nprint(pldf.slice(PROBLEM_ROW,1))  # hour=4.0\r\nwith duckdb.connect(database=DUCKDB_FILE, read_only=False) as conn:\r\n    print(conn.execute(f\"SELECT * from so_test WHERE (DAILY_FILE_ROW_ORDER = {PROBLEM_ROW}) and (DAILY_FILE_DATE = '2021-01-09')\").pl())  # hour=3.0 now\r\n```\r\n\r\nBelow is a screenshot of what I see when I run the code above. Note the rows are identical except `hour` has been changed from `4.0` to `3.0` (Also, I see `hour` for that row has been changed to `3.0` even if I read the result as a pandas `.df()`). \r\n<img width=\"834\" alt=\"screenshot for duckdb issue\" src=\"https://github.com/user-attachments/assets/ee217594-528c-49d3-861e-016758a19c02\">\r\n\r\n\r\n### OS:\r\n\r\nWindows Server 2019 Datacenter, Version 10.0.17763 Build 17763 x64\r\n\r\n### DuckDB Version:\r\n\r\n1.1.0\r\n\r\n### DuckDB Client:\r\n\r\npython (python version 3.9.6)\r\n\r\n### Hardware:\r\n\r\n_No response_\r\n\r\n### Full Name:\r\n\r\nMax Epstein\r\n\r\n### Affiliation:\r\n\r\nMax Power Consulting, LLC\r\n\r\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\r\n\r\nI have tested with a stable release\r\n\r\n### Did you include all relevant data sets for reproducing the issue?\r\n\r\nYes\r\n\r\n### Did you include all code required to reproduce the issue?\r\n\r\n- [X] Yes, I have\r\n\r\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\r\n\r\n- [X] Yes, I have\n",
  "hints_text": "I'll note one more fact here in case it's a helpful hint as to what's going on:\r\n\r\nMany records leading up to row `1108956` had `hour`=`3.0`. And in my duckdb table, `hour` changes to being `4.0` at the next row `1108957`, one record after it should change to `4.0`...\nI'll note one more fact here in case it's a helpful hint as to what's going on:\r\n\r\nMany records leading up to row `1108956` had `hour`=`3.0`. And in my duckdb table, `hour` changes to being `4.0` at the next row `1108957`, one record after it should change to `4.0`...",
  "created_at": "2024-09-19T08:04:50Z"
}