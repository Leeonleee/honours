{
  "repo": "duckdb/duckdb",
  "pull_number": 4065,
  "instance_id": "duckdb__duckdb-4065",
  "issue_numbers": [
    "3938"
  ],
  "base_commit": "84e6de02a7209a9ba12ede0d85fa62ce20d0c98d",
  "patch": "diff --git a/extension/httpfs/httpfs.cpp b/extension/httpfs/httpfs.cpp\nindex 0b602a0fa15a..5ca5b99d8ebc 100644\n--- a/extension/httpfs/httpfs.cpp\n+++ b/extension/httpfs/httpfs.cpp\n@@ -44,6 +44,7 @@ void HTTPFileSystem::ParseUrl(string &url, string &path_out, string &proto_host_\n \tproto_host_port_out = url.substr(0, slash_pos);\n \n \tpath_out = url.substr(slash_pos);\n+\n \tif (path_out.empty()) {\n \t\tthrow std::runtime_error(\"URL needs to contain a path\");\n \t}\ndiff --git a/src/include/duckdb/common/field_writer.hpp b/src/include/duckdb/common/field_writer.hpp\nindex df3b1b5a3b51..50486f301a5c 100644\n--- a/src/include/duckdb/common/field_writer.hpp\n+++ b/src/include/duckdb/common/field_writer.hpp\n@@ -199,7 +199,7 @@ class FieldReader {\n \t}\n \n \ttemplate <class T, class RETURN_TYPE = unique_ptr<T>, typename... ARGS>\n-\tRETURN_TYPE ReadSerializable(RETURN_TYPE default_value, ARGS &&... args) {\n+\tRETURN_TYPE ReadSerializable(RETURN_TYPE default_value, ARGS &&...args) {\n \t\tif (field_count >= max_field_count) {\n \t\t\t// field is not there, read the default value\n \t\t\treturn default_value;\n@@ -221,7 +221,7 @@ class FieldReader {\n \t}\n \n \ttemplate <class T, class RETURN_TYPE = unique_ptr<T>, typename... ARGS>\n-\tRETURN_TYPE ReadRequiredSerializable(ARGS &&... args) {\n+\tRETURN_TYPE ReadRequiredSerializable(ARGS &&...args) {\n \t\tif (field_count >= max_field_count) {\n \t\t\t// field is not there, read the default value\n \t\t\tthrow SerializationException(\"Attempting to read mandatory field, but field is missing\");\ndiff --git a/third_party/httplib/httplib.hpp b/third_party/httplib/httplib.hpp\nindex 7cb6324b3f27..0453af9c90de 100644\n--- a/third_party/httplib/httplib.hpp\n+++ b/third_party/httplib/httplib.hpp\n@@ -2050,7 +2050,7 @@ inline std::string encode_url(const std::string &s) {\n \tfor (size_t i = 0; s[i]; i++) {\n \t\tswitch (s[i]) {\n \t\tcase ' ': result += \"%20\"; break;\n-\t\tcase '+': result += \"%2B\"; break;\n+//\t\tcase '+': result += \"%2B\"; break;\n \t\tcase '\\r': result += \"%0D\"; break;\n \t\tcase '\\n': result += \"%0A\"; break;\n \t\tcase '\\'': result += \"%27\"; break;\n@@ -2096,7 +2096,12 @@ inline std::string decode_url(const std::string &s,\n \t\t\t\tint val = 0;\n \t\t\t\tif (from_hex_to_i(s, i + 1, 2, val)) {\n \t\t\t\t\t// 2 digits hex codes\n-\t\t\t\t\tresult += static_cast<char>(val);\n+\t\t\t\t\tif (static_cast<char>(val) == '+'){\n+\t\t\t\t\t\t// We don't decode +\n+\t\t\t\t\t\tresult += \"%2B\";\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tresult += static_cast<char>(val);\n+\t\t\t\t\t}\n \t\t\t\t\ti += 2; // '00'\n \t\t\t\t} else {\n \t\t\t\t\tresult += s[i];\n@@ -3695,7 +3700,7 @@ inline void parse_query_text(const std::string &s, Params &params) {\n \t\t});\n \n \t\tif (!key.empty()) {\n-\t\t\tparams.emplace(decode_url(key, true), decode_url(val, true));\n+\t\t\tparams.emplace(decode_url(key, true), decode_url(val, false));\n \t\t}\n \t});\n }\ndiff --git a/tools/rpkg/src/relational.cpp b/tools/rpkg/src/relational.cpp\nindex 64317a995075..68ade0f6338b 100644\n--- a/tools/rpkg/src/relational.cpp\n+++ b/tools/rpkg/src/relational.cpp\n@@ -26,7 +26,7 @@ using namespace duckdb;\n using namespace cpp11;\n \n template <typename T, typename... Args>\n-external_pointer<T> make_external(const string &rclass, Args &&... args) {\n+external_pointer<T> make_external(const string &rclass, Args &&...args) {\n \tauto extptr = external_pointer<T>(new T(std::forward<Args>(args)...));\n \t((sexp)extptr).attr(\"class\") = rclass;\n \treturn (extptr);\n",
  "test_patch": "diff --git a/test/sql/copy/csv/glob/read_csv_glob_s3.test b/test/sql/copy/csv/glob/read_csv_glob_s3.test\nindex 2d50eb726748..fe31e234dcc3 100644\n--- a/test/sql/copy/csv/glob/read_csv_glob_s3.test\n+++ b/test/sql/copy/csv/glob/read_csv_glob_s3.test\n@@ -126,7 +126,7 @@ SELECT * FROM read_csv('s3://test-bucket/read_csv_glob_s3/glob/f*/f\\*.csv', auto\n 2019-06-15\n 2019-06-25\n \n-# TODO: for supporting this we need to url combine s3 url encoding with duckdb pattern matching\n+# TODO: for supporting this we need to combine s3 url encoding with duckdb pattern matching\n #query I\n #SELECT * FROM read_csv('s3://test-bucket/read_csv_glob_s3/glob/f2/f[a].csv', auto_detect=1) ORDER BY 1\n #----\ndiff --git a/test/sql/copy/parquet/test_parquet_remote.test b/test/sql/copy/parquet/test_parquet_remote.test\nindex e38e9285f0f5..de2ecdd17751 100644\n--- a/test/sql/copy/parquet/test_parquet_remote.test\n+++ b/test/sql/copy/parquet/test_parquet_remote.test\n@@ -68,17 +68,12 @@ SELECT id, first_name, last_name, email FROM PARQUET_SCAN('https://github.com:44\n 9\tJose\tFoster\tjfoster8@yelp.com\n 10\tEmily\tStewart\testewart9@opensource.org\n \n-# with a + in the path\n query IIII\n-SELECT id, first_name, last_name, email FROM PARQUET_SCAN('https://github.com/cwida/duckdb-data/releases/download/v1.0/us+er+da+ta.parquet') LIMIT 10;\n+SELECT id, first_name, last_name, email FROM PARQUET_SCAN('https://github.com/cwida/duckdb-data/releases/download/v1.0/us+er+da+ta.parquet') LIMIT 1;\n ----\n 1\tAmanda\tJordan\tajordan0@com.com\n-2\tAlbert\tFreeman\tafreeman1@is.gd\n-3\tEvelyn\tMorgan\temorgan2@altervista.org\n-4\tDenise\tRiley\tdriley3@gmpg.org\n-5\tCarlos\tBurns\tcburns4@miitbeian.gov.cn\n-6\tKathryn\tWhite\tkwhite5@google.com\n-7\tSamuel\tHolmes\tsholmes6@foxnews.com\n-8\tHarry\tHowell\thhowell7@eepurl.com\n-9\tJose\tFoster\tjfoster8@yelp.com\n-10\tEmily\tStewart\testewart9@opensource.org\n+\n+query IIII\n+SELECT id, first_name, last_name, email FROM PARQUET_SCAN('https://github.com/cwida/duckdb-data/releases/download/v1.0/us%2Ber%2Bda%2Bta.parquet') LIMIT 1;\n+----\n+1\tAmanda\tJordan\tajordan0@com.com\n\\ No newline at end of file\ndiff --git a/test/sql/copy/s3/url_encode.test b/test/sql/copy/s3/url_encode.test\nnew file mode 100644\nindex 000000000000..e22d2c3858c1\n--- /dev/null\n+++ b/test/sql/copy/s3/url_encode.test\n@@ -0,0 +1,63 @@\n+# name: test/sql/copy/s3/url_encode.test\n+# description: S3 Url encoding\n+# group: [s3]\n+\n+require parquet\n+\n+require httpfs\n+\n+require-env S3_TEST_SERVER_AVAILABLE 1\n+\n+# override the default behaviour of skipping HTTP errors and connection failures: this test fails on connection issues\n+set ignore_error_messages\n+\n+statement ok\n+SET s3_secret_access_key='minio_duckdb_user_password';SET s3_access_key_id='minio_duckdb_user';SET s3_region='eu-west-1'; SET s3_endpoint='duckdb-minio.com:9000';SET s3_use_ssl=false;\n+\n+statement ok\n+CREATE TABLE test_1 as (SELECT 1 FROM range(0,5));\n+CREATE TABLE test_2 as (SELECT 2 FROM range(0,5));\n+CREATE TABLE test_3 as (SELECT 3 FROM range(0,5));\n+\n+statement ok\n+COPY test_1 TO 's3://test-bucket-public/url_encode/just because you can doesnt mean you should.parquet' (FORMAT 'parquet');\n+\n+statement ok\n+COPY test_2 TO 's3://test-bucket-public/url_encode/just+dont+use+plus+or+spaces+please.parquet' (FORMAT 'parquet');\n+\n+# For S3 urls spaces are fine\n+query I\n+SELECT * FROM \"s3://test-bucket-public/url_encode/just because you can doesnt mean you should.parquet\" LIMIT 1;\n+----\n+1\n+\n+# In S3 urls, + means a plus symbol\n+query I\n+SELECT * FROM \"s3://test-bucket-public/url_encode/just+dont+use+plus+or+spaces+please.parquet\" LIMIT 1;\n+----\n+2\n+\n+# NOTE! For HTTP(s) urls, the + symbol is not encoded by duckdb, leaving it up to the server to decide if it should be interpreted\n+# as a space or a plus. In the case of AWS S3, they are interpreted as encoded spaces, however Minio does not\n+#query I\n+#SELECT * FROM \"http://test-bucket-public.duckdb-minio.com:9000/url_encode/just+because+you+can+doesnt+mean+you+should.parquet\" LIMIT 1;\n+#----\n+#1\n+\n+# For HTTP urls, we also allow regular spaces, which will get encoded to %20 by duckdb\n+query I\n+SELECT * FROM \"http://test-bucket-public.duckdb-minio.com:9000/url_encode/just because you can doesnt mean you should.parquet\" LIMIT 1;\n+----\n+1\n+\n+# For HTTP urls from AWS with + symbols, encoding them with %2B is required\n+query I\n+SELECT * FROM \"http://test-bucket-public.duckdb-minio.com:9000/url_encode/just%2Bdont%2Buse%2Bplus%2Bor%2Bspaces%2Bplease.parquet\" LIMIT 1;\n+----\n+2\n+\n+# However Minio interprets them as spaces so this works too\n+query I\n+SELECT * FROM \"http://test-bucket-public.duckdb-minio.com:9000/url_encode/just+dont+use+plus+or+spaces+please.parquet\" LIMIT 1;\n+----\n+2\n\\ No newline at end of file\n",
  "problem_statement": "`httpfs` extension failing to parse URL with `+`\n#### What happens?\r\nAfter installing and loading `httpfs`, I can directly load a parquet file from a URL but not if that URL contains a `+` in it (or possibly another symbol that's messing with the parser?)\r\n\r\n#### To Reproduce\r\nSteps to reproduce the behavior. Bonus points if those are only SQL queries.\r\n\r\n```\r\n./duckdb\r\nv0.4.1-dev54 d4c18532b\r\nEnter \".help\" for usage hints.\r\nConnected to a transient in-memory database.\r\nUse \".open FILENAME\" to reopen on a persistent database.\r\nD load 'extension/httpfs/httpfs.duckdb_extension';\r\nD SELECT * FROM parquet_scan('https://raw.githubusercontent.com/cwida/duckdb/master/data/parquet-testing/bug1554.parquet') limit 5;\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502                                         id                                         \u2502 is_self_canonical \u2502 backlink_count \u2502 http_status_code \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 1584883:SSuWRbZnFmIqCUBQYxk9+48fdIwywjfQUyfcKP+pbJhaqWS+UZh0Sua8VNJKlQpIlRzyWr5... \u2502 false             \u2502                \u2502 200              \u2502\r\n\u2502 1584883:VduFa/R/CL7CbbEUmdFKysh80R38hXdrfuDlFhsa5mU3G3vfUDiQdTR0H0LzJzWojUDGgUr... \u2502 false             \u2502                \u2502 200              \u2502\r\n\u2502 1584883:NWflFlh0KoHKTGAQ6G1GM3cs6HiRkJuWX+GAmgI0TSo6zxjXB9YuidjQfJNP8dNi5fuHf6g... \u2502 true              \u2502                \u2502 200              \u2502\r\n\u2502 1584883:Hi9EQ0dC7sFD8uphsqx96y/QCPmVyHpE+0EhMfgIBpsWzinDKam6zdEw7rnV8IgI0DYAZZa... \u2502 false             \u2502                \u2502 200              \u2502\r\n\u2502 1584883:n/Bpv+w2E1VG36/a6fwm2zsLEAIHwsRmfW33wuSfwbrvOXCzMInLeNKpR+mioFw3W1smXcZ... \u2502 true              \u2502                \u2502 200              \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\nD SELECT * FROM parquet_scan('https://nyc-tlc.s3.amazonaws.com/trip+data/yellow_tripdata_2022-01.parquet') limit 5;\r\nError: Unable to connect to URL \"https://nyc-tlc.s3.amazonaws.com/trip+data/yellow_tripdata_2022-01.parquet\": 404 (Not Found)\r\n```\r\n\r\n#### Environment (please complete the following information):\r\n - OS: Arch Linux\r\n - DuckDB Version: 0.4.1-dev54 d4c18532b\r\n - DuckDB Client: CLI\r\n\r\n#### Identity Disclosure:\r\n - Full Name: Gil Forsyth\r\n - Affiliation: Voltron Data\r\n\r\nIf the above is not given and is not obvious from your GitHub profile page, we might close your issue without further review. Please refer to the [reasoning behind this rule](https://berthub.eu/articles/posts/anonymous-help/) if you have questions.\r\n\r\n\r\n#### Before Submitting\r\n\r\n- [x] **Have you tried this on the latest `master` branch?**\r\n* **Python**: `pip install duckdb --upgrade --pre`\r\n* **R**: `install.packages(\"https://github.com/duckdb/duckdb/releases/download/master-builds/duckdb_r_src.tar.gz\", repos = NULL)`\r\n* **Other Platforms**: You can find binaries [here](https://github.com/duckdb/duckdb/releases/tag/master-builds) or compile from source.\r\n\r\n- [x] **Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?**\r\n\n",
  "hints_text": "I have pushed a fix in #3965 which fixes this issue for certain files containing + characters, but upon verification it seems the example you mentioned here still does not work.\r\n\r\n@samansmink could you perhaps have a look?\n~~A plus character is generally pretty valid as a space in a URL, maybe try it with the encoded form of the plus?~~\n\nBeg pardon, looks like the issue is that it's using the encoded form when it shouldn't be",
  "created_at": "2022-07-08T13:52:42Z"
}