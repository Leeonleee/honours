diff --git a/data/parquet-testing/boolean_stats.parquet b/data/parquet-testing/boolean_stats.parquet
new file mode 100644
index 000000000000..24732e003687
Binary files /dev/null and b/data/parquet-testing/boolean_stats.parquet differ
diff --git a/data/parquet-testing/date_stats.parquet b/data/parquet-testing/date_stats.parquet
new file mode 100644
index 000000000000..2b9980df5004
Binary files /dev/null and b/data/parquet-testing/date_stats.parquet differ
diff --git a/data/parquet-testing/decimal_stats.parquet b/data/parquet-testing/decimal_stats.parquet
new file mode 100644
index 000000000000..a61842106769
Binary files /dev/null and b/data/parquet-testing/decimal_stats.parquet differ
diff --git a/data/parquet-testing/signed_stats.parquet b/data/parquet-testing/signed_stats.parquet
new file mode 100644
index 000000000000..845f9c979eec
Binary files /dev/null and b/data/parquet-testing/signed_stats.parquet differ
diff --git a/data/parquet-testing/unsigned_stats.parquet b/data/parquet-testing/unsigned_stats.parquet
new file mode 100644
index 000000000000..09d9a2b42eaa
Binary files /dev/null and b/data/parquet-testing/unsigned_stats.parquet differ
diff --git a/data/parquet-testing/varchar_stats.parquet b/data/parquet-testing/varchar_stats.parquet
new file mode 100644
index 000000000000..0dd319251185
Binary files /dev/null and b/data/parquet-testing/varchar_stats.parquet differ
diff --git a/test/optimizer/statistics/statistics_filter.test b/test/optimizer/statistics/statistics_filter.test
index f39425bf98ac..860d92e999c0 100644
--- a/test/optimizer/statistics/statistics_filter.test
+++ b/test/optimizer/statistics/statistics_filter.test
@@ -2,8 +2,10 @@
 # description: Statistics propagation test with filters
 # group: [statistics]
 
+foreach type utinyint usmallint uinteger ubigint tinyint smallint integer bigint hugeint float double
+
 statement ok
-CREATE TABLE integers AS SELECT * FROM (VALUES (1), (2), (3)) tbl(i);
+CREATE TABLE integers AS SELECT i::${type} i FROM (VALUES (1), (2), (3)) tbl(i);
 
 statement ok
 PRAGMA explain_output = OPTIMIZED_ONLY;
@@ -250,3 +252,8 @@ query I
 SELECT * FROM (SELECT * FROM integers LIMIT 10) integers(i) WHERE i<=1;
 ----
 1
+
+statement ok
+DROP TABLE integers;
+
+endloop
diff --git a/test/parquet/test_parquet_reader.test b/test/parquet/test_parquet_reader.test
index ca387b55e57e..c60189b16787 100644
--- a/test/parquet/test_parquet_reader.test
+++ b/test/parquet/test_parquet_reader.test
@@ -347,8 +347,6 @@ SELECT * FROM parquet_scan('data/parquet-testing/struct.parquet') limit 50;
 {'str_field': hello, 'f64_field': NULL}
 {'str_field': NULL, 'f64_field': 1.230000}
 
-mode skip
-
 query I
 SELECT * FROM parquet_scan('data/parquet-testing/arrow/byte_array_decimal.parquet') limit 50;
 ----
@@ -377,8 +375,6 @@ SELECT * FROM parquet_scan('data/parquet-testing/arrow/byte_array_decimal.parque
 23.00	
 24.00	
 
-mode unskip
-
 query II
 SELECT * FROM parquet_scan('data/parquet-testing/arrow/list_columns.parquet') limit 50;
 ----
@@ -942,8 +938,6 @@ f2807544-a424-444a-add3-3d5d486b70e2
 d0018041-41e3-4013-ba90-535ba03d46c3	
 c50e8ade-6051-436f-a26e-acc9c0594be5	
 
-mode unskip
-
 mode skip
 
 query III
diff --git a/test/sql/copy/parquet/parquet_stats.test b/test/sql/copy/parquet/parquet_stats.test
new file mode 100644
index 000000000000..2ec66720dffe
--- /dev/null
+++ b/test/sql/copy/parquet/parquet_stats.test
@@ -0,0 +1,188 @@
+# name: test/sql/copy/parquet/parquet_stats.test
+# description: Test stats reading in parquet reader
+# group: [parquet]
+
+require parquet
+
+# boolean values
+query IIII
+select stats_min, stats_max, stats_min_value, stats_max_value from parquet_metadata('data/parquet-testing/boolean_stats.parquet');
+----
+false	true	false	true
+
+# signed numbers
+query IIII
+select stats_min, stats_max, stats_min_value, stats_max_value from parquet_metadata('data/parquet-testing/signed_stats.parquet');
+----
+-128	127	-128	127
+-32768	32767	-32768	32767
+-2147483648	2147483647	-2147483648	2147483647
+-9223372036854775808	9223372036854775807	-9223372036854775808	9223372036854775807
+
+query IIII
+select * from 'data/parquet-testing/signed_stats.parquet';
+----
+-128	-32768	-2147483648	-9223372036854775808
+127	32767	2147483647	9223372036854775807
+
+# unsigned numbers
+query IIII
+select stats_min, stats_max, stats_min_value, stats_max_value from parquet_metadata('data/parquet-testing/unsigned_stats.parquet');
+----
+NULL	NULL	0	255
+NULL	NULL	0	65535
+0	4294967295	0	4294967295
+NULL	NULL	0	18446744073709551615
+
+query IIII
+select * from 'data/parquet-testing/unsigned_stats.parquet';
+----
+0	0	0	0
+255	65535	4294967295	18446744073709551615
+
+# dates/times/timestamps
+query IIII
+select stats_min, stats_max, stats_min_value, stats_max_value from parquet_metadata('data/parquet-testing/date_stats.parquet');
+----
+1900-01-01	2030-12-31	1900-01-01	2030-12-31
+00:00:00	23:59:59	00:00:00	23:59:59
+1990-01-01 00:00:00	2030-12-31 23:59:59	1990-01-01 00:00:00	2030-12-31 23:59:59
+1900-01-01 00:00:00	2030-12-31 23:59:59	1900-01-01 00:00:00	2030-12-31 23:59:59
+1900-01-01 00:00:00	2030-12-31 23:59:59	1900-01-01 00:00:00	2030-12-31 23:59:59
+1900-01-01 00:00:00	2030-12-31 23:59:59	1900-01-01 00:00:00	2030-12-31 23:59:59
+
+query IIIIII
+select * from 'data/parquet-testing/date_stats.parquet';
+----
+1900-01-01	00:00:00	1990-01-01 00:00:00	1900-01-01 00:00:00	1900-01-01 00:00:00	1900-01-01 00:00:00
+2030-12-31	23:59:59	2030-12-31 23:59:59	2030-12-31 23:59:59	2030-12-31 23:59:59	2030-12-31 23:59:59
+
+# varchar/blob stats
+query IIII
+select stats_min, stats_max, stats_min_value, stats_max_value from parquet_metadata('data/parquet-testing/varchar_stats.parquet');
+----
+NULL	NULL	hello world	world hello
+NULL	NULL	hello\x00world	world\x00hello
+
+query II
+select * from 'data/parquet-testing/varchar_stats.parquet';
+----
+hello world	hello\x00world
+world hello	world\x00hello
+
+# decimal stats
+query IIII
+select stats_min, stats_max, stats_min_value, stats_max_value from parquet_metadata('data/parquet-testing/decimal_stats.parquet');
+----
+-999.9	999.9	-999.9	999.9
+-999999.999	999999.999	-999999.999	999999.999
+-9999999999999.99999	9999999999999.99999	-9999999999999.99999	9999999999999.99999
+-999999999999999999999999999999999.99999	999999999999999999999999999999999.99999	-999999999999999999999999999999999.99999	999999999999999999999999999999999.99999
+
+query IIII
+select * from 'data/parquet-testing/decimal_stats.parquet';
+----
+-999.9	-999999.999	-9999999999999.99999	-999999999999999999999999999999999.99999
+999.9	999999.999	9999999999999.99999	999999999999999999999999999999999.99999
+
+# int32 decimal stats
+query IIII
+select stats_min, stats_max, stats_min_value, stats_max_value from parquet_metadata('data/parquet-testing/arrow/int32_decimal.parquet');
+----
+1.00	24.00	NULL	NULL
+
+query I
+SELECT * FROM 'data/parquet-testing/arrow/int32_decimal.parquet'
+----
+1.00
+2.00
+3.00
+4.00
+5.00
+6.00
+7.00
+8.00
+9.00
+10.00
+11.00
+12.00
+13.00
+14.00
+15.00
+16.00
+17.00
+18.00
+19.00
+20.00
+21.00
+22.00
+23.00
+24.00
+
+# int64 decimal stats
+query IIII
+select stats_min, stats_max, stats_min_value, stats_max_value from parquet_metadata('data/parquet-testing/arrow/int64_decimal.parquet');
+----
+1.00	24.00	NULL	NULL
+
+query I
+SELECT * FROM 'data/parquet-testing/arrow/int64_decimal.parquet'
+----
+1.00
+2.00
+3.00
+4.00
+5.00
+6.00
+7.00
+8.00
+9.00
+10.00
+11.00
+12.00
+13.00
+14.00
+15.00
+16.00
+17.00
+18.00
+19.00
+20.00
+21.00
+22.00
+23.00
+24.00
+
+# data-types stats
+query IIII
+SELECT stats_min, stats_max, stats_min_value, stats_max_value FROM parquet_metadata('data/parquet-testing/data-types.parquet')
+----
+-127	127	-127	127
+-32767	32767	-32767	32767
+-2147483647	2147483647	-2147483647	2147483647
+-9223372036854775807	9223372036854775807	-9223372036854775807	9223372036854775807
+-4.6	4.6	-4.6	4.6
+-4.7	4.7	-4.7	4.7
+4.80	4.80	4.80	4.80
+49	49	49	49
+50	50	50	50
+false	true	false	true
+2019-11-26 20:11:42.501	2019-11-26 20:11:42.501	2019-11-26 20:11:42.501	2019-11-26 20:11:42.501
+2020-01-10	2020-01-10	2020-01-10	2020-01-10
+
+query IIIIIIIIIIII
+SELECT * FROM 'data/parquet-testing/data-types.parquet'
+----
+NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL
+42	43	44	45	4.600000	4.700000	4.80	49	50	True	2019-11-26 20:11:42.501	2020-01-10
+-127	-32767	-2147483647	-9223372036854775807	-4.600000	-4.700000	NULL	NULL	NULL	False	NULL	NULL
+127	32767	2147483647	9223372036854775807	NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL
+NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL
+
+# parquet stats for all parquet files
+foreach parquet_file data/parquet-testing/manyrowgroups.parquet data/parquet-testing/map.parquet data/parquet-testing/arrow/int32_decimal.parquet data/parquet-testing/arrow/nonnullable.impala.parquet data/parquet-testing/bug687_nulls.parquet data/parquet-testing/bug1554.parquet data/parquet-testing/apkwan.parquet data/parquet-testing/arrow/nested_lists.snappy.parquet data/parquet-testing/arrow/nulls.snappy.parquet data/parquet-testing/nan-float.parquet data/parquet-testing/manyrowgroups2.parquet data/parquet-testing/struct.parquet data/parquet-testing/arrow/list_columns.parquet data/parquet-testing/timestamp-ms.parquet data/parquet-testing/arrow/alltypes_dictionary.parquet data/parquet-testing/arrow/binary.parquet data/parquet-testing/arrow/nation.dict-malformed.parquet data/parquet-testing/lineitem-top10000.gzip.parquet data/parquet-testing/arrow/nested_maps.snappy.parquet data/parquet-testing/arrow/dict-page-offset-zero.parquet data/parquet-testing/silly-names.parquet data/parquet-testing/zstd.parquet data/parquet-testing/bug1618_struct_strings.parquet data/parquet-testing/arrow/single_nan.parquet data/parquet-testing/arrow/int64_decimal.parquet data/parquet-testing/filter_bug1391.parquet data/parquet-testing/arrow/fixed_length_decimal_legacy.parquet data/parquet-testing/timestamp.parquet data/parquet-testing/arrow/fixed_length_decimal.parquet data/parquet-testing/leftdate3_192_loop_1.parquet data/parquet-testing/blob.parquet data/parquet-testing/bug1588.parquet data/parquet-testing/bug1589.parquet data/parquet-testing/arrow/alltypes_plain.parquet data/parquet-testing/arrow/repeated_no_annotation.parquet data/parquet-testing/data-types.parquet data/parquet-testing/unsigned.parquet data/parquet-testing/pandas-date.parquet data/parquet-testing/date.parquet data/parquet-testing/arrow/nullable.impala.parquet data/parquet-testing/fixed.parquet data/parquet-testing/arrow/alltypes_plain.snappy.parquet data/parquet-testing/decimal/int32_decimal.parquet data/parquet-testing/decimal/pandas_decimal.parquet data/parquet-testing/decimal/decimal_dc.parquet data/parquet-testing/decimal/int64_decimal.parquet data/parquet-testing/decimal/fixed_length_decimal_legacy.parquet data/parquet-testing/decimal/fixed_length_decimal.parquet data/parquet-testing/glob2/t1.parquet data/parquet-testing/cache/cache1.parquet data/parquet-testing/cache/cache2.parquet data/parquet-testing/glob/t2.parquet data/parquet-testing/glob/t1.parquet data/parquet-testing/bug2557.parquet
+
+statement ok
+select * from parquet_metadata('${parquet_file}');
+
+endloop
diff --git a/test/sql/copy/parquet/writer/parquet_test_all_types.test b/test/sql/copy/parquet/writer/parquet_test_all_types.test
new file mode 100644
index 000000000000..38b740a8ed97
--- /dev/null
+++ b/test/sql/copy/parquet/writer/parquet_test_all_types.test
@@ -0,0 +1,36 @@
+# name: test/sql/copy/parquet/writer/parquet_test_all_types.test
+# description: Parquet test_all_types function
+# group: [writer]
+
+require parquet
+
+statement ok
+PRAGMA enable_verification
+
+statement ok
+CREATE TABLE all_types AS
+SELECT * REPLACE (
+	case when extract(month from interval) <> 0 then interval '1 month 1 day 12:13:34.123' else interval end AS interval
+)
+FROM test_all_types();
+
+statement ok
+COPY all_types TO '__TEST_DIR__/all_types.parquet' (FORMAT PARQUET);
+
+# we have to make some replacements to get result equivalence
+# hugeint is stored as double -> we have to cast
+# datetz/timetz/timestamptz lose their tz qualifier -> cast to the non-tz type
+# intervals are saved with ms precision -> truncate microsecond precision to milisecond
+query I nosort alltypes
+SELECT * REPLACE (
+	hugeint::DOUBLE AS hugeint,
+	date_tz::DATE AS date_tz,
+	time_tz::TIME AS time_tz,
+	timestamp_tz::TIMESTAMP AS timestamp_tz
+)
+FROM all_types
+----
+
+query I nosort alltypes
+SELECT * FROM '__TEST_DIR__/all_types.parquet'
+----
diff --git a/test/sql/copy/parquet/writer/parquet_write_decimals.test b/test/sql/copy/parquet/writer/parquet_write_decimals.test
new file mode 100644
index 000000000000..b78f3a9918b3
--- /dev/null
+++ b/test/sql/copy/parquet/writer/parquet_write_decimals.test
@@ -0,0 +1,87 @@
+# name: test/sql/copy/parquet/writer/parquet_write_decimals.test
+# description: Parquet decimal types round trip
+# group: [writer]
+
+require parquet
+
+statement ok
+PRAGMA enable_verification
+
+statement ok
+CREATE TABLE decimals(
+	dec4 DECIMAL(4,1),
+	dec9 DECIMAL(9,2),
+	dec18 DECIMAL(18,3),
+	dec38 DECIMAL(38,4)
+);
+
+statement ok
+INSERT INTO decimals VALUES (
+	-999.9,
+	-9999999.99,
+	-999999999999999.999,
+	-999999999999999999999999999999999.9999
+), (
+	NULL, NULL, NULL, NULL
+), (
+ 	42, 42, 42, 42
+), (
+ 	-42, -42, -42, -42
+), (
+  	0, 0, 0, 0
+ ), (
+  	999.9,
+  	9999999.99,
+  	999999999999999.999,
+  	999999999999999999999999999999999.9999
+);
+
+statement ok
+COPY decimals TO '__TEST_DIR__/decimals.parquet';
+
+query IIII nosort decimal_scan
+SELECT * FROM decimals;
+
+query IIII nosort decimal_scan
+SELECT * FROM '__TEST_DIR__/decimals.parquet';
+
+query IIII
+SELECT stats_min, stats_max, stats_min_value, stats_max_value FROM parquet_metadata('__TEST_DIR__/decimals.parquet');
+----
+-999.9	999.9	-999.9	999.9
+-9999999.99	9999999.99	-9999999.99	9999999.99
+-999999999999999.999	999999999999999.999	-999999999999999.999	999999999999999.999
+-999999999999999999999999999999999.9999	999999999999999999999999999999999.9999	-999999999999999999999999999999999.9999	999999999999999999999999999999999.9999
+
+# filter pushdown
+statement ok
+DELETE FROM decimals WHERE dec4<-42 OR dec4>42
+
+statement ok
+COPY decimals TO '__TEST_DIR__/decimals.parquet';
+
+foreach dec_column dec4 dec9 dec18 dec38
+
+query IIII
+SELECT * FROM '__TEST_DIR__/decimals.parquet' WHERE ${dec_column}=42
+----
+42	42	42	42
+
+query IIII
+SELECT * FROM '__TEST_DIR__/decimals.parquet' WHERE ${dec_column}=-43
+----
+
+query IIII
+SELECT * FROM '__TEST_DIR__/decimals.parquet' WHERE ${dec_column}=43
+----
+
+endloop
+
+# check statistics
+statement ok
+PRAGMA disable_verification
+
+query IIII
+SELECT stats(dec4), stats(dec9), stats(dec18), stats(dec38) FROM '__TEST_DIR__/decimals.parquet' LIMIT 1
+----
+[Min: -42.0, Max: 42.0][Has Null: true]	[Min: -42.00, Max: 42.00][Has Null: true]	[Min: -42.000, Max: 42.000][Has Null: true]	[Min: -42.0000, Max: 42.0000][Has Null: true]
diff --git a/test/sql/copy/parquet/writer/parquet_write_enums.test b/test/sql/copy/parquet/writer/parquet_write_enums.test
new file mode 100644
index 000000000000..8374f92be571
--- /dev/null
+++ b/test/sql/copy/parquet/writer/parquet_write_enums.test
@@ -0,0 +1,141 @@
+# name: test/sql/copy/parquet/writer/parquet_write_enums.test
+# description: ENUM tests
+# group: [writer]
+
+require parquet
+
+statement ok
+PRAGMA enable_verification
+
+# standard enum
+statement ok
+CREATE TYPE mood AS ENUM ('joy', 'ok', 'happy');
+
+statement ok
+CREATE TABLE enums(m mood);
+
+statement ok
+INSERT INTO enums VALUES
+	('happy'), ('happy'), ('joy'), ('joy'),
+	('happy'), ('happy'), ('joy'), ('joy'),
+    ('happy'), ('happy'), ('joy'), ('joy'),
+    ('happy'), ('happy'), ('joy'), ('joy'),
+    ('happy'), ('happy'), ('joy'), ('joy'),
+    ('happy'), ('happy'), ('joy'), ('joy'),
+    ('happy'), ('happy'), ('joy'), ('joy'), ('joy')
+
+statement ok
+COPY enums TO '__TEST_DIR__/enums.parquet' (FORMAT PARQUET);
+
+query I
+SELECT * FROM '__TEST_DIR__/enums.parquet'
+----
+happy
+happy
+joy
+joy
+happy
+happy
+joy
+joy
+happy
+happy
+joy
+joy
+happy
+happy
+joy
+joy
+happy
+happy
+joy
+joy
+happy
+happy
+joy
+joy
+happy
+happy
+joy
+joy
+joy
+
+# enum with null values
+statement ok
+UPDATE enums SET m=NULL WHERE m='joy'
+
+statement ok
+COPY enums TO '__TEST_DIR__/enums.parquet' (FORMAT PARQUET);
+
+query I
+SELECT * FROM '__TEST_DIR__/enums.parquet'
+----
+happy
+happy
+NULL
+NULL
+happy
+happy
+NULL
+NULL
+happy
+happy
+NULL
+NULL
+happy
+happy
+NULL
+NULL
+happy
+happy
+NULL
+NULL
+happy
+happy
+NULL
+NULL
+happy
+happy
+NULL
+NULL
+NULL
+
+# all values are null
+statement ok
+UPDATE enums SET m=NULL
+
+statement ok
+COPY enums TO '__TEST_DIR__/enums.parquet' (FORMAT PARQUET);
+
+query I
+SELECT * FROM '__TEST_DIR__/enums.parquet'
+----
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
diff --git a/test/sql/copy/parquet/writer/parquet_write_interval.test b/test/sql/copy/parquet/writer/parquet_write_interval.test
new file mode 100644
index 000000000000..85d7b171ce9e
--- /dev/null
+++ b/test/sql/copy/parquet/writer/parquet_write_interval.test
@@ -0,0 +1,34 @@
+# name: test/sql/copy/parquet/writer/parquet_write_interval.test
+# description: Parquet interval round trip
+# group: [writer]
+
+require parquet
+
+statement ok
+PRAGMA enable_verification
+
+statement ok
+CREATE TABLE IF NOT EXISTS intervals (i interval);
+
+statement ok
+INSERT INTO intervals VALUES
+       (interval '1' day),
+       (interval '00:00:01'),
+       (NULL),
+       (interval '0' month),
+       (interval '1' month)
+
+statement ok
+COPY intervals TO '__TEST_DIR__/intervals.parquet'
+
+query I
+SELECT * FROM '__TEST_DIR__/intervals.parquet' ORDER BY 1
+----
+NULL
+00:00:00
+00:00:01
+1 day
+1 month
+
+statement error
+COPY (SELECT -interval '1 day') TO '__TEST_DIR__/intervals.parquet'
diff --git a/test/sql/copy/parquet/writer/parquet_write_tpcds.test_slow b/test/sql/copy/parquet/writer/parquet_write_tpcds.test_slow
new file mode 100644
index 000000000000..4d1a70496f58
--- /dev/null
+++ b/test/sql/copy/parquet/writer/parquet_write_tpcds.test_slow
@@ -0,0 +1,67 @@
+# name: test/sql/copy/parquet/writer/parquet_write_tpcds.test_slow
+# description: Parquet TPC-DS tests
+# group: [writer]
+
+require parquet
+
+require tpcds
+
+# answers are generated from postgres
+# hence check with NULLS LAST flag
+statement ok
+PRAGMA default_null_order='NULLS LAST'
+
+statement ok
+CREATE SCHEMA tpcds;
+
+statement ok
+CALL dsdgen(sf=1, schema='tpcds');
+
+foreach tbl call_center catalog_page catalog_returns catalog_sales customer customer_demographics customer_address date_dim household_demographics inventory income_band item promotion reason ship_mode store store_returns store_sales time_dim warehouse web_page web_returns web_sales web_site
+
+statement ok
+COPY tpcds.${tbl} TO '__TEST_DIR__/${tbl}.parquet' (FORMAT 'PARQUET', COMPRESSION 'ZSTD');
+
+statement ok
+CREATE VIEW ${tbl} AS SELECT * FROM parquet_scan('__TEST_DIR__/${tbl}.parquet');
+
+endloop
+
+# too slow queries:
+# 64, 85
+
+loop i 1 9
+
+query I
+PRAGMA tpcds(${i})
+----
+<FILE>:extension/tpcds/dsdgen/answers/sf1/0${i}.csv
+
+endloop
+
+loop i 10 64
+
+query I
+PRAGMA tpcds(${i})
+----
+<FILE>:extension/tpcds/dsdgen/answers/sf1/${i}.csv
+
+endloop
+
+loop i 65 85
+
+query I
+PRAGMA tpcds(${i})
+----
+<FILE>:extension/tpcds/dsdgen/answers/sf1/${i}.csv
+
+endloop
+
+loop i 86 99
+
+query I
+PRAGMA tpcds(${i})
+----
+<FILE>:extension/tpcds/dsdgen/answers/sf1/${i}.csv
+
+endloop
diff --git a/test/sql/copy/parquet/writer/parquet_write_tpch.test_slow b/test/sql/copy/parquet/writer/parquet_write_tpch.test_slow
index 3fdbd92e8a26..02b69dc96d82 100644
--- a/test/sql/copy/parquet/writer/parquet_write_tpch.test_slow
+++ b/test/sql/copy/parquet/writer/parquet_write_tpch.test_slow
@@ -31,18 +31,7 @@ PRAGMA tpch(${i})
 
 endloop
 
-# skip q15 for now: it is non-deterministic with multi-threading and doubles
-# this can be re-enabled once we write decimals to parquet
-loop i 10 15
-
-query I
-PRAGMA tpch(${i})
-----
-<FILE>:extension/tpch/dbgen/answers/sf1/q${i}.csv
-
-endloop
-
-loop i 16 23
+loop i 10 23
 
 query I
 PRAGMA tpch(${i})
diff --git a/test/sql/copy/parquet/writer/parquet_write_uuid.test b/test/sql/copy/parquet/writer/parquet_write_uuid.test
new file mode 100644
index 000000000000..88efd0a12ea2
--- /dev/null
+++ b/test/sql/copy/parquet/writer/parquet_write_uuid.test
@@ -0,0 +1,63 @@
+# name: test/sql/copy/parquet/writer/parquet_write_uuid.test
+# description: Parquet UUID round trip
+# group: [writer]
+
+require parquet
+
+statement ok
+PRAGMA enable_verification
+
+statement ok
+CREATE TABLE IF NOT EXISTS uuid (u uuid);
+
+statement ok
+INSERT INTO uuid VALUES
+       ('A0EEBC99-9C0B-4EF8-BB6D-6BB9BD380A11'),
+       (NULL),
+       ('47183823-2574-4bfd-b411-99ed177d3e43'),
+       ('{10203040506070800102030405060708}'),
+       ('A0EEBC99-9C0B-4EF8-BB6D-6BB9BD380A11'),
+       (NULL),
+       ('00112233-4455-6677-8899-aabbccddeeff'),
+       ('47183823-2574-4bfd-b411-99ed177d3e43'),
+       ('{10203040506070800102030405060708}'),
+       ('00000000-0000-0000-0000-000000000000'),
+       ('00000000-0000-0000-0000-000000000001'),
+       ('00000000-0000-0000-8000-000000000001'),
+       ('80000000-0000-0000-0000-000000000000'),
+       ('80000000-0000-0000-8000-000000000000'),
+       ('80000000-0000-0000-8fff-ffffffffffff'),
+       ('80000000-0000-0000-ffff-ffffffffffff'),
+       ('8fffffff-ffff-ffff-0000-000000000000'),
+       ('8fffffff-ffff-ffff-8000-000000000000'),
+       ('8fffffff-ffff-ffff-8fff-ffffffffffff'),
+       ('8fffffff-ffff-ffff-ffff-ffffffffffff'),
+       ('ffffffff-ffff-ffff-ffff-ffffffffffff');
+
+statement ok
+COPY uuid TO '__TEST_DIR__/uuid.parquet'
+
+query I
+SELECT * FROM '__TEST_DIR__/uuid.parquet' ORDER BY 1
+----
+NULL
+NULL
+00000000-0000-0000-0000-000000000000
+00000000-0000-0000-0000-000000000001
+00000000-0000-0000-8000-000000000001
+00112233-4455-6677-8899-aabbccddeeff
+10203040-5060-7080-0102-030405060708
+10203040-5060-7080-0102-030405060708
+47183823-2574-4bfd-b411-99ed177d3e43
+47183823-2574-4bfd-b411-99ed177d3e43
+80000000-0000-0000-0000-000000000000
+80000000-0000-0000-8000-000000000000
+80000000-0000-0000-8fff-ffffffffffff
+80000000-0000-0000-ffff-ffffffffffff
+8fffffff-ffff-ffff-0000-000000000000
+8fffffff-ffff-ffff-8000-000000000000
+8fffffff-ffff-ffff-8fff-ffffffffffff
+8fffffff-ffff-ffff-ffff-ffffffffffff
+a0eebc99-9c0b-4ef8-bb6d-6bb9bd380a11
+a0eebc99-9c0b-4ef8-bb6d-6bb9bd380a11
+ffffffff-ffff-ffff-ffff-ffffffffffff
diff --git a/test/sql/copy/parquet/writer/write_stats_big_string.test b/test/sql/copy/parquet/writer/write_stats_big_string.test
new file mode 100644
index 000000000000..9916c24e56aa
--- /dev/null
+++ b/test/sql/copy/parquet/writer/write_stats_big_string.test
@@ -0,0 +1,35 @@
+# name: test/sql/copy/parquet/writer/write_stats_big_string.test
+# description: We avoid writing min/max stats of large strings
+# group: [writer]
+
+require parquet
+
+statement ok
+PRAGMA enable_verification;
+
+statement ok
+CREATE TABLE varchar(v VARCHAR);
+
+statement ok
+INSERT INTO varchar VALUES (NULL), ('hello'), (NULL), ('world'), (NULL)
+
+# we write stats when there are only small strings
+statement ok
+COPY varchar TO '__TEST_DIR__/bigvarchar.parquet'
+
+query IIII
+SELECT stats_min_value, stats_max_value, stats_min, stats_max FROM parquet_metadata('__TEST_DIR__/bigvarchar.parquet')
+----
+hello	world	hello	world
+
+# we stop writing stats when we encounter a very large string
+statement ok
+INSERT INTO varchar SELECT repeat('A', 100000) v
+
+statement ok
+COPY varchar TO '__TEST_DIR__/bigvarchar.parquet'
+
+query IIII
+SELECT stats_min_value, stats_max_value, stats_min, stats_max FROM parquet_metadata('__TEST_DIR__/bigvarchar.parquet')
+----
+NULL	NULL	NULL	NULL
\ No newline at end of file
diff --git a/test/sql/copy/parquet/writer/write_stats_min_max.test b/test/sql/copy/parquet/writer/write_stats_min_max.test
new file mode 100644
index 000000000000..668ef65e4d5c
--- /dev/null
+++ b/test/sql/copy/parquet/writer/write_stats_min_max.test
@@ -0,0 +1,226 @@
+# name: test/sql/copy/parquet/writer/write_stats_min_max.test
+# description: Write min/max stats to Parquet files
+# group: [writer]
+
+require parquet
+
+statement ok
+PRAGMA enable_verification;
+
+statement ok
+PRAGMA explain_output = OPTIMIZED_ONLY;
+
+statement ok
+CREATE TABLE boolean_limits AS SELECT (false)::BOOLEAN min, true::BOOLEAN max
+
+statement ok
+CREATE TABLE tinyint_limits AS SELECT (-128)::TINYINT min, 127::TINYINT max
+
+statement ok
+CREATE TABLE smallint_limits AS SELECT (-32768)::SMALLINT min, 32767::SMALLINT max
+
+statement ok
+CREATE TABLE integer_limits AS SELECT (-2147483648)::INTEGER min, 2147483647::INTEGER max
+
+statement ok
+CREATE TABLE bigint_limits AS SELECT (-9223372036854775808)::BIGINT min, 9223372036854775807::BIGINT max
+
+statement ok
+CREATE TABLE float_limits AS SELECT (-0.5)::FLOAT min, 0.5::FLOAT max
+
+statement ok
+CREATE TABLE double_limits AS SELECT (-0.5)::DOUBLE min, 0.5::DOUBLE max
+
+statement ok
+CREATE TABLE varchar_limits AS SELECT 'hello world üë§üè†üìï' min, 'look at my ducks ü¶Üü¶Üü¶Ü' max;
+
+statement ok
+CREATE TABLE blob_limits AS SELECT blob '\x00hello\x00world\x00' min, blob '\x00look\x00at\x00my\x00nullbytes\x00' max;
+
+statement ok
+CREATE TABLE date_limits AS SELECT date '1900-01-01' min, date '2030-12-31' max;
+
+statement ok
+CREATE TABLE time_limits AS SELECT time '00:00:00' min, time '23:59:59' max;
+
+statement ok
+CREATE TABLE timestamp_limits AS SELECT timestamp '1900-01-01 00:00:00' min, timestamp '2030-12-31 23:59:59' max;
+
+statement ok
+CREATE TABLE timestamp_s_limits AS SELECT '1900-01-01 00:00:00'::timestamp_s min, '2030-12-31 23:59:59'::timestamp_s max;
+
+statement ok
+CREATE TABLE timestamp_ms_limits AS SELECT '1900-01-01 00:00:00'::timestamp_ms min, '2030-12-31 23:59:59'::timestamp_ms max;
+
+statement ok
+CREATE TABLE timestamp_ns_limits AS SELECT '1900-01-01 00:00:00'::timestamp_ns min, '2030-12-31 23:59:59'::timestamp_ns max;
+
+# min/max/min_value/max_value for signed tables
+foreach type date time timestamp timestamp_s timestamp_ms timestamp_ns varchar blob boolean tinyint smallint integer bigint float double
+
+statement ok
+CREATE TABLE tbl(i ${type});
+
+# empty stats (all values are NULL)
+statement ok
+INSERT INTO tbl SELECT NULL
+
+statement ok
+COPY tbl TO '__TEST_DIR__/${type}_stats.parquet.parquet' (FORMAT PARQUET);
+
+query IIII
+SELECT stats_min_value::${type}, stats_max_value::${type}, stats_min::${type}, stats_max::${type} FROM parquet_metadata('__TEST_DIR__/${type}_stats.parquet.parquet')
+----
+NULL	NULL	NULL	NULL
+
+# min/max stats
+statement ok
+INSERT INTO tbl SELECT min FROM ${type}_limits
+
+statement ok
+INSERT INTO tbl SELECT max FROM ${type}_limits
+
+statement ok
+COPY tbl TO '__TEST_DIR__/${type}_stats.parquet.parquet' (FORMAT PARQUET);
+
+query I
+SELECT stats_min_value::${type} FROM parquet_metadata('__TEST_DIR__/${type}_stats.parquet.parquet') EXCEPT SELECT min FROM ${type}_limits
+----
+
+query I
+SELECT stats_max_value::${type} FROM parquet_metadata('__TEST_DIR__/${type}_stats.parquet.parquet') EXCEPT SELECT max FROM ${type}_limits
+----
+
+query I
+SELECT stats_min::${type} FROM parquet_metadata('__TEST_DIR__/${type}_stats.parquet.parquet') EXCEPT SELECT min FROM ${type}_limits
+----
+
+query I
+SELECT stats_max::${type} FROM parquet_metadata('__TEST_DIR__/${type}_stats.parquet.parquet') EXCEPT SELECT max FROM ${type}_limits
+----
+
+statement ok
+DROP TABLE tbl
+
+endloop
+
+statement ok
+CREATE TABLE utinyint_limits AS SELECT (0)::UTINYINT min, 255::UTINYINT max
+
+statement ok
+CREATE TABLE usmallint_limits AS SELECT (0)::USMALLINT min, 65535::USMALLINT max
+
+statement ok
+CREATE TABLE uinteger_limits AS SELECT 0::UINTEGER min, 4294967295::UINTEGER max
+
+statement ok
+CREATE TABLE ubigint_limits AS SELECT 0::UBIGINT min, 18446744073709551615::UBIGINT max
+
+# unsigned types only define min_value/max_value
+foreach type utinyint usmallint uinteger ubigint
+
+statement ok
+CREATE TABLE tbl(i ${type});
+
+# empty stats (all values are NULL)
+statement ok
+INSERT INTO tbl SELECT NULL
+
+statement ok
+COPY tbl TO '__TEST_DIR__/${type}_stats.parquet.parquet' (FORMAT PARQUET);
+
+query I
+SELECT stats_min_value::${type} FROM parquet_metadata('__TEST_DIR__/${type}_stats.parquet.parquet')
+----
+NULL
+
+query I
+SELECT stats_max_value::${type} FROM parquet_metadata('__TEST_DIR__/${type}_stats.parquet.parquet')
+----
+NULL
+
+query I
+SELECT stats_min::${type} FROM parquet_metadata('__TEST_DIR__/${type}_stats.parquet.parquet')
+----
+NULL
+
+query I
+SELECT stats_max::${type} FROM parquet_metadata('__TEST_DIR__/${type}_stats.parquet.parquet')
+----
+NULL
+
+# min/max stats
+statement ok
+INSERT INTO tbl SELECT min FROM ${type}_limits
+
+statement ok
+INSERT INTO tbl SELECT max FROM ${type}_limits
+
+statement ok
+COPY tbl TO '__TEST_DIR__/${type}_stats.parquet.parquet' (FORMAT PARQUET);
+
+query I
+SELECT stats_min_value::${type} FROM parquet_metadata('__TEST_DIR__/${type}_stats.parquet.parquet') EXCEPT SELECT min FROM ${type}_limits
+----
+
+query I
+SELECT stats_max_value::${type} FROM parquet_metadata('__TEST_DIR__/${type}_stats.parquet.parquet') EXCEPT SELECT max FROM ${type}_limits
+----
+
+query I
+SELECT stats_min::${type} FROM parquet_metadata('__TEST_DIR__/${type}_stats.parquet.parquet')
+----
+NULL
+
+query I
+SELECT stats_max::${type} FROM parquet_metadata('__TEST_DIR__/${type}_stats.parquet.parquet')
+----
+NULL
+
+statement ok
+DROP TABLE tbl
+
+endloop
+
+# no stats for these types
+statement ok
+CREATE TABLE hugeint_limits AS SELECT (-170141183460469231731687303715884105727)::HUGEINT min, 170141183460469231731687303715884105727::HUGEINT max
+
+foreach type hugeint
+
+statement ok
+CREATE TABLE tbl(i ${type});
+
+statement ok
+INSERT INTO tbl SELECT min FROM ${type}_limits
+
+statement ok
+INSERT INTO tbl SELECT max FROM ${type}_limits
+
+statement ok
+COPY tbl TO '__TEST_DIR__/${type}_stats.parquet.parquet' (FORMAT PARQUET);
+
+query I
+SELECT stats_min_value::${type} FROM parquet_metadata('__TEST_DIR__/${type}_stats.parquet.parquet')
+----
+NULL
+
+query I
+SELECT stats_max_value::${type} FROM parquet_metadata('__TEST_DIR__/${type}_stats.parquet.parquet')
+----
+NULL
+
+query I
+SELECT stats_min::${type} FROM parquet_metadata('__TEST_DIR__/${type}_stats.parquet.parquet')
+----
+NULL
+
+query I
+SELECT stats_max::${type} FROM parquet_metadata('__TEST_DIR__/${type}_stats.parquet.parquet')
+----
+NULL
+
+statement ok
+DROP TABLE tbl
+
+endloop
\ No newline at end of file
diff --git a/test/sql/copy/parquet/writer/write_stats_null_count.test b/test/sql/copy/parquet/writer/write_stats_null_count.test
new file mode 100644
index 000000000000..2c3006fb536c
--- /dev/null
+++ b/test/sql/copy/parquet/writer/write_stats_null_count.test
@@ -0,0 +1,82 @@
+# name: test/sql/copy/parquet/writer/write_stats_null_count.test
+# description: Write null_count stats to Parquet files
+# group: [writer]
+
+require parquet
+
+statement ok
+PRAGMA enable_verification;
+
+statement ok
+PRAGMA explain_output = OPTIMIZED_ONLY;
+
+# null count
+statement ok
+COPY (SELECT 42 i) TO '__TEST_DIR__/stats.parquet' (FORMAT PARQUET);
+
+query I
+SELECT stats_null_count FROM parquet_metadata('__TEST_DIR__/stats.parquet')
+----
+0
+
+# we can filter out the IS NULL clause
+query II
+EXPLAIN SELECT COUNT(*) FROM '__TEST_DIR__/stats.parquet' WHERE i IS NULL
+----
+logical_opt	<!REGEX>:.*IS_NULL.*
+
+query I
+SELECT COUNT(*) FROM '__TEST_DIR__/stats.parquet' WHERE i IS NULL
+----
+0
+
+statement ok
+COPY (SELECT NULL i) TO '__TEST_DIR__/stats.parquet' (FORMAT PARQUET);
+
+query I
+SELECT stats_null_count FROM parquet_metadata('__TEST_DIR__/stats.parquet')
+----
+1
+
+# we cannot filter out the IS NULL clause
+query II
+EXPLAIN SELECT COUNT(*) FROM '__TEST_DIR__/stats.parquet' WHERE i IS NULL
+----
+logical_opt	<REGEX>:.*IS_NULL.*
+
+query I
+SELECT COUNT(*) FROM '__TEST_DIR__/stats.parquet' WHERE i IS NULL
+----
+1
+
+# list null count not supported (i.e. we don't write the null count in this case)
+statement ok
+COPY (SELECT [42, NULL, 43] i) TO '__TEST_DIR__/stats.parquet' (FORMAT PARQUET);
+
+query I
+SELECT stats_null_count FROM parquet_metadata('__TEST_DIR__/stats.parquet')
+----
+NULL
+
+statement ok
+COPY (SELECT {'a': NULL, 'b': 42} i) TO '__TEST_DIR__/stats.parquet' (FORMAT PARQUET);
+
+query I
+SELECT stats_null_count FROM parquet_metadata('__TEST_DIR__/stats.parquet')
+----
+1
+0
+
+# struct null count is propagated to the children
+# i.e. if a struct itself is null, this counts as NULL for the children
+statement ok
+CREATE TABLE structs AS SELECT {'a': NULL, 'b': 'hello'} i UNION ALL SELECT NULL UNION ALL SELECT {'a': 84, 'b': 'world'};
+
+statement ok
+COPY structs TO 'stats.parquet' (FORMAT PARQUET);
+
+query I
+SELECT stats_null_count FROM parquet_metadata('stats.parquet')
+----
+2
+1
diff --git a/test/sql/function/uuid/test_uuid.test b/test/sql/function/uuid/test_uuid.test
index 38775e7fa7ce..f40820aff92b 100644
--- a/test/sql/function/uuid/test_uuid.test
+++ b/test/sql/function/uuid/test_uuid.test
@@ -9,7 +9,7 @@ statement ok
 CREATE TEMPORARY TABLE t1 AS SELECT gen_random_uuid() a FROM range(0, 16);
 
 statement ok
-CREATE TEMPORARY TABLE t2 AS SELECT gen_random_uuid() b FROM range(0, 16);
+CREATE TEMPORARY TABLE t2 AS SELECT uuid() b FROM range(0, 16);
 
 statement ok
 CREATE TEMPORARY TABLE t3 AS SELECT gen_random_uuid() c FROM range(0, 16);
