{
  "repo": "duckdb/duckdb",
  "pull_number": 11948,
  "instance_id": "duckdb__duckdb-11948",
  "issue_numbers": [
    "11886"
  ],
  "base_commit": "7b5c71b279d4af5dc9832af5309e3bcb45cee5a4",
  "patch": "diff --git a/extension/json/json_functions/json_structure.cpp b/extension/json/json_functions/json_structure.cpp\nindex 0fd574f898e0..e6fb3456e583 100644\n--- a/extension/json/json_functions/json_structure.cpp\n+++ b/extension/json/json_functions/json_structure.cpp\n@@ -388,22 +388,28 @@ static inline void ExtractStructureObject(yyjson_val *obj, JSONStructureNode &no\n \tauto &description = node.GetOrCreateDescription(LogicalTypeId::STRUCT);\n \n \t// Keep track of keys so we can detect duplicates\n-\tcase_insensitive_set_t obj_keys;\n+\tunordered_set<string> obj_keys;\n+\tcase_insensitive_set_t ci_obj_keys;\n \n \tsize_t idx, max;\n \tyyjson_val *key, *val;\n \tyyjson_obj_foreach(obj, idx, max, key, val) {\n-\t\tauto key_ptr = unsafe_yyjson_get_str(key);\n-\t\tauto key_len = unsafe_yyjson_get_len(key);\n-\t\tauto insert_result = obj_keys.insert(string(key_ptr, key_len));\n-\t\tif (!ignore_errors && !insert_result.second) {\n-\t\t\tJSONCommon::ThrowValFormatError(\"Duplicate key \\\"\" + string(key_ptr, key_len) + \"\\\" in object %s\", obj);\n+\t\tconst string obj_key(unsafe_yyjson_get_str(key), unsafe_yyjson_get_len(key));\n+\t\tauto insert_result = obj_keys.insert(obj_key);\n+\t\tif (!ignore_errors && !insert_result.second) { // Exact match\n+\t\t\tJSONCommon::ThrowValFormatError(\"Duplicate key \\\"\" + obj_key + \"\\\" in object %s\", obj);\n+\t\t}\n+\t\tinsert_result = ci_obj_keys.insert(obj_key);\n+\t\tif (!ignore_errors && !insert_result.second) { // Case-insensitive match\n+\t\t\tJSONCommon::ThrowValFormatError(\"Duplicate key (different case) \\\"\" + obj_key + \"\\\" and \\\"\" +\n+\t\t\t                                    *insert_result.first + \"\\\" in object %s\",\n+\t\t\t                                obj);\n \t\t}\n \t\tdescription.GetOrCreateChild(key, val, ignore_errors);\n \t}\n }\n \n-static inline void ExtractStructureVal(yyjson_val *val, JSONStructureNode &node, const bool ignore_errors) {\n+static inline void ExtractStructureVal(yyjson_val *val, JSONStructureNode &node) {\n \tD_ASSERT(!yyjson_is_arr(val) && !yyjson_is_obj(val));\n \tnode.GetOrCreateDescription(JSONCommon::ValTypeToLogicalTypeId(val));\n }\n@@ -416,7 +422,7 @@ void JSONStructure::ExtractStructure(yyjson_val *val, JSONStructureNode &node, c\n \tcase YYJSON_TYPE_OBJ | YYJSON_SUBTYPE_NONE:\n \t\treturn ExtractStructureObject(val, node, ignore_errors);\n \tdefault:\n-\t\treturn ExtractStructureVal(val, node, ignore_errors);\n+\t\treturn ExtractStructureVal(val, node);\n \t}\n }\n \n@@ -475,9 +481,9 @@ static inline yyjson_mut_val *ConvertStructure(const JSONStructureNode &node, yy\n \t}\n }\n \n-static inline string_t JSONStructureFunction(yyjson_val *val, yyjson_alc *alc, Vector &result) {\n+static inline string_t JSONStructureFunction(yyjson_val *val, yyjson_alc *alc, Vector &) {\n \treturn JSONCommon::WriteVal<yyjson_mut_val>(\n-\t    ConvertStructure(ExtractStructureInternal(val, false), yyjson_mut_doc_new(alc)), alc);\n+\t    ConvertStructure(ExtractStructureInternal(val, true), yyjson_mut_doc_new(alc)), alc);\n }\n \n static void StructureFunction(DataChunk &args, ExpressionState &state, Vector &result) {\n@@ -497,8 +503,7 @@ ScalarFunctionSet JSONFunctions::GetStructureFunction() {\n }\n \n static LogicalType StructureToTypeArray(ClientContext &context, const JSONStructureNode &node, const idx_t max_depth,\n-                                        const double field_appearance_threshold, idx_t depth,\n-                                        const idx_t sample_count) {\n+                                        const double field_appearance_threshold, idx_t depth) {\n \tD_ASSERT(node.descriptions.size() == 1 && node.descriptions[0].type == LogicalTypeId::LIST);\n \tconst auto &desc = node.descriptions[0];\n \tD_ASSERT(desc.children.size() == 1);\n@@ -565,7 +570,7 @@ LogicalType JSONStructure::StructureToType(ClientContext &context, const JSONStr\n \tD_ASSERT(desc.type != LogicalTypeId::INVALID);\n \tswitch (desc.type) {\n \tcase LogicalTypeId::LIST:\n-\t\treturn StructureToTypeArray(context, node, max_depth, field_appearance_threshold, depth, sample_count);\n+\t\treturn StructureToTypeArray(context, node, max_depth, field_appearance_threshold, depth);\n \tcase LogicalTypeId::STRUCT:\n \t\treturn StructureToTypeObject(context, node, max_depth, field_appearance_threshold, depth, sample_count);\n \tcase LogicalTypeId::VARCHAR:\n",
  "test_patch": "diff --git a/test/sql/json/scalar/test_json_structure.test b/test/sql/json/scalar/test_json_structure.test\nindex 9997f8e88d7c..9f899a77e913 100644\n--- a/test/sql/json/scalar/test_json_structure.test\n+++ b/test/sql/json/scalar/test_json_structure.test\n@@ -152,10 +152,11 @@ select json_structure('[[1], {\"a\": 1}]')\n ----\n [\"JSON\"]\n \n-# duplicate key\n-statement error\n+# duplicate key, used to throw an error, now the error is ignored\n+query I\n select json_structure('{\"a\": 42, \"a\": 7}')\n ----\n+{\"a\":\"UBIGINT\"}\n \n # from a table\n statement ok\n@@ -177,3 +178,9 @@ select json_structure(j) from test\n NULL\n {\"family\":\"NULL\",\"species\":\"NULL\",\"hair\":\"NULL\",\"coolness\":\"NULL\"}\n {\"family\":\"VARCHAR\",\"species\":[\"VARCHAR\"],\"hair\":\"BOOLEAN\",\"coolness\":\"UBIGINT\"}\n+\n+# issue 11886\n+query I\n+select json_structure('{\"a\": 1, \"A\": 1}');\n+----\n+{\"a\":\"UBIGINT\",\"A\":\"UBIGINT\"}\n",
  "problem_statement": "JSON_GROUP_STRUCTURE is now (incorrectly?) case sensitive\n### What happens?\n\n```\r\nselect json_group_structure(json('{\"a\": 1, \"A\": 1}'));\r\n```\r\n\r\nnow returns\r\n\r\n```\r\nInvalid Input Error: Duplicate key \"A\" in object {\"a\":1,\"A\":1}\r\n```\r\n\r\nThis did not repro with 10.1\n\n### To Reproduce\n\nsee above\n\n### OS:\n\nmac os x, wasm, etc\n\n### DuckDB Version:\n\nv0.10.2\n\n### DuckDB Client:\n\nall\n\n### Full Name:\n\nAnkur Goyal\n\n### Affiliation:\n\nBraintrust\n\n### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.\n\nI have tested with a stable release\n\n### Did you include all relevant data sets for reproducing the issue?\n\nNo - Other reason (please specify in the issue body)\n\n### Did you include all code required to reproduce the issue?\n\n- [X] Yes, I have\n\n### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?\n\n- [X] Yes, I have\n",
  "hints_text": "Hi @ankrgyl, we use the same function to auto-detect the schema in our JSON reader. DuckDB is case-insensitive, and duplicate column names are not allowed in tables/structs, so this behavior is the result of a fix (https://github.com/duckdb/duckdb/pull/11271).\r\n\r\nThe `json_structure` function is just a function that exposes this automatic type detection, so its behavior also changed.\r\n\r\nThere are two options, we can either:\r\n1. Throw the error (like we do now)\r\n2. Ignore the error and return `{\"a\":\"UBIGINT\",\"A\":\"UBIGINT\"}`, but you will not be able to use this as an input to `json_transform` (like before)\r\n\r\nI'd happily receive your input on what you would prefer here. \nThanks for the clarification. In our case, we actually use `json_group_structure` _without_ using `json_transform`. Specifically, we:\r\n\r\n* Call `json_group_structure` to find the distinct set of fields\r\n* Populate a UI dropdown based on those fields\r\n* If the user selects one of the subfields, run a query using `json_extract` (which is case sensitive) to project / group by it\r\n\r\nSo my preference would be option 2. One suggestion could be that `json_transform` could error if you try to use it with something like `{\"a\":\"UBIGINT\",\"A\":\"UBIGINT\"}`, or you could have a flag to `json_group_structure` which allows you to pick your adventure.",
  "created_at": "2024-05-06T08:33:33Z"
}