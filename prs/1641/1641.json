{
  "repo": "duckdb/duckdb",
  "pull_number": 1641,
  "instance_id": "duckdb__duckdb-1641",
  "issue_numbers": [
    "1617"
  ],
  "base_commit": "a5ff22b0a25001e2e60c7fcdb96896d705497d4a",
  "patch": "diff --git a/extension/parquet/column_reader.cpp b/extension/parquet/column_reader.cpp\nindex 2dc0e2cc3d45..32887c099c99 100644\n--- a/extension/parquet/column_reader.cpp\n+++ b/extension/parquet/column_reader.cpp\n@@ -367,7 +367,8 @@ string_t StringParquetValueConversion::DictRead(ByteBuffer &dict, uint32_t &offs\n }\n \n string_t StringParquetValueConversion::PlainRead(ByteBuffer &plain_data, ColumnReader &reader) {\n-\tuint32_t str_len = plain_data.read<uint32_t>();\n+\tauto &scr = ((StringColumnReader &)reader);\n+\tuint32_t str_len = scr.fixed_width_string_length == 0 ? plain_data.read<uint32_t>() : scr.fixed_width_string_length;\n \tplain_data.available(str_len);\n \t((StringColumnReader &)reader).VerifyString(plain_data.ptr, str_len);\n \tauto ret_str = string_t(plain_data.ptr, str_len);\n@@ -376,7 +377,8 @@ string_t StringParquetValueConversion::PlainRead(ByteBuffer &plain_data, ColumnR\n }\n \n void StringParquetValueConversion::PlainSkip(ByteBuffer &plain_data, ColumnReader &reader) {\n-\tuint32_t str_len = plain_data.read<uint32_t>();\n+\tauto &scr = ((StringColumnReader &)reader);\n+\tuint32_t str_len = scr.fixed_width_string_length == 0 ? plain_data.read<uint32_t>() : scr.fixed_width_string_length;\n \tplain_data.available(str_len);\n \tplain_data.inc(str_len);\n }\ndiff --git a/extension/parquet/include/column_reader.hpp b/extension/parquet/include/column_reader.hpp\nindex 8098f1818762..17574d73a754 100644\n--- a/extension/parquet/include/column_reader.hpp\n+++ b/extension/parquet/include/column_reader.hpp\n@@ -25,6 +25,7 @@ using parquet::format::ColumnChunk;\n using parquet::format::FieldRepetitionType;\n using parquet::format::PageHeader;\n using parquet::format::SchemaElement;\n+using parquet::format::Type;\n \n typedef std::bitset<STANDARD_VECTOR_SIZE> parquet_filter_t;\n \n@@ -245,12 +246,19 @@ class StringColumnReader : public TemplatedColumnReader<string_t, StringParquetV\n \tStringColumnReader(LogicalType type_p, const SchemaElement &schema_p, idx_t schema_idx_p, idx_t max_define_p,\n \t                   idx_t max_repeat_p)\n \t    : TemplatedColumnReader<string_t, StringParquetValueConversion>(type_p, schema_p, schema_idx_p, max_define_p,\n-\t                                                                    max_repeat_p) {};\n+\t                                                                    max_repeat_p) {\n+\t\tfixed_width_string_length = 0;\n+\t\tif (schema_p.type == Type::FIXED_LEN_BYTE_ARRAY) {\n+\t\t\tD_ASSERT(schema_p.__isset.type_length);\n+\t\t\tfixed_width_string_length = schema_p.type_length;\n+\t\t}\n+\t};\n \n \tvoid Dictionary(shared_ptr<ByteBuffer> dictionary_data, idx_t num_entries) override;\n \n \tunique_ptr<string_t[]> dict_strings;\n \tvoid VerifyString(const char *str_data, idx_t str_len);\n+\tidx_t fixed_width_string_length;\n \n protected:\n \tvoid DictReference(Vector &result) override;\ndiff --git a/extension/parquet/parquet_reader.cpp b/extension/parquet/parquet_reader.cpp\nindex 9e6872afa166..42b533f398fe 100644\n--- a/extension/parquet/parquet_reader.cpp\n+++ b/extension/parquet/parquet_reader.cpp\n@@ -115,11 +115,19 @@ static LogicalType DeriveLogicalType(const SchemaElement &s_ele) {\n \t\treturn LogicalType::FLOAT;\n \tcase Type::DOUBLE:\n \t\treturn LogicalType::DOUBLE;\n-\t\t//\t\t\tcase parquet::format::Type::FIXED_LEN_BYTE_ARRAY: {\n-\t\t// TODO some decimals yuck\n \tcase Type::BYTE_ARRAY:\n+\tcase Type::FIXED_LEN_BYTE_ARRAY:\n+\t\tif (s_ele.type == Type::FIXED_LEN_BYTE_ARRAY && !s_ele.__isset.type_length) {\n+\t\t\treturn LogicalType::INVALID;\n+\t\t}\n \t\tif (s_ele.__isset.converted_type) {\n \t\t\tswitch (s_ele.converted_type) {\n+\t\t\tcase ConvertedType::DECIMAL:\n+\t\t\t\tif (s_ele.type == Type::FIXED_LEN_BYTE_ARRAY && s_ele.__isset.scale && s_ele.__isset.type_length) {\n+\t\t\t\t\treturn LogicalType(LogicalTypeId::DECIMAL, s_ele.precision, s_ele.scale);\n+\t\t\t\t}\n+\t\t\t\treturn LogicalType::INVALID;\n+\n \t\t\tcase ConvertedType::UTF8:\n \t\t\t\treturn LogicalType::VARCHAR;\n \t\t\tdefault:\n@@ -127,12 +135,6 @@ static LogicalType DeriveLogicalType(const SchemaElement &s_ele) {\n \t\t\t}\n \t\t}\n \t\treturn LogicalType::BLOB;\n-\tcase Type::FIXED_LEN_BYTE_ARRAY:\n-\t\tif (s_ele.__isset.converted_type && s_ele.converted_type == ConvertedType::DECIMAL && s_ele.__isset.scale &&\n-\t\t    s_ele.__isset.scale && s_ele.__isset.type_length) {\n-\t\t\t// habemus decimal\n-\t\t\treturn LogicalType(LogicalTypeId::DECIMAL, s_ele.precision, s_ele.scale);\n-\t\t}\n \tdefault:\n \t\treturn LogicalType::INVALID;\n \t}\n",
  "test_patch": "diff --git a/test/sql/copy/parquet/data/fixed.parquet b/test/sql/copy/parquet/data/fixed.parquet\nnew file mode 100644\nindex 000000000000..b533c0fdcfbd\nBinary files /dev/null and b/test/sql/copy/parquet/data/fixed.parquet differ\ndiff --git a/test/sql/copy/parquet/fixed.test b/test/sql/copy/parquet/fixed.test\nnew file mode 100644\nindex 000000000000..52e62d4ea49c\n--- /dev/null\n+++ b/test/sql/copy/parquet/fixed.test\n@@ -0,0 +1,10 @@\n+# name: test/sql/copy/parquet/fixed.test\n+# description: Strings in fixed length binary arrays\n+# group: [parquet]\n+\n+require parquet\n+\n+query I\n+SELECT data FROM parquet_scan('test/sql/copy/parquet/data/fixed.parquet')\n+----\n+\\x00\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\x09\\x0A\\x0B\\x0C\\x0D\\x0E\\x0F\n",
  "problem_statement": "Support for parquet fixed_len_byte_array columns\nAttempting to read a `fixed_len_byte_array` column from a parquet file yields the very unhelpful error:\r\n\r\n```\r\nError: Not implemented Error: INVALID\r\n```\r\n\r\nReproducer:\r\n```\r\n$ curl -O https://nelhage.com/files/fixed.parquet\r\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n                                 Dload  Upload   Total   Spent    Left  Speed\r\n100   135  100   135    0     0    480      0 --:--:-- --:--:-- --:--:--   480\r\n$ duckdb test.duckdb \"select * from parquet_scan('fixed.parquet');\"\r\nError: Not implemented Error: INVALID\r\n```\r\n\n",
  "hints_text": "What data type are you storing in the FLBA? Strings?\nYes, for my use case I'm storing fixed-length strings\nYes that's something we're happy to add. Just mapping to a `STRING` type in DuckDB is okay, right?\nYeah, that'd work fine. In general I don't know if parquet supports a UTF-8 ConvertedType on FLBA fields, so I'm not sure how you'd decide between `STRING` and `BLOB`, though.\nThis is also an issue for normal strings, because not all parquet files have the ConvertedType \nYour example file also does not set a converted_type, is that intentional?",
  "created_at": "2021-04-19T10:20:05Z"
}