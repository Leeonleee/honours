{
  "repo": "duckdb/duckdb",
  "pull_number": 7300,
  "instance_id": "duckdb__duckdb-7300",
  "issue_numbers": [
    "7176"
  ],
  "base_commit": "43a97f90780a2b534c27540310526013c7deca24",
  "patch": "diff --git a/extension/tpcds/dsdgen/dsdgen_helpers.cpp b/extension/tpcds/dsdgen/dsdgen_helpers.cpp\nindex e24de778d95c..37de51ddec10 100644\n--- a/extension/tpcds/dsdgen/dsdgen_helpers.cpp\n+++ b/extension/tpcds/dsdgen/dsdgen_helpers.cpp\n@@ -18,8 +18,8 @@ void InitializeDSDgen(double scale) {\n \tInitConstants::Reset();\n \tResetCountCount();\n \tstd::string t = std::to_string(scale);\n-\tset_str(\"SCALE\", (char*) t.c_str()); // set SF, which also does a default init (e.g. random seed)\n-\tinit_rand();                 // no random numbers without this\n+\tset_str(\"SCALE\", (char *)t.c_str()); // set SF, which also does a default init (e.g. random seed)\n+\tinit_rand();                         // no random numbers without this\n }\n \n ds_key_t GetRowCount(int table_id) {\ndiff --git a/src/common/radix_partitioning.cpp b/src/common/radix_partitioning.cpp\nindex 18122c6a9131..24be724fa358 100644\n--- a/src/common/radix_partitioning.cpp\n+++ b/src/common/radix_partitioning.cpp\n@@ -9,7 +9,7 @@\n namespace duckdb {\n \n template <class OP, class RETURN_TYPE, typename... ARGS>\n-RETURN_TYPE RadixBitsSwitch(idx_t radix_bits, ARGS &&...args) {\n+RETURN_TYPE RadixBitsSwitch(idx_t radix_bits, ARGS &&... args) {\n \tD_ASSERT(radix_bits <= sizeof(hash_t) * 8);\n \tswitch (radix_bits) {\n \tcase 1:\ndiff --git a/tools/pythonpkg/duckdb_python.cpp b/tools/pythonpkg/duckdb_python.cpp\nindex b26832a451ab..32f26b45975f 100644\n--- a/tools/pythonpkg/duckdb_python.cpp\n+++ b/tools/pythonpkg/duckdb_python.cpp\n@@ -192,7 +192,8 @@ static void InitializeConnectionMethods(py::module_ &m) {\n \t    py::arg(\"all_varchar\") = py::none(), py::arg(\"normalize_names\") = py::none(), py::arg(\"filename\") = py::none());\n \n \tm.def(\"append\", &PyConnectionWrapper::Append, \"Append the passed DataFrame to the named table\",\n-\t      py::arg(\"table_name\"), py::arg(\"df\"), py::arg(\"connection\") = py::none())\n+\t      py::arg(\"table_name\"), py::arg(\"df\"), py::kw_only(), py::arg(\"by_name\") = false,\n+\t      py::arg(\"connection\") = py::none())\n \t    .def(\"register\", &PyConnectionWrapper::RegisterPythonObject,\n \t         \"Register the passed Python Object value for querying with a view\", py::arg(\"view_name\"),\n \t         py::arg(\"python_object\"), py::arg(\"connection\") = py::none())\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/connection_wrapper.hpp b/tools/pythonpkg/src/include/duckdb_python/connection_wrapper.hpp\nindex 0df307d0e55a..c7ae8af4db55 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/connection_wrapper.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/connection_wrapper.hpp\n@@ -44,7 +44,7 @@ class PyConnectionWrapper {\n \t                                           shared_ptr<DuckDBPyConnection> conn = nullptr);\n \tstatic shared_ptr<DuckDBPyType> Type(const string &type_str, shared_ptr<DuckDBPyConnection> conn = nullptr);\n \n-\tstatic shared_ptr<DuckDBPyConnection> Append(const string &name, PandasDataFrame value,\n+\tstatic shared_ptr<DuckDBPyConnection> Append(const string &name, PandasDataFrame value, bool by_name,\n \t                                             shared_ptr<DuckDBPyConnection> conn = nullptr);\n \n \tstatic shared_ptr<DuckDBPyConnection> RegisterPythonObject(const string &name, py::object python_object,\ndiff --git a/tools/pythonpkg/src/include/duckdb_python/pyconnection/pyconnection.hpp b/tools/pythonpkg/src/include/duckdb_python/pyconnection/pyconnection.hpp\nindex aeef324baa32..56e51bc3aade 100644\n--- a/tools/pythonpkg/src/include/duckdb_python/pyconnection/pyconnection.hpp\n+++ b/tools/pythonpkg/src/include/duckdb_python/pyconnection/pyconnection.hpp\n@@ -96,7 +96,7 @@ struct DuckDBPyConnection : public std::enable_shared_from_this<DuckDBPyConnecti\n \n \tshared_ptr<DuckDBPyConnection> Execute(const string &query, py::object params = py::list(), bool many = false);\n \n-\tshared_ptr<DuckDBPyConnection> Append(const string &name, const PandasDataFrame &value);\n+\tshared_ptr<DuckDBPyConnection> Append(const string &name, const PandasDataFrame &value, bool by_name);\n \n \tshared_ptr<DuckDBPyConnection> RegisterPythonObject(const string &name, const py::object &python_object);\n \ndiff --git a/tools/pythonpkg/src/pyconnection.cpp b/tools/pythonpkg/src/pyconnection.cpp\nindex 50fe826e7f51..bf2c96fa6527 100644\n--- a/tools/pythonpkg/src/pyconnection.cpp\n+++ b/tools/pythonpkg/src/pyconnection.cpp\n@@ -163,8 +163,8 @@ static void InitializeConnectionMethods(py::class_<DuckDBPyConnection, shared_pt\n \t    .def(\"begin\", &DuckDBPyConnection::Begin, \"Start a new transaction\")\n \t    .def(\"commit\", &DuckDBPyConnection::Commit, \"Commit changes performed within a transaction\")\n \t    .def(\"rollback\", &DuckDBPyConnection::Rollback, \"Roll back changes performed within a transaction\")\n-\t    .def(\"append\", &DuckDBPyConnection::Append, \"Append the passed Data.Frame to the named table\",\n-\t         py::arg(\"table_name\"), py::arg(\"df\"))\n+\t    .def(\"append\", &DuckDBPyConnection::Append, \"Append the passed DataFrame to the named table\",\n+\t         py::arg(\"table_name\"), py::arg(\"df\"), py::kw_only(), py::arg(\"by_name\") = false)\n \t    .def(\"register\", &DuckDBPyConnection::RegisterPythonObject,\n \t         \"Register the passed Python Object value for querying with a view\", py::arg(\"view_name\"),\n \t         py::arg(\"python_object\"))\n@@ -439,9 +439,19 @@ shared_ptr<DuckDBPyConnection> DuckDBPyConnection::Execute(const string &query,\n \treturn shared_from_this();\n }\n \n-shared_ptr<DuckDBPyConnection> DuckDBPyConnection::Append(const string &name, const PandasDataFrame &value) {\n+shared_ptr<DuckDBPyConnection> DuckDBPyConnection::Append(const string &name, const PandasDataFrame &value,\n+                                                          bool by_name) {\n \tRegisterPythonObject(\"__append_df\", value);\n-\treturn Execute(\"INSERT INTO \\\"\" + name + \"\\\" SELECT * FROM __append_df\");\n+\tstring columns = \"\";\n+\tif (by_name) {\n+\t\tauto df_columns = value.attr(\"columns\");\n+\t\tvector<string> column_names;\n+\t\tfor (auto &column : df_columns) {\n+\t\t\tcolumn_names.push_back(std::string(py::str(column)));\n+\t\t}\n+\t\tcolumns = StringUtil::Format(\"(%s)\", StringUtil::Join(column_names, \",\"));\n+\t}\n+\treturn Execute(StringUtil::Format(\"INSERT INTO \\\"%s\\\"%s SELECT * FROM __append_df\", name, columns));\n }\n \n void DuckDBPyConnection::RegisterArrowObject(const py::object &arrow_object, const string &name) {\ndiff --git a/tools/pythonpkg/src/pyduckdb/connection_wrapper.cpp b/tools/pythonpkg/src/pyduckdb/connection_wrapper.cpp\nindex e0bc051de833..87604b48bb85 100644\n--- a/tools/pythonpkg/src/pyduckdb/connection_wrapper.cpp\n+++ b/tools/pythonpkg/src/pyduckdb/connection_wrapper.cpp\n@@ -97,9 +97,9 @@ shared_ptr<DuckDBPyConnection> PyConnectionWrapper::Execute(const string &query,\n \treturn conn->Execute(query, params, many);\n }\n \n-shared_ptr<DuckDBPyConnection> PyConnectionWrapper::Append(const string &name, PandasDataFrame value,\n+shared_ptr<DuckDBPyConnection> PyConnectionWrapper::Append(const string &name, PandasDataFrame value, bool by_name,\n                                                            shared_ptr<DuckDBPyConnection> conn) {\n-\treturn conn->Append(name, value);\n+\treturn conn->Append(name, value, by_name);\n }\n \n shared_ptr<DuckDBPyConnection> PyConnectionWrapper::RegisterPythonObject(const string &name, py::object python_object,\n",
  "test_patch": "diff --git a/tools/pythonpkg/tests/fast/pandas/test_append_df.py b/tools/pythonpkg/tests/fast/pandas/test_append_df.py\nindex b613969524d8..9ad0ffb71eea 100644\n--- a/tools/pythonpkg/tests/fast/pandas/test_append_df.py\n+++ b/tools/pythonpkg/tests/fast/pandas/test_append_df.py\n@@ -10,4 +10,56 @@ def test_df_to_table_append(self, duckdb_cursor, pandas):\n         conn.execute(\"Create table integers (i integer)\")\n         df_in = pandas.DataFrame({'numbers': [1,2,3,4,5],})\n         conn.append('integers',df_in)\n-        assert conn.execute('select count(*) from integers').fetchone()[0] == 5\n\\ No newline at end of file\n+        assert conn.execute('select count(*) from integers').fetchone()[0] == 5\n+\n+    @pytest.mark.parametrize('pandas', [NumpyPandas(), ArrowPandas()])\n+    def test_append_by_name(self, pandas):\n+        con = duckdb.connect()\n+        con.execute(\"create table tbl (a integer, b bool, c varchar)\")\n+        df_in = pandas.DataFrame({\n+            'c': ['duck', 'db'],\n+            'b': [False, True],\n+            'a': [4,2]\n+        })\n+        # By default we append by position, causing the following exception:\n+        with pytest.raises(duckdb.ConversionException, match=\"Conversion Error: Could not convert string 'duck' to INT32\"):\n+            con.append('tbl', df_in)\n+\n+        # When we use 'by_name' we instead append by name\n+        con.append('tbl', df_in, by_name=True)\n+        res = con.table('tbl').fetchall()\n+        assert res == [(4, False, 'duck'), (2, True, 'db')]\n+    \n+    @pytest.mark.parametrize('pandas', [NumpyPandas(), ArrowPandas()])\n+    def test_append_by_name_no_exact_match(self, pandas):\n+        con = duckdb.connect()\n+        con.execute(\"create table tbl (a integer, b bool)\")\n+        df_in = pandas.DataFrame({\n+            'c': ['a', 'b'],\n+            'b': [True, False],\n+            'a': [42, 1337]\n+        })\n+        # Too many columns raises an error, because the columns cant be found in the targeted table\n+        with pytest.raises(duckdb.BinderException, match='Table \"tbl\" does not have a column with name \"c\"'):\n+            con.append('tbl', df_in, by_name=True)\n+\n+        df_in = pandas.DataFrame({\n+            'b': [False, False, False]\n+        })\n+\n+        # Not matching all columns is not a problem, as they will be filled with NULL instead\n+        con.append('tbl', df_in, by_name=True)\n+        res = con.table('tbl').fetchall()\n+        # 'a' got filled by NULL automatically because it wasn't inserted into\n+        assert res == [(None, False), (None, False), (None, False)]\n+\n+        # Empty the table\n+        con.execute(\"create or replace table tbl (a integer, b bool)\")\n+\n+        df_in = pandas.DataFrame({\n+            'a': [1,2,3]\n+        })\n+        con.append('tbl', df_in, by_name=True)\n+        res = con.table('tbl').fetchall()\n+        # Also works for missing columns *after* the supplied ones\n+        assert res == [(1, None), (2, None), (3, None)]\n",
  "problem_statement": "python client append, insert_into, and INSERT INTO ... FROM dataframe commands don't respect column order and don't fill NULLs for missing columns\n### What happens?\n\nThe python client functions `append` and `insert_into`, and the SQL `INSERT INTO ... FROM <dataframe>`  command will naively insert data from the dataframe not accounting for the order of the columns.\r\n\r\nTo get around this, I must use the SQL `INSERT INTO <columns> VALUES (?, ...), <values list>` row-by-row. As long as the column string aligns with the values list, the values are placed into the correct column in the table, regardless of the order in which the columns are specified.\n\n### To Reproduce\n\n```python\r\nimport duckdb\r\nfrom pandas import DataFrame\r\n\r\nconnection = duckdb.connect()\r\nconnection.execute(\"CREATE TABLE data(a INTEGER, b INTEGER, c INTEGER)\")\r\n\r\ndf = DataFrame.from_records({'a': [1], 'b': [2], 'c': [3]})\r\n\r\n# nominal insert, everything is as expected\r\nconnection.append('data', df)\r\nconnection.sql(\"SELECT * FROM data\")\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502   a   \u2502   b   \u2502   c   \u2502\r\n\u2502 int32 \u2502 int32 \u2502 int32 \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502     1 \u2502     2 \u2502     3 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n# make some data that just has columns out of the expected order\r\ndf_out_of_order = df[['b', 'c', 'a']]\r\ndf_out_of_order\r\n   b  c  a\r\n0  2  3  1\r\n\r\n# append, expect that we'll get the value 1 for 'a', 2 for 'b' and 3 for 'c'\r\nconnection.append('data', df_out_of_order)\r\nconnection.sql(\"SELECT * FROM data\")\r\n\r\n# oh no! It naively just placed the data in the order left to right, not respecting the column names\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502   a   \u2502   b   \u2502   c   \u2502\r\n\u2502 int32 \u2502 int32 \u2502 int32 \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502     1 \u2502     2 \u2502     3 \u2502\r\n\u2502     2 \u2502     3 \u2502     1 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n# the same behavior is seen in `insert_into`\r\nconnection.sql(\"SELECT * FROM df_out_of_order\").insert_into(\"data\")\r\nconnection.sql(\"SELECT * FROM data\")\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502   a   \u2502   b   \u2502   c   \u2502\r\n\u2502 int32 \u2502 int32 \u2502 int32 \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502     1 \u2502     2 \u2502     3 \u2502\r\n\u2502     2 \u2502     3 \u2502     1 \u2502\r\n\u2502     2 \u2502     3 \u2502     1 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n# the same behavior is seen in INSERT FROM <dataframe>\r\nconnection.sql(\"INSERT INTO data SELECT * FROM df_out_of_order\")\r\nconnection.sql(\"SELECT * FROM data\")\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502   a   \u2502   b   \u2502   c   \u2502\r\n\u2502 int32 \u2502 int32 \u2502 int32 \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502     1 \u2502     2 \u2502     3 \u2502\r\n\u2502     2 \u2502     3 \u2502     1 \u2502\r\n\u2502     2 \u2502     3 \u2502     1 \u2502\r\n\u2502     2 \u2502     3 \u2502     1 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n# Ideally, these functions would insert NULLs for unspecified columns, but instead we get an error.\r\ndf = DataFrame.from_records({'a': [1], 'b': [2]})\r\nconnection.append('data', df)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nduckdb.BinderException: Binder Error: table data has 3 columns but 2 values were supplied\r\n```\n\n### OS:\n\nWindows\n\n### DuckDB Version:\n\n0.7.1\n\n### DuckDB Client:\n\nPython\n\n### Full Name:\n\nJ Nicolas Schrading\n\n### Affiliation:\n\npersonal\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\n",
  "hints_text": "If you don't explicitly provide columns for the insert, the columns are assumed to be the creation order of the columns.\r\nTo specify column order, here is an example:\r\n```sql\r\nD create table tbl (a integer, b varchar, c boolean);\r\nD insert into tbl(c, b, a) select NULL, 'c', 3;\r\nD select * from tbl;\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502   a   \u2502    b    \u2502    c    \u2502\r\n\u2502 int32 \u2502 varchar \u2502 boolean \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502     3 \u2502 c       \u2502         \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\nI do agree that when the columns are specified explicitly, it might be better to insert NULLs in the trailing columns that don't have a matching expression, instead of the current behavior:\r\n```sql\r\nD insert into tbl(c, b, a) select False, 'd';\r\nError: Binder Error: Column name/value mismatch for insert on tbl: expected 3 columns but 2 values were supplied\r\n```\nThanks for the additional info. I agree with the above, but at least you can do this and it will both insert all rows in the correct order and add NULLs for the missing columns\r\n\r\n```python\r\nconnection.sql(\"INSERT INTO data(a, b) SELECT a,b FROM df_out_of_order\")\r\n\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502   a   \u2502   b   \u2502   c   \u2502\r\n\u2502 int32 \u2502 int32 \u2502 int32 \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502     1 \u2502     3 \u2502  NULL \u2502\r\n\u2502     2 \u2502     4 \u2502  NULL \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\nI think at least for the `append` function, it would be a great usability improvement to operate in the way I'd expect, where column names are respected even if the columns are out of order in the dataframe / table, and by default add NULLs for missing columns. Perhaps an optional could be added to raise an error on missing columns.\r\n\r\n",
  "created_at": "2023-04-29T15:28:52Z"
}