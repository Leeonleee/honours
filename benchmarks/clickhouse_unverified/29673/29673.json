{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 29673,
  "instance_id": "ClickHouse__ClickHouse-29673",
  "issue_numbers": [
    "29671",
    "29670"
  ],
  "base_commit": "59fdfd18db42e357717aff9b8dffb7eda556a47a",
  "patch": "diff --git a/src/Storages/StorageURL.cpp b/src/Storages/StorageURL.cpp\nindex 5fb0ec13a9af..cbd935f79099 100644\n--- a/src/Storages/StorageURL.cpp\n+++ b/src/Storages/StorageURL.cpp\n@@ -57,10 +57,36 @@ IStorageURLBase::IStorageURLBase(\n \n namespace\n {\n+    ReadWriteBufferFromHTTP::HTTPHeaderEntries getHeaders(\n+        const ReadWriteBufferFromHTTP::HTTPHeaderEntries & headers_)\n+    {\n+        ReadWriteBufferFromHTTP::HTTPHeaderEntries headers(headers_.begin(), headers_.end());\n+        // Propagate OpenTelemetry trace context, if any, downstream.\n+        if (CurrentThread::isInitialized())\n+        {\n+            const auto & thread_trace_context = CurrentThread::get().thread_trace_context;\n+            if (thread_trace_context.trace_id != UUID())\n+            {\n+                headers.emplace_back(\"traceparent\",\n+                    thread_trace_context.composeTraceparentHeader());\n+\n+                if (!thread_trace_context.tracestate.empty())\n+                {\n+                    headers.emplace_back(\"tracestate\",\n+                        thread_trace_context.tracestate);\n+                }\n+            }\n+        }\n+        return headers;\n+    }\n+\n     class StorageURLSource : public SourceWithProgress\n     {\n+    using URIParams = std::vector<std::pair<String, String>>;\n+\n     public:\n-        StorageURLSource(const Poco::URI & uri,\n+        StorageURLSource(\n+            const std::vector<Poco::URI> & uri_options,\n             const std::string & method,\n             std::function<void(std::ostream &)> callback,\n             const String & format,\n@@ -71,56 +97,62 @@ namespace\n             const ColumnsDescription & columns,\n             UInt64 max_block_size,\n             const ConnectionTimeouts & timeouts,\n-            const CompressionMethod compression_method,\n-            const ReadWriteBufferFromHTTP::HTTPHeaderEntries & headers_ = {})\n+            const String & compression_method,\n+            const ReadWriteBufferFromHTTP::HTTPHeaderEntries & headers_ = {},\n+            const URIParams & params = {})\n             : SourceWithProgress(sample_block), name(std::move(name_))\n         {\n-            ReadWriteBufferFromHTTP::HTTPHeaderEntries headers;\n-\n-            for (const auto & header : headers_)\n-                headers.emplace_back(header);\n-\n-            // Propagate OpenTelemetry trace context, if any, downstream.\n-            if (CurrentThread::isInitialized())\n+            auto headers = getHeaders(headers_);\n+            /// Lazy initialization. We should not perform requests in constructor, because we need to do it in query pipeline.\n+            initialize = [=, this]\n             {\n-                const auto & thread_trace_context = CurrentThread::get().thread_trace_context;\n-                if (thread_trace_context.trace_id != UUID())\n+                WriteBufferFromOwnString error_message;\n+                for (auto option = uri_options.begin(); option < uri_options.end(); ++option)\n                 {\n-                    headers.emplace_back(\"traceparent\",\n-                        thread_trace_context.composeTraceparentHeader());\n+                    auto request_uri = *option;\n+                    for (const auto & [param, value] : params)\n+                        request_uri.addQueryParameter(param, value);\n \n-                    if (!thread_trace_context.tracestate.empty())\n+                    try\n+                    {\n+                        read_buf = wrapReadBufferWithCompressionMethod(\n+                            std::make_unique<ReadWriteBufferFromHTTP>(\n+                                request_uri,\n+                                method,\n+                                callback,\n+                                timeouts,\n+                                context->getSettingsRef().max_http_get_redirects,\n+                                Poco::Net::HTTPBasicCredentials{},\n+                                DBMS_DEFAULT_BUFFER_SIZE,\n+                                headers,\n+                                context->getRemoteHostFilter()),\n+                            chooseCompressionMethod(request_uri.getPath(), compression_method));\n+                    }\n+                    catch (...)\n                     {\n-                        headers.emplace_back(\"tracestate\",\n-                            thread_trace_context.tracestate);\n+                        if (uri_options.size() == 1)\n+                            throw;\n+\n+                        if (option == uri_options.end() - 1)\n+                            throw Exception(ErrorCodes::NETWORK_ERROR, \"All uri options are unreachable. {}\", error_message.str());\n+\n+                        error_message << option->toString() << \" error: \" << getCurrentExceptionMessage(false) << \"\\n\";\n+                        tryLogCurrentException(__PRETTY_FUNCTION__);\n                     }\n                 }\n-            }\n \n-            read_buf = wrapReadBufferWithCompressionMethod(\n-                std::make_unique<ReadWriteBufferFromHTTP>(\n-                    uri,\n-                    method,\n-                    std::move(callback),\n-                    timeouts,\n-                    context->getSettingsRef().max_http_get_redirects,\n-                    Poco::Net::HTTPBasicCredentials{},\n-                    DBMS_DEFAULT_BUFFER_SIZE,\n-                    headers,\n-                    context->getRemoteHostFilter()),\n-                compression_method);\n-\n-            auto input_format = FormatFactory::instance().getInput(format, *read_buf, sample_block, context, max_block_size, format_settings);\n-            QueryPipelineBuilder builder;\n-            builder.init(Pipe(input_format));\n-\n-            builder.addSimpleTransform([&](const Block & cur_header)\n-            {\n-                return std::make_shared<AddingDefaultsTransform>(cur_header, columns, *input_format, context);\n-            });\n+                auto input_format = FormatFactory::instance().getInput(format, *read_buf, sample_block, context, max_block_size, format_settings);\n+                QueryPipelineBuilder builder;\n+                builder.init(Pipe(input_format));\n+\n+                builder.addSimpleTransform([&](const Block & cur_header)\n+                {\n+                    return std::make_shared<AddingDefaultsTransform>(cur_header, columns, *input_format, context);\n+                });\n \n-            pipeline = std::make_unique<QueryPipeline>(QueryPipelineBuilder::getPipeline(std::move(builder)));\n-            reader = std::make_unique<PullingPipelineExecutor>(*pipeline);\n+                pipeline = std::make_unique<QueryPipeline>(QueryPipelineBuilder::getPipeline(std::move(builder)));\n+                reader = std::make_unique<PullingPipelineExecutor>(*pipeline);\n+            };\n         }\n \n         String getName() const override\n@@ -130,6 +162,12 @@ namespace\n \n         Chunk generate() override\n         {\n+            if (initialize)\n+            {\n+                initialize();\n+                initialize = {};\n+            }\n+\n             if (!reader)\n                 return {};\n \n@@ -144,6 +182,8 @@ namespace\n         }\n \n     private:\n+        std::function<void()> initialize;\n+\n         String name;\n         std::unique_ptr<ReadBuffer> read_buf;\n         std::unique_ptr<QueryPipeline> pipeline;\n@@ -225,13 +265,10 @@ Pipe IStorageURLBase::read(\n     size_t max_block_size,\n     unsigned /*num_streams*/)\n {\n-    auto request_uri = uri;\n     auto params = getReadURIParams(column_names, metadata_snapshot, query_info, local_context, processed_stage, max_block_size);\n-    for (const auto & [param, value] : params)\n-        request_uri.addQueryParameter(param, value);\n-\n+    std::vector<Poco::URI> uri_options{uri};\n     return Pipe(std::make_shared<StorageURLSource>(\n-        request_uri,\n+        uri_options,\n         getReadMethod(),\n         getReadPOSTDataCallback(\n             column_names, metadata_snapshot, query_info,\n@@ -244,8 +281,7 @@ Pipe IStorageURLBase::read(\n         metadata_snapshot->getColumns(),\n         max_block_size,\n         ConnectionTimeouts::getHTTPTimeouts(local_context),\n-        chooseCompressionMethod(request_uri.getPath(), compression_method),\n-        headers));\n+        compression_method, headers, params));\n }\n \n \n@@ -259,47 +295,23 @@ Pipe StorageURLWithFailover::read(\n     unsigned /*num_streams*/)\n {\n     auto params = getReadURIParams(column_names, metadata_snapshot, query_info, local_context, processed_stage, max_block_size);\n-    WriteBufferFromOwnString error_message;\n-    error_message << \"Detailed description:\";\n-\n-    for (const auto & uri_option : uri_options)\n-    {\n-        auto request_uri = uri_option;\n-        for (const auto & [param, value] : params)\n-            request_uri.addQueryParameter(param, value);\n-        try\n-        {\n-            /// Check for uri accessibility is done in constructor of ReadWriteBufferFromHTTP while creating StorageURLSource.\n-            auto url_source =  std::make_shared<StorageURLSource>(\n-                request_uri,\n-                getReadMethod(),\n-                getReadPOSTDataCallback(\n-                    column_names, metadata_snapshot, query_info,\n-                    local_context, processed_stage, max_block_size),\n-                format_name,\n-                format_settings,\n-                getName(),\n-                getHeaderBlock(column_names, metadata_snapshot),\n-                local_context,\n-                metadata_snapshot->getColumns(),\n-                max_block_size,\n-                ConnectionTimeouts::getHTTPTimeouts(local_context),\n-                chooseCompressionMethod(request_uri.getPath(), compression_method));\n-\n-            std::shuffle(uri_options.begin(), uri_options.end(), thread_local_rng);\n-\n-            return Pipe(url_source);\n-        }\n-        catch (...)\n-        {\n-            error_message << \" Host: \" << uri_option.getHost() << \", post: \" << uri_option.getPort() << \", path: \" << uri_option.getPath();\n-            error_message << \", error: \" << getCurrentExceptionMessage(false) << \";\";\n-\n-            tryLogCurrentException(__PRETTY_FUNCTION__);\n-        }\n-    }\n-\n-    throw Exception(ErrorCodes::NETWORK_ERROR, \"All uri options are unreachable. {}\", error_message.str());\n+    auto pipe =  Pipe(std::make_shared<StorageURLSource>(\n+        uri_options,\n+        getReadMethod(),\n+        getReadPOSTDataCallback(\n+            column_names, metadata_snapshot, query_info,\n+            local_context, processed_stage, max_block_size),\n+        format_name,\n+        format_settings,\n+        getName(),\n+        getHeaderBlock(column_names, metadata_snapshot),\n+        local_context,\n+        metadata_snapshot->getColumns(),\n+        max_block_size,\n+        ConnectionTimeouts::getHTTPTimeouts(local_context),\n+        compression_method, headers, params));\n+    std::shuffle(uri_options.begin(), uri_options.end(), thread_local_rng);\n+    return pipe;\n }\n \n \n",
  "test_patch": "diff --git a/tests/integration/test_redirect_url_storage/test.py b/tests/integration/test_redirect_url_storage/test.py\nindex a7fbc2f58212..d3808cd890d3 100644\n--- a/tests/integration/test_redirect_url_storage/test.py\n+++ b/tests/integration/test_redirect_url_storage/test.py\n@@ -54,7 +54,7 @@ def test_url_with_globs_and_failover(started_cluster):\n \n     result = node1.query(\n         \"select * from url('http://hdfs1:50075/webhdfs/v1/simple_storage_{0|1|2|3}_{1..3}?op=OPEN&namenoderpcaddress=hdfs1:9000&offset=0', 'TSV', 'data String') as data order by data\")\n-    assert result == \"1\\n2\\n3\\n\"\n+    assert result == \"1\\n2\\n3\\n\" or result == \"4\\n5\\n6\\n\"\n \n \n def test_url_with_redirect_not_allowed(started_cluster):\ndiff --git a/tests/queries/0_stateless/02044_url_glob_parallel.reference b/tests/queries/0_stateless/02044_url_glob_parallel.reference\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/queries/0_stateless/02044_url_glob_parallel.sh b/tests/queries/0_stateless/02044_url_glob_parallel.sh\nnew file mode 100755\nindex 000000000000..6491a661201c\n--- /dev/null\n+++ b/tests/queries/0_stateless/02044_url_glob_parallel.sh\n@@ -0,0 +1,13 @@\n+#!/usr/bin/env bash\n+# Tags: distributed\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+# Sometimes five seconds are not enough due to system overload.\n+# But if it can run in less than five seconds at least sometimes - it is enough for the test.\n+while true\n+do\n+    timeout 5s ${CLICKHOUSE_CLIENT} --max_threads 10 --query \"SELECT * FROM url('http://127.0.0.{1..10}:${CLICKHOUSE_PORT_HTTP}/?query=SELECT+sleep(1)', TSV, 'x UInt8')\" --format Null && break\n+done\n",
  "problem_statement": "`EXPLAIN` does not work as expected for a query with `url` table function\nIt performs unneeded requests:\r\n\r\n```\r\nEXPLAIN SELECT * FROM url('https://hacker-news.firebaseio.com/v0/item/{1..100}.json', JSONEachRow,\u3000$$\u3000id UInt32,\u3000deleted UInt8,\u3000type Enum('story' = 1, 'comment' = 2, 'poll' = 3, 'pollopt' = 4, 'job' = 5),\u3000by LowCardinality(String),\u3000time DateTime,\u3000text String,\u3000dead UInt8,\u3000parent UInt32,\u3000poll UInt32,\u3000kids Array(UInt32),\u3000url String,\u3000score Int32,\u3000title String,\u3000parts Array(UInt32),\u3000descendants Int32\u3000$$)\r\n```\n`url` table function does not process globs in parallel\n```\r\nSELECT * FROM url('https://hacker-news.firebaseio.com/v0/item/{1..100}.json', JSONEachRow,\r\n$$\r\nid UInt32,\r\ndeleted UInt8,\r\ntype Enum('story' = 1, 'comment' = 2, 'poll' = 3, 'pollopt' = 4, 'job' = 5),\r\nby LowCardinality(String),\r\ntime DateTime,\r\ntext String,\r\ndead UInt8,\r\nparent UInt32,\r\npoll UInt32,\r\nkids Array(UInt32),\r\nurl String,\r\nscore Int32,\r\ntitle String,\r\nparts Array(UInt32),\r\ndescendants Int32\r\n$$)\r\n```\r\n\r\nAll requests are done from single thread.\n",
  "hints_text": "\n",
  "created_at": "2021-10-03T04:31:29Z",
  "modified_files": [
    "src/Storages/StorageURL.cpp"
  ],
  "modified_test_files": [
    "tests/integration/test_redirect_url_storage/test.py",
    "b/tests/queries/0_stateless/02044_url_glob_parallel.sh"
  ]
}