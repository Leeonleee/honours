diff --git a/contrib/zookeeper b/contrib/zookeeper
index 438afae5af36..5aa9e889fe9e 160000
--- a/contrib/zookeeper
+++ b/contrib/zookeeper
@@ -1,1 +1,1 @@
-Subproject commit 438afae5af36c5be9c82d074f43a9bb19e0797c0
+Subproject commit 5aa9e889fe9e739af3c2a00222d9a3a0a57179dd
diff --git a/dbms/src/AggregateFunctions/AggregateFunctionSequenceMatch.h b/dbms/src/AggregateFunctions/AggregateFunctionSequenceMatch.h
index 297e74ae9755..d8c1a323e05d 100644
--- a/dbms/src/AggregateFunctions/AggregateFunctionSequenceMatch.h
+++ b/dbms/src/AggregateFunctions/AggregateFunctionSequenceMatch.h
@@ -164,8 +164,7 @@ class AggregateFunctionSequenceBase : public IAggregateFunctionDataHelper<Aggreg
         {
             const auto cond_arg = arguments[i].get();
             if (!typeid_cast<const DataTypeUInt8 *>(cond_arg))
-                throw Exception{
-                    "Illegal type " + cond_arg->getName() + " of argument " + toString(i + 1) +
+                throw Exception{"Illegal type " + cond_arg->getName() + " of argument " + toString(i + 1) +
                         " of aggregate function " + derived().getName() + ", must be UInt8",
                     ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT};
         }
diff --git a/dbms/src/Common/UInt128.h b/dbms/src/Common/UInt128.h
index 7885b0db9b89..8bda6e2b2047 100644
--- a/dbms/src/Common/UInt128.h
+++ b/dbms/src/Common/UInt128.h
@@ -40,9 +40,6 @@ struct UInt128
     bool inline operator>  (const UInt128 rhs) const { return tuple() > rhs.tuple(); }
     bool inline operator>= (const UInt128 rhs) const { return tuple() >= rhs.tuple(); }
 
-    /** Types who are stored at the moment in the database have no more than 64bits and can be handle
-     *  inside an unique UInt64.
-     */
     template <typename T> bool inline operator== (const T rhs) const { return *this == UInt128(rhs); }
     template <typename T> bool inline operator!= (const T rhs) const { return *this != UInt128(rhs); }
     template <typename T> bool inline operator>= (const T rhs) const { return *this >= UInt128(rhs); }
diff --git a/dbms/src/Core/Defines.h b/dbms/src/Core/Defines.h
index d730fd1b14fc..8b69d83d69e1 100644
--- a/dbms/src/Core/Defines.h
+++ b/dbms/src/Core/Defines.h
@@ -59,7 +59,7 @@
 #define DBMS_MIN_REVISION_WITH_SERVER_TIMEZONE 54058
 #define DBMS_MIN_REVISION_WITH_QUOTA_KEY_IN_CLIENT_INFO 54060
 #define DBMS_MIN_REVISION_WITH_TABLES_STATUS 54226
-#define DBMS_MIN_REVISION_WITH_TIME_ZONE_PARAMETER_IN_DATETIME_DATA_TYPE 54311
+#define DBMS_MIN_REVISION_WITH_TIME_ZONE_PARAMETER_IN_DATETIME_DATA_TYPE 54337
 
 /// Version of ClickHouse TCP protocol. Set to git tag with latest protocol change.
 #define DBMS_TCP_PROTOCOL_VERSION 54226
diff --git a/dbms/src/Core/Field.h b/dbms/src/Core/Field.h
index 9bb9cf6bb6e4..f4c2f1ade866 100644
--- a/dbms/src/Core/Field.h
+++ b/dbms/src/Core/Field.h
@@ -29,6 +29,7 @@ STRONG_TYPEDEF(TupleBackend, Tuple); /// Array and Tuple are different types wit
 
 
 /** 32 is enough. Round number is used for alignment and for better arithmetic inside std::vector.
+  * NOTE: Actually, sizeof(std::string) is 32 when using libc++, so Field is 40 bytes.
   */
 #define DBMS_MIN_FIELD_SIZE 32
 
diff --git a/dbms/src/Core/iostream_debug_helpers.cpp b/dbms/src/Core/iostream_debug_helpers.cpp
index 4277126e7e29..57a3d215b69b 100644
--- a/dbms/src/Core/iostream_debug_helpers.cpp
+++ b/dbms/src/Core/iostream_debug_helpers.cpp
@@ -18,7 +18,7 @@ namespace DB
 
 std::ostream & operator<<(std::ostream & stream, const IBlockInputStream & what)
 {
-    stream << "IBlockInputStream(id = " << what.getID() << ", name = " << what.getName() << ")";
+    stream << "IBlockInputStream(name = " << what.getName() << ")";
     //what.dumpTree(stream); // todo: set const
     return stream;
 }
@@ -115,7 +115,6 @@ std::ostream & operator<<(std::ostream & stream, const Connection::Packet & what
 std::ostream & operator<<(std::ostream & stream, const SubqueryForSet & what)
 {
     stream << "SubqueryForSet(source = " << what.source
-    << ", source_sample = " <<  what.source_sample
     // TODO: << ", set = " <<  what.set << ", join = " <<  what.join
     << ", table = " << what.table
     << ")";
diff --git a/dbms/src/DataStreams/AddingConstColumnBlockInputStream.h b/dbms/src/DataStreams/AddingConstColumnBlockInputStream.h
index e408e6b96d53..e22dd7f4310c 100644
--- a/dbms/src/DataStreams/AddingConstColumnBlockInputStream.h
+++ b/dbms/src/DataStreams/AddingConstColumnBlockInputStream.h
@@ -24,11 +24,11 @@ class AddingConstColumnBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "AddingConstColumn"; }
 
-    String getID() const override
+    Block getHeader() const override
     {
-        std::stringstream res;
-        res << "AddingConstColumn(" << children.back()->getID() << ")";
-        return res.str();
+        Block res = children.back()->getHeader();
+        res.insert({data_type->createColumn(), data_type, column_name});
+        return res;
     }
 
 protected:
diff --git a/dbms/src/DataStreams/AggregatingBlockInputStream.cpp b/dbms/src/DataStreams/AggregatingBlockInputStream.cpp
index b2cf9a7930a8..8896c40e5117 100644
--- a/dbms/src/DataStreams/AggregatingBlockInputStream.cpp
+++ b/dbms/src/DataStreams/AggregatingBlockInputStream.cpp
@@ -14,6 +14,11 @@ namespace ProfileEvents
 namespace DB
 {
 
+Block AggregatingBlockInputStream::getHeader() const
+{
+    return aggregator.getHeader(final);
+}
+
 
 Block AggregatingBlockInputStream::readImpl()
 {
@@ -42,7 +47,7 @@ Block AggregatingBlockInputStream::readImpl()
 
             if (!isCancelled())
             {
-                /// Flush data in the RAM to disk also. It's easier.
+                /// Flush data in the RAM to disk also. It's easier than merging on-disk and RAM data.
                 if (data_variants->size())
                     aggregator.writeToTemporaryFile(*data_variants);
             }
@@ -63,9 +68,8 @@ Block AggregatingBlockInputStream::readImpl()
         }
     }
 
-    Block res;
     if (isCancelled() || !impl)
-        return res;
+        return {};
 
     return impl->read();
 }
diff --git a/dbms/src/DataStreams/AggregatingBlockInputStream.h b/dbms/src/DataStreams/AggregatingBlockInputStream.h
index ea93188afba0..a28814dcab85 100644
--- a/dbms/src/DataStreams/AggregatingBlockInputStream.h
+++ b/dbms/src/DataStreams/AggregatingBlockInputStream.h
@@ -30,12 +30,7 @@ class AggregatingBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "Aggregating"; }
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << "Aggregating(" << children.back()->getID() << ", " << aggregator.getID() << ")";
-        return res.str();
-    }
+    Block getHeader() const override;
 
 protected:
     Block readImpl() override;
diff --git a/dbms/src/DataStreams/AggregatingSortedBlockInputStream.h b/dbms/src/DataStreams/AggregatingSortedBlockInputStream.h
index 60b6fba25f90..e428b3b7e205 100644
--- a/dbms/src/DataStreams/AggregatingSortedBlockInputStream.h
+++ b/dbms/src/DataStreams/AggregatingSortedBlockInputStream.h
@@ -28,26 +28,8 @@ class AggregatingSortedBlockInputStream : public MergingSortedBlockInputStream
 
     String getName() const override { return "AggregatingSorted"; }
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << "AggregatingSorted(inputs";
-
-        for (size_t i = 0; i < children.size(); ++i)
-            res << ", " << children[i]->getID();
-
-        res << ", description";
-
-        for (size_t i = 0; i < description.size(); ++i)
-            res << ", " << description[i].getID();
-
-        res << ")";
-        return res.str();
-    }
-
     bool isGroupedOutput() const override { return true; }
     bool isSortedOutput() const override { return true; }
-    const SortDescription & getSortDescription() const override { return description; }
 
 protected:
     /// Can return 1 more records than max_block_size.
diff --git a/dbms/src/DataStreams/AsynchronousBlockInputStream.h b/dbms/src/DataStreams/AsynchronousBlockInputStream.h
index e72b2f6489fb..0a80628cf2a2 100644
--- a/dbms/src/DataStreams/AsynchronousBlockInputStream.h
+++ b/dbms/src/DataStreams/AsynchronousBlockInputStream.h
@@ -35,13 +35,6 @@ class AsynchronousBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "Asynchronous"; }
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << "Asynchronous(" << children.back()->getID() << ")";
-        return res.str();
-    }
-
     void readPrefix() override
     {
         /// Do not call `readPrefix` on the child, so that the corresponding actions are performed in a separate thread.
@@ -80,6 +73,9 @@ class AsynchronousBlockInputStream : public IProfilingBlockInputStream
     }
 
 
+    Block getHeader() const override { return children.at(0)->getHeader(); }
+
+
     ~AsynchronousBlockInputStream() override
     {
         if (started)
diff --git a/dbms/src/DataStreams/BlockExtraInfoInputStream.h b/dbms/src/DataStreams/BlockExtraInfoInputStream.h
index c1a6d77874b9..6c6bd793f561 100644
--- a/dbms/src/DataStreams/BlockExtraInfoInputStream.h
+++ b/dbms/src/DataStreams/BlockExtraInfoInputStream.h
@@ -5,7 +5,7 @@
 namespace DB
 {
 
-/** Adds to one thread additional block information that is specified
+/** Adds to one stream additional block information that is specified
   * as the constructor parameter.
   */
 class BlockExtraInfoInputStream : public IProfilingBlockInputStream
@@ -24,12 +24,7 @@ class BlockExtraInfoInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "BlockExtraInfoInput"; }
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << "BlockExtraInfoInput(" << children.back()->getID() << ")";
-        return res.str();
-    }
+    Block getHeader() const override { return children.back()->getHeader(); }
 
 protected:
     Block readImpl() override
diff --git a/dbms/src/DataStreams/BlockIO.h b/dbms/src/DataStreams/BlockIO.h
index 5ac609f8a6ff..8cd19db9154b 100644
--- a/dbms/src/DataStreams/BlockIO.h
+++ b/dbms/src/DataStreams/BlockIO.h
@@ -21,7 +21,6 @@ struct BlockIO
     BlockInputStreamPtr in;
     BlockOutputStreamPtr out;
 
-    Block in_sample;    /// Example of a block to be read from `in`.
     Block out_sample;   /// Example of a block to be written to `out`.
 
     /// Callbacks for query logging could be set here.
@@ -51,7 +50,6 @@ struct BlockIO
         process_list_entry      = rhs.process_list_entry;
         in                      = rhs.in;
         out                     = rhs.out;
-        in_sample               = rhs.in_sample;
         out_sample              = rhs.out_sample;
 
         finish_callback         = rhs.finish_callback;
diff --git a/dbms/src/DataStreams/BlockInputStreamFromRowInputStream.h b/dbms/src/DataStreams/BlockInputStreamFromRowInputStream.h
index 0194bacba9e1..0ab725be9a01 100644
--- a/dbms/src/DataStreams/BlockInputStreamFromRowInputStream.h
+++ b/dbms/src/DataStreams/BlockInputStreamFromRowInputStream.h
@@ -29,15 +29,10 @@ class BlockInputStreamFromRowInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "BlockInputStreamFromRowInputStream"; }
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << this;
-        return res.str();
-    }
-
     RowInputStreamPtr & getRowInput() { return row_input; }
 
+    Block getHeader() const override { return sample; }
+
 protected:
     Block readImpl() override;
 
diff --git a/dbms/src/DataStreams/BlocksListBlockInputStream.h b/dbms/src/DataStreams/BlocksListBlockInputStream.h
index b477e34d3caa..6c8852de4a37 100644
--- a/dbms/src/DataStreams/BlocksListBlockInputStream.h
+++ b/dbms/src/DataStreams/BlocksListBlockInputStream.h
@@ -22,13 +22,6 @@ class BlocksListBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "BlocksList"; }
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << this;
-        return res.str();
-    }
-
 protected:
     Block readImpl() override
     {
diff --git a/dbms/src/DataStreams/CastTypeBlockInputStream.cpp b/dbms/src/DataStreams/CastTypeBlockInputStream.cpp
index e792fc8afa44..9dbd0962c934 100644
--- a/dbms/src/DataStreams/CastTypeBlockInputStream.cpp
+++ b/dbms/src/DataStreams/CastTypeBlockInputStream.cpp
@@ -20,11 +20,6 @@ String CastTypeBlockInputStream::getName() const
     return "CastType";
 }
 
-String CastTypeBlockInputStream::getID() const
-{
-    return "CastType(" + children.back()->getID() + ")";
-}
-
 Block CastTypeBlockInputStream::readImpl()
 {
     Block block = children.back()->read();
diff --git a/dbms/src/DataStreams/CastTypeBlockInputStream.h b/dbms/src/DataStreams/CastTypeBlockInputStream.h
index 23815210d54a..b92a7ffa31fd 100644
--- a/dbms/src/DataStreams/CastTypeBlockInputStream.h
+++ b/dbms/src/DataStreams/CastTypeBlockInputStream.h
@@ -17,7 +17,7 @@ class CastTypeBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override;
 
-    String getID() const override;
+    Block getHeader() const override { return ref_definition; }
 
 protected:
     Block readImpl() override;
diff --git a/dbms/src/DataStreams/CollapsingFinalBlockInputStream.h b/dbms/src/DataStreams/CollapsingFinalBlockInputStream.h
index 264b20838093..db06a2aa9d38 100644
--- a/dbms/src/DataStreams/CollapsingFinalBlockInputStream.h
+++ b/dbms/src/DataStreams/CollapsingFinalBlockInputStream.h
@@ -28,26 +28,11 @@ class CollapsingFinalBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "CollapsingFinal"; }
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << "CollapsingFinal(inputs";
-
-        for (size_t i = 0; i < children.size(); ++i)
-            res << ", " << children[i]->getID();
-
-        res << ", description";
-
-        for (size_t i = 0; i < description.size(); ++i)
-            res << ", " << description[i].getID();
-
-        res << ", sign_column, " << sign_column_name << ")";
-        return res.str();
-    }
-
     bool isSortedOutput() const override { return true; }
     const SortDescription & getSortDescription() const override { return description; }
 
+    Block getHeader() const override { return children.at(0)->getHeader(); }
+
 protected:
     Block readImpl() override;
 
diff --git a/dbms/src/DataStreams/CollapsingSortedBlockInputStream.h b/dbms/src/DataStreams/CollapsingSortedBlockInputStream.h
index 9d9043b30c54..7280dda02b1d 100644
--- a/dbms/src/DataStreams/CollapsingSortedBlockInputStream.h
+++ b/dbms/src/DataStreams/CollapsingSortedBlockInputStream.h
@@ -33,23 +33,6 @@ class CollapsingSortedBlockInputStream : public MergingSortedBlockInputStream
 
     String getName() const override { return "CollapsingSorted"; }
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << "CollapsingSorted(inputs";
-
-        for (size_t i = 0; i < children.size(); ++i)
-            res << ", " << children[i]->getID();
-
-        res << ", description";
-
-        for (size_t i = 0; i < description.size(); ++i)
-            res << ", " << description[i].getID();
-
-        res << ", sign_column, " << sign_column << ")";
-        return res.str();
-    }
-
 protected:
     /// Can return 1 more records than max_block_size.
     Block readImpl() override;
diff --git a/dbms/src/DataStreams/ColumnGathererStream.cpp b/dbms/src/DataStreams/ColumnGathererStream.cpp
index 81a9d3348b00..ba4107f7e8b9 100644
--- a/dbms/src/DataStreams/ColumnGathererStream.cpp
+++ b/dbms/src/DataStreams/ColumnGathererStream.cpp
@@ -30,19 +30,6 @@ ColumnGathererStream::ColumnGathererStream(
 }
 
 
-String ColumnGathererStream::getID() const
-{
-    std::stringstream res;
-
-    res << getName() << "(";
-    for (size_t i = 0; i < children.size(); ++i)
-        res << (i == 0 ? "" : ", " ) << children[i]->getID();
-    res << ")";
-
-    return res.str();
-}
-
-
 void ColumnGathererStream::init()
 {
     sources.reserve(children.size());
@@ -107,13 +94,13 @@ void ColumnGathererStream::fetchNewBlock(Source & source, size_t source_num)
     }
     catch (Exception & e)
     {
-        e.addMessage("Cannot fetch required block. Stream " + children[source_num]->getID() + ", part " + toString(source_num));
+        e.addMessage("Cannot fetch required block. Stream " + children[source_num]->getName() + ", part " + toString(source_num));
         throw;
     }
 
     if (0 == source.size)
     {
-        throw Exception("Fetched block is empty. Stream " + children[source_num]->getID() + ", part " + toString(source_num),
+        throw Exception("Fetched block is empty. Stream " + children[source_num]->getName() + ", part " + toString(source_num),
                         ErrorCodes::RECEIVED_EMPTY_DATA);
     }
 }
diff --git a/dbms/src/DataStreams/ColumnGathererStream.h b/dbms/src/DataStreams/ColumnGathererStream.h
index 66ad2645e2f9..101e8fdccf3c 100644
--- a/dbms/src/DataStreams/ColumnGathererStream.h
+++ b/dbms/src/DataStreams/ColumnGathererStream.h
@@ -61,12 +61,12 @@ class ColumnGathererStream : public IProfilingBlockInputStream
 
     String getName() const override { return "ColumnGatherer"; }
 
-    String getID() const override;
-
     Block readImpl() override;
 
     void readSuffixImpl() override;
 
+    Block getHeader() const override { return children.at(0)->getHeader(); }
+
     /// for use in implementations of IColumn::gather()
     template <typename Column>
     void gather(Column & column_res);
diff --git a/dbms/src/DataStreams/ConcatBlockInputStream.h b/dbms/src/DataStreams/ConcatBlockInputStream.h
index e8da47a7c02a..fafcbc6950c3 100644
--- a/dbms/src/DataStreams/ConcatBlockInputStream.h
+++ b/dbms/src/DataStreams/ConcatBlockInputStream.h
@@ -22,24 +22,7 @@ class ConcatBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "Concat"; }
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << "Concat(";
-
-        Strings children_ids(children.size());
-        for (size_t i = 0; i < children.size(); ++i)
-            children_ids[i] = children[i]->getID();
-
-        /// Let's assume that the order of concatenation of blocks does not matter.
-        std::sort(children_ids.begin(), children_ids.end());
-
-        for (size_t i = 0; i < children_ids.size(); ++i)
-            res << (i == 0 ? "" : ", ") << children_ids[i];
-
-        res << ")";
-        return res.str();
-    }
+    Block getHeader() const override { return children.at(0)->getHeader(); }
 
 protected:
     Block readImpl() override
diff --git a/dbms/src/DataStreams/CreatingSetsBlockInputStream.h b/dbms/src/DataStreams/CreatingSetsBlockInputStream.h
index 605caac90bcf..85088d1d8fcd 100644
--- a/dbms/src/DataStreams/CreatingSetsBlockInputStream.h
+++ b/dbms/src/DataStreams/CreatingSetsBlockInputStream.h
@@ -35,24 +35,7 @@ class CreatingSetsBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "CreatingSets"; }
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << "CreatingSets(";
-
-        Strings children_ids(children.size());
-        for (size_t i = 0; i < children.size(); ++i)
-            children_ids[i] = children[i]->getID();
-
-        /// Let's assume that the order of creating sets does not matter.
-        std::sort(children_ids.begin(), children_ids.end() - 1);
-
-        for (size_t i = 0; i < children_ids.size(); ++i)
-            res << (i == 0 ? "" : ", ") << children_ids[i];
-
-        res << ")";
-        return res.str();
-    }
+    Block getHeader() const override { return children.back()->getHeader(); }
 
     /// Takes `totals` only from the main source, not from subquery sources.
     const Block & getTotals() override;
diff --git a/dbms/src/DataStreams/DistinctBlockInputStream.cpp b/dbms/src/DataStreams/DistinctBlockInputStream.cpp
index f10eda57e053..50949b2f0ccd 100644
--- a/dbms/src/DataStreams/DistinctBlockInputStream.cpp
+++ b/dbms/src/DataStreams/DistinctBlockInputStream.cpp
@@ -18,13 +18,6 @@ DistinctBlockInputStream::DistinctBlockInputStream(const BlockInputStreamPtr & i
     children.push_back(input);
 }
 
-String DistinctBlockInputStream::getID() const
-{
-    std::stringstream res;
-    res << "Distinct(" << children.back()->getID() << ")";
-    return res.str();
-}
-
 Block DistinctBlockInputStream::readImpl()
 {
     /// Execute until end of stream or until
diff --git a/dbms/src/DataStreams/DistinctBlockInputStream.h b/dbms/src/DataStreams/DistinctBlockInputStream.h
index d35c6ced3d3c..60a92e0399aa 100644
--- a/dbms/src/DataStreams/DistinctBlockInputStream.h
+++ b/dbms/src/DataStreams/DistinctBlockInputStream.h
@@ -22,7 +22,7 @@ class DistinctBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "Distinct"; }
 
-    String getID() const override;
+    Block getHeader() const override { return children.at(0)->getHeader(); }
 
 protected:
     Block readImpl() override;
diff --git a/dbms/src/DataStreams/DistinctSortedBlockInputStream.cpp b/dbms/src/DataStreams/DistinctSortedBlockInputStream.cpp
index 59395d26b231..e9e5d69d047b 100644
--- a/dbms/src/DataStreams/DistinctSortedBlockInputStream.cpp
+++ b/dbms/src/DataStreams/DistinctSortedBlockInputStream.cpp
@@ -19,13 +19,6 @@ DistinctSortedBlockInputStream::DistinctSortedBlockInputStream(const BlockInputS
     children.push_back(input);
 }
 
-String DistinctSortedBlockInputStream::getID() const
-{
-    std::stringstream res;
-    res << "DistinctSorted(" << children.back()->getID() << ")";
-    return res.str();
-}
-
 Block DistinctSortedBlockInputStream::readImpl()
 {
     /// Execute until end of stream or until
diff --git a/dbms/src/DataStreams/DistinctSortedBlockInputStream.h b/dbms/src/DataStreams/DistinctSortedBlockInputStream.h
index 335e8406e700..33c6cef7774e 100644
--- a/dbms/src/DataStreams/DistinctSortedBlockInputStream.h
+++ b/dbms/src/DataStreams/DistinctSortedBlockInputStream.h
@@ -25,7 +25,7 @@ class DistinctSortedBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "DistinctSorted"; }
 
-    String getID() const override;
+    Block getHeader() const override { return children.at(0)->getHeader(); }
 
 protected:
     Block readImpl() override;
diff --git a/dbms/src/DataStreams/ExpressionBlockInputStream.cpp b/dbms/src/DataStreams/ExpressionBlockInputStream.cpp
index 369150796f75..d274a456c227 100644
--- a/dbms/src/DataStreams/ExpressionBlockInputStream.cpp
+++ b/dbms/src/DataStreams/ExpressionBlockInputStream.cpp
@@ -13,13 +13,6 @@ ExpressionBlockInputStream::ExpressionBlockInputStream(const BlockInputStreamPtr
 
 String ExpressionBlockInputStream::getName() const { return "Expression"; }
 
-String ExpressionBlockInputStream::getID() const
-{
-    std::stringstream res;
-    res << "Expression(" << children.back()->getID() << ", " << expression->getID() << ")";
-    return res.str();
-}
-
 const Block & ExpressionBlockInputStream::getTotals()
 {
     if (IProfilingBlockInputStream * child = dynamic_cast<IProfilingBlockInputStream *>(&*children.back()))
@@ -31,14 +24,19 @@ const Block & ExpressionBlockInputStream::getTotals()
     return totals;
 }
 
+Block ExpressionBlockInputStream::getHeader() const
+{
+    Block res = children.back()->getHeader();
+    expression->execute(res);
+    return res;
+}
+
 Block ExpressionBlockInputStream::readImpl()
 {
     Block res = children.back()->read();
     if (!res)
         return res;
-
     expression->execute(res);
-
     return res;
 }
 
diff --git a/dbms/src/DataStreams/ExpressionBlockInputStream.h b/dbms/src/DataStreams/ExpressionBlockInputStream.h
index 11d498332a36..a509d1e606ee 100644
--- a/dbms/src/DataStreams/ExpressionBlockInputStream.h
+++ b/dbms/src/DataStreams/ExpressionBlockInputStream.h
@@ -22,8 +22,8 @@ class ExpressionBlockInputStream : public IProfilingBlockInputStream
     ExpressionBlockInputStream(const BlockInputStreamPtr & input, const ExpressionActionsPtr & expression_);
 
     String getName() const override;
-    String getID() const override;
     const Block & getTotals() override;
+    Block getHeader() const override;
 
 protected:
     Block readImpl() override;
diff --git a/dbms/src/DataStreams/FilterBlockInputStream.cpp b/dbms/src/DataStreams/FilterBlockInputStream.cpp
index e3430119a1b2..5bfff19b7a78 100644
--- a/dbms/src/DataStreams/FilterBlockInputStream.cpp
+++ b/dbms/src/DataStreams/FilterBlockInputStream.cpp
@@ -23,24 +23,40 @@ FilterBlockInputStream::FilterBlockInputStream(const BlockInputStreamPtr & input
     children.push_back(input);
 }
 
-FilterBlockInputStream::FilterBlockInputStream(const BlockInputStreamPtr & input, const ExpressionActionsPtr & expression_, const String & filter_column_name_)
-    : expression(expression_), filter_column(-1), filter_column_name(filter_column_name_)
+FilterBlockInputStream::FilterBlockInputStream(const BlockInputStreamPtr & input, const ExpressionActionsPtr & expression_, const String & filter_column_name)
+    : expression(expression_)
 {
     children.push_back(input);
-}
 
+    /// Determine position of filter column.
+    header = input->getHeader();
+    expression->execute(header);
 
-String FilterBlockInputStream::getName() const { return "Filter"; }
+    filter_column = header.getPositionByName(filter_column_name);
 
+    /// Isn't the filter already constant?
+    ColumnPtr column = header.safeGetByPosition(filter_column).column;
 
-String FilterBlockInputStream::getID() const
-{
-    std::stringstream res;
-    res << "Filter(" << children.back()->getID() << ", " << expression->getID() << ", " << filter_column << ", " << filter_column_name << ")";
-    return res.str();
+    if (!have_constant_filter_description)
+    {
+        have_constant_filter_description = true;
+        if (column)
+            constant_filter_description = ConstantFilterDescription(*column);
+    }
+
+    if (!constant_filter_description.always_false
+        && !constant_filter_description.always_true)
+    {
+        /// Replace the filter column to a constant with value 1.
+        auto header_filter_elem = header.getByPosition(filter_column);
+        header_filter_elem.column = header_filter_elem.type->createColumnConst(header.rows(), UInt64(1));
+    }
 }
 
 
+String FilterBlockInputStream::getName() const { return "Filter"; }
+
+
 const Block & FilterBlockInputStream::getTotals()
 {
     if (IProfilingBlockInputStream * child = dynamic_cast<IProfilingBlockInputStream *>(&*children.back()))
@@ -53,34 +69,19 @@ const Block & FilterBlockInputStream::getTotals()
 }
 
 
+Block FilterBlockInputStream::getHeader() const
+{
+    return header;
+}
+
+
 Block FilterBlockInputStream::readImpl()
 {
     Block res;
 
-    if (is_first)
+    if (!have_constant_filter_description)
     {
-        is_first = false;
-
-        const Block & sample_block = expression->getSampleBlock();
-
-        /// Find the current position of the filter column in the block.
-        /** sample_block has the result structure of evaluating the expression.
-          * But this structure does not necessarily match expression->execute(res) below,
-          *  because the expression can be applied to a block that also contains additional,
-          *  columns unnecessary for this expression, but needed later, in the next stages of the query execution pipeline.
-          * There will be no such columns in sample_block.
-          * Therefore, the position of the filter column in it can be different.
-          */
-        ssize_t filter_column_in_sample_block = filter_column;
-        if (filter_column_in_sample_block == -1)
-            filter_column_in_sample_block = sample_block.getPositionByName(filter_column_name);
-
-        /// Let's check if the filter column is a constant containing 0 or 1.
-        ColumnPtr column = sample_block.safeGetByPosition(filter_column_in_sample_block).column;
-
-        if (column)
-            constant_filter_description = ConstantFilterDescription(*column);
-
+        getHeader();
         if (constant_filter_description.always_false)
             return res;
     }
@@ -97,10 +98,6 @@ Block FilterBlockInputStream::readImpl()
         if (constant_filter_description.always_true)
             return res;
 
-        /// Find the current position of the filter column in the block.
-        if (filter_column == -1)
-            filter_column = res.getPositionByName(filter_column_name);
-
         size_t columns = res.columns();
         ColumnPtr column = res.safeGetByPosition(filter_column).column;
 
diff --git a/dbms/src/DataStreams/FilterBlockInputStream.h b/dbms/src/DataStreams/FilterBlockInputStream.h
index 56a38b9e39aa..9cb27d6b1f08 100644
--- a/dbms/src/DataStreams/FilterBlockInputStream.h
+++ b/dbms/src/DataStreams/FilterBlockInputStream.h
@@ -25,20 +25,19 @@ class FilterBlockInputStream : public IProfilingBlockInputStream
     FilterBlockInputStream(const BlockInputStreamPtr & input, const ExpressionActionsPtr & expression_, const String & filter_column_name_);
 
     String getName() const override;
-    String getID() const override;
     const Block & getTotals() override;
+    Block getHeader() const override;
 
 protected:
     Block readImpl() override;
 
 private:
     ExpressionActionsPtr expression;
+    Block header;
     ssize_t filter_column;
-    String filter_column_name;
-
-    bool is_first = true;
 
     ConstantFilterDescription constant_filter_description;
+    bool have_constant_filter_description = false;
 };
 
 }
diff --git a/dbms/src/DataStreams/FilterColumnsBlockInputStream.cpp b/dbms/src/DataStreams/FilterColumnsBlockInputStream.cpp
index a8ee82945a73..fa7bb916fe7d 100644
--- a/dbms/src/DataStreams/FilterColumnsBlockInputStream.cpp
+++ b/dbms/src/DataStreams/FilterColumnsBlockInputStream.cpp
@@ -3,16 +3,16 @@
 namespace DB
 {
 
-String FilterColumnsBlockInputStream::getID() const
+Block FilterColumnsBlockInputStream::getHeader() const
 {
-    std::stringstream res;
-    res << "FilterColumnsBlockInputStream(" << children.back()->getID();
+    Block block = children.back()->getHeader();
+    Block filtered;
 
     for (const auto & it : columns_to_save)
-        res << ", " << it;
+        if (throw_if_column_not_found || block.has(it))
+            filtered.insert(std::move(block.getByName(it)));
 
-    res << ")";
-    return res.str();
+    return filtered;
 }
 
 Block FilterColumnsBlockInputStream::readImpl()
diff --git a/dbms/src/DataStreams/FilterColumnsBlockInputStream.h b/dbms/src/DataStreams/FilterColumnsBlockInputStream.h
index 07a9f6bd0932..b2ac83c8fdf2 100644
--- a/dbms/src/DataStreams/FilterColumnsBlockInputStream.h
+++ b/dbms/src/DataStreams/FilterColumnsBlockInputStream.h
@@ -24,7 +24,7 @@ class FilterColumnsBlockInputStream : public IProfilingBlockInputStream
         return "FilterColumnsBlockInputStream";
     }
 
-    String getID() const override;
+    Block getHeader() const override;
 
 protected:
     Block readImpl() override;
diff --git a/dbms/src/DataStreams/FormatFactory.cpp b/dbms/src/DataStreams/FormatFactory.cpp
index c9954dd8352b..d871a4b23a5b 100644
--- a/dbms/src/DataStreams/FormatFactory.cpp
+++ b/dbms/src/DataStreams/FormatFactory.cpp
@@ -59,7 +59,7 @@ BlockInputStreamPtr FormatFactory::getInput(const String & name, ReadBuffer & bu
 
     if (name == "Native")
     {
-        return std::make_shared<NativeBlockInputStream>(buf);
+        return std::make_shared<NativeBlockInputStream>(buf, sample, 0);
     }
     else if (name == "RowBinary")
     {
diff --git a/dbms/src/DataStreams/GraphiteRollupSortedBlockInputStream.h b/dbms/src/DataStreams/GraphiteRollupSortedBlockInputStream.h
index c5e85bcf8aee..99d9466408de 100644
--- a/dbms/src/DataStreams/GraphiteRollupSortedBlockInputStream.h
+++ b/dbms/src/DataStreams/GraphiteRollupSortedBlockInputStream.h
@@ -135,23 +135,6 @@ class GraphiteRollupSortedBlockInputStream : public MergingSortedBlockInputStrea
 
     String getName() const override { return "GraphiteRollupSorted"; }
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << "GraphiteRollupSorted(inputs";
-
-        for (size_t i = 0; i < children.size(); ++i)
-            res << ", " << children[i]->getID();
-
-        res << ", description";
-
-        for (size_t i = 0; i < description.size(); ++i)
-            res << ", " << description[i].getID();
-
-        res << ")";
-        return res.str();
-    }
-
     ~GraphiteRollupSortedBlockInputStream()
     {
         if (aggregate_state_created)
diff --git a/dbms/src/DataStreams/IBlockInputStream.cpp b/dbms/src/DataStreams/IBlockInputStream.cpp
index 13a3c99d393a..b4cc5444c875 100644
--- a/dbms/src/DataStreams/IBlockInputStream.cpp
+++ b/dbms/src/DataStreams/IBlockInputStream.cpp
@@ -64,6 +64,7 @@ void IBlockInputStream::dumpTree(std::ostream & ostr, size_t indent, size_t mult
     ostr << String(indent, ' ') << getName();
     if (multiplier > 1)
         ostr << " Ã— " << multiplier;
+    // ostr << ": " << getHeader().dumpStructure();
     ostr << std::endl;
     ++indent;
 
@@ -125,13 +126,5 @@ void IBlockInputStream::getLeavesImpl(BlockInputStreams & res, const BlockInputS
             (*it)->getLeavesImpl(res, *it);
 }
 
-/// By default all instances is different streams
-String IBlockInputStream::getID() const
-{
-    std::stringstream res;
-    res << getName() << "(" << this << ")";
-    return res.str();
-};
-
 }
 
diff --git a/dbms/src/DataStreams/IBlockInputStream.h b/dbms/src/DataStreams/IBlockInputStream.h
index 8a874ea127b1..77ee6b941573 100644
--- a/dbms/src/DataStreams/IBlockInputStream.h
+++ b/dbms/src/DataStreams/IBlockInputStream.h
@@ -48,6 +48,12 @@ class IBlockInputStream : private boost::noncopyable
 public:
     IBlockInputStream() {}
 
+    /** Get data structure of the stream in a form of "header" block (it is also called "sample block").
+      * Header block contains column names, data types, columns of size 0. Constant columns must have corresponding values.
+      * It is guaranteed that method "read" returns blocks of exactly that structure.
+      */
+    virtual Block getHeader() const = 0;
+
     /** Read next block.
       * If there are no more blocks, return an empty block (for which operator `bool` returns false).
       * NOTE: Only one thread can read from one instance of IBlockInputStream simultaneously.
@@ -76,14 +82,6 @@ class IBlockInputStream : private boost::noncopyable
       */
     virtual String getName() const = 0;
 
-    /** The unique identifier of the pipeline part of the query execution.
-      * Sources with the same identifier are considered identical
-      *  (producing the same data), and can be replaced by one source
-      *  if several queries are executed simultaneously.
-      * If the source can not be glued together with any other - return the object's address as an identifier.
-      */
-    virtual String getID() const;
-
     /// If this stream generates data in grouped by some keys, return true.
     virtual bool isGroupedOutput() const { return false; }
     /// If this stream generates data in order by some keys, return true.
diff --git a/dbms/src/DataStreams/InputStreamFromASTInsertQuery.h b/dbms/src/DataStreams/InputStreamFromASTInsertQuery.h
index 622ff46d4240..dbcf3799e3e8 100644
--- a/dbms/src/DataStreams/InputStreamFromASTInsertQuery.h
+++ b/dbms/src/DataStreams/InputStreamFromASTInsertQuery.h
@@ -1,20 +1,16 @@
 #pragma once
 
-#include <Parsers/ASTInsertQuery.h>
-#include <Interpreters/Context.h>
-#include <IO/ConcatReadBuffer.h>
+#include <Parsers/IAST.h>
 #include <DataStreams/IProfilingBlockInputStream.h>
-#include <DataStreams/BlockIO.h>
 #include <cstddef>
+#include <memory>
 
 
 namespace DB
 {
 
-namespace ErrorCodes
-{
-    extern const int LOGICAL_ERROR;
-}
+struct BlockIO;
+class Context;
 
 /** Prepares an input stream which produce data containing in INSERT query
   * Head of inserting data could be stored in INSERT ast directly
@@ -23,7 +19,6 @@ namespace ErrorCodes
 class InputStreamFromASTInsertQuery : public IProfilingBlockInputStream
 {
 public:
-
     InputStreamFromASTInsertQuery(const ASTPtr & ast, ReadBuffer & input_buffer_tail_part, const BlockIO & streams, Context & context);
 
     Block readImpl() override { return res_stream->read(); }
@@ -31,10 +26,10 @@ class InputStreamFromASTInsertQuery : public IProfilingBlockInputStream
     void readSuffixImpl() override { return res_stream->readSuffix(); }
 
     String getName() const override { return "InputStreamFromASTInsertQuery"; }
-    String getID() const override { return "InputStreamFromASTInsertQuery(" + toString(std::intptr_t(this)) + ")"; }
 
-private:
+    Block getHeader() const override { return res_stream->getHeader(); }
 
+private:
     std::unique_ptr<ReadBuffer> input_buffer_ast_part;
     std::unique_ptr<ReadBuffer> input_buffer_contacenated;
 
diff --git a/dbms/src/DataStreams/LazyBlockInputStream.h b/dbms/src/DataStreams/LazyBlockInputStream.h
index 8cf4f3a293d4..6d05e570f531 100644
--- a/dbms/src/DataStreams/LazyBlockInputStream.h
+++ b/dbms/src/DataStreams/LazyBlockInputStream.h
@@ -15,14 +15,13 @@ class LazyBlockInputStream : public IProfilingBlockInputStream
 public:
     using Generator = std::function<BlockInputStreamPtr()>;
 
-    LazyBlockInputStream(Generator generator_)
-        : generator(std::move(generator_))
+    LazyBlockInputStream(const Block & header_, Generator generator_)
+        : header(header_), generator(std::move(generator_))
     {
     }
 
-    LazyBlockInputStream(const char * name_, Generator generator_)
-        : name(name_)
-        , generator(std::move(generator_))
+    LazyBlockInputStream(const char * name_, const Block & header_, Generator generator_)
+        : name(name_), header(header_), generator(std::move(generator_))
     {
     }
 
@@ -34,6 +33,11 @@ class LazyBlockInputStream : public IProfilingBlockInputStream
         IProfilingBlockInputStream::cancel();
     }
 
+    Block getHeader() const override
+    {
+        return header;
+    }
+
 protected:
     Block readImpl() override
     {
@@ -89,6 +93,7 @@ class LazyBlockInputStream : public IProfilingBlockInputStream
 
 private:
     const char * name = "Lazy";
+    Block header;
     Generator generator;
 
     BlockInputStreamPtr input;
diff --git a/dbms/src/DataStreams/LimitBlockInputStream.h b/dbms/src/DataStreams/LimitBlockInputStream.h
index 23bd5739aafd..9739665243f6 100644
--- a/dbms/src/DataStreams/LimitBlockInputStream.h
+++ b/dbms/src/DataStreams/LimitBlockInputStream.h
@@ -21,12 +21,7 @@ class LimitBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "Limit"; }
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << "Limit(" << children.back()->getID() << ", " << limit << ", " << offset << ")";
-        return res.str();
-    }
+    Block getHeader() const override { return children.at(0)->getHeader(); }
 
 protected:
     Block readImpl() override;
diff --git a/dbms/src/DataStreams/LimitByBlockInputStream.h b/dbms/src/DataStreams/LimitByBlockInputStream.h
index 09eb357ca2e3..88cf2ff1670b 100644
--- a/dbms/src/DataStreams/LimitByBlockInputStream.h
+++ b/dbms/src/DataStreams/LimitByBlockInputStream.h
@@ -3,9 +3,9 @@
 #include <DataStreams/IProfilingBlockInputStream.h>
 
 #include <Common/HashTable/HashMap.h>
-#include <Common/SipHash.h>
 #include <Common/UInt128.h>
 
+
 namespace DB
 {
 
@@ -22,6 +22,8 @@ class LimitByBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "LimitBy"; }
 
+    Block getHeader() const override { return children.at(0)->getHeader(); }
+
 protected:
     Block readImpl() override;
 
diff --git a/dbms/src/DataStreams/MaterializingBlockInputStream.cpp b/dbms/src/DataStreams/MaterializingBlockInputStream.cpp
index b7ae5c6c000f..e0f287d44faf 100644
--- a/dbms/src/DataStreams/MaterializingBlockInputStream.cpp
+++ b/dbms/src/DataStreams/MaterializingBlockInputStream.cpp
@@ -15,11 +15,9 @@ String MaterializingBlockInputStream::getName() const
     return "Materializing";
 }
 
-String MaterializingBlockInputStream::getID() const
+Block MaterializingBlockInputStream::getHeader() const
 {
-    std::stringstream res;
-    res << "Materializing(" << children.back()->getID() << ")";
-    return res.str();
+    return materializeBlock(children.back()->getHeader());
 }
 
 Block MaterializingBlockInputStream::readImpl()
diff --git a/dbms/src/DataStreams/MaterializingBlockInputStream.h b/dbms/src/DataStreams/MaterializingBlockInputStream.h
index feeca05298e5..dfbad3b14b2e 100644
--- a/dbms/src/DataStreams/MaterializingBlockInputStream.h
+++ b/dbms/src/DataStreams/MaterializingBlockInputStream.h
@@ -12,7 +12,7 @@ class MaterializingBlockInputStream : public IProfilingBlockInputStream
 public:
     MaterializingBlockInputStream(const BlockInputStreamPtr & input);
     String getName() const override;
-    String getID() const override;
+    Block getHeader() const override;
 
 protected:
     Block readImpl() override;
diff --git a/dbms/src/DataStreams/MergeSortingBlockInputStream.h b/dbms/src/DataStreams/MergeSortingBlockInputStream.h
index 4a97d214a795..613169899d80 100644
--- a/dbms/src/DataStreams/MergeSortingBlockInputStream.h
+++ b/dbms/src/DataStreams/MergeSortingBlockInputStream.h
@@ -33,12 +33,13 @@ class MergeSortingBlocksBlockInputStream : public IProfilingBlockInputStream
         size_t max_merged_block_size_, size_t limit_ = 0);
 
     String getName() const override { return "MergeSortingBlocks"; }
-    String getID() const override { return getName(); }
 
     bool isGroupedOutput() const override { return true; }
     bool isSortedOutput() const override { return true; }
     const SortDescription & getSortDescription() const override { return description; }
 
+    Block getHeader() const override { return children.at(0)->getHeader(); }
+
 protected:
     Block readImpl() override;
 
@@ -80,22 +81,12 @@ class MergeSortingBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "MergeSorting"; }
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << "MergeSorting(" << children.back()->getID();
-
-        for (size_t i = 0; i < description.size(); ++i)
-            res << ", " << description[i].getID();
-
-        res << ")";
-        return res.str();
-    }
-
     bool isGroupedOutput() const override { return true; }
     bool isSortedOutput() const override { return true; }
     const SortDescription & getSortDescription() const override { return description; }
 
+    Block getHeader() const override { return children.at(0)->getHeader(); }
+
 protected:
     Block readImpl() override;
 
@@ -129,7 +120,7 @@ class MergeSortingBlockInputStream : public IProfilingBlockInputStream
         BlockInputStreamPtr block_in;
 
         TemporaryFileStream(const std::string & path)
-            : file_in(path), compressed_in(file_in), block_in(std::make_shared<NativeBlockInputStream>(compressed_in)) {}
+            : file_in(path), compressed_in(file_in), block_in(std::make_shared<NativeBlockInputStream>(compressed_in, 0)) {}
     };
 
     std::vector<std::unique_ptr<TemporaryFileStream>> temporary_inputs;
diff --git a/dbms/src/DataStreams/MergingAggregatedBlockInputStream.cpp b/dbms/src/DataStreams/MergingAggregatedBlockInputStream.cpp
index 63b42c319805..5586033482d8 100644
--- a/dbms/src/DataStreams/MergingAggregatedBlockInputStream.cpp
+++ b/dbms/src/DataStreams/MergingAggregatedBlockInputStream.cpp
@@ -6,6 +6,11 @@
 namespace DB
 {
 
+Block MergingAggregatedBlockInputStream::getHeader() const
+{
+    return aggregator.getHeader(final);
+}
+
 
 Block MergingAggregatedBlockInputStream::readImpl()
 {
diff --git a/dbms/src/DataStreams/MergingAggregatedBlockInputStream.h b/dbms/src/DataStreams/MergingAggregatedBlockInputStream.h
index f133524d0f15..b299aff0d1fc 100644
--- a/dbms/src/DataStreams/MergingAggregatedBlockInputStream.h
+++ b/dbms/src/DataStreams/MergingAggregatedBlockInputStream.h
@@ -22,12 +22,7 @@ class MergingAggregatedBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "MergingAggregated"; }
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << "MergingAggregated(" << children.back()->getID() << ", " << aggregator.getID() << ")";
-        return res.str();
-    }
+    Block getHeader() const override;
 
 protected:
     Block readImpl() override;
diff --git a/dbms/src/DataStreams/MergingAggregatedMemoryEfficientBlockInputStream.cpp b/dbms/src/DataStreams/MergingAggregatedMemoryEfficientBlockInputStream.cpp
index 10273caff24a..56e816cb05a7 100644
--- a/dbms/src/DataStreams/MergingAggregatedMemoryEfficientBlockInputStream.cpp
+++ b/dbms/src/DataStreams/MergingAggregatedMemoryEfficientBlockInputStream.cpp
@@ -90,14 +90,9 @@ MergingAggregatedMemoryEfficientBlockInputStream::MergingAggregatedMemoryEfficie
 }
 
 
-String MergingAggregatedMemoryEfficientBlockInputStream::getID() const
+Block MergingAggregatedMemoryEfficientBlockInputStream::getHeader() const
 {
-    std::stringstream res;
-    res << "MergingAggregatedMemoryEfficient(" << aggregator.getID();
-    for (size_t i = 0, size = children.size(); i < size; ++i)
-        res << ", " << children.back()->getID();
-    res << ")";
-    return res.str();
+    return aggregator.getHeader(final);
 }
 
 
diff --git a/dbms/src/DataStreams/MergingAggregatedMemoryEfficientBlockInputStream.h b/dbms/src/DataStreams/MergingAggregatedMemoryEfficientBlockInputStream.h
index f1300ee12af9..f7b978e9c66c 100644
--- a/dbms/src/DataStreams/MergingAggregatedMemoryEfficientBlockInputStream.h
+++ b/dbms/src/DataStreams/MergingAggregatedMemoryEfficientBlockInputStream.h
@@ -67,8 +67,6 @@ class MergingAggregatedMemoryEfficientBlockInputStream final : public IProfiling
 
     String getName() const override { return "MergingAggregatedMemoryEfficient"; }
 
-    String getID() const override;
-
     /// Sends the request (initiates calculations) earlier than `read`.
     void readPrefix() override;
 
@@ -80,6 +78,8 @@ class MergingAggregatedMemoryEfficientBlockInputStream final : public IProfiling
       */
     void cancel() override;
 
+    Block getHeader() const override;
+
 protected:
     Block readImpl() override;
 
diff --git a/dbms/src/DataStreams/MergingSortedBlockInputStream.cpp b/dbms/src/DataStreams/MergingSortedBlockInputStream.cpp
index 8ccabeb092b0..aee5b34899fb 100644
--- a/dbms/src/DataStreams/MergingSortedBlockInputStream.cpp
+++ b/dbms/src/DataStreams/MergingSortedBlockInputStream.cpp
@@ -24,28 +24,6 @@ MergingSortedBlockInputStream::MergingSortedBlockInputStream(
     children.insert(children.end(), inputs_.begin(), inputs_.end());
 }
 
-String MergingSortedBlockInputStream::getID() const
-{
-    std::stringstream res;
-    res << "MergingSorted(";
-
-    Strings children_ids(children.size());
-    for (size_t i = 0; i < children.size(); ++i)
-        children_ids[i] = children[i]->getID();
-
-    /// The order does not matter.
-    std::sort(children_ids.begin(), children_ids.end());
-
-    for (size_t i = 0; i < children_ids.size(); ++i)
-        res << (i == 0 ? "" : ", ") << children_ids[i];
-
-    for (size_t i = 0; i < description.size(); ++i)
-        res << ", " << description[i].getID();
-
-    res << ")";
-    return res.str();
-}
-
 void MergingSortedBlockInputStream::init(Block & header, MutableColumns & merged_columns)
 {
     /// Read the first blocks, initialize the queue.
diff --git a/dbms/src/DataStreams/MergingSortedBlockInputStream.h b/dbms/src/DataStreams/MergingSortedBlockInputStream.h
index 82eff68bae9a..a8e0c4bf4880 100644
--- a/dbms/src/DataStreams/MergingSortedBlockInputStream.h
+++ b/dbms/src/DataStreams/MergingSortedBlockInputStream.h
@@ -70,12 +70,12 @@ class MergingSortedBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "MergingSorted"; }
 
-    String getID() const override;
-
     bool isGroupedOutput() const override { return true; }
     bool isSortedOutput() const override { return true; }
     const SortDescription & getSortDescription() const override { return description; }
 
+    Block getHeader() const override { return children.at(0)->getHeader(); }
+
 protected:
     struct RowRef
     {
diff --git a/dbms/src/DataStreams/NativeBlockInputStream.cpp b/dbms/src/DataStreams/NativeBlockInputStream.cpp
index 0571bc08359b..1ec7c9020653 100644
--- a/dbms/src/DataStreams/NativeBlockInputStream.cpp
+++ b/dbms/src/DataStreams/NativeBlockInputStream.cpp
@@ -19,23 +19,40 @@ namespace ErrorCodes
     extern const int INCORRECT_INDEX;
     extern const int LOGICAL_ERROR;
     extern const int CANNOT_READ_ALL_DATA;
+    extern const int NOT_IMPLEMENTED;
 }
 
-NativeBlockInputStream::NativeBlockInputStream(
-    ReadBuffer & istr_, UInt64 server_revision_,
-    bool use_index_,
+
+NativeBlockInputStream::NativeBlockInputStream(ReadBuffer & istr_, UInt64 server_revision_)
+    : istr(istr_), server_revision(server_revision_)
+{
+}
+
+NativeBlockInputStream::NativeBlockInputStream(ReadBuffer & istr_, const Block & header_, UInt64 server_revision_)
+    : istr(istr_), header(header_), server_revision(server_revision_)
+{
+}
+
+NativeBlockInputStream::NativeBlockInputStream(ReadBuffer & istr_, UInt64 server_revision_,
     IndexForNativeFormat::Blocks::const_iterator index_block_it_,
     IndexForNativeFormat::Blocks::const_iterator index_block_end_)
     : istr(istr_), server_revision(server_revision_),
-    use_index(use_index_), index_block_it(index_block_it_), index_block_end(index_block_end_)
+    use_index(true), index_block_it(index_block_it_), index_block_end(index_block_end_)
 {
-    if (use_index)
-    {
-        istr_concrete = typeid_cast<CompressedReadBufferFromFile *>(&istr);
-        if (!istr_concrete)
-            throw Exception("When need to use index for NativeBlockInputStream, istr must be CompressedReadBufferFromFile.", ErrorCodes::LOGICAL_ERROR);
+    istr_concrete = typeid_cast<CompressedReadBufferFromFile *>(&istr);
+    if (!istr_concrete)
+        throw Exception("When need to use index for NativeBlockInputStream, istr must be CompressedReadBufferFromFile.", ErrorCodes::LOGICAL_ERROR);
 
-        index_column_it = index_block_it->columns.begin();
+    if (index_block_it == index_block_end)
+        return;
+
+    index_column_it = index_block_it->columns.begin();
+
+    /// Initialize header from the index.
+    for (const auto & column : index_block_it->columns)
+    {
+        auto type = DataTypeFactory::instance().get(column.type);
+        header.insert({ type->createColumn(), type, column.name });
     }
 }
 
@@ -50,6 +67,12 @@ void NativeBlockInputStream::readData(const IDataType & type, IColumn & column,
 }
 
 
+Block NativeBlockInputStream::getHeader() const
+{
+    return header;
+}
+
+
 Block NativeBlockInputStream::readImpl()
 {
     Block res;
diff --git a/dbms/src/DataStreams/NativeBlockInputStream.h b/dbms/src/DataStreams/NativeBlockInputStream.h
index b1df20a782a8..14ce18347e3a 100644
--- a/dbms/src/DataStreams/NativeBlockInputStream.h
+++ b/dbms/src/DataStreams/NativeBlockInputStream.h
@@ -60,35 +60,33 @@ struct IndexForNativeFormat
 class NativeBlockInputStream : public IProfilingBlockInputStream
 {
 public:
-    /** If a non-zero server_revision is specified, additional block information may be expected and read.
-      *
-      * `index` is not required parameter. If set, only parts of columns specified in the index will be read.
-      */
-    NativeBlockInputStream(
-        ReadBuffer & istr_, UInt64 server_revision_ = 0,
-        bool use_index_ = false,
-        IndexForNativeFormat::Blocks::const_iterator index_block_it_ = IndexForNativeFormat::Blocks::const_iterator{},
-        IndexForNativeFormat::Blocks::const_iterator index_block_end_ = IndexForNativeFormat::Blocks::const_iterator{});
+    /// If a non-zero server_revision is specified, additional block information may be expected and read.
+    NativeBlockInputStream(ReadBuffer & istr_, UInt64 server_revision_);
 
-    String getName() const override { return "Native"; }
+    /// For cases when data structure (header) is known in advance.
+    /// NOTE We may use header for data validation and/or type conversions. It is not implemented.
+    NativeBlockInputStream(ReadBuffer & istr_, const Block & header_, UInt64 server_revision_);
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << this;
-        return res.str();
-    }
+    /// For cases when we have an index. It allows to skip columns. Only columns specified in the index will be read.
+    NativeBlockInputStream(ReadBuffer & istr_, UInt64 server_revision_,
+        IndexForNativeFormat::Blocks::const_iterator index_block_it_,
+        IndexForNativeFormat::Blocks::const_iterator index_block_end_);
+
+    String getName() const override { return "Native"; }
 
     static void readData(const IDataType & type, IColumn & column, ReadBuffer & istr, size_t rows, double avg_value_size_hint);
 
+    Block getHeader() const override;
+
 protected:
     Block readImpl() override;
 
 private:
     ReadBuffer & istr;
+    Block header;
     UInt64 server_revision;
 
-    bool use_index;
+    bool use_index = false;
     IndexForNativeFormat::Blocks::const_iterator index_block_it;
     IndexForNativeFormat::Blocks::const_iterator index_block_end;
     IndexOfBlockForNativeFormat::Columns::const_iterator index_column_it;
diff --git a/dbms/src/DataStreams/NullAndDoCopyBlockInputStream.h b/dbms/src/DataStreams/NullAndDoCopyBlockInputStream.h
index cd7823f236d2..d03996be53fa 100644
--- a/dbms/src/DataStreams/NullAndDoCopyBlockInputStream.h
+++ b/dbms/src/DataStreams/NullAndDoCopyBlockInputStream.h
@@ -28,12 +28,7 @@ class NullAndDoCopyBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "NullAndDoCopy"; }
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << "copy from " << input->getID();
-        return res.str();
-    }
+    Block getHeader() const override { return {}; }
 
 protected:
     Block readImpl() override
diff --git a/dbms/src/DataStreams/NullBlockInputStream.h b/dbms/src/DataStreams/NullBlockInputStream.h
index fad7eb6629bb..9272dddd15a3 100644
--- a/dbms/src/DataStreams/NullBlockInputStream.h
+++ b/dbms/src/DataStreams/NullBlockInputStream.h
@@ -6,14 +6,19 @@
 namespace DB
 {
 
-/** Empty stream of blocks.
+/** Empty stream of blocks of specified structure.
   */
 class NullBlockInputStream : public IBlockInputStream
 {
 public:
-    Block read() override { return Block(); }
+    NullBlockInputStream(const Block & header) : header(header) {}
+
+    Block read() override { return {}; }
+    Block getHeader() const override { return header; }
     String getName() const override { return "Null"; }
 
+private:
+    Block header;
 };
 
 }
diff --git a/dbms/src/DataStreams/NullableAdapterBlockInputStream.cpp b/dbms/src/DataStreams/NullableAdapterBlockInputStream.cpp
index 50285284f213..60fe4013595c 100644
--- a/dbms/src/DataStreams/NullableAdapterBlockInputStream.cpp
+++ b/dbms/src/DataStreams/NullableAdapterBlockInputStream.cpp
@@ -17,18 +17,12 @@ namespace ErrorCodes
 NullableAdapterBlockInputStream::NullableAdapterBlockInputStream(
     const BlockInputStreamPtr & input,
     const Block & in_sample_, const Block & out_sample_)
+    : header(out_sample_)
 {
     buildActions(in_sample_, out_sample_);
     children.push_back(input);
 }
 
-String NullableAdapterBlockInputStream::getID() const
-{
-    std::stringstream res;
-    res << "NullableAdapterBlockInputStream(" << children.back()->getID() << ")";
-    return res.str();
-}
-
 Block NullableAdapterBlockInputStream::readImpl()
 {
     Block block = children.back()->read();
diff --git a/dbms/src/DataStreams/NullableAdapterBlockInputStream.h b/dbms/src/DataStreams/NullableAdapterBlockInputStream.h
index c8fd4c112925..47e064ecdf2a 100644
--- a/dbms/src/DataStreams/NullableAdapterBlockInputStream.h
+++ b/dbms/src/DataStreams/NullableAdapterBlockInputStream.h
@@ -18,12 +18,11 @@ namespace DB
 class NullableAdapterBlockInputStream : public IProfilingBlockInputStream
 {
 public:
-    NullableAdapterBlockInputStream(const BlockInputStreamPtr & input, const Block & in_sample_,
-        const Block & out_sample_);
+    NullableAdapterBlockInputStream(const BlockInputStreamPtr & input, const Block & in_sample_, const Block & out_sample_);
 
     String getName() const override { return "NullableAdapterBlockInputStream"; }
 
-    String getID() const override;
+    Block getHeader() const override { return header; }
 
 protected:
     Block readImpl() override;
@@ -52,6 +51,7 @@ class NullableAdapterBlockInputStream : public IProfilingBlockInputStream
     void buildActions(const Block & in_sample, const Block & out_sample);
 
 private:
+    Block header;
     Actions actions;
     std::vector<std::optional<String>> rename;
     bool must_transform = false;
diff --git a/dbms/src/DataStreams/OneBlockInputStream.h b/dbms/src/DataStreams/OneBlockInputStream.h
index 1a7bbe7efb8a..22480089f865 100644
--- a/dbms/src/DataStreams/OneBlockInputStream.h
+++ b/dbms/src/DataStreams/OneBlockInputStream.h
@@ -16,6 +16,14 @@ class OneBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "One"; }
 
+    Block getHeader() const override
+    {
+        Block res;
+        for (const auto & elem : block)
+            res.insert({ elem.column->cloneEmpty(), elem.type, elem.name });
+        return res;
+    }
+
 protected:
     Block readImpl() override
     {
diff --git a/dbms/src/DataStreams/OwningBlockInputStream.h b/dbms/src/DataStreams/OwningBlockInputStream.h
index 1c1d1acf3bc5..5bed4a9f9c32 100644
--- a/dbms/src/DataStreams/OwningBlockInputStream.h
+++ b/dbms/src/DataStreams/OwningBlockInputStream.h
@@ -20,13 +20,13 @@ class OwningBlockInputStream : public IProfilingBlockInputStream
         children.push_back(stream);
     }
 
+    Block getHeader() const override { return children.at(0)->getHeader(); }
+
 private:
     Block readImpl() override { return stream->read(); }
 
     String getName() const override { return "Owning"; }
 
-    String getID() const override {  return "Owning(" + stream->getID() + ")"; }
-
 protected:
     BlockInputStreamPtr stream;
     std::unique_ptr<OwnType> own;
diff --git a/dbms/src/DataStreams/ParallelAggregatingBlockInputStream.cpp b/dbms/src/DataStreams/ParallelAggregatingBlockInputStream.cpp
index 92bfe5e1f9ec..c29481671ddf 100644
--- a/dbms/src/DataStreams/ParallelAggregatingBlockInputStream.cpp
+++ b/dbms/src/DataStreams/ParallelAggregatingBlockInputStream.cpp
@@ -29,23 +29,9 @@ ParallelAggregatingBlockInputStream::ParallelAggregatingBlockInputStream(
 }
 
 
-String ParallelAggregatingBlockInputStream::getID() const
+Block ParallelAggregatingBlockInputStream::getHeader() const
 {
-    std::stringstream res;
-    res << "ParallelAggregating(";
-
-    Strings children_ids(children.size());
-    for (size_t i = 0; i < children.size(); ++i)
-        children_ids[i] = children[i]->getID();
-
-    /// Order does not matter.
-    std::sort(children_ids.begin(), children_ids.end());
-
-    for (size_t i = 0; i < children_ids.size(); ++i)
-        res << (i == 0 ? "" : ", ") << children_ids[i];
-
-    res << ", " << aggregator.getID() << ")";
-    return res.str();
+    return aggregator.getHeader(final);
 }
 
 
@@ -122,8 +108,7 @@ void ParallelAggregatingBlockInputStream::Handler::onBlock(Block & block, size_t
 {
     parent.aggregator.executeOnBlock(block, *parent.many_data[thread_num],
         parent.threads_data[thread_num].key_columns, parent.threads_data[thread_num].aggregate_columns,
-        parent.threads_data[thread_num].key_sizes, parent.threads_data[thread_num].key,
-        parent.no_more_keys);
+        parent.threads_data[thread_num].key, parent.no_more_keys);
 
     parent.threads_data[thread_num].src_rows += block.rows();
     parent.threads_data[thread_num].src_bytes += block.bytes();
diff --git a/dbms/src/DataStreams/ParallelAggregatingBlockInputStream.h b/dbms/src/DataStreams/ParallelAggregatingBlockInputStream.h
index 71a13e94ac48..a0dbb8a948b3 100644
--- a/dbms/src/DataStreams/ParallelAggregatingBlockInputStream.h
+++ b/dbms/src/DataStreams/ParallelAggregatingBlockInputStream.h
@@ -27,10 +27,10 @@ class ParallelAggregatingBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "ParallelAggregating"; }
 
-    String getID() const override;
-
     void cancel() override;
 
+    Block getHeader() const override;
+
 protected:
     /// Do nothing that preparation to execution of the query be done in parallel, in ParallelInputsProcessor.
     void readPrefix() override
@@ -83,14 +83,12 @@ class ParallelAggregatingBlockInputStream : public IProfilingBlockInputStream
         StringRefs key;
         ColumnRawPtrs key_columns;
         Aggregator::AggregateColumns aggregate_columns;
-        Sizes key_sizes;
 
         ThreadData(size_t keys_size, size_t aggregates_size)
         {
             key.resize(keys_size);
             key_columns.resize(keys_size);
             aggregate_columns.resize(aggregates_size);
-            key_sizes.resize(keys_size);
         }
     };
 
diff --git a/dbms/src/DataStreams/PartialSortingBlockInputStream.h b/dbms/src/DataStreams/PartialSortingBlockInputStream.h
index f46fa8e5ca5f..5b5001ce313b 100644
--- a/dbms/src/DataStreams/PartialSortingBlockInputStream.h
+++ b/dbms/src/DataStreams/PartialSortingBlockInputStream.h
@@ -23,22 +23,12 @@ class PartialSortingBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "PartialSorting"; }
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << "PartialSorting(" << children.back()->getID();
-
-        for (size_t i = 0; i < description.size(); ++i)
-            res << ", " << description[i].getID();
-
-        res << ")";
-        return res.str();
-    }
-
     bool isGroupedOutput() const override { return true; }
     bool isSortedOutput() const override { return true; }
     const SortDescription & getSortDescription() const override { return description; }
 
+    Block getHeader() const override { return children.at(0)->getHeader(); }
+
 protected:
     Block readImpl() override;
 
diff --git a/dbms/src/DataStreams/RemoteBlockInputStream.cpp b/dbms/src/DataStreams/RemoteBlockInputStream.cpp
index 31577f278460..311cda1727b9 100644
--- a/dbms/src/DataStreams/RemoteBlockInputStream.cpp
+++ b/dbms/src/DataStreams/RemoteBlockInputStream.cpp
@@ -2,6 +2,7 @@
 #include <DataStreams/OneBlockInputStream.h>
 #include <Common/NetException.h>
 #include <Interpreters/Context.h>
+#include <Interpreters/castColumn.h>
 #include <Storages/IStorage.h>
 
 
@@ -17,9 +18,9 @@ namespace ErrorCodes
 
 RemoteBlockInputStream::RemoteBlockInputStream(
         Connection & connection,
-        const String & query_, const Context & context_, const Settings * settings,
+        const String & query_, const Block & header_, const Context & context_, const Settings * settings,
         const ThrottlerPtr & throttler, const Tables & external_tables_, QueryProcessingStage::Enum stage_)
-    : query(query_), context(context_), external_tables(external_tables_), stage(stage_)
+    : header(header_), query(query_), context(context_), external_tables(external_tables_), stage(stage_)
 {
     if (settings)
         context.setSettings(*settings);
@@ -32,9 +33,9 @@ RemoteBlockInputStream::RemoteBlockInputStream(
 
 RemoteBlockInputStream::RemoteBlockInputStream(
         std::vector<IConnectionPool::Entry> && connections,
-        const String & query_, const Context & context_, const Settings * settings,
+        const String & query_, const Block & header_, const Context & context_, const Settings * settings,
         const ThrottlerPtr & throttler, const Tables & external_tables_, QueryProcessingStage::Enum stage_)
-    : query(query_), context(context_), external_tables(external_tables_), stage(stage_)
+    : header(header_), query(query_), context(context_), external_tables(external_tables_), stage(stage_)
 {
     if (settings)
         context.setSettings(*settings);
@@ -48,9 +49,9 @@ RemoteBlockInputStream::RemoteBlockInputStream(
 
 RemoteBlockInputStream::RemoteBlockInputStream(
         const ConnectionPoolWithFailoverPtr & pool,
-        const String & query_, const Context & context_, const Settings * settings,
+        const String & query_, const Block & header_, const Context & context_, const Settings * settings,
         const ThrottlerPtr & throttler, const Tables & external_tables_, QueryProcessingStage::Enum stage_)
-    : query(query_), context(context_), external_tables(external_tables_), stage(stage_)
+    : header(header_), query(query_), context(context_), external_tables(external_tables_), stage(stage_)
 {
     if (settings)
         context.setSettings(*settings);
@@ -148,6 +149,25 @@ void RemoteBlockInputStream::sendExternalTables()
     multiplexed_connections->sendExternalTablesData(external_tables_data);
 }
 
+
+/** If we receive a block with slightly different column types, or with excessive columns,
+  *  we will adapt it to expected structure.
+  */
+static Block adaptBlockStructure(const Block & block, const Block & header, const Context & context)
+{
+    /// Special case when reader doesn't care about result structure. Deprecated and used only in Benchmark, PerformanceTest.
+    if (!header)
+        return block;
+
+    Block res;
+    res.info = block.info;
+
+    for (const auto & elem : header)
+        res.insert({ castColumn(block.getByName(elem.name), elem.type, context), elem.type, elem.name });
+    return res;
+}
+
+
 Block RemoteBlockInputStream::readImpl()
 {
     if (!sent_query)
@@ -170,7 +190,7 @@ Block RemoteBlockInputStream::readImpl()
             case Protocol::Server::Data:
                 /// If the block is not empty and is not a header block
                 if (packet.block && (packet.block.rows() > 0))
-                    return packet.block;
+                    return adaptBlockStructure(packet.block, header, context);
                 break;  /// If the block is empty - we will receive other packets before EndOfStream.
 
             case Protocol::Server::Exception:
diff --git a/dbms/src/DataStreams/RemoteBlockInputStream.h b/dbms/src/DataStreams/RemoteBlockInputStream.h
index 2ee6aa2c6a50..8c3cff4f494f 100644
--- a/dbms/src/DataStreams/RemoteBlockInputStream.h
+++ b/dbms/src/DataStreams/RemoteBlockInputStream.h
@@ -24,7 +24,7 @@ class RemoteBlockInputStream : public IProfilingBlockInputStream
     /// If `settings` is nullptr, settings will be taken from context.
     RemoteBlockInputStream(
             Connection & connection,
-            const String & query_, const Context & context_, const Settings * settings = nullptr,
+            const String & query_, const Block & header_, const Context & context_, const Settings * settings = nullptr,
             const ThrottlerPtr & throttler = nullptr, const Tables & external_tables_ = Tables(),
             QueryProcessingStage::Enum stage_ = QueryProcessingStage::Complete);
 
@@ -32,7 +32,7 @@ class RemoteBlockInputStream : public IProfilingBlockInputStream
     /// If `settings` is nullptr, settings will be taken from context.
     RemoteBlockInputStream(
             std::vector<IConnectionPool::Entry> && connections,
-            const String & query_, const Context & context_, const Settings * settings = nullptr,
+            const String & query_, const Block & header_, const Context & context_, const Settings * settings = nullptr,
             const ThrottlerPtr & throttler = nullptr, const Tables & external_tables_ = Tables(),
             QueryProcessingStage::Enum stage_ = QueryProcessingStage::Complete);
 
@@ -40,7 +40,7 @@ class RemoteBlockInputStream : public IProfilingBlockInputStream
     /// If `settings` is nullptr, settings will be taken from context.
     RemoteBlockInputStream(
             const ConnectionPoolWithFailoverPtr & pool,
-            const String & query_, const Context & context_, const Settings * settings = nullptr,
+            const String & query_, const Block & header_, const Context & context_, const Settings * settings = nullptr,
             const ThrottlerPtr & throttler = nullptr, const Tables & external_tables_ = Tables(),
             QueryProcessingStage::Enum stage_ = QueryProcessingStage::Complete);
 
@@ -66,18 +66,13 @@ class RemoteBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "Remote"; }
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << this;
-        return res.str();
-    }
-
     BlockExtraInfo getBlockExtraInfo() const override
     {
         return multiplexed_connections->getBlockExtraInfo();
     }
 
+    Block getHeader() const override { return header; }
+
 protected:
     /// Send all temporary tables to remote servers
     void sendExternalTables();
@@ -95,10 +90,14 @@ class RemoteBlockInputStream : public IProfilingBlockInputStream
 private:
     void sendQuery();
 
+    Block receiveBlock();
+
     /// If wasn't sent yet, send request to cancell all connections to replicas
     void tryCancel(const char * reason);
 
 private:
+    Block header;
+
     std::function<std::unique_ptr<MultiplexedConnections>()> create_multiplexed_connections;
 
     std::unique_ptr<MultiplexedConnections> multiplexed_connections;
diff --git a/dbms/src/DataStreams/RemoveColumnsBlockInputStream.h b/dbms/src/DataStreams/RemoveColumnsBlockInputStream.h
index c8888440e282..a8b549622093 100644
--- a/dbms/src/DataStreams/RemoveColumnsBlockInputStream.h
+++ b/dbms/src/DataStreams/RemoveColumnsBlockInputStream.h
@@ -22,16 +22,15 @@ class RemoveColumnsBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "RemoveColumns"; }
 
-    String getID() const override
+    Block getHeader() const override
     {
-        std::stringstream res;
-        res << "RemoveColumns(" << children.back()->getID();
+        Block res = children.back()->getHeader();
 
         for (const auto & it : columns_to_remove)
-            res << ", " << it;
+            if (res.has(it))
+                res.erase(it);
 
-        res << ")";
-        return res.str();
+        return res;
     }
 
 protected:
diff --git a/dbms/src/DataStreams/ReplacingSortedBlockInputStream.h b/dbms/src/DataStreams/ReplacingSortedBlockInputStream.h
index 0e7fdadc25ac..0ab6b1858334 100644
--- a/dbms/src/DataStreams/ReplacingSortedBlockInputStream.h
+++ b/dbms/src/DataStreams/ReplacingSortedBlockInputStream.h
@@ -24,23 +24,6 @@ class ReplacingSortedBlockInputStream : public MergingSortedBlockInputStream
 
     String getName() const override { return "ReplacingSorted"; }
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << "ReplacingSorted(inputs";
-
-        for (size_t i = 0; i < children.size(); ++i)
-            res << ", " << children[i]->getID();
-
-        res << ", description";
-
-        for (size_t i = 0; i < description.size(); ++i)
-            res << ", " << description[i].getID();
-
-        res << ", version_column, " << version_column << ")";
-        return res.str();
-    }
-
 protected:
     /// Can return 1 more records than max_block_size.
     Block readImpl() override;
diff --git a/dbms/src/DataStreams/SquashingBlockInputStream.h b/dbms/src/DataStreams/SquashingBlockInputStream.h
index 3da819d21677..0f9a01d65e8c 100644
--- a/dbms/src/DataStreams/SquashingBlockInputStream.h
+++ b/dbms/src/DataStreams/SquashingBlockInputStream.h
@@ -16,12 +16,7 @@ class SquashingBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "Squashing"; }
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << "Squashing(" << children.at(0)->getID() << ")";
-        return res.str();
-    }
+    Block getHeader() const override { return children.at(0)->getHeader(); }
 
 protected:
     Block readImpl() override;
diff --git a/dbms/src/DataStreams/SummingSortedBlockInputStream.cpp b/dbms/src/DataStreams/SummingSortedBlockInputStream.cpp
index 42dffd5babf8..1102258d3482 100644
--- a/dbms/src/DataStreams/SummingSortedBlockInputStream.cpp
+++ b/dbms/src/DataStreams/SummingSortedBlockInputStream.cpp
@@ -23,24 +23,6 @@ namespace ErrorCodes
 }
 
 
-String SummingSortedBlockInputStream::getID() const
-{
-    std::stringstream res;
-    res << "SummingSorted(inputs";
-
-    for (size_t i = 0; i < children.size(); ++i)
-        res << ", " << children[i]->getID();
-
-    res << ", description";
-
-    for (size_t i = 0; i < description.size(); ++i)
-        res << ", " << description[i].getID();
-
-    res << ")";
-    return res.str();
-}
-
-
 void SummingSortedBlockInputStream::insertCurrentRowIfNeeded(MutableColumns & merged_columns, bool force_insertion)
 {
     for (auto & desc : columns_to_aggregate)
diff --git a/dbms/src/DataStreams/SummingSortedBlockInputStream.h b/dbms/src/DataStreams/SummingSortedBlockInputStream.h
index 6a81db02ea4d..62df3863fc66 100644
--- a/dbms/src/DataStreams/SummingSortedBlockInputStream.h
+++ b/dbms/src/DataStreams/SummingSortedBlockInputStream.h
@@ -35,8 +35,6 @@ class SummingSortedBlockInputStream : public MergingSortedBlockInputStream
 
     String getName() const override { return "SummingSorted"; }
 
-    String getID() const override;
-
 protected:
     /// Can return 1 more records than max_block_size.
     Block readImpl() override;
diff --git a/dbms/src/DataStreams/TotalsHavingBlockInputStream.cpp b/dbms/src/DataStreams/TotalsHavingBlockInputStream.cpp
index 4692dc6df57b..b204afc2944d 100644
--- a/dbms/src/DataStreams/TotalsHavingBlockInputStream.cpp
+++ b/dbms/src/DataStreams/TotalsHavingBlockInputStream.cpp
@@ -1,6 +1,7 @@
 #include <DataStreams/TotalsHavingBlockInputStream.h>
 #include <Interpreters/ExpressionActions.h>
 #include <Interpreters/AggregateDescription.h>
+#include <DataTypes/DataTypeAggregateFunction.h>
 #include <Columns/ColumnAggregateFunction.h>
 #include <Columns/ColumnsNumber.h>
 #include <Columns/FilterDescription.h>
@@ -29,26 +30,18 @@ TotalsHavingBlockInputStream::TotalsHavingBlockInputStream(
 }
 
 
-String TotalsHavingBlockInputStream::getID() const
-{
-    std::stringstream res;
-    res << "TotalsHavingBlockInputStream(" << children.back()->getID()
-        << "," << filter_column_name << ")";
-    return res.str();
-}
-
-
 static void finalize(Block & block)
 {
     for (size_t i = 0; i < block.columns(); ++i)
     {
         ColumnWithTypeAndName & current = block.safeGetByPosition(i);
-        const ColumnAggregateFunction * unfinalized_column = typeid_cast<const ColumnAggregateFunction *>(current.column.get());
+        const DataTypeAggregateFunction * unfinalized_type = typeid_cast<const DataTypeAggregateFunction *>(current.type.get());
 
-        if (unfinalized_column)
+        if (unfinalized_type)
         {
-            current.type = unfinalized_column->getAggregateFunction()->getReturnType();
-            current.column = unfinalized_column->convertToValues();
+            current.type = unfinalized_type->getReturnType();
+            if (current.column)
+                current.column = typeid_cast<const ColumnAggregateFunction &>(*current.column).convertToValues();
         }
     }
 }
@@ -70,7 +63,7 @@ const Block & TotalsHavingBlockInputStream::getTotals()
                 addToTotals(overflow_aggregates, nullptr);
         }
 
-        totals = header.cloneWithColumns(std::move(current_totals));
+        totals = children.at(0)->getHeader().cloneWithColumns(std::move(current_totals));
         finalize(totals);
     }
 
@@ -81,6 +74,16 @@ const Block & TotalsHavingBlockInputStream::getTotals()
 }
 
 
+Block TotalsHavingBlockInputStream::getHeader() const
+{
+    Block res = children.at(0)->getHeader();
+    finalize(res);
+    if (expression)
+        expression->execute(res);
+    return res;
+}
+
+
 Block TotalsHavingBlockInputStream::readImpl()
 {
     Block finalized;
@@ -90,9 +93,6 @@ Block TotalsHavingBlockInputStream::readImpl()
     {
         block = children[0]->read();
 
-        if (!header)
-            header = block.cloneEmpty();
-
         /// Block with values not included in `max_rows_to_group_by`. We'll postpone it.
         if (overflow_row && block && block.info.is_overflows)
         {
diff --git a/dbms/src/DataStreams/TotalsHavingBlockInputStream.h b/dbms/src/DataStreams/TotalsHavingBlockInputStream.h
index 1cc257983cb5..375854c5761a 100644
--- a/dbms/src/DataStreams/TotalsHavingBlockInputStream.h
+++ b/dbms/src/DataStreams/TotalsHavingBlockInputStream.h
@@ -19,6 +19,7 @@ class TotalsHavingBlockInputStream : public IProfilingBlockInputStream
     using ExpressionActionsPtr = std::shared_ptr<ExpressionActions>;
 
 public:
+    /// expression may be nullptr
     TotalsHavingBlockInputStream(
         const BlockInputStreamPtr & input_,
         bool overflow_row_, const ExpressionActionsPtr & expression_,
@@ -26,10 +27,10 @@ class TotalsHavingBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "TotalsHaving"; }
 
-    String getID() const override;
-
     const Block & getTotals() override;
 
+    Block getHeader() const override;
+
 protected:
     Block readImpl() override;
 
@@ -42,8 +43,6 @@ class TotalsHavingBlockInputStream : public IProfilingBlockInputStream
     size_t passed_keys = 0;
     size_t total_keys = 0;
 
-    Block header;
-
     /** Here are the values that did not pass max_rows_to_group_by.
       * They are added or not added to the current_totals, depending on the totals_mode.
       */
diff --git a/dbms/src/DataStreams/UnionBlockInputStream.h b/dbms/src/DataStreams/UnionBlockInputStream.h
index 60639002e9f2..176cb472a617 100644
--- a/dbms/src/DataStreams/UnionBlockInputStream.h
+++ b/dbms/src/DataStreams/UnionBlockInputStream.h
@@ -86,26 +86,6 @@ class UnionBlockInputStream final : public IProfilingBlockInputStream
 
     String getName() const override { return "Union"; }
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << "Union(";
-
-        Strings children_ids(children.size());
-        for (size_t i = 0; i < children.size(); ++i)
-            children_ids[i] = children[i]->getID();
-
-        /// Order does not matter.
-        std::sort(children_ids.begin(), children_ids.end());
-
-        for (size_t i = 0; i < children_ids.size(); ++i)
-            res << (i == 0 ? "" : ", ") << children_ids[i];
-
-        res << ")";
-        return res.str();
-    }
-
-
     ~UnionBlockInputStream() override
     {
         try
@@ -139,6 +119,8 @@ class UnionBlockInputStream final : public IProfilingBlockInputStream
         return doGetBlockExtraInfo();
     }
 
+    Block getHeader() const override { return children.at(0)->getHeader(); }
+
 protected:
     void finalize()
     {
diff --git a/dbms/src/DataStreams/VersionedCollapsingSortedBlockInputStream.h b/dbms/src/DataStreams/VersionedCollapsingSortedBlockInputStream.h
index ec75e218533b..1c299e78e81d 100644
--- a/dbms/src/DataStreams/VersionedCollapsingSortedBlockInputStream.h
+++ b/dbms/src/DataStreams/VersionedCollapsingSortedBlockInputStream.h
@@ -185,24 +185,6 @@ class VersionedCollapsingSortedBlockInputStream : public MergingSortedBlockInput
 
     String getName() const override { return "VersionedCollapsingSorted"; }
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << "VersionedCollapsingSortedBlockInputStream(inputs";
-
-        for (const auto & child : children)
-            res << ", " << child->getID();
-
-        res << ", description";
-
-        for (const auto & descr : description)
-            res << ", " << descr.getID();
-
-        res << ", sign_column, " << sign_column;
-        res << ", version_column, " << sign_column << ")";
-        return res.str();
-    }
-
 protected:
     /// Can return 1 more records than max_block_size.
     Block readImpl() override;
diff --git a/dbms/src/DataTypes/DataTypeEnum.h b/dbms/src/DataTypes/DataTypeEnum.h
index ea939c9f709e..a4cc36b1c922 100644
--- a/dbms/src/DataTypes/DataTypeEnum.h
+++ b/dbms/src/DataTypes/DataTypeEnum.h
@@ -112,7 +112,7 @@ class DataTypeEnum final : public IDataTypeEnum
     bool equals(const IDataType & rhs) const override;
 
     bool textCanContainOnlyValidUTF8() const override;
-    size_t getSizeOfValueInMemory() const override { return sizeof(Field); }
+    size_t getSizeOfValueInMemory() const override { return sizeof(FieldType); }
 };
 
 
diff --git a/dbms/src/Dictionaries/ClickHouseDictionarySource.cpp b/dbms/src/Dictionaries/ClickHouseDictionarySource.cpp
index 039126b458fb..f487aac36446 100644
--- a/dbms/src/Dictionaries/ClickHouseDictionarySource.cpp
+++ b/dbms/src/Dictionaries/ClickHouseDictionarySource.cpp
@@ -73,7 +73,7 @@ BlockInputStreamPtr ClickHouseDictionarySource::loadAll()
       */
     if (is_local)
         return executeQuery(load_all_query, context, true).in;
-    return std::make_shared<RemoteBlockInputStream>(pool, load_all_query, context);
+    return std::make_shared<RemoteBlockInputStream>(pool, load_all_query, sample_block, context);
 }
 
 
@@ -103,7 +103,7 @@ BlockInputStreamPtr ClickHouseDictionarySource::createStreamForSelectiveLoad(con
 {
     if (is_local)
         return executeQuery(query, context, true).in;
-    return std::make_shared<RemoteBlockInputStream>(pool, query, context);
+    return std::make_shared<RemoteBlockInputStream>(pool, query, sample_block, context);
 }
 
 }
diff --git a/dbms/src/Dictionaries/DictionaryBlockInputStreamBase.cpp b/dbms/src/Dictionaries/DictionaryBlockInputStreamBase.cpp
index 468d91a231d4..813504b084df 100644
--- a/dbms/src/Dictionaries/DictionaryBlockInputStreamBase.cpp
+++ b/dbms/src/Dictionaries/DictionaryBlockInputStreamBase.cpp
@@ -8,13 +8,6 @@ DictionaryBlockInputStreamBase::DictionaryBlockInputStreamBase(size_t rows_count
 {
 }
 
-String DictionaryBlockInputStreamBase::getID() const
-{
-    std::stringstream ss;
-    ss << static_cast<const void*>(this);
-    return ss.str();
-}
-
 Block DictionaryBlockInputStreamBase::readImpl()
 {
     if (next_row == rows_count)
@@ -26,4 +19,9 @@ Block DictionaryBlockInputStreamBase::readImpl()
     return block;
 }
 
+Block DictionaryBlockInputStreamBase::getHeader() const
+{
+    return getBlock(0, 0);
+}
+
 }
diff --git a/dbms/src/Dictionaries/DictionaryBlockInputStreamBase.h b/dbms/src/Dictionaries/DictionaryBlockInputStreamBase.h
index 6f34f73c957e..ea027026d3f7 100644
--- a/dbms/src/Dictionaries/DictionaryBlockInputStreamBase.h
+++ b/dbms/src/Dictionaries/DictionaryBlockInputStreamBase.h
@@ -11,17 +11,16 @@ class DictionaryBlockInputStreamBase : public IProfilingBlockInputStream
 
     DictionaryBlockInputStreamBase(size_t rows_count, size_t max_block_size);
 
-    String getID() const override;
-
     virtual Block getBlock(size_t start, size_t length) const = 0;
 
+    Block getHeader() const override;
+
 private:
     const size_t rows_count;
     const size_t max_block_size;
-    size_t next_row;
+    size_t next_row = 0;
 
     Block readImpl() override;
-    void readPrefixImpl() override { next_row = 0; }
 };
 
 }
diff --git a/dbms/src/Dictionaries/ExecutableDictionarySource.cpp b/dbms/src/Dictionaries/ExecutableDictionarySource.cpp
index 58b7445eb380..35ac7b4cbf93 100644
--- a/dbms/src/Dictionaries/ExecutableDictionarySource.cpp
+++ b/dbms/src/Dictionaries/ExecutableDictionarySource.cpp
@@ -101,6 +101,8 @@ class BlockInputStreamWithBackgroundThread final : public IProfilingBlockInputSt
         }
     }
 
+    Block getHeader() const override { return stream->getHeader(); };
+
 private:
     Block readImpl() override { return stream->read(); }
 
@@ -118,7 +120,6 @@ class BlockInputStreamWithBackgroundThread final : public IProfilingBlockInputSt
     }
 
     String getName() const override { return "WithBackgroundThread"; }
-    String getID() const override { return "WithBackgroundThread(" + stream->getID() + ")"; }
 
     BlockInputStreamPtr stream;
     std::unique_ptr<ShellCommand> command;
diff --git a/dbms/src/Dictionaries/MongoDBBlockInputStream.cpp b/dbms/src/Dictionaries/MongoDBBlockInputStream.cpp
index 9f13b8c345b6..b5f1d1f6f697 100644
--- a/dbms/src/Dictionaries/MongoDBBlockInputStream.cpp
+++ b/dbms/src/Dictionaries/MongoDBBlockInputStream.cpp
@@ -38,14 +38,6 @@ MongoDBBlockInputStream::MongoDBBlockInputStream(
 MongoDBBlockInputStream::~MongoDBBlockInputStream() = default;
 
 
-String MongoDBBlockInputStream::getID() const
-{
-    std::ostringstream stream;
-    stream << cursor.get();
-    return "MongoDB(@" + stream.str() + ")";
-}
-
-
 namespace
 {
     using ValueType = ExternalResultDescription::ValueType;
diff --git a/dbms/src/Dictionaries/MongoDBBlockInputStream.h b/dbms/src/Dictionaries/MongoDBBlockInputStream.h
index 25ba14d91459..046e3429b714 100644
--- a/dbms/src/Dictionaries/MongoDBBlockInputStream.h
+++ b/dbms/src/Dictionaries/MongoDBBlockInputStream.h
@@ -32,7 +32,7 @@ class MongoDBBlockInputStream final : public IProfilingBlockInputStream
 
     String getName() const override { return "MongoDB"; }
 
-    String getID() const override;
+    Block getHeader() const override { return description.sample_block; };
 
 private:
     Block readImpl() override;
diff --git a/dbms/src/Dictionaries/MySQLBlockInputStream.cpp b/dbms/src/Dictionaries/MySQLBlockInputStream.cpp
index f0c304343d2d..6e2275cd1059 100644
--- a/dbms/src/Dictionaries/MySQLBlockInputStream.cpp
+++ b/dbms/src/Dictionaries/MySQLBlockInputStream.cpp
@@ -33,12 +33,6 @@ MySQLBlockInputStream::MySQLBlockInputStream(
 }
 
 
-String MySQLBlockInputStream::getID() const
-{
-    return "MySQL(" + query.str() + ")";
-}
-
-
 namespace
 {
     using ValueType = ExternalResultDescription::ValueType;
diff --git a/dbms/src/Dictionaries/MySQLBlockInputStream.h b/dbms/src/Dictionaries/MySQLBlockInputStream.h
index 1013507f11ef..6e72f4eb3cf0 100644
--- a/dbms/src/Dictionaries/MySQLBlockInputStream.h
+++ b/dbms/src/Dictionaries/MySQLBlockInputStream.h
@@ -21,7 +21,7 @@ class MySQLBlockInputStream final : public IProfilingBlockInputStream
 
     String getName() const override { return "MySQL"; }
 
-    String getID() const override;
+    Block getHeader() const override { return description.sample_block; };
 
 private:
     Block readImpl() override;
diff --git a/dbms/src/Dictionaries/ODBCBlockInputStream.cpp b/dbms/src/Dictionaries/ODBCBlockInputStream.cpp
index 3f564d942b47..8b186f6791ee 100644
--- a/dbms/src/Dictionaries/ODBCBlockInputStream.cpp
+++ b/dbms/src/Dictionaries/ODBCBlockInputStream.cpp
@@ -38,12 +38,6 @@ ODBCBlockInputStream::ODBCBlockInputStream(
 }
 
 
-String ODBCBlockInputStream::getID() const
-{
-    return "ODBC(" + statement.toString() + ")";
-}
-
-
 namespace
 {
     using ValueType = ExternalResultDescription::ValueType;
diff --git a/dbms/src/Dictionaries/ODBCBlockInputStream.h b/dbms/src/Dictionaries/ODBCBlockInputStream.h
index 558f5cb56731..b881beb9b1f9 100644
--- a/dbms/src/Dictionaries/ODBCBlockInputStream.h
+++ b/dbms/src/Dictionaries/ODBCBlockInputStream.h
@@ -27,7 +27,7 @@ class ODBCBlockInputStream final : public IProfilingBlockInputStream
 
     String getName() const override { return "ODBC"; }
 
-    String getID() const override;
+    Block getHeader() const override { return description.sample_block; };
 
 private:
     Block readImpl() override;
diff --git a/dbms/src/Functions/FunctionsArray.cpp b/dbms/src/Functions/FunctionsArray.cpp
index 3db0e32e7948..27d5d3688e84 100644
--- a/dbms/src/Functions/FunctionsArray.cpp
+++ b/dbms/src/Functions/FunctionsArray.cpp
@@ -23,6 +23,7 @@
 #include <DataTypes/getMostSubtype.h>
 #include <Core/TypeListNumber.h>
 
+
 namespace DB
 {
 
@@ -156,7 +157,7 @@ class NullMapBuilder
         ++index;
     }
 
-    ColumnPtr getNullMapData() && { return std::move(sink_null_map_holder); }
+    ColumnPtr getNullMapColumnPtr() && { return std::move(sink_null_map_holder); }
 
 private:
     const UInt8 * src_null_map = nullptr;
@@ -776,25 +777,25 @@ DataTypePtr FunctionArrayElement::getReturnTypeImpl(const DataTypes & arguments)
 void FunctionArrayElement::executeImpl(Block & block, const ColumnNumbers & arguments, size_t result)
 {
     /// Check nullability.
-    bool is_nullable_array = false;
+    bool is_array_of_nullable = false;
 
     const ColumnArray * col_array = nullptr;
     const ColumnArray * col_const_array = nullptr;
 
     col_array = checkAndGetColumn<ColumnArray>(block.getByPosition(arguments[0]).column.get());
     if (col_array)
-        is_nullable_array = col_array->getData().isColumnNullable();
+        is_array_of_nullable = col_array->getData().isColumnNullable();
     else
     {
         col_const_array = checkAndGetColumnConstData<ColumnArray>(block.getByPosition(arguments[0]).column.get());
         if (col_const_array)
-            is_nullable_array = col_const_array->getData().isColumnNullable();
+            is_array_of_nullable = col_const_array->getData().isColumnNullable();
         else
             throw Exception("Illegal column " + block.getByPosition(arguments[0]).column->getName()
             + " of first argument of function " + getName(), ErrorCodes::ILLEGAL_COLUMN);
     }
 
-    if (!is_nullable_array)
+    if (!is_array_of_nullable)
     {
         ArrayImpl::NullMapBuilder builder;
         perform(block, arguments, result, builder);
@@ -860,7 +861,7 @@ void FunctionArrayElement::executeImpl(Block & block, const ColumnNumbers & argu
         /// Store the result.
         const ColumnWithTypeAndName & source_col = source_block.getByPosition(2);
         ColumnWithTypeAndName & dest_col = block.getByPosition(result);
-        dest_col.column = ColumnNullable::create(source_col.column, std::move(builder).getNullMapData());
+        dest_col.column = ColumnNullable::create(source_col.column, builder ? std::move(builder).getNullMapColumnPtr() : ColumnUInt8::create());
     }
 }
 
diff --git a/dbms/src/Functions/FunctionsConversion.h b/dbms/src/Functions/FunctionsConversion.h
index 8f3edca53eed..00884ca0ffb4 100644
--- a/dbms/src/Functions/FunctionsConversion.h
+++ b/dbms/src/Functions/FunctionsConversion.h
@@ -53,6 +53,13 @@ namespace ErrorCodes
     extern const int CANNOT_PARSE_UUID;
     extern const int TOO_LARGE_STRING_SIZE;
     extern const int TOO_LESS_ARGUMENTS_FOR_FUNCTION;
+    extern const int LOGICAL_ERROR;
+    extern const int TYPE_MISMATCH;
+    extern const int CANNOT_CONVERT_TYPE;
+    extern const int ILLEGAL_COLUMN;
+    extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;
+    extern const int ILLEGAL_TYPE_OF_ARGUMENT;
+    extern const int NOT_IMPLEMENTED;
 }
 
 
@@ -508,9 +515,6 @@ struct ConvertImplGenericFromString
         {
             auto res = data_type_to.createColumn();
 
-            if (!size)
-                return;
-
             IColumn & column_to = *res;
             column_to.reserve(size);
 
@@ -1272,9 +1276,7 @@ class FunctionCast final : public IFunctionBase
     static WrapperType createFixedStringWrapper(const DataTypePtr & from_type, const size_t N)
     {
         if (!from_type->isStringOrFixedString())
-            throw Exception{
-                "CAST AS FixedString is only implemented for types String and FixedString",
-                ErrorCodes::NOT_IMPLEMENTED};
+            throw Exception{"CAST AS FixedString is only implemented for types String and FixedString", ErrorCodes::NOT_IMPLEMENTED};
 
         return [N] (Block & block, const ColumnNumbers & arguments, const size_t result)
         {
@@ -1309,9 +1311,7 @@ class FunctionCast final : public IFunctionBase
 
         /// both from_type and to_type should be nullptr now is array types had same dimensions
         if ((from_type == nullptr) != (to_type == nullptr))
-            throw Exception{
-                "CAST AS Array can only be performed between same-dimensional array types or from String",
-                ErrorCodes::TYPE_MISMATCH};
+            throw Exception{"CAST AS Array can only be performed between same-dimensional array types or from String", ErrorCodes::TYPE_MISMATCH};
 
         /// Prepare nested type conversion
         const auto nested_function = prepare(from_nested_type, to_nested_type.get());
@@ -1337,9 +1337,7 @@ class FunctionCast final : public IFunctionBase
                 block.getByPosition(result).column = ColumnArray::create(nested_block.getByPosition(1).column, col_array->getOffsetsPtr());
             }
             else
-                throw Exception{
-                    "Illegal column " + array_arg.column->getName() + " for function CAST AS Array",
-                    ErrorCodes::LOGICAL_ERROR};
+                throw Exception{"Illegal column " + array_arg.column->getName() + " for function CAST AS Array", ErrorCodes::LOGICAL_ERROR};
         };
     }
 
@@ -1356,16 +1354,12 @@ class FunctionCast final : public IFunctionBase
 
         const auto from_type = checkAndGetDataType<DataTypeTuple>(from_type_untyped.get());
         if (!from_type)
-            throw Exception{
-                "CAST AS Tuple can only be performed between tuple types or from String.
Left type: " + from_type_untyped->getName() +
-                    ", right type: " + to_type->getName(),
-                ErrorCodes::TYPE_MISMATCH};
+            throw Exception{"CAST AS Tuple can only be performed between tuple types or from String.
Left type: " + from_type_untyped->getName() +
+                ", right type: " + to_type->getName(), ErrorCodes::TYPE_MISMATCH};
 
         if (from_type->getElements().size() != to_type->getElements().size())
-            throw Exception{
-                "CAST AS Tuple can only be performed between tuple types with the same number of elements or from String.
"
-                    "Left type: " + from_type->getName() + ", right type: " + to_type->getName(),
-                 ErrorCodes::TYPE_MISMATCH};
+            throw Exception{"CAST AS Tuple can only be performed between tuple types with the same number of elements or from String.
"
+                "Left type: " + from_type->getName() + ", right type: " + to_type->getName(), ErrorCodes::TYPE_MISMATCH};
 
         const auto & from_element_types = from_type->getElements();
         const auto & to_element_types = to_type->getElements();
@@ -1441,10 +1435,8 @@ class FunctionCast final : public IFunctionBase
             };
         }
         else
-            throw Exception{
-                "Conversion from " + from_type->getName() + " to " + to_type->getName() +
-                    " is not supported",
-                ErrorCodes::CANNOT_CONVERT_TYPE};
+            throw Exception{"Conversion from " + from_type->getName() + " to " + to_type->getName() +
+                " is not supported", ErrorCodes::CANNOT_CONVERT_TYPE};
     }
 
     template <typename EnumTypeFrom, typename EnumTypeTo>
@@ -1467,10 +1459,8 @@ class FunctionCast final : public IFunctionBase
             const auto & old_value = name_value.second;
             const auto & new_value = to_type->getValue(name_value.first);
             if (old_value != new_value)
-                throw Exception{
-                    "Enum conversion changes value for element '" + name_value.first +
-                        "' from " + toString(old_value) + " to " + toString(new_value),
-                    ErrorCodes::CANNOT_CONVERT_TYPE};
+                throw Exception{"Enum conversion changes value for element '" + name_value.first +
+                    "' from " + toString(old_value) + " to " + toString(new_value), ErrorCodes::CANNOT_CONVERT_TYPE};
         }
     };
 
@@ -1499,8 +1489,7 @@ class FunctionCast final : public IFunctionBase
                 col_with_type_and_name.column = std::move(res);
             }
             else
-                throw Exception{
-                    "Unexpected column " + first_col->getName() + " as first argument of function " + function_name,
+                throw Exception{"Unexpected column " + first_col->getName() + " as first argument of function " + function_name,
                     ErrorCodes::LOGICAL_ERROR};
         };
     }
@@ -1540,8 +1529,7 @@ class FunctionCast final : public IFunctionBase
 
         /// Check that the requested conversion is allowed.
         if (nullable_conversion.source_is_nullable && !nullable_conversion.result_is_nullable)
-            throw Exception{"Cannot convert data from a nullable type to a non-nullable type",
-                ErrorCodes::CANNOT_CONVERT_TYPE};
+            throw Exception{"Cannot convert data from a nullable type to a non-nullable type", ErrorCodes::CANNOT_CONVERT_TYPE};
 
         if (from_type->onlyNull())
         {
@@ -1671,9 +1659,7 @@ class FunctionCast final : public IFunctionBase
         /// It's possible to use ConvertImplGenericFromString to convert from String to AggregateFunction,
         ///  but it is disabled because deserializing aggregate functions state might be unsafe.
 
-        throw Exception{
-            "Conversion from " + from_type->getName() + " to " + to_type->getName() + " is not supported",
-            ErrorCodes::CANNOT_CONVERT_TYPE};
+        throw Exception{"Conversion from " + from_type->getName() + " to " + to_type->getName() + " is not supported", ErrorCodes::CANNOT_CONVERT_TYPE};
     }
 };
 
@@ -1709,8 +1695,7 @@ class FunctionBuilderCast : public FunctionBuilderImpl
     {
         const auto type_col = checkAndGetColumnConst<ColumnString>(arguments.back().column.get());
         if (!type_col)
-            throw Exception("Second argument to " + getName() + " must be a constant string describing type",
-                            ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT);
+            throw Exception("Second argument to " + getName() + " must be a constant string describing type", ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT);
 
         return DataTypeFactory::instance().get(type_col->getValue<String>());
     }
diff --git a/dbms/src/Functions/FunctionsHigherOrder.cpp b/dbms/src/Functions/FunctionsHigherOrder.cpp
index 567a80f195b2..a78769b061a0 100644
--- a/dbms/src/Functions/FunctionsHigherOrder.cpp
+++ b/dbms/src/Functions/FunctionsHigherOrder.cpp
@@ -17,7 +17,6 @@ void registerFunctionsHigherOrder(FunctionFactory & factory)
     factory.registerFunction<FunctionArraySort>();
     factory.registerFunction<FunctionArrayReverseSort>();
     factory.registerFunction<FunctionArrayCumSum>();
-
 }
 
 }
diff --git a/dbms/src/Functions/FunctionsMiscellaneous.cpp b/dbms/src/Functions/FunctionsMiscellaneous.cpp
index 9c2f94c97a2d..58ca5ce1d2d4 100644
--- a/dbms/src/Functions/FunctionsMiscellaneous.cpp
+++ b/dbms/src/Functions/FunctionsMiscellaneous.cpp
@@ -599,29 +599,16 @@ class FunctionSleep : public IFunction
     void executeImpl(Block & block, const ColumnNumbers & arguments, size_t result) override
     {
         const IColumn * col = block.getByPosition(arguments[0]).column.get();
-        double seconds;
-        size_t size = col->size();
-
-        if (auto column = checkAndGetColumnConst<ColumnVector<Float64>>(col))
-            seconds = column->getValue<Float64>();
-
-        else if (auto column = checkAndGetColumnConst<ColumnVector<Float32>>(col))
-            seconds = static_cast<double>(column->getValue<Float64>());
-
-        else if (auto column = checkAndGetColumnConst<ColumnVector<UInt64>>(col))
-            seconds = static_cast<double>(column->getValue<UInt64>());
 
-        else if (auto column = checkAndGetColumnConst<ColumnVector<UInt32>>(col))
-            seconds = static_cast<double>(column->getValue<UInt32>());
+        if (!col->isColumnConst())
+            throw Exception("The argument of function " + getName() + " must be constant.", ErrorCodes::ILLEGAL_COLUMN);
 
-        else if (auto column = checkAndGetColumnConst<ColumnVector<UInt16>>(col))
-            seconds = static_cast<double>(column->getValue<UInt16>());
+        Float64 seconds = applyVisitor(FieldVisitorConvertToNumber<Float64>(), static_cast<const ColumnConst &>(*col).getField());
 
-        else if (auto column = checkAndGetColumnConst<ColumnVector<UInt8>>(col))
-            seconds = static_cast<double>(column->getValue<UInt8>());
+        if (seconds < 0)
+            throw Exception("Cannot sleep negative amount of time (not implemented)", ErrorCodes::BAD_ARGUMENTS);
 
-        else
-            throw Exception("The argument of function " + getName() + " must be constant.", ErrorCodes::ILLEGAL_COLUMN);
+        size_t size = col->size();
 
         /// We do not sleep if the block is empty.
         if (size > 0)
diff --git a/dbms/src/Functions/FunctionsTransform.h b/dbms/src/Functions/FunctionsTransform.h
index c266df282b3a..2f5914138628 100644
--- a/dbms/src/Functions/FunctionsTransform.h
+++ b/dbms/src/Functions/FunctionsTransform.h
@@ -65,6 +65,8 @@ class FunctionTransform : public IFunction
 
     bool isVariadic() const override { return true; }
     size_t getNumberOfArguments() const override { return 0; }
+    bool useDefaultImplementationForConstants() const override { return true; }
+    ColumnNumbers getArgumentsThatAreAlwaysConstant() const override { return {1, 2}; }
 
     DataTypePtr getReturnTypeImpl(const DataTypes & arguments) const override
     {
@@ -189,13 +191,13 @@ class FunctionTransform : public IFunction
 private:
     void executeConst(Block & block, const ColumnNumbers & arguments, const size_t result)
     {
-        /// Construct a block of full-size columns of size 1 and compute the function as usual.
+        /// Materialize the input column and compute the function as usual.
 
         Block tmp_block;
         ColumnNumbers tmp_arguments;
 
         tmp_block.insert(block.getByPosition(arguments[0]));
-        tmp_block.getByPosition(0).column = static_cast<const ColumnConst *>(tmp_block.getByPosition(0).column.get())->getDataColumnPtr();
+        tmp_block.getByPosition(0).column = tmp_block.getByPosition(0).column->cloneResized(block.rows())->convertToFullColumnIfConst();
         tmp_arguments.push_back(0);
 
         for (size_t i = 1; i < arguments.size(); ++i)
@@ -209,9 +211,7 @@ class FunctionTransform : public IFunction
 
         execute(tmp_block, tmp_arguments, tmp_result);
 
-        block.getByPosition(result).column = block.getByPosition(result).type->createColumnConst(
-            block.rows(),
-            (*tmp_block.getByPosition(tmp_result).column)[0]);
+        block.getByPosition(result).column = tmp_block.getByPosition(tmp_result).column;
     }
 
     template <typename T>
@@ -727,7 +727,7 @@ class FunctionTransform : public IFunction
     /// Different versions of the hash tables to implement the mapping.
 
     using NumToNum = HashMap<UInt64, UInt64, HashCRC32<UInt64>>;
-    using NumToString = HashMap <UInt64, StringRef, HashCRC32 <UInt64 >>;     /// Everywhere StringRef's with trailing zero.
+    using NumToString = HashMap <UInt64, StringRef, HashCRC32<UInt64>>;     /// Everywhere StringRef's with trailing zero.
     using StringToNum = HashMap<StringRef, UInt64, StringRefHash>;
     using StringToString = HashMap<StringRef, StringRef, StringRefHash>;
 
@@ -740,7 +740,7 @@ class FunctionTransform : public IFunction
 
     Field const_default_value;    /// Null, if not specified.
 
-    bool initialized = false;
+    std::atomic<bool> initialized {false};
     std::mutex mutex;
 
     /// Can be called from different threads. It works only on the first call.
diff --git a/dbms/src/Interpreters/Aggregator.cpp b/dbms/src/Interpreters/Aggregator.cpp
index a3bbbe303cc6..b2816c752027 100644
--- a/dbms/src/Interpreters/Aggregator.cpp
+++ b/dbms/src/Interpreters/Aggregator.cpp
@@ -6,6 +6,7 @@
 #include <Common/setThreadName.h>
 
 #include <DataTypes/DataTypeAggregateFunction.h>
+#include <DataTypes/DataTypeNullable.h>
 #include <Columns/ColumnsNumber.h>
 #include <Columns/ColumnArray.h>
 #include <Columns/ColumnTuple.h>
@@ -88,31 +89,55 @@ void AggregatedDataVariants::convertToTwoLevel()
 }
 
 
-void Aggregator::Params::calculateColumnNumbers(const Block & block)
+Block Aggregator::getHeader(bool final) const
 {
-    if (keys.empty() && !key_names.empty())
-        for (Names::const_iterator it = key_names.begin(); it != key_names.end(); ++it)
-            keys.push_back(block.getPositionByName(*it));
-
-    for (AggregateDescriptions::iterator it = aggregates.begin(); it != aggregates.end(); ++it)
-        if (it->arguments.empty() && !it->argument_names.empty())
-            for (Names::const_iterator jt = it->argument_names.begin(); jt != it->argument_names.end(); ++jt)
-                it->arguments.push_back(block.getPositionByName(*jt));
-}
+    Block res;
 
+    if (params.src_header)
+    {
+        for (size_t i = 0; i < params.keys_size; ++i)
+            res.insert(params.src_header.safeGetByPosition(params.keys[i]).cloneEmpty());
 
-void Aggregator::initialize(const Block & block)
-{
-    if (isCancelled())
-        return;
+        for (size_t i = 0; i < params.aggregates_size; ++i)
+        {
+            size_t arguments_size = params.aggregates[i].arguments.size();
+            DataTypes argument_types(arguments_size);
+            for (size_t j = 0; j < arguments_size; ++j)
+                argument_types[j] = params.src_header.safeGetByPosition(params.aggregates[i].arguments[j]).type;
 
-    std::lock_guard<std::mutex> lock(mutex);
+            DataTypePtr type;
+            if (final)
+                type = params.aggregates[i].function->getReturnType();
+            else
+                type = std::make_shared<DataTypeAggregateFunction>(params.aggregates[i].function, argument_types, params.aggregates[i].parameters);
 
-    if (initialized)
-        return;
+            res.insert({ type->createColumn(), type, params.aggregates[i].column_name });
+        }
+    }
+    else if (params.intermediate_header)
+    {
+        res = params.intermediate_header.cloneEmpty();
+
+        if (final)
+        {
+            for (size_t i = 0; i < params.aggregates_size; ++i)
+            {
+                auto & elem = res.getByPosition(params.keys_size + i);
+
+                elem.type = params.aggregates[i].function->getReturnType();
+                elem.column = elem.type->createColumn();
+            }
+        }
+    }
+
+    return res;
+}
 
-    initialized = true;
 
+Aggregator::Aggregator(const Params & params_)
+    : params(params_),
+    isCancelled([]() { return false; })
+{
     if (current_memory_tracker)
         memory_usage_before_aggregation = current_memory_tracker->get();
 
@@ -134,56 +159,7 @@ void Aggregator::initialize(const Block & block)
             all_aggregates_has_trivial_destructor = false;
     }
 
-    if (isCancelled())
-        return;
-
-    /** All below, if non-empty block passed.
-      * (it doesn't needed in methods that merging blocks with aggregation states).
-      */
-    if (!block)
-        return;
-
-    /// Transform names of columns to numbers.
-    params.calculateColumnNumbers(block);
-
-    if (isCancelled())
-        return;
-
-    /// Create "header" block, describing result.
-    if (!sample)
-    {
-        for (size_t i = 0; i < params.keys_size; ++i)
-        {
-            sample.insert(block.safeGetByPosition(params.keys[i]).cloneEmpty());
-            if (ColumnPtr converted = sample.safeGetByPosition(i).column->convertToFullColumnIfConst())
-                sample.safeGetByPosition(i).column = converted;
-        }
-
-        for (size_t i = 0; i < params.aggregates_size; ++i)
-        {
-            ColumnWithTypeAndName col;
-            col.name = params.aggregates[i].column_name;
-
-            size_t arguments_size = params.aggregates[i].arguments.size();
-            DataTypes argument_types(arguments_size);
-            for (size_t j = 0; j < arguments_size; ++j)
-                argument_types[j] = block.safeGetByPosition(params.aggregates[i].arguments[j]).type;
-
-            col.type = std::make_shared<DataTypeAggregateFunction>(params.aggregates[i].function, argument_types, params.aggregates[i].parameters);
-            col.column = col.type->createColumn();
-
-            sample.insert(std::move(col));
-        }
-    }
-}
-
-
-void Aggregator::setSampleBlock(const Block & block)
-{
-    std::lock_guard<std::mutex> lock(mutex);
-
-    if (!sample)
-        sample = block.cloneEmpty();
+    method = chooseAggregationMethod();
 }
 
 
@@ -377,102 +353,70 @@ void Aggregator::compileIfPossible(AggregatedDataVariants::Type type)
 }
 
 
-AggregatedDataVariants::Type Aggregator::chooseAggregationMethod(const ColumnRawPtrs & key_columns, Sizes & key_sizes) const
+AggregatedDataVariants::Type Aggregator::chooseAggregationMethod()
 {
+    /// If no keys. All aggregating to single row.
+    if (params.keys_size == 0)
+        return AggregatedDataVariants::Type::without_key;
+
     /// Check if at least one of the specified keys is nullable.
-    /// Create a set of nested key columns from the corresponding key columns.
-    /// Here "nested" means that, if a key column is nullable, we take its nested
-    /// column; otherwise we take the key column as is.
-    ColumnRawPtrs nested_key_columns;
-    nested_key_columns.reserve(key_columns.size());
+    DataTypes types_removed_nullable;
+    types_removed_nullable.reserve(params.keys.size());
     bool has_nullable_key = false;
 
-    for (const auto & col : key_columns)
+    for (const auto & pos : params.keys)
     {
-        if (col->isColumnNullable())
+        const auto & type = (params.src_header ? params.src_header : params.intermediate_header).safeGetByPosition(pos).type;
+
+        if (type->isNullable())
         {
-            const ColumnNullable & nullable_col = static_cast<const ColumnNullable &>(*col);
-            nested_key_columns.push_back(&nullable_col.getNestedColumn());
             has_nullable_key = true;
+            types_removed_nullable.push_back(removeNullable(type));
         }
         else
-            nested_key_columns.push_back(col);
+            types_removed_nullable.push_back(type);
     }
 
     /** Returns ordinary (not two-level) methods, because we start from them.
       * Later, during aggregation process, data may be converted (partitioned) to two-level structure, if cardinality is high.
       */
 
-    bool all_fixed = true;
     size_t keys_bytes = 0;
 
-    size_t num_array_keys = 0;
-    bool has_arrays_of_non_fixed_elems = false;
-    bool all_non_array_keys_are_fixed = true;
-    bool has_tuples = false;
-    bool has_arrays_of_nullable = false;
+    size_t num_contiguous_keys = 0;
+    size_t num_fixed_contiguous_keys = 0;
+    size_t num_string_keys = 0;
 
     key_sizes.resize(params.keys_size);
     for (size_t j = 0; j < params.keys_size; ++j)
     {
-        if (nested_key_columns[j]->isFixedAndContiguous())
-        {
-            key_sizes[j] = nested_key_columns[j]->sizeOfValueIfFixed();
-            keys_bytes += key_sizes[j];
-        }
-        else
+        if (types_removed_nullable[j]->isValueUnambiguouslyRepresentedInContiguousMemoryRegion())
         {
-            all_fixed = false;
+            ++num_contiguous_keys;
 
-            if (const ColumnArray * arr = typeid_cast<const ColumnArray *>(nested_key_columns[j]))
+            if (types_removed_nullable[j]->isValueUnambiguouslyRepresentedInFixedSizeContiguousMemoryRegion())
             {
-                ++num_array_keys;
-
-                if (arr->getData().isColumnNullable())
-                    has_arrays_of_nullable = true;
-
-                if (!arr->getData().isFixedAndContiguous())
-                    has_arrays_of_non_fixed_elems = true;
+                ++num_fixed_contiguous_keys;
+                key_sizes[j] = types_removed_nullable[j]->getSizeOfValueInMemory();
+                keys_bytes += key_sizes[j];
             }
-            else
-            {
-                all_non_array_keys_are_fixed = false;
 
-                if (typeid_cast<const ColumnTuple *>(nested_key_columns[j]))
-                    has_tuples = true;
+            if (types_removed_nullable[j]->isString())
+            {
+                ++num_string_keys;
             }
         }
     }
 
-    /// If no keys. All aggregating to single row.
-    if (params.keys_size == 0)
-        return AggregatedDataVariants::Type::without_key;
-
-    if (has_nullable_key || has_arrays_of_nullable)
+    if (has_nullable_key)
     {
-        /// At least one key is nullable. Therefore we choose an aggregation method
-        /// that takes into account this fact.
-        if ((params.keys_size == 1) && (nested_key_columns[0]->isNumeric()))
-        {
-            /// We have exactly one key and it is nullable. We shall add it a tag
-            /// which specifies whether its value is null or not.
-            size_t size_of_field = nested_key_columns[0]->sizeOfValueIfFixed();
-            if ((size_of_field == 1) || (size_of_field == 2) || (size_of_field == 4) || (size_of_field == 8) || (size_of_field == 16))
-                return AggregatedDataVariants::Type::nullable_keys128;
-            else
-                throw Exception{"Logical error: numeric column has sizeOfField not in 1, 2, 4, 8, 16.",
-                    ErrorCodes::LOGICAL_ERROR};
-        }
-
-        if (all_fixed)
+        if (params.keys_size == num_fixed_contiguous_keys)
         {
             /// Pack if possible all the keys along with information about which key values are nulls
             /// into a fixed 16- or 32-byte blob.
-            if (keys_bytes > (std::numeric_limits<size_t>::max() - std::tuple_size<KeysNullMap<UInt128>>::value))
-                throw Exception{"Aggregator: keys sizes overflow", ErrorCodes::LOGICAL_ERROR};
-            if ((std::tuple_size<KeysNullMap<UInt128>>::value + keys_bytes) <= 16)
+            if (std::tuple_size<KeysNullMap<UInt128>>::value + keys_bytes <= 16)
                 return AggregatedDataVariants::Type::nullable_keys128;
-            if ((std::tuple_size<KeysNullMap<UInt256>>::value + keys_bytes) <= 32)
+            if (std::tuple_size<KeysNullMap<UInt256>>::value + keys_bytes <= 32)
                 return AggregatedDataVariants::Type::nullable_keys256;
         }
 
@@ -483,9 +427,9 @@ AggregatedDataVariants::Type Aggregator::chooseAggregationMethod(const ColumnRaw
     /// No key has been found to be nullable.
 
     /// Single numeric key.
-    if ((params.keys_size == 1) && nested_key_columns[0]->isNumeric())
+    if (params.keys_size == 1 && types_removed_nullable[0]->isValueRepresentedByNumber())
     {
-        size_t size_of_field = nested_key_columns[0]->sizeOfValueIfFixed();
+        size_t size_of_field = types_removed_nullable[0]->getSizeOfValueInMemory();
         if (size_of_field == 1)
             return AggregatedDataVariants::Type::key8;
         if (size_of_field == 2)
@@ -500,23 +444,24 @@ AggregatedDataVariants::Type Aggregator::chooseAggregationMethod(const ColumnRaw
     }
 
     /// If all keys fits in N bits, will use hash table with all keys packed (placed contiguously) to single N-bit key.
-    if (all_fixed && keys_bytes <= 16)
-        return AggregatedDataVariants::Type::keys128;
-    if (all_fixed && keys_bytes <= 32)
-        return AggregatedDataVariants::Type::keys256;
+    if (params.keys_size == num_fixed_contiguous_keys)
+    {
+        if (keys_bytes <= 16)
+            return AggregatedDataVariants::Type::keys128;
+        if (keys_bytes <= 32)
+            return AggregatedDataVariants::Type::keys256;
+    }
 
     /// If single string key - will use hash table with references to it. Strings itself are stored separately in Arena.
-    if (params.keys_size == 1 && typeid_cast<const ColumnString *>(nested_key_columns[0]))
+    if (params.keys_size == 1 && types_removed_nullable[0]->isString())
         return AggregatedDataVariants::Type::key_string;
 
-    if (params.keys_size == 1 && typeid_cast<const ColumnFixedString *>(nested_key_columns[0]))
+    if (params.keys_size == 1 && types_removed_nullable[0]->isFixedString())
         return AggregatedDataVariants::Type::key_fixed_string;
 
-    /** If some keys are arrays.
-      * If there is no more than one key that is array, and it is array of fixed-size elements, and all other keys are fixed-size,
-      *  then it is possible to use 'concat' method (due to one-to-one correspondense). Otherwise the method will be 'serialized'.
+    /** If it is possible to use 'concat' method due to one-to-one correspondense. Otherwise the method will be 'serialized'.
       */
-    if (num_array_keys == 1 && !has_arrays_of_non_fixed_elems && all_non_array_keys_are_fixed)
+    if (params.keys_size == num_contiguous_keys && num_fixed_contiguous_keys + 1 >= num_contiguous_keys)
         return AggregatedDataVariants::Type::concat;
 
     /** For case with multiple strings, we use 'concat' method despite the fact, that correspondense is not one-to-one.
@@ -524,11 +469,8 @@ AggregatedDataVariants::Type Aggregator::chooseAggregationMethod(const ColumnRaw
       * But if strings contains zero bytes in between, different keys may clash.
       * For example, keys ('a\0b', 'c') and ('a', 'b\0c') will be aggregated as one key.
       * This is documented behaviour. It may be avoided by just switching to 'serialized' method, which is less efficient.
-      *
-      * Some of aggregation keys may be tuples. In most cases, tuples are flattened in expression analyzer and not passed here.
-      * But in rare cases, they are not flattened. Will fallback to 'serialized' method for simplicity.
       */
-    if (num_array_keys == 0 && !has_tuples)
+    if (params.keys_size == num_fixed_contiguous_keys + num_string_keys)
         return AggregatedDataVariants::Type::concat;
 
     return AggregatedDataVariants::Type::serialized;
@@ -707,12 +649,9 @@ void NO_INLINE Aggregator::executeWithoutKeyImpl(
 
 
 bool Aggregator::executeOnBlock(Block & block, AggregatedDataVariants & result,
-    ColumnRawPtrs & key_columns, AggregateColumns & aggregate_columns,
-    Sizes & key_sizes, StringRefs & key,
+    ColumnRawPtrs & key_columns, AggregateColumns & aggregate_columns, StringRefs & key,
     bool & no_more_keys)
 {
-    initialize(block);
-
     if (isCancelled())
         return true;
 
@@ -769,7 +708,7 @@ bool Aggregator::executeOnBlock(Block & block, AggregatedDataVariants & result,
     /// How to perform the aggregation?
     if (result.empty())
     {
-        result.init(chooseAggregationMethod(key_columns, key_sizes));
+        result.init(method);
         result.keys_size = params.keys_size;
         result.key_sizes = key_sizes;
         LOG_TRACE(log, "Aggregation method: " << result.getMethodName());
@@ -1056,7 +995,6 @@ void Aggregator::execute(const BlockInputStreamPtr & stream, AggregatedDataVaria
     StringRefs key(params.keys_size);
     ColumnRawPtrs key_columns(params.keys_size);
     AggregateColumns aggregate_columns(params.aggregates_size);
-    Sizes key_sizes;
 
     /** Used if there is a limit on the maximum number of rows in the aggregation,
       *  and if group_by_overflow_mode == ANY.
@@ -1081,14 +1019,12 @@ void Aggregator::execute(const BlockInputStreamPtr & stream, AggregatedDataVaria
         src_rows += block.rows();
         src_bytes += block.bytes();
 
-        if (!executeOnBlock(block, result,
-            key_columns, aggregate_columns, key_sizes, key,
-            no_more_keys))
+        if (!executeOnBlock(block, result, key_columns, aggregate_columns, key, no_more_keys))
             break;
     }
 
     double elapsed_seconds = watch.elapsedSeconds();
-    size_t rows = result.size();
+    size_t rows = result.sizeWithoutOverflowRow();
     LOG_TRACE(log, std::fixed << std::setprecision(3)
         << "Aggregated. " << src_rows << " to " << rows << " rows (from " << src_bytes / 1048576.0 << " MiB)"
         << " in " << elapsed_seconds << " sec."
@@ -1174,9 +1110,11 @@ Block Aggregator::prepareBlockAndFill(
     MutableColumns final_aggregate_columns(params.aggregates_size);
     AggregateColumnsData aggregate_columns_data(params.aggregates_size);
 
+    Block header = getHeader(final);
+
     for (size_t i = 0; i < params.keys_size; ++i)
     {
-        key_columns[i] = sample.safeGetByPosition(i).column->cloneEmpty();
+        key_columns[i] = header.safeGetByPosition(i).type->createColumn();
         key_columns[i]->reserve(rows);
     }
 
@@ -1184,7 +1122,7 @@ Block Aggregator::prepareBlockAndFill(
     {
         if (!final)
         {
-            aggregate_columns[i] = sample.safeGetByPosition(i + params.keys_size).column->cloneEmpty();
+            aggregate_columns[i] = header.safeGetByPosition(i + params.keys_size).type->createColumn();
 
             /// The ColumnAggregateFunction column captures the shared ownership of the arena with the aggregate function states.
             ColumnAggregateFunction & column_aggregate_func = static_cast<ColumnAggregateFunction &>(*aggregate_columns[i]);
@@ -1213,7 +1151,7 @@ Block Aggregator::prepareBlockAndFill(
 
     filler(key_columns, aggregate_columns_data, final_aggregate_columns, data_variants.key_sizes, final);
 
-    Block res = sample.cloneEmpty();
+    Block res = header.cloneEmpty();
 
     for (size_t i = 0; i < params.keys_size; ++i)
         res.getByPosition(i).column = std::move(key_columns[i]);
@@ -1221,18 +1159,13 @@ Block Aggregator::prepareBlockAndFill(
     for (size_t i = 0; i < params.aggregates_size; ++i)
     {
         if (final)
-        {
-            res.getByPosition(i + params.keys_size).type = aggregate_functions[i]->getReturnType();
             res.getByPosition(i + params.keys_size).column = std::move(final_aggregate_columns[i]);
-        }
         else
-        {
             res.getByPosition(i + params.keys_size).column = std::move(aggregate_columns[i]);
-        }
     }
 
     /// Change the size of the columns-constants in the block.
-    size_t columns = sample.columns();
+    size_t columns = header.columns();
     for (size_t i = 0; i < columns; ++i)
         if (res.getByPosition(i).column->isColumnConst())
             res.getByPosition(i).column = res.getByPosition(i).column->cut(0, rows);
@@ -1653,12 +1586,7 @@ class MergingAndConvertingBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "MergingAndConverting"; }
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << this;
-        return res.str();
-    }
+    Block getHeader() const override { return aggregator.getHeader(final); }
 
     ~MergingAndConvertingBlockInputStream()
     {
@@ -1846,7 +1774,7 @@ std::unique_ptr<IBlockInputStream> Aggregator::mergeAndConvertToBlocks(
             non_empty_data.push_back(data);
 
     if (non_empty_data.empty())
-        return std::make_unique<NullBlockInputStream>();
+        return std::make_unique<NullBlockInputStream>(getHeader(final));
 
     if (non_empty_data.size() > 1)
     {
@@ -2023,14 +1951,6 @@ void NO_INLINE Aggregator::mergeWithoutKeyStreamsImpl(
 
 void Aggregator::mergeStream(const BlockInputStreamPtr & stream, AggregatedDataVariants & result, size_t max_threads)
 {
-    if (isCancelled())
-        return;
-
-    StringRefs key(params.keys_size);
-    ColumnRawPtrs key_columns(params.keys_size);
-
-    initialize({});
-
     if (isCancelled())
         return;
 
@@ -2062,15 +1982,6 @@ void Aggregator::mergeStream(const BlockInputStreamPtr & stream, AggregatedDataV
     if (bucket_to_blocks.empty())
         return;
 
-    setSampleBlock(bucket_to_blocks.begin()->second.front());
-
-    /// How to perform the aggregation?
-    for (size_t i = 0; i < params.keys_size; ++i)
-        key_columns[i] = sample.safeGetByPosition(i).column.get();
-
-    Sizes key_sizes;
-    AggregatedDataVariants::Type method = chooseAggregationMethod(key_columns, key_sizes);
-
     /** `minus one` means the absence of information about the bucket
       * - in the case of single-level aggregation, as well as for blocks with "overflowing" values.
       * If there is at least one block with a bucket number greater than zero, then there was a two-level aggregation.
@@ -2111,7 +2022,7 @@ void Aggregator::mergeStream(const BlockInputStreamPtr & stream, AggregatedDataV
 
         LOG_TRACE(log, "Merging partially aggregated two-level data.");
 
-        auto merge_bucket = [&bucket_to_blocks, &result, &key_sizes, this](Int32 bucket, Arena * aggregates_pool, MemoryTracker * memory_tracker)
+        auto merge_bucket = [&bucket_to_blocks, &result, this](Int32 bucket, Arena * aggregates_pool, MemoryTracker * memory_tracker)
         {
             current_memory_tracker = memory_tracker;
 
@@ -2122,7 +2033,7 @@ void Aggregator::mergeStream(const BlockInputStreamPtr & stream, AggregatedDataV
 
             #define M(NAME) \
                 else if (result.type == AggregatedDataVariants::Type::NAME) \
-                    mergeStreamsImpl(block, key_sizes, aggregates_pool, *result.NAME, result.NAME->data.impls[bucket], nullptr, false);
+                    mergeStreamsImpl(block, result.key_sizes, aggregates_pool, *result.NAME, result.NAME->data.impls[bucket], nullptr, false);
 
                 if (false) {}
                     APPLY_FOR_VARIANTS_TWO_LEVEL(M)
@@ -2190,7 +2101,7 @@ void Aggregator::mergeStream(const BlockInputStreamPtr & stream, AggregatedDataV
 
         #define M(NAME, IS_TWO_LEVEL) \
             else if (result.type == AggregatedDataVariants::Type::NAME) \
-                mergeStreamsImpl(block, key_sizes, result.aggregates_pool, *result.NAME, result.NAME->data, result.without_key, no_more_keys);
+                mergeStreamsImpl(block, result.key_sizes, result.aggregates_pool, *result.NAME, result.NAME->data, result.without_key, no_more_keys);
 
             APPLY_FOR_AGGREGATED_VARIANTS(M)
         #undef M
@@ -2214,32 +2125,19 @@ Block Aggregator::mergeBlocks(BlocksList & blocks, bool final)
     LOG_TRACE(log, "Merging partially aggregated blocks (bucket = " << bucket_num << ").");
     Stopwatch watch;
 
-    StringRefs key(params.keys_size);
-    ColumnRawPtrs key_columns(params.keys_size);
-
-    initialize({});
-    setSampleBlock(blocks.front());
-
-    /// How to perform the aggregation?
-    for (size_t i = 0; i < params.keys_size; ++i)
-        key_columns[i] = sample.safeGetByPosition(i).column.get();
-
-    Sizes key_sizes;
-    AggregatedDataVariants::Type method = chooseAggregationMethod(key_columns, key_sizes);
-
     /** If possible, change 'method' to some_hash64. Otherwise, leave as is.
       * Better hash function is needed because during external aggregation,
       *  we may merge partitions of data with total number of keys far greater than 4 billion.
       */
 
 #define APPLY_FOR_VARIANTS_THAT_MAY_USE_BETTER_HASH_FUNCTION(M) \
-        M(key64)             \
-        M(key_string)         \
+        M(key64)            \
+        M(key_string)       \
         M(key_fixed_string) \
-        M(keys128)             \
-        M(keys256)             \
-        M(concat)             \
-        M(serialized)        \
+        M(keys128)          \
+        M(keys256)          \
+        M(concat)           \
+        M(serialized)       \
 
 #define M(NAME) \
     if (method == AggregatedDataVariants::Type::NAME) \
@@ -2377,20 +2275,16 @@ std::vector<Block> Aggregator::convertBlockToTwoLevel(const Block & block)
     if (!block)
         return {};
 
-    initialize({});
-    setSampleBlock(block);
-
     AggregatedDataVariants data;
 
     StringRefs key(params.keys_size);
     ColumnRawPtrs key_columns(params.keys_size);
-    Sizes key_sizes;
 
     /// Remember the columns we will work with
     for (size_t i = 0; i < params.keys_size; ++i)
         key_columns[i] = block.safeGetByPosition(i).column.get();
 
-    AggregatedDataVariants::Type type = chooseAggregationMethod(key_columns, key_sizes);
+    AggregatedDataVariants::Type type = method;
     data.keys_size = params.keys_size;
     data.key_sizes = key_sizes;
 
@@ -2496,30 +2390,6 @@ void Aggregator::destroyAllAggregateStates(AggregatedDataVariants & result)
 }
 
 
-String Aggregator::getID() const
-{
-    std::stringstream res;
-
-    if (params.keys.empty())
-    {
-        res << "key_names";
-        for (size_t i = 0; i < params.key_names.size(); ++i)
-            res << ", " << params.key_names[i];
-    }
-    else
-    {
-        res << "keys";
-        for (size_t i = 0; i < params.keys.size(); ++i)
-            res << ", " << params.keys[i];
-    }
-
-    res << ", aggregates";
-    for (size_t i = 0; i < params.aggregates_size; ++i)
-        res << ", " << params.aggregates[i].column_name;
-
-    return res.str();
-}
-
 void Aggregator::setCancellationHook(const CancellationHook cancellation_hook)
 {
     isCancelled = cancellation_hook;
diff --git a/dbms/src/Interpreters/Aggregator.h b/dbms/src/Interpreters/Aggregator.h
index 02ef7f6835bc..08027fe6ae66 100644
--- a/dbms/src/Interpreters/Aggregator.h
+++ b/dbms/src/Interpreters/Aggregator.h
@@ -812,8 +812,8 @@ struct AggregatedDataVariants : private boost::noncopyable
     {
         switch (type_)
         {
-            case Type::EMPTY:        break;
-            case Type::without_key:    break;
+            case Type::EMPTY:       break;
+            case Type::without_key: break;
 
         #define M(NAME, IS_TWO_LEVEL) \
             case Type::NAME: NAME = std::make_unique<decltype(NAME)::element_type>(); break;
@@ -832,8 +832,8 @@ struct AggregatedDataVariants : private boost::noncopyable
     {
         switch (type)
         {
-            case Type::EMPTY:        return 0;
-            case Type::without_key:    return 1;
+            case Type::EMPTY:       return 0;
+            case Type::without_key: return 1;
 
         #define M(NAME, IS_TWO_LEVEL) \
             case Type::NAME: return NAME->data.size() + (without_key != nullptr);
@@ -850,8 +850,8 @@ struct AggregatedDataVariants : private boost::noncopyable
     {
         switch (type)
         {
-            case Type::EMPTY:        return 0;
-            case Type::without_key:    return 1;
+            case Type::EMPTY:       return 0;
+            case Type::without_key: return 1;
 
             #define M(NAME, IS_TWO_LEVEL) \
             case Type::NAME: return NAME->data.size();
@@ -867,8 +867,8 @@ struct AggregatedDataVariants : private boost::noncopyable
     {
         switch (type)
         {
-            case Type::EMPTY:        return "EMPTY";
-            case Type::without_key:    return "without_key";
+            case Type::EMPTY:       return "EMPTY";
+            case Type::without_key: return "without_key";
 
         #define M(NAME, IS_TWO_LEVEL) \
             case Type::NAME: return #NAME;
@@ -884,8 +884,8 @@ struct AggregatedDataVariants : private boost::noncopyable
     {
         switch (type)
         {
-            case Type::EMPTY:        return false;
-            case Type::without_key:    return false;
+            case Type::EMPTY:       return false;
+            case Type::without_key: return false;
 
         #define M(NAME, IS_TWO_LEVEL) \
             case Type::NAME: return IS_TWO_LEVEL;
@@ -900,25 +900,25 @@ struct AggregatedDataVariants : private boost::noncopyable
     #define APPLY_FOR_VARIANTS_CONVERTIBLE_TO_TWO_LEVEL(M) \
         M(key32)            \
         M(key64)            \
-        M(key_string)        \
-        M(key_fixed_string)    \
-        M(keys128)            \
-        M(keys256)            \
-        M(hashed)            \
-        M(concat)            \
-        M(serialized)        \
-        M(nullable_keys128)    \
-        M(nullable_keys256)    \
+        M(key_string)       \
+        M(key_fixed_string) \
+        M(keys128)          \
+        M(keys256)          \
+        M(hashed)           \
+        M(concat)           \
+        M(serialized)       \
+        M(nullable_keys128) \
+        M(nullable_keys256) \
 
     #define APPLY_FOR_VARIANTS_NOT_CONVERTIBLE_TO_TWO_LEVEL(M) \
-        M(key8)                \
+        M(key8)             \
         M(key16)            \
         M(key64_hash64)     \
-        M(key_string_hash64) \
+        M(key_string_hash64)\
         M(key_fixed_string_hash64) \
-        M(keys128_hash64)     \
-        M(keys256_hash64)     \
-        M(concat_hash64)     \
+        M(keys128_hash64)   \
+        M(keys256_hash64)   \
+        M(concat_hash64)    \
         M(serialized_hash64) \
 
     #define APPLY_FOR_VARIANTS_SINGLE_LEVEL(M) \
@@ -943,16 +943,16 @@ struct AggregatedDataVariants : private boost::noncopyable
     void convertToTwoLevel();
 
     #define APPLY_FOR_VARIANTS_TWO_LEVEL(M) \
-        M(key32_two_level)                \
-        M(key64_two_level)                \
-        M(key_string_two_level)            \
-        M(key_fixed_string_two_level)    \
-        M(keys128_two_level)            \
-        M(keys256_two_level)            \
-        M(hashed_two_level)                \
-        M(concat_two_level)                \
-        M(serialized_two_level)            \
-        M(nullable_keys128_two_level)    \
+        M(key32_two_level)            \
+        M(key64_two_level)            \
+        M(key_string_two_level)       \
+        M(key_fixed_string_two_level) \
+        M(keys128_two_level)          \
+        M(keys256_two_level)          \
+        M(hashed_two_level)           \
+        M(concat_two_level)           \
+        M(serialized_two_level)       \
+        M(nullable_keys128_two_level) \
         M(nullable_keys256_two_level)
 };
 
@@ -979,9 +979,13 @@ class Aggregator
 public:
     struct Params
     {
+        /// Data structure of source blocks.
+        Block src_header;
+        /// Data structure of intermediate blocks before merge.
+        Block intermediate_header;
+
         /// What to count.
-        Names key_names;
-        ColumnNumbers keys;            /// The column numbers are computed later.
+        ColumnNumbers keys;
         AggregateDescriptions aggregates;
         size_t keys_size;
         size_t aggregates_size;
@@ -1008,35 +1012,34 @@ class Aggregator
         const std::string tmp_path;
 
         Params(
-            const Names & key_names_, const AggregateDescriptions & aggregates_,
+            const Block & src_header_,
+            const ColumnNumbers & keys_, const AggregateDescriptions & aggregates_,
             bool overflow_row_, size_t max_rows_to_group_by_, OverflowMode group_by_overflow_mode_,
             Compiler * compiler_, UInt32 min_count_to_compile_,
             size_t group_by_two_level_threshold_, size_t group_by_two_level_threshold_bytes_,
             size_t max_bytes_before_external_group_by_, const std::string & tmp_path_)
-            : key_names(key_names_), aggregates(aggregates_), aggregates_size(aggregates.size()),
+            : src_header(src_header_),
+            keys(keys_), aggregates(aggregates_), keys_size(keys.size()), aggregates_size(aggregates.size()),
             overflow_row(overflow_row_), max_rows_to_group_by(max_rows_to_group_by_), group_by_overflow_mode(group_by_overflow_mode_),
             compiler(compiler_), min_count_to_compile(min_count_to_compile_),
             group_by_two_level_threshold(group_by_two_level_threshold_), group_by_two_level_threshold_bytes(group_by_two_level_threshold_bytes_),
             max_bytes_before_external_group_by(max_bytes_before_external_group_by_), tmp_path(tmp_path_)
         {
-            std::sort(key_names.begin(), key_names.end());
-            key_names.erase(std::unique(key_names.begin(), key_names.end()), key_names.end());
-            keys_size = key_names.size();
         }
 
         /// Only parameters that matter during merge.
-        Params(const Names & key_names_, const AggregateDescriptions & aggregates_, bool overflow_row_)
-            : Params(key_names_, aggregates_, overflow_row_, 0, OverflowMode::THROW, nullptr, 0, 0, 0, 0, "") {}
+        Params(const Block & intermediate_header_,
+            const ColumnNumbers & keys_, const AggregateDescriptions & aggregates_, bool overflow_row_)
+            : Params(Block(), keys_, aggregates_, overflow_row_, 0, OverflowMode::THROW, nullptr, 0, 0, 0, 0, "")
+        {
+            intermediate_header = intermediate_header_;
+        }
 
-        /// Compute the column numbers in `keys` and `aggregates`.
+        /// Calculate the column numbers in `keys` and `aggregates`.
         void calculateColumnNumbers(const Block & block);
     };
 
-    Aggregator(const Params & params_)
-        : params(params_),
-        isCancelled([]() { return false; })
-    {
-    }
+    Aggregator(const Params & params_);
 
     /// Aggregate the source. Get the result in the form of one of the data structures.
     void execute(const BlockInputStreamPtr & stream, AggregatedDataVariants & result);
@@ -1049,7 +1052,7 @@ class Aggregator
     /// Process one block. Return false if the processing should be aborted (with group_by_overflow_mode = 'break').
     bool executeOnBlock(Block & block, AggregatedDataVariants & result,
         ColumnRawPtrs & key_columns, AggregateColumns & aggregate_columns,    /// Passed to not create them anew for each block
-        Sizes & key_sizes, StringRefs & keys,                                        /// - pass the corresponding objects that are initially empty.
+        StringRefs & keys,                                        /// - pass the corresponding objects that are initially empty.
         bool & no_more_keys);
 
     /** Convert the aggregation data structure into a block.
@@ -1087,9 +1090,6 @@ class Aggregator
       */
     void setCancellationHook(const CancellationHook cancellation_hook);
 
-    /// For IBlockInputStream.
-    String getID() const;
-
     /// For external aggregation.
     void writeToTemporaryFile(AggregatedDataVariants & data_variants);
 
@@ -1111,12 +1111,18 @@ class Aggregator
 
     const TemporaryFiles & getTemporaryFiles() const { return temporary_files; }
 
+    /// Get data structure of the result.
+    Block getHeader(bool final) const;
+
 protected:
     friend struct AggregatedDataVariants;
     friend class MergingAndConvertingBlockInputStream;
 
     Params params;
 
+    AggregatedDataVariants::Type method;
+    Sizes key_sizes;
+
     AggregateFunctionsPlainPtrs aggregate_functions;
 
     /** This array serves two purposes.
@@ -1145,12 +1151,8 @@ class Aggregator
     /// How many RAM were used to process the query before processing the first block.
     Int64 memory_usage_before_aggregation = 0;
 
-    /// To initialize from the first block when used concurrently.
-    bool initialized = false;
     std::mutex mutex;
 
-    Block sample;
-
     Logger * log = &Logger::get("Aggregator");
 
     /** Dynamically compiled library for aggregation, if any.
@@ -1179,18 +1181,8 @@ class Aggregator
     /// For external aggregation.
     TemporaryFiles temporary_files;
 
-    /** If only the column names (key_names, and also aggregates[i].column_name) are specified, then calculate the column numbers.
-      * Generate block - sample of the result. It is used in the convertToBlocks, mergeAndConvertToBlocks methods.
-      */
-    void initialize(const Block & block);
-
-    /** Set the block - sample of the result,
-      *  only if it has not already been set.
-      */
-    void setSampleBlock(const Block & block);
-
     /** Select the aggregation method based on the number and types of keys. */
-    AggregatedDataVariants::Type chooseAggregationMethod(const ColumnRawPtrs & key_columns, Sizes & key_sizes) const;
+    AggregatedDataVariants::Type chooseAggregationMethod();
 
     /** Create states of aggregate functions for one key.
       */
diff --git a/dbms/src/Interpreters/ClusterProxy/DescribeStreamFactory.cpp b/dbms/src/Interpreters/ClusterProxy/DescribeStreamFactory.cpp
index 570e655263b5..a61e14763f7f 100644
--- a/dbms/src/Interpreters/ClusterProxy/DescribeStreamFactory.cpp
+++ b/dbms/src/Interpreters/ClusterProxy/DescribeStreamFactory.cpp
@@ -4,6 +4,7 @@
 #include <DataStreams/BlockExtraInfoInputStream.h>
 #include <DataStreams/RemoteBlockInputStream.h>
 
+
 namespace DB
 {
 
@@ -46,7 +47,7 @@ void DescribeStreamFactory::createForShard(
     }
 
     auto remote_stream = std::make_shared<RemoteBlockInputStream>(
-            shard_info.pool, query, context, nullptr, throttler);
+        shard_info.pool, query, InterpreterDescribeQuery::getSampleBlock(), context, nullptr, throttler);
     remote_stream->setPoolMode(PoolMode::GET_ALL);
     remote_stream->appendExtraInfo();
     res.emplace_back(std::move(remote_stream));
diff --git a/dbms/src/Interpreters/ClusterProxy/SelectStreamFactory.cpp b/dbms/src/Interpreters/ClusterProxy/SelectStreamFactory.cpp
index 7ba39c1eae56..43ef98dfb26c 100644
--- a/dbms/src/Interpreters/ClusterProxy/SelectStreamFactory.cpp
+++ b/dbms/src/Interpreters/ClusterProxy/SelectStreamFactory.cpp
@@ -28,12 +28,14 @@ namespace ClusterProxy
 {
 
 SelectStreamFactory::SelectStreamFactory(
-        QueryProcessingStage::Enum processed_stage_,
-        QualifiedTableName main_table_,
-        const Tables & external_tables_)
-    : processed_stage{processed_stage_}
-    , main_table(std::move(main_table_))
-    , external_tables{external_tables_}
+    const Block & header,
+    QueryProcessingStage::Enum processed_stage_,
+    QualifiedTableName main_table_,
+    const Tables & external_tables_)
+    : header(header),
+    processed_stage{processed_stage_},
+    main_table(std::move(main_table_)),
+    external_tables{external_tables_}
 {
 }
 
@@ -55,10 +57,10 @@ BlockInputStreamPtr createLocalStream(const ASTPtr & query_ast, const Context &
 }
 
 void SelectStreamFactory::createForShard(
-        const Cluster::ShardInfo & shard_info,
-        const String & query, const ASTPtr & query_ast,
-        const Context & context, const ThrottlerPtr & throttler,
-        BlockInputStreams & res)
+    const Cluster::ShardInfo & shard_info,
+    const String & query, const ASTPtr & query_ast,
+    const Context & context, const ThrottlerPtr & throttler,
+    BlockInputStreams & res)
 {
     auto emplace_local_stream = [&]()
     {
@@ -67,7 +69,7 @@ void SelectStreamFactory::createForShard(
 
     auto emplace_remote_stream = [&]()
     {
-        auto stream = std::make_shared<RemoteBlockInputStream>(shard_info.pool, query, context, nullptr, throttler, external_tables, processed_stage);
+        auto stream = std::make_shared<RemoteBlockInputStream>(shard_info.pool, query, header, context, nullptr, throttler, external_tables, processed_stage);
         stream->setPoolMode(PoolMode::GET_MANY);
         stream->setMainTable(main_table);
         res.emplace_back(std::move(stream));
@@ -157,7 +159,7 @@ void SelectStreamFactory::createForShard(
         auto lazily_create_stream = [
                 pool = shard_info.pool, shard_num = shard_info.shard_num, query, query_ast, context, throttler,
                 main_table = main_table, external_tables = external_tables, stage = processed_stage,
-                local_delay]()
+                local_delay, this]()
             -> BlockInputStreamPtr
         {
             std::vector<ConnectionPoolWithFailover::TryResult> try_results;
@@ -192,11 +194,11 @@ void SelectStreamFactory::createForShard(
                     connections.emplace_back(std::move(try_result.entry));
 
                 return std::make_shared<RemoteBlockInputStream>(
-                        std::move(connections), query, context, nullptr, throttler, external_tables, stage);
+                    std::move(connections), query, header, context, nullptr, throttler, external_tables, stage);
             }
         };
 
-        res.emplace_back(std::make_shared<LazyBlockInputStream>("LazyShardWithLocalReplica", lazily_create_stream));
+        res.emplace_back(std::make_shared<LazyBlockInputStream>("LazyShardWithLocalReplica", header, lazily_create_stream));
     }
     else
         emplace_remote_stream();
diff --git a/dbms/src/Interpreters/ClusterProxy/SelectStreamFactory.h b/dbms/src/Interpreters/ClusterProxy/SelectStreamFactory.h
index f683a3306f7c..53066a946e94 100644
--- a/dbms/src/Interpreters/ClusterProxy/SelectStreamFactory.h
+++ b/dbms/src/Interpreters/ClusterProxy/SelectStreamFactory.h
@@ -14,6 +14,7 @@ class SelectStreamFactory final : public IStreamFactory
 {
 public:
     SelectStreamFactory(
+        const Block & header,
         QueryProcessingStage::Enum processed_stage,
         QualifiedTableName main_table,
         const Tables & external_tables);
@@ -25,6 +26,7 @@ class SelectStreamFactory final : public IStreamFactory
         BlockInputStreams & res) override;
 
 private:
+    const Block header;
     QueryProcessingStage::Enum processed_stage;
     QualifiedTableName main_table;
     const Tables & external_tables;
diff --git a/dbms/src/Interpreters/DDLWorker.cpp b/dbms/src/Interpreters/DDLWorker.cpp
index f01bd8424e6d..c6bcb23989b3 100644
--- a/dbms/src/Interpreters/DDLWorker.cpp
+++ b/dbms/src/Interpreters/DDLWorker.cpp
@@ -940,7 +940,7 @@ class DDLQueryStatusInputSream : public IProfilingBlockInputStream
 public:
 
     DDLQueryStatusInputSream(const String & zk_node_path, const DDLLogEntry & entry, const Context & context)
-    : node_path(zk_node_path), context(context), watch(CLOCK_MONOTONIC_COARSE), log(&Logger::get("DDLQueryStatusInputSream"))
+        : node_path(zk_node_path), context(context), watch(CLOCK_MONOTONIC_COARSE), log(&Logger::get("DDLQueryStatusInputSream"))
     {
         sample = Block{
             {std::make_shared<DataTypeString>(),    "host"},
@@ -964,10 +964,7 @@ class DDLQueryStatusInputSream : public IProfilingBlockInputStream
         return "DDLQueryStatusInputSream";
     }
 
-    String getID() const override
-    {
-        return "DDLQueryStatusInputSream(" + node_path + ")";
-    }
+    Block getHeader() const override { return sample; };
 
     Block readImpl() override
     {
@@ -1138,7 +1135,6 @@ BlockIO executeDDLQueryOnCluster(const ASTPtr & query_ptr_, const Context & cont
         return io;
 
     auto stream = std::make_shared<DDLQueryStatusInputSream>(node_path, entry, context);
-    io.in_sample = stream->getSampleBlock();
     io.in = std::move(stream);
     return io;
 }
diff --git a/dbms/src/Interpreters/ExpressionActions.cpp b/dbms/src/Interpreters/ExpressionActions.cpp
index 490ab509c00a..1f8a5bb8f0d5 100644
--- a/dbms/src/Interpreters/ExpressionActions.cpp
+++ b/dbms/src/Interpreters/ExpressionActions.cpp
@@ -910,45 +910,6 @@ void ExpressionActions::finalize(const Names & output_columns)
 }
 
 
-std::string ExpressionActions::getID() const
-{
-    std::stringstream ss;
-
-    for (size_t i = 0; i < actions.size(); ++i)
-    {
-        if (i)
-            ss << ", ";
-        if (actions[i].type == ExpressionAction::APPLY_FUNCTION)
-            ss << actions[i].result_name;
-        if (actions[i].type == ExpressionAction::ARRAY_JOIN)
-        {
-            ss << (actions[i].array_join_is_left ? "LEFT ARRAY JOIN" : "ARRAY JOIN") << "{";
-            for (NameSet::const_iterator it = actions[i].array_joined_columns.begin();
-                 it != actions[i].array_joined_columns.end(); ++it)
-            {
-                if (it != actions[i].array_joined_columns.begin())
-                    ss << ", ";
-                ss << *it;
-            }
-            ss << "}";
-        }
-
-        /// TODO JOIN
-    }
-
-    ss << ": {";
-    NamesAndTypesList output_columns = sample_block.getNamesAndTypesList();
-    for (NamesAndTypesList::const_iterator it = output_columns.begin(); it != output_columns.end(); ++it)
-    {
-        if (it != output_columns.begin())
-            ss << ", ";
-        ss << it->name;
-    }
-    ss << "}";
-
-    return ss.str();
-}
-
 std::string ExpressionActions::dumpActions() const
 {
     std::stringstream ss;
@@ -1064,7 +1025,7 @@ BlockInputStreamPtr ExpressionActions::createStreamWithNonJoinedDataIfFullOrRigh
         {
             Block left_sample_block;
             for (const auto & input_elem : input_columns)
-                left_sample_block.insert({ nullptr, input_elem.type, input_elem.name });
+                left_sample_block.insert(ColumnWithTypeAndName{ input_elem.type, input_elem.name });
 
             return action.join->createStreamWithNonJoinedRows(left_sample_block, max_block_size);
         }
diff --git a/dbms/src/Interpreters/ExpressionActions.h b/dbms/src/Interpreters/ExpressionActions.h
index 5e8cc4ac1707..59434c741acc 100644
--- a/dbms/src/Interpreters/ExpressionActions.h
+++ b/dbms/src/Interpreters/ExpressionActions.h
@@ -194,8 +194,6 @@ class ExpressionActions
     /// Obtain a sample block that contains the names and types of result columns.
     const Block & getSampleBlock() const { return sample_block; }
 
-    std::string getID() const;
-
     std::string dumpActions() const;
 
     static std::string getSmallestColumn(const NamesAndTypesList & columns);
diff --git a/dbms/src/Interpreters/ExpressionAnalyzer.cpp b/dbms/src/Interpreters/ExpressionAnalyzer.cpp
index a519ebb6dbd3..259cd8f35034 100644
--- a/dbms/src/Interpreters/ExpressionAnalyzer.cpp
+++ b/dbms/src/Interpreters/ExpressionAnalyzer.cpp
@@ -883,7 +883,6 @@ void ExpressionAnalyzer::addExternalStorage(ASTPtr & subquery_or_table_name_or_t
 
     external_tables[external_table_name] = external_storage;
     subqueries_for_sets[external_table_name].source = interpreter->execute().in;
-    subqueries_for_sets[external_table_name].source_sample = interpreter->getSampleBlock();
     subqueries_for_sets[external_table_name].table = external_storage;
 
     /** NOTE If it was written IN tmp_table - the existing temporary (but not external) table,
@@ -1661,8 +1660,7 @@ void ExpressionAnalyzer::makeSet(const ASTFunction * node, const Block & sample_
         {
             auto interpreter = interpretSubquery(arg, context, subquery_depth, {});
             subquery_for_set.source = std::make_shared<LazyBlockInputStream>(
-                [interpreter]() mutable { return interpreter->execute().in; });
-            subquery_for_set.source_sample = interpreter->getSampleBlock();
+                interpreter->getSampleBlock(), [interpreter]() mutable { return interpreter->execute().in; });
 
             /** Why is LazyBlockInputStream used?
               *
@@ -2486,13 +2484,14 @@ bool ExpressionAnalyzer::appendJoin(ExpressionActionsChain & chain, bool only_ty
                 table = table_to_join.subquery;
 
             auto interpreter = interpretSubquery(table, context, subquery_depth, required_joined_columns);
-            subquery_for_set.source = std::make_shared<LazyBlockInputStream>([interpreter]() mutable { return interpreter->execute().in; });
-            subquery_for_set.source_sample = interpreter->getSampleBlock();
+            subquery_for_set.source = std::make_shared<LazyBlockInputStream>(
+                interpreter->getSampleBlock(),
+                [interpreter]() mutable { return interpreter->execute().in; });
         }
 
         /// TODO You do not need to set this up when JOIN is only needed on remote servers.
         subquery_for_set.join = join;
-        subquery_for_set.join->setSampleBlock(subquery_for_set.source_sample);
+        subquery_for_set.join->setSampleBlock(subquery_for_set.source->getHeader());
     }
 
     addJoinAction(step.actions, false);
diff --git a/dbms/src/Interpreters/ExpressionAnalyzer.h b/dbms/src/Interpreters/ExpressionAnalyzer.h
index b11bd025a2e8..ccd60b296cbb 100644
--- a/dbms/src/Interpreters/ExpressionAnalyzer.h
+++ b/dbms/src/Interpreters/ExpressionAnalyzer.h
@@ -41,7 +41,6 @@ struct SubqueryForSet
 {
     /// The source is obtained using the InterpreterSelectQuery subquery.
     BlockInputStreamPtr source;
-    Block source_sample;
 
     /// If set, build it from result.
     SetPtr set;
diff --git a/dbms/src/Interpreters/InterpreterCheckQuery.cpp b/dbms/src/Interpreters/InterpreterCheckQuery.cpp
index 722622cc70d9..d96344190b55 100644
--- a/dbms/src/Interpreters/InterpreterCheckQuery.cpp
+++ b/dbms/src/Interpreters/InterpreterCheckQuery.cpp
@@ -244,7 +244,6 @@ BlockIO InterpreterCheckQuery::execute()
 
         BlockIO res;
         res.in = std::make_shared<OneBlockInputStream>(block);
-        res.in_sample = getSampleBlock();
 
         return res;
     }
@@ -256,7 +255,6 @@ BlockIO InterpreterCheckQuery::execute()
 
         BlockIO res;
         res.in = std::make_shared<OneBlockInputStream>(result);
-        res.in_sample = result.cloneEmpty();
 
         return res;
     }
diff --git a/dbms/src/Interpreters/InterpreterCreateQuery.cpp b/dbms/src/Interpreters/InterpreterCreateQuery.cpp
index 853d42c5ccfd..aa4bf23fc20b 100644
--- a/dbms/src/Interpreters/InterpreterCreateQuery.cpp
+++ b/dbms/src/Interpreters/InterpreterCreateQuery.cpp
@@ -573,7 +573,6 @@ BlockIO InterpreterCreateQuery::createTable(ASTCreateQuery & create)
             out = std::make_shared<ProhibitColumnsBlockOutputStream>(out, columns.materialized_columns);
 
         BlockIO io;
-        io.in_sample = as_select_sample;
         io.in = std::make_shared<NullAndDoCopyBlockInputStream>(interpreter_select->execute().in, out);
 
         return io;
diff --git a/dbms/src/Interpreters/InterpreterDescribeQuery.cpp b/dbms/src/Interpreters/InterpreterDescribeQuery.cpp
index af61a20d6f81..a01f4e327e8a 100644
--- a/dbms/src/Interpreters/InterpreterDescribeQuery.cpp
+++ b/dbms/src/Interpreters/InterpreterDescribeQuery.cpp
@@ -24,8 +24,6 @@ BlockIO InterpreterDescribeQuery::execute()
 {
     BlockIO res;
     res.in = executeImpl();
-    res.in_sample = getSampleBlock();
-
     return res;
 }
 
diff --git a/dbms/src/Interpreters/InterpreterDescribeQuery.h b/dbms/src/Interpreters/InterpreterDescribeQuery.h
index 28bf635f34c0..fc0bea10f2d5 100644
--- a/dbms/src/Interpreters/InterpreterDescribeQuery.h
+++ b/dbms/src/Interpreters/InterpreterDescribeQuery.h
@@ -21,11 +21,12 @@ class InterpreterDescribeQuery : public IInterpreter
 
     BlockIO execute() override;
 
+    static Block getSampleBlock();
+
 private:
     ASTPtr query_ptr;
     const Context & context;
 
-    Block getSampleBlock();
     BlockInputStreamPtr executeImpl();
 };
 
diff --git a/dbms/src/Interpreters/InterpreterExistsQuery.cpp b/dbms/src/Interpreters/InterpreterExistsQuery.cpp
index 1dac1692a815..08df9fb39ad5 100644
--- a/dbms/src/Interpreters/InterpreterExistsQuery.cpp
+++ b/dbms/src/Interpreters/InterpreterExistsQuery.cpp
@@ -17,15 +17,16 @@ BlockIO InterpreterExistsQuery::execute()
 {
     BlockIO res;
     res.in = executeImpl();
-    res.in_sample = getSampleBlock();
-
     return res;
 }
 
 
 Block InterpreterExistsQuery::getSampleBlock()
 {
-    return {{ std::make_shared<DataTypeUInt8>(), "result" }};
+    return Block{{
+        ColumnUInt8::create(),
+        std::make_shared<DataTypeUInt8>(),
+        "result" }};
 }
 
 
diff --git a/dbms/src/Interpreters/InterpreterExistsQuery.h b/dbms/src/Interpreters/InterpreterExistsQuery.h
index e8a4d5e45ca4..b2050b443d85 100644
--- a/dbms/src/Interpreters/InterpreterExistsQuery.h
+++ b/dbms/src/Interpreters/InterpreterExistsQuery.h
@@ -21,11 +21,12 @@ class InterpreterExistsQuery : public IInterpreter
 
     BlockIO execute() override;
 
+    static Block getSampleBlock();
+
 private:
     ASTPtr query_ptr;
     const Context & context;
 
-    Block getSampleBlock();
     BlockInputStreamPtr executeImpl();
 };
 
diff --git a/dbms/src/Interpreters/InterpreterInsertQuery.cpp b/dbms/src/Interpreters/InterpreterInsertQuery.cpp
index 7ae0708fb05e..63eea9542b81 100644
--- a/dbms/src/Interpreters/InterpreterInsertQuery.cpp
+++ b/dbms/src/Interpreters/InterpreterInsertQuery.cpp
@@ -140,11 +140,10 @@ BlockIO InterpreterInsertQuery::execute()
     else
     {
         InterpreterSelectQuery interpreter_select{query.select, context};
-        res.in_sample = interpreter_select.getSampleBlock();
 
         res.in = interpreter_select.execute().in;
 
-        res.in = std::make_shared<NullableAdapterBlockInputStream>(res.in, res.in_sample, res.out_sample);
+        res.in = std::make_shared<NullableAdapterBlockInputStream>(res.in, res.in->getHeader(), res.out_sample);
         res.in = std::make_shared<CastTypeBlockInputStream>(context, res.in, res.out_sample);
         res.in = std::make_shared<NullAndDoCopyBlockInputStream>(res.in, out);
     }
diff --git a/dbms/src/Interpreters/InterpreterKillQueryQuery.cpp b/dbms/src/Interpreters/InterpreterKillQueryQuery.cpp
index 20c0ae143545..648054553685 100644
--- a/dbms/src/Interpreters/InterpreterKillQueryQuery.cpp
+++ b/dbms/src/Interpreters/InterpreterKillQueryQuery.cpp
@@ -105,7 +105,7 @@ class SyncKillQueryInputStream : public IProfilingBlockInputStream
 
     SyncKillQueryInputStream(ProcessList & process_list_, QueryDescriptors && processes_to_stop_, Block && processes_block_,
                              const Block & res_sample_block_)
-    :     process_list(process_list_),
+        : process_list(process_list_),
         processes_to_stop(std::move(processes_to_stop_)),
         processes_block(std::move(processes_block_)),
         res_sample_block(res_sample_block_)
@@ -118,10 +118,7 @@ class SyncKillQueryInputStream : public IProfilingBlockInputStream
         return "SynchronousQueryKiller";
     }
 
-    String getID() const override
-    {
-        return "SynchronousQueryKiller_" + toString(intptr_t(this));
-    }
+    Block getHeader() const override { return res_sample_block; };
 
     Block readImpl() override
     {
@@ -185,25 +182,25 @@ BlockIO InterpreterKillQueryQuery::execute()
     ProcessList & process_list = context.getProcessList();
     QueryDescriptors queries_to_stop = extractQueriesExceptMeAndCheckAccess(processes_block, context);
 
-    res_io.in_sample = processes_block.cloneEmpty();
-    res_io.in_sample.insert(0, {ColumnString::create(), std::make_shared<DataTypeString>(), "kill_status"});
+    auto header = processes_block.cloneEmpty();
+    header.insert(0, {ColumnString::create(), std::make_shared<DataTypeString>(), "kill_status"});
 
     if (!query.sync || query.test)
     {
-        MutableColumns res_columns = res_io.in_sample.cloneEmptyColumns();
+        MutableColumns res_columns = header.cloneEmptyColumns();
 
         for (const auto & query_desc : queries_to_stop)
         {
             auto code = (query.test) ? CancellationCode::Unknown : process_list.sendCancelToQuery(query_desc.query_id, query_desc.user);
-            insertResultRow(query_desc.source_num, code, processes_block, res_io.in_sample, res_columns);
+            insertResultRow(query_desc.source_num, code, processes_block, header, res_columns);
         }
 
-        res_io.in = std::make_shared<OneBlockInputStream>(res_io.in_sample.cloneWithColumns(std::move(res_columns)));
+        res_io.in = std::make_shared<OneBlockInputStream>(header.cloneWithColumns(std::move(res_columns)));
     }
     else
     {
         res_io.in = std::make_shared<SyncKillQueryInputStream>(
-            process_list, std::move(queries_to_stop), std::move(processes_block), res_io.in_sample);
+            process_list, std::move(queries_to_stop), std::move(processes_block), header);
     }
 
     return res_io;
diff --git a/dbms/src/Interpreters/InterpreterSelectQuery.cpp b/dbms/src/Interpreters/InterpreterSelectQuery.cpp
index 5eb0bd798aa2..b0579452e6fc 100644
--- a/dbms/src/Interpreters/InterpreterSelectQuery.cpp
+++ b/dbms/src/Interpreters/InterpreterSelectQuery.cpp
@@ -21,6 +21,7 @@
 #include <DataStreams/CreatingSetsBlockInputStream.h>
 #include <DataStreams/MaterializingBlockInputStream.h>
 #include <DataStreams/ConcatBlockInputStream.h>
+#include <DataStreams/OneBlockInputStream.h>
 
 #include <Parsers/ASTSelectQuery.h>
 #include <Parsers/ASTIdentifier.h>
@@ -148,37 +149,48 @@ bool InterpreterSelectQuery::hasAggregation(const ASTSelectQuery & query_ptr)
 
 void InterpreterSelectQuery::basicInit(const BlockInputStreamPtr & input)
 {
-    auto query_table = query.table();
-
-    if (query_table && typeid_cast<ASTSelectQuery *>(query_table.get()))
+    /// Read from prepared input.
+    if (input)
     {
         if (table_column_names.empty())
-        {
-            table_column_names = InterpreterSelectQuery::getSampleBlock(query_table, context).getNamesAndTypesList();
-        }
+            table_column_names = input->getHeader().getNamesAndTypesList();
     }
     else
     {
-        if (query_table && typeid_cast<const ASTFunction *>(query_table.get()))
+        auto table_expression = query.table();
+
+        /// Read from subquery.
+        if (table_expression && typeid_cast<const ASTSelectQuery *>(table_expression.get()))
         {
-            /// Get the table function
-            TableFunctionPtr table_function_ptr = TableFunctionFactory::instance().get(typeid_cast<const ASTFunction *>(query_table.get())->name, context);
-            /// Run it and remember the result
-            storage = table_function_ptr->execute(query_table, context);
+            if (table_column_names.empty())
+                table_column_names = InterpreterSelectQuery::getSampleBlock(table_expression, context).getNamesAndTypesList();
         }
         else
         {
-            String database_name;
-            String table_name;
+            /// Read from table function.
+            if (table_expression && typeid_cast<const ASTFunction *>(table_expression.get()))
+            {
+                /// Get the table function
+                TableFunctionPtr table_function_ptr = TableFunctionFactory::instance().get(
+                    typeid_cast<const ASTFunction *>(table_expression.get())->name, context);
+                /// Run it and remember the result
+                storage = table_function_ptr->execute(table_expression, context);
+            }
+            else
+            {
+                /// Read from table.
+                String database_name;
+                String table_name;
 
-            getDatabaseAndTableNames(database_name, table_name);
+                getDatabaseAndTableNames(database_name, table_name);
 
-            storage = context.getTable(database_name, table_name);
-        }
+                storage = context.getTable(database_name, table_name);
+            }
 
-        table_lock = storage->lockStructure(false, __PRETTY_FUNCTION__);
-        if (table_column_names.empty())
-            table_column_names = storage->getColumnsListNonMaterialized();
+            table_lock = storage->lockStructure(false, __PRETTY_FUNCTION__);
+            if (table_column_names.empty())
+                table_column_names = storage->getColumnsListNonMaterialized();
+        }
     }
 
     if (table_column_names.empty())
@@ -385,14 +397,6 @@ BlockIO InterpreterSelectQuery::execute()
 {
     (void) executeWithoutUnion();
 
-    if (hasNoData())
-    {
-        BlockIO res;
-        res.in = std::make_shared<NullBlockInputStream>();
-        res.in_sample = getSampleBlock();
-        return res;
-    }
-
     executeUnion();
 
     /// Constraints on the result, the quota on the result, and also callback for progress.
@@ -416,8 +420,6 @@ BlockIO InterpreterSelectQuery::execute()
 
     BlockIO res;
     res.in = streams[0];
-    res.in_sample = getSampleBlock();
-
     return res;
 }
 
@@ -553,14 +555,6 @@ void InterpreterSelectQuery::executeSingleQuery()
             chain.clear();
         }
 
-        /** If there is no data.
-         *  This check is specially postponed slightly lower than it could be (immediately after executeFetchColumns),
-         *  for the query to be analyzed, and errors (for example, type mismatches) could be found in it.
-         *  Otherwise, the empty result could be returned for the incorrect query.
-         */
-        if (hasNoData())
-            return;
-
         /// Before executing WHERE and HAVING, remove the extra columns from the block (mostly the aggregation keys).
         if (has_where)
             before_where->prependProjectInput();
@@ -700,10 +694,6 @@ void InterpreterSelectQuery::executeSingleQuery()
         }
     }
 
-    /** If there is no data. */
-    if (hasNoData())
-        return;
-
     SubqueriesForSets subqueries_for_sets = query_analyzer->getSubqueriesForSets();
     if (!subqueries_for_sets.empty())
         executeSubqueriesInSetsAndJoins(subqueries_for_sets);
@@ -724,9 +714,6 @@ static void getLimitLengthAndOffset(ASTSelectQuery & query, size_t & length, siz
 
 QueryProcessingStage::Enum InterpreterSelectQuery::executeFetchColumns()
 {
-    if (!hasNoData())
-        return QueryProcessingStage::FetchColumns;
-
     /// The subquery interpreter, if the subquery
     std::optional<InterpreterSelectQuery> interpreter_subquery;
 
@@ -873,7 +860,22 @@ QueryProcessingStage::Enum InterpreterSelectQuery::executeFetchColumns()
                 optimize_prewhere(*merge_tree);
         }
 
-        streams = storage->read(required_columns, query_info, context, from_stage, max_block_size, max_streams);
+        /// If there was no already prepared input.
+        if (streams.empty())
+            streams = storage->read(required_columns, query_info, context, from_stage, max_block_size, max_streams);
+
+        /// The storage has no data for this query.
+        if (streams.empty())
+        {
+            from_stage = QueryProcessingStage::FetchColumns;
+            Block header;
+            for (const auto & name : required_columns)
+            {
+                auto type = storage->getDataTypeByName(name);
+                header.insert({ type->createColumn(), type, name });
+            }
+            streams.emplace_back(std::make_shared<OneBlockInputStream>(header));
+        }
 
         if (alias_actions)
         {
@@ -927,7 +929,7 @@ QueryProcessingStage::Enum InterpreterSelectQuery::executeFetchColumns()
 }
 
 
-void InterpreterSelectQuery::executeWhere(ExpressionActionsPtr expression)
+void InterpreterSelectQuery::executeWhere(const ExpressionActionsPtr & expression)
 {
     transformStreams([&](auto & stream)
     {
@@ -936,7 +938,7 @@ void InterpreterSelectQuery::executeWhere(ExpressionActionsPtr expression)
 }
 
 
-void InterpreterSelectQuery::executeAggregation(ExpressionActionsPtr expression, bool overflow_row, bool final)
+void InterpreterSelectQuery::executeAggregation(const ExpressionActionsPtr & expression, bool overflow_row, bool final)
 {
     transformStreams([&](auto & stream)
     {
@@ -947,6 +949,15 @@ void InterpreterSelectQuery::executeAggregation(ExpressionActionsPtr expression,
     AggregateDescriptions aggregates;
     query_analyzer->getAggregateInfo(key_names, aggregates);
 
+    Block header = streams[0]->getHeader();
+    ColumnNumbers keys;
+    for (const auto & name : key_names)
+        keys.push_back(header.getPositionByName(name));
+    for (auto & descr : aggregates)
+        if (descr.arguments.empty())
+            for (const auto & name : descr.argument_names)
+                descr.arguments.push_back(header.getPositionByName(name));
+
     const Settings & settings = context.getSettingsRef();
 
     /** Two-level aggregation is useful in two cases:
@@ -955,7 +966,7 @@ void InterpreterSelectQuery::executeAggregation(ExpressionActionsPtr expression,
       */
     bool allow_to_use_two_level_group_by = streams.size() > 1 || settings.limits.max_bytes_before_external_group_by != 0;
 
-    Aggregator::Params params(key_names, aggregates,
+    Aggregator::Params params(header, keys, aggregates,
         overflow_row, settings.limits.max_rows_to_group_by, settings.limits.group_by_overflow_mode,
         settings.compile ? &context.getCompiler() : nullptr, settings.min_count_to_compile,
         allow_to_use_two_level_group_by ? settings.group_by_two_level_threshold : SettingUInt64(0),
@@ -999,6 +1010,12 @@ void InterpreterSelectQuery::executeMergeAggregated(bool overflow_row, bool fina
     AggregateDescriptions aggregates;
     query_analyzer->getAggregateInfo(key_names, aggregates);
 
+    Block header = streams[0]->getHeader();
+
+    ColumnNumbers keys;
+    for (const auto & name : key_names)
+        keys.push_back(header.getPositionByName(name));
+
     /** There are two modes of distributed aggregation.
       *
       * 1. In different threads read from the remote servers blocks.
@@ -1014,7 +1031,7 @@ void InterpreterSelectQuery::executeMergeAggregated(bool overflow_row, bool fina
       *  but it can work more slowly.
       */
 
-    Aggregator::Params params(key_names, aggregates, overflow_row);
+    Aggregator::Params params(header, keys, aggregates, overflow_row);
 
     const Settings & settings = context.getSettingsRef();
 
@@ -1039,7 +1056,7 @@ void InterpreterSelectQuery::executeMergeAggregated(bool overflow_row, bool fina
 }
 
 
-void InterpreterSelectQuery::executeHaving(ExpressionActionsPtr expression)
+void InterpreterSelectQuery::executeHaving(const ExpressionActionsPtr & expression)
 {
     transformStreams([&](auto & stream)
     {
@@ -1048,7 +1065,7 @@ void InterpreterSelectQuery::executeHaving(ExpressionActionsPtr expression)
 }
 
 
-void InterpreterSelectQuery::executeTotalsAndHaving(bool has_having, ExpressionActionsPtr expression, bool overflow_row)
+void InterpreterSelectQuery::executeTotalsAndHaving(bool has_having, const ExpressionActionsPtr & expression, bool overflow_row)
 {
     executeUnion();
 
@@ -1060,7 +1077,7 @@ void InterpreterSelectQuery::executeTotalsAndHaving(bool has_having, ExpressionA
 }
 
 
-void InterpreterSelectQuery::executeExpression(ExpressionActionsPtr expression)
+void InterpreterSelectQuery::executeExpression(const ExpressionActionsPtr & expression)
 {
     transformStreams([&](auto & stream)
     {
@@ -1161,7 +1178,7 @@ void InterpreterSelectQuery::executeMergeSorted()
 }
 
 
-void InterpreterSelectQuery::executeProjection(ExpressionActionsPtr expression)
+void InterpreterSelectQuery::executeProjection(const ExpressionActionsPtr & expression)
 {
     transformStreams([&](auto & stream)
     {
@@ -1339,12 +1356,6 @@ void InterpreterSelectQuery::transformStreams(Transform && transform)
 }
 
 
-bool InterpreterSelectQuery::hasNoData() const
-{
-    return streams.empty() && !stream_with_non_joined_data;
-}
-
-
 bool InterpreterSelectQuery::hasMoreThanOneStream() const
 {
     return streams.size() + (stream_with_non_joined_data ? 1 : 0) > 1;
diff --git a/dbms/src/Interpreters/InterpreterSelectQuery.h b/dbms/src/Interpreters/InterpreterSelectQuery.h
index 57e8c925f986..cfc61e35f2c9 100644
--- a/dbms/src/Interpreters/InterpreterSelectQuery.h
+++ b/dbms/src/Interpreters/InterpreterSelectQuery.h
@@ -80,6 +80,7 @@ class InterpreterSelectQuery : public IInterpreter
      */
     const BlockInputStreams & executeWithoutUnion();
 
+    /// TODO It's confusing that these methods return result structure for the case of QueryProcessingStage::Complete regardless to the actual 'to_stage'.
     DataTypes getReturnTypes();
     Block getSampleBlock();
 
@@ -137,19 +138,19 @@ class InterpreterSelectQuery : public IInterpreter
     /// Fetch data from the table. Returns the stage to which the query was processed in Storage.
     QueryProcessingStage::Enum executeFetchColumns();
 
-    void executeWhere(ExpressionActionsPtr expression);
-    void executeAggregation(ExpressionActionsPtr expression, bool overflow_row, bool final);
+    void executeWhere(const ExpressionActionsPtr & expression);
+    void executeAggregation(const ExpressionActionsPtr & expression, bool overflow_row, bool final);
     void executeMergeAggregated(bool overflow_row, bool final);
-    void executeTotalsAndHaving(bool has_having, ExpressionActionsPtr expression, bool overflow_row);
-    void executeHaving(ExpressionActionsPtr expression);
-    void executeExpression(ExpressionActionsPtr expression);
+    void executeTotalsAndHaving(bool has_having, const ExpressionActionsPtr & expression, bool overflow_row);
+    void executeHaving(const ExpressionActionsPtr & expression);
+    void executeExpression(const ExpressionActionsPtr & expression);
     void executeOrder();
     void executeMergeSorted();
     void executePreLimit();
     void executeUnion();
     void executeLimitBy();
     void executeLimit();
-    void executeProjection(ExpressionActionsPtr expression);
+    void executeProjection(const ExpressionActionsPtr & expression);
     void executeDistinct(bool before_order, Names columns);
     void executeSubqueriesInSetsAndJoins(std::unordered_map<String, SubqueryForSet> & subqueries_for_sets);
 
diff --git a/dbms/src/Interpreters/InterpreterShowCreateQuery.cpp b/dbms/src/Interpreters/InterpreterShowCreateQuery.cpp
index ab0c83a19715..774515c9cc35 100644
--- a/dbms/src/Interpreters/InterpreterShowCreateQuery.cpp
+++ b/dbms/src/Interpreters/InterpreterShowCreateQuery.cpp
@@ -19,15 +19,16 @@ BlockIO InterpreterShowCreateQuery::execute()
 {
     BlockIO res;
     res.in = executeImpl();
-    res.in_sample = getSampleBlock();
-
     return res;
 }
 
 
 Block InterpreterShowCreateQuery::getSampleBlock()
 {
-    return {{ std::make_shared<DataTypeString>(), "statement" }};
+    return Block{{
+        ColumnString::create(),
+        std::make_shared<DataTypeString>(),
+        "statement"}};
 }
 
 
diff --git a/dbms/src/Interpreters/InterpreterShowCreateQuery.h b/dbms/src/Interpreters/InterpreterShowCreateQuery.h
index 7fa85230f04f..5e8672c17678 100644
--- a/dbms/src/Interpreters/InterpreterShowCreateQuery.h
+++ b/dbms/src/Interpreters/InterpreterShowCreateQuery.h
@@ -21,11 +21,12 @@ class InterpreterShowCreateQuery : public IInterpreter
 
     BlockIO execute() override;
 
+    static Block getSampleBlock();
+
 private:
     ASTPtr query_ptr;
     const Context & context;
 
-    Block getSampleBlock();
     BlockInputStreamPtr executeImpl();
 };
 
diff --git a/dbms/src/Interpreters/Join.cpp b/dbms/src/Interpreters/Join.cpp
index aa406ca9b58f..c469fc733a8f 100644
--- a/dbms/src/Interpreters/Join.cpp
+++ b/dbms/src/Interpreters/Join.cpp
@@ -1038,12 +1038,7 @@ class NonJoinedBlockInputStream : public IProfilingBlockInputStream
 
     String getName() const override { return "NonJoined"; }
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << "NonJoined(" << &parent << ")";
-        return res.str();
-    }
+    Block getHeader() const override { return result_sample_block; };
 
 
 protected:
diff --git a/dbms/src/Interpreters/castColumn.cpp b/dbms/src/Interpreters/castColumn.cpp
index daa75081c526..6c5d68d4c7be 100644
--- a/dbms/src/Interpreters/castColumn.cpp
+++ b/dbms/src/Interpreters/castColumn.cpp
@@ -9,6 +9,9 @@ namespace DB
 
 ColumnPtr castColumn(const ColumnWithTypeAndName & arg, const DataTypePtr & type, const Context & context)
 {
+    if (arg.type->equals(*type))
+        return arg.column;
+
     Block temporary_block
     {
         arg,
diff --git a/dbms/src/Interpreters/executeQuery.cpp b/dbms/src/Interpreters/executeQuery.cpp
index c7cb2f58f6b9..eb31be2a80f5 100644
--- a/dbms/src/Interpreters/executeQuery.cpp
+++ b/dbms/src/Interpreters/executeQuery.cpp
@@ -442,7 +442,7 @@ void executeQuery(
                 ? typeid_cast<const ASTIdentifier &>(*ast_query_with_output->format).name
                 : context.getDefaultFormat();
 
-            BlockOutputStreamPtr out = context.getOutputFormat(format_name, *out_buf, streams.in_sample);
+            BlockOutputStreamPtr out = context.getOutputFormat(format_name, *out_buf, streams.in->getHeader());
 
             if (auto stream = dynamic_cast<IProfilingBlockInputStream *>(streams.in.get()))
             {
diff --git a/dbms/src/Server/Benchmark.cpp b/dbms/src/Server/Benchmark.cpp
index ceeb75acccea..989ab07aa0fe 100644
--- a/dbms/src/Server/Benchmark.cpp
+++ b/dbms/src/Server/Benchmark.cpp
@@ -303,7 +303,7 @@ class Benchmark
     void execute(ConnectionPool::Entry & connection, Query & query)
     {
         Stopwatch watch;
-        RemoteBlockInputStream stream(*connection, query, global_context, &settings, nullptr, Tables(), query_processing_stage);
+        RemoteBlockInputStream stream(*connection, query, {}, global_context, &settings, nullptr, Tables(), query_processing_stage);
 
         Progress progress;
         stream.setProgressCallback([&progress](const Progress & value) { progress.incrementPiecewiseAtomically(value); });
diff --git a/dbms/src/Server/ClusterCopier.cpp b/dbms/src/Server/ClusterCopier.cpp
index 7e0e9b27a8a2..02dbf7367c24 100644
--- a/dbms/src/Server/ClusterCopier.cpp
+++ b/dbms/src/Server/ClusterCopier.cpp
@@ -25,6 +25,8 @@
 #include <Interpreters/Cluster.h>
 #include <Interpreters/InterpreterSelectQuery.h>
 #include <Interpreters/InterpreterInsertQuery.h>
+#include <Interpreters/InterpreterExistsQuery.h>
+#include <Interpreters/InterpreterShowCreateQuery.h>
 #include <Interpreters/InterpreterFactory.h>
 #include <Interpreters/InterpreterDropQuery.h>
 #include <Interpreters/InterpreterCreateQuery.h>
@@ -49,6 +51,7 @@
 #include <DataStreams/SquashingBlockInputStream.h>
 #include <Common/isLocalAddress.h>
 #include <DataStreams/copyData.h>
+#include <DataTypes/DataTypeString.h>
 #include <DataStreams/NullBlockOutputStream.h>
 #include <IO/Operators.h>
 #include <IO/ReadBufferFromString.h>
@@ -1405,14 +1408,16 @@ class ClusterCopier
     bool existsRemoteTable(const DatabaseAndTableName & table, Connection & connection)
     {
         String query = "EXISTS " + getDatabaseDotTable(table);
-        Block block = getBlockWithAllStreamData(std::make_shared<RemoteBlockInputStream>(connection, query, context));
+        Block block = getBlockWithAllStreamData(std::make_shared<RemoteBlockInputStream>(
+            connection, query, InterpreterExistsQuery::getSampleBlock(), context));
         return block.safeGetByPosition(0).column->getUInt(0) != 0;
     }
 
     String getRemoteCreateTable(const DatabaseAndTableName & table, Connection & connection, const Settings * settings = nullptr)
     {
         String query = "SHOW CREATE TABLE " + getDatabaseDotTable(table);
-        Block block = getBlockWithAllStreamData(std::make_shared<RemoteBlockInputStream>(connection, query, context, settings));
+        Block block = getBlockWithAllStreamData(std::make_shared<RemoteBlockInputStream>(
+            connection, query, InterpreterShowCreateQuery::getSampleBlock(), context, settings));
 
         return typeid_cast<const ColumnString &>(*block.safeGetByPosition(0).column).getDataAt(0).toString();
     }
@@ -1426,7 +1431,8 @@ class ClusterCopier
                << " database = " << DB::quote << table.first
                << " AND table = " << DB::quote << table.second;
 
-            block = getBlockWithAllStreamData(std::make_shared<RemoteBlockInputStream>(connection, wb.str(), context, settings));
+            block = getBlockWithAllStreamData(std::make_shared<RemoteBlockInputStream>(
+                connection, wb.str(), Block{{ ColumnString::create(), std::make_shared<DataTypeString>(), "partition" }}, context, settings));
         }
 
         Strings res;
@@ -1449,8 +1455,8 @@ class ClusterCopier
     }
 
     /** Executes simple query (without output streams, for example DDL queries) on each shard of the cluster
-     * Returns number of shards for which at least one replica executed query successfully
-     */
+      * Returns number of shards for which at least one replica executed query successfully
+      */
     size_t executeQueryOnCluster(
         const ClusterPtr & cluster,
         const String & query,
@@ -1513,7 +1519,7 @@ class ClusterCopier
                     {
                         try
                         {
-                            RemoteBlockInputStream stream(*connection, query, context, &current_settings);
+                            RemoteBlockInputStream stream(*connection, query, {}, context, &current_settings);
                             NullBlockOutputStream output;
                             copyData(stream, output);
 
diff --git a/dbms/src/Server/PerformanceTest.cpp b/dbms/src/Server/PerformanceTest.cpp
index e111c53f7cab..d5239ac0e49a 100644
--- a/dbms/src/Server/PerformanceTest.cpp
+++ b/dbms/src/Server/PerformanceTest.cpp
@@ -1087,7 +1087,7 @@ class PerformanceTest
         statistics.last_query_rows_read = 0;
         statistics.last_query_bytes_read = 0;
 
-        RemoteBlockInputStream stream(connection, query, global_context, &settings);
+        RemoteBlockInputStream stream(connection, query, {}, global_context, &settings);
 
         stream.setProgressCallback(
             [&](const Progress & value) { this->checkFulfilledConditionsAndUpdate(value, stream, statistics, stop_conditions); });
diff --git a/dbms/src/Server/TCPHandler.cpp b/dbms/src/Server/TCPHandler.cpp
index 8aec67aa2ba4..e27d4f088e0e 100644
--- a/dbms/src/Server/TCPHandler.cpp
+++ b/dbms/src/Server/TCPHandler.cpp
@@ -32,6 +32,7 @@
 
 #include <Common/NetException.h>
 
+
 namespace DB
 {
 
@@ -302,8 +303,11 @@ void TCPHandler::processOrdinaryQuery()
     if (state.io.in)
     {
         /// Send header-block, to allow client to prepare output format for data to send.
-        if (state.io.in_sample)
-            sendData(state.io.in_sample);
+        {
+            Block header = state.io.in->getHeader();
+            if (header)
+                sendData(header);
+        }
 
         AsynchronousBlockInputStream async_in(state.io.in);
         async_in.readPrefix();
@@ -338,12 +342,12 @@ void TCPHandler::processOrdinaryQuery()
                 }
             }
 
-        /** If data has run out, we will send the profiling data and total values to
-          * the last zero block to be able to use
-          * this information in the suffix output of stream.
-          * If the request was interrupted, then `sendTotals` and other methods could not be called,
-          *  because we have not read all the data yet,
-          *  and there could be ongoing calculations in other threads at the same time.
+            /** If data has run out, we will send the profiling data and total values to
+              * the last zero block to be able to use
+              * this information in the suffix output of stream.
+              * If the request was interrupted, then `sendTotals` and other methods could not be called,
+              *  because we have not read all the data yet,
+              *  and there could be ongoing calculations in other threads at the same time.
               */
             if (!block && !isQueryCancelled())
             {
@@ -709,7 +713,7 @@ bool TCPHandler::isQueryCancelled()
 }
 
 
-void TCPHandler::sendData(Block & block)
+void TCPHandler::sendData(const Block & block)
 {
     initBlockOutput();
 
diff --git a/dbms/src/Server/TCPHandler.h b/dbms/src/Server/TCPHandler.h
index e699e5b44ebb..93b82acd7ead 100644
--- a/dbms/src/Server/TCPHandler.h
+++ b/dbms/src/Server/TCPHandler.h
@@ -130,7 +130,7 @@ class TCPHandler : public Poco::Net::TCPServerConnection
     void processTablesStatusRequest();
 
     void sendHello();
-    void sendData(Block & block);    /// Write a block to the network.
+    void sendData(const Block & block);    /// Write a block to the network.
     void sendException(const Exception & e);
     void sendProgress();
     void sendEndOfStream();
diff --git a/dbms/src/Storages/ITableDeclaration.cpp b/dbms/src/Storages/ITableDeclaration.cpp
index 8bc53a8163cf..da4cc920608e 100644
--- a/dbms/src/Storages/ITableDeclaration.cpp
+++ b/dbms/src/Storages/ITableDeclaration.cpp
@@ -121,6 +121,20 @@ Block ITableDeclaration::getSampleBlockNonMaterialized() const
 }
 
 
+Block ITableDeclaration::getSampleBlockForColumns(const Names & column_names) const
+{
+    Block res;
+
+    for (const auto & name : column_names)
+    {
+        auto col = getColumn(name);
+        res.insert({ col.type->createColumn(), col.type, name });
+    }
+
+    return res;
+}
+
+
 static std::string listOfColumns(const NamesAndTypesList & available_columns)
 {
     std::stringstream s;
diff --git a/dbms/src/Storages/ITableDeclaration.h b/dbms/src/Storages/ITableDeclaration.h
index 19c57d45e40e..335ca7ace3d2 100644
--- a/dbms/src/Storages/ITableDeclaration.h
+++ b/dbms/src/Storages/ITableDeclaration.h
@@ -59,6 +59,7 @@ class ITableDeclaration
       */
     Block getSampleBlock() const;
     Block getSampleBlockNonMaterialized() const;
+    Block getSampleBlockForColumns(const Names & column_names) const;
 
     /** Verify that all the requested names are in the table and are set correctly.
       * (the list of names is not empty and the names do not repeat)
diff --git a/dbms/src/Storages/MergeTree/MergeTreeBlockInputStream.cpp b/dbms/src/Storages/MergeTree/MergeTreeBlockInputStream.cpp
index 7b93c1fd1811..fcfb00084cfd 100644
--- a/dbms/src/Storages/MergeTree/MergeTreeBlockInputStream.cpp
+++ b/dbms/src/Storages/MergeTree/MergeTreeBlockInputStream.cpp
@@ -62,26 +62,13 @@ MergeTreeBlockInputStream::MergeTreeBlockInputStream(
     setTotalRowsApprox(total_rows);
 }
 
-String MergeTreeBlockInputStream::getID() const
-{
-    std::stringstream res;
-    res << "MergeTree(" << path << ", columns";
-
-    for (const NameAndTypePair & column : columns)
-        res << ", " << column.name;
-
-    if (prewhere_actions)
-        res << ", prewhere, " << prewhere_actions->getID();
 
-    res << ", marks";
-
-    for (size_t i = 0; i < all_mark_ranges.size(); ++i)
-        res << ", " << all_mark_ranges[i].begin << ", " << all_mark_ranges[i].end;
-
-    res << ")";
-    return res.str();
+Block MergeTreeBlockInputStream::getHeader() const
+{
+    return storage.getSampleBlockForColumns(ordered_names);
 }
 
+
 bool MergeTreeBlockInputStream::getNewTask()
 try
 {
diff --git a/dbms/src/Storages/MergeTree/MergeTreeBlockInputStream.h b/dbms/src/Storages/MergeTree/MergeTreeBlockInputStream.h
index 6eb9c2e85778..9739cfd49fca 100644
--- a/dbms/src/Storages/MergeTree/MergeTreeBlockInputStream.h
+++ b/dbms/src/Storages/MergeTree/MergeTreeBlockInputStream.h
@@ -38,7 +38,7 @@ class MergeTreeBlockInputStream : public MergeTreeBaseBlockInputStream
 
     String getName() const override { return "MergeTree"; }
 
-    String getID() const override;
+    Block getHeader() const override;
 
     /// Closes readers and unlock part locks
     void finish();
diff --git a/dbms/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp b/dbms/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp
index 9ded38715bca..79d5d226f31e 100644
--- a/dbms/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp
+++ b/dbms/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp
@@ -475,7 +475,7 @@ BlockInputStreams MergeTreeDataSelectExecutor::read(
 
             filter_expression = ExpressionAnalyzer(filter_function, context, nullptr, available_real_columns).getActions(false);
 
-            /// Add columns needed for `sampling_expression`.
+            /// Add columns needed for `sampling_expression` to `column_names_to_read`.
             std::vector<String> add_columns = filter_expression->getRequiredColumns();
             column_names_to_read.insert(column_names_to_read.end(), add_columns.begin(), add_columns.end());
             std::sort(column_names_to_read.begin(), column_names_to_read.end());
@@ -508,7 +508,7 @@ BlockInputStreams MergeTreeDataSelectExecutor::read(
           * They are done before the execution of the pipeline; they can not be interrupted; during the computation, packets of progress are not sent.
           */
         if (!prewhere_subqueries.empty())
-            CreatingSetsBlockInputStream(std::make_shared<NullBlockInputStream>(), prewhere_subqueries, settings.limits).read();
+            CreatingSetsBlockInputStream(std::make_shared<NullBlockInputStream>(Block()), prewhere_subqueries, settings.limits).read();
     }
 
     RangesInDataParts parts_with_ranges;
diff --git a/dbms/src/Storages/MergeTree/MergeTreeReadPool.cpp b/dbms/src/Storages/MergeTree/MergeTreeReadPool.cpp
index c30ddb3d27b3..e95c576274c6 100644
--- a/dbms/src/Storages/MergeTree/MergeTreeReadPool.cpp
+++ b/dbms/src/Storages/MergeTree/MergeTreeReadPool.cpp
@@ -117,6 +117,12 @@ MergeTreeReadTaskPtr MergeTreeReadPool::getTask(const size_t min_marks_to_read,
 }
 
 
+Block MergeTreeReadPool::getHeader() const
+{
+    return data.getSampleBlockForColumns(column_names);
+}
+
+
 void MergeTreeReadPool::profileFeedback(const ReadBufferFromFileBase::ProfileInfo info)
 {
     if (backoff_settings.min_read_latency_ms == 0 || do_not_steal_tasks)
diff --git a/dbms/src/Storages/MergeTree/MergeTreeReadPool.h b/dbms/src/Storages/MergeTree/MergeTreeReadPool.h
index e93a248bab1f..cf7a9c71ef16 100644
--- a/dbms/src/Storages/MergeTree/MergeTreeReadPool.h
+++ b/dbms/src/Storages/MergeTree/MergeTreeReadPool.h
@@ -79,6 +79,8 @@ class MergeTreeReadPool : private boost::noncopyable
       */
     void profileFeedback(const ReadBufferFromFileBase::ProfileInfo info);
 
+    Block getHeader() const;
+
 private:
     std::vector<size_t> fillPerPartInfo(
         RangesInDataParts & parts, const ExpressionActionsPtr & prewhere_actions, const String & prewhere_column_name,
diff --git a/dbms/src/Storages/MergeTree/MergeTreeThreadBlockInputStream.cpp b/dbms/src/Storages/MergeTree/MergeTreeThreadBlockInputStream.cpp
index b4e1cff0c930..ec961f28a99e 100644
--- a/dbms/src/Storages/MergeTree/MergeTreeThreadBlockInputStream.cpp
+++ b/dbms/src/Storages/MergeTree/MergeTreeThreadBlockInputStream.cpp
@@ -38,13 +38,10 @@ MergeTreeThreadBlockInputStream::MergeTreeThreadBlockInputStream(
 }
 
 
-String MergeTreeThreadBlockInputStream::getID() const
+Block MergeTreeThreadBlockInputStream::getHeader() const
 {
-    std::stringstream res;
-    /// @todo print some meaningful information
-    res << static_cast<const void *>(this);
-    return res.str();
-}
+    return pool->getHeader();
+};
 
 
 /// Requests read task from MergeTreeReadPool and signals whether it got one
diff --git a/dbms/src/Storages/MergeTree/MergeTreeThreadBlockInputStream.h b/dbms/src/Storages/MergeTree/MergeTreeThreadBlockInputStream.h
index 058746a5d15d..1a9c9a11befb 100644
--- a/dbms/src/Storages/MergeTree/MergeTreeThreadBlockInputStream.h
+++ b/dbms/src/Storages/MergeTree/MergeTreeThreadBlockInputStream.h
@@ -1,5 +1,5 @@
 #pragma once
-#include "MergeTreeBaseBlockInputStream.h"
+#include <Storages/MergeTree/MergeTreeBaseBlockInputStream.h>
 
 
 namespace DB
@@ -30,10 +30,10 @@ class MergeTreeThreadBlockInputStream : public MergeTreeBaseBlockInputStream
 
     String getName() const override { return "MergeTreeThread"; }
 
-    String getID() const override;
-
     ~MergeTreeThreadBlockInputStream() override;
 
+    Block getHeader() const override;
+
 protected:
     /// Requests read task from MergeTreeReadPool and signals whether it got one
     bool getNewTask() override;
diff --git a/dbms/src/Storages/MergeTree/ReplicatedMergeTreeBlockOutputStream.cpp b/dbms/src/Storages/MergeTree/ReplicatedMergeTreeBlockOutputStream.cpp
index bdcad7f0fe17..80992a79935a 100644
--- a/dbms/src/Storages/MergeTree/ReplicatedMergeTreeBlockOutputStream.cpp
+++ b/dbms/src/Storages/MergeTree/ReplicatedMergeTreeBlockOutputStream.cpp
@@ -417,7 +417,6 @@ void ReplicatedMergeTreeBlockOutputStream::commitPart(zkutil::ZooKeeperPtr & zoo
                         + zkutil::ZooKeeper::error2string(info.code), ErrorCodes::UNEXPECTED_ZOOKEEPER_ERROR);
     }
 
-
     if (quorum)
     {
         /// We are waiting for quorum to be satisfied.
diff --git a/dbms/src/Storages/StorageBuffer.cpp b/dbms/src/Storages/StorageBuffer.cpp
index ced007a4ced6..ec4f7b498da7 100644
--- a/dbms/src/Storages/StorageBuffer.cpp
+++ b/dbms/src/Storages/StorageBuffer.cpp
@@ -71,25 +71,15 @@ StorageBuffer::StorageBuffer(const std::string & name_, const NamesAndTypesList
 class BufferBlockInputStream : public IProfilingBlockInputStream
 {
 public:
-    BufferBlockInputStream(const Names & column_names_, StorageBuffer::Buffer & buffer_)
-        : column_names(column_names_.begin(), column_names_.end()), buffer(buffer_) {}
+    BufferBlockInputStream(const Names & column_names_, StorageBuffer::Buffer & buffer_, const StorageBuffer & storage_)
+        : column_names(column_names_.begin(), column_names_.end()), buffer(buffer_), storage(storage_) {}
 
-    String getName() const { return "Buffer"; }
+    String getName() const override { return "Buffer"; }
 
-    String getID() const
-    {
-        std::stringstream res;
-        res << "Buffer(" << &buffer;
-
-        for (const auto & name : column_names)
-            res << ", " << name;
-
-        res << ")";
-        return res.str();
-    }
+    Block getHeader() const override { return storage.getSampleBlockForColumns(column_names); };
 
 protected:
-    Block readImpl()
+    Block readImpl() override
     {
         Block res;
 
@@ -111,6 +101,7 @@ class BufferBlockInputStream : public IProfilingBlockInputStream
 private:
     Names column_names;
     StorageBuffer::Buffer & buffer;
+    const StorageBuffer & storage;
     bool has_been_read = false;
 };
 
@@ -140,7 +131,7 @@ BlockInputStreams StorageBuffer::read(
     BlockInputStreams streams_from_buffers;
     streams_from_buffers.reserve(num_shards);
     for (auto & buf : buffers)
-        streams_from_buffers.push_back(std::make_shared<BufferBlockInputStream>(column_names, buf));
+        streams_from_buffers.push_back(std::make_shared<BufferBlockInputStream>(column_names, buf, *this));
 
     /** If the sources from the table were processed before some non-initial stage of query execution,
       * then sources from the buffers must also be wrapped in the processing pipeline before the same stage.
diff --git a/dbms/src/Storages/StorageCatBoostPool.cpp b/dbms/src/Storages/StorageCatBoostPool.cpp
index d6c1b4291b98..d484158b0181 100644
--- a/dbms/src/Storages/StorageCatBoostPool.cpp
+++ b/dbms/src/Storages/StorageCatBoostPool.cpp
@@ -39,11 +39,6 @@ class CatBoostDatasetBlockInputStream : public IProfilingBlockInputStream
         return "CatBoostDatasetBlockInputStream";
     }
 
-    String getID() const override
-    {
-        return "CatBoostDataset(" + format_name + ", " + file_name + ")";
-    }
-
     Block readImpl() override
     {
         return reader->read();
@@ -59,6 +54,8 @@ class CatBoostDatasetBlockInputStream : public IProfilingBlockInputStream
         reader->readSuffix();
     }
 
+    Block getHeader() const override { return sample_block; };
+
 private:
     Block sample_block;
     std::unique_ptr<ReadBufferFromFileDescriptor> read_buf;
diff --git a/dbms/src/Storages/StorageDistributed.cpp b/dbms/src/Storages/StorageDistributed.cpp
index 747fc8ff4fac..e6683d6218bf 100644
--- a/dbms/src/Storages/StorageDistributed.cpp
+++ b/dbms/src/Storages/StorageDistributed.cpp
@@ -1,6 +1,4 @@
-#include <DataStreams/RemoteBlockInputStream.h>
-#include <DataStreams/BlockExtraInfoInputStream.h>
-#include <DataStreams/UnionBlockInputStream.h>
+#include <DataStreams/OneBlockInputStream.h>
 
 #include <Databases/IDatabase.h>
 
@@ -172,7 +170,7 @@ StoragePtr StorageDistributed::createWithOwnCluster(
 
 
 BlockInputStreams StorageDistributed::read(
-    const Names & /*column_names*/,
+    const Names & column_names,
     const SelectQueryInfo & query_info,
     const Context & context,
     QueryProcessingStage::Enum & processed_stage,
@@ -197,11 +195,14 @@ BlockInputStreams StorageDistributed::read(
     if (settings.global_subqueries_method == GlobalSubqueriesMethod::PUSH)
         external_tables = context.getExternalTables();
 
+    Block header = InterpreterSelectQuery(query_info.query, context, processed_stage, 0,
+        std::make_shared<OneBlockInputStream>(getSampleBlockForColumns(column_names))).execute().in->getHeader();
+
     ClusterProxy::SelectStreamFactory select_stream_factory(
-        processed_stage, QualifiedTableName{remote_database, remote_table}, external_tables);
+        header, processed_stage, QualifiedTableName{remote_database, remote_table}, external_tables);
 
     return ClusterProxy::executeQuery(
-            select_stream_factory, cluster, modified_query_ast, context, settings);
+        select_stream_factory, cluster, modified_query_ast, context, settings);
 }
 
 
diff --git a/dbms/src/Storages/StorageFile.cpp b/dbms/src/Storages/StorageFile.cpp
index 57d567ff9039..1bbe9d6d00c9 100644
--- a/dbms/src/Storages/StorageFile.cpp
+++ b/dbms/src/Storages/StorageFile.cpp
@@ -98,7 +98,6 @@ StorageFile::StorageFile(
 class StorageFileBlockInputStream : public IProfilingBlockInputStream
 {
 public:
-
     StorageFileBlockInputStream(StorageFile & storage_, const Context & context, size_t max_block_size)
         : storage(storage_)
     {
@@ -145,23 +144,13 @@ class StorageFileBlockInputStream : public IProfilingBlockInputStream
         return storage.getName();
     }
 
-    String getID() const override
-    {
-        std::stringstream res_stream;
-        res_stream << "File(" << storage.format_name << ", ";
-        if (!storage.path.empty())
-            res_stream << storage.path;
-        else
-            res_stream << storage.table_fd;
-        res_stream << ")";
-        return res_stream.str();
-    }
-
     Block readImpl() override
     {
         return reader->read();
     }
 
+    Block getHeader() const override { return reader->getHeader(); };
+
     void readPrefixImpl() override
     {
         reader->readPrefix();
diff --git a/dbms/src/Storages/StorageKafka.cpp b/dbms/src/Storages/StorageKafka.cpp
index 61236d34c323..c7ac83d11421 100644
--- a/dbms/src/Storages/StorageKafka.cpp
+++ b/dbms/src/Storages/StorageKafka.cpp
@@ -108,7 +108,8 @@ class ReadBufferFromKafkaConsumer : public ReadBuffer
     ~ReadBufferFromKafkaConsumer() { reset(); }
 
     /// Commit messages read with this consumer
-    void commit() {
+    void commit()
+    {
         LOG_TRACE(log, "Committing " << read_messages << " messages");
         if (read_messages == 0)
             return;
@@ -160,13 +161,6 @@ class KafkaBlockInputStream : public IProfilingBlockInputStream
         return storage.getName();
     }
 
-    String getID() const override
-    {
-        std::stringstream res_stream;
-        res_stream << "Kafka(" << storage.topics.size() << ", " << storage.format_name << ")";
-        return res_stream.str();
-    }
-
     Block readImpl() override
     {
         if (isCancelled())
@@ -175,6 +169,8 @@ class KafkaBlockInputStream : public IProfilingBlockInputStream
         return reader->read();
     }
 
+    Block getHeader() const override { return reader->getHeader(); };
+
     void readPrefixImpl() override
     {
         // Start reading data
diff --git a/dbms/src/Storages/StorageLog.cpp b/dbms/src/Storages/StorageLog.cpp
index 6fdcaa2ed6ac..443510fea42f 100644
--- a/dbms/src/Storages/StorageLog.cpp
+++ b/dbms/src/Storages/StorageLog.cpp
@@ -62,17 +62,15 @@ class LogBlockInputStream final : public IProfilingBlockInputStream
 
     String getName() const override { return "Log"; }
 
-    String getID() const override
+    Block getHeader() const override
     {
-        std::stringstream res;
-        res << "Log(" << storage.getTableName() << ", " << &storage << ", " << mark_number << ", " << rows_limit;
+        Block res;
 
         for (const auto & name_type : columns)
-            res << ", " << name_type.name;
+            res.insert({ name_type.type->createColumn(), name_type.type, name_type.name });
 
-        res << ")";
-        return res.str();
-    }
+        return Nested::flatten(res);
+    };
 
 protected:
     Block readImpl() override;
diff --git a/dbms/src/Storages/StorageMemory.cpp b/dbms/src/Storages/StorageMemory.cpp
index db4be02635cc..89ce474b065d 100644
--- a/dbms/src/Storages/StorageMemory.cpp
+++ b/dbms/src/Storages/StorageMemory.cpp
@@ -20,22 +20,12 @@ namespace ErrorCodes
 class MemoryBlockInputStream : public IProfilingBlockInputStream
 {
 public:
-    MemoryBlockInputStream(const Names & column_names_, BlocksList::iterator begin_, BlocksList::iterator end_)
-        : column_names(column_names_), begin(begin_), end(end_), it(begin) {}
+    MemoryBlockInputStream(const Names & column_names_, BlocksList::iterator begin_, BlocksList::iterator end_, const StorageMemory & storage_)
+        : column_names(column_names_), begin(begin_), end(end_), it(begin), storage(storage_) {}
 
     String getName() const override { return "Memory"; }
 
-    String getID() const override
-    {
-        std::stringstream res;
-        res << "Memory(" << &*begin << ", " << &*end;
-
-        for (const auto & name : column_names)
-            res << ", " << name;
-
-        res << ")";
-        return res.str();
-    }
+    Block getHeader() const override { return storage.getSampleBlockForColumns(column_names); }
 
 protected:
     Block readImpl() override
@@ -62,6 +52,7 @@ class MemoryBlockInputStream : public IProfilingBlockInputStream
     BlocksList::iterator begin;
     BlocksList::iterator end;
     BlocksList::iterator it;
+    const StorageMemory & storage;
 };
 
 
@@ -121,7 +112,7 @@ BlockInputStreams StorageMemory::read(
         std::advance(begin, stream * size / num_streams);
         std::advance(end, (stream + 1) * size / num_streams);
 
-        res.push_back(std::make_shared<MemoryBlockInputStream>(column_names, begin, end));
+        res.push_back(std::make_shared<MemoryBlockInputStream>(column_names, begin, end, *this));
     }
 
     return res;
diff --git a/dbms/src/Storages/StorageMerge.cpp b/dbms/src/Storages/StorageMerge.cpp
index 1e9a590714bd..39be47eab9b2 100644
--- a/dbms/src/Storages/StorageMerge.cpp
+++ b/dbms/src/Storages/StorageMerge.cpp
@@ -137,6 +137,7 @@ BlockInputStreams StorageMerge::read(
     const unsigned num_streams)
 {
     BlockInputStreams res;
+    Block header = getSampleBlockForColumns(column_names);
 
     Names virt_column_names, real_column_names;
     for (const auto & it : column_names)
@@ -223,13 +224,13 @@ BlockInputStreams StorageMerge::read(
             for (auto & stream : source_streams)
             {
                 /// will throw if some columns not convertible
-                stream = std::make_shared<CastTypeBlockInputStream>(context, stream, getSampleBlock());
+                stream = std::make_shared<CastTypeBlockInputStream>(context, stream, header);
             }
         }
         else
         {
             /// If many streams, initialize it lazily, to avoid long delay before start of query processing.
-            source_streams.emplace_back(std::make_shared<LazyBlockInputStream>([=]
+            source_streams.emplace_back(std::make_shared<LazyBlockInputStream>(header, [=]
             {
                 QueryProcessingStage::Enum processed_stage_in_source_table = processed_stage;
                 BlockInputStreams streams = table->read(
@@ -247,11 +248,11 @@ BlockInputStreams StorageMerge::read(
                     throw Exception("Source tables for Merge table are processing data up to different stages",
                         ErrorCodes::INCOMPATIBLE_SOURCE_TABLES);
 
-                auto stream = streams.empty() ? std::make_shared<NullBlockInputStream>() : streams.front();
+                auto stream = streams.empty() ? std::make_shared<NullBlockInputStream>(header) : streams.front();
                 if (!streams.empty())
                 {
                     /// will throw if some columns not convertible
-                    stream = std::make_shared<CastTypeBlockInputStream>(context, stream, getSampleBlock());
+                    stream = std::make_shared<CastTypeBlockInputStream>(context, stream, header);
                 }
                 return stream;
             }));
diff --git a/dbms/src/Storages/StorageNull.h b/dbms/src/Storages/StorageNull.h
index b2d3fb557bf2..e413ff2d9303 100644
--- a/dbms/src/Storages/StorageNull.h
+++ b/dbms/src/Storages/StorageNull.h
@@ -21,14 +21,14 @@ class StorageNull : public ext::shared_ptr_helper<StorageNull>, public IStorage
     std::string getTableName() const override { return name; }
 
     BlockInputStreams read(
-        const Names &,
+        const Names & column_names,
         const SelectQueryInfo &,
         const Context &,
         QueryProcessingStage::Enum &,
         size_t,
         unsigned) override
     {
-        return { std::make_shared<NullBlockInputStream>() };
+        return { std::make_shared<NullBlockInputStream>(getSampleBlockForColumns(column_names)) };
     }
 
     BlockOutputStreamPtr write(const ASTPtr &, const Settings &) override
diff --git a/dbms/src/Storages/StorageReplicatedMergeTree.cpp b/dbms/src/Storages/StorageReplicatedMergeTree.cpp
index d5c1075e07ef..14cc102f6095 100644
--- a/dbms/src/Storages/StorageReplicatedMergeTree.cpp
+++ b/dbms/src/Storages/StorageReplicatedMergeTree.cpp
@@ -1669,7 +1669,7 @@ namespace
 
             if (left->info.max_block <= part_info.min_block && right->info.min_block >= part_info.max_block)
             {
-                if (out_reason) 
+                if (out_reason)
                     *out_reason = "Quorum 'last part' condition is unsatisfied";
                 return false;
             }
@@ -3213,7 +3213,7 @@ void StorageReplicatedMergeTree::sendRequestToLeaderReplica(const ASTPtr & query
         leader_address.database,
         "", "", timeouts, "ClickHouse replica");
 
-    RemoteBlockInputStream stream(connection, formattedAST(new_query), context, &settings);
+    RemoteBlockInputStream stream(connection, formattedAST(new_query), {}, context, &settings);
     NullBlockOutputStream output;
 
     copyData(stream, output);
diff --git a/dbms/src/Storages/StorageSet.cpp b/dbms/src/Storages/StorageSet.cpp
index 3ec37897348b..498e475a4653 100644
--- a/dbms/src/Storages/StorageSet.cpp
+++ b/dbms/src/Storages/StorageSet.cpp
@@ -157,7 +157,7 @@ void StorageSetOrJoinBase::restoreFromFile(const String & file_path)
 {
     ReadBufferFromFile backup_buf(file_path);
     CompressedReadBuffer compressed_backup_buf(backup_buf);
-    NativeBlockInputStream backup_stream(compressed_backup_buf);
+    NativeBlockInputStream backup_stream(compressed_backup_buf, 0);
 
     backup_stream.readPrefix();
     while (Block block = backup_stream.read())
diff --git a/dbms/src/Storages/StorageStripeLog.cpp b/dbms/src/Storages/StorageStripeLog.cpp
index 62e9c3cc9985..1d2d31e27bb8 100644
--- a/dbms/src/Storages/StorageStripeLog.cpp
+++ b/dbms/src/Storages/StorageStripeLog.cpp
@@ -21,6 +21,8 @@
 #include <DataStreams/NativeBlockOutputStream.h>
 #include <DataStreams/NullBlockInputStream.h>
 
+#include <DataTypes/DataTypeFactory.h>
+
 #include <Columns/ColumnArray.h>
 
 #include <Interpreters/Context.h>
@@ -57,28 +59,25 @@ class StripeLogBlockInputStream final : public IProfilingBlockInputStream
 
     String getName() const override { return "StripeLog"; }
 
-    String getID() const override
+    Block getHeader() const override
     {
-        std::stringstream s;
-        s << this;
-        return s.str();
-    }
+        if (index_begin == index_end)
+            return {};
+
+        Block header;
+        for (const auto & column : index_begin->columns)
+        {
+            auto type = DataTypeFactory::instance().get(column.type);
+            header.insert({ type->createColumn(), type, column.name });
+        }
+        return header;
+    };
 
 protected:
     Block readImpl() override
     {
         Block res;
-
-        if (!started)
-        {
-            started = true;
-
-            data_in.emplace(
-                storage.full_path() + "data.bin", 0, 0,
-                std::min(static_cast<Poco::File::FileSize>(max_read_buffer_size), Poco::File(storage.full_path() + "data.bin").getSize()));
-
-            block_in.emplace(*data_in, 0, true, index_begin, index_end);
-        }
+        start();
 
         if (block_in)
         {
@@ -111,6 +110,20 @@ class StripeLogBlockInputStream final : public IProfilingBlockInputStream
     bool started = false;
     std::optional<CompressedReadBufferFromFile> data_in;
     std::optional<NativeBlockInputStream> block_in;
+
+    void start()
+    {
+        if (!started)
+        {
+            started = true;
+
+            data_in.emplace(
+                storage.full_path() + "data.bin", 0, 0,
+                std::min(static_cast<Poco::File::FileSize>(max_read_buffer_size), Poco::File(storage.full_path() + "data.bin").getSize()));
+
+            block_in.emplace(*data_in, 0, index_begin, index_end);
+        }
+    }
 };
 
 
@@ -232,7 +245,7 @@ BlockInputStreams StorageStripeLog::read(
     NameSet column_names_set(column_names.begin(), column_names.end());
 
     if (!Poco::File(full_path() + "index.mrk").exists())
-        return { std::make_shared<NullBlockInputStream>() };
+        return { std::make_shared<NullBlockInputStream>(getSampleBlockForColumns(column_names)) };
 
     CompressedReadBufferFromFile index_in(full_path() + "index.mrk", 0, 0, INDEX_BUFFER_SIZE);
     std::shared_ptr<const IndexForNativeFormat> index{std::make_shared<IndexForNativeFormat>(index_in, column_names_set)};
diff --git a/dbms/src/Storages/StorageTinyLog.cpp b/dbms/src/Storages/StorageTinyLog.cpp
index 23d1e0c44759..957d1ca9affb 100644
--- a/dbms/src/Storages/StorageTinyLog.cpp
+++ b/dbms/src/Storages/StorageTinyLog.cpp
@@ -60,7 +60,15 @@ class TinyLogBlockInputStream final : public IProfilingBlockInputStream
 
     String getName() const override { return "TinyLog"; }
 
-    String getID() const override;
+    Block getHeader() const override
+    {
+        Block res;
+
+        for (const auto & name_type : columns)
+            res.insert({ name_type.type->createColumn(), name_type.type, name_type.name });
+
+        return Nested::flatten(res);
+    };
 
 protected:
     Block readImpl() override;
@@ -144,19 +152,6 @@ class TinyLogBlockOutputStream final : public IBlockOutputStream
 };
 
 
-String TinyLogBlockInputStream::getID() const
-{
-    std::stringstream res;
-    res << "TinyLog(" << storage.getTableName() << ", " << &storage;
-
-    for (const auto & name_type : columns)
-        res << ", " << name_type.name;
-
-    res << ")";
-    return res.str();
-}
-
-
 Block TinyLogBlockInputStream::readImpl()
 {
     Block res;
diff --git a/dbms/src/Storages/System/StorageSystemNumbers.cpp b/dbms/src/Storages/System/StorageSystemNumbers.cpp
index 4a9e85049e76..30586bbbba35 100644
--- a/dbms/src/Storages/System/StorageSystemNumbers.cpp
+++ b/dbms/src/Storages/System/StorageSystemNumbers.cpp
@@ -15,11 +15,15 @@ class NumbersBlockInputStream : public IProfilingBlockInputStream
     NumbersBlockInputStream(size_t block_size_, size_t offset_, size_t step_)
         : block_size(block_size_), next(offset_), step(step_) {}
 
-    String getName() const { return "Numbers"; }
-    String getID() const { return "Numbers"; }
+    String getName() const override { return "Numbers"; }
+
+    Block getHeader() const override
+    {
+        return { ColumnWithTypeAndName(ColumnUInt64::create(), std::make_shared<DataTypeUInt64>(), "number") };
+    }
 
 protected:
-    Block readImpl()
+    Block readImpl() override
     {
         auto column = ColumnUInt64::create(block_size);
         ColumnUInt64::Container & vec = column->getData();
diff --git a/dbms/src/TableFunctions/getStructureOfRemoteTable.cpp b/dbms/src/TableFunctions/getStructureOfRemoteTable.cpp
index 8f0435608046..3cb68d254162 100644
--- a/dbms/src/TableFunctions/getStructureOfRemoteTable.cpp
+++ b/dbms/src/TableFunctions/getStructureOfRemoteTable.cpp
@@ -1,5 +1,6 @@
 #include <Interpreters/Cluster.h>
 #include <Interpreters/Context.h>
+#include <Interpreters/InterpreterDescribeQuery.h>
 #include <DataStreams/RemoteBlockInputStream.h>
 #include <DataTypes/DataTypeFactory.h>
 #include <Storages/IStorage.h>
@@ -33,7 +34,7 @@ NamesAndTypesList getStructureOfRemoteTable(
     if (shard_info.isLocal())
         return context.getTable(database, table)->getColumnsList();
 
-    auto input = std::make_shared<RemoteBlockInputStream>(shard_info.pool, query, context);
+    auto input = std::make_shared<RemoteBlockInputStream>(shard_info.pool, query, InterpreterDescribeQuery::getSampleBlock(), context);
     input->setPoolMode(PoolMode::GET_ONE);
     input->setMainTable(QualifiedTableName{database, table});
     input->readPrefix();
diff --git a/libs/libcommon/include/common/iostream_debug_helpers.h b/libs/libcommon/include/common/iostream_debug_helpers.h
index a33cfefe1010..09ab4de83e66 100644
--- a/libs/libcommon/include/common/iostream_debug_helpers.h
+++ b/libs/libcommon/include/common/iostream_debug_helpers.h
@@ -15,7 +15,7 @@
 #include <vector>
 
 // TODO: https://stackoverflow.com/questions/16464032/how-to-enhance-this-variable-dumping-debug-macro-to-be-variadic
-#define DUMPS(VAR) #VAR " = " << VAR
+#define DUMPS(VAR) #VAR " = " << (VAR)
 #define DUMPHEAD std::cerr << __FILE__ << ":" << __LINE__ << " "
 #define DUMP(V1) DUMPHEAD << DUMPS(V1) << "
";
 #define DUMP2(V1, V2) DUMPHEAD << DUMPS(V1) << ", " << DUMPS(V2) << "
";
