{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 73836,
  "instance_id": "ClickHouse__ClickHouse-73836",
  "issue_numbers": [
    "73835",
    "72960"
  ],
  "base_commit": "a40565d476fa35fd5e9613a47659fc1aada95bb3",
  "patch": "diff --git a/base/base/DecomposedFloat.h b/base/base/DecomposedFloat.h\nindex fef91adefb0a..b7b57278a5a1 100644\n--- a/base/base/DecomposedFloat.h\n+++ b/base/base/DecomposedFloat.h\n@@ -10,6 +10,17 @@\n \n template <typename T> struct FloatTraits;\n \n+struct Float16Tag;\n+\n+template <>\n+struct FloatTraits<Float16Tag>\n+{\n+    using UInt = uint16_t;\n+    static constexpr size_t bits = 16;\n+    static constexpr size_t exponent_bits = 5;\n+    static constexpr size_t mantissa_bits = bits - exponent_bits - 1;\n+};\n+\n template <>\n struct FloatTraits<BFloat16>\n {\n@@ -50,6 +61,10 @@ struct DecomposedFloat\n         memcpy(&x_uint, &x, sizeof(x));\n     }\n \n+    explicit DecomposedFloat(typename Traits::UInt x) : x_uint(x)\n+    {\n+    }\n+\n     typename Traits::UInt x_uint;\n \n     bool isNegative() const\n@@ -67,7 +82,7 @@ struct DecomposedFloat\n \n     uint16_t exponent() const\n     {\n-        return (x_uint >> (Traits::mantissa_bits)) & (((1ull << (Traits::exponent_bits + 1)) - 1) >> 1);\n+        return (x_uint >> (Traits::mantissa_bits)) & ((1ull << Traits::exponent_bits) - 1);\n     }\n \n     int16_t normalizedExponent() const\n@@ -230,4 +245,3 @@ struct DecomposedFloat\n \n using DecomposedFloat64 = DecomposedFloat<double>;\n using DecomposedFloat32 = DecomposedFloat<float>;\n-using DecomposedFloat16 = DecomposedFloat<BFloat16>;\ndiff --git a/docs/en/interfaces/formats.md b/docs/en/interfaces/formats.md\nindex b8d16debbacc..116cf482b0f8 100644\n--- a/docs/en/interfaces/formats.md\n+++ b/docs/en/interfaces/formats.md\n@@ -2449,6 +2449,8 @@ Unsupported Arrow data types: `FIXED_SIZE_BINARY`, `JSON`, `UUID`, `ENUM`.\n \n The data types of ClickHouse table columns do not have to match the corresponding Arrow data fields. When inserting data, ClickHouse interprets data types according to the table above and then [casts](/docs/en/sql-reference/functions/type-conversion-functions.md/#type_conversion_function-cast) the data to the data type set for the ClickHouse table column.\n \n+Keep in mind that the HALF_FLOAT data type is converted to Float32 while reading. This is needed, because it represents the IEEE-754 16-bit floating point value, not the BFloat16 format (more popular in AI and ML applications) which ClickHouse supports. \n+\n ### Inserting Data {#inserting-data-arrow}\n \n You can insert Arrow data from a file into ClickHouse table by the following command:\ndiff --git a/src/Common/FloatUtils.h b/src/Common/FloatUtils.h\nnew file mode 100644\nindex 000000000000..03ec55079c0f\n--- /dev/null\n+++ b/src/Common/FloatUtils.h\n@@ -0,0 +1,48 @@\n+#pragma once\n+\n+#include <cstdint>\n+#include <bit>\n+\n+\n+inline float convertFloat16ToFloat32(uint16_t float16_value)\n+{\n+    uint32_t old_sign = (float16_value & 0b10000000'00000000);\n+    uint32_t old_exponent = (float16_value & 0b01111100'00000000) >> 10;\n+    uint32_t old_mantissa = float16_value & 0b00000011'11111111;\n+\n+    uint32_t new_exponent;\n+    uint32_t new_mantissa;\n+    uint32_t new_sign = old_sign << 16;\n+\n+    if (unlikely(old_exponent == 0x1F))\n+    {\n+        /// Inf, NaN\n+        new_exponent = 0xFFu << 23;\n+        new_mantissa = old_mantissa << 13;\n+    }\n+    else if (old_exponent == 0)\n+    {\n+        if (likely(old_mantissa == 0))\n+        {\n+            /// Zeros\n+            new_exponent = 0;\n+            new_mantissa = 0;\n+        }\n+        else\n+        {\n+            /// Subnormals\n+            uint32_t adjustment = __builtin_clz(old_mantissa) - 22;\n+            new_exponent = (112 - adjustment) << 23;\n+            new_mantissa = (old_mantissa ^ (1 << (9 - adjustment))) << 13 << adjustment;\n+        }\n+    }\n+    else\n+    {\n+        /// Normals\n+        new_exponent = (old_exponent + 112) << 23;\n+        new_mantissa = old_mantissa << 13;\n+    }\n+\n+    uint32_t float32_value = new_sign | new_exponent | new_mantissa;\n+    return std::bit_cast<float>(float32_value);\n+}\ndiff --git a/src/Processors/Formats/Impl/ArrowColumnToCHColumn.cpp b/src/Processors/Formats/Impl/ArrowColumnToCHColumn.cpp\nindex 034a778c9b24..6a955e4ff59e 100644\n--- a/src/Processors/Formats/Impl/ArrowColumnToCHColumn.cpp\n+++ b/src/Processors/Formats/Impl/ArrowColumnToCHColumn.cpp\n@@ -30,7 +30,7 @@\n #include <Columns/ColumnLowCardinality.h>\n #include <Columns/ColumnUnique.h>\n #include <Columns/ColumnMap.h>\n-#include <Columns/ColumnsNumber.h>\n+#include <Common/FloatUtils.h>\n #include <Columns/ColumnNothing.h>\n #include <Interpreters/castColumn.h>\n #include <Common/quoteString.h>\n@@ -38,9 +38,9 @@\n #include <algorithm>\n #include <arrow/builder.h>\n #include <arrow/array.h>\n-#include <boost/algorithm/string.hpp>\n #include <boost/algorithm/string/case_conv.hpp>\n \n+\n /// UINT16 and UINT32 are processed separately, see comments in readColumnFromArrowColumn.\n #define FOR_ARROW_NUMERIC_TYPES(M) \\\n         M(arrow::Type::UINT8, UInt8) \\\n@@ -49,7 +49,6 @@\n         M(arrow::Type::UINT64, UInt64) \\\n         M(arrow::Type::INT64, Int64) \\\n         M(arrow::Type::DURATION, Int64) \\\n-        M(arrow::Type::HALF_FLOAT, Float32) \\\n         M(arrow::Type::FLOAT, Float32) \\\n         M(arrow::Type::DOUBLE, Float64)\n \n@@ -418,6 +417,21 @@ static ColumnWithTypeAndName readColumnWithDecimalDataImpl(const std::shared_ptr\n     return {std::move(internal_column), internal_type, column_name};\n }\n \n+static ColumnWithTypeAndName readColumnWithFloat16Data(const std::shared_ptr<arrow::ChunkedArray> & arrow_column, const String & column_name)\n+{\n+    auto column = ColumnFloat32::create();\n+    auto & column_data = column->getData();\n+    column_data.reserve(arrow_column->length());\n+\n+    for (int chunk_i = 0, num_chunks = arrow_column->num_chunks(); chunk_i < num_chunks; ++chunk_i)\n+    {\n+        auto & chunk = dynamic_cast<arrow::HalfFloatArray &>(*(arrow_column->chunk(chunk_i)));\n+        for (size_t value_i = 0, length = static_cast<size_t>(chunk.length()); value_i < length; ++value_i)\n+            column_data.emplace_back(chunk.IsNull(value_i) ? 0 : convertFloat16ToFloat32(chunk.Value(value_i)));\n+    }\n+    return {std::move(column), std::make_shared<DataTypeFloat32>(), column_name};\n+}\n+\n template <typename DecimalArray>\n static ColumnWithTypeAndName readColumnWithDecimalData(const std::shared_ptr<arrow::ChunkedArray> & arrow_column, const String & column_name)\n {\n@@ -1062,6 +1076,10 @@ static ColumnWithTypeAndName readNonNullableColumnFromArrowColumn(\n             return readColumnWithNumericData<CPP_NUMERIC_TYPE>(arrow_column, column_name);\n         FOR_ARROW_NUMERIC_TYPES(DISPATCH)\n #    undef DISPATCH\n+        case arrow::Type::HALF_FLOAT:\n+        {\n+            return readColumnWithFloat16Data(arrow_column, column_name);\n+        }\n         case arrow::Type::TIME32:\n         {\n             return readColumnWithTime32Data(arrow_column, column_name);\ndiff --git a/src/Processors/Formats/Impl/NpyRowInputFormat.cpp b/src/Processors/Formats/Impl/NpyRowInputFormat.cpp\nindex acff1b4f38f9..6a6afc645139 100644\n--- a/src/Processors/Formats/Impl/NpyRowInputFormat.cpp\n+++ b/src/Processors/Formats/Impl/NpyRowInputFormat.cpp\n@@ -8,7 +8,7 @@\n #include <Columns/ColumnFixedString.h>\n #include <Columns/ColumnString.h>\n #include <Columns/ColumnArray.h>\n-#include <Columns/ColumnsNumber.h>\n+#include <Common/FloatUtils.h>\n #include <DataTypes/IDataType.h>\n #include <IO/ReadBuffer.h>\n #include <boost/algorithm/string/split.hpp>\n@@ -30,46 +30,6 @@ namespace ErrorCodes\n namespace\n {\n \n-float convertFloat16ToFloat32(uint16_t float16_value)\n-{\n-    uint16_t sign = (float16_value >> 15) & 0x1;\n-    uint16_t exponent = (float16_value >> 10) & 0x1F;\n-    uint16_t fraction = float16_value & 0x3FF;\n-\n-    if (exponent == 0 && fraction == 0)\n-    {\n-        uint32_t float32_value = sign << 31;\n-        return std::bit_cast<float>(float32_value);\n-    }\n-\n-    // Handling special cases for exponent\n-    if (exponent == 0x1F)\n-    {\n-        // NaN or Infinity in float16\n-        return (fraction == 0) ? std::numeric_limits<float>::infinity() : std::numeric_limits<float>::quiet_NaN();\n-    }\n-\n-    // Convert exponent from float16 to float32 format\n-    int32_t new_exponent = static_cast<int32_t>(exponent) - 15 + 127;\n-\n-    // Constructing the float32 representation\n-    uint32_t float32_value = (static_cast<uint32_t>(sign) << 31) |\n-                             (static_cast<uint32_t>(new_exponent) << 23) |\n-                             (static_cast<uint32_t>(fraction) << 13);\n-\n-    // Interpret the binary representation as a float\n-    float result;\n-    std::memcpy(&result, &float32_value, sizeof(float));\n-\n-    // Determine decimal places dynamically based on the magnitude of the number\n-    int decimal_places = std::max(0, 6 - static_cast<int>(std::log10(std::abs(result))));\n-    // Truncate the decimal part to the determined number of decimal places\n-    float multiplier = static_cast<float>(std::pow(10.0f, decimal_places));\n-    result = std::round(result * multiplier) / multiplier;\n-\n-    return result;\n-}\n-\n DataTypePtr getDataTypeFromNumpyType(const std::shared_ptr<NumpyDataType> & numpy_type)\n {\n     switch (numpy_type->getTypeIndex())\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01273_arrow_load.reference b/tests/queries/0_stateless/01273_arrow_load.reference\nindex 53f2287f627b..4f43957890f7 100644\n--- a/tests/queries/0_stateless/01273_arrow_load.reference\n+++ b/tests/queries/0_stateless/01273_arrow_load.reference\n@@ -1,4 +1,4 @@\n-0\t127\t32767\t2147483647\t9223372036854775807\t0\t0\t0\t0\t2.6480716e36\t1e-45\t5e-324\tHello\t2010-10-10\t2020-05-05 03:36:28\t2020-05-05 03:36:28\n-1\t-128\t-32768\t-2147483648\t-9223372036854775808\t255\t65535\t4294967295\t18446744073709551615\t0\t3.4028235e38\t1.7976931348623157e308\tWorld\t2011-11-11\t2020-04-04 03:00:00\t2020-04-04 03:00:00\n-0\t127\t32767\t2147483647\t9223372036854775807\t0\t0\t0\t0\t2.6480716e36\t1e-45\t5e-324\tHello\t2010-10-10\t2020-05-05 03:36:28\t2020-05-05 03:36:28\n-1\t-128\t-32768\t-2147483648\t-9223372036854775808\t255\t65535\t4294967295\t18446744073709551615\t0\t3.4028235e38\t1.7976931348623157e308\tWorld\t2011-11-11\t2020-04-04 03:00:00\t2020-04-04 03:00:00\n+0\t127\t32767\t2147483647\t9223372036854775807\t0\t0\t0\t0\t5.9604645e-8\t1e-45\t5e-324\tHello\t2010-10-10\t2020-05-05 03:36:28\t2020-05-05 03:36:28\n+1\t-128\t-32768\t-2147483648\t-9223372036854775808\t255\t65535\t4294967295\t18446744073709551615\t65504\t3.4028235e38\t1.7976931348623157e308\tWorld\t2011-11-11\t2020-04-04 03:00:00\t2020-04-04 03:00:00\n+0\t127\t32767\t2147483647\t9223372036854775807\t0\t0\t0\t0\t5.9604645e-8\t1e-45\t5e-324\tHello\t2010-10-10\t2020-05-05 03:36:28\t2020-05-05 03:36:28\n+1\t-128\t-32768\t-2147483648\t-9223372036854775808\t255\t65535\t4294967295\t18446744073709551615\t65504\t3.4028235e38\t1.7976931348623157e308\tWorld\t2011-11-11\t2020-04-04 03:00:00\t2020-04-04 03:00:00\ndiff --git a/tests/queries/0_stateless/02895_npy_format.reference b/tests/queries/0_stateless/02895_npy_format.reference\nindex 52972f0acbdc..eb8a29d22884 100644\n--- a/tests/queries/0_stateless/02895_npy_format.reference\n+++ b/tests/queries/0_stateless/02895_npy_format.reference\n@@ -92,8 +92,8 @@ c\n 1\n 1\n 1\n-[2.199219,1.099609,3.300781]\n-[4.25,3.34961,6.628906]\n+[2.1992188,1.0996094,3.3007812]\n+[4.25,3.3496094,6.6289062]\n inf\n nan\n 0\ndiff --git a/tests/queries/0_stateless/03295_half_parquet.reference b/tests/queries/0_stateless/03295_half_parquet.reference\nnew file mode 100644\nindex 000000000000..d4d0d50f2f05\n--- /dev/null\n+++ b/tests/queries/0_stateless/03295_half_parquet.reference\n@@ -0,0 +1,5 @@\n+1.5\n+2.5\n+3.140625\n+-1\n+0\ndiff --git a/tests/queries/0_stateless/03295_half_parquet.sh b/tests/queries/0_stateless/03295_half_parquet.sh\nnew file mode 100755\nindex 000000000000..2fe3c3d20b35\n--- /dev/null\n+++ b/tests/queries/0_stateless/03295_half_parquet.sh\n@@ -0,0 +1,8 @@\n+#!/usr/bin/env bash\n+# Tags: no-fasttest\n+\n+CUR_DIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CUR_DIR\"/../shell_config.sh\n+\n+$CLICKHOUSE_LOCAL \"SELECT * FROM '${CUR_DIR}/data_parquet/example_half_float.parquet'\"\ndiff --git a/tests/queries/0_stateless/data_parquet/example_half_float.parquet b/tests/queries/0_stateless/data_parquet/example_half_float.parquet\nnew file mode 100644\nindex 000000000000..c8f9050c86e3\nBinary files /dev/null and b/tests/queries/0_stateless/data_parquet/example_half_float.parquet differ\n",
  "problem_statement": "HALF_FLOAT is not supported in Arrow/Parquet/ORC\n### Changelog category (leave one):\r\n- Bug Fix (user-visible misbehavior in an official stable release)\r\n\r\n\r\n### Changelog entry (a user-readable short description of the changes that goes to CHANGELOG.md):\r\nApache Arrow's HALF_FLOAT (don't be confused with BFloat16) is not supported. In previous versions, reading this data produced invalid results. This closes #72960\r\n\r\n\r\n> Information about CI checks: https://clickhouse.com/docs/en/development/continuous-integration/\r\n\r\n#### CI Settings (Only check the boxes if you know what you are doing)\r\n\r\nAll builds in Builds_1 and Builds_2 stages are always mandatory\r\nand will run independently of the checks below:\r\n\r\n- [ ] <!---ci_set_required--> Allow: All Required Checks\r\n- [ ] <!---ci_include_stateless--> Allow: Stateless tests\r\n- [ ] <!---ci_include_stateful--> Allow: Stateful tests\r\n- [ ] <!---ci_include_integration--> Allow: Integration Tests\r\n- [ ] <!---ci_include_performance--> Allow: Performance tests\r\n- [ ] <!---ci_set_builds--> Allow: All Builds\r\n- [ ] <!---batch_0_1--> Allow: batch 1, 2 for multi-batch jobs\r\n- [ ] <!---batch_2_3--> Allow: batch 3, 4, 5, 6 for multi-batch jobs\r\n---\r\n- [ ] <!---ci_exclude_style--> Exclude: Style check\r\n- [ ] <!---ci_exclude_fast--> Exclude: Fast test\r\n- [ ] <!---ci_exclude_asan--> Exclude: All with ASAN\r\n- [ ] <!---ci_exclude_tsan|msan|ubsan|coverage--> Exclude: All with TSAN, MSAN, UBSAN, Coverage\r\n- [ ] <!---ci_exclude_aarch64|release|debug--> Exclude: All with aarch64\r\n- [ ] <!---ci_exclude_release--> Exclude: All with release\r\n- [ ] <!---ci_exclude_debug--> Exclude: All with debug\r\n---\r\n- [ ] <!---ci_include_fuzzer--> Run only fuzzers related jobs (libFuzzer fuzzers, AST fuzzers, etc.)\r\n- [ ] <!---ci_exclude_ast--> Exclude: AST fuzzers\r\n---\r\n- [ ] <!---do_not_test--> Do not test\r\n- [ ] <!---woolen_wolfdog--> Woolen Wolfdog\r\n- [ ] <!---upload_all--> Upload binaries for special builds\r\n- [ ] <!---no_merge_commit--> Disable merge-commit\r\n- [ ] <!---no_ci_cache--> Disable CI cache\r\n\nValues from the Parquet file with logical datatype `Float16` are read incorrectly\n**ClickHouse version:** `24.11.1.708`\r\n\r\nI have a Parquet file with logical type `Float16`, when I read from it using ClickHouse I see the values that are incorrect. \r\n\r\n```sql\r\nSELECT *\r\nFROM file('float16.parquet')\r\n\r\nQuery id: 42eed709-8323-44c7-8ac9-8ee55d04190b\r\n\r\n    \u250c\u2500\u2500\u2500floatfield\u2500\u2510\r\n 1. \u2502 -0.007858276 \u2502\r\n 2. \u2502    0.0078125 \u2502\r\n 3. \u2502      32.0625 \u2502\r\n 4. \u2502      2052.25 \u2502\r\n 5. \u2502        32838 \u2502\r\n 6. \u2502       262720 \u2502\r\n 7. \u2502            0 \u2502\r\n 8. \u2502            0 \u2502\r\n 9. \u2502            0 \u2502\r\n10. \u2502            0 \u2502\r\n11. \u2502            0 \u2502\r\n12. \u2502            0 \u2502\r\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\nBut when I try to read values with other tools like `parquet-tools` for example I see these values that I've passed when generating the file with `parquet-java`:\r\n\r\n```\r\n parquet-tools show float16.parquet   \r\n+--------------+\r\n|   floatfield |\r\n|--------------|\r\n|           -2 |\r\n|           -1 |\r\n|            0 |\r\n|            1 |\r\n|            2 |\r\n|            3 |\r\n|            4 |\r\n|            5 |\r\n|            6 |\r\n|            7 |\r\n|            8 |\r\n|            9 |\r\n+--------------+\r\n```\r\n\r\nOne observation that I have is that the column in ClickHouse is being converted as `Float32`\r\n\r\n```sql\r\nDESCRIBE TABLE file('float16.parquet')\r\n\r\nQuery id: aeaafdd1-f256-41ef-aeac-b1f58d026b39\r\n\r\n   \u250c\u2500name\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500type\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500default_type\u2500\u252c\u2500default_expression\u2500\u252c\u2500comment\u2500\u252c\u2500codec_expression\u2500\u252c\u2500ttl_expression\u2500\u2510\r\n1. \u2502 floatfield \u2502 Nullable(Float32) \u2502              \u2502                    \u2502         \u2502                  \u2502                \u2502\r\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n1 row in set. Elapsed: 0.002 sec. \r\n```\r\n\r\nIn the documentation I see the datatype `BFloat16` exists so I assumed it would be possible to explicitly specify the structure when reading from the parquet as:\r\n\r\n```sql\r\nSELECT *\r\nFROM file('float16.parquet', Parquet, 'floatfield BFloat16')\r\n\r\nQuery id: a90810ee-60e3-4177-921a-cc864db4686e\r\n\r\n\r\nElapsed: 0.000 sec. \r\n\r\nReceived exception:\r\nCode: 50. DB::Exception: Unknown data type family: BFloat16. Maybe you meant: ['Float64','Float32']. (UNKNOWN_TYPE)\r\n```\r\n\r\nIs the error message here expected? Shouldn't the column with `Float16` automatically be converted to `BFloat16` in ClickHouse? And why does the error say `Unknown data type family?`\n",
  "hints_text": "\n",
  "created_at": "2024-12-25T15:45:44Z",
  "modified_files": [
    "base/base/DecomposedFloat.h",
    "docs/en/interfaces/formats.md",
    "b/src/Common/FloatUtils.h",
    "src/Processors/Formats/Impl/ArrowColumnToCHColumn.cpp",
    "src/Processors/Formats/Impl/NpyRowInputFormat.cpp"
  ],
  "modified_test_files": [
    "tests/queries/0_stateless/01273_arrow_load.reference",
    "tests/queries/0_stateless/02895_npy_format.reference",
    "b/tests/queries/0_stateless/03295_half_parquet.reference",
    "b/tests/queries/0_stateless/03295_half_parquet.sh"
  ]
}