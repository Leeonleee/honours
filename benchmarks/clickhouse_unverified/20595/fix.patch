diff --git a/contrib/CMakeLists.txt b/contrib/CMakeLists.txt
index 20b4fad0437a..bf4bf5eb472b 100644
--- a/contrib/CMakeLists.txt
+++ b/contrib/CMakeLists.txt
@@ -32,6 +32,7 @@ endif()
 
 set_property(DIRECTORY PROPERTY EXCLUDE_FROM_ALL 1)
 
+add_subdirectory (abseil-cpp-cmake)
 add_subdirectory (antlr4-runtime-cmake)
 add_subdirectory (boost-cmake)
 add_subdirectory (cctz-cmake)
diff --git a/contrib/abseil-cpp-cmake/CMakeLists.txt b/contrib/abseil-cpp-cmake/CMakeLists.txt
new file mode 100644
index 000000000000..c8cb512066a5
--- /dev/null
+++ b/contrib/abseil-cpp-cmake/CMakeLists.txt
@@ -0,0 +1,18 @@
+set(ABSL_ROOT_DIR "${ClickHouse_SOURCE_DIR}/contrib/abseil-cpp")
+if(NOT EXISTS "${ABSL_ROOT_DIR}/CMakeLists.txt")
+  message(FATAL_ERROR " submodule third_party/abseil-cpp is missing. To fix try run: 
 git submodule update --init --recursive")
+endif()
+add_subdirectory("${ABSL_ROOT_DIR}" "${ClickHouse_BINARY_DIR}/contrib/abseil-cpp")
+
+add_library(abseil_swiss_tables INTERFACE)
+
+target_link_libraries(abseil_swiss_tables INTERFACE
+  absl::flat_hash_map
+  absl::flat_hash_set
+)
+
+get_target_property(FLAT_HASH_MAP_INCLUDE_DIR absl::flat_hash_map INTERFACE_INCLUDE_DIRECTORIES)
+target_include_directories (abseil_swiss_tables SYSTEM BEFORE INTERFACE ${FLAT_HASH_MAP_INCLUDE_DIR})
+
+get_target_property(FLAT_HASH_SET_INCLUDE_DIR absl::flat_hash_set INTERFACE_INCLUDE_DIRECTORIES)
+target_include_directories (abseil_swiss_tables SYSTEM BEFORE INTERFACE ${FLAT_HASH_SET_INCLUDE_DIR})
diff --git a/contrib/grpc-cmake/CMakeLists.txt b/contrib/grpc-cmake/CMakeLists.txt
index 97ca3fab4db7..b93968f62f96 100644
--- a/contrib/grpc-cmake/CMakeLists.txt
+++ b/contrib/grpc-cmake/CMakeLists.txt
@@ -39,11 +39,6 @@ set(_gRPC_SSL_LIBRARIES ${OPENSSL_LIBRARIES})
 
 # Use abseil-cpp from ClickHouse contrib, not from gRPC third_party.
 set(gRPC_ABSL_PROVIDER "clickhouse" CACHE STRING "" FORCE)
-set(ABSL_ROOT_DIR "${ClickHouse_SOURCE_DIR}/contrib/abseil-cpp")
-if(NOT EXISTS "${ABSL_ROOT_DIR}/CMakeLists.txt")
-  message(FATAL_ERROR " grpc: submodule third_party/abseil-cpp is missing. To fix try run: 
 git submodule update --init --recursive")
-endif()
-add_subdirectory("${ABSL_ROOT_DIR}" "${ClickHouse_BINARY_DIR}/contrib/abseil-cpp")
 
 # Choose to build static or shared library for c-ares.
 if (MAKE_STATIC_LIBRARIES)
diff --git a/src/Columns/ColumnAggregateFunction.cpp b/src/Columns/ColumnAggregateFunction.cpp
index d0a5e120a073..df7b3cce7290 100644
--- a/src/Columns/ColumnAggregateFunction.cpp
+++ b/src/Columns/ColumnAggregateFunction.cpp
@@ -24,6 +24,7 @@ namespace ErrorCodes
     extern const int PARAMETER_OUT_OF_BOUND;
     extern const int SIZES_OF_COLUMNS_DOESNT_MATCH;
     extern const int ILLEGAL_TYPE_OF_ARGUMENT;
+    extern const int NOT_IMPLEMENTED;
 }
 
 
@@ -553,6 +554,11 @@ const char * ColumnAggregateFunction::deserializeAndInsertFromArena(const char *
     return read_buffer.position();
 }
 
+const char * ColumnAggregateFunction::skipSerializedInArena(const char *) const
+{
+    throw Exception("Method skipSerializedInArena is not supported for " + getName(), ErrorCodes::NOT_IMPLEMENTED);
+}
+
 void ColumnAggregateFunction::popBack(size_t n)
 {
     size_t size = data.size();
diff --git a/src/Columns/ColumnAggregateFunction.h b/src/Columns/ColumnAggregateFunction.h
index f023177d7f23..5cb9aaa4ad52 100644
--- a/src/Columns/ColumnAggregateFunction.h
+++ b/src/Columns/ColumnAggregateFunction.h
@@ -155,6 +155,8 @@ class ColumnAggregateFunction final : public COWHelper<IColumn, ColumnAggregateF
 
     const char * deserializeAndInsertFromArena(const char * src_arena) override;
 
+    const char * skipSerializedInArena(const char *) const override;
+
     void updateHashWithValue(size_t n, SipHash & hash) const override;
 
     void updateWeakHash32(WeakHash32 & hash) const override;
diff --git a/src/Columns/ColumnArray.cpp b/src/Columns/ColumnArray.cpp
index d8821a646ae2..5267bc5db5d0 100644
--- a/src/Columns/ColumnArray.cpp
+++ b/src/Columns/ColumnArray.cpp
@@ -239,6 +239,16 @@ const char * ColumnArray::deserializeAndInsertFromArena(const char * pos)
     return pos;
 }
 
+const char * ColumnArray::skipSerializedInArena(const char * pos) const
+{
+    size_t array_size = unalignedLoad<size_t>(pos);
+    pos += sizeof(array_size);
+
+    for (size_t i = 0; i < array_size; ++i)
+        pos = getData().skipSerializedInArena(pos);
+
+    return pos;
+}
 
 void ColumnArray::updateHashWithValue(size_t n, SipHash & hash) const
 {
diff --git a/src/Columns/ColumnArray.h b/src/Columns/ColumnArray.h
index 7d01d04735b5..75bd4a6dba40 100644
--- a/src/Columns/ColumnArray.h
+++ b/src/Columns/ColumnArray.h
@@ -61,6 +61,7 @@ class ColumnArray final : public COWHelper<IColumn, ColumnArray>
     void insertData(const char * pos, size_t length) override;
     StringRef serializeValueIntoArena(size_t n, Arena & arena, char const *& begin) const override;
     const char * deserializeAndInsertFromArena(const char * pos) override;
+    const char * skipSerializedInArena(const char * pos) const override;
     void updateHashWithValue(size_t n, SipHash & hash) const override;
     void updateWeakHash32(WeakHash32 & hash) const override;
     void updateHashFast(SipHash & hash) const override;
diff --git a/src/Columns/ColumnCompressed.h b/src/Columns/ColumnCompressed.h
index a31147b0702b..3cc2c0147326 100644
--- a/src/Columns/ColumnCompressed.h
+++ b/src/Columns/ColumnCompressed.h
@@ -85,6 +85,7 @@ class ColumnCompressed : public COWHelper<IColumn, ColumnCompressed>
     void popBack(size_t) override { throwMustBeDecompressed(); }
     StringRef serializeValueIntoArena(size_t, Arena &, char const *&) const override { throwMustBeDecompressed(); }
     const char * deserializeAndInsertFromArena(const char *) override { throwMustBeDecompressed(); }
+    const char * skipSerializedInArena(const char *) const override { throwMustBeDecompressed(); }
     void updateHashWithValue(size_t, SipHash &) const override { throwMustBeDecompressed(); }
     void updateWeakHash32(WeakHash32 &) const override { throwMustBeDecompressed(); }
     void updateHashFast(SipHash &) const override { throwMustBeDecompressed(); }
diff --git a/src/Columns/ColumnConst.h b/src/Columns/ColumnConst.h
index 9441f339085e..a19e0615dd7c 100644
--- a/src/Columns/ColumnConst.h
+++ b/src/Columns/ColumnConst.h
@@ -163,6 +163,11 @@ class ColumnConst final : public COWHelper<IColumn, ColumnConst>
         return res;
     }
 
+    const char * skipSerializedInArena(const char * pos) const override
+    {
+        return data->skipSerializedInArena(pos);
+    }
+
     void updateHashWithValue(size_t, SipHash & hash) const override
     {
         data->updateHashWithValue(0, hash);
diff --git a/src/Columns/ColumnDecimal.cpp b/src/Columns/ColumnDecimal.cpp
index 4a47919adf18..ec08db274b39 100644
--- a/src/Columns/ColumnDecimal.cpp
+++ b/src/Columns/ColumnDecimal.cpp
@@ -79,6 +79,12 @@ const char * ColumnDecimal<T>::deserializeAndInsertFromArena(const char * pos)
     return pos + sizeof(T);
 }
 
+template <typename T>
+const char * ColumnDecimal<T>::skipSerializedInArena(const char * pos) const
+{
+    return pos + sizeof(T);
+}
+
 template <typename T>
 UInt64 ColumnDecimal<T>::get64([[maybe_unused]] size_t n) const
 {
diff --git a/src/Columns/ColumnDecimal.h b/src/Columns/ColumnDecimal.h
index 33eb29461224..3187b5c02537 100644
--- a/src/Columns/ColumnDecimal.h
+++ b/src/Columns/ColumnDecimal.h
@@ -129,6 +129,7 @@ class ColumnDecimal final : public COWHelper<ColumnVectorHelper, ColumnDecimal<T
 
     StringRef serializeValueIntoArena(size_t n, Arena & arena, char const *& begin) const override;
     const char * deserializeAndInsertFromArena(const char * pos) override;
+    const char * skipSerializedInArena(const char * pos) const override;
     void updateHashWithValue(size_t n, SipHash & hash) const override;
     void updateWeakHash32(WeakHash32 & hash) const override;
     void updateHashFast(SipHash & hash) const override;
diff --git a/src/Columns/ColumnFixedString.cpp b/src/Columns/ColumnFixedString.cpp
index 84bd0561f012..4d54a46c924f 100644
--- a/src/Columns/ColumnFixedString.cpp
+++ b/src/Columns/ColumnFixedString.cpp
@@ -100,6 +100,11 @@ const char * ColumnFixedString::deserializeAndInsertFromArena(const char * pos)
     return pos + n;
 }
 
+const char * ColumnFixedString::skipSerializedInArena(const char * pos) const
+{
+    return pos + n;
+}
+
 void ColumnFixedString::updateHashWithValue(size_t index, SipHash & hash) const
 {
     hash.update(reinterpret_cast<const char *>(&chars[n * index]), n);
diff --git a/src/Columns/ColumnFixedString.h b/src/Columns/ColumnFixedString.h
index 58f6d8142fb2..5fd482aef6e0 100644
--- a/src/Columns/ColumnFixedString.h
+++ b/src/Columns/ColumnFixedString.h
@@ -112,6 +112,8 @@ class ColumnFixedString final : public COWHelper<ColumnVectorHelper, ColumnFixed
 
     const char * deserializeAndInsertFromArena(const char * pos) override;
 
+    const char * skipSerializedInArena(const char * pos) const override;
+
     void updateHashWithValue(size_t index, SipHash & hash) const override;
 
     void updateWeakHash32(WeakHash32 & hash) const override;
diff --git a/src/Columns/ColumnFunction.h b/src/Columns/ColumnFunction.h
index 6080a94d1fb5..fa605e741aa7 100644
--- a/src/Columns/ColumnFunction.h
+++ b/src/Columns/ColumnFunction.h
@@ -98,6 +98,11 @@ class ColumnFunction final : public COWHelper<IColumn, ColumnFunction>
         throw Exception("Cannot deserialize to " + getName(), ErrorCodes::NOT_IMPLEMENTED);
     }
 
+    const char * skipSerializedInArena(const char*) const override
+    {
+        throw Exception("Cannot skip serialized " + getName(), ErrorCodes::NOT_IMPLEMENTED);
+    }
+
     void updateHashWithValue(size_t, SipHash &) const override
     {
         throw Exception("updateHashWithValue is not implemented for " + getName(), ErrorCodes::NOT_IMPLEMENTED);
diff --git a/src/Columns/ColumnLowCardinality.cpp b/src/Columns/ColumnLowCardinality.cpp
index e420fd78a39a..9433bf079e25 100644
--- a/src/Columns/ColumnLowCardinality.cpp
+++ b/src/Columns/ColumnLowCardinality.cpp
@@ -247,6 +247,11 @@ const char * ColumnLowCardinality::deserializeAndInsertFromArena(const char * po
     return new_pos;
 }
 
+const char * ColumnLowCardinality::skipSerializedInArena(const char * pos) const
+{
+    return getDictionary().skipSerializedInArena(pos);
+}
+
 void ColumnLowCardinality::updateWeakHash32(WeakHash32 & hash) const
 {
     auto s = size();
diff --git a/src/Columns/ColumnLowCardinality.h b/src/Columns/ColumnLowCardinality.h
index 54ddb8ce68b1..92bf7ff0f95e 100644
--- a/src/Columns/ColumnLowCardinality.h
+++ b/src/Columns/ColumnLowCardinality.h
@@ -94,6 +94,8 @@ class ColumnLowCardinality final : public COWHelper<IColumn, ColumnLowCardinalit
 
     const char * deserializeAndInsertFromArena(const char * pos) override;
 
+    const char * skipSerializedInArena(const char * pos) const override;
+
     void updateHashWithValue(size_t n, SipHash & hash) const override
     {
         return getDictionary().updateHashWithValue(getIndexes().getUInt(n), hash);
diff --git a/src/Columns/ColumnMap.cpp b/src/Columns/ColumnMap.cpp
index 883a70db4352..05c0e0458d8e 100644
--- a/src/Columns/ColumnMap.cpp
+++ b/src/Columns/ColumnMap.cpp
@@ -116,6 +116,11 @@ const char * ColumnMap::deserializeAndInsertFromArena(const char * pos)
     return nested->deserializeAndInsertFromArena(pos);
 }
 
+const char * ColumnMap::skipSerializedInArena(const char * pos) const
+{
+    return nested->skipSerializedInArena(pos);
+}
+
 void ColumnMap::updateHashWithValue(size_t n, SipHash & hash) const
 {
     nested->updateHashWithValue(n, hash);
diff --git a/src/Columns/ColumnMap.h b/src/Columns/ColumnMap.h
index 3987d36b19d1..17f0ccc422c1 100644
--- a/src/Columns/ColumnMap.h
+++ b/src/Columns/ColumnMap.h
@@ -58,6 +58,7 @@ class ColumnMap final : public COWHelper<IColumn, ColumnMap>
     void popBack(size_t n) override;
     StringRef serializeValueIntoArena(size_t n, Arena & arena, char const *& begin) const override;
     const char * deserializeAndInsertFromArena(const char * pos) override;
+    const char * skipSerializedInArena(const char * pos) const override;
     void updateHashWithValue(size_t n, SipHash & hash) const override;
     void updateWeakHash32(WeakHash32 & hash) const override;
     void updateHashFast(SipHash & hash) const override;
diff --git a/src/Columns/ColumnNullable.cpp b/src/Columns/ColumnNullable.cpp
index df5b8789bfc9..1e5297514373 100644
--- a/src/Columns/ColumnNullable.cpp
+++ b/src/Columns/ColumnNullable.cpp
@@ -152,6 +152,17 @@ const char * ColumnNullable::deserializeAndInsertFromArena(const char * pos)
     return pos;
 }
 
+const char * ColumnNullable::skipSerializedInArena(const char * pos) const
+{
+    UInt8 val = unalignedLoad<UInt8>(pos);
+    pos += sizeof(val);
+
+    if (val == 0)
+        return getNestedColumn().skipSerializedInArena(pos);
+
+    return pos;
+}
+
 void ColumnNullable::insertRangeFrom(const IColumn & src, size_t start, size_t length)
 {
     const ColumnNullable & nullable_col = assert_cast<const ColumnNullable &>(src);
diff --git a/src/Columns/ColumnNullable.h b/src/Columns/ColumnNullable.h
index 0d68a6a0a3fd..963b3e1e8fad 100644
--- a/src/Columns/ColumnNullable.h
+++ b/src/Columns/ColumnNullable.h
@@ -71,6 +71,7 @@ class ColumnNullable final : public COWHelper<IColumn, ColumnNullable>
     void insertData(const char * pos, size_t length) override;
     StringRef serializeValueIntoArena(size_t n, Arena & arena, char const *& begin) const override;
     const char * deserializeAndInsertFromArena(const char * pos) override;
+    const char * skipSerializedInArena(const char * pos) const override;
     void insertRangeFrom(const IColumn & src, size_t start, size_t length) override;
     void insert(const Field & x) override;
     void insertFrom(const IColumn & src, size_t n) override;
diff --git a/src/Columns/ColumnString.cpp b/src/Columns/ColumnString.cpp
index 31f2b2f9275f..c1eddd539c99 100644
--- a/src/Columns/ColumnString.cpp
+++ b/src/Columns/ColumnString.cpp
@@ -237,6 +237,12 @@ const char * ColumnString::deserializeAndInsertFromArena(const char * pos)
     return pos + string_size;
 }
 
+const char * ColumnString::skipSerializedInArena(const char * pos) const
+{
+    const size_t string_size = unalignedLoad<size_t>(pos);
+    pos += sizeof(string_size);
+    return pos + string_size;
+}
 
 ColumnPtr ColumnString::index(const IColumn & indexes, size_t limit) const
 {
diff --git a/src/Columns/ColumnString.h b/src/Columns/ColumnString.h
index cf053d59b4d1..5f570afcdbb1 100644
--- a/src/Columns/ColumnString.h
+++ b/src/Columns/ColumnString.h
@@ -189,6 +189,8 @@ class ColumnString final : public COWHelper<IColumn, ColumnString>
 
     const char * deserializeAndInsertFromArena(const char * pos) override;
 
+    const char * skipSerializedInArena(const char * pos) const override;
+
     void updateHashWithValue(size_t n, SipHash & hash) const override
     {
         size_t string_size = sizeAt(n);
diff --git a/src/Columns/ColumnTuple.cpp b/src/Columns/ColumnTuple.cpp
index 7128b428b1a9..bb59d58b75d8 100644
--- a/src/Columns/ColumnTuple.cpp
+++ b/src/Columns/ColumnTuple.cpp
@@ -180,6 +180,14 @@ const char * ColumnTuple::deserializeAndInsertFromArena(const char * pos)
     return pos;
 }
 
+const char * ColumnTuple::skipSerializedInArena(const char * pos) const
+{
+    for (const auto & column : columns)
+        pos = column->skipSerializedInArena(pos);
+
+    return pos;
+}
+
 void ColumnTuple::updateHashWithValue(size_t n, SipHash & hash) const
 {
     for (const auto & column : columns)
diff --git a/src/Columns/ColumnTuple.h b/src/Columns/ColumnTuple.h
index 858eff7a75a6..3f5422c77195 100644
--- a/src/Columns/ColumnTuple.h
+++ b/src/Columns/ColumnTuple.h
@@ -61,6 +61,7 @@ class ColumnTuple final : public COWHelper<IColumn, ColumnTuple>
     void popBack(size_t n) override;
     StringRef serializeValueIntoArena(size_t n, Arena & arena, char const *& begin) const override;
     const char * deserializeAndInsertFromArena(const char * pos) override;
+    const char * skipSerializedInArena(const char * pos) const override;
     void updateHashWithValue(size_t n, SipHash & hash) const override;
     void updateWeakHash32(WeakHash32 & hash) const override;
     void updateHashFast(SipHash & hash) const override;
diff --git a/src/Columns/ColumnUnique.h b/src/Columns/ColumnUnique.h
index fbd3c3641b55..652487c2b090 100644
--- a/src/Columns/ColumnUnique.h
+++ b/src/Columns/ColumnUnique.h
@@ -26,6 +26,7 @@ namespace ErrorCodes
 {
     extern const int LOGICAL_ERROR;
     extern const int ILLEGAL_COLUMN;
+    extern const int NOT_IMPLEMENTED;
 }
 
 /** Stores another column with unique values
@@ -78,6 +79,7 @@ class ColumnUnique final : public COWHelper<IColumnUnique, ColumnUnique<ColumnTy
     bool getBool(size_t n) const override { return getNestedColumn()->getBool(n); }
     bool isNullAt(size_t n) const override { return is_nullable && n == getNullValueIndex(); }
     StringRef serializeValueIntoArena(size_t n, Arena & arena, char const *& begin) const override;
+    const char * skipSerializedInArena(const char * pos) const override;
     void updateHashWithValue(size_t n, SipHash & hash_func) const override
     {
         return getNestedColumn()->updateHashWithValue(n, hash_func);
@@ -373,6 +375,12 @@ size_t ColumnUnique<ColumnType>::uniqueDeserializeAndInsertFromArena(const char
     return uniqueInsertData(pos, string_size - 1);
 }
 
+template <typename ColumnType>
+const char * ColumnUnique<ColumnType>::skipSerializedInArena(const char *) const
+{
+    throw Exception("Method skipSerializedInArena is not supported for " + this->getName(), ErrorCodes::NOT_IMPLEMENTED);
+}
+
 template <typename ColumnType>
 int ColumnUnique<ColumnType>::compareAt(size_t n, size_t m, const IColumn & rhs, int nan_direction_hint) const
 {
diff --git a/src/Columns/ColumnVector.cpp b/src/Columns/ColumnVector.cpp
index 19ba86c51201..a64906ba2578 100644
--- a/src/Columns/ColumnVector.cpp
+++ b/src/Columns/ColumnVector.cpp
@@ -50,6 +50,12 @@ const char * ColumnVector<T>::deserializeAndInsertFromArena(const char * pos)
     return pos + sizeof(T);
 }
 
+template <typename T>
+const char * ColumnVector<T>::skipSerializedInArena(const char * pos) const
+{
+    return pos + sizeof(T);
+}
+
 template <typename T>
 void ColumnVector<T>::updateHashWithValue(size_t n, SipHash & hash) const
 {
diff --git a/src/Columns/ColumnVector.h b/src/Columns/ColumnVector.h
index 5af5ef20310a..3e6b90e739e6 100644
--- a/src/Columns/ColumnVector.h
+++ b/src/Columns/ColumnVector.h
@@ -154,6 +154,8 @@ class ColumnVector final : public COWHelper<ColumnVectorHelper, ColumnVector<T>>
 
     const char * deserializeAndInsertFromArena(const char * pos) override;
 
+    const char * skipSerializedInArena(const char * pos) const override;
+
     void updateHashWithValue(size_t n, SipHash & hash) const override;
 
     void updateWeakHash32(WeakHash32 & hash) const override;
diff --git a/src/Columns/IColumn.h b/src/Columns/IColumn.h
index 9ed064ede148..1dedd191e1d6 100644
--- a/src/Columns/IColumn.h
+++ b/src/Columns/IColumn.h
@@ -207,6 +207,10 @@ class IColumn : public COW<IColumn>
     /// Returns pointer to the position after the read data.
     virtual const char * deserializeAndInsertFromArena(const char * pos) = 0;
 
+    /// Skip previously serialized value that was serialized using IColumn::serializeValueIntoArena method.
+    /// Returns a pointer to the position after the deserialized data.
+    virtual const char * skipSerializedInArena(const char *) const = 0;
+
     /// Update state of hash function with value of n-th element.
     /// On subsequent calls of this method for sequence of column values of arbitrary types,
     ///  passed bytes to hash must identify sequence of values unambiguously.
diff --git a/src/Columns/IColumnDummy.h b/src/Columns/IColumnDummy.h
index bb08e86bb301..ff405184b7ae 100644
--- a/src/Columns/IColumnDummy.h
+++ b/src/Columns/IColumnDummy.h
@@ -67,6 +67,11 @@ class IColumnDummy : public IColumn
         return pos;
     }
 
+    const char * skipSerializedInArena(const char * pos) const override
+    {
+        return pos;
+    }
+
     void updateHashWithValue(size_t /*n*/, SipHash & /*hash*/) const override
     {
     }
diff --git a/src/Common/HashTable/Hash.h b/src/Common/HashTable/Hash.h
index ef20b70917d1..0abe96497bd9 100644
--- a/src/Common/HashTable/Hash.h
+++ b/src/Common/HashTable/Hash.h
@@ -1,8 +1,9 @@
 #pragma once
 
 #include <common/types.h>
-#include <Common/UInt128.h>
 #include <common/unaligned.h>
+#include <common/StringRef.h>
+#include <Common/UInt128.h>
 
 #include <type_traits>
 
@@ -178,13 +179,19 @@ inline size_t DefaultHash64(std::enable_if_t<(sizeof(T) <= sizeof(UInt64)), T> k
 }
 
 template <typename T>
-inline size_t DefaultHash64(std::enable_if_t<(sizeof(T) > sizeof(UInt64)), T> key)
+static constexpr bool UseDefaultHashForBigInts =
+    std::is_same_v<T, DB::Int128>  ||
+    std::is_same_v<T, DB::UInt128> ||
+    (is_big_int_v<T> && sizeof(T) == 32);
+
+template <typename T>
+inline size_t DefaultHash64(std::enable_if_t<(sizeof(T) > sizeof(UInt64) && UseDefaultHashForBigInts<T>), T> key)
 {
     if constexpr (std::is_same_v<T, DB::Int128>)
     {
         return intHash64(static_cast<UInt64>(key) ^ static_cast<UInt64>(key >> 64));
     }
-    if constexpr (std::is_same_v<T, DB::UInt128>)
+    else if constexpr (std::is_same_v<T, DB::UInt128>)
     {
         return intHash64(key.low ^ key.high);
     }
@@ -195,6 +202,8 @@ inline size_t DefaultHash64(std::enable_if_t<(sizeof(T) > sizeof(UInt64)), T> ke
             static_cast<UInt64>(key >> 128) ^
             static_cast<UInt64>(key >> 256));
     }
+
+    assert(false);
     __builtin_unreachable();
 }
 
@@ -341,6 +350,11 @@ struct IntHash32
         }
         else if constexpr (sizeof(T) <= sizeof(UInt64))
             return intHash32<salt>(key);
+
+        assert(false);
         __builtin_unreachable();
     }
 };
+
+template <>
+struct DefaultHash<StringRef> : public StringRefHash {};
diff --git a/src/Common/HashTable/LRUHashMap.h b/src/Common/HashTable/LRUHashMap.h
index 292006f24386..df9766c5ee83 100644
--- a/src/Common/HashTable/LRUHashMap.h
+++ b/src/Common/HashTable/LRUHashMap.h
@@ -77,7 +77,7 @@ struct LRUHashMapCellNodeTraits
     static void set_previous(node * __restrict ptr, node * __restrict prev) { ptr->prev = prev; }
 };
 
-template <typename TKey, typename TValue, typename Hash, bool save_hash_in_cells>
+template <typename TKey, typename TValue, typename Disposer, typename Hash, bool save_hash_in_cells>
 class LRUHashMapImpl :
     private HashMapTable<
         TKey,
@@ -108,24 +108,33 @@ class LRUHashMapImpl :
         boost::intrusive::value_traits<LRUHashMapCellIntrusiveValueTraits>,
         boost::intrusive::constant_time_size<false>>;
 
+    using LookupResult = typename Base::LookupResult;
+    using ConstLookupResult = typename Base::ConstLookupResult;
+
     using iterator = typename LRUList::iterator;
     using const_iterator = typename LRUList::const_iterator;
     using reverse_iterator = typename LRUList::reverse_iterator;
     using const_reverse_iterator = typename LRUList::const_reverse_iterator;
 
-    LRUHashMapImpl(size_t max_size_, bool preallocate_max_size_in_hash_map = false)
+    explicit LRUHashMapImpl(size_t max_size_, bool preallocate_max_size_in_hash_map = false, Disposer disposer_ = Disposer())
         : Base(preallocate_max_size_in_hash_map ? max_size_ : 32)
         , max_size(max_size_)
+        , disposer(std::move(disposer_))
     {
         assert(max_size > 0);
     }
 
-    std::pair<Cell *, bool> insert(const Key & key, const Value & value)
+    ~LRUHashMapImpl()
+    {
+        clear();
+    }
+
+    std::pair<Cell *, bool> ALWAYS_INLINE insert(const Key & key, const Value & value)
     {
         return emplace(key, value);
     }
 
-    std::pair<Cell *, bool> insert(const Key & key, Value && value)
+    std::pair<Cell *, bool> ALWAYS_INLINE insert(const Key & key, Value && value)
     {
         return emplace(key, std::move(value));
     }
@@ -147,15 +156,16 @@ class LRUHashMapImpl :
         if (size() == max_size)
         {
             /// Erase least recently used element from front of the list
-            Cell & node = lru_list.front();
+            Cell copy_node = lru_list.front();
 
-            const Key & element_to_remove_key = node.getKey();
-            size_t key_hash = node.getHash(*this);
+            const Key & element_to_remove_key = copy_node.getKey();
 
             lru_list.pop_front();
 
-            [[maybe_unused]] bool erased = Base::erase(element_to_remove_key, key_hash);
+            [[maybe_unused]] bool erased = Base::erase(element_to_remove_key);
             assert(erased);
+
+            disposer(element_to_remove_key, copy_node.getMapped());
         }
 
         [[maybe_unused]] bool inserted;
@@ -174,46 +184,64 @@ class LRUHashMapImpl :
         return std::make_pair(it, true);
     }
 
-    using Base::find;
-
-    Value & get(const Key & key)
+    LookupResult ALWAYS_INLINE find(const Key & key)
     {
         auto it = Base::find(key);
-        assert(it);
 
-        Value & value = it->getMapped();
+        if (!it)
+            return nullptr;
 
         /// Put cell to the end of lru list
         lru_list.splice(lru_list.end(), lru_list, lru_list.iterator_to(*it));
 
-        return value;
+        return it;
+    }
+
+    ConstLookupResult ALWAYS_INLINE find(const Key & key) const
+    {
+        return const_cast<std::decay_t<decltype(*this)> *>(this)->find(key);
     }
 
-    const Value & get(const Key & key) const
+    Value & ALWAYS_INLINE get(const Key & key)
+    {
+        auto it = find(key);
+        assert(it);
+
+        return it->getMapped();
+    }
+
+    const Value & ALWAYS_INLINE get(const Key & key) const
     {
         return const_cast<std::decay_t<decltype(*this)> *>(this)->get(key);
     }
 
-    bool contains(const Key & key) const
+    bool ALWAYS_INLINE contains(const Key & key) const
     {
-        return Base::has(key);
+        return find(key) != nullptr;
     }
 
-    bool erase(const Key & key)
+    bool ALWAYS_INLINE erase(const Key & key)
     {
-        auto hash = Base::hash(key);
-        auto it = Base::find(key, hash);
+        auto key_hash = Base::hash(key);
+        auto it = Base::find(key, key_hash);
 
         if (!it)
             return false;
 
         lru_list.erase(lru_list.iterator_to(*it));
 
-        return Base::erase(key, hash);
+        Cell copy_node = *it;
+        Base::erase(key, key_hash);
+        disposer(copy_node.getKey(), copy_node.getMapped());
+
+        return true;
     }
 
-    void clear()
+    void ALWAYS_INLINE clear()
     {
+        for (auto & cell : lru_list)
+            disposer(cell.getKey(), cell.getMapped());
+
         lru_list.clear();
         Base::clear();
     }
@@ -222,6 +250,10 @@ class LRUHashMapImpl :
 
     size_t getMaxSize() const { return max_size; }
 
+    size_t getSizeInBytes() const { return Base::getBufferSizeInBytes(); }
+
+    using Base::hash;
+
     iterator begin() { return lru_list.begin(); }
     const_iterator begin() const { return lru_list.cbegin(); }
     iterator end() { return lru_list.end(); }
@@ -235,10 +267,17 @@ class LRUHashMapImpl :
 private:
     size_t max_size;
     LRUList lru_list;
+    Disposer disposer;
+};
+
+template <typename Key, typename Mapped>
+struct DefaultCellDisposer
+{
+    void operator()(const Key &, const Mapped &) const {}
 };
 
-template <typename Key, typename Value, typename Hash = DefaultHash<Key>>
-using LRUHashMap = LRUHashMapImpl<Key, Value, Hash, false>;
+template <typename Key, typename Value, typename Disposer = DefaultCellDisposer<Key, Value>, typename Hash = DefaultHash<Key>>
+using LRUHashMap = LRUHashMapImpl<Key, Value, Disposer, Hash, false>;
 
-template <typename Key, typename Value, typename Hash = DefaultHash<Key>>
-using LRUHashMapWithSavedHash = LRUHashMapImpl<Key, Value, Hash, true>;
+template <typename Key, typename Value, typename Disposer = DefaultCellDisposer<Key, Value>, typename Hash = DefaultHash<Key>>
+using LRUHashMapWithSavedHash = LRUHashMapImpl<Key, Value, Disposer, Hash, true>;
diff --git a/src/Dictionaries/BucketCache.h b/src/Dictionaries/BucketCache.h
deleted file mode 100644
index 381110066a65..000000000000
--- a/src/Dictionaries/BucketCache.h
+++ /dev/null
@@ -1,226 +0,0 @@
-#pragma once
-
-#include <Common/HashTable/Hash.h>
-#include <common/logger_useful.h>
-#include <type_traits>
-#include <vector>
-
-namespace DB
-{
-
-namespace
-{
-    inline size_t roundUpToPowerOfTwoOrZero(size_t x)
-    {
-        size_t r = 8;
-        while (x > r)
-            r <<= 1;
-        return r;
-    }
-}
-
-struct EmptyDeleter {};
-
-struct Int64Hasher
-{
-    size_t operator()(const size_t x) const
-    {
-        return intHash64(x);
-    }
-};
-
-
-/*
-    Class for storing cache index.
-    It consists of two arrays.
-    The first one is split into buckets (each stores 8 elements (cells)) determined by hash of the element key.
-    The second one is split into 4bit numbers, which are positions in bucket for next element write (So cache uses FIFO eviction algorithm inside each bucket).
-*/
-template <typename K, typename V, typename Hasher, typename Deleter = EmptyDeleter>
-class BucketCacheIndex
-{
-    struct Cell
-    {
-        K key;
-        V index;
-    };
-
-public:
-    template <typename = std::enable_if<std::is_same_v<EmptyDeleter, Deleter>>>
-    BucketCacheIndex(size_t cells_)
-        : buckets(roundUpToPowerOfTwoOrZero(cells_) / bucket_size)
-        , bucket_mask(buckets - 1)
-        , cells(buckets * bucket_size)
-        , positions((buckets / 2) + 1)
-    {
-        for (auto & cell : cells)
-            cell.index.setNotExists();
-        for (size_t bucket = 0; bucket < buckets; ++bucket)
-            setPosition(bucket, 0);
-    }
-
-    template <typename = std::enable_if<!std::is_same_v<EmptyDeleter, Deleter>>>
-    BucketCacheIndex(size_t cells_, Deleter deleter_)
-        : deleter(deleter_)
-        , buckets(roundUpToPowerOfTwoOrZero(cells_) / bucket_size)
-        , bucket_mask(buckets - 1)
-        , cells(buckets * bucket_size)
-        , positions((buckets / 2) + 1)
-    {
-        for (auto & cell : cells)
-            cell.index.setNotExists();
-        for (size_t bucket = 0; bucket < buckets; ++bucket)
-            setPosition(bucket, 0);
-    }
-
-    void set(K key, V val)
-    {
-        const size_t bucket = (hash(key) & bucket_mask);
-        const size_t idx = getCellIndex(key, bucket);
-        if (!cells[idx].index.exists())
-        {
-            incPosition(bucket);
-            ++sz;
-        }
-
-        cells[idx].key = key;
-        cells[idx].index = val;
-    }
-
-    template <typename = std::enable_if<!std::is_same_v<EmptyDeleter, Deleter>>>
-    void setWithDelete(K key, V val)
-    {
-        const size_t bucket = (hash(key) & bucket_mask);
-        const size_t idx = getCellIndex(key, bucket);
-        if (!cells[idx].index.exists())
-        {
-            incPosition(bucket);
-            ++sz;
-        }
-        else
-        {
-            deleter(cells[idx].key);
-        }
-
-        cells[idx].key = key;
-        cells[idx].index = val;
-    }
-
-    bool get(K key, V & val) const
-    {
-        const size_t bucket = (hash(key) & bucket_mask);
-        const size_t idx = getCellIndex(key, bucket);
-        if (!cells[idx].index.exists() || cells[idx].key != key)
-            return false;
-        val = cells[idx].index;
-        return true;
-    }
-
-    bool getKeyAndValue(K & key, V & val) const
-    {
-        const size_t bucket = (hash(key) & bucket_mask);
-        const size_t idx = getCellIndex(key, bucket);
-        if (!cells[idx].index.exists() || cells[idx].key != key)
-            return false;
-        key = cells[idx].key;
-        val = cells[idx].index;
-        return true;
-    }
-
-    bool erase(K key)
-    {
-        const size_t bucket = (hash(key) & bucket_mask);
-        const size_t idx = getCellIndex(key, bucket);
-        if (!cells[idx].index.exists() || cells[idx].key != key)
-            return false;
-
-        cells[idx].index.setNotExists();
-        --sz;
-        if constexpr (!std::is_same_v<EmptyDeleter, Deleter>)
-            deleter(cells[idx].key);
-
-        return true;
-    }
-
-    size_t size() const
-    {
-        return sz;
-    }
-
-    size_t capacity() const
-    {
-        return cells.size();
-    }
-
-    auto keys() const
-    {
-        std::vector<K> res;
-        for (const auto & cell : cells)
-        {
-            if (cell.index.exists())
-            {
-                res.push_back(cell.key);
-            }
-        }
-        return res;
-    }
-
-private:
-    /// Searches for the key in the bucket.
-    /// Returns index of cell with provided key.
-    size_t getCellIndex(const K key, const size_t bucket) const
-    {
-        const size_t pos = getPosition(bucket);
-        for (int idx = 7; idx >= 0; --idx)
-        {
-            const size_t cur = ((pos + 1 + idx) & pos_mask);
-            if (cells[bucket * bucket_size + cur].index.exists() &&
-                cells[bucket * bucket_size + cur].key == key)
-            {
-                return bucket * bucket_size + cur;
-            }
-        }
-
-        return bucket * bucket_size + pos;
-    }
-
-    /// Returns current position for write in the bucket.
-    size_t getPosition(const size_t bucket) const
-    {
-        const size_t idx = (bucket >> 1);
-        if ((bucket & 1) == 0)
-            return ((positions[idx] >> 4) & pos_mask);
-        return (positions[idx] & pos_mask);
-    }
-
-    /// Sets current posiotion in the bucket.
-    void setPosition(const size_t bucket, const size_t pos)
-    {
-        const size_t idx = bucket >> 1;
-        if ((bucket & 1) == 0)
-            positions[idx] = ((pos << 4) | (positions[idx] & ((1 << 4) - 1)));
-        else
-            positions[idx] = (pos | (positions[idx] & (((1 << 4) - 1) << 4)));
-    }
-
-    void incPosition(const size_t bucket)
-    {
-        setPosition(bucket, (getPosition(bucket) + 1) & pos_mask);
-    }
-
-    static constexpr size_t bucket_size = 8;
-    static constexpr size_t pos_size = 3;
-    static constexpr size_t pos_mask = (1 << pos_size) - 1;
-
-    Hasher hash;
-    Deleter deleter;
-
-    size_t buckets;
-    size_t bucket_mask;
-
-    std::vector<Cell> cells;
-    std::vector<char> positions;
-    size_t sz = 0;
-};
-
-}
diff --git a/src/Dictionaries/CMakeLists.txt b/src/Dictionaries/CMakeLists.txt
index 4d6ab4b85f88..563c0f3914ba 100644
--- a/src/Dictionaries/CMakeLists.txt
+++ b/src/Dictionaries/CMakeLists.txt
@@ -20,6 +20,10 @@ target_link_libraries(clickhouse_dictionaries
         string_utils
 )
 
+target_link_libraries(clickhouse_dictionaries
+    PUBLIC
+        abseil_swiss_tables)
+
 if(USE_CASSANDRA)
     target_include_directories(clickhouse_dictionaries SYSTEM PRIVATE ${CASSANDRA_INCLUDE_DIR})
 endif()
diff --git a/src/Dictionaries/CacheDictionary.cpp b/src/Dictionaries/CacheDictionary.cpp
index 67bcab109ea2..fe777355ca19 100644
--- a/src/Dictionaries/CacheDictionary.cpp
+++ b/src/Dictionaries/CacheDictionary.cpp
@@ -1,25 +1,19 @@
 #include "CacheDictionary.h"
 
 #include <memory>
-#include <Columns/ColumnString.h>
-#include <Common/BitHelpers.h>
-#include <Common/CurrentMetrics.h>
-#include <Common/HashTable/Hash.h>
-#include <Common/ProfileEvents.h>
-#include <Common/ProfilingScopedRWLock.h>
-#include <Common/randomSeed.h>
-#include <Common/typeid_cast.h>
-#include <Core/Defines.h>
-#include <IO/WriteBufferFromOStream.h>
+
 #include <ext/range.h>
 #include <ext/size.h>
 #include <ext/map.h>
 #include <ext/chrono_io.h>
-#include <Common/setThreadName.h>
-#include <DataTypes/DataTypesDecimal.h>
-#include "DictionaryBlockInputStream.h"
-#include "DictionaryFactory.h"
-#include <Functions/FunctionHelpers.h>
+
+#include <Core/Defines.h>
+#include <Common/CurrentMetrics.h>
+#include <Common/HashTable/Hash.h>
+#include <Common/HashTable/HashSet.h>
+#include <Common/ProfileEvents.h>
+#include <Common/ProfilingScopedRWLock.h>
+#include <Dictionaries/DictionaryBlockInputStream.h>
 
 namespace ProfileEvents
 {
@@ -40,88 +34,85 @@ namespace CurrentMetrics
 extern const Metric DictCacheRequests;
 }
 
-
 namespace DB
 {
 namespace ErrorCodes
 {
     extern const int CACHE_DICTIONARY_UPDATE_FAIL;
     extern const int TYPE_MISMATCH;
-    extern const int BAD_ARGUMENTS;
     extern const int UNSUPPORTED_METHOD;
-    extern const int TOO_SMALL_BUFFER_SIZE;
-    extern const int TIMEOUT_EXCEEDED;
-}
-
-
-inline size_t CacheDictionary::getCellIdx(const Key id) const
-{
-    const auto hash = intHash64(id);
-    const auto idx = hash & size_overlap_mask;
-    return idx;
 }
 
-
-CacheDictionary::CacheDictionary(
+template <DictionaryKeyType dictionary_key_type>
+CacheDictionary<dictionary_key_type>::CacheDictionary(
     const StorageID & dict_id_,
     const DictionaryStructure & dict_struct_,
     DictionarySourcePtr source_ptr_,
+    CacheDictionaryStoragePtr cache_storage_ptr_,
+    CacheDictionaryUpdateQueueConfiguration update_queue_configuration_,
     DictionaryLifetime dict_lifetime_,
-    size_t strict_max_lifetime_seconds_,
-    size_t size_,
-    bool allow_read_expired_keys_,
-    size_t max_update_queue_size_,
-    size_t update_queue_push_timeout_milliseconds_,
-    size_t query_wait_timeout_milliseconds_,
-    size_t max_threads_for_updates_)
+    bool allow_read_expired_keys_)
     : IDictionary(dict_id_)
     , dict_struct(dict_struct_)
     , source_ptr{std::move(source_ptr_)}
+    , cache_storage_ptr(cache_storage_ptr_)
+    , update_queue(
+        dict_id_.getNameForLogs(),
+        update_queue_configuration_,
+        [this](CacheDictionaryUpdateUnitPtr<dictionary_key_type> unit_to_update)
+        {
+            update(unit_to_update);
+        })
     , dict_lifetime(dict_lifetime_)
-    , strict_max_lifetime_seconds(strict_max_lifetime_seconds_)
-    , allow_read_expired_keys(allow_read_expired_keys_)
-    , max_update_queue_size(max_update_queue_size_)
-    , update_queue_push_timeout_milliseconds(update_queue_push_timeout_milliseconds_)
-    , query_wait_timeout_milliseconds(query_wait_timeout_milliseconds_)
-    , max_threads_for_updates(max_threads_for_updates_)
     , log(&Poco::Logger::get("ExternalDictionaries"))
-    , size{roundUpToPowerOfTwoOrZero(std::max(size_, size_t(max_collision_length)))}
-    , size_overlap_mask{this->size - 1}
-    , cells{this->size}
+    , allow_read_expired_keys(allow_read_expired_keys_)
     , rnd_engine(randomSeed())
-    , update_queue(max_update_queue_size_)
-    , update_pool(max_threads_for_updates)
 {
     if (!source_ptr->supportsSelectiveLoad())
         throw Exception{full_name + ": source cannot be used with CacheDictionary", ErrorCodes::UNSUPPORTED_METHOD};
 
-    createAttributes();
-    for (size_t i = 0; i < max_threads_for_updates; ++i)
-        update_pool.scheduleOrThrowOnError([this] { updateThreadFunction(); });
+    setupHierarchicalAttribute();
 }
 
-CacheDictionary::~CacheDictionary()
+template <DictionaryKeyType dictionary_key_type>
+CacheDictionary<dictionary_key_type>::~CacheDictionary()
 {
-    finished = true;
-    update_queue.clear();
-    for (size_t i = 0; i < max_threads_for_updates; ++i)
-    {
-        auto empty_finishing_ptr = std::make_shared<UpdateUnit>(std::vector<Key>());
-        update_queue.push(empty_finishing_ptr);
-    }
-    update_pool.wait();
+    update_queue.stopAndWait();
 }
 
-size_t CacheDictionary::getBytesAllocated() const
+template <DictionaryKeyType dictionary_key_type>
+size_t CacheDictionary<dictionary_key_type>::getElementCount() const
+{
+    const ProfilingScopedReadRWLock read_lock{rw_lock, ProfileEvents::DictCacheLockReadNs};
+    return cache_storage_ptr->getSize();
+}
+
+template <DictionaryKeyType dictionary_key_type>
+size_t CacheDictionary<dictionary_key_type>::getBytesAllocated() const
 {
     /// In case of existing string arena we check the size of it.
     /// But the same appears in setAttributeValue() function, which is called from update() function
     /// which in turn is called from another thread.
     const ProfilingScopedReadRWLock read_lock{rw_lock, ProfileEvents::DictCacheLockReadNs};
-    return bytes_allocated + (string_arena ? string_arena->size() : 0);
+    return cache_storage_ptr->getBytesAllocated();
+}
+
+template <DictionaryKeyType dictionary_key_type>
+double CacheDictionary<dictionary_key_type>::getLoadFactor() const
+{
+    const ProfilingScopedReadRWLock read_lock{rw_lock, ProfileEvents::DictCacheLockReadNs};
+    return static_cast<double>(cache_storage_ptr->getSize()) / cache_storage_ptr->getMaxSize();
+}
+
+template <DictionaryKeyType dictionary_key_type>
+std::exception_ptr CacheDictionary<dictionary_key_type>::getLastException() const
+{
+    const ProfilingScopedReadRWLock read_lock{rw_lock, ProfileEvents::DictCacheLockReadNs};
+    return last_exception;
 }
 
-const IDictionarySource * CacheDictionary::getSource() const
+template <DictionaryKeyType dictionary_key_type>
+const IDictionarySource * CacheDictionary<dictionary_key_type>::getSource() const
 {
     /// Mutex required here because of the getSourceAndUpdateIfNeeded() function
     /// which is used from another thread.
@@ -129,34 +120,51 @@ const IDictionarySource * CacheDictionary::getSource() const
     return source_ptr.get();
 }
 
-void CacheDictionary::toParent(const PaddedPODArray<Key> & ids, PaddedPODArray<Key> & out) const
+template <DictionaryKeyType dictionary_key_type>
+void CacheDictionary<dictionary_key_type>::toParent(const PaddedPODArray<UInt64> & ids [[maybe_unused]], PaddedPODArray<UInt64> & out [[maybe_unused]]) const
 {
-    const auto null_value = std::get<UInt64>(hierarchical_attribute->null_value);
-    DictionaryDefaultValueExtractor<UInt64> default_value_extractor(null_value);
-    getItemsNumberImpl<UInt64, UInt64>(*hierarchical_attribute, ids, out, default_value_extractor);
+    if constexpr (dictionary_key_type == DictionaryKeyType::simple)
+    {
+        /// Run update on requested keys before fetch from storage
+        const auto & attribute_name = hierarchical_attribute->name;
+
+        auto result_type = std::make_shared<DataTypeUInt64>();
+        auto input_column = result_type->createColumn();
+        auto & input_column_typed = assert_cast<ColumnVector<UInt64> &>(*input_column);
+        auto & data = input_column_typed.getData();
+        data.insert(ids.begin(), ids.end());
+
+        auto column = getColumn({attribute_name}, result_type, {std::move(input_column)}, {result_type}, {nullptr});
+        const auto & result_column_typed = assert_cast<const ColumnVector<UInt64> &>(*column);
+        const auto & result_data = result_column_typed.getData();
+
+        out.assign(result_data);
+    }
+    else
+        throw Exception("Hierarchy is not supported for complex key CacheDictionary", ErrorCodes::UNSUPPORTED_METHOD);
 }
 
 
 /// Allow to use single value in same way as array.
-static inline CacheDictionary::Key getAt(const PaddedPODArray<CacheDictionary::Key> & arr, const size_t idx)
+static inline UInt64 getAt(const PaddedPODArray<UInt64> & arr, const size_t idx)
 {
     return arr[idx];
 }
-static inline CacheDictionary::Key getAt(const CacheDictionary::Key & value, const size_t)
+static inline UInt64 getAt(const UInt64 & value, const size_t)
 {
     return value;
 }
 
-
+template <DictionaryKeyType dictionary_key_type>
 template <typename AncestorType>
-void CacheDictionary::isInImpl(const PaddedPODArray<Key> & child_ids, const AncestorType & ancestor_ids, PaddedPODArray<UInt8> & out) const
+void CacheDictionary<dictionary_key_type>::isInImpl(const PaddedPODArray<Key> & child_ids, const AncestorType & ancestor_ids, PaddedPODArray<UInt8> & out) const
 {
     /// Transform all children to parents until ancestor id or null_value will be reached.
 
     size_t out_size = out.size();
     memset(out.data(), 0xFF, out_size); /// 0xFF means "not calculated"
 
-    const auto null_value = std::get<UInt64>(hierarchical_attribute->null_value);
+    const auto null_value = hierarchical_attribute->null_value.get<UInt64>();
 
     PaddedPODArray<Key> children(out_size, 0);
     PaddedPODArray<Key> parents(child_ids.begin(), child_ids.end());
@@ -213,22 +221,25 @@ void CacheDictionary::isInImpl(const PaddedPODArray<Key> & child_ids, const Ance
     }
 }
 
-void CacheDictionary::isInVectorVector(
-    const PaddedPODArray<Key> & child_ids, const PaddedPODArray<Key> & ancestor_ids, PaddedPODArray<UInt8> & out) const
+template <DictionaryKeyType dictionary_key_type>
+void CacheDictionary<dictionary_key_type>::isInVectorVector(
+    const PaddedPODArray<UInt64> & child_ids, const PaddedPODArray<UInt64> & ancestor_ids, PaddedPODArray<UInt8> & out) const
 {
     isInImpl(child_ids, ancestor_ids, out);
 }
 
-void CacheDictionary::isInVectorConstant(const PaddedPODArray<Key> & child_ids, const Key ancestor_id, PaddedPODArray<UInt8> & out) const
+template <DictionaryKeyType dictionary_key_type>
+void CacheDictionary<dictionary_key_type>::isInVectorConstant(const PaddedPODArray<UInt64> & child_ids, const UInt64 ancestor_id, PaddedPODArray<UInt8> & out) const
 {
     isInImpl(child_ids, ancestor_id, out);
 }
 
-void CacheDictionary::isInConstantVector(const Key child_id, const PaddedPODArray<Key> & ancestor_ids, PaddedPODArray<UInt8> & out) const
+template <DictionaryKeyType dictionary_key_type>
+void CacheDictionary<dictionary_key_type>::isInConstantVector(const UInt64 child_id, const PaddedPODArray<UInt64> & ancestor_ids, PaddedPODArray<UInt8> & out) const
 {
     /// Special case with single child value.
 
-    const auto null_value = std::get<UInt64>(hierarchical_attribute->null_value);
+    const auto null_value = hierarchical_attribute->null_value.get<UInt64>();
 
     PaddedPODArray<Key> child(1, child_id);
     PaddedPODArray<Key> parent(1);
@@ -251,1032 +262,435 @@ void CacheDictionary::isInConstantVector(const Key child_id, const PaddedPODArra
         out[i] = std::find(ancestors.begin(), ancestors.end(), ancestor_ids[i]) != ancestors.end();
 }
 
-ColumnPtr CacheDictionary::getColumn(
-    const std::string & attribute_name,
-    const DataTypePtr & result_type,
-    const Columns & key_columns,
-    const DataTypes &,
-    const ColumnPtr default_values_column) const
+template <DictionaryKeyType dictionary_key_type>
+void CacheDictionary<dictionary_key_type>::setupHierarchicalAttribute()
 {
-    ColumnPtr result;
-
-    PaddedPODArray<Key> backup_storage;
-    const auto & keys = getColumnVectorData(this, key_columns.front(), backup_storage);
-    auto keys_size = keys.size();
-
-    auto & attribute = getAttribute(attribute_name);
-    const auto & dictionary_attribute = dict_struct.getAttribute(attribute_name, result_type);
-
-    auto type_call = [&](const auto &dictionary_attribute_type)
+    /// TODO: Move this to DictionaryStructure
+    for (const auto & attribute : dict_struct.attributes)
     {
-        using Type = std::decay_t<decltype(dictionary_attribute_type)>;
-        using AttributeType = typename Type::AttributeType;
-        using ColumnProvider = DictionaryAttributeColumnProvider<AttributeType>;
-
-        const auto & null_value = std::get<AttributeType>(attribute.null_value);
-        DictionaryDefaultValueExtractor<AttributeType> default_value_extractor(null_value, default_values_column);
-
-        auto column = ColumnProvider::getColumn(dictionary_attribute, keys_size);
-
-        if constexpr (std::is_same_v<AttributeType, String>)
-        {
-            getItemsString(attribute, keys, column.get(), default_value_extractor);
-        }
-        else
+        if (attribute.hierarchical)
         {
-            auto & out = column->getData();
-            getItemsNumberImpl<AttributeType, AttributeType>(attribute, keys, out, default_value_extractor);
-        }
+            hierarchical_attribute = &attribute;
 
-        result = std::move(column);
-    };
-
-    callOnDictionaryAttributeType(attribute.type, type_call);
-
-    return result;
+            if (attribute.underlying_type != AttributeUnderlyingType::utUInt64)
+                throw Exception{full_name + ": hierarchical attribute must be UInt64.", ErrorCodes::TYPE_MISMATCH};
+        }
+    }
 }
 
-template <typename AttributeType, typename OutputType, typename DefaultValueExtractor>
-void CacheDictionary::getItemsNumberImpl(
-    Attribute & attribute,
-    const PaddedPODArray<Key> & ids,
-    ResultArrayType<OutputType> & out,
-    DefaultValueExtractor & default_value_extractor) const
+template <DictionaryKeyType dictionary_key_type>
+ColumnPtr CacheDictionary<dictionary_key_type>::getColumn(
+    const std::string & attribute_name,
+    const DataTypePtr & result_type,
+    const Columns & key_columns,
+    const DataTypes & key_types,
+    const ColumnPtr & default_values_column) const
 {
-    /// First fill everything with default values
-    const auto rows = ext::size(ids);
-    for (const auto row : ext::range(0, rows))
-        out[row] = default_value_extractor[row];
-
-    /// Maybe there are duplicate keys, so we remember their indices.
-    std::unordered_map<Key, std::vector<size_t>> cache_expired_or_not_found_ids;
-
-    auto & attribute_array = std::get<ContainerPtrType<AttributeType>>(attribute.arrays);
-
-    size_t cache_hit = 0;
-    size_t cache_not_found_count = 0;
-    size_t cache_expired_cound = 0;
-
-    {
-        const ProfilingScopedReadRWLock read_lock{rw_lock, ProfileEvents::DictCacheLockReadNs};
-
-        const auto now = std::chrono::system_clock::now();
-
-        auto insert_to_answer_routine = [&](size_t row, size_t idx)
-        {
-            auto & cell = cells[idx];
-            if (!cell.isDefault())
-                out[row] = static_cast<OutputType>(attribute_array[idx]);
-        };
-
-        /// fetch up-to-date values, decide which ones require update
-        for (const auto row : ext::range(0, rows))
-        {
-            const auto id = ids[row];
-
-            /** cell should be updated if either:
-                *    1. ids do not match,
-                *    2. cell has expired,
-                *    3. explicit defaults were specified and cell was set default. */
-
-            const auto [cell_idx, state] = findCellIdxForGet(id, now);
+    return getColumns({attribute_name}, {result_type}, key_columns, key_types, {default_values_column}).front();
+}
 
-            if (state == ResultState::FoundAndValid)
-            {
-                ++cache_hit;
-                insert_to_answer_routine(row, cell_idx);
-            }
-            else if (state == ResultState::NotFound || state == ResultState::FoundButExpiredPermanently)
-            {
-                ++cache_not_found_count;
-                cache_expired_or_not_found_ids[id].push_back(row);
-            }
-            else if (state == ResultState::FoundButExpired)
-            {
-                cache_expired_cound++;
-                cache_expired_or_not_found_ids[id].push_back(row);
+template <DictionaryKeyType dictionary_key_type>
+Columns CacheDictionary<dictionary_key_type>::getColumns(
+    const Strings & attribute_names,
+    const DataTypes &,
+    const Columns & key_columns,
+    const DataTypes & key_types,
+    const Columns & default_values_columns) const
+{
+    if (dictionary_key_type == DictionaryKeyType::complex)
+        dict_struct.validateKeyTypes(key_types);
 
-                if (allow_read_expired_keys)
-                    insert_to_answer_routine(row, cell_idx);
-            }
-        }
-    }
+    Arena complex_keys_arena;
+    DictionaryKeysExtractor<dictionary_key_type> extractor(key_columns, complex_keys_arena);
+    auto & keys = extractor.getKeys();
 
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysExpired, cache_expired_cound);
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysNotFound, cache_not_found_count);
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysHit, cache_hit);
+    return getColumnsImpl(attribute_names, key_columns, keys, default_values_columns);
+}
 
-    query_count.fetch_add(rows, std::memory_order_relaxed);
-    hit_count.fetch_add(rows - cache_not_found_count - cache_expired_cound, std::memory_order_release);
+template <DictionaryKeyType dictionary_key_type>
+Columns CacheDictionary<dictionary_key_type>::getColumnsImpl(
+    const Strings & attribute_names,
+    const Columns & key_columns,
+    const PaddedPODArray<KeyType> & keys,
+    const Columns & default_values_columns) const
+{
+    /**
+    * Flow of getColumsImpl
+    * 1. Get fetch result from storage
+    * 2. If all keys are found in storage and not expired
+    *   2.1. If storage returns fetched columns in order of keys then result is returned to client.
+    *   2.2. If storage does not return fetched columns in order of keys then reorder
+    *    result columns and return result to client.
+    * 3. If all keys are found in storage but some of them are expired and we allow to read expired keys
+    * start async request to source and perform actions from step 2 for result returned from storage.
+    * 4. If some keys are found and some are not, start sync update from source.
+    * 5. Aggregate columns returned from storage and source, if key is not found in storage and in source
+    * use default value.
+    */
+
+    DictionaryStorageFetchRequest request(dict_struct, attribute_names, default_values_columns);
+
+    FetchResult result_of_fetch_from_storage;
 
-    if (!cache_not_found_count)
     {
-        /// Nothing to update - return
-        if (!cache_expired_cound)
-            return;
-
-        /// Update async only if allow_read_expired_keys_is_enabledadd condvar usage and better code
-        if (allow_read_expired_keys)
-        {
-            std::vector<Key> required_expired_ids;
-            required_expired_ids.reserve(cache_expired_cound);
-            std::transform(std::begin(cache_expired_or_not_found_ids), std::end(cache_expired_or_not_found_ids),
-                           std::back_inserter(required_expired_ids), [](auto & pair) { return pair.first; });
-
-            /// request new values
-            auto update_unit_ptr = std::make_shared<UpdateUnit>(std::move(required_expired_ids));
-
-            tryPushToUpdateQueueOrThrow(update_unit_ptr);
+        /// Write lock on storage
+        const ProfilingScopedWriteRWLock write_lock{rw_lock, ProfileEvents::DictCacheLockWriteNs};
 
-            /// Nothing to do - return
-            return;
-        }
+        result_of_fetch_from_storage = cache_storage_ptr->fetchColumnsForKeys(keys, request);
     }
 
-    /// From this point we have to update all keys sync.
-    /// Maybe allow_read_expired_keys_from_cache_dictionary is disabled
-    /// and there no cache_not_found_ids but some cache_expired.
-
-    std::vector<Key> required_ids;
-    required_ids.reserve(cache_not_found_count + cache_expired_cound);
-    std::transform(std::begin(cache_expired_or_not_found_ids), std::end(cache_expired_or_not_found_ids),
-                   std::back_inserter(required_ids), [](auto & pair) { return pair.first; });
+    size_t found_keys_size = result_of_fetch_from_storage.found_keys_size;
+    size_t expired_keys_size = result_of_fetch_from_storage.expired_keys_size;
+    size_t not_found_keys_size = result_of_fetch_from_storage.not_found_keys_size;
 
-    /// Request new values
-    auto update_unit_ptr = std::make_shared<UpdateUnit>(std::move(required_ids));
+    ProfileEvents::increment(ProfileEvents::DictCacheKeysHit, found_keys_size);
+    ProfileEvents::increment(ProfileEvents::DictCacheKeysExpired, expired_keys_size);
+    ProfileEvents::increment(ProfileEvents::DictCacheKeysNotFound, not_found_keys_size);
 
-    tryPushToUpdateQueueOrThrow(update_unit_ptr);
-    waitForCurrentUpdateFinish(update_unit_ptr);
+    query_count.fetch_add(keys.size());
+    hit_count.fetch_add(found_keys_size);
 
-    /// Add updated keys to answer.
+    MutableColumns & fetched_columns_from_storage = result_of_fetch_from_storage.fetched_columns;
+    const PaddedPODArray<KeyState> & key_index_to_state_from_storage = result_of_fetch_from_storage.key_index_to_state;
 
-    const size_t attribute_index = getAttributeIndex(attribute.name);
+    bool source_returns_fetched_columns_in_order_of_keys = cache_storage_ptr->returnsFetchedColumnsInOrderOfRequestedKeys();
 
-    for (auto & [key, value] : update_unit_ptr->found_ids)
+    if (not_found_keys_size == 0 && expired_keys_size == 0)
     {
-        if (value.found)
+        /// All keys were found in storage
+
+        if (source_returns_fetched_columns_in_order_of_keys)
+            return request.filterRequestedColumns(fetched_columns_from_storage);
+        else
         {
-            for (const size_t row : cache_expired_or_not_found_ids[key])
-                out[row] = std::get<OutputType>(value.values[attribute_index]);
+            /// Reorder result from storage to requested keys indexes
+            MutableColumns aggregated_columns = aggregateColumnsInOrderOfKeys(
+                keys,
+                request,
+                fetched_columns_from_storage,
+                key_index_to_state_from_storage);
+
+            return request.filterRequestedColumns(aggregated_columns);
         }
     }
-}
-
-void CacheDictionary::getItemsString(
-    Attribute & attribute,
-    const PaddedPODArray<Key> & ids,
-    ColumnString * out,
-    DictionaryDefaultValueExtractor<String> & default_value_extractor) const
-{
-    const auto rows = ext::size(ids);
-
-    /// Save on some allocations.
-    out->getOffsets().reserve(rows);
 
-    auto & attribute_array = std::get<ContainerPtrType<StringRef>>(attribute.arrays);
+    size_t keys_to_update_size = not_found_keys_size + expired_keys_size;
+    auto update_unit = std::make_shared<CacheDictionaryUpdateUnit<dictionary_key_type>>(key_columns, key_index_to_state_from_storage, request, keys_to_update_size);
 
-    auto found_outdated_values = false;
+    HashMap<KeyType, size_t> requested_keys_to_fetched_columns_during_update_index;
+    MutableColumns fetched_columns_during_update = request.makeAttributesResultColumns();
 
-    /// Perform optimistic version, fallback to pessimistic if failed.
+    if (not_found_keys_size == 0 && expired_keys_size > 0 && allow_read_expired_keys)
     {
-        const ProfilingScopedReadRWLock read_lock{rw_lock, ProfileEvents::DictCacheLockReadNs};
-
-        const auto now = std::chrono::system_clock::now();
+        /// Start async update only if allow read expired keys and all keys are found
+        update_queue.tryPushToUpdateQueueOrThrow(update_unit);
 
-        /// Fetch up-to-date values, discard on fail.
-        for (const auto row : ext::range(0, rows))
+        if (source_returns_fetched_columns_in_order_of_keys)
+            return request.filterRequestedColumns(fetched_columns_from_storage);
+        else
         {
-            const auto id = ids[row];
-            const auto [cell_idx, state] = findCellIdxForGet(id, now);
-
-            if (state == ResultState::FoundAndValid)
-            {
-                auto & cell = cells[cell_idx];
-                const auto string_ref = cell.isDefault() ? default_value_extractor[row] : attribute_array[cell_idx];
-                out->insertData(string_ref.data, string_ref.size);
-            }
-            else
-            {
-                found_outdated_values = true;
-                break;
-            }
+            /// Reorder result from storage to requested keys indexes
+            MutableColumns aggregated_columns = aggregateColumnsInOrderOfKeys(
+                keys,
+                request,
+                fetched_columns_from_storage,
+                key_index_to_state_from_storage);
+
+            return request.filterRequestedColumns(aggregated_columns);
         }
     }
-
-    /// Optimistic code completed successfully.
-    if (!found_outdated_values)
-    {
-        query_count.fetch_add(rows, std::memory_order_relaxed);
-        hit_count.fetch_add(rows, std::memory_order_release);
-        ProfileEvents::increment(ProfileEvents::DictCacheKeysHit, ids.size());
-        return;
-    }
-
-    /// Now onto the pessimistic one, discard possible partial results from the optimistic path.
-    out->getChars().resize_assume_reserved(0);
-    out->getOffsets().resize_assume_reserved(0);
-
-    /// Mapping: <id> -> { all indices `i` of `ids` such that `ids[i]` = <id> }
-    std::unordered_map<Key, std::vector<size_t>> cache_expired_or_not_found_ids;
-    /// we are going to store every string separately
-    std::unordered_map<Key, String> local_cache;
-
-    size_t cache_not_found_count = 0;
-    size_t cache_expired_count = 0;
-
-    size_t total_length = 0;
-    size_t cache_hit = 0;
+    else
     {
-        const ProfilingScopedReadRWLock read_lock{rw_lock, ProfileEvents::DictCacheLockReadNs};
-
-        const auto now = std::chrono::system_clock::now();
+        /// Start sync update
+        update_queue.tryPushToUpdateQueueOrThrow(update_unit);
+        update_queue.waitForCurrentUpdateFinish(update_unit);
 
-        auto insert_value_routine = [&](size_t row, size_t id, size_t cell_idx)
-        {
-            const auto & cell = cells[cell_idx];
-            const auto string_ref = cell.isDefault() ? default_value_extractor[row] : attribute_array[cell_idx];
-
-            /// Do not store default, but count it in total length.
-            if (!cell.isDefault())
-                local_cache[id] = String{string_ref};
-
-            total_length += string_ref.size + 1;
-        };
-
-        for (const auto row : ext::range(0, ids.size()))
-        {
-            const auto id = ids[row];
-            const auto [cell_idx, state] = findCellIdxForGet(id, now);
-
-            if (state == ResultState::FoundAndValid)
-            {
-                ++cache_hit;
-                insert_value_routine(row, id, cell_idx);
-            }
-            else if (state == ResultState::NotFound || state == ResultState::FoundButExpiredPermanently)
-            {
-                ++cache_not_found_count;
-                cache_expired_or_not_found_ids[id].push_back(row);
-            }
-            else if (state == ResultState::FoundButExpired)
-            {
-                ++cache_expired_count;
-                cache_expired_or_not_found_ids[id].push_back(row);
-
-                if (allow_read_expired_keys)
-                    insert_value_routine(row, id, cell_idx);
-            }
-        }
+        requested_keys_to_fetched_columns_during_update_index = std::move(update_unit->requested_keys_to_fetched_columns_during_update_index);
+        fetched_columns_during_update = std::move(update_unit->fetched_columns_during_update);
     }
 
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysExpired, cache_expired_count);
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysNotFound, cache_not_found_count);
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysHit, cache_hit);
+    MutableColumns aggregated_columns = aggregateColumns(
+        keys,
+        request,
+        fetched_columns_from_storage,
+        key_index_to_state_from_storage,
+        fetched_columns_during_update,
+        requested_keys_to_fetched_columns_during_update_index);
 
-    query_count.fetch_add(rows, std::memory_order_relaxed);
-    hit_count.fetch_add(rows - cache_expired_count - cache_not_found_count, std::memory_order_release);
-
-    /// Async update of expired keys.
-    if (!cache_not_found_count)
-    {
-        if (allow_read_expired_keys && cache_expired_count)
-        {
-            std::vector<Key> required_expired_ids;
-            required_expired_ids.reserve(cache_expired_count);
-            std::transform(std::begin(cache_expired_or_not_found_ids), std::end(cache_expired_or_not_found_ids),
-                           std::back_inserter(required_expired_ids), [](auto & pair) { return pair.first; });
+    return request.filterRequestedColumns(aggregated_columns);
+}
 
-            auto update_unit_ptr = std::make_shared<UpdateUnit>(std::move(required_expired_ids));
+template <DictionaryKeyType dictionary_key_type>
+ColumnUInt8::Ptr CacheDictionary<dictionary_key_type>::hasKeys(const Columns & key_columns, const DataTypes & key_types) const
+{
+    /**
+    * Flow of hasKeys. It is similar to getColumns. But there is an important detail, if key is identified with default value in storage
+    * it means that in hasKeys result this key will be false.
+    *
+    * 1. Get fetch result from storage
+    * 2. If all keys are found in storage and not expired and there are no default keys return that we have all keys.
+    * Otherwise set allow_expired_keys_during_aggregation and go to step 5.
+    * 3. If all keys are found in storage and some of them are expired and allow_read_expired keys is true return that we have all keys.
+    * Otherwise set allow_expired_keys_during_aggregation and go to step 5.
+    * 4. If not all keys are found in storage start sync update from source.
+    * 5. Start aggregation of keys from source and storage.
+    * If we allow read expired keys from step 2 or 3 then count them as founded in storage.
+    * Check if key was found in storage not default for that key set true in result array.
+    * Check that key was fetched during update for that key set true in result array.
+    */
 
-            tryPushToUpdateQueueOrThrow(update_unit_ptr);
+    if (dictionary_key_type == DictionaryKeyType::complex)
+        dict_struct.validateKeyTypes(key_types);
 
-            /// Insert all found keys and defaults to output array.
-            out->getChars().reserve(total_length);
+    Arena complex_keys_arena;
+    DictionaryKeysExtractor<dictionary_key_type> extractor(key_columns, complex_keys_arena);
+    const auto & keys = extractor.getKeys();
 
-            for (const auto row : ext::range(0, ext::size(ids)))
-            {
-                const auto id = ids[row];
-                StringRef value;
+    /// We make empty request just to fetch if keys exists
+    DictionaryStorageFetchRequest request(dict_struct, {}, {});
 
-                /// Previously we stored found keys in map.
-                const auto it = local_cache.find(id);
-                if (it != local_cache.end())
-                    value = StringRef(it->second);
-                else
-                    value = default_value_extractor[row];
+    FetchResult result_of_fetch_from_storage;
 
-                out->insertData(value.data, value.size);
-            }
+    {
+        /// Write lock on storage
+        const ProfilingScopedWriteRWLock write_lock{rw_lock, ProfileEvents::DictCacheLockWriteNs};
 
-            /// Nothing to do else.
-            return;
-        }
+        result_of_fetch_from_storage = cache_storage_ptr->fetchColumnsForKeys(keys, request);
     }
 
-    /// We will request both cache_not_found_ids and cache_expired_ids sync.
-    std::vector<Key> required_ids;
-    required_ids.reserve(cache_not_found_count + cache_expired_count);
-    std::transform(
-        std::begin(cache_expired_or_not_found_ids), std::end(cache_expired_or_not_found_ids),
-        std::back_inserter(required_ids), [](auto & pair) { return pair.first; });
+    size_t found_keys_size = result_of_fetch_from_storage.found_keys_size;
+    size_t expired_keys_size = result_of_fetch_from_storage.expired_keys_size;
+    size_t not_found_keys_size = result_of_fetch_from_storage.not_found_keys_size;
 
-    auto update_unit_ptr = std::make_shared<UpdateUnit>(std::move(required_ids));
+    ProfileEvents::increment(ProfileEvents::DictCacheKeysHit, found_keys_size);
+    ProfileEvents::increment(ProfileEvents::DictCacheKeysExpired, expired_keys_size);
+    ProfileEvents::increment(ProfileEvents::DictCacheKeysNotFound, not_found_keys_size);
 
-    tryPushToUpdateQueueOrThrow(update_unit_ptr);
-    waitForCurrentUpdateFinish(update_unit_ptr);
+    query_count.fetch_add(keys.size());
+    hit_count.fetch_add(found_keys_size);
 
-    const size_t attribute_index = getAttributeIndex(attribute.name);
+    size_t keys_to_update_size = expired_keys_size + not_found_keys_size;
+    auto update_unit = std::make_shared<CacheDictionaryUpdateUnit<dictionary_key_type>>(key_columns, result_of_fetch_from_storage.key_index_to_state, request, keys_to_update_size);
 
-    /// Only calculate the total length.
-    for (auto & [key, value] : update_unit_ptr->found_ids)
-    {
-        if (value.found)
-        {
-            const auto found_value_ref = std::get<String>(value.values[attribute_index]);
-            total_length += (found_value_ref.size() + 1) * cache_expired_or_not_found_ids[key].size();
-        }
-        else
-        {
-            for (const auto row : cache_expired_or_not_found_ids[key])
-                total_length += default_value_extractor[row].size + 1;
-        }
-    }
-
-    out->getChars().reserve(total_length);
+    HashMap<KeyType, size_t> requested_keys_to_fetched_columns_during_update_index;
+    bool allow_expired_keys_during_aggregation = false;
 
-    for (const auto row : ext::range(0, ext::size(ids)))
+    if (not_found_keys_size == 0 && expired_keys_size == 0)
     {
-        const auto id = ids[row];
-        StringRef value;
-
-        /// We have two maps: found in cache and found in source.
-        const auto local_it = local_cache.find(id);
-        if (local_it != local_cache.end())
-            value = StringRef(local_it->second);
-        else
-        {
-            const auto found_it = update_unit_ptr->found_ids.find(id);
-
-            /// Previously we didn't store defaults in local cache.
-            if (found_it != update_unit_ptr->found_ids.end() && found_it->second.found)
-                value = std::get<String>(found_it->second.values[attribute_index]);
-            else
-                value = default_value_extractor[row];
-        }
+        /// All keys were found in storage
 
-        out->insertData(value.data, value.size);
-    }
-}
+        if (result_of_fetch_from_storage.default_keys_size == 0)
+            return ColumnUInt8::create(keys.size(), true);
 
-
-template<class... Ts>
-struct Overloaded : Ts... {using Ts::operator()...;};
-
-template<class... Ts>
-Overloaded(Ts...) -> Overloaded<Ts...>;
-
-std::string CacheDictionary::AttributeValuesForKey::dump()
-{
-    WriteBufferFromOwnString os;
-    for (auto & attr : values)
-        std::visit(Overloaded {
-            [&os](UInt8 arg)   { os << "type: UInt8, value: "   <<  std::to_string(arg) << "
"; },
-            [&os](UInt16 arg)  { os << "type: UInt16, value: "  <<  std::to_string(arg) << "
"; },
-            [&os](UInt32 arg)  { os << "type: UInt32, value: "  <<  std::to_string(arg) << "
"; },
-            [&os](UInt64 arg)  { os << "type: UInt64, value: "  <<  std::to_string(arg) << "
"; },
-            [&os](UInt128 arg) { os << "type: UInt128, value: " << arg.toHexString() << "
"; },
-            [&os](Int8 arg)   { os << "type: Int8, value: "   <<  std::to_string(arg) << "
"; },
-            [&os](Int16 arg)  { os << "type: Int16, value: "  <<  std::to_string(arg) << "
"; },
-            [&os](Int32 arg)  { os << "type: Int32, value: "  <<  std::to_string(arg) << "
"; },
-            [&os](Int64 arg)  { os << "type: Int64, value: "  <<  std::to_string(arg) << "
"; },
-            [&os](Decimal32 arg)   { os << "type: Decimal32, value: "  <<  std::to_string(arg) << "
"; },
-            [&os](Decimal64 arg)   { os << "type: Decimal64, value: "  <<  std::to_string(arg) << "
"; },
-            [&os](Decimal128)  { os << "type: Decimal128, value: ???" << "
" ; },
-            [&os](Float32 arg)   { os << "type: Float32, value: "  <<  std::to_string(arg) << "
"; },
-            [&os](Float64 arg)   { os << "type: Float64, value: "  <<  std::to_string(arg) << "
"; },
-            [&os](String arg)  { os << "type: String, value: " <<  arg + "
"; }
-        }, attr);
-    return os.str();
-};
-
-
-std::string CacheDictionary::UpdateUnit::dumpFoundIds()
-{
-    WriteBufferFromOwnString os;
-    for (auto it : found_ids)
-    {
-        os << "Key: " << std::to_string(it.first) << "
";
-        if (it.second.found)
-            os << it.second.dump() << "
";
+        allow_expired_keys_during_aggregation = true;
     }
-    return os.str();
-};
-
-/// Returns cell_idx in handmade open addressing cache table and the state of the cell stored the key.
-CacheDictionary::FindResult CacheDictionary::findCellIdxForGet(const Key & id, const time_point_t now) const
-{
-    auto pos = getCellIdx(id);
-    const auto stop = pos + max_collision_length;
-    for (; pos < stop; ++pos)
+    else if (not_found_keys_size == 0 && expired_keys_size > 0 && allow_read_expired_keys)
     {
-        const auto cell_idx = pos & size_overlap_mask;
-        const auto & cell = cells[cell_idx];
-
-        if (cell.id != id)
-            continue;
-
-        if (isExpiredPermanently(now, cell.expiresAt()))
-            return {cell_idx, ResultState::FoundButExpiredPermanently};
+        /// Start async update only if allow read expired keys and all keys are found
+        update_queue.tryPushToUpdateQueueOrThrow(update_unit);
 
-        if (isExpired(now, cell.expiresAt()))
-            return {cell_idx, ResultState::FoundButExpired};
+        if (result_of_fetch_from_storage.default_keys_size == 0)
+            return ColumnUInt8::create(keys.size(), true);
 
-        return {cell_idx, ResultState::FoundAndValid};
+        allow_expired_keys_during_aggregation = true;
     }
-
-    return {pos & size_overlap_mask, ResultState::NotFound};
-}
-
-/// Returns cell_idx such that cells[cell_idx].id = id or the oldest cell in bounds of max_coolision_length.
-size_t CacheDictionary::findCellIdxForSet(const Key & id) const
-{
-    auto pos = getCellIdx(id);
-    auto oldest_id = pos;
-    auto oldest_time = time_point_t::max();
-    const auto stop = pos + max_collision_length;
-    for (; pos < stop; ++pos)
+    else
     {
-        const auto cell_idx = pos & size_overlap_mask;
-        const auto & cell = cells[cell_idx];
+        /// Start sync update
+        update_queue.tryPushToUpdateQueueOrThrow(update_unit);
+        update_queue.waitForCurrentUpdateFinish(update_unit);
 
-        if (cell.id != id)
-        {
-            /// maybe we already found nearest expired cell (try minimize collision_length on insert)
-            if (cell.expiresAt() < oldest_time)
-            {
-                oldest_time = cell.expiresAt();
-                oldest_id = cell_idx;
-            }
-            continue;
-        }
-
-        /// We found the exact place for id.
-        return cell_idx;
+        requested_keys_to_fetched_columns_during_update_index = std::move(update_unit->requested_keys_to_fetched_columns_during_update_index);
     }
 
-    return oldest_id;
-}
-
-ColumnUInt8::Ptr CacheDictionary::hasKeys(const Columns & key_columns, const DataTypes &) const
-{
-    PaddedPODArray<Key> backup_storage;
-    const auto& ids = getColumnVectorData(this, key_columns.front(), backup_storage);
-
-    auto result = ColumnUInt8::create(ext::size(ids));
-    auto& out = result->getData();
-
-    /// There are three types of ids.
-    /// - Valid ids. These ids are presented in local cache and their lifetime is not expired.
-    /// - CacheExpired ids. Ids that are in local cache, but their values are rotted (lifetime is expired).
-    /// - CacheNotFound ids. We have to go to external storage to know its value.
-
-    /// Mark everything as absent.
-    const auto rows = ext::size(ids);
-    for (const auto row : ext::range(0, rows))
-        out[row] = false;
-
-    /// Mapping: <id> -> { all indices `i` of `ids` such that `ids[i]` = <id> }
-    std::unordered_map<Key, std::vector<size_t>> cache_expired_or_not_found_ids;
-
-    size_t cache_hit = 0;
-
-    size_t cache_expired_count = 0;
-    size_t cache_not_found_count = 0;
+    auto result = ColumnUInt8::create(keys.size(), false);
+    auto & data = result->getData();
 
+    for (size_t key_index = 0; key_index < keys.size(); ++key_index)
     {
-        const ProfilingScopedReadRWLock read_lock{rw_lock, ProfileEvents::DictCacheLockReadNs};
+        auto key = keys[key_index];
 
-        const auto now = std::chrono::system_clock::now();
-        /// fetch up-to-date values, decide which ones require update
-        for (const auto row : ext::range(0, rows))
-        {
-            const auto id = ids[row];
-            const auto [cell_idx, state] = findCellIdxForGet(id, now);
-            auto & cell = cells[cell_idx];
-
-            auto insert_to_answer_routine = [&] ()
-            {
-                out[row] = !cell.isDefault();
-            };
+        bool valid_expired_key = allow_expired_keys_during_aggregation && result_of_fetch_from_storage.key_index_to_state[key_index].isExpired();
 
-            if (state == ResultState::FoundAndValid)
-            {
-                ++cache_hit;
-                insert_to_answer_routine();
-            }
-            else if (state == ResultState::NotFound || state == ResultState::FoundButExpiredPermanently)
-            {
-                /// Permanently expired equals to not found semantically.
-                ++cache_not_found_count;
-                cache_expired_or_not_found_ids[id].push_back(row);
-            }
-            else if (state == ResultState::FoundButExpired)
-            {
-                cache_expired_count++;
-                cache_expired_or_not_found_ids[id].push_back(row);
-
-                if (allow_read_expired_keys)
-                    insert_to_answer_routine();
-            }
+        if (result_of_fetch_from_storage.key_index_to_state[key_index].isFound() || valid_expired_key)
+        {
+            /// Check if key was fetched from cache
+            data[key_index] = !result_of_fetch_from_storage.key_index_to_state[key_index].isDefault();
         }
-    }
-
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysExpired, cache_expired_count);
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysNotFound, cache_not_found_count);
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysHit, cache_hit);
-
-    query_count.fetch_add(rows, std::memory_order_relaxed);
-    hit_count.fetch_add(rows - cache_expired_count - cache_not_found_count, std::memory_order_release);
 
-    if (!cache_not_found_count)
-    {
-        /// Nothing to update - return;
-        if (!cache_expired_count)
-            return result;
-
-        if (allow_read_expired_keys)
+        if (requested_keys_to_fetched_columns_during_update_index.has(key))
         {
-            std::vector<Key> required_expired_ids;
-            required_expired_ids.reserve(cache_expired_count);
-            std::transform(
-                    std::begin(cache_expired_or_not_found_ids), std::end(cache_expired_or_not_found_ids),
-                    std::back_inserter(required_expired_ids), [](auto & pair) { return pair.first; });
-
-            auto update_unit_ptr = std::make_shared<UpdateUnit>(std::move(required_expired_ids));
-
-            tryPushToUpdateQueueOrThrow(update_unit_ptr);
-            /// Update is async - no need to wait.
-            return result;
+            /// Check if key was not in cache and was fetched during update
+            data[key_index] = true;
         }
     }
 
-    /// At this point we have two situations.
-    /// There may be both types of keys: expired and not_found.
-    /// We will update them all synchronously.
-
-    std::vector<Key> required_ids;
-    required_ids.reserve(cache_not_found_count + cache_expired_count);
-    std::transform(
-            std::begin(cache_expired_or_not_found_ids), std::end(cache_expired_or_not_found_ids),
-            std::back_inserter(required_ids), [](auto & pair) { return pair.first; });
-
-    auto update_unit_ptr = std::make_shared<UpdateUnit>(std::move(required_ids));
-
-    tryPushToUpdateQueueOrThrow(update_unit_ptr);
-    waitForCurrentUpdateFinish(update_unit_ptr);
-
-    for (auto & [key, value] : update_unit_ptr->found_ids)
-    {
-        if (value.found)
-            for (const auto row : cache_expired_or_not_found_ids[key])
-                out[row] = true;
-    }
-
     return result;
 }
 
-
-void CacheDictionary::createAttributes()
+template <DictionaryKeyType dictionary_key_type>
+MutableColumns CacheDictionary<dictionary_key_type>::aggregateColumnsInOrderOfKeys(
+    const PaddedPODArray<KeyType> & keys,
+    const DictionaryStorageFetchRequest & request,
+    const MutableColumns & fetched_columns,
+    const PaddedPODArray<KeyState> & key_index_to_state)
 {
-    const auto attributes_size = dict_struct.attributes.size();
-    attributes.reserve(attributes_size);
+    MutableColumns aggregated_columns = request.makeAttributesResultColumns();
 
-    bytes_allocated += size * sizeof(CellMetadata);
-    bytes_allocated += attributes_size * sizeof(attributes.front());
+    /// If keys were returned not in order of keys, aggregate fetched columns in order of requested keys.
 
-    for (const auto & attribute : dict_struct.attributes)
+    for (size_t fetch_request_index = 0; fetch_request_index < request.attributesSize(); ++fetch_request_index)
     {
-        attribute_index_by_name.emplace(attribute.name, attributes.size());
-        attributes.push_back(createAttributeWithTypeAndName(attribute.underlying_type, attribute.name, attribute.null_value));
+        if (!request.shouldFillResultColumnWithIndex(fetch_request_index))
+            continue;
 
-        if (attribute.hierarchical)
-        {
-            hierarchical_attribute = &attributes.back();
+        const auto & aggregated_column = aggregated_columns[fetch_request_index];
+        const auto & fetched_column = fetched_columns[fetch_request_index];
 
-            if (hierarchical_attribute->type != AttributeUnderlyingType::utUInt64)
-                throw Exception{full_name + ": hierarchical attribute must be UInt64.", ErrorCodes::TYPE_MISMATCH};
-        }
-    }
-}
+        for (size_t key_index = 0; key_index < keys.size(); ++key_index)
+        {
+            auto state = key_index_to_state[key_index];
 
-/* For unknown reason clang-tidy wants this function to be static, but it uses bytes_allocated, which is a class member.
- * NOLINT(readability-convert-member-functions-to-static) */
-CacheDictionary::Attribute CacheDictionary::createAttributeWithTypeAndName(const AttributeUnderlyingType type, const String & name, const Field & null_value)
-{
-    Attribute attr{type, name, {}, {}};
+            if (state.isNotFound())
+                continue;
 
-    switch (type)
-    {
-        /* Macro argument should be enclosed in parentheses, but if do so we cannot initialize \
-         * NearestFieldType which takes TYPE as a template parameter. */
-#define DISPATCH(TYPE)\
-        case AttributeUnderlyingType::ut##TYPE:\
-        {\
-            attr.null_value = TYPE(null_value.get<NearestFieldType<TYPE>>()); /* NOLINT(bugprone-macro-parentheses) */ \
-            attr.arrays = std::make_unique<ContainerType<TYPE>>(size); /* NOLINT(bugprone-macro-parentheses) */ \
-            bytes_allocated += size * sizeof(TYPE);\
-            break;\
-        }
-        DISPATCH(UInt8)
-        DISPATCH(UInt16)
-        DISPATCH(UInt32)
-        DISPATCH(UInt64)
-        DISPATCH(UInt128)
-        DISPATCH(Int8)
-        DISPATCH(Int16)
-        DISPATCH(Int32)
-        DISPATCH(Int64)
-        DISPATCH(Decimal32)
-        DISPATCH(Decimal64)
-        DISPATCH(Decimal128)
-        DISPATCH(Float32)
-        DISPATCH(Float64)
-#undef DISPATCH
-        case AttributeUnderlyingType::utString: {
-            attr.null_value = null_value.get<String>();
-            attr.arrays = std::make_unique<ContainerType<StringRef>>(size);
-            bytes_allocated += size * sizeof(StringRef);
-            if (!string_arena)
-                string_arena = std::make_unique<ArenaWithFreeLists>();
-            break;
+            aggregated_column->insertFrom(*fetched_column, state.getFetchedColumnIndex());
         }
     }
 
-    return attr;
+    return aggregated_columns;
 }
 
-void CacheDictionary::setDefaultAttributeValue(Attribute & attribute, const Key idx) const
+template <DictionaryKeyType dictionary_key_type>
+MutableColumns CacheDictionary<dictionary_key_type>::aggregateColumns(
+        const PaddedPODArray<KeyType> & keys,
+        const DictionaryStorageFetchRequest & request,
+        const MutableColumns & fetched_columns_from_storage,
+        const PaddedPODArray<KeyState> & key_index_to_fetched_columns_from_storage_result,
+        const MutableColumns & fetched_columns_during_update,
+        const HashMap<KeyType, size_t> & found_keys_to_fetched_columns_during_update_index)
 {
-    switch (attribute.type)
-    {
-        /* Macro argument should be enclosed in parentheses, but if do so we cannot initialize \
-        * NearestFieldType which takes TYPE as a template parameter.  */
-#define DISPATCH(TYPE)\
-        case AttributeUnderlyingType::ut##TYPE:\
-            std::get<ContainerPtrType<TYPE>>(attribute.arrays)[idx] = std::get<TYPE>(attribute.null_value); /* NOLINT(bugprone-macro-parentheses) */ \
-            break;
-        DISPATCH(UInt8)
-        DISPATCH(UInt16)
-        DISPATCH(UInt32)
-        DISPATCH(UInt64)
-        DISPATCH(UInt128)
-        DISPATCH(Int8)
-        DISPATCH(Int16)
-        DISPATCH(Int32)
-        DISPATCH(Int64)
-        DISPATCH(Decimal32)
-        DISPATCH(Decimal64)
-        DISPATCH(Decimal128)
-        DISPATCH(Float32)
-        DISPATCH(Float64)
-#undef DISPATCH
-        case AttributeUnderlyingType::utString:
-        {
-            const auto & null_value_ref = std::get<String>(attribute.null_value);
-            auto & string_ref = std::get<ContainerPtrType<StringRef>>(attribute.arrays)[idx];
-
-            if (string_ref.data != null_value_ref.data())
-            {
-                if (string_ref.data)
-                    string_arena->free(const_cast<char *>(string_ref.data), string_ref.size);
+    /**
+    * Aggregation of columns fetched from storage and from source during update.
+    * If key was found in storage add it to result.
+    * If key was found in source during update add it to result.
+    * If key was not found in storage or in source during update add default value.
+    */
 
-                string_ref = StringRef{null_value_ref};
-            }
+    MutableColumns aggregated_columns = request.makeAttributesResultColumns();
 
-            break;
-        }
-    }
-}
-
-void CacheDictionary::setAttributeValue(Attribute & attribute, const Key idx, const Field & value) const
-{
-    switch (attribute.type)
+    for (size_t fetch_request_index = 0; fetch_request_index < request.attributesSize(); ++fetch_request_index)
     {
-        case AttributeUnderlyingType::utUInt8:
-            std::get<ContainerPtrType<UInt8>>(attribute.arrays)[idx] = value.get<UInt64>();
-            break;
-        case AttributeUnderlyingType::utUInt16:
-            std::get<ContainerPtrType<UInt16>>(attribute.arrays)[idx] = value.get<UInt64>();
-            break;
-        case AttributeUnderlyingType::utUInt32:
-            std::get<ContainerPtrType<UInt32>>(attribute.arrays)[idx] = value.get<UInt64>();
-            break;
-        case AttributeUnderlyingType::utUInt64:
-            std::get<ContainerPtrType<UInt64>>(attribute.arrays)[idx] = value.get<UInt64>();
-            break;
-        case AttributeUnderlyingType::utUInt128:
-            std::get<ContainerPtrType<UInt128>>(attribute.arrays)[idx] = value.get<UInt128>();
-            break;
-        case AttributeUnderlyingType::utInt8:
-            std::get<ContainerPtrType<Int8>>(attribute.arrays)[idx] = value.get<Int64>();
-            break;
-        case AttributeUnderlyingType::utInt16:
-            std::get<ContainerPtrType<Int16>>(attribute.arrays)[idx] = value.get<Int64>();
-            break;
-        case AttributeUnderlyingType::utInt32:
-            std::get<ContainerPtrType<Int32>>(attribute.arrays)[idx] = value.get<Int64>();
-            break;
-        case AttributeUnderlyingType::utInt64:
-            std::get<ContainerPtrType<Int64>>(attribute.arrays)[idx] = value.get<Int64>();
-            break;
-        case AttributeUnderlyingType::utFloat32:
-            std::get<ContainerPtrType<Float32>>(attribute.arrays)[idx] = value.get<Float64>();
-            break;
-        case AttributeUnderlyingType::utFloat64:
-            std::get<ContainerPtrType<Float64>>(attribute.arrays)[idx] = value.get<Float64>();
-            break;
-        case AttributeUnderlyingType::utDecimal32:
-            std::get<ContainerPtrType<Decimal32>>(attribute.arrays)[idx] = value.get<Decimal32>();
-            break;
-        case AttributeUnderlyingType::utDecimal64:
-            std::get<ContainerPtrType<Decimal64>>(attribute.arrays)[idx] = value.get<Decimal64>();
-            break;
-        case AttributeUnderlyingType::utDecimal128:
-            std::get<ContainerPtrType<Decimal128>>(attribute.arrays)[idx] = value.get<Decimal128>();
-            break;
+        if (!request.shouldFillResultColumnWithIndex(fetch_request_index))
+            continue;
+
+        const auto & aggregated_column = aggregated_columns[fetch_request_index];
+        const auto & fetched_column_from_storage = fetched_columns_from_storage[fetch_request_index];
+        const auto & fetched_column_during_update = fetched_columns_during_update[fetch_request_index];
+        const auto & default_value_provider = request.defaultValueProviderAtIndex(fetch_request_index);
 
-        case AttributeUnderlyingType::utString:
+        for (size_t key_index = 0; key_index < keys.size(); ++key_index)
         {
-            const auto & string = value.get<String>();
-            auto & string_ref = std::get<ContainerPtrType<StringRef>>(attribute.arrays)[idx];
-            const auto & null_value_ref = std::get<String>(attribute.null_value);
+            auto key = keys[key_index];
 
-            /// free memory unless it points to a null_value
-            if (string_ref.data && string_ref.data != null_value_ref.data())
-                string_arena->free(const_cast<char *>(string_ref.data), string_ref.size);
+            auto key_state_from_storage = key_index_to_fetched_columns_from_storage_result[key_index];
+            if (key_state_from_storage.isFound())
+            {
+                /// Check and insert value if key was fetched from cache
+                aggregated_column->insertFrom(*fetched_column_from_storage, key_state_from_storage.getFetchedColumnIndex());
+                continue;
+            }
 
-            const auto str_size = string.size();
-            if (str_size != 0)
+            /// Check and insert value if key was not in cache and was fetched during update
+            const auto * find_iterator_in_fetch_during_update = found_keys_to_fetched_columns_during_update_index.find(key);
+            if (find_iterator_in_fetch_during_update)
             {
-                auto * string_ptr = string_arena->alloc(str_size + 1);
-                std::copy(string.data(), string.data() + str_size + 1, string_ptr);
-                string_ref = StringRef{string_ptr, str_size};
+                aggregated_column->insertFrom(*fetched_column_during_update, find_iterator_in_fetch_during_update->getMapped());
+                continue;
             }
-            else
-                string_ref = {};
 
-            break;
+            /// Insert default value
+            aggregated_column->insert(default_value_provider.getDefaultValue(key_index));
         }
     }
-}
-
-CacheDictionary::Attribute & CacheDictionary::getAttribute(const std::string & attribute_name) const
-{
-    const size_t attr_index = getAttributeIndex(attribute_name);
-    return attributes[attr_index];
-}
-
-size_t CacheDictionary::getAttributeIndex(const std::string & attribute_name) const
-{
-    const auto it = attribute_index_by_name.find(attribute_name);
-    if (it == std::end(attribute_index_by_name))
-        throw Exception{full_name + ": no such attribute '" + attribute_name + "'", ErrorCodes::BAD_ARGUMENTS};
-
-    return it->second;
-}
-
-bool CacheDictionary::isEmptyCell(const UInt64 idx) const
-{
-    return (idx != zero_cell_idx && cells[idx].id == 0) || (cells[idx].deadline == time_point_t());
-}
 
-
-PaddedPODArray<CacheDictionary::Key> CacheDictionary::getCachedIds() const
-{
-    const ProfilingScopedReadRWLock read_lock{rw_lock, ProfileEvents::DictCacheLockReadNs};
-
-    PaddedPODArray<Key> array;
-    for (size_t idx = 0; idx < cells.size(); ++idx)
-    {
-        auto & cell = cells[idx];
-        if (!isEmptyCell(idx) && !cells[idx].isDefault())
-            array.push_back(cell.id);
-    }
-    return array;
+    return aggregated_columns;
 }
 
-BlockInputStreamPtr CacheDictionary::getBlockInputStream(const Names & column_names, size_t max_block_size) const
+template <DictionaryKeyType dictionary_key_type>
+BlockInputStreamPtr CacheDictionary<dictionary_key_type>::getBlockInputStream(const Names & column_names, size_t max_block_size) const
 {
     using BlockInputStreamType = DictionaryBlockInputStream<Key>;
-    return std::make_shared<BlockInputStreamType>(shared_from_this(), max_block_size, getCachedIds(), column_names);
-}
-
-std::exception_ptr CacheDictionary::getLastException() const
-{
-    const ProfilingScopedReadRWLock read_lock{rw_lock, ProfileEvents::DictCacheLockReadNs};
-    return last_exception;
-}
-
-void registerDictionaryCache(DictionaryFactory & factory)
-{
-    auto create_layout = [=](const std::string & full_name,
-                             const DictionaryStructure & dict_struct,
-                             const Poco::Util::AbstractConfiguration & config,
-                             const std::string & config_prefix,
-                             DictionarySourcePtr source_ptr) -> DictionaryPtr
-    {
-        if (dict_struct.key)
-            throw Exception{"'key' is not supported for dictionary of layout 'cache'",
-                            ErrorCodes::UNSUPPORTED_METHOD};
-
-        if (dict_struct.range_min || dict_struct.range_max)
-            throw Exception{full_name
-                                + ": elements .structure.range_min and .structure.range_max should be defined only "
-                                  "for a dictionary of layout 'range_hashed'",
-                            ErrorCodes::BAD_ARGUMENTS};
-        const auto & layout_prefix = config_prefix + ".layout";
-
-        const size_t size = config.getUInt64(layout_prefix + ".cache.size_in_cells");
-        if (size == 0)
-            throw Exception{full_name + ": dictionary of layout 'cache' cannot have 0 cells",
-                            ErrorCodes::TOO_SMALL_BUFFER_SIZE};
-
-        const bool require_nonempty = config.getBool(config_prefix + ".require_nonempty", false);
-        if (require_nonempty)
-            throw Exception{full_name + ": dictionary of layout 'cache' cannot have 'require_nonempty' attribute set",
-                            ErrorCodes::BAD_ARGUMENTS};
-
-        const auto dict_id = StorageID::fromDictionaryConfig(config, config_prefix);
-        const DictionaryLifetime dict_lifetime{config, config_prefix + ".lifetime"};
-
-        const size_t strict_max_lifetime_seconds =
-                config.getUInt64(layout_prefix + ".cache.strict_max_lifetime_seconds", static_cast<size_t>(dict_lifetime.max_sec));
-
-        const size_t max_update_queue_size =
-                config.getUInt64(layout_prefix + ".cache.max_update_queue_size", 100000);
-        if (max_update_queue_size == 0)
-            throw Exception{full_name + ": dictionary of layout 'cache' cannot have empty update queue of size 0",
-                            ErrorCodes::TOO_SMALL_BUFFER_SIZE};
-
-        const bool allow_read_expired_keys =
-                config.getBool(layout_prefix + ".cache.allow_read_expired_keys", false);
-
-        const size_t update_queue_push_timeout_milliseconds =
-                config.getUInt64(layout_prefix + ".cache.update_queue_push_timeout_milliseconds", 10);
-        if (update_queue_push_timeout_milliseconds < 10)
-            throw Exception{full_name + ": dictionary of layout 'cache' have too little update_queue_push_timeout",
-                            ErrorCodes::BAD_ARGUMENTS};
-
-        const size_t query_wait_timeout_milliseconds =
-                config.getUInt64(layout_prefix + ".cache.query_wait_timeout_milliseconds", 60000);
-
-        const size_t max_threads_for_updates =
-                config.getUInt64(layout_prefix + ".max_threads_for_updates", 4);
-        if (max_threads_for_updates == 0)
-            throw Exception{full_name + ": dictionary of layout 'cache' cannot have zero threads for updates.",
-                            ErrorCodes::BAD_ARGUMENTS};
-
-        return std::make_unique<CacheDictionary>(
-                dict_id,
-                dict_struct,
-                std::move(source_ptr),
-                dict_lifetime,
-                strict_max_lifetime_seconds,
-                size,
-                allow_read_expired_keys,
-                max_update_queue_size,
-                update_queue_push_timeout_milliseconds,
-                query_wait_timeout_milliseconds,
-                max_threads_for_updates);
-    };
-    factory.registerLayout("cache", create_layout, false);
-}
+    std::shared_ptr<BlockInputStreamType> stream;
 
-void CacheDictionary::updateThreadFunction()
-{
-    setThreadName("AsyncUpdater");
-    while (!finished)
     {
-        UpdateUnitPtr popped;
-        update_queue.pop(popped);
-
-        if (finished)
-            break;
-
-        try
-        {
-            /// Update a bunch of ids.
-            update(popped);
+        /// Write lock on storage
+        const ProfilingScopedWriteRWLock write_lock{rw_lock, ProfileEvents::DictCacheLockWriteNs};
 
-            /// Notify thread about finished updating the bunch of ids
-            /// where their own ids were included.
-            std::unique_lock<std::mutex> lock(update_mutex);
-
-            popped->is_done = true;
-            is_update_finished.notify_all();
-        }
-        catch (...)
+        if constexpr (dictionary_key_type == DictionaryKeyType::simple)
+            stream = std::make_shared<BlockInputStreamType>(shared_from_this(), max_block_size, cache_storage_ptr->getCachedSimpleKeys(), column_names);
+        else
         {
-            std::unique_lock<std::mutex> lock(update_mutex);
-
-            popped->current_exception = std::current_exception();
-            is_update_finished.notify_all();
+            auto keys = cache_storage_ptr->getCachedComplexKeys();
+            stream = std::make_shared<BlockInputStreamType>(shared_from_this(), max_block_size, keys, column_names);
         }
     }
-}
 
-void CacheDictionary::waitForCurrentUpdateFinish(UpdateUnitPtr & update_unit_ptr) const
-{
-    std::unique_lock<std::mutex> update_lock(update_mutex);
-
-    bool result = is_update_finished.wait_for(
-            update_lock,
-            std::chrono::milliseconds(query_wait_timeout_milliseconds),
-            [&] { return update_unit_ptr->is_done || update_unit_ptr->current_exception; });
-
-    if (!result)
-    {
-        throw DB::Exception(ErrorCodes::TIMEOUT_EXCEEDED,
-                            "Dictionary {} source seems unavailable, because {}ms timeout exceeded.",
-                            getDictionaryID().getNameForLogs(), toString(query_wait_timeout_milliseconds));
-    }
+    return stream;
+}
+
+template <DictionaryKeyType dictionary_key_type>
+void CacheDictionary<dictionary_key_type>::update(CacheDictionaryUpdateUnitPtr<dictionary_key_type> update_unit_ptr)
+{
+    /**
+    * Update has following flow.
+    * 1. Filter only necessary keys to request, keys that are expired or not found.
+    * And create not_found_keys hash_set including each requested key.
+    * In case of simple_keys we need to fill requested_keys_vector with requested value key.
+    * In case of complex_keys we need to fill requested_complex_key_rows with requested row.
+    * 2. Create stream from source with necessary keys to request using method for simple or complex keys.
+    * 3. Create fetched columns during update variable. This columns will aggregate columns that we fetch from source.
+    * 4. When block is fetched from source. Split it into keys columns and attributes columns.
+    * Insert attributes columns into associated fetched columns during update.
+    * Create KeysExtractor and extract keys from keys columns.
+    * Update map of requested found key to fetched column index.
+    * Remove found key from not_found_keys.
+    * 5. Add aggregated columns during update into storage.
+    * 6. Add not found keys as default into storage.
+    */
+    CurrentMetrics::Increment metric_increment{CurrentMetrics::DictCacheRequests};
 
+    size_t found_keys_size = 0;
 
-    if (update_unit_ptr->current_exception)
-    {
-        // Don't just rethrow it, because sharing the same exception object
-        // between multiple threads can lead to weird effects if they decide to
-        // modify it, for example, by adding some error context.
-        try
-        {
-            std::rethrow_exception(update_unit_ptr->current_exception);
-        }
-        catch (...)
-        {
-            throw DB::Exception(ErrorCodes::CACHE_DICTIONARY_UPDATE_FAIL,
-                "Update failed for dictionary '{}': {}",
-                getDictionaryID().getNameForLogs(),
-                getCurrentExceptionMessage(true /*with stack trace*/,
-                    true /*check embedded stack trace*/));
-        }
-    }
-}
+    DictionaryKeysExtractor<dictionary_key_type> requested_keys_extractor(update_unit_ptr->key_columns, update_unit_ptr->complex_key_arena);
+    const auto & requested_keys = requested_keys_extractor.getKeys();
 
-void CacheDictionary::tryPushToUpdateQueueOrThrow(UpdateUnitPtr & update_unit_ptr) const
-{
-    if (!update_queue.tryPush(update_unit_ptr, update_queue_push_timeout_milliseconds))
-        throw DB::Exception(ErrorCodes::CACHE_DICTIONARY_UPDATE_FAIL,
-                "Cannot push to internal update queue in dictionary {}. "
-                "Timelimit of {} ms. exceeded. Current queue size is {}",
-                getDictionaryID().getNameForLogs(), std::to_string(update_queue_push_timeout_milliseconds),
-                std::to_string(update_queue.size()));
-}
+    HashSet<KeyType> not_found_keys;
 
+    std::vector<UInt64> requested_keys_vector;
+    std::vector<size_t> requested_complex_key_rows;
 
-std::vector<CacheDictionary::AttributeValue> CacheDictionary::getAttributeValuesFromBlockAtPosition(const std::vector<const IColumn *> & column_ptrs, size_t position)
-{
-    std::vector<AttributeValue> answer;
-    answer.reserve(column_ptrs.size());
+    auto & key_index_to_state_from_storage = update_unit_ptr->key_index_to_state;
 
-    for (const auto * pure_column : column_ptrs)
+    for (size_t i = 0; i < key_index_to_state_from_storage.size(); ++i)
     {
-#define DISPATCH(TYPE) \
-        if (const auto * column = typeid_cast<const Column##TYPE *>(pure_column)) { \
-            answer.emplace_back(column->getElement(position)); \
-            continue; \
-        }
-        DISPATCH(UInt8)
-        DISPATCH(UInt16)
-        DISPATCH(UInt32)
-        DISPATCH(UInt64)
-        DISPATCH(UInt128)
-        DISPATCH(Int8)
-        DISPATCH(Int16)
-        DISPATCH(Int32)
-        DISPATCH(Int64)
-        DISPATCH(Decimal<Decimal32>)
-        DISPATCH(Decimal<Decimal64>)
-        DISPATCH(Decimal<Decimal128>)
-        DISPATCH(Float32)
-        DISPATCH(Float64)
-#undef DISPATCH
-        if (const auto * column = typeid_cast<const ColumnString *>(pure_column))
+        if (key_index_to_state_from_storage[i].isExpired()
+            || key_index_to_state_from_storage[i].isNotFound())
         {
-            answer.emplace_back(column->getDataAt(position).toString());
-            continue;
+            if constexpr (dictionary_key_type == DictionaryKeyType::simple)
+                requested_keys_vector.emplace_back(requested_keys[i]);
+            else
+                requested_complex_key_rows.emplace_back(i);
+
+            auto requested_key = requested_keys[i];
+            not_found_keys.insert(requested_key);
         }
     }
-    return answer;
-}
-
-void CacheDictionary::update(UpdateUnitPtr & update_unit_ptr)
-{
-    CurrentMetrics::Increment metric_increment{CurrentMetrics::DictCacheRequests};
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysRequested, update_unit_ptr->requested_ids.size());
 
-    auto & map_ids = update_unit_ptr->found_ids;
+    size_t requested_keys_size = update_unit_ptr->keys_to_update_size;
+    ProfileEvents::increment(ProfileEvents::DictCacheKeysRequested, requested_keys_size);
 
-    size_t found_num = 0;
+    const auto & fetch_request = update_unit_ptr->request;
 
     const auto now = std::chrono::system_clock::now();
 
@@ -1287,86 +701,77 @@ void CacheDictionary::update(UpdateUnitPtr & update_unit_ptr)
             auto current_source_ptr = getSourceAndUpdateIfNeeded();
 
             Stopwatch watch;
+            BlockInputStreamPtr stream;
 
-            BlockInputStreamPtr stream = current_source_ptr->loadIds(update_unit_ptr->requested_ids);
-            stream->readPrefix();
+            if constexpr (dictionary_key_type == DictionaryKeyType::simple)
+                stream = current_source_ptr->loadIds(requested_keys_vector);
+            else
+                stream = current_source_ptr->loadKeys(update_unit_ptr->key_columns, requested_complex_key_rows);
 
-            while (true)
-            {
-                Block block = stream->read();
-                if (!block)
-                    break;
+            stream->readPrefix();
 
-                const auto * id_column = typeid_cast<const ColumnUInt64 *>(block.safeGetByPosition(0).column.get());
-                if (!id_column)
-                    throw Exception{ErrorCodes::TYPE_MISMATCH,
-                                    "{}: id column has type different from UInt64.", getDictionaryID().getNameForLogs()};
+            size_t skip_keys_size_offset = dict_struct.getKeysSize();
+            PaddedPODArray<KeyType> found_keys_in_source;
 
-                const auto & ids = id_column->getData();
+            Columns fetched_columns_during_update = fetch_request.makeAttributesResultColumnsNonMutable();
 
-                /// cache column pointers
-                const auto column_ptrs = ext::map<std::vector>(
-                        ext::range(0, attributes.size()), [&block](size_t i) { return block.safeGetByPosition(i + 1).column.get(); });
+            while (Block block = stream->read())
+            {
+                Columns key_columns;
+                key_columns.reserve(skip_keys_size_offset);
 
-                found_num += ids.size();
+                auto block_columns = block.getColumns();
 
-                for (const auto i : ext::range(0, ids.size()))
+                /// Split into keys columns and attribute columns
+                for (size_t i = 0; i < skip_keys_size_offset; ++i)
                 {
-                    /// Modifying cache with write lock
-                    ProfilingScopedWriteRWLock write_lock{rw_lock, ProfileEvents::DictCacheLockWriteNs};
-                    const auto id = ids[i];
-
-                    const auto cell_idx = findCellIdxForSet(id);
-                    auto & cell = cells[cell_idx];
-
-                    auto it = map_ids.find(id);
+                    key_columns.emplace_back(*block_columns.begin());
+                    block_columns.erase(block_columns.begin());
+                }
 
-                    /// We have some extra keys from source. Won't add them to cache.
-                    if (it == map_ids.end())
-                        continue;
+                DictionaryKeysExtractor<dictionary_key_type> keys_extractor(key_columns, update_unit_ptr->complex_key_arena);
+                const auto & keys_extracted_from_block = keys_extractor.getKeys();
 
-                    auto & all_attributes = it->second;
-                    all_attributes.found = true;
-                    all_attributes.values = getAttributeValuesFromBlockAtPosition(column_ptrs, i);
+                for (size_t index_of_attribute = 0; index_of_attribute < fetched_columns_during_update.size(); ++index_of_attribute)
+                {
+                    auto & column_to_update = fetched_columns_during_update[index_of_attribute];
+                    auto column = block.safeGetByPosition(skip_keys_size_offset + index_of_attribute).column;
+                    column_to_update->assumeMutable()->insertRangeFrom(*column, 0, keys_extracted_from_block.size());
+                }
 
-                    for (const auto attribute_idx : ext::range(0, attributes.size()))
-                    {
-                        const auto & attribute_column = *column_ptrs[attribute_idx];
-                        auto & attribute = attributes[attribute_idx];
+                for (size_t i = 0; i < keys_extracted_from_block.size(); ++i)
+                {
+                    auto fetched_key_from_source = keys_extracted_from_block[i];
+                    not_found_keys.erase(fetched_key_from_source);
+                    update_unit_ptr->requested_keys_to_fetched_columns_during_update_index[fetched_key_from_source] = found_keys_size;
+                    found_keys_in_source.emplace_back(fetched_key_from_source);
+                    ++found_keys_size;
+                }
+            }
 
-                        setAttributeValue(attribute, cell_idx, attribute_column[i]);
-                    }
+            PaddedPODArray<KeyType> not_found_keys_in_source;
+            not_found_keys_in_source.reserve(not_found_keys.size());
 
-                    /// if cell id is zero and zero does not map to this cell, then the cell is unused
-                    if (cell.id == 0 && cell_idx != zero_cell_idx)
-                        element_count.fetch_add(1, std::memory_order_relaxed);
+            for (auto & cell : not_found_keys)
+                not_found_keys_in_source.emplace_back(cell.getKey());
 
-                    cell.id = id;
-                    setLifetime(cell, now);
-                }
-            }
+            auto & update_unit_ptr_mutable_columns = update_unit_ptr->fetched_columns_during_update;
+            for (const auto & fetched_column : fetched_columns_during_update)
+                update_unit_ptr_mutable_columns.emplace_back(fetched_column->assumeMutable());
 
             stream->readSuffix();
 
-            /// Lock for cache modification
-            ProfilingScopedWriteRWLock write_lock{rw_lock, ProfileEvents::DictCacheLockWriteNs};
-
-            for (auto & [key, value] : update_unit_ptr->found_ids)
             {
-                if (!value.found)
-                {
-                    auto cell_idx = findCellIdxForSet(key);
-                    auto & cell = cells[cell_idx];
-                    cell.id = key;
-                    setLifetime(cell, now);
-                    cell.setDefault();
-                }
+                /// Lock for cache modification
+                ProfilingScopedWriteRWLock write_lock{rw_lock, ProfileEvents::DictCacheLockWriteNs};
+                cache_storage_ptr->insertColumnsForKeys(found_keys_in_source, fetched_columns_during_update);
+                cache_storage_ptr->insertDefaultKeys(not_found_keys_in_source);
+
+                error_count = 0;
+                last_exception = std::exception_ptr{};
+                backoff_end_time = std::chrono::system_clock::time_point{};
             }
 
-            error_count = 0;
-            last_exception = std::exception_ptr{};
-            backoff_end_time = std::chrono::system_clock::time_point{};
-
             ProfileEvents::increment(ProfileEvents::DictCacheRequestTimeNs, watch.elapsed());
         }
         catch (...)
@@ -1394,10 +799,9 @@ void CacheDictionary::update(UpdateUnitPtr & update_unit_ptr)
             }
         }
 
-
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysRequestedMiss, update_unit_ptr->requested_ids.size() - found_num);
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysRequestedFound, found_num);
-    ProfileEvents::increment(ProfileEvents::DictCacheRequests);
+        ProfileEvents::increment(ProfileEvents::DictCacheKeysRequestedMiss, requested_keys_size - found_keys_size);
+        ProfileEvents::increment(ProfileEvents::DictCacheKeysRequestedFound, found_keys_size);
+        ProfileEvents::increment(ProfileEvents::DictCacheRequests);
     }
     else
     {
@@ -1409,4 +813,7 @@ void CacheDictionary::update(UpdateUnitPtr & update_unit_ptr)
     }
 }
 
+template class CacheDictionary<DictionaryKeyType::simple>;
+template class CacheDictionary<DictionaryKeyType::complex>;
+
 }
diff --git a/src/Dictionaries/CacheDictionary.h b/src/Dictionaries/CacheDictionary.h
index 35d38f03cbe3..1192db737370 100644
--- a/src/Dictionaries/CacheDictionary.h
+++ b/src/Dictionaries/CacheDictionary.h
@@ -3,72 +3,76 @@
 #include <atomic>
 #include <chrono>
 #include <cmath>
-#include <map>
 #include <mutex>
 #include <shared_mutex>
 #include <utility>
-#include <variant>
 #include <vector>
+
+#include <pcg_random.hpp>
+
 #include <common/logger_useful.h>
-#include <Columns/ColumnDecimal.h>
-#include <Columns/ColumnString.h>
+
+#include <Common/randomSeed.h>
 #include <Common/ThreadPool.h>
-#include <Common/ConcurrentBoundedQueue.h>
-#include <pcg_random.hpp>
-#include <Common/ArenaWithFreeLists.h>
 #include <Common/CurrentMetrics.h>
-#include <ext/bit_cast.h>
-#include "DictionaryStructure.h"
-#include "IDictionary.h"
-#include "IDictionarySource.h"
-#include "DictionaryHelpers.h"
-
-namespace CurrentMetrics
-{
-    extern const Metric CacheDictionaryUpdateQueueBatches;
-    extern const Metric CacheDictionaryUpdateQueueKeys;
-}
 
+#include <Dictionaries/IDictionary.h>
+#include <Dictionaries/ICacheDictionaryStorage.h>
+#include <Dictionaries/DictionaryStructure.h>
+#include <Dictionaries/IDictionarySource.h>
+#include <Dictionaries/DictionaryHelpers.h>
+#include <Dictionaries/CacheDictionaryUpdateQueue.h>
 
 namespace DB
 {
+/** CacheDictionary store keys in cache storage and can asynchronous and synchronous updates during keys fetch.
 
-namespace ErrorCodes
-{
-}
+    If keys are not found in storage during fetch, dictionary start update operation with update queue.
+
+    During update operation necessary keys are fetched from source and inserted into storage.
+
+    After that data from storage and source are aggregated and returned to the client.
 
-/*
- *
- * This dictionary is stored in a cache that has a fixed number of cells.
- * These cells contain frequently used elements.
- * When searching for a dictionary, the cache is searched first and special heuristic is used:
- * while looking for the key, we take a look only at max_collision_length elements.
- * So, our cache is not perfect. It has errors like "the key is in cache, but the cache says that it does not".
- * And in this case we simply ask external source for the key which is faster.
- * You have to keep this logic in mind.
- * */
+    Typical flow:
+
+    1. Client request data during for example getColumn function call.
+    2. CacheDictionary request data from storage and if all data is found in storage it returns result to client.
+    3. If some data is not in storage cache dictionary try to perform update.
+
+    If all keys are just expired and allow_read_expired_keys option is set dictionary starts asynchronous update and
+    return result to client.
+
+    If there are not found keys dictionary start synchronous update and wait for result.
+
+    4. After getting result from synchronous update dictionary aggregates data that was previously fetched from
+    storage and data that was fetched during update and return result to client.
+ */
+template <DictionaryKeyType dictionary_key_type>
 class CacheDictionary final : public IDictionary
 {
 public:
+    using KeyType = std::conditional_t<dictionary_key_type == DictionaryKeyType::simple, UInt64, StringRef>;
+    static_assert(dictionary_key_type != DictionaryKeyType::range, "Range key type is not supported by cache dictionary");
+
     CacheDictionary(
         const StorageID & dict_id_,
         const DictionaryStructure & dict_struct_,
         DictionarySourcePtr source_ptr_,
+        CacheDictionaryStoragePtr cache_storage_ptr_,
+        CacheDictionaryUpdateQueueConfiguration update_queue_configuration_,
         DictionaryLifetime dict_lifetime_,
-        size_t strict_max_lifetime_seconds,
-        size_t size_,
-        bool allow_read_expired_keys_,
-        size_t max_update_queue_size_,
-        size_t update_queue_push_timeout_milliseconds_,
-        size_t query_wait_timeout_milliseconds,
-        size_t max_threads_for_updates);
+        bool allow_read_expired_keys_);
 
     ~CacheDictionary() override;
 
-    std::string getTypeName() const override { return "Cache"; }
+    std::string getTypeName() const override { return cache_storage_ptr->getName(); }
+
+    size_t getElementCount() const override;
 
     size_t getBytesAllocated() const override;
 
+    double getLoadFactor() const override;
+
     size_t getQueryCount() const override { return query_count.load(std::memory_order_relaxed); }
 
     double getHitRate() const override
@@ -76,10 +80,6 @@ class CacheDictionary final : public IDictionary
         return static_cast<double>(hit_count.load(std::memory_order_acquire)) / query_count.load(std::memory_order_relaxed);
     }
 
-    size_t getElementCount() const override { return element_count.load(std::memory_order_relaxed); }
-
-    double getLoadFactor() const override { return static_cast<double>(element_count.load(std::memory_order_relaxed)) / size; }
-
     bool supportUpdates() const override { return false; }
 
     std::shared_ptr<const IExternalLoadable> clone() const override
@@ -88,14 +88,10 @@ class CacheDictionary final : public IDictionary
                 getDictionaryID(),
                 dict_struct,
                 getSourceAndUpdateIfNeeded()->clone(),
+                cache_storage_ptr,
+                update_queue.getConfiguration(),
                 dict_lifetime,
-                strict_max_lifetime_seconds,
-                size,
-                allow_read_expired_keys,
-                max_update_queue_size,
-                update_queue_push_timeout_milliseconds,
-                query_wait_timeout_milliseconds,
-                max_threads_for_updates);
+                allow_read_expired_keys);
     }
 
     const IDictionarySource * getSource() const override;
@@ -106,133 +102,78 @@ class CacheDictionary final : public IDictionary
 
     bool isInjective(const std::string & attribute_name) const override
     {
-        return dict_struct.attributes[&getAttribute(attribute_name) - attributes.data()].injective;
+        return dict_struct.getAttribute(attribute_name).injective;
     }
 
-    bool hasHierarchy() const override { return hierarchical_attribute; }
-
-    void toParent(const PaddedPODArray<Key> & ids, PaddedPODArray<Key> & out) const override;
-
-    void isInVectorVector(
-        const PaddedPODArray<Key> & child_ids, const PaddedPODArray<Key> & ancestor_ids, PaddedPODArray<UInt8> & out) const override;
-    void isInVectorConstant(const PaddedPODArray<Key> & child_ids, const Key ancestor_id, PaddedPODArray<UInt8> & out) const override;
-    void isInConstantVector(const Key child_id, const PaddedPODArray<Key> & ancestor_ids, PaddedPODArray<UInt8> & out) const override;
-
-    std::exception_ptr getLastException() const override;
-
-    DictionaryKeyType getKeyType() const override { return DictionaryKeyType::simple; }
+    DictionaryKeyType getKeyType() const override
+    {
+        return dictionary_key_type == DictionaryKeyType::simple ? DictionaryKeyType::simple : DictionaryKeyType::complex;
+    }
 
     ColumnPtr getColumn(
         const std::string& attribute_name,
         const DataTypePtr & result_type,
         const Columns & key_columns,
         const DataTypes & key_types,
-        const ColumnPtr default_values_column) const override;
+        const ColumnPtr & default_values_column) const override;
 
-    ColumnUInt8::Ptr hasKeys(const Columns & key_columns, const DataTypes & key_types) const override;
+    Columns getColumns(
+        const Strings & attribute_names,
+        const DataTypes & result_types,
+        const Columns & key_columns,
+        const DataTypes & key_types,
+        const Columns & default_values_columns) const override;
 
-    template <typename T>
-    using ResultArrayType = std::conditional_t<IsDecimalNumber<T>, DecimalPaddedPODArray<T>, PaddedPODArray<T>>;
+    ColumnUInt8::Ptr hasKeys(const Columns & key_columns, const DataTypes & key_types) const override;
 
     BlockInputStreamPtr getBlockInputStream(const Names & column_names, size_t max_block_size) const override;
 
+    std::exception_ptr getLastException() const override;
+
+    bool hasHierarchy() const override { return dictionary_key_type == DictionaryKeyType::simple && hierarchical_attribute; }
+
+    void toParent(const PaddedPODArray<UInt64> & ids, PaddedPODArray<UInt64> & out) const override;
+
+    void isInVectorVector(
+        const PaddedPODArray<UInt64> & child_ids,
+        const PaddedPODArray<UInt64> & ancestor_ids,
+        PaddedPODArray<UInt8> & out) const override;
+
+    void isInVectorConstant(
+        const PaddedPODArray<UInt64> & child_ids,
+        const UInt64 ancestor_id, PaddedPODArray<UInt8> & out) const override;
+
+    void isInConstantVector(
+        const UInt64 child_id,
+        const PaddedPODArray<UInt64> & ancestor_ids,
+        PaddedPODArray<UInt8> & out) const override;
+
 private:
-    template <typename Value>
-    using ContainerType = Value[];
-    template <typename Value>
-    using ContainerPtrType = std::unique_ptr<ContainerType<Value>>;
+    using FetchResult = std::conditional_t<dictionary_key_type == DictionaryKeyType::simple, SimpleKeysStorageFetchResult, ComplexKeysStorageFetchResult>;
 
-    using time_point_t = std::chrono::system_clock::time_point;
+    Columns getColumnsImpl(
+        const Strings & attribute_names,
+        const Columns & key_columns,
+        const PaddedPODArray<KeyType> & keys,
+        const Columns & default_values_columns) const;
 
-    struct CellMetadata final
-    {
-        UInt64 id;
-        time_point_t deadline;
-        bool is_default{false};
-
-        time_point_t expiresAt() const { return deadline; }
-        void setExpiresAt(const time_point_t & t) { deadline = t; is_default = false; }
-        bool isDefault() const { return is_default; }
-        void setDefault() { is_default = true; }
-    };
-
-    using AttributeValue = std::variant<
-        UInt8, UInt16, UInt32, UInt64, UInt128,
-        Int8, Int16, Int32, Int64,
-        Decimal32, Decimal64, Decimal128,
-        Float32, Float64, String>;
-
-    struct AttributeValuesForKey
-    {
-        bool found{false};
-        std::vector<AttributeValue> values;
+    static MutableColumns aggregateColumnsInOrderOfKeys(
+        const PaddedPODArray<KeyType> & keys,
+        const DictionaryStorageFetchRequest & request,
+        const MutableColumns & fetched_columns,
+        const PaddedPODArray<KeyState> & key_index_to_state);
 
-        std::string dump();
-    };
+    static MutableColumns aggregateColumns(
+        const PaddedPODArray<KeyType> & keys,
+        const DictionaryStorageFetchRequest & request,
+        const MutableColumns & fetched_columns_from_storage,
+        const PaddedPODArray<KeyState> & key_index_to_fetched_columns_from_storage_result,
+        const MutableColumns & fetched_columns_during_update,
+        const HashMap<KeyType, size_t> & found_keys_to_fetched_columns_during_update_index);
 
-    using FoundValuesForKeys = std::unordered_map<Key, AttributeValuesForKey>;
+    void setupHierarchicalAttribute();
 
-    struct Attribute final
-    {
-        AttributeUnderlyingType type;
-        String name;
-        /// Default value for each type. Could be defined in config.
-        AttributeValue null_value;
-        /// We store attribute value for all keys. It is a "row" in a hand-made open addressing hashtable,
-        /// where "column" is key.
-        std::variant<
-            ContainerPtrType<UInt8>,
-            ContainerPtrType<UInt16>,
-            ContainerPtrType<UInt32>,
-            ContainerPtrType<UInt64>,
-            ContainerPtrType<UInt128>,
-            ContainerPtrType<Int8>,
-            ContainerPtrType<Int16>,
-            ContainerPtrType<Int32>,
-            ContainerPtrType<Int64>,
-            ContainerPtrType<Decimal32>,
-            ContainerPtrType<Decimal64>,
-            ContainerPtrType<Decimal128>,
-            ContainerPtrType<Float32>,
-            ContainerPtrType<Float64>,
-            ContainerPtrType<StringRef>>
-            arrays;
-    };
-
-    void createAttributes();
-
-    /* NOLINTNEXTLINE(readability-convert-member-functions-to-static) */
-    Attribute createAttributeWithTypeAndName(const AttributeUnderlyingType type, const String & name, const Field & null_value);
-
-    template <typename AttributeType, typename OutputType, typename DefaultValueExtractor>
-    void getItemsNumberImpl(
-        Attribute & attribute,
-        const PaddedPODArray<Key> & ids,
-        ResultArrayType<OutputType> & out,
-        DefaultValueExtractor & default_value_extractor) const;
-
-    void getItemsString(
-        Attribute & attribute,
-        const PaddedPODArray<Key> & ids,
-        ColumnString * out,
-        DictionaryDefaultValueExtractor<String> & default_value_extractor) const;
-
-    PaddedPODArray<Key> getCachedIds() const;
-
-    bool isEmptyCell(const UInt64 idx) const;
-
-    size_t getCellIdx(const Key id) const;
-
-    void setDefaultAttributeValue(Attribute & attribute, const Key idx) const;
-
-    void setAttributeValue(Attribute & attribute, const Key idx, const Field & value) const;
-
-    static std::vector<AttributeValue> getAttributeValuesFromBlockAtPosition(const std::vector<const IColumn *> & column_ptrs, size_t position);
-
-    Attribute & getAttribute(const std::string & attribute_name) const;
-    size_t getAttributeIndex(const std::string & attribute_name) const;
-
-    using SharedDictionarySourcePtr = std::shared_ptr<IDictionarySource>;
+    void update(CacheDictionaryUpdateUnitPtr<dictionary_key_type> update_unit_ptr);
 
     /// Update dictionary source pointer if required and return it. Thread safe.
     /// MultiVersion is not used here because it works with constant pointers.
@@ -252,47 +193,6 @@ class CacheDictionary final : public IDictionary
         return source_ptr;
     }
 
-    inline void setLifetime(CellMetadata & cell, time_point_t now)
-    {
-        if (dict_lifetime.min_sec != 0 && dict_lifetime.max_sec != 0)
-        {
-            std::uniform_int_distribution<UInt64> distribution{dict_lifetime.min_sec, dict_lifetime.max_sec};
-            cell.setExpiresAt(now + std::chrono::seconds{distribution(rnd_engine)});
-        }
-        else
-        {
-            /// This maybe not obvious, but when we define is this cell is expired or expired permanently, we add strict_max_lifetime_seconds
-            /// to the expiration time. And it overflows pretty well.
-            cell.setExpiresAt(std::chrono::time_point<std::chrono::system_clock>::max() - 2 * std::chrono::seconds(strict_max_lifetime_seconds));
-        }
-    }
-
-    inline bool isExpired(time_point_t now, time_point_t deadline) const
-    {
-        return now > deadline;
-    }
-
-    inline bool isExpiredPermanently(time_point_t now, time_point_t deadline) const
-    {
-        return now > deadline + std::chrono::seconds(strict_max_lifetime_seconds);
-    }
-
-    enum class ResultState
-    {
-        NotFound,
-        FoundAndValid,
-        FoundButExpired,
-        /// Here is a gap between there two states in which a key could be read
-        /// with an enabled setting in config enable_read_expired_keys.
-        FoundButExpiredPermanently
-    };
-
-    using FindResult = std::pair<size_t, ResultState>;
-
-    FindResult findCellIdxForGet(const Key & id, const time_point_t now) const;
-
-    size_t findCellIdxForSet(const Key & id) const;
-
     template <typename AncestorType>
     void isInImpl(const PaddedPODArray<Key> & child_ids, const AncestorType & ancestor_ids, PaddedPODArray<UInt8> & out) const;
 
@@ -302,110 +202,34 @@ class CacheDictionary final : public IDictionary
     mutable std::mutex source_mutex;
     mutable SharedDictionarySourcePtr source_ptr;
 
+    CacheDictionaryStoragePtr cache_storage_ptr;
+    mutable CacheDictionaryUpdateQueue<dictionary_key_type> update_queue;
+
     const DictionaryLifetime dict_lifetime;
-    const size_t strict_max_lifetime_seconds;
-    const bool allow_read_expired_keys;
-    const size_t max_update_queue_size;
-    const size_t update_queue_push_timeout_milliseconds;
-    const size_t query_wait_timeout_milliseconds;
-    const size_t max_threads_for_updates;
 
     Poco::Logger * log;
 
+    const bool allow_read_expired_keys;
+
+    mutable pcg64 rnd_engine;
+
     /// This lock is used for the inner cache state update function lock it for
     /// write, when it need to update cache state all other functions just
     /// readers. Surprisingly this lock is also used for last_exception pointer.
     mutable std::shared_mutex rw_lock;
 
-    /// Actual size will be increased to match power of 2
-    const size_t size;
-
-    /// all bits to 1  mask (size - 1) (0b1000 - 1 = 0b111)
-    const size_t size_overlap_mask;
-
-    /// Max tries to find cell, overlapped with mask: if size = 16 and start_cell=10: will try cells: 10,11,12,13,14,15,0,1,2,3
-    static constexpr size_t max_collision_length = 10;
-
-    const size_t zero_cell_idx{getCellIdx(0)};
-    std::map<std::string, size_t> attribute_index_by_name;
-    mutable std::vector<Attribute> attributes;
-    mutable std::vector<CellMetadata> cells;
-    Attribute * hierarchical_attribute = nullptr;
-    std::unique_ptr<ArenaWithFreeLists> string_arena;
+    const DictionaryAttribute * hierarchical_attribute = nullptr;
 
     mutable std::exception_ptr last_exception;
-    mutable std::atomic<size_t> error_count{0};
+    mutable std::atomic<size_t> error_count {0};
     mutable std::atomic<std::chrono::system_clock::time_point> backoff_end_time{std::chrono::system_clock::time_point{}};
 
-    mutable pcg64 rnd_engine;
-
-    mutable size_t bytes_allocated = 0;
-    mutable std::atomic<size_t> element_count{0};
     mutable std::atomic<size_t> hit_count{0};
     mutable std::atomic<size_t> query_count{0};
 
-    /*
-     * How the update goes: we basically have a method like get(keys)->values. Values are cached, so sometimes we
-     * can return them from the cache. For values not in cache, we query them from the source, and add to the
-     * cache. The cache is lossy, so we can't expect it to store all the keys, and we store them separately.
-     * So, there is a map of found keys to all its attributes.
-     */
-    struct UpdateUnit
-    {
-        explicit UpdateUnit(std::vector<Key> && requested_ids_) :
-                requested_ids(std::move(requested_ids_)),
-                alive_keys(CurrentMetrics::CacheDictionaryUpdateQueueKeys, requested_ids.size())
-        {
-            found_ids.reserve(requested_ids.size());
-            for (const auto id : requested_ids)
-                found_ids.insert({id, {}});
-        }
-
-        std::vector<Key> requested_ids;
-        FoundValuesForKeys found_ids;
-
-        std::atomic<bool> is_done{false};
-        std::exception_ptr current_exception{nullptr};
-
-        /// While UpdateUnit is alive, it is accounted in update_queue size.
-        CurrentMetrics::Increment alive_batch{CurrentMetrics::CacheDictionaryUpdateQueueBatches};
-        CurrentMetrics::Increment alive_keys;
-
-        std::string dumpFoundIds();
-    };
-
-    using UpdateUnitPtr = std::shared_ptr<UpdateUnit>;
-    using UpdateQueue = ConcurrentBoundedQueue<UpdateUnitPtr>;
-
-    mutable UpdateQueue update_queue;
-
-    ThreadPool update_pool;
-
-    /*
-     *  Actually, we can divide all requested keys into two 'buckets'. There are only four possible states and they
-     * are described in the table.
-     *
-     * cache_not_found_ids  |0|0|1|1|
-     * cache_expired_ids    |0|1|0|1|
-     *
-     * 0 - if set is empty, 1 - otherwise
-     *
-     * Only if there are no cache_not_found_ids and some cache_expired_ids
-     * (with allow_read_expired_keys setting) we can perform async update.
-     * Otherwise we have no concatenate ids and update them sync.
-     *
-     */
-    void updateThreadFunction();
-    void update(UpdateUnitPtr & update_unit_ptr);
-
-
-    void tryPushToUpdateQueueOrThrow(UpdateUnitPtr & update_unit_ptr) const;
-    void waitForCurrentUpdateFinish(UpdateUnitPtr & update_unit_ptr) const;
-
-    mutable std::mutex update_mutex;
-    mutable std::condition_variable is_update_finished;
-
-    std::atomic<bool> finished{false};
 };
 
+extern template class CacheDictionary<DictionaryKeyType::simple>;
+extern template class CacheDictionary<DictionaryKeyType::complex>;
+
 }
diff --git a/src/Dictionaries/CacheDictionaryStorage.h b/src/Dictionaries/CacheDictionaryStorage.h
new file mode 100644
index 000000000000..cf0b74e8bd26
--- /dev/null
+++ b/src/Dictionaries/CacheDictionaryStorage.h
@@ -0,0 +1,418 @@
+#pragma once
+
+#include <chrono>
+
+#include <pcg_random.hpp>
+
+#include <Common/randomSeed.h>
+#include <Common/Arena.h>
+#include <Common/ArenaWithFreeLists.h>
+#include <Common/HashTable/LRUHashMap.h>
+#include <Dictionaries/DictionaryStructure.h>
+#include <Dictionaries/ICacheDictionaryStorage.h>
+#include <Dictionaries/DictionaryHelpers.h>
+
+namespace DB
+{
+
+namespace ErrorCodes
+{
+    extern const int NOT_IMPLEMENTED;
+}
+
+struct CacheDictionaryStorageConfiguration
+{
+    /// Max size of storage in cells
+    const size_t max_size_in_cells;
+    /// Needed to perform check if cell is expired or not found. Default value is dictionary max lifetime.
+    const size_t strict_max_lifetime_seconds;
+    /// Lifetime of dictionary. Cell deadline is random value between lifetime min and max seconds.
+    const DictionaryLifetime lifetime;
+};
+
+/** Keys are stored in LRUCache and column values are serialized into arena.
+
+    Cell in LRUCache consists of allocated size and place in arena were columns serialized data is stored.
+
+    Columns are serialized by rows.
+
+    When cell is removed from LRUCache data associated with it is also removed from arena.
+
+    In case of complex key we also store key data in arena and it is removed from arena.
+*/
+template <DictionaryKeyType dictionary_key_type>
+class CacheDictionaryStorage final : public ICacheDictionaryStorage
+{
+public:
+    using KeyType = std::conditional_t<dictionary_key_type == DictionaryKeyType::simple, UInt64, StringRef>;
+    static_assert(dictionary_key_type != DictionaryKeyType::range, "Range key type is not supported by CacheDictionaryStorage");
+
+    explicit CacheDictionaryStorage(CacheDictionaryStorageConfiguration & configuration_)
+        : configuration(configuration_)
+        , rnd_engine(randomSeed())
+        , cache(configuration.max_size_in_cells, false, { arena })
+    {
+    }
+
+    bool returnsFetchedColumnsInOrderOfRequestedKeys() const override { return true; }
+
+    String getName() const override
+    {
+        if (dictionary_key_type == DictionaryKeyType::simple)
+            return "Cache";
+        else
+            return "ComplexKeyCache";
+    }
+
+    bool supportsSimpleKeys() const override { return dictionary_key_type == DictionaryKeyType::simple; }
+
+    SimpleKeysStorageFetchResult fetchColumnsForKeys(
+        const PaddedPODArray<UInt64> & keys,
+        const DictionaryStorageFetchRequest & fetch_request) override
+    {
+        if constexpr (dictionary_key_type == DictionaryKeyType::simple)
+        {
+            return fetchColumnsForKeysImpl<SimpleKeysStorageFetchResult>(keys, fetch_request);
+        }
+        else
+            throw Exception("Method fetchColumnsForKeys is not supported for complex key storage", ErrorCodes::NOT_IMPLEMENTED);
+    }
+
+    void insertColumnsForKeys(const PaddedPODArray<UInt64> & keys, Columns columns) override
+    {
+        if constexpr (dictionary_key_type == DictionaryKeyType::simple)
+            insertColumnsForKeysImpl(keys, columns);
+        else
+            throw Exception("Method insertColumnsForKeys is not supported for complex key storage", ErrorCodes::NOT_IMPLEMENTED);
+    }
+
+    void insertDefaultKeys(const PaddedPODArray<UInt64> & keys) override
+    {
+        if constexpr (dictionary_key_type == DictionaryKeyType::simple)
+            insertDefaultKeysImpl(keys);
+        else
+            throw Exception("Method insertDefaultKeysImpl is not supported for complex key storage", ErrorCodes::NOT_IMPLEMENTED);
+    }
+
+    PaddedPODArray<UInt64> getCachedSimpleKeys() const override
+    {
+        if constexpr (dictionary_key_type == DictionaryKeyType::simple)
+            return getCachedKeysImpl();
+        else
+            throw Exception("Method getCachedSimpleKeys is not supported for complex key storage", ErrorCodes::NOT_IMPLEMENTED);
+    }
+
+    bool supportsComplexKeys() const override { return dictionary_key_type == DictionaryKeyType::complex; }
+
+    ComplexKeysStorageFetchResult fetchColumnsForKeys(
+        const PaddedPODArray<StringRef> & keys,
+        const DictionaryStorageFetchRequest & column_fetch_requests) override
+    {
+        if constexpr (dictionary_key_type == DictionaryKeyType::complex)
+        {
+            return fetchColumnsForKeysImpl<ComplexKeysStorageFetchResult>(keys, column_fetch_requests);
+        }
+        else
+            throw Exception("Method fetchColumnsForKeys is not supported for simple key storage", ErrorCodes::NOT_IMPLEMENTED);
+    }
+
+    void insertColumnsForKeys(const PaddedPODArray<StringRef> & keys, Columns columns) override
+    {
+        if constexpr (dictionary_key_type == DictionaryKeyType::complex)
+            insertColumnsForKeysImpl(keys, columns);
+        else
+            throw Exception("Method insertColumnsForKeys is not supported for simple key storage", ErrorCodes::NOT_IMPLEMENTED);
+    }
+
+    void insertDefaultKeys(const PaddedPODArray<StringRef> & keys) override
+    {
+        if constexpr (dictionary_key_type == DictionaryKeyType::complex)
+            insertDefaultKeysImpl(keys);
+        else
+            throw Exception("Method insertDefaultKeysImpl is not supported for simple key storage", ErrorCodes::NOT_IMPLEMENTED);
+    }
+
+    PaddedPODArray<StringRef> getCachedComplexKeys() const override
+    {
+        if constexpr (dictionary_key_type == DictionaryKeyType::complex)
+            return getCachedKeysImpl();
+        else
+            throw Exception("Method getCachedComplexKeys is not supported for simple key storage", ErrorCodes::NOT_IMPLEMENTED);
+    }
+
+    size_t getSize() const override { return cache.size(); }
+
+    size_t getMaxSize() const override { return cache.getMaxSize(); }
+
+    size_t getBytesAllocated() const override { return arena.size() + cache.getSizeInBytes(); }
+
+private:
+
+    template <typename KeysStorageFetchResult>
+    ALWAYS_INLINE KeysStorageFetchResult fetchColumnsForKeysImpl(
+        const PaddedPODArray<KeyType> & keys,
+        const DictionaryStorageFetchRequest & fetch_request)
+    {
+        KeysStorageFetchResult result;
+
+        result.fetched_columns = fetch_request.makeAttributesResultColumns();
+        result.key_index_to_state.resize_fill(keys.size(), {KeyState::not_found});
+
+        const auto now = std::chrono::system_clock::now();
+
+        size_t fetched_columns_index = 0;
+
+        std::chrono::seconds max_lifetime_seconds(configuration.strict_max_lifetime_seconds);
+
+        size_t keys_size = keys.size();
+
+        for (size_t key_index = 0; key_index < keys_size; ++key_index)
+        {
+            auto key = keys[key_index];
+            auto * it = cache.find(key);
+
+            if (it)
+            {
+                /// Columns values for key are serialized in cache now deserialize them
+                const auto & cell = it->getMapped();
+
+                bool has_deadline = cellHasDeadline(cell);
+
+                if (has_deadline && now > cell.deadline + max_lifetime_seconds)
+                {
+                    result.key_index_to_state[key_index] = {KeyState::not_found};
+                    ++result.not_found_keys_size;
+                    continue;
+                }
+                else if (has_deadline && now > cell.deadline)
+                {
+                    result.key_index_to_state[key_index] = {KeyState::expired, fetched_columns_index};
+                    ++result.expired_keys_size;
+                }
+                else
+                {
+                    result.key_index_to_state[key_index] = {KeyState::found, fetched_columns_index};
+                    ++result.found_keys_size;
+                }
+
+                ++fetched_columns_index;
+
+                if (cell.isDefault())
+                {
+                    result.key_index_to_state[key_index].setDefault();
+                    ++result.default_keys_size;
+                    insertDefaultValuesIntoColumns(result.fetched_columns, fetch_request, key_index);
+                }
+                else
+                {
+                    const char * place_for_serialized_columns = cell.place_for_serialized_columns;
+                    deserializeAndInsertIntoColumns(result.fetched_columns, fetch_request, place_for_serialized_columns);
+                }
+            }
+            else
+            {
+                result.key_index_to_state[key_index] = {KeyState::not_found};
+                ++result.not_found_keys_size;
+            }
+        }
+
+        return result;
+    }
+
+    void insertColumnsForKeysImpl(const PaddedPODArray<KeyType> & keys, Columns columns)
+    {
+        Arena temporary_values_pool;
+
+        size_t columns_to_serialize_size = columns.size();
+        PaddedPODArray<StringRef> temporary_column_data(columns_to_serialize_size);
+
+        const auto now = std::chrono::system_clock::now();
+
+        size_t keys_size = keys.size();
+
+        for (size_t key_index = 0; key_index < keys_size; ++key_index)
+        {
+            size_t allocated_size_for_columns = 0;
+            const char * block_start = nullptr;
+
+            auto key = keys[key_index];
+            auto * it = cache.find(key);
+
+            for (size_t column_index = 0; column_index < columns_to_serialize_size; ++column_index)
+            {
+                auto & column = columns[column_index];
+                temporary_column_data[column_index] = column->serializeValueIntoArena(key_index, temporary_values_pool, block_start);
+                allocated_size_for_columns += temporary_column_data[column_index].size;
+            }
+
+            char * place_for_serialized_columns = arena.alloc(allocated_size_for_columns);
+            memcpy(reinterpret_cast<void*>(place_for_serialized_columns), reinterpret_cast<const void*>(block_start), allocated_size_for_columns);
+
+            if (it)
+            {
+                /// Cell exists need to free previous serialized place and update deadline
+                auto & cell = it->getMapped();
+
+                if (cell.place_for_serialized_columns)
+                    arena.free(cell.place_for_serialized_columns, cell.allocated_size_for_columns);
+
+                setCellDeadline(cell, now);
+                cell.allocated_size_for_columns = allocated_size_for_columns;
+                cell.place_for_serialized_columns = place_for_serialized_columns;
+            }
+            else
+            {
+                /// No cell exists so create and put in cache
+                Cell cell;
+
+                setCellDeadline(cell, now);
+                cell.allocated_size_for_columns = allocated_size_for_columns;
+                cell.place_for_serialized_columns = place_for_serialized_columns;
+
+                insertCellInCache(key, cell);
+            }
+
+            temporary_values_pool.rollback(allocated_size_for_columns);
+        }
+    }
+
+    void insertDefaultKeysImpl(const PaddedPODArray<KeyType> & keys)
+    {
+        const auto now = std::chrono::system_clock::now();
+
+        for (auto key : keys)
+        {
+            auto * it = cache.find(key);
+
+            if (it)
+            {
+                auto & cell = it->getMapped();
+
+                setCellDeadline(cell, now);
+
+                if (cell.place_for_serialized_columns)
+                    arena.free(cell.place_for_serialized_columns, cell.allocated_size_for_columns);
+
+                cell.allocated_size_for_columns = 0;
+                cell.place_for_serialized_columns = nullptr;
+            }
+            else
+            {
+                Cell cell;
+
+                setCellDeadline(cell, now);
+                cell.allocated_size_for_columns = 0;
+                cell.place_for_serialized_columns = nullptr;
+
+                insertCellInCache(key, cell);
+            }
+        }
+    }
+
+    PaddedPODArray<KeyType> getCachedKeysImpl() const
+    {
+        PaddedPODArray<KeyType> result;
+        result.reserve(cache.size());
+
+        for (auto & node : cache)
+        {
+            auto & cell = node.getMapped();
+
+            if (cell.isDefault())
+                continue;
+
+            result.emplace_back(node.getKey());
+        }
+
+        return result;
+    }
+
+    using TimePoint = std::chrono::system_clock::time_point;
+
+    struct Cell
+    {
+        TimePoint deadline;
+        size_t allocated_size_for_columns;
+        char * place_for_serialized_columns;
+
+        inline bool isDefault() const { return place_for_serialized_columns == nullptr; }
+        inline void setDefault()
+        {
+            place_for_serialized_columns = nullptr;
+            allocated_size_for_columns = 0;
+        }
+    };
+
+    void insertCellInCache(KeyType & key, const Cell & cell)
+    {
+        if constexpr (dictionary_key_type == DictionaryKeyType::complex)
+        {
+            /// Copy complex key into arena and put in cache
+            size_t key_size = key.size;
+            char * place_for_key = arena.alloc(key_size);
+            memcpy(reinterpret_cast<void *>(place_for_key), reinterpret_cast<const void *>(key.data), key_size);
+            KeyType updated_key{place_for_key, key_size};
+            key = updated_key;
+        }
+
+        cache.insert(key, cell);
+    }
+
+    inline static bool cellHasDeadline(const Cell & cell)
+    {
+        return cell.deadline != std::chrono::system_clock::from_time_t(0);
+    }
+
+    inline void setCellDeadline(Cell & cell, TimePoint now)
+    {
+        if (configuration.lifetime.min_sec == 0 && configuration.lifetime.max_sec == 0)
+        {
+            cell.deadline = std::chrono::system_clock::from_time_t(0);
+            return;
+        }
+
+        size_t min_sec_lifetime = configuration.lifetime.min_sec;
+        size_t max_sec_lifetime = configuration.lifetime.max_sec;
+
+        std::uniform_int_distribution<UInt64> distribution{min_sec_lifetime, max_sec_lifetime};
+        cell.deadline = now + std::chrono::seconds(distribution(rnd_engine));
+    }
+
+    template <typename>
+    friend class ArenaCellDisposer;
+
+    CacheDictionaryStorageConfiguration configuration;
+
+    ArenaWithFreeLists arena;
+
+    pcg64 rnd_engine;
+
+    class ArenaCellDisposer
+    {
+    public:
+        ArenaWithFreeLists & arena;
+
+        template <typename Key, typename Value>
+        void operator()(const Key & key, const Value & value) const
+        {
+            /// In case of complex key we keep it in arena
+            if constexpr (std::is_same_v<Key, StringRef>)
+                arena.free(const_cast<char *>(key.data), key.size);
+
+            if (value.place_for_serialized_columns)
+                arena.free(value.place_for_serialized_columns, value.allocated_size_for_columns);
+        }
+    };
+
+    using SimpleKeyLRUHashMap = LRUHashMap<UInt64, Cell, ArenaCellDisposer>;
+    using ComplexKeyLRUHashMap = LRUHashMapWithSavedHash<StringRef, Cell, ArenaCellDisposer>;
+
+    using CacheLRUHashMap = std::conditional_t<
+        dictionary_key_type == DictionaryKeyType::simple,
+        SimpleKeyLRUHashMap,
+        ComplexKeyLRUHashMap>;
+
+    CacheLRUHashMap cache;
+};
+
+}
diff --git a/src/Dictionaries/CacheDictionaryUpdateQueue.cpp b/src/Dictionaries/CacheDictionaryUpdateQueue.cpp
new file mode 100644
index 000000000000..eca833f62daf
--- /dev/null
+++ b/src/Dictionaries/CacheDictionaryUpdateQueue.cpp
@@ -0,0 +1,162 @@
+#include "CacheDictionaryUpdateQueue.h"
+
+#include <Dictionaries/CacheDictionaryUpdateQueue.h>
+
+#include <Common/setThreadName.h>
+
+namespace DB
+{
+
+namespace ErrorCodes
+{
+    extern const int CACHE_DICTIONARY_UPDATE_FAIL;
+    extern const int UNSUPPORTED_METHOD;
+    extern const int TIMEOUT_EXCEEDED;
+}
+
+template class CacheDictionaryUpdateUnit<DictionaryKeyType::simple>;
+template class CacheDictionaryUpdateUnit<DictionaryKeyType::complex>;
+
+template <DictionaryKeyType dictionary_key_type>
+CacheDictionaryUpdateQueue<dictionary_key_type>::CacheDictionaryUpdateQueue(
+    String dictionary_name_for_logs_,
+    CacheDictionaryUpdateQueueConfiguration configuration_,
+    UpdateFunction && update_func_)
+    : dictionary_name_for_logs(std::move(dictionary_name_for_logs_))
+    , configuration(configuration_)
+    , update_func(std::move(update_func_))
+    , update_queue(configuration.max_update_queue_size)
+    , update_pool(configuration.max_threads_for_updates)
+{
+    for (size_t i = 0; i < configuration.max_threads_for_updates; ++i)
+        update_pool.scheduleOrThrowOnError([this] { updateThreadFunction(); });
+}
+
+template <DictionaryKeyType dictionary_key_type>
+CacheDictionaryUpdateQueue<dictionary_key_type>::~CacheDictionaryUpdateQueue()
+{
+    try {
+        if (!finished)
+            stopAndWait();
+    }
+    catch (...)
+    {
+        /// TODO: Write log
+    }
+}
+
+template <DictionaryKeyType dictionary_key_type>
+void CacheDictionaryUpdateQueue<dictionary_key_type>::tryPushToUpdateQueueOrThrow(CacheDictionaryUpdateUnitPtr<dictionary_key_type> & update_unit_ptr)
+{
+    if (finished)
+        throw Exception{"CacheDictionaryUpdateQueue finished", ErrorCodes::UNSUPPORTED_METHOD};
+
+    if (!update_queue.tryPush(update_unit_ptr, configuration.update_queue_push_timeout_milliseconds))
+        throw DB::Exception(
+            ErrorCodes::CACHE_DICTIONARY_UPDATE_FAIL,
+            "Cannot push to internal update queue in dictionary {}. "
+            "Timelimit of {} ms. exceeded. Current queue size is {}",
+            dictionary_name_for_logs,
+            std::to_string(configuration.update_queue_push_timeout_milliseconds),
+            std::to_string(update_queue.size()));
+}
+
+template <DictionaryKeyType dictionary_key_type>
+void CacheDictionaryUpdateQueue<dictionary_key_type>::waitForCurrentUpdateFinish(CacheDictionaryUpdateUnitPtr<dictionary_key_type> & update_unit_ptr) const
+{
+    if (finished)
+        throw Exception{"CacheDictionaryUpdateQueue finished", ErrorCodes::UNSUPPORTED_METHOD};
+
+    std::unique_lock<std::mutex> update_lock(update_mutex);
+
+    bool result = is_update_finished.wait_for(
+        update_lock,
+        std::chrono::milliseconds(configuration.query_wait_timeout_milliseconds),
+        [&]
+        {
+            return update_unit_ptr->is_done || update_unit_ptr->current_exception;
+        });
+
+    if (!result)
+    {
+        throw DB::Exception(
+            ErrorCodes::TIMEOUT_EXCEEDED,
+            "Dictionary {} source seems unavailable, because {} ms timeout exceeded.",
+            dictionary_name_for_logs,
+            toString(configuration.query_wait_timeout_milliseconds));
+    }
+
+    if (update_unit_ptr->current_exception)
+    {
+        // Don't just rethrow it, because sharing the same exception object
+        // between multiple threads can lead to weird effects if they decide to
+        // modify it, for example, by adding some error context.
+        try
+        {
+            std::rethrow_exception(update_unit_ptr->current_exception);
+        }
+        catch (...)
+        {
+            throw DB::Exception(
+                ErrorCodes::CACHE_DICTIONARY_UPDATE_FAIL,
+                "Update failed for dictionary '{}': {}",
+                dictionary_name_for_logs,
+                getCurrentExceptionMessage(true /*with stack trace*/, true /*check embedded stack trace*/));
+        }
+    }
+}
+
+template <DictionaryKeyType dictionary_key_type>
+void CacheDictionaryUpdateQueue<dictionary_key_type>::stopAndWait()
+{
+    finished = true;
+    update_queue.clear();
+
+    for (size_t i = 0; i < configuration.max_threads_for_updates; ++i)
+    {
+        auto empty_finishing_ptr = std::make_shared<CacheDictionaryUpdateUnit<dictionary_key_type>>();
+        update_queue.push(empty_finishing_ptr);
+    }
+
+    update_pool.wait();
+}
+
+template <DictionaryKeyType dictionary_key_type>
+void CacheDictionaryUpdateQueue<dictionary_key_type>::updateThreadFunction()
+{
+    setThreadName("UpdQueue");
+
+    while (!finished)
+    {
+        CacheDictionaryUpdateUnitPtr<dictionary_key_type> unit_to_update;
+        update_queue.pop(unit_to_update);
+
+        if (finished)
+            break;
+
+        try
+        {
+            /// Update
+            update_func(unit_to_update);
+
+            /// Notify thread about finished updating the bunch of ids
+            /// where their own ids were included.
+            std::unique_lock<std::mutex> lock(update_mutex);
+
+            unit_to_update->is_done = true;
+            is_update_finished.notify_all();
+        }
+        catch (...)
+        {
+            std::unique_lock<std::mutex> lock(update_mutex);
+
+            unit_to_update->current_exception = std::current_exception(); // NOLINT(bugprone-throw-keyword-missing)
+            is_update_finished.notify_all();
+        }
+    }
+}
+
+template class CacheDictionaryUpdateQueue<DictionaryKeyType::simple>;
+template class CacheDictionaryUpdateQueue<DictionaryKeyType::complex>;
+
+}
diff --git a/src/Dictionaries/CacheDictionaryUpdateQueue.h b/src/Dictionaries/CacheDictionaryUpdateQueue.h
new file mode 100644
index 000000000000..2e636af6db66
--- /dev/null
+++ b/src/Dictionaries/CacheDictionaryUpdateQueue.h
@@ -0,0 +1,172 @@
+#pragma once
+
+#include <atomic>
+#include <mutex>
+#include <shared_mutex>
+#include <utility>
+#include <vector>
+#include <functional>
+
+#include <Common/ThreadPool.h>
+#include <Common/ConcurrentBoundedQueue.h>
+#include <Common/CurrentMetrics.h>
+#include <Common/PODArray.h>
+#include <Common/HashTable/HashMap.h>
+#include <Columns/IColumn.h>
+#include <Dictionaries/ICacheDictionaryStorage.h>
+
+namespace CurrentMetrics
+{
+    extern const Metric CacheDictionaryUpdateQueueBatches;
+    extern const Metric CacheDictionaryUpdateQueueKeys;
+}
+
+namespace DB
+{
+
+/** This class is passed between update queue and update queue client during update.
+
+    For simple keys we pass simple keys.
+
+    For complex keys we pass complex keys columns and requested rows to update.
+
+    During update cache dictionary should fill requested_keys_to_fetched_columns_during_update_index and
+    fetched_columns_during_update.
+
+    For complex key to extend lifetime of key complex key arena should be used.
+*/
+template <DictionaryKeyType dictionary_key_type>
+class CacheDictionaryUpdateUnit
+{
+public:
+    using KeyType = std::conditional_t<dictionary_key_type == DictionaryKeyType::simple, UInt64, StringRef>;
+
+    /// Constructor for complex keys update request
+    explicit CacheDictionaryUpdateUnit(
+        const Columns & key_columns_,
+        const PaddedPODArray<KeyState> & key_index_to_state_from_storage_,
+        const DictionaryStorageFetchRequest & request_,
+        size_t keys_to_update_size_)
+        : key_columns(key_columns_)
+        , key_index_to_state(key_index_to_state_from_storage_.begin(), key_index_to_state_from_storage_.end())
+        , request(request_)
+        , keys_to_update_size(keys_to_update_size_)
+        , alive_keys(CurrentMetrics::CacheDictionaryUpdateQueueKeys, keys_to_update_size)
+    {}
+
+    CacheDictionaryUpdateUnit()
+        : keys_to_update_size(0)
+        , alive_keys(CurrentMetrics::CacheDictionaryUpdateQueueKeys, 0)
+    {}
+
+    const Columns key_columns;
+    const PaddedPODArray<KeyState> key_index_to_state;
+    const DictionaryStorageFetchRequest request;
+    const size_t keys_to_update_size;
+
+    HashMap<KeyType, size_t> requested_keys_to_fetched_columns_during_update_index;
+    MutableColumns fetched_columns_during_update;
+    /// Complex keys are serialized in this arena
+    Arena complex_key_arena;
+
+private:
+    template <DictionaryKeyType>
+    friend class CacheDictionaryUpdateQueue;
+
+    std::atomic<bool> is_done{false};
+    std::exception_ptr current_exception{nullptr};
+
+    /// While UpdateUnit is alive, it is accounted in update_queue size.
+    CurrentMetrics::Increment alive_batch{CurrentMetrics::CacheDictionaryUpdateQueueBatches};
+    CurrentMetrics::Increment alive_keys;
+};
+
+template <DictionaryKeyType dictionary_key_type>
+using CacheDictionaryUpdateUnitPtr = std::shared_ptr<CacheDictionaryUpdateUnit<dictionary_key_type>>;
+
+extern template class CacheDictionaryUpdateUnit<DictionaryKeyType::simple>;
+extern template class CacheDictionaryUpdateUnit<DictionaryKeyType::complex>;
+
+struct CacheDictionaryUpdateQueueConfiguration
+{
+    /// Size of update queue
+    const size_t max_update_queue_size;
+    /// Size in thead pool of update queue
+    const size_t max_threads_for_updates;
+    /// Timeout for trying to push update unit into queue
+    const size_t update_queue_push_timeout_milliseconds;
+    /// Timeout during sync waititing of update unit
+    const size_t query_wait_timeout_milliseconds;
+};
+
+/** Responsibility of this class is to provide asynchronous and synchronous update support for CacheDictionary
+
+    It is responsibility of CacheDictionary to perform update with UpdateUnit using UpdateFunction.
+*/
+template <DictionaryKeyType dictionary_key_type>
+class CacheDictionaryUpdateQueue
+{
+public:
+    /// Client of update queue must provide this function in constructor and perform update using update unit.
+    using UpdateFunction = std::function<void (CacheDictionaryUpdateUnitPtr<dictionary_key_type>)>;
+    static_assert(dictionary_key_type != DictionaryKeyType::range, "Range key type is not supported by CacheDictionaryUpdateQueue");
+
+    CacheDictionaryUpdateQueue(
+        String dictionary_name_for_logs_,
+        CacheDictionaryUpdateQueueConfiguration configuration_,
+        UpdateFunction && update_func_);
+
+    ~CacheDictionaryUpdateQueue();
+
+    /// Get configuration that was passed to constructor
+    const CacheDictionaryUpdateQueueConfiguration & getConfiguration() const { return configuration; }
+
+    /// Is queue finished
+    bool isFinished() const { return finished; }
+
+    /// Synchronous wait for update queue to stop
+    void stopAndWait();
+
+    /** Try to add update unit into queue.
+
+        If queue is full and oush cannot be performed in update_queue_push_timeout_milliseconds from configuration
+        an exception will be thrown.
+
+        If queue already finished an exception will be thrown.
+    */
+    void tryPushToUpdateQueueOrThrow(CacheDictionaryUpdateUnitPtr<dictionary_key_type> & update_unit_ptr);
+
+    /** Try to synchronously wait for update completion.
+
+        If exception was passed from update function during update it will be rethrowed.
+
+        If update will not be finished in query_wait_timeout_milliseconds from configuration
+        an exception will be thrown.
+
+        If queue already finished an exception will be thrown.
+    */
+    void waitForCurrentUpdateFinish(CacheDictionaryUpdateUnitPtr<dictionary_key_type> & update_unit_ptr) const;
+
+private:
+    void updateThreadFunction();
+
+    using UpdateQueue = ConcurrentBoundedQueue<CacheDictionaryUpdateUnitPtr<dictionary_key_type>>;
+
+    String dictionary_name_for_logs;
+
+    CacheDictionaryUpdateQueueConfiguration configuration;
+    UpdateFunction update_func;
+
+    UpdateQueue update_queue;
+    ThreadPool update_pool;
+
+    mutable std::mutex update_mutex;
+    mutable std::condition_variable is_update_finished;
+
+    std::atomic<bool> finished{false};
+};
+
+extern template class CacheDictionaryUpdateQueue<DictionaryKeyType::simple>;
+extern template class CacheDictionaryUpdateQueue<DictionaryKeyType::complex>;
+
+}
diff --git a/src/Dictionaries/ComplexKeyCacheDictionary.cpp b/src/Dictionaries/ComplexKeyCacheDictionary.cpp
deleted file mode 100644
index cbb57f817937..000000000000
--- a/src/Dictionaries/ComplexKeyCacheDictionary.cpp
+++ /dev/null
@@ -1,915 +0,0 @@
-#include "ComplexKeyCacheDictionary.h"
-#include <Common/Arena.h>
-#include <Common/BitHelpers.h>
-#include <Common/CurrentMetrics.h>
-#include <Common/ProfileEvents.h>
-#include <Common/ProfilingScopedRWLock.h>
-#include <Common/Stopwatch.h>
-#include <Common/randomSeed.h>
-#include <ext/map.h>
-#include <ext/range.h>
-#include "DictionaryBlockInputStream.h"
-#include "DictionaryFactory.h"
-#include <Functions/FunctionHelpers.h>
-#include <DataTypes/DataTypesDecimal.h>
-
-namespace ProfileEvents
-{
-extern const Event DictCacheKeysRequested;
-extern const Event DictCacheKeysRequestedMiss;
-extern const Event DictCacheKeysRequestedFound;
-extern const Event DictCacheKeysExpired;
-extern const Event DictCacheKeysNotFound;
-extern const Event DictCacheKeysHit;
-extern const Event DictCacheRequestTimeNs;
-extern const Event DictCacheLockWriteNs;
-extern const Event DictCacheLockReadNs;
-}
-
-namespace CurrentMetrics
-{
-extern const Metric DictCacheRequests;
-}
-
-
-namespace DB
-{
-namespace ErrorCodes
-{
-    extern const int TYPE_MISMATCH;
-    extern const int BAD_ARGUMENTS;
-    extern const int UNSUPPORTED_METHOD;
-    extern const int TOO_SMALL_BUFFER_SIZE;
-}
-
-
-inline UInt64 ComplexKeyCacheDictionary::getCellIdx(const StringRef key) const
-{
-    const auto hash = StringRefHash{}(key);
-    const auto idx = hash & size_overlap_mask;
-    return idx;
-}
-
-
-ComplexKeyCacheDictionary::ComplexKeyCacheDictionary(
-    const StorageID & dict_id_,
-    const DictionaryStructure & dict_struct_,
-    DictionarySourcePtr source_ptr_,
-    const DictionaryLifetime dict_lifetime_,
-    const size_t size_)
-    : IDictionaryBase(dict_id_)
-    , dict_struct(dict_struct_)
-    , source_ptr{std::move(source_ptr_)}
-    , dict_lifetime(dict_lifetime_)
-    , size{roundUpToPowerOfTwoOrZero(std::max(size_, size_t(max_collision_length)))}
-    , size_overlap_mask{this->size - 1}
-    , rnd_engine(randomSeed())
-{
-    if (!this->source_ptr->supportsSelectiveLoad())
-        throw Exception{full_name + ": source cannot be used with ComplexKeyCacheDictionary", ErrorCodes::UNSUPPORTED_METHOD};
-
-    createAttributes();
-}
-
-ColumnPtr ComplexKeyCacheDictionary::getColumn(
-    const std::string & attribute_name,
-    const DataTypePtr & result_type,
-    const Columns & key_columns,
-    const DataTypes & key_types,
-    const ColumnPtr default_values_column) const
-{
-    dict_struct.validateKeyTypes(key_types);
-
-    ColumnPtr result;
-
-    auto & attribute = getAttribute(attribute_name);
-    const auto & dictionary_attribute = dict_struct.getAttribute(attribute_name, result_type);
-
-    auto keys_size = key_columns.front()->size();
-
-    auto type_call = [&](const auto &dictionary_attribute_type)
-    {
-        using Type = std::decay_t<decltype(dictionary_attribute_type)>;
-        using AttributeType = typename Type::AttributeType;
-        using ColumnProvider = DictionaryAttributeColumnProvider<AttributeType>;
-
-        const auto & null_value = std::get<AttributeType>(attribute.null_values);
-        DictionaryDefaultValueExtractor<AttributeType> default_value_extractor(null_value, default_values_column);
-
-        auto column = ColumnProvider::getColumn(dictionary_attribute, keys_size);
-
-        if constexpr (std::is_same_v<AttributeType, String>)
-        {
-            auto * out = column.get();
-            getItemsString(attribute, key_columns, out, default_value_extractor);
-        }
-        else
-        {
-            auto & out = column->getData();
-            getItemsNumberImpl<AttributeType, AttributeType>(attribute, key_columns, out, default_value_extractor);
-        }
-
-        result = std::move(column);
-    };
-
-    callOnDictionaryAttributeType(attribute.type, type_call);
-
-    return result;
-}
-
-/// returns cell_idx (always valid for replacing), 'cell is valid' flag, 'cell is outdated' flag,
-/// true  false   found and valid
-/// false true    not found (something outdated, maybe our cell)
-/// false false   not found (other id stored with valid data)
-/// true  true    impossible
-///
-/// todo: split this func to two: find_for_get and find_for_set
-ComplexKeyCacheDictionary::FindResult
-ComplexKeyCacheDictionary::findCellIdx(const StringRef & key, const CellMetadata::time_point_t now, const size_t hash) const
-{
-    auto pos = hash;
-    auto oldest_id = pos;
-    auto oldest_time = CellMetadata::time_point_t::max();
-    const auto stop = pos + max_collision_length;
-
-    for (; pos < stop; ++pos)
-    {
-        const auto cell_idx = pos & size_overlap_mask;
-        const auto & cell = cells[cell_idx];
-
-        if (cell.hash != hash || cell.key != key)
-        {
-            /// maybe we already found nearest expired cell
-            if (oldest_time > now && oldest_time > cell.expiresAt())
-            {
-                oldest_time = cell.expiresAt();
-                oldest_id = cell_idx;
-            }
-
-            continue;
-        }
-
-        if (cell.expiresAt() < now)
-        {
-            return {cell_idx, false, true};
-        }
-
-        return {cell_idx, true, false};
-    }
-
-    oldest_id &= size_overlap_mask;
-    return {oldest_id, false, false};
-}
-
-ColumnUInt8::Ptr ComplexKeyCacheDictionary::hasKeys(const Columns & key_columns, const DataTypes & key_types) const
-{
-    dict_struct.validateKeyTypes(key_types);
-
-    const auto rows_num = key_columns.front()->size();
-
-    auto result = ColumnUInt8::create(rows_num);
-    auto& out = result->getData();
-
-    for (const auto row : ext::range(0, rows_num))
-        out[row] = false;
-
-    /// Mapping: <key> -> { all indices `i` of `key_columns` such that `key_columns[i]` = <key> }
-    MapType<std::vector<size_t>> outdated_keys;
-
-    const auto keys_size = dict_struct.key->size();
-    StringRefs keys(keys_size);
-    Arena temporary_keys_pool;
-    PODArray<StringRef> keys_array(rows_num);
-
-    size_t cache_expired = 0, cache_not_found = 0, cache_hit = 0;
-    {
-        const ProfilingScopedReadRWLock read_lock{rw_lock, ProfileEvents::DictCacheLockReadNs};
-
-        const auto now = std::chrono::system_clock::now();
-        /// fetch up-to-date values, decide which ones require update
-        for (const auto row : ext::range(0, rows_num))
-        {
-            const StringRef key = placeKeysInPool(row, key_columns, keys, *dict_struct.key, temporary_keys_pool);
-            keys_array[row] = key;
-            const auto find_result = findCellIdx(key, now);
-            const auto & cell_idx = find_result.cell_idx;
-            /** cell should be updated if either:
-                *    1. keys (or hash) do not match,
-                *    2. cell has expired,
-                *    3. explicit defaults were specified and cell was set default. */
-            if (!find_result.valid)
-            {
-                outdated_keys[key].push_back(row);
-                if (find_result.outdated)
-                    ++cache_expired;
-                else
-                    ++cache_not_found;
-            }
-            else
-            {
-                ++cache_hit;
-                const auto & cell = cells[cell_idx];
-                out[row] = !cell.isDefault();
-            }
-        }
-    }
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysExpired, cache_expired);
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysNotFound, cache_not_found);
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysHit, cache_hit);
-
-    query_count.fetch_add(rows_num, std::memory_order_relaxed);
-    hit_count.fetch_add(rows_num - outdated_keys.size(), std::memory_order_release);
-
-    if (outdated_keys.empty())
-        return result;
-
-    std::vector<size_t> required_rows(outdated_keys.size());
-    std::transform(
-        std::begin(outdated_keys), std::end(outdated_keys), std::begin(required_rows), [](auto & pair) { return pair.getMapped().front(); });
-
-    /// request new values
-    update(
-        key_columns,
-        keys_array,
-        required_rows,
-        [&](const StringRef key, const auto)
-        {
-            for (const auto out_idx : outdated_keys[key])
-                out[out_idx] = true;
-        },
-        [&](const StringRef key, const auto)
-        {
-            for (const auto out_idx : outdated_keys[key])
-                out[out_idx] = false;
-        });
-
-    return result;
-}
-
-
-template <typename AttributeType, typename OutputType, typename DefaultValueExtractor>
-void ComplexKeyCacheDictionary::getItemsNumberImpl(
-    Attribute & attribute,
-    const Columns & key_columns,
-    PaddedPODArray<OutputType> & out,
-    DefaultValueExtractor & default_value_extractor) const
-{
-    /// Mapping: <key> -> { all indices `i` of `key_columns` such that `key_columns[i]` = <key> }
-    MapType<std::vector<size_t>> outdated_keys;
-    auto & attribute_array = std::get<ContainerPtrType<AttributeType>>(attribute.arrays);
-
-    const auto rows_num = key_columns.front()->size();
-    const auto keys_size = dict_struct.key->size();
-    StringRefs keys(keys_size);
-    Arena temporary_keys_pool;
-    PODArray<StringRef> keys_array(rows_num);
-
-    size_t cache_expired = 0, cache_not_found = 0, cache_hit = 0;
-    {
-        const ProfilingScopedReadRWLock read_lock{rw_lock, ProfileEvents::DictCacheLockReadNs};
-
-        const auto now = std::chrono::system_clock::now();
-        /// fetch up-to-date values, decide which ones require update
-        for (const auto row : ext::range(0, rows_num))
-        {
-            const StringRef key = placeKeysInPool(row, key_columns, keys, *dict_struct.key, temporary_keys_pool);
-            keys_array[row] = key;
-            const auto find_result = findCellIdx(key, now);
-
-            /** cell should be updated if either:
-                *    1. keys (or hash) do not match,
-                *    2. cell has expired,
-                *    3. explicit defaults were specified and cell was set default. */
-
-            if (!find_result.valid)
-            {
-                outdated_keys[key].push_back(row);
-                if (find_result.outdated)
-                    ++cache_expired;
-                else
-                    ++cache_not_found;
-            }
-            else
-            {
-                ++cache_hit;
-                const auto & cell_idx = find_result.cell_idx;
-                const auto & cell = cells[cell_idx];
-                out[row] = cell.isDefault() ? default_value_extractor[row] : static_cast<OutputType>(attribute_array[cell_idx]);
-            }
-        }
-    }
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysExpired, cache_expired);
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysNotFound, cache_not_found);
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysHit, cache_hit);
-    query_count.fetch_add(rows_num, std::memory_order_relaxed);
-    hit_count.fetch_add(rows_num - outdated_keys.size(), std::memory_order_release);
-
-    if (outdated_keys.empty())
-        return;
-
-    std::vector<size_t> required_rows(outdated_keys.size());
-    std::transform(std::begin(outdated_keys), std::end(outdated_keys), std::begin(required_rows), [](auto & pair)
-    {
-        return pair.getMapped().front();
-    });
-
-    /// request new values
-    update(
-        key_columns,
-        keys_array,
-        required_rows,
-        [&](const StringRef key, const size_t cell_idx)
-        {
-            for (const auto row : outdated_keys[key])
-                out[row] = static_cast<OutputType>(attribute_array[cell_idx]);
-        },
-        [&](const StringRef key, const size_t)
-        {
-            for (const auto row : outdated_keys[key])
-                out[row] = default_value_extractor[row];
-        });
-}
-
-void ComplexKeyCacheDictionary::getItemsString(
-    Attribute & attribute,
-    const Columns & key_columns,
-    ColumnString * out,
-    DictionaryDefaultValueExtractor<String> & default_value_extractor) const
-{
-    const auto rows_num = key_columns.front()->size();
-    /// save on some allocations
-    out->getOffsets().reserve(rows_num);
-
-    const auto keys_size = dict_struct.key->size();
-    StringRefs keys(keys_size);
-    Arena temporary_keys_pool;
-
-    auto & attribute_array = std::get<ContainerPtrType<StringRef>>(attribute.arrays);
-
-    auto found_outdated_values = false;
-
-    /// perform optimistic version, fallback to pessimistic if failed
-    {
-        const ProfilingScopedReadRWLock read_lock{rw_lock, ProfileEvents::DictCacheLockReadNs};
-
-        const auto now = std::chrono::system_clock::now();
-        /// fetch up-to-date values, discard on fail
-        for (const auto row : ext::range(0, rows_num))
-        {
-            const StringRef key = placeKeysInPool(row, key_columns, keys, *dict_struct.key, temporary_keys_pool);
-            SCOPE_EXIT(temporary_keys_pool.rollback(key.size));
-            const auto find_result = findCellIdx(key, now);
-
-            if (!find_result.valid)
-            {
-                found_outdated_values = true;
-                break;
-            }
-            else
-            {
-                const auto & cell_idx = find_result.cell_idx;
-                const auto & cell = cells[cell_idx];
-                const auto string_ref = cell.isDefault() ? default_value_extractor[row] : attribute_array[cell_idx];
-                out->insertData(string_ref.data, string_ref.size);
-            }
-        }
-    }
-
-    /// optimistic code completed successfully
-    if (!found_outdated_values)
-    {
-        query_count.fetch_add(rows_num, std::memory_order_relaxed);
-        hit_count.fetch_add(rows_num, std::memory_order_release);
-        return;
-    }
-
-    /// now onto the pessimistic one, discard possible partial results from the optimistic path
-    out->getChars().resize_assume_reserved(0);
-    out->getOffsets().resize_assume_reserved(0);
-
-    /// Mapping: <key> -> { all indices `i` of `key_columns` such that `key_columns[i]` = <key> }
-    MapType<std::vector<size_t>> outdated_keys;
-    /// we are going to store every string separately
-    MapType<StringRef> map;
-    PODArray<StringRef> keys_array(rows_num);
-
-    size_t total_length = 0;
-    size_t cache_expired = 0, cache_not_found = 0, cache_hit = 0;
-    {
-        const ProfilingScopedReadRWLock read_lock{rw_lock, ProfileEvents::DictCacheLockReadNs};
-
-        const auto now = std::chrono::system_clock::now();
-        for (const auto row : ext::range(0, rows_num))
-        {
-            const StringRef key = placeKeysInPool(row, key_columns, keys, *dict_struct.key, temporary_keys_pool);
-            keys_array[row] = key;
-            const auto find_result = findCellIdx(key, now);
-
-            if (!find_result.valid)
-            {
-                outdated_keys[key].push_back(row);
-                if (find_result.outdated)
-                    ++cache_expired;
-                else
-                    ++cache_not_found;
-            }
-            else
-            {
-                ++cache_hit;
-                const auto & cell_idx = find_result.cell_idx;
-                const auto & cell = cells[cell_idx];
-                const auto string_ref = cell.isDefault() ? default_value_extractor[row] : attribute_array[cell_idx];
-
-                if (!cell.isDefault())
-                    map[key] = copyIntoArena(string_ref, temporary_keys_pool);
-
-                total_length += string_ref.size + 1;
-            }
-        }
-    }
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysExpired, cache_expired);
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysNotFound, cache_not_found);
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysHit, cache_hit);
-
-    query_count.fetch_add(rows_num, std::memory_order_relaxed);
-    hit_count.fetch_add(rows_num - outdated_keys.size(), std::memory_order_release);
-
-    /// request new values
-    if (!outdated_keys.empty())
-    {
-        std::vector<size_t> required_rows(outdated_keys.size());
-        std::transform(std::begin(outdated_keys), std::end(outdated_keys), std::begin(required_rows), [](auto & pair)
-        {
-            return pair.getMapped().front();
-        });
-
-        update(
-            key_columns,
-            keys_array,
-            required_rows,
-            [&](const StringRef key, const size_t cell_idx)
-            {
-                const StringRef attribute_value = attribute_array[cell_idx];
-
-                /// We must copy key and value to own memory, because it may be replaced with another
-                ///  in next iterations of inner loop of update.
-                const StringRef copied_key = copyIntoArena(key, temporary_keys_pool);
-                const StringRef copied_value = copyIntoArena(attribute_value, temporary_keys_pool);
-
-                map[copied_key] = copied_value;
-                total_length += (attribute_value.size + 1) * outdated_keys[key].size();
-            },
-            [&](const StringRef key, const size_t)
-            {
-                for (const auto row : outdated_keys[key])
-                    total_length += default_value_extractor[row].size + 1;
-            });
-    }
-
-    out->getChars().reserve(total_length);
-
-    for (const auto row : ext::range(0, ext::size(keys_array)))
-    {
-        const StringRef key = keys_array[row];
-        auto * const it = map.find(key);
-        const auto string_ref = it ? it->getMapped() : default_value_extractor[row];
-        out->insertData(string_ref.data, string_ref.size);
-    }
-}
-
-template <typename PresentKeyHandler, typename AbsentKeyHandler>
-void ComplexKeyCacheDictionary::update(
-    const Columns & in_key_columns,
-    const PODArray<StringRef> & in_keys,
-    const std::vector<size_t> & in_requested_rows,
-    PresentKeyHandler && on_cell_updated,
-    AbsentKeyHandler && on_key_not_found) const
-{
-    MapType<bool> remaining_keys{in_requested_rows.size()};
-    for (const auto row : in_requested_rows)
-        remaining_keys.insert({in_keys[row], false});
-
-    std::uniform_int_distribution<UInt64> distribution(dict_lifetime.min_sec, dict_lifetime.max_sec);
-
-    const ProfilingScopedWriteRWLock write_lock{rw_lock, ProfileEvents::DictCacheLockWriteNs};
-    {
-        Stopwatch watch;
-        auto stream = source_ptr->loadKeys(in_key_columns, in_requested_rows);
-        stream->readPrefix();
-
-        const auto keys_size = dict_struct.key->size();
-        StringRefs keys(keys_size);
-
-        const auto attributes_size = attributes.size();
-        const auto now = std::chrono::system_clock::now();
-
-        while (const auto block = stream->read())
-        {
-            /// cache column pointers
-            const auto key_columns = ext::map<Columns>(
-                ext::range(0, keys_size), [&](const size_t attribute_idx) { return block.safeGetByPosition(attribute_idx).column; });
-
-            const auto attribute_columns = ext::map<Columns>(ext::range(0, attributes_size), [&](const size_t attribute_idx)
-            {
-                return block.safeGetByPosition(keys_size + attribute_idx).column;
-            });
-
-            const auto rows_num = block.rows();
-
-            for (const auto row : ext::range(0, rows_num))
-            {
-                auto key = allocKey(row, key_columns, keys);
-                const auto hash = StringRefHash{}(key);
-                const auto find_result = findCellIdx(key, now, hash);
-                const auto & cell_idx = find_result.cell_idx;
-                auto & cell = cells[cell_idx];
-
-                for (const auto attribute_idx : ext::range(0, attributes.size()))
-                {
-                    const auto & attribute_column = *attribute_columns[attribute_idx];
-                    auto & attribute = attributes[attribute_idx];
-
-                    setAttributeValue(attribute, cell_idx, attribute_column[row]);
-                }
-
-                /// if cell id is zero and zero does not map to this cell, then the cell is unused
-                if (cell.key == StringRef{} && cell_idx != zero_cell_idx)
-                    element_count.fetch_add(1, std::memory_order_relaxed);
-
-                /// handle memory allocated for old key
-                if (key == cell.key)
-                {
-                    freeKey(key);
-                    key = cell.key;
-                }
-                else
-                {
-                    /// new key is different from the old one
-                    if (cell.key.data)
-                        freeKey(cell.key);
-
-                    cell.key = key;
-                }
-
-                cell.hash = hash;
-
-                if (dict_lifetime.min_sec != 0 && dict_lifetime.max_sec != 0)
-                    cell.setExpiresAt(std::chrono::system_clock::now() + std::chrono::seconds{distribution(rnd_engine)});
-                else
-                    cell.setExpiresAt(std::chrono::time_point<std::chrono::system_clock>::max());
-
-                /// inform caller
-                on_cell_updated(key, cell_idx);
-                /// mark corresponding id as found
-                remaining_keys[key] = true;
-            }
-        }
-
-        stream->readSuffix();
-
-        ProfileEvents::increment(ProfileEvents::DictCacheKeysRequested, in_requested_rows.size());
-        ProfileEvents::increment(ProfileEvents::DictCacheRequestTimeNs, watch.elapsed());
-    }
-
-    size_t found_num = 0;
-    size_t not_found_num = 0;
-
-    const auto now = std::chrono::system_clock::now();
-
-    /// Check which ids have not been found and require setting null_value
-    for (const auto & key_found_pair : remaining_keys)
-    {
-        if (key_found_pair.getMapped())
-        {
-            ++found_num;
-            continue;
-        }
-
-        ++not_found_num;
-
-        auto key = key_found_pair.getKey();
-        const auto hash = StringRefHash{}(key);
-        const auto find_result = findCellIdx(key, now, hash);
-        const auto & cell_idx = find_result.cell_idx;
-        auto & cell = cells[cell_idx];
-
-        /// Set null_value for each attribute
-        for (auto & attribute : attributes)
-            setDefaultAttributeValue(attribute, cell_idx);
-
-        /// Check if cell had not been occupied before and increment element counter if it hadn't
-        if (cell.key == StringRef{} && cell_idx != zero_cell_idx)
-            element_count.fetch_add(1, std::memory_order_relaxed);
-
-        if (key == cell.key)
-            key = cell.key;
-        else
-        {
-            if (cell.key.data)
-                freeKey(cell.key);
-
-            /// copy key from temporary pool
-            key = copyKey(key);
-            cell.key = key;
-        }
-
-        cell.hash = hash;
-
-        if (dict_lifetime.min_sec != 0 && dict_lifetime.max_sec != 0)
-            cell.setExpiresAt(std::chrono::system_clock::now() + std::chrono::seconds{distribution(rnd_engine)});
-        else
-            cell.setExpiresAt(std::chrono::time_point<std::chrono::system_clock>::max());
-
-        cell.setDefault();
-
-        /// inform caller that the cell has not been found
-        on_key_not_found(key, cell_idx);
-    }
-
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysRequestedFound, found_num);
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysRequestedMiss, not_found_num);
-}
-
-
-void ComplexKeyCacheDictionary::createAttributes()
-{
-    const auto attributes_size = dict_struct.attributes.size();
-    attributes.reserve(attributes_size);
-
-    bytes_allocated += size * sizeof(CellMetadata);
-    bytes_allocated += attributes_size * sizeof(attributes.front());
-
-    for (const auto & attribute : dict_struct.attributes)
-    {
-        attribute_index_by_name.emplace(attribute.name, attributes.size());
-        attributes.push_back(createAttributeWithType(attribute.underlying_type, attribute.null_value));
-
-        if (attribute.hierarchical)
-            throw Exception{full_name + ": hierarchical attributes not supported for dictionary of type " + getTypeName(),
-                            ErrorCodes::TYPE_MISMATCH};
-    }
-}
-
-ComplexKeyCacheDictionary::Attribute & ComplexKeyCacheDictionary::getAttribute(const std::string & attribute_name) const
-{
-    const auto it = attribute_index_by_name.find(attribute_name);
-    if (it == std::end(attribute_index_by_name))
-        throw Exception{full_name + ": no such attribute '" + attribute_name + "'", ErrorCodes::BAD_ARGUMENTS};
-
-    return attributes[it->second];
-}
-
-void ComplexKeyCacheDictionary::setDefaultAttributeValue(Attribute & attribute, const size_t idx) const
-{
-    auto type_call = [&](const auto &dictionary_attribute_type)
-    {
-        using Type = std::decay_t<decltype(dictionary_attribute_type)>;
-        using AttributeType = typename Type::AttributeType;
-
-        if constexpr (std::is_same_v<AttributeType, String>)
-        {
-            const auto & null_value_ref = std::get<String>(attribute.null_values);
-            auto & string_ref = std::get<ContainerPtrType<StringRef>>(attribute.arrays)[idx];
-
-            if (string_ref.data != null_value_ref.data())
-            {
-                if (string_ref.data)
-                    string_arena->free(const_cast<char *>(string_ref.data), string_ref.size);
-
-                string_ref = StringRef{null_value_ref};
-            }
-        }
-        else
-        {
-            std::get<ContainerPtrType<AttributeType>>(attribute.arrays)[idx] = std::get<AttributeType>(attribute.null_values);
-        }
-    };
-
-    callOnDictionaryAttributeType(attribute.type, type_call);
-}
-
-ComplexKeyCacheDictionary::Attribute
-ComplexKeyCacheDictionary::createAttributeWithType(const AttributeUnderlyingType type, const Field & null_value)
-{
-    Attribute attr{type, {}, {}};
-
-    auto type_call = [&](const auto &dictionary_attribute_type)
-    {
-        using Type = std::decay_t<decltype(dictionary_attribute_type)>;
-        using AttributeType = typename Type::AttributeType;
-
-        if constexpr (std::is_same_v<AttributeType, String>)
-        {
-            attr.null_values = null_value.get<String>();
-            attr.arrays = std::make_unique<ContainerType<StringRef>>(size);
-            bytes_allocated += size * sizeof(StringRef);
-            if (!string_arena)
-                string_arena = std::make_unique<ArenaWithFreeLists>();
-        }
-        else
-        {
-            attr.null_values = AttributeType(null_value.get<NearestFieldType<AttributeType>>()); /* NOLINT */
-            attr.arrays = std::make_unique<ContainerType<AttributeType>>(size); /* NOLINT */
-            bytes_allocated += size * sizeof(AttributeType);
-        }
-    };
-
-    callOnDictionaryAttributeType(type, type_call);
-
-    return attr;
-}
-
-void ComplexKeyCacheDictionary::setAttributeValue(Attribute & attribute, const size_t idx, const Field & value) const
-{
-    auto type_call = [&](const auto &dictionary_attribute_type)
-    {
-        using Type = std::decay_t<decltype(dictionary_attribute_type)>;
-        using AttributeType = typename Type::AttributeType;
-
-        if constexpr (std::is_same_v<AttributeType, String>)
-        {
-            const auto & string = value.get<String>();
-            auto & string_ref = std::get<ContainerPtrType<StringRef>>(attribute.arrays)[idx];
-            const auto & null_value_ref = std::get<String>(attribute.null_values);
-
-            /// free memory unless it points to a null_value
-            if (string_ref.data && string_ref.data != null_value_ref.data())
-                string_arena->free(const_cast<char *>(string_ref.data), string_ref.size);
-
-            const auto str_size = string.size();
-            if (str_size != 0)
-            {
-                auto * str_ptr = string_arena->alloc(str_size);
-                std::copy(string.data(), string.data() + str_size, str_ptr);
-                string_ref = StringRef{str_ptr, str_size};
-            }
-            else
-                string_ref = {};
-        }
-        else
-        {
-            std::get<ContainerPtrType<AttributeType>>(attribute.arrays)[idx] = value.get<NearestFieldType<AttributeType>>();
-        }
-    };
-
-    callOnDictionaryAttributeType(attribute.type, type_call);
-}
-
-StringRef ComplexKeyCacheDictionary::allocKey(const size_t row, const Columns & key_columns, StringRefs & keys) const
-{
-    if (key_size_is_fixed)
-        return placeKeysInFixedSizePool(row, key_columns);
-
-    return placeKeysInPool(row, key_columns, keys, *dict_struct.key, *keys_pool);
-}
-
-void ComplexKeyCacheDictionary::freeKey(const StringRef key) const
-{
-    if (key_size_is_fixed)
-        fixed_size_keys_pool->free(const_cast<char *>(key.data));
-    else
-        keys_pool->free(const_cast<char *>(key.data), key.size);
-}
-
-template <typename Pool>
-StringRef ComplexKeyCacheDictionary::placeKeysInPool(
-    const size_t row, const Columns & key_columns, StringRefs & keys, const std::vector<DictionaryAttribute> & key_attributes, Pool & pool)
-{
-    const auto keys_size = key_columns.size();
-    size_t sum_keys_size{};
-
-    for (size_t j = 0; j < keys_size; ++j)
-    {
-        keys[j] = key_columns[j]->getDataAt(row);
-        sum_keys_size += keys[j].size;
-        if (key_attributes[j].underlying_type == AttributeUnderlyingType::utString)
-            sum_keys_size += sizeof(size_t) + 1;
-    }
-
-    auto place = pool.alloc(sum_keys_size);
-
-    auto key_start = place;
-    for (size_t j = 0; j < keys_size; ++j)
-    {
-        if (key_attributes[j].underlying_type == AttributeUnderlyingType::utString)
-        {
-            auto start = key_start;
-            auto key_size = keys[j].size + 1;
-            memcpy(key_start, &key_size, sizeof(size_t));
-            key_start += sizeof(size_t);
-            memcpy(key_start, keys[j].data, keys[j].size);
-            key_start += keys[j].size;
-            *key_start = '\0';
-            ++key_start;
-            keys[j].data = start;
-            keys[j].size += sizeof(size_t) + 1;
-        }
-        else
-        {
-            memcpy(key_start, keys[j].data, keys[j].size);
-            keys[j].data = key_start;
-            key_start += keys[j].size;
-        }
-    }
-
-    return {place, sum_keys_size};
-}
-
-/// Explicit instantiations.
-
-template StringRef ComplexKeyCacheDictionary::placeKeysInPool<Arena>(
-    const size_t row,
-    const Columns & key_columns,
-    StringRefs & keys,
-    const std::vector<DictionaryAttribute> & key_attributes,
-    Arena & pool);
-
-template StringRef ComplexKeyCacheDictionary::placeKeysInPool<ArenaWithFreeLists>(
-    const size_t row,
-    const Columns & key_columns,
-    StringRefs & keys,
-    const std::vector<DictionaryAttribute> & key_attributes,
-    ArenaWithFreeLists & pool);
-
-
-StringRef ComplexKeyCacheDictionary::placeKeysInFixedSizePool(const size_t row, const Columns & key_columns) const
-{
-    auto * res = fixed_size_keys_pool->alloc();
-    auto * place = res;
-
-    for (const auto & key_column : key_columns)
-    {
-        const StringRef key = key_column->getDataAt(row);
-        memcpy(place, key.data, key.size);
-        place += key.size;
-    }
-
-    return {res, key_size};
-}
-
-StringRef ComplexKeyCacheDictionary::copyIntoArena(StringRef src, Arena & arena)
-{
-    char * allocated = arena.alloc(src.size);
-    memcpy(allocated, src.data, src.size);
-    return {allocated, src.size};
-}
-
-StringRef ComplexKeyCacheDictionary::copyKey(const StringRef key) const
-{
-    auto * res = key_size_is_fixed ? fixed_size_keys_pool->alloc() : keys_pool->alloc(key.size);
-    memcpy(res, key.data, key.size);
-
-    return {res, key.size};
-}
-
-bool ComplexKeyCacheDictionary::isEmptyCell(const UInt64 idx) const
-{
-    return (
-        cells[idx].key == StringRef{}
-        && (idx != zero_cell_idx || cells[idx].data == ext::safe_bit_cast<CellMetadata::time_point_urep_t>(CellMetadata::time_point_t())));
-}
-
-BlockInputStreamPtr ComplexKeyCacheDictionary::getBlockInputStream(const Names & column_names, size_t max_block_size) const
-{
-    std::vector<StringRef> keys;
-    {
-        const ProfilingScopedReadRWLock read_lock{rw_lock, ProfileEvents::DictCacheLockReadNs};
-
-        for (auto idx : ext::range(0, cells.size()))
-            if (!isEmptyCell(idx) && !cells[idx].isDefault())
-                keys.push_back(cells[idx].key);
-    }
-
-    using BlockInputStreamType = DictionaryBlockInputStream<UInt64>;
-    return std::make_shared<BlockInputStreamType>(shared_from_this(), max_block_size, keys, column_names);
-}
-
-void registerDictionaryComplexKeyCache(DictionaryFactory & factory)
-{
-    auto create_layout = [=](const std::string & full_name,
-                             const DictionaryStructure & dict_struct,
-                             const Poco::Util::AbstractConfiguration & config,
-                             const std::string & config_prefix,
-                             DictionarySourcePtr source_ptr) -> DictionaryPtr
-    {
-        if (!dict_struct.key)
-            throw Exception{"'key' is required for dictionary of layout 'complex_key_hashed'", ErrorCodes::BAD_ARGUMENTS};
-        const auto & layout_prefix = config_prefix + ".layout";
-        const auto size = config.getInt(layout_prefix + ".complex_key_cache.size_in_cells");
-        if (size == 0)
-            throw Exception{full_name + ": dictionary of layout 'cache' cannot have 0 cells", ErrorCodes::TOO_SMALL_BUFFER_SIZE};
-
-        const bool require_nonempty = config.getBool(config_prefix + ".require_nonempty", false);
-        if (require_nonempty)
-            throw Exception{full_name + ": dictionary of layout 'cache' cannot have 'require_nonempty' attribute set",
-                            ErrorCodes::BAD_ARGUMENTS};
-
-        const auto dict_id = StorageID::fromDictionaryConfig(config, config_prefix);
-        const DictionaryLifetime dict_lifetime{config, config_prefix + ".lifetime"};
-        return std::make_unique<ComplexKeyCacheDictionary>(dict_id, dict_struct, std::move(source_ptr), dict_lifetime, size);
-    };
-    factory.registerLayout("complex_key_cache", create_layout, true);
-}
-
-
-}
diff --git a/src/Dictionaries/ComplexKeyCacheDictionary.h b/src/Dictionaries/ComplexKeyCacheDictionary.h
deleted file mode 100644
index f5643fc799c3..000000000000
--- a/src/Dictionaries/ComplexKeyCacheDictionary.h
+++ /dev/null
@@ -1,276 +0,0 @@
-#pragma once
-
-#include <atomic>
-#include <chrono>
-#include <map>
-#include <shared_mutex>
-#include <variant>
-#include <vector>
-#include <Columns/ColumnDecimal.h>
-#include <Columns/ColumnString.h>
-#include <pcg_random.hpp>
-#include <Common/ArenaWithFreeLists.h>
-#include <Common/HashTable/HashMap.h>
-#include <Common/ProfilingScopedRWLock.h>
-#include <Common/SmallObjectPool.h>
-#include <common/StringRef.h>
-#include <ext/bit_cast.h>
-#include <ext/map.h>
-#include <ext/range.h>
-#include <ext/size.h>
-#include <ext/scope_guard.h>
-#include "DictionaryStructure.h"
-#include "IDictionary.h"
-#include "IDictionarySource.h"
-#include <DataStreams/IBlockInputStream.h>
-#include "DictionaryHelpers.h"
-
-namespace ProfileEvents
-{
-extern const Event DictCacheKeysRequested;
-extern const Event DictCacheKeysRequestedMiss;
-extern const Event DictCacheKeysRequestedFound;
-extern const Event DictCacheKeysExpired;
-extern const Event DictCacheKeysNotFound;
-extern const Event DictCacheKeysHit;
-extern const Event DictCacheRequestTimeNs;
-extern const Event DictCacheLockWriteNs;
-extern const Event DictCacheLockReadNs;
-}
-
-namespace DB
-{
-class ComplexKeyCacheDictionary final : public IDictionaryBase
-{
-public:
-    ComplexKeyCacheDictionary(
-        const StorageID & dict_id_,
-        const DictionaryStructure & dict_struct_,
-        DictionarySourcePtr source_ptr_,
-        const DictionaryLifetime dict_lifetime_,
-        const size_t size_);
-
-    std::string getKeyDescription() const { return key_description; }
-
-    std::string getTypeName() const override { return "ComplexKeyCache"; }
-
-    size_t getBytesAllocated() const override
-    {
-        return bytes_allocated + (key_size_is_fixed ? fixed_size_keys_pool->size() : keys_pool->size())
-            + (string_arena ? string_arena->size() : 0);
-    }
-
-    size_t getQueryCount() const override { return query_count.load(std::memory_order_relaxed); }
-
-    double getHitRate() const override
-    {
-        return static_cast<double>(hit_count.load(std::memory_order_acquire)) / query_count.load(std::memory_order_relaxed);
-    }
-
-    size_t getElementCount() const override { return element_count.load(std::memory_order_relaxed); }
-
-    double getLoadFactor() const override { return static_cast<double>(element_count.load(std::memory_order_relaxed)) / size; }
-
-    bool supportUpdates() const override { return false; }
-
-    std::shared_ptr<const IExternalLoadable> clone() const override
-    {
-        return std::make_shared<ComplexKeyCacheDictionary>(getDictionaryID(), dict_struct, source_ptr->clone(), dict_lifetime, size);
-    }
-
-    const IDictionarySource * getSource() const override { return source_ptr.get(); }
-
-    const DictionaryLifetime & getLifetime() const override { return dict_lifetime; }
-
-    const DictionaryStructure & getStructure() const override { return dict_struct; }
-
-    bool isInjective(const std::string & attribute_name) const override
-    {
-        return dict_struct.attributes[&getAttribute(attribute_name) - attributes.data()].injective;
-    }
-
-    DictionaryKeyType getKeyType() const override { return DictionaryKeyType::complex; }
-
-    ColumnPtr getColumn(
-        const std::string& attribute_name,
-        const DataTypePtr & result_type,
-        const Columns & key_columns,
-        const DataTypes & key_types,
-        const ColumnPtr default_values_column) const override;
-
-    ColumnUInt8::Ptr hasKeys(const Columns & key_columns, const DataTypes & key_types) const override;
-
-    BlockInputStreamPtr getBlockInputStream(const Names & column_names, size_t max_block_size) const override;
-
-private:
-    template <typename Value>
-    using MapType = HashMapWithSavedHash<StringRef, Value, StringRefHash>;
-    template <typename Value>
-    using ContainerType = Value[];
-    template <typename Value>
-    using ContainerPtrType = std::unique_ptr<ContainerType<Value>>;
-
-    struct CellMetadata final
-    {
-        using time_point_t = std::chrono::system_clock::time_point;
-        using time_point_rep_t = time_point_t::rep;
-        using time_point_urep_t = std::make_unsigned_t<time_point_rep_t>;
-
-        static constexpr UInt64 EXPIRES_AT_MASK = std::numeric_limits<time_point_rep_t>::max();
-        static constexpr UInt64 IS_DEFAULT_MASK = ~EXPIRES_AT_MASK;
-
-        StringRef key;
-        decltype(StringRefHash{}(key)) hash;
-        /// Stores both expiration time and `is_default` flag in the most significant bit
-        time_point_urep_t data;
-
-        /// Sets expiration time, resets `is_default` flag to false
-        time_point_t expiresAt() const { return ext::safe_bit_cast<time_point_t>(data & EXPIRES_AT_MASK); }
-        void setExpiresAt(const time_point_t & t) { data = ext::safe_bit_cast<time_point_urep_t>(t); }
-
-        bool isDefault() const { return (data & IS_DEFAULT_MASK) == IS_DEFAULT_MASK; }
-        void setDefault() { data |= IS_DEFAULT_MASK; }
-    };
-
-    struct Attribute final
-    {
-        AttributeUnderlyingType type;
-        std::variant<
-            UInt8,
-            UInt16,
-            UInt32,
-            UInt64,
-            UInt128,
-            Int8,
-            Int16,
-            Int32,
-            Int64,
-            Decimal32,
-            Decimal64,
-            Decimal128,
-            Float32,
-            Float64,
-            String>
-            null_values;
-        std::variant<
-            ContainerPtrType<UInt8>,
-            ContainerPtrType<UInt16>,
-            ContainerPtrType<UInt32>,
-            ContainerPtrType<UInt64>,
-            ContainerPtrType<UInt128>,
-            ContainerPtrType<Int8>,
-            ContainerPtrType<Int16>,
-            ContainerPtrType<Int32>,
-            ContainerPtrType<Int64>,
-            ContainerPtrType<Decimal32>,
-            ContainerPtrType<Decimal64>,
-            ContainerPtrType<Decimal128>,
-            ContainerPtrType<Float32>,
-            ContainerPtrType<Float64>,
-            ContainerPtrType<StringRef>>
-            arrays;
-    };
-
-    void createAttributes();
-
-    Attribute createAttributeWithType(const AttributeUnderlyingType type, const Field & null_value);
-
-    template <typename AttributeType, typename OutputType, typename DefaultValueExtractor>
-    void getItemsNumberImpl(
-        Attribute & attribute,
-        const Columns & key_columns,
-        PaddedPODArray<OutputType> & out,
-        DefaultValueExtractor & default_value_extractor) const;
-
-    void getItemsString(
-        Attribute & attribute,
-        const Columns & key_columns,
-        ColumnString * out,
-        DictionaryDefaultValueExtractor<String> & default_value_extractor) const;
-
-    template <typename PresentKeyHandler, typename AbsentKeyHandler>
-    void update(
-        const Columns & in_key_columns,
-        const PODArray<StringRef> & in_keys,
-        const std::vector<size_t> & in_requested_rows,
-        PresentKeyHandler && on_cell_updated,
-        AbsentKeyHandler && on_key_not_found) const;
-
-    UInt64 getCellIdx(const StringRef key) const;
-
-    void setDefaultAttributeValue(Attribute & attribute, const size_t idx) const;
-
-    void setAttributeValue(Attribute & attribute, const size_t idx, const Field & value) const;
-
-    Attribute & getAttribute(const std::string & attribute_name) const;
-
-    StringRef allocKey(const size_t row, const Columns & key_columns, StringRefs & keys) const;
-
-    void freeKey(const StringRef key) const;
-
-    template <typename Arena>
-    static StringRef placeKeysInPool(
-        const size_t row,
-        const Columns & key_columns,
-        StringRefs & keys,
-        const std::vector<DictionaryAttribute> & key_attributes,
-        Arena & pool);
-
-    StringRef placeKeysInFixedSizePool(const size_t row, const Columns & key_columns) const;
-
-    static StringRef copyIntoArena(StringRef src, Arena & arena);
-    StringRef copyKey(const StringRef key) const;
-
-    struct FindResult
-    {
-        const size_t cell_idx;
-        const bool valid;
-        const bool outdated;
-    };
-
-    FindResult findCellIdx(const StringRef & key, const CellMetadata::time_point_t now, const size_t hash) const;
-    FindResult findCellIdx(const StringRef & key, const CellMetadata::time_point_t now) const
-    {
-        const auto hash = StringRefHash{}(key);
-        return findCellIdx(key, now, hash);
-    }
-
-    bool isEmptyCell(const UInt64 idx) const;
-
-    const DictionaryStructure dict_struct;
-    const DictionarySourcePtr source_ptr;
-    const DictionaryLifetime dict_lifetime;
-    const std::string key_description{dict_struct.getKeyDescription()};
-
-    mutable std::shared_mutex rw_lock;
-
-    /// Actual size will be increased to match power of 2
-    const size_t size;
-
-    /// all bits to 1  mask (size - 1) (0b1000 - 1 = 0b111)
-    const size_t size_overlap_mask;
-
-    /// Max tries to find cell, overlapped with mask: if size = 16 and start_cell=10: will try cells: 10,11,12,13,14,15,0,1,2,3
-    static constexpr size_t max_collision_length = 10;
-
-    const UInt64 zero_cell_idx{getCellIdx(StringRef{})};
-    std::map<std::string, size_t> attribute_index_by_name;
-    mutable std::vector<Attribute> attributes;
-    mutable std::vector<CellMetadata> cells{size};
-    const bool key_size_is_fixed{dict_struct.isKeySizeFixed()};
-    size_t key_size{key_size_is_fixed ? dict_struct.getKeySize() : 0};
-    std::unique_ptr<ArenaWithFreeLists> keys_pool = key_size_is_fixed ? nullptr : std::make_unique<ArenaWithFreeLists>();
-    std::unique_ptr<SmallObjectPool> fixed_size_keys_pool = key_size_is_fixed ? std::make_unique<SmallObjectPool>(key_size) : nullptr;
-    std::unique_ptr<ArenaWithFreeLists> string_arena;
-
-    mutable pcg64 rnd_engine;
-
-    mutable size_t bytes_allocated = 0;
-    mutable std::atomic<size_t> element_count{0};
-    mutable std::atomic<size_t> hit_count{0};
-    mutable std::atomic<size_t> query_count{0};
-
-    const std::chrono::time_point<std::chrono::system_clock> creation_time = std::chrono::system_clock::now();
-};
-
-}
diff --git a/src/Dictionaries/ComplexKeyDirectDictionary.cpp b/src/Dictionaries/ComplexKeyDirectDictionary.cpp
index 391b5c47980b..eedc24193a25 100644
--- a/src/Dictionaries/ComplexKeyDirectDictionary.cpp
+++ b/src/Dictionaries/ComplexKeyDirectDictionary.cpp
@@ -39,7 +39,7 @@ ColumnPtr ComplexKeyDirectDictionary::getColumn(
     const DataTypePtr & result_type,
     const Columns & key_columns,
     const DataTypes & key_types,
-    const ColumnPtr default_values_column) const
+    const ColumnPtr & default_values_column) const
 {
     dict_struct.validateKeyTypes(key_types);
 
diff --git a/src/Dictionaries/ComplexKeyDirectDictionary.h b/src/Dictionaries/ComplexKeyDirectDictionary.h
index 0e191321daa5..326ffa2924a7 100644
--- a/src/Dictionaries/ComplexKeyDirectDictionary.h
+++ b/src/Dictionaries/ComplexKeyDirectDictionary.h
@@ -66,7 +66,7 @@ class ComplexKeyDirectDictionary final : public IDictionaryBase
         const DataTypePtr & result_type,
         const Columns & key_columns,
         const DataTypes & key_types,
-        const ColumnPtr default_values_column) const override;
+        const ColumnPtr & default_values_column) const override;
 
     ColumnUInt8::Ptr hasKeys(const Columns & key_columns, const DataTypes & key_types) const override;
 
diff --git a/src/Dictionaries/ComplexKeyHashedDictionary.cpp b/src/Dictionaries/ComplexKeyHashedDictionary.cpp
index a0784b5a4171..861ce0e768d5 100644
--- a/src/Dictionaries/ComplexKeyHashedDictionary.cpp
+++ b/src/Dictionaries/ComplexKeyHashedDictionary.cpp
@@ -41,7 +41,7 @@ ColumnPtr ComplexKeyHashedDictionary::getColumn(
     const DataTypePtr & result_type,
     const Columns & key_columns,
     const DataTypes & key_types,
-    const ColumnPtr default_values_column) const
+    const ColumnPtr & default_values_column) const
 {
     dict_struct.validateKeyTypes(key_types);
 
@@ -563,7 +563,13 @@ std::vector<StringRef> ComplexKeyHashedDictionary::getKeys(const Attribute & att
 BlockInputStreamPtr ComplexKeyHashedDictionary::getBlockInputStream(const Names & column_names, size_t max_block_size) const
 {
     using BlockInputStreamType = DictionaryBlockInputStream<UInt64>;
-    return std::make_shared<BlockInputStreamType>(shared_from_this(), max_block_size, getKeys(), column_names);
+    auto vector_keys = getKeys();
+
+    PaddedPODArray<StringRef> keys;
+    keys.reserve(vector_keys.size());
+    keys.assign(vector_keys.begin(), vector_keys.end());
+
+    return std::make_shared<BlockInputStreamType>(shared_from_this(), max_block_size, keys, column_names);
 }
 
 void registerDictionaryComplexKeyHashed(DictionaryFactory & factory)
diff --git a/src/Dictionaries/ComplexKeyHashedDictionary.h b/src/Dictionaries/ComplexKeyHashedDictionary.h
index ecc720ca0b07..091974bbf435 100644
--- a/src/Dictionaries/ComplexKeyHashedDictionary.h
+++ b/src/Dictionaries/ComplexKeyHashedDictionary.h
@@ -67,7 +67,7 @@ class ComplexKeyHashedDictionary final : public IDictionaryBase
         const DataTypePtr & result_type,
         const Columns & key_columns,
         const DataTypes & key_types,
-        const ColumnPtr default_values_column) const override;
+        const ColumnPtr & default_values_column) const override;
 
     ColumnUInt8::Ptr hasKeys(const Columns & key_columns, const DataTypes & key_types) const override;
 
diff --git a/src/Dictionaries/DictionaryBlockInputStream.h b/src/Dictionaries/DictionaryBlockInputStream.h
index f045d47c2c21..71615efa7f8e 100644
--- a/src/Dictionaries/DictionaryBlockInputStream.h
+++ b/src/Dictionaries/DictionaryBlockInputStream.h
@@ -21,7 +21,7 @@ namespace ErrorCodes
     extern const int LOGICAL_ERROR;
 }
 
-
+/// TODO: Remove this class
 /* BlockInputStream implementation for external dictionaries
  * read() returns blocks consisting of the in-memory contents of the dictionaries
  */
@@ -30,12 +30,15 @@ class DictionaryBlockInputStream : public DictionaryBlockInputStreamBase
 {
 public:
     DictionaryBlockInputStream(
-        std::shared_ptr<const IDictionaryBase> dictionary, UInt64 max_block_size, PaddedPODArray<Key> && ids, const Names & column_names);
+        std::shared_ptr<const IDictionaryBase> dictionary,
+        UInt64 max_block_size,
+        PaddedPODArray<Key> && ids,
+        const Names & column_names);
 
     DictionaryBlockInputStream(
         std::shared_ptr<const IDictionaryBase> dictionary,
         UInt64 max_block_size,
-        const std::vector<StringRef> & keys,
+        const PaddedPODArray<StringRef> & keys,
         const Names & column_names);
 
     using GetColumnsFunction = std::function<ColumnsWithTypeAndName(const Columns &, const std::vector<DictionaryAttribute> & attributes)>;
@@ -55,7 +58,7 @@ class DictionaryBlockInputStream : public DictionaryBlockInputStreamBase
     String getName() const override { return "Dictionary"; }
 
 protected:
-    Block getBlock(size_t start, size_t size) const override;
+    Block getBlock(size_t start, size_t length) const override;
 
 private:
     Block
@@ -64,7 +67,7 @@ class DictionaryBlockInputStream : public DictionaryBlockInputStreamBase
     ColumnPtr getColumnFromIds(const PaddedPODArray<Key> & ids_to_fill) const;
 
     void fillKeyColumns(
-        const std::vector<StringRef> & keys,
+        const PaddedPODArray<StringRef> & keys,
         size_t start,
         size_t size,
         const DictionaryStructure & dictionary_structure,
@@ -105,7 +108,7 @@ template <typename Key>
 DictionaryBlockInputStream<Key>::DictionaryBlockInputStream(
     std::shared_ptr<const IDictionaryBase> dictionary_,
     UInt64 max_block_size_,
-    const std::vector<StringRef> & keys,
+    const PaddedPODArray<StringRef> & keys,
     const Names & column_names_)
     : DictionaryBlockInputStreamBase(keys.size(), max_block_size_)
     , dictionary(dictionary_)
@@ -260,7 +263,7 @@ ColumnPtr DictionaryBlockInputStream<Key>::getColumnFromIds(const PaddedPODArray
 
 template <typename Key>
 void DictionaryBlockInputStream<Key>::fillKeyColumns(
-    const std::vector<StringRef> & keys,
+    const PaddedPODArray<StringRef> & keys,
     size_t start,
     size_t size,
     const DictionaryStructure & dictionary_structure,
@@ -275,7 +278,7 @@ void DictionaryBlockInputStream<Key>::fillKeyColumns(
     for (auto idx : ext::range(start, size))
     {
         const auto & key = keys[idx];
-        auto ptr = key.data;
+        const auto *ptr = key.data;
         for (auto & column : columns)
             ptr = column->deserializeAndInsertFromArena(ptr);
     }
diff --git a/src/Dictionaries/DictionaryHelpers.h b/src/Dictionaries/DictionaryHelpers.h
index 0026d8848ca2..5fda5f2599ea 100644
--- a/src/Dictionaries/DictionaryHelpers.h
+++ b/src/Dictionaries/DictionaryHelpers.h
@@ -1,11 +1,13 @@
 #pragma once
 
+#include <Common/Arena.h>
 #include <Columns/IColumn.h>
 #include <Columns/ColumnDecimal.h>
 #include <Columns/ColumnString.h>
 #include <Columns/ColumnVector.h>
 #include <DataTypes/DataTypesDecimal.h>
-#include "DictionaryStructure.h"
+#include <Dictionaries/IDictionary.h>
+#include <Dictionaries/DictionaryStructure.h>
 
 namespace DB
 {
@@ -13,6 +15,190 @@ namespace DB
 namespace ErrorCodes
 {
     extern const int TYPE_MISMATCH;
+    extern const int BAD_ARGUMENTS;
+}
+
+/** Simple helper for getting default.
+  * Initialized with default value and default values column.
+  * If default values column is not null default value is taken from column.
+  * If default value is null default value is taken from initializer.
+  */
+class DefaultValueProvider final
+{
+public:
+    explicit DefaultValueProvider(Field default_value_, ColumnPtr default_values_column_ = nullptr)
+        : default_value(std::move(default_value_))
+        , default_values_column(default_values_column_)
+    {
+    }
+
+    inline bool isConstant() const { return default_values_column == nullptr; }
+
+    Field getDefaultValue(size_t row) const
+    {
+        if (default_values_column)
+            return (*default_values_column)[row];
+
+        return default_value;
+    }
+
+private:
+    Field default_value;
+    ColumnPtr default_values_column;
+};
+
+/** Support class for dictionary storages.
+
+    The main idea is that during fetch we create all columns, but fill only columns that client requested.
+
+    We need to create other columns during fetch, because in case of serialized storage we can skip
+    unnecessary columns serialized in cache with skipSerializedInArena method.
+
+    When result is fetched from the storage client of storage can filterOnlyNecessaryColumns
+    and get only columns that match attributes_names_to_fetch.
+ */
+class DictionaryStorageFetchRequest
+{
+public:
+    DictionaryStorageFetchRequest(const DictionaryStructure & structure, const Strings & attributes_names_to_fetch, Columns attributes_default_values_columns)
+        : attributes_to_fetch_names_set(attributes_names_to_fetch.begin(), attributes_names_to_fetch.end())
+        , attributes_to_fetch_filter(structure.attributes.size(), false)
+    {
+        assert(attributes_default_values_columns.size() == attributes_names_to_fetch.size());
+
+        if (attributes_to_fetch_names_set.size() != attributes_names_to_fetch.size())
+            throw Exception(ErrorCodes::BAD_ARGUMENTS, "Attribute names to fetch should be unique");
+
+        size_t attributes_size = structure.attributes.size();
+        dictionary_attributes_types.reserve(attributes_size);
+        attributes_default_value_providers.reserve(attributes_to_fetch_names_set.size());
+
+        size_t default_values_column_index = 0;
+        for (size_t i = 0; i < attributes_size; ++i)
+        {
+            const auto & dictionary_attribute = structure.attributes[i];
+            const auto & name = dictionary_attribute.name;
+            const auto & type = dictionary_attribute.type;
+            dictionary_attributes_types.emplace_back(type);
+
+            if (attributes_to_fetch_names_set.find(name) != attributes_to_fetch_names_set.end())
+            {
+                attributes_to_fetch_filter[i] = true;
+                attributes_default_value_providers.emplace_back(dictionary_attribute.null_value, attributes_default_values_columns[default_values_column_index]);
+                ++default_values_column_index;
+            }
+            else
+                attributes_default_value_providers.emplace_back(dictionary_attribute.null_value);
+        }
+    }
+
+    DictionaryStorageFetchRequest() = default;
+
+    /// Check requested attributes size
+    ALWAYS_INLINE size_t attributesSize() const
+    {
+        return dictionary_attributes_types.size();
+    }
+
+    /// Check if attribute with attribute_name was requested to fetch
+    ALWAYS_INLINE bool containsAttribute(const String & attribute_name) const
+    {
+        return attributes_to_fetch_names_set.find(attribute_name) != attributes_to_fetch_names_set.end();
+    }
+
+    /// Check if attribute with attribute_index should be filled during fetch
+    ALWAYS_INLINE bool shouldFillResultColumnWithIndex(size_t attribute_index) const
+    {
+        return attributes_to_fetch_filter[attribute_index];
+    }
+
+    const DataTypePtr & dataTypeAtIndex(size_t attribute_index) const
+    {
+        return dictionary_attributes_types[attribute_index];
+    }
+
+    const DefaultValueProvider & defaultValueProviderAtIndex(size_t attribute_index) const
+    {
+        return attributes_default_value_providers[attribute_index];
+    }
+
+    /// Create columns for each of dictionary attributes
+    MutableColumns makeAttributesResultColumns() const
+    {
+        MutableColumns result;
+        result.reserve(dictionary_attributes_types.size());
+
+        for (const auto & type : dictionary_attributes_types)
+            result.emplace_back(type->createColumn());
+
+        return result;
+    }
+
+    Columns makeAttributesResultColumnsNonMutable() const
+    {
+        Columns result;
+        result.reserve(dictionary_attributes_types.size());
+
+        for (const auto & type : dictionary_attributes_types)
+            result.emplace_back(type->createColumn());
+
+        return result;
+    }
+
+    /// Filter only requested columns
+    Columns filterRequestedColumns(MutableColumns & fetched_mutable_columns) const
+    {
+        Columns result;
+        result.reserve(dictionary_attributes_types.size());
+
+        for (size_t fetch_request_index = 0; fetch_request_index < dictionary_attributes_types.size(); ++fetch_request_index)
+            if (shouldFillResultColumnWithIndex(fetch_request_index))
+                result.emplace_back(std::move(fetched_mutable_columns[fetch_request_index]));
+
+        return result;
+    }
+private:
+    std::unordered_set<String> attributes_to_fetch_names_set;
+    std::vector<bool> attributes_to_fetch_filter;
+    std::vector<DefaultValueProvider> attributes_default_value_providers;
+    DataTypes dictionary_attributes_types;
+};
+
+static inline void insertDefaultValuesIntoColumns(
+    MutableColumns & columns,
+    const DictionaryStorageFetchRequest & fetch_request,
+    size_t row_index)
+{
+    size_t columns_size = columns.size();
+
+    for (size_t column_index = 0; column_index < columns_size; ++column_index)
+    {
+        const auto & column = columns[column_index];
+        const auto & default_value_provider = fetch_request.defaultValueProviderAtIndex(column_index);
+
+        if (fetch_request.shouldFillResultColumnWithIndex(column_index))
+            column->insert(default_value_provider.getDefaultValue(row_index));
+    }
+}
+
+/// Deserialize column value and insert it in columns.
+/// Skip unnecessary columns that were not requested from deserialization.
+static inline void deserializeAndInsertIntoColumns(
+    MutableColumns & columns,
+    const DictionaryStorageFetchRequest & fetch_request,
+    const char * place_for_serialized_columns)
+{
+    size_t columns_size = columns.size();
+
+    for (size_t column_index = 0; column_index < columns_size; ++column_index)
+    {
+        const auto & column = columns[column_index];
+
+        if (fetch_request.shouldFillResultColumnWithIndex(column_index))
+            place_for_serialized_columns = column->deserializeAndInsertFromArena(place_for_serialized_columns);
+        else
+            place_for_serialized_columns = column->skipSerializedInArena(place_for_serialized_columns);
+    }
 }
 
 /**
@@ -69,7 +255,7 @@ class DictionaryDefaultValueExtractor
 public:
     using DefaultValueType = DictionaryValueType<DictionaryAttributeType>;
 
-    DictionaryDefaultValueExtractor(DictionaryAttributeType attribute_default_value, ColumnPtr default_values_column_ = nullptr)
+    explicit DictionaryDefaultValueExtractor(DictionaryAttributeType attribute_default_value, ColumnPtr default_values_column_ = nullptr)
         : default_value(std::move(attribute_default_value))
     {
         if (default_values_column_ == nullptr)
@@ -109,6 +295,76 @@ class DictionaryDefaultValueExtractor
     bool use_default_value_from_column = false;
 };
 
+template <DictionaryKeyType key_type>
+class DictionaryKeysExtractor
+{
+public:
+    using KeyType = std::conditional_t<key_type == DictionaryKeyType::simple, UInt64, StringRef>;
+    static_assert(key_type != DictionaryKeyType::range, "Range key type is not supported by DictionaryKeysExtractor");
+
+    explicit DictionaryKeysExtractor(const Columns & key_columns, Arena & existing_arena)
+    {
+        assert(!key_columns.empty());
+
+        if constexpr (key_type == DictionaryKeyType::simple)
+            keys = getColumnVectorData(key_columns.front());
+        else
+            keys = deserializeKeyColumnsInArena(key_columns, existing_arena);
+    }
+
+
+    const PaddedPODArray<KeyType> & getKeys() const
+    {
+        return keys;
+    }
+
+private:
+    static PaddedPODArray<UInt64> getColumnVectorData(const ColumnPtr column)
+    {
+        PaddedPODArray<UInt64> result;
+
+        auto full_column = column->convertToFullColumnIfConst();
+        const auto *vector_col = checkAndGetColumn<ColumnVector<UInt64>>(full_column.get());
+
+        if (!vector_col)
+            throw Exception{ErrorCodes::TYPE_MISMATCH, "Column type mismatch for simple key expected UInt64"};
+
+        result.assign(vector_col->getData());
+
+        return result;
+    }
+
+    static PaddedPODArray<StringRef> deserializeKeyColumnsInArena(const Columns & key_columns, Arena & temporary_arena)
+    {
+        size_t keys_size = key_columns.front()->size();
+
+        PaddedPODArray<StringRef> result;
+        result.reserve(keys_size);
+
+        PaddedPODArray<StringRef> temporary_column_data(key_columns.size());
+
+        for (size_t key_index = 0; key_index < keys_size; ++key_index)
+        {
+            size_t allocated_size_for_columns = 0;
+            const char * block_start = nullptr;
+
+            for (size_t column_index = 0; column_index < key_columns.size(); ++column_index)
+            {
+                const auto & column = key_columns[column_index];
+                temporary_column_data[column_index] = column->serializeValueIntoArena(key_index, temporary_arena, block_start);
+                allocated_size_for_columns += temporary_column_data[column_index].size;
+            }
+
+            result.push_back(StringRef{block_start, allocated_size_for_columns});
+        }
+
+        return result;
+    }
+
+    PaddedPODArray<KeyType> keys;
+
+};
+
 /**
  * Returns ColumnVector data as PaddedPodArray.
 
diff --git a/src/Dictionaries/DictionaryStructure.cpp b/src/Dictionaries/DictionaryStructure.cpp
index 408e4803b1bc..25e29d7e0e82 100644
--- a/src/Dictionaries/DictionaryStructure.cpp
+++ b/src/Dictionaries/DictionaryStructure.cpp
@@ -147,7 +147,7 @@ DictionaryStructure::DictionaryStructure(const Poco::Util::AbstractConfiguration
         id.emplace(config, structure_prefix + ".id");
     else if (has_key)
     {
-        key.emplace(getAttributes(config, structure_prefix + ".key", false, false));
+        key.emplace(getAttributes(config, structure_prefix + ".key", true));
         if (key->empty())
             throw Exception{"Empty 'key' supplied", ErrorCodes::BAD_ARGUMENTS};
     }
@@ -196,7 +196,13 @@ DictionaryStructure::DictionaryStructure(const Poco::Util::AbstractConfiguration
             has_expressions = true;
     }
 
-    attributes = getAttributes(config, structure_prefix);
+    attributes = getAttributes(config, structure_prefix, false);
+
+    for (size_t i = 0; i < attributes.size(); ++i)
+    {
+        const auto & attribute_name = attributes[i].name;
+        attribute_name_to_index[attribute_name] = i;
+    }
 
     if (attributes.empty())
         throw Exception{"Dictionary has no attributes defined", ErrorCodes::BAD_ARGUMENTS};
@@ -223,24 +229,25 @@ void DictionaryStructure::validateKeyTypes(const DataTypes & key_types) const
     }
 }
 
-const DictionaryAttribute & DictionaryStructure::getAttribute(const String & attribute_name) const
+const DictionaryAttribute & DictionaryStructure::getAttribute(const std::string & attribute_name) const
 {
-    auto find_iter
-        = std::find_if(attributes.begin(), attributes.end(), [&](const auto & attribute) { return attribute.name == attribute_name; });
-    if (find_iter != attributes.end())
-        return *find_iter;
+    auto it = attribute_name_to_index.find(attribute_name);
 
-    if (key && access_to_key_from_attributes)
+    if (it == attribute_name_to_index.end())
     {
-        find_iter = std::find_if(key->begin(), key->end(), [&](const auto & attribute) { return attribute.name == attribute_name; });
-        if (find_iter != key->end())
-            return *find_iter;
+        if (!access_to_key_from_attributes)
+            throw Exception{"No such attribute '" + attribute_name + "'", ErrorCodes::BAD_ARGUMENTS};
+
+        for (const auto & key_attribute : *key)
+            if (key_attribute.name == attribute_name)
+                return key_attribute;
     }
 
-    throw Exception{"No such attribute '" + attribute_name + "'", ErrorCodes::BAD_ARGUMENTS};
+    size_t attribute_index = it->second;
+    return attributes[attribute_index];
 }
 
-const DictionaryAttribute & DictionaryStructure::getAttribute(const String & attribute_name, const DataTypePtr & type) const
+const DictionaryAttribute & DictionaryStructure::getAttribute(const std::string & attribute_name, const DataTypePtr & type) const
 {
     const auto & attribute = getAttribute(attribute_name);
 
@@ -251,6 +258,14 @@ const DictionaryAttribute & DictionaryStructure::getAttribute(const String & att
     return attribute;
 }
 
+size_t DictionaryStructure::getKeysSize() const
+{
+    if (id)
+        return 1;
+    else
+        return key->size();
+}
+
 std::string DictionaryStructure::getKeyDescription() const
 {
     if (id)
@@ -329,9 +344,12 @@ static void checkAttributeKeys(const Poco::Util::AbstractConfiguration::Keys & k
 std::vector<DictionaryAttribute> DictionaryStructure::getAttributes(
     const Poco::Util::AbstractConfiguration & config,
     const std::string & config_prefix,
-    const bool hierarchy_allowed,
-    const bool allow_null_values)
+    bool complex_key_attributes)
 {
+    /// If we request complex key attributes they does not support hierarchy and does not allow null values
+    const bool hierarchy_allowed = !complex_key_attributes;
+    const bool allow_null_values = !complex_key_attributes;
+
     Poco::Util::AbstractConfiguration::Keys config_elems;
     config.keys(config_prefix, config_elems);
     auto has_hierarchy = false;
@@ -358,7 +376,6 @@ std::vector<DictionaryAttribute> DictionaryStructure::getAttributes(
         if ((range_min && name == range_min->name) || (range_max && name == range_max->name))
             continue;
 
-
         const auto type_string = config.getString(prefix + "type");
         const auto initial_type = DataTypeFactory::instance().get(type_string);
         auto type = initial_type;
diff --git a/src/Dictionaries/DictionaryStructure.h b/src/Dictionaries/DictionaryStructure.h
index 0ff50868e264..08cc49aeb85c 100644
--- a/src/Dictionaries/DictionaryStructure.h
+++ b/src/Dictionaries/DictionaryStructure.h
@@ -1,17 +1,18 @@
 #pragma once
 
-#include <Core/Field.h>
-#include <DataTypes/IDataType.h>
-#include <IO/ReadBufferFromString.h>
-#include <Interpreters/IExternalLoadable.h>
-#include <Poco/Util/AbstractConfiguration.h>
-
 #include <map>
 #include <optional>
 #include <string>
 #include <vector>
 
 
+#include <Poco/Util/AbstractConfiguration.h>
+
+#include <Core/Field.h>
+#include <IO/ReadBufferFromString.h>
+#include <DataTypes/IDataType.h>
+#include <Interpreters/IExternalLoadable.h>
+
 namespace DB
 {
 
@@ -45,6 +46,7 @@ using DictionaryLifetime = ExternalLoadableLifetime;
 /** Holds the description of a single dictionary attribute:
 *    - name, used for lookup into dictionary and source;
 *    - type, used in conjunction with DataTypeFactory and getAttributeUnderlyingTypeByname;
+*    - nested_type, contains nested type of complex type like Nullable, Array
 *    - null_value, used as a default value for non-existent entries in the dictionary,
 *        decimal representation for numeric attributes;
 *    - hierarchical, whether this attribute defines a hierarchy;
@@ -147,6 +149,7 @@ struct DictionaryStructure final
     std::optional<DictionarySpecialAttribute> id;
     std::optional<std::vector<DictionaryAttribute>> key;
     std::vector<DictionaryAttribute> attributes;
+    std::unordered_map<std::string, size_t> attribute_name_to_index;
     std::optional<DictionaryTypedSpecialAttribute> range_min;
     std::optional<DictionaryTypedSpecialAttribute> range_max;
     bool has_expressions = false;
@@ -155,8 +158,11 @@ struct DictionaryStructure final
     DictionaryStructure(const Poco::Util::AbstractConfiguration & config, const std::string & config_prefix);
 
     void validateKeyTypes(const DataTypes & key_types) const;
-    const DictionaryAttribute & getAttribute(const String & attribute_name) const;
-    const DictionaryAttribute & getAttribute(const String & attribute_name, const DataTypePtr & type) const;
+
+    const DictionaryAttribute & getAttribute(const std::string & attribute_name) const;
+    const DictionaryAttribute & getAttribute(const std::string & attribute_name, const DataTypePtr & type) const;
+    size_t getKeysSize() const;
+
     std::string getKeyDescription() const;
     bool isKeySizeFixed() const;
     size_t getKeySize() const;
@@ -167,8 +173,7 @@ struct DictionaryStructure final
     std::vector<DictionaryAttribute> getAttributes(
         const Poco::Util::AbstractConfiguration & config,
         const std::string & config_prefix,
-        const bool hierarchy_allowed = true,
-        const bool allow_null_values = true);
+        bool complex_key_attributes);
 };
 
 }
diff --git a/src/Dictionaries/DirectDictionary.cpp b/src/Dictionaries/DirectDictionary.cpp
index b61f256b0cc6..ac995d51f097 100644
--- a/src/Dictionaries/DirectDictionary.cpp
+++ b/src/Dictionaries/DirectDictionary.cpp
@@ -138,7 +138,7 @@ ColumnPtr DirectDictionary::getColumn(
         const DataTypePtr & result_type,
         const Columns & key_columns,
         const DataTypes &,
-        const ColumnPtr default_values_column) const
+        const ColumnPtr & default_values_column) const
 {
     ColumnPtr result;
 
diff --git a/src/Dictionaries/DirectDictionary.h b/src/Dictionaries/DirectDictionary.h
index c6f4c15556b8..1fb6c8954b26 100644
--- a/src/Dictionaries/DirectDictionary.h
+++ b/src/Dictionaries/DirectDictionary.h
@@ -71,7 +71,7 @@ class DirectDictionary final : public IDictionary
         const DataTypePtr & result_type,
         const Columns & key_columns,
         const DataTypes & key_types,
-        const ColumnPtr default_values_column) const override;
+        const ColumnPtr & default_values_column) const override;
 
     ColumnUInt8::Ptr hasKeys(const Columns & key_columns, const DataTypes & key_types) const override;
 
diff --git a/src/Dictionaries/FlatDictionary.cpp b/src/Dictionaries/FlatDictionary.cpp
index f4f50a69598a..8cd6b51b65f9 100644
--- a/src/Dictionaries/FlatDictionary.cpp
+++ b/src/Dictionaries/FlatDictionary.cpp
@@ -113,7 +113,7 @@ ColumnPtr FlatDictionary::getColumn(
         const DataTypePtr & result_type,
         const Columns & key_columns,
         const DataTypes &,
-        const ColumnPtr default_values_column) const
+        const ColumnPtr & default_values_column) const
 {
     ColumnPtr result;
 
@@ -125,7 +125,7 @@ ColumnPtr FlatDictionary::getColumn(
     const auto & attribute = getAttribute(attribute_name);
     const auto & dictionary_attribute = dict_struct.getAttribute(attribute_name, result_type);
 
-    auto type_call = [&](const auto &dictionary_attribute_type)
+    auto type_call = [&](const auto & dictionary_attribute_type)
     {
         using Type = std::decay_t<decltype(dictionary_attribute_type)>;
         using AttributeType = typename Type::AttributeType;
@@ -167,7 +167,7 @@ ColumnPtr FlatDictionary::getColumn(
     if (attribute.nullable_set)
     {
         ColumnUInt8::MutablePtr col_null_map_to = ColumnUInt8::create(size, false);
-        ColumnUInt8::Container& vec_null_map_to = col_null_map_to->getData();
+        ColumnUInt8::Container & vec_null_map_to = col_null_map_to->getData();
 
         for (size_t row = 0; row < ids.size(); ++row)
         {
diff --git a/src/Dictionaries/FlatDictionary.h b/src/Dictionaries/FlatDictionary.h
index 23bfa3d37b55..f491eb286417 100644
--- a/src/Dictionaries/FlatDictionary.h
+++ b/src/Dictionaries/FlatDictionary.h
@@ -78,7 +78,7 @@ class FlatDictionary final : public IDictionary
         const DataTypePtr & result_type,
         const Columns & key_columns,
         const DataTypes & key_types,
-        const ColumnPtr default_values_column) const override;
+        const ColumnPtr & default_values_column) const override;
 
     ColumnUInt8::Ptr hasKeys(const Columns & key_columns, const DataTypes & key_types) const override;
 
diff --git a/src/Dictionaries/HashedDictionary.cpp b/src/Dictionaries/HashedDictionary.cpp
index b51f2414142c..ded446a21639 100644
--- a/src/Dictionaries/HashedDictionary.cpp
+++ b/src/Dictionaries/HashedDictionary.cpp
@@ -134,7 +134,7 @@ ColumnPtr HashedDictionary::getColumn(
     const DataTypePtr & result_type,
     const Columns & key_columns,
     const DataTypes &,
-    const ColumnPtr default_values_column) const
+    const ColumnPtr & default_values_column) const
 {
     ColumnPtr result;
 
diff --git a/src/Dictionaries/HashedDictionary.h b/src/Dictionaries/HashedDictionary.h
index 97b329a8b25f..ab37f1528ca7 100644
--- a/src/Dictionaries/HashedDictionary.h
+++ b/src/Dictionaries/HashedDictionary.h
@@ -75,7 +75,7 @@ class HashedDictionary final : public IDictionary
         const DataTypePtr & result_type,
         const Columns & key_columns,
         const DataTypes & key_types,
-        const ColumnPtr default_values_column) const override;
+        const ColumnPtr & default_values_column) const override;
 
     ColumnUInt8::Ptr hasKeys(const Columns & key_columns, const DataTypes & key_types) const override;
 
diff --git a/src/Dictionaries/ICacheDictionaryStorage.h b/src/Dictionaries/ICacheDictionaryStorage.h
new file mode 100644
index 000000000000..8db2dab536c6
--- /dev/null
+++ b/src/Dictionaries/ICacheDictionaryStorage.h
@@ -0,0 +1,124 @@
+#pragma once
+
+#include <Common/PODArray.h>
+#include <Common/HashTable/HashMap.h>
+#include <Columns/IColumn.h>
+#include <Dictionaries/DictionaryHelpers.h>
+
+namespace DB
+{
+
+struct KeyState
+{
+    enum State: uint8_t
+    {
+        not_found = 2,
+        expired = 4,
+        found = 8,
+    };
+
+    KeyState(State state_, size_t fetched_column_index_)
+        : state(state_)
+        , fetched_column_index(fetched_column_index_)
+    {}
+
+    KeyState(State state_)
+        : state(state_)
+    {}
+
+    inline bool isFound() const { return state == State::found; }
+    inline bool isExpired() const { return state == State::expired; }
+    inline bool isNotFound() const { return state == State::not_found; }
+    inline bool isDefault() const { return is_default; }
+    inline void setDefault() { is_default = true; }
+    /// Valid only if keyState is found or expired
+    inline size_t getFetchedColumnIndex() const { return fetched_column_index; }
+
+private:
+    State state = not_found;
+    size_t fetched_column_index = 0;
+    bool is_default = false;
+};
+
+/// Result of fetch from CacheDictionaryStorage
+template <typename KeyType>
+struct KeysStorageFetchResult
+{
+    /// Fetched column values
+    MutableColumns fetched_columns;
+
+    PaddedPODArray<KeyState> key_index_to_state;
+
+    size_t expired_keys_size = 0;
+
+    size_t found_keys_size = 0;
+
+    size_t not_found_keys_size = 0;
+
+    size_t default_keys_size = 0;
+
+};
+
+using SimpleKeysStorageFetchResult = KeysStorageFetchResult<UInt64>;
+using ComplexKeysStorageFetchResult = KeysStorageFetchResult<StringRef>;
+
+class ICacheDictionaryStorage
+{
+public:
+
+    virtual ~ICacheDictionaryStorage() = default;
+
+    /// Necessary if all keys are found we can return result to client without additional aggregation
+    virtual bool returnsFetchedColumnsInOrderOfRequestedKeys() const = 0;
+
+    /// Name of storage
+    virtual String getName() const = 0;
+
+    /// Does storage support simple keys
+    virtual bool supportsSimpleKeys() const = 0;
+
+    /// Fetch columns for keys, this method is not write thread safe
+    virtual SimpleKeysStorageFetchResult fetchColumnsForKeys(
+        const PaddedPODArray<UInt64> & keys,
+        const DictionaryStorageFetchRequest & fetch_request) = 0;
+
+    /// Fetch columns for keys, this method is not write thread safe
+    virtual void insertColumnsForKeys(const PaddedPODArray<UInt64> & keys, Columns columns) = 0;
+
+    /// Insert default keys
+    virtual void insertDefaultKeys(const PaddedPODArray<UInt64> & keys) = 0;
+
+    /// Return cached simple keys
+    virtual PaddedPODArray<UInt64> getCachedSimpleKeys() const = 0;
+
+    /// Does storage support complex keys
+    virtual bool supportsComplexKeys() const = 0;
+
+    /// Fetch columns for keys, this method is not write thread safe
+    virtual ComplexKeysStorageFetchResult fetchColumnsForKeys(
+        const PaddedPODArray<StringRef> & keys,
+        const DictionaryStorageFetchRequest & column_fetch_requests) = 0;
+
+    /// Fetch columns for keys, this method is not write thread safe
+    virtual void insertColumnsForKeys(const PaddedPODArray<StringRef> & keys, Columns columns) = 0;
+
+    /// Insert default keys
+    virtual void insertDefaultKeys(const PaddedPODArray<StringRef> & keys) = 0;
+
+    /// Return cached simple keys
+    virtual PaddedPODArray<StringRef> getCachedComplexKeys() const = 0;
+
+    /// Return size of keys in storage
+    virtual size_t getSize() const = 0;
+
+    /// Return maximum size of keys in storage
+    virtual size_t getMaxSize() const = 0;
+
+    /// Return bytes allocated in storage
+    virtual size_t getBytesAllocated() const = 0;
+
+};
+
+using CacheDictionaryStoragePtr = std::shared_ptr<ICacheDictionaryStorage>;
+
+}
diff --git a/src/Dictionaries/IDictionary.h b/src/Dictionaries/IDictionary.h
index e0e4c7eb880f..4d51747a6523 100644
--- a/src/Dictionaries/IDictionary.h
+++ b/src/Dictionaries/IDictionary.h
@@ -120,7 +120,36 @@ struct IDictionaryBase : public IExternalLoadable
         const DataTypePtr & result_type,
         const Columns & key_columns,
         const DataTypes & key_types,
-        const ColumnPtr default_values_column) const = 0;
+        const ColumnPtr & default_values_column) const = 0;
+
+    /** Get multiple columns from dictionary.
+      *
+      * Default implementation just calls getColumn multiple times.
+      * Subclasses can provide custom more efficient implementation.
+      */
+    virtual Columns getColumns(
+        const Strings & attribute_names,
+        const DataTypes & result_types,
+        const Columns & key_columns,
+        const DataTypes & key_types,
+        const Columns & default_values_columns) const
+    {
+        size_t attribute_names_size = attribute_names.size();
+
+        Columns result;
+        result.reserve(attribute_names_size);
+
+        for (size_t i = 0; i < attribute_names_size; ++i)
+        {
+            const auto & attribute_name = attribute_names[i];
+            const auto & result_type = result_types[i];
+            const auto & default_values_column = default_values_columns[i];
+
+            result.emplace_back(getColumn(attribute_name, result_type, key_columns, key_types, default_values_column));
+        }
+
+        return result;
+    }
 
     /** Subclass must validate key columns and key types and return ColumnUInt8 that
       * is bitmask representation of is key in dictionary or not.
diff --git a/src/Dictionaries/IDictionarySource.h b/src/Dictionaries/IDictionarySource.h
index 145b2e03dd2b..90f8b7f3a551 100644
--- a/src/Dictionaries/IDictionarySource.h
+++ b/src/Dictionaries/IDictionarySource.h
@@ -10,6 +10,7 @@ namespace DB
 {
 class IDictionarySource;
 using DictionarySourcePtr = std::unique_ptr<IDictionarySource>;
+using SharedDictionarySourcePtr = std::shared_ptr<IDictionarySource>;
 
 /** Data-provider interface for external dictionaries,
 *    abstracts out the data source (file, MySQL, ClickHouse, external program, network request et cetera)
diff --git a/src/Dictionaries/IPAddressDictionary.cpp b/src/Dictionaries/IPAddressDictionary.cpp
index 6447c76ee73e..20160d7b431d 100644
--- a/src/Dictionaries/IPAddressDictionary.cpp
+++ b/src/Dictionaries/IPAddressDictionary.cpp
@@ -267,7 +267,7 @@ ColumnPtr IPAddressDictionary::getColumn(
     const DataTypePtr & result_type,
     const Columns & key_columns,
     const DataTypes & key_types,
-    const ColumnPtr default_values_column) const
+    const ColumnPtr & default_values_column) const
 {
     validateKeyTypes(key_types);
 
@@ -290,7 +290,6 @@ ColumnPtr IPAddressDictionary::getColumn(
 
         auto column = ColumnProvider::getColumn(dictionary_attribute, size);
 
-
         if constexpr (std::is_same_v<AttributeType, String>)
         {
             auto * out = column.get();
diff --git a/src/Dictionaries/IPAddressDictionary.h b/src/Dictionaries/IPAddressDictionary.h
index 6c5cfa765e86..dcfb26c3c964 100644
--- a/src/Dictionaries/IPAddressDictionary.h
+++ b/src/Dictionaries/IPAddressDictionary.h
@@ -67,7 +67,7 @@ class IPAddressDictionary final : public IDictionaryBase
         const DataTypePtr & result_type,
         const Columns & key_columns,
         const DataTypes & key_types,
-        const ColumnPtr default_values_column) const override;
+        const ColumnPtr & default_values_column) const override;
 
     ColumnUInt8::Ptr hasKeys(const Columns & key_columns, const DataTypes & key_types) const override;
 
diff --git a/src/Dictionaries/PolygonDictionary.cpp b/src/Dictionaries/PolygonDictionary.cpp
index e0d0fa0a0e68..9cf5b47ac2b0 100644
--- a/src/Dictionaries/PolygonDictionary.cpp
+++ b/src/Dictionaries/PolygonDictionary.cpp
@@ -99,7 +99,7 @@ ColumnPtr IPolygonDictionary::getColumn(
     const DataTypePtr & result_type,
     const Columns & key_columns,
     const DataTypes &,
-    const ColumnPtr default_values_column) const
+    const ColumnPtr & default_values_column) const
 {
     ColumnPtr result;
 
diff --git a/src/Dictionaries/PolygonDictionary.h b/src/Dictionaries/PolygonDictionary.h
index a0ea189c10a7..362342c684be 100644
--- a/src/Dictionaries/PolygonDictionary.h
+++ b/src/Dictionaries/PolygonDictionary.h
@@ -86,7 +86,7 @@ class IPolygonDictionary : public IDictionaryBase
         const DataTypePtr & result_type,
         const Columns & key_columns,
         const DataTypes & key_types,
-        const ColumnPtr default_values_column) const override;
+        const ColumnPtr & default_values_column) const override;
 
     ColumnUInt8::Ptr hasKeys(const Columns & key_columns, const DataTypes & key_types) const override;
 
diff --git a/src/Dictionaries/RangeHashedDictionary.cpp b/src/Dictionaries/RangeHashedDictionary.cpp
index 9fb1a57a381b..f5be04c120d2 100644
--- a/src/Dictionaries/RangeHashedDictionary.cpp
+++ b/src/Dictionaries/RangeHashedDictionary.cpp
@@ -93,7 +93,7 @@ ColumnPtr RangeHashedDictionary::getColumn(
     const DataTypePtr & result_type,
     const Columns & key_columns,
     const DataTypes & key_types,
-    const ColumnPtr default_values_column) const
+    const ColumnPtr & default_values_column) const
 {
     ColumnPtr result;
 
diff --git a/src/Dictionaries/RangeHashedDictionary.h b/src/Dictionaries/RangeHashedDictionary.h
index 80cf47eb93b1..1f93fa757758 100644
--- a/src/Dictionaries/RangeHashedDictionary.h
+++ b/src/Dictionaries/RangeHashedDictionary.h
@@ -61,7 +61,7 @@ class RangeHashedDictionary final : public IDictionaryBase
         const DataTypePtr & result_type,
         const Columns & key_columns,
         const DataTypes & key_types,
-        const ColumnPtr default_values_column) const override;
+        const ColumnPtr & default_values_column) const override;
 
     ColumnUInt8::Ptr hasKeys(const Columns & key_columns, const DataTypes & key_types) const override;
 
diff --git a/src/Dictionaries/SSDCacheDictionary.cpp b/src/Dictionaries/SSDCacheDictionary.cpp
deleted file mode 100644
index cbeea39decb8..000000000000
--- a/src/Dictionaries/SSDCacheDictionary.cpp
+++ /dev/null
@@ -1,1667 +0,0 @@
-#if defined(OS_LINUX) || defined(__FreeBSD__)
-
-#include "SSDCacheDictionary.h"
-
-#include <algorithm>
-#include <Columns/ColumnsNumber.h>
-#include <Common/typeid_cast.h>
-#include <Common/ProfileEvents.h>
-#include <Common/ProfilingScopedRWLock.h>
-#include <Common/MemorySanitizer.h>
-#include <DataStreams/IBlockInputStream.h>
-#include "DictionaryBlockInputStream.h"
-#include "DictionaryFactory.h"
-#include <IO/AIO.h>
-#include <IO/ReadHelpers.h>
-#include <IO/WriteHelpers.h>
-#include <ext/chrono_io.h>
-#include <ext/map.h>
-#include <ext/range.h>
-#include <ext/size.h>
-#include <ext/bit_cast.h>
-#include <filesystem>
-#include <city.h>
-#include <fcntl.h>
-#include <Functions/FunctionHelpers.h>
-#include <DataTypes/DataTypesDecimal.h>
-
-namespace ProfileEvents
-{
-    extern const Event DictCacheKeysRequested;
-    extern const Event DictCacheKeysRequestedMiss;
-    extern const Event DictCacheKeysRequestedFound;
-    extern const Event DictCacheKeysExpired;
-    extern const Event DictCacheKeysNotFound;
-    extern const Event DictCacheKeysHit;
-    extern const Event DictCacheRequestTimeNs;
-    extern const Event DictCacheRequests;
-    extern const Event DictCacheLockWriteNs;
-    extern const Event DictCacheLockReadNs;
-    extern const Event FileOpen;
-    extern const Event WriteBufferAIOWrite;
-    extern const Event WriteBufferAIOWriteBytes;
-}
-
-namespace CurrentMetrics
-{
-    extern const Metric DictCacheRequests;
-    extern const Metric Write;
-}
-
-namespace DB
-{
-
-namespace ErrorCodes
-{
-    extern const int AIO_READ_ERROR;
-    extern const int AIO_WRITE_ERROR;
-    extern const int BAD_ARGUMENTS;
-    extern const int CACHE_DICTIONARY_UPDATE_FAIL;
-    extern const int CANNOT_ALLOCATE_MEMORY;
-    extern const int CANNOT_CREATE_DIRECTORY;
-    extern const int CANNOT_FSYNC;
-    extern const int CANNOT_IO_GETEVENTS;
-    extern const int CANNOT_IO_SUBMIT;
-    extern const int CANNOT_OPEN_FILE;
-    extern const int CORRUPTED_DATA;
-    extern const int FILE_DOESNT_EXIST;
-    extern const int LOGICAL_ERROR;
-    extern const int TYPE_MISMATCH;
-    extern const int UNSUPPORTED_METHOD;
-}
-
-namespace
-{
-    constexpr size_t DEFAULT_SSD_BLOCK_SIZE_BYTES = DEFAULT_AIO_FILE_BLOCK_SIZE;
-    constexpr size_t DEFAULT_FILE_SIZE_BYTES = 4 * 1024 * 1024 * 1024ULL;
-    constexpr size_t DEFAULT_PARTITIONS_COUNT = 16;
-    constexpr size_t DEFAULT_READ_BUFFER_SIZE_BYTES = 16 * DEFAULT_SSD_BLOCK_SIZE_BYTES;
-    constexpr size_t DEFAULT_WRITE_BUFFER_SIZE_BYTES = DEFAULT_SSD_BLOCK_SIZE_BYTES;
-
-    constexpr size_t DEFAULT_MAX_STORED_KEYS = 100000;
-
-    constexpr size_t BUFFER_ALIGNMENT = DEFAULT_AIO_FILE_BLOCK_SIZE;
-    constexpr size_t BLOCK_CHECKSUM_SIZE_BYTES = 8;
-    constexpr size_t BLOCK_SPECIAL_FIELDS_SIZE_BYTES = 4;
-
-    constexpr UInt64 KEY_METADATA_EXPIRES_AT_MASK = std::numeric_limits<std::chrono::system_clock::time_point::rep>::max();
-    constexpr UInt64 KEY_METADATA_IS_DEFAULT_MASK = ~KEY_METADATA_EXPIRES_AT_MASK;
-
-    constexpr size_t KEY_IN_MEMORY_BIT = 63;
-    constexpr size_t KEY_IN_MEMORY = (1ULL << KEY_IN_MEMORY_BIT);
-    constexpr size_t BLOCK_INDEX_BITS = 32;
-    constexpr size_t INDEX_IN_BLOCK_BITS = 16;
-    constexpr size_t INDEX_IN_BLOCK_MASK = (1ULL << INDEX_IN_BLOCK_BITS) - 1;
-    constexpr size_t BLOCK_INDEX_MASK = ((1ULL << (BLOCK_INDEX_BITS + INDEX_IN_BLOCK_BITS)) - 1) ^ INDEX_IN_BLOCK_MASK;
-
-    constexpr size_t NOT_EXISTS = -1;
-
-    constexpr UInt8 HAS_NOT_FOUND = 2;
-
-    const std::string BIN_FILE_EXT = ".bin";
-
-    int preallocateDiskSpace(int fd, size_t len)
-    {
-        #if defined(__FreeBSD__)
-            return posix_fallocate(fd, 0, len);
-        #else
-            return fallocate(fd, 0, 0, len);
-        #endif
-    }
-}
-
-SSDCachePartition::Metadata::time_point_t SSDCachePartition::Metadata::expiresAt() const
-{
-    return ext::safe_bit_cast<time_point_t>(data & KEY_METADATA_EXPIRES_AT_MASK);
-}
-
-void SSDCachePartition::Metadata::setExpiresAt(const time_point_t & t)
-{
-    data = ext::safe_bit_cast<time_point_urep_t>(t);
-}
-
-bool SSDCachePartition::Metadata::isDefault() const
-{
-    return (data & KEY_METADATA_IS_DEFAULT_MASK) == KEY_METADATA_IS_DEFAULT_MASK;
-}
-void SSDCachePartition::Metadata::setDefault()
-{
-    data |= KEY_METADATA_IS_DEFAULT_MASK;
-}
-
-bool SSDCachePartition::Index::inMemory() const
-{
-    return (index & KEY_IN_MEMORY) == KEY_IN_MEMORY;
-}
-
-bool SSDCachePartition::Index::exists() const
-{
-    return index != NOT_EXISTS;
-}
-
-void SSDCachePartition::Index::setNotExists()
-{
-    index = NOT_EXISTS;
-}
-
-void SSDCachePartition::Index::setInMemory(const bool in_memory)
-{
-    index = (index & ~KEY_IN_MEMORY) | (static_cast<size_t>(in_memory) << KEY_IN_MEMORY_BIT);
-}
-
-size_t SSDCachePartition::Index::getAddressInBlock() const
-{
-    return index & INDEX_IN_BLOCK_MASK;
-}
-
-void SSDCachePartition::Index::setAddressInBlock(const size_t address_in_block)
-{
-    index = (index & ~INDEX_IN_BLOCK_MASK) | address_in_block;
-}
-
-size_t SSDCachePartition::Index::getBlockId() const
-{
-    return (index & BLOCK_INDEX_MASK) >> INDEX_IN_BLOCK_BITS;
-}
-
-void SSDCachePartition::Index::setBlockId(const size_t block_id)
-{
-    index = (index & ~BLOCK_INDEX_MASK) | (block_id << INDEX_IN_BLOCK_BITS);
-}
-
-SSDCachePartition::SSDCachePartition(
-        const AttributeUnderlyingType & /* key_structure */,
-        const std::vector<AttributeUnderlyingType> & attributes_structure_,
-        const std::string & dir_path,
-        const size_t file_id_,
-        const size_t max_size_,
-        const size_t block_size_,
-        const size_t read_buffer_size_,
-        const size_t write_buffer_size_,
-        const size_t max_stored_keys_)
-    : file_id(file_id_)
-    , max_size(max_size_)
-    , block_size(block_size_)
-    , read_buffer_size(read_buffer_size_)
-    , write_buffer_size(write_buffer_size_)
-    , max_stored_keys(max_stored_keys_)
-    , path(dir_path + "/" + std::to_string(file_id))
-    , key_to_index(max_stored_keys)
-    , attributes_structure(attributes_structure_)
-{
-    keys_buffer.type = AttributeUnderlyingType::utUInt64;
-    keys_buffer.values = SSDCachePartition::Attribute::Container<UInt64>();
-
-    if (!std::filesystem::create_directories(std::filesystem::path{dir_path}))
-    {
-        if (std::filesystem::exists(std::filesystem::path{dir_path}))
-            LOG_INFO(&Poco::Logger::get("SSDCachePartition::Constructor"), "Using existing directory '{}' for cache-partition", dir_path);
-        else
-            throw Exception{"Failed to create directories.", ErrorCodes::CANNOT_CREATE_DIRECTORY};
-    }
-
-    {
-        ProfileEvents::increment(ProfileEvents::FileOpen);
-
-        const std::string filename = path + BIN_FILE_EXT;
-        fd = ::open(filename.c_str(), O_RDWR | O_CREAT | O_TRUNC | O_DIRECT, 0666);
-        if (fd == -1)
-        {
-            auto error_code = (errno == ENOENT) ? ErrorCodes::FILE_DOESNT_EXIST : ErrorCodes::CANNOT_OPEN_FILE;
-            throwFromErrnoWithPath("Cannot open file " + filename, filename, error_code);
-        }
-
-        if (preallocateDiskSpace(fd, max_size * block_size) < 0)
-        {
-            throwFromErrnoWithPath("Cannot preallocate space for the file " + filename, filename, ErrorCodes::CANNOT_ALLOCATE_MEMORY);
-        }
-    }
-}
-
-SSDCachePartition::~SSDCachePartition()
-{
-    std::unique_lock lock(rw_lock);
-    ::close(fd);
-}
-
-size_t SSDCachePartition::appendDefaults(
-    const Attribute & new_keys, const PaddedPODArray<Metadata> & metadata, const size_t begin)
-{
-    return appendBlock(new_keys, Attributes{}, metadata, begin);
-}
-
-size_t SSDCachePartition::appendBlock(
-    const Attribute & new_keys, const Attributes & new_attributes, const PaddedPODArray<Metadata> & metadata, const size_t begin)
-{
-    std::unique_lock lock(rw_lock);
-    if (!new_attributes.empty() && new_attributes.size() != attributes_structure.size())
-        throw Exception{"Wrong columns number in block.", ErrorCodes::BAD_ARGUMENTS};
-
-    const auto & ids = std::get<Attribute::Container<UInt64>>(new_keys.values);
-    auto & ids_buffer = std::get<Attribute::Container<UInt64>>(keys_buffer.values);
-
-    if (!memory)
-        memory.emplace(block_size * write_buffer_size, BUFFER_ALIGNMENT);
-
-    auto init_write_buffer = [&]()
-    {
-        write_buffer.emplace(memory->data() + current_memory_block_id * block_size, block_size);
-        uint64_t tmp = 0;
-        write_buffer->write(reinterpret_cast<char*>(&tmp), BLOCK_CHECKSUM_SIZE_BYTES);
-        write_buffer->write(reinterpret_cast<char*>(&tmp), BLOCK_SPECIAL_FIELDS_SIZE_BYTES);
-        keys_in_block = 0;
-    };
-
-    if (!write_buffer)
-        init_write_buffer();
-
-    bool flushed = false;
-    auto finish_block = [&]()
-    {
-        write_buffer.reset();
-        std::memcpy(memory->data() + block_size * current_memory_block_id + BLOCK_CHECKSUM_SIZE_BYTES, &keys_in_block, sizeof(keys_in_block)); // set count
-        uint64_t checksum = CityHash_v1_0_2::CityHash64(memory->data() + block_size * current_memory_block_id + BLOCK_CHECKSUM_SIZE_BYTES, block_size - BLOCK_CHECKSUM_SIZE_BYTES); // checksum
-        std::memcpy(memory->data() + block_size * current_memory_block_id, &checksum, sizeof(checksum));
-        if (++current_memory_block_id == write_buffer_size)
-            flush();
-        flushed = true;
-    };
-
-    for (size_t index = begin; index < ids.size();)
-    {
-        Index cache_index;
-        cache_index.setInMemory(true);
-        cache_index.setBlockId(current_memory_block_id);
-        if (current_memory_block_id >= write_buffer_size)
-            throw DB::Exception("lel " + std::to_string(current_memory_block_id) + " " +
-                std::to_string(write_buffer_size) + " " + std::to_string(index), ErrorCodes::LOGICAL_ERROR);
-
-        cache_index.setAddressInBlock(write_buffer->offset());
-
-        flushed = false;
-        if (2 * sizeof(UInt64) > write_buffer->available()) // place for key and metadata
-        {
-            finish_block();
-        }
-        else
-        {
-            writeBinary(ids[index], *write_buffer);
-            writeBinary(metadata[index].data, *write_buffer);
-        }
-
-        for (const auto & attribute : new_attributes)
-        {
-            if (flushed)
-                break;
-            switch (attribute.type)
-            {
-#define DISPATCH(TYPE) \
-            case AttributeUnderlyingType::ut##TYPE: \
-                { \
-                    if (sizeof(TYPE) > write_buffer->available()) \
-                    { \
-                        finish_block(); \
-                        continue; \
-                    } \
-                    else \
-                    { \
-                        const auto & values = std::get<Attribute::Container<TYPE>>(attribute.values); /* NOLINT */ \
-                        writeBinary(values[index], *write_buffer); \
-                    } \
-                } \
-                break;
-
-                DISPATCH(UInt8)
-                DISPATCH(UInt16)
-                DISPATCH(UInt32)
-                DISPATCH(UInt64)
-                DISPATCH(UInt128)
-                DISPATCH(Int8)
-                DISPATCH(Int16)
-                DISPATCH(Int32)
-                DISPATCH(Int64)
-                DISPATCH(Decimal32)
-                DISPATCH(Decimal64)
-                DISPATCH(Decimal128)
-                DISPATCH(Float32)
-                DISPATCH(Float64)
-#undef DISPATCH
-
-            case AttributeUnderlyingType::utString:
-                {
-                    const auto & value = std::get<Attribute::Container<String>>(attribute.values)[index];
-                    if (sizeof(UInt64) + value.size() > write_buffer->available())
-                    {
-                        finish_block();
-                        continue;
-                    }
-                    else
-                    {
-                        writeStringBinary(value, *write_buffer);
-                    }
-                }
-                break;
-            }
-        }
-
-        if (!flushed)
-        {
-            key_to_index.set(ids[index], cache_index);
-            ids_buffer.push_back(ids[index]);
-            ++index;
-            ++keys_in_block;
-        }
-        else  // next block in write buffer or flushed to ssd
-        {
-            init_write_buffer();
-        }
-    }
-    return ids.size() - begin;
-}
-
-void SSDCachePartition::flush()
-{
-    if (current_file_block_id >= max_size)
-        clearOldestBlocks();
-
-    const auto & ids = std::get<Attribute::Container<UInt64>>(keys_buffer.values);
-    if (ids.empty())
-        return;
-    LOG_INFO(&Poco::Logger::get("SSDCachePartition::flush()"), "Flushing to Disk.");
-
-    AIOContext aio_context{1};
-
-    iocb write_request{};
-    iocb * write_request_ptr{&write_request};
-
-#if defined(__FreeBSD__)
-    write_request.aio.aio_lio_opcode = LIO_WRITE;
-    write_request.aio.aio_fildes = fd;
-    write_request.aio.aio_buf = reinterpret_cast<volatile void *>(memory->data());
-    write_request.aio.aio_nbytes = block_size * write_buffer_size;
-    write_request.aio.aio_offset = (current_file_block_id % max_size) * block_size;
-#else
-    write_request.aio_lio_opcode = IOCB_CMD_PWRITE;
-    write_request.aio_fildes = fd;
-    write_request.aio_buf = reinterpret_cast<UInt64>(memory->data());
-    write_request.aio_nbytes = block_size * write_buffer_size;
-    write_request.aio_offset = (current_file_block_id % max_size) * block_size;
-#endif
-
-    while (io_submit(aio_context.ctx, 1, &write_request_ptr) < 0)
-    {
-        if (errno != EINTR)
-            throw Exception("Cannot submit request for asynchronous IO on file " + path + BIN_FILE_EXT, ErrorCodes::CANNOT_IO_SUBMIT);
-    }
-
-    CurrentMetrics::Increment metric_increment_write{CurrentMetrics::Write};
-
-    io_event event;
-    while (io_getevents(aio_context.ctx, 1, 1, &event, nullptr) < 0)
-    {
-        if (errno != EINTR)
-            throw Exception("Failed to wait for asynchronous IO completion on file " + path + BIN_FILE_EXT, ErrorCodes::CANNOT_IO_GETEVENTS);
-    }
-
-    // Unpoison the memory returned from an uninstrumented system function.
-    __msan_unpoison(&event, sizeof(event));
-
-    ssize_t  bytes_written;
-#if defined(__FreeBSD__)
-    bytes_written = aio_return(reinterpret_cast<struct aiocb *>(event.udata));
-#else
-    bytes_written = event.res;
-#endif
-
-    ProfileEvents::increment(ProfileEvents::WriteBufferAIOWrite);
-    ProfileEvents::increment(ProfileEvents::WriteBufferAIOWriteBytes, bytes_written);
-
-    if (bytes_written != static_cast<decltype(bytes_written)>(block_size * write_buffer_size))
-        throw Exception("Not all data was written for asynchronous IO on file " + path + BIN_FILE_EXT + ". returned: " + std::to_string(bytes_written), ErrorCodes::AIO_WRITE_ERROR);
-
-    if (::fsync(fd) < 0)
-        throwFromErrnoWithPath("Cannot fsync " + path + BIN_FILE_EXT, path + BIN_FILE_EXT, ErrorCodes::CANNOT_FSYNC);
-
-    /// commit changes in index
-    for (const auto & id : ids)
-    {
-        Index index;
-        if (key_to_index.get(id, index))
-        {
-            if (index.inMemory()) // Row can be inserted in the buffer twice, so we need to move to ssd only the last index.
-            {
-                index.setInMemory(false);
-                index.setBlockId((current_file_block_id % max_size) + index.getBlockId());
-            }
-            key_to_index.set(id, index);
-        }
-    }
-
-    current_file_block_id += write_buffer_size;
-    current_memory_block_id = 0;
-
-    /// clear buffer
-    std::visit([](auto & attr) { attr.clear(); }, keys_buffer.values);
-}
-
-template <typename Out, typename GetDefault>
-void SSDCachePartition::getValue(const size_t attribute_index, const PaddedPODArray<UInt64> & ids,
-    ResultArrayType<Out> & out, std::vector<bool> & found, GetDefault & default_value_extractor,
-    std::chrono::system_clock::time_point now) const
-{
-    auto set_value = [&](const size_t index, ReadBuffer & buf)
-    {
-        buf.ignore(sizeof(Key)); // key
-        Metadata metadata;
-        readBinary(metadata.data, buf);
-        if (metadata.expiresAt() > now)
-        {
-            if (metadata.isDefault())
-                out[index] = default_value_extractor[index];
-            else
-            {
-                ignoreFromBufferToAttributeIndex(attribute_index, buf);
-                readBinary(out[index], buf);
-            }
-            found[index] = true;
-        }
-    };
-
-    getImpl(ids, set_value, found);
-}
-
-void SSDCachePartition::getString(const size_t attribute_index, const PaddedPODArray<UInt64> & ids,
-    StringRefs & refs, ArenaWithFreeLists & arena, std::vector<bool> & found, std::vector<size_t> & default_ids,
-    std::chrono::system_clock::time_point now) const
-{
-    auto set_value = [&](const size_t index, ReadBuffer & buf)
-    {
-        buf.ignore(sizeof(Key)); // key
-        Metadata metadata;
-        readBinary(metadata.data, buf);
-
-        if (metadata.expiresAt() > now)
-        {
-            if (metadata.isDefault())
-                default_ids.push_back(index);
-            else
-            {
-                ignoreFromBufferToAttributeIndex(attribute_index, buf);
-                size_t size = 0;
-                readVarUInt(size, buf);
-                char * string_ptr = arena.alloc(size);
-                memcpy(string_ptr, buf.position(), size);
-                refs[index].data = string_ptr;
-                refs[index].size = size;
-            }
-            found[index] = true;
-        }
-    };
-
-    getImpl(ids, set_value, found);
-}
-
-void SSDCachePartition::has(const PaddedPODArray<UInt64> & ids, ResultArrayType<UInt8> & out,
-    std::vector<bool> & found, std::chrono::system_clock::time_point now) const
-{
-    auto set_value = [&](const size_t index, ReadBuffer & buf)
-    {
-        buf.ignore(sizeof(Key)); // key
-        Metadata metadata;
-        readBinary(metadata.data, buf);
-
-        if (metadata.expiresAt() > now)
-            out[index] = !metadata.isDefault();
-    };
-
-    getImpl(ids, set_value, found);
-}
-
-template <typename SetFunc>
-void SSDCachePartition::getImpl(const PaddedPODArray<UInt64> & ids, SetFunc & set,
-    std::vector<bool> & found) const
-{
-    std::shared_lock lock(rw_lock);
-    PaddedPODArray<Index> indices(ids.size());
-    for (size_t i = 0; i < ids.size(); ++i)
-    {
-        Index index;
-        if (found[i])
-            indices[i].setNotExists();
-        else if (key_to_index.get(ids[i], index))
-        {
-            indices[i] = index;
-        }
-        else
-            indices[i].setNotExists();
-    }
-
-    getValueFromMemory(indices, set);
-    getValueFromStorage(indices, set);
-}
-
-template <typename SetFunc>
-void SSDCachePartition::getValueFromMemory(const PaddedPODArray<Index> & indices, SetFunc & set) const
-{
-    // Do not check checksum while reading from memory.
-    for (size_t i = 0; i < indices.size(); ++i)
-    {
-        const auto & index = indices[i];
-        if (index.exists() && index.inMemory())
-        {
-            const size_t offset = index.getBlockId() * block_size + index.getAddressInBlock();
-
-            ReadBufferFromMemory read_buffer(memory->data() + offset, block_size * write_buffer_size - offset);
-            set(i, read_buffer);
-        }
-    }
-}
-
-template <typename SetFunc>
-void SSDCachePartition::getValueFromStorage(const PaddedPODArray<Index> & indices, SetFunc & set) const
-{
-    std::vector<std::pair<Index, size_t>> index_to_out;
-    for (size_t i = 0; i < indices.size(); ++i)
-    {
-        const auto & index = indices[i];
-        if (index.exists() && !index.inMemory())
-            index_to_out.emplace_back(index, i);
-    }
-    if (index_to_out.empty())
-        return;
-
-    /// sort by (block_id, offset_in_block)
-    std::sort(std::begin(index_to_out), std::end(index_to_out));
-
-    Memory read_buffer(block_size * read_buffer_size, BUFFER_ALIGNMENT);
-
-    std::vector<iocb> requests;
-    std::vector<iocb*> pointers;
-    std::vector<std::vector<size_t>> blocks_to_indices;
-    requests.reserve(index_to_out.size());
-    pointers.reserve(index_to_out.size());
-    blocks_to_indices.reserve(index_to_out.size());
-    for (size_t i = 0; i < index_to_out.size(); ++i)
-    {
-        #if defined(__FreeBSD__)
-        const size_t back_offset = requests.empty() ? -1 : static_cast<size_t>(requests.back().aio.aio_offset);
-        #else
-        const size_t back_offset = requests.empty() ? -1 : static_cast<size_t>(requests.back().aio_offset);
-        #endif
-
-        if (!requests.empty() && back_offset == index_to_out[i].first.getBlockId() * block_size)
-        {
-            blocks_to_indices.back().push_back(i);
-            continue;
-        }
-
-        iocb request{};
-#if defined(__FreeBSD__)
-        request.aio.aio_lio_opcode = LIO_READ;
-        request.aio.aio_fildes = fd;
-        request.aio.aio_buf = reinterpret_cast<volatile void *>(
-            reinterpret_cast<UInt64>(read_buffer.data()) + block_size * (requests.size() % read_buffer_size));
-        request.aio.aio_nbytes = block_size;
-        request.aio.aio_offset = index_to_out[i].first.getBlockId() * block_size;
-        request.aio_data = requests.size();
-#else
-        request.aio_lio_opcode = IOCB_CMD_PREAD;
-        request.aio_fildes = fd;
-        request.aio_buf = reinterpret_cast<UInt64>(read_buffer.data()) + block_size * (requests.size() % read_buffer_size);
-        request.aio_nbytes = block_size;
-        request.aio_offset = index_to_out[i].first.getBlockId() * block_size;
-        request.aio_data = requests.size();
-#endif
-        requests.push_back(request);
-        pointers.push_back(&requests.back());
-        blocks_to_indices.emplace_back();
-        blocks_to_indices.back().push_back(i);
-    }
-
-    AIOContext aio_context(read_buffer_size);
-
-    std::vector<bool> processed(requests.size(), false);
-    std::vector<io_event> events(requests.size());
-    #if defined(__linux__)
-    for (auto & event : events)
-        event.res = -1;
-    #endif
-
-    size_t to_push = 0;
-    size_t to_pop = 0;
-    while (to_pop < requests.size())
-    {
-        int popped = 0;
-        while (to_pop < to_push && (popped = io_getevents(aio_context.ctx, to_push - to_pop, to_push - to_pop, &events[to_pop], nullptr)) <= 0)
-        {
-            if (errno != EINTR)
-                throwFromErrno("io_getevents: Failed to get an event for asynchronous IO", ErrorCodes::CANNOT_IO_GETEVENTS);
-        }
-
-        for (size_t i = to_pop; i < to_pop + popped; ++i)
-        {
-            const auto request_id = events[i].data;
-            const auto & request = requests[request_id];
-
-            #if defined(__FreeBSD__)
-            const auto bytes_written = aio_return(reinterpret_cast<struct aiocb *>(events[i].udata));
-            #else
-            const auto bytes_written = events[i].res;
-            #endif
-
-            if (bytes_written != static_cast<ssize_t>(block_size))
-            {
-                #if defined(__FreeBSD__)
-                    throw Exception("AIO failed to read file " + path + BIN_FILE_EXT + ".", ErrorCodes::AIO_READ_ERROR);
-                #else
-                    throw Exception("AIO failed to read file " + path + BIN_FILE_EXT + ". " +
-                        "request_id= " + std::to_string(request.aio_data) + "/ " + std::to_string(requests.size()) +
-                        ", aio_nbytes=" + std::to_string(request.aio_nbytes) + ", aio_offset=" + std::to_string(request.aio_offset) +
-                        ", returned=" + std::to_string(events[i].res) + ", errno=" + std::to_string(errno), ErrorCodes::AIO_READ_ERROR);
-                #endif
-            }
-            #if defined(__FreeBSD__)
-            const char* buf_ptr = reinterpret_cast<char *>(reinterpret_cast<UInt64>(request.aio.aio_buf));
-            #else
-            const auto* buf_ptr = reinterpret_cast<char *>(request.aio_buf);
-            #endif
-            __msan_unpoison(buf_ptr, block_size);
-            uint64_t checksum = 0;
-            ReadBufferFromMemory buf_special(buf_ptr, block_size);
-            readBinary(checksum, buf_special);
-            uint64_t calculated_checksum = CityHash_v1_0_2::CityHash64(buf_ptr + BLOCK_CHECKSUM_SIZE_BYTES, block_size - BLOCK_CHECKSUM_SIZE_BYTES);
-            if (checksum != calculated_checksum)
-            {
-                throw Exception("Cache data corrupted. From block = " + std::to_string(checksum) + " calculated = " + std::to_string(calculated_checksum) + ".", ErrorCodes::CORRUPTED_DATA);
-            }
-
-            for (const size_t idx : blocks_to_indices[request_id])
-            {
-                const auto & [file_index, out_index] = index_to_out[idx];
-                ReadBufferFromMemory buf(
-                        buf_ptr + file_index.getAddressInBlock(),
-                        block_size - file_index.getAddressInBlock());
-                set(out_index, buf);
-            }
-
-            processed[request_id] = true;
-        }
-
-        while (to_pop < requests.size() && processed[to_pop])
-            ++to_pop;
-
-        /// add new io tasks
-        const int new_tasks_count = std::min(read_buffer_size - (to_push - to_pop), requests.size() - to_push);
-
-        int pushed = 0;
-        while (new_tasks_count > 0 && (pushed = io_submit(aio_context.ctx, new_tasks_count, &pointers[to_push])) <= 0)
-        {
-            if (errno != EINTR)
-                throwFromErrno("io_submit: Failed to submit a request for asynchronous IO", ErrorCodes::CANNOT_IO_SUBMIT);
-        }
-        to_push += pushed;
-    }
-}
-
-void SSDCachePartition::clearOldestBlocks()
-{
-    // write_buffer_size, because we need to erase the whole buffer.
-    Memory read_buffer_memory(block_size * write_buffer_size, BUFFER_ALIGNMENT);
-
-    iocb request{};
-#if defined(__FreeBSD__)
-    request.aio.aio_lio_opcode = LIO_READ;
-    request.aio.aio_fildes = fd;
-    request.aio.aio_buf = reinterpret_cast<volatile void *>(reinterpret_cast<UInt64>(read_buffer_memory.data()));
-    request.aio.aio_nbytes = block_size * write_buffer_size;
-    request.aio.aio_offset = (current_file_block_id % max_size) * block_size;
-    request.aio_data = 0;
-#else
-    request.aio_lio_opcode = IOCB_CMD_PREAD;
-    request.aio_fildes = fd;
-    request.aio_buf = reinterpret_cast<UInt64>(read_buffer_memory.data());
-    request.aio_nbytes = block_size * write_buffer_size;
-    request.aio_offset = (current_file_block_id % max_size) * block_size;
-    request.aio_data = 0;
-#endif
-
-    {
-        iocb* request_ptr = &request;
-        io_event event{};
-        AIOContext aio_context(1);
-
-        while (io_submit(aio_context.ctx, 1, &request_ptr) != 1)
-        {
-            if (errno != EINTR)
-                throwFromErrno("io_submit: Failed to submit a request for asynchronous IO", ErrorCodes::CANNOT_IO_SUBMIT);
-        }
-
-        while (io_getevents(aio_context.ctx, 1, 1, &event, nullptr) != 1)
-        {
-            if (errno != EINTR)
-                throwFromErrno("io_getevents: Failed to get an event for asynchronous IO", ErrorCodes::CANNOT_IO_GETEVENTS);
-        }
-
-#if defined(__FreeBSD__)
-        if (aio_return(reinterpret_cast<struct aiocb *>(event.udata)) != static_cast<ssize_t>(request.aio.aio_nbytes))
-            throw Exception("GC: AIO failed to read file " + path + BIN_FILE_EXT + ".", ErrorCodes::AIO_READ_ERROR);
-#else
-        if (event.res != static_cast<ssize_t>(request.aio_nbytes))
-            throw Exception("GC: AIO failed to read file " + path + BIN_FILE_EXT + ". " +
-                "aio_nbytes=" + std::to_string(request.aio_nbytes) +
-                ", returned=" + std::to_string(event.res) + ".", ErrorCodes::AIO_READ_ERROR);
-#endif
-        __msan_unpoison(read_buffer_memory.data(), read_buffer_memory.size());
-    }
-
-    std::vector<UInt64> keys;
-    keys.reserve(write_buffer_size);
-
-    for (size_t i = 0; i < write_buffer_size; ++i)
-    {
-        ReadBufferFromMemory read_buffer(read_buffer_memory.data() + i * block_size, block_size);
-
-        uint64_t checksum = 0;
-        readBinary(checksum, read_buffer);
-        uint64_t calculated_checksum = CityHash_v1_0_2::CityHash64(read_buffer_memory.data() + i * block_size + BLOCK_CHECKSUM_SIZE_BYTES, block_size - BLOCK_CHECKSUM_SIZE_BYTES);
-        if (checksum != calculated_checksum)
-        {
-            throw Exception("Cache data corrupted. From block = " + std::to_string(checksum) + " calculated = " + std::to_string(calculated_checksum) + ".", ErrorCodes::CORRUPTED_DATA);
-        }
-
-        uint32_t keys_in_current_block = 0;
-        readBinary(keys_in_current_block, read_buffer);
-
-        for (uint32_t j = 0; j < keys_in_current_block; ++j)
-        {
-            keys.emplace_back();
-            readBinary(keys.back(), read_buffer);
-            Metadata metadata;
-            readBinary(metadata.data, read_buffer);
-
-            if (!metadata.isDefault())
-            {
-                for (const auto & attribute : attributes_structure)
-                {
-                    switch (attribute)
-                    {
-            #define DISPATCH(TYPE) \
-                    case AttributeUnderlyingType::ut##TYPE: \
-                        read_buffer.ignore(sizeof(TYPE)); \
-                        break;
-
-                        DISPATCH(UInt8)
-                        DISPATCH(UInt16)
-                        DISPATCH(UInt32)
-                        DISPATCH(UInt64)
-                        DISPATCH(UInt128)
-                        DISPATCH(Int8)
-                        DISPATCH(Int16)
-                        DISPATCH(Int32)
-                        DISPATCH(Int64)
-                        DISPATCH(Decimal32)
-                        DISPATCH(Decimal64)
-                        DISPATCH(Decimal128)
-                        DISPATCH(Float32)
-                        DISPATCH(Float64)
-            #undef DISPATCH
-
-                    case AttributeUnderlyingType::utString:
-                        {
-                            size_t size = 0;
-                            readVarUInt(size, read_buffer);
-                            read_buffer.ignore(size);
-                        }
-                        break;
-                    }
-                }
-            }
-        }
-    }
-
-    const size_t start_block = current_file_block_id % max_size;
-    const size_t finish_block = start_block + write_buffer_size;
-    for (const auto & key : keys)
-    {
-        Index index;
-        if (key_to_index.get(key, index))
-        {
-            size_t block_id = index.getBlockId();
-            if (start_block <= block_id && block_id < finish_block)
-                key_to_index.erase(key);
-        }
-    }
-}
-
-void SSDCachePartition::ignoreFromBufferToAttributeIndex(const size_t attribute_index, ReadBuffer & buf) const
-{
-    for (size_t i = 0; i < attribute_index; ++i)
-    {
-        switch (attributes_structure[i])
-        {
-#define DISPATCH(TYPE) \
-        case AttributeUnderlyingType::ut##TYPE: \
-            buf.ignore(sizeof(TYPE)); \
-            break;
-
-            DISPATCH(UInt8)
-            DISPATCH(UInt16)
-            DISPATCH(UInt32)
-            DISPATCH(UInt64)
-            DISPATCH(UInt128)
-            DISPATCH(Int8)
-            DISPATCH(Int16)
-            DISPATCH(Int32)
-            DISPATCH(Int64)
-            DISPATCH(Decimal32)
-            DISPATCH(Decimal64)
-            DISPATCH(Decimal128)
-            DISPATCH(Float32)
-            DISPATCH(Float64)
-#undef DISPATCH
-
-        case AttributeUnderlyingType::utString:
-            {
-                size_t size = 0;
-                readVarUInt(size, buf);
-                buf.ignore(size);
-            }
-            break;
-        }
-    }
-}
-
-size_t SSDCachePartition::getId() const
-{
-    return file_id;
-}
-
-double SSDCachePartition::getLoadFactor() const
-{
-    std::shared_lock lock(rw_lock);
-    return static_cast<double>(current_file_block_id) / max_size;
-}
-
-size_t SSDCachePartition::getElementCount() const
-{
-    std::shared_lock lock(rw_lock);
-    return key_to_index.size();
-}
-
-size_t SSDCachePartition::getBytesAllocated() const
-{
-    std::shared_lock lock(rw_lock);
-    return 16.5 * key_to_index.capacity() + (memory ? memory->size() : 0);
-}
-
-PaddedPODArray<SSDCachePartition::Key> SSDCachePartition::getCachedIds(const std::chrono::system_clock::time_point /* now */) const
-{
-    std::unique_lock lock(rw_lock); // Begin and end iterators can be changed.
-    PaddedPODArray<Key> array;
-    for (const auto & key : key_to_index.keys())
-        array.push_back(key);
-    return array;
-}
-
-void SSDCachePartition::remove()
-{
-    std::unique_lock lock(rw_lock);
-    std::filesystem::remove(std::filesystem::path(path + BIN_FILE_EXT));
-}
-
-SSDCacheStorage::SSDCacheStorage(
-        const AttributeTypes & attributes_structure_,
-        const std::string & path_,
-        const size_t max_partitions_count_,
-        const size_t file_size_,
-        const size_t block_size_,
-        const size_t read_buffer_size_,
-        const size_t write_buffer_size_,
-        const size_t max_stored_keys_)
-    : attributes_structure(attributes_structure_)
-    , path(path_)
-    , max_partitions_count(max_partitions_count_)
-    , file_size(file_size_)
-    , block_size(block_size_)
-    , read_buffer_size(read_buffer_size_)
-    , write_buffer_size(write_buffer_size_)
-    , max_stored_keys(max_stored_keys_)
-    , log(&Poco::Logger::get("SSDCacheStorage"))
-{
-}
-
-SSDCacheStorage::~SSDCacheStorage()
-{
-    std::unique_lock lock(rw_lock);
-    partition_delete_queue.splice(std::end(partition_delete_queue), partitions);
-    collectGarbage();
-}
-
-template <typename Out, typename GetDefault>
-void SSDCacheStorage::getValue(const size_t attribute_index, const PaddedPODArray<UInt64> & ids,
-      ResultArrayType<Out> & out, std::unordered_map<Key, std::vector<size_t>> & not_found,
-      GetDefault & default_value_extractor, std::chrono::system_clock::time_point now) const
-{
-    std::vector<bool> found(ids.size(), false);
-
-    {
-        std::shared_lock lock(rw_lock);
-        for (const auto & partition : partitions)
-            partition->getValue<Out>(attribute_index, ids, out, found, default_value_extractor, now);
-    }
-
-    for (size_t i = 0; i < ids.size(); ++i)
-        if (!found[i])
-            not_found[ids[i]].push_back(i);
-
-    query_count.fetch_add(ids.size(), std::memory_order_relaxed);
-    hit_count.fetch_add(ids.size() - not_found.size(), std::memory_order_release);
-}
-
-void SSDCacheStorage::getString(const size_t attribute_index, const PaddedPODArray<UInt64> & ids,
-    StringRefs & refs, ArenaWithFreeLists & arena, std::unordered_map<Key, std::vector<size_t>> & not_found,
-    std::vector<size_t> & default_ids, std::chrono::system_clock::time_point now) const
-{
-    std::vector<bool> found(ids.size(), false);
-
-    {
-        std::shared_lock lock(rw_lock);
-        for (const auto & partition : partitions)
-            partition->getString(attribute_index, ids, refs, arena, found, default_ids, now);
-    }
-
-    for (size_t i = 0; i < ids.size(); ++i)
-        if (!found[i])
-            not_found[ids[i]].push_back(i);
-
-    query_count.fetch_add(ids.size(), std::memory_order_relaxed);
-    hit_count.fetch_add(ids.size() - not_found.size(), std::memory_order_release);
-}
-
-void SSDCacheStorage::has(const PaddedPODArray<UInt64> & ids, ResultArrayType<UInt8> & out,
-     std::unordered_map<Key, std::vector<size_t>> & not_found, std::chrono::system_clock::time_point now) const
-{
-    for (size_t i = 0; i < ids.size(); ++i)
-        out[i] = HAS_NOT_FOUND;
-    std::vector<bool> found(ids.size(), false);
-
-    {
-        std::shared_lock lock(rw_lock);
-        for (const auto & partition : partitions)
-            partition->has(ids, out, found, now);
-
-        for (size_t i = 0; i < ids.size(); ++i)
-            if (out[i] == HAS_NOT_FOUND)
-                not_found[ids[i]].push_back(i);
-    }
-
-    query_count.fetch_add(ids.size(), std::memory_order_relaxed);
-    hit_count.fetch_add(ids.size() - not_found.size(), std::memory_order_release);
-}
-
-namespace
-{
-SSDCachePartition::Attributes createAttributesFromBlock(
-        const Block & block, const size_t begin_column, const std::vector<AttributeUnderlyingType> & structure)
-{
-    SSDCachePartition::Attributes attributes;
-
-    const auto columns = block.getColumns();
-    for (size_t i = 0; i < structure.size(); ++i)
-    {
-        const auto & column = columns[i + begin_column];
-        switch (structure[i])
-        {
-#define DISPATCH(TYPE) \
-        case AttributeUnderlyingType::ut##TYPE: \
-            { \
-                SSDCachePartition::Attribute::Container<TYPE> values(column->size()); \
-                memcpy(&values[0], column->getRawData().data, sizeof(TYPE) * values.size()); \
-                attributes.emplace_back(); \
-                attributes.back().type = structure[i]; \
-                attributes.back().values = std::move(values); \
-            } \
-            break;
-
-            DISPATCH(UInt8)
-            DISPATCH(UInt16)
-            DISPATCH(UInt32)
-            DISPATCH(UInt64)
-            DISPATCH(UInt128)
-            DISPATCH(Int8)
-            DISPATCH(Int16)
-            DISPATCH(Int32)
-            DISPATCH(Int64)
-            DISPATCH(Decimal32)
-            DISPATCH(Decimal64)
-            DISPATCH(Decimal128)
-            DISPATCH(Float32)
-            DISPATCH(Float64)
-#undef DISPATCH
-
-        case AttributeUnderlyingType::utString:
-            {
-                attributes.emplace_back();
-                SSDCachePartition::Attribute::Container<String> values(column->size());
-                for (size_t j = 0; j < column->size(); ++j)
-                {
-                    const auto ref = column->getDataAt(j);
-                    values[j].resize(ref.size);
-                    memcpy(values[j].data(), ref.data, ref.size);
-                }
-                attributes.back().type = structure[i];
-                attributes.back().values = std::move(values);
-            }
-            break;
-        }
-    }
-
-    return attributes;
-}
-}
-
-template <typename PresentIdHandler, typename AbsentIdHandler>
-void SSDCacheStorage::update(DictionarySourcePtr & source_ptr, const std::vector<Key> & requested_ids,
-        PresentIdHandler && on_updated, AbsentIdHandler && on_id_not_found,
-        const DictionaryLifetime lifetime)
-{
-    auto append_block = [this](const SSDCachePartition::Attribute & new_keys,
-            const SSDCachePartition::Attributes & new_attributes, const PaddedPODArray<SSDCachePartition::Metadata> & metadata)
-    {
-        size_t inserted = 0;
-        while (inserted < metadata.size())
-        {
-            if (!partitions.empty())
-                inserted += partitions.front()->appendBlock(new_keys, new_attributes, metadata, inserted);
-            if (inserted < metadata.size())
-            {
-                partitions.emplace_front(std::make_unique<SSDCachePartition>(
-                        AttributeUnderlyingType::utUInt64, attributes_structure, path,
-                        (partitions.empty() ? 0 : partitions.front()->getId() + 1),
-                        file_size, block_size, read_buffer_size, write_buffer_size, max_stored_keys));
-            }
-        }
-
-        collectGarbage();
-    };
-
-    CurrentMetrics::Increment metric_increment{CurrentMetrics::DictCacheRequests};
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysRequested, requested_ids.size());
-
-    std::unordered_map<Key, UInt8> remaining_ids{requested_ids.size()};
-    for (const auto id : requested_ids)
-        remaining_ids.insert({id, 0});
-
-    const auto now = std::chrono::system_clock::now();
-
-    {
-        const ProfilingScopedWriteRWLock write_lock{rw_lock, ProfileEvents::DictCacheLockWriteNs};
-
-        if (now > backoff_end_time)
-        {
-            try
-            {
-                if (update_error_count)
-                {
-                    /// Recover after error: we have to clone the source here because
-                    /// it could keep connections which should be reset after error.
-                    source_ptr = source_ptr->clone();
-                }
-
-                Stopwatch watch;
-                auto stream = source_ptr->loadIds(requested_ids);
-                stream->readPrefix();
-
-                while (const auto block = stream->read())
-                {
-                    const auto new_keys = std::move(createAttributesFromBlock(block, 0, { AttributeUnderlyingType::utUInt64 }).front());
-                    const auto new_attributes = createAttributesFromBlock(block, 1, attributes_structure);
-
-                    const auto & ids = std::get<SSDCachePartition::Attribute::Container<UInt64>>(new_keys.values);
-
-                    PaddedPODArray<SSDCachePartition::Metadata> metadata(ids.size());
-
-                    for (const auto i : ext::range(0, ids.size()))
-                    {
-                        std::uniform_int_distribution<UInt64> distribution{lifetime.min_sec, lifetime.max_sec};
-                        metadata[i].setExpiresAt(now + std::chrono::seconds(distribution(rnd_engine)));
-                        /// mark corresponding id as found
-                        on_updated(ids[i], i, new_attributes);
-                        remaining_ids[ids[i]] = 1;
-                    }
-
-                    append_block(new_keys, new_attributes, metadata);
-                }
-
-                stream->readSuffix();
-
-                update_error_count = 0;
-                last_update_exception = std::exception_ptr{};
-                backoff_end_time = std::chrono::system_clock::time_point{};
-
-                ProfileEvents::increment(ProfileEvents::DictCacheRequestTimeNs, watch.elapsed());
-            }
-            catch (...)
-            {
-                ++update_error_count;
-                last_update_exception = std::current_exception();
-                backoff_end_time = now + std::chrono::seconds(calculateDurationWithBackoff(rnd_engine, update_error_count));
-
-                tryLogException(last_update_exception, log,
-                        "Could not update ssd cache dictionary, next update is scheduled at " + ext::to_string(backoff_end_time));
-            }
-        }
-    }
-
-    auto append_defaults = [this](const SSDCachePartition::Attribute & new_keys, const PaddedPODArray<SSDCachePartition::Metadata> & metadata)
-    {
-        size_t inserted = 0;
-        while (inserted < metadata.size())
-        {
-            if (!partitions.empty())
-                inserted += partitions.front()->appendDefaults(new_keys, metadata, inserted);
-            if (inserted < metadata.size())
-            {
-                partitions.emplace_front(std::make_unique<SSDCachePartition>(
-                        AttributeUnderlyingType::utUInt64, attributes_structure, path,
-                        (partitions.empty() ? 0 : partitions.front()->getId() + 1),
-                        file_size, block_size, read_buffer_size, write_buffer_size, max_stored_keys));
-            }
-        }
-
-        collectGarbage();
-    };
-
-    size_t not_found_num = 0, found_num = 0;
-    /// Check which ids have not been found and require setting null_value
-    SSDCachePartition::Attribute new_keys;
-    new_keys.type = AttributeUnderlyingType::utUInt64;
-    new_keys.values = SSDCachePartition::Attribute::Container<UInt64>();
-
-    PaddedPODArray<SSDCachePartition::Metadata> metadata;
-    {
-        const ProfilingScopedWriteRWLock write_lock{rw_lock, ProfileEvents::DictCacheLockWriteNs};
-
-        for (const auto & id_found_pair : remaining_ids)
-        {
-            if (id_found_pair.second)
-            {
-                ++found_num;
-                continue;
-            }
-            ++not_found_num;
-
-            const auto id = id_found_pair.first;
-
-            if (update_error_count)
-            {
-                /// TODO: use old values
-
-                // We don't have expired data for that `id` so all we can do is
-                // to rethrow `last_exception`. We might have to throw the same
-                // exception for different callers of dictGet() in different
-                // threads, which might then modify the exception object, so we
-                // have to throw a copy.
-                try
-                {
-                    std::rethrow_exception(last_update_exception);
-                }
-                catch (...)
-                {
-                    throw DB::Exception(ErrorCodes::CACHE_DICTIONARY_UPDATE_FAIL,
-                        "Update failed for dictionary '{}': {}",
-                        getPath(),
-                        getCurrentExceptionMessage(true /*with stack trace*/,
-                            true /*check embedded stack trace*/));
-                }
-            }
-
-            /// Set key
-            std::get<SSDCachePartition::Attribute::Container<UInt64>>(new_keys.values).push_back(id);
-
-            std::uniform_int_distribution<UInt64> distribution{lifetime.min_sec, lifetime.max_sec};
-            metadata.emplace_back();
-            metadata.back().setExpiresAt(now + std::chrono::seconds(distribution(rnd_engine)));
-            metadata.back().setDefault();
-
-            /// Inform caller that the cell has not been found
-            on_id_not_found(id);
-        }
-
-        if (not_found_num)
-            append_defaults(new_keys, metadata);
-    }
-
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysRequestedMiss, not_found_num);
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysRequestedFound, found_num);
-    ProfileEvents::increment(ProfileEvents::DictCacheRequests);
-}
-
-PaddedPODArray<SSDCachePartition::Key> SSDCacheStorage::getCachedIds() const
-{
-    PaddedPODArray<Key> array;
-
-    const auto now = std::chrono::system_clock::now();
-
-    std::shared_lock lock(rw_lock);
-    for (const auto & partition : partitions)
-    {
-        const auto cached_in_partition = partition->getCachedIds(now);
-        array.insert(std::begin(cached_in_partition), std::end(cached_in_partition));
-    }
-
-    return array;
-}
-
-double SSDCacheStorage::getLoadFactor() const
-{
-    double result = 0;
-    std::shared_lock lock(rw_lock);
-    for (const auto & partition : partitions)
-        result += partition->getLoadFactor();
-    return result / partitions.size();
-}
-
-size_t SSDCacheStorage::getElementCount() const
-{
-    size_t result = 0;
-    std::shared_lock lock(rw_lock);
-    for (const auto & partition : partitions)
-        result += partition->getElementCount();
-    return result;
-}
-
-size_t SSDCacheStorage::getBytesAllocated() const
-{
-    size_t result = 0;
-    std::shared_lock lock(rw_lock);
-    for (const auto & partition : partitions)
-        result += partition->getBytesAllocated();
-    return result;
-}
-
-void SSDCacheStorage::collectGarbage()
-{
-    // add partitions to queue
-    while (partitions.size() > max_partitions_count)
-        partition_delete_queue.splice(std::end(partition_delete_queue), partitions, std::prev(std::end(partitions)));
-
-    // drop unused partitions
-    while (!partition_delete_queue.empty() && partition_delete_queue.front().use_count() == 1)
-    {
-        partition_delete_queue.front()->remove();
-        partition_delete_queue.pop_front();
-    }
-}
-
-SSDCacheDictionary::SSDCacheDictionary(
-    const StorageID & dict_id_,
-    const DictionaryStructure & dict_struct_,
-    DictionarySourcePtr source_ptr_,
-    const DictionaryLifetime dict_lifetime_,
-    const std::string & path_,
-    const size_t max_partitions_count_,
-    const size_t file_size_,
-    const size_t block_size_,
-    const size_t read_buffer_size_,
-    const size_t write_buffer_size_,
-    const size_t max_stored_keys_)
-    : IDictionary(dict_id_)
-    , dict_struct(dict_struct_)
-    , source_ptr(std::move(source_ptr_))
-    , dict_lifetime(dict_lifetime_)
-    , path(path_)
-    , max_partitions_count(max_partitions_count_)
-    , file_size(file_size_)
-    , block_size(block_size_)
-    , read_buffer_size(read_buffer_size_)
-    , write_buffer_size(write_buffer_size_)
-    , max_stored_keys(max_stored_keys_)
-    , storage(ext::map<std::vector>(dict_struct.attributes, [](const auto & attribute) { return attribute.underlying_type; }),
-            path, max_partitions_count, file_size, block_size, read_buffer_size, write_buffer_size, max_stored_keys)
-    , log(&Poco::Logger::get("SSDCacheDictionary"))
-{
-    LOG_INFO(log, "Using storage path '{}'.", path);
-    if (!this->source_ptr->supportsSelectiveLoad())
-        throw Exception{name + ": source cannot be used with CacheDictionary", ErrorCodes::UNSUPPORTED_METHOD};
-
-    createAttributes();
-}
-
-ColumnPtr SSDCacheDictionary::getColumn(
-    const std::string & attribute_name,
-    const DataTypePtr & result_type,
-    const Columns & key_columns,
-    const DataTypes &,
-    const ColumnPtr default_values_column) const
-{
-    ColumnPtr result;
-
-    PaddedPODArray<Key> backup_storage;
-    const auto & ids = getColumnVectorData(this, key_columns.front(), backup_storage);
-    auto keys_size = ids.size();
-
-    const auto index = getAttributeIndex(attribute_name);
-    const auto & dictionary_attribute = dict_struct.getAttribute(attribute_name, result_type);
-
-    auto type_call = [&](const auto &dictionary_attribute_type)
-    {
-        using Type = std::decay_t<decltype(dictionary_attribute_type)>;
-        using AttributeType = typename Type::AttributeType;
-        using ColumnProvider = DictionaryAttributeColumnProvider<AttributeType>;
-
-        const auto & null_value = std::get<AttributeType>(null_values[index]);
-        DictionaryDefaultValueExtractor<AttributeType> default_value_extractor(null_value, default_values_column);
-
-        auto column = ColumnProvider::getColumn(dictionary_attribute, keys_size);
-
-        if constexpr (std::is_same_v<AttributeType, String>)
-        {
-            getItemsStringImpl(index, ids, column.get(), default_value_extractor);
-        }
-        else
-        {
-            auto & out = column->getData();
-            getItemsNumberImpl<AttributeType, AttributeType>(index, ids, out, default_value_extractor);
-        }
-
-        result = std::move(column);
-    };
-
-    callOnDictionaryAttributeType(dict_struct.attributes[index].underlying_type, type_call);
-
-    return result;
-}
-
-template <typename AttributeType, typename OutputType, typename DefaultGetter>
-void SSDCacheDictionary::getItemsNumberImpl(
-        const size_t attribute_index,
-        const PaddedPODArray<Key> & ids,
-        ResultArrayType<OutputType> & out,
-        DefaultGetter & default_value_extractor) const
-{
-    const auto now = std::chrono::system_clock::now();
-
-    std::unordered_map<Key, std::vector<size_t>> not_found_ids;
-    storage.getValue<OutputType>(attribute_index, ids, out, not_found_ids, default_value_extractor, now);
-    if (not_found_ids.empty())
-        return;
-
-    std::vector<Key> required_ids(not_found_ids.size());
-    std::transform(std::begin(not_found_ids), std::end(not_found_ids), std::begin(required_ids), [](const auto & pair) { return pair.first; });
-
-    storage.update(
-            source_ptr,
-            required_ids,
-            [&](const auto id, const auto row, const auto & new_attributes)
-            {
-                for (const size_t out_row : not_found_ids[id])
-                    out[out_row] = std::get<SSDCachePartition::Attribute::Container<OutputType>>(new_attributes[attribute_index].values)[row];
-            },
-            [&](const size_t id)
-            {
-                for (const size_t row : not_found_ids[id])
-                    out[row] = default_value_extractor[row];
-            },
-            getLifetime());
-}
-
-template <typename DefaultGetter>
-void SSDCacheDictionary::getItemsStringImpl(
-    const size_t attribute_index,
-    const PaddedPODArray<Key> & ids,
-    ColumnString * out,
-    DefaultGetter & default_value_extractor) const
-{
-    const auto now = std::chrono::system_clock::now();
-
-    std::unordered_map<Key, std::vector<size_t>> not_found_ids;
-
-    StringRefs refs(ids.size());
-    ArenaWithFreeLists string_arena;
-    std::vector<size_t> default_rows;
-    storage.getString(attribute_index, ids, refs, string_arena, not_found_ids, default_rows, now);
-    std::sort(std::begin(default_rows), std::end(default_rows));
-
-    if (not_found_ids.empty())
-    {
-        size_t default_index = 0;
-        for (size_t row = 0; row < ids.size(); ++row)
-        {
-            if (unlikely(default_index != default_rows.size() && default_rows[default_index] == row))
-            {
-                auto to_insert = default_value_extractor[row];
-                out->insertData(to_insert.data, to_insert.size);
-                ++default_index;
-            }
-            else
-                out->insertData(refs[row].data, refs[row].size);
-        }
-        return;
-    }
-
-    std::vector<Key> required_ids(not_found_ids.size());
-    std::transform(std::begin(not_found_ids), std::end(not_found_ids), std::begin(required_ids), [](const auto & pair) { return pair.first; });
-
-    std::unordered_map<Key, String> update_result;
-
-    storage.update(
-            source_ptr,
-            required_ids,
-            [&](const auto id, const auto row, const auto & new_attributes)
-            {
-                update_result[id] = std::get<SSDCachePartition::Attribute::Container<String>>(new_attributes[attribute_index].values)[row];
-            },
-            [&](const size_t) {},
-            getLifetime());
-
-    size_t default_index = 0;
-    for (size_t row = 0; row < ids.size(); ++row)
-    {
-        const auto & id = ids[row];
-        if (unlikely(default_index != default_rows.size() && default_rows[default_index] == row))
-        {
-            auto to_insert = default_value_extractor[row];
-            out->insertData(to_insert.data, to_insert.size);
-            ++default_index;
-        }
-        else if (auto it = not_found_ids.find(id); it == std::end(not_found_ids))
-        {
-            out->insertData(refs[row].data, refs[row].size);
-        }
-        else if (auto it_update = update_result.find(id); it_update != std::end(update_result))
-        {
-            out->insertData(it_update->second.data(), it_update->second.size());
-        }
-        else
-        {
-            auto to_insert = default_value_extractor[row];
-            out->insertData(to_insert.data, to_insert.size);
-        }
-    }
-}
-
-ColumnUInt8::Ptr SSDCacheDictionary::hasKeys(const Columns & key_columns, const DataTypes &) const
-{
-    PaddedPODArray<Key> backup_storage;
-    const auto& ids = getColumnVectorData(this, key_columns.front(), backup_storage);
-
-    auto result = ColumnUInt8::create(ext::size(ids));
-    auto& out = result->getData();
-
-    const auto rows = ext::size(ids);
-    for (const auto row : ext::range(0, rows))
-        out[row] = false;
-
-    const auto now = std::chrono::system_clock::now();
-
-    std::unordered_map<Key, std::vector<size_t>> not_found_ids;
-    storage.has(ids, out, not_found_ids, now);
-    if (not_found_ids.empty())
-        return result;
-
-    std::vector<Key> required_ids(not_found_ids.size());
-    std::transform(std::begin(not_found_ids), std::end(not_found_ids), std::begin(required_ids), [](const auto & pair) { return pair.first; });
-
-    storage.update(
-            source_ptr,
-            required_ids,
-            [&](const auto id, const auto, const auto &)
-            {
-                for (const size_t out_row : not_found_ids[id])
-                    out[out_row] = true;
-            },
-            [&](const size_t id)
-            {
-                for (const size_t row : not_found_ids[id])
-                    out[row] = false;
-            },
-            getLifetime());
-
-    return result;
-}
-
-BlockInputStreamPtr SSDCacheDictionary::getBlockInputStream(const Names & column_names, size_t max_block_size) const
-{
-    using BlockInputStreamType = DictionaryBlockInputStream<Key>;
-    return std::make_shared<BlockInputStreamType>(shared_from_this(), max_block_size, storage.getCachedIds(), column_names);
-}
-
-size_t SSDCacheDictionary::getAttributeIndex(const std::string & attr_name) const
-{
-    auto it = attribute_index_by_name.find(attr_name);
-    if (it == std::end(attribute_index_by_name))
-        throw  Exception{"Attribute `" + name + "` does not exist.", ErrorCodes::BAD_ARGUMENTS};
-    return it->second;
-}
-
-template <typename T>
-AttributeValueVariant SSDCacheDictionary::createAttributeNullValueWithTypeImpl(const Field & null_value)
-{
-    AttributeValueVariant var_null_value = static_cast<T>(null_value.get<NearestFieldType<T>>());
-    bytes_allocated += sizeof(T);
-    return var_null_value;
-}
-
-template <>
-AttributeValueVariant SSDCacheDictionary::createAttributeNullValueWithTypeImpl<String>(const Field & null_value)
-{
-    AttributeValueVariant var_null_value = null_value.get<String>();
-    bytes_allocated += sizeof(StringRef);
-    return var_null_value;
-}
-
-AttributeValueVariant SSDCacheDictionary::createAttributeNullValueWithType(const AttributeUnderlyingType type, const Field & null_value)
-{
-    switch (type)
-    {
-#define DISPATCH(TYPE) \
-case AttributeUnderlyingType::ut##TYPE: \
-    return createAttributeNullValueWithTypeImpl<TYPE>(null_value);
-
-        DISPATCH(UInt8)
-        DISPATCH(UInt16)
-        DISPATCH(UInt32)
-        DISPATCH(UInt64)
-        DISPATCH(UInt128)
-        DISPATCH(Int8)
-        DISPATCH(Int16)
-        DISPATCH(Int32)
-        DISPATCH(Int64)
-        DISPATCH(Decimal32)
-        DISPATCH(Decimal64)
-        DISPATCH(Decimal128)
-        DISPATCH(Float32)
-        DISPATCH(Float64)
-        DISPATCH(String)
-#undef DISPATCH
-    }
-    throw Exception{"Unknown attribute type: " + std::to_string(static_cast<int>(type)), ErrorCodes::TYPE_MISMATCH};
-}
-
-void SSDCacheDictionary::createAttributes()
-{
-    null_values.reserve(dict_struct.attributes.size());
-    for (size_t i = 0; i < dict_struct.attributes.size(); ++i)
-    {
-        const auto & attribute = dict_struct.attributes[i];
-
-        attribute_index_by_name.emplace(attribute.name, i);
-        null_values.push_back(createAttributeNullValueWithType(attribute.underlying_type, attribute.null_value));
-
-        if (attribute.hierarchical)
-            throw Exception{name + ": hierarchical attributes not supported for dictionary of type " + getTypeName(),
-                            ErrorCodes::TYPE_MISMATCH};
-    }
-}
-
-void registerDictionarySSDCache(DictionaryFactory & factory)
-{
-    auto create_layout = [=](const std::string & name,
-                             const DictionaryStructure & dict_struct,
-                             const Poco::Util::AbstractConfiguration & config,
-                             const std::string & config_prefix,
-                             DictionarySourcePtr source_ptr) -> DictionaryPtr
-    {
-        if (dict_struct.key)
-            throw Exception{"'key' is not supported for dictionary of layout 'cache'", ErrorCodes::UNSUPPORTED_METHOD};
-
-        const auto dict_id = StorageID::fromDictionaryConfig(config, config_prefix);
-
-        if (dict_struct.range_min || dict_struct.range_max)
-            throw Exception{name
-                            + ": elements .structure.range_min and .structure.range_max should be defined only "
-                              "for a dictionary of layout 'range_hashed'",
-                            ErrorCodes::BAD_ARGUMENTS};
-        const auto & layout_prefix = config_prefix + ".layout";
-
-        const auto max_partitions_count = config.getInt(layout_prefix + ".ssd_cache.max_partitions_count", DEFAULT_PARTITIONS_COUNT);
-        if (max_partitions_count <= 0)
-            throw Exception{name + ": dictionary of layout 'ssd_cache' cannot have 0 (or less) max_partitions_count", ErrorCodes::BAD_ARGUMENTS};
-
-        const auto block_size = config.getInt(layout_prefix + ".ssd_cache.block_size", DEFAULT_SSD_BLOCK_SIZE_BYTES);
-        if (block_size <= 0)
-            throw Exception{name + ": dictionary of layout 'ssd_cache' cannot have 0 (or less) block_size", ErrorCodes::BAD_ARGUMENTS};
-
-        const auto file_size = config.getInt64(layout_prefix + ".ssd_cache.file_size", DEFAULT_FILE_SIZE_BYTES);
-        if (file_size <= 0)
-            throw Exception{name + ": dictionary of layout 'ssd_cache' cannot have 0 (or less) file_size", ErrorCodes::BAD_ARGUMENTS};
-        if (file_size % block_size != 0)
-            throw Exception{name + ": file_size must be a multiple of block_size", ErrorCodes::BAD_ARGUMENTS};
-
-        const auto read_buffer_size = config.getInt64(layout_prefix + ".ssd_cache.read_buffer_size", DEFAULT_READ_BUFFER_SIZE_BYTES);
-        if (read_buffer_size <= 0)
-            throw Exception{name + ": dictionary of layout 'ssd_cache' cannot have 0 (or less) read_buffer_size", ErrorCodes::BAD_ARGUMENTS};
-        if (read_buffer_size % block_size != 0)
-            throw Exception{name + ": read_buffer_size must be a multiple of block_size", ErrorCodes::BAD_ARGUMENTS};
-
-        const auto write_buffer_size = config.getInt64(layout_prefix + ".ssd_cache.write_buffer_size", DEFAULT_WRITE_BUFFER_SIZE_BYTES);
-        if (write_buffer_size <= 0)
-            throw Exception{name + ": dictionary of layout 'ssd_cache' cannot have 0 (or less) write_buffer_size", ErrorCodes::BAD_ARGUMENTS};
-        if (write_buffer_size % block_size != 0)
-            throw Exception{name + ": write_buffer_size must be a multiple of block_size", ErrorCodes::BAD_ARGUMENTS};
-
-        auto path = config.getString(layout_prefix + ".ssd_cache.path");
-        if (path.empty())
-            throw Exception{name + ": dictionary of layout 'ssd_cache' cannot have empty path",
-                            ErrorCodes::BAD_ARGUMENTS};
-        if (path.at(0) != '/')
-            path = std::filesystem::path{config.getString("path")}.concat(path).string();
-
-        const auto max_stored_keys = config.getInt64(layout_prefix + ".ssd_cache.max_stored_keys", DEFAULT_MAX_STORED_KEYS);
-        if (max_stored_keys <= 0)
-            throw Exception{name + ": dictionary of layout 'ssd_cache' cannot have 0 (or less) max_stored_keys", ErrorCodes::BAD_ARGUMENTS};
-
-        const DictionaryLifetime dict_lifetime{config, config_prefix + ".lifetime"};
-        return std::make_unique<SSDCacheDictionary>(
-                dict_id, dict_struct, std::move(source_ptr), dict_lifetime, path,
-                max_partitions_count, file_size / block_size, block_size,
-                read_buffer_size / block_size, write_buffer_size / block_size,
-                max_stored_keys);
-    };
-    factory.registerLayout("ssd_cache", create_layout, false);
-}
-
-}
-
-#endif
diff --git a/src/Dictionaries/SSDCacheDictionary.h b/src/Dictionaries/SSDCacheDictionary.h
deleted file mode 100644
index 4d4d3befa22a..000000000000
--- a/src/Dictionaries/SSDCacheDictionary.h
+++ /dev/null
@@ -1,418 +0,0 @@
-#pragma once
-
-#if defined(__linux__) || defined(__FreeBSD__)
-
-#include <atomic>
-#include <chrono>
-#include <list>
-#include <shared_mutex>
-#include <variant>
-#include <vector>
-
-#include <Poco/Logger.h>
-
-#include <Columns/ColumnDecimal.h>
-#include <Columns/ColumnString.h>
-#include <Common/ArenaWithFreeLists.h>
-#include <Common/CurrentMetrics.h>
-#include <common/logger_useful.h>
-#include <Compression/CompressedWriteBuffer.h>
-#include <Core/Block.h>
-#include <Dictionaries/BucketCache.h>
-#include <IO/HashingWriteBuffer.h>
-#include <pcg_random.hpp>
-#include "DictionaryStructure.h"
-#include "IDictionary.h"
-#include "IDictionarySource.h"
-#include "DictionaryHelpers.h"
-
-namespace DB
-{
-
-using AttributeValueVariant = std::variant<
-        UInt8,
-        UInt16,
-        UInt32,
-        UInt64,
-        UInt128,
-        Int8,
-        Int16,
-        Int32,
-        Int64,
-        Decimal32,
-        Decimal64,
-        Decimal128,
-        Float32,
-        Float64,
-        String>;
-
-
-/*
-    Class for operations with cache file and index.
-    Supports GET/SET operations.
-*/
-class SSDCachePartition
-{
-public:
-    struct Index final
-    {
-        bool inMemory() const;
-        void setInMemory(bool in_memory);
-
-        bool exists() const;
-        void setNotExists();
-
-        size_t getAddressInBlock() const;
-        void setAddressInBlock(size_t address_in_block);
-
-        size_t getBlockId() const;
-        void setBlockId(size_t block_id);
-
-        bool operator< (const Index & rhs) const { return index < rhs.index; }
-
-        /// Stores `is_in_memory` flag, block id, address in uncompressed block
-        uint64_t index = 0;
-    };
-
-    struct Metadata final
-    {
-        using time_point_t = std::chrono::system_clock::time_point;
-        using time_point_rep_t = time_point_t::rep;
-        using time_point_urep_t = make_unsigned_t<time_point_rep_t>;
-
-        time_point_t expiresAt() const;
-        void setExpiresAt(const time_point_t & t);
-
-        bool isDefault() const;
-        void setDefault();
-
-        /// Stores both expiration time and `is_default` flag in the most significant bit
-        time_point_urep_t data = 0;
-    };
-
-    using Offset = size_t;
-    using Offsets = std::vector<Offset>;
-    using Key = IDictionary::Key;
-
-    SSDCachePartition(
-            const AttributeUnderlyingType & key_structure,
-            const std::vector<AttributeUnderlyingType> & attributes_structure,
-            const std::string & dir_path,
-            size_t file_id,
-            size_t max_size,
-            size_t block_size,
-            size_t read_buffer_size,
-            size_t write_buffer_size,
-            size_t max_stored_keys);
-
-    ~SSDCachePartition();
-
-    template <typename T>
-    using ResultArrayType = std::conditional_t<IsDecimalNumber<T>, DecimalPaddedPODArray<T>, PaddedPODArray<T>>;
-
-    template <typename Out, typename GetDefault>
-    void getValue(size_t attribute_index, const PaddedPODArray<UInt64> & ids,
-            ResultArrayType<Out> & out, std::vector<bool> & found, GetDefault & default_value_extractor,
-            std::chrono::system_clock::time_point now) const;
-
-    void getString(size_t attribute_index, const PaddedPODArray<UInt64> & ids,
-            StringRefs & refs, ArenaWithFreeLists & arena, std::vector<bool> & found,
-            std::vector<size_t> & default_ids, std::chrono::system_clock::time_point now) const;
-
-    void has(const PaddedPODArray<UInt64> & ids, ResultArrayType<UInt8> & out,
-            std::vector<bool> & found, std::chrono::system_clock::time_point now) const;
-
-    struct Attribute
-    {
-        template <typename T>
-        using Container = std::vector<T>;
-
-        AttributeUnderlyingType type;
-        std::variant<
-                Container<UInt8>,
-                Container<UInt16>,
-                Container<UInt32>,
-                Container<UInt64>,
-                Container<UInt128>,
-                Container<Int8>,
-                Container<Int16>,
-                Container<Int32>,
-                Container<Int64>,
-                Container<Decimal32>,
-                Container<Decimal64>,
-                Container<Decimal128>,
-                Container<Float32>,
-                Container<Float64>,
-                Container<String>> values;
-    };
-    using Attributes = std::vector<Attribute>;
-
-    size_t appendBlock(const Attribute & new_keys, const Attributes & new_attributes,
-            const PaddedPODArray<Metadata> & metadata, size_t begin);
-
-    size_t appendDefaults(const Attribute & new_keys, const PaddedPODArray<Metadata> & metadata, size_t begin);
-
-    void flush();
-
-    void remove();
-
-    size_t getId() const;
-
-    PaddedPODArray<Key> getCachedIds(std::chrono::system_clock::time_point now) const;
-
-    double getLoadFactor() const;
-
-    size_t getElementCount() const;
-
-    size_t getBytesAllocated() const;
-
-private:
-    void clearOldestBlocks();
-
-    template <typename SetFunc>
-    void getImpl(const PaddedPODArray<UInt64> & ids, SetFunc & set, std::vector<bool> & found) const;
-
-    template <typename SetFunc>
-    void getValueFromMemory(const PaddedPODArray<Index> & indices, SetFunc & set) const;
-
-    template <typename SetFunc>
-    void getValueFromStorage(const PaddedPODArray<Index> & indices, SetFunc & set) const;
-
-    void ignoreFromBufferToAttributeIndex(size_t attribute_index, ReadBuffer & buf) const;
-
-    const size_t file_id;
-    const size_t max_size;
-    const size_t block_size;
-    const size_t read_buffer_size;
-    const size_t write_buffer_size;
-    const size_t max_stored_keys;
-    const std::string path;
-
-    mutable std::shared_mutex rw_lock;
-
-    int fd = -1;
-
-    mutable BucketCacheIndex<UInt64, Index, Int64Hasher> key_to_index;
-
-    Attribute keys_buffer;
-    const std::vector<AttributeUnderlyingType> attributes_structure;
-
-    std::optional<Memory<>> memory;
-    std::optional<WriteBuffer> write_buffer;
-    uint32_t keys_in_block = 0;
-
-    size_t current_memory_block_id = 0;
-    size_t current_file_block_id = 0;
-};
-
-using SSDCachePartitionPtr = std::shared_ptr<SSDCachePartition>;
-
-
-/*
-    Class for managing SSDCachePartition and getting data from source.
-*/
-class SSDCacheStorage
-{
-public:
-    using AttributeTypes = std::vector<AttributeUnderlyingType>;
-    using Key = SSDCachePartition::Key;
-
-    SSDCacheStorage(
-            const AttributeTypes & attributes_structure,
-            const std::string & path,
-            size_t max_partitions_count,
-            size_t file_size,
-            size_t block_size,
-            size_t read_buffer_size,
-            size_t write_buffer_size,
-            size_t max_stored_keys);
-
-    ~SSDCacheStorage();
-
-    template <typename T>
-    using ResultArrayType = SSDCachePartition::ResultArrayType<T>;
-
-    template <typename Out, typename GetDefault>
-    void getValue(size_t attribute_index, const PaddedPODArray<UInt64> & ids,
-            ResultArrayType<Out> & out, std::unordered_map<Key, std::vector<size_t>> & not_found,
-            GetDefault & default_value_extractor, std::chrono::system_clock::time_point now) const;
-
-    void getString(size_t attribute_index, const PaddedPODArray<UInt64> & ids,
-            StringRefs & refs, ArenaWithFreeLists & arena, std::unordered_map<Key, std::vector<size_t>> & not_found,
-            std::vector<size_t> & default_ids, std::chrono::system_clock::time_point now) const;
-
-    void has(const PaddedPODArray<UInt64> & ids, ResultArrayType<UInt8> & out,
-             std::unordered_map<Key, std::vector<size_t>> & not_found, std::chrono::system_clock::time_point now) const;
-
-    template <typename PresentIdHandler, typename AbsentIdHandler>
-    void update(DictionarySourcePtr & source_ptr, const std::vector<Key> & requested_ids,
-            PresentIdHandler && on_updated, AbsentIdHandler && on_id_not_found,
-            DictionaryLifetime lifetime);
-
-    PaddedPODArray<Key> getCachedIds() const;
-
-    std::exception_ptr getLastException() const { return last_update_exception; }
-
-    const std::string & getPath() const { return path; }
-
-    size_t getQueryCount() const { return query_count.load(std::memory_order_relaxed); }
-
-    size_t getHitCount() const { return hit_count.load(std::memory_order_acquire); }
-
-    size_t getElementCount() const;
-
-    double getLoadFactor() const;
-
-    size_t getBytesAllocated() const;
-
-private:
-    void collectGarbage();
-
-    const AttributeTypes attributes_structure;
-
-    const std::string path;
-    const size_t max_partitions_count;
-    const size_t file_size;
-    const size_t block_size;
-    const size_t read_buffer_size;
-    const size_t write_buffer_size;
-    const size_t max_stored_keys;
-
-    mutable std::shared_mutex rw_lock;
-    std::list<SSDCachePartitionPtr> partitions;
-    std::list<SSDCachePartitionPtr> partition_delete_queue;
-
-    Poco::Logger * const log;
-
-    mutable pcg64 rnd_engine;
-
-    mutable std::exception_ptr last_update_exception;
-    mutable size_t update_error_count = 0;
-    mutable std::chrono::system_clock::time_point backoff_end_time;
-
-    mutable std::atomic<size_t> hit_count{0};
-    mutable std::atomic<size_t> query_count{0};
-};
-
-
-/*
-    Dictionary interface
-*/
-class SSDCacheDictionary final : public IDictionary
-{
-public:
-    SSDCacheDictionary(
-            const StorageID & dict_id_,
-            const DictionaryStructure & dict_struct_,
-            DictionarySourcePtr source_ptr_,
-            DictionaryLifetime dict_lifetime_,
-            const std::string & path,
-            size_t max_partitions_count_,
-            size_t file_size_,
-            size_t block_size_,
-            size_t read_buffer_size_,
-            size_t write_buffer_size_,
-            size_t max_stored_keys_);
-
-    std::string getTypeName() const override { return "SSDCache"; }
-
-    size_t getBytesAllocated() const override { return storage.getBytesAllocated(); }
-
-    size_t getQueryCount() const override { return storage.getQueryCount(); }
-
-    double getHitRate() const override
-    {
-        return static_cast<double>(storage.getHitCount()) / storage.getQueryCount();
-    }
-
-    size_t getElementCount() const override { return storage.getElementCount(); }
-
-    double getLoadFactor() const override { return storage.getLoadFactor(); }
-
-    bool supportUpdates() const override { return false; }
-
-    std::shared_ptr<const IExternalLoadable> clone() const override
-    {
-        return std::make_shared<SSDCacheDictionary>(getDictionaryID(), dict_struct, source_ptr->clone(), dict_lifetime,
-                path, max_partitions_count, file_size, block_size, read_buffer_size, write_buffer_size, max_stored_keys);
-    }
-
-    const IDictionarySource * getSource() const override { return source_ptr.get(); }
-
-    const DictionaryLifetime & getLifetime() const override { return dict_lifetime; }
-
-    const DictionaryStructure & getStructure() const override { return dict_struct; }
-
-    bool isInjective(const std::string & attribute_name) const override
-    {
-        return dict_struct.attributes[getAttributeIndex(attribute_name)].injective;
-    }
-
-    bool hasHierarchy() const override { return false; }
-
-    void toParent(const PaddedPODArray<Key> &, PaddedPODArray<Key> &) const override { }
-
-    std::exception_ptr getLastException() const override { return storage.getLastException(); }
-
-    DictionaryKeyType getKeyType() const override { return DictionaryKeyType::simple; }
-
-    ColumnPtr getColumn(
-        const std::string& attribute_name,
-        const DataTypePtr & result_type,
-        const Columns & key_columns,
-        const DataTypes & key_types,
-        const ColumnPtr default_values_column) const override;
-
-    ColumnUInt8::Ptr hasKeys(const Columns & key_columns, const DataTypes & key_types) const override;
-
-    template <typename T>
-    using ResultArrayType = SSDCacheStorage::ResultArrayType<T>;
-
-    BlockInputStreamPtr getBlockInputStream(const Names & column_names, size_t max_block_size) const override;
-
-private:
-    size_t getAttributeIndex(const std::string & attr_name) const;
-
-    template <typename T>
-    AttributeValueVariant createAttributeNullValueWithTypeImpl(const Field & null_value);
-    AttributeValueVariant createAttributeNullValueWithType(AttributeUnderlyingType type, const Field & null_value);
-    void createAttributes();
-
-    template <typename AttributeType, typename OutputType, typename DefaultGetter>
-    void getItemsNumberImpl(
-        size_t attribute_index,
-        const PaddedPODArray<Key> & ids,
-        ResultArrayType<OutputType> & out,
-        DefaultGetter & default_value_extractor) const;
-
-    template <typename DefaultGetter>
-    void getItemsStringImpl(
-        size_t attribute_index,
-        const PaddedPODArray<Key> & ids,
-        ColumnString * out,
-        DefaultGetter & default_value_extractor) const;
-
-    const std::string name;
-    const DictionaryStructure dict_struct;
-    mutable DictionarySourcePtr source_ptr;
-    const DictionaryLifetime dict_lifetime;
-
-    const std::string path;
-    const size_t max_partitions_count;
-    const size_t file_size;
-    const size_t block_size;
-    const size_t read_buffer_size;
-    const size_t write_buffer_size;
-    const size_t max_stored_keys;
-
-    std::map<std::string, size_t> attribute_index_by_name;
-    std::vector<AttributeValueVariant> null_values;
-    mutable SSDCacheStorage storage;
-    Poco::Logger * const log;
-
-    mutable size_t bytes_allocated = 0;
-};
-
-}
-
-#endif
diff --git a/src/Dictionaries/SSDCacheDictionaryStorage.h b/src/Dictionaries/SSDCacheDictionaryStorage.h
new file mode 100644
index 000000000000..16a8954de58c
--- /dev/null
+++ b/src/Dictionaries/SSDCacheDictionaryStorage.h
@@ -0,0 +1,1364 @@
+#pragma once
+
+#if defined(__linux__) || defined(__FreeBSD__)
+
+#include <chrono>
+
+#include <pcg_random.hpp>
+#include <filesystem>
+#include <city.h>
+#include <fcntl.h>
+#include <absl/container/flat_hash_map.h>
+#include <absl/container/flat_hash_set.h>
+
+#include <common/unaligned.h>
+#include <Common/Stopwatch.h>
+#include <Common/randomSeed.h>
+#include <Common/Arena.h>
+#include <Common/ArenaWithFreeLists.h>
+#include <Common/MemorySanitizer.h>
+#include <Common/HashTable/LRUHashMap.h>
+#include <IO/AIO.h>
+#include <Dictionaries/DictionaryStructure.h>
+#include <Dictionaries/ICacheDictionaryStorage.h>
+#include <Dictionaries/DictionaryHelpers.h>
+
+namespace ProfileEvents
+{
+    extern const Event FileOpen;
+    extern const Event WriteBufferAIOWrite;
+    extern const Event WriteBufferAIOWriteBytes;
+}
+
+namespace DB
+{
+
+namespace ErrorCodes
+{
+    extern const int AIO_READ_ERROR;
+    extern const int AIO_WRITE_ERROR;
+    extern const int CANNOT_ALLOCATE_MEMORY;
+    extern const int CANNOT_CREATE_DIRECTORY;
+    extern const int CANNOT_FSYNC;
+    extern const int CANNOT_IO_GETEVENTS;
+    extern const int CANNOT_IO_SUBMIT;
+    extern const int CANNOT_OPEN_FILE;
+    extern const int CORRUPTED_DATA;
+    extern const int FILE_DOESNT_EXIST;
+    extern const int UNSUPPORTED_METHOD;
+    extern const int NOT_IMPLEMENTED;
+}
+
+struct SSDCacheDictionaryStorageConfiguration
+{
+    const size_t strict_max_lifetime_seconds;
+    const DictionaryLifetime lifetime;
+
+    const std::string file_path;
+    const size_t max_partitions_count;
+    const size_t max_stored_keys;
+    const size_t block_size;
+    const size_t file_blocks_size;
+    const size_t read_buffer_blocks_size;
+    const size_t write_buffer_blocks_size;
+};
+
+
+/** Simple Key is serialized in block with following structure
+    key     | data_size | data
+    8 bytes | 8 bytes   | data_size bytes
+
+    Complex Key is serialized in block with following structure
+    key_size     | key_data       | data_size | data
+    8 bytes      | key_size bytes | 8 bytes   | data_size bytes
+*/
+template <typename TKeyType>
+struct SSDCacheKey final
+{
+    using KeyType = TKeyType;
+
+    SSDCacheKey(KeyType key_, size_t size_, const char * data_)
+        : key(key_)
+        , size(size_)
+        , data(data_)
+    {}
+
+    KeyType key;
+    size_t size;
+    const char * data;
+};
+
+using SSDCacheSimpleKey = SSDCacheKey<UInt64>;
+using SSDCacheComplexKey = SSDCacheKey<StringRef>;
+
+/** Block is serialized with following structure
+    check_sum | keys_size | [keys]
+    8 bytes   | 8 bytes   |
+*/
+class SSDCacheBlock final
+{
+    static constexpr size_t block_header_check_sum_size = sizeof(size_t);
+    static constexpr size_t block_header_keys_size = sizeof(size_t);
+public:
+
+    /// Block header size
+    static constexpr size_t block_header_size = block_header_check_sum_size + block_header_keys_size;
+
+    explicit SSDCacheBlock(size_t block_size_)
+        : block_size(block_size_)
+    {}
+
+    /// Checks if simple key can be written in empty block with block_size
+    static bool canBeWrittenInEmptyBlock(SSDCacheSimpleKey & simple_key, size_t block_size)
+    {
+        static constexpr size_t simple_key_size = sizeof(simple_key.key);
+
+        return (block_header_size + simple_key_size + sizeof(simple_key.size) + simple_key.size) <= block_size;
+    }
+
+    /// Checks if complex key can be written in empty block with block_size
+    static bool canBeWrittenInEmptyBlock(SSDCacheComplexKey & complex_key, size_t block_size)
+    {
+        StringRef & key = complex_key.key;
+        size_t complex_key_size = sizeof(key.size) + key.size;
+
+        return (block_header_size + complex_key_size + sizeof(complex_key.size) + complex_key.size) <= block_size;
+    }
+
+    /// Reset block with new block_data
+    /// block_data must be filled with zeroes if it is new block
+    ALWAYS_INLINE inline void reset(char * new_block_data)
+    {
+        block_data = new_block_data;
+        current_block_offset = block_header_size;
+        keys_size = unalignedLoad<size_t>(new_block_data + block_header_check_sum_size);
+    }
+
+    /// Check if it is enough place to write key in block
+    ALWAYS_INLINE inline bool enoughtPlaceToWriteKey(const SSDCacheSimpleKey & cache_key) const
+    {
+        return (current_block_offset + (sizeof(cache_key.key) + sizeof(cache_key.size) + cache_key.size)) <= block_size;
+    }
+
+    /// Check if it is enough place to write key in block
+    ALWAYS_INLINE inline bool enoughtPlaceToWriteKey(const SSDCacheComplexKey & cache_key) const
+    {
+        const StringRef & key = cache_key.key;
+        size_t complex_key_size = sizeof(key.size) + key.size;
+
+        return (current_block_offset + (complex_key_size + sizeof(cache_key.size) + cache_key.size)) <= block_size;
+    }
+
+    /// Write key and returns offset in ssd cache block where data is written
+    /// It is client responsibility to check if there is enough place in block to write key
+    /// Returns true if key was written and false if there was not enough place to write key
+    ALWAYS_INLINE inline bool writeKey(const SSDCacheSimpleKey & cache_key, size_t & offset_in_block)
+    {
+        assert(cache_key.size > 0);
+
+        if (!enoughtPlaceToWriteKey(cache_key))
+            return false;
+
+        char * current_block_offset_data = block_data + current_block_offset;
+
+        /// Write simple key
+        memcpy(reinterpret_cast<void *>(current_block_offset_data), reinterpret_cast<const void *>(&cache_key.key), sizeof(cache_key.key));
+        current_block_offset_data += sizeof(cache_key.key);
+        current_block_offset += sizeof(cache_key.key);
+
+        /// Write serialized columns size
+        memcpy(reinterpret_cast<void *>(current_block_offset_data), reinterpret_cast<const void *>(&cache_key.size), sizeof(cache_key.size));
+        current_block_offset_data += sizeof(cache_key.size);
+        current_block_offset += sizeof(cache_key.size);
+
+        offset_in_block = current_block_offset;
+
+        memcpy(reinterpret_cast<void *>(current_block_offset_data), reinterpret_cast<const void *>(cache_key.data), cache_key.size);
+        current_block_offset += cache_key.size;
+
+        ++keys_size;
+
+        return true;
+    }
+
+    ALWAYS_INLINE inline bool writeKey(const SSDCacheComplexKey & cache_key, size_t & offset_in_block)
+    {
+        assert(cache_key.size > 0);
+
+        if (!enoughtPlaceToWriteKey(cache_key))
+            return false;
+
+        char * current_block_offset_data = block_data + current_block_offset;
+
+        const StringRef & key = cache_key.key;
+
+        /// Write complex key
+        memcpy(reinterpret_cast<void *>(current_block_offset_data), reinterpret_cast<const void *>(&key.size), sizeof(key.size));
+        current_block_offset_data += sizeof(key.size);
+        current_block_offset += sizeof(key.size);
+
+        memcpy(reinterpret_cast<void *>(current_block_offset_data), reinterpret_cast<const void *>(key.data), key.size);
+        current_block_offset_data += key.size;
+        current_block_offset += key.size;
+
+        /// Write serialized columns size
+        memcpy(reinterpret_cast<void *>(current_block_offset_data), reinterpret_cast<const void *>(&cache_key.size), sizeof(cache_key.size));
+        current_block_offset_data += sizeof(cache_key.size);
+        current_block_offset += sizeof(cache_key.size);
+
+        offset_in_block = current_block_offset;
+
+        memcpy(reinterpret_cast<void *>(current_block_offset_data), reinterpret_cast<const void *>(cache_key.data), cache_key.size);
+        current_block_offset += cache_key.size;
+
+        ++keys_size;
+
+        return true;
+    }
+
+    ALWAYS_INLINE inline size_t getKeysSize() const { return keys_size; }
+
+    /// Write keys size into block header
+    ALWAYS_INLINE inline void writeKeysSize()
+    {
+        char * keys_size_offset_data = block_data + block_header_check_sum_size;
+        std::memcpy(keys_size_offset_data, &keys_size, sizeof(size_t));
+    }
+
+    /// Get check sum from block header
+    ALWAYS_INLINE inline size_t getCheckSum() const { return unalignedLoad<size_t>(block_data); }
+
+    /// Calculate check sum in block
+    ALWAYS_INLINE inline size_t calculateCheckSum() const
+    {
+        size_t calculated_check_sum = static_cast<size_t>(CityHash_v1_0_2::CityHash64(block_data + block_header_check_sum_size, block_size - block_header_check_sum_size));
+
+        return calculated_check_sum;
+    }
+
+    /// Check if check sum from block header matched calculated check sum in block
+    ALWAYS_INLINE inline bool checkCheckSum() const
+    {
+        size_t calculated_check_sum = calculateCheckSum();
+        size_t check_sum = getCheckSum();
+
+        return calculated_check_sum == check_sum;
+    }
+
+    /// Write check sum in block header
+    ALWAYS_INLINE inline void writeCheckSum()
+    {
+        size_t check_sum = static_cast<size_t>(CityHash_v1_0_2::CityHash64(block_data + block_header_check_sum_size, block_size - block_header_check_sum_size));
+        std::memcpy(block_data, &check_sum, sizeof(size_t));
+    }
+
+    ALWAYS_INLINE inline size_t getBlockSize() const { return block_size; }
+
+    /// Returns block data
+    ALWAYS_INLINE inline char * getBlockData() const { return block_data; }
+
+    /// Read keys that were serialized in block
+    /// It is client responsibility to ensure that simple or complex keys were written in block
+    void readSimpleKeys(PaddedPODArray<UInt64> & simple_keys) const
+    {
+        char * block_start = block_data + block_header_size;
+        char * block_end = block_data + block_size;
+
+        static constexpr size_t key_prefix_size = sizeof(UInt64) + sizeof(size_t);
+
+        while (block_start + key_prefix_size < block_end)
+        {
+            UInt64 key = unalignedLoad<UInt64>(block_start);
+            block_start += sizeof(UInt64);
+
+            size_t allocated_size = unalignedLoad<size_t>(block_start);
+            block_start += sizeof(size_t);
+
+            /// If we read empty allocated size that means it is end of block
+            if (allocated_size == 0)
+                break;
+
+            simple_keys.emplace_back(key);
+            block_start += allocated_size;
+        }
+    }
+
+    void readComplexKeys(PaddedPODArray<StringRef> & complex_keys) const
+    {
+        char * block_start = block_data + block_header_size;
+        char * block_end = block_data + block_size;
+
+        static constexpr size_t key_prefix_size = sizeof(size_t) + sizeof(size_t);
+
+        while (block_start + key_prefix_size < block_end)
+        {
+            size_t key_size = unalignedLoad<size_t>(block_start);
+            block_start += sizeof(key_size);
+
+            StringRef complex_key (block_start, key_size);
+
+            block_start += key_size;
+
+            size_t allocated_size = unalignedLoad<size_t>(block_start);
+            block_start += sizeof(size_t);
+
+            /// If we read empty allocated size that means it is end of block
+            if (allocated_size == 0)
+                break;
+
+            complex_keys.emplace_back(complex_key);
+            block_start += allocated_size;
+        }
+    }
+
+private:
+    size_t block_size;
+    char * block_data = nullptr;
+
+    size_t current_block_offset = block_header_size;
+    size_t keys_size = 0;
+};
+
+struct SSDCacheIndex
+{
+    SSDCacheIndex(size_t block_index_, size_t offset_in_block_)
+        : block_index(block_index_)
+        , offset_in_block(offset_in_block_)
+    {}
+
+    SSDCacheIndex() = default;
+
+    size_t block_index = 0;
+    size_t offset_in_block = 0;
+};
+
+inline bool operator==(const SSDCacheIndex & lhs, const SSDCacheIndex & rhs)
+{
+    return lhs.block_index == rhs.block_index && lhs.offset_in_block == rhs.offset_in_block;
+}
+
+/** SSDCacheMemoryBuffer initialized with block size and memory buffer blocks size.
+  * Allocate block_size * memory_buffer_blocks_size bytes with page alignment.
+  * Logically represents multiple memory_buffer_blocks_size blocks and current write block.
+  * If key cannot be written into current_write_block, current block keys size and check summ is written
+  * and buffer increase index of current_write_block_index.
+  * If current_write_block_index == memory_buffer_blocks_size write key will always returns true.
+  * If reset is called current_write_block_index is set to 0.
+  */
+template <typename SSDCacheKeyType>
+class SSDCacheMemoryBuffer
+{
+public:
+    using KeyType = typename SSDCacheKeyType::KeyType;
+
+    explicit SSDCacheMemoryBuffer(size_t block_size_, size_t memory_buffer_blocks_size_)
+        : block_size(block_size_)
+        , partition_blocks_size(memory_buffer_blocks_size_)
+        , buffer(block_size * partition_blocks_size, 4096)
+        , current_write_block(block_size)
+    {
+        current_write_block.reset(buffer.m_data);
+    }
+
+    bool writeKey(const SSDCacheKeyType & key, SSDCacheIndex & index)
+    {
+        if (current_block_index == partition_blocks_size)
+            return false;
+
+        size_t block_offset = 0;
+        bool write_in_current_block = current_write_block.writeKey(key, block_offset);
+
+        if (write_in_current_block)
+        {
+            index.block_index = current_block_index;
+            index.offset_in_block = block_offset;
+            return true;
+        }
+
+        current_write_block.writeKeysSize();
+        current_write_block.writeCheckSum();
+
+        ++current_block_index;
+
+        if (current_block_index == partition_blocks_size)
+            return false;
+
+        current_write_block.reset(buffer.m_data + (block_size * current_block_index));
+
+        write_in_current_block = current_write_block.writeKey(key, block_offset);
+        assert(write_in_current_block);
+
+        index.block_index = current_block_index;
+        index.offset_in_block = block_offset;
+
+        return write_in_current_block;
+    }
+
+    void writeKeysSizeAndCheckSumForCurrentWriteBlock()
+    {
+        current_write_block.writeKeysSize();
+        current_write_block.writeCheckSum();
+    }
+
+    inline char * getPlace(SSDCacheIndex index) const
+    {
+        return buffer.m_data + index.block_index * block_size + index.offset_in_block;
+    }
+
+    inline size_t getCurrentBlockIndex() const { return current_block_index; }
+
+    inline const char * getData() const { return buffer.m_data; }
+
+    inline size_t getSizeInBytes() const { return block_size * partition_blocks_size; }
+
+    void readKeys(PaddedPODArray<KeyType> & keys) const
+    {
+        SSDCacheBlock block(block_size);
+
+        for (size_t block_index = 0; block_index < partition_blocks_size; ++block_index)
+        {
+            block.reset(buffer.m_data + (block_index * block_size));
+
+            if constexpr (std::is_same_v<KeyType, UInt64>)
+                block.readSimpleKeys(keys);
+            else
+                block.readComplexKeys(keys);
+        }
+    }
+
+    inline void reset()
+    {
+        current_block_index = 0;
+        current_write_block.reset(buffer.m_data);
+    }
+
+    const size_t block_size;
+
+    const size_t partition_blocks_size;
+
+private:
+    Memory<Allocator<true>> buffer;
+
+    SSDCacheBlock current_write_block;
+
+    size_t current_block_index = 0;
+};
+
+/// TODO: Add documentation
+template <typename SSDCacheKeyType>
+class SSDCacheFileBuffer : private boost::noncopyable
+{
+    static constexpr auto BIN_FILE_EXT = ".bin";
+
+public:
+
+    using KeyType = typename SSDCacheKeyType::KeyType;
+
+    explicit SSDCacheFileBuffer(
+        const std::string & file_path_,
+        size_t block_size_,
+        size_t file_blocks_size_)
+        : file_path(file_path_ + BIN_FILE_EXT)
+        , block_size(block_size_)
+        , file_blocks_size(file_blocks_size_)
+    {
+        auto path = std::filesystem::path{file_path};
+        auto parent_path_directory = path.parent_path();
+
+        /// If cache file is in directory that does not exists create it
+        if (!std::filesystem::exists(parent_path_directory))
+            if (!std::filesystem::create_directories(parent_path_directory))
+                throw Exception{"Failed to create directories.", ErrorCodes::CANNOT_CREATE_DIRECTORY};
+
+        ProfileEvents::increment(ProfileEvents::FileOpen);
+
+        file.fd = ::open(file_path.c_str(), O_RDWR | O_CREAT | O_TRUNC | O_DIRECT, 0666);
+        if (file.fd == -1)
+        {
+            auto error_code = (errno == ENOENT) ? ErrorCodes::FILE_DOESNT_EXIST : ErrorCodes::CANNOT_OPEN_FILE;
+            throwFromErrnoWithPath("Cannot open file " + file_path, file_path, error_code);
+        }
+
+        allocateSizeForNextPartition();
+    }
+
+    void allocateSizeForNextPartition()
+    {
+        if (preallocateDiskSpace(file.fd, current_blocks_size * block_size, block_size * file_blocks_size) < 0)
+            throwFromErrnoWithPath("Cannot preallocate space for the file " + file_path, file_path, ErrorCodes::CANNOT_ALLOCATE_MEMORY);
+
+        current_blocks_size += file_blocks_size;
+    }
+
+    bool writeBuffer(const char * buffer, size_t buffer_size_in_blocks)
+    {
+        if (current_block_index + buffer_size_in_blocks > current_blocks_size)
+            return false;
+
+        AIOContext aio_context{1};
+
+        iocb write_request{};
+        iocb * write_request_ptr{&write_request};
+
+        #if defined(__FreeBSD__)
+        write_request.aio.aio_lio_opcode = LIO_WRITE;
+        write_request.aio.aio_fildes = file.fd;
+        write_request.aio.aio_buf = reinterpret_cast<volatile void *>(const_cast<char *>(buffer));
+        write_request.aio.aio_nbytes = block_size * buffer_size_in_blocks;
+        write_request.aio.aio_offset = current_block_index * block_size;
+        #else
+        write_request.aio_lio_opcode = IOCB_CMD_PWRITE;
+        write_request.aio_fildes = file.fd;
+        write_request.aio_buf = reinterpret_cast<UInt64>(buffer);
+        write_request.aio_nbytes = block_size * buffer_size_in_blocks;
+        write_request.aio_offset = current_block_index * block_size;
+        #endif
+
+        while (io_submit(aio_context.ctx, 1, &write_request_ptr) < 0)
+        {
+            if (errno != EINTR)
+                throw Exception("Cannot submit request for asynchronous IO on file " + file_path, ErrorCodes::CANNOT_IO_SUBMIT);
+        }
+
+        // CurrentMetrics::Increment metric_increment_write{CurrentMetrics::Write};
+
+        io_event event;
+
+        while (io_getevents(aio_context.ctx, 1, 1, &event, nullptr) < 0)
+        {
+            if (errno != EINTR)
+                throw Exception("Failed to wait for asynchronous IO completion on file " + file_path, ErrorCodes::CANNOT_IO_GETEVENTS);
+        }
+
+        // Unpoison the memory returned from an uninstrumented system function.
+        __msan_unpoison(&event, sizeof(event));
+
+        auto bytes_written = eventResult(event);
+
+        ProfileEvents::increment(ProfileEvents::WriteBufferAIOWrite);
+        ProfileEvents::increment(ProfileEvents::WriteBufferAIOWriteBytes, bytes_written);
+
+        if (bytes_written != static_cast<decltype(bytes_written)>(block_size * buffer_size_in_blocks))
+            throw Exception("Not all data was written for asynchronous IO on file " + file_path + ". returned: " + std::to_string(bytes_written), ErrorCodes::AIO_WRITE_ERROR);
+
+        if (::fsync(file.fd) < 0)
+            throwFromErrnoWithPath("Cannot fsync " + file_path, file_path, ErrorCodes::CANNOT_FSYNC);
+
+        current_block_index += buffer_size_in_blocks;
+
+        return true;
+    }
+
+    bool readKeys(size_t block_start, size_t blocks_length, PaddedPODArray<KeyType> & out) const
+    {
+        if (block_start + blocks_length > current_blocks_size)
+            return false;
+
+        size_t buffer_size_in_bytes = blocks_length * block_size;
+
+        Memory read_buffer_memory(block_size * blocks_length, block_size);
+
+        iocb request{};
+        iocb * request_ptr = &request;
+
+        #if defined(__FreeBSD__)
+        request.aio.aio_lio_opcode = LIO_READ;
+        request.aio.aio_fildes = file.fd;
+        request.aio.aio_buf = reinterpret_cast<volatile void *>(reinterpret_cast<UInt64>(read_buffer_memory.data()));
+        request.aio.aio_nbytes = buffer_size_in_bytes;
+        request.aio.aio_offset = block_start * block_size;
+        request.aio_data = 0;
+        #else
+        request.aio_lio_opcode = IOCB_CMD_PREAD;
+        request.aio_fildes = file.fd;
+        request.aio_buf = reinterpret_cast<UInt64>(read_buffer_memory.data());
+        request.aio_nbytes = buffer_size_in_bytes;
+        request.aio_offset = block_start * block_size;
+        request.aio_data = 0;
+        #endif
+
+        io_event event{};
+        AIOContext aio_context(1);
+
+        while (io_submit(aio_context.ctx, 1, &request_ptr) != 1)
+        {
+            if (errno != EINTR)
+                throwFromErrno("io_submit: Failed to submit a request for asynchronous IO", ErrorCodes::CANNOT_IO_SUBMIT);
+        }
+
+        while (io_getevents(aio_context.ctx, 1, 1, &event, nullptr) != 1)
+        {
+            if (errno != EINTR)
+                throwFromErrno("io_getevents: Failed to get an event for asynchronous IO", ErrorCodes::CANNOT_IO_GETEVENTS);
+        }
+
+        auto read_bytes = eventResult(event);
+
+        if (read_bytes != static_cast<ssize_t>(buffer_size_in_bytes))
+            throw Exception(ErrorCodes::AIO_READ_ERROR,
+                "GC: AIO failed to read file ({}). Expected bytes ({}). Actual bytes ({})", file_path, buffer_size_in_bytes, read_bytes);
+
+        SSDCacheBlock block(block_size);
+
+        for (size_t i = 0; i < blocks_length; ++i)
+        {
+            block.reset(read_buffer_memory.data() + (i * block_size));
+
+            if constexpr (std::is_same_v<SSDCacheKeyType, SSDCacheSimpleKey>)
+                block.readSimpleKeys(out);
+            else
+                block.readComplexKeys(out);
+        }
+
+        return true;
+    }
+
+    template <typename FetchBlockFunc>
+    ALWAYS_INLINE void fetchBlocks(char * read_buffer, size_t read_from_file_buffer_blocks_size, const PaddedPODArray<size_t> & blocks_to_fetch, FetchBlockFunc && func) const
+    {
+        if (blocks_to_fetch.empty())
+            return;
+
+        size_t blocks_to_fetch_size = blocks_to_fetch.size();
+
+        PaddedPODArray<iocb> requests;
+        PaddedPODArray<iocb *> pointers;
+
+        requests.reserve(blocks_to_fetch_size);
+        pointers.reserve(blocks_to_fetch_size);
+
+        for (size_t block_to_fetch_index = 0; block_to_fetch_index < blocks_to_fetch_size; ++block_to_fetch_index)
+        {
+            iocb request{};
+
+            char * buffer_place = read_buffer + block_size * (block_to_fetch_index % read_from_file_buffer_blocks_size);
+
+            #if defined(__FreeBSD__)
+            request.aio.aio_lio_opcode = LIO_READ;
+            request.aio.aio_fildes = file.fd;
+            request.aio.aio_buf = reinterpret_cast<volatile void *>(reinterpret_cast<UInt64>(buffer_place));
+            request.aio.aio_nbytes = block_size;
+            request.aio.aio_offset = block_size * blocks_to_fetch[block_to_fetch_index];
+            request.aio_data = block_to_fetch_index;
+            #else
+            request.aio_lio_opcode = IOCB_CMD_PREAD;
+            request.aio_fildes = file.fd;
+            request.aio_buf = reinterpret_cast<UInt64>(buffer_place);
+            request.aio_nbytes = block_size;
+            request.aio_offset = block_size * blocks_to_fetch[block_to_fetch_index];
+            request.aio_data = block_to_fetch_index;
+            #endif
+
+            requests.push_back(request);
+            pointers.push_back(&requests.back());
+        }
+
+        AIOContext aio_context(read_from_file_buffer_blocks_size);
+
+        PaddedPODArray<bool> processed(requests.size(), false);
+        PaddedPODArray<io_event> events;
+        events.resize_fill(requests.size());
+
+        size_t to_push = 0;
+        size_t to_pop = 0;
+
+        while (to_pop < requests.size())
+        {
+            int popped = 0;
+
+            while (to_pop < to_push && (popped = io_getevents(aio_context.ctx, to_push - to_pop, to_push - to_pop, &events[to_pop], nullptr)) <= 0)
+            {
+                if (errno != EINTR)
+                    throwFromErrno("io_getevents: Failed to get an event for asynchronous IO", ErrorCodes::CANNOT_IO_GETEVENTS);
+            }
+
+            for (size_t i = to_pop; i < to_pop + popped; ++i)
+            {
+                size_t block_to_fetch_index = events[i].data;
+                const auto & request = requests[block_to_fetch_index];
+
+                const ssize_t read_bytes = eventResult(events[i]);
+
+                if (read_bytes != static_cast<ssize_t>(block_size))
+                    throw Exception(ErrorCodes::AIO_READ_ERROR,
+                        "GC: AIO failed to read file ({}). Expected bytes ({}). Actual bytes ({})", file_path, block_size, read_bytes);
+
+                char * request_buffer = getRequestBuffer(request);
+
+                // Unpoison the memory returned from an uninstrumented system function.
+                __msan_unpoison(request_buffer, block_size);
+
+                SSDCacheBlock block(block_size);
+                block.reset(request_buffer);
+
+                if (!block.checkCheckSum())
+                {
+                    std::string calculated_check_sum = std::to_string(block.calculateCheckSum());
+                    std::string check_sum = std::to_string(block.getCheckSum());
+                    throw Exception("Cache data corrupted. Checksum validation failed. Calculated " +  calculated_check_sum + " in block " + check_sum, ErrorCodes::CORRUPTED_DATA);
+                }
+
+                std::forward<FetchBlockFunc>(func)(blocks_to_fetch[block_to_fetch_index], block.getBlockData());
+
+                processed[block_to_fetch_index] = true;
+            }
+
+            while (to_pop < requests.size() && processed[to_pop])
+                ++to_pop;
+
+            /// add new io tasks
+            const int new_tasks_count = std::min(read_from_file_buffer_blocks_size - (to_push - to_pop), requests.size() - to_push);
+
+            int pushed = 0;
+            while (new_tasks_count > 0 && (pushed = io_submit(aio_context.ctx, new_tasks_count, &pointers[to_push])) <= 0)
+            {
+                if (errno != EINTR)
+                    throwFromErrno("io_submit: Failed to submit a request for asynchronous IO", ErrorCodes::CANNOT_IO_SUBMIT);
+            }
+
+            to_push += pushed;
+        }
+    }
+
+    inline size_t getCurrentBlockIndex() const { return current_block_index; }
+
+    inline void reset()
+    {
+        current_block_index = 0;
+    }
+private:
+    struct FileDescriptor : private boost::noncopyable
+    {
+
+        FileDescriptor() = default;
+
+        FileDescriptor(FileDescriptor && rhs) : fd(rhs.fd) { rhs.fd = -1; }
+
+        FileDescriptor & operator=(FileDescriptor && rhs)
+        {
+            close(fd);
+
+            fd = rhs.fd;
+            rhs.fd = -1;
+        }
+
+        ~FileDescriptor()
+        {
+            if (fd != -1)
+                close(fd);
+        }
+
+        int fd = -1;
+    };
+
+    ALWAYS_INLINE inline static int preallocateDiskSpace(int fd, size_t offset, size_t len)
+    {
+        #if defined(__FreeBSD__)
+            return posix_fallocate(fd, offset, len);
+        #else
+            return fallocate(fd, 0, offset, len);
+        #endif
+    }
+
+    ALWAYS_INLINE inline static char * getRequestBuffer(const iocb & request)
+    {
+        char * result = nullptr;
+
+        #if defined(__FreeBSD__)
+            result = reinterpret_cast<char *>(reinterpret_cast<UInt64>(request.aio.aio_buf));
+        #else
+            result = reinterpret_cast<char *>(request.aio_buf);
+        #endif
+
+        return result;
+    }
+
+    ALWAYS_INLINE inline static ssize_t eventResult(io_event & event)
+    {
+        ssize_t  bytes_written;
+
+        #if defined(__FreeBSD__)
+            bytes_written = aio_return(reinterpret_cast<struct aiocb *>(event.udata));
+        #else
+            bytes_written = event.res;
+        #endif
+
+        return bytes_written;
+    }
+
+    String file_path;
+    size_t block_size;
+    size_t file_blocks_size;
+    FileDescriptor file;
+
+    size_t current_block_index = 0;
+    size_t current_blocks_size = 0;
+};
+
+/// TODO: Add documentation
+template <DictionaryKeyType dictionary_key_type>
+class SSDCacheDictionaryStorage final : public ICacheDictionaryStorage
+{
+public:
+    using SSDCacheKeyType = std::conditional_t<dictionary_key_type == DictionaryKeyType::simple, SSDCacheSimpleKey, SSDCacheComplexKey>;
+    using KeyType = std::conditional_t<dictionary_key_type == DictionaryKeyType::simple, UInt64, StringRef>;
+
+    explicit SSDCacheDictionaryStorage(const SSDCacheDictionaryStorageConfiguration & configuration_)
+        : configuration(configuration_)
+        , file_buffer(configuration_.file_path, configuration.block_size, configuration.file_blocks_size)
+        , read_from_file_buffer(configuration_.block_size * configuration_.read_buffer_blocks_size, 4096)
+        , rnd_engine(randomSeed())
+        , index(configuration.max_stored_keys, false, { complex_key_arena })
+    {
+        memory_buffer_partitions.emplace_back(configuration.block_size, configuration.write_buffer_blocks_size);
+    }
+
+    bool returnsFetchedColumnsInOrderOfRequestedKeys() const override { return false; }
+
+    String getName() const override
+    {
+        if (dictionary_key_type == DictionaryKeyType::simple)
+            return "SSDCache";
+        else
+            return "SSDComplexKeyCache";
+    }
+
+    bool supportsSimpleKeys() const override { return dictionary_key_type == DictionaryKeyType::simple; }
+
+    SimpleKeysStorageFetchResult fetchColumnsForKeys(
+        const PaddedPODArray<UInt64> & keys,
+        const DictionaryStorageFetchRequest & fetch_request) override
+    {
+        if constexpr (dictionary_key_type == DictionaryKeyType::simple)
+            return fetchColumnsForKeysImpl<SimpleKeysStorageFetchResult>(keys, fetch_request);
+        else
+            throw Exception("Method insertColumnsForKeys is not supported for complex key storage", ErrorCodes::NOT_IMPLEMENTED);
+    }
+
+    void insertColumnsForKeys(const PaddedPODArray<UInt64> & keys, Columns columns) override
+    {
+        if constexpr (dictionary_key_type == DictionaryKeyType::simple)
+            insertColumnsForKeysImpl(keys, columns);
+        else
+            throw Exception("Method insertColumnsForKeys is not supported for complex key storage", ErrorCodes::NOT_IMPLEMENTED);
+    }
+
+    void insertDefaultKeys(const PaddedPODArray<UInt64> & keys) override
+    {
+        if constexpr (dictionary_key_type == DictionaryKeyType::simple)
+            insertDefaultKeysImpl(keys);
+        else
+            throw Exception("Method insertDefaultKeysImpl is not supported for complex key storage", ErrorCodes::NOT_IMPLEMENTED);
+    }
+
+    PaddedPODArray<UInt64> getCachedSimpleKeys() const override
+    {
+        if constexpr (dictionary_key_type == DictionaryKeyType::simple)
+            return getCachedKeysImpl();
+        else
+            throw Exception("Method getCachedSimpleKeys is not supported for complex key storage", ErrorCodes::NOT_IMPLEMENTED);
+    }
+
+    bool supportsComplexKeys() const override { return dictionary_key_type == DictionaryKeyType::complex; }
+
+    ComplexKeysStorageFetchResult fetchColumnsForKeys(
+        const PaddedPODArray<StringRef> & keys,
+        const DictionaryStorageFetchRequest & fetch_request) override
+    {
+        if constexpr (dictionary_key_type == DictionaryKeyType::complex)
+            return fetchColumnsForKeysImpl<ComplexKeysStorageFetchResult>(keys, fetch_request);
+        else
+            throw Exception("Method fetchColumnsForKeys is not supported for simple key storage", ErrorCodes::NOT_IMPLEMENTED);
+    }
+
+    void insertColumnsForKeys(const PaddedPODArray<StringRef> & keys, Columns columns) override
+    {
+        if constexpr (dictionary_key_type == DictionaryKeyType::complex)
+            insertColumnsForKeysImpl(keys, columns);
+        else
+            throw Exception("Method insertColumnsForKeys is not supported for simple key storage", ErrorCodes::NOT_IMPLEMENTED);
+    }
+
+    void insertDefaultKeys(const PaddedPODArray<StringRef> & keys) override
+    {
+        if constexpr (dictionary_key_type == DictionaryKeyType::complex)
+            insertDefaultKeysImpl(keys);
+        else
+            throw Exception("Method insertDefaultKeysImpl is not supported for simple key storage", ErrorCodes::NOT_IMPLEMENTED);
+    }
+
+    PaddedPODArray<StringRef> getCachedComplexKeys() const override
+    {
+        if constexpr (dictionary_key_type == DictionaryKeyType::complex)
+            return getCachedKeysImpl();
+        else
+            throw Exception("Method getCachedSimpleKeys is not supported for simple key storage", ErrorCodes::NOT_IMPLEMENTED);
+    }
+
+    size_t getSize() const override { return index.size(); }
+
+    size_t getMaxSize() const override {return index.getMaxSize(); }
+
+    size_t getBytesAllocated() const override
+    {
+        size_t memory_partitions_bytes_size = memory_buffer_partitions.size() * configuration.write_buffer_blocks_size * configuration.block_size;
+        size_t file_partitions_bytes_size = memory_buffer_partitions.size() * configuration.file_blocks_size * configuration.block_size;
+
+        return index.getSizeInBytes() + memory_partitions_bytes_size + file_partitions_bytes_size;
+    }
+
+private:
+
+    using TimePoint = std::chrono::system_clock::time_point;
+
+    struct Cell
+    {
+        enum CellState
+        {
+            in_memory,
+            on_disk,
+            default_value
+        };
+
+        TimePoint deadline;
+
+        SSDCacheIndex index;
+        size_t in_memory_partition_index;
+        CellState state;
+
+        inline bool isInMemory() const { return state == in_memory; }
+        inline bool isOnDisk() const { return state == on_disk; }
+        inline bool isDefaultValue() const { return state == default_value; }
+    };
+
+    struct KeyToBlockOffset
+    {
+        KeyToBlockOffset(size_t key_index_, size_t offset_in_block_, bool is_expired_)
+            : key_index(key_index_), offset_in_block(offset_in_block_), is_expired(is_expired_)
+        {}
+
+        size_t key_index = 0;
+        size_t offset_in_block = 0;
+        bool is_expired = false;
+    };
+
+    template <typename Result>
+    Result fetchColumnsForKeysImpl(
+        const PaddedPODArray<KeyType> & keys,
+        const DictionaryStorageFetchRequest & fetch_request) const
+    {
+        Result result;
+
+        result.fetched_columns = fetch_request.makeAttributesResultColumns();
+        result.key_index_to_state.resize_fill(keys.size(), {KeyState::not_found});
+
+        const auto now = std::chrono::system_clock::now();
+
+        size_t fetched_columns_index = 0;
+
+        using BlockIndexToKeysMap = std::unordered_map<size_t, std::vector<KeyToBlockOffset>, DefaultHash<size_t>>;
+        BlockIndexToKeysMap block_to_keys_map;
+        absl::flat_hash_set<size_t, DefaultHash<size_t>> unique_blocks_to_request;
+        PaddedPODArray<size_t> blocks_to_request;
+
+        std::chrono::seconds strict_max_lifetime_seconds(configuration.strict_max_lifetime_seconds);
+        size_t keys_size = keys.size();
+
+        for (size_t key_index = 0; key_index < keys_size; ++key_index)
+        {
+            auto key = keys[key_index];
+
+            const auto * it = index.find(key);
+
+            if (!it)
+            {
+                ++result.not_found_keys_size;
+                continue;
+            }
+
+            const auto & cell = it->getMapped();
+
+            bool has_deadline = cellHasDeadline(cell);
+
+            if (has_deadline && now > cell.deadline + strict_max_lifetime_seconds)
+            {
+                ++result.not_found_keys_size;
+                continue;
+            }
+
+            bool cell_is_expired = false;
+            KeyState::State key_state = KeyState::found;
+
+            if (has_deadline && now > cell.deadline)
+            {
+                cell_is_expired = true;
+                key_state = KeyState::expired;
+            }
+
+            result.expired_keys_size += cell_is_expired;
+            result.found_keys_size += !cell_is_expired;
+
+            switch (cell.state)
+            {
+                case Cell::in_memory:
+                {
+                    result.key_index_to_state[key_index] = {key_state, fetched_columns_index};
+                    ++fetched_columns_index;
+
+                    const auto & partition = memory_buffer_partitions[cell.in_memory_partition_index];
+                    char * serialized_columns_place = partition.getPlace(cell.index);
+                    deserializeAndInsertIntoColumns(result.fetched_columns, fetch_request, serialized_columns_place);
+                    break;
+                }
+                case Cell::on_disk:
+                {
+                    block_to_keys_map[cell.index.block_index].emplace_back(key_index, cell.index.offset_in_block, cell_is_expired);
+
+                    if (!unique_blocks_to_request.contains(cell.index.block_index))
+                    {
+                        blocks_to_request.emplace_back(cell.index.block_index);
+                        unique_blocks_to_request.insert(cell.index.block_index);
+                    }
+                    break;
+                }
+                case Cell::default_value:
+                {
+                    result.key_index_to_state[key_index] = {key_state, fetched_columns_index};
+                    result.key_index_to_state[key_index].setDefault();
+                    ++fetched_columns_index;
+                    ++result.default_keys_size;
+
+                    insertDefaultValuesIntoColumns(result.fetched_columns, fetch_request, key_index);
+                    break;
+                }
+            }
+        }
+
+        /// Sort blocks by offset before start async io requests
+        std::sort(blocks_to_request.begin(), blocks_to_request.end());
+
+        file_buffer.fetchBlocks(read_from_file_buffer.m_data, configuration.read_buffer_blocks_size, blocks_to_request, [&](size_t block_index, char * block_data)
+        {
+            auto & keys_in_block = block_to_keys_map[block_index];
+
+            for (auto & key_in_block : keys_in_block)
+            {
+                char * key_data = block_data + key_in_block.offset_in_block;
+                deserializeAndInsertIntoColumns(result.fetched_columns, fetch_request, key_data);
+
+                if (key_in_block.is_expired)
+                    result.key_index_to_state[key_in_block.key_index] = {KeyState::expired, fetched_columns_index};
+                else
+                    result.key_index_to_state[key_in_block.key_index] = {KeyState::found, fetched_columns_index};
+
+                ++fetched_columns_index;
+            }
+        });
+
+        return result;
+    }
+
+    void insertColumnsForKeysImpl(const PaddedPODArray<KeyType> & keys, Columns columns)
+    {
+        size_t columns_to_serialize_size = columns.size();
+        PaddedPODArray<StringRef> temporary_column_data(columns_to_serialize_size);
+
+        Arena temporary_values_pool;
+
+        const auto now = std::chrono::system_clock::now();
+
+        for (size_t key_index = 0; key_index < keys.size(); ++key_index)
+        {
+            size_t allocated_size_for_columns = 0;
+            const char * block_start = nullptr;
+
+            auto key = keys[key_index];
+
+            for (size_t column_index = 0; column_index < columns_to_serialize_size; ++column_index)
+            {
+                auto & column = columns[column_index];
+                temporary_column_data[column_index] = column->serializeValueIntoArena(key_index, temporary_values_pool, block_start);
+                allocated_size_for_columns += temporary_column_data[column_index].size;
+            }
+
+            SSDCacheKeyType ssd_cache_key { key, allocated_size_for_columns, block_start };
+
+            if (!SSDCacheBlock::canBeWrittenInEmptyBlock(ssd_cache_key, configuration.block_size))
+                throw Exception("Serialized columns size is greater than allowed block size and metadata", ErrorCodes::UNSUPPORTED_METHOD);
+
+            /// We cannot reuse place that is already allocated in file or memory cache so we erase key from index
+            index.erase(key);
+
+            Cell cell;
+            setCellDeadline(cell, now);
+
+            if constexpr (dictionary_key_type == DictionaryKeyType::complex)
+            {
+                /// Copy complex key into arena and put in cache
+                size_t key_size = key.size;
+                char * place_for_key = complex_key_arena.alloc(key_size);
+                memcpy(reinterpret_cast<void *>(place_for_key), reinterpret_cast<const void *>(key.data), key_size);
+                KeyType updated_key{place_for_key, key_size};
+                ssd_cache_key.key = updated_key;
+            }
+
+            insertCell(ssd_cache_key, cell);
+
+            temporary_values_pool.rollback(allocated_size_for_columns);
+        }
+    }
+
+    void insertDefaultKeysImpl(const PaddedPODArray<KeyType> & keys)
+    {
+        const auto now = std::chrono::system_clock::now();
+
+        for (auto key : keys)
+        {
+            /// We cannot reuse place that is already allocated in file or memory cache so we erase key from index
+            index.erase(key);
+
+            Cell cell;
+
+            setCellDeadline(cell, now);
+            cell.index = {0, 0};
+            cell.in_memory_partition_index = 0;
+            cell.state = Cell::default_value;
+
+
+            if constexpr (dictionary_key_type == DictionaryKeyType::complex)
+            {
+                /// Copy complex key into arena and put in cache
+                size_t key_size = key.size;
+                char * place_for_key = complex_key_arena.alloc(key_size);
+                memcpy(reinterpret_cast<void *>(place_for_key), reinterpret_cast<const void *>(key.data), key_size);
+                KeyType updated_key{place_for_key, key_size};
+                key = updated_key;
+            }
+
+            index.insert(key, cell);
+        }
+    }
+
+    PaddedPODArray<KeyType> getCachedKeysImpl() const
+    {
+        PaddedPODArray<KeyType> result;
+        result.reserve(index.size());
+
+        for (auto & node : index)
+        {
+            auto & cell = node.getMapped();
+
+            if (cell.state == Cell::default_value)
+                continue;
+
+            result.emplace_back(node.getKey());
+        }
+
+        return result;
+    }
+
+    void insertCell(SSDCacheKeyType & ssd_cache_key, Cell & cell)
+    {
+        /** InsertCell has following flow
+
+            1. We try to write key into current memory buffer, if write succeeded then return.
+            2. Then if we does not write key into current memory buffer, we try to flush current memory buffer
+            to disk.
+
+            If flush succeeded then reset current memory buffer, write key into it and return.
+            If flush failed that means that current partition on disk is full, need to allocate new partition
+            or start reusing old ones.
+
+            Retry to step 1.
+         */
+
+        SSDCacheIndex cache_index {0, 0};
+
+        while (true)
+        {
+            bool started_reusing_old_partitions = memory_buffer_partitions.size() == configuration.max_partitions_count;
+
+            auto & current_memory_buffer_partition = memory_buffer_partitions[current_partition_index];
+
+            bool write_into_memory_buffer_result = current_memory_buffer_partition.writeKey(ssd_cache_key, cache_index);
+
+            if (write_into_memory_buffer_result)
+            {
+                cell.state = Cell::in_memory;
+                cell.index = cache_index;
+                cell.in_memory_partition_index = current_partition_index;
+
+                index.insert(ssd_cache_key.key, cell);
+                break;
+            }
+            else
+            {
+                /// Partition memory write buffer if full flush it to disk and retry
+                size_t block_index_in_file_before_write = file_buffer.getCurrentBlockIndex();
+
+                if (started_reusing_old_partitions)
+                {
+                    /// If we start reusing old partitions we need to remove old keys on disk from index before writing buffer
+                    PaddedPODArray<KeyType> old_keys;
+                    file_buffer.readKeys(block_index_in_file_before_write, configuration.write_buffer_blocks_size, old_keys);
+
+                    size_t file_read_end_block_index = block_index_in_file_before_write + configuration.write_buffer_blocks_size;
+
+                    for (auto old_key : old_keys)
+                    {
+                        auto * it = index.find(old_key);
+
+                        if (it)
+                        {
+                            const Cell & old_key_cell = it->getMapped();
+
+                            size_t old_key_block = old_key_cell.index.block_index;
+
+                            /// Check if key in index is key from old partition blocks
+                            if (old_key_cell.isOnDisk() &&
+                                old_key_block >= block_index_in_file_before_write &&
+                                old_key_block < file_read_end_block_index)
+                                index.erase(old_key);
+                        }
+                    }
+                }
+
+                const char * partition_data = current_memory_buffer_partition.getData();
+
+                bool flush_to_file_result = file_buffer.writeBuffer(partition_data, configuration.write_buffer_blocks_size);
+
+                if (flush_to_file_result)
+                {
+                    /// Update index cells keys offset and block index
+                    PaddedPODArray<KeyType> keys_to_update;
+                    current_memory_buffer_partition.readKeys(keys_to_update);
+
+                    absl::flat_hash_set<KeyType, DefaultHash<KeyType>> updated_keys;
+
+                    Int64 keys_to_update_size = static_cast<Int64>(keys_to_update.size());
+
+                    /// Start from last to first because there can be multiple keys in same partition.
+                    /// The valid key is the latest.
+                    for (Int64 i = keys_to_update_size - 1; i >= 0; --i)
+                    {
+                        auto key_to_update = keys_to_update[i];
+                        auto * it = index.find(key_to_update);
+
+                        /// If there are no key to update or key to update not in memory
+                        if (!it || it->getMapped().state != Cell::in_memory)
+                            continue;
+
+                        /// If there were duplicated keys in memory buffer partition
+                        if (updated_keys.contains(it->getKey()))
+                            continue;
+
+                        updated_keys.insert(key_to_update);
+
+                        Cell & cell_to_update = it->getMapped();
+
+                        cell_to_update.state = Cell::on_disk;
+                        cell_to_update.index.block_index += block_index_in_file_before_write;
+                    }
+
+                    /// Memory buffer partition flushed to disk start reusing it
+                    current_memory_buffer_partition.reset();
+                    memset(const_cast<char *>(current_memory_buffer_partition.getData()), 0, current_memory_buffer_partition.getSizeInBytes());
+
+                    write_into_memory_buffer_result = current_memory_buffer_partition.writeKey(ssd_cache_key, cache_index);
+                    assert(write_into_memory_buffer_result);
+
+                    cell.state = Cell::in_memory;
+                    cell.index = cache_index;
+                    cell.in_memory_partition_index = current_partition_index;
+
+                    index.insert(ssd_cache_key.key, cell);
+                    break;
+                }
+                else
+                {
+                    /// Partition is full need to try next partition
+
+                    if (memory_buffer_partitions.size() < configuration.max_partitions_count)
+                    {
+                        /// Try tro create next partition without reusing old partitions
+                        ++current_partition_index;
+                        file_buffer.allocateSizeForNextPartition();
+                        memory_buffer_partitions.emplace_back(configuration.block_size, configuration.write_buffer_blocks_size);
+                    }
+                    else
+                    {
+                        /// Start reusing old partitions
+                        current_partition_index = (current_partition_index + 1) % memory_buffer_partitions.size();
+                        file_buffer.reset();
+                    }
+                }
+            }
+        }
+    }
+
+    inline static bool cellHasDeadline(const Cell & cell)
+    {
+        return cell.deadline != std::chrono::system_clock::from_time_t(0);
+    }
+
+    inline void setCellDeadline(Cell & cell, TimePoint now)
+    {
+        if (configuration.lifetime.min_sec == 0 && configuration.lifetime.max_sec == 0)
+        {
+            cell.deadline = std::chrono::system_clock::from_time_t(0);
+            return;
+        }
+
+        size_t min_sec_lifetime = configuration.lifetime.min_sec;
+        size_t max_sec_lifetime = configuration.lifetime.max_sec;
+
+        std::uniform_int_distribution<UInt64> distribution{min_sec_lifetime, max_sec_lifetime};
+        cell.deadline = now + std::chrono::seconds{distribution(rnd_engine)};
+    }
+
+    template <typename>
+    friend class ArenaCellKeyDisposer;
+
+    SSDCacheDictionaryStorageConfiguration configuration;
+
+    SSDCacheFileBuffer<SSDCacheKeyType> file_buffer;
+
+    Memory<Allocator<true>> read_from_file_buffer;
+
+    std::vector<SSDCacheMemoryBuffer<SSDCacheKeyType>> memory_buffer_partitions;
+
+    pcg64 rnd_engine;
+
+    class ArenaCellKeyDisposer
+    {
+    public:
+        ArenaWithFreeLists & arena;
+
+        template <typename Key, typename Value>
+        void operator()(const Key & key, const Value &) const
+        {
+            /// In case of complex key we keep it in arena
+            if constexpr (std::is_same_v<Key, StringRef>)
+                arena.free(const_cast<char *>(key.data), key.size);
+        }
+    };
+
+    using SimpleKeyLRUHashMap = LRUHashMap<UInt64, Cell, ArenaCellKeyDisposer>;
+    using ComplexKeyLRUHashMap = LRUHashMapWithSavedHash<StringRef, Cell, ArenaCellKeyDisposer>;
+
+    using CacheLRUHashMap = std::conditional_t<
+        dictionary_key_type == DictionaryKeyType::simple,
+        SimpleKeyLRUHashMap,
+        ComplexKeyLRUHashMap>;
+
+    ArenaWithFreeLists complex_key_arena;
+
+    CacheLRUHashMap index;
+
+    size_t current_partition_index = 0;
+
+};
+
+}
+
+#endif
diff --git a/src/Dictionaries/SSDComplexKeyCacheDictionary.cpp b/src/Dictionaries/SSDComplexKeyCacheDictionary.cpp
deleted file mode 100644
index cb22dd2be155..000000000000
--- a/src/Dictionaries/SSDComplexKeyCacheDictionary.cpp
+++ /dev/null
@@ -1,1772 +0,0 @@
-#if defined(OS_LINUX) || defined(__FreeBSD__)
-
-#include "SSDComplexKeyCacheDictionary.h"
-
-#include <algorithm>
-#include <Columns/ColumnsNumber.h>
-#include <Common/typeid_cast.h>
-#include <Common/ProfileEvents.h>
-#include <Common/ProfilingScopedRWLock.h>
-#include <Common/MemorySanitizer.h>
-#include <DataStreams/IBlockInputStream.h>
-#include <DataTypes/DataTypesDecimal.h>
-#include "DictionaryBlockInputStream.h"
-#include "DictionaryFactory.h"
-#include <IO/AIO.h>
-#include <IO/ReadHelpers.h>
-#include <IO/WriteHelpers.h>
-#include <ext/chrono_io.h>
-#include <ext/map.h>
-#include <ext/range.h>
-#include <ext/size.h>
-#include <ext/bit_cast.h>
-#include <numeric>
-#include <filesystem>
-#include <city.h>
-#include <fcntl.h>
-#include <Functions/FunctionHelpers.h>
-
-namespace ProfileEvents
-{
-    extern const Event DictCacheKeysRequested;
-    extern const Event DictCacheKeysRequestedMiss;
-    extern const Event DictCacheKeysRequestedFound;
-    extern const Event DictCacheKeysExpired;
-    extern const Event DictCacheKeysNotFound;
-    extern const Event DictCacheKeysHit;
-    extern const Event DictCacheRequestTimeNs;
-    extern const Event DictCacheRequests;
-    extern const Event DictCacheLockWriteNs;
-    extern const Event DictCacheLockReadNs;
-    extern const Event FileOpen;
-    extern const Event WriteBufferAIOWrite;
-    extern const Event WriteBufferAIOWriteBytes;
-}
-
-namespace CurrentMetrics
-{
-    extern const Metric DictCacheRequests;
-    extern const Metric Write;
-}
-
-namespace DB
-{
-
-namespace ErrorCodes
-{
-    extern const int AIO_READ_ERROR;
-    extern const int AIO_WRITE_ERROR;
-    extern const int BAD_ARGUMENTS;
-    extern const int CACHE_DICTIONARY_UPDATE_FAIL;
-    extern const int CANNOT_ALLOCATE_MEMORY;
-    extern const int CANNOT_CREATE_DIRECTORY;
-    extern const int CANNOT_FSYNC;
-    extern const int CANNOT_IO_GETEVENTS;
-    extern const int CANNOT_IO_SUBMIT;
-    extern const int CANNOT_OPEN_FILE;
-    extern const int CORRUPTED_DATA;
-    extern const int FILE_DOESNT_EXIST;
-    extern const int NOT_IMPLEMENTED;
-    extern const int TYPE_MISMATCH;
-    extern const int UNSUPPORTED_METHOD;
-}
-
-namespace
-{
-    constexpr size_t DEFAULT_SSD_BLOCK_SIZE_BYTES = DEFAULT_AIO_FILE_BLOCK_SIZE;
-    constexpr size_t DEFAULT_FILE_SIZE_BYTES = 4 * 1024 * 1024 * 1024ULL;
-    constexpr size_t DEFAULT_PARTITIONS_COUNT = 16;
-    constexpr size_t DEFAULT_READ_BUFFER_SIZE_BYTES = 16 * DEFAULT_SSD_BLOCK_SIZE_BYTES;
-    constexpr size_t DEFAULT_WRITE_BUFFER_SIZE_BYTES = DEFAULT_SSD_BLOCK_SIZE_BYTES;
-
-    constexpr size_t DEFAULT_MAX_STORED_KEYS = 100000;
-
-    constexpr size_t BUFFER_ALIGNMENT = DEFAULT_AIO_FILE_BLOCK_SIZE;
-    constexpr size_t BLOCK_CHECKSUM_SIZE_BYTES = 8;
-    constexpr size_t BLOCK_SPECIAL_FIELDS_SIZE_BYTES = 4;
-
-    constexpr UInt64 KEY_METADATA_EXPIRES_AT_MASK = std::numeric_limits<std::chrono::system_clock::time_point::rep>::max();
-    constexpr UInt64 KEY_METADATA_IS_DEFAULT_MASK = ~KEY_METADATA_EXPIRES_AT_MASK;
-
-    constexpr size_t KEY_IN_MEMORY_BIT = 63;
-    constexpr size_t KEY_IN_MEMORY = (1ULL << KEY_IN_MEMORY_BIT);
-    constexpr size_t BLOCK_INDEX_BITS = 32;
-    constexpr size_t INDEX_IN_BLOCK_BITS = 16;
-    constexpr size_t INDEX_IN_BLOCK_MASK = (1ULL << INDEX_IN_BLOCK_BITS) - 1;
-    constexpr size_t BLOCK_INDEX_MASK = ((1ULL << (BLOCK_INDEX_BITS + INDEX_IN_BLOCK_BITS)) - 1) ^ INDEX_IN_BLOCK_MASK;
-
-    constexpr size_t NOT_EXISTS = -1;
-
-    constexpr UInt8 HAS_NOT_FOUND = 2;
-
-    const std::string BIN_FILE_EXT = ".bin";
-    const std::string IND_FILE_EXT = ".idx";
-
-    int preallocateDiskSpace(int fd, size_t len)
-    {
-        #if defined(__FreeBSD__)
-            return posix_fallocate(fd, 0, len);
-        #else
-            return fallocate(fd, 0, 0, len);
-        #endif
-    }
-}
-
-SSDComplexKeyCachePartition::Metadata::time_point_t SSDComplexKeyCachePartition::Metadata::expiresAt() const
-{
-    return ext::safe_bit_cast<time_point_t>(data & KEY_METADATA_EXPIRES_AT_MASK);
-}
-void SSDComplexKeyCachePartition::Metadata::setExpiresAt(const time_point_t & t)
-{
-    data = ext::safe_bit_cast<time_point_urep_t>(t);
-}
-
-bool SSDComplexKeyCachePartition::Metadata::isDefault() const
-{
-    return (data & KEY_METADATA_IS_DEFAULT_MASK) == KEY_METADATA_IS_DEFAULT_MASK;
-}
-void SSDComplexKeyCachePartition::Metadata::setDefault()
-{
-    data |= KEY_METADATA_IS_DEFAULT_MASK;
-}
-
-bool SSDComplexKeyCachePartition::Index::inMemory() const
-{
-    return (index & KEY_IN_MEMORY) == KEY_IN_MEMORY;
-}
-
-bool SSDComplexKeyCachePartition::Index::exists() const
-{
-    return index != NOT_EXISTS;
-}
-
-void SSDComplexKeyCachePartition::Index::setNotExists()
-{
-    index = NOT_EXISTS;
-}
-
-void SSDComplexKeyCachePartition::Index::setInMemory(const bool in_memory)
-{
-    index = (index & ~KEY_IN_MEMORY) | (static_cast<size_t>(in_memory) << KEY_IN_MEMORY_BIT);
-}
-
-size_t SSDComplexKeyCachePartition::Index::getAddressInBlock() const
-{
-    return index & INDEX_IN_BLOCK_MASK;
-}
-
-void SSDComplexKeyCachePartition::Index::setAddressInBlock(const size_t address_in_block)
-{
-    index = (index & ~INDEX_IN_BLOCK_MASK) | address_in_block;
-}
-
-size_t SSDComplexKeyCachePartition::Index::getBlockId() const
-{
-    return (index & BLOCK_INDEX_MASK) >> INDEX_IN_BLOCK_BITS;
-}
-
-void SSDComplexKeyCachePartition::Index::setBlockId(const size_t block_id)
-{
-    index = (index & ~BLOCK_INDEX_MASK) | (block_id << INDEX_IN_BLOCK_BITS);
-}
-
-SSDComplexKeyCachePartition::SSDComplexKeyCachePartition(
-        const AttributeUnderlyingType & /* key_structure */,
-        const std::vector<AttributeUnderlyingType> & attributes_structure_,
-        const std::string & dir_path,
-        const size_t file_id_,
-        const size_t max_size_,
-        const size_t block_size_,
-        const size_t read_buffer_size_,
-        const size_t write_buffer_size_,
-        const size_t max_stored_keys_)
-    : file_id(file_id_)
-    , max_size(max_size_)
-    , block_size(block_size_)
-    , read_buffer_size(read_buffer_size_)
-    , write_buffer_size(write_buffer_size_)
-    , max_stored_keys(max_stored_keys_)
-    , path(dir_path + "/" + std::to_string(file_id))
-    , key_to_index(max_stored_keys, KeyDeleter(keys_pool))
-    , attributes_structure(attributes_structure_)
-{
-    if (!std::filesystem::create_directories(std::filesystem::path{dir_path}))
-    {
-        if (std::filesystem::exists(std::filesystem::path{dir_path}))
-            LOG_INFO(&Poco::Logger::get("SSDComplexKeyCachePartition::Constructor"), "Using existing directory '{}' for cache-partition", dir_path);
-        else
-            throw Exception{"Failed to create directories.", ErrorCodes::CANNOT_CREATE_DIRECTORY};
-    }
-
-    {
-        ProfileEvents::increment(ProfileEvents::FileOpen);
-
-        const std::string filename = path + BIN_FILE_EXT;
-        fd = ::open(filename.c_str(), O_RDWR | O_CREAT | O_TRUNC | O_DIRECT, 0666);
-        if (fd == -1)
-        {
-            auto error_code = (errno == ENOENT) ? ErrorCodes::FILE_DOESNT_EXIST : ErrorCodes::CANNOT_OPEN_FILE;
-            throwFromErrnoWithPath("Cannot open file " + filename, filename, error_code);
-        }
-
-        if (preallocateDiskSpace(fd, max_size * block_size) < 0)
-            throwFromErrnoWithPath("Cannot preallocate space for the file " + filename, filename, ErrorCodes::CANNOT_ALLOCATE_MEMORY);
-    }
-}
-
-SSDComplexKeyCachePartition::~SSDComplexKeyCachePartition()
-{
-    std::unique_lock lock(rw_lock);
-    ::close(fd);
-}
-
-size_t SSDComplexKeyCachePartition::appendDefaults(
-    const KeyRefs & keys_in,
-    const PaddedPODArray<Metadata> & metadata,
-    const size_t begin)
-{
-    std::unique_lock lock(rw_lock);
-    KeyRefs keys(keys_in.size());
-    for (size_t i = 0; i < keys_in.size(); ++i)
-        keys[i] = keys_pool.copyKeyFrom(keys_in[i]);
-
-    return append(keys, Attributes{}, metadata, begin);
-}
-
-size_t SSDComplexKeyCachePartition::appendBlock(
-    const Columns & key_columns, const DataTypes & /* key_types */,
-    const Attributes & new_attributes, const PaddedPODArray<Metadata> & metadata, const size_t begin)
-{
-    std::unique_lock lock(rw_lock);
-    if (!new_attributes.empty() && new_attributes.size() != attributes_structure.size())
-        throw Exception{"Wrong columns number in block.", ErrorCodes::BAD_ARGUMENTS};
-
-    const auto keys_size = key_columns.size();
-    KeyRefs keys(key_columns.front()->size());
-    {
-        StringRefs tmp_keys_refs(keys_size);
-        for (size_t i = 0; i < key_columns.front()->size(); ++i)
-            keys[i] = keys_pool.allocKey(i, key_columns, tmp_keys_refs);
-    }
-
-    return append(keys, new_attributes, metadata, begin);
-}
-
-size_t SSDComplexKeyCachePartition::append(
-    const KeyRefs & keys,
-    const Attributes & new_attributes,
-    const PaddedPODArray<Metadata> & metadata,
-    const size_t begin)
-{
-    if (!memory)
-        memory.emplace(block_size * write_buffer_size, BUFFER_ALIGNMENT);
-
-    auto init_write_buffer = [&]()
-    {
-        write_buffer.emplace(memory->data() + current_memory_block_id * block_size, block_size);
-        uint64_t tmp = 0;
-        write_buffer->write(reinterpret_cast<char*>(&tmp), BLOCK_CHECKSUM_SIZE_BYTES);
-        write_buffer->write(reinterpret_cast<char*>(&tmp), BLOCK_SPECIAL_FIELDS_SIZE_BYTES);
-        keys_in_block = 0;
-    };
-
-    if (!write_buffer)
-        init_write_buffer();
-    if (!keys_buffer_pool)
-        keys_buffer_pool.emplace();
-
-    bool flushed = false;
-    auto finish_block = [&]()
-    {
-        write_buffer.reset();
-        std::memcpy(memory->data() + block_size * current_memory_block_id + BLOCK_CHECKSUM_SIZE_BYTES, &keys_in_block, sizeof(keys_in_block)); // set count
-        uint64_t checksum = CityHash_v1_0_2::CityHash64(memory->data() + block_size * current_memory_block_id + BLOCK_CHECKSUM_SIZE_BYTES, block_size - BLOCK_CHECKSUM_SIZE_BYTES); // checksum
-        std::memcpy(memory->data() + block_size * current_memory_block_id, &checksum, sizeof(checksum));
-        if (++current_memory_block_id == write_buffer_size)
-            flush();
-        flushed = true;
-    };
-
-    for (size_t index = begin; index < keys.size();)
-    {
-        Index cache_index;
-        cache_index.setInMemory(true);
-        cache_index.setBlockId(current_memory_block_id);
-        cache_index.setAddressInBlock(write_buffer->offset());
-
-        flushed = false;
-        if (keys[index].fullSize() + sizeof(UInt64) > write_buffer->available()) // place for key and metadata
-        {
-            finish_block();
-        }
-        else
-        {
-            keys_pool.writeKey(keys[index], *write_buffer);
-            writeBinary(metadata[index].data, *write_buffer);
-        }
-
-        for (const auto & attribute : new_attributes)
-        {
-            if (flushed)
-                break;
-            switch (attribute.type)
-            {
-#define DISPATCH(TYPE) \
-            case AttributeUnderlyingType::ut##TYPE: \
-                { \
-                    if (sizeof(TYPE) > write_buffer->available()) \
-                    { \
-                        finish_block(); \
-                        continue; \
-                    } \
-                    else \
-                    { \
-                        const auto & values = std::get<Attribute::Container<TYPE>>(attribute.values); /* NOLINT */ \
-                        writeBinary(values[index], *write_buffer); \
-                    } \
-                } \
-                break;
-
-                DISPATCH(UInt8)
-                DISPATCH(UInt16)
-                DISPATCH(UInt32)
-                DISPATCH(UInt64)
-                DISPATCH(UInt128)
-                DISPATCH(Int8)
-                DISPATCH(Int16)
-                DISPATCH(Int32)
-                DISPATCH(Int64)
-                DISPATCH(Decimal32)
-                DISPATCH(Decimal64)
-                DISPATCH(Decimal128)
-                DISPATCH(Float32)
-                DISPATCH(Float64)
-#undef DISPATCH
-
-            case AttributeUnderlyingType::utString:
-                {
-                    const auto & value = std::get<Attribute::Container<String>>(attribute.values)[index];
-                    if (sizeof(UInt64) + value.size() > write_buffer->available())
-                    {
-                        finish_block();
-                        continue;
-                    }
-                    else
-                    {
-                        writeStringBinary(value, *write_buffer);
-                    }
-                }
-                break;
-            }
-        }
-
-        if (!flushed)
-        {
-            key_to_index.setWithDelete(keys[index], cache_index);
-            keys_buffer.push_back(keys_buffer_pool->copyKeyFrom(keys[index]));
-            ++index;
-            ++keys_in_block;
-        }
-        else  // next block in write buffer or flushed to ssd
-        {
-            init_write_buffer();
-        }
-    }
-    return keys.size() - begin;
-}
-
-void SSDComplexKeyCachePartition::flush()
-{
-    if (current_file_block_id >= max_size)
-        clearOldestBlocks();
-
-    if (keys_buffer.empty())
-        return;
-
-    AIOContext aio_context{1};
-
-    iocb write_request{};
-    iocb * write_request_ptr{&write_request};
-
-#if defined(__FreeBSD__)
-    write_request.aio.aio_lio_opcode = LIO_WRITE;
-    write_request.aio.aio_fildes = fd;
-    write_request.aio.aio_buf = reinterpret_cast<volatile void *>(memory->data());
-    write_request.aio.aio_nbytes = block_size * write_buffer_size;
-    write_request.aio.aio_offset = (current_file_block_id % max_size) * block_size;
-#else
-    write_request.aio_lio_opcode = IOCB_CMD_PWRITE;
-    write_request.aio_fildes = fd;
-    write_request.aio_buf = reinterpret_cast<UInt64>(memory->data());
-    write_request.aio_nbytes = block_size * write_buffer_size;
-    write_request.aio_offset = (current_file_block_id % max_size) * block_size;
-#endif
-
-    while (io_submit(aio_context.ctx, 1, &write_request_ptr) < 0)
-    {
-        if (errno != EINTR)
-            throw Exception("Cannot submit request for asynchronous IO on file " + path + BIN_FILE_EXT, ErrorCodes::CANNOT_IO_SUBMIT);
-    }
-
-    CurrentMetrics::Increment metric_increment_write{CurrentMetrics::Write};
-
-    io_event event;
-    while (io_getevents(aio_context.ctx, 1, 1, &event, nullptr) < 0)
-    {
-        if (errno != EINTR)
-            throw Exception("Failed to wait for asynchronous IO completion on file " + path + BIN_FILE_EXT, ErrorCodes::CANNOT_IO_GETEVENTS);
-    }
-
-    // Unpoison the memory returned from an uninstrumented system function.
-    __msan_unpoison(&event, sizeof(event));
-
-    ssize_t  bytes_written;
-#if defined(__FreeBSD__)
-    bytes_written = aio_return(reinterpret_cast<struct aiocb *>(event.udata));
-#else
-    bytes_written = event.res;
-#endif
-
-    ProfileEvents::increment(ProfileEvents::WriteBufferAIOWrite);
-    ProfileEvents::increment(ProfileEvents::WriteBufferAIOWriteBytes, bytes_written);
-
-    if (bytes_written != static_cast<decltype(bytes_written)>(block_size * write_buffer_size))
-        throw Exception("Not all data was written for asynchronous IO on file " + path + BIN_FILE_EXT + ". returned: " + std::to_string(bytes_written), ErrorCodes::AIO_WRITE_ERROR);
-
-    if (::fsync(fd) < 0)
-        throwFromErrnoWithPath("Cannot fsync " + path + BIN_FILE_EXT, path + BIN_FILE_EXT, ErrorCodes::CANNOT_FSYNC);
-
-    /// commit changes in index
-    for (auto & key : keys_buffer)
-    {
-        Index index;
-        if (key_to_index.getKeyAndValue(key, index))
-        {
-            if (index.inMemory()) // Row can be inserted in the buffer twice, so we need to move to ssd only the last index.
-            {
-                index.setInMemory(false);
-                index.setBlockId((current_file_block_id % max_size) + index.getBlockId());
-            }
-            key_to_index.set(key, index);
-        }
-    }
-
-    current_file_block_id += write_buffer_size;
-    current_memory_block_id = 0;
-
-    /// clear buffer
-    keys_buffer.clear();
-    keys_buffer_pool.reset();
-    keys_buffer_pool.emplace();
-}
-
-template <typename Out, typename GetDefault>
-void SSDComplexKeyCachePartition::getValue(
-    const size_t attribute_index,
-    const Columns & key_columns,
-    const DataTypes & key_types,
-    ResultArrayType<Out> & out,
-    std::vector<bool> & found,
-    GetDefault & default_value_extractor,
-    std::chrono::system_clock::time_point now) const
-{
-    auto set_value = [&](const size_t index, ReadBuffer & buf)
-    {
-        keys_pool.ignoreKey(buf);
-        Metadata metadata;
-        readVarUInt(metadata.data, buf);
-
-        if (metadata.expiresAt() > now)
-        {
-            if (metadata.isDefault())
-                out[index] = default_value_extractor[index];
-            else
-            {
-                ignoreFromBufferToAttributeIndex(attribute_index, buf);
-                readBinary(out[index], buf);
-            }
-            found[index] = true;
-        }
-    };
-
-    getImpl(key_columns, key_types, set_value, found);
-}
-
-void SSDComplexKeyCachePartition::getString(const size_t attribute_index,
-    const Columns & key_columns, const DataTypes & key_types,
-    StringRefs & refs, ArenaWithFreeLists & arena, std::vector<bool> & found,
-    std::vector<size_t> & default_ids,
-    std::chrono::system_clock::time_point now) const
-{
-    auto set_value = [&](const size_t index, ReadBuffer & buf)
-    {
-        keys_pool.ignoreKey(buf);
-        Metadata metadata;
-        readBinary(metadata.data, buf);
-
-        if (metadata.expiresAt() > now)
-        {
-            if (metadata.isDefault())
-                default_ids.push_back(index);
-            else
-            {
-                ignoreFromBufferToAttributeIndex(attribute_index, buf);
-                size_t size = 0;
-                readVarUInt(size, buf);
-                char * string_ptr = arena.alloc(size);
-                memcpy(string_ptr, buf.position(), size);
-                refs[index].data = string_ptr;
-                refs[index].size = size;
-            }
-            found[index] = true;
-        }
-    };
-
-    getImpl(key_columns, key_types, set_value, found);
-}
-
-void SSDComplexKeyCachePartition::hasKeys(
-    const Columns & key_columns, const DataTypes & key_types, ResultArrayType<UInt8> & out,
-    std::vector<bool> & found, std::chrono::system_clock::time_point now) const
-{
-    auto set_value = [&](const size_t index, ReadBuffer & buf)
-    {
-        keys_pool.ignoreKey(buf);
-        Metadata metadata;
-        readBinary(metadata.data, buf);
-
-        if (metadata.expiresAt() > now)
-            out[index] = !metadata.isDefault();
-    };
-
-    getImpl(key_columns, key_types, set_value, found);
-}
-
-template <typename SetFunc>
-void SSDComplexKeyCachePartition::getImpl(
-    const Columns & key_columns, const DataTypes & /* key_types */,
-    SetFunc & set, std::vector<bool> & found) const
-{
-    TemporalComplexKeysPool tmp_keys_pool;
-    StringRefs tmp_refs(key_columns.size());
-
-    std::shared_lock lock(rw_lock);
-    PaddedPODArray<Index> indices(key_columns.front()->size());
-    for (size_t i = 0; i < key_columns.front()->size(); ++i)
-    {
-        auto key = tmp_keys_pool.allocKey(i, key_columns, tmp_refs);
-        SCOPE_EXIT(tmp_keys_pool.rollback(key));
-        Index index;
-        if (found[i])
-            indices[i].setNotExists();
-        else if (key_to_index.get(key, index))
-            indices[i] = index;
-        else
-            indices[i].setNotExists();
-    }
-
-    getValueFromMemory(indices, set);
-    getValueFromStorage(indices, set);
-}
-
-template <typename SetFunc>
-void SSDComplexKeyCachePartition::getValueFromMemory(const PaddedPODArray<Index> & indices, SetFunc & set) const
-{
-    // Do not check checksum while reading from memory.
-    for (size_t i = 0; i < indices.size(); ++i)
-    {
-        const auto & index = indices[i];
-        if (index.exists() && index.inMemory())
-        {
-            const size_t offset = index.getBlockId() * block_size + index.getAddressInBlock();
-
-            ReadBufferFromMemory read_buffer(memory->data() + offset, block_size * write_buffer_size - offset);
-            set(i, read_buffer);
-        }
-    }
-}
-
-template <typename SetFunc>
-void SSDComplexKeyCachePartition::getValueFromStorage(const PaddedPODArray<Index> & indices, SetFunc & set) const
-{
-    std::vector<std::pair<Index, size_t>> index_to_out;
-    for (size_t i = 0; i < indices.size(); ++i)
-    {
-        const auto & index = indices[i];
-        if (index.exists() && !index.inMemory())
-            index_to_out.emplace_back(index, i);
-    }
-    if (index_to_out.empty())
-        return;
-
-    /// sort by (block_id, offset_in_block)
-    std::sort(std::begin(index_to_out), std::end(index_to_out));
-
-    Memory read_buffer(block_size * read_buffer_size, BUFFER_ALIGNMENT);
-
-    // TODO: merge requests
-    std::vector<iocb> requests;
-    std::vector<iocb*> pointers;
-    std::vector<std::vector<size_t>> blocks_to_indices;
-    requests.reserve(index_to_out.size());
-    pointers.reserve(index_to_out.size());
-    blocks_to_indices.reserve(index_to_out.size());
-    for (size_t i = 0; i < index_to_out.size(); ++i)
-    {
-        #if defined(__FreeBSD__)
-        const size_t back_offset = requests.empty() ? -1 : static_cast<size_t>(requests.back().aio.aio_offset);
-        #else
-        const size_t back_offset = requests.empty() ? -1 : static_cast<size_t>(requests.back().aio_offset);
-        #endif
-
-        if (!requests.empty() && back_offset == index_to_out[i].first.getBlockId() * block_size)
-        {
-            blocks_to_indices.back().push_back(i);
-            continue;
-        }
-
-        iocb request{};
-#if defined(__FreeBSD__)
-        request.aio.aio_lio_opcode = LIO_READ;
-        request.aio.aio_fildes = fd;
-        request.aio.aio_buf = reinterpret_cast<volatile void *>(
-            reinterpret_cast<UInt64>(read_buffer.data()) + block_size * (requests.size() % read_buffer_size));
-        request.aio.aio_nbytes = block_size;
-        request.aio.aio_offset = index_to_out[i].first.getBlockId() * block_size;
-        request.aio_data = requests.size();
-#else
-        request.aio_lio_opcode = IOCB_CMD_PREAD;
-        request.aio_fildes = fd;
-        request.aio_buf = reinterpret_cast<UInt64>(read_buffer.data()) + block_size * (requests.size() % read_buffer_size);
-        request.aio_nbytes = block_size;
-        request.aio_offset = index_to_out[i].first.getBlockId() * block_size;
-        request.aio_data = requests.size();
-#endif
-        requests.push_back(request);
-        pointers.push_back(&requests.back());
-        blocks_to_indices.emplace_back();
-        blocks_to_indices.back().push_back(i);
-    }
-
-    AIOContext aio_context(read_buffer_size);
-
-    std::vector<bool> processed(requests.size(), false);
-    std::vector<io_event> events(requests.size());
-    #if defined(__linux__)
-    for (auto & event : events)
-        event.res = -1;
-    #endif
-
-
-    size_t to_push = 0;
-    size_t to_pop = 0;
-    while (to_pop < requests.size())
-    {
-        /// get io tasks from previous iteration
-        int popped = 0;
-        while (to_pop < to_push && (popped = io_getevents(aio_context.ctx, to_push - to_pop, to_push - to_pop, &events[to_pop], nullptr)) <= 0)
-        {
-            if (errno != EINTR)
-                throwFromErrno("io_getevents: Failed to get an event for asynchronous IO", ErrorCodes::CANNOT_IO_GETEVENTS);
-        }
-
-        for (size_t i = to_pop; i < to_pop + popped; ++i)
-        {
-            const auto request_id = events[i].data;
-            const auto & request = requests[request_id];
-
-            #if defined(__FreeBSD__)
-            const auto bytes_written = aio_return(reinterpret_cast<struct aiocb *>(events[i].udata));
-            #else
-            const auto bytes_written = events[i].res;
-            #endif
-
-            if (bytes_written != static_cast<ssize_t>(block_size))
-            {
-                #if defined(__FreeBSD__)
-                    throw Exception("AIO failed to read file " + path + BIN_FILE_EXT + ".", ErrorCodes::AIO_READ_ERROR);
-                #else
-                    throw Exception("AIO failed to read file " + path + BIN_FILE_EXT + ". " +
-                        "request_id= " + std::to_string(request.aio_data) + "/ " + std::to_string(requests.size()) +
-                        ", aio_nbytes=" + std::to_string(request.aio_nbytes) + ", aio_offset=" + std::to_string(request.aio_offset) +
-                        ", returned=" + std::to_string(events[i].res) + ", errno=" + std::to_string(errno), ErrorCodes::AIO_READ_ERROR);
-                #endif
-            }
-            #if defined(__FreeBSD__)
-            const char* buf_ptr = reinterpret_cast<char *>(reinterpret_cast<UInt64>(request.aio.aio_buf));
-            #else
-            const auto* buf_ptr = reinterpret_cast<char *>(request.aio_buf);
-            #endif
-
-            __msan_unpoison(buf_ptr, block_size);
-            uint64_t checksum = 0;
-            ReadBufferFromMemory buf_special(buf_ptr, block_size);
-            readBinary(checksum, buf_special);
-            uint64_t calculated_checksum = CityHash_v1_0_2::CityHash64(buf_ptr + BLOCK_CHECKSUM_SIZE_BYTES, block_size - BLOCK_CHECKSUM_SIZE_BYTES);
-            if (checksum != calculated_checksum)
-            {
-                throw Exception("Cache data corrupted. From block = " + std::to_string(checksum) + " calculated = " + std::to_string(calculated_checksum) + ".", ErrorCodes::CORRUPTED_DATA);
-            }
-
-            for (const size_t idx : blocks_to_indices[request_id])
-            {
-                const auto & [file_index, out_index] = index_to_out[idx];
-                ReadBufferFromMemory buf(
-                        buf_ptr + file_index.getAddressInBlock(),
-                        block_size - file_index.getAddressInBlock());
-                set(out_index, buf);
-            }
-
-            processed[request_id] = true;
-        }
-
-        while (to_pop < requests.size() && processed[to_pop])
-            ++to_pop;
-
-        /// add new io tasks
-        const int new_tasks_count = std::min(read_buffer_size - (to_push - to_pop), requests.size() - to_push);
-
-        int pushed = 0;
-        while (new_tasks_count > 0 && (pushed = io_submit(aio_context.ctx, new_tasks_count, &pointers[to_push])) <= 0)
-        {
-            if (errno != EINTR)
-                throwFromErrno("io_submit: Failed to submit a request for asynchronous IO", ErrorCodes::CANNOT_IO_SUBMIT);
-        }
-        to_push += pushed;
-    }
-}
-
-void SSDComplexKeyCachePartition::clearOldestBlocks()
-{
-    // write_buffer_size, because we need to erase the whole buffer.
-    Memory read_buffer_memory(block_size * write_buffer_size, BUFFER_ALIGNMENT);
-
-    iocb request{};
-#if defined(__FreeBSD__)
-    request.aio.aio_lio_opcode = LIO_READ;
-    request.aio.aio_fildes = fd;
-    request.aio.aio_buf = reinterpret_cast<volatile void *>(reinterpret_cast<UInt64>(read_buffer_memory.data()));
-    request.aio.aio_nbytes = block_size * write_buffer_size;
-    request.aio.aio_offset = (current_file_block_id % max_size) * block_size;
-    request.aio_data = 0;
-#else
-    request.aio_lio_opcode = IOCB_CMD_PREAD;
-    request.aio_fildes = fd;
-    request.aio_buf = reinterpret_cast<UInt64>(read_buffer_memory.data());
-    request.aio_nbytes = block_size * write_buffer_size;
-    request.aio_offset = (current_file_block_id % max_size) * block_size;
-    request.aio_data = 0;
-#endif
-
-    {
-        iocb* request_ptr = &request;
-        io_event event{};
-        AIOContext aio_context(1);
-
-        while (io_submit(aio_context.ctx, 1, &request_ptr) != 1)
-            if (errno != EINTR)
-                throwFromErrno("io_submit: Failed to submit a request for asynchronous IO", ErrorCodes::CANNOT_IO_SUBMIT);
-
-        while (io_getevents(aio_context.ctx, 1, 1, &event, nullptr) != 1)
-            if (errno != EINTR)
-                throwFromErrno("io_getevents: Failed to get an event for asynchronous IO", ErrorCodes::CANNOT_IO_GETEVENTS);
-
-#if defined(__FreeBSD__)
-        if (aio_return(reinterpret_cast<struct aiocb *>(event.udata)) != static_cast<ssize_t>(request.aio.aio_nbytes))
-            throw Exception("GC: AIO failed to read file " + path + BIN_FILE_EXT + ".", ErrorCodes::AIO_READ_ERROR);
-#else
-        if (event.res != static_cast<ssize_t>(request.aio_nbytes))
-            throw Exception("GC: AIO failed to read file " + path + BIN_FILE_EXT + ". " +
-                "aio_nbytes=" + std::to_string(request.aio_nbytes) +
-                ", returned=" + std::to_string(event.res) + ".", ErrorCodes::AIO_READ_ERROR);
-#endif
-        __msan_unpoison(read_buffer_memory.data(), read_buffer_memory.size());
-    }
-
-    TemporalComplexKeysPool tmp_keys_pool;
-    KeyRefs keys;
-
-    for (size_t i = 0; i < write_buffer_size; ++i)
-    {
-        ReadBufferFromMemory read_buffer(read_buffer_memory.data() + i * block_size, block_size);
-
-        uint64_t checksum = 0;
-        readBinary(checksum, read_buffer);
-        uint64_t calculated_checksum = CityHash_v1_0_2::CityHash64(read_buffer_memory.data() + i * block_size + BLOCK_CHECKSUM_SIZE_BYTES, block_size - BLOCK_CHECKSUM_SIZE_BYTES);
-        if (checksum != calculated_checksum)
-        {
-            throw Exception("Cache data corrupted. From block = " + std::to_string(checksum) + " calculated = " + std::to_string(calculated_checksum) + ".", ErrorCodes::CORRUPTED_DATA);
-        }
-
-        uint32_t keys_in_current_block = 0;
-        readBinary(keys_in_current_block, read_buffer);
-
-        for (uint32_t j = 0; j < keys_in_current_block; ++j)
-        {
-            keys.emplace_back();
-            tmp_keys_pool.readKey(keys.back(), read_buffer);
-
-            Metadata metadata;
-            readBinary(metadata.data, read_buffer);
-
-            if (!metadata.isDefault())
-            {
-                for (const auto & attr : attributes_structure)
-                {
-                    switch (attr)
-                    {
-            #define DISPATCH(TYPE) \
-                    case AttributeUnderlyingType::ut##TYPE: \
-                        read_buffer.ignore(sizeof(TYPE)); \
-                        break;
-
-                        DISPATCH(UInt8)
-                        DISPATCH(UInt16)
-                        DISPATCH(UInt32)
-                        DISPATCH(UInt64)
-                        DISPATCH(UInt128)
-                        DISPATCH(Int8)
-                        DISPATCH(Int16)
-                        DISPATCH(Int32)
-                        DISPATCH(Int64)
-                        DISPATCH(Decimal32)
-                        DISPATCH(Decimal64)
-                        DISPATCH(Decimal128)
-                        DISPATCH(Float32)
-                        DISPATCH(Float64)
-            #undef DISPATCH
-
-                    case AttributeUnderlyingType::utString:
-                        {
-                            size_t size = 0;
-                            readVarUInt(size, read_buffer);
-                            read_buffer.ignore(size);
-                        }
-                        break;
-                    }
-                }
-            }
-        }
-    }
-
-    const size_t start_block = current_file_block_id % max_size;
-    const size_t finish_block = start_block + write_buffer_size;
-    for (const auto& key : keys)
-    {
-        Index index;
-        if (key_to_index.get(key, index))
-        {
-            size_t block_id = index.getBlockId();
-            if (start_block <= block_id && block_id < finish_block)
-                key_to_index.erase(key);
-        }
-    }
-}
-
-void SSDComplexKeyCachePartition::ignoreFromBufferToAttributeIndex(const size_t attribute_index, ReadBuffer & buf) const
-{
-    for (size_t i = 0; i < attribute_index; ++i)
-    {
-        switch (attributes_structure[i])
-        {
-#define DISPATCH(TYPE) \
-        case AttributeUnderlyingType::ut##TYPE: \
-            buf.ignore(sizeof(TYPE)); \
-            break;
-
-            DISPATCH(UInt8)
-            DISPATCH(UInt16)
-            DISPATCH(UInt32)
-            DISPATCH(UInt64)
-            DISPATCH(UInt128)
-            DISPATCH(Int8)
-            DISPATCH(Int16)
-            DISPATCH(Int32)
-            DISPATCH(Int64)
-            DISPATCH(Decimal32)
-            DISPATCH(Decimal64)
-            DISPATCH(Decimal128)
-            DISPATCH(Float32)
-            DISPATCH(Float64)
-#undef DISPATCH
-
-        case AttributeUnderlyingType::utString:
-            {
-                size_t size = 0;
-                readVarUInt(size, buf);
-                buf.ignore(size);
-            }
-            break;
-        }
-    }
-}
-
-size_t SSDComplexKeyCachePartition::getId() const
-{
-    return file_id;
-}
-
-double SSDComplexKeyCachePartition::getLoadFactor() const
-{
-    std::shared_lock lock(rw_lock);
-    return static_cast<double>(current_file_block_id) / max_size;
-}
-
-size_t SSDComplexKeyCachePartition::getElementCount() const
-{
-    std::shared_lock lock(rw_lock);
-    return key_to_index.size();
-}
-
-size_t SSDComplexKeyCachePartition::getBytesAllocated() const
-{
-    std::shared_lock lock(rw_lock);
-    return 16.5 * key_to_index.capacity() + keys_pool.size() +
-        (keys_buffer_pool ? keys_buffer_pool->size() : 0) + (memory ? memory->size() : 0);
-}
-
-void SSDComplexKeyCachePartition::remove()
-{
-    std::unique_lock lock(rw_lock);
-    std::filesystem::remove(std::filesystem::path(path + BIN_FILE_EXT));
-}
-
-SSDComplexKeyCacheStorage::SSDComplexKeyCacheStorage(
-        const AttributeTypes & attributes_structure_,
-        const std::string & path_,
-        const size_t max_partitions_count_,
-        const size_t file_size_,
-        const size_t block_size_,
-        const size_t read_buffer_size_,
-        const size_t write_buffer_size_,
-        const size_t max_stored_keys_)
-    : attributes_structure(attributes_structure_)
-    , path(path_)
-    , max_partitions_count(max_partitions_count_)
-    , file_size(file_size_)
-    , block_size(block_size_)
-    , read_buffer_size(read_buffer_size_)
-    , write_buffer_size(write_buffer_size_)
-    , max_stored_keys(max_stored_keys_)
-    , log(&Poco::Logger::get("SSDComplexKeyCacheStorage"))
-{
-}
-
-SSDComplexKeyCacheStorage::~SSDComplexKeyCacheStorage()
-{
-    std::unique_lock lock(rw_lock);
-    partition_delete_queue.splice(std::end(partition_delete_queue), partitions);
-    collectGarbage();
-}
-
-template <typename Out, typename GetDefault>
-void SSDComplexKeyCacheStorage::getValue(
-    const size_t attribute_index, const Columns & key_columns, const DataTypes & key_types,
-    ResultArrayType<Out> & out, std::unordered_map<KeyRef, std::vector<size_t>> & not_found,
-    TemporalComplexKeysPool & not_found_pool,
-    GetDefault & get_default, std::chrono::system_clock::time_point now) const
-{
-    size_t n = key_columns.front()->size();
-    std::vector<bool> found(n, false);
-
-    {
-        std::shared_lock lock(rw_lock);
-        for (const auto & partition : partitions)
-            partition->getValue<Out>(attribute_index, key_columns, key_types, out, found, get_default, now);
-    }
-
-    size_t count_not_found = 0;
-    StringRefs tmp_refs(key_columns.size());
-    for (size_t i = 0; i < n; ++i)
-    {
-        if (!found[i])
-        {
-            auto key = not_found_pool.allocKey(i, key_columns, tmp_refs);
-            not_found[key].push_back(i);
-            ++count_not_found;
-        }
-    }
-
-    query_count.fetch_add(n, std::memory_order_relaxed);
-    hit_count.fetch_add(n - count_not_found, std::memory_order_release);
-}
-
-void SSDComplexKeyCacheStorage::getString(
-    const size_t attribute_index, const Columns & key_columns, const DataTypes & key_types,
-    StringRefs & refs, ArenaWithFreeLists & arena,
-    std::unordered_map<KeyRef, std::vector<size_t>> & not_found,
-    TemporalComplexKeysPool & not_found_pool,
-    std::vector<size_t> & default_ids, std::chrono::system_clock::time_point now) const
-{
-    size_t n = key_columns.front()->size();
-    std::vector<bool> found(n, false);
-
-    {
-        std::shared_lock lock(rw_lock);
-        for (const auto & partition : partitions)
-            partition->getString(attribute_index, key_columns, key_types, refs, arena, found, default_ids, now);
-    }
-
-    size_t count_not_found = 0;
-    StringRefs tmp_refs(key_columns.size());
-    for (size_t i = 0; i < n; ++i)
-    {
-        if (!found[i])
-        {
-            auto key = not_found_pool.allocKey(i, key_columns, tmp_refs);
-            not_found[key].push_back(i);
-            ++count_not_found;
-        }
-    }
-
-    query_count.fetch_add(n, std::memory_order_relaxed);
-    hit_count.fetch_add(n - count_not_found, std::memory_order_release);
-}
-
-void SSDComplexKeyCacheStorage::hasKeys(
-    const Columns & key_columns, const DataTypes & key_types, ResultArrayType<UInt8> & out,
-    std::unordered_map<KeyRef, std::vector<size_t>> & not_found,
-    TemporalComplexKeysPool & not_found_pool, std::chrono::system_clock::time_point now) const
-{
-    size_t n = key_columns.front()->size();
-    for (size_t i = 0; i < n; ++i)
-        out[i] = HAS_NOT_FOUND;
-    std::vector<bool> found(n, false);
-
-    {
-        std::shared_lock lock(rw_lock);
-        for (const auto & partition : partitions)
-            partition->hasKeys(key_columns, key_types, out, found, now);
-    }
-
-    size_t count_not_found = 0;
-    StringRefs tmp_refs(key_columns.size());
-    for (size_t i = 0; i < n; ++i)
-    {
-        if (out[i] == HAS_NOT_FOUND)
-        {
-            auto key = not_found_pool.allocKey(i, key_columns, tmp_refs);
-            not_found[key].push_back(i);
-            ++count_not_found;
-        }
-    }
-
-    query_count.fetch_add(n, std::memory_order_relaxed);
-    hit_count.fetch_add(n - count_not_found, std::memory_order_release);
-}
-
-namespace
-{
-SSDComplexKeyCachePartition::Attributes createAttributesFromBlock(
-        const Block & block, const size_t begin_column, const std::vector<AttributeUnderlyingType> & structure)
-{
-    SSDComplexKeyCachePartition::Attributes attributes;
-
-    const auto columns = block.getColumns();
-    for (size_t i = 0; i < structure.size(); ++i)
-    {
-        const auto & column = columns[i + begin_column];
-        switch (structure[i])
-        {
-#define DISPATCH(TYPE) \
-        case AttributeUnderlyingType::ut##TYPE: \
-            { \
-                SSDComplexKeyCachePartition::Attribute::Container<TYPE> values(column->size()); \
-                memcpy(&values[0], column->getRawData().data, sizeof(TYPE) * values.size()); \
-                attributes.emplace_back(); \
-                attributes.back().type = structure[i]; \
-                attributes.back().values = std::move(values); \
-            } \
-            break;
-
-            DISPATCH(UInt8)
-            DISPATCH(UInt16)
-            DISPATCH(UInt32)
-            DISPATCH(UInt64)
-            DISPATCH(UInt128)
-            DISPATCH(Int8)
-            DISPATCH(Int16)
-            DISPATCH(Int32)
-            DISPATCH(Int64)
-            DISPATCH(Decimal32)
-            DISPATCH(Decimal64)
-            DISPATCH(Decimal128)
-            DISPATCH(Float32)
-            DISPATCH(Float64)
-#undef DISPATCH
-
-        case AttributeUnderlyingType::utString:
-            {
-                attributes.emplace_back();
-                SSDComplexKeyCachePartition::Attribute::Container<String> values(column->size());
-                for (size_t j = 0; j < column->size(); ++j)
-                {
-                    const auto ref = column->getDataAt(j);
-                    values[j].resize(ref.size);
-                    memcpy(values[j].data(), ref.data, ref.size);
-                }
-                attributes.back().type = structure[i];
-                attributes.back().values = std::move(values);
-            }
-            break;
-        }
-    }
-
-    return attributes;
-}
-}
-
-template <typename PresentIdHandler, typename AbsentIdHandler>
-void SSDComplexKeyCacheStorage::update(
-    DictionarySourcePtr & source_ptr,
-    const Columns & key_columns,
-    const DataTypes & key_types,
-    const KeyRefs & required_keys,
-    const std::vector<size_t> & required_rows,
-    TemporalComplexKeysPool & tmp_keys_pool,
-    PresentIdHandler && on_updated,
-    AbsentIdHandler && on_key_not_found,
-    const DictionaryLifetime lifetime)
-{
-    assert(key_columns.size() == key_types.size());
-
-    auto append_block = [&key_types, this](
-        const Columns & new_keys,
-        const SSDComplexKeyCachePartition::Attributes & new_attributes,
-        const PaddedPODArray<SSDComplexKeyCachePartition::Metadata> & metadata)
-    {
-        size_t inserted = 0;
-        while (inserted < metadata.size())
-        {
-            if (!partitions.empty())
-                inserted += partitions.front()->appendBlock(
-                    new_keys, key_types, new_attributes, metadata, inserted);
-            if (inserted < metadata.size())
-            {
-                partitions.emplace_front(std::make_unique<SSDComplexKeyCachePartition>(
-                    AttributeUnderlyingType::utUInt64, attributes_structure, path,
-                    (partitions.empty() ? 0 : partitions.front()->getId() + 1),
-                    file_size, block_size, read_buffer_size, write_buffer_size, max_stored_keys));
-            }
-        }
-
-        collectGarbage();
-    };
-
-    CurrentMetrics::Increment metric_increment{CurrentMetrics::DictCacheRequests};
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysRequested, required_keys.size());
-
-    std::unordered_map<KeyRef, UInt8> remaining_keys{required_keys.size()};
-    for (const auto & key : required_keys)
-        remaining_keys.insert({key, 0});
-
-    const auto now = std::chrono::system_clock::now();
-
-    {
-        const auto keys_size = key_columns.size();
-        StringRefs keys(keys_size);
-
-        const ProfilingScopedWriteRWLock write_lock{rw_lock, ProfileEvents::DictCacheLockWriteNs};
-
-        if (now > backoff_end_time)
-        {
-            try
-            {
-                if (update_error_count)
-                {
-                    /// Recover after error: we have to clone the source here because
-                    /// it could keep connections which should be reset after error.
-                    source_ptr = source_ptr->clone();
-                }
-
-                Stopwatch watch;
-                auto stream = source_ptr->loadKeys(key_columns, required_rows);
-                stream->readPrefix();
-
-                while (const auto block = stream->read())
-                {
-                    const auto new_key_columns = ext::map<Columns>(
-                        ext::range(0, keys_size),
-                        [&](const size_t attribute_idx) { return block.safeGetByPosition(attribute_idx).column; });
-
-                    const auto new_attributes = createAttributesFromBlock(block, keys_size, attributes_structure);
-
-                    const auto rows_num = block.rows();
-                    PaddedPODArray<SSDComplexKeyCachePartition::Metadata> metadata(rows_num);
-
-                    for (const auto i : ext::range(0, rows_num))
-                    {
-                        auto key = tmp_keys_pool.allocKey(i, new_key_columns, keys);
-                        //SCOPE_EXIT(tmp_keys_pool.rollback(key));
-
-                        std::uniform_int_distribution<UInt64> distribution{lifetime.min_sec, lifetime.max_sec};
-                        metadata[i].setExpiresAt(now + std::chrono::seconds(distribution(rnd_engine)));
-                        /// mark corresponding id as found
-                        on_updated(key, i, new_attributes);
-                        remaining_keys[key] = 1;
-                    }
-
-                    append_block(new_key_columns, new_attributes, metadata);
-                }
-
-                stream->readSuffix();
-
-                update_error_count = 0;
-                last_update_exception = std::exception_ptr{};
-                backoff_end_time = std::chrono::system_clock::time_point{};
-
-                ProfileEvents::increment(ProfileEvents::DictCacheRequestTimeNs, watch.elapsed());
-            }
-            catch (...)
-            {
-                ++update_error_count;
-                last_update_exception = std::current_exception();
-                backoff_end_time = now + std::chrono::seconds(calculateDurationWithBackoff(rnd_engine, update_error_count));
-
-                tryLogException(last_update_exception, log,
-                        "Could not update ssd cache dictionary, next update is scheduled at " + ext::to_string(backoff_end_time));
-            }
-        }
-    }
-
-    auto append_defaults = [this](
-        const KeyRefs & new_keys,
-        const PaddedPODArray<SSDComplexKeyCachePartition::Metadata> & metadata)
-    {
-        size_t inserted = 0;
-        while (inserted < metadata.size())
-        {
-            if (!partitions.empty())
-                inserted += partitions.front()->appendDefaults(
-                    new_keys, metadata, inserted);
-            if (inserted < metadata.size())
-            {
-                partitions.emplace_front(std::make_unique<SSDComplexKeyCachePartition>(
-                        AttributeUnderlyingType::utUInt64, attributes_structure, path,
-                        (partitions.empty() ? 0 : partitions.front()->getId() + 1),
-                        file_size, block_size, read_buffer_size, write_buffer_size, max_stored_keys));
-            }
-        }
-
-        collectGarbage();
-    };
-
-    size_t not_found_num = 0, found_num = 0;
-    /// Check which ids have not been found and require setting null_value
-    KeyRefs default_keys;
-
-    PaddedPODArray<SSDComplexKeyCachePartition::Metadata> metadata;
-    {
-        const ProfilingScopedWriteRWLock write_lock{rw_lock, ProfileEvents::DictCacheLockWriteNs};
-
-        for (const auto & key_found_pair : remaining_keys)
-        {
-            if (key_found_pair.second)
-            {
-                ++found_num;
-                continue;
-            }
-            ++not_found_num;
-
-            const auto key = key_found_pair.first;
-
-            if (update_error_count)
-            {
-                /// TODO: use old values.
-
-                // We don't have expired data for that `id` so all we can do is
-                // to rethrow `last_exception`. We might have to throw the same
-                // exception for different callers of dictGet() in different
-                // threads, which might then modify the exception object, so we
-                // have to throw a copy.
-                try
-                {
-                    std::rethrow_exception(last_update_exception);
-                }
-                catch (...)
-                {
-                    throw DB::Exception(ErrorCodes::CACHE_DICTIONARY_UPDATE_FAIL,
-                        "Update failed for dictionary '{}': {}",
-                        getPath(),
-                        getCurrentExceptionMessage(true /*with stack trace*/,
-                            true /*check embedded stack trace*/));
-                }
-            }
-
-            std::uniform_int_distribution<UInt64> distribution{lifetime.min_sec, lifetime.max_sec};
-            metadata.emplace_back();
-            metadata.back().setExpiresAt(now + std::chrono::seconds(distribution(rnd_engine)));
-            metadata.back().setDefault();
-
-            default_keys.push_back(key);
-
-            /// inform caller that the cell has not been found
-            on_key_not_found(key);
-        }
-
-        if (not_found_num)
-            append_defaults(default_keys, metadata);
-    }
-
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysRequestedMiss, not_found_num);
-    ProfileEvents::increment(ProfileEvents::DictCacheKeysRequestedFound, found_num);
-    ProfileEvents::increment(ProfileEvents::DictCacheRequests);
-}
-
-double SSDComplexKeyCacheStorage::getLoadFactor() const
-{
-    double result = 0;
-    std::shared_lock lock(rw_lock);
-    for (const auto & partition : partitions)
-        result += partition->getLoadFactor();
-    return result / partitions.size();
-}
-
-size_t SSDComplexKeyCacheStorage::getElementCount() const
-{
-    size_t result = 0;
-    std::shared_lock lock(rw_lock);
-    for (const auto & partition : partitions)
-        result += partition->getElementCount();
-    return result;
-}
-
-void SSDComplexKeyCacheStorage::collectGarbage()
-{
-    // add partitions to queue
-    while (partitions.size() > max_partitions_count)
-    {
-        partition_delete_queue.splice(std::end(partition_delete_queue), partitions, std::prev(std::end(partitions)));
-    }
-
-    // drop unused partitions
-    while (!partition_delete_queue.empty() && partition_delete_queue.front().use_count() == 1)
-    {
-        partition_delete_queue.front()->remove();
-        partition_delete_queue.pop_front();
-    }
-}
-
-SSDComplexKeyCacheDictionary::SSDComplexKeyCacheDictionary(
-    const StorageID & dict_id_,
-    const DictionaryStructure & dict_struct_,
-    DictionarySourcePtr source_ptr_,
-    const DictionaryLifetime dict_lifetime_,
-    const std::string & path_,
-    const size_t max_partitions_count_,
-    const size_t file_size_,
-    const size_t block_size_,
-    const size_t read_buffer_size_,
-    const size_t write_buffer_size_,
-    const size_t max_stored_keys_)
-    : IDictionaryBase(dict_id_)
-    , dict_struct(dict_struct_)
-    , source_ptr(std::move(source_ptr_))
-    , dict_lifetime(dict_lifetime_)
-    , path(path_)
-    , max_partitions_count(max_partitions_count_)
-    , file_size(file_size_)
-    , block_size(block_size_)
-    , read_buffer_size(read_buffer_size_)
-    , write_buffer_size(write_buffer_size_)
-    , max_stored_keys(max_stored_keys_)
-    , storage(ext::map<std::vector>(dict_struct.attributes, [](const auto & attribute) { return attribute.underlying_type; }),
-            path, max_partitions_count, file_size, block_size, read_buffer_size, write_buffer_size, max_stored_keys)
-    , log(&Poco::Logger::get("SSDComplexKeyCacheDictionary"))
-{
-    LOG_INFO(log, "Using storage path '{}'.", path);
-    if (!this->source_ptr->supportsSelectiveLoad())
-        throw Exception{name + ": source cannot be used with CacheDictionary", ErrorCodes::UNSUPPORTED_METHOD};
-
-    createAttributes();
-}
-
-ColumnPtr SSDComplexKeyCacheDictionary::getColumn(
-    const std::string & attribute_name,
-    const DataTypePtr & result_type,
-    const Columns & key_columns,
-    const DataTypes & key_types,
-    const ColumnPtr default_values_column) const
-{
-    ColumnPtr result;
-
-    dict_struct.validateKeyTypes(key_types);
-
-    const auto index = getAttributeIndex(attribute_name);
-    const auto & dictionary_attribute = dict_struct.getAttribute(attribute_name, result_type);
-
-    auto keys_size = key_columns.front()->size();
-
-    auto type_call = [&](const auto &dictionary_attribute_type)
-    {
-        using Type = std::decay_t<decltype(dictionary_attribute_type)>;
-        using AttributeType = typename Type::AttributeType;
-        using ColumnProvider = DictionaryAttributeColumnProvider<AttributeType>;
-
-        const auto & null_value = std::get<AttributeType>(null_values[index]);
-        DictionaryDefaultValueExtractor<AttributeType> default_value_extractor(null_value, default_values_column);
-
-        auto column = ColumnProvider::getColumn(dictionary_attribute, keys_size);
-
-        if constexpr (std::is_same_v<AttributeType, String>)
-        {
-            auto * out = column.get();
-            getItemsStringImpl(index, key_columns, key_types, out, default_value_extractor);
-        }
-        else
-        {
-            auto & out = column->getData();
-            getItemsNumberImpl<AttributeType, AttributeType>(
-                index,
-                key_columns,
-                key_types,
-                out,
-                default_value_extractor);
-        }
-
-        result = std::move(column);
-    };
-
-    callOnDictionaryAttributeType(dict_struct.attributes[index].underlying_type, type_call);
-
-    return result;
-}
-
-template <typename AttributeType, typename OutputType, typename DefaultValueExtractor>
-void SSDComplexKeyCacheDictionary::getItemsNumberImpl(
-    const size_t attribute_index,
-    const Columns & key_columns,
-    const DataTypes & key_types,
-    ResultArrayType<OutputType> & out,
-    DefaultValueExtractor & default_value_extractor) const
-{
-    assert(dict_struct.key);
-    assert(key_columns.size() == key_types.size());
-
-    dict_struct.validateKeyTypes(key_types);
-
-    const auto now = std::chrono::system_clock::now();
-
-    TemporalComplexKeysPool not_found_pool;
-    std::unordered_map<KeyRef, std::vector<size_t>> not_found_keys;
-    storage.getValue<OutputType>(attribute_index, key_columns, key_types, out, not_found_keys, not_found_pool, default_value_extractor, now);
-    if (not_found_keys.empty())
-        return;
-
-    std::vector<KeyRef> required_keys(not_found_keys.size());
-    std::transform(std::begin(not_found_keys), std::end(not_found_keys), std::begin(required_keys), [](const auto & pair) { return pair.first; });
-    std::vector<size_t> required_rows;
-    required_rows.reserve(required_keys.size());
-    for (const auto & key_ref : required_keys)
-        required_rows.push_back(not_found_keys[key_ref].front());
-
-    TemporalComplexKeysPool tmp_keys_pool;
-    storage.update(
-            source_ptr,
-            key_columns,
-            key_types,
-            required_keys,
-            required_rows,
-            tmp_keys_pool,
-            [&](const auto key, const auto row, const auto & new_attributes)
-            {
-                for (const size_t out_row : not_found_keys[key])
-                    out[out_row] = std::get<SSDComplexKeyCachePartition::Attribute::Container<OutputType>>(new_attributes[attribute_index].values)[row];
-            },
-            [&](const auto key)
-            {
-                for (const size_t row : not_found_keys[key])
-                    out[row] = default_value_extractor[row];
-            },
-            getLifetime());
-}
-
-void SSDComplexKeyCacheDictionary::getItemsStringImpl(
-    const size_t attribute_index,
-    const Columns & key_columns,
-    const DataTypes & key_types,
-    ColumnString * out,
-    DictionaryDefaultValueExtractor<String> & default_value_extractor) const
-{
-    dict_struct.validateKeyTypes(key_types);
-
-    const auto now = std::chrono::system_clock::now();
-
-    TemporalComplexKeysPool not_found_pool;
-    std::unordered_map<KeyRef, std::vector<size_t>> not_found_keys;
-
-    const size_t n = key_columns.front()->size();
-
-    StringRefs refs(n);
-    ArenaWithFreeLists string_arena;
-    std::vector<size_t> default_rows;
-    storage.getString(
-        attribute_index, key_columns, key_types,
-        refs, string_arena, not_found_keys, not_found_pool, default_rows, now);
-    std::sort(std::begin(default_rows), std::end(default_rows));
-
-    if (not_found_keys.empty())
-    {
-        size_t default_index = 0;
-        for (size_t row = 0; row < n; ++row)
-        {
-            if (unlikely(default_index != default_rows.size() && default_rows[default_index] == row))
-            {
-                auto to_insert = default_value_extractor[row];
-                out->insertData(to_insert.data, to_insert.size);
-                ++default_index;
-            }
-            else
-                out->insertData(refs[row].data, refs[row].size);
-        }
-        return;
-    }
-
-    std::vector<KeyRef> required_keys(not_found_keys.size());
-    std::transform(std::begin(not_found_keys), std::end(not_found_keys), std::begin(required_keys), [](const auto & pair) { return pair.first; });
-
-    std::unordered_map<KeyRef, String> update_result;
-
-    std::vector<size_t> required_rows;
-    required_rows.reserve(required_keys.size());
-    for (const auto & key_ref : required_keys)
-        required_rows.push_back(not_found_keys[key_ref].front());
-
-    TemporalComplexKeysPool tmp_keys_pool;
-    storage.update(
-            source_ptr,
-            key_columns,
-            key_types,
-            required_keys,
-            required_rows,
-            tmp_keys_pool,
-            [&](const auto key, const auto row, const auto & new_attributes)
-            {
-                update_result[key] = std::get<SSDComplexKeyCachePartition::Attribute::Container<String>>(new_attributes[attribute_index].values)[row];
-            },
-            [&](const auto) {},
-            getLifetime());
-
-    StringRefs tmp_refs(key_columns.size());
-    size_t default_index = 0;
-    for (size_t row = 0; row < n; ++row)
-    {
-        const auto key = tmp_keys_pool.allocKey(row, key_columns, tmp_refs);
-        SCOPE_EXIT(tmp_keys_pool.rollback(key));
-        if (unlikely(default_index != default_rows.size() && default_rows[default_index] == row))
-        {
-            auto to_insert = default_value_extractor[row];
-            out->insertData(to_insert.data, to_insert.size);
-            ++default_index;
-        }
-        else if (auto it = not_found_keys.find(key); it == std::end(not_found_keys))
-        {
-            out->insertData(refs[row].data, refs[row].size);
-        }
-        else if (auto it_update = update_result.find(key); it_update != std::end(update_result))
-        {
-            out->insertData(it_update->second.data(), it_update->second.size());
-        }
-        else
-        {
-            auto to_insert = default_value_extractor[row];
-            out->insertData(to_insert.data, to_insert.size);
-        }
-    }
-}
-
-ColumnUInt8::Ptr SSDComplexKeyCacheDictionary::hasKeys(const Columns & key_columns, const DataTypes & key_types) const
-{
-    dict_struct.validateKeyTypes(key_types);
-
-    const auto rows_num = key_columns.front()->size();
-
-    auto result = ColumnUInt8::create(rows_num);
-    auto& out = result->getData();
-
-    for (const auto row : ext::range(0, rows_num))
-        out[row] = false;
-
-    const auto now = std::chrono::system_clock::now();
-
-    std::unordered_map<KeyRef, std::vector<size_t>> not_found_keys;
-    TemporalComplexKeysPool not_found_pool;
-    storage.hasKeys(key_columns, key_types, out, not_found_keys, not_found_pool, now);
-    if (not_found_keys.empty())
-        return result;
-
-    std::vector<KeyRef> required_keys(not_found_keys.size());
-    std::transform(std::begin(not_found_keys), std::end(not_found_keys), std::begin(required_keys), [](const auto & pair) { return pair.first; });
-
-    std::vector<size_t> required_rows;
-    required_rows.reserve(required_keys.size());
-    for (const auto & key_ref : required_keys)
-        required_rows.push_back(not_found_keys[key_ref].front());
-
-    TemporalComplexKeysPool tmp_keys_pool;
-    storage.update(
-            source_ptr,
-            key_columns,
-            key_types,
-            required_keys,
-            required_rows,
-            tmp_keys_pool,
-            [&](const auto key, const auto, const auto &)
-            {
-                for (const size_t out_row : not_found_keys[key])
-                    out[out_row] = true;
-            },
-            [&](const auto key)
-            {
-                for (const size_t row : not_found_keys[key])
-                    out[row] = false;
-            },
-            getLifetime());
-
-    return result;
-}
-
-BlockInputStreamPtr SSDComplexKeyCacheDictionary::getBlockInputStream(
-    const Names & /* column_names */, size_t /* max_block_size*/) const
-{
-    throw DB::Exception("Method not supported.", ErrorCodes::NOT_IMPLEMENTED);
-}
-
-size_t SSDComplexKeyCacheDictionary::getAttributeIndex(const std::string & attr_name) const
-{
-    auto it = attribute_index_by_name.find(attr_name);
-    if (it == std::end(attribute_index_by_name))
-        throw  Exception{"Attribute `" + name + "` does not exist.", ErrorCodes::BAD_ARGUMENTS};
-    return it->second;
-}
-
-template <typename T>
-AttributeValueVariant SSDComplexKeyCacheDictionary::createAttributeNullValueWithTypeImpl(const Field & null_value)
-{
-    AttributeValueVariant var_null_value = static_cast<T>(null_value.get<NearestFieldType<T>>());
-    bytes_allocated += sizeof(T);
-    return var_null_value;
-}
-
-template <>
-AttributeValueVariant SSDComplexKeyCacheDictionary::createAttributeNullValueWithTypeImpl<String>(const Field & null_value)
-{
-    AttributeValueVariant var_null_value = null_value.get<String>();
-    bytes_allocated += sizeof(StringRef);
-    return var_null_value;
-}
-
-AttributeValueVariant SSDComplexKeyCacheDictionary::createAttributeNullValueWithType(const AttributeUnderlyingType type, const Field & null_value)
-{
-    switch (type)
-    {
-#define DISPATCH(TYPE) \
-case AttributeUnderlyingType::ut##TYPE: \
-    return createAttributeNullValueWithTypeImpl<TYPE>(null_value); /* NOLINT */
-
-        DISPATCH(UInt8)
-        DISPATCH(UInt16)
-        DISPATCH(UInt32)
-        DISPATCH(UInt64)
-        DISPATCH(UInt128)
-        DISPATCH(Int8)
-        DISPATCH(Int16)
-        DISPATCH(Int32)
-        DISPATCH(Int64)
-        DISPATCH(Decimal32)
-        DISPATCH(Decimal64)
-        DISPATCH(Decimal128)
-        DISPATCH(Float32)
-        DISPATCH(Float64)
-        DISPATCH(String)
-#undef DISPATCH
-    }
-    throw Exception{"Unknown attribute type: " + std::to_string(static_cast<int>(type)), ErrorCodes::TYPE_MISMATCH};
-}
-
-void SSDComplexKeyCacheDictionary::createAttributes()
-{
-    null_values.reserve(dict_struct.attributes.size());
-    for (size_t i = 0; i < dict_struct.attributes.size(); ++i)
-    {
-        const auto & attribute = dict_struct.attributes[i];
-
-        attribute_index_by_name.emplace(attribute.name, i);
-        null_values.push_back(createAttributeNullValueWithType(attribute.underlying_type, attribute.null_value));
-
-        if (attribute.hierarchical)
-            throw Exception{name + ": hierarchical attributes not supported for dictionary of type " + getTypeName(),
-                            ErrorCodes::TYPE_MISMATCH};
-    }
-}
-
-void registerDictionarySSDComplexKeyCache(DictionaryFactory & factory)
-{
-    auto create_layout = [=](const std::string & name,
-                             const DictionaryStructure & dict_struct,
-                             const Poco::Util::AbstractConfiguration & config,
-                             const std::string & config_prefix,
-                             DictionarySourcePtr source_ptr) -> DictionaryPtr
-    {
-        const auto dict_id = StorageID::fromDictionaryConfig(config, config_prefix);
-
-        if (dict_struct.id)
-            throw Exception{"'id' is not supported for dictionary of layout 'complex_key_cache'", ErrorCodes::UNSUPPORTED_METHOD};
-
-        if (dict_struct.range_min || dict_struct.range_max)
-            throw Exception{name
-                            + ": elements .structure.range_min and .structure.range_max should be defined only "
-                              "for a dictionary of layout 'range_hashed'",
-                            ErrorCodes::BAD_ARGUMENTS};
-        const auto & layout_prefix = config_prefix + ".layout";
-
-        const auto max_partitions_count = config.getInt(layout_prefix + ".complex_key_ssd_cache.max_partitions_count", DEFAULT_PARTITIONS_COUNT);
-        if (max_partitions_count <= 0)
-            throw Exception{name + ": dictionary of layout 'complex_key_ssd_cache' cannot have 0 (or less) max_partitions_count", ErrorCodes::BAD_ARGUMENTS};
-
-        const auto block_size = config.getInt(layout_prefix + ".complex_key_ssd_cache.block_size", DEFAULT_SSD_BLOCK_SIZE_BYTES);
-        if (block_size <= 0)
-            throw Exception{name + ": dictionary of layout 'complex_key_ssd_cache' cannot have 0 (or less) block_size", ErrorCodes::BAD_ARGUMENTS};
-
-        const auto file_size = config.getInt64(layout_prefix + ".complex_key_ssd_cache.file_size", DEFAULT_FILE_SIZE_BYTES);
-        if (file_size <= 0)
-            throw Exception{name + ": dictionary of layout 'complex_key_ssd_cache' cannot have 0 (or less) file_size", ErrorCodes::BAD_ARGUMENTS};
-        if (file_size % block_size != 0)
-            throw Exception{name + ": file_size must be a multiple of block_size", ErrorCodes::BAD_ARGUMENTS};
-
-        const auto read_buffer_size = config.getInt64(layout_prefix + ".complex_key_ssd_cache.read_buffer_size", DEFAULT_READ_BUFFER_SIZE_BYTES);
-        if (read_buffer_size <= 0)
-            throw Exception{name + ": dictionary of layout 'complex_key_ssd_cache' cannot have 0 (or less) read_buffer_size", ErrorCodes::BAD_ARGUMENTS};
-        if (read_buffer_size % block_size != 0)
-            throw Exception{name + ": read_buffer_size must be a multiple of block_size", ErrorCodes::BAD_ARGUMENTS};
-
-        const auto write_buffer_size = config.getInt64(layout_prefix + ".complex_key_ssd_cache.write_buffer_size", DEFAULT_WRITE_BUFFER_SIZE_BYTES);
-        if (write_buffer_size <= 0)
-            throw Exception{name + ": dictionary of layout 'complex_key_ssd_cache' cannot have 0 (or less) write_buffer_size", ErrorCodes::BAD_ARGUMENTS};
-        if (write_buffer_size % block_size != 0)
-            throw Exception{name + ": write_buffer_size must be a multiple of block_size", ErrorCodes::BAD_ARGUMENTS};
-
-        auto path = config.getString(layout_prefix + ".complex_key_ssd_cache.path");
-        if (path.empty())
-            throw Exception{name + ": dictionary of layout 'complex_key_ssd_cache' cannot have empty path",
-                            ErrorCodes::BAD_ARGUMENTS};
-        if (path.at(0) != '/')
-            path = std::filesystem::path{config.getString("path")}.concat(path).string();
-
-        const auto max_stored_keys = config.getInt64(layout_prefix + ".complex_key_ssd_cache.max_stored_keys", DEFAULT_MAX_STORED_KEYS);
-        if (max_stored_keys <= 0)
-            throw Exception{name + ": dictionary of layout 'complex_key_ssd_cache' cannot have 0 (or less) max_stored_keys", ErrorCodes::BAD_ARGUMENTS};
-
-        const DictionaryLifetime dict_lifetime{config, config_prefix + ".lifetime"};
-        return std::make_unique<SSDComplexKeyCacheDictionary>(
-                dict_id, dict_struct, std::move(source_ptr), dict_lifetime, path,
-                max_partitions_count, file_size / block_size, block_size,
-                read_buffer_size / block_size, write_buffer_size / block_size,
-                max_stored_keys);
-    };
-    factory.registerLayout("complex_key_ssd_cache", create_layout, true);
-}
-
-}
-
-#endif
diff --git a/src/Dictionaries/SSDComplexKeyCacheDictionary.h b/src/Dictionaries/SSDComplexKeyCacheDictionary.h
deleted file mode 100644
index be65d823e342..000000000000
--- a/src/Dictionaries/SSDComplexKeyCacheDictionary.h
+++ /dev/null
@@ -1,634 +0,0 @@
-#pragma once
-
-#if defined(OS_LINUX) || defined(__FreeBSD__)
-
-#include <atomic>
-#include <chrono>
-#include <list>
-#include <shared_mutex>
-#include <variant>
-#include <vector>
-#include <Poco/Logger.h>
-#include <Columns/ColumnDecimal.h>
-#include <Columns/ColumnString.h>
-#include <Common/Arena.h>
-#include <Common/ArenaWithFreeLists.h>
-#include <Common/CurrentMetrics.h>
-#include <common/logger_useful.h>
-#include <Common/SmallObjectPool.h>
-#include <Compression/CompressedWriteBuffer.h>
-#include <Core/Block.h>
-#include <Dictionaries/BucketCache.h>
-#include <ext/scope_guard.h>
-#include <IO/HashingWriteBuffer.h>
-#include <pcg_random.hpp>
-#include "IDictionary.h"
-#include "IDictionarySource.h"
-#include "DictionaryStructure.h"
-#include "DictionaryHelpers.h"
-
-namespace DB
-{
-
-class KeyRef
-{
-public:
-    explicit KeyRef(char * data) : ptr(data) {}
-
-    KeyRef() : ptr(nullptr) {}
-
-    inline UInt16 size() const
-    {
-        UInt16 res;
-        memcpy(&res, ptr, sizeof(res));
-        return res;
-    }
-
-    inline size_t fullSize() const
-    {
-        return static_cast<size_t>(size()) + sizeof(UInt16);
-    }
-
-    inline bool isNull() const
-    {
-        return ptr == nullptr;
-    }
-
-    inline char * data() const
-    {
-        return ptr + sizeof(UInt16);
-    }
-
-    inline char * fullData() const
-    {
-        return ptr;
-    }
-
-    inline char * fullData()
-    {
-        return ptr;
-    }
-
-    inline const StringRef getRef() const
-    {
-        return StringRef(data(), size());
-    }
-
-    inline bool operator==(const KeyRef & other) const
-    {
-        return getRef() == other.getRef();
-    }
-
-    inline bool operator!=(const KeyRef & other) const
-    {
-        return !(*this == other);
-    }
-
-    inline bool operator<(const KeyRef & other) const
-    {
-        return getRef() <  other.getRef();
-    }
-
-private:
-    char * ptr;
-};
-
-using KeyRefs = std::vector<KeyRef>;
-}
-
-namespace std
-{
-    template <>
-    struct hash<DB::KeyRef>
-    {
-        size_t operator() (DB::KeyRef key_ref) const
-        {
-            return hasher(key_ref.getRef());
-        }
-
-        std::hash<StringRef> hasher;
-    };
-}
-
-namespace DB
-{
-
-using AttributeValueVariant = std::variant<
-        UInt8,
-        UInt16,
-        UInt32,
-        UInt64,
-        UInt128,
-        Int8,
-        Int16,
-        Int32,
-        Int64,
-        Decimal32,
-        Decimal64,
-        Decimal128,
-        Float32,
-        Float64,
-        String>;
-
-/*
-    The pool for storing complex keys.
-*/
-template <typename A>
-class ComplexKeysPoolImpl
-{
-public:
-    KeyRef allocKey(const size_t row, const Columns & key_columns, StringRefs & keys)
-    {
-        const auto keys_size = key_columns.size();
-        UInt16 sum_keys_size{};
-
-        for (size_t j = 0; j < keys_size; ++j)
-        {
-            keys[j] = key_columns[j]->getDataAt(row);
-            sum_keys_size += keys[j].size;
-            if (!key_columns[j]->valuesHaveFixedSize())  // String
-                sum_keys_size += sizeof(size_t) + 1;
-        }
-
-        auto place = arena.alloc(sum_keys_size + sizeof(sum_keys_size));
-
-        auto key_start = place;
-        memcpy(key_start, &sum_keys_size, sizeof(sum_keys_size));
-        key_start += sizeof(sum_keys_size);
-        for (size_t j = 0; j < keys_size; ++j)
-        {
-            if (!key_columns[j]->valuesHaveFixedSize())  // String
-            {
-                auto key_size = keys[j].size + 1;
-                memcpy(key_start, &key_size, sizeof(size_t));
-                key_start += sizeof(size_t);
-                memcpy(key_start, keys[j].data, keys[j].size);
-                key_start += keys[j].size;
-                *key_start = '\0';
-                ++key_start;
-            }
-            else
-            {
-                memcpy(key_start, keys[j].data, keys[j].size);
-                key_start += keys[j].size;
-            }
-        }
-
-        return KeyRef(place);
-    }
-
-    KeyRef copyKeyFrom(const KeyRef & key)
-    {
-        char * data = arena.alloc(key.fullSize());
-        memcpy(data, key.fullData(), key.fullSize());
-        return KeyRef(data);
-    }
-
-    void freeKey(const KeyRef & key)
-    {
-        if constexpr (std::is_same_v<A, ArenaWithFreeLists>)
-            arena.free(key.fullData(), key.fullSize());
-    }
-
-    void rollback(const KeyRef & key)
-    {
-        if constexpr (std::is_same_v<A, Arena>)
-            arena.rollback(key.fullSize());
-    }
-
-    void writeKey(const KeyRef & key, WriteBuffer & buf)
-    {
-        buf.write(key.fullData(), key.fullSize());
-    }
-
-    void readKey(KeyRef & key, ReadBuffer & buf)
-    {
-        UInt16 sz;
-        readBinary(sz, buf);
-        char * data = nullptr;
-        if constexpr (std::is_same_v<A, SmallObjectPool>)
-            data = arena.alloc();
-        else
-            data = arena.alloc(sz + sizeof(sz));
-        memcpy(data, &sz, sizeof(sz));
-        buf.read(data + sizeof(sz), sz);
-        key = KeyRef(data);
-    }
-
-    void ignoreKey(ReadBuffer & buf) const
-    {
-        UInt16 sz;
-        readBinary(sz, buf);
-        buf.ignore(sz);
-    }
-
-    size_t size() const
-    {
-        return arena.size();
-    }
-
-private:
-    A arena;
-};
-
-using TemporalComplexKeysPool = ComplexKeysPoolImpl<Arena>;
-using ComplexKeysPool = ComplexKeysPoolImpl<ArenaWithFreeLists>;
-
-struct KeyDeleter
-{
-    KeyDeleter(ComplexKeysPool & keys_pool_) : keys_pool(keys_pool_) {}
-
-    void operator()(const KeyRef key) const
-    {
-        keys_pool.freeKey(key);
-    }
-
-    ComplexKeysPool & keys_pool;
-};
-
-
-/*
-    Class for operations with cache file and index.
-    Supports GET/SET operations.
-*/
-class SSDComplexKeyCachePartition
-{
-public:
-    struct Index final
-    {
-        bool inMemory() const;
-        void setInMemory(const bool in_memory);
-
-        bool exists() const;
-        void setNotExists();
-
-        size_t getAddressInBlock() const;
-        void setAddressInBlock(const size_t address_in_block);
-
-        size_t getBlockId() const;
-        void setBlockId(const size_t block_id);
-
-        bool operator< (const Index & rhs) const { return index < rhs.index; }
-
-        /// Stores `is_in_memory` flag, block id, address in uncompressed block
-        uint64_t index = 0;
-    };
-
-    struct Metadata final
-    {
-        using time_point_t = std::chrono::system_clock::time_point;
-        using time_point_rep_t = time_point_t::rep;
-        using time_point_urep_t = std::make_unsigned_t<time_point_rep_t>;
-
-        time_point_t expiresAt() const;
-        void setExpiresAt(const time_point_t & t);
-
-        bool isDefault() const;
-        void setDefault();
-
-        /// Stores both expiration time and `is_default` flag in the most significant bit
-        time_point_urep_t data = 0;
-    };
-
-    using Offset = size_t;
-    using Offsets = std::vector<Offset>;
-
-
-    SSDComplexKeyCachePartition(
-            const AttributeUnderlyingType & key_structure,
-            const std::vector<AttributeUnderlyingType> & attributes_structure,
-            const std::string & dir_path,
-            const size_t file_id,
-            const size_t max_size,
-            const size_t block_size,
-            const size_t read_buffer_size,
-            const size_t write_buffer_size,
-            const size_t max_stored_keys);
-
-    ~SSDComplexKeyCachePartition();
-
-    template <typename T>
-    using ResultArrayType = std::conditional_t<IsDecimalNumber<T>, DecimalPaddedPODArray<T>, PaddedPODArray<T>>;
-
-    template <typename Out, typename GetDefault>
-    void getValue(const size_t attribute_index,
-            const Columns & key_columns, const DataTypes & key_types,
-            ResultArrayType<Out> & out, std::vector<bool> & found, GetDefault & default_value_extractor,
-            std::chrono::system_clock::time_point now) const;
-
-    void getString(const size_t attribute_index,
-            const Columns & key_columns, const DataTypes & key_types,
-            StringRefs & refs, ArenaWithFreeLists & arena, std::vector<bool> & found,
-            std::vector<size_t> & default_ids, std::chrono::system_clock::time_point now) const;
-
-    void hasKeys(const Columns & key_columns, const DataTypes & key_types,
-            ResultArrayType<UInt8> & out, std::vector<bool> & found,
-            std::chrono::system_clock::time_point now) const;
-
-    struct Attribute
-    {
-        template <typename T>
-        using Container = std::vector<T>;
-
-        AttributeUnderlyingType type;
-        std::variant<
-                Container<UInt8>,
-                Container<UInt16>,
-                Container<UInt32>,
-                Container<UInt64>,
-                Container<UInt128>,
-                Container<Int8>,
-                Container<Int16>,
-                Container<Int32>,
-                Container<Int64>,
-                Container<Decimal32>,
-                Container<Decimal64>,
-                Container<Decimal128>,
-                Container<Float32>,
-                Container<Float64>,
-                Container<String>> values;
-    };
-    using Attributes = std::vector<Attribute>;
-
-    size_t appendBlock(
-        const Columns & key_columns,
-        const DataTypes & key_types,
-        const Attributes & new_attributes,
-        const PaddedPODArray<Metadata> & metadata,
-        const size_t begin);
-
-    size_t appendDefaults(
-        const KeyRefs & keys,
-        const PaddedPODArray<Metadata> & metadata,
-        const size_t begin);
-
-    void clearOldestBlocks();
-
-    void flush();
-
-    void remove();
-
-    size_t getId() const;
-
-    double getLoadFactor() const;
-
-    size_t getElementCount() const;
-
-    size_t getBytesAllocated() const;
-
-private:
-    size_t append(
-        const KeyRefs & keys,
-        const Attributes & new_attributes,
-        const PaddedPODArray<Metadata> & metadata,
-        const size_t begin);
-
-    template <typename SetFunc>
-    void getImpl(const Columns & key_columns, const DataTypes & key_types,
-        SetFunc & set, std::vector<bool> & found) const;
-
-    template <typename SetFunc>
-    void getValueFromMemory(const PaddedPODArray<Index> & indices, SetFunc & set) const;
-
-    template <typename SetFunc>
-    void getValueFromStorage(const PaddedPODArray<Index> & indices, SetFunc & set) const;
-
-    void ignoreFromBufferToAttributeIndex(const size_t attribute_index, ReadBuffer & buf) const;
-
-    const size_t file_id;
-    const size_t max_size;
-    const size_t block_size;
-    const size_t read_buffer_size;
-    const size_t write_buffer_size;
-    const size_t max_stored_keys;
-    const std::string path;
-
-    mutable std::shared_mutex rw_lock;
-
-    int fd = -1;
-
-    ComplexKeysPool keys_pool;
-    mutable BucketCacheIndex<KeyRef, Index, std::hash<KeyRef>, KeyDeleter> key_to_index;
-
-    std::optional<TemporalComplexKeysPool> keys_buffer_pool;
-    KeyRefs keys_buffer;
-
-    const std::vector<AttributeUnderlyingType> attributes_structure;
-
-    std::optional<Memory<>> memory;
-    std::optional<WriteBuffer> write_buffer;
-    uint32_t keys_in_block = 0;
-
-    size_t current_memory_block_id = 0;
-    size_t current_file_block_id = 0;
-};
-
-using SSDComplexKeyCachePartitionPtr = std::shared_ptr<SSDComplexKeyCachePartition>;
-
-
-/** Class for managing SSDCachePartition and getting data from source.
-  */
-class SSDComplexKeyCacheStorage
-{
-public:
-    using AttributeTypes = std::vector<AttributeUnderlyingType>;
-
-    SSDComplexKeyCacheStorage(
-            const AttributeTypes & attributes_structure,
-            const std::string & path,
-            const size_t max_partitions_count,
-            const size_t file_size,
-            const size_t block_size,
-            const size_t read_buffer_size,
-            const size_t write_buffer_size,
-            const size_t max_stored_keys);
-
-    ~SSDComplexKeyCacheStorage();
-
-    template <typename T>
-    using ResultArrayType = SSDComplexKeyCachePartition::ResultArrayType<T>;
-
-    template <typename Out, typename GetDefault>
-    void getValue(const size_t attribute_index, const Columns & key_columns, const DataTypes & key_types,
-            ResultArrayType<Out> & out, std::unordered_map<KeyRef, std::vector<size_t>> & not_found,
-            TemporalComplexKeysPool & not_found_pool,
-            GetDefault & get_default, std::chrono::system_clock::time_point now) const;
-
-    void getString(const size_t attribute_index, const Columns & key_columns, const DataTypes & key_types,
-            StringRefs & refs, ArenaWithFreeLists & arena, std::unordered_map<KeyRef, std::vector<size_t>> & not_found,
-            TemporalComplexKeysPool & not_found_pool,
-            std::vector<size_t> & default_ids, std::chrono::system_clock::time_point now) const;
-
-    void hasKeys(const Columns & key_columns, const DataTypes & key_types, ResultArrayType<UInt8> & out,
-            std::unordered_map<KeyRef, std::vector<size_t>> & not_found,
-            TemporalComplexKeysPool & not_found_pool, std::chrono::system_clock::time_point now) const;
-
-    template <typename PresentIdHandler, typename AbsentIdHandler>
-    void update(DictionarySourcePtr & source_ptr,
-            const Columns & key_columns, const DataTypes & key_types,
-            const KeyRefs & required_keys, const std::vector<size_t> & required_rows,
-            TemporalComplexKeysPool & tmp_keys_pool,
-            PresentIdHandler && on_updated, AbsentIdHandler && on_key_not_found,
-            const DictionaryLifetime lifetime);
-
-    std::exception_ptr getLastException() const { return last_update_exception; }
-
-    const std::string & getPath() const { return path; }
-
-    size_t getQueryCount() const { return query_count.load(std::memory_order_relaxed); }
-
-    size_t getHitCount() const { return hit_count.load(std::memory_order_acquire); }
-
-    size_t getElementCount() const;
-
-    double getLoadFactor() const;
-
-private:
-    void collectGarbage();
-
-    const AttributeTypes attributes_structure;
-
-    const std::string path;
-    const size_t max_partitions_count;
-    const size_t file_size;
-    const size_t block_size;
-    const size_t read_buffer_size;
-    const size_t write_buffer_size;
-    const size_t max_stored_keys;
-
-    mutable std::shared_mutex rw_lock;
-    std::list<SSDComplexKeyCachePartitionPtr> partitions;
-    std::list<SSDComplexKeyCachePartitionPtr> partition_delete_queue;
-
-    Poco::Logger * const log;
-
-    mutable pcg64 rnd_engine;
-
-    mutable std::exception_ptr last_update_exception;
-    mutable size_t update_error_count = 0;
-    mutable std::chrono::system_clock::time_point backoff_end_time;
-
-    mutable std::atomic<size_t> hit_count{0};
-    mutable std::atomic<size_t> query_count{0};
-};
-
-
-/** Dictionary interface
-  */
-class SSDComplexKeyCacheDictionary final : public IDictionaryBase
-{
-public:
-    SSDComplexKeyCacheDictionary(
-            const StorageID & dict_id_,
-            const DictionaryStructure & dict_struct_,
-            DictionarySourcePtr source_ptr_,
-            const DictionaryLifetime dict_lifetime_,
-            const std::string & path,
-            const size_t max_partitions_count_,
-            const size_t file_size_,
-            const size_t block_size_,
-            const size_t read_buffer_size_,
-            const size_t write_buffer_size_,
-            const size_t max_stored_keys_);
-
-    std::string getKeyDescription() const { return dict_struct.getKeyDescription(); }
-
-    std::string getTypeName() const override { return "SSDComplexKeyCache"; }
-
-    size_t getBytesAllocated() const override { return 0; } // TODO: ?
-
-    size_t getQueryCount() const override { return storage.getQueryCount(); }
-
-    double getHitRate() const override
-    {
-        return static_cast<double>(storage.getHitCount()) / storage.getQueryCount();
-    }
-
-    size_t getElementCount() const override { return storage.getElementCount(); }
-
-    double getLoadFactor() const override { return storage.getLoadFactor(); }
-
-    bool supportUpdates() const override { return false; }
-
-    std::shared_ptr<const IExternalLoadable> clone() const override
-    {
-        return std::make_shared<SSDComplexKeyCacheDictionary>(getDictionaryID(), dict_struct, source_ptr->clone(), dict_lifetime, path,
-                max_partitions_count, file_size, block_size, read_buffer_size, write_buffer_size, max_stored_keys);
-    }
-
-    const IDictionarySource * getSource() const override { return source_ptr.get(); }
-
-    const DictionaryLifetime & getLifetime() const override { return dict_lifetime; }
-
-    const DictionaryStructure & getStructure() const override { return dict_struct; }
-
-    bool isInjective(const std::string & attribute_name) const override
-    {
-        return dict_struct.attributes[getAttributeIndex(attribute_name)].injective;
-    }
-
-    std::exception_ptr getLastException() const override { return storage.getLastException(); }
-
-    DictionaryKeyType getKeyType() const override { return DictionaryKeyType::complex; }
-
-    ColumnPtr getColumn(
-        const std::string& attribute_name,
-        const DataTypePtr & result_type,
-        const Columns & key_columns,
-        const DataTypes & key_types,
-        const ColumnPtr default_values_column) const override;
-
-    ColumnUInt8::Ptr hasKeys(const Columns & key_columns, const DataTypes & key_types) const override;
-
-    template <typename T>
-    using ResultArrayType = SSDComplexKeyCacheStorage::ResultArrayType<T>;
-
-    BlockInputStreamPtr getBlockInputStream(const Names & column_names, size_t max_block_size) const override;
-
-private:
-    size_t getAttributeIndex(const std::string & attr_name) const;
-
-    template <typename T>
-    AttributeValueVariant createAttributeNullValueWithTypeImpl(const Field & null_value);
-    AttributeValueVariant createAttributeNullValueWithType(const AttributeUnderlyingType type, const Field & null_value);
-    void createAttributes();
-
-    template <typename AttributeType, typename OutputType, typename DefaultValueExtractor>
-    void getItemsNumberImpl(
-        const size_t attribute_index,
-        const Columns & key_columns,
-        const DataTypes & key_types,
-        ResultArrayType<OutputType> & out,
-        DefaultValueExtractor & default_value_extractor) const;
-
-    void getItemsStringImpl(
-        const size_t attribute_index,
-        const Columns & key_columns,
-        const DataTypes & key_types,
-        ColumnString * out,
-        DictionaryDefaultValueExtractor<String> & default_value_extractor) const;
-
-    const std::string name;
-    const DictionaryStructure dict_struct;
-    mutable DictionarySourcePtr source_ptr;
-    const DictionaryLifetime dict_lifetime;
-
-    const std::string path;
-    const size_t max_partitions_count;
-    const size_t file_size;
-    const size_t block_size;
-    const size_t read_buffer_size;
-    const size_t write_buffer_size;
-    const size_t max_stored_keys;
-
-    std::map<std::string, size_t> attribute_index_by_name;
-    std::vector<AttributeValueVariant> null_values;
-    mutable SSDComplexKeyCacheStorage storage;
-    Poco::Logger * const log;
-
-    mutable size_t bytes_allocated = 0;
-};
-
-}
-
-#endif
diff --git a/src/Dictionaries/benchmark b/src/Dictionaries/benchmark
new file mode 100644
index 000000000000..37d0d92ac14e
--- /dev/null
+++ b/src/Dictionaries/benchmark
@@ -0,0 +1,154 @@
+clickhouse-client --query="DROP TABLE IF EXISTS simple_cache_dictionary_table_source";
+clickhouse-client --query="CREATE TABLE simple_cache_dictionary_table_source (id UInt64, value1 String, value2 UInt64, value3 String, value4 Float64, value5 Decimal64(4)) ENGINE=TinyLog;"
+clickhouse-client --query="INSERT INTO simple_cache_dictionary_table_source SELECT number, concat('Value1 ', toString(number)), number, concat('Value3 ', toString(number)), toFloat64(number), cast(number, 'Decimal64(4)') FROM system.numbers LIMIT 1000000;"
+
+clickhouse-client --multiquery --query="CREATE DICTIONARY clickhouse_simple_cache_dictionary (
+    id UInt64,
+    value1 String,
+    value2 UInt64,
+    value3 String,
+    value4 Float64,
+    value5 Decimal64(4)
+)
+PRIMARY KEY id
+SOURCE(CLICKHOUSE(HOST 'localhost' PORT tcpPort() USER 'default' TABLE 'simple_cache_dictionary_table_source' PASSWORD '' DB 'default'))
+LIFETIME(MIN 300 MAX 300)
+LAYOUT(CACHE(SIZE_IN_CELLS 100000));"
+
+clickhouse-client --multiquery --query="CREATE DICTIONARY clickhouse_ssd_simple_cache_dictionary (
+    id UInt64,
+    value1 String,
+    value2 UInt64,
+    value3 String,
+    value4 Float64,
+    value5 Decimal64(4)
+)
+PRIMARY KEY id
+SOURCE(CLICKHOUSE(HOST 'localhost' PORT tcpPort() USER 'default' TABLE 'simple_cache_dictionary_table_source' PASSWORD '' DB 'default'))
+LIFETIME(MIN 300 MAX 300)
+LAYOUT(SSD_CACHE(BLOCK_SIZE 4096 FILE_SIZE 16777216 READ_BUFFER_SIZE 1048576 WRITE_BUFFER_SIZE 327680 MAX_STORED_KEYS 1048576 PATH '/opt/mkita/ClickHouse/build_release/programs/ssd_cache'));"
+
+clickhouse-client --multiquery --query="CREATE DICTIONARY clickhouse_dummy_simple_cache_dictionary (
+    id UInt64,
+    value1 String,
+    value2 UInt64,
+    value3 String,
+    value4 Float64,
+    value5 Decimal64(4)
+)
+PRIMARY KEY id
+SOURCE(CLICKHOUSE(HOST 'localhost' PORT tcpPort() USER 'default' TABLE 'simple_cache_dictionary_table_source' PASSWORD '' DB 'default'))
+LIFETIME(MIN 300 MAX 300)
+LAYOUT(DUMMY_SIMPLE());"
+
+./clickhouse-benchmark --query="SELECT
+    dictGet('default.clickhouse_dummy_simple_cache_dictionary', 'value1', number),
+    dictGet('default.clickhouse_dummy_simple_cache_dictionary', 'value2', number),
+    dictGet('default.clickhouse_dummy_simple_cache_dictionary', 'value3', number),
+    dictGet('default.clickhouse_dummy_simple_cache_dictionary', 'value4', number),
+    dictGet('default.clickhouse_dummy_simple_cache_dictionary', 'value5', number)
+FROM system.numbers
+LIMIT 10000
+FORMAT Null"
+
+./clickhouse-benchmark --query="SELECT
+    dictGet('default.clickhouse_simple_cache_dictionary', ('value1', 'value2', 'value3', 'value4', 'value5'), number)
+FROM system.numbers
+LIMIT 10000
+FORMAT Null"
+
+./clickhouse-benchmark --query="SELECT dictGet('default.clickhouse_ssd_simple_cache_dictionary', 'value1', number) FROM system.numbers_mt LIMIT 10000 FORMAT Null"
+
+./clickhouse-benchmark --query="SELECT
+    dictGet('default.clickhouse_simple_cache_dictionary', 'value1', number),
+    dictGet('default.clickhouse_simple_cache_dictionary', 'value2', number),
+    dictGet('default.clickhouse_simple_cache_dictionary', 'value3', number),
+    dictGet('default.clickhouse_simple_cache_dictionary', 'value4', number),
+    dictGet('default.clickhouse_simple_cache_dictionary', 'value5', number)
+FROM system.numbers
+LIMIT 10000
+FORMAT Null"
+
+./clickhouse-benchmark --query="SELECT dictGet('default.clickhouse_ssd_simple_cache_dictionary', 'value1', number) FROM system.numbers_mt LIMIT 10000 FORMAT Null"
+
+SELECT
+    dictGet('default.clickhouse_ssd_simple_cache_dictionary', 'value1', number),
+    dictGet('default.clickhouse_ssd_simple_cache_dictionary', 'value2', number),
+    dictGet('default.clickhouse_ssd_simple_cache_dictionary', 'value3', number),
+    dictGet('default.clickhouse_ssd_simple_cache_dictionary', 'value4', number),
+    dictGet('default.clickhouse_ssd_simple_cache_dictionary', 'value5', number)
+FROM system.numbers
+    LIMIT 10000
+FORMAT Null
+
+SELECT dictGet('default.clickhouse_simple_cache_dictionary', ('value1', 'value2', 'value3', 'value4', 'value5'), number) FROM system.numbers LIMIT 10000 FORMAT Null
+
+SELECT dictGet('default.clickhouse_ssd_simple_cache_dictionary', ('value1', 'value2', 'value3', 'value4', 'value5'), number) FROM system.numbers LIMIT 10000
+FORMAT Null
+
+SELECT
+    dictGet('default.clickhouse_simple_cache_dictionary', ('value1', 'value2', 'value3', 'value4', 'value5'), number)
+FROM system.numbers
+    LIMIT 10000
+FORMAT
+    Null
+
+SELECT
+    dictGet('default.clickhouse_simple_cache_dictionary', 'value1', number),
+    dictGet('default.clickhouse_simple_cache_dictionary', 'value2', number),
+    dictGet('default.clickhouse_simple_cache_dictionary', 'value3', number),
+    dictGet('default.clickhouse_simple_cache_dictionary', 'value4', number),
+    dictGet('default.clickhouse_simple_cache_dictionary', 'value5', number)
+FROM system.numbers
+    LIMIT 10000
+FORMAT
+    Null
+
+SELECT
+    dictGet('default.clickhouse_simple_cache_dictionary', 'value1', number),
+    dictGet('default.clickhouse_simple_cache_dictionary', 'value2', number)
+FROM system.numbers
+LIMIT 10000
+FORMAT Null
+
+SELECT
+    dictGet('clickhouse_simple_cache_dictionary', 'value1', number)
+FROM system.numbers
+LIMIT 100000
+FORMAT Null
+
+SELECT
+    dictGet('clickhouse_simple_cache_dictionary', 'value2', number)
+FROM system.numbers
+LIMIT 100000
+FORMAT Null
+
+SELECT
+    dictGet('clickhouse_simple_cache_dictionary', 'value3', number)
+FROM system.numbers
+LIMIT 100000
+FORMAT Null
+
+SELECT
+    dictGet('clickhouse_simple_cache_dictionary', 'value4', number)
+FROM system.numbers
+LIMIT 100000
+FORMAT Null
+
+SELECT
+    dictGet('clickhouse_simple_cache_dictionary', 'value5', number)
+FROM system.numbers
+LIMIT 100000
+FORMAT Null
+
+SELECT
+    dictGet('clickhouse_simple_cache_dictionary', 'value1', number),
+    dictGet('clickhouse_simple_cache_dictionary', 'value2', number),
+    dictGet('clickhouse_simple_cache_dictionary', 'value3', number),
+    dictGet('clickhouse_simple_cache_dictionary', 'value4', number),
+    dictGet('clickhouse_simple_cache_dictionary', 'value5', number)
+FROM system.numbers
+LIMIT 100000
+FORMAT Null
+
+SELECT * FROM clickhouse_simple_cache_dictionary_table;
\ No newline at end of file
diff --git a/src/Dictionaries/registerCacheDictionaries.cpp b/src/Dictionaries/registerCacheDictionaries.cpp
new file mode 100644
index 000000000000..92e6eb97b63f
--- /dev/null
+++ b/src/Dictionaries/registerCacheDictionaries.cpp
@@ -0,0 +1,309 @@
+#include "CacheDictionary.h"
+#include "SSDCacheDictionaryStorage.h"
+#include "CacheDictionaryStorage.h"
+#include <Dictionaries/DictionaryFactory.h>
+
+namespace DB
+{
+
+namespace ErrorCodes
+{
+    extern const int TOO_SMALL_BUFFER_SIZE;
+    extern const int UNSUPPORTED_METHOD;
+    extern const int BAD_ARGUMENTS;
+}
+
+CacheDictionaryStorageConfiguration parseCacheStorageConfiguration(
+    const String & full_name,
+    const Poco::Util::AbstractConfiguration & config,
+    const String & layout_prefix,
+    const DictionaryLifetime & dict_lifetime,
+    DictionaryKeyType dictionary_key_type)
+{
+    String dictionary_type_prefix = dictionary_key_type == DictionaryKeyType::complex ? ".complex_key_cache." : ".cache.";
+    String dictionary_configuration_prefix = layout_prefix + dictionary_type_prefix;
+
+    const size_t size = config.getUInt64(dictionary_configuration_prefix + "size_in_cells");
+    if (size == 0)
+        throw Exception(ErrorCodes::TOO_SMALL_BUFFER_SIZE,
+            "({}: cache dictionary cannot have 0 cells",
+            full_name);
+
+    size_t dict_lifetime_seconds = static_cast<size_t>(dict_lifetime.max_sec);
+    const size_t strict_max_lifetime_seconds = config.getUInt64(dictionary_configuration_prefix + "strict_max_lifetime_seconds", dict_lifetime_seconds);
+
+    size_t rounded_size = roundUpToPowerOfTwoOrZero(size);
+
+    CacheDictionaryStorageConfiguration storage_configuration{rounded_size, strict_max_lifetime_seconds, dict_lifetime};
+
+    return storage_configuration;
+}
+
+#if defined(OS_LINUX) || defined(__FreeBSD__)
+
+SSDCacheDictionaryStorageConfiguration parseSSDCacheStorageConfiguration(
+    const String & full_name,
+    const Poco::Util::AbstractConfiguration & config,
+    const String & layout_prefix,
+    const DictionaryLifetime & dict_lifetime,
+    DictionaryKeyType dictionary_key_type)
+{
+    String dictionary_type_prefix = dictionary_key_type == DictionaryKeyType::complex ? ".complex_key_ssd_cache." : ".ssd_cache.";
+    String dictionary_configuration_prefix = layout_prefix + dictionary_type_prefix;
+
+    const size_t strict_max_lifetime_seconds
+        = config.getUInt64(dictionary_configuration_prefix + "strict_max_lifetime_seconds", static_cast<size_t>(dict_lifetime.max_sec));
+
+    static constexpr size_t DEFAULT_SSD_BLOCK_SIZE_BYTES = DEFAULT_AIO_FILE_BLOCK_SIZE;
+    static constexpr size_t DEFAULT_FILE_SIZE_BYTES = 4 * 1024 * 1024 * 1024ULL;
+    static constexpr size_t DEFAULT_READ_BUFFER_SIZE_BYTES = 16 * DEFAULT_SSD_BLOCK_SIZE_BYTES;
+    static constexpr size_t DEFAULT_WRITE_BUFFER_SIZE_BYTES = DEFAULT_SSD_BLOCK_SIZE_BYTES;
+
+    static constexpr size_t DEFAULT_MAX_STORED_KEYS = 100000;
+    static constexpr size_t DEFAULT_PARTITIONS_COUNT = 16;
+
+    const size_t max_partitions_count
+        = config.getInt64(dictionary_configuration_prefix + "ssd_cache.max_partitions_count", DEFAULT_PARTITIONS_COUNT);
+
+    const size_t block_size = config.getInt64(dictionary_configuration_prefix + "block_size", DEFAULT_SSD_BLOCK_SIZE_BYTES);
+    const size_t file_size = config.getInt64(dictionary_configuration_prefix + "file_size", DEFAULT_FILE_SIZE_BYTES);
+    if (file_size % block_size != 0)
+        throw Exception(ErrorCodes::BAD_ARGUMENTS,
+            "({}): file_size must be a multiple of block_size",
+            full_name);
+
+    const size_t read_buffer_size = config.getInt64(dictionary_configuration_prefix + "read_buffer_size", DEFAULT_READ_BUFFER_SIZE_BYTES);
+    if (read_buffer_size % block_size != 0)
+        throw Exception(ErrorCodes::BAD_ARGUMENTS,
+            "({}): read_buffer_size must be a multiple of block_size",
+            full_name);
+
+    const size_t write_buffer_size
+        = config.getInt64(dictionary_configuration_prefix + "write_buffer_size", DEFAULT_WRITE_BUFFER_SIZE_BYTES);
+    if (write_buffer_size % block_size != 0)
+        throw Exception(ErrorCodes::BAD_ARGUMENTS,
+            "({}): write_buffer_size must be a multiple of block_size",
+            full_name);
+
+    auto directory_path = config.getString(dictionary_configuration_prefix + "path");
+    if (directory_path.empty())
+        throw Exception(ErrorCodes::BAD_ARGUMENTS,
+            "({}): ssd cache dictionary cannot have empty path",
+            full_name);
+
+    if (directory_path.at(0) != '/')
+        directory_path = std::filesystem::path{config.getString("path")}.concat(directory_path).string();
+
+    const size_t max_stored_keys_in_partition
+        = config.getInt64(dictionary_configuration_prefix + "max_stored_keys", DEFAULT_MAX_STORED_KEYS);
+    const size_t rounded_size = roundUpToPowerOfTwoOrZero(max_stored_keys_in_partition);
+
+    SSDCacheDictionaryStorageConfiguration configuration{
+        strict_max_lifetime_seconds,
+        dict_lifetime,
+        directory_path,
+        max_partitions_count,
+        rounded_size,
+        block_size,
+        file_size / block_size,
+        read_buffer_size / block_size,
+        write_buffer_size / block_size};
+
+    return configuration;
+}
+
+#endif
+
+CacheDictionaryUpdateQueueConfiguration parseCacheDictionaryUpdateQueueConfiguration(
+    const String & full_name,
+    const Poco::Util::AbstractConfiguration & config,
+    const String & layout_prefix,
+    DictionaryKeyType key_type)
+{
+    String layout_type = key_type == DictionaryKeyType::complex ? "complex_key_cache" : "cache";
+
+    const size_t max_update_queue_size = config.getUInt64(layout_prefix + ".cache.max_update_queue_size", 100000);
+    if (max_update_queue_size == 0)
+        throw Exception(ErrorCodes::TOO_SMALL_BUFFER_SIZE,
+            "({}): dictionary of layout '({})' cannot have empty update queue of size 0",
+            full_name,
+            layout_type);
+
+    const size_t update_queue_push_timeout_milliseconds
+        = config.getUInt64(layout_prefix + ".cache.update_queue_push_timeout_milliseconds", 10);
+    if (update_queue_push_timeout_milliseconds < 10)
+        throw Exception(ErrorCodes::BAD_ARGUMENTS,
+            "({}): dictionary of layout '({})' have too little update_queue_push_timeout",
+            full_name,
+            layout_type);
+
+    const size_t query_wait_timeout_milliseconds = config.getUInt64(layout_prefix + ".cache.query_wait_timeout_milliseconds", 60000);
+
+    const size_t max_threads_for_updates = config.getUInt64(layout_prefix + ".max_threads_for_updates", 4);
+    if (max_threads_for_updates == 0)
+        throw Exception(ErrorCodes::BAD_ARGUMENTS,
+            "({}): dictionary of layout) '({})' cannot have zero threads for updates",
+            full_name,
+            layout_type);
+
+    CacheDictionaryUpdateQueueConfiguration update_queue_configuration{
+        max_update_queue_size, max_threads_for_updates, update_queue_push_timeout_milliseconds, query_wait_timeout_milliseconds};
+
+    return update_queue_configuration;
+}
+
+template <DictionaryKeyType dictionary_key_type>
+DictionaryPtr createCacheDictionaryLayout(
+    const String & full_name,
+    const DictionaryStructure & dict_struct,
+    const Poco::Util::AbstractConfiguration & config,
+    const std::string & config_prefix,
+    DictionarySourcePtr source_ptr)
+{
+    static_assert(dictionary_key_type != DictionaryKeyType::range, "Range key type is not supported by CacheDictionary");
+
+    if constexpr (dictionary_key_type == DictionaryKeyType::simple)
+    {
+        if (dict_struct.key)
+            throw Exception(ErrorCodes::UNSUPPORTED_METHOD, "'key' is not supported for dictionary of layout 'cache'");
+    }
+    else if constexpr (dictionary_key_type == DictionaryKeyType::complex)
+    {
+        if (dict_struct.id)
+            throw Exception(ErrorCodes::UNSUPPORTED_METHOD, "'id' is not supported for dictionary of layout 'complex_key_cache'");
+    }
+
+    if (dict_struct.range_min || dict_struct.range_max)
+        throw Exception(ErrorCodes::BAD_ARGUMENTS,
+            "({}): elements .structure.range_min and .structure.range_max should be defined only "
+                  "for a dictionary of layout 'range_hashed'",
+            full_name);
+
+    const bool require_nonempty = config.getBool(config_prefix + ".require_nonempty", false);
+    if (require_nonempty)
+        throw Exception(ErrorCodes::BAD_ARGUMENTS,
+            "({}): cache dictionary of layout cannot have 'require_nonempty' attribute set",
+            full_name);
+
+    const auto & layout_prefix = config_prefix + ".layout";
+
+    const auto dict_id = StorageID::fromDictionaryConfig(config, config_prefix);
+
+    const DictionaryLifetime dict_lifetime{config, config_prefix + ".lifetime"};
+
+    const bool allow_read_expired_keys = config.getBool(layout_prefix + ".cache.allow_read_expired_keys", false);
+
+    auto storage_configuration = parseCacheStorageConfiguration(full_name, config, layout_prefix, dict_lifetime, dictionary_key_type);
+    auto storage = std::make_shared<CacheDictionaryStorage<dictionary_key_type>>(storage_configuration);
+
+    auto update_queue_configuration = parseCacheDictionaryUpdateQueueConfiguration(full_name, config, layout_prefix, dictionary_key_type);
+
+    return std::make_unique<CacheDictionary<dictionary_key_type>>(
+        dict_id, dict_struct, std::move(source_ptr), storage, update_queue_configuration, dict_lifetime, allow_read_expired_keys);
+}
+
+#if defined(OS_LINUX) || defined(__FreeBSD__)
+
+template <DictionaryKeyType dictionary_key_type>
+DictionaryPtr createSSDCacheDictionaryLayout(
+    const String & full_name,
+    const DictionaryStructure & dict_struct,
+    const Poco::Util::AbstractConfiguration & config,
+    const std::string & config_prefix,
+    DictionarySourcePtr source_ptr)
+{
+    static_assert(dictionary_key_type != DictionaryKeyType::range, "Range key type is not supported by CacheDictionary");
+
+    if constexpr (dictionary_key_type == DictionaryKeyType::simple)
+    {
+        if (dict_struct.key)
+            throw Exception(ErrorCodes::UNSUPPORTED_METHOD, "'key' is not supported for dictionary of layout 'ssd_cache'");
+    }
+    else if constexpr (dictionary_key_type == DictionaryKeyType::complex)
+    {
+        if (dict_struct.id)
+            throw Exception(ErrorCodes::UNSUPPORTED_METHOD, "'id' is not supported for dictionary of layout 'complex_key_ssd_cache'");
+    }
+
+    if (dict_struct.range_min || dict_struct.range_max)
+        throw Exception(ErrorCodes::BAD_ARGUMENTS,
+            "({}): elements .structure.range_min and .structure.range_max should be defined only "
+                  "for a dictionary of layout 'range_hashed'",
+            full_name);
+
+    const bool require_nonempty = config.getBool(config_prefix + ".require_nonempty", false);
+    if (require_nonempty)
+        throw Exception(ErrorCodes::BAD_ARGUMENTS,
+            "({}): cache dictionary of layout cannot have 'require_nonempty' attribute set",
+            full_name);
+
+    const auto & layout_prefix = config_prefix + ".layout";
+
+    const auto dict_id = StorageID::fromDictionaryConfig(config, config_prefix);
+
+    const DictionaryLifetime dict_lifetime{config, config_prefix + ".lifetime"};
+
+    const bool allow_read_expired_keys = config.getBool(layout_prefix + ".cache.allow_read_expired_keys", false);
+
+    auto storage_configuration = parseSSDCacheStorageConfiguration(full_name, config, layout_prefix, dict_lifetime, dictionary_key_type);
+    auto storage = std::make_shared<SSDCacheDictionaryStorage<dictionary_key_type>>(storage_configuration);
+
+    auto update_queue_configuration
+        = parseCacheDictionaryUpdateQueueConfiguration(full_name, config, layout_prefix, dictionary_key_type);
+
+    return std::make_unique<CacheDictionary<dictionary_key_type>>(
+        dict_id, dict_struct, std::move(source_ptr), storage, update_queue_configuration, dict_lifetime, allow_read_expired_keys);
+}
+
+#endif
+
+void registerDictionaryCache(DictionaryFactory & factory)
+{
+    auto create_simple_cache_layout = [=](const String & full_name,
+                                          const DictionaryStructure & dict_struct,
+                                          const Poco::Util::AbstractConfiguration & config,
+                                          const std::string & config_prefix,
+                                          DictionarySourcePtr source_ptr) -> DictionaryPtr
+    {
+        return createCacheDictionaryLayout<DictionaryKeyType::simple>(full_name, dict_struct, config, config_prefix, std::move(source_ptr));
+    };
+
+    factory.registerLayout("cache", create_simple_cache_layout, false);
+
+    auto create_complex_key_cache_layout = [=](const std::string & full_name,
+                                               const DictionaryStructure & dict_struct,
+                                               const Poco::Util::AbstractConfiguration & config,
+                                               const std::string & config_prefix,
+                                               DictionarySourcePtr source_ptr) -> DictionaryPtr
+    {
+        return createCacheDictionaryLayout<DictionaryKeyType::complex>(full_name, dict_struct, config, config_prefix, std::move(source_ptr));
+    };
+
+    factory.registerLayout("complex_key_cache", create_complex_key_cache_layout, true);
+
+#if defined(OS_LINUX) || defined(__FreeBSD__)
+
+    auto create_simple_ssd_cache_layout = [=](const std::string & full_name,
+                                              const DictionaryStructure & dict_struct,
+                                              const Poco::Util::AbstractConfiguration & config,
+                                              const std::string & config_prefix,
+                                              DictionarySourcePtr source_ptr) -> DictionaryPtr
+    {
+        return createSSDCacheDictionaryLayout<DictionaryKeyType::simple>(full_name, dict_struct, config, config_prefix, std::move(source_ptr));
+    };
+
+    factory.registerLayout("ssd_cache", create_simple_ssd_cache_layout, false);
+
+    auto create_complex_key_ssd_cache_layout = [=](const std::string & full_name,
+                                                   const DictionaryStructure & dict_struct,
+                                                   const Poco::Util::AbstractConfiguration & config,
+                                                   const std::string & config_prefix,
+                                                   DictionarySourcePtr source_ptr) -> DictionaryPtr {
+        return createSSDCacheDictionaryLayout<DictionaryKeyType::complex>(full_name, dict_struct, config, config_prefix, std::move(source_ptr));
+    };
+
+    factory.registerLayout("complex_key_ssd_cache", create_complex_key_ssd_cache_layout, true);
+#endif
+}
+
+}
diff --git a/src/Dictionaries/registerDictionaries.cpp b/src/Dictionaries/registerDictionaries.cpp
index abcc0ce06ad5..b0bf61a74ef2 100644
--- a/src/Dictionaries/registerDictionaries.cpp
+++ b/src/Dictionaries/registerDictionaries.cpp
@@ -24,16 +24,11 @@ void registerDictionarySourceLibrary(DictionarySourceFactory & source_factory);
 class DictionaryFactory;
 void registerDictionaryRangeHashed(DictionaryFactory & factory);
 void registerDictionaryComplexKeyHashed(DictionaryFactory & factory);
-void registerDictionaryComplexKeyCache(DictionaryFactory & factory);
 void registerDictionaryComplexKeyDirect(DictionaryFactory & factory);
 void registerDictionaryTrie(DictionaryFactory & factory);
 void registerDictionaryFlat(DictionaryFactory & factory);
 void registerDictionaryHashed(DictionaryFactory & factory);
 void registerDictionaryCache(DictionaryFactory & factory);
-#if defined(__linux__) || defined(__FreeBSD__)
-void registerDictionarySSDCache(DictionaryFactory & factory);
-void registerDictionarySSDComplexKeyCache(DictionaryFactory & factory);
-#endif
 void registerDictionaryPolygon(DictionaryFactory & factory);
 void registerDictionaryDirect(DictionaryFactory & factory);
 
@@ -62,16 +57,11 @@ void registerDictionaries()
         auto & factory = DictionaryFactory::instance();
         registerDictionaryRangeHashed(factory);
         registerDictionaryComplexKeyHashed(factory);
-        registerDictionaryComplexKeyCache(factory);
         registerDictionaryComplexKeyDirect(factory);
         registerDictionaryTrie(factory);
         registerDictionaryFlat(factory);
         registerDictionaryHashed(factory);
         registerDictionaryCache(factory);
-#if defined(OS_LINUX) || defined(__FreeBSD__)
-        registerDictionarySSDCache(factory);
-        registerDictionarySSDComplexKeyCache(factory);
-#endif
         registerDictionaryPolygon(factory);
         registerDictionaryDirect(factory);
     }
diff --git a/src/Dictionaries/ya.make b/src/Dictionaries/ya.make
index 4f33dc805591..9dbc1edbb09d 100644
--- a/src/Dictionaries/ya.make
+++ b/src/Dictionaries/ya.make
@@ -9,6 +9,7 @@ PEERDIR(
     contrib/libs/poco/MongoDB
     contrib/libs/poco/Redis
     contrib/libs/sparsehash
+    contrib/restricted/abseil-cpp
 )
 
 IF (USE_ODBC)
@@ -20,11 +21,11 @@ NO_COMPILER_WARNINGS()
 
 SRCS(
     CacheDictionary.cpp
+    CacheDictionaryUpdateQueue.cpp
     CassandraBlockInputStream.cpp
     CassandraDictionarySource.cpp
     CassandraHelpers.cpp
     ClickHouseDictionarySource.cpp
-    ComplexKeyCacheDictionary.cpp
     ComplexKeyDirectDictionary.cpp
     ComplexKeyHashedDictionary.cpp
     DictionaryBlockInputStreamBase.cpp
@@ -58,11 +59,10 @@ SRCS(
     RangeHashedDictionary.cpp
     RedisBlockInputStream.cpp
     RedisDictionarySource.cpp
-    SSDCacheDictionary.cpp
-    SSDComplexKeyCacheDictionary.cpp
     XDBCDictionarySource.cpp
     getDictionaryConfigurationFromAST.cpp
     readInvalidateQuery.cpp
+    registerCacheDictionaries.cpp
     registerDictionaries.cpp
     writeParenthesisedString.cpp
 
diff --git a/src/Dictionaries/ya.make.in b/src/Dictionaries/ya.make.in
index e52b106d0342..aa82fb21ba60 100644
--- a/src/Dictionaries/ya.make.in
+++ b/src/Dictionaries/ya.make.in
@@ -8,6 +8,7 @@ PEERDIR(
     contrib/libs/poco/MongoDB
     contrib/libs/poco/Redis
     contrib/libs/sparsehash
+    contrib/restricted/abseil-cpp
 )
 
 IF (USE_ODBC)
diff --git a/src/Functions/FunctionsExternalDictionaries.h b/src/Functions/FunctionsExternalDictionaries.h
index 18b89ff96898..7c88d244815a 100644
--- a/src/Functions/FunctionsExternalDictionaries.h
+++ b/src/Functions/FunctionsExternalDictionaries.h
@@ -24,6 +24,7 @@
 
 #include <Interpreters/Context.h>
 #include <Interpreters/ExternalDictionariesLoader.h>
+#include <Interpreters/castColumn.h>
 
 #include <Functions/IFunctionImpl.h>
 #include <Functions/FunctionHelpers.h>
@@ -31,13 +32,7 @@
 #include <Dictionaries/FlatDictionary.h>
 #include <Dictionaries/HashedDictionary.h>
 #include <Dictionaries/CacheDictionary.h>
-#if defined(OS_LINUX) || defined(__FreeBSD__)
-#include <Dictionaries/SSDCacheDictionary.h>
-#include <Dictionaries/SSDComplexKeyCacheDictionary.h>
-#endif
 #include <Dictionaries/ComplexKeyHashedDictionary.h>
-#include <Dictionaries/ComplexKeyCacheDictionary.h>
-#include <Dictionaries/ComplexKeyDirectDictionary.h>
 #include <Dictionaries/RangeHashedDictionary.h>
 #include <Dictionaries/IPAddressDictionary.h>
 #include <Dictionaries/PolygonDictionaryImplementations.h>
@@ -275,15 +270,21 @@ class FunctionDictGetNoType final : public IFunction
             throw Exception{"Illegal type " + arguments[0].type->getName() + " of first argument of function " + getName()
                 + ", expected a const string.", ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT};
 
-        String attribute_name;
-        if (const auto * name_col = checkAndGetColumnConst<ColumnString>(arguments[1].column.get()))
-            attribute_name = name_col->getValue<String>();
-        else
-            throw Exception{"Illegal type " + arguments[1].type->getName() + " of second argument of function " + getName()
-                + ", expected a const string.", ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT};
+        Strings attribute_names = getAttributeNamesFromColumn(arguments[1].column, arguments[1].type);
 
-        /// We're extracting the return type from the dictionary's config, without loading the dictionary.
-        return helper.getDictionaryStructure(dictionary_name).getAttribute(attribute_name).type;
+        DataTypes types;
+
+        for (auto & attribute_name : attribute_names)
+        {
+            /// We're extracting the return type from the dictionary's config, without loading the dictionary.
+            auto attribute = helper.getDictionaryStructure(dictionary_name).getAttribute(attribute_name);
+            types.emplace_back(attribute.type);
+        }
+
+        if (types.size() > 1)
+            return std::make_shared<DataTypeTuple>(types);
+        else
+            return types.front();
     }
 
     ColumnPtr executeImpl(const ColumnsWithTypeAndName & arguments, const DataTypePtr & result_type, size_t input_rows_count) const override
@@ -299,13 +300,7 @@ class FunctionDictGetNoType final : public IFunction
             throw Exception{"Illegal type " + arguments[0].type->getName() + " of first argument of function " + getName()
                 + ", expected a const string.", ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT};
 
-        String attribute_name;
-
-        if (const auto * name_col = checkAndGetColumnConst<ColumnString>(arguments[1].column.get()))
-            attribute_name = name_col->getValue<String>();
-        else
-            throw Exception{"Illegal type " + arguments[1].type->getName() + " of second argument of function " + getName()
-                + ", expected a const string.", ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT};
+        Strings attribute_names = getAttributeNamesFromColumn(arguments[1].column, arguments[1].type);
 
         auto dictionary = helper.getDictionary(dictionary_name);
 
@@ -337,14 +332,54 @@ class FunctionDictGetNoType final : public IFunction
             ++current_arguments_index;
         }
 
-        ColumnPtr default_col = nullptr;
+        Columns default_cols;
 
         if (dictionary_get_function_type == DictionaryGetFunctionType::getOrDefault)
         {
             if (current_arguments_index >= arguments.size())
                 throw Exception{"Wrong argument count for function " + getName(), ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH};
 
-            default_col = arguments[current_arguments_index].column;
+            const auto & column_before_cast = arguments[current_arguments_index];
+
+            if (const DataTypeTuple * type_tuple = typeid_cast<const DataTypeTuple *>(column_before_cast.type.get()))
+            {
+                const DataTypes & nested_types = type_tuple->getElements();
+
+                for (const auto & nested_type : nested_types)
+                    if (nested_type->isNullable())
+                        throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, "Wrong argument for function ({}) default values column nullable is not supported", getName());
+            }
+            else if (column_before_cast.type->isNullable())
+                throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, "Wrong argument for function ({}) default values column nullable is not supported", getName());
+
+            auto result_type_no_nullable = removeNullable(result_type);
+
+            ColumnWithTypeAndName column_to_cast = {column_before_cast.column->convertToFullColumnIfConst(), column_before_cast.type, column_before_cast.name};
+
+            auto result = castColumnAccurate(column_to_cast, result_type_no_nullable);
+
+            if (attribute_names.size() > 1)
+            {
+                const auto * tuple_column = checkAndGetColumn<ColumnTuple>(result.get());
+
+                if (!tuple_column)
+                    throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,
+                        "Wrong argument for function ({}) default values column must be tuple", getName());
+
+                if (tuple_column->tupleSize() != attribute_names.size())
+                    throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,
+                        "Wrong argument for function ({}) default values tuple column must contain same column size as requested attributes",
+                        getName());
+
+                default_cols = tuple_column->getColumnsCopy();
+            }
+            else
+                default_cols.emplace_back(result);
+        }
+        else
+        {
+            for (size_t i = 0; i < attribute_names.size(); ++i)
+                default_cols.emplace_back(nullptr);
         }
 
         ColumnPtr result;
@@ -354,16 +389,42 @@ class FunctionDictGetNoType final : public IFunction
 
         if (dictionary_key_type == DictionaryKeyType::simple)
         {
-            result = dictionary->getColumn(attribute_name, result_type, {key_column}, {std::make_shared<DataTypeUInt64>()}, default_col);
+            if (!WhichDataType(key_col_with_type.type).isUInt64())
+                 throw Exception(
+                     ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,
+                     "Third argument of function ({}) must be uint64 when dictionary is simple. Actual type ({}).",
+                     getName(),
+                     key_col_with_type.type->getName());
+
+            if (attribute_names.size() > 1)
+            {
+                const auto & result_tuple_type = assert_cast<const DataTypeTuple &>(*result_type);
+
+                Columns result_columns = dictionary->getColumns(
+                    attribute_names,
+                    result_tuple_type.getElements(),
+                    {key_column},
+                    {std::make_shared<DataTypeUInt64>()},
+                    default_cols);
+
+                result = ColumnTuple::create(std::move(result_columns));
+            }
+            else
+                result = dictionary->getColumn(
+                    attribute_names[0],
+                    result_type,
+                    {key_column},
+                    {std::make_shared<DataTypeUInt64>()},
+                    default_cols.front());
         }
         else if (dictionary_key_type == DictionaryKeyType::complex)
         {
             if (!isTuple(key_col_with_type.type))
-                throw Exception(
-                    ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,
-                    "Third argument of function ({}) must be tuple when dictionary is complex. Actual type ({}).",
-                    getName(),
-                    key_col_with_type.type->getName());
+                 throw Exception(
+                     ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,
+                     "Third argument of function ({}) must be tuple when dictionary is complex. Actual type ({}).",
+                     getName(),
+                     key_col_with_type.type->getName());
 
             /// Functions in external dictionaries_loader only support full-value (not constant) columns with keys.
             ColumnPtr key_column_full = key_col_with_type.column->convertToFullColumnIfConst();
@@ -371,12 +432,56 @@ class FunctionDictGetNoType final : public IFunction
             const auto & key_columns = typeid_cast<const ColumnTuple &>(*key_column_full).getColumnsCopy();
             const auto & key_types = static_cast<const DataTypeTuple &>(*key_col_with_type.type).getElements();
 
-            result = dictionary->getColumn(attribute_name, result_type, key_columns, key_types, default_col);
+            if (attribute_names.size() > 1)
+            {
+                const auto & result_tuple_type = assert_cast<const DataTypeTuple &>(*result_type);
+
+                Columns result_columns = dictionary->getColumns(
+                    attribute_names,
+                    result_tuple_type.getElements(),
+                    key_columns,
+                    key_types,
+                    default_cols);
+
+                result = ColumnTuple::create(std::move(result_columns));
+            }
+            else
+                result = dictionary->getColumn(
+                    attribute_names[0],
+                    result_type,
+                    key_columns,
+                    key_types,
+                    default_cols.front());
         }
         else if (dictionary_key_type == DictionaryKeyType::range)
         {
-            result = dictionary->getColumn(
-                attribute_name, result_type, {key_column, range_col}, {std::make_shared<DataTypeUInt64>(), range_col_type}, default_col);
+            if (!WhichDataType(key_col_with_type.type).isUInt64())
+                 throw Exception(
+                     ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,
+                     "Third argument of function ({}) must be uint64 when dictionary is range. Actual type ({}).",
+                     getName(),
+                     key_col_with_type.type->getName());
+
+            if (attribute_names.size() > 1)
+            {
+                const auto & result_tuple_type = assert_cast<const DataTypeTuple &>(*result_type);
+
+                Columns result_columns = dictionary->getColumns(
+                    attribute_names,
+                    result_tuple_type.getElements(),
+                    {key_column, range_col},
+                    {std::make_shared<DataTypeUInt64>(), range_col_type},
+                    default_cols);
+
+                result = ColumnTuple::create(std::move(result_columns));
+            }
+            else
+                result = dictionary->getColumn(
+                    attribute_names[0],
+                    result_type,
+                    {key_column, range_col},
+                    {std::make_shared<DataTypeUInt64>(), range_col_type},
+                    default_cols.front());
         }
         else
             throw Exception{"Unknown dictionary identifier type", ErrorCodes::BAD_ARGUMENTS};
@@ -385,6 +490,45 @@ class FunctionDictGetNoType final : public IFunction
     }
 
 private:
+
+    Strings getAttributeNamesFromColumn(const ColumnPtr & column, const DataTypePtr & type) const
+    {
+        Strings attribute_names;
+
+        if (const auto * name_col = checkAndGetColumnConst<ColumnString>(column.get()))
+            attribute_names.emplace_back(name_col->getValue<String>());
+        else if (const auto * tuple_col_const = checkAndGetColumnConst<ColumnTuple>(column.get()))
+        {
+            const ColumnTuple & tuple_col = assert_cast<const ColumnTuple &>(tuple_col_const->getDataColumn());
+            size_t tuple_size = tuple_col.tupleSize();
+
+            if (tuple_size < 1)
+                throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,
+                    "Tuple second argument of function ({}) must contain multiple constant string columns");
+
+            for (size_t i = 0; i < tuple_col.tupleSize(); ++i)
+            {
+                const auto * tuple_column = tuple_col.getColumnPtr(i).get();
+
+                const auto * attribute_name_column = checkAndGetColumn<ColumnString>(tuple_column);
+
+                if (!attribute_name_column)
+                    throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,
+                        "Tuple second argument of function ({}) must contain multiple constant string columns",
+                        getName());
+
+                attribute_names.emplace_back(attribute_name_column->getDataAt(0));
+            }
+        }
+        else
+            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,
+                "Illegal type ({}) of second argument of function ({}), expected a const string or const tuple of const strings.",
+                type->getName(),
+                getName());
+
+        return attribute_names;
+    }
+
     mutable FunctionDictHelper helper;
 };
 
@@ -579,7 +723,7 @@ class FunctionDictGetHierarchy final : public IFunction
         if (!((res = executeDispatch<FlatDictionary>(arguments, result_type, dict))
             || (res = executeDispatch<DirectDictionary>(arguments, result_type, dict))
             || (res = executeDispatch<HashedDictionary>(arguments, result_type, dict))
-            || (res = executeDispatch<CacheDictionary>(arguments, result_type, dict))))
+            || (res = executeDispatch<CacheDictionary<DictionaryKeyType::simple>>(arguments, result_type, dict))))
             throw Exception{"Unsupported dictionary type " + dict->getTypeName(), ErrorCodes::UNKNOWN_TYPE};
 
         return res;
@@ -732,7 +876,7 @@ class FunctionDictIsIn final : public IFunction
         if (!((res = executeDispatch<FlatDictionary>(arguments, dict))
             || (res = executeDispatch<DirectDictionary>(arguments, dict))
             || (res = executeDispatch<HashedDictionary>(arguments, dict))
-            || (res = executeDispatch<CacheDictionary>(arguments, dict))))
+            || (res = executeDispatch<CacheDictionary<DictionaryKeyType::simple>>(arguments, dict))))
             throw Exception{"Unsupported dictionary type " + dict->getTypeName(), ErrorCodes::UNKNOWN_TYPE};
 
         return res;
diff --git a/src/Interpreters/AggregationCommon.h b/src/Interpreters/AggregationCommon.h
index e896b0e14dfc..8f15d1c6c56f 100644
--- a/src/Interpreters/AggregationCommon.h
+++ b/src/Interpreters/AggregationCommon.h
@@ -19,11 +19,6 @@
 #include <tmmintrin.h>
 #endif
 
-
-template <>
-struct DefaultHash<StringRef> : public StringRefHash {};
-
-
 namespace DB
 {
 namespace ErrorCodes
