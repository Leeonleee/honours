You will be provided with a partial code base and an issue statement explaining a problem to resolve.

<issue>
Support arrow::parquet fixed_size_list
**Use case**

I have a data processing pipeline that generates embeddings (fixed size arrays of floats) and stores them as parquet files. I want to read those parquet files and find closest matches with [cosine similarity](https://clickhouse.com/docs/knowledgebase/vector-search#3-search-for-related-embeddings).

My embedding generation pipeline currently generates data frames with [FixedSizeListArray arrow columns](https://arrow.apache.org/docs/python/generated/pyarrow.FixedSizeListArray.html), which when written as a parquet file cannot be read by ClickHouse.

The same data written with a [ListArray arrow column](https://arrow.apache.org/docs/python/generated/pyarrow.ListArray.html), the variable length list type, can be read by ClickHouse.

See "Additional context" (below) for repro.

**Describe the solution you'd like**

Both FixedSizeListArray and ListArray are stored the same way in parquet, namely as a parquet list; they only differ in the additional parquet metadata the arrow library adds. Insofar as ClickHouse support for [parquet](https://clickhouse.com/docs/en/sql-reference/formats#data-types-matching-parquet) is about the parquet file format and not how arrow works, I would expect either parquet file to be readable by ClickHouse.

Of course, I understand that ClickHouse uses the arrow library under the hood and the eventual in-memory arrow layout of ListArray and FixedSizeListArray are different.

Possibly relevant:
- Arrow's [fixed size list layout](https://arrow.apache.org/docs/format/Columnar.html#fixed-size-list-layout) is probably analogous to ClickHouse's FixedString, and
- there is [current work](https://issues.apache.org/jira/browse/PARQUET-2474) by the arrow/parquet projects to substantially improve parquet's fixed size list support to better support machine learning workloads.

**Describe alternatives you've considered**

For now, I can write embeddings as variable length lists, but given the roadmap for fixed size lists in the arrow/parquet ecosystem, it would be nice to know what the ClickHouse project's roadmap is on more directly supporting this datatype.

**Additional context**

Generating a fixed size list array:

```python
import pyarrow as pa
import pyarrow.parquet as pq

# FixedSizeListArray
typ = pa.list_(pa.field("values", pa.int64()), 2)
values = pa.array([1, 2, 3, 4])
tbl = pa.Table.from_arrays([pa.FixedSizeListArray.from_arrays(values, type=typ)], names=["values"])

pq.write_table(tbl, "tbl.parquet")
```

and then reading it with `clickhouse local` fails:

```shell
$ clickhouse local -q "SELECT * FROM file('tbl.parquet')"
Code: 50. DB::Exception: Unsupported Parquet type 'fixed_size_list' of an input column 'values'. If it happens during schema inference and you want to skip columns with unsupported types, you can enable setting input_format_parquet_skip_columns_with_unsupported_types_in_schema_inference: (in file/uri /tmp/tbl.parquet): While executing ParquetBlockInputFormat: While executing File. (UNKNOWN_TYPE)
```

while generating a variable length list array

```python
# ListArray (variable length lists)
typ = pa.list_(pa.field("values", pa.int64()))
offsets = pa.array([0, 2])
tbl = pa.Table.from_arrays([pa.ListArray.from_arrays(offsets, values, type=typ)], names=["values"])
```

succeeds

```shell
$ clickhouse local -q "SELECT * FROM file('tbl.parquet')"
[1,2]
```

From a parquet perspective, both FixedSizeListArray and ListArray arrow columns are written as parquet lists. I.e., `pq.read_metadata.schema` returns the same thing for both:

```
> pq.read_metadata("tbl.parquet").schema
parquet schema: <pyarrow._parquet.ParquetSchema object at 0x107e11800>
required group field_id=-1 schema {
  optional group field_id=-1 values (List) {
    repeated group field_id=-1 list {
      optional int64 field_id=-1 element;
    }
  }
}
> pq.read_metadata("tbl.parquet").metadata
{b'ARROW:schema': b'[...]'}
```

The only difference is the additional parquet metadata encoding the desired arrow schema.
</issue>

I need you to solve the provided issue by generating a code fix that can be applied directly to the repository

Respond below:
