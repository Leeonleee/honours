diff --git a/src/Columns/ColumnNullable.cpp b/src/Columns/ColumnNullable.cpp
index d8e98ec9406c..8d61f6e726aa 100644
--- a/src/Columns/ColumnNullable.cpp
+++ b/src/Columns/ColumnNullable.cpp
@@ -793,4 +793,18 @@ ColumnPtr makeNullable(const ColumnPtr & column)
     return ColumnNullable::create(column, ColumnUInt8::create(column->size(), 0));
 }
 
+ColumnPtr makeNullableSafe(const ColumnPtr & column)
+{
+    if (isColumnNullable(*column))
+        return column;
+
+    if (isColumnConst(*column))
+        return ColumnConst::create(makeNullableSafe(assert_cast<const ColumnConst &>(*column).getDataColumnPtr()), column->size());
+
+    if (column->canBeInsideNullable())
+        return makeNullable(column);
+
+    return column;
+}
+
 }
diff --git a/src/Columns/ColumnNullable.h b/src/Columns/ColumnNullable.h
index 52e57f7f0d04..e832f6d20e57 100644
--- a/src/Columns/ColumnNullable.h
+++ b/src/Columns/ColumnNullable.h
@@ -223,5 +223,6 @@ class ColumnNullable final : public COWHelper<IColumn, ColumnNullable>
 };
 
 ColumnPtr makeNullable(const ColumnPtr & column);
+ColumnPtr makeNullableSafe(const ColumnPtr & column);
 
 }
diff --git a/src/Core/Settings.h b/src/Core/Settings.h
index bda72f089eb1..71af2421cda9 100644
--- a/src/Core/Settings.h
+++ b/src/Core/Settings.h
@@ -132,6 +132,8 @@ static constexpr UInt64 operator""_GiB(unsigned long long value)
     M(UInt64, aggregation_memory_efficient_merge_threads, 0, "Number of threads to use for merge intermediate aggregation results in memory efficient mode. When bigger, then more memory is consumed. 0 means - same as 'max_threads'.", 0) \
     M(Bool, enable_positional_arguments, true, "Enable positional arguments in ORDER BY, GROUP BY and LIMIT BY", 0) \
     \
+    M(Bool, group_by_use_nulls, false, "Treat columns mentioned in ROLLUP, CUBE or GROUPING SETS as Nullable", 0) \
+    \
     M(UInt64, max_parallel_replicas, 1, "The maximum number of replicas of each shard used when the query is executed. For consistency (to get different parts of the same partition), this option only works for the specified sampling key. The lag of the replicas is not controlled.", 0) \
     M(UInt64, parallel_replicas_count, 0, "", 0) \
     M(UInt64, parallel_replica_offset, 0, "", 0) \
diff --git a/src/DataTypes/DataTypeNullable.cpp b/src/DataTypes/DataTypeNullable.cpp
index b354b1278be8..a14fb785b967 100644
--- a/src/DataTypes/DataTypeNullable.cpp
+++ b/src/DataTypes/DataTypeNullable.cpp
@@ -85,6 +85,13 @@ DataTypePtr makeNullable(const DataTypePtr & type)
     return std::make_shared<DataTypeNullable>(type);
 }
 
+DataTypePtr makeNullableSafe(const DataTypePtr & type)
+{
+    if (type->canBeInsideNullable())
+        return makeNullable(type);
+    return type;
+}
+
 DataTypePtr removeNullable(const DataTypePtr & type)
 {
     if (type->isNullable())
diff --git a/src/DataTypes/DataTypeNullable.h b/src/DataTypes/DataTypeNullable.h
index c87e4f77008e..379119b364c0 100644
--- a/src/DataTypes/DataTypeNullable.h
+++ b/src/DataTypes/DataTypeNullable.h
@@ -51,6 +51,7 @@ class DataTypeNullable final : public IDataType
 
 
 DataTypePtr makeNullable(const DataTypePtr & type);
+DataTypePtr makeNullableSafe(const DataTypePtr & type);
 DataTypePtr removeNullable(const DataTypePtr & type);
 
 }
diff --git a/src/DataTypes/IDataType.h b/src/DataTypes/IDataType.h
index fce8906abe5f..a26c703cd8a1 100644
--- a/src/DataTypes/IDataType.h
+++ b/src/DataTypes/IDataType.h
@@ -532,6 +532,12 @@ inline bool isBool(const DataTypePtr & data_type)
     return data_type->getName() == "Bool";
 }
 
+inline bool isAggregateFunction(const DataTypePtr & data_type)
+{
+    WhichDataType which(data_type);
+    return which.isAggregateFunction();
+}
+
 template <typename DataType> constexpr bool IsDataTypeDecimal = false;
 template <typename DataType> constexpr bool IsDataTypeNumber = false;
 template <typename DataType> constexpr bool IsDataTypeDateOrDateTime = false;
diff --git a/src/Interpreters/ExpressionAnalyzer.cpp b/src/Interpreters/ExpressionAnalyzer.cpp
index 23258c600991..a4bdc4ed2523 100644
--- a/src/Interpreters/ExpressionAnalyzer.cpp
+++ b/src/Interpreters/ExpressionAnalyzer.cpp
@@ -45,6 +45,9 @@
 
 #include <Common/typeid_cast.h>
 #include <Common/StringUtils/StringUtils.h>
+#include <Columns/ColumnNullable.h>
+#include <Core/ColumnsWithTypeAndName.h>
+#include <DataTypes/IDataType.h>
 #include <Core/SettingsEnums.h>
 #include <Core/ColumnNumbers.h>
 #include <Core/Names.h>
@@ -345,6 +348,7 @@ void ExpressionAnalyzer::analyzeAggregation(ActionsDAGPtr & temp_actions)
                 group_by_kind = GroupByKind::GROUPING_SETS;
             else
                 group_by_kind = GroupByKind::ORDINARY;
+            bool use_nulls = group_by_kind != GroupByKind::ORDINARY && getContext()->getSettingsRef().group_by_use_nulls;
 
             /// For GROUPING SETS with multiple groups we always add virtual __grouping_set column
             /// With set number, which is used as an additional key at the stage of merging aggregating data.
@@ -399,7 +403,7 @@ void ExpressionAnalyzer::analyzeAggregation(ActionsDAGPtr & temp_actions)
                             }
                         }
 
-                        NameAndTypePair key{column_name, node->result_type};
+                        NameAndTypePair key{column_name, use_nulls ? makeNullableSafe(node->result_type) : node->result_type };
 
                         grouping_set_list.push_back(key);
 
@@ -453,7 +457,7 @@ void ExpressionAnalyzer::analyzeAggregation(ActionsDAGPtr & temp_actions)
                         }
                     }
 
-                    NameAndTypePair key{column_name, node->result_type};
+                    NameAndTypePair key = NameAndTypePair{ column_name, use_nulls ? makeNullableSafe(node->result_type) : node->result_type };
 
                     /// Aggregation keys are uniqued.
                     if (!unique_keys.contains(key.name))
@@ -1489,6 +1493,28 @@ void SelectQueryExpressionAnalyzer::appendExpressionsAfterWindowFunctions(Expres
     }
 }
 
+void SelectQueryExpressionAnalyzer::appendGroupByModifiers(ActionsDAGPtr & before_aggregation, ExpressionActionsChain & chain, bool /* only_types */)
+{
+    const auto * select_query = getAggregatingQuery();
+
+    if (!select_query->groupBy() || !(select_query->group_by_with_rollup || select_query->group_by_with_cube))
+        return;
+
+    auto source_columns = before_aggregation->getResultColumns();
+    ColumnsWithTypeAndName result_columns;
+
+    for (const auto & source_column : source_columns)
+    {
+        if (source_column.type->canBeInsideNullable())
+            result_columns.emplace_back(makeNullableSafe(source_column.type), source_column.name);
+        else
+            result_columns.push_back(source_column);
+    }
+    ExpressionActionsChain::Step & step = chain.lastStep(before_aggregation->getNamesAndTypesList());
+
+    step.actions() = ActionsDAG::makeConvertingActions(source_columns, result_columns, ActionsDAG::MatchColumnsMode::Position);
+}
+
 void SelectQueryExpressionAnalyzer::appendSelectSkipWindowExpressions(ExpressionActionsChain::Step & step, ASTPtr const & node)
 {
     if (auto * function = node->as<ASTFunction>())
@@ -1956,6 +1982,9 @@ ExpressionAnalysisResult::ExpressionAnalysisResult(
             query_analyzer.appendAggregateFunctionsArguments(chain, only_types || !first_stage);
             before_aggregation = chain.getLastActions();
 
+            if (settings.group_by_use_nulls)
+                query_analyzer.appendGroupByModifiers(before_aggregation, chain, only_types);
+
             finalize_chain(chain);
 
             if (query_analyzer.appendHaving(chain, only_types || !second_stage))
diff --git a/src/Interpreters/ExpressionAnalyzer.h b/src/Interpreters/ExpressionAnalyzer.h
index 019cda8b924a..10c11499f14b 100644
--- a/src/Interpreters/ExpressionAnalyzer.h
+++ b/src/Interpreters/ExpressionAnalyzer.h
@@ -412,6 +412,8 @@ class SelectQueryExpressionAnalyzer : public ExpressionAnalyzer
     void appendExpressionsAfterWindowFunctions(ExpressionActionsChain & chain, bool only_types);
     void appendSelectSkipWindowExpressions(ExpressionActionsChain::Step & step, ASTPtr const & node);
 
+    void appendGroupByModifiers(ActionsDAGPtr & before_aggregation, ExpressionActionsChain & chain, bool only_types);
+
     /// After aggregation:
     bool appendHaving(ExpressionActionsChain & chain, bool only_types);
     ///  appendSelect
diff --git a/src/Interpreters/InterpreterSelectQuery.cpp b/src/Interpreters/InterpreterSelectQuery.cpp
index ac31588d2102..a05d353ac733 100644
--- a/src/Interpreters/InterpreterSelectQuery.cpp
+++ b/src/Interpreters/InterpreterSelectQuery.cpp
@@ -786,8 +786,16 @@ Block InterpreterSelectQuery::getSampleBlockImpl()
         if (analysis_result.use_grouping_set_key)
             res.insert({ nullptr, std::make_shared<DataTypeUInt64>(), "__grouping_set" });
 
-        for (const auto & key : query_analyzer->aggregationKeys())
-            res.insert({nullptr, header.getByName(key.name).type, key.name});
+        if (context->getSettingsRef().group_by_use_nulls && analysis_result.use_grouping_set_key)
+        {
+            for (const auto & key : query_analyzer->aggregationKeys())
+                res.insert({nullptr, makeNullableSafe(header.getByName(key.name).type), key.name});
+        }
+        else
+        {
+            for (const auto & key : query_analyzer->aggregationKeys())
+                res.insert({nullptr, header.getByName(key.name).type, key.name});
+        }
 
         for (const auto & aggregate : query_analyzer->aggregates())
         {
@@ -2326,6 +2334,7 @@ void InterpreterSelectQuery::executeAggregation(QueryPlan & query_plan, const Ac
         merge_threads,
         temporary_data_merge_threads,
         storage_has_evenly_distributed_read,
+        settings.group_by_use_nulls,
         std::move(group_by_info),
         std::move(group_by_sort_description),
         should_produce_results_in_order_of_bucket_number);
@@ -2402,9 +2411,9 @@ void InterpreterSelectQuery::executeRollupOrCube(QueryPlan & query_plan, Modific
 
     QueryPlanStepPtr step;
     if (modificator == Modificator::ROLLUP)
-        step = std::make_unique<RollupStep>(query_plan.getCurrentDataStream(), std::move(params), final);
+        step = std::make_unique<RollupStep>(query_plan.getCurrentDataStream(), std::move(params), final, settings.group_by_use_nulls);
     else if (modificator == Modificator::CUBE)
-        step = std::make_unique<CubeStep>(query_plan.getCurrentDataStream(), std::move(params), final);
+        step = std::make_unique<CubeStep>(query_plan.getCurrentDataStream(), std::move(params), final, settings.group_by_use_nulls);
 
     query_plan.addStep(std::move(step));
 }
diff --git a/src/Processors/QueryPlan/AggregatingStep.cpp b/src/Processors/QueryPlan/AggregatingStep.cpp
index 0a4b12084ebe..f4e3749bd70b 100644
--- a/src/Processors/QueryPlan/AggregatingStep.cpp
+++ b/src/Processors/QueryPlan/AggregatingStep.cpp
@@ -11,6 +11,7 @@
 #include <Processors/Merges/AggregatingSortedTransform.h>
 #include <Processors/Merges/FinishAggregatingInOrderTransform.h>
 #include <Interpreters/Aggregator.h>
+#include <Functions/FunctionFactory.h>
 #include <Processors/QueryPlan/IQueryPlanStep.h>
 #include <Columns/ColumnFixedString.h>
 #include <DataTypes/DataTypesNumber.h>
@@ -46,22 +47,32 @@ Block appendGroupingSetColumn(Block header)
     return res;
 }
 
-static Block appendGroupingColumn(Block block, const GroupingSetsParamsList & params)
+static inline void convertToNullable(Block & header, const Names & keys)
 {
-    if (params.empty())
-        return block;
+    for (const auto & key : keys)
+    {
+        auto & column = header.getByName(key);
 
-    Block res;
+        column.type = makeNullableSafe(column.type);
+        column.column = makeNullableSafe(column.column);
+    }
+}
 
-    size_t rows = block.rows();
-    auto column = ColumnUInt64::create(rows);
+Block generateOutputHeader(const Block & input_header, const Names & keys, bool use_nulls)
+{
+    auto header = appendGroupingSetColumn(input_header);
+    if (use_nulls)
+        convertToNullable(header, keys);
+    return header;
+}
 
-    res.insert({ColumnPtr(std::move(column)), std::make_shared<DataTypeUInt64>(), "__grouping_set"});
 
-    for (auto & col : block)
-        res.insert(std::move(col));
+static Block appendGroupingColumn(Block block, const Names & keys, const GroupingSetsParamsList & params, bool use_nulls)
+{
+    if (params.empty())
+        return block;
 
-    return res;
+    return generateOutputHeader(block, keys, use_nulls);
 }
 
 AggregatingStep::AggregatingStep(
@@ -74,11 +85,12 @@ AggregatingStep::AggregatingStep(
     size_t merge_threads_,
     size_t temporary_data_merge_threads_,
     bool storage_has_evenly_distributed_read_,
+    bool group_by_use_nulls_,
     InputOrderInfoPtr group_by_info_,
     SortDescription group_by_sort_description_,
     bool should_produce_results_in_order_of_bucket_number_)
     : ITransformingStep(
-        input_stream_, appendGroupingColumn(params_.getHeader(input_stream_.header, final_), grouping_sets_params_), getTraits(should_produce_results_in_order_of_bucket_number_), false)
+        input_stream_, appendGroupingColumn(params_.getHeader(input_stream_.header, final_), params_.keys, grouping_sets_params_, group_by_use_nulls_), getTraits(should_produce_results_in_order_of_bucket_number_), false)
     , params(std::move(params_))
     , grouping_sets_params(std::move(grouping_sets_params_))
     , final(final_)
@@ -87,6 +99,7 @@ AggregatingStep::AggregatingStep(
     , merge_threads(merge_threads_)
     , temporary_data_merge_threads(temporary_data_merge_threads_)
     , storage_has_evenly_distributed_read(storage_has_evenly_distributed_read_)
+    , group_by_use_nulls(group_by_use_nulls_)
     , group_by_info(std::move(group_by_info_))
     , group_by_sort_description(std::move(group_by_sort_description_))
     , should_produce_results_in_order_of_bucket_number(should_produce_results_in_order_of_bucket_number_)
@@ -217,6 +230,8 @@ void AggregatingStep::transformPipeline(QueryPipelineBuilder & pipeline, const B
 
             assert(ports.size() == grouping_sets_size);
             auto output_header = transform_params->getHeader();
+            if (group_by_use_nulls)
+                convertToNullable(output_header, params.keys);
 
             for (size_t set_counter = 0; set_counter < grouping_sets_size; ++set_counter)
             {
@@ -236,6 +251,7 @@ void AggregatingStep::transformPipeline(QueryPipelineBuilder & pipeline, const B
 
                 const auto & missing_columns = grouping_sets_params[set_counter].missing_keys;
 
+                auto to_nullable_function = FunctionFactory::instance().get("toNullable", nullptr);
                 for (size_t i = 0; i < output_header.columns(); ++i)
                 {
                     auto & col = output_header.getByPosition(i);
@@ -251,7 +267,13 @@ void AggregatingStep::transformPipeline(QueryPipelineBuilder & pipeline, const B
                         index.push_back(node);
                     }
                     else
-                        index.push_back(dag->getIndex()[header.getPositionByName(col.name)]);
+                    {
+                        const auto * column_node = dag->getIndex()[header.getPositionByName(col.name)];
+                        if (group_by_use_nulls && column_node->result_type->canBeInsideNullable())
+                            index.push_back(&dag->addFunction(to_nullable_function, { column_node }, col.name));
+                        else
+                            index.push_back(column_node);
+                    }
                 }
 
                 dag->getIndex().swap(index);
@@ -396,7 +418,7 @@ void AggregatingStep::updateOutputStream()
 {
     output_stream = createOutputStream(
         input_streams.front(),
-        appendGroupingColumn(params.getHeader(input_streams.front().header, final), grouping_sets_params),
+        appendGroupingColumn(params.getHeader(input_streams.front().header, final), params.keys, grouping_sets_params, group_by_use_nulls),
         getDataStreamTraits());
 }
 
diff --git a/src/Processors/QueryPlan/AggregatingStep.h b/src/Processors/QueryPlan/AggregatingStep.h
index 0e982d769404..71130b65adb8 100644
--- a/src/Processors/QueryPlan/AggregatingStep.h
+++ b/src/Processors/QueryPlan/AggregatingStep.h
@@ -20,6 +20,7 @@ struct GroupingSetsParams
 using GroupingSetsParamsList = std::vector<GroupingSetsParams>;
 
 Block appendGroupingSetColumn(Block header);
+Block generateOutputHeader(const Block & input_header, const Names & keys, bool use_nulls);
 
 /// Aggregation. See AggregatingTransform.
 class AggregatingStep : public ITransformingStep
@@ -35,6 +36,7 @@ class AggregatingStep : public ITransformingStep
         size_t merge_threads_,
         size_t temporary_data_merge_threads_,
         bool storage_has_evenly_distributed_read_,
+        bool group_by_use_nulls_,
         InputOrderInfoPtr group_by_info_,
         SortDescription group_by_sort_description_,
         bool should_produce_results_in_order_of_bucket_number_);
@@ -62,6 +64,7 @@ class AggregatingStep : public ITransformingStep
     size_t temporary_data_merge_threads;
 
     bool storage_has_evenly_distributed_read;
+    bool group_by_use_nulls;
 
     InputOrderInfoPtr group_by_info;
     SortDescription group_by_sort_description;
diff --git a/src/Processors/QueryPlan/CubeStep.cpp b/src/Processors/QueryPlan/CubeStep.cpp
index b0c57491085c..52539dec75fb 100644
--- a/src/Processors/QueryPlan/CubeStep.cpp
+++ b/src/Processors/QueryPlan/CubeStep.cpp
@@ -4,6 +4,7 @@
 #include <Processors/QueryPlan/AggregatingStep.h>
 #include <QueryPipeline/QueryPipelineBuilder.h>
 #include <DataTypes/DataTypesNumber.h>
+#include <Functions/FunctionFactory.h>
 
 namespace DB
 {
@@ -24,27 +25,41 @@ static ITransformingStep::Traits getTraits()
     };
 }
 
-CubeStep::CubeStep(const DataStream & input_stream_, Aggregator::Params params_, bool final_)
-    : ITransformingStep(input_stream_, appendGroupingSetColumn(params_.getHeader(input_stream_.header, final_)), getTraits())
+CubeStep::CubeStep(const DataStream & input_stream_, Aggregator::Params params_, bool final_, bool use_nulls_)
+    : ITransformingStep(input_stream_, generateOutputHeader(params_.getHeader(input_stream_.header, final_), params_.keys, use_nulls_), getTraits())
     , keys_size(params_.keys_size)
     , params(std::move(params_))
     , final(final_)
+    , use_nulls(use_nulls_)
 {
     /// Aggregation keys are distinct
     for (const auto & key : params.keys)
         output_stream->distinct_columns.insert(key);
 }
 
-ProcessorPtr addGroupingSetForTotals(const Block & header, const BuildQueryPipelineSettings & settings, UInt64 grouping_set_number)
+ProcessorPtr addGroupingSetForTotals(const Block & header, const Names & keys, bool use_nulls, const BuildQueryPipelineSettings & settings, UInt64 grouping_set_number)
 {
     auto dag = std::make_shared<ActionsDAG>(header.getColumnsWithTypeAndName());
+    auto & index = dag->getIndex();
+
+    if (use_nulls)
+    {
+        auto to_nullable = FunctionFactory::instance().get("toNullable", nullptr);
+        for (const auto & key : keys)
+        {
+            const auto * node = dag->getIndex()[header.getPositionByName(key)];
+            if (node->result_type->canBeInsideNullable())
+            {
+                dag->addOrReplaceInIndex(dag->addFunction(to_nullable, { node }, node->result_name));
+            }
+        }
+    }
 
     auto grouping_col = ColumnUInt64::create(1, grouping_set_number);
     const auto * grouping_node = &dag->addColumn(
         {ColumnPtr(std::move(grouping_col)), std::make_shared<DataTypeUInt64>(), "__grouping_set"});
 
     grouping_node = &dag->materializeNode(*grouping_node);
-    auto & index = dag->getIndex();
     index.insert(index.begin(), grouping_node);
 
     auto expression = std::make_shared<ExpressionActions>(dag, settings.getActionsSettings());
@@ -58,10 +73,10 @@ void CubeStep::transformPipeline(QueryPipelineBuilder & pipeline, const BuildQue
     pipeline.addSimpleTransform([&](const Block & header, QueryPipelineBuilder::StreamType stream_type) -> ProcessorPtr
     {
         if (stream_type == QueryPipelineBuilder::StreamType::Totals)
-            return addGroupingSetForTotals(header, settings, (UInt64(1) << keys_size) - 1);
+            return addGroupingSetForTotals(header, params.keys, use_nulls, settings, (UInt64(1) << keys_size) - 1);
 
         auto transform_params = std::make_shared<AggregatingTransformParams>(header, std::move(params), final);
-        return std::make_shared<CubeTransform>(header, std::move(transform_params));
+        return std::make_shared<CubeTransform>(header, std::move(transform_params), use_nulls);
     });
 }
 
@@ -73,7 +88,7 @@ const Aggregator::Params & CubeStep::getParams() const
 void CubeStep::updateOutputStream()
 {
     output_stream = createOutputStream(
-        input_streams.front(), appendGroupingSetColumn(params.getHeader(input_streams.front().header, final)), getDataStreamTraits());
+        input_streams.front(), generateOutputHeader(params.getHeader(input_streams.front().header, final), params.keys, use_nulls), getDataStreamTraits());
 
     /// Aggregation keys are distinct
     for (const auto & key : params.keys)
diff --git a/src/Processors/QueryPlan/CubeStep.h b/src/Processors/QueryPlan/CubeStep.h
index 87f22de7fc6b..8a03a33a0882 100644
--- a/src/Processors/QueryPlan/CubeStep.h
+++ b/src/Processors/QueryPlan/CubeStep.h
@@ -13,7 +13,7 @@ using AggregatingTransformParamsPtr = std::shared_ptr<AggregatingTransformParams
 class CubeStep : public ITransformingStep
 {
 public:
-    CubeStep(const DataStream & input_stream_, Aggregator::Params params_, bool final_);
+    CubeStep(const DataStream & input_stream_, Aggregator::Params params_, bool final_, bool use_nulls_);
 
     String getName() const override { return "Cube"; }
 
@@ -26,6 +26,7 @@ class CubeStep : public ITransformingStep
     size_t keys_size;
     Aggregator::Params params;
     bool final;
+    bool use_nulls;
 };
 
 }
diff --git a/src/Processors/QueryPlan/RollupStep.cpp b/src/Processors/QueryPlan/RollupStep.cpp
index 169976195eac..3305f24602fd 100644
--- a/src/Processors/QueryPlan/RollupStep.cpp
+++ b/src/Processors/QueryPlan/RollupStep.cpp
@@ -22,18 +22,19 @@ static ITransformingStep::Traits getTraits()
     };
 }
 
-RollupStep::RollupStep(const DataStream & input_stream_, Aggregator::Params params_, bool final_)
-    : ITransformingStep(input_stream_, appendGroupingSetColumn(params_.getHeader(input_stream_.header, final_)), getTraits())
+RollupStep::RollupStep(const DataStream & input_stream_, Aggregator::Params params_, bool final_, bool use_nulls_)
+    : ITransformingStep(input_stream_, generateOutputHeader(params_.getHeader(input_stream_.header, final_), params_.keys, use_nulls_), getTraits())
     , params(std::move(params_))
     , keys_size(params.keys_size)
     , final(final_)
+    , use_nulls(use_nulls_)
 {
     /// Aggregation keys are distinct
     for (const auto & key : params.keys)
         output_stream->distinct_columns.insert(key);
 }
 
-ProcessorPtr addGroupingSetForTotals(const Block & header, const BuildQueryPipelineSettings & settings, UInt64 grouping_set_number);
+ProcessorPtr addGroupingSetForTotals(const Block & header, const Names & keys, bool use_nulls, const BuildQueryPipelineSettings & settings, UInt64 grouping_set_number);
 
 void RollupStep::transformPipeline(QueryPipelineBuilder & pipeline, const BuildQueryPipelineSettings & settings)
 {
@@ -42,10 +43,10 @@ void RollupStep::transformPipeline(QueryPipelineBuilder & pipeline, const BuildQ
     pipeline.addSimpleTransform([&](const Block & header, QueryPipelineBuilder::StreamType stream_type) -> ProcessorPtr
     {
         if (stream_type == QueryPipelineBuilder::StreamType::Totals)
-            return addGroupingSetForTotals(header, settings, keys_size);
+            return addGroupingSetForTotals(header, params.keys, use_nulls, settings, keys_size);
 
         auto transform_params = std::make_shared<AggregatingTransformParams>(header, std::move(params), true);
-        return std::make_shared<RollupTransform>(header, std::move(transform_params));
+        return std::make_shared<RollupTransform>(header, std::move(transform_params), use_nulls);
     });
 }
 
diff --git a/src/Processors/QueryPlan/RollupStep.h b/src/Processors/QueryPlan/RollupStep.h
index c59bf9f3ee90..866de7178fa9 100644
--- a/src/Processors/QueryPlan/RollupStep.h
+++ b/src/Processors/QueryPlan/RollupStep.h
@@ -13,7 +13,7 @@ using AggregatingTransformParamsPtr = std::shared_ptr<AggregatingTransformParams
 class RollupStep : public ITransformingStep
 {
 public:
-    RollupStep(const DataStream & input_stream_, Aggregator::Params params_, bool final_);
+    RollupStep(const DataStream & input_stream_, Aggregator::Params params_, bool final_, bool use_nulls_);
 
     String getName() const override { return "Rollup"; }
 
@@ -25,6 +25,7 @@ class RollupStep : public ITransformingStep
     Aggregator::Params params;
     size_t keys_size;
     bool final;
+    bool use_nulls;
 };
 
 }
diff --git a/src/Processors/Transforms/CubeTransform.cpp b/src/Processors/Transforms/CubeTransform.cpp
index b80ca29327fc..669aaddd1df6 100644
--- a/src/Processors/Transforms/CubeTransform.cpp
+++ b/src/Processors/Transforms/CubeTransform.cpp
@@ -1,6 +1,7 @@
 #include <Processors/Transforms/CubeTransform.h>
 #include <Processors/Transforms/TotalsHavingTransform.h>
 #include <Processors/QueryPlan/AggregatingStep.h>
+#include "Processors/Transforms/RollupTransform.h"
 
 namespace DB
 {
@@ -9,61 +10,32 @@ namespace ErrorCodes
     extern const int LOGICAL_ERROR;
 }
 
-CubeTransform::CubeTransform(Block header, AggregatingTransformParamsPtr params_)
-    : IAccumulatingTransform(std::move(header), appendGroupingSetColumn(params_->getHeader()))
-    , params(std::move(params_))
+CubeTransform::CubeTransform(Block header, AggregatingTransformParamsPtr params_, bool use_nulls_)
+    : GroupByModifierTransform(std::move(header), params_, use_nulls_)
     , aggregates_mask(getAggregatesMask(params->getHeader(), params->params.aggregates))
 {
-    keys.reserve(params->params.keys_size);
-    for (const auto & key : params->params.keys)
-        keys.emplace_back(input.getHeader().getPositionByName(key));
-
     if (keys.size() >= 8 * sizeof(mask))
         throw Exception("Too many keys are used for CubeTransform.", ErrorCodes::LOGICAL_ERROR);
 }
 
-Chunk CubeTransform::merge(Chunks && chunks, bool final)
-{
-    BlocksList rollup_blocks;
-    for (auto & chunk : chunks)
-        rollup_blocks.emplace_back(getInputPort().getHeader().cloneWithColumns(chunk.detachColumns()));
-
-    auto rollup_block = params->aggregator.mergeBlocks(rollup_blocks, final);
-    auto num_rows = rollup_block.rows();
-    return Chunk(rollup_block.getColumns(), num_rows);
-}
-
-void CubeTransform::consume(Chunk chunk)
-{
-    consumed_chunks.emplace_back(std::move(chunk));
-}
-
-MutableColumnPtr getColumnWithDefaults(Block const & header, size_t key, size_t n);
-
 Chunk CubeTransform::generate()
 {
     if (!consumed_chunks.empty())
     {
-        if (consumed_chunks.size() > 1)
-            cube_chunk = merge(std::move(consumed_chunks), false);
-        else
-            cube_chunk = std::move(consumed_chunks.front());
-
-        consumed_chunks.clear();
+        mergeConsumed();
 
-        auto num_rows = cube_chunk.getNumRows();
+        auto num_rows = current_chunk.getNumRows();
         mask = (static_cast<UInt64>(1) << keys.size()) - 1;
 
-        current_columns = cube_chunk.getColumns();
+        current_columns = current_chunk.getColumns();
         current_zero_columns.clear();
         current_zero_columns.reserve(keys.size());
 
-        auto const & input_header = getInputPort().getHeader();
         for (auto key : keys)
-            current_zero_columns.emplace_back(getColumnWithDefaults(input_header, key, num_rows));
+            current_zero_columns.emplace_back(getColumnWithDefaults(key, num_rows));
     }
 
-    auto gen_chunk = std::move(cube_chunk);
+    auto gen_chunk = std::move(current_chunk);
 
     if (mask)
     {
@@ -78,7 +50,7 @@ Chunk CubeTransform::generate()
 
         Chunks chunks;
         chunks.emplace_back(std::move(columns), current_columns.front()->size());
-        cube_chunk = merge(std::move(chunks), false);
+        current_chunk = merge(std::move(chunks), !use_nulls, false);
     }
 
     finalizeChunk(gen_chunk, aggregates_mask);
diff --git a/src/Processors/Transforms/CubeTransform.h b/src/Processors/Transforms/CubeTransform.h
index bd33eabd7506..54a41e8f44e4 100644
--- a/src/Processors/Transforms/CubeTransform.h
+++ b/src/Processors/Transforms/CubeTransform.h
@@ -1,6 +1,7 @@
 #pragma once
 #include <Processors/IInflatingTransform.h>
 #include <Processors/Transforms/AggregatingTransform.h>
+#include <Processors/Transforms/RollupTransform.h>
 #include <Processors/Transforms/finalizeChunk.h>
 
 
@@ -9,30 +10,23 @@ namespace DB
 
 /// Takes blocks after grouping, with non-finalized aggregate functions.
 /// Calculates all subsets of columns and aggregates over them.
-class CubeTransform : public IAccumulatingTransform
+class CubeTransform : public GroupByModifierTransform
 {
 public:
-    CubeTransform(Block header, AggregatingTransformParamsPtr params);
+    CubeTransform(Block header, AggregatingTransformParamsPtr params, bool use_nulls_);
     String getName() const override { return "CubeTransform"; }
 
 protected:
-    void consume(Chunk chunk) override;
     Chunk generate() override;
 
 private:
-    AggregatingTransformParamsPtr params;
-    ColumnNumbers keys;
     const ColumnsMask aggregates_mask;
 
-    Chunks consumed_chunks;
-    Chunk cube_chunk;
     Columns current_columns;
     Columns current_zero_columns;
 
     UInt64 mask = 0;
     UInt64 grouping_set = 0;
-
-    Chunk merge(Chunks && chunks, bool final);
 };
 
 }
diff --git a/src/Processors/Transforms/RollupTransform.cpp b/src/Processors/Transforms/RollupTransform.cpp
index e5351d1d5e21..a5d67fb2f157 100644
--- a/src/Processors/Transforms/RollupTransform.cpp
+++ b/src/Processors/Transforms/RollupTransform.cpp
@@ -1,36 +1,80 @@
 #include <Processors/Transforms/RollupTransform.h>
 #include <Processors/Transforms/TotalsHavingTransform.h>
 #include <Processors/QueryPlan/AggregatingStep.h>
+#include <Columns/ColumnNullable.h>
 
 namespace DB
 {
 
-RollupTransform::RollupTransform(Block header, AggregatingTransformParamsPtr params_)
-    : IAccumulatingTransform(std::move(header), appendGroupingSetColumn(params_->getHeader()))
+GroupByModifierTransform::GroupByModifierTransform(Block header, AggregatingTransformParamsPtr params_, bool use_nulls_)
+    : IAccumulatingTransform(std::move(header), generateOutputHeader(params_->getHeader(), params_->params.keys, use_nulls_))
     , params(std::move(params_))
-    , aggregates_mask(getAggregatesMask(params->getHeader(), params->params.aggregates))
+    , use_nulls(use_nulls_)
 {
     keys.reserve(params->params.keys_size);
     for (const auto & key : params->params.keys)
         keys.emplace_back(input.getHeader().getPositionByName(key));
+
+    intermediate_header = getOutputPort().getHeader();
+    intermediate_header.erase(0);
+
+    if (use_nulls)
+    {
+        auto output_aggregator_params = params->params;
+        output_aggregator = std::make_unique<Aggregator>(intermediate_header, output_aggregator_params);
+    }
 }
 
-void RollupTransform::consume(Chunk chunk)
+void GroupByModifierTransform::consume(Chunk chunk)
 {
     consumed_chunks.emplace_back(std::move(chunk));
 }
 
-Chunk RollupTransform::merge(Chunks && chunks, bool final)
+void GroupByModifierTransform::mergeConsumed()
+{
+    if (consumed_chunks.size() > 1)
+        current_chunk = merge(std::move(consumed_chunks), true, false);
+    else
+        current_chunk = std::move(consumed_chunks.front());
+
+    size_t rows = current_chunk.getNumRows();
+    auto columns = current_chunk.getColumns();
+    if (use_nulls)
+    {
+        for (auto key : keys)
+            columns[key] = makeNullableSafe(columns[key]);
+    }
+    current_chunk = Chunk{ columns, rows };
+
+    consumed_chunks.clear();
+}
+
+Chunk GroupByModifierTransform::merge(Chunks && chunks, bool is_input, bool final)
 {
-    BlocksList rollup_blocks;
+    auto header = is_input ? getInputPort().getHeader() : intermediate_header;
+
+    BlocksList blocks;
     for (auto & chunk : chunks)
-        rollup_blocks.emplace_back(getInputPort().getHeader().cloneWithColumns(chunk.detachColumns()));
+        blocks.emplace_back(header.cloneWithColumns(chunk.detachColumns()));
 
-    auto rollup_block = params->aggregator.mergeBlocks(rollup_blocks, final);
-    auto num_rows = rollup_block.rows();
-    return Chunk(rollup_block.getColumns(), num_rows);
+    auto current_block = is_input ? params->aggregator.mergeBlocks(blocks, final) : output_aggregator->mergeBlocks(blocks, final);
+    auto num_rows = current_block.rows();
+    return Chunk(current_block.getColumns(), num_rows);
 }
 
+MutableColumnPtr GroupByModifierTransform::getColumnWithDefaults(size_t key, size_t n) const
+{
+    auto const & col = intermediate_header.getByPosition(key);
+    auto result_column = col.column->cloneEmpty();
+    col.type->insertManyDefaultsInto(*result_column, n);
+    return result_column;
+}
+
+RollupTransform::RollupTransform(Block header, AggregatingTransformParamsPtr params_, bool use_nulls_)
+    : GroupByModifierTransform(std::move(header), params_, use_nulls_)
+    , aggregates_mask(getAggregatesMask(params->getHeader(), params->params.aggregates))
+{}
+
 MutableColumnPtr getColumnWithDefaults(Block const & header, size_t key, size_t n)
 {
     auto const & col = header.getByPosition(key);
@@ -43,16 +87,11 @@ Chunk RollupTransform::generate()
 {
     if (!consumed_chunks.empty())
     {
-        if (consumed_chunks.size() > 1)
-            rollup_chunk = merge(std::move(consumed_chunks), false);
-        else
-            rollup_chunk = std::move(consumed_chunks.front());
-
-        consumed_chunks.clear();
+        mergeConsumed();
         last_removed_key = keys.size();
     }
 
-    auto gen_chunk = std::move(rollup_chunk);
+    auto gen_chunk = std::move(current_chunk);
 
     if (last_removed_key)
     {
@@ -61,11 +100,11 @@ Chunk RollupTransform::generate()
 
         auto num_rows = gen_chunk.getNumRows();
         auto columns = gen_chunk.getColumns();
-        columns[key] = getColumnWithDefaults(getInputPort().getHeader(), key, num_rows);
+        columns[key] = getColumnWithDefaults(key, num_rows);
 
         Chunks chunks;
         chunks.emplace_back(std::move(columns), num_rows);
-        rollup_chunk = merge(std::move(chunks), false);
+        current_chunk = merge(std::move(chunks), !use_nulls, false);
     }
 
     finalizeChunk(gen_chunk, aggregates_mask);
diff --git a/src/Processors/Transforms/RollupTransform.h b/src/Processors/Transforms/RollupTransform.h
index 1630df235798..e9fa0818779a 100644
--- a/src/Processors/Transforms/RollupTransform.h
+++ b/src/Processors/Transforms/RollupTransform.h
@@ -1,4 +1,6 @@
 #pragma once
+#include <memory>
+#include <Core/ColumnNumbers.h>
 #include <Processors/IAccumulatingTransform.h>
 #include <Processors/Transforms/AggregatingTransform.h>
 #include <Processors/Transforms/finalizeChunk.h>
@@ -6,29 +8,49 @@
 namespace DB
 {
 
+struct GroupByModifierTransform : public IAccumulatingTransform
+{
+    GroupByModifierTransform(Block header, AggregatingTransformParamsPtr params_, bool use_nulls_);
+
+protected:
+    void consume(Chunk chunk) override;
+
+    void mergeConsumed();
+
+    Chunk merge(Chunks && chunks, bool is_input, bool final);
+
+    MutableColumnPtr getColumnWithDefaults(size_t key, size_t n) const;
+
+    AggregatingTransformParamsPtr params;
+
+    bool use_nulls;
+
+    ColumnNumbers keys;
+
+    std::unique_ptr<Aggregator> output_aggregator;
+
+    Block intermediate_header;
+
+    Chunks consumed_chunks;
+    Chunk current_chunk;
+};
+
 /// Takes blocks after grouping, with non-finalized aggregate functions.
 /// Calculates subtotals and grand totals values for a set of columns.
-class RollupTransform : public IAccumulatingTransform
+class RollupTransform : public GroupByModifierTransform
 {
 public:
-    RollupTransform(Block header, AggregatingTransformParamsPtr params);
+    RollupTransform(Block header, AggregatingTransformParamsPtr params, bool use_nulls_);
     String getName() const override { return "RollupTransform"; }
 
 protected:
-    void consume(Chunk chunk) override;
     Chunk generate() override;
 
 private:
-    AggregatingTransformParamsPtr params;
-    ColumnNumbers keys;
     const ColumnsMask aggregates_mask;
 
-    Chunks consumed_chunks;
-    Chunk rollup_chunk;
     size_t last_removed_key = 0;
     size_t set_counter = 0;
-
-    Chunk merge(Chunks && chunks, bool final);
 };
 
 }
diff --git a/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp b/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp
index d9fc8ccaf42b..3916eae1556e 100644
--- a/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp
+++ b/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp
@@ -383,6 +383,7 @@ QueryPlanPtr MergeTreeDataSelectExecutor::read(
                     merge_threads,
                     temporary_data_merge_threads,
                     /* storage_has_evenly_distributed_read_= */ false,
+                    /* group_by_use_nulls */ false,
                     std::move(group_by_info),
                     std::move(group_by_sort_description),
                     should_produce_results_in_order_of_bucket_number);
