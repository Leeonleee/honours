{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 60434,
  "instance_id": "ClickHouse__ClickHouse-60434",
  "issue_numbers": [
    "59622"
  ],
  "base_commit": "f8ff15a023fcfc8dc85b75658901c30a77a9d5a6",
  "patch": "diff --git a/src/AggregateFunctions/AggregateFunctionCount.h b/src/AggregateFunctions/AggregateFunctionCount.h\nindex 36a8617ba91a..f5d6030a7770 100644\n--- a/src/AggregateFunctions/AggregateFunctionCount.h\n+++ b/src/AggregateFunctions/AggregateFunctionCount.h\n@@ -219,7 +219,7 @@ class AggregateFunctionCountNotNullUnary final\n         : IAggregateFunctionDataHelper<AggregateFunctionCountData, AggregateFunctionCountNotNullUnary>({argument}, params, createResultType())\n     {\n         if (!argument->isNullable())\n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: not Nullable data type passed to AggregateFunctionCountNotNullUnary\");\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Not Nullable data type passed to AggregateFunctionCountNotNullUnary\");\n     }\n \n     String getName() const override { return \"count\"; }\ndiff --git a/src/AggregateFunctions/AggregateFunctionFactory.cpp b/src/AggregateFunctions/AggregateFunctionFactory.cpp\nindex b6ba562045d7..18edb7c8ce0d 100644\n--- a/src/AggregateFunctions/AggregateFunctionFactory.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionFactory.cpp\n@@ -100,7 +100,7 @@ AggregateFunctionPtr AggregateFunctionFactory::get(\n     {\n         AggregateFunctionCombinatorPtr combinator = AggregateFunctionCombinatorFactory::instance().tryFindSuffix(\"Null\");\n         if (!combinator)\n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: cannot find aggregate function combinator \"\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Cannot find aggregate function combinator \"\n                             \"to apply a function to Nullable arguments.\");\n \n         DataTypes nested_types = combinator->transformArguments(types_without_low_cardinality);\n@@ -123,7 +123,7 @@ AggregateFunctionPtr AggregateFunctionFactory::get(\n     auto with_original_arguments = getImpl(name, action, types_without_low_cardinality, parameters, out_properties, false);\n \n     if (!with_original_arguments)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: AggregateFunctionFactory returned nullptr\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"AggregateFunctionFactory returned nullptr\");\n     return with_original_arguments;\n }\n \ndiff --git a/src/AggregateFunctions/Combinators/AggregateFunctionIf.cpp b/src/AggregateFunctions/Combinators/AggregateFunctionIf.cpp\nindex 20a4bde6bb40..9b5ee79a5330 100644\n--- a/src/AggregateFunctions/Combinators/AggregateFunctionIf.cpp\n+++ b/src/AggregateFunctions/Combinators/AggregateFunctionIf.cpp\n@@ -249,7 +249,7 @@ class AggregateFunctionIfNullVariadic final : public AggregateFunctionNullBase<\n         : Base(std::move(nested_function_), arguments, params), number_of_arguments(arguments.size())\n     {\n         if (number_of_arguments == 1)\n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: single argument is passed to AggregateFunctionIfNullVariadic\");\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Single argument is passed to AggregateFunctionIfNullVariadic\");\n \n         if (number_of_arguments > MAX_ARGS)\n             throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH,\ndiff --git a/src/AggregateFunctions/Combinators/AggregateFunctionNull.h b/src/AggregateFunctions/Combinators/AggregateFunctionNull.h\nindex 6b6580bf4c4a..c8574e82be5b 100644\n--- a/src/AggregateFunctions/Combinators/AggregateFunctionNull.h\n+++ b/src/AggregateFunctions/Combinators/AggregateFunctionNull.h\n@@ -429,7 +429,7 @@ class AggregateFunctionNullVariadic final : public AggregateFunctionNullBase<\n         , number_of_arguments(arguments.size())\n     {\n         if (number_of_arguments == 1)\n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: single argument is passed to AggregateFunctionNullVariadic\");\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Single argument is passed to AggregateFunctionNullVariadic\");\n \n         if (number_of_arguments > MAX_ARGS)\n             throw Exception(ErrorCodes::NUMBER_OF_ARGUMENTS_DOESNT_MATCH,\ndiff --git a/src/Client/ConnectionEstablisher.h b/src/Client/ConnectionEstablisher.h\nindex 1fa08d435e94..a3a01e63246d 100644\n--- a/src/Client/ConnectionEstablisher.h\n+++ b/src/Client/ConnectionEstablisher.h\n@@ -3,7 +3,6 @@\n #include <Common/AsyncTaskExecutor.h>\n #include <Common/Epoll.h>\n #include <Common/Fiber.h>\n-#include <Common/FiberStack.h>\n #include <Common/TimerDescriptor.h>\n #include <Common/PoolWithFailoverBase.h>\n #include <Client/ConnectionPool.h>\ndiff --git a/src/Client/MultiplexedConnections.cpp b/src/Client/MultiplexedConnections.cpp\nindex c7d7d0143c85..8433c8afe9f1 100644\n--- a/src/Client/MultiplexedConnections.cpp\n+++ b/src/Client/MultiplexedConnections.cpp\n@@ -320,7 +320,7 @@ Packet MultiplexedConnections::receivePacketUnlocked(AsyncCallback async_callbac\n     ReplicaState & state = getReplicaForReading();\n     current_connection = state.connection;\n     if (current_connection == nullptr)\n-        throw Exception(ErrorCodes::NO_AVAILABLE_REPLICA, \"Logical error: no available replica\");\n+        throw Exception(ErrorCodes::NO_AVAILABLE_REPLICA, \"No available replica\");\n \n     Packet packet;\n     try\ndiff --git a/src/Client/PacketReceiver.h b/src/Client/PacketReceiver.h\nindex deedf5cccdc7..6b3da6592903 100644\n--- a/src/Client/PacketReceiver.h\n+++ b/src/Client/PacketReceiver.h\n@@ -5,7 +5,6 @@\n #include <variant>\n \n #include <Client/IConnections.h>\n-#include <Common/FiberStack.h>\n #include <Common/Fiber.h>\n #include <Common/Epoll.h>\n #include <Common/TimerDescriptor.h>\ndiff --git a/src/Columns/ColumnArray.cpp b/src/Columns/ColumnArray.cpp\nindex 6f60ec0e6428..b3376b35b2e7 100644\n--- a/src/Columns/ColumnArray.cpp\n+++ b/src/Columns/ColumnArray.cpp\n@@ -810,7 +810,7 @@ ColumnPtr ColumnArray::filterTuple(const Filter & filt, ssize_t result_size_hint\n     size_t tuple_size = tuple.tupleSize();\n \n     if (tuple_size == 0)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: empty tuple\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Empty tuple\");\n \n     Columns temporary_arrays(tuple_size);\n     for (size_t i = 0; i < tuple_size; ++i)\n@@ -1263,7 +1263,7 @@ ColumnPtr ColumnArray::replicateTuple(const Offsets & replicate_offsets) const\n     size_t tuple_size = tuple.tupleSize();\n \n     if (tuple_size == 0)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: empty tuple\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Empty tuple\");\n \n     Columns temporary_arrays(tuple_size);\n     for (size_t i = 0; i < tuple_size; ++i)\ndiff --git a/src/Columns/ColumnNullable.cpp b/src/Columns/ColumnNullable.cpp\nindex 93638371b845..ddf5fc696fbf 100644\n--- a/src/Columns/ColumnNullable.cpp\n+++ b/src/Columns/ColumnNullable.cpp\n@@ -1,7 +1,5 @@\n #include <Common/Arena.h>\n #include <Common/SipHash.h>\n-#include <Common/NaNUtils.h>\n-#include <Common/typeid_cast.h>\n #include <Common/assert_cast.h>\n #include <Common/WeakHash.h>\n #include <Columns/ColumnDecimal.h>\n@@ -28,7 +26,6 @@ namespace ErrorCodes\n {\n     extern const int LOGICAL_ERROR;\n     extern const int ILLEGAL_COLUMN;\n-    extern const int SIZES_OF_NESTED_COLUMNS_ARE_INCONSISTENT;\n     extern const int NOT_IMPLEMENTED;\n }\n \n@@ -829,8 +826,7 @@ void ColumnNullable::applyNullMap(const ColumnNullable & other)\n void ColumnNullable::checkConsistency() const\n {\n     if (null_map->size() != getNestedColumn().size())\n-        throw Exception(ErrorCodes::SIZES_OF_NESTED_COLUMNS_ARE_INCONSISTENT,\n-                        \"Logical error: Sizes of nested column and null map of Nullable column are not equal\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Sizes of nested column and null map of Nullable column are not equal\");\n }\n \n ColumnPtr ColumnNullable::createWithOffsets(const IColumn::Offsets & offsets, const ColumnConst & column_with_default_value, size_t total_rows, size_t shift) const\ndiff --git a/src/Columns/getLeastSuperColumn.cpp b/src/Columns/getLeastSuperColumn.cpp\nindex 6ec5ca7a9c10..4f4a5f2b9b89 100644\n--- a/src/Columns/getLeastSuperColumn.cpp\n+++ b/src/Columns/getLeastSuperColumn.cpp\n@@ -21,7 +21,7 @@ static bool sameConstants(const IColumn & a, const IColumn & b)\n ColumnWithTypeAndName getLeastSuperColumn(const std::vector<const ColumnWithTypeAndName *> & columns)\n {\n     if (columns.empty())\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: no src columns for supercolumn\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"No src columns for supercolumn\");\n \n     ColumnWithTypeAndName result = *columns[0];\n \ndiff --git a/src/Common/Fiber.h b/src/Common/Fiber.h\nindex f48ace149f49..8b88bd323ef6 100644\n--- a/src/Common/Fiber.h\n+++ b/src/Common/Fiber.h\n@@ -17,7 +17,7 @@ class Fiber\n     template <typename T> friend class FiberLocal;\n \n public:\n-    template< typename StackAlloc, typename Fn>\n+    template <typename StackAlloc, typename Fn>\n     Fiber(StackAlloc && salloc, Fn && fn) : impl(std::allocator_arg_t(), std::forward<StackAlloc>(salloc), RoutineImpl(std::forward<Fn>(fn)))\n     {\n     }\n@@ -46,6 +46,12 @@ class Fiber\n         current_fiber = parent_fiber;\n     }\n \n+    static FiberPtr & getCurrentFiber()\n+    {\n+        thread_local static FiberPtr current_fiber;\n+        return current_fiber;\n+    }\n+\n private:\n     template <typename Fn>\n     struct RoutineImpl\n@@ -74,12 +80,6 @@ class Fiber\n         Fn fn;\n     };\n \n-    static FiberPtr & getCurrentFiber()\n-    {\n-        thread_local static FiberPtr current_fiber;\n-        return current_fiber;\n-    }\n-\n     /// Special wrapper to store data in uniquer_ptr.\n     struct DataWrapper\n     {\n@@ -146,4 +146,3 @@ class FiberLocal\n \n     T main_instance;\n };\n-\ndiff --git a/src/Common/SensitiveDataMasker.cpp b/src/Common/SensitiveDataMasker.cpp\nindex 70346919f65b..28eae6f451df 100644\n--- a/src/Common/SensitiveDataMasker.cpp\n+++ b/src/Common/SensitiveDataMasker.cpp\n@@ -91,7 +91,7 @@ void SensitiveDataMasker::setInstance(std::unique_ptr<SensitiveDataMasker>&& sen\n {\n \n     if (!sensitive_data_masker_)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: the 'sensitive_data_masker' is not set\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"The 'sensitive_data_masker' is not set\");\n \n     if (sensitive_data_masker_->rulesCount() > 0)\n     {\ndiff --git a/src/Common/SipHash.h b/src/Common/SipHash.h\nindex 5f27fdaa4b69..729fb76a573d 100644\n--- a/src/Common/SipHash.h\n+++ b/src/Common/SipHash.h\n@@ -209,7 +209,7 @@ class SipHash\n     {\n         if (!is_reference_128)\n             throw DB::Exception(\n-                DB::ErrorCodes::LOGICAL_ERROR, \"Logical error: can't call get128Reference when is_reference_128 is not set\");\n+                DB::ErrorCodes::LOGICAL_ERROR, \"Can't call get128Reference when is_reference_128 is not set\");\n         finalize();\n         const auto lo = v0 ^ v1 ^ v2 ^ v3;\n         v1 ^= 0xdd;\ndiff --git a/src/Common/StackTrace.cpp b/src/Common/StackTrace.cpp\nindex 7e683ae91de8..436b85ff30ba 100644\n--- a/src/Common/StackTrace.cpp\n+++ b/src/Common/StackTrace.cpp\n@@ -448,9 +448,6 @@ toStringEveryLineImpl([[maybe_unused]] bool fatal, const StackTraceRefTriple & s\n             DB::writePointerHex(frame.physical_addr, out);\n         }\n \n-        if (frame.object.has_value())\n-            out << \" in \" << *frame.object;\n-\n         callback(out.str());\n     };\n #else\ndiff --git a/src/Common/checkStackSize.cpp b/src/Common/checkStackSize.cpp\nindex 8c2a0aaed7f3..c88554ca8fee 100644\n--- a/src/Common/checkStackSize.cpp\n+++ b/src/Common/checkStackSize.cpp\n@@ -1,8 +1,8 @@\n-#include <Common/checkStackSize.h>\n-#include <Common/Exception.h>\n #include <base/getThreadId.h>\n-#include <base/scope_guard.h>\n #include <base/defines.h> /// THREAD_SANITIZER\n+#include <Common/checkStackSize.h>\n+#include <Common/Exception.h>\n+#include <Common/Fiber.h>\n #include <sys/resource.h>\n #include <pthread.h>\n #include <unistd.h>\n@@ -114,6 +114,10 @@ __attribute__((__weak__)) void checkStackSize()\n {\n     using namespace DB;\n \n+    /// Not implemented for coroutines.\n+    if (Fiber::getCurrentFiber())\n+        return;\n+\n     if (!stack_address)\n         max_stack_size = getStackSize(&stack_address);\n \n@@ -136,7 +140,7 @@ __attribute__((__weak__)) void checkStackSize()\n \n     /// We assume that stack grows towards lower addresses. And that it starts to grow from the end of a chunk of memory of max_stack_size.\n     if (int_frame_address > int_stack_address + max_stack_size)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: frame address is greater than stack begin address\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Frame address is greater than stack begin address\");\n \n     size_t stack_size = int_stack_address + max_stack_size - int_frame_address;\n     size_t max_stack_size_allowed = static_cast<size_t>(max_stack_size * STACK_SIZE_FREE_RATIO);\ndiff --git a/src/Coordination/KeeperStorage.cpp b/src/Coordination/KeeperStorage.cpp\nindex edd6743949de..a5e062a5aa66 100644\n--- a/src/Coordination/KeeperStorage.cpp\n+++ b/src/Coordination/KeeperStorage.cpp\n@@ -1614,7 +1614,7 @@ struct KeeperStorageListRequestProcessor final : public KeeperStorageRequestProc\n         {\n             auto path_prefix = request.path;\n             if (path_prefix.empty())\n-                throw DB::Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: path cannot be empty\");\n+                throw DB::Exception(ErrorCodes::LOGICAL_ERROR, \"Path cannot be empty\");\n \n             const auto & children = node_it->value.getChildren();\n             response.names.reserve(children.size());\ndiff --git a/src/Core/MySQL/PacketEndpoint.cpp b/src/Core/MySQL/PacketEndpoint.cpp\nindex 97b5d3b4d118..085d75951670 100644\n--- a/src/Core/MySQL/PacketEndpoint.cpp\n+++ b/src/Core/MySQL/PacketEndpoint.cpp\n@@ -40,7 +40,7 @@ bool PacketEndpoint::tryReceivePacket(IMySQLReadPacket & packet, UInt64 millisec\n         ReadBufferFromPocoSocket * socket_in = typeid_cast<ReadBufferFromPocoSocket *>(in);\n \n         if (!socket_in)\n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"LOGICAL ERROR: Attempt to pull the duration in a non socket stream\");\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Attempt to pull the duration in a non socket stream\");\n \n         if (!socket_in->poll(millisecond * 1000))\n             return false;\ndiff --git a/src/DataTypes/DataTypeAggregateFunction.cpp b/src/DataTypes/DataTypeAggregateFunction.cpp\nindex 7dc036cafa4a..14a3c6a4248e 100644\n--- a/src/DataTypes/DataTypeAggregateFunction.cpp\n+++ b/src/DataTypes/DataTypeAggregateFunction.cpp\n@@ -239,7 +239,7 @@ static DataTypePtr create(const ASTPtr & arguments)\n         argument_types.push_back(DataTypeFactory::instance().get(arguments->children[i]));\n \n     if (function_name.empty())\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: empty name of aggregate function passed\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Empty name of aggregate function passed\");\n \n     AggregateFunctionProperties properties;\n     AggregateFunctionPtr function = AggregateFunctionFactory::instance().get(function_name, action, argument_types, params_row, properties);\ndiff --git a/src/DataTypes/DataTypeCustomSimpleAggregateFunction.cpp b/src/DataTypes/DataTypeCustomSimpleAggregateFunction.cpp\nindex aa3b154e49be..ee9870eb0efd 100644\n--- a/src/DataTypes/DataTypeCustomSimpleAggregateFunction.cpp\n+++ b/src/DataTypes/DataTypeCustomSimpleAggregateFunction.cpp\n@@ -141,7 +141,7 @@ static std::pair<DataTypePtr, DataTypeCustomDescPtr> create(const ASTPtr & argum\n         argument_types.push_back(DataTypeFactory::instance().get(arguments->children[i]));\n \n     if (function_name.empty())\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: empty name of aggregate function passed\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Empty name of aggregate function passed\");\n \n     AggregateFunctionProperties properties;\n     /// NullsAction is not part of the type definition, instead it will have transformed the function into a different one\ndiff --git a/src/Databases/MySQL/MaterializedMySQLSyncThread.cpp b/src/Databases/MySQL/MaterializedMySQLSyncThread.cpp\nindex 2656835f912a..20db80369423 100644\n--- a/src/Databases/MySQL/MaterializedMySQLSyncThread.cpp\n+++ b/src/Databases/MySQL/MaterializedMySQLSyncThread.cpp\n@@ -779,7 +779,7 @@ static void writeFieldsToColumn(\n                         casted_int32_column->insertValue(num & 0x800000 ? num | 0xFF000000 : num);\n                     }\n                     else\n-                        throw Exception(ErrorCodes::LOGICAL_ERROR, \"LOGICAL ERROR: it is a bug.\");\n+                        throw Exception(ErrorCodes::LOGICAL_ERROR, \"MaterializedMySQL is a bug.\");\n                 }\n             }\n         }\n@@ -844,7 +844,7 @@ static inline bool differenceSortingKeys(const Tuple & row_old_data, const Tuple\n static inline size_t onUpdateData(const Row & rows_data, Block & buffer, size_t version, const std::vector<size_t> & sorting_columns_index)\n {\n     if (rows_data.size() % 2 != 0)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"LOGICAL ERROR: It is a bug.\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"MaterializedMySQL is a bug.\");\n \n     size_t prev_bytes = buffer.bytes();\n     std::vector<bool> writeable_rows_mask(rows_data.size());\ndiff --git a/src/Functions/EmptyImpl.h b/src/Functions/EmptyImpl.h\nindex 52484524e6ab..d3b2dda024bd 100644\n--- a/src/Functions/EmptyImpl.h\n+++ b/src/Functions/EmptyImpl.h\n@@ -35,7 +35,7 @@ struct EmptyImpl\n     /// Only make sense if is_fixed_to_constant.\n     static void vectorFixedToConstant(const ColumnString::Chars & /*data*/, size_t /*n*/, UInt8 & /*res*/)\n     {\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: 'vectorFixedToConstant method' is called\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"'vectorFixedToConstant method' is called\");\n     }\n \n     static void vectorFixedToVector(const ColumnString::Chars & data, size_t n, PaddedPODArray<UInt8> & res)\ndiff --git a/src/Functions/FunctionsComparison.h b/src/Functions/FunctionsComparison.h\nindex d04f76d051ae..3be675f39b39 100644\n--- a/src/Functions/FunctionsComparison.h\n+++ b/src/Functions/FunctionsComparison.h\n@@ -811,7 +811,7 @@ class FunctionComparison : public IFunction\n                 c0_const_size = c0_const_fixed_string->getN();\n             }\n             else\n-                throw Exception(ErrorCodes::ILLEGAL_COLUMN, \"Logical error: ColumnConst contains not String nor FixedString column\");\n+                throw Exception(ErrorCodes::ILLEGAL_COLUMN, \"ColumnConst contains not String nor FixedString column\");\n         }\n \n         if (c1_const)\n@@ -830,7 +830,7 @@ class FunctionComparison : public IFunction\n                 c1_const_size = c1_const_fixed_string->getN();\n             }\n             else\n-                throw Exception(ErrorCodes::ILLEGAL_COLUMN, \"Logical error: ColumnConst contains not String nor FixedString column\");\n+                throw Exception(ErrorCodes::ILLEGAL_COLUMN, \"ColumnConst contains not String nor FixedString column\");\n         }\n \n         using StringImpl = StringComparisonImpl<Op<int, int>>;\n@@ -1114,7 +1114,7 @@ class FunctionComparison : public IFunction\n         /// This is a paranoid check to protect from a broken query analysis.\n         if (c0->isNullable() != c1->isNullable())\n             throw Exception(ErrorCodes::LOGICAL_ERROR,\n-                \"Logical error: columns are assumed to be of identical types, but they are different in Nullable\");\n+                \"Columns are assumed to be of identical types, but they are different in Nullable\");\n \n         if (c0_const && c1_const)\n         {\ndiff --git a/src/Functions/FunctionsConversion.h b/src/Functions/FunctionsConversion.h\nindex 4089a5b542b2..62148fa80223 100644\n--- a/src/Functions/FunctionsConversion.h\n+++ b/src/Functions/FunctionsConversion.h\n@@ -2560,7 +2560,7 @@ class FunctionConvertFromString : public IFunction\n             if constexpr (std::is_same_v<ToDataType, DataTypeDateTime>)\n                 res = std::make_shared<DataTypeDateTime>(extractTimeZoneNameFromFunctionArguments(arguments, 1, 0, false));\n             else if constexpr (std::is_same_v<ToDataType, DataTypeDateTime64>)\n-                throw Exception(ErrorCodes::LOGICAL_ERROR, \"LOGICAL ERROR: It is a bug.\");\n+                throw Exception(ErrorCodes::LOGICAL_ERROR, \"MaterializedMySQL is a bug.\");\n             else if constexpr (to_decimal)\n             {\n                 UInt64 scale = extractToDecimalScale(arguments[1]);\ndiff --git a/src/Functions/FunctionsLogical.cpp b/src/Functions/FunctionsLogical.cpp\nindex d0795941e1f8..7e7ae76d6eb8 100644\n--- a/src/Functions/FunctionsLogical.cpp\n+++ b/src/Functions/FunctionsLogical.cpp\n@@ -531,7 +531,7 @@ DataTypePtr FunctionAnyArityLogical<Impl, Name>::getReturnTypeImpl(const DataTyp\n         {\n             has_nullable_arguments = arg_type->isNullable();\n             if (has_nullable_arguments && !Impl::specialImplementationForNulls())\n-                throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: Unexpected type of argument for function \\\"{}\\\": \"\n+                throw Exception(ErrorCodes::LOGICAL_ERROR, \"Unexpected type of argument for function \\\"{}\\\": \"\n                     \" argument {} is of type {}\", getName(), i + 1, arg_type->getName());\n         }\n \ndiff --git a/src/Functions/trap.cpp b/src/Functions/trap.cpp\nindex 99430f039a4f..6ce696fedb54 100644\n--- a/src/Functions/trap.cpp\n+++ b/src/Functions/trap.cpp\n@@ -177,7 +177,7 @@ class FunctionTrap : public IFunction\n             }\n             else if (mode == \"logical error\")\n             {\n-                throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: trap\");\n+                throw Exception(ErrorCodes::LOGICAL_ERROR, \"Trap\");\n             }\n             else\n                 throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Unknown trap mode\");\ndiff --git a/src/Interpreters/Aggregator.cpp b/src/Interpreters/Aggregator.cpp\nindex 331cd991ea19..50fab4865688 100644\n--- a/src/Interpreters/Aggregator.cpp\n+++ b/src/Interpreters/Aggregator.cpp\n@@ -624,7 +624,7 @@ Aggregator::Aggregator(const Block & header_, const Params & params_)\n         {\n             size_t alignment_of_next_state = params.aggregates[i + 1].function->alignOfData();\n             if ((alignment_of_next_state & (alignment_of_next_state - 1)) != 0)\n-                throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: alignOfData is not 2^N\");\n+                throw Exception(ErrorCodes::LOGICAL_ERROR, \"`alignOfData` is not 2^N\");\n \n             /// Extend total_size to next alignment requirement\n             /// Add padding by rounding up 'total_size_of_aggregate_states' to be a multiplier of alignment_of_next_state.\n@@ -857,7 +857,7 @@ AggregatedDataVariants::Type Aggregator::chooseAggregationMethod()\n                 return AggregatedDataVariants::Type::low_cardinality_keys128;\n             if (size_of_field == 32)\n                 return AggregatedDataVariants::Type::low_cardinality_keys256;\n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: low cardinality numeric column has sizeOfField not in 1, 2, 4, 8, 16, 32.\");\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"LowCardinality numeric column has sizeOfField not in 1, 2, 4, 8, 16, 32.\");\n         }\n \n         if (size_of_field == 1)\n@@ -872,7 +872,7 @@ AggregatedDataVariants::Type Aggregator::chooseAggregationMethod()\n             return AggregatedDataVariants::Type::keys128;\n         if (size_of_field == 32)\n             return AggregatedDataVariants::Type::keys256;\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: numeric column has sizeOfField not in 1, 2, 4, 8, 16, 32.\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Numeric column has sizeOfField not in 1, 2, 4, 8, 16, 32.\");\n     }\n \n     if (params.keys_size == 1 && isFixedString(types_removed_nullable[0]))\ndiff --git a/src/Interpreters/ArrayJoinedColumnsVisitor.h b/src/Interpreters/ArrayJoinedColumnsVisitor.h\nindex 3bbd6982213b..f16751c45616 100644\n--- a/src/Interpreters/ArrayJoinedColumnsVisitor.h\n+++ b/src/Interpreters/ArrayJoinedColumnsVisitor.h\n@@ -62,7 +62,7 @@ class ArrayJoinedColumnsMatcher\n     {\n         auto [array_join_expression_list, _] = node.arrayJoinExpressionList();\n         if (!array_join_expression_list)\n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: no ARRAY JOIN\");\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"No ARRAY JOIN\");\n \n         std::vector<ASTPtr *> out;\n         out.reserve(array_join_expression_list->children.size());\ndiff --git a/src/Interpreters/ClientInfo.cpp b/src/Interpreters/ClientInfo.cpp\nindex 347ec115abae..e4778edeb9cb 100644\n--- a/src/Interpreters/ClientInfo.cpp\n+++ b/src/Interpreters/ClientInfo.cpp\n@@ -23,7 +23,7 @@ namespace ErrorCodes\n void ClientInfo::write(WriteBuffer & out, UInt64 server_protocol_revision) const\n {\n     if (server_protocol_revision < DBMS_MIN_REVISION_WITH_CLIENT_INFO)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: method ClientInfo::write is called for unsupported server revision\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Method ClientInfo::write is called for unsupported server revision\");\n \n     writeBinary(static_cast<UInt8>(query_kind), out);\n     if (empty())\n@@ -103,7 +103,7 @@ void ClientInfo::write(WriteBuffer & out, UInt64 server_protocol_revision) const\n void ClientInfo::read(ReadBuffer & in, UInt64 client_protocol_revision)\n {\n     if (client_protocol_revision < DBMS_MIN_REVISION_WITH_CLIENT_INFO)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: method ClientInfo::read is called for unsupported client revision\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Method ClientInfo::read is called for unsupported client revision\");\n \n     UInt8 read_query_kind = 0;\n     readBinary(read_query_kind, in);\ndiff --git a/src/Interpreters/CrossToInnerJoinVisitor.cpp b/src/Interpreters/CrossToInnerJoinVisitor.cpp\nindex 42af164f4ad3..e3e8b80e4379 100644\n--- a/src/Interpreters/CrossToInnerJoinVisitor.cpp\n+++ b/src/Interpreters/CrossToInnerJoinVisitor.cpp\n@@ -173,7 +173,7 @@ std::vector<JoinedElement> getTables(const ASTSelectQuery & select)\n     {\n         const auto * table_element = child->as<ASTTablesInSelectQueryElement>();\n         if (!table_element)\n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: TablesInSelectQueryElement expected\");\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"TablesInSelectQueryElement expected\");\n \n         JoinedElement & t = joined_tables.emplace_back(*table_element);\n         t.rewriteCommaToCross();\n@@ -224,7 +224,7 @@ void CrossToInnerJoinMatcher::visit(ASTSelectQuery & select, ASTPtr &, Data & da\n     {\n         if (joined_tables.size() != data.tables_with_columns.size())\n             throw Exception(ErrorCodes::LOGICAL_ERROR,\n-                            \"Logical error: inconsistent number of tables: {} != {}\",\n+                            \"Inconsistent number of tables: {} != {}\",\n                             joined_tables.size(), data.tables_with_columns.size());\n \n         for (size_t i = 0; i < joined_tables.size(); ++i)\ndiff --git a/src/Interpreters/DatabaseAndTableWithAlias.cpp b/src/Interpreters/DatabaseAndTableWithAlias.cpp\nindex db020cb91660..329391b45d70 100644\n--- a/src/Interpreters/DatabaseAndTableWithAlias.cpp\n+++ b/src/Interpreters/DatabaseAndTableWithAlias.cpp\n@@ -71,7 +71,7 @@ DatabaseAndTableWithAlias::DatabaseAndTableWithAlias(const ASTTableExpression &\n         alias = table_expression.subquery->tryGetAlias();\n     }\n     else\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: no known elements in ASTTableExpression\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"No known elements in ASTTableExpression\");\n }\n \n bool DatabaseAndTableWithAlias::satisfies(const DatabaseAndTableWithAlias & db_table, bool table_may_be_an_alias) const\ndiff --git a/src/Interpreters/HashJoin.cpp b/src/Interpreters/HashJoin.cpp\nindex 33dc178ca00c..73487a0914a6 100644\n--- a/src/Interpreters/HashJoin.cpp\n+++ b/src/Interpreters/HashJoin.cpp\n@@ -368,7 +368,7 @@ HashJoin::Type HashJoin::chooseMethod(JoinKind kind, const ColumnRawPtrs & key_c\n             return Type::keys128;\n         if (size_of_field == 32)\n             return Type::keys256;\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: numeric column has sizeOfField not in 1, 2, 4, 8, 16, 32.\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Numeric column has sizeOfField not in 1, 2, 4, 8, 16, 32.\");\n     }\n \n     /// If the keys fit in N bits, we will use a hash table for N-bit-packed keys\ndiff --git a/src/Interpreters/InJoinSubqueriesPreprocessor.cpp b/src/Interpreters/InJoinSubqueriesPreprocessor.cpp\nindex 3858830a43bf..ec4241a27406 100644\n--- a/src/Interpreters/InJoinSubqueriesPreprocessor.cpp\n+++ b/src/Interpreters/InJoinSubqueriesPreprocessor.cpp\n@@ -103,12 +103,12 @@ struct NonGlobalTableData : public WithContext\n                     /// Already processed.\n                 }\n                 else\n-                    throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: unexpected function name {}\", concrete->name);\n+                    throw Exception(ErrorCodes::LOGICAL_ERROR, \"Unexpected function name {}\", concrete->name);\n             }\n             else if (table_join)\n                 table_join->locality = JoinLocality::Global;\n             else\n-                throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: unexpected AST node\");\n+                throw Exception(ErrorCodes::LOGICAL_ERROR, \"Unexpected AST node\");\n         }\n         else if (distributed_product_mode == DistributedProductMode::DENY)\n         {\ndiff --git a/src/Interpreters/InterpreterSelectWithUnionQuery.cpp b/src/Interpreters/InterpreterSelectWithUnionQuery.cpp\nindex 16bc4b1fe2e7..cc1d7dd65310 100644\n--- a/src/Interpreters/InterpreterSelectWithUnionQuery.cpp\n+++ b/src/Interpreters/InterpreterSelectWithUnionQuery.cpp\n@@ -56,7 +56,7 @@ InterpreterSelectWithUnionQuery::InterpreterSelectWithUnionQuery(\n \n     size_t num_children = ast->list_of_selects->children.size();\n     if (!num_children)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: no children in ASTSelectWithUnionQuery\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"No children in ASTSelectWithUnionQuery\");\n \n     /// Note that we pass 'required_result_column_names' to first SELECT.\n     /// And for the rest, we pass names at the corresponding positions of 'required_result_column_names' in the result of first SELECT,\ndiff --git a/src/Interpreters/JoinToSubqueryTransformVisitor.cpp b/src/Interpreters/JoinToSubqueryTransformVisitor.cpp\nindex bf2d1eb79cdf..6251a9604e18 100644\n--- a/src/Interpreters/JoinToSubqueryTransformVisitor.cpp\n+++ b/src/Interpreters/JoinToSubqueryTransformVisitor.cpp\n@@ -168,7 +168,7 @@ class ExtractAsterisksMatcher\n                 has_asterisks = true;\n \n                 if (!qualified_asterisk->qualifier)\n-                    throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: qualified asterisk must have a qualifier\");\n+                    throw Exception(ErrorCodes::LOGICAL_ERROR, \"Qualified asterisk must have a qualifier\");\n \n                 auto & identifier = qualified_asterisk->qualifier->as<ASTIdentifier &>();\n \n@@ -183,7 +183,7 @@ class ExtractAsterisksMatcher\n                             transformer->as<ASTColumnsReplaceTransformer>())\n                             IASTColumnsTransformer::transform(transformer, columns);\n                         else\n-                            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: qualified asterisk must only have children of IASTColumnsTransformer type\");\n+                            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Qualified asterisk must only have children of IASTColumnsTransformer type\");\n                     }\n                 }\n             }\ndiff --git a/src/Interpreters/MergeJoin.cpp b/src/Interpreters/MergeJoin.cpp\nindex 901c82029eec..d5fb0208d456 100644\n--- a/src/Interpreters/MergeJoin.cpp\n+++ b/src/Interpreters/MergeJoin.cpp\n@@ -239,7 +239,7 @@ class MergeJoinCursor\n \n         /// SortCursorImpl can work with permutation, but MergeJoinCursor can't.\n         if (impl.permutation)\n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: MergeJoinCursor doesn't support permutation\");\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"MergeJoinCursor doesn't support permutation\");\n     }\n \n     size_t position() const { return impl.getRow(); }\ndiff --git a/src/Interpreters/MySQL/InterpretersMySQLDDLQuery.cpp b/src/Interpreters/MySQL/InterpretersMySQLDDLQuery.cpp\nindex 0fdc9347ee97..107b435ded42 100644\n--- a/src/Interpreters/MySQL/InterpretersMySQLDDLQuery.cpp\n+++ b/src/Interpreters/MySQL/InterpretersMySQLDDLQuery.cpp\n@@ -337,7 +337,7 @@ static ASTPtr getPartitionPolicy(const NamesAndTypesList & primary_keys)\n         WhichDataType which(type);\n \n         if (which.isNullable())\n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"LOGICAL ERROR: MySQL primary key must be not null, it is a bug.\");\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"MySQL's primary key must be not null, it is a bug.\");\n \n         if (which.isDate() || which.isDate32() || which.isDateTime() || which.isDateTime64())\n         {\ndiff --git a/src/Interpreters/ProcessList.cpp b/src/Interpreters/ProcessList.cpp\nindex 5b3b87114ae8..3bd7b2d4206b 100644\n--- a/src/Interpreters/ProcessList.cpp\n+++ b/src/Interpreters/ProcessList.cpp\n@@ -295,7 +295,7 @@ ProcessListEntry::~ProcessListEntry()\n     auto user_process_list_it = parent.user_to_queries.find(user);\n     if (user_process_list_it == parent.user_to_queries.end())\n     {\n-        LOG_ERROR(getLogger(\"ProcessList\"), \"Logical error: cannot find user in ProcessList\");\n+        LOG_ERROR(getLogger(\"ProcessList\"), \"Cannot find user in ProcessList\");\n         std::terminate();\n     }\n \n@@ -323,7 +323,7 @@ ProcessListEntry::~ProcessListEntry()\n \n     if (!found)\n     {\n-        LOG_ERROR(getLogger(\"ProcessList\"), \"Logical error: cannot find query by query_id and pointer to ProcessListElement in ProcessListForUser\");\n+        LOG_ERROR(getLogger(\"ProcessList\"), \"Cannot find query by query_id and pointer to ProcessListElement in ProcessListForUser\");\n         std::terminate();\n     }\n \ndiff --git a/src/Interpreters/Set.cpp b/src/Interpreters/Set.cpp\nindex 84260faafd46..8f11754b3bef 100644\n--- a/src/Interpreters/Set.cpp\n+++ b/src/Interpreters/Set.cpp\n@@ -275,7 +275,7 @@ void Set::appendSetElements(SetKeyColumns & holder)\n void Set::checkIsCreated() const\n {\n     if (!is_created.load())\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: Trying to use set before it has been built.\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Trying to use set before it has been built.\");\n }\n \n ColumnPtr Set::execute(const ColumnsWithTypeAndName & columns, bool negative) const\n@@ -283,7 +283,7 @@ ColumnPtr Set::execute(const ColumnsWithTypeAndName & columns, bool negative) co\n     size_t num_key_columns = columns.size();\n \n     if (0 == num_key_columns)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: no columns passed to Set::execute method.\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"No columns passed to Set::execute method.\");\n \n     auto res = ColumnUInt8::create();\n     ColumnUInt8::Container & vec_res = res->getData();\ndiff --git a/src/Interpreters/SetVariants.cpp b/src/Interpreters/SetVariants.cpp\nindex cd9148a01cff..0fb2e5189d41 100644\n--- a/src/Interpreters/SetVariants.cpp\n+++ b/src/Interpreters/SetVariants.cpp\n@@ -146,7 +146,7 @@ typename SetVariantsTemplate<Variant>::Type SetVariantsTemplate<Variant>::choose\n             return Type::keys128;\n         if (size_of_field == 32)\n             return Type::keys256;\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: numeric column has sizeOfField not in 1, 2, 4, 8, 16, 32.\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Numeric column has sizeOfField not in 1, 2, 4, 8, 16, 32.\");\n     }\n \n     /// If the keys fit in N bits, we will use a hash table for N-bit-packed keys\ndiff --git a/src/Interpreters/TablesStatus.cpp b/src/Interpreters/TablesStatus.cpp\nindex 005a4515c3a7..911a028f8132 100644\n--- a/src/Interpreters/TablesStatus.cpp\n+++ b/src/Interpreters/TablesStatus.cpp\n@@ -35,7 +35,7 @@ void TableStatus::read(ReadBuffer & in)\n void TablesStatusRequest::write(WriteBuffer & out, UInt64 server_protocol_revision) const\n {\n     if (server_protocol_revision < DBMS_MIN_REVISION_WITH_TABLES_STATUS)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: method TablesStatusRequest::write is called for unsupported server revision\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Method TablesStatusRequest::write is called for unsupported server revision\");\n \n     writeVarUInt(tables.size(), out);\n     for (const auto & table_name : tables)\ndiff --git a/src/Interpreters/TranslateQualifiedNamesVisitor.cpp b/src/Interpreters/TranslateQualifiedNamesVisitor.cpp\nindex 130ce2194fda..3de7e217e535 100644\n--- a/src/Interpreters/TranslateQualifiedNamesVisitor.cpp\n+++ b/src/Interpreters/TranslateQualifiedNamesVisitor.cpp\n@@ -158,7 +158,7 @@ void TranslateQualifiedNamesMatcher::visit(ASTFunction & node, const ASTPtr &, D\n void TranslateQualifiedNamesMatcher::visit(const ASTQualifiedAsterisk & node, const ASTPtr &, Data & data)\n {\n     if (!node.qualifier)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: qualified asterisk must have a qualifier\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Qualified asterisk must have a qualifier\");\n \n     /// @note it could contain table alias as table name.\n     DatabaseAndTableWithAlias db_and_table(node.qualifier);\ndiff --git a/src/Interpreters/evaluateConstantExpression.cpp b/src/Interpreters/evaluateConstantExpression.cpp\nindex 00d36750cc11..b5c3e00e2997 100644\n--- a/src/Interpreters/evaluateConstantExpression.cpp\n+++ b/src/Interpreters/evaluateConstantExpression.cpp\n@@ -106,7 +106,7 @@ std::optional<EvaluateConstantExpressionResult> evaluateConstantExpressionImpl(c\n \n     if (result_column->empty())\n         throw Exception(ErrorCodes::LOGICAL_ERROR,\n-                        \"Logical error: empty result column after evaluation \"\n+                        \"Empty result column after evaluation \"\n                         \"of constant expression for IN, VALUES, or LIMIT, or aggregate function parameter, or a table function argument\");\n \n     /// Expressions like rand() or now() are not constant\ndiff --git a/src/Interpreters/getHeaderForProcessingStage.cpp b/src/Interpreters/getHeaderForProcessingStage.cpp\nindex 8104c6eb81f4..217392980366 100644\n--- a/src/Interpreters/getHeaderForProcessingStage.cpp\n+++ b/src/Interpreters/getHeaderForProcessingStage.cpp\n@@ -152,8 +152,7 @@ Block getHeaderForProcessingStage(\n             return result;\n         }\n     }\n-    throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical Error: unknown processed stage.\");\n+    throw Exception(ErrorCodes::LOGICAL_ERROR, \"Unknown processed stage.\");\n }\n \n }\n-\ndiff --git a/src/Parsers/ExpressionElementParsers.cpp b/src/Parsers/ExpressionElementParsers.cpp\nindex 62c480e0f6b0..486555ae86d9 100644\n--- a/src/Parsers/ExpressionElementParsers.cpp\n+++ b/src/Parsers/ExpressionElementParsers.cpp\n@@ -934,7 +934,7 @@ bool ParserNumber::parseImpl(Pos & pos, ASTPtr & node, Expected & expected)\n         {\n             if (float_value < 0)\n                 throw Exception(ErrorCodes::LOGICAL_ERROR,\n-                                \"Logical error: token number cannot begin with minus, \"\n+                                \"Token number cannot begin with minus, \"\n                                 \"but parsed float number is less than zero.\");\n \n             if (negative)\ndiff --git a/src/Parsers/IParser.h b/src/Parsers/IParser.h\nindex d53b58baa7c8..198ec0346fff 100644\n--- a/src/Parsers/IParser.h\n+++ b/src/Parsers/IParser.h\n@@ -9,6 +9,7 @@\n #include <Parsers/TokenIterator.h>\n #include <base/types.h>\n #include <Common/Exception.h>\n+#include <Common/checkStackSize.h>\n \n \n namespace DB\n@@ -73,6 +74,21 @@ class IParser\n             if (unlikely(max_depth > 0 && depth > max_depth))\n                 throw Exception(ErrorCodes::TOO_DEEP_RECURSION, \"Maximum parse depth ({}) exceeded. \"\n                     \"Consider rising max_parser_depth parameter.\", max_depth);\n+\n+            /** Sometimes the maximum parser depth can be set to a high value by the user,\n+              * but we still want to avoid stack overflow.\n+              * For this purpose, we can use the checkStackSize function, but it is too heavy.\n+              * The solution is to check not too frequently.\n+              * The frequency is arbitrary, but not too large, not too small,\n+              * and a power of two to simplify the division.\n+              */\n+#if defined(USE_MUSL) || defined(SANITIZER) || !defined(NDEBUG)\n+            static constexpr uint32_t check_frequency = 128;\n+#else\n+            static constexpr uint32_t check_frequency = 8192;\n+#endif\n+            if (depth % check_frequency == 0)\n+                checkStackSize();\n         }\n \n         ALWAYS_INLINE void decreaseDepth()\ndiff --git a/src/Processors/Formats/Impl/JSONEachRowRowInputFormat.cpp b/src/Processors/Formats/Impl/JSONEachRowRowInputFormat.cpp\nindex 0ef19a9c14fc..6fa94356cd32 100644\n--- a/src/Processors/Formats/Impl/JSONEachRowRowInputFormat.cpp\n+++ b/src/Processors/Formats/Impl/JSONEachRowRowInputFormat.cpp\n@@ -179,7 +179,7 @@ void JSONEachRowRowInputFormat::readJSONObject(MutableColumns & columns)\n             else if (column_index == NESTED_FIELD)\n                 readNestedData(name_ref.toString(), columns);\n             else\n-                throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: illegal value of column_index\");\n+                throw Exception(ErrorCodes::LOGICAL_ERROR, \"Illegal value of column_index\");\n         }\n         else\n         {\ndiff --git a/src/Processors/Formats/RowInputFormatWithDiagnosticInfo.cpp b/src/Processors/Formats/RowInputFormatWithDiagnosticInfo.cpp\nindex a56c24a740ad..fcf338577f8a 100644\n--- a/src/Processors/Formats/RowInputFormatWithDiagnosticInfo.cpp\n+++ b/src/Processors/Formats/RowInputFormatWithDiagnosticInfo.cpp\n@@ -136,7 +136,7 @@ bool RowInputFormatWithDiagnosticInfo::deserializeFieldAndPrintDiagnosticInfo(co\n     auto * curr_position = in->position();\n \n     if (curr_position < prev_position)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: parsing is non-deterministic.\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Parsing is non-deterministic.\");\n \n     if (isNativeNumber(type) || isDate(type) || isDateTime(type) || isDateTime64(type))\n     {\ndiff --git a/src/Processors/Sources/WaitForAsyncInsertSource.h b/src/Processors/Sources/WaitForAsyncInsertSource.h\nindex 1029c1649417..78af62942027 100644\n--- a/src/Processors/Sources/WaitForAsyncInsertSource.h\n+++ b/src/Processors/Sources/WaitForAsyncInsertSource.h\n@@ -33,7 +33,7 @@ class WaitForAsyncInsertSource : public ISource, WithContext\n     {\n         auto status = insert_future.wait_for(std::chrono::milliseconds(timeout_ms));\n         if (status == std::future_status::deferred)\n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: got future in deferred state\");\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Got future in deferred state\");\n \n         if (status == std::future_status::timeout)\n             throw Exception(ErrorCodes::TIMEOUT_EXCEEDED, \"Wait for async insert timeout ({} ms) exceeded)\", timeout_ms);\ndiff --git a/src/Processors/Transforms/CreatingSetsTransform.cpp b/src/Processors/Transforms/CreatingSetsTransform.cpp\nindex cc0b5926e66f..eeb8f4a60605 100644\n--- a/src/Processors/Transforms/CreatingSetsTransform.cpp\n+++ b/src/Processors/Transforms/CreatingSetsTransform.cpp\n@@ -163,7 +163,7 @@ void CreatingSetsTransform::startSubquery()\n     done_with_table = !external_table;\n \n     if ((done_with_set && !set_from_cache) && done_with_table)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: nothing to do with subquery\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Nothing to do with subquery\");\n \n     if (table_out.initialized())\n     {\ndiff --git a/src/Processors/Transforms/getSourceFromASTInsertQuery.cpp b/src/Processors/Transforms/getSourceFromASTInsertQuery.cpp\nindex 6c7c74470707..8a13973b9700 100644\n--- a/src/Processors/Transforms/getSourceFromASTInsertQuery.cpp\n+++ b/src/Processors/Transforms/getSourceFromASTInsertQuery.cpp\n@@ -37,7 +37,7 @@ InputFormatPtr getInputFormatFromASTInsertQuery(\n     const auto * ast_insert_query = ast->as<ASTInsertQuery>();\n \n     if (!ast_insert_query)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: query requires data to insert, but it is not INSERT query\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Query requires data to insert, but it is not INSERT query\");\n \n     if (ast_insert_query->infile && context->getApplicationType() == Context::ApplicationType::SERVER)\n         throw Exception(ErrorCodes::UNKNOWN_TYPE_OF_QUERY, \"Query has infile and was send directly to server\");\n@@ -47,7 +47,7 @@ InputFormatPtr getInputFormatFromASTInsertQuery(\n         if (input_function)\n             throw Exception(ErrorCodes::INVALID_USAGE_OF_INPUT, \"FORMAT must be specified for function input()\");\n         else\n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: INSERT query requires format to be set\");\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"INSERT query requires format to be set\");\n     }\n \n     /// Data could be in parsed (ast_insert_query.data) and in not parsed yet (input_buffer_tail_part) part of query.\n@@ -105,7 +105,7 @@ std::unique_ptr<ReadBuffer> getReadBufferFromASTInsertQuery(const ASTPtr & ast)\n {\n     const auto * insert_query = ast->as<ASTInsertQuery>();\n     if (!insert_query)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: query requires data to insert, but it is not INSERT query\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Query requires data to insert, but it is not INSERT query\");\n \n     if (insert_query->infile)\n     {\ndiff --git a/src/QueryPipeline/ExecutionSpeedLimits.cpp b/src/QueryPipeline/ExecutionSpeedLimits.cpp\nindex f8ae4c76d0fe..05fd394db775 100644\n--- a/src/QueryPipeline/ExecutionSpeedLimits.cpp\n+++ b/src/QueryPipeline/ExecutionSpeedLimits.cpp\n@@ -113,7 +113,7 @@ static bool handleOverflowMode(OverflowMode mode, int code, FormatStringHelper<A\n             ProfileEvents::increment(ProfileEvents::OverflowBreak);\n             return false;\n         default:\n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: unknown overflow mode\");\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Unknown overflow mode\");\n     }\n }\n \ndiff --git a/src/QueryPipeline/RemoteQueryExecutorReadContext.h b/src/QueryPipeline/RemoteQueryExecutorReadContext.h\nindex adfc0c5eacfc..50df7e2db351 100644\n--- a/src/QueryPipeline/RemoteQueryExecutorReadContext.h\n+++ b/src/QueryPipeline/RemoteQueryExecutorReadContext.h\n@@ -5,7 +5,6 @@\n #include <mutex>\n #include <atomic>\n #include <Common/Fiber.h>\n-#include <Common/FiberStack.h>\n #include <Common/TimerDescriptor.h>\n #include <Common/Epoll.h>\n #include <Common/AsyncTaskExecutor.h>\ndiff --git a/src/Server/HTTPHandlerFactory.cpp b/src/Server/HTTPHandlerFactory.cpp\nindex e9157266901c..ddea469d9d4d 100644\n--- a/src/Server/HTTPHandlerFactory.cpp\n+++ b/src/Server/HTTPHandlerFactory.cpp\n@@ -165,7 +165,7 @@ HTTPRequestHandlerFactoryPtr createHandlerFactory(IServer & server, const Poco::\n         return createPrometheusMainHandlerFactory(server, config, metrics_writer, name);\n     }\n \n-    throw Exception(ErrorCodes::LOGICAL_ERROR, \"LOGICAL ERROR: Unknown HTTP handler factory name.\");\n+    throw Exception(ErrorCodes::LOGICAL_ERROR, \"Unknown HTTP handler factory name.\");\n }\n \n \ndiff --git a/src/Server/TCPHandler.cpp b/src/Server/TCPHandler.cpp\nindex 833f8ecc8189..9464ef74586c 100644\n--- a/src/Server/TCPHandler.cpp\n+++ b/src/Server/TCPHandler.cpp\n@@ -943,7 +943,7 @@ void TCPHandler::processInsertQuery()\n                 auto wait_status = result.future.wait_for(std::chrono::milliseconds(timeout_ms));\n \n                 if (wait_status == std::future_status::deferred)\n-                    throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: got future in deferred state\");\n+                    throw Exception(ErrorCodes::LOGICAL_ERROR, \"Got future in deferred state\");\n \n                 if (wait_status == std::future_status::timeout)\n                     throw Exception(ErrorCodes::TIMEOUT_EXCEEDED, \"Wait for async insert timeout ({} ms) exceeded)\", timeout_ms);\ndiff --git a/src/Storages/MergeTree/DataPartsExchange.cpp b/src/Storages/MergeTree/DataPartsExchange.cpp\nindex ce70fbe18e50..168c5f729ce3 100644\n--- a/src/Storages/MergeTree/DataPartsExchange.cpp\n+++ b/src/Storages/MergeTree/DataPartsExchange.cpp\n@@ -903,7 +903,7 @@ MergeTreeData::MutableDataPartPtr Fetcher::downloadPartToDisk(\n         || part_name.empty()\n         || std::string::npos != tmp_prefix.find_first_of(\"/.\")\n         || std::string::npos != part_name.find_first_of(\"/.\"))\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: tmp_prefix and part_name cannot be empty or contain '.' or '/' characters.\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"`tmp_prefix` and `part_name` cannot be empty or contain '.' or '/' characters.\");\n \n     auto part_dir = tmp_prefix + part_name;\n     auto part_relative_path = data.getRelativeDataPath() + String(to_detached ? \"detached/\" : \"\");\ndiff --git a/src/Storages/MergeTree/EphemeralLockInZooKeeper.cpp b/src/Storages/MergeTree/EphemeralLockInZooKeeper.cpp\nindex 1ffb51774302..cbdeabffa972 100644\n--- a/src/Storages/MergeTree/EphemeralLockInZooKeeper.cpp\n+++ b/src/Storages/MergeTree/EphemeralLockInZooKeeper.cpp\n@@ -17,7 +17,7 @@ EphemeralLockInZooKeeper::EphemeralLockInZooKeeper(const String & path_prefix_,\n     : zookeeper(zookeeper_), path_prefix(path_prefix_), path(path_), conflict_path(conflict_path_)\n {\n     if (conflict_path.empty() && path.size() <= path_prefix.size())\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: name of the main node is shorter than prefix.\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Name of the main node is shorter than prefix.\");\n }\n \n template <typename T>\n@@ -179,7 +179,7 @@ EphemeralLocksInAllPartitions::EphemeralLocksInAllPartitions(\n             size_t prefix_size = block_numbers_path.size() + 1 + partitions[i].size() + 1 + path_prefix.size();\n             const String & path = dynamic_cast<const Coordination::CreateResponse &>(*lock_responses[i]).path_created;\n             if (path.size() <= prefix_size)\n-                throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: name of the sequential node is shorter than prefix.\");\n+                throw Exception(ErrorCodes::LOGICAL_ERROR, \"Name of the sequential node is shorter than prefix.\");\n \n             UInt64 number = parse<UInt64>(path.c_str() + prefix_size, path.size() - prefix_size);\n             locks.push_back(LockInfo{path, partitions[i], number});\ndiff --git a/src/Storages/MergeTree/MergeTreeData.cpp b/src/Storages/MergeTree/MergeTreeData.cpp\nindex 6d5e486f6a13..8aa188cfe5ce 100644\n--- a/src/Storages/MergeTree/MergeTreeData.cpp\n+++ b/src/Storages/MergeTree/MergeTreeData.cpp\n@@ -870,7 +870,7 @@ void MergeTreeData::MergingParams::check(const StorageInMemoryMetadata & metadat\n             if (is_optional)\n                 return;\n \n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: Sign column for storage {} is empty\", storage);\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Sign column for storage {} is empty\", storage);\n         }\n \n         bool miss_column = true;\n@@ -897,7 +897,7 @@ void MergeTreeData::MergingParams::check(const StorageInMemoryMetadata & metadat\n             if (is_optional)\n                 return;\n \n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: Version column for storage {} is empty\", storage);\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Version column for storage {} is empty\", storage);\n         }\n \n         bool miss_column = true;\n@@ -926,12 +926,12 @@ void MergeTreeData::MergingParams::check(const StorageInMemoryMetadata & metadat\n             if (is_optional)\n                 return;\n \n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: is_deleted ({}) column for storage {} is empty\", is_deleted_column, storage);\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"`is_deleted` ({}) column for storage {} is empty\", is_deleted_column, storage);\n         }\n         else\n         {\n             if (version_column.empty() && !is_optional)\n-                throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: Version column ({}) for storage {} is empty while is_deleted ({}) is not.\",\n+                throw Exception(ErrorCodes::LOGICAL_ERROR, \"Version column ({}) for storage {} is empty while is_deleted ({}) is not.\",\n                                 version_column, storage, is_deleted_column);\n \n             bool miss_is_deleted_column = true;\ndiff --git a/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp b/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp\nindex 58fddde7b545..1bf1d4a3c295 100644\n--- a/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp\n+++ b/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp\n@@ -85,7 +85,7 @@ UInt64 MergeTreeDataMergerMutator::getMaxSourcePartsSizeForMerge(size_t max_coun\n     if (scheduled_tasks_count > max_count)\n     {\n         throw Exception(ErrorCodes::LOGICAL_ERROR,\n-            \"Logical error: invalid argument passed to getMaxSourcePartsSize: scheduled_tasks_count = {} > max_count = {}\",\n+            \"Invalid argument passed to getMaxSourcePartsSize: scheduled_tasks_count = {} > max_count = {}\",\n             scheduled_tasks_count, max_count);\n     }\n \n@@ -511,7 +511,7 @@ SelectPartsDecision MergeTreeDataMergerMutator::selectPartsToMergeFromRanges(\n \n         /// Do not allow to \"merge\" part with itself for regular merges, unless it is a TTL-merge where it is ok to remove some values with expired ttl\n         if (parts_to_merge.size() == 1)\n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: merge selector returned only one part to merge\");\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Merge selector returned only one part to merge\");\n \n         if (parts_to_merge.empty())\n         {\ndiff --git a/src/Storages/MergeTree/MergeTreeDataWriter.cpp b/src/Storages/MergeTree/MergeTreeDataWriter.cpp\nindex c9c16b59f9e0..ebf887f5e9e0 100644\n--- a/src/Storages/MergeTree/MergeTreeDataWriter.cpp\n+++ b/src/Storages/MergeTree/MergeTreeDataWriter.cpp\n@@ -384,13 +384,13 @@ Block MergeTreeDataWriter::mergeBlock(\n \n     /// Check that after first merge merging_algorithm is waiting for data from input 0.\n     if (status.required_source != 0)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: required source after the first merge is not 0. Chunk rows: {}, is_finished: {}, required_source: {}, algorithm: {}\", status.chunk.getNumRows(), status.is_finished, status.required_source, merging_algorithm->getName());\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Required source after the first merge is not 0. Chunk rows: {}, is_finished: {}, required_source: {}, algorithm: {}\", status.chunk.getNumRows(), status.is_finished, status.required_source, merging_algorithm->getName());\n \n     status = merging_algorithm->merge();\n \n     /// Check that merge is finished.\n     if (!status.is_finished)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: merge is not finished after the second merge.\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Merge is not finished after the second merge.\");\n \n     /// Merged Block is sorted and we don't need to use permutation anymore\n     permutation = nullptr;\n@@ -439,7 +439,7 @@ MergeTreeDataWriter::TemporaryPart MergeTreeDataWriter::writeTempPartImpl(\n         auto max_month = date_lut.toNumYYYYMM(max_date);\n \n         if (min_month != max_month)\n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: part spans more than one month.\");\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Part spans more than one month.\");\n \n         part_name = new_part_info.getPartNameV0(min_date, max_date);\n     }\ndiff --git a/src/Storages/MergeTree/MergeTreeIndexConditionBloomFilter.cpp b/src/Storages/MergeTree/MergeTreeIndexConditionBloomFilter.cpp\nindex da49814b83a7..f506230b5eaf 100644\n--- a/src/Storages/MergeTree/MergeTreeIndexConditionBloomFilter.cpp\n+++ b/src/Storages/MergeTree/MergeTreeIndexConditionBloomFilter.cpp\n@@ -59,7 +59,7 @@ bool maybeTrueOnBloomFilter(const IColumn * hash_column, const BloomFilterPtr &\n     const auto * non_const_column = typeid_cast<const ColumnUInt64 *>(hash_column);\n \n     if (!const_column && !non_const_column)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"LOGICAL ERROR: hash column must be Const Column or UInt64 Column.\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Hash column must be Const or UInt64.\");\n \n     if (const_column)\n     {\ndiff --git a/src/Storages/MergeTree/MergeTreeIndexConditionBloomFilter.h b/src/Storages/MergeTree/MergeTreeIndexConditionBloomFilter.h\nindex db85c804d8d0..8029d6d405b2 100644\n--- a/src/Storages/MergeTree/MergeTreeIndexConditionBloomFilter.h\n+++ b/src/Storages/MergeTree/MergeTreeIndexConditionBloomFilter.h\n@@ -53,7 +53,7 @@ class MergeTreeIndexConditionBloomFilter final : public IMergeTreeIndexCondition\n         if (const auto & bf_granule = typeid_cast<const MergeTreeIndexGranuleBloomFilter *>(granule.get()))\n             return mayBeTrueOnGranule(bf_granule);\n \n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"LOGICAL ERROR: require bloom filter index granule.\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Requires bloom filter index granule.\");\n     }\n \n private:\ndiff --git a/src/Storages/MergeTree/MergeTreeIndexGranularityInfo.cpp b/src/Storages/MergeTree/MergeTreeIndexGranularityInfo.cpp\nindex 4e339964de36..da89d52a9ffd 100644\n--- a/src/Storages/MergeTree/MergeTreeIndexGranularityInfo.cpp\n+++ b/src/Storages/MergeTree/MergeTreeIndexGranularityInfo.cpp\n@@ -54,9 +54,9 @@ MarkType::MarkType(bool adaptive_, bool compressed_, MergeTreeDataPartType::Valu\n     : adaptive(adaptive_), compressed(compressed_), part_type(part_type_)\n {\n     if (!adaptive && part_type != MergeTreeDataPartType::Wide)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: non-Wide data part type with non-adaptive granularity\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Non-Wide data part type with non-adaptive granularity\");\n     if (part_type == MergeTreeDataPartType::Unknown)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: unknown data part type\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Unknown data part type\");\n }\n \n bool MarkType::isMarkFileExtension(std::string_view extension)\n@@ -71,7 +71,7 @@ std::string MarkType::getFileExtension() const\n     if (!adaptive)\n     {\n         if (part_type != MergeTreeDataPartType::Wide)\n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: non-Wide data part type with non-adaptive granularity\");\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Non-Wide data part type with non-adaptive granularity\");\n         return res;\n     }\n \n@@ -84,7 +84,7 @@ std::string MarkType::getFileExtension() const\n         case MergeTreeDataPartType::InMemory:\n             return \"\";\n         case MergeTreeDataPartType::Unknown:\n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: unknown data part type\");\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Unknown data part type\");\n     }\n }\n \ndiff --git a/src/Storages/StorageJoin.cpp b/src/Storages/StorageJoin.cpp\nindex b9e082c0b224..b122674466fc 100644\n--- a/src/Storages/StorageJoin.cpp\n+++ b/src/Storages/StorageJoin.cpp\n@@ -500,7 +500,7 @@ class JoinSource : public ISource\n         Chunk chunk;\n         if (!joinDispatch(join->kind, join->strictness, join->data->maps.front(),\n                 [&](auto kind, auto strictness, auto & map) { chunk = createChunk<kind, strictness>(map); }))\n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: unknown JOIN strictness\");\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Unknown JOIN strictness\");\n         return chunk;\n     }\n \ndiff --git a/src/Storages/StorageLog.cpp b/src/Storages/StorageLog.cpp\nindex 9fbeac5e4f36..7459760b0f5e 100644\n--- a/src/Storages/StorageLog.cpp\n+++ b/src/Storages/StorageLog.cpp\n@@ -241,7 +241,7 @@ void LogSource::readData(const NameAndTypePair & name_and_type, ColumnPtr & colu\n \n             const auto & data_file_it = storage.data_files_by_names.find(data_file_name);\n             if (data_file_it == storage.data_files_by_names.end())\n-                throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: no information about file {} in StorageLog\", data_file_name);\n+                throw Exception(ErrorCodes::LOGICAL_ERROR, \"No information about file {} in StorageLog\", data_file_name);\n             const auto & data_file = *data_file_it->second;\n \n             size_t offset = stream_for_prefix ? 0 : offsets[data_file.index];\n@@ -448,7 +448,7 @@ ISerialization::OutputStreamGetter LogSink::createStreamGetter(const NameAndType\n         String data_file_name = ISerialization::getFileNameForStream(name_and_type, path);\n         auto it = streams.find(data_file_name);\n         if (it == streams.end())\n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: stream was not created when writing data in LogSink\");\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Stream was not created when writing data in LogSink\");\n \n         Stream & stream = it->second;\n         if (stream.written)\n@@ -473,7 +473,7 @@ void LogSink::writeData(const NameAndTypePair & name_and_type, const IColumn & c\n         {\n             const auto & data_file_it = storage.data_files_by_names.find(data_file_name);\n             if (data_file_it == storage.data_files_by_names.end())\n-                throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: no information about file {} in StorageLog\", data_file_name);\n+                throw Exception(ErrorCodes::LOGICAL_ERROR, \"No information about file {} in StorageLog\", data_file_name);\n \n             const auto & data_file = *data_file_it->second;\n             const auto & columns = metadata_snapshot->getColumns();\ndiff --git a/src/Storages/StorageReplicatedMergeTree.cpp b/src/Storages/StorageReplicatedMergeTree.cpp\nindex 1702b52fa356..1c66a5f6ecda 100644\n--- a/src/Storages/StorageReplicatedMergeTree.cpp\n+++ b/src/Storages/StorageReplicatedMergeTree.cpp\n@@ -2050,7 +2050,7 @@ bool StorageReplicatedMergeTree::executeFetch(LogEntry & entry, bool need_to_che\n             if (entry.quorum)\n             {\n                 if (entry.type != LogEntry::GET_PART)\n-                    throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: log entry with quorum but type is not GET_PART\");\n+                    throw Exception(ErrorCodes::LOGICAL_ERROR, \"Log entry with quorum but type is not GET_PART\");\n \n                 LOG_DEBUG(log, \"No active replica has part {} which needs to be written with quorum. Will try to mark that quorum as failed.\", entry.new_part_name);\n \n@@ -2113,7 +2113,7 @@ bool StorageReplicatedMergeTree::executeFetch(LogEntry & entry, bool need_to_che\n                         auto part_info = MergeTreePartInfo::fromPartName(entry.new_part_name, format_version);\n \n                         if (part_info.min_block != part_info.max_block)\n-                            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: log entry with quorum for part covering more than one block number\");\n+                            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Log entry with quorum for part covering more than one block number\");\n \n                         ops.emplace_back(zkutil::makeCreateRequest(\n                             fs::path(zookeeper_path) / \"quorum\" / \"failed_parts\" / entry.new_part_name,\n@@ -6800,7 +6800,7 @@ bool StorageReplicatedMergeTree::tryWaitForReplicaToProcessLogEntry(\n     }\n     else\n     {\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: unexpected name of log node: {}\", entry.znode_name);\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Unexpected name of log node: {}\", entry.znode_name);\n     }\n \n     /** Second - find the corresponding entry in the queue of the specified replica.\n@@ -7176,7 +7176,7 @@ void StorageReplicatedMergeTree::fetchPartition(\n     }\n \n     if (best_replica.empty())\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: cannot choose best replica.\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Cannot choose best replica.\");\n \n     LOG_INFO(log, \"Found {} replicas, {} of them are active. Selected {} to fetch from.\", replicas.size(), active_replicas.size(), best_replica);\n \ndiff --git a/src/Storages/StorageView.cpp b/src/Storages/StorageView.cpp\nindex 181fd0ac61c5..5679effbcb28 100644\n--- a/src/Storages/StorageView.cpp\n+++ b/src/Storages/StorageView.cpp\n@@ -207,12 +207,12 @@ void StorageView::read(\n static ASTTableExpression * getFirstTableExpression(ASTSelectQuery & select_query)\n {\n     if (!select_query.tables() || select_query.tables()->children.empty())\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: no table expression in view select AST\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"No table expression in view select AST\");\n \n     auto * select_element = select_query.tables()->children[0]->as<ASTTablesInSelectQueryElement>();\n \n     if (!select_element->table_expression)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: incorrect table expression\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Incorrect table expression\");\n \n     return select_element->table_expression->as<ASTTableExpression>();\n }\n@@ -243,7 +243,7 @@ void StorageView::replaceWithSubquery(ASTSelectQuery & outer_query, ASTPtr view_\n \n         }\n         if (!table_expression->database_and_table_name)\n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: incorrect table expression\");\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Incorrect table expression\");\n     }\n \n     DatabaseAndTableWithAlias db_table(table_expression->database_and_table_name);\n@@ -270,7 +270,7 @@ ASTPtr StorageView::restoreViewName(ASTSelectQuery & select_query, const ASTPtr\n     ASTTableExpression * table_expression = getFirstTableExpression(select_query);\n \n     if (!table_expression->subquery)\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: incorrect table expression\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Incorrect table expression\");\n \n     ASTPtr subquery = table_expression->subquery;\n     table_expression->subquery = {};\ndiff --git a/src/Storages/System/StorageSystemStackTrace.cpp b/src/Storages/System/StorageSystemStackTrace.cpp\nindex c9758004a4de..74864bb50e12 100644\n--- a/src/Storages/System/StorageSystemStackTrace.cpp\n+++ b/src/Storages/System/StorageSystemStackTrace.cpp\n@@ -167,7 +167,7 @@ bool wait(int timeout_ms)\n                 continue;   /// Drain delayed notifications.\n         }\n \n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: read wrong number of bytes from pipe\");\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Read wrong number of bytes from pipe\");\n     }\n }\n \ndiff --git a/src/Storages/transformQueryForExternalDatabase.cpp b/src/Storages/transformQueryForExternalDatabase.cpp\nindex 4526a38a1c30..afc458ea6124 100644\n--- a/src/Storages/transformQueryForExternalDatabase.cpp\n+++ b/src/Storages/transformQueryForExternalDatabase.cpp\n@@ -145,7 +145,7 @@ bool isCompatible(ASTPtr & node)\n             return false;\n \n         if (!function->arguments)\n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Logical error: function->arguments is not set\");\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"function->arguments is not set\");\n \n         String name = function->name;\n \ndiff --git a/utils/check-style/check-style b/utils/check-style/check-style\nindex 6c12970c4bb9..a71dac91683c 100755\n--- a/utils/check-style/check-style\n+++ b/utils/check-style/check-style\n@@ -448,3 +448,8 @@ find $ROOT_PATH/{src,base,programs,utils} -name '*.h' -or -name '*.cpp' |\n     grep -vP $EXCLUDE_DIRS |\n     xargs grep -P 'Sql|Html|Xml|Cpu|Tcp|Udp|Http|Db|Json|Yaml' | grep -v -P 'RabbitMQ|Azure|Aws|aws|Avro|IO/S3' &&\n     echo \"Abbreviations such as SQL, XML, HTTP, should be in all caps. For example, SQL is right, Sql is wrong. XMLHttpRequest is very wrong.\"\n+\n+find $ROOT_PATH/{src,base,programs,utils} -name '*.h' -or -name '*.cpp' |\n+    grep -vP $EXCLUDE_DIRS |\n+    xargs grep -F -i 'ErrorCodes::LOGICAL_ERROR, \"Logical error:' &&\n+    echo \"If an exception has LOGICAL_ERROR code, there is no need to include the text 'Logical error' in the exception message, because then the phrase 'Logical error' will be printed twice.\"\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/00984_parser_stack_overflow.reference b/tests/queries/0_stateless/00984_parser_stack_overflow.reference\nindex 0cf6a1f96df3..e28ada842c02 100644\n--- a/tests/queries/0_stateless/00984_parser_stack_overflow.reference\n+++ b/tests/queries/0_stateless/00984_parser_stack_overflow.reference\n@@ -1,4 +1,6 @@\n-exceeded\n-exceeded\n+1\n+1\n+0\n+0\n 20002\n 1\ndiff --git a/tests/queries/0_stateless/00984_parser_stack_overflow.sh b/tests/queries/0_stateless/00984_parser_stack_overflow.sh\nindex a7854b91ee27..dc836388cf6c 100755\n--- a/tests/queries/0_stateless/00984_parser_stack_overflow.sh\n+++ b/tests/queries/0_stateless/00984_parser_stack_overflow.sh\n@@ -9,10 +9,10 @@ CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n . \"$CURDIR\"/../shell_config.sh\n \n # Too deep recursion\n-perl -e 'print \"(\" x 10000' | $CLICKHOUSE_CURL -sS \"$CLICKHOUSE_URL\" --data-binary @- | grep -oF 'exceeded'\n-perl -e 'print \"SELECT \" . (\"[\" x 10000)' | $CLICKHOUSE_CURL -sS \"$CLICKHOUSE_URL\" --data-binary @- | grep -oF 'exceeded'\n-perl -e 'print \"SELECT \" . (\"([\" x 5000)' | $CLICKHOUSE_CURL -sS \"$CLICKHOUSE_URL\" --data-binary @- | grep -oF 'exceeded'\n-perl -e 'print \"SELECT 1\" . (\"+1\" x 10000)' | $CLICKHOUSE_CURL -sS \"$CLICKHOUSE_URL\" --data-binary @- | grep -oF 'exceeded'\n+perl -e 'print \"(\" x 10000' | $CLICKHOUSE_CURL -sS \"$CLICKHOUSE_URL\" --data-binary @- | grep -cP 'exceeded|too large'\n+perl -e 'print \"SELECT \" . (\"[\" x 10000)' | $CLICKHOUSE_CURL -sS \"$CLICKHOUSE_URL\" --data-binary @- | grep -cP 'exceeded|too large'\n+perl -e 'print \"SELECT \" . (\"([\" x 5000)' | $CLICKHOUSE_CURL -sS \"$CLICKHOUSE_URL\" --data-binary @- | grep -cP 'exceeded|too large'\n+perl -e 'print \"SELECT 1\" . (\"+1\" x 10000)' | $CLICKHOUSE_CURL -sS \"$CLICKHOUSE_URL\" --data-binary @- | grep -cP 'exceeded|too large'\n \n # But this is Ok\n perl -e 'print \"SELECT 1\" . (\",1\" x 10000)' | $CLICKHOUSE_CURL -sS \"$CLICKHOUSE_URL\" --data-binary @- | wc -c\ndiff --git a/tests/queries/0_stateless/02985_parser_check_stack_size.reference b/tests/queries/0_stateless/02985_parser_check_stack_size.reference\nnew file mode 100644\nindex 000000000000..f83e0818db29\n--- /dev/null\n+++ b/tests/queries/0_stateless/02985_parser_check_stack_size.reference\n@@ -0,0 +1,1 @@\n+TOO_DEEP\ndiff --git a/tests/queries/0_stateless/02985_parser_check_stack_size.sh b/tests/queries/0_stateless/02985_parser_check_stack_size.sh\nnew file mode 100755\nindex 000000000000..c91a0a3eacca\n--- /dev/null\n+++ b/tests/queries/0_stateless/02985_parser_check_stack_size.sh\n@@ -0,0 +1,7 @@\n+#!/usr/bin/env bash\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+$CLICKHOUSE_CLIENT --query \"select 'create table test (x ' || repeat('Array(', 10000) || 'UInt64' || repeat(')', 10000) || ') engine=Memory' format TSVRaw\" | $CLICKHOUSE_CURL \"${CLICKHOUSE_URL}&max_parser_depth=100000\" --data-binary @- | grep -o -F 'TOO_DEEP'\n",
  "problem_statement": "Setting max_parser_depth too high can cause Segmentation fault\n**Describe what's wrong**\r\n\r\nYou can use [max_parser_depth](https://clickhouse.com/docs/en/operations/settings/settings#max_parser_depth) to control the stack size. It's default value is 1000. \r\nUser can increase it if there are really large queries that exceed this limit.\r\n\r\nBut setting it too high (in my example below to 100,000) can crash the server with Segmentation fault. \r\n\r\n**Does it reproduce on the most recent release?**\r\nYes, I tested this on `24.2.1.354`\r\n\r\n\r\n**How to reproduce**\r\n\r\n1). Install CH binary. \r\n2). Use clickhouse-client to run following query: \r\n\r\n> ./clickhouse client -q \"select 'create table test (x ' || repeat('Array(', 10000) || 'UInt64' || repeat(')', 10000) || ') engine=Memory' format TSVRaw\" | curl 'http://localhost:8123?max_parser_depth=100000' --data-binary @-\r\n\r\n3). It will crash with below info: \r\n\r\n```\r\n2024.02.06 06:02:48.952240 [ 2185 ] {} <Trace> DynamicQueryHandler: Request URI: /?max_parser_depth=100000\r\n2024.02.06 06:02:48.952547 [ 2185 ] {} <Trace> HTTP-Session: efee4087-7f45-4101-8997-8127f5ad46ad Creating query context from session context, user_id: 94309d50-4f52-5250-31bd-74fecac179db, parent context user: default\r\n2024.02.06 06:02:48.971146 [ 2183 ] {} <Trace> BaseDaemon: Received signal 11\r\n2024.02.06 06:02:48.971400 [ 2832 ] {} <Fatal> BaseDaemon: ########## Short fault info ############\r\n2024.02.06 06:02:48.971444 [ 2832 ] {} <Fatal> BaseDaemon: (version 24.2.1.354 (official build), build id: EC9C6D940F82DA4246E3BA422F5253E4A410D8DD, git hash: d8555af44836d6ecf4ce2d9bae04b1e7d7ae8f6b) (from thread 2185) Received signal 11\r\n2024.02.06 06:02:48.971578 [ 2832 ] {} <Fatal> BaseDaemon: Signal description: Segmentation fault\r\n2024.02.06 06:02:48.971651 [ 2832 ] {} <Fatal> BaseDaemon: Address: 0x7f0fb71feff8. Access: write. Attempted access has violated the permissions assigned to the memory area.\r\n2024.02.06 06:02:48.971678 [ 2832 ] {} <Fatal> BaseDaemon: Stack trace: 0x00000000131d5d09\r\n2024.02.06 06:02:48.971743 [ 2832 ] {} <Fatal> BaseDaemon: ########################################\r\n2024.02.06 06:02:48.971763 [ 2832 ] {} <Fatal> BaseDaemon: (version 24.2.1.354 (official build), build id: EC9C6D940F82DA4246E3BA422F5253E4A410D8DD, git hash: d8555af44836d6ecf4ce2d9bae04b1e7d7ae8f6b) (from thread 2185) (query_id: fbddfcf2-28db-4868-afc6-7a83e888911d) (query: ) Received signal Segmentation fault (11)\r\n2024.02.06 06:02:48.971782 [ 2832 ] {} <Fatal> BaseDaemon: Address: 0x7f0fb71feff8. Access: write. Attempted access has violated the permissions assigned to the memory area.\r\n2024.02.06 06:02:48.971796 [ 2832 ] {} <Fatal> BaseDaemon: Stack trace: 0x00000000131d5d09\r\n2024.02.06 06:02:48.971873 [ 2832 ] {} <Fatal> BaseDaemon: 2. DB::ParserIdentifier::parseImpl(DB::IParser::Pos&, std::shared_ptr<DB::IAST>&, DB::Expected&) @ 0x00000000131d5d09 in /home/ubuntu/clickhouse\r\n2024.02.06 06:02:49.000662 [ 2815 ] {} <Trace> AsynchronousMetrics: MemoryTracking: was 423.95 MiB, peak 423.95 MiB, free memory in arenas 11.51 MiB, will set to 431.38 MiB (RSS), difference: 7.43 MiB\r\n2024.02.06 06:02:49.147894 [ 2832 ] {} <Fatal> BaseDaemon: Integrity check of the executable successfully passed (checksum: 6FD11E78D45680053EF89061AE811EC8)\r\n2024.02.06 06:02:49.147954 [ 2832 ] {} <Information> SentryWriter: Not sending crash report\r\n2024.02.06 06:02:49.147979 [ 2832 ] {} <Fatal> BaseDaemon: Report this error to https://github.com/ClickHouse/ClickHouse/issues\r\n2024.02.06 06:02:49.148107 [ 2832 ] {} <Fatal> BaseDaemon: Changed settings: max_parser_depth = 100000\r\n2024.02.06 06:02:50.162727 [ 2209 ] {} <Debug> DNSResolver: Updating DNS cache\r\n2024.02.06 06:02:50.162809 [ 2209 ] {} <Debug> DNSResolver: Updated DNS cache\r\nSegmentation fault (core dumped)\r\n```\r\n\r\nPotential workaround: \r\nHave a check in [checkStackSize](https://github.com/ClickHouse/ClickHouse/blob/ea6f90b4f2c3cc2f7d8b846c769b7f3e84907e47/src/Common/checkStackSize.cpp) to avoid this problem. \r\n\r\n\n",
  "hints_text": "",
  "created_at": "2024-02-26T22:35:03Z",
  "modified_files": [
    "src/AggregateFunctions/AggregateFunctionCount.h",
    "src/AggregateFunctions/AggregateFunctionFactory.cpp",
    "src/AggregateFunctions/Combinators/AggregateFunctionIf.cpp",
    "src/AggregateFunctions/Combinators/AggregateFunctionNull.h",
    "src/Client/ConnectionEstablisher.h",
    "src/Client/MultiplexedConnections.cpp",
    "src/Client/PacketReceiver.h",
    "src/Columns/ColumnArray.cpp",
    "src/Columns/ColumnNullable.cpp",
    "src/Columns/getLeastSuperColumn.cpp",
    "src/Common/Fiber.h",
    "src/Common/SensitiveDataMasker.cpp",
    "src/Common/SipHash.h",
    "src/Common/StackTrace.cpp",
    "src/Common/checkStackSize.cpp",
    "src/Coordination/KeeperStorage.cpp",
    "src/Core/MySQL/PacketEndpoint.cpp",
    "src/DataTypes/DataTypeAggregateFunction.cpp",
    "src/DataTypes/DataTypeCustomSimpleAggregateFunction.cpp",
    "src/Databases/MySQL/MaterializedMySQLSyncThread.cpp",
    "src/Functions/EmptyImpl.h",
    "src/Functions/FunctionsComparison.h",
    "src/Functions/FunctionsConversion.h",
    "src/Functions/FunctionsLogical.cpp",
    "src/Functions/trap.cpp",
    "src/Interpreters/Aggregator.cpp",
    "src/Interpreters/ArrayJoinedColumnsVisitor.h",
    "src/Interpreters/ClientInfo.cpp",
    "src/Interpreters/CrossToInnerJoinVisitor.cpp",
    "src/Interpreters/DatabaseAndTableWithAlias.cpp",
    "src/Interpreters/HashJoin.cpp",
    "src/Interpreters/InJoinSubqueriesPreprocessor.cpp",
    "src/Interpreters/InterpreterSelectWithUnionQuery.cpp",
    "src/Interpreters/JoinToSubqueryTransformVisitor.cpp",
    "src/Interpreters/MergeJoin.cpp",
    "src/Interpreters/MySQL/InterpretersMySQLDDLQuery.cpp",
    "src/Interpreters/ProcessList.cpp",
    "src/Interpreters/Set.cpp",
    "src/Interpreters/SetVariants.cpp",
    "src/Interpreters/TablesStatus.cpp",
    "src/Interpreters/TranslateQualifiedNamesVisitor.cpp",
    "src/Interpreters/evaluateConstantExpression.cpp",
    "src/Interpreters/getHeaderForProcessingStage.cpp",
    "src/Parsers/ExpressionElementParsers.cpp",
    "src/Parsers/IParser.h",
    "src/Processors/Formats/Impl/JSONEachRowRowInputFormat.cpp",
    "src/Processors/Formats/RowInputFormatWithDiagnosticInfo.cpp",
    "src/Processors/Sources/WaitForAsyncInsertSource.h",
    "src/Processors/Transforms/CreatingSetsTransform.cpp",
    "src/Processors/Transforms/getSourceFromASTInsertQuery.cpp",
    "src/QueryPipeline/ExecutionSpeedLimits.cpp",
    "src/QueryPipeline/RemoteQueryExecutorReadContext.h",
    "src/Server/HTTPHandlerFactory.cpp",
    "src/Server/TCPHandler.cpp",
    "src/Storages/MergeTree/DataPartsExchange.cpp",
    "src/Storages/MergeTree/EphemeralLockInZooKeeper.cpp",
    "src/Storages/MergeTree/MergeTreeData.cpp",
    "src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp",
    "src/Storages/MergeTree/MergeTreeDataWriter.cpp",
    "src/Storages/MergeTree/MergeTreeIndexConditionBloomFilter.cpp",
    "src/Storages/MergeTree/MergeTreeIndexConditionBloomFilter.h",
    "src/Storages/MergeTree/MergeTreeIndexGranularityInfo.cpp",
    "src/Storages/StorageJoin.cpp",
    "src/Storages/StorageLog.cpp",
    "src/Storages/StorageReplicatedMergeTree.cpp",
    "src/Storages/StorageView.cpp",
    "src/Storages/System/StorageSystemStackTrace.cpp",
    "src/Storages/transformQueryForExternalDatabase.cpp",
    "utils/check-style/check-style"
  ],
  "modified_test_files": [
    "tests/queries/0_stateless/00984_parser_stack_overflow.reference",
    "tests/queries/0_stateless/00984_parser_stack_overflow.sh",
    "b/tests/queries/0_stateless/02985_parser_check_stack_size.reference",
    "b/tests/queries/0_stateless/02985_parser_check_stack_size.sh"
  ]
}