{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 68131,
  "instance_id": "ClickHouse__ClickHouse-68131",
  "issue_numbers": [
    "68403"
  ],
  "base_commit": "b64af2812f599f89779995b31b96eaee863ce9df",
  "patch": "diff --git a/src/Processors/Formats/Impl/ArrowColumnToCHColumn.cpp b/src/Processors/Formats/Impl/ArrowColumnToCHColumn.cpp\nindex fb56fdd4fe0a..77d5867c5540 100644\n--- a/src/Processors/Formats/Impl/ArrowColumnToCHColumn.cpp\n+++ b/src/Processors/Formats/Impl/ArrowColumnToCHColumn.cpp\n@@ -758,6 +758,15 @@ static ColumnWithTypeAndName readNonNullableColumnFromArrowColumn(\n                     case TypeIndex::IPv6:\n                         return readIPv6ColumnFromBinaryData(arrow_column, column_name);\n                     /// ORC format outputs big integers as binary column, because there is no fixed binary in ORC.\n+                    ///\n+                    /// When ORC/Parquet file says the type is \"byte array\" or \"fixed len byte array\",\n+                    /// but the clickhouse query says to interpret the column as e.g. Int128, it\n+                    /// may mean one of two things:\n+                    ///  * The byte array is the 16 bytes of Int128, little-endian.\n+                    ///  * The byte array is an ASCII string containing the Int128 formatted in base 10.\n+                    /// There's no reliable way to distinguish these cases. We just guess: if the\n+                    /// byte array is variable-length, and the length is different from sizeof(type),\n+                    /// we parse as text, otherwise as binary.\n                     case TypeIndex::Int128:\n                         return readColumnWithBigNumberFromBinaryData<ColumnInt128>(arrow_column, column_name, type_hint);\n                     case TypeIndex::UInt128:\ndiff --git a/src/Processors/Formats/Impl/ParquetBlockInputFormat.cpp b/src/Processors/Formats/Impl/ParquetBlockInputFormat.cpp\nindex bc5e82921923..c6167e572dff 100644\n--- a/src/Processors/Formats/Impl/ParquetBlockInputFormat.cpp\n+++ b/src/Processors/Formats/Impl/ParquetBlockInputFormat.cpp\n@@ -25,6 +25,7 @@\n #include <DataTypes/DataTypeNullable.h>\n #include <Common/FieldVisitorsAccurateComparison.h>\n #include <Processors/Formats/Impl/Parquet/ParquetRecordReader.h>\n+#include <Interpreters/convertFieldToType.h>\n \n namespace CurrentMetrics\n {\n@@ -54,7 +55,7 @@ namespace ErrorCodes\n         }                                                              \\\n     } while (false)\n \n-/// Decode min/max value from column chunk statistics.\n+/// Decode min/max value from column chunk statistics. Returns Null if missing or unsupported.\n ///\n /// There are two questionable decisions in this implementation:\n ///  * We parse the value from the encoded byte string instead of casting the parquet::Statistics\n@@ -62,7 +63,7 @@ namespace ErrorCodes\n ///  * We dispatch based on the parquet logical+converted+physical type instead of the ClickHouse type.\n /// The idea is that this is similar to what we'll have to do when reimplementing Parquet parsing in\n /// ClickHouse instead of using Arrow (for speed). So, this is an exercise in parsing Parquet manually.\n-static std::optional<Field> decodePlainParquetValueSlow(const std::string & data, parquet::Type::type physical_type, const parquet::ColumnDescriptor & descr)\n+static Field decodePlainParquetValueSlow(const std::string & data, parquet::Type::type physical_type, const parquet::ColumnDescriptor & descr, TypeIndex type_hint)\n {\n     using namespace parquet;\n \n@@ -118,8 +119,6 @@ static std::optional<Field> decodePlainParquetValueSlow(const std::string & data\n         if (data.size() != size || size < 1 || size > 32)\n             throw Exception(ErrorCodes::CANNOT_PARSE_NUMBER, \"Unexpected decimal size: {} (actual {})\", size, data.size());\n \n-        /// For simplicity, widen all decimals to 256-bit. It should compare correctly with values\n-        /// of different bitness.\n         Int256 val = 0;\n         memcpy(&val, data.data(), size);\n         if (big_endian)\n@@ -128,7 +127,19 @@ static std::optional<Field> decodePlainParquetValueSlow(const std::string & data\n         if (size < 32 && (val >> (size * 8 - 1)) != 0)\n             val |= ~((Int256(1) << (size * 8)) - 1);\n \n-        return Field(DecimalField<Decimal256>(Decimal256(val), static_cast<UInt32>(scale)));\n+        auto narrow = [&](auto x) -> Field\n+        {\n+            memcpy(&x, &val, sizeof(x));\n+            return Field(DecimalField<decltype(x)>(x, static_cast<UInt32>(scale)));\n+        };\n+        if (size <= 4)\n+            return narrow(Decimal32(0));\n+        else if (size <= 8)\n+            return narrow(Decimal64(0));\n+        else if (size <= 16)\n+            return narrow(Decimal128(0));\n+        else\n+            return narrow(Decimal256(0));\n     }\n     while (false);\n \n@@ -185,8 +196,6 @@ static std::optional<Field> decodePlainParquetValueSlow(const std::string & data\n         return Field(val);\n     }\n \n-    /// Strings.\n-\n     if (physical_type == Type::type::BYTE_ARRAY || physical_type == Type::type::FIXED_LEN_BYTE_ARRAY)\n     {\n         /// Arrow's parquet decoder handles missing min/max values slightly incorrectly.\n@@ -213,14 +222,31 @@ static std::optional<Field> decodePlainParquetValueSlow(const std::string & data\n         /// TODO: Remove this workaround either when we implement our own Parquet decoder that\n         ///       doesn't have this bug, or if it's fixed in Arrow.\n         if (data.empty())\n-            return std::nullopt;\n+            return Field();\n \n+        /// Long integers, encoded either as text or as little-endian bytes.\n+        /// The parquet file doesn't know that it's numbers, so the min/max are produced by comparing\n+        /// strings lexicographically. So these min and max are mostly useless to us.\n+        /// There's one case where they're not useless: min == max; currently we don't make use of this.\n+        switch (type_hint)\n+        {\n+            case TypeIndex::UInt128:\n+            case TypeIndex::UInt256:\n+            case TypeIndex::Int128:\n+            case TypeIndex::Int256:\n+            case TypeIndex::IPv6:\n+                return Field();\n+            default: break;\n+        }\n+\n+        /// Strings.\n         return Field(data);\n     }\n \n-    /// This one's deprecated in Parquet.\n+    /// This type is deprecated in Parquet.\n+    /// TODO: But turns out it's still used in practice, we should support it.\n     if (physical_type == Type::type::INT96)\n-        throw Exception(ErrorCodes::CANNOT_PARSE_NUMBER, \"Parquet INT96 type is deprecated and not supported\");\n+        return Field();\n \n     /// Integers.\n \n@@ -283,15 +309,13 @@ static std::vector<Range> getHyperrectangleForRowGroup(const parquet::FileMetaDa\n             continue;\n         auto stats = it->second;\n \n-        auto default_value = [&]() -> Field\n-        {\n-            DataTypePtr type = header.getByPosition(idx).type;\n-            if (type->lowCardinality())\n-                type = assert_cast<const DataTypeLowCardinality &>(*type).getDictionaryType();\n-            if (type->isNullable())\n-                type = assert_cast<const DataTypeNullable &>(*type).getNestedType();\n-            return type->getDefault();\n-        };\n+        DataTypePtr type = header.getByPosition(idx).type;\n+        if (type->lowCardinality())\n+            type = assert_cast<const DataTypeLowCardinality &>(*type).getDictionaryType();\n+        if (type->isNullable())\n+            type = assert_cast<const DataTypeNullable &>(*type).getNestedType();\n+        Field default_value = type->getDefault();\n+        TypeIndex type_index = type->getTypeId();\n \n         /// Only primitive fields are supported, not arrays, maps, tuples, or Nested.\n         /// Arrays, maps, and Nested can't be meaningfully supported because Parquet only has min/max\n@@ -299,14 +323,47 @@ static std::vector<Range> getHyperrectangleForRowGroup(const parquet::FileMetaDa\n         /// Same limitation for tuples, but maybe it would make sense to have some kind of tuple\n         /// expansion in KeyCondition to accept ranges per element instead of whole tuple.\n \n-        std::optional<Field> min;\n-        std::optional<Field> max;\n+        Field min;\n+        Field max;\n         if (stats->HasMinMax())\n         {\n             try\n             {\n-                min = decodePlainParquetValueSlow(stats->EncodeMin(), stats->physical_type(), *stats->descr());\n-                max = decodePlainParquetValueSlow(stats->EncodeMax(), stats->physical_type(), *stats->descr());\n+                min = decodePlainParquetValueSlow(stats->EncodeMin(), stats->physical_type(), *stats->descr(), type_index);\n+                max = decodePlainParquetValueSlow(stats->EncodeMax(), stats->physical_type(), *stats->descr(), type_index);\n+\n+                /// If the data type in parquet file substantially differs from the requested data type,\n+                /// it's sometimes correct to just typecast the min/max values.\n+                /// Other times it's incorrect, e.g.:\n+                ///   INSERT INTO FUNCTION file('t.parquet', Parquet, 'x String') VALUES ('1'), ('100'), ('2');\n+                ///   SELECT * FROM file('t.parquet', Parquet, 'x Int64') WHERE x >= 3;\n+                /// If we just typecast min/max from string to integer, this query will incorrectly return empty result.\n+                /// Allow conversion in some simple cases, otherwise ignore the min/max values.\n+                auto min_type = min.getType();\n+                auto max_type = max.getType();\n+                min = convertFieldToType(min, *type);\n+                max = convertFieldToType(max, *type);\n+                auto ok_cast = [&](Field::Types::Which from, Field::Types::Which to) -> bool\n+                {\n+                    if (from == to)\n+                        return true;\n+                    /// Decimal -> wider decimal.\n+                    if (Field::isDecimal(from) || Field::isDecimal(to))\n+                        return Field::isDecimal(from) && Field::isDecimal(to) && to >= from;\n+                    /// Integer -> IP.\n+                    if (to == Field::Types::IPv4)\n+                        return from == Field::Types::UInt64;\n+                    /// Disable index for everything else, especially string <-> number.\n+                    return false;\n+                };\n+                if (!(ok_cast(min_type, min.getType()) && ok_cast(max_type, max.getType())) &&\n+                    !(min == max) &&\n+                    !(min_type == Field::Types::Int64 && min.getType() == Field::Types::UInt64 && min.safeGet<Int64>() >= 0) &&\n+                    !(max_type == Field::Types::UInt64 && max.getType() == Field::Types::Int64 && max.safeGet<UInt64>() <= UInt64(INT64_MAX)))\n+                {\n+                    min = Field();\n+                    max = Field();\n+                }\n             }\n             catch (Exception & e)\n             {\n@@ -328,7 +385,7 @@ static std::vector<Range> getHyperrectangleForRowGroup(const parquet::FileMetaDa\n         {\n             /// Single-point range containing either the default value of one of the infinities.\n             if (null_as_default)\n-                hyperrectangle[idx].right = hyperrectangle[idx].left = default_value();\n+                hyperrectangle[idx].right = hyperrectangle[idx].left = default_value;\n             else\n                 hyperrectangle[idx].right = hyperrectangle[idx].left;\n             continue;\n@@ -339,32 +396,31 @@ static std::vector<Range> getHyperrectangleForRowGroup(const parquet::FileMetaDa\n             if (null_as_default)\n             {\n                 /// Make sure the range contains the default value.\n-                Field def = default_value();\n-                if (min.has_value() && applyVisitor(FieldVisitorAccurateLess(), def, *min))\n-                    min = def;\n-                if (max.has_value() && applyVisitor(FieldVisitorAccurateLess(), *max, def))\n-                    max = def;\n+                if (!min.isNull() && applyVisitor(FieldVisitorAccurateLess(), default_value, min))\n+                    min = default_value;\n+                if (!max.isNull() && applyVisitor(FieldVisitorAccurateLess(), max, default_value))\n+                    max = default_value;\n             }\n             else\n             {\n                 /// Make sure the range reaches infinity on at least one side.\n-                if (min.has_value() && max.has_value())\n-                    min.reset();\n+                if (!min.isNull() && !max.isNull())\n+                    min = Field();\n             }\n         }\n         else\n         {\n             /// If the column doesn't have nulls, exclude both infinities.\n-            if (!min.has_value())\n+            if (min.isNull())\n                 hyperrectangle[idx].left_included = false;\n-            if (!max.has_value())\n+            if (max.isNull())\n                 hyperrectangle[idx].right_included = false;\n         }\n \n-        if (min.has_value())\n-            hyperrectangle[idx].left = std::move(min.value());\n-        if (max.has_value())\n-            hyperrectangle[idx].right = std::move(max.value());\n+        if (!min.isNull())\n+            hyperrectangle[idx].left = std::move(min);\n+        if (!max.isNull())\n+            hyperrectangle[idx].right = std::move(max);\n     }\n \n     return hyperrectangle;\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02786_parquet_big_integer_compatibility.reference b/tests/queries/0_stateless/02786_parquet_big_integer_compatibility.reference\nindex 7764974255b0..877bb5f390f8 100644\n--- a/tests/queries/0_stateless/02786_parquet_big_integer_compatibility.reference\n+++ b/tests/queries/0_stateless/02786_parquet_big_integer_compatibility.reference\n@@ -1,1 +1,2 @@\n 424242424242424242424242424242424242424242424242424242\n+22707864971053448441042714569797161695738549521977760418632926980540162388532\ndiff --git a/tests/queries/0_stateless/02786_parquet_big_integer_compatibility.sh b/tests/queries/0_stateless/02786_parquet_big_integer_compatibility.sh\nindex 8865b2e7aabf..0f590027f194 100755\n--- a/tests/queries/0_stateless/02786_parquet_big_integer_compatibility.sh\n+++ b/tests/queries/0_stateless/02786_parquet_big_integer_compatibility.sh\n@@ -5,5 +5,8 @@ CUR_DIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n # shellcheck source=../shell_config.sh\n . \"$CUR_DIR\"/../shell_config.sh\n \n+# This is parsed as text.\n $CLICKHOUSE_LOCAL -q \"select toString(424242424242424242424242424242424242424242424242424242::UInt256) as x format Parquet\" | $CLICKHOUSE_LOCAL --input-format=Parquet --structure='x UInt256' -q \"select * from table\"\n \n+# But this is parsed as binary because text length happens to be 32 bytes. Not ideal.\n+$CLICKHOUSE_LOCAL -q \"select toString(42424242424242424242424242424242::UInt256) as x format Parquet\" | $CLICKHOUSE_LOCAL --input-format=Parquet --structure='x UInt256' -q \"select * from table\"\ndiff --git a/tests/queries/0_stateless/02841_parquet_filter_pushdown.reference b/tests/queries/0_stateless/02841_parquet_filter_pushdown.reference\nindex 4adf418bcc74..8003b9cb626d 100644\n--- a/tests/queries/0_stateless/02841_parquet_filter_pushdown.reference\n+++ b/tests/queries/0_stateless/02841_parquet_filter_pushdown.reference\n@@ -71,3 +71,5 @@ d256\tNullable(Decimal(76, 40))\n 500\t244750\n 500\t244750\n 500\t244750\n+42\n+100\ndiff --git a/tests/queries/0_stateless/02841_parquet_filter_pushdown.sql b/tests/queries/0_stateless/02841_parquet_filter_pushdown.sql\nindex 950485d53f0c..52caee50b326 100644\n--- a/tests/queries/0_stateless/02841_parquet_filter_pushdown.sql\n+++ b/tests/queries/0_stateless/02841_parquet_filter_pushdown.sql\n@@ -131,3 +131,9 @@ select count(), sum(number) from file('02841.parquet', Parquet, 'number UInt64,\n select count(), sum(number) from file('02841.parquet') where indexHint(string_or_null == ''); -- quirk with infinities\n select count(), sum(number) from file('02841.parquet', Parquet, 'number UInt64, string_or_null String') where indexHint(string_or_null == '');\n select count(), sum(number) from file('02841.parquet', Parquet, 'number UInt64, nEgAtIvE_oR_nUlL Int64') where indexHint(nEgAtIvE_oR_nUlL > -50) settings input_format_parquet_case_insensitive_column_matching = 1;\n+\n+-- Bad type conversions.\n+insert into function file('02841.parquet') select 42 as x;\n+select * from file('02841.parquet', Parquet, 'x Nullable(String)') where x not in (1);\n+insert into function file('t.parquet', Parquet, 'x String') values ('1'), ('100'), ('2');\n+select * from file('t.parquet', Parquet, 'x Int64') where x >= 3;\n",
  "problem_statement": "Parquet query failed with `In` decimal column filter\n\r\nAfter https://github.com/ClickHouse/ClickHouse/pull/68135,  let's execute the following sql:\r\n\r\n```sql \r\nCREATE TABLE file_engine_table (a DECIMAL(9,2)) ENGINE=File(Parquet);\r\nINSERT INTO file_engine_table VALUES (2.00), (4.01), (5.00) , (10.00);\r\nselect * from file_engine_table where a in (5.00, 6.00, 8.00, 10.000, 20.00);\r\n```\r\n\r\nwe get following error message:\r\n``` shell\r\nCode: 170. DB::Exception: Bad get: has Decimal256, requested Decimal32: (in file/uri ./store/769/76981421-d626-4639-b709-fd14c149a5ad//data.Parquet): While executing ParquetBlockInputFormat: While executing File. (BAD_GET) (version 24.9.1.1)\r\n```\n",
  "hints_text": "",
  "created_at": "2024-08-09T21:16:43Z",
  "modified_files": [
    "src/Processors/Formats/Impl/ArrowColumnToCHColumn.cpp",
    "src/Processors/Formats/Impl/ParquetBlockInputFormat.cpp"
  ],
  "modified_test_files": [
    "tests/queries/0_stateless/02786_parquet_big_integer_compatibility.reference",
    "tests/queries/0_stateless/02786_parquet_big_integer_compatibility.sh",
    "tests/queries/0_stateless/02841_parquet_filter_pushdown.reference",
    "tests/queries/0_stateless/02841_parquet_filter_pushdown.sql"
  ]
}