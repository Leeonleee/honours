{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 45615,
  "instance_id": "ClickHouse__ClickHouse-45615",
  "issue_numbers": [
    "45195"
  ],
  "base_commit": "297516a08470a4c33bf5dd80f908b3d48d953c2c",
  "patch": "diff --git a/src/Compression/CompressionCodecDelta.cpp b/src/Compression/CompressionCodecDelta.cpp\nindex 655ab92b5acc..1d27a0784c68 100644\n--- a/src/Compression/CompressionCodecDelta.cpp\n+++ b/src/Compression/CompressionCodecDelta.cpp\n@@ -30,7 +30,7 @@ class CompressionCodecDelta : public ICompressionCodec\n     bool isGenericCompression() const override { return false; }\n \n private:\n-    UInt8 delta_bytes_size;\n+    const UInt8 delta_bytes_size;\n };\n \n \n@@ -68,8 +68,8 @@ void compressDataForType(const char * source, UInt32 source_size, char * dest)\n     if (source_size % sizeof(T) != 0)\n         throw Exception(ErrorCodes::CANNOT_COMPRESS, \"Cannot delta compress, data size {}  is not aligned to {}\", source_size, sizeof(T));\n \n-    T prev_src{};\n-    const char * source_end = source + source_size;\n+    T prev_src = 0;\n+    const char * const source_end = source + source_size;\n     while (source < source_end)\n     {\n         T curr_src = unalignedLoad<T>(source);\n@@ -84,17 +84,17 @@ void compressDataForType(const char * source, UInt32 source_size, char * dest)\n template <typename T>\n void decompressDataForType(const char * source, UInt32 source_size, char * dest, UInt32 output_size)\n {\n-    const char * output_end = dest + output_size;\n+    const char * const output_end = dest + output_size;\n \n     if (source_size % sizeof(T) != 0)\n         throw Exception(ErrorCodes::CANNOT_DECOMPRESS, \"Cannot delta decompress, data size {}  is not aligned to {}\", source_size, sizeof(T));\n \n     T accumulator{};\n-    const char * source_end = source + source_size;\n+    const char * const source_end = source + source_size;\n     while (source < source_end)\n     {\n         accumulator += unalignedLoad<T>(source);\n-        if (dest + sizeof(accumulator) > output_end)\n+        if (dest + sizeof(accumulator) > output_end) [[unlikely]]\n             throw Exception(ErrorCodes::CANNOT_DECOMPRESS, \"Cannot decompress the data\");\n         unalignedStore<T>(dest, accumulator);\n \n@@ -140,7 +140,7 @@ void CompressionCodecDelta::doDecompressData(const char * source, UInt32 source_\n \n     UInt8 bytes_size = source[0];\n \n-    if (bytes_size == 0)\n+    if (!(bytes_size == 1 || bytes_size == 2 || bytes_size == 4 || bytes_size == 8))\n         throw Exception(ErrorCodes::CANNOT_DECOMPRESS, \"Cannot decompress. File has wrong header\");\n \n     UInt8 bytes_to_skip = uncompressed_size % bytes_size;\n@@ -190,7 +190,7 @@ UInt8 getDeltaBytesSize(const IDataType * column_type)\n void registerCodecDelta(CompressionCodecFactory & factory)\n {\n     UInt8 method_code = static_cast<UInt8>(CompressionMethodByte::Delta);\n-    factory.registerCompressionCodecWithType(\"Delta\", method_code, [&](const ASTPtr & arguments, const IDataType * column_type) -> CompressionCodecPtr\n+    auto codec_builder = [&](const ASTPtr & arguments, const IDataType * column_type) -> CompressionCodecPtr\n     {\n         UInt8 delta_bytes_size = 0;\n \n@@ -215,7 +215,8 @@ void registerCodecDelta(CompressionCodecFactory & factory)\n         }\n \n         return std::make_shared<CompressionCodecDelta>(delta_bytes_size);\n-    });\n+    };\n+    factory.registerCompressionCodecWithType(\"Delta\", method_code, codec_builder);\n }\n \n CompressionCodecPtr getCompressionCodecDelta(UInt8 delta_bytes_size)\ndiff --git a/src/Compression/CompressionCodecGorilla.cpp b/src/Compression/CompressionCodecGorilla.cpp\nindex cbae30d774e4..50ef94cd6259 100644\n--- a/src/Compression/CompressionCodecGorilla.cpp\n+++ b/src/Compression/CompressionCodecGorilla.cpp\n@@ -11,19 +11,18 @@\n #include <IO/ReadBufferFromMemory.h>\n #include <IO/BitHelpers.h>\n \n+#include <bitset>\n #include <cstring>\n #include <algorithm>\n #include <type_traits>\n \n-#include <bitset>\n-\n \n namespace DB\n {\n \n /** Gorilla column codec implementation.\n  *\n- * Based on Gorilla paper: http://www.vldb.org/pvldb/vol8/p1816-teller.pdf\n+ * Based on Gorilla paper: https://dl.acm.org/doi/10.14778/2824032.2824078\n  *\n  * This codec is best used against monotonic floating sequences, like CPU usage percentage\n  * or any other gauge.\n@@ -125,7 +124,7 @@ class CompressionCodecGorilla : public ICompressionCodec\n     bool isGenericCompression() const override { return false; }\n \n private:\n-    UInt8 data_bytes_size;\n+    const UInt8 data_bytes_size;\n };\n \n \n@@ -139,7 +138,7 @@ namespace ErrorCodes\n namespace\n {\n \n-constexpr inline UInt8 getBitLengthOfLength(UInt8 data_bytes_size)\n+constexpr UInt8 getBitLengthOfLength(UInt8 data_bytes_size)\n {\n     // 1-byte value is 8 bits, and we need 4 bits to represent 8 : 1000,\n     // 2-byte         16 bits        =>    5\n@@ -147,21 +146,20 @@ constexpr inline UInt8 getBitLengthOfLength(UInt8 data_bytes_size)\n     // 8-byte         64 bits        =>    7\n     const UInt8 bit_lengths[] = {0, 4, 5, 0, 6, 0, 0, 0, 7};\n     assert(data_bytes_size >= 1 && data_bytes_size < sizeof(bit_lengths) && bit_lengths[data_bytes_size] != 0);\n-\n     return bit_lengths[data_bytes_size];\n }\n \n \n UInt32 getCompressedHeaderSize(UInt8 data_bytes_size)\n {\n-    const UInt8 items_count_size = 4;\n-\n+    constexpr UInt8 items_count_size = 4;\n     return items_count_size + data_bytes_size;\n }\n \n UInt32 getCompressedDataSize(UInt8 data_bytes_size, UInt32 uncompressed_size)\n {\n     const UInt32 items_count = uncompressed_size / data_bytes_size;\n+\n     static const auto DATA_BIT_LENGTH = getBitLengthOfLength(data_bytes_size);\n     // -1 since there must be at least 1 non-zero bit.\n     static const auto LEADING_ZEROES_BIT_LENGTH = DATA_BIT_LENGTH - 1;\n@@ -182,7 +180,7 @@ struct BinaryValueInfo\n };\n \n template <typename T>\n-BinaryValueInfo getLeadingAndTrailingBits(const T & value)\n+BinaryValueInfo getBinaryValueInfo(const T & value)\n {\n     constexpr UInt8 bit_size = sizeof(T) * 8;\n \n@@ -190,28 +188,25 @@ BinaryValueInfo getLeadingAndTrailingBits(const T & value)\n     const UInt8 tz = getTrailingZeroBits(value);\n     const UInt8 data_size = value == 0 ? 0 : static_cast<UInt8>(bit_size - lz - tz);\n \n-    return BinaryValueInfo{lz, data_size, tz};\n+    return {lz, data_size, tz};\n }\n \n template <typename T>\n UInt32 compressDataForType(const char * source, UInt32 source_size, char * dest, UInt32 dest_size)\n {\n-    static const auto DATA_BIT_LENGTH = getBitLengthOfLength(sizeof(T));\n-    // -1 since there must be at least 1 non-zero bit.\n-    static const auto LEADING_ZEROES_BIT_LENGTH = DATA_BIT_LENGTH - 1;\n-\n     if (source_size % sizeof(T) != 0)\n         throw Exception(ErrorCodes::CANNOT_COMPRESS, \"Cannot compress, data size {} is not aligned to {}\", source_size, sizeof(T));\n-    const char * source_end = source + source_size;\n-    const char * dest_start = dest;\n-    const char * dest_end = dest + dest_size;\n+\n+    const char * const source_end = source + source_size;\n+    const char * const dest_start = dest;\n+    const char * const dest_end = dest + dest_size;\n \n     const UInt32 items_count = source_size / sizeof(T);\n \n     unalignedStoreLE<UInt32>(dest, items_count);\n     dest += sizeof(items_count);\n \n-    T prev_value{};\n+    T prev_value = 0;\n     // That would cause first XORed value to be written in-full.\n     BinaryValueInfo prev_xored_info{0, 0, 0};\n \n@@ -226,13 +221,17 @@ UInt32 compressDataForType(const char * source, UInt32 source_size, char * dest,\n \n     BitWriter writer(dest, dest_end - dest);\n \n+    static const auto DATA_BIT_LENGTH = getBitLengthOfLength(sizeof(T));\n+    // -1 since there must be at least 1 non-zero bit.\n+    static const auto LEADING_ZEROES_BIT_LENGTH = DATA_BIT_LENGTH - 1;\n+\n     while (source < source_end)\n     {\n         const T curr_value = unalignedLoadLE<T>(source);\n         source += sizeof(curr_value);\n \n         const auto xored_data = curr_value ^ prev_value;\n-        const BinaryValueInfo curr_xored_info = getLeadingAndTrailingBits(xored_data);\n+        const BinaryValueInfo curr_xored_info = getBinaryValueInfo(xored_data);\n \n         if (xored_data == 0)\n         {\n@@ -265,11 +264,7 @@ UInt32 compressDataForType(const char * source, UInt32 source_size, char * dest,\n template <typename T>\n void decompressDataForType(const char * source, UInt32 source_size, char * dest)\n {\n-    static const auto DATA_BIT_LENGTH = getBitLengthOfLength(sizeof(T));\n-    // -1 since there must be at least 1 non-zero bit.\n-    static const auto LEADING_ZEROES_BIT_LENGTH = DATA_BIT_LENGTH - 1;\n-\n-    const char * source_end = source + source_size;\n+    const char * const source_end = source + source_size;\n \n     if (source + sizeof(UInt32) > source_end)\n         return;\n@@ -277,7 +272,7 @@ void decompressDataForType(const char * source, UInt32 source_size, char * dest)\n     const UInt32 items_count = unalignedLoadLE<UInt32>(source);\n     source += sizeof(items_count);\n \n-    T prev_value{};\n+    T prev_value = 0;\n \n     // decoding first item\n     if (source + sizeof(T) > source_end || items_count < 1)\n@@ -293,13 +288,17 @@ void decompressDataForType(const char * source, UInt32 source_size, char * dest)\n \n     BinaryValueInfo prev_xored_info{0, 0, 0};\n \n+    static const auto DATA_BIT_LENGTH = getBitLengthOfLength(sizeof(T));\n+    // -1 since there must be at least 1 non-zero bit.\n+    static const auto LEADING_ZEROES_BIT_LENGTH = DATA_BIT_LENGTH - 1;\n+\n     // since data is tightly packed, up to 1 bit per value, and last byte is padded with zeroes,\n     // we have to keep track of items to avoid reading more that there is.\n     for (UInt32 items_read = 1; items_read < items_count && !reader.eof(); ++items_read)\n     {\n         T curr_value = prev_value;\n         BinaryValueInfo curr_xored_info = prev_xored_info;\n-        T xored_data{};\n+        T xored_data = 0;\n \n         if (reader.readBit() == 1)\n         {\n@@ -314,7 +313,7 @@ void decompressDataForType(const char * source, UInt32 source_size, char * dest)\n \n             if (curr_xored_info.leading_zero_bits == 0\n                 && curr_xored_info.data_bits == 0\n-                && curr_xored_info.trailing_zero_bits == 0)\n+                && curr_xored_info.trailing_zero_bits == 0) [[unlikely]]\n             {\n                 throw Exception(ErrorCodes::CANNOT_DECOMPRESS, \"Cannot decompress gorilla-encoded data: corrupted input data.\");\n             }\n@@ -403,7 +402,7 @@ UInt32 CompressionCodecGorilla::doCompressData(const char * source, UInt32 sourc\n         break;\n     }\n \n-    return 1 + 1 + result_size;\n+    return 2 + bytes_to_skip + result_size;\n }\n \n void CompressionCodecGorilla::doDecompressData(const char * source, UInt32 source_size, char * dest, UInt32 uncompressed_size) const\ndiff --git a/src/Compression/ICompressionCodec.h b/src/Compression/ICompressionCodec.h\nindex f40404a84f3d..46695f80adbc 100644\n--- a/src/Compression/ICompressionCodec.h\n+++ b/src/Compression/ICompressionCodec.h\n@@ -11,13 +11,6 @@\n namespace DB\n {\n \n-class ICompressionCodec;\n-\n-using CompressionCodecPtr = std::shared_ptr<ICompressionCodec>;\n-using Codecs = std::vector<CompressionCodecPtr>;\n-\n-class IDataType;\n-\n extern \"C\" int LLVMFuzzerTestOneInput(const uint8_t * data, size_t size);\n \n /**\n@@ -120,7 +113,7 @@ class ICompressionCodec : private boost::noncopyable\n     /// Return size of compressed data without header\n     virtual UInt32 getMaxCompressedDataSize(UInt32 uncompressed_size) const { return uncompressed_size; }\n \n-    /// Actually compress data, without header\n+    /// Actually compress data without header\n     virtual UInt32 doCompressData(const char * source, UInt32 source_size, char * dest) const = 0;\n \n     /// Actually decompress data without header\n@@ -134,4 +127,7 @@ class ICompressionCodec : private boost::noncopyable\n     CodecMode decompressMode{CodecMode::Synchronous};\n };\n \n+using CompressionCodecPtr = std::shared_ptr<ICompressionCodec>;\n+using Codecs = std::vector<CompressionCodecPtr>;\n+\n }\ndiff --git a/src/IO/BitHelpers.h b/src/IO/BitHelpers.h\nindex 471d1a3b8050..34173ccd8f95 100644\n--- a/src/IO/BitHelpers.h\n+++ b/src/IO/BitHelpers.h\n@@ -35,28 +35,26 @@ extern const int ATTEMPT_TO_READ_AFTER_EOF;\n \n class BitReader\n {\n-    using BufferType = unsigned __int128;\n-\n-    const char * source_begin;\n+    const char * const source_begin;\n+    const char * const source_end;\n     const char * source_current;\n-    const char * source_end;\n \n-    BufferType bits_buffer;\n-    UInt8 bits_count;\n+    using BufferType = unsigned __int128;\n+    BufferType bits_buffer = 0;\n+\n+    UInt8 bits_count = 0;\n \n public:\n     BitReader(const char * begin, size_t size)\n-        : source_begin(begin),\n-          source_current(begin),\n-          source_end(begin + size),\n-          bits_buffer(0),\n-          bits_count(0)\n+        : source_begin(begin)\n+        , source_end(begin + size)\n+        , source_current(begin)\n     {}\n \n     ~BitReader() = default;\n \n     // reads bits_to_read high-bits from bits_buffer\n-    ALWAYS_INLINE inline UInt64 readBits(UInt8 bits_to_read)\n+    ALWAYS_INLINE UInt64 readBits(UInt8 bits_to_read)\n     {\n         if (bits_to_read > bits_count)\n             fillBitBuffer();\n@@ -64,7 +62,7 @@ class BitReader\n         return getBitsFromBitBuffer<CONSUME>(bits_to_read);\n     }\n \n-    inline UInt8 peekByte()\n+    UInt8 peekByte()\n     {\n         if (bits_count < 8)\n             fillBitBuffer();\n@@ -72,31 +70,31 @@ class BitReader\n         return getBitsFromBitBuffer<PEEK>(8);\n     }\n \n-    ALWAYS_INLINE inline UInt8 readBit()\n+    ALWAYS_INLINE UInt8 readBit()\n     {\n         return static_cast<UInt8>(readBits(1));\n     }\n \n     // skip bits from bits_buffer\n-    inline void skipBufferedBits(UInt8 bits)\n+    void skipBufferedBits(UInt8 bits)\n     {\n         bits_buffer <<= bits;\n         bits_count -= bits;\n     }\n \n \n-    inline bool eof() const\n+    bool eof() const\n     {\n         return bits_count == 0 && source_current >= source_end;\n     }\n \n     // number of bits that was already read by clients with readBits()\n-    inline UInt64 count() const\n+    UInt64 count() const\n     {\n         return (source_current - source_begin) * 8 - bits_count;\n     }\n \n-    inline UInt64 remaining() const\n+    UInt64 remaining() const\n     {\n         return (source_end - source_current) * 8 + bits_count;\n     }\n@@ -105,7 +103,7 @@ class BitReader\n     enum GetBitsMode {CONSUME, PEEK};\n     // read data from internal buffer, if it has not enough bits, result is undefined.\n     template <GetBitsMode mode>\n-    inline UInt64 getBitsFromBitBuffer(UInt8 bits_to_read)\n+    UInt64 getBitsFromBitBuffer(UInt8 bits_to_read)\n     {\n         assert(bits_to_read > 0);\n \n@@ -152,24 +150,22 @@ class BitReader\n \n class BitWriter\n {\n-    using BufferType = unsigned __int128;\n-\n     char * dest_begin;\n-    char * dest_current;\n     char * dest_end;\n+    char * dest_current;\n+\n+    using BufferType = unsigned __int128;\n+    BufferType bits_buffer = 0;\n \n-    BufferType bits_buffer;\n-    UInt8 bits_count;\n+    UInt8 bits_count = 0;\n \n     static constexpr UInt8 BIT_BUFFER_SIZE = sizeof(bits_buffer) * 8;\n \n public:\n     BitWriter(char * begin, size_t size)\n-        : dest_begin(begin),\n-          dest_current(begin),\n-          dest_end(begin + size),\n-          bits_buffer(0),\n-          bits_count(0)\n+        : dest_begin(begin)\n+        , dest_end(begin + size)\n+        , dest_current(begin)\n     {}\n \n     ~BitWriter()\n@@ -178,7 +174,7 @@ class BitWriter\n     }\n \n     // write `bits_to_write` low-bits of `value` to the buffer\n-    inline void writeBits(UInt8 bits_to_write, UInt64 value)\n+    void writeBits(UInt8 bits_to_write, UInt64 value)\n     {\n         assert(bits_to_write > 0);\n \n@@ -199,14 +195,14 @@ class BitWriter\n     }\n \n     // flush contents of bits_buffer to the dest_current, partial bytes are completed with zeroes.\n-    inline void flush()\n+    void flush()\n     {\n         bits_count = (bits_count + 8 - 1) & ~(8 - 1); // align up to 8-bytes, so doFlush will write all data from bits_buffer\n         while (bits_count != 0)\n             doFlush();\n     }\n \n-    inline UInt64 count() const\n+    UInt64 count() const\n     {\n         return (dest_current - dest_begin) * 8 + bits_count;\n     }\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02536_delta_gorilla_corruption.reference b/tests/queries/0_stateless/02536_delta_gorilla_corruption.reference\nnew file mode 100644\nindex 000000000000..82220c1598a5\n--- /dev/null\n+++ b/tests/queries/0_stateless/02536_delta_gorilla_corruption.reference\n@@ -0,0 +1,9 @@\n+Original bug: the same query executed multiple times yielded different results.\n+For unclear reasons this happened only in Release builds, not in Debug builds.\n+0\n+0\n+0\n+The same issue in a much smaller repro happens also in Debug builds\n+0\n+1\n+3\ndiff --git a/tests/queries/0_stateless/02536_delta_gorilla_corruption.sql b/tests/queries/0_stateless/02536_delta_gorilla_corruption.sql\nnew file mode 100644\nindex 000000000000..74b5aa769f19\n--- /dev/null\n+++ b/tests/queries/0_stateless/02536_delta_gorilla_corruption.sql\n@@ -0,0 +1,37 @@\n+-- Tags: no-asan\n+-- no-asan: the flaky check complains that the test sometimes runs > 60 sec on asan builds\n+\n+select 'Original bug: the same query executed multiple times yielded different results.';\n+select 'For unclear reasons this happened only in Release builds, not in Debug builds.';\n+\n+drop table if exists bug_delta_gorilla;\n+\n+create table bug_delta_gorilla\n+(value_bug UInt64 codec (Delta, Gorilla))\n+engine = MergeTree\n+order by tuple()\n+as (select 0 from numbers(30000000));\n+\n+select count(*)\n+from bug_delta_gorilla\n+where 0 <> value_bug;\n+\n+select count(*)\n+from bug_delta_gorilla\n+where 0 <> value_bug;\n+\n+select count(*)\n+from bug_delta_gorilla\n+where 0 <> value_bug;\n+\n+drop table if exists bug_delta_gorilla;\n+\n+select 'The same issue in a much smaller repro happens also in Debug builds';\n+\n+create table bug_delta_gorilla (val UInt64 codec (Delta, Gorilla))\n+engine = MergeTree\n+order by val;\n+insert into bug_delta_gorilla values (0)(1)(3);\n+select * from bug_delta_gorilla;\n+\n+drop table if exists bug_delta_gorilla;\n",
  "problem_statement": "data corruption on delta+gorilla+lz4 codec pipeline\n**Describe what's wrong**\r\n\r\nI have dataset from sensors that was corrupted when using codec (Delta, Gorilla, LZ4)\r\n\r\n**Does it reproduce on recent release?**\r\n\r\nchecked only on \r\n```\r\n+----------------+----------------------------------------+\r\n|name            |value                                   |\r\n+----------------+----------------------------------------+\r\n|VERSION_FULL    |ClickHouse 22.10.1.1877                 |\r\n|VERSION_DESCRIBE|v22.10.1.1877-testing                   |\r\n|VERSION_INTEGER |22010001                                |\r\n|SYSTEM          |Linux                                   |\r\n|VERSION_GITHASH |98ab5a3c189232ea2a3dddb9d2be7196ae8b3434|\r\n|VERSION_REVISION|54467                                   |\r\n+----------------+----------------------------------------+\r\n```\r\n\r\n**Enable crash reporting**\r\n\r\nno errors in server logs\r\n\r\n**How to reproduce**\r\n\r\n```\r\ncreate table bug_gor_lz\r\n(\r\n    master_serial String,\r\n    sensor_serial String,\r\n    type          String,\r\n    datetime      DateTime codec (Delta, LZ4),\r\n    value Nullable(Decimal(15, 5)) default NULL,\r\n    value_bug Nullable(Decimal(15, 5)) default NULL codec (Delta, Gorilla, LZ4)\r\n)\r\n    engine = ReplacingMergeTree PARTITION BY toYYYYMM(datetime)\r\n        ORDER BY (master_serial, sensor_serial, type, datetime)\r\n        SETTINGS index_granularity = 8192;\r\n```\r\n\r\nImport from [file](https://github.com/mosinnik/bug_data/blob/6fae4459ea089869e0d20368d6814e8ee259de04/bug_click_data.zip) TabSeparated\r\nI export to file correct values in `value` column and in `value_bug` bugged value - check diffs:\r\n```\r\nselect * from bug_gor_lz\r\nwhere value <> value_bug\r\nlimit 10;\r\n```\r\n\r\nFor ex currently:\r\n```\r\n+-------------+-------------+-----+-------------------+-------+---------------------+\r\n|master_serial|sensor_serial|type |datetime           |value  |value_bug            |\r\n+-------------+-------------+-----+-------------------+-------+---------------------+\r\n|70160        |10000175HIT  |press|2022-06-14 06:07:02|0.00000|44483799547993.14956 |\r\n|70160        |10000175HIT  |press|2022-06-14 06:07:03|0.00000|-36626579495765.90833|\r\n|70160        |10000175HIT  |press|2022-06-14 06:07:04|0.00000|66730889016872.82706 |\r\n|70160        |10000175HIT  |press|2022-06-14 06:07:05|0.00000|-14377895735025.95563|\r\n|70160        |10000175HIT  |press|2022-06-14 06:07:06|0.00000|88981167069473.05496 |\r\n|70160        |10000175HIT  |press|2022-06-01 04:32:54|0.00000|0.64536              |\r\n|70160        |10000175HIT  |press|2022-06-01 04:32:55|0.00000|1.29072              |\r\n|70160        |10000175HIT  |press|2022-06-01 04:32:56|0.00000|1.93608              |\r\n|70160        |10000175HIT  |press|2022-06-01 04:32:57|0.00000|2.58144              |\r\n|70160        |10000175HIT  |press|2022-06-01 04:32:58|0.00000|3.22680              |\r\n+-------------+-------------+-----+-------------------+-------+---------------------+\r\n\r\n```\r\n\r\nTo reproduce create new table with above structure and refill from `value` to `value_bug`\r\n\r\n**Expected behavior**\r\n\r\nvalues in value and value_bug should be same\r\n\r\n**Error message and/or stacktrace**\r\n\r\nno\r\n\r\n**Additional context**\r\n\r\nno\r\n\n",
  "hints_text": "```sql\r\ncreate table bug_gor_lz (\r\n value Nullable(Decimal(15, 5)) default NULL,\r\n value_bug Nullable(Decimal(15, 5)) default NULL codec (Delta, Gorilla, LZ4)\r\n) engine = MergeTree order by tuple() as select 0 a, a from numbers(1e7);\r\n\r\nselect * from bug_gor_lz where value <> value_bug limit 10;\r\n\r\n\u250c\u2500value\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500value_bug\u2500\u2510\r\n\u2502     0 \u2502  75895212960677.40525 \u2502\r\n\u2502     0 \u2502 -35471917845052.35225 \u2502\r\n\u2502     0 \u2502  36161907420455.97013 \u2502\r\n\u2502     0 \u2502 -65097446656725.22828 \u2502\r\n\u2502     0 \u2502   7974549991303.27336 \u2502\r\n\u2502     0 \u2502  91168507926965.91725 \u2502\r\n\u2502     0 \u2502  -9401385829541.82547 \u2502\r\n\u2502     0 \u2502  50674911495242.95098 \u2502\r\n\u2502     0 \u2502 -49880908383758.45907 \u2502\r\n\u2502     0 \u2502  29667993143631.66816 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\nIn theory this combination `Delta, Gorilla` is unusable and Gorilla should be used only with Float.\r\n\r\n\r\n-----\r\nReceived exception from server (version 20.3.21):\r\nCode: 49. DB::Exception: Received from localhost:9000. DB::Exception: Value of type Nullable(Decimal(15, 5)) in memory is not of fixed size.. \r\n\r\nReceived exception from server (version 20.12.8):\r\nCode: 170. DB::Exception: Received from localhost:9000. DB::Exception: Bad get: has Float64, requested UInt64. \r\n\r\n\r\nReceived exception from server (version 21.2.10):\r\nCode: 170. DB::Exception: Received from localhost:9000. DB::Exception: Bad get: has Float64, requested UInt64. \r\n\r\n21.3 produces garbage.\r\n```\r\n0.00000\t89855300795807.82602\r\n0.00000\t-47252864602975.76428\r\n0.00000\t-82279610704849.79690\r\n```\nthx for clarification, but strange that partially data are good and not everything corrupted\n@den-crane Full stacks for the exceptions would be helpful to understand where the error comes from but in general I agree that we might as well disable Gorilla for everything != Float*. Interestingly, the FPC codec does so already.\nSmaller repro: https://github.com/ClickHouse/ClickHouse/pull/45252#issuecomment-1382195964 which also reproduces [on v22.12](https://fiddle.clickhouse.com/439c36e0-eb46-4c9a-834c-880b8a7fb50b). What is really weird is that I can't reproduce it on my local build on ClickHouse HEAD (I don't think it's fixed though).\n@rschu1ze \r\n\r\n> What is really weird is that I can't reproduce it on my local build on ClickHouse HEAD (\r\n\r\nI think probability of the issue depends on number of CPUs\r\n\r\ntry locally\r\n\r\n```\r\n create table bug_gor_lz ( value_bug Float64 codec (Delta, Gorilla, LZ4)\r\n                     ) engine = MergeTree order by tuple() as select 0 from numbers(1e8);\r\n  select * from bug_gor_lz where 0.0 <> value_bug limit 10;\r\n```\r\n\r\n\r\n\r\n ",
  "created_at": "2023-01-25T15:59:37Z",
  "modified_files": [
    "src/Compression/CompressionCodecDelta.cpp",
    "src/Compression/CompressionCodecGorilla.cpp",
    "src/Compression/ICompressionCodec.h",
    "src/IO/BitHelpers.h"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/02536_delta_gorilla_corruption.reference",
    "b/tests/queries/0_stateless/02536_delta_gorilla_corruption.sql"
  ]
}