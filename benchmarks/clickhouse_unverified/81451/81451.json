{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 81451,
  "instance_id": "ClickHouse__ClickHouse-81451",
  "issue_numbers": [
    "70874"
  ],
  "base_commit": "9c5fcfd4f5c2bad77fff41bdd15c7408138b93f3",
  "patch": "diff --git a/src/Storages/ObjectStorage/DataLakes/Iceberg/IcebergMetadata.cpp b/src/Storages/ObjectStorage/DataLakes/Iceberg/IcebergMetadata.cpp\nindex 7e318aed3906..6bec4c5c32ce 100644\n--- a/src/Storages/ObjectStorage/DataLakes/Iceberg/IcebergMetadata.cpp\n+++ b/src/Storages/ObjectStorage/DataLakes/Iceberg/IcebergMetadata.cpp\n@@ -15,6 +15,7 @@\n #include <Storages/ObjectStorage/DataLakes/DataLakeStorageSettings.h>\n #include \"Storages/ObjectStorage/DataLakes/Iceberg/IcebergMetadataFilesCache.h\"\n #include <Interpreters/ExpressionActions.h>\n+#include <IO/CompressedReadBufferWrapper.h>\n \n #include <Storages/ObjectStorage/DataLakes/Iceberg/IcebergMetadata.h>\n #include <Storages/ObjectStorage/DataLakes/Iceberg/Utils.h>\n@@ -103,12 +104,19 @@ Poco::JSON::Object::Ptr getMetadataJSONObject(\n     StorageObjectStorage::ConfigurationPtr configuration_ptr,\n     IcebergMetadataFilesCachePtr cache_ptr,\n     const ContextPtr & local_context,\n-    LoggerPtr log)\n+    LoggerPtr log,\n+    CompressionMethod compression_method)\n {\n     auto create_fn = [&]()\n     {\n         ObjectInfo object_info(metadata_file_path);\n-        auto buf = StorageObjectStorageSource::createReadBuffer(object_info, object_storage, local_context, log);\n+        auto source_buf = StorageObjectStorageSource::createReadBuffer(object_info, object_storage, local_context, log);\n+\n+        std::unique_ptr<ReadBuffer> buf;\n+        if (compression_method != CompressionMethod::None)\n+            buf = wrapReadBufferWithCompressionMethod(std::move(source_buf), compression_method);\n+        else\n+            buf = std::move(source_buf);\n \n         String json_str;\n         readJSONObjectPossiblyInvalid(json_str, *buf);\n@@ -269,7 +277,30 @@ Int32 IcebergMetadata::parseTableSchema(\n     }\n }\n \n-static std::pair<Int32, String> getMetadataFileAndVersion(const std::string & path)\n+struct MetadataFileWithInfo\n+{\n+    Int32 version;\n+    String path;\n+    CompressionMethod compression_method;\n+};\n+\n+static CompressionMethod getCompressionMethodFromMetadataFile(const String & path)\n+{\n+    constexpr std::string_view metadata_suffix = \".metadata.json\";\n+\n+    auto compression_method = chooseCompressionMethod(path, \"auto\");\n+\n+    /// NOTE you will be surprised, but some metadata files store compression not in the end of the file name,\n+    /// but somewhere in the middle of the file name, before metadata.json suffix.\n+    /// Maybe history of Iceberg metadata files is not so long, but it is already full of surprises.\n+    /// Example of weird engineering decisions: 00000-85befd5a-69c7-46d4-bca6-cfbd67f0f7e6.gz.metadata.json\n+    if (compression_method == CompressionMethod::None && path.ends_with(metadata_suffix))\n+        compression_method = chooseCompressionMethod(path.substr(0, path.size() - metadata_suffix.size()), \"auto\");\n+\n+    return compression_method;\n+}\n+\n+static MetadataFileWithInfo getMetadataFileAndVersion(const std::string & path)\n {\n     String file_name(path.begin() + path.find_last_of('/') + 1, path.end());\n     String version_str;\n@@ -284,7 +315,11 @@ static std::pair<Int32, String> getMetadataFileAndVersion(const std::string & pa\n         throw Exception(\n             ErrorCodes::BAD_ARGUMENTS, \"Bad metadata file name: {}. Expected vN.metadata.json where N is a number\", file_name);\n \n-    return std::make_pair(std::stoi(version_str), path);\n+\n+    return MetadataFileWithInfo{\n+        .version = std::stoi(version_str),\n+        .path = path,\n+        .compression_method = getCompressionMethodFromMetadataFile(path)};\n }\n \n enum class MostRecentMetadataFileSelectionWay\n@@ -295,7 +330,7 @@ enum class MostRecentMetadataFileSelectionWay\n \n struct ShortMetadataFileInfo\n {\n-    UInt32 version;\n+    Int32 version;\n     UInt64 last_updated_ms;\n     String path;\n };\n@@ -307,7 +342,7 @@ struct ShortMetadataFileInfo\n  *   1) v<V>.metadata.json, where V - metadata version.\n  *   2) <V>-<random-uuid>.metadata.json, where V - metadata version\n  */\n-static std::pair<Int32, String> getLatestMetadataFileAndVersion(\n+static MetadataFileWithInfo getLatestMetadataFileAndVersion(\n     const ObjectStoragePtr & object_storage,\n     StorageObjectStorage::ConfigurationPtr configuration_ptr,\n     IcebergMetadataFilesCachePtr cache_ptr,\n@@ -331,10 +366,10 @@ static std::pair<Int32, String> getLatestMetadataFileAndVersion(\n     metadata_files_with_versions.reserve(metadata_files.size());\n     for (const auto & path : metadata_files)\n     {\n-        auto [version, metadata_file_path] = getMetadataFileAndVersion(path);\n+        auto [version, metadata_file_path, compression_method] = getMetadataFileAndVersion(path);\n         if (need_all_metadata_files_parsing)\n         {\n-            auto metadata_file_object = getMetadataJSONObject(metadata_file_path, object_storage, configuration_ptr, cache_ptr, local_context, log);\n+            auto metadata_file_object = getMetadataJSONObject(metadata_file_path, object_storage, configuration_ptr, cache_ptr, local_context, log, compression_method);\n             if (table_uuid.has_value())\n             {\n                 if (metadata_file_object->has(f_table_uuid))\n@@ -384,10 +419,10 @@ static std::pair<Int32, String> getLatestMetadataFileAndVersion(\n                 [](const ShortMetadataFileInfo & a, const ShortMetadataFileInfo & b) { return a.version < b.version; });\n         }\n     }();\n-    return {latest_metadata_file_info.version, latest_metadata_file_info.path};\n+    return {latest_metadata_file_info.version, latest_metadata_file_info.path, getCompressionMethodFromMetadataFile(latest_metadata_file_info.path)};\n }\n \n-static std::pair<Int32, String> getLatestOrExplicitMetadataFileAndVersion(\n+static MetadataFileWithInfo getLatestOrExplicitMetadataFileAndVersion(\n     const ObjectStoragePtr & object_storage,\n     StorageObjectStorage::ConfigurationPtr configuration_ptr,\n     IcebergMetadataFilesCachePtr cache_ptr,\n@@ -452,7 +487,7 @@ bool IcebergMetadata::update(const ContextPtr & local_context)\n {\n     auto configuration_ptr = configuration.lock();\n \n-    const auto [metadata_version, metadata_file_path]\n+    const auto [metadata_version, metadata_file_path, compression_method]\n         = getLatestOrExplicitMetadataFileAndVersion(object_storage, configuration_ptr, manifest_cache, local_context, log.get());\n \n     bool metadata_file_changed = false;\n@@ -462,7 +497,7 @@ bool IcebergMetadata::update(const ContextPtr & local_context)\n         metadata_file_changed = true;\n     }\n \n-    auto metadata_object = getMetadataJSONObject(metadata_file_path, object_storage, configuration_ptr, manifest_cache, local_context, log);\n+    auto metadata_object = getMetadataJSONObject(metadata_file_path, object_storage, configuration_ptr, manifest_cache, local_context, log, compression_method);\n     chassert(format_version == metadata_object->getValue<int>(f_format_version));\n \n     auto previous_snapshot_id = relevant_snapshot_id;\n@@ -629,9 +664,9 @@ DataLakeMetadataPtr IcebergMetadata::create(\n     else\n         LOG_TRACE(log, \"Not using in-memory cache for iceberg metadata files, because the setting use_iceberg_metadata_files_cache is false.\");\n \n-    const auto [metadata_version, metadata_file_path] = getLatestOrExplicitMetadataFileAndVersion(object_storage, configuration_ptr, cache_ptr, local_context, log.get());\n+    const auto [metadata_version, metadata_file_path, compression_method] = getLatestOrExplicitMetadataFileAndVersion(object_storage, configuration_ptr, cache_ptr, local_context, log.get());\n \n-    Poco::JSON::Object::Ptr object = getMetadataJSONObject(metadata_file_path, object_storage, configuration_ptr, cache_ptr, local_context, log);\n+    Poco::JSON::Object::Ptr object = getMetadataJSONObject(metadata_file_path, object_storage, configuration_ptr, cache_ptr, local_context, log, compression_method);\n \n     IcebergSchemaProcessor schema_processor;\n \n@@ -706,11 +741,11 @@ IcebergMetadata::IcebergHistory IcebergMetadata::getHistory() const\n {\n     auto configuration_ptr = configuration.lock();\n \n-    const auto [metadata_version, metadata_file_path] = getLatestOrExplicitMetadataFileAndVersion(object_storage, configuration_ptr, manifest_cache, getContext(), log.get());\n+    const auto [metadata_version, metadata_file_path, compression_method] = getLatestOrExplicitMetadataFileAndVersion(object_storage, configuration_ptr, manifest_cache, getContext(), log.get());\n \n     chassert(metadata_version == last_metadata_version);\n \n-    auto metadata_object = getMetadataJSONObject(metadata_file_path, object_storage, configuration_ptr, manifest_cache, getContext(), log);\n+    auto metadata_object = getMetadataJSONObject(metadata_file_path, object_storage, configuration_ptr, manifest_cache, getContext(), log, compression_method);\n \n     chassert(format_version == metadata_object->getValue<int>(f_format_version));\n \ndiff --git a/src/Storages/ObjectStorage/DataLakes/Iceberg/Utils.cpp b/src/Storages/ObjectStorage/DataLakes/Iceberg/Utils.cpp\nindex 56d7b9565fb1..0a598be61211 100644\n--- a/src/Storages/ObjectStorage/DataLakes/Iceberg/Utils.cpp\n+++ b/src/Storages/ObjectStorage/DataLakes/Iceberg/Utils.cpp\n@@ -48,6 +48,7 @@ std::string getProperFilePathFromMetadataInfo(std::string_view data_path, std::s\n     };\n     common_path = trim_backward_slash(common_path);\n     table_location = trim_backward_slash(table_location);\n+\n     if (data_path.starts_with(table_location) && table_location.ends_with(common_path))\n     {\n         return std::filesystem::path{common_path} / trim_forward_slash(data_path.substr(table_location.size()));\n@@ -55,6 +56,14 @@ std::string getProperFilePathFromMetadataInfo(std::string_view data_path, std::s\n \n \n     auto pos = data_path.find(common_path);\n+    /// Valid situation when data and metadata files are stored in different directories.\n+    if (pos == std::string::npos)\n+    {\n+        /// connection://bucket\n+        auto prefix = table_location.substr(0, table_location.size() - common_path.size());\n+        return std::string{data_path.substr(prefix.size())};\n+    }\n+\n     size_t good_pos = std::string::npos;\n     while (pos != std::string::npos)\n     {\n",
  "test_patch": "diff --git a/tests/integration/test_storage_iceberg/test.py b/tests/integration/test_storage_iceberg/test.py\nindex 93f668811268..dedd7fddc7bd 100644\n--- a/tests/integration/test_storage_iceberg/test.py\n+++ b/tests/integration/test_storage_iceberg/test.py\n@@ -2,6 +2,7 @@\n import json\n import logging\n import os\n+import subprocess\n import time\n import uuid\n from datetime import datetime, timezone\n@@ -3122,3 +3123,41 @@ def execute_spark_query(query: str):\n     )\n \n     instance.query(f\"SELECT * FROM {table_function_expr_cluster} WHERE a = 1\")\n+\n+@pytest.mark.parametrize(\"storage_type\", [\"local\", \"s3\"])\n+def test_compressed_metadata(started_cluster, storage_type):\n+    instance = started_cluster.instances[\"node1\"]\n+    spark = started_cluster.spark_session\n+    TABLE_NAME = \"test_compressed_metadata_\" + storage_type + \"_\" + get_uuid_str()\n+\n+    table_properties = {\n+        \"write.metadata.compression\": \"gzip\"\n+    }\n+\n+    df = spark.createDataFrame([\n+        (1, \"Alice\"),\n+        (2, \"Bob\")\n+    ], [\"id\", \"name\"])\n+\n+    # for some reason write.metadata.compression is not working :(\n+    df.writeTo(TABLE_NAME) \\\n+        .tableProperty(\"write.metadata.compression\", \"gzip\") \\\n+        .using(\"iceberg\") \\\n+        .create()\n+\n+    # manual compression of metadata file before upload, still test some scenarios\n+    subprocess.check_output(f\"gzip /iceberg_data/default/{TABLE_NAME}/metadata/v1.metadata.json\", shell=True)\n+\n+    # Weird but compression extension is really in the middle of the file name, not in the end...\n+    subprocess.check_output(f\"mv /iceberg_data/default/{TABLE_NAME}/metadata/v1.metadata.json.gz /iceberg_data/default/{TABLE_NAME}/metadata/v1.gz.metadata.json\", shell=True)\n+\n+    default_upload_directory(\n+        started_cluster,\n+        storage_type,\n+        f\"/iceberg_data/default/{TABLE_NAME}/\",\n+        f\"/iceberg_data/default/{TABLE_NAME}/\",\n+    )\n+\n+    create_iceberg_table(storage_type, instance, TABLE_NAME, started_cluster, explicit_metadata_path=\"\")\n+\n+    assert instance.query(f\"SELECT * FROM {TABLE_NAME} WHERE not ignore(*)\") == \"1\\tAlice\\n2\\tBob\\n\"\n",
  "problem_statement": "Iceberg Integration: Support compressed manifest files\n**Use case**\r\n\r\nOur Iceberg catalog provider enables compression of the manifest.json file by default. The current Clickhouse Iceberg integration makes it impossible to open this file. \r\n\r\n**Describe the solution you'd like**\r\n\r\nClickhouse can read compressed Iceberg manifest files where `write.metadata.compression-codec = gzip` is set on the table.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nA workaround is to disable the compression of the manifest file by setting `write.metadata.compression-codec = none`\r\n\r\n**Additional context**\r\n\r\nhttps://iceberg.apache.org/docs/latest/configuration/#write-properties\r\n\n",
  "hints_text": "@netapp-vaughan What catalog are you using? \n> @netapp-vaughan What catalog are you using?\r\n\r\nREST Catalog.",
  "created_at": "2025-06-06T19:11:18Z",
  "modified_files": [
    "src/Storages/ObjectStorage/DataLakes/Iceberg/IcebergMetadata.cpp",
    "src/Storages/ObjectStorage/DataLakes/Iceberg/Utils.cpp"
  ],
  "modified_test_files": [
    "tests/integration/test_storage_iceberg/test.py"
  ]
}