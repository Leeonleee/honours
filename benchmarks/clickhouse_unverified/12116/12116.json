{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 12116,
  "instance_id": "ClickHouse__ClickHouse-12116",
  "issue_numbers": [
    "10994",
    "10397"
  ],
  "base_commit": "5a4d9fb9ae60de0d4e1744f8c47d102a2cb05b2b",
  "patch": "diff --git a/src/Databases/DatabaseDictionary.cpp b/src/Databases/DatabaseDictionary.cpp\nindex 6c5433cab38a..986e36de8cf6 100644\n--- a/src/Databases/DatabaseDictionary.cpp\n+++ b/src/Databases/DatabaseDictionary.cpp\n@@ -28,7 +28,11 @@ namespace\n             if (!load_result.config)\n                 return nullptr;\n             DictionaryStructure dictionary_structure = ExternalDictionariesLoader::getDictionaryStructure(*load_result.config);\n-            return StorageDictionary::create(StorageID(database_name, load_result.name), load_result.name, dictionary_structure);\n+            return StorageDictionary::create(\n+                StorageID(database_name, load_result.name),\n+                load_result.name,\n+                dictionary_structure,\n+                StorageDictionary::Location::DictionaryDatabase);\n         }\n         catch (Exception & e)\n         {\ndiff --git a/src/Databases/DatabaseWithDictionaries.cpp b/src/Databases/DatabaseWithDictionaries.cpp\nindex e0f2aa9286b2..9be7e4d8b3e1 100644\n--- a/src/Databases/DatabaseWithDictionaries.cpp\n+++ b/src/Databases/DatabaseWithDictionaries.cpp\n@@ -49,7 +49,8 @@ void DatabaseWithDictionaries::attachDictionary(const String & dictionary_name,\n                 StorageDictionary::create(\n                     StorageID(getDatabaseName(), dictionary_name),\n                     full_name,\n-                    ExternalDictionariesLoader::getDictionaryStructure(*attach_info.config)),\n+                    ExternalDictionariesLoader::getDictionaryStructure(*attach_info.config),\n+                    StorageDictionary::Location::SameDatabaseAndNameAsDictionary),\n                 lock);\n         }\n         catch (...)\ndiff --git a/src/Storages/StorageDictionary.cpp b/src/Storages/StorageDictionary.cpp\nindex 83a093d56357..4ea028c7ca8d 100644\n--- a/src/Storages/StorageDictionary.cpp\n+++ b/src/Storages/StorageDictionary.cpp\n@@ -96,19 +96,31 @@ String StorageDictionary::generateNamesAndTypesDescription(const NamesAndTypesLi\n StorageDictionary::StorageDictionary(\n     const StorageID & table_id_,\n     const String & dictionary_name_,\n-    const DictionaryStructure & dictionary_structure_)\n+    const ColumnsDescription & columns_,\n+    Location location_)\n     : IStorage(table_id_)\n     , dictionary_name(dictionary_name_)\n+    , location(location_)\n {\n     StorageInMemoryMetadata storage_metadata;\n-    storage_metadata.setColumns(ColumnsDescription{getNamesAndTypes(dictionary_structure_)});\n+    storage_metadata.setColumns(columns_);\n     setInMemoryMetadata(storage_metadata);\n }\n \n \n+StorageDictionary::StorageDictionary(\n+    const StorageID & table_id_, const String & dictionary_name_, const DictionaryStructure & dictionary_structure_, Location location_)\n+    : StorageDictionary(table_id_, dictionary_name_, ColumnsDescription{getNamesAndTypes(dictionary_structure_)}, location_)\n+{\n+}\n+\n+\n void StorageDictionary::checkTableCanBeDropped() const\n {\n-    throw Exception(\"Cannot detach dictionary \" + backQuote(dictionary_name) + \" as table, use DETACH DICTIONARY query.\", ErrorCodes::CANNOT_DETACH_DICTIONARY_AS_TABLE);\n+    if (location == Location::SameDatabaseAndNameAsDictionary)\n+        throw Exception(\"Cannot detach dictionary \" + backQuote(dictionary_name) + \" as table, use DETACH DICTIONARY query\", ErrorCodes::CANNOT_DETACH_DICTIONARY_AS_TABLE);\n+    if (location == Location::DictionaryDatabase)\n+        throw Exception(\"Cannot detach table \" + getStorageID().getFullTableName() + \" from a database with DICTIONARY engine\", ErrorCodes::CANNOT_DETACH_DICTIONARY_AS_TABLE);\n }\n \n Pipes StorageDictionary::read(\n@@ -141,11 +153,14 @@ void registerStorageDictionary(StorageFactory & factory)\n         args.engine_args[0] = evaluateConstantExpressionOrIdentifierAsLiteral(args.engine_args[0], args.local_context);\n         String dictionary_name = args.engine_args[0]->as<ASTLiteral &>().value.safeGet<String>();\n \n-        const auto & dictionary = args.context.getExternalDictionariesLoader().getDictionary(dictionary_name);\n-        const DictionaryStructure & dictionary_structure = dictionary->getStructure();\n-        checkNamesAndTypesCompatibleWithDictionary(dictionary_name, args.columns, dictionary_structure);\n+        if (!args.attach)\n+        {\n+            const auto & dictionary = args.context.getExternalDictionariesLoader().getDictionary(dictionary_name);\n+            const DictionaryStructure & dictionary_structure = dictionary->getStructure();\n+            checkNamesAndTypesCompatibleWithDictionary(dictionary_name, args.columns, dictionary_structure);\n+        }\n \n-        return StorageDictionary::create(args.table_id, dictionary_name, dictionary_structure);\n+        return StorageDictionary::create(args.table_id, dictionary_name, args.columns, StorageDictionary::Location::Custom);\n     });\n }\n \ndiff --git a/src/Storages/StorageDictionary.h b/src/Storages/StorageDictionary.h\nindex 6175902381b8..f152f8c9932d 100644\n--- a/src/Storages/StorageDictionary.h\n+++ b/src/Storages/StorageDictionary.h\n@@ -30,14 +30,40 @@ class StorageDictionary final : public ext::shared_ptr_helper<StorageDictionary>\n \n     const String & dictionaryName() const { return dictionary_name; }\n \n+    /// Specifies where the table is located relative to the dictionary.\n+    enum class Location\n+    {\n+        /// Table was created automatically as an element of a database with the Dictionary engine.\n+        DictionaryDatabase,\n+\n+        /// Table was created automatically along with a dictionary\n+        /// and has the same database and name as the dictionary.\n+        /// It provides table-like access to the dictionary.\n+        /// User cannot drop that table.\n+        SameDatabaseAndNameAsDictionary,\n+\n+        /// Table was created explicitly by a statement like\n+        /// CREATE TABLE ... ENGINE=Dictionary\n+        /// User chose the table's database and name and can drop that table.\n+        Custom,\n+    };\n+\n private:\n-    String dictionary_name;\n+    const String dictionary_name;\n+    const Location location;\n \n protected:\n     StorageDictionary(\n         const StorageID & table_id_,\n         const String & dictionary_name_,\n-        const DictionaryStructure & dictionary_structure);\n+        const ColumnsDescription & columns_,\n+        Location location_);\n+\n+    StorageDictionary(\n+        const StorageID & table_id_,\n+        const String & dictionary_name_,\n+        const DictionaryStructure & dictionary_structure,\n+        Location location_);\n };\n \n }\n",
  "test_patch": "diff --git a/tests/integration/test_dictionaries_depend_on_dictionaries/__init__.py b/tests/integration/test_dictionaries_dependency/__init__.py\nsimilarity index 100%\nrename from tests/integration/test_dictionaries_depend_on_dictionaries/__init__.py\nrename to tests/integration/test_dictionaries_dependency/__init__.py\ndiff --git a/tests/integration/test_dictionaries_dependency/configs/disable_lazy_load.xml b/tests/integration/test_dictionaries_dependency/configs/disable_lazy_load.xml\nnew file mode 100644\nindex 000000000000..d01f7a0155b6\n--- /dev/null\n+++ b/tests/integration/test_dictionaries_dependency/configs/disable_lazy_load.xml\n@@ -0,0 +1,4 @@\n+<yandex>\n+    <dictionaries_lazy_load>false</dictionaries_lazy_load>\n+</yandex>\n+\ndiff --git a/tests/integration/test_dictionaries_dependency/test.py b/tests/integration/test_dictionaries_dependency/test.py\nnew file mode 100644\nindex 000000000000..31c5a6c549a9\n--- /dev/null\n+++ b/tests/integration/test_dictionaries_dependency/test.py\n@@ -0,0 +1,109 @@\n+import pytest\n+from helpers.cluster import ClickHouseCluster\n+\n+cluster = ClickHouseCluster(__file__)\n+node1 = cluster.add_instance('node1', stay_alive=True)\n+node2 = cluster.add_instance('node2', stay_alive=True, main_configs=['configs/disable_lazy_load.xml'])\n+nodes = [node1, node2]\n+\n+\n+@pytest.fixture(scope=\"module\", autouse=True)\n+def start_cluster():\n+    try:\n+        cluster.start()\n+        for node in nodes:\n+            node.query(\"CREATE DATABASE IF NOT EXISTS test\")\n+            node.query(\"CREATE DATABASE IF NOT EXISTS atest\")\n+            node.query(\"CREATE DATABASE IF NOT EXISTS ztest\")\n+            node.query(\"CREATE TABLE test.source(x UInt64, y UInt64) ENGINE=Log\")\n+            node.query(\"INSERT INTO test.source VALUES (5,6)\")\n+            \n+            node.query(\"CREATE DICTIONARY test.dict(x UInt64, y UInt64) PRIMARY KEY x \"\\\n+                        \"SOURCE(CLICKHOUSE(HOST 'localhost' PORT 9000 USER 'default' TABLE 'source' DB 'test')) \"\\\n+                        \"LAYOUT(FLAT()) LIFETIME(0)\")\n+        yield cluster\n+\n+    finally:\n+        cluster.shutdown()\n+\n+\n+@pytest.fixture(autouse=True)\n+def cleanup_after_test():\n+    try:\n+        yield\n+    finally:\n+        for node in nodes:\n+            node.query(\"DROP DICTIONARY IF EXISTS test.adict\")\n+            node.query(\"DROP DICTIONARY IF EXISTS test.zdict\")\n+            node.query(\"DROP DICTIONARY IF EXISTS atest.dict\")\n+            node.query(\"DROP DICTIONARY IF EXISTS ztest.dict\")\n+            node.query(\"DROP TABLE IF EXISTS test.atbl\")\n+            node.query(\"DROP TABLE IF EXISTS test.ztbl\")\n+            node.query(\"DROP TABLE IF EXISTS atest.tbl\")\n+            node.query(\"DROP TABLE IF EXISTS ztest.tbl\")\n+            node.query(\"DROP DATABASE IF EXISTS dict_db\")\n+\n+\n+@pytest.mark.parametrize(\"node\", nodes)\n+def test_dependency_via_implicit_table(node):\n+    d_names = [\"test.adict\", \"test.zdict\", \"atest.dict\", \"ztest.dict\"]\n+    for d_name in d_names:\n+        node.query(\"CREATE DICTIONARY {}(x UInt64, y UInt64) PRIMARY KEY x \"\\\n+                   \"SOURCE(CLICKHOUSE(HOST 'localhost' PORT 9000 USER 'default' TABLE 'dict' DB 'test')) \"\\\n+                   \"LAYOUT(FLAT()) LIFETIME(0)\".format(d_name))\n+    \n+    def check():\n+        for d_name in d_names:\n+            assert node.query(\"SELECT dictGet({}, 'y', toUInt64(5))\".format(d_name)) == \"6\\n\"\n+    \n+    check()\n+\n+    # Restart must not break anything.\n+    node.restart_clickhouse()\n+    check()\n+\n+\n+@pytest.mark.parametrize(\"node\", nodes)\n+def test_dependency_via_explicit_table(node):\n+    tbl_names = [\"test.atbl\", \"test.ztbl\", \"atest.tbl\", \"ztest.tbl\"]\n+    d_names = [\"test.other_{}\".format(i) for i in range(0, len(tbl_names))]\n+    for i in range(0, len(tbl_names)):\n+        tbl_name = tbl_names[i]\n+        tbl_database, tbl_shortname = tbl_name.split('.')\n+        d_name = d_names[i]\n+        node.query(\"CREATE TABLE {}(x UInt64, y UInt64) ENGINE=Dictionary('test.dict')\".format(tbl_name))\n+        node.query(\"CREATE DICTIONARY {}(x UInt64, y UInt64) PRIMARY KEY x \"\\\n+                   \"SOURCE(CLICKHOUSE(HOST 'localhost' PORT 9000 USER 'default' TABLE '{}' DB '{}')) \"\\\n+                   \"LAYOUT(FLAT()) LIFETIME(0)\".format(d_name, tbl_shortname, tbl_database))\n+    \n+    def check():\n+        for d_name in d_names:\n+            assert node.query(\"SELECT dictGet({}, 'y', toUInt64(5))\".format(d_name)) == \"6\\n\"\n+    \n+    check()\n+\n+    # Restart must not break anything.\n+    node.restart_clickhouse()\n+    check()\n+\n+\n+@pytest.mark.skip(reason=\"TODO: should be fixed\")\n+@pytest.mark.parametrize(\"node\", nodes)\n+def test_dependency_via_dictionary_database(node):\n+    node.query(\"CREATE DATABASE dict_db ENGINE=Dictionary\")\n+\n+    d_names = [\"test.adict\", \"test.zdict\", \"atest.dict\", \"ztest.dict\"]\n+    for d_name in d_names:\n+        node.query(\"CREATE DICTIONARY {}(x UInt64, y UInt64) PRIMARY KEY x \"\\\n+                   \"SOURCE(CLICKHOUSE(HOST 'localhost' PORT 9000 USER 'default' TABLE 'test.dict' DB 'dict_db')) \"\\\n+                   \"LAYOUT(FLAT()) LIFETIME(0)\".format(d_name))\n+    \n+    def check():\n+        for d_name in d_names:\n+            assert node.query(\"SELECT dictGet({}, 'y', toUInt64(5))\".format(d_name)) == \"6\\n\"\n+    \n+    check()\n+\n+    # Restart must not break anything.\n+    node.restart_clickhouse()\n+    check()\ndiff --git a/tests/integration/test_dictionaries_dependency_xml/__init__.py b/tests/integration/test_dictionaries_dependency_xml/__init__.py\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/integration/test_dictionaries_depend_on_dictionaries/configs/config.xml b/tests/integration/test_dictionaries_dependency_xml/configs/config.xml\nsimilarity index 100%\nrename from tests/integration/test_dictionaries_depend_on_dictionaries/configs/config.xml\nrename to tests/integration/test_dictionaries_dependency_xml/configs/config.xml\ndiff --git a/tests/integration/test_dictionaries_depend_on_dictionaries/configs/dictionaries/dep_x.xml b/tests/integration/test_dictionaries_dependency_xml/configs/dictionaries/dep_x.xml\nsimilarity index 100%\nrename from tests/integration/test_dictionaries_depend_on_dictionaries/configs/dictionaries/dep_x.xml\nrename to tests/integration/test_dictionaries_dependency_xml/configs/dictionaries/dep_x.xml\ndiff --git a/tests/integration/test_dictionaries_depend_on_dictionaries/configs/dictionaries/dep_y.xml b/tests/integration/test_dictionaries_dependency_xml/configs/dictionaries/dep_y.xml\nsimilarity index 100%\nrename from tests/integration/test_dictionaries_depend_on_dictionaries/configs/dictionaries/dep_y.xml\nrename to tests/integration/test_dictionaries_dependency_xml/configs/dictionaries/dep_y.xml\ndiff --git a/tests/integration/test_dictionaries_depend_on_dictionaries/configs/dictionaries/dep_z.xml b/tests/integration/test_dictionaries_dependency_xml/configs/dictionaries/dep_z.xml\nsimilarity index 100%\nrename from tests/integration/test_dictionaries_depend_on_dictionaries/configs/dictionaries/dep_z.xml\nrename to tests/integration/test_dictionaries_dependency_xml/configs/dictionaries/dep_z.xml\ndiff --git a/tests/integration/test_dictionaries_depend_on_dictionaries/configs/users.xml b/tests/integration/test_dictionaries_dependency_xml/configs/users.xml\nsimilarity index 100%\nrename from tests/integration/test_dictionaries_depend_on_dictionaries/configs/users.xml\nrename to tests/integration/test_dictionaries_dependency_xml/configs/users.xml\ndiff --git a/tests/integration/test_dictionaries_depend_on_dictionaries/test.py b/tests/integration/test_dictionaries_dependency_xml/test.py\nsimilarity index 100%\nrename from tests/integration/test_dictionaries_depend_on_dictionaries/test.py\nrename to tests/integration/test_dictionaries_dependency_xml/test.py\n",
  "problem_statement": "Failed to load table with Dictionary engine when initializing ClickHouse server\n1 month ago, I found this issue when trying to use version 20.4.1 even it was not released. Now there is an official release of version 20.4.2 but the issue is still there.\r\nI created an issue on GitHub but there is no update then I want to re-post here\r\nhttps://github.com/ClickHouse/ClickHouse/issues/10397\r\n---------------------\r\nRecently, I upgraded ClickHouse from 19.5.3 to 20.4.2 and I got some issue when trying to load table with Dictionary engine during server's start up in version 20.4.2. (It worked fine with 19.5.3). \r\n\r\nI defined a Dictionary xml file with name topics_article and put this xml file under /etc/clickhouse-server/config.d/\r\n\r\nMy table create statement as:\r\nCREATE TABLE intermediate.topics_article (topic_idString,entryString,type String) ENGINE = Dictionary(topics_article)\r\n\r\nI also have setting in config.xml as <dictionaries_config>*_dictionary.xml</dictionaries_config>\r\n<dictionaries_lazy_load>true</dictionaries_lazy_load>\r\n\r\nHowever, in version 20.4.2, server can not start successfully during this error:\r\n\r\n```2020.05.18 07:25:16.032714 [ 191 ] {} <Information> DatabaseOrdinary (intermediate): Total 30 tables and 0 dictionaries.\r\n2020.05.18 07:25:16.087128 [ 218 ] {}<Error> ThreadPool: Exception in ThreadPool(max_threads: 4, max_free_threads: 4, queue_size: 4, shutdown_on_exception: 1).: Code: 36, e.displayText() = DB::Exception: external dictionary 'topics_article' not found: Cannot attach table `intermediate`.`topics_article` from metadata file /var/lib/clickhouse/metadata/intermediate/topics_article.sql from query ATTACH TABLE topics_article (`topic_id` String, `entry` String, `type` String) ENGINE = Dictionary('topics_article'), Stack trace (when copying this message, always include the lines below):\r\n\r\n0. Poco::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x10406ef0 in /usr/bin/clickhouse\r\n1. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x8ff88ad in /usr/bin/clickhouse\r\n2. ? @ 0xd03de31 in /usr/bin/clickhouse\r\n3. std::__1::shared_ptr<DB::IExternalLoadable const> DB::ExternalLoader::load<std::__1::shared_ptr<DB::IExternalLoadable const>, void>(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) const @ 0xd049ab3 in /usr/bin/clickhouse\r\n4. ? @ 0xd64ebcc in /usr/bin/clickhouse\r\n5. DB::StorageFactory::get(DB::ASTCreateQuery const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::Context&, DB::Context&, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, bool) const @ 0xd67073d in /usr/bin/clickhouse\r\n6. DB::createTableFromAST(DB::ASTCreateQuery, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::Context&, bool) @ 0xd02c9b7 in /usr/bin/clickhouse\r\n7. ? @ 0xd01fc58 in /usr/bin/clickhouse\r\n8. ? @ 0xd020612 in /usr/bin/clickhouse\r\n9. ThreadPoolImpl<ThreadFromGlobalPool>::worker(std::__1::__list_iterator<ThreadFromGlobalPool, void*>) @ 0x901f3ab in /usr/bin/clickhouse\r\n10. ThreadFromGlobalPool::ThreadFromGlobalPool<void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()>(void&&, void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()&&...)::'lambda'()::operator()() const @ 0x902017a in /usr/bin/clickhouse\r\n11. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x901e26b in /usr/bin/clickhouse\r\n12. ? @ 0x901c753 in /usr/bin/clickhouse\r\n13. start_thread @ 0x76db in /lib/x86_64-linux-gnu/libpthread-2.27.so\r\n14. __clone @ 0x12188f in /lib/x86_64-linux-gnu/libc-2.27.so\r\n(version 20.4.2.9 (official build))\r\n```\nFailed to load table with Dictionary engine when initializing ClickHouse server\nRecently, I upgraded ClickHouse from 19.5.3 to 20.4.1 and I got some issue when trying to load table with Dictionary engine during server's start up in version 20.4.1. (It worked fine with 19.5.3)\r\n\r\nI defined a Dictionary xml file with name `topics_article` and put this xml file under `/etc/clickhouse-server/config.d/`\r\n\r\nMy table create statement as:\r\n`CREATE TABLE intermediate.topics_article (`topic_id` String, `entry` String, `type` String) ENGINE = Dictionary(topics_article)`\r\n\r\nI also have setting in config.xml as `<dictionaries_config>*_dictionary.xml</dictionaries_config>`\r\n`<dictionaries_lazy_load>true</dictionaries_lazy_load>`\r\n\r\nHowever, in version 20.4.1, server can not start successfully during this error:\r\n\r\n```\r\n2020.04.20 18:34:56.575355 [ 191 ] {} <Information> DatabaseOrdinary (intermediate): Total 30 tables and 0 dictionaries.\r\n2020.04.20 18:34:56.639836 [ 218 ] {}<Error> ThreadPool: Exception in ThreadPool(max_threads: 4, max_free_threads: 4, queue_size: 4, shutdown_on_exception: 1).: Code: 36, e.displayText() = DB::Exception: external dictionary 'topics_article' not found: Cannot attach table `intermediate`.`topics_article` from metadata file /var/lib/clickhouse/metadata/intermediate/topics_article.sql from query ATTACH TABLE topics_article (`topic_id` String, `entry` String, `type` String) ENGINE = Dictionary('topics_article'), Stack trace (when copying this message, always include the lines below):\r\n\r\n0. Poco::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x105bbe70 in /usr/bin/clickhouse\r\n1. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x8f0c8ad in /usr/bin/clickhouse\r\n2. ? @ 0xcfca6c9 in /usr/bin/clickhouse\r\n3. std::__1::shared_ptr<DB::IExternalLoadable const> DB::ExternalLoader::load<std::__1::shared_ptr<DB::IExternalLoadable const>, void>(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) const @ 0xcfd6cc3 in /usr/bin/clickhouse\r\n4. ? @ 0xd66a9cc in /usr/bin/clickhouse\r\n5. DB::StorageFactory::get(DB::ASTCreateQuery const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::Context&, DB::Context&, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, bool) const @ 0xd68efa0 in /usr/bin/clickhouse\r\n6. DB::createTableFromAST(DB::ASTCreateQuery, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::Context&, bool) @ 0xd1090be in /usr/bin/clickhouse\r\n7. ? @ 0xd0fc36f in /usr/bin/clickhouse\r\n8. ? @ 0xd0fcb52 in /usr/bin/clickhouse\r\n9. ThreadPoolImpl<ThreadFromGlobalPool>::worker(std::__1::__list_iterator<ThreadFromGlobalPool, void*>) @ 0x8f333ab in /usr/bin/clickhouse\r\n10. ThreadFromGlobalPool::ThreadFromGlobalPool<void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()>(void&&, void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()&&...)::'lambda'()::operator()() const @ 0x8f3417a in /usr/bin/clickhouse\r\n11. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x8f3226b in /usr/bin/clickhouse\r\n12. ? @ 0x8f30753 in /usr/bin/clickhouse\r\n13. start_thread @ 0x76db in /lib/x86_64-linux-gnu/libpthread-2.27.so\r\n14. clone @ 0x12188f in /lib/x86_64-linux-gnu/libc-2.27.so\r\n (version 20.4.1.1 (official build))\r\n```\r\n\r\n \r\n\r\n\n",
  "hints_text": "What will be if you disable *dictionaries_lazy_load* ?\nhttps://github.com/ClickHouse/ClickHouse/issues/10397#issuecomment-631027204\nhttps://github.com/ClickHouse/ClickHouse/issues/10397#issuecomment-631200765\n@nikitamikhaylov I don't think disable _dictionaries_lazy_load_ should resolve the root cause. \nHave the same issue after upgrade 20.1.2.4 => 20.4.2.9, `dictionaries_lazy_load=false` didn't help.\nreproduce\r\n\r\n```\r\n<dictionaries_lazy_load>false</dictionaries_lazy_load>\r\n\r\ncat /etc/clickhouse-server/node.tsv\r\n1\txxxx\r\n\r\n\r\ncat /etc/clickhouse-server/dict/node.xml\r\n<dictionaries>\r\n    <dictionary>\r\n        <name>node</name>\r\n        <source>\r\n            <file>\r\n                <path>/etc/clickhouse-server/node.tsv</path>\r\n                <format>TabSeparated</format>\r\n            </file>\r\n        </source>\r\n        <lifetime>0</lifetime>\r\n        <layout><flat /></layout>\r\n        <structure>\r\n            <id><name>key</name></id>\r\n            <attribute>\r\n                <name>name</name>\r\n                <type>String</type>\r\n                <null_value></null_value>\r\n            </attribute>\r\n        </structure>\r\n    </dictionary>\r\n</dictionaries>\r\n\r\ncat /var/lib/clickhouse/metadata/default/node.sql\r\nATTACH TABLE node\r\n(\r\n    `key` UInt64,\r\n    `name` String\r\n)\r\nENGINE = Dictionary('node')\r\n```\r\n\r\n\r\n\r\n<Error> Application: Caught exception while loading metadata: Code: 36, e.displayText() = \r\nDB::Exception: external dictionary 'node' not found: Cannot attach table `default`.`node` from metadata file /var/lib/clickhouse/metadata/default/node.sql from query ATTACH TABLE node (`key` UInt64, `name` String) ENGINE = Dictionary('node'), Stack trace (when copying this message, always include the lines below):\r\n\r\n0. Poco::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x112387c0 in /usr/bin/clickhouse\r\n1. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x972236d in /usr/bin/clickhouse\r\n2. ? @ 0xdf0d851 in /usr/bin/clickhouse\r\n3. std::__1::shared_ptr<DB::IExternalLoadable const> DB::ExternalLoader::load<std::__1::shared_ptr<DB::IExternalLoadable const>, void>(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) const @ 0xdf188e3 in /usr/bin/clickhouse\r\n4. ? @ 0xe5148fc in /usr/bin/clickhouse\r\n5. DB::StorageFactory::get(DB::ASTCreateQuery const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::Context&, DB::Context&, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, bool) const @ 0xe5383ad in /usr/bin/clickhouse\r\n6. DB::createTableFromAST(DB::ASTCreateQuery, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::Context&, bool) @ 0xdefcb69 in /usr/bin/clickhouse\r\n7. ? @ 0xdeef558 in /usr/bin/clickhouse\r\n8. ? @ 0xdeeff12 in /usr/bin/clickhouse\r\n9. ThreadPoolImpl<ThreadFromGlobalPool>::worker(std::__1::__list_iterator<ThreadFromGlobalPool, void*>) @ 0x9750b17 in /usr/bin/clickhouse\r\n10. ThreadFromGlobalPool::ThreadFromGlobalPool<void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()>(void&&, void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()&&...)::'lambda'()::operator()() const @ 0x975128a in /usr/bin/clickhouse\r\n11. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x9750027 in /usr/bin/clickhouse\r\n12. ? @ 0x974e563 in /usr/bin/clickhouse\r\n13. start_thread @ 0x7fa3 in /lib/x86_64-linux-gnu/libpthread-2.28.so\r\n14. clone @ 0xf94cf in /lib/x86_64-linux-gnu/libc-2.28.so\r\n (version 20.6.1.3853 (official build))\r\n2020.06.30 22:10:01.483280 [ 18610 ] {} <Information> Application: Shutting down storages.\r\n2020.06.30 22:10:01.483302 [ 18645 ] {} <Trace> SystemLog (system.query_log): Terminating\r\n2020.06.30 22:10:01.483348 [ 18674 ] {} <Trace> SystemLog (system.query_thread_log): Terminating\r\n2020.06.30 22:10:01.483373 [ 18655 ] {} <Trace> SystemLog (system.trace_log): Terminating\r\n\n@vitlibar @alexey-milovidov it's impossible to start CH 20.4+ if one have a table with Engine=Dictionary (old xml dictionary).\r\n\r\nto start CH, it needs to remove tables metadata ( `rm /var/lib/clickhouse/metadata/default/node.sql` ) start CH, create tables.\nI'll try to fix it.\nYou took 20.4.1 from master? There was no 20.4 stable release https://github.com/ClickHouse/ClickHouse/pulls?q=is%3Apr+is%3Aopen+label%3Arelease\n@qoega yes, I took from master. \r\n\r\nI changed to version v20.3.5.21, which is a stable release, but the issue still happened. May you help for this?\nthis code in `DatabaseOrdinary.cpp` should have some problem\r\n\r\n```\r\nvoid tryAttachTable(\r\n        Context & context,\r\n        const ASTCreateQuery & query,\r\n        DatabaseOrdinary & database,\r\n        const String & database_name,\r\n        const String & metadata_path,\r\n        bool has_force_restore_data_flag)\r\n    {\r\n        assert(!query.is_dictionary);\r\n        try\r\n        {\r\n            String table_name;\r\n            StoragePtr table;\r\n            std::tie(table_name, table)\r\n                = createTableFromAST(query, database_name, database.getTableDataPath(query), context, has_force_restore_data_flag);\r\n            database.attachTable(table_name, table);\r\n        }\r\n        catch (Exception & e)\r\n        {\r\n            e.addMessage(\"Cannot attach table \" + backQuote(database_name) + \".\" + backQuote(query.table)\r\n                + \" from metadata file \" + metadata_path\r\n                + \" from query \" + serializeAST(query));\r\n            throw;\r\n        }\r\n    }\r\n``` \r\n\r\nIf a table has engine type of Dictionary('external_dictionary_a'). If `external_dictionary_a` is never loaded because of `dictionaries_lazy_load` set to true => exception is thrown during server starts up. We should expect `tryAttachTable` function will skip checking for table of Dictionary engine type.\r\n\r\n\nany update for this issue?\nSince 19.6? CH unable to use dictionaries from main folder using wildcards *_dictionary.xml\r\nTry to create a new folder `mkdir /etc/clickhouse-server/dict` and put dictionarie's xml there.\r\n\r\nand add to config:\r\n`    <dictionaries_config>dict/*.xml</dictionaries_config> `\n@den-crane in my setup, I already did that. Actually, server still can load the dictionaries from .xml files when server starts. Then I still can create Dictionary table. After that, the issue only happens when server needs to restart. At this time, server can not ATTACH the Dictionary table, which I created before restart. \nfacing the same issue ... !! any updates...!!\nHi, any update on this?",
  "created_at": "2020-07-03T14:00:31Z",
  "modified_files": [
    "src/Databases/DatabaseDictionary.cpp",
    "src/Databases/DatabaseWithDictionaries.cpp",
    "src/Storages/StorageDictionary.cpp",
    "src/Storages/StorageDictionary.h"
  ],
  "modified_test_files": [
    "b/tests/integration/test_dictionaries_dependency/configs/disable_lazy_load.xml",
    "b/tests/integration/test_dictionaries_dependency/test.py"
  ]
}