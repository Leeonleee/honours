{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 84561,
  "instance_id": "ClickHouse__ClickHouse-84561",
  "issue_numbers": [
    "38564"
  ],
  "base_commit": "f3535f375e495cda5f8576d6639880c296083970",
  "patch": "diff --git a/base/glibc-compatibility/memcpy/memcpy.h b/base/glibc-compatibility/memcpy/memcpy.h\nindex 86439dda0612..e202a685c1f8 100644\n--- a/base/glibc-compatibility/memcpy/memcpy.h\n+++ b/base/glibc-compatibility/memcpy/memcpy.h\n@@ -181,7 +181,14 @@ static inline void * inline_memcpy(void * __restrict dst_, const void * __restri\n             /// Aligned unrolled copy. We will use half of available SSE registers.\n             /// It's not possible to have both src and dst aligned.\n             /// So, we will use aligned stores and unaligned loads.\n-            __m128i c0, c1, c2, c3, c4, c5, c6, c7;\n+            __m128i c0;\n+            __m128i c1;\n+            __m128i c2;\n+            __m128i c3;\n+            __m128i c4;\n+            __m128i c5;\n+            __m128i c6;\n+            __m128i c7;\n \n             while (size >= 128)\n             {\ndiff --git a/src/DataTypes/Serializations/SerializationString.cpp b/src/DataTypes/Serializations/SerializationString.cpp\nindex d3f23603c4e5..5d1b374b6519 100644\n--- a/src/DataTypes/Serializations/SerializationString.cpp\n+++ b/src/DataTypes/Serializations/SerializationString.cpp\n@@ -14,12 +14,6 @@\n #include <IO/VarInt.h>\n #include <IO/ReadBufferFromString.h>\n \n-#include <base/unit.h>\n-\n-#ifdef __SSE2__\n-    #include <emmintrin.h>\n-#endif\n-\n \n namespace DB\n {\n@@ -147,8 +141,8 @@ void SerializationString::serializeBinaryBulk(const IColumn & column, WriteBuffe\n     }\n }\n \n-template <int UNROLL_TIMES>\n-static NO_INLINE void deserializeBinarySSE2(ColumnString::Chars & data, ColumnString::Offsets & offsets, ReadBuffer & istr, size_t limit)\n+template <size_t copy_size>\n+static NO_INLINE void deserializeBinaryImpl(ColumnString::Chars & data, ColumnString::Offsets & offsets, ReadBuffer & istr, size_t limit)\n {\n     size_t offset = data.size();\n     /// Avoiding calling resize in a loop improves the performance.\n@@ -178,27 +172,24 @@ static NO_INLINE void deserializeBinarySSE2(ColumnString::Chars & data, ColumnSt\n \n         if (size)\n         {\n-#ifdef __SSE2__\n             /// An optimistic branch in which more efficient copying is possible.\n-            if (offset + 16 * UNROLL_TIMES <= data.capacity() && istr.position() + size + 16 * UNROLL_TIMES <= istr.buffer().end())\n+            if (offset + copy_size <= data.capacity() && istr.position() + size + copy_size <= istr.buffer().end())\n             {\n-                const __m128i * sse_src_pos = reinterpret_cast<const __m128i *>(istr.position());\n-                const __m128i * sse_src_end = sse_src_pos + (size + (16 * UNROLL_TIMES - 1)) / 16 / UNROLL_TIMES * UNROLL_TIMES;\n-                __m128i * sse_dst_pos = reinterpret_cast<__m128i *>(&data[offset - size - 1]);\n+                const char * src_pos = istr.position();\n+                const char * src_end = src_pos + size;\n+                auto * dst_pos = &data[offset - size - 1];\n \n-                while (sse_src_pos < sse_src_end)\n+                while (src_pos < src_end)\n                 {\n-                    for (size_t j = 0; j < UNROLL_TIMES; ++j)\n-                        _mm_storeu_si128(sse_dst_pos + j, _mm_loadu_si128(sse_src_pos + j));\n+                    __builtin_memcpy(dst_pos, src_pos, copy_size);\n \n-                    sse_src_pos += UNROLL_TIMES;\n-                    sse_dst_pos += UNROLL_TIMES;\n+                    src_pos += copy_size;\n+                    dst_pos += copy_size;\n                 }\n \n                 istr.position() += size;\n             }\n             else\n-#endif\n             {\n                 istr.readStrict(reinterpret_cast<char*>(&data[offset - size - 1]), size);\n             }\n@@ -256,13 +247,13 @@ void SerializationString::deserializeBinaryBulk(IColumn & column, ReadBuffer & i\n     offsets.reserve(offsets.size() + limit);\n \n     if (avg_chars_size >= 64)\n-        deserializeBinarySSE2<4>(data, offsets, istr, limit);\n+        deserializeBinaryImpl<64>(data, offsets, istr, limit);\n     else if (avg_chars_size >= 48)\n-        deserializeBinarySSE2<3>(data, offsets, istr, limit);\n+        deserializeBinaryImpl<48>(data, offsets, istr, limit);\n     else if (avg_chars_size >= 32)\n-        deserializeBinarySSE2<2>(data, offsets, istr, limit);\n+        deserializeBinaryImpl<32>(data, offsets, istr, limit);\n     else\n-        deserializeBinarySSE2<1>(data, offsets, istr, limit);\n+        deserializeBinaryImpl<16>(data, offsets, istr, limit);\n }\n \n \n",
  "test_patch": "diff --git a/tests/performance/small_string_deserialization.xml b/tests/performance/small_string_deserialization.xml\nnew file mode 100644\nindex 000000000000..b3aef5632004\n--- /dev/null\n+++ b/tests/performance/small_string_deserialization.xml\n@@ -0,0 +1,8 @@\n+<test>\n+    <create_query>CREATE TABLE small_strings (s String) ENGINE = Log</create_query>\n+    <fill_query>INSERT INTO small_strings SELECT number % 10 = 0 ? 'ab' : 'c' FROM numbers_mt(1e9)</fill_query>\n+\n+    <query>SELECT count() FROM small_strings WHERE NOT ignore(s)</query>\n+\n+    <drop_query>DROP TABLE IF EXISTS small_strings</drop_query>\n+</test>\ndiff --git a/tests/performance/string_deserialization.xml b/tests/performance/string_deserialization.xml\nnew file mode 100644\nindex 000000000000..51e919160f7b\n--- /dev/null\n+++ b/tests/performance/string_deserialization.xml\n@@ -0,0 +1,8 @@\n+<test>\n+    <query>SELECT count() FROM hits_10m_single WHERE NOT ignore(MobilePhoneModel)</query>\n+    <query>SELECT count() FROM hits_10m_single WHERE NOT ignore(SearchPhrase)</query>\n+    <query>SELECT count() FROM hits_10m_single WHERE NOT ignore(URL)</query>\n+    <query>SELECT count() FROM hits_10m_single WHERE NOT ignore(Referer)</query>\n+    <query>SELECT count() FROM hits_10m_single WHERE NOT ignore(Title)</query>\n+    <query>SELECT count() FROM hits_10m_single WHERE CounterID &lt;= 10000 AND NOT ignore(MobilePhoneModel, SearchPhrase, URL, Referer, Title)</query>\n+</test>\n",
  "problem_statement": "Consider changing deserializeBinarySSE to more general form\nCurrently, Clickhouse specialized the optimistic branch for SSE2 with intrinsics.\r\n\r\nhttps://github.com/ClickHouse/ClickHouse/blob/8246e55002a34c8d88f3f6de28d757441660df12/src/DataTypes/Serializations/SerializationString.cpp#L129\r\n\r\nExperiments show that `__builtin_memcpy(_inline)` can actually yield similar result for generic x86 targets. Moreover, by switching to `__builtin_memcpy(_inline)`, other targets like asimd(aarch64), avx2, avx512f can also utilize the optimistic optimization.\r\n\r\nI have played with the following code, some bench results are listed at downstream: https://github.com/pingcap/tiflash/pull/5248.\r\n\r\n```c++\r\n#include <chrono>\r\n#include <cstddef>\r\n#include <cstdint>\r\n#include <cstring>\r\n#include <fstream>\r\n#include <iostream>\r\n#include <random>\r\n#include <vector>\r\nusing namespace std::chrono;\r\n\r\nstruct ReadBuffer\r\n{\r\n    FILE * input;\r\n    std::vector<char> buffer;\r\n    char * current;\r\n    char * end;\r\n\r\n    ReadBuffer(const char * path, size_t buffer_size)\r\n        : input(::fopen(path, \"r\"))\r\n        , buffer(buffer_size)\r\n        , current(buffer.data() + buffer_size)\r\n        , end(buffer.data() + buffer_size)\r\n    {\r\n    }\r\n\r\n    void nextFrame()\r\n    {\r\n        auto count = ::fread(buffer.data(), 1, buffer.size(), input);\r\n        current = buffer.data();\r\n        end = current + count;\r\n    }\r\n\r\n    void read(char * dst, size_t size)\r\n    {\r\n        while (size)\r\n        {\r\n            if (current >= end)\r\n            {\r\n                nextFrame();\r\n            }\r\n            auto length = std::min(static_cast<size_t>(end - current), size);\r\n            ::memcpy(dst, current, length);\r\n            current += length;\r\n            dst += length;\r\n            size -= length;\r\n        }\r\n    }\r\n\r\n    ~ReadBuffer()\r\n    {\r\n        ::fclose(input);\r\n    }\r\n};\r\n\r\ntemplate <size_t BLOCK_SIZE>\r\nstatic __attribute__((noinline)) inline void deserializeBinaryBlockImpl(ReadBuffer & input, std::vector<size_t> & offsets, std::vector<char> & data, size_t limit)\r\n{\r\n    size_t offset = data.size();\r\n\r\n    for (size_t i = 0; i < limit; ++i)\r\n    {\r\n        size_t size;\r\n        input.read(reinterpret_cast<char *>(&size), sizeof(size));\r\n        offset += size + 1;\r\n        offsets.push_back(offset);\r\n        data.resize(offset);\r\n\r\n#ifdef ERMS\r\n        // The intel reference manual states that for sizes larger than 128, using REP MOVSB will give identical performance with other variants.\r\n        // Beginning from 2048 bytes, REP MOVSB gives an even better performance.\r\n        if constexpr (BLOCK_SIZE >= 256)\r\n        {\r\n            /*\r\n             * According to intel's reference manual:\r\n             *\r\n             * On older microarchitecture (ivy bridge), a REP MOVSB implementation of memcpy can achieve throughput at\r\n             * slightly better than the 128-bit SIMD implementation when copying thousands of bytes.\r\n             *\r\n             * On newer microarchitecture (haswell), using REP MOVSB to implement memcpy operation for large copy length\r\n             * can take advantage the 256-bit store data path and deliver throughput of more than 20 bytes per cycle.\r\n             * For copy length that are smaller than a few hundred bytes, REP MOVSB approach is still slower than those\r\n             * SIMD approaches.\r\n             */\r\n            if (size >= 1024 && input.current + size <= input.end)\r\n            {\r\n                const auto * src = reinterpret_cast<const char *>(input.current);\r\n                auto * dst = reinterpret_cast<char *>(&data[offset - size - 1]);\r\n                input.current += size;\r\n                /*\r\n                 *  For destination buffer misalignment:\r\n                 *  The impact on Enhanced REP MOVSB and STOSB implementation can be 25%\r\n                 *  degradation, while 128-bit AVX implementation of memcpy may degrade only\r\n                 *  5%, relative to 16-byte aligned scenario.\r\n                 *\r\n                 *  Therefore, we manually align up the destination buffer before startup.\r\n                 */\r\n                __builtin_memcpy_inline(dst, src, 64);\r\n                auto address = reinterpret_cast<uintptr_t>(dst);\r\n                auto shift = 64ull - (address % 64ull);\r\n                dst += shift;\r\n                src += shift;\r\n                size -= shift;\r\n                asm volatile(\"rep movsb\"\r\n                             : \"+D\"(dst), \"+S\"(src), \"+c\"(size)\r\n                             :\r\n                             : \"memory\");\r\n                data[offset - 1] = 0;\r\n                continue;\r\n            }\r\n        }\r\n#endif\r\n\r\n        if (size)\r\n        {\r\n#ifdef OPTIMISTIC_BRANCH\r\n            /// An optimistic branch in which more efficient copying is possible.\r\n            if (offset + BLOCK_SIZE <= data.capacity() && input.current + size + BLOCK_SIZE <= input.end)\r\n            {\r\n                const auto * src = reinterpret_cast<const char *>(input.current);\r\n                const auto * target = src + (size + BLOCK_SIZE - 1) / BLOCK_SIZE * BLOCK_SIZE;\r\n                auto * dst = reinterpret_cast<char *>(&data[offset - size - 1]);\r\n\r\n                while (src < target)\r\n                {\r\n                    /**\r\n                     * Compiler expands the builtin memcpy perfectly. There is no need to\r\n                     * manually write SSE2 code for x86 here; moreover, this method can also bring\r\n                     * optimization to aarch64 targets.\r\n                     *\r\n                     * (x86 loop body for 64 bytes version with XMM registers)\r\n                     *     movups  xmm0, xmmword ptr [rsi]\r\n                     *     movups  xmm1, xmmword ptr [rsi + 16]\r\n                     *     movups  xmm2, xmmword ptr [rsi + 32]\r\n                     *     movups  xmm3, xmmword ptr [rsi + 48]\r\n                     *     movups  xmmword ptr [rdi + 48], xmm3\r\n                     *     movups  xmmword ptr [rdi + 32], xmm2\r\n                     *     movups  xmmword ptr [rdi + 16], xmm1\r\n                     *     movups  xmmword ptr [rdi], xmm0\r\n                     *\r\n                     * (aarch64 loop body for 64 bytes version with Q registers)\r\n                     *     ldp     q0, q1, [x1]\r\n                     *     ldp     q2, q3, [x1, #32]\r\n                     *     stp     q0, q1, [x0]\r\n                     *     add     x1, x1, #64\r\n                     *     cmp     x1, x8\r\n                     *     stp     q2, q3, [x0, #32]\r\n                     *     add     x0, x0, #64\r\n                     */\r\n                    __builtin_memcpy_inline(dst, src, BLOCK_SIZE);\r\n                    src += BLOCK_SIZE;\r\n                    dst += BLOCK_SIZE;\r\n                }\r\n                input.current += size;\r\n            }\r\n            else\r\n#endif\r\n            {\r\n                input.read(&data[offset - size - 1], size);\r\n            }\r\n        }\r\n\r\n        data[offset - 1] = 0;\r\n    }\r\n}\r\n\r\n\r\nvoid generate(const char * output, size_t count, size_t limit, uint64_t seed)\r\n{\r\n    std::default_random_engine eng(seed);\r\n    std::normal_distribution<double> dist{0.5, 0.16};\r\n    auto double_limit = static_cast<double>(limit);\r\n    auto * out = ::fopen(output, \"w\");\r\n    std::vector<char> data;\r\n    for (size_t i = 0; i < count; ++i)\r\n    {\r\n        auto length = static_cast<size_t>(dist(eng) * double_limit);\r\n        length = std::min(std::max(size_t{0}, length), limit);\r\n        data.resize(length, '@');\r\n        ::fwrite(&length, 1, sizeof(length), out);\r\n        ::fwrite(data.data(), 1, data.size(), out);\r\n    }\r\n    ::fclose(out);\r\n}\r\n\r\nstatic const uint64_t seed = 0x12345678ull;\r\nstatic const size_t count = 10000;\r\nstatic const size_t buffer_size = 1048576ULL;\r\n\r\nvoid bench(size_t average)\r\n{\r\n    std::cout << \"benchmarking for strings with average length: \" << average << \", \";\r\n    std::cout.flush();\r\n\r\n    generate(\"/tmp/data-test\", count, average * 2, seed);\r\n    auto buffer = ReadBuffer{\"/tmp/data-test\", buffer_size};\r\n    std::vector<char> data;\r\n    std::vector<size_t> offsets;\r\n#ifdef __x86_64__\r\n    auto start = __builtin_readcyclecounter();\r\n#else\r\n    auto start = high_resolution_clock::now();\r\n#endif\r\n    if (average >= 256)\r\n    {\r\n        deserializeBinaryBlockImpl<256>(buffer, offsets, data, count);\r\n    }\r\n    else if (average >= 128)\r\n    {\r\n        deserializeBinaryBlockImpl<128>(buffer, offsets, data, count);\r\n    }\r\n    else if (average >= 64)\r\n    {\r\n        deserializeBinaryBlockImpl<64>(buffer, offsets, data, count);\r\n    }\r\n    else if (average >= 48)\r\n    {\r\n        deserializeBinaryBlockImpl<48>(buffer, offsets, data, count);\r\n    }\r\n    else if (average >= 32)\r\n    {\r\n        deserializeBinaryBlockImpl<32>(buffer, offsets, data, count);\r\n    }\r\n    else\r\n    {\r\n        deserializeBinaryBlockImpl<16>(buffer, offsets, data, count);\r\n    }\r\n#ifdef __x86_64__\r\n    auto end = __builtin_readcyclecounter();\r\n    std::cout << \"cycle count: \" << end - start << std::endl;\r\n#else\r\n    auto end = high_resolution_clock::now();\r\n    std::cout << \"time count: \" << duration_cast<nanoseconds>(end - start).count() << std::endl;\r\n#endif\r\n}\r\n\r\nint main()\r\n{\r\n    bench(8);\r\n    bench(16);\r\n    bench(32);\r\n    bench(64);\r\n    bench(128);\r\n    bench(256);\r\n    bench(512);\r\n    bench(1024);\r\n    bench(2048);\r\n    bench(4096);\r\n    bench(16384);\r\n}\r\n```\n",
  "hints_text": "",
  "created_at": "2025-07-28T09:26:10Z",
  "modified_files": [
    "base/glibc-compatibility/memcpy/memcpy.h",
    "src/DataTypes/Serializations/SerializationString.cpp"
  ],
  "modified_test_files": [
    "b/tests/performance/small_string_deserialization.xml",
    "b/tests/performance/string_deserialization.xml"
  ]
}