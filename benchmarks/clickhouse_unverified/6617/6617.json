{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 6617,
  "instance_id": "ClickHouse__ClickHouse-6617",
  "issue_numbers": [
    "6502"
  ],
  "base_commit": "a52c004b5b364d64fa2fd6c5ae521beda60d106d",
  "patch": "diff --git a/dbms/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp b/dbms/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp\nindex 74193fa71568..5a9affaacd4d 100644\n--- a/dbms/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp\n+++ b/dbms/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp\n@@ -157,7 +157,14 @@ UInt64 MergeTreeDataMergerMutator::getMaxSourcePartsSizeForMerge(size_t pool_siz\n \n UInt64 MergeTreeDataMergerMutator::getMaxSourcePartSizeForMutation()\n {\n-    return static_cast<UInt64>(DiskSpaceMonitor::getUnreservedFreeSpace(data.full_path) / DISK_USAGE_COEFFICIENT_TO_RESERVE);\n+    size_t total_threads_in_pool = pool.getNumberOfThreads();\n+    size_t busy_threads_in_pool = CurrentMetrics::values[CurrentMetrics::BackgroundPoolTask].load(std::memory_order_relaxed);\n+\n+    /// Allow mutations only if there are enough threads, leave free threads for merges else\n+    if (total_threads_in_pool - busy_threads_in_pool >= data.settings.number_of_free_entries_in_pool_to_execute_mutation)\n+        return static_cast<UInt64>(DiskSpaceMonitor::getUnreservedFreeSpace(data.full_path) / DISK_USAGE_COEFFICIENT_TO_RESERVE);\n+\n+    return 0;\n }\n \n \ndiff --git a/dbms/src/Storages/MergeTree/MergeTreeSettings.h b/dbms/src/Storages/MergeTree/MergeTreeSettings.h\nindex e670000ecc5b..afd0772a9374 100644\n--- a/dbms/src/Storages/MergeTree/MergeTreeSettings.h\n+++ b/dbms/src/Storages/MergeTree/MergeTreeSettings.h\n@@ -30,8 +30,10 @@ struct MergeTreeSettings : public SettingsCollection<MergeTreeSettings>\n     /** Merge settings. */ \\\n     M(SettingUInt64, max_bytes_to_merge_at_max_space_in_pool, 150ULL * 1024 * 1024 * 1024, \"Maximum in total size of parts to merge, when there are maximum free threads in background pool (or entries in replication queue).\") \\\n     M(SettingUInt64, max_bytes_to_merge_at_min_space_in_pool, 1024 * 1024, \"Maximum in total size of parts to merge, when there are minimum free threads in background pool (or entries in replication queue).\") \\\n-    M(SettingUInt64, max_replicated_merges_in_queue, 16, \"How many tasks of merging parts are allowed simultaneously in ReplicatedMergeTree queue.\") \\\n+    M(SettingUInt64, max_replicated_merges_in_queue, 16, \"How many tasks of merging and mutating parts are allowed simultaneously in ReplicatedMergeTree queue.\") \\\n+    M(SettingUInt64, max_replicated_mutations_in_queue, 8, \"How many tasks of mutating parts are allowed simultaneously in ReplicatedMergeTree queue.\") \\\n     M(SettingUInt64, number_of_free_entries_in_pool_to_lower_max_size_of_merge, 8, \"When there is less than specified number of free entries in pool (or replicated queue), start to lower maximum size of merge to process (or to put in queue). This is to allow small merges to process - not filling the pool with long running merges.\") \\\n+    M(SettingUInt64, number_of_free_entries_in_pool_to_execute_mutation, 10, \"When there is less than specified number of free entries in pool, do not execute part mutations. This is to leave free threads for regular merges and avoid \\\"Too many parts\\\"\") \\\n     M(SettingSeconds, old_parts_lifetime, 8 * 60, \"How many seconds to keep obsolete parts.\") \\\n     M(SettingSeconds, temporary_directories_lifetime, 86400, \"How many seconds to keep tmp_-directories.\") \\\n     \\\ndiff --git a/dbms/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp b/dbms/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp\nindex 665e8c9bd5c5..fd65f14fedbf 100644\n--- a/dbms/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp\n+++ b/dbms/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp\n@@ -956,15 +956,19 @@ bool ReplicatedMergeTreeQueue::shouldExecuteLogEntry(\n             return false;\n         }\n \n-        /** Execute merge only if there are enough free threads in background pool to do merges of that size.\n-          * But if all threads are free (maximal size of merge is allowed) then execute any merge,\n-          *  (because it may be ordered by OPTIMIZE or early with differrent settings).\n+        UInt64 max_source_parts_size = entry.type == LogEntry::MERGE_PARTS ? merger_mutator.getMaxSourcePartsSizeForMerge()\n+                                                                           : merger_mutator.getMaxSourcePartSizeForMutation();\n+        /** If there are enough free threads in background pool to do large merges (maximal size of merge is allowed),\n+          * then ignore value returned by getMaxSourcePartsSizeForMerge() and execute merge of any size,\n+          * because it may be ordered by OPTIMIZE or early with different settings.\n+          * Setting max_bytes_to_merge_at_max_space_in_pool still working for regular merges,\n+          * because the leader replica does not assign merges of greater size (except OPTIMIZE PARTITION and OPTIMIZE FINAL).\n           */\n-        UInt64 max_source_parts_size = merger_mutator.getMaxSourcePartsSizeForMerge();\n-        if (max_source_parts_size != data.settings.max_bytes_to_merge_at_max_space_in_pool\n-            && sum_parts_size_in_bytes > max_source_parts_size)\n+        bool ignore_max_size = (entry.type == LogEntry::MERGE_PARTS) && (max_source_parts_size == data.settings.max_bytes_to_merge_at_max_space_in_pool);\n+\n+        if (!ignore_max_size && sum_parts_size_in_bytes > max_source_parts_size)\n         {\n-            String reason = \"Not executing log entry for part \" + entry.new_part_name\n+            String reason = \"Not executing log entry \" + entry.typeToString() + \" for part \" + entry.new_part_name\n                 + \" because source parts size (\" + formatReadableSizeWithBinarySuffix(sum_parts_size_in_bytes)\n                 + \") is greater than the current maximum (\" + formatReadableSizeWithBinarySuffix(max_source_parts_size) + \").\";\n             LOG_DEBUG(log, reason);\n@@ -1154,17 +1158,21 @@ bool ReplicatedMergeTreeQueue::processEntry(\n }\n \n \n-size_t ReplicatedMergeTreeQueue::countMergesAndPartMutations() const\n+std::pair<size_t, size_t> ReplicatedMergeTreeQueue::countMergesAndPartMutations() const\n {\n     std::lock_guard lock(state_mutex);\n \n-    size_t count = 0;\n+    size_t count_merges = 0;\n+    size_t count_mutations = 0;\n     for (const auto & entry : queue)\n-        if (entry->type == ReplicatedMergeTreeLogEntry::MERGE_PARTS\n-            || entry->type == ReplicatedMergeTreeLogEntry::MUTATE_PART)\n-            ++count;\n+    {\n+        if (entry->type == ReplicatedMergeTreeLogEntry::MERGE_PARTS)\n+            ++count_merges;\n+        else if (entry->type == ReplicatedMergeTreeLogEntry::MUTATE_PART)\n+            ++count_mutations;\n+    }\n \n-    return count;\n+    return std::make_pair(count_merges, count_mutations);\n }\n \n \ndiff --git a/dbms/src/Storages/MergeTree/ReplicatedMergeTreeQueue.h b/dbms/src/Storages/MergeTree/ReplicatedMergeTreeQueue.h\nindex 47d82f4a9a2a..5a84cfbb5a6b 100644\n--- a/dbms/src/Storages/MergeTree/ReplicatedMergeTreeQueue.h\n+++ b/dbms/src/Storages/MergeTree/ReplicatedMergeTreeQueue.h\n@@ -296,7 +296,7 @@ class ReplicatedMergeTreeQueue\n     bool processEntry(std::function<zkutil::ZooKeeperPtr()> get_zookeeper, LogEntryPtr & entry, const std::function<bool(LogEntryPtr &)> func);\n \n     /// Count the number of merges and mutations of single parts in the queue.\n-    size_t countMergesAndPartMutations() const;\n+    std::pair<size_t, size_t> countMergesAndPartMutations() const;\n \n     /// Count the total number of active mutations.\n     size_t countMutations() const;\ndiff --git a/dbms/src/Storages/StorageMergeTree.cpp b/dbms/src/Storages/StorageMergeTree.cpp\nindex d062bb197ca7..779efe95a8c2 100644\n--- a/dbms/src/Storages/StorageMergeTree.cpp\n+++ b/dbms/src/Storages/StorageMergeTree.cpp\n@@ -624,8 +624,6 @@ bool StorageMergeTree::tryMutatePart()\n     /// You must call destructor with unlocked `currently_merging_mutex`.\n     std::optional<CurrentlyMergingPartsTagger> tagger;\n     {\n-        auto disk_space = DiskSpaceMonitor::getUnreservedFreeSpace(full_path);\n-\n         std::lock_guard lock(currently_merging_mutex);\n \n         if (current_mutations_by_version.empty())\n@@ -641,8 +639,7 @@ bool StorageMergeTree::tryMutatePart()\n             if (mutations_begin_it == mutations_end_it)\n                 continue;\n \n-            auto estimated_needed_space = MergeTreeDataMergerMutator::estimateNeededDiskSpace({part});\n-            if (estimated_needed_space > disk_space)\n+            if (merger_mutator.getMaxSourcePartSizeForMutation() < part->bytes_on_disk)\n                 continue;\n \n             for (auto it = mutations_begin_it; it != mutations_end_it; ++it)\n@@ -655,7 +652,7 @@ bool StorageMergeTree::tryMutatePart()\n             future_part.part_info = new_part_info;\n             future_part.name = part->getNewName(new_part_info);\n \n-            tagger.emplace(future_part, estimated_needed_space, *this);\n+            tagger.emplace(future_part, MergeTreeDataMergerMutator::estimateNeededDiskSpace({part}), *this);\n             break;\n         }\n     }\ndiff --git a/dbms/src/Storages/StorageReplicatedMergeTree.cpp b/dbms/src/Storages/StorageReplicatedMergeTree.cpp\nindex 8b32cc327049..7a946400658a 100644\n--- a/dbms/src/Storages/StorageReplicatedMergeTree.cpp\n+++ b/dbms/src/Storages/StorageReplicatedMergeTree.cpp\n@@ -2193,17 +2193,18 @@ void StorageReplicatedMergeTree::mergeSelectingTask()\n         /// If many merges is already queued, then will queue only small enough merges.\n         /// Otherwise merge queue could be filled with only large merges,\n         /// and in the same time, many small parts could be created and won't be merged.\n-        size_t merges_and_mutations_queued = queue.countMergesAndPartMutations();\n-        if (merges_and_mutations_queued >= settings.max_replicated_merges_in_queue)\n+        auto merges_and_mutations_queued = queue.countMergesAndPartMutations();\n+        size_t merges_and_mutations_sum = merges_and_mutations_queued.first + merges_and_mutations_queued.second;\n+        if (merges_and_mutations_sum >= settings.max_replicated_merges_in_queue)\n         {\n-            LOG_TRACE(log, \"Number of queued merges and part mutations (\" << merges_and_mutations_queued\n-                << \") is greater than max_replicated_merges_in_queue (\"\n+            LOG_TRACE(log, \"Number of queued merges (\" << merges_and_mutations_queued.first << \") and part mutations (\"\n+                << merges_and_mutations_queued.second << \") is greater than max_replicated_merges_in_queue (\"\n                 << settings.max_replicated_merges_in_queue << \"), so won't select new parts to merge or mutate.\");\n         }\n         else\n         {\n             UInt64 max_source_parts_size_for_merge = merger_mutator.getMaxSourcePartsSizeForMerge(\n-                settings.max_replicated_merges_in_queue, merges_and_mutations_queued);\n+                settings.max_replicated_merges_in_queue, merges_and_mutations_sum);\n             UInt64 max_source_part_size_for_mutation = merger_mutator.getMaxSourcePartSizeForMutation();\n \n             FutureMergedMutatedPart future_merged_part;\n@@ -2213,7 +2214,9 @@ void StorageReplicatedMergeTree::mergeSelectingTask()\n                 success = createLogEntryToMergeParts(zookeeper, future_merged_part.parts,\n                     future_merged_part.name, deduplicate, force_ttl);\n             }\n-            else if (max_source_part_size_for_mutation > 0 && queue.countMutations() > 0)\n+            /// If there are many mutations in queue it may happen, that we cannot enqueue enough merges to merge all new parts\n+            else if (max_source_part_size_for_mutation > 0 && queue.countMutations() > 0\n+                     && merges_and_mutations_queued.second < settings.max_replicated_mutations_in_queue)\n             {\n                 /// Choose a part to mutate.\n                 DataPartsVector data_parts = getDataPartsVector();\n",
  "test_patch": "diff --git a/dbms/tests/integration/test_replicated_mutations/configs/merge_tree_max_parts.xml b/dbms/tests/integration/test_replicated_mutations/configs/merge_tree_max_parts.xml\nnew file mode 100644\nindex 000000000000..60047dcab2ce\n--- /dev/null\n+++ b/dbms/tests/integration/test_replicated_mutations/configs/merge_tree_max_parts.xml\n@@ -0,0 +1,6 @@\n+<yandex>\n+    <merge_tree>\n+        <parts_to_delay_insert>50</parts_to_delay_insert>\n+        <parts_to_throw_insert>50</parts_to_throw_insert>\n+    </merge_tree>\n+</yandex>\n\\ No newline at end of file\ndiff --git a/dbms/tests/integration/test_replicated_mutations/test.py b/dbms/tests/integration/test_replicated_mutations/test.py\nindex 351ceff36083..0347ba4782c5 100644\n--- a/dbms/tests/integration/test_replicated_mutations/test.py\n+++ b/dbms/tests/integration/test_replicated_mutations/test.py\n@@ -10,21 +10,29 @@\n \n cluster = ClickHouseCluster(__file__)\n \n-node1 = cluster.add_instance('node1', with_zookeeper=True)\n+node1 = cluster.add_instance('node1', macros={'cluster': 'test1'}, with_zookeeper=True)\n # Check, that limits on max part size for merges doesn`t affect mutations\n-node2 = cluster.add_instance('node2', main_configs=[\"configs/merge_tree.xml\"], with_zookeeper=True)\n-nodes = [node1, node2]\n+node2 = cluster.add_instance('node2', macros={'cluster': 'test1'}, main_configs=[\"configs/merge_tree.xml\"], with_zookeeper=True)\n+\n+node3 = cluster.add_instance('node3', macros={'cluster': 'test2'}, main_configs=[\"configs/merge_tree_max_parts.xml\"], with_zookeeper=True)\n+node4 = cluster.add_instance('node4', macros={'cluster': 'test2'}, main_configs=[\"configs/merge_tree_max_parts.xml\"], with_zookeeper=True)\n+\n+node5 = cluster.add_instance('node5', macros={'cluster': 'test3'}, main_configs=[\"configs/merge_tree_max_parts.xml\"])\n+\n+all_nodes = [node1, node2, node3, node4, node5]\n \n @pytest.fixture(scope=\"module\")\n def started_cluster():\n     try:\n         cluster.start()\n \n-        for node in nodes:\n+        for node in all_nodes:\n             node.query(\"DROP TABLE IF EXISTS test_mutations\")\n \n-        for node in nodes:\n-            node.query(\"CREATE TABLE test_mutations(d Date, x UInt32, i UInt32) ENGINE ReplicatedMergeTree('/clickhouse/tables/test/test_mutations', '{instance}') ORDER BY x PARTITION BY toYYYYMM(d)\")\n+        for node in [node1, node2, node3, node4]:\n+            node.query(\"CREATE TABLE test_mutations(d Date, x UInt32, i UInt32) ENGINE ReplicatedMergeTree('/clickhouse/{cluster}/tables/test/test_mutations', '{instance}') ORDER BY x PARTITION BY toYYYYMM(d)\")\n+\n+        node5.query(\"CREATE TABLE test_mutations(d Date, x UInt32, i UInt32) ENGINE MergeTree() ORDER BY x PARTITION BY toYYYYMM(d)\")\n \n         yield cluster\n \n@@ -33,7 +41,8 @@ def started_cluster():\n \n \n class Runner:\n-    def __init__(self):\n+    def __init__(self, nodes):\n+        self.nodes = nodes\n         self.mtx = threading.Lock()\n         self.total_inserted_xs = 0\n         self.total_inserted_rows = 0\n@@ -49,7 +58,9 @@ def __init__(self):\n \n         self.stop_ev = threading.Event()\n \n-    def do_insert(self, thread_num):\n+        self.exceptions = []\n+\n+    def do_insert(self, thread_num, partitions_num):\n         self.stop_ev.wait(random.random())\n \n         # Each thread inserts a small random number of rows with random year, month 01 and day determined\n@@ -67,7 +78,7 @@ def do_insert(self, thread_num):\n                 for x in xs:\n                     self.currently_inserting_xs[x] += 1\n \n-            year = 2000 + random.randint(0, 10)\n+            year = 2000 + random.randint(0, partitions_num)\n             date_str = '{year}-{month}-{day}'.format(year=year, month=month, day=day)\n             payload = ''\n             for x in xs:\n@@ -76,7 +87,7 @@ def do_insert(self, thread_num):\n \n             try:\n                 print 'thread {}: insert for {}: {}'.format(thread_num, date_str, ','.join(str(x) for x in xs))\n-                random.choice(nodes).query(\"INSERT INTO test_mutations FORMAT TSV\", payload)\n+                random.choice(self.nodes).query(\"INSERT INTO test_mutations FORMAT TSV\", payload)\n \n                 with self.mtx:\n                     for x in xs:\n@@ -86,6 +97,7 @@ def do_insert(self, thread_num):\n \n             except Exception, e:\n                 print 'Exception while inserting,', e\n+                self.exceptions.append(e)\n             finally:\n                 with self.mtx:\n                     for x in xs:\n@@ -113,7 +125,7 @@ def do_delete(self, thread_num):\n \n             try:\n                 print 'thread {}: delete {} * {}'.format(thread_num, to_delete_count, x)\n-                random.choice(nodes).query(\"ALTER TABLE test_mutations DELETE WHERE x = {}\".format(x))\n+                random.choice(self.nodes).query(\"ALTER TABLE test_mutations DELETE WHERE x = {}\".format(x))\n \n                 with self.mtx:\n                     self.total_mutations += 1\n@@ -130,14 +142,27 @@ def do_delete(self, thread_num):\n             self.stop_ev.wait(1.0 + random.random() * 2)\n \n \n+def wait_for_mutations(nodes, number_of_mutations):\n+    for i in range(100):  # wait for replication 80 seconds max\n+        time.sleep(0.8)\n+\n+        def get_done_mutations(node):\n+            return int(node.query(\"SELECT sum(is_done) FROM system.mutations WHERE table = 'test_mutations'\").rstrip())\n+\n+        if all([get_done_mutations(n) == number_of_mutations for n in nodes]):\n+            return True\n+    return False\n+\n+\n def test_mutations(started_cluster):\n     DURATION_SECONDS = 30\n+    nodes = [node1, node2]\n \n-    runner = Runner()\n+    runner = Runner(nodes)\n \n     threads = []\n     for thread_num in range(5):\n-        threads.append(threading.Thread(target=runner.do_insert, args=(thread_num, )))\n+        threads.append(threading.Thread(target=runner.do_insert, args=(thread_num, 10)))\n \n     for thread_num in (11, 12, 13):\n         threads.append(threading.Thread(target=runner.do_delete, args=(thread_num,)))\n@@ -155,18 +180,11 @@ def test_mutations(started_cluster):\n     assert runner.total_inserted_rows > 0\n     assert runner.total_mutations > 0\n \n-    all_done = False\n-    for i in range(100): # wait for replication 80 seconds max\n-        time.sleep(0.8)\n-\n-        def get_done_mutations(node):\n-            return int(node.query(\"SELECT sum(is_done) FROM system.mutations WHERE table = 'test_mutations'\").rstrip())\n+    all_done = wait_for_mutations(nodes, runner.total_mutations)\n \n-        if all([get_done_mutations(n) == runner.total_mutations for n in nodes]):\n-            all_done = True\n-            break\n-\n-    print node1.query(\"SELECT mutation_id, command, parts_to_do, is_done FROM system.mutations WHERE table = 'test_mutations' FORMAT TSVWithNames\")\n+    print \"Total mutations: \", runner.total_mutations\n+    for node in nodes:\n+        print node.query(\"SELECT mutation_id, command, parts_to_do, is_done FROM system.mutations WHERE table = 'test_mutations' FORMAT TSVWithNames\")\n     assert all_done\n \n     expected_sum = runner.total_inserted_xs - runner.total_deleted_xs\n@@ -174,3 +192,44 @@ def get_done_mutations(node):\n     for i, node in enumerate(nodes):\n         actual_sums.append(int(node.query(\"SELECT sum(x) FROM test_mutations\").rstrip()))\n         assert actual_sums[i] == expected_sum\n+\n+\n+@pytest.mark.parametrize(\n+    ('nodes', ),\n+    [\n+        ([node5, ], ),          # MergeTree\n+        ([node3, node4], ),     # ReplicatedMergeTree\n+    ]\n+)\n+def test_mutations_dont_prevent_merges(started_cluster, nodes):\n+    for year in range(2000, 2016):\n+        rows = ''\n+        date_str = '{}-01-{}'.format(year, random.randint(1, 10))\n+        for i in range(10):\n+            rows += '{}\t{}\t{}\\n'.format(date_str, random.randint(1, 10), i)\n+        nodes[0].query(\"INSERT INTO test_mutations FORMAT TSV\", rows)\n+\n+    # will run mutations of 16 parts in parallel, mutations will sleep for about 20 seconds\n+    nodes[0].query(\"ALTER TABLE test_mutations UPDATE i = sleepEachRow(2) WHERE 1\")\n+\n+    runner = Runner(nodes)\n+    threads = []\n+    for thread_num in range(2):\n+        threads.append(threading.Thread(target=runner.do_insert, args=(thread_num, 0)))\n+\n+    # will insert approx 8-10 new parts per 1 second into one partition\n+    for t in threads:\n+        t.start()\n+\n+    all_done = wait_for_mutations(nodes, 1)\n+\n+    runner.stop_ev.set()\n+    for t in threads:\n+        t.join()\n+\n+    for node in nodes:\n+        print node.query(\"SELECT mutation_id, command, parts_to_do, is_done FROM system.mutations WHERE table = 'test_mutations' FORMAT TSVWithNames\")\n+        print node.query(\"SELECT partition, count(name), sum(active), sum(active*rows) FROM system.parts WHERE table ='test_mutations' GROUP BY partition FORMAT TSVWithNames\")\n+\n+    assert all_done\n+    assert all([str(e).find(\"Too many parts\") < 0 for e in runner.exceptions])\n",
  "problem_statement": "Long ALTER UPDATE or DELETE may prevent regular merges to run.\nMerges and mutation use the same background pool and the same limit on the total size of planned operations. This may lead to \"Too many parts\" error after issuing a long running mutation.\n",
  "hints_text": "",
  "created_at": "2019-08-22T20:13:53Z",
  "modified_files": [
    "dbms/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp",
    "dbms/src/Storages/MergeTree/MergeTreeSettings.h",
    "dbms/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp",
    "dbms/src/Storages/MergeTree/ReplicatedMergeTreeQueue.h",
    "dbms/src/Storages/StorageMergeTree.cpp",
    "dbms/src/Storages/StorageReplicatedMergeTree.cpp"
  ],
  "modified_test_files": [
    "b/dbms/tests/integration/test_replicated_mutations/configs/merge_tree_max_parts.xml",
    "dbms/tests/integration/test_replicated_mutations/test.py"
  ]
}