diff --git a/tests/integration/test_endpoint_macro_substitution/__init__.py b/tests/integration/test_endpoint_macro_substitution/__init__.py
new file mode 100644
index 000000000000..e69de29bb2d1
diff --git a/tests/integration/test_endpoint_macro_substitution/configs/config.xml b/tests/integration/test_endpoint_macro_substitution/configs/config.xml
new file mode 100644
index 000000000000..d4a2a9cf3674
--- /dev/null
+++ b/tests/integration/test_endpoint_macro_substitution/configs/config.xml
@@ -0,0 +1,26 @@
+<clickhouse>
+    <logger>
+        <level>trace</level>
+        <log>/var/log/clickhouse-server/clickhouse-server.log</log>
+        <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>
+        <size>1000M</size>
+        <count>10</count>
+    </logger>
+
+    <tcp_port>9000</tcp_port>
+    <listen_host>127.0.0.1</listen_host>
+
+    <openSSL>
+        <client>
+            <cacheSessions>true</cacheSessions>
+            <verificationMode>none</verificationMode>
+            <invalidCertificateHandler>
+                <name>AcceptCertificateHandler</name>
+            </invalidCertificateHandler>
+        </client>
+    </openSSL>
+
+    <max_concurrent_queries>500</max_concurrent_queries>
+    <path>./clickhouse/</path>
+    <users_config>users.xml</users_config>
+</clickhouse>
diff --git a/tests/integration/test_endpoint_macro_substitution/configs/macros.xml b/tests/integration/test_endpoint_macro_substitution/configs/macros.xml
new file mode 100644
index 000000000000..ee21a24c3ba6
--- /dev/null
+++ b/tests/integration/test_endpoint_macro_substitution/configs/macros.xml
@@ -0,0 +1,12 @@
+<clickhouse>
+    <macros>
+        <test>Hello, world!</test>
+        <default_cluster_macro>test_shard_localhost</default_cluster_macro>
+        <shard>s1</shard>
+        <replica>r1</replica>
+        <endpoint_substitution>data</endpoint_substitution>
+        <hdfs_endpoint_substitution>clickhouse</hdfs_endpoint_substitution>
+        <default_path_test>/clickhouse/tables/{database}/{shard}/</default_path_test>
+        <default_name_test>table_{table}</default_name_test>
+    </macros>
+</clickhouse>
diff --git a/tests/integration/test_endpoint_macro_substitution/configs/storage.xml b/tests/integration/test_endpoint_macro_substitution/configs/storage.xml
new file mode 100644
index 000000000000..4c6320b2e488
--- /dev/null
+++ b/tests/integration/test_endpoint_macro_substitution/configs/storage.xml
@@ -0,0 +1,24 @@
+<clickhouse>
+    <macros incl="macros" optional="true" replace="replace"/>
+    <storage_configuration>
+        <disks>
+            <disk_s3>
+                <type>s3</type>
+                <endpoint>http://minio1:9001/root/{endpoint_substitution}/</endpoint>
+                <access_key_id>minio</access_key_id>
+                <secret_access_key>minio123</secret_access_key>
+            </disk_s3>
+            <disk_hdfs>
+                <type>hdfs</type>
+                <endpoint>hdfs://hdfs1:9000/{hdfs_endpoint_substitution}/</endpoint>
+                <!-- FIXME: chicken and egg problem with current cluster.py -->
+                <skip_access_check>true</skip_access_check>
+            </disk_hdfs>
+            <disk_encrypted>
+                <type>encrypted</type>
+                <disk>disk_s3</disk>
+                <key>1234567812345678</key>
+            </disk_encrypted>
+        </disks>
+    </storage_configuration>
+</clickhouse>
diff --git a/tests/integration/test_endpoint_macro_substitution/configs/users.xml b/tests/integration/test_endpoint_macro_substitution/configs/users.xml
new file mode 100644
index 000000000000..4555a2ed4945
--- /dev/null
+++ b/tests/integration/test_endpoint_macro_substitution/configs/users.xml
@@ -0,0 +1,22 @@
+<clickhouse>
+    <profiles>
+        <default>
+        </default>
+    </profiles>
+
+    <users>
+        <default>
+            <password></password>
+            <networks incl="networks" replace="replace">
+                <ip>::/0</ip>
+            </networks>
+            <profile>default</profile>
+            <quota>default</quota>
+        </default>
+    </users>
+
+    <quotas>
+        <default>
+        </default>
+    </quotas>
+</clickhouse>
diff --git a/tests/integration/test_endpoint_macro_substitution/test.py b/tests/integration/test_endpoint_macro_substitution/test.py
new file mode 100644
index 000000000000..42a8ddbda84a
--- /dev/null
+++ b/tests/integration/test_endpoint_macro_substitution/test.py
@@ -0,0 +1,81 @@
+import pytest
+from helpers.cluster import ClickHouseCluster
+from helpers.test_tools import TSV
+from pyhdfs import HdfsClient
+
+disk_types = {
+    "default": "local",
+    "disk_s3": "s3",
+    "disk_hdfs": "hdfs",
+    "disk_encrypted": "s3",
+}
+
+
+@pytest.fixture(scope="module")
+def cluster():
+    try:
+        cluster = ClickHouseCluster(__file__)
+        cluster.add_instance(
+            "node",
+            main_configs=["configs/storage.xml", "configs/macros.xml"],
+            with_minio=True,
+            with_hdfs=True,
+        )
+        cluster.start()
+
+        fs = HdfsClient(hosts=cluster.hdfs_ip)
+        fs.mkdirs("/clickhouse")
+
+        yield cluster
+    finally:
+        cluster.shutdown()
+
+
+def test_different_types(cluster):
+    node = cluster.instances["node"]
+    fs = HdfsClient(hosts=cluster.hdfs_ip)
+
+    response = TSV.toMat(node.query("SELECT * FROM system.disks FORMAT TSVWithNames"))
+
+    assert len(response) > len(disk_types)  # at least one extra line for header
+
+    name_col_ix = response[0].index("name")
+    type_col_ix = response[0].index("type")
+    encrypted_col_ix = response[0].index("is_encrypted")
+
+    for fields in response[1:]:  # skip header
+        assert len(fields) >= 7
+        assert (
+            disk_types.get(fields[name_col_ix], "UNKNOWN") == fields[type_col_ix]
+        ), f"Wrong type ({fields[type_col_ix]}) for disk {fields[name_col_ix]}!"
+        if "encrypted" in fields[name_col_ix]:
+            assert (
+                fields[encrypted_col_ix] == "1"
+            ), f"{fields[name_col_ix]} expected to be encrypted!"
+        else:
+            assert (
+                fields[encrypted_col_ix] == "0"
+            ), f"{fields[name_col_ix]} expected to be non-encrypted!"
+
+
+def test_select_by_type(cluster):
+    node = cluster.instances["node"]
+    fs = HdfsClient(hosts=cluster.hdfs_ip)
+
+    for name, disk_type in list(disk_types.items()):
+        if disk_type != "s3":
+            assert (
+                node.query(
+                    "SELECT name FROM system.disks WHERE type='" + disk_type + "'"
+                )
+                == name + "
"
+            )
+        else:
+            assert (
+                node.query(
+                    "SELECT name FROM system.disks WHERE type='"
+                    + disk_type
+                    + "' ORDER BY name"
+                )
+                == "disk_encrypted
disk_s3
"
+            )
