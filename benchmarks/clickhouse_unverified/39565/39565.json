{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 39565,
  "instance_id": "ClickHouse__ClickHouse-39565",
  "issue_numbers": [
    "39511"
  ],
  "base_commit": "778dcf6994b030138d32b990101a45ebe5362211",
  "patch": "diff --git a/src/Interpreters/DDLWorker.cpp b/src/Interpreters/DDLWorker.cpp\nindex 51932ad051b7..13432940c1be 100644\n--- a/src/Interpreters/DDLWorker.cpp\n+++ b/src/Interpreters/DDLWorker.cpp\n@@ -7,6 +7,8 @@\n #include <Parsers/ASTOptimizeQuery.h>\n #include <Parsers/ASTQueryWithOnCluster.h>\n #include <Parsers/ASTQueryWithTableAndOutput.h>\n+#include <Parsers/ASTCreateIndexQuery.h>\n+#include <Parsers/ASTDropIndexQuery.h>\n #include <Parsers/ParserQuery.h>\n #include <Parsers/parseQuery.h>\n #include <Parsers/queryToString.h>\n@@ -652,7 +654,11 @@ bool DDLWorker::taskShouldBeExecutedOnLeader(const ASTPtr & ast_ddl, const Stora\n     if (auto * query = ast_ddl->as<ASTDropQuery>(); query && query->kind != ASTDropQuery::Kind::Truncate)\n         return false;\n \n-    if (!ast_ddl->as<ASTAlterQuery>() && !ast_ddl->as<ASTOptimizeQuery>() && !ast_ddl->as<ASTDropQuery>())\n+    if (!ast_ddl->as<ASTAlterQuery>() &&\n+        !ast_ddl->as<ASTOptimizeQuery>() &&\n+        !ast_ddl->as<ASTDropQuery>() &&\n+        !ast_ddl->as<ASTCreateIndexQuery>() &&\n+        !ast_ddl->as<ASTDropIndexQuery>())\n         return false;\n \n     if (auto * alter = ast_ddl->as<ASTAlterQuery>())\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02319_sql_standard_create_drop_index.reference b/tests/queries/0_stateless/02319_sql_standard_create_drop_index.reference\nindex 6565857f89d5..bb0c387976a6 100644\n--- a/tests/queries/0_stateless/02319_sql_standard_create_drop_index.reference\n+++ b/tests/queries/0_stateless/02319_sql_standard_create_drop_index.reference\n@@ -2,3 +2,9 @@ CREATE TABLE default.t_index\\n(\\n    `a` Int32,\\n    `b` String,\\n    INDEX i_a\n t_index\ti_a\tminmax\ta\t4\n t_index\ti_b\tbloom_filter\tb\t2\n t_index\ti_b\tbloom_filter\tb\t2\n+CREATE TABLE default.t_index\\n(\\n    `a` Int32,\\n    `b` String,\\n    INDEX i_a a TYPE minmax GRANULARITY 4,\\n    INDEX i_b b TYPE bloom_filter GRANULARITY 2\\n)\\nENGINE = ReplicatedMergeTree(\\'/test/2319/default\\', \\'1\\')\\nORDER BY a\\nSETTINGS index_granularity = 8192\n+CREATE TABLE default.t_index_replica\\n(\\n    `a` Int32,\\n    `b` String,\\n    INDEX i_a a TYPE minmax GRANULARITY 4,\\n    INDEX i_b b TYPE bloom_filter GRANULARITY 2\\n)\\nENGINE = ReplicatedMergeTree(\\'/test/2319/default\\', \\'2\\')\\nORDER BY a\\nSETTINGS index_granularity = 8192\n+t_index\ti_a\tminmax\ta\t4\n+t_index\ti_b\tbloom_filter\tb\t2\n+t_index\ti_b\tbloom_filter\tb\t2\n+t_index_replica\ti_b\tbloom_filter\tb\t2\ndiff --git a/tests/queries/0_stateless/02319_sql_standard_create_drop_index.sql b/tests/queries/0_stateless/02319_sql_standard_create_drop_index.sql\nindex a33505ced3ad..581b170ee653 100644\n--- a/tests/queries/0_stateless/02319_sql_standard_create_drop_index.sql\n+++ b/tests/queries/0_stateless/02319_sql_standard_create_drop_index.sql\n@@ -15,3 +15,25 @@ drop index if exists i_a on t_index;\n select table, name, type, expr, granularity from system.data_skipping_indices where database = currentDatabase() and table = 't_index'; \n \n drop table t_index;\n+\n+create table t_index(a int, b String) engine=ReplicatedMergeTree('/test/2319/{database}', '1') order by a;\n+create table t_index_replica(a int, b String) engine=ReplicatedMergeTree('/test/2319/{database}', '2') order by a;\n+\n+create index i_a on t_index(a) TYPE minmax GRANULARITY 4;\n+create index if not exists i_a on t_index(a) TYPE minmax GRANULARITY 2;\n+\n+create index i_b on t_index(b) TYPE bloom_filter GRANULARITY 2;\n+\n+show create table t_index;\n+system sync replica t_index_replica;\n+show create table t_index_replica;\n+select table, name, type, expr, granularity from system.data_skipping_indices where database = currentDatabase() and table = 't_index';\n+\n+drop index i_a on t_index;\n+drop index if exists i_a on t_index;\n+\n+select table, name, type, expr, granularity from system.data_skipping_indices where database = currentDatabase() and table = 't_index';\n+system sync replica t_index_replica;\n+select table, name, type, expr, granularity from system.data_skipping_indices where database = currentDatabase() and table = 't_index_replica';\n+\n+drop table t_index;\n",
  "problem_statement": "CREATE INDEX on ReplicatedMergeTree table in a Replicated database causes infinite failure loop\nHey,\r\nI'd like to report a bug using the new CREATE INDEX syntax.\r\n\r\n**Description** \r\n\r\n- Using ClickHouse version 22.7.1.2484, in a cluster with 2 shards and 2 replicas for each shard (total of 4 nodes)\r\n- When using the new CREATE INDEX statement added in this version, on a ReplicatedMergeTree table that exists inside a database using the Replicated engine, the index is created but an infinite loop of exceptions begins in the log.\r\n- The only workaround i found is to manually edit the log_ptr in the ZooKeeper to point to the next log record, so it wont try to execute the problematic statement again.\r\n- The index is actually created successfully. \r\n- This problem doesn't happen when using ALTER TABLE ... ADD INDEX statement.\r\n\r\n**How to reproduce?**\r\n\r\n1. `CREATE DATABASE tests ENGINE = Replicated('/dbs/test', '{shard}', '{replica}')`\r\n2. Execute this statement on each node in the cluster (my topology is 2 shards each with 2 replicas)\r\n3. `CREATE TABLE tests.local_testTable \r\n(\r\n\tInsertionTime Datetime32,\r\n\tBlah1 String,\r\n\tBlah2 Int32\r\n) \r\nENGINE=ReplicatedMergeTree \r\nPARTITION BY toYYYYMM(InsertionTime)\r\nORDER BY InsertionTime`\r\n4. `CREATE INDEX IX_testsBlah_Blah2_MinMax ON tests.local_testTable(Blah2) TYPE MINMAX GRANULARITY 5`\r\n\r\n**The log**\r\nThis is part of the log. the exception keeps happening. \r\n\r\nclickhouse03  | 2022.07.22 22:12:02.642951 [ 236 ] {} <Debug> DDLWorker(tests): Will not execute task query-0000000005: Entry query-0000000005 is a dummy task\r\nclickhouse03  | 2022.07.22 22:12:02.644341 [ 236 ] {} <Debug> DDLWorker(tests): Will not execute task query-0000000006: Entry query-0000000006 hasn't been committed\r\nclickhouse03  | 2022.07.22 22:12:02.647018 [ 236 ] {} <Debug> DDLWorker(tests): Processing task query-0000000007 (CREATE INDEX IX_testsBlah_Blah2_MinMax ON local_testTable(Blah2) TYPE MINMAX GRANULARITY 5)\r\nclickhouse03  | 2022.07.22 22:12:02.653851 [ 236 ] {} <Debug> DDLWorker(tests): Executing query: CREATE INDEX IX_testsBlah_Blah2_MinMax ON tests.local_testTable(Blah2) TYPE MINMAX GRANULARITY 5\r\nclickhouse03  | 2022.07.22 22:12:02.654110 [ 236 ] {3d53abd5-e239-4a93-911f-9aac7d44855e} <Debug> executeQuery: (from 0.0.0.0:0, user: ) /* ddl_entry=query-0000000007 */ CREATE INDEX IX_testsBlah_Blah2_MinMax ON tests.local_testTable(Blah2) TYPE MINMAX GRANULARITY 5 (stage: Complete)\r\nclickhouse03  | 2022.07.22 22:12:02.654800 [ 236 ] {3d53abd5-e239-4a93-911f-9aac7d44855e} <Error> executeQuery: Code: 44. DB::Exception: Cannot add index IX_testsBlah_Blah2_MinMax: index with this name already exists. (ILLEGAL_COLUMN) (version 22.7.1.2484 (official build)) (from 0.0.0.0:0) (in query: /* ddl_entry=query-0000000007 */ CREATE INDEX IX_testsBlah_Blah2_MinMax ON tests.local_testTable(Blah2) TYPE MINMAX GRANULARITY 5), Stack trace (when copying this message, always include the lines below):\r\nclickhouse03  |\r\nclickhouse03  | 0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0xba37dda in /usr/bin/clickhouse\r\nclickhouse03  | 1. DB::AlterCommand::apply(DB::StorageInMemoryMetadata&, std::__1::shared_ptr<DB::Context const>) const @ 0x17042d3b in /usr/bin/clickhouse\r\nclickhouse03  | 2. DB::AlterCommands::apply(DB::StorageInMemoryMetadata&, std::__1::shared_ptr<DB::Context const>) const @ 0x1704cb4e in /usr/bin/clickhouse\r\nclickhouse03  | 3. DB::MergeTreeData::checkAlterIsPossible(DB::AlterCommands const&, std::__1::shared_ptr<DB::Context const>) const @ 0x1757c7e7 in /usr/bin/clickhouse\r\nclickhouse03  | 4. DB::InterpreterCreateIndexQuery::execute() @ 0x16b6f501 in /usr/bin/clickhouse\r\nclickhouse03  | 5. ? @ 0x16ecdbd7 in /usr/bin/clickhouse\r\nclickhouse03  | 6. DB::executeQuery(DB::ReadBuffer&, DB::WriteBuffer&, bool, std::__1::shared_ptr<DB::Context>, std::__1::function<void (std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)>, std::__1::optional<DB::FormatSettings> const&) @ 0x16ed2033 in /usr/bin/clickhouse\r\nclickhouse03  | 7. DB::DDLWorker::tryExecuteQuery(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::DDLTaskBase&, std::__1::shared_ptr<zkutil::ZooKeeper> const&) @ 0x166729b4 in /usr/bin/clickhouse\r\nclickhouse03  | 8. DB::DDLWorker::processTask(DB::DDLTaskBase&, std::__1::shared_ptr<zkutil::ZooKeeper> const&) @ 0x1667135d in /usr/bin/clickhouse\r\nclickhouse03  | 9. DB::DDLWorker::scheduleTasks(bool) @ 0x1666f213 in /usr/bin/clickhouse\r\nclickhouse03  | 10. DB::DDLWorker::runMainThread() @ 0x16668f7c in /usr/bin/clickhouse\r\nclickhouse03  | 11. void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<ThreadFromGlobalPool::ThreadFromGlobalPool<void (DB::DDLWorker::*)(), DB::DDLWorker*>(void (DB::DDLWorker::*&&)(), DB::DDLWorker*&&)::'lambda'(), void ()> >(std::__1::__function::__policy_storage const*) @ 0x1667d089 in /usr/bin/clickhouse\r\nclickhouse03  | 12. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0xbb046a8 in /usr/bin/clickhouse\r\nclickhouse03  | 13. ? @ 0xbb07a3d in /usr/bin/clickhouse\r\nclickhouse03  | 14. ? @ 0x7fe4948c0609 in ?\r\nclickhouse03  | 15. clone @ 0x7fe4947e5133 in ?\r\nclickhouse03  |\r\nclickhouse03  | 2022.07.22 22:12:02.655100 [ 236 ] {3d53abd5-e239-4a93-911f-9aac7d44855e} <Error> DDLWorker(tests): Query CREATE INDEX IX_testsBlah_Blah2_MinMax ON tests.local_testTable(Blah2) TYPE MINMAX GRANULARITY 5 wasn't finished successfully: Code: 44. DB::Exception: Cannot add index IX_testsBlah_Blah2_MinMax: index with this name already exists. (ILLEGAL_COLUMN), Stack trace (when copying this message, always include the lines below):\r\nclickhouse03  |\r\nclickhouse03  | 0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0xba37dda in /usr/bin/clickhouse\r\nclickhouse03  | 1. DB::AlterCommand::apply(DB::StorageInMemoryMetadata&, std::__1::shared_ptr<DB::Context const>) const @ 0x17042d3b in /usr/bin/clickhouse\r\nclickhouse03  | 2. DB::AlterCommands::apply(DB::StorageInMemoryMetadata&, std::__1::shared_ptr<DB::Context const>) const @ 0x1704cb4e in /usr/bin/clickhouse\r\nclickhouse03  | 3. DB::MergeTreeData::checkAlterIsPossible(DB::AlterCommands const&, std::__1::shared_ptr<DB::Context const>) const @ 0x1757c7e7 in /usr/bin/clickhouse\r\nclickhouse03  | 4. DB::InterpreterCreateIndexQuery::execute() @ 0x16b6f501 in /usr/bin/clickhouse\r\nclickhouse03  | 5. ? @ 0x16ecdbd7 in /usr/bin/clickhouse\r\nclickhouse03  | 6. DB::executeQuery(DB::ReadBuffer&, DB::WriteBuffer&, bool, std::__1::shared_ptr<DB::Context>, std::__1::function<void (std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)>, std::__1::optional<DB::FormatSettings> const&) @ 0x16ed2033 in /usr/bin/clickhouse\r\nclickhouse03  | 7. DB::DDLWorker::tryExecuteQuery(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::DDLTaskBase&, std::__1::shared_ptr<zkutil::ZooKeeper> const&) @ 0x166729b4 in /usr/bin/clickhouse\r\nclickhouse03  | 8. DB::DDLWorker::processTask(DB::DDLTaskBase&, std::__1::shared_ptr<zkutil::ZooKeeper> const&) @ 0x1667135d in /usr/bin/clickhouse\r\nclickhouse03  | 9. DB::DDLWorker::scheduleTasks(bool) @ 0x1666f213 in /usr/bin/clickhouse\r\nclickhouse03  | 10. DB::DDLWorker::runMainThread() @ 0x16668f7c in /usr/bin/clickhouse\r\nclickhouse03  | 11. void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<ThreadFromGlobalPool::ThreadFromGlobalPool<void (DB::DDLWorker::*)(), DB::DDLWorker*>(void (DB::DDLWorker::*&&)(), DB::DDLWorker*&&)::'lambda'(), void ()> >(std::__1::__function::__policy_storage const*) @ 0x1667d089 in /usr/bin/clickhouse\r\nclickhouse03  | 12. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0xbb046a8 in /usr/bin/clickhouse\r\nclickhouse03  | 13. ? @ 0xbb07a3d in /usr/bin/clickhouse\r\nclickhouse03  | 14. ? @ 0x7fe4948c0609 in ?\r\nclickhouse03  | 15. clone @ 0x7fe4947e5133 in ?\r\nclickhouse03  |  (version 22.7.1.2484 (official build))\r\nclickhouse03  | 2022.07.22 22:12:02.655153 [ 236 ] {3d53abd5-e239-4a93-911f-9aac7d44855e} <Debug> MemoryTracker: Peak memory usage (for query): 0.00 B.\r\nclickhouse03  | 2022.07.22 22:12:02.659441 [ 236 ] {} <Error> DDLWorker(tests): Unexpected error, will try to restart main thread: Code: 341. DB::Exception: Unexpected error: 44\r\nclickhouse03  | Code: 44. DB::Exception: Cannot add index IX_testsBlah_Blah2_MinMax: index with this name already exists. (ILLEGAL_COLUMN) (version 22.7.1.2484 (official build)). (UNFINISHED), Stack trace (when copying this message, always include the lines below):\r\nclickhouse03  |\r\nclickhouse03  | 0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0xba37dda in /usr/bin/clickhouse\r\nclickhouse03  | 1. DB::Exception::Exception<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >(int, fmt::v8::basic_format_string<char, fmt::v8::type_identity<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >::type>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >&&) @ 0xba83198 in /usr/bin/clickhouse\r\nclickhouse03  | 2. DB::DDLWorker::processTask(DB::DDLTaskBase&, std::__1::shared_ptr<zkutil::ZooKeeper> const&) @ 0x166718ad in /usr/bin/clickhouse\r\nclickhouse03  | 3. DB::DDLWorker::scheduleTasks(bool) @ 0x1666f213 in /usr/bin/clickhouse\r\nclickhouse03  | 4. DB::DDLWorker::runMainThread() @ 0x16668f7c in /usr/bin/clickhouse\r\nclickhouse03  | 5. void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<ThreadFromGlobalPool::ThreadFromGlobalPool<void (DB::DDLWorker::*)(), DB::DDLWorker*>(void (DB::DDLWorker::*&&)(), DB::DDLWorker*&&)::'lambda'(), void ()> >(std::__1::__function::__policy_storage const*) @ 0x1667d089 in /usr/bin/clickhouse\r\nclickhouse03  | 6. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0xbb046a8 in /usr/bin/clickhouse\r\nclickhouse03  | 7. ? @ 0xbb07a3d in /usr/bin/clickhouse\r\nclickhouse03  | 8. ? @ 0x7fe4948c0609 in ?\r\nclickhouse03  | 9. clone @ 0x7fe4947e5133 in ?\r\nclickhouse03  |  (version 22.7.1.2484 (official build))\r\nclickhouse03  | 2022.07.22 22:12:02.659643 [ 236 ] {} <Information> DDLWorker(tests): Cleaned DDLWorker state\r\nclickhouse03  | 2022.07.22 22:12:03.401779 [ 214 ] {} <Debug> DNSResolver: Updating DNS cache\r\nclickhouse03  | 2022.07.22 22:12:03.403668 [ 214 ] {} <Debug> DNSResolver: Updated DNS cache\r\nclickhouse03  | 2022.07.22 22:12:03.458538 [ 87 ] {} <Debug> DiskLocal: Reserving 1.00 MiB on disk `default`, having unreserved 230.82 GiB.\r\nclickhouse02  | 2022.07.22 22:12:03.672911 [ 93 ] {} <Debug> DNSResolver: Updating DNS cache\r\nclickhouse02  | 2022.07.22 22:12:03.674850 [ 93 ] {} <Debug> DNSResolver: Updated DNS cache\r\nclickhouse02  | 2022.07.22 22:12:03.710897 [ 87 ] {} <Debug> DiskLocal: Reserving 1.00 MiB on disk `default`, having unreserved 230.82 GiB.\r\nclickhouse02  | 2022.07.22 22:12:03.712491 [ 94 ] {} <Debug> system.query_log (396a2721-59d3-43e0-b261-e795b4974efa) (MergerMutator): Selected 6 parts from 202207_1_56_11 to 202207_61_61_0\r\nclickhouse02  | 2022.07.22 22:12:03.712565 [ 94 ] {} <Debug> DiskLocal: Reserving 1.00 MiB on disk `default`, having unreserved 230.82 GiB.\r\nclickhouse02  | 2022.07.22 22:12:03.712737 [ 52 ] {396a2721-59d3-43e0-b261-e795b4974efa::202207_1_61_12} <Debug> MergeTask::PrepareStage: Merging 6 parts: from 202207_1_56_11 to 202207_61_61_0 into Compact\r\nclickhouse02  | 2022.07.22 22:12:03.713024 [ 52 ] {396a2721-59d3-43e0-b261-e795b4974efa::202207_1_61_12} <Debug> MergeTask::PrepareStage: Selected MergeAlgorithm: Horizontal\r\nclickhouse02  | 2022.07.22 22:12:03.713198 [ 52 ] {396a2721-59d3-43e0-b261-e795b4974efa::202207_1_61_12} <Debug> MergeTreeSequentialSource: Reading 2 marks from part 202207_1_56_11, total 90 rows starting from the beginning of the part\r\nclickhouse02  | 2022.07.22 22:12:03.713834 [ 52 ] {396a2721-59d3-43e0-b261-e795b4974efa::202207_1_61_12} <Debug> MergeTreeSequentialSource: Reading 2 marks from part 202207_57_57_0, total 2 rows starting from the beginning of the part\r\nclickhouse02  | 2022.07.22 22:12:03.714327 [ 52 ] {396a2721-59d3-43e0-b261-e795b4974efa::202207_1_61_12} <Debug> MergeTreeSequentialSource: Reading 2 marks from part 202207_58_58_0, total 1 rows starting from the beginning of the part\r\nclickhouse02  | 2022.07.22 22:12:03.714875 [ 52 ] {396a2721-59d3-43e0-b261-e795b4974efa::202207_1_61_12} <Debug> MergeTreeSequentialSource: Reading 2 marks from part 202207_59_59_0, total 2 rows starting from the beginning of the part\r\nclickhouse02  | 2022.07.22 22:12:03.715424 [ 52 ] {396a2721-59d3-43e0-b261-e795b4974efa::202207_1_61_12} <Debug> MergeTreeSequentialSource: Reading 2 marks from part 202207_60_60_0, total 1 rows starting from the beginning of the part\r\nclickhouse02  | 2022.07.22 22:12:03.715979 [ 52 ] {396a2721-59d3-43e0-b261-e795b4974efa::202207_1_61_12} <Debug> MergeTreeSequentialSource: Reading 2 marks from part 202207_61_61_0, total 2 rows starting from the beginning of the part\r\nclickhouse02  | 2022.07.22 22:12:03.721938 [ 52 ] {396a2721-59d3-43e0-b261-e795b4974efa::202207_1_61_12} <Debug> MergeTask::MergeProjectionsStage: Merge sorted 98 rows, containing 68 columns (68 merged, 0 gathered) in 0.0092471 sec., 10597.917184847141 rows/sec., 30.92 MiB/sec.\r\nclickhouse02  | 2022.07.22 22:12:03.724269 [ 52 ] {} <Debug> MemoryTracker: Peak memory usage Mutate/Merge: 4.12 MiB.\r\nclickhouse04  | 2022.07.22 22:12:04.150026 [ 138 ] {} <Debug> DNSResolver: Updating DNS cache\r\nclickhouse01  | 2022.07.22 22:12:04.149923 [ 157 ] {} <Debug> DNSResolver: Updating DNS cache\r\nclickhouse01  | 2022.07.22 22:12:04.151499 [ 157 ] {} <Debug> DNSResolver: Updated DNS cache\r\nclickhouse04  | 2022.07.22 22:12:04.151653 [ 138 ] {} <Debug> DNSResolver: Updated DNS cache\r\nclickhouse02  | 2022.07.22 22:12:07.627785 [ 235 ] {} <Debug> DDLWorker(tests): Initialized DDLWorker thread\r\nclickhouse02  | 2022.07.22 22:12:07.627859 [ 235 ] {} <Debug> DDLWorker(tests): Scheduling tasks\r\nclickhouse02  | 2022.07.22 22:12:07.628706 [ 235 ] {} <Debug> DDLWorker(tests): Will schedule 5 tasks starting from query-0000000003\r\nclickhouse02  | 2022.07.22 22:12:07.635462 [ 235 ] {} <Debug> DDLWorker(tests): Will not execute task query-0000000003: Entry query-0000000003 is a dummy task\r\nclickhouse02  | 2022.07.22 22:12:07.641258 [ 235 ] {} <Debug> DDLWorker(tests): Will not execute task query-0000000004: Entry query-0000000004 is a dummy task\r\nclickhouse02  | 2022.07.22 22:12:07.647493 [ 235 ] {} <Debug> DDLWorker(tests): Will not execute task query-0000000005: Entry query-0000000005 is a dummy task\r\nclickhouse02  | 2022.07.22 22:12:07.649054 [ 235 ] {} <Debug> DDLWorker(tests): Will not execute task query-0000000006: Entry query-0000000006 hasn't been committed\r\nclickhouse02  | 2022.07.22 22:12:07.651712 [ 235 ] {} <Debug> DDLWorker(tests): Processing task query-0000000007 (CREATE INDEX IX_testsBlah_Blah2_MinMax ON local_testTable(Blah2) TYPE MINMAX GRANULARITY 5)\r\nclickhouse02  | 2022.07.22 22:12:07.655342 [ 235 ] {} <Debug> DDLWorker(tests): Executing query: CREATE INDEX IX_testsBlah_Blah2_MinMax ON tests.local_testTable(Blah2) TYPE MINMAX GRANULARITY 5\r\nclickhouse02  | 2022.07.22 22:12:07.655767 [ 235 ] {f347ba35-14b7-4709-b253-9bb15914d496} <Debug> executeQuery: (from 0.0.0.0:0, user: ) /* ddl_entry=query-0000000007 */ CREATE INDEX IX_testsBlah_Blah2_MinMax ON tests.local_testTable(Blah2) TYPE MINMAX GRANULARITY 5 (stage: Complete)\r\nclickhouse02  | 2022.07.22 22:12:07.656909 [ 235 ] {f347ba35-14b7-4709-b253-9bb15914d496} <Error> executeQuery: Code: 44. DB::Exception: Cannot add index IX_testsBlah_Blah2_MinMax: index with this name already exists. (ILLEGAL_COLUMN) (version 22.7.1.2484 (official build)) (from 0.0.0.0:0) (in query: /* ddl_entry=query-0000000007 */ CREATE INDEX IX_testsBlah_Blah2_MinMax ON tests.local_testTable(Blah2) TYPE MINMAX GRANULARITY 5), Stack trace (when copying this message, always include the lines below):\r\nclickhouse02  |\r\nclickhouse02  | 0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0xba37dda in /usr/bin/clickhouse\r\nclickhouse02  | 1. DB::AlterCommand::apply(DB::StorageInMemoryMetadata&, std::__1::shared_ptr<DB::Context const>) const @ 0x17042d3b in /usr/bin/clickhouse\r\nclickhouse02  | 2. DB::AlterCommands::apply(DB::StorageInMemoryMetadata&, std::__1::shared_ptr<DB::Context const>) const @ 0x1704cb4e in /usr/bin/clickhouse\r\nclickhouse02  | 3. DB::MergeTreeData::checkAlterIsPossible(DB::AlterCommands const&, std::__1::shared_ptr<DB::Context const>) const @ 0x1757c7e7 in /usr/bin/clickhouse\r\nclickhouse02  | 4. DB::InterpreterCreateIndexQuery::execute() @ 0x16b6f501 in /usr/bin/clickhouse\r\nclickhouse02  | 5. ? @ 0x16ecdbd7 in /usr/bin/clickhouse\r\nclickhouse02  | 6. DB::executeQuery(DB::ReadBuffer&, DB::WriteBuffer&, bool, std::__1::shared_ptr<DB::Context>, std::__1::function<void (std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)>, std::__1::optional<DB::FormatSettings> const&) @ 0x16ed2033 in /usr/bin/clickhouse\r\nclickhouse02  | 7. DB::DDLWorker::tryExecuteQuery(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::DDLTaskBase&, std::__1::shared_ptr<zkutil::ZooKeeper> const&) @ 0x166729b4 in /usr/bin/clickhouse\r\nclickhouse02  | 8. DB::DDLWorker::processTask(DB::DDLTaskBase&, std::__1::shared_ptr<zkutil::ZooKeeper> const&) @ 0x1667135d in /usr/bin/clickhouse\r\nclickhouse02  | 9. DB::DDLWorker::scheduleTasks(bool) @ 0x1666f213 in /usr/bin/clickhouse\r\nclickhouse02  | 10. DB::DDLWorker::runMainThread() @ 0x16668f7c in /usr/bin/clickhouse\r\nclickhouse02  | 11. void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<ThreadFromGlobalPool::ThreadFromGlobalPool<void (DB::DDLWorker::*)(), DB::DDLWorker*>(void (DB::DDLWorker::*&&)(), DB::DDLWorker*&&)::'lambda'(), void ()> >(std::__1::__function::__policy_storage const*) @ 0x1667d089 in /usr/bin/clickhouse\r\nclickhouse02  | 12. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0xbb046a8 in /usr/bin/clickhouse\r\nclickhouse02  | 13. ? @ 0xbb07a3d in /usr/bin/clickhouse\r\nclickhouse02  | 14. ? @ 0x7f764702c609 in ?\r\nclickhouse02  | 15. clone @ 0x7f7646f51133 in ?\r\nclickhouse02  |\r\nclickhouse02  | 2022.07.22 22:12:07.657163 [ 235 ] {f347ba35-14b7-4709-b253-9bb15914d496} <Error> DDLWorker(tests): Query CREATE INDEX IX_testsBlah_Blah2_MinMax ON tests.local_testTable(Blah2) TYPE MINMAX GRANULARITY 5 wasn't finished successfully: Code: 44. DB::Exception: Cannot add index IX_testsBlah_Blah2_MinMax: index with this name already exists. (ILLEGAL_COLUMN), Stack trace (when copying this message, always include the lines below):\r\nclickhouse02  |\r\nclickhouse02  | 0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0xba37dda in /usr/bin/clickhouse\r\nclickhouse02  | 1. DB::AlterCommand::apply(DB::StorageInMemoryMetadata&, std::__1::shared_ptr<DB::Context const>) const @ 0x17042d3b in /usr/bin/clickhouse\r\nclickhouse02  | 2. DB::AlterCommands::apply(DB::StorageInMemoryMetadata&, std::__1::shared_ptr<DB::Context const>) const @ 0x1704cb4e in /usr/bin/clickhouse\r\nclickhouse02  | 3. DB::MergeTreeData::checkAlterIsPossible(DB::AlterCommands const&, std::__1::shared_ptr<DB::Context const>) const @ 0x1757c7e7 in /usr/bin/clickhouse\r\nclickhouse02  | 4. DB::InterpreterCreateIndexQuery::execute() @ 0x16b6f501 in /usr/bin/clickhouse\r\nclickhouse02  | 5. ? @ 0x16ecdbd7 in /usr/bin/clickhouse\r\nclickhouse02  | 6. DB::executeQuery(DB::ReadBuffer&, DB::WriteBuffer&, bool, std::__1::shared_ptr<DB::Context>, std::__1::function<void (std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)>, std::__1::optional<DB::FormatSettings> const&) @ 0x16ed2033 in /usr/bin/clickhouse\r\nclickhouse02  | 7. DB::DDLWorker::tryExecuteQuery(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::DDLTaskBase&, std::__1::shared_ptr<zkutil::ZooKeeper> const&) @ 0x166729b4 in /usr/bin/clickhouse\r\nclickhouse02  | 8. DB::DDLWorker::processTask(DB::DDLTaskBase&, std::__1::shared_ptr<zkutil::ZooKeeper> const&) @ 0x1667135d in /usr/bin/clickhouse\r\nclickhouse02  | 9. DB::DDLWorker::scheduleTasks(bool) @ 0x1666f213 in /usr/bin/clickhouse\r\nclickhouse02  | 10. DB::DDLWorker::runMainThread() @ 0x16668f7c in /usr/bin/clickhouse\r\nclickhouse02  | 11. void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<ThreadFromGlobalPool::ThreadFromGlobalPool<void (DB::DDLWorker::*)(), DB::DDLWorker*>(void (DB::DDLWorker::*&&)(), DB::DDLWorker*&&)::'lambda'(), void ()> >(std::__1::__function::__policy_storage const*) @ 0x1667d089 in /usr/bin/clickhouse\r\nclickhouse02  | 12. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0xbb046a8 in /usr/bin/clickhouse\r\nclickhouse02  | 13. ? @ 0xbb07a3d in /usr/bin/clickhouse\r\nclickhouse03  | 2022.07.22 22:12:07.664076 [ 236 ] {} <Debug> DDLWorker(tests): Initialized DDLWorker thread\r\nclickhouse02  | 14. ? @ 0x7f764702c609 in ?\r\nclickhouse03  | 2022.07.22 22:12:07.664137 [ 236 ] {} <Debug> DDLWorker(tests): Scheduling tasks\r\nclickhouse02  | 15. clone @ 0x7f7646f51133 in ?\r\nclickhouse03  | 2022.07.22 22:12:07.664819 [ 236 ] {} <Debug> DDLWorker(tests): Will schedule 5 tasks starting from query-0000000003\r\nclickhouse02  |  (version 22.7.1.2484 (official build))\r\nclickhouse02  | 2022.07.22 22:12:07.657214 [ 235 ] {f347ba35-14b7-4709-b253-9bb15914d496} <Debug> MemoryTracker: Peak memory usage (for query): 0.00 B.\r\nclickhouse02  | 2022.07.22 22:12:07.662688 [ 235 ] {} <Error> DDLWorker(tests): Unexpected error, will try to restart main thread: Code: 341. DB::Exception: Unexpected error: 44\r\nclickhouse02  | Code: 44. DB::Exception: Cannot add index IX_testsBlah_Blah2_MinMax: index with this name already exists. (ILLEGAL_COLUMN) (version 22.7.1.2484 (official build)). (UNFINISHED), Stack trace (when copying this message, always include the lines below):\r\nclickhouse02  |\r\nclickhouse02  | 0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0xba37dda in /usr/bin/clickhouse\r\nclickhouse02  | 1. DB::Exception::Exception<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >(int, fmt::v8::basic_format_string<char, fmt::v8::type_identity<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >::type>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >&&) @ 0xba83198 in /usr/bin/clickhouse\r\nclickhouse02  | 2. DB::DDLWorker::processTask(DB::DDLTaskBase&, std::__1::shared_ptr<zkutil::ZooKeeper> const&) @ 0x166718ad in /usr/bin/clickhouse\r\nclickhouse02  | 3. DB::DDLWorker::scheduleTasks(bool) @ 0x1666f213 in /usr/bin/clickhouse\r\nclickhouse02  | 4. DB::DDLWorker::runMainThread() @ 0x16668f7c in /usr/bin/clickhouse\r\nclickhouse02  | 5. void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<ThreadFromGlobalPool::ThreadFromGlobalPool<void (DB::DDLWorker::*)(), DB::DDLWorker*>(void (DB::DDLWorker::*&&)(), DB::DDLWorker*&&)::'lambda'(), void ()> >(std::__1::__function::__policy_storage const*) @ 0x1667d089 in /usr/bin/clickhouse\r\nclickhouse02  | 6. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0xbb046a8 in /usr/bin/clickhouse\r\nclickhouse02  | 7. ? @ 0xbb07a3d in /usr/bin/clickhouse\r\nclickhouse02  | 8. ? @ 0x7f764702c609 in ?\r\nclickhouse02  | 9. clone @ 0x7f7646f51133 in ?\r\nclickhouse02  |  (version 22.7.1.2484 (official build))\r\nclickhouse02  | 2022.07.22 22:12:07.662752 [ 235 ] {} <Information> DDLWorker(tests): Cleaned DDLWorker state\r\nclickhouse03  | 2022.07.22 22:12:07.670201 [ 236 ] {} <Debug> DDLWorker(tests): Will not execute task query-0000000003: Entry query-0000000003 is a dummy task\r\nclickhouse03  | 2022.07.22 22:12:07.676692 [ 236 ] {} <Debug> DDLWorker(tests): Will not execute task query-0000000004: Entry query-0000000004 is a dummy task\r\nclickhouse03  | 2022.07.22 22:12:07.682419 [ 236 ] {} <Debug> DDLWorker(tests): Will not execute task query-0000000005: Entry query-0000000005 is a dummy task\r\nclickhouse03  | 2022.07.22 22:12:07.684090 [ 236 ] {} <Debug> DDLWorker(tests): Will not execute task query-0000000006: Entry query-0000000006 hasn't been committed\r\nclickhouse03  | 2022.07.22 22:12:07.687667 [ 236 ] {} <Debug> DDLWorker(tests): Processing task query-0000000007 (CREATE INDEX IX_testsBlah_Blah2_MinMax ON local_testTable(Blah2) TYPE MINMAX GRANULARITY 5)\r\nclickhouse03  | 2022.07.22 22:12:07.691499 [ 236 ] {} <Debug> DDLWorker(tests): Executing query: CREATE INDEX IX_testsBlah_Blah2_MinMax ON tests.local_testTable(Blah2) TYPE MINMAX GRANULARITY 5\r\n\r\nThanks!\n",
  "hints_text": "It's a bug in CREATE/DROP INDEX queries (#35166), `DDLWorker::taskShouldBeExecutedOnLeader` was not updated and no tests with `ReplicatedMergeTree` were added, so our CI did not catch this.\nHi, \r\nThanks for your response. \r\n\r\nIn addition to solving the issue itself, I believe it would be convenient when something like this happens if ClickHouse supported statements to:\r\n* Skip a log record, to avoid the loops caused by the error, and the manual editing of ZooKeeper values\r\n* Execute a  non-replicated DDL statement on a database using the Replicated database engine. Something like this issue might cause schema differences, and to allow fixing it manually with something like ALTER TABLE *ON LOCAL* statement can be useful. \r\n\r\nThanks.",
  "created_at": "2022-07-25T16:06:02Z",
  "modified_files": [
    "src/Interpreters/DDLWorker.cpp"
  ],
  "modified_test_files": [
    "tests/queries/0_stateless/02319_sql_standard_create_drop_index.reference",
    "tests/queries/0_stateless/02319_sql_standard_create_drop_index.sql"
  ]
}