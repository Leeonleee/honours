diff --git a/tests/integration/helpers/cluster.py b/tests/integration/helpers/cluster.py
index 5bd608ef758e..6287064b6168 100644
--- a/tests/integration/helpers/cluster.py
+++ b/tests/integration/helpers/cluster.py
@@ -126,7 +126,8 @@ class ClickHouseCluster:
     """
 
     def __init__(self, base_path, name=None, base_config_dir=None, server_bin_path=None, client_bin_path=None,
-                 odbc_bridge_bin_path=None, library_bridge_bin_path=None, zookeeper_config_path=None, custom_dockerd_host=None):
+                 odbc_bridge_bin_path=None, library_bridge_bin_path=None, zookeeper_config_path=None, 
+                 custom_dockerd_host=None):
         for param in list(os.environ.keys()):
             print("ENV %40s %s" % (param, os.environ[param]))
         self.base_dir = p.dirname(base_path)
@@ -219,7 +220,9 @@ def add_instance(self, name, base_config_dir=None, main_configs=None, user_confi
                      with_redis=False, with_minio=False, with_cassandra=False,
                      hostname=None, env_variables=None, image="yandex/clickhouse-integration-test", tag=None,
                      stay_alive=False, ipv4_address=None, ipv6_address=None, with_installed_binary=False, tmpfs=None,
-                     zookeeper_docker_compose_path=None, zookeeper_use_tmpfs=True, minio_certs_dir=None, use_keeper=True):
+                     zookeeper_docker_compose_path=None, zookeeper_use_tmpfs=True, minio_certs_dir=None, use_keeper=True,
+                     main_config_name="config.xml", users_config_name="users.xml", copy_common_configs=True):
+
         """Add an instance to the cluster.
 
         name - the name of the instance directory and the value of the 'instance' macro in ClickHouse.
@@ -280,6 +283,9 @@ def add_instance(self, name, base_config_dir=None, main_configs=None, user_confi
             ipv4_address=ipv4_address,
             ipv6_address=ipv6_address,
             with_installed_binary=with_installed_binary,
+            main_config_name=main_config_name,
+            users_config_name=users_config_name,
+            copy_common_configs=copy_common_configs,
             tmpfs=tmpfs or [])
 
         docker_compose_yml_dir = get_docker_compose_path()
@@ -944,7 +950,7 @@ def start_zookeeper_nodes(self, zk_nodes):
             subprocess_check_call(self.base_zookeeper_cmd + ["start", n])
 
 
-CLICKHOUSE_START_COMMAND = "clickhouse server --config-file=/etc/clickhouse-server/config.xml --log-file=/var/log/clickhouse-server/clickhouse-server.log --errorlog-file=/var/log/clickhouse-server/clickhouse-server.err.log"
+CLICKHOUSE_START_COMMAND = "clickhouse server --config-file=/etc/clickhouse-server/{main_config_file} --log-file=/var/log/clickhouse-server/clickhouse-server.log --errorlog-file=/var/log/clickhouse-server/clickhouse-server.err.log"
 
 CLICKHOUSE_STAY_ALIVE_COMMAND = 'bash -c "{} --daemon; tail -f /dev/null"'.format(CLICKHOUSE_START_COMMAND)
 
@@ -1000,6 +1006,8 @@ def __init__(
             macros, with_zookeeper, zookeeper_config_path, with_mysql, with_mysql_cluster, with_kafka, with_kerberized_kafka, with_rabbitmq, with_kerberized_hdfs,
             with_mongo, with_redis, with_minio,
             with_cassandra, server_bin_path, odbc_bridge_bin_path, library_bridge_bin_path, clickhouse_path_dir, with_odbc_drivers,
+            clickhouse_start_command=CLICKHOUSE_START_COMMAND,
+            main_config_name="config.xml", users_config_name="users.xml", copy_common_configs=True,
             hostname=None, env_variables=None,
             image="yandex/clickhouse-integration-test", tag="latest",
             stay_alive=False, ipv4_address=None, ipv6_address=None, with_installed_binary=False, tmpfs=None):
@@ -1036,6 +1044,12 @@ def __init__(
         self.with_minio = with_minio
         self.with_cassandra = with_cassandra
 
+        self.main_config_name = main_config_name
+        self.users_config_name = users_config_name
+        self.copy_common_configs = copy_common_configs
+
+        self.clickhouse_start_command = clickhouse_start_command.replace("{main_config_file}", self.main_config_name)
+
         self.path = p.join(self.cluster.instances_dir, name)
         self.docker_compose_path = p.join(self.path, 'docker-compose.yml')
         self.env_variables = env_variables or {}
@@ -1177,7 +1191,7 @@ def start_clickhouse(self, start_wait_sec=30):
         if not self.stay_alive:
             raise Exception("clickhouse can be started again only with stay_alive=True instance")
 
-        self.exec_in_container(["bash", "-c", "{} --daemon".format(CLICKHOUSE_START_COMMAND)], user=str(os.getuid()))
+        self.exec_in_container(["bash", "-c", "{} --daemon".format(self.clickhouse_start_command)], user=str(os.getuid()))
         # wait start
         from helpers.test_tools import assert_eq_with_retry
         assert_eq_with_retry(self, "select 1", "1", retry_count=int(start_wait_sec / 0.5), sleep_time=0.5)
@@ -1263,7 +1277,7 @@ def restart_with_latest_version(self, stop_start_wait_sec=10, callback_onstop=No
         self.exec_in_container(["bash", "-c",
                                 "cp /usr/share/clickhouse-odbc-bridge_fresh /usr/bin/clickhouse-odbc-bridge && chmod 777 /usr/bin/clickhouse"],
                                user='root')
-        self.exec_in_container(["bash", "-c", "{} --daemon".format(CLICKHOUSE_START_COMMAND)], user=str(os.getuid()))
+        self.exec_in_container(["bash", "-c", "{} --daemon".format(self.clickhouse_start_command)], user=str(os.getuid()))
         from helpers.test_tools import assert_eq_with_retry
         # wait start
         assert_eq_with_retry(self, "select 1", "1", retry_count=retries)
@@ -1404,8 +1418,10 @@ def create_dir(self, destroy_dir=True):
         os.makedirs(instance_config_dir)
 
         print("Copy common default production configuration from {}".format(self.base_config_dir))
-        shutil.copyfile(p.join(self.base_config_dir, 'config.xml'), p.join(instance_config_dir, 'config.xml'))
-        shutil.copyfile(p.join(self.base_config_dir, 'users.xml'), p.join(instance_config_dir, 'users.xml'))
+
+        shutil.copyfile(p.join(self.base_config_dir, self.main_config_name), p.join(instance_config_dir, self.main_config_name))
+
+        shutil.copyfile(p.join(self.base_config_dir, self.users_config_name), p.join(instance_config_dir, self.users_config_name))
 
         print("Create directory for configuration generated in this helper")
         # used by all utils with any config
@@ -1423,7 +1439,9 @@ def create_dir(self, destroy_dir=True):
 
         print("Copy common configuration from helpers")
         # The file is named with 0_ prefix to be processed before other configuration overloads.
-        shutil.copy(p.join(HELPERS_DIR, '0_common_instance_config.xml'), self.config_d_dir)
+        if self.copy_common_configs:
+            shutil.copy(p.join(HELPERS_DIR, '0_common_instance_config.xml'), self.config_d_dir)
+
         shutil.copy(p.join(HELPERS_DIR, '0_common_instance_users.xml'), users_d_dir)
         if len(self.custom_dictionaries_paths):
             shutil.copy(p.join(HELPERS_DIR, '0_common_enable_dictionaries.xml'), self.config_d_dir)
@@ -1502,11 +1520,11 @@ def create_dir(self, destroy_dir=True):
             self._create_odbc_config_file()
             odbc_ini_path = '- ' + self.odbc_ini_path
 
-        entrypoint_cmd = CLICKHOUSE_START_COMMAND
+        entrypoint_cmd = self.clickhouse_start_command
 
         if self.stay_alive:
-            entrypoint_cmd = CLICKHOUSE_STAY_ALIVE_COMMAND
-
+            entrypoint_cmd = CLICKHOUSE_STAY_ALIVE_COMMAND.replace("{main_config_file}", self.main_config_name)
+        
         print("Entrypoint cmd: {}".format(entrypoint_cmd))
 
         networks = app_net = ipv4_address = ipv6_address = net_aliases = net_alias1 = ""
diff --git a/tests/integration/runner b/tests/integration/runner
index ee116c29aa5e..16eb31dfd5e0 100755
--- a/tests/integration/runner
+++ b/tests/integration/runner
@@ -70,11 +70,11 @@ def check_args_and_update_paths(args):
         if not os.path.exists(path):
             raise Exception("Path {} doesn't exist".format(path))
 
-    if not os.path.exists(os.path.join(args.base_configs_dir, "config.xml")):
-        raise Exception("No configs.xml in {}".format(args.base_configs_dir))
+    if (not os.path.exists(os.path.join(args.base_configs_dir, "config.xml"))) and (not os.path.exists(os.path.join(args.base_configs_dir, "config.yaml"))):
+        raise Exception("No configs.xml or configs.yaml in {}".format(args.base_configs_dir))
 
-    if not os.path.exists(os.path.join(args.base_configs_dir, "users.xml")):
-        raise Exception("No users.xml in {}".format(args.base_configs_dir))
+    if (not os.path.exists(os.path.join(args.base_configs_dir, "users.xml"))) and (not os.path.exists(os.path.join(args.base_configs_dir, "users.yaml"))):
+        raise Exception("No users.xml or users.yaml in {}".format(args.base_configs_dir))
 
 def docker_kill_handler_handler(signum, frame):
     subprocess.check_call('docker kill $(docker ps -a -q --filter name={name} --format="{{{{.ID}}}}")'.format(name=CONTAINER_NAME), shell=True)
diff --git a/tests/integration/test_config_xml_full/__init__.py b/tests/integration/test_config_xml_full/__init__.py
new file mode 100644
index 000000000000..e69de29bb2d1
diff --git a/tests/integration/test_config_xml_full/configs/config.d/access_control.xml b/tests/integration/test_config_xml_full/configs/config.d/access_control.xml
new file mode 100644
index 000000000000..6567c39f171a
--- /dev/null
+++ b/tests/integration/test_config_xml_full/configs/config.d/access_control.xml
@@ -0,0 +1,13 @@
+<yandex>
+    <!-- Sources to read users, roles, access rights, profiles of settings, quotas. -->
+    <user_directories replace="replace">
+        <users_xml>
+            <!-- Path to configuration file with predefined users. -->
+            <path>users.xml</path>
+        </users_xml>
+        <local_directory>
+            <!-- Path to folder where users created by SQL commands are stored. -->
+            <path>access/</path>
+        </local_directory>
+    </user_directories>
+</yandex>
diff --git a/tests/integration/test_config_xml_full/configs/config.d/keeper_port.xml b/tests/integration/test_config_xml_full/configs/config.d/keeper_port.xml
new file mode 100644
index 000000000000..b21df47bc850
--- /dev/null
+++ b/tests/integration/test_config_xml_full/configs/config.d/keeper_port.xml
@@ -0,0 +1,23 @@
+<yandex>
+    <keeper_server>
+        <tcp_port>9181</tcp_port>
+        <server_id>1</server_id>
+
+        <coordination_settings>
+            <operation_timeout_ms>10000</operation_timeout_ms>
+            <session_timeout_ms>30000</session_timeout_ms>
+            <force_sync>false</force_sync>
+            <startup_timeout>60000</startup_timeout>
+            <!-- we want all logs for complex problems investigation -->
+            <reserved_log_items>1000000000000000</reserved_log_items>
+        </coordination_settings>
+
+        <raft_configuration>
+            <server>
+                <id>1</id>
+                <hostname>localhost</hostname>
+                <port>44444</port>
+            </server>
+        </raft_configuration>
+    </keeper_server>
+</yandex>
diff --git a/tests/integration/test_config_xml_full/configs/config.d/log_to_console.xml b/tests/integration/test_config_xml_full/configs/config.d/log_to_console.xml
new file mode 100644
index 000000000000..227c53647f32
--- /dev/null
+++ b/tests/integration/test_config_xml_full/configs/config.d/log_to_console.xml
@@ -0,0 +1,7 @@
+<yandex>
+    <logger>
+        <console>true</console>
+        <log remove="remove"/>
+        <errorlog remove="remove"/>
+    </logger>
+</yandex>
diff --git a/tests/integration/test_config_xml_full/configs/config.d/logging_no_rotate.xml b/tests/integration/test_config_xml_full/configs/config.d/logging_no_rotate.xml
new file mode 100644
index 000000000000..2c34585437bf
--- /dev/null
+++ b/tests/integration/test_config_xml_full/configs/config.d/logging_no_rotate.xml
@@ -0,0 +1,8 @@
+<yandex>
+    <logger>
+        <!-- Disable rotation
+             https://pocoproject.org/docs/Poco.FileChannel.html
+        -->
+        <size>never</size>
+    </logger>
+</yandex>
diff --git a/tests/integration/test_config_xml_full/configs/config.d/macros.xml b/tests/integration/test_config_xml_full/configs/config.d/macros.xml
new file mode 100644
index 000000000000..4902b12bc819
--- /dev/null
+++ b/tests/integration/test_config_xml_full/configs/config.d/macros.xml
@@ -0,0 +1,9 @@
+<yandex>
+    <macros>
+        <test>Hello, world!</test>
+        <shard>s1</shard>
+        <replica>r1</replica>
+        <default_path_test>/clickhouse/tables/{database}/{shard}/</default_path_test>
+        <default_name_test>table_{table}</default_name_test>
+    </macros>
+</yandex>
diff --git a/tests/integration/test_config_xml_full/configs/config.d/metric_log.xml b/tests/integration/test_config_xml_full/configs/config.d/metric_log.xml
new file mode 100644
index 000000000000..0ca9f1624169
--- /dev/null
+++ b/tests/integration/test_config_xml_full/configs/config.d/metric_log.xml
@@ -0,0 +1,8 @@
+<yandex>
+    <metric_log>
+        <database>system</database>
+        <table>metric_log</table>
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+        <collect_interval_milliseconds>1000</collect_interval_milliseconds>
+    </metric_log>
+</yandex>
diff --git a/tests/integration/test_config_xml_full/configs/config.d/more_clusters.xml b/tests/integration/test_config_xml_full/configs/config.d/more_clusters.xml
new file mode 100644
index 000000000000..aecbf9e0ba7b
--- /dev/null
+++ b/tests/integration/test_config_xml_full/configs/config.d/more_clusters.xml
@@ -0,0 +1,49 @@
+<yandex>
+    <remote_servers>
+
+        <![CDATA[
+            You can run additional servers simply as
+             ./clickhouse-server -- --path=9001 --tcp_port=9001
+        ]]>
+
+        <single_remote_shard_at_port_9001>
+            <shard>
+                <replica>
+                    <host>localhost</host>
+                    <port>9001</port>
+                </replica>
+            </shard>
+        </single_remote_shard_at_port_9001>
+
+        <two_remote_shards_at_port_9001_9002>
+            <shard>
+                <replica>
+                    <host>localhost</host>
+                    <port>9001</port>
+                </replica>
+            </shard>
+            <shard>
+                <replica>
+                    <host>localhost</host>
+                    <port>9002</port>
+                </replica>
+            </shard>
+        </two_remote_shards_at_port_9001_9002>
+
+        <two_shards_one_local_one_remote_at_port_9001>
+            <shard>
+                <replica>
+                    <host>localhost</host>
+                    <port>9000</port>
+                </replica>
+            </shard>
+            <shard>
+                <replica>
+                    <host>localhost</host>
+                    <port>9001</port>
+                </replica>
+            </shard>
+        </two_shards_one_local_one_remote_at_port_9001>
+
+    </remote_servers>
+</yandex>
diff --git a/tests/integration/test_config_xml_full/configs/config.d/part_log.xml b/tests/integration/test_config_xml_full/configs/config.d/part_log.xml
new file mode 100644
index 000000000000..6c6fc9c69823
--- /dev/null
+++ b/tests/integration/test_config_xml_full/configs/config.d/part_log.xml
@@ -0,0 +1,8 @@
+<yandex>
+    <part_log>
+        <database>system</database>
+        <table>part_log</table>
+
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+    </part_log>
+</yandex>
diff --git a/tests/integration/test_config_xml_full/configs/config.d/path.xml b/tests/integration/test_config_xml_full/configs/config.d/path.xml
new file mode 100644
index 000000000000..466ed0d16637
--- /dev/null
+++ b/tests/integration/test_config_xml_full/configs/config.d/path.xml
@@ -0,0 +1,8 @@
+<yandex>
+    <path replace="replace">./</path>
+    <tmp_path replace="replace">./tmp/</tmp_path>
+    <user_files_path replace="replace">./user_files/</user_files_path>
+    <format_schema_path replace="replace">./format_schemas/</format_schema_path>
+    <access_control_path replace="replace">./access/</access_control_path>
+    <top_level_domains_path replace="replace">./top_level_domains/</top_level_domains_path>
+</yandex>
diff --git a/tests/integration/test_config_xml_full/configs/config.d/query_masking_rules.xml b/tests/integration/test_config_xml_full/configs/config.d/query_masking_rules.xml
new file mode 100644
index 000000000000..5a854848f3d7
--- /dev/null
+++ b/tests/integration/test_config_xml_full/configs/config.d/query_masking_rules.xml
@@ -0,0 +1,10 @@
+<?xml version="1.0"?>
+<!-- Config for test server -->
+<yandex>
+    <query_masking_rules>
+        <rule>
+            <regexp>TOPSECRET.TOPSECRET</regexp>
+            <replace>[hidden]</replace>
+        </rule>
+    </query_masking_rules>
+</yandex>
diff --git a/tests/integration/test_config_xml_full/configs/config.d/tcp_with_proxy.xml b/tests/integration/test_config_xml_full/configs/config.d/tcp_with_proxy.xml
new file mode 100644
index 000000000000..19046054c166
--- /dev/null
+++ b/tests/integration/test_config_xml_full/configs/config.d/tcp_with_proxy.xml
@@ -0,0 +1,3 @@
+<yandex>
+    <tcp_with_proxy_port>9010</tcp_with_proxy_port>
+</yandex>
diff --git a/tests/integration/test_config_xml_full/configs/config.d/text_log.xml b/tests/integration/test_config_xml_full/configs/config.d/text_log.xml
new file mode 100644
index 000000000000..3699a23578cd
--- /dev/null
+++ b/tests/integration/test_config_xml_full/configs/config.d/text_log.xml
@@ -0,0 +1,7 @@
+<yandex>
+    <text_log>
+        <database>system</database>
+        <table>text_log</table>
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+    </text_log>
+</yandex>
diff --git a/tests/integration/test_config_xml_full/configs/config.d/zookeeper.xml b/tests/integration/test_config_xml_full/configs/config.d/zookeeper.xml
new file mode 100644
index 000000000000..06ed7fcd39f3
--- /dev/null
+++ b/tests/integration/test_config_xml_full/configs/config.d/zookeeper.xml
@@ -0,0 +1,8 @@
+<yandex>
+    <zookeeper>
+        <node index="1">
+            <host>localhost</host>
+            <port>9181</port>
+        </node>
+    </zookeeper>
+</yandex>
diff --git a/tests/integration/test_config_xml_full/configs/config.xml b/tests/integration/test_config_xml_full/configs/config.xml
new file mode 100644
index 000000000000..a7bb9d49e95c
--- /dev/null
+++ b/tests/integration/test_config_xml_full/configs/config.xml
@@ -0,0 +1,1118 @@
+<?xml version="1.0"?>
+<!--
+  NOTE: User and query level settings are set up in "users.xml" file.
+  If you have accidentally specified user-level settings here, server won't start.
+  You can either move the settings to the right place inside "users.xml" file
+   or add <skip_check_for_incorrect_settings>1</skip_check_for_incorrect_settings> here.
+-->
+<yandex>
+    <logger>
+        <!-- Possible levels [1]:
+
+          - none (turns off logging)
+          - fatal
+          - critical
+          - error
+          - warning
+          - notice
+          - information
+          - debug
+          - trace
+
+            [1]: https://github.com/pocoproject/poco/blob/poco-1.9.4-release/Foundation/include/Poco/Logger.h#L105-L114
+        -->
+        <level>trace</level>
+        <log>/var/log/clickhouse-server/clickhouse-server.log</log>
+        <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>
+        <!-- Rotation policy
+             See https://github.com/pocoproject/poco/blob/poco-1.9.4-release/Foundation/include/Poco/FileChannel.h#L54-L85
+          -->
+        <size>1000M</size>
+        <count>10</count>
+        <!-- <console>1</console> --> <!-- Default behavior is autodetection (log to console if not daemon mode and is tty) -->
+
+        <!-- Per level overrides (legacy):
+
+        For example to suppress logging of the ConfigReloader you can use:
+        NOTE: levels.logger is reserved, see below.
+        -->
+        <!--
+        <levels>
+          <ConfigReloader>none</ConfigReloader>
+        </levels>
+        -->
+
+        <!-- Per level overrides:
+
+        For example to suppress logging of the RBAC for default user you can use:
+        (But please note that the logger name maybe changed from version to version, even after minor upgrade)
+        -->
+        <!--
+        <levels>
+          <logger>
+            <name>ContextAccess (default)</name>
+            <level>none</level>
+          </logger>
+          <logger>
+            <name>DatabaseOrdinary (test)</name>
+            <level>none</level>
+          </logger>
+        </levels>
+        -->
+    </logger>
+
+    <!-- It is the name that will be shown in the clickhouse-client.
+         By default, anything with "production" will be highlighted in red in query prompt.
+    -->
+    <!--display_name>production</display_name-->
+
+    <!-- Port for HTTP API. See also 'https_port' for secure connections.
+         This interface is also used by ODBC and JDBC drivers (DataGrip, Dbeaver, ...)
+         and by most of web interfaces (embedded UI, Grafana, Redash, ...).
+      -->
+    <http_port>8123</http_port>
+
+    <!-- Port for interaction by native protocol with:
+         - clickhouse-client and other native ClickHouse tools (clickhouse-benchmark, clickhouse-copier);
+         - clickhouse-server with other clickhouse-servers for distributed query processing;
+         - ClickHouse drivers and applications supporting native protocol
+         (this protocol is also informally called as "the TCP protocol");
+         See also 'tcp_port_secure' for secure connections.
+    -->
+    <tcp_port>9000</tcp_port>
+
+    <!-- Compatibility with MySQL protocol.
+         ClickHouse will pretend to be MySQL for applications connecting to this port.
+    -->
+    <mysql_port>9004</mysql_port>
+
+    <!-- Compatibility with PostgreSQL protocol.
+         ClickHouse will pretend to be PostgreSQL for applications connecting to this port.
+    -->
+    <postgresql_port>9005</postgresql_port>
+
+    <!-- HTTP API with TLS (HTTPS).
+         You have to configure certificate to enable this interface.
+         See the openSSL section below.
+    -->
+    <!-- <https_port>8443</https_port> -->
+
+    <!-- Native interface with TLS.
+         You have to configure certificate to enable this interface.
+         See the openSSL section below.
+    -->
+    <!-- <tcp_port_secure>9440</tcp_port_secure> -->
+
+    <!-- Native interface wrapped with PROXYv1 protocol
+         PROXYv1 header sent for every connection.
+         ClickHouse will extract information about proxy-forwarded client address from the header.
+    -->
+    <!-- <tcp_with_proxy_port>9011</tcp_with_proxy_port> -->
+
+    <!-- Port for communication between replicas. Used for data exchange.
+         It provides low-level data access between servers.
+         This port should not be accessible from untrusted networks.
+         See also 'interserver_http_credentials'.
+         Data transferred over connections to this port should not go through untrusted networks.
+         See also 'interserver_https_port'.
+      -->
+    <interserver_http_port>9009</interserver_http_port>
+
+    <!-- Port for communication between replicas with TLS.
+         You have to configure certificate to enable this interface.
+         See the openSSL section below.
+         See also 'interserver_http_credentials'.
+      -->
+    <!-- <interserver_https_port>9010</interserver_https_port> -->
+
+    <!-- Hostname that is used by other replicas to request this server.
+         If not specified, than it is determined analogous to 'hostname -f' command.
+         This setting could be used to switch replication to another network interface
+         (the server may be connected to multiple networks via multiple addresses)
+      -->
+    <!--
+    <interserver_http_host>example.yandex.ru</interserver_http_host>
+    -->
+
+    <!-- You can specify credentials for authenthication between replicas.
+         This is required when interserver_https_port is accessible from untrusted networks,
+         and also recommended to avoid SSRF attacks from possibly compromised services in your network.
+      -->
+    <!--<interserver_http_credentials>
+        <user>interserver</user>
+        <password></password>
+    </interserver_http_credentials>-->
+
+    <!-- Listen specified address.
+         Use :: (wildcard IPv6 address), if you want to accept connections both with IPv4 and IPv6 from everywhere.
+         Notes:
+         If you open connections from wildcard address, make sure that at least one of the following measures applied:
+         - server is protected by firewall and not accessible from untrusted networks;
+         - all users are restricted to subset of network addresses (see users.xml);
+         - all users have strong passwords, only secure (TLS) interfaces are accessible, or connections are only made via TLS interfaces.
+         - users without password have readonly access.
+         See also: https://www.shodan.io/search?query=clickhouse
+      -->
+    <!-- <listen_host>::</listen_host> -->
+
+    <!-- Same for hosts without support for IPv6: -->
+    <!-- <listen_host>0.0.0.0</listen_host> -->
+
+    <!-- Default values - try listen localhost on IPv4 and IPv6. -->
+    <!--
+    <listen_host>::1</listen_host>
+    <listen_host>127.0.0.1</listen_host>
+    -->
+
+    <!-- Don't exit if IPv6 or IPv4 networks are unavailable while trying to listen. -->
+    <!-- <listen_try>0</listen_try> -->
+
+    <!-- Allow multiple servers to listen on the same address:port. This is not recommended.
+      -->
+    <!-- <listen_reuse_port>0</listen_reuse_port> -->
+
+    <!-- <listen_backlog>64</listen_backlog> -->
+
+    <max_connections>4096</max_connections>
+
+    <!-- For 'Connection: keep-alive' in HTTP 1.1 -->
+    <keep_alive_timeout>3</keep_alive_timeout>
+
+    <!-- gRPC protocol (see src/Server/grpc_protos/clickhouse_grpc.proto for the API) -->
+    <!-- <grpc_port>9100</grpc_port> -->
+    <grpc>
+        <enable_ssl>false</enable_ssl>
+
+        <!-- The following two files are used only if enable_ssl=1 -->
+        <ssl_cert_file>/path/to/ssl_cert_file</ssl_cert_file>
+        <ssl_key_file>/path/to/ssl_key_file</ssl_key_file>
+
+        <!-- Whether server will request client for a certificate -->
+        <ssl_require_client_auth>false</ssl_require_client_auth>
+
+        <!-- The following file is used only if ssl_require_client_auth=1 -->
+        <ssl_ca_cert_file>/path/to/ssl_ca_cert_file</ssl_ca_cert_file>
+
+        <!-- Default compression algorithm (applied if client doesn't specify another algorithm).
+             Supported algorithms: none, deflate, gzip, stream_gzip -->
+        <compression>deflate</compression>
+
+        <!-- Default compression level (applied if client doesn't specify another level).
+             Supported levels: none, low, medium, high -->
+        <compression_level>medium</compression_level>
+
+        <!-- Send/receive message size limits in bytes. -1 means unlimited -->
+        <max_send_message_size>-1</max_send_message_size>
+        <max_receive_message_size>-1</max_receive_message_size>
+
+        <!-- Enable if you want very detailed logs -->
+        <verbose_logs>false</verbose_logs>
+    </grpc>
+
+    <!-- Used with https_port and tcp_port_secure. Full ssl options list: https://github.com/ClickHouse-Extras/poco/blob/master/NetSSL_OpenSSL/include/Poco/Net/SSLManager.h#L71 -->
+    <openSSL>
+        <server> <!-- Used for https server AND secure tcp port -->
+            <!-- openssl req -subj "/CN=localhost" -new -newkey rsa:2048 -days 365 -nodes -x509 -keyout /etc/clickhouse-server/server.key -out /etc/clickhouse-server/server.crt -->
+            <certificateFile>/etc/clickhouse-server/server.crt</certificateFile>
+            <privateKeyFile>/etc/clickhouse-server/server.key</privateKeyFile>
+            <!-- dhparams are optional. You can delete the <dhParamsFile> element.
+                 To generate dhparams, use the following command:
+                  openssl dhparam -out /etc/clickhouse-server/dhparam.pem 4096
+                 Only file format with BEGIN DH PARAMETERS is supported.
+              -->
+            <dhParamsFile>/etc/clickhouse-server/dhparam.pem</dhParamsFile>
+            <verificationMode>none</verificationMode>
+            <loadDefaultCAFile>true</loadDefaultCAFile>
+            <cacheSessions>true</cacheSessions>
+            <disableProtocols>sslv2,sslv3</disableProtocols>
+            <preferServerCiphers>true</preferServerCiphers>
+        </server>
+
+        <client> <!-- Used for connecting to https dictionary source and secured Zookeeper communication -->
+            <loadDefaultCAFile>true</loadDefaultCAFile>
+            <cacheSessions>true</cacheSessions>
+            <disableProtocols>sslv2,sslv3</disableProtocols>
+            <preferServerCiphers>true</preferServerCiphers>
+            <!-- Use for self-signed: <verificationMode>none</verificationMode> -->
+            <invalidCertificateHandler>
+                <!-- Use for self-signed: <name>AcceptCertificateHandler</name> -->
+                <name>RejectCertificateHandler</name>
+            </invalidCertificateHandler>
+        </client>
+    </openSSL>
+
+    <!-- Default root page on http[s] server. For example load UI from https://tabix.io/ when opening http://localhost:8123 -->
+    <!--
+    <http_server_default_response><![CDATA[<html ng-app="SMI2"><head><base href="http://ui.tabix.io/"></head><body><div ui-view="" class="content-ui"></div><script src="http://loader.tabix.io/master.js"></script></body></html>]]></http_server_default_response>
+    -->
+
+    <!-- Maximum number of concurrent queries. -->
+    <max_concurrent_queries>100</max_concurrent_queries>
+
+    <!-- Maximum memory usage (resident set size) for server process.
+         Zero value or unset means default. Default is "max_server_memory_usage_to_ram_ratio" of available physical RAM.
+         If the value is larger than "max_server_memory_usage_to_ram_ratio" of available physical RAM, it will be cut down.
+
+         The constraint is checked on query execution time.
+         If a query tries to allocate memory and the current memory usage plus allocation is greater
+          than specified threshold, exception will be thrown.
+
+         It is not practical to set this constraint to small values like just a few gigabytes,
+          because memory allocator will keep this amount of memory in caches and the server will deny service of queries.
+      -->
+    <max_server_memory_usage>0</max_server_memory_usage>
+
+    <!-- Maximum number of threads in the Global thread pool.
+    This will default to a maximum of 10000 threads if not specified.
+    This setting will be useful in scenarios where there are a large number
+    of distributed queries that are running concurrently but are idling most
+    of the time, in which case a higher number of threads might be required.
+    -->
+
+    <max_thread_pool_size>10000</max_thread_pool_size>
+
+    <!-- On memory constrained environments you may have to set this to value larger than 1.
+      -->
+    <max_server_memory_usage_to_ram_ratio>0.9</max_server_memory_usage_to_ram_ratio>
+
+    <!-- Simple server-wide memory profiler. Collect a stack trace at every peak allocation step (in bytes).
+         Data will be stored in system.trace_log table with query_id = empty string.
+         Zero means disabled.
+      -->
+    <total_memory_profiler_step>4194304</total_memory_profiler_step>
+
+    <!-- Collect random allocations and deallocations and write them into system.trace_log with 'MemorySample' trace_type.
+         The probability is for every alloc/free regardless to the size of the allocation.
+         Note that sampling happens only when the amount of untracked memory exceeds the untracked memory limit,
+          which is 4 MiB by default but can be lowered if 'total_memory_profiler_step' is lowered.
+         You may want to set 'total_memory_profiler_step' to 1 for extra fine grained sampling.
+      -->
+    <total_memory_tracker_sample_probability>0</total_memory_tracker_sample_probability>
+
+    <!-- Set limit on number of open files (default: maximum). This setting makes sense on Mac OS X because getrlimit() fails to retrieve
+         correct maximum value. -->
+    <!-- <max_open_files>262144</max_open_files> -->
+
+    <!-- Size of cache of uncompressed blocks of data, used in tables of MergeTree family.
+         In bytes. Cache is single for server. Memory is allocated only on demand.
+         Cache is used when 'use_uncompressed_cache' user setting turned on (off by default).
+         Uncompressed cache is advantageous only for very short queries and in rare cases.
+
+         Note: uncompressed cache can be pointless for lz4, because memory bandwidth
+         is slower than multi-core decompression on some server configurations.
+         Enabling it can sometimes paradoxically make queries slower.
+      -->
+    <uncompressed_cache_size>8589934592</uncompressed_cache_size>
+
+    <!-- Approximate size of mark cache, used in tables of MergeTree family.
+         In bytes. Cache is single for server. Memory is allocated only on demand.
+         You should not lower this value.
+      -->
+    <mark_cache_size>5368709120</mark_cache_size>
+
+
+    <!-- If you enable the `min_bytes_to_use_mmap_io` setting,
+         the data in MergeTree tables can be read with mmap to avoid copying from kernel to userspace.
+         It makes sense only for large files and helps only if data reside in page cache.
+         To avoid frequent open/mmap/munmap/close calls (which are very expensive due to consequent page faults)
+         and to reuse mappings from several threads and queries,
+         the cache of mapped files is maintained. Its size is the number of mapped regions (usually equal to the number of mapped files).
+         The amount of data in mapped files can be monitored
+         in system.metrics, system.metric_log by the MMappedFiles, MMappedFileBytes metrics
+         and in system.asynchronous_metrics, system.asynchronous_metrics_log by the MMapCacheCells metric,
+         and also in system.events, system.processes, system.query_log, system.query_thread_log by the
+         CreatedReadBufferMMap, CreatedReadBufferMMapFailed, MMappedFileCacheHits, MMappedFileCacheMisses events.
+         Note that the amount of data in mapped files does not consume memory directly and is not accounted
+         in query or server memory usage - because this memory can be discarded similar to OS page cache.
+         The cache is dropped (the files are closed) automatically on removal of old parts in MergeTree,
+         also it can be dropped manually by the SYSTEM DROP MMAP CACHE query.
+      -->
+    <mmap_cache_size>1000</mmap_cache_size>
+
+
+    <!-- Path to data directory, with trailing slash. -->
+    <path>/var/lib/clickhouse/</path>
+
+    <!-- Path to temporary data for processing hard queries. -->
+    <tmp_path>/var/lib/clickhouse/tmp/</tmp_path>
+
+    <!-- Policy from the <storage_configuration> for the temporary files.
+         If not set <tmp_path> is used, otherwise <tmp_path> is ignored.
+
+         Notes:
+         - move_factor              is ignored
+         - keep_free_space_bytes    is ignored
+         - max_data_part_size_bytes is ignored
+         - you must have exactly one volume in that policy
+    -->
+    <!-- <tmp_policy>tmp</tmp_policy> -->
+
+    <!-- Directory with user provided files that are accessible by 'file' table function. -->
+    <user_files_path>/var/lib/clickhouse/user_files/</user_files_path>
+
+    <!-- LDAP server definitions. -->
+    <ldap_servers>
+        <!-- List LDAP servers with their connection parameters here to later 1) use them as authenticators for dedicated local users,
+              who have 'ldap' authentication mechanism specified instead of 'password', or to 2) use them as remote user directories.
+             Parameters:
+                host - LDAP server hostname or IP, this parameter is mandatory and cannot be empty.
+                port - LDAP server port, default is 636 if enable_tls is set to true, 389 otherwise.
+                bind_dn - template used to construct the DN to bind to.
+                        The resulting DN will be constructed by replacing all '{user_name}' substrings of the template with the actual
+                         user name during each authentication attempt.
+                verification_cooldown - a period of time, in seconds, after a successful bind attempt, during which a user will be assumed
+                         to be successfully authenticated for all consecutive requests without contacting the LDAP server.
+                        Specify 0 (the default) to disable caching and force contacting the LDAP server for each authentication request.
+                enable_tls - flag to trigger use of secure connection to the LDAP server.
+                        Specify 'no' for plain text (ldap://) protocol (not recommended).
+                        Specify 'yes' for LDAP over SSL/TLS (ldaps://) protocol (recommended, the default).
+                        Specify 'starttls' for legacy StartTLS protocol (plain text (ldap://) protocol, upgraded to TLS).
+                tls_minimum_protocol_version - the minimum protocol version of SSL/TLS.
+                        Accepted values are: 'ssl2', 'ssl3', 'tls1.0', 'tls1.1', 'tls1.2' (the default).
+                tls_require_cert - SSL/TLS peer certificate verification behavior.
+                        Accepted values are: 'never', 'allow', 'try', 'demand' (the default).
+                tls_cert_file - path to certificate file.
+                tls_key_file - path to certificate key file.
+                tls_ca_cert_file - path to CA certificate file.
+                tls_ca_cert_dir - path to the directory containing CA certificates.
+                tls_cipher_suite - allowed cipher suite (in OpenSSL notation).
+             Example:
+                <my_ldap_server>
+                    <host>localhost</host>
+                    <port>636</port>
+                    <bind_dn>uid={user_name},ou=users,dc=example,dc=com</bind_dn>
+                    <verification_cooldown>300</verification_cooldown>
+                    <enable_tls>yes</enable_tls>
+                    <tls_minimum_protocol_version>tls1.2</tls_minimum_protocol_version>
+                    <tls_require_cert>demand</tls_require_cert>
+                    <tls_cert_file>/path/to/tls_cert_file</tls_cert_file>
+                    <tls_key_file>/path/to/tls_key_file</tls_key_file>
+                    <tls_ca_cert_file>/path/to/tls_ca_cert_file</tls_ca_cert_file>
+                    <tls_ca_cert_dir>/path/to/tls_ca_cert_dir</tls_ca_cert_dir>
+                    <tls_cipher_suite>ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:AES256-GCM-SHA384</tls_cipher_suite>
+                </my_ldap_server>
+        -->
+    </ldap_servers>
+
+    <!-- To enable Kerberos authentication support for HTTP requests (GSS-SPNEGO), for those users who are explicitly configured
+          to authenticate via Kerberos, define a single 'kerberos' section here.
+         Parameters:
+            principal - canonical service principal name, that will be acquired and used when accepting security contexts.
+                    This parameter is optional, if omitted, the default principal will be used.
+                    This parameter cannot be specified together with 'realm' parameter.
+            realm - a realm, that will be used to restrict authentication to only those requests whose initiator's realm matches it.
+                    This parameter is optional, if omitted, no additional filtering by realm will be applied.
+                    This parameter cannot be specified together with 'principal' parameter.
+         Example:
+            <kerberos />
+         Example:
+            <kerberos>
+                <principal>HTTP/clickhouse.example.com@EXAMPLE.COM</principal>
+            </kerberos>
+         Example:
+            <kerberos>
+                <realm>EXAMPLE.COM</realm>
+            </kerberos>
+    -->
+
+    <!-- Sources to read users, roles, access rights, profiles of settings, quotas. -->
+    <user_directories>
+        <users_xml>
+            <!-- Path to configuration file with predefined users. -->
+            <path>users.xml</path>
+        </users_xml>
+        <local_directory>
+            <!-- Path to folder where users created by SQL commands are stored. -->
+            <path>/var/lib/clickhouse/access/</path>
+        </local_directory>
+
+        <!-- To add an LDAP server as a remote user directory of users that are not defined locally, define a single 'ldap' section
+              with the following parameters:
+                server - one of LDAP server names defined in 'ldap_servers' config section above.
+                        This parameter is mandatory and cannot be empty.
+                roles - section with a list of locally defined roles that will be assigned to each user retrieved from the LDAP server.
+                        If no roles are specified here or assigned during role mapping (below), user will not be able to perform any
+                         actions after authentication.
+                role_mapping - section with LDAP search parameters and mapping rules.
+                        When a user authenticates, while still bound to LDAP, an LDAP search is performed using search_filter and the
+                         name of the logged in user. For each entry found during that search, the value of the specified attribute is
+                         extracted. For each attribute value that has the specified prefix, the prefix is removed, and the rest of the
+                         value becomes the name of a local role defined in ClickHouse, which is expected to be created beforehand by
+                         CREATE ROLE command.
+                        There can be multiple 'role_mapping' sections defined inside the same 'ldap' section. All of them will be
+                         applied.
+                    base_dn - template used to construct the base DN for the LDAP search.
+                            The resulting DN will be constructed by replacing all '{user_name}' and '{bind_dn}' substrings
+                             of the template with the actual user name and bind DN during each LDAP search.
+                    scope - scope of the LDAP search.
+                            Accepted values are: 'base', 'one_level', 'children', 'subtree' (the default).
+                    search_filter - template used to construct the search filter for the LDAP search.
+                            The resulting filter will be constructed by replacing all '{user_name}', '{bind_dn}', and '{base_dn}'
+                             substrings of the template with the actual user name, bind DN, and base DN during each LDAP search.
+                            Note, that the special characters must be escaped properly in XML.
+                    attribute - attribute name whose values will be returned by the LDAP search.
+                    prefix - prefix, that will be expected to be in front of each string in the original list of strings returned by
+                             the LDAP search. Prefix will be removed from the original strings and resulting strings will be treated
+                             as local role names. Empty, by default.
+             Example:
+                <ldap>
+                    <server>my_ldap_server</server>
+                    <roles>
+                        <my_local_role1 />
+                        <my_local_role2 />
+                    </roles>
+                    <role_mapping>
+                        <base_dn>ou=groups,dc=example,dc=com</base_dn>
+                        <scope>subtree</scope>
+                        <search_filter>(&amp;(objectClass=groupOfNames)(member={bind_dn}))</search_filter>
+                        <attribute>cn</attribute>
+                        <prefix>clickhouse_</prefix>
+                    </role_mapping>
+                </ldap>
+        -->
+    </user_directories>
+
+    <!-- Default profile of settings. -->
+    <default_profile>default</default_profile>
+
+    <!-- Comma-separated list of prefixes for user-defined settings. -->
+    <custom_settings_prefixes></custom_settings_prefixes>
+
+    <!-- System profile of settings. This settings are used by internal processes (Distributed DDL worker and so on). -->
+    <!-- <system_profile>default</system_profile> -->
+
+    <!-- Buffer profile of settings.
+         This settings are used by Buffer storage to flush data to the underlying table.
+         Default: used from system_profile directive.
+    -->
+    <!-- <buffer_profile>default</buffer_profile> -->
+
+    <!-- Default database. -->
+    <default_database>default</default_database>
+
+    <!-- Server time zone could be set here.
+
+         Time zone is used when converting between String and DateTime types,
+          when printing DateTime in text formats and parsing DateTime from text,
+          it is used in date and time related functions, if specific time zone was not passed as an argument.
+
+         Time zone is specified as identifier from IANA time zone database, like UTC or Africa/Abidjan.
+         If not specified, system time zone at server startup is used.
+
+         Please note, that server could display time zone alias instead of specified name.
+         Example: W-SU is an alias for Europe/Moscow and Zulu is an alias for UTC.
+    -->
+    <!-- <timezone>Europe/Moscow</timezone> -->
+
+    <!-- You can specify umask here (see "man umask"). Server will apply it on startup.
+         Number is always parsed as octal. Default umask is 027 (other users cannot read logs, data files, etc; group can only read).
+    -->
+    <!-- <umask>022</umask> -->
+
+    <!-- Perform mlockall after startup to lower first queries latency
+          and to prevent clickhouse executable from being paged out under high IO load.
+         Enabling this option is recommended but will lead to increased startup time for up to a few seconds.
+    -->
+    <mlock_executable>true</mlock_executable>
+
+    <!-- Reallocate memory for machine code ("text") using huge pages. Highly experimental. -->
+    <remap_executable>false</remap_executable>
+
+    <![CDATA[
+         Uncomment below in order to use JDBC table engine and function.
+
+         To install and run JDBC bridge in background:
+         * [Debian/Ubuntu]
+           export MVN_URL=https://repo1.maven.org/maven2/ru/yandex/clickhouse/clickhouse-jdbc-bridge
+           export PKG_VER=$(curl -sL $MVN_URL/maven-metadata.xml | grep '<release>' | sed -e 's|.*>\(.*\)<.*|\1|')
+           wget https://github.com/ClickHouse/clickhouse-jdbc-bridge/releases/download/v$PKG_VER/clickhouse-jdbc-bridge_$PKG_VER-1_all.deb
+           apt install --no-install-recommends -f ./clickhouse-jdbc-bridge_$PKG_VER-1_all.deb
+           clickhouse-jdbc-bridge &
+
+         * [CentOS/RHEL]
+           export MVN_URL=https://repo1.maven.org/maven2/ru/yandex/clickhouse/clickhouse-jdbc-bridge
+           export PKG_VER=$(curl -sL $MVN_URL/maven-metadata.xml | grep '<release>' | sed -e 's|.*>\(.*\)<.*|\1|')
+           wget https://github.com/ClickHouse/clickhouse-jdbc-bridge/releases/download/v$PKG_VER/clickhouse-jdbc-bridge-$PKG_VER-1.noarch.rpm
+           yum localinstall -y clickhouse-jdbc-bridge-$PKG_VER-1.noarch.rpm
+           clickhouse-jdbc-bridge &
+
+         Please refer to https://github.com/ClickHouse/clickhouse-jdbc-bridge#usage for more information.
+    ]]>
+    <!--
+    <jdbc_bridge>
+        <host>127.0.0.1</host>
+        <port>9019</port>
+    </jdbc_bridge>
+    -->
+  
+    <!-- Configuration of clusters that could be used in Distributed tables.
+         https://clickhouse.tech/docs/en/operations/table_engines/distributed/
+      -->
+    <remote_servers>
+        <!-- Test only shard config for testing distributed storage -->
+        <test_shard_localhost>
+            <!-- Inter-server per-cluster secret for Distributed queries
+                 default: no secret (no authentication will be performed)
+
+                 If set, then Distributed queries will be validated on shards, so at least:
+                 - such cluster should exist on the shard,
+                 - such cluster should have the same secret.
+
+                 And also (and which is more important), the initial_user will
+                 be used as current user for the query.
+
+                 Right now the protocol is pretty simple and it only takes into account:
+                 - cluster name
+                 - query
+
+                 Also it will be nice if the following will be implemented:
+                 - source hostname (see interserver_http_host), but then it will depends from DNS,
+                   it can use IP address instead, but then the you need to get correct on the initiator node.
+                 - target hostname / ip address (same notes as for source hostname)
+                 - time-based security tokens
+            -->
+            <!-- <secret></secret> -->
+
+            <shard>
+                <!-- Optional. Whether to write data to just one of the replicas. Default: false (write data to all replicas). -->
+                <!-- <internal_replication>false</internal_replication> -->
+                <!-- Optional. Shard weight when writing data. Default: 1. -->
+                <!-- <weight>1</weight> -->
+                <replica>
+                    <host>localhost</host>
+                    <port>9000</port>
+                    <!-- Optional. Priority of the replica for load_balancing. Default: 1 (less value has more priority). -->
+                    <!-- <priority>1</priority> -->
+                </replica>
+            </shard>
+        </test_shard_localhost>
+        <test_cluster_two_shards_localhost>
+             <shard>
+                 <replica>
+                     <host>localhost</host>
+                     <port>9000</port>
+                 </replica>
+             </shard>
+             <shard>
+                 <replica>
+                     <host>localhost</host>
+                     <port>9000</port>
+                 </replica>
+             </shard>
+        </test_cluster_two_shards_localhost>
+        <test_cluster_two_shards>
+            <shard>
+                <replica>
+                    <host>127.0.0.1</host>
+                    <port>9000</port>
+                </replica>
+            </shard>
+            <shard>
+                <replica>
+                    <host>127.0.0.2</host>
+                    <port>9000</port>
+                </replica>
+            </shard>
+        </test_cluster_two_shards>
+        <test_cluster_two_shards_internal_replication>
+            <shard>
+                <internal_replication>true</internal_replication>
+                <replica>
+                    <host>127.0.0.1</host>
+                    <port>9000</port>
+                </replica>
+            </shard>
+            <shard>
+                <internal_replication>true</internal_replication>
+                <replica>
+                    <host>127.0.0.2</host>
+                    <port>9000</port>
+                </replica>
+            </shard>
+        </test_cluster_two_shards_internal_replication>
+        <test_shard_localhost_secure>
+            <shard>
+                <replica>
+                    <host>localhost</host>
+                    <port>9440</port>
+                    <secure>1</secure>
+                </replica>
+            </shard>
+        </test_shard_localhost_secure>
+        <test_unavailable_shard>
+            <shard>
+                <replica>
+                    <host>localhost</host>
+                    <port>9000</port>
+                </replica>
+            </shard>
+            <shard>
+                <replica>
+                    <host>localhost</host>
+                    <port>1</port>
+                </replica>
+            </shard>
+        </test_unavailable_shard>
+    </remote_servers>
+
+    <!-- The list of hosts allowed to use in URL-related storage engines and table functions.
+        If this section is not present in configuration, all hosts are allowed.
+    -->
+    <!--<remote_url_allow_hosts>-->
+        <!-- Host should be specified exactly as in URL. The name is checked before DNS resolution.
+            Example: "yandex.ru", "yandex.ru." and "www.yandex.ru" are different hosts.
+                    If port is explicitly specified in URL, the host:port is checked as a whole.
+                    If host specified here without port, any port with this host allowed.
+                    "yandex.ru" -> "yandex.ru:443", "yandex.ru:80" etc. is allowed, but "yandex.ru:80" -> only "yandex.ru:80" is allowed.
+            If the host is specified as IP address, it is checked as specified in URL. Example: "[2a02:6b8:a::a]".
+            If there are redirects and support for redirects is enabled, every redirect (the Location field) is checked.
+        -->
+
+        <!-- Regular expression can be specified. RE2 engine is used for regexps.
+            Regexps are not aligned: don't forget to add ^ and $. Also don't forget to escape dot (.) metacharacter
+            (forgetting to do so is a common source of error).
+        -->
+    <!--</remote_url_allow_hosts>-->
+
+    <!-- If element has 'incl' attribute, then for it's value will be used corresponding substitution from another file.
+         By default, path to file with substitutions is /etc/metrika.xml. It could be changed in config in 'include_from' element.
+         Values for substitutions are specified in /yandex/name_of_substitution elements in that file.
+      -->
+
+    <!-- ZooKeeper is used to store metadata about replicas, when using Replicated tables.
+         Optional. If you don't use replicated tables, you could omit that.
+
+         See https://clickhouse.tech/docs/en/engines/table-engines/mergetree-family/replication/
+      -->
+
+    <!--
+    <zookeeper>
+        <node>
+            <host>example1</host>
+            <port>2181</port>
+        </node>
+        <node>
+            <host>example2</host>
+            <port>2181</port>
+        </node>
+        <node>
+            <host>example3</host>
+            <port>2181</port>
+        </node>
+    </zookeeper>
+    -->
+
+    <!-- Substitutions for parameters of replicated tables.
+          Optional. If you don't use replicated tables, you could omit that.
+
+         See https://clickhouse.tech/docs/en/engines/table-engines/mergetree-family/replication/#creating-replicated-tables
+      -->
+    <!--
+    <macros>
+        <shard>01</shard>
+        <replica>example01-01-1</replica>
+    </macros>
+    -->
+
+
+    <!-- Reloading interval for embedded dictionaries, in seconds. Default: 3600. -->
+    <builtin_dictionaries_reload_interval>3600</builtin_dictionaries_reload_interval>
+
+
+    <!-- Maximum session timeout, in seconds. Default: 3600. -->
+    <max_session_timeout>3600</max_session_timeout>
+
+    <!-- Default session timeout, in seconds. Default: 60. -->
+    <default_session_timeout>60</default_session_timeout>
+
+    <!-- Sending data to Graphite for monitoring. Several sections can be defined. -->
+    <!--
+        interval - send every X second
+        root_path - prefix for keys
+        hostname_in_path - append hostname to root_path (default = true)
+        metrics - send data from table system.metrics
+        events - send data from table system.events
+        asynchronous_metrics - send data from table system.asynchronous_metrics
+    -->
+    <!--
+    <graphite>
+        <host>localhost</host>
+        <port>42000</port>
+        <timeout>0.1</timeout>
+        <interval>60</interval>
+        <root_path>one_min</root_path>
+        <hostname_in_path>true</hostname_in_path>
+
+        <metrics>true</metrics>
+        <events>true</events>
+        <events_cumulative>false</events_cumulative>
+        <asynchronous_metrics>true</asynchronous_metrics>
+    </graphite>
+    <graphite>
+        <host>localhost</host>
+        <port>42000</port>
+        <timeout>0.1</timeout>
+        <interval>1</interval>
+        <root_path>one_sec</root_path>
+
+        <metrics>true</metrics>
+        <events>true</events>
+        <events_cumulative>false</events_cumulative>
+        <asynchronous_metrics>false</asynchronous_metrics>
+    </graphite>
+    -->
+
+    <!-- Serve endpoint for Prometheus monitoring. -->
+    <!--
+        endpoint - mertics path (relative to root, statring with "/")
+        port - port to setup server. If not defined or 0 than http_port used
+        metrics - send data from table system.metrics
+        events - send data from table system.events
+        asynchronous_metrics - send data from table system.asynchronous_metrics
+        status_info - send data from different component from CH, ex: Dictionaries status
+    -->
+    <!--
+    <prometheus>
+        <endpoint>/metrics</endpoint>
+        <port>9363</port>
+
+        <metrics>true</metrics>
+        <events>true</events>
+        <asynchronous_metrics>true</asynchronous_metrics>
+        <status_info>true</status_info>
+    </prometheus>
+    -->
+
+    <!-- Query log. Used only for queries with setting log_queries = 1. -->
+    <query_log>
+        <!-- What table to insert data. If table is not exist, it will be created.
+             When query log structure is changed after system update,
+              then old table will be renamed and new table will be created automatically.
+        -->
+        <database>system</database>
+        <table>query_log</table>
+        <!--
+            PARTITION BY expr: https://clickhouse.yandex/docs/en/table_engines/mergetree-family/custom_partitioning_key/
+            Example:
+                event_date
+                toMonday(event_date)
+                toYYYYMM(event_date)
+                toStartOfHour(event_time)
+        -->
+        <partition_by>toYYYYMM(event_date)</partition_by>
+        <!--
+            Table TTL specification: https://clickhouse.tech/docs/en/engines/table-engines/mergetree-family/mergetree/#mergetree-table-ttl
+            Example:
+                event_date + INTERVAL 1 WEEK
+                event_date + INTERVAL 7 DAY DELETE
+                event_date + INTERVAL 2 WEEK TO DISK 'bbb'
+
+        <ttl>event_date + INTERVAL 30 DAY DELETE</ttl>
+        -->
+
+        <!-- Instead of partition_by, you can provide full engine expression (starting with ENGINE = ) with parameters,
+             Example: <engine>ENGINE = MergeTree PARTITION BY toYYYYMM(event_date) ORDER BY (event_date, event_time) SETTINGS index_granularity = 1024</engine>
+          -->
+
+        <!-- Interval of flushing data. -->
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+    </query_log>
+
+    <!-- Trace log. Stores stack traces collected by query profilers.
+         See query_profiler_real_time_period_ns and query_profiler_cpu_time_period_ns settings. -->
+    <trace_log>
+        <database>system</database>
+        <table>trace_log</table>
+
+        <partition_by>toYYYYMM(event_date)</partition_by>
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+    </trace_log>
+
+    <!-- Query thread log. Has information about all threads participated in query execution.
+         Used only for queries with setting log_query_threads = 1. -->
+    <query_thread_log>
+        <database>system</database>
+        <table>query_thread_log</table>
+        <partition_by>toYYYYMM(event_date)</partition_by>
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+    </query_thread_log>
+
+    <!-- Uncomment if use part log.
+         Part log contains information about all actions with parts in MergeTree tables (creation, deletion, merges, downloads).
+    <part_log>
+        <database>system</database>
+        <table>part_log</table>
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+    </part_log>
+    -->
+
+    <!-- Uncomment to write text log into table.
+         Text log contains all information from usual server log but stores it in structured and efficient way.
+         The level of the messages that goes to the table can be limited (<level>), if not specified all messages will go to the table.
+    <text_log>
+        <database>system</database>
+        <table>text_log</table>
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+        <level></level>
+    </text_log>
+    -->
+
+    <!-- Metric log contains rows with current values of ProfileEvents, CurrentMetrics collected with "collect_interval_milliseconds" interval. -->
+    <metric_log>
+        <database>system</database>
+        <table>metric_log</table>
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+        <collect_interval_milliseconds>1000</collect_interval_milliseconds>
+    </metric_log>
+
+    <!--
+        Asynchronous metric log contains values of metrics from
+        system.asynchronous_metrics.
+    -->
+    <asynchronous_metric_log>
+        <database>system</database>
+        <table>asynchronous_metric_log</table>
+        <!--
+            Asynchronous metrics are updated once a minute, so there is
+            no need to flush more often.
+        -->
+        <flush_interval_milliseconds>60000</flush_interval_milliseconds>
+    </asynchronous_metric_log>
+
+    <!--
+        OpenTelemetry log contains OpenTelemetry trace spans.
+    -->
+    <opentelemetry_span_log>
+        <!--
+            The default table creation code is insufficient, this <engine> spec
+            is a workaround. There is no 'event_time' for this log, but two times,
+            start and finish. It is sorted by finish time, to avoid inserting
+            data too far away in the past (probably we can sometimes insert a span
+            that is seconds earlier than the last span in the table, due to a race
+            between several spans inserted in parallel). This gives the spans a
+            global order that we can use to e.g. retry insertion into some external
+            system.
+        -->
+        <engine>
+            engine MergeTree
+            partition by toYYYYMM(finish_date)
+            order by (finish_date, finish_time_us, trace_id)
+        </engine>
+        <database>system</database>
+        <table>opentelemetry_span_log</table>
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+    </opentelemetry_span_log>
+
+
+    <!-- Crash log. Stores stack traces for fatal errors.
+         This table is normally empty. -->
+    <crash_log>
+        <database>system</database>
+        <table>crash_log</table>
+
+        <partition_by />
+        <flush_interval_milliseconds>1000</flush_interval_milliseconds>
+    </crash_log>
+
+    <!-- Parameters for embedded dictionaries, used in Yandex.Metrica.
+         See https://clickhouse.yandex/docs/en/dicts/internal_dicts/
+    -->
+
+    <!-- Path to file with region hierarchy. -->
+    <!-- <path_to_regions_hierarchy_file>/opt/geo/regions_hierarchy.txt</path_to_regions_hierarchy_file> -->
+
+    <!-- Path to directory with files containing names of regions -->
+    <!-- <path_to_regions_names_files>/opt/geo/</path_to_regions_names_files> -->
+
+
+    <!-- <top_level_domains_path>/var/lib/clickhouse/top_level_domains/</top_level_domains_path> -->
+    <!-- Custom TLD lists.
+         Format: <name>/path/to/file</name>
+
+         Changes will not be applied w/o server restart.
+         Path to the list is under top_level_domains_path (see above).
+    -->
+    <top_level_domains_lists>
+        <!--
+        <public_suffix_list>/path/to/public_suffix_list.dat</public_suffix_list>
+        -->
+    </top_level_domains_lists>
+
+    <!-- Configuration of external dictionaries. See:
+         https://clickhouse.tech/docs/en/sql-reference/dictionaries/external-dictionaries/external-dicts
+    -->
+    <dictionaries_config>*_dictionary.xml</dictionaries_config>
+
+    <!-- Uncomment if you want data to be compressed 30-100% better.
+         Don't do that if you just started using ClickHouse.
+      -->
+    <!--
+    <compression>
+        <!- - Set of variants. Checked in order. Last matching case wins. If nothing matches, lz4 will be used. - ->
+        <case>
+
+            <!- - Conditions. All must be satisfied. Some conditions may be omitted. - ->
+            <min_part_size>10000000000</min_part_size>        <!- - Min part size in bytes. - ->
+            <min_part_size_ratio>0.01</min_part_size_ratio>   <!- - Min size of part relative to whole table size. - ->
+
+            <!- - What compression method to use. - ->
+            <method>zstd</method>
+        </case>
+    </compression>
+    -->
+
+    <!-- Allow to execute distributed DDL queries (CREATE, DROP, ALTER, RENAME) on cluster.
+         Works only if ZooKeeper is enabled. Comment it if such functionality isn't required. -->
+    <distributed_ddl>
+        <!-- Path in ZooKeeper to queue with DDL queries -->
+        <path>/clickhouse/task_queue/ddl</path>
+
+        <!-- Settings from this profile will be used to execute DDL queries -->
+        <!-- <profile>default</profile> -->
+
+        <!-- Controls how much ON CLUSTER queries can be run simultaneously. -->
+        <!-- <pool_size>1</pool_size> -->
+
+        <!--
+             Cleanup settings (active tasks will not be removed)
+        -->
+
+        <!-- Controls task TTL (default 1 week) -->
+        <!-- <task_max_lifetime>604800</task_max_lifetime> -->
+
+        <!-- Controls how often cleanup should be performed (in seconds) -->
+        <!-- <cleanup_delay_period>60</cleanup_delay_period> -->
+
+        <!-- Controls how many tasks could be in the queue -->
+        <!-- <max_tasks_in_queue>1000</max_tasks_in_queue> -->
+    </distributed_ddl>
+
+    <!-- Settings to fine tune MergeTree tables. See documentation in source code, in MergeTreeSettings.h -->
+    <!--
+    <merge_tree>
+        <max_suspicious_broken_parts>5</max_suspicious_broken_parts>
+    </merge_tree>
+    -->
+
+    <!-- Protection from accidental DROP.
+         If size of a MergeTree table is greater than max_table_size_to_drop (in bytes) than table could not be dropped with any DROP query.
+         If you want do delete one table and don't want to change clickhouse-server config, you could create special file <clickhouse-path>/flags/force_drop_table and make DROP once.
+         By default max_table_size_to_drop is 50GB; max_table_size_to_drop=0 allows to DROP any tables.
+         The same for max_partition_size_to_drop.
+         Uncomment to disable protection.
+    -->
+    <!-- <max_table_size_to_drop>0</max_table_size_to_drop> -->
+    <!-- <max_partition_size_to_drop>0</max_partition_size_to_drop> -->
+
+    <!-- Example of parameters for GraphiteMergeTree table engine -->
+    <graphite_rollup_example>
+        <pattern>
+            <regexp>click_cost</regexp>
+            <function>any</function>
+            <retention>
+                <age>0</age>
+                <precision>3600</precision>
+            </retention>
+            <retention>
+                <age>86400</age>
+                <precision>60</precision>
+            </retention>
+        </pattern>
+        <default>
+            <function>max</function>
+            <retention>
+                <age>0</age>
+                <precision>60</precision>
+            </retention>
+            <retention>
+                <age>3600</age>
+                <precision>300</precision>
+            </retention>
+            <retention>
+                <age>86400</age>
+                <precision>3600</precision>
+            </retention>
+        </default>
+    </graphite_rollup_example>
+
+    <!-- Directory in <clickhouse-path> containing schema files for various input formats.
+         The directory will be created if it doesn't exist.
+      -->
+    <format_schema_path>/var/lib/clickhouse/format_schemas/</format_schema_path>
+
+    <!-- Default query masking rules, matching lines would be replaced with something else in the logs
+        (both text logs and system.query_log).
+        name - name for the rule (optional)
+        regexp - RE2 compatible regular expression (mandatory)
+        replace - substitution string for sensitive data (optional, by default - six asterisks)
+    -->
+    <query_masking_rules>
+        <rule>
+            <name>hide encrypt/decrypt arguments</name>
+            <regexp>((?:aes_)?(?:encrypt|decrypt)(?:_mysql)?)\s*\(\s*(?:'(?:\\'|.)+'|.*?)\s*\)</regexp>
+            <!-- or more secure, but also more invasive:
+                (aes_\w+)\s*\(.*\)
+            -->
+            <replace>\1(???)</replace>
+        </rule>
+    </query_masking_rules>
+
+    <!-- Uncomment to use custom http handlers.
+        rules are checked from top to bottom, first match runs the handler
+            url - to match request URL, you can use 'regex:' prefix to use regex match(optional)
+            methods - to match request method, you can use commas to separate multiple method matches(optional)
+            headers - to match request headers, match each child element(child element name is header name), you can use 'regex:' prefix to use regex match(optional)
+        handler is request handler
+            type - supported types: static, dynamic_query_handler, predefined_query_handler
+            query - use with predefined_query_handler type, executes query when the handler is called
+            query_param_name - use with dynamic_query_handler type, extracts and executes the value corresponding to the <query_param_name> value in HTTP request params
+            status - use with static type, response status code
+            content_type - use with static type, response content-type
+            response_content - use with static type, Response content sent to client, when using the prefix 'file://' or 'config://', find the content from the file or configuration send to client.
+
+    <http_handlers>
+        <rule>
+            <url>/</url>
+            <methods>POST,GET</methods>
+            <headers><pragma>no-cache</pragma></headers>
+            <handler>
+                <type>dynamic_query_handler</type>
+                <query_param_name>query</query_param_name>
+            </handler>
+        </rule>
+
+        <rule>
+            <url>/predefined_query</url>
+            <methods>POST,GET</methods>
+            <handler>
+                <type>predefined_query_handler</type>
+                <query>SELECT * FROM system.settings</query>
+            </handler>
+        </rule>
+
+        <rule>
+            <handler>
+                <type>static</type>
+                <status>200</status>
+                <content_type>text/plain; charset=UTF-8</content_type>
+                <response_content>config://http_server_default_response</response_content>
+            </handler>
+        </rule>
+    </http_handlers>
+    -->
+
+    <send_crash_reports>
+        <!-- Changing <enabled> to true allows sending crash reports to -->
+        <!-- the ClickHouse core developers team via Sentry https://sentry.io -->
+        <!-- Doing so at least in pre-production environments is highly appreciated -->
+        <enabled>false</enabled>
+        <!-- Change <anonymize> to true if you don't feel comfortable attaching the server hostname to the crash report -->
+        <anonymize>false</anonymize>
+        <!-- Default endpoint should be changed to different Sentry DSN only if you have -->
+        <!-- some in-house engineers or hired consultants who're going to debug ClickHouse issues for you -->
+        <endpoint>https://6f33034cfe684dd7a3ab9875e57b1c8d@o388870.ingest.sentry.io/5226277</endpoint>
+    </send_crash_reports>
+
+    <!-- Uncomment to disable ClickHouse internal DNS caching. -->
+    <!-- <disable_internal_dns_cache>1</disable_internal_dns_cache> -->
+</yandex>
diff --git a/tests/integration/test_config_xml_full/configs/embedded.xml b/tests/integration/test_config_xml_full/configs/embedded.xml
new file mode 100644
index 000000000000..a66f57d1eb70
--- /dev/null
+++ b/tests/integration/test_config_xml_full/configs/embedded.xml
@@ -0,0 +1,40 @@
+<?xml version="1.0"?>
+<!-- Config that is used when server is run without config file. -->
+<yandex>
+    <logger>
+        <level>trace</level>
+        <console>true</console>
+    </logger>
+
+    <http_port>8123</http_port>
+    <tcp_port>9000</tcp_port>
+    <mysql_port>9004</mysql_port>
+
+    <path>./</path>
+
+    <uncompressed_cache_size>8589934592</uncompressed_cache_size>
+    <mark_cache_size>5368709120</mark_cache_size>
+    <mlock_executable>true</mlock_executable>
+
+    <users>
+        <default>
+            <password></password>
+
+            <networks>
+                <ip>::/0</ip>
+            </networks>
+
+            <profile>default</profile>
+            <quota>default</quota>
+            <access_management>1</access_management>
+        </default>
+    </users>
+
+    <profiles>
+        <default/>
+    </profiles>
+
+    <quotas>
+        <default />
+    </quotas>
+</yandex>
diff --git a/tests/integration/test_config_xml_full/configs/users.d/allow_introspection_functions.xml b/tests/integration/test_config_xml_full/configs/users.d/allow_introspection_functions.xml
new file mode 100644
index 000000000000..b94e95bc043d
--- /dev/null
+++ b/tests/integration/test_config_xml_full/configs/users.d/allow_introspection_functions.xml
@@ -0,0 +1,8 @@
+<?xml version="1.0"?>
+<yandex>
+    <profiles>
+        <default>
+            <allow_introspection_functions>1</allow_introspection_functions>
+        </default>
+    </profiles>
+</yandex>
diff --git a/tests/integration/test_config_xml_full/configs/users.d/log_queries.xml b/tests/integration/test_config_xml_full/configs/users.d/log_queries.xml
new file mode 100644
index 000000000000..25261072ade6
--- /dev/null
+++ b/tests/integration/test_config_xml_full/configs/users.d/log_queries.xml
@@ -0,0 +1,7 @@
+<yandex>
+    <profiles>
+        <default>
+            <log_queries>1</log_queries>
+        </default>
+    </profiles>
+</yandex>
diff --git a/tests/integration/test_config_xml_full/configs/users.xml b/tests/integration/test_config_xml_full/configs/users.xml
new file mode 100644
index 000000000000..829748dafb14
--- /dev/null
+++ b/tests/integration/test_config_xml_full/configs/users.xml
@@ -0,0 +1,120 @@
+<?xml version="1.0"?>
+<yandex>
+    <!-- Profiles of settings. -->
+    <profiles>
+        <!-- Default settings. -->
+        <default>
+            <!-- Maximum memory usage for processing single query, in bytes. -->
+            <max_memory_usage>10000000000</max_memory_usage>
+            <max_block_size>64999</max_block_size>
+
+            <!-- How to choose between replicas during distributed query processing.
+                 random - choose random replica from set of replicas with minimum number of errors
+                 nearest_hostname - from set of replicas with minimum number of errors, choose replica
+                  with minimum number of different symbols between replica's hostname and local hostname
+                  (Hamming distance).
+                 in_order - first live replica is chosen in specified order.
+                 first_or_random - if first replica one has higher number of errors, pick a random one from replicas with minimum number of errors.
+            -->
+            <load_balancing>random</load_balancing>
+        </default>
+
+        <!-- Profile that allows only read queries. -->
+        <readonly>
+            <readonly>1</readonly>
+        </readonly>
+    </profiles>
+
+    <!-- Users and ACL. -->
+    <users>
+        <!-- If user name was not specified, 'default' user is used. -->
+        <default>
+            <!-- Password could be specified in plaintext or in SHA256 (in hex format).
+
+                 If you want to specify password in plaintext (not recommended), place it in 'password' element.
+                 Example: <password>qwerty</password>.
+                 Password could be empty.
+
+                 If you want to specify SHA256, place it in 'password_sha256_hex' element.
+                 Example: <password_sha256_hex>65e84be33532fb784c48129675f9eff3a682b27168c0ea744b2cf58ee02337c5</password_sha256_hex>
+                 Restrictions of SHA256: impossibility to connect to ClickHouse using MySQL JS client (as of July 2019).
+
+                 If you want to specify double SHA1, place it in 'password_double_sha1_hex' element.
+                 Example: <password_double_sha1_hex>e395796d6546b1b65db9d665cd43f0e858dd4303</password_double_sha1_hex>
+
+                 If you want to specify a previously defined LDAP server (see 'ldap_servers' in the main config) for authentication,
+                  place its name in 'server' element inside 'ldap' element.
+                 Example: <ldap><server>my_ldap_server</server></ldap>
+
+                 If you want to authenticate the user via Kerberos (assuming Kerberos is enabled, see 'kerberos' in the main config),
+                  place 'kerberos' element instead of 'password' (and similar) elements.
+                 The name part of the canonical principal name of the initiator must match the user name for authentication to succeed.
+                 You can also place 'realm' element inside 'kerberos' element to further restrict authentication to only those requests
+                  whose initiator's realm matches it. 
+                 Example: <kerberos />
+                 Example: <kerberos><realm>EXAMPLE.COM</realm></kerberos>
+
+                 How to generate decent password:
+                 Execute: PASSWORD=$(base64 < /dev/urandom | head -c8); echo "$PASSWORD"; echo -n "$PASSWORD" | sha256sum | tr -d '-'
+                 In first line will be password and in second - corresponding SHA256.
+
+                 How to generate double SHA1:
+                 Execute: PASSWORD=$(base64 < /dev/urandom | head -c8); echo "$PASSWORD"; echo -n "$PASSWORD" | sha1sum | tr -d '-' | xxd -r -p | sha1sum | tr -d '-'
+                 In first line will be password and in second - corresponding double SHA1.
+            -->
+            <password></password>
+
+            <!-- List of networks with open access.
+
+                 To open access from everywhere, specify:
+                    <ip>::/0</ip>
+
+                 To open access only from localhost, specify:
+                    <ip>::1</ip>
+                    <ip>127.0.0.1</ip>
+
+                 Each element of list has one of the following forms:
+                 <ip> IP-address or network mask. Examples: 213.180.204.3 or 10.0.0.1/8 or 10.0.0.1/255.255.255.0
+                     2a02:6b8::3 or 2a02:6b8::3/64 or 2a02:6b8::3/ffff:ffff:ffff:ffff::.
+                 <host> Hostname. Example: server01.yandex.ru.
+                     To check access, DNS query is performed, and all received addresses compared to peer address.
+                 <host_regexp> Regular expression for host names. Example, ^server\d\d-\d\d-\d\.yandex\.ru$
+                     To check access, DNS PTR query is performed for peer address and then regexp is applied.
+                     Then, for result of PTR query, another DNS query is performed and all received addresses compared to peer address.
+                     Strongly recommended that regexp is ends with $
+                 All results of DNS requests are cached till server restart.
+            -->
+            <networks>
+                <ip>::/0</ip>
+            </networks>
+
+            <!-- Settings profile for user. -->
+            <profile>default</profile>
+
+            <!-- Quota for user. -->
+            <quota>default</quota>
+
+            <!-- User can create other users and grant rights to them. -->
+            <!-- <access_management>1</access_management> -->
+        </default>
+    </users>
+
+    <!-- Quotas. -->
+    <quotas>
+        <!-- Name of quota. -->
+        <default>
+            <!-- Limits for time interval. You could specify many intervals with different limits. -->
+            <interval>
+                <!-- Length of interval. -->
+                <duration>3600</duration>
+
+                <!-- No limits. Just calculate resource usage for time interval. -->
+                <queries>0</queries>
+                <errors>0</errors>
+                <result_rows>0</result_rows>
+                <read_rows>0</read_rows>
+                <execution_time>0</execution_time>
+            </interval>
+        </default>
+    </quotas>
+</yandex>
diff --git a/tests/integration/test_config_xml_full/test.py b/tests/integration/test_config_xml_full/test.py
new file mode 100644
index 000000000000..a8650a0dc553
--- /dev/null
+++ b/tests/integration/test_config_xml_full/test.py
@@ -0,0 +1,40 @@
+import time
+import threading
+from os import path as p, unlink
+from tempfile import NamedTemporaryFile
+
+import helpers
+import pytest
+from helpers.cluster import ClickHouseCluster
+
+
+def test_xml_full_conf():
+    # all configs are in XML
+    cluster = ClickHouseCluster(__file__, zookeeper_config_path='configs/config.d/zookeeper.xml')
+
+    all_confd = ['configs/config.d/access_control.xml',
+                'configs/config.d/keeper_port.xml',
+                'configs/config.d/logging_no_rotate.xml',
+                'configs/config.d/log_to_console.xml',
+                'configs/config.d/macros.xml',
+                'configs/config.d/metric_log.xml',
+                'configs/config.d/more_clusters.xml',
+                'configs/config.d/part_log.xml',
+                'configs/config.d/path.xml',
+                'configs/config.d/query_masking_rules.xml',
+                'configs/config.d/tcp_with_proxy.xml',
+                'configs/config.d/text_log.xml',
+                'configs/config.d/zookeeper.xml']
+
+    all_userd = ['configs/users.d/allow_introspection_functions.xml',
+                'configs/users.d/log_queries.xml']
+
+    node = cluster.add_instance('node', base_config_dir='configs', main_configs=all_confd, user_configs=all_userd, with_zookeeper=False)
+
+    try:
+        cluster.start()
+        assert(node.query("select value from system.settings where name = 'max_memory_usage'") == "10000000000
")
+        assert(node.query("select value from system.settings where name = 'max_block_size'") == "64999
")
+
+    finally:
+        cluster.shutdown()
diff --git a/tests/integration/test_config_xml_main/__init__.py b/tests/integration/test_config_xml_main/__init__.py
new file mode 100644
index 000000000000..e69de29bb2d1
diff --git a/tests/integration/test_config_xml_main/configs/config.d/access_control.yaml b/tests/integration/test_config_xml_main/configs/config.d/access_control.yaml
new file mode 100644
index 000000000000..d8ead517c862
--- /dev/null
+++ b/tests/integration/test_config_xml_main/configs/config.d/access_control.yaml
@@ -0,0 +1,7 @@
+user_directories:
+  users_xml:
+    path: users.xml
+  local_directory:
+    path: access/
+  "@replace": replace
+
diff --git a/tests/integration/test_config_xml_main/configs/config.d/keeper_port.yaml b/tests/integration/test_config_xml_main/configs/config.d/keeper_port.yaml
new file mode 100644
index 000000000000..91723bc372f1
--- /dev/null
+++ b/tests/integration/test_config_xml_main/configs/config.d/keeper_port.yaml
@@ -0,0 +1,15 @@
+keeper_server:
+  tcp_port: 9181
+  server_id: 1
+  coordination_settings:
+    operation_timeout_ms: 10000
+    session_timeout_ms: 30000
+    force_sync: false
+    startup_timeout: 60000
+    reserved_log_items: 1000000000000000
+  raft_configuration:
+    server:
+      id: 1
+      hostname: localhost
+      port: 44444
+
diff --git a/tests/integration/test_config_xml_main/configs/config.d/log_to_console.yaml b/tests/integration/test_config_xml_main/configs/config.d/log_to_console.yaml
new file mode 100644
index 000000000000..7b59339800b9
--- /dev/null
+++ b/tests/integration/test_config_xml_main/configs/config.d/log_to_console.yaml
@@ -0,0 +1,7 @@
+logger:
+  console: true
+  log:
+    "@remove": remove
+  errorlog:
+    "@remove": remove
+
diff --git a/tests/integration/test_config_xml_main/configs/config.d/logging_no_rotate.yaml b/tests/integration/test_config_xml_main/configs/config.d/logging_no_rotate.yaml
new file mode 100644
index 000000000000..513cd3f7dc51
--- /dev/null
+++ b/tests/integration/test_config_xml_main/configs/config.d/logging_no_rotate.yaml
@@ -0,0 +1,2 @@
+logger:
+  size: never
diff --git a/tests/integration/test_config_xml_main/configs/config.d/macros.yaml b/tests/integration/test_config_xml_main/configs/config.d/macros.yaml
new file mode 100644
index 000000000000..a9c61e270ab3
--- /dev/null
+++ b/tests/integration/test_config_xml_main/configs/config.d/macros.yaml
@@ -0,0 +1,7 @@
+macros:
+  test: 'Hello, world!'
+  shard: s1
+  replica: r1
+  default_path_test: '/clickhouse/tables/{database}/{shard}/'
+  default_name_test: 'table_{table}'
+
diff --git a/tests/integration/test_config_xml_main/configs/config.d/metric_log.yaml b/tests/integration/test_config_xml_main/configs/config.d/metric_log.yaml
new file mode 100644
index 000000000000..aafad939c377
--- /dev/null
+++ b/tests/integration/test_config_xml_main/configs/config.d/metric_log.yaml
@@ -0,0 +1,6 @@
+metric_log:
+  database: system
+  table: metric_log
+  flush_interval_milliseconds: 7500
+  collect_interval_milliseconds: 1000
+
diff --git a/tests/integration/test_config_xml_main/configs/config.d/more_clusters.yaml b/tests/integration/test_config_xml_main/configs/config.d/more_clusters.yaml
new file mode 100644
index 000000000000..7da071908945
--- /dev/null
+++ b/tests/integration/test_config_xml_main/configs/config.d/more_clusters.yaml
@@ -0,0 +1,23 @@
+remote_servers:
+  single_remote_shard_at_port_9001:
+    shard:
+      replica:
+        host: localhost
+        port: 9001
+  two_remote_shards_at_port_9001_9002:
+    shard:
+      - replica:
+          host: localhost
+          port: 9001
+      - replica:
+          host: localhost
+          port: 9002
+  two_shards_one_local_one_remote_at_port_9001:
+    shard:
+      - replica:
+          host: localhost
+          port: 9000
+      - replica:
+          host: localhost
+          port: 9001
+
diff --git a/tests/integration/test_config_xml_main/configs/config.d/part_log.yaml b/tests/integration/test_config_xml_main/configs/config.d/part_log.yaml
new file mode 100644
index 000000000000..43f60146dca1
--- /dev/null
+++ b/tests/integration/test_config_xml_main/configs/config.d/part_log.yaml
@@ -0,0 +1,5 @@
+part_log:
+  database: system
+  table: part_log
+  flush_interval_milliseconds: 7500
+
diff --git a/tests/integration/test_config_xml_main/configs/config.d/path.yaml b/tests/integration/test_config_xml_main/configs/config.d/path.yaml
new file mode 100644
index 000000000000..3e26e8906eef
--- /dev/null
+++ b/tests/integration/test_config_xml_main/configs/config.d/path.yaml
@@ -0,0 +1,18 @@
+path:
+  - ./
+  - "@replace": replace
+tmp_path:
+  - ./tmp/
+  - "@replace": replace
+user_files_path:
+  - ./user_files/
+  - "@replace": replace
+format_schema_path:
+  - ./format_schemas/
+  - "@replace": replace
+access_control_path:
+  - ./access/
+  - "@replace": replace
+top_level_domains_path:
+  - ./top_level_domains/
+  - "@replace": replace
diff --git a/tests/integration/test_config_xml_main/configs/config.d/query_masking_rules.yaml b/tests/integration/test_config_xml_main/configs/config.d/query_masking_rules.yaml
new file mode 100644
index 000000000000..38163429d810
--- /dev/null
+++ b/tests/integration/test_config_xml_main/configs/config.d/query_masking_rules.yaml
@@ -0,0 +1,4 @@
+query_masking_rules:
+  rule:
+    regexp: TOPSECRET.TOPSECRET
+    replace: '[hidden]'
diff --git a/tests/integration/test_config_xml_main/configs/config.d/tcp_with_proxy.yaml b/tests/integration/test_config_xml_main/configs/config.d/tcp_with_proxy.yaml
new file mode 100644
index 000000000000..b0349f5a9b99
--- /dev/null
+++ b/tests/integration/test_config_xml_main/configs/config.d/tcp_with_proxy.yaml
@@ -0,0 +1,1 @@
+tcp_with_proxy_port: 9010
diff --git a/tests/integration/test_config_xml_main/configs/config.d/test_cluster_with_incorrect_pw.yaml b/tests/integration/test_config_xml_main/configs/config.d/test_cluster_with_incorrect_pw.yaml
new file mode 100644
index 000000000000..309a7daa81d1
--- /dev/null
+++ b/tests/integration/test_config_xml_main/configs/config.d/test_cluster_with_incorrect_pw.yaml
@@ -0,0 +1,11 @@
+remote_servers:
+  test_cluster_with_incorrect_pw:
+    shard:
+      internal_replication: true
+      replica:
+        - host: 127.0.0.1
+          port: 9000
+          password: foo
+        - host: 127.0.0.2
+          port: 9000
+          password: foo
diff --git a/tests/integration/test_config_xml_main/configs/config.d/text_log.yaml b/tests/integration/test_config_xml_main/configs/config.d/text_log.yaml
new file mode 100644
index 000000000000..4d188020e374
--- /dev/null
+++ b/tests/integration/test_config_xml_main/configs/config.d/text_log.yaml
@@ -0,0 +1,4 @@
+text_log:
+  database: system
+  table: text_log
+  flush_interval_milliseconds: 7500
diff --git a/tests/integration/test_config_xml_main/configs/config.d/zookeeper.yaml b/tests/integration/test_config_xml_main/configs/config.d/zookeeper.yaml
new file mode 100644
index 000000000000..be02c516798a
--- /dev/null
+++ b/tests/integration/test_config_xml_main/configs/config.d/zookeeper.yaml
@@ -0,0 +1,5 @@
+zookeeper:
+  node:
+    host: localhost
+    port: 9181
+    "@index": 1
diff --git a/tests/integration/test_config_xml_main/configs/config.xml b/tests/integration/test_config_xml_main/configs/config.xml
new file mode 100644
index 000000000000..3b5dab50ffe0
--- /dev/null
+++ b/tests/integration/test_config_xml_main/configs/config.xml
@@ -0,0 +1,277 @@
+<?xml version="1.0"?>
+<yandex>
+    <logger>
+        <level>trace</level>
+        <log>/var/log/clickhouse-server/clickhouse-server.log</log>
+        <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>
+        <size>1000M</size>
+        <count>10</count>
+    </logger>
+    <http_port>8123</http_port>
+    <tcp_port>9000</tcp_port>
+    <mysql_port>9004</mysql_port>
+    <postgresql_port>9005</postgresql_port>
+    <interserver_http_port>9009</interserver_http_port>
+    <max_connections>4096</max_connections>
+    <keep_alive_timeout>3</keep_alive_timeout>
+    <grpc>
+        <enable_ssl>false</enable_ssl>
+        <ssl_cert_file>/path/to/ssl_cert_file</ssl_cert_file>
+        <ssl_key_file>/path/to/ssl_key_file</ssl_key_file>
+        <ssl_require_client_auth>false</ssl_require_client_auth>
+        <ssl_ca_cert_file>/path/to/ssl_ca_cert_file</ssl_ca_cert_file>
+        <compression>deflate</compression>
+        <compression_level>medium</compression_level>
+        <max_send_message_size>-1</max_send_message_size>
+        <max_receive_message_size>-1</max_receive_message_size>
+        <verbose_logs>false</verbose_logs>
+    </grpc>
+    <openSSL>
+        <server> 
+            <certificateFile>/etc/clickhouse-server/server.crt</certificateFile>
+            <privateKeyFile>/etc/clickhouse-server/server.key</privateKeyFile>
+            <dhParamsFile>/etc/clickhouse-server/dhparam.pem</dhParamsFile>
+            <verificationMode>none</verificationMode>
+            <loadDefaultCAFile>true</loadDefaultCAFile>
+            <cacheSessions>true</cacheSessions>
+            <disableProtocols>sslv2,sslv3</disableProtocols>
+            <preferServerCiphers>true</preferServerCiphers>
+        </server>
+
+        <client>
+            <loadDefaultCAFile>true</loadDefaultCAFile>
+            <cacheSessions>true</cacheSessions>
+            <disableProtocols>sslv2,sslv3</disableProtocols>
+            <preferServerCiphers>true</preferServerCiphers>
+            <invalidCertificateHandler>
+                <name>RejectCertificateHandler</name>
+            </invalidCertificateHandler>
+        </client>
+    </openSSL>
+    <max_concurrent_queries>100</max_concurrent_queries>
+    <max_server_memory_usage>0</max_server_memory_usage>
+    <max_thread_pool_size>10000</max_thread_pool_size>
+
+    <max_server_memory_usage_to_ram_ratio>0.9</max_server_memory_usage_to_ram_ratio>
+
+    <total_memory_profiler_step>4194304</total_memory_profiler_step>
+
+    <total_memory_tracker_sample_probability>0</total_memory_tracker_sample_probability>
+
+    <uncompressed_cache_size>8589934592</uncompressed_cache_size>
+
+    <mark_cache_size>5368709120</mark_cache_size>
+
+    <mmap_cache_size>1000</mmap_cache_size>
+
+    <path>/var/lib/clickhouse/</path>
+
+    <tmp_path>/var/lib/clickhouse/tmp/</tmp_path>
+    <user_files_path>/var/lib/clickhouse/user_files/</user_files_path>
+    <ldap_servers>
+    </ldap_servers>
+    <user_directories>
+        <users_xml>
+            <path>users.xml</path>
+        </users_xml>
+        <local_directory>
+            <path>/var/lib/clickhouse/access/</path>
+        </local_directory>
+    </user_directories>
+    <default_profile>default</default_profile>
+    <custom_settings_prefixes></custom_settings_prefixes>
+    <default_database>default</default_database>
+    <mlock_executable>true</mlock_executable>
+
+    <remap_executable>false</remap_executable>
+    <remote_servers>
+        <test_shard_localhost>
+            <shard>
+                <replica>
+                    <host>localhost</host>
+                    <port>9000</port>
+                </replica>
+            </shard>
+        </test_shard_localhost>
+        <test_cluster_two_shards_localhost>
+             <shard>
+                 <replica>
+                     <host>localhost</host>
+                     <port>9000</port>
+                 </replica>
+             </shard>
+             <shard>
+                 <replica>
+                     <host>localhost</host>
+                     <port>9000</port>
+                 </replica>
+             </shard>
+        </test_cluster_two_shards_localhost>
+        <test_cluster_two_shards>
+            <shard>
+                <replica>
+                    <host>127.0.0.1</host>
+                    <port>9000</port>
+                </replica>
+            </shard>
+            <shard>
+                <replica>
+                    <host>127.0.0.2</host>
+                    <port>9000</port>
+                </replica>
+            </shard>
+        </test_cluster_two_shards>
+        <test_cluster_two_shards_internal_replication>
+            <shard>
+                <internal_replication>true</internal_replication>
+                <replica>
+                    <host>127.0.0.1</host>
+                    <port>9000</port>
+                </replica>
+            </shard>
+            <shard>
+                <internal_replication>true</internal_replication>
+                <replica>
+                    <host>127.0.0.2</host>
+                    <port>9000</port>
+                </replica>
+            </shard>
+        </test_cluster_two_shards_internal_replication>
+        <test_shard_localhost_secure>
+            <shard>
+                <replica>
+                    <host>localhost</host>
+                    <port>9440</port>
+                    <secure>1</secure>
+                </replica>
+            </shard>
+        </test_shard_localhost_secure>
+        <test_unavailable_shard>
+            <shard>
+                <replica>
+                    <host>localhost</host>
+                    <port>9000</port>
+                </replica>
+            </shard>
+            <shard>
+                <replica>
+                    <host>localhost</host>
+                    <port>1</port>
+                </replica>
+            </shard>
+        </test_unavailable_shard>
+    </remote_servers>
+
+    <builtin_dictionaries_reload_interval>3600</builtin_dictionaries_reload_interval>
+
+    <max_session_timeout>3600</max_session_timeout>
+
+    <default_session_timeout>60</default_session_timeout>
+
+    <query_log>
+        <database>system</database>
+        <table>query_log</table>
+        
+        <partition_by>toYYYYMM(event_date)</partition_by>
+        
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+    </query_log>
+
+    <trace_log>
+        <database>system</database>
+        <table>trace_log</table>
+
+        <partition_by>toYYYYMM(event_date)</partition_by>
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+    </trace_log>
+
+    <query_thread_log>
+        <database>system</database>
+        <table>query_thread_log</table>
+        <partition_by>toYYYYMM(event_date)</partition_by>
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+    </query_thread_log>
+
+    <metric_log>
+        <database>system</database>
+        <table>metric_log</table>
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+        <collect_interval_milliseconds>1000</collect_interval_milliseconds>
+    </metric_log>
+
+    <asynchronous_metric_log>
+        <database>system</database>
+        <table>asynchronous_metric_log</table>
+
+        <flush_interval_milliseconds>60000</flush_interval_milliseconds>
+    </asynchronous_metric_log>
+
+    <opentelemetry_span_log>
+        <engine>
+            engine MergeTree
+            partition by toYYYYMM(finish_date)
+            order by (finish_date, finish_time_us, trace_id)
+        </engine>
+        <database>system</database>
+        <table>opentelemetry_span_log</table>
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+    </opentelemetry_span_log>
+
+    <crash_log>
+        <database>system</database>
+        <table>crash_log</table>
+
+        <partition_by />
+        <flush_interval_milliseconds>1000</flush_interval_milliseconds>
+    </crash_log>
+
+    <top_level_domains_lists>
+    </top_level_domains_lists>
+
+    <dictionaries_config>*_dictionary.xml</dictionaries_config>
+    <distributed_ddl>
+        <path>/clickhouse/task_queue/ddl</path>
+    </distributed_ddl>
+    <graphite_rollup_example>
+        <pattern>
+            <regexp>click_cost</regexp>
+            <function>any</function>
+            <retention>
+                <age>0</age>
+                <precision>3600</precision>
+            </retention>
+            <retention>
+                <age>86400</age>
+                <precision>60</precision>
+            </retention>
+        </pattern>
+        <default>
+            <function>max</function>
+            <retention>
+                <age>0</age>
+                <precision>60</precision>
+            </retention>
+            <retention>
+                <age>3600</age>
+                <precision>300</precision>
+            </retention>
+            <retention>
+                <age>86400</age>
+                <precision>3600</precision>
+            </retention>
+        </default>
+    </graphite_rollup_example>
+    <format_schema_path>/var/lib/clickhouse/format_schemas/</format_schema_path>
+    <query_masking_rules>
+        <rule>
+            <name>hide encrypt/decrypt arguments</name>
+            <regexp>((?:aes_)?(?:encrypt|decrypt)(?:_mysql)?)\s*\(\s*(?:'(?:\\'|.)+'|.*?)\s*\)</regexp>
+            <replace>\1(???)</replace>
+        </rule>
+    </query_masking_rules>
+    <send_crash_reports>
+        <enabled>false</enabled>
+        <anonymize>false</anonymize>
+        <endpoint>https://6f33034cfe684dd7a3ab9875e57b1c8d@o388870.ingest.sentry.io/5226277</endpoint>
+    </send_crash_reports>
+</yandex>
diff --git a/tests/integration/test_config_xml_main/configs/embedded.xml b/tests/integration/test_config_xml_main/configs/embedded.xml
new file mode 100644
index 000000000000..a66f57d1eb70
--- /dev/null
+++ b/tests/integration/test_config_xml_main/configs/embedded.xml
@@ -0,0 +1,40 @@
+<?xml version="1.0"?>
+<!-- Config that is used when server is run without config file. -->
+<yandex>
+    <logger>
+        <level>trace</level>
+        <console>true</console>
+    </logger>
+
+    <http_port>8123</http_port>
+    <tcp_port>9000</tcp_port>
+    <mysql_port>9004</mysql_port>
+
+    <path>./</path>
+
+    <uncompressed_cache_size>8589934592</uncompressed_cache_size>
+    <mark_cache_size>5368709120</mark_cache_size>
+    <mlock_executable>true</mlock_executable>
+
+    <users>
+        <default>
+            <password></password>
+
+            <networks>
+                <ip>::/0</ip>
+            </networks>
+
+            <profile>default</profile>
+            <quota>default</quota>
+            <access_management>1</access_management>
+        </default>
+    </users>
+
+    <profiles>
+        <default/>
+    </profiles>
+
+    <quotas>
+        <default />
+    </quotas>
+</yandex>
diff --git a/tests/integration/test_config_xml_main/configs/users.d/allow_introspection_functions.yaml b/tests/integration/test_config_xml_main/configs/users.d/allow_introspection_functions.yaml
new file mode 100644
index 000000000000..84612c198c9d
--- /dev/null
+++ b/tests/integration/test_config_xml_main/configs/users.d/allow_introspection_functions.yaml
@@ -0,0 +1,3 @@
+profiles:
+  default:
+    allow_introspection_functions: 1
diff --git a/tests/integration/test_config_xml_main/configs/users.d/log_queries.yaml b/tests/integration/test_config_xml_main/configs/users.d/log_queries.yaml
new file mode 100644
index 000000000000..88574e8f764c
--- /dev/null
+++ b/tests/integration/test_config_xml_main/configs/users.d/log_queries.yaml
@@ -0,0 +1,3 @@
+profiles:
+  default:
+    log_queries: 1
diff --git a/tests/integration/test_config_xml_main/configs/users.xml b/tests/integration/test_config_xml_main/configs/users.xml
new file mode 100644
index 000000000000..b473413bdfab
--- /dev/null
+++ b/tests/integration/test_config_xml_main/configs/users.xml
@@ -0,0 +1,19 @@
+<?xml version="1.0"?>
+<yandex>
+    <profiles>
+        <default>
+            <max_memory_usage>10000000000</max_memory_usage>
+            <max_block_size>64999</max_block_size>
+        </default>
+    </profiles>
+
+    <users>
+        <default>
+            <password></password>
+            <networks replace="replace">
+                <ip>::/0</ip>
+            </networks>
+            <profile>default</profile>
+        </default>
+    </users>
+</yandex>
diff --git a/tests/integration/test_config_xml_main/test.py b/tests/integration/test_config_xml_main/test.py
new file mode 100644
index 000000000000..052f9adb01f8
--- /dev/null
+++ b/tests/integration/test_config_xml_main/test.py
@@ -0,0 +1,43 @@
+
+
+import time
+import threading
+from os import path as p, unlink
+from tempfile import NamedTemporaryFile
+
+import helpers
+import pytest
+from helpers.cluster import ClickHouseCluster
+
+
+def test_xml_main_conf():
+    # main configs are in XML; config.d and users.d are in YAML
+    cluster = ClickHouseCluster(__file__, zookeeper_config_path='configs/config.d/zookeeper.yaml')
+
+    all_confd = ['configs/config.d/access_control.yaml',
+                'configs/config.d/keeper_port.yaml',
+                'configs/config.d/logging_no_rotate.yaml',
+                'configs/config.d/log_to_console.yaml',
+                'configs/config.d/macros.yaml',
+                'configs/config.d/metric_log.yaml',
+                'configs/config.d/more_clusters.yaml',
+                'configs/config.d/part_log.yaml',
+                'configs/config.d/path.yaml',
+                'configs/config.d/query_masking_rules.yaml',
+                'configs/config.d/tcp_with_proxy.yaml',
+                'configs/config.d/test_cluster_with_incorrect_pw.yaml',
+                'configs/config.d/text_log.yaml',
+                'configs/config.d/zookeeper.yaml']
+
+    all_userd = ['configs/users.d/allow_introspection_functions.yaml',
+                'configs/users.d/log_queries.yaml']
+
+    node = cluster.add_instance('node', base_config_dir='configs', main_configs=all_confd, user_configs=all_userd, with_zookeeper=False)
+
+    try:
+        cluster.start()
+        assert(node.query("select value from system.settings where name = 'max_memory_usage'") == "10000000000
")
+        assert(node.query("select value from system.settings where name = 'max_block_size'") == "64999
")
+
+    finally:
+        cluster.shutdown()
diff --git a/tests/integration/test_config_xml_yaml_mix/__init__.py b/tests/integration/test_config_xml_yaml_mix/__init__.py
new file mode 100644
index 000000000000..e69de29bb2d1
diff --git a/tests/integration/test_config_xml_yaml_mix/configs/config.d/0_common_instance_config.yaml b/tests/integration/test_config_xml_yaml_mix/configs/config.d/0_common_instance_config.yaml
new file mode 100644
index 000000000000..62e4ba8c7442
--- /dev/null
+++ b/tests/integration/test_config_xml_yaml_mix/configs/config.d/0_common_instance_config.yaml
@@ -0,0 +1,6 @@
+timezone: Europe/Moscow
+listen_host: 0.0.0.0
+custom_settings_prefixes: custom_
+path: /var/lib/clickhouse/
+tmp_path: /var/lib/clickhouse/tmp/
+users_config: users.yaml
diff --git a/tests/integration/test_config_xml_yaml_mix/configs/config.d/access_control.yaml b/tests/integration/test_config_xml_yaml_mix/configs/config.d/access_control.yaml
new file mode 100644
index 000000000000..ce2e23839ef3
--- /dev/null
+++ b/tests/integration/test_config_xml_yaml_mix/configs/config.d/access_control.yaml
@@ -0,0 +1,7 @@
+user_directories:
+  users_xml:
+    path: users.yaml
+  local_directory:
+    path: access/
+  "@replace": replace
+
diff --git a/tests/integration/test_config_xml_yaml_mix/configs/config.d/keeper_port.xml b/tests/integration/test_config_xml_yaml_mix/configs/config.d/keeper_port.xml
new file mode 100644
index 000000000000..b21df47bc850
--- /dev/null
+++ b/tests/integration/test_config_xml_yaml_mix/configs/config.d/keeper_port.xml
@@ -0,0 +1,23 @@
+<yandex>
+    <keeper_server>
+        <tcp_port>9181</tcp_port>
+        <server_id>1</server_id>
+
+        <coordination_settings>
+            <operation_timeout_ms>10000</operation_timeout_ms>
+            <session_timeout_ms>30000</session_timeout_ms>
+            <force_sync>false</force_sync>
+            <startup_timeout>60000</startup_timeout>
+            <!-- we want all logs for complex problems investigation -->
+            <reserved_log_items>1000000000000000</reserved_log_items>
+        </coordination_settings>
+
+        <raft_configuration>
+            <server>
+                <id>1</id>
+                <hostname>localhost</hostname>
+                <port>44444</port>
+            </server>
+        </raft_configuration>
+    </keeper_server>
+</yandex>
diff --git a/tests/integration/test_config_xml_yaml_mix/configs/config.d/log_to_console.yaml b/tests/integration/test_config_xml_yaml_mix/configs/config.d/log_to_console.yaml
new file mode 100644
index 000000000000..7b59339800b9
--- /dev/null
+++ b/tests/integration/test_config_xml_yaml_mix/configs/config.d/log_to_console.yaml
@@ -0,0 +1,7 @@
+logger:
+  console: true
+  log:
+    "@remove": remove
+  errorlog:
+    "@remove": remove
+
diff --git a/tests/integration/test_config_xml_yaml_mix/configs/config.d/logging_no_rotate.xml b/tests/integration/test_config_xml_yaml_mix/configs/config.d/logging_no_rotate.xml
new file mode 100644
index 000000000000..2c34585437bf
--- /dev/null
+++ b/tests/integration/test_config_xml_yaml_mix/configs/config.d/logging_no_rotate.xml
@@ -0,0 +1,8 @@
+<yandex>
+    <logger>
+        <!-- Disable rotation
+             https://pocoproject.org/docs/Poco.FileChannel.html
+        -->
+        <size>never</size>
+    </logger>
+</yandex>
diff --git a/tests/integration/test_config_xml_yaml_mix/configs/config.d/macros.yaml b/tests/integration/test_config_xml_yaml_mix/configs/config.d/macros.yaml
new file mode 100644
index 000000000000..a9c61e270ab3
--- /dev/null
+++ b/tests/integration/test_config_xml_yaml_mix/configs/config.d/macros.yaml
@@ -0,0 +1,7 @@
+macros:
+  test: 'Hello, world!'
+  shard: s1
+  replica: r1
+  default_path_test: '/clickhouse/tables/{database}/{shard}/'
+  default_name_test: 'table_{table}'
+
diff --git a/tests/integration/test_config_xml_yaml_mix/configs/config.d/metric_log.xml b/tests/integration/test_config_xml_yaml_mix/configs/config.d/metric_log.xml
new file mode 100644
index 000000000000..0ca9f1624169
--- /dev/null
+++ b/tests/integration/test_config_xml_yaml_mix/configs/config.d/metric_log.xml
@@ -0,0 +1,8 @@
+<yandex>
+    <metric_log>
+        <database>system</database>
+        <table>metric_log</table>
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+        <collect_interval_milliseconds>1000</collect_interval_milliseconds>
+    </metric_log>
+</yandex>
diff --git a/tests/integration/test_config_xml_yaml_mix/configs/config.d/more_clusters.yaml b/tests/integration/test_config_xml_yaml_mix/configs/config.d/more_clusters.yaml
new file mode 100644
index 000000000000..7da071908945
--- /dev/null
+++ b/tests/integration/test_config_xml_yaml_mix/configs/config.d/more_clusters.yaml
@@ -0,0 +1,23 @@
+remote_servers:
+  single_remote_shard_at_port_9001:
+    shard:
+      replica:
+        host: localhost
+        port: 9001
+  two_remote_shards_at_port_9001_9002:
+    shard:
+      - replica:
+          host: localhost
+          port: 9001
+      - replica:
+          host: localhost
+          port: 9002
+  two_shards_one_local_one_remote_at_port_9001:
+    shard:
+      - replica:
+          host: localhost
+          port: 9000
+      - replica:
+          host: localhost
+          port: 9001
+
diff --git a/tests/integration/test_config_xml_yaml_mix/configs/config.d/part_log.xml b/tests/integration/test_config_xml_yaml_mix/configs/config.d/part_log.xml
new file mode 100644
index 000000000000..6c6fc9c69823
--- /dev/null
+++ b/tests/integration/test_config_xml_yaml_mix/configs/config.d/part_log.xml
@@ -0,0 +1,8 @@
+<yandex>
+    <part_log>
+        <database>system</database>
+        <table>part_log</table>
+
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+    </part_log>
+</yandex>
diff --git a/tests/integration/test_config_xml_yaml_mix/configs/config.d/path.yaml b/tests/integration/test_config_xml_yaml_mix/configs/config.d/path.yaml
new file mode 100644
index 000000000000..3e26e8906eef
--- /dev/null
+++ b/tests/integration/test_config_xml_yaml_mix/configs/config.d/path.yaml
@@ -0,0 +1,18 @@
+path:
+  - ./
+  - "@replace": replace
+tmp_path:
+  - ./tmp/
+  - "@replace": replace
+user_files_path:
+  - ./user_files/
+  - "@replace": replace
+format_schema_path:
+  - ./format_schemas/
+  - "@replace": replace
+access_control_path:
+  - ./access/
+  - "@replace": replace
+top_level_domains_path:
+  - ./top_level_domains/
+  - "@replace": replace
diff --git a/tests/integration/test_config_xml_yaml_mix/configs/config.d/query_masking_rules.xml b/tests/integration/test_config_xml_yaml_mix/configs/config.d/query_masking_rules.xml
new file mode 100644
index 000000000000..5a854848f3d7
--- /dev/null
+++ b/tests/integration/test_config_xml_yaml_mix/configs/config.d/query_masking_rules.xml
@@ -0,0 +1,10 @@
+<?xml version="1.0"?>
+<!-- Config for test server -->
+<yandex>
+    <query_masking_rules>
+        <rule>
+            <regexp>TOPSECRET.TOPSECRET</regexp>
+            <replace>[hidden]</replace>
+        </rule>
+    </query_masking_rules>
+</yandex>
diff --git a/tests/integration/test_config_xml_yaml_mix/configs/config.d/tcp_with_proxy.yaml b/tests/integration/test_config_xml_yaml_mix/configs/config.d/tcp_with_proxy.yaml
new file mode 100644
index 000000000000..b0349f5a9b99
--- /dev/null
+++ b/tests/integration/test_config_xml_yaml_mix/configs/config.d/tcp_with_proxy.yaml
@@ -0,0 +1,1 @@
+tcp_with_proxy_port: 9010
diff --git a/tests/integration/test_config_xml_yaml_mix/configs/config.d/test_cluster_with_incorrect_pw.xml b/tests/integration/test_config_xml_yaml_mix/configs/config.d/test_cluster_with_incorrect_pw.xml
new file mode 100644
index 000000000000..109e35afc37b
--- /dev/null
+++ b/tests/integration/test_config_xml_yaml_mix/configs/config.d/test_cluster_with_incorrect_pw.xml
@@ -0,0 +1,21 @@
+<yandex>
+    <remote_servers>
+        <test_cluster_with_incorrect_pw>
+             <shard>
+                 <internal_replication>true</internal_replication>
+                 <replica>
+                     <host>127.0.0.1</host>
+                     <port>9000</port>
+                     <!-- password is incorrect -->
+                     <password>foo</password>
+                 </replica>
+                 <replica>
+                     <host>127.0.0.2</host>
+                     <port>9000</port>
+                     <!-- password is incorrect -->
+                     <password>foo</password>
+                 </replica>
+             </shard>
+         </test_cluster_with_incorrect_pw>
+    </remote_servers>
+</yandex>
diff --git a/tests/integration/test_config_xml_yaml_mix/configs/config.d/text_log.yaml b/tests/integration/test_config_xml_yaml_mix/configs/config.d/text_log.yaml
new file mode 100644
index 000000000000..4d188020e374
--- /dev/null
+++ b/tests/integration/test_config_xml_yaml_mix/configs/config.d/text_log.yaml
@@ -0,0 +1,4 @@
+text_log:
+  database: system
+  table: text_log
+  flush_interval_milliseconds: 7500
diff --git a/tests/integration/test_config_xml_yaml_mix/configs/config.d/zookeeper.xml b/tests/integration/test_config_xml_yaml_mix/configs/config.d/zookeeper.xml
new file mode 100644
index 000000000000..06ed7fcd39f3
--- /dev/null
+++ b/tests/integration/test_config_xml_yaml_mix/configs/config.d/zookeeper.xml
@@ -0,0 +1,8 @@
+<yandex>
+    <zookeeper>
+        <node index="1">
+            <host>localhost</host>
+            <port>9181</port>
+        </node>
+    </zookeeper>
+</yandex>
diff --git a/tests/integration/test_config_xml_yaml_mix/configs/config.xml b/tests/integration/test_config_xml_yaml_mix/configs/config.xml
new file mode 100644
index 000000000000..e6a2b6d53245
--- /dev/null
+++ b/tests/integration/test_config_xml_yaml_mix/configs/config.xml
@@ -0,0 +1,277 @@
+<?xml version="1.0"?>
+<yandex>
+    <logger>
+        <level>trace</level>
+        <log>/var/log/clickhouse-server/clickhouse-server.log</log>
+        <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>
+        <size>1000M</size>
+        <count>10</count>
+    </logger>
+    <http_port>8123</http_port>
+    <tcp_port>9000</tcp_port>
+    <mysql_port>9004</mysql_port>
+    <postgresql_port>9005</postgresql_port>
+    <interserver_http_port>9009</interserver_http_port>
+    <max_connections>4096</max_connections>
+    <keep_alive_timeout>3</keep_alive_timeout>
+    <grpc>
+        <enable_ssl>false</enable_ssl>
+        <ssl_cert_file>/path/to/ssl_cert_file</ssl_cert_file>
+        <ssl_key_file>/path/to/ssl_key_file</ssl_key_file>
+        <ssl_require_client_auth>false</ssl_require_client_auth>
+        <ssl_ca_cert_file>/path/to/ssl_ca_cert_file</ssl_ca_cert_file>
+        <compression>deflate</compression>
+        <compression_level>medium</compression_level>
+        <max_send_message_size>-1</max_send_message_size>
+        <max_receive_message_size>-1</max_receive_message_size>
+        <verbose_logs>false</verbose_logs>
+    </grpc>
+    <openSSL>
+        <server> 
+            <certificateFile>/etc/clickhouse-server/server.crt</certificateFile>
+            <privateKeyFile>/etc/clickhouse-server/server.key</privateKeyFile>
+            <dhParamsFile>/etc/clickhouse-server/dhparam.pem</dhParamsFile>
+            <verificationMode>none</verificationMode>
+            <loadDefaultCAFile>true</loadDefaultCAFile>
+            <cacheSessions>true</cacheSessions>
+            <disableProtocols>sslv2,sslv3</disableProtocols>
+            <preferServerCiphers>true</preferServerCiphers>
+        </server>
+
+        <client>
+            <loadDefaultCAFile>true</loadDefaultCAFile>
+            <cacheSessions>true</cacheSessions>
+            <disableProtocols>sslv2,sslv3</disableProtocols>
+            <preferServerCiphers>true</preferServerCiphers>
+            <invalidCertificateHandler>
+                <name>RejectCertificateHandler</name>
+            </invalidCertificateHandler>
+        </client>
+    </openSSL>
+    <max_concurrent_queries>100</max_concurrent_queries>
+    <max_server_memory_usage>0</max_server_memory_usage>
+    <max_thread_pool_size>10000</max_thread_pool_size>
+
+    <max_server_memory_usage_to_ram_ratio>0.9</max_server_memory_usage_to_ram_ratio>
+
+    <total_memory_profiler_step>4194304</total_memory_profiler_step>
+
+    <total_memory_tracker_sample_probability>0</total_memory_tracker_sample_probability>
+
+    <uncompressed_cache_size>8589934592</uncompressed_cache_size>
+
+    <mark_cache_size>5368709120</mark_cache_size>
+
+    <mmap_cache_size>1000</mmap_cache_size>
+
+    <path>/var/lib/clickhouse/</path>
+
+    <tmp_path>/var/lib/clickhouse/tmp/</tmp_path>
+    <user_files_path>/var/lib/clickhouse/user_files/</user_files_path>
+    <ldap_servers>
+    </ldap_servers>
+    <user_directories>
+        <users_xml>
+            <path>users.yaml</path>
+        </users_xml>
+        <local_directory>
+            <path>/var/lib/clickhouse/access/</path>
+        </local_directory>
+    </user_directories>
+    <default_profile>default</default_profile>
+    <custom_settings_prefixes></custom_settings_prefixes>
+    <default_database>default</default_database>
+    <mlock_executable>true</mlock_executable>
+
+    <remap_executable>false</remap_executable>
+    <remote_servers>
+        <test_shard_localhost>
+            <shard>
+                <replica>
+                    <host>localhost</host>
+                    <port>9000</port>
+                </replica>
+            </shard>
+        </test_shard_localhost>
+        <test_cluster_two_shards_localhost>
+             <shard>
+                 <replica>
+                     <host>localhost</host>
+                     <port>9000</port>
+                 </replica>
+             </shard>
+             <shard>
+                 <replica>
+                     <host>localhost</host>
+                     <port>9000</port>
+                 </replica>
+             </shard>
+        </test_cluster_two_shards_localhost>
+        <test_cluster_two_shards>
+            <shard>
+                <replica>
+                    <host>127.0.0.1</host>
+                    <port>9000</port>
+                </replica>
+            </shard>
+            <shard>
+                <replica>
+                    <host>127.0.0.2</host>
+                    <port>9000</port>
+                </replica>
+            </shard>
+        </test_cluster_two_shards>
+        <test_cluster_two_shards_internal_replication>
+            <shard>
+                <internal_replication>true</internal_replication>
+                <replica>
+                    <host>127.0.0.1</host>
+                    <port>9000</port>
+                </replica>
+            </shard>
+            <shard>
+                <internal_replication>true</internal_replication>
+                <replica>
+                    <host>127.0.0.2</host>
+                    <port>9000</port>
+                </replica>
+            </shard>
+        </test_cluster_two_shards_internal_replication>
+        <test_shard_localhost_secure>
+            <shard>
+                <replica>
+                    <host>localhost</host>
+                    <port>9440</port>
+                    <secure>1</secure>
+                </replica>
+            </shard>
+        </test_shard_localhost_secure>
+        <test_unavailable_shard>
+            <shard>
+                <replica>
+                    <host>localhost</host>
+                    <port>9000</port>
+                </replica>
+            </shard>
+            <shard>
+                <replica>
+                    <host>localhost</host>
+                    <port>1</port>
+                </replica>
+            </shard>
+        </test_unavailable_shard>
+    </remote_servers>
+
+    <builtin_dictionaries_reload_interval>3600</builtin_dictionaries_reload_interval>
+
+    <max_session_timeout>3600</max_session_timeout>
+
+    <default_session_timeout>60</default_session_timeout>
+
+    <query_log>
+        <database>system</database>
+        <table>query_log</table>
+        
+        <partition_by>toYYYYMM(event_date)</partition_by>
+        
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+    </query_log>
+
+    <trace_log>
+        <database>system</database>
+        <table>trace_log</table>
+
+        <partition_by>toYYYYMM(event_date)</partition_by>
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+    </trace_log>
+
+    <query_thread_log>
+        <database>system</database>
+        <table>query_thread_log</table>
+        <partition_by>toYYYYMM(event_date)</partition_by>
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+    </query_thread_log>
+
+    <metric_log>
+        <database>system</database>
+        <table>metric_log</table>
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+        <collect_interval_milliseconds>1000</collect_interval_milliseconds>
+    </metric_log>
+
+    <asynchronous_metric_log>
+        <database>system</database>
+        <table>asynchronous_metric_log</table>
+
+        <flush_interval_milliseconds>60000</flush_interval_milliseconds>
+    </asynchronous_metric_log>
+
+    <opentelemetry_span_log>
+        <engine>
+            engine MergeTree
+            partition by toYYYYMM(finish_date)
+            order by (finish_date, finish_time_us, trace_id)
+        </engine>
+        <database>system</database>
+        <table>opentelemetry_span_log</table>
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+    </opentelemetry_span_log>
+
+    <crash_log>
+        <database>system</database>
+        <table>crash_log</table>
+
+        <partition_by />
+        <flush_interval_milliseconds>1000</flush_interval_milliseconds>
+    </crash_log>
+
+    <top_level_domains_lists>
+    </top_level_domains_lists>
+
+    <dictionaries_config>*_dictionary.xml</dictionaries_config>
+    <distributed_ddl>
+        <path>/clickhouse/task_queue/ddl</path>
+    </distributed_ddl>
+    <graphite_rollup_example>
+        <pattern>
+            <regexp>click_cost</regexp>
+            <function>any</function>
+            <retention>
+                <age>0</age>
+                <precision>3600</precision>
+            </retention>
+            <retention>
+                <age>86400</age>
+                <precision>60</precision>
+            </retention>
+        </pattern>
+        <default>
+            <function>max</function>
+            <retention>
+                <age>0</age>
+                <precision>60</precision>
+            </retention>
+            <retention>
+                <age>3600</age>
+                <precision>300</precision>
+            </retention>
+            <retention>
+                <age>86400</age>
+                <precision>3600</precision>
+            </retention>
+        </default>
+    </graphite_rollup_example>
+    <format_schema_path>/var/lib/clickhouse/format_schemas/</format_schema_path>
+    <query_masking_rules>
+        <rule>
+            <name>hide encrypt/decrypt arguments</name>
+            <regexp>((?:aes_)?(?:encrypt|decrypt)(?:_mysql)?)\s*\(\s*(?:'(?:\\'|.)+'|.*?)\s*\)</regexp>
+            <replace>\1(???)</replace>
+        </rule>
+    </query_masking_rules>
+    <send_crash_reports>
+        <enabled>false</enabled>
+        <anonymize>false</anonymize>
+        <endpoint>https://6f33034cfe684dd7a3ab9875e57b1c8d@o388870.ingest.sentry.io/5226277</endpoint>
+    </send_crash_reports>
+</yandex>
diff --git a/tests/integration/test_config_xml_yaml_mix/configs/embedded.xml b/tests/integration/test_config_xml_yaml_mix/configs/embedded.xml
new file mode 100644
index 000000000000..a66f57d1eb70
--- /dev/null
+++ b/tests/integration/test_config_xml_yaml_mix/configs/embedded.xml
@@ -0,0 +1,40 @@
+<?xml version="1.0"?>
+<!-- Config that is used when server is run without config file. -->
+<yandex>
+    <logger>
+        <level>trace</level>
+        <console>true</console>
+    </logger>
+
+    <http_port>8123</http_port>
+    <tcp_port>9000</tcp_port>
+    <mysql_port>9004</mysql_port>
+
+    <path>./</path>
+
+    <uncompressed_cache_size>8589934592</uncompressed_cache_size>
+    <mark_cache_size>5368709120</mark_cache_size>
+    <mlock_executable>true</mlock_executable>
+
+    <users>
+        <default>
+            <password></password>
+
+            <networks>
+                <ip>::/0</ip>
+            </networks>
+
+            <profile>default</profile>
+            <quota>default</quota>
+            <access_management>1</access_management>
+        </default>
+    </users>
+
+    <profiles>
+        <default/>
+    </profiles>
+
+    <quotas>
+        <default />
+    </quotas>
+</yandex>
diff --git a/tests/integration/test_config_xml_yaml_mix/configs/users.d/allow_introspection_functions.xml b/tests/integration/test_config_xml_yaml_mix/configs/users.d/allow_introspection_functions.xml
new file mode 100644
index 000000000000..b94e95bc043d
--- /dev/null
+++ b/tests/integration/test_config_xml_yaml_mix/configs/users.d/allow_introspection_functions.xml
@@ -0,0 +1,8 @@
+<?xml version="1.0"?>
+<yandex>
+    <profiles>
+        <default>
+            <allow_introspection_functions>1</allow_introspection_functions>
+        </default>
+    </profiles>
+</yandex>
diff --git a/tests/integration/test_config_xml_yaml_mix/configs/users.d/log_queries.yaml b/tests/integration/test_config_xml_yaml_mix/configs/users.d/log_queries.yaml
new file mode 100644
index 000000000000..88574e8f764c
--- /dev/null
+++ b/tests/integration/test_config_xml_yaml_mix/configs/users.d/log_queries.yaml
@@ -0,0 +1,3 @@
+profiles:
+  default:
+    log_queries: 1
diff --git a/tests/integration/test_config_xml_yaml_mix/configs/users.yaml b/tests/integration/test_config_xml_yaml_mix/configs/users.yaml
new file mode 100644
index 000000000000..a87a8c828191
--- /dev/null
+++ b/tests/integration/test_config_xml_yaml_mix/configs/users.yaml
@@ -0,0 +1,12 @@
+profiles:
+  default:
+    max_memory_usage: 10000000000
+    max_block_size: 64999
+users:
+  default:
+    password: ''
+    networks:
+      "@replace": replace
+      ip: '::/0'
+    profile: default
+
diff --git a/tests/integration/test_config_xml_yaml_mix/test.py b/tests/integration/test_config_xml_yaml_mix/test.py
new file mode 100644
index 000000000000..90ee8a2dea58
--- /dev/null
+++ b/tests/integration/test_config_xml_yaml_mix/test.py
@@ -0,0 +1,43 @@
+import time
+import threading
+from os import path as p, unlink
+from tempfile import NamedTemporaryFile
+
+import helpers
+import pytest
+from helpers.cluster import ClickHouseCluster
+
+
+def test_extra_yaml_mix():
+    # some configs are written in XML, others are written in YAML
+    cluster = ClickHouseCluster(__file__, zookeeper_config_path='configs/config.d/zookeeper.xml')
+
+    all_confd = ['configs/config.d/0_common_instance_config.yaml',
+                'configs/config.d/access_control.yaml',
+                'configs/config.d/keeper_port.xml',
+                'configs/config.d/logging_no_rotate.xml',
+                'configs/config.d/log_to_console.yaml',
+                'configs/config.d/macros.yaml',
+                'configs/config.d/metric_log.xml',
+                'configs/config.d/more_clusters.yaml',
+                'configs/config.d/part_log.xml',
+                'configs/config.d/path.yaml',
+                'configs/config.d/query_masking_rules.xml',
+                'configs/config.d/tcp_with_proxy.yaml',
+                'configs/config.d/test_cluster_with_incorrect_pw.xml',
+                'configs/config.d/text_log.yaml',
+                'configs/config.d/zookeeper.xml']
+
+    all_userd = ['configs/users.d/allow_introspection_functions.xml',
+                'configs/users.d/log_queries.yaml']
+
+    node = cluster.add_instance('node', base_config_dir='configs', main_configs=all_confd, user_configs=all_userd, with_zookeeper=False,
+    users_config_name="users.yaml", copy_common_configs=False)
+
+    try:
+        cluster.start()
+        assert(node.query("select value from system.settings where name = 'max_memory_usage'") == "10000000000
")
+        assert(node.query("select value from system.settings where name = 'max_block_size'") == "64999
")
+
+    finally:
+        cluster.shutdown()
diff --git a/tests/integration/test_config_yaml_full/__init__.py b/tests/integration/test_config_yaml_full/__init__.py
new file mode 100644
index 000000000000..e69de29bb2d1
diff --git a/tests/integration/test_config_yaml_full/configs/config.d/0_common_instance_config.yaml b/tests/integration/test_config_yaml_full/configs/config.d/0_common_instance_config.yaml
new file mode 100644
index 000000000000..62e4ba8c7442
--- /dev/null
+++ b/tests/integration/test_config_yaml_full/configs/config.d/0_common_instance_config.yaml
@@ -0,0 +1,6 @@
+timezone: Europe/Moscow
+listen_host: 0.0.0.0
+custom_settings_prefixes: custom_
+path: /var/lib/clickhouse/
+tmp_path: /var/lib/clickhouse/tmp/
+users_config: users.yaml
diff --git a/tests/integration/test_config_yaml_full/configs/config.d/access_control.yaml b/tests/integration/test_config_yaml_full/configs/config.d/access_control.yaml
new file mode 100644
index 000000000000..ce2e23839ef3
--- /dev/null
+++ b/tests/integration/test_config_yaml_full/configs/config.d/access_control.yaml
@@ -0,0 +1,7 @@
+user_directories:
+  users_xml:
+    path: users.yaml
+  local_directory:
+    path: access/
+  "@replace": replace
+
diff --git a/tests/integration/test_config_yaml_full/configs/config.d/keeper_port.yaml b/tests/integration/test_config_yaml_full/configs/config.d/keeper_port.yaml
new file mode 100644
index 000000000000..91723bc372f1
--- /dev/null
+++ b/tests/integration/test_config_yaml_full/configs/config.d/keeper_port.yaml
@@ -0,0 +1,15 @@
+keeper_server:
+  tcp_port: 9181
+  server_id: 1
+  coordination_settings:
+    operation_timeout_ms: 10000
+    session_timeout_ms: 30000
+    force_sync: false
+    startup_timeout: 60000
+    reserved_log_items: 1000000000000000
+  raft_configuration:
+    server:
+      id: 1
+      hostname: localhost
+      port: 44444
+
diff --git a/tests/integration/test_config_yaml_full/configs/config.d/log_to_console.yaml b/tests/integration/test_config_yaml_full/configs/config.d/log_to_console.yaml
new file mode 100644
index 000000000000..7b59339800b9
--- /dev/null
+++ b/tests/integration/test_config_yaml_full/configs/config.d/log_to_console.yaml
@@ -0,0 +1,7 @@
+logger:
+  console: true
+  log:
+    "@remove": remove
+  errorlog:
+    "@remove": remove
+
diff --git a/tests/integration/test_config_yaml_full/configs/config.d/logging_no_rotate.yaml b/tests/integration/test_config_yaml_full/configs/config.d/logging_no_rotate.yaml
new file mode 100644
index 000000000000..513cd3f7dc51
--- /dev/null
+++ b/tests/integration/test_config_yaml_full/configs/config.d/logging_no_rotate.yaml
@@ -0,0 +1,2 @@
+logger:
+  size: never
diff --git a/tests/integration/test_config_yaml_full/configs/config.d/macros.yaml b/tests/integration/test_config_yaml_full/configs/config.d/macros.yaml
new file mode 100644
index 000000000000..a9c61e270ab3
--- /dev/null
+++ b/tests/integration/test_config_yaml_full/configs/config.d/macros.yaml
@@ -0,0 +1,7 @@
+macros:
+  test: 'Hello, world!'
+  shard: s1
+  replica: r1
+  default_path_test: '/clickhouse/tables/{database}/{shard}/'
+  default_name_test: 'table_{table}'
+
diff --git a/tests/integration/test_config_yaml_full/configs/config.d/metric_log.yaml b/tests/integration/test_config_yaml_full/configs/config.d/metric_log.yaml
new file mode 100644
index 000000000000..aafad939c377
--- /dev/null
+++ b/tests/integration/test_config_yaml_full/configs/config.d/metric_log.yaml
@@ -0,0 +1,6 @@
+metric_log:
+  database: system
+  table: metric_log
+  flush_interval_milliseconds: 7500
+  collect_interval_milliseconds: 1000
+
diff --git a/tests/integration/test_config_yaml_full/configs/config.d/more_clusters.yaml b/tests/integration/test_config_yaml_full/configs/config.d/more_clusters.yaml
new file mode 100644
index 000000000000..7da071908945
--- /dev/null
+++ b/tests/integration/test_config_yaml_full/configs/config.d/more_clusters.yaml
@@ -0,0 +1,23 @@
+remote_servers:
+  single_remote_shard_at_port_9001:
+    shard:
+      replica:
+        host: localhost
+        port: 9001
+  two_remote_shards_at_port_9001_9002:
+    shard:
+      - replica:
+          host: localhost
+          port: 9001
+      - replica:
+          host: localhost
+          port: 9002
+  two_shards_one_local_one_remote_at_port_9001:
+    shard:
+      - replica:
+          host: localhost
+          port: 9000
+      - replica:
+          host: localhost
+          port: 9001
+
diff --git a/tests/integration/test_config_yaml_full/configs/config.d/part_log.yaml b/tests/integration/test_config_yaml_full/configs/config.d/part_log.yaml
new file mode 100644
index 000000000000..43f60146dca1
--- /dev/null
+++ b/tests/integration/test_config_yaml_full/configs/config.d/part_log.yaml
@@ -0,0 +1,5 @@
+part_log:
+  database: system
+  table: part_log
+  flush_interval_milliseconds: 7500
+
diff --git a/tests/integration/test_config_yaml_full/configs/config.d/path.yaml b/tests/integration/test_config_yaml_full/configs/config.d/path.yaml
new file mode 100644
index 000000000000..3e26e8906eef
--- /dev/null
+++ b/tests/integration/test_config_yaml_full/configs/config.d/path.yaml
@@ -0,0 +1,18 @@
+path:
+  - ./
+  - "@replace": replace
+tmp_path:
+  - ./tmp/
+  - "@replace": replace
+user_files_path:
+  - ./user_files/
+  - "@replace": replace
+format_schema_path:
+  - ./format_schemas/
+  - "@replace": replace
+access_control_path:
+  - ./access/
+  - "@replace": replace
+top_level_domains_path:
+  - ./top_level_domains/
+  - "@replace": replace
diff --git a/tests/integration/test_config_yaml_full/configs/config.d/query_masking_rules.yaml b/tests/integration/test_config_yaml_full/configs/config.d/query_masking_rules.yaml
new file mode 100644
index 000000000000..38163429d810
--- /dev/null
+++ b/tests/integration/test_config_yaml_full/configs/config.d/query_masking_rules.yaml
@@ -0,0 +1,4 @@
+query_masking_rules:
+  rule:
+    regexp: TOPSECRET.TOPSECRET
+    replace: '[hidden]'
diff --git a/tests/integration/test_config_yaml_full/configs/config.d/tcp_with_proxy.yaml b/tests/integration/test_config_yaml_full/configs/config.d/tcp_with_proxy.yaml
new file mode 100644
index 000000000000..b0349f5a9b99
--- /dev/null
+++ b/tests/integration/test_config_yaml_full/configs/config.d/tcp_with_proxy.yaml
@@ -0,0 +1,1 @@
+tcp_with_proxy_port: 9010
diff --git a/tests/integration/test_config_yaml_full/configs/config.d/test_cluster_with_incorrect_pw.yaml b/tests/integration/test_config_yaml_full/configs/config.d/test_cluster_with_incorrect_pw.yaml
new file mode 100644
index 000000000000..309a7daa81d1
--- /dev/null
+++ b/tests/integration/test_config_yaml_full/configs/config.d/test_cluster_with_incorrect_pw.yaml
@@ -0,0 +1,11 @@
+remote_servers:
+  test_cluster_with_incorrect_pw:
+    shard:
+      internal_replication: true
+      replica:
+        - host: 127.0.0.1
+          port: 9000
+          password: foo
+        - host: 127.0.0.2
+          port: 9000
+          password: foo
diff --git a/tests/integration/test_config_yaml_full/configs/config.d/text_log.yaml b/tests/integration/test_config_yaml_full/configs/config.d/text_log.yaml
new file mode 100644
index 000000000000..4d188020e374
--- /dev/null
+++ b/tests/integration/test_config_yaml_full/configs/config.d/text_log.yaml
@@ -0,0 +1,4 @@
+text_log:
+  database: system
+  table: text_log
+  flush_interval_milliseconds: 7500
diff --git a/tests/integration/test_config_yaml_full/configs/config.d/zookeeper.yaml b/tests/integration/test_config_yaml_full/configs/config.d/zookeeper.yaml
new file mode 100644
index 000000000000..be02c516798a
--- /dev/null
+++ b/tests/integration/test_config_yaml_full/configs/config.d/zookeeper.yaml
@@ -0,0 +1,5 @@
+zookeeper:
+  node:
+    host: localhost
+    port: 9181
+    "@index": 1
diff --git a/tests/integration/test_config_yaml_full/configs/config.yaml b/tests/integration/test_config_yaml_full/configs/config.yaml
new file mode 100644
index 000000000000..619a3735269a
--- /dev/null
+++ b/tests/integration/test_config_yaml_full/configs/config.yaml
@@ -0,0 +1,183 @@
+logger:
+  level: trace
+  log: /var/log/clickhouse-server/clickhouse-server.log
+  errorlog: /var/log/clickhouse-server/clickhouse-server.err.log
+  size: 1000M
+  count: 10
+http_port: 8123
+tcp_port: 9000
+mysql_port: 9004
+postgresql_port: 9005
+interserver_http_port: 9009
+max_connections: 4096
+keep_alive_timeout: 3
+grpc:
+  enable_ssl: false
+  ssl_cert_file: /path/to/ssl_cert_file
+  ssl_key_file: /path/to/ssl_key_file
+  ssl_require_client_auth: false
+  ssl_ca_cert_file: /path/to/ssl_ca_cert_file
+  compression: deflate
+  compression_level: medium
+  max_send_message_size: -1
+  max_receive_message_size: -1
+  verbose_logs: false
+openSSL:
+  server:
+    certificateFile: /etc/clickhouse-server/server.crt
+    privateKeyFile: /etc/clickhouse-server/server.key
+    dhParamsFile: /etc/clickhouse-server/dhparam.pem
+    verificationMode: none
+    loadDefaultCAFile: true
+    cacheSessions: true
+    disableProtocols: 'sslv2,sslv3'
+    preferServerCiphers: true
+  client:
+    loadDefaultCAFile: true
+    cacheSessions: true
+    disableProtocols: 'sslv2,sslv3'
+    preferServerCiphers: true
+    invalidCertificateHandler:
+      name: RejectCertificateHandler
+max_concurrent_queries: 100
+max_server_memory_usage: 0
+max_thread_pool_size: 10000
+max_server_memory_usage_to_ram_ratio: 0.9
+total_memory_profiler_step: 4194304
+total_memory_tracker_sample_probability: 0
+uncompressed_cache_size: 8589934592
+mark_cache_size: 5368709120
+mmap_cache_size: 1000
+path: /var/lib/clickhouse/
+tmp_path: /var/lib/clickhouse/tmp/
+user_files_path: /var/lib/clickhouse/user_files/
+ldap_servers: ''
+user_directories:
+  users_xml:
+    path: users.yaml
+  local_directory:
+    path: /var/lib/clickhouse/access/
+default_profile: default
+custom_settings_prefixes: ''
+default_database: default
+mlock_executable: true
+remap_executable: false
+remote_servers:
+  test_shard_localhost:
+    shard:
+      replica:
+        host: localhost
+        port: 9000
+  test_cluster_two_shards_localhost:
+    shard:
+      - replica:
+          host: localhost
+          port: 9000
+      - replica:
+          host: localhost
+          port: 9000
+  test_cluster_two_shards:
+    shard:
+      - replica:
+          host: 127.0.0.1
+          port: 9000
+      - replica:
+          host: 127.0.0.2
+          port: 9000
+  test_cluster_two_shards_internal_replication:
+    shard:
+      - internal_replication: true
+        replica:
+          host: 127.0.0.1
+          port: 9000
+      - internal_replication: true
+        replica:
+          host: 127.0.0.2
+          port: 9000
+  test_shard_localhost_secure:
+    shard:
+      replica:
+        host: localhost
+        port: 9440
+        secure: 1
+  test_unavailable_shard:
+    shard:
+      - replica:
+          host: localhost
+          port: 9000
+      - replica:
+          host: localhost
+          port: 1
+builtin_dictionaries_reload_interval: 3600
+max_session_timeout: 3600
+default_session_timeout: 60
+query_log:
+  database: system
+  table: query_log
+  partition_by: toYYYYMM(event_date)
+  flush_interval_milliseconds: 7500
+trace_log:
+  database: system
+  table: trace_log
+  partition_by: toYYYYMM(event_date)
+  flush_interval_milliseconds: 7500
+query_thread_log:
+  database: system
+  table: query_thread_log
+  partition_by: toYYYYMM(event_date)
+  flush_interval_milliseconds: 7500
+metric_log:
+  database: system
+  table: metric_log
+  flush_interval_milliseconds: 7500
+  collect_interval_milliseconds: 1000
+asynchronous_metric_log:
+  database: system
+  table: asynchronous_metric_log
+  flush_interval_milliseconds: 60000
+opentelemetry_span_log:
+  engine: |-
+    engine MergeTree
+                partition by toYYYYMM(finish_date)
+                order by (finish_date, finish_time_us, trace_id)
+  database: system
+  table: opentelemetry_span_log
+  flush_interval_milliseconds: 7500
+crash_log:
+  database: system
+  table: crash_log
+  partition_by: ''
+  flush_interval_milliseconds: 1000
+top_level_domains_lists: ''
+dictionaries_config: '*_dictionary.xml'
+distributed_ddl:
+  path: /clickhouse/task_queue/ddl
+graphite_rollup_example:
+  pattern:
+    regexp: click_cost
+    function: any
+    retention:
+      - age: 0
+        precision: 3600
+      - age: 86400
+        precision: 60
+  default:
+    function: max
+    retention:
+      - age: 0
+        precision: 60
+      - age: 3600
+        precision: 300
+      - age: 86400
+        precision: 3600
+format_schema_path: /var/lib/clickhouse/format_schemas/
+query_masking_rules:
+  rule:
+    name: hide encrypt/decrypt arguments
+    regexp: '((?:aes_)?(?:encrypt|decrypt)(?:_mysql)?)\s*\(\s*(?:''(?:\\''|.)+''|.*?)\s*\)'
+    replace: \1(???)
+send_crash_reports:
+  enabled: false
+  anonymize: false
+  endpoint: 'https://6f33034cfe684dd7a3ab9875e57b1c8d@o388870.ingest.sentry.io/5226277'
+
diff --git a/tests/integration/test_config_yaml_full/configs/embedded.xml b/tests/integration/test_config_yaml_full/configs/embedded.xml
new file mode 100644
index 000000000000..a66f57d1eb70
--- /dev/null
+++ b/tests/integration/test_config_yaml_full/configs/embedded.xml
@@ -0,0 +1,40 @@
+<?xml version="1.0"?>
+<!-- Config that is used when server is run without config file. -->
+<yandex>
+    <logger>
+        <level>trace</level>
+        <console>true</console>
+    </logger>
+
+    <http_port>8123</http_port>
+    <tcp_port>9000</tcp_port>
+    <mysql_port>9004</mysql_port>
+
+    <path>./</path>
+
+    <uncompressed_cache_size>8589934592</uncompressed_cache_size>
+    <mark_cache_size>5368709120</mark_cache_size>
+    <mlock_executable>true</mlock_executable>
+
+    <users>
+        <default>
+            <password></password>
+
+            <networks>
+                <ip>::/0</ip>
+            </networks>
+
+            <profile>default</profile>
+            <quota>default</quota>
+            <access_management>1</access_management>
+        </default>
+    </users>
+
+    <profiles>
+        <default/>
+    </profiles>
+
+    <quotas>
+        <default />
+    </quotas>
+</yandex>
diff --git a/tests/integration/test_config_yaml_full/configs/users.d/allow_introspection_functions.yaml b/tests/integration/test_config_yaml_full/configs/users.d/allow_introspection_functions.yaml
new file mode 100644
index 000000000000..84612c198c9d
--- /dev/null
+++ b/tests/integration/test_config_yaml_full/configs/users.d/allow_introspection_functions.yaml
@@ -0,0 +1,3 @@
+profiles:
+  default:
+    allow_introspection_functions: 1
diff --git a/tests/integration/test_config_yaml_full/configs/users.d/log_queries.yaml b/tests/integration/test_config_yaml_full/configs/users.d/log_queries.yaml
new file mode 100644
index 000000000000..88574e8f764c
--- /dev/null
+++ b/tests/integration/test_config_yaml_full/configs/users.d/log_queries.yaml
@@ -0,0 +1,3 @@
+profiles:
+  default:
+    log_queries: 1
diff --git a/tests/integration/test_config_yaml_full/configs/users.yaml b/tests/integration/test_config_yaml_full/configs/users.yaml
new file mode 100644
index 000000000000..a87a8c828191
--- /dev/null
+++ b/tests/integration/test_config_yaml_full/configs/users.yaml
@@ -0,0 +1,12 @@
+profiles:
+  default:
+    max_memory_usage: 10000000000
+    max_block_size: 64999
+users:
+  default:
+    password: ''
+    networks:
+      "@replace": replace
+      ip: '::/0'
+    profile: default
+
diff --git a/tests/integration/test_config_yaml_full/test.py b/tests/integration/test_config_yaml_full/test.py
new file mode 100644
index 000000000000..bc4fa40384c0
--- /dev/null
+++ b/tests/integration/test_config_yaml_full/test.py
@@ -0,0 +1,42 @@
+import time
+import threading
+from os import path as p, unlink
+from tempfile import NamedTemporaryFile
+
+import helpers
+import pytest
+from helpers.cluster import ClickHouseCluster
+
+def test_yaml_full_conf():
+    # all configs are in YAML
+    cluster = ClickHouseCluster(__file__, zookeeper_config_path='configs/config.d/zookeeper.yaml')
+
+    all_confd = ['configs/config.d/0_common_instance_config.yaml',
+                'configs/config.d/access_control.yaml',
+                'configs/config.d/keeper_port.yaml',
+                'configs/config.d/logging_no_rotate.yaml',
+                'configs/config.d/log_to_console.yaml',
+                'configs/config.d/macros.yaml',
+                'configs/config.d/metric_log.yaml',
+                'configs/config.d/more_clusters.yaml',
+                'configs/config.d/part_log.yaml',
+                'configs/config.d/path.yaml',
+                'configs/config.d/query_masking_rules.yaml',
+                'configs/config.d/tcp_with_proxy.yaml',
+                'configs/config.d/test_cluster_with_incorrect_pw.yaml',
+                'configs/config.d/text_log.yaml',
+                'configs/config.d/zookeeper.yaml']
+
+    all_userd = ['configs/users.d/allow_introspection_functions.yaml',
+                'configs/users.d/log_queries.yaml']
+
+    node = cluster.add_instance('node', base_config_dir='configs', main_configs=all_confd, user_configs=all_userd,
+                                with_zookeeper=False, main_config_name="config.yaml", users_config_name="users.yaml", copy_common_configs=False)
+
+    try:
+        cluster.start()
+        assert(node.query("select value from system.settings where name = 'max_memory_usage'") == "10000000000
")
+        assert(node.query("select value from system.settings where name = 'max_block_size'") == "64999
")
+
+    finally:
+        cluster.shutdown()
diff --git a/tests/integration/test_config_yaml_main/__init__.py b/tests/integration/test_config_yaml_main/__init__.py
new file mode 100644
index 000000000000..e69de29bb2d1
diff --git a/tests/integration/test_config_yaml_main/configs/config.d/0_common_instance_config.yaml b/tests/integration/test_config_yaml_main/configs/config.d/0_common_instance_config.yaml
new file mode 100644
index 000000000000..62e4ba8c7442
--- /dev/null
+++ b/tests/integration/test_config_yaml_main/configs/config.d/0_common_instance_config.yaml
@@ -0,0 +1,6 @@
+timezone: Europe/Moscow
+listen_host: 0.0.0.0
+custom_settings_prefixes: custom_
+path: /var/lib/clickhouse/
+tmp_path: /var/lib/clickhouse/tmp/
+users_config: users.yaml
diff --git a/tests/integration/test_config_yaml_main/configs/config.d/access_control.xml b/tests/integration/test_config_yaml_main/configs/config.d/access_control.xml
new file mode 100644
index 000000000000..b61f89bd9044
--- /dev/null
+++ b/tests/integration/test_config_yaml_main/configs/config.d/access_control.xml
@@ -0,0 +1,13 @@
+<yandex>
+    <!-- Sources to read users, roles, access rights, profiles of settings, quotas. -->
+    <user_directories replace="replace">
+        <users_xml>
+            <!-- Path to configuration file with predefined users. -->
+            <path>users.yaml</path>
+        </users_xml>
+        <local_directory>
+            <!-- Path to folder where users created by SQL commands are stored. -->
+            <path>access/</path>
+        </local_directory>
+    </user_directories>
+</yandex>
diff --git a/tests/integration/test_config_yaml_main/configs/config.d/keeper_port.xml b/tests/integration/test_config_yaml_main/configs/config.d/keeper_port.xml
new file mode 100644
index 000000000000..b21df47bc850
--- /dev/null
+++ b/tests/integration/test_config_yaml_main/configs/config.d/keeper_port.xml
@@ -0,0 +1,23 @@
+<yandex>
+    <keeper_server>
+        <tcp_port>9181</tcp_port>
+        <server_id>1</server_id>
+
+        <coordination_settings>
+            <operation_timeout_ms>10000</operation_timeout_ms>
+            <session_timeout_ms>30000</session_timeout_ms>
+            <force_sync>false</force_sync>
+            <startup_timeout>60000</startup_timeout>
+            <!-- we want all logs for complex problems investigation -->
+            <reserved_log_items>1000000000000000</reserved_log_items>
+        </coordination_settings>
+
+        <raft_configuration>
+            <server>
+                <id>1</id>
+                <hostname>localhost</hostname>
+                <port>44444</port>
+            </server>
+        </raft_configuration>
+    </keeper_server>
+</yandex>
diff --git a/tests/integration/test_config_yaml_main/configs/config.d/log_to_console.xml b/tests/integration/test_config_yaml_main/configs/config.d/log_to_console.xml
new file mode 100644
index 000000000000..227c53647f32
--- /dev/null
+++ b/tests/integration/test_config_yaml_main/configs/config.d/log_to_console.xml
@@ -0,0 +1,7 @@
+<yandex>
+    <logger>
+        <console>true</console>
+        <log remove="remove"/>
+        <errorlog remove="remove"/>
+    </logger>
+</yandex>
diff --git a/tests/integration/test_config_yaml_main/configs/config.d/logging_no_rotate.xml b/tests/integration/test_config_yaml_main/configs/config.d/logging_no_rotate.xml
new file mode 100644
index 000000000000..2c34585437bf
--- /dev/null
+++ b/tests/integration/test_config_yaml_main/configs/config.d/logging_no_rotate.xml
@@ -0,0 +1,8 @@
+<yandex>
+    <logger>
+        <!-- Disable rotation
+             https://pocoproject.org/docs/Poco.FileChannel.html
+        -->
+        <size>never</size>
+    </logger>
+</yandex>
diff --git a/tests/integration/test_config_yaml_main/configs/config.d/macros.xml b/tests/integration/test_config_yaml_main/configs/config.d/macros.xml
new file mode 100644
index 000000000000..4902b12bc819
--- /dev/null
+++ b/tests/integration/test_config_yaml_main/configs/config.d/macros.xml
@@ -0,0 +1,9 @@
+<yandex>
+    <macros>
+        <test>Hello, world!</test>
+        <shard>s1</shard>
+        <replica>r1</replica>
+        <default_path_test>/clickhouse/tables/{database}/{shard}/</default_path_test>
+        <default_name_test>table_{table}</default_name_test>
+    </macros>
+</yandex>
diff --git a/tests/integration/test_config_yaml_main/configs/config.d/metric_log.xml b/tests/integration/test_config_yaml_main/configs/config.d/metric_log.xml
new file mode 100644
index 000000000000..0ca9f1624169
--- /dev/null
+++ b/tests/integration/test_config_yaml_main/configs/config.d/metric_log.xml
@@ -0,0 +1,8 @@
+<yandex>
+    <metric_log>
+        <database>system</database>
+        <table>metric_log</table>
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+        <collect_interval_milliseconds>1000</collect_interval_milliseconds>
+    </metric_log>
+</yandex>
diff --git a/tests/integration/test_config_yaml_main/configs/config.d/more_clusters.xml b/tests/integration/test_config_yaml_main/configs/config.d/more_clusters.xml
new file mode 100644
index 000000000000..aecbf9e0ba7b
--- /dev/null
+++ b/tests/integration/test_config_yaml_main/configs/config.d/more_clusters.xml
@@ -0,0 +1,49 @@
+<yandex>
+    <remote_servers>
+
+        <![CDATA[
+            You can run additional servers simply as
+             ./clickhouse-server -- --path=9001 --tcp_port=9001
+        ]]>
+
+        <single_remote_shard_at_port_9001>
+            <shard>
+                <replica>
+                    <host>localhost</host>
+                    <port>9001</port>
+                </replica>
+            </shard>
+        </single_remote_shard_at_port_9001>
+
+        <two_remote_shards_at_port_9001_9002>
+            <shard>
+                <replica>
+                    <host>localhost</host>
+                    <port>9001</port>
+                </replica>
+            </shard>
+            <shard>
+                <replica>
+                    <host>localhost</host>
+                    <port>9002</port>
+                </replica>
+            </shard>
+        </two_remote_shards_at_port_9001_9002>
+
+        <two_shards_one_local_one_remote_at_port_9001>
+            <shard>
+                <replica>
+                    <host>localhost</host>
+                    <port>9000</port>
+                </replica>
+            </shard>
+            <shard>
+                <replica>
+                    <host>localhost</host>
+                    <port>9001</port>
+                </replica>
+            </shard>
+        </two_shards_one_local_one_remote_at_port_9001>
+
+    </remote_servers>
+</yandex>
diff --git a/tests/integration/test_config_yaml_main/configs/config.d/part_log.xml b/tests/integration/test_config_yaml_main/configs/config.d/part_log.xml
new file mode 100644
index 000000000000..6c6fc9c69823
--- /dev/null
+++ b/tests/integration/test_config_yaml_main/configs/config.d/part_log.xml
@@ -0,0 +1,8 @@
+<yandex>
+    <part_log>
+        <database>system</database>
+        <table>part_log</table>
+
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+    </part_log>
+</yandex>
diff --git a/tests/integration/test_config_yaml_main/configs/config.d/path.xml b/tests/integration/test_config_yaml_main/configs/config.d/path.xml
new file mode 100644
index 000000000000..466ed0d16637
--- /dev/null
+++ b/tests/integration/test_config_yaml_main/configs/config.d/path.xml
@@ -0,0 +1,8 @@
+<yandex>
+    <path replace="replace">./</path>
+    <tmp_path replace="replace">./tmp/</tmp_path>
+    <user_files_path replace="replace">./user_files/</user_files_path>
+    <format_schema_path replace="replace">./format_schemas/</format_schema_path>
+    <access_control_path replace="replace">./access/</access_control_path>
+    <top_level_domains_path replace="replace">./top_level_domains/</top_level_domains_path>
+</yandex>
diff --git a/tests/integration/test_config_yaml_main/configs/config.d/query_masking_rules.xml b/tests/integration/test_config_yaml_main/configs/config.d/query_masking_rules.xml
new file mode 100644
index 000000000000..5a854848f3d7
--- /dev/null
+++ b/tests/integration/test_config_yaml_main/configs/config.d/query_masking_rules.xml
@@ -0,0 +1,10 @@
+<?xml version="1.0"?>
+<!-- Config for test server -->
+<yandex>
+    <query_masking_rules>
+        <rule>
+            <regexp>TOPSECRET.TOPSECRET</regexp>
+            <replace>[hidden]</replace>
+        </rule>
+    </query_masking_rules>
+</yandex>
diff --git a/tests/integration/test_config_yaml_main/configs/config.d/tcp_with_proxy.xml b/tests/integration/test_config_yaml_main/configs/config.d/tcp_with_proxy.xml
new file mode 100644
index 000000000000..19046054c166
--- /dev/null
+++ b/tests/integration/test_config_yaml_main/configs/config.d/tcp_with_proxy.xml
@@ -0,0 +1,3 @@
+<yandex>
+    <tcp_with_proxy_port>9010</tcp_with_proxy_port>
+</yandex>
diff --git a/tests/integration/test_config_yaml_main/configs/config.d/test_cluster_with_incorrect_pw.xml b/tests/integration/test_config_yaml_main/configs/config.d/test_cluster_with_incorrect_pw.xml
new file mode 100644
index 000000000000..109e35afc37b
--- /dev/null
+++ b/tests/integration/test_config_yaml_main/configs/config.d/test_cluster_with_incorrect_pw.xml
@@ -0,0 +1,21 @@
+<yandex>
+    <remote_servers>
+        <test_cluster_with_incorrect_pw>
+             <shard>
+                 <internal_replication>true</internal_replication>
+                 <replica>
+                     <host>127.0.0.1</host>
+                     <port>9000</port>
+                     <!-- password is incorrect -->
+                     <password>foo</password>
+                 </replica>
+                 <replica>
+                     <host>127.0.0.2</host>
+                     <port>9000</port>
+                     <!-- password is incorrect -->
+                     <password>foo</password>
+                 </replica>
+             </shard>
+         </test_cluster_with_incorrect_pw>
+    </remote_servers>
+</yandex>
diff --git a/tests/integration/test_config_yaml_main/configs/config.d/text_log.xml b/tests/integration/test_config_yaml_main/configs/config.d/text_log.xml
new file mode 100644
index 000000000000..3699a23578cd
--- /dev/null
+++ b/tests/integration/test_config_yaml_main/configs/config.d/text_log.xml
@@ -0,0 +1,7 @@
+<yandex>
+    <text_log>
+        <database>system</database>
+        <table>text_log</table>
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+    </text_log>
+</yandex>
diff --git a/tests/integration/test_config_yaml_main/configs/config.d/zookeeper.xml b/tests/integration/test_config_yaml_main/configs/config.d/zookeeper.xml
new file mode 100644
index 000000000000..06ed7fcd39f3
--- /dev/null
+++ b/tests/integration/test_config_yaml_main/configs/config.d/zookeeper.xml
@@ -0,0 +1,8 @@
+<yandex>
+    <zookeeper>
+        <node index="1">
+            <host>localhost</host>
+            <port>9181</port>
+        </node>
+    </zookeeper>
+</yandex>
diff --git a/tests/integration/test_config_yaml_main/configs/config.yaml b/tests/integration/test_config_yaml_main/configs/config.yaml
new file mode 100644
index 000000000000..e5a36b1e49b7
--- /dev/null
+++ b/tests/integration/test_config_yaml_main/configs/config.yaml
@@ -0,0 +1,183 @@
+logger:
+  level: trace
+  log: /var/log/clickhouse-server/clickhouse-server.log
+  errorlog: /var/log/clickhouse-server/clickhouse-server.err.log
+  size: 1000M
+  count: 10
+http_port: 8123
+tcp_port: 9000
+mysql_port: 9004
+postgresql_port: 9005
+interserver_http_port: 9009
+max_connections: 4096
+keep_alive_timeout: 3
+grpc:
+  enable_ssl: false
+  ssl_cert_file: /path/to/ssl_cert_file
+  ssl_key_file: /path/to/ssl_key_file
+  ssl_require_client_auth: false
+  ssl_ca_cert_file: /path/to/ssl_ca_cert_file
+  compression: deflate
+  compression_level: medium
+  max_send_message_size: -1
+  max_receive_message_size: -1
+  verbose_logs: false
+openSSL:
+  server:
+    certificateFile: /etc/clickhouse-server/server.crt
+    privateKeyFile: /etc/clickhouse-server/server.key
+    dhParamsFile: /etc/clickhouse-server/dhparam.pem
+    verificationMode: none
+    loadDefaultCAFile: true
+    cacheSessions: true
+    disableProtocols: 'sslv2,sslv3'
+    preferServerCiphers: true
+  client:
+    loadDefaultCAFile: true
+    cacheSessions: true
+    disableProtocols: 'sslv2,sslv3'
+    preferServerCiphers: true
+    invalidCertificateHandler:
+      name: RejectCertificateHandler
+max_concurrent_queries: 100
+max_server_memory_usage: 0
+max_thread_pool_size: 10000
+max_server_memory_usage_to_ram_ratio: 0.9
+total_memory_profiler_step: 4194304
+total_memory_tracker_sample_probability: 0
+uncompressed_cache_size: 8589934592
+mark_cache_size: 5368709120
+mmap_cache_size: 1000
+path: /var/lib/clickhouse/
+tmp_path: /var/lib/clickhouse/tmp/
+user_files_path: /var/lib/clickhouse/user_files/
+ldap_servers: ''
+user_directories:
+  users_xml:
+    path: users.yml
+  local_directory:
+    path: /var/lib/clickhouse/access/
+default_profile: default
+custom_settings_prefixes: ''
+default_database: default
+mlock_executable: true
+remap_executable: false
+remote_servers:
+  test_shard_localhost:
+    shard:
+      replica:
+        host: localhost
+        port: 9000
+  test_cluster_two_shards_localhost:
+    shard:
+      - replica:
+          host: localhost
+          port: 9000
+      - replica:
+          host: localhost
+          port: 9000
+  test_cluster_two_shards:
+    shard:
+      - replica:
+          host: 127.0.0.1
+          port: 9000
+      - replica:
+          host: 127.0.0.2
+          port: 9000
+  test_cluster_two_shards_internal_replication:
+    shard:
+      - internal_replication: true
+        replica:
+          host: 127.0.0.1
+          port: 9000
+      - internal_replication: true
+        replica:
+          host: 127.0.0.2
+          port: 9000
+  test_shard_localhost_secure:
+    shard:
+      replica:
+        host: localhost
+        port: 9440
+        secure: 1
+  test_unavailable_shard:
+    shard:
+      - replica:
+          host: localhost
+          port: 9000
+      - replica:
+          host: localhost
+          port: 1
+builtin_dictionaries_reload_interval: 3600
+max_session_timeout: 3600
+default_session_timeout: 60
+query_log:
+  database: system
+  table: query_log
+  partition_by: toYYYYMM(event_date)
+  flush_interval_milliseconds: 7500
+trace_log:
+  database: system
+  table: trace_log
+  partition_by: toYYYYMM(event_date)
+  flush_interval_milliseconds: 7500
+query_thread_log:
+  database: system
+  table: query_thread_log
+  partition_by: toYYYYMM(event_date)
+  flush_interval_milliseconds: 7500
+metric_log:
+  database: system
+  table: metric_log
+  flush_interval_milliseconds: 7500
+  collect_interval_milliseconds: 1000
+asynchronous_metric_log:
+  database: system
+  table: asynchronous_metric_log
+  flush_interval_milliseconds: 60000
+opentelemetry_span_log:
+  engine: |-
+    engine MergeTree
+                partition by toYYYYMM(finish_date)
+                order by (finish_date, finish_time_us, trace_id)
+  database: system
+  table: opentelemetry_span_log
+  flush_interval_milliseconds: 7500
+crash_log:
+  database: system
+  table: crash_log
+  partition_by: ''
+  flush_interval_milliseconds: 1000
+top_level_domains_lists: ''
+dictionaries_config: '*_dictionary.xml'
+distributed_ddl:
+  path: /clickhouse/task_queue/ddl
+graphite_rollup_example:
+  pattern:
+    regexp: click_cost
+    function: any
+    retention:
+      - age: 0
+        precision: 3600
+      - age: 86400
+        precision: 60
+  default:
+    function: max
+    retention:
+      - age: 0
+        precision: 60
+      - age: 3600
+        precision: 300
+      - age: 86400
+        precision: 3600
+format_schema_path: /var/lib/clickhouse/format_schemas/
+query_masking_rules:
+  rule:
+    name: hide encrypt/decrypt arguments
+    regexp: '((?:aes_)?(?:encrypt|decrypt)(?:_mysql)?)\s*\(\s*(?:''(?:\\''|.)+''|.*?)\s*\)'
+    replace: \1(???)
+send_crash_reports:
+  enabled: false
+  anonymize: false
+  endpoint: 'https://6f33034cfe684dd7a3ab9875e57b1c8d@o388870.ingest.sentry.io/5226277'
+
diff --git a/tests/integration/test_config_yaml_main/configs/embedded.xml b/tests/integration/test_config_yaml_main/configs/embedded.xml
new file mode 100644
index 000000000000..a66f57d1eb70
--- /dev/null
+++ b/tests/integration/test_config_yaml_main/configs/embedded.xml
@@ -0,0 +1,40 @@
+<?xml version="1.0"?>
+<!-- Config that is used when server is run without config file. -->
+<yandex>
+    <logger>
+        <level>trace</level>
+        <console>true</console>
+    </logger>
+
+    <http_port>8123</http_port>
+    <tcp_port>9000</tcp_port>
+    <mysql_port>9004</mysql_port>
+
+    <path>./</path>
+
+    <uncompressed_cache_size>8589934592</uncompressed_cache_size>
+    <mark_cache_size>5368709120</mark_cache_size>
+    <mlock_executable>true</mlock_executable>
+
+    <users>
+        <default>
+            <password></password>
+
+            <networks>
+                <ip>::/0</ip>
+            </networks>
+
+            <profile>default</profile>
+            <quota>default</quota>
+            <access_management>1</access_management>
+        </default>
+    </users>
+
+    <profiles>
+        <default/>
+    </profiles>
+
+    <quotas>
+        <default />
+    </quotas>
+</yandex>
diff --git a/tests/integration/test_config_yaml_main/configs/users.d/allow_introspection_functions.xml b/tests/integration/test_config_yaml_main/configs/users.d/allow_introspection_functions.xml
new file mode 100644
index 000000000000..b94e95bc043d
--- /dev/null
+++ b/tests/integration/test_config_yaml_main/configs/users.d/allow_introspection_functions.xml
@@ -0,0 +1,8 @@
+<?xml version="1.0"?>
+<yandex>
+    <profiles>
+        <default>
+            <allow_introspection_functions>1</allow_introspection_functions>
+        </default>
+    </profiles>
+</yandex>
diff --git a/tests/integration/test_config_yaml_main/configs/users.d/log_queries.xml b/tests/integration/test_config_yaml_main/configs/users.d/log_queries.xml
new file mode 100644
index 000000000000..25261072ade6
--- /dev/null
+++ b/tests/integration/test_config_yaml_main/configs/users.d/log_queries.xml
@@ -0,0 +1,7 @@
+<yandex>
+    <profiles>
+        <default>
+            <log_queries>1</log_queries>
+        </default>
+    </profiles>
+</yandex>
diff --git a/tests/integration/test_config_yaml_main/configs/users.yaml b/tests/integration/test_config_yaml_main/configs/users.yaml
new file mode 100644
index 000000000000..a87a8c828191
--- /dev/null
+++ b/tests/integration/test_config_yaml_main/configs/users.yaml
@@ -0,0 +1,12 @@
+profiles:
+  default:
+    max_memory_usage: 10000000000
+    max_block_size: 64999
+users:
+  default:
+    password: ''
+    networks:
+      "@replace": replace
+      ip: '::/0'
+    profile: default
+
diff --git a/tests/integration/test_config_yaml_main/test.py b/tests/integration/test_config_yaml_main/test.py
new file mode 100644
index 000000000000..f4de16c35a2b
--- /dev/null
+++ b/tests/integration/test_config_yaml_main/test.py
@@ -0,0 +1,43 @@
+import time
+import threading
+from os import path as p, unlink
+from tempfile import NamedTemporaryFile
+
+import helpers
+import pytest
+from helpers.cluster import ClickHouseCluster
+
+
+def test_yaml_main_conf():
+    # main configs are in YAML; config.d and users.d are in XML
+    cluster = ClickHouseCluster(__file__, zookeeper_config_path='configs/config.d/zookeeper.xml')
+
+    all_confd = ['configs/config.d/0_common_instance_config.yaml',
+                'configs/config.d/access_control.xml',
+                'configs/config.d/keeper_port.xml',
+                'configs/config.d/logging_no_rotate.xml',
+                'configs/config.d/log_to_console.xml',
+                'configs/config.d/macros.xml',
+                'configs/config.d/metric_log.xml',
+                'configs/config.d/more_clusters.xml',
+                'configs/config.d/part_log.xml',
+                'configs/config.d/path.xml',
+                'configs/config.d/query_masking_rules.xml',
+                'configs/config.d/tcp_with_proxy.xml',
+                'configs/config.d/test_cluster_with_incorrect_pw.xml',
+                'configs/config.d/text_log.xml',
+                'configs/config.d/zookeeper.xml']
+
+    all_userd = ['configs/users.d/allow_introspection_functions.xml',
+                'configs/users.d/log_queries.xml']
+
+    node = cluster.add_instance('node', base_config_dir='configs', main_configs=all_confd, user_configs=all_userd,
+    with_zookeeper=False, main_config_name="config.yaml", users_config_name="users.yaml", copy_common_configs=False)
+
+    try:
+        cluster.start()
+        assert(node.query("select value from system.settings where name = 'max_memory_usage'") == "10000000000
")
+        assert(node.query("select value from system.settings where name = 'max_block_size'") == "64999
")
+
+    finally:
+        cluster.shutdown()
