You will be provided with a partial code base and an issue statement explaining a problem to resolve.

<issue>
sumMap/minMap/maxMap do not support IPv4 / IPv6 as a map key anymore
```sql
select sumMap(map(i, c)) from (select toIPv4('0.0.0.0') i, 1 c);

select sumMap(map(i, c)) from (select toIPv6('::ffff:0.0.0.0') i, 1 c);

select minMap(map(i, c)) from (select toIPv4('0.0.0.0') i, 1 c);

select minMap(map(i, c)) from (select toIPv6('::ffff:0.0.0.0') i, 1 c);
```

I found it during testing

```sql
select cityHash64(hex(sumMapState(map(ip_ipv4, c)))) s from (select number::UInt32::IPv4 ip_ipv4, 1::UInt64 c from numbers(5))
```
Different serialization state of aggregate functions on IPv4 or IPv6 data types after upgrade from version 22.3.18 to version 23.2.3
**Describe the issue**
 22.3.18 to version 23.2.3 upgrade does not seem to be a very big jump, but it caused data corruption and weird behaviour with memory allocation. Rolling back did not work.

**How to reproduce**
We are using clickhouse in kubernetes with clickhouse operator.
Setup: 4 shards replicated (8 nodes total).
Using distributed tables on top of ReplicatedSummingMergeTree engine (and similar others)
The update procedure included only the change in clickhouse docker image tag.
Containers were updated one by one by clickhouse operator.
After upgrade errors started to appear. Rolling back resulted in crashloop. 
While still upgraded, a lot of queries produced out of memory exceptions ( looks like this issue https://github.com/ClickHouse/ClickHouse/issues/41917 ) 
Solved by completely rebuilding the cluster and restoring data from backup solution.


Mostly affected (most queries made to) table definition:
```sql
CREATE TABLE IF NOT EXISTS stats.usage_by_client ON CLUSTER '{{ .Values.clickhouse.cluster }}'
    AS stats.usage_by_client_local
ENGINE = Distributed('{{ .Values.clickhouse.cluster }}', stats, usage_by_client_local, cityHash64(client_id));
```
```sql
CREATE MATERIALIZED VIEW IF NOT EXISTS stats.usage_by_client_mv ON CLUSTER '{{ .Values.clickhouse.cluster }}'
    TO stats.usage_by_client_local
AS SELECT
    toStartOfDay(created_at) AS created_at,
    client_id,
    client_login,
    client_login_type,
    uniqExactIfState(ip_ipv4, IPv4NumToString(ip_ipv4) != '0.0.0.0') AS ip_ipv4_uniq,
    uniqExactIfState(ip_ipv6, IPv6NumToString(ip_ipv6) != '::') AS ip_ipv6_uniq,
    sum(traffic_bytes) AS traffic_bytes,
    sum(requests_200) AS requests_200,
    sum(requests_300) AS requests_300,
    sum(requests_400) AS requests_400,
    sum(requests_500) AS requests_500,
    sum(requests_900) AS requests_900
FROM stats.logs_local
GROUP BY
    created_at,
    client_id,
    client_login,
    client_login_type;
```
```sql
CREATE TABLE IF NOT EXISTS stats.usage_by_client_local ON CLUSTER '{{ .Values.clickhouse.cluster }}'
(
    `created_at` Date,
    `client_id` UInt32 CODEC(DoubleDelta, LZ4),
    `client_login` LowCardinality(String),
    `client_login_type` LowCardinality(String),
    `ip_ipv4_uniq` AggregateFunction(uniqExactIf, IPv4, UInt8),
    `ip_ipv6_uniq` AggregateFunction(uniqExactIf, IPv6, UInt8),
    `traffic_bytes` UInt64,
    `requests_200` UInt64,
    `requests_300` UInt64,
    `requests_400` UInt64,
    `requests_500` UInt64,
    `requests_900` UInt64
)
    ENGINE = ReplicatedSummingMergeTree
    PARTITION BY toYYYYMM(created_at)
    ORDER BY (client_id, created_at, client_login)
    TTL created_at + toIntervalMonth(3)
    SETTINGS index_granularity = 32;
```

Example query that stopped working:
```
SELECT
    uniqExactIfMerge(ip_ipv4_uniq) + uniqExactIfMerge(ip_ipv6_uniq) AS uniqueIps
FROM stats.usage_by_client
WHERE (client_id = 461) AND ((created_at >= '2023-02-12') AND (created_at <= '2023-03-14'))
```

Errors encountered:
```
Multiple logs on multiple collumns after upgrade:
(MergeFromLogEntryTask): virtual bool DB::ReplicatedMergeMutateTaskBase::executeStep(): Code: 33. DB::Exception: Cannot read all data. Bytes read: 5. Bytes expected: 16.: (while reading column ip_ipv4_uniq): While executing MergeTreeSequentialSource. (CANNOT_READ_ALL_DATA)
(MergeFromLogEntryTask): virtual bool DB::ReplicatedMergeMutateTaskBase::executeStep(): Code: 33. DB::Exception: Cannot read all data in MergeTreeReaderCompact. Rows read: 10. Rows expected: 2381.: (while reading column requests_400): While executing MergeTreeSequentialSource. (CANNOT_READ_ALL_DATA)
```
Can't find the stack traces anymore but the call stack was related to serialization. 

While trying to use clickhouse-copier or even remote selects got memory errors:
`Memory limit (total) exceeded: would use 128.00 PiB (attempt to allocate chunk of 4607111 bytes)`
</issue>

I need you to solve the provided issue by generating a code fix that can be applied directly to the repository

Respond below:
