{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 43772,
  "instance_id": "ClickHouse__ClickHouse-43772",
  "issue_numbers": [
    "34527"
  ],
  "base_commit": "1d65d6a5e90f2dbf0f7d3d099e7608a898ce7827",
  "patch": "diff --git a/.github/workflows/pull_request.yml b/.github/workflows/pull_request.yml\nindex c677ec4bf5c7..40424c7a08c1 100644\n--- a/.github/workflows/pull_request.yml\n+++ b/.github/workflows/pull_request.yml\n@@ -2813,6 +2813,217 @@ jobs:\n           docker ps --quiet | xargs --no-run-if-empty docker kill ||:\n           docker ps --all --quiet | xargs --no-run-if-empty docker rm -f ||:\n           sudo rm -fr \"$TEMP_PATH\"\n+  # Parallel replicas\n+  FunctionalStatefulTestDebugParallelReplicas:\n+    needs: [BuilderDebDebug]\n+    runs-on: [self-hosted, func-tester]\n+    steps:\n+      - name: Set envs\n+        run: |\n+          cat >> \"$GITHUB_ENV\" << 'EOF'\n+          TEMP_PATH=${{runner.temp}}/stateful_debug\n+          REPORTS_PATH=${{runner.temp}}/reports_dir\n+          CHECK_NAME=Stateful tests (debug, ParallelReplicas)\n+          REPO_COPY=${{runner.temp}}/stateful_debug/ClickHouse\n+          KILL_TIMEOUT=3600\n+          EOF\n+      - name: Download json reports\n+        uses: actions/download-artifact@v2\n+        with:\n+          path: ${{ env.REPORTS_PATH }}\n+      - name: Clear repository\n+        run: |\n+          sudo rm -fr \"$GITHUB_WORKSPACE\" && mkdir \"$GITHUB_WORKSPACE\"\n+      - name: Check out repository code\n+        uses: actions/checkout@v2\n+      - name: Functional test\n+        run: |\n+          sudo rm -fr \"$TEMP_PATH\"\n+          mkdir -p \"$TEMP_PATH\"\n+          cp -r \"$GITHUB_WORKSPACE\" \"$TEMP_PATH\"\n+          cd \"$REPO_COPY/tests/ci\"\n+          python3 functional_test_check.py \"$CHECK_NAME\" \"$KILL_TIMEOUT\"\n+      - name: Cleanup\n+        if: always()\n+        run: |\n+          docker ps --quiet | xargs --no-run-if-empty docker kill ||:\n+          docker ps --all --quiet | xargs --no-run-if-empty docker rm -f ||:\n+          sudo rm -fr \"$TEMP_PATH\"\n+  FunctionalStatefulTestUBsanParallelReplicas:\n+    needs: [BuilderDebUBsan]\n+    runs-on: [self-hosted, func-tester]\n+    steps:\n+      - name: Set envs\n+        run: |\n+          cat >> \"$GITHUB_ENV\" << 'EOF'\n+          TEMP_PATH=${{runner.temp}}/stateful_ubsan\n+          REPORTS_PATH=${{runner.temp}}/reports_dir\n+          CHECK_NAME=Stateful tests (ubsan, ParallelReplicas)\n+          REPO_COPY=${{runner.temp}}/stateful_ubsan/ClickHouse\n+          KILL_TIMEOUT=3600\n+          EOF\n+      - name: Download json reports\n+        uses: actions/download-artifact@v2\n+        with:\n+          path: ${{ env.REPORTS_PATH }}\n+      - name: Clear repository\n+        run: |\n+          sudo rm -fr \"$GITHUB_WORKSPACE\" && mkdir \"$GITHUB_WORKSPACE\"\n+      - name: Check out repository code\n+        uses: actions/checkout@v2\n+      - name: Functional test\n+        run: |\n+          sudo rm -fr \"$TEMP_PATH\"\n+          mkdir -p \"$TEMP_PATH\"\n+          cp -r \"$GITHUB_WORKSPACE\" \"$TEMP_PATH\"\n+          cd \"$REPO_COPY/tests/ci\"\n+          python3 functional_test_check.py \"$CHECK_NAME\" \"$KILL_TIMEOUT\"\n+      - name: Cleanup\n+        if: always()\n+        run: |\n+          docker ps --quiet | xargs --no-run-if-empty docker kill ||:\n+          docker ps --all --quiet | xargs --no-run-if-empty docker rm -f ||:\n+          sudo rm -fr \"$TEMP_PATH\"\n+  FunctionalStatefulTestMsanParallelReplicas:\n+    needs: [BuilderDebMsan]\n+    runs-on: [self-hosted, func-tester]\n+    steps:\n+      - name: Set envs\n+        run: |\n+          cat >> \"$GITHUB_ENV\" << 'EOF'\n+          TEMP_PATH=${{runner.temp}}/stateful_msan\n+          REPORTS_PATH=${{runner.temp}}/reports_dir\n+          CHECK_NAME=Stateful tests (msan, ParallelReplicas)\n+          REPO_COPY=${{runner.temp}}/stateful_msan/ClickHouse\n+          KILL_TIMEOUT=3600\n+          EOF\n+      - name: Download json reports\n+        uses: actions/download-artifact@v2\n+        with:\n+          path: ${{ env.REPORTS_PATH }}\n+      - name: Clear repository\n+        run: |\n+          sudo rm -fr \"$GITHUB_WORKSPACE\" && mkdir \"$GITHUB_WORKSPACE\"\n+      - name: Check out repository code\n+        uses: actions/checkout@v2\n+      - name: Functional test\n+        run: |\n+          sudo rm -fr \"$TEMP_PATH\"\n+          mkdir -p \"$TEMP_PATH\"\n+          cp -r \"$GITHUB_WORKSPACE\" \"$TEMP_PATH\"\n+          cd \"$REPO_COPY/tests/ci\"\n+          python3 functional_test_check.py \"$CHECK_NAME\" \"$KILL_TIMEOUT\"\n+      - name: Cleanup\n+        if: always()\n+        run: |\n+          docker ps --quiet | xargs --no-run-if-empty docker kill ||:\n+          docker ps --all --quiet | xargs --no-run-if-empty docker rm -f ||:\n+          sudo rm -fr \"$TEMP_PATH\"\n+  FunctionalStatefulTestTsanParallelReplicas:\n+    needs: [BuilderDebTsan]\n+    runs-on: [self-hosted, func-tester]\n+    steps:\n+      - name: Set envs\n+        run: |\n+          cat >> \"$GITHUB_ENV\" << 'EOF'\n+          TEMP_PATH=${{runner.temp}}/stateful_tsan\n+          REPORTS_PATH=${{runner.temp}}/reports_dir\n+          CHECK_NAME=Stateful tests (tsan, ParallelReplicas)\n+          REPO_COPY=${{runner.temp}}/stateful_tsan/ClickHouse\n+          KILL_TIMEOUT=3600\n+          EOF\n+      - name: Download json reports\n+        uses: actions/download-artifact@v2\n+        with:\n+          path: ${{ env.REPORTS_PATH }}\n+      - name: Clear repository\n+        run: |\n+          sudo rm -fr \"$GITHUB_WORKSPACE\" && mkdir \"$GITHUB_WORKSPACE\"\n+      - name: Check out repository code\n+        uses: actions/checkout@v2\n+      - name: Functional test\n+        run: |\n+          sudo rm -fr \"$TEMP_PATH\"\n+          mkdir -p \"$TEMP_PATH\"\n+          cp -r \"$GITHUB_WORKSPACE\" \"$TEMP_PATH\"\n+          cd \"$REPO_COPY/tests/ci\"\n+          python3 functional_test_check.py \"$CHECK_NAME\" \"$KILL_TIMEOUT\"\n+      - name: Cleanup\n+        if: always()\n+        run: |\n+          docker ps --quiet | xargs --no-run-if-empty docker kill ||:\n+          docker ps --all --quiet | xargs --no-run-if-empty docker rm -f ||:\n+          sudo rm -fr \"$TEMP_PATH\"\n+  FunctionalStatefulTestAsanParallelReplicas:\n+    needs: [BuilderDebAsan]\n+    runs-on: [self-hosted, func-tester]\n+    steps:\n+      - name: Set envs\n+        run: |\n+          cat >> \"$GITHUB_ENV\" << 'EOF'\n+          TEMP_PATH=${{runner.temp}}/stateful_debug\n+          REPORTS_PATH=${{runner.temp}}/reports_dir\n+          CHECK_NAME=Stateful tests (asan, ParallelReplicas)\n+          REPO_COPY=${{runner.temp}}/stateful_debug/ClickHouse\n+          KILL_TIMEOUT=3600\n+          EOF\n+      - name: Download json reports\n+        uses: actions/download-artifact@v2\n+        with:\n+          path: ${{ env.REPORTS_PATH }}\n+      - name: Clear repository\n+        run: |\n+          sudo rm -fr \"$GITHUB_WORKSPACE\" && mkdir \"$GITHUB_WORKSPACE\"\n+      - name: Check out repository code\n+        uses: actions/checkout@v2\n+      - name: Functional test\n+        run: |\n+          sudo rm -fr \"$TEMP_PATH\"\n+          mkdir -p \"$TEMP_PATH\"\n+          cp -r \"$GITHUB_WORKSPACE\" \"$TEMP_PATH\"\n+          cd \"$REPO_COPY/tests/ci\"\n+          python3 functional_test_check.py \"$CHECK_NAME\" \"$KILL_TIMEOUT\"\n+      - name: Cleanup\n+        if: always()\n+        run: |\n+          docker ps --quiet | xargs --no-run-if-empty docker kill ||:\n+          docker ps --all --quiet | xargs --no-run-if-empty docker rm -f ||:\n+          sudo rm -fr \"$TEMP_PATH\"\n+  FunctionalStatefulTestReleaseParallelReplicas:\n+    needs: [BuilderDebRelease]\n+    runs-on: [self-hosted, func-tester]\n+    steps:\n+      - name: Set envs\n+        run: |\n+          cat >> \"$GITHUB_ENV\" << 'EOF'\n+          TEMP_PATH=${{runner.temp}}/stateful_release\n+          REPORTS_PATH=${{runner.temp}}/reports_dir\n+          CHECK_NAME=Stateful tests (release, ParallelReplicas)\n+          REPO_COPY=${{runner.temp}}/stateful_release/ClickHouse\n+          KILL_TIMEOUT=3600\n+          EOF\n+      - name: Download json reports\n+        uses: actions/download-artifact@v2\n+        with:\n+          path: ${{ env.REPORTS_PATH }}\n+      - name: Clear repository\n+        run: |\n+          sudo rm -fr \"$GITHUB_WORKSPACE\" && mkdir \"$GITHUB_WORKSPACE\"\n+      - name: Check out repository code\n+        uses: actions/checkout@v2\n+      - name: Functional test\n+        run: |\n+          sudo rm -fr \"$TEMP_PATH\"\n+          mkdir -p \"$TEMP_PATH\"\n+          cp -r \"$GITHUB_WORKSPACE\" \"$TEMP_PATH\"\n+          cd \"$REPO_COPY/tests/ci\"\n+          python3 functional_test_check.py \"$CHECK_NAME\" \"$KILL_TIMEOUT\"\n+      - name: Cleanup\n+        if: always()\n+        run: |\n+          docker ps --quiet | xargs --no-run-if-empty docker kill ||:\n+          docker ps --all --quiet | xargs --no-run-if-empty docker rm -f ||:\n+          sudo rm -fr \"$TEMP_PATH\"\n ##############################################################################################\n ######################################### STRESS TESTS #######################################\n ##############################################################################################\ndiff --git a/programs/benchmark/Benchmark.cpp b/programs/benchmark/Benchmark.cpp\nindex dae3aea2d2e1..7fb0b1f154f4 100644\n--- a/programs/benchmark/Benchmark.cpp\n+++ b/programs/benchmark/Benchmark.cpp\n@@ -474,7 +474,7 @@ class Benchmark : public Poco::Util::Application\n         executor.sendQuery(ClientInfo::QueryKind::INITIAL_QUERY);\n \n         ProfileInfo info;\n-        while (Block block = executor.read())\n+        while (Block block = executor.readBlock())\n             info.update(block);\n \n         executor.finish();\ndiff --git a/programs/copier/ClusterCopier.cpp b/programs/copier/ClusterCopier.cpp\nindex 256b40414c53..2fc0eb27213f 100644\n--- a/programs/copier/ClusterCopier.cpp\n+++ b/programs/copier/ClusterCopier.cpp\n@@ -2040,7 +2040,7 @@ UInt64 ClusterCopier::executeQueryOnCluster(\n \n                 while (true)\n                 {\n-                    auto block = remote_query_executor->read();\n+                    auto block = remote_query_executor->readBlock();\n                     if (!block)\n                         break;\n                 }\ndiff --git a/programs/server/config.xml b/programs/server/config.xml\nindex bd46263f851e..b860260834f2 100644\n--- a/programs/server/config.xml\n+++ b/programs/server/config.xml\n@@ -854,6 +854,51 @@\n                 </replica>\n             </shard-->\n         </test_cluster_one_shard_three_replicas_localhost>\n+\t<parallel_replicas>\n+\t\t<shard>\n+            <internal_replication>false</internal_replication>\n+            <replica>\n+                <host>127.0.0.1</host>\n+                <port>9000</port>\n+            </replica>\n+            <replica>\n+                <host>127.0.0.2</host>\n+                <port>9000</port>\n+            </replica>\n+            <replica>\n+                <host>127.0.0.3</host>\n+                <port>9000</port>\n+            </replica>\n+            <replica>\n+                <host>127.0.0.4</host>\n+                <port>9000</port>\n+            </replica>\n+            <replica>\n+                <host>127.0.0.5</host>\n+                <port>9000</port>\n+            </replica>\n+            <replica>\n+                <host>127.0.0.6</host>\n+                <port>9000</port>\n+            </replica>\n+            <replica>\n+                <host>127.0.0.7</host>\n+                <port>9000</port>\n+            </replica>\n+            <replica>\n+                <host>127.0.0.8</host>\n+                <port>9000</port>\n+            </replica>\n+            <replica>\n+                <host>127.0.0.9</host>\n+                <port>9000</port>\n+            </replica>\n+            <replica>\n+                <host>127.0.0.10</host>\n+                <port>9000</port>\n+            </replica>\n+        </shard>\n+\t</parallel_replicas>\n         <test_cluster_two_shards_localhost>\n              <shard>\n                  <replica>\ndiff --git a/src/CMakeLists.txt b/src/CMakeLists.txt\nindex 14838560a889..a74f10d2c3c3 100644\n--- a/src/CMakeLists.txt\n+++ b/src/CMakeLists.txt\n@@ -343,8 +343,8 @@ set_source_files_properties(\n         PROPERTIES COMPILE_FLAGS \"-mwaitpkg\")\n endif ()\n \n-target_link_libraries(clickhouse_common_io PUBLIC ch_contrib::re2_st)\n-target_link_libraries(clickhouse_common_io PUBLIC ch_contrib::re2)\n+target_link_libraries(common PUBLIC ch_contrib::re2_st)\n+target_link_libraries(common PUBLIC ch_contrib::re2)\n \n target_link_libraries(clickhouse_common_io\n         PUBLIC\ndiff --git a/src/Client/Connection.cpp b/src/Client/Connection.cpp\nindex 701e26e4f671..eea007a8608f 100644\n--- a/src/Client/Connection.cpp\n+++ b/src/Client/Connection.cpp\n@@ -686,7 +686,7 @@ void Connection::sendReadTaskResponse(const String & response)\n }\n \n \n-void Connection::sendMergeTreeReadTaskResponse(const PartitionReadResponse & response)\n+void Connection::sendMergeTreeReadTaskResponse(const ParallelReadResponse & response)\n {\n     writeVarUInt(Protocol::Client::MergeTreeReadTaskResponse, *out);\n     response.serialize(*out);\n@@ -960,8 +960,12 @@ Packet Connection::receivePacket()\n             case Protocol::Server::ReadTaskRequest:\n                 return res;\n \n+            case Protocol::Server::MergeTreeAllRangesAnnounecement:\n+                res.announcement = receiveInitialParallelReadAnnounecement();\n+                return res;\n+\n             case Protocol::Server::MergeTreeReadTaskRequest:\n-                res.request = receivePartitionReadRequest();\n+                res.request = receiveParallelReadRequest();\n                 return res;\n \n             case Protocol::Server::ProfileEvents:\n@@ -1114,13 +1118,20 @@ ProfileInfo Connection::receiveProfileInfo() const\n     return profile_info;\n }\n \n-PartitionReadRequest Connection::receivePartitionReadRequest() const\n+ParallelReadRequest Connection::receiveParallelReadRequest() const\n {\n-    PartitionReadRequest request;\n+    ParallelReadRequest request;\n     request.deserialize(*in);\n     return request;\n }\n \n+InitialAllRangesAnnouncement Connection::receiveInitialParallelReadAnnounecement() const\n+{\n+    InitialAllRangesAnnouncement announcement;\n+    announcement.deserialize(*in);\n+    return announcement;\n+}\n+\n \n void Connection::throwUnexpectedPacket(UInt64 packet_type, const char * expected) const\n {\ndiff --git a/src/Client/Connection.h b/src/Client/Connection.h\nindex 5128757f11c8..d806c5e8b1fc 100644\n--- a/src/Client/Connection.h\n+++ b/src/Client/Connection.h\n@@ -110,7 +110,7 @@ class Connection : public IServerConnection\n \n     void sendData(const Block & block, const String & name/* = \"\" */, bool scalar/* = false */) override;\n \n-    void sendMergeTreeReadTaskResponse(const PartitionReadResponse & response) override;\n+    void sendMergeTreeReadTaskResponse(const ParallelReadResponse & response) override;\n \n     void sendExternalTablesData(ExternalTablesData & data) override;\n \n@@ -265,7 +265,8 @@ class Connection : public IServerConnection\n     std::vector<String> receiveMultistringMessage(UInt64 msg_type) const;\n     std::unique_ptr<Exception> receiveException() const;\n     Progress receiveProgress() const;\n-    PartitionReadRequest receivePartitionReadRequest() const;\n+    ParallelReadRequest receiveParallelReadRequest() const;\n+    InitialAllRangesAnnouncement receiveInitialParallelReadAnnounecement() const;\n     ProfileInfo receiveProfileInfo() const;\n \n     void initInputBuffers();\ndiff --git a/src/Client/HedgedConnections.h b/src/Client/HedgedConnections.h\nindex fe697c78bb71..40f031a16a66 100644\n--- a/src/Client/HedgedConnections.h\n+++ b/src/Client/HedgedConnections.h\n@@ -94,7 +94,7 @@ class HedgedConnections : public IConnections\n         throw Exception(ErrorCodes::LOGICAL_ERROR, \"sendReadTaskResponse in not supported with HedgedConnections\");\n     }\n \n-    void sendMergeTreeReadTaskResponse(PartitionReadResponse) override\n+    void sendMergeTreeReadTaskResponse(const ParallelReadResponse &) override\n     {\n         throw Exception(ErrorCodes::LOGICAL_ERROR, \"sendMergeTreeReadTaskResponse in not supported with HedgedConnections\");\n     }\ndiff --git a/src/Client/IConnections.h b/src/Client/IConnections.h\nindex 9d695e6da92d..0040eeb31ed9 100644\n--- a/src/Client/IConnections.h\n+++ b/src/Client/IConnections.h\n@@ -34,7 +34,7 @@ class IConnections : boost::noncopyable\n         bool with_pending_data) = 0;\n \n     virtual void sendReadTaskResponse(const String &) = 0;\n-    virtual void sendMergeTreeReadTaskResponse(PartitionReadResponse response) = 0;\n+    virtual void sendMergeTreeReadTaskResponse(const ParallelReadResponse & response) = 0;\n \n     /// Get packet from any replica.\n     virtual Packet receivePacket() = 0;\n@@ -60,9 +60,9 @@ class IConnections : boost::noncopyable\n     /// Get the replica addresses as a string.\n     virtual std::string dumpAddresses() const = 0;\n \n-\n     struct ReplicaInfo\n     {\n+        bool collaborate_with_initiator{false};\n         size_t all_replicas_count{0};\n         size_t number_of_current_replica{0};\n     };\ndiff --git a/src/Client/IServerConnection.h b/src/Client/IServerConnection.h\nindex d75ea3a713c3..cd4db8f5258f 100644\n--- a/src/Client/IServerConnection.h\n+++ b/src/Client/IServerConnection.h\n@@ -33,8 +33,10 @@ struct Packet\n     Progress progress;\n     ProfileInfo profile_info;\n     std::vector<UUID> part_uuids;\n-    PartitionReadRequest request;\n-    PartitionReadResponse response;\n+\n+    InitialAllRangesAnnouncement announcement;\n+    ParallelReadRequest request;\n+    ParallelReadResponse response;\n \n     Packet() : type(Protocol::Server::Hello) {}\n };\n@@ -104,7 +106,7 @@ class IServerConnection : boost::noncopyable\n     /// Send all contents of external (temporary) tables.\n     virtual void sendExternalTablesData(ExternalTablesData & data) = 0;\n \n-    virtual void sendMergeTreeReadTaskResponse(const PartitionReadResponse & response) = 0;\n+    virtual void sendMergeTreeReadTaskResponse(const ParallelReadResponse & response) = 0;\n \n     /// Check, if has data to read.\n     virtual bool poll(size_t timeout_microseconds) = 0;\ndiff --git a/src/Client/LocalConnection.cpp b/src/Client/LocalConnection.cpp\nindex d86a097b9105..77a0a8463006 100644\n--- a/src/Client/LocalConnection.cpp\n+++ b/src/Client/LocalConnection.cpp\n@@ -508,7 +508,7 @@ void LocalConnection::sendExternalTablesData(ExternalTablesData &)\n     throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Not implemented\");\n }\n \n-void LocalConnection::sendMergeTreeReadTaskResponse(const PartitionReadResponse &)\n+void LocalConnection::sendMergeTreeReadTaskResponse(const ParallelReadResponse &)\n {\n     throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Not implemented\");\n }\ndiff --git a/src/Client/LocalConnection.h b/src/Client/LocalConnection.h\nindex cfdffefc0cec..3e6fc007fb94 100644\n--- a/src/Client/LocalConnection.h\n+++ b/src/Client/LocalConnection.h\n@@ -110,7 +110,7 @@ class LocalConnection : public IServerConnection, WithContext\n \n     void sendExternalTablesData(ExternalTablesData &) override;\n \n-    void sendMergeTreeReadTaskResponse(const PartitionReadResponse & response) override;\n+    void sendMergeTreeReadTaskResponse(const ParallelReadResponse & response) override;\n \n     bool poll(size_t timeout_microseconds/* = 0 */) override;\n \ndiff --git a/src/Client/MultiplexedConnections.cpp b/src/Client/MultiplexedConnections.cpp\nindex a10846657d67..cc2603533397 100644\n--- a/src/Client/MultiplexedConnections.cpp\n+++ b/src/Client/MultiplexedConnections.cpp\n@@ -133,16 +133,11 @@ void MultiplexedConnections::sendQuery(\n             modified_settings.group_by_two_level_threshold_bytes = 0;\n         }\n \n-        bool parallel_reading_from_replicas = settings.max_parallel_replicas > 1\n-            && settings.allow_experimental_parallel_reading_from_replicas\n-            /// To avoid trying to coordinate with clickhouse-benchmark,\n-            /// since it uses the same code.\n-            && client_info.query_kind != ClientInfo::QueryKind::INITIAL_QUERY;\n-        if (parallel_reading_from_replicas)\n+        if (replica_info)\n         {\n             client_info.collaborate_with_initiator = true;\n-            client_info.count_participating_replicas = replica_info.all_replicas_count;\n-            client_info.number_of_current_replica = replica_info.number_of_current_replica;\n+            client_info.count_participating_replicas = replica_info->all_replicas_count;\n+            client_info.number_of_current_replica = replica_info->number_of_current_replica;\n         }\n     }\n \n@@ -199,7 +194,7 @@ void MultiplexedConnections::sendReadTaskResponse(const String & response)\n }\n \n \n-void MultiplexedConnections::sendMergeTreeReadTaskResponse(PartitionReadResponse response)\n+void MultiplexedConnections::sendMergeTreeReadTaskResponse(const ParallelReadResponse & response)\n {\n     std::lock_guard lock(cancel_mutex);\n     if (cancelled)\n@@ -263,6 +258,7 @@ Packet MultiplexedConnections::drain()\n \n         switch (packet.type)\n         {\n+            case Protocol::Server::MergeTreeAllRangesAnnounecement:\n             case Protocol::Server::MergeTreeReadTaskRequest:\n             case Protocol::Server::ReadTaskRequest:\n             case Protocol::Server::PartUUIDs:\n@@ -343,6 +339,7 @@ Packet MultiplexedConnections::receivePacketUnlocked(AsyncCallback async_callbac\n \n     switch (packet.type)\n     {\n+        case Protocol::Server::MergeTreeAllRangesAnnounecement:\n         case Protocol::Server::MergeTreeReadTaskRequest:\n         case Protocol::Server::ReadTaskRequest:\n         case Protocol::Server::PartUUIDs:\ndiff --git a/src/Client/MultiplexedConnections.h b/src/Client/MultiplexedConnections.h\nindex e76d54218c71..dd228067ed2d 100644\n--- a/src/Client/MultiplexedConnections.h\n+++ b/src/Client/MultiplexedConnections.h\n@@ -42,7 +42,7 @@ class MultiplexedConnections final : public IConnections\n         bool with_pending_data) override;\n \n     void sendReadTaskResponse(const String &) override;\n-    void sendMergeTreeReadTaskResponse(PartitionReadResponse response) override;\n+    void sendMergeTreeReadTaskResponse(const ParallelReadResponse & response) override;\n \n     Packet receivePacket() override;\n \n@@ -104,7 +104,8 @@ class MultiplexedConnections final : public IConnections\n     bool sent_query = false;\n     bool cancelled = false;\n \n-    ReplicaInfo replica_info;\n+    /// std::nullopt if parallel reading from replicas is not used\n+    std::optional<ReplicaInfo> replica_info;\n \n     /// A mutex for the sendCancel function to execute safely\n     /// in separate thread.\ndiff --git a/src/Core/Protocol.h b/src/Core/Protocol.h\nindex 08c675eb4219..86c0a851c60f 100644\n--- a/src/Core/Protocol.h\n+++ b/src/Core/Protocol.h\n@@ -81,7 +81,8 @@ namespace Protocol\n                                             /// This is such an inverted logic, where server sends requests\n                                             /// And client returns back response\n             ProfileEvents = 14,             /// Packet with profile events from server.\n-            MergeTreeReadTaskRequest = 15,  /// Request from a MergeTree replica to a coordinator\n+            MergeTreeAllRangesAnnounecement = 15,\n+            MergeTreeReadTaskRequest = 16,  /// Request from a MergeTree replica to a coordinator\n             MAX = MergeTreeReadTaskRequest,\n \n         };\n@@ -108,6 +109,7 @@ namespace Protocol\n                 \"PartUUIDs\",\n                 \"ReadTaskRequest\",\n                 \"ProfileEvents\",\n+                \"MergeTreeAllRangesAnnounecement\",\n                 \"MergeTreeReadTaskRequest\",\n             };\n             return packet <= MAX\ndiff --git a/src/Core/ProtocolDefines.h b/src/Core/ProtocolDefines.h\nindex 01017a2b751c..3bbfb95f0204 100644\n--- a/src/Core/ProtocolDefines.h\n+++ b/src/Core/ProtocolDefines.h\n@@ -33,6 +33,8 @@\n #define DBMS_PARALLEL_REPLICAS_PROTOCOL_VERSION 1\n #define DBMS_MIN_REVISION_WITH_PARALLEL_REPLICAS 54453\n \n+#define DBMS_MERGE_TREE_PART_INFO_VERSION 1\n+\n /// Minimum revision supporting interserver secret.\n #define DBMS_MIN_REVISION_WITH_INTERSERVER_SECRET 54441\n \ndiff --git a/src/Core/Settings.h b/src/Core/Settings.h\nindex 54a466864944..cfc0d35a41c7 100644\n--- a/src/Core/Settings.h\n+++ b/src/Core/Settings.h\n@@ -151,7 +151,9 @@ class IColumn;\n     M(UInt64, parallel_replicas_count, 0, \"This is internal setting that should not be used directly and represents an implementation detail of the 'parallel replicas' mode. This setting will be automatically set up by the initiator server for distributed queries to the number of parallel replicas participating in query processing.\", 0) \\\n     M(UInt64, parallel_replica_offset, 0, \"This is internal setting that should not be used directly and represents an implementation detail of the 'parallel replicas' mode. This setting will be automatically set up by the initiator server for distributed queries to the index of the replica participating in query processing among parallel replicas.\", 0) \\\n     \\\n+    M(String, cluster_for_parallel_replicas, \"default\", \"Cluster for a shard in which current server is located\", 0) \\\n     M(Bool, allow_experimental_parallel_reading_from_replicas, false, \"If true, ClickHouse will send a SELECT query to all replicas of a table. It will work for any kind on MergeTree table.\", 0) \\\n+    M(Float, parallel_replicas_single_task_marks_count_multiplier, 2, \"A multiplier which will be added during calculation for minimal number of marks to retrieve from coordinator. This will be applied only for remote replicas.\", 0) \\\n     \\\n     M(Bool, skip_unavailable_shards, false, \"If true, ClickHouse silently skips unavailable shards and nodes unresolvable through DNS. Shard is marked as unavailable when none of the replicas can be reached.\", 0) \\\n     \\\ndiff --git a/src/Disks/IDisk.h b/src/Disks/IDisk.h\nindex 7907c0b2a741..460ce14f1971 100644\n--- a/src/Disks/IDisk.h\n+++ b/src/Disks/IDisk.h\n@@ -28,6 +28,7 @@ namespace Poco\n {\n     namespace Util\n     {\n+        /// NOLINTNEXTLINE(cppcoreguidelines-virtual-class-destructor)\n         class AbstractConfiguration;\n     }\n }\ndiff --git a/src/Interpreters/ClusterProxy/SelectStreamFactory.cpp b/src/Interpreters/ClusterProxy/SelectStreamFactory.cpp\nindex 5c781c531ed2..b08ec7e5ab50 100644\n--- a/src/Interpreters/ClusterProxy/SelectStreamFactory.cpp\n+++ b/src/Interpreters/ClusterProxy/SelectStreamFactory.cpp\n@@ -7,7 +7,10 @@\n #include <Common/ProfileEvents.h>\n #include <Common/checkStackSize.h>\n #include <TableFunctions/TableFunctionFactory.h>\n+#include <IO/ConnectionTimeoutsContext.h>\n+#include <Interpreters/AddDefaultDatabaseVisitor.h>\n #include <Interpreters/RequiredSourceColumnsVisitor.h>\n+#include <Interpreters/TranslateQualifiedNamesVisitor.h>\n #include <DataTypes/ObjectUtils.h>\n \n #include <Client/IConnections.h>\n@@ -36,6 +39,53 @@ namespace ErrorCodes\n namespace ClusterProxy\n {\n \n+/// select query has database, table and table function names as AST pointers\n+/// Creates a copy of query, changes database, table and table function names.\n+ASTPtr rewriteSelectQuery(\n+    ContextPtr context,\n+    const ASTPtr & query,\n+    const std::string & remote_database,\n+    const std::string & remote_table,\n+    ASTPtr table_function_ptr)\n+{\n+    auto modified_query_ast = query->clone();\n+\n+    ASTSelectQuery & select_query = modified_query_ast->as<ASTSelectQuery &>();\n+\n+    // Get rid of the settings clause so we don't send them to remote. Thus newly non-important\n+    // settings won't break any remote parser. It's also more reasonable since the query settings\n+    // are written into the query context and will be sent by the query pipeline.\n+    select_query.setExpression(ASTSelectQuery::Expression::SETTINGS, {});\n+\n+    if (table_function_ptr)\n+        select_query.addTableFunction(table_function_ptr);\n+    else\n+        select_query.replaceDatabaseAndTable(remote_database, remote_table);\n+\n+    /// Restore long column names (cause our short names are ambiguous).\n+    /// TODO: aliased table functions & CREATE TABLE AS table function cases\n+    if (!table_function_ptr)\n+    {\n+        RestoreQualifiedNamesVisitor::Data data;\n+        data.distributed_table = DatabaseAndTableWithAlias(*getTableExpression(query->as<ASTSelectQuery &>(), 0));\n+        data.remote_table.database = remote_database;\n+        data.remote_table.table = remote_table;\n+        RestoreQualifiedNamesVisitor(data).visit(modified_query_ast);\n+    }\n+\n+    /// To make local JOIN works, default database should be added to table names.\n+    /// But only for JOIN section, since the following should work using default_database:\n+    /// - SELECT * FROM d WHERE value IN (SELECT l.value FROM l) ORDER BY value\n+    ///   (see 01487_distributed_in_not_default_db)\n+    AddDefaultDatabaseVisitor visitor(context, context->getCurrentDatabase(),\n+        /* only_replace_current_database_function_= */false,\n+        /* only_replace_in_join_= */true);\n+    visitor.visit(modified_query_ast);\n+\n+    return modified_query_ast;\n+}\n+\n+\n SelectStreamFactory::SelectStreamFactory(\n     const Block & header_,\n     const ColumnsDescriptionByShardNum & objects_by_shard_,\n@@ -171,67 +221,5 @@ void SelectStreamFactory::createForShard(\n }\n \n \n-void SelectStreamFactory::createForShardWithParallelReplicas(\n-    const Cluster::ShardInfo & shard_info,\n-    const ASTPtr & query_ast,\n-    const StorageID & main_table,\n-    ContextPtr context,\n-    UInt32 shard_count,\n-    std::vector<QueryPlanPtr> & local_plans,\n-    Shards & remote_shards)\n-{\n-    if (auto it = objects_by_shard.find(shard_info.shard_num); it != objects_by_shard.end())\n-        replaceMissedSubcolumnsByConstants(storage_snapshot->object_columns, it->second, query_ast);\n-\n-    const auto & settings = context->getSettingsRef();\n-\n-    auto is_local_replica_obsolete = [&]()\n-    {\n-        auto resolved_id = context->resolveStorageID(main_table);\n-        auto main_table_storage = DatabaseCatalog::instance().tryGetTable(resolved_id, context);\n-        const auto * replicated_storage = dynamic_cast<const StorageReplicatedMergeTree *>(main_table_storage.get());\n-\n-        if (!replicated_storage)\n-            return false;\n-\n-        UInt64 max_allowed_delay = settings.max_replica_delay_for_distributed_queries;\n-\n-        if (!max_allowed_delay)\n-            return false;\n-\n-        UInt64 local_delay = replicated_storage->getAbsoluteDelay();\n-        return local_delay >= max_allowed_delay;\n-    };\n-\n-    size_t next_replica_number = 0;\n-    size_t all_replicas_count = shard_info.getRemoteNodeCount();\n-\n-    auto coordinator = std::make_shared<ParallelReplicasReadingCoordinator>();\n-\n-    if (settings.prefer_localhost_replica && shard_info.isLocal())\n-    {\n-        /// We don't need more than one local replica in parallel reading\n-        if (!is_local_replica_obsolete())\n-        {\n-            ++all_replicas_count;\n-\n-            local_plans.emplace_back(createLocalPlan(\n-                query_ast, header, context, processed_stage, shard_info.shard_num, shard_count, next_replica_number, all_replicas_count, coordinator));\n-\n-            ++next_replica_number;\n-        }\n-    }\n-\n-    if (shard_info.hasRemoteConnections())\n-        remote_shards.emplace_back(Shard{\n-            .query = query_ast,\n-            .header = header,\n-            .shard_info = shard_info,\n-            .lazy = false,\n-            .local_delay = 0,\n-            .coordinator = coordinator,\n-        });\n-}\n-\n }\n }\ndiff --git a/src/Interpreters/ClusterProxy/SelectStreamFactory.h b/src/Interpreters/ClusterProxy/SelectStreamFactory.h\nindex a8f7d131b153..f1a8b3e09840 100644\n--- a/src/Interpreters/ClusterProxy/SelectStreamFactory.h\n+++ b/src/Interpreters/ClusterProxy/SelectStreamFactory.h\n@@ -29,6 +29,14 @@ struct StorageID;\n namespace ClusterProxy\n {\n \n+/// select query has database, table and table function names as AST pointers\n+/// Creates a copy of query, changes database, table and table function names.\n+ASTPtr rewriteSelectQuery(\n+    ContextPtr context,\n+    const ASTPtr & query,\n+    const std::string & remote_database,\n+    const std::string & remote_table,\n+    ASTPtr table_function_ptr = nullptr);\n \n using ColumnsDescriptionByShardNum = std::unordered_map<UInt32, ColumnsDescription>;\n \n@@ -80,16 +88,6 @@ class SelectStreamFactory\n         std::unique_ptr<QueryPlan> remote_plan;\n     };\n \n-    void createForShardWithParallelReplicas(\n-        const Cluster::ShardInfo & shard_info,\n-        const ASTPtr & query_ast,\n-        const StorageID & main_table,\n-        ContextPtr context,\n-        UInt32 shard_count,\n-        std::vector<QueryPlanPtr> & local_plans,\n-        Shards & remote_shards);\n-\n-private:\n     const Block header;\n     const ColumnsDescriptionByShardNum objects_by_shard;\n     const StorageSnapshotPtr storage_snapshot;\ndiff --git a/src/Interpreters/ClusterProxy/executeQuery.cpp b/src/Interpreters/ClusterProxy/executeQuery.cpp\nindex fe31b4d8302a..2e035ef883fc 100644\n--- a/src/Interpreters/ClusterProxy/executeQuery.cpp\n+++ b/src/Interpreters/ClusterProxy/executeQuery.cpp\n@@ -1,6 +1,8 @@\n #include <Core/QueryProcessingStage.h>\n #include <Core/Settings.h>\n+#include <Core/UUID.h>\n #include <DataTypes/DataTypesNumber.h>\n+#include <DataTypes/ObjectUtils.h>\n #include <Interpreters/Cluster.h>\n #include <Interpreters/ClusterProxy/SelectStreamFactory.h>\n #include <Interpreters/ClusterProxy/executeQuery.h>\n@@ -13,8 +15,11 @@\n #include <Processors/QueryPlan/QueryPlan.h>\n #include <Processors/QueryPlan/ReadFromRemote.h>\n #include <Processors/QueryPlan/UnionStep.h>\n+#include <Processors/QueryPlan/DistributedCreateLocalPlan.h>\n+#include <Processors/ResizeProcessor.h>\n #include <QueryPipeline/Pipe.h>\n #include <Storages/SelectQueryInfo.h>\n+#include <Storages/StorageReplicatedMergeTree.h>\n \n namespace DB\n {\n@@ -23,6 +28,7 @@ namespace ErrorCodes\n {\n     extern const int TOO_LARGE_DISTRIBUTED_DEPTH;\n     extern const int LOGICAL_ERROR;\n+    extern const int SUPPORT_IS_DISABLED;\n }\n \n namespace ClusterProxy\n@@ -117,6 +123,31 @@ ContextMutablePtr updateSettingsForCluster(const Cluster & cluster, ContextPtr c\n     return new_context;\n }\n \n+static ThrottlerPtr getThrottler(const ContextPtr & context)\n+{\n+    const Settings & settings = context->getSettingsRef();\n+\n+    ThrottlerPtr user_level_throttler;\n+    if (auto process_list_element = context->getProcessListElement())\n+        user_level_throttler = process_list_element->getUserNetworkThrottler();\n+\n+    /// Network bandwidth limit, if needed.\n+    ThrottlerPtr throttler;\n+    if (settings.max_network_bandwidth || settings.max_network_bytes)\n+    {\n+        throttler = std::make_shared<Throttler>(\n+                settings.max_network_bandwidth,\n+                settings.max_network_bytes,\n+                \"Limit for bytes to send or receive over network exceeded.\",\n+                user_level_throttler);\n+    }\n+    else\n+        throttler = user_level_throttler;\n+\n+    return throttler;\n+}\n+\n+\n void executeQuery(\n     QueryPlan & query_plan,\n     const Block & header,\n@@ -138,26 +169,8 @@ void executeQuery(\n     SelectStreamFactory::Shards remote_shards;\n \n     auto new_context = updateSettingsForCluster(*query_info.getCluster(), context, settings, main_table, &query_info, log);\n-\n     new_context->getClientInfo().distributed_depth += 1;\n \n-    ThrottlerPtr user_level_throttler;\n-    if (auto process_list_element = context->getProcessListElement())\n-        user_level_throttler = process_list_element->getUserNetworkThrottler();\n-\n-    /// Network bandwidth limit, if needed.\n-    ThrottlerPtr throttler;\n-    if (settings.max_network_bandwidth || settings.max_network_bytes)\n-    {\n-        throttler = std::make_shared<Throttler>(\n-                settings.max_network_bandwidth,\n-                settings.max_network_bytes,\n-                \"Limit for bytes to send or receive over network exceeded.\",\n-                user_level_throttler);\n-    }\n-    else\n-        throttler = user_level_throttler;\n-\n     size_t shards = query_info.getCluster()->getShardCount();\n     for (const auto & shard_info : query_info.getCluster()->getShardsInfo())\n     {\n@@ -199,7 +212,7 @@ void executeQuery(\n             main_table,\n             table_func_ptr,\n             new_context,\n-            throttler,\n+            getThrottler(context),\n             std::move(scalars),\n             std::move(external_tables),\n             log,\n@@ -236,103 +249,76 @@ void executeQueryWithParallelReplicas(\n     const StorageID & main_table,\n     const ASTPtr & table_func_ptr,\n     SelectStreamFactory & stream_factory,\n-    const ASTPtr & query_ast,\n-    ContextPtr context,\n-    const SelectQueryInfo & query_info,\n-    const ExpressionActionsPtr & sharding_key_expr,\n-    const std::string & sharding_key_column_name,\n-    const ClusterPtr & not_optimized_cluster,\n-    QueryProcessingStage::Enum processed_stage)\n+    const ASTPtr & query_ast, ContextPtr context, const SelectQueryInfo & query_info,\n+    const ClusterPtr & not_optimized_cluster)\n {\n-    const Settings & settings = context->getSettingsRef();\n-\n-    ThrottlerPtr user_level_throttler;\n-    if (auto process_list_element = context->getProcessListElement())\n-        user_level_throttler = process_list_element->getUserNetworkThrottler();\n-\n-    /// Network bandwidth limit, if needed.\n-    ThrottlerPtr throttler;\n-    if (settings.max_network_bandwidth || settings.max_network_bytes)\n-    {\n-        throttler = std::make_shared<Throttler>(\n-                settings.max_network_bandwidth,\n-                settings.max_network_bytes,\n-                \"Limit for bytes to send or receive over network exceeded.\",\n-                user_level_throttler);\n-    }\n-    else\n-        throttler = user_level_throttler;\n-\n-\n-    std::vector<QueryPlanPtr> plans;\n-    SelectStreamFactory::Shards remote_shards;\n-    size_t shards = query_info.getCluster()->getShardCount();\n-\n-    for (const auto & shard_info : query_info.getCluster()->getShardsInfo())\n-    {\n-        ASTPtr query_ast_for_shard;\n-        if (query_info.optimized_cluster && settings.optimize_skip_unused_shards_rewrite_in && shards > 1)\n-        {\n-            query_ast_for_shard = query_ast->clone();\n-\n-            OptimizeShardingKeyRewriteInVisitor::Data visitor_data{\n-                sharding_key_expr,\n-                sharding_key_expr->getSampleBlock().getByPosition(0).type,\n-                sharding_key_column_name,\n-                shard_info,\n-                not_optimized_cluster->getSlotToShard(),\n-            };\n-            OptimizeShardingKeyRewriteInVisitor visitor(visitor_data);\n-            visitor.visit(query_ast_for_shard);\n-        }\n-        else\n-            query_ast_for_shard = query_ast;\n-\n-        stream_factory.createForShardWithParallelReplicas(\n-            shard_info, query_ast_for_shard, main_table, context, static_cast<UInt32>(shards), plans, remote_shards);\n-    }\n-\n-    Scalars scalars = context->hasQueryContext() ? context->getQueryContext()->getScalars() : Scalars{};\n-    scalars.emplace(\n-        \"_shard_count\", Block{{DataTypeUInt32().createColumnConst(1, shards), std::make_shared<DataTypeUInt32>(), \"_shard_count\"}});\n-    auto external_tables = context->getExternalTables();\n-\n-    if (!remote_shards.empty())\n-    {\n-        auto new_context = Context::createCopy(context);\n-\n-        for (const auto & shard : remote_shards)\n-        {\n-            auto read_from_remote = std::make_unique<ReadFromParallelRemoteReplicasStep>(\n-                shard.coordinator,\n-                shard,\n-                shard.header,\n-                processed_stage,\n-                main_table,\n-                table_func_ptr,\n-                new_context,\n-                throttler,\n-                scalars,\n-                external_tables,\n-                &Poco::Logger::get(\"ReadFromParallelRemoteReplicasStep\"),\n-                query_info.storage_limits);\n-\n-            auto remote_plan = std::make_unique<QueryPlan>();\n-            remote_plan->addStep(std::move(read_from_remote));\n-            remote_plan->addInterpreterContext(new_context);\n-            plans.emplace_back(std::move(remote_plan));\n-        }\n-    }\n-\n-    if (plans.empty())\n-        throw Exception(ErrorCodes::LOGICAL_ERROR, \"No plans were generated for reading from Distributed. This is a bug\");\n-\n-    if (plans.size() == 1)\n+    if (not_optimized_cluster->getShardsInfo().size() != 1)\n+        throw Exception(ErrorCodes::SUPPORT_IS_DISABLED, \"Cluster for parallel replicas should consist only from one shard\");\n+\n+    auto shard_info = not_optimized_cluster->getShardsInfo().front();\n+\n+    const auto & settings = context->getSettingsRef();\n+    auto all_replicas_count = std::min(static_cast<size_t>(settings.max_parallel_replicas), shard_info.all_addresses.size());\n+    auto coordinator = std::make_shared<ParallelReplicasReadingCoordinator>(all_replicas_count);\n+    auto remote_plan = std::make_unique<QueryPlan>();\n+    auto plans = std::vector<QueryPlanPtr>();\n+\n+    /// This is a little bit weird, but we construct an \"empty\" coordinator without\n+    /// any specified reading/coordination method (like Default, InOrder, InReverseOrder)\n+    /// Because we will understand it later during QueryPlan optimization\n+    /// So we place a reference to the coordinator to some common plane like QueryInfo\n+    /// to then tell it about the reading method we chose.\n+    query_info.coordinator = coordinator;\n+\n+    UUID parallel_group_id = UUIDHelpers::generateV4();\n+\n+    plans.emplace_back(createLocalPlan(\n+        query_ast,\n+        stream_factory.header,\n+        context,\n+        stream_factory.processed_stage,\n+        shard_info.shard_num,\n+        /*shard_count*/1,\n+        0,\n+        all_replicas_count,\n+        coordinator,\n+        parallel_group_id));\n+\n+    if (!shard_info.hasRemoteConnections())\n     {\n+        if (!plans.front())\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"An empty plan was generated to read from local shard and there is no remote connections. This is a bug\");\n         query_plan = std::move(*plans.front());\n         return;\n     }\n \n+    auto new_context = Context::createCopy(context);\n+    auto scalars = new_context->hasQueryContext() ? new_context->getQueryContext()->getScalars() : Scalars{};\n+    auto external_tables = new_context->getExternalTables();\n+\n+    auto read_from_remote = std::make_unique<ReadFromParallelRemoteReplicasStep>(\n+        query_ast,\n+        std::move(shard_info),\n+        coordinator,\n+        stream_factory.header,\n+        stream_factory.processed_stage,\n+        main_table,\n+        table_func_ptr,\n+        new_context,\n+        getThrottler(new_context),\n+        std::move(scalars),\n+        std::move(external_tables),\n+        &Poco::Logger::get(\"ReadFromParallelRemoteReplicasStep\"),\n+        query_info.storage_limits,\n+        parallel_group_id);\n+\n+    remote_plan->addStep(std::move(read_from_remote));\n+    remote_plan->addInterpreterContext(context);\n+    plans.emplace_back(std::move(remote_plan));\n+\n+    if (std::all_of(plans.begin(), plans.end(), [](const QueryPlanPtr & plan) { return !plan; }))\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"No plans were generated for reading from shard. This is a bug\");\n+\n     DataStreams input_streams;\n     input_streams.reserve(plans.size());\n     for (const auto & plan : plans)\ndiff --git a/src/Interpreters/ClusterProxy/executeQuery.h b/src/Interpreters/ClusterProxy/executeQuery.h\nindex 662fe47ca651..787e79313cc0 100644\n--- a/src/Interpreters/ClusterProxy/executeQuery.h\n+++ b/src/Interpreters/ClusterProxy/executeQuery.h\n@@ -61,10 +61,7 @@ void executeQueryWithParallelReplicas(\n     const ASTPtr & query_ast,\n     ContextPtr context,\n     const SelectQueryInfo & query_info,\n-    const ExpressionActionsPtr & sharding_key_expr,\n-    const std::string & sharding_key_column_name,\n-    const ClusterPtr & not_optimized_cluster,\n-    QueryProcessingStage::Enum processed_stage);\n+    const ClusterPtr & not_optimized_cluster);\n }\n \n }\ndiff --git a/src/Interpreters/Context.cpp b/src/Interpreters/Context.cpp\nindex d9a7aa2e6773..4032590de711 100644\n--- a/src/Interpreters/Context.cpp\n+++ b/src/Interpreters/Context.cpp\n@@ -3621,6 +3621,32 @@ void Context::setMergeTreeReadTaskCallback(MergeTreeReadTaskCallback && callback\n     merge_tree_read_task_callback = callback;\n }\n \n+\n+MergeTreeAllRangesCallback Context::getMergeTreeAllRangesCallback() const\n+{\n+    if (!merge_tree_all_ranges_callback.has_value())\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Next task callback is not set for query with id: {}\", getInitialQueryId());\n+\n+    return merge_tree_all_ranges_callback.value();\n+}\n+\n+\n+void Context::setMergeTreeAllRangesCallback(MergeTreeAllRangesCallback && callback)\n+{\n+    merge_tree_all_ranges_callback = callback;\n+}\n+\n+\n+void Context::setParallelReplicasGroupUUID(UUID uuid)\n+{\n+    parallel_replicas_group_uuid = uuid;\n+}\n+\n+UUID Context::getParallelReplicasGroupUUID() const\n+{\n+    return parallel_replicas_group_uuid;\n+}\n+\n PartUUIDsPtr Context::getIgnoredPartUUIDs() const\n {\n     auto lock = getLock();\n@@ -3886,4 +3912,22 @@ WriteSettings Context::getWriteSettings() const\n     return res;\n }\n \n+bool Context::canUseParallelReplicasOnInitiator() const\n+{\n+    const auto & settings = getSettingsRef();\n+    return settings.allow_experimental_parallel_reading_from_replicas\n+        && settings.max_parallel_replicas > 1\n+        && !settings.use_hedged_requests\n+        && !getClientInfo().collaborate_with_initiator;\n+}\n+\n+bool Context::canUseParallelReplicasOnFollower() const\n+{\n+    const auto & settings = getSettingsRef();\n+    return settings.allow_experimental_parallel_reading_from_replicas\n+        && settings.max_parallel_replicas > 1\n+        && !settings.use_hedged_requests\n+        && getClientInfo().collaborate_with_initiator;\n+}\n+\n }\ndiff --git a/src/Interpreters/Context.h b/src/Interpreters/Context.h\nindex 00dc4204496b..d0eab42fec22 100644\n--- a/src/Interpreters/Context.h\n+++ b/src/Interpreters/Context.h\n@@ -1,5 +1,11 @@\n #pragma once\n \n+#include <base/types.h>\n+#include <Common/isLocalAddress.h>\n+#include <Common/MultiVersion.h>\n+#include <Common/OpenTelemetryTraceContext.h>\n+#include <Common/RemoteHostFilter.h>\n+#include <Common/ThreadPool.h>\n #include <Core/Block.h>\n #include <Core/NamesAndTypes.h>\n #include <Core/Settings.h>\n@@ -8,32 +14,24 @@\n #include <Interpreters/Context_fwd.h>\n #include <Interpreters/DatabaseCatalog.h>\n #include <Interpreters/MergeTreeTransactionHolder.h>\n-#include <Parsers/IAST_fwd.h>\n-#include <Parsers/ASTSelectQuery.h>\n-#include <Storages/IStorage_fwd.h>\n-#include <Common/MultiVersion.h>\n-#include <Common/OpenTelemetryTraceContext.h>\n-#include <Common/RemoteHostFilter.h>\n-#include <Common/ThreadPool.h>\n-#include <Common/isLocalAddress.h>\n-#include <base/types.h>\n-#include <Storages/MergeTree/ParallelReplicasReadingCoordinator.h>\n-#include <Storages/ColumnsDescription.h>\n #include <IO/IResourceManager.h>\n-\n+#include <Parsers/ASTSelectQuery.h>\n+#include <Parsers/IAST_fwd.h>\n+#include <Processors/ResizeProcessor.h>\n+#include <Processors/Transforms/ReadFromMergeTreeDependencyTransform.h>\n #include <Server/HTTP/HTTPContext.h>\n-\n+#include <Storages/ColumnsDescription.h>\n+#include <Storages/IStorage_fwd.h>\n \n #include \"config.h\"\n \n #include <boost/container/flat_set.hpp>\n+#include <exception>\n #include <functional>\n #include <memory>\n #include <mutex>\n #include <optional>\n-\n #include <thread>\n-#include <exception>\n \n \n namespace Poco::Net { class IPAddress; }\n@@ -98,7 +96,11 @@ class TransactionsInfoLog;\n class ProcessorsProfileLog;\n class FilesystemCacheLog;\n class AsynchronousInsertLog;\n+class IAsynchronousReader;\n struct MergeTreeSettings;\n+struct InitialAllRangesAnnouncement;\n+struct ParallelReadRequest;\n+struct ParallelReadResponse;\n class StorageS3Settings;\n class IDatabase;\n class DDLWorker;\n@@ -172,11 +174,15 @@ using InputBlocksReader = std::function<Block(ContextPtr)>;\n /// Used in distributed task processing\n using ReadTaskCallback = std::function<String()>;\n \n-using MergeTreeReadTaskCallback = std::function<std::optional<PartitionReadResponse>(PartitionReadRequest)>;\n+using MergeTreeAllRangesCallback = std::function<void(InitialAllRangesAnnouncement)>;\n+using MergeTreeReadTaskCallback = std::function<std::optional<ParallelReadResponse>(ParallelReadRequest)>;\n \n class TemporaryDataOnDiskScope;\n using TemporaryDataOnDiskScopePtr = std::shared_ptr<TemporaryDataOnDiskScope>;\n \n+class ParallelReplicasReadingCoordinator;\n+using ParallelReplicasReadingCoordinatorPtr = std::shared_ptr<ParallelReplicasReadingCoordinator>;\n+\n #if USE_ROCKSDB\n class MergeTreeMetadataCache;\n using MergeTreeMetadataCachePtr = std::shared_ptr<MergeTreeMetadataCache>;\n@@ -262,6 +268,8 @@ class Context: public std::enable_shared_from_this<Context>\n     /// Used in parallel reading from replicas. A replica tells about its intentions to read\n     /// some ranges from some part and initiator will tell the replica about whether it is accepted or denied.\n     std::optional<MergeTreeReadTaskCallback> merge_tree_read_task_callback;\n+    std::optional<MergeTreeAllRangesCallback> merge_tree_all_ranges_callback;\n+    UUID parallel_replicas_group_uuid{UUIDHelpers::Nil};\n \n     /// Record entities accessed by current query, and store this information in system.query_log.\n     struct QueryAccessInfo\n@@ -380,6 +388,7 @@ class Context: public std::enable_shared_from_this<Context>\n \n     /// Temporary data for query execution accounting.\n     TemporaryDataOnDiskScopePtr temp_data_on_disk;\n+\n public:\n     /// Some counters for current query execution.\n     /// Most of them are workarounds and should be removed in the future.\n@@ -402,6 +411,8 @@ class Context: public std::enable_shared_from_this<Context>\n \n     KitchenSink kitchen_sink;\n \n+    ParallelReplicasReadingCoordinatorPtr parallel_reading_coordinator;\n+\n private:\n     using SampleBlockCache = std::unordered_map<std::string, Block>;\n     mutable SampleBlockCache sample_block_cache;\n@@ -1045,6 +1056,12 @@ class Context: public std::enable_shared_from_this<Context>\n     MergeTreeReadTaskCallback getMergeTreeReadTaskCallback() const;\n     void setMergeTreeReadTaskCallback(MergeTreeReadTaskCallback && callback);\n \n+    MergeTreeAllRangesCallback getMergeTreeAllRangesCallback() const;\n+    void setMergeTreeAllRangesCallback(MergeTreeAllRangesCallback && callback);\n+\n+    UUID getParallelReplicasGroupUUID() const;\n+    void setParallelReplicasGroupUUID(UUID uuid);\n+\n     /// Background executors related methods\n     void initializeBackgroundExecutorsIfNeeded();\n     bool areBackgroundExecutorsInitialized();\n@@ -1071,6 +1088,10 @@ class Context: public std::enable_shared_from_this<Context>\n     /** Get settings for writing to filesystem. */\n     WriteSettings getWriteSettings() const;\n \n+    /** There are multiple conditions that have to be met to be able to use parallel replicas */\n+    bool canUseParallelReplicasOnInitiator() const;\n+    bool canUseParallelReplicasOnFollower() const;\n+\n private:\n     std::unique_lock<std::recursive_mutex> getLock() const;\n \ndiff --git a/src/Interpreters/InterpreterSelectQuery.cpp b/src/Interpreters/InterpreterSelectQuery.cpp\nindex 8e11da479c08..2ce116f77962 100644\n--- a/src/Interpreters/InterpreterSelectQuery.cpp\n+++ b/src/Interpreters/InterpreterSelectQuery.cpp\n@@ -448,6 +448,16 @@ InterpreterSelectQuery::InterpreterSelectQuery(\n         }\n     }\n \n+    /// FIXME: Memory bound aggregation may cause another reading algorithm to be used on remote replicas\n+    if (settings.allow_experimental_parallel_reading_from_replicas && settings.enable_memory_bound_merging_of_aggregation_results)\n+        context->setSetting(\"enable_memory_bound_merging_of_aggregation_results\", false);\n+\n+    if (joined_tables.tablesCount() > 1 && settings.allow_experimental_parallel_reading_from_replicas)\n+    {\n+        LOG_WARNING(log, \"Joins are not supported with parallel replicas. Query will be executed without using them.\");\n+        context->setSetting(\"allow_experimental_parallel_reading_from_replicas\", false);\n+    }\n+\n     /// Rewrite JOINs\n     if (!has_input && joined_tables.tablesCount() > 1)\n     {\n@@ -543,6 +553,7 @@ InterpreterSelectQuery::InterpreterSelectQuery(\n             parameter_values,\n             parameter_types);\n \n+\n         query_info.syntax_analyzer_result = syntax_analyzer_result;\n         context->setDistributed(syntax_analyzer_result->is_remote_storage);\n \n@@ -1902,22 +1913,6 @@ void InterpreterSelectQuery::addEmptySourceToQueryPlan(\n     }\n }\n \n-void InterpreterSelectQuery::setMergeTreeReadTaskCallbackAndClientInfo(MergeTreeReadTaskCallback && callback)\n-{\n-    context->getClientInfo().collaborate_with_initiator = true;\n-    context->setMergeTreeReadTaskCallback(std::move(callback));\n-}\n-\n-void InterpreterSelectQuery::setProperClientInfo(size_t replica_num, size_t replica_count)\n-{\n-    context->getClientInfo().query_kind = ClientInfo::QueryKind::SECONDARY_QUERY;\n-    context->getClientInfo().count_participating_replicas = replica_count;\n-    context->getClientInfo().number_of_current_replica = replica_num;\n-    context->getClientInfo().connection_client_version_major = DBMS_VERSION_MAJOR;\n-    context->getClientInfo().connection_client_version_minor = DBMS_VERSION_MINOR;\n-    context->getClientInfo().connection_tcp_protocol_version = DBMS_TCP_PROTOCOL_VERSION;\n-}\n-\n RowPolicyFilterPtr InterpreterSelectQuery::getRowPolicyFilter() const\n {\n     return row_policy_filter;\n@@ -2572,12 +2567,13 @@ void InterpreterSelectQuery::executeMergeAggregated(QueryPlan & query_plan, bool\n \n     const bool should_produce_results_in_order_of_bucket_number = options.to_stage == QueryProcessingStage::WithMergeableState\n         && (settings.distributed_aggregation_memory_efficient || settings.enable_memory_bound_merging_of_aggregation_results);\n+    const bool parallel_replicas_from_merge_tree = storage->isMergeTree() && context->canUseParallelReplicasOnInitiator();\n \n     executeMergeAggregatedImpl(\n         query_plan,\n         overflow_row,\n         final,\n-        storage && storage->isRemote(),\n+        storage && (storage->isRemote() || parallel_replicas_from_merge_tree),\n         has_grouping_sets,\n         context->getSettingsRef(),\n         query_analyzer->aggregationKeys(),\ndiff --git a/src/Interpreters/InterpreterSelectQuery.h b/src/Interpreters/InterpreterSelectQuery.h\nindex 761eea8e1b8a..0ab1ba58e0ff 100644\n--- a/src/Interpreters/InterpreterSelectQuery.h\n+++ b/src/Interpreters/InterpreterSelectQuery.h\n@@ -122,16 +122,6 @@ class InterpreterSelectQuery : public IInterpreterUnionOrSelectQuery\n \n     bool supportsTransactions() const override { return true; }\n \n-    /// This is tiny crutch to support reading from localhost replica during distributed query\n-    /// Replica need to talk to the initiator through a connection to ask for a next task\n-    /// but there will be no connection if we create Interpreter explicitly.\n-    /// The other problem is that context is copied inside Interpreter's constructor\n-    /// And with this method we can change the internals of cloned one\n-    void setMergeTreeReadTaskCallbackAndClientInfo(MergeTreeReadTaskCallback && callback);\n-\n-    /// It will set shard_num and shard_count to the client_info\n-    void setProperClientInfo(size_t replica_num, size_t replica_count);\n-\n     FilterDAGInfoPtr getAdditionalQueryInfo() const { return additional_filter_info; }\n \n     RowPolicyFilterPtr getRowPolicyFilter() const;\ndiff --git a/src/Interpreters/InterpreterSelectQueryAnalyzer.cpp b/src/Interpreters/InterpreterSelectQueryAnalyzer.cpp\nindex 85bc70e93829..6b6f3560c5ab 100644\n--- a/src/Interpreters/InterpreterSelectQueryAnalyzer.cpp\n+++ b/src/Interpreters/InterpreterSelectQueryAnalyzer.cpp\n@@ -135,20 +135,4 @@ void InterpreterSelectQueryAnalyzer::addStorageLimits(const StorageLimitsList &\n     planner.addStorageLimits(storage_limits);\n }\n \n-void InterpreterSelectQueryAnalyzer::setMergeTreeReadTaskCallbackAndClientInfo(MergeTreeReadTaskCallback && callback)\n-{\n-    context->getClientInfo().collaborate_with_initiator = true;\n-    context->setMergeTreeReadTaskCallback(std::move(callback));\n-}\n-\n-void InterpreterSelectQueryAnalyzer::setProperClientInfo(size_t replica_number, size_t count_participating_replicas)\n-{\n-    context->getClientInfo().query_kind = ClientInfo::QueryKind::SECONDARY_QUERY;\n-    context->getClientInfo().number_of_current_replica = replica_number;\n-    context->getClientInfo().count_participating_replicas = count_participating_replicas;\n-    context->getClientInfo().connection_client_version_major = DBMS_VERSION_MAJOR;\n-    context->getClientInfo().connection_client_version_minor = DBMS_VERSION_MINOR;\n-    context->getClientInfo().connection_tcp_protocol_version = DBMS_TCP_PROTOCOL_VERSION;\n-}\n-\n }\ndiff --git a/src/Interpreters/interpretSubquery.cpp b/src/Interpreters/interpretSubquery.cpp\nindex 5f00be07fa5d..2358b0ab42a3 100644\n--- a/src/Interpreters/interpretSubquery.cpp\n+++ b/src/Interpreters/interpretSubquery.cpp\n@@ -112,6 +112,8 @@ std::shared_ptr<InterpreterSelectWithUnionQuery> interpretSubquery(\n         subquery_options.removeDuplicates();\n     }\n \n+    /// We don't want to execute reading for subqueries in parallel\n+    subquery_context->setSetting(\"allow_experimental_parallel_reading_from_replicas\", false);\n     return std::make_shared<InterpreterSelectWithUnionQuery>(query, subquery_context, subquery_options, required_source_columns);\n }\n \ndiff --git a/src/Processors/QueryPlan/DistributedCreateLocalPlan.cpp b/src/Processors/QueryPlan/DistributedCreateLocalPlan.cpp\nindex 166b021b5cee..2bb29a0b6fee 100644\n--- a/src/Processors/QueryPlan/DistributedCreateLocalPlan.cpp\n+++ b/src/Processors/QueryPlan/DistributedCreateLocalPlan.cpp\n@@ -1,9 +1,12 @@\n #include <Processors/QueryPlan/DistributedCreateLocalPlan.h>\n+\n+#include \"config_version.h\"\n #include <Common/checkStackSize.h>\n-#include <Processors/QueryPlan/ExpressionStep.h>\n+#include <Core/ProtocolDefines.h>\n #include <Interpreters/ActionsDAG.h>\n #include <Interpreters/InterpreterSelectQuery.h>\n #include <Interpreters/InterpreterSelectQueryAnalyzer.h>\n+#include <Processors/QueryPlan/ExpressionStep.h>\n \n namespace DB\n {\n@@ -40,48 +43,58 @@ std::unique_ptr<QueryPlan> createLocalPlan(\n     const Block & header,\n     ContextPtr context,\n     QueryProcessingStage::Enum processed_stage,\n-    UInt32 shard_num,\n-    UInt32 shard_count,\n+    size_t shard_num,\n+    size_t shard_count,\n     size_t replica_num,\n     size_t replica_count,\n-    std::shared_ptr<ParallelReplicasReadingCoordinator> coordinator)\n+    std::shared_ptr<ParallelReplicasReadingCoordinator> coordinator,\n+    UUID group_uuid)\n {\n     checkStackSize();\n \n     auto query_plan = std::make_unique<QueryPlan>();\n+    auto new_context = Context::createCopy(context);\n \n     /// Do not apply AST optimizations, because query\n     /// is already optimized and some optimizations\n     /// can be applied only for non-distributed tables\n     /// and we can produce query, inconsistent with remote plans.\n     auto select_query_options = SelectQueryOptions(processed_stage)\n-        .setShardInfo(shard_num, shard_count)\n+        .setShardInfo(static_cast<UInt32>(shard_num), static_cast<UInt32>(shard_count))\n         .ignoreASTOptimizations();\n \n-    auto update_interpreter = [&](auto & interpreter)\n+    /// There are much things that are needed for coordination\n+    /// during reading with parallel replicas\n+    if (coordinator)\n     {\n-        interpreter.setProperClientInfo(replica_num, replica_count);\n-        if (coordinator)\n+        new_context->parallel_reading_coordinator = coordinator;\n+        new_context->getClientInfo().interface = ClientInfo::Interface::LOCAL;\n+        new_context->getClientInfo().collaborate_with_initiator = true;\n+        new_context->getClientInfo().query_kind = ClientInfo::QueryKind::SECONDARY_QUERY;\n+        new_context->getClientInfo().count_participating_replicas = replica_count;\n+        new_context->getClientInfo().number_of_current_replica = replica_num;\n+        new_context->getClientInfo().connection_client_version_major = DBMS_VERSION_MAJOR;\n+        new_context->getClientInfo().connection_client_version_minor = DBMS_VERSION_MINOR;\n+        new_context->getClientInfo().connection_tcp_protocol_version = DBMS_TCP_PROTOCOL_VERSION;\n+        new_context->setParallelReplicasGroupUUID(group_uuid);\n+        new_context->setMergeTreeAllRangesCallback([coordinator](InitialAllRangesAnnouncement announcement)\n         {\n-            interpreter.setMergeTreeReadTaskCallbackAndClientInfo([coordinator](PartitionReadRequest request) -> std::optional<PartitionReadResponse>\n-            {\n-                return coordinator->handleRequest(request);\n-            });\n-        }\n-    };\n+            coordinator->handleInitialAllRangesAnnouncement(announcement);\n+        });\n+        new_context->setMergeTreeReadTaskCallback([coordinator](ParallelReadRequest request) -> std::optional<ParallelReadResponse>\n+        {\n+            return coordinator->handleRequest(request);\n+        });\n+    }\n \n     if (context->getSettingsRef().allow_experimental_analyzer)\n     {\n-        auto interpreter = InterpreterSelectQueryAnalyzer(query_ast, context, select_query_options);\n-        update_interpreter(interpreter);\n+        auto interpreter = InterpreterSelectQueryAnalyzer(query_ast, new_context, select_query_options);\n         query_plan = std::make_unique<QueryPlan>(std::move(interpreter).extractQueryPlan());\n     }\n     else\n     {\n-        auto interpreter = InterpreterSelectQuery(\n-            query_ast, context,\n-            select_query_options);\n-        update_interpreter(interpreter);\n+        auto interpreter = InterpreterSelectQuery(query_ast, new_context, select_query_options);\n         interpreter.buildQueryPlan(*query_plan);\n     }\n \ndiff --git a/src/Processors/QueryPlan/DistributedCreateLocalPlan.h b/src/Processors/QueryPlan/DistributedCreateLocalPlan.h\nindex b55cedf98710..16bf1c565ffb 100644\n--- a/src/Processors/QueryPlan/DistributedCreateLocalPlan.h\n+++ b/src/Processors/QueryPlan/DistributedCreateLocalPlan.h\n@@ -3,6 +3,7 @@\n #include <Core/QueryProcessingStage.h>\n #include <Parsers/IAST_fwd.h>\n #include <Processors/QueryPlan/QueryPlan.h>\n+#include <Processors/ResizeProcessor.h>\n #include <Storages/MergeTree/ParallelReplicasReadingCoordinator.h>\n \n namespace DB\n@@ -13,10 +14,11 @@ std::unique_ptr<QueryPlan> createLocalPlan(\n     const Block & header,\n     ContextPtr context,\n     QueryProcessingStage::Enum processed_stage,\n-    UInt32 shard_num,\n-    UInt32 shard_count,\n+    size_t shard_num,\n+    size_t shard_count,\n     size_t replica_num,\n     size_t replica_count,\n-    std::shared_ptr<ParallelReplicasReadingCoordinator> coordinator);\n+    std::shared_ptr<ParallelReplicasReadingCoordinator> coordinator,\n+    UUID group_uuid = UUIDHelpers::Nil);\n \n }\ndiff --git a/src/Processors/QueryPlan/Optimizations/optimizeReadInOrder.cpp b/src/Processors/QueryPlan/Optimizations/optimizeReadInOrder.cpp\nindex bdf8f24f9d68..301c3bca571c 100644\n--- a/src/Processors/QueryPlan/Optimizations/optimizeReadInOrder.cpp\n+++ b/src/Processors/QueryPlan/Optimizations/optimizeReadInOrder.cpp\n@@ -1005,8 +1005,6 @@ InputOrderInfoPtr buildInputOrderInfo(SortingStep & sorting, QueryPlan::Node & n\n \n     if (auto * reading = typeid_cast<ReadFromMergeTree *>(reading_node->step.get()))\n     {\n-\n-        //std::cerr << \"---- optimizeReadInOrder found mt\" << std::endl;\n         auto order_info = buildInputOrderInfo(\n             reading,\n             fixed_columns,\ndiff --git a/src/Processors/QueryPlan/Optimizations/optimizeTree.cpp b/src/Processors/QueryPlan/Optimizations/optimizeTree.cpp\nindex 13095dfad47e..0378c5ef416b 100644\n--- a/src/Processors/QueryPlan/Optimizations/optimizeTree.cpp\n+++ b/src/Processors/QueryPlan/Optimizations/optimizeTree.cpp\n@@ -1,8 +1,9 @@\n-#include <Processors/QueryPlan/Optimizations/Optimizations.h>\n-#include <Processors/QueryPlan/Optimizations/QueryPlanOptimizationSettings.h>\n #include <Common/Exception.h>\n #include <Processors/QueryPlan/MergingAggregatedStep.h>\n+#include <Processors/QueryPlan/Optimizations/Optimizations.h>\n+#include <Processors/QueryPlan/Optimizations/QueryPlanOptimizationSettings.h>\n #include <Processors/QueryPlan/UnionStep.h>\n+\n #include <stack>\n \n namespace DB\ndiff --git a/src/Processors/QueryPlan/PartsSplitter.cpp b/src/Processors/QueryPlan/PartsSplitter.cpp\nindex e7ea7a4e34bb..917bea4c8841 100644\n--- a/src/Processors/QueryPlan/PartsSplitter.cpp\n+++ b/src/Processors/QueryPlan/PartsSplitter.cpp\n@@ -13,6 +13,7 @@\n #include <Processors/QueryPlan/PartsSplitter.h>\n #include <Processors/Transforms/FilterSortedStreamByRange.h>\n #include <Storages/MergeTree/RangesInDataPart.h>\n+#include <Storages/MergeTree/IMergeTreeDataPart.h>\n \n using namespace DB;\n \n@@ -77,7 +78,7 @@ std::pair<std::vector<Values>, std::vector<RangesInDataParts>> split(RangesInDat\n             RangeEnd,\n         };\n \n-        bool operator<(const PartsRangesIterator & other) const { return std::tie(value, event) > std::tie(other.value, other.event); }\n+        [[ maybe_unused ]] bool operator<(const PartsRangesIterator & other) const { return std::tie(value, event) > std::tie(other.value, other.event); }\n \n         Values value;\n         MarkRangeWithPartIdx range;\ndiff --git a/src/Processors/QueryPlan/QueryPlan.cpp b/src/Processors/QueryPlan/QueryPlan.cpp\nindex e817a9ef8a9b..48a9fbd7a346 100644\n--- a/src/Processors/QueryPlan/QueryPlan.cpp\n+++ b/src/Processors/QueryPlan/QueryPlan.cpp\n@@ -166,6 +166,7 @@ QueryPipelineBuilderPtr QueryPlan::buildQueryPipeline(\n \n     QueryPipelineBuilderPtr last_pipeline;\n \n+\n     std::stack<Frame> stack;\n     stack.push(Frame{.node = root});\n \n@@ -198,6 +199,13 @@ QueryPipelineBuilderPtr QueryPlan::buildQueryPipeline(\n     last_pipeline->setProcessListElement(build_pipeline_settings.process_list_element);\n     last_pipeline->addResources(std::move(resources));\n \n+    /// This is related to parallel replicas.\n+    /// Not to let the remote sources starve for CPU we create an\n+    /// explicit dependency between processors which read from local replica\n+    /// and ones that receive data from remote replicas and constantly answer\n+    /// to coordination packets.\n+    last_pipeline->connectDependencies();\n+\n     return last_pipeline;\n }\n \ndiff --git a/src/Processors/QueryPlan/ReadFromMergeTree.cpp b/src/Processors/QueryPlan/ReadFromMergeTree.cpp\nindex 22245b82966a..cca8e5297eea 100644\n--- a/src/Processors/QueryPlan/ReadFromMergeTree.cpp\n+++ b/src/Processors/QueryPlan/ReadFromMergeTree.cpp\n@@ -1,16 +1,18 @@\n-#include <algorithm>\n-#include <functional>\n-#include <memory>\n-#include <numeric>\n-#include <queue>\n-#include <stdexcept>\n-#include <IO/Operators.h>\n+#include <Storages/MergeTree/MergeTreeReadPool.h>\n+\n+#include <base/sort.h>\n+#include <Common/JSONBuilder.h>\n+#include <Common/logger_useful.h>\n+#include <Common/isLocalAddress.h>\n+#include \"Storages/MergeTree/RequestResponse.h\"\n+#include <Interpreters/Context.h>\n #include <Interpreters/ExpressionAnalyzer.h>\n #include <Interpreters/TreeRewriter.h>\n-#include <Interpreters/Context.h>\n+#include <IO/Operators.h>\n #include <Parsers/ASTFunction.h>\n #include <Parsers/ASTIdentifier.h>\n #include <Parsers/ASTSelectQuery.h>\n+#include <Poco/Logger.h>\n #include <Processors/ConcatProcessor.h>\n #include <Processors/Merges/AggregatingSortedTransform.h>\n #include <Processors/Merges/CollapsingSortedTransform.h>\n@@ -25,18 +27,22 @@\n #include <Processors/Transforms/ExpressionTransform.h>\n #include <Processors/Transforms/FilterTransform.h>\n #include <Processors/Transforms/ReverseTransform.h>\n+#include <Processors/Transforms/ReadFromMergeTreeDependencyTransform.h>\n #include <QueryPipeline/QueryPipelineBuilder.h>\n #include <Storages/MergeTree/MergeTreeDataSelectExecutor.h>\n #include <Storages/MergeTree/MergeTreeInOrderSelectProcessor.h>\n-#include <Storages/MergeTree/MergeTreeReadPool.h>\n #include <Storages/MergeTree/MergeTreeReverseSelectProcessor.h>\n #include <Storages/MergeTree/MergeTreeThreadSelectProcessor.h>\n #include <Storages/MergeTree/MergeTreeSource.h>\n+#include <Storages/MergeTree/RangesInDataPart.h>\n #include <Storages/VirtualColumnUtils.h>\n-#include <Common/logger_useful.h>\n-#include <base/sort.h>\n-#include <Poco/Logger.h>\n-#include <Common/JSONBuilder.h>\n+\n+#include <algorithm>\n+#include <functional>\n+#include <memory>\n+#include <numeric>\n+#include <queue>\n+#include <stdexcept>\n \n namespace ProfileEvents\n {\n@@ -114,6 +120,7 @@ ReadFromMergeTree::ReadFromMergeTree(\n     , max_block_numbers_to_read(std::move(max_block_numbers_to_read_))\n     , log(log_)\n     , analyzed_result_ptr(analyzed_result_ptr_)\n+    , is_parallel_reading_from_replicas(enable_parallel_reading)\n {\n     if (sample_factor_column_queried)\n     {\n@@ -123,8 +130,11 @@ ReadFromMergeTree::ReadFromMergeTree(\n         output_stream->header.insert({type->createColumn(), type, \"_sample_factor\"});\n     }\n \n-    if (enable_parallel_reading)\n+    if (is_parallel_reading_from_replicas)\n+    {\n+        all_ranges_callback = context->getMergeTreeAllRangesCallback();\n         read_task_callback = context->getMergeTreeReadTaskCallback();\n+    }\n \n     const auto & settings = context->getSettingsRef();\n     if (settings.max_streams_for_merge_tree_reading)\n@@ -173,30 +183,107 @@ ReadFromMergeTree::ReadFromMergeTree(\n     }\n }\n \n-Pipe ReadFromMergeTree::readFromPool(\n+\n+Pipe ReadFromMergeTree::readFromPoolParallelReplicas(\n     RangesInDataParts parts_with_range,\n     Names required_columns,\n     size_t max_streams,\n     size_t min_marks_for_concurrent_read,\n-    bool use_uncompressed_cache)\n+    bool use_uncompressed_cache\n+)\n {\n+    const auto & client_info = context->getClientInfo();\n+    auto extension = ParallelReadingExtension\n+    {\n+        .all_callback = all_ranges_callback.value(),\n+        .callback = read_task_callback.value(),\n+        .count_participating_replicas = client_info.count_participating_replicas,\n+        .number_of_current_replica = client_info.number_of_current_replica,\n+        .colums_to_read = required_columns\n+    };\n+\n+    /// We have a special logic for local replica. It has to read less data, because in some cases it should\n+    /// merge states of aggregate functions or do some other important stuff other than reading from Disk.\n+    auto is_local_replica = context->getClientInfo().interface == ClientInfo::Interface::LOCAL;\n+    if (!is_local_replica)\n+        min_marks_for_concurrent_read = static_cast<size_t>(min_marks_for_concurrent_read * context->getSettingsRef().parallel_replicas_single_task_marks_count_multiplier);\n+\n+    auto pool = std::make_shared<MergeTreeReadPoolParallelReplicas>(\n+        storage_snapshot,\n+        max_streams,\n+        extension,\n+        parts_with_range,\n+        prewhere_info,\n+        required_columns,\n+        virt_column_names,\n+        min_marks_for_concurrent_read\n+    );\n+\n     Pipes pipes;\n-    size_t sum_marks = 0;\n-    size_t total_rows = 0;\n+    const auto & settings = context->getSettingsRef();\n+    size_t total_rows = parts_with_range.getRowsCountAllParts();\n \n-    for (const auto & part : parts_with_range)\n+    for (size_t i = 0; i < max_streams; ++i)\n     {\n-        sum_marks += part.getMarksCount();\n-        total_rows += part.getRowsCount();\n+        auto algorithm = std::make_unique<MergeTreeThreadSelectAlgorithm>(\n+            i, pool, min_marks_for_concurrent_read, max_block_size,\n+            settings.preferred_block_size_bytes, settings.preferred_max_column_in_block_size_bytes,\n+            data, storage_snapshot, use_uncompressed_cache,\n+            prewhere_info, actions_settings, reader_settings, virt_column_names);\n+\n+        auto source = std::make_shared<MergeTreeSource>(std::move(algorithm));\n+\n+        /// Set the approximate number of rows for the first source only\n+        /// In case of parallel processing on replicas do not set approximate rows at all.\n+        /// Because the value will be identical on every replicas and will be accounted\n+        /// multiple times (settings.max_parallel_replicas times more)\n+        if (i == 0 && !client_info.collaborate_with_initiator)\n+            source->addTotalRowsApprox(total_rows);\n+\n+        pipes.emplace_back(std::move(source));\n+\n+        /// Add a special dependency transform which will be connected later with\n+        /// all RemoteSources through a simple scheduler (ResizeProcessor)\n+        if (context->getClientInfo().interface == ClientInfo::Interface::LOCAL)\n+        {\n+            pipes.back().addSimpleTransform([&](const Block & header) -> ProcessorPtr\n+            {\n+                return std::make_shared<ReadFromMergeTreeDependencyTransform>(header, context->getParallelReplicasGroupUUID());\n+            });\n+        }\n     }\n \n+    return Pipe::unitePipes(std::move(pipes));\n+}\n+\n+\n+Pipe ReadFromMergeTree::readFromPool(\n+    RangesInDataParts parts_with_range,\n+    Names required_columns,\n+    size_t max_streams,\n+    size_t min_marks_for_concurrent_read,\n+    bool use_uncompressed_cache)\n+{\n+    Pipes pipes;\n+    size_t sum_marks = parts_with_range.getMarksCountAllParts();\n+    size_t total_rows = parts_with_range.getRowsCountAllParts();\n+\n     if (query_info.limit > 0 && query_info.limit < total_rows)\n         total_rows = query_info.limit;\n \n     const auto & settings = context->getSettingsRef();\n-    const auto & client_info = context->getClientInfo();\n     MergeTreeReadPool::BackoffSettings backoff_settings(settings);\n \n+    /// round min_marks_to_read up to nearest multiple of block_size expressed in marks\n+    /// If granularity is adaptive it doesn't make sense\n+    /// Maybe it will make sense to add settings `max_block_size_bytes`\n+    if (max_block_size && !data.canUseAdaptiveGranularity())\n+    {\n+        size_t fixed_index_granularity = data.getSettings()->index_granularity;\n+        min_marks_for_concurrent_read = (min_marks_for_concurrent_read * fixed_index_granularity + max_block_size - 1)\n+            / max_block_size * max_block_size / fixed_index_granularity;\n+    }\n+\n     auto pool = std::make_shared<MergeTreeReadPool>(\n         max_streams,\n         sum_marks,\n@@ -215,34 +302,17 @@ Pipe ReadFromMergeTree::readFromPool(\n \n     for (size_t i = 0; i < max_streams; ++i)\n     {\n-        std::optional<ParallelReadingExtension> extension;\n-        if (read_task_callback)\n-        {\n-            extension = ParallelReadingExtension\n-            {\n-                .callback = read_task_callback.value(),\n-                .count_participating_replicas = client_info.count_participating_replicas,\n-                .number_of_current_replica = client_info.number_of_current_replica,\n-                .colums_to_read = required_columns\n-            };\n-        }\n-\n         auto algorithm = std::make_unique<MergeTreeThreadSelectAlgorithm>(\n             i, pool, min_marks_for_concurrent_read, max_block_size,\n             settings.preferred_block_size_bytes, settings.preferred_max_column_in_block_size_bytes,\n             data, storage_snapshot, use_uncompressed_cache,\n-            prewhere_info, actions_settings, reader_settings, virt_column_names, std::move(extension));\n+            prewhere_info, actions_settings, reader_settings, virt_column_names);\n \n         auto source = std::make_shared<MergeTreeSource>(std::move(algorithm));\n \n-        /// Set the approximate number of rows for the first source only\n-        /// In case of parallel processing on replicas do not set approximate rows at all.\n-        /// Because the value will be identical on every replicas and will be accounted\n-        /// multiple times (settings.max_parallel_replicas times more)\n-        if (i == 0 && !client_info.collaborate_with_initiator)\n+        if (i == 0)\n             source->addTotalRowsApprox(total_rows);\n \n-\n         pipes.emplace_back(std::move(source));\n     }\n \n@@ -257,21 +327,9 @@ ProcessorPtr ReadFromMergeTree::createSource(\n     const RangesInDataPart & part,\n     const Names & required_columns,\n     bool use_uncompressed_cache,\n-    bool has_limit_below_one_block)\n+    bool has_limit_below_one_block,\n+    MergeTreeInOrderReadPoolParallelReplicasPtr pool)\n {\n-    const auto & client_info = context->getClientInfo();\n-    std::optional<ParallelReadingExtension> extension;\n-    if (read_task_callback)\n-    {\n-        extension = ParallelReadingExtension\n-        {\n-            .callback = read_task_callback.value(),\n-            .count_participating_replicas = client_info.count_participating_replicas,\n-            .number_of_current_replica = client_info.number_of_current_replica,\n-            .colums_to_read = required_columns\n-        };\n-    }\n-\n     auto total_rows = part.getRowsCount();\n     if (query_info.limit > 0 && query_info.limit < total_rows)\n         total_rows = query_info.limit;\n@@ -281,12 +339,12 @@ ProcessorPtr ReadFromMergeTree::createSource(\n     /// In this case we won't set approximate rows, because it will be accounted multiple times.\n     /// Also do not count amount of read rows if we read in order of sorting key,\n     /// because we don't know actual amount of read rows in case when limit is set.\n-    bool set_rows_approx = !extension.has_value() && !reader_settings.read_in_order;\n+    bool set_rows_approx = !is_parallel_reading_from_replicas && !reader_settings.read_in_order;\n \n     auto algorithm = std::make_unique<Algorithm>(\n             data, storage_snapshot, part.data_part, max_block_size, preferred_block_size_bytes,\n             preferred_max_column_in_block_size_bytes, required_columns, part.ranges, use_uncompressed_cache, prewhere_info,\n-            actions_settings, reader_settings, virt_column_names, part.part_index_in_query, has_limit_below_one_block, std::move(extension));\n+            actions_settings, reader_settings, pool, virt_column_names, part.part_index_in_query, has_limit_below_one_block);\n \n     auto source = std::make_shared<MergeTreeSource>(std::move(algorithm));\n \n@@ -301,7 +359,8 @@ Pipe ReadFromMergeTree::readInOrder(\n     Names required_columns,\n     ReadType read_type,\n     bool use_uncompressed_cache,\n-    UInt64 limit)\n+    UInt64 limit,\n+    MergeTreeInOrderReadPoolParallelReplicasPtr pool)\n {\n     Pipes pipes;\n     /// For reading in order it makes sense to read only\n@@ -311,8 +370,8 @@ Pipe ReadFromMergeTree::readInOrder(\n     for (const auto & part : parts_with_range)\n     {\n         auto source = read_type == ReadType::InReverseOrder\n-                    ? createSource<MergeTreeReverseSelectAlgorithm>(part, required_columns, use_uncompressed_cache, has_limit_below_one_block)\n-                    : createSource<MergeTreeInOrderSelectAlgorithm>(part, required_columns, use_uncompressed_cache, has_limit_below_one_block);\n+                    ? createSource<MergeTreeReverseSelectAlgorithm>(part, required_columns, use_uncompressed_cache, has_limit_below_one_block, pool)\n+                    : createSource<MergeTreeInOrderSelectAlgorithm>(part, required_columns, use_uncompressed_cache, has_limit_below_one_block, pool);\n \n         pipes.emplace_back(std::move(source));\n     }\n@@ -334,11 +393,14 @@ Pipe ReadFromMergeTree::read(\n     RangesInDataParts parts_with_range, Names required_columns, ReadType read_type,\n     size_t max_streams, size_t min_marks_for_concurrent_read, bool use_uncompressed_cache)\n {\n+    if (read_type == ReadType::ParallelReplicas)\n+        return readFromPoolParallelReplicas(parts_with_range, required_columns, max_streams, min_marks_for_concurrent_read, use_uncompressed_cache);\n+\n     if (read_type == ReadType::Default && max_streams > 1)\n         return readFromPool(parts_with_range, required_columns, max_streams,\n                             min_marks_for_concurrent_read, use_uncompressed_cache);\n \n-    auto pipe = readInOrder(parts_with_range, required_columns, read_type, use_uncompressed_cache, 0);\n+    auto pipe = readInOrder(parts_with_range, required_columns, read_type, use_uncompressed_cache, /*limit  */0, /*pool*/nullptr);\n \n     /// Use ConcatProcessor to concat sources together.\n     /// It is needed to read in parts order (and so in PK order) if single thread is used.\n@@ -425,6 +487,8 @@ Pipe ReadFromMergeTree::spreadMarkRangesAmongStreams(\n     const auto & settings = context->getSettingsRef();\n     const auto data_settings = data.getSettings();\n \n+    LOG_TRACE(log, \"Spreading mark ranges among streams (default reading)\");\n+\n     PartRangesReadInfo info(parts_with_ranges, settings, *data_settings);\n \n     if (0 == info.sum_marks)\n@@ -438,7 +502,9 @@ Pipe ReadFromMergeTree::spreadMarkRangesAmongStreams(\n             num_streams = std::max((info.sum_marks + info.min_marks_for_concurrent_read - 1) / info.min_marks_for_concurrent_read, parts_with_ranges.size());\n     }\n \n-    return read(std::move(parts_with_ranges), column_names, ReadType::Default,\n+    auto read_type = is_parallel_reading_from_replicas ? ReadType::ParallelReplicas : ReadType::Default;\n+\n+    return read(std::move(parts_with_ranges), column_names, read_type,\n                 num_streams, info.min_marks_for_concurrent_read, info.use_uncompressed_cache);\n }\n \n@@ -459,6 +525,8 @@ Pipe ReadFromMergeTree::spreadMarkRangesAmongStreamsWithOrder(\n     const auto & settings = context->getSettingsRef();\n     const auto data_settings = data.getSettings();\n \n+    LOG_TRACE(log, \"Spreading ranges among streams with order\");\n+\n     PartRangesReadInfo info(parts_with_ranges, settings, *data_settings);\n \n     Pipes res;\n@@ -534,7 +602,41 @@ Pipe ReadFromMergeTree::spreadMarkRangesAmongStreamsWithOrder(\n     const size_t min_marks_per_stream = (info.sum_marks - 1) / requested_num_streams + 1;\n     bool need_preliminary_merge = (parts_with_ranges.size() > settings.read_in_order_two_level_merge_threshold);\n \n-    Pipes pipes;\n+    std::vector<RangesInDataParts> splitted_parts_and_ranges;\n+    splitted_parts_and_ranges.reserve(requested_num_streams);\n+\n+    const auto read_type = input_order_info->direction == 1\n+                       ? ReadFromMergeTree::ReadType::InOrder\n+                       : ReadFromMergeTree::ReadType::InReverseOrder;\n+\n+    MergeTreeInOrderReadPoolParallelReplicasPtr pool;\n+\n+    if (is_parallel_reading_from_replicas)\n+    {\n+        const auto & client_info = context->getClientInfo();\n+        auto extension = ParallelReadingExtension\n+        {\n+            .all_callback = all_ranges_callback.value(),\n+            .callback = read_task_callback.value(),\n+            .count_participating_replicas = client_info.count_participating_replicas,\n+            .number_of_current_replica = client_info.number_of_current_replica,\n+            .colums_to_read = column_names\n+        };\n+\n+        /// We have a special logic for local replica. It has to read less data, because in some cases it should\n+        /// merge states of aggregate functions or do some other important stuff other than reading from Disk.\n+        auto is_local_replica = context->getClientInfo().interface == ClientInfo::Interface::LOCAL;\n+        auto min_marks_for_concurrent_read = info.min_marks_for_concurrent_read;\n+        if (!is_local_replica)\n+            min_marks_for_concurrent_read = static_cast<size_t>(min_marks_for_concurrent_read * settings.parallel_replicas_single_task_marks_count_multiplier);\n+\n+        pool = std::make_shared<MergeTreeInOrderReadPoolParallelReplicas>(\n+            parts_with_ranges,\n+            extension,\n+            read_type == ReadFromMergeTree::ReadType::InOrder ? CoordinationMode::WithOrder : CoordinationMode::ReverseOrder,\n+            min_marks_for_concurrent_read);\n+    }\n+\n \n     for (size_t i = 0; i < requested_num_streams && !parts_with_ranges.empty(); ++i)\n     {\n@@ -602,12 +704,14 @@ Pipe ReadFromMergeTree::spreadMarkRangesAmongStreamsWithOrder(\n             new_parts.emplace_back(part.data_part, part.part_index_in_query, std::move(ranges_to_get_from_part));\n         }\n \n-        auto read_type = input_order_info->direction == 1\n-                       ? ReadFromMergeTree::ReadType::InOrder\n-                       : ReadFromMergeTree::ReadType::InReverseOrder;\n+        splitted_parts_and_ranges.emplace_back(std::move(new_parts));\n+    }\n \n-        pipes.emplace_back(readInOrder(std::move(new_parts), column_names, read_type,\n-                                        info.use_uncompressed_cache, input_order_info->limit));\n+    Pipes pipes;\n+    for (auto & item : splitted_parts_and_ranges)\n+    {\n+        pipes.emplace_back(readInOrder(std::move(item), column_names, read_type,\n+                                        info.use_uncompressed_cache, input_order_info->limit, pool));\n     }\n \n     Block pipe_header;\n@@ -758,7 +862,7 @@ Pipe ReadFromMergeTree::spreadMarkRangesAmongStreamsFinal(\n \n     /// If do_not_merge_across_partitions_select_final is true and num_streams > 1\n     /// we will store lonely parts with level > 0 to use parallel select on them.\n-    std::vector<RangesInDataPart> lonely_parts;\n+    RangesInDataParts lonely_parts;\n     size_t sum_marks_in_lonely_parts = 0;\n \n     for (size_t range_index = 0; range_index < parts_to_merge_ranges.size() - 1; ++range_index)\n@@ -1265,6 +1369,17 @@ void ReadFromMergeTree::initializePipeline(QueryPipelineBuilder & pipeline, cons\n \n     const auto & input_order_info = query_info.getInputOrderInfo();\n \n+    /// Construct a proper coordinator\n+    if (input_order_info && is_parallel_reading_from_replicas && context->getClientInfo().interface == ClientInfo::Interface::LOCAL)\n+    {\n+        assert(context->parallel_reading_coordinator);\n+        auto mode = input_order_info->direction == 1 ? CoordinationMode::WithOrder : CoordinationMode::ReverseOrder;\n+        context->parallel_reading_coordinator->setMode(mode);\n+    }\n+\n+    if (final && is_parallel_reading_from_replicas)\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Final modifier is not supported with parallel replicas\");\n+\n     if (final)\n     {\n         /// Add columns needed to calculate the sorting expression and the sign.\n@@ -1406,6 +1521,8 @@ static const char * readTypeToString(ReadFromMergeTree::ReadType type)\n             return \"InOrder\";\n         case ReadFromMergeTree::ReadType::InReverseOrder:\n             return \"InReverseOrder\";\n+        case ReadFromMergeTree::ReadType::ParallelReplicas:\n+            return \"Parallel\";\n     }\n \n     UNREACHABLE();\ndiff --git a/src/Processors/QueryPlan/ReadFromMergeTree.h b/src/Processors/QueryPlan/ReadFromMergeTree.h\nindex a3cea2a8afee..8b2eca5e08ee 100644\n--- a/src/Processors/QueryPlan/ReadFromMergeTree.h\n+++ b/src/Processors/QueryPlan/ReadFromMergeTree.h\n@@ -3,6 +3,8 @@\n #include <Storages/MergeTree/RangesInDataPart.h>\n #include <Storages/MergeTree/RequestResponse.h>\n #include <Storages/SelectQueryInfo.h>\n+#include <Storages/MergeTree/MergeTreeData.h>\n+#include <Storages/MergeTree/MergeTreeReadPool.h>\n \n namespace DB\n {\n@@ -11,7 +13,7 @@ using PartitionIdToMaxBlock = std::unordered_map<String, Int64>;\n \n class Pipe;\n \n-using MergeTreeReadTaskCallback = std::function<std::optional<PartitionReadResponse>(PartitionReadRequest)>;\n+using MergeTreeReadTaskCallback = std::function<std::optional<ParallelReadResponse>(ParallelReadRequest)>;\n \n struct MergeTreeDataSelectSamplingData\n {\n@@ -68,6 +70,10 @@ class ReadFromMergeTree final : public ISourceStep\n         /// The same as InOrder, but in reverse order.\n         /// For every part, read ranges and granules from end to begin. Also add ReverseTransform.\n         InReverseOrder,\n+        /// A special type of reading where every replica\n+        /// talks to a remote coordinator (which is located on the initiator node)\n+        /// and who spreads marks and parts across them.\n+        ParallelReplicas,\n     };\n \n     struct AnalysisResult\n@@ -212,10 +218,11 @@ class ReadFromMergeTree final : public ISourceStep\n \n     Pipe read(RangesInDataParts parts_with_range, Names required_columns, ReadType read_type, size_t max_streams, size_t min_marks_for_concurrent_read, bool use_uncompressed_cache);\n     Pipe readFromPool(RangesInDataParts parts_with_ranges, Names required_columns, size_t max_streams, size_t min_marks_for_concurrent_read, bool use_uncompressed_cache);\n-    Pipe readInOrder(RangesInDataParts parts_with_range, Names required_columns, ReadType read_type, bool use_uncompressed_cache, UInt64 limit);\n+    Pipe readFromPoolParallelReplicas(RangesInDataParts parts_with_ranges, Names required_columns, size_t max_streams, size_t min_marks_for_concurrent_read, bool use_uncompressed_cache);\n+    Pipe readInOrder(RangesInDataParts parts_with_range, Names required_columns, ReadType read_type, bool use_uncompressed_cache, UInt64 limit, MergeTreeInOrderReadPoolParallelReplicasPtr pool);\n \n     template<typename TSource>\n-    ProcessorPtr createSource(const RangesInDataPart & part, const Names & required_columns, bool use_uncompressed_cache, bool has_limit_below_one_block);\n+    ProcessorPtr createSource(const RangesInDataPart & part, const Names & required_columns, bool use_uncompressed_cache, bool has_limit_below_one_block, MergeTreeInOrderReadPoolParallelReplicasPtr pool);\n \n     Pipe spreadMarkRangesAmongStreams(\n         RangesInDataParts && parts_with_ranges,\n@@ -236,6 +243,8 @@ class ReadFromMergeTree final : public ISourceStep\n     ReadFromMergeTree::AnalysisResult getAnalysisResult() const;\n     MergeTreeDataSelectAnalysisResultPtr analyzed_result_ptr;\n \n+    bool is_parallel_reading_from_replicas;\n+    std::optional<MergeTreeAllRangesCallback> all_ranges_callback;\n     std::optional<MergeTreeReadTaskCallback> read_task_callback;\n };\n \ndiff --git a/src/Processors/QueryPlan/ReadFromRemote.cpp b/src/Processors/QueryPlan/ReadFromRemote.cpp\nindex 103f2734b069..9e5ecc791dca 100644\n--- a/src/Processors/QueryPlan/ReadFromRemote.cpp\n+++ b/src/Processors/QueryPlan/ReadFromRemote.cpp\n@@ -9,10 +9,13 @@\n #include <Processors/Sources/RemoteSource.h>\n #include <Processors/Sources/DelayedSource.h>\n #include <Processors/Transforms/ExpressionTransform.h>\n+#include <Processors/Transforms/ReadFromMergeTreeDependencyTransform.h>\n #include <Interpreters/ActionsDAG.h>\n #include <Interpreters/InterpreterSelectQuery.h>\n #include <IO/ConnectionTimeoutsContext.h>\n+#include \"Common/logger_useful.h\"\n #include <Common/checkStackSize.h>\n+#include <Core/QueryProcessingStage.h>\n #include <Client/ConnectionPool.h>\n #include <Client/ConnectionPoolWithFailover.h>\n #include <QueryPipeline/QueryPipelineBuilder.h>\n@@ -180,7 +183,8 @@ void ReadFromRemote::addLazyPipe(Pipes & pipes, const ClusterProxy::SelectStream\n \n         if (try_results.empty() || local_delay < max_remote_delay)\n         {\n-            auto plan = createLocalPlan(query, header, context, stage, shard.shard_info.shard_num, shard_count, 0, 0, /*coordinator=*/nullptr);\n+            auto plan = createLocalPlan(\n+                query, header, context, stage, shard.shard_info.shard_num, shard_count, 0, 0, /*coordinator=*/nullptr);\n \n             return std::move(*plan->buildQueryPipeline(\n                 QueryPlanOptimizationSettings::fromContext(context),\n@@ -231,7 +235,7 @@ void ReadFromRemote::addPipe(Pipes & pipes, const ClusterProxy::SelectStreamFact\n     std::shared_ptr<RemoteQueryExecutor> remote_query_executor;\n \n     remote_query_executor = std::make_shared<RemoteQueryExecutor>(\n-            shard.shard_info.pool, query_string, shard.header, context, throttler, scalars, external_tables, stage);\n+            shard.shard_info.pool, query_string, output_stream->header, context, throttler, scalars, external_tables, stage);\n \n     remote_query_executor->setLogger(log);\n     remote_query_executor->setPoolMode(PoolMode::GET_MANY);\n@@ -265,8 +269,9 @@ void ReadFromRemote::initializePipeline(QueryPipelineBuilder & pipeline, const B\n \n \n ReadFromParallelRemoteReplicasStep::ReadFromParallelRemoteReplicasStep(\n+    ASTPtr query_ast_,\n+    Cluster::ShardInfo shard_info_,\n     ParallelReplicasReadingCoordinatorPtr coordinator_,\n-    ClusterProxy::SelectStreamFactory::Shard shard_,\n     Block header_,\n     QueryProcessingStage::Enum stage_,\n     StorageID main_table_,\n@@ -276,10 +281,12 @@ ReadFromParallelRemoteReplicasStep::ReadFromParallelRemoteReplicasStep(\n     Scalars scalars_,\n     Tables external_tables_,\n     Poco::Logger * log_,\n-    std::shared_ptr<const StorageLimitsList> storage_limits_)\n+    std::shared_ptr<const StorageLimitsList> storage_limits_,\n+    UUID uuid_)\n     : ISourceStep(DataStream{.header = std::move(header_)})\n+    , shard_info(shard_info_)\n+    , query_ast(query_ast_)\n     , coordinator(std::move(coordinator_))\n-    , shard(std::move(shard_))\n     , stage(std::move(stage_))\n     , main_table(std::move(main_table_))\n     , table_func_ptr(table_func_ptr_)\n@@ -289,10 +296,11 @@ ReadFromParallelRemoteReplicasStep::ReadFromParallelRemoteReplicasStep(\n     , external_tables{external_tables_}\n     , storage_limits(std::move(storage_limits_))\n     , log(log_)\n+    , uuid(uuid_)\n {\n     std::vector<String> description;\n \n-    for (const auto & address : shard.shard_info.all_addresses)\n+    for (const auto & address : shard_info.all_addresses)\n         if (!address.is_local)\n             description.push_back(fmt::format(\"Replica: {}\", address.host_name));\n \n@@ -312,28 +320,46 @@ void ReadFromParallelRemoteReplicasStep::enforceAggregationInOrder()\n void ReadFromParallelRemoteReplicasStep::initializePipeline(QueryPipelineBuilder & pipeline, const BuildQueryPipelineSettings &)\n {\n     Pipes pipes;\n-\n     const Settings & current_settings = context->getSettingsRef();\n     auto timeouts = ConnectionTimeouts::getTCPTimeoutsWithFailover(current_settings);\n \n-    for (size_t replica_num = 0; replica_num < shard.shard_info.getAllNodeCount(); ++replica_num)\n+    size_t all_replicas_count = current_settings.max_parallel_replicas;\n+    if (all_replicas_count > shard_info.all_addresses.size())\n     {\n-        if (shard.shard_info.all_addresses[replica_num].is_local)\n+        LOG_INFO(&Poco::Logger::get(\"ReadFromParallelRemoteReplicasStep\"),\n+            \"The number of replicas requested ({}) is bigger than the real number available in the cluster ({}). \"\\\n+            \"Will use the latter number to execute the query.\", current_settings.max_parallel_replicas, shard_info.all_addresses.size());\n+        all_replicas_count = shard_info.all_addresses.size();\n+    }\n+\n+    /// The requested number of replicas to read from could be less\n+    /// than the total number of replicas in the shard\n+    /// And we have to pick only \"remote\" ones\n+    /// So, that's why this loop looks like this.\n+    size_t replica_num = 0;\n+    while (pipes.size() != all_replicas_count - 1)\n+    {\n+        if (shard_info.all_addresses[replica_num].is_local)\n+        {\n+            ++replica_num;\n             continue;\n+        }\n \n         IConnections::ReplicaInfo replica_info\n         {\n-            .all_replicas_count = shard.shard_info.getAllNodeCount(),\n-            .number_of_current_replica = replica_num\n+            .all_replicas_count = all_replicas_count,\n+            /// Replica 0 is threated as local always\n+            .number_of_current_replica = pipes.size() + 1\n         };\n \n-        auto pool = shard.shard_info.per_replica_pools[replica_num];\n+        auto pool = shard_info.per_replica_pools[replica_num];\n         assert(pool);\n \n         auto pool_with_failover = std::make_shared<ConnectionPoolWithFailover>(\n             ConnectionPoolPtrs{pool}, current_settings.load_balancing);\n \n         addPipeForSingeReplica(pipes, std::move(pool_with_failover), replica_info);\n+        ++replica_num;\n     }\n \n     auto pipe = Pipe::unitePipes(std::move(pipes));\n@@ -355,25 +381,22 @@ void ReadFromParallelRemoteReplicasStep::addPipeForSingeReplica(Pipes & pipes, s\n \n     if (stage == QueryProcessingStage::Complete)\n     {\n-        add_totals = shard.query->as<ASTSelectQuery &>().group_by_with_totals;\n+        add_totals = query_ast->as<ASTSelectQuery &>().group_by_with_totals;\n         add_extremes = context->getSettingsRef().extremes;\n     }\n \n-    String query_string = formattedAST(shard.query);\n+    String query_string = formattedAST(query_ast);\n \n-    scalars[\"_shard_num\"]\n-        = Block{{DataTypeUInt32().createColumnConst(1, shard.shard_info.shard_num), std::make_shared<DataTypeUInt32>(), \"_shard_num\"}};\n+    assert(stage != QueryProcessingStage::Complete);\n+    assert(output_stream);\n \n     auto remote_query_executor = std::make_shared<RemoteQueryExecutor>(\n-        pool, query_string, shard.header, context, throttler, scalars, external_tables, stage,\n+        pool, query_string, output_stream->header, context, throttler, scalars, external_tables, stage,\n         RemoteQueryExecutor::Extension{.parallel_reading_coordinator = coordinator, .replica_info = std::move(replica_info)});\n \n     remote_query_executor->setLogger(log);\n \n-    if (!table_func_ptr)\n-        remote_query_executor->setMainTable(main_table);\n-\n-    pipes.emplace_back(createRemoteSourcePipe(std::move(remote_query_executor), add_agg_info, add_totals, add_extremes, async_read));\n+    pipes.emplace_back(createRemoteSourcePipe(std::move(remote_query_executor), add_agg_info, add_totals, add_extremes, async_read, uuid));\n     addConvertingActions(pipes.back(), output_stream->header);\n }\n \ndiff --git a/src/Processors/QueryPlan/ReadFromRemote.h b/src/Processors/QueryPlan/ReadFromRemote.h\nindex 60a7cd90f3f0..e1979ee1aaa8 100644\n--- a/src/Processors/QueryPlan/ReadFromRemote.h\n+++ b/src/Processors/QueryPlan/ReadFromRemote.h\n@@ -6,6 +6,7 @@\n #include <Interpreters/StorageID.h>\n #include <Interpreters/ClusterProxy/SelectStreamFactory.h>\n #include <Storages/MergeTree/ParallelReplicasReadingCoordinator.h>\n+#include \"Core/UUID.h\"\n \n namespace DB\n {\n@@ -45,18 +46,13 @@ class ReadFromRemote final : public ISourceStep\n private:\n     ClusterProxy::SelectStreamFactory::Shards shards;\n     QueryProcessingStage::Enum stage;\n-\n     StorageID main_table;\n     ASTPtr table_func_ptr;\n-\n     ContextMutablePtr context;\n-\n     ThrottlerPtr throttler;\n     Scalars scalars;\n     Tables external_tables;\n-\n     std::shared_ptr<const StorageLimitsList> storage_limits;\n-\n     Poco::Logger * log;\n \n     UInt32 shard_count;\n@@ -69,8 +65,9 @@ class ReadFromParallelRemoteReplicasStep : public ISourceStep\n {\n public:\n     ReadFromParallelRemoteReplicasStep(\n+        ASTPtr query_ast_,\n+        Cluster::ShardInfo shard_info,\n         ParallelReplicasReadingCoordinatorPtr coordinator_,\n-        ClusterProxy::SelectStreamFactory::Shard shard,\n         Block header_,\n         QueryProcessingStage::Enum stage_,\n         StorageID main_table_,\n@@ -80,7 +77,8 @@ class ReadFromParallelRemoteReplicasStep : public ISourceStep\n         Scalars scalars_,\n         Tables external_tables_,\n         Poco::Logger * log_,\n-        std::shared_ptr<const StorageLimitsList> storage_limits_);\n+        std::shared_ptr<const StorageLimitsList> storage_limits_,\n+        UUID uuid);\n \n     String getName() const override { return \"ReadFromRemoteParallelReplicas\"; }\n \n@@ -93,22 +91,20 @@ class ReadFromParallelRemoteReplicasStep : public ISourceStep\n \n     void addPipeForSingeReplica(Pipes & pipes, std::shared_ptr<ConnectionPoolWithFailover> pool, IConnections::ReplicaInfo replica_info);\n \n+    Cluster::ShardInfo shard_info;\n+    ASTPtr query_ast;\n     ParallelReplicasReadingCoordinatorPtr coordinator;\n-    ClusterProxy::SelectStreamFactory::Shard shard;\n     QueryProcessingStage::Enum stage;\n-\n     StorageID main_table;\n     ASTPtr table_func_ptr;\n-\n     ContextMutablePtr context;\n-\n     ThrottlerPtr throttler;\n     Scalars scalars;\n     Tables external_tables;\n \n     std::shared_ptr<const StorageLimitsList> storage_limits;\n-\n     Poco::Logger * log;\n+    UUID uuid;\n };\n \n }\ndiff --git a/src/Processors/Sources/RemoteSource.cpp b/src/Processors/Sources/RemoteSource.cpp\nindex 9f29ad9ad071..69964d569fab 100644\n--- a/src/Processors/Sources/RemoteSource.cpp\n+++ b/src/Processors/Sources/RemoteSource.cpp\n@@ -1,3 +1,4 @@\n+#include <variant>\n #include <Processors/Sources/RemoteSource.h>\n #include <QueryPipeline/RemoteQueryExecutor.h>\n #include <QueryPipeline/RemoteQueryExecutorReadContext.h>\n@@ -8,10 +9,16 @@\n namespace DB\n {\n \n-RemoteSource::RemoteSource(RemoteQueryExecutorPtr executor, bool add_aggregation_info_, bool async_read_)\n+namespace ErrorCodes\n+{\n+    extern const int LOGICAL_ERROR;\n+}\n+\n+RemoteSource::RemoteSource(RemoteQueryExecutorPtr executor, bool add_aggregation_info_, bool async_read_, UUID uuid_)\n     : ISource(executor->getHeader(), false)\n     , add_aggregation_info(add_aggregation_info_), query_executor(std::move(executor))\n     , async_read(async_read_)\n+    , uuid(uuid_)\n {\n     /// Add AggregatedChunkInfo if we expect DataTypeAggregateFunction as a result.\n     const auto & sample = getPort().getHeader();\n@@ -22,6 +29,18 @@ RemoteSource::RemoteSource(RemoteQueryExecutorPtr executor, bool add_aggregation\n \n RemoteSource::~RemoteSource() = default;\n \n+void RemoteSource::connectToScheduler(InputPort & input_port)\n+{\n+    outputs.emplace_back(Block{}, this);\n+    dependency_port = &outputs.back();\n+    connect(*dependency_port, input_port);\n+}\n+\n+UUID RemoteSource::getParallelReplicasGroupUUID()\n+{\n+    return uuid;\n+}\n+\n void RemoteSource::setStorageLimits(const std::shared_ptr<const StorageLimitsList> & storage_limits_)\n {\n     /// Remove leaf limits for remote source.\n@@ -50,8 +69,21 @@ ISource::Status RemoteSource::prepare()\n     if (status == Status::Finished)\n     {\n         query_executor->finish(&read_context);\n+        if (dependency_port)\n+            dependency_port->finish();\n         is_async_state = false;\n+\n+        return status;\n     }\n+\n+    if (status == Status::PortFull)\n+    {\n+        /// Also push empty chunk to dependency to signal that we read data from remote source\n+        /// or answered to the incoming request from parallel replica\n+        if (dependency_port && !dependency_port->isFinished() && dependency_port->canPush())\n+            dependency_port->push(Chunk());\n+    }\n+\n     return status;\n }\n \n@@ -88,19 +120,29 @@ std::optional<Chunk> RemoteSource::tryGenerate()\n     if (async_read)\n     {\n         auto res = query_executor->read(read_context);\n-        if (std::holds_alternative<int>(res))\n+\n+        if (res.getType() == RemoteQueryExecutor::ReadResult::Type::Nothing)\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Got an empty packet from the RemoteQueryExecutor. This is a bug\");\n+\n+        if (res.getType() == RemoteQueryExecutor::ReadResult::Type::FileDescriptor)\n         {\n-            fd = std::get<int>(res);\n+            fd = res.getFileDescriptor();\n             is_async_state = true;\n             return Chunk();\n         }\n \n+        if (res.getType() == RemoteQueryExecutor::ReadResult::Type::ParallelReplicasToken)\n+        {\n+            is_async_state = false;\n+            return Chunk();\n+        }\n+\n         is_async_state = false;\n \n-        block = std::get<Block>(std::move(res));\n+        block = res.getBlock();\n     }\n     else\n-        block = query_executor->read();\n+        block = query_executor->readBlock();\n \n     if (!block)\n     {\n@@ -180,9 +222,9 @@ Chunk RemoteExtremesSource::generate()\n \n Pipe createRemoteSourcePipe(\n     RemoteQueryExecutorPtr query_executor,\n-    bool add_aggregation_info, bool add_totals, bool add_extremes, bool async_read)\n+    bool add_aggregation_info, bool add_totals, bool add_extremes, bool async_read, UUID uuid)\n {\n-    Pipe pipe(std::make_shared<RemoteSource>(query_executor, add_aggregation_info, async_read));\n+    Pipe pipe(std::make_shared<RemoteSource>(query_executor, add_aggregation_info, async_read, uuid));\n \n     if (add_totals)\n         pipe.addTotalsSource(std::make_shared<RemoteTotalsSource>(query_executor));\ndiff --git a/src/Processors/Sources/RemoteSource.h b/src/Processors/Sources/RemoteSource.h\nindex f415b91aae0d..8fe0114ab6ff 100644\n--- a/src/Processors/Sources/RemoteSource.h\n+++ b/src/Processors/Sources/RemoteSource.h\n@@ -3,6 +3,7 @@\n #include <Processors/ISource.h>\n #include <Processors/RowsBeforeLimitCounter.h>\n #include <QueryPipeline/Pipe.h>\n+#include \"Core/UUID.h\"\n #include <atomic>\n \n namespace DB\n@@ -14,20 +15,24 @@ using RemoteQueryExecutorPtr = std::shared_ptr<RemoteQueryExecutor>;\n class RemoteQueryExecutorReadContext;\n \n /// Source from RemoteQueryExecutor. Executes remote query and returns query result chunks.\n-class RemoteSource : public ISource\n+class RemoteSource final : public ISource\n {\n public:\n     /// Flag add_aggregation_info tells if AggregatedChunkInfo should be added to result chunk.\n     /// AggregatedChunkInfo stores the bucket number used for two-level aggregation.\n     /// This flag should be typically enabled for queries with GROUP BY which are executed till WithMergeableState.\n-    RemoteSource(RemoteQueryExecutorPtr executor, bool add_aggregation_info_, bool async_read_);\n+    RemoteSource(RemoteQueryExecutorPtr executor, bool add_aggregation_info_, bool async_read_, UUID uuid = UUIDHelpers::Nil);\n     ~RemoteSource() override;\n \n     Status prepare() override;\n     String getName() const override { return \"Remote\"; }\n \n+    void connectToScheduler(InputPort & input_port);\n+\n     void setRowsBeforeLimitCounter(RowsBeforeLimitCounterPtr counter) { rows_before_limit.swap(counter); }\n \n+    UUID getParallelReplicasGroupUUID();\n+\n     /// Stop reading from stream if output port is finished.\n     void onUpdatePorts() override;\n \n@@ -46,9 +51,12 @@ class RemoteSource : public ISource\n     RemoteQueryExecutorPtr query_executor;\n     RowsBeforeLimitCounterPtr rows_before_limit;\n \n+    OutputPort * dependency_port{nullptr};\n+\n     const bool async_read;\n     bool is_async_state = false;\n     std::unique_ptr<RemoteQueryExecutorReadContext> read_context;\n+    UUID uuid;\n     int fd = -1;\n };\n \n@@ -87,6 +95,6 @@ class RemoteExtremesSource : public ISource\n /// Create pipe with remote sources.\n Pipe createRemoteSourcePipe(\n     RemoteQueryExecutorPtr query_executor,\n-    bool add_aggregation_info, bool add_totals, bool add_extremes, bool async_read);\n+    bool add_aggregation_info, bool add_totals, bool add_extremes, bool async_read, UUID uuid = UUIDHelpers::Nil);\n \n }\ndiff --git a/src/Processors/Transforms/ReadFromMergeTreeDependencyTransform.cpp b/src/Processors/Transforms/ReadFromMergeTreeDependencyTransform.cpp\nnew file mode 100644\nindex 000000000000..295eddb206de\n--- /dev/null\n+++ b/src/Processors/Transforms/ReadFromMergeTreeDependencyTransform.cpp\n@@ -0,0 +1,103 @@\n+#include <Processors/Transforms/ReadFromMergeTreeDependencyTransform.h>\n+\n+#include <QueryPipeline/RemoteQueryExecutor.h>\n+#include \"Processors/Port.h\"\n+\n+namespace DB\n+{\n+\n+ReadFromMergeTreeDependencyTransform::ReadFromMergeTreeDependencyTransform(const Block & header, UUID uuid_)\n+    : IProcessor(InputPorts(1, header), OutputPorts(1, header))\n+    , uuid(uuid_)\n+    , data_port(&inputs.front())\n+{\n+}\n+\n+void ReadFromMergeTreeDependencyTransform::connectToScheduler(OutputPort & output_port)\n+{\n+    inputs.emplace_back(Block{}, this);\n+    dependency_port = &inputs.back();\n+    connect(output_port, *dependency_port);\n+}\n+\n+UUID ReadFromMergeTreeDependencyTransform::getParallelReplicasGroupUUID()\n+{\n+    return uuid;\n+}\n+\n+IProcessor::Status ReadFromMergeTreeDependencyTransform::prepare()\n+{\n+    Status status = Status::Ready;\n+\n+    while (status == Status::Ready)\n+    {\n+        status = !has_data ? prepareConsume()\n+                           : prepareGenerate();\n+    }\n+\n+    return status;\n+}\n+\n+IProcessor::Status ReadFromMergeTreeDependencyTransform::prepareConsume()\n+{\n+    auto & output_port = getOutputPort();\n+\n+    /// Check all outputs are finished or ready to get data.\n+    if (output_port.isFinished())\n+    {\n+        data_port->close();\n+        dependency_port->close();\n+        return Status::Finished;\n+    }\n+\n+    /// Try get chunk from input.\n+    if (data_port->isFinished())\n+    {\n+        if (dependency_port->hasData())\n+            dependency_port->pull(true);\n+        dependency_port->close();\n+        output_port.finish();\n+        return Status::Finished;\n+    }\n+\n+    if (!dependency_port->isFinished())\n+    {\n+        dependency_port->setNeeded();\n+        if (!dependency_port->hasData())\n+            return Status::NeedData;\n+    }\n+\n+    data_port->setNeeded();\n+    if (!data_port->hasData())\n+        return Status::NeedData;\n+\n+    if (!dependency_port->isFinished())\n+        dependency_port->pull();\n+\n+    chunk = data_port->pull();\n+    has_data = true;\n+\n+    return Status::Ready;\n+}\n+\n+IProcessor::Status ReadFromMergeTreeDependencyTransform::prepareGenerate()\n+{\n+    auto & output_port = getOutputPort();\n+    if (!output_port.isFinished() && output_port.canPush())\n+    {\n+        output_port.push(std::move(chunk));\n+        has_data = false;\n+        return Status::Ready;\n+    }\n+\n+    if (output_port.isFinished())\n+    {\n+        data_port->close();\n+        dependency_port->close();\n+        return Status::Finished;\n+    }\n+\n+    return Status::PortFull;\n+}\n+\n+}\ndiff --git a/src/Processors/Transforms/ReadFromMergeTreeDependencyTransform.h b/src/Processors/Transforms/ReadFromMergeTreeDependencyTransform.h\nnew file mode 100644\nindex 000000000000..929841e7ce04\n--- /dev/null\n+++ b/src/Processors/Transforms/ReadFromMergeTreeDependencyTransform.h\n@@ -0,0 +1,48 @@\n+#pragma once\n+#include <Processors/IProcessor.h>\n+\n+namespace DB\n+{\n+\n+class RemoteQueryExecutor;\n+using RemoteQueryExecutorPtr = std::shared_ptr<RemoteQueryExecutor>;\n+\n+/// A tiny class which is used for reading with multiple replicas in parallel.\n+/// Motivation is that we don't have a full control on how\n+/// processors are scheduled across threads and there could be a situation\n+/// when all available threads will read from local replica and will just\n+/// forget about remote replicas existence. That is not what we want.\n+/// For parallel replicas we have to constantly answer to incoming requests\n+/// with a set of marks to read.\n+/// With the help of this class, we explicitly connect a \"local\" source with\n+/// all the remote ones. And thus achieve fairness somehow.\n+class ReadFromMergeTreeDependencyTransform : public IProcessor\n+{\n+public:\n+    ReadFromMergeTreeDependencyTransform(const Block & header, UUID uuid_);\n+\n+    String getName() const override { return \"ReadFromMergeTreeDependency\"; }\n+    Status prepare() override;\n+\n+    InputPort & getInputPort() { assert(data_port); return *data_port; }\n+    InputPort & getDependencyPort() { assert(dependency_port); return *dependency_port; }\n+    OutputPort & getOutputPort() { return outputs.front(); }\n+\n+    UUID getParallelReplicasGroupUUID();\n+\n+    void connectToScheduler(OutputPort & output_port);\n+private:\n+    bool has_data{false};\n+    Chunk chunk;\n+\n+    UUID uuid;\n+\n+    InputPort * data_port{nullptr};\n+    InputPort * dependency_port{nullptr};\n+\n+    Status prepareGenerate();\n+    Status prepareConsume();\n+};\n+\n+\n+}\ndiff --git a/src/QueryPipeline/Pipe.h b/src/QueryPipeline/Pipe.h\nindex 2b61bfe75737..09931e385782 100644\n--- a/src/QueryPipeline/Pipe.h\n+++ b/src/QueryPipeline/Pipe.h\n@@ -102,6 +102,8 @@ class Pipe\n     /// Get processors from Pipe without destroying pipe (used for EXPLAIN to keep QueryPlan).\n     const Processors & getProcessors() const { return *processors; }\n \n+    std::shared_ptr<Processors> getProcessorsPtr() { return processors; }\n+\n private:\n     /// Header is common for all output below.\n     Block header;\ndiff --git a/src/QueryPipeline/QueryPipelineBuilder.cpp b/src/QueryPipeline/QueryPipelineBuilder.cpp\nindex 483447d1e4dd..07adc6b0b3a6 100644\n--- a/src/QueryPipeline/QueryPipelineBuilder.cpp\n+++ b/src/QueryPipeline/QueryPipelineBuilder.cpp\n@@ -1,34 +1,35 @@\n-#include <vector>\n #include <QueryPipeline/QueryPipelineBuilder.h>\n \n-#include <Processors/QueryPlan/ExpressionStep.h>\n-#include <Processors/ResizeProcessor.h>\n-#include <Processors/LimitTransform.h>\n-#include <Processors/Transforms/TotalsHavingTransform.h>\n-#include <Processors/Transforms/ExtremesTransform.h>\n-#include <Processors/Transforms/CreatingSetsTransform.h>\n-#include <Processors/Transforms/ExpressionTransform.h>\n-#include <Processors/Transforms/MergingAggregatedMemoryEfficientTransform.h>\n-#include <Processors/Transforms/JoiningTransform.h>\n-#include <Processors/Transforms/MergeJoinTransform.h>\n-#include <Processors/Formats/IOutputFormat.h>\n-#include <Processors/Executors/PipelineExecutor.h>\n-#include <Processors/Transforms/PartialSortingTransform.h>\n-#include <Processors/Sources/SourceFromSingleChunk.h>\n-#include <IO/WriteHelpers.h>\n+#include <Common/CurrentThread.h>\n+#include <Common/typeid_cast.h>\n+#include \"Core/UUID.h\"\n+#include <Core/SortDescription.h>\n #include <Interpreters/Context.h>\n #include <Interpreters/ExpressionActions.h>\n #include <Interpreters/IJoin.h>\n #include <Interpreters/TableJoin.h>\n-#include <Common/typeid_cast.h>\n-#include <Common/CurrentThread.h>\n+#include <IO/WriteHelpers.h>\n #include <Processors/ConcatProcessor.h>\n-#include <Core/SortDescription.h>\n-#include <QueryPipeline/narrowPipe.h>\n #include <Processors/DelayedPortsProcessor.h>\n+#include <Processors/Executors/PipelineExecutor.h>\n+#include <Processors/Formats/IOutputFormat.h>\n+#include <Processors/LimitTransform.h>\n+#include <Processors/QueryPlan/ExpressionStep.h>\n+#include <Processors/QueryPlan/QueryPlan.h>\n+#include <Processors/ResizeProcessor.h>\n #include <Processors/RowsBeforeLimitCounter.h>\n #include <Processors/Sources/RemoteSource.h>\n-#include <Processors/QueryPlan/QueryPlan.h>\n+#include <Processors/Sources/SourceFromSingleChunk.h>\n+#include <Processors/Transforms/CreatingSetsTransform.h>\n+#include <Processors/Transforms/ExpressionTransform.h>\n+#include <Processors/Transforms/ExtremesTransform.h>\n+#include <Processors/Transforms/JoiningTransform.h>\n+#include <Processors/Transforms/MergeJoinTransform.h>\n+#include <Processors/Transforms/MergingAggregatedMemoryEfficientTransform.h>\n+#include <Processors/Transforms/PartialSortingTransform.h>\n+#include <Processors/Transforms/ReadFromMergeTreeDependencyTransform.h>\n+#include <Processors/Transforms/TotalsHavingTransform.h>\n+#include <QueryPipeline/narrowPipe.h>\n \n namespace DB\n {\n@@ -620,6 +621,65 @@ void QueryPipelineBuilder::setProgressCallback(ProgressCallback callback)\n     progress_callback = callback;\n }\n \n+void QueryPipelineBuilder::connectDependencies()\n+{\n+    /**\n+    * This is needed because among all RemoteSources there could be\n+    * one or several that don't belong to the parallel replicas reading process.\n+    * It could happen for example if we read through distributed table + prefer_localhost_replica=1 + parallel replicas\n+    * SELECT * FROM remote('127.0.0.{1,2}', table.merge_tree)\n+    * Will generate a local pipeline and a remote source. For local pipeline because of parallel replicas we will create\n+    * several processors to read and several remote sources.\n+    */\n+    std::set<UUID> all_parallel_replicas_groups;\n+    for (auto & processor : *pipe.getProcessorsPtr())\n+    {\n+        if (auto * remote_dependency = typeid_cast<RemoteSource *>(processor.get()); remote_dependency)\n+            if (auto uuid = remote_dependency->getParallelReplicasGroupUUID(); uuid != UUIDHelpers::Nil)\n+                all_parallel_replicas_groups.insert(uuid);\n+        if (auto * merge_tree_dependency = typeid_cast<ReadFromMergeTreeDependencyTransform *>(processor.get()); merge_tree_dependency)\n+            if (auto uuid = merge_tree_dependency->getParallelReplicasGroupUUID(); uuid != UUIDHelpers::Nil)\n+                all_parallel_replicas_groups.insert(uuid);\n+    }\n+\n+    for (const auto & group_id : all_parallel_replicas_groups)\n+    {\n+        std::vector<RemoteSource *> input_dependencies;\n+        std::vector<ReadFromMergeTreeDependencyTransform *> output_dependencies;\n+\n+        for (auto & processor : *pipe.getProcessorsPtr())\n+        {\n+            if (auto * remote_dependency = typeid_cast<RemoteSource *>(processor.get()); remote_dependency)\n+                if (auto uuid = remote_dependency->getParallelReplicasGroupUUID(); uuid == group_id)\n+                    input_dependencies.emplace_back(remote_dependency);\n+            if (auto * merge_tree_dependency = typeid_cast<ReadFromMergeTreeDependencyTransform *>(processor.get()); merge_tree_dependency)\n+                if (auto uuid = merge_tree_dependency->getParallelReplicasGroupUUID(); uuid == group_id)\n+                    output_dependencies.emplace_back(merge_tree_dependency);\n+        }\n+\n+        if (input_dependencies.empty() || output_dependencies.empty())\n+            continue;\n+\n+        auto input_dependency_iter = input_dependencies.begin();\n+        auto output_dependency_iter = output_dependencies.begin();\n+        auto scheduler = std::make_shared<ResizeProcessor>(Block{}, input_dependencies.size(), output_dependencies.size());\n+\n+        for (auto & scheduler_input : scheduler->getInputs())\n+        {\n+            (*input_dependency_iter)->connectToScheduler(scheduler_input);\n+            ++input_dependency_iter;\n+        }\n+\n+        for (auto & scheduler_output : scheduler->getOutputs())\n+        {\n+            (*output_dependency_iter)->connectToScheduler(scheduler_output);\n+            ++output_dependency_iter;\n+        }\n+\n+        pipe.getProcessorsPtr()->emplace_back(std::move(scheduler));\n+    }\n+}\n+\n PipelineExecutorPtr QueryPipelineBuilder::execute()\n {\n     if (!isCompleted())\ndiff --git a/src/QueryPipeline/QueryPipelineBuilder.h b/src/QueryPipeline/QueryPipelineBuilder.h\nindex 5a0694100ebb..0a102d186ca7 100644\n--- a/src/QueryPipeline/QueryPipelineBuilder.h\n+++ b/src/QueryPipeline/QueryPipelineBuilder.h\n@@ -140,6 +140,12 @@ class QueryPipelineBuilder\n \n     void addCreatingSetsTransform(const Block & res_header, SubqueryForSet subquery_for_set, const SizeLimits & limits, ContextPtr context);\n \n+    /// Finds all processors for reading from MergeTree\n+    /// And explicitly connects them with all RemoteSources\n+    /// using a ResizeProcessor. This is needed not to let\n+    /// the RemoteSource to starve for CPU time\n+    void connectDependencies();\n+\n     PipelineExecutorPtr execute();\n \n     size_t getNumStreams() const { return pipe.numOutputPorts(); }\ndiff --git a/src/QueryPipeline/RemoteQueryExecutor.cpp b/src/QueryPipeline/RemoteQueryExecutor.cpp\nindex 961d8129d29c..033907e9e2b5 100644\n--- a/src/QueryPipeline/RemoteQueryExecutor.cpp\n+++ b/src/QueryPipeline/RemoteQueryExecutor.cpp\n@@ -259,48 +259,62 @@ void RemoteQueryExecutor::sendQuery(ClientInfo::QueryKind query_kind)\n     sendExternalTables();\n }\n \n-Block RemoteQueryExecutor::read()\n+\n+Block RemoteQueryExecutor::readBlock()\n+{\n+    while (true)\n+    {\n+        auto res = read();\n+\n+        if (res.getType() == ReadResult::Type::Data)\n+            return res.getBlock();\n+    }\n+}\n+\n+\n+RemoteQueryExecutor::ReadResult RemoteQueryExecutor::read()\n {\n     if (!sent_query)\n     {\n         sendQuery();\n \n         if (context->getSettingsRef().skip_unavailable_shards && (0 == connections->size()))\n-            return {};\n+            return ReadResult(Block());\n     }\n \n     while (true)\n     {\n         std::lock_guard lock(was_cancelled_mutex);\n         if (was_cancelled)\n-            return Block();\n+            return ReadResult(Block());\n \n-        Packet packet = connections->receivePacket();\n+        auto packet = connections->receivePacket();\n+        auto anything = processPacket(std::move(packet));\n \n-        if (auto block = processPacket(std::move(packet)))\n-            return *block;\n-        else if (got_duplicated_part_uuids)\n-            return std::get<Block>(restartQueryWithoutDuplicatedUUIDs());\n+        if (anything.getType() == ReadResult::Type::Data || anything.getType() == ReadResult::Type::ParallelReplicasToken)\n+            return anything;\n+\n+        if (got_duplicated_part_uuids)\n+            return restartQueryWithoutDuplicatedUUIDs();\n     }\n }\n \n-std::variant<Block, int> RemoteQueryExecutor::read(std::unique_ptr<ReadContext> & read_context [[maybe_unused]])\n+RemoteQueryExecutor::ReadResult RemoteQueryExecutor::read(std::unique_ptr<ReadContext> & read_context [[maybe_unused]])\n {\n-\n #if defined(OS_LINUX)\n     if (!sent_query)\n     {\n         sendQuery();\n \n         if (context->getSettingsRef().skip_unavailable_shards && (0 == connections->size()))\n-            return Block();\n+            return ReadResult(Block());\n     }\n \n     if (!read_context || resent_query)\n     {\n         std::lock_guard lock(was_cancelled_mutex);\n         if (was_cancelled)\n-            return Block();\n+            return ReadResult(Block());\n \n         read_context = std::make_unique<ReadContext>(*connections);\n     }\n@@ -308,12 +322,12 @@ std::variant<Block, int> RemoteQueryExecutor::read(std::unique_ptr<ReadContext>\n     do\n     {\n         if (!read_context->resumeRoutine())\n-            return Block();\n+            return ReadResult(Block());\n \n         if (read_context->is_read_in_progress.load(std::memory_order_relaxed))\n         {\n             read_context->setTimer();\n-            return read_context->epoll.getFileDescriptor();\n+            return ReadResult(read_context->epoll.getFileDescriptor());\n         }\n         else\n         {\n@@ -321,11 +335,14 @@ std::variant<Block, int> RemoteQueryExecutor::read(std::unique_ptr<ReadContext>\n             /// to avoid the race between cancel() thread and read() thread.\n             /// (since cancel() thread will steal the fiber and may update the packet).\n             if (was_cancelled)\n-                return Block();\n+                return ReadResult(Block());\n \n-            if (auto data = processPacket(std::move(read_context->packet)))\n-                return std::move(*data);\n-            else if (got_duplicated_part_uuids)\n+            auto anything = processPacket(std::move(read_context->packet));\n+\n+            if (anything.getType() == ReadResult::Type::Data || anything.getType() == ReadResult::Type::ParallelReplicasToken)\n+                return anything;\n+\n+            if (got_duplicated_part_uuids)\n                 return restartQueryWithoutDuplicatedUUIDs(&read_context);\n         }\n     }\n@@ -336,7 +353,7 @@ std::variant<Block, int> RemoteQueryExecutor::read(std::unique_ptr<ReadContext>\n }\n \n \n-std::variant<Block, int> RemoteQueryExecutor::restartQueryWithoutDuplicatedUUIDs(std::unique_ptr<ReadContext> * read_context)\n+RemoteQueryExecutor::ReadResult RemoteQueryExecutor::restartQueryWithoutDuplicatedUUIDs(std::unique_ptr<ReadContext> * read_context)\n {\n     /// Cancel previous query and disconnect before retry.\n     cancel(read_context);\n@@ -360,13 +377,18 @@ std::variant<Block, int> RemoteQueryExecutor::restartQueryWithoutDuplicatedUUIDs\n     throw Exception(ErrorCodes::DUPLICATED_PART_UUIDS, \"Found duplicate uuids while processing query\");\n }\n \n-std::optional<Block> RemoteQueryExecutor::processPacket(Packet packet)\n+RemoteQueryExecutor::ReadResult RemoteQueryExecutor::processPacket(Packet packet)\n {\n     switch (packet.type)\n     {\n         case Protocol::Server::MergeTreeReadTaskRequest:\n             processMergeTreeReadTaskRequest(packet.request);\n-            break;\n+            return ReadResult(ReadResult::Type::ParallelReplicasToken);\n+\n+        case Protocol::Server::MergeTreeAllRangesAnnounecement:\n+            processMergeTreeInitialReadAnnounecement(packet.announcement);\n+            return ReadResult(ReadResult::Type::ParallelReplicasToken);\n+\n         case Protocol::Server::ReadTaskRequest:\n             processReadTaskRequest();\n             break;\n@@ -379,7 +401,7 @@ std::optional<Block> RemoteQueryExecutor::processPacket(Packet packet)\n             /// We can actually return it, and the first call to RemoteQueryExecutor::read\n             /// will return earlier. We should consider doing it.\n             if (packet.block && (packet.block.rows() > 0))\n-                return adaptBlockStructure(packet.block, header);\n+                return ReadResult(adaptBlockStructure(packet.block, header));\n             break;  /// If the block is empty - we will receive other packets before EndOfStream.\n \n         case Protocol::Server::Exception:\n@@ -391,7 +413,8 @@ std::optional<Block> RemoteQueryExecutor::processPacket(Packet packet)\n             if (!connections->hasActiveConnections())\n             {\n                 finished = true;\n-                return Block();\n+                /// TODO: Replace with Type::Finished\n+                return ReadResult(Block{});\n             }\n             break;\n \n@@ -446,7 +469,7 @@ std::optional<Block> RemoteQueryExecutor::processPacket(Packet packet)\n                 connections->dumpAddresses());\n     }\n \n-    return {};\n+    return ReadResult(ReadResult::Type::Nothing);\n }\n \n bool RemoteQueryExecutor::setPartUUIDs(const std::vector<UUID> & uuids)\n@@ -471,7 +494,7 @@ void RemoteQueryExecutor::processReadTaskRequest()\n     connections->sendReadTaskResponse(response);\n }\n \n-void RemoteQueryExecutor::processMergeTreeReadTaskRequest(PartitionReadRequest request)\n+void RemoteQueryExecutor::processMergeTreeReadTaskRequest(ParallelReadRequest request)\n {\n     if (!parallel_reading_coordinator)\n         throw Exception(ErrorCodes::LOGICAL_ERROR, \"Coordinator for parallel reading from replicas is not initialized\");\n@@ -480,6 +503,14 @@ void RemoteQueryExecutor::processMergeTreeReadTaskRequest(PartitionReadRequest r\n     connections->sendMergeTreeReadTaskResponse(response);\n }\n \n+void RemoteQueryExecutor::processMergeTreeInitialReadAnnounecement(InitialAllRangesAnnouncement announcement)\n+{\n+    if (!parallel_reading_coordinator)\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Coordinator for parallel reading from replicas is not initialized\");\n+\n+    parallel_reading_coordinator->handleInitialAllRangesAnnouncement(announcement);\n+}\n+\n void RemoteQueryExecutor::finish(std::unique_ptr<ReadContext> * read_context)\n {\n     /** If one of:\ndiff --git a/src/QueryPipeline/RemoteQueryExecutor.h b/src/QueryPipeline/RemoteQueryExecutor.h\nindex 8b8f21a3ae4a..c67a45c7275d 100644\n--- a/src/QueryPipeline/RemoteQueryExecutor.h\n+++ b/src/QueryPipeline/RemoteQueryExecutor.h\n@@ -10,6 +10,7 @@\n #include <Interpreters/StorageID.h>\n #include <Common/TimerDescriptor.h>\n #include <Storages/MergeTree/ParallelReplicasReadingCoordinator.h>\n+#include <sys/types.h>\n \n \n namespace DB\n@@ -94,12 +95,60 @@ class RemoteQueryExecutor\n     /// Query is resent to a replica, the query itself can be modified.\n     std::atomic<bool> resent_query { false };\n \n+    struct ReadResult\n+    {\n+        enum class Type : uint8_t\n+        {\n+            Data,\n+            ParallelReplicasToken,\n+            FileDescriptor,\n+            Finished,\n+            Nothing\n+        };\n+\n+        explicit ReadResult(Block block_)\n+            : type(Type::Data)\n+            , block(std::move(block_))\n+        {}\n+\n+        explicit ReadResult(int fd_)\n+            : type(Type::FileDescriptor)\n+            , fd(fd_)\n+        {}\n+\n+        explicit ReadResult(Type type_)\n+            : type(type_)\n+        {\n+            assert(type != Type::Data && type != Type::FileDescriptor);\n+        }\n+\n+        Type getType() const { return type; }\n+\n+        Block getBlock()\n+        {\n+            chassert(type == Type::Data);\n+            return std::move(block);\n+        }\n+\n+        int getFileDescriptor() const\n+        {\n+            chassert(type == Type::FileDescriptor);\n+            return fd;\n+        }\n+\n+        Type type;\n+        Block block;\n+        int fd{-1};\n+    };\n+\n     /// Read next block of data. Returns empty block if query is finished.\n-    Block read();\n+    Block readBlock();\n+\n+    ReadResult read();\n \n     /// Async variant of read. Returns ready block or file descriptor which may be used for polling.\n     /// ReadContext is an internal read state. Pass empty ptr first time, reuse created one for every call.\n-    std::variant<Block, int> read(std::unique_ptr<ReadContext> & read_context);\n+    ReadResult read(std::unique_ptr<ReadContext> & read_context);\n \n     /// Receive all remain packets and finish query.\n     /// It should be cancelled after read returned empty block.\n@@ -231,11 +280,12 @@ class RemoteQueryExecutor\n \n     void processReadTaskRequest();\n \n-    void processMergeTreeReadTaskRequest(PartitionReadRequest request);\n+    void processMergeTreeReadTaskRequest(ParallelReadRequest request);\n+    void processMergeTreeInitialReadAnnounecement(InitialAllRangesAnnouncement announcement);\n \n     /// Cancel query and restart it with info about duplicate UUIDs\n     /// only for `allow_experimental_query_deduplication`.\n-    std::variant<Block, int> restartQueryWithoutDuplicatedUUIDs(std::unique_ptr<ReadContext> * read_context = nullptr);\n+    ReadResult restartQueryWithoutDuplicatedUUIDs(std::unique_ptr<ReadContext> * read_context = nullptr);\n \n     /// If wasn't sent yet, send request to cancel all connections to replicas\n     void tryCancel(const char * reason, std::unique_ptr<ReadContext> * read_context);\n@@ -247,11 +297,10 @@ class RemoteQueryExecutor\n     bool hasThrownException() const;\n \n     /// Process packet for read and return data block if possible.\n-    std::optional<Block> processPacket(Packet packet);\n+    ReadResult processPacket(Packet packet);\n \n     /// Reads packet by packet\n     Block readPackets();\n-\n };\n \n }\ndiff --git a/src/Server/TCPHandler.cpp b/src/Server/TCPHandler.cpp\nindex a48a3bb1ed6d..28377edf8ca9 100644\n--- a/src/Server/TCPHandler.cpp\n+++ b/src/Server/TCPHandler.cpp\n@@ -54,6 +54,7 @@\n #include <Processors/Sinks/SinkToStorage.h>\n \n #include \"Core/Protocol.h\"\n+#include \"Storages/MergeTree/RequestResponse.h\"\n #include \"TCPHandler.h\"\n \n #include \"config_version.h\"\n@@ -363,7 +364,17 @@ void TCPHandler::runImpl()\n                 return receiveReadTaskResponseAssumeLocked();\n             });\n \n-            query_context->setMergeTreeReadTaskCallback([this](PartitionReadRequest request) -> std::optional<PartitionReadResponse>\n+            query_context->setMergeTreeAllRangesCallback([this](InitialAllRangesAnnouncement announcement)\n+            {\n+                std::lock_guard lock(task_callback_mutex);\n+\n+                if (state.is_cancelled)\n+                    return;\n+\n+                sendMergeTreeAllRangesAnnounecementAssumeLocked(announcement);\n+            });\n+\n+            query_context->setMergeTreeReadTaskCallback([this](ParallelReadRequest request) -> std::optional<ParallelReadResponse>\n             {\n                 std::lock_guard lock(task_callback_mutex);\n \n@@ -920,7 +931,15 @@ void TCPHandler::sendReadTaskRequestAssumeLocked()\n }\n \n \n-void TCPHandler::sendMergeTreeReadTaskRequestAssumeLocked(PartitionReadRequest request)\n+void TCPHandler::sendMergeTreeAllRangesAnnounecementAssumeLocked(InitialAllRangesAnnouncement announcement)\n+{\n+    writeVarUInt(Protocol::Server::MergeTreeAllRangesAnnounecement, *out);\n+    announcement.serialize(*out);\n+    out->next();\n+}\n+\n+\n+void TCPHandler::sendMergeTreeReadTaskRequestAssumeLocked(ParallelReadRequest request)\n {\n     writeVarUInt(Protocol::Server::MergeTreeReadTaskRequest, *out);\n     request.serialize(*out);\n@@ -1348,7 +1367,7 @@ String TCPHandler::receiveReadTaskResponseAssumeLocked()\n }\n \n \n-std::optional<PartitionReadResponse> TCPHandler::receivePartitionMergeTreeReadTaskResponseAssumeLocked()\n+std::optional<ParallelReadResponse> TCPHandler::receivePartitionMergeTreeReadTaskResponseAssumeLocked()\n {\n     UInt64 packet_type = 0;\n     readVarUInt(packet_type, *in);\n@@ -1371,7 +1390,7 @@ std::optional<PartitionReadResponse> TCPHandler::receivePartitionMergeTreeReadTa\n                     Protocol::Client::toString(packet_type));\n         }\n     }\n-    PartitionReadResponse response;\n+    ParallelReadResponse response;\n     response.deserialize(*in);\n     return response;\n }\ndiff --git a/src/Server/TCPHandler.h b/src/Server/TCPHandler.h\nindex 0b296aaef4e0..f06b0b060b38 100644\n--- a/src/Server/TCPHandler.h\n+++ b/src/Server/TCPHandler.h\n@@ -21,6 +21,7 @@\n \n #include \"IServer.h\"\n #include \"Server/TCPProtocolStackData.h\"\n+#include \"Storages/MergeTree/RequestResponse.h\"\n #include \"base/types.h\"\n \n \n@@ -220,7 +221,7 @@ class TCPHandler : public Poco::Net::TCPServerConnection\n     void receiveQuery();\n     void receiveIgnoredPartUUIDs();\n     String receiveReadTaskResponseAssumeLocked();\n-    std::optional<PartitionReadResponse> receivePartitionMergeTreeReadTaskResponseAssumeLocked();\n+    std::optional<ParallelReadResponse> receivePartitionMergeTreeReadTaskResponseAssumeLocked();\n     bool receiveData(bool scalar);\n     bool readDataNext();\n     void readData();\n@@ -253,7 +254,8 @@ class TCPHandler : public Poco::Net::TCPServerConnection\n     void sendEndOfStream();\n     void sendPartUUIDs();\n     void sendReadTaskRequestAssumeLocked();\n-    void sendMergeTreeReadTaskRequestAssumeLocked(PartitionReadRequest request);\n+    void sendMergeTreeAllRangesAnnounecementAssumeLocked(InitialAllRangesAnnouncement announcement);\n+    void sendMergeTreeReadTaskRequestAssumeLocked(ParallelReadRequest request);\n     void sendProfileInfo(const ProfileInfo & info);\n     void sendTotals(const Block & totals);\n     void sendExtremes(const Block & extremes);\ndiff --git a/src/Storages/MergeTree/IntersectionsIndexes.h b/src/Storages/MergeTree/IntersectionsIndexes.h\nindex 68ccbc4a0b11..d9445f446ce3 100644\n--- a/src/Storages/MergeTree/IntersectionsIndexes.h\n+++ b/src/Storages/MergeTree/IntersectionsIndexes.h\n@@ -136,7 +136,7 @@ struct HalfIntervals\n     MarkRanges convertToMarkRangesFinal()\n     {\n         MarkRanges result;\n-        std::move(intervals.begin(), intervals.end(), std::back_inserter(result));\n+        std::copy(intervals.begin(), intervals.end(), std::back_inserter(result));\n         return result;\n     }\n \ndiff --git a/src/Storages/MergeTree/MarkRange.cpp b/src/Storages/MergeTree/MarkRange.cpp\nindex 0eea0e5afd10..c6c197919f42 100644\n--- a/src/Storages/MergeTree/MarkRange.cpp\n+++ b/src/Storages/MergeTree/MarkRange.cpp\n@@ -1,5 +1,8 @@\n #include \"MarkRange.h\"\n \n+#include <IO/ReadHelpers.h>\n+#include <IO/WriteHelpers.h>\n+\n namespace DB\n {\n \n@@ -8,6 +11,11 @@ namespace ErrorCodes\n     extern const int LOGICAL_ERROR;\n }\n \n+size_t MarkRange::getNumberOfMarks() const\n+{\n+    return end - begin;\n+}\n+\n bool MarkRange::operator==(const MarkRange & rhs) const\n {\n     return begin == rhs.begin && end == rhs.end;\n@@ -65,4 +73,41 @@ void assertSortedAndNonIntersecting(const MarkRanges & ranges)\n             toString(ranges));\n }\n \n+size_t MarkRanges::getNumberOfMarks() const\n+{\n+    size_t result = 0;\n+    for (const auto & mark : *this)\n+        result += mark.getNumberOfMarks();\n+    return result;\n+}\n+\n+void MarkRanges::serialize(WriteBuffer & out) const\n+{\n+    writeIntBinary(this->size(), out);\n+\n+    for (const auto & [begin, end] : *this)\n+    {\n+        writeIntBinary(begin, out);\n+        writeIntBinary(end, out);\n+    }\n+}\n+\n+String MarkRanges::describe() const\n+{\n+    return fmt::format(\"Size: {}, Data: {}\", this->size(), fmt::join(*this, \",\"));\n+}\n+\n+void MarkRanges::deserialize(ReadBuffer & in)\n+{\n+    size_t size = 0;\n+    readIntBinary(size, in);\n+\n+    this->resize(size);\n+    for (size_t i = 0; i < size; ++i)\n+    {\n+        readIntBinary((*this)[i].begin, in);\n+        readIntBinary((*this)[i].end, in);\n+    }\n+}\n+\n }\ndiff --git a/src/Storages/MergeTree/MarkRange.h b/src/Storages/MergeTree/MarkRange.h\nindex 076fc7dfea2c..d1f4e1a4b45a 100644\n--- a/src/Storages/MergeTree/MarkRange.h\n+++ b/src/Storages/MergeTree/MarkRange.h\n@@ -4,7 +4,11 @@\n #include <deque>\n #include <set>\n \n+#include <fmt/core.h>\n+#include <fmt/format.h>\n+\n #include <IO/WriteBuffer.h>\n+#include <IO/ReadBuffer.h>\n \n namespace DB\n {\n@@ -21,12 +25,22 @@ struct MarkRange\n     MarkRange() = default;\n     MarkRange(const size_t begin_, const size_t end_) : begin{begin_}, end{end_} {}\n \n-    bool operator==(const MarkRange & rhs) const;\n+    size_t getNumberOfMarks() const;\n \n+    bool operator==(const MarkRange & rhs) const;\n     bool operator<(const MarkRange & rhs) const;\n };\n \n-using MarkRanges = std::deque<MarkRange>;\n+struct MarkRanges : public std::deque<MarkRange>\n+{\n+    using std::deque<MarkRange>::deque;\n+\n+    size_t getNumberOfMarks() const;\n+\n+    void serialize(WriteBuffer & out) const;\n+    String describe() const;\n+    void deserialize(ReadBuffer & in);\n+};\n \n /** Get max range.end from ranges.\n  */\n@@ -37,3 +51,26 @@ std::string toString(const MarkRanges & ranges);\n void assertSortedAndNonIntersecting(const MarkRanges & ranges);\n \n }\n+\n+\n+template <>\n+struct fmt::formatter<DB::MarkRange>\n+{\n+    constexpr static auto parse(format_parse_context & ctx)\n+    {\n+        const auto * it = ctx.begin();\n+        const auto * end = ctx.end();\n+\n+        /// Only support {}.\n+        if (it != end && *it != '}')\n+            throw format_error(\"invalid format\");\n+\n+        return it;\n+    }\n+\n+    template <typename FormatContext>\n+    auto format(const DB::MarkRange & range, FormatContext & ctx)\n+    {\n+        return format_to(ctx.out(), \"{}\", fmt::format(\"({}, {})\", range.begin, range.end));\n+    }\n+};\ndiff --git a/src/Storages/MergeTree/MergeTreeBaseSelectProcessor.cpp b/src/Storages/MergeTree/MergeTreeBaseSelectProcessor.cpp\nindex e2997df3bb00..db32baadbc65 100644\n--- a/src/Storages/MergeTree/MergeTreeBaseSelectProcessor.cpp\n+++ b/src/Storages/MergeTree/MergeTreeBaseSelectProcessor.cpp\n@@ -49,8 +49,7 @@ IMergeTreeSelectAlgorithm::IMergeTreeSelectAlgorithm(\n     UInt64 preferred_max_column_in_block_size_bytes_,\n     const MergeTreeReaderSettings & reader_settings_,\n     bool use_uncompressed_cache_,\n-    const Names & virt_column_names_,\n-    std::optional<ParallelReadingExtension> extension_)\n+    const Names & virt_column_names_)\n     : storage(storage_)\n     , storage_snapshot(storage_snapshot_)\n     , prewhere_info(prewhere_info_)\n@@ -62,7 +61,6 @@ IMergeTreeSelectAlgorithm::IMergeTreeSelectAlgorithm(\n     , use_uncompressed_cache(use_uncompressed_cache_)\n     , virt_column_names(virt_column_names_)\n     , partition_value_type(storage.getPartitionValueType())\n-    , extension(extension_)\n {\n     header_without_const_virtual_columns = applyPrewhereActions(std::move(header), prewhere_info);\n     size_t non_const_columns_offset = header_without_const_virtual_columns.columns();\n@@ -115,90 +113,15 @@ std::unique_ptr<PrewhereExprInfo> IMergeTreeSelectAlgorithm::getPrewhereActions(\n \n bool IMergeTreeSelectAlgorithm::getNewTask()\n {\n-    /// No parallel reading feature\n-    if (!extension.has_value())\n+    if (getNewTaskImpl())\n     {\n-        if (getNewTaskImpl())\n-        {\n-            finalizeNewTask();\n-            return true;\n-        }\n-        return false;\n-    }\n-    return getNewTaskParallelReading();\n-}\n-\n-\n-bool IMergeTreeSelectAlgorithm::getNewTaskParallelReading()\n-{\n-    if (getTaskFromBuffer())\n+        finalizeNewTask();\n         return true;\n-\n-    if (no_more_tasks)\n-        return getDelayedTasks();\n-\n-    while (true)\n-    {\n-        /// The end of execution. No task.\n-        if (!getNewTaskImpl())\n-        {\n-            no_more_tasks = true;\n-            return getDelayedTasks();\n-        }\n-\n-        splitCurrentTaskRangesAndFillBuffer();\n-\n-        if (getTaskFromBuffer())\n-            return true;\n-    }\n-}\n-\n-\n-bool IMergeTreeSelectAlgorithm::getTaskFromBuffer()\n-{\n-    while (!buffered_ranges.empty())\n-    {\n-        auto ranges = std::move(buffered_ranges.front());\n-        buffered_ranges.pop_front();\n-\n-        assert(!ranges.empty());\n-\n-        auto res = performRequestToCoordinator(ranges, /*delayed=*/false);\n-\n-        if (Status::Accepted == res)\n-            return true;\n-\n-        /// To avoid any possibility of ignoring cancellation, exception will be thrown.\n-        if (Status::Cancelled == res)\n-            throw Exception(ErrorCodes::QUERY_WAS_CANCELLED, \"Query had been cancelled\");\n     }\n     return false;\n }\n \n \n-bool IMergeTreeSelectAlgorithm::getDelayedTasks()\n-{\n-    while (!delayed_tasks.empty())\n-    {\n-        task = std::move(delayed_tasks.front());\n-        delayed_tasks.pop_front();\n-\n-        assert(!task->mark_ranges.empty());\n-\n-        auto res = performRequestToCoordinator(task->mark_ranges, /*delayed=*/true);\n-\n-        if (Status::Accepted == res)\n-            return true;\n-\n-        if (Status::Cancelled == res)\n-            break;\n-    }\n-\n-    finish();\n-    return false;\n-}\n-\n-\n ChunkAndProgress IMergeTreeSelectAlgorithm::read()\n {\n     size_t num_read_rows = 0;\n@@ -688,170 +611,6 @@ std::unique_ptr<MergeTreeBlockSizePredictor> IMergeTreeSelectAlgorithm::getSizeP\n }\n \n \n-IMergeTreeSelectAlgorithm::Status IMergeTreeSelectAlgorithm::performRequestToCoordinator(MarkRanges requested_ranges, bool delayed)\n-{\n-    String partition_id = task->data_part->info.partition_id;\n-    String part_name;\n-    String projection_name;\n-\n-    if (task->data_part->isProjectionPart())\n-    {\n-        part_name = task->data_part->getParentPart()->name;\n-        projection_name = task->data_part->name;\n-    }\n-    else\n-    {\n-        part_name = task->data_part->name;\n-    }\n-\n-    PartBlockRange block_range\n-    {\n-        .begin = task->data_part->info.min_block,\n-        .end = task->data_part->info.max_block\n-    };\n-\n-    PartitionReadRequest request\n-    {\n-        .partition_id = std::move(partition_id),\n-        .part_name = std::move(part_name),\n-        .projection_name = std::move(projection_name),\n-        .block_range = std::move(block_range),\n-        .mark_ranges = std::move(requested_ranges)\n-    };\n-    String request_description = request.toString();\n-\n-    /// Consistent hashing won't work with reading in order, because at the end of the execution\n-    /// we could possibly seek back\n-    if (!delayed && canUseConsistentHashingForParallelReading())\n-    {\n-        const auto hash = request.getConsistentHash(extension->count_participating_replicas);\n-        if (hash != extension->number_of_current_replica)\n-        {\n-            auto delayed_task = std::make_unique<MergeTreeReadTask>(*task); // Create a copy\n-            delayed_task->mark_ranges = std::move(request.mark_ranges);\n-            delayed_tasks.emplace_back(std::move(delayed_task));\n-            LOG_TRACE(log, \"Request delayed by hash: {}\", request_description);\n-            return Status::Denied;\n-        }\n-    }\n-\n-    auto optional_response = extension.value().callback(std::move(request));\n-\n-    if (!optional_response.has_value())\n-    {\n-        LOG_TRACE(log, \"Request cancelled: {}\", request_description);\n-        return Status::Cancelled;\n-    }\n-\n-    auto response = optional_response.value();\n-\n-    task->mark_ranges = std::move(response.mark_ranges);\n-\n-    if (response.denied || task->mark_ranges.empty())\n-    {\n-        LOG_TRACE(log, \"Request rejected: {}\", request_description);\n-        return Status::Denied;\n-    }\n-\n-    finalizeNewTask();\n-\n-    LOG_TRACE(log, \"Request accepted: {}\", request_description);\n-    return Status::Accepted;\n-}\n-\n-\n-size_t IMergeTreeSelectAlgorithm::estimateMaxBatchSizeForHugeRanges()\n-{\n-    /// This is an empirical number and it is so,\n-    /// because we have an adaptive granularity by default.\n-    const size_t average_granule_size_bytes = 1024 * 1024 * 10; // 10 MiB\n-\n-    /// We want to have one RTT per one gigabyte of data read from disk\n-    /// this could be configurable.\n-    const size_t max_size_for_one_request = 1024 * 1024 * 1024; // 1 GiB\n-\n-    size_t sum_average_marks_size = 0;\n-    /// getColumnSize is not fully implemented for compact parts\n-    if (task->data_part->getType() == IMergeTreeDataPart::Type::Compact)\n-    {\n-        sum_average_marks_size = average_granule_size_bytes;\n-    }\n-    else\n-    {\n-        for (const auto & name : extension->colums_to_read)\n-        {\n-            auto size = task->data_part->getColumnSize(name);\n-\n-            assert(size.marks != 0);\n-            sum_average_marks_size += size.data_uncompressed / size.marks;\n-        }\n-    }\n-\n-    if (sum_average_marks_size == 0)\n-        sum_average_marks_size = average_granule_size_bytes; // 10 MiB\n-\n-    LOG_TEST(log, \"Reading from {} part, average mark size is {}\",\n-        task->data_part->getTypeName(), sum_average_marks_size);\n-\n-    return max_size_for_one_request / sum_average_marks_size;\n-}\n-\n-void IMergeTreeSelectAlgorithm::splitCurrentTaskRangesAndFillBuffer()\n-{\n-    const size_t max_batch_size = estimateMaxBatchSizeForHugeRanges();\n-\n-    size_t current_batch_size = 0;\n-    buffered_ranges.emplace_back();\n-\n-    for (const auto & range : task->mark_ranges)\n-    {\n-        auto expand_if_needed = [&]\n-        {\n-            if (current_batch_size > max_batch_size)\n-            {\n-                buffered_ranges.emplace_back();\n-                current_batch_size = 0;\n-            }\n-        };\n-\n-        expand_if_needed();\n-\n-        if (range.end - range.begin < max_batch_size)\n-        {\n-            buffered_ranges.back().push_back(range);\n-            current_batch_size += range.end - range.begin;\n-            continue;\n-        }\n-\n-        auto current_begin = range.begin;\n-        auto current_end = range.begin + max_batch_size;\n-\n-        while (current_end < range.end)\n-        {\n-            auto current_range = MarkRange{current_begin, current_end};\n-            buffered_ranges.back().push_back(current_range);\n-            current_batch_size += current_end - current_begin;\n-\n-            current_begin = current_end;\n-            current_end = current_end + max_batch_size;\n-\n-            expand_if_needed();\n-        }\n-\n-        if (range.end - current_begin > 0)\n-        {\n-            auto current_range = MarkRange{current_begin, range.end};\n-            buffered_ranges.back().push_back(current_range);\n-            current_batch_size += range.end - current_begin;\n-\n-            expand_if_needed();\n-        }\n-    }\n-\n-    if (buffered_ranges.back().empty())\n-        buffered_ranges.pop_back();\n-}\n-\n IMergeTreeSelectAlgorithm::~IMergeTreeSelectAlgorithm() = default;\n \n }\ndiff --git a/src/Storages/MergeTree/MergeTreeBaseSelectProcessor.h b/src/Storages/MergeTree/MergeTreeBaseSelectProcessor.h\nindex 3615127ea345..77d2a383e288 100644\n--- a/src/Storages/MergeTree/MergeTreeBaseSelectProcessor.h\n+++ b/src/Storages/MergeTree/MergeTreeBaseSelectProcessor.h\n@@ -24,6 +24,7 @@ struct ChunkAndProgress\n \n struct ParallelReadingExtension\n {\n+    MergeTreeAllRangesCallback all_callback;\n     MergeTreeReadTaskCallback callback;\n     size_t count_participating_replicas{0};\n     size_t number_of_current_replica{0};\n@@ -48,8 +49,7 @@ class IMergeTreeSelectAlgorithm\n         UInt64 preferred_max_column_in_block_size_bytes_,\n         const MergeTreeReaderSettings & reader_settings_,\n         bool use_uncompressed_cache_,\n-        const Names & virt_column_names_ = {},\n-        std::optional<ParallelReadingExtension> extension_ = {});\n+        const Names & virt_column_names_ = {});\n \n     virtual ~IMergeTreeSelectAlgorithm();\n \n@@ -90,8 +90,6 @@ class IMergeTreeSelectAlgorithm\n \n     size_t estimateMaxBatchSizeForHugeRanges();\n \n-    virtual bool canUseConsistentHashingForParallelReading() { return false; }\n-\n     /// Closes readers and unlock part locks\n     virtual void finish() = 0;\n \n@@ -164,11 +162,6 @@ class IMergeTreeSelectAlgorithm\n \n     MergeTreeReadTaskPtr task;\n \n-    std::optional<ParallelReadingExtension> extension;\n-    bool no_more_tasks{false};\n-    std::deque<MergeTreeReadTaskPtr> delayed_tasks;\n-    std::deque<MarkRanges> buffered_ranges;\n-\n     /// This setting is used in base algorithm only to additionally limit the number of granules to read.\n     /// It is changed in ctor of MergeTreeThreadSelectAlgorithm.\n     ///\n@@ -186,44 +179,8 @@ class IMergeTreeSelectAlgorithm\n \n     std::atomic<bool> is_cancelled{false};\n \n-    enum class Status\n-    {\n-        Accepted,\n-        Cancelled,\n-        Denied\n-    };\n-\n-    /// Calls getNewTaskImpl() to get new task, then performs a request to a coordinator\n-    /// The coordinator may modify the set of ranges to read from a part or could\n-    /// deny the whole request. In the latter case it creates new task and retries.\n-    /// Then it calls finalizeNewTask() to create readers for a task if it is needed.\n     bool getNewTask();\n-    bool getNewTaskParallelReading();\n-\n-    /// After PK analysis the range of marks could be extremely big\n-    /// We divide this range to a set smaller consecutive ranges\n-    /// Then, depending on the type of reading (concurrent, in order or in reverse order)\n-    /// we can calculate a consistent hash function with the number of buckets equal to\n-    /// the number of replicas involved. And after that we can throw away some ranges with\n-    /// hash not equals to the number of the current replica.\n-    bool getTaskFromBuffer();\n-\n-    /// But we can't throw that ranges completely, because if we have different sets of parts\n-    /// on replicas (have merged part on one, but not on another), then such a situation is possible\n-    /// - Coordinator allows to read from a big merged part, but this part is present only on one replica.\n-    ///   And that replica calculates consistent hash and throws away some ranges\n-    /// - Coordinator denies other replicas to read from another parts (source parts for that big one)\n-    /// At the end, the result of the query is wrong, because we didn't read all the data.\n-    /// So, we have to remember parts and mark ranges with hash different then current replica number.\n-    /// An we have to ask the coordinator about its permission to read from that \"delayed\" parts.\n-    /// It won't work with reading in order or reading in reverse order, because we can possibly seek back.\n-    bool getDelayedTasks();\n-\n-    /// It will form a request to coordinator and\n-    /// then reinitialize the mark ranges of this->task object\n-    Status performRequestToCoordinator(MarkRanges requested_ranges, bool delayed);\n-\n-    void splitCurrentTaskRangesAndFillBuffer();\n+\n     static Block applyPrewhereActions(Block block, const PrewhereInfoPtr & prewhere_info);\n };\n \ndiff --git a/src/Storages/MergeTree/MergeTreeBlockReadUtils.cpp b/src/Storages/MergeTree/MergeTreeBlockReadUtils.cpp\nindex 6bd8cc60979e..e300723b37be 100644\n--- a/src/Storages/MergeTree/MergeTreeBlockReadUtils.cpp\n+++ b/src/Storages/MergeTree/MergeTreeBlockReadUtils.cpp\n@@ -135,10 +135,9 @@ NameSet injectRequiredColumns(\n \n \n MergeTreeReadTask::MergeTreeReadTask(\n-    const MergeTreeData::DataPartPtr & data_part_,\n+    const DataPartPtr & data_part_,\n     const MarkRanges & mark_ranges_,\n     size_t part_index_in_query_,\n-    const Names & ordered_names_,\n     const NameSet & column_name_set_,\n     const MergeTreeReadTaskColumns & task_columns_,\n     bool remove_prewhere_column_,\n@@ -146,7 +145,6 @@ MergeTreeReadTask::MergeTreeReadTask(\n     : data_part{data_part_}\n     , mark_ranges{mark_ranges_}\n     , part_index_in_query{part_index_in_query_}\n-    , ordered_names{ordered_names_}\n     , column_name_set{column_name_set_}\n     , task_columns{task_columns_}\n     , remove_prewhere_column{remove_prewhere_column_}\n@@ -156,7 +154,7 @@ MergeTreeReadTask::MergeTreeReadTask(\n \n \n MergeTreeBlockSizePredictor::MergeTreeBlockSizePredictor(\n-    const MergeTreeData::DataPartPtr & data_part_, const Names & columns, const Block & sample_block)\n+    const DataPartPtr & data_part_, const Names & columns, const Block & sample_block)\n     : data_part(data_part_)\n {\n     number_of_rows_in_part = data_part->rows_count;\ndiff --git a/src/Storages/MergeTree/MergeTreeBlockReadUtils.h b/src/Storages/MergeTree/MergeTreeBlockReadUtils.h\nindex 72cdbc562ee5..162b15b6388c 100644\n--- a/src/Storages/MergeTree/MergeTreeBlockReadUtils.h\n+++ b/src/Storages/MergeTree/MergeTreeBlockReadUtils.h\n@@ -2,6 +2,7 @@\n \n #include <optional>\n #include <Core/NamesAndTypes.h>\n+#include <Storages/StorageSnapshot.h>\n #include <Storages/MergeTree/RangesInDataPart.h>\n #include <Storages/MergeTree/MergeTreeRangeReader.h>\n \n@@ -17,6 +18,9 @@ class IMergeTreeDataPartInfoForReader;\n using MergeTreeReadTaskPtr = std::unique_ptr<MergeTreeReadTask>;\n using MergeTreeBlockSizePredictorPtr = std::shared_ptr<MergeTreeBlockSizePredictor>;\n \n+class IMergeTreeDataPart;\n+using DataPartPtr = std::shared_ptr<const IMergeTreeDataPart>;\n+\n \n /** If some of the requested columns are not in the part,\n   * then find out which columns may need to be read further,\n@@ -44,13 +48,11 @@ struct MergeTreeReadTaskColumns\n struct MergeTreeReadTask\n {\n     /// data part which should be read while performing this task\n-    MergeTreeData::DataPartPtr data_part;\n+    DataPartPtr data_part;\n     /// Ranges to read from `data_part`.\n     MarkRanges mark_ranges;\n     /// for virtual `part_index` virtual column\n     size_t part_index_in_query;\n-    /// ordered list of column names used in this query, allows returning blocks with consistent ordering\n-    const Names & ordered_names;\n     /// used to determine whether column should be filtered during PREWHERE or WHERE\n     const NameSet & column_name_set;\n     /// column names to read during PREWHERE and WHERE\n@@ -68,10 +70,9 @@ struct MergeTreeReadTask\n     bool isFinished() const { return mark_ranges.empty() && range_reader.isCurrentRangeFinished(); }\n \n     MergeTreeReadTask(\n-        const MergeTreeData::DataPartPtr & data_part_,\n+        const DataPartPtr & data_part_,\n         const MarkRanges & mark_ranges_,\n         size_t part_index_in_query_,\n-        const Names & ordered_names_,\n         const NameSet & column_name_set_,\n         const MergeTreeReadTaskColumns & task_columns_,\n         bool remove_prewhere_column_,\n@@ -88,7 +89,7 @@ MergeTreeReadTaskColumns getReadTaskColumns(\n \n struct MergeTreeBlockSizePredictor\n {\n-    MergeTreeBlockSizePredictor(const MergeTreeData::DataPartPtr & data_part_, const Names & columns, const Block & sample_block);\n+    MergeTreeBlockSizePredictor(const DataPartPtr & data_part_, const Names & columns, const Block & sample_block);\n \n     /// Reset some values for correct statistics calculating\n     void startBlock();\n@@ -137,7 +138,7 @@ struct MergeTreeBlockSizePredictor\n \n protected:\n \n-    MergeTreeData::DataPartPtr data_part;\n+    DataPartPtr data_part;\n \n     struct ColumnInfo\n     {\ndiff --git a/src/Storages/MergeTree/MergeTreeData.cpp b/src/Storages/MergeTree/MergeTreeData.cpp\nindex b2e0c14489ae..94f6251224d7 100644\n--- a/src/Storages/MergeTree/MergeTreeData.cpp\n+++ b/src/Storages/MergeTree/MergeTreeData.cpp\n@@ -1,36 +1,48 @@\n #include \"Storages/MergeTree/MergeTreeDataPartBuilder.h\"\n #include <Storages/MergeTree/MergeTreeData.h>\n \n+#include <AggregateFunctions/AggregateFunctionCount.h>\n #include <Backups/BackupEntriesCollector.h>\n #include <Backups/BackupEntryFromSmallFile.h>\n #include <Backups/BackupEntryWrappedWith.h>\n #include <Backups/IBackup.h>\n #include <Backups/RestorerFromBackup.h>\n+#include <Common/escapeForFileName.h>\n+#include <Common/Increment.h>\n+#include <Common/noexcept_scope.h>\n+#include <Common/quoteString.h>\n+#include <Common/scope_guard_safe.h>\n+#include <Common/SimpleIncrement.h>\n+#include <Common/Stopwatch.h>\n+#include <Common/StringUtils/StringUtils.h>\n+#include <Common/typeid_cast.h>\n #include <Compression/CompressedReadBuffer.h>\n+#include <Core/QueryProcessingStage.h>\n #include <DataTypes/DataTypeEnum.h>\n #include <DataTypes/DataTypeLowCardinality.h>\n-#include <DataTypes/DataTypeUUID.h>\n #include <DataTypes/DataTypeTuple.h>\n+#include <DataTypes/DataTypeUUID.h>\n+#include <DataTypes/hasNullable.h>\n #include <DataTypes/NestedUtils.h>\n #include <DataTypes/ObjectUtils.h>\n-#include <DataTypes/hasNullable.h>\n #include <Disks/createVolume.h>\n #include <Disks/ObjectStorages/DiskObjectStorage.h>\n+#include <Disks/TemporaryFileOnDisk.h>\n #include <Functions/IFunction.h>\n-#include <IO/Operators.h>\n-#include <IO/WriteBufferFromString.h>\n-#include <IO/S3Common.h>\n #include <Interpreters/Aggregator.h>\n+#include <Interpreters/Context.h>\n+#include <Interpreters/convertFieldToType.h>\n+#include <Interpreters/evaluateConstantExpression.h>\n #include <Interpreters/ExpressionAnalyzer.h>\n-#include <Interpreters/PartLog.h>\n-#include <Interpreters/TreeRewriter.h>\n #include <Interpreters/inplaceBlockConversions.h>\n-#include <Interpreters/MergeTreeTransaction.h>\n-#include <Interpreters/Context.h>\n #include <Interpreters/InterpreterSelectQuery.h>\n+#include <Interpreters/MergeTreeTransaction.h>\n+#include <Interpreters/PartLog.h>\n #include <Interpreters/TransactionLog.h>\n-#include <Interpreters/evaluateConstantExpression.h>\n-#include <Interpreters/convertFieldToType.h>\n+#include <Interpreters/TreeRewriter.h>\n+#include <IO/S3Common.h>\n+#include <IO/Operators.h>\n+#include <IO/WriteBufferFromString.h>\n #include <Parsers/ASTFunction.h>\n #include <Parsers/ASTLiteral.h>\n #include <Parsers/ASTNameTypePair.h>\n@@ -40,29 +52,19 @@\n #include <Parsers/ExpressionListParsers.h>\n #include <Parsers/parseQuery.h>\n #include <Parsers/queryToString.h>\n+#include <Processors/Formats/IInputFormat.h>\n+#include <Processors/QueryPlan/ReadFromMergeTree.h>\n #include <Storages/AlterCommands.h>\n+#include <Storages/Freeze.h>\n+#include <Storages/MergeTree/checkDataPart.h>\n #include <Storages/MergeTree/MergeTreeBaseSelectProcessor.h>\n #include <Storages/MergeTree/MergeTreeDataPartCompact.h>\n #include <Storages/MergeTree/MergeTreeDataPartInMemory.h>\n #include <Storages/MergeTree/MergeTreeDataPartWide.h>\n #include <Storages/MergeTree/DataPartStorageOnDiskFull.h>\n-#include <Storages/MergeTree/checkDataPart.h>\n #include <Storages/StorageMergeTree.h>\n #include <Storages/StorageReplicatedMergeTree.h>\n #include <Storages/VirtualColumnUtils.h>\n-#include <Storages/Freeze.h>\n-#include <Common/Increment.h>\n-#include <Common/SimpleIncrement.h>\n-#include <Common/Stopwatch.h>\n-#include <Common/StringUtils/StringUtils.h>\n-#include <Disks/TemporaryFileOnDisk.h>\n-#include <Common/escapeForFileName.h>\n-#include <Common/quoteString.h>\n-#include <Common/typeid_cast.h>\n-#include <Common/noexcept_scope.h>\n-#include <Processors/Formats/IInputFormat.h>\n-#include <AggregateFunctions/AggregateFunctionCount.h>\n-#include <Common/scope_guard_safe.h>\n \n #include <boost/range/algorithm_ext/erase.hpp>\n #include <boost/algorithm/string/join.hpp>\n@@ -82,6 +84,7 @@\n #include <filesystem>\n \n #include <fmt/format.h>\n+#include <Poco/Logger.h>\n \n template <>\n struct fmt::formatter<DB::DataPartPtr> : fmt::formatter<std::string>\n@@ -6783,6 +6786,14 @@ QueryProcessingStage::Enum MergeTreeData::getQueryProcessingStage(\n     const StorageSnapshotPtr & storage_snapshot,\n     SelectQueryInfo & query_info) const\n {\n+    if (query_context->getClientInfo().collaborate_with_initiator)\n+        return QueryProcessingStage::Enum::FetchColumns;\n+\n+    if (query_context->getSettingsRef().allow_experimental_parallel_reading_from_replicas\n+        && !query_context->getClientInfo().collaborate_with_initiator\n+        && to_stage >= QueryProcessingStage::WithMergeableState)\n+        return QueryProcessingStage::Enum::WithMergeableState;\n+\n     if (to_stage >= QueryProcessingStage::Enum::WithMergeableState)\n     {\n         if (auto projection = getQueryProcessingStageWithAggregateProjection(query_context, storage_snapshot, query_info))\ndiff --git a/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp b/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp\nindex 512f194ea53d..597241c17533 100644\n--- a/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp\n+++ b/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp\n@@ -876,7 +876,8 @@ RangesInDataParts MergeTreeDataSelectExecutor::filterPartsByPrimaryKeyAndSkipInd\n     ReadFromMergeTree::IndexStats & index_stats,\n     bool use_skip_indexes)\n {\n-    RangesInDataParts parts_with_ranges(parts.size());\n+    RangesInDataParts parts_with_ranges;\n+    parts_with_ranges.resize(parts.size());\n     const Settings & settings = context->getSettingsRef();\n \n     /// Let's start analyzing all useful indices\n@@ -1010,7 +1011,7 @@ RangesInDataParts MergeTreeDataSelectExecutor::filterPartsByPrimaryKeyAndSkipInd\n             if (metadata_snapshot->hasPrimaryKey())\n                 ranges.ranges = markRangesFromPKRange(part, metadata_snapshot, key_condition, settings, log);\n             else if (total_marks_count)\n-                ranges.ranges = MarkRanges{MarkRange{0, total_marks_count}};\n+                ranges.ranges = MarkRanges{{MarkRange{0, total_marks_count}}};\n \n             sum_marks_pk.fetch_add(ranges.getMarksCount(), std::memory_order_relaxed);\n \ndiff --git a/src/Storages/MergeTree/MergeTreeInOrderSelectProcessor.cpp b/src/Storages/MergeTree/MergeTreeInOrderSelectProcessor.cpp\nindex 0882b7fa129a..bd7aa34ec0e8 100644\n--- a/src/Storages/MergeTree/MergeTreeInOrderSelectProcessor.cpp\n+++ b/src/Storages/MergeTree/MergeTreeInOrderSelectProcessor.cpp\n@@ -1,4 +1,6 @@\n #include <Storages/MergeTree/MergeTreeInOrderSelectProcessor.h>\n+#include \"Storages/MergeTree/RangesInDataPart.h\"\n+#include <Storages/MergeTree/IntersectionsIndexes.h>\n \n namespace DB\n {\n@@ -18,23 +20,42 @@ try\n         initializeReaders();\n \n     MarkRanges mark_ranges_for_task;\n-    /// If we need to read few rows, set one range per task to reduce number of read data.\n-    if (has_limit_below_one_block)\n+\n+    if (!pool)\n     {\n-        mark_ranges_for_task = { std::move(all_mark_ranges.front()) };\n-        all_mark_ranges.pop_front();\n+        /// If we need to read few rows, set one range per task to reduce number of read data.\n+        if (has_limit_below_one_block)\n+        {\n+            mark_ranges_for_task = MarkRanges{};\n+            mark_ranges_for_task.emplace_front(std::move(all_mark_ranges.front()));\n+            all_mark_ranges.pop_front();\n+        }\n+        else\n+        {\n+            mark_ranges_for_task = std::move(all_mark_ranges);\n+            all_mark_ranges.clear();\n+        }\n     }\n     else\n     {\n-        mark_ranges_for_task = std::move(all_mark_ranges);\n-        all_mark_ranges.clear();\n+        auto description = RangesInDataPartDescription{\n+            .info = data_part->info,\n+            /// We just ignore all the distribution done before\n+            /// Everything will be done on coordinator side\n+            .ranges = {},\n+        };\n+\n+        mark_ranges_for_task = pool->getNewTask(description);\n+\n+        if (mark_ranges_for_task.empty())\n+            return false;\n     }\n \n     auto size_predictor = (preferred_block_size_bytes == 0) ? nullptr\n         : getSizePredictor(data_part, task_columns, sample_block);\n \n     task = std::make_unique<MergeTreeReadTask>(\n-        data_part, mark_ranges_for_task, part_index_in_query, ordered_names, column_name_set, task_columns,\n+        data_part, mark_ranges_for_task, part_index_in_query, column_name_set, task_columns,\n         prewhere_info && prewhere_info->remove_prewhere_column,\n         std::move(size_predictor));\n \ndiff --git a/src/Storages/MergeTree/MergeTreePartInfo.cpp b/src/Storages/MergeTree/MergeTreePartInfo.cpp\nindex a6baecee125e..84432a293d7f 100644\n--- a/src/Storages/MergeTree/MergeTreePartInfo.cpp\n+++ b/src/Storages/MergeTree/MergeTreePartInfo.cpp\n@@ -2,6 +2,7 @@\n #include <IO/ReadBufferFromString.h>\n #include <IO/ReadHelpers.h>\n #include <IO/WriteHelpers.h>\n+#include \"Core/ProtocolDefines.h\"\n \n namespace DB\n {\n@@ -10,6 +11,7 @@ namespace ErrorCodes\n {\n     extern const int BAD_DATA_PART_NAME;\n     extern const int INVALID_PARTITION_VALUE;\n+    extern const int UNKNOWN_FORMAT_VERSION;\n }\n \n \n@@ -253,6 +255,43 @@ String MergeTreePartInfo::getPartNameV0(DayNum left_date, DayNum right_date) con\n     return wb.str();\n }\n \n+void MergeTreePartInfo::serialize(WriteBuffer & out) const\n+{\n+    UInt64 version = DBMS_MERGE_TREE_PART_INFO_VERSION;\n+    /// Must be the first\n+    writeIntBinary(version, out);\n+\n+    writeStringBinary(partition_id, out);\n+    writeIntBinary(min_block, out);\n+    writeIntBinary(max_block, out);\n+    writeIntBinary(level, out);\n+    writeIntBinary(mutation, out);\n+    writeBoolText(use_leagcy_max_level, out);\n+}\n+\n+\n+String MergeTreePartInfo::describe() const\n+{\n+    return getPartNameV1();\n+}\n+\n+\n+void MergeTreePartInfo::deserialize(ReadBuffer & in)\n+{\n+    UInt64 version;\n+    readIntBinary(version, in);\n+    if (version != DBMS_MERGE_TREE_PART_INFO_VERSION)\n+        throw Exception(ErrorCodes::UNKNOWN_FORMAT_VERSION, \"Version for MergeTreePart info mismatched. Got: {}, supported version: {}\",\n+            version, DBMS_MERGE_TREE_PART_INFO_VERSION);\n+\n+    readStringBinary(partition_id, in);\n+    readIntBinary(min_block, in);\n+    readIntBinary(max_block, in);\n+    readIntBinary(level, in);\n+    readIntBinary(mutation, in);\n+    readBoolText(use_leagcy_max_level, in);\n+}\n+\n DetachedPartInfo DetachedPartInfo::parseDetachedPartName(\n     const DiskPtr & disk, std::string_view dir_name, MergeTreeDataFormatVersion format_version)\n {\ndiff --git a/src/Storages/MergeTree/MergeTreePartInfo.h b/src/Storages/MergeTree/MergeTreePartInfo.h\nindex cad851fb882f..b91bc1e595ba 100644\n--- a/src/Storages/MergeTree/MergeTreePartInfo.h\n+++ b/src/Storages/MergeTree/MergeTreePartInfo.h\n@@ -7,6 +7,8 @@\n #include <array>\n #include <base/types.h>\n #include <base/DayNum.h>\n+#include <IO/ReadBuffer.h>\n+#include <IO/WriteBuffer.h>\n #include <Storages/MergeTree/MergeTreeDataFormatVersion.h>\n \n \n@@ -112,6 +114,10 @@ struct MergeTreePartInfo\n         return static_cast<UInt64>(max_block - min_block + 1);\n     }\n \n+    void serialize(WriteBuffer & out) const;\n+    String describe() const;\n+    void deserialize(ReadBuffer & in);\n+\n     /// Simple sanity check for partition ID. Checking that it's not too long or too short, doesn't contain a lot of '_'.\n     static void validatePartitionID(const String & partition_id, MergeTreeDataFormatVersion format_version);\n \ndiff --git a/src/Storages/MergeTree/MergeTreeReadPool.cpp b/src/Storages/MergeTree/MergeTreeReadPool.cpp\nindex 37b24422af01..7444e099150d 100644\n--- a/src/Storages/MergeTree/MergeTreeReadPool.cpp\n+++ b/src/Storages/MergeTree/MergeTreeReadPool.cpp\n@@ -1,6 +1,7 @@\n #include <Storages/MergeTree/MergeTreeReadPool.h>\n #include <Storages/MergeTree/MergeTreeBaseSelectProcessor.h>\n #include <Storages/MergeTree/LoadedMergeTreeDataPartInfoForReader.h>\n+#include \"Common/Stopwatch.h\"\n #include <Common/formatReadable.h>\n #include <base/range.h>\n \n@@ -18,6 +19,52 @@ namespace ErrorCodes\n \n namespace DB\n {\n+\n+std::vector<size_t> IMergeTreeReadPool::fillPerPartInfo(const RangesInDataParts & parts)\n+{\n+    std::vector<size_t> per_part_sum_marks;\n+    Block sample_block = storage_snapshot->metadata->getSampleBlock();\n+    is_part_on_remote_disk.resize(parts.size());\n+\n+    for (const auto i : collections::range(0, parts.size()))\n+    {\n+        const auto & part = parts[i];\n+#ifndef NDEBUG\n+        assertSortedAndNonIntersecting(part.ranges);\n+#endif\n+\n+        bool part_on_remote_disk = part.data_part->isStoredOnRemoteDisk();\n+        is_part_on_remote_disk[i] = part_on_remote_disk;\n+        do_not_steal_tasks |= part_on_remote_disk;\n+\n+        /// Read marks for every data part.\n+        size_t sum_marks = 0;\n+        for (const auto & range : part.ranges)\n+            sum_marks += range.end - range.begin;\n+\n+        per_part_sum_marks.push_back(sum_marks);\n+\n+        auto task_columns = getReadTaskColumns(\n+            LoadedMergeTreeDataPartInfoForReader(part.data_part), storage_snapshot,\n+            column_names, virtual_column_names, prewhere_info, /*with_subcolumns=*/ true);\n+\n+        auto size_predictor = !predict_block_size_bytes ? nullptr\n+            : IMergeTreeSelectAlgorithm::getSizePredictor(part.data_part, task_columns, sample_block);\n+\n+        auto & per_part = per_part_params.emplace_back();\n+\n+        per_part.data_part = part;\n+        per_part.size_predictor = std::move(size_predictor);\n+\n+        /// will be used to distinguish between PREWHERE and WHERE columns when applying filter\n+        const auto & required_column_names = task_columns.columns.getNames();\n+        per_part.column_name_set = {required_column_names.begin(), required_column_names.end()};\n+        per_part.task_columns = std::move(task_columns);\n+    }\n+\n+    return per_part_sum_marks;\n+}\n+\n MergeTreeReadPool::MergeTreeReadPool(\n     size_t threads_,\n     size_t sum_marks_,\n@@ -30,23 +77,25 @@ MergeTreeReadPool::MergeTreeReadPool(\n     const BackoffSettings & backoff_settings_,\n     size_t preferred_block_size_bytes_,\n     bool do_not_steal_tasks_)\n-    : backoff_settings{backoff_settings_}\n+    : IMergeTreeReadPool(\n+        storage_snapshot_,\n+        column_names_,\n+        virtual_column_names_,\n+        min_marks_for_concurrent_read_,\n+        prewhere_info_,\n+        std::move(parts_),\n+        (preferred_block_size_bytes_ > 0),\n+        do_not_steal_tasks_)\n+    , backoff_settings{backoff_settings_}\n     , backoff_state{threads_}\n-    , storage_snapshot{storage_snapshot_}\n-    , column_names{column_names_}\n-    , virtual_column_names{virtual_column_names_}\n-    , do_not_steal_tasks{do_not_steal_tasks_}\n-    , predict_block_size_bytes{preferred_block_size_bytes_ > 0}\n-    , prewhere_info{prewhere_info_}\n-    , parts_ranges{std::move(parts_)}\n {\n     /// parts don't contain duplicate MergeTreeDataPart's.\n     const auto per_part_sum_marks = fillPerPartInfo(parts_ranges);\n-    fillPerThreadInfo(threads_, sum_marks_, per_part_sum_marks, parts_ranges, min_marks_for_concurrent_read_);\n+    fillPerThreadInfo(threads_, sum_marks_, per_part_sum_marks, parts_ranges);\n }\n \n \n-MergeTreeReadTaskPtr MergeTreeReadPool::getTask(size_t min_marks_to_read, size_t thread, const Names & ordered_names)\n+MergeTreeReadTaskPtr MergeTreeReadPool::getTask(size_t thread)\n {\n     const std::lock_guard lock{mutex};\n \n@@ -86,18 +135,18 @@ MergeTreeReadTaskPtr MergeTreeReadPool::getTask(size_t min_marks_to_read, size_t\n     auto & thread_task = thread_tasks.parts_and_ranges.back();\n     const auto part_idx = thread_task.part_idx;\n \n-    auto & part = parts_with_idx[part_idx];\n+    auto & part = per_part_params[part_idx].data_part;\n     auto & marks_in_part = thread_tasks.sum_marks_in_parts.back();\n \n     size_t need_marks;\n     if (is_part_on_remote_disk[part_idx]) /// For better performance with remote disks\n         need_marks = marks_in_part;\n     else /// Get whole part to read if it is small enough.\n-        need_marks = std::min(marks_in_part, min_marks_to_read);\n+        need_marks = std::min(marks_in_part, min_marks_for_concurrent_read);\n \n     /// Do not leave too little rows in part for next time.\n     if (marks_in_part > need_marks &&\n-        marks_in_part - need_marks < min_marks_to_read)\n+        marks_in_part - need_marks < min_marks_for_concurrent_read)\n         need_marks = marks_in_part;\n \n     MarkRanges ranges_to_get_from_part;\n@@ -142,7 +191,7 @@ MergeTreeReadTaskPtr MergeTreeReadPool::getTask(size_t min_marks_to_read, size_t\n         : std::make_unique<MergeTreeBlockSizePredictor>(*per_part.size_predictor); /// make a copy\n \n     return std::make_unique<MergeTreeReadTask>(\n-        part.data_part, ranges_to_get_from_part, part.part_index_in_query, ordered_names,\n+        part.data_part, ranges_to_get_from_part, part.part_index_in_query,\n         per_part.column_name_set, per_part.task_columns,\n         prewhere_info && prewhere_info->remove_prewhere_column, std::move(curr_task_size_predictor));\n }\n@@ -192,56 +241,9 @@ void MergeTreeReadPool::profileFeedback(ReadBufferFromFileBase::ProfileInfo info\n }\n \n \n-std::vector<size_t> MergeTreeReadPool::fillPerPartInfo(const RangesInDataParts & parts)\n-{\n-    std::vector<size_t> per_part_sum_marks;\n-    Block sample_block = storage_snapshot->metadata->getSampleBlock();\n-    is_part_on_remote_disk.resize(parts.size());\n-\n-    for (const auto i : collections::range(0, parts.size()))\n-    {\n-        const auto & part = parts[i];\n-#ifndef NDEBUG\n-        assertSortedAndNonIntersecting(part.ranges);\n-#endif\n-\n-        bool part_on_remote_disk = part.data_part->isStoredOnRemoteDisk();\n-        is_part_on_remote_disk[i] = part_on_remote_disk;\n-        do_not_steal_tasks |= part_on_remote_disk;\n-\n-        /// Read marks for every data part.\n-        size_t sum_marks = 0;\n-        for (const auto & range : part.ranges)\n-            sum_marks += range.end - range.begin;\n-\n-        per_part_sum_marks.push_back(sum_marks);\n-\n-        auto task_columns = getReadTaskColumns(\n-            LoadedMergeTreeDataPartInfoForReader(part.data_part), storage_snapshot,\n-            column_names, virtual_column_names, prewhere_info, /*with_subcolumns=*/ true);\n-\n-        auto size_predictor = !predict_block_size_bytes ? nullptr\n-            : IMergeTreeSelectAlgorithm::getSizePredictor(part.data_part, task_columns, sample_block);\n-\n-        auto & per_part = per_part_params.emplace_back();\n-\n-        per_part.size_predictor = std::move(size_predictor);\n-\n-        /// will be used to distinguish between PREWHERE and WHERE columns when applying filter\n-        const auto & required_column_names = task_columns.columns.getNames();\n-        per_part.column_name_set = {required_column_names.begin(), required_column_names.end()};\n-        per_part.task_columns = std::move(task_columns);\n-\n-        parts_with_idx.push_back({ part.data_part, part.part_index_in_query });\n-    }\n-\n-    return per_part_sum_marks;\n-}\n-\n-\n void MergeTreeReadPool::fillPerThreadInfo(\n     size_t threads, size_t sum_marks, std::vector<size_t> per_part_sum_marks,\n-    const RangesInDataParts & parts, size_t min_marks_for_concurrent_read)\n+    const RangesInDataParts & parts)\n {\n     threads_tasks.resize(threads);\n     if (parts.empty())\n@@ -355,4 +357,148 @@ void MergeTreeReadPool::fillPerThreadInfo(\n }\n \n \n+MergeTreeReadPoolParallelReplicas::~MergeTreeReadPoolParallelReplicas() = default;\n+\n+\n+Block MergeTreeReadPoolParallelReplicas::getHeader() const\n+{\n+    return storage_snapshot->getSampleBlockForColumns(extension.colums_to_read);\n+}\n+\n+MergeTreeReadTaskPtr MergeTreeReadPoolParallelReplicas::getTask(size_t thread)\n+{\n+    /// This parameter is needed only to satisfy the interface\n+    UNUSED(thread);\n+\n+    std::lock_guard lock(mutex);\n+\n+    if (no_more_tasks_available)\n+        return nullptr;\n+\n+    if (buffered_ranges.empty())\n+    {\n+        auto result = extension.callback(ParallelReadRequest{\n+            .replica_num = extension.number_of_current_replica, .min_number_of_marks = min_marks_for_concurrent_read * threads});\n+\n+        if (!result || result->finish)\n+        {\n+            no_more_tasks_available = true;\n+            return nullptr;\n+        }\n+\n+        buffered_ranges = std::move(result->description);\n+    }\n+\n+    if (buffered_ranges.empty())\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"No tasks to read. This is a bug\");\n+\n+    auto & current_task = buffered_ranges.front();\n+\n+    RangesInDataPart part;\n+    size_t part_idx = 0;\n+    for (size_t index = 0; index < per_part_params.size(); ++index)\n+    {\n+        auto & other_part = per_part_params[index];\n+        if (other_part.data_part.data_part->info == current_task.info)\n+        {\n+            part = other_part.data_part;\n+            part_idx = index;\n+            break;\n+        }\n+    }\n+\n+    MarkRanges ranges_to_read;\n+    size_t current_sum_marks = 0;\n+    while (current_sum_marks < min_marks_for_concurrent_read && !current_task.ranges.empty())\n+    {\n+        auto diff = min_marks_for_concurrent_read - current_sum_marks;\n+        auto range = current_task.ranges.front();\n+        if (range.getNumberOfMarks() > diff)\n+        {\n+            auto new_range = range;\n+            new_range.end = range.begin + diff;\n+            range.begin += diff;\n+\n+            current_task.ranges.front() = range;\n+            ranges_to_read.push_back(new_range);\n+            current_sum_marks += new_range.getNumberOfMarks();\n+            continue;\n+        }\n+\n+        ranges_to_read.push_back(range);\n+        current_sum_marks += range.getNumberOfMarks();\n+        current_task.ranges.pop_front();\n+    }\n+\n+    if (current_task.ranges.empty())\n+        buffered_ranges.pop_front();\n+\n+    const auto & per_part = per_part_params[part_idx];\n+\n+    auto curr_task_size_predictor\n+        = !per_part.size_predictor ? nullptr : std::make_unique<MergeTreeBlockSizePredictor>(*per_part.size_predictor); /// make a copy\n+\n+    return std::make_unique<MergeTreeReadTask>(\n+        part.data_part,\n+        ranges_to_read,\n+        part.part_index_in_query,\n+        per_part.column_name_set,\n+        per_part.task_columns,\n+        prewhere_info && prewhere_info->remove_prewhere_column,\n+        std::move(curr_task_size_predictor));\n+}\n+\n+\n+MarkRanges MergeTreeInOrderReadPoolParallelReplicas::getNewTask(RangesInDataPartDescription description)\n+{\n+    std::lock_guard lock(mutex);\n+\n+    auto get_from_buffer = [&]() -> std::optional<MarkRanges>\n+    {\n+        for (auto & desc : buffered_tasks)\n+        {\n+            if (desc.info == description.info && !desc.ranges.empty())\n+            {\n+                auto result = std::move(desc.ranges);\n+                desc.ranges = MarkRanges{};\n+                return result;\n+            }\n+        }\n+        return std::nullopt;\n+    };\n+\n+    if (auto result = get_from_buffer(); result)\n+        return result.value();\n+\n+    if (no_more_tasks)\n+        return {};\n+\n+    auto response = extension.callback(ParallelReadRequest{\n+        .mode = mode,\n+        .replica_num = extension.number_of_current_replica,\n+        .min_number_of_marks = min_marks_for_concurrent_read * request.size(),\n+        .description = request,\n+    });\n+\n+    if (!response || response->description.empty() || response->finish)\n+    {\n+        no_more_tasks = true;\n+        return {};\n+    }\n+\n+    /// Fill the buffer\n+    for (size_t i = 0; i < request.size(); ++i)\n+    {\n+        auto & new_ranges = response->description[i].ranges;\n+        auto & old_ranges = buffered_tasks[i].ranges;\n+        std::move(new_ranges.begin(), new_ranges.end(), std::back_inserter(old_ranges));\n+    }\n+\n+    if (auto result = get_from_buffer(); result)\n+        return result.value();\n+\n+    return {};\n+}\n+\n+\n }\ndiff --git a/src/Storages/MergeTree/MergeTreeReadPool.h b/src/Storages/MergeTree/MergeTreeReadPool.h\nindex c9fe70d9a78a..46d2e8bae3bb 100644\n--- a/src/Storages/MergeTree/MergeTreeReadPool.h\n+++ b/src/Storages/MergeTree/MergeTreeReadPool.h\n@@ -1,10 +1,13 @@\n #pragma once\n \n #include <Core/NamesAndTypes.h>\n-#include <Storages/MergeTree/RangesInDataPart.h>\n+#include <Storages/MergeTree/MergeTreeBaseSelectProcessor.h>\n #include <Storages/MergeTree/MergeTreeBlockReadUtils.h>\n #include <Storages/MergeTree/MergeTreeData.h>\n+#include <Storages/MergeTree/RangesInDataPart.h>\n+#include <Storages/MergeTree/RequestResponse.h>\n #include <Storages/SelectQueryInfo.h>\n+\n #include <mutex>\n \n \n@@ -13,6 +16,64 @@ namespace DB\n \n using MergeTreeReadTaskPtr = std::unique_ptr<MergeTreeReadTask>;\n \n+\n+class IMergeTreeReadPool\n+{\n+public:\n+    IMergeTreeReadPool(\n+        StorageSnapshotPtr storage_snapshot_,\n+        Names column_names_,\n+        Names virtual_column_names_,\n+        size_t min_marks_for_concurrent_read_,\n+        PrewhereInfoPtr prewhere_info_,\n+        RangesInDataParts parts_ranges_,\n+        bool predict_block_size_bytes_,\n+        bool do_not_steal_tasks_)\n+        : storage_snapshot(storage_snapshot_)\n+        , column_names(column_names_)\n+        , virtual_column_names(virtual_column_names_)\n+        , min_marks_for_concurrent_read(min_marks_for_concurrent_read_)\n+        , prewhere_info(prewhere_info_)\n+        , parts_ranges(parts_ranges_)\n+        , predict_block_size_bytes(predict_block_size_bytes_)\n+        , do_not_steal_tasks(do_not_steal_tasks_)\n+    {}\n+\n+    virtual MergeTreeReadTaskPtr getTask(size_t thread) = 0;\n+    virtual Block getHeader() const = 0;\n+    virtual void profileFeedback(ReadBufferFromFileBase::ProfileInfo info) = 0;\n+    virtual ~IMergeTreeReadPool() = default;\n+\n+protected:\n+\n+    std::vector<size_t> fillPerPartInfo(const RangesInDataParts & parts);\n+\n+    /// Initialized in constructor\n+    StorageSnapshotPtr storage_snapshot;\n+    const Names column_names;\n+    const Names virtual_column_names;\n+    size_t min_marks_for_concurrent_read{0};\n+    PrewhereInfoPtr prewhere_info;\n+    RangesInDataParts parts_ranges;\n+    bool predict_block_size_bytes;\n+    bool do_not_steal_tasks;\n+\n+    struct PerPartParams\n+    {\n+        MergeTreeReadTaskColumns task_columns;\n+        NameSet column_name_set;\n+        MergeTreeBlockSizePredictorPtr size_predictor;\n+        RangesInDataPart data_part;\n+    };\n+\n+    std::vector<PerPartParams> per_part_params;\n+    std::vector<bool> is_part_on_remote_disk;\n+\n+    mutable std::mutex mutex;\n+};\n+\n+using IMergeTreeReadPoolPtr = std::shared_ptr<IMergeTreeReadPool>;\n+\n /**   Provides read tasks for MergeTreeThreadSelectProcessor`s in fine-grained batches, allowing for more\n  *    uniform distribution of work amongst multiple threads. All parts and their ranges are divided into `threads`\n  *    workloads with at most `sum_marks / threads` marks. Then, threads are performing reads from these workloads\n@@ -20,7 +81,7 @@ using MergeTreeReadTaskPtr = std::unique_ptr<MergeTreeReadTask>;\n  *    it's workload, it either is signaled that no more work is available (`do_not_steal_tasks == false`) or\n  *    continues taking small batches from other threads' workloads (`do_not_steal_tasks == true`).\n  */\n-class MergeTreeReadPool : private boost::noncopyable\n+class MergeTreeReadPool final: public IMergeTreeReadPool, private boost::noncopyable\n {\n public:\n     /** Pull could dynamically lower (backoff) number of threads, if read operation are too slow.\n@@ -82,47 +143,22 @@ class MergeTreeReadPool : private boost::noncopyable\n         size_t preferred_block_size_bytes_,\n         bool do_not_steal_tasks_ = false);\n \n-    MergeTreeReadTaskPtr getTask(size_t min_marks_to_read, size_t thread, const Names & ordered_names);\n+    ~MergeTreeReadPool() override = default;\n+    MergeTreeReadTaskPtr getTask(size_t thread) override;\n \n     /** Each worker could call this method and pass information about read performance.\n       * If read performance is too low, pool could decide to lower number of threads: do not assign more tasks to several threads.\n       * This allows to overcome excessive load to disk subsystem, when reads are not from page cache.\n       */\n-    void profileFeedback(ReadBufferFromFileBase::ProfileInfo info);\n+    void profileFeedback(ReadBufferFromFileBase::ProfileInfo info) override;\n \n-    Block getHeader() const;\n+    Block getHeader() const override;\n \n private:\n-    std::vector<size_t> fillPerPartInfo(const RangesInDataParts & parts);\n \n     void fillPerThreadInfo(\n         size_t threads, size_t sum_marks, std::vector<size_t> per_part_sum_marks,\n-        const RangesInDataParts & parts, size_t min_marks_for_concurrent_read);\n-\n-    StorageSnapshotPtr storage_snapshot;\n-    const Names column_names;\n-    const Names virtual_column_names;\n-    bool do_not_steal_tasks;\n-    bool predict_block_size_bytes;\n-\n-    struct PerPartParams\n-    {\n-        MergeTreeReadTaskColumns task_columns;\n-        NameSet column_name_set;\n-        MergeTreeBlockSizePredictorPtr size_predictor;\n-    };\n-\n-    std::vector<PerPartParams> per_part_params;\n-\n-    PrewhereInfoPtr prewhere_info;\n-\n-    struct Part\n-    {\n-        MergeTreeData::DataPartPtr data_part;\n-        size_t part_index_in_query;\n-    };\n-\n-    std::vector<Part> parts_with_idx;\n+        const RangesInDataParts & parts);\n \n     struct ThreadTask\n     {\n@@ -137,18 +173,104 @@ class MergeTreeReadPool : private boost::noncopyable\n     };\n \n     std::vector<ThreadTask> threads_tasks;\n-\n     std::set<size_t> remaining_thread_tasks;\n+    Poco::Logger * log = &Poco::Logger::get(\"MergeTreeReadPool\");\n \n-    RangesInDataParts parts_ranges;\n+};\n \n-    mutable std::mutex mutex;\n+using MergeTreeReadPoolPtr = std::shared_ptr<MergeTreeReadPool>;\n \n-    Poco::Logger * log = &Poco::Logger::get(\"MergeTreeReadPool\");\n+class MergeTreeReadPoolParallelReplicas : public IMergeTreeReadPool, private boost::noncopyable\n+{\n+public:\n \n-    std::vector<bool> is_part_on_remote_disk;\n+    MergeTreeReadPoolParallelReplicas(\n+        StorageSnapshotPtr storage_snapshot_,\n+        size_t threads_,\n+        ParallelReadingExtension extension_,\n+        const RangesInDataParts & parts_,\n+        const PrewhereInfoPtr & prewhere_info_,\n+        const Names & column_names_,\n+        const Names & virtual_column_names_,\n+        size_t min_marks_for_concurrent_read_\n+    )\n+    : IMergeTreeReadPool(\n+        storage_snapshot_,\n+        column_names_,\n+        virtual_column_names_,\n+        min_marks_for_concurrent_read_,\n+        prewhere_info_,\n+        parts_,\n+        /*predict_block_size*/false,\n+        /*do_not_steal_tasks*/false)\n+    , extension(extension_)\n+    , threads(threads_)\n+    {\n+        fillPerPartInfo(parts_ranges);\n+\n+        extension.all_callback({\n+            .description = parts_ranges.getDescriptions(),\n+            .replica_num = extension.number_of_current_replica\n+        });\n+    }\n+\n+    ~MergeTreeReadPoolParallelReplicas() override;\n+\n+    MergeTreeReadTaskPtr getTask(size_t thread) override;\n+    Block getHeader() const override;\n+    void profileFeedback(ReadBufferFromFileBase::ProfileInfo) override {}\n+\n+private:\n+    ParallelReadingExtension extension;\n+\n+    RangesInDataPartsDescription buffered_ranges;\n+    size_t threads;\n+    bool no_more_tasks_available{false};\n+    Poco::Logger * log = &Poco::Logger::get(\"MergeTreeReadPoolParallelReplicas\");\n };\n \n-using MergeTreeReadPoolPtr = std::shared_ptr<MergeTreeReadPool>;\n+using MergeTreeReadPoolParallelReplicasPtr = std::shared_ptr<MergeTreeReadPoolParallelReplicas>;\n+\n+\n+class MergeTreeInOrderReadPoolParallelReplicas : private boost::noncopyable\n+{\n+public:\n+    MergeTreeInOrderReadPoolParallelReplicas(\n+        RangesInDataParts parts_,\n+        ParallelReadingExtension extension_,\n+        CoordinationMode mode_,\n+        size_t min_marks_for_concurrent_read_)\n+    : parts_ranges(parts_)\n+    , extension(extension_)\n+    , mode(mode_)\n+    , min_marks_for_concurrent_read(min_marks_for_concurrent_read_)\n+    {\n+        for (const auto & part : parts_ranges)\n+            request.push_back({part.data_part->info, MarkRanges{}});\n+\n+        for (const auto & part : parts_ranges)\n+            buffered_tasks.push_back({part.data_part->info, MarkRanges{}});\n+\n+        extension.all_callback({\n+            .description = parts_ranges.getDescriptions(),\n+            .replica_num = extension.number_of_current_replica\n+        });\n+    }\n+\n+    MarkRanges getNewTask(RangesInDataPartDescription description);\n+\n+    RangesInDataParts parts_ranges;\n+    ParallelReadingExtension extension;\n+    CoordinationMode mode;\n+    size_t min_marks_for_concurrent_read{0};\n+\n+    bool no_more_tasks{false};\n+    RangesInDataPartsDescription request;\n+    RangesInDataPartsDescription buffered_tasks;\n+\n+    std::mutex mutex;\n+};\n+\n+using MergeTreeInOrderReadPoolParallelReplicasPtr = std::shared_ptr<MergeTreeInOrderReadPoolParallelReplicas>;\n \n }\ndiff --git a/src/Storages/MergeTree/MergeTreeReverseSelectProcessor.cpp b/src/Storages/MergeTree/MergeTreeReverseSelectProcessor.cpp\nindex d0d464b3c298..367818c7af14 100644\n--- a/src/Storages/MergeTree/MergeTreeReverseSelectProcessor.cpp\n+++ b/src/Storages/MergeTree/MergeTreeReverseSelectProcessor.cpp\n@@ -1,4 +1,6 @@\n #include <Storages/MergeTree/MergeTreeReverseSelectProcessor.h>\n+#include <Storages/MergeTree/IntersectionsIndexes.h>\n+#include \"Storages/MergeTree/MergeTreeBaseSelectProcessor.h\"\n \n namespace DB\n {\n@@ -10,6 +12,22 @@ namespace ErrorCodes\n \n bool MergeTreeReverseSelectAlgorithm::getNewTaskImpl()\n try\n+{\n+    if (pool)\n+        return getNewTaskParallelReplicas();\n+    else\n+        return getNewTaskOrdinaryReading();\n+}\n+catch (...)\n+{\n+    /// Suspicion of the broken part. A part is added to the queue for verification.\n+    if (getCurrentExceptionCode() != ErrorCodes::MEMORY_LIMIT_EXCEEDED)\n+        storage.reportBrokenPart(data_part);\n+    throw;\n+}\n+\n+\n+bool MergeTreeReverseSelectAlgorithm::getNewTaskOrdinaryReading()\n {\n     if (chunks.empty() && all_mark_ranges.empty())\n         return false;\n@@ -23,25 +41,57 @@ try\n         initializeReaders();\n \n     /// Read ranges from right to left.\n-    MarkRanges mark_ranges_for_task = { all_mark_ranges.back() };\n+    MarkRanges mark_ranges_for_task{std::move(all_mark_ranges.back())};\n     all_mark_ranges.pop_back();\n \n     auto size_predictor = (preferred_block_size_bytes == 0) ? nullptr\n         : getSizePredictor(data_part, task_columns, sample_block);\n \n     task = std::make_unique<MergeTreeReadTask>(\n-        data_part, mark_ranges_for_task, part_index_in_query, ordered_names, column_name_set,\n+        data_part, mark_ranges_for_task, part_index_in_query, column_name_set,\n         task_columns, prewhere_info && prewhere_info->remove_prewhere_column,\n         std::move(size_predictor));\n \n     return true;\n+\n }\n-catch (...)\n+\n+bool MergeTreeReverseSelectAlgorithm::getNewTaskParallelReplicas()\n {\n-    /// Suspicion of the broken part. A part is added to the queue for verification.\n-    if (getCurrentExceptionCode() != ErrorCodes::MEMORY_LIMIT_EXCEEDED)\n-        storage.reportBrokenPart(data_part);\n-    throw;\n+    if (chunks.empty() && no_more_tasks)\n+        return false;\n+\n+    /// We have some blocks to return in buffer.\n+    /// Return true to continue reading, but actually don't create a task.\n+    if (no_more_tasks)\n+        return true;\n+\n+    if (!reader)\n+        initializeReaders();\n+\n+    auto description = RangesInDataPartDescription{\n+        .info = data_part->info,\n+        /// We just ignore all the distribution done before\n+        /// Everything will be done on coordinator side\n+        .ranges = {},\n+    };\n+\n+    auto mark_ranges_for_task = pool->getNewTask(description);\n+    if (mark_ranges_for_task.empty())\n+    {\n+        /// If we have chunks in buffer - return true to continue reading from them\n+        return !chunks.empty();\n+    }\n+\n+    auto size_predictor = (preferred_block_size_bytes == 0) ? nullptr\n+        : getSizePredictor(data_part, task_columns, sample_block);\n+\n+    task = std::make_unique<MergeTreeReadTask>(\n+        data_part, mark_ranges_for_task, part_index_in_query, column_name_set,\n+        task_columns, prewhere_info && prewhere_info->remove_prewhere_column,\n+        std::move(size_predictor));\n+\n+    return true;\n }\n \n MergeTreeReverseSelectAlgorithm::BlockAndProgress MergeTreeReverseSelectAlgorithm::readFromPart()\ndiff --git a/src/Storages/MergeTree/MergeTreeReverseSelectProcessor.h b/src/Storages/MergeTree/MergeTreeReverseSelectProcessor.h\nindex ccadb1f1c611..fd25748050a2 100644\n--- a/src/Storages/MergeTree/MergeTreeReverseSelectProcessor.h\n+++ b/src/Storages/MergeTree/MergeTreeReverseSelectProcessor.h\n@@ -27,9 +27,16 @@ class MergeTreeReverseSelectAlgorithm final : public MergeTreeSelectAlgorithm\n     bool getNewTaskImpl() override;\n     void finalizeNewTask() override {}\n \n+    bool getNewTaskParallelReplicas();\n+    bool getNewTaskOrdinaryReading();\n+\n     BlockAndProgress readFromPart() override;\n \n     std::vector<BlockAndProgress> chunks;\n+\n+    /// Used for parallel replicas\n+    bool no_more_tasks{false};\n+\n     Poco::Logger * log = &Poco::Logger::get(\"MergeTreeReverseSelectProcessor\");\n };\n \ndiff --git a/src/Storages/MergeTree/MergeTreeSelectProcessor.cpp b/src/Storages/MergeTree/MergeTreeSelectProcessor.cpp\nindex 3f9da9c130a1..e5ca851c76b8 100644\n--- a/src/Storages/MergeTree/MergeTreeSelectProcessor.cpp\n+++ b/src/Storages/MergeTree/MergeTreeSelectProcessor.cpp\n@@ -21,21 +21,22 @@ MergeTreeSelectAlgorithm::MergeTreeSelectAlgorithm(\n     const PrewhereInfoPtr & prewhere_info_,\n     ExpressionActionsSettings actions_settings,\n     const MergeTreeReaderSettings & reader_settings_,\n+    MergeTreeInOrderReadPoolParallelReplicasPtr pool_,\n     const Names & virt_column_names_,\n     size_t part_index_in_query_,\n-    bool has_limit_below_one_block_,\n-    std::optional<ParallelReadingExtension> extension_)\n+    bool has_limit_below_one_block_)\n     : IMergeTreeSelectAlgorithm{\n         storage_snapshot_->getSampleBlockForColumns(required_columns_),\n         storage_, storage_snapshot_, prewhere_info_, std::move(actions_settings), max_block_size_rows_,\n         preferred_block_size_bytes_, preferred_max_column_in_block_size_bytes_,\n-        reader_settings_, use_uncompressed_cache_, virt_column_names_, extension_},\n+        reader_settings_, use_uncompressed_cache_, virt_column_names_},\n     required_columns{std::move(required_columns_)},\n     data_part{owned_data_part_},\n     sample_block(storage_snapshot_->metadata->getSampleBlock()),\n     all_mark_ranges(std::move(mark_ranges_)),\n     part_index_in_query(part_index_in_query_),\n     has_limit_below_one_block(has_limit_below_one_block_),\n+    pool(pool_),\n     total_rows(data_part->index_granularity.getRowsCountInRanges(all_mark_ranges))\n {\n     ordered_names = header_without_const_virtual_columns.getNames();\ndiff --git a/src/Storages/MergeTree/MergeTreeSelectProcessor.h b/src/Storages/MergeTree/MergeTreeSelectProcessor.h\nindex 12f4804835c0..76c8d81dd0b6 100644\n--- a/src/Storages/MergeTree/MergeTreeSelectProcessor.h\n+++ b/src/Storages/MergeTree/MergeTreeSelectProcessor.h\n@@ -3,6 +3,7 @@\n #include <Storages/MergeTree/MergeTreeData.h>\n #include <Storages/MergeTree/MarkRange.h>\n #include <Storages/MergeTree/MergeTreeBlockReadUtils.h>\n+#include <Storages/MergeTree/MergeTreeReadPool.h>\n #include <Storages/SelectQueryInfo.h>\n \n \n@@ -29,10 +30,10 @@ class MergeTreeSelectAlgorithm : public IMergeTreeSelectAlgorithm\n         const PrewhereInfoPtr & prewhere_info,\n         ExpressionActionsSettings actions_settings,\n         const MergeTreeReaderSettings & reader_settings,\n+        MergeTreeInOrderReadPoolParallelReplicasPtr pool_,\n         const Names & virt_column_names = {},\n         size_t part_index_in_query_ = 0,\n-        bool has_limit_below_one_block_ = false,\n-        std::optional<ParallelReadingExtension> extension_ = {});\n+        bool has_limit_below_one_block_ = false);\n \n     ~MergeTreeSelectAlgorithm() override;\n \n@@ -64,6 +65,9 @@ class MergeTreeSelectAlgorithm : public IMergeTreeSelectAlgorithm\n     /// It reduces amount of read data for queries with small LIMIT.\n     bool has_limit_below_one_block = false;\n \n+    /// Pool for reading in order\n+    MergeTreeInOrderReadPoolParallelReplicasPtr pool;\n+\n     size_t total_rows = 0;\n };\n \ndiff --git a/src/Storages/MergeTree/MergeTreeThreadSelectProcessor.cpp b/src/Storages/MergeTree/MergeTreeThreadSelectProcessor.cpp\nindex 60586024359d..97c283b8c018 100644\n--- a/src/Storages/MergeTree/MergeTreeThreadSelectProcessor.cpp\n+++ b/src/Storages/MergeTree/MergeTreeThreadSelectProcessor.cpp\n@@ -7,16 +7,11 @@\n namespace DB\n {\n \n-namespace ErrorCodes\n-{\n-    extern const int LOGICAL_ERROR;\n-}\n-\n MergeTreeThreadSelectAlgorithm::MergeTreeThreadSelectAlgorithm(\n     size_t thread_,\n-    const MergeTreeReadPoolPtr & pool_,\n-    size_t min_marks_to_read_,\n-    UInt64 max_block_size_rows_,\n+    IMergeTreeReadPoolPtr pool_,\n+    size_t min_marks_for_concurrent_read_,\n+    size_t max_block_size_rows_,\n     size_t preferred_block_size_bytes_,\n     size_t preferred_max_column_in_block_size_bytes_,\n     const MergeTreeData & storage_,\n@@ -25,74 +20,22 @@ MergeTreeThreadSelectAlgorithm::MergeTreeThreadSelectAlgorithm(\n     const PrewhereInfoPtr & prewhere_info_,\n     ExpressionActionsSettings actions_settings,\n     const MergeTreeReaderSettings & reader_settings_,\n-    const Names & virt_column_names_,\n-    std::optional<ParallelReadingExtension> extension_)\n+    const Names & virt_column_names_)\n     :\n     IMergeTreeSelectAlgorithm{\n         pool_->getHeader(), storage_, storage_snapshot_, prewhere_info_, std::move(actions_settings), max_block_size_rows_,\n         preferred_block_size_bytes_, preferred_max_column_in_block_size_bytes_,\n-        reader_settings_, use_uncompressed_cache_, virt_column_names_, extension_},\n+        reader_settings_, use_uncompressed_cache_, virt_column_names_},\n     thread{thread_},\n-    pool{pool_}\n+    pool{std::move(pool_)}\n {\n-    /// round min_marks_to_read up to nearest multiple of block_size expressed in marks\n-    /// If granularity is adaptive it doesn't make sense\n-    /// Maybe it will make sense to add settings `max_block_size_bytes`\n-    if (max_block_size_rows && !storage.canUseAdaptiveGranularity())\n-    {\n-        size_t fixed_index_granularity = storage.getSettings()->index_granularity;\n-        min_marks_to_read = (min_marks_to_read_ * fixed_index_granularity + max_block_size_rows - 1)\n-            / max_block_size_rows * max_block_size_rows / fixed_index_granularity;\n-    }\n-    else if (extension.has_value())\n-    {\n-        /// Parallel reading from replicas is enabled.\n-        /// We try to estimate the average number of bytes in a granule\n-        /// to make one request over the network per one gigabyte of data\n-        /// Actually we will ask MergeTreeReadPool to provide us heavier tasks to read\n-        /// because the most part of each task will be postponed\n-        /// (due to using consistent hash for better cache affinity)\n-        const size_t amount_of_read_bytes_per_one_request = 1024 * 1024 * 1024; // 1GiB\n-        /// In case of reading from compact parts (for which we can't estimate the average size of marks)\n-        /// we will use this value\n-        const size_t empirical_size_of_mark = 1024 * 1024 * 10; // 10 MiB\n-\n-        if (extension->colums_to_read.empty())\n-            throw Exception(ErrorCodes::LOGICAL_ERROR, \"A set of column to read is empty. It is a bug\");\n-\n-        size_t sum_average_marks_size = 0;\n-        auto column_sizes = storage.getColumnSizes();\n-        for (const auto & name : extension->colums_to_read)\n-        {\n-            auto it = column_sizes.find(name);\n-            if (it == column_sizes.end())\n-                continue;\n-            auto size = it->second;\n-\n-            if (size.data_compressed == 0 || size.data_uncompressed == 0 || size.marks == 0)\n-                continue;\n-\n-            sum_average_marks_size += size.data_uncompressed / size.marks;\n-        }\n-\n-        if (sum_average_marks_size == 0)\n-            sum_average_marks_size = empirical_size_of_mark * extension->colums_to_read.size();\n-\n-        min_marks_to_read = extension->count_participating_replicas * amount_of_read_bytes_per_one_request / sum_average_marks_size;\n-    }\n-    else\n-    {\n-        min_marks_to_read = min_marks_to_read_;\n-    }\n-\n-\n-    ordered_names = getHeader().getNames();\n+    min_marks_to_read = min_marks_for_concurrent_read_;\n }\n \n /// Requests read task from MergeTreeReadPool and signals whether it got one\n bool MergeTreeThreadSelectAlgorithm::getNewTaskImpl()\n {\n-    task = pool->getTask(min_marks_to_read, thread, ordered_names);\n+    task = pool->getTask(thread);\n     return static_cast<bool>(task);\n }\n \n@@ -113,19 +56,19 @@ void MergeTreeThreadSelectAlgorithm::finalizeNewTask()\n             owned_uncompressed_cache = storage.getContext()->getUncompressedCache();\n         owned_mark_cache = storage.getContext()->getMarkCache();\n     }\n-    else if (part_name != last_readed_part_name)\n+    else if (part_name != last_read_part_name)\n     {\n         value_size_map = reader->getAvgValueSizeHints();\n     }\n \n-    const bool init_new_readers = !reader || part_name != last_readed_part_name;\n+    const bool init_new_readers = !reader || part_name != last_read_part_name;\n     if (init_new_readers)\n     {\n         initializeMergeTreeReadersForPart(task->data_part, task->task_columns, metadata_snapshot,\n             task->mark_ranges, value_size_map, profile_callback);\n     }\n \n-    last_readed_part_name = part_name;\n+    last_read_part_name = part_name;\n }\n \n \ndiff --git a/src/Storages/MergeTree/MergeTreeThreadSelectProcessor.h b/src/Storages/MergeTree/MergeTreeThreadSelectProcessor.h\nindex ac3dcf0cc417..37c9375a5811 100644\n--- a/src/Storages/MergeTree/MergeTreeThreadSelectProcessor.h\n+++ b/src/Storages/MergeTree/MergeTreeThreadSelectProcessor.h\n@@ -5,8 +5,8 @@\n namespace DB\n {\n \n-class MergeTreeReadPool;\n-\n+class IMergeTreeReadPool;\n+using IMergeTreeReadPoolPtr = std::shared_ptr<IMergeTreeReadPool>;\n \n /** Used in conjunction with MergeTreeReadPool, asking it for more work to do and performing whatever reads it is asked\n   * to perform.\n@@ -16,9 +16,9 @@ class MergeTreeThreadSelectAlgorithm final : public IMergeTreeSelectAlgorithm\n public:\n     MergeTreeThreadSelectAlgorithm(\n         size_t thread_,\n-        const std::shared_ptr<MergeTreeReadPool> & pool_,\n-        size_t min_marks_to_read_,\n-        UInt64 max_block_size_,\n+        IMergeTreeReadPoolPtr pool_,\n+        size_t min_marks_for_concurrent_read,\n+        size_t max_block_size_,\n         size_t preferred_block_size_bytes_,\n         size_t preferred_max_column_in_block_size_bytes_,\n         const MergeTreeData & storage_,\n@@ -27,8 +27,7 @@ class MergeTreeThreadSelectAlgorithm final : public IMergeTreeSelectAlgorithm\n         const PrewhereInfoPtr & prewhere_info_,\n         ExpressionActionsSettings actions_settings,\n         const MergeTreeReaderSettings & reader_settings_,\n-        const Names & virt_column_names_,\n-        std::optional<ParallelReadingExtension> extension_);\n+        const Names & virt_column_names_);\n \n     String getName() const override { return \"MergeTreeThread\"; }\n \n@@ -42,18 +41,14 @@ class MergeTreeThreadSelectAlgorithm final : public IMergeTreeSelectAlgorithm\n \n     void finish() override;\n \n-    bool canUseConsistentHashingForParallelReading() override { return true; }\n-\n private:\n     /// \"thread\" index (there are N threads and each thread is assigned index in interval [0..N-1])\n     size_t thread;\n \n-    std::shared_ptr<MergeTreeReadPool> pool;\n+    IMergeTreeReadPoolPtr pool;\n \n     /// Last part read in this thread\n-    std::string last_readed_part_name;\n-    /// Names from header. Used in order to order columns in read blocks.\n-    Names ordered_names;\n+    std::string last_read_part_name;\n };\n \n }\ndiff --git a/src/Storages/MergeTree/ParallelReplicasReadingCoordinator.cpp b/src/Storages/MergeTree/ParallelReplicasReadingCoordinator.cpp\nindex e07f19fb64c9..3ef064ff7439 100644\n--- a/src/Storages/MergeTree/ParallelReplicasReadingCoordinator.cpp\n+++ b/src/Storages/MergeTree/ParallelReplicasReadingCoordinator.cpp\n@@ -1,23 +1,95 @@\n #include <Storages/MergeTree/ParallelReplicasReadingCoordinator.h>\n \n+#include <algorithm>\n+#include <mutex>\n+#include <numeric>\n+#include <vector>\n #include <map>\n+#include <set>\n+\n+#include <consistent_hashing.h>\n \n #include <Common/logger_useful.h>\n-#include <base/scope_guard.h>\n-#include <Common/Stopwatch.h>\n-#include <IO/WriteBufferFromString.h>\n+#include <Common/SipHash.h>\n+#include <Common/thread_local_rng.h>\n+#include <base/types.h>\n+#include \"IO/WriteBufferFromString.h\"\n+#include \"Storages/MergeTree/RangesInDataPart.h\"\n+#include \"Storages/MergeTree/RequestResponse.h\"\n+#include <Storages/MergeTree/MarkRange.h>\n #include <Storages/MergeTree/IntersectionsIndexes.h>\n+#include <fmt/format.h>\n \n \n namespace DB\n {\n \n-class ParallelReplicasReadingCoordinator::Impl\n+namespace ErrorCodes\n+{\n+    extern const int LOGICAL_ERROR;\n+}\n+\n+class ParallelReplicasReadingCoordinator::ImplInterface\n+{\n+public:\n+    struct Stat\n+    {\n+        size_t number_of_requests{0};\n+        size_t sum_marks{0};\n+    };\n+    using Stats = std::vector<Stat>;\n+    static String toString(Stats stats)\n+    {\n+        String result = \"Statistics: \";\n+        for (size_t i = 0; i < stats.size(); ++i)\n+            result += fmt::format(\"-- replica {}, requests: {} marks: {} \", i, stats[i].number_of_requests, stats[i].sum_marks);\n+        return result;\n+    }\n+\n+    Stats stats;\n+    std::mutex mutex;\n+    size_t replicas_count;\n+\n+    explicit ImplInterface(size_t replicas_count_)\n+        : stats{replicas_count_}\n+        , replicas_count(replicas_count_)\n+    {}\n+\n+    virtual ~ImplInterface() = default;\n+    virtual ParallelReadResponse handleRequest(ParallelReadRequest request) = 0;\n+    virtual void handleInitialAllRangesAnnouncement(InitialAllRangesAnnouncement announcement) = 0;\n+};\n+\n+\n+struct Part\n+{\n+    mutable RangesInDataPartDescription description;\n+    // FIXME: This is needed to put this struct in set\n+    // and modify through iterator\n+    mutable std::set<size_t> replicas;\n+\n+    bool operator<(const Part & rhs) const { return description.info < rhs.description.info; }\n+};\n+\n+using Parts = std::set<Part>;\n+using PartRefs = std::deque<Parts::iterator>;\n+\n+\n+class DefaultCoordinator : public ParallelReplicasReadingCoordinator::ImplInterface\n {\n public:\n-    using PartitionReadRequestPtr = std::unique_ptr<PartitionReadRequest>;\n+    using ParallelReadRequestPtr = std::unique_ptr<ParallelReadRequest>;\n     using PartToMarkRanges = std::map<PartToRead::PartAndProjectionNames, HalfIntervals>;\n \n+    explicit DefaultCoordinator(size_t replicas_count_)\n+        : ParallelReplicasReadingCoordinator::ImplInterface(replicas_count_)\n+        , announcements(replicas_count_)\n+        , reading_state(replicas_count_)\n+    {\n+    }\n+\n+    ~DefaultCoordinator() override;\n+\n     struct PartitionReading\n     {\n         PartSegments part_ranges;\n@@ -27,115 +99,423 @@ class ParallelReplicasReadingCoordinator::Impl\n     using PartitionToBlockRanges = std::map<String, PartitionReading>;\n     PartitionToBlockRanges partitions;\n \n-    std::mutex mutex;\n+    size_t sent_initial_requests{0};\n+    std::vector<InitialAllRangesAnnouncement> announcements;\n+\n+    Parts all_parts_to_read;\n+    /// Contains only parts which we haven't started to read from\n+    PartRefs delayed_parts;\n+    /// Per-replica preferred parts split by consistent hash\n+    /// Once all task will be done by some replica, it can steal tasks\n+    std::vector<PartRefs> reading_state;\n+\n+    Poco::Logger * log = &Poco::Logger::get(\"DefaultCoordinator\");\n+\n+    std::atomic<bool> state_initialized{false};\n+\n+    ParallelReadResponse handleRequest(ParallelReadRequest request) override;\n+    void handleInitialAllRangesAnnouncement(InitialAllRangesAnnouncement announcement) override;\n+\n+    void updateReadingState(const InitialAllRangesAnnouncement & announcement);\n+    void finalizeReadingState();\n+\n+    size_t computeConsistentHash(const MergeTreePartInfo & info) const\n+    {\n+        auto hash = SipHash();\n+        hash.update(info.getPartNameV1());\n+        return ConsistentHashing(hash.get64(), replicas_count);\n+    }\n \n-    PartitionReadResponse handleRequest(PartitionReadRequest request);\n+    void selectPartsAndRanges(const PartRefs & container, size_t replica_num, size_t min_number_of_marks, size_t & current_mark_size, ParallelReadResponse & response) const;\n };\n \n+DefaultCoordinator::~DefaultCoordinator()\n+{\n+    LOG_INFO(log, \"Coordination done: {}\", toString(stats));\n+}\n \n-PartitionReadResponse ParallelReplicasReadingCoordinator::Impl::handleRequest(PartitionReadRequest request)\n+void DefaultCoordinator::updateReadingState(const InitialAllRangesAnnouncement & announcement)\n {\n-    auto * log = &Poco::Logger::get(\"ParallelReplicasReadingCoordinator\");\n-    Stopwatch watch;\n+    PartRefs parts_diff;\n \n-    String request_description = request.toString();\n-    std::lock_guard lock(mutex);\n+    /// To get rid of duplicates\n+    for (const auto & part: announcement.description)\n+    {\n+        auto the_same_it = std::find_if(all_parts_to_read.begin(), all_parts_to_read.end(),\n+            [&part] (const Part & other) { return other.description.info.getPartNameV1() == part.info.getPartNameV1(); });\n \n-    auto partition_it = partitions.find(request.partition_id);\n+        /// We have the same part - add the info about presence on current replica to it\n+        if (the_same_it != all_parts_to_read.end())\n+        {\n+            the_same_it->replicas.insert(announcement.replica_num);\n+            continue;\n+        }\n \n-    PartToRead::PartAndProjectionNames part_and_projection\n-    {\n-        .part = request.part_name,\n-        .projection = request.projection_name\n-    };\n+        auto covering_or_the_same_it = std::find_if(all_parts_to_read.begin(), all_parts_to_read.end(),\n+            [&part] (const Part & other) { return !other.description.info.isDisjoint(part.info); });\n+\n+        /// It is covering part or we have covering - skip it\n+        if (covering_or_the_same_it != all_parts_to_read.end())\n+            continue;\n \n-    /// We are the first who wants to process parts in partition\n-    if (partition_it == partitions.end())\n+        auto new_part = Part{\n+            .description = part,\n+            .replicas = {announcement.replica_num}\n+        };\n+\n+        auto [insert_it, _] = all_parts_to_read.insert(new_part);\n+        parts_diff.push_back(insert_it);\n+    }\n+\n+    /// Split all parts by consistent hash\n+    while (!parts_diff.empty())\n     {\n-        PartitionReading partition_reading;\n+        auto current_part_it = parts_diff.front();\n+        parts_diff.pop_front();\n+        auto consistent_hash = computeConsistentHash(current_part_it->description.info);\n \n-        PartToRead part_to_read;\n-        part_to_read.range = request.block_range;\n-        part_to_read.name = part_and_projection;\n+        /// Check whether the new part can easy go to replica queue\n+        if (current_part_it->replicas.contains(consistent_hash))\n+        {\n+            reading_state[consistent_hash].emplace_back(current_part_it);\n+            continue;\n+        }\n \n-        partition_reading.part_ranges.addPart(std::move(part_to_read));\n+        /// Add to delayed parts\n+        delayed_parts.emplace_back(current_part_it);\n+    }\n+}\n+\n+void DefaultCoordinator::finalizeReadingState()\n+{\n+    /// Clear all the delayed queue\n+    while (!delayed_parts.empty())\n+    {\n+        auto current_part_it = delayed_parts.front();\n+        auto consistent_hash = computeConsistentHash(current_part_it->description.info);\n \n-        /// As this query is first in partition, we will accept all ranges from it.\n-        /// We need just to update our state.\n-        auto request_ranges = HalfIntervals::initializeFromMarkRanges(request.mark_ranges);\n-        auto mark_ranges_index = HalfIntervals::initializeWithEntireSpace();\n-        mark_ranges_index.intersect(request_ranges.negate());\n+        if (current_part_it->replicas.contains(consistent_hash))\n+        {\n+            reading_state[consistent_hash].emplace_back(current_part_it);\n+            delayed_parts.pop_front();\n+            continue;\n+        }\n \n-        partition_reading.mark_ranges_in_part.insert({part_and_projection, std::move(mark_ranges_index)});\n-        partitions.insert({request.partition_id, std::move(partition_reading)});\n+        /// In this situation just assign to a random replica which has this part\n+        auto replica = *(std::next(current_part_it->replicas.begin(), thread_local_rng() % current_part_it->replicas.size()));\n+        reading_state[replica].emplace_back(current_part_it);\n+        delayed_parts.pop_front();\n+    }\n \n-        LOG_TRACE(log, \"Request is first in partition, accepted in {} ns: {}\", watch.elapsed(), request_description);\n-        return {.denied = false, .mark_ranges = std::move(request.mark_ranges)};\n+    String description;\n+    for (const auto & part : all_parts_to_read)\n+    {\n+        description += part.description.describe();\n+        description += fmt::format(\"Replicas: ({}) --- \", fmt::join(part.replicas, \",\"));\n     }\n \n-    auto & partition_reading = partition_it->second;\n+    LOG_INFO(log, \"Reading state is fully initialized: {}\", description);\n+}\n+\n+\n+void DefaultCoordinator::handleInitialAllRangesAnnouncement(InitialAllRangesAnnouncement announcement)\n+{\n+    std::lock_guard lock(mutex);\n \n-    PartToRead part_to_read;\n-    part_to_read.range = request.block_range;\n-    part_to_read.name = part_and_projection;\n+    updateReadingState(announcement);\n+    stats[announcement.replica_num].number_of_requests +=1;\n \n-    auto part_intersection_res = partition_reading.part_ranges.getIntersectionResult(part_to_read);\n+    ++sent_initial_requests;\n+    LOG_INFO(log, \"{} {}\", sent_initial_requests, replicas_count);\n+    if (sent_initial_requests == replicas_count)\n+        finalizeReadingState();\n+}\n \n-    switch (part_intersection_res)\n+void DefaultCoordinator::selectPartsAndRanges(const PartRefs & container, size_t replica_num, size_t min_number_of_marks, size_t & current_mark_size, ParallelReadResponse & response) const\n+{\n+    for (const auto & part : container)\n     {\n-        case PartSegments::IntersectionResult::REJECT:\n+        if (current_mark_size >= min_number_of_marks)\n         {\n-            LOG_TRACE(log, \"Request rejected in {} ns: {}\", watch.elapsed(), request_description);\n-            return {.denied = true, .mark_ranges = {}};\n+            LOG_TEST(log, \"Current mark size {} is bigger than min_number_marks {}\", current_mark_size, min_number_of_marks);\n+            break;\n         }\n-        case PartSegments::IntersectionResult::EXACTLY_ONE_INTERSECTION:\n+\n+        if (part->description.ranges.empty())\n         {\n-            auto marks_it = partition_reading.mark_ranges_in_part.find(part_and_projection);\n+            LOG_TEST(log, \"Part {} is already empty in reading state\", part->description.info.getPartNameV1());\n+            continue;\n+        }\n \n-            auto & intervals_to_do = marks_it->second;\n-            auto result = HalfIntervals::initializeFromMarkRanges(request.mark_ranges);\n-            result.intersect(intervals_to_do);\n+        if (std::find(part->replicas.begin(), part->replicas.end(), replica_num) == part->replicas.end())\n+        {\n+            LOG_TEST(log, \"Not found part {} on replica {}\", part->description.info.getPartNameV1(), replica_num);\n+            continue;\n+        }\n \n-            /// Update intervals_to_do\n-            intervals_to_do.intersect(HalfIntervals::initializeFromMarkRanges(std::move(request.mark_ranges)).negate());\n+        response.description.push_back({\n+            .info = part->description.info,\n+            .ranges = {},\n+        });\n \n-            auto result_ranges = result.convertToMarkRangesFinal();\n-            const bool denied = result_ranges.empty();\n+        while (!part->description.ranges.empty() && current_mark_size < min_number_of_marks)\n+        {\n+            auto & range = part->description.ranges.front();\n+\n+            if (range.getNumberOfMarks() > min_number_of_marks)\n+            {\n+                auto new_range = range;\n+                range.begin += min_number_of_marks;\n+                new_range.end = new_range.begin + min_number_of_marks;\n+\n+                response.description.back().ranges.emplace_back(new_range);\n+                current_mark_size += new_range.getNumberOfMarks();\n+                continue;\n+            }\n+\n+            current_mark_size += part->description.ranges.front().getNumberOfMarks();\n+            response.description.back().ranges.emplace_back(part->description.ranges.front());\n+            part->description.ranges.pop_front();\n+        }\n+    }\n+}\n+\n+ParallelReadResponse DefaultCoordinator::handleRequest(ParallelReadRequest request)\n+{\n+    std::lock_guard lock(mutex);\n+\n+    LOG_TRACE(log, \"Handling request from replica {}, minimal marks size is {}\", request.replica_num, request.min_number_of_marks);\n+\n+    size_t current_mark_size = 0;\n+    ParallelReadResponse response;\n+\n+    /// 1. Try to select from preferred set of parts for current replica\n+    selectPartsAndRanges(reading_state[request.replica_num], request.replica_num, request.min_number_of_marks, current_mark_size, response);\n+\n+    /// 2. Try to use parts from delayed queue\n+    while (!delayed_parts.empty() && current_mark_size < request.min_number_of_marks)\n+    {\n+        auto part = delayed_parts.front();\n+        delayed_parts.pop_front();\n+        reading_state[request.replica_num].emplace_back(part);\n+        selectPartsAndRanges(reading_state[request.replica_num], request.replica_num, request.min_number_of_marks, current_mark_size, response);\n+    }\n \n-            if (denied)\n-                LOG_TRACE(log, \"Request rejected due to intersection in {} ns: {}\", watch.elapsed(), request_description);\n-            else\n-                LOG_TRACE(log, \"Request accepted partially in {} ns: {}\", watch.elapsed(), request_description);\n+    /// 3. Try to steal tasks;\n+    if (current_mark_size < request.min_number_of_marks)\n+    {\n+        for (size_t i = 0; i < replicas_count; ++i)\n+        {\n+            if (i != request.replica_num)\n+                selectPartsAndRanges(reading_state[i], request.replica_num, request.min_number_of_marks, current_mark_size, response);\n \n-            return {.denied = denied, .mark_ranges = std::move(result_ranges)};\n+            if (current_mark_size >= request.min_number_of_marks)\n+                break;\n         }\n-        case PartSegments::IntersectionResult::NO_INTERSECTION:\n+    }\n+\n+    stats[request.replica_num].number_of_requests += 1;\n+    stats[request.replica_num].sum_marks += current_mark_size;\n+\n+    if (response.description.empty())\n+        response.finish = true;\n+\n+    LOG_TRACE(log, \"Going to respond to replica {} with {}\", request.replica_num, response.describe());\n+    return response;\n+}\n+\n+\n+template <CoordinationMode mode>\n+class InOrderCoordinator : public ParallelReplicasReadingCoordinator::ImplInterface\n+{\n+public:\n+    explicit InOrderCoordinator([[ maybe_unused ]] size_t replicas_count_)\n+        : ParallelReplicasReadingCoordinator::ImplInterface(replicas_count_)\n+    {}\n+    ~InOrderCoordinator() override\n+    {\n+        LOG_INFO(log, \"Coordination done: {}\", toString(stats));\n+    }\n+\n+    ParallelReadResponse handleRequest([[ maybe_unused ]]  ParallelReadRequest request) override;\n+    void handleInitialAllRangesAnnouncement([[ maybe_unused ]]  InitialAllRangesAnnouncement announcement) override;\n+\n+    Parts all_parts_to_read;\n+\n+    Poco::Logger * log = &Poco::Logger::get(fmt::format(\"{}{}\", magic_enum::enum_name(mode), \"Coordinator\"));\n+};\n+\n+\n+template <CoordinationMode mode>\n+void InOrderCoordinator<mode>::handleInitialAllRangesAnnouncement(InitialAllRangesAnnouncement announcement)\n+{\n+    std::lock_guard lock(mutex);\n+    LOG_TRACE(log, \"Received an announecement {}\", announcement.describe());\n+\n+    /// To get rid of duplicates\n+    for (const auto & part: announcement.description)\n+    {\n+        auto the_same_it = std::find_if(all_parts_to_read.begin(), all_parts_to_read.end(),\n+            [&part] (const Part & other) { return other.description.info == part.info; });\n+\n+        /// We have the same part - add the info about presence on current replica to it\n+        if (the_same_it != all_parts_to_read.end())\n         {\n-            partition_reading.part_ranges.addPart(std::move(part_to_read));\n+            the_same_it->replicas.insert(announcement.replica_num);\n+            continue;\n+        }\n \n-            auto mark_ranges_index = HalfIntervals::initializeWithEntireSpace().intersect(\n-            HalfIntervals::initializeFromMarkRanges(request.mark_ranges).negate()\n-            );\n-            partition_reading.mark_ranges_in_part.insert({part_and_projection, std::move(mark_ranges_index)});\n+        auto covering_or_the_same_it = std::find_if(all_parts_to_read.begin(), all_parts_to_read.end(),\n+            [&part] (const Part & other) { return other.description.info.contains(part.info) ||  part.info.contains(other.description.info); });\n \n-            LOG_TRACE(log, \"Request accepted in {} ns: {}\", watch.elapsed(), request_description);\n-            return {.denied = false, .mark_ranges = std::move(request.mark_ranges)};\n+        /// It is covering part or we have covering - skip it\n+        if (covering_or_the_same_it != all_parts_to_read.end())\n+            continue;\n+\n+        auto new_part = Part{\n+            .description = part,\n+            .replicas = {announcement.replica_num}\n+        };\n+\n+        auto insert_it = all_parts_to_read.insert(new_part);\n+        auto & ranges = insert_it.first->description.ranges;\n+        std::sort(ranges.begin(), ranges.end());\n+    }\n+}\n+\n+\n+template <CoordinationMode mode>\n+ParallelReadResponse InOrderCoordinator<mode>::handleRequest(ParallelReadRequest request)\n+{\n+    std::lock_guard lock(mutex);\n+\n+    if (request.mode != mode)\n+        throw Exception(ErrorCodes::LOGICAL_ERROR,\n+            \"Replica {} decided to read in {} mode, not in {}. This is a bug\",\n+            request.replica_num, magic_enum::enum_name(request.mode), magic_enum::enum_name(mode));\n+\n+    LOG_TRACE(log, \"Got request from replica {}, data {}\", request.replica_num, request.describe());\n+\n+    ParallelReadResponse response;\n+    response.description = request.description;\n+    size_t overall_number_of_marks = 0;\n+\n+    for (auto & part : response.description)\n+    {\n+        auto global_part_it = std::find_if(all_parts_to_read.begin(), all_parts_to_read.end(),\n+            [&part] (const Part & other) { return other.description.info == part.info; });\n+\n+        if (global_part_it == all_parts_to_read.end())\n+            continue;\n+\n+        if (!global_part_it->replicas.contains(request.replica_num))\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Part {} doesn't exist on replica {} according to the global state\", part.info.getPartNameV1(), request.replica_num);\n+\n+        size_t current_mark_size = 0;\n+\n+        /// Now we can recommend to read more intervals\n+        if constexpr (mode == CoordinationMode::ReverseOrder)\n+        {\n+            while (!global_part_it->description.ranges.empty() && current_mark_size < request.min_number_of_marks)\n+            {\n+                auto range = global_part_it->description.ranges.back();\n+\n+                if (range.getNumberOfMarks() > request.min_number_of_marks)\n+                {\n+                    auto new_range = range;\n+                    range.end -= request.min_number_of_marks;\n+                    new_range.begin = new_range.end - request.min_number_of_marks;\n+\n+                    global_part_it->description.ranges.back() = range;\n+\n+                    part.ranges.emplace_front(new_range);\n+                    current_mark_size += new_range.getNumberOfMarks();\n+                    continue;\n+                }\n+\n+                current_mark_size += global_part_it->description.ranges.back().getNumberOfMarks();\n+                part.ranges.emplace_front(global_part_it->description.ranges.back());\n+                global_part_it->description.ranges.pop_back();\n+            }\n         }\n+        else if constexpr (mode == CoordinationMode::WithOrder)\n+        {\n+            while (!global_part_it->description.ranges.empty() && current_mark_size < request.min_number_of_marks)\n+            {\n+                auto range = global_part_it->description.ranges.front();\n+\n+                if (range.getNumberOfMarks() > request.min_number_of_marks)\n+                {\n+                    auto new_range = range;\n+                    range.begin += request.min_number_of_marks;\n+                    new_range.end = new_range.begin + request.min_number_of_marks;\n+\n+                    global_part_it->description.ranges.front() = range;\n+\n+                    part.ranges.emplace_back(new_range);\n+                    current_mark_size += new_range.getNumberOfMarks();\n+                    continue;\n+                }\n+\n+                current_mark_size += global_part_it->description.ranges.front().getNumberOfMarks();\n+                part.ranges.emplace_back(global_part_it->description.ranges.front());\n+                global_part_it->description.ranges.pop_front();\n+            }\n+        }\n+\n+        overall_number_of_marks += current_mark_size;\n     }\n \n-    UNREACHABLE();\n+    if (!overall_number_of_marks)\n+        response.finish = true;\n+\n+    stats[request.replica_num].number_of_requests += 1;\n+    stats[request.replica_num].sum_marks += overall_number_of_marks;\n+\n+    LOG_TRACE(log, \"Going to respond to replica {} with {}\", request.replica_num, response.describe());\n+    return response;\n }\n \n-PartitionReadResponse ParallelReplicasReadingCoordinator::handleRequest(PartitionReadRequest request)\n+\n+void ParallelReplicasReadingCoordinator::handleInitialAllRangesAnnouncement(InitialAllRangesAnnouncement announcement)\n {\n+    if (!pimpl)\n+        initialize();\n+\n+    return pimpl->handleInitialAllRangesAnnouncement(announcement);\n+}\n+\n+ParallelReadResponse ParallelReplicasReadingCoordinator::handleRequest(ParallelReadRequest request)\n+{\n+    if (!pimpl)\n+        initialize();\n+\n     return pimpl->handleRequest(std::move(request));\n }\n \n-ParallelReplicasReadingCoordinator::ParallelReplicasReadingCoordinator()\n+void ParallelReplicasReadingCoordinator::setMode(CoordinationMode mode_)\n+{\n+    mode = mode_;\n+}\n+\n+void ParallelReplicasReadingCoordinator::initialize()\n {\n-    pimpl = std::make_unique<ParallelReplicasReadingCoordinator::Impl>();\n+    switch (mode)\n+    {\n+        case CoordinationMode::Default:\n+            pimpl = std::make_unique<DefaultCoordinator>(replicas_count);\n+            return;\n+        case CoordinationMode::WithOrder:\n+            pimpl = std::make_unique<InOrderCoordinator<CoordinationMode::WithOrder>>(replicas_count);\n+            return;\n+        case CoordinationMode::ReverseOrder:\n+            pimpl = std::make_unique<InOrderCoordinator<CoordinationMode::ReverseOrder>>(replicas_count);\n+            return;\n+    }\n }\n \n+ParallelReplicasReadingCoordinator::ParallelReplicasReadingCoordinator(size_t replicas_count_) : replicas_count(replicas_count_) {}\n+\n ParallelReplicasReadingCoordinator::~ParallelReplicasReadingCoordinator() = default;\n \n }\ndiff --git a/src/Storages/MergeTree/ParallelReplicasReadingCoordinator.h b/src/Storages/MergeTree/ParallelReplicasReadingCoordinator.h\nindex 4800533e919b..0656a1288845 100644\n--- a/src/Storages/MergeTree/ParallelReplicasReadingCoordinator.h\n+++ b/src/Storages/MergeTree/ParallelReplicasReadingCoordinator.h\n@@ -7,15 +7,28 @@\n namespace DB\n {\n \n+/// The main class to spread mark ranges across replicas dynamically\n+/// The reason why it uses pimpl - this header file is included in\n+/// multiple other files like Context or RemoteQueryExecutor\n class ParallelReplicasReadingCoordinator\n {\n public:\n-    ParallelReplicasReadingCoordinator();\n+    class ImplInterface;\n+\n+    explicit ParallelReplicasReadingCoordinator(size_t replicas_count_);\n     ~ParallelReplicasReadingCoordinator();\n-    PartitionReadResponse handleRequest(PartitionReadRequest request);\n+\n+    void setMode(CoordinationMode mode);\n+    void handleInitialAllRangesAnnouncement(InitialAllRangesAnnouncement);\n+    ParallelReadResponse handleRequest(ParallelReadRequest request);\n+\n private:\n-    class Impl;\n-    std::unique_ptr<Impl> pimpl;\n+    void initialize();\n+\n+    CoordinationMode mode{CoordinationMode::Default};\n+    size_t replicas_count{0};\n+    std::atomic<bool> initialized{false};\n+    std::unique_ptr<ImplInterface> pimpl;\n };\n \n using ParallelReplicasReadingCoordinatorPtr = std::shared_ptr<ParallelReplicasReadingCoordinator>;\ndiff --git a/src/Storages/MergeTree/RangesInDataPart.cpp b/src/Storages/MergeTree/RangesInDataPart.cpp\nnew file mode 100644\nindex 000000000000..29a236c98652\n--- /dev/null\n+++ b/src/Storages/MergeTree/RangesInDataPart.cpp\n@@ -0,0 +1,113 @@\n+#include <Storages/MergeTree/RangesInDataPart.h>\n+\n+#include <Storages/MergeTree/IMergeTreeDataPart.h>\n+\n+#include \"IO/VarInt.h\"\n+\n+#include <IO/ReadHelpers.h>\n+#include <IO/WriteHelpers.h>\n+\n+\n+namespace DB\n+{\n+\n+void RangesInDataPartDescription::serialize(WriteBuffer & out) const\n+{\n+    info.serialize(out);\n+    ranges.serialize(out);\n+}\n+\n+String RangesInDataPartDescription::describe() const\n+{\n+    String result;\n+    result += fmt::format(\"Part: {}, \", info.getPartNameV1());\n+    result += fmt::format(\"Ranges: [{}], \", fmt::join(ranges, \",\"));\n+    return result;\n+}\n+\n+void RangesInDataPartDescription::deserialize(ReadBuffer & in)\n+{\n+    info.deserialize(in);\n+    ranges.deserialize(in);\n+}\n+\n+void RangesInDataPartsDescription::serialize(WriteBuffer & out) const\n+{\n+    writeVarUInt(this->size(), out);\n+    for (const auto & desc : *this)\n+        desc.serialize(out);\n+}\n+\n+String RangesInDataPartsDescription::describe() const\n+{\n+    String result;\n+    for (const auto & desc : *this)\n+        result += desc.describe() + \",\";\n+    return result;\n+}\n+\n+void RangesInDataPartsDescription::deserialize(ReadBuffer & in)\n+{\n+    size_t new_size = 0;\n+    readVarUInt(new_size, in);\n+\n+    this->resize(new_size);\n+    for (auto & desc : *this)\n+        desc.deserialize(in);\n+}\n+\n+void RangesInDataPartsDescription::merge(RangesInDataPartsDescription & other)\n+{\n+    for (const auto & desc : other)\n+        this->emplace_back(desc);\n+}\n+\n+RangesInDataPartDescription RangesInDataPart::getDescription() const\n+{\n+    return RangesInDataPartDescription{\n+        .info = data_part->info,\n+        .ranges = ranges,\n+    };\n+}\n+\n+size_t RangesInDataPart::getMarksCount() const\n+{\n+    size_t total = 0;\n+    for (const auto & range : ranges)\n+        total += range.end - range.begin;\n+\n+    return total;\n+}\n+\n+size_t RangesInDataPart::getRowsCount() const\n+{\n+    return data_part->index_granularity.getRowsCountInRanges(ranges);\n+}\n+\n+\n+RangesInDataPartsDescription RangesInDataParts::getDescriptions() const\n+{\n+    RangesInDataPartsDescription result;\n+    for (const auto & part : *this)\n+        result.emplace_back(part.getDescription());\n+    return result;\n+}\n+\n+\n+size_t RangesInDataParts::getMarksCountAllParts() const\n+{\n+    size_t result = 0;\n+    for (const auto & part : *this)\n+        result += part.getMarksCount();\n+    return result;\n+}\n+\n+size_t RangesInDataParts::getRowsCountAllParts() const\n+{\n+    size_t result = 0;\n+    for (const auto & part: *this)\n+        result += part.getRowsCount();\n+    return result;\n+}\n+\n+}\ndiff --git a/src/Storages/MergeTree/RangesInDataPart.h b/src/Storages/MergeTree/RangesInDataPart.h\nindex 4f5d34e118d9..9c8ab4859a0b 100644\n--- a/src/Storages/MergeTree/RangesInDataPart.h\n+++ b/src/Storages/MergeTree/RangesInDataPart.h\n@@ -1,42 +1,73 @@\n #pragma once\n \n-#include <Storages/MergeTree/MergeTreeData.h>\n+#include <vector>\n+\n+#include <IO/WriteBuffer.h>\n+#include <IO/ReadBuffer.h>\n #include <Storages/MergeTree/MarkRange.h>\n+#include \"Storages/MergeTree/MergeTreePartInfo.h\"\n \n \n namespace DB\n {\n \n+class IMergeTreeDataPart;\n+using DataPartPtr = std::shared_ptr<const IMergeTreeDataPart>;\n+\n+/// The only purpose of this struct is that serialize and deserialize methods\n+/// they look natural here because we can fully serialize and then deserialize original DataPart class.\n+struct RangesInDataPartDescription\n+{\n+    MergeTreePartInfo info;\n+    MarkRanges ranges;\n+\n+    void serialize(WriteBuffer & out) const;\n+    String describe() const;\n+    void deserialize(ReadBuffer & in);\n+};\n+\n+struct RangesInDataPartsDescription: public std::deque<RangesInDataPartDescription>\n+{\n+    using std::deque<RangesInDataPartDescription>::deque;\n+\n+    void serialize(WriteBuffer & out) const;\n+    String describe() const;\n+    void deserialize(ReadBuffer & in);\n+\n+    void merge(RangesInDataPartsDescription & other);\n+};\n \n struct RangesInDataPart\n {\n-    MergeTreeData::DataPartPtr data_part;\n+    DataPartPtr data_part;\n     size_t part_index_in_query;\n     MarkRanges ranges;\n \n     RangesInDataPart() = default;\n \n-    RangesInDataPart(const MergeTreeData::DataPartPtr & data_part_, const size_t part_index_in_query_,\n-                     const MarkRanges & ranges_ = MarkRanges{})\n-        : data_part{data_part_}, part_index_in_query{part_index_in_query_}, ranges{ranges_}\n-    {\n-    }\n-\n-    size_t getMarksCount() const\n-    {\n-        size_t total = 0;\n-        for (const auto & range : ranges)\n-            total += range.end - range.begin;\n-\n-        return total;\n-    }\n-\n-    size_t getRowsCount() const\n-    {\n-        return data_part->index_granularity.getRowsCountInRanges(ranges);\n-    }\n+    RangesInDataPart(\n+        const DataPartPtr & data_part_,\n+        const size_t part_index_in_query_,\n+        const MarkRanges & ranges_ = MarkRanges{})\n+        : data_part{data_part_}\n+        , part_index_in_query{part_index_in_query_}\n+        , ranges{ranges_}\n+    {}\n+\n+    RangesInDataPartDescription getDescription() const;\n+\n+    size_t getMarksCount() const;\n+    size_t getRowsCount() const;\n };\n \n-using RangesInDataParts = std::vector<RangesInDataPart>;\n+struct RangesInDataParts: public std::vector<RangesInDataPart>\n+{\n+    using std::vector<RangesInDataPart>::vector;\n+\n+    RangesInDataPartsDescription getDescriptions() const;\n+\n+    size_t getMarksCountAllParts() const;\n+    size_t getRowsCountAllParts() const;\n+};\n \n }\ndiff --git a/src/Storages/MergeTree/RequestResponse.cpp b/src/Storages/MergeTree/RequestResponse.cpp\nindex 2ea6b0c9f9fe..5249128590ff 100644\n--- a/src/Storages/MergeTree/RequestResponse.cpp\n+++ b/src/Storages/MergeTree/RequestResponse.cpp\n@@ -1,159 +1,129 @@\n+#include <chrono>\n #include <Storages/MergeTree/RequestResponse.h>\n \n #include <Core/ProtocolDefines.h>\n #include <Common/SipHash.h>\n+#include \"IO/VarInt.h\"\n #include <IO/WriteHelpers.h>\n #include <IO/ReadHelpers.h>\n-#include <IO/Operators.h>\n \n #include <consistent_hashing.h>\n \n-\n namespace DB\n {\n \n namespace ErrorCodes\n {\n     extern const int UNKNOWN_PROTOCOL;\n-    extern const int BAD_ARGUMENTS;\n }\n \n-static void readMarkRangesBinary(MarkRanges & ranges, ReadBuffer & buf)\n+void ParallelReadRequest::serialize(WriteBuffer & out) const\n {\n-    size_t size = 0;\n-    readVarUInt(size, buf);\n-\n-    if (size > DEFAULT_MAX_STRING_SIZE)\n-        throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Too large ranges size: {}.\", size);\n-\n-    ranges.resize(size);\n-    for (size_t i = 0; i < size; ++i)\n-    {\n-        readBinary(ranges[i].begin, buf);\n-        readBinary(ranges[i].end, buf);\n-    }\n+    UInt64 version = DBMS_PARALLEL_REPLICAS_PROTOCOL_VERSION;\n+    /// Must be the first\n+    writeIntBinary(version, out);\n+\n+    writeIntBinary(mode, out);\n+    writeIntBinary(replica_num, out);\n+    writeIntBinary(min_number_of_marks, out);\n+    description.serialize(out);\n }\n \n \n-static void writeMarkRangesBinary(const MarkRanges & ranges, WriteBuffer & buf)\n+String ParallelReadRequest::describe() const\n {\n-    writeVarUInt(ranges.size(), buf);\n+    String result;\n+    result += fmt::format(\"replica_num: {} \\n\", replica_num);\n+    result += fmt::format(\"min_num_of_marks: {} \\n\", min_number_of_marks);\n+    result += description.describe();\n+    return result;\n+}\n+\n+void ParallelReadRequest::deserialize(ReadBuffer & in)\n+{\n+    UInt64 version;\n+    readIntBinary(version, in);\n+    if (version != DBMS_PARALLEL_REPLICAS_PROTOCOL_VERSION)\n+        throw Exception(ErrorCodes::UNKNOWN_PROTOCOL, \"Protocol versions for parallel reading \"\\\n+            \"from replicas differ. Got: {}, supported version: {}\",\n+            version, DBMS_PARALLEL_REPLICAS_PROTOCOL_VERSION);\n \n-    for (const auto & [begin, end] : ranges)\n-    {\n-        writeBinary(begin, buf);\n-        writeBinary(end, buf);\n-    }\n+    readIntBinary(mode, in);\n+    readIntBinary(replica_num, in);\n+    readIntBinary(min_number_of_marks, in);\n+    description.deserialize(in);\n }\n \n+void ParallelReadRequest::merge(ParallelReadRequest & other)\n+{\n+    assert(mode == other.mode);\n+    assert(replica_num == other.replica_num);\n+    assert(min_number_of_marks == other.min_number_of_marks);\n+    description.merge(other.description);\n+}\n \n-void PartitionReadRequest::serialize(WriteBuffer & out) const\n+void ParallelReadResponse::serialize(WriteBuffer & out) const\n {\n+    UInt64 version = DBMS_PARALLEL_REPLICAS_PROTOCOL_VERSION;\n     /// Must be the first\n-    writeVarUInt(DBMS_PARALLEL_REPLICAS_PROTOCOL_VERSION, out);\n+    writeIntBinary(version, out);\n \n-    writeStringBinary(partition_id, out);\n-    writeStringBinary(part_name, out);\n-    writeStringBinary(projection_name, out);\n-\n-    writeVarInt(block_range.begin, out);\n-    writeVarInt(block_range.end, out);\n-\n-    writeMarkRangesBinary(mark_ranges, out);\n+    writeBoolText(finish, out);\n+    description.serialize(out);\n }\n \n-\n-String PartitionReadRequest::toString() const\n+String ParallelReadResponse::describe() const\n {\n-    WriteBufferFromOwnString out;\n-    out << \"partition: \" << partition_id << \", part: \" << part_name;\n-    if (!projection_name.empty())\n-        out << \", projection: \" << projection_name;\n-    out << \", block range: [\" << block_range.begin << \", \" << block_range.end << \"]\";\n-    out << \", mark ranges: \";\n-\n-    bool is_first = true;\n-    for (const auto & [begin, end] : mark_ranges)\n-    {\n-        if (!is_first)\n-            out << \", \";\n-        out << \"[\" << begin << \", \" << end << \")\";\n-        is_first = false;\n-    }\n-\n-    return out.str();\n+    String result;\n+    result += fmt::format(\"finish: {} \\n\", finish);\n+    result += description.describe();\n+    return result;\n }\n \n-\n-void PartitionReadRequest::deserialize(ReadBuffer & in)\n+void ParallelReadResponse::deserialize(ReadBuffer & in)\n {\n     UInt64 version;\n-    readVarUInt(version, in);\n+    readIntBinary(version, in);\n     if (version != DBMS_PARALLEL_REPLICAS_PROTOCOL_VERSION)\n-        throw Exception(ErrorCodes::UNKNOWN_PROTOCOL, \"Protocol versions for parallel reading \\\n-            from replicas differ. Got: {}, supported version: {}\",\n+        throw Exception(ErrorCodes::UNKNOWN_PROTOCOL, \"Protocol versions for parallel reading \" \\\n+            \"from replicas differ. Got: {}, supported version: {}\",\n             version, DBMS_PARALLEL_REPLICAS_PROTOCOL_VERSION);\n \n-    readStringBinary(partition_id, in);\n-    readStringBinary(part_name, in);\n-    readStringBinary(projection_name, in);\n-\n-    readVarInt(block_range.begin, in);\n-    readVarInt(block_range.end, in);\n-\n-    readMarkRangesBinary(mark_ranges, in);\n+    readBoolText(finish, in);\n+    description.deserialize(in);\n }\n \n-UInt64 PartitionReadRequest::getConsistentHash(size_t buckets) const\n-{\n-    SipHash hash;\n-\n-    hash.update(partition_id.size());\n-    hash.update(partition_id);\n-\n-    hash.update(part_name.size());\n-    hash.update(part_name);\n-\n-    hash.update(projection_name.size());\n-    hash.update(projection_name);\n \n-    hash.update(block_range.begin);\n-    hash.update(block_range.end);\n-\n-    hash.update(mark_ranges.size());\n-    for (const auto & range : mark_ranges)\n-    {\n-        hash.update(range.begin);\n-        hash.update(range.end);\n-    }\n+void InitialAllRangesAnnouncement::serialize(WriteBuffer & out) const\n+{\n+    UInt64 version = DBMS_PARALLEL_REPLICAS_PROTOCOL_VERSION;\n+    /// Must be the first\n+    writeIntBinary(version, out);\n \n-    return ConsistentHashing(hash.get64(), buckets);\n+    description.serialize(out);\n+    writeIntBinary(replica_num, out);\n }\n \n \n-void PartitionReadResponse::serialize(WriteBuffer & out) const\n+String InitialAllRangesAnnouncement::describe()\n {\n-    /// Must be the first\n-    writeVarUInt(DBMS_PARALLEL_REPLICAS_PROTOCOL_VERSION, out);\n-\n-    writeBinary(denied, out);\n-    writeMarkRangesBinary(mark_ranges, out);\n+    String result;\n+    result += description.describe();\n+    result += fmt::format(\"----------\\nReceived from {} replica\\n\", replica_num);\n+    return result;\n }\n \n-\n-void PartitionReadResponse::deserialize(ReadBuffer & in)\n+void InitialAllRangesAnnouncement::deserialize(ReadBuffer & in)\n {\n     UInt64 version;\n-    readVarUInt(version, in);\n+    readIntBinary(version, in);\n     if (version != DBMS_PARALLEL_REPLICAS_PROTOCOL_VERSION)\n-        throw Exception(ErrorCodes::UNKNOWN_PROTOCOL, \"Protocol versions for parallel reading \\\n-            from replicas differ. Got: {}, supported version: {}\",\n+        throw Exception(ErrorCodes::UNKNOWN_PROTOCOL, \"Protocol versions for parallel reading \" \\\n+            \"from replicas differ. Got: {}, supported version: {}\",\n             version, DBMS_PARALLEL_REPLICAS_PROTOCOL_VERSION);\n \n-    UInt64 value;\n-    readVarUInt(value, in);\n-    denied = static_cast<bool>(value);\n-    readMarkRangesBinary(mark_ranges, in);\n+    description.deserialize(in);\n+    readIntBinary(replica_num, in);\n }\n \n }\ndiff --git a/src/Storages/MergeTree/RequestResponse.h b/src/Storages/MergeTree/RequestResponse.h\nindex ce9dc55f479c..8cdb9e49be5f 100644\n--- a/src/Storages/MergeTree/RequestResponse.h\n+++ b/src/Storages/MergeTree/RequestResponse.h\n@@ -1,5 +1,6 @@\n #pragma once\n \n+#include <condition_variable>\n #include <functional>\n #include <optional>\n \n@@ -9,12 +10,21 @@\n #include <IO/ReadBuffer.h>\n \n #include <Storages/MergeTree/MarkRange.h>\n+#include <Storages/MergeTree/RangesInDataPart.h>\n \n \n namespace DB\n {\n \n-/// Represents a segment [left; right] of part's block numbers.\n+enum class CoordinationMode\n+{\n+    Default,\n+    /// For reading in order\n+    WithOrder,\n+    ReverseOrder\n+};\n+\n+/// Represents a segment [left; right]\n struct PartBlockRange\n {\n     Int64 begin;\n@@ -26,34 +36,44 @@ struct PartBlockRange\n     }\n };\n \n-struct PartitionReadRequest\n+struct ParallelReadRequest\n {\n-    String partition_id;\n-    String part_name;\n-    String projection_name;\n-    PartBlockRange block_range;\n-    MarkRanges mark_ranges;\n+    CoordinationMode mode;\n+    size_t replica_num;\n+    size_t min_number_of_marks;\n+\n+    /// Extension for ordered mode\n+    RangesInDataPartsDescription description;\n \n     void serialize(WriteBuffer & out) const;\n+    String describe() const;\n     void deserialize(ReadBuffer & in);\n+    void merge(ParallelReadRequest & other);\n+};\n \n-    UInt64 getConsistentHash(size_t buckets) const;\n+struct ParallelReadResponse\n+{\n+    bool finish{false};\n+    RangesInDataPartsDescription description;\n \n-    /// Describe it for debugging purposes.\n-    String toString() const;\n+    void serialize(WriteBuffer & out) const;\n+    String describe() const;\n+    void deserialize(ReadBuffer & in);\n };\n \n-struct PartitionReadResponse\n+\n+struct InitialAllRangesAnnouncement\n {\n-    bool denied{false};\n-    MarkRanges mark_ranges{};\n+    RangesInDataPartsDescription description;\n+    size_t replica_num;\n \n     void serialize(WriteBuffer & out) const;\n+    String describe();\n     void deserialize(ReadBuffer & in);\n };\n \n \n-using MergeTreeReadTaskCallback = std::function<std::optional<PartitionReadResponse>(PartitionReadRequest)>;\n-\n+using MergeTreeAllRangesCallback = std::function<void(InitialAllRangesAnnouncement)>;\n+using MergeTreeReadTaskCallback = std::function<std::optional<ParallelReadResponse>(ParallelReadRequest)>;\n \n }\ndiff --git a/src/Storages/SelectQueryInfo.h b/src/Storages/SelectQueryInfo.h\nindex 9e29d438a4bb..40ea84ec68bb 100644\n--- a/src/Storages/SelectQueryInfo.h\n+++ b/src/Storages/SelectQueryInfo.h\n@@ -1,15 +1,16 @@\n #pragma once\n \n-#include <Interpreters/PreparedSets.h>\n-#include <Interpreters/DatabaseAndTableWithAlias.h>\n-#include <Core/SortDescription.h>\n-#include <Core/Names.h>\n-#include <Storages/ProjectionsDescription.h>\n-#include <Interpreters/AggregateDescription.h>\n-#include <QueryPipeline/StreamLocalLimits.h>\n #include <Analyzer/IQueryTreeNode.h>\n #include <Analyzer/TableExpressionModifiers.h>\n+#include <Core/Names.h>\n+#include <Core/SortDescription.h>\n+#include <Interpreters/AggregateDescription.h>\n+#include <Interpreters/DatabaseAndTableWithAlias.h>\n+#include <Interpreters/PreparedSets.h>\n #include <Planner/PlannerContext.h>\n+#include <QueryPipeline/StreamLocalLimits.h>\n+#include <Storages/ProjectionsDescription.h>\n+#include <Storages/MergeTree/ParallelReplicasReadingCoordinator.h>\n \n #include <memory>\n \n@@ -207,6 +208,8 @@ struct SelectQueryInfo\n     /// Configured in StorageDistributed::getQueryProcessingStage()\n     ClusterPtr optimized_cluster;\n \n+    mutable ParallelReplicasReadingCoordinatorPtr coordinator;\n+\n     TreeRewriterResultPtr syntax_analyzer_result;\n \n     /// This is an additional filer applied to current table.\ndiff --git a/src/Storages/StorageDistributed.cpp b/src/Storages/StorageDistributed.cpp\nindex 740ad67cc951..8da9e74a9f4c 100644\n--- a/src/Storages/StorageDistributed.cpp\n+++ b/src/Storages/StorageDistributed.cpp\n@@ -140,52 +140,6 @@ namespace ActionLocks\n namespace\n {\n \n-/// select query has database, table and table function names as AST pointers\n-/// Creates a copy of query, changes database, table and table function names.\n-ASTPtr rewriteSelectQuery(\n-    ContextPtr context,\n-    const ASTPtr & query,\n-    const std::string & remote_database,\n-    const std::string & remote_table,\n-    ASTPtr table_function_ptr = nullptr)\n-{\n-    auto modified_query_ast = query->clone();\n-\n-    ASTSelectQuery & select_query = modified_query_ast->as<ASTSelectQuery &>();\n-\n-    // Get rid of the settings clause so we don't send them to remote. Thus newly non-important\n-    // settings won't break any remote parser. It's also more reasonable since the query settings\n-    // are written into the query context and will be sent by the query pipeline.\n-    select_query.setExpression(ASTSelectQuery::Expression::SETTINGS, {});\n-\n-    if (table_function_ptr)\n-        select_query.addTableFunction(table_function_ptr);\n-    else\n-        select_query.replaceDatabaseAndTable(remote_database, remote_table);\n-\n-    /// Restore long column names (cause our short names are ambiguous).\n-    /// TODO: aliased table functions & CREATE TABLE AS table function cases\n-    if (!table_function_ptr)\n-    {\n-        RestoreQualifiedNamesVisitor::Data data;\n-        data.distributed_table = DatabaseAndTableWithAlias(*getTableExpression(query->as<ASTSelectQuery &>(), 0));\n-        data.remote_table.database = remote_database;\n-        data.remote_table.table = remote_table;\n-        RestoreQualifiedNamesVisitor(data).visit(modified_query_ast);\n-    }\n-\n-    /// To make local JOIN works, default database should be added to table names.\n-    /// But only for JOIN section, since the following should work using default_database:\n-    /// - SELECT * FROM d WHERE value IN (SELECT l.value FROM l) ORDER BY value\n-    ///   (see 01487_distributed_in_not_default_db)\n-    AddDefaultDatabaseVisitor visitor(context, context->getCurrentDatabase(),\n-        /* only_replace_current_database_function_= */false,\n-        /* only_replace_in_join_= */true);\n-    visitor.visit(modified_query_ast);\n-\n-    return modified_query_ast;\n-}\n-\n /// Calculate maximum number in file names in directory and all subdirectories.\n /// To ensure global order of data blocks yet to be sent across server restarts.\n UInt64 getMaximumFileNumber(const std::string & dir_path)\n@@ -696,6 +650,7 @@ void StorageDistributed::read(\n     const size_t /*max_block_size*/,\n     const size_t /*num_streams*/)\n {\n+\n     const auto * select_query = query_info.query->as<ASTSelectQuery>();\n     if (select_query->final() && local_context->getSettingsRef().allow_experimental_parallel_reading_from_replicas)\n         throw Exception(ErrorCodes::ILLEGAL_FINAL, \"Final modifier is not allowed together with parallel reading from replicas feature\");\n@@ -719,10 +674,11 @@ void StorageDistributed::read(\n         query_ast = query_info.query;\n     }\n \n-    auto modified_query_ast = rewriteSelectQuery(\n-        local_context, query_ast,\n+    const auto & modified_query_ast = ClusterProxy::rewriteSelectQuery(\n+        local_context, query_info.query,\n         remote_database, remote_table, remote_table_function_ptr);\n \n+\n     /// Return directly (with correct header) if no shard to query.\n     if (query_info.getCluster()->getShardsInfo().empty())\n     {\n@@ -746,25 +702,13 @@ void StorageDistributed::read(\n             storage_snapshot,\n             processed_stage);\n \n-\n-    auto settings = local_context->getSettingsRef();\n-    bool parallel_replicas = settings.max_parallel_replicas > 1 && settings.allow_experimental_parallel_reading_from_replicas && !settings.use_hedged_requests;\n-\n-    if (parallel_replicas)\n-        ClusterProxy::executeQueryWithParallelReplicas(\n-            query_plan, main_table, remote_table_function_ptr,\n-            select_stream_factory, modified_query_ast,\n-            local_context, query_info,\n-            sharding_key_expr, sharding_key_column_name,\n-            query_info.cluster, processed_stage);\n-    else\n-        ClusterProxy::executeQuery(\n-            query_plan, header, processed_stage,\n-            main_table, remote_table_function_ptr,\n-            select_stream_factory, log, modified_query_ast,\n-            local_context, query_info,\n-            sharding_key_expr, sharding_key_column_name,\n-            query_info.cluster);\n+    ClusterProxy::executeQuery(\n+        query_plan, header, processed_stage,\n+        main_table, remote_table_function_ptr,\n+        select_stream_factory, log, modified_query_ast,\n+        local_context, query_info,\n+        sharding_key_expr, sharding_key_column_name,\n+        query_info.cluster);\n \n     /// This is a bug, it is possible only when there is no shards to query, and this is handled earlier.\n     if (!query_plan.isInitialized())\ndiff --git a/src/Storages/StorageMergeTree.cpp b/src/Storages/StorageMergeTree.cpp\nindex 4ef34ae91d53..b003a1113982 100644\n--- a/src/Storages/StorageMergeTree.cpp\n+++ b/src/Storages/StorageMergeTree.cpp\n@@ -1,4 +1,5 @@\n #include \"StorageMergeTree.h\"\n+#include \"Core/QueryProcessingStage.h\"\n #include \"Storages/MergeTree/IMergeTreeDataPart.h\"\n \n #include <optional>\n@@ -14,6 +15,8 @@\n #include <Interpreters/MutationsInterpreter.h>\n #include <Interpreters/Context.h>\n #include <Interpreters/TransactionLog.h>\n+#include <Interpreters/ClusterProxy/executeQuery.h>\n+#include <Interpreters/ClusterProxy/SelectStreamFactory.h>\n #include <IO/copyData.h>\n #include <Parsers/ASTCheckQuery.h>\n #include <Parsers/ASTFunction.h>\n@@ -209,15 +212,39 @@ void StorageMergeTree::read(\n     size_t max_block_size,\n     size_t num_streams)\n {\n-    /// If true, then we will ask initiator if we can read chosen ranges\n-    bool enable_parallel_reading = local_context->getClientInfo().collaborate_with_initiator;\n+    if (local_context->canUseParallelReplicasOnInitiator())\n+    {\n+        auto table_id = getStorageID();\n+\n+        const auto & modified_query_ast =  ClusterProxy::rewriteSelectQuery(\n+            local_context, query_info.query,\n+            table_id.database_name, table_id.table_name, /*remote_table_function_ptr*/nullptr);\n+\n+        auto cluster = local_context->getCluster(local_context->getSettingsRef().cluster_for_parallel_replicas);\n+\n+        Block header =\n+            InterpreterSelectQuery(modified_query_ast, local_context, SelectQueryOptions(processed_stage).analyze()).getSampleBlock();\n \n-    if (enable_parallel_reading)\n-        LOG_TRACE(log, \"Parallel reading from replicas enabled: {}\", enable_parallel_reading);\n+        ClusterProxy::SelectStreamFactory select_stream_factory =\n+            ClusterProxy::SelectStreamFactory(\n+                header,\n+                {},\n+                storage_snapshot,\n+                processed_stage);\n \n-    if (auto plan = reader.read(\n-        column_names, storage_snapshot, query_info, local_context, max_block_size, num_streams, processed_stage, nullptr, enable_parallel_reading))\n-        query_plan = std::move(*plan);\n+        ClusterProxy::executeQueryWithParallelReplicas(\n+            query_plan, getStorageID(), /*remove_table_function_ptr*/ nullptr,\n+            select_stream_factory, modified_query_ast,\n+            local_context, query_info, cluster);\n+    }\n+    else\n+    {\n+        if (auto plan = reader.read(\n+            column_names, storage_snapshot, query_info,\n+            local_context, max_block_size, num_streams,\n+            processed_stage, nullptr, /*enable_parallel_reading*/local_context->canUseParallelReplicasOnFollower()))\n+            query_plan = std::move(*plan);\n+    }\n \n     /// Now, copy of parts that is required for the query, stored in the processors,\n     /// while snapshot_data.parts includes all parts, even one that had been filtered out with partition pruning,\ndiff --git a/src/Storages/StorageProxy.h b/src/Storages/StorageProxy.h\nindex 2afd9e8a63b0..b31707eeb626 100644\n--- a/src/Storages/StorageProxy.h\n+++ b/src/Storages/StorageProxy.h\n@@ -162,4 +162,3 @@ class StorageProxy : public IStorage\n \n \n }\n-\ndiff --git a/src/Storages/StorageReplicatedMergeTree.cpp b/src/Storages/StorageReplicatedMergeTree.cpp\nindex 7a4b97f6e49c..a58a561f9fac 100644\n--- a/src/Storages/StorageReplicatedMergeTree.cpp\n+++ b/src/Storages/StorageReplicatedMergeTree.cpp\n@@ -71,15 +71,18 @@\n #include <IO/ConnectionTimeouts.h>\n #include <IO/ConnectionTimeoutsContext.h>\n \n-#include <Interpreters/InterpreterAlterQuery.h>\n-#include <Interpreters/PartLog.h>\n+#include <Interpreters/ClusterProxy/executeQuery.h>\n+#include <Interpreters/ClusterProxy/SelectStreamFactory.h>\n #include <Interpreters/Context.h>\n #include <Interpreters/DDLTask.h>\n+#include <Interpreters/InterpreterAlterQuery.h>\n+#include <Interpreters/InterpreterSelectQuery.h>\n #include <Interpreters/InterserverCredentials.h>\n+#include <Interpreters/PartLog.h>\n #include <Interpreters/SelectQueryOptions.h>\n-#include <Interpreters/InterpreterSelectQuery.h>\n #include <Interpreters/JoinedTables.h>\n \n+\n #include <Backups/BackupEntriesCollector.h>\n #include <Backups/IBackup.h>\n #include <Backups/IBackupCoordination.h>\n@@ -4543,9 +4546,6 @@ void StorageReplicatedMergeTree::read(\n     const size_t max_block_size,\n     const size_t num_streams)\n {\n-    /// If true, then we will ask initiator if we can read chosen ranges\n-    const bool enable_parallel_reading = local_context->getClientInfo().collaborate_with_initiator;\n-\n     SCOPE_EXIT({\n         /// Now, copy of parts that is required for the query, stored in the processors,\n         /// while snapshot_data.parts includes all parts, even one that had been filtered out with partition pruning,\n@@ -4564,16 +4564,43 @@ void StorageReplicatedMergeTree::read(\n         auto max_added_blocks = std::make_shared<ReplicatedMergeTreeQuorumAddedParts::PartitionIdToMaxBlock>(getMaxAddedBlocks());\n         if (auto plan = reader.read(\n                 column_names, storage_snapshot, query_info, local_context,\n-                max_block_size, num_streams, processed_stage, std::move(max_added_blocks), enable_parallel_reading))\n+                max_block_size, num_streams, processed_stage, std::move(max_added_blocks), /*enable_parallel_reading*/false))\n             query_plan = std::move(*plan);\n         return;\n     }\n \n-    if (auto plan = reader.read(\n-        column_names, storage_snapshot, query_info, local_context,\n-        max_block_size, num_streams, processed_stage, nullptr, enable_parallel_reading))\n+    if (local_context->canUseParallelReplicasOnInitiator())\n+    {\n+        auto table_id = getStorageID();\n+\n+        const auto & modified_query_ast =  ClusterProxy::rewriteSelectQuery(\n+            local_context, query_info.query,\n+            table_id.database_name, table_id.table_name, /*remote_table_function_ptr*/nullptr);\n+\n+        auto cluster = local_context->getCluster(local_context->getSettingsRef().cluster_for_parallel_replicas);\n+\n+        Block header =\n+            InterpreterSelectQuery(modified_query_ast, local_context, SelectQueryOptions(processed_stage).analyze()).getSampleBlock();\n+\n+        ClusterProxy::SelectStreamFactory select_stream_factory =\n+            ClusterProxy::SelectStreamFactory(\n+                header,\n+                {},\n+                storage_snapshot,\n+                processed_stage);\n+\n+        ClusterProxy::executeQueryWithParallelReplicas(\n+            query_plan, getStorageID(), /*remove_table_function_ptr*/ nullptr,\n+            select_stream_factory, modified_query_ast,\n+            local_context, query_info, cluster);\n+    }\n+    else\n     {\n-        query_plan = std::move(*plan);\n+        if (auto plan = reader.read(\n+            column_names, storage_snapshot, query_info,\n+            local_context, max_block_size, num_streams,\n+            processed_stage, nullptr, /*enable_parallel_reading*/local_context->canUseParallelReplicasOnFollower()))\n+            query_plan = std::move(*plan);\n     }\n }\n \ndiff --git a/src/Storages/getStructureOfRemoteTable.cpp b/src/Storages/getStructureOfRemoteTable.cpp\nindex 0721cfaa9c46..b27372491668 100644\n--- a/src/Storages/getStructureOfRemoteTable.cpp\n+++ b/src/Storages/getStructureOfRemoteTable.cpp\n@@ -79,7 +79,7 @@ ColumnsDescription getStructureOfRemoteTableInShard(\n \n     ParserExpression expr_parser;\n \n-    while (Block current = executor.read())\n+    while (Block current = executor.readBlock())\n     {\n         ColumnPtr name = current.getByName(\"name\").column;\n         ColumnPtr type = current.getByName(\"type\").column;\n@@ -187,7 +187,7 @@ ColumnsDescriptionByShardNum getExtendedObjectsOfRemoteTables(\n         executor.setMainTable(remote_table_id);\n \n         ColumnsDescription res;\n-        while (auto block = executor.read())\n+        while (auto block = executor.readBlock())\n         {\n             const auto & name_col = *block.getByName(\"name\").column;\n             const auto & type_col = *block.getByName(\"type\").column;\n",
  "test_patch": "diff --git a/docker/test/stateful/run.sh b/docker/test/stateful/run.sh\nindex e69a85c0fca4..80a437999145 100755\n--- a/docker/test/stateful/run.sh\n+++ b/docker/test/stateful/run.sh\n@@ -126,13 +126,16 @@ function run_tests()\n     fi\n \n     set +e\n-    clickhouse-test -j 2 --testname --shard --zookeeper --check-zookeeper-session --no-stateless --hung-check --print-time \\\n-        --skip 00168_parallel_processing_on_replicas \"${ADDITIONAL_OPTIONS[@]}\" \\\n-        \"$SKIP_TESTS_OPTION\" 2>&1 | ts '%Y-%m-%d %H:%M:%S' | tee test_output/test_result.txt\n-\n-    clickhouse-test --timeout 1200 --testname --shard --zookeeper --check-zookeeper-session --no-stateless --hung-check --print-time \\\n-    00168_parallel_processing_on_replicas \"${ADDITIONAL_OPTIONS[@]}\" 2>&1 | ts '%Y-%m-%d %H:%M:%S' | tee -a test_output/test_result.txt\n \n+    if [[ -n \"$USE_PARALLEL_REPLICAS\" ]] && [[ \"$USE_PARALLEL_REPLICAS\" -eq 1 ]]; then\n+        clickhouse-test --client=\"clickhouse-client --use_hedged_requests=0  --allow_experimental_parallel_reading_from_replicas=1 \\\n+            --max_parallel_replicas=100 --cluster_for_parallel_replicas='parallel_replicas'\" \\\n+            -j 2 --testname --shard --zookeeper --check-zookeeper-session --no-stateless --no-parallel-replicas --hung-check --print-time \"${ADDITIONAL_OPTIONS[@]}\" \\\n+        \"$SKIP_TESTS_OPTION\" 2>&1 | ts '%Y-%m-%d %H:%M:%S' | tee test_output/test_result.txt\n+    else\n+        clickhouse-test -j 2 --testname --shard --zookeeper --check-zookeeper-session --no-stateless --hung-check --print-time \"${ADDITIONAL_OPTIONS[@]}\" \\\n+        \"$SKIP_TESTS_OPTION\" 2>&1 | ts '%Y-%m-%d %H:%M:%S' | tee test_output/test_result.txt\n+    fi\n     set -e\n }\n \ndiff --git a/docker/test/stateless/run.sh b/docker/test/stateless/run.sh\nindex fef3fc4d2288..8e7d0ef55b96 100755\n--- a/docker/test/stateless/run.sh\n+++ b/docker/test/stateless/run.sh\n@@ -134,9 +134,9 @@ function run_tests()\n \n     set +e\n     clickhouse-test --testname --shard --zookeeper --check-zookeeper-session --hung-check --print-time \\\n-            --test-runs \"$NUM_TRIES\" \"${ADDITIONAL_OPTIONS[@]}\" 2>&1 \\\n-        | ts '%Y-%m-%d %H:%M:%S' \\\n-        | tee -a test_output/test_result.txt\n+        --test-runs \"$NUM_TRIES\" \"${ADDITIONAL_OPTIONS[@]}\" 2>&1 \\\n+    | ts '%Y-%m-%d %H:%M:%S' \\\n+    | tee -a test_output/test_result.txt\n     set -e\n }\n \ndiff --git a/src/Storages/MergeTree/tests/gtest_coordinator.cpp b/src/Storages/MergeTree/tests/gtest_coordinator.cpp\ndeleted file mode 100644\nindex 7bcf3304c2b0..000000000000\n--- a/src/Storages/MergeTree/tests/gtest_coordinator.cpp\n+++ /dev/null\n@@ -1,240 +0,0 @@\n-#include <gtest/gtest.h>\n-\n-#include <utility>\n-#include <limits>\n-#include <set>\n-\n-#include <Storages/MergeTree/IntersectionsIndexes.h>\n-\n-#include <Storages/MergeTree/ParallelReplicasReadingCoordinator.h>\n-\n-using namespace DB;\n-\n-\n-TEST(HalfIntervals, Simple)\n-{\n-    ASSERT_TRUE((\n-        HalfIntervals{{{1, 2}, {3, 4}}}.negate() ==\n-        HalfIntervals{{{0, 1}, {2, 3}, {4, 18446744073709551615UL}}}\n-    ));\n-\n-    {\n-        auto left = HalfIntervals{{{0, 2}, {4, 6}}}.negate();\n-        ASSERT_TRUE((\n-            left ==\n-            HalfIntervals{{{2, 4}, {6, 18446744073709551615UL}}}\n-        ));\n-    }\n-\n-    {\n-        auto left = HalfIntervals{{{0, 2}, {4, 6}}};\n-        auto right = HalfIntervals{{{1, 5}}}.negate();\n-        auto intersection = left.intersect(right);\n-\n-        ASSERT_TRUE((\n-            intersection ==\n-            HalfIntervals{{{0, 1}, {5, 6}}}\n-        ));\n-    }\n-\n-    {\n-        auto left = HalfIntervals{{{1, 2}, {2, 3}}};\n-        auto right = HalfIntervals::initializeWithEntireSpace();\n-        auto intersection = right.intersect(left.negate());\n-\n-        ASSERT_TRUE((\n-            intersection ==\n-            HalfIntervals{{{0, 1}, {3, 18446744073709551615UL}}}\n-        ));\n-    }\n-\n-    {\n-        auto left = HalfIntervals{{{1, 2}, {2, 3}, {3, 4}, {4, 5}}};\n-\n-        ASSERT_EQ(getIntersection(left, HalfIntervals{{{1, 4}}}).convertToMarkRangesFinal().size(), 3);\n-        ASSERT_EQ(getIntersection(left, HalfIntervals{{{1, 5}}}).convertToMarkRangesFinal().size(), 4);\n-    }\n-\n-    {\n-        auto left = HalfIntervals{{{1, 3}, {3, 5}, {5, 7}}};\n-\n-        ASSERT_EQ(getIntersection(left, HalfIntervals{{{3, 5}}}).convertToMarkRangesFinal().size(), 1);\n-        ASSERT_EQ(getIntersection(left, HalfIntervals{{{3, 7}}}).convertToMarkRangesFinal().size(), 2);\n-        ASSERT_EQ(getIntersection(left, HalfIntervals{{{4, 6}}}).convertToMarkRangesFinal().size(), 2);\n-        ASSERT_EQ(getIntersection(left, HalfIntervals{{{1, 7}}}).convertToMarkRangesFinal().size(), 3);\n-    }\n-\n-    {\n-        auto left = HalfIntervals{{{1, 3}}};\n-\n-        ASSERT_EQ(getIntersection(left, HalfIntervals{{{3, 4}}}).convertToMarkRangesFinal().size(), 0);\n-    }\n-\n-    {\n-        auto left = HalfIntervals{{{1, 2}, {3, 4}, {5, 6}}};\n-\n-        ASSERT_EQ(getIntersection(left, HalfIntervals{{{2, 3}}}).convertToMarkRangesFinal().size(), 0);\n-        ASSERT_EQ(getIntersection(left, HalfIntervals{{{4, 5}}}).convertToMarkRangesFinal().size(), 0);\n-        ASSERT_EQ(getIntersection(left, HalfIntervals{{{1, 6}}}).convertToMarkRangesFinal().size(), 3);\n-    }\n-}\n-\n-TEST(HalfIntervals, TwoRequests)\n-{\n-    auto left = HalfIntervals{{{1, 2}, {2, 3}}};\n-    auto right = HalfIntervals{{{2, 3}, {3, 4}}};\n-    auto intersection = left.intersect(right);\n-\n-    ASSERT_TRUE((\n-        intersection ==\n-        HalfIntervals{{{2, 3}}}\n-    ));\n-\n-    /// With negation\n-    left = HalfIntervals{{{1, 2}, {2, 3}}}.negate();\n-    right = HalfIntervals{{{2, 3}, {3, 4}}};\n-    intersection = left.intersect(right);\n-\n-\n-    ASSERT_TRUE((\n-        intersection ==\n-        HalfIntervals{{{3, 4}}}\n-    ));\n-}\n-\n-TEST(HalfIntervals, SelfIntersection)\n-{\n-    auto left = HalfIntervals{{{1, 2}, {2, 3}, {4, 5}}};\n-    auto right = left;\n-    auto intersection = left.intersect(right);\n-\n-    ASSERT_TRUE((\n-        intersection == right\n-    ));\n-\n-    left = HalfIntervals{{{1, 2}, {2, 3}, {4, 5}}};\n-    right = left;\n-    right.negate();\n-    intersection = left.intersect(right);\n-\n-    ASSERT_TRUE((\n-        intersection == HalfIntervals{}\n-    ));\n-}\n-\n-\n-TEST(Coordinator, Simple)\n-{\n-    PartitionReadRequest request;\n-    request.partition_id = \"a\";\n-    request.part_name = \"b\";\n-    request.projection_name = \"c\";\n-    request.block_range = PartBlockRange{1, 2};\n-    request.mark_ranges = MarkRanges{{1, 2}, {3, 4}};\n-\n-    ParallelReplicasReadingCoordinator coordinator;\n-    auto response = coordinator.handleRequest(request);\n-\n-    ASSERT_FALSE(response.denied) << \"Process request at first has to be accepted\";\n-\n-    ASSERT_EQ(response.mark_ranges.size(), request.mark_ranges.size());\n-\n-    for (int i = 0; i < response.mark_ranges.size(); ++i)\n-        EXPECT_EQ(response.mark_ranges[i], request.mark_ranges[i]);\n-\n-    response = coordinator.handleRequest(request);\n-    ASSERT_TRUE(response.denied) << \"Process the same request second time\";\n-}\n-\n-\n-TEST(Coordinator, TwoRequests)\n-{\n-    PartitionReadRequest first;\n-    first.partition_id = \"a\";\n-    first.part_name = \"b\";\n-    first.projection_name = \"c\";\n-    first.block_range = PartBlockRange{0, 0};\n-    first.mark_ranges = MarkRanges{{1, 2}, {2, 3}};\n-\n-    auto second = first;\n-    second.mark_ranges = MarkRanges{{2, 3}, {3, 4}};\n-\n-    ParallelReplicasReadingCoordinator coordinator;\n-    auto response = coordinator.handleRequest(first);\n-\n-    ASSERT_FALSE(response.denied) << \"First request must me accepted\";\n-\n-    ASSERT_EQ(response.mark_ranges.size(), first.mark_ranges.size());\n-    for (int i = 0; i < response.mark_ranges.size(); ++i)\n-        EXPECT_EQ(response.mark_ranges[i], first.mark_ranges[i]);\n-\n-    response = coordinator.handleRequest(second);\n-    ASSERT_FALSE(response.denied);\n-    ASSERT_EQ(response.mark_ranges.size(), 1);\n-    ASSERT_EQ(response.mark_ranges.front(), (MarkRange{3, 4}));\n-}\n-\n-\n-TEST(Coordinator, PartIntersections)\n-{\n-    {\n-        PartSegments boundaries;\n-\n-        boundaries.addPart(PartToRead{{1, 1}, {\"TestPart\", \"TestProjection\"}});\n-        boundaries.addPart(PartToRead{{2, 2}, {\"TestPart\", \"TestProjection\"}});\n-        boundaries.addPart(PartToRead{{3, 3}, {\"TestPart\", \"TestProjection\"}});\n-        boundaries.addPart(PartToRead{{4, 4}, {\"TestPart\", \"TestProjection\"}});\n-\n-        ASSERT_EQ(boundaries.getIntersectionResult({{1, 4}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::REJECT);\n-        ASSERT_EQ(boundaries.getIntersectionResult({{0, 5}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::REJECT);\n-        ASSERT_EQ(boundaries.getIntersectionResult({{1, 1}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::EXACTLY_ONE_INTERSECTION);\n-        ASSERT_EQ(boundaries.getIntersectionResult({{1, 1}, {\"ClickHouse\", \"AnotherProjection\"}}), PartSegments::IntersectionResult::REJECT);\n-        ASSERT_EQ(boundaries.getIntersectionResult({{1, 2}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::REJECT);\n-\n-        boundaries.addPart(PartToRead{{5, 5}, {\"TestPart\", \"TestProjection\"}});\n-        boundaries.addPart(PartToRead{{0, 0}, {\"TestPart\", \"TestProjection\"}});\n-\n-        ASSERT_EQ(boundaries.getIntersectionResult({{0, 5}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::REJECT);\n-        ASSERT_EQ(boundaries.getIntersectionResult({{1, 1}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::EXACTLY_ONE_INTERSECTION);\n-        ASSERT_EQ(boundaries.getIntersectionResult({{1, 1}, {\"ClickHouse\", \"AnotherProjection\"}}), PartSegments::IntersectionResult::REJECT);\n-        ASSERT_EQ(boundaries.getIntersectionResult({{1, 2}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::REJECT);\n-        ASSERT_EQ(boundaries.getIntersectionResult({{0, 3}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::REJECT);\n-    }\n-\n-    {\n-        PartSegments boundaries;\n-        boundaries.addPart(PartToRead{{1, 3}, {\"TestPart\", \"TestProjection\"}});\n-        boundaries.addPart(PartToRead{{4, 5}, {\"TestPart\", \"TestProjection\"}});\n-\n-        ASSERT_EQ(boundaries.getIntersectionResult({{2, 4}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::REJECT);\n-        ASSERT_EQ(boundaries.getIntersectionResult({{0, 6}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::REJECT);\n-    }\n-\n-    {\n-        PartSegments boundaries;\n-        boundaries.addPart(PartToRead{{1, 3}, {\"TestPart\", \"TestProjection\"}});\n-        boundaries.addPart(PartToRead{{4, 6}, {\"TestPart\", \"TestProjection\"}});\n-        boundaries.addPart(PartToRead{{7, 9}, {\"TestPart\", \"TestProjection\"}});\n-\n-        ASSERT_EQ(boundaries.getIntersectionResult({{2, 8}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::REJECT);\n-        ASSERT_EQ(boundaries.getIntersectionResult({{4, 6}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::EXACTLY_ONE_INTERSECTION);\n-        ASSERT_EQ(boundaries.getIntersectionResult({{3, 7}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::REJECT);\n-        ASSERT_EQ(boundaries.getIntersectionResult({{5, 7}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::REJECT);\n-    }\n-\n-    {\n-        PartSegments boundaries;\n-\n-        ASSERT_EQ(boundaries.getIntersectionResult({{1, 1}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::NO_INTERSECTION);\n-        ASSERT_EQ(boundaries.getIntersectionResult({{1, 3}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::NO_INTERSECTION);\n-        ASSERT_EQ(boundaries.getIntersectionResult({{0, 100500}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::NO_INTERSECTION);\n-\n-        boundaries.addPart(PartToRead{{1, 1}, {\"TestPart\", \"TestProjection\"}});\n-        boundaries.addPart(PartToRead{{2, 2}, {\"TestPart\", \"TestProjection\"}});\n-        boundaries.addPart(PartToRead{{3, 3}, {\"TestPart\", \"TestProjection\"}});\n-\n-        ASSERT_EQ(boundaries.getIntersectionResult({{1, 1}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::EXACTLY_ONE_INTERSECTION);\n-        ASSERT_EQ(boundaries.getIntersectionResult({{1, 3}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::REJECT);\n-        ASSERT_EQ(boundaries.getIntersectionResult({{100, 100500}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::NO_INTERSECTION);\n-    }\n-}\ndiff --git a/tests/ci/ci_config.py b/tests/ci/ci_config.py\nindex c77acfb679f4..b671b8683d7f 100644\n--- a/tests/ci/ci_config.py\n+++ b/tests/ci/ci_config.py\n@@ -209,6 +209,26 @@\n         \"Stateful tests (release, DatabaseReplicated)\": {\n             \"required_build\": \"package_release\",\n         },\n+        # Stateful tests for parallel replicas\n+        \"Stateful tests (release, ParallelReplicas)\": {\n+            \"required_build\": \"package_release\",\n+        },\n+        \"Stateful tests (debug, ParallelReplicas)\": {\n+            \"required_build\": \"package_debug\",\n+        },\n+        \"Stateful tests (asan, ParallelReplicas)\": {\n+            \"required_build\": \"package_asan\",\n+        },\n+        \"Stateful tests (msan, ParallelReplicas)\": {\n+            \"required_build\": \"package_msan\",\n+        },\n+        \"Stateful tests (ubsan, ParallelReplicas)\": {\n+            \"required_build\": \"package_ubsan\",\n+        },\n+        \"Stateful tests (tsan, ParallelReplicas)\": {\n+            \"required_build\": \"package_tsan\",\n+        },\n+        # End stateful tests for parallel replicas\n         \"Stateless tests (asan)\": {\n             \"required_build\": \"package_asan\",\n         },\ndiff --git a/tests/ci/functional_test_check.py b/tests/ci/functional_test_check.py\nindex cf5f53afbf98..c33454d1d904 100644\n--- a/tests/ci/functional_test_check.py\n+++ b/tests/ci/functional_test_check.py\n@@ -48,7 +48,8 @@ def get_additional_envs(check_name, run_by_hash_num, run_by_hash_total):\n         result.append(\"USE_DATABASE_ORDINARY=1\")\n     if \"wide parts enabled\" in check_name:\n         result.append(\"USE_POLYMORPHIC_PARTS=1\")\n-\n+    if \"ParallelReplicas\" in check_name:\n+        result.append(\"USE_PARALLEL_REPLICAS=1\")\n     if \"s3 storage\" in check_name:\n         result.append(\"USE_S3_STORAGE_FOR_MERGE_TREE=1\")\n \n@@ -355,16 +356,34 @@ def main():\n \n     print(f\"::notice:: {check_name} Report url: {report_url}\")\n     if args.post_commit_status == \"commit_status\":\n-        post_commit_status(\n-            gh, pr_info.sha, check_name_with_group, description, state, report_url\n-        )\n+        if \"parallelreplicas\" in check_name.lower():\n+            post_commit_status(\n+                gh,\n+                pr_info.sha,\n+                check_name_with_group,\n+                description,\n+                \"success\",\n+                report_url,\n+            )\n+        else:\n+            post_commit_status(\n+                gh, pr_info.sha, check_name_with_group, description, state, report_url\n+            )\n     elif args.post_commit_status == \"file\":\n-        post_commit_status_to_file(\n-            post_commit_path,\n-            description,\n-            state,\n-            report_url,\n-        )\n+        if \"parallelreplicas\" in check_name.lower():\n+            post_commit_status_to_file(\n+                post_commit_path,\n+                description,\n+                \"success\",\n+                report_url,\n+            )\n+        else:\n+            post_commit_status_to_file(\n+                post_commit_path,\n+                description,\n+                state,\n+                report_url,\n+            )\n     else:\n         raise Exception(\n             f'Unknown post_commit_status option \"{args.post_commit_status}\"'\n@@ -382,7 +401,11 @@ def main():\n     ch_helper.insert_events_into(db=\"default\", table=\"checks\", events=prepared_events)\n \n     if state != \"success\":\n-        if FORCE_TESTS_LABEL in pr_info.labels:\n+        # Parallel replicas are always green for now\n+        if (\n+            FORCE_TESTS_LABEL in pr_info.labels\n+            or \"parallelreplicas\" in check_name.lower()\n+        ):\n             print(f\"'{FORCE_TESTS_LABEL}' enabled, will report success\")\n         else:\n             sys.exit(1)\ndiff --git a/tests/clickhouse-test b/tests/clickhouse-test\nindex 50d940bc23ce..366197cfd037 100755\n--- a/tests/clickhouse-test\n+++ b/tests/clickhouse-test\n@@ -442,6 +442,7 @@ class FailureReason(enum.Enum):\n     STRESS = \"stress\"\n     BUILD = \"not running for current build\"\n     BACKWARD_INCOMPATIBLE = \"test is backward incompatible\"\n+    NO_PARALLEL_REPLICAS = \"smth in not supported with parallel replicas\"\n \n     # UNKNOWN reasons\n     NO_REFERENCE = \"no reference file\"\n@@ -729,6 +730,9 @@ class TestCase:\n         ):\n             return FailureReason.DISABLED\n \n+        elif \"no-parallel-replicas\" in tags and args.no_parallel_replicas:\n+            return FailureReason.NO_PARALLEL_REPLICAS\n+\n         elif args.skip and any(s in self.name for s in args.skip):\n             return FailureReason.SKIP\n \n@@ -2399,6 +2403,13 @@ if __name__ == \"__main__\":\n         default=False,\n         help=\"Report statistics about log messages\",\n     )\n+    parser.add_argument(\n+        \"--no-parallel-replicas\",\n+        action=\"store_true\",\n+        default=False,\n+        help=\"Do not include tests that are not supported with parallel replicas feature\",\n+    )\n+\n     args = parser.parse_args()\n \n     if args.queries and not os.path.isdir(args.queries):\ndiff --git a/tests/performance/memory_bound_merging.xml b/tests/performance/memory_bound_merging.xml\nindex 3b13400151c8..15dc1b29fba0 100644\n--- a/tests/performance/memory_bound_merging.xml\n+++ b/tests/performance/memory_bound_merging.xml\n@@ -11,7 +11,5 @@\n \n   <query>select avg(a) from remote('127.0.0.{{1,2}}', default, t_mbm) group by a format Null</query>\n \n-  <query>select * from remote('127.0.0.{{1,2}}', default, t_mbm) group by a format Null settings allow_experimental_parallel_reading_from_replicas = 1, max_parallel_replicas = 2, use_hedged_requests = 0</query>\n-\n   <drop_query>drop table t_mbm</drop_query>\n </test>\ndiff --git a/tests/queries/0_stateless/02404_memory_bound_merging.reference b/tests/queries/0_stateless/02404_memory_bound_merging.reference\nindex 47d3470ef6ed..98e53cd50abb 100644\n--- a/tests/queries/0_stateless/02404_memory_bound_merging.reference\n+++ b/tests/queries/0_stateless/02404_memory_bound_merging.reference\n@@ -98,8 +98,9 @@ select a, count() from dist_t_different_dbs group by a, b order by a limit 5 off\n 502\t2000\n 503\t2000\n 504\t2000\n+1000000\n -- { echoOn } --\n-explain pipeline select a from dist_pr_t group by a order by a limit 5 offset 500;\n+explain pipeline select a from pr_t group by a order by a limit 5 offset 500;\n (Expression)\n ExpressionTransform\n   (Limit)\n@@ -112,28 +113,29 @@ ExpressionTransform\n             (Expression)\n             ExpressionTransform \u00d7 4\n               (MergingAggregated)\n-              MergingAggregatedBucketTransform \u00d7 4\n-                Resize 1 \u2192 4\n-                  FinishAggregatingInOrderTransform 3 \u2192 1\n-                    (Union)\n-                      (Aggregating)\n-                      SortingAggregatedForMemoryBoundMergingTransform 4 \u2192 1\n-                        MergingAggregatedBucketTransform \u00d7 4\n-                          Resize 1 \u2192 4\n-                            FinishAggregatingInOrderTransform 4 \u2192 1\n-                              AggregatingInOrderTransform \u00d7 4\n-                                (Expression)\n-                                ExpressionTransform \u00d7 4\n-                                  (ReadFromMergeTree)\n-                                  MergeTreeInOrder \u00d7 4 0 \u2192 1\n-                      (ReadFromRemoteParallelReplicas)\n-select a, count() from dist_pr_t group by a order by a limit 5 offset 500;\n+              Resize 1 \u2192 4\n+                SortingAggregatedTransform 4 \u2192 1\n+                  MergingAggregatedBucketTransform \u00d7 4\n+                    Resize 1 \u2192 4\n+                      GroupingAggregatedTransform 6 \u2192 1\n+                        (Union)\n+                          (Aggregating)\n+                          MergingAggregatedBucketTransform \u00d7 4\n+                            Resize 1 \u2192 4\n+                              FinishAggregatingInOrderTransform 4 \u2192 1\n+                                AggregatingInOrderTransform \u00d7 4\n+                                  (Expression)\n+                                  ExpressionTransform \u00d7 4\n+                                    (ReadFromMergeTree)\n+                                    MergeTreeInOrder \u00d7 4 0 \u2192 1\n+                          (ReadFromRemoteParallelReplicas)\n+select a, count() from pr_t group by a order by a limit 5 offset 500;\n 500\t1000\n 501\t1000\n 502\t1000\n 503\t1000\n 504\t1000\n-select a, count() from dist_pr_t group by a, b order by a limit 5 offset 500;\n+select a, count() from pr_t group by a, b order by a limit 5 offset 500;\n 500\t1000\n 501\t1000\n 502\t1000\ndiff --git a/tests/queries/0_stateless/02404_memory_bound_merging.sql b/tests/queries/0_stateless/02404_memory_bound_merging.sql\nindex f4a1e75e3983..a38e4c5ec6b4 100644\n--- a/tests/queries/0_stateless/02404_memory_bound_merging.sql\n+++ b/tests/queries/0_stateless/02404_memory_bound_merging.sql\n@@ -1,13 +1,13 @@\n -- Tags: no-parallel\n \n drop table if exists pr_t;\n-drop table if exists dist_pr_t;\n drop table if exists dist_t_different_dbs;\n drop table if exists shard_1.t_different_dbs;\n drop table if exists t_different_dbs;\n drop table if exists dist_t;\n drop table if exists t;\n \n+\n create table t(a UInt64, b UInt64) engine=MergeTree order by a;\n system stop merges t;\n insert into t select number, number from numbers_mt(1e6);\n@@ -15,6 +15,7 @@ insert into t select number, number from numbers_mt(1e6);\n set enable_memory_bound_merging_of_aggregation_results = 1;\n set max_threads = 4;\n set optimize_aggregation_in_order = 1;\n+set optimize_read_in_order = 1;\n set prefer_localhost_replica = 1;\n \n -- slightly different transforms will be generated by reading steps if we let settings randomisation to change this setting value --\n@@ -56,26 +57,28 @@ select a, count() from dist_t_different_dbs group by a, b order by a limit 5 off\n \n -- { echoOff } --\n \n+create table pr_t(a UInt64, b UInt64) engine=MergeTree order by a;\n+insert into pr_t select number % 1000, number % 1000 from numbers_mt(1e6);\n+\n set allow_experimental_parallel_reading_from_replicas = 1;\n set max_parallel_replicas = 3;\n set use_hedged_requests = 0;\n+set cluster_for_parallel_replicas = 'test_cluster_one_shard_three_replicas_localhost';\n+set distributed_aggregation_memory_efficient=1;\n \n-create table pr_t(a UInt64, b UInt64) engine=MergeTree order by a;\n-insert into pr_t select number % 1000, number % 1000 from numbers_mt(1e6);\n-create table dist_pr_t as pr_t engine = Distributed(test_cluster_one_shard_three_replicas_localhost, currentDatabase(), pr_t);\n+select count() from pr_t;\n \n -- { echoOn } --\n-explain pipeline select a from dist_pr_t group by a order by a limit 5 offset 500;\n+explain pipeline select a from pr_t group by a order by a limit 5 offset 500;\n \n-select a, count() from dist_pr_t group by a order by a limit 5 offset 500;\n-select a, count() from dist_pr_t group by a, b order by a limit 5 offset 500;\n+select a, count() from pr_t group by a order by a limit 5 offset 500;\n+select a, count() from pr_t group by a, b order by a limit 5 offset 500;\n \n -- { echoOff } --\n \n-drop table pr_t;\n-drop table dist_pr_t;\n-drop table dist_t_different_dbs;\n-drop table shard_1.t_different_dbs;\n-drop table t_different_dbs;\n-drop table dist_t;\n-drop table t;\n+drop table if exists pr_t;\n+drop table if exists dist_t_different_dbs;\n+drop table if exists shard_1.t_different_dbs;\n+drop table if exists t_different_dbs;\n+drop table if exists dist_t;\n+drop table if exists t;\ndiff --git a/tests/queries/1_stateful/00009_uniq_distributed.sql b/tests/queries/1_stateful/00009_uniq_distributed.sql\nindex f78604fd401c..352514cd059c 100644\n--- a/tests/queries/1_stateful/00009_uniq_distributed.sql\n+++ b/tests/queries/1_stateful/00009_uniq_distributed.sql\n@@ -1,3 +1,4 @@\n -- Tags: distributed\n \n+\n SELECT uniq(UserID), uniqIf(UserID, CounterID = 800784), uniqIf(FUniqID, RegionID = 213) FROM remote('127.0.0.{1,2}', test, hits)\ndiff --git a/tests/queries/1_stateful/00012_sorting_distributed.sql b/tests/queries/1_stateful/00012_sorting_distributed.sql\nindex 2f852af1dba3..afbaf89d9ae8 100644\n--- a/tests/queries/1_stateful/00012_sorting_distributed.sql\n+++ b/tests/queries/1_stateful/00012_sorting_distributed.sql\n@@ -1,3 +1,4 @@\n -- Tags: distributed\n \n+\n SELECT EventTime::DateTime('Asia/Dubai') FROM remote('127.0.0.{1,2}', test, hits) ORDER BY EventTime DESC LIMIT 10\ndiff --git a/tests/queries/1_stateful/00013_sorting_of_nested.sql b/tests/queries/1_stateful/00013_sorting_of_nested.sql\nindex 44f7684d7469..f97120e2b981 100644\n--- a/tests/queries/1_stateful/00013_sorting_of_nested.sql\n+++ b/tests/queries/1_stateful/00013_sorting_of_nested.sql\n@@ -1,2 +1,4 @@\n+-- Tags: no-parallel-replicas\n+\n SELECT ParsedParams.Key1 FROM test.visits FINAL WHERE VisitID != 0 AND notEmpty(ParsedParams.Key1) ORDER BY VisitID LIMIT 10\n \ndiff --git a/tests/queries/1_stateful/00016_any_if_distributed_cond_always_false.sql b/tests/queries/1_stateful/00016_any_if_distributed_cond_always_false.sql\nindex 2afe28639f26..50a3402244e8 100644\n--- a/tests/queries/1_stateful/00016_any_if_distributed_cond_always_false.sql\n+++ b/tests/queries/1_stateful/00016_any_if_distributed_cond_always_false.sql\n@@ -1,3 +1,4 @@\n -- Tags: distributed\n \n+\n SELECT anyIf(SearchPhrase, CounterID = -1) FROM remote('127.0.0.{1,2}:9000', test, hits)\ndiff --git a/tests/queries/1_stateful/00022_merge_prewhere.sql b/tests/queries/1_stateful/00022_merge_prewhere.sql\nindex 74a3677b68eb..400a896d5a87 100644\n--- a/tests/queries/1_stateful/00022_merge_prewhere.sql\n+++ b/tests/queries/1_stateful/00022_merge_prewhere.sql\n@@ -1,3 +1,5 @@\n+-- Tags: no-parallel-replicas\n+\n DROP TABLE IF EXISTS test.merge_hits;\n CREATE TABLE IF NOT EXISTS test.merge_hits AS test.hits ENGINE = Merge(test, '^hits$');\n SELECT count() FROM test.merge_hits WHERE AdvEngineID = 2;\ndiff --git a/tests/queries/1_stateful/00042_any_left_join.sql b/tests/queries/1_stateful/00042_any_left_join.sql\nindex b87cf88f0071..c7c0f0f987a6 100644\n--- a/tests/queries/1_stateful/00042_any_left_join.sql\n+++ b/tests/queries/1_stateful/00042_any_left_join.sql\n@@ -1,3 +1,5 @@\n+-- Tags: no-parallel-replicas\n+\n SELECT\n     EventDate,\n     hits,\ndiff --git a/tests/queries/1_stateful/00043_any_left_join.sql b/tests/queries/1_stateful/00043_any_left_join.sql\nindex 704d38f727a8..6b8cce540515 100644\n--- a/tests/queries/1_stateful/00043_any_left_join.sql\n+++ b/tests/queries/1_stateful/00043_any_left_join.sql\n@@ -1,3 +1,5 @@\n+-- Tags: no-parallel-replicas\n+\n SELECT\n     EventDate,\n     count() AS hits,\ndiff --git a/tests/queries/1_stateful/00044_any_left_join_string.sql b/tests/queries/1_stateful/00044_any_left_join_string.sql\nindex a4f2e9e1b964..ceb7a1c1783f 100644\n--- a/tests/queries/1_stateful/00044_any_left_join_string.sql\n+++ b/tests/queries/1_stateful/00044_any_left_join_string.sql\n@@ -1,3 +1,5 @@\n+-- Tags: no-parallel-replicas\n+\n SELECT\n     domain,\n     hits,\ndiff --git a/tests/queries/1_stateful/00063_loyalty_joins.sql b/tests/queries/1_stateful/00063_loyalty_joins.sql\nindex 1e7011ea9099..44f0767a87a0 100644\n--- a/tests/queries/1_stateful/00063_loyalty_joins.sql\n+++ b/tests/queries/1_stateful/00063_loyalty_joins.sql\n@@ -1,15 +1,17 @@\n+-- Tags: no-parallel-replicas\n+\n SET any_join_distinct_right_table_keys = 1;\n SET joined_subquery_requires_alias = 0;\n \n SELECT\n-    loyalty, \n+    loyalty,\n     count()\n-FROM test.hits ANY LEFT JOIN \n+FROM test.hits ANY LEFT JOIN\n (\n     SELECT\n-        UserID, \n-        sum(SearchEngineID = 2) AS yandex, \n-        sum(SearchEngineID = 3) AS google, \n+        UserID,\n+        sum(SearchEngineID = 2) AS yandex,\n+        sum(SearchEngineID = 3) AS google,\n         toInt8(if(yandex > google, yandex / (yandex + google), -google / (yandex + google)) * 10) AS loyalty\n     FROM test.hits\n     WHERE (SearchEngineID = 2) OR (SearchEngineID = 3)\n@@ -21,18 +23,18 @@ ORDER BY loyalty ASC;\n \n \n SELECT\n-    loyalty, \n+    loyalty,\n     count()\n FROM\n (\n     SELECT UserID\n     FROM test.hits\n-) ANY LEFT JOIN \n+) ANY LEFT JOIN\n (\n     SELECT\n-        UserID, \n-        sum(SearchEngineID = 2) AS yandex, \n-        sum(SearchEngineID = 3) AS google, \n+        UserID,\n+        sum(SearchEngineID = 2) AS yandex,\n+        sum(SearchEngineID = 3) AS google,\n         toInt8(if(yandex > google, yandex / (yandex + google), -google / (yandex + google)) * 10) AS loyalty\n     FROM test.hits\n     WHERE (SearchEngineID = 2) OR (SearchEngineID = 3)\n@@ -44,23 +46,23 @@ ORDER BY loyalty ASC;\n \n \n SELECT\n-    loyalty, \n+    loyalty,\n     count()\n FROM\n (\n     SELECT\n-        loyalty, \n+        loyalty,\n         UserID\n     FROM\n     (\n         SELECT UserID\n         FROM test.hits\n-    ) ANY LEFT JOIN \n+    ) ANY LEFT JOIN\n     (\n         SELECT\n-            UserID, \n-            sum(SearchEngineID = 2) AS yandex, \n-            sum(SearchEngineID = 3) AS google, \n+            UserID,\n+            sum(SearchEngineID = 2) AS yandex,\n+            sum(SearchEngineID = 3) AS google,\n             toInt8(if(yandex > google, yandex / (yandex + google), -google / (yandex + google)) * 10) AS loyalty\n         FROM test.hits\n         WHERE (SearchEngineID = 2) OR (SearchEngineID = 3)\n@@ -73,19 +75,19 @@ ORDER BY loyalty ASC;\n \n \n SELECT\n-    loyalty, \n-    count() AS c, \n+    loyalty,\n+    count() AS c,\n     bar(log(c + 1) * 1000, 0, log(3000000) * 1000, 80)\n-FROM test.hits ANY INNER JOIN \n+FROM test.hits ANY INNER JOIN\n (\n     SELECT\n-        UserID, \n+        UserID,\n         toInt8(if(yandex > google, yandex / (yandex + google), -google / (yandex + google)) * 10) AS loyalty\n     FROM\n     (\n         SELECT\n-            UserID, \n-            sum(SearchEngineID = 2) AS yandex, \n+            UserID,\n+            sum(SearchEngineID = 2) AS yandex,\n             sum(SearchEngineID = 3) AS google\n         FROM test.hits\n         WHERE (SearchEngineID = 2) OR (SearchEngineID = 3)\ndiff --git a/tests/queries/1_stateful/00065_loyalty_with_storage_join.sql b/tests/queries/1_stateful/00065_loyalty_with_storage_join.sql\nindex 515a24105830..35f0c7b60b94 100644\n--- a/tests/queries/1_stateful/00065_loyalty_with_storage_join.sql\n+++ b/tests/queries/1_stateful/00065_loyalty_with_storage_join.sql\n@@ -1,3 +1,5 @@\n+-- Tags: no-parallel-replicas\n+\n USE test;\n \n DROP TABLE IF EXISTS join;\n@@ -7,7 +9,7 @@ INSERT INTO join\n SELECT\n     UserID,\n     toInt8(if((sum(SearchEngineID = 2) AS yandex) > (sum(SearchEngineID = 3) AS google),\n-    yandex / (yandex + google), \n+    yandex / (yandex + google),\n     -google / (yandex + google)) * 10) AS loyalty\n FROM hits\n WHERE (SearchEngineID = 2) OR (SearchEngineID = 3)\ndiff --git a/tests/queries/1_stateful/00066_sorting_distributed_many_replicas.sql b/tests/queries/1_stateful/00066_sorting_distributed_many_replicas.sql\nindex c7a34c493c9d..c60e342dd414 100644\n--- a/tests/queries/1_stateful/00066_sorting_distributed_many_replicas.sql\n+++ b/tests/queries/1_stateful/00066_sorting_distributed_many_replicas.sql\n@@ -1,4 +1,5 @@\n -- Tags: replica, distributed, no-random-settings\n \n+\n SET max_parallel_replicas = 2;\n SELECT EventTime::DateTime('Asia/Dubai') FROM remote('127.0.0.{1|2}', test, hits) ORDER BY EventTime DESC LIMIT 10\ndiff --git a/tests/queries/1_stateful/00074_full_join.sql b/tests/queries/1_stateful/00074_full_join.sql\nindex f049be2a74d4..c1d9e4be1a4f 100644\n--- a/tests/queries/1_stateful/00074_full_join.sql\n+++ b/tests/queries/1_stateful/00074_full_join.sql\n@@ -1,3 +1,5 @@\n+-- Tags: no-parallel-replicas\n+\n set any_join_distinct_right_table_keys = 1;\n set joined_subquery_requires_alias = 0;\n \ndiff --git a/tests/queries/1_stateful/00075_left_array_join.sql b/tests/queries/1_stateful/00075_left_array_join.sql\nindex 1fd045a26bf6..3540d7911573 100644\n--- a/tests/queries/1_stateful/00075_left_array_join.sql\n+++ b/tests/queries/1_stateful/00075_left_array_join.sql\n@@ -1,2 +1,4 @@\n+-- Tags: no-parallel-replicas\n+\n SELECT UserID, EventTime::DateTime('Asia/Dubai'), pp.Key1, pp.Key2, ParsedParams.Key1 FROM test.hits ARRAY JOIN ParsedParams AS pp WHERE CounterID = 1704509 ORDER BY UserID, EventTime, pp.Key1, pp.Key2 LIMIT 100;\n SELECT UserID, EventTime::DateTime('Asia/Dubai'), pp.Key1, pp.Key2, ParsedParams.Key1 FROM test.hits LEFT ARRAY JOIN ParsedParams AS pp WHERE CounterID = 1704509 ORDER BY UserID, EventTime, pp.Key1, pp.Key2 LIMIT 100;\ndiff --git a/tests/queries/1_stateful/00079_array_join_not_used_joined_column.sql b/tests/queries/1_stateful/00079_array_join_not_used_joined_column.sql\nindex 8e6742bb1e17..9431e1cf5963 100644\n--- a/tests/queries/1_stateful/00079_array_join_not_used_joined_column.sql\n+++ b/tests/queries/1_stateful/00079_array_join_not_used_joined_column.sql\n@@ -1,3 +1,5 @@\n+-- Tags: no-parallel-replicas\n+\n SELECT PP.Key1 AS `ym:s:paramsLevel1`, sum(arrayAll(`x_1` -> `x_1`= '', ParsedParams.Key2)) AS `ym:s:visits` FROM test.hits ARRAY JOIN ParsedParams AS `PP`  WHERE CounterID = 1704509 GROUP BY `ym:s:paramsLevel1` ORDER BY PP.Key1, `ym:s:visits` LIMIT 0, 100;\n SELECT PP.Key1 AS x1, ParsedParams.Key2 AS x2 FROM test.hits ARRAY JOIN ParsedParams AS PP WHERE CounterID = 1704509 ORDER BY x1, x2 LIMIT 10;\n SELECT ParsedParams.Key2 AS x FROM test.hits ARRAY JOIN ParsedParams AS PP ORDER BY x DESC LIMIT 10;\ndiff --git a/tests/queries/1_stateful/00080_array_join_and_union.sql b/tests/queries/1_stateful/00080_array_join_and_union.sql\nindex d9aa1cc17cc4..2f2e5e9324fa 100644\n--- a/tests/queries/1_stateful/00080_array_join_and_union.sql\n+++ b/tests/queries/1_stateful/00080_array_join_and_union.sql\n@@ -1,1 +1,3 @@\n+-- Tags: no-parallel-replicas\n+\n SELECT count() FROM (SELECT Goals.ID FROM test.visits ARRAY JOIN Goals WHERE CounterID = 842440 LIMIT 10 UNION ALL SELECT Goals.ID FROM test.visits ARRAY JOIN Goals WHERE CounterID = 842440 LIMIT 10);\ndiff --git a/tests/queries/1_stateful/00084_external_aggregation.sql b/tests/queries/1_stateful/00084_external_aggregation.sql\nindex 816d95f4b8b3..330aa158cf75 100644\n--- a/tests/queries/1_stateful/00084_external_aggregation.sql\n+++ b/tests/queries/1_stateful/00084_external_aggregation.sql\n@@ -1,4 +1,4 @@\n--- Tags: no-random-settings\n+-- Tags: no-random-settings, no-parallel-replicas\n \n SET max_bytes_before_external_group_by = 200000000;\n \ndiff --git a/tests/queries/1_stateful/00091_prewhere_two_conditions.sql b/tests/queries/1_stateful/00091_prewhere_two_conditions.sql\nindex 1e476d3a27dc..745bb125c2bd 100644\n--- a/tests/queries/1_stateful/00091_prewhere_two_conditions.sql\n+++ b/tests/queries/1_stateful/00091_prewhere_two_conditions.sql\n@@ -1,3 +1,6 @@\n+-- Tags: no-parallel-replicas\n+-- Requires investigation (max_bytes_to_read is not respected)\n+\n SET max_bytes_to_read = 600000000;\n \n SET optimize_move_to_prewhere = 1;\ndiff --git a/tests/queries/1_stateful/00092_obfuscator.sh b/tests/queries/1_stateful/00092_obfuscator.sh\nindex 85f476c6ae5c..f19473f01ac1 100755\n--- a/tests/queries/1_stateful/00092_obfuscator.sh\n+++ b/tests/queries/1_stateful/00092_obfuscator.sh\n@@ -1,4 +1,6 @@\n #!/usr/bin/env bash\n+# Tags: no-parallel-replicas\n+# clickhouse-local may not work with parallel replicas\n \n CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n # shellcheck source=../shell_config.sh\ndiff --git a/tests/queries/1_stateful/00096_obfuscator_save_load.sh b/tests/queries/1_stateful/00096_obfuscator_save_load.sh\nindex a88dfcdb9b9a..1bb212e1bbae 100755\n--- a/tests/queries/1_stateful/00096_obfuscator_save_load.sh\n+++ b/tests/queries/1_stateful/00096_obfuscator_save_load.sh\n@@ -1,4 +1,6 @@\n #!/usr/bin/env bash\n+# Tags: no-parallel-replicas\n+# clickhouse-local may not work with parallel replicas\n \n CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n # shellcheck source=../shell_config.sh\ndiff --git a/tests/queries/1_stateful/00146_aggregate_function_uniq.sql b/tests/queries/1_stateful/00146_aggregate_function_uniq.sql\nindex fd3fde7636d8..2cab6e70d22a 100644\n--- a/tests/queries/1_stateful/00146_aggregate_function_uniq.sql\n+++ b/tests/queries/1_stateful/00146_aggregate_function_uniq.sql\n@@ -1,3 +1,5 @@\n+-- Tags: no-parallel-replicas\n+\n SELECT RegionID, uniqHLL12(WatchID) AS X FROM remote('127.0.0.{1,2}', test, hits) GROUP BY RegionID HAVING X > 100000 ORDER BY RegionID ASC;\n SELECT RegionID, uniqCombined(WatchID) AS X FROM remote('127.0.0.{1,2}', test, hits) GROUP BY RegionID HAVING X > 100000 ORDER BY RegionID ASC;\n SELECT abs(uniq(WatchID) - uniqExact(WatchID)) FROM test.hits;\ndiff --git a/tests/queries/1_stateful/00149_quantiles_timing_distributed.sql b/tests/queries/1_stateful/00149_quantiles_timing_distributed.sql\nindex 6f910646fb7b..5d2476226bae 100644\n--- a/tests/queries/1_stateful/00149_quantiles_timing_distributed.sql\n+++ b/tests/queries/1_stateful/00149_quantiles_timing_distributed.sql\n@@ -1,4 +1,4 @@\n--- Tags: distributed\n+-- Tags: distributed, no-parallel-replicas\n \n SELECT sum(cityHash64(*)) FROM (SELECT CounterID, quantileTiming(0.5)(SendTiming), count() FROM remote('127.0.0.{1,2,3,4,5,6,7,8,9,10}', test.hits) WHERE SendTiming != -1 GROUP BY CounterID);\n SELECT sum(cityHash64(*)) FROM (SELECT CounterID, quantileTiming(0.5)(SendTiming), count() FROM remote('127.0.0.{1,2,3,4,5,6,7,8,9,10}', test.hits) WHERE SendTiming != -1 GROUP BY CounterID) SETTINGS optimize_aggregation_in_order = 1;\ndiff --git a/tests/queries/1_stateful/00152_insert_different_granularity.sql b/tests/queries/1_stateful/00152_insert_different_granularity.sql\nindex 294d71b384ba..354831494983 100644\n--- a/tests/queries/1_stateful/00152_insert_different_granularity.sql\n+++ b/tests/queries/1_stateful/00152_insert_different_granularity.sql\n@@ -1,4 +1,4 @@\n--- Tags: no-tsan, no-replicated-database, no-parallel\n+-- Tags: no-tsan, no-replicated-database, no-parallel, no-parallel-replicas\n -- Tag no-replicated-database: Fails due to additional replicas or shards\n \n DROP TABLE IF EXISTS fixed_granularity_table;\ndiff --git a/tests/queries/1_stateful/00156_max_execution_speed_sample_merge.sql b/tests/queries/1_stateful/00156_max_execution_speed_sample_merge.sql\nindex e325c18200b5..32079111f6ce 100644\n--- a/tests/queries/1_stateful/00156_max_execution_speed_sample_merge.sql\n+++ b/tests/queries/1_stateful/00156_max_execution_speed_sample_merge.sql\n@@ -1,3 +1,6 @@\n+-- Tags: no-parallel-replicas\n+-- Merge tables doesn't work with parallel replicas currently\n+\n SET max_execution_speed = 4000000, timeout_before_checking_execution_speed = 0;\n \n CREATE TEMPORARY TABLE times (t DateTime);\ndiff --git a/tests/queries/1_stateful/00166_explain_estimate.sql b/tests/queries/1_stateful/00166_explain_estimate.sql\nindex c40712717363..abac92ecb2e2 100644\n--- a/tests/queries/1_stateful/00166_explain_estimate.sql\n+++ b/tests/queries/1_stateful/00166_explain_estimate.sql\n@@ -1,4 +1,4 @@\n--- Tags: no-replicated-database\n+-- Tags: no-replicated-database, no-parallel-replicas\n -- Tag no-replicated-database: Requires investigation\n \n EXPLAIN ESTIMATE SELECT count() FROM test.hits WHERE CounterID = 29103473;\ndiff --git a/tests/queries/1_stateful/00170_s3_cache.sql b/tests/queries/1_stateful/00170_s3_cache.sql\nindex b03b2a16bf09..815922554287 100644\n--- a/tests/queries/1_stateful/00170_s3_cache.sql\n+++ b/tests/queries/1_stateful/00170_s3_cache.sql\n@@ -1,4 +1,4 @@\n--- Tags: no-parallel, no-random-settings\n+-- Tags: no-parallel, no-random-settings, no-parallel-replicas\n \n -- { echo }\n \ndiff --git a/tests/queries/1_stateful/00171_grouping_aggregated_transform_bug.sql b/tests/queries/1_stateful/00171_grouping_aggregated_transform_bug.sql\nindex 7068780a1b1c..07788af927e0 100644\n--- a/tests/queries/1_stateful/00171_grouping_aggregated_transform_bug.sql\n+++ b/tests/queries/1_stateful/00171_grouping_aggregated_transform_bug.sql\n@@ -1,4 +1,4 @@\n--- Tags: distributed\n+-- Tags: distributed, no-parallel-replicas\n \n SELECT sum(cityHash64(*)) FROM (SELECT CounterID, quantileTiming(0.5)(SendTiming), count() FROM remote('127.0.0.{1,2,3,4,5,6,7,8,9,10}', test.hits) WHERE SendTiming != -1 GROUP BY CounterID) SETTINGS max_block_size = 63169;\n SELECT sum(cityHash64(*)) FROM (SELECT CounterID, quantileTiming(0.5)(SendTiming), count() FROM remote('127.0.0.{1,2,3,4,5,6,7,8,9,10}', test.hits) WHERE SendTiming != -1 GROUP BY CounterID) SETTINGS optimize_aggregation_in_order = 1, max_block_size = 63169;\ndiff --git a/tests/queries/1_stateful/00172_early_constant_folding.sql b/tests/queries/1_stateful/00172_early_constant_folding.sql\nindex cc3d2274ecde..b31e418b4926 100644\n--- a/tests/queries/1_stateful/00172_early_constant_folding.sql\n+++ b/tests/queries/1_stateful/00172_early_constant_folding.sql\n@@ -1,1 +1,3 @@\n+-- Tags: no-parallel-replicas\n+\n EXPLAIN PIPELINE SELECT count(JavaEnable) FROM test.hits WHERE WatchID = 1 OR Title = 'next' OR URL = 'prev' OR URL = '???' OR 1;\ndiff --git a/tests/queries/1_stateful/00172_hits_joins.sql.j2 b/tests/queries/1_stateful/00172_hits_joins.sql.j2\nindex 4599d1d5a5d1..4617fe5aef84 100644\n--- a/tests/queries/1_stateful/00172_hits_joins.sql.j2\n+++ b/tests/queries/1_stateful/00172_hits_joins.sql.j2\n@@ -1,3 +1,4 @@\n+-- Tags: no-parallel-replicas\n {% for join_algorithm in ['hash', 'parallel_hash', 'full_sorting_merge', 'grace_hash'] -%}\n \n SET max_rows_in_join = '{% if join_algorithm == 'grace_hash' %}10K{% else %}0{% endif %}';\ndiff --git a/tests/queries/1_stateful/00175_obfuscator_schema_inference.sh b/tests/queries/1_stateful/00175_obfuscator_schema_inference.sh\nindex 771c7ab54361..0b308c650610 100755\n--- a/tests/queries/1_stateful/00175_obfuscator_schema_inference.sh\n+++ b/tests/queries/1_stateful/00175_obfuscator_schema_inference.sh\n@@ -1,4 +1,5 @@\n #!/usr/bin/env bash\n+# Tags: no-parallel-replicas\n \n CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n # shellcheck source=../shell_config.sh\n",
  "problem_statement": "Double output while using allow_experimental_parallel_reading_from_replicas=1\nHow to reproduce: run test 00124_shard_distributed_with_many_replicas.sql with different values of setting `allow_experimental_parallel_reading_from_replicas` \r\n```\r\nch-client --allow_experimental_parallel_reading_from_replicas=0 -nmT < 00124_shard_distributed_with_many_replicas.sql\r\n1\t2015-01-01\t1\tfoo\r\n2\t2015-02-01\t2\tbar\r\n3\t2015-03-01\t3\tfoo\r\n4\t2015-04-01\t4\tbar\r\n5\t2015-05-01\t5\tfoo\r\n```\r\n\r\n```\r\nch-client --allow_experimental_parallel_reading_from_replicas=1 -nmT < 00124_shard_distributed_with_many_replicas.sql\r\n1\t2015-01-01\t1\tfoo\r\n1\t2015-01-01\t1\tfoo\r\n2\t2015-02-01\t2\tbar\r\n2\t2015-02-01\t2\tbar\r\n3\t2015-03-01\t3\tfoo\r\n3\t2015-03-01\t3\tfoo\r\n4\t2015-04-01\t4\tbar\r\n4\t2015-04-01\t4\tbar\r\n5\t2015-05-01\t5\tfoo\r\n5\t2015-05-01\t5\tfoo\r\n```\n",
  "hints_text": "",
  "created_at": "2022-11-28T17:45:29Z",
  "modified_files": [
    ".github/workflows/pull_request.yml",
    "programs/benchmark/Benchmark.cpp",
    "programs/copier/ClusterCopier.cpp",
    "programs/server/config.xml",
    "src/CMakeLists.txt",
    "src/Client/Connection.cpp",
    "src/Client/Connection.h",
    "src/Client/HedgedConnections.h",
    "src/Client/IConnections.h",
    "src/Client/IServerConnection.h",
    "src/Client/LocalConnection.cpp",
    "src/Client/LocalConnection.h",
    "src/Client/MultiplexedConnections.cpp",
    "src/Client/MultiplexedConnections.h",
    "src/Core/Protocol.h",
    "src/Core/ProtocolDefines.h",
    "src/Core/Settings.h",
    "src/Disks/IDisk.h",
    "src/Interpreters/ClusterProxy/SelectStreamFactory.cpp",
    "src/Interpreters/ClusterProxy/SelectStreamFactory.h",
    "src/Interpreters/ClusterProxy/executeQuery.cpp",
    "src/Interpreters/ClusterProxy/executeQuery.h",
    "src/Interpreters/Context.cpp",
    "src/Interpreters/Context.h",
    "src/Interpreters/InterpreterSelectQuery.cpp",
    "src/Interpreters/InterpreterSelectQuery.h",
    "src/Interpreters/InterpreterSelectQueryAnalyzer.cpp",
    "src/Interpreters/interpretSubquery.cpp",
    "src/Processors/QueryPlan/DistributedCreateLocalPlan.cpp",
    "src/Processors/QueryPlan/DistributedCreateLocalPlan.h",
    "src/Processors/QueryPlan/Optimizations/optimizeReadInOrder.cpp",
    "src/Processors/QueryPlan/Optimizations/optimizeTree.cpp",
    "src/Processors/QueryPlan/PartsSplitter.cpp",
    "src/Processors/QueryPlan/QueryPlan.cpp",
    "src/Processors/QueryPlan/ReadFromMergeTree.cpp",
    "src/Processors/QueryPlan/ReadFromMergeTree.h",
    "src/Processors/QueryPlan/ReadFromRemote.cpp",
    "src/Processors/QueryPlan/ReadFromRemote.h",
    "src/Processors/Sources/RemoteSource.cpp",
    "src/Processors/Sources/RemoteSource.h",
    "b/src/Processors/Transforms/ReadFromMergeTreeDependencyTransform.cpp",
    "b/src/Processors/Transforms/ReadFromMergeTreeDependencyTransform.h",
    "src/QueryPipeline/Pipe.h",
    "src/QueryPipeline/QueryPipelineBuilder.cpp",
    "src/QueryPipeline/QueryPipelineBuilder.h",
    "src/QueryPipeline/RemoteQueryExecutor.cpp",
    "src/QueryPipeline/RemoteQueryExecutor.h",
    "src/Server/TCPHandler.cpp",
    "src/Server/TCPHandler.h",
    "src/Storages/MergeTree/IntersectionsIndexes.h",
    "src/Storages/MergeTree/MarkRange.cpp",
    "src/Storages/MergeTree/MarkRange.h",
    "src/Storages/MergeTree/MergeTreeBaseSelectProcessor.cpp",
    "src/Storages/MergeTree/MergeTreeBaseSelectProcessor.h",
    "src/Storages/MergeTree/MergeTreeBlockReadUtils.cpp",
    "src/Storages/MergeTree/MergeTreeBlockReadUtils.h",
    "src/Storages/MergeTree/MergeTreeData.cpp",
    "src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp",
    "src/Storages/MergeTree/MergeTreeInOrderSelectProcessor.cpp",
    "src/Storages/MergeTree/MergeTreePartInfo.cpp",
    "src/Storages/MergeTree/MergeTreePartInfo.h",
    "src/Storages/MergeTree/MergeTreeReadPool.cpp",
    "src/Storages/MergeTree/MergeTreeReadPool.h",
    "src/Storages/MergeTree/MergeTreeReverseSelectProcessor.cpp",
    "src/Storages/MergeTree/MergeTreeReverseSelectProcessor.h",
    "src/Storages/MergeTree/MergeTreeSelectProcessor.cpp",
    "src/Storages/MergeTree/MergeTreeSelectProcessor.h",
    "src/Storages/MergeTree/MergeTreeThreadSelectProcessor.cpp",
    "src/Storages/MergeTree/MergeTreeThreadSelectProcessor.h",
    "src/Storages/MergeTree/ParallelReplicasReadingCoordinator.cpp",
    "src/Storages/MergeTree/ParallelReplicasReadingCoordinator.h",
    "b/src/Storages/MergeTree/RangesInDataPart.cpp",
    "src/Storages/MergeTree/RangesInDataPart.h",
    "src/Storages/MergeTree/RequestResponse.cpp",
    "src/Storages/MergeTree/RequestResponse.h",
    "src/Storages/SelectQueryInfo.h",
    "src/Storages/StorageDistributed.cpp",
    "src/Storages/StorageMergeTree.cpp",
    "src/Storages/StorageProxy.h",
    "src/Storages/StorageReplicatedMergeTree.cpp",
    "src/Storages/getStructureOfRemoteTable.cpp"
  ],
  "modified_test_files": [
    "docker/test/stateful/run.sh",
    "docker/test/stateless/run.sh",
    "src/Storages/MergeTree/tests/gtest_coordinator.cpp",
    "tests/ci/ci_config.py",
    "tests/ci/functional_test_check.py",
    "tests/clickhouse-test",
    "tests/performance/memory_bound_merging.xml",
    "tests/queries/0_stateless/02404_memory_bound_merging.reference",
    "tests/queries/0_stateless/02404_memory_bound_merging.sql",
    "tests/queries/1_stateful/00009_uniq_distributed.sql",
    "tests/queries/1_stateful/00012_sorting_distributed.sql",
    "tests/queries/1_stateful/00013_sorting_of_nested.sql",
    "tests/queries/1_stateful/00016_any_if_distributed_cond_always_false.sql",
    "tests/queries/1_stateful/00022_merge_prewhere.sql",
    "tests/queries/1_stateful/00042_any_left_join.sql",
    "tests/queries/1_stateful/00043_any_left_join.sql",
    "tests/queries/1_stateful/00044_any_left_join_string.sql",
    "tests/queries/1_stateful/00063_loyalty_joins.sql",
    "tests/queries/1_stateful/00065_loyalty_with_storage_join.sql",
    "tests/queries/1_stateful/00066_sorting_distributed_many_replicas.sql",
    "tests/queries/1_stateful/00074_full_join.sql",
    "tests/queries/1_stateful/00075_left_array_join.sql",
    "tests/queries/1_stateful/00079_array_join_not_used_joined_column.sql",
    "tests/queries/1_stateful/00080_array_join_and_union.sql",
    "tests/queries/1_stateful/00084_external_aggregation.sql",
    "tests/queries/1_stateful/00091_prewhere_two_conditions.sql",
    "tests/queries/1_stateful/00092_obfuscator.sh",
    "tests/queries/1_stateful/00096_obfuscator_save_load.sh",
    "tests/queries/1_stateful/00146_aggregate_function_uniq.sql",
    "tests/queries/1_stateful/00149_quantiles_timing_distributed.sql",
    "tests/queries/1_stateful/00152_insert_different_granularity.sql",
    "tests/queries/1_stateful/00156_max_execution_speed_sample_merge.sql",
    "tests/queries/1_stateful/00166_explain_estimate.sql",
    "tests/queries/1_stateful/00170_s3_cache.sql",
    "tests/queries/1_stateful/00171_grouping_aggregated_transform_bug.sql",
    "tests/queries/1_stateful/00172_early_constant_folding.sql",
    "tests/queries/1_stateful/00172_hits_joins.sql.j2",
    "tests/queries/1_stateful/00175_obfuscator_schema_inference.sh"
  ]
}