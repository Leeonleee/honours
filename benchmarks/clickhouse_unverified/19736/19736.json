{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 19736,
  "instance_id": "ClickHouse__ClickHouse-19736",
  "issue_numbers": [
    "19108"
  ],
  "base_commit": "d37ca628df96acd631bd3834d620228e19a8e2c5",
  "patch": "diff --git a/src/DataTypes/DataTypeFactory.cpp b/src/DataTypes/DataTypeFactory.cpp\nindex 2f100202ee9e..dc3ce039dbde 100644\n--- a/src/DataTypes/DataTypeFactory.cpp\n+++ b/src/DataTypes/DataTypeFactory.cpp\n@@ -29,8 +29,14 @@ namespace ErrorCodes\n \n DataTypePtr DataTypeFactory::get(const String & full_name) const\n {\n+    /// Data type parser can be invoked from coroutines with small stack.\n+    /// Value 315 is known to cause stack overflow in some test configurations (debug build, sanitizers)\n+    /// let's make the threshold significantly lower.\n+    /// It is impractical for user to have complex data types with this depth.\n+    static constexpr size_t data_type_max_parse_depth = 200;\n+\n     ParserDataType parser;\n-    ASTPtr ast = parseQuery(parser, full_name.data(), full_name.data() + full_name.size(), \"data type\", 0, DBMS_DEFAULT_MAX_PARSER_DEPTH);\n+    ASTPtr ast = parseQuery(parser, full_name.data(), full_name.data() + full_name.size(), \"data type\", 0, data_type_max_parse_depth);\n     return get(ast);\n }\n \ndiff --git a/src/Parsers/ParserDataType.cpp b/src/Parsers/ParserDataType.cpp\nindex 0148f2f3bb9c..3d3f393a300b 100644\n--- a/src/Parsers/ParserDataType.cpp\n+++ b/src/Parsers/ParserDataType.cpp\n@@ -14,21 +14,29 @@ namespace\n {\n \n /// Wrapper to allow mixed lists of nested and normal types.\n-class ParserNestedTableOrExpression : public IParserBase\n+/// Parameters are either:\n+/// - Nested table elements;\n+/// - Enum element in form of 'a' = 1;\n+/// - literal;\n+/// - another data type (or identifier)\n+class ParserDataTypeArgument : public IParserBase\n {\n-    private:\n-        const char * getName() const override { return \"data type or expression\"; }\n-        bool parseImpl(Pos & pos, ASTPtr & node, Expected & expected) override\n-        {\n-            ParserNestedTable parser1;\n-\n-            if (parser1.parse(pos, node, expected))\n-                return true;\n+private:\n+    const char * getName() const override { return \"data type argument\"; }\n+    bool parseImpl(Pos & pos, ASTPtr & node, Expected & expected) override\n+    {\n+        ParserNestedTable nested_parser;\n+        ParserDataType data_type_parser;\n+        ParserLiteral literal_parser;\n \n-            ParserExpression parser2;\n+        const char * operators[] = {\"=\", \"equals\", nullptr};\n+        ParserLeftAssociativeBinaryOperatorList enum_parser(operators, std::make_unique<ParserLiteral>());\n \n-            return parser2.parse(pos, node, expected);\n-        }\n+        return nested_parser.parse(pos, node, expected)\n+            || enum_parser.parse(pos, node, expected)\n+            || literal_parser.parse(pos, node, expected)\n+            || data_type_parser.parse(pos, node, expected);\n+    }\n };\n \n }\n@@ -104,7 +112,7 @@ bool ParserDataType::parseImpl(Pos & pos, ASTPtr & node, Expected & expected)\n     ++pos;\n \n     /// Parse optional parameters\n-    ParserList args_parser(std::make_unique<ParserNestedTableOrExpression>(), std::make_unique<ParserToken>(TokenType::Comma));\n+    ParserList args_parser(std::make_unique<ParserDataTypeArgument>(), std::make_unique<ParserToken>(TokenType::Comma));\n     ASTPtr expr_list_args;\n \n     if (!args_parser.parse(pos, expr_list_args, expected))\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/00945_bloom_filter_index.sql b/tests/queries/0_stateless/00945_bloom_filter_index.sql\nindex 82321a75c679..ad9c807fc5a6 100644\n--- a/tests/queries/0_stateless/00945_bloom_filter_index.sql\n+++ b/tests/queries/0_stateless/00945_bloom_filter_index.sql\n@@ -163,23 +163,23 @@ DROP TABLE IF EXISTS bloom_filter_lc_null_types_test;\n DROP TABLE IF EXISTS bloom_filter_array_lc_null_types_test;\n \n CREATE TABLE bloom_filter_array_lc_null_types_test (\n-    order_key   Array(LowCardinality(Nullable((UInt64)))),\n-\n-    i8 Array(LowCardinality(Nullable((Int8)))),\n-    i16 Array(LowCardinality(Nullable((Int16)))),\n-    i32 Array(LowCardinality(Nullable((Int32)))),\n-    i64 Array(LowCardinality(Nullable((Int64)))),\n-    u8 Array(LowCardinality(Nullable((UInt8)))),\n-    u16 Array(LowCardinality(Nullable((UInt16)))),\n-    u32 Array(LowCardinality(Nullable((UInt32)))),\n-    u64 Array(LowCardinality(Nullable((UInt64)))),\n-    f32 Array(LowCardinality(Nullable((Float32)))),\n-    f64 Array(LowCardinality(Nullable((Float64)))),\n-\n-    date Array(LowCardinality(Nullable((Date)))),\n+    order_key   Array(LowCardinality(Nullable(UInt64))),\n+\n+    i8 Array(LowCardinality(Nullable(Int8))),\n+    i16 Array(LowCardinality(Nullable(Int16))),\n+    i32 Array(LowCardinality(Nullable(Int32))),\n+    i64 Array(LowCardinality(Nullable(Int64))),\n+    u8 Array(LowCardinality(Nullable(UInt8))),\n+    u16 Array(LowCardinality(Nullable(UInt16))),\n+    u32 Array(LowCardinality(Nullable(UInt32))),\n+    u64 Array(LowCardinality(Nullable(UInt64))),\n+    f32 Array(LowCardinality(Nullable(Float32))),\n+    f64 Array(LowCardinality(Nullable(Float64))),\n+\n+    date Array(LowCardinality(Nullable(Date))),\n     date_time Array(LowCardinality(Nullable(DateTime('Europe/Moscow')))),\n \n-    str Array(LowCardinality(Nullable((String)))),\n+    str Array(LowCardinality(Nullable(String))),\n     fixed_string Array(LowCardinality(Nullable(FixedString(5)))),\n     INDEX idx (i8, i16, i32, i64, u8, u16, u32, u64, f32, f64, date, date_time, str, fixed_string)\n     TYPE bloom_filter GRANULARITY 1)\n@@ -286,7 +286,7 @@ SELECT COUNT() FROM bloom_filter_array_lc_null_types_test WHERE has(fixed_string\n DROP TABLE IF EXISTS bloom_filter_array_lc_null_types_test;\n \n DROP TABLE IF EXISTS bloom_filter_array_offsets_lc_str;\n-CREATE TABLE bloom_filter_array_offsets_lc_str (order_key int, str Array(LowCardinality((String))), INDEX idx str TYPE bloom_filter(1.) GRANULARITY 1024) ENGINE = MergeTree() ORDER BY order_key SETTINGS index_granularity = 1024;\n+CREATE TABLE bloom_filter_array_offsets_lc_str (order_key int, str Array(LowCardinality(String)), INDEX idx str TYPE bloom_filter(1.) GRANULARITY 1024) ENGINE = MergeTree() ORDER BY order_key SETTINGS index_granularity = 1024;\n INSERT INTO bloom_filter_array_offsets_lc_str SELECT number AS i, if(i%2, ['value'], []) FROM system.numbers LIMIT 10000;\n SELECT count() FROM bloom_filter_array_offsets_lc_str WHERE has(str, 'value');\n DROP TABLE IF EXISTS bloom_filter_array_offsets_lc_str;\ndiff --git a/tests/queries/0_stateless/01414_low_cardinality_nullable.sql b/tests/queries/0_stateless/01414_low_cardinality_nullable.sql\nindex 9a554ead7763..596e90adfd66 100644\n--- a/tests/queries/0_stateless/01414_low_cardinality_nullable.sql\n+++ b/tests/queries/0_stateless/01414_low_cardinality_nullable.sql\n@@ -1,7 +1,7 @@\n DROP TABLE IF EXISTS lc_nullable;\n \n CREATE TABLE lc_nullable (\n-    order_key   Array(LowCardinality(Nullable((UInt64)))),\n+    order_key   Array(LowCardinality(Nullable(UInt64))),\n \n     i8  Array(LowCardinality(Nullable(Int8))),\n     i16 Array(LowCardinality(Nullable(Int16))),\n@@ -14,10 +14,10 @@ CREATE TABLE lc_nullable (\n     f32 Array(LowCardinality(Nullable(Float32))),\n     f64 Array(LowCardinality(Nullable(Float64))),\n \n-    date Array(LowCardinality(Nullable((Date)))),\n+    date Array(LowCardinality(Nullable(Date))),\n     date_time Array(LowCardinality(Nullable(DateTime('Europe/Moscow')))),\n \n-    str Array(LowCardinality(Nullable((String)))),\n+    str Array(LowCardinality(Nullable(String))),\n     fixed_string Array(LowCardinality(Nullable(FixedString(5))))\n ) ENGINE = MergeTree() ORDER BY order_key;\n \ndiff --git a/tests/queries/0_stateless/01675_data_type_coroutine.reference b/tests/queries/0_stateless/01675_data_type_coroutine.reference\nnew file mode 100644\nindex 000000000000..7326d9603970\n--- /dev/null\n+++ b/tests/queries/0_stateless/01675_data_type_coroutine.reference\n@@ -0,0 +1,1 @@\n+Ok\ndiff --git a/tests/queries/0_stateless/01675_data_type_coroutine.sh b/tests/queries/0_stateless/01675_data_type_coroutine.sh\nnew file mode 100755\nindex 000000000000..781e43e41346\n--- /dev/null\n+++ b/tests/queries/0_stateless/01675_data_type_coroutine.sh\n@@ -0,0 +1,16 @@\n+#!/usr/bin/env bash\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+I=0\n+while true\n+do\n+    I=$((I + 1))\n+    TYPE=$(perl -e \"print 'Array(' x $I; print 'UInt8'; print ')' x $I\")\n+    ${CLICKHOUSE_CLIENT} --max_parser_depth 1000000 --query \"SELECT * FROM remote('127.0.0.{1,2}', generateRandom('x $TYPE', 1, 1, 1)) LIMIT 1 FORMAT Null\" 2>&1 | grep -q -F 'Maximum parse depth' && break;\n+done\n+\n+#echo \"I = ${I}\"\n+echo 'Ok'\ndiff --git a/tests/queries/0_stateless/arcadia_skip_list.txt b/tests/queries/0_stateless/arcadia_skip_list.txt\nindex 871d429e0371..253eab720af5 100644\n--- a/tests/queries/0_stateless/arcadia_skip_list.txt\n+++ b/tests/queries/0_stateless/arcadia_skip_list.txt\n@@ -196,4 +196,5 @@\n 01181_db_atomic_drop_on_cluster\n 01658_test_base64Encode_mysql_compatibility\n 01659_test_base64Decode_mysql_compatibility\n+01675_data_type_coroutine\n 01671_aggregate_function_group_bitmap_data\n",
  "problem_statement": "Fuzzer: Segfault without stacktrace\nhttps://clickhouse-test-reports.s3.yandex.net/18979/27600064159ac63e05800ef37afa41b317771352/fuzzer/report.html#fail1\r\n\r\nFuzzer log:\r\n```\r\nSELECT ((100, (toUInt8(3), toUInt8(NULL)), toUInt8(1048576)), 65537, toUInt8(1023))\r\nFROM dist_01528\r\nWHERE dummy = 100\r\nSETTINGS allow_nondeterministic_optimize_skip_unused_shards = 1\r\n\r\nError on processing query 'SELECT ((100, (toUInt8(3), toUInt8(NULL)), toUInt8(1048576)), 65537, toUInt8(1023)) FROM dist_01528 WHERE dummy = 100 SETTINGS allow_nondeterministic_optimize_skip_unused_shards = 1': Code: 32, e.displayText() = DB::Exception: Attempt to read after eof: while receiving packet from localhost:9000, Stack trace (when copying this message, always include the lines below):\r\n\r\n0. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/exception:133: std::exception::capture() @ 0x10763718 in /workspace/clickhouse\r\n1. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/exception:111: std::exception::exception() @ 0x107636e5 in /workspace/clickhouse\r\n2. ./obj-x86_64-linux-gnu/../contrib/poco/Foundation/src/Exception.cpp:27: Poco::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x1e2fad93 in /workspace/clickhouse\r\n3. ./obj-x86_64-linux-gnu/../src/Common/Exception.cpp:54: DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x107455ea in /workspace/clickhouse\r\n4. ./obj-x86_64-linux-gnu/../src/IO/VarInt.h:122: DB::throwReadAfterEOF() @ 0x10763ac7 in /workspace/clickhouse\r\n5. ./obj-x86_64-linux-gnu/../src/IO/VarInt.h:135: void DB::readVarUIntImpl<false>(unsigned long&, DB::ReadBuffer&) @ 0x1079ec87 in /workspace/clickhouse\r\n6. ./obj-x86_64-linux-gnu/../src/IO/VarInt.h:149: DB::readVarUInt(unsigned long&, DB::ReadBuffer&) @ 0x1079e914 in /workspace/clickhouse\r\n7. ./obj-x86_64-linux-gnu/../src/Client/Connection.cpp:762: DB::Connection::receivePacket(std::__1::function<void (Poco::Net::Socket&)>) @ 0x1a954da2 in /workspace/clickhouse\r\n8. ./obj-x86_64-linux-gnu/../programs/client/Client.cpp:1667: DB::Client::receiveAndProcessPacket(bool) @ 0x1088fc7b in /workspace/clickhouse\r\n9. ./obj-x86_64-linux-gnu/../programs/client/Client.cpp:1653: DB::Client::receiveResult() @ 0x1089477c in /workspace/clickhouse\r\n10. ./obj-x86_64-linux-gnu/../programs/client/Client.cpp:1373: DB::Client::processOrdinaryQuery() @ 0x1087be6c in /workspace/clickhouse\r\n11. ./obj-x86_64-linux-gnu/../programs/client/Client.cpp:1280: DB::Client::processParsedSingleQuery() @ 0x1087ac5b in /workspace/clickhouse\r\n12. ./obj-x86_64-linux-gnu/../programs/client/Client.cpp:1130: DB::Client::processWithFuzzing(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) @ 0x108786b8 in /workspace/clickhouse\r\n13. ./obj-x86_64-linux-gnu/../programs/client/Client.cpp:988: DB::Client::processMultiQuery(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) @ 0x10879591 in /workspace/clickhouse\r\n14. ./obj-x86_64-linux-gnu/../programs/client/Client.cpp:804: DB::Client::nonInteractive() @ 0x10866314 in /workspace/clickhouse\r\n15. ./obj-x86_64-linux-gnu/../programs/client/Client.cpp:706: DB::Client::mainImpl() @ 0x10863665 in /workspace/clickhouse\r\n16. ./obj-x86_64-linux-gnu/../programs/client/Client.cpp:278: DB::Client::main(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) @ 0x10859a76 in /workspace/clickhouse\r\n17. ./obj-x86_64-linux-gnu/../contrib/poco/Util/src/Application.cpp:334: Poco::Util::Application::run() @ 0x1e254aef in /workspace/clickhouse\r\n18. ./obj-x86_64-linux-gnu/../programs/client/Client.cpp:2486: mainEntryClickHouseClient(int, char**) @ 0x10851787 in /workspace/clickhouse\r\n19. ./obj-x86_64-linux-gnu/../programs/main.cpp:368: main @ 0x10736ae5 in /workspace/clickhouse\r\n20. /build/glibc-S9d2JN/glibc-2.27/csu/../csu/libc-start.c:344: __libc_start_main @ 0x21bf7 in /usr/lib/debug/lib/x86_64-linux-gnu/libc-2.27.so\r\n21. _start @ 0x1073672e in /workspace/clickhouse\r\n (version 21.1.1.5681)\r\nFuzzing step 314 out of 1000\r\n```\r\n\r\nServer log:\r\n```\r\n2021.01.15 01:03:18.452778 [ 66 ] {4d77c30c-b1e8-4cf0-8b78-f1ad5573edb1} <Debug> executeQuery: (from [::1]:46782, using production parser) SELECT (65537, toUInt8(-1)) FROM dist_01528 WHERE dummy = 100 SETTINGS allow_nondeterministic_optimize_skip_unused_shards = 1\r\n2021.01.15 01:03:18.455101 [ 66 ] {4d77c30c-b1e8-4cf0-8b78-f1ad5573edb1} <Debug> StorageDistributed (dist_01528): Skipping irrelevant shards - the query will be sent to the following shards of the cluster (shard numbers): [1]\r\n2021.01.15 01:03:18.457177 [ 66 ] {4d77c30c-b1e8-4cf0-8b78-f1ad5573edb1} <Trace> ContextAccess (default): Access granted: SELECT(dummy) ON default.dist_01528\r\n2021.01.15 01:03:18.459540 [ 66 ] {4d77c30c-b1e8-4cf0-8b78-f1ad5573edb1} <Debug> StorageDistributed (dist_01528): Skipping irrelevant shards - the query will be sent to the following shards of the cluster (shard numbers): [1]\r\n2021.01.15 01:03:18.461553 [ 66 ] {4d77c30c-b1e8-4cf0-8b78-f1ad5573edb1} <Trace> ContextAccess (default): Access granted: SELECT(dummy) ON default.dist_01528\r\n2021.01.15 01:03:18.465080 [ 66 ] {4d77c30c-b1e8-4cf0-8b78-f1ad5573edb1} <Trace> ContextAccess (default): Access granted: SELECT(dummy) ON system.one\r\n2021.01.15 01:03:18.465414 [ 66 ] {4d77c30c-b1e8-4cf0-8b78-f1ad5573edb1} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n2021.01.15 01:03:18.466918 [ 66 ] {4d77c30c-b1e8-4cf0-8b78-f1ad5573edb1} <Trace> InterpreterSelectQuery: Complete -> Complete\r\n2021.01.15 01:03:18.470815 [ 114 ] {4d77c30c-b1e8-4cf0-8b78-f1ad5573edb1} <Trace> PipelineExecutor: Thread finished. Total time: 0.000321977 sec. Execution time: 0.000111691 sec. Processing time: 0.000193292 sec. Wait time: 1.6994e-05 sec.\r\n2021.01.15 01:03:18.471511 [ 66 ] {4d77c30c-b1e8-4cf0-8b78-f1ad5573edb1} <Information> executeQuery: Read 1 rows, 1.00 B in 0.018558757 sec., 53 rows/sec., 53.88 B/sec.\r\n2021.01.15 01:03:18.471696 [ 66 ] {4d77c30c-b1e8-4cf0-8b78-f1ad5573edb1} <Debug> MemoryTracker: Peak memory usage (for query): 0.00 B.\r\n2021.01.15 01:03:18.472569 [ 66 ] {} <Debug> TCPHandler: Processed in 0.022818956 sec.\r\n2021.01.15 01:03:18.482945 [ 66 ] {d4a8e027-35e0-4fa2-94d7-9f1fa1d61276} <Debug> executeQuery: (from [::1]:46782, using production parser) SELECT ((-1, (toUInt8(3), toUInt8(NULL)), toUInt8(65537)), 65537, toUInt8(1023)) FROM dist_01528 WHERE dummy = 100 SETTINGS allow_nondeterministic_optimize_skip_unused_shards = 1\r\n2021.01.15 01:03:18.485741 [ 66 ] {d4a8e027-35e0-4fa2-94d7-9f1fa1d61276} <Debug> StorageDistributed (dist_01528): Skipping irrelevant shards - the query will be sent to the following shards of the cluster (shard numbers): [1]\r\n2021.01.15 01:03:18.489727 [ 66 ] {d4a8e027-35e0-4fa2-94d7-9f1fa1d61276} <Trace> ContextAccess (default): Access granted: SELECT(dummy) ON default.dist_01528\r\n2021.01.15 01:03:18.492585 [ 66 ] {d4a8e027-35e0-4fa2-94d7-9f1fa1d61276} <Debug> StorageDistributed (dist_01528): Skipping irrelevant shards - the query will be sent to the following shards of the cluster (shard numbers): [2]\r\n2021.01.15 01:03:18.496532 [ 66 ] {d4a8e027-35e0-4fa2-94d7-9f1fa1d61276} <Trace> ContextAccess (default): Access granted: SELECT(dummy) ON default.dist_01528\r\n2021.01.15 01:03:18.502449 [ 66 ] {d4a8e027-35e0-4fa2-94d7-9f1fa1d61276} <Trace> ContextAccess (default): Access granted: SELECT(dummy) ON system.one\r\n2021.01.15 01:03:18.502786 [ 66 ] {d4a8e027-35e0-4fa2-94d7-9f1fa1d61276} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n2021.01.15 01:03:18.505113 [ 66 ] {d4a8e027-35e0-4fa2-94d7-9f1fa1d61276} <Trace> InterpreterSelectQuery: Complete -> Complete\r\n2021.01.15 01:03:18.510451 [ 131 ] {d4a8e027-35e0-4fa2-94d7-9f1fa1d61276} <Trace> PipelineExecutor: Thread finished. Total time: 0.000431822 sec. Execution time: 0.000240757 sec. Processing time: 0.000171492 sec. Wait time: 1.9573e-05 sec.\r\n2021.01.15 01:03:18.511127 [ 66 ] {d4a8e027-35e0-4fa2-94d7-9f1fa1d61276} <Information> executeQuery: Read 1 rows, 1.00 B in 0.027976969 sec., 35 rows/sec., 35.74 B/sec.\r\n2021.01.15 01:03:18.511310 [ 66 ] {d4a8e027-35e0-4fa2-94d7-9f1fa1d61276} <Debug> MemoryTracker: Peak memory usage (for query): 0.00 B.\r\n2021.01.15 01:03:18.512219 [ 66 ] {} <Debug> TCPHandler: Processed in 0.035391971 sec.\r\n2021.01.15 01:03:18.520945 [ 66 ] {5c6bacee-e200-4b99-84c7-193fd79cef3b} <Debug> executeQuery: (from [::1]:46782, using production parser) SELECT ((100, (toUInt8(3), toUInt8(NULL)), toUInt8(1048576)), 65537, toUInt8(1023)) FROM dist_01528 WHERE dummy = 100 SETTINGS allow_nondeterministic_optimize_skip_unused_shards = 1\r\n2021.01.15 01:03:18.523659 [ 66 ] {5c6bacee-e200-4b99-84c7-193fd79cef3b} <Debug> StorageDistributed (dist_01528): Skipping irrelevant shards - the query will be sent to the following shards of the cluster (shard numbers): [2]\r\n2021.01.15 01:03:18.527695 [ 66 ] {5c6bacee-e200-4b99-84c7-193fd79cef3b} <Trace> ContextAccess (default): Access granted: SELECT(dummy) ON default.dist_01528\r\n2021.01.15 01:03:18.530462 [ 66 ] {5c6bacee-e200-4b99-84c7-193fd79cef3b} <Debug> StorageDistributed (dist_01528): Skipping irrelevant shards - the query will be sent to the following shards of the cluster (shard numbers): [1]\r\n2021.01.15 01:03:18.534410 [ 66 ] {5c6bacee-e200-4b99-84c7-193fd79cef3b} <Trace> ContextAccess (default): Access granted: SELECT(dummy) ON default.dist_01528\r\n2021.01.15 01:03:18.535889 [ 66 ] {5c6bacee-e200-4b99-84c7-193fd79cef3b} <Trace> InterpreterSelectQuery: Complete -> Complete\r\n2021.01.15 01:03:18.546266 [ 142 ] {ae3f89c4-0593-425a-ba17-513c9b90ca4a} <Debug> executeQuery: (from [::ffff:127.0.0.1]:46004, initial_query_id: 5c6bacee-e200-4b99-84c7-193fd79cef3b, using production parser) SELECT ((100, (toUInt8(3), toUInt8(NULL)), toUInt8(1048576)), 65537, toUInt8(1023)) FROM system.one WHERE dummy = 100\r\n2021.01.15 01:03:18.552015 [ 142 ] {ae3f89c4-0593-425a-ba17-513c9b90ca4a} <Trace> ContextAccess (default): Access granted: SELECT(dummy) ON system.one\r\n2021.01.15 01:03:18.552394 [ 142 ] {ae3f89c4-0593-425a-ba17-513c9b90ca4a} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n2021.01.15 01:03:20.101390 [ 56 ] {} <Fatal> Application: Child process was terminated by signal 11.\r\n```\r\n\r\nNo other messages from thread 56 in log.\n",
  "hints_text": "same issue in debug stateless tests\r\nhttps://clickhouse-test-reports.s3.yandex.net/0/d8b9278193405512bc96bd74d3f30d281c481bb9/functional_stateless_tests_(debug).html\nhttps://clickhouse-test-reports.s3.yandex.net/19385/117708abc616a777014566cca6f1a00a3dae4109/fuzzer_debug/server.log\nIt may happen after adding \"sigaltstack\".\r\nIf some thread expects to have alternative signal stack but it has not been set up correctly, we will have this error.\r\n\r\n> No other messages from thread 56 in log.\r\n\r\nWe have only tail of the server log, maybe we need a full log to figure out what thread 56 is.\nAnother one? https://clickhouse-test-reports.s3.yandex.net/19529/61e93d15a8f36702920238a93bfeee64f80715c7/functional_stateless_tests_(antlr_debug).html#fail1\nThe diagnostics started to work:\r\nhttps://clickhouse-test-reports.s3.yandex.net/19713/83b9677f1cf51d75114927e8fcdb2fe12ae078db/fuzzer_asan/main.log\nIt is stack overflow in coroutine, CC @KochetovNicolai \r\n\r\nIt looks like stack overflow:\r\n```\r\ngrep -c wrapParseImpl main.log\r\n158\r\n```\r\nBut thread stack size must be sufficient even in debug build.\r\n\r\nThis is the culprit:\r\n```\r\n2021-01-27 22:30:24\t #605 0x000000001df43c21 in DB::DataTypeFactory::get (this=<optimized out>, full_name=...) at ../src/DataTypes/DataTypeFactory.cpp:33\r\n2021-01-27 22:30:24\t #606 0x000000001f1e0087 in DB::NativeBlockInputStream::readImpl (this=<optimized out>) at ../src/DataStreams/NativeBlockInputStream.cpp:149\r\n2021-01-27 22:30:24\t #607 0x000000001de76e08 in DB::IBlockInputStream::read (this=0x61800049e498) at ../src/DataStreams/IBlockInputStream.cpp:58\r\n2021-01-27 22:30:24\t #608 0x00000000205f08ab in DB::Connection::receiveDataImpl (this=0x616000372698, stream=...) at ../src/Client/Connection.cpp:845\r\n2021-01-27 22:30:24\t #609 0x00000000205ee599 in DB::Connection::receiveData (this=0x616000372698) at ../src/Client/Connection.cpp:826\r\n2021-01-27 22:30:24\t #610 DB::Connection::receivePacket(std::__1::function<void (Poco::Net::Socket&)>) (this=0x616000372698, async_callback=...) at ../src/Client/Connection.cpp:775\r\n2021-01-27 22:30:24\t #611 0x0000000020616fa0 in DB::MultiplexedConnections::receivePacketUnlocked(std::__1::function<void (Poco::Net::Socket&)>) (this=<optimized out>, async_callback=...) at ../src/Client/MultiplexedConnections.cpp:252\r\n2021-01-27 22:30:24\t #612 0x000000001decb482 in DB::RemoteQueryExecutorRoutine::operator() (this=0x7fdcf03b0f20, sink=...) at ../src/DataStreams/RemoteQueryExecutorReadContext.cpp:46\r\n2021-01-27 22:30:24\t #613 0x000000001deca996 in boost::context::detail::invoke<DB::RemoteQueryExecutorRoutine&, boost::context::fiber> (fn=..., args=...) at ../contrib/boost/boost/context/detail/invoke.hpp:41\r\n2021-01-27 22:30:24\t #614 boost::context::detail::fiber_capture_record<boost::context::fiber, FiberStack&, DB::RemoteQueryExecutorRoutine>::run (this=0x7fdcf03b0b00) at ../contrib/boost/boost/context/fiber_ucontext.hpp:289\r\n2021-01-27 22:30:24\t #615 0x000000001dec923b in boost::context::detail::fiber_entry_func<boost::context::detail::fiber_capture_record<boost::context::fiber, FiberStack&, DB::RemoteQueryExecutorRoutine> > (data=0x7fdcf03aee60) at ../contrib/boost/boost/context/fiber_ucontext.hpp:72\r\n2021-01-27 22:30:24\t #616 0x00007fddfc06d660 in ?? () at ../sysdeps/unix/sysv/linux/x86_64/__start_context.S:91 from /lib/x86_64-linux-gnu/libc.so.6\r\n2021-01-27 22:30:24\t #617 0x0000000000000000 in ?? ()\r\n```",
  "created_at": "2021-01-28T01:31:04Z",
  "modified_files": [
    "src/DataTypes/DataTypeFactory.cpp",
    "src/Parsers/ParserDataType.cpp"
  ],
  "modified_test_files": [
    "tests/queries/0_stateless/00945_bloom_filter_index.sql",
    "tests/queries/0_stateless/01414_low_cardinality_nullable.sql",
    "b/tests/queries/0_stateless/01675_data_type_coroutine.reference",
    "b/tests/queries/0_stateless/01675_data_type_coroutine.sh",
    "tests/queries/0_stateless/arcadia_skip_list.txt"
  ]
}