{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 14845,
  "instance_id": "ClickHouse__ClickHouse-14845",
  "issue_numbers": [
    "14531"
  ],
  "base_commit": "1ba67ea8a1aa3964677ebb534cf1837b691f1fe9",
  "patch": "diff --git a/src/Storages/MergeTree/MergeTreeBlockReadUtils.cpp b/src/Storages/MergeTree/MergeTreeBlockReadUtils.cpp\nindex 03235742a683..739dfedfde41 100644\n--- a/src/Storages/MergeTree/MergeTreeBlockReadUtils.cpp\n+++ b/src/Storages/MergeTree/MergeTreeBlockReadUtils.cpp\n@@ -1,5 +1,6 @@\n #include <Storages/MergeTree/MergeTreeBlockReadUtils.h>\n #include <Storages/MergeTree/MergeTreeData.h>\n+#include <Common/checkStackSize.h>\n #include <Common/typeid_cast.h>\n #include <Columns/ColumnConst.h>\n #include <unordered_set>\n@@ -10,61 +11,89 @@ namespace DB\n namespace ErrorCodes\n {\n     extern const int LOGICAL_ERROR;\n+    extern const int NO_SUCH_COLUMN_IN_TABLE;\n }\n \n+namespace\n+{\n+\n+/// Columns absent in part may depend on other absent columns so we are\n+/// searching all required physical columns recursively. Return true if found at\n+/// least one existing (physical) column in part.\n+bool injectRequiredColumnsRecursively(\n+    const String & column_name,\n+    const ColumnsDescription & storage_columns,\n+    const MergeTreeData::AlterConversions & alter_conversions,\n+    const MergeTreeData::DataPartPtr & part,\n+    Names & columns,\n+    NameSet & required_columns,\n+    NameSet & injected_columns)\n+{\n+    /// This is needed to prevent stack overflow in case of cyclic defaults or\n+    /// huge AST which for some reason was not validated on parsing/interpreter\n+    /// stages.\n+    checkStackSize();\n+    String column_name_in_part = column_name;\n+    if (alter_conversions.isColumnRenamed(column_name_in_part))\n+        column_name_in_part = alter_conversions.getColumnOldName(column_name_in_part);\n+\n+    /// column has files and hence does not require evaluation\n+    if (storage_columns.hasPhysical(column_name) && part->hasColumnFiles(column_name_in_part, *storage_columns.getPhysical(column_name).type))\n+    {\n+        /// ensure each column is added only once\n+        if (required_columns.count(column_name) == 0)\n+        {\n+            columns.emplace_back(column_name);\n+            required_columns.emplace(column_name);\n+            injected_columns.emplace(column_name);\n+        }\n+        return true;\n+    }\n+\n+    /// Column doesn't have default value and don't exist in part\n+    /// don't need to add to required set.\n+    const auto column_default = storage_columns.getDefault(column_name);\n+    if (!column_default)\n+        return false;\n+\n+    /// collect identifiers required for evaluation\n+    IdentifierNameSet identifiers;\n+    column_default->expression->collectIdentifierNames(identifiers);\n+\n+    bool result = false;\n+    for (const auto & identifier : identifiers)\n+        result |= injectRequiredColumnsRecursively(identifier, storage_columns, alter_conversions, part, columns, required_columns, injected_columns);\n+\n+    return result;\n+}\n+\n+}\n \n NameSet injectRequiredColumns(const MergeTreeData & storage, const StorageMetadataPtr & metadata_snapshot, const MergeTreeData::DataPartPtr & part, Names & columns)\n {\n     NameSet required_columns{std::begin(columns), std::end(columns)};\n     NameSet injected_columns;\n \n-    auto all_column_files_missing = true;\n+    bool have_at_least_one_physical_column = false;\n \n     const auto & storage_columns = metadata_snapshot->getColumns();\n     auto alter_conversions = storage.getAlterConversionsForPart(part);\n     for (size_t i = 0; i < columns.size(); ++i)\n     {\n-        /// possibly renamed\n-        auto column_name_in_part = columns[i];\n-\n-        if (alter_conversions.isColumnRenamed(column_name_in_part))\n-            column_name_in_part = alter_conversions.getColumnOldName(column_name_in_part);\n-\n-        /// column has files and hence does not require evaluation\n-        if (part->hasColumnFiles(column_name_in_part, *storage_columns.getPhysical(columns[i]).type))\n-        {\n-            all_column_files_missing = false;\n-            continue;\n-        }\n-\n-        const auto column_default = storage_columns.getDefault(columns[i]);\n-        if (!column_default)\n-            continue;\n+        /// We are going to fetch only physical columns\n+        if (!storage_columns.hasPhysical(columns[i]))\n+            throw Exception(\"There is no physical column \" + columns[i] + \" in table.\", ErrorCodes::NO_SUCH_COLUMN_IN_TABLE);\n \n-        /// collect identifiers required for evaluation\n-        IdentifierNameSet identifiers;\n-        column_default->expression->collectIdentifierNames(identifiers);\n-\n-        for (const auto & identifier : identifiers)\n-        {\n-            if (storage_columns.hasPhysical(identifier))\n-            {\n-                /// ensure each column is added only once\n-                if (required_columns.count(identifier) == 0)\n-                {\n-                    columns.emplace_back(identifier);\n-                    required_columns.emplace(identifier);\n-                    injected_columns.emplace(identifier);\n-                }\n-            }\n-        }\n+        have_at_least_one_physical_column |= injectRequiredColumnsRecursively(\n+            columns[i], storage_columns, alter_conversions,\n+            part, columns, required_columns, injected_columns);\n     }\n \n     /** Add a column of the minimum size.\n         * Used in case when no column is needed or files are missing, but at least you need to know number of rows.\n         * Adds to the columns.\n         */\n-    if (all_column_files_missing)\n+    if (!have_at_least_one_physical_column)\n     {\n         const auto minimum_size_column_name = part->getColumnNameWithMinumumCompressedSize(metadata_snapshot);\n         columns.push_back(minimum_size_column_name);\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01084_defaults_on_aliases.reference b/tests/queries/0_stateless/01084_defaults_on_aliases.reference\nindex 9b39b07db94f..6c75649efd7a 100644\n--- a/tests/queries/0_stateless/01084_defaults_on_aliases.reference\n+++ b/tests/queries/0_stateless/01084_defaults_on_aliases.reference\n@@ -1,5 +1,6 @@\n 1\t1\n 1\t1\t1\n+1\n 2\t2\t4\n 2\t2\t2\t4\n 3\t3\t9\ndiff --git a/tests/queries/0_stateless/01084_defaults_on_aliases.sql b/tests/queries/0_stateless/01084_defaults_on_aliases.sql\nindex 2e4be37cc733..2f9d8227338f 100644\n--- a/tests/queries/0_stateless/01084_defaults_on_aliases.sql\n+++ b/tests/queries/0_stateless/01084_defaults_on_aliases.sql\n@@ -2,12 +2,16 @@ DROP TABLE IF EXISTS table_with_defaults_on_aliases;\n \n CREATE TABLE table_with_defaults_on_aliases (col1 UInt32, col2 ALIAS col1, col3 DEFAULT col2) Engine = MergeTree() ORDER BY tuple();\n \n+SYSTEM STOP MERGES table_with_defaults_on_aliases;\n+\n INSERT INTO table_with_defaults_on_aliases (col1) VALUES (1);\n \n SELECT * FROM table_with_defaults_on_aliases WHERE col1 = 1;\n \n SELECT col1, col2, col3 FROM table_with_defaults_on_aliases WHERE col1 = 1;\n \n+SELECT col3 FROM table_with_defaults_on_aliases; -- important to check without WHERE\n+\n ALTER TABLE table_with_defaults_on_aliases ADD COLUMN col4 UInt64 DEFAULT col2 * col3;\n \n INSERT INTO table_with_defaults_on_aliases (col1) VALUES (2);\n@@ -24,7 +28,6 @@ SELECT * FROM table_with_defaults_on_aliases WHERE col1 = 3;\n \n SELECT col1, col2, col3, col4, col5 FROM table_with_defaults_on_aliases WHERE col1 = 3;\n \n-\n ALTER TABLE table_with_defaults_on_aliases ADD COLUMN col6 UInt64 MATERIALIZED col2 * col4;\n \n DROP TABLE IF EXISTS table_with_defaults_on_aliases;\ndiff --git a/tests/queries/0_stateless/01497_alias_on_default_array.reference b/tests/queries/0_stateless/01497_alias_on_default_array.reference\nnew file mode 100644\nindex 000000000000..8a4406e57f3b\n--- /dev/null\n+++ b/tests/queries/0_stateless/01497_alias_on_default_array.reference\n@@ -0,0 +1,6 @@\n+a1\tb1\n+a2\tb2\n+a3\tb3\n+c1\n+c2\n+c3\ndiff --git a/tests/queries/0_stateless/01497_alias_on_default_array.sql b/tests/queries/0_stateless/01497_alias_on_default_array.sql\nnew file mode 100644\nindex 000000000000..c0c26b05eb8a\n--- /dev/null\n+++ b/tests/queries/0_stateless/01497_alias_on_default_array.sql\n@@ -0,0 +1,21 @@\n+DROP TABLE IF EXISTS test_new_col;\n+\n+CREATE TABLE test_new_col\n+(\n+  `_csv` String,\n+  `csv_as_array` Array(String) ALIAS splitByChar(';',_csv),\n+  `csv_col1` String DEFAULT csv_as_array[1],\n+  `csv_col2` String DEFAULT csv_as_array[2]\n+)\n+ENGINE = MergeTree\n+ORDER BY tuple();\n+\n+INSERT INTO test_new_col (_csv) VALUES ('a1;b1;c1;d1'), ('a2;b2;c2;d2'), ('a3;b3;c3;d3');\n+\n+SELECT csv_col1, csv_col2 FROM test_new_col ORDER BY csv_col1;\n+\n+ALTER TABLE test_new_col ADD COLUMN `csv_col3` String DEFAULT csv_as_array[3];\n+\n+SELECT csv_col3 FROM test_new_col ORDER BY csv_col3;\n+\n+DROP TABLE IF EXISTS test_new_col;\n",
  "problem_statement": "'Missing columns' when column DEFAULT value refers to ALIAS columns\n```sql\r\nCREATE TABLE test_new_col\r\n (\r\n     `_csv` String,\r\n     `csv_as_array` Array(String) ALIAS splitByChar(';',_csv),\r\n     `csv_col1` String DEFAULT csv_as_array[1],\r\n     `csv_col2` String DEFAULT csv_as_array[2]\r\n)\r\nENGINE = MergeTree\r\nORDER BY tuple();\r\n\r\nINSERT INTO test_new_col (_csv) values\r\n    ('a1;b1;c1;d1'), \r\n    ('a2;b2;c2;d2'), \r\n    ('a3;b3;c3;d3');\r\n\r\nSELECT csv_col1, csv_col2 FROM test_new_col;\r\n\r\n\u250c\u2500csv_col1\u2500\u252c\u2500csv_col2\u2500\u2510\r\n\u2502 a1       \u2502 b1       \u2502\r\n\u2502 a2       \u2502 b2       \u2502\r\n\u2502 a3       \u2502 b3       \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\nALTER TABLE test_new_col ADD COLUMN `csv_col3` String DEFAULT csv_as_array[3];\r\n\r\nSELECT csv_col3 FROM test_new_col\r\n\r\n\u2192 Progress: 0.00 rows, 0.00 B (0.00 rows/s., 0.00 B/s.) \r\nReceived exception from server (version 20.3.17):\r\nCode: 47. DB::Exception: Received from localhost:9000. DB::Exception: Missing columns: '_csv' while processing query: 'splitByChar(';', _csv) AS csv_as_array, CAST(csv_as_array[3], 'String') AS csv_col3', required columns: '_csv', source columns: 'csv_col1': (while reading from part /var/lib/clickhouse/data/default/test_new_col/all_1_1_0/): While executing MergeTreeThread. Stack trace:\r\n\r\n0. Poco::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x1059b460 in /usr/bin/clickhouse\r\n1. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x8f9972d in /usr/bin/clickhouse\r\n2. ? @ 0xd536aa8 in /usr/bin/clickhouse\r\n3. DB::SyntaxAnalyzer::analyze(std::__1::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::__1::shared_ptr<DB::IStorage>) const @ 0xd5316c3 in /usr/bin/clickhouse\r\n4. ? @ 0xd5acb8b in /usr/bin/clickhouse\r\n5. DB::evaluateMissingDefaults(DB::Block&, DB::NamesAndTypesList const&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, DB::ColumnDefault, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, DB::ColumnDefault> > > const&, DB::Context const&, bool) @ 0xd5ad69d in /usr/bin/clickhouse\r\n6. DB::IMergeTreeReader::evaluateMissingDefaults(DB::Block, std::__1::vector<COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn> > >&) @ 0xda7e62e in /usr/bin/clickhouse\r\n7. DB::MergeTreeRangeReader::read(unsigned long, std::__1::deque<DB::MarkRange, std::__1::allocator<DB::MarkRange> >&) @ 0xdaaf969 in /usr/bin/clickhouse\r\n8. DB::MergeTreeBaseSelectProcessor::readFromPartImpl() @ 0xdaa6e8d in /usr/bin/clickhouse\r\n9. DB::MergeTreeBaseSelectProcessor::generate() @ 0xdaa79c7 in /usr/bin/clickhouse\r\n10. DB::ISource::work() @ 0xdbea94b in /usr/bin/clickhouse\r\n11. DB::SourceWithProgress::work() @ 0xdf43827 in /usr/bin/clickhouse\r\n12. ? @ 0xdc25a21 in /usr/bin/clickhouse\r\n13. DB::PipelineExecutor::executeSingleThread(unsigned long, unsigned long) @ 0xdc29bad in /usr/bin/clickhouse\r\n14. DB::PipelineExecutor::executeImpl(unsigned long) @ 0xdc2bc58 in /usr/bin/clickhouse\r\n15. DB::PipelineExecutor::execute(unsigned long) @ 0xdc2be25 in /usr/bin/clickhouse\r\n16. ? @ 0x9072357 in /usr/bin/clickhouse\r\n17. ThreadPoolImpl<ThreadFromGlobalPool>::worker(std::__1::__list_iterator<ThreadFromGlobalPool, void*>) @ 0x8fbde77 in /usr/bin/clickhouse\r\n18. ThreadFromGlobalPool::ThreadFromGlobalPool<void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()>(void&&, void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()&&...)::'lambda'()::operator()() const @ 0x8fbe4f8 in /usr/bin/clickhouse\r\n19. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x8fbd387 in /usr/bin/clickhouse\r\n20. ? @ 0x8fbb7d3 in /usr/bin/clickhouse\r\n21. start_thread @ 0x76db in /lib/x86_64-linux-gnu/libpthread-2.27.so\r\n22. clone @ 0x121a3f in /lib/x86_64-linux-gnu/libc-2.27.so\r\n\r\n\r\n0 rows in set. Elapsed: 0.106 sec. \r\n```\r\n\r\nBut during merges, the default is calculated properly, and after the column is materialized it works properly:\r\n```sql\r\nOPTIMIZE TABLE test_new_col FINAL;\r\nSELECT csv_col3 FROM test_new_col\r\n\r\n\u250c\u2500csv_col3\u2500\u2510\r\n\u2502 c1       \u2502\r\n\u2502 c2       \u2502\r\n\u2502 c3       \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\n\r\nBut it doesn't work at all when one alias column refers to another:\r\n```sql\r\nALTER TABLE test_new_col ADD COLUMN  `csv_col4` String ALIAS csv_as_array[4];\r\nSELECT csv_col4 FROM test_new_col;\r\n```\r\n\r\n/cc @alesapin \n",
  "hints_text": "All versions affected.",
  "created_at": "2020-09-15T11:27:32Z",
  "modified_files": [
    "src/Storages/MergeTree/MergeTreeBlockReadUtils.cpp"
  ],
  "modified_test_files": [
    "tests/queries/0_stateless/01084_defaults_on_aliases.reference",
    "tests/queries/0_stateless/01084_defaults_on_aliases.sql",
    "b/tests/queries/0_stateless/01497_alias_on_default_array.reference",
    "b/tests/queries/0_stateless/01497_alias_on_default_array.sql"
  ]
}