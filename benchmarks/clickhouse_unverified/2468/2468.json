{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 2468,
  "instance_id": "ClickHouse__ClickHouse-2468",
  "issue_numbers": [
    "2342"
  ],
  "base_commit": "4d12a823da3f0773c661717869613bf981628c6d",
  "patch": "diff --git a/dbms/src/Storages/MergeTree/KeyCondition.cpp b/dbms/src/Storages/MergeTree/KeyCondition.cpp\nindex bc618f8d6550..1a8423e7f1d8 100644\n--- a/dbms/src/Storages/MergeTree/KeyCondition.cpp\n+++ b/dbms/src/Storages/MergeTree/KeyCondition.cpp\n@@ -921,7 +921,7 @@ bool KeyCondition::mayBeTrueInRange(\n     return forAnyParallelogram(used_key_size, left_key, right_key, true, right_bounded, key_ranges, 0,\n         [&] (const std::vector<Range> & key_ranges)\n     {\n-        auto res = mayBeTrueInRangeImpl(key_ranges, data_types);\n+        auto res = mayBeTrueInParallelogram(key_ranges, data_types);\n \n /*      std::cerr << \"Parallelogram: \";\n         for (size_t i = 0, size = key_ranges.size(); i != size; ++i)\n@@ -969,7 +969,7 @@ std::optional<Range> KeyCondition::applyMonotonicFunctionsChainToRange(\n     return key_range;\n }\n \n-bool KeyCondition::mayBeTrueInRangeImpl(const std::vector<Range> & key_ranges, const DataTypes & data_types) const\n+bool KeyCondition::mayBeTrueInParallelogram(const std::vector<Range> & parallelogram, const DataTypes & data_types) const\n {\n     std::vector<BoolMask> rpn_stack;\n     for (size_t i = 0; i < rpn.size(); ++i)\n@@ -982,7 +982,7 @@ bool KeyCondition::mayBeTrueInRangeImpl(const std::vector<Range> & key_ranges, c\n         else if (element.function == RPNElement::FUNCTION_IN_RANGE\n             || element.function == RPNElement::FUNCTION_NOT_IN_RANGE)\n         {\n-            const Range * key_range = &key_ranges[element.key_column];\n+            const Range * key_range = &parallelogram[element.key_column];\n \n             /// The case when the column is wrapped in a chain of possibly monotonic functions.\n             Range transformed_range;\n@@ -1019,7 +1019,7 @@ bool KeyCondition::mayBeTrueInRangeImpl(const std::vector<Range> & key_ranges, c\n             PreparedSets::const_iterator it = prepared_sets.find(args[1]->range);\n             if (in_func && it != prepared_sets.end())\n             {\n-                rpn_stack.emplace_back(element.set_index->mayBeTrueInRange(key_ranges, data_types));\n+                rpn_stack.emplace_back(element.set_index->mayBeTrueInRange(parallelogram, data_types));\n                 if (element.function == RPNElement::FUNCTION_NOT_IN_SET)\n                     rpn_stack.back() = !rpn_stack.back();\n             }\ndiff --git a/dbms/src/Storages/MergeTree/KeyCondition.h b/dbms/src/Storages/MergeTree/KeyCondition.h\nindex c7d55b0a575c..f9f44ecc2bd8 100644\n--- a/dbms/src/Storages/MergeTree/KeyCondition.h\n+++ b/dbms/src/Storages/MergeTree/KeyCondition.h\n@@ -240,6 +240,9 @@ class KeyCondition\n     /// data_types - the types of the key columns.\n     bool mayBeTrueInRange(size_t used_key_size, const Field * left_key, const Field * right_key, const DataTypes & data_types) const;\n \n+    /// Whether the condition is feasible in the direct product of single column ranges specified by `parallelogram`.\n+    bool mayBeTrueInParallelogram(const std::vector<Range> & parallelogram, const DataTypes & data_types) const;\n+\n     /// Is the condition valid in a semi-infinite (not limited to the right) key range.\n     /// left_key must contain all the fields in the sort_descr in the appropriate order.\n     bool mayBeTrueAfter(size_t used_key_size, const Field * left_key, const DataTypes & data_types) const;\n@@ -325,8 +328,6 @@ class KeyCondition\n         const DataTypes & data_types,\n         bool right_bounded) const;\n \n-    bool mayBeTrueInRangeImpl(const std::vector<Range> & key_ranges, const DataTypes & data_types) const;\n-\n     void traverseAST(const ASTPtr & node, const Context & context, Block & block_with_constants);\n     bool atomFromAST(const ASTPtr & node, const Context & context, Block & block_with_constants, RPNElement & out);\n     bool operatorFromAST(const ASTFunction * func, RPNElement & out);\ndiff --git a/dbms/src/Storages/MergeTree/MergeTreeDataPart.cpp b/dbms/src/Storages/MergeTree/MergeTreeDataPart.cpp\nindex 6bac6047dacd..131fe50f0a7b 100644\n--- a/dbms/src/Storages/MergeTree/MergeTreeDataPart.cpp\n+++ b/dbms/src/Storages/MergeTree/MergeTreeDataPart.cpp\n@@ -48,15 +48,19 @@ static ReadBufferFromFile openForReading(const String & path)\n void MergeTreeDataPart::MinMaxIndex::load(const MergeTreeData & storage, const String & part_path)\n {\n     size_t minmax_idx_size = storage.minmax_idx_column_types.size();\n-    min_values.resize(minmax_idx_size);\n-    max_values.resize(minmax_idx_size);\n+    parallelogram.reserve(minmax_idx_size);\n     for (size_t i = 0; i < minmax_idx_size; ++i)\n     {\n         String file_name = part_path + \"minmax_\" + escapeForFileName(storage.minmax_idx_columns[i]) + \".idx\";\n         ReadBufferFromFile file = openForReading(file_name);\n         const DataTypePtr & type = storage.minmax_idx_column_types[i];\n-        type->deserializeBinary(min_values[i], file);\n-        type->deserializeBinary(max_values[i], file);\n+\n+        Field min_val;\n+        type->deserializeBinary(min_val, file);\n+        Field max_val;\n+        type->deserializeBinary(max_val, file);\n+\n+        parallelogram.emplace_back(min_val, true, max_val, true);\n     }\n     initialized = true;\n }\n@@ -74,8 +78,8 @@ void MergeTreeDataPart::MinMaxIndex::store(const MergeTreeData & storage, const\n \n         WriteBufferFromFile out(part_path + file_name);\n         HashingWriteBuffer out_hashing(out);\n-        type->serializeBinary(min_values[i], out_hashing);\n-        type->serializeBinary(max_values[i], out_hashing);\n+        type->serializeBinary(parallelogram[i].left, out_hashing);\n+        type->serializeBinary(parallelogram[i].right, out_hashing);\n         out_hashing.next();\n         checksums.files[file_name].file_size = out_hashing.count();\n         checksums.files[file_name].file_hash = out_hashing.getHash();\n@@ -85,10 +89,7 @@ void MergeTreeDataPart::MinMaxIndex::store(const MergeTreeData & storage, const\n void MergeTreeDataPart::MinMaxIndex::update(const Block & block, const Names & column_names)\n {\n     if (!initialized)\n-    {\n-        min_values.resize(column_names.size());\n-        max_values.resize(column_names.size());\n-    }\n+        parallelogram.reserve(column_names.size());\n \n     for (size_t i = 0; i < column_names.size(); ++i)\n     {\n@@ -98,14 +99,11 @@ void MergeTreeDataPart::MinMaxIndex::update(const Block & block, const Names & c\n         column.column->getExtremes(min_value, max_value);\n \n         if (!initialized)\n-        {\n-            min_values[i] = Field(min_value);\n-            max_values[i] = Field(max_value);\n-        }\n+            parallelogram.emplace_back(min_value, true, max_value, true);\n         else\n         {\n-            min_values[i] = std::min(min_values[i], min_value);\n-            max_values[i] = std::max(max_values[i], max_value);\n+            parallelogram[i].left = std::min(parallelogram[i].left, min_value);\n+            parallelogram[i].right = std::max(parallelogram[i].right, max_value);\n         }\n     }\n \n@@ -119,16 +117,15 @@ void MergeTreeDataPart::MinMaxIndex::merge(const MinMaxIndex & other)\n \n     if (!initialized)\n     {\n-        min_values.assign(other.min_values);\n-        max_values.assign(other.max_values);\n+        parallelogram = other.parallelogram;\n         initialized = true;\n     }\n     else\n     {\n-        for (size_t i = 0; i < min_values.size(); ++i)\n+        for (size_t i = 0; i < parallelogram.size(); ++i)\n         {\n-            min_values[i] = std::min(min_values[i], other.min_values[i]);\n-            max_values[i] = std::max(max_values[i], other.max_values[i]);\n+            parallelogram[i].left = std::min(parallelogram[i].left, other.parallelogram[i].left);\n+            parallelogram[i].right = std::max(parallelogram[i].right, other.parallelogram[i].right);\n         }\n     }\n }\n@@ -255,7 +252,7 @@ String MergeTreeDataPart::getNewName(const MergeTreePartInfo & new_part_info) co\n DayNum MergeTreeDataPart::getMinDate() const\n {\n     if (storage.minmax_idx_date_column_pos != -1 && minmax_idx.initialized)\n-        return DayNum(minmax_idx.min_values[storage.minmax_idx_date_column_pos].get<UInt64>());\n+        return DayNum(minmax_idx.parallelogram[storage.minmax_idx_date_column_pos].left.get<UInt64>());\n     else\n         return DayNum();\n }\n@@ -264,7 +261,7 @@ DayNum MergeTreeDataPart::getMinDate() const\n DayNum MergeTreeDataPart::getMaxDate() const\n {\n     if (storage.minmax_idx_date_column_pos != -1 && minmax_idx.initialized)\n-        return DayNum(minmax_idx.max_values[storage.minmax_idx_date_column_pos].get<UInt64>());\n+        return DayNum(minmax_idx.parallelogram[storage.minmax_idx_date_column_pos].right.get<UInt64>());\n     else\n         return DayNum();\n }\ndiff --git a/dbms/src/Storages/MergeTree/MergeTreeDataPart.h b/dbms/src/Storages/MergeTree/MergeTreeDataPart.h\nindex c3d8b4c2478e..03b6756bd81f 100644\n--- a/dbms/src/Storages/MergeTree/MergeTreeDataPart.h\n+++ b/dbms/src/Storages/MergeTree/MergeTreeDataPart.h\n@@ -2,14 +2,17 @@\n \n #include <Core/Row.h>\n #include <Core/Block.h>\n+#include <Core/Types.h>\n #include <Core/NamesAndTypes.h>\n #include <Storages/MergeTree/MergeTreePartInfo.h>\n #include <Storages/MergeTree/MergeTreePartition.h>\n #include <Storages/MergeTree/MergeTreeDataPartChecksum.h>\n+#include <Storages/MergeTree/KeyCondition.h>\n #include <Columns/IColumn.h>\n+\n+#include <Poco/Path.h>\n+\n #include <shared_mutex>\n-#include \"../../../../contrib/poco/Foundation/include/Poco/Path.h\"\n-#include \"../../Core/Types.h\"\n \n \n namespace DB\n@@ -176,8 +179,8 @@ struct MergeTreeDataPart\n     /// can be built using any set of columns.\n     struct MinMaxIndex\n     {\n-        Row min_values;\n-        Row max_values;\n+        /// A direct product of ranges for each key column. See Storages/MergeTree/KeyCondition.cpp for details.\n+        std::vector<Range> parallelogram;\n         bool initialized = false;\n \n     public:\n@@ -185,8 +188,7 @@ struct MergeTreeDataPart\n \n         /// For month-based partitioning.\n         MinMaxIndex(DayNum min_date, DayNum max_date)\n-            : min_values(1, static_cast<UInt64>(min_date))\n-            , max_values(1, static_cast<UInt64>(max_date))\n+            : parallelogram(1, Range(static_cast<UInt64>(min_date), true, static_cast<UInt64>(max_date), true))\n             , initialized(true)\n         {\n         }\ndiff --git a/dbms/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp b/dbms/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp\nindex ec0c2cd66744..9cdb52a621b6 100644\n--- a/dbms/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp\n+++ b/dbms/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp\n@@ -251,10 +251,8 @@ BlockInputStreams MergeTreeDataSelectExecutor::read(\n             if (part->isEmpty())\n                 continue;\n \n-            if (minmax_idx_condition && !minmax_idx_condition->mayBeTrueInRange(\n-                    data.minmax_idx_columns.size(),\n-                    &part->minmax_idx.min_values[0], &part->minmax_idx.max_values[0],\n-                    data.minmax_idx_column_types))\n+            if (minmax_idx_condition && !minmax_idx_condition->mayBeTrueInParallelogram(\n+                    part->minmax_idx.parallelogram, data.minmax_idx_column_types))\n                 continue;\n \n             if (max_block_number_to_read && part->info.max_block > max_block_number_to_read)\ndiff --git a/dbms/src/Storages/MergeTree/MergeTreeDataWriter.cpp b/dbms/src/Storages/MergeTree/MergeTreeDataWriter.cpp\nindex 4565a4c67793..2a0919f45fec 100644\n--- a/dbms/src/Storages/MergeTree/MergeTreeDataWriter.cpp\n+++ b/dbms/src/Storages/MergeTree/MergeTreeDataWriter.cpp\n@@ -140,8 +140,8 @@ MergeTreeData::MutableDataPartPtr MergeTreeDataWriter::writeTempPart(BlockWithPa\n     String part_name;\n     if (data.format_version < MERGE_TREE_DATA_MIN_FORMAT_VERSION_WITH_CUSTOM_PARTITIONING)\n     {\n-        DayNum min_date(minmax_idx.min_values[data.minmax_idx_date_column_pos].get<UInt64>());\n-        DayNum max_date(minmax_idx.max_values[data.minmax_idx_date_column_pos].get<UInt64>());\n+        DayNum min_date(minmax_idx.parallelogram[data.minmax_idx_date_column_pos].left.get<UInt64>());\n+        DayNum max_date(minmax_idx.parallelogram[data.minmax_idx_date_column_pos].right.get<UInt64>());\n \n         const auto & date_lut = DateLUT::instance();\n \n",
  "test_patch": "diff --git a/dbms/tests/queries/0_stateless/00636_partition_key_parts_pruning.reference b/dbms/tests/queries/0_stateless/00636_partition_key_parts_pruning.reference\nnew file mode 100644\nindex 000000000000..72bb01e4a626\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00636_partition_key_parts_pruning.reference\n@@ -0,0 +1,12 @@\n+*** Single column partition key ***\n+<rows_read>4</rows_read>\n+<rows_read>3</rows_read>\n+<rows_read>1</rows_read>\n+*** Composite partition key ***\n+<rows_read>0</rows_read>\n+<rows_read>6</rows_read>\n+<rows_read>0</rows_read>\n+<rows_read>3</rows_read>\n+<rows_read>0</rows_read>\n+<rows_read>6</rows_read>\n+<rows_read>3</rows_read>\ndiff --git a/dbms/tests/queries/0_stateless/00636_partition_key_parts_pruning.sh b/dbms/tests/queries/0_stateless/00636_partition_key_parts_pruning.sh\nnew file mode 100755\nindex 000000000000..cbd1e456688e\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/00636_partition_key_parts_pruning.sh\n@@ -0,0 +1,43 @@\n+#!/usr/bin/env bash\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+. $CURDIR/../shell_config.sh\n+\n+${CLICKHOUSE_CLIENT} --query=\"SELECT '*** Single column partition key ***'\"\n+\n+${CLICKHOUSE_CLIENT} --query=\"DROP TABLE IF EXISTS test.single_col_partition_key\"\n+${CLICKHOUSE_CLIENT} --query=\"CREATE TABLE test.single_col_partition_key(x UInt32) ENGINE MergeTree ORDER BY x PARTITION BY intDiv(x, 10)\"\n+\n+${CLICKHOUSE_CLIENT} --query=\"INSERT INTO test.single_col_partition_key VALUES (1), (2), (3), (4), (11), (12), (20)\"\n+\n+${CLICKHOUSE_CLIENT} --query=\"SELECT count() FROM test.single_col_partition_key WHERE x < 3 FORMAT XML\" | grep -F rows_read | sed 's/^[ \\t]*//g'\n+${CLICKHOUSE_CLIENT} --query=\"SELECT count() FROM test.single_col_partition_key WHERE x >= 11 FORMAT XML\" | grep -F rows_read | sed 's/^[ \\t]*//g'\n+${CLICKHOUSE_CLIENT} --query=\"SELECT count() FROM test.single_col_partition_key WHERE x = 20 FORMAT XML\" | grep -F rows_read | sed 's/^[ \\t]*//g'\n+\n+${CLICKHOUSE_CLIENT} --query=\"DROP TABLE test.single_col_partition_key\"\n+\n+${CLICKHOUSE_CLIENT} --query=\"SELECT '*** Composite partition key ***'\"\n+\n+${CLICKHOUSE_CLIENT} --query=\"DROP TABLE IF EXISTS test.composite_partition_key\"\n+${CLICKHOUSE_CLIENT} --query=\"CREATE TABLE test.composite_partition_key(a UInt32, b UInt32, c UInt32) ENGINE MergeTree ORDER BY c PARTITION BY (intDiv(a, 100), intDiv(b, 10), c)\"\n+\n+${CLICKHOUSE_CLIENT} --query=\"INSERT INTO test.composite_partition_key VALUES \\\n+    (1, 1, 1), (2, 2, 1), (3, 3, 1)\"\n+${CLICKHOUSE_CLIENT} --query=\"INSERT INTO test.composite_partition_key VALUES \\\n+    (100, 10, 2), (101, 11, 2), (102, 12, 2)\"\n+${CLICKHOUSE_CLIENT} --query=\"INSERT INTO test.composite_partition_key VALUES \\\n+    (200, 10, 2), (201, 11, 2), (202, 12, 2)\"\n+${CLICKHOUSE_CLIENT} --query=\"INSERT INTO test.composite_partition_key VALUES \\\n+    (301, 20, 3), (302, 21, 3), (303, 22, 3)\"\n+\n+${CLICKHOUSE_CLIENT} --query=\"SELECT count() FROM test.composite_partition_key WHERE a > 400 FORMAT XML\" | grep -F rows_read | sed 's/^[ \\t]*//g'\n+${CLICKHOUSE_CLIENT} --query=\"SELECT count() FROM test.composite_partition_key WHERE b = 11 FORMAT XML\" | grep -F rows_read | sed 's/^[ \\t]*//g'\n+${CLICKHOUSE_CLIENT} --query=\"SELECT count() FROM test.composite_partition_key WHERE c = 4 FORMAT XML\" | grep -F rows_read | sed 's/^[ \\t]*//g'\n+\n+${CLICKHOUSE_CLIENT} --query=\"SELECT count() FROM test.composite_partition_key WHERE a < 200 AND c = 2 FORMAT XML\" | grep -F rows_read | sed 's/^[ \\t]*//g'\n+${CLICKHOUSE_CLIENT} --query=\"SELECT count() FROM test.composite_partition_key WHERE a = 301 AND b < 20 FORMAT XML\" | grep -F rows_read | sed 's/^[ \\t]*//g'\n+${CLICKHOUSE_CLIENT} --query=\"SELECT count() FROM test.composite_partition_key WHERE b >= 12 AND c = 2 FORMAT XML\" | grep -F rows_read | sed 's/^[ \\t]*//g'\n+\n+${CLICKHOUSE_CLIENT} --query=\"SELECT count() FROM test.composite_partition_key WHERE a = 301 AND b = 21 AND c = 3 FORMAT XML\" | grep -F rows_read | sed 's/^[ \\t]*//g'\n+\n+${CLICKHOUSE_CLIENT} --query=\"DROP TABLE test.composite_partition_key\"\n",
  "problem_statement": "custom partition: partition elimination issue? 1.1.54380.\nCH reads all partitions in some cases.\r\n\r\nissue:\r\n\r\nCREATE TABLE test.testy(d Date, n Int64, k Int64, arr Array(String)) \r\nENGINE = MergeTree Partition by **(n,toStartOfMonth(d))** Order by (k);\r\n```\r\ninsert into test.testy select toDate('2018-05-01') as d, 33, 0, []  from numbers(16);\r\ninsert into test.testy select toDate('2018-05-02') as d, 33, 0, []  from numbers(933);\r\ninsert into test.testy select toDate('2018-05-03') as d, 33, 0, []  from numbers(20000000);\r\n```\r\nSELECT count() FROM test.testy PREWHERE (n = -1) AND (d >= '2018-05-01');\r\n\r\n0 rows in set. **Elapsed: 0.014 sec**. Processed 14.68 million rows, 146.81 MB (1.05 billion rows/s., 10.55 GB/s.)\r\n\r\nKey condition: unknown, unknown, and\r\nMinMax index condition: (column 1 in [-1, -1]), (column 0 in [17652, +inf)), and\r\nSelected 1 parts by date, **1 parts by key**, 2433 marks to read from 1 ranges\r\nReading approx. **19931136** rows\r\n\r\n----\r\nIf I change the order of inserts, then no issue?\r\n```\r\ndrop table test.testy;\r\n\r\nCREATE TABLE test.testy(d Date, n Int64, k Int64, arr Array(String)) ENGINE = MergeTree Partition by (n,toStartOfMonth(d)) Order by (k);\r\n\r\ninsert into test.testy select toDate('2018-05-03') as d, 33, 0, []  from numbers(20000000);\r\ninsert into test.testy select toDate('2018-05-01') as d, 33, 0, []  from numbers(16);\r\ninsert into test.testy select toDate('2018-05-02') as d, 33, 0, []  from numbers(933);\r\n```\r\n\r\nSELECT count() FROM test.testy PREWHERE (n = -1) AND (d >= '2018-05-01');\r\n0 rows in set. Elapsed: 0.002 sec.\r\n\r\nKey condition: unknown, unknown, and\r\nMinMax index condition: (column 1 in [-1, -1]), (column 0 in [17652, +inf)), and\r\nSelected 0 parts by date, 0 parts by key, 0 marks to read from 0 ranges\r\n\r\n\n",
  "hints_text": "drop table test.testy;\r\n\r\nCREATE TABLE test.testy(d Int64, n Int64) ENGINE = MergeTree Partition by (ceil(d/2), n) Order by tuple();\r\n\r\ninsert into test.testy select 1, 33 n  from numbers(1);\r\ninsert into test.testy select 2, 33 n  from numbers(10000000);\r\ninsert into test.testy select 1, 34 n  from numbers(1);  \r\n\r\nSELECT count() FROM test.testy PREWHERE (n = 34);\r\n1 rows in set. Elapsed: 0.007 sec. **Processed 10.00 million rows**, 80.00 MB (1.46 billion rows/s., 11.64 GB/s.)\r\n\r\nSELECT count() FROM test.testy PREWHERE (n = 34 and d>=1);\r\n1 rows in set. Elapsed: 0.014 sec. **Processed 10.00 million rows**, 160.00 MB (725.83 million rows/s., 11.61 GB/s.)\r\n\r\nSELECT count() FROM test.testy PREWHERE (n = 34 and d=1);\r\n1 rows in set. Elapsed: 0.014 sec. **Processed 10.00 million rows**, 160.00 MB (708.99 million rows/s., 11.34 GB/s.)\r\n\r\n\r\nselect partition, rows from system.parts where active = 1 and table ='testy'\r\n\r\n(1, 34) | 1\r\n-- | --\r\n(1, 33) | 10000001\r\n\r\n\nAnother order in partition by\r\n\r\ndrop table test.testy;\r\n\r\nCREATE TABLE test.testy(d Int64, n Int64) ENGINE = MergeTree Partition by (n,ceil(d/2)) Order by tuple();\r\n\r\ninsert into test.testy select 1, 33 n  from numbers(1);\r\ninsert into test.testy select 2, 33 n  from numbers(10000000);\r\ninsert into test.testy select 1, 34 n  from numbers(1);\r\n\r\nSELECT count() FROM test.testy PREWHERE (n = 34);\r\n1 rows in set. Elapsed: 0.007 sec. Processed 10.00 million rows, 80.00 MB (1.41 billion rows/s., 11.27 GB/s.)\r\n\r\nSELECT count() FROM test.testy PREWHERE (n = 34 and d>=1);\r\n1 rows in set. Elapsed: 0.013 sec. Processed 10.00 million rows, 160.00 MB (798.77 million rows/s., 12.78 GB/s.)\r\n\r\nSELECT count() FROM test.testy PREWHERE (n = 34 and d=1);\r\n1 rows in set. Elapsed: 0.013 sec. Processed 10.00 million rows, 160.00 MB (796.54 million rows/s., 12.74 GB/s.)\r\n\r\n\r\nselect partition, rows from system.parts where active = 1 and table ='testy'\r\n\r\n(34, 1) | 1\r\n-- | --\r\n(33, 1) | 10000001\r\n\r\n\nChanged the order of inserts:\r\n\r\ndrop table test.testy;\r\n\r\nCREATE TABLE test.testy(d Int64, n Int64) ENGINE = MergeTree Partition by (ceil(d/2),n) Order by tuple();\r\n\r\ninsert into test.testy select 2, 33 n  from numbers(10000000);\r\ninsert into test.testy select 1, 33 n  from numbers(1);\r\ninsert into test.testy select 1, 34 n  from numbers(1);\r\n\r\nSELECT count() FROM test.testy WHERE (n = 34 );\r\n**1 rows in set. Elapsed: 0.002 sec.  <<<<--- Bingo!!!!**\r\n\r\nselect partition, rows from system.parts where active = 1 and table ='testy'\r\n\r\n(1, 34) | 1\r\n-- | --\r\n(1, 33) | 10000000\r\n(1, 33) | 1\r\n\r\n**optimize table test.testy;**\r\n\r\nselect partition, rows from system.parts where active = 1 and table ='testy'\r\n\r\n(1, 34) | 1\r\n-- | --\r\n(1, 33) | 10000001\r\n\r\nSELECT count() FROM test.testy WHERE (n = 34 );\r\n**1 rows in set. Elapsed: 0.007 sec. Processed 10.00 million rows, 80.00 MB (1.38 billion rows/s., 11.07 GB/s.)**",
  "created_at": "2018-06-05T11:05:04Z",
  "modified_files": [
    "dbms/src/Storages/MergeTree/KeyCondition.cpp",
    "dbms/src/Storages/MergeTree/KeyCondition.h",
    "dbms/src/Storages/MergeTree/MergeTreeDataPart.cpp",
    "dbms/src/Storages/MergeTree/MergeTreeDataPart.h",
    "dbms/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp",
    "dbms/src/Storages/MergeTree/MergeTreeDataWriter.cpp"
  ],
  "modified_test_files": [
    "b/dbms/tests/queries/0_stateless/00636_partition_key_parts_pruning.reference",
    "b/dbms/tests/queries/0_stateless/00636_partition_key_parts_pruning.sh"
  ]
}