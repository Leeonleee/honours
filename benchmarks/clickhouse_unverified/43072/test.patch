diff --git a/src/Common/tests/gtest_hash_table.cpp b/src/Common/tests/gtest_hash_table.cpp
index fd0b2495fdee..0221a682577b 100644
--- a/src/Common/tests/gtest_hash_table.cpp
+++ b/src/Common/tests/gtest_hash_table.cpp
@@ -15,6 +15,17 @@
 
 using namespace DB;
 
+namespace
+{
+std::vector<UInt64> getVectorWithNumbersUpToN(size_t n)
+{
+    std::vector<UInt64> res(n);
+    std::iota(res.begin(), res.end(), 0);
+    return res;
+}
+
+}
+
 
 /// To test dump functionality without using other hashes that can change
 template <typename T>
@@ -371,3 +382,48 @@ TEST(HashTable, Resize)
         ASSERT_EQ(actual, expected);
     }
 }
+
+
+using HashSetContent = std::vector<UInt64>;
+
+class TwoLevelHashSetFixture : public ::testing::TestWithParam<HashSetContent>
+{
+};
+
+
+TEST_P(TwoLevelHashSetFixture, WriteAsSingleLevel)
+{
+    using Key = UInt64;
+
+    {
+        const auto & hash_set_content = GetParam();
+
+        TwoLevelHashSet<Key, HashCRC32<Key>> two_level;
+        for (const auto & elem : hash_set_content)
+            two_level.insert(elem);
+
+        WriteBufferFromOwnString wb;
+        two_level.writeAsSingleLevel(wb);
+
+        ReadBufferFromString rb(wb.str());
+        HashSet<Key, HashCRC32<Key>> single_level;
+        single_level.read(rb);
+
+        EXPECT_EQ(single_level.size(), hash_set_content.size());
+        for (const auto & elem : hash_set_content)
+            EXPECT_NE(single_level.find(elem), nullptr);
+    }
+}
+
+
+INSTANTIATE_TEST_SUITE_P(
+    TwoLevelHashSetTests,
+    TwoLevelHashSetFixture,
+    ::testing::Values(
+        HashSetContent{},
+        getVectorWithNumbersUpToN(1),
+        getVectorWithNumbersUpToN(100),
+        getVectorWithNumbersUpToN(1000),
+        getVectorWithNumbersUpToN(10000),
+        getVectorWithNumbersUpToN(100000),
+        getVectorWithNumbersUpToN(1000000)));
diff --git a/tests/integration/test_backward_compatibility/test_aggregate_function_state.py b/tests/integration/test_backward_compatibility/test_aggregate_function_state.py
new file mode 100644
index 000000000000..1f6d405603a6
--- /dev/null
+++ b/tests/integration/test_backward_compatibility/test_aggregate_function_state.py
@@ -0,0 +1,228 @@
+import pytest
+
+from helpers.cluster import ClickHouseCluster
+
+cluster = ClickHouseCluster(__file__)
+node1 = cluster.add_instance(
+    "node1",
+    with_zookeeper=False,
+    image="yandex/clickhouse-server",
+    tag="19.16.9.37",
+    stay_alive=True,
+    with_installed_binary=True,
+)
+node2 = cluster.add_instance(
+    "node2",
+    with_zookeeper=False,
+    image="yandex/clickhouse-server",
+    tag="19.16.9.37",
+    stay_alive=True,
+    with_installed_binary=True,
+)
+node3 = cluster.add_instance("node3", with_zookeeper=False)
+node4 = cluster.add_instance("node4", with_zookeeper=False)
+
+
+@pytest.fixture(scope="module")
+def start_cluster():
+    try:
+        cluster.start()
+        yield cluster
+
+    finally:
+        cluster.shutdown()
+
+
+# We will test that serialization of internal state of "avg" function is compatible between different versions.
+# TODO Implement versioning of serialization format for aggregate function states.
+# NOTE This test is too ad-hoc.
+
+
+def test_backward_compatability_for_avg(start_cluster):
+    node1.query("create table tab (x UInt64) engine = Memory")
+    node2.query("create table tab (x UInt64) engine = Memory")
+    node3.query("create table tab (x UInt64) engine = Memory")
+    node4.query("create table tab (x UInt64) engine = Memory")
+
+    node1.query("INSERT INTO tab VALUES (1)")
+    node2.query("INSERT INTO tab VALUES (2)")
+    node3.query("INSERT INTO tab VALUES (3)")
+    node4.query("INSERT INTO tab VALUES (4)")
+
+    assert (
+        node1.query("SELECT avg(x) FROM remote('node{1..4}', default, tab)") == "2.5
"
+    )
+    assert (
+        node2.query("SELECT avg(x) FROM remote('node{1..4}', default, tab)") == "2.5
"
+    )
+    assert (
+        node3.query("SELECT avg(x) FROM remote('node{1..4}', default, tab)") == "2.5
"
+    )
+    assert (
+        node4.query("SELECT avg(x) FROM remote('node{1..4}', default, tab)") == "2.5
"
+    )
+
+    # Also check with persisted aggregate function state
+
+    node1.query("create table state (x AggregateFunction(avg, UInt64)) engine = Log")
+    node1.query(
+        "INSERT INTO state SELECT avgState(arrayJoin(CAST([1, 2, 3, 4] AS Array(UInt64))))"
+    )
+
+    assert node1.query("SELECT avgMerge(x) FROM state") == "2.5
"
+
+    node1.restart_with_latest_version(fix_metadata=True)
+
+    assert node1.query("SELECT avgMerge(x) FROM state") == "2.5
"
+
+    node1.query("drop table tab")
+    node1.query("drop table state")
+    node2.query("drop table tab")
+    node3.query("drop table tab")
+    node4.query("drop table tab")
+
+
+@pytest.mark.parametrize("uniq_keys", [1000, 500000])
+def test_backward_compatability_for_uniq_exact(start_cluster, uniq_keys):
+    node1.query(f"CREATE TABLE tab_{uniq_keys} (x UInt64) Engine = Memory")
+    node2.query(f"CREATE TABLE tab_{uniq_keys} (x UInt64) Engine = Memory")
+    node3.query(f"CREATE TABLE tab_{uniq_keys} (x UInt64) Engine = Memory")
+    node4.query(f"CREATE TABLE tab_{uniq_keys} (x UInt64) Engine = Memory")
+
+    node1.query(
+        f"INSERT INTO tab_{uniq_keys} SELECT number FROM numbers_mt(0, {uniq_keys})"
+    )
+    node2.query(
+        f"INSERT INTO tab_{uniq_keys} SELECT number FROM numbers_mt(1, {uniq_keys})"
+    )
+    node3.query(
+        f"INSERT INTO tab_{uniq_keys} SELECT number FROM numbers_mt(2, {uniq_keys})"
+    )
+    node4.query(
+        f"INSERT INTO tab_{uniq_keys} SELECT number FROM numbers_mt(3, {uniq_keys})"
+    )
+
+    assert (
+        node1.query(
+            f"SELECT uniqExact(x) FROM remote('node{{1..4}}', default, tab_{uniq_keys})"
+        )
+        == f"{uniq_keys + 3}
"
+    )
+    assert (
+        node2.query(
+            f"SELECT uniqExact(x) FROM remote('node{{1..4}}', default, tab_{uniq_keys})"
+        )
+        == f"{uniq_keys + 3}
"
+    )
+    assert (
+        node3.query(
+            f"SELECT uniqExact(x) FROM remote('node{{1..4}}', default, tab_{uniq_keys})"
+        )
+        == f"{uniq_keys + 3}
"
+    )
+    assert (
+        node4.query(
+            f"SELECT uniqExact(x) FROM remote('node{{1..4}}', default, tab_{uniq_keys})"
+        )
+        == f"{uniq_keys + 3}
"
+    )
+
+    # Also check with persisted aggregate function state
+
+    node1.query(
+        f"CREATE TABLE state_{uniq_keys} (x AggregateFunction(uniqExact, UInt64)) Engine = Log"
+    )
+    node1.query(
+        f"INSERT INTO state_{uniq_keys} SELECT uniqExactState(number) FROM numbers_mt({uniq_keys})"
+    )
+
+    assert (
+        node1.query(f"SELECT uniqExactMerge(x) FROM state_{uniq_keys}")
+        == f"{uniq_keys}
"
+    )
+
+    node1.restart_with_latest_version()
+
+    assert (
+        node1.query(f"SELECT uniqExactMerge(x) FROM state_{uniq_keys}")
+        == f"{uniq_keys}
"
+    )
+
+    node1.query(f"DROP TABLE state_{uniq_keys}")
+    node1.query(f"DROP TABLE tab_{uniq_keys}")
+    node2.query(f"DROP TABLE tab_{uniq_keys}")
+    node3.query(f"DROP TABLE tab_{uniq_keys}")
+    node4.query(f"DROP TABLE tab_{uniq_keys}")
+
+
+@pytest.mark.parametrize("uniq_keys", [1000, 500000])
+def test_backward_compatability_for_uniq_exact_variadic(start_cluster, uniq_keys):
+    node1.query(f"CREATE TABLE tab_{uniq_keys} (x UInt64, y UInt64) Engine = Memory")
+    node2.query(f"CREATE TABLE tab_{uniq_keys} (x UInt64, y UInt64) Engine = Memory")
+    node3.query(f"CREATE TABLE tab_{uniq_keys} (x UInt64, y UInt64) Engine = Memory")
+    node4.query(f"CREATE TABLE tab_{uniq_keys} (x UInt64, y UInt64) Engine = Memory")
+
+    node1.query(
+        f"INSERT INTO tab_{uniq_keys} SELECT number, number/2 FROM numbers_mt(0, {uniq_keys})"
+    )
+    node2.query(
+        f"INSERT INTO tab_{uniq_keys} SELECT number, number/2 FROM numbers_mt(1, {uniq_keys})"
+    )
+    node3.query(
+        f"INSERT INTO tab_{uniq_keys} SELECT number, number/2 FROM numbers_mt(2, {uniq_keys})"
+    )
+    node4.query(
+        f"INSERT INTO tab_{uniq_keys} SELECT number, number/2 FROM numbers_mt(3, {uniq_keys})"
+    )
+
+    assert (
+        node1.query(
+            f"SELECT uniqExact(x, y) FROM remote('node{{1..4}}', default, tab_{uniq_keys})"
+        )
+        == f"{uniq_keys + 3}
"
+    )
+    assert (
+        node2.query(
+            f"SELECT uniqExact(x, y) FROM remote('node{{1..4}}', default, tab_{uniq_keys})"
+        )
+        == f"{uniq_keys + 3}
"
+    )
+    assert (
+        node3.query(
+            f"SELECT uniqExact(x, y) FROM remote('node{{1..4}}', default, tab_{uniq_keys})"
+        )
+        == f"{uniq_keys + 3}
"
+    )
+    assert (
+        node4.query(
+            f"SELECT uniqExact(x, y) FROM remote('node{{1..4}}', default, tab_{uniq_keys})"
+        )
+        == f"{uniq_keys + 3}
"
+    )
+
+    # Also check with persisted aggregate function state
+
+    node1.query(
+        f"CREATE TABLE state_{uniq_keys} (x AggregateFunction(uniqExact, UInt64, UInt64)) Engine = Log"
+    )
+    node1.query(
+        f"INSERT INTO state_{uniq_keys} SELECT uniqExactState(number, intDiv(number,2)) FROM numbers_mt({uniq_keys})"
+    )
+
+    assert (
+        node1.query(f"SELECT uniqExactMerge(x) FROM state_{uniq_keys}")
+        == f"{uniq_keys}
"
+    )
+
+    node1.restart_with_latest_version()
+
+    assert (
+        node1.query(f"SELECT uniqExactMerge(x) FROM state_{uniq_keys}")
+        == f"{uniq_keys}
"
+    )
+
+    node1.query(f"DROP TABLE state_{uniq_keys}")
+    node1.query(f"DROP TABLE tab_{uniq_keys}")
+    node2.query(f"DROP TABLE tab_{uniq_keys}")
+    node3.query(f"DROP TABLE tab_{uniq_keys}")
+    node4.query(f"DROP TABLE tab_{uniq_keys}")
diff --git a/tests/integration/test_backward_compatibility/test_aggregate_function_state_avg.py b/tests/integration/test_backward_compatibility/test_aggregate_function_state_avg.py
deleted file mode 100644
index 1e54e6220d7a..000000000000
--- a/tests/integration/test_backward_compatibility/test_aggregate_function_state_avg.py
+++ /dev/null
@@ -1,82 +0,0 @@
-import pytest
-
-from helpers.cluster import ClickHouseCluster
-
-cluster = ClickHouseCluster(__file__)
-node1 = cluster.add_instance(
-    "node1",
-    with_zookeeper=False,
-    image="yandex/clickhouse-server",
-    tag="19.16.9.37",
-    stay_alive=True,
-    with_installed_binary=True,
-)
-node2 = cluster.add_instance(
-    "node2",
-    with_zookeeper=False,
-    image="yandex/clickhouse-server",
-    tag="19.16.9.37",
-    stay_alive=True,
-    with_installed_binary=True,
-)
-node3 = cluster.add_instance("node3", with_zookeeper=False)
-node4 = cluster.add_instance("node4", with_zookeeper=False)
-
-
-@pytest.fixture(scope="module")
-def start_cluster():
-    try:
-        cluster.start()
-        yield cluster
-
-    finally:
-        cluster.shutdown()
-
-
-# We will test that serialization of internal state of "avg" function is compatible between different versions.
-# TODO Implement versioning of serialization format for aggregate function states.
-# NOTE This test is too ad-hoc.
-
-
-def test_backward_compatability(start_cluster):
-    node1.query("create table tab (x UInt64) engine = Memory")
-    node2.query("create table tab (x UInt64) engine = Memory")
-    node3.query("create table tab (x UInt64) engine = Memory")
-    node4.query("create table tab (x UInt64) engine = Memory")
-
-    node1.query("INSERT INTO tab VALUES (1)")
-    node2.query("INSERT INTO tab VALUES (2)")
-    node3.query("INSERT INTO tab VALUES (3)")
-    node4.query("INSERT INTO tab VALUES (4)")
-
-    assert (
-        node1.query("SELECT avg(x) FROM remote('node{1..4}', default, tab)") == "2.5
"
-    )
-    assert (
-        node2.query("SELECT avg(x) FROM remote('node{1..4}', default, tab)") == "2.5
"
-    )
-    assert (
-        node3.query("SELECT avg(x) FROM remote('node{1..4}', default, tab)") == "2.5
"
-    )
-    assert (
-        node4.query("SELECT avg(x) FROM remote('node{1..4}', default, tab)") == "2.5
"
-    )
-
-    # Also check with persisted aggregate function state
-
-    node1.query("create table state (x AggregateFunction(avg, UInt64)) engine = Log")
-    node1.query(
-        "INSERT INTO state SELECT avgState(arrayJoin(CAST([1, 2, 3, 4] AS Array(UInt64))))"
-    )
-
-    assert node1.query("SELECT avgMerge(x) FROM state") == "2.5
"
-
-    node1.restart_with_latest_version(fix_metadata=True)
-
-    assert node1.query("SELECT avgMerge(x) FROM state") == "2.5
"
-
-    node1.query("drop table tab")
-    node1.query("drop table state")
-    node2.query("drop table tab")
-    node3.query("drop table tab")
-    node4.query("drop table tab")
diff --git a/tests/performance/uniq_without_key.xml b/tests/performance/uniq_without_key.xml
new file mode 100644
index 000000000000..4394aef7889e
--- /dev/null
+++ b/tests/performance/uniq_without_key.xml
@@ -0,0 +1,33 @@
+<test>
+    <substitutions>
+        <substitution>
+           <name>uniq_keys</name>
+           <values>
+               <value>10000</value>
+               <value>50000</value>
+               <value>100000</value>
+               <value>250000</value>
+               <value>500000</value>
+               <value>1000000</value>
+           </values>
+        </substitution>
+    </substitutions>
+
+    <create_query>create table t_{uniq_keys}(a UInt64) engine=MergeTree order by tuple()</create_query>
+
+    <fill_query>insert into t_{uniq_keys} select number % {uniq_keys} from numbers_mt(5e7)</fill_query>
+
+    <query>SELECT count(distinct a) FROM t_{uniq_keys} GROUP BY a FORMAT Null</query>
+    <query>SELECT uniqExact(a) FROM t_{uniq_keys} GROUP BY a FORMAT Null</query>
+
+    <query>SELECT count(distinct a) FROM t_{uniq_keys}</query>
+    <query>SELECT uniqExact(a) FROM t_{uniq_keys}</query>
+
+    <query>SELECT uniqExact(number) from numbers_mt(1e7)</query>
+    <query>SELECT uniqExact(number) from numbers_mt(5e7)</query>
+
+    <query>SELECT uniqExact(number, number) from numbers_mt(5e6)</query>
+    <query>SELECT uniqExact(number, number) from numbers_mt(1e7)</query>
+
+    <drop_query>drop table t_{uniq_keys}</drop_query>
+</test>
