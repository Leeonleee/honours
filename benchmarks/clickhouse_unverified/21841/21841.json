{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 21841,
  "instance_id": "ClickHouse__ClickHouse-21841",
  "issue_numbers": [
    "21773"
  ],
  "base_commit": "89e79185a0f764e1009a061ba01ea4cb93704c55",
  "patch": "diff --git a/src/Interpreters/ActionsDAG.cpp b/src/Interpreters/ActionsDAG.cpp\nindex 83844176f3b4..94d9b72b8e99 100644\n--- a/src/Interpreters/ActionsDAG.cpp\n+++ b/src/Interpreters/ActionsDAG.cpp\n@@ -91,7 +91,7 @@ const ActionsDAG::Node & ActionsDAG::addInput(std::string name, DataTypePtr type\n     return addNode(std::move(node), can_replace, add_to_index);\n }\n \n-const ActionsDAG::Node & ActionsDAG::addInput(ColumnWithTypeAndName column, bool can_replace)\n+const ActionsDAG::Node & ActionsDAG::addInput(ColumnWithTypeAndName column, bool can_replace, bool add_to_index)\n {\n     Node node;\n     node.type = ActionType::INPUT;\n@@ -99,7 +99,7 @@ const ActionsDAG::Node & ActionsDAG::addInput(ColumnWithTypeAndName column, bool\n     node.result_name = std::move(column.name);\n     node.column = std::move(column.column);\n \n-    return addNode(std::move(node), can_replace);\n+    return addNode(std::move(node), can_replace, add_to_index);\n }\n \n const ActionsDAG::Node & ActionsDAG::addColumn(ColumnWithTypeAndName column, bool can_replace, bool materialize)\n@@ -1360,7 +1360,7 @@ ColumnsWithTypeAndName prepareFunctionArguments(const std::vector<ActionsDAG::No\n ///\n /// Result actions add single column with conjunction result (it is always last in index).\n /// No other columns are added or removed.\n-ActionsDAGPtr ActionsDAG::cloneActionsForConjunction(std::vector<Node *> conjunction)\n+ActionsDAGPtr ActionsDAG::cloneActionsForConjunction(std::vector<Node *> conjunction, const ColumnsWithTypeAndName & all_inputs)\n {\n     if (conjunction.empty())\n         return nullptr;\n@@ -1374,6 +1374,7 @@ ActionsDAGPtr ActionsDAG::cloneActionsForConjunction(std::vector<Node *> conjunc\n                             std::make_shared<FunctionAnd>()));\n \n     std::unordered_map<const ActionsDAG::Node *, ActionsDAG::Node *> nodes_mapping;\n+    std::unordered_map<std::string, std::list<Node *>> required_inputs;\n \n     struct Frame\n     {\n@@ -1416,16 +1417,31 @@ ActionsDAGPtr ActionsDAG::cloneActionsForConjunction(std::vector<Node *> conjunc\n                     child = nodes_mapping[child];\n \n                 if (node.type == ActionType::INPUT)\n-                {\n-                    actions->inputs.emplace_back(&node);\n-                    actions->index.insert(&node);\n-                }\n+                    required_inputs[node.result_name].push_back(&node);\n \n                 stack.pop();\n             }\n         }\n     }\n \n+    /// Actions must have the same inputs as in all_inputs list.\n+    /// See comment to cloneActionsForFilterPushDown.\n+    for (const auto & col : all_inputs)\n+    {\n+        Node * input;\n+        auto & list = required_inputs[col.name];\n+        if (list.empty())\n+            input = &const_cast<Node &>(actions->addInput(col, true, false));\n+        else\n+        {\n+            input = list.front();\n+            list.pop_front();\n+            actions->inputs.push_back(input);\n+        }\n+\n+        actions->index.insert(input);\n+    }\n+\n     Node * result_predicate = nodes_mapping[*conjunction.begin()];\n \n     if (conjunction.size() > 1)\n@@ -1442,7 +1458,11 @@ ActionsDAGPtr ActionsDAG::cloneActionsForConjunction(std::vector<Node *> conjunc\n     return actions;\n }\n \n-ActionsDAGPtr ActionsDAG::splitActionsForFilter(const std::string & filter_name, bool can_remove_filter, const Names & available_inputs)\n+ActionsDAGPtr ActionsDAG::cloneActionsForFilterPushDown(\n+    const std::string & filter_name,\n+    bool can_remove_filter,\n+    const Names & available_inputs,\n+    const ColumnsWithTypeAndName & all_inputs)\n {\n     Node * predicate;\n \n@@ -1480,7 +1500,7 @@ ActionsDAGPtr ActionsDAG::splitActionsForFilter(const std::string & filter_name,\n     }\n \n     auto conjunction = getConjunctionNodes(predicate, allowed_nodes);\n-    auto actions = cloneActionsForConjunction(conjunction.allowed);\n+    auto actions = cloneActionsForConjunction(conjunction.allowed, all_inputs);\n     if (!actions)\n         return nullptr;\n \ndiff --git a/src/Interpreters/ActionsDAG.h b/src/Interpreters/ActionsDAG.h\nindex 165f712a627c..4e334bd1be80 100644\n--- a/src/Interpreters/ActionsDAG.h\n+++ b/src/Interpreters/ActionsDAG.h\n@@ -120,8 +120,31 @@ class ActionsDAG\n         /// Insert method doesn't check if map already have node with the same name.\n         /// If node with the same name exists, it is removed from map, but not list.\n         /// It is expected and used for project(), when result may have several columns with the same name.\n-        void insert(Node * node) { map[node->result_name] = list.emplace(list.end(), node); }\n-        void prepend(Node * node) { map[node->result_name] = list.emplace(list.begin(), node); }\n+        void insert(Node * node)\n+        {\n+            auto it = list.emplace(list.end(), node);\n+            if (auto handle = map.extract(node->result_name))\n+            {\n+                handle.key() = node->result_name; /// Change string_view\n+                handle.mapped() = it;\n+                map.insert(std::move(handle));\n+            }\n+            else\n+                map[node->result_name] = it;\n+        }\n+\n+        void prepend(Node * node)\n+        {\n+            auto it = list.emplace(list.begin(), node);\n+            if (auto handle = map.extract(node->result_name))\n+            {\n+                handle.key() = node->result_name; /// Change string_view\n+                handle.mapped() = it;\n+                map.insert(std::move(handle));\n+            }\n+            else\n+                map[node->result_name] = it;\n+        }\n \n         /// If node with same name exists in index, replace it. Otherwise insert new node to index.\n         void replace(Node * node)\n@@ -200,7 +223,7 @@ class ActionsDAG\n     std::string dumpDAG() const;\n \n     const Node & addInput(std::string name, DataTypePtr type, bool can_replace = false, bool add_to_index = true);\n-    const Node & addInput(ColumnWithTypeAndName column, bool can_replace = false);\n+    const Node & addInput(ColumnWithTypeAndName column, bool can_replace = false, bool add_to_index = true);\n     const Node & addColumn(ColumnWithTypeAndName column, bool can_replace = false, bool materialize = false);\n     const Node & addAlias(const std::string & name, std::string alias, bool can_replace = false);\n     const Node & addArrayJoin(const std::string & source_name, std::string result_name);\n@@ -292,7 +315,23 @@ class ActionsDAG\n     /// Otherwise, return actions which inputs are from available_inputs.\n     /// Returned actions add single column which may be used for filter.\n     /// Also, replace some nodes of current inputs to constant 1 in case they are filtered.\n-    ActionsDAGPtr splitActionsForFilter(const std::string & filter_name, bool can_remove_filter, const Names & available_inputs);\n+    ///\n+    /// @param all_inputs should contain inputs from previous step, which will be used for result actions.\n+    /// It is expected that all_inputs contain columns from available_inputs.\n+    /// This parameter is needed to enforce result actions save columns order in block.\n+    /// Otherwise for some queries, e.g. with GROUP BY, columns will be mixed.\n+    /// Example: SELECT sum(x), y, z FROM tab WHERE z > 0 and sum(x) > 0\n+    /// Pushed condition: z > 0\n+    /// GROUP BY step will transform columns `x, y, z` -> `sum(x), y, z`\n+    /// If we just add filter step with actions `z -> z > 0` before GROUP BY,\n+    /// columns will be transformed like `x, y, z` -> `z, z > 0, x, y` -(remove filter)-> `z, x, y`.\n+    /// To avoid it, add inputs from `all_inputs` list,\n+    /// so actions `x, y, z -> x, y, z, z > 0` -(remove filter)-> `x, y, z` will not change columns order.\n+    ActionsDAGPtr cloneActionsForFilterPushDown(\n+        const std::string & filter_name,\n+        bool can_remove_filter,\n+        const Names & available_inputs,\n+        const ColumnsWithTypeAndName & all_inputs);\n \n private:\n     Node & addNode(Node node, bool can_replace = false, bool add_to_index = true);\n@@ -323,7 +362,7 @@ class ActionsDAG\n \n     void compileFunctions();\n \n-    ActionsDAGPtr cloneActionsForConjunction(std::vector<Node *> conjunction);\n+    ActionsDAGPtr cloneActionsForConjunction(std::vector<Node *> conjunction, const ColumnsWithTypeAndName & all_inputs);\n };\n \n \ndiff --git a/src/Processors/QueryPlan/Optimizations/filterPushDown.cpp b/src/Processors/QueryPlan/Optimizations/filterPushDown.cpp\nindex d64f082b7ee0..0b988f9803f0 100644\n--- a/src/Processors/QueryPlan/Optimizations/filterPushDown.cpp\n+++ b/src/Processors/QueryPlan/Optimizations/filterPushDown.cpp\n@@ -43,7 +43,8 @@ static size_t tryAddNewFilterStep(\n \n     // std::cerr << \"Filter: \\n\" << expression->dumpDAG() << std::endl;\n \n-    auto split_filter = expression->splitActionsForFilter(filter_column_name, removes_filter, allowed_inputs);\n+    const auto & all_inputs = child->getInputStreams().front().header.getColumnsWithTypeAndName();\n+    auto split_filter = expression->cloneActionsForFilterPushDown(filter_column_name, removes_filter, allowed_inputs, all_inputs);\n     if (!split_filter)\n         return 0;\n \n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01763_filter_push_down_bugs.reference b/tests/queries/0_stateless/01763_filter_push_down_bugs.reference\nnew file mode 100644\nindex 000000000000..66ea84a07c11\n--- /dev/null\n+++ b/tests/queries/0_stateless/01763_filter_push_down_bugs.reference\n@@ -0,0 +1,6 @@\n+1\t2\n+1\t2\n+[1]\t2\n+[[1]]\t2\n+String1_0\tString2_0\tString3_0\tString4_0\t1\n+String1_0\tString2_0\tString3_0\tString4_0\t1\ndiff --git a/tests/queries/0_stateless/01763_filter_push_down_bugs.sql b/tests/queries/0_stateless/01763_filter_push_down_bugs.sql\nnew file mode 100644\nindex 000000000000..5000eb388786\n--- /dev/null\n+++ b/tests/queries/0_stateless/01763_filter_push_down_bugs.sql\n@@ -0,0 +1,37 @@\n+SELECT * FROM (SELECT col1, col2 FROM (select '1' as col1, '2' as col2) GROUP by col1, col2) AS expr_qry WHERE col2 != '';\n+SELECT * FROM (SELECT materialize('1') AS s1, materialize('2') AS s2 GROUP BY s1, s2) WHERE s2 = '2';\n+SELECT * FROM (SELECT materialize([1]) AS s1, materialize('2') AS s2 GROUP BY s1, s2) WHERE s2 = '2';\n+SELECT * FROM (SELECT materialize([[1]]) AS s1, materialize('2') AS s2 GROUP BY s1, s2) WHERE s2 = '2';\n+\n+DROP TABLE IF EXISTS Test;\n+\n+CREATE TABLE Test\n+ENGINE = MergeTree()\n+PRIMARY KEY (String1,String2)\n+ORDER BY (String1,String2)\n+AS \n+SELECT\n+   'String1_' || toString(number) as String1,\n+   'String2_' || toString(number) as String2,\n+   'String3_' || toString(number) as String3,\n+   'String4_' || toString(number%4) as String4\n+FROM numbers(1);\n+\n+SELECT *\n+FROM\n+  (\n+   SELECT String1,String2,String3,String4,COUNT(*)\n+   FROM Test\n+   GROUP by String1,String2,String3,String4\n+  ) AS expr_qry;\n+\n+SELECT *\n+FROM\n+  (\n+    SELECT String1,String2,String3,String4,COUNT(*)\n+    FROM Test\n+    GROUP by String1,String2,String3,String4\n+  ) AS expr_qry\n+WHERE  String4 ='String4_0';\n+\n+DROP TABLE IF EXISTS Test;\n",
  "problem_statement": "Would use 1.00 EiB ... while executing ConvertingAggregatedToChunksTransform\nAbnormal memory requirements for a query with string filter\r\n\r\n\r\nAppeared fresh after upgrade to 21.3.2.5 \r\n\r\nThe table is not big - 480 mb compressed\r\n\r\nGetting an error\r\n```\r\nSQL Error [241]: ClickHouse exception, code: 241, host: localhost, port: 8123; Code: 241, e.displayText() = DB::Exception: Memory limit (for query) exceeded: would use 1.00 EiB (attempt to allocate chunk of 1152921504606554384 bytes), maximum: 101.47 GiB: While executing ConvertingAggregatedToChunksTransform (version 21.3.2.5 (official build))\r\n\r\nThe query is quite plain\r\nSELECT \r\n       FirstScreen,\r\n       \"SessionResult\" AS \"SessionResult\",\r\n       count(*) AS count\r\nFROM\r\n  (SELECT FirstScreen,\r\n          SessionResult,\r\n          LastResponse,\r\n          toDate(LastResponseDateTime),\r\n          WasEligible,\r\n          WasSessionSuccessfull,\r\n          COUNT (*)\r\n   FROM MPTUSSDSESSIONS\r\n   GROUP by FirstScreen,\r\n            SessionResult,\r\n            LastResponse,\r\n            toDate(LastResponseDateTime),\r\n            WasEligible,\r\n            WasSessionSuccessfull) AS expr_qry\r\nWHERE  \"SessionResult\" NOT IN ('unknown result')\r\n  AND \"WasSessionSuccessfull\" ='Y'\r\nGROUP BY FirstScreen,  \"SessionResult\"\r\nORDER BY count DESC\r\nLIMIT 10000;\r\n```\r\n\r\nMost interesting - when line  `AND \"WasSessionSuccessfull\" ='Y' ` is removed from the query it completes ok.\n",
  "hints_text": "",
  "created_at": "2021-03-17T17:11:57Z",
  "modified_files": [
    "src/Interpreters/ActionsDAG.cpp",
    "src/Interpreters/ActionsDAG.h",
    "src/Processors/QueryPlan/Optimizations/filterPushDown.cpp"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/01763_filter_push_down_bugs.reference",
    "b/tests/queries/0_stateless/01763_filter_push_down_bugs.sql"
  ]
}