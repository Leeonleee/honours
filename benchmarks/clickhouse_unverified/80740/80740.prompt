You will be provided with a partial code base and an issue statement explaining a problem to resolve.

<issue>
Unity catalog is unusable if a table contains an unsupported feature
### Company or project name

_No response_

### Describe the unexpected behaviour

I created a db using the DataLakeCatalog db engine pointing to a dbx Unity catalog. I created a Delta table in dbx which contained a column of type 'timestamp_ntz' which a public preview feature. 

If I then run `SHOW TABLES;` in ClickHouse on my DataLakeCatalog DB, it fails:

```
Unsupported DeltaLake type: timestamp_ntz: while parsing JSON: ...etc...
```

I cannot perform any actions on the db or its tables due to this error.

I would expect that an unsupported type would prevent me from using the specific table, but not prevent me from using the catalog & other tables.

### How to reproduce

Have a Unity catalog with a table with an unsupported feature (e.g. a datatype like `timestamp_ntz`)

CREATE DATABASE unity_test ENGINE = DataLakeCatalog(...)

USE unity_test;
SHOW TABLES;

### Expected behavior

_No response_

### Error message and/or stacktrace

_No response_

### Additional context

_No response_
DeltaLake timestamp_ntz data type unsupported
### Company or project name

I am writing telemetry data to a delta lake platform and I would like to use ClickHouse to explore this data.  


### Describe the unexpected behaviour

When I am trying to query my DeltaLake data, I encounter the following error: 

```
Code 36 : BAD_ARGUMENTS
Unsupported DeltaLake type: timestamp_ntz.
```

Here is the query I am using: 
```
SELECT
    log_id,
    level
FROM deltaLake('http://s3.mnm.st/data-lake/telemetry_logs/', '2z...', 'yA...')
LIMIT 2
```

### How to reproduce

I created my table with the following queries, using [Arroyo](https://www.arroyo.dev): 

```
CREATE TABLE telemetry_logs (
    log_id TEXT,
    level TEXT,
    logger_name TEXT,
    message TEXT,
    schema_version TEXT,
    timestamp TIMESTAMP,
    ingested_at TIMESTAMP,
    ...

) WITH (
    -- https://doc.arroyo.dev/connectors/filesystem
    -- https://doc.arroyo.dev/connectors/delta
    connector = 'delta',
    path = '...',
    format = 'parquet',
    parquet_compression = 'zstd',
    'filename.strategy' = 'uuid',
    time_partition_pattern = '%Y/%m/%d/%H'
);
```

And 


```
INSERT INTO telemetry_logs
SELECT
    -- Extract top-level fields using ->>
    CAST(value ->> 'id' AS TEXT) AS log_id,
    CAST(value ->> 'level' AS TEXT) AS level,
    CAST(value ->> 'logger_name' AS TEXT) AS logger_name,
    CAST(value ->> 'message' AS TEXT) AS message,
    CAST(value ->> 'schema_version' AS TEXT) AS schema_version,
    TO_TIMESTAMP(CAST(value ->> 'timestamp' AS DOUBLE)) AS timestamp,
    NOW() as ingested_at,
    ...

FROM telemetry_events
WHERE
    CAST(value->'type' AS TEXT) = 'log';
```

### Expected behavior

Ideally I would like to be able to read that type into Clickhouse. Alternatively, I would like the column to be ignored.

### Error message and/or stacktrace

_No response_

### Additional context

_No response_
</issue>

I need you to solve the provided issue by generating a code fix that can be applied directly to the repository

Respond below:
