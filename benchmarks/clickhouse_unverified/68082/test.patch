diff --git a/src/IO/tests/gtest_s3_uri.cpp b/src/IO/tests/gtest_s3_uri.cpp
index 0ec28f800727..c0bf7fcb28a1 100644
--- a/src/IO/tests/gtest_s3_uri.cpp
+++ b/src/IO/tests/gtest_s3_uri.cpp
@@ -206,11 +206,6 @@ TEST(S3UriTest, validPatterns)
     }
 }
 
-TEST_P(S3UriTest, invalidPatterns)
-{
-    ASSERT_ANY_THROW(S3::URI new_uri(GetParam()));
-}
-
 TEST(S3UriTest, versionIdChecks)
 {
     for (const auto& test_case : TestCases)
@@ -223,19 +218,5 @@ TEST(S3UriTest, versionIdChecks)
     }
 }
 
-INSTANTIATE_TEST_SUITE_P(
-    S3,
-    S3UriTest,
-    testing::Values(
-        "https:///",
-        "https://.s3.amazonaws.com/key",
-        "https://s3.amazonaws.com/key",
-        "https://jokserfn.s3amazonaws.com/key",
-        "https://s3.amazonaws.com//",
-        "https://amazonaws.com/",
-        "https://amazonaws.com//",
-        "https://amazonaws.com//key"));
-
 }
-
 #endif
diff --git a/tests/integration/test_odbc_interaction/test.py b/tests/integration/test_odbc_interaction/test.py
index 0d0d7a0afb17..9d4ca5ad49f0 100644
--- a/tests/integration/test_odbc_interaction/test.py
+++ b/tests/integration/test_odbc_interaction/test.py
@@ -51,9 +51,9 @@
     """
 
 
-def skip_test_msan(instance):
-    if instance.is_built_with_memory_sanitizer():
-        pytest.skip("Memory Sanitizer cannot work with third-party shared libraries")
+def skip_test_sanitizers(instance):
+    if instance.is_built_with_sanitizer():
+        pytest.skip("Sanitizers cannot work with third-party shared libraries")
 
 
 def get_mysql_conn():
@@ -208,7 +208,7 @@ def started_cluster():
 
 
 def test_mysql_odbc_select_nullable(started_cluster):
-    skip_test_msan(node1)
+    skip_test_sanitizers(node1)
     mysql_setup = node1.odbc_drivers["MySQL"]
 
     table_name = "test_insert_nullable_select"
@@ -248,7 +248,7 @@ def test_mysql_odbc_select_nullable(started_cluster):
 
 
 def test_mysql_simple_select_works(started_cluster):
-    skip_test_msan(node1)
+    skip_test_sanitizers(node1)
 
     mysql_setup = node1.odbc_drivers["MySQL"]
 
@@ -331,7 +331,7 @@ def test_mysql_simple_select_works(started_cluster):
 
 
 def test_mysql_insert(started_cluster):
-    skip_test_msan(node1)
+    skip_test_sanitizers(node1)
 
     mysql_setup = node1.odbc_drivers["MySQL"]
     table_name = "test_insert"
@@ -374,7 +374,7 @@ def test_mysql_insert(started_cluster):
 
 
 def test_sqlite_simple_select_function_works(started_cluster):
-    skip_test_msan(node1)
+    skip_test_sanitizers(node1)
 
     sqlite_setup = node1.odbc_drivers["SQLite3"]
     sqlite_db = sqlite_setup["Database"]
@@ -438,7 +438,7 @@ def test_sqlite_simple_select_function_works(started_cluster):
 
 
 def test_sqlite_table_function(started_cluster):
-    skip_test_msan(node1)
+    skip_test_sanitizers(node1)
 
     sqlite_setup = node1.odbc_drivers["SQLite3"]
     sqlite_db = sqlite_setup["Database"]
@@ -470,7 +470,7 @@ def test_sqlite_table_function(started_cluster):
 
 
 def test_sqlite_simple_select_storage_works(started_cluster):
-    skip_test_msan(node1)
+    skip_test_sanitizers(node1)
 
     sqlite_setup = node1.odbc_drivers["SQLite3"]
     sqlite_db = sqlite_setup["Database"]
@@ -503,7 +503,7 @@ def test_sqlite_simple_select_storage_works(started_cluster):
 
 
 def test_sqlite_odbc_hashed_dictionary(started_cluster):
-    skip_test_msan(node1)
+    skip_test_sanitizers(node1)
 
     sqlite_db = node1.odbc_drivers["SQLite3"]["Database"]
     node1.exec_in_container(
@@ -586,7 +586,7 @@ def test_sqlite_odbc_hashed_dictionary(started_cluster):
 
 
 def test_sqlite_odbc_cached_dictionary(started_cluster):
-    skip_test_msan(node1)
+    skip_test_sanitizers(node1)
 
     sqlite_db = node1.odbc_drivers["SQLite3"]["Database"]
     node1.exec_in_container(
@@ -635,7 +635,7 @@ def test_sqlite_odbc_cached_dictionary(started_cluster):
 
 
 def test_postgres_odbc_hashed_dictionary_with_schema(started_cluster):
-    skip_test_msan(node1)
+    skip_test_sanitizers(node1)
 
     try:
         conn = get_postgres_conn(started_cluster)
@@ -663,7 +663,7 @@ def test_postgres_odbc_hashed_dictionary_with_schema(started_cluster):
 
 
 def test_postgres_odbc_hashed_dictionary_no_tty_pipe_overflow(started_cluster):
-    skip_test_msan(node1)
+    skip_test_sanitizers(node1)
 
     try:
         conn = get_postgres_conn(started_cluster)
@@ -685,7 +685,7 @@ def test_postgres_odbc_hashed_dictionary_no_tty_pipe_overflow(started_cluster):
 
 
 def test_no_connection_pooling(started_cluster):
-    skip_test_msan(node1)
+    skip_test_sanitizers(node1)
 
     try:
         conn = get_postgres_conn(started_cluster)
@@ -717,7 +717,7 @@ def test_no_connection_pooling(started_cluster):
 
 
 def test_postgres_insert(started_cluster):
-    skip_test_msan(node1)
+    skip_test_sanitizers(node1)
 
     conn = get_postgres_conn(started_cluster)
 
@@ -754,7 +754,7 @@ def test_postgres_insert(started_cluster):
 
 
 def test_odbc_postgres_date_data_type(started_cluster):
-    skip_test_msan(node1)
+    skip_test_sanitizers(node1)
 
     try:
         conn = get_postgres_conn(started_cluster)
@@ -783,7 +783,7 @@ def test_odbc_postgres_date_data_type(started_cluster):
 
 
 def test_odbc_postgres_conversions(started_cluster):
-    skip_test_msan(node1)
+    skip_test_sanitizers(node1)
 
     try:
         conn = get_postgres_conn(started_cluster)
@@ -841,7 +841,7 @@ def test_odbc_postgres_conversions(started_cluster):
 
 
 def test_odbc_cyrillic_with_varchar(started_cluster):
-    skip_test_msan(node1)
+    skip_test_sanitizers(node1)
 
     conn = get_postgres_conn(started_cluster)
     cursor = conn.cursor()
@@ -868,7 +868,7 @@ def test_odbc_cyrillic_with_varchar(started_cluster):
 
 
 def test_many_connections(started_cluster):
-    skip_test_msan(node1)
+    skip_test_sanitizers(node1)
 
     conn = get_postgres_conn(started_cluster)
     cursor = conn.cursor()
@@ -894,7 +894,7 @@ def test_many_connections(started_cluster):
 
 
 def test_concurrent_queries(started_cluster):
-    skip_test_msan(node1)
+    skip_test_sanitizers(node1)
 
     conn = get_postgres_conn(started_cluster)
     cursor = conn.cursor()
@@ -948,7 +948,7 @@ def node_insert_select(_):
 
 
 def test_odbc_long_column_names(started_cluster):
-    skip_test_msan(node1)
+    skip_test_sanitizers(node1)
 
     conn = get_postgres_conn(started_cluster)
     cursor = conn.cursor()
@@ -986,7 +986,7 @@ def test_odbc_long_column_names(started_cluster):
 
 
 def test_odbc_long_text(started_cluster):
-    skip_test_msan(node1)
+    skip_test_sanitizers(node1)
 
     conn = get_postgres_conn(started_cluster)
     cursor = conn.cursor()
diff --git a/tests/integration/test_s3_imds/test_simple.py b/tests/integration/test_s3_imds/test_simple.py
index 0dacac2b0b96..4884c824f998 100644
--- a/tests/integration/test_s3_imds/test_simple.py
+++ b/tests/integration/test_s3_imds/test_simple.py
@@ -56,7 +56,7 @@ def test_credentials_from_metadata():
     )
 
     expected_logs = [
-        "Calling EC2MetadataService to get token failed, falling back to less secure way",
+        "Calling EC2MetadataService to get token failed, falling back to a less secure way",
         "Getting default credentials for ec2 instance from resolver:8080",
         "Calling EC2MetadataService resource, /latest/meta-data/iam/security-credentials returned credential string myrole",
         "Calling EC2MetadataService resource /latest/meta-data/iam/security-credentials/myrole",
diff --git a/tests/queries/0_stateless/02490_benchmark_max_consecutive_errors.sh b/tests/queries/0_stateless/02490_benchmark_max_consecutive_errors.sh
index f747b3156a57..df7e93866627 100755
--- a/tests/queries/0_stateless/02490_benchmark_max_consecutive_errors.sh
+++ b/tests/queries/0_stateless/02490_benchmark_max_consecutive_errors.sh
@@ -11,5 +11,6 @@ if [ "$RES" -eq 10 ]
 then
     echo "$RES"
 else
+    echo "$RES"
     cat "${CLICKHOUSE_TMP}/${CLICKHOUSE_DATABASE}.log"
 fi
diff --git a/tests/queries/0_stateless/03221_s3_imds_decent_timeout.reference b/tests/queries/0_stateless/03221_s3_imds_decent_timeout.reference
new file mode 100644
index 000000000000..d00491fd7e5b
--- /dev/null
+++ b/tests/queries/0_stateless/03221_s3_imds_decent_timeout.reference
@@ -0,0 +1,1 @@
+1
diff --git a/tests/queries/0_stateless/03221_s3_imds_decent_timeout.sh b/tests/queries/0_stateless/03221_s3_imds_decent_timeout.sh
new file mode 100755
index 000000000000..021278955cd6
--- /dev/null
+++ b/tests/queries/0_stateless/03221_s3_imds_decent_timeout.sh
@@ -0,0 +1,16 @@
+#!/usr/bin/env bash
+# Tags: no-fasttest, no-asan, no-msan, no-tsan
+# ^ requires S3
+
+CUR_DIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
+# shellcheck source=../shell_config.sh
+. "$CUR_DIR"/../shell_config.sh
+
+# Inaccessible IMDS should not introduce large delays, so this query should reply quickly at least sometimes:
+while true
+do
+    # This host (likely) drops packets sent to it (does not reply), so it is good for testing timeouts.
+    # At the same time, we expect that the clickhouse host does not drop packets and quickly replies with 4xx, which is a non-retriable error for S3.
+    AWS_EC2_METADATA_SERVICE_ENDPOINT='https://10.255.255.255/' ${CLICKHOUSE_LOCAL} --time --query "SELECT * FROM s3('${CLICKHOUSE_PORT_HTTP_PROTO}://${CLICKHOUSE_HOST}:${CLICKHOUSE_PORT_HTTP}/nonexistent')" |& grep -v -F 404 |
+        ${CLICKHOUSE_LOCAL} --input-format TSV "SELECT c1::Float64 < 1 FROM table" | grep 1 && break
+done
