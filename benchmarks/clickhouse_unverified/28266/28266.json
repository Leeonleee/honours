{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 28266,
  "instance_id": "ClickHouse__ClickHouse-28266",
  "issue_numbers": [
    "28198"
  ],
  "base_commit": "481cc011c7f5908a2b4db8e9c22ebb4323454382",
  "patch": "diff --git a/src/Storages/StorageMerge.cpp b/src/Storages/StorageMerge.cpp\nindex 4e50b78ea8e0..d537ef05cdb0 100644\n--- a/src/Storages/StorageMerge.cpp\n+++ b/src/Storages/StorageMerge.cpp\n@@ -338,9 +338,10 @@ Pipe StorageMerge::read(\n \n     auto pipe = Pipe::unitePipes(std::move(pipes));\n \n-    if (!pipe.empty())\n+    if (!pipe.empty() && !query_info.input_order_info)\n         // It's possible to have many tables read from merge, resize(num_streams) might open too many files at the same time.\n-        // Using narrowPipe instead.\n+        // Using narrowPipe instead. But in case of reading in order of primary key, we cannot do it,\n+        // because narrowPipe doesn't preserve order.\n         narrowPipe(pipe, num_streams);\n \n     return pipe;\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02014_storage_merge_order_by.reference b/tests/queries/0_stateless/02014_storage_merge_order_by.reference\nnew file mode 100644\nindex 000000000000..0bb816b39871\n--- /dev/null\n+++ b/tests/queries/0_stateless/02014_storage_merge_order_by.reference\n@@ -0,0 +1,5 @@\n+20\n+20\n+20\n+20\n+20\ndiff --git a/tests/queries/0_stateless/02014_storage_merge_order_by.sql b/tests/queries/0_stateless/02014_storage_merge_order_by.sql\nnew file mode 100644\nindex 000000000000..5b9789ae1d97\n--- /dev/null\n+++ b/tests/queries/0_stateless/02014_storage_merge_order_by.sql\n@@ -0,0 +1,22 @@\n+DROP TABLE IF EXISTS short;\n+DROP TABLE IF EXISTS long;\n+DROP TABLE IF EXISTS merged;\n+\n+CREATE TABLE short (e Int64, t DateTime ) ENGINE = MergeTree PARTITION BY e ORDER BY t;\n+CREATE TABLE long (e Int64, t DateTime ) ENGINE = MergeTree PARTITION BY (e, toStartOfMonth(t)) ORDER BY t;\n+\n+insert into short select number % 11, toDateTime('2021-01-01 00:00:00') + number from numbers(1000);\n+insert into long select number % 11, toDateTime('2021-01-01 00:00:00') + number from numbers(1000);\n+\n+CREATE TABLE merged as short ENGINE = Merge(currentDatabase(), 'short|long');\n+\n+select sum(e) from (select * from merged order by t limit 10) SETTINGS optimize_read_in_order = 0;\n+\n+select sum(e) from (select * from merged order by t limit 10) SETTINGS max_threads = 1;\n+select sum(e) from (select * from merged order by t limit 10) SETTINGS max_threads = 3;\n+select sum(e) from (select * from merged order by t limit 10) SETTINGS max_threads = 10;\n+select sum(e) from (select * from merged order by t limit 10) SETTINGS max_threads = 50;\n+\n+DROP TABLE IF EXISTS short;\n+DROP TABLE IF EXISTS long;\n+DROP TABLE IF EXISTS merged;\n",
  "problem_statement": "ORDER BY does not work as expected with Merge engine\nI have two tables something like the following (ClickHouse server version 20.8.7 revision 54438):\r\n\r\n```\r\nCREATE TABLE short (e UUID, t DateTime, ...24 additional columns...) ENGINE = MergeTree PARTITION BY e ORDER BY t TTL t + toIntervalDay(7)\r\nCREATE TABLE long (e UUID, t DateTime, ...24 additional columns...) ENGINE = MergeTree PARTITION BY (e, toStartOfMonth(t)) ORDER BY t TTL t + toIntervalDay(30)\r\n```\r\n\r\nThe two tables are identical except for their partition and TTL expressions.  We generate a unified view of these two tables using the Merge engine:\r\n\r\n`CREATE TABLE merged (e UUID, t DateTime, ...24 additional columns...) ENGINE = Merge('db', 'short|long')`\r\n\r\nThe problem is that when I query the merged table and order by t, the results are non-deterministic (and almost always wrong).  For example:\r\n\r\n```\r\nSELECT t\r\nFROM merged\r\nWHERE t > '2021-08-01 00:00:00'\r\nORDER BY t ASC\r\nLIMIT 5\r\n\r\nQuery id: e81738ae-8177-4f30-8a33-4b6fd1540f55\r\n\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500t\u2500\u2510\r\n\u2502 2021-08-20 09:42:51 \u2502\r\n\u2502 2021-08-20 09:43:53 \u2502\r\n\u2502 2021-08-20 09:44:56 \u2502\r\n\u2502 2021-08-20 09:45:59 \u2502\r\n\u2502 2021-08-20 09:47:02 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n5 rows in set. Elapsed: 0.147 sec. Processed 132.74 thousand rows, 530.94 KB (903.28 thousand rows/s., 3.61 MB/s.)\r\n```\r\n\r\nRepeating the exact same query yields different results:\r\n\r\n```\r\nSELECT t\r\nFROM merged\r\nWHERE t > '2021-08-01 00:00:00'\r\nORDER BY t ASC\r\nLIMIT 5\r\n\r\nQuery id: 3bdf4d80-58b7-42f2-8dd3-85a61bc7e4a0\r\n\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500t\u2500\u2510\r\n\u2502 2021-08-26 14:55:55 \u2502\r\n\u2502 2021-08-26 14:55:55 \u2502\r\n\u2502 2021-08-26 14:55:57 \u2502\r\n\u2502 2021-08-26 14:56:00 \u2502\r\n\u2502 2021-08-26 14:56:20 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n5 rows in set. Elapsed: 0.357 sec. Processed 1.82 thousand rows, 7.28 KB (5.09 thousand rows/s., 20.38 KB/s.)\r\n```\r\n\r\nThe correct results can be seen with an expensive union query:\r\n\r\n```\r\nSELECT t\r\nFROM\r\n(\r\n    SELECT t\r\n    FROM short\r\n    UNION ALL\r\n    SELECT t\r\n    FROM long\r\n)\r\nWHERE t > '2021-08-01 00:00:00'\r\nORDER BY t ASC\r\nLIMIT 5\r\n\r\nQuery id: 2e1e2712-6025-4de5-9d82-34ac11ef4662\r\n\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500t\u2500\u2510\r\n\u2502 2021-08-01 00:00:01 \u2502\r\n\u2502 2021-08-01 00:00:01 \u2502\r\n\u2502 2021-08-01 00:00:01 \u2502\r\n\u2502 2021-08-01 00:00:02 \u2502\r\n\u2502 2021-08-01 00:00:02 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n5 rows in set. Elapsed: 0.403 sec. Processed 42.56 million rows, 170.26 MB (105.55 million rows/s., 422.20 MB/s.)\r\n```\r\n\r\nI'm not sure what the secret sauce is to trigger this behaviour.  I tried reproducing it with a simpler set of tables but was unable to do so.  \r\n\n",
  "hints_text": "repro:\r\n\r\n```sql\r\n21.9.1.7603\r\n\r\nCREATE TABLE short (e Int64, t DateTime ) ENGINE = MergeTree PARTITION BY e ORDER BY t;\r\nCREATE TABLE long (e Int64, t DateTime ) ENGINE = MergeTree PARTITION BY (e, toStartOfMonth(t)) ORDER BY t;\r\n\r\n\r\ninsert into short select number%11, toDateTime('2021-01-01 00:00:00')+number from numbers(1000);\r\ninsert into long select number%11, toDateTime('2021-01-01 00:00:00')+number from numbers(1000);\r\n\r\nCREATE TABLE merged as short ENGINE = Merge(currentDatabase(), 'short|long')\r\n\r\n\r\nselect * from merged order by t limit 3;\r\n\u250c\u2500e\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500t\u2500\u2510\r\n\u2502 0 \u2502 2021-01-01 00:00:00 \u2502\r\n\u2502 1 \u2502 2021-01-01 00:00:01 \u2502\r\n\u2502 1 \u2502 2021-01-01 00:00:01 \u2502\r\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\nselect * from merged order by t limit 3;\r\n\u250c\u2500e\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500t\u2500\u2510\r\n\u2502 0 \u2502 2021-01-01 00:00:00 \u2502\r\n\u2502 0 \u2502 2021-01-01 00:00:00 \u2502\r\n\u2502 1 \u2502 2021-01-01 00:00:01 \u2502\r\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\nresults are consistent with `set optimize_read_in_order=0;`\r\n\r\n```sql\r\nset optimize_read_in_order=0;\r\n\r\n\u250c\u2500e\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500t\u2500\u2510\r\n\u2502 0 \u2502 2021-01-01 00:00:00 \u2502\r\n\u2502 0 \u2502 2021-01-01 00:00:00 \u2502\r\n\u2502 1 \u2502 2021-01-01 00:00:01 \u2502\r\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n\u250c\u2500e\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500t\u2500\u2510\r\n\u2502 0 \u2502 2021-01-01 00:00:00 \u2502\r\n\u2502 0 \u2502 2021-01-01 00:00:00 \u2502\r\n\u2502 1 \u2502 2021-01-01 00:00:01 \u2502\r\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\n\r\n```bash\r\nfor i in `seq 1 10`; do clickhouse-client -q \"select sum(e) from (select * from merged order by t limit 10)\"; done;\r\n33\r\n39\r\n31\r\n31\r\n32\r\n40\r\n33\r\n33\r\n24\r\n33\r\n\r\n# optimize_read_in_order=0\r\nfor i in `seq 1 10`; do clickhouse-client --optimize_read_in_order=0 -q \"select sum(e) from (select * from merged order by t limit 10)\"; done;\r\n20\r\n20\r\n20\r\n20\r\n20\r\n20\r\n20\r\n20\r\n20\r\n20\r\n```\n@pgruderman check consistency with `set optimize_read_in_order=0;`\nLooks good.  Thanks a lot @den-crane!\nNo issue in 20.3\r\n\r\n```\r\n20.3.20.6, 20.5.5.74\r\n\r\nfor i in `seq 1 10`; do clickhouse-client --optimize_read_in_order=1 -q \"select sum(e) from (select * from merged order by t limit 10)\"; done;\r\n20\r\n20\r\n20\r\n20\r\n20\r\n20\r\n20\r\n20\r\n20\r\n20\r\n```\r\n\r\nissue is in clickhouse 20.6+\n@CurtizJ ",
  "created_at": "2021-08-27T13:58:16Z",
  "modified_files": [
    "src/Storages/StorageMerge.cpp"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/02014_storage_merge_order_by.reference",
    "b/tests/queries/0_stateless/02014_storage_merge_order_by.sql"
  ]
}