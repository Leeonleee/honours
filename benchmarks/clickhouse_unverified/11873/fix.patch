diff --git a/src/Core/SortDescription.cpp b/src/Core/SortDescription.cpp
new file mode 100644
index 000000000000..4a5952c3bc2e
--- /dev/null
+++ b/src/Core/SortDescription.cpp
@@ -0,0 +1,41 @@
+#include <Core/SortDescription.h>
+#include <Core/Block.h>
+#include <IO/Operators.h>
+
+namespace DB
+{
+
+void dumpSortDescription(const SortDescription & description, const Block & header, WriteBuffer & out)
+{
+    bool first = true;
+
+    for (const auto & desc : description)
+    {
+        if (!first)
+            out << ", ";
+        first = false;
+
+        if (!desc.column_name.empty())
+            out << desc.column_name;
+        else
+        {
+            if (desc.column_number < header.columns())
+                out << header.getByPosition(desc.column_number).name;
+            else
+                out << "?";
+
+            out << " (pos " << desc.column_number << ")";
+        }
+
+        if (desc.direction > 0)
+            out << " ASC";
+        else
+            out << " DESC";
+
+        if (desc.with_fill)
+            out << " WITH FILL";
+    }
+}
+
+}
+
diff --git a/src/Core/SortDescription.h b/src/Core/SortDescription.h
index 86e4bb573eda..d433d369d0be 100644
--- a/src/Core/SortDescription.h
+++ b/src/Core/SortDescription.h
@@ -71,4 +71,9 @@ struct SortColumnDescription
 /// Description of the sorting rule for several columns.
 using SortDescription = std::vector<SortColumnDescription>;
 
+class Block;
+
+/// Outputs user-readable description into `out`.
+void dumpSortDescription(const SortDescription & description, const Block & header, WriteBuffer & out);
+
 }
diff --git a/src/Core/ya.make b/src/Core/ya.make
index 06fed2dc2573..14d609dfa963 100644
--- a/src/Core/ya.make
+++ b/src/Core/ya.make
@@ -20,6 +20,7 @@ SRCS(
     NamesAndTypes.cpp
     Settings.cpp
     SettingsCollection.cpp
+    SortDescription.cpp
 )
 
 END()
diff --git a/src/Interpreters/AggregateDescription.cpp b/src/Interpreters/AggregateDescription.cpp
new file mode 100644
index 000000000000..e483eb1b7a12
--- /dev/null
+++ b/src/Interpreters/AggregateDescription.cpp
@@ -0,0 +1,102 @@
+#include <Interpreters/AggregateDescription.h>
+#include <Common/FieldVisitors.h>
+#include <IO/Operators.h>
+
+namespace DB
+{
+
+void AggregateDescription::explain(WriteBuffer & out, size_t indent) const
+{
+    String prefix(indent, ' ');
+
+    out << prefix << column_name << '
';
+
+    auto dump_params = [&](const Array & arr)
+    {
+        bool first = true;
+        for (const auto & param : arr)
+        {
+            if (!first)
+                out << ", ";
+
+            first = false;
+
+            out << applyVisitor(FieldVisitorToString(), param);
+        }
+    };
+
+    if (function)
+    {
+        /// Double whitespace is intentional.
+        out << prefix << "  Function: " << function->getName();
+
+        const auto & params = function->getParameters();
+        if (!params.empty())
+        {
+            out << "(";
+            dump_params(params);
+            out << ")";
+        }
+
+        out << "(";
+
+        bool first = true;
+        for (const auto & type : function->getArgumentTypes())
+        {
+            if (!first)
+                out << ", ";
+            first = false;
+
+            out << type->getName();
+        }
+
+        out << ") â†’ " << function->getReturnType()->getName() << "
";
+    }
+    else
+        out << prefix << "  Function: nullptr
";
+
+    if (!parameters.empty())
+    {
+        out << prefix << "  Parameters: ";
+        dump_params(parameters);
+        out << '
';
+    }
+
+    out << prefix << "  Arguments: ";
+
+    if (argument_names.empty())
+        out << "none
";
+    else
+    {
+        bool first = true;
+        for (const auto & arg : argument_names)
+        {
+            if (!first)
+                out << ", ";
+            first = false;
+
+            out << arg;
+        }
+        out << "
";
+    }
+
+    out << prefix << "  Argument positions: ";
+
+    if (arguments.empty())
+        out << "none
";
+    else
+    {
+        bool first = true;
+        for (auto arg : arguments)
+        {
+            if (!first)
+                out << ", ";
+            first = false;
+
+            out << arg;
+        }
+        out << '
';
+    }
+}
+
+}
diff --git a/src/Interpreters/AggregateDescription.h b/src/Interpreters/AggregateDescription.h
index dece93c90932..396a62c446a1 100644
--- a/src/Interpreters/AggregateDescription.h
+++ b/src/Interpreters/AggregateDescription.h
@@ -15,6 +15,8 @@ struct AggregateDescription
     ColumnNumbers arguments;
     Names argument_names;    /// used if no `arguments` are specified.
     String column_name;      /// What name to use for a column with aggregate function values
+
+    void explain(WriteBuffer & out, size_t indent) const; /// Get description for EXPLAIN query.
 };
 
 using AggregateDescriptions = std::vector<AggregateDescription>;
diff --git a/src/Interpreters/Aggregator.cpp b/src/Interpreters/Aggregator.cpp
index 39fcb382e571..13c7f6ddb355 100644
--- a/src/Interpreters/Aggregator.cpp
+++ b/src/Interpreters/Aggregator.cpp
@@ -30,6 +30,7 @@
 #include <AggregateFunctions/AggregateFunctionState.h>
 #include <AggregateFunctions/AggregateFunctionResample.h>
 #include <Disks/StoragePolicy.h>
+#include <IO/Operators.h>
 
 
 namespace ProfileEvents
@@ -151,6 +152,42 @@ Block Aggregator::Params::getHeader(
     return materializeBlock(res);
 }
 
+void Aggregator::Params::explain(WriteBuffer & out, size_t indent) const
+{
+    Strings res;
+    const auto & header = src_header ? src_header
+                                     : intermediate_header;
+
+    String prefix(indent, ' ');
+
+    {
+        /// Dump keys.
+        out << prefix << "Keys: ";
+
+        bool first = true;
+        for (auto key : keys)
+        {
+            if (!first)
+                out << ", ";
+            first = false;
+
+            if (key >= header.columns())
+                out << "unknown position " << key;
+            else
+                out << header.getByPosition(key).name;
+        }
+
+        out << '
';
+    }
+
+    if (!aggregates.empty())
+    {
+        out << prefix << "Aggregates:
";
+
+        for (const auto & aggregate : aggregates)
+            aggregate.explain(out, indent + 4);
+    }
+}
 
 Aggregator::Aggregator(const Params & params_)
     : params(params_),
diff --git a/src/Interpreters/Aggregator.h b/src/Interpreters/Aggregator.h
index 7eb30bef7873..87480301c696 100644
--- a/src/Interpreters/Aggregator.h
+++ b/src/Interpreters/Aggregator.h
@@ -923,6 +923,9 @@ class Aggregator
         {
             return getHeader(src_header, intermediate_header, keys, aggregates, final);
         }
+
+        /// Returns keys and aggregated for EXPLAIN query
+        void explain(WriteBuffer & out, size_t indent) const;
     };
 
     Aggregator(const Params & params_);
diff --git a/src/Interpreters/InterpreterExplainQuery.cpp b/src/Interpreters/InterpreterExplainQuery.cpp
index 4890287e81e1..cf74be26fc8e 100644
--- a/src/Interpreters/InterpreterExplainQuery.cpp
+++ b/src/Interpreters/InterpreterExplainQuery.cpp
@@ -10,16 +10,25 @@
 #include <Parsers/DumpASTNode.h>
 #include <Parsers/queryToString.h>
 #include <Parsers/ASTExplainQuery.h>
-#include <Parsers/ASTTablesInSelectQuery.h>
 #include <Parsers/ASTSelectQuery.h>
+#include <IO/WriteBufferFromOStream.h>
 
 #include <Storages/StorageView.h>
 #include <sstream>
-
+#include <Processors/QueryPlan/QueryPlan.h>
+#include <Processors/printPipeline.h>
 
 namespace DB
 {
 
+namespace ErrorCodes
+{
+    extern const int INCORRECT_QUERY;
+    extern const int INVALID_SETTING_VALUE;
+    extern const int UNKNOWN_SETTING;
+    extern const int LOGICAL_ERROR;
+}
+
 namespace
 {
     struct ExplainAnalyzedSyntaxMatcher
@@ -79,10 +88,133 @@ Block InterpreterExplainQuery::getSampleBlock()
     return block;
 }
 
+/// Split str by line feed and write as separate row to ColumnString.
+static void fillColumn(IColumn & column, const std::string & str)
+{
+    size_t start = 0;
+    size_t end = 0;
+    size_t size = str.size();
+
+    while (end < size)
+    {
+        if (str[end] == '
')
+        {
+            column.insertData(str.data() + start, end - start);
+            start = end + 1;
+        }
+
+        ++end;
+    }
+
+    if (start < end)
+        column.insertData(str.data() + start, end - start);
+}
+
+namespace
+{
+
+/// Settings. Different for each explain type.
+
+struct QueryPlanSettings
+{
+    QueryPlan::ExplainPlanOptions query_plan_options;
+
+    constexpr static char name[] = "PLAN";
+
+    std::unordered_map<std::string, std::reference_wrapper<bool>> boolean_settings =
+    {
+            {"header", query_plan_options.header},
+            {"description", query_plan_options.description},
+            {"actions", query_plan_options.actions}
+    };
+};
+
+struct QueryPipelineSettings
+{
+    QueryPlan::ExplainPipelineOptions query_pipeline_options;
+    bool graph = false;
+    bool compact = true;
+
+    constexpr static char name[] = "PIPELINE";
+
+    std::unordered_map<std::string, std::reference_wrapper<bool>> boolean_settings =
+    {
+            {"header", query_pipeline_options.header},
+            {"graph", graph},
+            {"compact", compact},
+    };
+};
+
+template <typename Settings>
+struct ExplainSettings : public Settings
+{
+    using Settings::boolean_settings;
+
+    bool has(const std::string & name_) const
+    {
+        return boolean_settings.count(name_) > 0;
+    }
+
+    void setBooleanSetting(const std::string & name_, bool value)
+    {
+        auto it = boolean_settings.find(name_);
+        if (it == boolean_settings.end())
+            throw Exception("Unknown setting for ExplainSettings: " + name_, ErrorCodes::LOGICAL_ERROR);
+
+        it->second.get() = value;
+    }
+
+    std::string getSettingsList() const
+    {
+        std::string res;
+        for (const auto & setting : boolean_settings)
+        {
+            if (!res.empty())
+                res += ", ";
+
+            res += setting.first;
+        }
+
+        return res;
+    }
+};
+
+template <typename Settings>
+ExplainSettings<Settings> checkAndGetSettings(const ASTPtr & ast_settings)
+{
+    if (!ast_settings)
+        return {};
+
+    ExplainSettings<Settings> settings;
+    const auto & set_query = ast_settings->as<ASTSetQuery &>();
+
+    for (const auto & change : set_query.changes)
+    {
+        if (!settings.has(change.name))
+            throw Exception("Unknown setting \"" + change.name + "\" for EXPLAIN " + Settings::name + " query. "
+                            "Supported settings: " + settings.getSettingsList(), ErrorCodes::UNKNOWN_SETTING);
+
+        if (change.value.getType() != Field::Types::UInt64)
+            throw Exception("Invalid type " + std::string(change.value.getTypeName()) + " for setting \"" + change.name +
+                            "\" only boolean settings are supported", ErrorCodes::INVALID_SETTING_VALUE);
+
+        auto value = change.value.get<UInt64>();
+        if (value > 1)
+            throw Exception("Invalid value " + std::to_string(value) + " for setting \"" + change.name +
+                            "\". Only boolean settings are supported", ErrorCodes::INVALID_SETTING_VALUE);
+
+        settings.setBooleanSetting(change.name, value);
+    }
+
+    return settings;
+}
+
+}
 
 BlockInputStreamPtr InterpreterExplainQuery::executeImpl()
 {
     const auto & ast = query->as<ASTExplainQuery &>();
+
     Block sample_block = getSampleBlock();
     MutableColumns res_columns = sample_block.cloneEmptyColumns();
 
@@ -90,17 +222,63 @@ BlockInputStreamPtr InterpreterExplainQuery::executeImpl()
 
     if (ast.getKind() == ASTExplainQuery::ParsedAST)
     {
-        dumpAST(ast, ss);
+        if (ast.getSettings())
+            throw Exception("Settings are not supported for EXPLAIN AST query.", ErrorCodes::UNKNOWN_SETTING);
+
+        dumpAST(*ast.getExplainedQuery(), ss);
     }
     else if (ast.getKind() == ASTExplainQuery::AnalyzedSyntax)
     {
+        if (ast.getSettings())
+            throw Exception("Settings are not supported for EXPLAIN SYNTAX query.", ErrorCodes::UNKNOWN_SETTING);
+
         ExplainAnalyzedSyntaxVisitor::Data data{.context = context};
         ExplainAnalyzedSyntaxVisitor(data).visit(query);
 
-        ast.children.at(0)->format(IAST::FormatSettings(ss, false));
+        ast.getExplainedQuery()->format(IAST::FormatSettings(ss, false));
+    }
+    else if (ast.getKind() == ASTExplainQuery::QueryPlan)
+    {
+        if (!dynamic_cast<const ASTSelectWithUnionQuery *>(ast.getExplainedQuery().get()))
+            throw Exception("Only SELECT is supported for EXPLAIN query", ErrorCodes::INCORRECT_QUERY);
+
+        auto settings = checkAndGetSettings<QueryPlanSettings>(ast.getSettings());
+        QueryPlan plan;
+
+        InterpreterSelectWithUnionQuery interpreter(ast.getExplainedQuery(), context, SelectQueryOptions());
+        interpreter.buildQueryPlan(plan);
+
+        WriteBufferFromOStream buffer(ss);
+        plan.explainPlan(buffer, settings.query_plan_options);
+    }
+    else if (ast.getKind() == ASTExplainQuery::QueryPipeline)
+    {
+        if (!dynamic_cast<const ASTSelectWithUnionQuery *>(ast.getExplainedQuery().get()))
+            throw Exception("Only SELECT is supported for EXPLAIN query", ErrorCodes::INCORRECT_QUERY);
+
+        auto settings = checkAndGetSettings<QueryPipelineSettings>(ast.getSettings());
+        QueryPlan plan;
+
+        InterpreterSelectWithUnionQuery interpreter(ast.getExplainedQuery(), context, SelectQueryOptions());
+        interpreter.buildQueryPlan(plan);
+        auto pipeline = plan.buildQueryPipeline();
+
+        WriteBufferFromOStream buffer(ss);
+
+        if (settings.graph)
+        {
+            if (settings.compact)
+                printPipelineCompact(pipeline->getProcessors(), buffer, settings.query_pipeline_options.header);
+            else
+                printPipeline(pipeline->getProcessors(), buffer);
+        }
+        else
+        {
+            plan.explainPipeline(buffer, settings.query_pipeline_options);
+        }
     }
 
-    res_columns[0]->insert(ss.str());
+    fillColumn(*res_columns[0], ss.str());
 
     return std::make_shared<OneBlockInputStream>(sample_block.cloneWithColumns(std::move(res_columns)));
 }
diff --git a/src/Interpreters/InterpreterSelectQuery.cpp b/src/Interpreters/InterpreterSelectQuery.cpp
index dff40e56ae8d..e0abc80b51d5 100644
--- a/src/Interpreters/InterpreterSelectQuery.cpp
+++ b/src/Interpreters/InterpreterSelectQuery.cpp
@@ -54,7 +54,7 @@
 #include <Processors/QueryPlan/CubeStep.h>
 #include <Processors/QueryPlan/FillingStep.h>
 #include <Processors/QueryPlan/ExtremesStep.h>
-#include <Processors/QueryPlan/OffsetsStep.h>
+#include <Processors/QueryPlan/OffsetStep.h>
 #include <Processors/QueryPlan/FinishSortingStep.h>
 #include <Processors/QueryPlan/QueryPlan.h>
 
@@ -962,7 +962,7 @@ void InterpreterSelectQuery::executeImpl(QueryPlan & query_plan, const BlockInpu
                   */
 
                 if (!expressions.first_stage && !expressions.need_aggregate && !(query.group_by_with_totals && !aggregate_final))
-                    executeMergeSorted(query_plan, "before ORDER BY");
+                    executeMergeSorted(query_plan, "for ORDER BY");
                 else    /// Otherwise, just sort.
                     executeOrder(query_plan, query_info.input_order_info);
             }
@@ -1589,7 +1589,7 @@ void InterpreterSelectQuery::executeOrder(QueryPlan & query_plan, InputOrderInfo
             limit,
             SizeLimits(settings.max_rows_to_sort, settings.max_bytes_to_sort, settings.sort_overflow_mode));
 
-    partial_sorting->setStepDescription("Sort each block before ORDER BY");
+    partial_sorting->setStepDescription("Sort each block for ORDER BY");
     query_plan.addStep(std::move(partial_sorting));
 
     /// Merge the sorted blocks.
@@ -1600,11 +1600,11 @@ void InterpreterSelectQuery::executeOrder(QueryPlan & query_plan, InputOrderInfo
             settings.max_bytes_before_external_sort, context->getTemporaryVolume(),
             settings.min_free_disk_space_for_temporary_data);
 
-    merge_sorting_step->setStepDescription("Merge sorted blocks before ORDER BY");
+    merge_sorting_step->setStepDescription("Merge sorted blocks for ORDER BY");
     query_plan.addStep(std::move(merge_sorting_step));
 
     /// If there are several streams, we merge them into one
-    executeMergeSorted(query_plan, output_order_descr, limit, "before ORDER BY");
+    executeMergeSorted(query_plan, output_order_descr, limit, "for ORDER BY");
 }
 
 
@@ -1785,7 +1785,7 @@ void InterpreterSelectQuery::executeOffset(QueryPlan & query_plan)
         UInt64 limit_offset;
         std::tie(limit_length, limit_offset) = getLimitLengthAndOffset(query, *context);
 
-        auto offsets_step = std::make_unique<OffsetsStep>(query_plan.getCurrentDataStream(), limit_offset);
+        auto offsets_step = std::make_unique<OffsetStep>(query_plan.getCurrentDataStream(), limit_offset);
         query_plan.addStep(std::move(offsets_step));
     }
 }
diff --git a/src/Interpreters/ya.make b/src/Interpreters/ya.make
index 394c9c360644..3df3cb7f3dca 100644
--- a/src/Interpreters/ya.make
+++ b/src/Interpreters/ya.make
@@ -18,6 +18,7 @@ SRCS(
     ActionsVisitor.cpp
     addMissingDefaults.cpp
     addTypeConversionToAST.cpp
+    AggregateDescription.cpp
     Aggregator.cpp
     AnyInputOptimize.cpp
     ArithmeticOperationsInAgrFuncOptimize.cpp
diff --git a/src/Parsers/ASTExplainQuery.h b/src/Parsers/ASTExplainQuery.h
index d7a40a2eb859..0c376e270d45 100644
--- a/src/Parsers/ASTExplainQuery.h
+++ b/src/Parsers/ASTExplainQuery.h
@@ -1,6 +1,6 @@
 #pragma once
 
-#include <Parsers/IAST.h>
+#include <Parsers/ASTQueryWithOutput.h>
 
 
 namespace DB
@@ -8,45 +8,78 @@ namespace DB
 
 
 /// AST, EXPLAIN or other query with meaning of explanation query instead of execution
-class ASTExplainQuery : public IAST
+class ASTExplainQuery : public ASTQueryWithOutput
 {
 public:
     enum ExplainKind
     {
-        ParsedAST,
-        AnalyzedSyntax,
+        ParsedAST, /// 'EXPLAIN AST SELECT ...'
+        AnalyzedSyntax, /// 'EXPLAIN SYNTAX SELECT ...'
+        QueryPlan, /// 'EXPLAIN SELECT ...'
+        QueryPipeline, /// 'EXPLAIN PIPELINE ...'
     };
 
-    ASTExplainQuery(ExplainKind kind_)
-        : kind(kind_)
-    {}
+    ASTExplainQuery(ExplainKind kind_, bool old_syntax_)
+        : kind(kind_), old_syntax(old_syntax_)
+    {
+    }
 
-    String getID(char delim) const override { return "Explain" + (delim + toString(kind)); }
+    String getID(char delim) const override { return "Explain" + (delim + toString(kind, old_syntax)); }
     ExplainKind getKind() const { return kind; }
     ASTPtr clone() const override
     {
         auto res = std::make_shared<ASTExplainQuery>(*this);
         res->children.clear();
         res->children.push_back(children[0]->clone());
+        cloneOutputOptions(*res);
         return res;
     }
 
+    void setExplainedQuery(ASTPtr query_)
+    {
+        children.emplace_back(query_);
+        query = std::move(query_);
+    }
+
+    void setSettings(ASTPtr settings_)
+    {
+        children.emplace_back(settings_);
+        ast_settings = std::move(settings_);
+    }
+
+    const ASTPtr & getExplainedQuery() const { return query; }
+    const ASTPtr & getSettings() const { return ast_settings; }
+
 protected:
-    void formatImpl(const FormatSettings & settings, FormatState & state, FormatStateStacked frame) const override
+    void formatQueryImpl(const FormatSettings & settings, FormatState & state, FormatStateStacked frame) const override
     {
-        settings.ostr << (settings.hilite ? hilite_keyword : "") << toString(kind) << (settings.hilite ? hilite_none : "") << " ";
-        children.at(0)->formatImpl(settings, state, frame);
+        settings.ostr << (settings.hilite ? hilite_keyword : "") << toString(kind, old_syntax) << (settings.hilite ? hilite_none : "");
+
+        if (ast_settings)
+        {
+            settings.ostr << ' ';
+            ast_settings->formatImpl(settings, state, frame);
+        }
+
+        settings.ostr << settings.nl_or_ws;
+        query->formatImpl(settings, state, frame);
     }
 
 private:
     ExplainKind kind;
+    bool old_syntax; /// "EXPLAIN AST" -> "AST", "EXPLAIN SYNTAX" -> "ANALYZE"
+
+    ASTPtr query;
+    ASTPtr ast_settings;
 
-    static String toString(ExplainKind kind)
+    static String toString(ExplainKind kind, bool old_syntax)
     {
         switch (kind)
         {
-            case ParsedAST: return "AST";
-            case AnalyzedSyntax: return "ANALYZE";
+            case ParsedAST: return old_syntax ? "AST" : "EXPLAIN AST";
+            case AnalyzedSyntax: return old_syntax ? "ANALYZE" : "EXPLAIN SYNTAX";
+            case QueryPlan: return "EXPLAIN";
+            case QueryPipeline: return "EXPLAIN PIPELINE";
         }
 
         __builtin_unreachable();
diff --git a/src/Parsers/ParserExplainQuery.cpp b/src/Parsers/ParserExplainQuery.cpp
new file mode 100644
index 000000000000..c6792d6094b5
--- /dev/null
+++ b/src/Parsers/ParserExplainQuery.cpp
@@ -0,0 +1,72 @@
+#include <Parsers/ParserExplainQuery.h>
+#include <Parsers/ASTExplainQuery.h>
+#include <Parsers/CommonParsers.h>
+#include <Parsers/ParserSelectWithUnionQuery.h>
+#include <Parsers/ParserSetQuery.h>
+
+namespace DB
+{
+
+bool ParserExplainQuery::parseImpl(Pos & pos, ASTPtr & node, Expected & expected)
+{
+    ASTExplainQuery::ExplainKind kind;
+    bool old_syntax = false;
+
+    ParserKeyword s_ast("AST");
+    ParserKeyword s_analyze("ANALYZE");
+    ParserKeyword s_explain("EXPLAIN");
+    ParserKeyword s_syntax("SYNTAX");
+    ParserKeyword s_pipeline("PIPELINE");
+    ParserKeyword s_plan("PLAN");
+
+    if (enable_debug_queries && s_ast.ignore(pos, expected))
+    {
+        old_syntax = true;
+        kind = ASTExplainQuery::ExplainKind::ParsedAST;
+    }
+    else if (enable_debug_queries && s_analyze.ignore(pos, expected))
+    {
+        old_syntax = true;
+        kind = ASTExplainQuery::ExplainKind::AnalyzedSyntax;
+    }
+    else if (s_explain.ignore(pos, expected))
+    {
+        kind = ASTExplainQuery::QueryPlan;
+
+        if (s_ast.ignore(pos, expected))
+            kind = ASTExplainQuery::ExplainKind::ParsedAST;
+        else if (s_syntax.ignore(pos, expected))
+            kind = ASTExplainQuery::ExplainKind::AnalyzedSyntax;
+        else if (s_pipeline.ignore(pos, expected))
+            kind = ASTExplainQuery::ExplainKind::QueryPipeline;
+        else if (s_plan.ignore(pos, expected))
+            kind = ASTExplainQuery::ExplainKind::QueryPlan;
+    }
+    else
+        return false;
+
+    auto explain_query = std::make_shared<ASTExplainQuery>(kind, old_syntax);
+
+    {
+        ASTPtr settings;
+        ParserSetQuery parser_settings(true);
+
+        auto begin = pos;
+        if (parser_settings.parse(pos, settings, expected))
+            explain_query->setSettings(std::move(settings));
+        else
+            pos = begin;
+    }
+
+    ParserSelectWithUnionQuery select_p;
+    ASTPtr query;
+    if (!select_p.parse(pos, query, expected))
+        return false;
+
+    explain_query->setExplainedQuery(std::move(query));
+
+    node = std::move(explain_query);
+    return true;
+}
+
+}
diff --git a/src/Parsers/ParserExplainQuery.h b/src/Parsers/ParserExplainQuery.h
new file mode 100644
index 000000000000..224f466c1a16
--- /dev/null
+++ b/src/Parsers/ParserExplainQuery.h
@@ -0,0 +1,25 @@
+#pragma once
+
+#include <Parsers/IParserBase.h>
+
+namespace DB
+{
+
+
+class ParserExplainQuery : public IParserBase
+{
+public:
+    explicit ParserExplainQuery(bool enable_debug_queries_ = false)
+        : enable_debug_queries(enable_debug_queries_)
+    {
+    }
+
+protected:
+    const char * getName() const override { return "EXPLAIN"; }
+    bool parseImpl(Pos & pos, ASTPtr & node, Expected & expected) override;
+
+private:
+    bool enable_debug_queries;
+};
+
+}
diff --git a/src/Parsers/ParserQueryWithOutput.cpp b/src/Parsers/ParserQueryWithOutput.cpp
index c7a42b5bdad6..6c356955932f 100644
--- a/src/Parsers/ParserQueryWithOutput.cpp
+++ b/src/Parsers/ParserQueryWithOutput.cpp
@@ -19,6 +19,7 @@
 #include <Parsers/ParserShowCreateAccessEntityQuery.h>
 #include <Parsers/ParserShowGrantsQuery.h>
 #include <Parsers/ParserShowPrivilegesQuery.h>
+#include <Parsers/ParserExplainQuery.h>
 
 
 namespace DB
@@ -44,21 +45,13 @@ bool ParserQueryWithOutput::parseImpl(Pos & pos, ASTPtr & node, Expected & expec
     ParserShowCreateAccessEntityQuery show_create_access_entity_p;
     ParserShowGrantsQuery show_grants_p;
     ParserShowPrivilegesQuery show_privileges_p;
+    ParserExplainQuery explain_p(enable_debug_queries);
 
     ASTPtr query;
 
-    ParserKeyword s_ast("AST");
-    ParserKeyword s_analyze("ANALYZE");
-    bool explain_ast = false;
-    bool analyze_syntax = false;
-
-    if (enable_explain && s_ast.ignore(pos, expected))
-        explain_ast = true;
-
-    if (enable_explain && s_analyze.ignore(pos, expected))
-        analyze_syntax = true;
-
-    bool parsed = select_p.parse(pos, query, expected)
+    bool parsed =
+           explain_p.parse(pos, query, expected)
+        || select_p.parse(pos, query, expected)
         || show_create_access_entity_p.parse(pos, query, expected) /// should be before `show_tables_p`
         || show_tables_p.parse(pos, query, expected)
         || table_p.parse(pos, query, expected)
@@ -116,19 +109,17 @@ bool ParserQueryWithOutput::parseImpl(Pos & pos, ASTPtr & node, Expected & expec
         query_with_output.children.push_back(query_with_output.settings_ast);
     }
 
-    if (explain_ast)
-    {
-        node = std::make_shared<ASTExplainQuery>(ASTExplainQuery::ParsedAST);
-        node->children.push_back(query);
-    }
-    else if (analyze_syntax)
+    if (auto * ast = query->as<ASTExplainQuery>())
     {
-        node = std::make_shared<ASTExplainQuery>(ASTExplainQuery::AnalyzedSyntax);
-        node->children.push_back(query);
+        /// Set default format TSV, because output is a single string column.
+        if (!ast->format)
+        {
+            ast->format = std::make_shared<ASTIdentifier>("TSV");
+            ast->children.push_back(ast->format);
+        }
     }
-    else
-        node = query;
 
+    node = std::move(query);
     return true;
 }
 
diff --git a/src/Parsers/ParserQueryWithOutput.h b/src/Parsers/ParserQueryWithOutput.h
index 3163bc38437c..d0962862c42d 100644
--- a/src/Parsers/ParserQueryWithOutput.h
+++ b/src/Parsers/ParserQueryWithOutput.h
@@ -11,8 +11,9 @@ namespace DB
 class ParserQueryWithOutput : public IParserBase
 {
 public:
-    ParserQueryWithOutput(bool enable_explain_ = false)
-        : enable_explain(enable_explain_)
+    /// enable_debug_queries flag enables queries 'AST SELECT' and 'ANALYZE SELECT'
+    explicit ParserQueryWithOutput(bool enable_debug_queries_ = false)
+        : enable_debug_queries(enable_debug_queries_)
     {}
 
 protected:
@@ -21,7 +22,7 @@ class ParserQueryWithOutput : public IParserBase
     bool parseImpl(Pos & pos, ASTPtr & node, Expected & expected) override;
 
 private:
-    bool enable_explain;
+    bool enable_debug_queries;
 };
 
 }
diff --git a/src/Parsers/ya.make b/src/Parsers/ya.make
index cf1ff9f5a022..c7029426a49a 100644
--- a/src/Parsers/ya.make
+++ b/src/Parsers/ya.make
@@ -84,6 +84,7 @@ SRCS(
     ParserDictionaryAttributeDeclaration.cpp
     ParserDropAccessEntityQuery.cpp
     ParserDropQuery.cpp
+    ParserExplainQuery.cpp
     ParserGrantQuery.cpp
     ParserInsertQuery.cpp
     ParserKillQueryQuery.cpp
diff --git a/src/Processors/IProcessor.h b/src/Processors/IProcessor.h
index a9bd73d8026e..e9148dd50756 100644
--- a/src/Processors/IProcessor.h
+++ b/src/Processors/IProcessor.h
@@ -15,6 +15,8 @@ namespace ErrorCodes
     extern const int NOT_IMPLEMENTED;
 }
 
+class IQueryPlanStep;
+
 class IProcessor;
 using ProcessorPtr = std::shared_ptr<IProcessor>;
 using Processors = std::vector<ProcessorPtr>;
@@ -288,6 +290,16 @@ class IProcessor
     void enableQuota() { has_quota = true; }
     bool hasQuota() const { return has_quota; }
 
+    /// Step of QueryPlan from which processor was created.
+    void setQueryPlanStep(IQueryPlanStep * step, size_t group = 0)
+    {
+        query_plan_step = step;
+        query_plan_step_group = group;
+    }
+
+    IQueryPlanStep * getQueryPlanStep() const { return query_plan_step; }
+    size_t getQueryPlanStepGroup() const { return query_plan_step_group; }
+
 protected:
     virtual void onCancel() {}
 
@@ -299,6 +311,9 @@ class IProcessor
     size_t stream_number = NO_STREAM;
 
     bool has_quota = false;
+
+    IQueryPlanStep * query_plan_step = nullptr;
+    size_t query_plan_step_group = 0;
 };
 
 
diff --git a/src/Processors/QueryPipeline.cpp b/src/Processors/QueryPipeline.cpp
index 7ad7bddb1048..fa04082c82ff 100644
--- a/src/Processors/QueryPipeline.cpp
+++ b/src/Processors/QueryPipeline.cpp
@@ -69,7 +69,8 @@ void QueryPipeline::init(Pipe pipe)
     init(std::move(pipes));
 }
 
-static OutputPort * uniteExtremes(const std::vector<OutputPort *> & ports, const Block & header, Processors & processors)
+static OutputPort * uniteExtremes(const std::vector<OutputPort *> & ports, const Block & header,
+                                  QueryPipeline::ProcessorsContainer & processors)
 {
     /// Here we calculate extremes for extremes in case we unite several pipelines.
     /// Example: select number from numbers(2) union all select number from numbers(3)
@@ -90,14 +91,15 @@ static OutputPort * uniteExtremes(const std::vector<OutputPort *> & ports, const
     connect(resize->getOutputs().front(), extremes->getInputPort());
     connect(extremes->getOutputPort(), sink->getPort());
 
-    processors.emplace_back(std::move(resize));
-    processors.emplace_back(std::move(extremes));
-    processors.emplace_back(std::move(sink));
+    processors.emplace(std::move(resize));
+    processors.emplace(std::move(extremes));
+    processors.emplace(std::move(sink));
 
     return extremes_port;
 }
 
-static OutputPort * uniteTotals(const std::vector<OutputPort *> & ports, const Block & header, Processors & processors)
+static OutputPort * uniteTotals(const std::vector<OutputPort *> & ports, const Block & header,
+                                QueryPipeline::ProcessorsContainer & processors)
 {
     /// Calculate totals fro several streams.
     /// Take totals from first sources which has any, skip others.
@@ -115,8 +117,8 @@ static OutputPort * uniteTotals(const std::vector<OutputPort *> & ports, const B
 
     connect(concat->getOutputs().front(), limit->getInputPort());
 
-    processors.emplace_back(std::move(concat));
-    processors.emplace_back(std::move(limit));
+    processors.emplace(std::move(concat));
+    processors.emplace(std::move(limit));
 
     return totals_port;
 }
@@ -167,8 +169,7 @@ void QueryPipeline::init(Pipes pipes)
         }
 
         streams.addStream(&pipe.getPort(), pipe.maxParallelStreams());
-        auto cur_processors = std::move(pipe).detachProcessors();
-        processors.insert(processors.end(), cur_processors.begin(), cur_processors.end());
+        processors.emplace(std::move(pipe).detachProcessors());
     }
 
     if (!totals.empty())
@@ -242,7 +243,7 @@ void QueryPipeline::addSimpleTransformImpl(const TProcessorGetter & getter)
         {
             connect(*stream, transform->getInputs().front());
             stream = &transform->getOutputs().front();
-            processors.emplace_back(std::move(transform));
+            processors.emplace(std::move(transform));
         }
     };
 
@@ -293,7 +294,7 @@ void QueryPipeline::setSinks(const ProcessorGetterWithStreamKind & getter)
             transform = std::make_shared<NullSink>(stream->getHeader());
 
         connect(*stream, transform->getInputs().front());
-        processors.emplace_back(std::move(transform));
+        processors.emplace(std::move(transform));
     };
 
     for (auto & stream : streams)
@@ -339,7 +340,7 @@ void QueryPipeline::addPipe(Processors pipe)
             header = output.getHeader();
     }
 
-    processors.insert(processors.end(), pipe.begin(), pipe.end());
+    processors.emplace(pipe);
     current_header = std::move(header);
 }
 
@@ -352,7 +353,7 @@ void QueryPipeline::addDelayedStream(ProcessorPtr source)
 
     IProcessor::PortNumbers delayed_streams = { streams.size() };
     streams.addStream(&source->getOutputs().front(), 0);
-    processors.emplace_back(std::move(source));
+    processors.emplace(std::move(source));
 
     auto processor = std::make_shared<DelayedPortsProcessor>(current_header, streams.size(), delayed_streams);
     addPipe({ std::move(processor) });
@@ -383,7 +384,7 @@ void QueryPipeline::resize(size_t num_streams, bool force, bool strict)
     for (auto & output : resize->getOutputs())
         streams.addStream(&output, 0);
 
-    processors.emplace_back(std::move(resize));
+    processors.emplace(std::move(resize));
 }
 
 void QueryPipeline::enableQuotaForCurrentStreams()
@@ -412,7 +413,7 @@ void QueryPipeline::addTotalsHavingTransform(ProcessorPtr transform)
     streams.assign({ &outputs.front() });
     totals_having_port = &outputs.back();
     current_header = outputs.front().getHeader();
-    processors.emplace_back(std::move(transform));
+    processors.emplace(std::move(transform));
 }
 
 void QueryPipeline::addDefaultTotals()
@@ -434,7 +435,7 @@ void QueryPipeline::addDefaultTotals()
 
     auto source = std::make_shared<SourceFromSingleChunk>(current_header, Chunk(std::move(columns), 1));
     totals_having_port = &source->getPort();
-    processors.emplace_back(source);
+    processors.emplace(std::move(source));
 }
 
 void QueryPipeline::addTotals(ProcessorPtr source)
@@ -448,7 +449,7 @@ void QueryPipeline::addTotals(ProcessorPtr source)
     assertBlocksHaveEqualStructure(current_header, source->getOutputs().front().getHeader(), "QueryPipeline");
 
     totals_having_port = &source->getOutputs().front();
-    processors.emplace_back(std::move(source));
+    processors.emplace(std::move(source));
 }
 
 void QueryPipeline::dropTotalsAndExtremes()
@@ -457,7 +458,7 @@ void QueryPipeline::dropTotalsAndExtremes()
     {
         auto null_sink = std::make_shared<NullSink>(port->getHeader());
         connect(*port, null_sink->getPort());
-        processors.emplace_back(std::move(null_sink));
+        processors.emplace(std::move(null_sink));
         port = nullptr;
     };
 
@@ -486,7 +487,7 @@ void QueryPipeline::addExtremesTransform()
         stream = &transform->getOutputPort();
         extremes.push_back(&transform->getExtremesPort());
 
-        processors.emplace_back(std::move(transform));
+        processors.emplace(std::move(transform));
     }
 
     if (extremes.size() == 1)
@@ -510,8 +511,8 @@ void QueryPipeline::addCreatingSetsTransform(ProcessorPtr transform)
     connect(*streams.back(), concat->getInputs().back());
 
     streams.assign({ &concat->getOutputs().front() });
-    processors.emplace_back(std::move(transform));
-    processors.emplace_back(std::move(concat));
+    processors.emplace(std::move(transform));
+    processors.emplace(std::move(concat));
 }
 
 void QueryPipeline::setOutputFormat(ProcessorPtr output)
@@ -538,17 +539,17 @@ void QueryPipeline::setOutputFormat(ProcessorPtr output)
     {
         auto null_source = std::make_shared<NullSource>(totals.getHeader());
         totals_having_port = &null_source->getPort();
-        processors.emplace_back(std::move(null_source));
+        processors.emplace(std::move(null_source));
     }
 
     if (!extremes_port)
     {
         auto null_source = std::make_shared<NullSource>(extremes.getHeader());
         extremes_port = &null_source->getPort();
-        processors.emplace_back(std::move(null_source));
+        processors.emplace(std::move(null_source));
     }
 
-    processors.emplace_back(std::move(output));
+    processors.emplace(std::move(output));
 
     connect(*streams.front(), main);
     connect(*totals_having_port, totals);
@@ -587,6 +588,7 @@ void QueryPipeline::unitePipelines(
     {
         auto & pipeline = *pipeline_ptr;
         pipeline.checkInitialized();
+        pipeline.processors.setCollectedProcessors(processors.getCollectedProcessors());
 
         if (!pipeline.isCompleted())
         {
@@ -604,7 +606,7 @@ void QueryPipeline::unitePipelines(
 
             connect(*pipeline.extremes_port, converting->getInputPort());
             extremes.push_back(&converting->getOutputPort());
-            processors.push_back(std::move(converting));
+            processors.emplace(std::move(converting));
         }
 
         /// Take totals only from first port.
@@ -615,10 +617,13 @@ void QueryPipeline::unitePipelines(
 
             connect(*pipeline.totals_having_port, converting->getInputPort());
             totals.push_back(&converting->getOutputPort());
-            processors.push_back(std::move(converting));
+            processors.emplace(std::move(converting));
         }
 
-        processors.insert(processors.end(), pipeline.processors.begin(), pipeline.processors.end());
+        auto * collector = processors.setCollectedProcessors(nullptr);
+        processors.emplace(pipeline.processors.detach());
+        processors.setCollectedProcessors(collector);
+
         streams.addStreams(pipeline.streams);
 
         table_locks.insert(table_locks.end(), std::make_move_iterator(pipeline.table_locks.begin()), std::make_move_iterator(pipeline.table_locks.end()));
@@ -649,7 +654,7 @@ void QueryPipeline::unitePipelines(
 
 void QueryPipeline::setProgressCallback(const ProgressCallback & callback)
 {
-    for (auto & processor : processors)
+    for (auto & processor : processors.get())
     {
         if (auto * source = dynamic_cast<ISourceWithProgress *>(processor.get()))
             source->setProgressCallback(callback);
@@ -663,7 +668,7 @@ void QueryPipeline::setProcessListElement(QueryStatus * elem)
 {
     process_list_element = elem;
 
-    for (auto & processor : processors)
+    for (auto & processor : processors.get())
     {
         if (auto * source = dynamic_cast<ISourceWithProgress *>(processor.get()))
             source->setProcessListElement(elem);
@@ -775,7 +780,7 @@ Pipe QueryPipeline::getPipe() &&
 
 Pipes QueryPipeline::getPipes() &&
 {
-    Pipe pipe(std::move(processors), streams.at(0), totals_having_port, extremes_port);
+    Pipe pipe(processors.detach(), streams.at(0), totals_having_port, extremes_port);
     pipe.max_parallel_streams = streams.maxParallelStreams();
 
     for (auto & lock : table_locks)
@@ -807,7 +812,7 @@ PipelineExecutorPtr QueryPipeline::execute()
     if (!isCompleted())
         throw Exception("Cannot execute pipeline because it is not completed.", ErrorCodes::LOGICAL_ERROR);
 
-    return std::make_shared<PipelineExecutor>(processors, process_list_element);
+    return std::make_shared<PipelineExecutor>(processors.get(), process_list_element);
 }
 
 QueryPipeline & QueryPipeline::operator= (QueryPipeline && rhs)
@@ -837,4 +842,49 @@ QueryPipeline & QueryPipeline::operator= (QueryPipeline && rhs)
     return *this;
 }
 
+void QueryPipeline::ProcessorsContainer::emplace(ProcessorPtr processor)
+{
+    if (collected_processors)
+        collected_processors->emplace_back(processor);
+
+    processors.emplace_back(std::move(processor));
+}
+
+void QueryPipeline::ProcessorsContainer::emplace(Processors processors_)
+{
+    for (auto & processor : processors_)
+        emplace(std::move(processor));
+}
+
+Processors * QueryPipeline::ProcessorsContainer::setCollectedProcessors(Processors * collected_processors_)
+{
+    if (collected_processors && collected_processors_)
+        throw Exception("Cannot set collected processors to QueryPipeline because "
+                        "another one object was already created for current pipeline." , ErrorCodes::LOGICAL_ERROR);
+
+    std::swap(collected_processors, collected_processors_);
+    return collected_processors_;
+}
+
+QueryPipelineProcessorsCollector::QueryPipelineProcessorsCollector(QueryPipeline & pipeline_, IQueryPlanStep * step_)
+    : pipeline(pipeline_), step(step_)
+{
+    pipeline.processors.setCollectedProcessors(&processors);
+}
+
+QueryPipelineProcessorsCollector::~QueryPipelineProcessorsCollector()
+{
+    pipeline.processors.setCollectedProcessors(nullptr);
+}
+
+Processors QueryPipelineProcessorsCollector::detachProcessors(size_t group)
+{
+    for (auto & processor : processors)
+        processor->setQueryPlanStep(step, group);
+
+    Processors res;
+    res.swap(processors);
+    return res;
+}
+
 }
diff --git a/src/Processors/QueryPipeline.h b/src/Processors/QueryPipeline.h
index d1342385292a..7990b0b79f52 100644
--- a/src/Processors/QueryPipeline.h
+++ b/src/Processors/QueryPipeline.h
@@ -18,6 +18,8 @@ class Context;
 
 class IOutputFormat;
 
+class QueryPipelineProcessorsCollector;
+
 class QueryPipeline
 {
 private:
@@ -69,6 +71,27 @@ class QueryPipeline
     };
 
 public:
+
+    class ProcessorsContainer
+    {
+    public:
+        bool empty() const { return processors.empty(); }
+        void emplace(ProcessorPtr processor);
+        void emplace(Processors processors_);
+        Processors * getCollectedProcessors() const { return collected_processors; }
+        Processors * setCollectedProcessors(Processors * collected_processors);
+        Processors & get() { return processors; }
+        const Processors & get() const { return processors; }
+        Processors detach() { return std::move(processors); }
+    private:
+        /// All added processors.
+        Processors processors;
+
+        /// If is set, all newly created processors will be added to this too.
+        /// It is needed for debug. See QueryPipelineProcessorsCollector below.
+        Processors * collected_processors = nullptr;
+    };
+
     QueryPipeline() = default;
     QueryPipeline(QueryPipeline &&) = default;
     ~QueryPipeline() = default;
@@ -136,6 +159,8 @@ class QueryPipeline
 
     void enableQuotaForCurrentStreams();
 
+    /// Unite several pipelines together. Result pipeline would have common_header structure.
+    /// If collector is used, it will collect only newly-added processors, but not processors from pipelines.
     void unitePipelines(std::vector<std::unique_ptr<QueryPipeline>> pipelines, const Block & common_header);
 
     PipelineExecutorPtr execute();
@@ -180,6 +205,9 @@ class QueryPipeline
     Pipe getPipe() &&;
     Pipes getPipes() &&;
 
+    /// Get internal processors.
+    const Processors & getProcessors() const { return processors.get(); }
+
 private:
     /// Destruction order: processors, header, locks, temporary storages, local contexts
 
@@ -193,8 +221,7 @@ class QueryPipeline
     /// Common header for each stream.
     Block current_header;
 
-    /// All added processors.
-    Processors processors;
+    ProcessorsContainer processors;
 
     /// Port for each independent "stream".
     Streams streams;
@@ -222,6 +249,24 @@ class QueryPipeline
     void addSimpleTransformImpl(const TProcessorGetter & getter);
 
     void initRowsBeforeLimit();
+
+    friend class QueryPipelineProcessorsCollector;
+};
+
+/// This is a small class which collects newly added processors to QueryPipeline.
+/// Pipeline must live longer that this class.
+class QueryPipelineProcessorsCollector
+{
+public:
+    explicit QueryPipelineProcessorsCollector(QueryPipeline & pipeline_, IQueryPlanStep * step_ = nullptr);
+    ~QueryPipelineProcessorsCollector();
+
+    Processors detachProcessors(size_t group = 0);
+
+private:
+    QueryPipeline & pipeline;
+    IQueryPlanStep * step;
+    Processors processors;
 };
 
 }
diff --git a/src/Processors/QueryPlan/AddingDelayedSourceStep.cpp b/src/Processors/QueryPlan/AddingDelayedSourceStep.cpp
index 8aeb7485c71e..9326d7808baf 100644
--- a/src/Processors/QueryPlan/AddingDelayedSourceStep.cpp
+++ b/src/Processors/QueryPlan/AddingDelayedSourceStep.cpp
@@ -24,6 +24,7 @@ AddingDelayedSourceStep::AddingDelayedSourceStep(
 
 void AddingDelayedSourceStep::transformPipeline(QueryPipeline & pipeline)
 {
+    source->setQueryPlanStep(this);
     pipeline.addDelayedStream(source);
 }
 
diff --git a/src/Processors/QueryPlan/AggregatingStep.cpp b/src/Processors/QueryPlan/AggregatingStep.cpp
index cc6e1833a724..d8163cfa1cab 100644
--- a/src/Processors/QueryPlan/AggregatingStep.cpp
+++ b/src/Processors/QueryPlan/AggregatingStep.cpp
@@ -27,7 +27,7 @@ AggregatingStep::AggregatingStep(
     bool storage_has_evenly_distributed_read_,
     InputOrderInfoPtr group_by_info_,
     SortDescription group_by_sort_description_)
-    : ITransformingStep(input_stream_, params_.getHeader(final_), getTraits())
+    : ITransformingStep(input_stream_, params_.getHeader(final_), getTraits(), false)
     , params(std::move(params_))
     , final(std::move(final_))
     , max_block_size(max_block_size_)
@@ -41,6 +41,8 @@ AggregatingStep::AggregatingStep(
 
 void AggregatingStep::transformPipeline(QueryPipeline & pipeline)
 {
+    QueryPipelineProcessorsCollector collector(pipeline, this);
+
     /// Forget about current totals and extremes. They will be calculated again after aggregation if needed.
     pipeline.dropTotalsAndExtremes();
 
@@ -76,6 +78,8 @@ void AggregatingStep::transformPipeline(QueryPipeline & pipeline)
                     return std::make_shared<AggregatingInOrderTransform>(header, transform_params, group_by_sort_description, max_block_size, many_data, counter++);
                 });
 
+                aggregating_in_order = collector.detachProcessors(0);
+
                 for (auto & column_description : group_by_sort_description)
                 {
                     if (!column_description.column_name.empty())
@@ -92,6 +96,7 @@ void AggregatingStep::transformPipeline(QueryPipeline & pipeline)
                     max_block_size);
 
                 pipeline.addPipe({ std::move(transform) });
+                aggregating_sorted = collector.detachProcessors(1);
             }
             else
             {
@@ -99,6 +104,8 @@ void AggregatingStep::transformPipeline(QueryPipeline & pipeline)
                 {
                     return std::make_shared<AggregatingInOrderTransform>(header, transform_params, group_by_sort_description, max_block_size);
                 });
+
+                aggregating_in_order = collector.detachProcessors(0);
             }
 
             pipeline.addSimpleTransform([&](const Block & header)
@@ -106,6 +113,8 @@ void AggregatingStep::transformPipeline(QueryPipeline & pipeline)
                 return std::make_shared<FinalizingSimpleTransform>(header, transform_params);
             });
 
+            finalizing = collector.detachProcessors(2);
+
             pipeline.enableQuotaForCurrentStreams();
             return;
         }
@@ -127,6 +136,8 @@ void AggregatingStep::transformPipeline(QueryPipeline & pipeline)
         });
 
         pipeline.resize(1);
+
+        aggregating = collector.detachProcessors(0);
     }
     else
     {
@@ -136,9 +147,29 @@ void AggregatingStep::transformPipeline(QueryPipeline & pipeline)
         {
             return std::make_shared<AggregatingTransform>(header, transform_params);
         });
+
+        aggregating = collector.detachProcessors(0);
     }
 
     pipeline.enableQuotaForCurrentStreams();
 }
 
+void AggregatingStep::describeActions(FormatSettings & settings) const
+{
+    params.explain(settings.out, settings.offset);
+}
+
+void AggregatingStep::describePipeline(FormatSettings & settings) const
+{
+    if (!aggregating.empty())
+        IQueryPlanStep::describePipeline(aggregating, settings);
+    else
+    {
+        /// Processors are printed in reverse order.
+        IQueryPlanStep::describePipeline(finalizing, settings);
+        IQueryPlanStep::describePipeline(aggregating_sorted, settings);
+        IQueryPlanStep::describePipeline(aggregating_in_order, settings);
+    }
+}
+
 }
diff --git a/src/Processors/QueryPlan/AggregatingStep.h b/src/Processors/QueryPlan/AggregatingStep.h
index e1be5ff0d348..853173895b32 100644
--- a/src/Processors/QueryPlan/AggregatingStep.h
+++ b/src/Processors/QueryPlan/AggregatingStep.h
@@ -29,6 +29,9 @@ class AggregatingStep : public ITransformingStep
 
     void transformPipeline(QueryPipeline & pipeline) override;
 
+    void describeActions(FormatSettings &) const override;
+    void describePipeline(FormatSettings & settings) const override;
+
 private:
     Aggregator::Params params;
     bool final;
@@ -40,6 +43,13 @@ class AggregatingStep : public ITransformingStep
 
     InputOrderInfoPtr group_by_info;
     SortDescription group_by_sort_description;
+
+    Processors aggregating_in_order;
+    Processors aggregating_sorted;
+    Processors finalizing;
+
+    Processors aggregating;
+
 };
 
 }
diff --git a/src/Processors/QueryPlan/ConvertingStep.cpp b/src/Processors/QueryPlan/ConvertingStep.cpp
index 1c4c3529e805..4713a3c44027 100644
--- a/src/Processors/QueryPlan/ConvertingStep.cpp
+++ b/src/Processors/QueryPlan/ConvertingStep.cpp
@@ -1,6 +1,7 @@
 #include <Processors/QueryPlan/ConvertingStep.h>
 #include <Processors/QueryPipeline.h>
 #include <Processors/Transforms/ConvertingTransform.h>
+#include <IO/Operators.h>
 
 namespace DB
 {
@@ -30,4 +31,40 @@ void ConvertingStep::transformPipeline(QueryPipeline & pipeline)
     });
 }
 
+void ConvertingStep::describeActions(FormatSettings & settings) const
+{
+    const auto & header = input_streams[0].header;
+    auto conversion = ConvertingTransform(header, result_header, ConvertingTransform::MatchColumnsMode::Name)
+            .getConversion();
+
+    auto dump_description = [&](const ColumnWithTypeAndName & elem, bool is_const)
+    {
+        settings.out << elem.name << ' ' << elem.type->getName() << (is_const ? " Const" : "") << '
';
+    };
+
+    String prefix(settings.offset, ' ');
+
+    for (size_t i = 0; i < conversion.size(); ++i)
+    {
+        const auto & from = header.getByPosition(conversion[i]);
+        const auto & to = result_header.getByPosition(i);
+
+        bool from_const = from.column && isColumnConst(*from.column);
+        bool to_const = to.column && isColumnConst(*to.column);
+
+        settings.out << prefix;
+
+        if (from.name == to.name && from.type->equals(*to.type) && from_const == to_const)
+            dump_description(from, from_const);
+        else
+        {
+            dump_description(to, to_const);
+            settings.out << " â† ";
+            dump_description(from, from_const);
+        }
+
+        settings.out << '
';
+    }
+}
+
 }
diff --git a/src/Processors/QueryPlan/ConvertingStep.h b/src/Processors/QueryPlan/ConvertingStep.h
index cb53dfcbd5f4..5591b49028c5 100644
--- a/src/Processors/QueryPlan/ConvertingStep.h
+++ b/src/Processors/QueryPlan/ConvertingStep.h
@@ -14,6 +14,8 @@ class ConvertingStep : public ITransformingStep
 
     void transformPipeline(QueryPipeline & pipeline) override;
 
+    void describeActions(FormatSettings & settings) const override;
+
 private:
     Block result_header;
 };
diff --git a/src/Processors/QueryPlan/CreatingSetsStep.cpp b/src/Processors/QueryPlan/CreatingSetsStep.cpp
index e402318ad709..a61900662c52 100644
--- a/src/Processors/QueryPlan/CreatingSetsStep.cpp
+++ b/src/Processors/QueryPlan/CreatingSetsStep.cpp
@@ -1,6 +1,7 @@
 #include <Processors/QueryPlan/CreatingSetsStep.h>
 #include <Processors/QueryPipeline.h>
 #include <Processors/Transforms/CreatingSetsTransform.h>
+#include <IO/Operators.h>
 
 namespace DB
 {
@@ -37,4 +38,20 @@ void CreatingSetsStep::transformPipeline(QueryPipeline & pipeline)
     pipeline.addCreatingSetsTransform(std::move(creating_sets));
 }
 
+void CreatingSetsStep::describeActions(FormatSettings & settings) const
+{
+    String prefix(settings.offset, ' ');
+
+    for (const auto & set : subqueries_for_sets)
+    {
+        settings.out << prefix;
+        if (set.second.set)
+            settings.out << "Set: ";
+        else if (set.second.join)
+            settings.out << "Join: ";
+
+        settings.out << set.first << '
';
+    }
+}
+
 }
diff --git a/src/Processors/QueryPlan/CreatingSetsStep.h b/src/Processors/QueryPlan/CreatingSetsStep.h
index e749b79c9a5c..4ba4863c043d 100644
--- a/src/Processors/QueryPlan/CreatingSetsStep.h
+++ b/src/Processors/QueryPlan/CreatingSetsStep.h
@@ -20,6 +20,8 @@ class CreatingSetsStep : public ITransformingStep
 
     void transformPipeline(QueryPipeline & pipeline) override;
 
+    void describeActions(FormatSettings & settings) const override;
+
 private:
     SubqueriesForSets subqueries_for_sets;
     SizeLimits network_transfer_limits;
diff --git a/src/Processors/QueryPlan/DistinctStep.cpp b/src/Processors/QueryPlan/DistinctStep.cpp
index be810a5f5cd5..2a94754a6b0e 100644
--- a/src/Processors/QueryPlan/DistinctStep.cpp
+++ b/src/Processors/QueryPlan/DistinctStep.cpp
@@ -1,6 +1,7 @@
 #include <Processors/QueryPlan/DistinctStep.h>
 #include <Processors/Transforms/DistinctTransform.h>
 #include <Processors/QueryPipeline.h>
+#include <IO/Operators.h>
 
 namespace DB
 {
@@ -68,4 +69,27 @@ void DistinctStep::transformPipeline(QueryPipeline & pipeline)
     });
 }
 
+void DistinctStep::describeActions(FormatSettings & settings) const
+{
+    String prefix(settings.offset, ' ');
+    settings.out << prefix << "Columns: ";
+
+    if (columns.empty())
+        settings.out << "none";
+    else
+    {
+        bool first = true;
+        for (const auto & column : columns)
+        {
+            if (!first)
+                settings.out << ", ";
+            first = false;
+
+            settings.out << column;
+        }
+    }
+
+    settings.out << '
';
+}
+
 }
diff --git a/src/Processors/QueryPlan/DistinctStep.h b/src/Processors/QueryPlan/DistinctStep.h
index 4460b3a37646..4bfd73ce0442 100644
--- a/src/Processors/QueryPlan/DistinctStep.h
+++ b/src/Processors/QueryPlan/DistinctStep.h
@@ -20,6 +20,8 @@ class DistinctStep : public ITransformingStep
 
     void transformPipeline(QueryPipeline & pipeline) override;
 
+    void describeActions(FormatSettings & settings) const override;
+
 private:
     SizeLimits set_size_limits;
     UInt64 limit_hint;
diff --git a/src/Processors/QueryPlan/ExpressionStep.cpp b/src/Processors/QueryPlan/ExpressionStep.cpp
index ca28d22163d3..66dd5fed31aa 100644
--- a/src/Processors/QueryPlan/ExpressionStep.cpp
+++ b/src/Processors/QueryPlan/ExpressionStep.cpp
@@ -3,6 +3,7 @@
 #include <Processors/QueryPipeline.h>
 #include <Processors/Transforms/InflatingExpressionTransform.h>
 #include <Interpreters/ExpressionActions.h>
+#include <IO/Operators.h>
 
 namespace DB
 {
@@ -37,6 +38,25 @@ void ExpressionStep::transformPipeline(QueryPipeline & pipeline)
     });
 }
 
+static void doDescribeActions(const ExpressionActionsPtr & expression, IQueryPlanStep::FormatSettings & settings)
+{
+    String prefix(settings.offset, ' ');
+    bool first = true;
+
+    for (const auto & action : expression->getActions())
+    {
+        settings.out << prefix << (first ? "Actions: "
+                                         : "         ");
+        first = false;
+        settings.out << action.toString() << '
';
+    }
+}
+
+void ExpressionStep::describeActions(FormatSettings & settings) const
+{
+    doDescribeActions(expression, settings);
+}
+
 InflatingExpressionStep::InflatingExpressionStep(const DataStream & input_stream_, ExpressionActionsPtr expression_)
     : ITransformingStep(
         input_stream_,
@@ -64,4 +84,9 @@ void InflatingExpressionStep::transformPipeline(QueryPipeline & pipeline)
     });
 }
 
+void InflatingExpressionStep::describeActions(FormatSettings & settings) const
+{
+    doDescribeActions(expression, settings);
+}
+
 }
diff --git a/src/Processors/QueryPlan/ExpressionStep.h b/src/Processors/QueryPlan/ExpressionStep.h
index 0a7292ebdd90..80d2fd2630dc 100644
--- a/src/Processors/QueryPlan/ExpressionStep.h
+++ b/src/Processors/QueryPlan/ExpressionStep.h
@@ -21,6 +21,8 @@ class ExpressionStep : public ITransformingStep
 
     void transformPipeline(QueryPipeline & pipeline) override;
 
+    void describeActions(FormatSettings & settings) const override;
+
 private:
     ExpressionActionsPtr expression;
 };
@@ -36,6 +38,8 @@ class InflatingExpressionStep : public ITransformingStep
 
     void transformPipeline(QueryPipeline & pipeline) override;
 
+    void describeActions(FormatSettings & settings) const override;
+
 private:
     ExpressionActionsPtr expression;
 };
diff --git a/src/Processors/QueryPlan/FillingStep.cpp b/src/Processors/QueryPlan/FillingStep.cpp
index dbd4874bffce..2c06d14e6a5a 100644
--- a/src/Processors/QueryPlan/FillingStep.cpp
+++ b/src/Processors/QueryPlan/FillingStep.cpp
@@ -1,6 +1,7 @@
 #include <Processors/QueryPlan/FillingStep.h>
 #include <Processors/Transforms/FillingTransform.h>
 #include <Processors/QueryPipeline.h>
+#include <IO/Operators.h>
 
 namespace DB
 {
@@ -36,4 +37,11 @@ void FillingStep::transformPipeline(QueryPipeline & pipeline)
     });
 }
 
+void FillingStep::describeActions(FormatSettings & settings) const
+{
+    settings.out << String(settings.offset, ' ');
+    dumpSortDescription(sort_description, input_streams.front().header, settings.out);
+    settings.out << '
';
+}
+
 }
diff --git a/src/Processors/QueryPlan/FillingStep.h b/src/Processors/QueryPlan/FillingStep.h
index fba63a3f0af7..85736464a6c3 100644
--- a/src/Processors/QueryPlan/FillingStep.h
+++ b/src/Processors/QueryPlan/FillingStep.h
@@ -15,6 +15,8 @@ class FillingStep : public ITransformingStep
 
     void transformPipeline(QueryPipeline & pipeline) override;
 
+    void describeActions(FormatSettings & settings) const override;
+
 private:
     SortDescription sort_description;
 };
diff --git a/src/Processors/QueryPlan/FilterStep.cpp b/src/Processors/QueryPlan/FilterStep.cpp
index 4b9dd449b7cd..9abca58a5de3 100644
--- a/src/Processors/QueryPlan/FilterStep.cpp
+++ b/src/Processors/QueryPlan/FilterStep.cpp
@@ -2,6 +2,7 @@
 #include <Processors/Transforms/FilterTransform.h>
 #include <Processors/QueryPipeline.h>
 #include <Interpreters/ExpressionActions.h>
+#include <IO/Operators.h>
 
 namespace DB
 {
@@ -42,4 +43,19 @@ void FilterStep::transformPipeline(QueryPipeline & pipeline)
     });
 }
 
+void FilterStep::describeActions(FormatSettings & settings) const
+{
+    String prefix(settings.offset, ' ');
+    settings.out << prefix << "Filter column: " << filter_column_name << '
';
+
+    bool first = true;
+    for (const auto & action : expression->getActions())
+    {
+        settings.out << prefix << (first ? "Actions: "
+                                         : "         ");
+        first = false;
+        settings.out << action.toString() << '
';
+    }
+}
+
 }
diff --git a/src/Processors/QueryPlan/FilterStep.h b/src/Processors/QueryPlan/FilterStep.h
index 940253955eea..1decc61349a8 100644
--- a/src/Processors/QueryPlan/FilterStep.h
+++ b/src/Processors/QueryPlan/FilterStep.h
@@ -20,6 +20,8 @@ class FilterStep : public ITransformingStep
     String getName() const override { return "Filter"; }
     void transformPipeline(QueryPipeline & pipeline) override;
 
+    void describeActions(FormatSettings & settings) const override;
+
 private:
     ExpressionActionsPtr expression;
     String filter_column_name;
diff --git a/src/Processors/QueryPlan/FinishSortingStep.cpp b/src/Processors/QueryPlan/FinishSortingStep.cpp
index a6a071b78486..85325e07a0cd 100644
--- a/src/Processors/QueryPlan/FinishSortingStep.cpp
+++ b/src/Processors/QueryPlan/FinishSortingStep.cpp
@@ -4,6 +4,7 @@
 #include <Processors/Merges/MergingSortedTransform.h>
 #include <Processors/Transforms/PartialSortingTransform.h>
 #include <Processors/Transforms/FinishSortingTransform.h>
+#include <IO/Operators.h>
 
 namespace DB
 {
@@ -68,4 +69,20 @@ void FinishSortingStep::transformPipeline(QueryPipeline & pipeline)
     }
 }
 
+void FinishSortingStep::describeActions(FormatSettings & settings) const
+{
+    String prefix(settings.offset, ' ');
+
+    settings.out << prefix << "Prefix sort description: ";
+    dumpSortDescription(prefix_description, input_streams.front().header, settings.out);
+    settings.out << '
';
+
+    settings.out << prefix << "Result sort description: ";
+    dumpSortDescription(result_description, input_streams.front().header, settings.out);
+    settings.out << '
';
+
+    if (limit)
+        settings.out << prefix << "Limit " << limit << '
';
+}
+
 }
diff --git a/src/Processors/QueryPlan/FinishSortingStep.h b/src/Processors/QueryPlan/FinishSortingStep.h
index e5bba41d51e3..41a96b9456a3 100644
--- a/src/Processors/QueryPlan/FinishSortingStep.h
+++ b/src/Processors/QueryPlan/FinishSortingStep.h
@@ -20,6 +20,8 @@ class FinishSortingStep : public ITransformingStep
 
     void transformPipeline(QueryPipeline & pipeline) override;
 
+    void describeActions(FormatSettings & settings) const override;
+
 private:
     SortDescription prefix_description;
     SortDescription result_description;
diff --git a/src/Processors/QueryPlan/IQueryPlanStep.cpp b/src/Processors/QueryPlan/IQueryPlanStep.cpp
index f25d17188ea1..0be40019c582 100644
--- a/src/Processors/QueryPlan/IQueryPlanStep.cpp
+++ b/src/Processors/QueryPlan/IQueryPlanStep.cpp
@@ -1,4 +1,6 @@
 #include <Processors/QueryPlan/IQueryPlanStep.h>
+#include <Processors/IProcessor.h>
+#include <IO/Operators.h>
 
 namespace DB
 {
@@ -16,4 +18,94 @@ const DataStream & IQueryPlanStep::getOutputStream() const
     return *output_stream;
 }
 
+static void doDescribeHeader(const Block & header, size_t count, IQueryPlanStep::FormatSettings & settings)
+{
+    String prefix(settings.offset, settings.indent_char);
+    prefix += "Header";
+
+    if (count > 1)
+        prefix += " Ã— " + std::to_string(count) + " ";
+
+    prefix += ": ";
+
+    settings.out << prefix;
+
+    if (!header)
+    {
+        settings.out << " empty
";
+        return;
+    }
+
+    prefix.assign(prefix.size(), settings.indent_char);
+    bool first = true;
+
+    for (const auto & elem : header)
+    {
+        if (!first)
+            settings.out << prefix;
+
+        first = false;
+        elem.dumpStructure(settings.out);
+        settings.out << '
';
+    }
+}
+
+static void doDescribeProcessor(const IProcessor & processor, size_t count, IQueryPlanStep::FormatSettings & settings)
+{
+    settings.out << String(settings.offset, settings.indent_char) << processor.getName();
+    if (count > 1)
+        settings.out << " Ã— " << std::to_string(count);
+
+    size_t num_inputs = processor.getInputs().size();
+    size_t num_outputs = processor.getOutputs().size();
+    if (num_inputs != 1 || num_outputs != 1)
+        settings.out << " " << std::to_string(num_inputs) << " â†’ " << std::to_string(num_outputs);
+
+    settings.out << '
';
+
+    if (settings.write_header)
+    {
+        const Block * last_header = nullptr;
+        size_t num_equal_headers = 0;
+
+        for (const auto & port : processor.getOutputs())
+        {
+            if (last_header && !blocksHaveEqualStructure(*last_header, port.getHeader()))
+            {
+                doDescribeHeader(*last_header, num_equal_headers, settings);
+                num_equal_headers = 0;
+            }
+
+            ++num_equal_headers;
+            last_header = &port.getHeader();
+        }
+
+        if (last_header)
+            doDescribeHeader(*last_header, num_equal_headers, settings);
+    }
+
+    settings.offset += settings.indent;
+}
+
+void IQueryPlanStep::describePipeline(const Processors & processors, FormatSettings & settings)
+{
+    const IProcessor * prev = nullptr;
+    size_t count = 0;
+
+    for (auto it = processors.rbegin(); it != processors.rend(); ++it)
+    {
+        if (prev && prev->getName() != (*it)->getName())
+        {
+            doDescribeProcessor(*prev, count, settings);
+            count = 0;
+        }
+
+        ++count;
+        prev = it->get();
+    }
+
+    if (prev)
+        doDescribeProcessor(*prev, count, settings);
+}
+
 }
diff --git a/src/Processors/QueryPlan/IQueryPlanStep.h b/src/Processors/QueryPlan/IQueryPlanStep.h
index 6612f165188a..558b6a825cbc 100644
--- a/src/Processors/QueryPlan/IQueryPlanStep.h
+++ b/src/Processors/QueryPlan/IQueryPlanStep.h
@@ -8,6 +8,10 @@ class QueryPipeline;
 using QueryPipelinePtr = std::unique_ptr<QueryPipeline>;
 using QueryPipelines = std::vector<QueryPipelinePtr>;
 
+class IProcessor;
+using ProcessorPtr = std::shared_ptr<IProcessor>;
+using Processors = std::vector<ProcessorPtr>;
+
 /// Description of data stream.
 /// Single logical data stream may relate to many ports of pipeline.
 class DataStream
@@ -57,12 +61,29 @@ class IQueryPlanStep
     const std::string & getStepDescription() const { return step_description; }
     void setStepDescription(std::string description) { step_description = std::move(description); }
 
+    struct FormatSettings
+    {
+        WriteBuffer & out;
+        size_t offset = 0;
+        const size_t indent = 2;
+        const char indent_char = ' ';
+        const bool write_header = false;
+    };
+
+    /// Get detailed description of step actions. This is shown in EXPLAIN query with options `actions = 1`.
+    virtual void describeActions(FormatSettings & /*settings*/) const {}
+
+    /// Get description of processors added in current step. Should be called after updatePipeline().
+    virtual void describePipeline(FormatSettings & /*settings*/) const {}
+
 protected:
     DataStreams input_streams;
     std::optional<DataStream> output_stream;
 
     /// Text description about what current step does.
     std::string step_description;
+
+    static void describePipeline(const Processors & processors, FormatSettings & settings);
 };
 
 using QueryPlanStepPtr = std::unique_ptr<IQueryPlanStep>;
diff --git a/src/Processors/QueryPlan/ISourceStep.cpp b/src/Processors/QueryPlan/ISourceStep.cpp
index 9909a7772675..cf68104f18c1 100644
--- a/src/Processors/QueryPlan/ISourceStep.cpp
+++ b/src/Processors/QueryPlan/ISourceStep.cpp
@@ -12,8 +12,15 @@ ISourceStep::ISourceStep(DataStream output_stream_)
 QueryPipelinePtr ISourceStep::updatePipeline(QueryPipelines)
 {
     auto pipeline = std::make_unique<QueryPipeline>();
+    QueryPipelineProcessorsCollector collector(*pipeline, this);
     initializePipeline(*pipeline);
+    processors = collector.detachProcessors();
     return pipeline;
 }
 
+void ISourceStep::describePipeline(FormatSettings & settings) const
+{
+    IQueryPlanStep::describePipeline(processors, settings);
+}
+
 }
diff --git a/src/Processors/QueryPlan/ISourceStep.h b/src/Processors/QueryPlan/ISourceStep.h
index 7fdfa3e0e388..54bc19957f41 100644
--- a/src/Processors/QueryPlan/ISourceStep.h
+++ b/src/Processors/QueryPlan/ISourceStep.h
@@ -13,6 +13,12 @@ class ISourceStep : public IQueryPlanStep
     QueryPipelinePtr updatePipeline(QueryPipelines pipelines) override;
 
     virtual void initializePipeline(QueryPipeline & pipeline) = 0;
+
+    void describePipeline(FormatSettings & settings) const override;
+
+private:
+    /// We collect processors got after pipeline transformation.
+    Processors processors;
 };
 
 }
diff --git a/src/Processors/QueryPlan/ITransformingStep.cpp b/src/Processors/QueryPlan/ITransformingStep.cpp
index 1510ee1e0eb5..9c67fedc734e 100644
--- a/src/Processors/QueryPlan/ITransformingStep.cpp
+++ b/src/Processors/QueryPlan/ITransformingStep.cpp
@@ -4,7 +4,8 @@
 namespace DB
 {
 
-ITransformingStep::ITransformingStep(DataStream input_stream, Block output_header, DataStreamTraits traits)
+ITransformingStep::ITransformingStep(DataStream input_stream, Block output_header, DataStreamTraits traits, bool collect_processors_)
+    : collect_processors(collect_processors_)
 {
     output_stream = DataStream{.header = std::move(output_header)};
 
@@ -19,7 +20,15 @@ ITransformingStep::ITransformingStep(DataStream input_stream, Block output_heade
 
 QueryPipelinePtr ITransformingStep::updatePipeline(QueryPipelines pipelines)
 {
-    transformPipeline(*pipelines.front());
+    if (collect_processors)
+    {
+        QueryPipelineProcessorsCollector collector(*pipelines.front(), this);
+        transformPipeline(*pipelines.front());
+        processors = collector.detachProcessors();
+    }
+    else
+        transformPipeline(*pipelines.front());
+
     return std::move(pipelines.front());
 }
 
@@ -38,4 +47,9 @@ void ITransformingStep::updateDistinctColumns(const Block & res_header, NameSet
     }
 }
 
+void ITransformingStep::describePipeline(FormatSettings & settings) const
+{
+    IQueryPlanStep::describePipeline(processors, settings);
+}
+
 }
diff --git a/src/Processors/QueryPlan/ITransformingStep.h b/src/Processors/QueryPlan/ITransformingStep.h
index 45b48c9ecc74..30ff039cf39c 100644
--- a/src/Processors/QueryPlan/ITransformingStep.h
+++ b/src/Processors/QueryPlan/ITransformingStep.h
@@ -25,15 +25,22 @@ class ITransformingStep : public IQueryPlanStep
         bool preserves_number_of_streams;
     };
 
-    ITransformingStep(DataStream input_stream, Block output_header, DataStreamTraits traits);
+    ITransformingStep(DataStream input_stream, Block output_header, DataStreamTraits traits, bool collect_processors_ = true);
 
     QueryPipelinePtr updatePipeline(QueryPipelines pipelines) override;
 
     virtual void transformPipeline(QueryPipeline & pipeline) = 0;
 
+    void describePipeline(FormatSettings & settings) const override;
+
 protected:
     /// Clear distinct_columns if res_header doesn't contain all of them.
     static void updateDistinctColumns(const Block & res_header, NameSet & distinct_columns);
+
+private:
+    /// We collect processors got after pipeline transformation.
+    Processors processors;
+    bool collect_processors;
 };
 
 }
diff --git a/src/Processors/QueryPlan/LimitByStep.cpp b/src/Processors/QueryPlan/LimitByStep.cpp
index 5eea41936669..30d226307868 100644
--- a/src/Processors/QueryPlan/LimitByStep.cpp
+++ b/src/Processors/QueryPlan/LimitByStep.cpp
@@ -1,6 +1,7 @@
 #include <Processors/QueryPlan/LimitByStep.h>
 #include <Processors/Transforms/LimitByTransform.h>
 #include <Processors/QueryPipeline.h>
+#include <IO/Operators.h>
 
 namespace DB
 {
@@ -39,4 +40,30 @@ void LimitByStep::transformPipeline(QueryPipeline & pipeline)
     });
 }
 
+void LimitByStep::describeActions(FormatSettings & settings) const
+{
+    String prefix(settings.offset, ' ');
+
+    settings.out << prefix << "Columns: ";
+
+    if (columns.empty())
+        settings.out << "none
";
+    else
+    {
+        bool first = true;
+        for (const auto & column : columns)
+        {
+            if (!first)
+                settings.out << ", ";
+            first = false;
+
+            settings.out << column;
+        }
+        settings.out << '
';
+    }
+
+    settings.out << prefix << "Length " << group_length << '
';
+    settings.out << prefix << "Offset " << group_offset << '
';
+}
+
 }
diff --git a/src/Processors/QueryPlan/LimitByStep.h b/src/Processors/QueryPlan/LimitByStep.h
index bf3943a7f592..9320735640c9 100644
--- a/src/Processors/QueryPlan/LimitByStep.h
+++ b/src/Processors/QueryPlan/LimitByStep.h
@@ -16,6 +16,8 @@ class LimitByStep : public ITransformingStep
 
     void transformPipeline(QueryPipeline & pipeline) override;
 
+    void describeActions(FormatSettings & settings) const override;
+
 private:
     size_t group_length;
     size_t group_offset;
@@ -23,5 +25,3 @@ class LimitByStep : public ITransformingStep
 };
 
 }
-
-
diff --git a/src/Processors/QueryPlan/LimitStep.cpp b/src/Processors/QueryPlan/LimitStep.cpp
index 9e11a8205676..55447535f814 100644
--- a/src/Processors/QueryPlan/LimitStep.cpp
+++ b/src/Processors/QueryPlan/LimitStep.cpp
@@ -1,6 +1,7 @@
 #include <Processors/QueryPlan/LimitStep.h>
 #include <Processors/QueryPipeline.h>
 #include <Processors/LimitTransform.h>
+#include <IO/Operators.h>
 
 namespace DB
 {
@@ -36,4 +37,30 @@ void LimitStep::transformPipeline(QueryPipeline & pipeline)
     pipeline.addPipe({std::move(transform)});
 }
 
+void LimitStep::describeActions(FormatSettings & settings) const
+{
+    String prefix(settings.offset, ' ');
+    settings.out << prefix << "Limit " << limit << '
';
+    settings.out << prefix << "Offset " << offset << '
';
+
+    if (with_ties || always_read_till_end)
+    {
+        settings.out << prefix;
+
+        String str;
+        if (with_ties)
+            settings.out << "WITH TIES";
+
+        if (always_read_till_end)
+        {
+            if (!with_ties)
+                settings.out << ", ";
+
+            settings.out << "Reads all data";
+        }
+
+        settings.out << '
';
+    }
+}
+
 }
diff --git a/src/Processors/QueryPlan/LimitStep.h b/src/Processors/QueryPlan/LimitStep.h
index 3fd77bea22fc..e04ecfcb471f 100644
--- a/src/Processors/QueryPlan/LimitStep.h
+++ b/src/Processors/QueryPlan/LimitStep.h
@@ -21,6 +21,8 @@ class LimitStep : public ITransformingStep
 
     void transformPipeline(QueryPipeline & pipeline) override;
 
+    void describeActions(FormatSettings & settings) const override;
+
 private:
     size_t limit;
     size_t offset;
diff --git a/src/Processors/QueryPlan/MergeSortingStep.cpp b/src/Processors/QueryPlan/MergeSortingStep.cpp
index 8fa5f4782f60..410d68d3c01f 100644
--- a/src/Processors/QueryPlan/MergeSortingStep.cpp
+++ b/src/Processors/QueryPlan/MergeSortingStep.cpp
@@ -1,6 +1,7 @@
 #include <Processors/QueryPlan/MergeSortingStep.h>
 #include <Processors/QueryPipeline.h>
 #include <Processors/Transforms/MergeSortingTransform.h>
+#include <IO/Operators.h>
 
 namespace DB
 {
@@ -50,4 +51,15 @@ void MergeSortingStep::transformPipeline(QueryPipeline & pipeline)
     });
 }
 
+void MergeSortingStep::describeActions(FormatSettings & settings) const
+{
+    String prefix(settings.offset, ' ');
+    settings.out << prefix << "Sort description: ";
+    dumpSortDescription(description, input_streams.front().header, settings.out);
+    settings.out << '
';
+
+    if (limit)
+        settings.out << prefix << "Limit " << limit << '
';
+}
+
 }
diff --git a/src/Processors/QueryPlan/MergeSortingStep.h b/src/Processors/QueryPlan/MergeSortingStep.h
index a0e33a826909..0bbc066622ec 100644
--- a/src/Processors/QueryPlan/MergeSortingStep.h
+++ b/src/Processors/QueryPlan/MergeSortingStep.h
@@ -25,6 +25,8 @@ class MergeSortingStep : public ITransformingStep
 
     void transformPipeline(QueryPipeline & pipeline) override;
 
+    void describeActions(FormatSettings & settings) const override;
+
 private:
     SortDescription description;
     size_t max_merged_block_size;
diff --git a/src/Processors/QueryPlan/MergingAggregatedStep.cpp b/src/Processors/QueryPlan/MergingAggregatedStep.cpp
index 870203842a1f..7e9d073e1868 100644
--- a/src/Processors/QueryPlan/MergingAggregatedStep.cpp
+++ b/src/Processors/QueryPlan/MergingAggregatedStep.cpp
@@ -65,4 +65,9 @@ void MergingAggregatedStep::transformPipeline(QueryPipeline & pipeline)
     pipeline.enableQuotaForCurrentStreams();
 }
 
+void MergingAggregatedStep::describeActions(FormatSettings & settings) const
+{
+    return params->params.explain(settings.out, settings.offset);
+}
+
 }
diff --git a/src/Processors/QueryPlan/MergingAggregatedStep.h b/src/Processors/QueryPlan/MergingAggregatedStep.h
index c0da5961c52c..5ffceb7f9387 100644
--- a/src/Processors/QueryPlan/MergingAggregatedStep.h
+++ b/src/Processors/QueryPlan/MergingAggregatedStep.h
@@ -23,6 +23,8 @@ class MergingAggregatedStep : public ITransformingStep
 
     void transformPipeline(QueryPipeline & pipeline) override;
 
+    void describeActions(FormatSettings & settings) const override;
+
 private:
     AggregatingTransformParamsPtr params;
     bool memory_efficient_aggregation;
diff --git a/src/Processors/QueryPlan/MergingSortedStep.cpp b/src/Processors/QueryPlan/MergingSortedStep.cpp
index dc44a96e45e1..50bef82910c0 100644
--- a/src/Processors/QueryPlan/MergingSortedStep.cpp
+++ b/src/Processors/QueryPlan/MergingSortedStep.cpp
@@ -1,6 +1,7 @@
 #include <Processors/QueryPlan/MergingSortedStep.h>
 #include <Processors/QueryPipeline.h>
 #include <Processors/Merges/MergingSortedTransform.h>
+#include <IO/Operators.h>
 
 namespace DB
 {
@@ -45,4 +46,12 @@ void MergingSortedStep::transformPipeline(QueryPipeline & pipeline)
     }
 }
 
+void MergingSortedStep::describeActions(FormatSettings & settings) const
+{
+    String prefix(settings.offset, ' ');
+    settings.out << prefix << "Sort description: ";
+    dumpSortDescription(sort_description, input_streams.front().header, settings.out);
+    settings.out << '
';
+}
+
 }
diff --git a/src/Processors/QueryPlan/MergingSortedStep.h b/src/Processors/QueryPlan/MergingSortedStep.h
index 195843032391..a5b0c12b1fb7 100644
--- a/src/Processors/QueryPlan/MergingSortedStep.h
+++ b/src/Processors/QueryPlan/MergingSortedStep.h
@@ -21,6 +21,8 @@ class MergingSortedStep : public ITransformingStep
 
     void transformPipeline(QueryPipeline & pipeline) override;
 
+    void describeActions(FormatSettings & settings) const override;
+
 private:
     SortDescription sort_description;
     size_t max_block_size;
diff --git a/src/Processors/QueryPlan/OffsetsStep.cpp b/src/Processors/QueryPlan/OffsetStep.cpp
similarity index 64%
rename from src/Processors/QueryPlan/OffsetsStep.cpp
rename to src/Processors/QueryPlan/OffsetStep.cpp
index fc6ef1e7c302..79ccad26686a 100644
--- a/src/Processors/QueryPlan/OffsetsStep.cpp
+++ b/src/Processors/QueryPlan/OffsetStep.cpp
@@ -1,6 +1,7 @@
-#include <Processors/QueryPlan/OffsetsStep.h>
+#include <Processors/QueryPlan/OffsetStep.h>
 #include <Processors/OffsetTransform.h>
 #include <Processors/QueryPipeline.h>
+#include <IO/Operators.h>
 
 namespace DB
 {
@@ -15,13 +16,13 @@ static ITransformingStep::DataStreamTraits getTraits()
     };
 }
 
-OffsetsStep::OffsetsStep(const DataStream & input_stream_, size_t offset_)
+OffsetStep::OffsetStep(const DataStream & input_stream_, size_t offset_)
     : ITransformingStep(input_stream_, input_stream_.header, getTraits())
     , offset(offset_)
 {
 }
 
-void OffsetsStep::transformPipeline(QueryPipeline & pipeline)
+void OffsetStep::transformPipeline(QueryPipeline & pipeline)
 {
     auto transform = std::make_shared<OffsetTransform>(
             pipeline.getHeader(), offset, pipeline.getNumStreams());
@@ -29,4 +30,9 @@ void OffsetsStep::transformPipeline(QueryPipeline & pipeline)
     pipeline.addPipe({std::move(transform)});
 }
 
+void OffsetStep::describeActions(FormatSettings & settings) const
+{
+    settings.out << String(settings.offset, ' ') << "Offset " << offset << '
';
+}
+
 }
diff --git a/src/Processors/QueryPlan/OffsetsStep.h b/src/Processors/QueryPlan/OffsetStep.h
similarity index 54%
rename from src/Processors/QueryPlan/OffsetsStep.h
rename to src/Processors/QueryPlan/OffsetStep.h
index 41efac1a4220..17949371edf4 100644
--- a/src/Processors/QueryPlan/OffsetsStep.h
+++ b/src/Processors/QueryPlan/OffsetStep.h
@@ -6,15 +6,17 @@ namespace DB
 {
 
 /// Executes OFFSET (without LIMIT). See OffsetTransform.
-class OffsetsStep : public ITransformingStep
+class OffsetStep : public ITransformingStep
 {
 public:
-    OffsetsStep(const DataStream & input_stream_, size_t offset_);
+    OffsetStep(const DataStream & input_stream_, size_t offset_);
 
-    String getName() const override { return "Offsets"; }
+    String getName() const override { return "Offset"; }
 
     void transformPipeline(QueryPipeline & pipeline) override;
 
+    void describeActions(FormatSettings & settings) const override;
+
 private:
     size_t offset;
 };
diff --git a/src/Processors/QueryPlan/PartialSortingStep.cpp b/src/Processors/QueryPlan/PartialSortingStep.cpp
index e9400492710a..3d602169087a 100644
--- a/src/Processors/QueryPlan/PartialSortingStep.cpp
+++ b/src/Processors/QueryPlan/PartialSortingStep.cpp
@@ -2,6 +2,7 @@
 #include <Processors/QueryPipeline.h>
 #include <Processors/Transforms/PartialSortingTransform.h>
 #include <Processors/Transforms/LimitsCheckingTransform.h>
+#include <IO/Operators.h>
 
 namespace DB
 {
@@ -52,4 +53,12 @@ void PartialSortingStep::transformPipeline(QueryPipeline & pipeline)
     });
 }
 
+void PartialSortingStep::describeActions(FormatSettings & settings) const
+{
+    String prefix(settings.offset, ' ');
+    settings.out << prefix << "Sort description: ";
+    dumpSortDescription(sort_description, input_streams.front().header, settings.out);
+    settings.out << '
';
+}
+
 }
diff --git a/src/Processors/QueryPlan/PartialSortingStep.h b/src/Processors/QueryPlan/PartialSortingStep.h
index c4656b8c9f30..12e9cec961a9 100644
--- a/src/Processors/QueryPlan/PartialSortingStep.h
+++ b/src/Processors/QueryPlan/PartialSortingStep.h
@@ -20,6 +20,8 @@ class PartialSortingStep : public ITransformingStep
 
     void transformPipeline(QueryPipeline & pipeline) override;
 
+    void describeActions(FormatSettings & settings) const override;
+
 private:
     SortDescription sort_description;
     UInt64 limit;
diff --git a/src/Processors/QueryPlan/QueryPlan.cpp b/src/Processors/QueryPlan/QueryPlan.cpp
index cd8c442a3db7..2e5d2a3a5f41 100644
--- a/src/Processors/QueryPlan/QueryPlan.cpp
+++ b/src/Processors/QueryPlan/QueryPlan.cpp
@@ -1,6 +1,8 @@
 #include <Processors/QueryPlan/QueryPlan.h>
 #include <Processors/QueryPlan/IQueryPlanStep.h>
 #include <Processors/QueryPipeline.h>
+#include <IO/WriteBuffer.h>
+#include <IO/Operators.h>
 #include <stack>
 
 namespace DB
@@ -11,6 +13,7 @@ namespace ErrorCodes
     extern const int LOGICAL_ERROR;
 }
 
+QueryPlan::QueryPlan() = default;
 QueryPlan::~QueryPlan() = default;
 
 void QueryPlan::checkInitialized() const
@@ -173,4 +176,135 @@ void QueryPlan::addInterpreterContext(std::shared_ptr<Context> context)
     interpreter_context.emplace_back(std::move(context));
 }
 
+
+static void explainStep(
+    const IQueryPlanStep & step,
+    IQueryPlanStep::FormatSettings & settings,
+    const QueryPlan::ExplainPlanOptions & options)
+{
+    std::string prefix(settings.offset, ' ');
+    settings.out << prefix;
+    settings.out << step.getName();
+
+    const auto & description = step.getStepDescription();
+    if (options.description && !description.empty())
+        settings.out <<" (" << description << ')';
+
+    settings.out.write('
');
+
+    if (options.header)
+    {
+        settings.out << prefix;
+
+        if (!step.hasOutputStream())
+            settings.out << "No header";
+        else if (!step.getOutputStream().header)
+            settings.out << "Empty header";
+        else
+        {
+            settings.out << "Header: ";
+            bool first = true;
+
+            for (const auto & elem : step.getOutputStream().header)
+            {
+                if (!first)
+                    settings.out << "
" << prefix << "        ";
+
+                first = false;
+                elem.dumpStructure(settings.out);
+            }
+        }
+
+        settings.out.write('
');
+    }
+
+    if (options.actions)
+        step.describeActions(settings);
+}
+
+void QueryPlan::explainPlan(WriteBuffer & buffer, const ExplainPlanOptions & options)
+{
+    checkInitialized();
+
+    IQueryPlanStep::FormatSettings settings{.out = buffer, .write_header = options.header};
+
+    struct Frame
+    {
+        Node * node;
+        bool is_description_printed = false;
+        size_t next_child = 0;
+    };
+
+    std::stack<Frame> stack;
+    stack.push(Frame{.node = root});
+
+    while (!stack.empty())
+    {
+        auto & frame = stack.top();
+
+        if (!frame.is_description_printed)
+        {
+            settings.offset = (stack.size() - 1) * settings.indent;
+            explainStep(*frame.node->step, settings, options);
+            frame.is_description_printed = true;
+        }
+
+        if (frame.next_child < frame.node->children.size())
+        {
+            stack.push(Frame{frame.node->children[frame.next_child]});
+            ++frame.next_child;
+        }
+        else
+            stack.pop();
+    }
+}
+
+static void explainPipelineStep(IQueryPlanStep & step, IQueryPlanStep::FormatSettings & settings)
+{
+    settings.out << String(settings.offset, settings.indent_char) << "(" << step.getName() << ")
";
+    size_t current_offset = settings.offset;
+    step.describePipeline(settings);
+    if (current_offset == settings.offset)
+        settings.offset += settings.indent;
+}
+
+void QueryPlan::explainPipeline(WriteBuffer & buffer, const ExplainPipelineOptions & options)
+{
+    checkInitialized();
+
+    IQueryPlanStep::FormatSettings settings{.out = buffer, .write_header = options.header};
+
+    struct Frame
+    {
+        Node * node;
+        size_t offset = 0;
+        bool is_description_printed = false;
+        size_t next_child = 0;
+    };
+
+    std::stack<Frame> stack;
+    stack.push(Frame{.node = root});
+
+    while (!stack.empty())
+    {
+        auto & frame = stack.top();
+
+        if (!frame.is_description_printed)
+        {
+            settings.offset = frame.offset;
+            explainPipelineStep(*frame.node->step, settings);
+            frame.offset = settings.offset;
+            frame.is_description_printed = true;
+        }
+
+        if (frame.next_child < frame.node->children.size())
+        {
+            stack.push(Frame{frame.node->children[frame.next_child], frame.offset});
+            ++frame.next_child;
+        }
+        else
+            stack.pop();
+    }
+}
+
 }
diff --git a/src/Processors/QueryPlan/QueryPlan.h b/src/Processors/QueryPlan/QueryPlan.h
index 9fadc45c3b2d..6f965f7daece 100644
--- a/src/Processors/QueryPlan/QueryPlan.h
+++ b/src/Processors/QueryPlan/QueryPlan.h
@@ -15,6 +15,7 @@ class QueryPipeline;
 using QueryPipelinePtr = std::unique_ptr<QueryPipeline>;
 
 class Context;
+class WriteBuffer;
 
 /// A tree of query steps.
 /// The goal of QueryPlan is to build QueryPipeline.
@@ -22,6 +23,7 @@ class Context;
 class QueryPlan
 {
 public:
+    QueryPlan();
     ~QueryPlan();
 
     void unitePlans(QueryPlanStepPtr step, std::vector<QueryPlan> plans);
@@ -33,6 +35,25 @@ class QueryPlan
 
     QueryPipelinePtr buildQueryPipeline();
 
+    struct ExplainPlanOptions
+    {
+        /// Add output header to step.
+        bool header = false;
+        /// Add description of step.
+        bool description = true;
+        /// Add detailed information about step actions.
+        bool actions = false;
+    };
+
+    struct ExplainPipelineOptions
+    {
+        /// Show header of output ports.
+        bool header = false;
+    };
+
+    void explainPlan(WriteBuffer & buffer, const ExplainPlanOptions & options);
+    void explainPipeline(WriteBuffer & buffer, const ExplainPipelineOptions & options);
+
     /// Set upper limit for the recommend number of threads. Will be applied to the newly-created pipelines.
     /// TODO: make it in a better way.
     void setMaxThreads(size_t max_threads_) { max_threads = max_threads_; }
diff --git a/src/Processors/QueryPlan/ReadFromStorageStep.cpp b/src/Processors/QueryPlan/ReadFromStorageStep.cpp
index 7e8d44abed87..f3f7dd1bc8bf 100644
--- a/src/Processors/QueryPlan/ReadFromStorageStep.cpp
+++ b/src/Processors/QueryPlan/ReadFromStorageStep.cpp
@@ -68,6 +68,7 @@ ReadFromStorageStep::ReadFromStorageStep(
     }
 
     pipeline = std::make_unique<QueryPipeline>();
+    QueryPipelineProcessorsCollector collector(*pipeline, this);
 
     /// Table lock is stored inside pipeline here.
     pipeline->addTableLock(table_lock);
@@ -124,6 +125,8 @@ ReadFromStorageStep::ReadFromStorageStep(
     pipeline->addInterpreterContext(std::move(context));
     pipeline->addStorageHolder(std::move(storage));
 
+    processors = collector.detachProcessors();
+
     output_stream = DataStream{.header = pipeline->getHeader(), .has_single_port = pipeline->getNumStreams() == 1};
 }
 
@@ -134,4 +137,9 @@ QueryPipelinePtr ReadFromStorageStep::updatePipeline(QueryPipelines)
     return std::move(pipeline);
 }
 
+void ReadFromStorageStep::describePipeline(FormatSettings & settings) const
+{
+    IQueryPlanStep::describePipeline(processors, settings);
+}
+
 }
diff --git a/src/Processors/QueryPlan/ReadFromStorageStep.h b/src/Processors/QueryPlan/ReadFromStorageStep.h
index fa34dedd573b..fce69bb0f0f9 100644
--- a/src/Processors/QueryPlan/ReadFromStorageStep.h
+++ b/src/Processors/QueryPlan/ReadFromStorageStep.h
@@ -38,6 +38,8 @@ class ReadFromStorageStep : public IQueryPlanStep
 
     QueryPipelinePtr updatePipeline(QueryPipelines) override;
 
+    void describePipeline(FormatSettings & settings) const override;
+
 private:
     TableLockHolder table_lock;
     StorageMetadataPtr metadata_snapshot;
@@ -52,6 +54,7 @@ class ReadFromStorageStep : public IQueryPlanStep
     size_t max_streams;
 
     QueryPipelinePtr pipeline;
+    Processors processors;
 };
 
 }
diff --git a/src/Processors/QueryPlan/TotalsHavingStep.cpp b/src/Processors/QueryPlan/TotalsHavingStep.cpp
index 8464e6d2ba67..aa1ee0bc49c0 100644
--- a/src/Processors/QueryPlan/TotalsHavingStep.cpp
+++ b/src/Processors/QueryPlan/TotalsHavingStep.cpp
@@ -2,6 +2,8 @@
 #include <Processors/Transforms/DistinctTransform.h>
 #include <Processors/QueryPipeline.h>
 #include <Processors/Transforms/TotalsHavingTransform.h>
+#include <Interpreters/ExpressionActions.h>
+#include <IO/Operators.h>
 
 namespace DB
 {
@@ -46,4 +48,37 @@ void TotalsHavingStep::transformPipeline(QueryPipeline & pipeline)
     pipeline.addTotalsHavingTransform(std::move(totals_having));
 }
 
+static String totalsModeToString(TotalsMode totals_mode, double auto_include_threshold)
+{
+    switch (totals_mode)
+    {
+        case TotalsMode::BEFORE_HAVING:
+            return "before_having";
+        case TotalsMode::AFTER_HAVING_INCLUSIVE:
+            return "after_having_inclusive";
+        case TotalsMode::AFTER_HAVING_EXCLUSIVE:
+            return "after_having_exclusive";
+        case TotalsMode::AFTER_HAVING_AUTO:
+            return "after_having_auto threshold " + std::to_string(auto_include_threshold);
+    }
+
+    __builtin_unreachable();
+}
+
+void TotalsHavingStep::describeActions(FormatSettings & settings) const
+{
+    String prefix(settings.offset, ' ');
+    settings.out << prefix << "Filter column: " << filter_column_name << '
';
+    settings.out << prefix << "Mode: " << totalsModeToString(totals_mode, auto_include_threshold) << '
';
+
+    bool first = true;
+    for (const auto & action : expression->getActions())
+    {
+        settings.out << prefix << (first ? "Actions: "
+                                         : "         ");
+        first = false;
+        settings.out << action.toString() << '
';
+    }
+}
+
 }
diff --git a/src/Processors/QueryPlan/TotalsHavingStep.h b/src/Processors/QueryPlan/TotalsHavingStep.h
index 76d793bff774..c9c73985126a 100644
--- a/src/Processors/QueryPlan/TotalsHavingStep.h
+++ b/src/Processors/QueryPlan/TotalsHavingStep.h
@@ -26,6 +26,8 @@ class TotalsHavingStep : public ITransformingStep
 
     void transformPipeline(QueryPipeline & pipeline) override;
 
+    void describeActions(FormatSettings & settings) const override;
+
 private:
     bool overflow_row;
     ExpressionActionsPtr expression;
diff --git a/src/Processors/QueryPlan/UnionStep.cpp b/src/Processors/QueryPlan/UnionStep.cpp
index 14a43cac78b9..a8897e778a1f 100644
--- a/src/Processors/QueryPlan/UnionStep.cpp
+++ b/src/Processors/QueryPlan/UnionStep.cpp
@@ -21,9 +21,12 @@ UnionStep::UnionStep(DataStreams input_streams_, Block result_header, size_t max
 QueryPipelinePtr UnionStep::updatePipeline(QueryPipelines pipelines)
 {
     auto pipeline = std::make_unique<QueryPipeline>();
+    QueryPipelineProcessorsCollector collector(*pipeline, this);
+
     if (pipelines.empty())
     {
         pipeline->init(Pipe(std::make_shared<NullSource>(output_stream->header)));
+        processors = collector.detachProcessors();
         return pipeline;
     }
 
@@ -37,7 +40,13 @@ QueryPipelinePtr UnionStep::updatePipeline(QueryPipelines pipelines)
         pipeline->setMaxThreads(std::min<UInt64>(num_pipelines, max_threads));
     }
 
+    processors = collector.detachProcessors();
     return pipeline;
 }
 
+void UnionStep::describePipeline(FormatSettings & settings) const
+{
+    IQueryPlanStep::describePipeline(processors, settings);
+}
+
 }
diff --git a/src/Processors/QueryPlan/UnionStep.h b/src/Processors/QueryPlan/UnionStep.h
index 8209c95fa984..9e00e24279b6 100644
--- a/src/Processors/QueryPlan/UnionStep.h
+++ b/src/Processors/QueryPlan/UnionStep.h
@@ -15,9 +15,12 @@ class UnionStep : public IQueryPlanStep
 
     QueryPipelinePtr updatePipeline(QueryPipelines pipelines) override;
 
+    void describePipeline(FormatSettings & settings) const override;
+
 private:
     Block header;
     size_t max_threads;
+    Processors processors;
 };
 
 }
diff --git a/src/Processors/Transforms/ConvertingTransform.h b/src/Processors/Transforms/ConvertingTransform.h
index 45a6688c07ab..b4b42dcb6ead 100644
--- a/src/Processors/Transforms/ConvertingTransform.h
+++ b/src/Processors/Transforms/ConvertingTransform.h
@@ -35,6 +35,8 @@ class ConvertingTransform : public ISimpleTransform
 
     String getName() const override { return "Converting"; }
 
+    const ColumnNumbers & getConversion() const { return conversion; }
+
 protected:
     void transform(Chunk & chunk) override;
 
diff --git a/src/Processors/printPipeline.cpp b/src/Processors/printPipeline.cpp
new file mode 100644
index 000000000000..5cdab1ed3ffd
--- /dev/null
+++ b/src/Processors/printPipeline.cpp
@@ -0,0 +1,177 @@
+#include <Processors/printPipeline.h>
+#include <Processors/QueryPlan/IQueryPlanStep.h>
+#include <set>
+#include <map>
+
+namespace DB
+{
+
+void printPipelineCompact(const Processors & processors, WriteBuffer & out, bool with_header)
+{
+    struct Node;
+
+    /// Group by processors name, QueryPlanStep and group in this step.
+    struct Key
+    {
+        size_t group;
+        IQueryPlanStep * step;
+        std::string name;
+
+        auto getTuple() const { return std::forward_as_tuple(group, step, name); }
+
+        bool operator<(const Key & other) const
+        {
+            return getTuple() < other.getTuple();
+        }
+    };
+
+    /// Group ports by header.
+    struct EdgeData
+    {
+        Block header;
+        size_t count;
+    };
+
+    using Edge = std::vector<EdgeData>;
+
+    struct Node
+    {
+        size_t id = 0;
+        std::map<Node *, Edge> edges = {};
+        std::vector<const IProcessor *> agents = {};
+    };
+
+    std::map<Key, Node> graph;
+
+    auto get_key = [](const IProcessor & processor)
+    {
+        return Key{processor.getQueryPlanStepGroup(), processor.getQueryPlanStep(), processor.getName()};
+    };
+
+    /// Fill nodes.
+    for (const auto & processor : processors)
+    {
+        auto res = graph.emplace(get_key(*processor), Node());
+        auto & node = res.first->second;
+        node.agents.emplace_back(processor.get());
+
+        if (res.second)
+            node.id = graph.size();
+    }
+
+    Block empty_header;
+
+    /// Fill edges.
+    for (const auto & processor : processors)
+    {
+        auto & from =  graph[get_key(*processor)];
+
+        for (auto & port : processor->getOutputs())
+        {
+            if (!port.isConnected())
+                continue;
+
+            auto & to = graph[get_key(port.getInputPort().getProcessor())];
+            auto & edge = from.edges[&to];
+
+            /// Use empty header for each edge if with_header is false.
+            const auto & header = with_header ? port.getHeader()
+                                              : empty_header;
+
+            /// Group by header.
+            bool found = false;
+            for (auto & item : edge)
+            {
+                if (blocksHaveEqualStructure(header, item.header))
+                {
+                    found = true;
+                    ++item.count;
+                    break;
+                }
+            }
+
+            if (!found)
+                edge.emplace_back(EdgeData{header, 1});
+        }
+    }
+
+    /// Group processors by it's QueryPlanStep.
+    std::map<IQueryPlanStep *, std::vector<const Node *>> steps_map;
+
+    for (const auto & item : graph)
+        steps_map[item.first.step].emplace_back(&item.second);
+
+    out << "digraph
{
";
+    out << "  rankdir=\"LR\";
";
+    out << "  { node [shape = box]
";
+
+    /// Nodes // TODO quoting and escaping
+    size_t next_step = 0;
+    for (const auto & item : steps_map)
+    {
+        /// Use separate clusters for each step.
+        if (item.first != nullptr)
+        {
+            out << "    subgraph cluster_" << next_step << " {
";
+            out << "      label =\"" << item.first->getName() << "\";
";
+            out << "      style=filled;
";
+            out << "      color=lightgrey;
";
+            out << "      node [style=filled,color=white];
";
+            out << "      { rank = same;
";
+
+            ++next_step;
+        }
+
+        for (const auto & node : item.second)
+        {
+            const auto & processor = node->agents.front();
+            out << "        n" << node->id << " [label=\"" << processor->getName();
+
+            if (node->agents.size() > 1)
+                out << " Ã— " << node->agents.size();
+
+            const auto & description = processor->getDescription();
+            if (!description.empty())
+                out << ' ' << description;
+
+            out << "\"];
";
+        }
+
+        if (item.first != nullptr)
+        {
+            out << "      }
";
+            out << "    }
";
+        }
+    }
+
+    out << "  }
";
+
+    /// Edges
+    for (const auto & item : graph)
+    {
+        for (const auto & edge : item.second.edges)
+        {
+            for (const auto & data : edge.second)
+            {
+                out << "  n" << item.second.id << " -> " << "n" << edge.first->id << " [label=\"";
+
+                if (data.count > 1)
+                    out << "Ã— " << data.count;
+
+                if (with_header)
+                {
+                    for (const auto & elem : data.header)
+                    {
+                        out << "
";
+                        elem.dumpStructure(out);
+                    }
+                }
+
+                out << "\"];
";
+            }
+        }
+    }
+    out << "}
";
+}
+
+}
diff --git a/src/Processors/printPipeline.h b/src/Processors/printPipeline.h
index ce7306ec4cf9..9497bc3cc3c2 100644
--- a/src/Processors/printPipeline.h
+++ b/src/Processors/printPipeline.h
@@ -15,6 +15,8 @@ template <typename Processors, typename Statuses>
 void printPipeline(const Processors & processors, const Statuses & statuses, WriteBuffer & out)
 {
     out << "digraph
{
";
+    out << "  rankdir=\"LR\";
";
+    out << "  { node [shape = box]
";
 
     auto get_proc_id = [](const IProcessor & proc) -> UInt64
     {
@@ -26,7 +28,7 @@ void printPipeline(const Processors & processors, const Statuses & statuses, Wri
     /// Nodes // TODO quoting and escaping
     for (const auto & processor : processors)
     {
-        out << "n" << get_proc_id(*processor) << "[label=\"" << processor->getName() << processor->getDescription();
+        out << "    n" << get_proc_id(*processor) << "[label=\"" << processor->getName() << processor->getDescription();
 
         if (statuses_iter != statuses.end())
         {
@@ -37,6 +39,8 @@ void printPipeline(const Processors & processors, const Statuses & statuses, Wri
         out << "\"];
";
     }
 
+    out << "  }
";
+
     /// Edges
     for (const auto & processor : processors)
     {
@@ -48,7 +52,7 @@ void printPipeline(const Processors & processors, const Statuses & statuses, Wri
             const IProcessor & curr = *processor;
             const IProcessor & next = port.getInputPort().getProcessor();
 
-            out << "n" << get_proc_id(curr) << " -> n" << get_proc_id(next) << ";
";
+            out << "  n" << get_proc_id(curr) << " -> n" << get_proc_id(next) << ";
";
         }
     }
     out << "}
";
@@ -60,4 +64,10 @@ void printPipeline(const Processors & processors, WriteBuffer & out)
     printPipeline(processors, std::vector<IProcessor::Status>(), out);
 }
 
+/// Prints pipeline in compact representation.
+/// Group processors by it's name, QueryPlanStep and QueryPlanStepGroup.
+/// If QueryPlanStep wasn't set for processor, representation may be not correct.
+/// If with_header is set, prints block header for each edge.
+void printPipelineCompact(const Processors & processors, WriteBuffer & out, bool with_header);
+
 }
diff --git a/src/Processors/ya.make b/src/Processors/ya.make
index e0a9d96e1d3d..6cf7bee1dbd8 100644
--- a/src/Processors/ya.make
+++ b/src/Processors/ya.make
@@ -105,6 +105,7 @@ SRCS(
     OffsetTransform.cpp
     Pipe.cpp
     Port.cpp
+    printPipeline.cpp
     QueryPipeline.cpp
     ResizeProcessor.cpp
     Sources/DelayedSource.cpp
@@ -157,7 +158,7 @@ SRCS(
     QueryPlan/MergeSortingStep.cpp
     QueryPlan/MergingAggregatedStep.cpp
     QueryPlan/MergingSortedStep.cpp
-    QueryPlan/OffsetsStep.cpp
+    QueryPlan/OffsetStep.cpp
     QueryPlan/PartialSortingStep.cpp
     QueryPlan/UnionStep.cpp
     QueryPlan/ReadFromPreparedSource.cpp
