diff --git a/tests/integration/helpers/keeper_utils.py b/tests/integration/helpers/keeper_utils.py
new file mode 100644
index 000000000000..681407e5e8c2
--- /dev/null
+++ b/tests/integration/helpers/keeper_utils.py
@@ -0,0 +1,41 @@
+import socket
+import time
+
+
+def get_keeper_socket(cluster, node, port=9181):
+    hosts = cluster.get_instance_ip(node.name)
+    client = socket.socket()
+    client.settimeout(10)
+    client.connect((hosts, port))
+    return client
+
+
+def send_4lw_cmd(cluster, node, cmd="ruok", port=9181):
+    client = None
+    try:
+        client = get_keeper_socket(cluster, node, port)
+        client.send(cmd.encode())
+        data = client.recv(100_000)
+        data = data.decode()
+        return data
+    finally:
+        if client is not None:
+            client.close()
+
+
+NOT_SERVING_REQUESTS_ERROR_MSG = "This instance is not currently serving requests"
+
+
+def wait_until_connected(cluster, node, port=9181):
+    while send_4lw_cmd(cluster, node, "mntr", port) == NOT_SERVING_REQUESTS_ERROR_MSG:
+        time.sleep(0.1)
+
+
+def wait_until_quorum_lost(cluster, node, port=9181):
+    while send_4lw_cmd(cluster, node, "mntr", port) != NOT_SERVING_REQUESTS_ERROR_MSG:
+        time.sleep(0.1)
+
+
+def wait_nodes(cluster, nodes):
+    for node in nodes:
+        wait_until_connected(cluster, node)
diff --git a/tests/integration/test_keeper_and_access_storage/test.py b/tests/integration/test_keeper_and_access_storage/test.py
index ae6b0085094d..6ec307f7082f 100644
--- a/tests/integration/test_keeper_and_access_storage/test.py
+++ b/tests/integration/test_keeper_and_access_storage/test.py
@@ -15,6 +15,7 @@
 def started_cluster():
     try:
         cluster.start()
+
         yield cluster
     finally:
         cluster.shutdown()
diff --git a/tests/integration/test_keeper_clickhouse_hard_restart/configs/enable_keeper.xml b/tests/integration/test_keeper_clickhouse_hard_restart/configs/enable_keeper.xml
deleted file mode 100644
index c1d38a1de52f..000000000000
--- a/tests/integration/test_keeper_clickhouse_hard_restart/configs/enable_keeper.xml
+++ /dev/null
@@ -1,22 +0,0 @@
-<clickhouse>
-    <keeper_server>
-        <tcp_port>9181</tcp_port>
-        <server_id>1</server_id>
-        <log_storage_path>/var/lib/clickhouse/coordination/log</log_storage_path>
-        <snapshot_storage_path>/var/lib/clickhouse/coordination/snapshots</snapshot_storage_path>
-
-        <coordination_settings>
-            <operation_timeout_ms>5000</operation_timeout_ms>
-            <session_timeout_ms>10000</session_timeout_ms>
-            <raft_logs_level>trace</raft_logs_level>
-        </coordination_settings>
-
-        <raft_configuration>
-            <server>
-                <id>1</id>
-                <hostname>node1</hostname>
-                <port>9234</port>
-            </server>
-        </raft_configuration>
-    </keeper_server>
-</clickhouse>
diff --git a/tests/integration/test_keeper_clickhouse_hard_restart/configs/keeper_conf.xml b/tests/integration/test_keeper_clickhouse_hard_restart/configs/keeper_conf.xml
deleted file mode 100644
index ebb0d98ddf46..000000000000
--- a/tests/integration/test_keeper_clickhouse_hard_restart/configs/keeper_conf.xml
+++ /dev/null
@@ -1,8 +0,0 @@
-<clickhouse>
-    <zookeeper>
-        <node index="1">
-            <host>node1</host>
-            <port>9181</port>
-        </node>
-    </zookeeper>
-</clickhouse>
diff --git a/tests/integration/test_keeper_force_recovery/test.py b/tests/integration/test_keeper_force_recovery/test.py
index f3bb0ca56e3b..f7c3787b4d8b 100644
--- a/tests/integration/test_keeper_force_recovery/test.py
+++ b/tests/integration/test_keeper_force_recovery/test.py
@@ -2,6 +2,7 @@
 import pytest
 import socket
 from helpers.cluster import ClickHouseCluster
+import helpers.keeper_utils as keeper_utils
 import time
 
 
@@ -62,37 +63,6 @@ def get_fake_zk(nodename, timeout=30.0):
     return _fake_zk_instance
 
 
-def get_keeper_socket(node_name):
-    hosts = cluster.get_instance_ip(node_name)
-    client = socket.socket()
-    client.settimeout(10)
-    client.connect((hosts, 9181))
-    return client
-
-
-def send_4lw_cmd(node_name, cmd="ruok"):
-    client = None
-    try:
-        client = get_keeper_socket(node_name)
-        client.send(cmd.encode())
-        data = client.recv(100_000)
-        data = data.decode()
-        return data
-    finally:
-        if client is not None:
-            client.close()
-
-
-def wait_until_connected(node_name):
-    while send_4lw_cmd(node_name, "mntr") == NOT_SERVING_REQUESTS_ERROR_MSG:
-        time.sleep(0.1)
-
-
-def wait_nodes(nodes):
-    for node in nodes:
-        wait_until_connected(node.name)
-
-
 def wait_and_assert_data(zk, path, data):
     while zk.retry(zk.exists, path) is None:
         time.sleep(0.1)
@@ -104,9 +74,6 @@ def close_zk(zk):
     zk.close()
 
 
-NOT_SERVING_REQUESTS_ERROR_MSG = "This instance is not currently serving requests"
-
-
 def test_cluster_recovery(started_cluster):
     node_zks = []
     try:
@@ -114,7 +81,7 @@ def test_cluster_recovery(started_cluster):
         for node in nodes[CLUSTER_SIZE:]:
             node.stop_clickhouse()
 
-        wait_nodes(nodes[:CLUSTER_SIZE])
+        keeper_utils.wait_nodes(cluster, nodes[:CLUSTER_SIZE])
 
         node_zks = [get_fake_zk(node.name) for node in nodes[:CLUSTER_SIZE]]
 
@@ -152,7 +119,7 @@ def assert_all_data(zk):
             wait_and_assert_data(node_zk, "/test_force_recovery_extra", "somedataextra")
 
         nodes[0].start_clickhouse()
-        wait_until_connected(nodes[0].name)
+        keeper_utils.wait_until_connected(cluster, nodes[0])
         node_zks[0] = get_fake_zk(nodes[0].name)
         wait_and_assert_data(node_zks[0], "/test_force_recovery_extra", "somedataextra")
 
@@ -167,8 +134,7 @@ def assert_all_data(zk):
             node.stop_clickhouse()
 
         # wait for node1 to lose quorum
-        while send_4lw_cmd(nodes[0].name, "mntr") != NOT_SERVING_REQUESTS_ERROR_MSG:
-            time.sleep(0.2)
+        keeper_utils.wait_until_quorum_lost(cluster, nodes[0])
 
         nodes[0].copy_file_to_container(
             os.path.join(CONFIG_DIR, "recovered_keeper1.xml"),
@@ -177,9 +143,15 @@ def assert_all_data(zk):
 
         nodes[0].query("SYSTEM RELOAD CONFIG")
 
-        assert send_4lw_cmd(nodes[0].name, "mntr") == NOT_SERVING_REQUESTS_ERROR_MSG
-        send_4lw_cmd(nodes[0].name, "rcvr")
-        assert send_4lw_cmd(nodes[0].name, "mntr") == NOT_SERVING_REQUESTS_ERROR_MSG
+        assert (
+            keeper_utils.send_4lw_cmd(cluster, nodes[0], "mntr")
+            == keeper_utils.NOT_SERVING_REQUESTS_ERROR_MSG
+        )
+        keeper_utils.send_4lw_cmd(cluster, nodes[0], "rcvr")
+        assert (
+            keeper_utils.send_4lw_cmd(cluster, nodes[0], "mntr")
+            == keeper_utils.NOT_SERVING_REQUESTS_ERROR_MSG
+        )
 
         # add one node to restore the quorum
         nodes[CLUSTER_SIZE].copy_file_to_container(
@@ -191,10 +163,10 @@ def assert_all_data(zk):
         )
 
         nodes[CLUSTER_SIZE].start_clickhouse()
-        wait_until_connected(nodes[CLUSTER_SIZE].name)
+        keeper_utils.wait_until_connected(cluster, nodes[CLUSTER_SIZE])
 
         # node1 should have quorum now and accept requests
-        wait_until_connected(nodes[0].name)
+        keeper_utils.wait_until_connected(cluster, nodes[0])
 
         node_zks.append(get_fake_zk(nodes[CLUSTER_SIZE].name))
 
@@ -206,7 +178,7 @@ def assert_all_data(zk):
                 f"/etc/clickhouse-server/config.d/enable_keeper{i+1}.xml",
             )
             node.start_clickhouse()
-            wait_until_connected(node.name)
+            keeper_utils.wait_until_connected(cluster, node)
             node_zks.append(get_fake_zk(node.name))
 
         # refresh old zk sessions
@@ -223,7 +195,7 @@ def assert_all_data(zk):
         wait_and_assert_data(node_zks[-1], "/test_force_recovery_last", "somedatalast")
 
         nodes[0].start_clickhouse()
-        wait_until_connected(nodes[0].name)
+        keeper_utils.wait_until_connected(cluster, nodes[0])
         node_zks[0] = get_fake_zk(nodes[0].name)
         for zk in node_zks[:nodes_left]:
             assert_all_data(zk)
diff --git a/tests/integration/test_keeper_force_recovery_single_node/test.py b/tests/integration/test_keeper_force_recovery_single_node/test.py
index 0a554e331195..1c0d5e9a3062 100644
--- a/tests/integration/test_keeper_force_recovery_single_node/test.py
+++ b/tests/integration/test_keeper_force_recovery_single_node/test.py
@@ -2,10 +2,11 @@
 import pytest
 import socket
 from helpers.cluster import ClickHouseCluster
+import helpers.keeper_utils as keeper_utils
 import time
 
 
-from kazoo.client import KazooClient
+from kazoo.client import KazooClient, KazooRetry
 
 CLUSTER_SIZE = 3
 
@@ -45,47 +46,19 @@ def started_cluster():
 
 def get_fake_zk(nodename, timeout=30.0):
     _fake_zk_instance = KazooClient(
-        hosts=cluster.get_instance_ip(nodename) + ":9181", timeout=timeout
+        hosts=cluster.get_instance_ip(nodename) + ":9181",
+        timeout=timeout,
+        connection_retry=KazooRetry(max_tries=10),
+        command_retry=KazooRetry(max_tries=10),
     )
     _fake_zk_instance.start()
     return _fake_zk_instance
 
 
-def get_keeper_socket(node_name):
-    hosts = cluster.get_instance_ip(node_name)
-    client = socket.socket()
-    client.settimeout(10)
-    client.connect((hosts, 9181))
-    return client
-
-
-def send_4lw_cmd(node_name, cmd="ruok"):
-    client = None
-    try:
-        client = get_keeper_socket(node_name)
-        client.send(cmd.encode())
-        data = client.recv(100_000)
-        data = data.decode()
-        return data
-    finally:
-        if client is not None:
-            client.close()
-
-
-def wait_until_connected(node_name):
-    while send_4lw_cmd(node_name, "mntr") == NOT_SERVING_REQUESTS_ERROR_MSG:
-        time.sleep(0.1)
-
-
-def wait_nodes(nodes):
-    for node in nodes:
-        wait_until_connected(node.name)
-
-
 def wait_and_assert_data(zk, path, data):
-    while zk.exists(path) is None:
+    while zk.retry(zk.exists, path) is None:
         time.sleep(0.1)
-    assert zk.get(path)[0] == data.encode()
+    assert zk.retry(zk.get, path)[0] == data.encode()
 
 
 def close_zk(zk):
@@ -93,20 +66,17 @@ def close_zk(zk):
     zk.close()
 
 
-NOT_SERVING_REQUESTS_ERROR_MSG = "This instance is not currently serving requests"
-
-
 def test_cluster_recovery(started_cluster):
     node_zks = []
     try:
-        wait_nodes(nodes)
+        keeper_utils.wait_nodes(cluster, nodes)
 
         node_zks = [get_fake_zk(node.name) for node in nodes]
 
         data_in_cluster = []
 
         def add_data(zk, path, data):
-            zk.create(path, data.encode())
+            zk.retry(zk.create, path, data.encode())
             data_in_cluster.append((path, data))
 
         def assert_all_data(zk):
@@ -137,7 +107,7 @@ def assert_all_data(zk):
             wait_and_assert_data(node_zk, "/test_force_recovery_extra", "somedataextra")
 
         nodes[0].start_clickhouse()
-        wait_until_connected(nodes[0].name)
+        keeper_utils.wait_until_connected(cluster, nodes[0])
 
         node_zks[0] = get_fake_zk(nodes[0].name)
         wait_and_assert_data(node_zks[0], "/test_force_recovery_extra", "somedataextra")
@@ -156,7 +126,7 @@ def assert_all_data(zk):
         )
 
         nodes[0].start_clickhouse()
-        wait_until_connected(nodes[0].name)
+        keeper_utils.wait_until_connected(cluster, nodes[0])
 
         assert_all_data(get_fake_zk(nodes[0].name))
     finally:
diff --git a/tests/integration/test_keeper_four_word_command/test.py b/tests/integration/test_keeper_four_word_command/test.py
index e8136d322d34..30abc7422c49 100644
--- a/tests/integration/test_keeper_four_word_command/test.py
+++ b/tests/integration/test_keeper_four_word_command/test.py
@@ -1,6 +1,7 @@
 import socket
 import pytest
 from helpers.cluster import ClickHouseCluster
+import helpers.keeper_utils as keeper_utils
 import random
 import string
 import os
@@ -25,6 +26,10 @@
 from kazoo.client import KazooClient, KazooState
 
 
+def wait_nodes():
+    keeper_utils.wait_nodes(cluster, [node1, node2, node3])
+
+
 @pytest.fixture(scope="module")
 def started_cluster():
     try:
@@ -56,28 +61,6 @@ def clear_znodes():
         destroy_zk_client(zk)
 
 
-def wait_node(node):
-    for _ in range(100):
-        zk = None
-        try:
-            zk = get_fake_zk(node.name, timeout=30.0)
-            # zk.create("/test", sequence=True)
-            print("node", node.name, "ready")
-            break
-        except Exception as ex:
-            time.sleep(0.2)
-            print("Waiting until", node.name, "will be ready, exception", ex)
-        finally:
-            destroy_zk_client(zk)
-    else:
-        raise Exception("Can't wait node", node.name, "to become ready")
-
-
-def wait_nodes():
-    for n in [node1, node2, node3]:
-        wait_node(n)
-
-
 def get_fake_zk(nodename, timeout=30.0):
     _fake_zk_instance = KazooClient(
         hosts=cluster.get_instance_ip(nodename) + ":9181", timeout=timeout
@@ -86,23 +69,15 @@ def get_fake_zk(nodename, timeout=30.0):
     return _fake_zk_instance
 
 
-def get_keeper_socket(node_name):
-    hosts = cluster.get_instance_ip(node_name)
-    client = socket.socket()
-    client.settimeout(10)
-    client.connect((hosts, 9181))
-    return client
-
-
 def close_keeper_socket(cli):
     if cli is not None:
         cli.close()
 
 
-def reset_node_stats(node_name=node1.name):
+def reset_node_stats(node=node1):
     client = None
     try:
-        client = get_keeper_socket(node_name)
+        client = keeper_utils.get_keeper_socket(cluster, node)
         client.send(b"srst")
         client.recv(10)
     finally:
@@ -110,23 +85,10 @@ def reset_node_stats(node_name=node1.name):
             client.close()
 
 
-def send_4lw_cmd(node_name=node1.name, cmd="ruok"):
-    client = None
-    try:
-        client = get_keeper_socket(node_name)
-        client.send(cmd.encode())
-        data = client.recv(100_000)
-        data = data.decode()
-        return data
-    finally:
-        if client is not None:
-            client.close()
-
-
-def reset_conn_stats(node_name=node1.name):
+def reset_conn_stats(node=node1):
     client = None
     try:
-        client = get_keeper_socket(node_name)
+        client = keeper_utils.get_keeper_socket(cluster, node)
         client.send(b"crst")
         client.recv(10_000)
     finally:
@@ -138,7 +100,7 @@ def test_cmd_ruok(started_cluster):
     client = None
     try:
         wait_nodes()
-        data = send_4lw_cmd(cmd="ruok")
+        data = keeper_utils.send_4lw_cmd(cluster, node1, cmd="ruok")
         assert data == "imok"
     finally:
         close_keeper_socket(client)
@@ -187,7 +149,7 @@ def test_cmd_mntr(started_cluster):
         clear_znodes()
 
         # reset stat first
-        reset_node_stats(node1.name)
+        reset_node_stats(node1)
 
         zk = get_fake_zk(node1.name, timeout=30.0)
         do_some_action(
@@ -200,7 +162,7 @@ def test_cmd_mntr(started_cluster):
             delete_cnt=2,
         )
 
-        data = send_4lw_cmd(cmd="mntr")
+        data = keeper_utils.send_4lw_cmd(cluster, node1, cmd="mntr")
 
         # print(data.decode())
         reader = csv.reader(data.split("
"), delimiter="\t")
@@ -252,10 +214,10 @@ def test_cmd_srst(started_cluster):
         wait_nodes()
         clear_znodes()
 
-        data = send_4lw_cmd(cmd="srst")
+        data = keeper_utils.send_4lw_cmd(cluster, node1, cmd="srst")
         assert data.strip() == "Server stats reset."
 
-        data = send_4lw_cmd(cmd="mntr")
+        data = keeper_utils.send_4lw_cmd(cluster, node1, cmd="mntr")
         assert len(data) != 0
 
         # print(data)
@@ -279,7 +241,7 @@ def test_cmd_conf(started_cluster):
         wait_nodes()
         clear_znodes()
 
-        data = send_4lw_cmd(cmd="conf")
+        data = keeper_utils.send_4lw_cmd(cluster, node1, cmd="conf")
 
         reader = csv.reader(data.split("
"), delimiter="=")
         result = {}
@@ -335,8 +297,8 @@ def test_cmd_conf(started_cluster):
 
 def test_cmd_isro(started_cluster):
     wait_nodes()
-    assert send_4lw_cmd(node1.name, "isro") == "rw"
-    assert send_4lw_cmd(node2.name, "isro") == "ro"
+    assert keeper_utils.send_4lw_cmd(cluster, node1, "isro") == "rw"
+    assert keeper_utils.send_4lw_cmd(cluster, node2, "isro") == "ro"
 
 
 def test_cmd_srvr(started_cluster):
@@ -345,12 +307,12 @@ def test_cmd_srvr(started_cluster):
         wait_nodes()
         clear_znodes()
 
-        reset_node_stats(node1.name)
+        reset_node_stats(node1)
 
         zk = get_fake_zk(node1.name, timeout=30.0)
         do_some_action(zk, create_cnt=10)
 
-        data = send_4lw_cmd(cmd="srvr")
+        data = keeper_utils.send_4lw_cmd(cluster, node1, cmd="srvr")
 
         print("srvr output -------------------------------------")
         print(data)
@@ -380,13 +342,13 @@ def test_cmd_stat(started_cluster):
     try:
         wait_nodes()
         clear_znodes()
-        reset_node_stats(node1.name)
-        reset_conn_stats(node1.name)
+        reset_node_stats(node1)
+        reset_conn_stats(node1)
 
         zk = get_fake_zk(node1.name, timeout=30.0)
         do_some_action(zk, create_cnt=10)
 
-        data = send_4lw_cmd(cmd="stat")
+        data = keeper_utils.send_4lw_cmd(cluster, node1, cmd="stat")
 
         print("stat output -------------------------------------")
         print(data)
@@ -440,7 +402,7 @@ def test_cmd_cons(started_cluster):
         zk = get_fake_zk(node1.name, timeout=30.0)
         do_some_action(zk, create_cnt=10)
 
-        data = send_4lw_cmd(cmd="cons")
+        data = keeper_utils.send_4lw_cmd(cluster, node1, cmd="cons")
 
         print("cons output -------------------------------------")
         print(data)
@@ -485,12 +447,12 @@ def test_cmd_crst(started_cluster):
         zk = get_fake_zk(node1.name, timeout=30.0)
         do_some_action(zk, create_cnt=10)
 
-        data = send_4lw_cmd(cmd="crst")
+        data = keeper_utils.send_4lw_cmd(cluster, node1, cmd="crst")
 
         print("crst output -------------------------------------")
         print(data)
 
-        data = send_4lw_cmd(cmd="cons")
+        data = keeper_utils.send_4lw_cmd(cluster, node1, cmd="cons")
         print("cons output(after crst) -------------------------------------")
         print(data)
 
@@ -537,7 +499,7 @@ def test_cmd_dump(started_cluster):
         zk = get_fake_zk(node1.name, timeout=30.0)
         do_some_action(zk, ephemeral_cnt=2)
 
-        data = send_4lw_cmd(cmd="dump")
+        data = keeper_utils.send_4lw_cmd(cluster, node1, cmd="dump")
 
         print("dump output -------------------------------------")
         print(data)
@@ -563,7 +525,7 @@ def test_cmd_wchs(started_cluster):
         zk = get_fake_zk(node1.name, timeout=30.0)
         do_some_action(zk, create_cnt=2, watch_cnt=2)
 
-        data = send_4lw_cmd(cmd="wchs")
+        data = keeper_utils.send_4lw_cmd(cluster, node1, cmd="wchs")
 
         print("wchs output -------------------------------------")
         print(data)
@@ -598,7 +560,7 @@ def test_cmd_wchc(started_cluster):
         zk = get_fake_zk(node1.name, timeout=30.0)
         do_some_action(zk, create_cnt=2, watch_cnt=2)
 
-        data = send_4lw_cmd(cmd="wchc")
+        data = keeper_utils.send_4lw_cmd(cluster, node1, cmd="wchc")
 
         print("wchc output -------------------------------------")
         print(data)
@@ -622,7 +584,7 @@ def test_cmd_wchp(started_cluster):
         zk = get_fake_zk(node1.name, timeout=30.0)
         do_some_action(zk, create_cnt=2, watch_cnt=2)
 
-        data = send_4lw_cmd(cmd="wchp")
+        data = keeper_utils.send_4lw_cmd(cluster, node1, cmd="wchp")
 
         print("wchp output -------------------------------------")
         print(data)
diff --git a/tests/integration/test_keeper_incorrect_config/test.py b/tests/integration/test_keeper_incorrect_config/test.py
index cedb195a6e0f..95482745b314 100644
--- a/tests/integration/test_keeper_incorrect_config/test.py
+++ b/tests/integration/test_keeper_incorrect_config/test.py
@@ -204,7 +204,7 @@ def started_cluster():
 """
 
 
-def test_duplicate_endpoint(started_cluster):
+def test_invalid_configs(started_cluster):
     node1.stop_clickhouse()
 
     def assert_config_fails(config):
diff --git a/tests/integration/test_keeper_mntr_pressure/test.py b/tests/integration/test_keeper_mntr_pressure/test.py
index 471767210d6a..d351b238eade 100644
--- a/tests/integration/test_keeper_mntr_pressure/test.py
+++ b/tests/integration/test_keeper_mntr_pressure/test.py
@@ -1,6 +1,7 @@
 #!/usr/bin/env python3
 
 from helpers.cluster import ClickHouseCluster
+import helpers.keeper_utils as keeper_utils
 import pytest
 import random
 import string
@@ -37,40 +38,22 @@ def started_cluster():
         cluster.shutdown()
 
 
-def get_keeper_socket(node_name):
-    hosts = cluster.get_instance_ip(node_name)
-    client = socket.socket()
-    client.settimeout(10)
-    client.connect((hosts, 9181))
-    return client
-
-
 def close_keeper_socket(cli):
     if cli is not None:
         cli.close()
 
 
-def send_4lw_cmd(node_name, cmd="ruok"):
-    client = None
-    try:
-        client = get_keeper_socket(node_name)
-        client.send(cmd.encode())
-        data = client.recv(100_000)
-        data = data.decode()
-        return data
-    finally:
-        if client is not None:
-            client.close()
-
-
 def test_aggressive_mntr(started_cluster):
-    def go_mntr(node_name):
-        for _ in range(100000):
-            print(node_name, send_4lw_cmd(node_name, "mntr"))
-
-    node1_thread = threading.Thread(target=lambda: go_mntr(node1.name))
-    node2_thread = threading.Thread(target=lambda: go_mntr(node2.name))
-    node3_thread = threading.Thread(target=lambda: go_mntr(node3.name))
+    def go_mntr(node):
+        for _ in range(10000):
+            try:
+                print(node.name, keeper_utils.send_4lw_cmd(cluster, node, "mntr"))
+            except ConnectionRefusedError:
+                pass
+
+    node1_thread = threading.Thread(target=lambda: go_mntr(node1))
+    node2_thread = threading.Thread(target=lambda: go_mntr(node2))
+    node3_thread = threading.Thread(target=lambda: go_mntr(node3))
     node1_thread.start()
     node2_thread.start()
     node3_thread.start()
@@ -78,8 +61,7 @@ def go_mntr(node_name):
     node2.stop_clickhouse()
     node3.stop_clickhouse()
 
-    while send_4lw_cmd(node1.name, "mntr") != NOT_SERVING_REQUESTS_ERROR_MSG:
-        time.sleep(0.2)
+    keeper_utils.wait_until_quorum_lost(cluster, node1)
 
     node1.stop_clickhouse()
     starters = []
diff --git a/tests/integration/test_keeper_multinode_blocade_leader/test.py b/tests/integration/test_keeper_multinode_blocade_leader/test.py
index d6d01a5d0a64..a7a80d90a58e 100644
--- a/tests/integration/test_keeper_multinode_blocade_leader/test.py
+++ b/tests/integration/test_keeper_multinode_blocade_leader/test.py
@@ -1,5 +1,6 @@
 import pytest
 from helpers.cluster import ClickHouseCluster
+import helpers.keeper_utils as keeper_utils
 import random
 import string
 import os
@@ -55,31 +56,6 @@ def smaller_exception(ex):
     return "
".join(str(ex).split("
")[0:2])
 
 
-def wait_node(node):
-    for _ in range(100):
-        zk = None
-        try:
-            node.query("SELECT * FROM system.zookeeper WHERE path = '/'")
-            zk = get_fake_zk(node.name, timeout=30.0)
-            zk.create("/test", sequence=True)
-            print("node", node.name, "ready")
-            break
-        except Exception as ex:
-            time.sleep(0.2)
-            print("Waiting until", node.name, "will be ready, exception", ex)
-        finally:
-            if zk:
-                zk.stop()
-                zk.close()
-    else:
-        raise Exception("Can't wait node", node.name, "to become ready")
-
-
-def wait_nodes():
-    for node in [node1, node2, node3]:
-        wait_node(node)
-
-
 def get_fake_zk(nodename, timeout=30.0):
     _fake_zk_instance = KazooClient(
         hosts=cluster.get_instance_ip(nodename) + ":9181", timeout=timeout
@@ -88,6 +64,10 @@ def get_fake_zk(nodename, timeout=30.0):
     return _fake_zk_instance
 
 
+def wait_nodes():
+    keeper_utils.wait_nodes(cluster, [node1, node2, node3])
+
+
 # in extremely rare case it can take more than 5 minutes in debug build with sanitizer
 @pytest.mark.timeout(600)
 def test_blocade_leader(started_cluster):
diff --git a/tests/integration/test_keeper_multinode_simple/test.py b/tests/integration/test_keeper_multinode_simple/test.py
index 694600acc677..1dcbb290fa8c 100644
--- a/tests/integration/test_keeper_multinode_simple/test.py
+++ b/tests/integration/test_keeper_multinode_simple/test.py
@@ -1,5 +1,6 @@
 import pytest
 from helpers.cluster import ClickHouseCluster
+import helpers.keeper_utils as keeper_utils
 import random
 import string
 import os
@@ -43,29 +44,8 @@ def smaller_exception(ex):
     return "
".join(str(ex).split("
")[0:2])
 
 
-def wait_node(node):
-    for _ in range(100):
-        zk = None
-        try:
-            node.query("SELECT * FROM system.zookeeper WHERE path = '/'")
-            zk = get_fake_zk(node.name, timeout=30.0)
-            zk.create("/test", sequence=True)
-            print("node", node.name, "ready")
-            break
-        except Exception as ex:
-            time.sleep(0.2)
-            print("Waiting until", node.name, "will be ready, exception", ex)
-        finally:
-            if zk:
-                zk.stop()
-                zk.close()
-    else:
-        raise Exception("Can't wait node", node.name, "to become ready")
-
-
 def wait_nodes():
-    for node in [node1, node2, node3]:
-        wait_node(node)
+    keeper_utils.wait_nodes(cluster, [node1, node2, node3])
 
 
 def get_fake_zk(nodename, timeout=30.0):
diff --git a/tests/integration/test_keeper_nodes_add/test.py b/tests/integration/test_keeper_nodes_add/test.py
index c3449534e872..aad674332ac3 100644
--- a/tests/integration/test_keeper_nodes_add/test.py
+++ b/tests/integration/test_keeper_nodes_add/test.py
@@ -2,6 +2,7 @@
 
 import pytest
 from helpers.cluster import ClickHouseCluster
+import helpers.keeper_utils as keeper_utils
 import random
 import string
 import os
@@ -41,9 +42,11 @@ def started_cluster():
 
 def start(node):
     node.start_clickhouse()
+    keeper_utils.wait_until_connected(cluster, node)
 
 
 def test_nodes_add(started_cluster):
+    keeper_utils.wait_until_connected(cluster, node1)
     zk_conn = get_fake_zk(node1)
 
     for i in range(100):
@@ -62,6 +65,7 @@ def test_nodes_add(started_cluster):
     )
     node1.query("SYSTEM RELOAD CONFIG")
     waiter.wait()
+    keeper_utils.wait_until_connected(cluster, node2)
 
     zk_conn2 = get_fake_zk(node2)
 
@@ -93,6 +97,7 @@ def test_nodes_add(started_cluster):
     node2.query("SYSTEM RELOAD CONFIG")
 
     waiter.wait()
+    keeper_utils.wait_until_connected(cluster, node3)
     zk_conn3 = get_fake_zk(node3)
 
     for i in range(100):
diff --git a/tests/integration/test_keeper_nodes_move/test.py b/tests/integration/test_keeper_nodes_move/test.py
index 31082846fb8b..1e3bd95c5e78 100644
--- a/tests/integration/test_keeper_nodes_move/test.py
+++ b/tests/integration/test_keeper_nodes_move/test.py
@@ -11,6 +11,7 @@
 import time
 from multiprocessing.dummy import Pool
 from helpers.test_tools import assert_eq_with_retry
+import helpers.keeper_utils as keeper_utils
 from kazoo.client import KazooClient, KazooState
 
 cluster = ClickHouseCluster(__file__)
@@ -41,6 +42,7 @@ def started_cluster():
 
 def start(node):
     node.start_clickhouse()
+    keeper_utils.wait_until_connected(cluster, node)
 
 
 def get_fake_zk(node, timeout=30.0):
diff --git a/tests/integration/test_keeper_nodes_remove/test.py b/tests/integration/test_keeper_nodes_remove/test.py
index 13303d320eb4..59bdaadf2e2b 100644
--- a/tests/integration/test_keeper_nodes_remove/test.py
+++ b/tests/integration/test_keeper_nodes_remove/test.py
@@ -2,6 +2,7 @@
 
 import pytest
 from helpers.cluster import ClickHouseCluster
+import time
 import os
 from kazoo.client import KazooClient, KazooState
 
@@ -79,9 +80,12 @@ def test_nodes_remove(started_cluster):
         assert zk_conn.exists("test_two_" + str(i)) is not None
         assert zk_conn.exists("test_two_" + str(100 + i)) is not None
 
-    with pytest.raises(Exception):
+    try:
         zk_conn3 = get_fake_zk(node3)
         zk_conn3.sync("/test_two_0")
+        time.sleep(0.1)
+    except Exception:
+        pass
 
     node3.stop_clickhouse()
 
@@ -91,6 +95,7 @@ def test_nodes_remove(started_cluster):
     )
 
     node1.query("SYSTEM RELOAD CONFIG")
+
     zk_conn = get_fake_zk(node1)
     zk_conn.sync("/test_two_0")
 
@@ -98,8 +103,11 @@ def test_nodes_remove(started_cluster):
         assert zk_conn.exists("test_two_" + str(i)) is not None
         assert zk_conn.exists("test_two_" + str(100 + i)) is not None
 
-    with pytest.raises(Exception):
+    try:
         zk_conn2 = get_fake_zk(node2)
         zk_conn2.sync("/test_two_0")
+        time.sleep(0.1)
+    except Exception:
+        pass
 
     node2.stop_clickhouse()
diff --git a/tests/integration/test_keeper_persistent_log/test.py b/tests/integration/test_keeper_persistent_log/test.py
index 377fa436a87a..70cc14fe26df 100644
--- a/tests/integration/test_keeper_persistent_log/test.py
+++ b/tests/integration/test_keeper_persistent_log/test.py
@@ -46,6 +46,10 @@ def get_connection_zk(nodename, timeout=30.0):
     return _fake_zk_instance
 
 
+def restart_clickhouse():
+    node.restart_clickhouse(kill=True)
+
+
 def test_state_after_restart(started_cluster):
     try:
         node_zk = None
@@ -62,7 +66,7 @@ def test_state_after_restart(started_cluster):
             if i % 7 == 0:
                 node_zk.delete("/test_state_after_restart/node" + str(i))
 
-        node.restart_clickhouse(kill=True)
+        restart_clickhouse()
 
         node_zk2 = get_connection_zk("node")
 
@@ -111,7 +115,7 @@ def test_state_duplicate_restart(started_cluster):
             if i % 7 == 0:
                 node_zk.delete("/test_state_duplicated_restart/node" + str(i))
 
-        node.restart_clickhouse(kill=True)
+        restart_clickhouse()
 
         node_zk2 = get_connection_zk("node")
 
@@ -119,7 +123,7 @@ def test_state_duplicate_restart(started_cluster):
         node_zk2.create("/test_state_duplicated_restart/just_test2")
         node_zk2.create("/test_state_duplicated_restart/just_test3")
 
-        node.restart_clickhouse(kill=True)
+        restart_clickhouse()
 
         node_zk3 = get_connection_zk("node")
 
@@ -159,6 +163,7 @@ def test_state_duplicate_restart(started_cluster):
 
 # http://zookeeper-user.578899.n2.nabble.com/Why-are-ephemeral-nodes-written-to-disk-tp7583403p7583418.html
 def test_ephemeral_after_restart(started_cluster):
+
     try:
         node_zk = None
         node_zk2 = None
@@ -176,7 +181,7 @@ def test_ephemeral_after_restart(started_cluster):
             if i % 7 == 0:
                 node_zk.delete("/test_ephemeral_after_restart/node" + str(i))
 
-        node.restart_clickhouse(kill=True)
+        restart_clickhouse()
 
         node_zk2 = get_connection_zk("node")
 
diff --git a/tests/integration/test_keeper_persistent_log_multinode/test.py b/tests/integration/test_keeper_persistent_log_multinode/test.py
index f15e772fd5f3..1552abd32e94 100644
--- a/tests/integration/test_keeper_persistent_log_multinode/test.py
+++ b/tests/integration/test_keeper_persistent_log_multinode/test.py
@@ -1,6 +1,7 @@
 #!/usr/bin/env python3
 import pytest
 from helpers.cluster import ClickHouseCluster
+import helpers.keeper_utils as keeper_utils
 import random
 import string
 import os
@@ -26,10 +27,15 @@
 from kazoo.client import KazooClient, KazooState
 
 
+def wait_nodes():
+    keeper_utils.wait_nodes(cluster, [node1, node2, node3])
+
+
 @pytest.fixture(scope="module")
 def started_cluster():
     try:
         cluster.start()
+        wait_nodes()
 
         yield cluster
 
@@ -100,6 +106,8 @@ def test_restart_multinode(started_cluster):
     node1.restart_clickhouse(kill=True)
     node2.restart_clickhouse(kill=True)
     node3.restart_clickhouse(kill=True)
+    wait_nodes()
+
     for i in range(100):
         try:
             node1_zk = get_fake_zk("node1")
diff --git a/tests/integration/test_keeper_remove_leader/configs/enable_keeper1.xml b/tests/integration/test_keeper_remove_leader/configs/enable_keeper1.xml
deleted file mode 100644
index 1e57d42016d1..000000000000
--- a/tests/integration/test_keeper_remove_leader/configs/enable_keeper1.xml
+++ /dev/null
@@ -1,34 +0,0 @@
-<clickhouse>
-    <keeper_server>
-        <tcp_port>9181</tcp_port>
-        <server_id>1</server_id>
-        <log_storage_path>/var/lib/clickhouse/coordination/log</log_storage_path>
-        <snapshot_storage_path>/var/lib/clickhouse/coordination/snapshots</snapshot_storage_path>
-
-        <coordination_settings>
-            <operation_timeout_ms>5000</operation_timeout_ms>
-            <session_timeout_ms>10000</session_timeout_ms>
-            <raft_logs_level>trace</raft_logs_level>
-        </coordination_settings>
-
-        <raft_configuration>
-            <server>
-                <id>1</id>
-                <hostname>node1</hostname>
-                <port>9234</port>
-            </server>
-            <server>
-                <id>2</id>
-                <hostname>node2</hostname>
-                <port>9234</port>
-                <start_as_follower>true</start_as_follower>
-            </server>
-            <server>
-                <id>3</id>
-                <hostname>node3</hostname>
-                <port>9234</port>
-                <start_as_follower>true</start_as_follower>
-            </server>
-        </raft_configuration>
-    </keeper_server>
-</clickhouse>
diff --git a/tests/integration/test_keeper_remove_leader/configs/enable_keeper2.xml b/tests/integration/test_keeper_remove_leader/configs/enable_keeper2.xml
deleted file mode 100644
index 98422b41c9b1..000000000000
--- a/tests/integration/test_keeper_remove_leader/configs/enable_keeper2.xml
+++ /dev/null
@@ -1,34 +0,0 @@
-<clickhouse>
-    <keeper_server>
-        <tcp_port>9181</tcp_port>
-        <server_id>2</server_id>
-        <log_storage_path>/var/lib/clickhouse/coordination/log</log_storage_path>
-        <snapshot_storage_path>/var/lib/clickhouse/coordination/snapshots</snapshot_storage_path>
-
-        <coordination_settings>
-            <operation_timeout_ms>5000</operation_timeout_ms>
-            <session_timeout_ms>10000</session_timeout_ms>
-            <raft_logs_level>trace</raft_logs_level>
-        </coordination_settings>
-
-        <raft_configuration>
-            <server>
-                <id>1</id>
-                <hostname>node1</hostname>
-                <port>9234</port>
-            </server>
-            <server>
-                <id>2</id>
-                <hostname>node2</hostname>
-                <port>9234</port>
-                <start_as_follower>true</start_as_follower>
-            </server>
-            <server>
-                <id>3</id>
-                <hostname>node3</hostname>
-                <port>9234</port>
-                <start_as_follower>true</start_as_follower>
-            </server>
-        </raft_configuration>
-    </keeper_server>
-</clickhouse>
diff --git a/tests/integration/test_keeper_remove_leader/configs/enable_keeper3.xml b/tests/integration/test_keeper_remove_leader/configs/enable_keeper3.xml
deleted file mode 100644
index 43800bd2dfb6..000000000000
--- a/tests/integration/test_keeper_remove_leader/configs/enable_keeper3.xml
+++ /dev/null
@@ -1,34 +0,0 @@
-<clickhouse>
-    <keeper_server>
-        <tcp_port>9181</tcp_port>
-        <server_id>3</server_id>
-        <log_storage_path>/var/lib/clickhouse/coordination/log</log_storage_path>
-        <snapshot_storage_path>/var/lib/clickhouse/coordination/snapshots</snapshot_storage_path>
-
-        <coordination_settings>
-            <operation_timeout_ms>5000</operation_timeout_ms>
-            <session_timeout_ms>10000</session_timeout_ms>
-            <raft_logs_level>trace</raft_logs_level>
-        </coordination_settings>
-
-        <raft_configuration>
-            <server>
-                <id>1</id>
-                <hostname>node1</hostname>
-                <port>9234</port>
-            </server>
-            <server>
-                <id>2</id>
-                <hostname>node2</hostname>
-                <port>9234</port>
-                <start_as_follower>true</start_as_follower>
-            </server>
-            <server>
-                <id>3</id>
-                <hostname>node3</hostname>
-                <port>9234</port>
-                <start_as_follower>true</start_as_follower>
-            </server>
-        </raft_configuration>
-    </keeper_server>
-</clickhouse>
diff --git a/tests/integration/test_keeper_remove_leader/configs/enable_keeper_two_nodes_1.xml b/tests/integration/test_keeper_remove_leader/configs/enable_keeper_two_nodes_1.xml
deleted file mode 100644
index d51e420f7331..000000000000
--- a/tests/integration/test_keeper_remove_leader/configs/enable_keeper_two_nodes_1.xml
+++ /dev/null
@@ -1,28 +0,0 @@
-<clickhouse>
-    <keeper_server>
-        <tcp_port>9181</tcp_port>
-        <server_id>1</server_id>
-        <log_storage_path>/var/lib/clickhouse/coordination/log</log_storage_path>
-        <snapshot_storage_path>/var/lib/clickhouse/coordination/snapshots</snapshot_storage_path>
-
-        <coordination_settings>
-            <operation_timeout_ms>5000</operation_timeout_ms>
-            <session_timeout_ms>10000</session_timeout_ms>
-            <raft_logs_level>trace</raft_logs_level>
-        </coordination_settings>
-
-        <raft_configuration>
-            <server>
-                <id>2</id>
-                <hostname>node2</hostname>
-                <port>9234</port>
-            </server>
-            <server>
-                <id>3</id>
-                <hostname>node3</hostname>
-                <port>9234</port>
-                <start_as_follower>true</start_as_follower>
-            </server>
-        </raft_configuration>
-    </keeper_server>
-</clickhouse>
diff --git a/tests/integration/test_keeper_remove_leader/configs/enable_keeper_two_nodes_2.xml b/tests/integration/test_keeper_remove_leader/configs/enable_keeper_two_nodes_2.xml
deleted file mode 100644
index 3f1ee1e01a8a..000000000000
--- a/tests/integration/test_keeper_remove_leader/configs/enable_keeper_two_nodes_2.xml
+++ /dev/null
@@ -1,28 +0,0 @@
-<clickhouse>
-    <keeper_server>
-        <tcp_port>9181</tcp_port>
-        <server_id>2</server_id>
-        <log_storage_path>/var/lib/clickhouse/coordination/log</log_storage_path>
-        <snapshot_storage_path>/var/lib/clickhouse/coordination/snapshots</snapshot_storage_path>
-
-        <coordination_settings>
-            <operation_timeout_ms>5000</operation_timeout_ms>
-            <session_timeout_ms>10000</session_timeout_ms>
-            <raft_logs_level>trace</raft_logs_level>
-        </coordination_settings>
-
-        <raft_configuration>
-            <server>
-                <id>2</id>
-                <hostname>node2</hostname>
-                <port>9234</port>
-            </server>
-            <server>
-                <id>3</id>
-                <hostname>node3</hostname>
-                <port>9234</port>
-                <start_as_follower>true</start_as_follower>
-            </server>
-        </raft_configuration>
-    </keeper_server>
-</clickhouse>
diff --git a/tests/integration/test_keeper_remove_leader/configs/enable_keeper_two_nodes_3.xml b/tests/integration/test_keeper_remove_leader/configs/enable_keeper_two_nodes_3.xml
deleted file mode 100644
index a99bd5d5296b..000000000000
--- a/tests/integration/test_keeper_remove_leader/configs/enable_keeper_two_nodes_3.xml
+++ /dev/null
@@ -1,28 +0,0 @@
-<clickhouse>
-    <keeper_server>
-        <tcp_port>9181</tcp_port>
-        <server_id>3</server_id>
-        <log_storage_path>/var/lib/clickhouse/coordination/log</log_storage_path>
-        <snapshot_storage_path>/var/lib/clickhouse/coordination/snapshots</snapshot_storage_path>
-
-        <coordination_settings>
-            <operation_timeout_ms>5000</operation_timeout_ms>
-            <session_timeout_ms>10000</session_timeout_ms>
-            <raft_logs_level>trace</raft_logs_level>
-        </coordination_settings>
-
-        <raft_configuration>
-            <server>
-                <id>2</id>
-                <hostname>node2</hostname>
-                <port>9234</port>
-            </server>
-            <server>
-                <id>3</id>
-                <hostname>node3</hostname>
-                <port>9234</port>
-                <start_as_follower>true</start_as_follower>
-            </server>
-        </raft_configuration>
-    </keeper_server>
-</clickhouse>
diff --git a/tests/integration/test_keeper_restore_from_snapshot/test.py b/tests/integration/test_keeper_restore_from_snapshot/test.py
index 7270c84bdda3..bc33689dd200 100644
--- a/tests/integration/test_keeper_restore_from_snapshot/test.py
+++ b/tests/integration/test_keeper_restore_from_snapshot/test.py
@@ -1,6 +1,7 @@
 #!/usr/bin/env python3
 import pytest
 from helpers.cluster import ClickHouseCluster
+import helpers.keeper_utils as keeper_utils
 import random
 import string
 import os
@@ -84,6 +85,7 @@ def test_recover_from_snapshot(started_cluster):
     # stale node should recover from leader's snapshot
     # with some sanitizers can start longer than 5 seconds
     node3.start_clickhouse(20)
+    keeper_utils.wait_until_connected(cluster, node3)
     print("Restarted")
 
     try:
diff --git a/tests/integration/test_keeper_secure_client/test.py b/tests/integration/test_keeper_secure_client/test.py
index 55e00880da04..2a17afac75ba 100644
--- a/tests/integration/test_keeper_secure_client/test.py
+++ b/tests/integration/test_keeper_secure_client/test.py
@@ -40,4 +40,4 @@ def started_cluster():
 
 def test_connection(started_cluster):
     # just nothrow
-    node2.query("SELECT * FROM system.zookeeper WHERE path = '/'")
+    node2.query_with_retry("SELECT * FROM system.zookeeper WHERE path = '/'")
diff --git a/tests/integration/test_keeper_session/test.py b/tests/integration/test_keeper_session/test.py
index 4b3aa7e3fdfd..72a162c17656 100644
--- a/tests/integration/test_keeper_session/test.py
+++ b/tests/integration/test_keeper_session/test.py
@@ -1,5 +1,6 @@
 import pytest
 from helpers.cluster import ClickHouseCluster
+import helpers.keeper_utils as keeper_utils
 import time
 import socket
 import struct
@@ -52,25 +53,8 @@ def destroy_zk_client(zk):
         pass
 
 
-def wait_node(node):
-    for _ in range(100):
-        zk = None
-        try:
-            zk = get_fake_zk(node.name, timeout=30.0)
-            print("node", node.name, "ready")
-            break
-        except Exception as ex:
-            time.sleep(0.2)
-            print("Waiting until", node.name, "will be ready, exception", ex)
-        finally:
-            destroy_zk_client(zk)
-    else:
-        raise Exception("Can't wait node", node.name, "to become ready")
-
-
 def wait_nodes():
-    for n in [node1, node2, node3]:
-        wait_node(n)
+    keeper_utils.wait_nodes(cluster, [node1, node2, node3])
 
 
 def get_fake_zk(nodename, timeout=30.0):
diff --git a/tests/integration/test_keeper_snapshot_small_distance/test.py b/tests/integration/test_keeper_snapshot_small_distance/test.py
index 4351c5ac96f8..6a64cf0ac92f 100644
--- a/tests/integration/test_keeper_snapshot_small_distance/test.py
+++ b/tests/integration/test_keeper_snapshot_small_distance/test.py
@@ -2,6 +2,7 @@
 ##!/usr/bin/env python3
 import pytest
 from helpers.cluster import ClickHouseCluster
+import helpers.keeper_utils as keeper_utils
 from multiprocessing.dummy import Pool
 from kazoo.client import KazooClient, KazooState
 import random
@@ -22,7 +23,7 @@
 
 
 def start_zookeeper(node):
-    node1.exec_in_container(["bash", "-c", "/opt/zookeeper/bin/zkServer.sh start"])
+    node.exec_in_container(["bash", "-c", "/opt/zookeeper/bin/zkServer.sh start"])
 
 
 def stop_zookeeper(node):
@@ -66,6 +67,7 @@ def stop_clickhouse(node):
 
 def start_clickhouse(node):
     node.start_clickhouse()
+    keeper_utils.wait_until_connected(cluster, node)
 
 
 def copy_zookeeper_data(make_zk_snapshots, node):
diff --git a/tests/integration/test_keeper_snapshots/test.py b/tests/integration/test_keeper_snapshots/test.py
index 08f60e538a4a..ce57a852dcab 100644
--- a/tests/integration/test_keeper_snapshots/test.py
+++ b/tests/integration/test_keeper_snapshots/test.py
@@ -3,6 +3,7 @@
 #!/usr/bin/env python3
 import pytest
 from helpers.cluster import ClickHouseCluster
+import helpers.keeper_utils as keeper_utils
 import random
 import string
 import os
@@ -50,6 +51,11 @@ def get_connection_zk(nodename, timeout=30.0):
     return _fake_zk_instance
 
 
+def restart_clickhouse():
+    node.restart_clickhouse(kill=True)
+    keeper_utils.wait_until_connected(cluster, node)
+
+
 def test_state_after_restart(started_cluster):
     try:
         node_zk = None
@@ -69,7 +75,7 @@ def test_state_after_restart(started_cluster):
             else:
                 existing_children.append("node" + str(i))
 
-        node.restart_clickhouse(kill=True)
+        restart_clickhouse()
 
         node_zk2 = get_connection_zk("node")
 
@@ -123,7 +129,7 @@ def test_ephemeral_after_restart(started_cluster):
             else:
                 existing_children.append("node" + str(i))
 
-        node.restart_clickhouse(kill=True)
+        restart_clickhouse()
 
         node_zk2 = get_connection_zk("node")
 
diff --git a/tests/integration/test_keeper_snapshots_multinode/test.py b/tests/integration/test_keeper_snapshots_multinode/test.py
index 1461f35e6a47..a68a34dae2e5 100644
--- a/tests/integration/test_keeper_snapshots_multinode/test.py
+++ b/tests/integration/test_keeper_snapshots_multinode/test.py
@@ -1,6 +1,7 @@
 #!/usr/bin/env python3
 import pytest
 from helpers.cluster import ClickHouseCluster
+import helpers.keeper_utils as keeper_utils
 import random
 import string
 import os
@@ -20,6 +21,10 @@
 from kazoo.client import KazooClient, KazooState
 
 
+def wait_nodes():
+    keeper_utils.wait_nodes(cluster, [node1, node2, node3])
+
+
 @pytest.fixture(scope="module")
 def started_cluster():
     try:
@@ -94,6 +99,8 @@ def test_restart_multinode(started_cluster):
     node1.restart_clickhouse(kill=True)
     node2.restart_clickhouse(kill=True)
     node3.restart_clickhouse(kill=True)
+    wait_nodes()
+
     for i in range(100):
         try:
             node1_zk = get_fake_zk("node1")
diff --git a/tests/integration/test_keeper_start_as_follower_multinode/configs/enable_keeper1.xml b/tests/integration/test_keeper_start_as_follower_multinode/configs/enable_keeper1.xml
deleted file mode 100644
index 1e57d42016d1..000000000000
--- a/tests/integration/test_keeper_start_as_follower_multinode/configs/enable_keeper1.xml
+++ /dev/null
@@ -1,34 +0,0 @@
-<clickhouse>
-    <keeper_server>
-        <tcp_port>9181</tcp_port>
-        <server_id>1</server_id>
-        <log_storage_path>/var/lib/clickhouse/coordination/log</log_storage_path>
-        <snapshot_storage_path>/var/lib/clickhouse/coordination/snapshots</snapshot_storage_path>
-
-        <coordination_settings>
-            <operation_timeout_ms>5000</operation_timeout_ms>
-            <session_timeout_ms>10000</session_timeout_ms>
-            <raft_logs_level>trace</raft_logs_level>
-        </coordination_settings>
-
-        <raft_configuration>
-            <server>
-                <id>1</id>
-                <hostname>node1</hostname>
-                <port>9234</port>
-            </server>
-            <server>
-                <id>2</id>
-                <hostname>node2</hostname>
-                <port>9234</port>
-                <start_as_follower>true</start_as_follower>
-            </server>
-            <server>
-                <id>3</id>
-                <hostname>node3</hostname>
-                <port>9234</port>
-                <start_as_follower>true</start_as_follower>
-            </server>
-        </raft_configuration>
-    </keeper_server>
-</clickhouse>
diff --git a/tests/integration/test_keeper_start_as_follower_multinode/configs/enable_keeper2.xml b/tests/integration/test_keeper_start_as_follower_multinode/configs/enable_keeper2.xml
deleted file mode 100644
index 98422b41c9b1..000000000000
--- a/tests/integration/test_keeper_start_as_follower_multinode/configs/enable_keeper2.xml
+++ /dev/null
@@ -1,34 +0,0 @@
-<clickhouse>
-    <keeper_server>
-        <tcp_port>9181</tcp_port>
-        <server_id>2</server_id>
-        <log_storage_path>/var/lib/clickhouse/coordination/log</log_storage_path>
-        <snapshot_storage_path>/var/lib/clickhouse/coordination/snapshots</snapshot_storage_path>
-
-        <coordination_settings>
-            <operation_timeout_ms>5000</operation_timeout_ms>
-            <session_timeout_ms>10000</session_timeout_ms>
-            <raft_logs_level>trace</raft_logs_level>
-        </coordination_settings>
-
-        <raft_configuration>
-            <server>
-                <id>1</id>
-                <hostname>node1</hostname>
-                <port>9234</port>
-            </server>
-            <server>
-                <id>2</id>
-                <hostname>node2</hostname>
-                <port>9234</port>
-                <start_as_follower>true</start_as_follower>
-            </server>
-            <server>
-                <id>3</id>
-                <hostname>node3</hostname>
-                <port>9234</port>
-                <start_as_follower>true</start_as_follower>
-            </server>
-        </raft_configuration>
-    </keeper_server>
-</clickhouse>
diff --git a/tests/integration/test_keeper_start_as_follower_multinode/configs/enable_keeper3.xml b/tests/integration/test_keeper_start_as_follower_multinode/configs/enable_keeper3.xml
deleted file mode 100644
index 43800bd2dfb6..000000000000
--- a/tests/integration/test_keeper_start_as_follower_multinode/configs/enable_keeper3.xml
+++ /dev/null
@@ -1,34 +0,0 @@
-<clickhouse>
-    <keeper_server>
-        <tcp_port>9181</tcp_port>
-        <server_id>3</server_id>
-        <log_storage_path>/var/lib/clickhouse/coordination/log</log_storage_path>
-        <snapshot_storage_path>/var/lib/clickhouse/coordination/snapshots</snapshot_storage_path>
-
-        <coordination_settings>
-            <operation_timeout_ms>5000</operation_timeout_ms>
-            <session_timeout_ms>10000</session_timeout_ms>
-            <raft_logs_level>trace</raft_logs_level>
-        </coordination_settings>
-
-        <raft_configuration>
-            <server>
-                <id>1</id>
-                <hostname>node1</hostname>
-                <port>9234</port>
-            </server>
-            <server>
-                <id>2</id>
-                <hostname>node2</hostname>
-                <port>9234</port>
-                <start_as_follower>true</start_as_follower>
-            </server>
-            <server>
-                <id>3</id>
-                <hostname>node3</hostname>
-                <port>9234</port>
-                <start_as_follower>true</start_as_follower>
-            </server>
-        </raft_configuration>
-    </keeper_server>
-</clickhouse>
diff --git a/tests/integration/test_keeper_three_nodes_two_alive/test.py b/tests/integration/test_keeper_three_nodes_two_alive/test.py
index f1de469c5a12..bd29ded357fa 100644
--- a/tests/integration/test_keeper_three_nodes_two_alive/test.py
+++ b/tests/integration/test_keeper_three_nodes_two_alive/test.py
@@ -1,6 +1,7 @@
 #!/usr/bin/env python3
 import pytest
 from helpers.cluster import ClickHouseCluster
+import helpers.keeper_utils as keeper_utils
 import random
 import string
 import os
@@ -48,6 +49,7 @@ def started_cluster():
 
 def start(node):
     node.start_clickhouse()
+    keeper_utils.wait_until_connected(cluster, node)
 
 
 def delete_with_retry(node_name, path):
@@ -138,6 +140,7 @@ def test_restart_third_node(started_cluster):
     node1_zk.create("/test_restart", b"aaaa")
 
     node3.restart_clickhouse()
+    keeper_utils.wait_until_connected(cluster, node3)
 
     assert node3.contains_in_log(
         "Connected to ZooKeeper (or Keeper) before internal Keeper start"
diff --git a/tests/integration/test_keeper_two_nodes_cluster/test.py b/tests/integration/test_keeper_two_nodes_cluster/test.py
index 8c0276f7d775..c6bc0ebd33a9 100644
--- a/tests/integration/test_keeper_two_nodes_cluster/test.py
+++ b/tests/integration/test_keeper_two_nodes_cluster/test.py
@@ -2,6 +2,7 @@
 
 import pytest
 from helpers.cluster import ClickHouseCluster
+import helpers.keeper_utils as keeper_utils
 import random
 import string
 import os
@@ -40,29 +41,8 @@ def smaller_exception(ex):
     return "
".join(str(ex).split("
")[0:2])
 
 
-def wait_node(node):
-    for _ in range(100):
-        zk = None
-        try:
-            node.query("SELECT * FROM system.zookeeper WHERE path = '/'")
-            zk = get_fake_zk(node.name, timeout=30.0)
-            zk.create("/test", sequence=True)
-            print("node", node.name, "ready")
-            break
-        except Exception as ex:
-            time.sleep(0.2)
-            print("Waiting until", node.name, "will be ready, exception", ex)
-        finally:
-            if zk:
-                zk.stop()
-                zk.close()
-    else:
-        raise Exception("Can't wait node", node.name, "to become ready")
-
-
 def wait_nodes():
-    for node in [node1, node2]:
-        wait_node(node)
+    keeper_utils.wait_nodes(cluster, [node1, node2])
 
 
 def get_fake_zk(nodename, timeout=30.0):
diff --git a/tests/integration/test_keeper_znode_time/test.py b/tests/integration/test_keeper_znode_time/test.py
index bff3d52014e1..f2076acc4d26 100644
--- a/tests/integration/test_keeper_znode_time/test.py
+++ b/tests/integration/test_keeper_znode_time/test.py
@@ -1,5 +1,6 @@
 import pytest
 from helpers.cluster import ClickHouseCluster
+import helpers.keeper_utils as keeper_utils
 import random
 import string
 import os
@@ -42,29 +43,8 @@ def smaller_exception(ex):
     return "
".join(str(ex).split("
")[0:2])
 
 
-def wait_node(node):
-    for _ in range(100):
-        zk = None
-        try:
-            node.query("SELECT * FROM system.zookeeper WHERE path = '/'")
-            zk = get_fake_zk(node.name, timeout=30.0)
-            zk.create("/test", sequence=True)
-            print("node", node.name, "ready")
-            break
-        except Exception as ex:
-            time.sleep(0.2)
-            print("Waiting until", node.name, "will be ready, exception", ex)
-        finally:
-            if zk:
-                zk.stop()
-                zk.close()
-    else:
-        raise Exception("Can't wait node", node.name, "to become ready")
-
-
 def wait_nodes():
-    for node in [node1, node2, node3]:
-        wait_node(node)
+    keeper_utils.wait_nodes(cluster, [node1, node2, node3])
 
 
 def get_fake_zk(nodename, timeout=30.0):
@@ -129,6 +109,7 @@ def test_server_restart(started_cluster):
             node1_zk.set("/test_server_restart/" + str(child_node), b"somevalue")
 
         node3.restart_clickhouse(kill=True)
+        keeper_utils.wait_until_connected(cluster, node3)
 
         node2_zk = get_fake_zk("node2")
         node3_zk = get_fake_zk("node3")
diff --git a/tests/integration/test_keeper_zookeeper_converter/test.py b/tests/integration/test_keeper_zookeeper_converter/test.py
index 50a9ee6a4a73..af8d1ca4bf9d 100644
--- a/tests/integration/test_keeper_zookeeper_converter/test.py
+++ b/tests/integration/test_keeper_zookeeper_converter/test.py
@@ -1,6 +1,7 @@
 #!/usr/bin/env python3
 import pytest
 from helpers.cluster import ClickHouseCluster
+import helpers.keeper_utils as keeper_utils
 from kazoo.client import KazooClient, KazooState
 from kazoo.security import ACL, make_digest_acl, make_acl
 from kazoo.exceptions import (
@@ -60,6 +61,7 @@ def stop_clickhouse():
 
 def start_clickhouse():
     node.start_clickhouse()
+    keeper_utils.wait_until_connected(cluster, node)
 
 
 def copy_zookeeper_data(make_zk_snapshots):
