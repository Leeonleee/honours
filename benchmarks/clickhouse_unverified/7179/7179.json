{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 7179,
  "instance_id": "ClickHouse__ClickHouse-7179",
  "issue_numbers": [
    "7176"
  ],
  "base_commit": "71cbe878fc148440d9e0f6a2b36df82376d61c96",
  "patch": "diff --git a/dbms/src/Columns/ColumnTuple.cpp b/dbms/src/Columns/ColumnTuple.cpp\nindex 4c5fe54b3d61..d7aacec8d09d 100644\n--- a/dbms/src/Columns/ColumnTuple.cpp\n+++ b/dbms/src/Columns/ColumnTuple.cpp\n@@ -94,16 +94,17 @@ MutableColumnPtr ColumnTuple::cloneResized(size_t new_size) const\n \n Field ColumnTuple::operator[](size_t n) const\n {\n-    return Tuple{ext::map<TupleBackend>(columns, [n] (const auto & column) { return (*column)[n]; })};\n+    return ext::map<Tuple>(columns, [n] (const auto & column) { return (*column)[n]; });\n }\n \n void ColumnTuple::get(size_t n, Field & res) const\n {\n     const size_t tuple_size = columns.size();\n-    res = Tuple(TupleBackend(tuple_size));\n-    TupleBackend & res_arr = DB::get<Tuple &>(res).toUnderType();\n+    Tuple tuple(tuple_size);\n     for (const auto i : ext::range(0, tuple_size))\n-        columns[i]->get(n, res_arr[i]);\n+        columns[i]->get(n, tuple[i]);\n+\n+    res = tuple;\n }\n \n StringRef ColumnTuple::getDataAt(size_t) const\n@@ -118,7 +119,7 @@ void ColumnTuple::insertData(const char *, size_t)\n \n void ColumnTuple::insert(const Field & x)\n {\n-    const TupleBackend & tuple = DB::get<const Tuple &>(x).toUnderType();\n+    auto & tuple = DB::get<const Tuple &>(x);\n \n     const size_t tuple_size = columns.size();\n     if (tuple.size() != tuple_size)\n@@ -352,14 +353,14 @@ void ColumnTuple::getExtremes(Field & min, Field & max) const\n {\n     const size_t tuple_size = columns.size();\n \n-    min = Tuple(TupleBackend(tuple_size));\n-    max = Tuple(TupleBackend(tuple_size));\n-\n-    auto & min_backend = min.get<Tuple &>().toUnderType();\n-    auto & max_backend = max.get<Tuple &>().toUnderType();\n+    Tuple min_tuple(tuple_size);\n+    Tuple max_tuple(tuple_size);\n \n     for (const auto i : ext::range(0, tuple_size))\n-        columns[i]->getExtremes(min_backend[i], max_backend[i]);\n+        columns[i]->getExtremes(min_tuple[i], max_tuple[i]);\n+\n+    min = min_tuple;\n+    max = max_tuple;\n }\n \n void ColumnTuple::forEachSubcolumn(ColumnCallback callback)\ndiff --git a/dbms/src/Common/FieldVisitors.cpp b/dbms/src/Common/FieldVisitors.cpp\nindex c5ce10c0db46..8380061209af 100644\n--- a/dbms/src/Common/FieldVisitors.cpp\n+++ b/dbms/src/Common/FieldVisitors.cpp\n@@ -72,9 +72,8 @@ String FieldVisitorDump::operator() (const Array & x) const\n     return wb.str();\n }\n \n-String FieldVisitorDump::operator() (const Tuple & x_def) const\n+String FieldVisitorDump::operator() (const Tuple & x) const\n {\n-    auto & x = x_def.toUnderType();\n     WriteBufferFromOwnString wb;\n \n     wb << \"Tuple_(\";\n@@ -149,9 +148,8 @@ String FieldVisitorToString::operator() (const Array & x) const\n     return wb.str();\n }\n \n-String FieldVisitorToString::operator() (const Tuple & x_def) const\n+String FieldVisitorToString::operator() (const Tuple & x) const\n {\n-    auto & x = x_def.toUnderType();\n     WriteBufferFromOwnString wb;\n \n     wb << '(';\n@@ -211,6 +209,16 @@ void FieldVisitorHash::operator() (const String & x) const\n     hash.update(x.data(), x.size());\n }\n \n+void FieldVisitorHash::operator() (const Tuple & x) const\n+{\n+    UInt8 type = Field::Types::Tuple;\n+    hash.update(type);\n+    hash.update(x.size());\n+\n+    for (const auto & elem : x)\n+        applyVisitor(*this, elem);\n+}\n+\n void FieldVisitorHash::operator() (const Array & x) const\n {\n     UInt8 type = Field::Types::Array;\ndiff --git a/dbms/src/Common/FieldVisitors.h b/dbms/src/Common/FieldVisitors.h\nindex 56d3c84decc5..a1de23d58204 100644\n--- a/dbms/src/Common/FieldVisitors.h\n+++ b/dbms/src/Common/FieldVisitors.h\n@@ -231,6 +231,7 @@ class FieldVisitorHash : public StaticVisitor<>\n     void operator() (const Float64 & x) const;\n     void operator() (const String & x) const;\n     void operator() (const Array & x) const;\n+    void operator() (const Tuple & x) const;\n     void operator() (const DecimalField<Decimal32> & x) const;\n     void operator() (const DecimalField<Decimal64> & x) const;\n     void operator() (const DecimalField<Decimal128> & x) const;\n@@ -479,6 +480,7 @@ class FieldVisitorSum : public StaticVisitor<bool>\n     bool operator() (Null &) const { throw Exception(\"Cannot sum Nulls\", ErrorCodes::LOGICAL_ERROR); }\n     bool operator() (String &) const { throw Exception(\"Cannot sum Strings\", ErrorCodes::LOGICAL_ERROR); }\n     bool operator() (Array &) const { throw Exception(\"Cannot sum Arrays\", ErrorCodes::LOGICAL_ERROR); }\n+    bool operator() (Tuple &) const { throw Exception(\"Cannot sum Tuples\", ErrorCodes::LOGICAL_ERROR); }\n     bool operator() (UInt128 &) const { throw Exception(\"Cannot sum UUIDs\", ErrorCodes::LOGICAL_ERROR); }\n     bool operator() (AggregateFunctionStateData &) const { throw Exception(\"Cannot sum AggregateFunctionStates\", ErrorCodes::LOGICAL_ERROR); }\n \ndiff --git a/dbms/src/Core/Field.cpp b/dbms/src/Core/Field.cpp\nindex a952dccc27d0..9d27e33c4142 100644\n--- a/dbms/src/Core/Field.cpp\n+++ b/dbms/src/Core/Field.cpp\n@@ -152,9 +152,8 @@ namespace DB\n         buf.write(res.data(), res.size());\n     }\n \n-    void readBinary(Tuple & x_def, ReadBuffer & buf)\n+    void readBinary(Tuple & x, ReadBuffer & buf)\n     {\n-        auto & x = x_def.toUnderType();\n         size_t size;\n         DB::readBinary(size, buf);\n \n@@ -231,9 +230,8 @@ namespace DB\n         }\n     }\n \n-    void writeBinary(const Tuple & x_def, WriteBuffer & buf)\n+    void writeBinary(const Tuple & x, WriteBuffer & buf)\n     {\n-        auto & x = x_def.toUnderType();\n         const size_t size = x.size();\n         DB::writeBinary(size, buf);\n \n@@ -292,7 +290,12 @@ namespace DB\n \n     void writeText(const Tuple & x, WriteBuffer & buf)\n     {\n-        DB::String res = applyVisitor(DB::FieldVisitorToString(), DB::Field(x));\n+        writeFieldText(DB::Field(x), buf);\n+    }\n+\n+    void writeFieldText(const Field & x, WriteBuffer & buf)\n+    {\n+        DB::String res = applyVisitor(DB::FieldVisitorToString(), x);\n         buf.write(res.data(), res.size());\n     }\n \ndiff --git a/dbms/src/Core/Field.h b/dbms/src/Core/Field.h\nindex 81374683d9ab..a35bf608e5c6 100644\n--- a/dbms/src/Core/Field.h\n+++ b/dbms/src/Core/Field.h\n@@ -34,9 +34,23 @@ template <typename T>\n using NearestFieldType = typename NearestFieldTypeImpl<T>::Type;\n \n class Field;\n-using Array = std::vector<Field>;\n-using TupleBackend = std::vector<Field>;\n-STRONG_TYPEDEF(TupleBackend, Tuple) /// Array and Tuple are different types with equal representation inside Field.\n+using FieldVector = std::vector<Field>;\n+\n+/// Array and Tuple use the same storage type -- FieldVector, but we declare\n+/// distinct types for them, so that the caller can choose whether it wants to\n+/// construct a Field of Array or a Tuple type. An alternative approach would be\n+/// to construct both of these types from FieldVector, and have the caller\n+/// specify the desired Field type explicitly.\n+#define DEFINE_FIELD_VECTOR(X) \\\n+struct X : public FieldVector \\\n+{ \\\n+    using FieldVector::FieldVector; \\\n+}\n+\n+DEFINE_FIELD_VECTOR(Array);\n+DEFINE_FIELD_VECTOR(Tuple);\n+\n+#undef DEFINE_FIELD_VECTOR\n \n struct AggregateFunctionStateData\n {\n@@ -748,5 +762,7 @@ void writeBinary(const Tuple & x, WriteBuffer & buf);\n \n void writeText(const Tuple & x, WriteBuffer & buf);\n \n+void writeFieldText(const Field & x, WriteBuffer & buf);\n+\n [[noreturn]] inline void writeQuoted(const Tuple &, WriteBuffer &) { throw Exception(\"Cannot write Tuple quoted.\", ErrorCodes::NOT_IMPLEMENTED); }\n }\ndiff --git a/dbms/src/DataTypes/DataTypeTuple.cpp b/dbms/src/DataTypes/DataTypeTuple.cpp\nindex 051683596cf5..bd0e7e6ea3a4 100644\n--- a/dbms/src/DataTypes/DataTypeTuple.cpp\n+++ b/dbms/src/DataTypes/DataTypeTuple.cpp\n@@ -101,7 +101,7 @@ static inline const IColumn & extractElementColumn(const IColumn & column, size_\n \n void DataTypeTuple::serializeBinary(const Field & field, WriteBuffer & ostr) const\n {\n-    const auto & tuple = get<const Tuple &>(field).toUnderType();\n+    const auto & tuple = get<const Tuple &>(field);\n     for (const auto idx_elem : ext::enumerate(elems))\n         idx_elem.second->serializeBinary(tuple[idx_elem.first], ostr);\n }\n@@ -109,10 +109,12 @@ void DataTypeTuple::serializeBinary(const Field & field, WriteBuffer & ostr) con\n void DataTypeTuple::deserializeBinary(Field & field, ReadBuffer & istr) const\n {\n     const size_t size = elems.size();\n-    field = Tuple(TupleBackend(size));\n-    TupleBackend & tuple = get<Tuple &>(field).toUnderType();\n+\n+    Tuple tuple(size);\n     for (const auto i : ext::range(0, size))\n         elems[i]->deserializeBinary(tuple[i], istr);\n+\n+    field = tuple;\n }\n \n void DataTypeTuple::serializeBinary(const IColumn & column, size_t row_num, WriteBuffer & ostr) const\n@@ -447,7 +449,7 @@ MutableColumnPtr DataTypeTuple::createColumn() const\n \n Field DataTypeTuple::getDefault() const\n {\n-    return Tuple(ext::map<TupleBackend>(elems, [] (const DataTypePtr & elem) { return elem->getDefault(); }));\n+    return Tuple(ext::map<Tuple>(elems, [] (const DataTypePtr & elem) { return elem->getDefault(); }));\n }\n \n void DataTypeTuple::insertDefaultInto(IColumn & column) const\ndiff --git a/dbms/src/DataTypes/FieldToDataType.cpp b/dbms/src/DataTypes/FieldToDataType.cpp\nindex 70fab5338386..fcea9d53f399 100644\n--- a/dbms/src/DataTypes/FieldToDataType.cpp\n+++ b/dbms/src/DataTypes/FieldToDataType.cpp\n@@ -90,9 +90,8 @@ DataTypePtr FieldToDataType::operator() (const Array & x) const\n }\n \n \n-DataTypePtr FieldToDataType::operator() (const Tuple & x) const\n+DataTypePtr FieldToDataType::operator() (const Tuple & tuple) const\n {\n-    auto & tuple = static_cast<const TupleBackend &>(x);\n     if (tuple.empty())\n         throw Exception(\"Cannot infer type of an empty tuple\", ErrorCodes::EMPTY_DATA_PASSED);\n \ndiff --git a/dbms/src/Interpreters/Set.cpp b/dbms/src/Interpreters/Set.cpp\nindex 68c219c3a91f..188d0a84b495 100644\n--- a/dbms/src/Interpreters/Set.cpp\n+++ b/dbms/src/Interpreters/Set.cpp\n@@ -246,7 +246,7 @@ void Set::createFromAST(const DataTypes & types, ASTPtr node, const Context & co\n         else if (const auto * func = elem->as<ASTFunction>())\n         {\n             Field function_result;\n-            const TupleBackend * tuple = nullptr;\n+            const Tuple * tuple = nullptr;\n             if (func->name != \"tuple\")\n             {\n                 if (!tuple_type)\n@@ -257,7 +257,7 @@ void Set::createFromAST(const DataTypes & types, ASTPtr node, const Context & co\n                     throw Exception(\"Invalid type of set. Expected tuple, got \" + String(function_result.getTypeName()),\n                                     ErrorCodes::INCORRECT_ELEMENT_OF_SET);\n \n-                tuple = &function_result.get<Tuple>().toUnderType();\n+                tuple = &function_result.get<Tuple>();\n             }\n \n             size_t tuple_size = tuple ? tuple->size() : func->arguments->children.size();\ndiff --git a/dbms/src/Interpreters/convertFieldToType.cpp b/dbms/src/Interpreters/convertFieldToType.cpp\nindex b9d965b017ff..372aad048e5c 100644\n--- a/dbms/src/Interpreters/convertFieldToType.cpp\n+++ b/dbms/src/Interpreters/convertFieldToType.cpp\n@@ -248,7 +248,7 @@ Field convertFieldToTypeImpl(const Field & src, const IDataType & type, const ID\n     {\n         if (src.getType() == Field::Types::Tuple)\n         {\n-            const TupleBackend & src_tuple = src.get<Tuple>();\n+            const auto & src_tuple = src.get<Tuple>();\n             size_t src_tuple_size = src_tuple.size();\n             size_t dst_tuple_size = type_tuple->getElements().size();\n \n@@ -256,7 +256,7 @@ Field convertFieldToTypeImpl(const Field & src, const IDataType & type, const ID\n                 throw Exception(\"Bad size of tuple in IN or VALUES section. Expected size: \"\n                     + toString(dst_tuple_size) + \", actual size: \" + toString(src_tuple_size), ErrorCodes::TYPE_MISMATCH);\n \n-            TupleBackend res(dst_tuple_size);\n+            Tuple res(dst_tuple_size);\n             bool have_unconvertible_element = false;\n             for (size_t i = 0; i < dst_tuple_size; ++i)\n             {\ndiff --git a/dbms/src/Processors/Formats/Impl/CapnProtoRowInputFormat.cpp b/dbms/src/Processors/Formats/Impl/CapnProtoRowInputFormat.cpp\nindex 1d6cd4a839e4..be4e6eaaf3f8 100644\n--- a/dbms/src/Processors/Formats/Impl/CapnProtoRowInputFormat.cpp\n+++ b/dbms/src/Processors/Formats/Impl/CapnProtoRowInputFormat.cpp\n@@ -81,12 +81,11 @@ static Field convertNodeToField(const capnp::DynamicValue::Reader & value)\n             auto structValue = value.as<capnp::DynamicStruct>();\n             const auto & fields = structValue.getSchema().getFields();\n \n-            Field field = Tuple(TupleBackend(fields.size()));\n-            TupleBackend & tuple = get<Tuple &>(field).toUnderType();\n+            Tuple tuple(fields.size());\n             for (auto i : kj::indices(fields))\n                 tuple[i] = convertNodeToField(structValue.get(fields[i]));\n \n-            return field;\n+            return tuple;\n         }\n         case capnp::DynamicValue::CAPABILITY:\n             throw Exception(\"CAPABILITY type not supported\", ErrorCodes::BAD_TYPE_OF_FIELD);\n@@ -271,7 +270,7 @@ bool CapnProtoRowInputFormat::readRow(MutableColumns & columns, RowReadExtension\n                         // Populate array with a single tuple elements\n                         for (size_t off = 0; off < size; ++off)\n                         {\n-                            const TupleBackend & tuple = DB::get<const Tuple &>(collected[off]).toUnderType();\n+                            const auto & tuple = DB::get<const Tuple &>(collected[off]);\n                             flattened[off] = tuple[column_index];\n                         }\n                         auto & col = columns[action.columns[column_index]];\ndiff --git a/dbms/src/Storages/MergeTree/MergeTreeIndexConditionBloomFilter.cpp b/dbms/src/Storages/MergeTree/MergeTreeIndexConditionBloomFilter.cpp\nindex 56a18122f298..856354959f9d 100644\n--- a/dbms/src/Storages/MergeTree/MergeTreeIndexConditionBloomFilter.cpp\n+++ b/dbms/src/Storages/MergeTree/MergeTreeIndexConditionBloomFilter.cpp\n@@ -331,7 +331,7 @@ bool MergeTreeIndexConditionBloomFilter::traverseASTEquals(\n \n         if (which.isTuple() && function->name == \"tuple\")\n         {\n-            const TupleBackend & tuple = get<const Tuple &>(value_field).toUnderType();\n+            const Tuple & tuple = get<const Tuple &>(value_field);\n             const auto value_tuple_data_type = typeid_cast<const DataTypeTuple *>(value_type.get());\n             const ASTs & arguments = typeid_cast<const ASTExpressionList &>(*function->arguments).children;\n \ndiff --git a/dbms/src/TableFunctions/TableFunctionValues.cpp b/dbms/src/TableFunctions/TableFunctionValues.cpp\nindex 30a423a3384a..d4ca0ff42110 100644\n--- a/dbms/src/TableFunctions/TableFunctionValues.cpp\n+++ b/dbms/src/TableFunctions/TableFunctionValues.cpp\n@@ -44,7 +44,7 @@ static void parseAndInsertValues(MutableColumns & res_columns, const ASTs & args\n         {\n             const auto & [value_field, value_type_ptr] = evaluateConstantExpression(args[i], context);\n             const DataTypes & value_types_tuple = typeid_cast<const DataTypeTuple *>(value_type_ptr.get())->getElements();\n-            const TupleBackend & value_tuple = value_field.safeGet<Tuple>().toUnderType();\n+            const Tuple & value_tuple = value_field.safeGet<Tuple>();\n \n             if (value_tuple.size() != sample_block.columns())\n                 throw Exception(\"Values size should match with number of columns\", ErrorCodes::LOGICAL_ERROR);\n",
  "test_patch": "diff --git a/dbms/tests/queries/0_stateless/01016_index_tuple_field_type.reference b/dbms/tests/queries/0_stateless/01016_index_tuple_field_type.reference\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/dbms/tests/queries/0_stateless/01016_index_tuple_field_type.sql b/dbms/tests/queries/0_stateless/01016_index_tuple_field_type.sql\nnew file mode 100644\nindex 000000000000..1c5e6d81a900\n--- /dev/null\n+++ b/dbms/tests/queries/0_stateless/01016_index_tuple_field_type.sql\n@@ -0,0 +1,17 @@\n+DROP TABLE IF EXISTS tuple_01016;\n+\n+CREATE TABLE tuple_01016(a Tuple(DateTime, Int32)) ENGINE = MergeTree() ORDER BY a;\n+\n+-- repeat a couple of times, because it doesn't always reproduce well\n+INSERT INTO tuple_01016 VALUES (('2018-01-01 00:00:00', 1));\n+SELECT * FROM tuple_01016 WHERE a < tuple(toDateTime('2019-01-01 00:00:00'), 0) format Null;\n+INSERT INTO tuple_01016 VALUES (('2018-01-01 00:00:00', 1));\n+SELECT * FROM tuple_01016 WHERE a < tuple(toDateTime('2019-01-01 00:00:00'), 0) format Null;\n+INSERT INTO tuple_01016 VALUES (('2018-01-01 00:00:00', 1));\n+SELECT * FROM tuple_01016 WHERE a < tuple(toDateTime('2019-01-01 00:00:00'), 0) format Null;\n+INSERT INTO tuple_01016 VALUES (('2018-01-01 00:00:00', 1));\n+SELECT * FROM tuple_01016 WHERE a < tuple(toDateTime('2019-01-01 00:00:00'), 0) format Null;\n+INSERT INTO tuple_01016 VALUES (('2018-01-01 00:00:00', 1));\n+SELECT * FROM tuple_01016 WHERE a < tuple(toDateTime('2019-01-01 00:00:00'), 0) format Null;\n+\n+DROP TABLE tuple_01016;\n",
  "problem_statement": "Tuples can be used in ORDER BY but cannot be directly compared when engine is MergeTree\nTo reproduce: server 19.14.3.3 with CLI client.\r\n```\r\n2177cc704f03 :) CREATE TABLE T2( a Tuple(DateTime, Int32)) ENGINE = MergeTree() ORDER BY a;\r\n\r\nCREATE TABLE T2\r\n(\r\n    `a` Tuple(DateTime, Int32)\r\n)\r\nENGINE = MergeTree()\r\nORDER BY a\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.006 sec.\r\n\r\n2177cc704f03 :) INSERT INTO T2 (a) VALUES (('2018-01-01 00:00:00', 1));\r\n\r\nINSERT INTO T2 (a) VALUES\r\n\r\nOk.\r\n\r\n1 rows in set. Elapsed: 0.003 sec.\r\n\r\n2177cc704f03 :) SELECT * FROM T2 WHERE a < tuple(toDateTime('2019-01-01 00:00:00'), 0);\r\n\r\nSELECT *\r\nFROM T2\r\nWHERE a < (toDateTime('2019-01-01 00:00:00'), 0)\r\n\r\nReceived exception from server (version 19.14.3):\r\nCode: 169. DB::Exception: Received from localhost:9000. DB::Exception: Cannot compare std::vector<DB::Field, std::allocator<DB::Field> > with StrongTypedef<std::vector<DB::Field, std::allocator<DB::Field> >, DB::TupleTag>.\r\n\r\n0 rows in set. Elapsed: 0.004 sec.\r\n```\r\n\r\nInterestingly enough, when engine is Memory, everything works.\n",
  "hints_text": "",
  "created_at": "2019-10-03T08:29:43Z",
  "modified_files": [
    "dbms/src/Columns/ColumnTuple.cpp",
    "dbms/src/Common/FieldVisitors.cpp",
    "dbms/src/Common/FieldVisitors.h",
    "dbms/src/Core/Field.cpp",
    "dbms/src/Core/Field.h",
    "dbms/src/DataTypes/DataTypeTuple.cpp",
    "dbms/src/DataTypes/FieldToDataType.cpp",
    "dbms/src/Interpreters/Set.cpp",
    "dbms/src/Interpreters/convertFieldToType.cpp",
    "dbms/src/Processors/Formats/Impl/CapnProtoRowInputFormat.cpp",
    "dbms/src/Storages/MergeTree/MergeTreeIndexConditionBloomFilter.cpp",
    "dbms/src/TableFunctions/TableFunctionValues.cpp"
  ],
  "modified_test_files": [
    "b/dbms/tests/queries/0_stateless/01016_index_tuple_field_type.sql"
  ]
}