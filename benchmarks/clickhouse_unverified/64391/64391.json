{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 64391,
  "instance_id": "ClickHouse__ClickHouse-64391",
  "issue_numbers": [
    "64201"
  ],
  "base_commit": "2993be118606a27b4269fdc10b3f768970bb10d0",
  "patch": "diff --git a/src/Core/Settings.h b/src/Core/Settings.h\nindex dc61a049de80..b8f5a8b5a75a 100644\n--- a/src/Core/Settings.h\n+++ b/src/Core/Settings.h\n@@ -260,6 +260,8 @@ class IColumn;\n     M(Bool, force_primary_key, false, \"Throw an exception if there is primary key in a table, and it is not used.\", 0) \\\n     M(Bool, use_skip_indexes, true, \"Use data skipping indexes during query execution.\", 0) \\\n     M(Bool, use_skip_indexes_if_final, false, \"If query has FINAL, then skipping data based on indexes may produce incorrect result, hence disabled by default.\", 0) \\\n+    M(Bool, materialize_skip_indexes_on_insert, true, \"If true skip indexes are calculated on inserts, otherwise skip indexes will be calculated only during merges\", 0) \\\n+    M(Bool, materialize_statistics_on_insert, true, \"If true statistics are calculated on inserts, otherwise statistics will be calculated only during merges\", 0) \\\n     M(String, ignore_data_skipping_indices, \"\", \"Comma separated list of strings or literals with the name of the data skipping indices that should be excluded during query execution.\", 0) \\\n     \\\n     M(String, force_data_skipping_indices, \"\", \"Comma separated list of strings or literals with the name of the data skipping indices that should be used during query execution, otherwise an exception will be thrown.\", 0) \\\ndiff --git a/src/Core/SettingsChangesHistory.h b/src/Core/SettingsChangesHistory.h\nindex 3a0f2ca1e270..9352b22132f0 100644\n--- a/src/Core/SettingsChangesHistory.h\n+++ b/src/Core/SettingsChangesHistory.h\n@@ -85,7 +85,9 @@ namespace SettingsChangesHistory\n /// It's used to implement `compatibility` setting (see https://github.com/ClickHouse/ClickHouse/issues/35972)\n static std::map<ClickHouseVersion, SettingsChangesHistory::SettingsChanges> settings_changes_history =\n {\n-    {\"24.6\", {{\"input_format_parquet_use_native_reader\", false, false, \"When reading Parquet files, to use native reader instead of arrow reader.\"},\n+    {\"24.6\", {{\"materialize_skip_indexes_on_insert\", true, true, \"Added new setting to allow to disable materialization of skip indexes on insert\"},\n+              {\"materialize_statistics_on_insert\", true, true, \"Added new setting to allow to disable materialization of statistics on insert\"},\n+              {\"input_format_parquet_use_native_reader\", false, false, \"When reading Parquet files, to use native reader instead of arrow reader.\"},\n               {\"hdfs_throw_on_zero_files_match\", false, false, \"Allow to throw an error when ListObjects request cannot match any files in HDFS engine instead of empty query result\"},\n               {\"azure_throw_on_zero_files_match\", false, false, \"Allow to throw an error when ListObjects request cannot match any files in AzureBlobStorage engine instead of empty query result\"},\n               {\"s3_validate_request_settings\", true, true, \"Allow to disable S3 request settings validation\"},\ndiff --git a/src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.cpp b/src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.cpp\nindex 0a8920790e01..bcf51bfcd3d2 100644\n--- a/src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.cpp\n+++ b/src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.cpp\n@@ -176,6 +176,7 @@ MergeTreeDataPartWriterOnDisk::MergeTreeDataPartWriterOnDisk(\n \n     if (settings.rewrite_primary_key)\n         initPrimaryIndex();\n+\n     initSkipIndices();\n     initStatistics();\n }\n@@ -272,6 +273,9 @@ void MergeTreeDataPartWriterOnDisk::initStatistics()\n \n void MergeTreeDataPartWriterOnDisk::initSkipIndices()\n {\n+    if (skip_indices.empty())\n+        return;\n+\n     ParserCodec codec_parser;\n     auto ast = parseQuery(codec_parser, \"(\" + Poco::toUpper(settings.marks_compression_codec) + \")\", 0, DBMS_DEFAULT_MAX_PARSER_DEPTH, DBMS_DEFAULT_MAX_PARSER_BACKTRACKS);\n     CompressionCodecPtr marks_compression_codec = CompressionCodecFactory::instance().get(ast, nullptr);\ndiff --git a/src/Storages/MergeTree/MergeTreeDataWriter.cpp b/src/Storages/MergeTree/MergeTreeDataWriter.cpp\nindex df4087b85460..2ffd23df0150 100644\n--- a/src/Storages/MergeTree/MergeTreeDataWriter.cpp\n+++ b/src/Storages/MergeTree/MergeTreeDataWriter.cpp\n@@ -464,7 +464,13 @@ MergeTreeDataWriter::TemporaryPart MergeTreeDataWriter::writeTempPartImpl(\n \n     temp_part.temporary_directory_lock = data.getTemporaryPartDirectoryHolder(part_dir);\n \n-    auto indices = MergeTreeIndexFactory::instance().getMany(metadata_snapshot->getSecondaryIndices());\n+    MergeTreeIndices indices;\n+    if (context->getSettingsRef().materialize_skip_indexes_on_insert)\n+        indices = MergeTreeIndexFactory::instance().getMany(metadata_snapshot->getSecondaryIndices());\n+\n+    Statistics statistics;\n+    if (context->getSettingsRef().materialize_statistics_on_insert)\n+        statistics = MergeTreeStatisticsFactory::instance().getMany(metadata_snapshot->getColumns());\n \n     /// If we need to calculate some columns to sort.\n     if (metadata_snapshot->hasSortingKey() || metadata_snapshot->hasSecondaryIndices())\n@@ -596,7 +602,7 @@ MergeTreeDataWriter::TemporaryPart MergeTreeDataWriter::writeTempPartImpl(\n         metadata_snapshot,\n         columns,\n         indices,\n-        MergeTreeStatisticsFactory::instance().getMany(metadata_snapshot->getColumns()),\n+        statistics,\n         compression_codec,\n         context->getCurrentTransaction() ? context->getCurrentTransaction()->tid : Tx::PrehistoricTID,\n         false,\ndiff --git a/src/Storages/MergeTree/MergeTreeWhereOptimizer.cpp b/src/Storages/MergeTree/MergeTreeWhereOptimizer.cpp\nindex 6f1c5302b0ef..3844ac182681 100644\n--- a/src/Storages/MergeTree/MergeTreeWhereOptimizer.cpp\n+++ b/src/Storages/MergeTree/MergeTreeWhereOptimizer.cpp\n@@ -261,9 +261,9 @@ void MergeTreeWhereOptimizer::analyzeImpl(Conditions & res, const RPNBuilderTree\n         cond.columns_size = getColumnsSize(cond.table_columns);\n \n         cond.viable =\n-            !has_invalid_column &&\n+            !has_invalid_column\n             /// Condition depend on some column. Constant expressions are not moved.\n-            !cond.table_columns.empty()\n+            && !cond.table_columns.empty()\n             && !cannotBeMoved(node, where_optimizer_context)\n             /// When use final, do not take into consideration the conditions with non-sorting keys. Because final select\n             /// need to use all sorting keys, it will cause correctness issues if we filter other columns before final merge.\n@@ -273,17 +273,15 @@ void MergeTreeWhereOptimizer::analyzeImpl(Conditions & res, const RPNBuilderTree\n             /// Do not move conditions involving all queried columns.\n             && cond.table_columns.size() < queried_columns.size();\n \n-        if (cond.viable)\n-            cond.good = isConditionGood(node, table_columns);\n-\n         if (where_optimizer_context.use_statistic)\n         {\n             cond.good = cond.viable;\n-\n             cond.selectivity = estimator.estimateSelectivity(node);\n-\n-            if (node.getASTNode() != nullptr)\n-                LOG_TEST(log, \"Condition {} has selectivity {}\", node.getASTNode()->dumpTree(), cond.selectivity);\n+            LOG_TEST(log, \"Condition {} has selectivity {}\", node.getColumnName(), cond.selectivity);\n+        }\n+        else if (cond.viable)\n+        {\n+            cond.good = isConditionGood(node, table_columns);\n         }\n \n         if (where_optimizer_context.move_primary_key_columns_to_end_of_prewhere)\n@@ -363,6 +361,7 @@ std::optional<MergeTreeWhereOptimizer::OptimizeResult> MergeTreeWhereOptimizer::\n     /// Move condition and all other conditions depend on the same set of columns.\n     auto move_condition = [&](Conditions::iterator cond_it)\n     {\n+        LOG_TRACE(log, \"Condition {} moved to PREWHERE\", cond_it->node.getColumnName());\n         prewhere_conditions.splice(prewhere_conditions.end(), where_conditions, cond_it);\n         total_size_of_moved_conditions += cond_it->columns_size;\n         total_number_of_moved_columns += cond_it->table_columns.size();\n@@ -371,9 +370,14 @@ std::optional<MergeTreeWhereOptimizer::OptimizeResult> MergeTreeWhereOptimizer::\n         for (auto jt = where_conditions.begin(); jt != where_conditions.end();)\n         {\n             if (jt->viable && jt->columns_size == cond_it->columns_size && jt->table_columns == cond_it->table_columns)\n+            {\n+                LOG_TRACE(log, \"Condition {} moved to PREWHERE\", jt->node.getColumnName());\n                 prewhere_conditions.splice(prewhere_conditions.end(), where_conditions, jt++);\n+            }\n             else\n+            {\n                 ++jt;\n+            }\n         }\n     };\n \ndiff --git a/src/Storages/Statistics/Estimator.cpp b/src/Storages/Statistics/Estimator.cpp\nindex 7e0e465c7bff..e272014c1c29 100644\n--- a/src/Storages/Statistics/Estimator.cpp\n+++ b/src/Storages/Statistics/Estimator.cpp\n@@ -112,7 +112,7 @@ Float64 ConditionEstimator::estimateSelectivity(const RPNBuilderTreeNode & node)\n     auto [op, val] = extractBinaryOp(node, col);\n     if (op == \"equals\")\n     {\n-        if (val < - threshold || val > threshold)\n+        if (val < -threshold || val > threshold)\n             return default_normal_cond_factor;\n         else\n             return default_good_cond_factor;\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/03164_materialize_skip_index.reference b/tests/queries/0_stateless/03164_materialize_skip_index.reference\nnew file mode 100644\nindex 000000000000..34251101e894\n--- /dev/null\n+++ b/tests/queries/0_stateless/03164_materialize_skip_index.reference\n@@ -0,0 +1,52 @@\n+20\n+Expression ((Project names + Projection))\n+  Aggregating\n+    Expression (Before GROUP BY)\n+      Expression\n+        ReadFromMergeTree (default.t_skip_index_insert)\n+        Indexes:\n+          Skip\n+            Name: idx_a\n+            Description: minmax GRANULARITY 1\n+            Parts: 2/2\n+            Granules: 50/50\n+          Skip\n+            Name: idx_b\n+            Description: set GRANULARITY 1\n+            Parts: 2/2\n+            Granules: 50/50\n+20\n+Expression ((Project names + Projection))\n+  Aggregating\n+    Expression (Before GROUP BY)\n+      Expression\n+        ReadFromMergeTree (default.t_skip_index_insert)\n+        Indexes:\n+          Skip\n+            Name: idx_a\n+            Description: minmax GRANULARITY 1\n+            Parts: 1/1\n+            Granules: 6/50\n+          Skip\n+            Name: idx_b\n+            Description: set GRANULARITY 1\n+            Parts: 1/1\n+            Granules: 6/6\n+20\n+Expression ((Project names + Projection))\n+  Aggregating\n+    Expression (Before GROUP BY)\n+      Expression\n+        ReadFromMergeTree (default.t_skip_index_insert)\n+        Indexes:\n+          Skip\n+            Name: idx_a\n+            Description: minmax GRANULARITY 1\n+            Parts: 1/2\n+            Granules: 6/50\n+          Skip\n+            Name: idx_b\n+            Description: set GRANULARITY 1\n+            Parts: 1/1\n+            Granules: 6/6\n+4\t0\ndiff --git a/tests/queries/0_stateless/03164_materialize_skip_index.sql b/tests/queries/0_stateless/03164_materialize_skip_index.sql\nnew file mode 100644\nindex 000000000000..4e59ef6b6cd9\n--- /dev/null\n+++ b/tests/queries/0_stateless/03164_materialize_skip_index.sql\n@@ -0,0 +1,50 @@\n+DROP TABLE IF EXISTS t_skip_index_insert;\n+\n+CREATE TABLE t_skip_index_insert\n+(\n+    a UInt64,\n+    b UInt64,\n+    INDEX idx_a a TYPE minmax,\n+    INDEX idx_b b TYPE set(3)\n+)\n+ENGINE = MergeTree ORDER BY tuple() SETTINGS index_granularity = 4;\n+\n+SET allow_experimental_analyzer = 1;\n+SET materialize_skip_indexes_on_insert = 0;\n+\n+SYSTEM STOP MERGES t_skip_index_insert;\n+\n+INSERT INTO t_skip_index_insert SELECT number, number / 50 FROM numbers(100);\n+INSERT INTO t_skip_index_insert SELECT number, number / 50 FROM numbers(100, 100);\n+\n+SELECT count() FROM t_skip_index_insert WHERE a >= 110 AND a < 130 AND b = 2;\n+EXPLAIN indexes = 1 SELECT count() FROM t_skip_index_insert WHERE a >= 110 AND a < 130 AND b = 2;\n+\n+SYSTEM START MERGES t_skip_index_insert;\n+OPTIMIZE TABLE t_skip_index_insert FINAL;\n+\n+SELECT count() FROM t_skip_index_insert WHERE a >= 110 AND a < 130 AND b = 2;\n+EXPLAIN indexes = 1 SELECT count() FROM t_skip_index_insert WHERE a >= 110 AND a < 130 AND b = 2;\n+\n+TRUNCATE TABLE t_skip_index_insert;\n+\n+INSERT INTO t_skip_index_insert SELECT number, number / 50 FROM numbers(100);\n+INSERT INTO t_skip_index_insert SELECT number, number / 50 FROM numbers(100, 100);\n+\n+SET mutations_sync = 2;\n+\n+ALTER TABLE t_skip_index_insert MATERIALIZE INDEX idx_a;\n+ALTER TABLE t_skip_index_insert MATERIALIZE INDEX idx_b;\n+\n+SELECT count() FROM t_skip_index_insert WHERE a >= 110 AND a < 130 AND b = 2;\n+EXPLAIN indexes = 1 SELECT count() FROM t_skip_index_insert WHERE a >= 110 AND a < 130 AND b = 2;\n+\n+DROP TABLE IF EXISTS t_skip_index_insert;\n+\n+SYSTEM FLUSH LOGS;\n+\n+SELECT count(), sum(ProfileEvents['MergeTreeDataWriterSkipIndicesCalculationMicroseconds'])\n+FROM system.query_log\n+WHERE current_database = currentDatabase()\n+    AND query LIKE 'INSERT INTO t_skip_index_insert SELECT%'\n+    AND type = 'QueryFinish';\ndiff --git a/tests/queries/0_stateless/03164_materialize_statistics.reference b/tests/queries/0_stateless/03164_materialize_statistics.reference\nnew file mode 100644\nindex 000000000000..c209d2e8b630\n--- /dev/null\n+++ b/tests/queries/0_stateless/03164_materialize_statistics.reference\n@@ -0,0 +1,10 @@\n+10\n+10\n+10\n+statistic not used\tCondition less(b, 10_UInt8) moved to PREWHERE\n+statistic not used\tCondition less(a, 10_UInt8) moved to PREWHERE\n+statistic used after merge\tCondition less(a, 10_UInt8) moved to PREWHERE\n+statistic used after merge\tCondition less(b, 10_UInt8) moved to PREWHERE\n+statistic used after materialize\tCondition less(a, 10_UInt8) moved to PREWHERE\n+statistic used after materialize\tCondition less(b, 10_UInt8) moved to PREWHERE\n+2\t0\ndiff --git a/tests/queries/0_stateless/03164_materialize_statistics.sql b/tests/queries/0_stateless/03164_materialize_statistics.sql\nnew file mode 100644\nindex 000000000000..763644d16abe\n--- /dev/null\n+++ b/tests/queries/0_stateless/03164_materialize_statistics.sql\n@@ -0,0 +1,49 @@\n+DROP TABLE IF EXISTS t_statistic_materialize;\n+\n+SET allow_experimental_analyzer = 1;\n+SET allow_experimental_statistic = 1;\n+SET allow_statistic_optimize = 1;\n+SET materialize_statistics_on_insert = 0;\n+\n+CREATE TABLE t_statistic_materialize\n+(\n+    a Int64 STATISTIC(tdigest),\n+    b Int16 STATISTIC(tdigest),\n+) ENGINE = MergeTree() ORDER BY tuple()\n+SETTINGS min_bytes_for_wide_part = 0, enable_vertical_merge_algorithm = 0; -- TODO: there is a bug in vertical merge with statistics.\n+\n+INSERT INTO t_statistic_materialize SELECT number, -number FROM system.numbers LIMIT 10000;\n+\n+SELECT count(*) FROM t_statistic_materialize WHERE b < 10 and a < 10 SETTINGS log_comment = 'statistic not used';\n+\n+OPTIMIZE TABLE t_statistic_materialize FINAL;\n+\n+SELECT count(*) FROM t_statistic_materialize WHERE b < 10 and a < 10 SETTINGS log_comment = 'statistic used after merge';\n+\n+TRUNCATE TABLE t_statistic_materialize;\n+SET mutations_sync = 2;\n+\n+INSERT INTO t_statistic_materialize SELECT number, -number FROM system.numbers LIMIT 10000;\n+ALTER TABLE t_statistic_materialize MATERIALIZE STATISTIC a, b TYPE tdigest;\n+\n+SELECT count(*) FROM t_statistic_materialize WHERE b < 10 and a < 10 SETTINGS log_comment = 'statistic used after materialize';\n+\n+DROP TABLE t_statistic_materialize;\n+\n+SYSTEM FLUSH LOGS;\n+\n+SELECT log_comment, message FROM system.text_log JOIN\n+(\n+    SELECT Settings['log_comment'] AS log_comment, query_id FROM system.query_log\n+    WHERE current_database = currentDatabase()\n+        AND query LIKE 'SELECT count(*) FROM t_statistic_materialize%'\n+        AND type = 'QueryFinish'\n+) AS query_log USING (query_id)\n+WHERE message LIKE '%moved to PREWHERE%'\n+ORDER BY event_time_microseconds;\n+\n+SELECT count(), sum(ProfileEvents['MergeTreeDataWriterStatisticsCalculationMicroseconds'])\n+FROM system.query_log\n+WHERE current_database = currentDatabase()\n+    AND query LIKE 'INSERT INTO t_statistic_materialize SELECT%'\n+    AND type = 'QueryFinish';\n",
  "problem_statement": "Do not materialize indexes during inserts\n**Use case**\r\n\r\nUser wants to have fast inserts and there are many indexes.\r\nLevel0 parts are small vs the whole data in table so reading it without indexes can be possible.\r\n\r\n**Describe the solution you'd like**\r\n\r\nA setting `materialize_index_on_insert`. Enabled by default as today. By disabling index will not be materialized on insert, but will appear during merge.\n",
  "hints_text": "Same for projections\nQuoting @CurtizJ :-) `No, for projections it won\u2019t work because we don\u2019t recalculate projections on merges.`\nInteresting, I did not know that it works this way.\r\n\r\nParts have different number of projections: 0 in part 'all_2_2_0' and 1 in part 'all_3_3_0'. Cannot select parts for optimization. (CANNOT_ASSIGN_OPTIMIZE)\r\n\r\nhttps://fiddle.clickhouse.com/9b184f13-270f-46df-a195-df5d71a231e7\n> Quoting @CurtizJ :-) `No, for projections it won\u2019t work because we don\u2019t recalculate projections on merges.`\r\n\r\nThis can be solved by #62364, if any part participating in merge has materialized the projection .",
  "created_at": "2024-05-24T17:11:17Z",
  "modified_files": [
    "src/Core/Settings.h",
    "src/Core/SettingsChangesHistory.h",
    "src/Storages/MergeTree/MergeTreeDataPartWriterOnDisk.cpp",
    "src/Storages/MergeTree/MergeTreeDataWriter.cpp",
    "src/Storages/MergeTree/MergeTreeWhereOptimizer.cpp",
    "src/Storages/Statistics/Estimator.cpp"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/03164_materialize_skip_index.reference",
    "b/tests/queries/0_stateless/03164_materialize_skip_index.sql",
    "b/tests/queries/0_stateless/03164_materialize_statistics.reference",
    "b/tests/queries/0_stateless/03164_materialize_statistics.sql"
  ]
}