You will be provided with a partial code base and an issue statement explaining a problem to resolve.

<issue>
Object('json'): File name too long. (CANNOT_OPEN_FILE) long key
**Describe what's wrong**

When cloning a bunch of data over to a new Object('json') column, I got the following error.

**Does it reproduce on recent release?**


Tested on 22.6.1 revision 54455

**How to reproduce**

This occurred to me when copying ~1M records from an old table to a new one. I did manage to eventually reproduce this:

```sql

SET allow_experimental_object_type = 1;
CREATE TABLE t_json(id UInt64, obj JSON) ENGINE = MergeTree ORDER BY id;

INSERT INTO t_json (id, obj) SELECT
    number,
    concat('{"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa', toString(number), '":1}')
FROM system.numbers
LIMIT 10000;
```

**Expected behavior**

INSERT succeeds or long object keys are explicitly forbidden.

**Error message and/or stacktrace**

```
2022.06.29 09:04:37.920717 [ 18087 ] {44e0edf4-9939-4ab4-a0c3-48300e794fb5} <Error> TCPHandler: Code: 76. DB::ErrnoException: Cannot open file /var/lib/clickhouse/store/d71/d712ff2b-a7fe-4ad6-bdee-80acea7e7087/t
mp_insert_all_16_16_0/obj%2Eaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa0.bin, errno: 36, strerror: File name too long. (CANNOT_OPEN_FILE), Stack trace (when copying this message, always include the lines below):

0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0xb8a147a in /usr/bin/clickhouse
1. DB::throwFromErrnoWithPath(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, int) @ 0xb8a252a in /usr/bin/clickhouse
2. DB::WriteBufferFromFile::WriteBufferFromFile(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long, int, unsigned int, char*, unsigned long) @ 0xb9ea23a in /usr/bin/clickhouse
3. DB::DiskLocal::writeFile(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long, DB::WriteMode, DB::WriteSettings const&) @ 0x159734b7 in /usr/bin/clickhouse
4. DB::MergeTreeDataPartWriterOnDisk::Stream::Stream(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::shared_ptr<DB::IDisk>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::shared_ptr<DB::ICompressionCodec> const&, unsigned long, DB::WriteSettings const&) @ 0x16c1e02b in /usr/bin/clickhouse
5. ? @ 0x16c27db8 in /usr/bin/clickhouse
6. DB::ISerialization::enumerateStreams(DB::ISerialization::SubstreamPath&, std::__1::function<void (DB::ISerialization::SubstreamPath const&)> const&, DB::ISerialization::SubstreamData const&) const @ 0x15840511 in /usr/bin/clickhouse
7. DB::SerializationNamed::enumerateStreams(DB::ISerialization::SubstreamPath&, std::__1::function<void (DB::ISerialization::SubstreamPath const&)> const&, DB::ISerialization::SubstreamData const&) const @ 0x15865bfb in /usr/bin/clickhouse
8. DB::SerializationTuple::enumerateStreams(DB::ISerialization::SubstreamPath&, std::__1::function<void (DB::ISerialization::SubstreamPath const&)> const&, DB::ISerialization::SubstreamData const&) const @ 0x158874c6 in /usr/bin/clickhouse
9. DB::ISerialization::enumerateStreams(DB::ISerialization::SubstreamPath&, std::__1::function<void (DB::ISerialization::SubstreamPath const&)> const&, std::__1::shared_ptr<DB::IDataType const> const&) const @ 0x158408f5 in /usr/bin/clickhouse
10. DB::MergeTreeDataPartWriterWide::addStreams(DB::NameAndTypePair const&, std::__1::shared_ptr<DB::IAST> const&) @ 0x16c2196c in /usr/bin/clickhouse
11. DB::MergeTreeDataPartWriterWide::MergeTreeDataPartWriterWide(std::__1::shared_ptr<DB::IMergeTreeDataPart const> const&, DB::NamesAndTypesList const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, std::__1::vector<std::__1::shared_ptr<DB::IMergeTreeIndex const>, std::__1::allocator<std::__1::shared_ptr<DB::IMergeTreeIndex const> > > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::shared_ptr<DB::ICompressionCodec> const&, DB::MergeTreeWriterSettings const&, DB::MergeTreeIndexGranularity const&) @ 0x16c2178a in /usr/bin/clickhouse
12. DB::MergeTreeDataPartWide::getWriter(DB::NamesAndTypesList const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, std::__1::vector<std::__1::shared_ptr<DB::IMergeTreeIndex const>, std::__1::allocator<std::__1::shared_ptr<DB::IMergeTreeIndex const> > > const&, std::__1::shared_ptr<DB::ICompressionCodec> const&, DB::MergeTreeWriterSettings const&, DB::MergeTreeIndexGranularity const&) const @ 0x16c11162 in /usr/bin/clickhouse
13. DB::MergedBlockOutputStream::MergedBlockOutputStream(std::__1::shared_ptr<DB::IMergeTreeDataPart const> const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, DB::NamesAndTypesList const&, std::__1::vector<std::__1::shared_ptr<DB::IMergeTreeIndex const>, std::__1::allocator<std::__1::shared_ptr<DB::IMergeTreeIndex const> > > const&, std::__1::shared_ptr<DB::ICompressionCodec>, std::__1::shared_ptr<DB::MergeTreeTransaction> const&, bool, bool, DB::WriteSettings const&) @ 0x16d0573e in /usr/bin/clickhouse
14. DB::MergeTreeDataWriter::writeTempPart(DB::BlockWithPartition&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, std::__1::shared_ptr<DB::Context const>) @ 0x16cf31aa in /usr/bin/clickhouse
15. DB::MergeTreeSink::consume(DB::Chunk) @ 0x16ce8284 in /usr/bin/clickhouse
16. DB::SinkToStorage::onConsume(DB::Chunk) @ 0x17407b40 in /usr/bin/clickhouse
17. ? @ 0x17373ff7 in /usr/bin/clickhouse
18. ? @ 0x17373cd6 in /usr/bin/clickhouse
19. DB::ExceptionKeepingTransform::work() @ 0x1737354a in /usr/bin/clickhouse
20. DB::ExecutionThreadContext::executeTask() @ 0x171af9fa in /usr/bin/clickhouse
21. DB::PipelineExecutor::executeStepImpl(unsigned long, std::__1::atomic<bool>*) @ 0x171a491e in /usr/bin/clickhouse
22. DB::PipelineExecutor::executeImpl(unsigned long) @ 0x171a3921 in /usr/bin/clickhouse
23. DB::PipelineExecutor::execute(unsigned long) @ 0x171a36b8 in /usr/bin/clickhouse
24. ? @ 0x171a2a2b in /usr/bin/clickhouse
25. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0xb94d0b7 in /usr/bin/clickhouse
26. ? @ 0xb9504dd in /usr/bin/clickhouse
27. ? @ 0x7fae6e91db43 in ?
28. ? @ 0x7fae6e9afa00 in ?
```

**Additional context**

This only seems to occur when the table switches to the wide format, so the setup above might need to be run a few times.
Adding Checks on the column name to avoid: strerror: File name too long.
ClickHouse should have checks on the column name to avoid long column names that could lead to the following error:

> <Error> MergeFromLogEntryTask: virtual bool DB::ReplicatedMergeMutateTaskBase::executeStep(): Code: 76. DB::ErrnoException: Cannot open file /var/lib/clickhouse/data/yc%2Dosquery/shard_syslog_shell/tmp_merge_20220422_46793_50514_2474/sudo__command_continued__cr%2Ecorp_yc%2Dcr%2Dinternal_container%2Dregistry%2Dmigrator_cr%2D2022%2D04%2D21%2Dcloud%2D98762%2Dpeasa%2D25602%2D58a09ee3f3_java_%2Djar_maven_container%2Dregistry%2Dmigrator%2Dcr%2D2022%2D04%2D21%2Dcloud%2D98762%2Dpeasa%2D25602%2D58a09ee3f3%2Ejar__migration.bin, errno: 36, strerror: File name too long.

This kind of issue might happen if you have an automated process of creating tables and columns. It would be nice if there was a hard/soft limit implemented to make sure that column names do not exceed a specific threshold.

Or maybe we could find a different mechanism to create the name of the file.
</issue>

I need you to solve the provided issue by generating a code fix that can be applied directly to the repository

Respond below:
