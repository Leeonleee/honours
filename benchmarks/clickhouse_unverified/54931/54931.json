{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 54931,
  "instance_id": "ClickHouse__ClickHouse-54931",
  "issue_numbers": [
    "31093"
  ],
  "base_commit": "03aa886904331774fb707951bdd65845d31650ba",
  "patch": "diff --git a/docs/en/sql-reference/table-functions/s3.md b/docs/en/sql-reference/table-functions/s3.md\nindex 07addafcf58e..8649295e8150 100644\n--- a/docs/en/sql-reference/table-functions/s3.md\n+++ b/docs/en/sql-reference/table-functions/s3.md\n@@ -162,6 +162,28 @@ The below get data from all `test-data.csv.gz` files from any folder inside `my-\n SELECT * FROM s3('https://clickhouse-public-datasets.s3.amazonaws.com/my-test-bucket-768/**/test-data.csv.gz', 'CSV', 'name String, value UInt32', 'gzip');\n ```\n \n+Note. It is possible to specify custom URL mappers in the server configuration file. Example: \n+``` sql\n+SELECT * FROM s3('s3://clickhouse-public-datasets/my-test-bucket-768/**/test-data.csv.gz', 'CSV', 'name String, value UInt32', 'gzip');\n+```\n+The URL `'s3://clickhouse-public-datasets/my-test-bucket-768/**/test-data.csv.gz'` would be replaced to `'http://clickhouse-public-datasets.s3.amazonaws.com/my-test-bucket-768/**/test-data.csv.gz'`\n+\n+\n+Custom mapper can be added into `config.xml`:\n+``` xml\n+<url_scheme_mappers>\n+   <s3>\n+      <to>https://{bucket}.s3.amazonaws.com</to>\n+   </s3>\n+   <gs>\n+      <to>https://{bucket}.storage.googleapis.com</to>\n+   </gs>\n+   <oss>\n+      <to>https://{bucket}.oss.aliyuncs.com</to>\n+   </oss>\n+</url_scheme_mappers>\n+```\n+\n ## Partitioned Write\n \n If you specify `PARTITION BY` expression when inserting data into `S3` table, a separate file is created for each partition value. Splitting the data into separate files helps to improve reading operations efficiency.\ndiff --git a/programs/server/config.xml b/programs/server/config.xml\nindex 07427c2851a0..38eceb083ddb 100644\n--- a/programs/server/config.xml\n+++ b/programs/server/config.xml\n@@ -91,6 +91,18 @@\n         </formatting> -->\n     </logger>\n \n+    <url_scheme_mappers>\n+        <s3>\n+            <to>https://{bucket}.s3.amazonaws.com</to>\n+        </s3>\n+        <gs>\n+            <to>https://{bucket}.storage.googleapis.com</to>\n+        </gs>\n+        <oss>\n+            <to>https://{bucket}.oss.aliyuncs.com</to>\n+        </oss>\n+    </url_scheme_mappers>\n+\n     <!-- Add headers to response in options request. OPTIONS method is used in CORS preflight requests. -->\n     <!-- It is off by default. Next headers are obligate for CORS.-->\n     <!-- http_options_response>\ndiff --git a/src/Common/Macros.cpp b/src/Common/Macros.cpp\nindex f43fed6c4992..891aa53c0615 100644\n--- a/src/Common/Macros.cpp\n+++ b/src/Common/Macros.cpp\n@@ -1,3 +1,5 @@\n+#include <algorithm>\n+#include <unordered_map>\n #include <Poco/Util/AbstractConfiguration.h>\n #include <Common/Macros.h>\n #include <Common/Exception.h>\n@@ -36,6 +38,11 @@ Macros::Macros(const Poco::Util::AbstractConfiguration & config, const String &\n     }\n }\n \n+Macros::Macros(std::map<String, String> map)\n+{\n+    macros = std::move(map);\n+}\n+\n String Macros::expand(const String & s,\n                       MacroExpansionInfo & info) const\n {\ndiff --git a/src/Common/Macros.h b/src/Common/Macros.h\nindex d403f5d2ceee..9fe5717effc0 100644\n--- a/src/Common/Macros.h\n+++ b/src/Common/Macros.h\n@@ -27,6 +27,7 @@ class Macros\n public:\n     Macros() = default;\n     Macros(const Poco::Util::AbstractConfiguration & config, const String & key, Poco::Logger * log = nullptr);\n+    explicit Macros(std::map<String, String> map);\n \n     struct MacroExpansionInfo\n     {\ndiff --git a/src/IO/S3/URI.cpp b/src/IO/S3/URI.cpp\nindex cb86908ea713..a08e7b5a65d4 100644\n--- a/src/IO/S3/URI.cpp\n+++ b/src/IO/S3/URI.cpp\n@@ -1,5 +1,8 @@\n #include <IO/S3/URI.h>\n-\n+#include <Poco/URI.h>\n+#include \"Common/Macros.h\"\n+#include <Interpreters/Context.h>\n+#include <Storages/NamedCollectionsHelpers.h>\n #if USE_AWS_S3\n #include <Common/Exception.h>\n #include <Common/quoteString.h>\n@@ -18,6 +21,15 @@\n namespace DB\n {\n \n+struct URIConverter\n+{\n+    static void modifyURI(Poco::URI & uri, std::unordered_map<std::string, std::string> mapper)\n+    {\n+        Macros macros({{\"bucket\", uri.getHost()}});\n+        uri = macros.expand(mapper[uri.getScheme()]).empty()? uri : Poco::URI(macros.expand(mapper[uri.getScheme()]) + \"/\" + uri.getPathAndQuery());\n+    }\n+};\n+\n namespace ErrorCodes\n {\n     extern const int BAD_ARGUMENTS;\n@@ -46,6 +58,29 @@ URI::URI(const std::string & uri_)\n \n     uri = Poco::URI(uri_);\n \n+    std::unordered_map<std::string, std::string> mapper;\n+    auto context = Context::getGlobalContextInstance();\n+    if (context)\n+    {\n+        const auto *config = &context->getConfigRef();\n+        if (config->has(\"url_scheme_mappers\"))\n+        {\n+            std::vector<String> config_keys;\n+            config->keys(\"url_scheme_mappers\", config_keys);\n+            for (const std::string & config_key : config_keys)\n+                mapper[config_key] = config->getString(\"url_scheme_mappers.\" + config_key + \".to\");\n+        }\n+        else\n+        {\n+            mapper[\"s3\"] = \"https://{bucket}.s3.amazonaws.com\";\n+            mapper[\"gs\"] = \"https://{bucket}.storage.googleapis.com\";\n+            mapper[\"oss\"] = \"https://{bucket}.oss.aliyuncs.com\";\n+        }\n+\n+        if (!mapper.empty())\n+            URIConverter::modifyURI(uri, mapper);\n+    }\n+\n     storage_name = S3;\n \n     if (uri.getHost().empty())\n",
  "test_patch": "diff --git a/tests/integration/test_s3_style_link/__init__.py b/tests/integration/test_s3_style_link/__init__.py\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/integration/test_s3_style_link/configs/config.d/minio.xml b/tests/integration/test_s3_style_link/configs/config.d/minio.xml\nnew file mode 100644\nindex 000000000000..072d07b7f739\n--- /dev/null\n+++ b/tests/integration/test_s3_style_link/configs/config.d/minio.xml\n@@ -0,0 +1,10 @@\n+<?xml version=\"1.0\"?>\n+\n+<!-- Using named collections 22.4+ -->\n+<clickhouse>\n+    <url_scheme_mappers>\n+        <minio>\n+            <to>http://minio1:9001/root/{bucket}</to>\n+        </minio>\n+    </url_scheme_mappers>\n+</clickhouse>\ndiff --git a/tests/integration/test_s3_style_link/configs/users.d/users.xml b/tests/integration/test_s3_style_link/configs/users.d/users.xml\nnew file mode 100644\nindex 000000000000..4b6ba057ecb1\n--- /dev/null\n+++ b/tests/integration/test_s3_style_link/configs/users.d/users.xml\n@@ -0,0 +1,9 @@\n+<clickhouse>\n+    <users>\n+        <default>\n+            <password></password>\n+            <profile>default</profile>\n+            <named_collection_control>1</named_collection_control>\n+        </default>\n+    </users>\n+</clickhouse>\ndiff --git a/tests/integration/test_s3_style_link/test.py b/tests/integration/test_s3_style_link/test.py\nnew file mode 100644\nindex 000000000000..7ecf4e633e31\n--- /dev/null\n+++ b/tests/integration/test_s3_style_link/test.py\n@@ -0,0 +1,57 @@\n+import logging\n+import pytest\n+from helpers.cluster import ClickHouseCluster\n+\n+\n+cluster = ClickHouseCluster(__file__)\n+node = cluster.add_instance(\n+    \"node\",\n+    main_configs=[\n+        \"configs/config.d/minio.xml\",\n+    ],\n+    user_configs=[\n+        \"configs/users.d/users.xml\",\n+    ],\n+    with_minio=True,\n+)\n+\n+\n+@pytest.fixture(scope=\"module\")\n+def started_cluster():\n+    try:\n+        logging.info(\"Starting cluster...\")\n+        cluster.start()\n+        logging.info(\"Cluster started\")\n+\n+        yield cluster\n+    finally:\n+        logging.info(\"Stopping cluster\")\n+        cluster.shutdown()\n+        logging.info(\"Cluster stopped\")\n+\n+\n+def test_s3_table_functions(started_cluster):\n+    \"\"\"\n+    Simple test to check s3 table function functionalities\n+    \"\"\"\n+    node.query(\n+        \"\"\"\n+            INSERT INTO FUNCTION s3\n+                (\n+                    'minio://data/test_file.tsv.gz', 'minio', 'minio123'\n+                )\n+            SELECT * FROM numbers(1000000);\n+        \"\"\"\n+    )\n+\n+    assert (\n+        node.query(\n+            \"\"\"\n+            SELECT count(*) FROM s3\n+            (\n+                'minio://data/test_file.tsv.gz', 'minio', 'minio123'\n+            );\n+        \"\"\"\n+        )\n+        == \"1000000\\n\"\n+    )\n",
  "problem_statement": "s3-style URL does not work.\n**Describe the issue**\r\n\r\nThis works successfully:\r\n```\r\naws s3 cp 'hits.csv' 's3://milovidov-clickhouse-test/hits.csv'\r\n```\r\n\r\nThis does not:\r\n```\r\nSELECT count() FROM s3('s3://milovidov-clickhouse-test/hits.csv', '...', '...', 'CSV', 'WatchID UInt64, JavaEnable UInt8, Title String, GoodEvent Int16, EventTime DateTime, EventDate Date, CounterID UInt32, ClientIP UInt32, RegionID UInt32, UserID UInt64, CounterClass Int8, OS UInt8, UserAgent UInt8, URL String, Referer String, Refresh UInt8, RefererCategoryID UInt16, RefererRegionID UInt32, URLCategoryID UInt16, URLRegionID UInt32, ResolutionWidth UInt16, ResolutionHeight UInt16, ResolutionDepth UInt8, FlashMajor UInt8, FlashMinor UInt8, FlashMinor2 String, NetMajor UInt8, NetMinor UInt8, UserAgentMajor UInt16, UserAgentMinor FixedString(2), CookieEnable UInt8, JavascriptEnable UInt8, IsMobile UInt8, MobilePhone UInt8, MobilePhoneModel String, Params String, IPNetworkID UInt32, TraficSourceID Int8, SearchEngineID UInt16, SearchPhrase String, AdvEngineID UInt8, IsArtifical UInt8, WindowClientWidth UInt16, WindowClientHeight UInt16, ClientTimeZone Int16, ClientEventTime DateTime, SilverlightVersion1 UInt8, SilverlightVersion2 UInt8, SilverlightVersion3 UInt32, SilverlightVersion4 UInt16, PageCharset String, CodeVersion UInt32, IsLink UInt8, IsDownload UInt8, IsNotBounce UInt8, FUniqID UInt64, OriginalURL String, HID UInt32, IsOldCounter UInt8, IsEvent UInt8, IsParameter UInt8, DontCountHits UInt8, WithHash UInt8, HitColor FixedString(1), LocalEventTime DateTime, Age UInt8, Sex UInt8, Income UInt8, Interests UInt16, Robotness UInt8, RemoteIP UInt32, WindowName Int32, OpenerName Int32, HistoryLength Int16, BrowserLanguage FixedString(2), BrowserCountry FixedString(2), SocialNetwork String, SocialAction String, HTTPError UInt16, SendTiming UInt32, DNSTiming UInt32, ConnectTiming UInt32, ResponseStartTiming UInt32, ResponseEndTiming UInt32, FetchTiming UInt32, SocialSourceNetworkID UInt8, SocialSourcePage String, ParamPrice Int64, ParamOrderID String, ParamCurrency FixedString(3), ParamCurrencyID UInt16, OpenstatServiceName String, OpenstatCampaignID String, OpenstatAdID String, OpenstatSourceID String, UTMSource String, UTMMedium String, UTMCampaign String, UTMContent String, UTMTerm String, FromTag String, HasGCLID UInt8, RefererHash UInt64, URLHash UInt64, CLID UInt32')\r\n```\r\n\r\nIt argues about the URL:\r\n\r\n```\r\nCode: 36. DB::Exception: Bucket or key name are invalid in S3 URI. (BAD_ARGUMENTS)\r\n```\r\n\r\nBut I'm using the same URL as with `s3 aws` tool :(\n",
  "hints_text": "Because it should also know about the region.\r\nThis works: https://s3.us-east-2.amazonaws.com/milovidov-clickhouse-test/hits.csv\nWe have the possibility to specify default region in configuration,\r\nthen `s3://milovidov-clickhouse-test/hits.csv` style URLs should work.\nWe can easily determine the region by:\r\n\r\n`curl http://169.254.169.254/latest/meta-data/placement/region`\nOne issue is that there is a place for s3-related settings for DiskS3 (see DiskS3Settings and config examples), but these settings are not applied to table function s3 and StorageS3.\r\n\r\nBut they should be applicable as well. Let's allow to specify them in some global place in config (as the default) and in SETTINGS for table engine.\r\n\r\nAnd this is all to add a setting `default_region_from_url`.\nBut it should not even know about the region.\r\n\r\n```\r\ns3://milovidov-clickhouse-test/hits.csv\r\n```\r\n\r\ncan be translated to\r\n\r\n```\r\nhttps://milovidov-clickhouse-test.s3.amazonaws.com/hits.csv\r\n```\r\n\r\nwe can introduce a notion of the default s3 endpoint, which will be `s3.amazonaws.com` by default.\nWe should have a configuration for schema-to-domain mapping, with hardcoded defaults:\r\n\r\n```\r\ns3 -> s3.amazonaws.com\r\ngs -> ...\r\noss -> ...\r\ncos -> ...\r\n```\r\n\nI am working on this issue.\n@xiedeyantu are you still working on this issue?\nHad this same issue; \r\n\r\nWhen using a R2 - S3 emulation URL it detects it as invalid. It seems it used to work in the past, https://blog.qryn.dev/cloudflare-r2-clickhouse so something must've changed recently. \r\n\r\n`\r\nthrow Exception(ErrorCodes::BAD_ARGUMENTS, \"Bucket or key name are invalid in S3 URI.\");`\nTesting with the URL from the Example \"https://abcdefghi.r2.cloudflarestorage.com/somebucket\" it also breaks with that exception. So anyone who had it working before when they update clickhouse will have their server stop working.\nas a workaround if anyone else has this issue for the R2 one at least.\r\n\r\n\"https://abcdefghi.r2.cloudflarestorage.com/somebucket\" \r\n-->\r\n\"https://abcdefghi.r2.cloudflarestorage.com/somebucket/fakekey/\" seems to solve it.\nImplement a global server configuration:\r\n\r\n```\r\n<url_scheme_mappers>\r\n    <s3>\r\n        <from>s3://{bucket}/</from>\r\n        <to>https://{bucket}.s3.amazonaws.com/</to>\r\n    </s3>\r\n    ...\r\n</url_scheme_mappers>\r\n```\r\n\r\nalso, this form can be used as a shortcut:\r\n\r\n```\r\n<url_scheme_mappers>\r\n    <s3>\r\n        <domain>s3.amazonaws.com</domain>\r\n    </s3>\r\n    ...\r\n</url_scheme_mappers>\r\n```\r\n\r\nIt will be applied for both `s3`, `gcs`, and `url` functions and engines.\r\nThe code will extract the scheme from the URL, check for available mappers, and if a mapper is present, apply the rewrite rule.\r\n\r\nCaveats: we can also support the `{region}` substitution and extract its value from the `AWS_REGION` environment variable, or from the AWS config, or from a setting inside ClickHouse. But as everything works as is, we don't need to do it.\nAlso a question - why the S3 SDK by itself does not support the s3-style URLs? Maybe it does, but we missed it?",
  "created_at": "2023-09-22T16:22:05Z",
  "modified_files": [
    "docs/en/sql-reference/table-functions/s3.md",
    "programs/server/config.xml",
    "src/Common/Macros.cpp",
    "src/Common/Macros.h",
    "src/IO/S3/URI.cpp"
  ],
  "modified_test_files": [
    "b/tests/integration/test_s3_style_link/configs/config.d/minio.xml",
    "b/tests/integration/test_s3_style_link/configs/users.d/users.xml",
    "b/tests/integration/test_s3_style_link/test.py"
  ]
}