{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 45250,
  "instance_id": "ClickHouse__ClickHouse-45250",
  "issue_numbers": [
    "43188"
  ],
  "base_commit": "eefbffcc5b178bf08b4ec36a4106a73154d5d1a5",
  "patch": "diff --git a/programs/server/Server.cpp b/programs/server/Server.cpp\nindex 742838d64334..419b80ccff24 100644\n--- a/programs/server/Server.cpp\n+++ b/programs/server/Server.cpp\n@@ -140,6 +140,7 @@ namespace CurrentMetrics\n namespace ProfileEvents\n {\n     extern const Event MainConfigLoads;\n+    extern const Event ServerStartupMilliseconds;\n }\n \n namespace fs = std::filesystem;\n@@ -652,6 +653,8 @@ static void sanityChecks(Server & server)\n int Server::main(const std::vector<std::string> & /*args*/)\n try\n {\n+    Stopwatch startup_watch;\n+\n     Poco::Logger * log = &logger();\n \n     UseSSL use_ssl;\n@@ -1822,6 +1825,9 @@ try\n             LOG_INFO(log, \"Ready for connections.\");\n         }\n \n+        startup_watch.stop();\n+        ProfileEvents::increment(ProfileEvents::ServerStartupMilliseconds, startup_watch.elapsedMilliseconds());\n+\n         try\n         {\n             global_context->startClusterDiscovery();\ndiff --git a/src/Common/ProfileEvents.cpp b/src/Common/ProfileEvents.cpp\nindex abc28299f96c..1b387c5a080f 100644\n--- a/src/Common/ProfileEvents.cpp\n+++ b/src/Common/ProfileEvents.cpp\n@@ -449,7 +449,8 @@ The server successfully detected this situation and will download merged part fr\n     M(OverflowBreak, \"Number of times, data processing was cancelled by query complexity limitation with setting '*_overflow_mode' = 'break' and the result is incomplete.\") \\\n     M(OverflowThrow, \"Number of times, data processing was cancelled by query complexity limitation with setting '*_overflow_mode' = 'throw' and exception was thrown.\") \\\n     M(OverflowAny, \"Number of times approximate GROUP BY was in effect: when aggregation was performed only on top of first 'max_rows_to_group_by' unique keys and other keys were ignored due to 'group_by_overflow_mode' = 'any'.\") \\\n-\n+    \\\n+    M(ServerStartupMilliseconds, \"Time elapsed from starting server to listening to sockets in milliseconds\")\\\n \n namespace ProfileEvents\n {\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02532_profileevents_server_startup_time.reference b/tests/queries/0_stateless/02532_profileevents_server_startup_time.reference\nnew file mode 100644\nindex 000000000000..e3c0063769c5\n--- /dev/null\n+++ b/tests/queries/0_stateless/02532_profileevents_server_startup_time.reference\n@@ -0,0 +1,1 @@\n+ServerStartupMilliseconds\ndiff --git a/tests/queries/0_stateless/02532_profileevents_server_startup_time.sql b/tests/queries/0_stateless/02532_profileevents_server_startup_time.sql\nnew file mode 100644\nindex 000000000000..d7c97d08c151\n--- /dev/null\n+++ b/tests/queries/0_stateless/02532_profileevents_server_startup_time.sql\n@@ -0,0 +1,1 @@\n+SELECT event FROM system.events WHERE event = 'ServerStartupMilliseconds'\n\\ No newline at end of file\n",
  "problem_statement": "Record the startup time in ProfileEvents.\nSimply record the time from entering `main` to start listening sockets.\n",
  "hints_text": "Would it be possible to record more granular metrics like time taken by TablesLoader, StorageSetOrJoinBase for each separate table loaded?\nProfileEvents are for predefined events, so - they cannot be used for per-table info.\nJust now, I wanted to create this task again - it means that it's still relevant.",
  "created_at": "2023-01-13T12:49:38Z",
  "modified_files": [
    "programs/server/Server.cpp",
    "src/Common/ProfileEvents.cpp"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/02532_profileevents_server_startup_time.reference",
    "b/tests/queries/0_stateless/02532_profileevents_server_startup_time.sql"
  ]
}