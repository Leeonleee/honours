diff --git a/docker/test/stateful/run.sh b/docker/test/stateful/run.sh
index 680392df43eb..f8dee0f8bc94 100755
--- a/docker/test/stateful/run.sh
+++ b/docker/test/stateful/run.sh
@@ -61,6 +61,7 @@ chmod 777 -R /var/lib/clickhouse
 clickhouse-client --query "SHOW DATABASES"
 
 clickhouse-client --query "ATTACH DATABASE datasets ENGINE = Ordinary"
+
 service clickhouse-server restart
 
 # Wait for server to start accepting connections
@@ -109,8 +110,13 @@ function run_tests()
     fi
 
     set +e
-    clickhouse-test --testname --shard --zookeeper --check-zookeeper-session --no-stateless --hung-check --print-time "${ADDITIONAL_OPTIONS[@]}" \
+    clickhouse-test --testname --shard --zookeeper --check-zookeeper-session --no-stateless --hung-check --print-time \
+        --skip 00168_parallel_processing_on_replicas "${ADDITIONAL_OPTIONS[@]}" \
         "$SKIP_TESTS_OPTION" 2>&1 | ts '%Y-%m-%d %H:%M:%S' | tee test_output/test_result.txt
+
+    clickhouse-test --timeout 1200 --testname --shard --zookeeper --check-zookeeper-session --no-stateless --hung-check --print-time \
+    00168_parallel_processing_on_replicas "${ADDITIONAL_OPTIONS[@]}" 2>&1 | ts '%Y-%m-%d %H:%M:%S' | tee -a test_output/test_result.txt
+
     set -e
 }
 
diff --git a/src/Storages/MergeTree/tests/gtest_coordinator.cpp b/src/Storages/MergeTree/tests/gtest_coordinator.cpp
new file mode 100644
index 000000000000..7bcf3304c2b0
--- /dev/null
+++ b/src/Storages/MergeTree/tests/gtest_coordinator.cpp
@@ -0,0 +1,240 @@
+#include <gtest/gtest.h>
+
+#include <utility>
+#include <limits>
+#include <set>
+
+#include <Storages/MergeTree/IntersectionsIndexes.h>
+
+#include <Storages/MergeTree/ParallelReplicasReadingCoordinator.h>
+
+using namespace DB;
+
+
+TEST(HalfIntervals, Simple)
+{
+    ASSERT_TRUE((
+        HalfIntervals{{{1, 2}, {3, 4}}}.negate() ==
+        HalfIntervals{{{0, 1}, {2, 3}, {4, 18446744073709551615UL}}}
+    ));
+
+    {
+        auto left = HalfIntervals{{{0, 2}, {4, 6}}}.negate();
+        ASSERT_TRUE((
+            left ==
+            HalfIntervals{{{2, 4}, {6, 18446744073709551615UL}}}
+        ));
+    }
+
+    {
+        auto left = HalfIntervals{{{0, 2}, {4, 6}}};
+        auto right = HalfIntervals{{{1, 5}}}.negate();
+        auto intersection = left.intersect(right);
+
+        ASSERT_TRUE((
+            intersection ==
+            HalfIntervals{{{0, 1}, {5, 6}}}
+        ));
+    }
+
+    {
+        auto left = HalfIntervals{{{1, 2}, {2, 3}}};
+        auto right = HalfIntervals::initializeWithEntireSpace();
+        auto intersection = right.intersect(left.negate());
+
+        ASSERT_TRUE((
+            intersection ==
+            HalfIntervals{{{0, 1}, {3, 18446744073709551615UL}}}
+        ));
+    }
+
+    {
+        auto left = HalfIntervals{{{1, 2}, {2, 3}, {3, 4}, {4, 5}}};
+
+        ASSERT_EQ(getIntersection(left, HalfIntervals{{{1, 4}}}).convertToMarkRangesFinal().size(), 3);
+        ASSERT_EQ(getIntersection(left, HalfIntervals{{{1, 5}}}).convertToMarkRangesFinal().size(), 4);
+    }
+
+    {
+        auto left = HalfIntervals{{{1, 3}, {3, 5}, {5, 7}}};
+
+        ASSERT_EQ(getIntersection(left, HalfIntervals{{{3, 5}}}).convertToMarkRangesFinal().size(), 1);
+        ASSERT_EQ(getIntersection(left, HalfIntervals{{{3, 7}}}).convertToMarkRangesFinal().size(), 2);
+        ASSERT_EQ(getIntersection(left, HalfIntervals{{{4, 6}}}).convertToMarkRangesFinal().size(), 2);
+        ASSERT_EQ(getIntersection(left, HalfIntervals{{{1, 7}}}).convertToMarkRangesFinal().size(), 3);
+    }
+
+    {
+        auto left = HalfIntervals{{{1, 3}}};
+
+        ASSERT_EQ(getIntersection(left, HalfIntervals{{{3, 4}}}).convertToMarkRangesFinal().size(), 0);
+    }
+
+    {
+        auto left = HalfIntervals{{{1, 2}, {3, 4}, {5, 6}}};
+
+        ASSERT_EQ(getIntersection(left, HalfIntervals{{{2, 3}}}).convertToMarkRangesFinal().size(), 0);
+        ASSERT_EQ(getIntersection(left, HalfIntervals{{{4, 5}}}).convertToMarkRangesFinal().size(), 0);
+        ASSERT_EQ(getIntersection(left, HalfIntervals{{{1, 6}}}).convertToMarkRangesFinal().size(), 3);
+    }
+}
+
+TEST(HalfIntervals, TwoRequests)
+{
+    auto left = HalfIntervals{{{1, 2}, {2, 3}}};
+    auto right = HalfIntervals{{{2, 3}, {3, 4}}};
+    auto intersection = left.intersect(right);
+
+    ASSERT_TRUE((
+        intersection ==
+        HalfIntervals{{{2, 3}}}
+    ));
+
+    /// With negation
+    left = HalfIntervals{{{1, 2}, {2, 3}}}.negate();
+    right = HalfIntervals{{{2, 3}, {3, 4}}};
+    intersection = left.intersect(right);
+
+
+    ASSERT_TRUE((
+        intersection ==
+        HalfIntervals{{{3, 4}}}
+    ));
+}
+
+TEST(HalfIntervals, SelfIntersection)
+{
+    auto left = HalfIntervals{{{1, 2}, {2, 3}, {4, 5}}};
+    auto right = left;
+    auto intersection = left.intersect(right);
+
+    ASSERT_TRUE((
+        intersection == right
+    ));
+
+    left = HalfIntervals{{{1, 2}, {2, 3}, {4, 5}}};
+    right = left;
+    right.negate();
+    intersection = left.intersect(right);
+
+    ASSERT_TRUE((
+        intersection == HalfIntervals{}
+    ));
+}
+
+
+TEST(Coordinator, Simple)
+{
+    PartitionReadRequest request;
+    request.partition_id = "a";
+    request.part_name = "b";
+    request.projection_name = "c";
+    request.block_range = PartBlockRange{1, 2};
+    request.mark_ranges = MarkRanges{{1, 2}, {3, 4}};
+
+    ParallelReplicasReadingCoordinator coordinator;
+    auto response = coordinator.handleRequest(request);
+
+    ASSERT_FALSE(response.denied) << "Process request at first has to be accepted";
+
+    ASSERT_EQ(response.mark_ranges.size(), request.mark_ranges.size());
+
+    for (int i = 0; i < response.mark_ranges.size(); ++i)
+        EXPECT_EQ(response.mark_ranges[i], request.mark_ranges[i]);
+
+    response = coordinator.handleRequest(request);
+    ASSERT_TRUE(response.denied) << "Process the same request second time";
+}
+
+
+TEST(Coordinator, TwoRequests)
+{
+    PartitionReadRequest first;
+    first.partition_id = "a";
+    first.part_name = "b";
+    first.projection_name = "c";
+    first.block_range = PartBlockRange{0, 0};
+    first.mark_ranges = MarkRanges{{1, 2}, {2, 3}};
+
+    auto second = first;
+    second.mark_ranges = MarkRanges{{2, 3}, {3, 4}};
+
+    ParallelReplicasReadingCoordinator coordinator;
+    auto response = coordinator.handleRequest(first);
+
+    ASSERT_FALSE(response.denied) << "First request must me accepted";
+
+    ASSERT_EQ(response.mark_ranges.size(), first.mark_ranges.size());
+    for (int i = 0; i < response.mark_ranges.size(); ++i)
+        EXPECT_EQ(response.mark_ranges[i], first.mark_ranges[i]);
+
+    response = coordinator.handleRequest(second);
+    ASSERT_FALSE(response.denied);
+    ASSERT_EQ(response.mark_ranges.size(), 1);
+    ASSERT_EQ(response.mark_ranges.front(), (MarkRange{3, 4}));
+}
+
+
+TEST(Coordinator, PartIntersections)
+{
+    {
+        PartSegments boundaries;
+
+        boundaries.addPart(PartToRead{{1, 1}, {"TestPart", "TestProjection"}});
+        boundaries.addPart(PartToRead{{2, 2}, {"TestPart", "TestProjection"}});
+        boundaries.addPart(PartToRead{{3, 3}, {"TestPart", "TestProjection"}});
+        boundaries.addPart(PartToRead{{4, 4}, {"TestPart", "TestProjection"}});
+
+        ASSERT_EQ(boundaries.getIntersectionResult({{1, 4}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::REJECT);
+        ASSERT_EQ(boundaries.getIntersectionResult({{0, 5}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::REJECT);
+        ASSERT_EQ(boundaries.getIntersectionResult({{1, 1}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::EXACTLY_ONE_INTERSECTION);
+        ASSERT_EQ(boundaries.getIntersectionResult({{1, 1}, {"ClickHouse", "AnotherProjection"}}), PartSegments::IntersectionResult::REJECT);
+        ASSERT_EQ(boundaries.getIntersectionResult({{1, 2}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::REJECT);
+
+        boundaries.addPart(PartToRead{{5, 5}, {"TestPart", "TestProjection"}});
+        boundaries.addPart(PartToRead{{0, 0}, {"TestPart", "TestProjection"}});
+
+        ASSERT_EQ(boundaries.getIntersectionResult({{0, 5}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::REJECT);
+        ASSERT_EQ(boundaries.getIntersectionResult({{1, 1}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::EXACTLY_ONE_INTERSECTION);
+        ASSERT_EQ(boundaries.getIntersectionResult({{1, 1}, {"ClickHouse", "AnotherProjection"}}), PartSegments::IntersectionResult::REJECT);
+        ASSERT_EQ(boundaries.getIntersectionResult({{1, 2}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::REJECT);
+        ASSERT_EQ(boundaries.getIntersectionResult({{0, 3}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::REJECT);
+    }
+
+    {
+        PartSegments boundaries;
+        boundaries.addPart(PartToRead{{1, 3}, {"TestPart", "TestProjection"}});
+        boundaries.addPart(PartToRead{{4, 5}, {"TestPart", "TestProjection"}});
+
+        ASSERT_EQ(boundaries.getIntersectionResult({{2, 4}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::REJECT);
+        ASSERT_EQ(boundaries.getIntersectionResult({{0, 6}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::REJECT);
+    }
+
+    {
+        PartSegments boundaries;
+        boundaries.addPart(PartToRead{{1, 3}, {"TestPart", "TestProjection"}});
+        boundaries.addPart(PartToRead{{4, 6}, {"TestPart", "TestProjection"}});
+        boundaries.addPart(PartToRead{{7, 9}, {"TestPart", "TestProjection"}});
+
+        ASSERT_EQ(boundaries.getIntersectionResult({{2, 8}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::REJECT);
+        ASSERT_EQ(boundaries.getIntersectionResult({{4, 6}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::EXACTLY_ONE_INTERSECTION);
+        ASSERT_EQ(boundaries.getIntersectionResult({{3, 7}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::REJECT);
+        ASSERT_EQ(boundaries.getIntersectionResult({{5, 7}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::REJECT);
+    }
+
+    {
+        PartSegments boundaries;
+
+        ASSERT_EQ(boundaries.getIntersectionResult({{1, 1}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::NO_INTERSECTION);
+        ASSERT_EQ(boundaries.getIntersectionResult({{1, 3}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::NO_INTERSECTION);
+        ASSERT_EQ(boundaries.getIntersectionResult({{0, 100500}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::NO_INTERSECTION);
+
+        boundaries.addPart(PartToRead{{1, 1}, {"TestPart", "TestProjection"}});
+        boundaries.addPart(PartToRead{{2, 2}, {"TestPart", "TestProjection"}});
+        boundaries.addPart(PartToRead{{3, 3}, {"TestPart", "TestProjection"}});
+
+        ASSERT_EQ(boundaries.getIntersectionResult({{1, 1}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::EXACTLY_ONE_INTERSECTION);
+        ASSERT_EQ(boundaries.getIntersectionResult({{1, 3}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::REJECT);
+        ASSERT_EQ(boundaries.getIntersectionResult({{100, 100500}, {"TestPart", "TestProjection"}}), PartSegments::IntersectionResult::NO_INTERSECTION);
+    }
+}
diff --git a/tests/queries/0_stateless/00124_shard_distributed_with_many_replicas.sql b/tests/queries/0_stateless/00124_shard_distributed_with_many_replicas.sql
index 6bc5fe268d6c..f9cbf92db41f 100644
--- a/tests/queries/0_stateless/00124_shard_distributed_with_many_replicas.sql
+++ b/tests/queries/0_stateless/00124_shard_distributed_with_many_replicas.sql
@@ -1,7 +1,6 @@
 -- Tags: replica, distributed
 
 SET max_parallel_replicas = 2;
-
 DROP TABLE IF EXISTS report;
 
 CREATE TABLE report(id UInt32, event_date Date, priority UInt32, description String) ENGINE = MergeTree(event_date, intHash32(id), (id, event_date, intHash32(id)), 8192);
diff --git a/tests/queries/0_stateless/01870_modulo_partition_key.sql b/tests/queries/0_stateless/01870_modulo_partition_key.sql
index 06b6fc86d3ea..3d839de9c644 100644
--- a/tests/queries/0_stateless/01870_modulo_partition_key.sql
+++ b/tests/queries/0_stateless/01870_modulo_partition_key.sql
@@ -50,7 +50,7 @@ SELECT count() FROM table4 WHERE id % 10 = 7;
 SELECT 'comparison:';
 SELECT v, v-205 as vv, modulo(vv, 200), moduloLegacy(vv, 200) FROM table1 ORDER BY v;
 
-DROP TABLE table1;
-DROP TABLE table2;
-DROP TABLE table3;
-DROP TABLE table4;
+DROP TABLE table1 SYNC;
+DROP TABLE table2 SYNC;
+DROP TABLE table3 SYNC;
+DROP TABLE table4 SYNC;
diff --git a/tests/queries/1_stateful/00168_parallel_processing_on_replicas_part_1.reference b/tests/queries/1_stateful/00168_parallel_processing_on_replicas_part_1.reference
new file mode 100644
index 000000000000..2675904dea0a
--- /dev/null
+++ b/tests/queries/1_stateful/00168_parallel_processing_on_replicas_part_1.reference
@@ -0,0 +1,110 @@
+Testing 00001_count_hits.sql ----> Ok! ✅
+Testing 00002_count_visits.sql ----> Ok! ✅
+Testing 00004_top_counters.sql ----> Ok! ✅
+Testing 00005_filtering.sql ----> Ok! ✅
+Testing 00006_agregates.sql ----> Ok! ✅
+Testing 00007_uniq.sql ----> Ok! ✅
+Testing 00008_uniq.sql ----> Ok! ✅
+Testing 00009_uniq_distributed.sql ----> Ok! ✅
+Testing 00010_quantiles_segfault.sql ----> Ok! ✅
+Testing 00011_sorting.sql ----> Ok! ✅
+Testing 00012_sorting_distributed.sql ----> Ok! ✅
+Skipping 00013_sorting_of_nested.sql 
+Testing 00014_filtering_arrays.sql ----> Ok! ✅
+Testing 00015_totals_and_no_aggregate_functions.sql ----> Ok! ✅
+Testing 00016_any_if_distributed_cond_always_false.sql ----> Ok! ✅
+Testing 00017_aggregation_uninitialized_memory.sql ----> Ok! ✅
+Testing 00020_distinct_order_by_distributed.sql ----> Ok! ✅
+Testing 00021_1_select_with_in.sql ----> Ok! ✅
+Testing 00021_2_select_with_in.sql ----> Ok! ✅
+Testing 00021_3_select_with_in.sql ----> Ok! ✅
+Testing 00022_merge_prewhere.sql ----> Ok! ✅
+Testing 00023_totals_limit.sql ----> Ok! ✅
+Testing 00024_random_counters.sql ----> Ok! ✅
+Testing 00030_array_enumerate_uniq.sql ----> Ok! ✅
+Testing 00031_array_enumerate_uniq.sql ----> Ok! ✅
+Testing 00032_aggregate_key64.sql ----> Ok! ✅
+Testing 00033_aggregate_key_string.sql ----> Ok! ✅
+Testing 00034_aggregate_key_fixed_string.sql ----> Ok! ✅
+Testing 00035_aggregate_keys128.sql ----> Ok! ✅
+Testing 00036_aggregate_hashed.sql ----> Ok! ✅
+Testing 00037_uniq_state_merge1.sql ----> Ok! ✅
+Testing 00038_uniq_state_merge2.sql ----> Ok! ✅
+Testing 00039_primary_key.sql ----> Ok! ✅
+Testing 00040_aggregating_materialized_view.sql ----> Ok! ✅
+Testing 00041_aggregating_materialized_view.sql ----> Ok! ✅
+Testing 00042_any_left_join.sql ----> Ok! ✅
+Testing 00043_any_left_join.sql ----> Ok! ✅
+Testing 00044_any_left_join_string.sql ----> Ok! ✅
+Testing 00045_uniq_upto.sql ----> Ok! ✅
+Testing 00046_uniq_upto_distributed.sql ----> Ok! ✅
+Testing 00047_bar.sql ----> Ok! ✅
+Testing 00048_min_max.sql ----> Ok! ✅
+Testing 00049_max_string_if.sql ----> Ok! ✅
+Testing 00050_min_max.sql ----> Ok! ✅
+Testing 00051_min_max_array.sql ----> Ok! ✅
+Testing 00052_group_by_in.sql ----> Ok! ✅
+Testing 00053_replicate_segfault.sql ----> Ok! ✅
+Testing 00054_merge_tree_partitions.sql ----> Ok! ✅
+Testing 00055_index_and_not.sql ----> Ok! ✅
+Testing 00056_view.sql ----> Ok! ✅
+Testing 00059_merge_sorting_empty_array_joined.sql ----> Ok! ✅
+Testing 00060_move_to_prewhere_and_sets.sql ----> Ok! ✅
+Skipping 00061_storage_buffer.sql 
+Testing 00062_loyalty.sql ----> Ok! ✅
+Testing 00063_loyalty_joins.sql ----> Ok! ✅
+Testing 00065_loyalty_with_storage_join.sql ----> Ok! ✅
+Testing 00066_sorting_distributed_many_replicas.sql ----> Ok! ✅
+Testing 00067_union_all.sql ----> Ok! ✅
+Testing 00068_subquery_in_prewhere.sql ----> Ok! ✅
+Testing 00069_duplicate_aggregation_keys.sql ----> Ok! ✅
+Testing 00071_merge_tree_optimize_aio.sql ----> Ok! ✅
+Testing 00072_compare_date_and_string_index.sql ----> Ok! ✅
+Testing 00073_uniq_array.sql ----> Ok! ✅
+Testing 00074_full_join.sql ----> Ok! ✅
+Testing 00075_left_array_join.sql ----> Ok! ✅
+Testing 00076_system_columns_bytes.sql ----> Ok! ✅
+Testing 00077_log_tinylog_stripelog.sql ----> Ok! ✅
+Testing 00078_group_by_arrays.sql ----> Ok! ✅
+Testing 00079_array_join_not_used_joined_column.sql ----> Ok! ✅
+Testing 00080_array_join_and_union.sql ----> Ok! ✅
+Testing 00081_group_by_without_key_and_totals.sql ----> Ok! ✅
+Testing 00082_quantiles.sql ----> Ok! ✅
+Testing 00083_array_filter.sql ----> Ok! ✅
+Testing 00084_external_aggregation.sql ----> Ok! ✅
+Testing 00085_monotonic_evaluation_segfault.sql ----> Ok! ✅
+Testing 00086_array_reduce.sql ----> Ok! ✅
+Testing 00087_where_0.sql ----> Ok! ✅
+Testing 00088_global_in_one_shard_and_rows_before_limit.sql ----> Ok! ✅
+Testing 00089_position_functions_with_non_constant_arg.sql ----> Ok! ✅
+Testing 00091_prewhere_two_conditions.sql ----> Ok! ✅
+Testing 00093_prewhere_array_join.sql ----> Ok! ✅
+Testing 00094_order_by_array_join_limit.sql ----> Ok! ✅
+Skipping 00095_hyperscan_profiler.sql 
+Testing 00139_like.sql ----> Ok! ✅
+Skipping 00140_rename.sql 
+Testing 00141_transform.sql ----> Ok! ✅
+Testing 00142_system_columns.sql ----> Ok! ✅
+Testing 00143_transform_non_const_default.sql ----> Ok! ✅
+Testing 00144_functions_of_aggregation_states.sql ----> Ok! ✅
+Testing 00145_aggregate_functions_statistics.sql ----> Ok! ✅
+Testing 00146_aggregate_function_uniq.sql ----> Ok! ✅
+Testing 00147_global_in_aggregate_function.sql ----> Ok! ✅
+Testing 00148_monotonic_functions_and_index.sql ----> Ok! ✅
+Testing 00149_quantiles_timing_distributed.sql ----> Ok! ✅
+Testing 00150_quantiles_timing_precision.sql ----> Ok! ✅
+Testing 00151_order_by_read_in_order.sql ----> Ok! ✅
+Skipping 00151_replace_partition_with_different_granularity.sql 
+Skipping 00152_insert_different_granularity.sql 
+Testing 00153_aggregate_arena_race.sql ----> Ok! ✅
+Skipping 00154_avro.sql 
+Testing 00156_max_execution_speed_sample_merge.sql ----> Ok! ✅
+Skipping 00157_cache_dictionary.sql 
+Skipping 00158_cache_dictionary_has.sql 
+Testing 00160_decode_xml_component.sql ----> Ok! ✅
+Testing 00162_mmap_compression_none.sql ----> Ok! ✅
+Testing 00164_quantileBfloat16.sql ----> Ok! ✅
+Testing 00165_jit_aggregate_functions.sql ----> Ok! ✅
+Skipping 00166_explain_estimate.sql 
+Testing 00167_read_bytes_from_fs.sql ----> Ok! ✅
+Total failed tests: 
diff --git a/tests/queries/1_stateful/00168_parallel_processing_on_replicas_part_1.sh b/tests/queries/1_stateful/00168_parallel_processing_on_replicas_part_1.sh
new file mode 100755
index 000000000000..ba1245d96795
--- /dev/null
+++ b/tests/queries/1_stateful/00168_parallel_processing_on_replicas_part_1.sh
@@ -0,0 +1,98 @@
+#!/usr/bin/env bash
+# Tags: no-tsan
+
+CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
+# shellcheck source=../shell_config.sh
+. "$CURDIR"/../shell_config.sh
+
+# set -e
+
+# All replicas are localhost, disable `prefer_localhost_replica` option to test network interface
+# Currently this feature could not work with hedged requests
+# Enabling `enable_sample_offset_parallel_processing` feature could lead to intersecting marks, so some of them would be thrown away and it will lead to incorrect result of SELECT query
+SETTINGS="--max_parallel_replicas=3 --prefer_localhost_replica=false --use_hedged_requests=false --async_socket_for_remote=false  --allow_experimental_parallel_reading_from_replicas=true"
+
+# Prepare tables
+$CLICKHOUSE_CLIENT $SETTINGS -nm -q '''
+    drop table if exists test.dist_hits SYNC;
+    drop table if exists test.dist_visits SYNC;
+
+    create table test.dist_hits as test.hits engine = Distributed("test_cluster_one_shard_three_replicas_localhost", test, hits, rand());
+    create table test.dist_visits as test.visits engine = Distributed("test_cluster_one_shard_three_replicas_localhost", test, visits, rand());
+''';
+
+FAILED=()
+
+# PreviouslyFailed=(
+# )
+
+SkipList=(
+    "00013_sorting_of_nested.sql" # It contains FINAL, which is not allowed together with parallel reading
+
+    "00061_storage_buffer.sql"
+    "00095_hyperscan_profiler.sql" # too long in debug (there is a --no-debug tag inside a test)
+
+    "00140_rename.sql" # Multiple renames are not allowed with DatabaseReplicated and tags are not forwarded through this test
+
+    "00154_avro.sql" # Plain select * with limit with Distributed table is not deterministic
+    "00151_replace_partition_with_different_granularity.sql" # Replace partition from Distributed is not allowed
+    "00152_insert_different_granularity.sql" # The same as above
+
+    "00157_cache_dictionary.sql" # Too long in debug mode, but result is correct
+    "00158_cache_dictionary_has.sql" # The same as above
+
+    "00166_explain_estimate.sql" # Distributed table returns nothing
+)
+
+# for TESTPATH in "${PreviouslyFailed[@]}"
+for TESTPATH in "$CURDIR"/*.sql;
+do
+    TESTNAME=$(basename $TESTPATH)
+
+    if [[ " ${SkipList[*]} " =~ ${TESTNAME} ]]; then
+        echo  "Skipping $TESTNAME "
+        continue
+    fi
+
+    echo -n "Testing $TESTNAME ----> "
+
+    # prepare test
+    NEW_TESTNAME="/tmp/dist_$TESTNAME"
+    # Added g to sed command to replace all tables, not the first
+    cat $TESTPATH | sed -e 's/test.hits/test.dist_hits/g'  | sed -e 's/test.visits/test.dist_visits/g' > $NEW_TESTNAME
+
+    TESTNAME_RESULT="/tmp/result_$TESTNAME"
+    NEW_TESTNAME_RESULT="/tmp/result_dist_$TESTNAME"
+
+    $CLICKHOUSE_CLIENT $SETTINGS -nm --testmode < $TESTPATH > $TESTNAME_RESULT
+    $CLICKHOUSE_CLIENT $SETTINGS -nm --testmode < $NEW_TESTNAME > $NEW_TESTNAME_RESULT
+
+    expected=$(cat $TESTNAME_RESULT | md5sum)
+    actual=$(cat $NEW_TESTNAME_RESULT | md5sum)
+
+    if [[ "$expected" != "$actual" ]]; then
+        FAILED+=("$TESTNAME")
+        echo "Failed! ❌ "
+        echo "Plain:"
+        cat $TESTNAME_RESULT
+        echo "Distributed:"
+        cat $NEW_TESTNAME_RESULT
+    else
+        echo "Ok! ✅"
+    fi
+done
+
+
+echo "Total failed tests: "
+# Iterate the loop to read and print each array element
+for value in "${FAILED[@]}"
+do
+    echo "🔺  $value"
+done
+
+# Drop tables
+
+$CLICKHOUSE_CLIENT $SETTINGS -nm -q '''
+    drop table if exists test.dist_hits SYNC;
+    drop table if exists test.dist_visits SYNC;
+''';
