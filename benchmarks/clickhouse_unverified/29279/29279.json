{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 29279,
  "instance_id": "ClickHouse__ClickHouse-29279",
  "issue_numbers": [
    "26748"
  ],
  "base_commit": "4cc45c1e15912ee300bca7cc8b8da2b888a70e2a",
  "patch": "diff --git a/programs/server/config.xml b/programs/server/config.xml\nindex 37f36aa52155..9a2a6d7729f1 100644\n--- a/programs/server/config.xml\n+++ b/programs/server/config.xml\n@@ -650,6 +650,38 @@\n                 </replica>\n             </shard>\n         </test_shard_localhost>\n+        <test_cluster_one_shard_three_replicas_localhost>\n+            <shard>\n+                <internal_replication>false</internal_replication>\n+                <replica>\n+                    <host>127.0.0.1</host>\n+                    <port>9000</port>\n+                </replica>\n+                <replica>\n+                    <host>127.0.0.2</host>\n+                    <port>9000</port>\n+                </replica>\n+                <replica>\n+                    <host>127.0.0.3</host>\n+                    <port>9000</port>\n+                </replica>\n+            </shard>\n+            <!--shard>\n+                <internal_replication>false</internal_replication>\n+                <replica>\n+                    <host>127.0.0.1</host>\n+                    <port>9000</port>\n+                </replica>\n+                <replica>\n+                    <host>127.0.0.2</host>\n+                    <port>9000</port>\n+                </replica>\n+                <replica>\n+                    <host>127.0.0.3</host>\n+                    <port>9000</port>\n+                </replica>\n+            </shard-->\n+        </test_cluster_one_shard_three_replicas_localhost>\n         <test_cluster_two_shards_localhost>\n              <shard>\n                  <replica>\ndiff --git a/src/CMakeLists.txt b/src/CMakeLists.txt\nindex 5f4ebaaa895a..5e4a16cfda7d 100644\n--- a/src/CMakeLists.txt\n+++ b/src/CMakeLists.txt\n@@ -517,6 +517,8 @@ if (USE_BZIP2)\n     target_include_directories (clickhouse_common_io SYSTEM BEFORE PRIVATE ${BZIP2_INCLUDE_DIR})\n endif()\n \n+dbms_target_link_libraries(PUBLIC consistent-hashing)\n+\n include (\"${ClickHouse_SOURCE_DIR}/cmake/add_check.cmake\")\n \n if (ENABLE_TESTS AND USE_GTEST)\ndiff --git a/src/Client/Connection.cpp b/src/Client/Connection.cpp\nindex ca10160fa88d..505a6514812b 100644\n--- a/src/Client/Connection.cpp\n+++ b/src/Client/Connection.cpp\n@@ -603,6 +603,14 @@ void Connection::sendReadTaskResponse(const String & response)\n     out->next();\n }\n \n+\n+void Connection::sendMergeTreeReadTaskResponse(const PartitionReadResponse & response)\n+{\n+    writeVarUInt(Protocol::Client::MergeTreeReadTaskResponse, *out);\n+    response.serialize(*out);\n+    out->next();\n+}\n+\n void Connection::sendPreparedData(ReadBuffer & input, size_t size, const String & name)\n {\n     /// NOTE 'Throttler' is not used in this method (could use, but it's not important right now).\n@@ -872,6 +880,10 @@ Packet Connection::receivePacket()\n             case Protocol::Server::ReadTaskRequest:\n                 return res;\n \n+            case Protocol::Server::MergeTreeReadTaskRequest:\n+                res.request = receivePartitionReadRequest();\n+                return res;\n+\n             case Protocol::Server::ProfileEvents:\n                 res.block = receiveProfileEvents();\n                 return res;\n@@ -1023,6 +1035,13 @@ ProfileInfo Connection::receiveProfileInfo() const\n     return profile_info;\n }\n \n+PartitionReadRequest Connection::receivePartitionReadRequest() const\n+{\n+    PartitionReadRequest request;\n+    request.deserialize(*in);\n+    return request;\n+}\n+\n \n void Connection::throwUnexpectedPacket(UInt64 packet_type, const char * expected) const\n {\ndiff --git a/src/Client/Connection.h b/src/Client/Connection.h\nindex 3b49760ba104..2ea5334bbd39 100644\n--- a/src/Client/Connection.h\n+++ b/src/Client/Connection.h\n@@ -16,6 +16,8 @@\n \n #include <Compression/ICompressionCodec.h>\n \n+#include <Storages/MergeTree/RequestResponse.h>\n+\n #include <atomic>\n #include <optional>\n \n@@ -104,6 +106,8 @@ class Connection : public IServerConnection\n \n     void sendData(const Block & block, const String & name/* = \"\" */, bool scalar/* = false */) override;\n \n+    void sendMergeTreeReadTaskResponse(const PartitionReadResponse & response) override;\n+\n     void sendExternalTablesData(ExternalTablesData & data) override;\n \n     bool poll(size_t timeout_microseconds/* = 0 */) override;\n@@ -255,6 +259,7 @@ class Connection : public IServerConnection\n     std::vector<String> receiveMultistringMessage(UInt64 msg_type) const;\n     std::unique_ptr<Exception> receiveException() const;\n     Progress receiveProgress() const;\n+    PartitionReadRequest receivePartitionReadRequest() const;\n     ProfileInfo receiveProfileInfo() const;\n \n     void initInputBuffers();\ndiff --git a/src/Client/HedgedConnections.cpp b/src/Client/HedgedConnections.cpp\nindex c73bea53d105..791ac4c1ef18 100644\n--- a/src/Client/HedgedConnections.cpp\n+++ b/src/Client/HedgedConnections.cpp\n@@ -132,7 +132,7 @@ void HedgedConnections::sendQuery(\n     const String & query,\n     const String & query_id,\n     UInt64 stage,\n-    const ClientInfo & client_info,\n+    ClientInfo & client_info,\n     bool with_pending_data)\n {\n     std::lock_guard lock(cancel_mutex);\n@@ -171,7 +171,9 @@ void HedgedConnections::sendQuery(\n             modified_settings.group_by_two_level_threshold_bytes = 0;\n         }\n \n-        if (offset_states.size() > 1)\n+        const bool enable_sample_offset_parallel_processing = settings.max_parallel_replicas > 1 && !settings.allow_experimental_parallel_reading_from_replicas;\n+\n+        if (offset_states.size() > 1 && enable_sample_offset_parallel_processing)\n         {\n             modified_settings.parallel_replicas_count = offset_states.size();\n             modified_settings.parallel_replica_offset = fd_to_replica_location[replica.packet_receiver->getFileDescriptor()].offset;\ndiff --git a/src/Client/HedgedConnections.h b/src/Client/HedgedConnections.h\nindex e39d9582cdea..d64f7ea4286e 100644\n--- a/src/Client/HedgedConnections.h\n+++ b/src/Client/HedgedConnections.h\n@@ -86,7 +86,7 @@ class HedgedConnections : public IConnections\n         const String & query,\n         const String & query_id,\n         UInt64 stage,\n-        const ClientInfo & client_info,\n+        ClientInfo & client_info,\n         bool with_pending_data) override;\n \n     void sendReadTaskResponse(const String &) override\n@@ -94,6 +94,11 @@ class HedgedConnections : public IConnections\n         throw Exception(\"sendReadTaskResponse in not supported with HedgedConnections\", ErrorCodes::LOGICAL_ERROR);\n     }\n \n+    void sendMergeTreeReadTaskResponse(PartitionReadResponse) override\n+    {\n+        throw Exception(\"sendMergeTreeReadTaskResponse in not supported with HedgedConnections\", ErrorCodes::LOGICAL_ERROR);\n+    }\n+\n     Packet receivePacket() override;\n \n     Packet receivePacketUnlocked(AsyncCallback async_callback, bool is_draining) override;\n@@ -112,6 +117,8 @@ class HedgedConnections : public IConnections\n \n     bool hasActiveConnections() const override { return active_connection_count > 0; }\n \n+    void setReplicaInfo(ReplicaInfo value) override { replica_info = value; }\n+\n private:\n     /// If we don't receive data from replica and there is no progress in query\n     /// execution for receive_data_timeout, we are trying to get new\n@@ -199,6 +206,8 @@ class HedgedConnections : public IConnections\n     bool sent_query = false;\n     bool cancelled = false;\n \n+    ReplicaInfo replica_info;\n+\n     mutable std::mutex cancel_mutex;\n };\n \ndiff --git a/src/Client/IConnections.h b/src/Client/IConnections.h\nindex 53267cbbb3e3..8dbd58c9598c 100644\n--- a/src/Client/IConnections.h\n+++ b/src/Client/IConnections.h\n@@ -1,6 +1,9 @@\n #pragma once\n \n+#include <compare>\n+\n #include <Client/Connection.h>\n+#include <Storages/MergeTree/RequestResponse.h>\n \n namespace DB\n {\n@@ -27,10 +30,11 @@ class IConnections : boost::noncopyable\n         const String & query,\n         const String & query_id,\n         UInt64 stage,\n-        const ClientInfo & client_info,\n+        ClientInfo & client_info,\n         bool with_pending_data) = 0;\n \n     virtual void sendReadTaskResponse(const String &) = 0;\n+    virtual void sendMergeTreeReadTaskResponse(PartitionReadResponse response) = 0;\n \n     /// Get packet from any replica.\n     virtual Packet receivePacket() = 0;\n@@ -56,6 +60,17 @@ class IConnections : boost::noncopyable\n     /// Get the replica addresses as a string.\n     virtual std::string dumpAddresses() const = 0;\n \n+\n+    struct ReplicaInfo\n+    {\n+        size_t all_replicas_count{0};\n+        size_t number_of_current_replica{0};\n+    };\n+\n+    /// This is needed in max_parallel_replicas case.\n+    /// We create a RemoteQueryExecutor for each replica\n+    virtual void setReplicaInfo(ReplicaInfo value) = 0;\n+\n     /// Returns the number of replicas.\n     virtual size_t size() const = 0;\n \ndiff --git a/src/Client/IServerConnection.h b/src/Client/IServerConnection.h\nindex 9d6b54ef32fa..b7c6ae314e26 100644\n--- a/src/Client/IServerConnection.h\n+++ b/src/Client/IServerConnection.h\n@@ -12,6 +12,8 @@\n #include <IO/ConnectionTimeouts.h>\n #include <IO/Progress.h>\n \n+#include <Storages/MergeTree/RequestResponse.h>\n+\n \n #include <boost/noncopyable.hpp>\n \n@@ -32,10 +34,13 @@ struct Packet\n     Progress progress;\n     ProfileInfo profile_info;\n     std::vector<UUID> part_uuids;\n+    PartitionReadRequest request;\n+    PartitionReadResponse response;\n \n     Packet() : type(Protocol::Server::Hello) {}\n };\n \n+\n /// Struct which represents data we are going to send for external table.\n struct ExternalTableData\n {\n@@ -96,6 +101,8 @@ class IServerConnection : boost::noncopyable\n     /// Send all contents of external (temporary) tables.\n     virtual void sendExternalTablesData(ExternalTablesData & data) = 0;\n \n+    virtual void sendMergeTreeReadTaskResponse(const PartitionReadResponse & response) = 0;\n+\n     /// Check, if has data to read.\n     virtual bool poll(size_t timeout_microseconds) = 0;\n \ndiff --git a/src/Client/LocalConnection.cpp b/src/Client/LocalConnection.cpp\nindex 4f476b57c270..9eaa9ce883a1 100644\n--- a/src/Client/LocalConnection.cpp\n+++ b/src/Client/LocalConnection.cpp\n@@ -424,6 +424,11 @@ void LocalConnection::sendExternalTablesData(ExternalTablesData &)\n     throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Not implemented\");\n }\n \n+void LocalConnection::sendMergeTreeReadTaskResponse(const PartitionReadResponse &)\n+{\n+    throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Not implemented\");\n+}\n+\n ServerConnectionPtr LocalConnection::createConnection(const ConnectionParameters &, ContextPtr current_context, bool send_progress)\n {\n     return std::make_unique<LocalConnection>(current_context, send_progress);\ndiff --git a/src/Client/LocalConnection.h b/src/Client/LocalConnection.h\nindex 1cc23defa6e1..fbd054506e70 100644\n--- a/src/Client/LocalConnection.h\n+++ b/src/Client/LocalConnection.h\n@@ -92,6 +92,8 @@ class LocalConnection : public IServerConnection, WithContext\n \n     void sendExternalTablesData(ExternalTablesData &) override;\n \n+    void sendMergeTreeReadTaskResponse(const PartitionReadResponse & response) override;\n+\n     bool poll(size_t timeout_microseconds/* = 0 */) override;\n \n     bool hasReadPendingData() const override;\ndiff --git a/src/Client/MultiplexedConnections.cpp b/src/Client/MultiplexedConnections.cpp\nindex a27f77095556..c3000443a9c6 100644\n--- a/src/Client/MultiplexedConnections.cpp\n+++ b/src/Client/MultiplexedConnections.cpp\n@@ -1,9 +1,10 @@\n #include <Client/MultiplexedConnections.h>\n+\n+#include <Common/thread_local_rng.h>\n+#include <Core/Protocol.h>\n #include <IO/ConnectionTimeouts.h>\n #include <IO/Operators.h>\n-#include <Common/thread_local_rng.h>\n-#include \"Core/Protocol.h\"\n-\n+#include <Interpreters/ClientInfo.h>\n \n namespace DB\n {\n@@ -110,7 +111,7 @@ void MultiplexedConnections::sendQuery(\n     const String & query,\n     const String & query_id,\n     UInt64 stage,\n-    const ClientInfo & client_info,\n+    ClientInfo & client_info,\n     bool with_pending_data)\n {\n     std::lock_guard lock(cancel_mutex);\n@@ -131,16 +132,29 @@ void MultiplexedConnections::sendQuery(\n             modified_settings.group_by_two_level_threshold = 0;\n             modified_settings.group_by_two_level_threshold_bytes = 0;\n         }\n+\n+        if (settings.allow_experimental_parallel_reading_from_replicas)\n+        {\n+            client_info.collaborate_with_initiator = true;\n+            client_info.count_participating_replicas = replica_info.all_replicas_count;\n+            client_info.number_of_current_replica = replica_info.number_of_current_replica;\n+        }\n     }\n \n+    const bool enable_sample_offset_parallel_processing = settings.max_parallel_replicas > 1 && !settings.allow_experimental_parallel_reading_from_replicas;\n+\n     size_t num_replicas = replica_states.size();\n     if (num_replicas > 1)\n     {\n-        /// Use multiple replicas for parallel query processing.\n-        modified_settings.parallel_replicas_count = num_replicas;\n+        if (enable_sample_offset_parallel_processing)\n+            /// Use multiple replicas for parallel query processing.\n+            modified_settings.parallel_replicas_count = num_replicas;\n+\n         for (size_t i = 0; i < num_replicas; ++i)\n         {\n-            modified_settings.parallel_replica_offset = i;\n+            if (enable_sample_offset_parallel_processing)\n+                modified_settings.parallel_replica_offset = i;\n+\n             replica_states[i].connection->sendQuery(timeouts, query, query_id,\n                 stage, &modified_settings, &client_info, with_pending_data);\n         }\n@@ -179,6 +193,16 @@ void MultiplexedConnections::sendReadTaskResponse(const String & response)\n     current_connection->sendReadTaskResponse(response);\n }\n \n+\n+void MultiplexedConnections::sendMergeTreeReadTaskResponse(PartitionReadResponse response)\n+{\n+    std::lock_guard lock(cancel_mutex);\n+    if (cancelled)\n+        return;\n+    current_connection->sendMergeTreeReadTaskResponse(response);\n+}\n+\n+\n Packet MultiplexedConnections::receivePacket()\n {\n     std::lock_guard lock(cancel_mutex);\n@@ -234,6 +258,7 @@ Packet MultiplexedConnections::drain()\n \n         switch (packet.type)\n         {\n+            case Protocol::Server::MergeTreeReadTaskRequest:\n             case Protocol::Server::ReadTaskRequest:\n             case Protocol::Server::PartUUIDs:\n             case Protocol::Server::Data:\n@@ -313,6 +338,7 @@ Packet MultiplexedConnections::receivePacketUnlocked(AsyncCallback async_callbac\n \n     switch (packet.type)\n     {\n+        case Protocol::Server::MergeTreeReadTaskRequest:\n         case Protocol::Server::ReadTaskRequest:\n         case Protocol::Server::PartUUIDs:\n         case Protocol::Server::Data:\ndiff --git a/src/Client/MultiplexedConnections.h b/src/Client/MultiplexedConnections.h\nindex 4fb7d496b0c5..e76d54218c71 100644\n--- a/src/Client/MultiplexedConnections.h\n+++ b/src/Client/MultiplexedConnections.h\n@@ -38,10 +38,11 @@ class MultiplexedConnections final : public IConnections\n         const String & query,\n         const String & query_id,\n         UInt64 stage,\n-        const ClientInfo & client_info,\n+        ClientInfo & client_info,\n         bool with_pending_data) override;\n \n     void sendReadTaskResponse(const String &) override;\n+    void sendMergeTreeReadTaskResponse(PartitionReadResponse response) override;\n \n     Packet receivePacket() override;\n \n@@ -62,6 +63,7 @@ class MultiplexedConnections final : public IConnections\n     /// Without locking, because sendCancel() does not change the state of the replicas.\n     bool hasActiveConnections() const override { return active_connection_count > 0; }\n \n+    void setReplicaInfo(ReplicaInfo value) override { replica_info = value; }\n private:\n     Packet receivePacketUnlocked(AsyncCallback async_callback, bool is_draining) override;\n \n@@ -102,6 +104,8 @@ class MultiplexedConnections final : public IConnections\n     bool sent_query = false;\n     bool cancelled = false;\n \n+    ReplicaInfo replica_info;\n+\n     /// A mutex for the sendCancel function to execute safely\n     /// in separate thread.\n     mutable std::mutex cancel_mutex;\ndiff --git a/src/Common/PoolBase.h b/src/Common/PoolBase.h\nindex 3f7f340c5d1a..85d4e84abcab 100644\n--- a/src/Common/PoolBase.h\n+++ b/src/Common/PoolBase.h\n@@ -163,4 +163,3 @@ class PoolBase : private boost::noncopyable\n     /** Creates a new object to put into the pool. */\n     virtual ObjectPtr allocObject() = 0;\n };\n-\ndiff --git a/src/Core/Protocol.h b/src/Core/Protocol.h\nindex fb18e1135a51..08c675eb4219 100644\n--- a/src/Core/Protocol.h\n+++ b/src/Core/Protocol.h\n@@ -64,24 +64,26 @@ namespace Protocol\n     {\n         enum Enum\n         {\n-            Hello = 0,                /// Name, version, revision.\n-            Data = 1,                 /// A block of data (compressed or not).\n-            Exception = 2,            /// The exception during query execution.\n-            Progress = 3,             /// Query execution progress: rows read, bytes read.\n-            Pong = 4,                 /// Ping response\n-            EndOfStream = 5,          /// All packets were transmitted\n-            ProfileInfo = 6,          /// Packet with profiling info.\n-            Totals = 7,               /// A block with totals (compressed or not).\n-            Extremes = 8,             /// A block with minimums and maximums (compressed or not).\n-            TablesStatusResponse = 9, /// A response to TablesStatus request.\n-            Log = 10,                 /// System logs of the query execution\n-            TableColumns = 11,        /// Columns' description for default values calculation\n-            PartUUIDs = 12,           /// List of unique parts ids.\n-            ReadTaskRequest = 13,     /// String (UUID) describes a request for which next task is needed\n-                                      /// This is such an inverted logic, where server sends requests\n-                                      /// And client returns back response\n-            ProfileEvents = 14,       /// Packet with profile events from server.\n-            MAX = ProfileEvents,\n+            Hello = 0,                      /// Name, version, revision.\n+            Data = 1,                       /// A block of data (compressed or not).\n+            Exception = 2,                  /// The exception during query execution.\n+            Progress = 3,                   /// Query execution progress: rows read, bytes read.\n+            Pong = 4,                       /// Ping response\n+            EndOfStream = 5,                /// All packets were transmitted\n+            ProfileInfo = 6,                /// Packet with profiling info.\n+            Totals = 7,                     /// A block with totals (compressed or not).\n+            Extremes = 8,                   /// A block with minimums and maximums (compressed or not).\n+            TablesStatusResponse = 9,       /// A response to TablesStatus request.\n+            Log = 10,                       /// System logs of the query execution\n+            TableColumns = 11,              /// Columns' description for default values calculation\n+            PartUUIDs = 12,                 /// List of unique parts ids.\n+            ReadTaskRequest = 13,           /// String (UUID) describes a request for which next task is needed\n+                                            /// This is such an inverted logic, where server sends requests\n+                                            /// And client returns back response\n+            ProfileEvents = 14,             /// Packet with profile events from server.\n+            MergeTreeReadTaskRequest = 15,  /// Request from a MergeTree replica to a coordinator\n+            MAX = MergeTreeReadTaskRequest,\n+\n         };\n \n         /// NOTE: If the type of packet argument would be Enum, the comparison packet >= 0 && packet < 10\n@@ -106,6 +108,7 @@ namespace Protocol\n                 \"PartUUIDs\",\n                 \"ReadTaskRequest\",\n                 \"ProfileEvents\",\n+                \"MergeTreeReadTaskRequest\",\n             };\n             return packet <= MAX\n                 ? data[packet]\n@@ -130,20 +133,20 @@ namespace Protocol\n     {\n         enum Enum\n         {\n-            Hello = 0,               /// Name, version, revision, default DB\n-            Query = 1,               /// Query id, query settings, stage up to which the query must be executed,\n-                                     /// whether the compression must be used,\n-                                     /// query text (without data for INSERTs).\n-            Data = 2,                /// A block of data (compressed or not).\n-            Cancel = 3,              /// Cancel the query execution.\n-            Ping = 4,                /// Check that connection to the server is alive.\n-            TablesStatusRequest = 5, /// Check status of tables on the server.\n-            KeepAlive = 6,           /// Keep the connection alive\n-            Scalar = 7,              /// A block of data (compressed or not).\n-            IgnoredPartUUIDs = 8,    /// List of unique parts ids to exclude from query processing\n-            ReadTaskResponse = 9,     /// TODO:\n-\n-            MAX = ReadTaskResponse,\n+            Hello = 0,                      /// Name, version, revision, default DB\n+            Query = 1,                      /// Query id, query settings, stage up to which the query must be executed,\n+                                            /// whether the compression must be used,\n+                                            /// query text (without data for INSERTs).\n+            Data = 2,                       /// A block of data (compressed or not).\n+            Cancel = 3,                     /// Cancel the query execution.\n+            Ping = 4,                       /// Check that connection to the server is alive.\n+            TablesStatusRequest = 5,        /// Check status of tables on the server.\n+            KeepAlive = 6,                  /// Keep the connection alive\n+            Scalar = 7,                     /// A block of data (compressed or not).\n+            IgnoredPartUUIDs = 8,           /// List of unique parts ids to exclude from query processing\n+            ReadTaskResponse = 9,           /// A filename to read from s3 (used in s3Cluster)\n+            MergeTreeReadTaskResponse = 10, /// Coordinator's decision with a modified set of mark ranges allowed to read\n+            MAX = MergeTreeReadTaskResponse,\n         };\n \n         inline const char * toString(UInt64 packet)\n@@ -159,6 +162,7 @@ namespace Protocol\n                 \"Scalar\",\n                 \"IgnoredPartUUIDs\",\n                 \"ReadTaskResponse\",\n+                \"MergeTreeReadTaskResponse\"\n             };\n             return packet <= MAX\n                 ? data[packet]\ndiff --git a/src/Core/ProtocolDefines.h b/src/Core/ProtocolDefines.h\nindex ac0fba384b86..36820788b91f 100644\n--- a/src/Core/ProtocolDefines.h\n+++ b/src/Core/ProtocolDefines.h\n@@ -31,6 +31,9 @@\n \n #define DBMS_CLUSTER_PROCESSING_PROTOCOL_VERSION 1\n \n+#define DBMS_PARALLEL_REPLICAS_PROTOCOL_VERSION 1\n+#define DBMS_MIN_REVISION_WITH_PARALLEL_REPLICAS 54453\n+\n /// Minimum revision supporting interserver secret.\n #define DBMS_MIN_REVISION_WITH_INTERSERVER_SECRET 54441\n \n@@ -48,6 +51,7 @@\n /// NOTE: DBMS_TCP_PROTOCOL_VERSION has nothing common with VERSION_REVISION,\n /// later is just a number for server version (one number instead of commit SHA)\n /// for simplicity (sometimes it may be more convenient in some use cases).\n-#define DBMS_TCP_PROTOCOL_VERSION 54452\n+\n+#define DBMS_TCP_PROTOCOL_VERSION 54453\n \n #define DBMS_MIN_PROTOCOL_VERSION_WITH_INITIAL_QUERY_START_TIME 54449\ndiff --git a/src/Core/Settings.h b/src/Core/Settings.h\nindex 4e0e50cc5218..47b01655c264 100644\n--- a/src/Core/Settings.h\n+++ b/src/Core/Settings.h\n@@ -126,6 +126,8 @@ class IColumn;\n     M(UInt64, parallel_replicas_count, 0, \"\", 0) \\\n     M(UInt64, parallel_replica_offset, 0, \"\", 0) \\\n     \\\n+    M(Bool, allow_experimental_parallel_reading_from_replicas, false, \"If true, ClickHouse will send a SELECT query to all replicas of a table. It will work for any kind on MergeTree table.\", 0) \\\n+    \\\n     M(Bool, skip_unavailable_shards, false, \"If true, ClickHouse silently skips unavailable shards and nodes unresolvable through DNS. Shard is marked as unavailable when none of the replicas can be reached.\", 0) \\\n     \\\n     M(UInt64, parallel_distributed_insert_select, 0, \"Process distributed INSERT SELECT query in the same cluster on local tables on every shard, if 1 SELECT is executed on each shard, if 2 SELECT and INSERT is executed on each shard\", 0) \\\ndiff --git a/src/IO/WriteHelpers.h b/src/IO/WriteHelpers.h\nindex 9cdc77df957c..5498e1c90f39 100644\n--- a/src/IO/WriteHelpers.h\n+++ b/src/IO/WriteHelpers.h\n@@ -118,6 +118,7 @@ inline void writeStringBinary(const std::string_view & s, WriteBuffer & buf)\n     writeStringBinary(StringRef{s}, buf);\n }\n \n+\n template <typename T>\n void writeVectorBinary(const std::vector<T> & v, WriteBuffer & buf)\n {\ndiff --git a/src/Interpreters/ClientInfo.cpp b/src/Interpreters/ClientInfo.cpp\nindex 79956aaebed7..827e7d274092 100644\n--- a/src/Interpreters/ClientInfo.cpp\n+++ b/src/Interpreters/ClientInfo.cpp\n@@ -89,6 +89,13 @@ void ClientInfo::write(WriteBuffer & out, const UInt64 server_protocol_revision)\n             writeBinary(uint8_t(0), out);\n         }\n     }\n+\n+    if (server_protocol_revision >= DBMS_MIN_REVISION_WITH_PARALLEL_REPLICAS)\n+    {\n+        writeVarUInt(static_cast<UInt64>(collaborate_with_initiator), out);\n+        writeVarUInt(count_participating_replicas, out);\n+        writeVarUInt(number_of_current_replica, out);\n+    }\n }\n \n \n@@ -170,6 +177,15 @@ void ClientInfo::read(ReadBuffer & in, const UInt64 client_protocol_revision)\n             readBinary(client_trace_context.trace_flags, in);\n         }\n     }\n+\n+    if (client_protocol_revision >= DBMS_MIN_REVISION_WITH_PARALLEL_REPLICAS)\n+    {\n+        UInt64 value;\n+        readVarUInt(value, in);\n+        collaborate_with_initiator = static_cast<bool>(value);\n+        readVarUInt(count_participating_replicas, in);\n+        readVarUInt(number_of_current_replica, in);\n+    }\n }\n \n \ndiff --git a/src/Interpreters/ClientInfo.h b/src/Interpreters/ClientInfo.h\nindex d42c34f07e2e..3ce740c64368 100644\n--- a/src/Interpreters/ClientInfo.h\n+++ b/src/Interpreters/ClientInfo.h\n@@ -108,6 +108,11 @@ class ClientInfo\n \n     bool is_replicated_database_internal = false;\n \n+    /// For parallel processing on replicas\n+    bool collaborate_with_initiator{false};\n+    UInt64 count_participating_replicas{0};\n+    UInt64 number_of_current_replica{0};\n+\n     bool empty() const { return query_kind == QueryKind::NO_QUERY; }\n \n     /** Serialization and deserialization.\ndiff --git a/src/Interpreters/Cluster.h b/src/Interpreters/Cluster.h\nindex ec78abf574c7..a64e17264b11 100644\n--- a/src/Interpreters/Cluster.h\n+++ b/src/Interpreters/Cluster.h\n@@ -184,6 +184,8 @@ class Cluster\n         bool isLocal() const { return !local_addresses.empty(); }\n         bool hasRemoteConnections() const { return local_addresses.size() != per_replica_pools.size(); }\n         size_t getLocalNodeCount() const { return local_addresses.size(); }\n+        size_t getRemoteNodeCount() const { return per_replica_pools.size() - local_addresses.size(); }\n+        size_t getAllNodeCount() const { return per_replica_pools.size(); }\n         bool hasInternalReplication() const { return has_internal_replication; }\n         /// Name of directory for asynchronous write to StorageDistributed if has_internal_replication\n         const std::string & insertPathForInternalReplication(bool prefer_localhost_replica, bool use_compact_format) const;\ndiff --git a/src/Interpreters/ClusterProxy/IStreamFactory.h b/src/Interpreters/ClusterProxy/IStreamFactory.h\nindex 6360aee2f55b..483ce9dcab90 100644\n--- a/src/Interpreters/ClusterProxy/IStreamFactory.h\n+++ b/src/Interpreters/ClusterProxy/IStreamFactory.h\n@@ -37,7 +37,9 @@ class IStreamFactory\n         Block header;\n \n         size_t shard_num = 0;\n+        size_t num_replicas = 0;\n         ConnectionPoolWithFailoverPtr pool;\n+        ConnectionPoolPtrs per_replica_pools;\n \n         /// If we connect to replicas lazily.\n         /// (When there is a local replica with big delay).\ndiff --git a/src/Interpreters/ClusterProxy/SelectStreamFactory.cpp b/src/Interpreters/ClusterProxy/SelectStreamFactory.cpp\nindex b644f2936d9e..a47874c475a9 100644\n--- a/src/Interpreters/ClusterProxy/SelectStreamFactory.cpp\n+++ b/src/Interpreters/ClusterProxy/SelectStreamFactory.cpp\n@@ -117,7 +117,9 @@ void SelectStreamFactory::createForShard(\n             .query = modified_query_ast,\n             .header = header,\n             .shard_num = shard_info.shard_num,\n+            .num_replicas = shard_info.getAllNodeCount(),\n             .pool = shard_info.pool,\n+            .per_replica_pools = shard_info.per_replica_pools,\n             .lazy = lazy,\n             .local_delay = local_delay,\n         });\ndiff --git a/src/Interpreters/Context.cpp b/src/Interpreters/Context.cpp\nindex 9b2721cd15d4..db1d6a378779 100644\n--- a/src/Interpreters/Context.cpp\n+++ b/src/Interpreters/Context.cpp\n@@ -2962,7 +2962,7 @@ PartUUIDsPtr Context::getPartUUIDs() const\n ReadTaskCallback Context::getReadTaskCallback() const\n {\n     if (!next_task_callback.has_value())\n-        throw Exception(fmt::format(\"Next task callback is not set for query {}\", getInitialQueryId()), ErrorCodes::LOGICAL_ERROR);\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Next task callback is not set for query {}\", getInitialQueryId());\n     return next_task_callback.value();\n }\n \n@@ -2972,6 +2972,20 @@ void Context::setReadTaskCallback(ReadTaskCallback && callback)\n     next_task_callback = callback;\n }\n \n+\n+MergeTreeReadTaskCallback Context::getMergeTreeReadTaskCallback() const\n+{\n+    if (!merge_tree_read_task_callback.has_value())\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Next task callback for is not set for query {}\", getInitialQueryId());\n+\n+    return merge_tree_read_task_callback.value();\n+}\n+\n+void Context::setMergeTreeReadTaskCallback(MergeTreeReadTaskCallback && callback)\n+{\n+    merge_tree_read_task_callback = callback;\n+}\n+\n PartUUIDsPtr Context::getIgnoredPartUUIDs() const\n {\n     auto lock = getLock();\ndiff --git a/src/Interpreters/Context.h b/src/Interpreters/Context.h\nindex 5948cc7f7a75..823bc028c157 100644\n--- a/src/Interpreters/Context.h\n+++ b/src/Interpreters/Context.h\n@@ -14,6 +14,7 @@\n #include <Common/RemoteHostFilter.h>\n #include <Common/isLocalAddress.h>\n #include <base/types.h>\n+#include <Storages/MergeTree/ParallelReplicasReadingCoordinator.h>\n \n #include \"config_core.h\"\n \n@@ -148,6 +149,8 @@ using InputBlocksReader = std::function<Block(ContextPtr)>;\n /// Used in distributed task processing\n using ReadTaskCallback = std::function<String()>;\n \n+using MergeTreeReadTaskCallback = std::function<std::optional<PartitionReadResponse>(PartitionReadRequest)>;\n+\n /// An empty interface for an arbitrary object that may be attached by a shared pointer\n /// to query context, when using ClickHouse as a library.\n struct IHostContext\n@@ -216,8 +219,12 @@ class Context: public std::enable_shared_from_this<Context>\n     Scalars scalars;\n     Scalars local_scalars;\n \n-    /// Fields for distributed s3 function\n+    /// Used in s3Cluster table function. With this callback, a worker node could ask an initiator\n+    /// about next file to read from s3.\n     std::optional<ReadTaskCallback> next_task_callback;\n+    /// Used in parallel reading from replicas. A replica tells about its intentions to read\n+    /// some ranges from some part and initiator will tell the replica about whether it is accepted or denied.\n+    std::optional<MergeTreeReadTaskCallback> merge_tree_read_task_callback;\n \n     /// Record entities accessed by current query, and store this information in system.query_log.\n     struct QueryAccessInfo\n@@ -865,6 +872,9 @@ class Context: public std::enable_shared_from_this<Context>\n     ReadTaskCallback getReadTaskCallback() const;\n     void setReadTaskCallback(ReadTaskCallback && callback);\n \n+    MergeTreeReadTaskCallback getMergeTreeReadTaskCallback() const;\n+    void setMergeTreeReadTaskCallback(MergeTreeReadTaskCallback && callback);\n+\n     /// Background executors related methods\n     void initializeBackgroundExecutorsIfNeeded();\n \ndiff --git a/src/Processors/QueryPlan/ReadFromMergeTree.cpp b/src/Processors/QueryPlan/ReadFromMergeTree.cpp\nindex 67ca6d3d8e0d..eddbbb9138c0 100644\n--- a/src/Processors/QueryPlan/ReadFromMergeTree.cpp\n+++ b/src/Processors/QueryPlan/ReadFromMergeTree.cpp\n@@ -74,7 +74,8 @@ ReadFromMergeTree::ReadFromMergeTree(\n     bool sample_factor_column_queried_,\n     std::shared_ptr<PartitionIdToMaxBlock> max_block_numbers_to_read_,\n     Poco::Logger * log_,\n-    MergeTreeDataSelectAnalysisResultPtr analyzed_result_ptr_)\n+    MergeTreeDataSelectAnalysisResultPtr analyzed_result_ptr_,\n+    bool enable_parallel_reading)\n     : ISourceStep(DataStream{.header = MergeTreeBaseSelectProcessor::transformHeader(\n         metadata_snapshot_->getSampleBlockForColumns(real_column_names_, data_.getVirtuals(), data_.getStorageID()),\n         getPrewhereInfo(query_info_),\n@@ -107,6 +108,9 @@ ReadFromMergeTree::ReadFromMergeTree(\n         auto type = std::make_shared<DataTypeFloat64>();\n         output_stream->header.insert({type->createColumn(), type, \"_sample_factor\"});\n     }\n+\n+    if (enable_parallel_reading)\n+        read_task_callback = context->getMergeTreeReadTaskCallback();\n }\n \n Pipe ReadFromMergeTree::readFromPool(\n@@ -127,6 +131,7 @@ Pipe ReadFromMergeTree::readFromPool(\n     }\n \n     const auto & settings = context->getSettingsRef();\n+    const auto & client_info = context->getClientInfo();\n     MergeTreeReadPool::BackoffSettings backoff_settings(settings);\n \n     auto pool = std::make_shared<MergeTreeReadPool>(\n@@ -147,17 +152,30 @@ Pipe ReadFromMergeTree::readFromPool(\n \n     for (size_t i = 0; i < max_streams; ++i)\n     {\n+        std::optional<ParallelReadingExtension> extension;\n+        if (read_task_callback)\n+        {\n+            extension = ParallelReadingExtension\n+            {\n+                .callback = read_task_callback.value(),\n+                .count_participating_replicas = client_info.count_participating_replicas,\n+                .number_of_current_replica = client_info.number_of_current_replica,\n+                .colums_to_read = required_columns\n+            };\n+        }\n+\n         auto source = std::make_shared<MergeTreeThreadSelectProcessor>(\n             i, pool, min_marks_for_concurrent_read, max_block_size,\n             settings.preferred_block_size_bytes, settings.preferred_max_column_in_block_size_bytes,\n             data, metadata_snapshot, use_uncompressed_cache,\n-            prewhere_info, actions_settings, reader_settings, virt_column_names);\n+            prewhere_info, actions_settings, reader_settings, virt_column_names, std::move(extension));\n \n-        if (i == 0)\n-        {\n-            /// Set the approximate number of rows for the first source only\n+        /// Set the approximate number of rows for the first source only\n+        /// In case of parallel processing on replicas do not set approximate rows at all.\n+        /// Because the value will be identical on every replicas and will be accounted\n+        /// multiple times (settings.max_parallel_replicas times more)\n+        if (i == 0 && !client_info.collaborate_with_initiator)\n             source->addTotalRowsApprox(total_rows);\n-        }\n \n         pipes.emplace_back(std::move(source));\n     }\n@@ -172,10 +190,22 @@ ProcessorPtr ReadFromMergeTree::createSource(\n     bool use_uncompressed_cache,\n     bool has_limit_below_one_block)\n {\n+    const auto & client_info = context->getClientInfo();\n+    std::optional<ParallelReadingExtension> extension;\n+    if (read_task_callback)\n+    {\n+        extension = ParallelReadingExtension\n+        {\n+            .callback = read_task_callback.value(),\n+            .count_participating_replicas = client_info.count_participating_replicas,\n+            .number_of_current_replica = client_info.number_of_current_replica,\n+            .colums_to_read = required_columns\n+        };\n+    }\n     return std::make_shared<TSource>(\n             data, metadata_snapshot, part.data_part, max_block_size, preferred_block_size_bytes,\n             preferred_max_column_in_block_size_bytes, required_columns, part.ranges, use_uncompressed_cache, prewhere_info,\n-            actions_settings, reader_settings, virt_column_names, part.part_index_in_query, has_limit_below_one_block);\n+            actions_settings, reader_settings, virt_column_names, part.part_index_in_query, has_limit_below_one_block, std::move(extension));\n }\n \n Pipe ReadFromMergeTree::readInOrder(\ndiff --git a/src/Processors/QueryPlan/ReadFromMergeTree.h b/src/Processors/QueryPlan/ReadFromMergeTree.h\nindex 46b62467ae03..0bdfa66bcc7a 100644\n--- a/src/Processors/QueryPlan/ReadFromMergeTree.h\n+++ b/src/Processors/QueryPlan/ReadFromMergeTree.h\n@@ -97,7 +97,8 @@ class ReadFromMergeTree final : public ISourceStep\n         bool sample_factor_column_queried_,\n         std::shared_ptr<PartitionIdToMaxBlock> max_block_numbers_to_read_,\n         Poco::Logger * log_,\n-        MergeTreeDataSelectAnalysisResultPtr analyzed_result_ptr_\n+        MergeTreeDataSelectAnalysisResultPtr analyzed_result_ptr_,\n+        bool enable_parallel_reading\n     );\n \n     String getName() const override { return \"ReadFromMergeTree\"; }\n@@ -184,6 +185,8 @@ class ReadFromMergeTree final : public ISourceStep\n     MergeTreeDataSelectAnalysisResultPtr selectRangesToRead(MergeTreeData::DataPartsVector parts) const;\n     ReadFromMergeTree::AnalysisResult getAnalysisResult() const;\n     MergeTreeDataSelectAnalysisResultPtr analyzed_result_ptr;\n+\n+    std::optional<MergeTreeReadTaskCallback> read_task_callback;\n };\n \n struct MergeTreeDataSelectAnalysisResult\ndiff --git a/src/Processors/QueryPlan/ReadFromRemote.cpp b/src/Processors/QueryPlan/ReadFromRemote.cpp\nindex 399e7d018390..8fcec03d746c 100644\n--- a/src/Processors/QueryPlan/ReadFromRemote.cpp\n+++ b/src/Processors/QueryPlan/ReadFromRemote.cpp\n@@ -12,6 +12,8 @@\n #include <Interpreters/InterpreterSelectQuery.h>\n #include <IO/ConnectionTimeoutsContext.h>\n #include <Common/checkStackSize.h>\n+#include <Client/ConnectionPool.h>\n+#include <Client/ConnectionPoolWithFailover.h>\n \n namespace DB\n {\n@@ -112,7 +114,10 @@ ReadFromRemote::ReadFromRemote(\n {\n }\n \n-void ReadFromRemote::addLazyPipe(Pipes & pipes, const ClusterProxy::IStreamFactory::Shard & shard)\n+void ReadFromRemote::addLazyPipe(Pipes & pipes, const ClusterProxy::IStreamFactory::Shard & shard,\n+    std::shared_ptr<ParallelReplicasReadingCoordinator> coordinator,\n+    std::shared_ptr<ConnectionPoolWithFailover> pool,\n+    std::optional<IConnections::ReplicaInfo> replica_info)\n {\n     bool add_agg_info = stage == QueryProcessingStage::WithMergeableState;\n     bool add_totals = false;\n@@ -125,7 +130,10 @@ void ReadFromRemote::addLazyPipe(Pipes & pipes, const ClusterProxy::IStreamFacto\n     }\n \n     auto lazily_create_stream = [\n-            pool = shard.pool, shard_num = shard.shard_num, shard_count = shard_count, query = shard.query, header = shard.header,\n+            replica_info = replica_info,\n+            pool = pool ? pool : shard.pool,\n+            coordinator = coordinator,\n+            shard_num = shard.shard_num, shard_count = shard_count, query = shard.query, header = shard.header,\n             context = context, throttler = throttler,\n             main_table = main_table, table_func_ptr = table_func_ptr,\n             scalars = scalars, external_tables = external_tables,\n@@ -161,9 +169,12 @@ void ReadFromRemote::addLazyPipe(Pipes & pipes, const ClusterProxy::IStreamFacto\n                 max_remote_delay = std::max(try_result.staleness, max_remote_delay);\n         }\n \n-        if (try_results.empty() || local_delay < max_remote_delay)\n+        /// We disable this branch in case of parallel reading from replicas, because createLocalPlan will call\n+        /// InterpreterSelectQuery directly and it will be too ugly to pass ParallelReplicasCoordinator or some callback there.\n+        if (!context->getClientInfo().collaborate_with_initiator && (try_results.empty() || local_delay < max_remote_delay))\n         {\n             auto plan = createLocalPlan(query, header, context, stage, shard_num, shard_count);\n+\n             return QueryPipelineBuilder::getPipe(std::move(*plan->buildQueryPipeline(\n                 QueryPlanOptimizationSettings::fromContext(context),\n                 BuildQueryPipelineSettings::fromContext(context))));\n@@ -180,7 +191,8 @@ void ReadFromRemote::addLazyPipe(Pipes & pipes, const ClusterProxy::IStreamFacto\n             scalars[\"_shard_num\"]\n                 = Block{{DataTypeUInt32().createColumnConst(1, shard_num), std::make_shared<DataTypeUInt32>(), \"_shard_num\"}};\n             auto remote_query_executor = std::make_shared<RemoteQueryExecutor>(\n-                pool, std::move(connections), query_string, header, context, throttler, scalars, external_tables, stage);\n+                pool, std::move(connections), query_string, header, context, throttler, scalars, external_tables, stage,\n+                RemoteQueryExecutor::Extension{.parallel_reading_coordinator = std::move(coordinator), .replica_info = replica_info});\n \n             return createRemoteSourcePipe(remote_query_executor, add_agg_info, add_totals, add_extremes, async_read);\n         }\n@@ -191,7 +203,10 @@ void ReadFromRemote::addLazyPipe(Pipes & pipes, const ClusterProxy::IStreamFacto\n     addConvertingActions(pipes.back(), output_stream->header);\n }\n \n-void ReadFromRemote::addPipe(Pipes & pipes, const ClusterProxy::IStreamFactory::Shard & shard)\n+void ReadFromRemote::addPipe(Pipes & pipes, const ClusterProxy::IStreamFactory::Shard & shard,\n+    std::shared_ptr<ParallelReplicasReadingCoordinator> coordinator,\n+    std::shared_ptr<ConnectionPoolWithFailover> pool,\n+    std::optional<IConnections::ReplicaInfo> replica_info)\n {\n     bool add_agg_info = stage == QueryProcessingStage::WithMergeableState;\n     bool add_totals = false;\n@@ -207,11 +222,20 @@ void ReadFromRemote::addPipe(Pipes & pipes, const ClusterProxy::IStreamFactory::\n \n     scalars[\"_shard_num\"]\n         = Block{{DataTypeUInt32().createColumnConst(1, shard.shard_num), std::make_shared<DataTypeUInt32>(), \"_shard_num\"}};\n-    auto remote_query_executor = std::make_shared<RemoteQueryExecutor>(\n-        shard.pool, query_string, shard.header, context, throttler, scalars, external_tables, stage);\n+\n+    std::shared_ptr<RemoteQueryExecutor> remote_query_executor;\n+\n+    remote_query_executor = std::make_shared<RemoteQueryExecutor>(\n+            pool ? pool : shard.pool, query_string, shard.header, context, throttler, scalars, external_tables, stage,\n+            RemoteQueryExecutor::Extension{.parallel_reading_coordinator = std::move(coordinator), .replica_info = std::move(replica_info)});\n+\n     remote_query_executor->setLogger(log);\n \n-    remote_query_executor->setPoolMode(PoolMode::GET_MANY);\n+    /// In case of parallel reading from replicas we have a connection pool per replica.\n+    /// Setting PoolMode will make no sense.\n+    if (!pool)\n+        remote_query_executor->setPoolMode(PoolMode::GET_MANY);\n+\n     if (!table_func_ptr)\n         remote_query_executor->setMainTable(main_table);\n \n@@ -223,12 +247,51 @@ void ReadFromRemote::addPipe(Pipes & pipes, const ClusterProxy::IStreamFactory::\n void ReadFromRemote::initializePipeline(QueryPipelineBuilder & pipeline, const BuildQueryPipelineSettings &)\n {\n     Pipes pipes;\n-    for (const auto & shard : shards)\n+\n+    const auto & settings = context->getSettingsRef();\n+    const bool enable_sample_offset_parallel_processing = settings.max_parallel_replicas > 1 && !settings.allow_experimental_parallel_reading_from_replicas;\n+\n+    /// We have to create a pipe for each replica\n+    /// FIXME: The second condition is only for tests to work, because hedged connections enabled by default.\n+    if (settings.max_parallel_replicas > 1 && !enable_sample_offset_parallel_processing && !context->getSettingsRef().use_hedged_requests)\n     {\n-        if (shard.lazy)\n-            addLazyPipe(pipes, shard);\n-        else\n-            addPipe(pipes, shard);\n+        const Settings & current_settings = context->getSettingsRef();\n+        auto timeouts = ConnectionTimeouts::getTCPTimeoutsWithFailover(current_settings);\n+\n+        for (const auto & shard : shards)\n+        {\n+            auto coordinator = std::make_shared<ParallelReplicasReadingCoordinator>();\n+\n+            for (size_t replica_num = 0; replica_num < shard.num_replicas; ++replica_num)\n+            {\n+                IConnections::ReplicaInfo replica_info\n+                {\n+                    .all_replicas_count = shard.num_replicas,\n+                    .number_of_current_replica = replica_num\n+                };\n+\n+                auto pool = shard.per_replica_pools[replica_num];\n+                auto pool_with_failover =  std::make_shared<ConnectionPoolWithFailover>(\n+                    ConnectionPoolPtrs{pool}, current_settings.load_balancing);\n+\n+                if (shard.lazy)\n+                    addLazyPipe(pipes, shard, coordinator, pool_with_failover, replica_info);\n+                else\n+                    addPipe(pipes, shard, coordinator, pool_with_failover, replica_info);\n+            }\n+        }\n+    }\n+    else\n+    {\n+        for (const auto & shard : shards)\n+        {\n+            auto coordinator = std::make_shared<ParallelReplicasReadingCoordinator>();\n+\n+            if (shard.lazy)\n+                addLazyPipe(pipes, shard, /*coordinator=*/nullptr, /*pool*/{}, /*replica_info*/std::nullopt);\n+            else\n+                addPipe(pipes, shard, /*coordinator=*/nullptr, /*pool*/{}, /*replica_info*/std::nullopt);\n+        }\n     }\n \n     auto pipe = Pipe::unitePipes(std::move(pipes));\ndiff --git a/src/Processors/QueryPlan/ReadFromRemote.h b/src/Processors/QueryPlan/ReadFromRemote.h\nindex f963164dd3f7..f361be93b5a7 100644\n--- a/src/Processors/QueryPlan/ReadFromRemote.h\n+++ b/src/Processors/QueryPlan/ReadFromRemote.h\n@@ -1,9 +1,11 @@\n #pragma once\n #include <Processors/QueryPlan/ISourceStep.h>\n #include <Core/QueryProcessingStage.h>\n+#include <Client/IConnections.h>\n #include <Storages/IStorage_fwd.h>\n #include <Interpreters/StorageID.h>\n #include <Interpreters/ClusterProxy/IStreamFactory.h>\n+#include <Storages/MergeTree/ParallelReplicasReadingCoordinator.h>\n \n namespace DB\n {\n@@ -37,6 +39,12 @@ class ReadFromRemote final : public ISourceStep\n     void initializePipeline(QueryPipelineBuilder & pipeline, const BuildQueryPipelineSettings &) override;\n \n private:\n+    enum class Mode\n+    {\n+        PerReplica,\n+        PerShard\n+    };\n+\n     ClusterProxy::IStreamFactory::Shards shards;\n     QueryProcessingStage::Enum stage;\n \n@@ -52,8 +60,16 @@ class ReadFromRemote final : public ISourceStep\n     Poco::Logger * log;\n \n     UInt32 shard_count;\n-    void addLazyPipe(Pipes & pipes, const ClusterProxy::IStreamFactory::Shard & shard);\n-    void addPipe(Pipes & pipes, const ClusterProxy::IStreamFactory::Shard & shard);\n+    void addLazyPipe(Pipes & pipes, const ClusterProxy::IStreamFactory::Shard & shard,\n+        std::shared_ptr<ParallelReplicasReadingCoordinator> coordinator,\n+        std::shared_ptr<ConnectionPoolWithFailover> pool,\n+        std::optional<IConnections::ReplicaInfo> replica_info);\n+    void addPipe(Pipes & pipes, const ClusterProxy::IStreamFactory::Shard & shard,\n+        std::shared_ptr<ParallelReplicasReadingCoordinator> coordinator,\n+        std::shared_ptr<ConnectionPoolWithFailover> pool,\n+        std::optional<IConnections::ReplicaInfo> replica_info);\n+\n+    void addPipeForReplica();\n };\n \n }\ndiff --git a/src/QueryPipeline/RemoteQueryExecutor.cpp b/src/QueryPipeline/RemoteQueryExecutor.cpp\nindex ada16a1f201b..653d9a2bbf8b 100644\n--- a/src/QueryPipeline/RemoteQueryExecutor.cpp\n+++ b/src/QueryPipeline/RemoteQueryExecutor.cpp\n@@ -7,6 +7,7 @@\n #include <Columns/ColumnConst.h>\n #include <Common/CurrentThread.h>\n #include \"Core/Protocol.h\"\n+#include \"IO/ReadHelpers.h\"\n #include <QueryPipeline/Pipe.h>\n #include <Processors/Sources/SourceFromSingleChunk.h>\n #include <Processors/Transforms/LimitsCheckingTransform.h>\n@@ -20,6 +21,7 @@\n #include <Client/MultiplexedConnections.h>\n #include <Client/HedgedConnections.h>\n #include <Storages/MergeTree/MergeTreeDataPartUUID.h>\n+#include <IO/ReadBufferFromString.h>\n \n \n namespace CurrentMetrics\n@@ -42,21 +44,26 @@ namespace ErrorCodes\n RemoteQueryExecutor::RemoteQueryExecutor(\n     const String & query_, const Block & header_, ContextPtr context_,\n     const Scalars & scalars_, const Tables & external_tables_,\n-    QueryProcessingStage::Enum stage_, std::shared_ptr<TaskIterator> task_iterator_)\n+    QueryProcessingStage::Enum stage_, std::optional<Extension> extension_)\n     : header(header_), query(query_), context(context_), scalars(scalars_)\n-    , external_tables(external_tables_), stage(stage_), task_iterator(task_iterator_)\n+    , external_tables(external_tables_), stage(stage_)\n+    , task_iterator(extension_ ? extension_->task_iterator : nullptr)\n+    , parallel_reading_coordinator(extension_ ? extension_->parallel_reading_coordinator : nullptr)\n {}\n \n RemoteQueryExecutor::RemoteQueryExecutor(\n     Connection & connection,\n     const String & query_, const Block & header_, ContextPtr context_,\n     ThrottlerPtr throttler, const Scalars & scalars_, const Tables & external_tables_,\n-    QueryProcessingStage::Enum stage_, std::shared_ptr<TaskIterator> task_iterator_)\n-    : RemoteQueryExecutor(query_, header_, context_, scalars_, external_tables_, stage_, task_iterator_)\n+    QueryProcessingStage::Enum stage_, std::optional<Extension> extension_)\n+    : RemoteQueryExecutor(query_, header_, context_, scalars_, external_tables_, stage_, extension_)\n {\n-    create_connections = [this, &connection, throttler]()\n+    create_connections = [this, &connection, throttler, extension_]()\n     {\n-        return std::make_shared<MultiplexedConnections>(connection, context->getSettingsRef(), throttler);\n+        auto res = std::make_shared<MultiplexedConnections>(connection, context->getSettingsRef(), throttler);\n+        if (extension_ && extension_->replica_info)\n+            res->setReplicaInfo(*extension_->replica_info);\n+        return res;\n     };\n }\n \n@@ -64,12 +71,15 @@ RemoteQueryExecutor::RemoteQueryExecutor(\n     std::shared_ptr<Connection> connection_ptr,\n     const String & query_, const Block & header_, ContextPtr context_,\n     ThrottlerPtr throttler, const Scalars & scalars_, const Tables & external_tables_,\n-    QueryProcessingStage::Enum stage_, std::shared_ptr<TaskIterator> task_iterator_)\n-    : RemoteQueryExecutor(query_, header_, context_, scalars_, external_tables_, stage_, task_iterator_)\n+    QueryProcessingStage::Enum stage_, std::optional<Extension> extension_)\n+    : RemoteQueryExecutor(query_, header_, context_, scalars_, external_tables_, stage_, extension_)\n {\n-    create_connections = [this, connection_ptr, throttler]()\n+    create_connections = [this, connection_ptr, throttler, extension_]()\n     {\n-        return std::make_shared<MultiplexedConnections>(connection_ptr, context->getSettingsRef(), throttler);\n+        auto res = std::make_shared<MultiplexedConnections>(connection_ptr, context->getSettingsRef(), throttler);\n+        if (extension_ && extension_->replica_info)\n+            res->setReplicaInfo(*extension_->replica_info);\n+        return res;\n     };\n }\n \n@@ -78,12 +88,18 @@ RemoteQueryExecutor::RemoteQueryExecutor(\n     std::vector<IConnectionPool::Entry> && connections_,\n     const String & query_, const Block & header_, ContextPtr context_,\n     const ThrottlerPtr & throttler, const Scalars & scalars_, const Tables & external_tables_,\n-    QueryProcessingStage::Enum stage_, std::shared_ptr<TaskIterator> task_iterator_)\n+    QueryProcessingStage::Enum stage_, std::optional<Extension> extension_)\n     : header(header_), query(query_), context(context_)\n-    , scalars(scalars_), external_tables(external_tables_), stage(stage_), task_iterator(task_iterator_), pool(pool_)\n+    , scalars(scalars_), external_tables(external_tables_), stage(stage_)\n+    , task_iterator(extension_ ? extension_->task_iterator : nullptr)\n+    , parallel_reading_coordinator(extension_ ? extension_->parallel_reading_coordinator : nullptr)\n+    , pool(pool_)\n {\n-    create_connections = [this, connections_, throttler]() mutable {\n-        return std::make_shared<MultiplexedConnections>(std::move(connections_), context->getSettingsRef(), throttler);\n+    create_connections = [this, connections_, throttler, extension_]() mutable {\n+        auto res = std::make_shared<MultiplexedConnections>(std::move(connections_), context->getSettingsRef(), throttler);\n+        if (extension_ && extension_->replica_info)\n+            res->setReplicaInfo(*extension_->replica_info);\n+        return res;\n     };\n }\n \n@@ -91,11 +107,14 @@ RemoteQueryExecutor::RemoteQueryExecutor(\n     const ConnectionPoolWithFailoverPtr & pool_,\n     const String & query_, const Block & header_, ContextPtr context_,\n     const ThrottlerPtr & throttler, const Scalars & scalars_, const Tables & external_tables_,\n-    QueryProcessingStage::Enum stage_, std::shared_ptr<TaskIterator> task_iterator_)\n+    QueryProcessingStage::Enum stage_, std::optional<Extension> extension_)\n     : header(header_), query(query_), context(context_)\n-    , scalars(scalars_), external_tables(external_tables_), stage(stage_), task_iterator(task_iterator_), pool(pool_)\n+    , scalars(scalars_), external_tables(external_tables_), stage(stage_)\n+    , task_iterator(extension_ ? extension_->task_iterator : nullptr)\n+    , parallel_reading_coordinator(extension_ ? extension_->parallel_reading_coordinator : nullptr)\n+    , pool(pool_)\n {\n-    create_connections = [this, throttler]()->std::shared_ptr<IConnections>\n+    create_connections = [this, throttler, extension_]()->std::shared_ptr<IConnections>\n     {\n         const Settings & current_settings = context->getSettingsRef();\n         auto timeouts = ConnectionTimeouts::getTCPTimeoutsWithFailover(current_settings);\n@@ -107,7 +126,10 @@ RemoteQueryExecutor::RemoteQueryExecutor(\n             if (main_table)\n                 table_to_check = std::make_shared<QualifiedTableName>(main_table.getQualifiedName());\n \n-            return std::make_shared<HedgedConnections>(pool, context, timeouts, throttler, pool_mode, table_to_check);\n+            auto res = std::make_shared<HedgedConnections>(pool, context, timeouts, throttler, pool_mode, table_to_check);\n+            if (extension_ && extension_->replica_info)\n+                res->setReplicaInfo(*extension_->replica_info);\n+            return res;\n         }\n #endif\n \n@@ -122,7 +144,10 @@ RemoteQueryExecutor::RemoteQueryExecutor(\n         else\n             connection_entries = pool->getMany(timeouts, &current_settings, pool_mode);\n \n-        return std::make_shared<MultiplexedConnections>(std::move(connection_entries), current_settings, throttler);\n+        auto res = std::make_shared<MultiplexedConnections>(std::move(connection_entries), current_settings, throttler);\n+        if (extension_ && extension_->replica_info)\n+            res->setReplicaInfo(*extension_->replica_info);\n+        return res;\n     };\n }\n \n@@ -344,6 +369,9 @@ std::optional<Block> RemoteQueryExecutor::processPacket(Packet packet)\n {\n     switch (packet.type)\n     {\n+        case Protocol::Server::MergeTreeReadTaskRequest:\n+            processMergeTreeReadTaskRequest(packet.request);\n+            break;\n         case Protocol::Server::ReadTaskRequest:\n             processReadTaskRequest();\n             break;\n@@ -440,6 +468,15 @@ void RemoteQueryExecutor::processReadTaskRequest()\n     connections->sendReadTaskResponse(response);\n }\n \n+void RemoteQueryExecutor::processMergeTreeReadTaskRequest(PartitionReadRequest request)\n+{\n+    if (!parallel_reading_coordinator)\n+        throw Exception(\"Coordinator for parallel reading from replicas is not initialized\", ErrorCodes::LOGICAL_ERROR);\n+\n+    auto response = parallel_reading_coordinator->handleRequest(std::move(request));\n+    connections->sendMergeTreeReadTaskResponse(response);\n+}\n+\n void RemoteQueryExecutor::finish(std::unique_ptr<ReadContext> * read_context)\n {\n     /** If one of:\ndiff --git a/src/QueryPipeline/RemoteQueryExecutor.h b/src/QueryPipeline/RemoteQueryExecutor.h\nindex b7a2509ea978..d5603fd22812 100644\n--- a/src/QueryPipeline/RemoteQueryExecutor.h\n+++ b/src/QueryPipeline/RemoteQueryExecutor.h\n@@ -1,5 +1,7 @@\n #pragma once\n \n+#include <variant>\n+\n #include <Client/ConnectionPool.h>\n #include <Client/IConnections.h>\n #include <Client/ConnectionPoolWithFailover.h>\n@@ -7,7 +9,7 @@\n #include <Interpreters/Context.h>\n #include <Interpreters/StorageID.h>\n #include <Common/TimerDescriptor.h>\n-#include <variant>\n+#include <Storages/MergeTree/ParallelReplicasReadingCoordinator.h>\n \n \n namespace DB\n@@ -35,20 +37,33 @@ class RemoteQueryExecutor\n public:\n     using ReadContext = RemoteQueryExecutorReadContext;\n \n+    /// We can provide additional logic for RemoteQueryExecutor\n+    /// For example for s3Cluster table function we provide an Iterator over tasks to do.\n+    /// Nodes involved into the query send request for a new task and we answer them using this object.\n+    /// In case of parallel reading from replicas we provide a Coordinator object\n+    /// Every replica will tell us about parts and mark ranges it wants to read and coordinator will\n+    /// decide whether to deny or to accept that request.\n+    struct Extension\n+    {\n+      std::shared_ptr<TaskIterator> task_iterator{nullptr};\n+      std::shared_ptr<ParallelReplicasReadingCoordinator> parallel_reading_coordinator;\n+      std::optional<IConnections::ReplicaInfo> replica_info;\n+    };\n+\n     /// Takes already set connection.\n     /// We don't own connection, thus we have to drain it synchronously.\n     RemoteQueryExecutor(\n         Connection & connection,\n         const String & query_, const Block & header_, ContextPtr context_,\n         ThrottlerPtr throttler_ = nullptr, const Scalars & scalars_ = Scalars(), const Tables & external_tables_ = Tables(),\n-        QueryProcessingStage::Enum stage_ = QueryProcessingStage::Complete, std::shared_ptr<TaskIterator> task_iterator_ = {});\n+        QueryProcessingStage::Enum stage_ = QueryProcessingStage::Complete, std::optional<Extension> extension_ = std::nullopt);\n \n     /// Takes already set connection.\n     RemoteQueryExecutor(\n         std::shared_ptr<Connection> connection,\n         const String & query_, const Block & header_, ContextPtr context_,\n         ThrottlerPtr throttler_ = nullptr, const Scalars & scalars_ = Scalars(), const Tables & external_tables_ = Tables(),\n-        QueryProcessingStage::Enum stage_ = QueryProcessingStage::Complete, std::shared_ptr<TaskIterator> task_iterator_ = {});\n+        QueryProcessingStage::Enum stage_ = QueryProcessingStage::Complete, std::optional<Extension> extension_ = std::nullopt);\n \n     /// Accepts several connections already taken from pool.\n     RemoteQueryExecutor(\n@@ -56,14 +71,14 @@ class RemoteQueryExecutor\n         std::vector<IConnectionPool::Entry> && connections_,\n         const String & query_, const Block & header_, ContextPtr context_,\n         const ThrottlerPtr & throttler = nullptr, const Scalars & scalars_ = Scalars(), const Tables & external_tables_ = Tables(),\n-        QueryProcessingStage::Enum stage_ = QueryProcessingStage::Complete, std::shared_ptr<TaskIterator> task_iterator_ = {});\n+        QueryProcessingStage::Enum stage_ = QueryProcessingStage::Complete, std::optional<Extension> extension_ = std::nullopt);\n \n     /// Takes a pool and gets one or several connections from it.\n     RemoteQueryExecutor(\n         const ConnectionPoolWithFailoverPtr & pool,\n         const String & query_, const Block & header_, ContextPtr context_,\n         const ThrottlerPtr & throttler = nullptr, const Scalars & scalars_ = Scalars(), const Tables & external_tables_ = Tables(),\n-        QueryProcessingStage::Enum stage_ = QueryProcessingStage::Complete, std::shared_ptr<TaskIterator> task_iterator_ = {});\n+        QueryProcessingStage::Enum stage_ = QueryProcessingStage::Complete, std::optional<Extension> extension_ = std::nullopt);\n \n     ~RemoteQueryExecutor();\n \n@@ -115,7 +130,7 @@ class RemoteQueryExecutor\n     RemoteQueryExecutor(\n         const String & query_, const Block & header_, ContextPtr context_,\n         const Scalars & scalars_, const Tables & external_tables_,\n-        QueryProcessingStage::Enum stage_, std::shared_ptr<TaskIterator> task_iterator_);\n+        QueryProcessingStage::Enum stage_, std::optional<Extension> extension_);\n \n     Block header;\n     Block totals;\n@@ -136,6 +151,13 @@ class RemoteQueryExecutor\n     /// Initiator identifier for distributed task processing\n     std::shared_ptr<TaskIterator> task_iterator;\n \n+    std::shared_ptr<ParallelReplicasReadingCoordinator> parallel_reading_coordinator;\n+\n+    /// This is needed only for parallel reading from replicas, because\n+    /// we create a RemoteQueryExecutor per replica and have to store additional info\n+    /// about the number of the current replica or the count of replicas at all.\n+    IConnections::ReplicaInfo replica_info;\n+\n     std::function<std::shared_ptr<IConnections>()> create_connections;\n     /// Hold a shared reference to the connection pool so that asynchronous connection draining will\n     /// work safely. Make sure it's the first member so that we don't destruct it too early.\n@@ -203,6 +225,8 @@ class RemoteQueryExecutor\n \n     void processReadTaskRequest();\n \n+    void processMergeTreeReadTaskRequest(PartitionReadRequest request);\n+\n     /// Cancell query and restart it with info about duplicated UUIDs\n     /// only for `allow_experimental_query_deduplication`.\n     std::variant<Block, int> restartQueryWithoutDuplicatedUUIDs(std::unique_ptr<ReadContext> * read_context = nullptr);\ndiff --git a/src/Server/TCPHandler.cpp b/src/Server/TCPHandler.cpp\nindex 32154054cc08..cdf1838c06b4 100644\n--- a/src/Server/TCPHandler.cpp\n+++ b/src/Server/TCPHandler.cpp\n@@ -310,10 +310,25 @@ void TCPHandler::runImpl()\n             query_context->setReadTaskCallback([this]() -> String\n             {\n                 std::lock_guard lock(task_callback_mutex);\n+\n+                if (state.is_cancelled)\n+                    return {};\n+\n                 sendReadTaskRequestAssumeLocked();\n                 return receiveReadTaskResponseAssumeLocked();\n             });\n \n+            query_context->setMergeTreeReadTaskCallback([this](PartitionReadRequest request) -> std::optional<PartitionReadResponse>\n+            {\n+                std::lock_guard lock(task_callback_mutex);\n+\n+                if (state.is_cancelled)\n+                    return std::nullopt;\n+\n+                sendMergeTreeReadTaskRequstAssumeLocked(std::move(request));\n+                return receivePartitionMergeTreeReadTaskResponseAssumeLocked();\n+            });\n+\n             /// Processing Query\n             state.io = executeQuery(state.query, query_context, false, state.stage);\n \n@@ -663,10 +678,13 @@ void TCPHandler::processOrdinaryQueryWithProcessors()\n         Block block;\n         while (executor.pull(block, interactive_delay / 1000))\n         {\n-            std::lock_guard lock(task_callback_mutex);\n+            std::unique_lock lock(task_callback_mutex);\n \n             if (isQueryCancelled())\n             {\n+                /// Several callback like callback for parallel reading could be called from inside the pipeline\n+                /// and we have to unlock the mutex from our side to prevent deadlock.\n+                lock.unlock();\n                 /// A packet was received requesting to stop execution of the request.\n                 executor.cancel();\n                 break;\n@@ -786,6 +804,15 @@ void TCPHandler::sendReadTaskRequestAssumeLocked()\n     out->next();\n }\n \n+\n+void TCPHandler::sendMergeTreeReadTaskRequstAssumeLocked(PartitionReadRequest request)\n+{\n+    writeVarUInt(Protocol::Server::MergeTreeReadTaskRequest, *out);\n+    request.serialize(*out);\n+    out->next();\n+}\n+\n+\n void TCPHandler::sendProfileInfo(const ProfileInfo & info)\n {\n     writeVarUInt(Protocol::Server::ProfileInfo, *out);\n@@ -1297,6 +1324,35 @@ String TCPHandler::receiveReadTaskResponseAssumeLocked()\n }\n \n \n+std::optional<PartitionReadResponse> TCPHandler::receivePartitionMergeTreeReadTaskResponseAssumeLocked()\n+{\n+    UInt64 packet_type = 0;\n+    readVarUInt(packet_type, *in);\n+    if (packet_type != Protocol::Client::MergeTreeReadTaskResponse)\n+    {\n+        if (packet_type == Protocol::Client::Cancel)\n+        {\n+            state.is_cancelled = true;\n+            /// For testing connection collector.\n+            if (sleep_in_receive_cancel.totalMilliseconds())\n+            {\n+                std::chrono::milliseconds ms(sleep_in_receive_cancel.totalMilliseconds());\n+                std::this_thread::sleep_for(ms);\n+            }\n+            return std::nullopt;\n+        }\n+        else\n+        {\n+            throw Exception(fmt::format(\"Received {} packet after requesting read task\",\n+                    Protocol::Client::toString(packet_type)), ErrorCodes::UNEXPECTED_PACKET_FROM_CLIENT);\n+        }\n+    }\n+    PartitionReadResponse response;\n+    response.deserialize(*in);\n+    return response;\n+}\n+\n+\n void TCPHandler::receiveClusterNameAndSalt()\n {\n     readStringBinary(cluster, *in);\n@@ -1697,7 +1753,7 @@ bool TCPHandler::isQueryCancelled()\n                 return true;\n \n             default:\n-                throw NetException(\"Unknown packet from client\", ErrorCodes::UNKNOWN_PACKET_FROM_CLIENT);\n+                throw NetException(\"Unknown packet from client \" + toString(packet_type), ErrorCodes::UNKNOWN_PACKET_FROM_CLIENT);\n         }\n     }\n \ndiff --git a/src/Server/TCPHandler.h b/src/Server/TCPHandler.h\nindex 3cf3346cd720..4a340e328ed5 100644\n--- a/src/Server/TCPHandler.h\n+++ b/src/Server/TCPHandler.h\n@@ -15,6 +15,8 @@\n #include <Interpreters/Context_fwd.h>\n #include <Formats/NativeReader.h>\n \n+#include <Storages/MergeTree/ParallelReplicasReadingCoordinator.h>\n+\n #include \"IServer.h\"\n #include \"base/types.h\"\n \n@@ -201,6 +203,7 @@ class TCPHandler : public Poco::Net::TCPServerConnection\n     void receiveQuery();\n     void receiveIgnoredPartUUIDs();\n     String receiveReadTaskResponseAssumeLocked();\n+    std::optional<PartitionReadResponse> receivePartitionMergeTreeReadTaskResponseAssumeLocked();\n     bool receiveData(bool scalar);\n     bool readDataNext();\n     void readData();\n@@ -233,6 +236,7 @@ class TCPHandler : public Poco::Net::TCPServerConnection\n     void sendEndOfStream();\n     void sendPartUUIDs();\n     void sendReadTaskRequestAssumeLocked();\n+    void sendMergeTreeReadTaskRequstAssumeLocked(PartitionReadRequest request);\n     void sendProfileInfo(const ProfileInfo & info);\n     void sendTotals(const Block & totals);\n     void sendExtremes(const Block & extremes);\ndiff --git a/src/Storages/IStorage.h b/src/Storages/IStorage.h\nindex cf7b075a2047..8432e5c48d16 100644\n--- a/src/Storages/IStorage.h\n+++ b/src/Storages/IStorage.h\n@@ -20,6 +20,7 @@\n \n #include <optional>\n #include <shared_mutex>\n+#include <compare>\n \n \n namespace DB\ndiff --git a/src/Storages/MergeTree/IMergeTreeDataPart.cpp b/src/Storages/MergeTree/IMergeTreeDataPart.cpp\nindex 1255bf975e6a..21dbedbb6ac8 100644\n--- a/src/Storages/MergeTree/IMergeTreeDataPart.cpp\n+++ b/src/Storages/MergeTree/IMergeTreeDataPart.cpp\n@@ -546,7 +546,7 @@ String IMergeTreeDataPart::getColumnNameWithMinimumCompressedSize(const StorageM\n         if (!hasColumnFiles(column))\n             continue;\n \n-        const auto size = getColumnSize(column_name, *column_type).data_compressed;\n+        const auto size = getColumnSize(column_name).data_compressed;\n         if (size < minimum_size)\n         {\n             minimum_size = size;\n@@ -747,7 +747,7 @@ CompressionCodecPtr IMergeTreeDataPart::detectDefaultCompressionCodec() const\n     for (const auto & part_column : columns)\n     {\n         /// It was compressed with default codec and it's not empty\n-        auto column_size = getColumnSize(part_column.name, *part_column.type);\n+        auto column_size = getColumnSize(part_column.name);\n         if (column_size.data_compressed != 0 && !storage_columns.hasCompressionCodec(part_column.name))\n         {\n             auto serialization = IDataType::getSerialization(part_column,\n@@ -885,7 +885,7 @@ void IMergeTreeDataPart::loadRowsCount()\n             /// Most trivial types\n             if (column.type->isValueRepresentedByNumber() && !column.type->haveSubtypes())\n             {\n-                auto size = getColumnSize(column.name, *column.type);\n+                auto size = getColumnSize(column.name);\n \n                 if (size.data_uncompressed == 0)\n                     continue;\n@@ -933,7 +933,7 @@ void IMergeTreeDataPart::loadRowsCount()\n             if (!column_col->isFixedAndContiguous() || column_col->lowCardinality())\n                 continue;\n \n-            size_t column_size = getColumnSize(column.name, *column.type).data_uncompressed;\n+            size_t column_size = getColumnSize(column.name).data_uncompressed;\n             if (!column_size)\n                 continue;\n \n@@ -1490,7 +1490,7 @@ void IMergeTreeDataPart::calculateSecondaryIndicesSizesOnDisk()\n     }\n }\n \n-ColumnSize IMergeTreeDataPart::getColumnSize(const String & column_name, const IDataType & /* type */) const\n+ColumnSize IMergeTreeDataPart::getColumnSize(const String & column_name) const\n {\n     /// For some types of parts columns_size maybe not calculated\n     auto it = columns_sizes.find(column_name);\ndiff --git a/src/Storages/MergeTree/IMergeTreeDataPart.h b/src/Storages/MergeTree/IMergeTreeDataPart.h\nindex 1467b0ef03f4..3515da20fa99 100644\n--- a/src/Storages/MergeTree/IMergeTreeDataPart.h\n+++ b/src/Storages/MergeTree/IMergeTreeDataPart.h\n@@ -103,7 +103,7 @@ class IMergeTreeDataPart : public std::enable_shared_from_this<IMergeTreeDataPar\n \n     /// NOTE: Returns zeros if column files are not found in checksums.\n     /// Otherwise return information about column size on disk.\n-    ColumnSize getColumnSize(const String & column_name, const IDataType & /* type */) const;\n+    ColumnSize getColumnSize(const String & column_name) const;\n \n     /// NOTE: Returns zeros if secondary indexes are not found in checksums.\n     /// Otherwise return information about secondary index size on disk.\ndiff --git a/src/Storages/MergeTree/IntersectionsIndexes.h b/src/Storages/MergeTree/IntersectionsIndexes.h\nnew file mode 100644\nindex 000000000000..68ccbc4a0b11\n--- /dev/null\n+++ b/src/Storages/MergeTree/IntersectionsIndexes.h\n@@ -0,0 +1,237 @@\n+#pragma once\n+\n+#include <fmt/format.h>\n+#include <Storages/MergeTree/RequestResponse.h>\n+\n+namespace DB\n+{\n+\n+namespace ErrorCodes\n+{\n+    extern const int LOGICAL_ERROR;\n+}\n+\n+/// A boundary of a segment (left or right)\n+struct PartToRead\n+{\n+    PartBlockRange range;\n+    struct PartAndProjectionNames\n+    {\n+        String part;\n+        String projection;\n+        bool operator<(const PartAndProjectionNames & rhs) const\n+        {\n+            if (part == rhs.part)\n+                return projection < rhs.projection;\n+            return part < rhs.part;\n+        }\n+        bool operator==(const PartAndProjectionNames & rhs) const\n+        {\n+            return part == rhs.part && projection == rhs.projection;\n+        }\n+    };\n+\n+    PartAndProjectionNames name;\n+\n+    bool operator==(const PartToRead & rhs) const\n+    {\n+        return range == rhs.range && name == rhs.name;\n+    }\n+\n+    bool operator<(const PartToRead & rhs) const\n+    {\n+        /// We allow only consecutive non-intersecting ranges\n+        const bool intersection =\n+            (range.begin <= rhs.range.begin && rhs.range.begin < range.end) ||\n+            (rhs.range.begin <= range.begin && range.begin <= rhs.range.end);\n+        if (intersection)\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"Got intersecting parts. First [{}, {}]. Second [{}, {}]\",\n+                range.begin, range.end, rhs.range.begin, rhs.range.end);\n+        return range.begin < rhs.range.begin && range.end <= rhs.range.begin;\n+    }\n+};\n+\n+/// MergeTreeDataPart is described as a segment (min block and max block)\n+/// During request handling we have to know how many intersection\n+/// current part has with already saved parts in our state.\n+struct PartSegments\n+{\n+    enum class IntersectionResult\n+    {\n+        NO_INTERSECTION,\n+        EXACTLY_ONE_INTERSECTION,\n+        REJECT\n+    };\n+\n+    void addPart(PartToRead part) { segments.insert(std::move(part)); }\n+\n+    IntersectionResult getIntersectionResult(PartToRead part)\n+    {\n+        bool intersected_before = false;\n+        for (const auto & segment: segments)\n+        {\n+            auto are_intersect = [](auto & x, auto & y)\n+            {\n+                /// <= is important here, because we are working with segments [a, b]\n+                if ((x.begin <= y.begin) && (y.begin <= x.end))\n+                    return true;\n+                if ((y.begin <= x.begin) && (x.begin <= y.end))\n+                    return true;\n+                return false;\n+            };\n+\n+            if (are_intersect(segment.range, part.range))\n+            {\n+                /// We have two or possibly more intersections\n+                if (intersected_before)\n+                    return IntersectionResult::REJECT;\n+\n+                /// We have intersection with part with different name\n+                /// or with different min or max block\n+                /// It could happens if we have merged part on one replica\n+                /// but not on another.\n+                if (segment != part)\n+                    return IntersectionResult::REJECT;\n+\n+                /// We allow only the intersection with the same part as we have\n+                intersected_before = true;\n+            }\n+        }\n+\n+        return intersected_before ? IntersectionResult::EXACTLY_ONE_INTERSECTION : IntersectionResult::NO_INTERSECTION;\n+    }\n+\n+    using OrderedSegments = std::set<PartToRead>;\n+    OrderedSegments segments;\n+};\n+\n+/// This is used only in parallel reading from replicas\n+/// This struct is an ordered set of half intervals and it is responsible for\n+/// giving an inversion of that intervals (e.g. [a, b) => {[-inf, a), [b, +inf)})\n+/// or giving an intersection of two sets of intervals\n+/// This is needed, because MarkRange is actually a half-opened interval\n+/// and during the query execution we receive some kind of request from every replica\n+/// to read some ranges from a specific part.\n+/// We have to avoid the situation, where some range is read twice.\n+/// This struct helps us to do it using only two operations (intersection and inversion)\n+/// over a set of half opened intervals.\n+struct HalfIntervals\n+{\n+    static HalfIntervals initializeWithEntireSpace()\n+    {\n+        auto left_inf = std::numeric_limits<decltype(MarkRange::begin)>::min();\n+        auto right_inf = std::numeric_limits<decltype(MarkRange::end)>::max();\n+        return HalfIntervals{{{left_inf, right_inf}}};\n+    }\n+\n+    static HalfIntervals initializeFromMarkRanges(MarkRanges ranges)\n+    {\n+        OrderedRanges new_intervals;\n+        for (const auto & range : ranges)\n+            new_intervals.insert(range);\n+\n+        return HalfIntervals{std::move(new_intervals)};\n+    }\n+\n+    MarkRanges convertToMarkRangesFinal()\n+    {\n+        MarkRanges result;\n+        std::move(intervals.begin(), intervals.end(), std::back_inserter(result));\n+        return result;\n+    }\n+\n+    HalfIntervals & intersect(const HalfIntervals & rhs)\n+    {\n+        /**\n+         * first   [   ) [   ) [   ) [  ) [  )\n+         * second    [       ) [ ) [   )  [    )\n+         */\n+        OrderedRanges intersected;\n+\n+        const auto & first_intervals = intervals;\n+        auto first = first_intervals.begin();\n+        const auto & second_intervals = rhs.intervals;\n+        auto second = second_intervals.begin();\n+\n+        while (first != first_intervals.end() && second != second_intervals.end())\n+        {\n+            auto curr_intersection = MarkRange{\n+                std::max(second->begin, first->begin),\n+                std::min(second->end, first->end)\n+            };\n+\n+            /// Insert only if segments are intersect\n+            if (curr_intersection.begin < curr_intersection.end)\n+                intersected.insert(std::move(curr_intersection));\n+\n+            if (first->end <= second->end)\n+                ++first;\n+            else\n+                ++second;\n+        }\n+\n+        std::swap(intersected, intervals);\n+\n+        return *this;\n+    }\n+\n+    HalfIntervals & negate()\n+    {\n+        auto left_inf = std::numeric_limits<decltype(MarkRange::begin)>::min();\n+        auto right_inf = std::numeric_limits<decltype(MarkRange::end)>::max();\n+\n+        if (intervals.empty())\n+        {\n+            intervals.insert(MarkRange{left_inf, right_inf});\n+            return *this;\n+        }\n+\n+        OrderedRanges new_ranges;\n+\n+        /// Possibly add (-inf; begin)\n+        if (auto begin = intervals.begin()->begin; begin != left_inf)\n+            new_ranges.insert(MarkRange{left_inf, begin});\n+\n+        auto prev = intervals.begin();\n+        for (auto it = std::next(intervals.begin()); it != intervals.end(); ++it)\n+        {\n+            if (prev->end != it->begin)\n+                new_ranges.insert(MarkRange{prev->end, it->begin});\n+            prev = it;\n+        }\n+\n+        /// Try to add (end; +inf)\n+        if (auto end = intervals.rbegin()->end; end != right_inf)\n+            new_ranges.insert(MarkRange{end, right_inf});\n+\n+        std::swap(new_ranges, intervals);\n+\n+        return *this;\n+    }\n+\n+    bool operator==(const HalfIntervals & rhs) const\n+    {\n+        return intervals == rhs.intervals;\n+    }\n+\n+    using OrderedRanges = std::set<MarkRange>;\n+    OrderedRanges intervals;\n+};\n+\n+\n+[[ maybe_unused ]] static std::ostream & operator<< (std::ostream & out, const HalfIntervals & ranges)\n+{\n+    for (const auto & range: ranges.intervals)\n+        out << fmt::format(\"({}, {}) \", range.begin, range.end);\n+    return out;\n+}\n+\n+/// This is needed for tests where we don't need to modify objects\n+[[ maybe_unused ]] static HalfIntervals getIntersection(const HalfIntervals & first, const HalfIntervals & second)\n+{\n+    auto result = first;\n+    result.intersect(second);\n+    return result;\n+}\n+\n+}\ndiff --git a/src/Storages/MergeTree/MarkRange.cpp b/src/Storages/MergeTree/MarkRange.cpp\nindex 7f097cd71065..343c4ecaf22b 100644\n--- a/src/Storages/MergeTree/MarkRange.cpp\n+++ b/src/Storages/MergeTree/MarkRange.cpp\n@@ -3,6 +3,31 @@\n namespace DB\n {\n \n+namespace ErrorCodes\n+{\n+    extern const int LOGICAL_ERROR;\n+}\n+\n+bool MarkRange::operator==(const MarkRange & rhs) const\n+{\n+    return begin == rhs.begin && end == rhs.end;\n+}\n+\n+bool MarkRange::operator<(const MarkRange & rhs) const\n+{\n+    /// We allow only consecutive non-intersecting ranges\n+    /// Here we check whether a beginning of one range lies inside another range\n+    /// (ranges are intersect)\n+    const bool is_intersection = (begin <= rhs.begin && rhs.begin < end) ||\n+        (rhs.begin <= begin && begin < rhs.end);\n+\n+    if (is_intersection)\n+        throw Exception(ErrorCodes::LOGICAL_ERROR,\n+        \"Intersecting mark ranges are not allowed, it is a bug! First range ({}, {}), second range ({}, {})\", begin, end, rhs.begin, rhs.end);\n+\n+    return begin < rhs.begin && end <= rhs.begin;\n+}\n+\n size_t getLastMark(const MarkRanges & ranges)\n {\n     size_t current_task_last_mark = 0;\ndiff --git a/src/Storages/MergeTree/MarkRange.h b/src/Storages/MergeTree/MarkRange.h\nindex b46913db30cb..4f32be6ab140 100644\n--- a/src/Storages/MergeTree/MarkRange.h\n+++ b/src/Storages/MergeTree/MarkRange.h\n@@ -2,7 +2,9 @@\n \n #include <cstddef>\n #include <deque>\n+#include <set>\n \n+#include <IO/WriteBuffer.h>\n \n namespace DB\n {\n@@ -18,6 +20,10 @@ struct MarkRange\n \n     MarkRange() = default;\n     MarkRange(const size_t begin_, const size_t end_) : begin{begin_}, end{end_} {}\n+\n+    bool operator==(const MarkRange & rhs) const;\n+\n+    bool operator<(const MarkRange & rhs) const;\n };\n \n using MarkRanges = std::deque<MarkRange>;\ndiff --git a/src/Storages/MergeTree/MergeTreeBaseSelectProcessor.cpp b/src/Storages/MergeTree/MergeTreeBaseSelectProcessor.cpp\nindex 2f46543b03cc..fbc818a7de95 100644\n--- a/src/Storages/MergeTree/MergeTreeBaseSelectProcessor.cpp\n+++ b/src/Storages/MergeTree/MergeTreeBaseSelectProcessor.cpp\n@@ -3,6 +3,7 @@\n #include <Storages/MergeTree/IMergeTreeDataPart.h>\n #include <Storages/MergeTree/IMergeTreeReader.h>\n #include <Storages/MergeTree/MergeTreeBlockReadUtils.h>\n+#include <Storages/MergeTree/RequestResponse.h>\n #include <Columns/FilterDescription.h>\n #include <Common/typeid_cast.h>\n #include <DataTypes/DataTypeNothing.h>\n@@ -12,6 +13,8 @@\n #include <Processors/Transforms/AggregatingTransform.h>\n \n \n+#include <city.h>\n+\n namespace DB\n {\n \n@@ -33,7 +36,8 @@ MergeTreeBaseSelectProcessor::MergeTreeBaseSelectProcessor(\n     UInt64 preferred_max_column_in_block_size_bytes_,\n     const MergeTreeReaderSettings & reader_settings_,\n     bool use_uncompressed_cache_,\n-    const Names & virt_column_names_)\n+    const Names & virt_column_names_,\n+    std::optional<ParallelReadingExtension> extension_)\n     : SourceWithProgress(transformHeader(std::move(header), prewhere_info_, storage_.getPartitionValueType(), virt_column_names_))\n     , storage(storage_)\n     , metadata_snapshot(metadata_snapshot_)\n@@ -45,6 +49,7 @@ MergeTreeBaseSelectProcessor::MergeTreeBaseSelectProcessor(\n     , use_uncompressed_cache(use_uncompressed_cache_)\n     , virt_column_names(virt_column_names_)\n     , partition_value_type(storage.getPartitionValueType())\n+    , extension(extension_)\n {\n     header_without_virtual_columns = getPort().getHeader();\n \n@@ -71,6 +76,91 @@ MergeTreeBaseSelectProcessor::MergeTreeBaseSelectProcessor(\n }\n \n \n+bool MergeTreeBaseSelectProcessor::getNewTask()\n+{\n+    /// No parallel reading feature\n+    if (!extension.has_value())\n+    {\n+        if (getNewTaskImpl())\n+        {\n+            finalizeNewTask();\n+            return true;\n+        }\n+        return false;\n+    }\n+    return getNewTaskParallelReading();\n+}\n+\n+\n+bool MergeTreeBaseSelectProcessor::getNewTaskParallelReading()\n+{\n+    if (getTaskFromBuffer())\n+        return true;\n+\n+    if (no_more_tasks)\n+        return getDelayedTasks();\n+\n+    while (true)\n+    {\n+        /// The end of execution. No task.\n+        if (!getNewTaskImpl())\n+        {\n+            no_more_tasks = true;\n+            return getDelayedTasks();\n+        }\n+\n+        splitCurrentTaskRangesAndFillBuffer();\n+\n+        if (getTaskFromBuffer())\n+            return true;\n+    }\n+}\n+\n+\n+bool MergeTreeBaseSelectProcessor::getTaskFromBuffer()\n+{\n+    while (!buffered_ranges.empty())\n+    {\n+        auto ranges = std::move(buffered_ranges.front());\n+        buffered_ranges.pop_front();\n+\n+        assert(!ranges.empty());\n+\n+        auto res = performRequestToCoordinator(ranges, /*delayed=*/false);\n+\n+        if (Status::Accepted == res)\n+            return true;\n+\n+        if (Status::Cancelled == res)\n+            break;\n+    }\n+    return false;\n+}\n+\n+\n+bool MergeTreeBaseSelectProcessor::getDelayedTasks()\n+{\n+    while (!delayed_tasks.empty())\n+    {\n+        task = std::move(delayed_tasks.front());\n+        delayed_tasks.pop_front();\n+\n+        assert(!task->mark_ranges.empty());\n+\n+        auto res = performRequestToCoordinator(task->mark_ranges, /*delayed=*/true);\n+\n+        if (Status::Accepted == res)\n+            return true;\n+\n+        if (Status::Cancelled == res)\n+            break;\n+    }\n+\n+    finish();\n+    return false;\n+}\n+\n+\n Chunk MergeTreeBaseSelectProcessor::generate()\n {\n     while (!isCancelled())\n@@ -479,6 +569,163 @@ std::unique_ptr<MergeTreeBlockSizePredictor> MergeTreeBaseSelectProcessor::getSi\n         data_part, Names(complete_column_names.begin(), complete_column_names.end()), sample_block);\n }\n \n+\n+MergeTreeBaseSelectProcessor::Status MergeTreeBaseSelectProcessor::performRequestToCoordinator(MarkRanges requested_ranges, bool delayed)\n+{\n+    String partition_id = task->data_part->info.partition_id;\n+    String part_name;\n+    String projection_name;\n+\n+    if (task->data_part->isProjectionPart())\n+    {\n+        part_name = task->data_part->getParentPart()->name;\n+        projection_name  = task->data_part->name;\n+    }\n+    else\n+    {\n+        part_name = task->data_part->name;\n+        projection_name = \"\";\n+    }\n+\n+    PartBlockRange block_range\n+    {\n+        .begin = task->data_part->info.min_block,\n+        .end = task->data_part->info.max_block\n+    };\n+\n+    PartitionReadRequest request\n+    {\n+        .partition_id = std::move(partition_id),\n+        .part_name = std::move(part_name),\n+        .projection_name = std::move(projection_name),\n+        .block_range = std::move(block_range),\n+        .mark_ranges = std::move(requested_ranges)\n+    };\n+\n+    /// Constistent hashing won't work with reading in order, because at the end of the execution\n+    /// we could possibly seek back\n+    if (!delayed && canUseConsistentHashingForParallelReading())\n+    {\n+        const auto hash = request.getConsistentHash(extension->count_participating_replicas);\n+        if (hash != extension->number_of_current_replica)\n+        {\n+            auto delayed_task = std::make_unique<MergeTreeReadTask>(*task); // Create a copy\n+            delayed_task->mark_ranges = std::move(request.mark_ranges);\n+            delayed_tasks.emplace_back(std::move(delayed_task));\n+            return Status::Denied;\n+        }\n+    }\n+\n+    auto optional_response = extension.value().callback(std::move(request));\n+\n+    if (!optional_response.has_value())\n+        return Status::Cancelled;\n+\n+    auto response = optional_response.value();\n+\n+    task->mark_ranges = std::move(response.mark_ranges);\n+\n+    if (response.denied || task->mark_ranges.empty())\n+        return Status::Denied;\n+\n+    finalizeNewTask();\n+\n+    return Status::Accepted;\n+}\n+\n+\n+size_t MergeTreeBaseSelectProcessor::estimateMaxBatchSizeForHugeRanges()\n+{\n+    /// This is an empirical number and it is so,\n+    /// because we have an adaptive granularity by default.\n+    const size_t average_granule_size_bytes = 8UL * 1024 * 1024 * 10; // 10 MiB\n+\n+    /// We want to have one RTT per one gigabyte of data read from disk\n+    /// this could be configurable.\n+    const size_t max_size_for_one_request = 8UL * 1024 * 1024 * 1024; // 1 GiB\n+\n+    size_t sum_average_marks_size = 0;\n+    /// getColumnSize is not fully implemented for compact parts\n+    if (task->data_part->getType() == IMergeTreeDataPart::Type::COMPACT)\n+    {\n+        sum_average_marks_size = average_granule_size_bytes;\n+    }\n+    else\n+    {\n+        for (const auto & name : extension->colums_to_read)\n+        {\n+            auto size = task->data_part->getColumnSize(name);\n+\n+            assert(size.marks != 0);\n+            sum_average_marks_size += size.data_uncompressed / size.marks;\n+        }\n+    }\n+\n+    if (sum_average_marks_size == 0)\n+        sum_average_marks_size = average_granule_size_bytes; // 10 MiB\n+\n+    LOG_TEST(log, \"Reading from {} part, average mark size is {}\",\n+        task->data_part->getTypeName(), sum_average_marks_size);\n+\n+    return max_size_for_one_request / sum_average_marks_size;\n+}\n+\n+void MergeTreeBaseSelectProcessor::splitCurrentTaskRangesAndFillBuffer()\n+{\n+    const size_t max_batch_size = estimateMaxBatchSizeForHugeRanges();\n+\n+    size_t current_batch_size = 0;\n+    buffered_ranges.emplace_back();\n+\n+    for (const auto & range : task->mark_ranges)\n+    {\n+        auto expand_if_needed = [&]\n+        {\n+            if (current_batch_size > max_batch_size)\n+            {\n+                buffered_ranges.emplace_back();\n+                current_batch_size = 0;\n+            }\n+        };\n+\n+        expand_if_needed();\n+\n+        if (range.end - range.begin < max_batch_size)\n+        {\n+            buffered_ranges.back().push_back(range);\n+            current_batch_size += range.end - range.begin;\n+            continue;\n+        }\n+\n+        auto current_begin = range.begin;\n+        auto current_end = range.begin + max_batch_size;\n+\n+        while (current_end < range.end)\n+        {\n+            auto current_range = MarkRange{current_begin, current_end};\n+            buffered_ranges.back().push_back(current_range);\n+            current_batch_size += current_end - current_begin;\n+\n+            current_begin = current_end;\n+            current_end = current_end + max_batch_size;\n+\n+            expand_if_needed();\n+        }\n+\n+        if (range.end - current_begin > 0)\n+        {\n+            auto current_range = MarkRange{current_begin, range.end};\n+            buffered_ranges.back().push_back(current_range);\n+            current_batch_size += range.end - current_begin;\n+\n+            expand_if_needed();\n+        }\n+    }\n+\n+    if (buffered_ranges.back().empty())\n+        buffered_ranges.pop_back();\n+}\n+\n MergeTreeBaseSelectProcessor::~MergeTreeBaseSelectProcessor() = default;\n \n }\ndiff --git a/src/Storages/MergeTree/MergeTreeBaseSelectProcessor.h b/src/Storages/MergeTree/MergeTreeBaseSelectProcessor.h\nindex d102e4f07a4e..c462c34aa835 100644\n--- a/src/Storages/MergeTree/MergeTreeBaseSelectProcessor.h\n+++ b/src/Storages/MergeTree/MergeTreeBaseSelectProcessor.h\n@@ -3,6 +3,7 @@\n #include <Storages/MergeTree/MergeTreeBlockReadUtils.h>\n #include <Storages/MergeTree/MergeTreeData.h>\n #include <Storages/SelectQueryInfo.h>\n+#include <Storages/MergeTree/RequestResponse.h>\n \n #include <Processors/Sources/SourceWithProgress.h>\n \n@@ -15,6 +16,18 @@ class UncompressedCache;\n class MarkCache;\n struct PrewhereExprInfo;\n \n+\n+struct ParallelReadingExtension\n+{\n+    MergeTreeReadTaskCallback callback;\n+    size_t count_participating_replicas{0};\n+    size_t number_of_current_replica{0};\n+    /// This is needed to estimate the number of bytes\n+    /// between a pair of marks to perform one request\n+    /// over the network for a 1Gb of data.\n+    Names colums_to_read;\n+};\n+\n /// Base class for MergeTreeThreadSelectProcessor and MergeTreeSelectProcessor\n class MergeTreeBaseSelectProcessor : public SourceWithProgress\n {\n@@ -30,7 +43,8 @@ class MergeTreeBaseSelectProcessor : public SourceWithProgress\n         UInt64 preferred_max_column_in_block_size_bytes_,\n         const MergeTreeReaderSettings & reader_settings_,\n         bool use_uncompressed_cache_,\n-        const Names & virt_column_names_ = {});\n+        const Names & virt_column_names_ = {},\n+        std::optional<ParallelReadingExtension> extension = {});\n \n     ~MergeTreeBaseSelectProcessor() override;\n \n@@ -43,10 +57,22 @@ class MergeTreeBaseSelectProcessor : public SourceWithProgress\n         const Block & sample_block);\n \n protected:\n+\n     Chunk generate() final;\n \n-    /// Creates new this->task, and initializes readers.\n-    virtual bool getNewTask() = 0;\n+    /// Creates new this->task and return a flag whether it was successful or not\n+    virtual bool getNewTaskImpl() = 0;\n+    /// Creates new readers for a task it is needed. These methods are separate, because\n+    /// in case of parallel reading from replicas the whole task could be denied by a coodinator\n+    /// or it could modified somehow.\n+    virtual void finalizeNewTask() = 0;\n+\n+    size_t estimateMaxBatchSizeForHugeRanges();\n+\n+    virtual bool canUseConsistentHashingForParallelReading() { return false; }\n+\n+    /// Closes readers and unlock part locks\n+    virtual void finish() = 0;\n \n     virtual Chunk readFromPart();\n \n@@ -82,14 +108,62 @@ class MergeTreeBaseSelectProcessor : public SourceWithProgress\n     /// This header is used for chunks from readFromPart().\n     Block header_without_virtual_columns;\n \n-    std::unique_ptr<MergeTreeReadTask> task;\n-\n     std::shared_ptr<UncompressedCache> owned_uncompressed_cache;\n     std::shared_ptr<MarkCache> owned_mark_cache;\n \n     using MergeTreeReaderPtr = std::unique_ptr<IMergeTreeReader>;\n     MergeTreeReaderPtr reader;\n     MergeTreeReaderPtr pre_reader;\n+\n+    MergeTreeReadTaskPtr task;\n+\n+    std::optional<ParallelReadingExtension> extension;\n+    bool no_more_tasks{false};\n+    std::deque<MergeTreeReadTaskPtr> delayed_tasks;\n+    std::deque<MarkRanges> buffered_ranges;\n+\n+private:\n+    Poco::Logger * log = &Poco::Logger::get(\"MergeTreeBaseSelectProcessor\");\n+\n+    enum class Status\n+    {\n+        Accepted,\n+        Cancelled,\n+        Denied\n+    };\n+\n+    /// Calls getNewTaskImpl() to get new task, then performs a request to a coordinator\n+    /// The coordinator may modify the set of ranges to read from a part or could\n+    /// deny the whole request. In the latter case it creates new task and retries.\n+    /// Then it calls finalizeNewTask() to create readers for a task if it is needed.\n+    bool getNewTask();\n+    bool getNewTaskParallelReading();\n+\n+    /// After PK analysis the range of marks could be extremely big\n+    /// We divide this range to a set smaller consecutive ranges\n+    /// Then, depending on the type of reading (concurrent, in order or in reverse order)\n+    /// we can calculate a consistent hash function with the number of buckets equal to\n+    /// the number of replicas involved. And after that we can throw away some ranges with\n+    /// hash not equals to the number of the current replica.\n+    bool getTaskFromBuffer();\n+\n+    /// But we can't throw that ranges completely, because if we have different sets of parts\n+    /// on replicas (have merged part on one, but not on another), then such a situation is possible\n+    /// - Coordinator allows to read from a big merged part, but this part is present only on one replica.\n+    ///   And that replica calculates consistent hash and throws away some ranges\n+    /// - Coordinator denies other replicas to read from another parts (source parts for that big one)\n+    /// At the end, the result of the query is wrong, because we didn't read all the data.\n+    /// So, we have to remember parts and mark ranges with hash different then current replica number.\n+    /// An we have to ask the coordinator about its permission to read from that \"delayed\" parts.\n+    /// It won't work with reading in order or reading in reverse order, because we can possibly seek back.\n+    bool getDelayedTasks();\n+\n+    /// It will form a request a request to coordinator and\n+    /// then reinitialize the mark ranges of this->task object\n+    Status performRequestToCoordinator(MarkRanges requested_ranges, bool delayed);\n+\n+    void splitCurrentTaskRangesAndFillBuffer();\n+\n };\n \n }\ndiff --git a/src/Storages/MergeTree/MergeTreeBlockReadUtils.cpp b/src/Storages/MergeTree/MergeTreeBlockReadUtils.cpp\nindex 88f3052e8330..07d51d257001 100644\n--- a/src/Storages/MergeTree/MergeTreeBlockReadUtils.cpp\n+++ b/src/Storages/MergeTree/MergeTreeBlockReadUtils.cpp\n@@ -128,8 +128,6 @@ MergeTreeReadTask::MergeTreeReadTask(\n {\n }\n \n-MergeTreeReadTask::~MergeTreeReadTask() = default;\n-\n \n MergeTreeBlockSizePredictor::MergeTreeBlockSizePredictor(\n     const MergeTreeData::DataPartPtr & data_part_, const Names & columns, const Block & sample_block)\n@@ -175,8 +173,7 @@ void MergeTreeBlockSizePredictor::initialize(const Block & sample_block, const C\n             ColumnInfo info;\n             info.name = column_name;\n             /// If column isn't fixed and doesn't have checksum, than take first\n-            ColumnSize column_size = data_part->getColumnSize(\n-                column_name, *column_with_type_and_name.type);\n+            ColumnSize column_size = data_part->getColumnSize(column_name);\n \n             info.bytes_per_row_global = column_size.data_uncompressed\n                 ? column_size.data_uncompressed / number_of_rows_in_part\ndiff --git a/src/Storages/MergeTree/MergeTreeBlockReadUtils.h b/src/Storages/MergeTree/MergeTreeBlockReadUtils.h\nindex 2dfe6fcf06da..b931a13c027d 100644\n--- a/src/Storages/MergeTree/MergeTreeBlockReadUtils.h\n+++ b/src/Storages/MergeTree/MergeTreeBlockReadUtils.h\n@@ -14,7 +14,7 @@ struct MergeTreeReadTask;\n struct MergeTreeBlockSizePredictor;\n \n using MergeTreeReadTaskPtr = std::unique_ptr<MergeTreeReadTask>;\n-using MergeTreeBlockSizePredictorPtr = std::unique_ptr<MergeTreeBlockSizePredictor>;\n+using MergeTreeBlockSizePredictorPtr = std::shared_ptr<MergeTreeBlockSizePredictor>;\n \n \n /** If some of the requested columns are not in the part,\n@@ -59,8 +59,6 @@ struct MergeTreeReadTask\n         const Names & ordered_names_, const NameSet & column_name_set_, const NamesAndTypesList & columns_,\n         const NamesAndTypesList & pre_columns_, const bool remove_prewhere_column_, const bool should_reorder_,\n         MergeTreeBlockSizePredictorPtr && size_predictor_);\n-\n-    virtual ~MergeTreeReadTask();\n };\n \n struct MergeTreeReadTaskColumns\ndiff --git a/src/Storages/MergeTree/MergeTreeData.cpp b/src/Storages/MergeTree/MergeTreeData.cpp\nindex 3cf7023053fd..e58472e572bf 100644\n--- a/src/Storages/MergeTree/MergeTreeData.cpp\n+++ b/src/Storages/MergeTree/MergeTreeData.cpp\n@@ -3163,7 +3163,7 @@ void MergeTreeData::addPartContributionToColumnAndSecondaryIndexSizes(const Data\n     for (const auto & column : part->getColumns())\n     {\n         ColumnSize & total_column_size = column_sizes[column.name];\n-        ColumnSize part_column_size = part->getColumnSize(column.name, *column.type);\n+        ColumnSize part_column_size = part->getColumnSize(column.name);\n         total_column_size.add(part_column_size);\n     }\n \n@@ -3181,7 +3181,7 @@ void MergeTreeData::removePartContributionToColumnAndSecondaryIndexSizes(const D\n     for (const auto & column : part->getColumns())\n     {\n         ColumnSize & total_column_size = column_sizes[column.name];\n-        ColumnSize part_column_size = part->getColumnSize(column.name, *column.type);\n+        ColumnSize part_column_size = part->getColumnSize(column.name);\n \n         auto log_subtract = [&](size_t & from, size_t value, const char * field)\n         {\ndiff --git a/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp b/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp\nindex 036e7d89c5ae..cdedd37e14ae 100644\n--- a/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp\n+++ b/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp\n@@ -124,7 +124,8 @@ QueryPlanPtr MergeTreeDataSelectExecutor::read(\n     const UInt64 max_block_size,\n     const unsigned num_streams,\n     QueryProcessingStage::Enum processed_stage,\n-    std::shared_ptr<PartitionIdToMaxBlock> max_block_numbers_to_read) const\n+    std::shared_ptr<PartitionIdToMaxBlock> max_block_numbers_to_read,\n+    bool enable_parallel_reading) const\n {\n     if (query_info.merge_tree_empty_result)\n         return std::make_unique<QueryPlan>();\n@@ -142,7 +143,8 @@ QueryPlanPtr MergeTreeDataSelectExecutor::read(\n             max_block_size,\n             num_streams,\n             max_block_numbers_to_read,\n-            query_info.merge_tree_select_result_ptr);\n+            query_info.merge_tree_select_result_ptr,\n+            enable_parallel_reading);\n \n         if (plan->isInitialized() && settings.allow_experimental_projection_optimization && settings.force_optimize_projection\n             && !metadata_snapshot->projections.empty())\n@@ -184,7 +186,8 @@ QueryPlanPtr MergeTreeDataSelectExecutor::read(\n             max_block_size,\n             num_streams,\n             max_block_numbers_to_read,\n-            query_info.projection->merge_tree_projection_select_result_ptr);\n+            query_info.projection->merge_tree_projection_select_result_ptr,\n+            enable_parallel_reading);\n     }\n \n     if (projection_plan->isInitialized())\n@@ -1210,7 +1213,8 @@ QueryPlanPtr MergeTreeDataSelectExecutor::readFromParts(\n     const UInt64 max_block_size,\n     const unsigned num_streams,\n     std::shared_ptr<PartitionIdToMaxBlock> max_block_numbers_to_read,\n-    MergeTreeDataSelectAnalysisResultPtr merge_tree_select_result_ptr) const\n+    MergeTreeDataSelectAnalysisResultPtr merge_tree_select_result_ptr,\n+    bool enable_parallel_reading) const\n {\n     /// If merge_tree_select_result_ptr != nullptr, we use analyzed result so parts will always be empty.\n     if (merge_tree_select_result_ptr)\n@@ -1243,7 +1247,8 @@ QueryPlanPtr MergeTreeDataSelectExecutor::readFromParts(\n         sample_factor_column_queried,\n         max_block_numbers_to_read,\n         log,\n-        merge_tree_select_result_ptr\n+        merge_tree_select_result_ptr,\n+        enable_parallel_reading\n     );\n \n     QueryPlanPtr plan = std::make_unique<QueryPlan>();\ndiff --git a/src/Storages/MergeTree/MergeTreeDataSelectExecutor.h b/src/Storages/MergeTree/MergeTreeDataSelectExecutor.h\nindex f19d145fc93c..3dde324ce22d 100644\n--- a/src/Storages/MergeTree/MergeTreeDataSelectExecutor.h\n+++ b/src/Storages/MergeTree/MergeTreeDataSelectExecutor.h\n@@ -34,7 +34,8 @@ class MergeTreeDataSelectExecutor\n         UInt64 max_block_size,\n         unsigned num_streams,\n         QueryProcessingStage::Enum processed_stage,\n-        std::shared_ptr<PartitionIdToMaxBlock> max_block_numbers_to_read = nullptr) const;\n+        std::shared_ptr<PartitionIdToMaxBlock> max_block_numbers_to_read = nullptr,\n+        bool enable_parallel_reading = false) const;\n \n     /// The same as read, but with specified set of parts.\n     QueryPlanPtr readFromParts(\n@@ -47,7 +48,8 @@ class MergeTreeDataSelectExecutor\n         UInt64 max_block_size,\n         unsigned num_streams,\n         std::shared_ptr<PartitionIdToMaxBlock> max_block_numbers_to_read = nullptr,\n-        MergeTreeDataSelectAnalysisResultPtr merge_tree_select_result_ptr = nullptr) const;\n+        MergeTreeDataSelectAnalysisResultPtr merge_tree_select_result_ptr = nullptr,\n+        bool enable_parallel_reading = false) const;\n \n     /// Get an estimation for the number of marks we are going to read.\n     /// Reads nothing. Secondary indexes are not used.\ndiff --git a/src/Storages/MergeTree/MergeTreeInOrderSelectProcessor.cpp b/src/Storages/MergeTree/MergeTreeInOrderSelectProcessor.cpp\nindex 48a9d62d8726..961106af51b2 100644\n--- a/src/Storages/MergeTree/MergeTreeInOrderSelectProcessor.cpp\n+++ b/src/Storages/MergeTree/MergeTreeInOrderSelectProcessor.cpp\n@@ -8,14 +8,11 @@ namespace ErrorCodes\n     extern const int MEMORY_LIMIT_EXCEEDED;\n }\n \n-bool MergeTreeInOrderSelectProcessor::getNewTask()\n+bool MergeTreeInOrderSelectProcessor::getNewTaskImpl()\n try\n {\n     if (all_mark_ranges.empty())\n-    {\n-        finish();\n         return false;\n-    }\n \n     if (!reader)\n         initializeReaders();\ndiff --git a/src/Storages/MergeTree/MergeTreeInOrderSelectProcessor.h b/src/Storages/MergeTree/MergeTreeInOrderSelectProcessor.h\nindex ecf648b02916..467292d88bb7 100644\n--- a/src/Storages/MergeTree/MergeTreeInOrderSelectProcessor.h\n+++ b/src/Storages/MergeTree/MergeTreeInOrderSelectProcessor.h\n@@ -12,7 +12,7 @@ class MergeTreeInOrderSelectProcessor final : public MergeTreeSelectProcessor\n {\n public:\n     template <typename... Args>\n-    MergeTreeInOrderSelectProcessor(Args &&... args)\n+    explicit MergeTreeInOrderSelectProcessor(Args &&... args)\n         : MergeTreeSelectProcessor{std::forward<Args>(args)...}\n     {\n         LOG_DEBUG(log, \"Reading {} ranges in order from part {}, approx. {} rows starting from {}\",\n@@ -23,7 +23,8 @@ class MergeTreeInOrderSelectProcessor final : public MergeTreeSelectProcessor\n     String getName() const override { return \"MergeTreeInOrder\"; }\n \n private:\n-    bool getNewTask() override;\n+    bool getNewTaskImpl() override;\n+    void finalizeNewTask() override {}\n \n     Poco::Logger * log = &Poco::Logger::get(\"MergeTreeInOrderSelectProcessor\");\n };\ndiff --git a/src/Storages/MergeTree/MergeTreeRangeReader.cpp b/src/Storages/MergeTree/MergeTreeRangeReader.cpp\nindex 124f13b14a8d..8481cee0f86f 100644\n--- a/src/Storages/MergeTree/MergeTreeRangeReader.cpp\n+++ b/src/Storages/MergeTree/MergeTreeRangeReader.cpp\n@@ -14,6 +14,7 @@ namespace DB\n namespace ErrorCodes\n {\n     extern const int LOGICAL_ERROR;\n+    extern const int BAD_ARGUMENTS;\n }\n \n \n@@ -185,7 +186,7 @@ MergeTreeRangeReader::Stream::Stream(\n void MergeTreeRangeReader::Stream::checkNotFinished() const\n {\n     if (isFinished())\n-        throw Exception(\"Cannot read out of marks range.\", ErrorCodes::LOGICAL_ERROR);\n+        throw Exception(\"Cannot read out of marks range.\", ErrorCodes::BAD_ARGUMENTS);\n }\n \n void MergeTreeRangeReader::Stream::checkEnoughSpaceInCurrentGranule(size_t num_rows) const\n@@ -290,7 +291,7 @@ void MergeTreeRangeReader::ReadResult::adjustLastGranule()\n     size_t num_rows_to_subtract = total_rows_per_granule - num_read_rows;\n \n     if (rows_per_granule.empty())\n-        throw Exception(\"Can't adjust last granule because no granules were added.\", ErrorCodes::LOGICAL_ERROR);\n+        throw Exception(\"Can't adjust last granule because no granules were added\", ErrorCodes::LOGICAL_ERROR);\n \n     if (num_rows_to_subtract > rows_per_granule.back())\n         throw Exception(ErrorCodes::LOGICAL_ERROR,\ndiff --git a/src/Storages/MergeTree/MergeTreeReverseSelectProcessor.cpp b/src/Storages/MergeTree/MergeTreeReverseSelectProcessor.cpp\nindex 16ce9823ebbf..6c4059d64d0a 100644\n--- a/src/Storages/MergeTree/MergeTreeReverseSelectProcessor.cpp\n+++ b/src/Storages/MergeTree/MergeTreeReverseSelectProcessor.cpp\n@@ -8,14 +8,11 @@ namespace ErrorCodes\n     extern const int MEMORY_LIMIT_EXCEEDED;\n }\n \n-bool MergeTreeReverseSelectProcessor::getNewTask()\n+bool MergeTreeReverseSelectProcessor::getNewTaskImpl()\n try\n {\n     if (chunks.empty() && all_mark_ranges.empty())\n-    {\n-        finish();\n         return false;\n-    }\n \n     /// We have some blocks to return in buffer.\n     /// Return true to continue reading, but actually don't create a task.\ndiff --git a/src/Storages/MergeTree/MergeTreeReverseSelectProcessor.h b/src/Storages/MergeTree/MergeTreeReverseSelectProcessor.h\nindex 18ab51c03a02..395f5d5cd2aa 100644\n--- a/src/Storages/MergeTree/MergeTreeReverseSelectProcessor.h\n+++ b/src/Storages/MergeTree/MergeTreeReverseSelectProcessor.h\n@@ -13,7 +13,7 @@ class MergeTreeReverseSelectProcessor final : public MergeTreeSelectProcessor\n {\n public:\n     template <typename... Args>\n-    MergeTreeReverseSelectProcessor(Args &&... args)\n+    explicit MergeTreeReverseSelectProcessor(Args &&... args)\n         : MergeTreeSelectProcessor{std::forward<Args>(args)...}\n     {\n         LOG_DEBUG(log, \"Reading {} ranges in reverse order from part {}, approx. {} rows starting from {}\",\n@@ -24,7 +24,9 @@ class MergeTreeReverseSelectProcessor final : public MergeTreeSelectProcessor\n     String getName() const override { return \"MergeTreeReverse\"; }\n \n private:\n-    bool getNewTask() override;\n+    bool getNewTaskImpl() override;\n+    void finalizeNewTask() override {}\n+\n     Chunk readFromPart() override;\n \n     Chunks chunks;\ndiff --git a/src/Storages/MergeTree/MergeTreeSelectProcessor.cpp b/src/Storages/MergeTree/MergeTreeSelectProcessor.cpp\nindex 203ce7a57d28..2d4d3617cee9 100644\n--- a/src/Storages/MergeTree/MergeTreeSelectProcessor.cpp\n+++ b/src/Storages/MergeTree/MergeTreeSelectProcessor.cpp\n@@ -22,12 +22,13 @@ MergeTreeSelectProcessor::MergeTreeSelectProcessor(\n     const MergeTreeReaderSettings & reader_settings_,\n     const Names & virt_column_names_,\n     size_t part_index_in_query_,\n-    bool has_limit_below_one_block_)\n+    bool has_limit_below_one_block_,\n+    std::optional<ParallelReadingExtension> extension_)\n     : MergeTreeBaseSelectProcessor{\n         metadata_snapshot_->getSampleBlockForColumns(required_columns_, storage_.getVirtuals(), storage_.getStorageID()),\n         storage_, metadata_snapshot_, prewhere_info_, std::move(actions_settings), max_block_size_rows_,\n         preferred_block_size_bytes_, preferred_max_column_in_block_size_bytes_,\n-        reader_settings_, use_uncompressed_cache_, virt_column_names_},\n+        reader_settings_, use_uncompressed_cache_, virt_column_names_, extension_},\n     required_columns{std::move(required_columns_)},\n     data_part{owned_data_part_},\n     sample_block(metadata_snapshot_->getSampleBlock()),\n@@ -36,7 +37,11 @@ MergeTreeSelectProcessor::MergeTreeSelectProcessor(\n     has_limit_below_one_block(has_limit_below_one_block_),\n     total_rows(data_part->index_granularity.getRowsCountInRanges(all_mark_ranges))\n {\n-    addTotalRowsApprox(total_rows);\n+    /// Actually it means that parallel reading from replicas enabled\n+    /// and we have to collaborate with initiator.\n+    /// In this case we won't set approximate rows, because it will be accounted multiple times\n+    if (!extension_.has_value())\n+        addTotalRowsApprox(total_rows);\n     ordered_names = header_without_virtual_columns.getNames();\n }\n \n@@ -64,6 +69,7 @@ void MergeTreeSelectProcessor::initializeReaders()\n \n }\n \n+\n void MergeTreeSelectProcessor::finish()\n {\n     /** Close the files (before destroying the object).\ndiff --git a/src/Storages/MergeTree/MergeTreeSelectProcessor.h b/src/Storages/MergeTree/MergeTreeSelectProcessor.h\nindex f9b19f9f692f..2ecdc3b59a8f 100644\n--- a/src/Storages/MergeTree/MergeTreeSelectProcessor.h\n+++ b/src/Storages/MergeTree/MergeTreeSelectProcessor.h\n@@ -31,17 +31,16 @@ class MergeTreeSelectProcessor : public MergeTreeBaseSelectProcessor\n         const MergeTreeReaderSettings & reader_settings,\n         const Names & virt_column_names = {},\n         size_t part_index_in_query_ = 0,\n-        bool has_limit_below_one_block_ = false);\n+        bool has_limit_below_one_block_ = false,\n+        std::optional<ParallelReadingExtension> extension_ = {});\n \n     ~MergeTreeSelectProcessor() override;\n \n-    /// Closes readers and unlock part locks\n-    void finish();\n-\n protected:\n     /// Defer initialization from constructor, because it may be heavy\n-    /// and it's better to do it lazily in `getNewTask`, which is executing in parallel.\n+    /// and it's better to do it lazily in `getNewTaskImpl`, which is executing in parallel.\n     void initializeReaders();\n+    void finish() override final;\n \n     /// Used by Task\n     Names required_columns;\ndiff --git a/src/Storages/MergeTree/MergeTreeSequentialSource.cpp b/src/Storages/MergeTree/MergeTreeSequentialSource.cpp\nindex df8d6a7c127b..687458ee681a 100644\n--- a/src/Storages/MergeTree/MergeTreeSequentialSource.cpp\n+++ b/src/Storages/MergeTree/MergeTreeSequentialSource.cpp\n@@ -36,6 +36,8 @@ MergeTreeSequentialSource::MergeTreeSequentialSource(\n                 data_part->getMarksCount(), data_part->name, data_part->rows_count);\n     }\n \n+    /// Note, that we don't check setting collaborate_with_coordinator presence, because this source\n+    /// is only used in background merges.\n     addTotalRowsApprox(data_part->rows_count);\n \n     /// Add columns because we don't want to read empty blocks\ndiff --git a/src/Storages/MergeTree/MergeTreeThreadSelectProcessor.cpp b/src/Storages/MergeTree/MergeTreeThreadSelectProcessor.cpp\nindex 6a8ef860c874..6a44da06f1f6 100644\n--- a/src/Storages/MergeTree/MergeTreeThreadSelectProcessor.cpp\n+++ b/src/Storages/MergeTree/MergeTreeThreadSelectProcessor.cpp\n@@ -7,6 +7,10 @@\n namespace DB\n {\n \n+namespace ErrorCodes\n+{\n+    extern const int LOGICAL_ERROR;\n+}\n \n MergeTreeThreadSelectProcessor::MergeTreeThreadSelectProcessor(\n     const size_t thread_,\n@@ -21,12 +25,13 @@ MergeTreeThreadSelectProcessor::MergeTreeThreadSelectProcessor(\n     const PrewhereInfoPtr & prewhere_info_,\n     ExpressionActionsSettings actions_settings,\n     const MergeTreeReaderSettings & reader_settings_,\n-    const Names & virt_column_names_)\n+    const Names & virt_column_names_,\n+    std::optional<ParallelReadingExtension> extension_)\n     :\n     MergeTreeBaseSelectProcessor{\n         pool_->getHeader(), storage_, metadata_snapshot_, prewhere_info_, std::move(actions_settings), max_block_size_rows_,\n         preferred_block_size_bytes_, preferred_max_column_in_block_size_bytes_,\n-        reader_settings_, use_uncompressed_cache_, virt_column_names_},\n+        reader_settings_, use_uncompressed_cache_, virt_column_names_, extension_},\n     thread{thread_},\n     pool{pool_}\n {\n@@ -39,28 +44,61 @@ MergeTreeThreadSelectProcessor::MergeTreeThreadSelectProcessor(\n         min_marks_to_read = (min_marks_to_read_ * fixed_index_granularity + max_block_size_rows - 1)\n             / max_block_size_rows * max_block_size_rows / fixed_index_granularity;\n     }\n+    else if (extension.has_value())\n+    {\n+        /// Parallel reading from replicas is enabled.\n+        /// We try to estimate the average number of bytes in a granule\n+        /// to make one request over the network per one gigabyte of data\n+        /// Actually we will ask MergeTreeReadPool to provide us heavier tasks to read\n+        /// because the most part of each task will be postponed\n+        /// (due to using consistent hash for better cache affinity)\n+        const size_t amount_of_read_bytes_per_one_request = 1024 * 1024 * 1024; // 1GiB\n+        /// In case of reading from compact parts (for which we can't estimate the average size of marks)\n+        /// we will use this value\n+        const size_t empirical_size_of_mark = 1024 * 1024 * 10; // 10 MiB\n+\n+        if (extension->colums_to_read.empty())\n+            throw Exception(ErrorCodes::LOGICAL_ERROR, \"A set of column to read is empty. It is a bug\");\n+\n+        size_t sum_average_marks_size = 0;\n+        auto column_sizes = storage.getColumnSizes();\n+        for (const auto & name : extension->colums_to_read)\n+        {\n+            auto it = column_sizes.find(name);\n+            if (it == column_sizes.end())\n+                continue;\n+            auto size = it->second;\n+\n+            if (size.data_compressed == 0 || size.data_uncompressed == 0 || size.marks == 0)\n+                continue;\n+\n+            sum_average_marks_size += size.data_uncompressed / size.marks;\n+        }\n+\n+        if (sum_average_marks_size == 0)\n+            sum_average_marks_size = empirical_size_of_mark * extension->colums_to_read.size();\n+\n+        min_marks_to_read = extension->count_participating_replicas * amount_of_read_bytes_per_one_request / sum_average_marks_size;\n+    }\n     else\n+    {\n         min_marks_to_read = min_marks_to_read_;\n+    }\n+\n \n     ordered_names = getPort().getHeader().getNames();\n }\n \n /// Requests read task from MergeTreeReadPool and signals whether it got one\n-bool MergeTreeThreadSelectProcessor::getNewTask()\n+bool MergeTreeThreadSelectProcessor::getNewTaskImpl()\n {\n     task = pool->getTask(min_marks_to_read, thread, ordered_names);\n+    return static_cast<bool>(task);\n+}\n \n-    if (!task)\n-    {\n-        /** Close the files (before destroying the object).\n-          * When many sources are created, but simultaneously reading only a few of them,\n-          * buffers don't waste memory.\n-          */\n-        reader.reset();\n-        pre_reader.reset();\n-        return false;\n-    }\n \n+void MergeTreeThreadSelectProcessor::finalizeNewTask()\n+{\n     const std::string part_name = task->data_part->isProjectionPart() ? task->data_part->getParentPart()->name : task->data_part->name;\n \n     /// Allows pool to reduce number of threads in case of too slow reads.\n@@ -99,8 +137,13 @@ bool MergeTreeThreadSelectProcessor::getNewTask()\n     }\n \n     last_readed_part_name = part_name;\n+}\n \n-    return true;\n+\n+void MergeTreeThreadSelectProcessor::finish()\n+{\n+    reader.reset();\n+    pre_reader.reset();\n }\n \n \ndiff --git a/src/Storages/MergeTree/MergeTreeThreadSelectProcessor.h b/src/Storages/MergeTree/MergeTreeThreadSelectProcessor.h\nindex d17b15c36356..110c4fa34e65 100644\n--- a/src/Storages/MergeTree/MergeTreeThreadSelectProcessor.h\n+++ b/src/Storages/MergeTree/MergeTreeThreadSelectProcessor.h\n@@ -11,7 +11,7 @@ class MergeTreeReadPool;\n /** Used in conjunction with MergeTreeReadPool, asking it for more work to do and performing whatever reads it is asked\n   * to perform.\n   */\n-class MergeTreeThreadSelectProcessor : public MergeTreeBaseSelectProcessor\n+class MergeTreeThreadSelectProcessor final : public MergeTreeBaseSelectProcessor\n {\n public:\n     MergeTreeThreadSelectProcessor(\n@@ -27,8 +27,8 @@ class MergeTreeThreadSelectProcessor : public MergeTreeBaseSelectProcessor\n         const PrewhereInfoPtr & prewhere_info_,\n         ExpressionActionsSettings actions_settings,\n         const MergeTreeReaderSettings & reader_settings_,\n-\n-        const Names & virt_column_names_);\n+        const Names & virt_column_names_,\n+        std::optional<ParallelReadingExtension> extension_);\n \n     String getName() const override { return \"MergeTreeThread\"; }\n \n@@ -36,7 +36,13 @@ class MergeTreeThreadSelectProcessor : public MergeTreeBaseSelectProcessor\n \n protected:\n     /// Requests read task from MergeTreeReadPool and signals whether it got one\n-    bool getNewTask() override;\n+    bool getNewTaskImpl() override;\n+\n+    void finalizeNewTask() override;\n+\n+    void finish() override;\n+\n+    bool canUseConsistentHashingForParallelReading() override { return true; }\n \n private:\n     /// \"thread\" index (there are N threads and each thread is assigned index in interval [0..N-1])\ndiff --git a/src/Storages/MergeTree/ParallelReplicasReadingCoordinator.cpp b/src/Storages/MergeTree/ParallelReplicasReadingCoordinator.cpp\nnew file mode 100644\nindex 000000000000..80f438a46dbc\n--- /dev/null\n+++ b/src/Storages/MergeTree/ParallelReplicasReadingCoordinator.cpp\n@@ -0,0 +1,143 @@\n+#include <Storages/MergeTree/ParallelReplicasReadingCoordinator.h>\n+\n+#include <algorithm>\n+#include <vector>\n+#include <compare>\n+#include <numeric>\n+#include <unordered_map>\n+#include <map>\n+#include <iostream>\n+#include <set>\n+#include <cassert>\n+\n+\n+#include <base/logger_useful.h>\n+#include <base/types.h>\n+#include <base/scope_guard.h>\n+#include <Common/Stopwatch.h>\n+#include \"IO/WriteBufferFromString.h\"\n+#include <Storages/MergeTree/MarkRange.h>\n+#include <Storages/MergeTree/IntersectionsIndexes.h>\n+\n+namespace DB\n+{\n+\n+class ParallelReplicasReadingCoordinator::Impl\n+{\n+public:\n+    using PartitionReadRequestPtr = std::unique_ptr<PartitionReadRequest>;\n+    using PartToMarkRanges = std::map<PartToRead::PartAndProjectionNames, HalfIntervals>;\n+\n+    struct PartitionReading\n+    {\n+        PartSegments part_ranges;\n+        PartToMarkRanges mark_ranges_in_part;\n+    };\n+\n+    using PartitionToBlockRanges = std::map<String, PartitionReading>;\n+    PartitionToBlockRanges partitions;\n+\n+    std::mutex mutex;\n+\n+    PartitionReadResponse handleRequest(PartitionReadRequest request);\n+};\n+\n+\n+PartitionReadResponse ParallelReplicasReadingCoordinator::Impl::handleRequest(PartitionReadRequest request)\n+{\n+    AtomicStopwatch watch;\n+    std::lock_guard lock(mutex);\n+\n+    auto partition_it = partitions.find(request.partition_id);\n+\n+    SCOPE_EXIT({\n+        LOG_TRACE(&Poco::Logger::get(\"ParallelReplicasReadingCoordinator\"), \"Time for handling request: {}ns\", watch.elapsed());\n+    });\n+\n+    PartToRead::PartAndProjectionNames part_and_projection\n+    {\n+        .part = request.part_name,\n+        .projection = request.projection_name\n+    };\n+\n+    /// We are the first who wants to process parts in partition\n+    if (partition_it == partitions.end())\n+    {\n+        PartitionReading partition_reading;\n+\n+        PartToRead part_to_read;\n+        part_to_read.range = request.block_range;\n+        part_to_read.name = part_and_projection;\n+\n+        partition_reading.part_ranges.addPart(std::move(part_to_read));\n+\n+        /// As this query is first in partition, we will accept all ranges from it.\n+        /// We need just to update our state.\n+        auto request_ranges = HalfIntervals::initializeFromMarkRanges(request.mark_ranges);\n+        auto mark_ranges_index = HalfIntervals::initializeWithEntireSpace();\n+        mark_ranges_index.intersect(request_ranges.negate());\n+\n+        partition_reading.mark_ranges_in_part.insert({part_and_projection, std::move(mark_ranges_index)});\n+        partitions.insert({request.partition_id, std::move(partition_reading)});\n+\n+        return {.denied = false, .mark_ranges = std::move(request.mark_ranges)};\n+    }\n+\n+    auto & partition_reading = partition_it->second;\n+\n+    PartToRead part_to_read;\n+    part_to_read.range = request.block_range;\n+    part_to_read.name = part_and_projection;\n+\n+    auto part_intersection_res = partition_reading.part_ranges.getIntersectionResult(part_to_read);\n+\n+    switch (part_intersection_res)\n+    {\n+        case PartSegments::IntersectionResult::REJECT:\n+        {\n+            return {.denied = true, .mark_ranges = {}};\n+        }\n+        case PartSegments::IntersectionResult::EXACTLY_ONE_INTERSECTION:\n+        {\n+            auto marks_it = partition_reading.mark_ranges_in_part.find(part_and_projection);\n+\n+            auto & intervals_to_do = marks_it->second;\n+            auto result = HalfIntervals::initializeFromMarkRanges(request.mark_ranges);\n+            result.intersect(intervals_to_do);\n+\n+            /// Update intervals_to_do\n+            intervals_to_do.intersect(HalfIntervals::initializeFromMarkRanges(std::move(request.mark_ranges)).negate());\n+\n+            auto result_ranges = result.convertToMarkRangesFinal();\n+            const bool denied = result_ranges.empty();\n+            return {.denied = denied, .mark_ranges = std::move(result_ranges)};\n+        }\n+        case PartSegments::IntersectionResult::NO_INTERSECTION:\n+        {\n+            partition_reading.part_ranges.addPart(std::move(part_to_read));\n+\n+            auto mark_ranges_index = HalfIntervals::initializeWithEntireSpace().intersect(\n+            HalfIntervals::initializeFromMarkRanges(request.mark_ranges).negate()\n+            );\n+            partition_reading.mark_ranges_in_part.insert({part_and_projection, std::move(mark_ranges_index)});\n+\n+            return {.denied = false, .mark_ranges = std::move(request.mark_ranges)};\n+        }\n+    }\n+\n+    __builtin_unreachable();\n+}\n+\n+PartitionReadResponse ParallelReplicasReadingCoordinator::handleRequest(PartitionReadRequest request)\n+{\n+    return pimpl->handleRequest(std::move(request));\n+}\n+\n+ParallelReplicasReadingCoordinator::ParallelReplicasReadingCoordinator()\n+{\n+    pimpl = std::make_unique<ParallelReplicasReadingCoordinator::Impl>();\n+}\n+\n+ParallelReplicasReadingCoordinator::~ParallelReplicasReadingCoordinator() = default;\n+\n+}\ndiff --git a/src/Storages/MergeTree/ParallelReplicasReadingCoordinator.h b/src/Storages/MergeTree/ParallelReplicasReadingCoordinator.h\nnew file mode 100644\nindex 000000000000..af74e0fae49b\n--- /dev/null\n+++ b/src/Storages/MergeTree/ParallelReplicasReadingCoordinator.h\n@@ -0,0 +1,20 @@\n+#pragma once\n+\n+#include <memory>\n+#include <Storages/MergeTree/RequestResponse.h>\n+\n+namespace DB\n+{\n+\n+class ParallelReplicasReadingCoordinator\n+{\n+public:\n+    ParallelReplicasReadingCoordinator();\n+    ~ParallelReplicasReadingCoordinator();\n+    PartitionReadResponse handleRequest(PartitionReadRequest request);\n+private:\n+    class Impl;\n+    std::unique_ptr<Impl> pimpl;\n+};\n+\n+}\ndiff --git a/src/Storages/MergeTree/RequestResponse.cpp b/src/Storages/MergeTree/RequestResponse.cpp\nnew file mode 100644\nindex 000000000000..a266540b99ad\n--- /dev/null\n+++ b/src/Storages/MergeTree/RequestResponse.cpp\n@@ -0,0 +1,141 @@\n+#include <Storages/MergeTree/RequestResponse.h>\n+\n+#include <Core/ProtocolDefines.h>\n+#include <Common/SipHash.h>\n+#include <IO/WriteHelpers.h>\n+#include <IO/ReadHelpers.h>\n+\n+#include <consistent_hashing.h>\n+\n+namespace DB\n+{\n+\n+namespace ErrorCodes\n+{\n+    extern const int UNKNOWN_PROTOCOL;\n+}\n+\n+static void readMarkRangesBinary(MarkRanges & ranges, ReadBuffer & buf, size_t MAX_RANGES_SIZE = DEFAULT_MAX_STRING_SIZE)\n+{\n+    size_t size = 0;\n+    readVarUInt(size, buf);\n+\n+    if (size > MAX_RANGES_SIZE)\n+        throw Poco::Exception(\"Too large ranges size.\");\n+\n+    ranges.resize(size);\n+    for (size_t i = 0; i < size; ++i)\n+    {\n+        readBinary(ranges[i].begin, buf);\n+        readBinary(ranges[i].end, buf);\n+    }\n+}\n+\n+\n+static void writeMarkRangesBinary(const MarkRanges & ranges, WriteBuffer & buf)\n+{\n+    writeVarUInt(ranges.size(), buf);\n+\n+    for (const auto & [begin, end] : ranges)\n+    {\n+        writeBinary(begin, buf);\n+        writeBinary(end, buf);\n+    }\n+}\n+\n+\n+void PartitionReadRequest::serialize(WriteBuffer & out) const\n+{\n+    /// Must be the first\n+    writeVarUInt(DBMS_PARALLEL_REPLICAS_PROTOCOL_VERSION, out);\n+\n+    writeStringBinary(partition_id, out);\n+    writeStringBinary(part_name, out);\n+    writeStringBinary(projection_name, out);\n+\n+    writeVarInt(block_range.begin, out);\n+    writeVarInt(block_range.end, out);\n+\n+    writeMarkRangesBinary(mark_ranges, out);\n+}\n+\n+\n+void PartitionReadRequest::describe(WriteBuffer & out) const\n+{\n+    String result;\n+    result += fmt::format(\"partition_id: {} \\n\", partition_id);\n+    result += fmt::format(\"part_name: {} \\n\", part_name);\n+    result += fmt::format(\"projection_name: {} \\n\", projection_name);\n+    result += fmt::format(\"block_range: ({}, {}) \\n\", block_range.begin, block_range.end);\n+    result += \"mark_ranges: \";\n+    for (const auto & range : mark_ranges)\n+        result += fmt::format(\"({}, {}) \", range.begin, range.end);\n+    result += '\\n';\n+    out.write(result.c_str(), result.size());\n+}\n+\n+void PartitionReadRequest::deserialize(ReadBuffer & in)\n+{\n+    UInt64 version;\n+    readVarUInt(version, in);\n+    if (version != DBMS_PARALLEL_REPLICAS_PROTOCOL_VERSION)\n+        throw Exception(ErrorCodes::UNKNOWN_PROTOCOL, \"Protocol versions for parallel reading \\\n+            from replicas differ. Got: {}, supported version: {}\",\n+            version, DBMS_PARALLEL_REPLICAS_PROTOCOL_VERSION);\n+\n+    readStringBinary(partition_id, in);\n+    readStringBinary(part_name, in);\n+    readStringBinary(projection_name, in);\n+\n+    readVarInt(block_range.begin, in);\n+    readVarInt(block_range.end, in);\n+\n+    readMarkRangesBinary(mark_ranges, in);\n+}\n+\n+UInt64 PartitionReadRequest::getConsistentHash(size_t buckets) const\n+{\n+    auto hash = SipHash();\n+    hash.update(partition_id);\n+    hash.update(part_name);\n+    hash.update(projection_name);\n+\n+    hash.update(block_range.begin);\n+    hash.update(block_range.end);\n+\n+    for (const auto & range : mark_ranges)\n+    {\n+        hash.update(range.begin);\n+        hash.update(range.end);\n+    }\n+\n+    return ConsistentHashing(hash.get64(), buckets);\n+}\n+\n+\n+void PartitionReadResponse::serialize(WriteBuffer & out) const\n+{\n+    /// Must be the first\n+    writeVarUInt(DBMS_PARALLEL_REPLICAS_PROTOCOL_VERSION, out);\n+\n+    writeVarUInt(static_cast<UInt64>(denied), out);\n+    writeMarkRangesBinary(mark_ranges, out);\n+}\n+\n+\n+void PartitionReadResponse::deserialize(ReadBuffer & in)\n+{\n+    UInt64 version;\n+    readVarUInt(version, in);\n+    if (version != DBMS_PARALLEL_REPLICAS_PROTOCOL_VERSION)\n+        throw Exception(ErrorCodes::UNKNOWN_PROTOCOL, \"Protocol versions for parallel reading \\\n+            from replicas differ. Got: {}, supported version: {}\",\n+            version, DBMS_PARALLEL_REPLICAS_PROTOCOL_VERSION);\n+\n+    UInt64 value;\n+    readVarUInt(value, in);\n+    denied = static_cast<bool>(value);\n+    readMarkRangesBinary(mark_ranges, in);\n+}\n+\n+}\ndiff --git a/src/Storages/MergeTree/RequestResponse.h b/src/Storages/MergeTree/RequestResponse.h\nnew file mode 100644\nindex 000000000000..85c8f7181af2\n--- /dev/null\n+++ b/src/Storages/MergeTree/RequestResponse.h\n@@ -0,0 +1,57 @@\n+#pragma once\n+\n+#include <functional>\n+#include <optional>\n+\n+#include <base/types.h>\n+\n+#include <IO/WriteBuffer.h>\n+#include <IO/ReadBuffer.h>\n+\n+#include <Storages/MergeTree/MarkRange.h>\n+\n+\n+namespace DB\n+{\n+\n+/// Represents a segment [left; right]\n+struct PartBlockRange\n+{\n+    Int64 begin;\n+    Int64 end;\n+\n+    bool operator==(const PartBlockRange & rhs) const\n+    {\n+        return begin == rhs.begin && end == rhs.end;\n+    }\n+};\n+\n+struct PartitionReadRequest\n+{\n+    String partition_id;\n+    String part_name;\n+    String projection_name;\n+    PartBlockRange block_range;\n+    MarkRanges mark_ranges;\n+\n+    void serialize(WriteBuffer & out) const;\n+    void describe(WriteBuffer & out) const;\n+    void deserialize(ReadBuffer & in);\n+\n+    UInt64 getConsistentHash(size_t buckets) const;\n+};\n+\n+struct PartitionReadResponse\n+{\n+    bool denied{false};\n+    MarkRanges mark_ranges{};\n+\n+    void serialize(WriteBuffer & out) const;\n+    void deserialize(ReadBuffer & in);\n+};\n+\n+\n+using MergeTreeReadTaskCallback = std::function<std::optional<PartitionReadResponse>(PartitionReadRequest)>;\n+\n+\n+}\ndiff --git a/src/Storages/StorageDistributed.cpp b/src/Storages/StorageDistributed.cpp\nindex a45afd847e6a..e033d319fc8c 100644\n--- a/src/Storages/StorageDistributed.cpp\n+++ b/src/Storages/StorageDistributed.cpp\n@@ -110,6 +110,7 @@ namespace ErrorCodes\n     extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n     extern const int INCORRECT_NUMBER_OF_COLUMNS;\n     extern const int INFINITE_LOOP;\n+    extern const int ILLEGAL_FINAL;\n     extern const int TYPE_MISMATCH;\n     extern const int TOO_MANY_ROWS;\n     extern const int UNABLE_TO_SKIP_UNUSED_SHARDS;\n@@ -273,7 +274,7 @@ size_t getClusterQueriedNodes(const Settings & settings, const ClusterPtr & clus\n {\n     size_t num_local_shards = cluster->getLocalShardCount();\n     size_t num_remote_shards = cluster->getRemoteShardCount();\n-    return (num_remote_shards * settings.max_parallel_replicas) + num_local_shards;\n+    return (num_remote_shards + num_local_shards) * settings.max_parallel_replicas;\n }\n \n }\n@@ -590,6 +591,10 @@ void StorageDistributed::read(\n     const size_t /*max_block_size*/,\n     const unsigned /*num_streams*/)\n {\n+    const auto * select_query = query_info.query->as<ASTSelectQuery>();\n+    if (select_query->final() && local_context->getSettingsRef().allow_experimental_parallel_reading_from_replicas)\n+        throw Exception(ErrorCodes::ILLEGAL_FINAL, \"Final modifier is not allowed together with parallel reading from replicas feature\");\n+\n     const auto & modified_query_ast = rewriteSelectQuery(\n         query_info.query, remote_database, remote_table, remote_table_function_ptr);\n \ndiff --git a/src/Storages/StorageMergeTree.cpp b/src/Storages/StorageMergeTree.cpp\nindex 8a3d786532ea..470a406dbe4d 100644\n--- a/src/Storages/StorageMergeTree.cpp\n+++ b/src/Storages/StorageMergeTree.cpp\n@@ -191,7 +191,14 @@ void StorageMergeTree::read(\n     size_t max_block_size,\n     unsigned num_streams)\n {\n-    if (auto plan = reader.read(column_names, metadata_snapshot, query_info, local_context, max_block_size, num_streams, processed_stage))\n+    /// If true, then we will ask initiator if we can read chosen ranges\n+    bool enable_parallel_reading = local_context->getClientInfo().collaborate_with_initiator;\n+\n+    if (enable_parallel_reading)\n+        LOG_TRACE(log, \"Parallel reading from replicas enabled {}\", enable_parallel_reading);\n+\n+    if (auto plan = reader.read(\n+        column_names, metadata_snapshot, query_info, local_context, max_block_size, num_streams, processed_stage, nullptr, enable_parallel_reading))\n         query_plan = std::move(*plan);\n }\n \ndiff --git a/src/Storages/StorageReplicatedMergeTree.cpp b/src/Storages/StorageReplicatedMergeTree.cpp\nindex 852e2b10e6cb..132d69344a12 100644\n--- a/src/Storages/StorageReplicatedMergeTree.cpp\n+++ b/src/Storages/StorageReplicatedMergeTree.cpp\n@@ -48,8 +48,10 @@\n #include <Parsers/ASTSetQuery.h>\n \n #include <Processors/QueryPlan/QueryPlan.h>\n+#include <Processors/Sources/RemoteSource.h>\n #include <Processors/QueryPlan/BuildQueryPipelineSettings.h>\n #include <Processors/QueryPlan/Optimizations/QueryPlanOptimizationSettings.h>\n+#include <Processors/QueryPlan/ReadFromPreparedSource.h>\n \n #include <IO/ReadBufferFromString.h>\n #include <IO/Operators.h>\n@@ -61,6 +63,8 @@\n #include <Interpreters/Context.h>\n #include <Interpreters/DDLTask.h>\n #include <Interpreters/InterserverCredentials.h>\n+#include <Interpreters/SelectQueryOptions.h>\n+#include <Interpreters/InterpreterSelectQuery.h>\n \n #include <Poco/DirectoryIterator.h>\n \n@@ -4227,6 +4231,9 @@ void StorageReplicatedMergeTree::read(\n     const size_t max_block_size,\n     const unsigned num_streams)\n {\n+    /// If true, then we will ask initiator if we can read chosen ranges\n+    const bool enable_parallel_reading = local_context->getClientInfo().collaborate_with_initiator;\n+\n     /** The `select_sequential_consistency` setting has two meanings:\n     * 1. To throw an exception if on a replica there are not all parts which have been written down on quorum of remaining replicas.\n     * 2. Do not read parts that have not yet been written to the quorum of the replicas.\n@@ -4236,13 +4243,18 @@ void StorageReplicatedMergeTree::read(\n     {\n         auto max_added_blocks = std::make_shared<ReplicatedMergeTreeQuorumAddedParts::PartitionIdToMaxBlock>(getMaxAddedBlocks());\n         if (auto plan = reader.read(\n-                column_names, metadata_snapshot, query_info, local_context, max_block_size, num_streams, processed_stage, std::move(max_added_blocks)))\n+                column_names, metadata_snapshot, query_info, local_context,\n+                max_block_size, num_streams, processed_stage, std::move(max_added_blocks), enable_parallel_reading))\n             query_plan = std::move(*plan);\n         return;\n     }\n \n-    if (auto plan = reader.read(column_names, metadata_snapshot, query_info, local_context, max_block_size, num_streams, processed_stage))\n+    if (auto plan = reader.read(\n+        column_names, metadata_snapshot, query_info, local_context,\n+        max_block_size, num_streams, processed_stage, nullptr, enable_parallel_reading))\n+    {\n         query_plan = std::move(*plan);\n+    }\n }\n \n Pipe StorageReplicatedMergeTree::read(\ndiff --git a/src/Storages/StorageS3Cluster.cpp b/src/Storages/StorageS3Cluster.cpp\nindex f49fd35044d6..659071b392d6 100644\n--- a/src/Storages/StorageS3Cluster.cpp\n+++ b/src/Storages/StorageS3Cluster.cpp\n@@ -126,7 +126,7 @@ Pipe StorageS3Cluster::read(\n                 scalars,\n                 Tables(),\n                 processed_stage,\n-                callback);\n+                RemoteQueryExecutor::Extension{.task_iterator = callback});\n \n             pipes.emplace_back(std::make_shared<RemoteSource>(remote_query_executor, add_agg_info, false));\n         }\ndiff --git a/src/Storages/System/StorageSystemPartsColumns.cpp b/src/Storages/System/StorageSystemPartsColumns.cpp\nindex 33ec5c457f66..8dbd73628cac 100644\n--- a/src/Storages/System/StorageSystemPartsColumns.cpp\n+++ b/src/Storages/System/StorageSystemPartsColumns.cpp\n@@ -206,7 +206,7 @@ void StorageSystemPartsColumns::processNextStorage(\n                     columns[res_index++]->insertDefault();\n             }\n \n-            ColumnSize column_size = part->getColumnSize(column.name, *column.type);\n+            ColumnSize column_size = part->getColumnSize(column.name);\n             if (columns_mask[src_index++])\n                 columns[res_index++]->insert(column_size.data_compressed + column_size.marks);\n             if (columns_mask[src_index++])\ndiff --git a/src/Storages/System/StorageSystemProjectionPartsColumns.cpp b/src/Storages/System/StorageSystemProjectionPartsColumns.cpp\nindex bdbe9a468463..f6490177014c 100644\n--- a/src/Storages/System/StorageSystemProjectionPartsColumns.cpp\n+++ b/src/Storages/System/StorageSystemProjectionPartsColumns.cpp\n@@ -237,7 +237,7 @@ void StorageSystemProjectionPartsColumns::processNextStorage(\n                     columns[res_index++]->insertDefault();\n             }\n \n-            ColumnSize column_size = part->getColumnSize(column.name, *column.type);\n+            ColumnSize column_size = part->getColumnSize(column.name);\n             if (columns_mask[src_index++])\n                 columns[res_index++]->insert(column_size.data_compressed + column_size.marks);\n             if (columns_mask[src_index++])\n",
  "test_patch": "diff --git a/docker/test/stateful/run.sh b/docker/test/stateful/run.sh\nindex 680392df43eb..f8dee0f8bc94 100755\n--- a/docker/test/stateful/run.sh\n+++ b/docker/test/stateful/run.sh\n@@ -61,6 +61,7 @@ chmod 777 -R /var/lib/clickhouse\n clickhouse-client --query \"SHOW DATABASES\"\n \n clickhouse-client --query \"ATTACH DATABASE datasets ENGINE = Ordinary\"\n+\n service clickhouse-server restart\n \n # Wait for server to start accepting connections\n@@ -109,8 +110,13 @@ function run_tests()\n     fi\n \n     set +e\n-    clickhouse-test --testname --shard --zookeeper --check-zookeeper-session --no-stateless --hung-check --print-time \"${ADDITIONAL_OPTIONS[@]}\" \\\n+    clickhouse-test --testname --shard --zookeeper --check-zookeeper-session --no-stateless --hung-check --print-time \\\n+        --skip 00168_parallel_processing_on_replicas \"${ADDITIONAL_OPTIONS[@]}\" \\\n         \"$SKIP_TESTS_OPTION\" 2>&1 | ts '%Y-%m-%d %H:%M:%S' | tee test_output/test_result.txt\n+\n+    clickhouse-test --timeout 1200 --testname --shard --zookeeper --check-zookeeper-session --no-stateless --hung-check --print-time \\\n+    00168_parallel_processing_on_replicas \"${ADDITIONAL_OPTIONS[@]}\" 2>&1 | ts '%Y-%m-%d %H:%M:%S' | tee -a test_output/test_result.txt\n+\n     set -e\n }\n \ndiff --git a/src/Storages/MergeTree/tests/gtest_coordinator.cpp b/src/Storages/MergeTree/tests/gtest_coordinator.cpp\nnew file mode 100644\nindex 000000000000..7bcf3304c2b0\n--- /dev/null\n+++ b/src/Storages/MergeTree/tests/gtest_coordinator.cpp\n@@ -0,0 +1,240 @@\n+#include <gtest/gtest.h>\n+\n+#include <utility>\n+#include <limits>\n+#include <set>\n+\n+#include <Storages/MergeTree/IntersectionsIndexes.h>\n+\n+#include <Storages/MergeTree/ParallelReplicasReadingCoordinator.h>\n+\n+using namespace DB;\n+\n+\n+TEST(HalfIntervals, Simple)\n+{\n+    ASSERT_TRUE((\n+        HalfIntervals{{{1, 2}, {3, 4}}}.negate() ==\n+        HalfIntervals{{{0, 1}, {2, 3}, {4, 18446744073709551615UL}}}\n+    ));\n+\n+    {\n+        auto left = HalfIntervals{{{0, 2}, {4, 6}}}.negate();\n+        ASSERT_TRUE((\n+            left ==\n+            HalfIntervals{{{2, 4}, {6, 18446744073709551615UL}}}\n+        ));\n+    }\n+\n+    {\n+        auto left = HalfIntervals{{{0, 2}, {4, 6}}};\n+        auto right = HalfIntervals{{{1, 5}}}.negate();\n+        auto intersection = left.intersect(right);\n+\n+        ASSERT_TRUE((\n+            intersection ==\n+            HalfIntervals{{{0, 1}, {5, 6}}}\n+        ));\n+    }\n+\n+    {\n+        auto left = HalfIntervals{{{1, 2}, {2, 3}}};\n+        auto right = HalfIntervals::initializeWithEntireSpace();\n+        auto intersection = right.intersect(left.negate());\n+\n+        ASSERT_TRUE((\n+            intersection ==\n+            HalfIntervals{{{0, 1}, {3, 18446744073709551615UL}}}\n+        ));\n+    }\n+\n+    {\n+        auto left = HalfIntervals{{{1, 2}, {2, 3}, {3, 4}, {4, 5}}};\n+\n+        ASSERT_EQ(getIntersection(left, HalfIntervals{{{1, 4}}}).convertToMarkRangesFinal().size(), 3);\n+        ASSERT_EQ(getIntersection(left, HalfIntervals{{{1, 5}}}).convertToMarkRangesFinal().size(), 4);\n+    }\n+\n+    {\n+        auto left = HalfIntervals{{{1, 3}, {3, 5}, {5, 7}}};\n+\n+        ASSERT_EQ(getIntersection(left, HalfIntervals{{{3, 5}}}).convertToMarkRangesFinal().size(), 1);\n+        ASSERT_EQ(getIntersection(left, HalfIntervals{{{3, 7}}}).convertToMarkRangesFinal().size(), 2);\n+        ASSERT_EQ(getIntersection(left, HalfIntervals{{{4, 6}}}).convertToMarkRangesFinal().size(), 2);\n+        ASSERT_EQ(getIntersection(left, HalfIntervals{{{1, 7}}}).convertToMarkRangesFinal().size(), 3);\n+    }\n+\n+    {\n+        auto left = HalfIntervals{{{1, 3}}};\n+\n+        ASSERT_EQ(getIntersection(left, HalfIntervals{{{3, 4}}}).convertToMarkRangesFinal().size(), 0);\n+    }\n+\n+    {\n+        auto left = HalfIntervals{{{1, 2}, {3, 4}, {5, 6}}};\n+\n+        ASSERT_EQ(getIntersection(left, HalfIntervals{{{2, 3}}}).convertToMarkRangesFinal().size(), 0);\n+        ASSERT_EQ(getIntersection(left, HalfIntervals{{{4, 5}}}).convertToMarkRangesFinal().size(), 0);\n+        ASSERT_EQ(getIntersection(left, HalfIntervals{{{1, 6}}}).convertToMarkRangesFinal().size(), 3);\n+    }\n+}\n+\n+TEST(HalfIntervals, TwoRequests)\n+{\n+    auto left = HalfIntervals{{{1, 2}, {2, 3}}};\n+    auto right = HalfIntervals{{{2, 3}, {3, 4}}};\n+    auto intersection = left.intersect(right);\n+\n+    ASSERT_TRUE((\n+        intersection ==\n+        HalfIntervals{{{2, 3}}}\n+    ));\n+\n+    /// With negation\n+    left = HalfIntervals{{{1, 2}, {2, 3}}}.negate();\n+    right = HalfIntervals{{{2, 3}, {3, 4}}};\n+    intersection = left.intersect(right);\n+\n+\n+    ASSERT_TRUE((\n+        intersection ==\n+        HalfIntervals{{{3, 4}}}\n+    ));\n+}\n+\n+TEST(HalfIntervals, SelfIntersection)\n+{\n+    auto left = HalfIntervals{{{1, 2}, {2, 3}, {4, 5}}};\n+    auto right = left;\n+    auto intersection = left.intersect(right);\n+\n+    ASSERT_TRUE((\n+        intersection == right\n+    ));\n+\n+    left = HalfIntervals{{{1, 2}, {2, 3}, {4, 5}}};\n+    right = left;\n+    right.negate();\n+    intersection = left.intersect(right);\n+\n+    ASSERT_TRUE((\n+        intersection == HalfIntervals{}\n+    ));\n+}\n+\n+\n+TEST(Coordinator, Simple)\n+{\n+    PartitionReadRequest request;\n+    request.partition_id = \"a\";\n+    request.part_name = \"b\";\n+    request.projection_name = \"c\";\n+    request.block_range = PartBlockRange{1, 2};\n+    request.mark_ranges = MarkRanges{{1, 2}, {3, 4}};\n+\n+    ParallelReplicasReadingCoordinator coordinator;\n+    auto response = coordinator.handleRequest(request);\n+\n+    ASSERT_FALSE(response.denied) << \"Process request at first has to be accepted\";\n+\n+    ASSERT_EQ(response.mark_ranges.size(), request.mark_ranges.size());\n+\n+    for (int i = 0; i < response.mark_ranges.size(); ++i)\n+        EXPECT_EQ(response.mark_ranges[i], request.mark_ranges[i]);\n+\n+    response = coordinator.handleRequest(request);\n+    ASSERT_TRUE(response.denied) << \"Process the same request second time\";\n+}\n+\n+\n+TEST(Coordinator, TwoRequests)\n+{\n+    PartitionReadRequest first;\n+    first.partition_id = \"a\";\n+    first.part_name = \"b\";\n+    first.projection_name = \"c\";\n+    first.block_range = PartBlockRange{0, 0};\n+    first.mark_ranges = MarkRanges{{1, 2}, {2, 3}};\n+\n+    auto second = first;\n+    second.mark_ranges = MarkRanges{{2, 3}, {3, 4}};\n+\n+    ParallelReplicasReadingCoordinator coordinator;\n+    auto response = coordinator.handleRequest(first);\n+\n+    ASSERT_FALSE(response.denied) << \"First request must me accepted\";\n+\n+    ASSERT_EQ(response.mark_ranges.size(), first.mark_ranges.size());\n+    for (int i = 0; i < response.mark_ranges.size(); ++i)\n+        EXPECT_EQ(response.mark_ranges[i], first.mark_ranges[i]);\n+\n+    response = coordinator.handleRequest(second);\n+    ASSERT_FALSE(response.denied);\n+    ASSERT_EQ(response.mark_ranges.size(), 1);\n+    ASSERT_EQ(response.mark_ranges.front(), (MarkRange{3, 4}));\n+}\n+\n+\n+TEST(Coordinator, PartIntersections)\n+{\n+    {\n+        PartSegments boundaries;\n+\n+        boundaries.addPart(PartToRead{{1, 1}, {\"TestPart\", \"TestProjection\"}});\n+        boundaries.addPart(PartToRead{{2, 2}, {\"TestPart\", \"TestProjection\"}});\n+        boundaries.addPart(PartToRead{{3, 3}, {\"TestPart\", \"TestProjection\"}});\n+        boundaries.addPart(PartToRead{{4, 4}, {\"TestPart\", \"TestProjection\"}});\n+\n+        ASSERT_EQ(boundaries.getIntersectionResult({{1, 4}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::REJECT);\n+        ASSERT_EQ(boundaries.getIntersectionResult({{0, 5}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::REJECT);\n+        ASSERT_EQ(boundaries.getIntersectionResult({{1, 1}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::EXACTLY_ONE_INTERSECTION);\n+        ASSERT_EQ(boundaries.getIntersectionResult({{1, 1}, {\"ClickHouse\", \"AnotherProjection\"}}), PartSegments::IntersectionResult::REJECT);\n+        ASSERT_EQ(boundaries.getIntersectionResult({{1, 2}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::REJECT);\n+\n+        boundaries.addPart(PartToRead{{5, 5}, {\"TestPart\", \"TestProjection\"}});\n+        boundaries.addPart(PartToRead{{0, 0}, {\"TestPart\", \"TestProjection\"}});\n+\n+        ASSERT_EQ(boundaries.getIntersectionResult({{0, 5}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::REJECT);\n+        ASSERT_EQ(boundaries.getIntersectionResult({{1, 1}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::EXACTLY_ONE_INTERSECTION);\n+        ASSERT_EQ(boundaries.getIntersectionResult({{1, 1}, {\"ClickHouse\", \"AnotherProjection\"}}), PartSegments::IntersectionResult::REJECT);\n+        ASSERT_EQ(boundaries.getIntersectionResult({{1, 2}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::REJECT);\n+        ASSERT_EQ(boundaries.getIntersectionResult({{0, 3}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::REJECT);\n+    }\n+\n+    {\n+        PartSegments boundaries;\n+        boundaries.addPart(PartToRead{{1, 3}, {\"TestPart\", \"TestProjection\"}});\n+        boundaries.addPart(PartToRead{{4, 5}, {\"TestPart\", \"TestProjection\"}});\n+\n+        ASSERT_EQ(boundaries.getIntersectionResult({{2, 4}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::REJECT);\n+        ASSERT_EQ(boundaries.getIntersectionResult({{0, 6}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::REJECT);\n+    }\n+\n+    {\n+        PartSegments boundaries;\n+        boundaries.addPart(PartToRead{{1, 3}, {\"TestPart\", \"TestProjection\"}});\n+        boundaries.addPart(PartToRead{{4, 6}, {\"TestPart\", \"TestProjection\"}});\n+        boundaries.addPart(PartToRead{{7, 9}, {\"TestPart\", \"TestProjection\"}});\n+\n+        ASSERT_EQ(boundaries.getIntersectionResult({{2, 8}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::REJECT);\n+        ASSERT_EQ(boundaries.getIntersectionResult({{4, 6}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::EXACTLY_ONE_INTERSECTION);\n+        ASSERT_EQ(boundaries.getIntersectionResult({{3, 7}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::REJECT);\n+        ASSERT_EQ(boundaries.getIntersectionResult({{5, 7}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::REJECT);\n+    }\n+\n+    {\n+        PartSegments boundaries;\n+\n+        ASSERT_EQ(boundaries.getIntersectionResult({{1, 1}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::NO_INTERSECTION);\n+        ASSERT_EQ(boundaries.getIntersectionResult({{1, 3}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::NO_INTERSECTION);\n+        ASSERT_EQ(boundaries.getIntersectionResult({{0, 100500}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::NO_INTERSECTION);\n+\n+        boundaries.addPart(PartToRead{{1, 1}, {\"TestPart\", \"TestProjection\"}});\n+        boundaries.addPart(PartToRead{{2, 2}, {\"TestPart\", \"TestProjection\"}});\n+        boundaries.addPart(PartToRead{{3, 3}, {\"TestPart\", \"TestProjection\"}});\n+\n+        ASSERT_EQ(boundaries.getIntersectionResult({{1, 1}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::EXACTLY_ONE_INTERSECTION);\n+        ASSERT_EQ(boundaries.getIntersectionResult({{1, 3}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::REJECT);\n+        ASSERT_EQ(boundaries.getIntersectionResult({{100, 100500}, {\"TestPart\", \"TestProjection\"}}), PartSegments::IntersectionResult::NO_INTERSECTION);\n+    }\n+}\ndiff --git a/tests/queries/0_stateless/00124_shard_distributed_with_many_replicas.sql b/tests/queries/0_stateless/00124_shard_distributed_with_many_replicas.sql\nindex 6bc5fe268d6c..f9cbf92db41f 100644\n--- a/tests/queries/0_stateless/00124_shard_distributed_with_many_replicas.sql\n+++ b/tests/queries/0_stateless/00124_shard_distributed_with_many_replicas.sql\n@@ -1,7 +1,6 @@\n -- Tags: replica, distributed\n \n SET max_parallel_replicas = 2;\n-\n DROP TABLE IF EXISTS report;\n \n CREATE TABLE report(id UInt32, event_date Date, priority UInt32, description String) ENGINE = MergeTree(event_date, intHash32(id), (id, event_date, intHash32(id)), 8192);\ndiff --git a/tests/queries/0_stateless/01870_modulo_partition_key.sql b/tests/queries/0_stateless/01870_modulo_partition_key.sql\nindex 06b6fc86d3ea..3d839de9c644 100644\n--- a/tests/queries/0_stateless/01870_modulo_partition_key.sql\n+++ b/tests/queries/0_stateless/01870_modulo_partition_key.sql\n@@ -50,7 +50,7 @@ SELECT count() FROM table4 WHERE id % 10 = 7;\n SELECT 'comparison:';\n SELECT v, v-205 as vv, modulo(vv, 200), moduloLegacy(vv, 200) FROM table1 ORDER BY v;\n \n-DROP TABLE table1;\n-DROP TABLE table2;\n-DROP TABLE table3;\n-DROP TABLE table4;\n+DROP TABLE table1 SYNC;\n+DROP TABLE table2 SYNC;\n+DROP TABLE table3 SYNC;\n+DROP TABLE table4 SYNC;\ndiff --git a/tests/queries/1_stateful/00168_parallel_processing_on_replicas_part_1.reference b/tests/queries/1_stateful/00168_parallel_processing_on_replicas_part_1.reference\nnew file mode 100644\nindex 000000000000..2675904dea0a\n--- /dev/null\n+++ b/tests/queries/1_stateful/00168_parallel_processing_on_replicas_part_1.reference\n@@ -0,0 +1,110 @@\n+Testing 00001_count_hits.sql ----> Ok! \u2705\n+Testing 00002_count_visits.sql ----> Ok! \u2705\n+Testing 00004_top_counters.sql ----> Ok! \u2705\n+Testing 00005_filtering.sql ----> Ok! \u2705\n+Testing 00006_agregates.sql ----> Ok! \u2705\n+Testing 00007_uniq.sql ----> Ok! \u2705\n+Testing 00008_uniq.sql ----> Ok! \u2705\n+Testing 00009_uniq_distributed.sql ----> Ok! \u2705\n+Testing 00010_quantiles_segfault.sql ----> Ok! \u2705\n+Testing 00011_sorting.sql ----> Ok! \u2705\n+Testing 00012_sorting_distributed.sql ----> Ok! \u2705\n+Skipping 00013_sorting_of_nested.sql \n+Testing 00014_filtering_arrays.sql ----> Ok! \u2705\n+Testing 00015_totals_and_no_aggregate_functions.sql ----> Ok! \u2705\n+Testing 00016_any_if_distributed_cond_always_false.sql ----> Ok! \u2705\n+Testing 00017_aggregation_uninitialized_memory.sql ----> Ok! \u2705\n+Testing 00020_distinct_order_by_distributed.sql ----> Ok! \u2705\n+Testing 00021_1_select_with_in.sql ----> Ok! \u2705\n+Testing 00021_2_select_with_in.sql ----> Ok! \u2705\n+Testing 00021_3_select_with_in.sql ----> Ok! \u2705\n+Testing 00022_merge_prewhere.sql ----> Ok! \u2705\n+Testing 00023_totals_limit.sql ----> Ok! \u2705\n+Testing 00024_random_counters.sql ----> Ok! \u2705\n+Testing 00030_array_enumerate_uniq.sql ----> Ok! \u2705\n+Testing 00031_array_enumerate_uniq.sql ----> Ok! \u2705\n+Testing 00032_aggregate_key64.sql ----> Ok! \u2705\n+Testing 00033_aggregate_key_string.sql ----> Ok! \u2705\n+Testing 00034_aggregate_key_fixed_string.sql ----> Ok! \u2705\n+Testing 00035_aggregate_keys128.sql ----> Ok! \u2705\n+Testing 00036_aggregate_hashed.sql ----> Ok! \u2705\n+Testing 00037_uniq_state_merge1.sql ----> Ok! \u2705\n+Testing 00038_uniq_state_merge2.sql ----> Ok! \u2705\n+Testing 00039_primary_key.sql ----> Ok! \u2705\n+Testing 00040_aggregating_materialized_view.sql ----> Ok! \u2705\n+Testing 00041_aggregating_materialized_view.sql ----> Ok! \u2705\n+Testing 00042_any_left_join.sql ----> Ok! \u2705\n+Testing 00043_any_left_join.sql ----> Ok! \u2705\n+Testing 00044_any_left_join_string.sql ----> Ok! \u2705\n+Testing 00045_uniq_upto.sql ----> Ok! \u2705\n+Testing 00046_uniq_upto_distributed.sql ----> Ok! \u2705\n+Testing 00047_bar.sql ----> Ok! \u2705\n+Testing 00048_min_max.sql ----> Ok! \u2705\n+Testing 00049_max_string_if.sql ----> Ok! \u2705\n+Testing 00050_min_max.sql ----> Ok! \u2705\n+Testing 00051_min_max_array.sql ----> Ok! \u2705\n+Testing 00052_group_by_in.sql ----> Ok! \u2705\n+Testing 00053_replicate_segfault.sql ----> Ok! \u2705\n+Testing 00054_merge_tree_partitions.sql ----> Ok! \u2705\n+Testing 00055_index_and_not.sql ----> Ok! \u2705\n+Testing 00056_view.sql ----> Ok! \u2705\n+Testing 00059_merge_sorting_empty_array_joined.sql ----> Ok! \u2705\n+Testing 00060_move_to_prewhere_and_sets.sql ----> Ok! \u2705\n+Skipping 00061_storage_buffer.sql \n+Testing 00062_loyalty.sql ----> Ok! \u2705\n+Testing 00063_loyalty_joins.sql ----> Ok! \u2705\n+Testing 00065_loyalty_with_storage_join.sql ----> Ok! \u2705\n+Testing 00066_sorting_distributed_many_replicas.sql ----> Ok! \u2705\n+Testing 00067_union_all.sql ----> Ok! \u2705\n+Testing 00068_subquery_in_prewhere.sql ----> Ok! \u2705\n+Testing 00069_duplicate_aggregation_keys.sql ----> Ok! \u2705\n+Testing 00071_merge_tree_optimize_aio.sql ----> Ok! \u2705\n+Testing 00072_compare_date_and_string_index.sql ----> Ok! \u2705\n+Testing 00073_uniq_array.sql ----> Ok! \u2705\n+Testing 00074_full_join.sql ----> Ok! \u2705\n+Testing 00075_left_array_join.sql ----> Ok! \u2705\n+Testing 00076_system_columns_bytes.sql ----> Ok! \u2705\n+Testing 00077_log_tinylog_stripelog.sql ----> Ok! \u2705\n+Testing 00078_group_by_arrays.sql ----> Ok! \u2705\n+Testing 00079_array_join_not_used_joined_column.sql ----> Ok! \u2705\n+Testing 00080_array_join_and_union.sql ----> Ok! \u2705\n+Testing 00081_group_by_without_key_and_totals.sql ----> Ok! \u2705\n+Testing 00082_quantiles.sql ----> Ok! \u2705\n+Testing 00083_array_filter.sql ----> Ok! \u2705\n+Testing 00084_external_aggregation.sql ----> Ok! \u2705\n+Testing 00085_monotonic_evaluation_segfault.sql ----> Ok! \u2705\n+Testing 00086_array_reduce.sql ----> Ok! \u2705\n+Testing 00087_where_0.sql ----> Ok! \u2705\n+Testing 00088_global_in_one_shard_and_rows_before_limit.sql ----> Ok! \u2705\n+Testing 00089_position_functions_with_non_constant_arg.sql ----> Ok! \u2705\n+Testing 00091_prewhere_two_conditions.sql ----> Ok! \u2705\n+Testing 00093_prewhere_array_join.sql ----> Ok! \u2705\n+Testing 00094_order_by_array_join_limit.sql ----> Ok! \u2705\n+Skipping 00095_hyperscan_profiler.sql \n+Testing 00139_like.sql ----> Ok! \u2705\n+Skipping 00140_rename.sql \n+Testing 00141_transform.sql ----> Ok! \u2705\n+Testing 00142_system_columns.sql ----> Ok! \u2705\n+Testing 00143_transform_non_const_default.sql ----> Ok! \u2705\n+Testing 00144_functions_of_aggregation_states.sql ----> Ok! \u2705\n+Testing 00145_aggregate_functions_statistics.sql ----> Ok! \u2705\n+Testing 00146_aggregate_function_uniq.sql ----> Ok! \u2705\n+Testing 00147_global_in_aggregate_function.sql ----> Ok! \u2705\n+Testing 00148_monotonic_functions_and_index.sql ----> Ok! \u2705\n+Testing 00149_quantiles_timing_distributed.sql ----> Ok! \u2705\n+Testing 00150_quantiles_timing_precision.sql ----> Ok! \u2705\n+Testing 00151_order_by_read_in_order.sql ----> Ok! \u2705\n+Skipping 00151_replace_partition_with_different_granularity.sql \n+Skipping 00152_insert_different_granularity.sql \n+Testing 00153_aggregate_arena_race.sql ----> Ok! \u2705\n+Skipping 00154_avro.sql \n+Testing 00156_max_execution_speed_sample_merge.sql ----> Ok! \u2705\n+Skipping 00157_cache_dictionary.sql \n+Skipping 00158_cache_dictionary_has.sql \n+Testing 00160_decode_xml_component.sql ----> Ok! \u2705\n+Testing 00162_mmap_compression_none.sql ----> Ok! \u2705\n+Testing 00164_quantileBfloat16.sql ----> Ok! \u2705\n+Testing 00165_jit_aggregate_functions.sql ----> Ok! \u2705\n+Skipping 00166_explain_estimate.sql \n+Testing 00167_read_bytes_from_fs.sql ----> Ok! \u2705\n+Total failed tests: \ndiff --git a/tests/queries/1_stateful/00168_parallel_processing_on_replicas_part_1.sh b/tests/queries/1_stateful/00168_parallel_processing_on_replicas_part_1.sh\nnew file mode 100755\nindex 000000000000..ba1245d96795\n--- /dev/null\n+++ b/tests/queries/1_stateful/00168_parallel_processing_on_replicas_part_1.sh\n@@ -0,0 +1,98 @@\n+#!/usr/bin/env bash\n+# Tags: no-tsan\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+# set -e\n+\n+# All replicas are localhost, disable `prefer_localhost_replica` option to test network interface\n+# Currently this feature could not work with hedged requests\n+# Enabling `enable_sample_offset_parallel_processing` feature could lead to intersecting marks, so some of them would be thrown away and it will lead to incorrect result of SELECT query\n+SETTINGS=\"--max_parallel_replicas=3 --prefer_localhost_replica=false --use_hedged_requests=false --async_socket_for_remote=false  --allow_experimental_parallel_reading_from_replicas=true\"\n+\n+# Prepare tables\n+$CLICKHOUSE_CLIENT $SETTINGS -nm -q '''\n+    drop table if exists test.dist_hits SYNC;\n+    drop table if exists test.dist_visits SYNC;\n+\n+    create table test.dist_hits as test.hits engine = Distributed(\"test_cluster_one_shard_three_replicas_localhost\", test, hits, rand());\n+    create table test.dist_visits as test.visits engine = Distributed(\"test_cluster_one_shard_three_replicas_localhost\", test, visits, rand());\n+''';\n+\n+FAILED=()\n+\n+# PreviouslyFailed=(\n+# )\n+\n+SkipList=(\n+    \"00013_sorting_of_nested.sql\" # It contains FINAL, which is not allowed together with parallel reading\n+\n+    \"00061_storage_buffer.sql\"\n+    \"00095_hyperscan_profiler.sql\" # too long in debug (there is a --no-debug tag inside a test)\n+\n+    \"00140_rename.sql\" # Multiple renames are not allowed with DatabaseReplicated and tags are not forwarded through this test\n+\n+    \"00154_avro.sql\" # Plain select * with limit with Distributed table is not deterministic\n+    \"00151_replace_partition_with_different_granularity.sql\" # Replace partition from Distributed is not allowed\n+    \"00152_insert_different_granularity.sql\" # The same as above\n+\n+    \"00157_cache_dictionary.sql\" # Too long in debug mode, but result is correct\n+    \"00158_cache_dictionary_has.sql\" # The same as above\n+\n+    \"00166_explain_estimate.sql\" # Distributed table returns nothing\n+)\n+\n+# for TESTPATH in \"${PreviouslyFailed[@]}\"\n+for TESTPATH in \"$CURDIR\"/*.sql;\n+do\n+    TESTNAME=$(basename $TESTPATH)\n+\n+    if [[ \" ${SkipList[*]} \" =~ ${TESTNAME} ]]; then\n+        echo  \"Skipping $TESTNAME \"\n+        continue\n+    fi\n+\n+    echo -n \"Testing $TESTNAME ----> \"\n+\n+    # prepare test\n+    NEW_TESTNAME=\"/tmp/dist_$TESTNAME\"\n+    # Added g to sed command to replace all tables, not the first\n+    cat $TESTPATH | sed -e 's/test.hits/test.dist_hits/g'  | sed -e 's/test.visits/test.dist_visits/g' > $NEW_TESTNAME\n+\n+    TESTNAME_RESULT=\"/tmp/result_$TESTNAME\"\n+    NEW_TESTNAME_RESULT=\"/tmp/result_dist_$TESTNAME\"\n+\n+    $CLICKHOUSE_CLIENT $SETTINGS -nm --testmode < $TESTPATH > $TESTNAME_RESULT\n+    $CLICKHOUSE_CLIENT $SETTINGS -nm --testmode < $NEW_TESTNAME > $NEW_TESTNAME_RESULT\n+\n+    expected=$(cat $TESTNAME_RESULT | md5sum)\n+    actual=$(cat $NEW_TESTNAME_RESULT | md5sum)\n+\n+    if [[ \"$expected\" != \"$actual\" ]]; then\n+        FAILED+=(\"$TESTNAME\")\n+        echo \"Failed! \u274c \"\n+        echo \"Plain:\"\n+        cat $TESTNAME_RESULT\n+        echo \"Distributed:\"\n+        cat $NEW_TESTNAME_RESULT\n+    else\n+        echo \"Ok! \u2705\"\n+    fi\n+done\n+\n+\n+echo \"Total failed tests: \"\n+# Iterate the loop to read and print each array element\n+for value in \"${FAILED[@]}\"\n+do\n+    echo \"\ud83d\udd3a  $value\"\n+done\n+\n+# Drop tables\n+\n+$CLICKHOUSE_CLIENT $SETTINGS -nm -q '''\n+    drop table if exists test.dist_hits SYNC;\n+    drop table if exists test.dist_visits SYNC;\n+''';\n",
  "problem_statement": "Parallel processing on replicas, reworked.\nWe want to parallelize data processing using multiple replicas of single shard.\r\nEvery replica should process some split of data.\r\n\r\nThere are the following considerations that makes the task non-trivial:\r\n1. Replicas may contain different set of data parts, because some replicas may lag behind and miss some new parts.\r\n2. Replicas may contain different set of data parts, because some parts may be merged on one replica and unmerged on another replica.\r\n3. We want to distribute the work uniformly across replicas, so if one replica is slower than another, we should not be bounded by performance of the most slow replica.\r\n\r\nWe cannot use some hashing based split of data parts, because replicas have different set of data parts.\r\nWe cannot split the set of data parts statically and assign to replicas before query processing.\r\n\r\nThis task will also help to implement distributed processing over shared storage.\r\nIn most simple case, multiple computation nodes over shared storage can look as replicas, and we split data processing over them.\r\n\r\n**Proposal**\r\n\r\nInitiator node sends the query to all participating replicas (all available replicas or limited subset of available replicas depending on settings) along with the setting that these replicas should coordinate in parallel processing and with another setting - a hint on how many replicas are participating.\r\n\r\nEvery replica collects a snapshot of data parts to process the query as usual. From these data parts \"read tasks\" are being formed like: - read this data part; - read this range of marks from this data part (for large data parts). Read tasks are identical to what the replica wants to read during normal query processing.\r\n\r\nReplica collects some amount of read tasks and make a request with the list of read tasks back to initiator node. Initiator node acts like a \"semaphore\" for replicas to coordinate their data processing. The request like \"tell me if I can take these tasks and assign them for me\". Initiator node builds the set of data parts (in memory state) with the ranges inside them that are being processed.\r\n\r\nNote: this is similar to already implemented `s3Cluster` table function that coordinates processing of files on remote storage across multiple computation nodes.\r\n\r\nFor every read task it answers:\r\n- if no replicas already took this data part or covering or intersecting data part - then allow it to be processed;\r\n- if some other replica already took this data part as a whole, or anything from covering or intersecting data part - then answer that replica should skip it;\r\n- if some other replica already took a range of this data part - then answer that replica should took another range of this data part starting from already taken range with the size comparable to already taken range.\r\n\r\nIn addition it can send info about already taken tasks - so replica will not ask about them later.\r\n\r\nThe amount of read tasks that are sent to initiator in one network request is selected to balance between uniform workload distribution and low number of RTTs for short queries.\r\nE.g. it can be one request per 1 GB of data (controlled by a setting).\r\nIt will automatically lower the number of replicas and the amount of coordination to process short queries.\r\n\r\nIf some replicas lagging behind and miss some parts, the result will include the data available at least on one replica (the most complete result).\r\n\r\nIf some replicas have processed and unprocessed mutations, the result will be calculated over the data parts either before or after mutation (non deterministically).\r\nE.g. if some records were deleted on one replica and not deleted on another, the result may include half of these records.\r\n\r\nIf some replicas have lost half of data parts that should be merged and other replicas have completed the merge (rare case), the result may not include the data in lost parts.\r\n\r\nEvery replica may select read tasks in order determined by consistent hashing function of replica number and data part. It will allow to maintain better cache affinity in case of shared storage.\r\n\r\nNote: as simple extension, we can implement failover during query processing. If some replica died in the middle of query processing and did not return any block of data yet, we can drop processing on that replica and reassign tasks.\r\n\n",
  "hints_text": "Any process on this task?\n> Any process on this task?\r\n\r\nFeature is being developed, no PR. I would write a bit about an algorithm chosen, but I'd better write some code.",
  "created_at": "2021-09-22T22:29:35Z",
  "modified_files": [
    "programs/server/config.xml",
    "src/CMakeLists.txt",
    "src/Client/Connection.cpp",
    "src/Client/Connection.h",
    "src/Client/HedgedConnections.cpp",
    "src/Client/HedgedConnections.h",
    "src/Client/IConnections.h",
    "src/Client/IServerConnection.h",
    "src/Client/LocalConnection.cpp",
    "src/Client/LocalConnection.h",
    "src/Client/MultiplexedConnections.cpp",
    "src/Client/MultiplexedConnections.h",
    "src/Common/PoolBase.h",
    "src/Core/Protocol.h",
    "src/Core/ProtocolDefines.h",
    "src/Core/Settings.h",
    "src/IO/WriteHelpers.h",
    "src/Interpreters/ClientInfo.cpp",
    "src/Interpreters/ClientInfo.h",
    "src/Interpreters/Cluster.h",
    "src/Interpreters/ClusterProxy/IStreamFactory.h",
    "src/Interpreters/ClusterProxy/SelectStreamFactory.cpp",
    "src/Interpreters/Context.cpp",
    "src/Interpreters/Context.h",
    "src/Processors/QueryPlan/ReadFromMergeTree.cpp",
    "src/Processors/QueryPlan/ReadFromMergeTree.h",
    "src/Processors/QueryPlan/ReadFromRemote.cpp",
    "src/Processors/QueryPlan/ReadFromRemote.h",
    "src/QueryPipeline/RemoteQueryExecutor.cpp",
    "src/QueryPipeline/RemoteQueryExecutor.h",
    "src/Server/TCPHandler.cpp",
    "src/Server/TCPHandler.h",
    "src/Storages/IStorage.h",
    "src/Storages/MergeTree/IMergeTreeDataPart.cpp",
    "src/Storages/MergeTree/IMergeTreeDataPart.h",
    "b/src/Storages/MergeTree/IntersectionsIndexes.h",
    "src/Storages/MergeTree/MarkRange.cpp",
    "src/Storages/MergeTree/MarkRange.h",
    "src/Storages/MergeTree/MergeTreeBaseSelectProcessor.cpp",
    "src/Storages/MergeTree/MergeTreeBaseSelectProcessor.h",
    "src/Storages/MergeTree/MergeTreeBlockReadUtils.cpp",
    "src/Storages/MergeTree/MergeTreeBlockReadUtils.h",
    "src/Storages/MergeTree/MergeTreeData.cpp",
    "src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp",
    "src/Storages/MergeTree/MergeTreeDataSelectExecutor.h",
    "src/Storages/MergeTree/MergeTreeInOrderSelectProcessor.cpp",
    "src/Storages/MergeTree/MergeTreeInOrderSelectProcessor.h",
    "src/Storages/MergeTree/MergeTreeRangeReader.cpp",
    "src/Storages/MergeTree/MergeTreeReverseSelectProcessor.cpp",
    "src/Storages/MergeTree/MergeTreeReverseSelectProcessor.h",
    "src/Storages/MergeTree/MergeTreeSelectProcessor.cpp",
    "src/Storages/MergeTree/MergeTreeSelectProcessor.h",
    "src/Storages/MergeTree/MergeTreeSequentialSource.cpp",
    "src/Storages/MergeTree/MergeTreeThreadSelectProcessor.cpp",
    "src/Storages/MergeTree/MergeTreeThreadSelectProcessor.h",
    "b/src/Storages/MergeTree/ParallelReplicasReadingCoordinator.cpp",
    "b/src/Storages/MergeTree/ParallelReplicasReadingCoordinator.h",
    "b/src/Storages/MergeTree/RequestResponse.cpp",
    "b/src/Storages/MergeTree/RequestResponse.h",
    "src/Storages/StorageDistributed.cpp",
    "src/Storages/StorageMergeTree.cpp",
    "src/Storages/StorageReplicatedMergeTree.cpp",
    "src/Storages/StorageS3Cluster.cpp",
    "src/Storages/System/StorageSystemPartsColumns.cpp",
    "src/Storages/System/StorageSystemProjectionPartsColumns.cpp"
  ],
  "modified_test_files": [
    "docker/test/stateful/run.sh",
    "b/src/Storages/MergeTree/tests/gtest_coordinator.cpp",
    "tests/queries/0_stateless/00124_shard_distributed_with_many_replicas.sql",
    "tests/queries/0_stateless/01870_modulo_partition_key.sql",
    "b/tests/queries/1_stateful/00168_parallel_processing_on_replicas_part_1.reference",
    "b/tests/queries/1_stateful/00168_parallel_processing_on_replicas_part_1.sh"
  ]
}