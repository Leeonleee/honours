{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 57648,
  "instance_id": "ClickHouse__ClickHouse-57648",
  "issue_numbers": [
    "56728"
  ],
  "base_commit": "3e52fcb6c05ad357c1cbd6188c154c72bfa0d2bc",
  "patch": "diff --git a/src/Storages/MergeTree/IMergeTreeDataPart.cpp b/src/Storages/MergeTree/IMergeTreeDataPart.cpp\nindex 38ecd8f40678..d5e1cf25188a 100644\n--- a/src/Storages/MergeTree/IMergeTreeDataPart.cpp\n+++ b/src/Storages/MergeTree/IMergeTreeDataPart.cpp\n@@ -593,6 +593,23 @@ UInt64 IMergeTreeDataPart::getMarksCount() const\n     return index_granularity.getMarksCount();\n }\n \n+UInt64 IMergeTreeDataPart::getExistingBytesOnDisk() const\n+{\n+    if (!supportLightweightDeleteMutate() || !hasLightweightDelete() || !rows_count\n+        || !storage.getSettings()->exclude_deleted_rows_for_part_size_in_merge)\n+        return bytes_on_disk;\n+\n+    /// Uninitialized existing_rows_count\n+    /// (if existing_rows_count equals rows_count, it means that previously we failed to read existing_rows_count)\n+    if (existing_rows_count > rows_count)\n+        readExistingRowsCount();\n+\n+    if (existing_rows_count < rows_count)\n+        return bytes_on_disk * existing_rows_count / rows_count;\n+    else /// Load failed\n+        return bytes_on_disk;\n+}\n+\n size_t IMergeTreeDataPart::getFileSizeOrZero(const String & file_name) const\n {\n     auto checksum = checksums.files.find(file_name);\n@@ -1285,6 +1302,85 @@ void IMergeTreeDataPart::loadRowsCount()\n     }\n }\n \n+void IMergeTreeDataPart::readExistingRowsCount() const\n+{\n+    if (!supportLightweightDeleteMutate() || !hasLightweightDelete() || !storage.getSettings()->exclude_deleted_rows_for_part_size_in_merge\n+        || existing_rows_count < rows_count || !getMarksCount())\n+        return;\n+\n+    std::lock_guard lock(existing_rows_count_mutex);\n+\n+    /// Already read by another thread\n+    if (existing_rows_count < rows_count)\n+        return;\n+\n+    NamesAndTypesList cols;\n+    cols.push_back(LightweightDeleteDescription::FILTER_COLUMN);\n+\n+    StorageMetadataPtr metadata_ptr = storage.getInMemoryMetadataPtr();\n+    StorageSnapshotPtr storage_snapshot_ptr = std::make_shared<StorageSnapshot>(storage, metadata_ptr);\n+\n+    MergeTreeReaderPtr reader = getReader(\n+        cols,\n+        storage_snapshot_ptr,\n+        MarkRanges{MarkRange(0, getMarksCount())},\n+        nullptr,\n+        storage.getContext()->getMarkCache().get(),\n+        std::make_shared<AlterConversions>(),\n+        MergeTreeReaderSettings{},\n+        ValueSizeMap{},\n+        ReadBufferFromFileBase::ProfileCallback{});\n+\n+    if (!reader)\n+    {\n+        LOG_WARNING(storage.log, \"Create reader failed while reading existing rows count\");\n+        existing_rows_count = rows_count;\n+        return;\n+    }\n+\n+    size_t current_mark = 0;\n+    const size_t total_mark = getMarksCount();\n+\n+    bool continue_reading = false;\n+    size_t current_row = 0;\n+    size_t existing_count = 0;\n+\n+    while (current_row < rows_count)\n+    {\n+        size_t rows_to_read = index_granularity.getMarkRows(current_mark);\n+        continue_reading = (current_mark != 0);\n+\n+        Columns result;\n+        result.resize(1);\n+\n+        size_t rows_read = reader->readRows(current_mark, total_mark, continue_reading, rows_to_read, result);\n+        if (!rows_read)\n+        {\n+            LOG_WARNING(storage.log, \"Part {} has lightweight delete, but _row_exists column not found\", name);\n+            existing_rows_count = rows_count;\n+            return;\n+        }\n+\n+        current_row += rows_read;\n+        current_mark += (rows_to_read == rows_read);\n+\n+        const ColumnUInt8 * row_exists_col = typeid_cast<const ColumnUInt8 *>(result[0].get());\n+        if (!row_exists_col)\n+        {\n+            LOG_WARNING(storage.log, \"Part {} _row_exists column type is not UInt8\", name);\n+            existing_rows_count = rows_count;\n+            return;\n+        }\n+\n+        for (UInt8 row_exists : row_exists_col->getData())\n+            if (row_exists)\n+                existing_count++;\n+    }\n+\n+    existing_rows_count = existing_count;\n+    LOG_DEBUG(storage.log, \"Part {} existing_rows_count = {}\", name, existing_rows_count);\n+}\n+\n void IMergeTreeDataPart::appendFilesOfRowsCount(Strings & files)\n {\n     files.push_back(\"count.txt\");\ndiff --git a/src/Storages/MergeTree/IMergeTreeDataPart.h b/src/Storages/MergeTree/IMergeTreeDataPart.h\nindex 06e0712646a4..349f58da7c1b 100644\n--- a/src/Storages/MergeTree/IMergeTreeDataPart.h\n+++ b/src/Storages/MergeTree/IMergeTreeDataPart.h\n@@ -229,6 +229,13 @@ class IMergeTreeDataPart : public std::enable_shared_from_this<IMergeTreeDataPar\n \n     size_t rows_count = 0;\n \n+    /// Existing rows count (excluding lightweight deleted rows)\n+    /// UINT64_MAX -> uninitialized\n+    /// 0 -> all rows were deleted\n+    /// if reading failed, it will be set to rows_count\n+    mutable size_t existing_rows_count = UINT64_MAX;\n+    mutable std::mutex existing_rows_count_mutex;\n+\n     time_t modification_time = 0;\n     /// When the part is removed from the working set. Changes once.\n     mutable std::atomic<time_t> remove_time { std::numeric_limits<time_t>::max() };\n@@ -372,6 +379,10 @@ class IMergeTreeDataPart : public std::enable_shared_from_this<IMergeTreeDataPar\n     UInt64 getBytesOnDisk() const { return bytes_on_disk; }\n     void setBytesOnDisk(UInt64 bytes_on_disk_) { bytes_on_disk = bytes_on_disk_; }\n \n+    /// Returns estimated size of existing rows if setting exclude_deleted_rows_for_part_size_in_merge is true\n+    /// Otherwise returns bytes_on_disk\n+    UInt64 getExistingBytesOnDisk() const;\n+\n     size_t getFileSizeOrZero(const String & file_name) const;\n     auto getFilesChecksums() const { return checksums.files; }\n \n@@ -498,6 +509,9 @@ class IMergeTreeDataPart : public std::enable_shared_from_this<IMergeTreeDataPar\n     /// True if here is lightweight deleted mask file in part.\n     bool hasLightweightDelete() const { return columns.contains(LightweightDeleteDescription::FILTER_COLUMN.name); }\n \n+    /// Read existing rows count from _row_exists column\n+    void readExistingRowsCount() const;\n+\n     void writeChecksums(const MergeTreeDataPartChecksums & checksums_, const WriteSettings & settings);\n \n     /// Checks the consistency of this data part.\ndiff --git a/src/Storages/MergeTree/MergeFromLogEntryTask.cpp b/src/Storages/MergeTree/MergeFromLogEntryTask.cpp\nindex 3d8bc62b5cc3..975cffbed9f2 100644\n--- a/src/Storages/MergeTree/MergeFromLogEntryTask.cpp\n+++ b/src/Storages/MergeTree/MergeFromLogEntryTask.cpp\n@@ -160,7 +160,7 @@ ReplicatedMergeMutateTaskBase::PrepareResult MergeFromLogEntryTask::prepare()\n     }\n \n     /// Start to make the main work\n-    size_t estimated_space_for_merge = MergeTreeDataMergerMutator::estimateNeededDiskSpace(parts);\n+    size_t estimated_space_for_merge = MergeTreeDataMergerMutator::estimateNeededDiskSpace(parts, true);\n \n     /// Can throw an exception while reserving space.\n     IMergeTreeDataPart::TTLInfos ttl_infos;\ndiff --git a/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp b/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp\nindex f78b383e1732..042a6cce24cc 100644\n--- a/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp\n+++ b/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp\n@@ -405,7 +405,7 @@ MergeTreeDataMergerMutator::MergeSelectingInfo MergeTreeDataMergerMutator::getPo\n         }\n \n         IMergeSelector::Part part_info;\n-        part_info.size = part->getBytesOnDisk();\n+        part_info.size = part->getExistingBytesOnDisk();\n         part_info.age = res.current_time - part->modification_time;\n         part_info.level = part->info.level;\n         part_info.data = &part;\n@@ -611,7 +611,7 @@ SelectPartsDecision MergeTreeDataMergerMutator::selectAllPartsToMergeWithinParti\n             return SelectPartsDecision::CANNOT_SELECT;\n         }\n \n-        sum_bytes += (*it)->getBytesOnDisk();\n+        sum_bytes += (*it)->getExistingBytesOnDisk();\n \n         prev_it = it;\n         ++it;\n@@ -793,7 +793,7 @@ MergeTreeData::DataPartPtr MergeTreeDataMergerMutator::renameMergedTemporaryPart\n }\n \n \n-size_t MergeTreeDataMergerMutator::estimateNeededDiskSpace(const MergeTreeData::DataPartsVector & source_parts)\n+size_t MergeTreeDataMergerMutator::estimateNeededDiskSpace(const MergeTreeData::DataPartsVector & source_parts, const bool & is_merge)\n {\n     size_t res = 0;\n     time_t current_time = std::time(nullptr);\n@@ -804,7 +804,10 @@ size_t MergeTreeDataMergerMutator::estimateNeededDiskSpace(const MergeTreeData::\n         if (part_max_ttl && part_max_ttl <= current_time)\n             continue;\n \n-        res += part->getBytesOnDisk();\n+        if (is_merge && part->storage.getSettings()->exclude_deleted_rows_for_part_size_in_merge)\n+            res += part->getExistingBytesOnDisk();\n+        else\n+            res += part->getBytesOnDisk();\n     }\n \n     return static_cast<size_t>(res * DISK_USAGE_COEFFICIENT_TO_RESERVE);\ndiff --git a/src/Storages/MergeTree/MergeTreeDataMergerMutator.h b/src/Storages/MergeTree/MergeTreeDataMergerMutator.h\nindex 6eab0ee0c371..4cc9ea170f3e 100644\n--- a/src/Storages/MergeTree/MergeTreeDataMergerMutator.h\n+++ b/src/Storages/MergeTree/MergeTreeDataMergerMutator.h\n@@ -193,7 +193,7 @@ class MergeTreeDataMergerMutator\n \n \n     /// The approximate amount of disk space needed for merge or mutation. With a surplus.\n-    static size_t estimateNeededDiskSpace(const MergeTreeData::DataPartsVector & source_parts);\n+    static size_t estimateNeededDiskSpace(const MergeTreeData::DataPartsVector & source_parts, const bool & is_merge);\n \n private:\n     /** Select all parts belonging to the same partition.\ndiff --git a/src/Storages/MergeTree/MergeTreeSettings.h b/src/Storages/MergeTree/MergeTreeSettings.h\nindex 5bb712ea7861..07051a695de5 100644\n--- a/src/Storages/MergeTree/MergeTreeSettings.h\n+++ b/src/Storages/MergeTree/MergeTreeSettings.h\n@@ -73,6 +73,7 @@ struct Settings;\n     M(UInt64, number_of_mutations_to_throw, 1000, \"If table has at least that many unfinished mutations, throw 'Too many mutations' exception. Disabled if set to 0\", 0) \\\n     M(UInt64, min_delay_to_mutate_ms, 10, \"Min delay of mutating MergeTree table in milliseconds, if there are a lot of unfinished mutations\", 0) \\\n     M(UInt64, max_delay_to_mutate_ms, 1000, \"Max delay of mutating MergeTree table in milliseconds, if there are a lot of unfinished mutations\", 0) \\\n+    M(Bool, exclude_deleted_rows_for_part_size_in_merge, false, \"Use an estimated source part size (excluding lightweight deleted rows) when selecting parts to merge\", 0) \\\n     \\\n     /** Inserts settings. */ \\\n     M(UInt64, parts_to_delay_insert, 1000, \"If table contains at least that many active parts in single partition, artificially slow down insert into table. Disabled if set to 0\", 0) \\\ndiff --git a/src/Storages/MergeTree/MutateFromLogEntryTask.cpp b/src/Storages/MergeTree/MutateFromLogEntryTask.cpp\nindex a9ff687fe4de..620b0e34c6ad 100644\n--- a/src/Storages/MergeTree/MutateFromLogEntryTask.cpp\n+++ b/src/Storages/MergeTree/MutateFromLogEntryTask.cpp\n@@ -49,7 +49,7 @@ ReplicatedMergeMutateTaskBase::PrepareResult MutateFromLogEntryTask::prepare()\n     }\n \n     /// TODO - some better heuristic?\n-    size_t estimated_space_for_result = MergeTreeDataMergerMutator::estimateNeededDiskSpace({source_part});\n+    size_t estimated_space_for_result = MergeTreeDataMergerMutator::estimateNeededDiskSpace({source_part}, false);\n \n     if (entry.create_time + storage_settings_ptr->prefer_fetch_merged_part_time_threshold.totalSeconds() <= time(nullptr)\n         && estimated_space_for_result >= storage_settings_ptr->prefer_fetch_merged_part_size_threshold)\ndiff --git a/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp b/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp\nindex bb74c4dd7bb6..c45abb282a08 100644\n--- a/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp\n+++ b/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp\n@@ -1349,7 +1349,7 @@ bool ReplicatedMergeTreeQueue::shouldExecuteLogEntry(\n                 if (auto part_in_memory = asInMemoryPart(part))\n                     sum_parts_size_in_bytes += part_in_memory->block.bytes();\n                 else\n-                    sum_parts_size_in_bytes += part->getBytesOnDisk();\n+                    sum_parts_size_in_bytes += part->getExistingBytesOnDisk();\n             }\n         }\n \ndiff --git a/src/Storages/StorageMergeTree.cpp b/src/Storages/StorageMergeTree.cpp\nindex e9a0dd5fbf34..d1192bbfbd90 100644\n--- a/src/Storages/StorageMergeTree.cpp\n+++ b/src/Storages/StorageMergeTree.cpp\n@@ -1062,7 +1062,7 @@ MergeMutateSelectedEntryPtr StorageMergeTree::selectPartsToMerge(\n     if (isTTLMergeType(future_part->merge_type))\n         getContext()->getMergeList().bookMergeWithTTL();\n \n-    merging_tagger = std::make_unique<CurrentlyMergingPartsTagger>(future_part, MergeTreeDataMergerMutator::estimateNeededDiskSpace(future_part->parts), *this, metadata_snapshot, false);\n+    merging_tagger = std::make_unique<CurrentlyMergingPartsTagger>(future_part, MergeTreeDataMergerMutator::estimateNeededDiskSpace(future_part->parts, true), *this, metadata_snapshot, false);\n     return std::make_shared<MergeMutateSelectedEntry>(future_part, std::move(merging_tagger), std::make_shared<MutationCommands>());\n }\n \n@@ -1279,7 +1279,7 @@ MergeMutateSelectedEntryPtr StorageMergeTree::selectPartsToMutate(\n             future_part->name = part->getNewName(new_part_info);\n             future_part->part_format = part->getFormat();\n \n-            tagger = std::make_unique<CurrentlyMergingPartsTagger>(future_part, MergeTreeDataMergerMutator::estimateNeededDiskSpace({part}), *this, metadata_snapshot, true);\n+            tagger = std::make_unique<CurrentlyMergingPartsTagger>(future_part, MergeTreeDataMergerMutator::estimateNeededDiskSpace({part}, false), *this, metadata_snapshot, true);\n             return std::make_shared<MergeMutateSelectedEntry>(future_part, std::move(tagger), commands, txn);\n         }\n     }\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02942_consider_lwd_when_merge.reference b/tests/queries/0_stateless/02942_consider_lwd_when_merge.reference\nnew file mode 100644\nindex 000000000000..19920de3d3ca\n--- /dev/null\n+++ b/tests/queries/0_stateless/02942_consider_lwd_when_merge.reference\n@@ -0,0 +1,3 @@\n+2\n+2\n+1\ndiff --git a/tests/queries/0_stateless/02942_consider_lwd_when_merge.sql b/tests/queries/0_stateless/02942_consider_lwd_when_merge.sql\nnew file mode 100644\nindex 000000000000..a65e8877020c\n--- /dev/null\n+++ b/tests/queries/0_stateless/02942_consider_lwd_when_merge.sql\n@@ -0,0 +1,23 @@\n+DROP TABLE IF EXISTS lwd_merge;\n+\n+CREATE TABLE lwd_merge (id UInt64 CODEC(NONE))\n+    ENGINE = MergeTree ORDER BY id\n+SETTINGS max_bytes_to_merge_at_max_space_in_pool = 80000, exclude_deleted_rows_for_part_size_in_merge = 0;\n+\n+INSERT INTO lwd_merge SELECT number FROM numbers(10000);\n+INSERT INTO lwd_merge SELECT number FROM numbers(10000, 10000);\n+\n+OPTIMIZE TABLE lwd_merge;\n+SELECT count() FROM system.parts WHERE database = currentDatabase() AND table = 'lwd_merge' AND active = 1;\n+\n+DELETE FROM lwd_merge WHERE id % 10 > 0;\n+\n+OPTIMIZE TABLE lwd_merge;\n+SELECT count() FROM system.parts WHERE database = currentDatabase() AND table = 'lwd_merge' AND active = 1;\n+\n+ALTER TABLE lwd_merge MODIFY SETTING exclude_deleted_rows_for_part_size_in_merge = 1;\n+\n+OPTIMIZE TABLE lwd_merge;\n+SELECT count() FROM system.parts WHERE database = currentDatabase() AND table = 'lwd_merge' AND active = 1;\n+\n+DROP TABLE IF EXISTS lwd_merge;\n",
  "problem_statement": "Merge issue about large data part with lightweight delete\n**Use case**\r\n\r\nWhen a data part is larger than `max_bytes_to_merge_at_max_space_in_pool`, lightweight deleted data inside the data part will never be really deleted unless `OPTIMIZE FINAL` is executed.\r\n\r\n**Describe the solution you'd like**\r\n\r\nWhen selecting parts to merge, use estimated existed rows size\r\n (`bytes_on_disk * (rows_count - lwd_rows_count) / rows_count`) as the source part size instead of `bytes_on_disk`.\r\nWe can enable this mode only when deleted rows ratio exceeds a certain value (maybe 25%).\r\n\n",
  "hints_text": "@alexey-milovidov We plan to implement this feature. What are your thoughts on it? Do you think it's a good solution?\nAdding @alesapin as he also might have some thought about the topic. \nYes, good idea - it will be appreciated.",
  "created_at": "2023-12-08T07:37:33Z",
  "modified_files": [
    "src/Storages/MergeTree/IMergeTreeDataPart.cpp",
    "src/Storages/MergeTree/IMergeTreeDataPart.h",
    "src/Storages/MergeTree/MergeFromLogEntryTask.cpp",
    "src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp",
    "src/Storages/MergeTree/MergeTreeDataMergerMutator.h",
    "src/Storages/MergeTree/MergeTreeSettings.h",
    "src/Storages/MergeTree/MutateFromLogEntryTask.cpp",
    "src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp",
    "src/Storages/StorageMergeTree.cpp"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/02942_consider_lwd_when_merge.reference",
    "b/tests/queries/0_stateless/02942_consider_lwd_when_merge.sql"
  ]
}