{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 36299,
  "instance_id": "ClickHouse__ClickHouse-36299",
  "issue_numbers": [
    "36259"
  ],
  "base_commit": "7380a713335e849f92a941e3ec1a9f46961a1176",
  "patch": "diff --git a/src/Disks/DiskCacheWrapper.cpp b/src/Disks/DiskCacheWrapper.cpp\nindex cc2c330975af..8e355f704328 100644\n--- a/src/Disks/DiskCacheWrapper.cpp\n+++ b/src/Disks/DiskCacheWrapper.cpp\n@@ -309,23 +309,26 @@ void DiskCacheWrapper::removeSharedFile(const String & path, bool keep_s3)\n     DiskDecorator::removeSharedFile(path, keep_s3);\n }\n \n-void DiskCacheWrapper::removeSharedRecursive(const String & path, bool keep_s3)\n+void DiskCacheWrapper::removeSharedRecursive(const String & path, bool keep_all, const NameSet & files_to_keep)\n {\n     if (cache_disk->exists(path))\n-        cache_disk->removeSharedRecursive(path, keep_s3);\n-    DiskDecorator::removeSharedRecursive(path, keep_s3);\n+        cache_disk->removeSharedRecursive(path, keep_all, files_to_keep);\n+    DiskDecorator::removeSharedRecursive(path, keep_all, files_to_keep);\n }\n \n \n-void DiskCacheWrapper::removeSharedFiles(const RemoveBatchRequest & files, bool keep_s3)\n+void DiskCacheWrapper::removeSharedFiles(const RemoveBatchRequest & files, bool keep_all, const NameSet & files_to_keep)\n {\n     for (const auto & file : files)\n     {\n         if (cache_disk->exists(file.path))\n-            cache_disk->removeSharedFile(file.path, keep_s3);\n+        {\n+            bool keep_file = keep_all || files_to_keep.contains(fs::path(file.path).filename());\n+            cache_disk->removeSharedFile(file.path, keep_file);\n+        }\n     }\n \n-    DiskDecorator::removeSharedFiles(files, keep_s3);\n+    DiskDecorator::removeSharedFiles(files, keep_all, files_to_keep);\n }\n \n void DiskCacheWrapper::createHardLink(const String & src_path, const String & dst_path)\ndiff --git a/src/Disks/DiskCacheWrapper.h b/src/Disks/DiskCacheWrapper.h\nindex e413a3742f35..0e0b2e25f2c3 100644\n--- a/src/Disks/DiskCacheWrapper.h\n+++ b/src/Disks/DiskCacheWrapper.h\n@@ -47,8 +47,9 @@ class DiskCacheWrapper : public DiskDecorator\n     void removeDirectory(const String & path) override;\n     void removeRecursive(const String & path) override;\n     void removeSharedFile(const String & path, bool keep_s3) override;\n-    void removeSharedRecursive(const String & path, bool keep_s3) override;\n-    void removeSharedFiles(const RemoveBatchRequest & files, bool keep_s3) override;\n+\n+    void removeSharedRecursive(const String & path, bool keep_all, const NameSet & files_to_keep) override;\n+    void removeSharedFiles(const RemoveBatchRequest & files, bool keep_all, const NameSet & files_to_keep) override;\n     void createHardLink(const String & src_path, const String & dst_path) override;\n     ReservationPtr reserve(UInt64 bytes) override;\n \ndiff --git a/src/Disks/DiskDecorator.cpp b/src/Disks/DiskDecorator.cpp\nindex 14f507af55db..80cfc23d2109 100644\n--- a/src/Disks/DiskDecorator.cpp\n+++ b/src/Disks/DiskDecorator.cpp\n@@ -108,6 +108,11 @@ void DiskDecorator::copy(const String & from_path, const std::shared_ptr<IDisk>\n     delegate->copy(from_path, to_disk, to_path);\n }\n \n+void DiskDecorator::copyDirectoryContent(const String & from_dir, const std::shared_ptr<IDisk> & to_disk, const String & to_dir)\n+{\n+    delegate->copyDirectoryContent(from_dir, to_disk, to_dir);\n+}\n+\n void DiskDecorator::listFiles(const String & path, std::vector<String> & file_names)\n {\n     delegate->listFiles(path, file_names);\n@@ -151,14 +156,14 @@ void DiskDecorator::removeSharedFile(const String & path, bool keep_s3)\n     delegate->removeSharedFile(path, keep_s3);\n }\n \n-void DiskDecorator::removeSharedFiles(const RemoveBatchRequest & files, bool keep_in_remote_fs)\n+void DiskDecorator::removeSharedFiles(const RemoveBatchRequest & files, bool keep_all_batch_data, const NameSet & file_names_remove_metadata_only)\n {\n-    delegate->removeSharedFiles(files, keep_in_remote_fs);\n+    delegate->removeSharedFiles(files, keep_all_batch_data, file_names_remove_metadata_only);\n }\n \n-void DiskDecorator::removeSharedRecursive(const String & path, bool keep_s3)\n+void DiskDecorator::removeSharedRecursive(const String & path, bool keep_all_batch_data, const NameSet & file_names_remove_metadata_only)\n {\n-    delegate->removeSharedRecursive(path, keep_s3);\n+    delegate->removeSharedRecursive(path, keep_all_batch_data, file_names_remove_metadata_only);\n }\n \n void DiskDecorator::setLastModified(const String & path, const Poco::Timestamp & timestamp)\ndiff --git a/src/Disks/DiskDecorator.h b/src/Disks/DiskDecorator.h\nindex e5c9c7699bf4..d707eb3e51db 100644\n--- a/src/Disks/DiskDecorator.h\n+++ b/src/Disks/DiskDecorator.h\n@@ -33,6 +33,7 @@ class DiskDecorator : public IDisk\n     void moveFile(const String & from_path, const String & to_path) override;\n     void replaceFile(const String & from_path, const String & to_path) override;\n     void copy(const String & from_path, const std::shared_ptr<IDisk> & to_disk, const String & to_path) override;\n+    void copyDirectoryContent(const String & from_dir, const std::shared_ptr<IDisk> & to_disk, const String & to_dir) override;\n     void listFiles(const String & path, std::vector<String> & file_names) override;\n \n     std::unique_ptr<ReadBufferFromFileBase> readFile(\n@@ -52,8 +53,8 @@ class DiskDecorator : public IDisk\n     void removeDirectory(const String & path) override;\n     void removeRecursive(const String & path) override;\n     void removeSharedFile(const String & path, bool keep_s3) override;\n-    void removeSharedRecursive(const String & path, bool keep_s3) override;\n-    void removeSharedFiles(const RemoveBatchRequest & files, bool keep_in_remote_fs) override;\n+    void removeSharedRecursive(const String & path, bool keep_all_batch_data, const NameSet & file_names_remove_metadata_only) override;\n+    void removeSharedFiles(const RemoveBatchRequest & files, bool keep_all_batch_data, const NameSet & file_names_remove_metadata_only) override;\n     void setLastModified(const String & path, const Poco::Timestamp & timestamp) override;\n     Poco::Timestamp getLastModified(const String & path) override;\n     void setReadOnly(const String & path) override;\ndiff --git a/src/Disks/DiskEncrypted.cpp b/src/Disks/DiskEncrypted.cpp\nindex 3cee205fafc6..4ac59af95ab3 100644\n--- a/src/Disks/DiskEncrypted.cpp\n+++ b/src/Disks/DiskEncrypted.cpp\n@@ -249,6 +249,36 @@ void DiskEncrypted::copy(const String & from_path, const std::shared_ptr<IDisk>\n     copyThroughBuffers(from_path, to_disk, to_path);\n }\n \n+\n+void DiskEncrypted::copyDirectoryContent(const String & from_dir, const std::shared_ptr<IDisk> & to_disk, const String & to_dir)\n+{\n+    /// Check if we can copy the file without deciphering.\n+    if (isSameDiskType(*this, *to_disk))\n+    {\n+        /// Disk type is the same, check if the key is the same too.\n+        if (auto * to_disk_enc = typeid_cast<DiskEncrypted *>(to_disk.get()))\n+        {\n+            auto from_settings = current_settings.get();\n+            auto to_settings = to_disk_enc->current_settings.get();\n+            if (from_settings->keys == to_settings->keys)\n+            {\n+                /// Keys are the same so we can simply copy the encrypted file.\n+                auto wrapped_from_path = wrappedPath(from_dir);\n+                auto to_delegate = to_disk_enc->delegate;\n+                auto wrapped_to_path = to_disk_enc->wrappedPath(to_dir);\n+                delegate->copyDirectoryContent(wrapped_from_path, to_delegate, wrapped_to_path);\n+                return;\n+            }\n+        }\n+    }\n+\n+    if (!to_disk->exists(to_dir))\n+        to_disk->createDirectories(to_dir);\n+\n+    /// Copy the file through buffers with deciphering.\n+    copyThroughBuffers(from_dir, to_disk, to_dir);\n+}\n+\n std::unique_ptr<ReadBufferFromFileBase> DiskEncrypted::readFile(\n     const String & path,\n     const ReadSettings & settings,\ndiff --git a/src/Disks/DiskEncrypted.h b/src/Disks/DiskEncrypted.h\nindex 07a2ad81010d..14793818f075 100644\n--- a/src/Disks/DiskEncrypted.h\n+++ b/src/Disks/DiskEncrypted.h\n@@ -117,6 +117,8 @@ class DiskEncrypted : public DiskDecorator\n \n     void copy(const String & from_path, const std::shared_ptr<IDisk> & to_disk, const String & to_path) override;\n \n+    void copyDirectoryContent(const String & from_dir, const std::shared_ptr<IDisk> & to_disk, const String & to_dir) override;\n+\n     std::unique_ptr<ReadBufferFromFileBase> readFile(\n         const String & path,\n         const ReadSettings & settings,\n@@ -159,10 +161,23 @@ class DiskEncrypted : public DiskDecorator\n         delegate->removeSharedFile(wrapped_path, flag);\n     }\n \n-    void removeSharedRecursive(const String & path, bool flag) override\n+    void removeSharedRecursive(const String & path, bool keep_all_batch_data, const NameSet & file_names_remove_metadata_only) override\n     {\n         auto wrapped_path = wrappedPath(path);\n-        delegate->removeSharedRecursive(wrapped_path, flag);\n+        delegate->removeSharedRecursive(wrapped_path, keep_all_batch_data, file_names_remove_metadata_only);\n+    }\n+\n+    void removeSharedFiles(const RemoveBatchRequest & files, bool keep_all_batch_data, const NameSet & file_names_remove_metadata_only) override\n+    {\n+        for (const auto & file : files)\n+        {\n+            auto wrapped_path = wrappedPath(file.path);\n+            bool keep = keep_all_batch_data || file_names_remove_metadata_only.contains(fs::path(file.path).filename());\n+            if (file.if_exists)\n+                delegate->removeSharedFileIfExists(wrapped_path, keep);\n+            else\n+                delegate->removeSharedFile(wrapped_path, keep);\n+        }\n     }\n \n     void removeSharedFileIfExists(const String & path, bool flag) override\ndiff --git a/src/Disks/DiskLocal.cpp b/src/Disks/DiskLocal.cpp\nindex d81782a8af12..29277d0cb4e4 100644\n--- a/src/Disks/DiskLocal.cpp\n+++ b/src/Disks/DiskLocal.cpp\n@@ -440,6 +440,14 @@ void DiskLocal::copy(const String & from_path, const std::shared_ptr<IDisk> & to\n         copyThroughBuffers(from_path, to_disk, to_path); /// Base implementation.\n }\n \n+void DiskLocal::copyDirectoryContent(const String & from_dir, const std::shared_ptr<IDisk> & to_disk, const String & to_dir)\n+{\n+    if (isSameDiskType(*this, *to_disk))\n+        fs::copy(from_dir, to_dir, fs::copy_options::recursive | fs::copy_options::overwrite_existing); /// Use more optimal way.\n+    else\n+        copyThroughBuffers(from_dir, to_disk, to_dir); /// Base implementation.\n+}\n+\n SyncGuardPtr DiskLocal::getDirectorySyncGuard(const String & path) const\n {\n     return std::make_unique<LocalDirectorySyncGuard>(fs::path(disk_path) / path);\ndiff --git a/src/Disks/DiskLocal.h b/src/Disks/DiskLocal.h\nindex 59dcf5e5c138..14ce8831c50b 100644\n--- a/src/Disks/DiskLocal.h\n+++ b/src/Disks/DiskLocal.h\n@@ -68,6 +68,8 @@ class DiskLocal : public IDisk\n \n     void copy(const String & from_path, const std::shared_ptr<IDisk> & to_disk, const String & to_path) override;\n \n+    void copyDirectoryContent(const String & from_dir, const std::shared_ptr<IDisk> & to_disk, const String & to_dir) override;\n+\n     void listFiles(const String & path, std::vector<String> & file_names) override;\n \n     std::unique_ptr<ReadBufferFromFileBase> readFile(\ndiff --git a/src/Disks/DiskRestartProxy.cpp b/src/Disks/DiskRestartProxy.cpp\nindex 8045a0e8c727..8bb31cec55fd 100644\n--- a/src/Disks/DiskRestartProxy.cpp\n+++ b/src/Disks/DiskRestartProxy.cpp\n@@ -200,6 +200,12 @@ void DiskRestartProxy::copy(const String & from_path, const std::shared_ptr<IDis\n     DiskDecorator::copy(from_path, to_disk, to_path);\n }\n \n+void DiskRestartProxy::copyDirectoryContent(const String & from_dir, const std::shared_ptr<IDisk> & to_disk, const String & to_dir)\n+{\n+    ReadLock lock (mutex);\n+    DiskDecorator::copyDirectoryContent(from_dir, to_disk, to_dir);\n+}\n+\n void DiskRestartProxy::listFiles(const String & path, std::vector<String> & file_names)\n {\n     ReadLock lock (mutex);\n@@ -251,16 +257,16 @@ void DiskRestartProxy::removeSharedFile(const String & path, bool keep_s3)\n     DiskDecorator::removeSharedFile(path, keep_s3);\n }\n \n-void DiskRestartProxy::removeSharedFiles(const RemoveBatchRequest & files, bool keep_in_remote_fs)\n+void DiskRestartProxy::removeSharedFiles(const RemoveBatchRequest & files, bool keep_all_batch_data, const NameSet & file_names_remove_metadata_only)\n {\n     ReadLock lock (mutex);\n-    DiskDecorator::removeSharedFiles(files, keep_in_remote_fs);\n+    DiskDecorator::removeSharedFiles(files, keep_all_batch_data, file_names_remove_metadata_only);\n }\n \n-void DiskRestartProxy::removeSharedRecursive(const String & path, bool keep_s3)\n+void DiskRestartProxy::removeSharedRecursive(const String & path, bool keep_all_batch_data, const NameSet & file_names_remove_metadata_only)\n {\n     ReadLock lock (mutex);\n-    DiskDecorator::removeSharedRecursive(path, keep_s3);\n+    DiskDecorator::removeSharedRecursive(path, keep_all_batch_data, file_names_remove_metadata_only);\n }\n \n void DiskRestartProxy::setLastModified(const String & path, const Poco::Timestamp & timestamp)\ndiff --git a/src/Disks/DiskRestartProxy.h b/src/Disks/DiskRestartProxy.h\nindex baa57386e685..07d1524af081 100644\n--- a/src/Disks/DiskRestartProxy.h\n+++ b/src/Disks/DiskRestartProxy.h\n@@ -42,6 +42,7 @@ class DiskRestartProxy : public DiskDecorator\n     void moveFile(const String & from_path, const String & to_path) override;\n     void replaceFile(const String & from_path, const String & to_path) override;\n     void copy(const String & from_path, const DiskPtr & to_disk, const String & to_path) override;\n+    void copyDirectoryContent(const String & from_dir, const std::shared_ptr<IDisk> & to_disk, const String & to_dir) override;\n     void listFiles(const String & path, std::vector<String> & file_names) override;\n     std::unique_ptr<ReadBufferFromFileBase> readFile(\n         const String & path,\n@@ -54,8 +55,8 @@ class DiskRestartProxy : public DiskDecorator\n     void removeDirectory(const String & path) override;\n     void removeRecursive(const String & path) override;\n     void removeSharedFile(const String & path, bool keep_s3) override;\n-    void removeSharedFiles(const RemoveBatchRequest & files, bool keep_in_remote_fs) override;\n-    void removeSharedRecursive(const String & path, bool keep_s3) override;\n+    void removeSharedFiles(const RemoveBatchRequest & files, bool keep_all_batch_data, const NameSet & file_names_remove_metadata_only) override;\n+    void removeSharedRecursive(const String & path, bool keep_all_batch_data, const NameSet & file_names_remove_metadata_only) override;\n     void setLastModified(const String & path, const Poco::Timestamp & timestamp) override;\n     Poco::Timestamp getLastModified(const String & path) override;\n     void setReadOnly(const String & path) override;\ndiff --git a/src/Disks/DiskWebServer.cpp b/src/Disks/DiskWebServer.cpp\nindex 2f8929982e34..f7b399c4c972 100644\n--- a/src/Disks/DiskWebServer.cpp\n+++ b/src/Disks/DiskWebServer.cpp\n@@ -165,10 +165,10 @@ std::unique_ptr<ReadBufferFromFileBase> DiskWebServer::readFile(const String & p\n     auto remote_path = fs_path.parent_path() / (escapeForFileName(fs_path.stem()) + fs_path.extension().string());\n     remote_path = remote_path.string().substr(url.size());\n \n-    RemoteMetadata meta(path, remote_path);\n-    meta.remote_fs_objects.emplace_back(remote_path, iter->second.size);\n+    std::vector<BlobPathWithSize> blobs_to_read;\n+    blobs_to_read.emplace_back(remote_path, iter->second.size);\n \n-    auto web_impl = std::make_unique<ReadBufferFromWebServerGather>(url, meta.remote_fs_root_path, meta.remote_fs_objects, getContext(), read_settings);\n+    auto web_impl = std::make_unique<ReadBufferFromWebServerGather>(url, path, blobs_to_read, getContext(), read_settings);\n \n     if (read_settings.remote_fs_method == RemoteFSReadMethod::threadpool)\n     {\ndiff --git a/src/Disks/DiskWebServer.h b/src/Disks/DiskWebServer.h\nindex 98f92fe59867..dd699921f7c0 100644\n--- a/src/Disks/DiskWebServer.h\n+++ b/src/Disks/DiskWebServer.h\n@@ -139,7 +139,7 @@ class DiskWebServer : public IDisk, WithContext\n         throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Disk {} is read-only\", getName());\n     }\n \n-    void removeSharedRecursive(const String &, bool) override\n+    void removeSharedRecursive(const String &, bool, const NameSet &) override\n     {\n         throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Disk {} is read-only\", getName());\n     }\ndiff --git a/src/Disks/IDisk.cpp b/src/Disks/IDisk.cpp\nindex 42d5f5fce10c..b4d1c52c1d84 100644\n--- a/src/Disks/IDisk.cpp\n+++ b/src/Disks/IDisk.cpp\n@@ -20,13 +20,13 @@ bool IDisk::isDirectoryEmpty(const String & path)\n     return !iterateDirectory(path)->isValid();\n }\n \n-void copyFile(IDisk & from_disk, const String & from_path, IDisk & to_disk, const String & to_path)\n+void IDisk::copyFile(const String & from_file_path, IDisk & to_disk, const String & to_file_path)\n {\n     LOG_DEBUG(&Poco::Logger::get(\"IDisk\"), \"Copying from {} (path: {}) {} to {} (path: {}) {}.\",\n-              from_disk.getName(), from_disk.getPath(), from_path, to_disk.getName(), to_disk.getPath(), to_path);\n+              getName(), getPath(), from_file_path, to_disk.getName(), to_disk.getPath(), to_file_path);\n \n-    auto in = from_disk.readFile(from_path);\n-    auto out = to_disk.writeFile(to_path);\n+    auto in = readFile(from_file_path);\n+    auto out = to_disk.writeFile(to_file_path);\n     copyData(*in, *out);\n     out->finalize();\n }\n@@ -34,7 +34,7 @@ void copyFile(IDisk & from_disk, const String & from_path, IDisk & to_disk, cons\n \n using ResultsCollector = std::vector<std::future<void>>;\n \n-void asyncCopy(IDisk & from_disk, String from_path, IDisk & to_disk, String to_path, Executor & exec, ResultsCollector & results)\n+void asyncCopy(IDisk & from_disk, String from_path, IDisk & to_disk, String to_path, Executor & exec, ResultsCollector & results, bool copy_root_dir)\n {\n     if (from_disk.isFile(from_path))\n     {\n@@ -42,28 +42,32 @@ void asyncCopy(IDisk & from_disk, String from_path, IDisk & to_disk, String to_p\n             [&from_disk, from_path, &to_disk, to_path]()\n             {\n                 setThreadName(\"DiskCopier\");\n-                DB::copyFile(from_disk, from_path, to_disk, fs::path(to_path) / fileName(from_path));\n+                from_disk.copyFile(from_path, to_disk, fs::path(to_path) / fileName(from_path));\n             });\n \n         results.push_back(std::move(result));\n     }\n     else\n     {\n-        fs::path dir_name = fs::path(from_path).parent_path().filename();\n-        fs::path dest(fs::path(to_path) / dir_name);\n-        to_disk.createDirectories(dest);\n+        fs::path dest(to_path);\n+        if (copy_root_dir)\n+        {\n+            fs::path dir_name = fs::path(from_path).parent_path().filename();\n+            dest /= dir_name;\n+            to_disk.createDirectories(dest);\n+        }\n \n         for (auto it = from_disk.iterateDirectory(from_path); it->isValid(); it->next())\n-            asyncCopy(from_disk, it->path(), to_disk, dest, exec, results);\n+            asyncCopy(from_disk, it->path(), to_disk, dest, exec, results, true);\n     }\n }\n \n-void IDisk::copyThroughBuffers(const String & from_path, const std::shared_ptr<IDisk> & to_disk, const String & to_path)\n+void IDisk::copyThroughBuffers(const String & from_path, const std::shared_ptr<IDisk> & to_disk, const String & to_path, bool copy_root_dir)\n {\n     auto & exec = to_disk->getExecutor();\n     ResultsCollector results;\n \n-    asyncCopy(*this, from_path, *to_disk, to_path, exec, results);\n+    asyncCopy(*this, from_path, *to_disk, to_path, exec, results, copy_root_dir);\n \n     for (auto & result : results)\n         result.wait();\n@@ -73,7 +77,16 @@ void IDisk::copyThroughBuffers(const String & from_path, const std::shared_ptr<I\n \n void IDisk::copy(const String & from_path, const std::shared_ptr<IDisk> & to_disk, const String & to_path)\n {\n-    copyThroughBuffers(from_path, to_disk, to_path);\n+    copyThroughBuffers(from_path, to_disk, to_path, true);\n+}\n+\n+\n+void IDisk::copyDirectoryContent(const String & from_dir, const std::shared_ptr<IDisk> & to_disk, const String & to_dir)\n+{\n+    if (!to_disk->exists(to_dir))\n+        to_disk->createDirectories(to_dir);\n+\n+    copyThroughBuffers(from_dir, to_disk, to_dir, false);\n }\n \n void IDisk::truncateFile(const String &, size_t)\ndiff --git a/src/Disks/IDisk.h b/src/Disks/IDisk.h\nindex 81cdf47e1fb6..c4578d51b6eb 100644\n--- a/src/Disks/IDisk.h\n+++ b/src/Disks/IDisk.h\n@@ -160,6 +160,12 @@ class IDisk : public Space\n     /// Recursively copy data containing at `from_path` to `to_path` located at `to_disk`.\n     virtual void copy(const String & from_path, const std::shared_ptr<IDisk> & to_disk, const String & to_path);\n \n+    /// Recursively copy files from from_dir to to_dir. Create to_dir if not exists.\n+    virtual void copyDirectoryContent(const String & from_dir, const std::shared_ptr<IDisk> & to_disk, const String & to_dir);\n+\n+    /// Copy file `from_file_path` to `to_file_path` located at `to_disk`.\n+    virtual void copyFile(const String & from_file_path, IDisk & to_disk, const String & to_file_path);\n+\n     /// List files at `path` and add their names to `file_names`\n     virtual void listFiles(const String & path, std::vector<String> & file_names) = 0;\n \n@@ -192,17 +198,18 @@ class IDisk : public Space\n     /// Remove file. Throws exception if file doesn't exists or if directory is not empty.\n     /// Differs from removeFile for S3/HDFS disks\n     /// Second bool param is a flag to remove (true) or keep (false) shared data on S3\n-    virtual void removeSharedFile(const String & path, bool) { removeFile(path); }\n+    virtual void removeSharedFile(const String & path, bool /* keep_shared_data */) { removeFile(path); }\n \n     /// Remove file or directory with all children. Use with extra caution. Throws exception if file doesn't exists.\n     /// Differs from removeRecursive for S3/HDFS disks\n-    /// Second bool param is a flag to remove (true) or keep (false) shared data on S3\n-    virtual void removeSharedRecursive(const String & path, bool) { removeRecursive(path); }\n+    /// Second bool param is a flag to remove (false) or keep (true) shared data on S3.\n+    /// Third param determines which files cannot be removed even if second is true.\n+    virtual void removeSharedRecursive(const String & path, bool /* keep_all_shared_data */, const NameSet & /* file_names_remove_metadata_only */) { removeRecursive(path); }\n \n     /// Remove file or directory if it exists.\n     /// Differs from removeFileIfExists for S3/HDFS disks\n     /// Second bool param is a flag to remove (true) or keep (false) shared data on S3\n-    virtual void removeSharedFileIfExists(const String & path, bool) { removeFileIfExists(path); }\n+    virtual void removeSharedFileIfExists(const String & path, bool /* keep_shared_data */) { removeFileIfExists(path); }\n \n \n     virtual String getCacheBasePath() const { return \"\"; }\n@@ -237,14 +244,17 @@ class IDisk : public Space\n \n     /// Batch request to remove multiple files.\n     /// May be much faster for blob storage.\n-    virtual void removeSharedFiles(const RemoveBatchRequest & files, bool keep_in_remote_fs)\n+    /// Second bool param is a flag to remove (true) or keep (false) shared data on S3.\n+    /// Third param determines which files cannot be removed even if second is true.\n+    virtual void removeSharedFiles(const RemoveBatchRequest & files, bool keep_all_batch_data, const NameSet & file_names_remove_metadata_only)\n     {\n         for (const auto & file : files)\n         {\n+            bool keep_file = keep_all_batch_data || file_names_remove_metadata_only.contains(fs::path(file.path).filename());\n             if (file.if_exists)\n-                removeSharedFileIfExists(file.path, keep_in_remote_fs);\n+                removeSharedFileIfExists(file.path, keep_file);\n             else\n-                removeSharedFile(file.path, keep_in_remote_fs);\n+                removeSharedFile(file.path, keep_file);\n         }\n     }\n \n@@ -343,7 +353,7 @@ class IDisk : public Space\n     /// Base implementation of the function copy().\n     /// It just opens two files, reads data by portions from the first file, and writes it to the second one.\n     /// A derived class may override copy() to provide a faster implementation.\n-    void copyThroughBuffers(const String & from_path, const std::shared_ptr<IDisk> & to_disk, const String & to_path);\n+    void copyThroughBuffers(const String & from_path, const std::shared_ptr<IDisk> & to_disk, const String & to_path, bool copy_root_dir = true);\n \n private:\n     std::unique_ptr<Executor> executor;\ndiff --git a/src/Disks/IDiskRemote.cpp b/src/Disks/IDiskRemote.cpp\nindex 6a2f0383f9dd..3021dc79dcc3 100644\n--- a/src/Disks/IDiskRemote.cpp\n+++ b/src/Disks/IDiskRemote.cpp\n@@ -45,7 +45,6 @@ IDiskRemote::Metadata IDiskRemote::Metadata::createAndStoreMetadata(const String\n     return result;\n }\n \n-\n IDiskRemote::Metadata IDiskRemote::Metadata::readUpdateAndStoreMetadata(const String & remote_fs_root_path_, DiskPtr metadata_disk_, const String & metadata_file_path_, bool sync, IDiskRemote::MetadataUpdater updater)\n {\n     Metadata result(remote_fs_root_path_, metadata_disk_, metadata_file_path_);\n@@ -55,7 +54,6 @@ IDiskRemote::Metadata IDiskRemote::Metadata::readUpdateAndStoreMetadata(const St\n     return result;\n }\n \n-\n IDiskRemote::Metadata IDiskRemote::Metadata::createUpdateAndStoreMetadata(const String & remote_fs_root_path_, DiskPtr metadata_disk_, const String & metadata_file_path_, bool sync, IDiskRemote::MetadataUpdater updater)\n {\n     Metadata result(remote_fs_root_path_, metadata_disk_, metadata_file_path_);\n@@ -64,6 +62,17 @@ IDiskRemote::Metadata IDiskRemote::Metadata::createUpdateAndStoreMetadata(const\n     return result;\n }\n \n+IDiskRemote::Metadata IDiskRemote::Metadata::readUpdateStoreMetadataAndRemove(const String & remote_fs_root_path_, DiskPtr metadata_disk_, const String & metadata_file_path_, bool sync, IDiskRemote::MetadataUpdater updater)\n+{\n+    Metadata result(remote_fs_root_path_, metadata_disk_, metadata_file_path_);\n+    result.load();\n+    if (updater(result))\n+        result.save(sync);\n+    metadata_disk_->removeFile(metadata_file_path_);\n+\n+    return result;\n+\n+}\n \n IDiskRemote::Metadata IDiskRemote::Metadata::createAndStoreMetadataIfNotExists(const String & remote_fs_root_path_, DiskPtr metadata_disk_, const String & metadata_file_path_, bool sync, bool overwrite)\n {\n@@ -154,7 +163,8 @@ IDiskRemote::Metadata::Metadata(\n         const String & remote_fs_root_path_,\n         DiskPtr metadata_disk_,\n         const String & metadata_file_path_)\n-    : RemoteMetadata(remote_fs_root_path_, metadata_file_path_)\n+    : remote_fs_root_path(remote_fs_root_path_)\n+    , metadata_file_path(metadata_file_path_)\n     , metadata_disk(metadata_disk_)\n     , total_size(0), ref_count(0)\n {\n@@ -230,6 +240,12 @@ IDiskRemote::Metadata IDiskRemote::readUpdateAndStoreMetadata(const String & pat\n }\n \n \n+IDiskRemote::Metadata IDiskRemote::readUpdateStoreMetadataAndRemove(const String & path, bool sync, IDiskRemote::MetadataUpdater updater)\n+{\n+    std::unique_lock lock(metadata_mutex);\n+    return Metadata::readUpdateStoreMetadataAndRemove(remote_fs_root_path, metadata_disk, path, sync, updater);\n+}\n+\n IDiskRemote::Metadata IDiskRemote::readOrCreateUpdateAndStoreMetadata(const String & path, WriteMode mode, bool sync, IDiskRemote::MetadataUpdater updater)\n {\n     if (mode == WriteMode::Rewrite || !metadata_disk->exists(path))\n@@ -270,7 +286,7 @@ std::unordered_map<String, String> IDiskRemote::getSerializedMetadata(const std:\n     return metadatas;\n }\n \n-void IDiskRemote::removeMetadata(const String & path, std::vector<std::string> & paths_to_remove)\n+void IDiskRemote::removeMetadata(const String & path, std::vector<String> & paths_to_remove)\n {\n     LOG_TRACE(log, \"Remove file by path: {}\", backQuote(metadata_disk->getPath() + path));\n \n@@ -288,6 +304,7 @@ void IDiskRemote::removeMetadata(const String & path, std::vector<std::string> &\n             {\n                 for (const auto & [remote_fs_object_path, _] : metadata.remote_fs_objects)\n                 {\n+\n                     paths_to_remove.push_back(remote_fs_root_path + remote_fs_object_path);\n \n                     if (cache)\n@@ -307,8 +324,7 @@ void IDiskRemote::removeMetadata(const String & path, std::vector<std::string> &\n             return true;\n         };\n \n-        readUpdateAndStoreMetadata(path, false, metadata_updater);\n-        metadata_disk->removeFile(path);\n+        readUpdateStoreMetadataAndRemove(path, false, metadata_updater);\n         /// If there is no references - delete content from remote FS.\n     }\n     catch (const Exception & e)\n@@ -327,13 +343,13 @@ void IDiskRemote::removeMetadata(const String & path, std::vector<std::string> &\n }\n \n \n-void IDiskRemote::removeMetadataRecursive(const String & path, std::vector<String> & paths_to_remove)\n+void IDiskRemote::removeMetadataRecursive(const String & path, std::unordered_map<String, std::vector<String>> & paths_to_remove)\n {\n     checkStackSize(); /// This is needed to prevent stack overflow in case of cyclic symlinks.\n \n     if (metadata_disk->isFile(path))\n     {\n-        removeMetadata(path, paths_to_remove);\n+        removeMetadata(path, paths_to_remove[path]);\n     }\n     else\n     {\n@@ -522,27 +538,43 @@ void IDiskRemote::removeSharedFileIfExists(const String & path, bool delete_meta\n     }\n }\n \n-void IDiskRemote::removeSharedFiles(const RemoveBatchRequest & files, bool delete_metadata_only)\n+void IDiskRemote::removeSharedFiles(const RemoveBatchRequest & files, bool keep_all_batch_data, const NameSet & file_names_remove_metadata_only)\n {\n-    std::vector<String> paths_to_remove;\n+    std::unordered_map<String, std::vector<String>> paths_to_remove;\n     for (const auto & file : files)\n     {\n         bool skip = file.if_exists && !metadata_disk->exists(file.path);\n         if (!skip)\n-            removeMetadata(file.path, paths_to_remove);\n+            removeMetadata(file.path, paths_to_remove[file.path]);\n     }\n \n-    if (!delete_metadata_only)\n-        removeFromRemoteFS(paths_to_remove);\n+    if (!keep_all_batch_data)\n+    {\n+        std::vector<String> remove_from_remote;\n+        for (auto && [path, remote_paths] : paths_to_remove)\n+        {\n+            if (!file_names_remove_metadata_only.contains(fs::path(path).filename()))\n+                remove_from_remote.insert(remove_from_remote.end(), remote_paths.begin(), remote_paths.end());\n+        }\n+        removeFromRemoteFS(remove_from_remote);\n+    }\n }\n \n-void IDiskRemote::removeSharedRecursive(const String & path, bool delete_metadata_only)\n+void IDiskRemote::removeSharedRecursive(const String & path, bool keep_all_batch_data, const NameSet & file_names_remove_metadata_only)\n {\n-    std::vector<String> paths_to_remove;\n+    std::unordered_map<String, std::vector<String>> paths_to_remove;\n     removeMetadataRecursive(path, paths_to_remove);\n \n-    if (!delete_metadata_only)\n-        removeFromRemoteFS(paths_to_remove);\n+    if (!keep_all_batch_data)\n+    {\n+        std::vector<String> remove_from_remote;\n+        for (auto && [local_path, remote_paths] : paths_to_remove)\n+        {\n+            if (!file_names_remove_metadata_only.contains(fs::path(local_path).filename()))\n+                remove_from_remote.insert(remove_from_remote.end(), remote_paths.begin(), remote_paths.end());\n+        }\n+        removeFromRemoteFS(remove_from_remote);\n+    }\n }\n \n \ndiff --git a/src/Disks/IDiskRemote.h b/src/Disks/IDiskRemote.h\nindex ac2b1634d054..65bcdf3e719b 100644\n--- a/src/Disks/IDiskRemote.h\n+++ b/src/Disks/IDiskRemote.h\n@@ -78,6 +78,8 @@ friend class DiskRemoteReservation;\n     Metadata readMetadata(const String & path) const;\n     Metadata readMetadataUnlocked(const String & path, std::shared_lock<std::shared_mutex> &) const;\n     Metadata readUpdateAndStoreMetadata(const String & path, bool sync, MetadataUpdater updater);\n+    Metadata readUpdateStoreMetadataAndRemove(const String & path, bool sync, MetadataUpdater updater);\n+\n     Metadata readOrCreateUpdateAndStoreMetadata(const String & path, WriteMode mode, bool sync, MetadataUpdater updater);\n \n     Metadata createAndStoreMetadata(const String & path, bool sync);\n@@ -107,15 +109,16 @@ friend class DiskRemoteReservation;\n \n     void removeFileIfExists(const String & path) override { removeSharedFileIfExists(path, false); }\n \n-    void removeRecursive(const String & path) override { removeSharedRecursive(path, false); }\n+    void removeRecursive(const String & path) override { removeSharedRecursive(path, false, {}); }\n+\n \n     void removeSharedFile(const String & path, bool delete_metadata_only) override;\n \n     void removeSharedFileIfExists(const String & path, bool delete_metadata_only) override;\n \n-    void removeSharedFiles(const RemoveBatchRequest & files, bool delete_metadata_only) override;\n+    void removeSharedFiles(const RemoveBatchRequest & files, bool keep_all_batch_data, const NameSet & file_names_remove_metadata_only) override;\n \n-    void removeSharedRecursive(const String & path, bool delete_metadata_only) override;\n+    void removeSharedRecursive(const String & path, bool keep_all_batch_data, const NameSet & file_names_remove_metadata_only) override;\n \n     void listFiles(const String & path, std::vector<String> & file_names) override;\n \n@@ -172,7 +175,7 @@ friend class DiskRemoteReservation;\n private:\n     void removeMetadata(const String & path, std::vector<String> & paths_to_remove);\n \n-    void removeMetadataRecursive(const String & path, std::vector<String> & paths_to_remove);\n+    void removeMetadataRecursive(const String & path, std::unordered_map<String, std::vector<String>> & paths_to_remove);\n \n     bool tryReserve(UInt64 bytes);\n \n@@ -184,28 +187,11 @@ friend class DiskRemoteReservation;\n \n using RemoteDiskPtr = std::shared_ptr<IDiskRemote>;\n \n-\n-/// Minimum info, required to be passed to ReadIndirectBufferFromRemoteFS<T>\n-struct RemoteMetadata\n-{\n-    /// Remote FS objects paths and their sizes.\n-    std::vector<BlobPathWithSize> remote_fs_objects;\n-\n-    /// URI\n-    const String & remote_fs_root_path;\n-\n-    /// Relative path to metadata file on local FS.\n-    const String metadata_file_path;\n-\n-    RemoteMetadata(const String & remote_fs_root_path_, const String & metadata_file_path_)\n-        : remote_fs_root_path(remote_fs_root_path_), metadata_file_path(metadata_file_path_) {}\n-};\n-\n /// Remote FS (S3, HDFS) metadata file layout:\n /// FS objects, their number and total size of all FS objects.\n /// Each FS object represents a file path in remote FS and its size.\n \n-struct IDiskRemote::Metadata : RemoteMetadata\n+struct IDiskRemote::Metadata\n {\n     using Updater = std::function<bool(IDiskRemote::Metadata & metadata)>;\n     /// Metadata file version.\n@@ -213,6 +199,15 @@ struct IDiskRemote::Metadata : RemoteMetadata\n     static constexpr UInt32 VERSION_RELATIVE_PATHS = 2;\n     static constexpr UInt32 VERSION_READ_ONLY_FLAG = 3;\n \n+    /// Remote FS objects paths and their sizes.\n+    std::vector<BlobPathWithSize> remote_fs_objects;\n+\n+    /// URI\n+    const String & remote_fs_root_path;\n+\n+    /// Relative path to metadata file on local FS.\n+    const String metadata_file_path;\n+\n     DiskPtr metadata_disk;\n \n     /// Total size of all remote FS (S3, HDFS) objects.\n@@ -236,6 +231,7 @@ struct IDiskRemote::Metadata : RemoteMetadata\n \n     static Metadata readMetadata(const String & remote_fs_root_path_, DiskPtr metadata_disk_, const String & metadata_file_path_);\n     static Metadata readUpdateAndStoreMetadata(const String & remote_fs_root_path_, DiskPtr metadata_disk_, const String & metadata_file_path_, bool sync, Updater updater);\n+    static Metadata readUpdateStoreMetadataAndRemove(const String & remote_fs_root_path_, DiskPtr metadata_disk_, const String & metadata_file_path_, bool sync, Updater updater);\n \n     static Metadata createAndStoreMetadata(const String & remote_fs_root_path_, DiskPtr metadata_disk_, const String & metadata_file_path_, bool sync);\n     static Metadata createUpdateAndStoreMetadata(const String & remote_fs_root_path_, DiskPtr metadata_disk_, const String & metadata_file_path_, bool sync, Updater updater);\ndiff --git a/src/Disks/S3/DiskS3.cpp b/src/Disks/S3/DiskS3.cpp\nindex c49ccd867166..1e8894632b8c 100644\n--- a/src/Disks/S3/DiskS3.cpp\n+++ b/src/Disks/S3/DiskS3.cpp\n@@ -755,7 +755,7 @@ void DiskS3::restore()\n         bool cleanup_s3 = information.source_bucket != bucket || information.source_path != remote_fs_root_path;\n         for (const auto & root : data_roots)\n             if (exists(root))\n-                removeSharedRecursive(root + '/', !cleanup_s3);\n+                removeSharedRecursive(root + '/', !cleanup_s3, {});\n \n         restoreFiles(information);\n         restoreFileOperations(information);\ndiff --git a/src/Storages/MergeTree/DataPartsExchange.cpp b/src/Storages/MergeTree/DataPartsExchange.cpp\nindex bb2855b7da6e..064447c54ada 100644\n--- a/src/Storages/MergeTree/DataPartsExchange.cpp\n+++ b/src/Storages/MergeTree/DataPartsExchange.cpp\n@@ -534,6 +534,7 @@ MergeTreeData::MutableDataPartPtr Fetcher::fetchPart(\n         {\n             if (e.code() != ErrorCodes::S3_ERROR && e.code() != ErrorCodes::ZERO_COPY_REPLICATION_ERROR)\n                 throw;\n+\n             LOG_WARNING(log, fmt::runtime(e.message() + \" Will retry fetching part without zero-copy.\"));\n             /// Try again but without zero-copy\n             return fetchPart(metadata_snapshot, context, part_name, replica_path, host, port, timeouts,\n@@ -826,7 +827,7 @@ MergeTreeData::MutableDataPartPtr Fetcher::downloadPartToDiskRemoteMeta(\n                 /// NOTE The is_cancelled flag also makes sense to check every time you read over the network,\n                 /// performing a poll with a not very large timeout.\n                 /// And now we check it only between read chunks (in the `copyData` function).\n-                disk->removeSharedRecursive(part_download_path, true);\n+                disk->removeSharedRecursive(part_download_path, true, {});\n                 throw Exception(\"Fetching of part was cancelled\", ErrorCodes::ABORTED);\n             }\n \n@@ -850,7 +851,7 @@ MergeTreeData::MutableDataPartPtr Fetcher::downloadPartToDiskRemoteMeta(\n     new_data_part->modification_time = time(nullptr);\n     new_data_part->loadColumnsChecksumsIndexes(true, false);\n \n-    data.lockSharedData(*new_data_part, /* replace_existing_lock = */ true);\n+    data.lockSharedData(*new_data_part, /* replace_existing_lock = */ true, {});\n \n     LOG_DEBUG(log, \"Download of part {} unique id {} metadata onto disk {} finished.\",\n         part_name, part_id, disk->getName());\ndiff --git a/src/Storages/MergeTree/IMergeTreeDataPart.cpp b/src/Storages/MergeTree/IMergeTreeDataPart.cpp\nindex b687823f6e29..85aaac18099b 100644\n--- a/src/Storages/MergeTree/IMergeTreeDataPart.cpp\n+++ b/src/Storages/MergeTree/IMergeTreeDataPart.cpp\n@@ -504,10 +504,8 @@ void IMergeTreeDataPart::removeIfNeeded()\n \n         if (parent_part)\n         {\n-            std::optional<bool> keep_shared_data = keepSharedDataInDecoupledStorage();\n-            if (!keep_shared_data.has_value())\n-                return;\n-            projectionRemove(parent_part->getFullRelativePath(), *keep_shared_data);\n+            auto [can_remove, _] = canRemovePart();\n+            projectionRemove(parent_part->getFullRelativePath(), !can_remove);\n         }\n         else\n             remove();\n@@ -1514,8 +1512,6 @@ try\n     SyncGuardPtr sync_guard;\n     if (storage.getSettings()->fsync_part_directory)\n         sync_guard = volume->getDisk()->getDirectorySyncGuard(to);\n-\n-    storage.lockSharedData(*this);\n }\n catch (...)\n {\n@@ -1530,21 +1526,13 @@ catch (...)\n         throw;\n }\n \n-void IMergeTreeDataPart::cleanupOldName(const String & old_part_name) const\n-{\n-    if (name == old_part_name)\n-        return;\n-\n-    storage.unlockSharedData(*this, old_part_name);\n-}\n-\n-std::optional<bool> IMergeTreeDataPart::keepSharedDataInDecoupledStorage() const\n+std::pair<bool, NameSet> IMergeTreeDataPart::canRemovePart() const\n {\n     /// NOTE: It's needed for zero-copy replication\n     if (force_keep_shared_data)\n-        return true;\n+        return std::make_pair(false, NameSet{});\n \n-    return !storage.unlockSharedData(*this);\n+    return storage.unlockSharedData(*this);\n }\n \n void IMergeTreeDataPart::initializePartMetadataManager()\n@@ -1564,9 +1552,7 @@ void IMergeTreeDataPart::remove() const\n     assert(assertHasValidVersionMetadata());\n     part_is_probably_removed_from_disk = true;\n \n-    std::optional<bool> keep_shared_data = keepSharedDataInDecoupledStorage();\n-    if (!keep_shared_data.has_value())\n-        return;\n+    auto [can_remove, files_not_to_remove] = canRemovePart();\n \n     if (!isStoredOnDisk())\n         return;\n@@ -1577,7 +1563,7 @@ void IMergeTreeDataPart::remove() const\n     if (isProjectionPart())\n     {\n         LOG_WARNING(storage.log, \"Projection part {} should be removed by its parent {}.\", name, parent_part->name);\n-        projectionRemove(parent_part->getFullRelativePath(), *keep_shared_data);\n+        projectionRemove(parent_part->getFullRelativePath(), !can_remove);\n         return;\n     }\n \n@@ -1609,7 +1595,7 @@ void IMergeTreeDataPart::remove() const\n         LOG_WARNING(storage.log, \"Directory {} (to which part must be renamed before removing) already exists. Most likely this is due to unclean restart or race condition. Removing it.\", fullPath(disk, to));\n         try\n         {\n-            disk->removeSharedRecursive(fs::path(to) / \"\", *keep_shared_data);\n+            disk->removeSharedRecursive(fs::path(to) / \"\", !can_remove, files_not_to_remove);\n         }\n         catch (...)\n         {\n@@ -1636,7 +1622,9 @@ void IMergeTreeDataPart::remove() const\n     std::unordered_set<String> projection_directories;\n     for (const auto & [p_name, projection_part] : projection_parts)\n     {\n-        projection_part->projectionRemove(to, *keep_shared_data);\n+        /// NOTE: projections currently unsupported with zero copy replication.\n+        /// TODO: fix it.\n+        projection_part->projectionRemove(to, !can_remove);\n         projection_directories.emplace(p_name + \".proj\");\n     }\n \n@@ -1644,7 +1632,7 @@ void IMergeTreeDataPart::remove() const\n     if (checksums.empty())\n     {\n         /// If the part is not completely written, we cannot use fast path by listing files.\n-        disk->removeSharedRecursive(fs::path(to) / \"\", *keep_shared_data);\n+        disk->removeSharedRecursive(fs::path(to) / \"\", !can_remove, files_not_to_remove);\n     }\n     else\n     {\n@@ -1673,16 +1661,15 @@ void IMergeTreeDataPart::remove() const\n             request.emplace_back(fs::path(to) / DELETE_ON_DESTROY_MARKER_FILE_NAME, true);\n             request.emplace_back(fs::path(to) / TXN_VERSION_METADATA_FILE_NAME, true);\n \n-            disk->removeSharedFiles(request, *keep_shared_data);\n+            disk->removeSharedFiles(request, !can_remove, files_not_to_remove);\n             disk->removeDirectory(to);\n         }\n         catch (...)\n         {\n             /// Recursive directory removal does many excessive \"stat\" syscalls under the hood.\n-\n             LOG_ERROR(storage.log, \"Cannot quickly remove directory {} by removing files; fallback to recursive removal. Reason: {}\", fullPath(disk, to), getCurrentExceptionMessage(false));\n \n-            disk->removeSharedRecursive(fs::path(to) / \"\", *keep_shared_data);\n+            disk->removeSharedRecursive(fs::path(to) / \"\", !can_remove, files_not_to_remove);\n         }\n     }\n }\n@@ -1703,7 +1690,7 @@ void IMergeTreeDataPart::projectionRemove(const String & parent_to, bool keep_sh\n             \"Cannot quickly remove directory {} by removing files; fallback to recursive removal. Reason: checksums.txt is missing\",\n             fullPath(disk, to));\n         /// If the part is not completely written, we cannot use fast path by listing files.\n-        disk->removeSharedRecursive(fs::path(to) / \"\", keep_shared_data);\n+        disk->removeSharedRecursive(fs::path(to) / \"\", keep_shared_data, {});\n     }\n     else\n     {\n@@ -1727,8 +1714,8 @@ void IMergeTreeDataPart::projectionRemove(const String & parent_to, bool keep_sh\n             request.emplace_back(fs::path(to) / DEFAULT_COMPRESSION_CODEC_FILE_NAME, true);\n             request.emplace_back(fs::path(to) / DELETE_ON_DESTROY_MARKER_FILE_NAME, true);\n \n-            disk->removeSharedFiles(request, keep_shared_data);\n-            disk->removeSharedRecursive(to, keep_shared_data);\n+            disk->removeSharedFiles(request, keep_shared_data, {});\n+            disk->removeSharedRecursive(to, keep_shared_data, {});\n         }\n         catch (...)\n         {\n@@ -1736,7 +1723,7 @@ void IMergeTreeDataPart::projectionRemove(const String & parent_to, bool keep_sh\n \n             LOG_ERROR(storage.log, \"Cannot quickly remove directory {} by removing files; fallback to recursive removal. Reason: {}\", fullPath(disk, to), getCurrentExceptionMessage(false));\n \n-            disk->removeSharedRecursive(fs::path(to) / \"\", keep_shared_data);\n+            disk->removeSharedRecursive(fs::path(to) / \"\", keep_shared_data, {});\n          }\n      }\n  }\ndiff --git a/src/Storages/MergeTree/IMergeTreeDataPart.h b/src/Storages/MergeTree/IMergeTreeDataPart.h\nindex 19df88c54662..0b57d726ccdb 100644\n--- a/src/Storages/MergeTree/IMergeTreeDataPart.h\n+++ b/src/Storages/MergeTree/IMergeTreeDataPart.h\n@@ -105,6 +105,8 @@ class IMergeTreeDataPart : public std::enable_shared_from_this<IMergeTreeDataPar\n \n     virtual bool isStoredOnRemoteDisk() const = 0;\n \n+    virtual bool isStoredOnRemoteDiskWithZeroCopySupport() const = 0;\n+\n     virtual bool supportsVerticalMerge() const { return false; }\n \n     /// NOTE: Returns zeros if column files are not found in checksums.\n@@ -354,9 +356,6 @@ class IMergeTreeDataPart : public std::enable_shared_from_this<IMergeTreeDataPar\n     /// Changes only relative_dir_name, you need to update other metadata (name, is_temp) explicitly\n     virtual void renameTo(const String & new_relative_path, bool remove_new_dir_if_exists) const;\n \n-    /// Cleanup shared locks made with old name after part renaming\n-    virtual void cleanupOldName(const String & old_part_name) const;\n-\n     /// Makes clone of a part in detached/ directory via hard links\n     virtual void makeCloneInDetached(const String & prefix, const StorageMetadataPtr & metadata_snapshot) const;\n \n@@ -515,7 +514,17 @@ class IMergeTreeDataPart : public std::enable_shared_from_this<IMergeTreeDataPar\n \n     String getRelativePathForDetachedPart(const String & prefix) const;\n \n-    std::optional<bool> keepSharedDataInDecoupledStorage() const;\n+    /// Checks that part can be actually removed from disk.\n+    /// In ordinary scenario always returns true, but in case of\n+    /// zero-copy replication part can be hold by some other replicas.\n+    ///\n+    /// If method return false than only metadata of part from\n+    /// local storage can be removed, leaving data in remove FS untouched.\n+    ///\n+    /// If method return true, than files can be actually removed from remote\n+    /// storage storage, excluding files in the second returned argument.\n+    /// They can be hardlinks to some newer parts.\n+    std::pair<bool, NameSet> canRemovePart() const;\n \n     void initializePartMetadataManager();\n \ndiff --git a/src/Storages/MergeTree/MergeTreeData.cpp b/src/Storages/MergeTree/MergeTreeData.cpp\nindex 7770dff28dbf..3571e09ff3c0 100644\n--- a/src/Storages/MergeTree/MergeTreeData.cpp\n+++ b/src/Storages/MergeTree/MergeTreeData.cpp\n@@ -1575,8 +1575,36 @@ MergeTreeData::DataPartsVector MergeTreeData::grabOldParts(bool force)\n     if (!lock.try_lock())\n         return res;\n \n+    bool need_remove_parts_in_order = supportsReplication() && getSettings()->allow_remote_fs_zero_copy_replication;\n+    if (need_remove_parts_in_order)\n+    {\n+        bool has_zero_copy_disk = false;\n+        for (const auto & disk : getDisks())\n+        {\n+            if (disk->supportZeroCopyReplication())\n+            {\n+                has_zero_copy_disk = true;\n+                break;\n+            }\n+        }\n+        need_remove_parts_in_order = has_zero_copy_disk;\n+    }\n+\n     time_t now = time(nullptr);\n     std::vector<DataPartIteratorByStateAndInfo> parts_to_delete;\n+    std::vector<MergeTreePartInfo> skipped_parts;\n+\n+    auto has_skipped_mutation_parent = [&skipped_parts, need_remove_parts_in_order] (const DataPartPtr & part)\n+    {\n+        if (!need_remove_parts_in_order)\n+            return false;\n+\n+        for (const auto & part_info : skipped_parts)\n+            if (part->info.isMutationChildOf(part_info))\n+                return true;\n+\n+        return false;\n+    };\n \n     {\n         auto parts_lock = lockParts();\n@@ -1588,21 +1616,31 @@ MergeTreeData::DataPartsVector MergeTreeData::grabOldParts(bool force)\n \n             /// Do not remove outdated part if it may be visible for some transaction\n             if (!part->version.canBeRemoved())\n+            {\n+                skipped_parts.push_back(part->info);\n                 continue;\n+            }\n \n             auto part_remove_time = part->remove_time.load(std::memory_order_relaxed);\n \n             /// Grab only parts that are not used by anyone (SELECTs for example).\n             if (!part.unique())\n+            {\n+                skipped_parts.push_back(part->info);\n                 continue;\n+            }\n \n-            if ((part_remove_time < now && now - part_remove_time > getSettings()->old_parts_lifetime.totalSeconds())\n+            if ((part_remove_time < now && now - part_remove_time > getSettings()->old_parts_lifetime.totalSeconds() && !has_skipped_mutation_parent(part))\n                 || force\n                 || isInMemoryPart(part)     /// Remove in-memory parts immediately to not store excessive data in RAM\n                 || (part->version.creation_csn == Tx::RolledBackCSN && getSettings()->remove_rolled_back_parts_immediately))\n             {\n                 parts_to_delete.emplace_back(it);\n             }\n+            else\n+            {\n+                skipped_parts.push_back(part->info);\n+            }\n         }\n \n         res.reserve(parts_to_delete.size());\n@@ -2663,8 +2701,6 @@ bool MergeTreeData::renameTempPartAndReplace(\n     MergeTreePartInfo part_info = part->info;\n     String part_name;\n \n-    String old_part_name = part->name;\n-\n     if (DataPartPtr existing_part_in_partition = getAnyPartInPartition(part->info.partition_id, lock))\n     {\n         if (part->partition.value != existing_part_in_partition->partition.value)\n@@ -2786,9 +2822,6 @@ bool MergeTreeData::renameTempPartAndReplace(\n             out_covered_parts->emplace_back(std::move(covered_part));\n     }\n \n-    /// Cleanup shared locks made with old name\n-    part->cleanupOldName(old_part_name);\n-\n     return true;\n }\n \n@@ -3333,11 +3366,10 @@ void MergeTreeData::swapActivePart(MergeTreeData::DataPartPtr part_copy)\n \n             /// We do not check allow_remote_fs_zero_copy_replication here because data may be shared\n             /// when allow_remote_fs_zero_copy_replication turned on and off again\n-\n             original_active_part->force_keep_shared_data = false;\n \n             if (original_active_part->volume->getDisk()->supportZeroCopyReplication() &&\n-                part_copy->volume->getDisk()->supportZeroCopyReplication() &&\n+                part_copy->isStoredOnRemoteDiskWithZeroCopySupport() &&\n                 original_active_part->getUniqueId() == part_copy->getUniqueId())\n             {\n                 /// May be when several volumes use the same S3/HDFS storage\n@@ -3354,6 +3386,10 @@ void MergeTreeData::swapActivePart(MergeTreeData::DataPartPtr part_copy)\n             ssize_t diff_rows = part_copy->rows_count - original_active_part->rows_count;\n             increaseDataVolume(diff_bytes, diff_rows, /* parts= */ 0);\n \n+            /// Move parts are non replicated operations, so we take lock here.\n+            /// All other locks are taken in StorageReplicatedMergeTree\n+            lockSharedData(*part_copy);\n+\n             auto disk = original_active_part->volume->getDisk();\n             String marker_path = fs::path(original_active_part->getFullRelativePath()) / IMergeTreeDataPart::DELETE_ON_DESTROY_MARKER_FILE_NAME;\n             try\n@@ -5701,7 +5737,9 @@ MergeTreeData::MutableDataPartPtr MergeTreeData::cloneAndLoadDataPartOnSameDisk(\n     const String & tmp_part_prefix,\n     const MergeTreePartInfo & dst_part_info,\n     const StorageMetadataPtr & metadata_snapshot,\n-    const MergeTreeTransactionPtr & txn)\n+    const MergeTreeTransactionPtr & txn,\n+    HardlinkedFiles * hardlinked_files,\n+    bool copy_instead_of_hardlink)\n {\n     /// Check that the storage policy contains the disk where the src_part is located.\n     bool does_storage_policy_allow_same_disk = false;\n@@ -5739,14 +5777,32 @@ MergeTreeData::MutableDataPartPtr MergeTreeData::cloneAndLoadDataPartOnSameDisk(\n         src_part_path = fs::path(src_relative_data_path) / flushed_part_path / \"\";\n     }\n \n-    LOG_DEBUG(log, \"Cloning part {} to {}\", fullPath(disk, src_part_path), fullPath(disk, dst_part_path));\n-    localBackup(disk, src_part_path, dst_part_path, /* make_source_readonly */ false);\n+    String with_copy;\n+    if (copy_instead_of_hardlink)\n+        with_copy = \" (copying data)\";\n+\n+    LOG_DEBUG(log, \"Cloning part {} to {}{}\", fullPath(disk, src_part_path), fullPath(disk, dst_part_path), with_copy);\n+\n+    localBackup(disk, src_part_path, dst_part_path, /* make_source_readonly */ false, {}, /* copy_instead_of_hardlinks */ copy_instead_of_hardlink);\n+\n     disk->removeFileIfExists(fs::path(dst_part_path) / IMergeTreeDataPart::DELETE_ON_DESTROY_MARKER_FILE_NAME);\n     disk->removeFileIfExists(fs::path(dst_part_path) / IMergeTreeDataPart::TXN_VERSION_METADATA_FILE_NAME);\n \n     auto single_disk_volume = std::make_shared<SingleDiskVolume>(disk->getName(), disk, 0);\n     auto dst_data_part = createPart(dst_part_name, dst_part_info, single_disk_volume, tmp_dst_part_name);\n \n+    if (!copy_instead_of_hardlink && hardlinked_files)\n+    {\n+        hardlinked_files->source_part_name = src_part->name;\n+        hardlinked_files->source_table_shared_id = src_part->storage.getTableSharedID();\n+\n+        for (auto it = disk->iterateDirectory(src_part_path); it->isValid(); it->next())\n+        {\n+            if (it->name() != IMergeTreeDataPart::DELETE_ON_DESTROY_MARKER_FILE_NAME && it->name() != IMergeTreeDataPart::TXN_VERSION_METADATA_FILE_NAME)\n+                hardlinked_files->hardlinks_from_source_part.insert(it->name());\n+        }\n+    }\n+\n     /// We should write version metadata on part creation to distinguish it from parts that were created without transaction.\n     TransactionID tid = txn ? txn->tid : Tx::PrehistoricTID;\n     dst_data_part->version.setCreationTID(tid, nullptr);\ndiff --git a/src/Storages/MergeTree/MergeTreeData.h b/src/Storages/MergeTree/MergeTreeData.h\nindex aa345ece6ec4..7590d2e1d49e 100644\n--- a/src/Storages/MergeTree/MergeTreeData.h\n+++ b/src/Storages/MergeTree/MergeTreeData.h\n@@ -769,9 +769,21 @@ class MergeTreeData : public IStorage, public WithMutableContext\n     MergeTreeData & checkStructureAndGetMergeTreeData(const StoragePtr & source_table, const StorageMetadataPtr & src_snapshot, const StorageMetadataPtr & my_snapshot) const;\n     MergeTreeData & checkStructureAndGetMergeTreeData(IStorage & source_table, const StorageMetadataPtr & src_snapshot, const StorageMetadataPtr & my_snapshot) const;\n \n+    struct HardlinkedFiles\n+    {\n+        /// Shared table uuid where hardlinks live\n+        std::string source_table_shared_id;\n+        /// Hardlinked from part\n+        std::string source_part_name;\n+        /// Hardlinked files list\n+        NameSet hardlinks_from_source_part;\n+    };\n+\n     MergeTreeData::MutableDataPartPtr cloneAndLoadDataPartOnSameDisk(\n-        const MergeTreeData::DataPartPtr & src_part, const String & tmp_part_prefix, const MergeTreePartInfo & dst_part_info,\n-        const StorageMetadataPtr & metadata_snapshot, const MergeTreeTransactionPtr & txn);\n+        const MergeTreeData::DataPartPtr & src_part, const String & tmp_part_prefix,\n+        const MergeTreePartInfo & dst_part_info, const StorageMetadataPtr & metadata_snapshot,\n+        const MergeTreeTransactionPtr & txn, HardlinkedFiles * hardlinked_files,\n+        bool copy_instead_of_hardlink);\n \n     virtual std::vector<MergeTreeMutationStatus> getMutationsStatus() const = 0;\n \n@@ -939,16 +951,14 @@ class MergeTreeData : public IStorage, public WithMutableContext\n     bool scheduleDataMovingJob(BackgroundJobsAssignee & assignee);\n     bool areBackgroundMovesNeeded() const;\n \n+\n     /// Lock part in zookeeper for shared data in several nodes\n     /// Overridden in StorageReplicatedMergeTree\n-    virtual void lockSharedData(const IMergeTreeDataPart &, bool = false) const {} /// NOLINT\n+    virtual void lockSharedData(const IMergeTreeDataPart &, bool = false, std::optional<HardlinkedFiles> = {}) const {} /// NOLINT\n \n     /// Unlock shared data part in zookeeper\n     /// Overridden in StorageReplicatedMergeTree\n-    virtual bool unlockSharedData(const IMergeTreeDataPart &) const { return true; }\n-\n-    /// Remove lock with old name for shared data part after rename\n-    virtual bool unlockSharedData(const IMergeTreeDataPart &, const String &) const { return true; }\n+    virtual std::pair<bool, NameSet> unlockSharedData(const IMergeTreeDataPart &) const { return std::make_pair(true, NameSet{}); }\n \n     /// Fetch part only if some replica has it on shared storage like S3\n     /// Overridden in StorageReplicatedMergeTree\n@@ -958,6 +968,8 @@ class MergeTreeData : public IStorage, public WithMutableContext\n     /// Remove local files and remote files if needed\n     virtual bool removeDetachedPart(DiskPtr disk, const String & path, const String & part_name, bool is_freezed);\n \n+    virtual String getTableSharedID() const { return \"\"; }\n+\n     /// Store metadata for replicated tables\n     /// Do nothing for non-replicated tables\n     virtual void createAndStoreFreezeMetadata(DiskPtr disk, DataPartPtr part, String backup_part_path) const;\ndiff --git a/src/Storages/MergeTree/MergeTreeDataPartCompact.cpp b/src/Storages/MergeTree/MergeTreeDataPartCompact.cpp\nindex 14713541d3f5..41ff202bf147 100644\n--- a/src/Storages/MergeTree/MergeTreeDataPartCompact.cpp\n+++ b/src/Storages/MergeTree/MergeTreeDataPartCompact.cpp\n@@ -187,6 +187,11 @@ bool MergeTreeDataPartCompact::isStoredOnRemoteDisk() const\n     return volume->getDisk()->isRemote();\n }\n \n+bool MergeTreeDataPartCompact::isStoredOnRemoteDiskWithZeroCopySupport() const\n+{\n+    return volume->getDisk()->supportZeroCopyReplication();\n+}\n+\n MergeTreeDataPartCompact::~MergeTreeDataPartCompact()\n {\n     removeIfNeeded();\ndiff --git a/src/Storages/MergeTree/MergeTreeDataPartCompact.h b/src/Storages/MergeTree/MergeTreeDataPartCompact.h\nindex 38bfa11652a0..79d1af06db56 100644\n--- a/src/Storages/MergeTree/MergeTreeDataPartCompact.h\n+++ b/src/Storages/MergeTree/MergeTreeDataPartCompact.h\n@@ -58,6 +58,8 @@ class MergeTreeDataPartCompact : public IMergeTreeDataPart\n \n     bool isStoredOnRemoteDisk() const override;\n \n+    bool isStoredOnRemoteDiskWithZeroCopySupport() const override;\n+\n     bool hasColumnFiles(const NameAndTypePair & column) const override;\n \n     String getFileNameForColumn(const NameAndTypePair & /* column */) const override { return DATA_FILE_NAME; }\ndiff --git a/src/Storages/MergeTree/MergeTreeDataPartInMemory.h b/src/Storages/MergeTree/MergeTreeDataPartInMemory.h\nindex c5ee9ebd01fd..d64245ca6166 100644\n--- a/src/Storages/MergeTree/MergeTreeDataPartInMemory.h\n+++ b/src/Storages/MergeTree/MergeTreeDataPartInMemory.h\n@@ -45,6 +45,7 @@ class MergeTreeDataPartInMemory : public IMergeTreeDataPart\n \n     bool isStoredOnDisk() const override { return false; }\n     bool isStoredOnRemoteDisk() const override { return false; }\n+    bool isStoredOnRemoteDiskWithZeroCopySupport() const override { return false; }\n     bool hasColumnFiles(const NameAndTypePair & column) const override { return !!getColumnPosition(column.getNameInStorage()); }\n     String getFileNameForColumn(const NameAndTypePair & /* column */) const override { return \"\"; }\n     void renameTo(const String & new_relative_path, bool remove_new_dir_if_exists) const override;\ndiff --git a/src/Storages/MergeTree/MergeTreeDataPartWide.cpp b/src/Storages/MergeTree/MergeTreeDataPartWide.cpp\nindex c8ddf3c8e2f9..aa5dc5422c02 100644\n--- a/src/Storages/MergeTree/MergeTreeDataPartWide.cpp\n+++ b/src/Storages/MergeTree/MergeTreeDataPartWide.cpp\n@@ -146,6 +146,11 @@ bool MergeTreeDataPartWide::isStoredOnRemoteDisk() const\n     return volume->getDisk()->isRemote();\n }\n \n+bool MergeTreeDataPartWide::isStoredOnRemoteDiskWithZeroCopySupport() const\n+{\n+    return volume->getDisk()->supportZeroCopyReplication();\n+}\n+\n MergeTreeDataPartWide::~MergeTreeDataPartWide()\n {\n     removeIfNeeded();\ndiff --git a/src/Storages/MergeTree/MergeTreeDataPartWide.h b/src/Storages/MergeTree/MergeTreeDataPartWide.h\nindex 078dda394eef..bc2c399c100f 100644\n--- a/src/Storages/MergeTree/MergeTreeDataPartWide.h\n+++ b/src/Storages/MergeTree/MergeTreeDataPartWide.h\n@@ -52,6 +52,8 @@ class MergeTreeDataPartWide : public IMergeTreeDataPart\n \n     bool isStoredOnRemoteDisk() const override;\n \n+    bool isStoredOnRemoteDiskWithZeroCopySupport() const override;\n+\n     bool supportsVerticalMerge() const override { return true; }\n \n     String getFileNameForColumn(const NameAndTypePair & column) const override;\ndiff --git a/src/Storages/MergeTree/MergeTreePartInfo.h b/src/Storages/MergeTree/MergeTreePartInfo.h\nindex e9ff6f87f0b9..d6d9f45bc1bd 100644\n--- a/src/Storages/MergeTree/MergeTreePartInfo.h\n+++ b/src/Storages/MergeTree/MergeTreePartInfo.h\n@@ -72,6 +72,16 @@ struct MergeTreePartInfo\n             && strictly_contains_block_range;\n     }\n \n+    /// Part was created with mutation of parent_candidate part\n+    bool isMutationChildOf(const MergeTreePartInfo & parent_candidate) const\n+    {\n+        return partition_id == parent_candidate.partition_id\n+            && min_block == parent_candidate.min_block\n+            && max_block == parent_candidate.max_block\n+            && level == parent_candidate.level\n+            && mutation >= parent_candidate.mutation;\n+    }\n+\n     /// Return part mutation version, if part wasn't mutated return zero\n     Int64 getMutationVersion() const\n     {\ndiff --git a/src/Storages/MergeTree/MergeTreePartsMover.cpp b/src/Storages/MergeTree/MergeTreePartsMover.cpp\nindex 83b58960ad11..bb625d74eade 100644\n--- a/src/Storages/MergeTree/MergeTreePartsMover.cpp\n+++ b/src/Storages/MergeTree/MergeTreePartsMover.cpp\n@@ -214,10 +214,14 @@ MergeTreeData::DataPartPtr MergeTreePartsMover::clonePart(const MergeTreeMoveEnt\n             LOG_WARNING(log, \"Path {} already exists. Will remove it and clone again.\", fullPath(disk, path_to_clone + relative_path));\n             disk->removeRecursive(fs::path(path_to_clone) / relative_path / \"\");\n         }\n+\n         disk->createDirectories(path_to_clone);\n         bool is_fetched = data->tryToFetchIfShared(*part, disk, fs::path(path_to_clone) / part->name);\n         if (!is_fetched)\n+        {\n+            LOG_INFO(log, \"Part {} was not fetched, we are the first who move it to another disk, so we will copy it\", part->name);\n             part->volume->getDisk()->copy(fs::path(data->getRelativeDataPath()) / relative_path / \"\", disk, path_to_clone);\n+        }\n         part->volume->getDisk()->removeFileIfExists(fs::path(path_to_clone) / IMergeTreeDataPart::DELETE_ON_DESTROY_MARKER_FILE_NAME);\n     }\n     else\ndiff --git a/src/Storages/MergeTree/MergedBlockOutputStream.cpp b/src/Storages/MergeTree/MergedBlockOutputStream.cpp\nindex 6acbfacd4c1b..09711e512a56 100644\n--- a/src/Storages/MergeTree/MergedBlockOutputStream.cpp\n+++ b/src/Storages/MergeTree/MergedBlockOutputStream.cpp\n@@ -100,8 +100,6 @@ void MergedBlockOutputStream::Finalizer::Impl::finish()\n         if (sync)\n             file->sync();\n     }\n-\n-    part->storage.lockSharedData(*part);\n }\n \n MergedBlockOutputStream::Finalizer::~Finalizer()\ndiff --git a/src/Storages/MergeTree/MutateFromLogEntryTask.cpp b/src/Storages/MergeTree/MutateFromLogEntryTask.cpp\nindex de31fbe3c56c..64c2d6fb8a69 100644\n--- a/src/Storages/MergeTree/MutateFromLogEntryTask.cpp\n+++ b/src/Storages/MergeTree/MutateFromLogEntryTask.cpp\n@@ -115,7 +115,7 @@ ReplicatedMergeMutateTaskBase::PrepareResult MutateFromLogEntryTask::prepare()\n             String dummy;\n             if (!storage.findReplicaHavingCoveringPart(entry.new_part_name, true, dummy).empty())\n             {\n-                LOG_DEBUG(log, \"Mutation of part {} finished by some other replica, will download merged part\", entry.new_part_name);\n+                LOG_DEBUG(log, \"Mutation of part {} finished by some other replica, will download mutated part\", entry.new_part_name);\n                 return PrepareResult{\n                     .prepared_successfully = false,\n                     .need_to_check_missing_part_in_fetch = true,\n@@ -127,7 +127,7 @@ ReplicatedMergeMutateTaskBase::PrepareResult MutateFromLogEntryTask::prepare()\n \n             if (!zero_copy_lock)\n             {\n-                LOG_DEBUG(log, \"Mutation of part {} started by some other replica, will wait it and fetch merged part\", entry.new_part_name);\n+                LOG_DEBUG(log, \"Mutation of part {} started by some other replica, will wait it and mutated merged part\", entry.new_part_name);\n                 return PrepareResult{\n                     .prepared_successfully = false,\n                     .need_to_check_missing_part_in_fetch = false,\n@@ -175,7 +175,7 @@ bool MutateFromLogEntryTask::finalize(ReplicatedMergeMutateTaskBase::PartLogWrit\n \n     try\n     {\n-        storage.checkPartChecksumsAndCommit(*transaction_ptr, new_part);\n+        storage.checkPartChecksumsAndCommit(*transaction_ptr, new_part, mutate_task->getHardlinkedFiles());\n     }\n     catch (const Exception & e)\n     {\ndiff --git a/src/Storages/MergeTree/MutateTask.cpp b/src/Storages/MergeTree/MutateTask.cpp\nindex 7fb77ac12f5c..73b703aa9caf 100644\n--- a/src/Storages/MergeTree/MutateTask.cpp\n+++ b/src/Storages/MergeTree/MutateTask.cpp\n@@ -481,7 +481,6 @@ void finalizeMutatedPart(\n         MergeTreeData::DataPart::calculateTotalSizeOnDisk(new_data_part->volume->getDisk(), part_path));\n     new_data_part->default_codec = codec;\n     new_data_part->calculateColumnsAndSecondaryIndicesSizesOnDisk();\n-    new_data_part->storage.lockSharedData(*new_data_part);\n }\n \n }\n@@ -549,6 +548,8 @@ struct MutationContext\n     ExecuteTTLType execute_ttl_type{ExecuteTTLType::NONE};\n \n     MergeTreeTransactionPtr txn;\n+\n+    MergeTreeData::HardlinkedFiles hardlinked_files;\n };\n \n using MutationContextPtr = std::shared_ptr<MutationContext>;\n@@ -1071,6 +1072,7 @@ class MutateSomePartColumnsTask : public IExecutableTask\n         ctx->new_data_part->version.setCreationTID(tid, nullptr);\n         ctx->new_data_part->storeVersionMetadata();\n \n+        NameSet hardlinked_files;\n         /// Create hardlinks for unchanged files\n         for (auto it = ctx->disk->iterateDirectory(ctx->source_part->getFullRelativePath()); it->isValid(); it->next())\n         {\n@@ -1084,10 +1086,12 @@ class MutateSomePartColumnsTask : public IExecutableTask\n             {\n                 return rename_pair.first == file_name;\n             });\n+\n             if (rename_it != ctx->files_to_rename.end())\n             {\n                 if (rename_it->second.empty())\n                     continue;\n+\n                 destination += rename_it->second;\n             }\n             else\n@@ -1095,8 +1099,13 @@ class MutateSomePartColumnsTask : public IExecutableTask\n                 destination += it->name();\n             }\n \n+\n             if (!ctx->disk->isDirectory(it->path()))\n+            {\n                 ctx->disk->createHardLink(it->path(), destination);\n+                hardlinked_files.insert(it->name());\n+            }\n+\n             else if (!endsWith(\".tmp_proj\", it->name())) // ignore projection tmp merge dir\n             {\n                 // it's a projection part directory\n@@ -1105,10 +1114,18 @@ class MutateSomePartColumnsTask : public IExecutableTask\n                 {\n                     String p_destination = fs::path(destination) / p_it->name();\n                     ctx->disk->createHardLink(p_it->path(), p_destination);\n+                    hardlinked_files.insert(p_it->name());\n                 }\n             }\n         }\n \n+        /// Tracking of hardlinked files required for zero-copy replication.\n+        /// We don't remove them when we delete last copy of source part because\n+        /// new part can use them.\n+        ctx->hardlinked_files.source_table_shared_id = ctx->source_part->storage.getTableSharedID();\n+        ctx->hardlinked_files.source_part_name = ctx->source_part->name;\n+        ctx->hardlinked_files.hardlinks_from_source_part = hardlinked_files;\n+\n         (*ctx->mutate_entry)->columns_written = ctx->storage_columns.size() - ctx->updated_header.columns();\n \n         ctx->new_data_part->checksums = ctx->source_part->checksums;\n@@ -1283,7 +1300,7 @@ bool MutateTask::prepare()\n         storage_from_source_part, ctx->metadata_snapshot, ctx->commands_for_part, Context::createCopy(context_for_reading)))\n     {\n         LOG_TRACE(ctx->log, \"Part {} doesn't change up to mutation version {}\", ctx->source_part->name, ctx->future_part->part_info.mutation);\n-        promise.set_value(ctx->data->cloneAndLoadDataPartOnSameDisk(ctx->source_part, \"tmp_clone_\", ctx->future_part->part_info, ctx->metadata_snapshot, ctx->txn));\n+        promise.set_value(ctx->data->cloneAndLoadDataPartOnSameDisk(ctx->source_part, \"tmp_clone_\", ctx->future_part->part_info, ctx->metadata_snapshot, ctx->txn, &ctx->hardlinked_files, false));\n         return false;\n     }\n     else\n@@ -1374,7 +1391,7 @@ bool MutateTask::prepare()\n             && ctx->files_to_rename.empty())\n         {\n             LOG_TRACE(ctx->log, \"Part {} doesn't change up to mutation version {} (optimized)\", ctx->source_part->name, ctx->future_part->part_info.mutation);\n-            promise.set_value(ctx->data->cloneAndLoadDataPartOnSameDisk(ctx->source_part, \"tmp_mut_\", ctx->future_part->part_info, ctx->metadata_snapshot, ctx->txn));\n+            promise.set_value(ctx->data->cloneAndLoadDataPartOnSameDisk(ctx->source_part, \"tmp_mut_\", ctx->future_part->part_info, ctx->metadata_snapshot, ctx->txn, &ctx->hardlinked_files, false));\n             return false;\n         }\n \n@@ -1384,5 +1401,10 @@ bool MutateTask::prepare()\n     return true;\n }\n \n+const MergeTreeData::HardlinkedFiles & MutateTask::getHardlinkedFiles() const\n+{\n+    return ctx->hardlinked_files;\n+}\n+\n \n }\ndiff --git a/src/Storages/MergeTree/MutateTask.h b/src/Storages/MergeTree/MutateTask.h\nindex aa38ee34b4af..f4848dac3b3d 100644\n--- a/src/Storages/MergeTree/MutateTask.h\n+++ b/src/Storages/MergeTree/MutateTask.h\n@@ -13,7 +13,7 @@ namespace DB\n \n \n class MutateTask;\n-using MutateTaskPtr = std::shared_ptr<MutateTask>;\\\n+using MutateTaskPtr = std::shared_ptr<MutateTask>;\n \n \n class MergeTreeDataMergerMutator;\n@@ -44,6 +44,8 @@ class MutateTask\n         return promise.get_future();\n     }\n \n+    const MergeTreeData::HardlinkedFiles & getHardlinkedFiles() const;\n+\n private:\n \n     bool prepare();\n@@ -56,7 +58,6 @@ class MutateTask\n \n     State state{State::NEED_PREPARE};\n \n-\n     std::promise<MergeTreeData::MutableDataPartPtr> promise;\n \n     std::shared_ptr<MutationContext> ctx;\ndiff --git a/src/Storages/MergeTree/ReplicatedMergeTreeSink.cpp b/src/Storages/MergeTree/ReplicatedMergeTreeSink.cpp\nindex 187e4eb96c5d..c96c180b83de 100644\n--- a/src/Storages/MergeTree/ReplicatedMergeTreeSink.cpp\n+++ b/src/Storages/MergeTree/ReplicatedMergeTreeSink.cpp\n@@ -314,8 +314,6 @@ void ReplicatedMergeTreeSink::commitPart(\n \n     bool is_already_existing_part = false;\n \n-    String old_part_name = part->name;\n-\n     while (true)\n     {\n         /// Obtain incremental block number and lock it. The lock holds our intention to add the block to the filesystem.\n@@ -499,6 +497,8 @@ void ReplicatedMergeTreeSink::commitPart(\n                     part->name);\n         }\n \n+        storage.lockSharedData(*part, false, {});\n+\n         Coordination::Responses responses;\n         Coordination::Error multi_code = zookeeper->tryMultiNoThrow(ops, responses); /// 1 RTT\n \n@@ -553,11 +553,13 @@ void ReplicatedMergeTreeSink::commitPart(\n             }\n             else if (multi_code == Coordination::Error::ZNODEEXISTS && failed_op_path == quorum_info.status_path)\n             {\n+                storage.unlockSharedData(*part);\n                 transaction.rollback();\n                 throw Exception(\"Another quorum insert has been already started\", ErrorCodes::UNSATISFIED_QUORUM_FOR_PREVIOUS_WRITE);\n             }\n             else\n             {\n+                storage.unlockSharedData(*part);\n                 /// NOTE: We could be here if the node with the quorum existed, but was quickly removed.\n                 transaction.rollback();\n                 throw Exception(\"Unexpected logical error while adding block \" + toString(block_number) + \" with ID '\" + block_id + \"': \"\n@@ -567,12 +569,14 @@ void ReplicatedMergeTreeSink::commitPart(\n         }\n         else if (Coordination::isHardwareError(multi_code))\n         {\n+            storage.unlockSharedData(*part);\n             transaction.rollback();\n             throw Exception(\"Unrecoverable network error while adding block \" + toString(block_number) + \" with ID '\" + block_id + \"': \"\n                             + Coordination::errorMessage(multi_code), ErrorCodes::UNEXPECTED_ZOOKEEPER_ERROR);\n         }\n         else\n         {\n+            storage.unlockSharedData(*part);\n             transaction.rollback();\n             throw Exception(\"Unexpected ZooKeeper error while adding block \" + toString(block_number) + \" with ID '\" + block_id + \"': \"\n                             + Coordination::errorMessage(multi_code), ErrorCodes::UNEXPECTED_ZOOKEEPER_ERROR);\n@@ -595,9 +599,6 @@ void ReplicatedMergeTreeSink::commitPart(\n \n         waitForQuorum(zookeeper, part->name, quorum_info.status_path, quorum_info.is_active_node_value);\n     }\n-\n-    /// Cleanup shared locks made with old name\n-    part->cleanupOldName(old_part_name);\n }\n \n void ReplicatedMergeTreeSink::onStart()\ndiff --git a/src/Storages/MergeTree/localBackup.cpp b/src/Storages/MergeTree/localBackup.cpp\nindex 8bb3e4cf78a1..10aff144914e 100644\n--- a/src/Storages/MergeTree/localBackup.cpp\n+++ b/src/Storages/MergeTree/localBackup.cpp\n@@ -13,9 +13,13 @@ namespace ErrorCodes\n     extern const int DIRECTORY_ALREADY_EXISTS;\n }\n \n+namespace\n+{\n \n-static void localBackupImpl(const DiskPtr & disk, const String & source_path, const String & destination_path, bool make_source_readonly, size_t level,\n-                            std::optional<size_t> max_level)\n+void localBackupImpl(\n+    const DiskPtr & disk, const String & source_path,\n+    const String & destination_path, bool make_source_readonly, size_t level,\n+    std::optional<size_t> max_level)\n {\n     if (max_level && level > *max_level)\n         return;\n@@ -43,8 +47,6 @@ static void localBackupImpl(const DiskPtr & disk, const String & source_path, co\n     }\n }\n \n-namespace\n-{\n class CleanupOnFail\n {\n public:\n@@ -81,7 +83,10 @@ class CleanupOnFail\n };\n }\n \n-void localBackup(const DiskPtr & disk, const String & source_path, const String & destination_path, bool make_source_readonly, std::optional<size_t> max_level)\n+void localBackup(\n+    const DiskPtr & disk, const String & source_path,\n+    const String & destination_path, bool make_source_readonly,\n+    std::optional<size_t> max_level, bool copy_instead_of_hardlinks)\n {\n     if (disk->exists(destination_path) && !disk->isDirectoryEmpty(destination_path))\n     {\n@@ -101,7 +106,10 @@ void localBackup(const DiskPtr & disk, const String & source_path, const String\n     {\n         try\n         {\n-            localBackupImpl(disk, source_path, destination_path, make_source_readonly, 0, max_level);\n+            if (copy_instead_of_hardlinks)\n+                disk->copyDirectoryContent(source_path, disk, destination_path);\n+            else\n+                localBackupImpl(disk, source_path, destination_path, make_source_readonly, 0, max_level);\n         }\n         catch (const DB::ErrnoException & e)\n         {\ndiff --git a/src/Storages/MergeTree/localBackup.h b/src/Storages/MergeTree/localBackup.h\nindex c6a466204470..2eac45ac6a35 100644\n--- a/src/Storages/MergeTree/localBackup.h\n+++ b/src/Storages/MergeTree/localBackup.h\n@@ -20,6 +20,6 @@ namespace DB\n   *  If max_level is specified, than only files which depth relative source_path less or equal max_level will be copied.\n   *  So, if max_level=0 than only direct file child are copied.\n   */\n-void localBackup(const DiskPtr & disk, const String & source_path, const String & destination_path, bool make_source_readonly = true, std::optional<size_t> max_level = {});\n+void localBackup(const DiskPtr & disk, const String & source_path, const String & destination_path, bool make_source_readonly = true, std::optional<size_t> max_level = {}, bool copy_instead_of_hardlinks = false);\n \n }\ndiff --git a/src/Storages/StorageMergeTree.cpp b/src/Storages/StorageMergeTree.cpp\nindex 31f3f0b4036e..8db6fc6c88ee 100644\n--- a/src/Storages/StorageMergeTree.cpp\n+++ b/src/Storages/StorageMergeTree.cpp\n@@ -1583,7 +1583,7 @@ void StorageMergeTree::replacePartitionFrom(const StoragePtr & source_table, con\n         Int64 temp_index = insert_increment.get();\n         MergeTreePartInfo dst_part_info(partition_id, temp_index, temp_index, src_part->info.level);\n \n-        auto dst_part = cloneAndLoadDataPartOnSameDisk(src_part, TMP_PREFIX, dst_part_info, my_metadata_snapshot, local_context->getCurrentTransaction());\n+        auto dst_part = cloneAndLoadDataPartOnSameDisk(src_part, TMP_PREFIX, dst_part_info, my_metadata_snapshot, local_context->getCurrentTransaction(), {}, false);\n         dst_parts.emplace_back(std::move(dst_part));\n     }\n \n@@ -1669,7 +1669,7 @@ void StorageMergeTree::movePartitionToTable(const StoragePtr & dest_table, const\n         Int64 temp_index = insert_increment.get();\n         MergeTreePartInfo dst_part_info(partition_id, temp_index, temp_index, src_part->info.level);\n \n-        auto dst_part = dest_table_storage->cloneAndLoadDataPartOnSameDisk(src_part, TMP_PREFIX, dst_part_info, dest_metadata_snapshot, local_context->getCurrentTransaction());\n+        auto dst_part = dest_table_storage->cloneAndLoadDataPartOnSameDisk(src_part, TMP_PREFIX, dst_part_info, dest_metadata_snapshot, local_context->getCurrentTransaction(), {}, false);\n         dst_parts.emplace_back(std::move(dst_part));\n     }\n \ndiff --git a/src/Storages/StorageReplicatedMergeTree.cpp b/src/Storages/StorageReplicatedMergeTree.cpp\nindex 484434d7d17e..ea69f658aa9b 100644\n--- a/src/Storages/StorageReplicatedMergeTree.cpp\n+++ b/src/Storages/StorageReplicatedMergeTree.cpp\n@@ -75,6 +75,7 @@\n \n #include <boost/algorithm/string/join.hpp>\n #include <boost/algorithm/string/replace.hpp>\n+#include <boost/algorithm/string.hpp>\n \n #include <algorithm>\n #include <ctime>\n@@ -1446,15 +1447,18 @@ void StorageReplicatedMergeTree::checkPartChecksumsAndAddCommitOps(const zkutil:\n }\n \n MergeTreeData::DataPartsVector StorageReplicatedMergeTree::checkPartChecksumsAndCommit(Transaction & transaction,\n-    const DataPartPtr & part)\n+    const DataPartPtr & part, std::optional<MergeTreeData::HardlinkedFiles> hardlinked_files)\n {\n     auto zookeeper = getZooKeeper();\n \n+\n     while (true)\n     {\n         Coordination::Requests ops;\n         NameSet absent_part_paths_on_replicas;\n \n+        lockSharedData(*part, false, hardlinked_files);\n+\n         /// Checksums are checked here and `ops` is filled. In fact, the part is added to ZK just below, when executing `multi`.\n         checkPartChecksumsAndAddCommitOps(zookeeper, part, ops, part->name, &absent_part_paths_on_replicas);\n \n@@ -1493,7 +1497,10 @@ MergeTreeData::DataPartsVector StorageReplicatedMergeTree::checkPartChecksumsAnd\n                 LOG_INFO(log, \"The part {} on a replica suddenly appeared, will recheck checksums\", e.getPathForFirstFailedOp());\n             }\n             else\n+            {\n+                unlockSharedData(*part);\n                 throw;\n+            }\n         }\n     }\n }\n@@ -1933,6 +1940,7 @@ bool StorageReplicatedMergeTree::executeReplaceRange(const LogEntry & entry)\n               entry.znode_name, entry_replace.drop_range_part_name, entry_replace.new_part_names.size(),\n               entry_replace.from_database, entry_replace.from_table);\n     auto metadata_snapshot = getInMemoryMetadataPtr();\n+    auto storage_settings_ptr = getSettings();\n \n     MergeTreePartInfo drop_range = MergeTreePartInfo::fromPartName(entry_replace.drop_range_part_name, format_version);\n     /// Range with only one block has special meaning: it's ATTACH PARTITION or MOVE PARTITION, so there is no drop range\n@@ -1985,6 +1993,8 @@ bool StorageReplicatedMergeTree::executeReplaceRange(const LogEntry & entry)\n \n         /// A replica that will be used to fetch part\n         String replica;\n+\n+        MergeTreeData::HardlinkedFiles hardlinked_files;\n     };\n \n     using PartDescriptionPtr = std::shared_ptr<PartDescription>;\n@@ -2083,6 +2093,14 @@ bool StorageReplicatedMergeTree::executeReplaceRange(const LogEntry & entry)\n                 continue;\n             }\n \n+            bool avoid_copy_local_part = storage_settings_ptr->allow_remote_fs_zero_copy_replication && src_part->isStoredOnRemoteDiskWithZeroCopySupport();\n+\n+            if (avoid_copy_local_part)\n+            {\n+                LOG_DEBUG(log, \"Avoid copy local part {} from table {} because of zero-copy replication\", part_desc->src_part_name, source_table_id.getNameForLogs());\n+                continue;\n+            }\n+\n             String checksum_hex  = src_part->checksums.getTotalChecksumHex();\n \n             if (checksum_hex != part_desc->checksum_hex)\n@@ -2190,16 +2208,17 @@ bool StorageReplicatedMergeTree::executeReplaceRange(const LogEntry & entry)\n \n     static const String TMP_PREFIX = \"tmp_replace_from_\";\n \n+    std::vector<MergeTreeData::HardlinkedFiles> hardlinked_files_for_parts;\n+\n     auto obtain_part = [&] (PartDescriptionPtr & part_desc)\n     {\n         if (part_desc->src_table_part)\n         {\n-\n             if (part_desc->checksum_hex != part_desc->src_table_part->checksums.getTotalChecksumHex())\n                 throw Exception(\"Checksums of \" + part_desc->src_table_part->name + \" is suddenly changed\", ErrorCodes::UNFINISHED);\n \n             part_desc->res_part = cloneAndLoadDataPartOnSameDisk(\n-                part_desc->src_table_part, TMP_PREFIX + \"clone_\", part_desc->new_part_info, metadata_snapshot, NO_TRANSACTION_PTR);\n+                part_desc->src_table_part, TMP_PREFIX + \"clone_\", part_desc->new_part_info, metadata_snapshot, NO_TRANSACTION_PTR, &part_desc->hardlinked_files, false);\n         }\n         else if (!part_desc->replica.empty())\n         {\n@@ -2246,8 +2265,11 @@ bool StorageReplicatedMergeTree::executeReplaceRange(const LogEntry & entry)\n         {\n             renameTempPartAndReplace(part_desc->res_part, NO_TRANSACTION_RAW, nullptr, &transaction);\n             getCommitPartOps(ops, part_desc->res_part);\n+\n+            lockSharedData(*part_desc->res_part, false, part_desc->hardlinked_files);\n         }\n \n+\n         if (!ops.empty())\n             zookeeper->multi(ops);\n \n@@ -2274,6 +2296,10 @@ bool StorageReplicatedMergeTree::executeReplaceRange(const LogEntry & entry)\n     catch (...)\n     {\n         PartLog::addNewParts(getContext(), res_parts, watch.elapsed(), ExecutionStatus::fromCurrentException());\n+\n+        for (const auto & res_part : res_parts)\n+            unlockSharedData(*res_part);\n+\n         throw;\n     }\n \n@@ -3818,7 +3844,7 @@ bool StorageReplicatedMergeTree::partIsLastQuorumPart(const MergeTreePartInfo &\n \n \n bool StorageReplicatedMergeTree::fetchPart(const String & part_name, const StorageMetadataPtr & metadata_snapshot,\n-    const String & source_replica_path, bool to_detached, size_t quorum, zkutil::ZooKeeper::Ptr zookeeper_)\n+    const String & source_replica_path, bool to_detached, size_t quorum, zkutil::ZooKeeper::Ptr zookeeper_, bool try_fetch_shared)\n {\n     auto zookeeper = zookeeper_ ? zookeeper_ : getZooKeeper();\n     const auto part_info = MergeTreePartInfo::fromPartName(part_name, format_version);\n@@ -3926,12 +3952,13 @@ bool StorageReplicatedMergeTree::fetchPart(const String & part_name, const Stora\n     InterserverCredentialsPtr credentials;\n     std::optional<CurrentlySubmergingEmergingTagger> tagger_ptr;\n     std::function<MutableDataPartPtr()> get_part;\n+    MergeTreeData::HardlinkedFiles hardlinked_files;\n \n     if (part_to_clone)\n     {\n         get_part = [&, part_to_clone]()\n         {\n-            return cloneAndLoadDataPartOnSameDisk(part_to_clone, \"tmp_clone_\", part_info, metadata_snapshot, NO_TRANSACTION_PTR);\n+            return cloneAndLoadDataPartOnSameDisk(part_to_clone, \"tmp_clone_\", part_info, metadata_snapshot, NO_TRANSACTION_PTR, &hardlinked_files, false);\n         };\n     }\n     else\n@@ -3964,7 +3991,7 @@ bool StorageReplicatedMergeTree::fetchPart(const String & part_name, const Stora\n                 to_detached,\n                 \"\",\n                 &tagger_ptr,\n-                true);\n+                try_fetch_shared);\n         };\n     }\n \n@@ -3977,7 +4004,7 @@ bool StorageReplicatedMergeTree::fetchPart(const String & part_name, const Stora\n             Transaction transaction(*this, NO_TRANSACTION_RAW);\n             renameTempPartAndReplace(part, NO_TRANSACTION_RAW, nullptr, &transaction);\n \n-            replaced_parts = checkPartChecksumsAndCommit(transaction, part);\n+            replaced_parts = checkPartChecksumsAndCommit(transaction, part, hardlinked_files);\n \n             /** If a quorum is tracked for this part, you must update it.\n               * If you do not have time, in case of losing the session, when you restart the server - see the `ReplicatedMergeTreeRestartingThread::updateQuorumIfWeHavePart` method.\n@@ -5716,7 +5743,7 @@ void StorageReplicatedMergeTree::fetchPartition(\n         try\n         {\n             /// part name , metadata, part_path , true, 0, zookeeper\n-            if (!fetchPart(part_name, metadata_snapshot, part_path, true, 0, zookeeper))\n+            if (!fetchPart(part_name, metadata_snapshot, part_path, true, 0, zookeeper, /* try_fetch_shared = */ false))\n                 throw Exception(ErrorCodes::UNFINISHED, \"Failed to fetch part {} from {}\", part_name, from_);\n         }\n         catch (const DB::Exception & e)\n@@ -5854,7 +5881,7 @@ void StorageReplicatedMergeTree::fetchPartition(\n \n             try\n             {\n-                fetched = fetchPart(part, metadata_snapshot, best_replica_path, true, 0, zookeeper);\n+                fetched = fetchPart(part, metadata_snapshot, best_replica_path, true, 0, zookeeper, /* try_fetch_shared = */ false);\n             }\n             catch (const DB::Exception & e)\n             {\n@@ -6332,6 +6359,7 @@ void StorageReplicatedMergeTree::replacePartitionFrom(\n     /// First argument is true, because we possibly will add new data to current table.\n     auto lock1 = lockForShare(query_context->getCurrentQueryId(), query_context->getSettingsRef().lock_acquire_timeout);\n     auto lock2 = source_table->lockForShare(query_context->getCurrentQueryId(), query_context->getSettingsRef().lock_acquire_timeout);\n+    auto storage_settings_ptr = getSettings();\n \n     auto source_metadata_snapshot = source_table->getInMemoryMetadataPtr();\n     auto metadata_snapshot = getInMemoryMetadataPtr();\n@@ -6383,6 +6411,7 @@ void StorageReplicatedMergeTree::replacePartitionFrom(\n         assert(replace == !LogEntry::ReplaceRangeEntry::isMovePartitionOrAttachFrom(drop_range));\n \n         String drop_range_fake_part_name = getPartNamePossiblyFake(format_version, drop_range);\n+        std::vector<MergeTreeData::HardlinkedFiles> hardlinked_files_for_parts;\n \n         for (const auto & src_part : src_all_parts)\n         {\n@@ -6413,13 +6442,19 @@ void StorageReplicatedMergeTree::replacePartitionFrom(\n \n             UInt64 index = lock->getNumber();\n             MergeTreePartInfo dst_part_info(partition_id, index, index, src_part->info.level);\n-            auto dst_part = cloneAndLoadDataPartOnSameDisk(src_part, TMP_PREFIX, dst_part_info, metadata_snapshot, NO_TRANSACTION_PTR);\n+            MergeTreeData::HardlinkedFiles hardlinked_files;\n+\n+            bool copy_instead_of_hardlink = storage_settings_ptr->allow_remote_fs_zero_copy_replication\n+                                            && src_part->isStoredOnRemoteDiskWithZeroCopySupport();\n+\n+            auto dst_part = cloneAndLoadDataPartOnSameDisk(src_part, TMP_PREFIX, dst_part_info, metadata_snapshot, NO_TRANSACTION_PTR, &hardlinked_files, copy_instead_of_hardlink);\n \n             src_parts.emplace_back(src_part);\n             dst_parts.emplace_back(dst_part);\n             ephemeral_locks.emplace_back(std::move(*lock));\n             block_id_paths.emplace_back(block_id_path);\n             part_checksums.emplace_back(hash_hex);\n+            hardlinked_files_for_parts.emplace_back(hardlinked_files);\n         }\n \n         ReplicatedMergeTreeLogEntryData entry;\n@@ -6477,6 +6512,9 @@ void StorageReplicatedMergeTree::replacePartitionFrom(\n                     renameTempPartAndReplace(part, query_context->getCurrentTransaction().get(), nullptr, &transaction, data_parts_lock);\n             }\n \n+            for (size_t i = 0; i < dst_parts.size(); ++i)\n+                lockSharedData(*dst_parts[i], false, hardlinked_files_for_parts[i]);\n+\n             Coordination::Error code = zookeeper->tryMulti(ops, op_results);\n             if (code == Coordination::Error::ZOK)\n                 delimiting_block_lock->assumeUnlocked();\n@@ -6504,6 +6542,9 @@ void StorageReplicatedMergeTree::replacePartitionFrom(\n         catch (...)\n         {\n             PartLog::addNewParts(getContext(), dst_parts, watch.elapsed(), ExecutionStatus::fromCurrentException());\n+            for (const auto & dst_part : dst_parts)\n+                unlockSharedData(*dst_part);\n+\n             throw;\n         }\n \n@@ -6536,6 +6577,7 @@ void StorageReplicatedMergeTree::movePartitionToTable(const StoragePtr & dest_ta\n {\n     auto lock1 = lockForShare(query_context->getCurrentQueryId(), query_context->getSettingsRef().lock_acquire_timeout);\n     auto lock2 = dest_table->lockForShare(query_context->getCurrentQueryId(), query_context->getSettingsRef().lock_acquire_timeout);\n+    auto storage_settings_ptr = getSettings();\n \n     auto dest_table_storage = std::dynamic_pointer_cast<StorageReplicatedMergeTree>(dest_table);\n     if (!dest_table_storage)\n@@ -6605,6 +6647,8 @@ void StorageReplicatedMergeTree::movePartitionToTable(const StoragePtr & dest_ta\n         String dest_alter_partition_version_path = dest_table_storage->zookeeper_path + \"/alter_partition_version\";\n         Coordination::Stat dest_alter_partition_version_stat;\n         zookeeper->get(dest_alter_partition_version_path, &dest_alter_partition_version_stat);\n+        std::vector<MergeTreeData::HardlinkedFiles> hardlinked_files_for_parts;\n+\n         for (const auto & src_part : src_all_parts)\n         {\n             if (!dest_table_storage->canReplacePartition(src_part))\n@@ -6624,13 +6668,20 @@ void StorageReplicatedMergeTree::movePartitionToTable(const StoragePtr & dest_ta\n \n             UInt64 index = lock->getNumber();\n             MergeTreePartInfo dst_part_info(partition_id, index, index, src_part->info.level);\n-            auto dst_part = dest_table_storage->cloneAndLoadDataPartOnSameDisk(src_part, TMP_PREFIX, dst_part_info, dest_metadata_snapshot, NO_TRANSACTION_PTR);\n+\n+            MergeTreeData::HardlinkedFiles hardlinked_files;\n+\n+            bool copy_instead_of_hardlink = storage_settings_ptr->allow_remote_fs_zero_copy_replication\n+                                            && src_part->isStoredOnRemoteDiskWithZeroCopySupport();\n+\n+            auto dst_part = dest_table_storage->cloneAndLoadDataPartOnSameDisk(src_part, TMP_PREFIX, dst_part_info, dest_metadata_snapshot, NO_TRANSACTION_PTR, &hardlinked_files, copy_instead_of_hardlink);\n \n             src_parts.emplace_back(src_part);\n             dst_parts.emplace_back(dst_part);\n             ephemeral_locks.emplace_back(std::move(*lock));\n             block_id_paths.emplace_back(block_id_path);\n             part_checksums.emplace_back(hash_hex);\n+            hardlinked_files_for_parts.emplace_back(hardlinked_files);\n         }\n \n         ReplicatedMergeTreeLogEntryData entry_delete;\n@@ -6697,6 +6748,9 @@ void StorageReplicatedMergeTree::movePartitionToTable(const StoragePtr & dest_ta\n                 for (MutableDataPartPtr & part : dst_parts)\n                     dest_table_storage->renameTempPartAndReplace(part, query_context->getCurrentTransaction().get(), nullptr, &transaction, lock);\n \n+                for (size_t i = 0; i < dst_parts.size(); ++i)\n+                    dest_table_storage->lockSharedData(*dst_parts[i], false, hardlinked_files_for_parts[i]);\n+\n                 Coordination::Error code = zookeeper->tryMulti(ops, op_results);\n                 if (code == Coordination::Error::ZBADVERSION)\n                     continue;\n@@ -6712,6 +6766,10 @@ void StorageReplicatedMergeTree::movePartitionToTable(const StoragePtr & dest_ta\n         catch (...)\n         {\n             PartLog::addNewParts(getContext(), dst_parts, watch.elapsed(), ExecutionStatus::fromCurrentException());\n+\n+            for (const auto & dst_part : dst_parts)\n+                dest_table_storage->unlockSharedData(*dst_part);\n+\n             throw;\n         }\n \n@@ -7305,7 +7363,9 @@ void StorageReplicatedMergeTree::createTableSharedID()\n \n void StorageReplicatedMergeTree::lockSharedDataTemporary(const String & part_name, const String & part_id, const DiskPtr & disk) const\n {\n-    if (!disk || !disk->supportZeroCopyReplication())\n+    auto settings = getSettings();\n+\n+    if (!disk || !disk->supportZeroCopyReplication() || !settings->allow_remote_fs_zero_copy_replication)\n         return;\n \n     zkutil::ZooKeeperPtr zookeeper = tryGetZooKeeper();\n@@ -7327,9 +7387,11 @@ void StorageReplicatedMergeTree::lockSharedDataTemporary(const String & part_nam\n     }\n }\n \n-void StorageReplicatedMergeTree::lockSharedData(const IMergeTreeDataPart & part, bool replace_existing_lock) const\n+void StorageReplicatedMergeTree::lockSharedData(const IMergeTreeDataPart & part, bool replace_existing_lock, std::optional<HardlinkedFiles> hardlinked_files) const\n {\n-    if (!part.volume || !part.isStoredOnDisk())\n+    auto settings = getSettings();\n+\n+    if (!part.volume || !part.isStoredOnDisk() || !settings->allow_remote_fs_zero_copy_replication)\n         return;\n \n     DiskPtr disk = part.volume->getDisk();\n@@ -7343,33 +7405,42 @@ void StorageReplicatedMergeTree::lockSharedData(const IMergeTreeDataPart & part,\n     String id = part.getUniqueId();\n     boost::replace_all(id, \"/\", \"_\");\n \n-    Strings zc_zookeeper_paths = getZeroCopyPartPath(*getSettings(), disk->getType(), getTableSharedID(),\n+    Strings zc_zookeeper_paths = getZeroCopyPartPath(\n+        *getSettings(), disk->getType(), getTableSharedID(),\n         part.name, zookeeper_path);\n+\n+    String path_to_set_hardlinked_files;\n+    NameSet hardlinks;\n+\n+    if (hardlinked_files.has_value() && !hardlinked_files->hardlinks_from_source_part.empty())\n+    {\n+        path_to_set_hardlinked_files = getZeroCopyPartPath(\n+            *getSettings(), disk->getType(), hardlinked_files->source_table_shared_id,\n+            hardlinked_files->source_part_name, zookeeper_path)[0];\n+\n+        hardlinks = hardlinked_files->hardlinks_from_source_part;\n+    }\n+\n     for (const auto & zc_zookeeper_path : zc_zookeeper_paths)\n     {\n         String zookeeper_node = fs::path(zc_zookeeper_path) / id / replica_name;\n \n         LOG_TRACE(log, \"Set zookeeper persistent lock {}\", zookeeper_node);\n \n-        createZeroCopyLockNode(zookeeper, zookeeper_node, zkutil::CreateMode::Persistent, replace_existing_lock);\n+        createZeroCopyLockNode(\n+            zookeeper, zookeeper_node, zkutil::CreateMode::Persistent,\n+            replace_existing_lock, path_to_set_hardlinked_files, hardlinks);\n     }\n }\n \n-\n-bool StorageReplicatedMergeTree::unlockSharedData(const IMergeTreeDataPart & part) const\n-{\n-    return unlockSharedData(part, part.name);\n-}\n-\n-\n-bool StorageReplicatedMergeTree::unlockSharedData(const IMergeTreeDataPart & part, const String & name) const\n+std::pair<bool, NameSet> StorageReplicatedMergeTree::unlockSharedData(const IMergeTreeDataPart & part) const\n {\n     if (!part.volume || !part.isStoredOnDisk())\n-        return true;\n+        return std::make_pair(true, NameSet{});\n \n     DiskPtr disk = part.volume->getDisk();\n     if (!disk || !disk->supportZeroCopyReplication())\n-        return true;\n+        return std::make_pair(true, NameSet{});\n \n     /// If part is temporary refcount file may be absent\n     auto ref_count_path = fs::path(part.getFullRelativePath()) / IMergeTreeDataPart::FILE_FOR_REFERENCES_CHECK;\n@@ -7377,20 +7448,20 @@ bool StorageReplicatedMergeTree::unlockSharedData(const IMergeTreeDataPart & par\n     {\n         auto ref_count = disk->getRefCount(ref_count_path);\n         if (ref_count > 0) /// Keep part shard info for frozen backups\n-            return false;\n+            return std::make_pair(false, NameSet{});\n     }\n     else\n     {\n         /// Temporary part with some absent file cannot be locked in shared mode\n-        return true;\n+        return std::make_pair(true, NameSet{});\n     }\n \n-    return unlockSharedDataByID(part.getUniqueId(), getTableSharedID(), name, replica_name, disk, getZooKeeper(), *getSettings(), log,\n+    return unlockSharedDataByID(part.getUniqueId(), getTableSharedID(), part.name, replica_name, disk, getZooKeeper(), *getSettings(), log,\n         zookeeper_path);\n }\n \n-\n-bool StorageReplicatedMergeTree::unlockSharedDataByID(String part_id, const String & table_uuid, const String & part_name,\n+std::pair<bool, NameSet> StorageReplicatedMergeTree::unlockSharedDataByID(\n+        String part_id, const String & table_uuid, const String & part_name,\n         const String & replica_name_, DiskPtr disk, zkutil::ZooKeeperPtr zookeeper_ptr, const MergeTreeSettings & settings,\n         Poco::Logger * logger, const String & zookeeper_path_old)\n {\n@@ -7399,17 +7470,28 @@ bool StorageReplicatedMergeTree::unlockSharedDataByID(String part_id, const Stri\n     Strings zc_zookeeper_paths = getZeroCopyPartPath(settings, disk->getType(), table_uuid, part_name, zookeeper_path_old);\n \n     bool part_has_no_more_locks = true;\n+    NameSet files_not_to_remove;\n \n     for (const auto & zc_zookeeper_path : zc_zookeeper_paths)\n     {\n+        String files_not_to_remove_str;\n+        zookeeper_ptr->tryGet(zc_zookeeper_path, files_not_to_remove_str);\n+\n+        files_not_to_remove.clear();\n+        if (!files_not_to_remove_str.empty())\n+            boost::split(files_not_to_remove, files_not_to_remove_str, boost::is_any_of(\"\\n \"));\n+\n         String zookeeper_part_uniq_node = fs::path(zc_zookeeper_path) / part_id;\n \n         /// Delete our replica node for part from zookeeper (we are not interested in it anymore)\n         String zookeeper_part_replica_node = fs::path(zookeeper_part_uniq_node) / replica_name_;\n \n-        LOG_TRACE(logger, \"Remove zookeeper lock {}\", zookeeper_part_replica_node);\n+        LOG_TRACE(logger, \"Remove zookeeper lock {} for part {}\", zookeeper_part_replica_node, part_name);\n \n-        zookeeper_ptr->tryRemove(zookeeper_part_replica_node);\n+        if (auto ec = zookeeper_ptr->tryRemove(zookeeper_part_replica_node); ec != Coordination::Error::ZOK && ec != Coordination::Error::ZNONODE)\n+        {\n+            throw zkutil::KeeperException(ec, zookeeper_part_replica_node);\n+        }\n \n         /// Check, maybe we were the last replica and can remove part forever\n         Strings children;\n@@ -7417,37 +7499,66 @@ bool StorageReplicatedMergeTree::unlockSharedDataByID(String part_id, const Stri\n \n         if (!children.empty())\n         {\n-            LOG_TRACE(logger, \"Found zookeper locks for {}\", zookeeper_part_uniq_node);\n+            LOG_TRACE(logger, \"Found {} ({}) zookeper locks for {}\", zookeeper_part_uniq_node, children.size(), fmt::join(children, \", \"));\n             part_has_no_more_locks = false;\n             continue;\n         }\n \n         auto error_code = zookeeper_ptr->tryRemove(zookeeper_part_uniq_node);\n \n-        LOG_TRACE(logger, \"Remove parent zookeeper lock {} : {}\", zookeeper_part_uniq_node, error_code != Coordination::Error::ZNOTEMPTY);\n+        if (error_code == Coordination::Error::ZOK)\n+        {\n+            LOG_TRACE(logger, \"Removed last parent zookeeper lock {} for part {} with id {}\", zookeeper_part_uniq_node, part_name, part_id);\n+        }\n+        else if (error_code == Coordination::Error::ZNOTEMPTY)\n+        {\n+            LOG_TRACE(logger, \"Cannot remove last parent zookeeper lock {} for part {} with id {}, another replica locked part concurrently\", zookeeper_part_uniq_node, part_name, part_id);\n+        }\n+        else if (error_code == Coordination::Error::ZNONODE)\n+        {\n+            LOG_TRACE(logger, \"Node with parent zookeeper lock {} for part {} with id {} doesn't exist\", zookeeper_part_uniq_node, part_name, part_id);\n+        }\n+        else\n+        {\n+            throw zkutil::KeeperException(error_code, zookeeper_part_uniq_node);\n+        }\n+\n \n         /// Even when we have lock with same part name, but with different uniq, we can remove files on S3\n         children.clear();\n         String zookeeper_part_node = fs::path(zookeeper_part_uniq_node).parent_path();\n         zookeeper_ptr->tryGetChildren(zookeeper_part_node, children);\n+\n         if (children.empty())\n         {\n             /// Cleanup after last uniq removing\n             error_code = zookeeper_ptr->tryRemove(zookeeper_part_node);\n \n-            LOG_TRACE(logger, \"Remove parent zookeeper lock {} : {}\", zookeeper_part_node, error_code != Coordination::Error::ZNOTEMPTY);\n+            if (error_code == Coordination::Error::ZOK)\n+            {\n+                LOG_TRACE(logger, \"Removed last parent zookeeper lock {} for part {} (part is finally unlocked)\", zookeeper_part_uniq_node, part_name);\n+            }\n+            else if (error_code == Coordination::Error::ZNOTEMPTY)\n+            {\n+                LOG_TRACE(logger, \"Cannot remove last parent zookeeper lock {} for part {}, another replica locked part concurrently\", zookeeper_part_uniq_node, part_name);\n+            }\n+            else if (error_code == Coordination::Error::ZNONODE)\n+            {\n+                LOG_TRACE(logger, \"Node with parent zookeeper lock {} for part {} doesn't exist (part was unlocked before)\", zookeeper_part_uniq_node, part_name);\n+            }\n+            else\n+            {\n+                throw zkutil::KeeperException(error_code, zookeeper_part_uniq_node);\n+            }\n         }\n         else\n         {\n-            LOG_TRACE(logger, \"Can't remove parent zookeeper lock {} : {}\", zookeeper_part_node, children.size());\n-            for (auto & c : children)\n-            {\n-                LOG_TRACE(logger, \"Child node {}\", c);\n-            }\n+            LOG_TRACE(logger, \"Can't remove parent zookeeper lock {} for part {}, because children {} ({}) were concurrently created\",\n+                      zookeeper_part_node, part_name, children.size(), fmt::join(children, \", \"));\n         }\n     }\n \n-    return part_has_no_more_locks;\n+    return std::make_pair(part_has_no_more_locks, files_not_to_remove);\n }\n \n \n@@ -7780,6 +7891,8 @@ bool StorageReplicatedMergeTree::createEmptyPartInsteadOfLost(zkutil::ZooKeeperP\n             throw Exception(ErrorCodes::INCORRECT_DATA, \"Tried to create empty part {}, but it replaces existing parts {}.\", lost_part_name, fmt::join(part_names, \", \"));\n         }\n \n+        lockSharedData(*new_data_part, false, {});\n+\n         while (true)\n         {\n \n@@ -7827,6 +7940,7 @@ bool StorageReplicatedMergeTree::createEmptyPartInsteadOfLost(zkutil::ZooKeeperP\n     }\n     catch (const Exception & ex)\n     {\n+        unlockSharedData(*new_data_part);\n         LOG_WARNING(log, \"Cannot commit empty part {} with error {}\", lost_part_name, ex.displayText());\n         return false;\n     }\n@@ -7837,11 +7951,14 @@ bool StorageReplicatedMergeTree::createEmptyPartInsteadOfLost(zkutil::ZooKeeperP\n }\n \n \n-void StorageReplicatedMergeTree::createZeroCopyLockNode(const zkutil::ZooKeeperPtr & zookeeper, const String & zookeeper_node, int32_t mode, bool replace_existing_lock)\n+void StorageReplicatedMergeTree::createZeroCopyLockNode(\n+    const zkutil::ZooKeeperPtr & zookeeper, const String & zookeeper_node, int32_t mode,\n+    bool replace_existing_lock, const String & path_to_set_hardlinked_files, const NameSet & hardlinked_files)\n {\n     /// In rare case other replica can remove path between createAncestors and createIfNotExists\n     /// So we make up to 5 attempts\n \n+    bool created = false;\n     for (int attempts = 5; attempts > 0; --attempts)\n     {\n         try\n@@ -7857,25 +7974,67 @@ void StorageReplicatedMergeTree::createZeroCopyLockNode(const zkutil::ZooKeeperP\n                 Coordination::Requests ops;\n                 ops.emplace_back(zkutil::makeRemoveRequest(zookeeper_node, -1));\n                 ops.emplace_back(zkutil::makeCreateRequest(zookeeper_node, \"\", mode));\n+                if (!path_to_set_hardlinked_files.empty() && !hardlinked_files.empty())\n+                {\n+                    std::string data = boost::algorithm::join(hardlinked_files, \"\\n\");\n+                    /// List of files used to detect hardlinks. path_to_set_hardlinked_files --\n+                    /// is a path to source part zero copy node. During part removal hardlinked\n+                    /// files will be left for source part.\n+                    ops.emplace_back(zkutil::makeSetRequest(path_to_set_hardlinked_files, data, -1));\n+                }\n                 Coordination::Responses responses;\n                 auto error = zookeeper->tryMulti(ops, responses);\n                 if (error == Coordination::Error::ZOK)\n+                {\n+                    created = true;\n                     break;\n+                }\n+                else if (error == Coordination::Error::ZNONODE && mode != zkutil::CreateMode::Persistent)\n+                {\n+                    throw Exception(ErrorCodes::NOT_FOUND_NODE, \"Cannot create ephemeral zero copy lock {} because part was unlocked from zookeeper\", zookeeper_node);\n+                }\n             }\n             else\n             {\n-                auto error = zookeeper->tryCreate(zookeeper_node, \"\", mode);\n+                Coordination::Requests ops;\n+                if (!path_to_set_hardlinked_files.empty() && !hardlinked_files.empty())\n+                {\n+                    std::string data = boost::algorithm::join(hardlinked_files, \"\\n\");\n+                    /// List of files used to detect hardlinks. path_to_set_hardlinked_files --\n+                    /// is a path to source part zero copy node. During part removal hardlinked\n+                    /// files will be left for source part.\n+                    ops.emplace_back(zkutil::makeSetRequest(path_to_set_hardlinked_files, data, -1));\n+                }\n+                ops.emplace_back(zkutil::makeCreateRequest(zookeeper_node, \"\", mode));\n+\n+                Coordination::Responses responses;\n+                auto error = zookeeper->tryMulti(ops, responses);\n                 if (error == Coordination::Error::ZOK || error == Coordination::Error::ZNODEEXISTS)\n+                {\n+                    created = true;\n                     break;\n+                }\n+                else if (error == Coordination::Error::ZNONODE && mode != zkutil::CreateMode::Persistent)\n+                {\n+                    /// Ephemeral locks used during fetches so if parent node was removed we cannot do anything\n+                    throw Exception(ErrorCodes::NOT_FOUND_NODE, \"Cannot create ephemeral zero copy lock {} because part was unlocked from zookeeper\", zookeeper_node);\n+                }\n             }\n         }\n         catch (const zkutil::KeeperException & e)\n         {\n             if (e.code == Coordination::Error::ZNONODE)\n                 continue;\n+\n             throw;\n         }\n     }\n+\n+    if (!created)\n+    {\n+        String mode_str = mode == zkutil::CreateMode::Persistent ? \"persistent\" : \"ephemral\";\n+        throw Exception(ErrorCodes::NOT_FOUND_NODE, \"Cannot create {} zero copy lock {} because part was unlocked from zookeeper\", mode_str, zookeeper_node);\n+    }\n }\n \n \n@@ -8000,6 +8159,7 @@ bool StorageReplicatedMergeTree::removeSharedDetachedPart(DiskPtr disk, const St\n     bool keep_shared = false;\n \n     zkutil::ZooKeeperPtr zookeeper = getZooKeeper();\n+    NameSet files_not_to_remove;\n \n     fs::path checksums = fs::path(path) / IMergeTreeDataPart::FILE_FOR_REFERENCES_CHECK;\n     if (disk->exists(checksums))\n@@ -8007,15 +8167,18 @@ bool StorageReplicatedMergeTree::removeSharedDetachedPart(DiskPtr disk, const St\n         if (disk->getRefCount(checksums) == 0)\n         {\n             String id = disk->getUniqueId(checksums);\n-            keep_shared = !StorageReplicatedMergeTree::unlockSharedDataByID(id, table_uuid, part_name,\n+            bool can_remove = false;\n+            std::tie(can_remove, files_not_to_remove) = StorageReplicatedMergeTree::unlockSharedDataByID(id, table_uuid, part_name,\n                 detached_replica_name, disk, zookeeper, getContext()->getReplicatedMergeTreeSettings(), log,\n                 detached_zookeeper_path);\n+\n+            keep_shared = !can_remove;\n         }\n         else\n             keep_shared = true;\n     }\n \n-    disk->removeSharedRecursive(path, keep_shared);\n+    disk->removeSharedRecursive(path, keep_shared, files_not_to_remove);\n \n     return keep_shared;\n }\ndiff --git a/src/Storages/StorageReplicatedMergeTree.h b/src/Storages/StorageReplicatedMergeTree.h\nindex e2528d60d072..096ef20cf7fd 100644\n--- a/src/Storages/StorageReplicatedMergeTree.h\n+++ b/src/Storages/StorageReplicatedMergeTree.h\n@@ -236,22 +236,19 @@ class StorageReplicatedMergeTree final : public shared_ptr_helper<StorageReplica\n     bool executeFetchShared(const String & source_replica, const String & new_part_name, const DiskPtr & disk, const String & path);\n \n     /// Lock part in zookeeper for use shared data in several nodes\n-    void lockSharedData(const IMergeTreeDataPart & part, bool replace_existing_lock) const override;\n+    void lockSharedData(const IMergeTreeDataPart & part, bool replace_existing_lock, std::optional<HardlinkedFiles> hardlinked_files) const override;\n \n     void lockSharedDataTemporary(const String & part_name, const String & part_id, const DiskPtr & disk) const;\n \n     /// Unlock shared data part in zookeeper\n     /// Return true if data unlocked\n     /// Return false if data is still used by another node\n-    bool unlockSharedData(const IMergeTreeDataPart & part) const override;\n-\n-    /// Remove lock with old name for shared data part after rename\n-    bool unlockSharedData(const IMergeTreeDataPart & part, const String & name) const override;\n+    std::pair<bool, NameSet> unlockSharedData(const IMergeTreeDataPart & part) const override;\n \n     /// Unlock shared data part in zookeeper by part id\n     /// Return true if data unlocked\n     /// Return false if data is still used by another node\n-    static bool unlockSharedDataByID(String part_id, const String & table_uuid, const String & part_name, const String & replica_name_,\n+    static std::pair<bool, NameSet> unlockSharedDataByID(String part_id, const String & table_uuid, const String & part_name, const String & replica_name_,\n         DiskPtr disk, zkutil::ZooKeeperPtr zookeeper_, const MergeTreeSettings & settings, Poco::Logger * logger,\n         const String & zookeeper_path_old);\n \n@@ -286,7 +283,7 @@ class StorageReplicatedMergeTree final : public shared_ptr_helper<StorageReplica\n     String getZooKeeperName() const { return zookeeper_name; }\n \n     // Return table id, common for different replicas\n-    String getTableSharedID() const;\n+    String getTableSharedID() const override;\n \n     static String getDefaultZooKeeperName() { return default_zookeeper_name; }\n \n@@ -479,7 +476,7 @@ class StorageReplicatedMergeTree final : public shared_ptr_helper<StorageReplica\n     String getChecksumsForZooKeeper(const MergeTreeDataPartChecksums & checksums) const;\n \n     /// Accepts a PreActive part, atomically checks its checksums with ones on other replicas and commit the part\n-    DataPartsVector checkPartChecksumsAndCommit(Transaction & transaction, const DataPartPtr & part);\n+    DataPartsVector checkPartChecksumsAndCommit(Transaction & transaction, const DataPartPtr & part, std::optional<HardlinkedFiles> hardlinked_files = {});\n \n     bool partIsAssignedToBackgroundOperation(const DataPartPtr & part) const override;\n \n@@ -624,7 +621,8 @@ class StorageReplicatedMergeTree final : public shared_ptr_helper<StorageReplica\n         const String & replica_path,\n         bool to_detached,\n         size_t quorum,\n-        zkutil::ZooKeeper::Ptr zookeeper_ = nullptr);\n+        zkutil::ZooKeeper::Ptr zookeeper_ = nullptr,\n+        bool try_fetch_shared = true);\n \n     /** Download the specified part from the specified replica.\n       * Used for replace local part on the same s3-shared part in hybrid storage.\n@@ -766,7 +764,10 @@ class StorageReplicatedMergeTree final : public shared_ptr_helper<StorageReplica\n     static Strings getZeroCopyPartPath(const MergeTreeSettings & settings, DiskType disk_type, const String & table_uuid,\n         const String & part_name, const String & zookeeper_path_old);\n \n-    static void createZeroCopyLockNode(const zkutil::ZooKeeperPtr & zookeeper, const String & zookeeper_node, int32_t mode = zkutil::CreateMode::Persistent, bool replace_existing_lock = false);\n+    static void createZeroCopyLockNode(\n+        const zkutil::ZooKeeperPtr & zookeeper, const String & zookeeper_node,\n+        int32_t mode = zkutil::CreateMode::Persistent, bool replace_existing_lock = false,\n+        const String & path_to_set_hardlinked_files = \"\", const NameSet & hardlinked_files = {});\n \n     bool removeDetachedPart(DiskPtr disk, const String & path, const String & part_name, bool is_freezed) override;\n \n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02067_lost_part_s3.reference b/tests/queries/0_stateless/02067_lost_part_s3.reference\nnew file mode 100644\nindex 000000000000..f6f7853d3b69\n--- /dev/null\n+++ b/tests/queries/0_stateless/02067_lost_part_s3.reference\n@@ -0,0 +1,3 @@\n+10000\n+10000\n+10000\ndiff --git a/tests/queries/0_stateless/02067_lost_part_s3.sql b/tests/queries/0_stateless/02067_lost_part_s3.sql\nnew file mode 100644\nindex 000000000000..ee3297331cde\n--- /dev/null\n+++ b/tests/queries/0_stateless/02067_lost_part_s3.sql\n@@ -0,0 +1,32 @@\n+DROP TABLE IF EXISTS partslost_0;\n+DROP TABLE IF EXISTS partslost_1;\n+DROP TABLE IF EXISTS partslost_2;\n+\n+CREATE TABLE partslost_0 (x String) ENGINE=ReplicatedMergeTree('/clickhouse/table/{database}_02067_lost/partslost', '0') ORDER BY tuple() SETTINGS min_rows_for_wide_part = 0, min_bytes_for_wide_part = 0, old_parts_lifetime = 1, cleanup_delay_period = 1, cleanup_delay_period_random_add = 1;\n+\n+CREATE TABLE partslost_1 (x String) ENGINE=ReplicatedMergeTree('/clickhouse/table/{database}_02067_lost/partslost', '1') ORDER BY tuple() SETTINGS min_rows_for_wide_part = 0, min_bytes_for_wide_part = 0, old_parts_lifetime = 1, cleanup_delay_period = 1, cleanup_delay_period_random_add = 1;\n+\n+CREATE TABLE partslost_2 (x String) ENGINE=ReplicatedMergeTree('/clickhouse/table/{database}_02067_lost/partslost', '2') ORDER BY tuple() SETTINGS min_rows_for_wide_part = 0, min_bytes_for_wide_part = 0, old_parts_lifetime = 1, cleanup_delay_period = 1, cleanup_delay_period_random_add = 1;\n+\n+\n+INSERT INTO partslost_0 SELECT toString(number) AS x from system.numbers LIMIT 10000;\n+\n+ALTER TABLE partslost_0 ADD INDEX idx x TYPE tokenbf_v1(285000, 3, 12345) GRANULARITY 3;\n+\n+ALTER TABLE partslost_0 MATERIALIZE INDEX idx;\n+\n+-- In worst case doesn't check anything, but it's not flaky\n+select sleep(3) FORMAT Null;\n+select sleep(3) FORMAT Null;\n+select sleep(3) FORMAT Null;\n+select sleep(3) FORMAT Null;\n+\n+ALTER TABLE partslost_0 DROP INDEX idx;\n+\n+select count() from partslost_0;\n+select count() from partslost_1;\n+select count() from partslost_2;\n+\n+DROP TABLE IF EXISTS partslost_0;\n+DROP TABLE IF EXISTS partslost_1;\n+DROP TABLE IF EXISTS partslost_2;\ndiff --git a/tests/queries/0_stateless/02271_replace_partition_many_tables.reference b/tests/queries/0_stateless/02271_replace_partition_many_tables.reference\nnew file mode 100644\nindex 000000000000..627e1097cda3\n--- /dev/null\n+++ b/tests/queries/0_stateless/02271_replace_partition_many_tables.reference\n@@ -0,0 +1,5 @@\n+1\n+1\n+1\n+1\n+1\ndiff --git a/tests/queries/0_stateless/02271_replace_partition_many_tables.sql b/tests/queries/0_stateless/02271_replace_partition_many_tables.sql\nnew file mode 100644\nindex 000000000000..a31a2bee58a6\n--- /dev/null\n+++ b/tests/queries/0_stateless/02271_replace_partition_many_tables.sql\n@@ -0,0 +1,82 @@\n+DROP TABLE IF EXISTS replace_partition_source;\n+DROP TABLE IF EXISTS replace_partition_dest1;\n+DROP TABLE IF EXISTS replace_partition_dest1_2;\n+DROP TABLE IF EXISTS replace_partition_dest2;\n+DROP TABLE IF EXISTS replace_partition_dest2_2;\n+\n+CREATE TABLE replace_partition_source\n+(\n+    key UInt64\n+)\n+ENGINE = ReplicatedMergeTree('/test/02271_replace_partition_many/{database}/source', '1')\n+PARTITION BY key\n+ORDER BY tuple();\n+\n+INSERT INTO replace_partition_source VALUES (1);\n+\n+CREATE TABLE replace_partition_dest1\n+(\n+    key UInt64\n+)\n+ENGINE = ReplicatedMergeTree('/test/02271_replace_partition_many/{database}/dest1', '1')\n+PARTITION BY key\n+ORDER BY tuple();\n+\n+CREATE TABLE replace_partition_dest1_2\n+(\n+    key UInt64\n+)\n+ENGINE = ReplicatedMergeTree('/test/02271_replace_partition_many/{database}/dest1', '2')\n+PARTITION BY key\n+ORDER BY tuple();\n+\n+\n+CREATE TABLE replace_partition_dest2\n+(\n+    key UInt64\n+)\n+ENGINE = ReplicatedMergeTree('/test/02271_replace_partition_many/{database}/dest2', '1')\n+PARTITION BY key\n+ORDER BY tuple();\n+\n+CREATE TABLE replace_partition_dest2_2\n+(\n+    key UInt64\n+)\n+ENGINE = ReplicatedMergeTree('/test/02271_replace_partition_many/{database}/dest2', '2')\n+PARTITION BY key\n+ORDER BY tuple();\n+\n+\n+ALTER TABLE replace_partition_dest1 REPLACE PARTITION 1 FROM replace_partition_source;\n+ALTER TABLE replace_partition_dest2 REPLACE PARTITION 1 FROM replace_partition_source;\n+\n+OPTIMIZE TABLE replace_partition_source FINAL;\n+\n+SELECT sleep(3) FORMAT Null;\n+SELECT sleep(3) FORMAT Null;\n+SELECT sleep(3) FORMAT Null;\n+SELECT sleep(3) FORMAT Null;\n+SELECT sleep(3) FORMAT Null;\n+\n+OPTIMIZE TABLE replace_partition_dest1_2 FINAL;\n+OPTIMIZE TABLE replace_partition_dest2_2 FINAL;\n+\n+SELECT sleep(3) FORMAT Null;\n+SELECT sleep(3) FORMAT Null;\n+SELECT sleep(3) FORMAT Null;\n+SELECT sleep(3) FORMAT Null;\n+SELECT sleep(3) FORMAT Null;\n+\n+SELECT * FROM replace_partition_source;\n+SELECT * FROM replace_partition_dest1;\n+SELECT * FROM replace_partition_dest2;\n+SELECT * FROM replace_partition_dest1_2;\n+SELECT * FROM replace_partition_dest2_2;\n+\n+\n+--DROP TABLE IF EXISTS replace_partition_source;\n+--DROP TABLE IF EXISTS replace_partition_dest1;\n+--DROP TABLE IF EXISTS replace_partition_dest1_2;\n+--DROP TABLE IF EXISTS replace_partition_dest2;\n+--DROP TABLE IF EXISTS replace_partition_dest2_2;\n",
  "problem_statement": "Broken part after DROP INDEX when using a s3 disk (only when using non-production \"zero-copy replication\")\n**Describe what's wrong**\r\n\r\nBroken part (which leads to missing data) after `DROP INDEX` when using a s3 disk.\r\n\r\n**Does it reproduce on recent release?**\r\n\r\nYes. Tested on  22.4.1.1289\r\n\r\n**How to reproduce**\r\n\r\nPrerequesite: Create a storage policy with s3 disks named `s3`.\r\n\r\n```\r\nCREATE TABLE partslost\r\n  (x String) \r\nENGINE=ReplicatedMergeTree('/clickhouse/table/partslost/{shard}', '{replica}') \r\nORDER BY tuple() \r\nSETTINGS \r\n   min_rows_for_wide_part = 0, \r\n   min_bytes_for_wide_part = 0, \r\n   old_parts_lifetime = 10;\r\n\r\nINSERT INTO partslost SELECT toString(number) AS x from system.numbers LIMIT 10000;\r\n\r\n-- not sure if this is necessary\r\nOPTIMIZE TABLE partslost FINAL;\r\n\r\n-- the concrete type of the index probably doesn't matter\r\nALTER TABLE partslost ADD INDEX idx x TYPE tokenbf_v1(285000, 3, 12345) GRANULARITY 3;\r\n\r\nALTER TABLE partslost MATERIALIZE INDEX idx;\r\n\r\n-- this causes a mutation where new parts reuse (s3) files of the old part \r\nALTER TABLE partslost DROP INDEX idx\r\n```\r\n\r\nAfter some time, I see this in the log file:\r\n```\r\n2022.04.14 08:10:06.372439 [ 226 ] {} <Error> default.partslost (ReplicatedMergeTreePartCheckThread): Part all_0_0_1_2 looks broken. Removing it and will try to fetch.\r\n```\r\nand the part is moved to the `detached/broken/all_0_0_1_2` directory.\r\n\r\nAfter that, a `SELECT * FROM partslost` returns 0 rows.\r\n\r\n**Expected behavior**\r\n\r\nPart shouldn't be broken and `SELECT * FROM partslost` should still return 10000 rows.\r\n\r\n**Additional Context**\r\nIt seems that the part `all_0_0_1_2` (which is the result of the drop-index-mutation) reuses some files of the previous `all_0_0_1_1` part. But when the old `all_0_0_1_1` is removed, then those files are deleted from S3 - which turns the new `all_0_0_1_2` into a \"broken\" part because files are missing.\r\n\n",
  "hints_text": "",
  "created_at": "2022-04-15T14:25:54Z",
  "modified_files": [
    "src/Disks/DiskCacheWrapper.cpp",
    "src/Disks/DiskCacheWrapper.h",
    "src/Disks/DiskDecorator.cpp",
    "src/Disks/DiskDecorator.h",
    "src/Disks/DiskEncrypted.cpp",
    "src/Disks/DiskEncrypted.h",
    "src/Disks/DiskLocal.cpp",
    "src/Disks/DiskLocal.h",
    "src/Disks/DiskRestartProxy.cpp",
    "src/Disks/DiskRestartProxy.h",
    "src/Disks/DiskWebServer.cpp",
    "src/Disks/DiskWebServer.h",
    "src/Disks/IDisk.cpp",
    "src/Disks/IDisk.h",
    "src/Disks/IDiskRemote.cpp",
    "src/Disks/IDiskRemote.h",
    "src/Disks/S3/DiskS3.cpp",
    "src/Storages/MergeTree/DataPartsExchange.cpp",
    "src/Storages/MergeTree/IMergeTreeDataPart.cpp",
    "src/Storages/MergeTree/IMergeTreeDataPart.h",
    "src/Storages/MergeTree/MergeTreeData.cpp",
    "src/Storages/MergeTree/MergeTreeData.h",
    "src/Storages/MergeTree/MergeTreeDataPartCompact.cpp",
    "src/Storages/MergeTree/MergeTreeDataPartCompact.h",
    "src/Storages/MergeTree/MergeTreeDataPartInMemory.h",
    "src/Storages/MergeTree/MergeTreeDataPartWide.cpp",
    "src/Storages/MergeTree/MergeTreeDataPartWide.h",
    "src/Storages/MergeTree/MergeTreePartInfo.h",
    "src/Storages/MergeTree/MergeTreePartsMover.cpp",
    "src/Storages/MergeTree/MergedBlockOutputStream.cpp",
    "src/Storages/MergeTree/MutateFromLogEntryTask.cpp",
    "src/Storages/MergeTree/MutateTask.cpp",
    "src/Storages/MergeTree/MutateTask.h",
    "src/Storages/MergeTree/ReplicatedMergeTreeSink.cpp",
    "src/Storages/MergeTree/localBackup.cpp",
    "src/Storages/MergeTree/localBackup.h",
    "src/Storages/StorageMergeTree.cpp",
    "src/Storages/StorageReplicatedMergeTree.cpp",
    "src/Storages/StorageReplicatedMergeTree.h"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/02067_lost_part_s3.reference",
    "b/tests/queries/0_stateless/02067_lost_part_s3.sql",
    "b/tests/queries/0_stateless/02271_replace_partition_many_tables.reference",
    "b/tests/queries/0_stateless/02271_replace_partition_many_tables.sql"
  ]
}