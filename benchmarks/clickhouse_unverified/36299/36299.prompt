You will be provided with a partial code base and an issue statement explaining a problem to resolve.

<issue>
Broken part after DROP INDEX when using a s3 disk (only when using non-production "zero-copy replication")
**Describe what's wrong**

Broken part (which leads to missing data) after `DROP INDEX` when using a s3 disk.

**Does it reproduce on recent release?**

Yes. Tested on  22.4.1.1289

**How to reproduce**

Prerequesite: Create a storage policy with s3 disks named `s3`.

```
CREATE TABLE partslost
  (x String) 
ENGINE=ReplicatedMergeTree('/clickhouse/table/partslost/{shard}', '{replica}') 
ORDER BY tuple() 
SETTINGS 
   min_rows_for_wide_part = 0, 
   min_bytes_for_wide_part = 0, 
   old_parts_lifetime = 10;

INSERT INTO partslost SELECT toString(number) AS x from system.numbers LIMIT 10000;

-- not sure if this is necessary
OPTIMIZE TABLE partslost FINAL;

-- the concrete type of the index probably doesn't matter
ALTER TABLE partslost ADD INDEX idx x TYPE tokenbf_v1(285000, 3, 12345) GRANULARITY 3;

ALTER TABLE partslost MATERIALIZE INDEX idx;

-- this causes a mutation where new parts reuse (s3) files of the old part 
ALTER TABLE partslost DROP INDEX idx
```

After some time, I see this in the log file:
```
2022.04.14 08:10:06.372439 [ 226 ] {} <Error> default.partslost (ReplicatedMergeTreePartCheckThread): Part all_0_0_1_2 looks broken. Removing it and will try to fetch.
```
and the part is moved to the `detached/broken/all_0_0_1_2` directory.

After that, a `SELECT * FROM partslost` returns 0 rows.

**Expected behavior**

Part shouldn't be broken and `SELECT * FROM partslost` should still return 10000 rows.

**Additional Context**
It seems that the part `all_0_0_1_2` (which is the result of the drop-index-mutation) reuses some files of the previous `all_0_0_1_1` part. But when the old `all_0_0_1_1` is removed, then those files are deleted from S3 - which turns the new `all_0_0_1_2` into a "broken" part because files are missing.
</issue>

I need you to solve the provided issue by generating a code fix that can be applied directly to the repository

Respond below:
