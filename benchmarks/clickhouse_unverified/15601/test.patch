diff --git a/tests/integration/helpers/network.py b/tests/integration/helpers/network.py
index a237f7d3cc7c..7ad3ceed54b7 100644
--- a/tests/integration/helpers/network.py
+++ b/tests/integration/helpers/network.py
@@ -166,6 +166,17 @@ def _ensure_container(self):
                 except docker.errors.NotFound:
                     pass
 
+            # for some reason docker api may hang if image doesn't exist, so we download it
+            # before running
+            for i in range(5):
+                try:
+                    subprocess.check_call("docker pull yandex/clickhouse-integration-helper", shell=True)
+                    break
+                except:
+                    time.sleep(i)
+            else:
+                raise Exception("Cannot pull yandex/clickhouse-integration-helper image")
+
             self._container = self._docker_client.containers.run('yandex/clickhouse-integration-helper',
                                                                  auto_remove=True,
                                                                  command=('sleep %s' % self.container_exit_timeout),
diff --git a/tests/integration/test_quorum_inserts_parallel/__init__.py b/tests/integration/test_quorum_inserts_parallel/__init__.py
new file mode 100644
index 000000000000..e5a0d9b4834e
--- /dev/null
+++ b/tests/integration/test_quorum_inserts_parallel/__init__.py
@@ -0,0 +1,1 @@
+#!/usr/bin/env python3
diff --git a/tests/integration/test_quorum_inserts_parallel/test.py b/tests/integration/test_quorum_inserts_parallel/test.py
new file mode 100644
index 000000000000..c89f1a03df73
--- /dev/null
+++ b/tests/integration/test_quorum_inserts_parallel/test.py
@@ -0,0 +1,102 @@
+#!/usr/bin/env python3
+
+import pytest
+from helpers.cluster import ClickHouseCluster
+from multiprocessing.dummy import Pool
+from helpers.network import PartitionManager
+from helpers.client import QueryRuntimeException
+from helpers.test_tools import assert_eq_with_retry
+
+
+cluster = ClickHouseCluster(__file__)
+
+node1 = cluster.add_instance("node1", with_zookeeper=True)
+node2 = cluster.add_instance("node2", with_zookeeper=True)
+node3 = cluster.add_instance("node3", with_zookeeper=True)
+
+@pytest.fixture(scope="module")
+def started_cluster():
+    global cluster
+    try:
+        cluster.start()
+        yield cluster
+
+    finally:
+        cluster.shutdown()
+
+
+def test_parallel_quorum_actually_parallel(started_cluster):
+    settings = {"insert_quorum": "3", "insert_quorum_parallel": "1"}
+    for i, node in enumerate([node1, node2, node3]):
+        node.query("CREATE TABLE r (a UInt64, b String) ENGINE=ReplicatedMergeTree('/test/r', '{num}') ORDER BY tuple()".format(num=i))
+
+    p = Pool(10)
+
+    def long_insert(node):
+        node.query("INSERT INTO r SELECT number, toString(number) FROM numbers(5) where sleepEachRow(1) == 0", settings=settings)
+
+    job = p.apply_async(long_insert, (node1,))
+
+    node2.query("INSERT INTO r VALUES (6, '6')", settings=settings)
+    assert node1.query("SELECT COUNT() FROM r") == "1
"
+    assert node2.query("SELECT COUNT() FROM r") == "1
"
+    assert node3.query("SELECT COUNT() FROM r") == "1
"
+
+    node1.query("INSERT INTO r VALUES (7, '7')", settings=settings)
+    assert node1.query("SELECT COUNT() FROM r") == "2
"
+    assert node2.query("SELECT COUNT() FROM r") == "2
"
+    assert node3.query("SELECT COUNT() FROM r") == "2
"
+
+    job.get()
+
+    assert node1.query("SELECT COUNT() FROM r") == "7
"
+    assert node2.query("SELECT COUNT() FROM r") == "7
"
+    assert node3.query("SELECT COUNT() FROM r") == "7
"
+    p.close()
+    p.join()
+
+
+def test_parallel_quorum_actually_quorum(started_cluster):
+    for i, node in enumerate([node1, node2, node3]):
+        node.query("CREATE TABLE q (a UInt64, b String) ENGINE=ReplicatedMergeTree('/test/q', '{num}') ORDER BY tuple()".format(num=i))
+
+    with PartitionManager() as pm:
+        pm.partition_instances(node2, node1, port=9009)
+        pm.partition_instances(node2, node3, port=9009)
+        with pytest.raises(QueryRuntimeException):
+            node1.query("INSERT INTO q VALUES(1, 'Hello')", settings={"insert_quorum": "3", "insert_quorum_parallel": "1", "insert_quorum_timeout": "3000"})
+
+        assert_eq_with_retry(node1, "SELECT COUNT() FROM q", "1")
+        assert_eq_with_retry(node2, "SELECT COUNT() FROM q", "0")
+        assert_eq_with_retry(node3, "SELECT COUNT() FROM q", "1")
+
+        node1.query("INSERT INTO q VALUES(2, 'wlrd')", settings={"insert_quorum": "2", "insert_quorum_parallel": "1", "insert_quorum_timeout": "3000"})
+
+        assert_eq_with_retry(node1, "SELECT COUNT() FROM q", "2")
+        assert_eq_with_retry(node2, "SELECT COUNT() FROM q", "0")
+        assert_eq_with_retry(node3, "SELECT COUNT() FROM q", "2")
+
+        def insert_value_to_node(node, settings):
+            node.query("INSERT INTO q VALUES(3, 'Hi')", settings=settings)
+
+        p = Pool(2)
+        res = p.apply_async(insert_value_to_node, (node1, {"insert_quorum": "3", "insert_quorum_parallel": "1", "insert_quorum_timeout": "60000"}))
+
+        assert_eq_with_retry(node1, "SELECT COUNT() FROM system.parts WHERE table == 'q' and active == 1", "3")
+        assert_eq_with_retry(node3, "SELECT COUNT() FROM system.parts WHERE table == 'q' and active == 1", "3")
+        assert_eq_with_retry(node2, "SELECT COUNT() FROM system.parts WHERE table == 'q' and active == 1", "0")
+
+        # Insert to the second to satisfy quorum
+        insert_value_to_node(node2, {"insert_quorum": "3", "insert_quorum_parallel": "1"})
+
+        res.get()
+
+        assert_eq_with_retry(node1, "SELECT COUNT() FROM q", "3")
+        assert_eq_with_retry(node2, "SELECT COUNT() FROM q", "1")
+        assert_eq_with_retry(node3, "SELECT COUNT() FROM q", "3")
+
+        p.close()
+        p.join()
+
+    node2.query("SYSTEM SYNC REPLICA q", timeout=10)
+    assert_eq_with_retry(node2, "SELECT COUNT() FROM q", "3")
diff --git a/tests/queries/0_stateless/01509_check_many_parallel_quorum_inserts.reference b/tests/queries/0_stateless/01509_check_many_parallel_quorum_inserts.reference
new file mode 100644
index 000000000000..52dea650ebc7
--- /dev/null
+++ b/tests/queries/0_stateless/01509_check_many_parallel_quorum_inserts.reference
@@ -0,0 +1,10 @@
+100	0	99	4950
+100	0	99	4950
+100	0	99	4950
+100	0	99	4950
+100	0	99	4950
+100	0	99	4950
+100	0	99	4950
+100	0	99	4950
+100	0	99	4950
+100	0	99	4950
diff --git a/tests/queries/0_stateless/01509_check_many_parallel_quorum_inserts.sh b/tests/queries/0_stateless/01509_check_many_parallel_quorum_inserts.sh
new file mode 100755
index 000000000000..99dc1c5e8f57
--- /dev/null
+++ b/tests/queries/0_stateless/01509_check_many_parallel_quorum_inserts.sh
@@ -0,0 +1,36 @@
+#!/usr/bin/env bash
+
+set -e
+
+CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
+. "$CURDIR"/../shell_config.sh
+
+NUM_REPLICAS=10
+
+for i in $(seq 1 $NUM_REPLICAS); do
+    $CLICKHOUSE_CLIENT -n -q "
+        DROP TABLE IF EXISTS r$i;
+        CREATE TABLE r$i (x UInt64) ENGINE = ReplicatedMergeTree('/clickhouse/tables/test_01509/parallel_quorum_many', 'r$i') ORDER BY x;
+    "
+done
+
+function thread {
+    $CLICKHOUSE_CLIENT --insert_quorum 5 --insert_quorum_parallel 1 --query "INSERT INTO r$1 SELECT $2"
+}
+
+for i in $(seq 1 $NUM_REPLICAS); do
+    for j in {0..9}; do
+        a=$((($i - 1) * 10 + $j))
+        thread $i $a &
+    done
+done
+
+wait
+
+for i in $(seq 1 $NUM_REPLICAS); do
+    $CLICKHOUSE_CLIENT -n -q "
+        SYSTEM SYNC REPLICA r$i;
+        SELECT count(), min(x), max(x), sum(x) FROM r$i;
+        DROP TABLE IF EXISTS r$i;
+"
+done
diff --git a/tests/queries/0_stateless/01509_check_parallel_quorum_inserts.reference b/tests/queries/0_stateless/01509_check_parallel_quorum_inserts.reference
new file mode 100644
index 000000000000..103d5e370943
--- /dev/null
+++ b/tests/queries/0_stateless/01509_check_parallel_quorum_inserts.reference
@@ -0,0 +1,2 @@
+5	1	5	15
+5	1	5	15
diff --git a/tests/queries/0_stateless/01509_check_parallel_quorum_inserts.sh b/tests/queries/0_stateless/01509_check_parallel_quorum_inserts.sh
new file mode 100755
index 000000000000..eecb06bda5df
--- /dev/null
+++ b/tests/queries/0_stateless/01509_check_parallel_quorum_inserts.sh
@@ -0,0 +1,37 @@
+#!/usr/bin/env bash
+
+set -e
+
+CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
+. "$CURDIR"/../shell_config.sh
+
+NUM_REPLICAS=2
+NUM_INSERTS=5
+
+for i in $(seq 1 $NUM_REPLICAS); do
+    $CLICKHOUSE_CLIENT -n -q "
+        DROP TABLE IF EXISTS r$i;
+        CREATE TABLE r$i (x UInt64) ENGINE = ReplicatedMergeTree('/clickhouse/tables/test_01509/parallel_quorum', 'r$i') ORDER BY x;
+    "
+done
+
+$CLICKHOUSE_CLIENT -n -q "SYSTEM STOP REPLICATION QUEUES r2;"
+
+function thread {
+    $CLICKHOUSE_CLIENT --insert_quorum 2 --insert_quorum_parallel 1 --query "INSERT INTO r1 SELECT $1"
+}
+
+for i in $(seq 1 $NUM_INSERTS); do
+    thread $i &
+done
+
+$CLICKHOUSE_CLIENT -n -q "SYSTEM START REPLICATION QUEUES r2;"
+
+wait
+
+for i in $(seq 1 $NUM_REPLICAS); do
+    $CLICKHOUSE_CLIENT -n -q "
+        SELECT count(), min(x), max(x), sum(x) FROM r$i;
+        DROP TABLE IF EXISTS r$i;
+"
+done
diff --git a/tests/queries/0_stateless/01509_parallel_quorum_and_merge.reference b/tests/queries/0_stateless/01509_parallel_quorum_and_merge.reference
new file mode 100644
index 000000000000..a5c40a850490
--- /dev/null
+++ b/tests/queries/0_stateless/01509_parallel_quorum_and_merge.reference
@@ -0,0 +1,4 @@
+all_0_1_1
+DownloadPart
+2
+2
diff --git a/tests/queries/0_stateless/01509_parallel_quorum_and_merge.sh b/tests/queries/0_stateless/01509_parallel_quorum_and_merge.sh
new file mode 100755
index 000000000000..214c39a21cce
--- /dev/null
+++ b/tests/queries/0_stateless/01509_parallel_quorum_and_merge.sh
@@ -0,0 +1,66 @@
+#!/usr/bin/env bash
+
+set -e
+
+CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
+. "$CURDIR"/../shell_config.sh
+
+$CLICKHOUSE_CLIENT -q "DROP TABLE IF EXISTS parallel_q1"
+$CLICKHOUSE_CLIENT -q "DROP TABLE IF EXISTS parallel_q2"
+
+
+$CLICKHOUSE_CLIENT -q "CREATE TABLE parallel_q1 (x UInt64) ENGINE=ReplicatedMergeTree('/clickhouse/tables/test_01509/parallel_q', 'r1') ORDER BY tuple() SETTINGS old_parts_lifetime = 1, cleanup_delay_period = 0, cleanup_delay_period_random_add = 0"
+
+$CLICKHOUSE_CLIENT -q "CREATE TABLE parallel_q2 (x UInt64) ENGINE=ReplicatedMergeTree('/clickhouse/tables/test_01509/parallel_q', 'r2') ORDER BY tuple() SETTINGS always_fetch_merged_part = 1"
+
+$CLICKHOUSE_CLIENT -q "SYSTEM STOP REPLICATION QUEUES parallel_q2"
+
+$CLICKHOUSE_CLIENT -q "INSERT INTO parallel_q1 VALUES (1)"
+
+$CLICKHOUSE_CLIENT --insert_quorum 2 --insert_quorum_parallel 1 --query="INSERT INTO parallel_q1 VALUES (2)" &
+
+part_count=$($CLICKHOUSE_CLIENT --query="SELECT COUNT() FROM system.parts WHERE table='parallel_q1' and database='${CLICKHOUSE_DATABASE}'")
+
+# Check part inserted locally
+while [[ $part_count != 2 ]]
+do
+    sleep 0.1
+    part_count=$($CLICKHOUSE_CLIENT --query="SELECT COUNT() FROM system.parts WHERE table='parallel_q1' and database='${CLICKHOUSE_DATABASE}'")
+done
+
+$CLICKHOUSE_CLIENT --replication_alter_partitions_sync 0 -q "OPTIMIZE TABLE parallel_q1 FINAL"
+
+# check part merged locally
+has_part=$($CLICKHOUSE_CLIENT --query="SELECT COUNT() FROM system.parts WHERE table='parallel_q1' and database='${CLICKHOUSE_DATABASE}' and name='all_0_1_1'")
+
+while [[ $has_part != 1 ]]
+do
+    sleep 0.1
+    has_part=$($CLICKHOUSE_CLIENT --query="SELECT COUNT() FROM system.parts WHERE table='parallel_q1' and database='${CLICKHOUSE_DATABASE}' and name='all_0_1_1'")
+done
+
+# check source parts removed locally
+active_parts_count=$($CLICKHOUSE_CLIENT --query="SELECT COUNT() FROM system.parts WHERE table='parallel_q1' and database='${CLICKHOUSE_DATABASE}' and active=1")
+
+while [[ $active_parts_count != 1 ]]
+do
+    sleep 0.1
+    active_parts_count=$($CLICKHOUSE_CLIENT --query="SELECT COUNT() FROM system.parts WHERE table='parallel_q1' and database='${CLICKHOUSE_DATABASE}'")
+done
+
+# download merged part
+$CLICKHOUSE_CLIENT -q "SYSTEM START REPLICATION QUEUES parallel_q2"
+
+$CLICKHOUSE_CLIENT -q "SYSTEM SYNC REPLICA parallel_q2"
+
+# quorum satisfied even for merged part
+wait
+
+$CLICKHOUSE_CLIENT --query="SYSTEM FLUSH LOGS"
+$CLICKHOUSE_CLIENT --query="SELECT name FROM system.parts WHERE table='parallel_q2' and database='${CLICKHOUSE_DATABASE}' and active=1 ORDER BY name"
+$CLICKHOUSE_CLIENT --query="SELECT event_type FROM system.part_log WHERE table='parallel_q2' and database='${CLICKHOUSE_DATABASE}' and part_name='all_0_1_1'"
+$CLICKHOUSE_CLIENT --query="SELECT COUNT() FROM parallel_q2"
+$CLICKHOUSE_CLIENT --query="SELECT COUNT() FROM parallel_q1"
+
+$CLICKHOUSE_CLIENT -q "DROP TABLE IF EXISTS parallel_q1"
+$CLICKHOUSE_CLIENT -q "DROP TABLE IF EXISTS parallel_q2"
diff --git a/tests/queries/0_stateless/01509_parallel_quorum_insert_no_replicas.reference b/tests/queries/0_stateless/01509_parallel_quorum_insert_no_replicas.reference
new file mode 100644
index 000000000000..5647890ac1c6
--- /dev/null
+++ b/tests/queries/0_stateless/01509_parallel_quorum_insert_no_replicas.reference
@@ -0,0 +1,12 @@
+insert to two replicas works
+1
+1
+insert to single replica works
+3
+3
+deduplication works
+3
+3
+insert happened
+4
+4
diff --git a/tests/queries/0_stateless/01509_parallel_quorum_insert_no_replicas.sql b/tests/queries/0_stateless/01509_parallel_quorum_insert_no_replicas.sql
new file mode 100644
index 000000000000..7607a4e90125
--- /dev/null
+++ b/tests/queries/0_stateless/01509_parallel_quorum_insert_no_replicas.sql
@@ -0,0 +1,66 @@
+DROP TABLE IF EXISTS r1;
+DROP TABLE IF EXISTS r2;
+
+CREATE TABLE r1 (
+    key UInt64, value String
+)
+ENGINE = ReplicatedMergeTree('/clickhouse/01509_no_repliacs', '1')
+ORDER BY tuple();
+
+CREATE TABLE r2 (
+    key UInt64, value String
+)
+ENGINE = ReplicatedMergeTree('/clickhouse/01509_no_repliacs', '2')
+ORDER BY tuple();
+
+SET insert_quorum_parallel=1;
+
+SET insert_quorum=3;
+INSERT INTO r1 VALUES(1, '1'); --{serverError 285}
+
+SELECT 'insert to two replicas works';
+SET insert_quorum=2, insert_quorum_parallel=1;
+INSERT INTO r1 VALUES(1, '1');
+
+SELECT COUNT() FROM r1;
+SELECT COUNT() FROM r2;
+
+DETACH TABLE r2;
+
+INSERT INTO r1 VALUES(2, '2'); --{serverError 285}
+
+SET insert_quorum=1, insert_quorum_parallel=1;
+SELECT 'insert to single replica works';
+INSERT INTO r1 VALUES(2, '2');
+
+ATTACH TABLE r2;
+
+SET insert_quorum=2, insert_quorum_parallel=1;
+
+INSERT INTO r1 VALUES(3, '3');
+
+SELECT COUNT() FROM r1;
+SELECT COUNT() FROM r2;
+
+SELECT 'deduplication works';
+INSERT INTO r2 VALUES(3, '3');
+
+SELECT COUNT() FROM r1;
+SELECT COUNT() FROM r2;
+
+SYSTEM STOP FETCHES r2;
+
+SET insert_quorum_timeout=0;
+
+INSERT INTO r1 VALUES (4, '4'); -- { serverError 319 }
+
+SYSTEM START FETCHES r2;
+
+SYSTEM SYNC REPLICA r2;
+
+SELECT 'insert happened';
+SELECT COUNT() FROM r1;
+SELECT COUNT() FROM r2;
+
+DROP TABLE IF EXISTS r1;
+DROP TABLE IF EXISTS r2;
