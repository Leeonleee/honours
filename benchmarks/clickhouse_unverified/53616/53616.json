{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 53616,
  "instance_id": "ClickHouse__ClickHouse-53616",
  "issue_numbers": [
    "52637",
    "52107"
  ],
  "base_commit": "e67c002cb026a6f9f8f4ff04833282693efcbe65",
  "patch": "diff --git a/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp b/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp\nindex 62547ff8786b..afb73ff38592 100644\n--- a/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp\n+++ b/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp\n@@ -981,9 +981,9 @@ RangesInDataParts MergeTreeDataSelectExecutor::filterPartsByPrimaryKeyAndSkipInd\n                 const auto & index_and_condition = skip_indexes.useful_indices[idx];\n                 auto & stat = useful_indices_stat[idx];\n                 stat.total_parts.fetch_add(1, std::memory_order_relaxed);\n-                stat.total_granules.fetch_add(ranges.ranges.getNumberOfMarks(), std::memory_order_relaxed);\n+                size_t total_granules = ranges.ranges.getNumberOfMarks();\n+                stat.total_granules.fetch_add(total_granules, std::memory_order_relaxed);\n \n-                size_t granules_dropped = 0;\n                 ranges.ranges = filterMarksUsingIndex(\n                     index_and_condition.index,\n                     index_and_condition.condition,\n@@ -991,12 +991,11 @@ RangesInDataParts MergeTreeDataSelectExecutor::filterPartsByPrimaryKeyAndSkipInd\n                     ranges.ranges,\n                     settings,\n                     reader_settings,\n-                    granules_dropped,\n                     mark_cache.get(),\n                     uncompressed_cache.get(),\n                     log);\n \n-                stat.granules_dropped.fetch_add(granules_dropped, std::memory_order_relaxed);\n+                stat.granules_dropped.fetch_add(total_granules - ranges.ranges.getNumberOfMarks(), std::memory_order_relaxed);\n                 if (ranges.ranges.empty())\n                     stat.parts_dropped.fetch_add(1, std::memory_order_relaxed);\n             }\n@@ -1010,17 +1009,15 @@ RangesInDataParts MergeTreeDataSelectExecutor::filterPartsByPrimaryKeyAndSkipInd\n                 auto & stat = merged_indices_stat[idx];\n                 stat.total_parts.fetch_add(1, std::memory_order_relaxed);\n \n-                size_t total_granules = 0;\n-                size_t granules_dropped = 0;\n+                size_t total_granules = ranges.ranges.getNumberOfMarks();\n                 ranges.ranges = filterMarksUsingMergedIndex(\n                     indices_and_condition.indices, indices_and_condition.condition,\n                     part, ranges.ranges,\n                     settings, reader_settings,\n-                    total_granules, granules_dropped,\n                     mark_cache.get(), uncompressed_cache.get(), log);\n \n                 stat.total_granules.fetch_add(total_granules, std::memory_order_relaxed);\n-                stat.granules_dropped.fetch_add(granules_dropped, std::memory_order_relaxed);\n+                stat.granules_dropped.fetch_add(total_granules - ranges.ranges.getNumberOfMarks(), std::memory_order_relaxed);\n \n                 if (ranges.ranges.empty())\n                     stat.parts_dropped.fetch_add(1, std::memory_order_relaxed);\n@@ -1578,7 +1575,6 @@ MarkRanges MergeTreeDataSelectExecutor::filterMarksUsingIndex(\n     const MarkRanges & ranges,\n     const Settings & settings,\n     const MergeTreeReaderSettings & reader_settings,\n-    size_t & granules_dropped,\n     MarkCache * mark_cache,\n     UncompressedCache * uncompressed_cache,\n     Poco::Logger * log)\n@@ -1648,8 +1644,6 @@ MarkRanges MergeTreeDataSelectExecutor::filterMarksUsingIndex(\n             {\n                 // vector of indexes of useful ranges\n                 auto result = ann_condition->getUsefulRanges(granule);\n-                if (result.empty())\n-                    ++granules_dropped;\n \n                 for (auto range : result)\n                 {\n@@ -1674,10 +1668,7 @@ MarkRanges MergeTreeDataSelectExecutor::filterMarksUsingIndex(\n                 result = cache_in_store.store ? gin_filter_condition->mayBeTrueOnGranuleInPart(granule, cache_in_store) : true;\n \n             if (!result)\n-            {\n-                ++granules_dropped;\n                 continue;\n-            }\n \n             MarkRange data_range(\n                     std::max(ranges[i].begin, index_mark * index_granularity),\n@@ -1702,8 +1693,6 @@ MarkRanges MergeTreeDataSelectExecutor::filterMarksUsingMergedIndex(\n     const MarkRanges & ranges,\n     const Settings & settings,\n     const MergeTreeReaderSettings & reader_settings,\n-    size_t & total_granules,\n-    size_t & granules_dropped,\n     MarkCache * mark_cache,\n     UncompressedCache * uncompressed_cache,\n     Poco::Logger * log)\n@@ -1760,8 +1749,6 @@ MarkRanges MergeTreeDataSelectExecutor::filterMarksUsingMergedIndex(\n             for (auto & reader : readers)\n                 reader->seek(index_range.begin);\n \n-        total_granules += index_range.end - index_range.begin;\n-\n         for (size_t index_mark = index_range.begin; index_mark < index_range.end; ++index_mark)\n         {\n             if (index_mark != index_range.begin || !granules_filled || last_index_mark != index_range.begin)\n@@ -1774,10 +1761,7 @@ MarkRanges MergeTreeDataSelectExecutor::filterMarksUsingMergedIndex(\n             }\n \n             if (!condition->mayBeTrueOnGranule(granules))\n-            {\n-                ++granules_dropped;\n                 continue;\n-            }\n \n             MarkRange data_range(\n                 std::max(range.begin, index_mark * index_granularity),\ndiff --git a/src/Storages/MergeTree/MergeTreeDataSelectExecutor.h b/src/Storages/MergeTree/MergeTreeDataSelectExecutor.h\nindex a5dcbfe66508..74d8d8e3c8f7 100644\n--- a/src/Storages/MergeTree/MergeTreeDataSelectExecutor.h\n+++ b/src/Storages/MergeTree/MergeTreeDataSelectExecutor.h\n@@ -93,7 +93,6 @@ class MergeTreeDataSelectExecutor\n         const MarkRanges & ranges,\n         const Settings & settings,\n         const MergeTreeReaderSettings & reader_settings,\n-        size_t & granules_dropped,\n         MarkCache * mark_cache,\n         UncompressedCache * uncompressed_cache,\n         Poco::Logger * log);\n@@ -105,8 +104,6 @@ class MergeTreeDataSelectExecutor\n         const MarkRanges & ranges,\n         const Settings & settings,\n         const MergeTreeReaderSettings & reader_settings,\n-        size_t & total_granules,\n-        size_t & granules_dropped,\n         MarkCache * mark_cache,\n         UncompressedCache * uncompressed_cache,\n         Poco::Logger * log);\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01786_explain_merge_tree.reference b/tests/queries/0_stateless/01786_explain_merge_tree.reference\nindex 794acc310ce2..46f89745ba32 100644\n--- a/tests/queries/0_stateless/01786_explain_merge_tree.reference\n+++ b/tests/queries/0_stateless/01786_explain_merge_tree.reference\n@@ -24,12 +24,12 @@\n       Name: t_minmax\n       Description: minmax GRANULARITY 2\n       Parts: 1/2\n-      Granules: 4/6\n+      Granules: 3/6\n     Skip\n       Name: t_set\n       Description: set GRANULARITY 2\n       Parts: 1/1\n-      Granules: 2/4\n+      Granules: 2/3\n -----------------\n           \"Node Type\": \"ReadFromMergeTree\",\n           \"Description\": \"default.test_index\",\n@@ -68,7 +68,7 @@\n               \"Initial Parts\": 2,\n               \"Selected Parts\": 1,\n               \"Initial Granules\": 6,\n-              \"Selected Granules\": 4\n+              \"Selected Granules\": 3\n             },\n             {\n               \"Type\": \"Skip\",\n@@ -76,7 +76,7 @@\n               \"Description\": \"set GRANULARITY 2\",\n               \"Initial Parts\": 1,\n               \"Selected Parts\": 1,\n-              \"Initial Granules\": 4,\n+              \"Initial Granules\": 3,\n               \"Selected Granules\": 2\n             }\n           ]\ndiff --git a/tests/queries/0_stateless/02354_annoy_index.reference b/tests/queries/0_stateless/02354_annoy_index.reference\nindex cf17a7a7eabf..a0ffb1e1f7ff 100644\n--- a/tests/queries/0_stateless/02354_annoy_index.reference\n+++ b/tests/queries/0_stateless/02354_annoy_index.reference\n@@ -94,7 +94,7 @@ Expression ((Projection + Before ORDER BY))\n         Name: annoy_index\n         Description: annoy GRANULARITY 2\n         Parts: 0/1\n-        Granules: 2/4\n+        Granules: 0/4\n ORDER BY type, L2Distance, check that index is used\n Expression (Projection)\n   Limit (preliminary LIMIT (without OFFSET))\n@@ -110,7 +110,7 @@ Expression (Projection)\n             Name: annoy_index\n             Description: annoy GRANULARITY 2\n             Parts: 1/1\n-            Granules: 4/4\n+            Granules: 2/4\n --- Test with Array, GRANULARITY = 4, index_granularity = 4 ---\n WHERE type, L2Distance, check that index is used\n Expression ((Projection + Before ORDER BY))\n@@ -125,7 +125,7 @@ Expression ((Projection + Before ORDER BY))\n         Name: annoy_index\n         Description: annoy GRANULARITY 4\n         Parts: 0/1\n-        Granules: 3/4\n+        Granules: 0/4\n ORDER BY type, L2Distance, check that index is used\n Expression (Projection)\n   Limit (preliminary LIMIT (without OFFSET))\n@@ -141,7 +141,7 @@ Expression (Projection)\n             Name: annoy_index\n             Description: annoy GRANULARITY 4\n             Parts: 1/1\n-            Granules: 4/4\n+            Granules: 1/4\n --- Test correctness of Annoy index with > 1 mark\n 1\t[1,0,0,0]\n 9000\t[9000,0,0,0]\ndiff --git a/tests/queries/0_stateless/02354_usearch_index.reference b/tests/queries/0_stateless/02354_usearch_index.reference\nindex 9896f149d453..a93209f6ba8c 100644\n--- a/tests/queries/0_stateless/02354_usearch_index.reference\n+++ b/tests/queries/0_stateless/02354_usearch_index.reference\n@@ -93,7 +93,7 @@ Expression ((Projection + Before ORDER BY))\n         Name: usearch_index\n         Description: usearch GRANULARITY 2\n         Parts: 0/1\n-        Granules: 2/4\n+        Granules: 0/4\n ORDER BY type, L2Distance, check that index is used\n Expression (Projection)\n   Limit (preliminary LIMIT (without OFFSET))\n@@ -109,7 +109,7 @@ Expression (Projection)\n             Name: usearch_index\n             Description: usearch GRANULARITY 2\n             Parts: 1/1\n-            Granules: 4/4\n+            Granules: 2/4\n --- Test with Array, GRANULARITY = 4, index_granularity = 4 ---\n WHERE type, L2Distance, check that index is used\n Expression ((Projection + Before ORDER BY))\n@@ -124,7 +124,7 @@ Expression ((Projection + Before ORDER BY))\n         Name: usearch_index\n         Description: usearch GRANULARITY 4\n         Parts: 0/1\n-        Granules: 3/4\n+        Granules: 0/4\n ORDER BY type, L2Distance, check that index is used\n Expression (Projection)\n   Limit (preliminary LIMIT (without OFFSET))\n@@ -140,4 +140,4 @@ Expression (Projection)\n             Name: usearch_index\n             Description: usearch GRANULARITY 4\n             Parts: 1/1\n-            Granules: 4/4\n+            Granules: 1/4\ndiff --git a/tests/queries/0_stateless/02866_size_of_marks_skip_idx_explain.reference b/tests/queries/0_stateless/02866_size_of_marks_skip_idx_explain.reference\nnew file mode 100644\nindex 000000000000..d3502e9893cf\n--- /dev/null\n+++ b/tests/queries/0_stateless/02866_size_of_marks_skip_idx_explain.reference\n@@ -0,0 +1,28 @@\n+Expression ((Project names + Projection))\n+  Filter ((WHERE + Change column names to column identifiers))\n+    ReadFromMergeTree (default.test_skip_idx)\n+    Indexes:\n+      Skip\n+        Name: name_idx_g2\n+        Description: minmax GRANULARITY 2\n+        Parts: 1/1\n+        Granules: 2/5\n+      Skip\n+        Name: name_idx_g1\n+        Description: minmax GRANULARITY 1\n+        Parts: 1/1\n+        Granules: 1/2\n+Expression ((Project names + Projection))\n+  Filter ((WHERE + Change column names to column identifiers))\n+    ReadFromMergeTree (default.test_skip_idx)\n+    Indexes:\n+      Skip\n+        Name: name_idx_g2\n+        Description: minmax GRANULARITY 2\n+        Parts: 1/1\n+        Granules: 2/5\n+      Skip\n+        Name: name_idx_g1\n+        Description: minmax GRANULARITY 1\n+        Parts: 1/1\n+        Granules: 2/2\ndiff --git a/tests/queries/0_stateless/02866_size_of_marks_skip_idx_explain.sql b/tests/queries/0_stateless/02866_size_of_marks_skip_idx_explain.sql\nnew file mode 100644\nindex 000000000000..b916c5ca13da\n--- /dev/null\n+++ b/tests/queries/0_stateless/02866_size_of_marks_skip_idx_explain.sql\n@@ -0,0 +1,24 @@\n+-- Tags: no-random-merge-tree-settings\n+\n+SET optimize_move_to_prewhere = 1;\n+SET convert_query_to_cnf = 0;\n+SET optimize_read_in_order = 1;\n+\n+SET allow_experimental_analyzer = 1; -- slightly different operator names than w/o\n+\n+DROP TABLE IF EXISTS test_skip_idx;\n+\n+CREATE TABLE test_skip_idx (\n+    id UInt32,\n+    INDEX name_idx_g2 id TYPE minmax GRANULARITY 2,\n+    INDEX name_idx_g1 id TYPE minmax GRANULARITY 1)\n+ENGINE = MergeTree\n+ORDER BY tuple()\n+SETTINGS index_granularity = 1, index_granularity_bytes = 0, min_bytes_for_wide_part = 0;\n+\n+INSERT INTO test_skip_idx SELECT number FROM system.numbers LIMIT 5 OFFSET 1;\n+\n+EXPLAIN indexes = 1 SELECT * FROM test_skip_idx WHERE id < 2;\n+EXPLAIN indexes = 1 SELECT * FROM test_skip_idx WHERE id < 3;\n+\n+DROP TABLE test_skip_idx;\n",
  "problem_statement": "Skip indexes and functions and dropped granules\n-- granularity 100\r\n```sql\r\nClickHouse local version 23.6.2.18 (official build).\r\n\r\ncreate table test (K Int64,  A Int64, B Int64, C Int64, \r\nindex x1 (greatest(A,B,C)) type minmax granularity 100) \r\nEngine=MergeTree order by K as select number,0,0,0 from numbers(1e7);\r\n\r\nselect count() from test where greatest(A,B,C) >0;\r\n\r\nIndex `x1` has dropped 15/1221 granules.\r\n\r\n\r\nselect count() from test where greatest(A,B,C)!=0;\r\n\r\nIndex `x1` has dropped 15/1221 granules.\r\n```\r\n\r\nwhy only 15 granules is dropped?\r\n\r\n-- granularity 1\r\n```sql\r\ncreate table test (K Int64,  A Int64, B Int64, C Int64, \r\nindex x1 (greatest(A,B,C)) type minmax granularity 1) \r\nEngine=MergeTree order by K as select number,0,0,0 from numbers(1e7);\r\n\r\nselect count() from test where greatest(A,B,C) >0;\r\nIndex `x1` has dropped 1221/1221 granules.\r\n```\r\n\r\nit seems it's a statistics/show issue.\r\n\r\n\r\n```sql\r\ncreate table test (K Int64,  A Int64, B Int64, C Int64, \r\nindex x1 (A>0,B>0,C>0) type set(2) granularity 1000) \r\nEngine=MergeTree order by K as select number,0,0,0 from numbers(1e8);\r\n\r\nselect count() from test where A>0 and B>0 and C>0;\r\n\r\nIndex `x1` has dropped 14/12209 granules.\r\nSelected 5/5 parts by partition key, 0 parts by primary key, 12209/12209 marks by primary key, 0 marks to read from 0 ranges\r\n```\nwhy set type index should invalid\uff0cbut the explain shows Selected Granules is less than Initial Granules\ni have a big data table, there is a column with non-repetitive datas. there is a set type index on this column. the max_rows was set 100.( index_granularity = 8192, and GRANULARITY of the index is 16. so i think the row number is 131072, is bigger than max_rows which be set as 100,  so as the official document said, this index should be invalid )\r\nbut where i execute explain indexes = 1, it show, after using this index ,Selected Granules is less than Initial Granules, it shows the index is valid, so im confused about this.\r\n\r\nthe explain info of this index :\r\n                                          \"Type\": \"Skip\",\r\n                                          \"Name\": \"a\",\r\n                                          \"Description\": \"set GRANULARITY 16\",\r\n                                          \"Initial Parts\": 8,\r\n                                          \"Selected Parts\": 8,\r\n                                          \"Initial Granules\": 41323,\r\n                                          \"Selected Granules\": 3201\n",
  "hints_text": "set index is very slow for some reason\r\n\r\n```sql\r\ncreate table test (K Int64,  A Int64, B Int64, C Int64, \r\n\r\nindex x1 (A>0,B>0,C>0) type set(2) granularity 1000\r\n\r\n) Engine=MergeTree order by K as select number,0,0,0 from numbers(1e8);\r\nElapsed: 56.916 sec.\r\n\r\n\r\ncreate table test (K Int64,  A Int64, B Int64, C Int64, \r\n\r\nindex x1 (greatest(A,B,C)) type minmax granularity 1000\r\n\r\n) Engine=MergeTree order by K as select number,0,0,0 from numbers(1e8);\r\nElapsed: 3.058 sec.\r\n```\r\nBut why 20 times difference?\nplease provide:\r\n\r\n```sql\r\n-- output of:\r\nSHOW CREATE the_table;\r\n\r\n-- the query SQL\r\n\r\n-- the full output of:\r\nEXPLAIN indexes=1 SELECT ... \r\n\r\n-- output of:\r\nSELECT rows FROM system.parts WHERE active AND table='the_table' ORDER BY rows ASC LIMIT 5;\r\n```\n-- output of: SHOW CREATE the_table;\r\n--local table\uff1a\r\nCREATE TABLE XX.XXX_20230715_local\r\n(\r\n    `item_sku_id` UInt64,\r\n    `item_id` UInt64,\r\n-- fold one hundred selling data column\r\n    `dt` Date,\r\n    `dt_date` DateTime,\r\n    INDEX a item_sku_id TYPE SET(100) GRANULARITY 16,\r\n    INDEX b item_id TYPE SET(100) GRANULARITY 16\r\n)\r\nENGINE = ReplicatedReplacingMergeTree('/clickhouse/tables/XX/{shard}/XXX_20230715_local', '{replica}')\r\nPARTITION BY dt\r\nORDER BY (sku_data_flag, item_third_cate_cd, oper_dept_id_3, erp, sku_good_comment_ratio, bm_score_rank_rate, sku_d180_deal_sale_qtty, brand_code, sku_long_age_stock_qtty, sku_long_age_stock_amt, sku_over_wh_cost, sku_pv_d30, sku_d30_sale_qtty, sku_d30_deal_amt, item_sku_id)\r\nTTL dt_date + toIntervalDay(10)\r\nSETTINGS enable_mixed_granularity_parts = 1, index_granularity = 8192\r\n\r\n-- Distributed table\uff1a\r\nshow create table XX.XXX_20230715\r\nCREATE TABLE ecodata.app_eco_nirvana_sku_unify_label_out_20230715\r\n(\r\n    `item_sku_id` UInt64,\r\n    `item_id` UInt64,\r\n-- fold one hundred selling data column\r\n    `dt` Date,\r\n    `dt_date` DateTime\r\n)\r\nENGINE = Distributed('default', 'XX', 'XXX_20230715_local', abs(javaHash(toString(item_sku_id))))\r\n\r\n-- the query SQL\r\n\r\n explain indexes = 1, json = 1 select  item_sku_id from ecodata.app_eco_nirvana_sku_unify_label_out_20230715_local where  item_sku_id in ('10076385769241')\r\n\r\n-- the full output of EXPLAIN:\r\n[\r\n  {\r\n    \"Plan\": {\r\n      \"Node Type\": \"Expression\",\r\n      \"Description\": \"(Projection + Before ORDER BY)\",\r\n      \"Plans\": [\r\n        {\r\n          \"Node Type\": \"Filter\",\r\n          \"Description\": \"WHERE\",\r\n          \"Plans\": [\r\n            {\r\n              \"Node Type\": \"SettingQuotaAndLimits\",\r\n              \"Description\": \"Set limits and quota after reading from storage\",\r\n              \"Plans\": [\r\n                {\r\n                  \"Node Type\": \"ReadFromMergeTree\",\r\n                  \"Indexes\": [\r\n                    {\r\n                      \"Type\": \"MinMax\",\r\n                      \"Condition\": \"true\",\r\n                      \"Initial Parts\": 13,\r\n                      \"Selected Parts\": 13,\r\n                      \"Initial Granules\": 42677,\r\n                      \"Selected Granules\": 42677\r\n                    },\r\n                    {\r\n                      \"Type\": \"Partition\",\r\n                      \"Condition\": \"true\",\r\n                      \"Initial Parts\": 13,\r\n                      \"Selected Parts\": 13,\r\n                      \"Initial Granules\": 42677,\r\n                      \"Selected Granules\": 42677\r\n                    },\r\n                    {\r\n                      \"Type\": \"PrimaryKey\",\r\n                      \"Keys\": [\"item_sku_id\"],\r\n                      \"Condition\": \"(item_sku_id in 1-element set)\",\r\n                      \"Initial Parts\": 13,\r\n                      \"Selected Parts\": 13,\r\n                      \"Initial Granules\": 42677,\r\n                      \"Selected Granules\": 41870\r\n                    },\r\n                    {\r\n                      \"Type\": \"Skip\",\r\n                      \"Name\": \"a\",\r\n                      \"Description\": \"set GRANULARITY 16\",\r\n                      \"Initial Parts\": 13,\r\n                      \"Selected Parts\": 13,\r\n                      \"Initial Granules\": 41870,\r\n                      \"Selected Granules\": 3169\r\n                    }\r\n                  ]\r\n                }\r\n              ]\r\n            }\r\n          ]\r\n        }\r\n      ]\r\n    }\r\n  }\r\n]\r\n\r\n-- output of:\r\nSELECT rows FROM system.parts WHERE active AND table='the_table' ORDER BY rows ASC LIMIT 5;\r\n4122144\r\n18477\r\n154519\r\n147846\r\n141372\r\n(because of Distributed table, the rows number may be a little different with EXPLAIN)\r\n\r\n\r\n--and if i use not in, the EXPLAIN also show less than 10% Granules be skip\r\n explain indexes = 1, json = 1 select  item_sku_id from ecodata.app_eco_nirvana_sku_unify_label_out_20230715_local where  item_sku_id not in ('10076385769241')\r\n--\r\n[\r\n  {\r\n    \"Plan\": {\r\n      \"Node Type\": \"Expression\",\r\n      \"Description\": \"(Projection + Before ORDER BY)\",\r\n      \"Plans\": [\r\n        {\r\n          \"Node Type\": \"Filter\",\r\n          \"Description\": \"WHERE\",\r\n          \"Plans\": [\r\n            {\r\n              \"Node Type\": \"SettingQuotaAndLimits\",\r\n              \"Description\": \"Set limits and quota after reading from storage\",\r\n              \"Plans\": [\r\n                {\r\n                  \"Node Type\": \"ReadFromMergeTree\",\r\n                  \"Indexes\": [\r\n                    {\r\n                      \"Type\": \"MinMax\",\r\n                      \"Condition\": \"true\",\r\n                      \"Initial Parts\": 1,\r\n                      \"Selected Parts\": 1,\r\n                      \"Initial Granules\": 42671,\r\n                      \"Selected Granules\": 42671\r\n                    },\r\n                    {\r\n                      \"Type\": \"Partition\",\r\n                      \"Condition\": \"true\",\r\n                      \"Initial Parts\": 1,\r\n                      \"Selected Parts\": 1,\r\n                      \"Initial Granules\": 42671,\r\n                      \"Selected Granules\": 42671\r\n                    },\r\n                    {\r\n                      \"Type\": \"PrimaryKey\",\r\n                      \"Keys\": [\"item_sku_id\"],\r\n                      \"Condition\": \"(item_sku_id notIn 1-element set)\",\r\n                      \"Initial Parts\": 1,\r\n                      \"Selected Parts\": 1,\r\n                      \"Initial Granules\": 42671,\r\n                      \"Selected Granules\": 42671\r\n                    },\r\n                    {\r\n                      \"Type\": \"Skip\",\r\n                      \"Name\": \"a\",\r\n                      \"Description\": \"set GRANULARITY 16\",\r\n                      \"Initial Parts\": 1,\r\n                      \"Selected Parts\": 1,\r\n                      \"Initial Granules\": 42671,\r\n                      \"Selected Granules\": 2667\r\n                    }\r\n                  ]\r\n                }\r\n              ]\r\n            }\r\n          ]\r\n        }\r\n      ]\r\n    }\r\n  }\r\n]\r\n\r\n\nBTW, the value of \u2018item_sku_id\u2019  is not repeated and is not null\n> SELECT rows FROM system.parts WHERE active AND table='the_table' ORDER BY rows ASC LIMIT 5;\r\n> 4122144\r\n> 18477\r\n> 154519\r\n> 147846\r\n> 141372\r\n\r\nThis looks like faked data.\nThese are the real data running on the system. In other words, even if the data is fake, it shows a phenomenon that is not consistent with the official documents.:)",
  "created_at": "2023-08-20T15:07:44Z",
  "modified_files": [
    "src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp",
    "src/Storages/MergeTree/MergeTreeDataSelectExecutor.h"
  ],
  "modified_test_files": [
    "tests/queries/0_stateless/01786_explain_merge_tree.reference",
    "tests/queries/0_stateless/02354_annoy_index.reference",
    "tests/queries/0_stateless/02354_usearch_index.reference",
    "b/tests/queries/0_stateless/02866_size_of_marks_skip_idx_explain.reference",
    "b/tests/queries/0_stateless/02866_size_of_marks_skip_idx_explain.sql"
  ]
}