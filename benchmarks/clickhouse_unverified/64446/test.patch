diff --git a/tests/integration/test_disks_app_func/test.py b/tests/integration/test_disks_app_func/test.py
index 97d5da787cd6..56ea5c8846a5 100644
--- a/tests/integration/test_disks_app_func/test.py
+++ b/tests/integration/test_disks_app_func/test.py
@@ -9,7 +9,9 @@ def started_cluster():
     try:
         cluster = ClickHouseCluster(__file__)
         cluster.add_instance(
-            "disks_app_test", main_configs=["config.xml"], with_minio=True
+            "disks_app_test",
+            main_configs=["config.xml"],
+            with_minio=True,
         )
 
         cluster.start()
@@ -47,12 +49,18 @@ def test_disks_app_func_ld(started_cluster):
     source = cluster.instances["disks_app_test"]
 
     out = source.exec_in_container(
-        ["/usr/bin/clickhouse", "disks", "--save-logs", "list-disks"]
+        ["/usr/bin/clickhouse", "disks", "--save-logs", "--query", "list-disks"]
     )
 
-    disks = out.split("
")
+    disks = list(
+        sorted(
+            map(
+                lambda x: x.split(":")[0], filter(lambda x: len(x) > 1, out.split("
"))
+            )
+        )
+    )
 
-    assert disks[0] == "default" and disks[1] == "test1" and disks[2] == "test2"
+    assert disks[:4] == ["default", "local", "test1", "test2"]
 
 
 def test_disks_app_func_ls(started_cluster):
@@ -61,7 +69,15 @@ def test_disks_app_func_ls(started_cluster):
     init_data(source)
 
     out = source.exec_in_container(
-        ["/usr/bin/clickhouse", "disks", "--save-logs", "--disk", "test1", "list", "."]
+        [
+            "/usr/bin/clickhouse",
+            "disks",
+            "--save-logs",
+            "--disk",
+            "test1",
+            "--query",
+            "list .",
+        ]
     )
 
     files = out.split("
")
@@ -75,9 +91,8 @@ def test_disks_app_func_ls(started_cluster):
             "--save-logs",
             "--disk",
             "test1",
-            "list",
-            ".",
-            "--recursive",
+            "--query",
+            "list . --recursive",
         ]
     )
 
@@ -102,8 +117,8 @@ def test_disks_app_func_cp(started_cluster):
                     "--save-logs",
                     "--disk",
                     "test1",
-                    "write",
-                    "path1",
+                    "--query",
+                    "'write path1'",
                 ]
             ),
         ]
@@ -113,18 +128,21 @@ def test_disks_app_func_cp(started_cluster):
         [
             "/usr/bin/clickhouse",
             "disks",
-            "copy",
-            "--disk-from",
-            "test1",
-            "--disk-to",
-            "test2",
-            ".",
-            ".",
+            "--query",
+            "copy --recursive --disk-from test1 --disk-to test2 . .",
         ]
     )
 
     out = source.exec_in_container(
-        ["/usr/bin/clickhouse", "disks", "--save-logs", "--disk", "test2", "list", "."]
+        [
+            "/usr/bin/clickhouse",
+            "disks",
+            "--save-logs",
+            "--disk",
+            "test2",
+            "--query",
+            "list .",
+        ]
     )
 
     assert "path1" in out
@@ -136,8 +154,8 @@ def test_disks_app_func_cp(started_cluster):
             "--save-logs",
             "--disk",
             "test2",
-            "remove",
-            "path1",
+            "--query",
+            "remove path1",
         ]
     )
 
@@ -148,21 +166,37 @@ def test_disks_app_func_cp(started_cluster):
             "--save-logs",
             "--disk",
             "test1",
-            "remove",
-            "path1",
+            "--query",
+            "remove path1",
         ]
     )
 
     # alesapin: Why we need list one more time?
     # kssenii: it is an assertion that the file is indeed deleted
     out = source.exec_in_container(
-        ["/usr/bin/clickhouse", "disks", "--save-logs", "--disk", "test2", "list", "."]
+        [
+            "/usr/bin/clickhouse",
+            "disks",
+            "--save-logs",
+            "--disk",
+            "test2",
+            "--query",
+            "list .",
+        ]
     )
 
     assert "path1" not in out
 
     out = source.exec_in_container(
-        ["/usr/bin/clickhouse", "disks", "--save-logs", "--disk", "test1", "list", "."]
+        [
+            "/usr/bin/clickhouse",
+            "disks",
+            "--save-logs",
+            "--disk",
+            "test1",
+            "--query",
+            "list .",
+        ]
     )
 
     assert "path1" not in out
@@ -177,14 +211,13 @@ def test_disks_app_func_ln(started_cluster):
         [
             "/usr/bin/clickhouse",
             "disks",
-            "link",
-            "data/default/test_table",
-            "data/default/z_tester",
+            "--query",
+            "link data/default/test_table data/default/z_tester",
         ]
     )
 
     out = source.exec_in_container(
-        ["/usr/bin/clickhouse", "disks", "--save-logs", "list", "data/default/"]
+        ["/usr/bin/clickhouse", "disks", "--save-logs", "--query", "list data/default/"]
     )
 
     files = out.split("
")
@@ -209,15 +242,23 @@ def test_disks_app_func_rm(started_cluster):
                     "--save-logs",
                     "--disk",
                     "test2",
-                    "write",
-                    "path3",
+                    "--query",
+                    "'write path3'",
                 ]
             ),
         ]
     )
 
     out = source.exec_in_container(
-        ["/usr/bin/clickhouse", "disks", "--save-logs", "--disk", "test2", "list", "."]
+        [
+            "/usr/bin/clickhouse",
+            "disks",
+            "--save-logs",
+            "--disk",
+            "test2",
+            "--query",
+            "list .",
+        ]
     )
 
     assert "path3" in out
@@ -229,13 +270,21 @@ def test_disks_app_func_rm(started_cluster):
             "--save-logs",
             "--disk",
             "test2",
-            "remove",
-            "path3",
+            "--query",
+            "remove path3",
         ]
     )
 
     out = source.exec_in_container(
-        ["/usr/bin/clickhouse", "disks", "--save-logs", "--disk", "test2", "list", "."]
+        [
+            "/usr/bin/clickhouse",
+            "disks",
+            "--save-logs",
+            "--disk",
+            "test2",
+            "--query",
+            "list .",
+        ]
     )
 
     assert "path3" not in out
@@ -247,7 +296,15 @@ def test_disks_app_func_mv(started_cluster):
     init_data(source)
 
     out = source.exec_in_container(
-        ["/usr/bin/clickhouse", "disks", "--save-logs", "--disk", "test1", "list", "."]
+        [
+            "/usr/bin/clickhouse",
+            "disks",
+            "--save-logs",
+            "--disk",
+            "test1",
+            "--query",
+            "list .",
+        ]
     )
 
     files = out.split("
")
@@ -260,14 +317,21 @@ def test_disks_app_func_mv(started_cluster):
             "disks",
             "--disk",
             "test1",
-            "move",
-            "store",
-            "old_store",
+            "--query",
+            "move store old_store",
         ]
     )
 
     out = source.exec_in_container(
-        ["/usr/bin/clickhouse", "disks", "--save-logs", "--disk", "test1", "list", "."]
+        [
+            "/usr/bin/clickhouse",
+            "disks",
+            "--save-logs",
+            "--disk",
+            "test1",
+            "--query",
+            "list .",
+        ]
     )
 
     files = out.split("
")
@@ -290,8 +354,8 @@ def test_disks_app_func_read_write(started_cluster):
                     "--save-logs",
                     "--disk",
                     "test1",
-                    "write",
-                    "5.txt",
+                    "--query",
+                    "'write 5.txt'",
                 ]
             ),
         ]
@@ -304,8 +368,8 @@ def test_disks_app_func_read_write(started_cluster):
             "--save-logs",
             "--disk",
             "test1",
-            "read",
-            "5.txt",
+            "--query",
+            "read 5.txt",
         ]
     )
 
@@ -319,7 +383,15 @@ def test_remote_disk_list(started_cluster):
     init_data_s3(source)
 
     out = source.exec_in_container(
-        ["/usr/bin/clickhouse", "disks", "--save-logs", "--disk", "test3", "list", "."]
+        [
+            "/usr/bin/clickhouse",
+            "disks",
+            "--save-logs",
+            "--disk",
+            "test3",
+            "--query",
+            "list .",
+        ]
     )
 
     files = out.split("
")
@@ -333,9 +405,8 @@ def test_remote_disk_list(started_cluster):
             "--save-logs",
             "--disk",
             "test3",
-            "list",
-            ".",
-            "--recursive",
+            "--query",
+            "list . --recursive",
         ]
     )
 
diff --git a/tests/integration/test_disks_app_interactive/__init__.py b/tests/integration/test_disks_app_interactive/__init__.py
new file mode 100644
index 000000000000..e69de29bb2d1
diff --git a/tests/integration/test_disks_app_interactive/configs/config.xml b/tests/integration/test_disks_app_interactive/configs/config.xml
new file mode 100644
index 000000000000..bcbb107f0a27
--- /dev/null
+++ b/tests/integration/test_disks_app_interactive/configs/config.xml
@@ -0,0 +1,3 @@
+<clickhouse>
+    <path>/var/lib/clickhouse/</path>
+</clickhouse>
\ No newline at end of file
diff --git a/tests/integration/test_disks_app_interactive/test.py b/tests/integration/test_disks_app_interactive/test.py
new file mode 100644
index 000000000000..ca4ba5d90658
--- /dev/null
+++ b/tests/integration/test_disks_app_interactive/test.py
@@ -0,0 +1,331 @@
+from helpers.cluster import ClickHouseCluster
+
+import pytest
+
+import pathlib
+
+import subprocess
+import select
+import io
+from typing import List, Tuple, Dict, Union, Optional
+
+import os
+
+
+class ClickHouseDisksException(Exception):
+    pass
+
+
+@pytest.fixture(scope="module")
+def started_cluster():
+    global cluster
+    try:
+        cluster = ClickHouseCluster(__file__)
+        cluster.add_instance(
+            "disks_app_test",
+            main_configs=["server_configs/config.xml"],
+            with_minio=True,
+        )
+
+        cluster.start()
+        yield cluster
+
+    finally:
+        cluster.shutdown()
+
+
+class DisksClient(object):
+    SEPARATOR = b"\a\a\a\a
"
+    local_client: Optional["DisksClient"] = None  # static variable
+    default_disk_root_directory: str = "/var/lib/clickhouse"
+
+    def __init__(self, bin_path: str, config_path: str, working_path: str):
+        self.bin_path = bin_path
+        self.working_path = working_path
+
+        self.proc = subprocess.Popen(
+            [bin_path, "disks", "--test-mode", "--config", config_path],
+            stdin=subprocess.PIPE,
+            stdout=subprocess.PIPE,
+            stderr=subprocess.PIPE,
+        )
+
+        self.poller = select.epoll()
+        self.poller.register(self.proc.stdout)
+        self.poller.register(self.proc.stderr)
+
+        self.stopped = False
+
+        self._fd_nums = {
+            self.proc.stdout.fileno(): self.proc.stdout,
+            self.proc.stderr.fileno(): self.proc.stderr,
+        }
+
+    def execute_query(self, query: str, timeout: float = 5.0) -> str:
+        output = io.BytesIO()
+
+        self.proc.stdin.write(query.encode() + b"
")
+        self.proc.stdin.flush()
+
+        events = self.poller.poll(timeout)
+        if not events:
+            raise TimeoutError(f"Disks client returned no output")
+
+        for fd_num, event in events:
+            if event & (select.EPOLLIN | select.EPOLLPRI):
+                file = self._fd_nums[fd_num]
+
+                if file == self.proc.stdout:
+                    while True:
+                        chunk = file.readline()
+                        if chunk.endswith(self.SEPARATOR):
+                            break
+
+                        output.write(chunk)
+
+                elif file == self.proc.stderr:
+                    error_line = self.proc.stderr.readline()
+                    print(error_line)
+                    raise ClickHouseDisksException(error_line.strip().decode())
+
+            else:
+                raise ValueError(f"Failed to read from pipe. Flag {event}")
+
+        data = output.getvalue().strip().decode()
+        return data
+
+    def list_disks(self) -> List[Tuple[str, str]]:
+        output = self.execute_query("list-disks")
+        return list(
+            sorted(
+                map(
+                    lambda x: (x.split(":")[0], ":".join(x.split(":")[1:])),
+                    output.split("
"),
+                )
+            )
+        )
+
+    def current_disk_with_path(self) -> Tuple[str, str]:
+        output = self.execute_query("current_disk_with_path")
+        disk_line = output.split("
")[0]
+        path_line = output.split("
")[1]
+        assert disk_line.startswith("Disk: ")
+        assert path_line.startswith("Path: ")
+        return disk_line[6:], path_line[6:]
+
+    def ls(
+        self, path: str, recursive: bool = False, show_hidden: bool = False
+    ) -> Union[List[str], Dict[str, List[str]]]:
+        recursive_adding = "--recursive " if recursive else ""
+        show_hidden_adding = "--all " if show_hidden else ""
+        output = self.execute_query(
+            f"list {path} {recursive_adding} {show_hidden_adding}"
+        )
+        if recursive:
+            answer: Dict[str, List[str]] = dict()
+            blocks = output.split("

")
+            for block in blocks:
+                directory = block.split("
")[0][:-1]
+                files = block.split("
")[1:]
+                answer[directory] = files
+            return answer
+        else:
+            return output.split("
")
+
+    def switch_disk(self, disk: str, directory: Optional[str] = None):
+        directory_addition = f"--path {directory} " if directory is not None else ""
+        self.execute_query(f"switch-disk {disk} {directory_addition}")
+
+    def cd(self, directory: str, disk: Optional[str] = None):
+        disk_addition = f"--disk {disk} " if disk is not None else ""
+        self.execute_query(f"cd {directory} {disk_addition}")
+
+    def copy(
+        self,
+        path_from,
+        path_to,
+        disk_from: Optional[str] = None,
+        disk_to: Optional[str] = None,
+        recursive: bool = False,
+    ):
+        disk_from_option = f"--disk-from {disk_from} " if disk_from is not None else ""
+        disk_to_option = f"--disk-to {disk_to} " if disk_to is not None else ""
+        recursive_tag = "--recursive" if recursive else ""
+
+        self.execute_query(
+            f"copy {recursive_tag} {path_from} {path_to} {disk_from_option} {disk_to_option}"
+        )
+
+    def move(self, path_from: str, path_to: str):
+        self.execute_query(f"move {path_from} {path_to}")
+
+    def rm(self, path: str, recursive: bool = False):
+        recursive_tag = "--recursive" if recursive else ""
+        self.execute_query(f"rm {recursive_tag} {path}")
+
+    def mkdir(self, path: str, recursive: bool = False):
+        recursive_adding = "--recursive " if recursive else ""
+        self.execute_query(f"mkdir {path} {recursive_adding}")
+
+    def ln(self, path_from: str, path_to: str):
+        self.execute_query(f"link {path_from} {path_to}")
+
+    def read(self, path_from: str, path_to: Optional[str] = None):
+        path_to_adding = f"--path-to {path_to} " if path_to is not None else ""
+        output = self.execute_query(f"read {path_from} {path_to_adding}")
+        return output
+
+    def write(
+        self, path_from: str, path_to: str
+    ):  # Writing from stdin is difficult to test (do not know how to do this in python)
+        path_from_adding = f"--path-from {path_from}"
+        self.execute_query(f"write {path_from_adding} {path_to}")
+
+    @staticmethod
+    def getLocalDisksClient(refresh: bool):
+        if (DisksClient.local_client is None) or refresh:
+            binary_file = os.environ.get("CLICKHOUSE_TESTS_SERVER_BIN_PATH")
+            current_working_directory = str(pathlib.Path().resolve())
+            config_file = f"{current_working_directory}/test_disks_app_interactive/configs/config.xml"
+            if not os.path.exists(DisksClient.default_disk_root_directory):
+                os.mkdir(DisksClient.default_disk_root_directory)
+
+            DisksClient.local_client = DisksClient(
+                binary_file, config_file, current_working_directory
+            )
+            return DisksClient.local_client
+        else:
+            return DisksClient.local_client
+
+
+def test_disks_app_interactive_list_disks():
+    client = DisksClient.getLocalDisksClient(True)
+    expected_disks_with_path = [
+        ("default", "/"),
+        ("local", client.working_path),
+    ]
+    assert expected_disks_with_path == client.list_disks()
+    assert client.current_disk_with_path() == ("default", "/")
+    client.switch_disk("local")
+    assert client.current_disk_with_path() == (
+        "local",
+        client.working_path,
+    )
+
+
+def test_disks_app_interactive_list_files_local():
+    client = DisksClient.getLocalDisksClient(True)
+    client.switch_disk("local")
+    excepted_listed_files = sorted(os.listdir("test_disks_app_interactive/"))
+    listed_files = sorted(client.ls("test_disks_app_interactive/"))
+    assert excepted_listed_files == listed_files
+
+
+def test_disks_app_interactive_list_directories_default():
+    client = DisksClient.getLocalDisksClient(True)
+    traversed_dir = client.ls(".", recursive=True)
+    client.mkdir("dir1")
+    client.mkdir("dir2")
+    client.mkdir(".dir3")
+    client.cd("dir1")
+    client.mkdir("dir11")
+    client.mkdir(".dir12")
+    client.mkdir("dir13")
+    client.cd("../dir2")
+    client.mkdir("dir21")
+    client.mkdir("dir22")
+    client.mkdir(".dir23")
+    client.cd("../.dir3")
+    client.mkdir("dir31")
+    client.mkdir(".dir32")
+    client.cd("..")
+    traversed_dir = client.ls(".", recursive=True)
+    assert traversed_dir == {
+        ".": ["dir1", "dir2"],
+        "./dir1": ["dir11", "dir13"],
+        "./dir2": ["dir21", "dir22"],
+        "./dir1/dir11": [],
+        "./dir1/dir13": [],
+        "./dir2/dir21": [],
+        "./dir2/dir22": [],
+    }
+    traversed_dir = client.ls(".", recursive=True, show_hidden=True)
+    assert traversed_dir == {
+        ".": [".dir3", "dir1", "dir2"],
+        "./dir1": [".dir12", "dir11", "dir13"],
+        "./dir2": [".dir23", "dir21", "dir22"],
+        "./.dir3": [".dir32", "dir31"],
+        "./dir1/dir11": [],
+        "./dir1/.dir12": [],
+        "./dir1/dir13": [],
+        "./dir2/dir21": [],
+        "./dir2/dir22": [],
+        "./dir2/.dir23": [],
+        "./.dir3/dir31": [],
+        "./.dir3/.dir32": [],
+    }
+    client.rm("dir2", recursive=True)
+    traversed_dir = client.ls(".", recursive=True, show_hidden=True)
+    assert traversed_dir == {
+        ".": [".dir3", "dir1"],
+        "./dir1": [".dir12", "dir11", "dir13"],
+        "./.dir3": [".dir32", "dir31"],
+        "./dir1/dir11": [],
+        "./dir1/.dir12": [],
+        "./dir1/dir13": [],
+        "./.dir3/dir31": [],
+        "./.dir3/.dir32": [],
+    }
+    traversed_dir = client.ls(".", recursive=True, show_hidden=False)
+    assert traversed_dir == {
+        ".": ["dir1"],
+        "./dir1": ["dir11", "dir13"],
+        "./dir1/dir11": [],
+        "./dir1/dir13": [],
+    }
+    client.rm("dir1", recursive=True)
+    client.rm(".dir3", recursive=True)
+    assert client.ls(".", recursive=True, show_hidden=False) == {".": []}
+
+
+def test_disks_app_interactive_cp_and_read():
+    initial_text = "File content"
+    with open("a.txt", "w") as file:
+        file.write(initial_text)
+    client = DisksClient.getLocalDisksClient(True)
+    client.switch_disk("default")
+    client.copy("a.txt", "/a.txt", disk_from="local", disk_to="default")
+    read_text = client.read("a.txt")
+    assert initial_text == read_text
+    client.mkdir("dir1")
+    client.copy("a.txt", "/dir1/b.txt", disk_from="local", disk_to="default")
+    read_text = client.read("a.txt", path_to="dir1/b.txt")
+    assert "" == read_text
+    read_text = client.read("/dir1/b.txt")
+    assert read_text == initial_text
+    with open(f"{DisksClient.default_disk_root_directory}/dir1/b.txt", "r") as file:
+        read_text = file.read()
+        assert read_text == initial_text
+    os.remove("a.txt")
+    client.rm("a.txt")
+    client.rm("/dir1", recursive=True)
+
+
+def test_disks_app_interactive_test_move_and_write():
+    initial_text = "File content"
+    with open("a.txt", "w") as file:
+        file.write(initial_text)
+    client = DisksClient.getLocalDisksClient(True)
+    client.switch_disk("default")
+    client.copy("a.txt", "/a.txt", disk_from="local", disk_to="default")
+    files = client.ls(".")
+    assert files == ["a.txt"]
+    client.move("a.txt", "b.txt")
+    files = client.ls(".")
+    assert files == ["b.txt"]
+    read_text = client.read("/b.txt")
+    assert read_text == initial_text
+    client.write("b.txt", "c.txt")
+    read_text = client.read("c.txt")
+    assert read_text == initial_text
+    os.remove("a.txt")
diff --git a/tests/queries/0_stateless/02802_clickhouse_disks_s3_copy.sh b/tests/queries/0_stateless/02802_clickhouse_disks_s3_copy.sh
index 2b9e5296a05e..20b02bcba32f 100755
--- a/tests/queries/0_stateless/02802_clickhouse_disks_s3_copy.sh
+++ b/tests/queries/0_stateless/02802_clickhouse_disks_s3_copy.sh
@@ -14,14 +14,11 @@ function run_test_for_disk()
 
     echo "$disk"
 
-    clickhouse-disks -C "$config" --disk "$disk" write --input "$config" $CLICKHOUSE_DATABASE/test
-    clickhouse-disks -C "$config" --log-level test --disk "$disk" copy $CLICKHOUSE_DATABASE/test $CLICKHOUSE_DATABASE/test.copy |& {
+    clickhouse-disks -C "$config" --disk "$disk" --query "write --path-from $config $CLICKHOUSE_DATABASE/test"
+    clickhouse-disks -C "$config" --log-level test --disk "$disk" --query "copy -r $CLICKHOUSE_DATABASE/test $CLICKHOUSE_DATABASE/test.copy" |& {
         grep -o -e "Single part upload has completed." -e "Single operation copy has completed."
     }
-    clickhouse-disks -C "$config" --disk "$disk" remove $CLICKHOUSE_DATABASE/test
-    # NOTE: this is due to "copy" does works like "cp -R from to/" instead of "cp from to"
-    clickhouse-disks -C "$config" --disk "$disk" remove $CLICKHOUSE_DATABASE/test.copy/test
-    clickhouse-disks -C "$config" --disk "$disk" remove $CLICKHOUSE_DATABASE/test.copy
+    clickhouse-disks -C "$config" --disk "$disk" --query "remove -r $CLICKHOUSE_DATABASE/test"
 }
 
 function run_test_copy_from_s3_to_s3(){
@@ -29,13 +26,12 @@ function run_test_copy_from_s3_to_s3(){
     local disk_dest=$1 && shift
 
     echo "copy from $disk_src to $disk_dest"
-    clickhouse-disks -C "$config" --disk "$disk_src" write  --input "$config" $CLICKHOUSE_DATABASE/test
+    clickhouse-disks -C "$config" --disk "$disk_src" --query "write --path-from $config $CLICKHOUSE_DATABASE/test"
 
-    clickhouse-disks -C "$config" --log-level test copy --disk-from "$disk_src" --disk-to "$disk_dest"  $CLICKHOUSE_DATABASE/test $CLICKHOUSE_DATABASE/test.copy |& {
+    clickhouse-disks -C "$config" --log-level test --query "copy -r --disk-from $disk_src --disk-to $disk_dest $CLICKHOUSE_DATABASE/test $CLICKHOUSE_DATABASE/test.copy" |& {
         grep -o -e "Single part upload has completed." -e "Single operation copy has completed."
     }
-    clickhouse-disks -C "$config" --disk "$disk_dest" remove $CLICKHOUSE_DATABASE/test.copy/test
-    clickhouse-disks -C "$config" --disk "$disk_dest" remove $CLICKHOUSE_DATABASE/test.copy
+    clickhouse-disks -C "$config" --disk "$disk_dest" --query "remove -r $CLICKHOUSE_DATABASE/test.copy"
 }
 
 run_test_for_disk s3_plain_native_copy
diff --git a/tests/queries/0_stateless/02980_s3_plain_DROP_TABLE_MergeTree.reference b/tests/queries/0_stateless/02980_s3_plain_DROP_TABLE_MergeTree.reference
index 531163e1d84e..3135f2d01e1a 100644
--- a/tests/queries/0_stateless/02980_s3_plain_DROP_TABLE_MergeTree.reference
+++ b/tests/queries/0_stateless/02980_s3_plain_DROP_TABLE_MergeTree.reference
@@ -3,28 +3,28 @@ data after ATTACH	1
 Files before DETACH TABLE
 all_1_1_0
 
-backups/ordinary_default/data/ordinary_default/data/all_1_1_0:
-primary.cidx
-serialization.json
-metadata_version.txt
-default_compression_codec.txt
+/backups/ordinary_default/data/ordinary_default/data/all_1_1_0:
+checksums.txt
+columns.txt
+count.txt
 data.bin
 data.cmrk3
-count.txt
-columns.txt
-checksums.txt
+default_compression_codec.txt
+metadata_version.txt
+primary.cidx
+serialization.json
 
 Files after DETACH TABLE
 all_1_1_0
 
-backups/ordinary_default/data/ordinary_default/data/all_1_1_0:
-primary.cidx
-serialization.json
-metadata_version.txt
-default_compression_codec.txt
+/backups/ordinary_default/data/ordinary_default/data/all_1_1_0:
+checksums.txt
+columns.txt
+count.txt
 data.bin
 data.cmrk3
-count.txt
-columns.txt
-checksums.txt
+default_compression_codec.txt
+metadata_version.txt
+primary.cidx
+serialization.json
 
diff --git a/tests/queries/0_stateless/02980_s3_plain_DROP_TABLE_MergeTree.sh b/tests/queries/0_stateless/02980_s3_plain_DROP_TABLE_MergeTree.sh
index 12d08159012d..d543f7195a9a 100755
--- a/tests/queries/0_stateless/02980_s3_plain_DROP_TABLE_MergeTree.sh
+++ b/tests/queries/0_stateless/02980_s3_plain_DROP_TABLE_MergeTree.sh
@@ -49,11 +49,11 @@ path=$($CLICKHOUSE_CLIENT -q "SELECT replace(data_paths[1], 's3_plain', '') FROM
 path=${path%/}
 
 echo "Files before DETACH TABLE"
-clickhouse-disks -C "$config" --disk s3_plain_disk list --recursive "${path:?}" | tail -n+2
+clickhouse-disks -C "$config" --disk s3_plain_disk --query "list --recursive $path" | tail -n+2
 
 $CLICKHOUSE_CLIENT -q "detach table data"
 echo "Files after DETACH TABLE"
-clickhouse-disks -C "$config" --disk s3_plain_disk list --recursive "$path" | tail -n+2
+clickhouse-disks -C "$config" --disk s3_plain_disk --query "list --recursive $path" | tail -n+2
 
 # metadata file is left
 $CLICKHOUSE_CLIENT --force_remove_data_recursively_on_drop=1 -q "drop database if exists $CLICKHOUSE_DATABASE"
diff --git a/tests/queries/0_stateless/02980_s3_plain_DROP_TABLE_ReplicatedMergeTree.reference b/tests/queries/0_stateless/02980_s3_plain_DROP_TABLE_ReplicatedMergeTree.reference
index 1e191b719a5a..a2dd196083e1 100644
--- a/tests/queries/0_stateless/02980_s3_plain_DROP_TABLE_ReplicatedMergeTree.reference
+++ b/tests/queries/0_stateless/02980_s3_plain_DROP_TABLE_ReplicatedMergeTree.reference
@@ -3,28 +3,28 @@ data after ATTACH	1
 Files before DETACH TABLE
 all_X_X_X
 
-backups/ordinary_default/data/ordinary_default/data_read/all_X_X_X:
-primary.cidx
-serialization.json
-metadata_version.txt
-default_compression_codec.txt
+/backups/ordinary_default/data/ordinary_default/data_read/all_X_X_X:
+checksums.txt
+columns.txt
+count.txt
 data.bin
 data.cmrk3
-count.txt
-columns.txt
-checksums.txt
+default_compression_codec.txt
+metadata_version.txt
+primary.cidx
+serialization.json
 
 Files after DETACH TABLE
 all_X_X_X
 
-backups/ordinary_default/data/ordinary_default/data_read/all_X_X_X:
-primary.cidx
-serialization.json
-metadata_version.txt
-default_compression_codec.txt
+/backups/ordinary_default/data/ordinary_default/data_read/all_X_X_X:
+checksums.txt
+columns.txt
+count.txt
 data.bin
 data.cmrk3
-count.txt
-columns.txt
-checksums.txt
+default_compression_codec.txt
+metadata_version.txt
+primary.cidx
+serialization.json
 
diff --git a/tests/queries/0_stateless/02980_s3_plain_DROP_TABLE_ReplicatedMergeTree.sh b/tests/queries/0_stateless/02980_s3_plain_DROP_TABLE_ReplicatedMergeTree.sh
index b079e67a0001..eec05c813446 100755
--- a/tests/queries/0_stateless/02980_s3_plain_DROP_TABLE_ReplicatedMergeTree.sh
+++ b/tests/queries/0_stateless/02980_s3_plain_DROP_TABLE_ReplicatedMergeTree.sh
@@ -55,14 +55,14 @@ path=${path%/}
 
 echo "Files before DETACH TABLE"
 # sed to match any part, since in case of fault injection part name may not be all_0_0_0 but all_1_1_0
-clickhouse-disks -C "$config" --disk s3_plain_disk list --recursive "${path:?}" | tail -n+2 | sed 's/all_[^_]*_[^_]*_0/all_X_X_X/g'
+clickhouse-disks -C "$config" --disk s3_plain_disk --query "list --recursive $path" | tail -n+2 | sed 's/all_[^_]*_[^_]*_0/all_X_X_X/g'
 
 $CLICKHOUSE_CLIENT -nm -q "
     detach table data_read;
     detach table data_write;
 "
 echo "Files after DETACH TABLE"
-clickhouse-disks -C "$config" --disk s3_plain_disk list --recursive "$path" | tail -n+2 | sed 's/all_[^_]*_[^_]*_0/all_X_X_X/g'
+clickhouse-disks -C "$config" --disk s3_plain_disk --query "list --recursive $path" | tail -n+2 | sed 's/all_[^_]*_[^_]*_0/all_X_X_X/g'
 
 # metadata file is left
 $CLICKHOUSE_CLIENT --force_remove_data_recursively_on_drop=1 -q "drop database if exists $CLICKHOUSE_DATABASE"
