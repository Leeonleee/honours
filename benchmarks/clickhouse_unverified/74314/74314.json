{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 74314,
  "instance_id": "ClickHouse__ClickHouse-74314",
  "issue_numbers": [
    "70551"
  ],
  "base_commit": "f96931780900446cba66fcb8cf52307b9c775594",
  "patch": "diff --git a/src/Planner/CollectTableExpressionData.cpp b/src/Planner/CollectTableExpressionData.cpp\nindex cef0222bffba..58c8541e30e7 100644\n--- a/src/Planner/CollectTableExpressionData.cpp\n+++ b/src/Planner/CollectTableExpressionData.cpp\n@@ -10,6 +10,7 @@\n #include <Analyzer/TableFunctionNode.h>\n #include <Analyzer/JoinNode.h>\n #include <Analyzer/ListNode.h>\n+#include <Analyzer/FunctionNode.h>\n \n #include <Planner/PlannerContext.h>\n #include <Planner/PlannerActionsVisitor.h>\n@@ -26,16 +27,24 @@ namespace ErrorCodes\n namespace\n {\n \n-class CollectSourceColumnsVisitor : public InDepthQueryTreeVisitor<CollectSourceColumnsVisitor>\n+class CollectSourceColumnsVisitor : public InDepthQueryTreeVisitorWithContext<CollectSourceColumnsVisitor>\n {\n public:\n     explicit CollectSourceColumnsVisitor(PlannerContextPtr & planner_context_, bool keep_alias_columns_ = true)\n-        : planner_context(planner_context_)\n+        : InDepthQueryTreeVisitorWithContext(planner_context_->getQueryContext())\n+        , planner_context(planner_context_)\n         , keep_alias_columns(keep_alias_columns_)\n-    {}\n+    {\n+    }\n \n-    void visitImpl(QueryTreeNodePtr & node)\n+    void enterImpl(QueryTreeNodePtr & node)\n     {\n+        if (isIndexHintFunction(node))\n+        {\n+            is_inside_index_hint_function = true;\n+            return;\n+        }\n+\n         auto * column_node = node->as<ColumnNode>();\n         if (!column_node)\n             return;\n@@ -43,6 +52,12 @@ class CollectSourceColumnsVisitor : public InDepthQueryTreeVisitor<CollectSource\n         if (column_node->getColumnName() == \"__grouping_set\")\n             return;\n \n+        /// A special case for the \"indexHint\" function. We don't need its arguments for execution if column's source table is MergeTree.\n+        /// Instead, we prepare an ActionsDAG for its arguments and store it inside a function (see ActionsDAG::buildFilterActionsDAG).\n+        /// So this optimization allows not to read arguments of \"indexHint\" (if not needed in other contexts) but only to use index analysis for them.\n+        if (is_inside_index_hint_function && isColumnSourceMergeTree(*column_node))\n+            return;\n+\n         auto column_source_node = column_node->getColumnSource();\n         auto column_source_node_type = column_source_node->getNodeType();\n \n@@ -128,6 +143,15 @@ class CollectSourceColumnsVisitor : public InDepthQueryTreeVisitor<CollectSource\n         table_expression_data.addColumn(column_node->getColumn(), column_identifier, select_added_columns);\n     }\n \n+    void leaveImpl(QueryTreeNodePtr & node)\n+    {\n+        if (isIndexHintFunction(node))\n+        {\n+            is_inside_index_hint_function = false;\n+            return;\n+        }\n+    }\n+\n     static bool isAliasColumn(const QueryTreeNodePtr & node)\n     {\n         const auto * column_node = node->as<ColumnNode>();\n@@ -149,6 +173,17 @@ class CollectSourceColumnsVisitor : public InDepthQueryTreeVisitor<CollectSource\n                  isAliasColumn(parent_node));\n     }\n \n+    static bool isIndexHintFunction(const QueryTreeNodePtr & node)\n+    {\n+        return node->as<FunctionNode>() && node->as<FunctionNode>()->getFunctionName() == \"indexHint\";\n+    }\n+\n+    static bool isColumnSourceMergeTree(const ColumnNode & node)\n+    {\n+        const auto * source_table = node.getColumnSource()->as<TableNode>();\n+        return source_table && source_table->getStorage()->isMergeTree();\n+    }\n+\n     void setKeepAliasColumns(bool keep_alias_columns_)\n     {\n         keep_alias_columns = keep_alias_columns_;\n@@ -169,6 +204,9 @@ class CollectSourceColumnsVisitor : public InDepthQueryTreeVisitor<CollectSource\n     /// Column `b` is selected explicitly by user, but not `a` (that is also read though).\n     /// Distinguishing such columns is important for checking access rights for ALIAS columns.\n     bool select_added_columns = true;\n+\n+    /// True if we are traversing arguments of function \"indexHint\".\n+    bool is_inside_index_hint_function = false;\n };\n \n class CollectPrewhereTableExpressionVisitor : public ConstInDepthQueryTreeVisitor<CollectPrewhereTableExpressionVisitor>\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/03310_index_hints_read_columns.reference b/tests/queries/0_stateless/03310_index_hints_read_columns.reference\nnew file mode 100644\nindex 000000000000..731e339250ad\n--- /dev/null\n+++ b/tests/queries/0_stateless/03310_index_hints_read_columns.reference\n@@ -0,0 +1,12 @@\n+14950\n+14950\n+14950\n+2\t1000\t['b']\n+4\t101\t['a','b']\n+2\t101\t['b']\n+1\n+1\n+1\n+2\t2\t['s']\n+8\t1\t['s','s_tokens']\n+4\t1\t['s']\ndiff --git a/tests/queries/0_stateless/03310_index_hints_read_columns.sql b/tests/queries/0_stateless/03310_index_hints_read_columns.sql\nnew file mode 100644\nindex 000000000000..918ff5d6b913\n--- /dev/null\n+++ b/tests/queries/0_stateless/03310_index_hints_read_columns.sql\n@@ -0,0 +1,74 @@\n+-- Tags: no-parallel, no-random-settings, no-object-storage\n+\n+SET enable_analyzer = 1;\n+DROP TABLE IF EXISTS t_index_hint;\n+\n+CREATE TABLE t_index_hint (a UInt64, b UInt64)\n+ENGINE = MergeTree ORDER BY a\n+SETTINGS index_granularity = 1, min_bytes_for_wide_part = 0;\n+\n+INSERT INTO t_index_hint SELECT number, number FROM numbers(1000);\n+\n+SYSTEM DROP MARK CACHE;\n+SELECT sum(b) FROM t_index_hint WHERE b >= 100 AND b < 200 SETTINGS max_threads = 1;\n+\n+SYSTEM DROP MARK CACHE;\n+SELECT sum(b) FROM t_index_hint WHERE a >= 100 AND a < 200 AND b >= 100 AND b < 200 SETTINGS max_threads = 1, force_primary_key = 1;\n+\n+SYSTEM DROP MARK CACHE;\n+SELECT sum(b) FROM t_index_hint WHERE indexHint(a >= 100 AND a < 200) AND b >= 100 AND b < 200 SETTINGS max_threads = 1, force_primary_key = 1;\n+\n+SYSTEM FLUSH LOGS;\n+\n+SELECT\n+    ProfileEvents['FileOpen'],\n+    read_rows,\n+    arraySort(arrayMap(x -> splitByChar('.', x)[-1], columns))\n+FROM system.query_log\n+WHERE type = 'QueryFinish'\n+    AND current_database = currentDatabase()\n+    AND query LIKE '%SELECT sum(b) FROM t_index_hint%'\n+ORDER BY event_time_microseconds;\n+\n+DROP TABLE IF EXISTS t_index_hint;\n+\n+CREATE TABLE t_index_hint\n+(\n+    a UInt64,\n+    s String,\n+    s_tokens Array(String) MATERIALIZED arrayDistinct(splitByWhitespace(s)),\n+    INDEX idx_tokens s_tokens TYPE bloom_filter(0.01) GRANULARITY 1,\n+)\n+ENGINE = MergeTree ORDER BY a\n+SETTINGS index_granularity = 1, min_bytes_for_wide_part = 0;\n+\n+INSERT INTO t_index_hint (a, s) VALUES (1, 'Text with my_token') (2, 'Another text');\n+\n+SYSTEM DROP MARK CACHE;\n+SYSTEM DROP INDEX MARK CACHE;\n+SYSTEM DROP SKIPPING INDEX CACHE;\n+SELECT count() FROM t_index_hint WHERE s LIKE '%my_token%' SETTINGS max_threads = 1;\n+\n+SYSTEM DROP MARK CACHE;\n+SYSTEM DROP INDEX MARK CACHE;\n+SYSTEM DROP SKIPPING INDEX CACHE;\n+SELECT count() FROM t_index_hint WHERE has(s_tokens, 'my_token') AND s LIKE '%my_token%' SETTINGS max_threads = 1, force_data_skipping_indices = 'idx_tokens';\n+\n+SYSTEM DROP MARK CACHE;\n+SYSTEM DROP INDEX MARK CACHE;\n+SYSTEM DROP SKIPPING INDEX CACHE;\n+SELECT count() FROM t_index_hint WHERE indexHint(has(s_tokens, 'my_token')) AND s LIKE '%my_token%' SETTINGS max_threads = 1, force_data_skipping_indices = 'idx_tokens';\n+\n+SYSTEM FLUSH LOGS;\n+\n+SELECT\n+    ProfileEvents['FileOpen'],\n+    read_rows,\n+    arraySort(arrayMap(x -> splitByChar('.', x)[-1], columns))\n+FROM system.query_log\n+WHERE type = 'QueryFinish'\n+    AND current_database = currentDatabase()\n+    AND query LIKE '%SELECT count() FROM t_index_hint%'\n+ORDER BY event_time_microseconds;\n+\n+DROP TABLE t_index_hint;\n",
  "problem_statement": "Do not read column when indexHint is used for the column used in predicate\nAs discussed in #57484, clickhouse still reads the column used in indexHint predicate. In CH Cloud it can add additional overhead of downloading the column from S3 which can increase the query latency. Is it possible to add the optimization of not reading the column and just use the index to filter out the granules? \n",
  "hints_text": "",
  "created_at": "2025-01-08T15:41:21Z",
  "modified_files": [
    "src/Planner/CollectTableExpressionData.cpp"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/03310_index_hints_read_columns.reference",
    "b/tests/queries/0_stateless/03310_index_hints_read_columns.sql"
  ]
}