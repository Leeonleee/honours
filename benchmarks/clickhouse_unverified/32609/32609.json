{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 32609,
  "instance_id": "ClickHouse__ClickHouse-32609",
  "issue_numbers": [
    "3575"
  ],
  "base_commit": "a7f29f959f9590f60c3d2db25e0db5782a14ace1",
  "patch": "diff --git a/docs/en/operations/server-configuration-parameters/settings.md b/docs/en/operations/server-configuration-parameters/settings.md\nindex e8099ef0ac61..bd164fa59f9d 100644\n--- a/docs/en/operations/server-configuration-parameters/settings.md\n+++ b/docs/en/operations/server-configuration-parameters/settings.md\n@@ -672,7 +672,8 @@ On hosts with low RAM and swap, you possibly need setting `max_server_memory_usa\n \n ## max_concurrent_queries {#max-concurrent-queries}\n \n-The maximum number of simultaneously processed queries related to MergeTree table. Queries may be limited by other settings: [max_concurrent_queries_for_user](#max-concurrent-queries-for-user), [max_concurrent_queries_for_all_users](#max-concurrent-queries-for-all-users), [min_marks_to_honor_max_concurrent_queries](#min-marks-to-honor-max-concurrent-queries).\n+The maximum number of simultaneously processed queries related to MergeTree table.\n+Queries may be limited by other settings: [max_concurrent_insert_queries](#max-concurrent-insert-queries), [max_concurrent_select_queries](#max-concurrent-select-queries), [max_concurrent_queries_for_user](#max-concurrent-queries-for-user), [max_concurrent_queries_for_all_users](#max-concurrent-queries-for-all-users), [min_marks_to_honor_max_concurrent_queries](#min-marks-to-honor-max-concurrent-queries).\n \n !!! info \"Note\"\n \tThese settings can be modified at runtime and will take effect immediately. Queries that are already running will remain unchanged.\n@@ -688,6 +689,42 @@ Possible values:\n <max_concurrent_queries>100</max_concurrent_queries>\n ```\n \n+## max_concurrent_insert_queries {#max-concurrent-insert-queries}\n+\n+The maximum number of simultaneously processed insert queries.\n+\n+!!! info \"Note\"\n+    These settings can be modified at runtime and will take effect immediately. Queries that are already running will remain unchanged.\n+\n+Possible values:\n+\n+-   Positive integer.\n+-   0 \u2014 Disabled.\n+\n+**Example**\n+\n+``` xml\n+<max_concurrent_insert_queries>100</max_concurrent_insert_queries>\n+```\n+\n+## max_concurrent_select_queries {#max-concurrent-select-queries}\n+\n+The maximum number of simultaneously processed select queries.\n+\n+!!! info \"Note\"\n+    These settings can be modified at runtime and will take effect immediately. Queries that are already running will remain unchanged.\n+\n+Possible values:\n+\n+-   Positive integer.\n+-   0 \u2014 Disabled.\n+\n+**Example**\n+\n+``` xml\n+<max_concurrent_select_queries>100</max_concurrent_select_queries>\n+```\n+\n ## max_concurrent_queries_for_user {#max-concurrent-queries-for-user}\n \n The maximum number of simultaneously processed queries related to MergeTree table per user.\ndiff --git a/programs/server/Server.cpp b/programs/server/Server.cpp\nindex 14075f9fbf22..d5b8eaf25573 100644\n--- a/programs/server/Server.cpp\n+++ b/programs/server/Server.cpp\n@@ -859,6 +859,12 @@ if (ThreadFuzzer::instance().isEffective())\n             if (config->has(\"max_concurrent_queries\"))\n                 global_context->getProcessList().setMaxSize(config->getInt(\"max_concurrent_queries\", 0));\n \n+            if (config->has(\"max_concurrent_insert_queries\"))\n+                global_context->getProcessList().setMaxInsertQueriesAmount(config->getInt(\"max_concurrent_insert_queries\", 0));\n+\n+            if (config->has(\"max_concurrent_select_queries\"))\n+                global_context->getProcessList().setMaxSelectQueriesAmount(config->getInt(\"max_concurrent_select_queries\", 0));\n+\n             if (config->has(\"keeper_server\"))\n                 global_context->updateKeeperConfiguration(*config);\n \ndiff --git a/src/Interpreters/ProcessList.cpp b/src/Interpreters/ProcessList.cpp\nindex a4583685a90e..40b1b5fd40e2 100644\n--- a/src/Interpreters/ProcessList.cpp\n+++ b/src/Interpreters/ProcessList.cpp\n@@ -86,6 +86,20 @@ ProcessList::EntryPtr ProcessList::insert(const String & query_, const IAST * as\n                 throw Exception(\"Too many simultaneous queries. Maximum: \" + toString(max_size), ErrorCodes::TOO_MANY_SIMULTANEOUS_QUERIES);\n         }\n \n+        String query_kind{ast->getQueryKindString()};\n+        if (!is_unlimited_query)\n+        {\n+            auto amount = getQueryKindAmount(query_kind);\n+            if (max_insert_queries_amount && query_kind == \"Insert\" && amount >= max_insert_queries_amount)\n+                throw Exception(ErrorCodes::TOO_MANY_SIMULTANEOUS_QUERIES,\n+                                \"Too many simultaneous insert queries. Maximum: {}, current: {}\",\n+                                max_insert_queries_amount, amount);\n+            if (max_select_queries_amount && query_kind == \"Select\" && amount >= max_select_queries_amount)\n+                throw Exception(ErrorCodes::TOO_MANY_SIMULTANEOUS_QUERIES,\n+                                \"Too many simultaneous select queries. Maximum: {}, current: {}\",\n+                                max_select_queries_amount, amount);\n+        }\n+\n         {\n             /**\n              * `max_size` check above is controlled by `max_concurrent_queries` server setting and is a \"hard\" limit for how many\n@@ -176,7 +190,9 @@ ProcessList::EntryPtr ProcessList::insert(const String & query_, const IAST * as\n         }\n \n         auto process_it = processes.emplace(processes.end(),\n-            query_context, query_, client_info, priorities.insert(settings.priority));\n+            query_context, query_, client_info, priorities.insert(settings.priority), query_kind);\n+\n+        increaseQueryKindAmount(query_kind);\n \n         res = std::make_shared<Entry>(*this, process_it);\n \n@@ -242,6 +258,7 @@ ProcessListEntry::~ProcessListEntry()\n \n     String user = it->getClientInfo().current_user;\n     String query_id = it->getClientInfo().current_query_id;\n+    String query_kind = it->query_kind;\n \n     const QueryStatus * process_list_element_ptr = &*it;\n \n@@ -273,6 +290,9 @@ ProcessListEntry::~ProcessListEntry()\n         LOG_ERROR(&Poco::Logger::get(\"ProcessList\"), \"Logical error: cannot find query by query_id and pointer to ProcessListElement in ProcessListForUser\");\n         std::terminate();\n     }\n+\n+    parent.decreaseQueryKindAmount(query_kind);\n+\n     parent.have_space.notify_all();\n \n     /// If there are no more queries for the user, then we will reset memory tracker and network throttler.\n@@ -286,11 +306,12 @@ ProcessListEntry::~ProcessListEntry()\n \n \n QueryStatus::QueryStatus(\n-    ContextPtr context_, const String & query_, const ClientInfo & client_info_, QueryPriorities::Handle && priority_handle_)\n+    ContextPtr context_, const String & query_, const ClientInfo & client_info_, QueryPriorities::Handle && priority_handle_, const String & query_kind_)\n     : WithContext(context_)\n     , query(query_)\n     , client_info(client_info_)\n     , priority_handle(std::move(priority_handle_))\n+    , query_kind(query_kind_)\n {\n     auto settings = getContext()->getSettings();\n     limits.max_execution_time = settings.max_execution_time;\n@@ -485,4 +506,33 @@ ProcessList::UserInfo ProcessList::getUserInfo(bool get_profile_events) const\n     return per_user_infos;\n }\n \n+void ProcessList::increaseQueryKindAmount(const String & query_kind)\n+{\n+    auto found = query_kind_amounts.find(query_kind);\n+    if (found == query_kind_amounts.end())\n+        query_kind_amounts[query_kind] = 1;\n+    else\n+        found->second += 1;\n+}\n+\n+void ProcessList::decreaseQueryKindAmount(const String & query_kind)\n+{\n+    auto found = query_kind_amounts.find(query_kind);\n+    /// TODO: we could just rebuild the map, as we have saved all query_kind.\n+    if (found == query_kind_amounts.end())\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Wrong query kind amount: decrease before increase on '{}'\", query_kind);\n+    else if (found->second == 0)\n+        throw Exception(ErrorCodes::LOGICAL_ERROR, \"Wrong query kind amount: decrease to negative on '{}'\", query_kind, found->second);\n+    else\n+        found->second -= 1;\n+\n+}\n+ProcessList::QueryAmount ProcessList::getQueryKindAmount(const String & query_kind)\n+{\n+    auto found = query_kind_amounts.find(query_kind);\n+    if (found == query_kind_amounts.end())\n+        return 0;\n+    return found->second;\n+}\n+\n }\ndiff --git a/src/Interpreters/ProcessList.h b/src/Interpreters/ProcessList.h\nindex 9c826bde0614..208aed8d3648 100644\n--- a/src/Interpreters/ProcessList.h\n+++ b/src/Interpreters/ProcessList.h\n@@ -118,13 +118,17 @@ class QueryStatus : public WithContext\n \n     ProcessListForUser * user_process_list = nullptr;\n \n+    String query_kind;\n+\n public:\n \n     QueryStatus(\n         ContextPtr context_,\n         const String & query_,\n         const ClientInfo & client_info_,\n-        QueryPriorities::Handle && priority_handle_);\n+        QueryPriorities::Handle && priority_handle_,\n+        const String & query_kind_\n+        );\n \n     ~QueryStatus();\n \n@@ -256,6 +260,7 @@ class ProcessList\n public:\n     using Element = QueryStatus;\n     using Entry = ProcessListEntry;\n+    using QueryAmount = UInt64;\n \n     /// list, for iterators not to invalidate. NOTE: could replace with cyclic buffer, but not worth.\n     using Container = std::list<Element>;\n@@ -265,6 +270,8 @@ class ProcessList\n     /// User -> queries\n     using UserToQueries = std::unordered_map<String, ProcessListForUser>;\n \n+    using QueryKindToAmount = std::unordered_map<String, QueryAmount>;\n+\n protected:\n     friend class ProcessListEntry;\n \n@@ -287,6 +294,19 @@ class ProcessList\n     /// Call under lock. Finds process with specified current_user and current_query_id.\n     QueryStatus * tryGetProcessListElement(const String & current_query_id, const String & current_user);\n \n+    /// limit for insert. 0 means no limit. Otherwise, when limit exceeded, an exception is thrown.\n+    size_t max_insert_queries_amount = 0;\n+\n+    /// limit for select. 0 means no limit. Otherwise, when limit exceeded, an exception is thrown.\n+    size_t max_select_queries_amount = 0;\n+\n+    /// amount of queries by query kind.\n+    QueryKindToAmount query_kind_amounts;\n+\n+    void increaseQueryKindAmount(const String & query_kind);\n+    void decreaseQueryKindAmount(const String & query_kind);\n+    QueryAmount getQueryKindAmount(const String & query_kind);\n+\n public:\n     using EntryPtr = std::shared_ptr<ProcessListEntry>;\n \n@@ -312,6 +332,18 @@ class ProcessList\n         max_size = max_size_;\n     }\n \n+    void setMaxInsertQueriesAmount(size_t max_insert_queries_amount_)\n+    {\n+        std::lock_guard lock(mutex);\n+        max_insert_queries_amount = max_insert_queries_amount_;\n+    }\n+\n+    void setMaxSelectQueriesAmount(size_t max_select_queries_amount_)\n+    {\n+        std::lock_guard lock(mutex);\n+        max_select_queries_amount = max_select_queries_amount_;\n+    }\n+\n     /// Try call cancel() for input and output streams of query with specified id and user\n     CancellationCode sendCancelToQuery(const String & current_query_id, const String & current_user, bool kill = false);\n \n",
  "test_patch": "diff --git a/tests/integration/test_concurrent_queries_restriction_by_query_kind/__init__.py b/tests/integration/test_concurrent_queries_restriction_by_query_kind/__init__.py\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/integration/test_concurrent_queries_restriction_by_query_kind/configs/concurrent_insert_restriction.xml b/tests/integration/test_concurrent_queries_restriction_by_query_kind/configs/concurrent_insert_restriction.xml\nnew file mode 100644\nindex 000000000000..7753c5799028\n--- /dev/null\n+++ b/tests/integration/test_concurrent_queries_restriction_by_query_kind/configs/concurrent_insert_restriction.xml\n@@ -0,0 +1,3 @@\n+<clickhouse>\n+    <max_concurrent_insert_queries>2</max_concurrent_insert_queries>\n+</clickhouse>\ndiff --git a/tests/integration/test_concurrent_queries_restriction_by_query_kind/configs/concurrent_select_restriction.xml b/tests/integration/test_concurrent_queries_restriction_by_query_kind/configs/concurrent_select_restriction.xml\nnew file mode 100644\nindex 000000000000..c8f081e68045\n--- /dev/null\n+++ b/tests/integration/test_concurrent_queries_restriction_by_query_kind/configs/concurrent_select_restriction.xml\n@@ -0,0 +1,3 @@\n+<clickhouse>\n+    <max_concurrent_select_queries>2</max_concurrent_select_queries>\n+</clickhouse>\ndiff --git a/tests/integration/test_concurrent_queries_restriction_by_query_kind/test.py b/tests/integration/test_concurrent_queries_restriction_by_query_kind/test.py\nnew file mode 100644\nindex 000000000000..2d16d9157f6d\n--- /dev/null\n+++ b/tests/integration/test_concurrent_queries_restriction_by_query_kind/test.py\n@@ -0,0 +1,77 @@\n+import time\n+from multiprocessing.dummy import Pool\n+\n+import pytest\n+from helpers.cluster import ClickHouseCluster\n+\n+\n+cluster = ClickHouseCluster(__file__)\n+node_insert = cluster.add_instance('node_insert', main_configs=['configs/concurrent_insert_restriction.xml'])\n+node_select = cluster.add_instance('node_select', main_configs=['configs/concurrent_select_restriction.xml'])\n+\n+\n+@pytest.fixture(scope=\"module\")\n+def started_cluster():\n+    try:\n+        cluster.start()\n+        node_select.query(\"create table test_concurrent_insert (x UInt64) ENGINE = MergeTree() order by tuple()\")\n+        node_insert.query(\"create table test_concurrent_insert (x UInt64) ENGINE = MergeTree() order by tuple()\")\n+        yield cluster\n+    finally:\n+        cluster.shutdown()\n+\n+\n+def execute_with_background(node, sql, background_sql, background_times, wait_times=3):\n+    r = None\n+    for _ in range(wait_times):\n+        r = node.query('show processlist', stdin='')\n+        if not r.strip():\n+            break\n+        time.sleep(1)\n+    else:\n+        assert False, \"there are unknown background queries: {}\".format(r)\n+    for _ in range(background_times):\n+        node.get_query_request(background_sql, stdin='')\n+    time.sleep(0.5) # wait background to start.\n+    return node.query(sql, stdin='')\n+\n+\n+def common_pattern(node, query_kind, restricted_sql, normal_sql, limit, wait_times):\n+    # restriction is working\n+    with pytest.raises(Exception, match=r\".*Too many simultaneous {} queries.*\".format(query_kind)):\n+        execute_with_background(node, restricted_sql, restricted_sql, limit, wait_times)\n+\n+    # different query kind is independent\n+    execute_with_background(node, normal_sql, restricted_sql, limit, wait_times)\n+\n+    # normal\n+    execute_with_background(node, restricted_sql, '', 0, wait_times)\n+\n+\n+def test_select(started_cluster):\n+    common_pattern(\n+        node_select, 'select',\n+        'select sleep(3)',\n+        'insert into test_concurrent_insert values (0)',\n+        2,\n+        10\n+    )\n+\n+    # subquery is not counted\n+    execute_with_background(\n+        node_select,\n+        'select sleep(3)',\n+        'insert into test_concurrent_insert select sleep(3)',\n+        2,\n+        10\n+    )\n+\n+\n+def test_insert(started_cluster):\n+    common_pattern(\n+        node_insert, 'insert',\n+        'insert into test_concurrent_insert select sleep(3)',\n+        'select 1',\n+        2,\n+        10\n+    )\n",
  "problem_statement": "Separator the  resource for Insert and Query\uff0cKeep the  insert ability.\nNow  insert and query share the resource ( Max Process Count control) \u3002 When the query with high TPS\uff0cthe insert will get error (\u201cerror: too many process\u201d).   I think separator the resource for Insert and Query will makes sense.   Ensure enough resource for insert\u3002It looks like Use Yarn\uff0c Insert and Query use the different resource quota\u3002 \r\n       Or the simple way , Can we set Ratio for Insert and Query in the total max process count\uff1f\n",
  "hints_text": "Right now I only can advise to update your current configuration settings (like, `max_concurrent_queries` and `max_connections`). Also, there is no such error message \"too many process\" - maybe you meant: \"Too many simultaneous queries\". The possible solution in the future is to implement separate configuration options for pools of read-only and read-write queries.\n@abyss7  thanks .Yes, I meant the errors message: 'Too many simultaneous queries. Maxmum:xx'\u3002the configuration set \"max_concurrent_queries and max_connections\" can't guaranteed write stability\u3002Hope the feature like ' pools of read-only and read-write queries' in the future\u3002\r\n\nIt's easy to add new settings\r\n`max_concurrent_insert_queries`\r\n`max_concurrent_select_queries`\r\n\r\nUp for grabs.\nIs this active?I'm a newbee.I want to fix it.\n2 years have passed and still no PRs. Is it really an \"easy task\"? :)\n@GinGin3203 Yes, the task is easy to implement.\r\nWe have no current plans to do it.",
  "created_at": "2021-12-12T08:16:07Z",
  "modified_files": [
    "docs/en/operations/server-configuration-parameters/settings.md",
    "programs/server/Server.cpp",
    "src/Interpreters/ProcessList.cpp",
    "src/Interpreters/ProcessList.h"
  ],
  "modified_test_files": [
    "b/tests/integration/test_concurrent_queries_restriction_by_query_kind/configs/concurrent_insert_restriction.xml",
    "b/tests/integration/test_concurrent_queries_restriction_by_query_kind/configs/concurrent_select_restriction.xml",
    "b/tests/integration/test_concurrent_queries_restriction_by_query_kind/test.py"
  ]
}