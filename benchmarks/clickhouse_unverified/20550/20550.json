{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 20550,
  "instance_id": "ClickHouse__ClickHouse-20550",
  "issue_numbers": [
    "20457"
  ],
  "base_commit": "749dd8d555398ca3655efd20e6f227b5c0892ea8",
  "patch": "diff --git a/src/Interpreters/ExecuteScalarSubqueriesVisitor.cpp b/src/Interpreters/ExecuteScalarSubqueriesVisitor.cpp\nindex e6061aabe947..7ee7bb1f3017 100644\n--- a/src/Interpreters/ExecuteScalarSubqueriesVisitor.cpp\n+++ b/src/Interpreters/ExecuteScalarSubqueriesVisitor.cpp\n@@ -21,7 +21,7 @@\n \n #include <IO/WriteHelpers.h>\n \n-#include <Processors/Executors/PullingPipelineExecutor.h>\n+#include <Processors/Executors/PullingAsyncPipelineExecutor.h>\n \n namespace DB\n {\n@@ -122,8 +122,10 @@ void ExecuteScalarSubqueriesMatcher::visit(const ASTSubquery & subquery, ASTPtr\n \n             try\n             {\n-                PullingPipelineExecutor executor(io.pipeline);\n-                if (!executor.pull(block))\n+                PullingAsyncPipelineExecutor executor(io.pipeline);\n+                while (block.rows() == 0 && executor.pull(block));\n+\n+                if (block.rows() == 0)\n                 {\n                     /// Interpret subquery with empty result as Null literal\n                     auto ast_new = std::make_unique<ASTLiteral>(Null());\n@@ -132,7 +134,13 @@ void ExecuteScalarSubqueriesMatcher::visit(const ASTSubquery & subquery, ASTPtr\n                     return;\n                 }\n \n-                if (block.rows() != 1 || executor.pull(block))\n+                if (block.rows() != 1)\n+                    throw Exception(\"Scalar subquery returned more than one row\", ErrorCodes::INCORRECT_RESULT_OF_SCALAR_SUBQUERY);\n+\n+                Block tmp_block;\n+                while (tmp_block.rows() == 0 && executor.pull(tmp_block));\n+\n+                if (tmp_block.rows() != 0)\n                     throw Exception(\"Scalar subquery returned more than one row\", ErrorCodes::INCORRECT_RESULT_OF_SCALAR_SUBQUERY);\n             }\n             catch (const Exception & e)\ndiff --git a/src/Interpreters/ExpressionAnalyzer.cpp b/src/Interpreters/ExpressionAnalyzer.cpp\nindex 660718549b34..4a43b52f2397 100644\n--- a/src/Interpreters/ExpressionAnalyzer.cpp\n+++ b/src/Interpreters/ExpressionAnalyzer.cpp\n@@ -54,7 +54,7 @@\n #include <IO/Operators.h>\n #include <IO/WriteBufferFromString.h>\n \n-#include <Processors/Executors/PullingPipelineExecutor.h>\n+#include <Processors/Executors/PullingAsyncPipelineExecutor.h>\n #include <Parsers/formatAST.h>\n \n namespace DB\n@@ -320,7 +320,7 @@ void SelectQueryExpressionAnalyzer::tryMakeSetForIndexFromSubquery(const ASTPtr\n \n     auto interpreter_subquery = interpretSubquery(subquery_or_table_name, context, {}, query_options);\n     auto io = interpreter_subquery->execute();\n-    PullingPipelineExecutor executor(io.pipeline);\n+    PullingAsyncPipelineExecutor executor(io.pipeline);\n \n     SetPtr set = std::make_shared<Set>(settings.size_limits_for_set, true, context.getSettingsRef().transform_null_in);\n     set->setHeader(executor.getHeader());\n@@ -328,6 +328,9 @@ void SelectQueryExpressionAnalyzer::tryMakeSetForIndexFromSubquery(const ASTPtr\n     Block block;\n     while (executor.pull(block))\n     {\n+        if (block.rows() == 0)\n+            continue;\n+\n         /// If the limits have been exceeded, give up and let the default subquery processing actions take place.\n         if (!set->insertFromBlock(block))\n             return;\ndiff --git a/src/Processors/Executors/PullingAsyncPipelineExecutor.cpp b/src/Processors/Executors/PullingAsyncPipelineExecutor.cpp\nindex e4bcf6dc0ab1..c975153d317c 100644\n--- a/src/Processors/Executors/PullingAsyncPipelineExecutor.cpp\n+++ b/src/Processors/Executors/PullingAsyncPipelineExecutor.cpp\n@@ -14,6 +14,7 @@ struct PullingAsyncPipelineExecutor::Data\n {\n     PipelineExecutorPtr executor;\n     std::exception_ptr exception;\n+    LazyOutputFormat * lazy_format = nullptr;\n     std::atomic_bool is_finished = false;\n     std::atomic_bool has_exception = false;\n     ThreadFromGlobalPool thread;\n@@ -82,6 +83,10 @@ static void threadFunction(PullingAsyncPipelineExecutor::Data & data, ThreadGrou\n     {\n         data.exception = std::current_exception();\n         data.has_exception = true;\n+\n+        /// Finish lazy format in case of exception. Otherwise thread.join() may hung.\n+        if (data.lazy_format)\n+            data.lazy_format->finalize();\n     }\n \n     data.is_finished = true;\n@@ -95,6 +100,7 @@ bool PullingAsyncPipelineExecutor::pull(Chunk & chunk, uint64_t milliseconds)\n     {\n         data = std::make_unique<Data>();\n         data->executor = pipeline.execute();\n+        data->lazy_format = lazy_format.get();\n \n         auto func = [&, thread_group = CurrentThread::getGroup()]()\n         {\n@@ -105,14 +111,7 @@ bool PullingAsyncPipelineExecutor::pull(Chunk & chunk, uint64_t milliseconds)\n     }\n \n     if (data->has_exception)\n-    {\n-        /// Finish lazy format in case of exception. Otherwise thread.join() may hung.\n-        if (lazy_format)\n-            lazy_format->finish();\n-\n-        data->has_exception = false;\n         std::rethrow_exception(std::move(data->exception));\n-    }\n \n     bool is_execution_finished = lazy_format ? lazy_format->isFinished()\n                                              : data->is_finished.load();\n@@ -121,7 +120,7 @@ bool PullingAsyncPipelineExecutor::pull(Chunk & chunk, uint64_t milliseconds)\n     {\n         /// If lazy format is finished, we don't cancel pipeline but wait for main thread to be finished.\n         data->is_finished = true;\n-        /// Wait thread ant rethrow exception if any.\n+        /// Wait thread and rethrow exception if any.\n         cancel();\n         return false;\n     }\n@@ -133,7 +132,12 @@ bool PullingAsyncPipelineExecutor::pull(Chunk & chunk, uint64_t milliseconds)\n     }\n \n     chunk.clear();\n-    data->finish_event.tryWait(milliseconds);\n+\n+    if (milliseconds)\n+        data->finish_event.tryWait(milliseconds);\n+    else\n+        data->finish_event.wait();\n+\n     return true;\n }\n \ndiff --git a/src/Processors/Formats/LazyOutputFormat.cpp b/src/Processors/Formats/LazyOutputFormat.cpp\nindex 46287d1cce9e..0663ff28f84e 100644\n--- a/src/Processors/Formats/LazyOutputFormat.cpp\n+++ b/src/Processors/Formats/LazyOutputFormat.cpp\n@@ -16,8 +16,13 @@ Chunk LazyOutputFormat::getChunk(UInt64 milliseconds)\n     }\n \n     Chunk chunk;\n-    if (!queue.tryPop(chunk, milliseconds))\n-        return {};\n+    if (milliseconds)\n+    {\n+        if (!queue.tryPop(chunk, milliseconds))\n+            return {};\n+    }\n+    else\n+        queue.pop(chunk);\n \n     if (chunk)\n         info.update(chunk.getNumRows(), chunk.allocatedBytes());\ndiff --git a/src/Processors/Formats/LazyOutputFormat.h b/src/Processors/Formats/LazyOutputFormat.h\nindex 06ec116f3dde..15ea5022f825 100644\n--- a/src/Processors/Formats/LazyOutputFormat.h\n+++ b/src/Processors/Formats/LazyOutputFormat.h\n@@ -36,6 +36,14 @@ class LazyOutputFormat : public IOutputFormat\n         queue.clear();\n     }\n \n+    void finalize() override\n+    {\n+        finished_processing = true;\n+\n+        /// In case we are waiting for result.\n+        queue.emplace(Chunk());\n+    }\n+\n protected:\n     void consume(Chunk chunk) override\n     {\n@@ -46,14 +54,6 @@ class LazyOutputFormat : public IOutputFormat\n     void consumeTotals(Chunk chunk) override { totals = std::move(chunk); }\n     void consumeExtremes(Chunk chunk) override { extremes = std::move(chunk); }\n \n-    void finalize() override\n-    {\n-        finished_processing = true;\n-\n-        /// In case we are waiting for result.\n-        queue.emplace(Chunk());\n-    }\n-\n private:\n \n     ConcurrentBoundedQueue<Chunk> queue;\n",
  "test_patch": "diff --git a/tests/performance/subqueries.xml b/tests/performance/subqueries.xml\nnew file mode 100644\nindex 000000000000..0d41099841b3\n--- /dev/null\n+++ b/tests/performance/subqueries.xml\n@@ -0,0 +1,7 @@\n+<test>\n+    <create_query>create table tab (a UInt32, b UInt32) engine = MergeTree order by (a, b)</create_query>\n+    <fill_query>insert into tab values (1, 1)</fill_query>\n+    <query>select a, b from tab where (a, b) in (select toUInt32(number) as x, toUInt32(sleep(0.1) + 1) from numbers_mt(16)) settings max_threads = 2, max_block_size = 4</query>\n+    <query>select a, b from tab where (1, 1) = (select min(toUInt32(number + 1)) as x, min(toUInt32(sleep(0.1) + 1)) from numbers_mt(16)) settings max_threads = 2, max_block_size = 4</query>\n+    <drop_query>DROP TABLE tab</drop_query>\n+</test>\ndiff --git a/tests/queries/0_stateless/00205_scalar_subqueries.sql b/tests/queries/0_stateless/00205_scalar_subqueries.sql\nindex 14244377e5f7..03bcd0a3ebce 100644\n--- a/tests/queries/0_stateless/00205_scalar_subqueries.sql\n+++ b/tests/queries/0_stateless/00205_scalar_subqueries.sql\n@@ -7,3 +7,4 @@ SELECT (SELECT toDate('2015-01-02'), 'Hello');\n SELECT (SELECT toDate('2015-01-02'), 'Hello') AS x, x, identity((SELECT 1)), identity((SELECT 1) AS y);\n -- SELECT (SELECT uniqState(''));\n \n+ SELECT ( SELECT throwIf(1 + dummy) );  -- { serverError 395 }\n",
  "problem_statement": "where .. in (select  ) by index does  not work anymore in some cases that worked before\n```sql\r\n\r\ndrop table if exists t ;\r\ndrop table if exists temp ;\r\n\r\nCREATE TABLE t\r\n(\r\n    game String,\r\n    round String,\r\n    casino Int32)\r\nENGINE = MergeTree() ORDER BY (casino, game, round);\r\n\r\nCREATE TABLE temp\r\n(\r\n    game String,\r\n    round String,\r\n    casino Int32)\r\nENGINE = MergeTree() ORDER BY (casino, game, round);\r\n\r\ninsert into t(casino, game, round)\r\nselect number%103, toString(cityHash64(number%999)), toString(number) from numbers(3, 50000000);\r\n\r\ninsert into temp(casino, game, round)\r\nselect number%103, toString(cityHash64(number%999)), toString(number) from numbers(5000);\r\n\r\nQ1: SELECT count(*)\r\nFROM temp WHERE (casino, game, round) NOT IN\r\n(     SELECT  casino, game, round\r\n    FROM t\r\n    WHERE (casino, game, round) IN\r\n    (\r\n        SELECT casino, game, round\r\n        FROM temp\r\n    )\r\n)\r\n\r\n21.3.1.5944  Elapsed: 4.464 sec. Processed 5.00 thousand rows, 225.89 KB (1.12 thousand rows/s., 50.60 KB/s.)\r\n\r\n20.8.11.17    Elapsed: 0.611 sec. Processed 5.00 thousand rows, 225.89 KB (8.18 thousand rows/s., 369.73 KB/s.)\r\n\r\n18.14.19.    Elapsed: 0.341 sec. Processed 5.00 thousand rows, 225.89 KB (14.66 thousand rows/s., 662.46 KB/s.)\r\n\r\n```\n",
  "hints_text": "Introduced in #19007.\n@KochetovNicolai, can you take a look, please? Regression was beetween e2a2ab6 and b03f28f commits.\nWith build from e2a2ab6.\r\n\r\n```sql\r\nSELECT version()\r\n\r\n\u250c\u2500version()\u2500\u2500\u2500\u2510\r\n\u2502 21.1.1.5664 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\nSELECT count(*)\u3000FROM temp WHERE (casino, game, round) NOT IN\u3000(     SELECT  casino, game, round\u3000    FROM t\u3000    WHERE (casino, game, round) IN\u3000    (\u3000        SELECT casino, game, round\u3000        FROM temp ))\r\n\r\nQuery id: dd18adcd-5729-459f-8781-a4a389201a8d\r\n\r\n\u250c\u2500count()\u2500\u2510\r\n\u2502       3 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n1 rows in set. Elapsed: 0.213 sec. Processed 5.00 thousand rows, 225.89 KB (23.48 thousand rows/s., 1.06 MB/s.)\r\n```\nWith build from b03f28f.\r\n\r\n```sql\r\nSELECT version()\r\n\r\n\u250c\u2500version()\u2500\u2500\u2500\u2510\r\n\u2502 21.1.1.5668 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n1 rows in set. Elapsed: 0.002 sec. \r\n\r\nSELECT count(*)\u3000FROM temp WHERE (casino, game, round) NOT IN\u3000(     SELECT  casino, game, round\u3000    FROM t\u3000    WHERE (casino, game, round) IN\u3000    (\u3000        SELECT casino, game, round\u3000        FROM temp ))\r\n\r\n\u250c\u2500count()\u2500\u2510\r\n\u2502       3 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n1 rows in set. Elapsed: 6.147 sec. Processed 5.00 thousand rows, 225.89 KB (813.44 rows/s., 36.75 KB/s.) \nInteresting, that a trick with `order by (Int64 )` is still OK.\r\n\r\n```\r\ncreate table data(K Int64, V String) engine=MergeTree order by K;\r\ninsert into data select number, toString(number) from numbers(100,100000000);\r\noptimize table data final;\r\ncreate table buffer(K Int64, V String) engine=Memory;\r\ninsert into buffer select number, toString(number) from numbers(0,1000);\r\n\r\nselect count() from buffer where K not in (select K from data where K in (select K from buffer));\r\n\u250c\u2500count()\u2500\u2510\r\n\u2502     100 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n1 rows in set. Elapsed: 0.002 sec. Processed 9.19 thousand rows, 73.54 KB (4.76 million rows/s., 38.09 MB/s.)\r\n\r\n21.3.1.5998.\r\n```\r\n\r\nThough, maybe I misunderstand and it's another case because it's working with `set force_primary_key=1;`\r\n```\r\nset force_primary_key=1;\r\nselect count() from buffer where K not in (select K from data where K in (select K from buffer));\r\n\u250c\u2500count()\u2500\u2510\r\n\u2502     100 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n1 rows in set. Elapsed: 0.002 sec. Processed 9.19 thousand rows, 73.54 KB (5.38 million rows/s., 43.00 MB/s.)\r\n\r\n```",
  "created_at": "2021-02-16T08:37:10Z",
  "modified_files": [
    "src/Interpreters/ExecuteScalarSubqueriesVisitor.cpp",
    "src/Interpreters/ExpressionAnalyzer.cpp",
    "src/Processors/Executors/PullingAsyncPipelineExecutor.cpp",
    "src/Processors/Formats/LazyOutputFormat.cpp",
    "src/Processors/Formats/LazyOutputFormat.h"
  ],
  "modified_test_files": [
    "b/tests/performance/subqueries.xml",
    "tests/queries/0_stateless/00205_scalar_subqueries.sql"
  ]
}