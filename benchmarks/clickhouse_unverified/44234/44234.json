{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 44234,
  "instance_id": "ClickHouse__ClickHouse-44234",
  "issue_numbers": [
    "43558"
  ],
  "base_commit": "94604f71b7b69b566f2bf3bd3dedf30300bc05ce",
  "patch": "diff --git a/src/Interpreters/InterpreterInsertQuery.cpp b/src/Interpreters/InterpreterInsertQuery.cpp\nindex a1ffe8abac39..62f3e190ef62 100644\n--- a/src/Interpreters/InterpreterInsertQuery.cpp\n+++ b/src/Interpreters/InterpreterInsertQuery.cpp\n@@ -14,6 +14,7 @@\n #include <Interpreters/addMissingDefaults.h>\n #include <Interpreters/getTableExpressions.h>\n #include <Interpreters/processColumnTransformers.h>\n+#include <Interpreters/InterpreterSelectQueryAnalyzer.h>\n #include <Parsers/ASTFunction.h>\n #include <Parsers/ASTInsertQuery.h>\n #include <Parsers/ASTSelectQuery.h>\n@@ -63,39 +64,54 @@ InterpreterInsertQuery::InterpreterInsertQuery(\n \n StoragePtr InterpreterInsertQuery::getTable(ASTInsertQuery & query)\n {\n+    auto current_context = getContext();\n+\n     if (query.table_function)\n     {\n         const auto & factory = TableFunctionFactory::instance();\n-        TableFunctionPtr table_function_ptr = factory.get(query.table_function, getContext());\n+        TableFunctionPtr table_function_ptr = factory.get(query.table_function, current_context);\n \n         /// If table function needs structure hint from select query\n         /// we can create a temporary pipeline and get the header.\n         if (query.select && table_function_ptr->needStructureHint())\n         {\n-            InterpreterSelectWithUnionQuery interpreter_select{\n-                query.select, getContext(), SelectQueryOptions(QueryProcessingStage::Complete, 1)};\n-            auto tmp_pipeline = interpreter_select.buildQueryPipeline();\n-            ColumnsDescription structure_hint{tmp_pipeline.getHeader().getNamesAndTypesList()};\n+            Block header_block;\n+            auto select_query_options = SelectQueryOptions(QueryProcessingStage::Complete, 1);\n+\n+            if (current_context->getSettingsRef().allow_experimental_analyzer)\n+            {\n+                InterpreterSelectQueryAnalyzer interpreter_select(query.select, current_context, select_query_options);\n+                header_block = interpreter_select.getSampleBlock();\n+            }\n+            else\n+            {\n+                InterpreterSelectWithUnionQuery interpreter_select{\n+                    query.select, current_context, select_query_options};\n+                auto tmp_pipeline = interpreter_select.buildQueryPipeline();\n+                header_block = tmp_pipeline.getHeader();\n+            }\n+\n+            ColumnsDescription structure_hint{header_block.getNamesAndTypesList()};\n             table_function_ptr->setStructureHint(structure_hint);\n         }\n \n-        return table_function_ptr->execute(query.table_function, getContext(), table_function_ptr->getName(),\n+        return table_function_ptr->execute(query.table_function, current_context, table_function_ptr->getName(),\n                                            /* cached_columns */ {}, /* use_global_context */ false, /* is_insert_query */true);\n     }\n \n     if (query.table_id)\n     {\n-        query.table_id = getContext()->resolveStorageID(query.table_id);\n+        query.table_id = current_context->resolveStorageID(query.table_id);\n     }\n     else\n     {\n         /// Insert query parser does not fill table_id because table and\n         /// database can be parameters and be filled after parsing.\n         StorageID local_table_id(query.getDatabase(), query.getTable());\n-        query.table_id = getContext()->resolveStorageID(local_table_id);\n+        query.table_id = current_context->resolveStorageID(local_table_id);\n     }\n \n-    return DatabaseCatalog::instance().getTable(query.table_id, getContext());\n+    return DatabaseCatalog::instance().getTable(query.table_id, current_context);\n }\n \n Block InterpreterInsertQuery::getSampleBlock(\n@@ -384,16 +400,34 @@ BlockIO InterpreterInsertQuery::execute()\n                 new_context->setSettings(new_settings);\n                 new_context->setInsertionTable(getContext()->getInsertionTable());\n \n-                InterpreterSelectWithUnionQuery interpreter_select{\n-                    query.select, new_context, SelectQueryOptions(QueryProcessingStage::Complete, 1)};\n-                pipeline = interpreter_select.buildQueryPipeline();\n+                auto select_query_options = SelectQueryOptions(QueryProcessingStage::Complete, 1);\n+\n+                if (settings.allow_experimental_analyzer)\n+                {\n+                    InterpreterSelectQueryAnalyzer interpreter_select_analyzer(query.select, new_context, select_query_options);\n+                    pipeline = interpreter_select_analyzer.buildQueryPipeline();\n+                }\n+                else\n+                {\n+                    InterpreterSelectWithUnionQuery interpreter_select(query.select, new_context, select_query_options);\n+                    pipeline = interpreter_select.buildQueryPipeline();\n+                }\n             }\n             else\n             {\n                 /// Passing 1 as subquery_depth will disable limiting size of intermediate result.\n-                InterpreterSelectWithUnionQuery interpreter_select{\n-                    query.select, getContext(), SelectQueryOptions(QueryProcessingStage::Complete, 1)};\n-                pipeline = interpreter_select.buildQueryPipeline();\n+                auto select_query_options = SelectQueryOptions(QueryProcessingStage::Complete, 1);\n+\n+                if (settings.allow_experimental_analyzer)\n+                {\n+                    InterpreterSelectQueryAnalyzer interpreter_select_analyzer(query.select, getContext(), select_query_options);\n+                    pipeline = interpreter_select_analyzer.buildQueryPipeline();\n+                }\n+                else\n+                {\n+                    InterpreterSelectWithUnionQuery interpreter_select(query.select, getContext(), select_query_options);\n+                    pipeline = interpreter_select.buildQueryPipeline();\n+                }\n             }\n \n             pipeline.dropTotalsAndExtremes();\ndiff --git a/src/Interpreters/InterpreterSelectQueryAnalyzer.cpp b/src/Interpreters/InterpreterSelectQueryAnalyzer.cpp\nindex 076d52cab5e3..853687918c81 100644\n--- a/src/Interpreters/InterpreterSelectQueryAnalyzer.cpp\n+++ b/src/Interpreters/InterpreterSelectQueryAnalyzer.cpp\n@@ -116,6 +116,17 @@ QueryPlan && InterpreterSelectQueryAnalyzer::extractQueryPlan() &&\n     return std::move(planner).extractQueryPlan();\n }\n \n+QueryPipelineBuilder InterpreterSelectQueryAnalyzer::buildQueryPipeline()\n+{\n+    planner.buildQueryPlanIfNeeded();\n+    auto & query_plan = planner.getQueryPlan();\n+\n+    QueryPlanOptimizationSettings optimization_settings;\n+    BuildQueryPipelineSettings build_pipeline_settings;\n+\n+    return std::move(*query_plan.buildQueryPipeline(optimization_settings, build_pipeline_settings));\n+}\n+\n void InterpreterSelectQueryAnalyzer::addStorageLimits(const StorageLimitsList & storage_limits)\n {\n     planner.addStorageLimits(storage_limits);\ndiff --git a/src/Interpreters/InterpreterSelectQueryAnalyzer.h b/src/Interpreters/InterpreterSelectQueryAnalyzer.h\nindex 4a0346c65bb2..0c2465224e71 100644\n--- a/src/Interpreters/InterpreterSelectQueryAnalyzer.h\n+++ b/src/Interpreters/InterpreterSelectQueryAnalyzer.h\n@@ -36,6 +36,8 @@ class InterpreterSelectQueryAnalyzer : public IInterpreter\n \n     QueryPlan && extractQueryPlan() &&;\n \n+    QueryPipelineBuilder buildQueryPipeline();\n+\n     void addStorageLimits(const StorageLimitsList & storage_limits);\n \n     bool supportsTransactions() const override { return true; }\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02501_analyzer_expired_context_crash_fix.reference b/tests/queries/0_stateless/02501_analyzer_expired_context_crash_fix.reference\nnew file mode 100644\nindex 000000000000..c3174a11f71e\n--- /dev/null\n+++ b/tests/queries/0_stateless/02501_analyzer_expired_context_crash_fix.reference\n@@ -0,0 +1,1 @@\n+0\t0\t\\N\ndiff --git a/tests/queries/0_stateless/02501_analyzer_expired_context_crash_fix.sql b/tests/queries/0_stateless/02501_analyzer_expired_context_crash_fix.sql\nnew file mode 100644\nindex 000000000000..b9ec14501bd1\n--- /dev/null\n+++ b/tests/queries/0_stateless/02501_analyzer_expired_context_crash_fix.sql\n@@ -0,0 +1,15 @@\n+SET allow_experimental_analyzer = 1;\n+\n+DROP TABLE IF EXISTS test_table;\n+CREATE TABLE test_table\n+(\n+    b Int64,\n+    a Int64,\n+    grp_aggreg AggregateFunction(groupArrayArray, Array(UInt64))\n+) ENGINE = MergeTree() ORDER BY a;\n+\n+INSERT INTO test_table SELECT 0, 0, groupArrayArrayState([toUInt64(1)]);\n+\n+SELECT b, a, JSONLength(grp_aggreg, 100, NULL) FROM test_table SETTINGS optimize_aggregation_in_order = 1;\n+\n+DROP TABLE test_table;\ndiff --git a/tests/queries/0_stateless/02502_analyzer_insert_select_crash_fix.reference b/tests/queries/0_stateless/02502_analyzer_insert_select_crash_fix.reference\nnew file mode 100644\nindex 000000000000..e07d6e49e151\n--- /dev/null\n+++ b/tests/queries/0_stateless/02502_analyzer_insert_select_crash_fix.reference\n@@ -0,0 +1,3 @@\n+0\tValue_0\n+1\tValue_1\n+2\tValue_2\ndiff --git a/tests/queries/0_stateless/02502_analyzer_insert_select_crash_fix.sql b/tests/queries/0_stateless/02502_analyzer_insert_select_crash_fix.sql\nnew file mode 100644\nindex 000000000000..4643f65988a8\n--- /dev/null\n+++ b/tests/queries/0_stateless/02502_analyzer_insert_select_crash_fix.sql\n@@ -0,0 +1,26 @@\n+SET allow_experimental_analyzer = 1;\n+\n+DROP TABLE IF EXISTS test_table;\n+CREATE TABLE test_table\n+(\n+    id UInt64,\n+    value String\n+) ENGINE=MergeTree ORDER BY id;\n+\n+INSERT INTO test_table SELECT 0, 'Value_0';\n+\n+DROP TABLE IF EXISTS test_table_data;\n+CREATE TABLE test_table_data\n+(\n+    id UInt64,\n+    value String\n+) ENGINE=MergeTree ORDER BY id;\n+\n+INSERT INTO test_table_data VALUES (1, 'Value_1'), (2, 'Value_2');\n+\n+INSERT INTO test_table SELECT id, value FROM test_table_data;\n+\n+SELECT id, value FROM test_table ORDER BY id;\n+\n+DROP TABLE test_table_data;\n+DROP TABLE test_table;\n",
  "problem_statement": "`Context has expired` while using new analyzer and optimize_aggregation_in_order\nhttps://s3.amazonaws.com/clickhouse-test-reports/42033/ebdfbf43db5e5eacaff81b4a3dd55c5a285ee025/fuzzer_astfuzzerasan//report.html\r\nHow to reproduce:\r\n```\r\n:) create table data_02295 (b Int64, a Int64, grp_aggreg AggregateFunction(groupArrayArray, Array(UInt64))) engine = MergeTree() order by a;\r\n:) set allow_experimental_analyzer=1;\r\n:) SELECT grp_aggreg FROM data_02295 WHERE JSONLength(grp_aggreg, 100, NULL) SETTINGS optimize_aggregation_in_order = 1;\r\n```\r\n\r\nCC: @kitaisreal \n",
  "hints_text": "",
  "created_at": "2022-12-14T18:02:48Z",
  "modified_files": [
    "src/Interpreters/InterpreterInsertQuery.cpp",
    "src/Interpreters/InterpreterSelectQueryAnalyzer.cpp",
    "src/Interpreters/InterpreterSelectQueryAnalyzer.h"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/02501_analyzer_expired_context_crash_fix.reference",
    "b/tests/queries/0_stateless/02501_analyzer_expired_context_crash_fix.sql",
    "b/tests/queries/0_stateless/02502_analyzer_insert_select_crash_fix.reference",
    "b/tests/queries/0_stateless/02502_analyzer_insert_select_crash_fix.sql"
  ]
}