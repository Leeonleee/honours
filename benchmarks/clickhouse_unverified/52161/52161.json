{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 52161,
  "instance_id": "ClickHouse__ClickHouse-52161",
  "issue_numbers": [
    "52020"
  ],
  "base_commit": "f4e095b50237c891ade2f8dba332963419cde91d",
  "patch": "diff --git a/src/AggregateFunctions/AggregateFunctionGroupArrayMoving.cpp b/src/AggregateFunctions/AggregateFunctionGroupArrayMoving.cpp\nindex e2acccce5166..026b8d1956f0 100644\n--- a/src/AggregateFunctions/AggregateFunctionGroupArrayMoving.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionGroupArrayMoving.cpp\n@@ -1,10 +1,25 @@\n+#include <AggregateFunctions/IAggregateFunction.h>\n #include <AggregateFunctions/AggregateFunctionFactory.h>\n-#include <AggregateFunctions/AggregateFunctionGroupArrayMoving.h>\n #include <AggregateFunctions/Helpers.h>\n #include <AggregateFunctions/FactoryHelpers.h>\n #include <DataTypes/DataTypeDate.h>\n-#include <DataTypes/DataTypeDateTime.h>\n #include <DataTypes/DataTypeDateTime64.h>\n+#include <DataTypes/DataTypeArray.h>\n+#include <DataTypes/DataTypesNumber.h>\n+#include <DataTypes/DataTypesDecimal.h>\n+\n+#include <IO/WriteHelpers.h>\n+#include <IO/ReadHelpers.h>\n+\n+#include <Columns/ColumnVector.h>\n+#include <Columns/ColumnArray.h>\n+\n+#include <Common/ArenaAllocator.h>\n+#include <Common/assert_cast.h>\n+\n+#include <type_traits>\n+\n+#define AGGREGATE_FUNCTION_MOVING_MAX_ARRAY_SIZE 0xFFFFFF\n \n \n namespace DB\n@@ -13,11 +28,186 @@ struct Settings;\n \n namespace ErrorCodes\n {\n+    extern const int TOO_LARGE_ARRAY_SIZE;\n     extern const int ILLEGAL_TYPE_OF_ARGUMENT;\n     extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n     extern const int BAD_ARGUMENTS;\n }\n \n+template <typename T>\n+struct MovingData\n+{\n+    /// For easy serialization.\n+    static_assert(std::has_unique_object_representations_v<T> || std::is_floating_point_v<T>);\n+\n+    using Accumulator = T;\n+\n+    /// Switch to ordinary Allocator after 4096 bytes to avoid fragmentation and trash in Arena\n+    using Allocator = MixedAlignedArenaAllocator<alignof(T), 4096>;\n+    using Array = PODArray<T, 32, Allocator>;\n+\n+    Array value;    /// Prefix sums.\n+    T sum{};\n+\n+    void NO_SANITIZE_UNDEFINED add(T val, Arena * arena)\n+    {\n+        sum += val;\n+        value.push_back(sum, arena);\n+    }\n+};\n+\n+template <typename T>\n+struct MovingSumData : public MovingData<T>\n+{\n+    static constexpr auto name = \"groupArrayMovingSum\";\n+\n+    T NO_SANITIZE_UNDEFINED get(size_t idx, UInt64 window_size) const\n+    {\n+        if (idx < window_size)\n+            return this->value[idx];\n+        else\n+            return this->value[idx] - this->value[idx - window_size];\n+    }\n+};\n+\n+template <typename T>\n+struct MovingAvgData : public MovingData<T>\n+{\n+    static constexpr auto name = \"groupArrayMovingAvg\";\n+\n+    T NO_SANITIZE_UNDEFINED get(size_t idx, UInt64 window_size) const\n+    {\n+        if (idx < window_size)\n+            return this->value[idx] / T(window_size);\n+        else\n+            return (this->value[idx] - this->value[idx - window_size]) / T(window_size);\n+    }\n+};\n+\n+\n+template <typename T, typename LimitNumElements, typename Data>\n+class MovingImpl final\n+    : public IAggregateFunctionDataHelper<Data, MovingImpl<T, LimitNumElements, Data>>\n+{\n+    static constexpr bool limit_num_elems = LimitNumElements::value;\n+    UInt64 window_size;\n+\n+public:\n+    using ResultT = typename Data::Accumulator;\n+\n+    using ColumnSource = ColumnVectorOrDecimal<T>;\n+\n+    /// Probably for overflow function in the future.\n+    using ColumnResult = ColumnVectorOrDecimal<ResultT>;\n+\n+    explicit MovingImpl(const DataTypePtr & data_type_, UInt64 window_size_ = std::numeric_limits<UInt64>::max())\n+        : IAggregateFunctionDataHelper<Data, MovingImpl<T, LimitNumElements, Data>>({data_type_}, {}, createResultType(data_type_))\n+        , window_size(window_size_) {}\n+\n+    String getName() const override { return Data::name; }\n+\n+    static DataTypePtr createResultType(const DataTypePtr & argument)\n+    {\n+        return std::make_shared<DataTypeArray>(getReturnTypeElement(argument));\n+    }\n+\n+    void NO_SANITIZE_UNDEFINED add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * arena) const override\n+    {\n+        auto value = static_cast<const ColumnSource &>(*columns[0]).getData()[row_num];\n+        this->data(place).add(static_cast<ResultT>(value), arena);\n+    }\n+\n+    void NO_SANITIZE_UNDEFINED merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena * arena) const override\n+    {\n+        auto & cur_elems = this->data(place);\n+        auto & rhs_elems = this->data(rhs);\n+\n+        size_t cur_size = cur_elems.value.size();\n+\n+        if (rhs_elems.value.size())\n+            cur_elems.value.insert(rhs_elems.value.begin(), rhs_elems.value.end(), arena);\n+\n+        for (size_t i = cur_size; i < cur_elems.value.size(); ++i)\n+        {\n+            cur_elems.value[i] += cur_elems.sum;\n+        }\n+\n+        cur_elems.sum += rhs_elems.sum;\n+    }\n+\n+    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n+    {\n+        const auto & value = this->data(place).value;\n+        size_t size = value.size();\n+        writeVarUInt(size, buf);\n+        buf.write(reinterpret_cast<const char *>(value.data()), size * sizeof(value[0]));\n+    }\n+\n+    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena * arena) const override\n+    {\n+        size_t size = 0;\n+        readVarUInt(size, buf);\n+\n+        if (unlikely(size > AGGREGATE_FUNCTION_MOVING_MAX_ARRAY_SIZE))\n+            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE,\n+                            \"Too large array size (maximum: {})\", AGGREGATE_FUNCTION_MOVING_MAX_ARRAY_SIZE);\n+\n+        if (size > 0)\n+        {\n+            auto & value = this->data(place).value;\n+            value.resize(size, arena);\n+            buf.readStrict(reinterpret_cast<char *>(value.data()), size * sizeof(value[0]));\n+            this->data(place).sum = value.back();\n+        }\n+    }\n+\n+    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n+    {\n+        const auto & data = this->data(place);\n+        size_t size = data.value.size();\n+\n+        ColumnArray & arr_to = assert_cast<ColumnArray &>(to);\n+        ColumnArray::Offsets & offsets_to = arr_to.getOffsets();\n+\n+        offsets_to.push_back(offsets_to.back() + size);\n+\n+        if (size)\n+        {\n+            typename ColumnResult::Container & data_to = assert_cast<ColumnResult &>(arr_to.getData()).getData();\n+\n+            for (size_t i = 0; i < size; ++i)\n+            {\n+                if (!limit_num_elems)\n+                {\n+                    data_to.push_back(data.get(i, size));\n+                }\n+                else\n+                {\n+                    data_to.push_back(data.get(i, window_size));\n+                }\n+            }\n+        }\n+    }\n+\n+    bool allocatesMemoryInArena() const override\n+    {\n+        return true;\n+    }\n+\n+private:\n+    static auto getReturnTypeElement(const DataTypePtr & argument)\n+    {\n+        if constexpr (!is_decimal<ResultT>)\n+            return std::make_shared<DataTypeNumber<ResultT>>();\n+        else\n+        {\n+            using Res = DataTypeDecimal<ResultT>;\n+            return std::make_shared<Res>(Res::maxPrecision(), getDecimalScale(*argument));\n+        }\n+    }\n+};\n+\n+\n namespace\n {\n \n@@ -79,7 +269,7 @@ AggregateFunctionPtr createAggregateFunctionMoving(\n         if (type != Field::Types::Int64 && type != Field::Types::UInt64)\n                throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Parameter for aggregate function {} should be positive integer\", name);\n \n-        if ((type == Field::Types::Int64 && parameters[0].get<Int64>() < 0) ||\n+        if ((type == Field::Types::Int64 && parameters[0].get<Int64>() <= 0) ||\n             (type == Field::Types::UInt64 && parameters[0].get<UInt64>() == 0))\n             throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Parameter for aggregate function {} should be positive integer\", name);\n \ndiff --git a/src/AggregateFunctions/AggregateFunctionGroupArrayMoving.h b/src/AggregateFunctions/AggregateFunctionGroupArrayMoving.h\ndeleted file mode 100644\nindex e6f79d7bca1b..000000000000\n--- a/src/AggregateFunctions/AggregateFunctionGroupArrayMoving.h\n+++ /dev/null\n@@ -1,207 +0,0 @@\n-#pragma once\n-\n-#include <IO/WriteHelpers.h>\n-#include <IO/ReadHelpers.h>\n-\n-#include <DataTypes/DataTypeArray.h>\n-#include <DataTypes/DataTypesNumber.h>\n-#include <DataTypes/DataTypesDecimal.h>\n-\n-#include <Columns/ColumnVector.h>\n-#include <Columns/ColumnArray.h>\n-\n-#include <Common/ArenaAllocator.h>\n-#include <Common/assert_cast.h>\n-\n-#include <AggregateFunctions/IAggregateFunction.h>\n-\n-#include <type_traits>\n-\n-#define AGGREGATE_FUNCTION_MOVING_MAX_ARRAY_SIZE 0xFFFFFF\n-\n-\n-namespace DB\n-{\n-struct Settings;\n-\n-namespace ErrorCodes\n-{\n-    extern const int TOO_LARGE_ARRAY_SIZE;\n-}\n-\n-template <typename T>\n-struct MovingData\n-{\n-    /// For easy serialization.\n-    static_assert(std::has_unique_object_representations_v<T> || std::is_floating_point_v<T>);\n-\n-    using Accumulator = T;\n-\n-    /// Switch to ordinary Allocator after 4096 bytes to avoid fragmentation and trash in Arena\n-    using Allocator = MixedAlignedArenaAllocator<alignof(T), 4096>;\n-    using Array = PODArray<T, 32, Allocator>;\n-\n-    Array value;    /// Prefix sums.\n-    T sum{};\n-\n-    void NO_SANITIZE_UNDEFINED add(T val, Arena * arena)\n-    {\n-        sum += val;\n-        value.push_back(sum, arena);\n-    }\n-};\n-\n-template <typename T>\n-struct MovingSumData : public MovingData<T>\n-{\n-    static constexpr auto name = \"groupArrayMovingSum\";\n-\n-    T NO_SANITIZE_UNDEFINED get(size_t idx, UInt64 window_size) const\n-    {\n-        if (idx < window_size)\n-            return this->value[idx];\n-        else\n-            return this->value[idx] - this->value[idx - window_size];\n-    }\n-};\n-\n-template <typename T>\n-struct MovingAvgData : public MovingData<T>\n-{\n-    static constexpr auto name = \"groupArrayMovingAvg\";\n-\n-    T NO_SANITIZE_UNDEFINED get(size_t idx, UInt64 window_size) const\n-    {\n-        if (idx < window_size)\n-            return this->value[idx] / T(window_size);\n-        else\n-            return (this->value[idx] - this->value[idx - window_size]) / T(window_size);\n-    }\n-};\n-\n-\n-template <typename T, typename LimitNumElements, typename Data>\n-class MovingImpl final\n-    : public IAggregateFunctionDataHelper<Data, MovingImpl<T, LimitNumElements, Data>>\n-{\n-    static constexpr bool limit_num_elems = LimitNumElements::value;\n-    UInt64 window_size;\n-\n-public:\n-    using ResultT = typename Data::Accumulator;\n-\n-    using ColumnSource = ColumnVectorOrDecimal<T>;\n-\n-    /// Probably for overflow function in the future.\n-    using ColumnResult = ColumnVectorOrDecimal<ResultT>;\n-\n-    explicit MovingImpl(const DataTypePtr & data_type_, UInt64 window_size_ = std::numeric_limits<UInt64>::max())\n-        : IAggregateFunctionDataHelper<Data, MovingImpl<T, LimitNumElements, Data>>({data_type_}, {}, createResultType(data_type_))\n-        , window_size(window_size_) {}\n-\n-    String getName() const override { return Data::name; }\n-\n-    static DataTypePtr createResultType(const DataTypePtr & argument)\n-    {\n-        return std::make_shared<DataTypeArray>(getReturnTypeElement(argument));\n-    }\n-\n-    void NO_SANITIZE_UNDEFINED add(AggregateDataPtr __restrict place, const IColumn ** columns, size_t row_num, Arena * arena) const override\n-    {\n-        auto value = static_cast<const ColumnSource &>(*columns[0]).getData()[row_num];\n-        this->data(place).add(static_cast<ResultT>(value), arena);\n-    }\n-\n-    void NO_SANITIZE_UNDEFINED merge(AggregateDataPtr __restrict place, ConstAggregateDataPtr rhs, Arena * arena) const override\n-    {\n-        auto & cur_elems = this->data(place);\n-        auto & rhs_elems = this->data(rhs);\n-\n-        size_t cur_size = cur_elems.value.size();\n-\n-        if (rhs_elems.value.size())\n-            cur_elems.value.insert(rhs_elems.value.begin(), rhs_elems.value.end(), arena);\n-\n-        for (size_t i = cur_size; i < cur_elems.value.size(); ++i)\n-        {\n-            cur_elems.value[i] += cur_elems.sum;\n-        }\n-\n-        cur_elems.sum += rhs_elems.sum;\n-    }\n-\n-    void serialize(ConstAggregateDataPtr __restrict place, WriteBuffer & buf, std::optional<size_t> /* version */) const override\n-    {\n-        const auto & value = this->data(place).value;\n-        size_t size = value.size();\n-        writeVarUInt(size, buf);\n-        buf.write(reinterpret_cast<const char *>(value.data()), size * sizeof(value[0]));\n-    }\n-\n-    void deserialize(AggregateDataPtr __restrict place, ReadBuffer & buf, std::optional<size_t> /* version */, Arena * arena) const override\n-    {\n-        size_t size = 0;\n-        readVarUInt(size, buf);\n-\n-        if (unlikely(size > AGGREGATE_FUNCTION_MOVING_MAX_ARRAY_SIZE))\n-            throw Exception(ErrorCodes::TOO_LARGE_ARRAY_SIZE,\n-                            \"Too large array size (maximum: {})\", AGGREGATE_FUNCTION_MOVING_MAX_ARRAY_SIZE);\n-\n-        if (size > 0)\n-        {\n-            auto & value = this->data(place).value;\n-            value.resize(size, arena);\n-            buf.readStrict(reinterpret_cast<char *>(value.data()), size * sizeof(value[0]));\n-            this->data(place).sum = value.back();\n-        }\n-    }\n-\n-    void insertResultInto(AggregateDataPtr __restrict place, IColumn & to, Arena *) const override\n-    {\n-        const auto & data = this->data(place);\n-        size_t size = data.value.size();\n-\n-        ColumnArray & arr_to = assert_cast<ColumnArray &>(to);\n-        ColumnArray::Offsets & offsets_to = arr_to.getOffsets();\n-\n-        offsets_to.push_back(offsets_to.back() + size);\n-\n-        if (size)\n-        {\n-            typename ColumnResult::Container & data_to = assert_cast<ColumnResult &>(arr_to.getData()).getData();\n-\n-            for (size_t i = 0; i < size; ++i)\n-            {\n-                if (!limit_num_elems)\n-                {\n-                    data_to.push_back(data.get(i, size));\n-                }\n-                else\n-                {\n-                    data_to.push_back(data.get(i, window_size));\n-                }\n-            }\n-        }\n-    }\n-\n-    bool allocatesMemoryInArena() const override\n-    {\n-        return true;\n-    }\n-\n-private:\n-    static auto getReturnTypeElement(const DataTypePtr & argument)\n-    {\n-        if constexpr (!is_decimal<ResultT>)\n-            return std::make_shared<DataTypeNumber<ResultT>>();\n-        else\n-        {\n-            using Res = DataTypeDecimal<ResultT>;\n-            return std::make_shared<Res>(Res::maxPrecision(), getDecimalScale(*argument));\n-        }\n-    }\n-};\n-\n-#undef AGGREGATE_FUNCTION_MOVING_MAX_ARRAY_SIZE\n-\n-}\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02817_group_array_moving_zero_window_size.reference b/tests/queries/0_stateless/02817_group_array_moving_zero_window_size.reference\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/queries/0_stateless/02817_group_array_moving_zero_window_size.sql b/tests/queries/0_stateless/02817_group_array_moving_zero_window_size.sql\nnew file mode 100644\nindex 000000000000..fcbcaf1245bc\n--- /dev/null\n+++ b/tests/queries/0_stateless/02817_group_array_moving_zero_window_size.sql\n@@ -0,0 +1,2 @@\n+SELECT groupArrayMovingAvg ( toInt64 ( 0 ) ) ( toDecimal32 ( 1 , 1 ) ); -- { serverError BAD_ARGUMENTS }\n+\n",
  "problem_statement": "ClickHouse Server receives SIGFPE after running a SELECT statement\n**Describe the bug**\r\nThe ClickHouse server received signal Arithmetic exception (8) due to \"Integer divide by zero\" after running a SQL statement.\r\n\r\n**How to reproduce**\r\nThe SQL statement to reproduce:\r\n```sql\r\nSELECT groupArrayMovingAvg ( toInt64 ( 0 ) ) ( toDecimal32 ( 1 , 1 ) );\r\n```\r\n\r\nIt can be reproduced on the official docker image. (`clickhouse/clickhouse-server:head` and `clickhouse/clickhouse-server:latest`).\r\n\r\nThe log:\r\n```\r\nSELECT groupArrayMovingAvg(toInt64(0))(toDecimal32(1, 1 AS is_empty))\r\nFROM numbers(300)\r\n\r\nQuery id: fae5edc7-50d4-4462-872b-9530457300ee\r\n\r\n[50992739ea1d] 2023.07.10 13:52:59.888348 [ 388 ] <Fatal> BaseDaemon: ########################################\r\n[50992739ea1d] 2023.07.10 13:52:59.888405 [ 388 ] <Fatal> BaseDaemon: (version 23.7.1.857 (official build), build id: EBF7F00D257A03E61ABF10B376C4A7BDD0EED2BA, git hash: 9aef39a7888e10995ea85faad559a110c0e22a82) (from thread 349) (query_id: fae5edc7-50d4-4462-872b-9530457300ee) (query: SELECT groupArrayMovingAvg ( toInt64 ( 0 ) ) ( toDecimal32 ( 1 , 1 AS is_empty ) ) FROM numbers ( 300 ) ;) Received signal Arithmetic exception (8)\r\n[50992739ea1d] 2023.07.10 13:52:59.888444 [ 388 ] <Fatal> BaseDaemon: Integer divide by zero.\r\n[50992739ea1d] 2023.07.10 13:52:59.888472 [ 388 ] <Fatal> BaseDaemon: Stack trace: 0x00000000081aa9af 0x0000000010a90a87 0x0000000010abee26 0x00000000131a426d 0x00000000131a3e6b 0x0000000014c5c790 0x0000000014a5d1e9 0x0000000014a53e50 0x0000000014a54fe3 0x000000000e29d8af 0x000000000e2a05fc 0x000000000e2991ef 0x000000000e29f1e1 0x00007f92b3447609 0x00007f92b336c133\r\n[50992739ea1d] 2023.07.10 13:52:59.888529 [ 388 ] <Fatal> BaseDaemon: 2. ? @ 0x00000000081aa9af in /usr/bin/clickhouse\r\n[50992739ea1d] 2023.07.10 13:52:59.888566 [ 388 ] <Fatal> BaseDaemon: 3. ? @ 0x0000000010a90a87 in /usr/bin/clickhouse\r\n[50992739ea1d] 2023.07.10 13:52:59.888592 [ 388 ] <Fatal> BaseDaemon: 4. ? @ 0x0000000010abee26 in /usr/bin/clickhouse\r\n[50992739ea1d] 2023.07.10 13:52:59.888624 [ 388 ] <Fatal> BaseDaemon: 5. ? @ 0x00000000131a426d in /usr/bin/clickhouse\r\n[50992739ea1d] 2023.07.10 13:52:59.888669 [ 388 ] <Fatal> BaseDaemon: 6. DB::Aggregator::prepareBlockAndFillWithoutKey(DB::AggregatedDataVariants&, bool, bool) const @ 0x00000000131a3e6b in /usr/bin/clickhouse\r\n[50992739ea1d] 2023.07.10 13:52:59.888701 [ 388 ] <Fatal> BaseDaemon: 7. ? @ 0x0000000014c5c790 in /usr/bin/clickhouse\r\n[50992739ea1d] 2023.07.10 13:52:59.888733 [ 388 ] <Fatal> BaseDaemon: 8. DB::ExecutionThreadContext::executeTask() @ 0x0000000014a5d1e9 in /usr/bin/clickhouse\r\n[50992739ea1d] 2023.07.10 13:52:59.888761 [ 388 ] <Fatal> BaseDaemon: 9. DB::PipelineExecutor::executeStepImpl(unsigned long, std::atomic<bool>*) @ 0x0000000014a53e50 in /usr/bin/clickhouse\r\n[50992739ea1d] 2023.07.10 13:52:59.888797 [ 388 ] <Fatal> BaseDaemon: 10. ? @ 0x0000000014a54fe3 in /usr/bin/clickhouse\r\n[50992739ea1d] 2023.07.10 13:52:59.888858 [ 388 ] <Fatal> BaseDaemon: 11. ThreadPoolImpl<ThreadFromGlobalPoolImpl<false>>::worker(std::__list_iterator<ThreadFromGlobalPoolImpl<false>, void*>) @ 0x000000000e29d8af in /usr/bin/clickhouse\r\n[50992739ea1d] 2023.07.10 13:52:59.888931 [ 388 ] <Fatal> BaseDaemon: 12. void std::__function::__policy_invoker<void ()>::__call_impl<std::__function::__default_alloc_func<ThreadFromGlobalPoolImpl<false>::ThreadFromGlobalPoolImpl<void ThreadPoolImpl<ThreadFromGlobalPoolImpl<false>>::scheduleImpl<void>(std::function<void ()>, Priority, std::optional<unsigned long>, bool)::'lambda0'()>(void&&)::'lambda'(), void ()>>(std::__function::__policy_storage const*) @ 0x000000000e2a05fc in /usr/bin/clickhouse\r\n[50992739ea1d] 2023.07.10 13:52:59.888962 [ 388 ] <Fatal> BaseDaemon: 13. ThreadPoolImpl<std::thread>::worker(std::__list_iterator<std::thread, void*>) @ 0x000000000e2991ef in /usr/bin/clickhouse\r\n[50992739ea1d] 2023.07.10 13:52:59.888991 [ 388 ] <Fatal> BaseDaemon: 14. ? @ 0x000000000e29f1e1 in /usr/bin/clickhouse\r\n[50992739ea1d] 2023.07.10 13:52:59.889042 [ 388 ] <Fatal> BaseDaemon: 15. ? @ 0x00007f92b3447609 in ?\r\n[50992739ea1d] 2023.07.10 13:52:59.889075 [ 388 ] <Fatal> BaseDaemon: 16. clone @ 0x00007f92b336c133 in ?\r\n[50992739ea1d] 2023.07.10 13:53:00.072033 [ 388 ] <Fatal> BaseDaemon: Integrity check of the executable successfully passed (checksum: C8DB2CC6CEEB111C8AB95A0F4BA5538E)\r\n[50992739ea1d] 2023.07.10 13:53:00.072250 [ 388 ] <Fatal> BaseDaemon: Report this error to https://github.com/ClickHouse/ClickHouse/issues\r\n[50992739ea1d] 2023.07.10 13:53:00.072353 [ 388 ] <Fatal> BaseDaemon: No settings were changed\r\n```\n",
  "hints_text": "Thank you! Please continue fuzzing and send us more of these!",
  "created_at": "2023-07-16T22:32:48Z",
  "modified_files": [
    "src/AggregateFunctions/AggregateFunctionGroupArrayMoving.cpp",
    "src/AggregateFunctions/AggregateFunctionGroupArrayMoving.h"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/02817_group_array_moving_zero_window_size.sql"
  ]
}