{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 36953,
  "instance_id": "ClickHouse__ClickHouse-36953",
  "issue_numbers": [
    "36714"
  ],
  "base_commit": "084dd6f3c27bead9662af4a65cdc5c513d0eb311",
  "patch": "diff --git a/src/AggregateFunctions/AggregateFunctionMannWhitney.h b/src/AggregateFunctions/AggregateFunctionMannWhitney.h\nindex 089f70cd26bf..d861eef10abf 100644\n--- a/src/AggregateFunctions/AggregateFunctionMannWhitney.h\n+++ b/src/AggregateFunctions/AggregateFunctionMannWhitney.h\n@@ -6,8 +6,10 @@\n #include <Columns/ColumnVector.h>\n #include <Columns/ColumnTuple.h>\n #include <Common/assert_cast.h>\n+#include <Common/ArenaAllocator.h>\n #include <Common/PODArray_fwd.h>\n #include <base/types.h>\n+#include <DataTypes/DataTypeArray.h>\n #include <DataTypes/DataTypesDecimal.h>\n #include <DataTypes/DataTypeNullable.h>\n #include <DataTypes/DataTypesNumber.h>\n@@ -16,10 +18,7 @@\n #include <IO/WriteHelpers.h>\n #include <limits>\n \n-#include <DataTypes/DataTypeArray.h>\n-\n-#include <Common/ArenaAllocator.h>\n-\n+#include <boost/math/distributions/normal.hpp>\n \n namespace DB\n {\n@@ -84,15 +83,14 @@ struct MannWhitneyData : public StatisticalSample<Float64, Float64>\n         if (alternative == Alternative::TwoSided)\n             z = std::abs(z);\n \n-        /// In fact cdf is a probability function, so it is intergral of density from (-inf, z].\n-        /// But since standard normal distribution is symmetric, cdf(0) = 0.5 and we have to compute integral from [0, z].\n-        const Float64 cdf = integrateSimpson(0, z, [] (Float64 t) { return std::pow(M_E, -0.5 * t * t) / std::sqrt(2 * M_PI);});\n+        auto standart_normal_distribution = boost::math::normal_distribution<Float64>();\n+        auto cdf = boost::math::cdf(standart_normal_distribution, z);\n \n         Float64 p_value = 0;\n         if (alternative == Alternative::TwoSided)\n-            p_value = 1 - 2 * cdf;\n+            p_value = 2 - 2 * cdf;\n         else\n-            p_value = 0.5 - cdf;\n+            p_value = 1 - cdf;\n \n         return {u2, p_value};\n     }\ndiff --git a/src/AggregateFunctions/AggregateFunctionStudentTTest.cpp b/src/AggregateFunctions/AggregateFunctionStudentTTest.cpp\nindex 83a91ef06fc3..f1beff806e24 100644\n--- a/src/AggregateFunctions/AggregateFunctionStudentTTest.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionStudentTTest.cpp\n@@ -62,7 +62,17 @@ struct StudentTTestData : public TTestMoments<Float64>\n         /// t-statistic\n         Float64 t_stat = (mean_x - mean_y) / sqrt(std_err2);\n \n-        return {t_stat, getPValue(degrees_of_freedom, t_stat * t_stat)};\n+        if (isNaN(t_stat))\n+            throw Exception(ErrorCodes::BAD_ARGUMENTS, \"Resulted t-statistics is NaN\");\n+\n+        auto student = boost::math::students_t_distribution<Float64>(getDegreesOfFreedom());\n+        Float64 pvalue = 0;\n+        if (t_stat > 0)\n+            pvalue = 2 * boost::math::cdf<Float64>(student, -t_stat);\n+        else\n+            pvalue = 2 * boost::math::cdf<Float64>(student, t_stat);\n+\n+        return {t_stat, pvalue};\n     }\n };\n \ndiff --git a/src/AggregateFunctions/AggregateFunctionTTest.h b/src/AggregateFunctions/AggregateFunctionTTest.h\nindex 7ef5cfce9c90..b72e7a3cdcb6 100644\n--- a/src/AggregateFunctions/AggregateFunctionTTest.h\n+++ b/src/AggregateFunctions/AggregateFunctionTTest.h\n@@ -34,50 +34,6 @@ namespace ErrorCodes\n     extern const int BAD_ARGUMENTS;\n }\n \n-/**\n- * If you have a cumulative distribution function F, then calculating the p-value for given statistic T is simply 1\u2212F(T)\n- * In our case p-value is two-sided, so we multiply it by 2.\n- * So cumulative distribution function F equals to\n- * \\[ F(t) = \\int_{-\\infty}^{t} f(u)du = 1 - \\frac{1}{2} I_{x(t)}(\\frac{v}{2}, \\frac{1}{2}) \\]\n- * where \\[ x(t) = \\frac{v}{t^2 + v} \\]: https://en.wikipedia.org/wiki/Student%27s_t-distribution#Cumulative_distribution_function\n- *\n- * so our resulting \\[ p-value = I_{x(t)}(\\frac{v}{2}, \\frac{1}{2}) \\].\n- *\n- * And I is regularized incomplete beta function: https://en.wikipedia.org/wiki/Beta_function#Incomplete_beta_function\n- *\n- * Keepenig in mind that \\[ \\mathrm {B} (x;a,b)=\\int _{0}^{x}r^{a-1}\\,(1-r)^{b-1}\\,\\mathrm {d} r.\\! \\]\n- * and\n- * \\[ \\mathrm {B} (x,y)={\\dfrac {\\Gamma (x)\\,\\Gamma (y)}{\\Gamma (x+y)}}=\\\n- * \\exp(\\ln {\\dfrac {\\Gamma (x)\\,\\Gamma (y)}{\\Gamma (x+y)}})=\\exp((\\ln(\\Gamma (x))+\\ln(\\Gamma (y))-\\ln(\\Gamma (x+y))) \\]\n- *\n- * p-value can be calculated in terms of gamma functions and integrals more simply:\n- * \\[ {\\frac {\\int _{0}^{\\frac {\\nu }{t^{2}+\\nu }}r^{{\\frac {\\nu }{2}}-1}\\,(1-r)^{-0.5}\\,\\mathrm {d} r}\\\n- * {\\exp((\\ln(\\Gamma ({\\frac {\\nu }{2}}))+\\ln(\\Gamma (0.5))-\\ln(\\Gamma ({\\frac {\\nu }{2}}+0.5)))}} \\]\n- *\n- * which simplifies to:\n- *\n- * \\[ {\\frac {\\int _{0}^{\\frac {\\nu }{t^{2}+\\nu }}{\\frac {r^{{\\frac {\\nu }{2}}-1}}{\\sqrt {1-r}}}\\,\\mathrm {d} r}\\\n- * {\\exp((\\ln(\\Gamma ({\\frac {\\nu }{2}}))+\\ln(\\Gamma (0.5))-\\ln(\\Gamma ({\\frac {\\nu }{2}}+0.5)))}} \\]\n- *\n- * Read here for details https://rosettacode.org/wiki/Welch%27s_t-test#\n- *\n- * Both WelchTTest and StudentTTest have t-statistric with Student distribution but with different degrees of freedom.\n- * So the procedure of computing p-value is the same.\n-*/\n-static inline Float64 getPValue(Float64 degrees_of_freedom, Float64 t_stat2) /// NOLINT\n-{\n-    Float64 numerator = integrateSimpson(0, degrees_of_freedom / (t_stat2 + degrees_of_freedom),\n-        [degrees_of_freedom](double x) { return std::pow(x, degrees_of_freedom / 2 - 1) / std::sqrt(1 - x); });\n-\n-    int unused;\n-    Float64 denominator = std::exp(\n-        lgamma_r(degrees_of_freedom / 2, &unused)\n-        + lgamma_r(0.5, &unused)\n-        - lgamma_r(degrees_of_freedom / 2 + 0.5, &unused));\n-\n-    return std::min(1.0, std::max(0.0, numerator / denominator));\n-}\n-\n \n /// Returns tuple of (t-statistic, p-value)\n /// https://cpb-us-w2.wpmucdn.com/voices.uchicago.edu/dist/9/1193/files/2016/01/05b-TandP.pdf\ndiff --git a/src/AggregateFunctions/AggregateFunctionWelchTTest.cpp b/src/AggregateFunctions/AggregateFunctionWelchTTest.cpp\nindex fe5cf83c5093..74000296a2dc 100644\n--- a/src/AggregateFunctions/AggregateFunctionWelchTTest.cpp\n+++ b/src/AggregateFunctions/AggregateFunctionWelchTTest.cpp\n@@ -10,7 +10,6 @@ namespace ErrorCodes\n     extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;\n }\n \n-\n namespace DB\n {\n struct Settings;\n@@ -53,7 +52,14 @@ struct WelchTTestData : public TTestMoments<Float64>\n         Float64 se = getStandardError();\n         Float64 t_stat = (mean_x - mean_y) / se;\n \n-        return {t_stat, getPValue(getDegreesOfFreedom(), t_stat * t_stat)};\n+        auto students_t_distribution = boost::math::students_t_distribution<Float64>(getDegreesOfFreedom());\n+        Float64 pvalue = 0;\n+        if (t_stat > 0)\n+            pvalue = 2 * boost::math::cdf<Float64>(students_t_distribution, -t_stat);\n+        else\n+            pvalue = 2 * boost::math::cdf<Float64>(students_t_distribution, t_stat);\n+\n+        return {t_stat, pvalue};\n     }\n };\n \ndiff --git a/src/AggregateFunctions/StatCommon.h b/src/AggregateFunctions/StatCommon.h\nindex d670e646f4bd..29163b63f778 100644\n--- a/src/AggregateFunctions/StatCommon.h\n+++ b/src/AggregateFunctions/StatCommon.h\n@@ -21,20 +21,6 @@ namespace ErrorCodes\n     extern const int BAD_ARGUMENTS;\n }\n \n-template <typename F>\n-static Float64 integrateSimpson(Float64 a, Float64 b, F && func)\n-{\n-    const size_t iterations = std::max(1e6, 1e4 * std::abs(std::round(b) - std::round(a)));\n-    const long double h = (b - a) / iterations;\n-    Float64 sum_odds = 0.0;\n-    for (size_t i = 1; i < iterations; i += 2)\n-        sum_odds += func(a + i * h);\n-    Float64 sum_evens = 0.0;\n-    for (size_t i = 2; i < iterations; i += 2)\n-        sum_evens += func(a + i * h);\n-    return (func(a) + func(b) + 2 * sum_evens + 4 * sum_odds) * h / 3;\n-}\n-\n /// Because ranks are adjusted, we have to store each of them in Float type.\n using RanksArray = std::vector<Float64>;\n \n@@ -126,4 +112,3 @@ struct StatisticalSample\n };\n \n }\n-\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01560_mann_whitney.reference b/tests/queries/0_stateless/01560_mann_whitney.reference\nindex 5a718fdca977..dcd1882b0964 100644\n--- a/tests/queries/0_stateless/01560_mann_whitney.reference\n+++ b/tests/queries/0_stateless/01560_mann_whitney.reference\n@@ -1,5 +1,5 @@\n-(223,0.5426959774289524)\n+(223,0.5426959774289482)\n 223.0\t0.5426959774289482\n-223\t0.5426959774289524\n-223\t0.5426959774289524\n-223\t0.5426959774289524\n+223\t0.5426959774289482\n+223\t0.5426959774289482\n+223\t0.5426959774289482\ndiff --git a/tests/queries/0_stateless/02293_ttest_large_samples.reference b/tests/queries/0_stateless/02293_ttest_large_samples.reference\nnew file mode 100644\nindex 000000000000..2e90a4a98b23\n--- /dev/null\n+++ b/tests/queries/0_stateless/02293_ttest_large_samples.reference\n@@ -0,0 +1,2 @@\n+-0.12709\t0.89887\n+-1.27088\t0.20377\ndiff --git a/tests/queries/0_stateless/02293_ttest_large_samples.sql b/tests/queries/0_stateless/02293_ttest_large_samples.sql\nnew file mode 100644\nindex 000000000000..d4d919d6e7ce\n--- /dev/null\n+++ b/tests/queries/0_stateless/02293_ttest_large_samples.sql\n@@ -0,0 +1,53 @@\n+SELECT roundBankers(result.1, 5), roundBankers(result.2, 5) FROM (\n+SELECT\n+     studentTTest(sample, variant) as result\n+FROM (\n+SELECT\n+    toFloat64(number) % 30 AS sample,\n+    0 AS variant\n+FROM system.numbers limit 500000\n+\n+UNION ALL\n+\n+SELECT\n+    toFloat64(number) % 30 + 0.0022 AS sample,\n+    1 AS variant\n+FROM system.numbers limit 500000));\n+\n+\n+SELECT roundBankers(result.1, 5), roundBankers(result.2, 5 ) FROM (\n+SELECT\n+     studentTTest(sample, variant) as result\n+FROM (\n+SELECT\n+    toFloat64(number) % 30 AS sample,\n+    0 AS variant\n+FROM system.numbers limit 50000000\n+\n+UNION ALL\n+\n+SELECT\n+    toFloat64(number) % 30 + 0.0022 AS sample,\n+    1 AS variant\n+FROM system.numbers limit 50000000));\n+\n+\n+SELECT roundBankers(result.2, 1025)\n+FROM\n+(\n+    SELECT studentTTest(sample, variant) AS result\n+    FROM\n+    (\n+        SELECT\n+            toFloat64(number) % 30 AS sample,\n+            1048576 AS variant\n+        FROM system.numbers\n+        LIMIT 1\n+        UNION ALL\n+        SELECT\n+            (toFloat64(number) % 7) + inf AS sample,\n+            255 AS variant\n+        FROM system.numbers\n+        LIMIT 1023\n+    )\n+); -- { serverError 36 }\n",
  "problem_statement": "Incorrect pvalue in studentTTest\n**Describe what's wrong**\r\n\r\nWhen using the studentTTest or welchTTest function these sometimes return the pvalue \"1\" while this result is wrong. I can't see a very specific pattern to it, but it might be related to high numbers of input rows as these are the only examples I can produce. Here two examples:\r\n\r\n```\r\nSELECT\r\n     studentTTest(sample, variant)\r\nFROM (\r\nSELECT\r\n    toFloat64(number) % 30 AS sample,\r\n    0 AS variant\r\nFROM system.numbers limit 500000\r\n\r\nUNION ALL\r\n\r\nSELECT\r\n    toFloat64(number) % 30 + 0.0022 AS sample,\r\n    1 AS variant\r\nFROM system.numbers limit 500000\r\n)\r\n```\r\nOut put in the above is `(-0.12708812085024285,1)`. The t-statsitic value (-0.12..) appears correct to me. However the pvalue based on this t-statistic should be about 0.9. A more extreme example can be created by keeping the same example but increasing the number of rows (however, this scale of input rows is still very common in our use-case):\r\n\r\n```\r\nSELECT\r\n     studentTTest(sample, variant)\r\nFROM (\r\nSELECT\r\n    toFloat64(number) % 30 AS sample,\r\n    0 AS variant\r\nFROM system.numbers limit 50000000\r\n\r\nUNION ALL\r\n\r\nSELECT\r\n    toFloat64(number) % 30 + 0.0022 AS sample,\r\n    1 AS variant\r\nFROM system.numbers limit 50000000\r\n)\r\n```\r\n\r\nOutput is `(-1.2708804531666449,1)`. Again the t-statistic looks correct to me, while the pvalue should be about 0.2. \r\n\r\nHaving the option to do a ttest directly in clickhouse is awesome and it would be great if this is being tackled, as it keeps us from utilizing it.\r\n\r\nMy clickhouse version: 22.3.3.44. \r\nI don't have the setup to check it for the more recent versions unfortunately.\r\n\r\nThank you!\n",
  "hints_text": "@wol-e Thank you! The problem is that for generating p-value we have to integrate a function and we use Simpson's method with 1e6 iterations https://github.com/ClickHouse/ClickHouse/blob/8567fea0166b78b475b6b4a45e1a743d7e2c7d48/src/AggregateFunctions/StatCommon.h#L24-L36\r\n\r\nChanging iterations to 1e8 saves the situation (and queries above works as expected) but it affects performance. Maybe you know some fast method to calculate an integral of a function? I will be much appreciated! \r\n\r\nQueries with 1e8 iterations: \r\n\r\n```sql\r\nSELECT studentTTest(sample, variant)\r\nFROM\r\n(\r\n    SELECT\r\n        toFloat64(number) % 30 AS sample,\r\n        0 AS variant\r\n    FROM system.numbers\r\n    LIMIT 500000\r\n    UNION ALL\r\n    SELECT\r\n        (toFloat64(number) % 30) + 0.0022 AS sample,\r\n        1 AS variant\r\n    FROM system.numbers\r\n    LIMIT 500000\r\n)\r\n\r\nQuery id: b1c20aed-34b5-4a4f-9380-9755b315c631\r\n\r\n\u250c\u2500studentTTest(sample, variant)\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 (-0.1270881208646145,0.8989211063140815) \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n1 rows in set. Elapsed: 2.034 sec. Processed 1.05 million rows, 8.38 MB (515.33 thousand rows/s., 4.12 MB/s.)\r\n\r\n\r\nSELECT studentTTest(sample, variant)\r\nFROM\r\n(\r\n    SELECT\r\n        toFloat64(number) % 30 AS sample,\r\n        0 AS variant\r\n    FROM system.numbers\r\n    LIMIT 50000000\r\n    UNION ALL\r\n    SELECT\r\n        (toFloat64(number) % 30) + 0.0022 AS sample,\r\n        1 AS variant\r\n    FROM system.numbers\r\n    LIMIT 50000000\r\n)\r\n\r\nQuery id: 9fe2373a-922a-4ead-9777-4cbbfb0e959e\r\n\r\n\u250c\u2500studentTTest(sample, variant)\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 (-1.2708803762020429,0.20441982326310723) \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\n1 rows in set. Elapsed: 3.698 sec. Processed 100.09 million rows, 800.73 MB (27.07 million rows/s., 216.55 MB/s.)\r\n\r\n```\r\n\r\n2 and 3 seconds is too slow. Slower than python \ud83d\ude25\r\n\r\n```python\r\n$ python3 test_bug_ttest.py\r\nequal_var=True Ttest_indResult(statistic=-0.12708812152566754, pvalue=0.8988706784292392)\r\nequal_val=False Ttest_indResult(statistic=-0.12708812152566754, pvalue=0.8988706784292391)\r\nubuntu@ip-10-1-13-116:~/ClickHouse/ClickHouse/tests/queries/0_stateless$ cat test_bug_ttest.py\r\nfrom scipy import stats\r\n\r\nrvs1 = [number % 30 for number in range(500000)]\r\nrvs2 = [number % 30 + 0.0022 for number in range(500000)]\r\n\r\nprint(\"equal_var=True\", stats.ttest_ind(rvs1, rvs2, equal_var = True))\r\nprint(\"equal_val=False\", stats.ttest_ind(rvs1, rvs2, equal_var = False))\r\n\r\n$ time python3 test_bug_ttest.py\r\nequal_var=True Ttest_indResult(statistic=-0.12708812152566754, pvalue=0.8988706784292392)\r\nequal_val=False Ttest_indResult(statistic=-0.12708812152566754, pvalue=0.8988706784292391)\r\n\r\nreal    0m0.795s\r\nuser    0m3.182s\r\nsys     0m2.777s\r\nubuntu@ip-10-1-13-116:~/ClickHouse/ClickHouse/tests/queries/0_stateless$\r\n\r\n```\nBut we can have the analytical solution and just calculate this at some point. Will do this! \n@nikitamikhaylov thank you for looking into this! I don't know much about solving integrals numericaly, sorry. Given that the calculation of the t-statistic looks correct, maybe there is a simpler way to get the p-value based on the t-statistic. Essentially you would need to get the percentile of the corresponding t-distribution for that t value to calculate the p-value. But I don't know how that compares to what you currently do, or if you would still need to calculate integrals for approximating that. If you have an approximation of cumulative distribution function of the t distribution at hand you could do without integrals I think.",
  "created_at": "2022-05-05T21:44:09Z",
  "modified_files": [
    "src/AggregateFunctions/AggregateFunctionMannWhitney.h",
    "src/AggregateFunctions/AggregateFunctionStudentTTest.cpp",
    "src/AggregateFunctions/AggregateFunctionTTest.h",
    "src/AggregateFunctions/AggregateFunctionWelchTTest.cpp",
    "src/AggregateFunctions/StatCommon.h"
  ],
  "modified_test_files": [
    "tests/queries/0_stateless/01560_mann_whitney.reference",
    "b/tests/queries/0_stateless/02293_ttest_large_samples.reference",
    "b/tests/queries/0_stateless/02293_ttest_large_samples.sql"
  ]
}