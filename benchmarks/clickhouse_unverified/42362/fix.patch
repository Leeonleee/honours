diff --git a/src/Client/LocalConnection.cpp b/src/Client/LocalConnection.cpp
index 7ac68324915f..476386889d23 100644
--- a/src/Client/LocalConnection.cpp
+++ b/src/Client/LocalConnection.cpp
@@ -6,8 +6,6 @@
 #include <Processors/Executors/PushingAsyncPipelineExecutor.h>
 #include <Storages/IStorage.h>
 #include <Core/Protocol.h>
-#include <DataTypes/DataTypesNumber.h>
-#include <DataTypes/DataTypeString.h>
 
 
 namespace DB
diff --git a/src/Common/OvercommitTracker.cpp b/src/Common/OvercommitTracker.cpp
index c7730667f55f..bb477d6019db 100644
--- a/src/Common/OvercommitTracker.cpp
+++ b/src/Common/OvercommitTracker.cpp
@@ -5,6 +5,7 @@
 #include <Common/ProfileEvents.h>
 #include <Interpreters/ProcessList.h>
 
+
 namespace ProfileEvents
 {
     extern const Event MemoryOvercommitWaitTimeMicroseconds;
@@ -170,7 +171,8 @@ void UserOvercommitTracker::pickQueryToExcludeImpl()
 
 GlobalOvercommitTracker::GlobalOvercommitTracker(DB::ProcessList * process_list_)
     : OvercommitTracker(process_list_)
-{}
+{
+}
 
 void GlobalOvercommitTracker::pickQueryToExcludeImpl()
 {
@@ -180,16 +182,16 @@ void GlobalOvercommitTracker::pickQueryToExcludeImpl()
     // This is guaranteed by locking global_mutex in OvercommitTracker::needToStopQuery.
     for (auto const & query : process_list->processes)
     {
-        if (query.isKilled())
+        if (query->isKilled())
             continue;
 
         Int64 user_soft_limit = 0;
-        if (auto const * user_process_list = query.getUserProcessList())
+        if (auto const * user_process_list = query->getUserProcessList())
             user_soft_limit = user_process_list->user_memory_tracker.getSoftLimit();
         if (user_soft_limit == 0)
             continue;
 
-        auto * memory_tracker = query.getMemoryTracker();
+        auto * memory_tracker = query->getMemoryTracker();
         if (!memory_tracker)
             continue;
         auto ratio = memory_tracker->getOvercommitRatio(user_soft_limit);
diff --git a/src/Formats/FormatFactory.cpp b/src/Formats/FormatFactory.cpp
index bfe651dd1af8..a882fcf50096 100644
--- a/src/Formats/FormatFactory.cpp
+++ b/src/Formats/FormatFactory.cpp
@@ -303,7 +303,7 @@ InputFormatPtr FormatFactory::getInputFormat(
 
 static void addExistingProgressToOutputFormat(OutputFormatPtr format, ContextPtr context)
 {
-    auto * element_id = context->getProcessListElement();
+    auto element_id = context->getProcessListElement();
     if (element_id)
     {
         /// While preparing the query there might have been progress (for example in subscalar subqueries) so add it here
diff --git a/src/Interpreters/ClusterProxy/executeQuery.cpp b/src/Interpreters/ClusterProxy/executeQuery.cpp
index 923b4a767b7b..3c294dd78858 100644
--- a/src/Interpreters/ClusterProxy/executeQuery.cpp
+++ b/src/Interpreters/ClusterProxy/executeQuery.cpp
@@ -141,7 +141,7 @@ void executeQuery(
     new_context->getClientInfo().distributed_depth += 1;
 
     ThrottlerPtr user_level_throttler;
-    if (auto * process_list_element = context->getProcessListElement())
+    if (auto process_list_element = context->getProcessListElement())
         user_level_throttler = process_list_element->getUserNetworkThrottler();
 
     /// Network bandwidth limit, if needed.
@@ -243,7 +243,7 @@ void executeQueryWithParallelReplicas(
     const Settings & settings = context->getSettingsRef();
 
     ThrottlerPtr user_level_throttler;
-    if (auto * process_list_element = context->getProcessListElement())
+    if (auto process_list_element = context->getProcessListElement())
         user_level_throttler = process_list_element->getUserNetworkThrottler();
 
     /// Network bandwidth limit, if needed.
diff --git a/src/Interpreters/Context.cpp b/src/Interpreters/Context.cpp
index 1de56e950c69..721d701c9a22 100644
--- a/src/Interpreters/Context.cpp
+++ b/src/Interpreters/Context.cpp
@@ -1463,10 +1463,8 @@ void Context::setCurrentQueryId(const String & query_id)
 
 void Context::killCurrentQuery()
 {
-    if (process_list_elem)
-    {
-        process_list_elem->cancelQuery(true);
-    }
+    if (auto elem = process_list_elem.lock())
+        elem->cancelQuery(true);
 }
 
 String Context::getDefaultFormat() const
@@ -1707,15 +1705,15 @@ ProgressCallback Context::getProgressCallback() const
 }
 
 
-void Context::setProcessListElement(ProcessList::Element * elem)
+void Context::setProcessListElement(QueryStatusPtr elem)
 {
     /// Set to a session or query. In the session, only one query is processed at a time. Therefore, the lock is not needed.
     process_list_elem = elem;
 }
 
-ProcessList::Element * Context::getProcessListElement() const
+QueryStatusPtr Context::getProcessListElement() const
 {
-    return process_list_elem;
+    return process_list_elem.lock();
 }
 
 
diff --git a/src/Interpreters/Context.h b/src/Interpreters/Context.h
index 233f4011ce3b..eeb9e8da1483 100644
--- a/src/Interpreters/Context.h
+++ b/src/Interpreters/Context.h
@@ -68,6 +68,7 @@ class MMappedFileCache;
 class UncompressedCache;
 class ProcessList;
 class QueryStatus;
+using QueryStatusPtr = std::shared_ptr<QueryStatus>;
 class Macros;
 struct Progress;
 struct FileProgress;
@@ -230,7 +231,7 @@ class Context: public std::enable_shared_from_this<Context>
     using FileProgressCallback = std::function<void(const FileProgress & progress)>;
     FileProgressCallback file_progress_callback; /// Callback for tracking progress of file loading.
 
-    QueryStatus * process_list_elem = nullptr;  /// For tracking total resource usage for query.
+    std::weak_ptr<QueryStatus> process_list_elem;  /// For tracking total resource usage for query.
     StorageID insertion_table = StorageID::createEmpty();  /// Saved insertion table in query context
     bool is_distributed = false;  /// Whether the current context it used for distributed query
 
@@ -750,9 +751,9 @@ class Context: public std::enable_shared_from_this<Context>
     /** Set in executeQuery and InterpreterSelectQuery. Then it is used in QueryPipeline,
       *  to update and monitor information about the total number of resources spent for the query.
       */
-    void setProcessListElement(QueryStatus * elem);
+    void setProcessListElement(QueryStatusPtr elem);
     /// Can return nullptr if the query was not inserted into the ProcessList.
-    QueryStatus * getProcessListElement() const;
+    QueryStatusPtr getProcessListElement() const;
 
     /// List all queries.
     ProcessList & getProcessList();
diff --git a/src/Interpreters/ProcessList.cpp b/src/Interpreters/ProcessList.cpp
index d5194a025136..3c1ebe21c48d 100644
--- a/src/Interpreters/ProcessList.cpp
+++ b/src/Interpreters/ProcessList.cpp
@@ -243,15 +243,15 @@ ProcessList::EntryPtr ProcessList::insert(const String & query_, const IAST * as
         }
 
         auto process_it = processes.emplace(processes.end(),
-            query_context, query_, client_info, priorities.insert(settings.priority), std::move(thread_group), query_kind);
+            std::make_shared<QueryStatus>(query_context, query_, client_info, priorities.insert(settings.priority), std::move(thread_group), query_kind));
 
         increaseQueryKindAmount(query_kind);
 
         res = std::make_shared<Entry>(*this, process_it);
 
-        process_it->setUserProcessList(&user_process_list);
+        (*process_it)->setUserProcessList(&user_process_list);
 
-        user_process_list.queries.emplace(client_info.current_query_id, &res->get());
+        user_process_list.queries.emplace(client_info.current_query_id, res->getQueryStatus());
 
         /// Track memory usage for all simultaneously running queries from single user.
         user_process_list.user_memory_tracker.setOrRaiseHardLimit(settings.max_memory_usage_for_user);
@@ -280,11 +280,11 @@ ProcessListEntry::~ProcessListEntry()
 {
     auto lock = parent.safeLock();
 
-    String user = it->getClientInfo().current_user;
-    String query_id = it->getClientInfo().current_query_id;
-    IAST::QueryKind query_kind = it->query_kind;
+    String user = (*it)->getClientInfo().current_user;
+    String query_id = (*it)->getClientInfo().current_query_id;
+    IAST::QueryKind query_kind = (*it)->query_kind;
 
-    const QueryStatus * process_list_element_ptr = &*it;
+    const QueryStatusPtr process_list_element_ptr = *it;
 
     auto user_process_list_it = parent.user_to_queries.find(user);
     if (user_process_list_it == parent.user_to_queries.end())
@@ -307,7 +307,7 @@ ProcessListEntry::~ProcessListEntry()
     }
 
     /// Wait for the query if it is in the cancellation right now.
-    parent.cancelled_cv.wait(lock.lock, [&]() { return it->is_cancelling == false; });
+    parent.cancelled_cv.wait(lock.lock, [&]() { return process_list_element_ptr->is_cancelling == false; });
 
     /// This removes the memory_tracker of one request.
     parent.processes.erase(it);
@@ -344,6 +344,7 @@ QueryStatus::QueryStatus(
     , client_info(client_info_)
     , thread_group(std::move(thread_group_))
     , priority_handle(std::move(priority_handle_))
+    , global_overcommit_tracker(context_->getGlobalOvercommitTracker())
     , query_kind(query_kind_)
     , num_queries_increment(CurrentMetrics::Query)
 {
@@ -360,8 +361,8 @@ QueryStatus::~QueryStatus()
     {
         if (user_process_list)
             user_process_list->user_overcommit_tracker.onQueryStop(memory_tracker);
-        if (auto shared_context = getContext())
-            shared_context->getGlobalOvercommitTracker()->onQueryStop(memory_tracker);
+        if (global_overcommit_tracker)
+            global_overcommit_tracker->onQueryStop(memory_tracker);
     }
 }
 
@@ -430,7 +431,7 @@ ThrottlerPtr QueryStatus::getUserNetworkThrottler()
 }
 
 
-QueryStatus * ProcessList::tryGetProcessListElement(const String & current_query_id, const String & current_user)
+QueryStatusPtr ProcessList::tryGetProcessListElement(const String & current_query_id, const String & current_user)
 {
     auto user_it = user_to_queries.find(current_user);
     if (user_it != user_to_queries.end())
@@ -442,13 +443,13 @@ QueryStatus * ProcessList::tryGetProcessListElement(const String & current_query
             return query_it->second;
     }
 
-    return nullptr;
+    return {};
 }
 
 
 CancellationCode ProcessList::sendCancelToQuery(const String & current_query_id, const String & current_user, bool kill)
 {
-    QueryStatus * elem;
+    QueryStatusPtr elem;
 
     /// Cancelling the query should be done without the lock.
     ///
@@ -484,7 +485,7 @@ CancellationCode ProcessList::sendCancelToQuery(const String & current_query_id,
 
 void ProcessList::killAllQueries()
 {
-    std::vector<QueryStatus *> cancelled_processes;
+    std::vector<QueryStatusPtr> cancelled_processes;
 
     SCOPE_EXIT({
         auto lock = safeLock();
@@ -498,8 +499,8 @@ void ProcessList::killAllQueries()
         cancelled_processes.reserve(processes.size());
         for (auto & process : processes)
         {
-            cancelled_processes.push_back(&process);
-            process.is_cancelling = true;
+            cancelled_processes.push_back(process);
+            process->is_cancelling = true;
         }
     }
 
@@ -558,7 +559,7 @@ ProcessList::Info ProcessList::getInfo(bool get_thread_list, bool get_profile_ev
 
     per_query_infos.reserve(processes.size());
     for (const auto & process : processes)
-        per_query_infos.emplace_back(process.getInfo(get_thread_list, get_profile_events, get_settings));
+        per_query_infos.emplace_back(process->getInfo(get_thread_list, get_profile_events, get_settings));
 
     return per_query_infos;
 }
diff --git a/src/Interpreters/ProcessList.h b/src/Interpreters/ProcessList.h
index 6943c7cfcd8a..5fbdce358f96 100644
--- a/src/Interpreters/ProcessList.h
+++ b/src/Interpreters/ProcessList.h
@@ -133,6 +133,8 @@ class QueryStatus : public WithContext
 
     ProcessListForUser * user_process_list = nullptr;
 
+    OvercommitTracker * global_overcommit_tracker = nullptr;
+
     IAST::QueryKind query_kind;
 
     /// This field is unused in this class, but it
@@ -221,6 +223,8 @@ class QueryStatus : public WithContext
     [[nodiscard]] bool checkTimeLimitSoft();
 };
 
+using QueryStatusPtr = std::shared_ptr<QueryStatus>;
+
 
 /// Information of process list for user.
 struct ProcessListForUserInfo
@@ -241,7 +245,7 @@ struct ProcessListForUser
     ProcessListForUser(ContextPtr global_context, ProcessList * global_process_list);
 
     /// query_id -> ProcessListElement(s). There can be multiple queries with the same query_id as long as all queries except one are cancelled.
-    using QueryToElement = std::unordered_map<String, QueryStatus *>;
+    using QueryToElement = std::unordered_map<String, QueryStatusPtr>;
     QueryToElement queries;
 
     ProfileEvents::Counters user_performance_counters{VariableContext::User, &ProfileEvents::global_counters};
@@ -278,7 +282,7 @@ class ProcessList;
 class ProcessListEntry
 {
 private:
-    using Container = std::list<QueryStatus>;
+    using Container = std::list<QueryStatusPtr>;
 
     ProcessList & parent;
     Container::iterator it;
@@ -289,11 +293,8 @@ class ProcessListEntry
 
     ~ProcessListEntry();
 
-    QueryStatus * operator->() { return &*it; }
-    const QueryStatus * operator->() const { return &*it; }
-
-    QueryStatus & get() { return *it; }
-    const QueryStatus & get() const { return *it; }
+    QueryStatusPtr getQueryStatus() { return *it; }
+    const QueryStatusPtr getQueryStatus() const { return *it; }
 };
 
 
@@ -319,7 +320,7 @@ class ProcessListBase
 class ProcessList : public ProcessListBase
 {
 public:
-    using Element = QueryStatus;
+    using Element = QueryStatusPtr;
     using Entry = ProcessListEntry;
     using QueryAmount = UInt64;
 
@@ -358,7 +359,7 @@ class ProcessList : public ProcessListBase
     ThrottlerPtr total_network_throttler;
 
     /// Call under lock. Finds process with specified current_user and current_query_id.
-    QueryStatus * tryGetProcessListElement(const String & current_query_id, const String & current_user);
+    QueryStatusPtr tryGetProcessListElement(const String & current_query_id, const String & current_user);
 
     /// limit for insert. 0 means no limit. Otherwise, when limit exceeded, an exception is thrown.
     size_t max_insert_queries_amount = 0;
diff --git a/src/Interpreters/executeQuery.cpp b/src/Interpreters/executeQuery.cpp
index abca563de55f..86cf3401f039 100644
--- a/src/Interpreters/executeQuery.cpp
+++ b/src/Interpreters/executeQuery.cpp
@@ -537,7 +537,7 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(
         {
             /// processlist also has query masked now, to avoid secrets leaks though SHOW PROCESSLIST by other users.
             process_list_entry = context->getProcessList().insert(query_for_logging, ast.get(), context);
-            context->setProcessListElement(&process_list_entry->get());
+            context->setProcessListElement(process_list_entry->getQueryStatus());
         }
 
         /// Load external tables if they were provided
@@ -713,9 +713,9 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(
         if (process_list_entry)
         {
             /// Query was killed before execution
-            if ((*process_list_entry)->isKilled())
-                throw Exception("Query '" + (*process_list_entry)->getInfo().client_info.current_query_id + "' is killed in pending state",
-                    ErrorCodes::QUERY_WAS_CANCELLED);
+            if (process_list_entry->getQueryStatus()->isKilled())
+                throw Exception(ErrorCodes::QUERY_WAS_CANCELLED,
+                    "Query '{}' is killed in pending state", process_list_entry->getQueryStatus()->getInfo().client_info.current_query_id);
         }
 
         /// Hold element of process list till end of query execution.
@@ -859,7 +859,7 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(
                                     pulling_pipeline = pipeline.pulling(),
                                     query_span](QueryPipeline & query_pipeline) mutable
             {
-                QueryStatus * process_list_elem = context->getProcessListElement();
+                QueryStatusPtr process_list_elem = context->getProcessListElement();
 
                 if (process_list_elem)
                 {
@@ -1025,7 +1025,7 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(
                 elem.exception_code = getCurrentExceptionCode();
                 elem.exception = getCurrentExceptionMessage(false);
 
-                QueryStatus * process_list_elem = context->getProcessListElement();
+                QueryStatusPtr process_list_elem = context->getProcessListElement();
                 const Settings & current_settings = context->getSettingsRef();
 
                 /// Update performance counters before logging to query_log
diff --git a/src/Processors/Executors/CompletedPipelineExecutor.cpp b/src/Processors/Executors/CompletedPipelineExecutor.cpp
index 9e5ea3916bce..a4c7fe2f6874 100644
--- a/src/Processors/Executors/CompletedPipelineExecutor.cpp
+++ b/src/Processors/Executors/CompletedPipelineExecutor.cpp
@@ -72,9 +72,9 @@ void CompletedPipelineExecutor::execute()
         data->executor = std::make_shared<PipelineExecutor>(pipeline.processors, pipeline.process_list_element);
         data->executor->setReadProgressCallback(pipeline.getReadProgressCallback());
 
-        /// Avoid passing this to labmda, copy ptr to data instead.
+        /// Avoid passing this to lambda, copy ptr to data instead.
         /// Destructor of unique_ptr copy raw ptr into local variable first, only then calls object destructor.
-        auto func = [data_ptr = data.get(), num_threads = pipeline.getNumThreads(), thread_group = CurrentThread::getGroup()]()
+        auto func = [data_ptr = data.get(), num_threads = pipeline.getNumThreads(), thread_group = CurrentThread::getGroup()]
         {
             threadFunction(*data_ptr, thread_group, num_threads);
         };
diff --git a/src/Processors/Executors/CompletedPipelineExecutor.h b/src/Processors/Executors/CompletedPipelineExecutor.h
index e616cd6a2b71..65fab6035b14 100644
--- a/src/Processors/Executors/CompletedPipelineExecutor.h
+++ b/src/Processors/Executors/CompletedPipelineExecutor.h
@@ -1,7 +1,9 @@
 #pragma once
+
 #include <functional>
 #include <memory>
 
+
 namespace DB
 {
 
diff --git a/src/Processors/Executors/ExecutingGraph.cpp b/src/Processors/Executors/ExecutingGraph.cpp
index 651ede10cfdb..9d69abc5e87c 100644
--- a/src/Processors/Executors/ExecutingGraph.cpp
+++ b/src/Processors/Executors/ExecutingGraph.cpp
@@ -10,17 +10,17 @@ namespace ErrorCodes
     extern const int LOGICAL_ERROR;
 }
 
-ExecutingGraph::ExecutingGraph(Processors & processors_, bool profile_processors_)
-    : processors(processors_)
+ExecutingGraph::ExecutingGraph(std::shared_ptr<Processors> processors_, bool profile_processors_)
+    : processors(std::move(processors_))
     , profile_processors(profile_processors_)
 {
-    uint64_t num_processors = processors.size();
+    uint64_t num_processors = processors->size();
     nodes.reserve(num_processors);
 
     /// Create nodes.
     for (uint64_t node = 0; node < num_processors; ++node)
     {
-        IProcessor * proc = processors[node].get();
+        IProcessor * proc = processors->at(node).get();
         processors_map[proc] = node;
         nodes.emplace_back(std::make_unique<Node>(proc, node));
     }
@@ -109,10 +109,10 @@ bool ExecutingGraph::expandPipeline(std::stack<uint64_t> & stack, uint64_t pid)
 
     {
         std::lock_guard guard(processors_mutex);
-        processors.insert(processors.end(), new_processors.begin(), new_processors.end());
+        processors->insert(processors->end(), new_processors.begin(), new_processors.end());
     }
 
-    uint64_t num_processors = processors.size();
+    uint64_t num_processors = processors->size();
     std::vector<uint64_t> back_edges_sizes(num_processors, 0);
     std::vector<uint64_t> direct_edge_sizes(num_processors, 0);
 
@@ -126,7 +126,7 @@ bool ExecutingGraph::expandPipeline(std::stack<uint64_t> & stack, uint64_t pid)
 
     while (nodes.size() < num_processors)
     {
-        auto * processor = processors[nodes.size()].get();
+        auto * processor = processors->at(nodes.size()).get();
         if (processors_map.contains(processor))
             throw Exception(ErrorCodes::LOGICAL_ERROR, "Processor {} was already added to pipeline", processor->getName());
 
@@ -386,7 +386,7 @@ bool ExecutingGraph::updateNode(uint64_t pid, Queue & queue, Queue & async_queue
 void ExecutingGraph::cancel()
 {
     std::lock_guard guard(processors_mutex);
-    for (auto & processor : processors)
+    for (auto & processor : *processors)
         processor->cancel();
 }
 
diff --git a/src/Processors/Executors/ExecutingGraph.h b/src/Processors/Executors/ExecutingGraph.h
index 587a2561ae02..b374f9681225 100644
--- a/src/Processors/Executors/ExecutingGraph.h
+++ b/src/Processors/Executors/ExecutingGraph.h
@@ -1,4 +1,5 @@
 #pragma once
+
 #include <Processors/Port.h>
 #include <Processors/IProcessor.h>
 #include <Processors/Executors/UpgradableLock.h>
@@ -6,6 +7,7 @@
 #include <queue>
 #include <stack>
 
+
 namespace DB
 {
 
@@ -123,9 +125,9 @@ class ExecutingGraph
     using ProcessorsMap = std::unordered_map<const IProcessor *, uint64_t>;
     ProcessorsMap processors_map;
 
-    explicit ExecutingGraph(Processors & processors_, bool profile_processors_);
+    explicit ExecutingGraph(std::shared_ptr<Processors> processors_, bool profile_processors_);
 
-    const Processors & getProcessors() const { return processors; }
+    const Processors & getProcessors() const { return *processors; }
 
     /// Traverse graph the first time to update all the childless nodes.
     void initializeExecution(Queue & queue);
@@ -149,7 +151,7 @@ class ExecutingGraph
     /// All new nodes and nodes with updated ports are pushed into stack.
     bool expandPipeline(std::stack<uint64_t> & stack, uint64_t pid);
 
-    Processors & processors;
+    std::shared_ptr<Processors> processors;
     std::mutex processors_mutex;
 
     UpgradableMutex nodes_mutex;
diff --git a/src/Processors/Executors/PipelineExecutor.cpp b/src/Processors/Executors/PipelineExecutor.cpp
index ae20d97604bf..3772381de042 100644
--- a/src/Processors/Executors/PipelineExecutor.cpp
+++ b/src/Processors/Executors/PipelineExecutor.cpp
@@ -15,6 +15,7 @@
     #include <Common/Stopwatch.h>
 #endif
 
+
 namespace DB
 {
 
@@ -24,8 +25,8 @@ namespace ErrorCodes
 }
 
 
-PipelineExecutor::PipelineExecutor(Processors & processors, QueryStatus * elem)
-    : process_list_element(elem)
+PipelineExecutor::PipelineExecutor(std::shared_ptr<Processors> & processors, QueryStatusPtr elem)
+    : process_list_element(std::move(elem))
 {
     if (process_list_element)
     {
@@ -41,7 +42,7 @@ PipelineExecutor::PipelineExecutor(Processors & processors, QueryStatus * elem)
         /// If exception was thrown while pipeline initialization, it means that query pipeline was not build correctly.
         /// It is logical error, and we need more information about pipeline.
         WriteBufferFromOwnString buf;
-        printPipeline(processors, buf);
+        printPipeline(*processors, buf);
         buf.finalize();
         exception.addMessage("Query pipeline:
" + buf.str());
 
diff --git a/src/Processors/Executors/PipelineExecutor.h b/src/Processors/Executors/PipelineExecutor.h
index cea64d309faa..21bde312cbc8 100644
--- a/src/Processors/Executors/PipelineExecutor.h
+++ b/src/Processors/Executors/PipelineExecutor.h
@@ -10,16 +10,19 @@
 #include <queue>
 #include <mutex>
 
+
 namespace DB
 {
 
 class QueryStatus;
+using QueryStatusPtr = std::shared_ptr<QueryStatus>;
 class ExecutingGraph;
 using ExecutingGraphPtr = std::unique_ptr<ExecutingGraph>;
 
 class ReadProgressCallback;
 using ReadProgressCallbackPtr = std::unique_ptr<ReadProgressCallback>;
 
+
 /// Executes query pipeline.
 class PipelineExecutor
 {
@@ -30,7 +33,7 @@ class PipelineExecutor
     /// During pipeline execution new processors can appear. They will be added to existing set.
     ///
     /// Explicit graph representation is built in constructor. Throws if graph is not correct.
-    explicit PipelineExecutor(Processors & processors, QueryStatus * elem);
+    explicit PipelineExecutor(std::shared_ptr<Processors> & processors, QueryStatusPtr elem);
     ~PipelineExecutor();
 
     /// Execute pipeline in multiple threads. Must be called once.
@@ -79,7 +82,7 @@ class PipelineExecutor
     Poco::Logger * log = &Poco::Logger::get("PipelineExecutor");
 
     /// Now it's used to check if query was killed.
-    QueryStatus * const process_list_element = nullptr;
+    QueryStatusPtr process_list_element;
 
     ReadProgressCallbackPtr read_progress_callback;
 
diff --git a/src/Processors/Executors/PushingAsyncPipelineExecutor.cpp b/src/Processors/Executors/PushingAsyncPipelineExecutor.cpp
index 7a55d26f16cd..ee8e94b6f28a 100644
--- a/src/Processors/Executors/PushingAsyncPipelineExecutor.cpp
+++ b/src/Processors/Executors/PushingAsyncPipelineExecutor.cpp
@@ -129,7 +129,7 @@ PushingAsyncPipelineExecutor::PushingAsyncPipelineExecutor(QueryPipeline & pipel
 
     pushing_source = std::make_shared<PushingAsyncSource>(pipeline.input->getHeader());
     connect(pushing_source->getPort(), *pipeline.input);
-    pipeline.processors.emplace_back(pushing_source);
+    pipeline.processors->emplace_back(pushing_source);
 }
 
 PushingAsyncPipelineExecutor::~PushingAsyncPipelineExecutor()
diff --git a/src/Processors/Executors/PushingPipelineExecutor.cpp b/src/Processors/Executors/PushingPipelineExecutor.cpp
index bf43cd327fec..d9a14704cd08 100644
--- a/src/Processors/Executors/PushingPipelineExecutor.cpp
+++ b/src/Processors/Executors/PushingPipelineExecutor.cpp
@@ -58,7 +58,7 @@ PushingPipelineExecutor::PushingPipelineExecutor(QueryPipeline & pipeline_) : pi
 
     pushing_source = std::make_shared<PushingSource>(pipeline.input->getHeader(), input_wait_flag);
     connect(pushing_source->getPort(), *pipeline.input);
-    pipeline.processors.emplace_back(pushing_source);
+    pipeline.processors->emplace_back(pushing_source);
 }
 
 PushingPipelineExecutor::~PushingPipelineExecutor()
diff --git a/src/Processors/Formats/Impl/MySQLOutputFormat.cpp b/src/Processors/Formats/Impl/MySQLOutputFormat.cpp
index 344c5c179db6..b4aafbd3d9e2 100644
--- a/src/Processors/Formats/Impl/MySQLOutputFormat.cpp
+++ b/src/Processors/Formats/Impl/MySQLOutputFormat.cpp
@@ -74,7 +74,7 @@ void MySQLOutputFormat::finalizeImpl()
 {
     size_t affected_rows = 0;
     std::string human_readable_info;
-    if (QueryStatus * process_list_elem = getContext()->getProcessListElement())
+    if (QueryStatusPtr process_list_elem = getContext()->getProcessListElement())
     {
         CurrentThread::finalizePerformanceCounters();
         QueryStatusInfo info = process_list_elem->getInfo();
diff --git a/src/Processors/QueryPlan/BuildQueryPipelineSettings.h b/src/Processors/QueryPlan/BuildQueryPipelineSettings.h
index fadbd061fbd5..3b5e4e06953c 100644
--- a/src/Processors/QueryPlan/BuildQueryPipelineSettings.h
+++ b/src/Processors/QueryPlan/BuildQueryPipelineSettings.h
@@ -5,16 +5,18 @@
 
 #include <cstddef>
 
+
 namespace DB
 {
 
 struct Settings;
 class QueryStatus;
+using QueryStatusPtr = std::shared_ptr<QueryStatus>;
 
 struct BuildQueryPipelineSettings
 {
     ExpressionActionsSettings actions_settings;
-    QueryStatus * process_list_element = nullptr;
+    QueryStatusPtr process_list_element;
     ProgressCallback progress_callback = nullptr;
 
     const ExpressionActionsSettings & getActionsSettings() const { return actions_settings; }
diff --git a/src/Processors/Transforms/CountingTransform.h b/src/Processors/Transforms/CountingTransform.h
index bd2ec58a27f9..05d8e2aeac89 100644
--- a/src/Processors/Transforms/CountingTransform.h
+++ b/src/Processors/Transforms/CountingTransform.h
@@ -9,6 +9,7 @@ namespace DB
 {
 
 class QueryStatus;
+using QueryStatusPtr = std::shared_ptr<QueryStatus>;
 class ThreadStatus;
 
 /// Proxy class which counts number of written block, rows, bytes
@@ -29,7 +30,7 @@ class CountingTransform final : public ExceptionKeepingTransform
         progress_callback = callback;
     }
 
-    void setProcessListElement(QueryStatus * elem)
+    void setProcessListElement(QueryStatusPtr elem)
     {
         process_elem = elem;
     }
@@ -50,7 +51,7 @@ class CountingTransform final : public ExceptionKeepingTransform
 protected:
     Progress progress;
     ProgressCallback progress_callback;
-    QueryStatus * process_elem = nullptr;
+    QueryStatusPtr process_elem;
     ThreadStatus * thread_status = nullptr;
 
     /// Quota is used to limit amount of written bytes.
diff --git a/src/Processors/Transforms/buildPushingToViewsChain.cpp b/src/Processors/Transforms/buildPushingToViewsChain.cpp
index 174aaf67ec5c..830f400faf28 100644
--- a/src/Processors/Transforms/buildPushingToViewsChain.cpp
+++ b/src/Processors/Transforms/buildPushingToViewsChain.cpp
@@ -620,9 +620,10 @@ void PushingToLiveViewSink::consume(Chunk chunk)
 {
     Progress local_progress(chunk.getNumRows(), chunk.bytes(), 0);
     StorageLiveView::writeIntoLiveView(live_view, getHeader().cloneWithColumns(chunk.detachColumns()), context);
-    auto * process = context->getProcessListElement();
-    if (process)
+
+    if (auto process = context->getProcessListElement())
         process->updateProgressIn(local_progress);
+
     ProfileEvents::increment(ProfileEvents::SelectedRows, local_progress.read_rows);
     ProfileEvents::increment(ProfileEvents::SelectedBytes, local_progress.read_bytes);
 }
@@ -643,9 +644,10 @@ void PushingToWindowViewSink::consume(Chunk chunk)
     Progress local_progress(chunk.getNumRows(), chunk.bytes(), 0);
     StorageWindowView::writeIntoWindowView(
         window_view, getHeader().cloneWithColumns(chunk.detachColumns()), context);
-    auto * process = context->getProcessListElement();
-    if (process)
+
+    if (auto process = context->getProcessListElement())
         process->updateProgressIn(local_progress);
+
     ProfileEvents::increment(ProfileEvents::SelectedRows, local_progress.read_rows);
     ProfileEvents::increment(ProfileEvents::SelectedBytes, local_progress.read_bytes);
 }
diff --git a/src/QueryPipeline/BlockIO.cpp b/src/QueryPipeline/BlockIO.cpp
index 35463ca6be99..9e42e06c722f 100644
--- a/src/QueryPipeline/BlockIO.cpp
+++ b/src/QueryPipeline/BlockIO.cpp
@@ -53,9 +53,8 @@ void BlockIO::setAllDataSent() const
     /// - internal
     /// - SHOW PROCESSLIST
     if (process_list_entry)
-        (*process_list_entry)->setAllDataSent();
+        process_list_entry->getQueryStatus()->setAllDataSent();
 }
 
 
 }
-
diff --git a/src/QueryPipeline/BlockIO.h b/src/QueryPipeline/BlockIO.h
index 1f2a8f6f0334..b69f86ac684a 100644
--- a/src/QueryPipeline/BlockIO.h
+++ b/src/QueryPipeline/BlockIO.h
@@ -34,9 +34,8 @@ struct BlockIO
     void onFinish()
     {
         if (finish_callback)
-        {
             finish_callback(pipeline);
-        }
+
         pipeline.reset();
     }
 
diff --git a/src/QueryPipeline/Pipe.cpp b/src/QueryPipeline/Pipe.cpp
index 291739079a28..62a928d814c3 100644
--- a/src/QueryPipeline/Pipe.cpp
+++ b/src/QueryPipeline/Pipe.cpp
@@ -102,7 +102,12 @@ static OutputPort * uniteTotals(const OutputPortRawPtrs & ports, const Block & h
     return totals_port;
 }
 
+Pipe::Pipe() : processors(std::make_shared<Processors>())
+{
+}
+
 Pipe::Pipe(ProcessorPtr source, OutputPort * output, OutputPort * totals, OutputPort * extremes)
+    : processors(std::make_shared<Processors>())
 {
     if (!source->getInputs().empty())
         throw Exception(
@@ -155,11 +160,12 @@ Pipe::Pipe(ProcessorPtr source, OutputPort * output, OutputPort * totals, Output
     totals_port = totals;
     extremes_port = extremes;
     output_ports.push_back(output);
-    processors.emplace_back(std::move(source));
+    processors->emplace_back(std::move(source));
     max_parallel_streams = 1;
 }
 
 Pipe::Pipe(ProcessorPtr source)
+    : processors(std::make_shared<Processors>())
 {
     checkSource(*source);
 
@@ -168,18 +174,18 @@ Pipe::Pipe(ProcessorPtr source)
 
     output_ports.push_back(&source->getOutputs().front());
     header = output_ports.front()->getHeader();
-    processors.emplace_back(std::move(source));
+    processors->emplace_back(std::move(source));
     max_parallel_streams = 1;
 }
 
-Pipe::Pipe(Processors processors_) : processors(std::move(processors_))
+Pipe::Pipe(std::shared_ptr<Processors> processors_) : processors(std::move(processors_))
 {
     /// Create hash table with processors.
     std::unordered_set<const IProcessor *> set;
-    for (const auto & processor : processors)
+    for (const auto & processor : *processors)
         set.emplace(processor.get());
 
-    for (auto & processor : processors)
+    for (auto & processor : *processors)
     {
         for (const auto & port : processor->getInputs())
         {
@@ -225,7 +231,7 @@ Pipe::Pipe(Processors processors_) : processors(std::move(processors_))
     max_parallel_streams = output_ports.size();
 
     if (collected_processors)
-        for (const auto & processor : processors)
+        for (const auto & processor : *processors)
             collected_processors->emplace_back(processor);
 }
 
@@ -311,7 +317,7 @@ Pipe Pipe::unitePipes(Pipes pipes, Processors * collected_processors, bool allow
         if (!allow_empty_header || pipe.header)
             assertCompatibleHeader(pipe.header, res.header, "Pipe::unitePipes");
 
-        res.processors.insert(res.processors.end(), pipe.processors.begin(), pipe.processors.end());
+        res.processors->insert(res.processors->end(), pipe.processors->begin(), pipe.processors->end());
         res.output_ports.insert(res.output_ports.end(), pipe.output_ports.begin(), pipe.output_ports.end());
 
         res.max_parallel_streams += pipe.max_parallel_streams;
@@ -323,15 +329,15 @@ Pipe Pipe::unitePipes(Pipes pipes, Processors * collected_processors, bool allow
             extremes.emplace_back(pipe.extremes_port);
     }
 
-    size_t num_processors = res.processors.size();
+    size_t num_processors = res.processors->size();
 
-    res.totals_port = uniteTotals(totals, res.header, res.processors);
-    res.extremes_port = uniteExtremes(extremes, res.header, res.processors);
+    res.totals_port = uniteTotals(totals, res.header, *res.processors);
+    res.extremes_port = uniteExtremes(extremes, res.header, *res.processors);
 
     if (res.collected_processors)
     {
-        for (; num_processors < res.processors.size(); ++num_processors)
-            res.collected_processors->emplace_back(res.processors[num_processors]);
+        for (; num_processors < res.processors->size(); ++num_processors)
+            res.collected_processors->emplace_back(res.processors->at(num_processors));
     }
 
     return res;
@@ -351,7 +357,7 @@ void Pipe::addSource(ProcessorPtr source)
         collected_processors->emplace_back(source);
 
     output_ports.push_back(&source->getOutputs().front());
-    processors.emplace_back(std::move(source));
+    processors->emplace_back(std::move(source));
 
     max_parallel_streams = std::max<size_t>(max_parallel_streams, output_ports.size());
 }
@@ -373,7 +379,7 @@ void Pipe::addTotalsSource(ProcessorPtr source)
         collected_processors->emplace_back(source);
 
     totals_port = &source->getOutputs().front();
-    processors.emplace_back(std::move(source));
+    processors->emplace_back(std::move(source));
 }
 
 void Pipe::addExtremesSource(ProcessorPtr source)
@@ -393,7 +399,7 @@ void Pipe::addExtremesSource(ProcessorPtr source)
         collected_processors->emplace_back(source);
 
     extremes_port = &source->getOutputs().front();
-    processors.emplace_back(std::move(source));
+    processors->emplace_back(std::move(source));
 }
 
 static void dropPort(OutputPort *& port, Processors & processors, Processors * collected_processors)
@@ -413,12 +419,12 @@ static void dropPort(OutputPort *& port, Processors & processors, Processors * c
 
 void Pipe::dropTotals()
 {
-    dropPort(totals_port, processors, collected_processors);
+    dropPort(totals_port, *processors, collected_processors);
 }
 
 void Pipe::dropExtremes()
 {
-    dropPort(extremes_port, processors, collected_processors);
+    dropPort(extremes_port, *processors, collected_processors);
 }
 
 void Pipe::addTransform(ProcessorPtr transform)
@@ -504,7 +510,7 @@ void Pipe::addTransform(ProcessorPtr transform, OutputPort * totals, OutputPort
     if (collected_processors)
         collected_processors->emplace_back(transform);
 
-    processors.emplace_back(std::move(transform));
+    processors->emplace_back(std::move(transform));
 
     max_parallel_streams = std::max<size_t>(max_parallel_streams, output_ports.size());
 }
@@ -595,7 +601,7 @@ void Pipe::addTransform(ProcessorPtr transform, InputPort * totals, InputPort *
     if (collected_processors)
         collected_processors->emplace_back(transform);
 
-    processors.emplace_back(std::move(transform));
+    processors->emplace_back(std::move(transform));
 
     max_parallel_streams = std::max<size_t>(max_parallel_streams, output_ports.size());
 }
@@ -647,7 +653,7 @@ void Pipe::addSimpleTransform(const ProcessorGetterWithStreamKind & getter)
             if (collected_processors)
                 collected_processors->emplace_back(transform);
 
-            processors.emplace_back(std::move(transform));
+            processors->emplace_back(std::move(transform));
         }
     };
 
@@ -698,7 +704,7 @@ void Pipe::addChains(std::vector<Chain> chains)
             if (collected_processors)
                 collected_processors->emplace_back(transform);
 
-            processors.emplace_back(std::move(transform));
+            processors->emplace_back(std::move(transform));
         }
     }
 
@@ -757,7 +763,7 @@ void Pipe::setSinks(const Pipe::ProcessorGetterWithStreamKind & getter)
             transform = std::make_shared<NullSink>(stream->getHeader());
 
         connect(*stream, transform->getInputs().front());
-        processors.emplace_back(std::move(transform));
+        processors->emplace_back(std::move(transform));
     };
 
     for (auto & port : output_ports)
@@ -858,7 +864,7 @@ void Pipe::transform(const Transformer & transformer, bool check_ports)
             collected_processors->emplace_back(processor);
     }
 
-    processors.insert(processors.end(), new_processors.begin(), new_processors.end());
+    processors->insert(processors->end(), new_processors.begin(), new_processors.end());
 
     max_parallel_streams = std::max<size_t>(max_parallel_streams, output_ports.size());
 }
diff --git a/src/QueryPipeline/Pipe.h b/src/QueryPipeline/Pipe.h
index 79d19a181935..7e30d9c990ea 100644
--- a/src/QueryPipeline/Pipe.h
+++ b/src/QueryPipeline/Pipe.h
@@ -5,6 +5,7 @@
 #include <QueryPipeline/Chain.h>
 #include <QueryPipeline/SizeLimits.h>
 
+
 namespace DB
 {
 
@@ -27,13 +28,13 @@ class Pipe
 public:
     /// Default constructor creates empty pipe. Generally, you cannot do anything with it except to check it is empty().
     /// You cannot get empty pipe in any other way. All transforms check that result pipe is not empty.
-    Pipe() = default;
+    Pipe();
     /// Create from source. Source must have no input ports and single output.
     explicit Pipe(ProcessorPtr source);
     /// Create from source with specified totals end extremes (may be nullptr). Ports should be owned by source.
     explicit Pipe(ProcessorPtr source, OutputPort * output, OutputPort * totals, OutputPort * extremes);
     /// Create from processors. Use all not-connected output ports as output_ports. Check invariants.
-    explicit Pipe(Processors processors_);
+    explicit Pipe(std::shared_ptr<Processors> processors_);
 
     Pipe(const Pipe & other) = delete;
     Pipe(Pipe && other) = default;
@@ -41,7 +42,7 @@ class Pipe
     Pipe & operator=(Pipe && other) = default;
 
     const Block & getHeader() const { return header; }
-    bool empty() const { return processors.empty(); }
+    bool empty() const { return processors->empty(); }
     size_t numOutputPorts() const { return output_ports.size(); }
     size_t maxParallelStreams() const { return max_parallel_streams; }
     OutputPort * getOutputPort(size_t pos) const { return output_ports[pos]; }
@@ -96,15 +97,15 @@ class Pipe
     /// Unite several pipes together. They should have same header.
     static Pipe unitePipes(Pipes pipes);
 
-    /// Get processors from Pipe. Use it with cautious, it is easy to loss totals and extremes ports.
-    static Processors detachProcessors(Pipe pipe) { return std::move(pipe.processors); }
+    /// Get processors from Pipe. Use it with caution, it is easy to lose totals and extremes ports.
+    static Processors detachProcessors(Pipe pipe) { return *std::move(pipe.processors); }
     /// Get processors from Pipe without destroying pipe (used for EXPLAIN to keep QueryPlan).
-    const Processors & getProcessors() const { return processors; }
+    const Processors & getProcessors() const { return *processors; }
 
 private:
     /// Header is common for all output below.
     Block header;
-    Processors processors;
+    std::shared_ptr<Processors> processors;
 
     /// Output ports. Totals and extremes are allowed to be empty.
     OutputPortRawPtrs output_ports;
diff --git a/src/QueryPipeline/PipelineResourcesHolder.h b/src/QueryPipeline/PipelineResourcesHolder.h
index 46b1024f384e..ed9eb68b7bac 100644
--- a/src/QueryPipeline/PipelineResourcesHolder.h
+++ b/src/QueryPipeline/PipelineResourcesHolder.h
@@ -19,8 +19,9 @@ struct QueryPlanResourceHolder
     QueryPlanResourceHolder();
     QueryPlanResourceHolder(QueryPlanResourceHolder &&) noexcept;
     ~QueryPlanResourceHolder();
+
     /// Custom move assignment does not destroy data from lhs. It appends data from rhs to lhs.
-    QueryPlanResourceHolder& operator=(QueryPlanResourceHolder &&) noexcept;
+    QueryPlanResourceHolder & operator=(QueryPlanResourceHolder &&) noexcept;
 
     /// Some processors may implicitly use Context or temporary Storage created by Interpreter.
     /// But lifetime of Streams is not nested in lifetime of Interpreters, so we have to store it here,
diff --git a/src/QueryPipeline/QueryPipeline.cpp b/src/QueryPipeline/QueryPipeline.cpp
index 31b18c7f7f0c..e0da4c4f0eb6 100644
--- a/src/QueryPipeline/QueryPipeline.cpp
+++ b/src/QueryPipeline/QueryPipeline.cpp
@@ -21,6 +21,7 @@
 #include <Processors/Transforms/ExpressionTransform.h>
 #include <Processors/QueryPlan/ReadFromPreparedSource.h>
 
+
 namespace DB
 {
 
@@ -29,7 +30,11 @@ namespace ErrorCodes
     extern const int LOGICAL_ERROR;
 }
 
-QueryPipeline::QueryPipeline() = default;
+QueryPipeline::QueryPipeline()
+    : processors(std::make_shared<Processors>())
+{
+}
+
 QueryPipeline::QueryPipeline(QueryPipeline &&) noexcept = default;
 QueryPipeline & QueryPipeline::operator=(QueryPipeline &&) noexcept = default;
 QueryPipeline::~QueryPipeline() = default;
@@ -210,16 +215,16 @@ static void initRowsBeforeLimit(IOutputFormat * output_format)
 
 QueryPipeline::QueryPipeline(
     QueryPlanResourceHolder resources_,
-    Processors processors_)
+    std::shared_ptr<Processors> processors_)
     : resources(std::move(resources_))
     , processors(std::move(processors_))
 {
-    checkCompleted(processors);
+    checkCompleted(*processors);
 }
 
 QueryPipeline::QueryPipeline(
     QueryPlanResourceHolder resources_,
-    Processors processors_,
+    std::shared_ptr<Processors> processors_,
     InputPort * input_)
     : resources(std::move(resources_))
     , processors(std::move(processors_))
@@ -231,7 +236,7 @@ QueryPipeline::QueryPipeline(
             "Cannot create pushing QueryPipeline because its input port is connected or null");
 
     bool found_input = false;
-    for (const auto & processor : processors)
+    for (const auto & processor : *processors)
     {
         for (const auto & in : processor->getInputs())
         {
@@ -255,7 +260,7 @@ QueryPipeline::QueryPipeline(std::shared_ptr<ISource> source) : QueryPipeline(Pi
 
 QueryPipeline::QueryPipeline(
     QueryPlanResourceHolder resources_,
-    Processors processors_,
+    std::shared_ptr<Processors> processors_,
     OutputPort * output_,
     OutputPort * totals_,
     OutputPort * extremes_)
@@ -265,7 +270,7 @@ QueryPipeline::QueryPipeline(
     , totals(totals_)
     , extremes(extremes_)
 {
-    checkPulling(processors, output, totals, extremes);
+    checkPulling(*processors, output, totals, extremes);
 }
 
 QueryPipeline::QueryPipeline(Pipe pipe)
@@ -278,32 +283,34 @@ QueryPipeline::QueryPipeline(Pipe pipe)
         extremes = pipe.getExtremesPort();
 
         processors = std::move(pipe.processors);
-        checkPulling(processors, output, totals, extremes);
+        checkPulling(*processors, output, totals, extremes);
     }
     else
     {
         processors = std::move(pipe.processors);
-        checkCompleted(processors);
+        checkCompleted(*processors);
     }
 }
 
 QueryPipeline::QueryPipeline(Chain chain)
     : resources(chain.detachResources())
+    , processors(std::make_shared<Processors>())
     , input(&chain.getInputPort())
     , num_threads(chain.getNumThreads())
 {
-    processors.reserve(chain.getProcessors().size() + 1);
+    processors->reserve(chain.getProcessors().size() + 1);
     for (auto processor : chain.getProcessors())
-        processors.emplace_back(std::move(processor));
+        processors->emplace_back(std::move(processor));
 
     auto sink = std::make_shared<EmptySink>(chain.getOutputPort().getHeader());
     connect(chain.getOutputPort(), sink->getPort());
-    processors.emplace_back(std::move(sink));
+    processors->emplace_back(std::move(sink));
 
     input = &chain.getInputPort();
 }
 
 QueryPipeline::QueryPipeline(std::shared_ptr<IOutputFormat> format)
+    : processors(std::make_shared<Processors>())
 {
     auto & format_main = format->getPort(IOutputFormat::PortKind::Main);
     auto & format_totals = format->getPort(IOutputFormat::PortKind::Totals);
@@ -313,14 +320,14 @@ QueryPipeline::QueryPipeline(std::shared_ptr<IOutputFormat> format)
     {
         auto source = std::make_shared<NullSource>(format_totals.getHeader());
         totals = &source->getPort();
-        processors.emplace_back(std::move(source));
+        processors->emplace_back(std::move(source));
     }
 
     if (!extremes)
     {
         auto source = std::make_shared<NullSource>(format_extremes.getHeader());
         extremes = &source->getPort();
-        processors.emplace_back(std::move(source));
+        processors->emplace_back(std::move(source));
     }
 
     connect(*totals, format_totals);
@@ -332,7 +339,7 @@ QueryPipeline::QueryPipeline(std::shared_ptr<IOutputFormat> format)
 
     output_format = format.get();
 
-    processors.emplace_back(std::move(format));
+    processors->emplace_back(std::move(format));
 }
 
 static void drop(OutputPort *& port, Processors & processors)
@@ -354,11 +361,11 @@ void QueryPipeline::complete(std::shared_ptr<ISink> sink)
     if (!pulling())
         throw Exception(ErrorCodes::LOGICAL_ERROR, "Pipeline must be pulling to be completed with sink");
 
-    drop(totals, processors);
-    drop(extremes, processors);
+    drop(totals, *processors);
+    drop(extremes, *processors);
 
     connect(*output, sink->getPort());
-    processors.emplace_back(std::move(sink));
+    processors->emplace_back(std::move(sink));
     output = nullptr;
 }
 
@@ -369,17 +376,17 @@ void QueryPipeline::complete(Chain chain)
 
     resources = chain.detachResources();
 
-    drop(totals, processors);
-    drop(extremes, processors);
+    drop(totals, *processors);
+    drop(extremes, *processors);
 
-    processors.reserve(processors.size() + chain.getProcessors().size() + 1);
+    processors->reserve(processors->size() + chain.getProcessors().size() + 1);
     for (auto processor : chain.getProcessors())
-        processors.emplace_back(std::move(processor));
+        processors->emplace_back(std::move(processor));
 
     auto sink = std::make_shared<EmptySink>(chain.getOutputPort().getHeader());
     connect(*output, chain.getInputPort());
     connect(chain.getOutputPort(), sink->getPort());
-    processors.emplace_back(std::move(sink));
+    processors->emplace_back(std::move(sink));
     output = nullptr;
 }
 
@@ -400,7 +407,7 @@ void QueryPipeline::complete(Pipe pipe)
     input = nullptr;
 
     auto pipe_processors = Pipe::detachProcessors(std::move(pipe));
-    processors.insert(processors.end(), pipe_processors.begin(), pipe_processors.end());
+    processors->insert(processors->end(), pipe_processors.begin(), pipe_processors.end());
 }
 
 static void addMaterializing(OutputPort *& output, Processors & processors)
@@ -421,9 +428,9 @@ void QueryPipeline::complete(std::shared_ptr<IOutputFormat> format)
 
     if (format->expectMaterializedColumns())
     {
-        addMaterializing(output, processors);
-        addMaterializing(totals, processors);
-        addMaterializing(extremes, processors);
+        addMaterializing(output, *processors);
+        addMaterializing(totals, *processors);
+        addMaterializing(extremes, *processors);
     }
 
     auto & format_main = format->getPort(IOutputFormat::PortKind::Main);
@@ -434,14 +441,14 @@ void QueryPipeline::complete(std::shared_ptr<IOutputFormat> format)
     {
         auto source = std::make_shared<NullSource>(format_totals.getHeader());
         totals = &source->getPort();
-        processors.emplace_back(std::move(source));
+        processors->emplace_back(std::move(source));
     }
 
     if (!extremes)
     {
         auto source = std::make_shared<NullSource>(format_extremes.getHeader());
         extremes = &source->getPort();
-        processors.emplace_back(std::move(source));
+        processors->emplace_back(std::move(source));
     }
 
     connect(*output, format_main);
@@ -455,7 +462,7 @@ void QueryPipeline::complete(std::shared_ptr<IOutputFormat> format)
     initRowsBeforeLimit(format.get());
     output_format = format.get();
 
-    processors.emplace_back(std::move(format));
+    processors->emplace_back(std::move(format));
 }
 
 Block QueryPipeline::getHeader() const
@@ -475,7 +482,7 @@ void QueryPipeline::setProgressCallback(const ProgressCallback & callback)
     progress_callback = callback;
 }
 
-void QueryPipeline::setProcessListElement(QueryStatus * elem)
+void QueryPipeline::setProcessListElement(QueryStatusPtr elem)
 {
     process_list_element = elem;
 
@@ -504,7 +511,7 @@ void QueryPipeline::setLimitsAndQuota(const StreamLocalLimits & limits, std::sha
     transform->setQuota(quota_);
     connect(*output, transform->getInputPort());
     output = &transform->getOutputPort();
-    processors.emplace_back(std::move(transform));
+    processors->emplace_back(std::move(transform));
 }
 
 
@@ -529,7 +536,7 @@ void QueryPipeline::addCompletedPipeline(QueryPipeline other)
         throw Exception(ErrorCodes::LOGICAL_ERROR, "Cannot add not completed pipeline");
 
     resources = std::move(other.resources);
-    processors.insert(processors.end(), other.processors.begin(), other.processors.end());
+    processors->insert(processors->end(), other.processors->begin(), other.processors->end());
 }
 
 void QueryPipeline::reset()
@@ -560,9 +567,9 @@ void QueryPipeline::convertStructureTo(const ColumnsWithTypeAndName & columns)
         ActionsDAG::MatchColumnsMode::Position);
 
     auto actions = std::make_shared<ExpressionActions>(std::move(converting));
-    addExpression(output, actions, processors);
-    addExpression(totals, actions, processors);
-    addExpression(extremes, actions, processors);
+    addExpression(output, actions, *processors);
+    addExpression(totals, actions, *processors);
+    addExpression(extremes, actions, *processors);
 }
 
 std::unique_ptr<ReadProgressCallback> QueryPipeline::getReadProgressCallback() const
diff --git a/src/QueryPipeline/QueryPipeline.h b/src/QueryPipeline/QueryPipeline.h
index 1b88ede33493..63f444e6ec17 100644
--- a/src/QueryPipeline/QueryPipeline.h
+++ b/src/QueryPipeline/QueryPipeline.h
@@ -4,6 +4,7 @@
 #include <QueryPipeline/StreamLocalLimits.h>
 #include <functional>
 
+
 namespace DB
 {
 
@@ -15,6 +16,7 @@ using ProcessorPtr = std::shared_ptr<IProcessor>;
 using Processors = std::vector<ProcessorPtr>;
 
 class QueryStatus;
+using QueryStatusPtr = std::shared_ptr<QueryStatus>;
 
 struct Progress;
 using ProgressCallback = std::function<void(const Progress & progress)>;
@@ -34,6 +36,7 @@ class ReadProgressCallback;
 struct ColumnWithTypeAndName;
 using ColumnsWithTypeAndName = std::vector<ColumnWithTypeAndName>;
 
+
 class QueryPipeline
 {
 public:
@@ -58,23 +61,23 @@ class QueryPipeline
     /// completed
     QueryPipeline(
         QueryPlanResourceHolder resources_,
-        Processors processors_);
+        std::shared_ptr<Processors> processors_);
 
     /// pushing
     QueryPipeline(
         QueryPlanResourceHolder resources_,
-        Processors processors_,
+        std::shared_ptr<Processors> processors_,
         InputPort * input_);
 
     /// pulling
     QueryPipeline(
         QueryPlanResourceHolder resources_,
-        Processors processors_,
+        std::shared_ptr<Processors> processors_,
         OutputPort * output_,
         OutputPort * totals_ = nullptr,
         OutputPort * extremes_ = nullptr);
 
-    bool initialized() const { return !processors.empty(); }
+    bool initialized() const { return !processors->empty(); }
     /// When initialized, exactly one of the following is true.
     /// Use PullingPipelineExecutor or PullingAsyncPipelineExecutor.
     bool pulling() const { return output != nullptr; }
@@ -97,7 +100,7 @@ class QueryPipeline
     size_t getNumThreads() const { return num_threads; }
     void setNumThreads(size_t num_threads_) { num_threads = num_threads_; }
 
-    void setProcessListElement(QueryStatus * elem);
+    void setProcessListElement(QueryStatusPtr elem);
     void setProgressCallback(const ProgressCallback & callback);
     void setLimitsAndQuota(const StreamLocalLimits & limits, std::shared_ptr<const EnabledQuota> quota_);
     bool tryGetResultRowsAndBytes(UInt64 & result_rows, UInt64 & result_bytes) const;
@@ -119,7 +122,7 @@ class QueryPipeline
     /// Add processors and resources from other pipeline. Other pipeline should be completed.
     void addCompletedPipeline(QueryPipeline other);
 
-    const Processors & getProcessors() const { return processors; }
+    const Processors & getProcessors() const { return *processors; }
 
     /// For pulling pipeline, convert structure to expected.
     /// Trash, need to remove later.
@@ -134,7 +137,7 @@ class QueryPipeline
     std::shared_ptr<const EnabledQuota> quota;
     bool update_profile_events = true;
 
-    Processors processors;
+    std::shared_ptr<Processors> processors;
 
     InputPort * input = nullptr;
 
@@ -142,7 +145,7 @@ class QueryPipeline
     OutputPort * totals = nullptr;
     OutputPort * extremes = nullptr;
 
-    QueryStatus * process_list_element = nullptr;
+    QueryStatusPtr process_list_element;
 
     IOutputFormat * output_format = nullptr;
 
diff --git a/src/QueryPipeline/QueryPipelineBuilder.cpp b/src/QueryPipeline/QueryPipelineBuilder.cpp
index 440f123e8763..812bd155b423 100644
--- a/src/QueryPipeline/QueryPipelineBuilder.cpp
+++ b/src/QueryPipeline/QueryPipelineBuilder.cpp
@@ -327,9 +327,9 @@ QueryPipelineBuilderPtr QueryPipelineBuilder::mergePipelines(
         collected_processors->emplace_back(transform);
 
     left->pipe.output_ports.front() = &transform->getOutputs().front();
-    left->pipe.processors.emplace_back(transform);
+    left->pipe.processors->emplace_back(transform);
 
-    left->pipe.processors.insert(left->pipe.processors.end(), right->pipe.processors.begin(), right->pipe.processors.end());
+    left->pipe.processors->insert(left->pipe.processors->end(), right->pipe.processors->begin(), right->pipe.processors->end());
     left->pipe.header = left->pipe.output_ports.front()->getHeader();
     left->pipe.max_parallel_streams = std::max(left->pipe.max_parallel_streams, right->pipe.max_parallel_streams);
     return left;
@@ -383,7 +383,7 @@ std::unique_ptr<QueryPipelineBuilder> QueryPipelineBuilder::joinPipelinesRightLe
     /// Collect the NEW processors for the right pipeline.
     QueryPipelineProcessorsCollector collector(*right);
     /// Remember the last step of the right pipeline.
-    ExpressionStep* step = typeid_cast<ExpressionStep*>(right->pipe.processors.back()->getQueryPlanStep());
+    ExpressionStep* step = typeid_cast<ExpressionStep*>(right->pipe.processors->back()->getQueryPlanStep());
     if (!step)
     {
         throw Exception(ErrorCodes::LOGICAL_ERROR, "The top step of the right pipeline should be ExpressionStep");
@@ -467,7 +467,7 @@ std::unique_ptr<QueryPipelineBuilder> QueryPipelineBuilder::joinPipelinesRightLe
         if (collected_processors)
             collected_processors->emplace_back(joining);
 
-        left->pipe.processors.emplace_back(std::move(joining));
+        left->pipe.processors->emplace_back(std::move(joining));
     }
 
     if (left->hasTotals())
@@ -482,14 +482,14 @@ std::unique_ptr<QueryPipelineBuilder> QueryPipelineBuilder::joinPipelinesRightLe
         if (collected_processors)
             collected_processors->emplace_back(joining);
 
-        left->pipe.processors.emplace_back(std::move(joining));
+        left->pipe.processors->emplace_back(std::move(joining));
     }
 
     /// Move the collected processors to the last step in the right pipeline.
     Processors processors = collector.detachProcessors();
     step->appendExtraProcessors(processors);
 
-    left->pipe.processors.insert(left->pipe.processors.end(), right->pipe.processors.begin(), right->pipe.processors.end());
+    left->pipe.processors->insert(left->pipe.processors->end(), right->pipe.processors->begin(), right->pipe.processors->end());
     left->resources = std::move(right->resources);
     left->pipe.header = left->pipe.output_ports.front()->getHeader();
     left->pipe.max_parallel_streams = std::max(left->pipe.max_parallel_streams, right->pipe.max_parallel_streams);
@@ -537,7 +537,7 @@ void QueryPipelineBuilder::addPipelineBefore(QueryPipelineBuilder pipeline)
     addTransform(std::move(processor));
 }
 
-void QueryPipelineBuilder::setProcessListElement(QueryStatus * elem)
+void QueryPipelineBuilder::setProcessListElement(QueryStatusPtr elem)
 {
     process_list_element = elem;
 }
diff --git a/src/QueryPipeline/QueryPipelineBuilder.h b/src/QueryPipeline/QueryPipelineBuilder.h
index 13b4d681b7d6..5a0694100ebb 100644
--- a/src/QueryPipeline/QueryPipelineBuilder.h
+++ b/src/QueryPipeline/QueryPipelineBuilder.h
@@ -148,7 +148,7 @@ class QueryPipelineBuilder
 
     const Block & getHeader() const { return pipe.getHeader(); }
 
-    void setProcessListElement(QueryStatus * elem);
+    void setProcessListElement(QueryStatusPtr elem);
     void setProgressCallback(ProgressCallback callback);
 
     /// Recommend number of threads for pipeline execution.
@@ -189,7 +189,7 @@ class QueryPipelineBuilder
     /// Sometimes, more streams are created then the number of threads for more optimal execution.
     size_t max_threads = 0;
 
-    QueryStatus * process_list_element = nullptr;
+    QueryStatusPtr process_list_element;
     ProgressCallback progress_callback = nullptr;
 
     void checkInitialized();
diff --git a/src/QueryPipeline/ReadProgressCallback.cpp b/src/QueryPipeline/ReadProgressCallback.cpp
index bbdabb8e8d80..6692b0f96bd6 100644
--- a/src/QueryPipeline/ReadProgressCallback.cpp
+++ b/src/QueryPipeline/ReadProgressCallback.cpp
@@ -2,6 +2,7 @@
 #include <Interpreters/ProcessList.h>
 #include <Access/EnabledQuota.h>
 
+
 namespace ProfileEvents
 {
     extern const Event SelectedRows;
@@ -17,7 +18,7 @@ namespace ErrorCodes
     extern const int TOO_MANY_BYTES;
 }
 
-void ReadProgressCallback::setProcessListElement(QueryStatus * elem)
+void ReadProgressCallback::setProcessListElement(QueryStatusPtr elem)
 {
     process_list_elem = elem;
     if (!elem)
diff --git a/src/QueryPipeline/ReadProgressCallback.h b/src/QueryPipeline/ReadProgressCallback.h
index f64123ef39dd..c8f0d4cf5373 100644
--- a/src/QueryPipeline/ReadProgressCallback.h
+++ b/src/QueryPipeline/ReadProgressCallback.h
@@ -4,20 +4,23 @@
 #include <IO/Progress.h>
 #include <mutex>
 
+
 namespace DB
 {
 
 class QueryStatus;
+using QueryStatusPtr = std::shared_ptr<QueryStatus>;
 class EnabledQuota;
 
 struct StorageLimits;
 using StorageLimitsList = std::list<StorageLimits>;
 
+
 class ReadProgressCallback
 {
 public:
     void setQuota(const std::shared_ptr<const EnabledQuota> & quota_) { quota = quota_; }
-    void setProcessListElement(QueryStatus * elem);
+    void setProcessListElement(QueryStatusPtr elem);
     void setProgressCallback(const ProgressCallback & callback) { progress_callback = callback; }
     void addTotalRowsApprox(size_t value) { total_rows_approx += value; }
 
@@ -30,7 +33,7 @@ class ReadProgressCallback
 private:
     std::shared_ptr<const EnabledQuota> quota;
     ProgressCallback progress_callback;
-    QueryStatus * process_list_elem = nullptr;
+    QueryStatusPtr process_list_elem;
 
     /// The approximate total number of rows to read. For progress bar.
     std::atomic_size_t total_rows_approx = 0;
diff --git a/src/Server/TCPHandler.cpp b/src/Server/TCPHandler.cpp
index 25a832ab7e35..962d5412b483 100644
--- a/src/Server/TCPHandler.cpp
+++ b/src/Server/TCPHandler.cpp
@@ -377,8 +377,8 @@ void TCPHandler::runImpl()
             after_send_progress.restart();
 
             if (state.io.pipeline.pushing())
-            /// FIXME: check explicitly that insert query suggests to receive data via native protocol,
             {
+                /// FIXME: check explicitly that insert query suggests to receive data via native protocol,
                 state.need_receive_data_for_insert = true;
                 processInsertQuery();
                 state.io.onFinish();
@@ -390,27 +390,30 @@ void TCPHandler::runImpl()
             }
             else if (state.io.pipeline.completed())
             {
-                CompletedPipelineExecutor executor(state.io.pipeline);
-                /// Should not check for cancel in case of input.
-                if (!state.need_receive_data_for_input)
                 {
-                    auto callback = [this]()
+                    CompletedPipelineExecutor executor(state.io.pipeline);
+
+                    /// Should not check for cancel in case of input.
+                    if (!state.need_receive_data_for_input)
                     {
-                        std::lock_guard lock(fatal_error_mutex);
+                        auto callback = [this]()
+                        {
+                            std::lock_guard lock(fatal_error_mutex);
 
-                        if (isQueryCancelled())
-                            return true;
+                            if (isQueryCancelled())
+                                return true;
 
-                        sendProgress();
-                        sendSelectProfileEvents();
-                        sendLogs();
+                            sendProgress();
+                            sendSelectProfileEvents();
+                            sendLogs();
 
-                        return false;
-                    };
+                            return false;
+                        };
 
-                    executor.setCancelCallback(callback, interactive_delay / 1000);
+                        executor.setCancelCallback(callback, interactive_delay / 1000);
+                    }
+                    executor.execute();
                 }
-                executor.execute();
 
                 state.io.onFinish();
                 /// Send final progress after calling onFinish(), since it will update the progress.
