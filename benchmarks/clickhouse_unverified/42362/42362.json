{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 42362,
  "instance_id": "ClickHouse__ClickHouse-42362",
  "issue_numbers": [
    "42346"
  ],
  "base_commit": "45dadd7c5be13f0253327a5078c82ada0723b971",
  "patch": "diff --git a/src/Client/LocalConnection.cpp b/src/Client/LocalConnection.cpp\nindex 7ac68324915f..476386889d23 100644\n--- a/src/Client/LocalConnection.cpp\n+++ b/src/Client/LocalConnection.cpp\n@@ -6,8 +6,6 @@\n #include <Processors/Executors/PushingAsyncPipelineExecutor.h>\n #include <Storages/IStorage.h>\n #include <Core/Protocol.h>\n-#include <DataTypes/DataTypesNumber.h>\n-#include <DataTypes/DataTypeString.h>\n \n \n namespace DB\ndiff --git a/src/Common/OvercommitTracker.cpp b/src/Common/OvercommitTracker.cpp\nindex c7730667f55f..bb477d6019db 100644\n--- a/src/Common/OvercommitTracker.cpp\n+++ b/src/Common/OvercommitTracker.cpp\n@@ -5,6 +5,7 @@\n #include <Common/ProfileEvents.h>\n #include <Interpreters/ProcessList.h>\n \n+\n namespace ProfileEvents\n {\n     extern const Event MemoryOvercommitWaitTimeMicroseconds;\n@@ -170,7 +171,8 @@ void UserOvercommitTracker::pickQueryToExcludeImpl()\n \n GlobalOvercommitTracker::GlobalOvercommitTracker(DB::ProcessList * process_list_)\n     : OvercommitTracker(process_list_)\n-{}\n+{\n+}\n \n void GlobalOvercommitTracker::pickQueryToExcludeImpl()\n {\n@@ -180,16 +182,16 @@ void GlobalOvercommitTracker::pickQueryToExcludeImpl()\n     // This is guaranteed by locking global_mutex in OvercommitTracker::needToStopQuery.\n     for (auto const & query : process_list->processes)\n     {\n-        if (query.isKilled())\n+        if (query->isKilled())\n             continue;\n \n         Int64 user_soft_limit = 0;\n-        if (auto const * user_process_list = query.getUserProcessList())\n+        if (auto const * user_process_list = query->getUserProcessList())\n             user_soft_limit = user_process_list->user_memory_tracker.getSoftLimit();\n         if (user_soft_limit == 0)\n             continue;\n \n-        auto * memory_tracker = query.getMemoryTracker();\n+        auto * memory_tracker = query->getMemoryTracker();\n         if (!memory_tracker)\n             continue;\n         auto ratio = memory_tracker->getOvercommitRatio(user_soft_limit);\ndiff --git a/src/Formats/FormatFactory.cpp b/src/Formats/FormatFactory.cpp\nindex bfe651dd1af8..a882fcf50096 100644\n--- a/src/Formats/FormatFactory.cpp\n+++ b/src/Formats/FormatFactory.cpp\n@@ -303,7 +303,7 @@ InputFormatPtr FormatFactory::getInputFormat(\n \n static void addExistingProgressToOutputFormat(OutputFormatPtr format, ContextPtr context)\n {\n-    auto * element_id = context->getProcessListElement();\n+    auto element_id = context->getProcessListElement();\n     if (element_id)\n     {\n         /// While preparing the query there might have been progress (for example in subscalar subqueries) so add it here\ndiff --git a/src/Interpreters/ClusterProxy/executeQuery.cpp b/src/Interpreters/ClusterProxy/executeQuery.cpp\nindex 923b4a767b7b..3c294dd78858 100644\n--- a/src/Interpreters/ClusterProxy/executeQuery.cpp\n+++ b/src/Interpreters/ClusterProxy/executeQuery.cpp\n@@ -141,7 +141,7 @@ void executeQuery(\n     new_context->getClientInfo().distributed_depth += 1;\n \n     ThrottlerPtr user_level_throttler;\n-    if (auto * process_list_element = context->getProcessListElement())\n+    if (auto process_list_element = context->getProcessListElement())\n         user_level_throttler = process_list_element->getUserNetworkThrottler();\n \n     /// Network bandwidth limit, if needed.\n@@ -243,7 +243,7 @@ void executeQueryWithParallelReplicas(\n     const Settings & settings = context->getSettingsRef();\n \n     ThrottlerPtr user_level_throttler;\n-    if (auto * process_list_element = context->getProcessListElement())\n+    if (auto process_list_element = context->getProcessListElement())\n         user_level_throttler = process_list_element->getUserNetworkThrottler();\n \n     /// Network bandwidth limit, if needed.\ndiff --git a/src/Interpreters/Context.cpp b/src/Interpreters/Context.cpp\nindex 1de56e950c69..721d701c9a22 100644\n--- a/src/Interpreters/Context.cpp\n+++ b/src/Interpreters/Context.cpp\n@@ -1463,10 +1463,8 @@ void Context::setCurrentQueryId(const String & query_id)\n \n void Context::killCurrentQuery()\n {\n-    if (process_list_elem)\n-    {\n-        process_list_elem->cancelQuery(true);\n-    }\n+    if (auto elem = process_list_elem.lock())\n+        elem->cancelQuery(true);\n }\n \n String Context::getDefaultFormat() const\n@@ -1707,15 +1705,15 @@ ProgressCallback Context::getProgressCallback() const\n }\n \n \n-void Context::setProcessListElement(ProcessList::Element * elem)\n+void Context::setProcessListElement(QueryStatusPtr elem)\n {\n     /// Set to a session or query. In the session, only one query is processed at a time. Therefore, the lock is not needed.\n     process_list_elem = elem;\n }\n \n-ProcessList::Element * Context::getProcessListElement() const\n+QueryStatusPtr Context::getProcessListElement() const\n {\n-    return process_list_elem;\n+    return process_list_elem.lock();\n }\n \n \ndiff --git a/src/Interpreters/Context.h b/src/Interpreters/Context.h\nindex 233f4011ce3b..eeb9e8da1483 100644\n--- a/src/Interpreters/Context.h\n+++ b/src/Interpreters/Context.h\n@@ -68,6 +68,7 @@ class MMappedFileCache;\n class UncompressedCache;\n class ProcessList;\n class QueryStatus;\n+using QueryStatusPtr = std::shared_ptr<QueryStatus>;\n class Macros;\n struct Progress;\n struct FileProgress;\n@@ -230,7 +231,7 @@ class Context: public std::enable_shared_from_this<Context>\n     using FileProgressCallback = std::function<void(const FileProgress & progress)>;\n     FileProgressCallback file_progress_callback; /// Callback for tracking progress of file loading.\n \n-    QueryStatus * process_list_elem = nullptr;  /// For tracking total resource usage for query.\n+    std::weak_ptr<QueryStatus> process_list_elem;  /// For tracking total resource usage for query.\n     StorageID insertion_table = StorageID::createEmpty();  /// Saved insertion table in query context\n     bool is_distributed = false;  /// Whether the current context it used for distributed query\n \n@@ -750,9 +751,9 @@ class Context: public std::enable_shared_from_this<Context>\n     /** Set in executeQuery and InterpreterSelectQuery. Then it is used in QueryPipeline,\n       *  to update and monitor information about the total number of resources spent for the query.\n       */\n-    void setProcessListElement(QueryStatus * elem);\n+    void setProcessListElement(QueryStatusPtr elem);\n     /// Can return nullptr if the query was not inserted into the ProcessList.\n-    QueryStatus * getProcessListElement() const;\n+    QueryStatusPtr getProcessListElement() const;\n \n     /// List all queries.\n     ProcessList & getProcessList();\ndiff --git a/src/Interpreters/ProcessList.cpp b/src/Interpreters/ProcessList.cpp\nindex d5194a025136..3c1ebe21c48d 100644\n--- a/src/Interpreters/ProcessList.cpp\n+++ b/src/Interpreters/ProcessList.cpp\n@@ -243,15 +243,15 @@ ProcessList::EntryPtr ProcessList::insert(const String & query_, const IAST * as\n         }\n \n         auto process_it = processes.emplace(processes.end(),\n-            query_context, query_, client_info, priorities.insert(settings.priority), std::move(thread_group), query_kind);\n+            std::make_shared<QueryStatus>(query_context, query_, client_info, priorities.insert(settings.priority), std::move(thread_group), query_kind));\n \n         increaseQueryKindAmount(query_kind);\n \n         res = std::make_shared<Entry>(*this, process_it);\n \n-        process_it->setUserProcessList(&user_process_list);\n+        (*process_it)->setUserProcessList(&user_process_list);\n \n-        user_process_list.queries.emplace(client_info.current_query_id, &res->get());\n+        user_process_list.queries.emplace(client_info.current_query_id, res->getQueryStatus());\n \n         /// Track memory usage for all simultaneously running queries from single user.\n         user_process_list.user_memory_tracker.setOrRaiseHardLimit(settings.max_memory_usage_for_user);\n@@ -280,11 +280,11 @@ ProcessListEntry::~ProcessListEntry()\n {\n     auto lock = parent.safeLock();\n \n-    String user = it->getClientInfo().current_user;\n-    String query_id = it->getClientInfo().current_query_id;\n-    IAST::QueryKind query_kind = it->query_kind;\n+    String user = (*it)->getClientInfo().current_user;\n+    String query_id = (*it)->getClientInfo().current_query_id;\n+    IAST::QueryKind query_kind = (*it)->query_kind;\n \n-    const QueryStatus * process_list_element_ptr = &*it;\n+    const QueryStatusPtr process_list_element_ptr = *it;\n \n     auto user_process_list_it = parent.user_to_queries.find(user);\n     if (user_process_list_it == parent.user_to_queries.end())\n@@ -307,7 +307,7 @@ ProcessListEntry::~ProcessListEntry()\n     }\n \n     /// Wait for the query if it is in the cancellation right now.\n-    parent.cancelled_cv.wait(lock.lock, [&]() { return it->is_cancelling == false; });\n+    parent.cancelled_cv.wait(lock.lock, [&]() { return process_list_element_ptr->is_cancelling == false; });\n \n     /// This removes the memory_tracker of one request.\n     parent.processes.erase(it);\n@@ -344,6 +344,7 @@ QueryStatus::QueryStatus(\n     , client_info(client_info_)\n     , thread_group(std::move(thread_group_))\n     , priority_handle(std::move(priority_handle_))\n+    , global_overcommit_tracker(context_->getGlobalOvercommitTracker())\n     , query_kind(query_kind_)\n     , num_queries_increment(CurrentMetrics::Query)\n {\n@@ -360,8 +361,8 @@ QueryStatus::~QueryStatus()\n     {\n         if (user_process_list)\n             user_process_list->user_overcommit_tracker.onQueryStop(memory_tracker);\n-        if (auto shared_context = getContext())\n-            shared_context->getGlobalOvercommitTracker()->onQueryStop(memory_tracker);\n+        if (global_overcommit_tracker)\n+            global_overcommit_tracker->onQueryStop(memory_tracker);\n     }\n }\n \n@@ -430,7 +431,7 @@ ThrottlerPtr QueryStatus::getUserNetworkThrottler()\n }\n \n \n-QueryStatus * ProcessList::tryGetProcessListElement(const String & current_query_id, const String & current_user)\n+QueryStatusPtr ProcessList::tryGetProcessListElement(const String & current_query_id, const String & current_user)\n {\n     auto user_it = user_to_queries.find(current_user);\n     if (user_it != user_to_queries.end())\n@@ -442,13 +443,13 @@ QueryStatus * ProcessList::tryGetProcessListElement(const String & current_query\n             return query_it->second;\n     }\n \n-    return nullptr;\n+    return {};\n }\n \n \n CancellationCode ProcessList::sendCancelToQuery(const String & current_query_id, const String & current_user, bool kill)\n {\n-    QueryStatus * elem;\n+    QueryStatusPtr elem;\n \n     /// Cancelling the query should be done without the lock.\n     ///\n@@ -484,7 +485,7 @@ CancellationCode ProcessList::sendCancelToQuery(const String & current_query_id,\n \n void ProcessList::killAllQueries()\n {\n-    std::vector<QueryStatus *> cancelled_processes;\n+    std::vector<QueryStatusPtr> cancelled_processes;\n \n     SCOPE_EXIT({\n         auto lock = safeLock();\n@@ -498,8 +499,8 @@ void ProcessList::killAllQueries()\n         cancelled_processes.reserve(processes.size());\n         for (auto & process : processes)\n         {\n-            cancelled_processes.push_back(&process);\n-            process.is_cancelling = true;\n+            cancelled_processes.push_back(process);\n+            process->is_cancelling = true;\n         }\n     }\n \n@@ -558,7 +559,7 @@ ProcessList::Info ProcessList::getInfo(bool get_thread_list, bool get_profile_ev\n \n     per_query_infos.reserve(processes.size());\n     for (const auto & process : processes)\n-        per_query_infos.emplace_back(process.getInfo(get_thread_list, get_profile_events, get_settings));\n+        per_query_infos.emplace_back(process->getInfo(get_thread_list, get_profile_events, get_settings));\n \n     return per_query_infos;\n }\ndiff --git a/src/Interpreters/ProcessList.h b/src/Interpreters/ProcessList.h\nindex 6943c7cfcd8a..5fbdce358f96 100644\n--- a/src/Interpreters/ProcessList.h\n+++ b/src/Interpreters/ProcessList.h\n@@ -133,6 +133,8 @@ class QueryStatus : public WithContext\n \n     ProcessListForUser * user_process_list = nullptr;\n \n+    OvercommitTracker * global_overcommit_tracker = nullptr;\n+\n     IAST::QueryKind query_kind;\n \n     /// This field is unused in this class, but it\n@@ -221,6 +223,8 @@ class QueryStatus : public WithContext\n     [[nodiscard]] bool checkTimeLimitSoft();\n };\n \n+using QueryStatusPtr = std::shared_ptr<QueryStatus>;\n+\n \n /// Information of process list for user.\n struct ProcessListForUserInfo\n@@ -241,7 +245,7 @@ struct ProcessListForUser\n     ProcessListForUser(ContextPtr global_context, ProcessList * global_process_list);\n \n     /// query_id -> ProcessListElement(s). There can be multiple queries with the same query_id as long as all queries except one are cancelled.\n-    using QueryToElement = std::unordered_map<String, QueryStatus *>;\n+    using QueryToElement = std::unordered_map<String, QueryStatusPtr>;\n     QueryToElement queries;\n \n     ProfileEvents::Counters user_performance_counters{VariableContext::User, &ProfileEvents::global_counters};\n@@ -278,7 +282,7 @@ class ProcessList;\n class ProcessListEntry\n {\n private:\n-    using Container = std::list<QueryStatus>;\n+    using Container = std::list<QueryStatusPtr>;\n \n     ProcessList & parent;\n     Container::iterator it;\n@@ -289,11 +293,8 @@ class ProcessListEntry\n \n     ~ProcessListEntry();\n \n-    QueryStatus * operator->() { return &*it; }\n-    const QueryStatus * operator->() const { return &*it; }\n-\n-    QueryStatus & get() { return *it; }\n-    const QueryStatus & get() const { return *it; }\n+    QueryStatusPtr getQueryStatus() { return *it; }\n+    const QueryStatusPtr getQueryStatus() const { return *it; }\n };\n \n \n@@ -319,7 +320,7 @@ class ProcessListBase\n class ProcessList : public ProcessListBase\n {\n public:\n-    using Element = QueryStatus;\n+    using Element = QueryStatusPtr;\n     using Entry = ProcessListEntry;\n     using QueryAmount = UInt64;\n \n@@ -358,7 +359,7 @@ class ProcessList : public ProcessListBase\n     ThrottlerPtr total_network_throttler;\n \n     /// Call under lock. Finds process with specified current_user and current_query_id.\n-    QueryStatus * tryGetProcessListElement(const String & current_query_id, const String & current_user);\n+    QueryStatusPtr tryGetProcessListElement(const String & current_query_id, const String & current_user);\n \n     /// limit for insert. 0 means no limit. Otherwise, when limit exceeded, an exception is thrown.\n     size_t max_insert_queries_amount = 0;\ndiff --git a/src/Interpreters/executeQuery.cpp b/src/Interpreters/executeQuery.cpp\nindex abca563de55f..86cf3401f039 100644\n--- a/src/Interpreters/executeQuery.cpp\n+++ b/src/Interpreters/executeQuery.cpp\n@@ -537,7 +537,7 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(\n         {\n             /// processlist also has query masked now, to avoid secrets leaks though SHOW PROCESSLIST by other users.\n             process_list_entry = context->getProcessList().insert(query_for_logging, ast.get(), context);\n-            context->setProcessListElement(&process_list_entry->get());\n+            context->setProcessListElement(process_list_entry->getQueryStatus());\n         }\n \n         /// Load external tables if they were provided\n@@ -713,9 +713,9 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(\n         if (process_list_entry)\n         {\n             /// Query was killed before execution\n-            if ((*process_list_entry)->isKilled())\n-                throw Exception(\"Query '\" + (*process_list_entry)->getInfo().client_info.current_query_id + \"' is killed in pending state\",\n-                    ErrorCodes::QUERY_WAS_CANCELLED);\n+            if (process_list_entry->getQueryStatus()->isKilled())\n+                throw Exception(ErrorCodes::QUERY_WAS_CANCELLED,\n+                    \"Query '{}' is killed in pending state\", process_list_entry->getQueryStatus()->getInfo().client_info.current_query_id);\n         }\n \n         /// Hold element of process list till end of query execution.\n@@ -859,7 +859,7 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(\n                                     pulling_pipeline = pipeline.pulling(),\n                                     query_span](QueryPipeline & query_pipeline) mutable\n             {\n-                QueryStatus * process_list_elem = context->getProcessListElement();\n+                QueryStatusPtr process_list_elem = context->getProcessListElement();\n \n                 if (process_list_elem)\n                 {\n@@ -1025,7 +1025,7 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(\n                 elem.exception_code = getCurrentExceptionCode();\n                 elem.exception = getCurrentExceptionMessage(false);\n \n-                QueryStatus * process_list_elem = context->getProcessListElement();\n+                QueryStatusPtr process_list_elem = context->getProcessListElement();\n                 const Settings & current_settings = context->getSettingsRef();\n \n                 /// Update performance counters before logging to query_log\ndiff --git a/src/Processors/Executors/CompletedPipelineExecutor.cpp b/src/Processors/Executors/CompletedPipelineExecutor.cpp\nindex 9e5ea3916bce..a4c7fe2f6874 100644\n--- a/src/Processors/Executors/CompletedPipelineExecutor.cpp\n+++ b/src/Processors/Executors/CompletedPipelineExecutor.cpp\n@@ -72,9 +72,9 @@ void CompletedPipelineExecutor::execute()\n         data->executor = std::make_shared<PipelineExecutor>(pipeline.processors, pipeline.process_list_element);\n         data->executor->setReadProgressCallback(pipeline.getReadProgressCallback());\n \n-        /// Avoid passing this to labmda, copy ptr to data instead.\n+        /// Avoid passing this to lambda, copy ptr to data instead.\n         /// Destructor of unique_ptr copy raw ptr into local variable first, only then calls object destructor.\n-        auto func = [data_ptr = data.get(), num_threads = pipeline.getNumThreads(), thread_group = CurrentThread::getGroup()]()\n+        auto func = [data_ptr = data.get(), num_threads = pipeline.getNumThreads(), thread_group = CurrentThread::getGroup()]\n         {\n             threadFunction(*data_ptr, thread_group, num_threads);\n         };\ndiff --git a/src/Processors/Executors/CompletedPipelineExecutor.h b/src/Processors/Executors/CompletedPipelineExecutor.h\nindex e616cd6a2b71..65fab6035b14 100644\n--- a/src/Processors/Executors/CompletedPipelineExecutor.h\n+++ b/src/Processors/Executors/CompletedPipelineExecutor.h\n@@ -1,7 +1,9 @@\n #pragma once\n+\n #include <functional>\n #include <memory>\n \n+\n namespace DB\n {\n \ndiff --git a/src/Processors/Executors/ExecutingGraph.cpp b/src/Processors/Executors/ExecutingGraph.cpp\nindex 651ede10cfdb..9d69abc5e87c 100644\n--- a/src/Processors/Executors/ExecutingGraph.cpp\n+++ b/src/Processors/Executors/ExecutingGraph.cpp\n@@ -10,17 +10,17 @@ namespace ErrorCodes\n     extern const int LOGICAL_ERROR;\n }\n \n-ExecutingGraph::ExecutingGraph(Processors & processors_, bool profile_processors_)\n-    : processors(processors_)\n+ExecutingGraph::ExecutingGraph(std::shared_ptr<Processors> processors_, bool profile_processors_)\n+    : processors(std::move(processors_))\n     , profile_processors(profile_processors_)\n {\n-    uint64_t num_processors = processors.size();\n+    uint64_t num_processors = processors->size();\n     nodes.reserve(num_processors);\n \n     /// Create nodes.\n     for (uint64_t node = 0; node < num_processors; ++node)\n     {\n-        IProcessor * proc = processors[node].get();\n+        IProcessor * proc = processors->at(node).get();\n         processors_map[proc] = node;\n         nodes.emplace_back(std::make_unique<Node>(proc, node));\n     }\n@@ -109,10 +109,10 @@ bool ExecutingGraph::expandPipeline(std::stack<uint64_t> & stack, uint64_t pid)\n \n     {\n         std::lock_guard guard(processors_mutex);\n-        processors.insert(processors.end(), new_processors.begin(), new_processors.end());\n+        processors->insert(processors->end(), new_processors.begin(), new_processors.end());\n     }\n \n-    uint64_t num_processors = processors.size();\n+    uint64_t num_processors = processors->size();\n     std::vector<uint64_t> back_edges_sizes(num_processors, 0);\n     std::vector<uint64_t> direct_edge_sizes(num_processors, 0);\n \n@@ -126,7 +126,7 @@ bool ExecutingGraph::expandPipeline(std::stack<uint64_t> & stack, uint64_t pid)\n \n     while (nodes.size() < num_processors)\n     {\n-        auto * processor = processors[nodes.size()].get();\n+        auto * processor = processors->at(nodes.size()).get();\n         if (processors_map.contains(processor))\n             throw Exception(ErrorCodes::LOGICAL_ERROR, \"Processor {} was already added to pipeline\", processor->getName());\n \n@@ -386,7 +386,7 @@ bool ExecutingGraph::updateNode(uint64_t pid, Queue & queue, Queue & async_queue\n void ExecutingGraph::cancel()\n {\n     std::lock_guard guard(processors_mutex);\n-    for (auto & processor : processors)\n+    for (auto & processor : *processors)\n         processor->cancel();\n }\n \ndiff --git a/src/Processors/Executors/ExecutingGraph.h b/src/Processors/Executors/ExecutingGraph.h\nindex 587a2561ae02..b374f9681225 100644\n--- a/src/Processors/Executors/ExecutingGraph.h\n+++ b/src/Processors/Executors/ExecutingGraph.h\n@@ -1,4 +1,5 @@\n #pragma once\n+\n #include <Processors/Port.h>\n #include <Processors/IProcessor.h>\n #include <Processors/Executors/UpgradableLock.h>\n@@ -6,6 +7,7 @@\n #include <queue>\n #include <stack>\n \n+\n namespace DB\n {\n \n@@ -123,9 +125,9 @@ class ExecutingGraph\n     using ProcessorsMap = std::unordered_map<const IProcessor *, uint64_t>;\n     ProcessorsMap processors_map;\n \n-    explicit ExecutingGraph(Processors & processors_, bool profile_processors_);\n+    explicit ExecutingGraph(std::shared_ptr<Processors> processors_, bool profile_processors_);\n \n-    const Processors & getProcessors() const { return processors; }\n+    const Processors & getProcessors() const { return *processors; }\n \n     /// Traverse graph the first time to update all the childless nodes.\n     void initializeExecution(Queue & queue);\n@@ -149,7 +151,7 @@ class ExecutingGraph\n     /// All new nodes and nodes with updated ports are pushed into stack.\n     bool expandPipeline(std::stack<uint64_t> & stack, uint64_t pid);\n \n-    Processors & processors;\n+    std::shared_ptr<Processors> processors;\n     std::mutex processors_mutex;\n \n     UpgradableMutex nodes_mutex;\ndiff --git a/src/Processors/Executors/PipelineExecutor.cpp b/src/Processors/Executors/PipelineExecutor.cpp\nindex ae20d97604bf..3772381de042 100644\n--- a/src/Processors/Executors/PipelineExecutor.cpp\n+++ b/src/Processors/Executors/PipelineExecutor.cpp\n@@ -15,6 +15,7 @@\n     #include <Common/Stopwatch.h>\n #endif\n \n+\n namespace DB\n {\n \n@@ -24,8 +25,8 @@ namespace ErrorCodes\n }\n \n \n-PipelineExecutor::PipelineExecutor(Processors & processors, QueryStatus * elem)\n-    : process_list_element(elem)\n+PipelineExecutor::PipelineExecutor(std::shared_ptr<Processors> & processors, QueryStatusPtr elem)\n+    : process_list_element(std::move(elem))\n {\n     if (process_list_element)\n     {\n@@ -41,7 +42,7 @@ PipelineExecutor::PipelineExecutor(Processors & processors, QueryStatus * elem)\n         /// If exception was thrown while pipeline initialization, it means that query pipeline was not build correctly.\n         /// It is logical error, and we need more information about pipeline.\n         WriteBufferFromOwnString buf;\n-        printPipeline(processors, buf);\n+        printPipeline(*processors, buf);\n         buf.finalize();\n         exception.addMessage(\"Query pipeline:\\n\" + buf.str());\n \ndiff --git a/src/Processors/Executors/PipelineExecutor.h b/src/Processors/Executors/PipelineExecutor.h\nindex cea64d309faa..21bde312cbc8 100644\n--- a/src/Processors/Executors/PipelineExecutor.h\n+++ b/src/Processors/Executors/PipelineExecutor.h\n@@ -10,16 +10,19 @@\n #include <queue>\n #include <mutex>\n \n+\n namespace DB\n {\n \n class QueryStatus;\n+using QueryStatusPtr = std::shared_ptr<QueryStatus>;\n class ExecutingGraph;\n using ExecutingGraphPtr = std::unique_ptr<ExecutingGraph>;\n \n class ReadProgressCallback;\n using ReadProgressCallbackPtr = std::unique_ptr<ReadProgressCallback>;\n \n+\n /// Executes query pipeline.\n class PipelineExecutor\n {\n@@ -30,7 +33,7 @@ class PipelineExecutor\n     /// During pipeline execution new processors can appear. They will be added to existing set.\n     ///\n     /// Explicit graph representation is built in constructor. Throws if graph is not correct.\n-    explicit PipelineExecutor(Processors & processors, QueryStatus * elem);\n+    explicit PipelineExecutor(std::shared_ptr<Processors> & processors, QueryStatusPtr elem);\n     ~PipelineExecutor();\n \n     /// Execute pipeline in multiple threads. Must be called once.\n@@ -79,7 +82,7 @@ class PipelineExecutor\n     Poco::Logger * log = &Poco::Logger::get(\"PipelineExecutor\");\n \n     /// Now it's used to check if query was killed.\n-    QueryStatus * const process_list_element = nullptr;\n+    QueryStatusPtr process_list_element;\n \n     ReadProgressCallbackPtr read_progress_callback;\n \ndiff --git a/src/Processors/Executors/PushingAsyncPipelineExecutor.cpp b/src/Processors/Executors/PushingAsyncPipelineExecutor.cpp\nindex 7a55d26f16cd..ee8e94b6f28a 100644\n--- a/src/Processors/Executors/PushingAsyncPipelineExecutor.cpp\n+++ b/src/Processors/Executors/PushingAsyncPipelineExecutor.cpp\n@@ -129,7 +129,7 @@ PushingAsyncPipelineExecutor::PushingAsyncPipelineExecutor(QueryPipeline & pipel\n \n     pushing_source = std::make_shared<PushingAsyncSource>(pipeline.input->getHeader());\n     connect(pushing_source->getPort(), *pipeline.input);\n-    pipeline.processors.emplace_back(pushing_source);\n+    pipeline.processors->emplace_back(pushing_source);\n }\n \n PushingAsyncPipelineExecutor::~PushingAsyncPipelineExecutor()\ndiff --git a/src/Processors/Executors/PushingPipelineExecutor.cpp b/src/Processors/Executors/PushingPipelineExecutor.cpp\nindex bf43cd327fec..d9a14704cd08 100644\n--- a/src/Processors/Executors/PushingPipelineExecutor.cpp\n+++ b/src/Processors/Executors/PushingPipelineExecutor.cpp\n@@ -58,7 +58,7 @@ PushingPipelineExecutor::PushingPipelineExecutor(QueryPipeline & pipeline_) : pi\n \n     pushing_source = std::make_shared<PushingSource>(pipeline.input->getHeader(), input_wait_flag);\n     connect(pushing_source->getPort(), *pipeline.input);\n-    pipeline.processors.emplace_back(pushing_source);\n+    pipeline.processors->emplace_back(pushing_source);\n }\n \n PushingPipelineExecutor::~PushingPipelineExecutor()\ndiff --git a/src/Processors/Formats/Impl/MySQLOutputFormat.cpp b/src/Processors/Formats/Impl/MySQLOutputFormat.cpp\nindex 344c5c179db6..b4aafbd3d9e2 100644\n--- a/src/Processors/Formats/Impl/MySQLOutputFormat.cpp\n+++ b/src/Processors/Formats/Impl/MySQLOutputFormat.cpp\n@@ -74,7 +74,7 @@ void MySQLOutputFormat::finalizeImpl()\n {\n     size_t affected_rows = 0;\n     std::string human_readable_info;\n-    if (QueryStatus * process_list_elem = getContext()->getProcessListElement())\n+    if (QueryStatusPtr process_list_elem = getContext()->getProcessListElement())\n     {\n         CurrentThread::finalizePerformanceCounters();\n         QueryStatusInfo info = process_list_elem->getInfo();\ndiff --git a/src/Processors/QueryPlan/BuildQueryPipelineSettings.h b/src/Processors/QueryPlan/BuildQueryPipelineSettings.h\nindex fadbd061fbd5..3b5e4e06953c 100644\n--- a/src/Processors/QueryPlan/BuildQueryPipelineSettings.h\n+++ b/src/Processors/QueryPlan/BuildQueryPipelineSettings.h\n@@ -5,16 +5,18 @@\n \n #include <cstddef>\n \n+\n namespace DB\n {\n \n struct Settings;\n class QueryStatus;\n+using QueryStatusPtr = std::shared_ptr<QueryStatus>;\n \n struct BuildQueryPipelineSettings\n {\n     ExpressionActionsSettings actions_settings;\n-    QueryStatus * process_list_element = nullptr;\n+    QueryStatusPtr process_list_element;\n     ProgressCallback progress_callback = nullptr;\n \n     const ExpressionActionsSettings & getActionsSettings() const { return actions_settings; }\ndiff --git a/src/Processors/Transforms/CountingTransform.h b/src/Processors/Transforms/CountingTransform.h\nindex bd2ec58a27f9..05d8e2aeac89 100644\n--- a/src/Processors/Transforms/CountingTransform.h\n+++ b/src/Processors/Transforms/CountingTransform.h\n@@ -9,6 +9,7 @@ namespace DB\n {\n \n class QueryStatus;\n+using QueryStatusPtr = std::shared_ptr<QueryStatus>;\n class ThreadStatus;\n \n /// Proxy class which counts number of written block, rows, bytes\n@@ -29,7 +30,7 @@ class CountingTransform final : public ExceptionKeepingTransform\n         progress_callback = callback;\n     }\n \n-    void setProcessListElement(QueryStatus * elem)\n+    void setProcessListElement(QueryStatusPtr elem)\n     {\n         process_elem = elem;\n     }\n@@ -50,7 +51,7 @@ class CountingTransform final : public ExceptionKeepingTransform\n protected:\n     Progress progress;\n     ProgressCallback progress_callback;\n-    QueryStatus * process_elem = nullptr;\n+    QueryStatusPtr process_elem;\n     ThreadStatus * thread_status = nullptr;\n \n     /// Quota is used to limit amount of written bytes.\ndiff --git a/src/Processors/Transforms/buildPushingToViewsChain.cpp b/src/Processors/Transforms/buildPushingToViewsChain.cpp\nindex 174aaf67ec5c..830f400faf28 100644\n--- a/src/Processors/Transforms/buildPushingToViewsChain.cpp\n+++ b/src/Processors/Transforms/buildPushingToViewsChain.cpp\n@@ -620,9 +620,10 @@ void PushingToLiveViewSink::consume(Chunk chunk)\n {\n     Progress local_progress(chunk.getNumRows(), chunk.bytes(), 0);\n     StorageLiveView::writeIntoLiveView(live_view, getHeader().cloneWithColumns(chunk.detachColumns()), context);\n-    auto * process = context->getProcessListElement();\n-    if (process)\n+\n+    if (auto process = context->getProcessListElement())\n         process->updateProgressIn(local_progress);\n+\n     ProfileEvents::increment(ProfileEvents::SelectedRows, local_progress.read_rows);\n     ProfileEvents::increment(ProfileEvents::SelectedBytes, local_progress.read_bytes);\n }\n@@ -643,9 +644,10 @@ void PushingToWindowViewSink::consume(Chunk chunk)\n     Progress local_progress(chunk.getNumRows(), chunk.bytes(), 0);\n     StorageWindowView::writeIntoWindowView(\n         window_view, getHeader().cloneWithColumns(chunk.detachColumns()), context);\n-    auto * process = context->getProcessListElement();\n-    if (process)\n+\n+    if (auto process = context->getProcessListElement())\n         process->updateProgressIn(local_progress);\n+\n     ProfileEvents::increment(ProfileEvents::SelectedRows, local_progress.read_rows);\n     ProfileEvents::increment(ProfileEvents::SelectedBytes, local_progress.read_bytes);\n }\ndiff --git a/src/QueryPipeline/BlockIO.cpp b/src/QueryPipeline/BlockIO.cpp\nindex 35463ca6be99..9e42e06c722f 100644\n--- a/src/QueryPipeline/BlockIO.cpp\n+++ b/src/QueryPipeline/BlockIO.cpp\n@@ -53,9 +53,8 @@ void BlockIO::setAllDataSent() const\n     /// - internal\n     /// - SHOW PROCESSLIST\n     if (process_list_entry)\n-        (*process_list_entry)->setAllDataSent();\n+        process_list_entry->getQueryStatus()->setAllDataSent();\n }\n \n \n }\n-\ndiff --git a/src/QueryPipeline/BlockIO.h b/src/QueryPipeline/BlockIO.h\nindex 1f2a8f6f0334..b69f86ac684a 100644\n--- a/src/QueryPipeline/BlockIO.h\n+++ b/src/QueryPipeline/BlockIO.h\n@@ -34,9 +34,8 @@ struct BlockIO\n     void onFinish()\n     {\n         if (finish_callback)\n-        {\n             finish_callback(pipeline);\n-        }\n+\n         pipeline.reset();\n     }\n \ndiff --git a/src/QueryPipeline/Pipe.cpp b/src/QueryPipeline/Pipe.cpp\nindex 291739079a28..62a928d814c3 100644\n--- a/src/QueryPipeline/Pipe.cpp\n+++ b/src/QueryPipeline/Pipe.cpp\n@@ -102,7 +102,12 @@ static OutputPort * uniteTotals(const OutputPortRawPtrs & ports, const Block & h\n     return totals_port;\n }\n \n+Pipe::Pipe() : processors(std::make_shared<Processors>())\n+{\n+}\n+\n Pipe::Pipe(ProcessorPtr source, OutputPort * output, OutputPort * totals, OutputPort * extremes)\n+    : processors(std::make_shared<Processors>())\n {\n     if (!source->getInputs().empty())\n         throw Exception(\n@@ -155,11 +160,12 @@ Pipe::Pipe(ProcessorPtr source, OutputPort * output, OutputPort * totals, Output\n     totals_port = totals;\n     extremes_port = extremes;\n     output_ports.push_back(output);\n-    processors.emplace_back(std::move(source));\n+    processors->emplace_back(std::move(source));\n     max_parallel_streams = 1;\n }\n \n Pipe::Pipe(ProcessorPtr source)\n+    : processors(std::make_shared<Processors>())\n {\n     checkSource(*source);\n \n@@ -168,18 +174,18 @@ Pipe::Pipe(ProcessorPtr source)\n \n     output_ports.push_back(&source->getOutputs().front());\n     header = output_ports.front()->getHeader();\n-    processors.emplace_back(std::move(source));\n+    processors->emplace_back(std::move(source));\n     max_parallel_streams = 1;\n }\n \n-Pipe::Pipe(Processors processors_) : processors(std::move(processors_))\n+Pipe::Pipe(std::shared_ptr<Processors> processors_) : processors(std::move(processors_))\n {\n     /// Create hash table with processors.\n     std::unordered_set<const IProcessor *> set;\n-    for (const auto & processor : processors)\n+    for (const auto & processor : *processors)\n         set.emplace(processor.get());\n \n-    for (auto & processor : processors)\n+    for (auto & processor : *processors)\n     {\n         for (const auto & port : processor->getInputs())\n         {\n@@ -225,7 +231,7 @@ Pipe::Pipe(Processors processors_) : processors(std::move(processors_))\n     max_parallel_streams = output_ports.size();\n \n     if (collected_processors)\n-        for (const auto & processor : processors)\n+        for (const auto & processor : *processors)\n             collected_processors->emplace_back(processor);\n }\n \n@@ -311,7 +317,7 @@ Pipe Pipe::unitePipes(Pipes pipes, Processors * collected_processors, bool allow\n         if (!allow_empty_header || pipe.header)\n             assertCompatibleHeader(pipe.header, res.header, \"Pipe::unitePipes\");\n \n-        res.processors.insert(res.processors.end(), pipe.processors.begin(), pipe.processors.end());\n+        res.processors->insert(res.processors->end(), pipe.processors->begin(), pipe.processors->end());\n         res.output_ports.insert(res.output_ports.end(), pipe.output_ports.begin(), pipe.output_ports.end());\n \n         res.max_parallel_streams += pipe.max_parallel_streams;\n@@ -323,15 +329,15 @@ Pipe Pipe::unitePipes(Pipes pipes, Processors * collected_processors, bool allow\n             extremes.emplace_back(pipe.extremes_port);\n     }\n \n-    size_t num_processors = res.processors.size();\n+    size_t num_processors = res.processors->size();\n \n-    res.totals_port = uniteTotals(totals, res.header, res.processors);\n-    res.extremes_port = uniteExtremes(extremes, res.header, res.processors);\n+    res.totals_port = uniteTotals(totals, res.header, *res.processors);\n+    res.extremes_port = uniteExtremes(extremes, res.header, *res.processors);\n \n     if (res.collected_processors)\n     {\n-        for (; num_processors < res.processors.size(); ++num_processors)\n-            res.collected_processors->emplace_back(res.processors[num_processors]);\n+        for (; num_processors < res.processors->size(); ++num_processors)\n+            res.collected_processors->emplace_back(res.processors->at(num_processors));\n     }\n \n     return res;\n@@ -351,7 +357,7 @@ void Pipe::addSource(ProcessorPtr source)\n         collected_processors->emplace_back(source);\n \n     output_ports.push_back(&source->getOutputs().front());\n-    processors.emplace_back(std::move(source));\n+    processors->emplace_back(std::move(source));\n \n     max_parallel_streams = std::max<size_t>(max_parallel_streams, output_ports.size());\n }\n@@ -373,7 +379,7 @@ void Pipe::addTotalsSource(ProcessorPtr source)\n         collected_processors->emplace_back(source);\n \n     totals_port = &source->getOutputs().front();\n-    processors.emplace_back(std::move(source));\n+    processors->emplace_back(std::move(source));\n }\n \n void Pipe::addExtremesSource(ProcessorPtr source)\n@@ -393,7 +399,7 @@ void Pipe::addExtremesSource(ProcessorPtr source)\n         collected_processors->emplace_back(source);\n \n     extremes_port = &source->getOutputs().front();\n-    processors.emplace_back(std::move(source));\n+    processors->emplace_back(std::move(source));\n }\n \n static void dropPort(OutputPort *& port, Processors & processors, Processors * collected_processors)\n@@ -413,12 +419,12 @@ static void dropPort(OutputPort *& port, Processors & processors, Processors * c\n \n void Pipe::dropTotals()\n {\n-    dropPort(totals_port, processors, collected_processors);\n+    dropPort(totals_port, *processors, collected_processors);\n }\n \n void Pipe::dropExtremes()\n {\n-    dropPort(extremes_port, processors, collected_processors);\n+    dropPort(extremes_port, *processors, collected_processors);\n }\n \n void Pipe::addTransform(ProcessorPtr transform)\n@@ -504,7 +510,7 @@ void Pipe::addTransform(ProcessorPtr transform, OutputPort * totals, OutputPort\n     if (collected_processors)\n         collected_processors->emplace_back(transform);\n \n-    processors.emplace_back(std::move(transform));\n+    processors->emplace_back(std::move(transform));\n \n     max_parallel_streams = std::max<size_t>(max_parallel_streams, output_ports.size());\n }\n@@ -595,7 +601,7 @@ void Pipe::addTransform(ProcessorPtr transform, InputPort * totals, InputPort *\n     if (collected_processors)\n         collected_processors->emplace_back(transform);\n \n-    processors.emplace_back(std::move(transform));\n+    processors->emplace_back(std::move(transform));\n \n     max_parallel_streams = std::max<size_t>(max_parallel_streams, output_ports.size());\n }\n@@ -647,7 +653,7 @@ void Pipe::addSimpleTransform(const ProcessorGetterWithStreamKind & getter)\n             if (collected_processors)\n                 collected_processors->emplace_back(transform);\n \n-            processors.emplace_back(std::move(transform));\n+            processors->emplace_back(std::move(transform));\n         }\n     };\n \n@@ -698,7 +704,7 @@ void Pipe::addChains(std::vector<Chain> chains)\n             if (collected_processors)\n                 collected_processors->emplace_back(transform);\n \n-            processors.emplace_back(std::move(transform));\n+            processors->emplace_back(std::move(transform));\n         }\n     }\n \n@@ -757,7 +763,7 @@ void Pipe::setSinks(const Pipe::ProcessorGetterWithStreamKind & getter)\n             transform = std::make_shared<NullSink>(stream->getHeader());\n \n         connect(*stream, transform->getInputs().front());\n-        processors.emplace_back(std::move(transform));\n+        processors->emplace_back(std::move(transform));\n     };\n \n     for (auto & port : output_ports)\n@@ -858,7 +864,7 @@ void Pipe::transform(const Transformer & transformer, bool check_ports)\n             collected_processors->emplace_back(processor);\n     }\n \n-    processors.insert(processors.end(), new_processors.begin(), new_processors.end());\n+    processors->insert(processors->end(), new_processors.begin(), new_processors.end());\n \n     max_parallel_streams = std::max<size_t>(max_parallel_streams, output_ports.size());\n }\ndiff --git a/src/QueryPipeline/Pipe.h b/src/QueryPipeline/Pipe.h\nindex 79d19a181935..7e30d9c990ea 100644\n--- a/src/QueryPipeline/Pipe.h\n+++ b/src/QueryPipeline/Pipe.h\n@@ -5,6 +5,7 @@\n #include <QueryPipeline/Chain.h>\n #include <QueryPipeline/SizeLimits.h>\n \n+\n namespace DB\n {\n \n@@ -27,13 +28,13 @@ class Pipe\n public:\n     /// Default constructor creates empty pipe. Generally, you cannot do anything with it except to check it is empty().\n     /// You cannot get empty pipe in any other way. All transforms check that result pipe is not empty.\n-    Pipe() = default;\n+    Pipe();\n     /// Create from source. Source must have no input ports and single output.\n     explicit Pipe(ProcessorPtr source);\n     /// Create from source with specified totals end extremes (may be nullptr). Ports should be owned by source.\n     explicit Pipe(ProcessorPtr source, OutputPort * output, OutputPort * totals, OutputPort * extremes);\n     /// Create from processors. Use all not-connected output ports as output_ports. Check invariants.\n-    explicit Pipe(Processors processors_);\n+    explicit Pipe(std::shared_ptr<Processors> processors_);\n \n     Pipe(const Pipe & other) = delete;\n     Pipe(Pipe && other) = default;\n@@ -41,7 +42,7 @@ class Pipe\n     Pipe & operator=(Pipe && other) = default;\n \n     const Block & getHeader() const { return header; }\n-    bool empty() const { return processors.empty(); }\n+    bool empty() const { return processors->empty(); }\n     size_t numOutputPorts() const { return output_ports.size(); }\n     size_t maxParallelStreams() const { return max_parallel_streams; }\n     OutputPort * getOutputPort(size_t pos) const { return output_ports[pos]; }\n@@ -96,15 +97,15 @@ class Pipe\n     /// Unite several pipes together. They should have same header.\n     static Pipe unitePipes(Pipes pipes);\n \n-    /// Get processors from Pipe. Use it with cautious, it is easy to loss totals and extremes ports.\n-    static Processors detachProcessors(Pipe pipe) { return std::move(pipe.processors); }\n+    /// Get processors from Pipe. Use it with caution, it is easy to lose totals and extremes ports.\n+    static Processors detachProcessors(Pipe pipe) { return *std::move(pipe.processors); }\n     /// Get processors from Pipe without destroying pipe (used for EXPLAIN to keep QueryPlan).\n-    const Processors & getProcessors() const { return processors; }\n+    const Processors & getProcessors() const { return *processors; }\n \n private:\n     /// Header is common for all output below.\n     Block header;\n-    Processors processors;\n+    std::shared_ptr<Processors> processors;\n \n     /// Output ports. Totals and extremes are allowed to be empty.\n     OutputPortRawPtrs output_ports;\ndiff --git a/src/QueryPipeline/PipelineResourcesHolder.h b/src/QueryPipeline/PipelineResourcesHolder.h\nindex 46b1024f384e..ed9eb68b7bac 100644\n--- a/src/QueryPipeline/PipelineResourcesHolder.h\n+++ b/src/QueryPipeline/PipelineResourcesHolder.h\n@@ -19,8 +19,9 @@ struct QueryPlanResourceHolder\n     QueryPlanResourceHolder();\n     QueryPlanResourceHolder(QueryPlanResourceHolder &&) noexcept;\n     ~QueryPlanResourceHolder();\n+\n     /// Custom move assignment does not destroy data from lhs. It appends data from rhs to lhs.\n-    QueryPlanResourceHolder& operator=(QueryPlanResourceHolder &&) noexcept;\n+    QueryPlanResourceHolder & operator=(QueryPlanResourceHolder &&) noexcept;\n \n     /// Some processors may implicitly use Context or temporary Storage created by Interpreter.\n     /// But lifetime of Streams is not nested in lifetime of Interpreters, so we have to store it here,\ndiff --git a/src/QueryPipeline/QueryPipeline.cpp b/src/QueryPipeline/QueryPipeline.cpp\nindex 31b18c7f7f0c..e0da4c4f0eb6 100644\n--- a/src/QueryPipeline/QueryPipeline.cpp\n+++ b/src/QueryPipeline/QueryPipeline.cpp\n@@ -21,6 +21,7 @@\n #include <Processors/Transforms/ExpressionTransform.h>\n #include <Processors/QueryPlan/ReadFromPreparedSource.h>\n \n+\n namespace DB\n {\n \n@@ -29,7 +30,11 @@ namespace ErrorCodes\n     extern const int LOGICAL_ERROR;\n }\n \n-QueryPipeline::QueryPipeline() = default;\n+QueryPipeline::QueryPipeline()\n+    : processors(std::make_shared<Processors>())\n+{\n+}\n+\n QueryPipeline::QueryPipeline(QueryPipeline &&) noexcept = default;\n QueryPipeline & QueryPipeline::operator=(QueryPipeline &&) noexcept = default;\n QueryPipeline::~QueryPipeline() = default;\n@@ -210,16 +215,16 @@ static void initRowsBeforeLimit(IOutputFormat * output_format)\n \n QueryPipeline::QueryPipeline(\n     QueryPlanResourceHolder resources_,\n-    Processors processors_)\n+    std::shared_ptr<Processors> processors_)\n     : resources(std::move(resources_))\n     , processors(std::move(processors_))\n {\n-    checkCompleted(processors);\n+    checkCompleted(*processors);\n }\n \n QueryPipeline::QueryPipeline(\n     QueryPlanResourceHolder resources_,\n-    Processors processors_,\n+    std::shared_ptr<Processors> processors_,\n     InputPort * input_)\n     : resources(std::move(resources_))\n     , processors(std::move(processors_))\n@@ -231,7 +236,7 @@ QueryPipeline::QueryPipeline(\n             \"Cannot create pushing QueryPipeline because its input port is connected or null\");\n \n     bool found_input = false;\n-    for (const auto & processor : processors)\n+    for (const auto & processor : *processors)\n     {\n         for (const auto & in : processor->getInputs())\n         {\n@@ -255,7 +260,7 @@ QueryPipeline::QueryPipeline(std::shared_ptr<ISource> source) : QueryPipeline(Pi\n \n QueryPipeline::QueryPipeline(\n     QueryPlanResourceHolder resources_,\n-    Processors processors_,\n+    std::shared_ptr<Processors> processors_,\n     OutputPort * output_,\n     OutputPort * totals_,\n     OutputPort * extremes_)\n@@ -265,7 +270,7 @@ QueryPipeline::QueryPipeline(\n     , totals(totals_)\n     , extremes(extremes_)\n {\n-    checkPulling(processors, output, totals, extremes);\n+    checkPulling(*processors, output, totals, extremes);\n }\n \n QueryPipeline::QueryPipeline(Pipe pipe)\n@@ -278,32 +283,34 @@ QueryPipeline::QueryPipeline(Pipe pipe)\n         extremes = pipe.getExtremesPort();\n \n         processors = std::move(pipe.processors);\n-        checkPulling(processors, output, totals, extremes);\n+        checkPulling(*processors, output, totals, extremes);\n     }\n     else\n     {\n         processors = std::move(pipe.processors);\n-        checkCompleted(processors);\n+        checkCompleted(*processors);\n     }\n }\n \n QueryPipeline::QueryPipeline(Chain chain)\n     : resources(chain.detachResources())\n+    , processors(std::make_shared<Processors>())\n     , input(&chain.getInputPort())\n     , num_threads(chain.getNumThreads())\n {\n-    processors.reserve(chain.getProcessors().size() + 1);\n+    processors->reserve(chain.getProcessors().size() + 1);\n     for (auto processor : chain.getProcessors())\n-        processors.emplace_back(std::move(processor));\n+        processors->emplace_back(std::move(processor));\n \n     auto sink = std::make_shared<EmptySink>(chain.getOutputPort().getHeader());\n     connect(chain.getOutputPort(), sink->getPort());\n-    processors.emplace_back(std::move(sink));\n+    processors->emplace_back(std::move(sink));\n \n     input = &chain.getInputPort();\n }\n \n QueryPipeline::QueryPipeline(std::shared_ptr<IOutputFormat> format)\n+    : processors(std::make_shared<Processors>())\n {\n     auto & format_main = format->getPort(IOutputFormat::PortKind::Main);\n     auto & format_totals = format->getPort(IOutputFormat::PortKind::Totals);\n@@ -313,14 +320,14 @@ QueryPipeline::QueryPipeline(std::shared_ptr<IOutputFormat> format)\n     {\n         auto source = std::make_shared<NullSource>(format_totals.getHeader());\n         totals = &source->getPort();\n-        processors.emplace_back(std::move(source));\n+        processors->emplace_back(std::move(source));\n     }\n \n     if (!extremes)\n     {\n         auto source = std::make_shared<NullSource>(format_extremes.getHeader());\n         extremes = &source->getPort();\n-        processors.emplace_back(std::move(source));\n+        processors->emplace_back(std::move(source));\n     }\n \n     connect(*totals, format_totals);\n@@ -332,7 +339,7 @@ QueryPipeline::QueryPipeline(std::shared_ptr<IOutputFormat> format)\n \n     output_format = format.get();\n \n-    processors.emplace_back(std::move(format));\n+    processors->emplace_back(std::move(format));\n }\n \n static void drop(OutputPort *& port, Processors & processors)\n@@ -354,11 +361,11 @@ void QueryPipeline::complete(std::shared_ptr<ISink> sink)\n     if (!pulling())\n         throw Exception(ErrorCodes::LOGICAL_ERROR, \"Pipeline must be pulling to be completed with sink\");\n \n-    drop(totals, processors);\n-    drop(extremes, processors);\n+    drop(totals, *processors);\n+    drop(extremes, *processors);\n \n     connect(*output, sink->getPort());\n-    processors.emplace_back(std::move(sink));\n+    processors->emplace_back(std::move(sink));\n     output = nullptr;\n }\n \n@@ -369,17 +376,17 @@ void QueryPipeline::complete(Chain chain)\n \n     resources = chain.detachResources();\n \n-    drop(totals, processors);\n-    drop(extremes, processors);\n+    drop(totals, *processors);\n+    drop(extremes, *processors);\n \n-    processors.reserve(processors.size() + chain.getProcessors().size() + 1);\n+    processors->reserve(processors->size() + chain.getProcessors().size() + 1);\n     for (auto processor : chain.getProcessors())\n-        processors.emplace_back(std::move(processor));\n+        processors->emplace_back(std::move(processor));\n \n     auto sink = std::make_shared<EmptySink>(chain.getOutputPort().getHeader());\n     connect(*output, chain.getInputPort());\n     connect(chain.getOutputPort(), sink->getPort());\n-    processors.emplace_back(std::move(sink));\n+    processors->emplace_back(std::move(sink));\n     output = nullptr;\n }\n \n@@ -400,7 +407,7 @@ void QueryPipeline::complete(Pipe pipe)\n     input = nullptr;\n \n     auto pipe_processors = Pipe::detachProcessors(std::move(pipe));\n-    processors.insert(processors.end(), pipe_processors.begin(), pipe_processors.end());\n+    processors->insert(processors->end(), pipe_processors.begin(), pipe_processors.end());\n }\n \n static void addMaterializing(OutputPort *& output, Processors & processors)\n@@ -421,9 +428,9 @@ void QueryPipeline::complete(std::shared_ptr<IOutputFormat> format)\n \n     if (format->expectMaterializedColumns())\n     {\n-        addMaterializing(output, processors);\n-        addMaterializing(totals, processors);\n-        addMaterializing(extremes, processors);\n+        addMaterializing(output, *processors);\n+        addMaterializing(totals, *processors);\n+        addMaterializing(extremes, *processors);\n     }\n \n     auto & format_main = format->getPort(IOutputFormat::PortKind::Main);\n@@ -434,14 +441,14 @@ void QueryPipeline::complete(std::shared_ptr<IOutputFormat> format)\n     {\n         auto source = std::make_shared<NullSource>(format_totals.getHeader());\n         totals = &source->getPort();\n-        processors.emplace_back(std::move(source));\n+        processors->emplace_back(std::move(source));\n     }\n \n     if (!extremes)\n     {\n         auto source = std::make_shared<NullSource>(format_extremes.getHeader());\n         extremes = &source->getPort();\n-        processors.emplace_back(std::move(source));\n+        processors->emplace_back(std::move(source));\n     }\n \n     connect(*output, format_main);\n@@ -455,7 +462,7 @@ void QueryPipeline::complete(std::shared_ptr<IOutputFormat> format)\n     initRowsBeforeLimit(format.get());\n     output_format = format.get();\n \n-    processors.emplace_back(std::move(format));\n+    processors->emplace_back(std::move(format));\n }\n \n Block QueryPipeline::getHeader() const\n@@ -475,7 +482,7 @@ void QueryPipeline::setProgressCallback(const ProgressCallback & callback)\n     progress_callback = callback;\n }\n \n-void QueryPipeline::setProcessListElement(QueryStatus * elem)\n+void QueryPipeline::setProcessListElement(QueryStatusPtr elem)\n {\n     process_list_element = elem;\n \n@@ -504,7 +511,7 @@ void QueryPipeline::setLimitsAndQuota(const StreamLocalLimits & limits, std::sha\n     transform->setQuota(quota_);\n     connect(*output, transform->getInputPort());\n     output = &transform->getOutputPort();\n-    processors.emplace_back(std::move(transform));\n+    processors->emplace_back(std::move(transform));\n }\n \n \n@@ -529,7 +536,7 @@ void QueryPipeline::addCompletedPipeline(QueryPipeline other)\n         throw Exception(ErrorCodes::LOGICAL_ERROR, \"Cannot add not completed pipeline\");\n \n     resources = std::move(other.resources);\n-    processors.insert(processors.end(), other.processors.begin(), other.processors.end());\n+    processors->insert(processors->end(), other.processors->begin(), other.processors->end());\n }\n \n void QueryPipeline::reset()\n@@ -560,9 +567,9 @@ void QueryPipeline::convertStructureTo(const ColumnsWithTypeAndName & columns)\n         ActionsDAG::MatchColumnsMode::Position);\n \n     auto actions = std::make_shared<ExpressionActions>(std::move(converting));\n-    addExpression(output, actions, processors);\n-    addExpression(totals, actions, processors);\n-    addExpression(extremes, actions, processors);\n+    addExpression(output, actions, *processors);\n+    addExpression(totals, actions, *processors);\n+    addExpression(extremes, actions, *processors);\n }\n \n std::unique_ptr<ReadProgressCallback> QueryPipeline::getReadProgressCallback() const\ndiff --git a/src/QueryPipeline/QueryPipeline.h b/src/QueryPipeline/QueryPipeline.h\nindex 1b88ede33493..63f444e6ec17 100644\n--- a/src/QueryPipeline/QueryPipeline.h\n+++ b/src/QueryPipeline/QueryPipeline.h\n@@ -4,6 +4,7 @@\n #include <QueryPipeline/StreamLocalLimits.h>\n #include <functional>\n \n+\n namespace DB\n {\n \n@@ -15,6 +16,7 @@ using ProcessorPtr = std::shared_ptr<IProcessor>;\n using Processors = std::vector<ProcessorPtr>;\n \n class QueryStatus;\n+using QueryStatusPtr = std::shared_ptr<QueryStatus>;\n \n struct Progress;\n using ProgressCallback = std::function<void(const Progress & progress)>;\n@@ -34,6 +36,7 @@ class ReadProgressCallback;\n struct ColumnWithTypeAndName;\n using ColumnsWithTypeAndName = std::vector<ColumnWithTypeAndName>;\n \n+\n class QueryPipeline\n {\n public:\n@@ -58,23 +61,23 @@ class QueryPipeline\n     /// completed\n     QueryPipeline(\n         QueryPlanResourceHolder resources_,\n-        Processors processors_);\n+        std::shared_ptr<Processors> processors_);\n \n     /// pushing\n     QueryPipeline(\n         QueryPlanResourceHolder resources_,\n-        Processors processors_,\n+        std::shared_ptr<Processors> processors_,\n         InputPort * input_);\n \n     /// pulling\n     QueryPipeline(\n         QueryPlanResourceHolder resources_,\n-        Processors processors_,\n+        std::shared_ptr<Processors> processors_,\n         OutputPort * output_,\n         OutputPort * totals_ = nullptr,\n         OutputPort * extremes_ = nullptr);\n \n-    bool initialized() const { return !processors.empty(); }\n+    bool initialized() const { return !processors->empty(); }\n     /// When initialized, exactly one of the following is true.\n     /// Use PullingPipelineExecutor or PullingAsyncPipelineExecutor.\n     bool pulling() const { return output != nullptr; }\n@@ -97,7 +100,7 @@ class QueryPipeline\n     size_t getNumThreads() const { return num_threads; }\n     void setNumThreads(size_t num_threads_) { num_threads = num_threads_; }\n \n-    void setProcessListElement(QueryStatus * elem);\n+    void setProcessListElement(QueryStatusPtr elem);\n     void setProgressCallback(const ProgressCallback & callback);\n     void setLimitsAndQuota(const StreamLocalLimits & limits, std::shared_ptr<const EnabledQuota> quota_);\n     bool tryGetResultRowsAndBytes(UInt64 & result_rows, UInt64 & result_bytes) const;\n@@ -119,7 +122,7 @@ class QueryPipeline\n     /// Add processors and resources from other pipeline. Other pipeline should be completed.\n     void addCompletedPipeline(QueryPipeline other);\n \n-    const Processors & getProcessors() const { return processors; }\n+    const Processors & getProcessors() const { return *processors; }\n \n     /// For pulling pipeline, convert structure to expected.\n     /// Trash, need to remove later.\n@@ -134,7 +137,7 @@ class QueryPipeline\n     std::shared_ptr<const EnabledQuota> quota;\n     bool update_profile_events = true;\n \n-    Processors processors;\n+    std::shared_ptr<Processors> processors;\n \n     InputPort * input = nullptr;\n \n@@ -142,7 +145,7 @@ class QueryPipeline\n     OutputPort * totals = nullptr;\n     OutputPort * extremes = nullptr;\n \n-    QueryStatus * process_list_element = nullptr;\n+    QueryStatusPtr process_list_element;\n \n     IOutputFormat * output_format = nullptr;\n \ndiff --git a/src/QueryPipeline/QueryPipelineBuilder.cpp b/src/QueryPipeline/QueryPipelineBuilder.cpp\nindex 440f123e8763..812bd155b423 100644\n--- a/src/QueryPipeline/QueryPipelineBuilder.cpp\n+++ b/src/QueryPipeline/QueryPipelineBuilder.cpp\n@@ -327,9 +327,9 @@ QueryPipelineBuilderPtr QueryPipelineBuilder::mergePipelines(\n         collected_processors->emplace_back(transform);\n \n     left->pipe.output_ports.front() = &transform->getOutputs().front();\n-    left->pipe.processors.emplace_back(transform);\n+    left->pipe.processors->emplace_back(transform);\n \n-    left->pipe.processors.insert(left->pipe.processors.end(), right->pipe.processors.begin(), right->pipe.processors.end());\n+    left->pipe.processors->insert(left->pipe.processors->end(), right->pipe.processors->begin(), right->pipe.processors->end());\n     left->pipe.header = left->pipe.output_ports.front()->getHeader();\n     left->pipe.max_parallel_streams = std::max(left->pipe.max_parallel_streams, right->pipe.max_parallel_streams);\n     return left;\n@@ -383,7 +383,7 @@ std::unique_ptr<QueryPipelineBuilder> QueryPipelineBuilder::joinPipelinesRightLe\n     /// Collect the NEW processors for the right pipeline.\n     QueryPipelineProcessorsCollector collector(*right);\n     /// Remember the last step of the right pipeline.\n-    ExpressionStep* step = typeid_cast<ExpressionStep*>(right->pipe.processors.back()->getQueryPlanStep());\n+    ExpressionStep* step = typeid_cast<ExpressionStep*>(right->pipe.processors->back()->getQueryPlanStep());\n     if (!step)\n     {\n         throw Exception(ErrorCodes::LOGICAL_ERROR, \"The top step of the right pipeline should be ExpressionStep\");\n@@ -467,7 +467,7 @@ std::unique_ptr<QueryPipelineBuilder> QueryPipelineBuilder::joinPipelinesRightLe\n         if (collected_processors)\n             collected_processors->emplace_back(joining);\n \n-        left->pipe.processors.emplace_back(std::move(joining));\n+        left->pipe.processors->emplace_back(std::move(joining));\n     }\n \n     if (left->hasTotals())\n@@ -482,14 +482,14 @@ std::unique_ptr<QueryPipelineBuilder> QueryPipelineBuilder::joinPipelinesRightLe\n         if (collected_processors)\n             collected_processors->emplace_back(joining);\n \n-        left->pipe.processors.emplace_back(std::move(joining));\n+        left->pipe.processors->emplace_back(std::move(joining));\n     }\n \n     /// Move the collected processors to the last step in the right pipeline.\n     Processors processors = collector.detachProcessors();\n     step->appendExtraProcessors(processors);\n \n-    left->pipe.processors.insert(left->pipe.processors.end(), right->pipe.processors.begin(), right->pipe.processors.end());\n+    left->pipe.processors->insert(left->pipe.processors->end(), right->pipe.processors->begin(), right->pipe.processors->end());\n     left->resources = std::move(right->resources);\n     left->pipe.header = left->pipe.output_ports.front()->getHeader();\n     left->pipe.max_parallel_streams = std::max(left->pipe.max_parallel_streams, right->pipe.max_parallel_streams);\n@@ -537,7 +537,7 @@ void QueryPipelineBuilder::addPipelineBefore(QueryPipelineBuilder pipeline)\n     addTransform(std::move(processor));\n }\n \n-void QueryPipelineBuilder::setProcessListElement(QueryStatus * elem)\n+void QueryPipelineBuilder::setProcessListElement(QueryStatusPtr elem)\n {\n     process_list_element = elem;\n }\ndiff --git a/src/QueryPipeline/QueryPipelineBuilder.h b/src/QueryPipeline/QueryPipelineBuilder.h\nindex 13b4d681b7d6..5a0694100ebb 100644\n--- a/src/QueryPipeline/QueryPipelineBuilder.h\n+++ b/src/QueryPipeline/QueryPipelineBuilder.h\n@@ -148,7 +148,7 @@ class QueryPipelineBuilder\n \n     const Block & getHeader() const { return pipe.getHeader(); }\n \n-    void setProcessListElement(QueryStatus * elem);\n+    void setProcessListElement(QueryStatusPtr elem);\n     void setProgressCallback(ProgressCallback callback);\n \n     /// Recommend number of threads for pipeline execution.\n@@ -189,7 +189,7 @@ class QueryPipelineBuilder\n     /// Sometimes, more streams are created then the number of threads for more optimal execution.\n     size_t max_threads = 0;\n \n-    QueryStatus * process_list_element = nullptr;\n+    QueryStatusPtr process_list_element;\n     ProgressCallback progress_callback = nullptr;\n \n     void checkInitialized();\ndiff --git a/src/QueryPipeline/ReadProgressCallback.cpp b/src/QueryPipeline/ReadProgressCallback.cpp\nindex bbdabb8e8d80..6692b0f96bd6 100644\n--- a/src/QueryPipeline/ReadProgressCallback.cpp\n+++ b/src/QueryPipeline/ReadProgressCallback.cpp\n@@ -2,6 +2,7 @@\n #include <Interpreters/ProcessList.h>\n #include <Access/EnabledQuota.h>\n \n+\n namespace ProfileEvents\n {\n     extern const Event SelectedRows;\n@@ -17,7 +18,7 @@ namespace ErrorCodes\n     extern const int TOO_MANY_BYTES;\n }\n \n-void ReadProgressCallback::setProcessListElement(QueryStatus * elem)\n+void ReadProgressCallback::setProcessListElement(QueryStatusPtr elem)\n {\n     process_list_elem = elem;\n     if (!elem)\ndiff --git a/src/QueryPipeline/ReadProgressCallback.h b/src/QueryPipeline/ReadProgressCallback.h\nindex f64123ef39dd..c8f0d4cf5373 100644\n--- a/src/QueryPipeline/ReadProgressCallback.h\n+++ b/src/QueryPipeline/ReadProgressCallback.h\n@@ -4,20 +4,23 @@\n #include <IO/Progress.h>\n #include <mutex>\n \n+\n namespace DB\n {\n \n class QueryStatus;\n+using QueryStatusPtr = std::shared_ptr<QueryStatus>;\n class EnabledQuota;\n \n struct StorageLimits;\n using StorageLimitsList = std::list<StorageLimits>;\n \n+\n class ReadProgressCallback\n {\n public:\n     void setQuota(const std::shared_ptr<const EnabledQuota> & quota_) { quota = quota_; }\n-    void setProcessListElement(QueryStatus * elem);\n+    void setProcessListElement(QueryStatusPtr elem);\n     void setProgressCallback(const ProgressCallback & callback) { progress_callback = callback; }\n     void addTotalRowsApprox(size_t value) { total_rows_approx += value; }\n \n@@ -30,7 +33,7 @@ class ReadProgressCallback\n private:\n     std::shared_ptr<const EnabledQuota> quota;\n     ProgressCallback progress_callback;\n-    QueryStatus * process_list_elem = nullptr;\n+    QueryStatusPtr process_list_elem;\n \n     /// The approximate total number of rows to read. For progress bar.\n     std::atomic_size_t total_rows_approx = 0;\ndiff --git a/src/Server/TCPHandler.cpp b/src/Server/TCPHandler.cpp\nindex 25a832ab7e35..962d5412b483 100644\n--- a/src/Server/TCPHandler.cpp\n+++ b/src/Server/TCPHandler.cpp\n@@ -377,8 +377,8 @@ void TCPHandler::runImpl()\n             after_send_progress.restart();\n \n             if (state.io.pipeline.pushing())\n-            /// FIXME: check explicitly that insert query suggests to receive data via native protocol,\n             {\n+                /// FIXME: check explicitly that insert query suggests to receive data via native protocol,\n                 state.need_receive_data_for_insert = true;\n                 processInsertQuery();\n                 state.io.onFinish();\n@@ -390,27 +390,30 @@ void TCPHandler::runImpl()\n             }\n             else if (state.io.pipeline.completed())\n             {\n-                CompletedPipelineExecutor executor(state.io.pipeline);\n-                /// Should not check for cancel in case of input.\n-                if (!state.need_receive_data_for_input)\n                 {\n-                    auto callback = [this]()\n+                    CompletedPipelineExecutor executor(state.io.pipeline);\n+\n+                    /// Should not check for cancel in case of input.\n+                    if (!state.need_receive_data_for_input)\n                     {\n-                        std::lock_guard lock(fatal_error_mutex);\n+                        auto callback = [this]()\n+                        {\n+                            std::lock_guard lock(fatal_error_mutex);\n \n-                        if (isQueryCancelled())\n-                            return true;\n+                            if (isQueryCancelled())\n+                                return true;\n \n-                        sendProgress();\n-                        sendSelectProfileEvents();\n-                        sendLogs();\n+                            sendProgress();\n+                            sendSelectProfileEvents();\n+                            sendLogs();\n \n-                        return false;\n-                    };\n+                            return false;\n+                        };\n \n-                    executor.setCancelCallback(callback, interactive_delay / 1000);\n+                        executor.setCancelCallback(callback, interactive_delay / 1000);\n+                    }\n+                    executor.execute();\n                 }\n-                executor.execute();\n \n                 state.io.onFinish();\n                 /// Send final progress after calling onFinish(), since it will update the progress.\n",
  "test_patch": "diff --git a/src/Processors/tests/gtest_exception_on_incorrect_pipeline.cpp b/src/Processors/tests/gtest_exception_on_incorrect_pipeline.cpp\nindex b137eaf0f477..40718bd968a9 100644\n--- a/src/Processors/tests/gtest_exception_on_incorrect_pipeline.cpp\n+++ b/src/Processors/tests/gtest_exception_on_incorrect_pipeline.cpp\n@@ -23,11 +23,11 @@ TEST(Processors, PortsConnected)\n \n     connect(source->getPort(), sink->getPort());\n \n-    Processors processors;\n-    processors.emplace_back(std::move(source));\n-    processors.emplace_back(std::move(sink));\n+    auto processors = std::make_shared<Processors>();\n+    processors->emplace_back(std::move(source));\n+    processors->emplace_back(std::move(sink));\n \n-    QueryStatus * element = nullptr;\n+    QueryStatusPtr element;\n     PipelineExecutor executor(processors, element);\n     executor.execute(1);\n }\n@@ -46,14 +46,14 @@ TEST(Processors, PortsNotConnected)\n \n     /// connect(source->getPort(), sink->getPort());\n \n-    Processors processors;\n-    processors.emplace_back(std::move(source));\n-    processors.emplace_back(std::move(sink));\n+    auto processors = std::make_shared<Processors>();\n+    processors->emplace_back(std::move(source));\n+    processors->emplace_back(std::move(sink));\n \n #ifndef ABORT_ON_LOGICAL_ERROR\n     try\n     {\n-        QueryStatus * element = nullptr;\n+        QueryStatusPtr element;\n         PipelineExecutor executor(processors, element);\n         executor.execute(1);\n         ASSERT_TRUE(false) << \"Should have thrown.\";\ndiff --git a/tests/queries/0_stateless/02461_cancel_finish_race.reference b/tests/queries/0_stateless/02461_cancel_finish_race.reference\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/queries/0_stateless/02461_cancel_finish_race.sh b/tests/queries/0_stateless/02461_cancel_finish_race.sh\nnew file mode 100755\nindex 000000000000..7e775437da14\n--- /dev/null\n+++ b/tests/queries/0_stateless/02461_cancel_finish_race.sh\n@@ -0,0 +1,59 @@\n+#!/usr/bin/env bash\n+# Tags: no-fasttest\n+\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+# shellcheck source=../shell_config.sh\n+. \"$CURDIR\"/../shell_config.sh\n+\n+function thread_query()\n+{\n+    while true; do\n+        $CLICKHOUSE_CLIENT --query \"SELECT count() FROM numbers_mt(10000) WHERE rand() = 0 FORMAT Null\";\n+    done\n+}\n+\n+function thread_cancel()\n+{\n+    while true; do\n+        $CLICKHOUSE_CLIENT --query \"KILL QUERY WHERE current_database = '$CLICKHOUSE_DATABASE' SYNC FORMAT Null\";\n+    done\n+}\n+\n+# https://stackoverflow.com/questions/9954794/execute-a-shell-function-with-timeout\n+export -f thread_query;\n+export -f thread_cancel;\n+\n+TIMEOUT=30\n+\n+timeout $TIMEOUT bash -c thread_query 2> /dev/null &\n+timeout $TIMEOUT bash -c thread_cancel 2> /dev/null &\n+\n+timeout $TIMEOUT bash -c thread_query 2> /dev/null &\n+timeout $TIMEOUT bash -c thread_cancel 2> /dev/null &\n+\n+timeout $TIMEOUT bash -c thread_query 2> /dev/null &\n+timeout $TIMEOUT bash -c thread_cancel 2> /dev/null &\n+\n+timeout $TIMEOUT bash -c thread_query 2> /dev/null &\n+timeout $TIMEOUT bash -c thread_cancel 2> /dev/null &\n+\n+timeout $TIMEOUT bash -c thread_query 2> /dev/null &\n+timeout $TIMEOUT bash -c thread_cancel 2> /dev/null &\n+\n+timeout $TIMEOUT bash -c thread_query 2> /dev/null &\n+timeout $TIMEOUT bash -c thread_cancel 2> /dev/null &\n+\n+timeout $TIMEOUT bash -c thread_query 2> /dev/null &\n+timeout $TIMEOUT bash -c thread_cancel 2> /dev/null &\n+\n+timeout $TIMEOUT bash -c thread_query 2> /dev/null &\n+timeout $TIMEOUT bash -c thread_cancel 2> /dev/null &\n+\n+timeout $TIMEOUT bash -c thread_query 2> /dev/null &\n+timeout $TIMEOUT bash -c thread_cancel 2> /dev/null &\n+\n+timeout $TIMEOUT bash -c thread_query 2> /dev/null &\n+timeout $TIMEOUT bash -c thread_cancel 2> /dev/null &\n+\n+wait\n",
  "problem_statement": "ThreadSanitizer: data race between query finish and cancel\n```\r\nWARNING: ThreadSanitizer: data race (pid=661)\r\n  Write of size 8 at 0x7b6800590188 by thread T350:\r\n    #0 memset <null> (clickhouse+0xb89f44d) (BuildId: 34dcdceaa0c18fb90c4378c415f7da4e0b1622f0)\r\n    #1 std::__1::vector<std::__1::shared_ptr<DB::IProcessor>, std::__1::allocator<std::__1::shared_ptr<DB::IProcessor>>>::vector(std::__1::vector<std::__1::shared_ptr<DB::IProcessor>, std::__1::allocator<std::__1::shared_ptr<DB::IProcessor>>>&&) build_docker/../contrib/libcxx/include/vector:1194:31 (clickhouse+0x1ac8fb6f) (BuildId: 34dcdceaa0c18fb90c4378c415f7da4e0b1622f0)\r\n    #2 DB::QueryPipeline::QueryPipeline(DB::QueryPipeline&&) build_docker/../src/QueryPipeline/QueryPipeline.cpp:33:16 (clickhouse+0x1ac8fb6f)\r\n    #3 DB::QueryPipeline::reset() build_docker/../src/QueryPipeline/QueryPipeline.cpp:537:31 (clickhouse+0x1ac8fb6f)\r\n    #4 DB::BlockIO::onFinish() build_docker/../src/QueryPipeline/BlockIO.h:40:18 (clickhouse+0x1d22f087) (BuildId: 34dcdceaa0c18fb90c4378c415f7da4e0b1622f0)\r\n    #5 DB::TCPHandler::runImpl() build_docker/../src/Server/TCPHandler.cpp:403:26 (clickhouse+0x1d22f087)\r\n    #6 DB::TCPHandler::run() build_docker/../src/Server/TCPHandler.cpp:1884:9 (clickhouse+0x1d2420c7) (BuildId: 34dcdceaa0c18fb90c4378c415f7da4e0b1622f0)\r\n    #7 Poco::Net::TCPServerConnection::start() build_docker/../contrib/poco/Net/src/TCPServerConnection.cpp:43:3 (clickhouse+0x20a8fd62) (BuildId: 34dcdceaa0c18fb90c4378c415f7da4e0b1622f0)\r\n    #8 Poco::Net::TCPServerDispatcher::run() build_docker/../contrib/poco/Net/src/TCPServerDispatcher.cpp:115:20 (clickhouse+0x20a905d2) (BuildId: 34dcdceaa0c18fb90c4378c415f7da4e0b1622f0)\r\n    #9 Poco::PooledThread::run() build_docker/../contrib/poco/Foundation/src/ThreadPool.cpp:199:14 (clickhouse+0x20ce8239) (BuildId: 34dcdceaa0c18fb90c4378c415f7da4e0b1622f0)\r\n    #10 Poco::(anonymous namespace)::RunnableHolder::run() build_docker/../contrib/poco/Foundation/src/Thread.cpp:55:11 (clickhouse+0x20ce664f) (BuildId: 34dcdceaa0c18fb90c4378c415f7da4e0b1622f0)\r\n    #11 Poco::ThreadImpl::runnableEntry(void*) build_docker/../contrib/poco/Foundation/src/Thread_POSIX.cpp:345:27 (clickhouse+0x20ce4c87) (BuildId: 34dcdceaa0c18fb90c4378c415f7da4e0b1622f0)\r\n\r\n  Previous read of size 8 at 0x7b6800590188 by thread T359 (mutexes: write M0, write M1):\r\n    #0 std::__1::vector<std::__1::shared_ptr<DB::IProcessor>, std::__1::allocator<std::__1::shared_ptr<DB::IProcessor>>>::begin() build_docker/../contrib/libcxx/include/vector:1408:30 (clickhouse+0x1d2af3d7) (BuildId: 34dcdceaa0c18fb90c4378c415f7da4e0b1622f0)\r\n    #1 DB::ExecutingGraph::cancel() build_docker/../src/Processors/Executors/ExecutingGraph.cpp:389:27 (clickhouse+0x1d2af3d7)\r\n    #2 DB::PipelineExecutor::cancel() build_docker/../src/Processors/Executors/PipelineExecutor.cpp:73:12 (clickhouse+0x1d2a6aa0) (BuildId: 34dcdceaa0c18fb90c4378c415f7da4e0b1622f0)\r\n    #3 DB::QueryStatus::cancelQuery(bool) build_docker/../src/Interpreters/ProcessList.cpp:382:12 (clickhouse+0x1bed782f) (BuildId: 34dcdceaa0c18fb90c4378c415f7da4e0b1622f0)\r\n    #4 DB::ProcessList::sendCancelToQuery(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, bool) build_docker/../src/Interpreters/ProcessList.cpp:486:18 (clickhouse+0x1bed782f)\r\n    #5 DB::SyncKillQuerySource::generate() build_docker/../src/Interpreters/InterpreterKillQueryQuery.cpp:164:42 (clickhouse+0x1bdc15d4) (BuildId: 34dcdceaa0c18fb90c4378c415f7da4e0b1622f0)\r\n    #6 DB::ISource::tryGenerate() build_docker/../src/Processors/ISource.cpp:124:18 (clickhouse+0x1d290d54) (BuildId: 34dcdceaa0c18fb90c4378c415f7da4e0b1622f0)\r\n    #7 DB::ISource::work() build_docker/../src/Processors/ISource.cpp:94:26 (clickhouse+0x1d290789) (BuildId: 34dcdceaa0c18fb90c4378c415f7da4e0b1622f0)\r\n    #8 DB::executeJob(DB::ExecutingGraph::Node*, DB::ReadProgressCallback*) build_docker/../src/Processors/Executors/ExecutionThreadContext.cpp:47:26 (clickhouse+0x1d2b65e8) (BuildId: 34dcdceaa0c18fb90c4378c415f7da4e0b1622f0)\r\n    #9 DB::ExecutionThreadContext::executeTask() build_docker/../src/Processors/Executors/ExecutionThreadContext.cpp:92:9 (clickhouse+0x1d2b65e8)\r\n    #10 DB::PipelineExecutor::executeStepImpl(unsigned long, std::__1::atomic<bool>*) build_docker/../src/Processors/Executors/PipelineExecutor.cpp:228:26 (clickhouse+0x1d2a7aa0) (BuildId: 34dcdceaa0c18fb90c4378c415f7da4e0b1622f0)\r\n    #11 DB::PipelineExecutor::executeSingleThread(unsigned long) build_docker/../src/Processors/Executors/PipelineExecutor.cpp:194:5 (clickhouse+0x1d2a6dc2) (BuildId: 34dcdceaa0c18fb90c4378c415f7da4e0b1622f0)\r\n    #12 DB::PipelineExecutor::executeImpl(unsigned long) build_docker/../src/Processors/Executors/PipelineExecutor.cpp:367:9 (clickhouse+0x1d2a6dc2)\r\n    #13 DB::PipelineExecutor::execute(unsigned long) build_docker/../src/Processors/Executors/PipelineExecutor.cpp:89:9 (clickhouse+0x1d2a6b99) (BuildId: 34dcdceaa0c18fb90c4378c415f7da4e0b1622f0)\r\n    #14 DB::threadFunction(DB::PullingAsyncPipelineExecutor::Data&, std::__1::shared_ptr<DB::ThreadGroupStatus>, unsigned long) build_docker/../src/Processors/Executors/PullingAsyncPipelineExecutor.cpp:79:24 (clickhouse+0x1d2babd4) (BuildId: 34dcdceaa0c18fb90c4378c415f7da4e0b1622f0)\r\n    #15 DB::PullingAsyncPipelineExecutor::pull(DB::Chunk&, unsigned long)::$_0::operator()() const build_docker/../src/Processors/Executors/PullingAsyncPipelineExecutor.cpp:107:13 (clickhouse+0x1d2babd4)\r\n    #16 decltype(static_cast<DB::PullingAsyncPipelineExecutor::pull(DB::Chunk&, unsigned long)::$_0&>(fp)()) std::__1::__invoke_constexpr<DB::PullingAsyncPipelineExecutor::pull(DB::Chunk&, unsigned long)::$_0&>(DB::PullingAsyncPipelineExecutor::pull(DB::Chunk&, unsigned long)::$_0&) build_docker/../contrib/libcxx/include/type_traits:3648:23 (clickhouse+0x1d2babd4)\r\n    #17 decltype(auto) std::__1::__apply_tuple_impl<DB::PullingAsyncPipelineExecutor::pull(DB::Chunk&, unsigned long)::$_0&, std::__1::tuple<>&>(DB::PullingAsyncPipelineExecutor::pull(DB::Chunk&, unsigned long)::$_0&, std::__1::tuple<>&, std::__1::__tuple_indices<>) build_docker/../contrib/libcxx/include/tuple:1595:1 (clickhouse+0x1d2babd4)\r\n    #18 decltype(auto) std::__1::apply<DB::PullingAsyncPipelineExecutor::pull(DB::Chunk&, unsigned long)::$_0&, std::__1::tuple<>&>(DB::PullingAsyncPipelineExecutor::pull(DB::Chunk&, unsigned long)::$_0&, std::__1::tuple<>&) build_docker/../contrib/libcxx/include/tuple:1604:1 (clickhouse+0x1d2babd4)\r\n    #19 ThreadFromGlobalPoolImpl<true>::ThreadFromGlobalPoolImpl<DB::PullingAsyncPipelineExecutor::pull(DB::Chunk&, unsigned long)::$_0>(DB::PullingAsyncPipelineExecutor::pull(DB::Chunk&, unsigned long)::$_0&&)::'lambda'()::operator()() build_docker/../src/Common/ThreadPool.h:193:13 (clickhouse+0x1d2babd4)\r\n    #20 decltype(static_cast<DB::PullingAsyncPipelineExecutor::pull(DB::Chunk&, unsigned long)::$_0>(fp)()) std::__1::__invoke<ThreadFromGlobalPoolImpl<true>::ThreadFromGlobalPoolImpl<DB::PullingAsyncPipelineExecutor::pull(DB::Chunk&, unsigned long)::$_0>(DB::PullingAsyncPipelineExecutor::pull(DB::Chunk&, unsigned long)::$_0&&)::'lambda'()&>(DB::PullingAsyncPipelineExecutor::pull(DB::Chunk&, unsigned long)::$_0&&) build_docker/../contrib/libcxx/include/type_traits:3640:23 (clickhouse+0x1d2babd4)\r\n    #21 void std::__1::__invoke_void_return_wrapper<void, true>::__call<ThreadFromGlobalPoolImpl<true>::ThreadFromGlobalPoolImpl<DB::PullingAsyncPipelineExecutor::pull(DB::Chunk&, unsigned long)::$_0>(DB::PullingAsyncPipelineExecutor::pull(DB::Chunk&, unsigned long)::$_0&&)::'lambda'()&>(ThreadFromGlobalPoolImpl<true>::ThreadFromGlobalPoolImpl<DB::PullingAsyncPipelineExecutor::pull(DB::Chunk&, unsigned long)::$_0>(DB::PullingAsyncPipelineExecutor::pull(DB::Chunk&, unsigned long)::$_0&&)::'lambda'()&) build_docker/../contrib/libcxx/include/__functional/invoke.h:61:9 (clickhouse+0x1d2babd4)\r\n    #22 std::__1::__function::__default_alloc_func<ThreadFromGlobalPoolImpl<true>::ThreadFromGlobalPoolImpl<DB::PullingAsyncPipelineExecutor::pull(DB::Chunk&, unsigned long)::$_0>(DB::PullingAsyncPipelineExecutor::pull(DB::Chunk&, unsigned long)::$_0&&)::'lambda'(), void ()>::operator()() build_docker/../contrib/libcxx/include/__functional/function.h:230:12 (clickhouse+0x1d2babd4)\r\n    #23 void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<ThreadFromGlobalPoolImpl<true>::ThreadFromGlobalPoolImpl<DB::PullingAsyncPipelineExecutor::pull(DB::Chunk&, unsigned long)::$_0>(DB::PullingAsyncPipelineExecutor::pull(DB::Chunk&, unsigned long)::$_0&&)::'lambda'(), void ()>>(std::__1::__function::__policy_storage const*) build_docker/../contrib/libcxx/include/__functional/function.h:711:16 (clickhouse+0x1d2babd4)\r\n    #24 std::__1::__function::__policy_func<void ()>::operator()() const build_docker/../contrib/libcxx/include/__functional/function.h:843:16 (clickhouse+0x1326d54e) (BuildId: 34dcdceaa0c18fb90c4378c415f7da4e0b1622f0)\r\n    #25 std::__1::function<void ()>::operator()() const build_docker/../contrib/libcxx/include/__functional/function.h:1184:12 (clickhouse+0x1326d54e)\r\n    #26 ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) build_docker/../src/Common/ThreadPool.cpp:294:17 (clickhouse+0x1326d54e)\r\n    #27 void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, long, std::__1::optional<unsigned long>, bool)::'lambda0'()::operator()() const build_docker/../src/Common/ThreadPool.cpp:144:73 (clickhouse+0x13271b51) (BuildId: 34dcdceaa0c18fb90c4378c415f7da4e0b1622f0)\r\n    #28 decltype(static_cast<void>(fp)()) std::__1::__invoke<void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, long, std::__1::optional<unsigned long>, bool)::'lambda0'()>(void&&) build_docker/../contrib/libcxx/include/type_traits:3640:23 (clickhouse+0x13271b51)\r\n    #29 void std::__1::__thread_execute<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, long, std::__1::optional<unsigned long>, bool)::'lambda0'()>(std::__1::tuple<void, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, long, std::__1::optional<unsigned long>, bool)::'lambda0'()>&, std::__1::__tuple_indices<>) build_docker/../contrib/libcxx/include/thread:282:5 (clickhouse+0x13271b51)\r\n    #30 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, long, std::__1::optional<unsigned long>, bool)::'lambda0'()>>(void*) build_docker/../contrib/libcxx/include/thread:293:5 (clickhouse+0x13271b51)\r\n```\r\n\r\nhttps://s3.amazonaws.com/clickhouse-test-reports/42190/352f57d1058def63fd35e3e7f9aa7c318d9d711d/stateless_tests__tsan__[1/3].html\n",
  "hints_text": "",
  "created_at": "2022-10-17T00:11:55Z",
  "modified_files": [
    "src/Client/LocalConnection.cpp",
    "src/Common/OvercommitTracker.cpp",
    "src/Formats/FormatFactory.cpp",
    "src/Interpreters/ClusterProxy/executeQuery.cpp",
    "src/Interpreters/Context.cpp",
    "src/Interpreters/Context.h",
    "src/Interpreters/ProcessList.cpp",
    "src/Interpreters/ProcessList.h",
    "src/Interpreters/executeQuery.cpp",
    "src/Processors/Executors/CompletedPipelineExecutor.cpp",
    "src/Processors/Executors/CompletedPipelineExecutor.h",
    "src/Processors/Executors/ExecutingGraph.cpp",
    "src/Processors/Executors/ExecutingGraph.h",
    "src/Processors/Executors/PipelineExecutor.cpp",
    "src/Processors/Executors/PipelineExecutor.h",
    "src/Processors/Executors/PushingAsyncPipelineExecutor.cpp",
    "src/Processors/Executors/PushingPipelineExecutor.cpp",
    "src/Processors/Formats/Impl/MySQLOutputFormat.cpp",
    "src/Processors/QueryPlan/BuildQueryPipelineSettings.h",
    "src/Processors/Transforms/CountingTransform.h",
    "src/Processors/Transforms/buildPushingToViewsChain.cpp",
    "src/QueryPipeline/BlockIO.cpp",
    "src/QueryPipeline/BlockIO.h",
    "src/QueryPipeline/Pipe.cpp",
    "src/QueryPipeline/Pipe.h",
    "src/QueryPipeline/PipelineResourcesHolder.h",
    "src/QueryPipeline/QueryPipeline.cpp",
    "src/QueryPipeline/QueryPipeline.h",
    "src/QueryPipeline/QueryPipelineBuilder.cpp",
    "src/QueryPipeline/QueryPipelineBuilder.h",
    "src/QueryPipeline/ReadProgressCallback.cpp",
    "src/QueryPipeline/ReadProgressCallback.h",
    "src/Server/TCPHandler.cpp"
  ],
  "modified_test_files": [
    "src/Processors/tests/gtest_exception_on_incorrect_pipeline.cpp",
    "b/tests/queries/0_stateless/02461_cancel_finish_race.sh"
  ]
}