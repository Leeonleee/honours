You will be provided with a partial code base and an issue statement explaining a problem to resolve.

<issue>
Support large_utf8 column format on parquet
**Describe the unexpected behaviour**
Clickhouse does not support parquet with 'large_utf8' columns (only 'utf8'). From my understanding, the only difference is offsets are u64 in 'large_utf8' instead of u32

**How to reproduce**

```
import pyarrow
import pyarrow.parquet
import subprocess


for schema in (None,pyarrow.schema({"a": pyarrow.large_utf8()})):
    a = pyarrow.table({"a": ["00000"]}, schema=schema)
    pyarrow.parquet.write_table(a, "test.parquet")
    subprocess.run(
        """cat test.parquet | clickhouse local \
            --input-format "Parquet" \
            --structure "a String" \
            --query "select * from table"\
        """,
        shell=True,
        check=True,
    )

```
gives
```
00000
Code: 50. DB::Exception: Unsupported Parquet type 'large_utf8' of an input column 'a'.: While executing ParquetBlockInputFormat: While executing File. (UNKNOWN_TYPE)
```
</issue>

I need you to solve the provided issue by generating a code fix that can be applied directly to the repository

Respond below:
