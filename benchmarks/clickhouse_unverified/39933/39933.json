{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 39933,
  "instance_id": "ClickHouse__ClickHouse-39933",
  "issue_numbers": [
    "39546"
  ],
  "base_commit": "a3a124cc349adf95fff5016eac176bf33d2d3c67",
  "patch": "diff --git a/programs/server/Server.cpp b/programs/server/Server.cpp\nindex cdb828840bda..39d7b1d0e5b7 100644\n--- a/programs/server/Server.cpp\n+++ b/programs/server/Server.cpp\n@@ -1541,7 +1541,7 @@ int Server::main(const std::vector<std::string> & /*args*/)\n         /// We load temporary database first, because projections need it.\n         database_catalog.initializeAndLoadTemporaryDatabase();\n         loadMetadataSystem(global_context);\n-        maybeConvertOrdinaryDatabaseToAtomic(global_context, DatabaseCatalog::instance().getSystemDatabase());\n+        maybeConvertSystemDatabase(global_context);\n         /// After attaching system databases we can initialize system log.\n         global_context->initializeSystemLogs();\n         global_context->setSystemZooKeeperLogAfterInitializationIfNeeded();\n@@ -1555,6 +1555,7 @@ int Server::main(const std::vector<std::string> & /*args*/)\n         database_catalog.loadMarkedAsDroppedTables();\n         /// Then, load remaining databases\n         loadMetadata(global_context, default_database);\n+        convertDatabasesEnginesIfNeed(global_context);\n         startupSystemTables();\n         database_catalog.loadDatabases();\n         /// After loading validate that default database exists\ndiff --git a/src/Databases/DatabaseOrdinary.cpp b/src/Databases/DatabaseOrdinary.cpp\nindex 18b702223829..b008b13143a5 100644\n--- a/src/Databases/DatabaseOrdinary.cpp\n+++ b/src/Databases/DatabaseOrdinary.cpp\n@@ -198,6 +198,7 @@ void DatabaseOrdinary::loadTablesMetadata(ContextPtr local_context, ParsedTables\n                 if (fs::exists(full_path.string() + detached_suffix))\n                 {\n                     const std::string table_name = unescapeForFileName(file_name.substr(0, file_name.size() - 4));\n+                    permanently_detached_tables.push_back(table_name);\n                     LOG_DEBUG(log, \"Skipping permanently detached table {}.\", backQuote(table_name));\n                     return;\n                 }\ndiff --git a/src/Databases/DatabaseOrdinary.h b/src/Databases/DatabaseOrdinary.h\nindex 6e524ae18b0c..78a48adf9ec2 100644\n--- a/src/Databases/DatabaseOrdinary.h\n+++ b/src/Databases/DatabaseOrdinary.h\n@@ -36,6 +36,8 @@ class DatabaseOrdinary : public DatabaseOnDisk\n         const StorageID & table_id,\n         const StorageInMemoryMetadata & metadata) override;\n \n+    Strings getNamesOfPermanentlyDetachedTables() const override { return permanently_detached_tables; }\n+\n protected:\n     virtual void commitAlterTable(\n         const StorageID & table_id,\n@@ -43,6 +45,8 @@ class DatabaseOrdinary : public DatabaseOnDisk\n         const String & table_metadata_path,\n         const String & statement,\n         ContextPtr query_context);\n+\n+    Strings permanently_detached_tables;\n };\n \n }\ndiff --git a/src/Databases/IDatabase.h b/src/Databases/IDatabase.h\nindex 72155bc818c4..99ce0b51d547 100644\n--- a/src/Databases/IDatabase.h\n+++ b/src/Databases/IDatabase.h\n@@ -223,6 +223,13 @@ class IDatabase : public std::enable_shared_from_this<IDatabase>\n         throw Exception(\"There is no DETACH TABLE PERMANENTLY query for Database\" + getEngineName(), ErrorCodes::NOT_IMPLEMENTED);\n     }\n \n+    /// Returns list of table names that were permanently detached.\n+    /// This list may not be updated in runtime and may be filled only on server startup\n+    virtual Strings getNamesOfPermanentlyDetachedTables() const\n+    {\n+        throw Exception(\"Cannot get names of permanently detached tables for Database\" + getEngineName(), ErrorCodes::NOT_IMPLEMENTED);\n+    }\n+\n     /// Rename the table and possibly move the table to another database.\n     virtual void renameTable(\n         ContextPtr /*context*/,\ndiff --git a/src/Interpreters/loadMetadata.cpp b/src/Interpreters/loadMetadata.cpp\nindex 15d4f7929f87..be380043ddc3 100644\n--- a/src/Interpreters/loadMetadata.cpp\n+++ b/src/Interpreters/loadMetadata.cpp\n@@ -1,7 +1,5 @@\n #include <Common/ThreadPool.h>\n \n-#include <Poco/DirectoryIterator.h>\n-\n #include <Parsers/ParserCreateQuery.h>\n #include <Parsers/ASTCreateQuery.h>\n #include <Parsers/parseQuery.h>\n@@ -13,6 +11,7 @@\n \n #include <Databases/DatabaseOrdinary.h>\n #include <Databases/TablesLoader.h>\n+#include <Storages/StorageMaterializedView.h>\n \n #include <IO/ReadBufferFromFile.h>\n #include <IO/ReadHelpers.h>\n@@ -211,17 +210,12 @@ static void loadSystemDatabaseImpl(ContextMutablePtr context, const String & dat\n     }\n }\n \n-static void convertOrdinaryDatabaseToAtomic(ContextMutablePtr context, const DatabasePtr & database)\n+static void convertOrdinaryDatabaseToAtomic(Poco::Logger * log, ContextMutablePtr context, const DatabasePtr & database,\n+                                            const String & name, const String tmp_name)\n {\n     /// It's kind of C++ script that creates temporary database with Atomic engine,\n     /// moves all tables to it, drops old database and then renames new one to old name.\n \n-    Poco::Logger * log = &Poco::Logger::get(\"loadMetadata\");\n-\n-    String name = database->getDatabaseName();\n-\n-    String tmp_name = fmt::format(\".tmp_convert.{}.{}\", name, thread_local_rng());\n-\n     String name_quoted = backQuoteIfNeed(name);\n     String tmp_name_quoted = backQuoteIfNeed(tmp_name);\n \n@@ -235,19 +229,34 @@ static void convertOrdinaryDatabaseToAtomic(ContextMutablePtr context, const Dat\n     assert(tmp_database->getEngineName() == \"Atomic\");\n \n     size_t num_tables = 0;\n+    std::unordered_set<String> inner_mv_tables;\n     for (auto iterator = database->getTablesIterator(context); iterator->isValid(); iterator->next())\n     {\n         ++num_tables;\n         auto id = iterator->table()->getStorageID();\n         id.database_name = tmp_name;\n+        /// We need some uuid for checkTableCanBeRenamed\n+        id.uuid = UUIDHelpers::generateV4();\n         iterator->table()->checkTableCanBeRenamed(id);\n+        if (const auto * mv = dynamic_cast<const StorageMaterializedView *>(iterator->table().get()))\n+        {\n+            /// We should not rename inner tables of MVs, because MVs are responsible for renaming it...\n+            if (mv->hasInnerTable())\n+                inner_mv_tables.emplace(mv->getTargetTable()->getStorageID().table_name);\n+        }\n     }\n \n-    LOG_INFO(log, \"Will move {} tables to {}\", num_tables, tmp_name_quoted);\n+    LOG_INFO(log, \"Will move {} tables to {} (including {} inner tables of MVs)\", num_tables, tmp_name_quoted, inner_mv_tables.size());\n \n     for (auto iterator = database->getTablesIterator(context); iterator->isValid(); iterator->next())\n     {\n         auto id = iterator->table()->getStorageID();\n+        if (inner_mv_tables.contains(id.table_name))\n+        {\n+            LOG_DEBUG(log, \"Do not rename {}, because it will be renamed together with MV\", id.getNameForLogs());\n+            continue;\n+        }\n+\n         String qualified_quoted_name = id.getFullTableName();\n         id.database_name = tmp_name;\n         String tmp_qualified_quoted_name = id.getFullTableName();\n@@ -264,6 +273,7 @@ static void convertOrdinaryDatabaseToAtomic(ContextMutablePtr context, const Dat\n         throw Exception(ErrorCodes::LOGICAL_ERROR, \"Database {} is not empty after moving tables\", name_quoted);\n \n     String drop_query = fmt::format(\"DROP DATABASE {}\", name_quoted);\n+    context->setSetting(\"force_remove_data_recursively_on_drop\", false);\n     res = executeQuery(drop_query, context, true);\n     executeTrivialBlockIO(res, context);\n     res = {};\n@@ -275,31 +285,54 @@ static void convertOrdinaryDatabaseToAtomic(ContextMutablePtr context, const Dat\n     LOG_INFO(log, \"Finished database engine conversion of {}\", name_quoted);\n }\n \n-void maybeConvertOrdinaryDatabaseToAtomic(ContextMutablePtr context, const DatabasePtr & database)\n+/// Converts database with Ordinary engine to Atomic. Does nothing if database is not Ordinary.\n+/// Can be called only during server startup when there are no queries from users.\n+static void maybeConvertOrdinaryDatabaseToAtomic(ContextMutablePtr context, const String & database_name, bool tables_started)\n {\n-    if (database->getEngineName() != \"Ordinary\")\n+    Poco::Logger * log = &Poco::Logger::get(\"loadMetadata\");\n+\n+    auto database = DatabaseCatalog::instance().getDatabase(database_name);\n+    if (!database)\n+    {\n+        LOG_WARNING(log, \"Database {} not found (while trying to convert it from Ordinary to Atomic)\", database_name);\n         return;\n+    }\n \n-    if (context->getSettingsRef().allow_deprecated_database_ordinary)\n+    if (database->getEngineName() != \"Ordinary\")\n         return;\n \n+    Strings permanently_detached_tables = database->getNamesOfPermanentlyDetachedTables();\n+    if (!permanently_detached_tables.empty())\n+    {\n+        throw Exception(ErrorCodes::NOT_IMPLEMENTED, \"Cannot automatically convert database {} from Ordinary to Atomic, \"\n+                        \"because it contains permanently detached tables ({}) that were not loaded during startup. \"\n+                        \"Attach these tables, so server will load and convert them\",\n+                        database_name, fmt::join(permanently_detached_tables, \", \"));\n+    }\n+\n+    String tmp_name = fmt::format(\".tmp_convert.{}.{}\", database_name, thread_local_rng());\n+\n     try\n     {\n-        /// It's not quite correct to run DDL queries while database is not started up.\n-        startupSystemTables();\n+        if (!tables_started)\n+        {\n+            /// It's not quite correct to run DDL queries while database is not started up.\n+            ThreadPool pool;\n+            DatabaseCatalog::instance().getSystemDatabase()->startupTables(pool, /* force_restore */ true, /* force_attach */ true);\n+        }\n \n         auto local_context = Context::createCopy(context);\n         local_context->setSetting(\"check_table_dependencies\", false);\n-        convertOrdinaryDatabaseToAtomic(local_context, database);\n+        convertOrdinaryDatabaseToAtomic(log, local_context, database, database_name, tmp_name);\n \n-        auto new_database = DatabaseCatalog::instance().getDatabase(DatabaseCatalog::SYSTEM_DATABASE);\n+        auto new_database = DatabaseCatalog::instance().getDatabase(database_name);\n         UUID db_uuid = new_database->getUUID();\n         std::vector<UUID> tables_uuids;\n         for (auto iterator = new_database->getTablesIterator(context); iterator->isValid(); iterator->next())\n             tables_uuids.push_back(iterator->uuid());\n \n         /// Reload database just in case (and update logger name)\n-        String detach_query = fmt::format(\"DETACH DATABASE {}\", backQuoteIfNeed(DatabaseCatalog::SYSTEM_DATABASE));\n+        String detach_query = fmt::format(\"DETACH DATABASE {}\", backQuoteIfNeed(database_name));\n         auto res = executeQuery(detach_query, context, true);\n         executeTrivialBlockIO(res, context);\n         res = {};\n@@ -310,23 +343,54 @@ void maybeConvertOrdinaryDatabaseToAtomic(ContextMutablePtr context, const Datab\n         for (const auto & uuid : tables_uuids)\n             DatabaseCatalog::instance().removeUUIDMappingFinally(uuid);\n \n-        loadSystemDatabaseImpl(context, DatabaseCatalog::SYSTEM_DATABASE, \"Atomic\");\n+        String path = context->getPath() + \"metadata/\" + escapeForFileName(database_name);\n+        /// force_restore_data is needed to re-create metadata symlinks\n+        loadDatabase(context, database_name, path, /* force_restore_data */ true);\n+\n         TablesLoader::Databases databases =\n         {\n-            {DatabaseCatalog::SYSTEM_DATABASE, DatabaseCatalog::instance().getSystemDatabase()},\n+            {database_name, DatabaseCatalog::instance().getDatabase(database_name)},\n         };\n         TablesLoader loader{context, databases, /* force_restore */ true, /* force_attach */ true};\n         loader.loadTables();\n \n-        /// Will startup tables usual way\n+        /// Startup tables if they were started before conversion and detach/attach\n+        if (tables_started)\n+            loader.startupTables();\n     }\n     catch (Exception & e)\n     {\n-        e.addMessage(\"While trying to convert {} to Atomic\", database->getDatabaseName());\n+        e.addMessage(\"Exception while trying to convert database {} from Ordinary to Atomic. It may be in some intermediate state.\"\n+            \"You can finish conversion manually by moving the rest tables from {} to {} (using RENAME TABLE)\"\n+            \"and executing DROP DATABASE {} and RENAME DATABASE {} TO {}.\",\n+            database_name, database_name, tmp_name, database_name, tmp_name, database_name);\n         throw;\n     }\n }\n \n+void maybeConvertSystemDatabase(ContextMutablePtr context)\n+{\n+    /// TODO remove this check, convert system database unconditionally\n+    if (context->getSettingsRef().allow_deprecated_database_ordinary)\n+        return;\n+\n+    maybeConvertOrdinaryDatabaseToAtomic(context, DatabaseCatalog::SYSTEM_DATABASE, /* tables_started */ false);\n+}\n+\n+void convertDatabasesEnginesIfNeed(ContextMutablePtr context)\n+{\n+    auto convert_flag_path = fs::path(context->getFlagsPath()) / \"convert_ordinary_to_atomic\";\n+    if (!fs::exists(convert_flag_path))\n+        return;\n+\n+    LOG_INFO(&Poco::Logger::get(\"loadMetadata\"), \"Found convert_ordinary_to_atomic file in flags directory, \"\n+                                                 \"will try to convert all Ordinary databases to Atomic\");\n+    fs::remove(convert_flag_path);\n+\n+    for (const auto & [name, _] : DatabaseCatalog::instance().getDatabases())\n+        if (name != DatabaseCatalog::SYSTEM_DATABASE)\n+            maybeConvertOrdinaryDatabaseToAtomic(context, name, /* tables_started */ true);\n+}\n \n void startupSystemTables()\n {\ndiff --git a/src/Interpreters/loadMetadata.h b/src/Interpreters/loadMetadata.h\nindex 8dc332defc53..b229a2b4c314 100644\n--- a/src/Interpreters/loadMetadata.h\n+++ b/src/Interpreters/loadMetadata.h\n@@ -19,8 +19,10 @@ void loadMetadata(ContextMutablePtr context, const String & default_database_nam\n /// so we startup system tables after all databases are loaded.\n void startupSystemTables();\n \n-/// Converts database with Ordinary engine to Atomic. Does nothing if database is not Ordinary.\n-/// Can be called only during server startup when there are no queries from users.\n-void maybeConvertOrdinaryDatabaseToAtomic(ContextMutablePtr context, const DatabasePtr & database);\n+/// Converts `system` database from Ordinary to Atomic (if needed)\n+void maybeConvertSystemDatabase(ContextMutablePtr context);\n+\n+/// Converts all databases (except system) from Ordinary to Atomic if convert_ordinary_to_atomic flag exists\n+void convertDatabasesEnginesIfNeed(ContextMutablePtr context);\n \n }\ndiff --git a/src/Storages/StorageLog.cpp b/src/Storages/StorageLog.cpp\nindex ccb88992732d..c6bc55fd620e 100644\n--- a/src/Storages/StorageLog.cpp\n+++ b/src/Storages/StorageLog.cpp\n@@ -729,6 +729,7 @@ void StorageLog::rename(const String & new_path_to_table_data, const StorageID &\n {\n     assert(table_path != new_path_to_table_data);\n     {\n+        disk->createDirectories(new_path_to_table_data);\n         disk->moveDirectory(table_path, new_path_to_table_data);\n \n         table_path = new_path_to_table_data;\ndiff --git a/src/Storages/StorageReplicatedMergeTree.cpp b/src/Storages/StorageReplicatedMergeTree.cpp\nindex 90b516320008..cb77458502f6 100644\n--- a/src/Storages/StorageReplicatedMergeTree.cpp\n+++ b/src/Storages/StorageReplicatedMergeTree.cpp\n@@ -5261,9 +5261,28 @@ void StorageReplicatedMergeTree::checkTableCanBeRenamed(const StorageID & new_na\n         return;\n \n     if (renaming_restrictions == RenamingRestrictions::DO_NOT_ALLOW)\n-        throw Exception(\"Cannot rename Replicated table, because zookeeper_path contains implicit 'database' or 'table' macro. \"\n-                        \"We cannot rename path in ZooKeeper, so path may become inconsistent with table name. If you really want to rename table, \"\n-                        \"you should edit metadata file first and restart server or reattach the table.\", ErrorCodes::NOT_IMPLEMENTED);\n+    {\n+        auto old_name = getStorageID();\n+        bool is_server_startup = Context::getGlobalContextInstance()->getApplicationType() == Context::ApplicationType::SERVER\n+            && !Context::getGlobalContextInstance()->isServerCompletelyStarted();\n+        bool move_to_atomic = old_name.uuid == UUIDHelpers::Nil && new_name.uuid != UUIDHelpers::Nil;\n+\n+        bool likely_converting_ordinary_to_atomic = is_server_startup && move_to_atomic;\n+        if (likely_converting_ordinary_to_atomic)\n+        {\n+            LOG_INFO(log, \"Table {} should not be renamed, because zookeeper_path contains implicit 'database' or 'table' macro. \"\n+                          \"We cannot rename path in ZooKeeper, so path may become inconsistent with table name. \"\n+                          \"However, we allow renaming while converting Ordinary database to Atomic, because all tables will be renamed back\",\n+                          old_name.getNameForLogs());\n+            return;\n+        }\n+\n+        throw Exception(\n+            \"Cannot rename Replicated table, because zookeeper_path contains implicit 'database' or 'table' macro. \"\n+            \"We cannot rename path in ZooKeeper, so path may become inconsistent with table name. If you really want to rename table, \"\n+            \"you should edit metadata file first and restart server or reattach the table.\",\n+            ErrorCodes::NOT_IMPLEMENTED);\n+    }\n \n     assert(renaming_restrictions == RenamingRestrictions::ALLOW_PRESERVING_UUID);\n     if (!new_name.hasUUID() && getStorageID().hasUUID())\ndiff --git a/src/Storages/StorageStripeLog.cpp b/src/Storages/StorageStripeLog.cpp\nindex e3f477936db0..0ecbdb0db100 100644\n--- a/src/Storages/StorageStripeLog.cpp\n+++ b/src/Storages/StorageStripeLog.cpp\n@@ -320,6 +320,7 @@ void StorageStripeLog::rename(const String & new_path_to_table_data, const Stora\n {\n     assert(table_path != new_path_to_table_data);\n     {\n+        disk->createDirectories(new_path_to_table_data);\n         disk->moveDirectory(table_path, new_path_to_table_data);\n \n         table_path = new_path_to_table_data;\n",
  "test_patch": "diff --git a/tests/integration/test_backward_compatibility/test_convert_ordinary.py b/tests/integration/test_backward_compatibility/test_convert_ordinary.py\nindex c509dade0b82..afc44c91fc45 100644\n--- a/tests/integration/test_backward_compatibility/test_convert_ordinary.py\n+++ b/tests/integration/test_backward_compatibility/test_convert_ordinary.py\n@@ -7,6 +7,7 @@\n     image=\"yandex/clickhouse-server\",\n     tag=\"19.17.8.54\",\n     stay_alive=True,\n+    with_zookeeper=True,\n     with_installed_binary=True,\n )\n \n@@ -25,7 +26,7 @@ def q(query):\n     return node.query(query, settings={\"log_queries\": 1})\n \n \n-def test_convert_system_db_to_atomic(start_cluster):\n+def check_convert_system_db_to_atomic():\n     q(\n         \"CREATE TABLE t(date Date, id UInt32) ENGINE = MergeTree PARTITION BY toYYYYMM(date) ORDER BY id\"\n     )\n@@ -75,3 +76,167 @@ def test_convert_system_db_to_atomic(start_cluster):\n         \"1\\n\" == errors_count\n         and \"1\\n\" == node.count_in_log(\"Can't receive Netlink response\")\n     )\n+\n+\n+def create_some_tables(db):\n+    node.query(\"CREATE TABLE {}.t1 (n int) ENGINE=Memory\".format(db))\n+    node.query(\n+        \"CREATE TABLE {}.mt1 (n int) ENGINE=MergeTree order by n\".format(db),\n+    )\n+    node.query(\n+        \"CREATE TABLE {}.mt2 (n int) ENGINE=MergeTree order by n\".format(db),\n+    )\n+    node.query(\n+        \"CREATE TABLE {}.rmt1 (n int, m int) ENGINE=ReplicatedMergeTree('/test/rmt1/{}', '1') order by n\".format(\n+            db, db\n+        ),\n+    )\n+    node.query(\n+        \"CREATE TABLE {}.rmt2 (n int, m int) ENGINE=ReplicatedMergeTree('/test/{}/rmt2', '1') order by n\".format(\n+            db, db\n+        ),\n+    )\n+    node.exec_in_container(\n+        [\n+            \"bash\",\n+            \"-c\",\n+            f\"sed --follow-symlinks -i 's|/test/{db}/rmt2|/test/{{database}}/{{table}}|' /var/lib/clickhouse/metadata/{db}/rmt2.sql\",\n+        ]\n+    )\n+    node.query(\n+        \"CREATE MATERIALIZED VIEW {}.mv1 (n int) ENGINE=ReplicatedMergeTree('/test/{}/mv1/', '1') order by n AS SELECT n FROM {}.rmt1\".format(\n+            db, db, db\n+        ),\n+    )\n+    node.query(\n+        \"CREATE MATERIALIZED VIEW {}.mv2 (n int) ENGINE=MergeTree order by n AS SELECT n FROM {}.rmt2\".format(\n+            db, db\n+        ),\n+    )\n+    node.query(\n+        \"CREATE DICTIONARY {}.d1 (n int DEFAULT 0, m int DEFAULT 1) PRIMARY KEY n \"\n+        \"SOURCE(CLICKHOUSE(HOST 'localhost' PORT 9000 USER 'default' TABLE 'rmt1' PASSWORD '' DB '{}')) \"\n+        \"LIFETIME(MIN 1 MAX 10) LAYOUT(FLAT())\".format(db, db)\n+    )\n+    node.query(\n+        \"CREATE DICTIONARY {}.d2 (n int DEFAULT 0, m int DEFAULT 1) PRIMARY KEY n \"\n+        \"SOURCE(CLICKHOUSE(HOST 'localhost' PORT 9000 USER 'default' TABLE 'rmt2' PASSWORD '' DB '{}')) \"\n+        \"LIFETIME(MIN 1 MAX 10) LAYOUT(FLAT())\".format(db, db)\n+    )\n+    node.query(\n+        \"CREATE TABLE {}.merge (n int) ENGINE=Merge('{}', '(mt)|(mv)')\".format(db, db)\n+    )\n+    node.query(\"CREATE TABLE {}.detached (n int) ENGINE=Log\".format(db))\n+\n+\n+def check_convert_all_dbs_to_atomic():\n+    node.query(\n+        \"CREATE DATABASE ordinary ENGINE=Ordinary\",\n+        settings={\"allow_deprecated_database_ordinary\": 1},\n+    )\n+    node.query(\n+        \"CREATE DATABASE other ENGINE=Ordinary\",\n+        settings={\"allow_deprecated_database_ordinary\": 1},\n+    )\n+    node.query(\n+        \"CREATE DATABASE `.o r d i n a r y.` ENGINE=Ordinary\",\n+        settings={\"allow_deprecated_database_ordinary\": 1},\n+    )\n+    node.query(\"CREATE DATABASE atomic ENGINE=Atomic\")\n+    node.query(\"CREATE DATABASE mem ENGINE=Memory\")\n+    node.query(\"CREATE DATABASE lazy ENGINE=Lazy(1)\")\n+\n+    tables_with_data = [\"mt1\", \"mt2\", \"rmt1\", \"rmt2\", \"mv1\", \"mv2\", \"detached\"]\n+\n+    for db in [\"ordinary\", \"other\", \"atomic\"]:\n+        create_some_tables(db)\n+        for table in tables_with_data:\n+            node.query(\"INSERT INTO {}.{} (n) VALUES ({})\".format(db, table, len(db)))\n+\n+    node.query(\n+        \"CREATE TABLE `.o r d i n a r y.`.`t. a. b. l. e.` (n int) ENGINE=MergeTree ORDER BY n\"\n+    )\n+    node.query(\"CREATE TABLE lazy.table (n int) ENGINE=Log\")\n+\n+    # Introduce some cross dependencies\n+    node.query(\n+        \"CREATE TABLE ordinary.l (n DEFAULT dictGet('other.d1', 'm', toUInt64(3))) ENGINE=Log\"\n+    )\n+    node.query(\n+        \"CREATE TABLE other.l (n DEFAULT dictGet('ordinary.d1', 'm', toUInt64(3))) ENGINE=StripeLog\"\n+    )\n+\n+    node.query(\n+        \"CREATE TABLE atomic.l (n DEFAULT dictGet('ordinary.d1', 'm', toUInt64(3))) ENGINE=TinyLog\"\n+    )\n+\n+    tables_without_data = [\"t1\", \"d1\", \"d2\", \"merge\", \"l\"]\n+\n+    # 6 tables + 2 inner tables of MVs, each contains 2 rows\n+    for db in [\"ordinary\", \"other\"]:\n+        assert \"12\\t{}\\n\".format(12 * len(db)) == node.query(\n+            \"SELECT count(), sum(n) FROM {}.merge\".format(db)\n+        )\n+\n+    # 6 tables, MVs contain 2 rows (inner tables does not match regexp)\n+    assert \"8\\t{}\\n\".format(8 * len(\"atomic\")) == node.query(\n+        \"SELECT count(), sum(n) FROM atomic.merge\".format(db)\n+    )\n+\n+    node.query(\"DETACH TABLE ordinary.detached PERMANENTLY\")\n+\n+    node.exec_in_container(\n+        [\"bash\", \"-c\", f\"touch /var/lib/clickhouse/flags/convert_ordinary_to_atomic\"]\n+    )\n+    node.restart_clickhouse()\n+\n+    assert \"Ordinary\\n\" == node.query(\n+        \"SELECT engine FROM system.databases where name='ordinary'\"\n+    )\n+    node.query(\"ATTACH TABLE ordinary.detached\")\n+\n+    node.exec_in_container(\n+        [\"bash\", \"-c\", f\"touch /var/lib/clickhouse/flags/convert_ordinary_to_atomic\"]\n+    )\n+    node.restart_clickhouse()\n+\n+    assert (\n+        \".o r d i n a r y.\\natomic\\ndefault\\nordinary\\nother\\nsystem\\n\"\n+        == node.query(\n+            \"SELECT name FROM system.databases WHERE engine='Atomic' ORDER BY name\"\n+        )\n+    )\n+    assert \"Lazy\\nMemory\\n\" == node.query(\n+        \"SELECT engine FROM system.databases WHERE name IN ('mem', 'lazy') ORDER BY name\"\n+    )\n+    assert \"t. a. b. l. e.\\n\" == node.query(\"SHOW TABLES FROM `.o r d i n a r y.`\")\n+    assert \"table\\n\" == node.query(\"SHOW TABLES FROM lazy\")\n+\n+    for db in [\"ordinary\", \"other\", \"atomic\"]:\n+        assert \"\\n\".join(\n+            sorted(tables_with_data + tables_without_data) + [\"\"]\n+        ) == node.query(\"SHOW TABLES FROM {} NOT LIKE '%inner%'\".format(db))\n+\n+    for db in [\"ordinary\", \"other\"]:\n+        assert \"8\\t{}\\n\".format(8 * len(db)) == node.query(\n+            \"SELECT count(), sum(n) FROM {}.merge\".format(db)\n+        )\n+\n+    for db in [\"ordinary\", \"other\", \"atomic\"]:\n+        for table in tables_with_data:\n+            node.query(\n+                \"INSERT INTO {}.{} (n) VALUES ({})\".format(db, table, len(db) * 3)\n+            )\n+\n+    for db in [\"ordinary\", \"other\", \"atomic\"]:\n+        assert \"16\\t{}\\n\".format(16 * len(db) * 2) == node.query(\n+            \"SELECT count(), sum(n) FROM {}.merge\".format(db)\n+        )\n+        assert \"2\\t{}\\n\".format(2 * len(db) * 2) == node.query(\n+            \"SELECT count(), sum(n) FROM {}.detached\".format(db)\n+        )\n+\n+\n+def test_convert_ordinary_to_atomic(start_cluster):\n+    check_convert_system_db_to_atomic()\n+    check_convert_all_dbs_to_atomic()\n",
  "problem_statement": "Mechanism to migrate databases from Ordinary to Atomic engine\nOrdinary database engine is deprecated but there is no simple mean to change database engine to Atomic for existing databases.\r\n\r\nPossible options:\r\n- ALTER DATABASE MODIFY ENGINE query.\r\n- Flag that triggers migration at ClickHouse startup.\r\n\r\nThe latter should be easier to implement. \r\n\n",
  "hints_text": "Related: https://github.com/ClickHouse/ClickHouse/pull/38335\r\n\r\nI prefer the option with flag, but it makes sense to add a query that creates this flag as well (but not a synchronous query that converts database in runtime). \r\n\r\n",
  "created_at": "2022-08-05T19:44:13Z",
  "modified_files": [
    "programs/server/Server.cpp",
    "src/Databases/DatabaseOrdinary.cpp",
    "src/Databases/DatabaseOrdinary.h",
    "src/Databases/IDatabase.h",
    "src/Interpreters/loadMetadata.cpp",
    "src/Interpreters/loadMetadata.h",
    "src/Storages/StorageLog.cpp",
    "src/Storages/StorageReplicatedMergeTree.cpp",
    "src/Storages/StorageStripeLog.cpp"
  ],
  "modified_test_files": [
    "tests/integration/test_backward_compatibility/test_convert_ordinary.py"
  ]
}