You will be provided with a partial code base and an issue statement explaining a problem to resolve.

<issue>
Can not read iceberg table with glue catalog after schema evolution (rename column, delete column)
### Company or project name

_No response_

### Describe what's wrong

I perform different schema evolution actions like rename column, delete column etc.

After rename operation (RENAME COLUMN boolean_col TO new_boolean_col)
```sql
describe table iceberg_database.`iceberg.table`
```
I see both column in output.
```
new_boolean_col	Nullable(Bool)  
long_col	Nullable(Int64)  
double_col	Nullable(Float64)  
string_col	Nullable(String)  
date_col	Nullable(Date)  
boolean_col	Nullable(Bool)  
```

And when I try to select from the table:
```sql
SELECT * FROM iceberg_database.`iceberg.table` ORDER BY tuple(*) FORMAT TabSeparated
```
I get:
`
Code: 10. DB::Exception: Received from localhost:9000. DB::Exception: Not found column or subcolumn boolean_col in block. There are only columns: new_boolean_col, long_col, double_col, string_col, date_col: While executing IcebergS3(iceberg_database.`iceberg.table`)Source. (NOT_FOUND_COLUMN_IN_BLOCK)
`

### Does it reproduce on the most recent release?

Yes

### How to reproduce

1. Create database DataLakeCatalog with type=glue
2. Create iceberg table
3. Perform schema evolution action
4. Read from the table

I was using pyiceberg to create iceberg table and change schema.
As glue catalog I used localstack.



### Expected behavior

Successful select.

### Error message and/or stacktrace

After deleting column `double_col`:
```
Code: 10. DB::Exception: Received from localhost:9000. DB::Exception: Not found column or subcolumn double_col in block. There are only columns: boolean_col, long_col, string_col, date_col: While executing IcebergS3(iceberg_database_0c9ed3d9_4133_11f0_9df3_c76e50725ea7.`iceberg_0c9ed3da_4133_11f0_9df3_c76e50725ea7.table_0c9ed3db_4133_11f0_9df3_c76e50725ea7`)Source.
```
Describe table query shows deleted row.

_______________________________________

Looks like `add column`, `move column`, `update column type` actions work as expected.

### Additional context

I checked that I can correctly read table with PyIceberg and Spark to eliminate localstack as cause of a bug.

When I was using rest catalog and PyIceberg, I was able to read tables after schema evolution.
</issue>

I need you to solve the provided issue by generating a code fix that can be applied directly to the repository

Respond below:
