diff --git a/src/Storages/Kafka/KafkaBlockInputStream.cpp b/src/Storages/Kafka/KafkaBlockInputStream.cpp
index a2403e66c504..3e4533f8bb28 100644
--- a/src/Storages/Kafka/KafkaBlockInputStream.cpp
+++ b/src/Storages/Kafka/KafkaBlockInputStream.cpp
@@ -19,9 +19,8 @@ KafkaBlockInputStream::KafkaBlockInputStream(
     , column_names(columns)
     , max_block_size(max_block_size_)
     , commit_in_suffix(commit_in_suffix_)
-    , non_virtual_header(storage.getSampleBlockNonMaterialized()) /// FIXME: add materialized columns support
-    , virtual_header(storage.getSampleBlockForColumns({"_topic", "_key", "_offset", "_partition", "_timestamp"}))
-
+    , non_virtual_header(storage.getSampleBlockNonMaterialized())
+    , virtual_header(storage.getSampleBlockForColumns({"_topic", "_key", "_offset", "_partition", "_timestamp","_timestamp_ms","_headers.name","_headers.value"}))
 {
     context.setSetting("input_format_skip_unknown_fields", 1u); // Always skip unknown fields regardless of the context (JSON or TSKV)
     context.setSetting("input_format_allow_errors_ratio", 0.);
@@ -141,8 +140,22 @@ Block KafkaBlockInputStream::readImpl()
         auto offset        = buffer->currentOffset();
         auto partition     = buffer->currentPartition();
         auto timestamp_raw = buffer->currentTimestamp();
-        auto timestamp     = timestamp_raw ? std::chrono::duration_cast<std::chrono::seconds>(timestamp_raw->get_timestamp()).count()
-                                                : 0;
+        auto header_list   = buffer->currentHeaderList();
+
+        Array headers_names;
+        Array headers_values;
+
+        if (!header_list.empty())
+        {
+            headers_names.reserve(header_list.size());
+            headers_values.reserve(header_list.size());
+            for (const auto & header : header_list)
+            {
+                headers_names.emplace_back(header.get_name());
+                headers_values.emplace_back(static_cast<std::string>(header.get_value()));
+            }
+        }
+
         for (size_t i = 0; i < new_rows; ++i)
         {
             virtual_columns[0]->insert(topic);
@@ -151,12 +164,17 @@ Block KafkaBlockInputStream::readImpl()
             virtual_columns[3]->insert(partition);
             if (timestamp_raw)
             {
-                virtual_columns[4]->insert(timestamp);
+                auto ts = timestamp_raw->get_timestamp();
+                virtual_columns[4]->insert(std::chrono::duration_cast<std::chrono::seconds>(ts).count());
+                virtual_columns[5]->insert(DecimalField<Decimal64>(std::chrono::duration_cast<std::chrono::milliseconds>(ts).count(),3));
             }
             else
             {
                 virtual_columns[4]->insertDefault();
+                virtual_columns[5]->insertDefault();
             }
+            virtual_columns[6]->insert(headers_names);
+            virtual_columns[7]->insert(headers_values);
         }
 
         total_rows = total_rows + new_rows;
diff --git a/src/Storages/Kafka/ReadBufferFromKafkaConsumer.h b/src/Storages/Kafka/ReadBufferFromKafkaConsumer.h
index e90e3b488816..7449f58c838f 100644
--- a/src/Storages/Kafka/ReadBufferFromKafkaConsumer.h
+++ b/src/Storages/Kafka/ReadBufferFromKafkaConsumer.h
@@ -49,6 +49,7 @@ class ReadBufferFromKafkaConsumer : public ReadBuffer
     auto currentOffset() const { return current[-1].get_offset(); }
     auto currentPartition() const { return current[-1].get_partition(); }
     auto currentTimestamp() const { return current[-1].get_timestamp(); }
+    const auto & currentHeaderList() const { return current[-1].get_header_list(); }
 
 private:
     using Messages = std::vector<cppkafka::Message>;
diff --git a/src/Storages/Kafka/StorageKafka.cpp b/src/Storages/Kafka/StorageKafka.cpp
index 7731cf3c06a9..d1014fdb0f83 100644
--- a/src/Storages/Kafka/StorageKafka.cpp
+++ b/src/Storages/Kafka/StorageKafka.cpp
@@ -6,9 +6,11 @@
 #include <DataStreams/UnionBlockInputStream.h>
 #include <DataStreams/copyData.h>
 #include <DataTypes/DataTypeDateTime.h>
+#include <DataTypes/DataTypeDateTime64.h>
 #include <DataTypes/DataTypeNullable.h>
 #include <DataTypes/DataTypesNumber.h>
 #include <DataTypes/DataTypeString.h>
+#include <DataTypes/DataTypeArray.h>
 #include <Interpreters/InterpreterInsertQuery.h>
 #include <Interpreters/evaluateConstantExpression.h>
 #include <Parsers/ASTCreateQuery.h>
@@ -724,7 +726,10 @@ NamesAndTypesList StorageKafka::getVirtuals() const
         {"_key", std::make_shared<DataTypeString>()},
         {"_offset", std::make_shared<DataTypeUInt64>()},
         {"_partition", std::make_shared<DataTypeUInt64>()},
-        {"_timestamp", std::make_shared<DataTypeNullable>(std::make_shared<DataTypeDateTime>())}
+        {"_timestamp", std::make_shared<DataTypeNullable>(std::make_shared<DataTypeDateTime>())},
+        {"_timestamp_ms", std::make_shared<DataTypeNullable>(std::make_shared<DataTypeDateTime64>(3))},
+        {"_headers.name", std::make_shared<DataTypeArray>(std::make_shared<DataTypeString>())},
+        {"_headers.value", std::make_shared<DataTypeArray>(std::make_shared<DataTypeString>())}
     };
 }
 
